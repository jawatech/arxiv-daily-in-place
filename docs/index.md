# arxiv-daily
 Automated deployment @ 2024-12-05 20:38:56 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-04**|**Enhancing Supply Chain Visibility with Generative AI: An Exploratory Case Study on Relationship Prediction in Knowledge Graphs**|Ge Zheng et.al.|[2412.03390v1](http://arxiv.org/abs/2412.03390v1)|null|
|**2024-12-03**|**Hybrid-SQuAD: Hybrid Scholarly Question Answering Dataset**|Tilahun Abedissa Taffa et.al.|[2412.02788v1](http://arxiv.org/abs/2412.02788v1)|null|
|**2024-12-03**|**Characterizing Information Shared by Participants to Coding Challenges: The Case of Advent of Code**|Francesco Cauteruccio et.al.|[2412.02290v1](http://arxiv.org/abs/2412.02290v1)|null|
|**2024-12-02**|**A Neurosymbolic Fast and Slow Architecture for Graph Coloring**|Vedant Khandelwal et.al.|[2412.01752v1](http://arxiv.org/abs/2412.01752v1)|null|
|**2024-12-01**|**SelfPrompt: Autonomously Evaluating LLM Robustness via Domain-Constrained Knowledge Guidelines and Refined Adversarial Prompts**|Aihua Pei et.al.|[2412.00765v1](http://arxiv.org/abs/2412.00765v1)|null|
|**2024-11-30**|**Leveraging LLM for Automated Ontology Extraction and Knowledge Graph Generation**|Mohammad Sadeq Abolhasani et.al.|[2412.00608v2](http://arxiv.org/abs/2412.00608v2)|null|
|**2024-11-30**|**Opus: A Large Work Model for Complex Workflow Generation**|Théo Fagnoni et.al.|[2412.00573v1](http://arxiv.org/abs/2412.00573v1)|null|
|**2024-11-30**|**Node Importance Estimation Leveraging LLMs for Semantic Augmentation in Knowledge Graphs**|Xinyu Lin et.al.|[2412.00478v1](http://arxiv.org/abs/2412.00478v1)|[link](https://github.com/xinyulin-fz/lenie)|
|**2024-11-29**|**An AI-Driven Data Mesh Architecture Enhancing Decision-Making in Infrastructure Construction and Public Procurement**|Saurabh Mishra et.al.|[2412.00224v1](http://arxiv.org/abs/2412.00224v1)|null|
|**2024-11-29**|**PerLA: Perceptive 3D Language Assistant**|Guofeng Mei et.al.|[2411.19774v1](http://arxiv.org/abs/2411.19774v1)|null|
|**2024-11-29**|**Knowledge Management for Automobile Failure Analysis Using Graph RAG**|Yuta Ojima et.al.|[2411.19539v1](http://arxiv.org/abs/2411.19539v1)|null|
|**2024-11-28**|**Way to Specialist: Closing Loop Between Specialized LLM and Evolving Domain Knowledge Graph**|Yutong Zhang et.al.|[2411.19064v1](http://arxiv.org/abs/2411.19064v1)|null|
|**2024-11-28**|**EzSQL: An SQL intermediate representation for improving SQL-to-text Generation**|Meher Bhardwaj et.al.|[2411.18923v1](http://arxiv.org/abs/2411.18923v1)|null|
|**2024-11-27**|**MLLM-Search: A Zero-Shot Approach to Finding People using Multimodal Large Language Models**|Angus Fung et.al.|[2412.00103v1](http://arxiv.org/abs/2412.00103v1)|null|
|**2024-11-27**|**Regularized Multi-LLMs Collaboration for Enhanced Score-based Causal Discovery**|Xiaoxuan Li et.al.|[2411.17989v1](http://arxiv.org/abs/2411.17989v1)|null|
|**2024-11-26**|**ShowUI: One Vision-Language-Action Model for GUI Visual Agent**|Kevin Qinghong Lin et.al.|[2411.17465v1](http://arxiv.org/abs/2411.17465v1)|[link](https://github.com/showlab/showui)|
|**2024-11-26**|**Can LLMs be Good Graph Judger for Knowledge Graph Construction?**|Haoyu Huang et.al.|[2411.17388v1](http://arxiv.org/abs/2411.17388v1)|[link](https://github.com/hhy-huang/graphjudger)|
|**2024-11-26**|**Interleaved Scene Graph for Interleaved Text-and-Image Generation Assessment**|Dongping Chen et.al.|[2411.17188v1](http://arxiv.org/abs/2411.17188v1)|null|
|**2024-11-25**|**AtomR: Atomic Operator-Empowered Large Language Models for Heterogeneous Knowledge Reasoning**|Amy Xin et.al.|[2411.16495v2](http://arxiv.org/abs/2411.16495v2)|[link](https://github.com/THU-KEG/AtomR)|
|**2024-11-25**|**Learning by Analogy: Enhancing Few-Shot Prompting for Math Word Problem Solving with Computational Graph-Based Retrieval**|Xiaocong Yang et.al.|[2411.16454v1](http://arxiv.org/abs/2411.16454v1)|null|
|**2024-11-25**|**Adapter-based Approaches to Knowledge-enhanced Language Models -- A Survey**|Alexander Fichtl et.al.|[2411.16403v1](http://arxiv.org/abs/2411.16403v1)|null|
|**2024-11-24**|**Decoding Urban Industrial Complexity: Enhancing Knowledge-Driven Insights via IndustryScopeGPT**|Siqi Wang et.al.|[2411.15758v1](http://arxiv.org/abs/2411.15758v1)|[link](https://github.com/tongji-kgllm/industryscope)|
|**2024-11-22**|**One to rule them all: natural language to bind communication, perception and action**|Simone Colombani et.al.|[2411.15033v1](http://arxiv.org/abs/2411.15033v1)|null|
|**2024-11-22**|**Time is on my sight: scene graph filtering for dynamic environment perception in an LLM-driven robot**|Simone Colombani et.al.|[2411.15027v1](http://arxiv.org/abs/2411.15027v1)|null|
|**2024-11-22**|**GOT4Rec: Graph of Thoughts for Sequential Recommendation**|Zewen Long et.al.|[2411.14922v1](http://arxiv.org/abs/2411.14922v1)|null|
|**2024-11-22**|**VisGraphVar: A Benchmark Generator for Assessing Variability in Graph Analysis Using Large Vision-Language Models**|Camilo Chacón Sartori et.al.|[2411.14832v1](http://arxiv.org/abs/2411.14832v1)|null|
|**2024-11-22**|**MolReFlect: Towards In-Context Fine-grained Alignments between Molecules and Texts**|Jiatong Li et.al.|[2411.14721v1](http://arxiv.org/abs/2411.14721v1)|null|
|**2024-11-21**|**G-RAG: Knowledge Expansion in Material Science**|Radeen Mostafa et.al.|[2411.14592v2](http://arxiv.org/abs/2411.14592v2)|[link](https://github.com/RadeenXALNW/G-RAG_1.0)|
|**2024-11-21**|**Knowledge Graphs, Large Language Models, and Hallucinations: An NLP Perspective**|Ernests Lavrinovics et.al.|[2411.14258v1](http://arxiv.org/abs/2411.14258v1)|null|
|**2024-11-21**|**Logic Augmented Generation**|Aldo Gangemi et.al.|[2411.14012v1](http://arxiv.org/abs/2411.14012v1)|null|
|**2024-11-21**|**FastRAG: Retrieval Augmented Generation for Semi-structured Data**|Amar Abane et.al.|[2411.13773v1](http://arxiv.org/abs/2411.13773v1)|null|
|**2024-11-20**|**Predictive Insights into LGBTQ+ Minority Stress: A Transductive Exploration of Social Media Discourse**|S. Chapagain et.al.|[2411.13534v1](http://arxiv.org/abs/2411.13534v1)|[link](https://github.com/chapagaisa/transductive)|
|**2024-11-20**|**KAAE: Numerical Reasoning for Knowledge Graphs via Knowledge-aware Attributes Learning**|Ming Yin et.al.|[2411.12950v2](http://arxiv.org/abs/2411.12950v2)|null|
|**2024-11-19**|**Neurosymbolic Graph Enrichment for Grounded World Models**|Stefano De Giorgis et.al.|[2411.12671v1](http://arxiv.org/abs/2411.12671v1)|null|
|**2024-11-19**|**Instant Policy: In-Context Imitation Learning via Graph Diffusion**|Vitalis Vosylius et.al.|[2411.12633v1](http://arxiv.org/abs/2411.12633v1)|null|
|**2024-11-19**|**Bias-Free Sentiment Analysis through Semantic Blinding and Graph Neural Networks**|Hubert Plisiecki et.al.|[2411.12493v2](http://arxiv.org/abs/2411.12493v2)|null|
|**2024-11-19**|**Neon: News Entity-Interaction Extraction for Enhanced Question Answering**|Sneha Singhania et.al.|[2411.12449v2](http://arxiv.org/abs/2411.12449v2)|null|
|**2024-11-19**|**GRL-Prompt: Towards Knowledge Graph based Prompt Optimization via Reinforcement Learning**|Yuze Liu et.al.|[2411.14479v1](http://arxiv.org/abs/2411.14479v1)|null|
|**2024-11-19**|**Just KIDDIN: Knowledge Infusion and Distillation for Detection of INdecent Memes**|Rahul Garg et.al.|[2411.12174v1](http://arxiv.org/abs/2411.12174v1)|null|
|**2024-11-18**|**Regret-Free Reinforcement Learning for LTL Specifications**|Rupak Majumdar et.al.|[2411.12019v1](http://arxiv.org/abs/2411.12019v1)|null|
|**2024-11-18**|**Semantic-Geometric-Physical-Driven Robot Manipulation Skill Transfer via Skill Library and Tactile Representation**|Mingchao Qi et.al.|[2411.11714v1](http://arxiv.org/abs/2411.11714v1)|[link](https://github.com/mingchaoqi/skill_transfer)|
|**2024-11-18**|**Addressing Hallucinations in Language Models with Knowledge Graph Embeddings as an Additional Modality**|Viktoriia Chekalina et.al.|[2411.11531v1](http://arxiv.org/abs/2411.11531v1)|null|
|**2024-11-17**|**RPN 2: On Interdependence Function Learning Towards Unifying and Advancing CNN, RNN, GNN, and Transformer**|Jiawei Zhang et.al.|[2411.11162v1](http://arxiv.org/abs/2411.11162v1)|null|
|**2024-11-16**|**LLaSA: Large Language and Structured Data Assistant**|Yao Xu et.al.|[2411.14460v1](http://arxiv.org/abs/2411.14460v1)|null|
|**2024-11-16**|**Unveiling User Preferences: A Knowledge Graph and LLM-Driven Approach for Conversational Recommendation**|Zhangchi Qiu et.al.|[2411.14459v1](http://arxiv.org/abs/2411.14459v1)|null|
|**2024-11-16**|**A Novel Approach to Eliminating Hallucinations in Large Language Model-Assisted Causal Discovery**|Grace Sng et.al.|[2411.12759v1](http://arxiv.org/abs/2411.12759v1)|null|
|**2024-11-15**|**VeriGraph: Scene Graphs for Execution Verifiable Robot Planning**|Daniel Ekpo et.al.|[2411.10446v2](http://arxiv.org/abs/2411.10446v2)|null|
|**2024-11-15**|**A Survey of Event Causality Identification: Principles, Taxonomy, Challenges, and Assessment**|Qing Cheng et.al.|[2411.10371v2](http://arxiv.org/abs/2411.10371v2)|null|
|**2024-11-15**|**Prompting and Fine-tuning Large Language Models for Automated Code Review Comment Generation**|Md. Asif Haider et.al.|[2411.10129v1](http://arxiv.org/abs/2411.10129v1)|null|
|**2024-11-15**|**HistoLens: An LLM-Powered Framework for Multi-Layered Analysis of Historical Texts -- A Case Application of Yantie Lun**|Yifan Zeng et.al.|[2411.09978v1](http://arxiv.org/abs/2411.09978v1)|null|
|**2024-11-14**|**Accelerating Knowledge Graph and Ontology Engineering with Large Language Models**|Cogan Shimizu et.al.|[2411.09601v1](http://arxiv.org/abs/2411.09601v1)|null|
|**2024-11-14**|**Automating Reformulation of Essence Specifications via Graph Rewriting**|Ian Miguel et.al.|[2411.09576v1](http://arxiv.org/abs/2411.09576v1)|null|
|**2024-11-13**|**Towards Evaluating Large Language Models for Graph Query Generation**|Siraj Munir et.al.|[2411.08449v2](http://arxiv.org/abs/2411.08449v2)|null|
|**2024-11-13**|**Knowledge Bases in Support of Large Language Models for Processing Web News**|Yihe Zhang et.al.|[2411.08278v2](http://arxiv.org/abs/2411.08278v2)|null|
|**2024-11-12**|**Retrieval, Reasoning, Re-ranking: A Context-Enriched Framework for Knowledge Graph Completion**|Muzhi Li et.al.|[2411.08165v1](http://arxiv.org/abs/2411.08165v1)|null|
|**2024-11-12**|**Language Models as Causal Effect Generators**|Lucius E. J. Bynum et.al.|[2411.08019v1](http://arxiv.org/abs/2411.08019v1)|[link](https://github.com/lbynum/sequence-driven-scms)|
|**2024-11-12**|**From General to Specific: Utilizing General Hallucination to Benchmark Specific Role-Playing Agents**|Chuyi Kong et.al.|[2411.07965v2](http://arxiv.org/abs/2411.07965v2)|null|
|**2024-11-12**|**Chain Association-based Attacking and Shielding Natural Language Processing Systems**|Jiacheng Huang et.al.|[2411.07843v1](http://arxiv.org/abs/2411.07843v1)|null|
|**2024-11-11**|**Gradual Fine-Tuning with Graph Routing for Multi-Source Unsupervised Domain Adaptation**|Yao Ma et.al.|[2411.07185v1](http://arxiv.org/abs/2411.07185v1)|null|
|**2024-11-11**|**A Domain-Agnostic Neurosymbolic Approach for Big Social Data Analysis: Evaluating Mental Health Sentiment on Social Media during COVID-19**|Vedant Khandelwal et.al.|[2411.07163v1](http://arxiv.org/abs/2411.07163v1)|null|
|**2024-11-11**|**A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs**|Myeongsoo Kim et.al.|[2411.07098v1](http://arxiv.org/abs/2411.07098v1)|null|
|**2024-11-11**|**Bridge: A Unified Framework to Knowledge Graph Completion via Language Models and Knowledge Representation**|Qiao Qiao et.al.|[2411.06660v1](http://arxiv.org/abs/2411.06660v1)|null|
|**2024-11-10**|**CausalStock: Deep End-to-end Causal Discovery for News-driven Stock Movement Prediction**|Shuqi Li et.al.|[2411.06391v1](http://arxiv.org/abs/2411.06391v1)|null|
|**2024-11-09**|**Analyzing the Evolution of Graphs and Texts**|Xingzhi Guo et.al.|[2411.06295v1](http://arxiv.org/abs/2411.06295v1)|null|
|**2024-11-09**|**An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models**|Fatemeh Shiri et.al.|[2411.06048v1](http://arxiv.org/abs/2411.06048v1)|[link](https://github.com/fatemehshiri/spatial-mm)|
|**2024-11-08**|**Mitigating Hallucination with ZeroG: An Advanced Knowledge Management Engine**|Anantha Sharma et.al.|[2411.05936v1](http://arxiv.org/abs/2411.05936v1)|null|
|**2024-11-08**|**SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark**|Sithursan Sivasubramaniam et.al.|[2411.05521v2](http://arxiv.org/abs/2411.05521v2)|[link](https://github.com/jf87/sm3-text-to-query)|
|**2024-11-08**|**EUREKHA: Enhancing User Representation for Key Hackers Identification in Underground Forums**|Abdoul Nasser Hassane Amadou et.al.|[2411.05479v1](http://arxiv.org/abs/2411.05479v1)|[link](https://github.com/jumbo110/eurekha)|
|**2024-11-08**|**When are 1.58 bits enough? A Bottom-up Exploration of BitNet Quantization**|Jacob Nielsen et.al.|[2411.05882v1](http://arxiv.org/abs/2411.05882v1)|null|
|**2024-11-08**|**Exploring the Alignment Landscape: LLMs and Geometric Deep Models in Protein Representation**|Dong Shu et.al.|[2411.05316v1](http://arxiv.org/abs/2411.05316v1)|[link](https://github.com/tizzzzy/llm-gdm-alignment)|
|**2024-11-07**|**AMSnet-KG: A Netlist Dataset for LLM-based AMS Circuit Auto-Design Using Knowledge Graph RAG**|Yichen Shi et.al.|[2411.13560v1](http://arxiv.org/abs/2411.13560v1)|null|
|**2024-11-06**|**LEGO-GraphRAG: Modularizing Graph-based Retrieval-Augmented Generation for Design Space Exploration**|Yukun Cao et.al.|[2411.05844v1](http://arxiv.org/abs/2411.05844v1)|null|
|**2024-11-06**|**MEG: Medical Knowledge-Augmented Large Language Models for Question Answering**|Laura Cabello et.al.|[2411.03883v2](http://arxiv.org/abs/2411.03883v2)|[link](https://github.com/lautel/meg)|
|**2024-11-06**|**A Library Perspective on Supervised Text Processing in Digital Libraries: An Investigation in the Biomedical Domain**|Hermann Kroll et.al.|[2411.12752v1](http://arxiv.org/abs/2411.12752v1)|[link](https://github.com/hermannkroll/supervisedtextprocessing)|
|**2024-11-06**|**The American Sign Language Knowledge Graph: Infusing ASL Models with Linguistic Knowledge**|Lee Kezar et.al.|[2411.03568v1](http://arxiv.org/abs/2411.03568v1)|null|
|**2024-11-05**|**Graph-DPEP: Decomposed Plug and Ensemble Play for Few-Shot Document Relation Extraction with Graph-of-Thoughts Reasoning**|Tao Zhang et.al.|[2411.02864v1](http://arxiv.org/abs/2411.02864v1)|null|
|**2024-11-05**|**Multimodal Commonsense Knowledge Distillation for Visual Question Answering**|Shuo Yang et.al.|[2411.02722v1](http://arxiv.org/abs/2411.02722v1)|null|
|**2024-11-04**|**Geometry of orofacial neuromuscular signals: speech articulation decoding using surface electromyography**|Harshavardhana T. Gowda et.al.|[2411.02591v2](http://arxiv.org/abs/2411.02591v2)|[link](https://github.com/HarshavardhanaTG/geometryOfOrofacialNeuromuscularSystem)|
|**2024-11-04**|**GraphXAIN: Narratives to Explain Graph Neural Networks**|Mateusz Cedro et.al.|[2411.02540v2](http://arxiv.org/abs/2411.02540v2)|[link](https://github.com/ADMAntwerp/GraphXAIN)|
|**2024-11-04**|**Improving Scientific Hypothesis Generation with Knowledge Grounded Large Language Models**|Guangzhi Xiong et.al.|[2411.02382v1](http://arxiv.org/abs/2411.02382v1)|null|
|**2024-11-04**|**QCG-Rerank: Chunks Graph Rerank with Query Expansion in Retrieval-Augmented LLMs for Tourism Domain**|Qikai Wei et.al.|[2411.08724v1](http://arxiv.org/abs/2411.08724v1)|null|
|**2024-11-04**|**Can Language Models Enable In-Context Database?**|Yu Pan et.al.|[2411.01807v1](http://arxiv.org/abs/2411.01807v1)|null|
|**2024-11-03**|**Graph-based Confidence Calibration for Large Language Models**|Yukun Li et.al.|[2411.02454v1](http://arxiv.org/abs/2411.02454v1)|null|
|**2024-11-03**|**Ontology Population using LLMs**|Sanaz Saki Norouzi et.al.|[2411.01612v1](http://arxiv.org/abs/2411.01612v1)|null|
|**2024-11-03**|**Pre-trained Molecular Language Models with Random Functional Group Masking**|Tianhao Peng et.al.|[2411.01401v1](http://arxiv.org/abs/2411.01401v1)|null|
|**2024-11-01**|**Narrative Analysis of True Crime Podcasts With Knowledge Graph-Augmented Large Language Models**|Xinyi Leng et.al.|[2411.02435v1](http://arxiv.org/abs/2411.02435v1)|null|
|**2024-11-01**|**WLPlan: Relational Features for Symbolic Planning**|Dillon Z. Chen et.al.|[2411.00577v1](http://arxiv.org/abs/2411.00577v1)|null|
|**2024-11-01**|**GRS-QA -- Graph Reasoning-Structured Question Answering Dataset**|Anish Pahilajani et.al.|[2411.00369v3](http://arxiv.org/abs/2411.00369v3)|null|
|**2024-11-01**|**Evaluating the Impact of Lab Test Results on Large Language Models Generated Differential Diagnoses from Clinical Case Vignettes**|Balu Bhasuran et.al.|[2411.02523v1](http://arxiv.org/abs/2411.02523v1)|null|
|**2024-10-31**|**Compositional Automata Embeddings for Goal-Conditioned Reinforcement Learning**|Beyazit Yalcinkaya et.al.|[2411.00205v1](http://arxiv.org/abs/2411.00205v1)|null|
|**2024-10-31**|**Building Multi-Agent Copilot towards Autonomous Agricultural Data Management and Analysis**|Yu Pan et.al.|[2411.00188v1](http://arxiv.org/abs/2411.00188v1)|null|
|**2024-10-31**|**Exploring the Knowledge Mismatch Hypothesis: Hallucination Propensity in Small Models Fine-tuned on Data from Larger Models**|Phil Wee et.al.|[2411.00878v1](http://arxiv.org/abs/2411.00878v1)|null|
|**2024-10-31**|**Failure Modes of LLMs for Causal Reasoning on Narratives**|Khurram Yamin et.al.|[2410.23884v1](http://arxiv.org/abs/2410.23884v1)|[link](https://github.com/shantanu95/llm_causal_reasoning)|
|**2024-10-31**|**Plan-on-Graph: Self-Correcting Adaptive Planning of Large Language Model on Knowledge Graphs**|Liyi Chen et.al.|[2410.23875v1](http://arxiv.org/abs/2410.23875v1)|[link](https://github.com/liyichen-cly/pog)|
|**2024-10-31**|**LLaMo: Large Language Model-based Molecular Graph Assistant**|Jinyoung Park et.al.|[2411.00871v1](http://arxiv.org/abs/2411.00871v1)|[link](https://github.com/mlvlab/llamo)|
|**2024-10-31**|**End-to-End Ontology Learning with Large Language Models**|Andy Lo et.al.|[2410.23584v1](http://arxiv.org/abs/2410.23584v1)|[link](https://github.com/andylolu2/ollm)|
|**2024-10-30**|**Graph-Augmented Relation Extraction Model with LLMs-Generated Support Document**|Vicky Dong et.al.|[2410.23452v1](http://arxiv.org/abs/2410.23452v1)|null|
|**2024-10-30**|**FlowLLM: Flow Matching for Material Generation with Large Language Models as Base Distributions**|Anuroop Sriram et.al.|[2410.23405v1](http://arxiv.org/abs/2410.23405v1)|[link](https://github.com/facebookresearch/flowmm)|
|**2024-10-30**|**EMMA: End-to-End Multimodal Model for Autonomous Driving**|Jyh-Jing Hwang et.al.|[2410.23262v2](http://arxiv.org/abs/2410.23262v2)|null|
|**2024-10-30**|**ProTransformer: Robustify Transformers via Plug-and-Play Paradigm**|Zhichao Hou et.al.|[2410.23182v1](http://arxiv.org/abs/2410.23182v1)|null|

#### Abstracts
##### **Enhancing Supply Chain Visibility with Generative AI: An Exploratory Case Study on Relationship Prediction in Knowledge Graphs**
2412.03390v1 by Ge Zheng, Alexandra Brintrup

A key stumbling block in effective supply chain risk management for companies
and policymakers is a lack of visibility on interdependent supply network
relationships. Relationship prediction, also called link prediction is an
emergent area of supply chain surveillance research that aims to increase the
visibility of supply chains using data-driven techniques. Existing methods have
been successful for predicting relationships but struggle to extract the
context in which these relationships are embedded - such as the products being
supplied or locations they are supplied from. Lack of context prevents
practitioners from distinguishing transactional relations from established
supply chain relations, hindering accurate estimations of risk. In this work,
we develop a new Generative Artificial Intelligence (Gen AI) enhanced machine
learning framework that leverages pre-trained language models as embedding
models combined with machine learning models to predict supply chain
relationships within knowledge graphs. By integrating Generative AI techniques,
our approach captures the nuanced semantic relationships between entities,
thereby improving supply chain visibility and facilitating more precise risk
management. Using data from a real case study, we show that GenAI-enhanced link
prediction surpasses all benchmarks, and demonstrate how GenAI models can be
explored and effectively used in supply chain risk management.

摘要：供應鏈風險管理中的一個關鍵障礙在於企業和政策制定者缺乏對相互依存供應網路關係的能見度。關係預測，也稱為連結預測，是供應鏈監控研究中一個新興領域，旨在使用資料驅動技術提高供應鏈的能見度。現有方法已成功預測關係，但難以提取這些關係所嵌入的背景，例如所供應的產品或供應地點。缺乏背景會妨礙從業者區分交易關係和既定的供應鏈關係，進而阻礙風險的準確評估。在這項工作中，我們開發了一個新的生成式人工智慧 (Gen AI) 增強機器學習架構，它利用預先訓練的語言模型作為嵌入模型，並結合機器學習模型來預測知識圖譜中的供應鏈關係。透過整合生成式 AI 技術，我們的做法捕捉到實體之間細微的語義關係，從而提高供應鏈能見度並促進更精確的風險管理。使用來自真實案例研究的資料，我們證明 GenAI 增強連結預測優於所有基準，並展示如何探索和有效地在供應鏈風險管理中使用 GenAI 模型。

##### **Hybrid-SQuAD: Hybrid Scholarly Question Answering Dataset**
2412.02788v1 by Tilahun Abedissa Taffa, Debayan Baneerje, Yaregal Assabie, Ricardo Usbeck

Existing Scholarly Question Answering (QA) methods typically target
homogeneous data sources, relying solely on either text or Knowledge Graphs
(KGs). However, scholarly information often spans heterogeneous sources,
necessitating the development of QA systems that can integrate information from
multiple heterogeneous data sources. To address this challenge, we introduce
Hybrid-SQuAD (Hybrid Scholarly Question Answering Dataset), a novel large-scale
QA dataset designed to facilitate answering questions incorporating both text
and KG facts. The dataset consists of 10.5K question-answer pairs generated by
a large language model, leveraging the KGs - DBLP and SemOpenAlex alongside
corresponding text from Wikipedia. In addition, we propose a RAG-based baseline
hybrid QA model, achieving an exact match score of 69.65 on the Hybrid-SQuAD
test set.

摘要：現有的學術問答 (QA) 方法通常針對同質資料來源，僅依賴文字或知識圖譜 (KG)。然而，學術資訊常常橫跨異質來源，這使得我們必須開發能夠整合來自多個異質資料來源的資訊的 QA 系統。為了應對此挑戰，我們引入了 Hybrid-SQuAD（混合學術問答資料集），這是一個新穎的大型 QA 資料集，旨在促進回答包含文字和 KG 事實的提問。此資料集包含 10.5K 個問題解答對，這些對是由一個大型語言模型產生的，並利用了 KG（DBLP 和 SemOpenAlex）以及來自維基百科的對應文字。此外，我們提出了一個基於 RAG 的基準混合 QA 模型，在 Hybrid-SQuAD 測試集中達到了 69.65 的完全匹配分數。

##### **Characterizing Information Shared by Participants to Coding Challenges: The Case of Advent of Code**
2412.02290v1 by Francesco Cauteruccio, Enrico Corradini, Luca Virgili

Advent of Code (AoC from now on) is a popular coding challenge requiring to
solve programming puzzles for a variety of skill sets and levels. AoC follows
the advent calendar, therefore it is an annual challenge that lasts for 25
days. AoC participants usually post their solutions on social networks and
discuss them online. These challenges are interesting to study since they could
highlight the adoption of new tools, the evolution of the developer community,
or the technological requirements of well-known companies. For these reasons,
we first create a dataset of the 2019-2021 AoC editions containing the
discussion threads made on the subreddit {\tt /r/adventofcode}. Then, we
propose a model based on stream graphs to best study this context, where we
represent its most important actors through time: participants, comments, and
programming languages. Thanks to our model, we investigate user participation,
adoption of new programming languages during a challenge and between two of
them, and resiliency of programming languages based on a Stack Overflow survey.
We find that the top-used programming languages are almost the same in the
three years, pointing out their importance. Moreover, participants tend to keep
the same programming language for the whole challenge, while the ones attending
two AoCs usually change it in the next one. Finally, we observe interesting
results about the programming languages that are ``Popular'' or ``Loved''
according to the Stack Overflow survey. Firstly, these are the ones adopted for
the longest time in an AoC edition, thanks to which users have a high chance of
reaching the end of the challenge. Secondly, they are the most chosen when a
participant decides to change programming language during the same challenge.

摘要：降臨節密碼（以下簡稱 AoC）是一項流行的編碼挑戰，需要解決各種技能組和等級的程式設計謎題。AoC 遵循降臨曆，因此是一項為期 25 天的年度挑戰。AoC 參與者通常在社群網路上發布他們的解決方案，並在網路上討論它們。這些挑戰很有趣，因為它們可以突顯新工具的採用、開發人員社群的演進，或知名公司的技術需求。基於這些原因，我們首先建立一個包含在 subreddit {\tt /r/adventofcode} 上進行討論串的 2019-2021 年 AoC 版本資料集。然後，我們提出一個基於串流圖的模型來最佳研究此背景，其中我們隨著時間呈現其最重要的參與者：參與者、留言和程式語言。透過我們的模型，我們調查使用者參與度、在挑戰期間和兩者之間採用新程式語言的情況，以及根據 Stack Overflow 調查對程式語言的復原力。我們發現三年來最常用的程式語言幾乎相同，指出了它們的重要性。此外，參與者傾向於在整個挑戰中使用相同的程式語言，而參加兩個 AoC 的參與者通常會在下一場比賽中更換程式語言。最後，我們觀察到關於根據 Stack Overflow 調查被歸類為「熱門」或「喜愛」的程式語言的一些有趣結果。首先，這些程式語言是 AoC 版本中採用最久的程式語言，因此使用者有很高的機會完成挑戰。其次，當參與者決定在同一個挑戰中更改程式語言時，它們是最常被選用的程式語言。

##### **A Neurosymbolic Fast and Slow Architecture for Graph Coloring**
2412.01752v1 by Vedant Khandelwal, Vishal Pallagani, Biplav Srivastava, Francesca Rossi

Constraint Satisfaction Problems (CSPs) present significant challenges to
artificial intelligence due to their intricate constraints and the necessity
for precise solutions. Existing symbolic solvers are often slow, and prior
research has shown that Large Language Models (LLMs) alone struggle with CSPs
because of their complexity. To bridge this gap, we build upon the existing
SOFAI architecture (or SOFAI-v1), which adapts Daniel Kahneman's ''Thinking,
Fast and Slow'' cognitive model to AI. Our enhanced architecture, SOFAI-v2,
integrates refined metacognitive governance mechanisms to improve adaptability
across complex domains, specifically tailored for solving CSPs like graph
coloring. SOFAI-v2 combines a fast System 1 (S1) based on LLMs with a
deliberative System 2 (S2) governed by a metacognition module. S1's initial
solutions, often limited by non-adherence to constraints, are enhanced through
metacognitive governance, which provides targeted feedback and examples to
adapt S1 to CSP requirements. If S1 fails to solve the problem, metacognition
strategically invokes S2, ensuring accurate and reliable solutions. With
empirical results, we show that SOFAI-v2 for graph coloring problems achieves a
16.98% increased success rate and is 32.42% faster than symbolic solvers.

摘要：約束滿足問題 (CSP) 因為其複雜的約束和對精確解的必要性，對人工智慧提出了重大的挑戰。現有的符號求解器通常很慢，而先前的研究表明，大型語言模型 (LLM) 因為其複雜性而無法單獨處理 CSP。為了彌補這個差距，我們建立在現有的 SOFAI 架構（或 SOFAI-v1）之上，它將 Daniel Kahneman 的「快思慢想」認知模型調整為 AI。我們增強的架構 SOFAI-v2 整合了精緻的元認知治理機制，以提高跨複雜領域的適應性，特別是針對解決圖形著色等 CSP 而量身打造。SOFAI-v2 結合了基於 LLM 的快速系統 1 (S1) 和由元認知模組管控的審慎系統 2 (S2)。S1 的初始解法通常受到不遵守約束的限制，透過元認知治理得以增強，提供有針對性的回饋和範例，以適應 S1 的 CSP 需求。如果 S1 無法解決問題，元認知會策略性地呼叫 S2，確保準確且可靠的解法。透過經驗結果，我們展示了用於圖形著色問題的 SOFAI-v2 達到了成功率提高 16.98%，並且比符號求解器快 32.42%。

##### **SelfPrompt: Autonomously Evaluating LLM Robustness via Domain-Constrained Knowledge Guidelines and Refined Adversarial Prompts**
2412.00765v1 by Aihua Pei, Zehua Yang, Shunan Zhu, Ruoxi Cheng, Ju Jia

Traditional methods for evaluating the robustness of large language models
(LLMs) often rely on standardized benchmarks, which can escalate costs and
limit evaluations across varied domains. This paper introduces a novel
framework designed to autonomously evaluate the robustness of LLMs by
incorporating refined adversarial prompts and domain-constrained knowledge
guidelines in the form of knowledge graphs. Our method systematically generates
descriptive sentences from domain-constrained knowledge graph triplets to
formulate adversarial prompts, enhancing the relevance and challenge of the
evaluation. These prompts, generated by the LLM itself and tailored to evaluate
its own robustness, undergo a rigorous filtering and refinement process,
ensuring that only those with high textual fluency and semantic fidelity are
used. This self-evaluation mechanism allows the LLM to evaluate its robustness
without the need for external benchmarks. We assess the effectiveness of our
framework through extensive testing on both proprietary models like ChatGPT and
open-source models such as Llama-3.1, Phi-3, and Mistral. Results confirm that
our approach not only reduces dependency on conventional data but also provides
a targeted and efficient means of evaluating LLM robustness in constrained
domains.

摘要：傳統用於評估大型語言模型 (LLM) 穩健性的方法通常依賴標準化基準，這可能會增加成本並限制跨不同領域的評估。本文介紹了一個新穎的框架，旨在透過在知識圖譜的形式中納入精緻的對抗提示和領域約束知識準則，來自主評估 LLM 的穩健性。我們的做法是系統性地從領域約束知識圖譜三元組中產生描述性句子，以制定對抗提示，增強評估的相關性和挑戰性。這些提示是由 LLM 本身產生，並針對評估其自身的穩健性而量身打造，它們會經歷嚴格的過濾和精煉過程，確保只有那些具有高度文本流暢性和語義保真性的提示才會被使用。這種自我評估機制允許 LLM 在不需要外部基準的情況下評估其穩健性。我們透過對專有模型（例如 ChatGPT）和開源模型（例如 Llama-3.1、Phi-3 和 Mistral）進行廣泛測試，評估我們框架的有效性。結果證實，我們的做法不僅減少了對傳統資料的依賴性，還提供了一種有針對性和有效的方法，可以在受限領域中評估 LLM 的穩健性。

##### **Leveraging LLM for Automated Ontology Extraction and Knowledge Graph Generation**
2412.00608v2 by Mohammad Sadeq Abolhasani, Rong Pan

Extracting relevant and structured knowledge from large, complex technical
documents within the Reliability and Maintainability (RAM) domain is
labor-intensive and prone to errors. Our work addresses this challenge by
presenting OntoKGen, a genuine pipeline for ontology extraction and Knowledge
Graph (KG) generation. OntoKGen leverages Large Language Models (LLMs) through
an interactive user interface guided by our adaptive iterative Chain of Thought
(CoT) algorithm to ensure that the ontology extraction process and, thus, KG
generation align with user-specific requirements. Although KG generation
follows a clear, structured path based on the confirmed ontology, there is no
universally correct ontology as it is inherently based on the user's
preferences. OntoKGen recommends an ontology grounded in best practices,
minimizing user effort and providing valuable insights that may have been
overlooked, all while giving the user complete control over the final ontology.
Having generated the KG based on the confirmed ontology, OntoKGen enables
seamless integration into schemeless, non-relational databases like Neo4j. This
integration allows for flexible storage and retrieval of knowledge from
diverse, unstructured sources, facilitating advanced querying, analysis, and
decision-making. Moreover, the generated KG serves as a robust foundation for
future integration into Retrieval Augmented Generation (RAG) systems, offering
enhanced capabilities for developing domain-specific intelligent applications.

摘要：從可靠度和可維護性 (RAM) 領域中大量複雜的技術文件萃取相關且結構化的知識，是一項勞力密集且容易出錯的任務。我們的研究透過提供 OntoKGen 來解決這個挑戰，這是一個真正的本体萃取和知識圖譜 (KG) 生成管線。OntoKGen 透過一個互動式使用者介面，利用大型語言模型 (LLM) 並由我們自適應的迭代思考鏈 (CoT) 演算法引導，以確保本体萃取過程，以及隨之而來的 KG 生成，符合使用者特定的需求。雖然 KG 生成遵循一個明確的結構化路徑，基於已確認的本体，但並沒有一個普遍正確的本体，因為它本質上是基於使用者的偏好。OntoKGen 建議一個基於最佳實務的本体，將使用者的工作量降到最低，並提供有價值的見解，這些見解可能是被忽略的，同時讓使用者完全控制最終的本体。在基於已確認的本体產生 KG 之後，OntoKGen 能夠無縫整合到無模式、非關聯式資料庫，例如 Neo4j。這個整合允許從各種非結構化來源靈活地儲存和檢索知識，促進進階查詢、分析和決策制定。此外，生成的 KG 可作為未來整合到檢索增強生成 (RAG) 系統的穩固基礎，提供開發特定領域智慧型應用程式的增強功能。

##### **Opus: A Large Work Model for Complex Workflow Generation**
2412.00573v1 by Théo Fagnoni, Bellinda Mesbah, Mahsun Altin, Phillip Kingston

This paper introduces Opus, a novel framework for generating and optimizing
Workflows tailored to complex Business Process Outsourcing (BPO) use cases,
focusing on cost reduction and quality enhancement while adhering to
established industry processes and operational constraints. Our approach
generates executable Workflows from Intention, defined as the alignment of
Client Input, Client Output, and Process Context. These Workflows are
represented as Directed Acyclic Graphs (DAGs), with nodes as Tasks consisting
of sequences of executable Instructions, including tools and human expert
reviews. We adopt a two-phase methodology: Workflow Generation and Workflow
Optimization. In the Generation phase, Workflows are generated using a Large
Work Model (LWM) informed by a Work Knowledge Graph (WKG) that encodes
domain-specific procedural and operational knowledge. In the Optimization
phase, Workflows are transformed into Workflow Graphs (WFGs), where optimal
Workflows are determined through path optimization. Our experiments demonstrate
that state-of-the-art Large Language Models (LLMs) face challenges in reliably
retrieving detailed process data as well as generating industry-compliant
workflows. The key contributions of this paper include: - The integration of a
Work Knowledge Graph (WKG) into a Large Work Model (LWM), enabling the
generation of context-aware, semantically aligned, structured and auditable
Workflows. - A two-phase approach that combines Workflow Generation from
Intention with graph-based Workflow Optimization. - Opus Alpha 1 Large and Opus
Alpha 1 Small, models that outperform state-of-the-art LLMs by 38\% and 29\%
respectively in Workflow Generation for a Medical Coding use case.

摘要：<paragraph>這篇論文介紹了 Opus，一個用於產生和最佳化工作流程的新穎架構，專為複雜的業務流程外包 (BPO) 使用案例而設計，專注於在遵守既定的產業流程和營運限制的情況下，降低成本並提升品質。我們的做法是根據意圖產生可執行的工作流程，定義為客戶輸入、客戶輸出和流程背景的一致性。這些工作流程表示為有向無環圖 (DAG)，其中節點為任務，包含可執行指令的順序，包括工具和人類專家審查。我們採用兩階段方法：工作流程產生和工作流程最佳化。在產生階段，工作流程使用大型工作模型 (LWM) 產生，該模型由編碼特定領域程序和運作知識的工作知識圖 (WKG) 提供資訊。在最佳化階段，工作流程轉換為工作流程圖 (WFG)，其中最佳工作流程透過路徑最佳化來確定。我們的實驗證明，最先進的大語言模型 (LLM) 在可靠地擷取詳細的流程資料以及產生符合產業規範的工作流程方面面臨挑戰。本文的主要貢獻包括：- 將工作知識圖 (WKG) 整合到大型工作模型 (LWM) 中，讓產生有脈絡感知、語意對齊、結構化且可稽核的工作流程成為可能。- 一種結合意圖工作流程產生與基於圖形的工作流程最佳化的兩階段方法。- Opus Alpha 1 大型和 Opus Alpha 1 小型，在醫療編碼使用案例中，其工作流程產生表現分別優於最先進的 LLM 38% 和 29%。</paragraph>

##### **Node Importance Estimation Leveraging LLMs for Semantic Augmentation in Knowledge Graphs**
2412.00478v1 by Xinyu Lin, Tianyu Zhang, Chengbin Hou, Jinbao Wang, Jianye Xue, Hairong Lv

Node Importance Estimation (NIE) is a task that quantifies the importance of
node in a graph. Recent research has investigated to exploit various
information from Knowledge Graphs (KGs) to estimate node importance scores.
However, the semantic information in KGs could be insufficient, missing, and
inaccurate, which would limit the performance of existing NIE models. To
address these issues, we leverage Large Language Models (LLMs) for semantic
augmentation thanks to the LLMs' extra knowledge and ability of integrating
knowledge from both LLMs and KGs. To this end, we propose the LLMs Empowered
Node Importance Estimation (LENIE) method to enhance the semantic information
in KGs for better supporting NIE tasks. To our best knowledge, this is the
first work incorporating LLMs into NIE. Specifically, LENIE employs a novel
clustering-based triplet sampling strategy to extract diverse knowledge of a
node sampled from the given KG. After that, LENIE adopts the node-specific
adaptive prompts to integrate the sampled triplets and the original node
descriptions, which are then fed into LLMs for generating richer and more
precise augmented node descriptions. These augmented descriptions finally
initialize node embeddings for boosting the downstream NIE model performance.
Extensive experiments demonstrate LENIE's effectiveness in addressing semantic
deficiencies in KGs, enabling more informative semantic augmentation and
enhancing existing NIE models to achieve the state-of-the-art performance. The
source code of LENIE is freely available at
\url{https://github.com/XinyuLin-FZ/LENIE}.

摘要：節點重要性估計 (NIE) 是一項量化圖中節點重要性的任務。最近的研究已調查利用知識圖譜 (KG) 中的各種資訊來估計節點重要性分數。然而，KG 中的語義資訊可能不足、遺失且不準確，這將限制現有 NIE 模型的效能。為了解決這些問題，我們利用大型語言模型 (LLM) 進行語義增強，這要歸功於 LLM 的額外知識和整合 LLM 和 KG 中知識的能力。為此，我們提出 LLM 強化節點重要性估計 (LENIE) 方法，以增強 KG 中的語義資訊，以便更好地支援 NIE 任務。據我們所知，這是將 LLM 納入 NIE 的第一項工作。具體來說，LENIE 採用新穎的基於群集的三元組取樣策略，以萃取從給定 KG 取樣的節點的多元知識。在那之後，LENIE 採用特定於節點的自適應提示，以整合取樣的三元組和原始節點描述，然後將它們輸入 LLM 以產生更豐富且更精確的增強節點描述。這些增強的描述最終初始化節點嵌入，以提升下游 NIE 模型效能。廣泛的實驗證明了 LENIE 在解決 KG 中的語義缺陷方面的有效性，實現更多資訊性的語義增強，並增強現有的 NIE 模型以達成最先進的效能。LENIE 的原始程式碼可於\url{https://github.com/XinyuLin-FZ/LENIE} 免費取得。

##### **An AI-Driven Data Mesh Architecture Enhancing Decision-Making in Infrastructure Construction and Public Procurement**
2412.00224v1 by Saurabh Mishra, Mahendra Shinde, Aniket Yadav, Bilal Ayyub, Anand Rao

Infrastructure construction, often dubbed an "industry of industries," is
closely linked with government spending and public procurement, offering
significant opportunities for improved efficiency and productivity through
better transparency and information access. By leveraging these opportunities,
we can achieve notable gains in productivity, cost savings, and broader
economic benefits. Our approach introduces an integrated software ecosystem
utilizing Data Mesh and Service Mesh architectures. This system includes the
largest training dataset for infrastructure and procurement, encompassing over
100 billion tokens, scientific publications, activities, and risk data, all
structured by a systematic AI framework. Supported by a Knowledge Graph linked
to domain-specific multi-agent tasks and Q&A capabilities, our platform
standardizes and ingests diverse data sources, transforming them into
structured knowledge. Leveraging large language models (LLMs) and automation,
our system revolutionizes data structuring and knowledge creation, aiding
decision-making in early-stage project planning, detailed research, market
trend analysis, and qualitative assessments. Its web-scalable architecture
delivers domain-curated information, enabling AI agents to facilitate reasoning
and manage uncertainties, while preparing for future expansions with
specialized agents targeting particular challenges. This integration of AI with
domain expertise not only boosts efficiency and decision-making in construction
and infrastructure but also establishes a framework for enhancing government
efficiency and accelerating the transition of traditional industries to digital
workflows. This work is poised to significantly influence AI-driven initiatives
in this sector and guide best practices in AI Operations.

摘要：基礎建設建設，常被稱為「產業中的產業」，與政府支出和公共採購息息相關，透過提升透明度和資訊取得，能大幅提升效率和生產力。透過善用這些機會，我們能在生產力、成本節省和更廣泛的經濟效益上獲得顯著的收益。我們的做法引進一個整合式軟體生態系，利用資料網格和服務網格架構。這個系統包含基礎建設和採購最大的訓練資料集，涵蓋超過 1000 億個符號、科學出版品、活動和風險資料，所有資料都以系統化的 AI 架構進行結構化。我們的平台由連結到特定領域的多重代理人任務和問答功能的知識圖譜提供支援，標準化並匯入不同的資料來源，將其轉換為結構化的知識。我們的系統利用大語言模型 (LLM) 和自動化，徹底改革資料結構化和知識建立，協助在早期階段的專案規劃、詳細研究、市場趨勢分析和定性評估中進行決策制定。其可擴充至網路規模的架構提供領域策展的資訊，讓 AI 代理人能夠促進推理和管理不確定性，同時準備好以專門代理人因應特定挑戰，進行未來的擴充。這種將 AI 與領域專業知識整合的方式，不僅提升建設和基礎建設的效率和決策制定，也建立了一個架構，以提升政府效率並加速傳統產業轉型至數位工作流程。這項工作準備對這個部門的 AI 驅動計畫產生重大影響，並引導 AI 作業的最佳實務。

##### **PerLA: Perceptive 3D Language Assistant**
2411.19774v1 by Guofeng Mei, Wei Lin, Luigi Riz, Yujiao Wu, Fabio Poiesi, Yiming Wang

Enabling Large Language Models (LLMs) to understand the 3D physical world is
an emerging yet challenging research direction. Current strategies for
processing point clouds typically downsample the scene or divide it into
smaller parts for separate analysis. However, both approaches risk losing key
local details or global contextual information. In this paper, we introduce
PerLA, a 3D language assistant designed to be more perceptive to both details
and context, making visual representations more informative for the LLM. PerLA
captures high-resolution (local) details in parallel from different point cloud
areas and integrates them with (global) context obtained from a
lower-resolution whole point cloud. We present a novel algorithm that preserves
point cloud locality through the Hilbert curve and effectively aggregates
local-to-global information via cross-attention and a graph neural network.
Lastly, we introduce a novel loss for local representation consensus to promote
training stability. PerLA outperforms state-of-the-art 3D language assistants,
with gains of up to +1.34 CiDEr on ScanQA for question answering, and +4.22 on
ScanRefer and +3.88 on Nr3D for dense
captioning.\url{https://gfmei.github.io/PerLA/}

摘要：讓大型語言模型 (LLM) 理解 3D 物理世界是一個新興但具有挑戰性的研究方向。當前處理點雲的策略通常會對場景進行降採樣或將其分為更小的部分以進行單獨分析。然而，這兩種方法都有可能遺失關鍵的局部細節或全局背景資訊。在本文中，我們介紹了 PerLA，這是一個 3D 語言助理，旨在更敏銳地感知細節和背景，讓視覺表現對 LLM 更有資訊性。PerLA 從不同的點雲區域並行擷取高解析度（局部）細節，並將其與從低解析度全點雲中獲得的（全局）背景整合在一起。我們提出了一種新演算法，透過希爾伯特曲線保留點雲局部性，並透過交叉注意力和圖形神經網路有效地匯總局部到全局資訊。最後，我們引入了一個新的損失函數，用於局部表示共識，以促進訓練穩定性。PerLA 優於最先進的 3D 語言助理，在 ScanQA 上問答獲得高達 +1.34 CiDEr 的增益，在 ScanRefer 上獲得 +4.22，在 Nr3D 上獲得 +3.88 的密集標題。\url{https://gfmei.github.io/PerLA/}

##### **Knowledge Management for Automobile Failure Analysis Using Graph RAG**
2411.19539v1 by Yuta Ojima, Hiroki Sakaji, Tadashi Nakamura, Hiroaki Sakata, Kazuya Seki, Yuu Teshigawara, Masami Yamashita, Kazuhiro Aoyama

This paper presents a knowledge management system for automobile failure
analysis using retrieval-augmented generation (RAG) with large language models
(LLMs) and knowledge graphs (KGs). In the automotive industry, there is a
growing demand for knowledge transfer of failure analysis from experienced
engineers to young engineers. However, failure events are phenomena that occur
in a chain reaction, making them difficult for beginners to analyze them. While
knowledge graphs, which can describe semantic relationships and structure
information is effective in representing failure events, due to their
capability of representing the relationships between components, there is much
information in KGs, so it is challenging for young engineers to extract and
understand sub-graphs from the KG. On the other hand, there is increasing
interest in the use of Graph RAG, a type of RAG that combines LLMs and KGs for
knowledge management. However, when using the current Graph RAG framework with
an existing knowledge graph for automobile failures, several issues arise
because it is difficult to generate executable queries for a knowledge graph
database which is not constructed by LLMs. To address this, we focused on
optimizing the Graph RAG pipeline for existing knowledge graphs. Using an
original Q&A dataset, the ROUGE F1 score of the sentences generated by the
proposed method showed an average improvement of 157.6% compared to the current
method. This highlights the effectiveness of the proposed method for automobile
failure analysis.

摘要：本文提出了一個使用檢索增強生成（RAG）和大型語言模型（LLM）和知識圖譜（KG）的汽車故障分析知識管理系統。在汽車產業中，有越來越多的需求，將故障分析知識從經驗豐富的工程師傳授給年輕的工程師。然而，故障事件是一種連鎖反應中發生的現象，這使得初學者難以分析它們。儘管知識圖譜可以描述語義關係和結構化資訊，並有效地表示故障事件，由於它們有表示元件之間關係的能力，KG 中有許多資訊，因此年輕的工程師很難從 KG 中提取和理解子圖。另一方面，人們越來越有興趣使用 Graph RAG，這是一種結合 LLM 和 KG 進行知識管理的 RAG。然而，當將目前的 Graph RAG 框架與現有的汽車故障知識圖譜一起使用時，會出現幾個問題，因為難以生成針對非 LLM 構建的知識圖譜資料庫的可執行查詢。為了解決這個問題，我們專注於針對現有知識圖譜最佳化 Graph RAG 管道。使用原始問答資料集，所提出方法生成的句子的 ROUGE F1 分數與目前方法相比，平均提升了 157.6%。這突顯了所提出方法對於汽車故障分析的有效性。

##### **Way to Specialist: Closing Loop Between Specialized LLM and Evolving Domain Knowledge Graph**
2411.19064v1 by Yutong Zhang, Lixing Chen, Shenghong Li, Nan Cao, Yang Shi, Jiaxin Ding, Zhe Qu, Pan Zhou, Yang Bai

Large language models (LLMs) have demonstrated exceptional performance across
a wide variety of domains. Nonetheless, generalist LLMs continue to fall short
in reasoning tasks necessitating specialized knowledge. Prior investigations
into specialized LLMs focused on domain-specific training, which entails
substantial efforts in domain data acquisition and model parameter fine-tuning.
To address these challenges, this paper proposes the Way-to-Specialist (WTS)
framework, which synergizes retrieval-augmented generation with knowledge
graphs (KGs) to enhance the specialized capability of LLMs in the absence of
specialized training. In distinction to existing paradigms that merely utilize
external knowledge from general KGs or static domain KGs to prompt LLM for
enhanced domain-specific reasoning, WTS proposes an innovative
"LLM$\circlearrowright$KG" paradigm, which achieves bidirectional enhancement
between specialized LLM and domain knowledge graph (DKG). The proposed paradigm
encompasses two closely coupled components: the DKG-Augmented LLM and the
LLM-Assisted DKG Evolution. The former retrieves question-relevant domain
knowledge from DKG and uses it to prompt LLM to enhance the reasoning
capability for domain-specific tasks; the latter leverages LLM to generate new
domain knowledge from processed tasks and use it to evolve DKG. WTS closes the
loop between DKG-Augmented LLM and LLM-Assisted DKG Evolution, enabling
continuous improvement in the domain specialization as it progressively answers
and learns from domain-specific questions. We validate the performance of WTS
on 6 datasets spanning 5 domains. The experimental results show that WTS
surpasses the previous SOTA in 4 specialized domains and achieves a maximum
performance improvement of 11.3%.

摘要：大型語言模型 (LLM) 已在各個領域展現出優異的表現。然而，通才 LLM 在需要專業知識的推理任務中仍表現不佳。先前對專業 LLM 的研究集中在特定領域訓練，這需要大量領域資料取得和模型參數微調。為了應對這些挑戰，本文提出 Way-to-Specialist (WTS) 架構，它將檢索增強生成與知識圖譜 (KG) 結合起來，以提升 LLM 在沒有專業訓練情況下的專業能力。與僅利用來自一般 KG 或靜態領域 KG 的外部知識提示 LLM 以增強特定領域推理的既有範例不同，WTS 提出一個創新的「LLM$\circlearrowright$KG」範例，它在專業 LLM 和領域知識圖譜 (DKG) 之間實現雙向增強。所提出的範例包含兩個緊密結合的組成部分：DKG 增強 LLM 和 LLM 輔助 DKG 演化。前者從 DKG 中檢索與問題相關的領域知識，並使用它提示 LLM 以增強特定領域任務的推理能力；後者利用 LLM 從處理過的任務中產生新的領域知識，並使用它來演化 DKG。WTS 閉合了 DKG 增強 LLM 和 LLM 輔助 DKG 演化之間的迴路，隨著它逐漸回答和學習特定領域問題，能夠持續改善領域專業化。我們在橫跨 5 個領域的 6 個資料集上驗證 WTS 的效能。實驗結果顯示，WTS 在 4 個專業領域中超越先前的 SOTA，並達到 11.3% 的最大效能提升。

##### **EzSQL: An SQL intermediate representation for improving SQL-to-text Generation**
2411.18923v1 by Meher Bhardwaj, Hrishikesh Ethari, Dennis Singh Moirangthem

The SQL-to-text generation task traditionally uses template base, Seq2Seq,
tree-to-sequence, and graph-to-sequence models. Recent models take advantage of
pre-trained generative language models for this task in the Seq2Seq framework.
However, treating SQL as a sequence of inputs to the pre-trained models is not
optimal. In this work, we put forward a new SQL intermediate representation
called EzSQL to align SQL with the natural language text sequence. EzSQL
simplifies the SQL queries and brings them closer to natural language text by
modifying operators and keywords, which can usually be described in natural
language. EzSQL also removes the need for set operators. Our proposed
SQL-to-text generation model uses EzSQL as the input to a pre-trained
generative language model for generating the text descriptions. We demonstrate
that our model is an effective state-of-the-art method to generate text
narrations from SQL queries on the WikiSQL and Spider datasets. We also show
that by generating pretraining data using our SQL-to-text generation model, we
can enhance the performance of Text-to-SQL parsers.

摘要：SQL 轉文字生成任務傳統上使用範本基礎、Seq2Seq、樹到序列和圖到序列模型。最近的模型利用預訓練生成式語言模型來執行 Seq2Seq 架構中的此項任務。然而，將 SQL 視為預訓練模型輸入序列並非最佳解。在此項工作中，我們提出一個名為 EzSQL 的新式 SQL 中間表示，以將 SQL 與自然語言文字序列對齊。EzSQL 簡化 SQL 查詢，並透過修改運算子與關鍵字（通常可以用自然語言描述），讓它們更接近自然語言文字。EzSQL 也消除了對集合運算子的需求。我們提出的 SQL 轉文字生成模型使用 EzSQL 作為輸入，輸入預訓練生成式語言模型以產生文字描述。我們示範我們的模型是一種有效的最新方法，可以用於從 WikiSQL 與 Spider 資料集中的 SQL 查詢產生文字敘述。我們也展示透過使用我們的 SQL 轉文字生成模型產生預訓練資料，我們可以提升文字轉 SQL 解析器的效能。

##### **MLLM-Search: A Zero-Shot Approach to Finding People using Multimodal Large Language Models**
2412.00103v1 by Angus Fung, Aaron Hao Tan, Haitong Wang, Beno Benhabib, Goldie Nejat

Robotic search of people in human-centered environments, including healthcare
settings, is challenging as autonomous robots need to locate people without
complete or any prior knowledge of their schedules, plans or locations.
Furthermore, robots need to be able to adapt to real-time events that can
influence a person's plan in an environment. In this paper, we present
MLLM-Search, a novel zero-shot person search architecture that leverages
multimodal large language models (MLLM) to address the mobile robot problem of
searching for a person under event-driven scenarios with varying user
schedules. Our approach introduces a novel visual prompting method to provide
robots with spatial understanding of the environment by generating a spatially
grounded waypoint map, representing navigable waypoints by a topological graph
and regions by semantic labels. This is incorporated into a MLLM with a region
planner that selects the next search region based on the semantic relevance to
the search scenario, and a waypoint planner which generates a search path by
considering the semantically relevant objects and the local spatial context
through our unique spatial chain-of-thought prompting approach. Extensive 3D
photorealistic experiments were conducted to validate the performance of
MLLM-Search in searching for a person with a changing schedule in different
environments. An ablation study was also conducted to validate the main design
choices of MLLM-Search. Furthermore, a comparison study with state-of-the art
search methods demonstrated that MLLM-Search outperforms existing methods with
respect to search efficiency. Real-world experiments with a mobile robot in a
multi-room floor of a building showed that MLLM-Search was able to generalize
to finding a person in a new unseen environment.

摘要：機器人在以人為中心的環境中搜尋人，包括醫療保健環境，這是一個挑戰，因為自主機器人需要在完全或沒有事先知道他們的時間表、計畫或位置的情況下找到人。此外，機器人需要能夠適應可能影響環境中某人計畫的即時事件。在本文中，我們提出 MLLM-Search，一種新穎的零次人搜尋架構，它利用多模態大型語言模型 (MLLM) 來解決在事件驅動場景中搜尋具有不同使用者時間表的某人的行動機器人問題。我們的做法引入了一種新穎的視覺提示方法，通過生成一個空間接地的航點圖，以拓撲圖表示可導航航點，並通過語義標籤表示區域，為機器人提供環境的空間理解。這被整合到一個具有區域規劃器的 MLLM 中，該區域規劃器根據與搜尋場景的語義相關性選擇下一個搜尋區域，以及一個航點規劃器，該規劃器通過考慮語義相關物件和局部空間背景通過我們獨特的空間思維提示方法生成搜尋路徑。進行了廣泛的 3D 真實感實驗，以驗證 MLLM-Search 在不同環境中搜尋具有變更時間表的人的效能。還進行了一項消融研究，以驗證 MLLM-Search 的主要設計選擇。此外，與最先進的搜尋方法的比較研究表明，MLLM-Search 在搜尋效率方面優於現有方法。在建築物多房間樓層中使用行動機器人進行的真實世界實驗表明，MLLM-Search 能夠概括到在一個新的未見環境中找到某人。

##### **Regularized Multi-LLMs Collaboration for Enhanced Score-based Causal Discovery**
2411.17989v1 by Xiaoxuan Li, Yao Liu, Ruoyu Wang, Lina Yao

As the significance of understanding the cause-and-effect relationships among
variables increases in the development of modern systems and algorithms,
learning causality from observational data has become a preferred and efficient
approach over conducting randomized control trials. However, purely
observational data could be insufficient to reconstruct the true causal graph.
Consequently, many researchers tried to utilise some form of prior knowledge to
improve causal discovery process. In this context, the impressive capabilities
of large language models (LLMs) have emerged as a promising alternative to the
costly acquisition of prior expert knowledge. In this work, we further explore
the potential of using LLMs to enhance causal discovery approaches,
particularly focusing on score-based methods, and we propose a general
framework to utilise the capacity of not only one but multiple LLMs to augment
the discovery process.

摘要：隨著理解現代系統和演算法中變數之間的因果關係的重要性日益增加，從觀測資料中學習因果關係已成為一種比進行隨機對照試驗更受青睞且更有效率的方法。然而，純粹的觀測資料可能不足以重建真正的因果圖。因此，許多研究人員嘗試利用某種形式的先驗知識來改善因果發現過程。在此背景下，大型語言模型 (LLM) 的強大功能已成為昂貴的先驗專家知識獲取的替代方案。在這項工作中，我們進一步探討了使用 LLM 來增強因果發現方法的可能性，特別關注基於評分的模型，並且我們提出了一個通用框架，不僅可以利用一個 LLM，還可以利用多個 LLM 來擴充發現過程。

##### **ShowUI: One Vision-Language-Action Model for GUI Visual Agent**
2411.17465v1 by Kevin Qinghong Lin, Linjie Li, Difei Gao, Zhengyuan Yang, Shiwei Wu, Zechen Bai, Weixian Lei, Lijuan Wang, Mike Zheng Shou

Building Graphical User Interface (GUI) assistants holds significant promise
for enhancing human workflow productivity. While most agents are
language-based, relying on closed-source API with text-rich meta-information
(e.g., HTML or accessibility tree), they show limitations in perceiving UI
visuals as humans do, highlighting the need for GUI visual agents. In this
work, we develop a vision-language-action model in digital world, namely
ShowUI, which features the following innovations: (i) UI-Guided Visual Token
Selection to reduce computational costs by formulating screenshots as an UI
connected graph, adaptively identifying their redundant relationship and serve
as the criteria for token selection during self-attention blocks; (ii)
Interleaved Vision-Language-Action Streaming that flexibly unifies diverse
needs within GUI tasks, enabling effective management of visual-action history
in navigation or pairing multi-turn query-action sequences per screenshot to
enhance training efficiency; (iii) Small-scale High-quality GUI
Instruction-following Datasets by careful data curation and employing a
resampling strategy to address significant data type imbalances. With above
components, ShowUI, a lightweight 2B model using 256K data, achieves a strong
75.1% accuracy in zero-shot screenshot grounding. Its UI-guided token selection
further reduces 33% of redundant visual tokens during training and speeds up
the performance by 1.4x. Navigation experiments across web Mind2Web, mobile
AITW, and online MiniWob environments further underscore the effectiveness and
potential of our model in advancing GUI visual agents. The models are available
at https://github.com/showlab/ShowUI.

摘要：<paragraph>建構圖形使用者介面 (GUI) 助理極有望提升人類工作流程的生產力。雖然大多數代理都是基於語言，仰賴具有豐富文字元資訊封閉原始碼 API（例如 HTML 或無障礙樹），但它們在感知使用者介面視覺效果方面顯示出限制，這凸顯了對 GUI 視覺代理的需求。在這項工作中，我們在數位世界中開發了一個視覺語言動作模型，即 ShowUI，其具有以下創新功能：(i) UI 引導視覺代幣選擇，透過將螢幕截圖表述為 UI 連接圖，自適應地識別其冗餘關係，並作為自注意力區塊中代幣選擇的準則，以降低運算成本；(ii) 交錯視覺語言動作串流，靈活地統一 GUI 任務中的各種需求，在導覽中有效管理視覺動作歷程，或配對每個螢幕截圖的多輪查詢動作序列，以提升訓練效率；(iii) 小規模高品質 GUI 指令遵循資料集，透過仔細的資料整理和採用再抽樣策略，來解決顯著的資料類型不平衡。ShowUI 是一個使用 256K 資料的輕量級 2B 模型，具備上述組成部分，在零次方螢幕截圖接地中達到強勁的 75.1% 精確度。其 UI 引導代幣選擇進一步減少了訓練期間 33% 的冗餘視覺代幣，並將效能提升了 1.4 倍。跨網路 Mind2Web、行動 AITW 和線上 MiniWob 環境的導覽實驗進一步強調了我們的模型在推進 GUI 視覺代理方面的有效性和潛力。這些模型可在 https://github.com/showlab/ShowUI 取得。</paragraph>

##### **Can LLMs be Good Graph Judger for Knowledge Graph Construction?**
2411.17388v1 by Haoyu Huang, Chong Chen, Conghui He, Yang Li, Jiawei Jiang, Wentao Zhang

In real-world scenarios, most of the data obtained from information retrieval
(IR) system is unstructured. Converting natural language sentences into
structured Knowledge Graphs (KGs) remains a critical challenge. The quality of
constructed KGs may also impact the performance of some KG-dependent domains
like GraphRAG systems and recommendation systems. Recently, Large Language
Models (LLMs) have demonstrated impressive capabilities in addressing a wide
range of natural language processing tasks. However, there are still challenges
when utilizing LLMs to address the task of generating structured KGs. And we
have identified three limitations with respect to existing KG construction
methods. (1)There is a large amount of information and excessive noise in
real-world documents, which could result in extracting messy information.
(2)Native LLMs struggle to effectively extract accuracy knowledge from some
domain-specific documents. (3)Hallucinations phenomenon cannot be overlooked
when utilizing LLMs directly as an unsupervised method for constructing KGs.
  In this paper, we propose GraphJudger, a knowledge graph construction
framework to address the aforementioned challenges. We introduce three
innovative modules in our method, which are entity-centric iterative text
denoising, knowledge aware instruction tuning and graph judgement,
respectively. We seek to utilize the capacity of LLMs to function as a graph
judger, a capability superior to their role only as a predictor for KG
construction problems. Experiments conducted on two general text-graph pair
datasets and one domain-specific text-graph pair dataset show superior
performances compared to baseline methods. The code of our proposed method is
available at https://github.com/hhy-huang/GraphJudger.

摘要：<paragraph>在現實世界的場景中，從資訊檢索 (IR) 系統取得的大部分資料都是非結構化的。將自然語言句子轉換為結構化的知識圖譜 (KG) 仍然是一項重大的挑戰。已建構的 KG 品質也可能影響某些依賴 KG 的領域，例如 GraphRAG 系統和推薦系統的效能。最近，大型語言模型 (LLM) 已展現出令人印象深刻的能力，能處理廣泛的自然語言處理任務。然而，當利用 LLM 來處理產生結構化 KG 的任務時，仍然存在挑戰。我們已針對現有的 KG 建構方法找出三個限制。(1) 在現實世界的文件中有大量的資訊和過多的雜訊，這可能會導致萃取雜亂的資訊。(2) 原生 LLM 難以從某些特定領域的文件中有效萃取精確的知識。(3) 在將 LLM 直接用作建構 KG 的非監督式方法時，無法忽略幻覺現象。在本文中，我們提出 GraphJudger，這是一個知識圖譜建構架構，用於解決上述挑戰。我們在方法中引入了三個創新的模組，分別是實體為中心的反覆文字去雜訊、知識感知指令微調和圖形判斷。我們尋求利用 LLM 的能力，使其發揮圖形判斷者的功能，這項能力優於其僅作為 KG 建構問題預測者的角色。在兩個一般文字圖形配對資料集和一個特定領域文字圖形配對資料集上進行的實驗顯示，與基線方法相比，其效能優異。我們提出的方法的程式碼可於 https://github.com/hhy-huang/GraphJudger 取得。</paragraph>

##### **Interleaved Scene Graph for Interleaved Text-and-Image Generation Assessment**
2411.17188v1 by Dongping Chen, Ruoxi Chen, Shu Pu, Zhaoyi Liu, Yanru Wu, Caixi Chen, Benlin Liu, Yue Huang, Yao Wan, Pan Zhou, Ranjay Krishna

Many real-world user queries (e.g. "How do to make egg fried rice?") could
benefit from systems capable of generating responses with both textual steps
with accompanying images, similar to a cookbook. Models designed to generate
interleaved text and images face challenges in ensuring consistency within and
across these modalities. To address these challenges, we present ISG, a
comprehensive evaluation framework for interleaved text-and-image generation.
ISG leverages a scene graph structure to capture relationships between text and
image blocks, evaluating responses on four levels of granularity: holistic,
structural, block-level, and image-specific. This multi-tiered evaluation
allows for a nuanced assessment of consistency, coherence, and accuracy, and
provides interpretable question-answer feedback. In conjunction with ISG, we
introduce a benchmark, ISG-Bench, encompassing 1,150 samples across 8
categories and 21 subcategories. This benchmark dataset includes complex
language-vision dependencies and golden answers to evaluate models effectively
on vision-centric tasks such as style transfer, a challenging area for current
models. Using ISG-Bench, we demonstrate that recent unified vision-language
models perform poorly on generating interleaved content. While compositional
approaches that combine separate language and image models show a 111%
improvement over unified models at the holistic level, their performance
remains suboptimal at both block and image levels. To facilitate future work,
we develop ISG-Agent, a baseline agent employing a "plan-execute-refine"
pipeline to invoke tools, achieving a 122% performance improvement.

摘要：許多真實世界的使用者查詢（例如「如何製作蛋炒飯？」）可以受益於能夠產生包含文字步驟和附帶圖片的回應的系統，類似於食譜。專門用於產生交錯文本和圖片的模型面臨確保這些方式內部和之間的一致性的挑戰。為了應對這些挑戰，我們提出了 ISG，一個用於交錯文本和圖片產生的綜合評估架構。ISG 利用場景圖結構來捕捉文本和圖片區塊之間的關係，在四個層級的粒度上評估回應：整體、結構、區塊層級和圖片特定。這種多層評估允許對一致性、連貫性和準確性進行細緻的評估，並提供可解釋的問題解答回饋。結合 ISG，我們引入了基準 ISG-Bench，涵蓋 8 個類別和 21 個子類別中的 1,150 個範例。這個基準資料集包含複雜的語言視覺依賴關係和黃金答案，以有效評估模型在以視覺為中心的任務（例如風格轉移）上的表現，這是當前模型面臨的挑戰領域。使用 ISG-Bench，我們證明了最近的統一視覺語言模型在產生交錯內容上的表現不佳。雖然結合單獨語言和圖片模型的組合方法在整體層級上比統一模型提升了 111%，但它們在區塊和圖片層級上的表現仍然不佳。為了促進後續工作，我們開發了 ISG-Agent，一個採用「計畫執行修正」管線的基準代理，用於呼叫工具，實現了 122% 的效能提升。

##### **AtomR: Atomic Operator-Empowered Large Language Models for Heterogeneous Knowledge Reasoning**
2411.16495v2 by Amy Xin, Jinxin Liu, Zijun Yao, Zhicheng Lee, Shulin Cao, Lei Hou, Juanzi Li

Recent advancements in large language models (LLMs) have led to significant
improvements in various natural language processing tasks, but it is still
challenging for LLMs to perform knowledge-intensive complex question answering
due to LLMs' inefficacy in reasoning planning and the hallucination problem. A
typical solution is to employ retrieval-augmented generation (RAG) coupled with
chain-of-thought (CoT) reasoning, which decomposes complex questions into
chain-like sub-questions and applies iterative RAG at each sub-question.
However, prior works exhibit sub-optimal reasoning planning and overlook
dynamic knowledge retrieval from heterogeneous sources. In this paper, we
propose AtomR, a novel heterogeneous knowledge reasoning framework that
conducts multi-source reasoning at the atomic level. Drawing inspiration from
the graph modeling of knowledge, AtomR leverages large language models (LLMs)
to decompose complex questions into combinations of three atomic knowledge
operators, significantly enhancing the reasoning process at both the planning
and execution stages. We also introduce BlendQA, a novel evaluation benchmark
tailored to assess complex heterogeneous knowledge reasoning. Experiments show
that AtomR significantly outperforms state-of-the-art baselines across three
single-source and two multi-source reasoning benchmarks, with notable
performance gains of 9.4% on 2WikiMultihop and 9.5% on BlendQA.

摘要：大型語言模型 (LLM) 的最新進展已大幅提升各種自然語言處理任務的表現，但 LLM 仍難以執行知識密集型複雜問題解答，原因在於 LLM 在推理規劃和幻覺問題方面效率不彰。典型的解決方案是採用檢索增強生成 (RAG) 搭配思維鏈 (CoT) 推理，將複雜問題分解成鏈狀子問題，並在每個子問題套用反覆 RAG。然而，先前的研究展現出次佳推理規劃，並忽略從異質來源進行動態知識檢索。在本文中，我們提出 AtomR，一個新穎的異質知識推理架構，在原子層級進行多來源推理。AtomR 從知識的圖形建模中汲取靈感，利用大型語言模型 (LLM) 將複雜問題分解成三種原子知識運算子的組合，大幅提升規劃和執行階段的推理程序。我們也引進 BlendQA，一個新穎的評量基準，專門用於評估複雜異質知識推理。實驗顯示，AtomR 在三個單一來源和兩個多來源推理基準中，表現顯著優於現有技術基線，在 2WikiMultihop 上獲得 9.4% 的顯著效能提升，在 BlendQA 上獲得 9.5% 的提升。

##### **Learning by Analogy: Enhancing Few-Shot Prompting for Math Word Problem Solving with Computational Graph-Based Retrieval**
2411.16454v1 by Xiaocong Yang, Jiacheng Lin, Ziqi Wang, Chengxiang Zhai

Large language models (LLMs) are known to struggle with complicated reasoning
tasks such as math word problems (MWPs). In this paper, we present how analogy
from similarly structured questions can improve LLMs' problem-solving
capabilities for MWPs. Specifically, we rely on the retrieval of problems with
similar computational graphs to the given question to serve as exemplars in the
prompt, providing the correct reasoning path for the generation model to refer
to. Empirical results across six math word problem datasets demonstrate the
effectiveness of our proposed method, which achieves a significant improvement
of up to 6.7 percent on average in absolute value, compared to baseline
methods. These results highlight our method's potential in addressing the
reasoning challenges in current LLMs.

摘要：大型語言模型 (LLM) 已知在複雜推理任務（例如數學文字題 (MWP)）中會遇到困難。在本文中，我們展示了來自結構相似的問題的類比如何能改善 LLM 對 MWP 的問題解決能力。具體來說，我們依賴於擷取與給定問題具有類似運算圖形的問題，作為提示中的範例，為生成模型提供正確的推理路徑以供參考。六個數學文字題數據集的實證結果證明了我們提出的方法的有效性，與基線方法相比，平均絕對值提高了 6.7 個百分點。這些結果突出了我們的方法在解決當前 LLM 中的推理挑戰方面的潛力。

##### **Adapter-based Approaches to Knowledge-enhanced Language Models -- A Survey**
2411.16403v1 by Alexander Fichtl, Juraj Vladika, Georg Groh

Knowledge-enhanced language models (KELMs) have emerged as promising tools to
bridge the gap between large-scale language models and domain-specific
knowledge. KELMs can achieve higher factual accuracy and mitigate
hallucinations by leveraging knowledge graphs (KGs). They are frequently
combined with adapter modules to reduce the computational load and risk of
catastrophic forgetting. In this paper, we conduct a systematic literature
review (SLR) on adapter-based approaches to KELMs. We provide a structured
overview of existing methodologies in the field through quantitative and
qualitative analysis and explore the strengths and potential shortcomings of
individual approaches. We show that general knowledge and domain-specific
approaches have been frequently explored along with various adapter
architectures and downstream tasks. We particularly focused on the popular
biomedical domain, where we provided an insightful performance comparison of
existing KELMs. We outline the main trends and propose promising future
directions.

摘要：知識增強語言模型（KELM）已成為彌合大規模語言模型與特定領域知識差距的有前途的工具。KELM 可以透過利用知識圖譜（KG）來提高事實準確性並減少幻覺。它們經常與適配器模組結合使用，以降低運算負載和災難性遺忘的風險。在本文中，我們對基於適配器的 KELM 方法進行系統性的文獻回顧（SLR）。我們透過定量和定性分析提供該領域既有方法論的結構化概觀，並探討個別方法的優點和潛在缺點。我們表明，一般知識和特定領域的方法已與各種適配器架構和下游任務一起被頻繁探索。我們特別關注熱門的生物醫學領域，在該領域中，我們提供了現有 KELM 的有見地效能比較。我們概述了主要趨勢，並提出了有前途的未來方向。

##### **Decoding Urban Industrial Complexity: Enhancing Knowledge-Driven Insights via IndustryScopeGPT**
2411.15758v1 by Siqi Wang, Chao Liang, Yunfan Gao, Yang Liu, Jing Li, Haofen Wang

Industrial parks are critical to urban economic growth. Yet, their
development often encounters challenges stemming from imbalances between
industrial requirements and urban services, underscoring the need for strategic
planning and operations. This paper introduces IndustryScopeKG, a pioneering
large-scale multi-modal, multi-level industrial park knowledge graph, which
integrates diverse urban data including street views, corporate,
socio-economic, and geospatial information, capturing the complex relationships
and semantics within industrial parks. Alongside this, we present the
IndustryScopeGPT framework, which leverages Large Language Models (LLMs) with
Monte Carlo Tree Search to enhance tool-augmented reasoning and decision-making
in Industrial Park Planning and Operation (IPPO). Our work significantly
improves site recommendation and functional planning, demonstrating the
potential of combining LLMs with structured datasets to advance industrial park
management. This approach sets a new benchmark for intelligent IPPO research
and lays a robust foundation for advancing urban industrial development. The
dataset and related code are available at
https://github.com/Tongji-KGLLM/IndustryScope.

摘要：工業園區對於都市經濟成長至關重要。然而，其發展經常會遇到工業需求與都市服務之間不平衡所產生的挑戰，這凸顯了策略性規劃與營運的需求。本文介紹了 IndustryScopeKG，一個先驅性的、大規模、多模式、多層級的工業園區知識圖譜，它整合了包含街景、公司、社會經濟和地理空間資訊在內的各種都市資料，捕捉工業園區內複雜的關係和語意。除此之外，我們提出了 IndustryScopeGPT 架構，它利用大型語言模型 (LLM) 與蒙地卡羅樹狀搜尋，以增強工具輔助推理和在工業園區規劃和營運 (IPPO) 中的決策制定。我們的研究大幅改善了場地推薦和功能規劃，展示了結合 LLM 和結構化資料集以推進工業園區管理的潛力。這個方法為智慧 IPPO 研究設定了新的基準，並為推進都市產業發展奠定了穩固的基礎。資料集和相關程式碼可在 https://github.com/Tongji-KGLLM/IndustryScope 取得。

##### **One to rule them all: natural language to bind communication, perception and action**
2411.15033v1 by Simone Colombani, Dimitri Ognibene, Giuseppe Boccignone

In recent years, research in the area of human-robot interaction has focused
on developing robots capable of understanding complex human instructions and
performing tasks in dynamic and diverse environments. These systems have a wide
range of applications, from personal assistance to industrial robotics,
emphasizing the importance of robots interacting flexibly, naturally and safely
with humans. This paper presents an advanced architecture for robotic action
planning that integrates communication, perception, and planning with Large
Language Models (LLMs). Our system is designed to translate commands expressed
in natural language into executable robot actions, incorporating environmental
information and dynamically updating plans based on real-time feedback. The
Planner Module is the core of the system where LLMs embedded in a modified
ReAct framework are employed to interpret and carry out user commands. By
leveraging their extensive pre-trained knowledge, LLMs can effectively process
user requests without the need to introduce new knowledge on the changing
environment. The modified ReAct framework further enhances the execution space
by providing real-time environmental perception and the outcomes of physical
actions. By combining robust and dynamic semantic map representations as graphs
with control components and failure explanations, this architecture enhances a
robot adaptability, task execution, and seamless collaboration with human users
in shared and dynamic environments. Through the integration of continuous
feedback loops with the environment the system can dynamically adjusts the plan
to accommodate unexpected changes, optimizing the robot ability to perform
tasks. Using a dataset of previous experience is possible to provide detailed
feedback about the failure. Updating the LLMs context of the next iteration
with suggestion on how to overcame the issue.

摘要：近年来，人机交互领域的研究重点
在于开发能够理解复杂人类指令并在动态和多样化环境中执行任务的机器人。这些系统具有广泛的应用，从个人助理到工业机器人，强调了机器人与人类灵活、自然和安全交互的重要性。本文提出了一种先进的机器人动作规划架构，该架构集成了通信、感知和规划与大型语言模型 (LLM)。我们的系统旨在将以自然语言表达的命令翻译成可执行的机器人动作，并结合环境信息并根据实时反馈动态更新计划。规划器模块是系统的核心，其中嵌入在修改后的 ReAct 框架中的 LLM 用于解释和执行用户命令。通过利用其广泛的预训练知识，LLM 可以有效处理用户请求，而无需引入有关不断变化的环境的新知识。修改后的 ReAct 框架通过提供实时环境感知和物理动作的结果进一步增强了执行空间。通过将鲁棒且动态语义地图表示与控制组件和故障解释相结合，该架构增强了机器人的适应性、任务执行以及与人类用户在共享和动态环境中的无缝协作。通过将连续反馈回路与环境相结合，系统可以动态调整计划以适应意外变化，从而优化机器人执行任务的能力。利用先前的经验数据集，可以提供有关故障的详细反馈。使用有关如何克服问题的建议更新下一个迭代的 LLM 上下文。

##### **Time is on my sight: scene graph filtering for dynamic environment perception in an LLM-driven robot**
2411.15027v1 by Simone Colombani, Luca Brini, Dimitri Ognibene, Giuseppe Boccignone

Robots are increasingly being used in dynamic environments like workplaces,
hospitals, and homes. As a result, interactions with robots must be simple and
intuitive, with robots perception adapting efficiently to human-induced
changes. This paper presents a robot control architecture that addresses key
challenges in human-robot interaction, with a particular focus on the dynamic
creation and continuous update of the robot state representation. The
architecture uses Large Language Models to integrate diverse information
sources, including natural language commands, robotic skills representation,
real-time dynamic semantic mapping of the perceived scene. This enables
flexible and adaptive robotic behavior in complex, dynamic environments.
Traditional robotic systems often rely on static, pre-programmed instructions
and settings, limiting their adaptability to dynamic environments and real-time
collaboration. In contrast, this architecture uses LLMs to interpret complex,
high-level instructions and generate actionable plans that enhance human-robot
collaboration. At its core, the system Perception Module generates and
continuously updates a semantic scene graph using RGB-D sensor data, providing
a detailed and structured representation of the environment. A particle filter
is employed to ensure accurate object localization in dynamic, real-world
settings. The Planner Module leverages this up-to-date semantic map to break
down high-level tasks into sub-tasks and link them to robotic skills such as
navigation, object manipulation (e.g., PICK and PLACE), and movement (e.g.,
GOTO). By combining real-time perception, state tracking, and LLM-driven
communication and task planning, the architecture enhances adaptability, task
efficiency, and human-robot collaboration in dynamic environments.

摘要：<paragraph>機器人正越來越廣泛地應用於工作場所、醫院和家庭等動態環境中。因此，與機器人的互動必須簡單直觀，機器人的感知能力必須有效適應人類引發的變化。本文提出了一種機器人控制架構，用於解決人機互動中的關鍵挑戰，特別關注機器人狀態表示的動態建立和持續更新。該架構使用大型語言模型整合多種資訊來源，包括自然語言命令、機器人技能表示、感知場景的即時動態語義對應。這使得機器人在複雜的動態環境中能夠靈活適應。傳統的機器人系統通常依賴於靜態的、預先編程的指令和設定，這限制了它們對動態環境和即時協作的適應能力。相比之下，此架構使用 LLM 來詮釋複雜的高層級指令，並制定可行的計畫，以增強人機協作。在系統的核心，感知模組使用 RGB-D 感測器資料產生並持續更新語義場景圖，提供環境的詳細且結構化的表示。採用粒子濾波器以確保在動態的真實世界設定中準確定位物件。規劃模組利用這個最新的語義地圖，將高層級任務分解為子任務，並將它們連結到機器人技能，例如導航、物件操作（例如，取放）和移動（例如，前往）。透過結合即時感知、狀態追蹤和 LLM 驅動的溝通和任務規劃，此架構增強了動態環境中的適應能力、任務效率和人機協作。</paragraph>

##### **GOT4Rec: Graph of Thoughts for Sequential Recommendation**
2411.14922v1 by Zewen Long, Liang Wang, Shu Wu, Qiang Liu, Liang Wang

With the advancement of large language models (LLMs), researchers have
explored various methods to optimally leverage their comprehension and
generation capabilities in sequential recommendation scenarios. However,
several challenges persist in this endeavor. Firstly, most existing approaches
rely on the input-output prompting paradigm, which can result in irrelevant or
inaccurate responses. Secondly, while there have been attempts to enhance LLMs
using prompting strategies such as chain-of-thought (CoT), these efforts have
not fully harnessed the reasoning abilities of LLMs or effectively captured the
multifaceted information contained within user sequences. To address these
limitations, we propose GOT4Rec, a sequential recommendation method that
utilizes the graph of thoughts (GoT) prompting strategy. Specifically, we
identify and utilize three key types of information within user history
sequences: short-term interests, long-term interests and collaborative
information from other users. Our approach enables LLMs to independently reason
and generate recommendations based on these distinct types of information,
subsequently aggregating the results within the GoT framework to derive the
final recommended items. This method allows LLMs, with enhanced reasoning
capabilities, to more effectively consider the diverse information within user
sequences, resulting in more accurate recommendations and more comprehensive
explanations. Extensive experiments on real-world datasets demonstrate the
effectiveness of GOT4Rec, indicating that it outperforms existing
state-of-the-art baselines. Our code is available at
https://anonymous.4open.science/r/GOT4Rec-ED99.

摘要：隨著大型語言模型 (LLM) 的進步，研究人員已探索各種方法，以最佳方式利用其理解和生成能力在順序推薦場景中。然而，在這個努力中仍存在一些挑戰。首先，大多數現有方法依賴於輸入輸出提示範例，這可能會導致不相關或不準確的回應。其次，雖然有人嘗試使用提示策略（例如思想鏈 (CoT)）來增強 LLM，但這些努力並未充分利用 LLM 的推理能力或有效擷取使用者序列中包含的多方面資訊。為了解決這些限制，我們提出 GOT4Rec，這是一種順序推薦方法，利用了思想圖 (GoT) 提示策略。具體來說，我們在使用者歷史序列中識別並利用三種類型的關鍵資訊：短期興趣、長期興趣和來自其他使用者的協作資訊。我們的方法使 LLM 能夠根據這些不同類型的資訊獨立推理並產生建議，然後在 GoT 框架內匯總結果以推導出最終推薦的項目。這種方法允許 LLM 在增強推理能力的同時，更有效地考慮使用者序列中的不同資訊，從而產生更準確的建議和更全面的說明。在真實世界資料集上的大量實驗證明了 GOT4Rec 的有效性，表明它優於現有的最先進基準。我們的程式碼可在 https://anonymous.4open.science/r/GOT4Rec-ED99 取得。

##### **VisGraphVar: A Benchmark Generator for Assessing Variability in Graph Analysis Using Large Vision-Language Models**
2411.14832v1 by Camilo Chacón Sartori, Christian Blum, Filippo Bistaffa

The fast advancement of Large Vision-Language Models (LVLMs) has shown
immense potential. These models are increasingly capable of tackling abstract
visual tasks. Geometric structures, particularly graphs with their inherent
flexibility and complexity, serve as an excellent benchmark for evaluating
these models' predictive capabilities. While human observers can readily
identify subtle visual details and perform accurate analyses, our investigation
reveals that state-of-the-art LVLMs exhibit consistent limitations in specific
visual graph scenarios, especially when confronted with stylistic variations.
In response to these challenges, we introduce VisGraphVar (Visual Graph
Variability), a customizable benchmark generator able to produce graph images
for seven distinct task categories (detection, classification, segmentation,
pattern recognition, link prediction, reasoning, matching), designed to
systematically evaluate the strengths and limitations of individual LVLMs. We
use VisGraphVar to produce 990 graph images and evaluate six LVLMs, employing
two distinct prompting strategies, namely zero-shot and chain-of-thought. The
findings demonstrate that variations in visual attributes of images (e.g., node
labeling and layout) and the deliberate inclusion of visual imperfections, such
as overlapping nodes, significantly affect model performance. This research
emphasizes the importance of a comprehensive evaluation across graph-related
tasks, extending beyond reasoning alone. VisGraphVar offers valuable insights
to guide the development of more reliable and robust systems capable of
performing advanced visual graph analysis.

摘要：大型視覺語言模型 (LVLMs) 的快速進步已展現出巨大的潛力。這些模型越來越有能力處理抽象的視覺任務。幾何結構，特別是具有內在靈活性與複雜性的圖形，可用作評估這些模型預測能力的絕佳基準。人類觀察者可以輕易辨識微妙的視覺細節並執行準確的分析，但我們的調查顯示，最先進的 LVLMs 在特定的視覺圖形場景中表現出持續的限制，特別是在面對風格變化時。為了應對這些挑戰，我們引入了 VisGraphVar（視覺圖形變異），這是一個可自訂的基準產生器，能夠產生七個不同任務類別的圖形影像（偵測、分類、分割、模式辨識、連結預測、推理、配對），旨在系統性地評估個別 LVLMs 的優點和限制。我們使用 VisGraphVar 產生 990 個圖形影像並評估六個 LVLMs，採用兩種不同的提示策略，即零次學習和思維鏈。研究結果表明，影像視覺屬性的變化（例如節點標籤和版面）以及視覺瑕疵的故意加入（例如重疊節點）會顯著影響模型效能。這項研究強調了跨圖形相關任務進行全面評估的重要性，而不僅限於推理。VisGraphVar 提供了寶貴的見解，以指導更可靠且強大的系統的開發，這些系統能夠執行進階的視覺圖形分析。

##### **MolReFlect: Towards In-Context Fine-grained Alignments between Molecules and Texts**
2411.14721v1 by Jiatong Li, Yunqing Liu, Wei Liu, Jingdi Le, Di Zhang, Wenqi Fan, Dongzhan Zhou, Yuqiang Li, Qing Li

Molecule discovery is a pivotal research field, impacting everything from the
medicines we take to the materials we use. Recently, Large Language Models
(LLMs) have been widely adopted in molecule understanding and generation, yet
the alignments between molecules and their corresponding captions remain a
significant challenge. Previous endeavours often treat the molecule as a
general SMILES string or molecular graph, neglecting the fine-grained
alignments between the molecular sub-structures and the descriptive textual
phrases, which are crucial for accurate and explainable predictions. In this
case, we introduce MolReFlect, a novel teacher-student framework designed to
contextually perform the molecule-caption alignments in a fine-grained way. Our
approach initially leverages a larger teacher LLM to label the detailed
alignments by directly extracting critical phrases from molecule captions or
SMILES strings and implying them to corresponding sub-structures or
characteristics. To refine these alignments, we propose In-Context Selective
Reflection, which retrieves previous extraction results as context examples for
teacher LLM to reflect and lets a smaller student LLM select from in-context
reflection and previous extraction results. Finally, we enhance the learning
process of the student LLM through Chain-of-Thought In-Context Molecule Tuning,
integrating the fine-grained alignments and the reasoning processes within the
Chain-of-Thought format. Our experimental results demonstrate that MolReFlect
enables LLMs like Mistral-7B to significantly outperform the previous
baselines, achieving SOTA performance on the ChEBI-20 dataset. This advancement
not only enhances the generative capabilities of LLMs in the molecule-caption
translation task, but also contributes to a more explainable framework.

摘要：分子發現是一個關鍵的研究領域，從我們服用的藥物到我們使用的材料，影響著一切。最近，大型語言模型 (LLM) 已廣泛應用於分子理解和生成中，但分子及其對應標題之間的對齊仍然是一項重大挑戰。先前的努力通常將分子視為一般的 SMILES 字符串或分子圖，忽略了分子子結構和描述性文本短語之間的細粒度對齊，這對於準確且可解釋的預測至關重要。在這種情況下，我們引入了 MolReFlect，這是一個新穎的師生框架，旨在以細粒度的方式對分子標題對齊進行上下文執行。我們的做法最初利用一個更大的教師 LLM 來標記詳細對齊，方法是直接從分子標題或 SMILES 字符串中提取關鍵短語，並將它們暗示為對應的子結構或特徵。為了優化這些對齊，我們提出了上下文選擇性反射，它將以前的提取結果作為上下文範例，供教師 LLM 進行反射，並讓一個較小的學生 LLM 從上下文反射和以前的提取結果中進行選擇。最後，我們通過思想鏈上下文分子調整增強了學生 LLM 的學習過程，將細粒度對齊和推理過程整合到思想鏈格式中。我們的實驗結果表明，MolReFlect 使像 Mistral-7B 這樣的 LLM 能夠顯著優於先前的基準，在 ChEBI-20 數據集上實現了 SOTA 性能。這一進步不僅增強了 LLM 在分子標題翻譯任務中的生成能力，而且還有助於建立一個更具可解釋性的框架。

##### **G-RAG: Knowledge Expansion in Material Science**
2411.14592v2 by Radeen Mostafa, Mirza Nihal Baig, Mashaekh Tausif Ehsan, Jakir Hasan

In the field of Material Science, effective information retrieval systems are
essential for facilitating research. Traditional Retrieval-Augmented Generation
(RAG) approaches in Large Language Models (LLMs) often encounter challenges
such as outdated information, hallucinations, limited interpretability due to
context constraints, and inaccurate retrieval. To address these issues, Graph
RAG integrates graph databases to enhance the retrieval process. Our proposed
method processes Material Science documents by extracting key entities
(referred to as MatIDs) from sentences, which are then utilized to query
external Wikipedia knowledge bases (KBs) for additional relevant information.
We implement an agent-based parsing technique to achieve a more detailed
representation of the documents. Our improved version of Graph RAG called G-RAG
further leverages a graph database to capture relationships between these
entities, improving both retrieval accuracy and contextual understanding. This
enhanced approach demonstrates significant improvements in performance for
domains that require precise information retrieval, such as Material Science.

摘要：在材料科學領域，有效的資訊檢索系統對於促進研究至關重要。大型語言模型 (LLM) 中的傳統檢索增強生成 (RAG) 方法通常會遇到挑戰，例如過時的資訊、幻覺、由於上下文限制而導致的可解釋性有限，以及檢索不準確。為了解決這些問題，Graph RAG 整合了圖形資料庫以增強檢索過程。我們提出的方法透過從句子中萃取關鍵實體 (稱為 MatID) 來處理材料科學文件，然後利用這些實體查詢外部的維基百科知識庫 (KB) 以取得其他相關資訊。我們實作了一種基於代理的解析技術，以達成更詳細的文件表示。我們改良版本的 Graph RAG，稱為 G-RAG，進一步利用圖形資料庫來擷取這些實體之間的關係，進而改善檢索準確度和脈絡理解。這種增強的方法在需要精確資訊檢索的領域（例如材料科學）中，展現了顯著的效能提升。

##### **Knowledge Graphs, Large Language Models, and Hallucinations: An NLP Perspective**
2411.14258v1 by Ernests Lavrinovics, Russa Biswas, Johannes Bjerva, Katja Hose

Large Language Models (LLMs) have revolutionized Natural Language Processing
(NLP) based applications including automated text generation, question
answering, chatbots, and others. However, they face a significant challenge:
hallucinations, where models produce plausible-sounding but factually incorrect
responses. This undermines trust and limits the applicability of LLMs in
different domains. Knowledge Graphs (KGs), on the other hand, provide a
structured collection of interconnected facts represented as entities (nodes)
and their relationships (edges). In recent research, KGs have been leveraged to
provide context that can fill gaps in an LLM understanding of certain topics
offering a promising approach to mitigate hallucinations in LLMs, enhancing
their reliability and accuracy while benefiting from their wide applicability.
Nonetheless, it is still a very active area of research with various unresolved
open problems. In this paper, we discuss these open challenges covering
state-of-the-art datasets and benchmarks as well as methods for knowledge
integration and evaluating hallucinations. In our discussion, we consider the
current use of KGs in LLM systems and identify future directions within each of
these challenges.

摘要：大型語言模型（LLM）徹底改變了基於自然語言處理（NLP）的應用，包括自動文字生成、問題解答、聊天機器人等。然而，它們面臨著一個重大的挑戰：幻覺，模型產生聽起來合理但事實上不正確的回應。這會破壞信任，並限制 LLM 在不同領域的適用性。另一方面，知識圖譜（KG）提供了以實體（節點）及其關係（邊緣）表示的相互連接事實的結構化集合。在最近的研究中，KG 已被用於提供上下文，可以填補 LLM 對某些主題理解的空白，提供了一種有希望的方法來減輕 LLM 中的幻覺，提高它們的可靠性和準確性，同時受益於它們的廣泛適用性。儘管如此，這仍然是一個非常活躍的研究領域，有各種未解決的開放問題。在本文中，我們討論了這些開放挑戰，涵蓋了最先進的數據集和基準，以及知識整合和評估幻覺的方法。在我們的討論中，我們考慮了 LLM 系統中 KG 的當前使用，並確定了這些挑戰中的每一個未來的方向。

##### **Logic Augmented Generation**
2411.14012v1 by Aldo Gangemi, Andrea Giovanni Nuzzolese

Semantic Knowledge Graphs (SKG) face challenges with scalability,
flexibility, contextual understanding, and handling unstructured or ambiguous
information. However, they offer formal and structured knowledge enabling
highly interpretable and reliable results by means of reasoning and querying.
Large Language Models (LLMs) overcome those limitations making them suitable in
open-ended tasks and unstructured environments. Nevertheless, LLMs are neither
interpretable nor reliable. To solve the dichotomy between LLMs and SKGs we
envision Logic Augmented Generation (LAG) that combines the benefits of the two
worlds. LAG uses LLMs as Reactive Continuous Knowledge Graphs that can generate
potentially infinite relations and tacit knowledge on-demand. SKGs are key for
injecting a discrete heuristic dimension with clear logical and factual
boundaries. We exemplify LAG in two tasks of collective intelligence, i.e.,
medical diagnostics and climate projections. Understanding the properties and
limitations of LAG, which are still mostly unknown, is of utmost importance for
enabling a variety of tasks involving tacit knowledge in order to provide
interpretable and effective results.

摘要：語意知識圖（SKG）在可擴充性、靈活性、情境理解以及處理非結構化或含糊資訊方面面臨挑戰。然而，它們提供正式且結構化的知識，能透過推理和查詢提供高度可解釋且可靠的結果。大型語言模型（LLM）克服了這些限制，使其適用於開放式任務和非結構化環境。儘管如此，LLM 既不可解釋也不可靠。為了解決 LLM 和 SKG 之間的二分法，我們設想了邏輯增強生成（LAG），它結合了兩個世界的優點。LAG 使用 LLM 作為反應式連續知識圖，它可以按需產生潛在的無限關係和默會知識。SKG 是注入離散啟發式維度（具有明確邏輯和事實邊界）的關鍵。我們在集體智慧的兩個任務中舉例說明 LAG，即醫療診斷和氣候預測。理解 LAG 的特性和限制（目前仍然大多數未知）對於啟用涉及默會知識的各種任務以提供可解釋且有效的結果至關重要。

##### **FastRAG: Retrieval Augmented Generation for Semi-structured Data**
2411.13773v1 by Amar Abane, Anis Bekri, Abdella Battou

Efficiently processing and interpreting network data is critical for the
operation of increasingly complex networks. Recent advances in Large Language
Models (LLM) and Retrieval-Augmented Generation (RAG) techniques have improved
data processing in network management. However, existing RAG methods like
VectorRAG and GraphRAG struggle with the complexity and implicit nature of
semi-structured technical data, leading to inefficiencies in time, cost, and
retrieval. This paper introduces FastRAG, a novel RAG approach designed for
semi-structured data. FastRAG employs schema learning and script learning to
extract and structure data without needing to submit entire data sources to an
LLM. It integrates text search with knowledge graph (KG) querying to improve
accuracy in retrieving context-rich information. Evaluation results demonstrate
that FastRAG provides accurate question answering, while improving up to 90% in
time and 85% in cost compared to GraphRAG.

摘要：有效率地處理和解讀網路資料對於日益複雜的網路操作至關重要。大型語言模型 (LLM) 和檢索增強產生 (RAG) 技術的最新進展已經改善了網路管理中的資料處理。然而，現有的 RAG 方法（例如 VectorRAG 和 GraphRAG）難以應付半結構化技術資料的複雜性和隱含性質，導致時間、成本和檢索效率不彰。本文介紹 FastRAG，一種專為半結構化資料設計的新穎 RAG 方法。FastRAG 使用架構學習和腳本學習來萃取和建構資料，而無需將整個資料來源提交給 LLM。它將文字搜尋與知識圖譜 (KG) 查詢整合，以提高檢索內容豐富資訊的準確性。評估結果證明，FastRAG 提供了準確的問答，同時與 GraphRAG 相比，時間改善了 90%，成本改善了 85%。

##### **Predictive Insights into LGBTQ+ Minority Stress: A Transductive Exploration of Social Media Discourse**
2411.13534v1 by S. Chapagain, Y. Zhao, T. K. Rohleen, S. M. Hamdi, S. F. Boubrahimi, R. E. Flinn, E. M. Lund, D. Klooster, J. R. Scheer, C. J. Cascalheira

Individuals who identify as sexual and gender minorities, including lesbian,
gay, bisexual, transgender, queer, and others (LGBTQ+) are more likely to
experience poorer health than their heterosexual and cisgender counterparts.
One primary source that drives these health disparities is minority stress
(i.e., chronic and social stressors unique to LGBTQ+ communities' experiences
adapting to the dominant culture). This stress is frequently expressed in
LGBTQ+ users' posts on social media platforms. However, these expressions are
not just straightforward manifestations of minority stress. They involve
linguistic complexity (e.g., idiom or lexical diversity), rendering them
challenging for many traditional natural language processing methods to detect.
In this work, we designed a hybrid model using Graph Neural Networks (GNN) and
Bidirectional Encoder Representations from Transformers (BERT), a pre-trained
deep language model to improve the classification performance of minority
stress detection. We experimented with our model on a benchmark social media
dataset for minority stress detection (LGBTQ+ MiSSoM+). The dataset is
comprised of 5,789 human-annotated Reddit posts from LGBTQ+ subreddits. Our
approach enables the extraction of hidden linguistic nuances through
pretraining on a vast amount of raw data, while also engaging in transductive
learning to jointly develop representations for both labeled training data and
unlabeled test data. The RoBERTa-GCN model achieved an accuracy of 0.86 and an
F1 score of 0.86, surpassing the performance of other baseline models in
predicting LGBTQ+ minority stress. Improved prediction of minority stress
expressions on social media could lead to digital health interventions to
improve the wellbeing of LGBTQ+ people-a community with high rates of
stress-sensitive health problems.

摘要：<paragraph>認同自己是性與性別少數族群的人，包括女同性戀、男同性戀、雙性戀、跨性別、酷兒和其他 LGBTQ+ 族群，比異性戀和順性別者更容易有較差的健康狀況。造成這些健康差異的主要來源之一是少數族群壓力（即 LGBTQ+ 社群在適應主流文化時獨有的慢性與社會壓力）。這種壓力經常在 LGBTQ+ 使用者於社群媒體平台上的貼文中表達出來。然而，這些表達並不僅僅是少數族群壓力的直接表現。它們包含了語言複雜性（例如慣用語或詞彙多樣性），讓許多傳統的自然語言處理方法難以辨識。在這項研究中，我們設計了一個混合模型，使用圖神經網路 (GNN) 和來自 Transformer 的雙向編碼器表徵 (BERT)，這是一個經過預先訓練的深度語言模型，以提升少數族群壓力辨識的分類效能。我們在一個用於少數族群壓力辨識的基準社群媒體資料集 (LGBTQ+ MiSSoM+) 上對我們的模型進行實驗。該資料集包含了 5,789 篇由人類註解的 Reddit 貼文，來自於 LGBTQ+ 的 subreddit。我們的做法能夠透過在大量的原始資料上進行預訓練來萃取隱藏的語言差異，同時也參與轉導式學習，以共同開發標籤訓練資料和未標籤測試資料的表徵。RoBERTa-GCN 模型達到了 0.86 的準確率和 0.86 的 F1 分數，在預測 LGBTQ+ 少數族群壓力方面超越了其他基線模型的效能。在社群媒體上對少數族群壓力表達的預測改善，可以導致數位健康介入措施，以改善 LGBTQ+ 族群的福祉，而這個族群有很高的壓力敏感性健康問題發生率。</paragraph>

##### **KAAE: Numerical Reasoning for Knowledge Graphs via Knowledge-aware Attributes Learning**
2411.12950v2 by Ming Yin, Qiang Zhou, Zongsheng Cao, Mei Li

Numerical reasoning is pivotal in various artificial intelligence
applications, such as natural language processing and recommender systems,
where it involves using entities, relations, and attribute values (e.g.,
weight, length) to infer new factual relations (e.g., the Nile is longer than
the Amazon). However, existing approaches encounter two critical challenges in
modeling: (1) semantic relevance-the challenge of insufficiently capturing the
necessary contextual interactions among entities, relations, and numerical
attributes, often resulting in suboptimal inference; and (2) semantic
ambiguity-the difficulty in accurately distinguishing ordinal relationships
during numerical reasoning, which compromises the generation of high-quality
samples and limits the effectiveness of contrastive learning. To address these
challenges, we propose the novel Knowledge-Aware Attributes Embedding model
(KAAE) for knowledge graph embeddings in numerical reasoning. Specifically, to
overcome the challenge of semantic relevance, we introduce a
Mixture-of-Experts-Knowledge-Aware (MoEKA) Encoder, designed to integrate the
semantics of entities, relations, and numerical attributes into a joint
semantic space. To tackle semantic ambiguity, we implement a new ordinal
knowledge contrastive learning (OKCL) strategy that generates high-quality
ordinal samples from the original data with the aid of ordinal relations,
capturing fine-grained semantic nuances essential for accurate numerical
reasoning. Experiments on three public benchmark datasets demonstrate the
superior performance of KAAE across various attribute value distributions.

摘要：數值推理在各種人工智慧應用中至關重要，例如自然語言處理和推薦系統，其中涉及使用實體、關係和屬性值（例如，重量、長度）來推論新的事實關係（例如，尼羅河比亞馬遜河長）。然而，現有方法在建模中遇到兩個關鍵挑戰：（1）語義相關性 - 無法充分捕捉實體、關係和數值屬性之間必要的上下文交互的挑戰，通常導致次優推理；以及（2）語義歧義 - 在數值推理期間準確區分序數關係的難度，這會損害高品質樣本的產生並限制對比學習的有效性。為了應對這些挑戰，我們提出了用於數值推理的知識圖譜嵌入的新型知識感知屬性嵌入模型 (KAAE)。具體來說，為了克服語義相關性的挑戰，我們引入了一個混合專家知識感知 (MoEKA) 編碼器，旨在將實體、關係和數值屬性的語義整合到一個聯合語義空間中。為了應對語義歧義，我們實施了一種新的序數知識對比學習 (OKCL) 策略，該策略利用序數關係從原始數據中生成高品質序數樣本，捕捉對準確數值推理至關重要的細緻語義差異。在三個公開基準數據集上的實驗證明了 KAAE 在各種屬性值分佈中的優異性能。

##### **Neurosymbolic Graph Enrichment for Grounded World Models**
2411.12671v1 by Stefano De Giorgis, Aldo Gangemi, Alessandro Russo

The development of artificial intelligence systems capable of understanding
and reasoning about complex real-world scenarios is a significant challenge. In
this work we present a novel approach to enhance and exploit LLM reactive
capability to address complex problems and interpret deeply contextual
real-world meaning. We introduce a method and a tool for creating a multimodal,
knowledge-augmented formal representation of meaning that combines the
strengths of large language models with structured semantic representations.
Our method begins with an image input, utilizing state-of-the-art large
language models to generate a natural language description. This description is
then transformed into an Abstract Meaning Representation (AMR) graph, which is
formalized and enriched with logical design patterns, and layered semantics
derived from linguistic and factual knowledge bases. The resulting graph is
then fed back into the LLM to be extended with implicit knowledge activated by
complex heuristic learning, including semantic implicatures, moral values,
embodied cognition, and metaphorical representations. By bridging the gap
between unstructured language models and formal semantic structures, our method
opens new avenues for tackling intricate problems in natural language
understanding and reasoning.

摘要：人工智能系統的發展能夠理解並推理複雜的真實世界場景是一個重大的挑戰。在這項工作中，我們提出了一種新穎的方法來增強和利用 LLM 反應能力，以解決複雜的問題並解釋深層的語境真實世界意義。我們介紹了一種方法和工具，用於建立多模態、知識增強的意義形式化表示，結合了大型語言模型與結構化語義表示的優點。我們的模型從影像輸入開始，利用最先進的大型語言模型來產生自然語言描述。然後將此描述轉換為抽象意義表示 (AMR) 圖形，並使用邏輯設計模式進行形式化和豐富，以及從語言和事實知識庫中衍生的分層語義。然後將結果圖形回饋到 LLM，以擴充 LLM 中由複雜的啟發式學習所啟用的內隱知識，包括語義蘊涵、道德價值、具身認知和隱喻表示。我們的模型透過彌合非結構化語言模型與形式語義結構之間的差距，為解決自然語言理解和推理中的複雜問題開闢了新的途徑。

##### **Instant Policy: In-Context Imitation Learning via Graph Diffusion**
2411.12633v1 by Vitalis Vosylius, Edward Johns

Following the impressive capabilities of in-context learning with large
transformers, In-Context Imitation Learning (ICIL) is a promising opportunity
for robotics. We introduce Instant Policy, which learns new tasks instantly
(without further training) from just one or two demonstrations, achieving ICIL
through two key components. First, we introduce inductive biases through a
graph representation and model ICIL as a graph generation problem with a
learned diffusion process, enabling structured reasoning over demonstrations,
observations, and actions. Second, we show that such a model can be trained
using pseudo-demonstrations - arbitrary trajectories generated in simulation -
as a virtually infinite pool of training data. Simulated and real experiments
show that Instant Policy enables rapid learning of various everyday robot
tasks. We also show how it can serve as a foundation for cross-embodiment and
zero-shot transfer to language-defined tasks. Code and videos are available at
https://www.robot-learning.uk/instant-policy.

摘要：繼大型Transformer在情境學習中表現出令人印象深刻的能力後，情境模仿學習 (ICIL) 成為了機器人領域中一個有前途的機會。我們引入了即時策略，它僅從一或兩次示範中立即學習新任務（無需進一步訓練），並通過兩個關鍵組成部分實現 ICIL。首先，我們通過圖形表示和模型 ICIL 引入歸納偏差，並將其作為具有學習擴散過程的圖形生成問題，從而能夠對示範、觀察和動作進行結構化推理。其次，我們展示了這種模型可以使用偽示範進行訓練，而偽示範是模擬中產生的任意軌跡，可用作幾乎無限的訓練數據池。模擬和真實實驗表明，即時策略能夠快速學習各種日常機器人任務。我們還展示了它如何作為跨具身和零次傳輸到語言定義任務的基礎。代碼和影片可在 https://www.robot-learning.uk/instant-policy 取得。

##### **Bias-Free Sentiment Analysis through Semantic Blinding and Graph Neural Networks**
2411.12493v2 by Hubert Plisiecki

This paper introduces the Semantic Propagation Graph Neural Network (SProp
GNN), a machine learning sentiment analysis (SA) architecture that relies
exclusively on syntactic structures and word-level emotional cues to predict
emotions in text. By semantically blinding the model to information about
specific words, it is robust to biases such as political or gender bias that
have been plaguing previous machine learning-based SA systems. The SProp GNN
shows performance superior to lexicon-based alternatives such as VADER and
EmoAtlas on two different prediction tasks, and across two languages.
Additionally, it approaches the accuracy of transformer-based models while
significantly reducing bias in emotion prediction tasks. By offering improved
explainability and reducing bias, the SProp GNN bridges the methodological gap
between interpretable lexicon approaches and powerful, yet often opaque, deep
learning models, offering a robust tool for fair and effective emotion analysis
in understanding human behavior through text.

摘要：本文介紹了語義傳播圖神經網路 (SProp GNN)，這是一種機器學習情緒分析 (SA) 架構，專門依賴句法結構和詞彙層級的情緒線索來預測文字中的情緒。透過在語義上讓模型對特定字詞的資訊視而不見，它能有效消除政治或性別偏見等偏誤，這些偏誤一直困擾著先前的機器學習式 SA 系統。SProp GNN 在兩項不同的預測任務和兩種語言上的表現都優於基於詞彙庫的替代方案，例如 VADER 和 EmoAtlas。此外，它在大幅減少情緒預測任務中的偏誤同時，也接近了基於轉換器的模型的準確度。透過提供更好的可解釋性並減少偏誤，SProp GNN 搭起了可詮釋詞彙方法與強大但經常不透明的深度學習模型之間的方法論鴻溝，提供了一個強健的工具，可以透過文字理解人類行為，進行公平且有效的分析。

##### **Neon: News Entity-Interaction Extraction for Enhanced Question Answering**
2411.12449v2 by Sneha Singhania, Silviu Cucerzan, Allen Herring, Sujay Kumar Jauhar

Capturing fresh information in near real-time and using it to augment
existing large language models (LLMs) is essential to generate up-to-date,
grounded, and reliable output. This problem becomes particularly challenging
when LLMs are used for informational tasks in rapidly evolving fields, such as
Web search related to recent or unfolding events involving entities, where
generating temporally relevant responses requires access to up-to-the-hour news
sources. However, the information modeled by the parametric memory of LLMs is
often outdated, and Web results from prototypical retrieval systems may fail to
capture the latest relevant information and struggle to handle conflicting
reports in evolving news. To address this challenge, we present the NEON
framework, designed to extract emerging entity interactions -- such as events
or activities -- as described in news articles. NEON constructs an
entity-centric timestamped knowledge graph that captures such interactions,
thereby facilitating enhanced QA capabilities related to news events. Our
framework innovates by integrating open Information Extraction (openIE) style
tuples into LLMs to enable in-context retrieval-augmented generation. This
integration demonstrates substantial improvements in QA performance when
tackling temporal, entity-centric search queries. Through NEON, LLMs can
deliver more accurate, reliable, and up-to-date responses.

摘要：捕捉近乎實時的最新資訊，並利用它來擴充現有的大型語言模型 (LLM)，對於產生即時、有根據且可靠的輸出至關重要。當 LLM 被用於快速演化的領域中的訊息任務時，這個問題會變得特別具有挑戰性，例如與涉及實體的近期或正在發生的事件相關的網路搜尋，在這種情況下，產生時間相關的回應需要取得最新的新聞來源。然而，LLM 的參數記憶體建模的資訊經常過時，而原型檢索系統的網路結果可能無法捕捉最新的相關資訊，並且難以處理演化中的新聞中的相互矛盾的報導。為了應對這個挑戰，我們提出了 NEON 框架，旨在萃取新興實體互動（例如事件或活動），如新聞文章中所描述的。NEON 建構了一個以實體為中心的帶時間戳記的知識圖譜，用來捕捉此類互動，從而促進與新聞事件相關的增強式問答能力。我們的框架透過將開放資訊萃取 (openIE) 風格元組整合到 LLM 中，以啟用情境內檢索增強式產生，進而創新。當處理時間、以實體為中心的搜尋查詢時，這種整合顯示出問答效能的顯著提升。透過 NEON，LLM 可以提供更準確、可靠且最新的回應。

##### **GRL-Prompt: Towards Knowledge Graph based Prompt Optimization via Reinforcement Learning**
2411.14479v1 by Yuze Liu, Tingjie Liu, Tiehua Zhang, Youhua Xia, Jinze Wang, Zhishu Shen, Jiong Jin, Fei Richard Yu

Large language models (LLMs) have demonstrated impressive success in a wide
range of natural language processing (NLP) tasks due to their extensive general
knowledge of the world. Recent works discovered that the performance of LLMs is
heavily dependent on the input prompt. However, prompt engineering is usually
done manually in a trial-and-error fashion, which can be labor-intensive and
challenging in order to find the optimal prompts. To address these problems and
unleash the utmost potential of LLMs, we propose a novel LLMs-agnostic
framework for prompt optimization, namely GRL-Prompt, which aims to
automatically construct optimal prompts via reinforcement learning (RL) in an
end-to-end manner. To provide structured action/state representation for
optimizing prompts, we construct a knowledge graph (KG) that better encodes the
correlation between the user query and candidate in-context examples.
Furthermore, a policy network is formulated to generate the optimal action by
selecting a set of in-context examples in a rewardable order to construct the
prompt. Additionally, the embedding-based reward shaping is utilized to
stabilize the RL training process. The experimental results show that
GRL-Prompt outperforms recent state-of-the-art methods, achieving an average
increase of 0.10 in ROUGE-1, 0.07 in ROUGE-2, 0.07 in ROUGE-L, and 0.05 in
BLEU.

摘要：大型語言模型 (LLM) 在廣泛的自然語言處理 (NLP) 任務中展現出令人印象深刻的成功，這歸功於它們對世界的廣泛一般知識。最近的研究發現，LLM 的效能高度依賴於輸入提示。然而，提示工程通常以試錯的方式手動完成，這在尋找最佳提示時可能會耗費大量人力且具有挑戰性。為了解決這些問題並發揮 LLM 的最大潛力，我們提出了一個新的 LLM 不可知框架，用於提示最佳化，即 GRL-Prompt，其旨在透過強化學習 (RL) 以端到端的方式自動建構最佳提示。為了提供結構化的動作/狀態表示以最佳化提示，我們建構了一個知識圖譜 (KG)，它能更好地編碼使用者查詢與候選情境範例之間的關聯性。此外，我們制定了一個策略網路，透過以可獎勵的順序選擇一組情境範例來建構提示，以產生最佳動作。此外，我們利用基於嵌入的獎勵塑造來穩定 RL 訓練過程。實驗結果顯示，GRL-Prompt 優於最近的最新方法，在 ROUGE-1 中平均增加 0.10，在 ROUGE-2 中增加 0.07，在 ROUGE-L 中增加 0.07，在 BLEU 中增加 0.05。

##### **Just KIDDIN: Knowledge Infusion and Distillation for Detection of INdecent Memes**
2411.12174v1 by Rahul Garg, Trilok Padhi, Hemang Jain, Ugur Kursuncu, Ponnurangam Kumaraguru

Toxicity identification in online multimodal environments remains a
challenging task due to the complexity of contextual connections across
modalities (e.g., textual and visual). In this paper, we propose a novel
framework that integrates Knowledge Distillation (KD) from Large Visual
Language Models (LVLMs) and knowledge infusion to enhance the performance of
toxicity detection in hateful memes. Our approach extracts sub-knowledge graphs
from ConceptNet, a large-scale commonsense Knowledge Graph (KG) to be infused
within a compact VLM framework. The relational context between toxic phrases in
captions and memes, as well as visual concepts in memes enhance the model's
reasoning capabilities. Experimental results from our study on two hate speech
benchmark datasets demonstrate superior performance over the state-of-the-art
baselines across AU-ROC, F1, and Recall with improvements of 1.1%, 7%, and 35%,
respectively. Given the contextual complexity of the toxicity detection task,
our approach showcases the significance of learning from both explicit (i.e.
KG) as well as implicit (i.e. LVLMs) contextual cues incorporated through a
hybrid neurosymbolic approach. This is crucial for real-world applications
where accurate and scalable recognition of toxic content is critical for
creating safer online environments.

摘要：網路多模態環境中的毒性辨識，由於模態間（例如文字和視覺）的脈絡關聯複雜，因此仍是一項具有挑戰性的任務。在本文中，我們提出一個新穎的架構，整合來自大型視覺語言模型 (LVLMs) 的知識蒸餾 (KD) 和知識注入，以增強仇恨迷因中毒性偵測的效能。我們的做法從 ConceptNet（一個大型常識知識圖譜 (KG)）中萃取子知識圖，並注入到一個緊湊的 VLM 架構中。標題和迷因中具有毒性的詞彙之間的關係脈絡，以及迷因中的視覺概念，增強了模型的推理能力。我們在兩個仇恨言論基準資料集上進行的研究的實驗結果，證明了在 AU-ROC、F1 和召回率方面，我們的做法優於最先進的基準，分別提升了 1.1%、7% 和 35%。鑑於毒性偵測任務的脈絡複雜性，我們的做法展示了從明確（例如 KG）和隱含（例如 LVLMs）脈絡線索中學習，並透過混合神經符號方法整合起來的重要性。這對於真實世界的應用至關重要，在這些應用中，準確且可擴充的毒性內容辨識對於創造更安全的網路環境至關重要。

##### **Regret-Free Reinforcement Learning for LTL Specifications**
2411.12019v1 by Rupak Majumdar, Mahmoud Salamati, Sadegh Soudjani

Reinforcement learning (RL) is a promising method to learn optimal control
policies for systems with unknown dynamics. In particular, synthesizing
controllers for safety-critical systems based on high-level specifications,
such as those expressed in temporal languages like linear temporal logic (LTL),
presents a significant challenge in control systems research. Current RL-based
methods designed for LTL tasks typically offer only asymptotic guarantees,
which provide no insight into the transient performance during the learning
phase. While running an RL algorithm, it is crucial to assess how close we are
to achieving optimal behavior if we stop learning.
  In this paper, we present the first regret-free online algorithm for learning
a controller that addresses the general class of LTL specifications over Markov
decision processes (MDPs) with a finite set of states and actions. We begin by
proposing a regret-free learning algorithm to solve infinite-horizon
reach-avoid problems. For general LTL specifications, we show that the
synthesis problem can be reduced to a reach-avoid problem when the graph
structure is known. Additionally, we provide an algorithm for learning the
graph structure, assuming knowledge of a minimum transition probability, which
operates independently of the main regret-free algorithm.

摘要：強化學習 (RL) 是一種有希望的方法，可以學習未知動態系統的最佳控制策略。特別是，基於高階規範（例如用線性時序邏輯 (LTL) 等時序語言表達的規範）為安全關鍵系統合成控制器，這在控制系統研究中是一個重大挑戰。目前的基於 RL 的 LTL 任務方法通常僅提供漸近保證，這在學習階段沒有提供暫態效能的見解。在執行 RL 演算法時，如果我們停止學習，評估我們距離達成最佳行為有多近至關重要。在本文中，我們提出了第一個無遺憾線上演算法，用於學習一個控制器，該控制器解決了馬可夫決策過程 (MDP) 上的一般類別 LTL 規範，其中包含有限的狀態和動作集合。我們首先提出一個無遺憾學習演算法來解決無限時域到達避免問題。對於一般 LTL 規範，我們表明當圖形結構已知時，合成問題可以簡化為到達避免問題。此外，我們提供了一個演算法來學習圖形結構，假設知道最小轉移機率，它獨立於主要的無遺憾演算法運作。

##### **Semantic-Geometric-Physical-Driven Robot Manipulation Skill Transfer via Skill Library and Tactile Representation**
2411.11714v1 by Mingchao Qi, Yuanjin Li, Xing Liu, Zhengxiong Liu, Panfeng Huang

Deploying robots in open-world environments involves complex tasks
characterized by long sequences and rich interactions, necessitating efficient
transfer of robotic skills across diverse and complex scenarios. To address
this challenge, we propose a skill library framework based on knowledge graphs,
which endows robots with high-level skill awareness and spatial semantic
understanding. The framework hierarchically organizes operational knowledge by
constructing a "task graph" and a "scene graph" to represent task and scene
semantic information, respectively. We introduce a "state graph" to facilitate
interaction between high-level task planning and low-level scene information.
Furthermore, we propose a hierarchical transfer framework for operational
skills. At the task level, the framework integrates contextual learning and
chain-of-thought prompting within a four-stage prompt paradigm, leveraging
large language models' (LLMs) reasoning and generalization capabilities to
achieve task-level subtask sequence transfer. At the motion level, an adaptive
trajectory transfer method is developed using the A* algorithm and the skill
library, enabling motion-level adaptive trajectory transfer. At the physical
level, we introduce an adaptive contour extraction and posture perception
method based on tactile perception. This method dynamically obtains
high-precision contour and posture information from visual-tactile texture data
and adjusts transferred skills, such as contact positions and postures, to
ensure effectiveness in new environments. Experimental results validate the
effectiveness of the proposed methods. Project
website:https://github.com/MingchaoQi/skill_transfer

摘要：<paragraph>在开放世界环境中部署机器人涉及复杂的任务，其特点是序列长、交互丰富，需要在不同且复杂的场景中高效地转移机器人技能。为了应对这一挑战，我们提出一个基于知识图谱的技能库框架，它赋予机器人高级技能意识和空间语义理解。该框架通过构建“任务图”和“场景图”来分层组织操作知识，分别表示任务和场景语义信息。我们引入一个“状态图”来促进高级任务规划和低级场景信息之间的交互。此外，我们提出了一个操作技能的分层转移框架。在任务层面，该框架在一个四阶段提示范式中集成了上下文学习和思想链提示，利用大语言模型 (LLM) 的推理和泛化能力来实现任务级子任务序列转移。在运动层面，使用 A* 算法和技能库开发了一种自适应轨迹转移方法，实现运动级自适应轨迹转移。在物理层面，我们引入了一种基于触觉感知的自适应轮廓提取和姿态感知方法。该方法从视觉触觉纹理数据中动态获取高精度的轮廓和姿态信息，并调整转移的技能，例如接触位置和姿态，以确保在新的环境中有效。实验结果验证了所提出方法的有效性。项目网站：https://github.com/MingchaoQi/skill_transfer</paragraph>

##### **Addressing Hallucinations in Language Models with Knowledge Graph Embeddings as an Additional Modality**
2411.11531v1 by Viktoriia Chekalina, Anton Razzigaev, Elizaveta Goncharova, Andrey Kuznetsov

In this paper we present an approach to reduce hallucinations in Large
Language Models (LLMs) by incorporating Knowledge Graphs (KGs) as an additional
modality. Our method involves transforming input text into a set of KG
embeddings and using an adapter to integrate these embeddings into the language
model space, without relying on external retrieval processes.
  To facilitate this, we created WikiEntities, a dataset containing over 3
million Wikipedia texts annotated with entities from Wikidata and their
corresponding embeddings from PyTorch-BigGraph. This dataset serves as a
valuable resource for training Entity Linking models and adapting the described
method to various LLMs using specialized adapters.
  Our method does not require fine-tuning of the language models themselves;
instead, we only train the adapter. This ensures that the model's performance
on other tasks is not affected. We trained an adapter for the Mistral 7B, LLaMA
2-7B (chat), and LLaMA 3-8B (instruct) models using this dataset and
demonstrated that our approach improves performance on the HaluEval, True-False
benchmarks and FEVER dataset. The results indicate that incorporating KGs as a
new modality can effectively reduce hallucinations and improve the factual
accuracy of language models, all without the need for external retrieval.

摘要：<paragraph>在本文中，我們提出了一種方法，透過將知識圖譜 (KG) 作為附加方式納入大型語言模型 (LLM)，以減少幻覺。我們的做法包括將輸入文字轉換成一組 KG 嵌入，並使用適配器將這些嵌入整合到語言模型空間，而無需依賴外部檢索程序。
為了促進這一點，我們建立了 WikiEntities，這是一個包含超過 300 萬個維基百科文字的資料集，其中附有來自 Wikidata 的實體註解，以及它們來自 PyTorch-BigGraph 的對應嵌入。此資料集作為訓練實體連結模型和使用專門適配器將所述方法調整到各種 LLM 的寶貴資源。
我們的做法不需要微調語言模型本身；相反，我們只訓練適配器。這確保了模型在其他任務上的效能不受影響。我們使用此資料集訓練了 Mistral 7B、LLaMA 2-7B (聊天) 和 LLaMA 3-8B (指令) 模型的適配器，並證明了我們的做法改善了 HaluEval、真假基準和 FEVER 資料集的效能。結果表明，將 KG 作為一種新方式納入可以有效減少幻覺，並提高語言模型的事實準確性，而無需外部檢索。</paragraph>

##### **RPN 2: On Interdependence Function Learning Towards Unifying and Advancing CNN, RNN, GNN, and Transformer**
2411.11162v1 by Jiawei Zhang

This paper builds upon our previous work on the Reconciled Polynomial Network
(RPN). The original RPN model was designed under the assumption of input data
independence, presuming the independence among both individual instances within
data batches and attributes in each data instance. However, this assumption
often proves invalid for function learning tasks involving complex,
interdependent data such as language, images, time series, and graphs. Ignoring
such data interdependence may inevitably lead to significant performance
degradation.
  To overcome these limitations, we introduce the new Reconciled Polynomial
Network (version 2), namely RPN 2, in this paper. By incorporating data and
structural interdependence functions, RPN 2 explicitly models data
interdependence via new component functions in its architecture.
  This enhancement not only significantly improves RPN 2's learning performance
but also substantially expands its unifying potential, enabling it to encompass
a broader range of contemporary dominant backbone models within its canonical
representation. These backbones include, but are not limited to, convolutional
neural networks (CNNs), recurrent neural networks (RNNs), graph neural networks
(GNNs), and Transformers. Our analysis reveals that the fundamental
distinctions among these backbone models primarily stem from their diverse
approaches to defining the interdependence functions. Furthermore, this unified
representation opens up new opportunities for designing innovative
architectures with the potential to surpass the performance of these dominant
backbones.

摘要：本文建立在我们先前关于协调多项式网络 (RPN) 的工作之上。最初的 RPN 模型是在输入数据独立性的假设下设计的，假定数据批次中各个实例之间的独立性以及每个数据实例中的属性之间的独立性。然而，对于涉及复杂相互依赖数据（例如语言、图像、时间序列和图形）的功能学习任务，这种假设通常被证明是无效的。忽略此类数据相互依赖性不可避免地会导致性能显着下降。
为了克服这些限制，我们在本文中引入了新的协调多项式网络（版本 2），即 RPN 2。通过结合数据和结构相互依赖函数，RPN 2 通过其架构中的新组件函数明确地对数据相互依赖性进行建模。
这种增强不仅显着提高了 RPN 2 的学习性能，而且还大幅扩展了其统一潜力，使其能够在其规范表示中包含更广泛的当代主干模型。这些主干包括但不限于卷积神经网络 (CNN)、循环神经网络 (RNN)、图神经网络 (GNN) 和 Transformer。我们的分析表明，这些主干模型之间的根本区别主要源于它们定义相互依赖函数的不同方法。此外，这种统一表示为设计创新架构开辟了新的机会，这些架构有可能超越这些主干的性能。

##### **LLaSA: Large Language and Structured Data Assistant**
2411.14460v1 by Yao Xu, Shizhu He, Zeng Xiangrong, Jiabei Chen, Guang Liu, Bingning Wang, Jun Zhao, Kang Liu

Structured data, such as tables, graphs, and databases, play a critical role
in plentiful NLP tasks such as question answering and dialogue system.
Recently, inspired by Vision-Language Models, Graph Neutral Networks (GNNs)
have been introduced as an additional modality into the input of Large Language
Models (LLMs) to improve their performance on Structured Knowledge Grounding
(SKG) tasks. However, those GNN-enhanced LLMs have the following limitations:
(1) They employ diverse GNNs to model varying types of structured data,
rendering them unable to uniformly process various forms of structured data.
(2) The pretraining of GNNs is coupled with specific LLMs, which prevents GNNs
from fully aligning with the textual space and limits their adaptability to
other LLMs. To address these issues, we propose \textbf{L}arge
\textbf{L}anguage and \textbf{S}tructured Data \textbf{A}ssistant (LLaSA), a
general framework for enhancing LLMs' ability to handle structured data.
Specifically, we represent various types of structured data in a unified
hypergraph format, and use self-supervised learning to pretrain a hypergraph
encoder, and a G-Former compressing encoded hypergraph representations with
cross-attention. The compressed hypergraph representations are appended to the
serialized inputs during training and inference stages of LLMs. Experimental
results on multiple SKG tasks show that our pretrained hypergraph encoder can
adapt to various LLMs and enhance their ability to process different types of
structured data. Besides, LLaSA, with LoRA fine-tuning, outperforms previous
SOTA method using full parameters tuning.

摘要：<paragraph>結構化資料，例如表格、圖表和資料庫，在豐富的 NLP 任務中扮演著至關重要的角色，例如問答和對話系統。
最近，受到視覺語言模型的啟發，圖形中立網路 (GNN) 已被引入大型語言模型 (LLM) 的輸入中作為一種額外的模式，以提升其在結構化知識基礎 (SKG) 任務上的表現。然而，這些 GNN 增強的 LLM 具有以下限制：
(1) 它們使用不同的 GNN 來建模各種結構化資料類型，導致它們無法統一處理各種形式的結構化資料。
(2) GNN 的預訓練與特定的 LLM 結合在一起，這會阻止 GNN 與文本空間完全對齊，並限制其適應其他 LLM。為了解決這些問題，我們提出了**L**arge **L**anguage and **S**tructured Data **A**ssistant (LLaSA)，一個用於增強 LLM 處理結構化資料能力的通用框架。
具體來說，我們以統一的超圖格式表示各種結構化資料類型，並使用自我監督學習來預訓練超圖編碼器，以及使用跨注意力壓縮編碼超圖表示的 G-Former。壓縮的超圖表示會附加到 LLM 的訓練和推論階段的序列化輸入中。多個 SKG 任務的實驗結果表明，我們預訓練的超圖編碼器可以適應各種 LLM，並增強其處理不同類型結構化資料的能力。此外，LLaSA 使用 LoRA 微調，優於使用全參數微調的先前 SOTA 方法。</paragraph>

##### **Unveiling User Preferences: A Knowledge Graph and LLM-Driven Approach for Conversational Recommendation**
2411.14459v1 by Zhangchi Qiu, Linhao Luo, Shirui Pan, Alan Wee-Chung Liew

Conversational Recommender Systems (CRSs) aim to provide personalized
recommendations through dynamically capturing user preferences in interactive
conversations. Conventional CRSs often extract user preferences as hidden
representations, which are criticized for their lack of interpretability. This
diminishes the transparency and trustworthiness of the recommendation process.
Recent works have explored combining the impressive capabilities of Large
Language Models (LLMs) with the domain-specific knowledge of Knowledge Graphs
(KGs) to generate human-understandable recommendation explanations. Despite
these efforts, the integration of LLMs and KGs for CRSs remains challenging due
to the modality gap between unstructured dialogues and structured KGs.
Moreover, LLMs pre-trained on large-scale corpora may not be well-suited for
analyzing user preferences, which require domain-specific knowledge. In this
paper, we propose COMPASS, a plug-and-play framework that synergizes LLMs and
KGs to unveil user preferences, enhancing the performance and explainability of
existing CRSs. To address integration challenges, COMPASS employs a two-stage
training approach: first, it bridges the gap between the structured KG and
natural language through an innovative graph entity captioning pre-training
mechanism. This enables the LLM to transform KG entities into concise natural
language descriptions, allowing them to comprehend domain-specific knowledge.
Following, COMPASS optimizes user preference modeling via knowledge-aware
instruction fine-tuning, where the LLM learns to reason and summarize user
preferences from both dialogue histories and KG-augmented context. This enables
COMPASS to perform knowledge-aware reasoning and generate comprehensive and
interpretable user preferences that can seamlessly integrate with existing CRS
models for improving recommendation performance and explainability.

摘要：對話式推薦系統 (CRS) 旨在透過動態捕捉互動對話中的使用者偏好，提供個人化推薦。傳統的 CRS 通常會將使用者偏好擷取為隱藏式表徵，而其缺點在於缺乏可解釋性，這降低了推薦程式的透明度和可信度。最近的研究探討將大型語言模型 (LLM) 的強大功能與知識圖譜 (KG) 的特定領域知識結合，以產生人類可以理解的推薦說明。儘管有這些努力，由於非結構化對話和結構化 KG 之間的模式差異，LLM 和 KG 在 CRS 中的整合仍然具有挑戰性。此外，針對大型語料庫預先訓練的 LLM 可能不適合分析使用者偏好，因為這需要特定領域的知識。在本文中，我們提出 COMPASS，這是一個即插即用的架構，它協同運用 LLM 和 KG 來揭示使用者偏好，增強現有 CRS 的效能和可解釋性。為了應對整合挑戰，COMPASS 採用了兩階段的訓練方法：首先，它透過創新的圖形實體標題預訓練機制，彌合結構化 KG 和自然語言之間的差距。這讓 LLM 能夠將 KG 實體轉換為簡潔的自然語言描述，讓它們能夠理解特定領域的知識。接下來，COMPASS 透過知識感知指令微調來最佳化使用者偏好建模，其中 LLM 學習從對話記錄和 KG 擴充的內容中推論和總結使用者偏好。這讓 COMPASS 能夠執行知識感知推理，並產生全面且可解釋的使用者偏好，這些偏好可以無縫整合到現有的 CRS 模型中，以改善推薦效能和可解釋性。

##### **A Novel Approach to Eliminating Hallucinations in Large Language Model-Assisted Causal Discovery**
2411.12759v1 by Grace Sng, Yanming Zhang, Klaus Mueller

The increasing use of large language models (LLMs) in causal discovery as a
substitute for human domain experts highlights the need for optimal model
selection. This paper presents the first hallucination survey of popular LLMs
for causal discovery. We show that hallucinations exist when using LLMs in
causal discovery so the choice of LLM is important. We propose using Retrieval
Augmented Generation (RAG) to reduce hallucinations when quality data is
available. Additionally, we introduce a novel method employing multiple LLMs
with an arbiter in a debate to audit edges in causal graphs, achieving a
comparable reduction in hallucinations to RAG.

摘要：隨著大型語言模型 (LLM) 在因果發現中作為人類領域專家的替代品使用日益增加，這凸顯了最佳模型選擇的需求。本文提出了第一份流行 LLM 的幻覺調查以進行因果發現。我們表明在因果發現中使用 LLM 時存在幻覺，因此 LLM 的選擇很重要。我們建議使用檢索強化生成 (RAG) 來減少在有品質資料時產生的幻覺。此外，我們引入了一種新的方法，在辯論中使用多個 LLM 和仲裁者來審核因果圖中的邊緣，與 RAG 相比，幻覺減少了許多。

##### **VeriGraph: Scene Graphs for Execution Verifiable Robot Planning**
2411.10446v2 by Daniel Ekpo, Mara Levy, Saksham Suri, Chuong Huynh, Abhinav Shrivastava

Recent advancements in vision-language models (VLMs) offer potential for
robot task planning, but challenges remain due to VLMs' tendency to generate
incorrect action sequences. To address these limitations, we propose VeriGraph,
a novel framework that integrates VLMs for robotic planning while verifying
action feasibility. VeriGraph employs scene graphs as an intermediate
representation, capturing key objects and spatial relationships to improve plan
verification and refinement. The system generates a scene graph from input
images and uses it to iteratively check and correct action sequences generated
by an LLM-based task planner, ensuring constraints are respected and actions
are executable. Our approach significantly enhances task completion rates
across diverse manipulation scenarios, outperforming baseline methods by 58%
for language-based tasks and 30% for image-based tasks.

摘要：視覺語言模型 (VLM) 的最新進展為機器人任務規劃提供了潛力，但由於 VLM 傾向於生成不正確的動作序列，因此仍存在挑戰。為了解決這些限制，我們提出了 VeriGraph，這是一個新穎的架構，它整合了 VLM 以進行機器人規劃，同時驗證動作的可行性。VeriGraph 使用場景圖作為中間表示，擷取關鍵物件和空間關係以改善計畫驗證和精煉。系統從輸入影像中生成場景圖，並使用它來反覆檢查和修正由基於 LLM 的任務規劃器產生的動作序列，確保遵守約束且動作可執行。我們的做法大幅提高了在各種操作場景中的任務完成率，在基於語言的任務中優於基線方法 58%，在基於影像的任務中優於 30%。

##### **A Survey of Event Causality Identification: Principles, Taxonomy, Challenges, and Assessment**
2411.10371v2 by Qing Cheng, Zefan Zeng, Xingchen Hu, Yuehang Si, Zhong Liu

Event Causality Identification (ECI) has become a crucial task in Natural
Language Processing (NLP), aimed at automatically extracting causalities from
textual data. In this survey, we systematically address the foundational
principles, technical frameworks, and challenges of ECI, offering a
comprehensive taxonomy to categorize and clarify current research
methodologies, as well as a quantitative assessment of existing models. We
first establish a conceptual framework for ECI, outlining key definitions,
problem formulations, and evaluation standards. Our taxonomy classifies ECI
methods according to the two primary tasks of sentence-level (SECI) and
document-level (DECI) event causality identification. For SECI, we examine
feature pattern-based matching, deep semantic encoding, causal knowledge
pre-training and prompt-based fine-tuning, and external knowledge enhancement
methods. For DECI, we highlight approaches focused on event graph reasoning and
prompt-based techniques to address the complexity of cross-sentence causal
inference. Additionally, we analyze the strengths, limitations, and open
challenges of each approach. We further conduct an extensive quantitative
evaluation of various ECI methods on two benchmark datasets. Finally, we
explore future research directions, highlighting promising pathways to overcome
current limitations and broaden ECI applications.

摘要：事件因果關係識別 (ECI) 已成為自然語言處理 (NLP) 中一項至關重要的任務，旨在從文本資料中自動萃取因果關係。在此調查中，我們系統性地探討 ECI 的基礎原理、技術架構和挑戰，提供一個全面的分類法來分類和釐清當前的研究方法，以及對現有模型的量化評估。我們首先為 ECI 建立一個概念框架，概述關鍵定義、問題表述和評估標準。我們的分類法根據句子層級 (SECI) 和文件層級 (DECI) 事件因果關係識別這兩個主要任務，對 ECI 方法進行分類。對於 SECI，我們檢視基於特徵模式的比對、深度語意編碼、因果知識預訓練和基於提示的微調，以及外部知識增強方法。對於 DECI，我們強調以事件圖推論和基於提示的技術為重點的方法，以解決跨句子因果推論的複雜性。此外，我們分析每種方法的優點、限制和開放性挑戰。我們進一步對各種 ECI 方法在兩個基準資料集上進行廣泛的量化評估。最後，我們探討未來的研究方向，強調有希望克服當前限制和擴展 ECI 應用程式的途徑。

##### **Prompting and Fine-tuning Large Language Models for Automated Code Review Comment Generation**
2411.10129v1 by Md. Asif Haider, Ayesha Binte Mostofa, Sk. Sabit Bin Mosaddek, Anindya Iqbal, Toufique Ahmed

Generating accurate code review comments remains a significant challenge due
to the inherently diverse and non-unique nature of the task output. Large
language models pretrained on both programming and natural language data tend
to perform well in code-oriented tasks. However, large-scale pretraining is not
always feasible due to its environmental impact and project-specific
generalizability issues. In this work, first we fine-tune open-source Large
language models (LLM) in parameter-efficient, quantized low-rank (QLoRA)
fashion on consumer-grade hardware to improve review comment generation. Recent
studies demonstrate the efficacy of augmenting semantic metadata information
into prompts to boost performance in other code-related tasks. To explore this
in code review activities, we also prompt proprietary, closed-source LLMs
augmenting the input code patch with function call graphs and code summaries.
Both of our strategies improve the review comment generation performance, with
function call graph augmented few-shot prompting on the GPT-3.5 model
surpassing the pretrained baseline by around 90% BLEU-4 score on the
CodeReviewer dataset. Moreover, few-shot prompted Gemini-1.0 Pro, QLoRA
fine-tuned Code Llama and Llama 3.1 models achieve competitive results (ranging
from 25% to 83% performance improvement) on this task. An additional human
evaluation study further validates our experimental findings, reflecting
real-world developers' perceptions of LLM-generated code review comments based
on relevant qualitative metrics.

摘要：<paragraph>產生準確的程式碼審查評論仍然是一個重大挑戰，因為任務輸出的本質上是多樣且非獨特的。在程式設計和自然語言資料上進行預訓練的大型語言模型往往在以程式碼為導向的任務中表現良好。然而，由於其對環境的影響和專案特定的一般化問題，大規模預訓練並非總是可行的。在這項工作中，我們首先在參數有效、量化的低秩 (QLoRA) 方式中微調開源大型語言模型 (LLM)，在消費級硬體上改善審查評論的產生。最近的研究證明了在提示中增加語義元資料資訊以提升其他與程式碼相關任務中效能的功效。為了在程式碼審查活動中探索這一點，我們也提示專有的、閉源 LLM，使用函數呼叫圖和程式碼摘要來增加輸入程式碼修補程式。我們的兩種策略都改善了審查評論產生的效能，在 GPT-3.5 模型上使用函數呼叫圖增加的少量提示，在 CodeReviewer 資料集上超越了預訓練基準，BLEU-4 分數提高了約 90%。此外，少量提示的 Gemini-1.0 Pro、QLoRA 微調的 Code Llama 和 Llama 3.1 模型在此任務上達到了有競爭力的結果（效能提升範圍為 25% 至 83%）。額外的使用者評估研究進一步驗證了我們的實驗結果，反映了實際開發人員對 LLM 產生的程式碼審查評論的看法，這些看法基於相關的定性指標。</paragraph>

##### **HistoLens: An LLM-Powered Framework for Multi-Layered Analysis of Historical Texts -- A Case Application of Yantie Lun**
2411.09978v1 by Yifan Zeng

This paper proposes HistoLens, a multi-layered analysis framework for
historical texts based on Large Language Models (LLMs). Using the important
Western Han dynasty text "Yantie Lun" as a case study, we demonstrate the
framework's potential applications in historical research and education.
HistoLens integrates NLP technology (especially LLMs), including named entity
recognition, knowledge graph construction, and geographic information
visualization. The paper showcases how HistoLens explores Western Han culture
in "Yantie Lun" through multi-dimensional, visual, and quantitative methods,
focusing particularly on the influence of Confucian and Legalist thoughts on
political, economic, military, and ethnic. We also demonstrate how HistoLens
constructs a machine teaching scenario using LLMs for explainable analysis,
based on a dataset of Confucian and Legalist ideas extracted with LLM
assistance. This approach offers novel and diverse perspectives for studying
historical texts like "Yantie Lun" and provides new auxiliary tools for history
education. The framework aims to equip historians and learners with
LLM-assisted tools to facilitate in-depth, multi-layered analysis of historical
texts and foster innovation in historical education.

摘要：本文提出 HistoLens，一個基於大型語言模型 (LLM) 的多層分析架構，用於歷史文本。使用重要的西漢王朝文本「鹽鐵論」作為個案研究，我們展示了該架構在歷史研究和教育中的潛在應用。HistoLens 整合了 NLP 技術（尤其是 LLM），包括命名實體識別、知識圖譜建構和地理資訊視覺化。本文展示了 HistoLens 如何透過多維度、視覺化和量化方法探索「鹽鐵論」中的西漢文化，特別關注儒家和法家思想對政治、經濟、軍事和種族的影響。我們還展示了 HistoLens 如何建構一個使用 LLM 的機器教學場景，以進行可解釋分析，這是基於 LLM 協助提取的儒家和法家思想資料集。這種方法為研究「鹽鐵論」等歷史文本提供了新穎且多樣化的觀點，並為歷史教育提供了新的輔助工具。該架構旨在為歷史學家和學習者提供 LLM 協助的工具，以利於深入、多層次地分析歷史文本，並促進歷史教育的創新。

##### **Accelerating Knowledge Graph and Ontology Engineering with Large Language Models**
2411.09601v1 by Cogan Shimizu, Pascal Hitzler

Large Language Models bear the promise of significant acceleration of key
Knowledge Graph and Ontology Engineering tasks, including ontology modeling,
extension, modification, population, alignment, as well as entity
disambiguation. We lay out LLM-based Knowledge Graph and Ontology Engineering
as a new and coming area of research, and argue that modular approaches to
ontologies will be of central importance.

摘要：大型語言模型承諾大幅加速關鍵知識圖譜和本体工程任務，包括本体建模、擴充、修改、填充、比對以及實體消歧。我們將 LLM 為基礎的知識圖譜和本体工程規劃為一個新興的研究領域，並主張模組化本体方法將至關重要。

##### **Automating Reformulation of Essence Specifications via Graph Rewriting**
2411.09576v1 by Ian Miguel, András Z. Salamon, Christopher Stone

Formulating an effective constraint model of a parameterised problem class is
crucial to the efficiency with which instances of the class can subsequently be
solved. It is difficult to know beforehand which of a set of candidate models
will perform best in practice. This paper presents a system that employs graph
rewriting to reformulate an input model for improved performance automatically.
By situating our work in the Essence abstract constraint specification
language, we can use the structure in its high level variable types to trigger
rewrites directly. We implement our system via rewrite rules expressed in the
Graph Programs 2 language, applied to the abstract syntax tree of an input
specification. We show how to automatically translate the solution of the
reformulated problem into a solution of the original problem for verification
and presentation. We demonstrate the efficacy of our system with a detailed
case study.

摘要：制定一個參數化問題類別的有效約束模型對於隨後求解該類別的實例的效率至關重要。事先很難知道一組候選模型中哪一個在實務上表現最佳。本文提出一個系統，採用圖形重寫來自動重新制定輸入模型以改善效能。透過將我們的工作置於 Essence 抽象約束規範語言中，我們可以使用其高層級變數類型中的結構來直接觸發重寫。我們透過以 Graph Programs 2 語言表示的重寫規則來實作我們的系統，應用於輸入規範的抽象語法樹。我們展示如何自動將重新制定問題的解法轉換為原始問題的解法，以進行驗證和呈現。我們透過詳細的個案研究來展示我們系統的效能。

##### **Towards Evaluating Large Language Models for Graph Query Generation**
2411.08449v2 by Siraj Munir, Alessandro Aldini

Large Language Models (LLMs) are revolutionizing the landscape of Generative
Artificial Intelligence (GenAI), with innovative LLM-backed solutions emerging
rapidly. However, when applied to database technologies, specifically query
generation for graph databases and Knowledge Graphs (KGs), LLMs still face
significant challenges. While research on LLM-driven query generation for
Structured Query Language (SQL) exists, similar systems for graph databases
remain underdeveloped. This paper presents a comparative study addressing the
challenge of generating Cypher queries a powerful language for interacting with
graph databases using open-access LLMs. We rigorously evaluate several LLM
agents (OpenAI ChatGPT 4o, Claude Sonnet 3.5, Google Gemini Pro 1.5, and a
locally deployed Llama 3.1 8B) using a designed few-shot learning prompt and
Retrieval Augmented Generation (RAG) backed by Chain-of-Thoughts (CoT)
reasoning. Our empirical analysis of query generation accuracy reveals that
Claude Sonnet 3.5 outperforms its counterparts in this specific domain.
Further, we highlight promising future research directions to address the
identified limitations and advance LLM-driven query generation for graph
databases.

摘要：大型語言模型 (LLM) 正在革新生成式人工智慧 (GenAI) 的領域，創新的 LLM 支持解決方案迅速湧現。然而，當應用於資料庫技術，特別是圖形資料庫和知識圖譜 (KG) 的查詢產生時，LLM 仍然面臨重大挑戰。雖然存在針對結構化查詢語言 (SQL) 的 LLM 驅動查詢產生的研究，但圖形資料庫的類似系統仍未充分發展。本文提出了一項比較研究，以解決使用開放式 LLM 產生 Cypher 查詢的挑戰，Cypher 查詢是一種用於與圖形資料庫互動的強大語言。我們使用設計的少量學習提示和由思想鏈 (CoT) 推理支持的檢索擴充生成 (RAG) 嚴格評估了多個 LLM 代理（OpenAI ChatGPT 4o、Claude Sonnet 3.5、Google Gemini Pro 1.5 和本地部署的 Llama 3.1 8B）。我們對查詢產生準確性的實證分析表明，Claude Sonnet 3.5 在這個特定領域優於其同類產品。此外，我們重點介紹了有希望的未來研究方向，以解決已識別的限制並推進 LLM 驅動的圖形資料庫查詢產生。

##### **Knowledge Bases in Support of Large Language Models for Processing Web News**
2411.08278v2 by Yihe Zhang, Nabin Pakka, Nian-Feng Tzeng

Large Language Models (LLMs) have received considerable interest in wide
applications lately. During pre-training via massive datasets, such a model
implicitly memorizes the factual knowledge of trained datasets in its hidden
parameters. However, knowledge held implicitly in parameters often makes its
use by downstream applications ineffective due to the lack of common-sense
reasoning. In this article, we introduce a general framework that permits to
build knowledge bases with an aid of LLMs, tailored for processing Web news.
The framework applies a rule-based News Information Extractor (NewsIE) to news
items for extracting their relational tuples, referred to as knowledge bases,
which are then graph-convoluted with the implicit knowledge facts of news items
obtained by LLMs, for their classification. It involves two lightweight
components: 1) NewsIE: for extracting the structural information of every news
item, in the form of relational tuples; 2) BERTGraph: for graph convoluting the
implicit knowledge facts with relational tuples extracted by NewsIE. We have
evaluated our framework under different news-related datasets for news category
classification, with promising experimental results.

摘要：大型語言模型 (LLM) 近來在廣泛的應用中備受關注。在透過大量資料集進行預訓練期間，此類模型會隱含地將訓練資料集的事實知識記憶在其隱藏參數中。然而，隱含在參數中的知識通常會因為缺乏常識推理而導致下游應用無法有效使用。在本文中，我們介紹了一個通用架構，允許在 LLM 的協助下建立知識庫，專門用於處理網路新聞。此架構將基於規則的新聞資訊萃取器 (NewsIE) 套用到新聞項目，以萃取其關係元組（稱為知識庫），然後將其與 LLM 取得的新聞項目的隱含知識事實進行圖形卷積，以進行分類。它包含兩個輕量級元件：1) NewsIE：用於萃取每個新聞項目的結構化資訊，以關係元組的形式呈現；2) BERTGraph：用於將 NewsIE 萃取的關係元組與隱含知識事實進行圖形卷積。我們已在不同的與新聞相關的資料集下評估我們的架構，用於新聞類別分類，並獲得有希望的實驗結果。

##### **Retrieval, Reasoning, Re-ranking: A Context-Enriched Framework for Knowledge Graph Completion**
2411.08165v1 by Muzhi Li, Cehao Yang, Chengjin Xu, Xuhui Jiang, Yiyan Qi, Jian Guo, Ho-fung Leung, Irwin King

The Knowledge Graph Completion~(KGC) task aims to infer the missing entity
from an incomplete triple. Existing embedding-based methods rely solely on
triples in the KG, which is vulnerable to specious relation patterns and
long-tail entities. On the other hand, text-based methods struggle with the
semantic gap between KG triples and natural language. Apart from triples,
entity contexts (e.g., labels, descriptions, aliases) also play a significant
role in augmenting KGs. To address these limitations, we propose KGR3, a
context-enriched framework for KGC. KGR3 is composed of three modules. Firstly,
the Retrieval module gathers supporting triples from the KG, collects plausible
candidate answers from a base embedding model, and retrieves context for each
related entity. Then, the Reasoning module employs a large language model to
generate potential answers for each query triple. Finally, the Re-ranking
module combines candidate answers from the two modules mentioned above, and
fine-tunes an LLM to provide the best answer. Extensive experiments on widely
used datasets demonstrate that KGR3 consistently improves various KGC methods.
Specifically, the best variant of KGR3 achieves absolute Hits@1 improvements of
12.3% and 5.6% on the FB15k237 and WN18RR datasets.

摘要：知識圖譜完成功能 (KGC) 的任務旨在從不完整的 3 元組中推斷出遺失的實體。現有的嵌入式方法僅依賴於 KG 中的 3 元組，這容易受到虛假關係模式和長尾實體的影響。另一方面，基於文本的方法難以處理 KG 3 元組和自然語言之間的語義差距。除了 3 元組之外，實體上下文（例如標籤、描述、別名）在擴充 KG 中也扮演著重要的角色。為了解決這些限制，我們提出了 KGR3，一個用於 KGC 的上下文豐富架構。KGR3 由三個模組組成。首先，檢索模組從 KG 中收集支援 3 元組，從基礎嵌入模型中收集可能的候選答案，並為每個相關實體檢索上下文。接著，推理模組採用大型語言模型為每個查詢 3 元組生成潛在答案。最後，重新排名模組將上述兩個模組的候選答案結合起來，並微調 LLM 以提供最佳答案。在廣泛使用的資料集上進行的廣泛實驗證明，KGR3 持續改進各種 KGC 方法。具體來說，KGR3 的最佳變體在 FB15k237 和 WN18RR 資料集上分別實現了 12.3% 和 5.6% 的絕對 Hits@1 改進。

##### **Language Models as Causal Effect Generators**
2411.08019v1 by Lucius E. J. Bynum, Kyunghyun Cho

We present a framework for large language model (LLM) based data generation
with controllable causal structure. In particular, we define a procedure for
turning any language model and any directed acyclic graph (DAG) into a
sequence-driven structural causal model (SD-SCM). Broadly speaking, an SD-SCM
is a causal model with user-defined structure and LLM-defined structural
equations. We characterize how an SD-SCM allows sampling from observational,
interventional, and counterfactual distributions according to the desired
causal structure. We then leverage this procedure to propose a new type of
benchmark for causal inference methods, generating individual-level
counterfactual data without needing to manually specify functional
relationships between variables. We create an example benchmark consisting of
thousands of datasets, and test a suite of popular estimation methods on these
datasets for average, conditional average, and individual treatment effect
estimation, both with and without hidden confounding. Apart from generating
data, the same procedure also allows us to test for the presence of a causal
effect that might be encoded in an LLM. This procedure can underpin auditing
LLMs for misinformation, discrimination, or otherwise undesirable behavior. We
believe SD-SCMs can serve as a useful tool in any application that would
benefit from sequential data with controllable causal structure.

摘要：<paragraph>我們提出了一個基於大型語言模型 (LLM) 的資料生成架構，具有可控制的因果結構。具體來說，我們定義了一個程序，將任何語言模型和任何有向無環圖 (DAG) 轉換成一個序列驅動的結構因果模型 (SD-SCM)。廣義來說，SD-SCM 是一個因果模型，具有使用者定義的結構和 LLM 定義的結構方程式。我們描述了 SD-SCM 如何根據所需的因果結構，允許從觀測、介入和反事實分佈中進行抽樣。然後，我們利用這個程序提出了一種類型的因果推論方法基準，生成個體層級的反事實資料，而無需手動指定變數之間的功能關係。我們建立了一個範例基準，包含數千個資料集，並在這些資料集上測試了一系列流行的估計方法，用於平均值、條件平均值和個別處理效果估計，無論是有或沒有隱藏混淆。除了生成資料之外，相同的程序也允許我們測試 LLM 中可能編碼的因果效應的存在。此程序可以支持審核 LLM 的錯誤資訊、歧視或其他不良行為。我們相信 SD-SCM 可以作為任何應用程式的有用工具，這些應用程式可以從具有可控制因果結構的序列資料中受益。</paragraph>

##### **From General to Specific: Utilizing General Hallucination to Benchmark Specific Role-Playing Agents**
2411.07965v2 by Chuyi Kong, Ziyang Luo, Hongzhan Lin, Zhiyuan Fan, Yaxin Fan, Yuxi Sun, Jing Ma

The advanced role-playing capabilities of Large Language Models (LLMs) have
paved the way for developing Role-Playing Agents (RPAs). However, existing
benchmarks in this domain, such as HPD and SocialBench face limitations like
poor generalizability, implicit and inaccurate judgments, and the risk of model
forgetting. To address the above issues, we propose an automatic, scalable, and
generalizable paradigm. Specifically, we construct a benchmark, SHARP, by
extracting relations from a general knowledge graph and leveraging the inherent
hallucination properties of RPAs to simulate interactions across roles. We
employ ChatGPT for stance detection and define relationship hallucination along
with three related metrics based on stance transfer. Extensive experiments
validate the effectiveness and stability of our paradigm. Our findings further
explore the factors influencing these metrics and discuss the trade-off between
blind loyalty to relationships and adherence to facts in RPAs.

摘要：大型語言模型 (LLM) 的進階角色扮演能力已為角色扮演代理 (RPA) 的開發鋪平道路。然而，此領域現有的基準，例如 HPD 和 SocialBench，面臨著概括性差、判斷隱含且不準確，以及模型遺忘的風險等限制。為了解決上述問題，我們提出了一個自動化、可擴充且可概括的範例。具體來說，我們通過從一般知識圖譜中提取關係，並利用 RPA 固有的幻覺特性來模擬跨角色互動，構建了一個基準 SHARP。我們採用 ChatGPT 進行立場檢測，並定義關係幻覺以及基於立場轉移的三個相關指標。廣泛的實驗驗證了我們範例的有效性和穩定性。我們的發現進一步探討了影響這些指標的因素，並討論了 RPA 中對關係的盲目忠誠度與對事實的堅持之間的權衡。

##### **Chain Association-based Attacking and Shielding Natural Language Processing Systems**
2411.07843v1 by Jiacheng Huang, Long Chen

Association as a gift enables people do not have to mention something in
completely straightforward words and allows others to understand what they
intend to refer to. In this paper, we propose a chain association-based
adversarial attack against natural language processing systems, utilizing the
comprehension gap between humans and machines. We first generate a chain
association graph for Chinese characters based on the association paradigm for
building search space of potential adversarial examples. Then, we introduce an
discrete particle swarm optimization algorithm to search for the optimal
adversarial examples. We conduct comprehensive experiments and show that
advanced natural language processing models and applications, including large
language models, are vulnerable to our attack, while humans appear good at
understanding the perturbed text. We also explore two methods, including
adversarial training and associative graph-based recovery, to shield systems
from chain association-based attack. Since a few examples that use some
derogatory terms, this paper contains materials that may be offensive or
upsetting to some people.

摘要：聯想作為一種禮物，使人們不必用完全直白的話語提及某事，並讓其他人明白他們想提的是什麼。在本文中，我們提出了一種基於鏈式聯想的對抗性攻擊，用於自然語言處理系統，利用了人類與機器之間的理解差距。我們首先基於聯想範例為漢字生成一個鏈式聯想圖，用於構建潛在對抗性範例的搜索空間。然後，我們引入一個離散粒子群優化演算法來搜索最佳的對抗性範例。我們進行了全面的實驗，並表明先進的自然語言處理模型和應用程式，包括大型語言模型，都容易受到我們的攻擊，而人類似乎很擅長理解擾動後的文字。我們還探索了兩種方法，包括對抗性訓練和基於聯想圖的恢復，以保護系統免受基於鏈式聯想的攻擊。由於一些範例使用了某些貶義詞，因此本文包含可能冒犯或令某些人感到不安的材料。

##### **Gradual Fine-Tuning with Graph Routing for Multi-Source Unsupervised Domain Adaptation**
2411.07185v1 by Yao Ma, Samuel Louvan, Zhunxuan Wang

Multi-source unsupervised domain adaptation aims to leverage labeled data
from multiple source domains for training a machine learning model to
generalize well on a target domain without labels. Source domain selection
plays a crucial role in determining the model's performance. It relies on the
similarities amongst source and target domains. Nonetheless, existing work for
source domain selection often involves heavyweight computational procedures,
especially when dealing with numerous source domains and the need to identify
the best ones from them. In this paper, we introduce a framework for gradual
fine tuning (GFT) of machine learning models on multiple source domains. We
represent multiple source domains as an undirected weighted graph. We then give
a new generalization error bound for GFT along any path within the graph, which
is used to determine the optimal path corresponding to the optimal training
order. With this formulation, we introduce three lightweight graph-routing
strategies which tend to minimize the error bound. Our best strategy improves
$2.3\%$ of accuracy over the state-of-the-art on Natural Language Inference
(NLI) task and achieves competitive performance on Sentiment Analysis (SA)
task, especially a $3.9\%$ improvement on a more diverse subset of data we use
for SA.

摘要：多源无监督域自适应旨在利用来自多个源域的标记数据，训练机器学习模型，以便在没有标签的目标域上很好地泛化。源域选择在确定模型性能方面起着至关重要的作用。它依赖于源域和目标域之间的相似性。尽管如此，现有的源域选择工作通常涉及重量级计算程序，尤其是在处理众多源域以及需要从中识别最佳源域时。在本文中，我们介绍了一个在多个源域上对机器学习模型进行逐步微调 (GFT) 的框架。我们将多个源域表示为无向加权图。然后，我们为图中沿任何路径的 GFT 给出了一个新的泛化误差界，用于确定对应于最佳训练顺序的最佳路径。通过这种表述，我们介绍了三种轻量级的图路由策略，这些策略倾向于最小化误差界。我们最好的策略在自然语言推理 (NLI) 任务上比最先进的技术提高了 2.3% 的准确率，并在情感分析 (SA) 任务上取得了有竞争力的性能，特别是在我们用于 SA 的更多样化的数据子集上提高了 3.9%。

##### **A Domain-Agnostic Neurosymbolic Approach for Big Social Data Analysis: Evaluating Mental Health Sentiment on Social Media during COVID-19**
2411.07163v1 by Vedant Khandelwal, Manas Gaur, Ugur Kursuncu, Valerie Shalin, Amit Sheth

Monitoring public sentiment via social media is potentially helpful during
health crises such as the COVID-19 pandemic. However, traditional
frequency-based, data-driven neural network-based approaches can miss newly
relevant content due to the evolving nature of language in a dynamically
evolving environment. Human-curated symbolic knowledge sources, such as
lexicons for standard language and slang terms, can potentially elevate social
media signals in evolving language. We introduce a neurosymbolic method that
integrates neural networks with symbolic knowledge sources, enhancing the
detection and interpretation of mental health-related tweets relevant to
COVID-19. Our method was evaluated using a corpus of large datasets
(approximately 12 billion tweets, 2.5 million subreddit data, and 700k news
articles) and multiple knowledge graphs. This method dynamically adapts to
evolving language, outperforming purely data-driven models with an F1 score
exceeding 92\%. This approach also showed faster adaptation to new data and
lower computational demands than fine-tuning pre-trained large language models
(LLMs). This study demonstrates the benefit of neurosymbolic methods in
interpreting text in a dynamic environment for tasks such as health
surveillance.

摘要：透過社群媒體監控公眾情緒在 COVID-19 等健康危機期間可能很有幫助。然而，傳統的基於頻率、資料驅動的神經網路方法可能會錯過新相關的內容，因為語言在動態演化的環境中會持續演化。由人類策劃的象徵性知識來源（例如標準語言和俚語術語的詞彙）可能會提升社群媒體在演化語言中的訊號。我們引入一種將神經網路與象徵性知識來源整合的神經符號方法，增強與 COVID-19 相關的心理健康相關推文的偵測和詮釋。我們的做法使用大型資料集語料庫（約 120 億則推文、250 萬個 subreddit 資料和 70 萬則新聞文章）和多個知識圖譜進行評估。這種方法動態適應演化的語言，優於純資料驅動模型，F1 分數超過 92%。這種方法也顯示出比微調預訓練大型語言模型 (LLM) 更快適應新資料和更低的運算需求。本研究證明了神經符號方法在動態環境中詮釋文字的優點，適用於健康監控等任務。

##### **A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs**
2411.07098v1 by Myeongsoo Kim, Tyler Stennett, Saurabh Sinha, Alessandro Orso

As modern web services increasingly rely on REST APIs, their thorough testing
has become crucial. Furthermore, the advent of REST API specifications such as
the OpenAPI Specification has led to the emergence of many black-box REST API
testing tools. However, these tools often focus on individual test elements in
isolation (e.g., APIs, parameters, values), resulting in lower coverage and
less effectiveness in detecting faults (i.e., 500 response codes). To address
these limitations, we present AutoRestTest, the first black-box framework to
adopt a dependency-embedded multi-agent approach for REST API testing,
integrating Multi-Agent Reinforcement Learning (MARL) with a Semantic Property
Dependency Graph (SPDG) and Large Language Models (LLMs). Our approach treats
REST API testing as a separable problem, where four agents -- API, dependency,
parameter, and value -- collaborate to optimize API exploration. LLMs handle
domain-specific value restrictions, the SPDG model simplifies the search space
for dependencies using a similarity score between API operations, and MARL
dynamically optimizes the agents' behavior. Evaluated on 12 real-world REST
services, AutoRestTest outperforms the four leading black-box REST API testing
tools, including those assisted by RESTGPT (which augments realistic test
inputs using LLMs), in terms of code coverage, operation coverage, and fault
detection. Notably, AutoRestTest is the only tool able to identify an internal
server error in Spotify. Our ablation study underscores the significant
contributions of the agent learning, SPDG, and LLM components.

摘要：<paragraph>隨著現代網路服務日益依賴 REST API，其徹底的測試變得至關重要。此外，REST API 規範（例如 OpenAPI 規範）的出現，導致許多黑盒 REST API 測試工具的出現。然而，這些工具通常專注於單獨的測試元素（例如 API、參數、值），導致覆蓋率較低，且在偵測錯誤（即 500 回應碼）方面效率較低。為了解決這些限制，我們提出 AutoRestTest，這是第一個採用依賴嵌入式多代理方法進行 REST API 測試的黑盒框架，將多代理強化學習 (MARL) 與語義屬性依賴圖 (SPDG) 和大型語言模型 (LLM) 整合在一起。我們的做法將 REST API 測試視為一個可分離的問題，其中四個代理（API、依賴關係、參數和值）協同合作以最佳化 API 探索。LLM 處理特定領域的值限制，SPDG 模型使用 API 操作之間的相似性分數簡化依賴關係的搜尋空間，而 MARL 則動態最佳化代理的行為。在 12 項真實世界的 REST 服務上進行評估，AutoRestTest 在程式碼覆蓋率、操作覆蓋率和錯誤偵測方面，優於四種領先的黑盒 REST API 測試工具，包括那些由 RESTGPT（使用 LLM 增加逼真的測試輸入）輔助的工具。值得注意的是，AutoRestTest 是唯一能夠識別 Spotify 中內部伺服器錯誤的工具。我們的消融研究強調了代理學習、SPDG 和 LLM 組件的重大貢獻。</paragraph>

##### **Bridge: A Unified Framework to Knowledge Graph Completion via Language Models and Knowledge Representation**
2411.06660v1 by Qiao Qiao, Yuepei Li, Qing Wang, Kang Zhou, Qi Li

Knowledge graph completion (KGC) is a task of inferring missing triples based
on existing Knowledge Graphs (KGs). Both structural and semantic information
are vital for successful KGC. However, existing methods only use either the
structural knowledge from the KG embeddings or the semantic information from
pre-trained language models (PLMs), leading to suboptimal model performance.
Moreover, since PLMs are not trained on KGs, directly using PLMs to encode
triples may be inappropriate. To overcome these limitations, we propose a novel
framework called Bridge, which jointly encodes structural and semantic
information of KGs. Specifically, we strategically encode entities and
relations separately by PLMs to better utilize the semantic knowledge of PLMs
and enable structured representation learning via a structural learning
principle. Furthermore, to bridge the gap between KGs and PLMs, we employ a
self-supervised representation learning method called BYOL to fine-tune PLMs
with two different views of a triple. Unlike BYOL, which uses augmentation
methods to create two semantically similar views of the same image, potentially
altering the semantic information. We strategically separate the triple into
two parts to create different views, thus avoiding semantic alteration.
Experiments demonstrate that Bridge outperforms the SOTA models on three
benchmark datasets.

摘要：知識圖譜補全 (KGC) 是一項根據現有知識圖譜 (KG) 推論遺失三元組的任務。結構和語義資訊對於成功的 KGC 至關重要。然而，現有方法僅使用來自 KG 嵌入的結構知識或來自預訓練語言模型 (PLM) 的語義資訊，導致模型效能不佳。此外，由於 PLM 沒有在 KG 上訓練，因此直接使用 PLM 編碼三元組可能並不適當。為了克服這些限制，我們提出一個名為 Bridge 的新架構，該架構聯合編碼 KG 的結構和語義資訊。具體來說，我們透過 PLM 分別對實體和關係進行策略性編碼，以更好地利用 PLM 的語義知識，並透過結構學習原則啟用結構化表示學習。此外，為了彌合 KG 和 PLM 之間的差距，我們採用一種稱為 BYOL 的自監督表示學習方法，以三元組的兩個不同視圖微調 PLM。與 BYOL 不同，BYOL 使用擴充方法來建立兩個語義上相似的相同影像視圖，可能會改變語義資訊。我們策略性地將三元組分為兩部分以建立不同的視圖，從而避免語義改變。實驗證明 Bridge 在三個基準資料集上優於 SOTA 模型。

##### **CausalStock: Deep End-to-end Causal Discovery for News-driven Stock Movement Prediction**
2411.06391v1 by Shuqi Li, Yuebo Sun, Yuxin Lin, Xin Gao, Shuo Shang, Rui Yan

There are two issues in news-driven multi-stock movement prediction tasks
that are not well solved in the existing works. On the one hand, "relation
discovery" is a pivotal part when leveraging the price information of other
stocks to achieve accurate stock movement prediction. Given that stock
relations are often unidirectional, such as the "supplier-consumer"
relationship, causal relations are more appropriate to capture the impact
between stocks. On the other hand, there is substantial noise existing in the
news data leading to extracting effective information with difficulty. With
these two issues in mind, we propose a novel framework called CausalStock for
news-driven multi-stock movement prediction, which discovers the temporal
causal relations between stocks. We design a lag-dependent temporal causal
discovery mechanism to model the temporal causal graph distribution. Then a
Functional Causal Model is employed to encapsulate the discovered causal
relations and predict the stock movements. Additionally, we propose a Denoised
News Encoder by taking advantage of the excellent text evaluation ability of
large language models (LLMs) to extract useful information from massive news
data. The experiment results show that CausalStock outperforms the strong
baselines for both news-driven multi-stock movement prediction and multi-stock
movement prediction tasks on six real-world datasets collected from the US,
China, Japan, and UK markets. Moreover, getting benefit from the causal
relations, CausalStock could offer a clear prediction mechanism with good
explainability.

摘要：<paragraph>在新聞驅動的多股票移動預測任務中，現有研究尚未妥善解決兩個問題。一方面，在利用其他股票的價格資訊來實現準確的股票移動預測時，「關係發現」是一個關鍵部分。由於股票關係通常是單向的，例如「供應商-消費者」關係，因此因果關係更適合捕捉股票之間的影響。另一方面，新聞資料中存在大量雜訊，導致難以提取有效資訊。考慮到這兩個問題，我們提出了一個名為 CausalStock 的新框架，用於新聞驅動的多股票移動預測，該框架發現了股票之間的時序因果關係。我們設計了一個延遲依賴的時序因果發現機制，以建模時序因果圖分布。然後採用功能因果模型來封裝發現的因果關係並預測股票走勢。此外，我們提出了一個去噪新聞編碼器，利用大型語言模型 (LLM) 出色的文本評估能力從大量新聞資料中提取有用資訊。實驗結果表明，CausalStock 在從美國、中國、日本和英國市場收集的六個真實世界資料集上，在新聞驅動的多股票移動預測和多股票移動預測任務中都優於強大的基線。此外，CausalStock 受益於因果關係，可以提供具有良好可解釋性的清晰預測機制。</paragraph>

##### **Analyzing the Evolution of Graphs and Texts**
2411.06295v1 by Xingzhi Guo

With the recent advance of representation learning algorithms on graphs
(e.g., DeepWalk/GraphSage) and natural languages (e.g., Word2Vec/BERT) , the
state-of-the art models can even achieve human-level performance over many
downstream tasks, particularly for the task of node and sentence
classification. However, most algorithms focus on large-scale models for static
graphs and text corpus without considering the inherent dynamic characteristics
or discovering the reasons behind the changes. This dissertation aims to
efficiently model the dynamics in graphs (such as social networks and citation
graphs) and understand the changes in texts (specifically news titles and
personal biographies). To achieve this goal, we utilize the renowned
Personalized PageRank algorithm to create effective dynamic network embeddings
for evolving graphs. Our proposed approaches significantly improve the running
time and accuracy for both detecting network abnormal intruders and discovering
entity meaning shifts over large-scale dynamic graphs. For text changes, we
analyze the post-publication changes in news titles to understand the intents
behind the edits and discuss the potential impact of titles changes from
information integrity perspective. Moreover, we investigate self-presented
occupational identities in Twitter users' biographies over five years,
investigating job prestige and demographics effects in how people disclose
jobs, quantifying over-represented jobs and their transitions over time.

摘要：隨著圖形表示學習演算法的最新進展（例如 DeepWalk/GraphSage）和自然語言（例如 Word2Vec/BERT），最先進的模型甚至可以在許多下游任務中達到人類等級的效能，特別是對於節點和句子分類的任務。然而，大多數演算法都專注於靜態圖形和大規模文字語料庫的模型，而沒有考慮固有的動態特性或找出變化的原因。本論文旨在有效地為圖形（例如社群網路和引文圖形）建模動態，並了解文字的變化（特別是新聞標題和個人傳記）。為了達成這個目標，我們利用著名的 Personalized PageRank 演算法為不斷變化的圖形建立有效的動態網路嵌入。我們提出的方法顯著改善了偵測網路異常入侵者和找出大規模動態圖形中實體含義轉移的執行時間和準確度。對於文字變化的部分，我們分析了新聞標題在出版後的變化，以了解編輯背後的意圖，並討論標題變更對資訊完整性的潛在影響。此外，我們調查了 Twitter 使用者在傳記中呈現的職業身分長達五年，探討了工作聲望和人口統計資料對人們揭露工作的影響，並量化了過度代表的工作及其隨著時間推移的轉變。

##### **An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models**
2411.06048v1 by Fatemeh Shiri, Xiao-Yu Guo, Mona Golestan Far, Xin Yu, Gholamreza Haffari, Yuan-Fang Li

Large Multimodal Models (LMMs) have achieved strong performance across a
range of vision and language tasks. However, their spatial reasoning
capabilities are under-investigated. In this paper, we construct a novel VQA
dataset, Spatial-MM, to comprehensively study LMMs' spatial understanding and
reasoning capabilities. Our analyses on object-relationship and multi-hop
reasoning reveal several important findings. Firstly, bounding boxes and scene
graphs, even synthetic ones, can significantly enhance LMMs' spatial reasoning.
Secondly, LMMs struggle more with questions posed from the human perspective
than the camera perspective about the image. Thirdly, chain of thought (CoT)
prompting does not improve model performance on complex multi-hop questions
involving spatial relations. % Moreover, spatial reasoning steps are much less
accurate than non-spatial ones across MLLMs. Lastly, our perturbation analysis
on GQA-spatial reveals that LMMs are much stronger at basic object detection
than complex spatial reasoning. We believe our benchmark dataset and in-depth
analyses can spark further research on LMMs spatial reasoning. Spatial-MM
benchmark is available at: https://github.com/FatemehShiri/Spatial-MM

摘要：大型多模態模型 (LMM) 已在各種視覺和語言任務中取得強勁的表現。然而，它們的空間推理能力尚未得到充分研究。在本文中，我們構建了一個新穎的 VQA 資料集 Spatial-MM，以全面研究 LMM 的空間理解和推理能力。我們對物件關係和多跳推理的分析揭示了幾個重要的發現。首先，邊界框和場景圖，即使是合成的，也可以顯著增強 LMM 的空間推理能力。其次，LMM 在回答從人類視角提出的問題時比從相機視角提出的問題時遇到更多困難。第三，思考鏈 (CoT) 提示並未改善模型在涉及空間關係的複雜多跳問題上的效能。% 此外，在 MLLM 中，空間推理步驟的準確度遠低於非空間步驟。最後，我們對 GQA-spatial 的擾動分析表明，LMM 在基本物件偵測方面的能力遠強於複雜的空間推理。我們相信我們的基準資料集和深入分析可以激發對 LMM 空間推理的進一步研究。Spatial-MM 基準可在以下網址取得：https://github.com/FatemehShiri/Spatial-MM

##### **Mitigating Hallucination with ZeroG: An Advanced Knowledge Management Engine**
2411.05936v1 by Anantha Sharma, Sheeba Elizabeth John, Fatemeh Rezapoor Nikroo, Krupali Bhatt, Mrunal Zambre, Aditi Wikhe

The growth of digital documents presents significant challenges in efficient
management and knowledge extraction. Traditional methods often struggle with
complex documents, leading to issues such as hallucinations and high latency in
responses from Large Language Models (LLMs). ZeroG, an innovative approach,
significantly mitigates these challenges by leveraging knowledge distillation
and prompt tuning to enhance model performance.
  ZeroG utilizes a smaller model that replicates the behavior of a larger
teacher model, ensuring contextually relevant and grounded responses, by
employing a black-box distillation approach, it creates a distilled dataset
without relying on intermediate features, optimizing computational efficiency.
This method significantly enhances accuracy and reduces response times,
providing a balanced solution for modern document management.
  Incorporating advanced techniques for document ingestion and metadata
utilization, ZeroG improves the accuracy of question-and-answer systems. The
integration of graph databases and robust metadata management further
streamlines information retrieval, allowing for precise and context-aware
responses. By transforming how organizations interact with complex data, ZeroG
enhances productivity and user experience, offering a scalable solution for the
growing demands of digital document management.

摘要：數位文件成長帶來顯著的挑戰，包括有效管理和知識萃取。傳統方法經常難以處理複雜文件，導致問題，例如產生幻覺和大型語言模型 (LLM) 回應的高延遲。ZeroG 是一種創新的方法，透過利用知識蒸餾和提示調整來增強模型效能，大幅減輕這些挑戰。
ZeroG 使用較小的模型複製較大的教師模型的行為，透過採用黑盒蒸餾方法，確保在脈絡上相關且有根據的回應，它建立一個蒸餾的資料集，而不需要依賴中間特徵，最佳化運算效率。這種方法大幅提升準確度並減少回應時間，提供現代文件管理的平衡解決方案。
透過整合進階技術來擷取文件和使用元資料，ZeroG 改善問答系統的準確度。圖形資料庫和強健的元資料管理的整合進一步簡化資訊擷取，允許精確且符合脈絡的回應。透過轉換組織與複雜資料互動的方式，ZeroG 提升生產力和使用者體驗，提供可擴充的解決方案，以滿足數位文件管理日益增長的需求。

##### **SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark**
2411.05521v2 by Sithursan Sivasubramaniam, Cedric Osei-Akoto, Yi Zhang, Kurt Stockinger, Jonathan Fuerst

Electronic health records (EHRs) are stored in various database systems with
different database models on heterogeneous storage architectures, such as
relational databases, document stores, or graph databases. These different
database models have a big impact on query complexity and performance. While
this has been a known fact in database research, its implications for the
growing number of Text-to-Query systems have surprisingly not been investigated
so far. In this paper, we present SM3-Text-to-Query, the first multi-model
medical Text-to-Query benchmark based on synthetic patient data from Synthea,
following the SNOMED-CT taxonomy -- a widely used knowledge graph ontology
covering medical terminology. SM3-Text-to-Query provides data representations
for relational databases (PostgreSQL), document stores (MongoDB), and graph
databases (Neo4j and GraphDB (RDF)), allowing the evaluation across four
popular query languages, namely SQL, MQL, Cypher, and SPARQL. We systematically
and manually develop 408 template questions, which we augment to construct a
benchmark of 10K diverse natural language question/query pairs for these four
query languages (40K pairs overall). On our dataset, we evaluate several common
in-context-learning (ICL) approaches for a set of representative closed and
open-source LLMs. Our evaluation sheds light on the trade-offs between database
models and query languages for different ICL strategies and LLMs. Last,
SM3-Text-to-Query is easily extendable to additional query languages or real,
standard-based patient databases.

摘要：電子健康記錄 (EHR) 儲存在具有不同資料庫模型的各種資料庫系統中，採用異質儲存架構，例如關聯式資料庫、文件儲存庫或圖形資料庫。這些不同的資料庫模型對查詢複雜度和效能有很大的影響。雖然這在資料庫研究中是一個已知的事實，但其對越來越多的文字轉查詢系統的影響卻令人驚訝地尚未被研究。在本文中，我們提出 SM3-Text-to-Query，這是第一個基於 Synthea 合成患者資料的多模型醫療文字轉查詢基準，遵循 SNOMED-CT 分類法，這是一個廣泛使用的知識圖形本體，涵蓋醫學術語。SM3-Text-to-Query 提供了關係資料庫 (PostgreSQL)、文件儲存庫 (MongoDB) 和圖形資料庫 (Neo4j 和 GraphDB (RDF)) 的資料表示，允許跨四種流行的查詢語言進行評估，即 SQL、MQL、Cypher 和 SPARQL。我們系統且手動開發了 408 個範本問題，並擴充這些問題以建構一個基準，其中包含 10K 個針對這四種查詢語言的多樣化自然語言問題/查詢配對（總共 40K 個配對）。在我們的資料集上，我們評估了一組代表性的封閉和開放原始碼 LLM 的幾個常見情境學習 (ICL) 方法。我們的評估揭示了不同 ICL 策略和 LLM 的資料庫模型和查詢語言之間的權衡。最後，SM3-Text-to-Query 可以輕鬆擴充到其他查詢語言或真實的、基於標準的患者資料庫。

##### **EUREKHA: Enhancing User Representation for Key Hackers Identification in Underground Forums**
2411.05479v1 by Abdoul Nasser Hassane Amadou, Anas Motii, Saida Elouardi, EL Houcine Bergou

Underground forums serve as hubs for cybercriminal activities, offering a
space for anonymity and evasion of conventional online oversight. In these
hidden communities, malicious actors collaborate to exchange illicit knowledge,
tools, and tactics, driving a range of cyber threats from hacking techniques to
the sale of stolen data, malware, and zero-day exploits. Identifying the key
instigators (i.e., key hackers), behind these operations is essential but
remains a complex challenge. This paper presents a novel method called EUREKHA
(Enhancing User Representation for Key Hacker Identification in Underground
Forums), designed to identify these key hackers by modeling each user as a
textual sequence. This sequence is processed through a large language model
(LLM) for domain-specific adaptation, with LLMs acting as feature extractors.
These extracted features are then fed into a Graph Neural Network (GNN) to
model user structural relationships, significantly improving identification
accuracy. Furthermore, we employ BERTopic (Bidirectional Encoder
Representations from Transformers Topic Modeling) to extract personalized
topics from user-generated content, enabling multiple textual representations
per user and optimizing the selection of the most representative sequence. Our
study demonstrates that fine-tuned LLMs outperform state-of-the-art methods in
identifying key hackers. Additionally, when combined with GNNs, our model
achieves significant improvements, resulting in approximately 6% and 10%
increases in accuracy and F1-score, respectively, over existing methods.
EUREKHA was tested on the Hack-Forums dataset, and we provide open-source
access to our code.

摘要：<paragraph>地下論壇是網路犯罪活動的樞紐，提供匿名和規避傳統網路監督的空間。在這些隱藏的社群中，惡意行為者合作交換非法知識、工具和策略，推動從駭客技術到銷售竊取資料、惡意軟體和零時差漏洞的各種網路威脅。找出這些行動背後的關鍵煽動者（即關鍵駭客）至關重要，但仍然是一個複雜的挑戰。本文提出了一種稱為 EUREKHA（增強使用者表徵以識別地下論壇中的關鍵駭客）的新方法，旨在透過將每個使用者建模為文字序列來識別這些關鍵駭客。此序列透過大型語言模型（LLM）處理以進行特定領域的適應，其中 LLM 作為特徵萃取器。然後將這些萃取的特徵輸入圖神經網路（GNN）以建模使用者結構關係，大幅提升識別準確度。此外，我們採用 BERTopic（來自 Transformer 主題建模的雙向編碼器表徵）從使用者產生的內容中萃取個人化主題，為每個使用者啟用多個文字表徵，並最佳化最具代表性序列的選擇。我們的研究表明，微調後的 LLM 在識別關鍵駭客方面優於最先進的方法。此外，當與 GNN 結合使用時，我們的模型獲得顯著的提升，與現有方法相比，準確度和 F1 分數分別提高了約 6% 和 10%。EUREKHA 已在 Hack-Forums 資料集上進行測試，我們提供開源方式存取我們的程式碼。</paragraph>

##### **When are 1.58 bits enough? A Bottom-up Exploration of BitNet Quantization**
2411.05882v1 by Jacob Nielsen, Lukas Galke, Peter Schneider-Kamp

Contemporary machine learning models, such as language models, are powerful,
but come with immense resource requirements both at training and inference
time. It has been shown that decoder-only language models can be trained to a
competitive state with ternary weights (1.58 bits per weight), facilitating
efficient inference. Here, we start our exploration with non-transformer model
architectures, investigating 1.58-bit training for multi-layer perceptrons and
graph neural networks. Then, we explore 1.58-bit training in other
transformer-based language models, namely encoder-only and encoder-decoder
models. Our results show that in all of these settings, 1.58-bit training is on
par with or sometimes even better than the standard 32/16-bit models.

摘要：當代機器學習模型（例如語言模型）功能強大，
但在訓練和推論時間上都需要大量的資源。已經證明，僅解碼器語言模型可以用三元權重（每個權重 1.58 位元）訓練到競爭狀態，促進有效率的推論。在此，我們從非Transformer模型架構開始探討，研究多層感知器和圖神經網路的 1.58 位元訓練。接著，我們探討其他基於Transformer的語言模型（即僅編碼器和編碼器-解碼器模型）的 1.58 位元訓練。我們的結果顯示，在所有這些設定中，1.58 位元訓練與標準 32/16 位元模型相當，有時甚至更好。

##### **Exploring the Alignment Landscape: LLMs and Geometric Deep Models in Protein Representation**
2411.05316v1 by Dong Shu, Bingbing Duan, Kai Guo, Kaixiong Zhou, Jiliang Tang, Mengnan Du

Latent representation alignment has become a foundational technique for
constructing multimodal large language models (MLLM) by mapping embeddings from
different modalities into a shared space, often aligned with the embedding
space of large language models (LLMs) to enable effective cross-modal
understanding. While preliminary protein-focused MLLMs have emerged, they have
predominantly relied on heuristic approaches, lacking a fundamental
understanding of optimal alignment practices across representations. In this
study, we explore the alignment of multimodal representations between LLMs and
Geometric Deep Models (GDMs) in the protein domain. We comprehensively evaluate
three state-of-the-art LLMs (Gemma2-2B, LLaMa3.1-8B, and LLaMa3.1-70B) with
four protein-specialized GDMs (GearNet, GVP, ScanNet, GAT). Our work examines
alignment factors from both model and protein perspectives, identifying
challenges in current alignment methodologies and proposing strategies to
improve the alignment process. Our key findings reveal that GDMs incorporating
both graph and 3D structural information align better with LLMs, larger LLMs
demonstrate improved alignment capabilities, and protein rarity significantly
impacts alignment performance. We also find that increasing GDM embedding
dimensions, using two-layer projection heads, and fine-tuning LLMs on
protein-specific data substantially enhance alignment quality. These strategies
offer potential enhancements to the performance of protein-related multimodal
models. Our code and data are available at
https://github.com/Tizzzzy/LLM-GDM-alignment.

摘要：潛在表徵對齊已成為建構多模態大型語言模型 (MLLM) 的基礎技術，方法是將不同模態的嵌入映射到共享空間中，通常與大型語言模型 (LLM) 的嵌入空間對齊，以實現有效的跨模態理解。雖然初步以蛋白質為重點的 MLLM 已出現，但它們主要依賴啟發式方法，缺乏對跨表徵最佳對齊實務的基本理解。在本研究中，我們探討了蛋白質領域中 LLM 與幾何深度模型 (GDM) 之間的多模態表徵對齊。我們全面評估了三個最先進的 LLM（Gemma2-2B、LLaMa3.1-8B 和 LLaMa3.1-70B）與四個蛋白質專用 GDM（GearNet、GVP、ScanNet、GAT）。我們的研究從模型和蛋白質角度檢視對齊因素，識別當前對齊方法的挑戰，並提出改善對齊程序的策略。我們的關鍵發現顯示，同時包含圖形和 3D 結構資訊的 GDM 與 LLM 的對齊效果較佳，較大的 LLM 展現出更佳的對齊能力，而蛋白質的稀有性顯著影響對齊效能。我們還發現，增加 GDM 嵌入維度、使用兩層投影頭，以及針對蛋白質特定資料微調 LLM，可以大幅提升對齊品質。這些策略為蛋白質相關多模態模型的效能提供潛在的強化。我們的程式碼和資料可在 https://github.com/Tizzzzy/LLM-GDM-alignment 取得。

##### **AMSnet-KG: A Netlist Dataset for LLM-based AMS Circuit Auto-Design Using Knowledge Graph RAG**
2411.13560v1 by Yichen Shi, Zhuofu Tao, Yuhao Gao, Tianjia Zhou, Cheng Chang, Yaxing Wang, Bingyu Chen, Genhao Zhang, Alvin Liu, Zhiping Yu, Ting-Jung Lin, Lei He

High-performance analog and mixed-signal (AMS) circuits are mainly
full-custom designed, which is time-consuming and labor-intensive. A
significant portion of the effort is experience-driven, which makes the
automation of AMS circuit design a formidable challenge. Large language models
(LLMs) have emerged as powerful tools for Electronic Design Automation (EDA)
applications, fostering advancements in the automatic design process for
large-scale AMS circuits. However, the absence of high-quality datasets has led
to issues such as model hallucination, which undermines the robustness of
automatically generated circuit designs. To address this issue, this paper
introduces AMSnet-KG, a dataset encompassing various AMS circuit schematics and
netlists. We construct a knowledge graph with annotations on detailed
functional and performance characteristics. Facilitated by AMSnet-KG, we
propose an automated AMS circuit generation framework that utilizes the
comprehensive knowledge embedded in LLMs. We first formulate a design strategy
(e.g., circuit architecture using a number of circuit components) based on
required specifications. Next, matched circuit components are retrieved and
assembled into a complete topology, and transistor sizing is obtained through
Bayesian optimization. Simulation results of the netlist are fed back to the
LLM for further topology refinement, ensuring the circuit design specifications
are met. We perform case studies of operational amplifier and comparator design
to verify the automatic design flow from specifications to netlists with
minimal human effort. The dataset used in this paper will be open-sourced upon
publishing of this paper.

摘要：高性能類比與混合訊號 (AMS) 電路主要為全客製化設計，這相當耗時且費工。其中很大一部分的工作仰賴經驗，這讓 AMS 電路設計的自動化成為一項艱鉅的挑戰。大型語言模型 (LLM) 已成為電子設計自動化 (EDA) 應用程式強大的工具，促進大規模 AMS 電路自動設計流程的進展。然而，缺乏高品質的資料集導致模型出現幻覺等問題，這損害了自動產生電路設計的穩健性。為了解決此問題，本文介紹了 AMSnet-KG，這是一個包含各種 AMS 電路原理圖和網路清單的資料集。我們建立了一個包含詳細功能和效能特徵註解的知識圖譜。在 AMSnet-KG 的協助下，我們提出了一個自動化 AMS 電路產生架構，它利用了內嵌在 LLM 中的全面知識。我們首先根據所需規格制定設計策略（例如使用多個電路元件的電路架構）。接著，擷取匹配的電路元件並組裝成一個完整的拓撲，並透過貝氏最佳化取得電晶體尺寸。網路清單的模擬結果會回饋給 LLM 以進一步優化拓撲，確保電路設計規格得到滿足。我們執行運算放大器和比較器設計的個案研究，以驗證從規格到網路清單的自動設計流程，並將人為介入降到最低。本文中使用的資料集將在本文發布後開源。

##### **LEGO-GraphRAG: Modularizing Graph-based Retrieval-Augmented Generation for Design Space Exploration**
2411.05844v1 by Yukun Cao, Zengyi Gao, Zhiyang Li, Xike Xie, S Kevin Zhou

GraphRAG addresses significant challenges in Retrieval-Augmented Generation
(RAG) by leveraging graphs with embedded knowledge to enhance the reasoning
capabilities of Large Language Models (LLMs). Despite its promising potential,
the GraphRAG community currently lacks a unified framework for fine-grained
decomposition of the graph-based knowledge retrieval process. Furthermore,
there is no systematic categorization or evaluation of existing solutions
within the retrieval process. In this paper, we present LEGO-GraphRAG, a
modular framework that decomposes the retrieval process of GraphRAG into three
interconnected modules: subgraph-extraction, path-filtering, and
path-refinement. We systematically summarize and classify the algorithms and
neural network (NN) models relevant to each module, providing a clearer
understanding of the design space for GraphRAG instances. Additionally, we
identify key design factors, such as Graph Coupling and Computational Cost,
that influence the effectiveness of GraphRAG implementations. Through extensive
empirical studies, we construct high-quality GraphRAG instances using a
representative selection of solutions and analyze their impact on retrieval and
reasoning performance. Our findings offer critical insights into optimizing
GraphRAG instance design, ultimately contributing to the advancement of more
accurate and contextually relevant LLM applications.

摘要：GraphRAG 透過利用具嵌入知識的圖表來增強大型語言模型 (LLM) 的推理能力，解決了檢索增強生成 (RAG) 中的重大挑戰。儘管具有令人期待的潛力，但 GraphRAG 社群目前缺乏一個統一的架構，用於對基於圖表的知識檢索過程進行細粒度的分解。此外，在檢索過程中，現有解決方案並未進行系統性的分類或評估。在本文中，我們提出了 LEGO-GraphRAG，這是一個模組化架構，將 GraphRAG 的檢索過程分解為三個相互連接的模組：子圖萃取、路徑過濾和路徑精煉。我們系統性地總結和分類與每個模組相關的演算法和神經網路 (NN) 模型，提供對 GraphRAG 實例設計空間的更清晰理解。此外，我們找出影響 GraphRAG 實作有效性的關鍵設計因素，例如圖表耦合和運算成本。透過廣泛的經驗研究，我們使用具代表性的解決方案選擇來建構高品質的 GraphRAG 實例，並分析它們對檢索和推理效能的影響。我們的研究結果提供了優化 GraphRAG 實例設計的重要見解，最終有助於推進更準確且與脈絡相關的 LLM 應用。

##### **MEG: Medical Knowledge-Augmented Large Language Models for Question Answering**
2411.03883v2 by Laura Cabello, Carmen Martin-Turrero, Uchenna Akujuobi, Anders Søgaard, Carlos Bobed

Question answering is a natural language understanding task that involves
reasoning over both explicit context and unstated, relevant domain knowledge.
Large language models (LLMs), which underpin most contemporary question
answering systems, struggle to induce how concepts relate in specialized
domains such as medicine. Existing medical LLMs are also costly to train. In
this work, we present MEG, a parameter-efficient approach for medical
knowledge-augmented LLMs. MEG uses a lightweight mapping network to integrate
graph embeddings into the LLM, enabling it to leverage external knowledge in a
cost-effective way. We evaluate our method on four popular medical
multiple-choice datasets and show that LLMs greatly benefit from the factual
grounding provided by knowledge graph embeddings. MEG attains an average of
+10.2% accuracy over the Mistral-Instruct baseline, and +6.7% over specialized
models like BioMistral. We also show results based on Llama-3. Finally, we show
that MEG's performance remains robust to the choice of graph encoder.

摘要：問答是自然語言理解任務，涉及對明確的上下文和未說明的相關領域知識進行推理。支撐大多數當代問答系統的大型語言模型 (LLM) 難以推論概念如何在醫學等專業領域中關聯。現有的醫學 LLM 訓練成本也很高。在這項工作中，我們提出了 MEG，這是一種用於醫學知識增強 LLM 的參數有效方法。MEG 使用輕量級映射網路將圖表嵌入整合到 LLM 中，使其能夠以經濟有效的方式利用外部知識。我們在四個流行的醫學多選題資料集上評估了我們的方法，並表明 LLM 從知識圖表嵌入提供的實際依據中受益匪淺。MEG 在 Mistral-Instruct 基準上平均提高了 +10.2% 的準確度，在 BioMistral 等專門模型上提高了 +6.7%。我們還展示了基於 Llama-3 的結果。最後，我們表明 MEG 的性能對圖表編碼器的選擇保持穩健。

##### **A Library Perspective on Supervised Text Processing in Digital Libraries: An Investigation in the Biomedical Domain**
2411.12752v1 by Hermann Kroll, Pascal Sackhoff, Bill Matthias Thang, Maha Ksouri, Wolf-Tilo Balke

Digital libraries that maintain extensive textual collections may want to
further enrich their content for certain downstream applications, e.g.,
building knowledge graphs, semantic enrichment of documents, or implementing
novel access paths. All of these applications require some text processing,
either to identify relevant entities, extract semantic relationships between
them, or to classify documents into some categories. However, implementing
reliable, supervised workflows can become quite challenging for a digital
library because suitable training data must be crafted, and reliable models
must be trained. While many works focus on achieving the highest accuracy on
some benchmarks, we tackle the problem from a digital library practitioner. In
other words, we also consider trade-offs between accuracy and application
costs, dive into training data generation through distant supervision and large
language models such as ChatGPT, LLama, and Olmo, and discuss how to design
final pipelines. Therefore, we focus on relation extraction and text
classification, using the showcase of eight biomedical benchmarks.

摘要：維護廣泛文本集合的數位圖書館可能希望進一步豐富其內容以供特定下游應用程式使用，例如建構知識圖譜、文件語意豐富化或實作新穎的存取路徑。所有這些應用程式都需要一些文字處理，才能識別相關實體、萃取它們之間的語意關係，或將文件分類到某些類別中。然而，對於數位圖書館來說，實作可靠的監督式工作流程可能會變得相當具有挑戰性，因為必須建立適當的訓練資料，並訓練可靠的模型。雖然許多研究專注於在某些基準上達成最高準確度，但我們從數位圖書館實務者的角度來解決這個問題。換句話說，我們也考慮準確度和應用成本之間的權衡，深入探討透過遠距監督和大型語言模型（例如 ChatGPT、LLama 和 Olmo）來產生訓練資料，並討論如何設計最終管線。因此，我們專注於關係萃取和文字分類，並使用八個生物醫學基準作為展示案例。

##### **The American Sign Language Knowledge Graph: Infusing ASL Models with Linguistic Knowledge**
2411.03568v1 by Lee Kezar, Nidhi Munikote, Zian Zeng, Zed Sehyr, Naomi Caselli, Jesse Thomason

Language models for American Sign Language (ASL) could make language
technologies substantially more accessible to those who sign. To train models
on tasks such as isolated sign recognition (ISR) and ASL-to-English
translation, datasets provide annotated video examples of ASL signs. To
facilitate the generalizability and explainability of these models, we
introduce the American Sign Language Knowledge Graph (ASLKG), compiled from
twelve sources of expert linguistic knowledge. We use the ASLKG to train
neuro-symbolic models for 3 ASL understanding tasks, achieving accuracies of
91% on ISR, 14% for predicting the semantic features of unseen signs, and 36%
for classifying the topic of Youtube-ASL videos.

摘要：美國手語 (ASL) 的語言模型可以讓語言技術對手語使用者更易於使用。為了訓練模型執行手語辨識 (ISR) 和 ASL 轉換成英文等任務，資料集提供 ASL 手勢的註解影片範例。為了促進這些模型的概括性和可解釋性，我們引入了美國手語知識圖譜 (ASLKG)，它是由十二個專家語言知識來源編譯而成的。我們使用 ASLKG 訓練神經符號模型來執行 3 項 ASL 理解任務，在 ISR 上達到 91% 的準確度、在預測未見手勢的語義特徵上達到 14%，以及在分類 YouTube-ASL 影片主題上達到 36%。

##### **Graph-DPEP: Decomposed Plug and Ensemble Play for Few-Shot Document Relation Extraction with Graph-of-Thoughts Reasoning**
2411.02864v1 by Tao Zhang, Ning Yan, Masood Mortazavi, Hoang H. Nguyen, Zhongfen Deng, Philip S. Yu

Large language models (LLMs) pre-trained on massive corpora have demonstrated
impressive few-shot learning capability on many NLP tasks. Recasting an NLP
task into a text-to-text generation task is a common practice so that
generative LLMs can be prompted to resolve it. However, performing
document-level relation extraction (DocRE) tasks with generative LLM models is
still challenging due to the structured output format of DocRE, which
complicates the conversion to plain text. Limited information available in
few-shot samples and prompt instructions induce further difficulties and
challenges in relation extraction for mentioned entities in a document. In this
paper, we represent the structured output as a graph-style triplet rather than
natural language expressions and leverage generative LLMs for the DocRE task.
Our approach, the Graph-DPEP framework is grounded in the reasoning behind
triplet explanation thoughts presented in natural language. In this framework,
we first introduce a ``decomposed-plug" method for performing the generation
from LLMs over prompts with type-space decomposition to alleviate the burden of
distinguishing all relation types. Second, we employ a verifier for calibrating
the generation and identifying overlooked query entity pairs. Third, we develop
"ensemble-play", reapplying generation on the entire type list by leveraging
the reasoning thoughts embedded in a sub-graph associated with the missing
query pair to address the missingness issue. Through extensive comparisons with
existing prompt techniques and alternative Language Models (LLMs), our
framework demonstrates superior performance on publicly available benchmarks in
experiments.

摘要：大型語言模型 (LLM) 在海量語料庫上預先訓練，已在許多自然語言處理任務上展現出令人印象深刻的少量樣本學習能力。將自然語言處理任務轉化為文字到文字的生成任務是一種常見做法，這樣生成式大型語言模型就可以提示解決它。然而，由於 DocRE 的結構化輸出格式，使用生成式大型語言模型來執行文件級別關係萃取 (DocRE) 任務仍然具有挑戰性，這使得轉換為純文字變得複雜。少量樣本和提示說明中可用的資訊有限，會導致在文件中提到實體的關係萃取中產生進一步的困難和挑戰。在本文中，我們將結構化輸出表示為圖形樣式的三元組，而不是自然語言表達，並利用生成式大型語言模型來執行 DocRE 任務。我們的做法，圖形 DPEP 框架，是基於自然語言中呈現的三元組解釋思想背後的推理。在這個框架中，我們首先介紹一種「分解插入」方法，用於對具有類型空間分解的提示進行大型語言模型生成，以減輕區分所有關係類型的負擔。其次，我們使用驗證器來校準生成並識別被忽略的查詢實體對。第三，我們開發「整體遊戲」，通過利用與遺失查詢對相關的子圖中嵌入的推理思想，在整個類型列表上重新應用生成，以解決遺失問題。通過與現有提示技術和替代語言模型 (LLM) 的廣泛比較，我們的框架在實驗中證明了在公開基準上的優異性能。

##### **Multimodal Commonsense Knowledge Distillation for Visual Question Answering**
2411.02722v1 by Shuo Yang, Siwen Luo, Soyeon Caren Han

Existing Multimodal Large Language Models (MLLMs) and Visual Language
Pretrained Models (VLPMs) have shown remarkable performances in the general
Visual Question Answering (VQA). However, these models struggle with VQA
questions that require external commonsense knowledge due to the challenges in
generating high-quality prompts and the high computational costs of
fine-tuning. In this work, we propose a novel graph-based multimodal
commonsense knowledge distillation framework that constructs a unified
relational graph over commonsense knowledge, visual objects and questions
through a Graph Convolutional Network (GCN) following a teacher-student
environment. This proposed framework is flexible with any type of teacher and
student models without further fine-tuning, and has achieved competitive
performances on the ScienceQA dataset.

摘要：現有的多模態大型語言模型 (MLLM) 和視覺語言預訓練模型 (VLPM) 在一般的視覺問答 (VQA) 中展現了卓越的表現。然而，這些模型在需要外部常識知識的 VQA 問題上會遇到困難，原因在於產生高品質提示的挑戰以及微調的高運算成本。在這項工作中，我們提出了一個新穎的基於圖形的模態常識知識萃取架構，透過圖形卷積網路 (GCN) 在常識知識、視覺物件和問題上建構一個統一的關聯圖形，遵循師生環境。這個提出的架構對於任何類型的教師和學生模型都具有彈性，無需進一步微調，並在 ScienceQA 資料集上取得了有競爭力的表現。

##### **Geometry of orofacial neuromuscular signals: speech articulation decoding using surface electromyography**
2411.02591v2 by Harshavardhana T. Gowda, Zachary D. McNaughton, Lee M. Miller

Each year, millions of individuals lose the ability to speak intelligibly due
to causes such as neuromuscular disease, stroke, trauma, and head/neck cancer
surgery (e.g. laryngectomy) or treatment (e.g. radiotherapy toxicity to the
speech articulators). Effective communication is crucial for daily activities,
and losing the ability to speak leads to isolation, depression, anxiety, and a
host of detrimental sequelae. Noninvasive surface electromyography (sEMG) has
shown promise to restore speech output in these individuals. The goal is to
collect sEMG signals from multiple articulatory sites as people silently
produce speech and then decode the signals to enable fluent and natural
communication. Currently, many fundamental properties of orofacial
neuromuscular signals relating to speech articulation remain unanswered. They
include questions relating to 1) the data structure of the orofacial sEMG
signals, 2)the signal distribution shift of sEMG across individuals, 3) ability
of sEMG signals to span the entire English language phonetic space during
silent speech articulations, and 4) the generalization capability of
non-invasive sEMG based silent speech interfaces. We address these questions
through a series of experiments involving healthy human subjects. We show that
sEMG signals evince graph data structure and that the signal distribution shift
is given by a change of basis. Furthermore, we show that silently voiced
articulations spanning the entire English language phonetic space can be
decoded using small neural networks which can be trained with little data and
that such architectures work well across individuals. To ensure transparency
and reproducibility, we open-source all the data and codes used in this study.

摘要：每年，數百萬人因神經肌肉疾病、中風、創傷、頭頸癌手術（例如喉切除術）或治療（例如放射治療對言語構音器官的毒性）而失去清晰說話的能力。有效的溝通對於日常活動至關重要，而失去說話的能力會導致孤立、沮喪、焦慮和一系列有害的後遺症。非侵入性表面肌電圖 (sEMG) 已顯示出恢復這些人說話輸出的希望。目標是從多個構音部位收集 sEMG 信號，因為人們在無聲地發音，然後解碼信號以實現流利而自然的溝通。目前，許多與言語構音有關的面部神經肌肉信號的基本特性仍未得到解答。它們包括與 1) 面部 sEMG 信號的數據結構、2) sEMG 在個人之間的信號分佈轉移、3) sEMG 信號在無聲言語構音過程中跨越整個英語語音空間的能力以及 4) 基於非侵入性 sEMG 的無聲言語介面的泛化能力相關的問題。我們通過一系列涉及健康人類受試者的實驗來解決這些問題。我們表明 sEMG 信號表現出圖數據結構，並且信號分佈轉移是由基變化的給出的。此外，我們表明，使用可以通過少量數據訓練的小神經網路可以解碼跨越整個英語語音空間的無聲發音，並且這種架構在不同個體之間都能很好地工作。為了確保透明度和可複製性，我們公開了本研究中使用的所有數據和代碼。

##### **GraphXAIN: Narratives to Explain Graph Neural Networks**
2411.02540v2 by Mateusz Cedro, David Martens

Graph Neural Networks (GNNs) are a powerful technique for machine learning on
graph-structured data, yet they pose interpretability challenges, especially
for non-expert users. Existing GNN explanation methods often yield technical
outputs such as subgraphs and feature importance scores, which are not easily
understood. Building on recent insights from social science and other
Explainable AI (XAI) methods, we propose GraphXAIN, a natural language
narrative that explains individual predictions made by GNNs. We present a
model-agnostic and explainer-agnostic XAI approach that complements graph
explainers by generating GraphXAINs, using Large Language Models (LLMs) and
integrating graph data, individual predictions from GNNs, explanatory
subgraphs, and feature importances. We define XAI Narratives and XAI
Descriptions, highlighting their distinctions and emphasizing the importance of
narrative principles in effective explanations. By incorporating natural
language narratives, our approach supports graph practitioners and non-expert
users, aligning with social science research on explainability and enhancing
user understanding and trust in complex GNN models. We demonstrate GraphXAIN's
capabilities on a real-world graph dataset, illustrating how its generated
narratives can aid understanding compared to traditional graph explainer
outputs or other descriptive explanation methods.

摘要：圖形神經網路 (GNN) 是用於圖形結構資料的機器學習強大技術，但它們會造成可解釋性挑戰，特別是對於非專家使用者。現有的 GNN 解釋方法通常會產生技術輸出，例如子圖和特徵重要性分數，這些輸出不容易理解。建構於社會科學和其他可解釋 AI (XAI) 方法的最新見解，我們提出 GraphXAIN，這是一種自然語言敘述，可以解釋 GNN 做出的個別預測。我們提出一個與模型無關且與解釋器無關的 XAI 方法，它透過使用大型語言模型 (LLM) 和整合圖形資料、GNN 的個別預測、說明性子圖和特徵重要性來補充圖形解釋器，進而產生 GraphXAIN。我們定義 XAI 敘述和 XAI 描述，強調它們的區別，並強調敘述原則在有效解釋中的重要性。透過結合自然語言敘述，我們的做法支援圖形從業者和非專家使用者，與可解釋性的社會科學研究保持一致，並增強使用者對複雜 GNN 模型的理解和信任。我們在真實世界圖形資料集上展示 GraphXAIN 的功能，說明與傳統圖形解釋器輸出或其他描述性解釋方法相比，其產生的敘述如何有助於理解。

##### **Improving Scientific Hypothesis Generation with Knowledge Grounded Large Language Models**
2411.02382v1 by Guangzhi Xiong, Eric Xie, Amir Hassan Shariatmadari, Sikun Guo, Stefan Bekiranov, Aidong Zhang

Large language models (LLMs) have demonstrated remarkable capabilities in
various scientific domains, from natural language processing to complex
problem-solving tasks. Their ability to understand and generate human-like text
has opened up new possibilities for advancing scientific research, enabling
tasks such as data analysis, literature review, and even experimental design.
One of the most promising applications of LLMs in this context is hypothesis
generation, where they can identify novel research directions by analyzing
existing knowledge. However, despite their potential, LLMs are prone to
generating ``hallucinations'', outputs that are plausible-sounding but
factually incorrect. Such a problem presents significant challenges in
scientific fields that demand rigorous accuracy and verifiability, potentially
leading to erroneous or misleading conclusions. To overcome these challenges,
we propose KG-CoI (Knowledge Grounded Chain of Ideas), a novel system that
enhances LLM hypothesis generation by integrating external, structured
knowledge from knowledge graphs (KGs). KG-CoI guides LLMs through a structured
reasoning process, organizing their output as a chain of ideas (CoI), and
includes a KG-supported module for the detection of hallucinations. With
experiments on our newly constructed hypothesis generation dataset, we
demonstrate that KG-CoI not only improves the accuracy of LLM-generated
hypotheses but also reduces the hallucination in their reasoning chains,
highlighting its effectiveness in advancing real-world scientific research.

摘要：大型語言模型 (LLM) 已在各種科學領域展現卓越的能力，從自然語言處理到複雜的解決問題任務。它們理解和產生類似人類文字的能力為推進科學研究開啟了新的可能性，讓資料分析、文獻回顧，甚至實驗設計等任務成為可能。LLM 在此脈絡中最有希望的應用之一是假設產生，它們能透過分析現有知識來找出新的研究方向。然而，儘管 LLM 具有潛力，它們卻容易產生「幻覺」，也就是聽起來合理但事實上不正確的輸出。此類問題在需要嚴謹準確性和可驗證性的科學領域中會造成重大挑戰，有可能導致錯誤或誤導性的結論。為了克服這些挑戰，我們提出 KG-CoI（知識基礎觀念鏈），這是一個創新的系統，它透過整合知識圖譜 (KG) 中的外部結構化知識來增強 LLM 假設產生。KG-CoI 引導 LLM 進行結構化推理程序，將其輸出整理成觀念鏈 (CoI)，並包含一個由 KG 支援的模組來偵測幻覺。透過我們新建立的假設產生資料集進行的實驗，我們證明 KG-CoI 不僅改善了 LLM 產生的假設的準確性，也減少了其推理鏈中的幻覺，突顯了其在推進現實世界科學研究中的效能。

##### **QCG-Rerank: Chunks Graph Rerank with Query Expansion in Retrieval-Augmented LLMs for Tourism Domain**
2411.08724v1 by Qikai Wei, Mingzhi Yang, Chunlong Han, Jingfu Wei, Minghao Zhang, Feifei Shi, Huansheng Ning

Retrieval-Augmented Generation (RAG) mitigates the issue of hallucination in
Large Language Models (LLMs) by integrating information retrieval techniques.
However, in the tourism domain, since the query is usually brief and the
content in the database is diverse, existing RAG may contain a significant
amount of irrelevant or contradictory information contents after retrieval. To
address this challenge, we propose the QCG-Rerank model. This model first
performs an initial retrieval to obtain candidate chunks and then enhances
semantics by extracting critical information to expand the original query.
Next, we utilize the expanded query and candidate chunks to calculate
similarity scores as the initial transition probability and construct the
chunks graph. Subsequently, We iteratively compute the transition probabilities
based on an initial estimate until convergence. The chunks with the highest
score are selected and input into the LLMs to generate responses. We evaluate
the model on Cultour, IIRC, StrategyQA, HotpotQA, SQuAD, and MuSiQue datasets.
The experimental results demonstrate the effectiveness and superiority of the
QCG-Rerank method.

摘要：擷取增強生成（RAG）透過整合資訊擷取技術來緩解大型語言模型（LLM）中的幻覺問題。然而，在旅遊領域中，由於查詢通常很簡短，而資料庫中的內容多樣，因此現有的 RAG 可能會在擷取後包含大量不相關或矛盾的資訊內容。為了應對這個挑戰，我們提出了 QCG-Rerank 模型。此模型首先執行初始擷取以取得候選區塊，然後透過擷取關鍵資訊來擴充原始查詢以增強語意。接著，我們利用擴充的查詢和候選區塊來計算相似度分數作為初始轉移機率，並建構區塊圖。隨後，我們根據初始估計反覆計算轉移機率，直到收斂。會選取分數最高的區塊，並輸入到 LLM 以產生回應。我們在 Cultour、IIRC、StrategyQA、HotpotQA、SQuAD 和 MuSiQue 資料集上評估此模型。實驗結果證明了 QCG-Rerank 方法的有效性和優越性。

##### **Can Language Models Enable In-Context Database?**
2411.01807v1 by Yu Pan, Hongfeng Yu, Tianjiao Zhao, Jianxin Sun

Large language models (LLMs) are emerging as few-shot learners capable of
handling a variety of tasks, including comprehension, planning, reasoning,
question answering, arithmetic calculations, and more. At the core of these
capabilities is LLMs' proficiency in representing and understanding structural
or semi-structural data, such as tables and graphs. Numerous studies have
demonstrated that reasoning on tabular data or graphs is not only feasible for
LLMs but also gives a promising research direction which treats these data as
in-context data. The lightweight and human readable characteristics of
in-context database can potentially make it an alternative for the traditional
database in typical RAG (Retrieval Augmented Generation) settings. However,
almost all current work focuses on static in-context data, which does not allow
dynamic update. In this paper, to enable dynamic database update, delta
encoding of database is proposed. We explore how data stored in traditional
RDBMS can be encoded as in-context text and evaluate LLMs' proficiency for CRUD
(Create, Read, Update and Delete) operations on in-context databases. A
benchmark named InConDB is presented and extensive experiments are conducted to
show the performance of different language models in enabling in-context
database by varying the database encoding method, prompting method, operation
type and input data distribution, revealing both the proficiency and
limitations.

摘要：大型語言模型 (LLM) 逐漸成為僅需少量範例就能處理各種任務的學習者，包括理解、規劃、推理、問答、算術計算等。這些能力的核心是 LLM 在表示和理解結構化或半結構化資料（例如表格和圖形）方面的能力。許多研究已證明，LLM 不僅可以推論表格資料或圖形，還提供了一個有前景的研究方向，將這些資料視為語境資料。語境資料庫的輕量級和人類可讀取特性有可能使其成為典型 RAG（檢索擴充生成）設定中傳統資料庫的替代方案。然而，幾乎所有目前的工作都專注於靜態語境資料，這不允許動態更新。在本文中，為了實現動態資料庫更新，提出了資料庫的 delta 編碼。我們探討了如何將儲存在傳統 RDBMS 中的資料編碼為語境文字，並評估 LLM 在語境資料庫上進行 CRUD（建立、讀取、更新和刪除）操作的能力。提出了名為 InConDB 的基準，並進行了廣泛的實驗，以顯示不同語言模型在通過改變資料庫編碼方法、提示方法、操作類型和輸入資料分佈來啟用語境資料庫方面的效能，揭示了能力和限制。

##### **Graph-based Confidence Calibration for Large Language Models**
2411.02454v1 by Yukun Li, Sijia Wang, Lifu Huang, Li-Ping Liu

One important approach to improving the reliability of large language models
(LLMs) is to provide accurate confidence estimations regarding the correctness
of their answers. However, developing a well-calibrated confidence estimation
model is challenging, as mistakes made by LLMs can be difficult to detect. We
propose a novel method combining the LLM's self-consistency with labeled data
and training an auxiliary model to estimate the correctness of its responses to
questions. This auxiliary model predicts the correctness of responses based
solely on their consistent information. To set up the learning problem, we use
a weighted graph to represent the consistency among the LLM's multiple
responses to a question. Correctness labels are assigned to these responses
based on their similarity to the correct answer. We then train a graph neural
network to estimate the probability of correct responses. Experiments
demonstrate that the proposed approach substantially outperforms several of the
most recent methods in confidence calibration across multiple widely adopted
benchmark datasets. Furthermore, the proposed approach significantly improves
the generalization capability of confidence calibration on out-of-domain (OOD)
data.

摘要：一種改善大型語言模型 (LLM) 可靠性的重要方法是提供有關其答案正確性的準確信心估計。然而，開發一個校準良好的信心估計模型具有挑戰性，因為 LLM 所犯的錯誤可能難以偵測。我們提出一個新方法，結合 LLM 的自我一致性與標籤資料，並訓練一個輔助模型來估計其對問題的回應正確性。這個輔助模型僅根據其一致性資訊來預測回應的正確性。為了設定學習問題，我們使用一個加權圖形來表示 LLM 對一個問題的多次回應之間的一致性。正確性標籤會根據這些回應與正確答案的相似性分配給這些回應。然後，我們訓練一個圖形神經網路來估計正確回應的機率。實驗證明，所提出的方法在多個廣泛採用的基準資料集上，在信心校準方面明顯優於多種最新方法。此外，所提出的方法顯著改善了在領域外 (OOD) 資料上信心校準的泛化能力。

##### **Ontology Population using LLMs**
2411.01612v1 by Sanaz Saki Norouzi, Adrita Barua, Antrea Christou, Nikita Gautam, Andrew Eells, Pascal Hitzler, Cogan Shimizu

Knowledge graphs (KGs) are increasingly utilized for data integration,
representation, and visualization. While KG population is critical, it is often
costly, especially when data must be extracted from unstructured text in
natural language, which presents challenges, such as ambiguity and complex
interpretations. Large Language Models (LLMs) offer promising capabilities for
such tasks, excelling in natural language understanding and content generation.
However, their tendency to ``hallucinate'' can produce inaccurate outputs.
Despite these limitations, LLMs offer rapid and scalable processing of natural
language data, and with prompt engineering and fine-tuning, they can
approximate human-level performance in extracting and structuring data for KGs.
This study investigates LLM effectiveness for the KG population, focusing on
the Enslaved.org Hub Ontology. In this paper, we report that compared to the
ground truth, LLM's can extract ~90% of triples, when provided a modular
ontology as guidance in the prompts.

摘要：知識圖譜 (KG) 愈來愈多用於資料整合、表示和視覺化。儘管 KG 填充至關重要，但它通常很昂貴，特別是在必須從自然語言中非結構化文字中提取資料時，這會帶來挑戰，例如歧義和複雜的詮釋。大型語言模型 (LLM) 為此類任務提供了有前景的能力，擅長自然語言理解和內容生成。然而，它們「產生幻覺」的傾向可能會產生不準確的輸出。儘管有這些限制，LLM 提供了自然語言資料的快速且可擴充處理，並且透過提示工程和微調，它們可以近似人類層級的效能，以提取和建構 KG 的資料。本研究調查 LLM 對 KG 填充的有效性，重點關注 Enslaved.org Hub Ontology。在本文中，我們報告與真實情況相比，當在提示中提供模組化本体作為指導時，LLM 可以提取約 90% 的三元組。

##### **Pre-trained Molecular Language Models with Random Functional Group Masking**
2411.01401v1 by Tianhao Peng, Yuchen Li, Xuhong Li, Jiang Bian, Zeke Xie, Ning Sui, Shahid Mumtaz, Yanwu Xu, Linghe Kong, Haoyi Xiong

Recent advancements in computational chemistry have leveraged the power of
trans-former-based language models, such as MoLFormer, pre-trained using a vast
amount of simplified molecular-input line-entry system (SMILES) sequences, to
understand and predict molecular properties and activities, a critical step in
fields like drug discovery and materials science. To further improve
performance, researchers have introduced graph neural networks with graph-based
molecular representations, such as GEM, incorporating the topology, geometry,
2D or even 3D structures of molecules into pre-training. While most of
molecular graphs in existing studies were automatically converted from SMILES
sequences, it is to assume that transformer-based language models might be able
to implicitly learn structure-aware representations from SMILES sequences. In
this paper, we propose \ours{} -- a SMILES-based \underline{\em M}olecular
\underline{\em L}anguage \underline{\em M}odel, which randomly masking SMILES
subsequences corresponding to specific molecular \underline{\em F}unctional
\underline{\em G}roups to incorporate structure information of atoms during the
pre-training phase. This technique aims to compel the model to better infer
molecular structures and properties, thus enhancing its predictive
capabilities. Extensive experimental evaluations across 11 benchmark
classification and regression tasks in the chemical domain demonstrate the
robustness and superiority of \ours{}. Our findings reveal that \ours{}
outperforms existing pre-training models, either based on SMILES or graphs, in
9 out of the 11 downstream tasks, ranking as a close second in the remaining
ones.

摘要：<paragraph>計算化學的近期進展已利用轉換器語言模型的力量，例如 MoLFormer，使用大量簡化分子輸入線條輸入系統 (SMILES) 序列進行預訓練，以了解和預測分子特性和活性，這是藥物發現和材料科學等領域的重要步驟。為了進一步提升效能，研究人員引入了具有圖形為基礎的分子表示的圖形神經網路，例如 GEM，將分子的拓樸、幾何、2D 甚至 3D 結構納入預訓練中。雖然現有研究中的大多數分子圖形都是從 SMILES 序列自動轉換而來的，但可以假設基於轉換器的語言模型可能能夠從 SMILES 序列中隱式學習結構感知表示。在本文中，我們提出 \ours{} -- 一個基於 SMILES 的\underline{\em M}olecular\underline{\em L}anguage \underline{\em M}odel，它隨機遮蔽對應於特定分子\underline{\em F}unctional\underline{\em G}roups 的 SMILES 子序列，以在預訓練階段納入原子的結構資訊。此技術旨在強制模型更好地推斷分子結構和特性，從而增強其預測能力。在化學領域的 11 個基準分類和回歸任務中進行的廣泛實驗評估證明了 \ours{} 的穩健性和優越性。我們的研究結果顯示，\ours{} 在 11 個下游任務中的 9 個任務中優於現有的預訓練模型（基於 SMILES 或圖形），在剩下的任務中排名第二。</paragraph>

##### **Narrative Analysis of True Crime Podcasts With Knowledge Graph-Augmented Large Language Models**
2411.02435v1 by Xinyi Leng, Jason Liang, Jack Mauro, Xu Wang, Andrea L. Bertozzi, James Chapman, Junyuan Lin, Bohan Chen, Chenchen Ye, Temple Daniel, P. Jeffrey Brantingham

Narrative data spans all disciplines and provides a coherent model of the
world to the reader or viewer. Recent advancement in machine learning and Large
Language Models (LLMs) have enable great strides in analyzing natural language.
However, Large language models (LLMs) still struggle with complex narrative
arcs as well as narratives containing conflicting information. Recent work
indicates LLMs augmented with external knowledge bases can improve the accuracy
and interpretability of the resulting models. In this work, we analyze the
effectiveness of applying knowledge graphs (KGs) in understanding true-crime
podcast data from both classical Natural Language Processing (NLP) and LLM
approaches. We directly compare KG-augmented LLMs (KGLLMs) with classical
methods for KG construction, topic modeling, and sentiment analysis.
Additionally, the KGLLM allows us to query the knowledge base in natural
language and test its ability to factually answer questions. We examine the
robustness of the model to adversarial prompting in order to test the model's
ability to deal with conflicting information. Finally, we apply classical
methods to understand more subtle aspects of the text such as the use of
hearsay and sentiment in narrative construction and propose future directions.
Our results indicate that KGLLMs outperform LLMs on a variety of metrics, are
more robust to adversarial prompts, and are more capable of summarizing the
text into topics.

摘要：敘事資料涵蓋所有學科，並為讀者或觀眾提供一個連貫的世界模型。機器學習和大型語言模型 (LLM) 的最新進展在分析自然語言方面取得了長足的進步。然而，大型語言模型 (LLM) 仍然難以應付複雜的敘事弧線以及包含相互矛盾資訊的敘事。最近的研究表明，使用外部知識庫增強的 LLM 可以提高所產生模型的準確性和可解釋性。在這項工作中，我們分析了在從傳統自然語言處理 (NLP) 和 LLM 方法中理解真實犯罪播客資料時，應用知識圖譜 (KG) 的有效性。我們直接比較了 KG 增強的 LLM (KGLLM) 與用於 KG 建構、主題建模和情緒分析的傳統方法。此外，KGLLM 允許我們以自然語言查詢知識庫，並測試其事實回答問題的能力。我們檢查了模型對對抗性提示的穩健性，以測試模型處理相互矛盾資訊的能力。最後，我們應用傳統方法來理解文本的更細微方面，例如在敘事建構中使用道聽途說和情緒，並提出未來的方向。我們的結果表明，KGLLM 在各種指標上優於 LLM，對對抗提示更穩健，並且更能夠將文本總結為主題。

##### **WLPlan: Relational Features for Symbolic Planning**
2411.00577v1 by Dillon Z. Chen

Scalable learning for planning research generally involves juggling between
different programming languages for handling learning and planning modules
effectively. Interpreted languages such as Python are commonly used for
learning routines due to their ease of use and the abundance of highly
maintained learning libraries they exhibit, while compiled languages such as
C++ are used for planning routines due to their optimised resource usage.
Motivated by the need for tools for developing scalable learning planners, we
introduce WLPlan, a C++ package with Python bindings which implements recent
promising work for automatically generating relational features of planning
tasks. Such features can be used for any downstream routine, such as learning
domain control knowledge or probing and understanding planning tasks. More
specifically, WLPlan provides functionality for (1) transforming planning tasks
into graphs, and (2) embedding planning graphs into feature vectors via graph
kernels. The source code and instructions for the installation and usage of
WLPlan are available at tinyurl.com/42kymswc

摘要：可擴充的學習規劃研究通常需要在不同的程式語言之間切換，才能有效地處理學習和規劃模組。例如 Python 等直譯語言通常用於學習常式，因為它們易於使用，且有許多維護完善的學習函式庫；而例如 C++ 等編譯語言則用於規劃常式，因為它們能最佳化資源使用。由於需要開發可擴充學習規劃器的工具，我們引進了 WLPlan，這是一個具有 Python 繫結的 C++ 套件，實作了近期有前途的自動產生規劃任務關係特徵的工作。此類特徵可用於任何下游常式，例如學習領域控制知識或探測和理解規劃任務。更具體地說，WLPlan 提供了以下功能：(1) 將規劃任務轉換為圖形，以及 (2) 透過圖形核將規劃圖形嵌入特徵向量。WLPlan 的原始碼和安裝及使用說明可在 tinyurl.com/42kymswc 取得

##### **GRS-QA -- Graph Reasoning-Structured Question Answering Dataset**
2411.00369v3 by Anish Pahilajani, Devasha Trivedi, Jincen Shuai, Khin S. Yone, Samyak Rajesh Jain, Namyong Park, Ryan A. Rossi, Nesreen K. Ahmed, Franck Dernoncourt, Yu Wang

Large Language Models (LLMs) have excelled in multi-hop question-answering
(M-QA) due to their advanced reasoning abilities. However, the impact of the
inherent reasoning structures on LLM M-QA performance remains unclear, largely
due to the absence of QA datasets that provide fine-grained reasoning
structures. To address this gap, we introduce the Graph Reasoning-Structured
Question Answering Dataset (GRS-QA), which includes both semantic contexts and
reasoning structures for QA pairs. Unlike existing M-QA datasets, where
different reasoning structures are entangled together, GRS-QA explicitly
captures intricate reasoning pathways by constructing reasoning graphs, where
nodes represent textual contexts and edges denote logical flows. These
reasoning graphs of different structures enable a fine-grained evaluation of
LLM reasoning capabilities across various reasoning structures. Our empirical
analysis reveals that LLMs perform differently when handling questions with
varying reasoning structures. This finding facilitates the exploration of
textual structures as compared with semantics.

摘要：大型語言模型 (LLM) 由於其先進的推理能力，在多跳問答 (M-QA) 中表現出色。然而，固有推理結構對 LLM M-QA 效能的影響仍不清楚，這主要是由於缺乏提供細粒度推理結構的 QA 資料集。為了解決這個差距，我們引入了圖形推理結構化問答資料集 (GRS-QA)，其中包含語義脈絡和 QA 對應的推理結構。與現有的 M-QA 資料集不同，其中不同的推理結構糾纏在一起，GRS-QA 透過建構推理圖形明確捕捉複雜的推理路徑，其中節點表示文字脈絡，邊緣表示邏輯流程。這些不同結構的推理圖形能夠細緻地評估 LLM 在各種推理結構中的推理能力。我們的實證分析顯示，LLM 在處理具有不同推理結構的問題時表現不同。這個發現促進了對文字結構與語義的比較探索。

##### **Evaluating the Impact of Lab Test Results on Large Language Models Generated Differential Diagnoses from Clinical Case Vignettes**
2411.02523v1 by Balu Bhasuran, Qiao Jin, Yuzhang Xie, Carl Yang, Karim Hanna, Jennifer Costa, Cindy Shavor, Zhiyong Lu, Zhe He

Differential diagnosis is crucial for medicine as it helps healthcare
providers systematically distinguish between conditions that share similar
symptoms. This study assesses the impact of lab test results on differential
diagnoses (DDx) made by large language models (LLMs). Clinical vignettes from
50 case reports from PubMed Central were created incorporating patient
demographics, symptoms, and lab results. Five LLMs GPT-4, GPT-3.5, Llama-2-70b,
Claude-2, and Mixtral-8x7B were tested to generate Top 10, Top 5, and Top 1 DDx
with and without lab data. A comprehensive evaluation involving GPT-4, a
knowledge graph, and clinicians was conducted. GPT-4 performed best, achieving
55% accuracy for Top 1 diagnoses and 60% for Top 10 with lab data, with lenient
accuracy up to 80%. Lab results significantly improved accuracy, with GPT-4 and
Mixtral excelling, though exact match rates were low. Lab tests, including
liver function, metabolic/toxicology panels, and serology/immune tests, were
generally interpreted correctly by LLMs for differential diagnosis.

摘要：鑑別診斷對於醫學至關重要，因為它有助於醫療保健提供者系統區分具有相似症狀的疾病。這項研究評估了實驗室檢驗結果對大型語言模型 (LLM) 做出的鑑別診斷 (DDx) 的影響。從 PubMed Central 的 50 份病例報告中建立了臨床簡報，其中包含患者人口統計、症狀和實驗室結果。測試了五個 LLM GPT-4、GPT-3.5、Llama-2-70b、Claude-2 和 Mixtral-8x7B，以生成帶和不帶實驗室數據的前 10、前 5 和前 1 DDx。進行了一項涉及 GPT-4、知識圖譜和臨床醫生的綜合評估。GPT-4 表現最佳，在有實驗室數據的情況下，前 1 名診斷的準確率達到 55%，前 10 名的準確率達到 60%，寬鬆準確率高達 80%。實驗室結果顯著提高了準確率，GPT-4 和 Mixtral 表現出色，儘管完全匹配率較低。LLM 通常可以正確解釋包括肝功能、代謝/毒理學檢查和血清學/免疫測試在內的實驗室檢驗，以進行鑑別診斷。

##### **Compositional Automata Embeddings for Goal-Conditioned Reinforcement Learning**
2411.00205v1 by Beyazit Yalcinkaya, Niklas Lauffer, Marcell Vazquez-Chanlatte, Sanjit A. Seshia

Goal-conditioned reinforcement learning is a powerful way to control an AI
agent's behavior at runtime. That said, popular goal representations, e.g.,
target states or natural language, are either limited to Markovian tasks or
rely on ambiguous task semantics. We propose representing temporal goals using
compositions of deterministic finite automata (cDFAs) and use cDFAs to guide RL
agents. cDFAs balance the need for formal temporal semantics with ease of
interpretation: if one can understand a flow chart, one can understand a cDFA.
On the other hand, cDFAs form a countably infinite concept class with Boolean
semantics, and subtle changes to the automaton can result in very different
tasks, making them difficult to condition agent behavior on. To address this,
we observe that all paths through a DFA correspond to a series of reach-avoid
tasks and propose pre-training graph neural network embeddings on "reach-avoid
derived" DFAs. Through empirical evaluation, we demonstrate that the proposed
pre-training method enables zero-shot generalization to various cDFA task
classes and accelerated policy specialization without the myopic suboptimality
of hierarchical methods.

摘要：目標條件強化學習是一種在執行階段控制 AI 代理行為的強大方法。話雖如此，熱門的目標表示，例如目標狀態或自然語言，僅限於馬可夫任務或依賴於含糊不清的任務語義。我們建議使用確定性有限狀態自動機 (cDFA) 的組合來表示時間目標，並使用 cDFA 來指導 RL 代理。cDFA 平衡了對形式時間語義的需求與易於解釋之間的關係：如果一個人能理解流程圖，那麼他就能理解 cDFA。另一方面，cDFA 形成了一個具有布林語義的可數無限概念類，而對自動機的細微更改可能會導致非常不同的任務，這使得它們難以對代理行為進行條件化。為了解決這個問題，我們觀察到通過 DFA 的所有路徑都對應於一系列到達避免任務，並提出對「到達避免衍生」DFA 進行預訓練圖神經網路嵌入。通過經驗評估，我們證明了所提出的預訓練方法能夠對各種 cDFA 任務類別進行零次學習泛化，並加速策略專業化，而沒有分層方法的近視次優性。

##### **Building Multi-Agent Copilot towards Autonomous Agricultural Data Management and Analysis**
2411.00188v1 by Yu Pan, Jianxin Sun, Hongfeng Yu, Joe Luck, Geng Bai, Nipuna Chamara, Yufeng Ge, Tala Awada

Current agricultural data management and analysis paradigms are to large
extent traditional, in which data collecting, curating, integration, loading,
storing, sharing and analyzing still involve too much human effort and
know-how. The experts, researchers and the farm operators need to understand
the data and the whole process of data management pipeline to make fully use of
the data. The essential problem of the traditional paradigm is the lack of a
layer of orchestrational intelligence which can understand, organize and
coordinate the data processing utilities to maximize data management and
analysis outcome. The emerging reasoning and tool mastering abilities of large
language models (LLM) make it a potentially good fit to this position, which
helps a shift from the traditional user-driven paradigm to AI-driven paradigm.
In this paper, we propose and explore the idea of a LLM based copilot for
autonomous agricultural data management and analysis. Based on our previously
developed platform of Agricultural Data Management and Analytics (ADMA), we
build a proof-of-concept multi-agent system called ADMA Copilot, which can
understand user's intent, makes plans for data processing pipeline and
accomplishes tasks automatically, in which three agents: a LLM based
controller, an input formatter and an output formatter collaborate together.
Different from existing LLM based solutions, by defining a meta-program graph,
our work decouples control flow and data flow to enhance the predictability of
the behaviour of the agents. Experiments demonstrates the intelligence,
autonomy, efficacy, efficiency, extensibility, flexibility and privacy of our
system. Comparison is also made between ours and existing systems to show the
superiority and potential of our system.

摘要：<paragraph>目前的農業資料管理與分析模式在很大程度上仍是傳統的，其中資料收集、整理、整合、載入、儲存、分享和分析仍然需要太多的人力與專業知識。專家、研究人員和農場經營者需要了解資料和整個資料管理流程，才能充分利用資料。傳統模式的基本問題是缺乏一層編排智能，無法理解、組織和協調資料處理工具，以最大化資料管理和分析成果。大型語言模型 (LLM) 新興的推理和工具掌握能力使其潛在適合這個職位，這有助於從傳統的使用者驅動模式轉變為 AI 驅動模式。在本文中，我們提出並探討了基於 LLM 的副駕駛的想法，用於自動化農業資料管理和分析。基於我們先前開發的農業資料管理和分析 (ADMA) 平台，我們建立了一個名為 ADMA Copilot 的概念驗證多代理系統，它可以理解使用者的意圖、規劃資料處理流程並自動完成任務，其中三個代理：基於 LLM 的控制器、輸入格式化程式和輸出格式化程式共同合作。與現有的基於 LLM 的解決方案不同，透過定義元程式圖，我們的研究將控制流程和資料流程解耦，以增強代理行為的可預測性。實驗證明了我們系統的智慧、自主性、效能、效率、可擴充性、靈活性與隱私性。我們也與現有系統進行比較，以顯示我們系統的優越性和潛力。</paragraph>

##### **Exploring the Knowledge Mismatch Hypothesis: Hallucination Propensity in Small Models Fine-tuned on Data from Larger Models**
2411.00878v1 by Phil Wee, Riyadh Baghdadi

Recently, there has been an explosion of large language models created
through fine-tuning with data from larger models. These small models able to
produce outputs that appear qualitatively similar to significantly larger
models. However, one of the key limitations that have been observed with these
models is their propensity to hallucinate significantly more often than larger
models. In particular, they have been observed to generate coherent outputs
that involve factually incorrect information and spread misinformation,
toxicity, and stereotypes. There are many potential causes of hallucination, of
which, one hypothesis is that fine-tuning a model on data produced by a larger
model leads to a knowledge mismatch which contributes to hallucination. In
particular, it is hypothesized that there is a mismatch between the knowledge
that is fed to the model to fine-tune it and the knowledge that is already
present in the graph. Fine-tuning the model on data that has such mismatch
could contribute to an increased propensity to hallucinate. We show that on an
unseen test set, a smaller model fine-tuned on data generated from a larger
model produced more wrong answers when compared to models fine-tuned on data
created by the small model, which confirms the hypothesis.

摘要：最近，通过使用更大模型的数据进行微调，创建了大量语言模型爆炸。这些小模型能够产生与明显更大的模型在质量上类似的输出。然而，在这些模型中观察到的一个关键限制是，它们比更大的模型更容易出现幻觉。特别是，已经观察到它们会生成涉及事实不正确的信息并传播错误信息、毒性和刻板印象的连贯输出。幻觉有很多潜在原因，其中一个假设是，在更大模型生成的数据上微调模型会导致知识不匹配，从而导致幻觉。特别是，假设模型微调所馈送的知识与图中已有的知识之间存在不匹配。在具有这种不匹配的数据上微调模型可能会导致幻觉倾向增加。我们表明，在一个看不见的测试集中，一个在从一个更大的模型生成的数据上微调的小模型，与在小模型创建的数据上微调的模型相比，产生了更多错误的答案，这证实了这一假设。

##### **Failure Modes of LLMs for Causal Reasoning on Narratives**
2410.23884v1 by Khurram Yamin, Shantanu Gupta, Gaurav R. Ghosal, Zachary C. Lipton, Bryan Wilder

In this work, we investigate the causal reasoning abilities of large language
models (LLMs) through the representative problem of inferring causal
relationships from narratives. We find that even state-of-the-art language
models rely on unreliable shortcuts, both in terms of the narrative
presentation and their parametric knowledge. For example, LLMs tend to
determine causal relationships based on the topological ordering of events
(i.e., earlier events cause later ones), resulting in lower performance
whenever events are not narrated in their exact causal order. Similarly, we
demonstrate that LLMs struggle with long-term causal reasoning and often fail
when the narratives are long and contain many events. Additionally, we show
LLMs appear to rely heavily on their parametric knowledge at the expense of
reasoning over the provided narrative. This degrades their abilities whenever
the narrative opposes parametric knowledge. We extensively validate these
failure modes through carefully controlled synthetic experiments, as well as
evaluations on real-world narratives. Finally, we observe that explicitly
generating a causal graph generally improves performance while naive
chain-of-thought is ineffective. Collectively, our results distill precise
failure modes of current state-of-the-art models and can pave the way for
future techniques to enhance causal reasoning in LLMs.

摘要：在這項工作中，我們透過推論敘述中的因果關係這個代表性問題，來探討大型語言模型 (LLM) 的因果推理能力。我們發現，即使是最先進的語言模型，也會依賴於不可靠的捷徑，無論是在敘述呈現或其參數知識方面。例如，LLM 傾向於根據事件的拓撲順序（即，較早的事件導致較晚的事件）來確定因果關係，當事件未按其確切的因果順序敘述時，就會導致較低的效能。同樣地，我們證明 LLM 難以進行長期因果推理，並且當敘述很長且包含許多事件時，它們通常會失敗。此外，我們表明 LLM 似乎過度依賴其參數知識，而犧牲了對所提供敘述的推理。每當敘述與參數知識相衝突時，這就會降低它們的能力。我們透過仔細控制的合成實驗以及對真實世界敘述的評估，廣泛驗證了這些失敗模式。最後，我們觀察到，明確產生因果圖通常會改善效能，而天真的思考鏈則無效。總的來說，我們的結果精確地提煉了當前最先進模型的失敗模式，並可以為未來增強 LLM 中因果推理的技術鋪路。

##### **Plan-on-Graph: Self-Correcting Adaptive Planning of Large Language Model on Knowledge Graphs**
2410.23875v1 by Liyi Chen, Panrong Tong, Zhongming Jin, Ying Sun, Jieping Ye, Hui Xiong

Large Language Models (LLMs) have shown remarkable reasoning capabilities on
complex tasks, but they still suffer from out-of-date knowledge,
hallucinations, and opaque decision-making. In contrast, Knowledge Graphs (KGs)
can provide explicit and editable knowledge for LLMs to alleviate these issues.
Existing paradigm of KG-augmented LLM manually predefines the breadth of
exploration space and requires flawless navigation in KGs. However, this
paradigm cannot adaptively explore reasoning paths in KGs based on the question
semantics and self-correct erroneous reasoning paths, resulting in a bottleneck
in efficiency and effect. To address these limitations, we propose a novel
self-correcting adaptive planning paradigm for KG-augmented LLM named
Plan-on-Graph (PoG), which first decomposes the question into several
sub-objectives and then repeats the process of adaptively exploring reasoning
paths, updating memory, and reflecting on the need to self-correct erroneous
reasoning paths until arriving at the answer. Specifically, three important
mechanisms of Guidance, Memory, and Reflection are designed to work together,
to guarantee the adaptive breadth of self-correcting planning for graph
reasoning. Finally, extensive experiments on three real-world datasets
demonstrate the effectiveness and efficiency of PoG.

摘要：大型語言模型 (LLM) 在複雜任務中展現出非凡的推理能力，但仍存在知識過時、幻覺和決策不透明的問題。相反地，知識圖譜 (KG) 可以提供明確且可編輯的知識，供 LLM 緩解這些問題。現有的 KG 增強 LLM 典範手動預先定義探索空間的廣度，並需要在 KG 中完美導航。然而，此典範無法根據問題語意自適應地探索 KG 中的推理路徑，並自行糾正錯誤的推理路徑，導致效率和效果的瓶頸。為了解決這些限制，我們提出了一個名為圖形計畫 (PoG) 的 KG 增強 LLM 的新穎自修正自適應規劃典範，它首先將問題分解成幾個子目標，然後重複自適應探索推理路徑、更新記憶體和反思需要自行糾正錯誤推理路徑的過程，直到得出答案。具體來說，指導、記憶和反思這三個重要機制被設計為協同運作，以保證自修正規劃在圖形推理中的自適應廣度。最後，在三個真實世界資料集上的廣泛實驗證明了 PoG 的有效性和效率。

##### **LLaMo: Large Language Model-based Molecular Graph Assistant**
2411.00871v1 by Jinyoung Park, Minseong Bae, Dohwan Ko, Hyunwoo J. Kim

Large Language Models (LLMs) have demonstrated remarkable generalization and
instruction-following capabilities with instruction tuning. The advancements in
LLMs and instruction tuning have led to the development of Large
Vision-Language Models (LVLMs). However, the competency of the LLMs and
instruction tuning have been less explored in the molecular domain. Thus, we
propose LLaMo: Large Language Model-based Molecular graph assistant, which is
an end-to-end trained large molecular graph-language model. To bridge the
discrepancy between the language and graph modalities, we present the
multi-level graph projector that transforms graph representations into graph
tokens by abstracting the output representations of each GNN layer and motif
representations with the cross-attention mechanism. We also introduce
machine-generated molecular graph instruction data to instruction-tune the
large molecular graph-language model for general-purpose molecule and language
understanding. Our extensive experiments demonstrate that LLaMo shows the best
performance on diverse tasks, such as molecular description generation,
property prediction, and IUPAC name prediction. The code of LLaMo is available
at https://github.com/mlvlab/LLaMo.

摘要：大型语言模型 (LLM) 已展示出卓越的概括和指令遵循能力，并进行指令调整。LLM 和指令调整的进步导致了大型视觉语言模型 (LVLMs) 的发展。然而，LLM 和指令调整的能力在分子领域的研究较少。因此，我们提出了 LLaMo：基于大语言模型的分子图助手，这是一个端到端训练的大分子图语言模型。为了弥合语言和图模式之间的差异，我们提出了多级图投影仪，它通过抽象每个 GNN 层的输出表示和基序表示（使用交叉注意力机制）将图表示转换为图标记。我们还引入了机器生成的分子图指令数据，以对大型分子图语言模型进行指令调整，以用于通用分子和语言理解。我们广泛的实验表明，LLaMo 在分子描述生成、属性预测和 IUPAC 名称预测等不同任务上表现出最佳性能。LLaMo 的代码可在 https://github.com/mlvlab/LLaMo 获得。

##### **End-to-End Ontology Learning with Large Language Models**
2410.23584v1 by Andy Lo, Albert Q. Jiang, Wenda Li, Mateja Jamnik

Ontologies are useful for automatic machine processing of domain knowledge as
they represent it in a structured format. Yet, constructing ontologies requires
substantial manual effort. To automate part of this process, large language
models (LLMs) have been applied to solve various subtasks of ontology learning.
However, this partial ontology learning does not capture the interactions
between subtasks. We address this gap by introducing OLLM, a general and
scalable method for building the taxonomic backbone of an ontology from
scratch. Rather than focusing on subtasks, like individual relations between
entities, we model entire subcomponents of the target ontology by finetuning an
LLM with a custom regulariser that reduces overfitting on high-frequency
concepts. We introduce a novel suite of metrics for evaluating the quality of
the generated ontology by measuring its semantic and structural similarity to
the ground truth. In contrast to standard metrics, our metrics use deep
learning techniques to define more robust distance measures between graphs.
Both our quantitative and qualitative results on Wikipedia show that OLLM
outperforms subtask composition methods, producing more semantically accurate
ontologies while maintaining structural integrity. We further demonstrate that
our model can be effectively adapted to new domains, like arXiv, needing only a
small number of training examples. Our source code and datasets are available
at https://github.com/andylolu2/ollm.

摘要：本体对于领域知识的自动机器处理很有用，因为它们以结构化格式表示知识。然而，构建本体需要大量的手动工作。为了自动化这个过程的一部分，大型语言模型（LLM）已被应用于解决本体学习的各种子任务。然而，这种部分本体学习并没有捕捉到子任务之间的交互。我们通过引入 OLLM 来解决这一差距，这是一种从头开始构建本体分类骨架的通用且可扩展的方法。我们没有专注于子任务，例如实体之间的个别关系，而是通过使用自定义正则化器微调 LLM 来对目标本体的整个子组件进行建模，该正则化器减少了对高频概念的过度拟合。我们引入了一套新的指标来评估生成本体的质量，方法是测量它与地面真实值的语义和结构相似性。与标准指标相反，我们的指标使用深度学习技术来定义图之间的更稳健的距离度量。我们在维基百科上的定量和定性结果表明，OLLM 优于子任务组合方法，在保持结构完整性的同时生成语义上更准确的本体。我们进一步证明，我们的模型可以有效地适应新的领域，如 arXiv，只需要少量的训练样本。我们的源代码和数据集可在 https://github.com/andylolu2/ollm 获得。

##### **Graph-Augmented Relation Extraction Model with LLMs-Generated Support Document**
2410.23452v1 by Vicky Dong, Hao Yu, Yao Chen

This study introduces a novel approach to sentence-level relation extraction
(RE) that integrates Graph Neural Networks (GNNs) with Large Language Models
(LLMs) to generate contextually enriched support documents. By harnessing the
power of LLMs to generate auxiliary information, our approach crafts an
intricate graph representation of textual data. This graph is subsequently
processed through a Graph Neural Network (GNN) to refine and enrich the
embeddings associated with each entity ensuring a more nuanced and
interconnected understanding of the data. This methodology addresses the
limitations of traditional sentence-level RE models by incorporating broader
contexts and leveraging inter-entity interactions, thereby improving the
model's ability to capture complex relationships across sentences. Our
experiments, conducted on the CrossRE dataset, demonstrate the effectiveness of
our approach, with notable improvements in performance across various domains.
The results underscore the potential of combining GNNs with LLM-generated
context to advance the field of relation extraction.

摘要：本研究提出了一個句子層級關係萃取 (RE) 的新方法，該方法整合了圖形神經網路 (GNN) 和大型語言模型 (LLM)，以產生脈絡豐富的支援文件。透過利用 LLM 的功能來產生輔助資訊，我們的做法建立了一個文本資料的複雜圖形表示。此圖形隨後透過圖形神經網路 (GNN) 進行處理，以改善和豐富與每個實體相關的嵌入，確保對資料有更細緻且相互連結的理解。此方法透過納入更廣泛的脈絡並利用實體間互動，來解決傳統句子層級 RE 模型的限制，進而提升模型捕捉跨句子的複雜關係的能力。我們在 CrossRE 資料集上執行的實驗證明了我們方法的有效性，在各種領域的效能都有顯著的提升。這些結果強調了將 GNN 與 LLM 產生的脈絡相結合，以推進關係萃取領域的潛力。

##### **FlowLLM: Flow Matching for Material Generation with Large Language Models as Base Distributions**
2410.23405v1 by Anuroop Sriram, Benjamin Kurt Miller, Ricky T. Q. Chen, Brandon M. Wood

Material discovery is a critical area of research with the potential to
revolutionize various fields, including carbon capture, renewable energy, and
electronics. However, the immense scale of the chemical space makes it
challenging to explore all possible materials experimentally. In this paper, we
introduce FlowLLM, a novel generative model that combines large language models
(LLMs) and Riemannian flow matching (RFM) to design novel crystalline
materials. FlowLLM first fine-tunes an LLM to learn an effective base
distribution of meta-stable crystals in a text representation. After converting
to a graph representation, the RFM model takes samples from the LLM and
iteratively refines the coordinates and lattice parameters. Our approach
significantly outperforms state-of-the-art methods, increasing the generation
rate of stable materials by over three times and increasing the rate for
stable, unique, and novel crystals by $\sim50\%$ - a huge improvement on a
difficult problem. Additionally, the crystals generated by FlowLLM are much
closer to their relaxed state when compared with another leading model,
significantly reducing post-hoc computational cost.

摘要：材料發現是一個重要的研究領域，具有革新各種領域的潛力，包括碳捕集、可再生能源和電子產品。然而，化學空間的巨大規模使得實驗探索所有可能的材料具有挑戰性。在本文中，我們介紹了 FlowLLM，這是一種新穎的生成模型，結合了大型語言模型 (LLM) 和黎曼流匹配 (RFM) 來設計新型晶體材料。FlowLLM 首先微調 LLM，以學習文本表示中亞穩態晶體的有效基礎分佈。在轉換為圖形表示後，RFM 模型從 LLM 中獲取樣本，並反覆精煉坐標和晶格參數。我們的做法顯著優於最先進的方法，將穩定材料的生成率提高了三倍以上，並將穩定、獨特和新穎晶體的生成率提高了約 50%——這在一個困難的問題上是一個巨大的改進。此外，與另一種領先模型相比，FlowLLM 生成的晶體更接近其鬆弛狀態，顯著降低了事後計算成本。

##### **EMMA: End-to-End Multimodal Model for Autonomous Driving**
2410.23262v2 by Jyh-Jing Hwang, Runsheng Xu, Hubert Lin, Wei-Chih Hung, Jingwei Ji, Kristy Choi, Di Huang, Tong He, Paul Covington, Benjamin Sapp, Yin Zhou, James Guo, Dragomir Anguelov, Mingxing Tan

We introduce EMMA, an End-to-end Multimodal Model for Autonomous driving.
Built on a multi-modal large language model foundation, EMMA directly maps raw
camera sensor data into various driving-specific outputs, including planner
trajectories, perception objects, and road graph elements. EMMA maximizes the
utility of world knowledge from the pre-trained large language models, by
representing all non-sensor inputs (e.g. navigation instructions and ego
vehicle status) and outputs (e.g. trajectories and 3D locations) as natural
language text. This approach allows EMMA to jointly process various driving
tasks in a unified language space, and generate the outputs for each task using
task-specific prompts. Empirically, we demonstrate EMMA's effectiveness by
achieving state-of-the-art performance in motion planning on nuScenes as well
as competitive results on the Waymo Open Motion Dataset (WOMD). EMMA also
yields competitive results for camera-primary 3D object detection on the Waymo
Open Dataset (WOD). We show that co-training EMMA with planner trajectories,
object detection, and road graph tasks yields improvements across all three
domains, highlighting EMMA's potential as a generalist model for autonomous
driving applications. However, EMMA also exhibits certain limitations: it can
process only a small amount of image frames, does not incorporate accurate 3D
sensing modalities like LiDAR or radar and is computationally expensive. We
hope that our results will inspire further research to mitigate these issues
and to further evolve the state of the art in autonomous driving model
architectures.

摘要：<paragraph>我們介紹 EMMA，一種用於自動駕駛的端到端多模態模型。
建立在多模態大型語言模型基礎上，EMMA 直接將原始
相機感測器資料對應到各種特定於駕駛的輸出，包括規劃器
軌跡、感知物件和道路圖形元素。EMMA 最大化利用預訓練大型語言模型中的世界知識，方法是
將所有非感測器輸入（例如導航指示和自我
車輛狀態）和輸出（例如軌跡和 3D 位置）表示為自然
語言文字。這種方法允許 EMMA 在統一的語言空間中共同處理各種駕駛
任務，並使用特定於任務的提示為每個任務產生輸出。
根據經驗，我們證明了 EMMA 的有效性，在 nuScenes 上的運動規劃中達到了最先進的性能，以及
在 Waymo 開放運動資料集 (WOMD) 上取得了有競爭力的結果。EMMA 也
在 Waymo 開放資料集 (WOD) 上對相機優先的 3D 物件偵測產生了有競爭力的結果。我們展示了使用規劃器軌跡、
物件偵測和道路圖形任務共同訓練 EMMA 會在所有三個
領域產生改進，突顯了 EMMA 作為自動駕駛應用程式通用模型的潛力。然而，EMMA 也表現出某些限制：它只能
處理少量的影像幀，不包含像 LiDAR 或雷達等準確的 3D 感測模式，並且計算成本昂貴。我們
希望我們的結果能激勵進一步的研究，以減輕這些問題並進一步發展自動駕駛模型
架構的最新技術。</paragraph>

##### **ProTransformer: Robustify Transformers via Plug-and-Play Paradigm**
2410.23182v1 by Zhichao Hou, Weizhi Gao, Yuchen Shen, Feiyi Wang, Xiaorui Liu

Transformer-based architectures have dominated various areas of machine
learning in recent years. In this paper, we introduce a novel robust attention
mechanism designed to enhance the resilience of transformer-based
architectures. Crucially, this technique can be integrated into existing
transformers as a plug-and-play layer, improving their robustness without the
need for additional training or fine-tuning. Through comprehensive experiments
and ablation studies, we demonstrate that our ProTransformer significantly
enhances the robustness of transformer models across a variety of prediction
tasks, attack mechanisms, backbone architectures, and data domains. Notably,
without further fine-tuning, the ProTransformer consistently improves the
performance of vanilla transformers by 19.5%, 28.3%, 16.1%, and 11.4% for BERT,
ALBERT, DistilBERT, and RoBERTa, respectively, under the classical TextFooler
attack. Furthermore, ProTransformer shows promising resilience in large
language models (LLMs) against prompting-based attacks, improving the
performance of T5 and LLaMA by 24.8% and 17.8%, respectively, and enhancing
Vicuna by an average of 10.4% against the Jailbreaking attack. Beyond the
language domain, ProTransformer also demonstrates outstanding robustness in
both vision and graph domains.

摘要：<paragraph>近年來，基於 Transformer 的架構主導了機器學習的各個領域。在本文中，我們介紹了一種新穎且強大的注意力機制，旨在增強基於 Transformer 的架構的韌性。至關重要的是，此技術可以作為即插即用的層整合到現有的 Transformer 中，在無需額外訓練或微調的情況下提高其穩健性。通過全面的實驗和消融研究，我們證明了我們的 ProTransformer 在各種預測任務、攻擊機制、主幹架構和數據領域中顯著增強了 Transformer 模型的穩健性。值得注意的是，在不進一步微調的情況下，ProTransformer 在經典的 TextFooler 攻擊下，分別為 BERT、ALBERT、DistilBERT 和 RoBERTa 提升了 19.5%、28.3%、16.1% 和 11.4% 的性能。此外，ProTransformer 在基於提示的攻擊中對大型語言模型 (LLM) 顯示出有希望的韌性，分別將 T5 和 LLaMA 的性能提升了 24.8% 和 17.8%，並在越獄攻擊中將 Vicuna 的性能平均提升了 10.4%。除了語言領域之外，ProTransformer 在視覺和圖形領域也表現出出色的穩健性。</paragraph>


### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-30**|**2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**|Jim Solomon et.al.|[2412.00372v1](http://arxiv.org/abs/2412.00372v1)|null|
|**2024-11-28**|**Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**|Philipp Brauner et.al.|[2411.19356v1](http://arxiv.org/abs/2411.19356v1)|null|
|**2024-11-26**|**Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**|Yujie Dai et.al.|[2411.17645v1](http://arxiv.org/abs/2411.17645v1)|null|
|**2024-11-18**|**Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**|Jeffrey N. Clark et.al.|[2411.11774v1](http://arxiv.org/abs/2411.11774v1)|null|
|**2024-11-15**|**Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**|Mohammed Yaseen Jabarulla et.al.|[2411.10255v1](http://arxiv.org/abs/2411.10255v1)|null|
|**2024-11-01**|**Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**|Mehdi Hosseini Chagahi et.al.|[2411.00916v2](http://arxiv.org/abs/2411.00916v2)|null|
|**2024-10-25**|**A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**|Muath Alsuhaibani et.al.|[2410.19898v1](http://arxiv.org/abs/2410.19898v1)|null|
|**2024-10-23**|**An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**|Shruthi Chari et.al.|[2410.17504v1](http://arxiv.org/abs/2410.17504v1)|[link](https://github.com/tetherless-world/metaexplainer)|
|**2024-10-22**|**Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**|Lukas Hughes-Noehrer et.al.|[2410.16879v1](http://arxiv.org/abs/2410.16879v1)|null|
|**2024-10-19**|**Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**|Gesa Mittmann et.al.|[2410.15012v1](http://arxiv.org/abs/2410.15012v1)|null|
|**2024-10-15**|**Explainable AI Methods for Multi-Omics Analysis: A Survey**|Ahmad Hussein et.al.|[2410.11910v1](http://arxiv.org/abs/2410.11910v1)|null|
|**2024-10-14**|**Study on the Helpfulness of Explainable Artificial Intelligence**|Tobias Labarta et.al.|[2410.11896v1](http://arxiv.org/abs/2410.11896v1)|[link](https://github.com/tlabarta/helpfulnessofxai)|
|**2024-10-12**|**Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**|Abdullah Mamun et.al.|[2410.09635v1](http://arxiv.org/abs/2410.09635v1)|[link](https://github.com/ab9mamun/aimen)|
|**2024-10-10**|**Artificial intelligence techniques in inherited retinal diseases: A review**|Han Trinh et.al.|[2410.09105v1](http://arxiv.org/abs/2410.09105v1)|null|
|**2024-10-07**|**CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**|Ekaterina Sviridova et.al.|[2410.05235v2](http://arxiv.org/abs/2410.05235v2)|[link](https://github.com/ixa-ehu/antidote-casimedicos)|
|**2024-10-01**|**Explainable Diagnosis Prediction through Neuro-Symbolic Integration**|Qiuhao Lu et.al.|[2410.01855v1](http://arxiv.org/abs/2410.01855v1)|null|
|**2024-10-01**|**Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**|Prasenjit Maji et.al.|[2410.00366v1](http://arxiv.org/abs/2410.00366v1)|null|
|**2024-09-20**|**Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**|Tirtha Chanda et.al.|[2409.13476v1](http://arxiv.org/abs/2409.13476v1)|null|
|**2024-09-19**|**Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**|Suryansh Vidya et.al.|[2409.15374v1](http://arxiv.org/abs/2409.15374v1)|null|
|**2024-09-19**|**Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**|Daniel Flores-Araiza et.al.|[2409.12883v1](http://arxiv.org/abs/2409.12883v1)|null|
|**2024-09-18**|**Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**|Yubo Li et.al.|[2409.12087v3](http://arxiv.org/abs/2409.12087v3)|null|
|**2024-09-09**|**Explainable AI: Definition and attributes of a good explanation for health AI**|Evangelia Kyrimi et.al.|[2409.15338v1](http://arxiv.org/abs/2409.15338v1)|null|
|**2024-08-30**|**Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**|Antonio Rago et.al.|[2408.17401v1](http://arxiv.org/abs/2408.17401v1)|null|
|**2024-08-29**|**A Survey for Large Language Models in Biomedicine**|Chong Wang et.al.|[2409.00133v1](http://arxiv.org/abs/2409.00133v1)|null|
|**2024-08-27**|**Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**|Francesco Sovrano et.al.|[2408.15121v1](http://arxiv.org/abs/2408.15121v1)|null|
|**2024-08-24**|**Towards Case-based Interpretability for Medical Federated Learning**|Laura Latorre et.al.|[2408.13626v1](http://arxiv.org/abs/2408.13626v1)|null|
|**2024-08-22**|**AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**|Douwe J. Spaanderman et.al.|[2408.12491v1](http://arxiv.org/abs/2408.12491v1)|null|
|**2024-08-14**|**Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**|Kimji N. Pellano et.al.|[2409.00001v1](http://arxiv.org/abs/2409.00001v1)|null|
|**2024-08-06**|**MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**|Hanchen David Wang et.al.|[2408.11837v1](http://arxiv.org/abs/2408.11837v1)|null|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**|Michele Fiori et.al.|[2408.06352v1](http://arxiv.org/abs/2408.06352v1)|null|
|**2024-07-21**|**Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**|Naseem Khan et.al.|[2408.03335v1](http://arxiv.org/abs/2408.03335v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v2](http://arxiv.org/abs/2407.05440v2)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v2](http://arxiv.org/abs/2407.15851v2)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-17**|**Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**|Vincent Olesen et.al.|[2406.12142v2](http://arxiv.org/abs/2406.12142v2)|[link](https://github.com/volesen/slicing-through-bias)|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v3](http://arxiv.org/abs/2406.16908v3)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. Zając et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel Miró-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|Séamus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Cause and Effect: Can Large Language Models Truly Understand Causality?**|Swagata Ashwani et.al.|[2402.18139v3](http://arxiv.org/abs/2402.18139v3)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|Timothée Schmude et.al.|[2401.13324v6](http://arxiv.org/abs/2401.13324v6)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-12-04**|**Class-Discriminative Attention Maps for Vision Transformers**|Lennart Brocki et.al.|[2312.02364v3](http://arxiv.org/abs/2312.02364v3)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|
|**2023-11-21**|**Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**|Robert Gorwa et.al.|[2311.12573v3](http://arxiv.org/abs/2311.12573v3)|null|
|**2023-11-20**|**Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**|Muta Tah Hira et.al.|[2311.11932v1](http://arxiv.org/abs/2311.11932v1)|null|
|**2023-11-18**|**Representing visual classification as a linear combination of words**|Shobhit Agarwal et.al.|[2311.10933v1](http://arxiv.org/abs/2311.10933v1)|[link](https://github.com/lotterlab/task_word_explainability)|

#### Abstracts
##### **2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**
2412.00372v1 by Jim Solomon, Laleh Jalilian, Alexander Vilesov, Meryl Mathew, Tristan Grogan, Arash Bedayat, Achuta Kadambi

Human-machine teaming in medical AI requires us to understand to what degree
a trained clinician should weigh AI predictions. While previous work has shown
the potential of AI assistance at improving clinical predictions, existing
clinical decision support systems either provide no explainability of their
predictions or use techniques like saliency and Shapley values, which do not
allow for physician-based verification. To address this gap, this study
compares previously used explainable AI techniques with a newly proposed
technique termed '2-factor retrieval (2FR)', which is a combination of
interface design and search retrieval that returns similarly labeled data
without processing this data. This results in a 2-factor security blanket
where: (a) correct images need to be retrieved by the AI; and (b) humans should
associate the retrieved images with the current pathology under test. We find
that when tested on chest X-ray diagnoses, 2FR leads to increases in clinician
accuracy, with particular improvements when clinicians are radiologists and
have low confidence in their decision. Our results highlight the importance of
understanding how different modes of human-AI decision making may impact
clinician accuracy in clinical decision support systems.

摘要：人機協作在醫療 AI 中，需要我們理解受過訓練的臨床醫生在多大程度上應重視 AI 預測。雖然先前的研究顯示 AI 輔助在改善臨床預測方面的潛力，但現有的臨床決策支援系統，要不就沒有提供預測的可解釋性，要不就是使用像顯著性和 Shapley 值之類的技術，這些技術不允許基於醫生的驗證。為了解決這個差距，本研究將先前使用的可解釋 AI 技術與一種新提出的稱為「2 因子檢索 (2FR)」的技術進行比較，後者是一種介面設計和搜尋檢索的組合，它會傳回標籤相似的資料，而不會處理這些資料。這會產生一個 2 因子安全機制，其中：(a) 正確的影像需要由 AI 檢索；(b) 人類應將檢索的影像與正在測試中的病理聯想起來。我們發現，當在胸部 X 光診斷上進行測試時，2FR 會提高臨床醫生的準確度，特別是在臨床醫生是放射科醫生且對其決策信心不足時，會有顯著的改善。我們的結果強調了理解人機決策的不同模式如何影響臨床醫生在臨床決策支援系統中的準確性的重要性。

##### **Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**
2411.19356v1 by Philipp Brauner, Felix Glawe, Gian Luca Liehner, Luisa Vervier, Martina Ziefle

Understanding public perception of artificial intelligence (AI) and the
tradeoffs between potential risks and benefits is crucial, as these perceptions
might shape policy decisions, influence innovation trajectories for successful
market strategies, and determine individual and societal acceptance of AI
technologies. Using a representative sample of 1100 participants from Germany,
this study examines mental models of AI. Participants quantitatively evaluated
71 statements about AI's future capabilities (e.g., autonomous driving, medical
care, art, politics, warfare, and societal divides), assessing the expected
likelihood of occurrence, perceived risks, benefits, and overall value. We
present rankings of these projections alongside visual mappings illustrating
public risk-benefit tradeoffs. While many scenarios were deemed likely,
participants often associated them with high risks, limited benefits, and low
overall value. Across all scenarios, 96.4% ($r^2=96.4\%$) of the variance in
value assessment can be explained by perceived risks ($\beta=-.504$) and
perceived benefits ($\beta=+.710$), with no significant relation to expected
likelihood. Demographics and personality traits influenced perceptions of
risks, benefits, and overall evaluations, underscoring the importance of
increasing AI literacy and tailoring public information to diverse user needs.
These findings provide actionable insights for researchers, developers, and
policymakers by highlighting critical public concerns and individual factors
essential to align AI development with individual values.

摘要：<paragraph>了解公眾對人工智慧 (AI) 的認知以及潛在風險與好處之間的權衡至關重要，因為這些認知可能會影響政策決策、影響成功市場策略的創新軌跡，並決定個人和社會對 AI 技術的接受度。本研究使用來自德國的 1100 名參與者的代表性樣本，探討了 AI 的心智模型。參與者對 71 項關於 AI 未來能力的陳述（例如，自動駕駛、醫療保健、藝術、政治、戰爭和社會分歧）進行了定量評估，評估預期的發生可能性、感知風險、好處和整體價值。我們展示了這些預測的排名，並附上視覺化映射，說明了公眾的風險收益權衡。儘管許多場景被認為是可能的，但參與者通常將它們與高風險、有限的好處和低整體價值聯繫起來。在所有場景中，96.4% ($r^2=96.4\%$) 的價值評估差異可以用感知風險 ($\beta=-.504$) 和感知好處 ($\beta=+.710$) 來解釋，與預期的可能性沒有顯著關係。人口統計和人格特質影響了對風險、好處和整體評估的看法，這凸顯了提高 AI 素養和根據不同的使用者需求調整公共資訊的重要性。這些發現通過強調關鍵的公共關注和與個人價值觀一致的 AI 開發必不可少的個人因素，為研究人員、開發人員和政策制定者提供了可行的見解。</paragraph>

##### **Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**
2411.17645v1 by Yujie Dai, Brian Sullivan, Axel Montout, Amy Dillon, Chris Waller, Peter Acs, Rachel Denholm, Philip Williams, Alastair D Hay, Raul Santos-Rodriguez, Andrew Dowsey

The use of machine learning and AI on electronic health records (EHRs) holds
substantial potential for clinical insight. However, this approach faces
significant challenges due to data heterogeneity, sparsity, temporal
misalignment, and limited labeled outcomes. In this context, we leverage a
linked EHR dataset of approximately one million de-identified individuals from
Bristol, North Somerset, and South Gloucestershire, UK, to characterize urinary
tract infections (UTIs) and develop predictive models focused on data quality,
fairness and transparency. A comprehensive data pre-processing and curation
pipeline transforms the raw EHR data into a structured format suitable for AI
modeling. Given the limited availability and biases of ground truth UTI
outcomes, we introduce a UTI risk estimation framework informed by clinical
expertise to estimate UTI risk across individual patient timelines. Using this
framework, we built pairwise XGBoost models to differentiate UTI risk
categories with explainable AI techniques to identify key predictors while
ensuring interpretability. Our findings reveal differences in clinical and
demographic factors across risk groups, offering insights into UTI risk
stratification and progression. This study demonstrates the added value of
AI-driven insights into UTI clinical decision-making while prioritizing
interpretability, transparency, and fairness, underscoring the importance of
sound data practices in advancing health outcomes.

摘要：機器學習和人工智慧在電子健康紀錄 (EHR) 上的應用具有
臨床見解的巨大潛力。然而，這種方法由於資料異質性、稀疏性、時間錯位和標記結果有限，因此面臨重大挑戰。在此背景下，我們利用來自英國布里斯托、北薩默塞特郡和南格洛斯特郡的大約一百萬名去識別化個人的連結式 EHR 資料集，以描述泌尿道感染 (UTI) 並開發專注於資料品質、公平性和透明度的預測模型。全面的資料前處理和整理管道將原始 EHR 資料轉換為適合 AI 建模的結構化格式。鑑於實際 UTI 結果的可用性有限和偏見，我們引入了一個由臨床專業知識提供資訊的 UTI 風險評估架構，以估計個人患者時間線上的 UTI 風險。使用此架構，我們建立了成對的 XGBoost 模型，以區分 UTI 風險類別，並使用可解釋的 AI 技術來識別關鍵預測因子，同時確保可解釋性。我們的研究結果揭示了不同風險群組的臨床和人口統計因素的差異，提供了對 UTI 風險分層和進展的見解。本研究展示了 AI 驅動的見解在 UTI 臨床決策中的附加價值，同時優先考慮可解釋性、透明度和公平性，強調了健全資料實務在促進健康結果中的重要性。

##### **Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**
2411.11774v1 by Jeffrey N. Clark, Matthew Wragg, Emily Nielsen, Miquel Perello-Nieto, Nawid Keshtmand, Michael Ambler, Shiv Sharma, Christopher P. Bourdeaux, Amberly Brigden, Raul Santos-Rodriguez

There is a growing need to understand how digital systems can support
clinical decision-making, particularly as artificial intelligence (AI) models
become increasingly complex and less human-interpretable. This complexity
raises concerns about trustworthiness, impacting safe and effective adoption of
such technologies. Improved understanding of decision-making processes and
requirements for explanations coming from decision support tools is a vital
component in providing effective explainable solutions. This is particularly
relevant in the data-intensive, fast-paced environments of intensive care units
(ICUs). To explore these issues, group interviews were conducted with seven ICU
clinicians, representing various roles and experience levels. Thematic analysis
revealed three core themes: (T1) ICU decision-making relies on a wide range of
factors, (T2) the complexity of patient state is challenging for shared
decision-making, and (T3) requirements and capabilities of AI decision support
systems. We include design recommendations from clinical input, providing
insights to inform future AI systems for intensive care.

摘要：隨著人工智慧 (AI) 模型變得越來越複雜，且越來越難以被人理解，了解數位系統如何支援臨床決策的需求也日益增加。這種複雜性引發了對可信度的疑慮，影響了此類技術的安全且有效採用。改善對決策制定流程的理解，以及對決策支援工具所提供說明的要求，是提供有效可解釋解決方案的重要組成部分。這在資料密集、快節奏的加護病房 (ICU) 環境中特別相關。為了探討這些問題，對七位 ICU 臨床醫師進行了小組訪談，這些醫師代表了不同的角色和經驗層級。主題分析揭露了三個核心主題：(T1) ICU 決策制定依賴於廣泛的因素，(T2) 病患狀態的複雜性對共同決策制定構成挑戰，以及 (T3) AI 決策支援系統的要求和能力。我們納入了臨床輸入的設計建議，提供見解以提供資訊給未來用於加護的 AI 系統。

##### **Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**
2411.10255v1 by Mohammed Yaseen Jabarulla, Theodor Uden, Thomas Jack, Philipp Beerbaum, Steffen Oeltze-Jafra

Pediatric heart diseases present a broad spectrum of congenital and acquired
diseases. More complex congenital malformations require a differentiated and
multimodal decision-making process, usually including echocardiography as a
central imaging method. Artificial intelligence (AI) offers considerable
promise for clinicians by facilitating automated interpretation of pediatric
echocardiography data. However, adapting AI technologies for pediatric
echocardiography analysis has challenges such as limited public data
availability, data privacy, and AI model transparency. Recently, researchers
have focused on disruptive technologies, such as federated learning (FL) and
explainable AI (XAI), to improve automatic diagnostic and decision support
workflows. This study offers a comprehensive overview of the limitations and
opportunities of AI in pediatric echocardiography, emphasizing the synergistic
workflow and role of XAI and FL, identifying research gaps, and exploring
potential future developments. Additionally, three relevant clinical use cases
demonstrate the functionality of XAI and FL with a focus on (i) view
recognition, (ii) disease classification, (iii) segmentation of cardiac
structures, and (iv) quantitative assessment of cardiac function.

摘要：小兒心臟疾病呈現先天性與後天性疾病的廣泛光譜。較複雜的先天性畸形需要一個差異化且多模式的決策過程，通常包括超音波檢查作為主要的影像方法。人工智慧 (AI) 為臨床醫生提供了相當大的希望，因為它可以促進小兒超音波檢查資料的自動化解讀。然而，將人工智慧技術應用於小兒超音波檢查分析有許多挑戰，例如有限的公開資料可用性、資料隱私和人工智慧模型透明度。最近，研究人員專注於破壞性技術，例如聯合學習 (FL) 和可解釋人工智慧 (XAI)，以改善自動診斷和決策支援工作流程。本研究提供了人工智慧在小兒超音波檢查中的限制和機會的全面概述，強調了 XAI 和 FL 的協同工作流程和角色，找出研究差距並探討潛在的未來發展。此外，三個相關的臨床使用案例展示了 XAI 和 FL 的功能，重點在於 (i) 檢視辨識、(ii) 疾病分類、(iii) 心臟結構分割和 (iv) 心臟功能的量化評估。

##### **Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**
2411.00916v2 by Mehdi Hosseini Chagahi, Saeed Mohammadi Dashtaki, Niloufar Delfan, Nadia Mohammadi, Alireza Samari, Behzad Moshiri, Md. Jalil Piran, Oliver Faust

Osteoporosis is a common condition that increases fracture risk, especially
in older adults. Early diagnosis is vital for preventing fractures, reducing
treatment costs, and preserving mobility. However, healthcare providers face
challenges like limited labeled data and difficulties in processing medical
images. This study presents a novel multi-modal learning framework that
integrates clinical and imaging data to improve diagnostic accuracy and model
interpretability. The model utilizes three pre-trained networks-VGG19,
InceptionV3, and ResNet50-to extract deep features from X-ray images. These
features are transformed using PCA to reduce dimensionality and focus on the
most relevant components. A clustering-based selection process identifies the
most representative components, which are then combined with preprocessed
clinical data and processed through a fully connected network (FCN) for final
classification. A feature importance plot highlights key variables, showing
that Medical History, BMI, and Height were the main contributors, emphasizing
the significance of patient-specific data. While imaging features were
valuable, they had lower importance, indicating that clinical data are crucial
for accurate predictions. This framework promotes precise and interpretable
predictions, enhancing transparency and building trust in AI-driven diagnoses
for clinical integration.

摘要：骨質疏鬆症是一種常見的疾病，會增加骨折的風險，特別是老年人。早期診斷對於預防骨折、降低治療成本和維持行動能力至關重要。然而，醫療保健提供者面臨著標記數據有限和處理醫學影像困難等挑戰。本研究提出了一個新穎的多模式學習框架，該框架整合了臨床和影像數據，以提高診斷準確性和模型可解釋性。該模型利用三個預訓練的網路，VGG19、InceptionV3 和 ResNet50，從 X 射線影像中提取深度特徵。這些特徵使用 PCA 轉換以降低維度並專注於最相關的組成部分。基於聚類的選擇過程識別出最具代表性的組成部分，然後將這些組成部分與預處理的臨床數據結合，並通過全連接網路 (FCN) 進行最終分類。特徵重要性圖突出了關鍵變數，表明病史、BMI 和身高是主要貢獻因素，強調了患者特定數據的重要性。雖然影像特徵很有價值，但它們的重要性較低，這表明臨床數據對於準確預測至關重要。此框架促进了準確且可解釋的預測，提高了透明度，並建立了對 AI 驅動診斷在臨床整合中的信任。

##### **A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**
2410.19898v1 by Muath Alsuhaibani, Ali Pourramezan Fard, Jian Sun, Farida Far Poor, Peter S. Pressman, Mohammad H. Mahoor

This review paper explores recent advances in deep learning approaches for
non-invasive cognitive impairment detection. We examine various non-invasive
indicators of cognitive decline, including speech and language, facial, and
motoric mobility. The paper provides an overview of relevant datasets,
feature-extracting techniques, and deep-learning architectures applied to this
domain. We have analyzed the performance of different methods across modalities
and observed that speech and language-based methods generally achieved the
highest detection performance. Studies combining acoustic and linguistic
features tended to outperform those using a single modality. Facial analysis
methods showed promise for visual modalities but were less extensively studied.
Most papers focused on binary classification (impaired vs. non-impaired), with
fewer addressing multi-class or regression tasks. Transfer learning and
pre-trained language models emerged as popular and effective techniques,
especially for linguistic analysis. Despite significant progress, several
challenges remain, including data standardization and accessibility, model
explainability, longitudinal analysis limitations, and clinical adaptation.
Lastly, we propose future research directions, such as investigating
language-agnostic speech analysis methods, developing multi-modal diagnostic
systems, and addressing ethical considerations in AI-assisted healthcare. By
synthesizing current trends and identifying key obstacles, this review aims to
guide further development of deep learning-based cognitive impairment detection
systems to improve early diagnosis and ultimately patient outcomes.

摘要：本篇評論探討了深度學習方法在非侵入式認知功能障礙檢測上的最新進展。我們檢視了各種非侵入式的認知衰退指標，包括語言和語言、面部和運動機能。本文概述了與此領域相關的資料集、特徵提取技術和深度學習架構。我們分析了不同方法在不同方式上的表現，並觀察到基於語言和語言的方法通常能達到最高的檢測表現。結合聲學和語言特徵的研究往往優於使用單一方式的研究。面部分析方法顯示出視覺方式的潛力，但研究較少。大多數論文專注於二元分類（受損與未受損），較少探討多類或回歸任務。遷移學習和預訓練語言模型已成為流行且有效的技術，特別是對於語言分析。儘管取得了重大進展，但仍存在一些挑戰，包括資料標準化和可及性、模型可解釋性、縱向分析限制和臨床適應性。最後，我們提出了未來的研究方向，例如調查與語言無關的語音分析方法、開發多模式診斷系統，以及解決人工智慧輔助醫療保健中的倫理考量。透過綜合目前的趨勢和找出關鍵障礙，本篇評論旨在引導深度學習為基礎的認知功能障礙檢測系統的進一步發展，以改善早期診斷，並最終改善患者的治療結果。

##### **An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**
2410.17504v1 by Shruthi Chari

Explainable Artificial Intelligence (AI) focuses on helping humans understand
the working of AI systems or their decisions and has been a cornerstone of AI
for decades. Recent research in explainability has focused on explaining the
workings of AI models or model explainability. There have also been several
position statements and review papers detailing the needs of end-users for
user-centered explainability but fewer implementations. Hence, this thesis
seeks to bridge some gaps between model and user-centered explainability. We
create an explanation ontology (EO) to represent literature-derived explanation
types via their supporting components. We implement a knowledge-augmented
question-answering (QA) pipeline to support contextual explanations in a
clinical setting. Finally, we are implementing a system to combine explanations
from different AI methods and data modalities. Within the EO, we can represent
fifteen different explanation types, and we have tested these representations
in six exemplar use cases. We find that knowledge augmentations improve the
performance of base large language models in the contextualized QA, and the
performance is variable across disease groups. In the same setting, clinicians
also indicated that they prefer to see actionability as one of the main foci in
explanations. In our explanations combination method, we plan to use similarity
metrics to determine the similarity of explanations in a chronic disease
detection setting. Overall, through this thesis, we design methods that can
support knowledge-enabled explanations across different use cases, accounting
for the methods in today's AI era that can generate the supporting components
of these explanations and domain knowledge sources that can enhance them.

摘要：可解釋人工智慧（AI）專注於協助人類了解 AI 系統運作或其決策，數十年來一直是 AI 的基石。最近的可解釋性研究專注於解釋 AI 模型或模型可解釋性的運作。也有幾份立場聲明和評論論文詳細說明了最終使用者對以使用者為中心的可解釋性的需求，但實作較少。因此，本論文旨在彌補模型和以使用者為中心的可解釋性之間的一些差距。我們建立一個解釋本體（EO）以透過其支援元件來表示從文獻中衍生的解釋類型。我們實作一個知識增強的問答（QA）管線，以在臨床環境中支援情境解釋。最後，我們正在實作一個系統，以結合來自不同 AI 方法和資料模式的解釋。在 EO 中，我們可以表示 15 種不同的解釋類型，並且我們已在六個範例使用案例中測試這些表示。我們發現，知識增強改善了基礎大型語言模型在情境化 QA 中的效能，並且效能因疾病群組而異。在相同的環境中，臨床醫生也表示他們希望將可操作性視為解釋中的主要焦點之一。在我們的解釋組合方法中，我們計畫使用相似性指標來確定慢性病偵測環境中解釋的相似性。總體而言，透過本論文，我們設計了可以在不同使用案例中支援知識啟用解釋的方法，考量到當今 AI 時代中可以產生這些解釋的支援元件和可以增強這些解釋的領域知識來源的方法。

##### **Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**
2410.16879v1 by Lukas Hughes-Noehrer, Leda Channer, Gabriel Strain, Gregory Yates, Richard Body, Caroline Jay

Objectives: To investigate clinicians' attitudes towards current automated
interpretation of ECG and novel AI technologies and their perception of
computer-assisted interpretation. Materials and Methods: We conducted a series
of interviews with clinicians in the UK. Our study: (i) explores the potential
for AI, specifically future 'human-like' computing approaches, to facilitate
ECG interpretation and support clinical decision making, and (ii) elicits their
opinions about the importance of explainability and trustworthiness of AI
algorithms. Results: We performed inductive thematic analysis on interview
transcriptions from 23 clinicians and identified the following themes: (i) a
lack of trust in current systems, (ii) positive attitudes towards future AI
applications and requirements for these, (iii) the relationship between the
accuracy and explainability of algorithms, and (iv) opinions on education,
possible deskilling, and the impact of AI on clinical competencies. Discussion:
Clinicians do not trust current computerised methods, but welcome future 'AI'
technologies. Where clinicians trust future AI interpretation to be accurate,
they are less concerned that it is explainable. They also preferred ECG
interpretation that demonstrated the results of the algorithm visually. Whilst
clinicians do not fear job losses, they are concerned about deskilling and the
need to educate the workforce to use AI responsibly. Conclusion: Clinicians are
positive about the future application of AI in clinical decision-making.
Accuracy is a key factor of uptake and visualisations are preferred over
current computerised methods. This is viewed as a potential means of training
and upskilling, in contrast to the deskilling that automation might be
perceived to bring.

摘要：<paragraph>目的：調查臨床醫生對目前自動化心電圖解讀和新的人工智慧技術的態度，以及他們對電腦輔助解讀的看法。材料和方法：我們對英國的臨床醫生進行了一系列訪談。我們的研究：(i) 探討人工智慧的潛力，特別是未來的「類人類」運算方法，以促進心電圖解讀並支持臨床決策制定，以及 (ii) 徵求他們對人工智慧演算法的可解釋性和可信度的看法。結果：我們對 23 位臨床醫生的訪談記錄進行了歸納主題分析，並找出以下主題：(i) 對目前系統缺乏信任，(ii) 對未來人工智慧應用和對這些應用的要求持正面態度，(iii) 演算法的準確性和可解釋性之間的關係，以及 (iv) 對教育、可能的技能退化，以及人工智慧對臨床能力的影響的看法。討論：臨床醫生不信任目前的電腦化方法，但歡迎未來的「人工智慧」技術。在臨床醫生相信未來的 AI 解讀準確的情況下，他們不太擔心它是否可解釋。他們也比較喜歡能以視覺方式呈現演算法結果的心電圖解讀。雖然臨床醫生不害怕失業，但他們擔心技能退化，以及需要教育員工負責任地使用人工智慧。結論：臨床醫生對人工智慧在臨床決策制定中的未來應用持正面態度。準確性是採用人工智慧的一個關鍵因素，而視覺化比目前的電腦化方法更受青睞。這被視為一種潛在的培訓和提升技能的方法，與自動化可能帶來的技能退化形成對比。</paragraph>

##### **Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**
2410.15012v1 by Gesa Mittmann, Sara Laiouar-Pedari, Hendrik A. Mehrtens, Sarah Haggenmüller, Tabea-Clara Bucher, Tirtha Chanda, Nadine T. Gaisa, Mathias Wagner, Gilbert Georg Klamminger, Tilman T. Rau, Christina Neppl, Eva Maria Compérat, Andreas Gocht, Monika Hämmerle, Niels J. Rupp, Jula Westhoff, Irene Krücken, Maximillian Seidl, Christian M. Schürch, Marcus Bauer, Wiebke Solass, Yu Chun Tam, Florian Weber, Rainer Grobholz, Jaroslaw Augustyniak, Thomas Kalinski, Christian Hörner, Kirsten D. Mertz, Constanze Döring, Andreas Erbersdobler, Gabriele Deubler, Felix Bremmer, Ulrich Sommer, Michael Brodhun, Jon Griffin, Maria Sarah L. Lenon, Kiril Trpkov, Liang Cheng, Fei Chen, Angelique Levi, Guoping Cai, Tri Q. Nguyen, Ali Amin, Alessia Cimadamore, Ahmed Shabaik, Varsha Manucha, Nazeel Ahmad, Nidia Messias, Francesca Sanguedolce, Diana Taheri, Ezra Baraban, Liwei Jia, Rajal B. Shah, Farshid Siadat, Nicole Swarbrick, Kyung Park, Oudai Hassan, Siamak Sakhaie, Michelle R. Downes, Hiroshi Miyamoto, Sean R. Williamson, Tim Holland-Letz, Carolin V. Schneider, Jakob Nikolas Kather, Yuri Tolkach, Titus J. Brinker

The aggressiveness of prostate cancer, the most common cancer in men
worldwide, is primarily assessed based on histopathological data using the
Gleason scoring system. While artificial intelligence (AI) has shown promise in
accurately predicting Gleason scores, these predictions often lack inherent
explainability, potentially leading to distrust in human-machine interactions.
To address this issue, we introduce a novel dataset of 1,015 tissue microarray
core images, annotated by an international group of 54 pathologists. The
annotations provide detailed localized pattern descriptions for Gleason grading
in line with international guidelines. Utilizing this dataset, we develop an
inherently explainable AI system based on a U-Net architecture that provides
predictions leveraging pathologists' terminology. This approach circumvents
post-hoc explainability methods while maintaining or exceeding the performance
of methods trained directly for Gleason pattern segmentation (Dice score: 0.713
$\pm$ 0.003 trained on explanations vs. 0.691 $\pm$ 0.010 trained on Gleason
patterns). By employing soft labels during training, we capture the intrinsic
uncertainty in the data, yielding strong results in Gleason pattern
segmentation even in the context of high interobserver variability. With the
release of this dataset, we aim to encourage further research into segmentation
in medical tasks with high levels of subjectivity and to advance the
understanding of pathologists' reasoning processes.

摘要：前列腺癌是全球男性最常見的癌症，其惡性程度主要根據 Gleason 評分系統使用組織病理學數據進行評估。雖然人工智慧 (AI) 在準確預測 Gleason 評分方面已展現潛力，但這些預測通常缺乏內在的可解釋性，可能會導致對人機互動的不信任。為了解決這個問題，我們引進了一個由 54 位病理學家組成的國際團隊註解的 1,015 個組織微陣列核心影像的新穎資料集。這些註解提供了詳細的局部模式描述，用於符合國際準則的 Gleason 分級。利用這個資料集，我們開發了一個基於 U-Net 架構的內在可解釋 AI 系統，該系統提供了利用病理學家術語進行預測。這種方法規避了事後可解釋性方法，同時維持或超越了直接訓練用於 Gleason 模式分割的方法的效能（Dice 分數：0.713 ± 0.003，訓練於解釋，相對於 0.691 ± 0.010，訓練於 Gleason 模式）。透過在訓練期間採用軟標籤，我們捕捉了資料中的內在不確定性，即使在觀察者間變異性高的情況下，也能在 Gleason 模式分割中產生強大的結果。透過釋出這個資料集，我們旨在鼓勵進一步研究主觀性高的醫療任務中的分割，並增進對病理學家推理過程的理解。

##### **Explainable AI Methods for Multi-Omics Analysis: A Survey**
2410.11910v1 by Ahmad Hussein, Mukesh Prasad, Ali Braytee

Advancements in high-throughput technologies have led to a shift from
traditional hypothesis-driven methodologies to data-driven approaches.
Multi-omics refers to the integrative analysis of data derived from multiple
'omes', such as genomics, proteomics, transcriptomics, metabolomics, and
microbiomics. This approach enables a comprehensive understanding of biological
systems by capturing different layers of biological information. Deep learning
methods are increasingly utilized to integrate multi-omics data, offering
insights into molecular interactions and enhancing research into complex
diseases. However, these models, with their numerous interconnected layers and
nonlinear relationships, often function as black boxes, lacking transparency in
decision-making processes. To overcome this challenge, explainable artificial
intelligence (xAI) methods are crucial for creating transparent models that
allow clinicians to interpret and work with complex data more effectively. This
review explores how xAI can improve the interpretability of deep learning
models in multi-omics research, highlighting its potential to provide
clinicians with clear insights, thereby facilitating the effective application
of such models in clinical settings.

摘要：高通量技術的進步導致從傳統的假設驅動方法轉變為資料驅動的方法。多組學是指整合分析來自多個「組學」的資料，例如基因組學、蛋白質組學、轉錄組學、代謝組學和微生物組學。此方法透過擷取生物資訊的不同層面，能全面了解生物系統。深度學習方法愈來愈常被用於整合多組學資料，提供分子交互作用的洞察力，並加強對複雜疾病的研究。然而，這些模型具有許多相互連接的層級和非線性關係，通常會像黑盒子一樣運作，缺乏決策過程的透明度。為了克服此挑戰，可解釋人工智慧 (xAI) 方法對於建立透明模型至關重要，讓臨床醫生可以更有效地解釋和處理複雜資料。此評論探討 xAI 如何能改善多組學研究中深度學習模型的可解釋性，強調其提供臨床醫生明確見解的潛力，進而促進此類模型在臨床環境中的有效應用。

##### **Study on the Helpfulness of Explainable Artificial Intelligence**
2410.11896v1 by Tobias Labarta, Elizaveta Kulicheva, Ronja Froelian, Christian Geißler, Xenia Melman, Julian von Klitzing

Explainable Artificial Intelligence (XAI) is essential for building advanced
machine learning-powered applications, especially in critical domains such as
medical diagnostics or autonomous driving. Legal, business, and ethical
requirements motivate using effective XAI, but the increasing number of
different methods makes it challenging to pick the right ones. Further, as
explanations are highly context-dependent, measuring the effectiveness of XAI
methods without users can only reveal a limited amount of information,
excluding human factors such as the ability to understand it. We propose to
evaluate XAI methods via the user's ability to successfully perform a proxy
task, designed such that a good performance is an indicator for the explanation
to provide helpful information. In other words, we address the helpfulness of
XAI for human decision-making. Further, a user study on state-of-the-art
methods was conducted, showing differences in their ability to generate trust
and skepticism and the ability to judge the rightfulness of an AI decision
correctly. Based on the results, we highly recommend using and extending this
approach for more objective-based human-centered user studies to measure XAI
performance in an end-to-end fashion.

摘要：可解釋人工智慧 (XAI) 對於建構先進的機器學習驅動應用程式至關重要，特別是在醫療診斷或自動駕駛等關鍵領域。法律、商業和倫理要求促使使用有效的 XAI，但數量日益增加的不同方法使得挑選正確的方法具有挑戰性。此外，由於解釋高度依賴於背景，在沒有使用者的情況下衡量 XAI 方法的有效性只能揭示有限的資訊，排除人類因素，例如理解它的能力。我們建議透過使用者成功執行代理任務的能力來評估 XAI 方法，設計使得良好的執行表現是解釋提供有用資訊的指標。換句話說，我們探討 XAI 對人類決策制定的幫助。此外，對最先進的方法進行使用者研究，顯示出它們在產生信任和懷疑的能力以及正確判斷 AI 決策是否正確的能力方面存在差異。根據結果，我們強烈建議使用和擴充這種方法，以進行更多以目標為基礎的人為中心使用者研究，以終端到終端的方式衡量 XAI 效能。

##### **Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**
2410.09635v1 by Abdullah Mamun, Lawrence D. Devoe, Mark I. Evans, David W. Britt, Judith Klein-Seetharaman, Hassan Ghasemzadeh

Early detection of intrapartum risk enables interventions to potentially
prevent or mitigate adverse labor outcomes such as cerebral palsy. Currently,
there is no accurate automated system to predict such events to assist with
clinical decision-making. To fill this gap, we propose "Artificial Intelligence
(AI) for Modeling and Explaining Neonatal Health" (AIMEN), a deep learning
framework that not only predicts adverse labor outcomes from maternal, fetal,
obstetrical, and intrapartum risk factors but also provides the model's
reasoning behind the predictions made. The latter can provide insights into
what modifications in the input variables of the model could have changed the
predicted outcome. We address the challenges of imbalance and small datasets by
synthesizing additional training data using Adaptive Synthetic Sampling
(ADASYN) and Conditional Tabular Generative Adversarial Networks (CTGAN). AIMEN
uses an ensemble of fully-connected neural networks as the backbone for its
classification with the data augmentation supported by either ADASYN or CTGAN.
AIMEN, supported by CTGAN, outperforms AIMEN supported by ADASYN in
classification. AIMEN can predict a high risk for adverse labor outcomes with
an average F1 score of 0.784. It also provides counterfactual explanations that
can be achieved by changing 2 to 3 attributes on average. Resources available:
https://github.com/ab9mamun/AIMEN.

摘要：產程中風險的早期偵測有助於進行干預措施，以預防或減輕不利的生產結果，例如腦性麻痺。目前，沒有準確的自動化系統可以預測此類事件，以協助臨床決策。為了填補這一空白，我們提出「用於建模和解釋新生兒健康的人工智慧」(AIMEN)，這是一個深度學習架構，它不僅可以根據孕產婦、胎兒、產科和產程風險因素預測不利的生產結果，還能提供模型做出預測背後的原因。後者可以提供見解，說明模型輸入變數中的哪些修改可能會改變預測結果。我們透過使用適應性合成抽樣 (ADASYN) 和條件表格生成對抗網路 (CTGAN) 來合成額外的訓練資料，以解決不平衡和小型資料集的挑戰。AIMEN 使用全連接神經網路的集合作為其分類的骨幹，並透過 ADASYN 或 CTGAN 支援資料擴充。由 CTGAN 支援的 AIMEN 在分類方面優於由 ADASYN 支援的 AIMEN。AIMEN 可以預測不利的生產結果的高風險，平均 F1 分數為 0.784。它還提供反事實解釋，可透過平均變更 2 至 3 個屬性來達成。可用資源：https://github.com/ab9mamun/AIMEN。

##### **Artificial intelligence techniques in inherited retinal diseases: A review**
2410.09105v1 by Han Trinh, Jordan Vice, Jason Charng, Zahra Tajbakhsh, Khyber Alam, Fred K. Chen, Ajmal Mian

Inherited retinal diseases (IRDs) are a diverse group of genetic disorders
that lead to progressive vision loss and are a major cause of blindness in
working-age adults. The complexity and heterogeneity of IRDs pose significant
challenges in diagnosis, prognosis, and management. Recent advancements in
artificial intelligence (AI) offer promising solutions to these challenges.
However, the rapid development of AI techniques and their varied applications
have led to fragmented knowledge in this field. This review consolidates
existing studies, identifies gaps, and provides an overview of AI's potential
in diagnosing and managing IRDs. It aims to structure pathways for advancing
clinical applications by exploring AI techniques like machine learning and deep
learning, particularly in disease detection, progression prediction, and
personalized treatment planning. Special focus is placed on the effectiveness
of convolutional neural networks in these areas. Additionally, the integration
of explainable AI is discussed, emphasizing its importance in clinical settings
to improve transparency and trust in AI-based systems. The review addresses the
need to bridge existing gaps in focused studies on AI's role in IRDs, offering
a structured analysis of current AI techniques and outlining future research
directions. It concludes with an overview of the challenges and opportunities
in deploying AI for IRDs, highlighting the need for interdisciplinary
collaboration and the continuous development of robust, interpretable AI models
to advance clinical applications.

摘要：遺傳性視網膜疾病 (IRD) 是一組多樣化的遺傳疾病，
會導致視力逐漸喪失，是工作年齡成人失明的主要原因。IRD 的複雜性和異質性對診斷、預後和管理提出了重大挑戰。最近人工智能 (AI) 的進步為這些挑戰提供了有希望的解決方案。
然而，AI 技術的快速發展及其多種應用導致了該領域的知識分散。本綜述整合了現有研究，找出差距，並概述了 AI 在診斷和管理 IRD 中的潛力。它旨在通過探索機器學習和深度學習等 AI 技術，特別是在疾病檢測、進程預測和個性化治療計劃中，為推進臨床應用構建途徑。特別關注這些領域中卷積神經網路的有效性。此外，討論了可解釋 AI 的整合，強調了其在臨床環境中提高透明度和對基於 AI 的系統的信任的重要性。該綜述解決了彌合 AI 在 IRD 中作用的重點研究中現有差距的必要性，提供了對當前 AI 技術的結構化分析，並概述了未來的研究方向。最後概述了在 IRD 中部署 AI 的挑戰和機遇，強調了跨學科合作和持續開發強大、可解釋的 AI 模型以推進臨床應用的必要性。

##### **CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**
2410.05235v2 by Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri

Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.

摘要：解釋人工智慧 (AI) 的決策是現在 AI 的一項重大挑戰，特別是應用於像醫學和法律等敏感情境時。然而，解釋決策背後理由的需求也是基於人類的考量的一個主要問題，因為有必要證明為什麼做出某個決策。例如，住院醫師不僅需要提供（可能是正確的）診斷，還需要解釋他們如何達成某個結論。因此，開發新的工具來幫助住院醫師訓練他們的解釋技巧是教育中 AI 的一項核心目標。在本文中，我們遵循這個方向，並且根據我們的了解，提出第一個多語言醫學問答資料集，其中臨床病例的正確和不正確診斷都附有由醫生撰寫的自然語言解釋。這些解釋已使用論證組成（即前提、主張）和論證關係（即攻擊、支持）進行手動註解，產生多語言 CasiMedicos-Arg 資料集，其中包含 558 個具有解釋的四種語言（英語、西班牙語、法語、義大利語）的臨床病例，我們註解了 5021 個主張、2313 個前提、2431 個支持關係和 1106 個攻擊關係。我們最後展示了競爭基準如何針對論證探勘任務執行此具挑戰性的資料集。

##### **Explainable Diagnosis Prediction through Neuro-Symbolic Integration**
2410.01855v1 by Qiuhao Lu, Rui Li, Elham Sagheb, Andrew Wen, Jinlian Wang, Liwei Wang, Jungwei W. Fan, Hongfang Liu

Diagnosis prediction is a critical task in healthcare, where timely and
accurate identification of medical conditions can significantly impact patient
outcomes. Traditional machine learning and deep learning models have achieved
notable success in this domain but often lack interpretability which is a
crucial requirement in clinical settings. In this study, we explore the use of
neuro-symbolic methods, specifically Logical Neural Networks (LNNs), to develop
explainable models for diagnosis prediction. Essentially, we design and
implement LNN-based models that integrate domain-specific knowledge through
logical rules with learnable thresholds. Our models, particularly
$M_{\text{multi-pathway}}$ and $M_{\text{comprehensive}}$, demonstrate superior
performance over traditional models such as Logistic Regression, SVM, and
Random Forest, achieving higher accuracy (up to 80.52\%) and AUROC scores (up
to 0.8457) in the case study of diabetes prediction. The learned weights and
thresholds within the LNN models provide direct insights into feature
contributions, enhancing interpretability without compromising predictive
power. These findings highlight the potential of neuro-symbolic approaches in
bridging the gap between accuracy and explainability in healthcare AI
applications. By offering transparent and adaptable diagnostic models, our work
contributes to the advancement of precision medicine and supports the
development of equitable healthcare solutions. Future research will focus on
extending these methods to larger and more diverse datasets to further validate
their applicability across different medical conditions and populations.

摘要：診斷預測是醫療保健中的一項關鍵任務，及時且準確地識別醫療狀況會對患者的結果產生重大影響。傳統機器學習和深度學習模型已在此領域取得顯著成功，但通常缺乏可解釋性，這是臨床環境中的關鍵要求。在本研究中，我們探討了神經符號方法，特別是邏輯神經網路 (LNN)，以開發可解釋的診斷預測模型。基本上，我們設計並實作了基於 LNN 的模型，該模型透過邏輯規則和可學習的閾值整合領域特定的知識。我們的模型，特別是 $M_{\text{multi-pathway}}$ 和 $M_{\text{comprehensive}}$，表現出優於傳統模型（如邏輯迴歸、SVM 和隨機森林）的卓越效能，在糖尿病預測的案例研究中，達到了更高的準確度（高達 80.52%）和 AUROC 分數（高達 0.8457）。LNN 模型中學習的權重和閾值提供了對特徵貢獻的直接見解，增強了可解釋性，同時不損害預測能力。這些發現突顯了神經符號方法在彌合醫療保健 AI 應用中準確性和可解釋性差距方面的潛力。透過提供透明且適應性強的診斷模型，我們的研究有助於精準醫療的進步，並支援公平醫療保健解決方案的開發。未來的研究將專注於將這些方法擴展到更大且更多樣化的資料集，以進一步驗證其在不同醫療狀況和人群中的適用性。

##### **Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**
2410.00366v1 by Prasenjit Maji, Amit Kumar Mondal, Hemanta Kumar Mondal, Saraju P. Mohanty

The rapid advancements in artificial intelligence (AI) have revolutionized
smart healthcare, driving innovations in wearable technologies, continuous
monitoring devices, and intelligent diagnostic systems. However, security,
explainability, robustness, and performance optimization challenges remain
critical barriers to widespread adoption in clinical environments. This
research presents an innovative algorithmic method using the Adaptive Feature
Evaluator (AFE) algorithm to improve feature selection in healthcare datasets
and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable
Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT),
the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby
enhancing predictive accuracy and interpretability. The proposed method is
validated across three diverse healthcare datasets using six distinct machine
learning algorithms, demonstrating its robustness and superiority over
conventional feature selection techniques. The results underscore the
transformative potential of AFE in smart healthcare, enabling personalized and
transparent patient care. Notably, the AFE algorithm, when combined with a
Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting
its capability to improve clinical decision-making processes in real-world
healthcare applications.

摘要：人工智慧 (AI) 的快速進展徹底改變了智慧醫療保健，推動了可穿戴技術、持續監控裝置和智慧診斷系統的創新。然而，安全性、可解釋性、穩健性和效能最佳化挑戰仍然是臨床環境中廣泛採用的關鍵障礙。本研究提出一個創新的演算法方法，使用自適應特徵評估器 (AFE) 演算法來改善醫療保健資料集中的特徵選取並克服問題。AFE 整合了遺傳演算法 (GA)、可解釋人工智慧 (XAI) 和排列組合技術 (PCT)，該演算法最佳化了臨床決策支援系統 (CDSS)，從而提高了預測準確性和可解釋性。所提出的方法使用六種不同的機器學習演算法驗證了三個不同的醫療保健資料集，證明了其穩健性和優於傳統特徵選取技術。結果強調了 AFE 在智慧醫療保健中的轉變潛力，實現了個人化和透明的患者照護。值得注意的是，AFE 演算法與多層感知器 (MLP) 結合使用時，準確度高達 98.5%，突顯了其改善實際醫療保健應用中臨床決策制定流程的能力。

##### **Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**
2409.13476v1 by Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker

Artificial intelligence (AI) systems have substantially improved
dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI)
systems further enhancing clinicians' confidence and trust in AI-driven
decisions. Despite these advancements, there remains a critical need for
objective evaluation of how dermatologists engage with both AI and XAI tools.
In this study, 76 dermatologists participated in a reader study, diagnosing 16
dermoscopic images of melanomas and nevi using an XAI system that provides
detailed, domain-specific explanations. Eye-tracking technology was employed to
assess their interactions. Diagnostic performance was compared with that of a
standard AI system lacking explanatory features. Our findings reveal that XAI
systems improved balanced diagnostic accuracy by 2.8 percentage points relative
to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and
complex lesions were associated with elevated cognitive load, as evidenced by
increased ocular fixations. These insights have significant implications for
clinical practice, the design of AI tools for visual tasks, and the broader
development of XAI in medical diagnostics.

摘要：人工智慧 (AI) 系統已大幅改善皮膚科醫師對黑色素瘤的診斷準確度，而可解釋 AI (XAI) 系統進一步提升臨床醫師對 AI 驅動決策的信心與信賴。儘管有這些進展，對於皮膚科醫師如何使用 AI 和 XAI 工具，仍有客觀評估的迫切需求。在這項研究中，76 位皮膚科醫師參與了一項讀者研究，使用 XAI 系統診斷 16 張黑色素瘤和痣的皮膚鏡影像，該系統提供詳細的領域特定說明。採用眼球追蹤技術來評估他們的互動。將診斷表現與缺乏說明功能的標準 AI 系統進行比較。我們的研究結果顯示，XAI 系統相較於標準 AI，將平衡診斷準確度提升了 2.8 個百分點。此外，與 AI/XAI 系統的診斷分歧和複雜的病灶與認知負擔升高有關，這由增加的眼睛注視次數所證實。這些見解對臨床實務、視覺任務 AI 工具的設計和醫學診斷中 XAI 的廣泛發展具有重大意義。

##### **Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**
2409.15374v1 by Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar

Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been
shown to significantly improve the quality of life of autistic individuals.
However, diagnostics methods for ASD rely on assessments based on clinical
presentation that are prone to bias and can be challenging to arrive at an
early diagnosis. There is a need for objective biomarkers of ASD which can help
improve diagnostic accuracy. Deep learning (DL) has achieved outstanding
performance in diagnosing diseases and conditions from medical imaging data.
Extensive research has been conducted on creating models that classify ASD
using resting-state functional Magnetic Resonance Imaging (fMRI) data. However,
existing models lack interpretability. This research aims to improve the
accuracy and interpretability of ASD diagnosis by creating a DL model that can
not only accurately classify ASD but also provide explainable insights into its
working. The dataset used is a preprocessed version of the Autism Brain Imaging
Data Exchange (ABIDE) with 884 samples. Our findings show a model that can
accurately classify ASD and highlight critical brain regions differing between
ASD and typical controls, with potential implications for early diagnosis and
understanding of the neural basis of ASD. These findings are validated by
studies in the literature that use different datasets and modalities,
confirming that the model actually learned characteristics of ASD and not just
the dataset. This study advances the field of explainable AI in medical imaging
by providing a robust and interpretable model, thereby contributing to a future
with objective and reliable ASD diagnostics.

摘要：自閉症譜系障礙 (ASD) 的早期診斷和介入已被證實能顯著改善自閉症患者的生活品質。然而，ASD 的診斷方法依賴於基於臨床表現的評估，容易產生偏見，且可能難以做出早期診斷。有必要找出 ASD 的客觀生物標記，以幫助提高診斷準確性。深度學習 (DL) 在從醫學影像資料診斷疾病和病症方面取得傑出的表現。已經針對建立使用靜態功能性磁振造影 (fMRI) 資料對 ASD 進行分類的模型進行廣泛的研究。然而，現有的模型缺乏可解釋性。本研究旨在透過建立一個不僅能準確分類 ASD，還能提供可解釋見解說明其運作原理的 DL 模型，來改善 ASD 診斷的準確性和可解釋性。所使用的資料集是自閉症大腦影像資料交換 (ABIDE) 的預處理版本，包含 884 個樣本。我們的研究結果顯示，該模型能準確分類 ASD，並強調 ASD 與典型對照組之間存在差異的關鍵腦區，對於 ASD 的早期診斷和神經基礎的理解具有潛在的意義。這些研究結果已由使用不同資料集和方式的文獻研究驗證，證實該模型實際上學習了 ASD 的特徵，而不僅僅是資料集。本研究透過提供一個強健且可解釋的模型，推動了醫學影像中可解釋 AI 的領域，從而為未來提供客觀且可靠的 ASD 診斷做出貢獻。

##### **Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**
2409.12883v1 by Daniel Flores-Araiza, Francisco Lopez-Tiro, Clément Larose, Salvador Hinojosa, Andres Mendez-Vazquez, Miguel Gonzalez-Mendoza, Gilberto Ochoa-Ruiz, Christian Daul

The in-vivo identification of the kidney stone types during an ureteroscopy
would be a major medical advance in urology, as it could reduce the time of the
tedious renal calculi extraction process, while diminishing infection risks.
Furthermore, such an automated procedure would make possible to prescribe
anti-recurrence treatments immediately. Nowadays, only few experienced
urologists are able to recognize the kidney stone types in the images of the
videos displayed on a screen during the endoscopy. Thus, several deep learning
(DL) models have recently been proposed to automatically recognize the kidney
stone types using ureteroscopic images. However, these DL models are of black
box nature whicl limits their applicability in clinical settings. This
contribution proposes a case-based reasoning DL model which uses prototypical
parts (PPs) and generates local and global descriptors. The PPs encode for each
class (i.e., kidney stone type) visual feature information (hue, saturation,
intensity and textures) similar to that used by biologists. The PPs are
optimally generated due a new loss function used during the model training.
Moreover, the local and global descriptors of PPs allow to explain the
decisions ("what" information, "where in the images") in an understandable way
for biologists and urologists. The proposed DL model has been tested on a
database including images of the six most widespread kidney stone types. The
overall average classification accuracy was 90.37. When comparing this results
with that of the eight other DL models of the kidney stone state-of-the-art, it
can be seen that the valuable gain in explanability was not reached at the
expense of accuracy which was even slightly increased with respect to that
(88.2) of the best method of the literature. These promising and interpretable
results also encourage urologists to put their trust in AI-based solutions.

摘要：尿路鏡檢查中腎結石類型的體內識別將是泌尿科的一項重大進展，因為它可以減少繁瑣的腎結石取出過程的時間，同時降低感染風險。此外，這種自動化程序將使立即開立抗復發治療成為可能。如今，只有少數經驗豐富的泌尿科醫生能夠在內視鏡檢查期間屏幕上顯示的視頻圖像中識別腎結石類型。因此，最近已提出多種深度學習 (DL) 模型，以使用輸尿管鏡圖像自動識別腎結石類型。然而，這些 DL 模型本質上是黑盒子，這限制了它們在臨床環境中的應用性。本文提出了一個基於案例推理的 DL 模型，它使用原型部分 (PP) 並生成局部和全局描述符。PP 為每種類型（即腎結石類型）編碼視覺特徵信息（色調、飽和度、強度和紋理），類似於生物學家使用的信息。由於在模型訓練期間使用的新損失函數，PP 得到了最佳生成。此外，PP 的局部和全局描述符允許以生物學家和泌尿科醫生可以理解的方式解釋決策（“什麼”信息，“圖像中的什麼位置”）。所提出的 DL 模型已在一個包含六種最廣泛的腎結石類型圖像的數據庫上進行了測試。總體平均分類準確率為 90.37。將此結果與腎結石最先進的八個其他 DL 模型的結果進行比較時，可以看出，可解釋性的寶貴增益並未以準確性為代價，甚至略有增加與文獻中最好的方法 (88.2) 相比。這些有希望且可解釋的結果也鼓勵泌尿科醫生相信基於人工智能的解決方案。

##### **Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**
2409.12087v3 by Yubo Li, Saba Al-Sayouri, Rema Padman

This study explores the potential of utilizing administrative claims data,
combined with advanced machine learning and deep learning techniques, to
predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal
Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major
health insurance organization to develop prediction models for multiple
observation windows using traditional machine learning methods such as Random
Forest and XGBoost as well as deep learning approaches such as Long Short-Term
Memory (LSTM) networks. Our findings demonstrate that the LSTM model,
particularly with a 24-month observation window, exhibits superior performance
in predicting ESRD progression, outperforming existing models in the
literature. We further apply SHapley Additive exPlanations (SHAP) analysis to
enhance interpretability, providing insights into the impact of individual
features on predictions at the individual patient level. This study underscores
the value of leveraging administrative claims data for CKD management and
predicting ESRD progression.

摘要：本研究探討利用行政申報資料，結合先進機器學習與深度學習技術，預測慢性腎臟病 (CKD) 進展至末期腎臟疾病 (ESRD) 的可能性。我們分析一家大型健康保險組織提供的 10 年綜合資料集，使用傳統機器學習方法（例如隨機森林和 XGBoost）以及深度學習方法（例如長期短期記憶 (LSTM) 網路）開發多個觀察視窗的預測模型。我們的研究結果顯示，LSTM 模型（尤其是 24 個月觀察視窗）在預測 ESRD 進展方面表現優異，優於文獻中的現有模型。我們進一步應用 SHapley 可加性解釋 (SHAP) 分析以增強可解釋性，深入了解個別特徵對個別患者層級預測的影響。本研究強調了利用行政申報資料進行 CKD 管理和預測 ESRD 進展的價值。

##### **Explainable AI: Definition and attributes of a good explanation for health AI**
2409.15338v1 by Evangelia Kyrimi, Scott McLachlan, Jared M Wohlgemut, Zane B Perkins, David A. Lagnado, William Marsh, the ExAIDSS Expert Group

Proposals of artificial intelligence (AI) solutions based on increasingly
complex and accurate predictive models are becoming ubiquitous across many
disciplines. As the complexity of these models grows, transparency and users'
understanding often diminish. This suggests that accurate prediction alone is
insufficient for making an AI-based solution truly useful. In the development
of healthcare systems, this introduces new issues related to accountability and
safety. Understanding how and why an AI system makes a recommendation may
require complex explanations of its inner workings and reasoning processes.
Although research on explainable AI (XAI) has significantly increased in recent
years and there is high demand for XAI in medicine, defining what constitutes a
good explanation remains ad hoc, and providing adequate explanations continues
to be challenging. To fully realize the potential of AI, it is critical to
address two fundamental questions about explanations for safety-critical AI
applications, such as health-AI: (1) What is an explanation in health-AI? and
(2) What are the attributes of a good explanation in health-AI? In this study,
we examined published literature and gathered expert opinions through a
two-round Delphi study. The research outputs include (1) a definition of what
constitutes an explanation in health-AI and (2) a comprehensive list of
attributes that characterize a good explanation in health-AI.

摘要：隨著越來越複雜且準確的預測模型，基於人工智慧 (AI) 解決方案的提案在許多領域中變得無處不在。隨著這些模型複雜性的增加，透明度和使用者的理解力往往會降低。這表示僅有準確的預測並不足以讓 AI 解決方案真正有用。在醫療保健系統的開發中，這引入了與問責制和安全性相關的新問題。瞭解 AI 系統如何以及為何提出建議可能需要對其內部運作和推理過程進行複雜的說明。儘管近年來對可解釋 AI (XAI) 的研究已大幅增加，且醫學領域對 XAI 有很高的需求，但定義什麼構成一個好的解釋仍是臨時性的，而提供適當的解釋仍然具有挑戰性。為了充分發揮 AI 的潛力，對於安全關鍵型 AI 應用（例如健康 AI）的解釋，探討兩個基本問題至關重要：(1) 什麼是健康 AI 中的解釋？以及 (2) 健康 AI 中一個好的解釋有哪些屬性？在本研究中，我們檢視了已發表的文獻，並透過兩輪德爾菲研究收集了專家意見。研究成果包括：(1) 健康 AI 中什麼構成解釋的定義，以及 (2) 健康 AI 中一個好解釋的屬性清單。

##### **Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**
2408.17401v1 by Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni

In recent years, various methods have been introduced for explaining the
outputs of "black-box" AI models. However, it is not well understood whether
users actually comprehend and trust these explanations. In this paper, we focus
on explanations for a regression tool for assessing cancer risk and examine the
effect of the explanations' content and format on the user-centric metrics of
comprehension and trust. Regarding content, we experiment with two explanation
methods: the popular SHAP, based on game-theoretic notions and thus potentially
complex for everyday users to comprehend, and occlusion-1, based on feature
occlusion which may be more comprehensible. Regarding format, we present SHAP
explanations as charts (SC), as is conventional, and occlusion-1 explanations
as charts (OC) as well as text (OT), to which their simpler nature also lends
itself. The experiments amount to user studies questioning participants, with
two different levels of expertise (the general population and those with some
medical training), on their subjective and objective comprehension of and trust
in explanations for the outputs of the regression tool. In both studies we
found a clear preference in terms of subjective comprehension and trust for
occlusion-1 over SHAP explanations in general, when comparing based on content.
However, direct comparisons of explanations when controlling for format only
revealed evidence for OT over SC explanations in most cases, suggesting that
the dominance of occlusion-1 over SHAP explanations may be driven by a
preference for text over charts as explanations. Finally, we found no evidence
of a difference between the explanation types in terms of objective
comprehension. Thus overall, the choice of the content and format of
explanations needs careful attention, since in some contexts format, rather
than content, may play the critical role in improving user experience.

摘要：<paragraph>近年來，已經引進各種方法來解釋「黑箱」AI 模型的輸出。然而，目前並不清楚使用者是否實際理解和信任這些解釋。在本文中，我們專注於評估癌症風險的回歸工具的解釋，並探討解釋的內容和格式對以使用者為中心的理解和信任指標的影響。關於內容，我們實驗了兩種解釋方法：流行的 SHAP，基於博弈論概念，因此對於日常使用者來說可能很複雜，以及基於特徵遮蔽的 occlusion-1，可能更易於理解。關於格式，我們將 SHAP 解釋呈現為圖表 (SC)，這是慣例，而將 occlusion-1 解釋呈現為圖表 (OC) 以及文字 (OT)，其較為簡單的性質也適用於此。這些實驗等同於使用者研究，詢問參與者，具有兩種不同程度的專業知識（一般民眾和具備一些醫學訓練的人），他們對回歸工具輸出解釋的主觀和客觀理解和信任。在兩項研究中，我們發現，在基於內容進行比較時，一般來說，occlusion-1 優於 SHAP 解釋，在主觀理解和信任方面有明顯的偏好。然而，在僅控制格式的情況下直接比較解釋，在大多數情況下只顯示 OT 優於 SC 解釋的證據，這表明 occlusion-1 優於 SHAP 解釋的主導地位可能是由偏好文字而非圖表作為解釋所驅動的。最後，我們沒有發現解釋類型在客觀理解方面的差異證據。因此，總體而言，對解釋的內容和格式的選擇需要仔細注意，因為在某些情況下，格式而非內容，可能在改善使用者體驗方面發揮關鍵作用。</paragraph>

##### **A Survey for Large Language Models in Biomedicine**
2409.00133v1 by Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro Liò, Tianyun Wang, Yu Guang Wang, Yiqing Shen

Recent breakthroughs in large language models (LLMs) offer unprecedented
natural language understanding and generation capabilities. However, existing
surveys on LLMs in biomedicine often focus on specific applications or model
architectures, lacking a comprehensive analysis that integrates the latest
advancements across various biomedical domains. This review, based on an
analysis of 484 publications sourced from databases including PubMed, Web of
Science, and arXiv, provides an in-depth examination of the current landscape,
applications, challenges, and prospects of LLMs in biomedicine, distinguishing
itself by focusing on the practical implications of these models in real-world
biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot
learning across a broad spectrum of biomedical tasks, including diagnostic
assistance, drug discovery, and personalized medicine, among others, with
insights drawn from 137 key studies. Then, we discuss adaptation strategies of
LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to
enhance their performance in specialized biomedical contexts where zero-shot
fails to achieve, such as medical question answering and efficient processing
of biomedical literature. Finally, we discuss the challenges that LLMs face in
the biomedicine domain including data privacy concerns, limited model
interpretability, issues with dataset quality, and ethics due to the sensitive
nature of biomedical data, the need for highly reliable model outputs, and the
ethical implications of deploying AI in healthcare. To address these
challenges, we also identify future research directions of LLM in biomedicine
including federated learning methods to preserve data privacy and integrating
explainable AI methodologies to enhance the transparency of LLMs.

摘要：大型語言模型 (LLM) 的最新突破提供了前所未有的自然語言理解和生成能力。然而，現有關於生物醫學中 LLM 的調查通常專注於特定應用或模型架構，缺乏整合各種生物醫學領域最新進展的全面分析。本綜述基於對來自 PubMed、Web of Science 和 arXiv 等數據庫的 484 篇出版物的分析，深入探討了生物醫學中 LLM 的當前現況、應用、挑戰和前景，其特點是關注這些模型在現實世界生物醫學背景中的實際應用。首先，我們探討了 LLM 在廣泛的生物醫學任務中的零次學習能力，包括診斷輔助、藥物發現和個性化醫療等，並從 137 項關鍵研究中汲取見解。然後，我們討論了 LLM 的適應策略，包括單模態和多模態 LLM 的微調方法，以增強它們在零次學習無法實現的專業生物醫學背景中的性能，例如醫療問題解答和生物醫學文獻的有效處理。最後，我們討論了 LLM 在生物醫學領域面臨的挑戰，包括數據隱私問題、模型可解釋性有限、數據集質量問題以及由於生物醫學數據的敏感性、對高度可靠模型輸出的需求以及在醫療保健中部署 AI 的倫理影響而產生的倫理問題。為了應對這些挑戰，我們還確定了生物醫學中 LLM 未來的研究方向，包括用於保護數據隱私的聯合學習方法以及整合可解釋 AI 方法以增強 LLM 的透明度。

##### **Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**
2408.15121v1 by Francesco Sovrano, Michael Lognoul, Giulia Vilone

Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.

摘要：人工智慧（AI）在醫療和保健應用中投入了大量的投資和開發，進而導致醫療技術中的先進控制系統。然而，AI 系統的不透明性引發了對此類敏感應用中所需基本特性的擔憂，例如透明度和可信度。我們的研究透過調查一個程序來解決這些問題，用於選擇最充分的可解釋 AI（XAI）方法，以符合歐盟法規在醫療器材的智慧型生物電子學中的說明要求。採用的方法從透過其控制機制（開迴路、閉迴路和半閉迴路系統）對智慧型裝置進行分類，並深入探討其技術開始。然後，我們分析這些法規以定義其對各種裝置和相關目標的可解釋性要求。同時，我們透過其說明目標對 XAI 方法進行分類。這允許將法律可解釋性要求與 XAI 說明目標相匹配，並確定適當的 XAI 演算法來達成它們。我們的研究結果提供了對哪些 XAI 演算法更符合歐盟法規以適用於不同類型的醫療器材的細緻理解。我們透過不同神經植入物的實際案例研究來證明這一點，從慢性疾病管理到先進的義肢。這項研究填補了將生物電子學中的 XAI 應用與歐盟法規的嚴格規定相符的重要空白。它為開發人員和研究人員提供了一個實用的架構，確保其 AI 創新能促進醫療技術並遵守法律和道德標準。

##### **Towards Case-based Interpretability for Medical Federated Learning**
2408.13626v1 by Laura Latorre, Liliana Petrychenko, Regina Beets-Tan, Taisiya Kopytova, Wilson Silva

We explore deep generative models to generate case-based explanations in a
medical federated learning setting. Explaining AI model decisions through
case-based interpretability is paramount to increasing trust and allowing
widespread adoption of AI in clinical practice. However, medical AI training
paradigms are shifting towards federated learning settings in order to comply
with data protection regulations. In a federated scenario, past data is
inaccessible to the current user. Thus, we use a deep generative model to
generate synthetic examples that protect privacy and explain decisions. Our
proof-of-concept focuses on pleural effusion diagnosis and uses publicly
available Chest X-ray data.

摘要：我們探索深度生成模型，在醫療聯邦學習設置中生成基於案例的說明。透過基於案例的可解釋性來解釋 AI 模型決策，對於增加信任並允許 AI 在臨床實務中廣泛採用至關重要。然而，醫療 AI 訓練範例正轉向聯邦學習設置，以符合資料保護法規。在聯邦情境中，過去的資料對目前的使用者而言是無法取得的。因此，我們使用深度生成模型來產生保護隱私和解釋決策的合成範例。我們的概念驗證著重於胸腔積液診斷，並使用公開可取得的胸部 X 光資料。

##### **AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**
2408.12491v1 by Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, Jacob J. Visser, Robert Hemke, Kirsten van Langevelde, David F. Hanff, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. Gruühagen, Wiro J. Niessen, Stefan Klein, Martijn P. A. Starmans

Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging
lesions with variable clinical behaviours and treatment approaches. This
systematic review provides an overview of Artificial Intelligence (AI) methods
using radiological imaging for diagnosis and prognosis of these tumours,
highlighting challenges in clinical translation, and evaluating study alignment
with the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI
international consensus guidelines for trustworthy and deployable AI to promote
the clinical translation of AI methods. The review covered literature from
several bibliographic databases, including papers published before 17/07/2024.
Original research in peer-reviewed journals focused on radiology-based AI for
diagnosing or prognosing primary STBT was included. Exclusion criteria were
animal, cadaveric, or laboratory studies, and non-English papers. Abstracts
were screened by two of three independent reviewers for eligibility. Eligible
papers were assessed against guidelines by one of three independent reviewers.
The search identified 15,015 abstracts, from which 325 articles were included
for evaluation. Most studies performed moderately on CLAIM, averaging a score
of 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 out
of 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,
indicating significant room for improvement. Future efforts by AI developers
should focus on design (e.g. define unmet clinical need, intended clinical
setting and how AI would be integrated in clinical workflow), development (e.g.
build on previous work, explainability), evaluation (e.g. evaluating and
addressing biases, evaluating AI against best practices), and data
reproducibility and availability (making documented code and data publicly
available). Following these recommendations could improve clinical translation
of AI methods.

摘要：軟組織和骨骼腫瘤（STBT）是罕見、診斷具有挑戰性的病灶，其臨床行為和治療方法各不相同。這篇系統性回顧提供了使用放射影像進行診斷和預後的人工智慧 (AI) 方法的概觀，重點說明了臨床轉譯的挑戰，並評估研究與醫療影像 AI 核查表 (CLAIM) 和 FUTURE-AI 可信賴且可部署 AI 的國際共識準則的一致性，以促進 AI 方法的臨床轉譯。這篇回顧涵蓋了幾個書目資料庫中的文獻，包括在 2024 年 7 月 17 日之前發表的論文。納入了以放射為基礎的 AI 診斷或預後原發性 STBT 的同行評審期刊中的原始研究。排除標準是動物、屍體或實驗室研究，以及非英文論文。摘要由三位獨立審查員中的兩位篩選資格。合格的論文由三位獨立審查員中的一位根據準則進行評估。搜索識別出 15,015 篇摘要，其中 325 篇文章被納入評估。大多數研究在 CLAIM 中表現中等，平均得分為 53 分中的 28.9±7.5 分，但在 FUTURE-AI 中表現不佳，平均得分為 30 分中的 5.1±2.1 分。STBT 的影像 AI 工具仍處於概念驗證階段，表明有顯著的改進空間。AI 開發人員未來的努力應集中在設計（例如定義未滿足的臨床需求、預期的臨床環境以及 AI 如何整合到臨床工作流程中）、開發（例如建立在先前的工作、可解釋性）、評估（例如評估和解決偏差、評估 AI 與最佳實務）、以及數據可複製性和可用性（公開提供文件化的代碼和數據）。遵循這些建議可以改善 AI 方法的臨床轉譯。

##### **Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**
2409.00001v1 by Kimji N. Pellano, Inga Strümke, Daniel Groos, Lars Adde, Espen Alexander F. Ihlen

Early detection of Cerebral Palsy (CP) is crucial for effective intervention
and monitoring. This paper tests the reliability and applicability of
Explainable AI (XAI) methods using a deep learning method that predicts CP by
analyzing skeletal data extracted from video recordings of infant movements.
Specifically, we use XAI evaluation metrics -- namely faithfulness and
stability -- to quantitatively assess the reliability of Class Activation
Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this
specific medical application. We utilize a unique dataset of infant movements
and apply skeleton data perturbations without distorting the original dynamics
of the infant movements. Our CP prediction model utilizes an ensemble approach,
so we evaluate the XAI metrics performances for both the overall ensemble and
the individual models. Our findings indicate that both XAI methods effectively
identify key body points influencing CP predictions and that the explanations
are robust against minor data perturbations. Grad-CAM significantly outperforms
CAM in the RISv metric, which measures stability in terms of velocity. In
contrast, CAM performs better in the RISb metric, which relates to bone
stability, and the RRS metric, which assesses internal representation
robustness. Individual models within the ensemble show varied results, and
neither CAM nor Grad-CAM consistently outperform the other, with the ensemble
approach providing a representation of outcomes from its constituent models.

摘要：腦性麻痺 (CP) 的早期偵測對於有效的介入和監測至關重要。本文測試了可解釋 AI (XAI) 方法的可靠性和適用性，使用深度學習方法，透過分析從嬰兒動作影片記錄中提取的骨骼資料來預測 CP。具體來說，我們使用 XAI 評估指標（即忠實度和穩定性）來量化評估類別激活映射 (CAM) 和梯度加權類別激活映射 (Grad-CAM) 在這個特定醫療應用中的可靠性。我們利用一個獨特的嬰兒動作資料集，並應用骨骼資料擾動，而不會扭曲嬰兒動作的原始動力。我們的 CP 預測模型利用整體方法，因此我們評估了整體整體和個別模型的 XAI 指標表現。我們的研究結果表明，兩種 XAI 方法都能有效識別影響 CP 預測的關鍵身體部位，並且這些解釋對於微小的資料擾動具有魯棒性。Grad-CAM 在 RISv 指標中顯著優於 CAM，該指標衡量速度方面的穩定性。相比之下，CAM 在 RISb 指標中表現得更好，該指標與骨骼穩定性有關，而 RRS 指標則評估內部表示的魯棒性。整體中的個別模型顯示出不同的結果，CAM 和 Grad-CAM 都不一致地優於另一種，整體方法提供了其組成模型結果的表示。

##### **MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**
2408.11837v1 by Hanchen David Wang, Nibraas Khan, Anna Chen, Nilanjan Sarkar, Pamela Wisniewski, Meiyi Ma

Recent global estimates suggest that as many as 2.41 billion individuals have
health conditions that would benefit from rehabilitation services. Home-based
Physical Therapy (PT) faces significant challenges in providing interactive
feedback and meaningful observation for therapists and patients. To fill this
gap, we present MicroXercise, which integrates micro-motion analysis with
wearable sensors, providing therapists and patients with a comprehensive
feedback interface, including video, text, and scores. Crucially, it employs
multi-dimensional Dynamic Time Warping (DTW) and attribution-based explainable
methods to analyze the existing deep learning neural networks in monitoring
exercises, focusing on a high granularity of exercise. This synergistic
approach is pivotal, providing output matching the input size to precisely
highlight critical subtleties and movements in PT, thus transforming complex AI
analysis into clear, actionable feedback. By highlighting these micro-motions
in different metrics, such as stability and range of motion, MicroXercise
significantly enhances the understanding and relevance of feedback for
end-users. Comparative performance metrics underscore its effectiveness over
traditional methods, such as a 39% and 42% improvement in Feature Mutual
Information (FMI) and Continuity. MicroXercise is a step ahead in home-based
physical therapy, providing a technologically advanced and intuitively helpful
solution to enhance patient care and outcomes.

摘要：最近的全球估計表明，多達 24.1 億人有
健康狀況可從復健服務中受益。居家
物理治療 (PT) 在提供互動式
回饋和有意義的觀察方面面臨重大挑戰，供治療師和患者使用。為了填補這
個缺口，我們提出 MicroXercise，它將微動作分析與
可穿戴式感測器整合在一起，為治療師和患者提供一個全面的
回饋介面，包括影片、文字和分數。至關重要的是，它採用
多維動態時間規整 (DTW) 和基於歸因的可解釋
方法來分析監控運動中現有的深度學習神經網路，專注於運動的高粒度。這種協同
方法至關重要，提供與輸入大小匹配的輸出，以精確地
突出 PT 中關鍵的細微差別和動作，從而將複雜的 AI
分析轉換為清晰、可操作的回饋。透過在不同指標中突顯這些微動作，例如穩定性和動作範圍，MicroXercise
顯著提升最終使用者對回饋的理解和相關性。比較效能指標強調其優於
傳統方法的有效性，例如特徵互惠資訊 (FMI) 和連續性分別提升了 39% 和 42%。MicroXercise 在居家
物理治療方面更進一步，提供技術先進且直覺有用的
解決方案，以提升患者照護和結果。

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah Rösman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

摘要：系統性文獻回顧是研究中證據品質最高的。然而，回顧過程受到顯著資源和資料限制的阻礙。文獻回顧網路 (LRN) 是第一個遵循 PRISMA 2020 標準的可解釋 AI 平台，旨在自動化整個文獻回顧過程。LRN 在外科手套實務領域中進行評估，使用專家開發的 3 個搜尋字串來查詢 PubMed。非專家訓練所有 LRN 模型。效能以專家手動回顧作為基準。可解釋性和效能指標評估 LRN 複製專家回顧的能力。一致性以 Jaccard 指數和混淆矩陣測量。研究人員在研究完成前對彼此的結果保密。重疊的研究整合到 LRN 生成的系統性回顧中。LRN 模型在沒有專家訓練的情況下展現出優異的分類準確率，達到 84.78% 和 85.71% 的準確率。效能最高的模型達到了高評分者間信賴度 (k = 0.4953) 和可解釋性指標，將「減少」、「意外」和「銳利」與「雙重戴手套」連結在一起。另一個 LRN 模型涵蓋了 91.51% 的相關文獻，儘管與非專家的判斷不同 (k = 0.2174)，但包含了「乳膠」、「雙重」（手套）和「適應症」等詞彙。LRN 優於手動回顧（11 個月超過 19,920 分鐘），將整個過程縮短為 5 天超過 288.6 分鐘。這項研究顯示，可解釋的 AI 不需要專家訓練即可成功進行專家等級的 PRISMA 相容系統性文獻回顧。LRN 總結了外科手套研究的結果，並找出與臨床研究人員發現幾乎相同的主题。可解釋的 AI 可以準確地加快我們對臨床實務的理解，有潛力革新醫療保健研究。

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

摘要：本研究使用盒子學框架分析混合人工智慧系統的設計模式及其在臨床決策中的有效性。它分類並比較結合機器學習和基於規則的推理的各種架構，以深入了解其結構基礎和醫療保健應用。針對兩個主要問題，如何根據既定的設計模式對這些系統進行分類，以及如何通過比較分析提取見解，本研究使用軟體工程中的設計模式來了解和優化醫療保健人工智慧系統。盒子學有助於識別共性並建立可重複使用的解決方案，從而增強這些系統的可擴充性、可靠性和效能。檢查了五種主要的架構：REML、MLRB、RBML、RMLT 和 PERML。每種架構都有獨特的優缺點，強調了在臨床任務中需要量身打造的方法。REML 在資料有限的資料集中表現出高精度的預測；MLRB 在處理大型資料集和複雜資料整合方面表現出色；RBML 在可解釋性和可信度方面表現出色；RMLT 在管理高維資料方面表現出色；而 PERML 儘管在分析方面有限，但在緊急照護場景中表現出潛力。本研究引入了四種新模式，建立了五種抽象分類模式，並進一步將這五種模式細化為具體的系統。這些貢獻增強了盒子學的分類組織，並提供了將專家知識與機器學習整合的新方法。盒子學的結構化、模組化方法在開發和分析混合人工智慧系統、揭示共性以及推廣可重複使用的解決方案方面具有顯著優勢。總之，本研究強調了混合人工智慧系統在推進醫療保健中的關鍵作用，以及盒子學在推動人工智慧整合進一步創新方面的潛力，最終改善臨床決策支援和患者的治療成果。

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

摘要：由於其強大的預測能力，深度學習已成為許多產業中不可或缺的工具，包括醫療保健。然而，傳統的深度學習模型通常缺乏可解釋性，並且忽略了將預測不確定性納入考量，而這兩個因素是臨床決策制定的關鍵組成部分。為了產生可解釋且具有不確定性意識的預測，本研究提出了一個名為貝氏柯爾莫哥洛夫阿諾德網路 (BKAN) 的新架構，它結合了柯爾莫哥洛夫阿諾德網路的表達能力與貝氏推論。我們在兩個醫學資料集上使用 BKAN，這些資料集是評估機器學習模型在醫學診斷中的廣泛使用基準：皮馬印第安人糖尿病資料集和克里夫蘭心臟病資料集。我們的模型提供了對預測信心和決策邊界的有益見解，並且在預測準確度方面優於傳統的深度學習模型。此外，BKAN 表現隨機和認識不確定性的能力，可確保醫生獲得更可靠且值得信賴的決策支援。根據實驗結果，我們的貝氏策略提高了模型的可解釋性，並大幅減少了過度擬合，這對於小型且不平衡的醫學資料集非常重要。我們提出了可能的擴充功能，以進一步將 BKAN 用於更複雜的多模式資料集，並探討這些發現對於未來建立可靠的醫療保健 AI 系統研究的重要性。這項工作為深度學習模型部署在透明度和可靠性至關重要的重要領域中開啟了一個新的典範。

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

摘要：在現代醫療保健中，解決準確疾病預測和個性化建議的複雜性既至關重要又具有挑戰性。本研究引入了 MLtoGAI，它將語義網路技術與機器學習 (ML) 相結合，以增強疾病預測並透過 ChatGPT 提供使用者友善的說明。該系統包含三個關鍵組成部分：一個可重複使用的疾病本体，其中包含有關各種疾病的詳細知識；一個診斷分類模型，它使用患者症狀來準確檢測特定疾病；以及語義網路規則語言 (SWRL) 與本体和 ChatGPT 的整合，以產生清晰、個性化的健康建議。這種方法顯著提高了預測準確性，並確保了易於理解的結果，解決了疾病和不同症狀的複雜性。MLtoGAI 系統展示了準確性和使用者滿意度的實質性進步，有助於開發更智慧且更易於取得的醫療保健解決方案。這種創新的方法結合了 ML 演算法的優點，以及透過 ChatGPT 提供透明且人類可以理解的說明的能力，在預測準確性和使用者理解方面取得了顯著的進步。透過利用語義技術和可解釋的 AI，該系統提高了疾病預測的準確性，並確保了建議與個別患者相關且易於理解。我們的研究強調了整合先進技術以克服醫療診斷中現有挑戰的潛力，為智慧醫療保健系統的未來發展鋪路。此外，該系統使用 200 個合成患者資料記錄進行驗證，確保了穩健的效能和可靠性。

##### **Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

摘要：可解釋人工智慧 (XAI) 是將人工智慧 (AI) 和機器學習 (ML) 演算法整合到臨床實務中的辯論核心。高執行效能的 AI/ML 模型，例如整體學習器和深度神經網路，通常缺乏可解釋性，阻礙臨床醫生對其預測的信任。為了解決這個問題，正在開發 XAI 技術，以人類可以理解的術語描述 AI/ML 預測。一個有希望的方向是採用敏感度分析 (SA) 和全球敏感度分析 (GSA)，它們本質上會依據模型輸入對預測的影響來對其進行排名。在此，我們介紹一種新的 delta-XAI 方法，透過擴充 GSA 指標 delta 指數來提供 ML 模型預測的局部解釋。delta-XAI 指數評估每個特徵值對回歸和分類問題中個別例項的預測輸出之影響。我們將 delta-XAI 指數形式化，並提供其實作的程式碼。使用線性回歸模型對模擬情境評估 delta-XAI 方法，並以 Shapley 值作為基準。結果顯示 delta-XAI 指數通常與 Shapley 值一致，但在具有高度影響力或極端特徵值的模型中存在顯著差異。delta-XAI 指數在偵測主要特徵和處理極端特徵值方面表現出更高的敏感度。定性地來說，delta-XAI 透過利用機率密度函數提供直觀的解釋，使特徵排名更清晰且對從業人員來說更具可解釋性。總體而言，delta-XAI 方法對於穩健地取得 ML 模型預測的局部解釋似乎很有希望。將在真實世界的臨床環境中進行進一步調查，以評估其對 AI 輔助臨床工作流程的影響。

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

摘要：失智症是一種影響全球數百萬人的衰弱性神經疾病，在診斷上具有重大挑戰。在這項工作中，我們提出了一種新的方法，用於對失智和非失智老年患者進行分類，使用 3D 大腦磁振造影 (MRI) 掃描。我們的做法採用了一種獨特技術，用於選擇性處理 MRI 切片，重點關注最相關的大腦區域，並排除信息量較少的部分。這種方法由一個基於信心的分類委員會補充，該委員會由三個自定義深度學習模型組成：Dem3D ResNet、Dem3D CNN 和 Dem3D EfficientNet。這些模型協同工作以增強決策的準確性，利用它們的集體優勢。在影像研究開放存取系列 (OASIS) 資料集上進行測試，我們的模型達到了 94.12% 的驚人準確度，超過了現有方法。此外，在阿茲海默症神經影像倡議 (ADNI) 資料集上的驗證證實了我們方法的穩健性和普遍性。可解釋 AI (XAI) 技術和全面的消融研究進一步證實了我們技術的有效性，提供了對決策過程和我們方法重要性的見解。這項研究為失智症診斷提供了重大進展，為臨床應用提供了一個高度準確且高效的工具。

##### **Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**
2408.06352v1 by Michele Fiori, Gabriele Civitarese, Claudio Bettini

Recognizing daily activities with unobtrusive sensors in smart environments
enables various healthcare applications. Monitoring how subjects perform
activities at home and their changes over time can reveal early symptoms of
health issues, such as cognitive decline. Most approaches in this field use
deep learning models, which are often seen as black boxes mapping sensor data
to activities. However, non-expert users like clinicians need to trust and
understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human
Activity Recognition have emerged to provide intuitive natural language
explanations from these models. Different XAI methods generate different
explanations, and their effectiveness is typically evaluated through user
surveys, that are often challenging in terms of costs and fairness. This paper
proposes an automatic evaluation method using Large Language Models (LLMs) to
identify, in a pool of candidates, the best XAI approach for non-expert users.
Our preliminary results suggest that LLM evaluation aligns with user surveys.

摘要：藉由智慧環境中不引人注目的感測器辨識日常活動，能啟用各種醫療保健應用。監控受試者在家中如何執行活動，以及其隨著時間的變化，可以揭示健康問題的早期症狀，例如認知能力下降。此領域中的大多數方法都使用深度學習模型，這些模型通常被視為將感測器資料對應至活動的黑盒子。然而，非專家使用者（例如臨床醫師）需要信任並了解這些模型的輸出。因此，人類活動辨識的可解釋 AI (XAI) 方法應運而生，以提供來自這些模型的直覺自然語言說明。不同的 XAI 方法會產生不同的說明，而其有效性通常透過使用者調查來評估，這在成本和公平性方面通常具有挑戰性。本文提出使用大型語言模型 (LLM) 的自動評估方法，以在候選者中找出最適合非專家使用者的 XAI 方法。我們的初步結果表明，LLM 評估與使用者調查一致。

##### **Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**
2408.03335v1 by Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil

Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.

摘要：工業 5.0 著重於人類與人工智慧 (AI) 合作執行製造中的不同任務，涉及更多機器人、物聯網 (IoT) 裝置和互連、擴增/虛擬實境 (AR) 和其他智慧裝置。這些裝置和互連在經濟、醫療保健、教育和國防系統等各種關鍵領域的廣泛參與，引發了多種類型的潛在安全漏洞。AI 本身已被證明是網路安全不同領域中非常有效且強大的工具，例如入侵偵測、惡意軟體偵測和網路釣魚偵測等。就像在許多應用領域一樣，網路安全專業人員不願意接受黑盒 ML 解決方案來應用於網路安全。這種不願意促使可解釋人工智慧 (XAI) 作為一種工具被採用，有助於說明在基於 ML 的系統中如何做出決策。在這項調查中，我們對工業 5.0 的不同基於 XAI 的入侵偵測系統進行了全面的研究，並且我們也透過對抗式 XIDS (Adv-XIDS) 方法的觀點來探討可解釋性和可詮釋性對網路安全實務的影響。此外，我們分析了工業 5.0 的 XAI 網路安全系統中可能存在的機會和挑戰，引發了未來針對 XAI 基礎解決方案的研究，以供高風險的工業 5.0 應用採用。我們相信這項嚴謹的分析將為指定領域內的後續研究工作建立基礎架構。

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

摘要：本研究旨在探討將自然語言處理 (NLP) 和機器學習 (ML) 技術實作於醫療信函編碼自動化，並具備視覺化說明能力和輕量化的本地電腦設定。目前在臨床環境中，編碼是一種手動流程，涉及為病患文件中的每項病症、程序和藥物指派代碼 (例如，使用 SNOMED CT 代碼 56265001 表示心臟病)。此領域有使用最新 ML 模型進行自動編碼的初步研究；然而，由於模型的複雜性和大小，並未實現實際部署。為了進一步促進自動編碼實務的可能性，我們在本地電腦設定中探討了一些解決方案；此外，我們探討了說明功能在 AI 模型透明度中的功能。我們使用公開的 MIMIC-III 資料庫和 HAN/HLAN 網路模型進行 ICD 代碼預測。我們還試驗了 ICD 和 SNOMED CT 知識庫之間的對應。在我們的實驗中，這些模型提供了 97.98% 代碼的有用資訊。這項調查結果可以為實務中的自動臨床編碼實作提供一些見解，例如在醫院環境中，由臨床醫生使用的本地電腦，專案頁面 \url{https://github.com/Glenj01/Medical-Coding}。

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

摘要：人工智能 (AI) 支持的決策制定是未來 6G 網路中的關鍵元素，其中將引入原生 AI 的概念。此外，AI 廣泛用於不同的關鍵應用中，例如自動駕駛和醫療診斷。在這些應用中，使用 AI 作為黑盒模型是有風險且具有挑戰性的。因此，理解和信任這些模型做出的決策至關重要。解決此問題的方法是開發可解釋 AI (XAI) 架構，旨在解釋黑盒模型行為背後的邏輯，從而確保其有效且安全的部署。最近，我們提出了一個新的基於擾動的 XAI-CHEST 框架，該框架面向無線通信中的信道估計。XAI-CHEST 框架的核心思想是通過在無關輸入上引入高噪聲來識別相關模型輸入。這份手稿提供了 XAI-CHEST 框架的詳細理論基礎。特別是，我們推導了 XAI-CHEST 損失函數和噪聲閾值微調優化問題的解析表達式。因此，設計的 XAI-CHEST 提供了一種智能輸入特徵選擇方法，可以在優化所用模型的架構的同時進一步提高整體性能。模擬結果表明，XAI-CHEST 框架提供了有效的解釋，在降低所需的計算複雜度的同時，提供了改進的比特錯誤率性能，而這與基於傳統 DL 的信道估計相比。

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v2 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

摘要：这篇论文提出了用于从视网膜眼底图像进行疾病分类的扩张残差网络 (ResNet) 模型。扩张卷积滤波器用于替换 ResNet 模型较高层中的正常卷积滤波器（扩张 ResNet），以改善感知场，从而针对疾病分类对正常 ResNet 模型进行改进。本研究引入了采用深度学习的计算机辅助诊断工具，并通过可解释的 AI 技术进行了增强。这些技术旨在使该工具的决策过程透明化，从而使医学专业人士能够理解和信任 AI 的诊断决策。它们与当今的医疗保健领域尤为相关，在该领域，对 AI 应用的透明度需求不断增长，以确保其可靠性和合乎道德的使用。扩张 ResNet 用作正常 ResNet 的替代品，以提高视网膜眼部疾病的分类准确性并减少所需的计算时间。本工作中使用的数据集是眼科疾病智能识别 (ODIR) 数据集，这是一个结构化的眼科数据库，包含八类涵盖大多数常见视网膜眼部疾病。本工作中使用的评估指标包括精确度、召回率、准确度和 F1 得分。在这项工作中，对 ResNet-18、ResNet-34、ResNet-50、ResNet-101 和 ResNet-152 五个变体的正常 ResNet 模型和扩张 ResNet 模型进行了比较研究。与正常 ResNet 相比，扩张 ResNet 模型显示出有希望的结果，在 ODIR 多类疾病分类中，上述各个变体的平均 F1 得分为 0.71、0.70、0.69、0.67 和 0.70。

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v2 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
existing surveys on the trustworthiness of foundation models do not adequately
address their specific variations and applications within the medical imaging
domain. This survey aims to fill that gap by presenting a novel taxonomy of
foundation models used in medical imaging and analyzing the key motivations for
ensuring their trustworthiness. We review current research on foundation models
in major medical imaging applications, focusing on segmentation, medical report
generation, medical question and answering (Q\&A), and disease diagnosis. These
areas are highlighted because they have seen a relatively mature and
substantial number of foundation models compared to other applications. We
focus on literature that discusses trustworthiness in medical image analysis
manuscripts. We explore the complex challenges of building trustworthy
foundation models for each application, summarizing current concerns and
strategies for enhancing trustworthiness. Furthermore, we examine the potential
of these models to revolutionize patient care. Our analysis underscores the
imperative for advancing towards trustworthy AI in medical image analysis,
advocating for a balanced approach that fosters innovation while ensuring
ethical and equitable healthcare delivery.

摘要：基礎模型在醫學影像方面的快速進展，代表著在加強診斷準確性和個人化治療方面邁出一大步。然而，基礎模型在醫療保健中的部署需要對其可信度進行嚴格的審查，包括隱私、穩健性、可靠性、可解釋性和公平性。目前關於醫學影像中基礎模型的調查文獻中顯示出相當大的差距，特別是在可信度方面。此外，現有關於基礎模型可信度的調查並未充分解決其在醫學影像領域中的特定變化和應用。本調查旨在通過提出醫學影像中使用的基礎模型的新分類法並分析確保其可信度的關鍵動機，來填補這一空白。我們回顧了基礎模型在主要醫學影像應用中的當前研究，重點關注分割、醫療報告生成、醫療問題和回答 (Q&A) 以及疾病診斷。這些領域之所以被強調，是因為與其他應用相比，它們已經看到相對成熟且大量的基礎模型。我們專注於探討醫學影像分析手稿中可信度的文獻。我們探討了為每個應用構建可信基礎模型的複雜挑戰，總結了當前關注點和增強可信度的策略。此外，我們探討了這些模型在革新患者護理方面的潛力。我們的分析強調了在醫學影像分析中朝著可信賴的人工智慧邁進的必要性，並倡導一種平衡的方法，既能促進創新，又能確保道德和公平的醫療保健服務。

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

摘要：床邊超音波 (POCUS) 是臨床醫師在患者床邊進行和解讀超音波掃描的實務。然而，解讀這些影像所需的專業知識相當可觀，而且在緊急情況下可能並非隨時具備。這種現實情況使得機器學習分類器等演算法對於加強人類決策變得極為有價值。POCUS 裝置正以合理成本推出，尺寸為手機大小。將 POCUS 裝置轉變為救生工具的挑戰在於，解讀超音波影像需要專門訓練和經驗。不幸的是，取得正向訓練影像的困難度代表著建置有效率且準確的分類器的一大障礙。因此，我們嘗試探討的問題是如何探索策略，以提高使用稀疏資料訓練的分類器的準確度。我們假設使用少數資料實例進行訓練可能不足以讓分類器概括，導致它們過度擬合。我們的做法使用可解釋 AI 增強方法，以協助演算法從較少的資料中學習更多，並潛在協助分類器更好地概括。

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

摘要：近年來，美國見證了電子煙或電子香菸使用率大幅激增，導致電子煙和電子煙使用相關肺損傷 (EVALI) 病例顯著增加，在 2019 年 EVALI 爆發期間造成住院和死亡，凸顯了理解電子煙行為和制定有效戒菸策略的迫切性。由於社群媒體平台的普及，全球超過 47 億使用者使用它們進行連結、溝通、新聞和娛樂，其中很大一部分與健康相關，因此將社群媒體資料建立為公共衛生研究中無價的有機資料資源。在本研究中，我們從 Reddit 上一個電子煙子社群中提取一個範例資料集，以分析使用者的戒電子煙意圖。利用 OpenAI 最新的大型語言模型 GPT-4 進行句子層級的戒電子煙意圖偵測，本研究比較了此模型的結果與外行人和臨床專家註解。使用不同的提示策略，例如零次學習、一次學習、少次學習和思考鏈提示，我們開發了 8 個提示，詳細程度不同，向 GPT-4 解釋任務，並評估這些策略彼此之間的效能。這些初步發現強調了 GPT-4 在社群媒體資料分析中的潛力，特別是在識別人類偵測可能無法察覺的使用者微妙意圖方面。

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

摘要：<paragraph>人工智慧（AI）目前在很大程度上依賴於缺乏可解釋性的黑盒機器學習模型。可解釋性人工智慧（XAI）領域致力於解決這個主要問題，這在金融、法律和健康等高風險領域至關重要。
我們提出了一種基於範疇論定義 AI 模型及其可解釋性的方法。為此，我們採用組合模型的概念，它以形式弦圖的形式看待模型，這些弦圖捕獲了模型的抽象結構及其具體實現。這種綜合觀點包含了確定性、概率性和量子模型。我們將各種 AI 模型作為組合模型進行比較，包括線性和基於規則的模型、（遞迴）神經網路、Transformer、VAE，以及因果和 DisCoCirc 模型。
接下來，我們根據模型的組合結構給出模型解釋的定義，展示如何分析模型的可解釋性，並使用它來澄清 XAI 中的常見主題。我們發現，讓標準的「內在可解釋」模型如此透明的原因在圖表中表現得最為清楚。這引導我們得出更一般的組合可解釋（CI）模型概念，它另外還包括因果、概念空間和 DisCoCirc 模型。
接下來，我們展示了 CI 模型的可解釋性優勢。首先，它們的組合結構允許計算其他感興趣的量，並可能通過匹配模型的結構來促進從模型到被建模現象的推理。其次，它們允許對其行為進行圖解說明，這些說明基於影響約束、圖解手術和重寫說明。最後，我們討論了這種方法的許多未來方向，提出了如何在實踐中學習這種有意義的結構化模型的問題。</paragraph>

##### **Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**
2406.12142v2 by Vincent Olesen, Nina Weng, Aasa Feragen, Eike Petersen

Machine learning models have achieved high overall accuracy in medical image
analysis. However, performance disparities on specific patient groups pose
challenges to their clinical utility, safety, and fairness. This can affect
known patient groups - such as those based on sex, age, or disease subtype - as
well as previously unknown and unlabeled groups. Furthermore, the root cause of
such observed performance disparities is often challenging to uncover,
hindering mitigation efforts. In this paper, to address these issues, we
leverage Slice Discovery Methods (SDMs) to identify interpretable
underperforming subsets of data and formulate hypotheses regarding the cause of
observed performance disparities. We introduce a novel SDM and apply it in a
case study on the classification of pneumothorax and atelectasis from chest
x-rays. Our study demonstrates the effectiveness of SDMs in hypothesis
formulation and yields an explanation of previously observed but unexplained
performance disparities between male and female patients in widely used chest
X-ray datasets and models. Our findings indicate shortcut learning in both
classification tasks, through the presence of chest drains and ECG wires,
respectively. Sex-based differences in the prevalence of these shortcut
features appear to cause the observed classification performance gap,
representing a previously underappreciated interaction between shortcut
learning and model fairness analyses.

摘要：機器學習模型在醫學影像分析中已達到整體高準確度。然而，特定患者群體的效能差異對其臨床效用、安全性與公平性構成挑戰。這可能會影響已知的患者群體（例如基於性別、年齡或疾病亞型）以及先前未知且未標籤的群體。此外，此類觀察到的效能差異的根本原因通常難以發現，阻礙了緩解措施。在本文中，為了解決這些問題，我們利用切片發現方法 (SDM) 來識別可解釋的資料效能不佳子集，並針對觀察到的效能差異原因制定假設。我們引入一種新的 SDM，並在胸部 X 光片中肺炎和肺不張分類的案例研究中應用它。我們的研究證明了 SDM 在假設制定中的有效性，並對廣泛使用的胸部 X 光片資料集和模型中先前觀察到但無法解釋的男性和女性患者之間的效能差異提供了解釋。我們的發現表明，在分類任務中，透過胸腔引流管和心電圖導線的存在，存在捷徑學習。這些捷徑特徵的盛行率存在基於性別的差異，似乎會導致觀察到的分類效能差距，這代表捷徑學習和模型公平性分析之間先前未受到重視的交互作用。

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

摘要：元宇宙的概念在各個領域都備受關注，其重要應用之一便是醫療保健。元宇宙有巨大的潛力透過改變病患照護、醫學教育，以及教學/學習和研究的方式來轉型醫療保健。本研究的目的是提供元宇宙基本概念和基礎技術的介紹。本文探討了元宇宙在醫療保健背景下的優缺點，並從技術和 AI 的角度分析其潛力。特別是，討論了機器學習方法的角色；我們將說明如何將機器學習演算法應用於元宇宙產生的資料，以獲得醫療保健應用方面的更佳見解。此外，我們透過探討區塊鏈等新興技術，並解決隱私問題，來探討元宇宙在醫療保健方面的未來願景。本研究的發現有助於更深入地了解元宇宙在醫療保健中的應用，以及其在醫療服務提供方面發揮革命性變革的潛力。

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

摘要：慢性腎臟病（CKD）是一種廣泛的慢性疾病，沒有已知的最終療法且發病率很高。研究表明，進行性慢性腎臟病（CKD）是一種異質性疾病，會顯著影響腎臟結構和功能，最終導致腎衰竭。隨著時間的推移，慢性腎臟病已從影響少數人的致命疾病轉變為一種嚴重程度不同的常見疾病。本研究的目標是使用集成學習和可解釋的 AI 進行早期預後和 CKD 檢測，並視覺化主導特徵、特徵分數和表現出的值。為此，提出了一種 AI 驅動的預測分析方法，以幫助臨床醫生為個別患者開具生活方式修改建議，以降低這種疾病的進展速度。我們的數據集是從 CKD 患者和健康受試者的身體生命體徵中收集的，以準確開發我們提出的 AI 驅動的解決方案。在這方面，提供了血液和尿液檢測結果，並應用基於集成樹的機器學習模型來預測未發現的 CKD 病例。我們的研究結果經過與腎臟科醫生的長期諮詢後得到驗證。我們的實驗和解釋結果與各種醫療保健領域中現有的可解釋 AI 應用進行了比較，包括 CKD。比較表明，我們開發的 AI 模型，特別是隨機森林模型，已經確定了比 XgBoost 更多作為重要貢獻者的特徵。可解釋性 (I) 衡量重要特徵與掩蓋特徵的比率，表明我們的 XgBoost 模型在這個指標中獲得了更高的分數，特別是 98% 的保真度，並且在 FII 指數中自然高於競爭模型。

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

摘要：心理健康構成了一項複雜且普遍的全球挑戰，影響了數百萬人的生活，並經常導致嚴重的後果。在本文中，我們進行了一項徹底的調查，以探索數據科學、人工智慧和心理保健的交集，重點關注通過線上社交媒體 (OSM) 進行心理疾病檢測的最新發展。很大一部分人口積極參與 OSM 平台，創造了一個龐大的人員資料庫，對心理健康分析具有巨大的潛力。本文探討了傳統的診斷方法、最先進的資料和 AI 驅動的研究，以及心理保健中可解釋 AI (XAI) 模型的出現。我們回顧了最先進的機器學習方法，特別是那些基於現代深度學習的方法，同時強調了醫療保健 AI 模型中可解釋性的必要性。實驗設計部分提供了對普遍做法的見解，包括可用的資料集和評估方法。我們還找出該領域的主要問題和挑戰，並提出了有希望的未來研究方向。由於心理健康決策需要透明度、可解釋性和道德考量，本文有助於推進心理保健中透過社交媒體推進 XAI 的持續討論。這裡提出的全面概述旨在引導研究人員、從業人員和政策制定者發展心理疾病檢測領域。

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

摘要：<paragraph>醫療照護中需要 AI 輔助的臨床診斷。現有的深度學習模型缺乏可解釋性，並且主要專注於影像分析。最近開發的動態不確定因果關係圖 (DUCG) 方法是因果驅動的、可解釋的，並且在不同的應用場景中是不變的，沒有資料收集、標記、擬合、隱私、偏見、概化、高成本和高能耗的問題。通過臨床專家和 DUCG 技術人員之間的密切合作，構建了涵蓋 54 個主訴的 46 個 DUCG 模型。可以在沒有分流的情況下診斷出 1,000 多種疾病。在應用於實際世界之前，46 個 DUCG 模型已由第三方醫院回溯性驗證。驗證的診斷精度不低於 95%，其中包括罕見疾病在內的每種疾病的診斷精度不低於 80%。驗證後，46 個 DUCG 模型已在中國實際應用。已經執行了超過一百萬個真實診斷案例，僅發現 17 個不正確的診斷。由於 DUCG 的透明性，發現並糾正了導致不正確診斷的錯誤。頻繁應用 DUCG 的臨床醫生的診斷能力得到了顯著提高。在介紹了前面提出的 DUCG 方法論之後，提出了潛在健康檢查的推薦演算法，並提取了 DUCG 的關鍵思想。</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

摘要：精確且及時地偵測乳癌對於改善患者預後至關重要。診斷方法傳統上依賴於單一模式方法；然而，醫療資料分析正在整合超越傳統影像的各種資料來源。使用整合影像和非影像資料的多模式技術，標誌著乳癌診斷的變革性進展。本篇綜述的目的是探討多模式技術的新興領域，特別是將組織病理學影像與非影像資料融合。此外，可解釋人工智慧 (XAI) 將用於闡明複雜演算法的決策過程，強調診斷過程中可解釋性的必要性。本綜述利用多模式資料並強調可解釋性，以提高診斷準確性、臨床醫師的信心和患者參與度，最終促進乳癌更個人化的治療策略，同時也找出多模式和可解釋性的研究差距，引導未來的研究，並為該領域的策略方向做出貢獻。

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

摘要：自注意力機制已被採用於多個廣泛使用的訊息傳遞神經網路 (MPNN)（例如 GAT），它可以自適應地控制沿著底層圖形邊緣流動的資訊量。這種注意力的使用使得此類模型成為可解釋 AI (XAI) 研究的基線，因為透過注意力的詮釋已在各種領域（例如自然語言處理和電腦視覺）中普及。然而，現有的研究通常使用天真的計算方法從注意力中推導出歸因分數，並且沒有考慮到邊緣歸因的精確且仔細的計算。在我們的研究中，我們旨在填補注意力啟用 MPNN 的廣泛使用與它們在很大程度上未被充分探索的可解釋性之間的差距，這個主題已在其他領域積極研究。為此，作為第一次嘗試，我們將 GNN 中注意力權重的邊緣歸因問題形式化。然後，我們提出 GATT，一種建立在計算樹上的邊緣歸因計算方法。透過全面的實驗，我們展示了我們提出的方法在評估 GAT 的歸因時所具有的效果。相反地，我們憑經驗驗證了僅對圖注意力層上的注意力權重取平均值不足以詮釋 GAT 模型的行為。程式碼已公開於 https://github.com/jordan7186/GAtt/tree/main。

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v3 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

摘要：新生兒期是大腦發育最脆弱的時期，容易出現癲癇發作。大腦發育不成熟時出現癲癇發作會造成不良後果，因此需要及早診斷。目前新生兒癲癇發作的黃金標準依賴於連續的視訊腦電圖 (EEG) 監測；其中包括在新生兒加護病房 (NICU) 內同時進行多頻道腦電圖 (EEG) 記錄和即時視訊監控。然而，視訊腦電圖監控技術需要臨床專業知識，而且通常僅限於技術先進且資源豐富的環境。具成本效益的新技術可以幫助醫療界準確診斷並立即提倡治療。在這項工作中，提出了一個新穎的可解釋深度學習模型，以自動化新生兒癲癇發作偵測過程，並採用減少的腦電圖裝置，其中採用了卷積神經網路、圖形注意力層和全連接層。除了能夠使用減少的裝置即時偵測癲癇發作外，此模型還提供了即時可解釋性的獨特優勢。透過在 Zenodo 資料集上使用 10 倍交叉驗證評估效能，所提出的模型在曲線下面積 (AUC) 和召回率方面分別達到了 8.31% 和 42.86% 的絕對改善。

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

摘要：乳癌 (BC) 是影響全球女性最常見的惡性腫瘤之一，因此需要進步的診斷方法，以改善臨床結果。本文全面探討了可解釋人工智慧 (XAI) 技術在乳癌偵測和診斷中的應用。隨著人工智慧 (AI) 技術持續滲透醫療保健領域，特別是在腫瘤學中，透明且可解釋的模型需求變得勢在必行，以增強臨床決策制定和患者照護。此篇評論探討了各種 XAI 方法的整合，例如 SHAP、LIME、Grad-CAM 等，以及用於乳癌偵測和分類的機器學習和深度學習模型。透過探討乳癌資料集的模式，包括乳房攝影、超音波及其在 AI 中的處理，本文重點說明 XAI 如何能導致更準確的診斷和個人化治療計畫。它也探討了實施這些技術的挑戰，以及制定標準化評量指標以評估 XAI 在臨床環境中的有效性的重要性。透過詳細的分析和討論，本文旨在強調 XAI 在縮小複雜 AI 模型與實務醫療保健應用之間差距的潛力，進而促進醫療專業人員之間的信任與理解，並改善患者的結果。

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

摘要：語音情緒辨識 (SER) 由於其在心理健康、教育和人機互動等多個應用領域而備受關注。然而，SER 系統的準確性受到高維特徵集的阻礙，這些特徵集可能包含不相關和冗餘的資訊。為了克服這個挑戰，本研究提出了一種用於 SER 的迭代特徵提升方法，該方法強調特徵相關性和可解釋性，以增強機器學習模型的效能。我們的做法涉及仔細的特徵選擇和分析，以建立高效的 SER 系統。為了透過模型可解釋性解決我們的核心問題，我們採用了具有 Shapley 值的特徵評估迴圈，以反覆改善特徵集。這個過程在模型效能和透明度之間取得平衡，這使得我們能夠全面了解模型的預測。所提出的方法提供了多項優點，包括識別和移除不相關和冗餘的特徵，從而建立更有效的模型。此外，它促進了可解釋性，有助於理解模型的預測以及識別情緒決定的關鍵特徵。所提出的方法的有效性已在多倫多情緒語音集 (TESS)、柏林情緒語音資料庫 (EMO-DB)、賴爾森音訊視覺情緒語音和歌曲資料庫 (RAVDESS) 和薩里音訊視覺表達情緒 (SAVEE) 資料集的 SER 基準上得到驗證，其效能優於現有方法。據我們所知，這是第一個將模型可解釋性納入 SER 架構的研究。本文的原始碼可透過此連結公開取得：https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition。

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, Héloïse de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

摘要：可解释性通常对于人工智能 (AI) 的可接受实施至关重要。在医疗保健领域，这一点尤为重要，因为决策直接影响患者，并且对 AI 系统的信任至关重要。这种信任通常建立在 AI 提供的解释和诠释之上。尽管 AI 可解释性取得了重大进展，但仍然需要明确的指导方针，说明在医疗环境中何时以及在多大程度上需要解释。我们提出了一种新颖的分类系统，该系统具有四种不同的解释必要性类别，指导所需的解释级别：患者或样本（局部）级别、队列或数据集（全局）级别，或两个级别。我们引入了一个数学公式，该公式区分了这些类别，并为研究人员提供了一个实用框架，以确定医疗 AI 应用中所需的解释的必要性和深度。考虑了三个关键因素：评估协议的稳健性、专家观察的可变性以及应用程序的表示维数。从这个角度来看，我们解决了这个问题：AI 医疗应用何时需要解释，以及需要解释到何种程度？

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

摘要：人工智慧 (AI) 領域正快速影響著健康與醫療保健，但對於面臨廣泛結構性壓迫的人群來說，偏見和不良表現依然存在。先前的研究已清楚說明，需要更嚴格地注意資料代表性和模型效能，以促進公平性並減少偏見。然而，我們有機會透過運用社會流行病學和健康公平的最佳實務，來改善 AI 的可解釋性，以幫助我們針對發現的關聯性，發展假設。在本文中，我們專注於可解釋 AI (XAI)，並描述一個跨領域專家小組審查架構，以從多重觀點討論和批判性評估 AI 模型的解釋，並找出偏見領域和未來研究的方向。我們強調跨領域專家小組對於產生更準確、公平的詮釋至關重要，而這些詮釋是根據歷史和脈絡而來的。跨領域小組討論有助於減少偏見、找出潛在的混淆因素，並在文獻中有缺口時找出額外研究的機會。反過來，這些見解可以建議 AI 模型改進的機會。

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. Zając, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

摘要：人工智慧（AI）在實驗室實驗中不斷地與放射科醫師匹敵或表現得更出色。然而，發現放射科 AI 為基礎系統的實際執行幾乎沒有提供臨床價值。本文探討如何為 AI 設計在不同情境中臨床上的效用。我們根據功能性 AI 為基礎原型的三次迭代，在丹麥和肯亞的 7 個臨床場域與 13 位放射科醫師進行了 19 次設計會議和設計介入。十個社會技術依賴關係被認為對於放射科中 AI 的設計至關重要。我們概念化了四個技術面向，必須根據預期的臨床使用情境進行設定：AI 功能、AI 醫療重點、AI 決策門檻，以及 AI 可解釋性。我們提出四項設計建議，說明如何處理與醫療知識、診所類型、使用者專業知識等級、患者情境，以及影響這些技術面向設定的使用者情境相關的依賴關係。

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

摘要：隨著先進的 AI/ML，對可解釋 AI (XAI) 的研究不斷增加，以及關於人類如何與 AI 和 XAI 互動以進行有效的人工智慧協作決策制定。然而，我們仍然缺乏對 AI 系統和 XAI 應如何首先呈現給沒有技術背景的用戶的了解。在本文中，我們展示了與醫療專業人員 (n=12) 和主修醫學和健康的學生 (n=4) 進行半結構化訪談的結果，以研究如何改善 AI 和 XAI 的入門。對於訪談，我們建立在人機互動準則之上，為中風康復評估和 AI 解釋的 AI 系統創建入門材料，並將它們介紹給參與者。我們的研究結果表明，除了呈現傳統的 AI 性能指標外，參與者還希望基准信息、AI 的實際好處以及交互試驗，以更好地將 AI 性能情境化，並完善 AI 的目標和性能。根據這些發現，我們強調了改進 AI 和 XAI 以及人機協作決策制定的入門方向。

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

摘要：本文使用機器學習 (ML) 和可解釋人工智慧 (XAI) 技術來探討營養狀況與阿茲海默症 (AD) 相關的死亡率之間的關係。採用第三次全國健康與營養檢查調查 (NHANES III) 資料庫進行分析。選擇隨機森林模型作為 XAI 分析的基礎模型，並使用 Shapley Additive Explanations (SHAP) 方法來評估特徵重要性。結果突顯了重要的營養因素，例如血清維生素 B12 和糖化血紅蛋白。該研究證明了隨機森林在預測 AD 死亡率方面相較於其他疾病的有效性。本研究提供了營養對 AD 的影響的見解，並有助於更深入地了解疾病的進展。

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

摘要：<paragraph>初級保健提供者對於最初的分流和轉診到專科照護至關重要。在青光眼的情況下，無症狀且快速惡化可能導致視力喪失，因此需要及時轉診給專家。然而，初級眼科保健提供者可能無法識別緊急情況，可能會延誤照護。提供解釋的人工智慧 (AI) 可以加強他們的轉診決策。我們研究各種 AI 解釋如何幫助提供者區分需要立即或非緊急專科轉診的患者。我們建立了解釋性 AI 演算法，以從例行眼科護理資料預測青光眼手術需求，作為識別高風險患者的代理。我們納入了內在和事後解釋性，並與驗光師進行了一項線上研究，以評估人機團隊的表現，衡量轉診準確度並分析與 AI 的互動，包括同意率、任務時間和使用者體驗感知。在 87 名參與者中，AI 支援提高了轉診準確度（使用 AI/未使用的比例為 59.9%/50.8%），儘管人機團隊的表現不如單獨使用 AI。參與者認為他們在使用內在模型時更多地納入了 AI 建議，並認為它更有用且更有希望。沒有解釋，AI 建議的偏差會增加。AI 支援並未增加工作量、信心和信任，但減少了挑戰。在一個單獨的測試集中，我們的黑盒子和內在模型在預測手術結果方面分別達到了 77% 和 71% 的準確度。我們找出在初級眼科保健中，人機團隊合作管理青光眼的機會，並注意到雖然 AI 提高了轉診準確度，但即使有解釋，它也顯示出與單獨使用 AI 相比的效能差距。人類參與在醫療決策中仍然至關重要，這強調了未來研究優化協作、確保正面經驗和安全使用 AI 的必要性。</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

摘要：在醫學影像中，特別是在早期疾病檢測和預後任務中，辨別 AI 模型預測背後的原理對於評估其決策的可靠性至關重要。傳統的解釋方法在識別醫學影像分類中可識別的決定性特徵時面臨挑戰，其中區別性特徵很微妙或並不明顯。為了彌合這一差距，我們提出了一個可解釋的模型，該模型具備決策推理和特徵識別能力。我們的做法不僅檢測有影響力的影像模式，還揭示了推動模型最終預測的決定性特徵。通過實施我們的模型，我們可以有效識別和視覺化由數據驅動模型利用的類特定特徵，從而深入了解深度學習模型的決策過程。我們在要求嚴格的醫學預後任務領域驗證了我們的模型，展示了其在提高 AI 在醫療保健中的可靠性和發現預後理解受限疾病的新知識方面的功效和潛力。

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

摘要：本研究探討線上健康社群中尋求資訊支持的問題、回應，以及有幫助的評分之間的關係。我們建立了一組標記的問答配對資料集，並開發了多模態機器學習和深度學習模型，以可靠地預測資訊支持問題和回應。我們採用可解釋的 AI 來揭示資訊支持交流中蘊含的情緒，證明情緒在提供資訊支持中的重要性。這種情緒支持和資訊支持之間的複雜交互作用以前並未被研究過。本研究改進了社會支持理論，並為使用者決策輔助工具的開發奠定了基礎。討論了進一步的影響。

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

摘要：在科技飛速發展的時代，一位意外的訪客已在全球教室中佔有一席之地，那就是人工智慧。生成式 AI，例如 ChatGPT，承諾在教育領域掀起一場革命，但它卻是一把雙面刃。它在個人化學習方面的潛力，卻因作弊、不準確以及教育工作者難以將其有效融入教學設計等問題而抵銷。我們正站在這教育前沿的邊緣，顯然我們需要非常小心地探索這片領域。這是一個重大的挑戰，可能會損害我們教育過程的完整性和價值。那麼，我們如何將這些挑戰轉化為機遇？當不適當地使用時，AI 工具可能會成為複製貼上心態的完美工具，並迅速腐蝕批判性思維、創造力和深入理解，這些都是我們快速變化的世界中最重要的技能。教師們覺得他們沒有能力利用這項技術，這擴大了教育工作者和機構之間的數位鴻溝。解決這些問題需要深入的研究方法。我們將採用實證研究，借鑑技術接受模型，來評估教育工作者和學生對生成式 AI 的態度。了解他們的看法、使用模式和障礙是創造有效解決方案的第一個關鍵步驟。本研究將作為未來研究人員應用的流程手冊，根據此處說明的步驟運行他們自己的數據

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike Grüne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, André Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

摘要：隨著醫療保健系統的數位化，人工智慧在醫學領域中變得更加普及。特別是機器學習在時間序列分類等複雜任務中展現出極大的潛力，但通常是以透明度和可理解性為代價。這導致人類缺乏信任，從而阻礙了其積極使用。可解釋的人工智慧試圖通過提供對決策過程的洞察來彌補這一差距，但其不同方法的實際效用尚不清楚。本文提出了一個基於使用者研究的評估，其中包含了 Grad-CAM 解釋方法，並將其應用於神經網路以分類時間序列新生兒呼吸數據中的呼吸。我們展示了不同利益相關者對可解釋性方法的感知效用，揭示了實現實際透明度的難度，以及許多參與者希望獲得更深入的解釋。

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

摘要：大型語言模型 (LLM) 與醫療診斷整合
為臨床決策提供了一個有前景的途徑。本研究概述了一種新穎方法的開發，用於零次學習/少量學習情境學習 (ICL)，方法是使用多層結構化提示整合醫療領域知識。我們還探討了使用者與 LLM 之間兩種溝通方式的功效：數值對話 (NC) 方式，它會逐步處理資料，以及自然語言單回合 (NL-ST) 方式，它會使用長篇敘事提示。
我們的研究系統性地評估了診斷準確性和風險因子，包括性別偏見和假陰性率，使用了一個包含 920 個患者記錄的資料集，採用各種少量學習情境。結果表明，傳統的臨床機器學習 (ML) 模型通常在零次學習和少量學習設定中表現優於 LLM。然而，當使用少量學習範例以及有效的可解釋 AI (XAI) 方法作為領域知識來源時，效能差距會顯著縮小。此外，隨著時間充足和範例數量增加，對話方式 (NC) 幾乎可以媲美 ML 模型的效能。最值得注意的是，LLM 相對於 ML 模型展現出相當或更佳的成本敏感準確度。
本研究證實，透過適當的領域知識和量身打造的溝通策略，LLM 可以顯著增強診斷程序。這些發現突顯了最佳化訓練範例數量和溝通方式的重要性，以提高準確度並減少 LLM 應用中的偏差。

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel Miró-Nicolau, Gabriel Moyà-Alcover, Antoni Jaume-i-Capó, Manuel González-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

摘要：隨著對深度學習模型依賴性的增加，加上其固有的透明度不足，促使一個新的研究領域發展，稱為可解釋 AI (XAI) 方法。這些方法旨在透過深入了解決策背後的原理，來提升最終使用者對自動化系統的信賴。本文提出了一種衡量使用者對 XAI 系統信賴度的新穎方法，允許對其進行改進。我們提出的指標結合了客觀觀點下的效能指標和信賴指標。為了驗證這個新穎的方法，我們在一個真實的醫療場景中進行了一個案例研究：使用 XAI 系統從 X 光影像中偵測肺炎。

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

摘要：COVID-19 疫情對全球公共衛生造成壓力，必須進行準確的診斷和干預，以控制疾病傳播並降低死亡率。本文介紹了一個可解釋的深度生存預測模型，專門設計用於透過胸部 X 光 (CXR) 影像改善對 COVID-19 預後的理解和信賴。透過整合大規模預訓練影像編碼器、風險特定 Grad-CAM 和解剖區域偵測技術，我們的做法產生區域可解釋的結果，有效捕捉必要的疾病特徵，同時專注於罕見但關鍵的異常區域。我們的模型預測結果透過風險區域定位提供增強的清晰度和透明度，讓臨床醫生能夠在更了解預後見解的情況下，就 COVID-19 診斷做出明智的決策。我們在多中心生存資料集上評估所提出的方法，並透過量化和質化評估證明其有效性，達到優異的 C 指數（0.764 和 0.727）和時間相關 AUC（0.799 和 0.691）。這些結果表明，我們可解釋的深度生存預測模型在風險預測方面超越傳統的生存分析方法，提升臨床決策的解釋性，並增強 AI 系統的信賴度。

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

摘要：<paragraph>在過去幾年，臨床決策支援系統 (CDSS) 中的人工智慧 (AI) 在利用機器學習和深度學習架構方面發揮了關鍵作用。儘管 AI 模型具有令人滿意的能力，但缺乏透明度和可解釋性，特別是在可靠性為必要考量的醫療背景下，這帶來了重大的挑戰。在不影響預測精準度的情況下實現透明度仍然是一項關鍵挑戰。本文提出了一種新方法，即 Rad4XCNN，以增強 CNN 衍生特徵的預測能力，同時具備放射特徵固有的可解釋性。Rad4XCNN 不同於基於顯著性圖的傳統方法，它通過放射組學將可理解的含義與 CNN 衍生特徵關聯起來，為超越視覺化圖表的解釋方法提供了新的觀點。我們以乳癌分類任務作為案例研究，在超音波影像資料集上評估 Rad4XCNN，包括一個線上資料集和兩個用於內部和外部驗證的內部資料集。一些關鍵結果如下：i) 與 ViT 衍生特徵和放射特徵相比，CNN 衍生特徵保證了更穩健的準確度；ii) 傳統的視覺化圖解釋方法存在一些缺陷；iii) Rad4XCNN 沒有犧牲模型準確度來換取其可解釋性；iv) Rad4XCNN 提供了全局解釋見解，使醫師能夠分析模型輸出和發現。此外，我們強調將可解釋性整合到 AI 模型中對於增強臨床實務中的信任和採用至關重要，並強調了我們的方法如何能緩解與可解釋 AI 方法相關的一些疑慮。</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

摘要：隨著人工智慧 (AI) 的普及整合，在涉及 AI 驅動系統的事故中，責任和義務歸屬產生了複雜的挑戰。這些系統的互連性、AI 引發事故的倫理問題，加上 AI 技術的不確定性和缺乏相應法規，使得傳統責任歸屬面臨挑戰。為此，本研究提出了一種計算反思均衡 (CRE) 方法，以建立一個連貫且在倫理上可接受的責任歸屬架構，適用於所有利害關係人。計算方法提供了結構化的分析，克服了概念方法在處理動態且多面向情境時的限制，展示了該架構在責任歸屬過程中具備的可解釋性、連貫性和適應性。我們探討了與均衡計算中索賠相關的初始啟動層級的關鍵作用。我們以 AI 輔助醫療決策支援系統為案例研究，說明不同的初始化如何導致不同的責任分配。該架構提供了對 AI 引發事故中問責制的寶貴見解，透過持續監控、修訂和反思，促進了永續且有韌性的系統發展。

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

摘要：人工智慧透過預測模型協助醫療專業人員，大幅轉變了臨床決策制定。本研究探討了在醫療保健中使用人工智慧應用程式時公平性和可解釋性的關鍵需求，以確保在不同的患者人口統計資料中獲得公平的結果。透過專注於敗血症相關死亡率的預測模型，我們提出了一種方法，該方法會學習一個效能最佳化的預測模型，然後採用轉移學習過程來產生一個具有更好公平性的模型。我們的模型還引入了一種新穎的基於排列的特徵重要性演算法，旨在闡明每個特徵在增強預測公平性方面的貢獻。與現有的可解釋性方法專注於解釋特徵對預測效能的貢獻不同，我們提出的方法獨特地彌補了理解每個特徵如何有助於公平性的差距。這項進展至關重要，因為敗血症的死亡率很高，且在三分之一的醫院死亡中扮演著角色。我們的模型不僅有助於識別和減輕預測模型中的偏差，還能透過提高模型預測的透明度和公平性來培養醫療保健利益相關者之間的信任，進而有助於提供更公平且值得信賴的醫療保健服務。

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

摘要：現今，憂鬱症是一個重要的議題。根據世界衛生組織 (WHO) 的資料，在 2023 年，超過 2.8 億人正在與憂鬱症搏鬥。這是一個龐大的數字；如果不認真看待，這些數字將會快速增加。大約有 48.9 億人是社群媒體使用者。人們在 Twitter、Facebook、Reddit、Instagram 等平台上表達自己的感受和情緒。這些平台包含有價值的資訊，可用於研究目的。已經在各種社群媒體平台上進行了大量的研究。然而，這些努力仍存在某些限制。特別是，先前的研究僅專注於偵測推文中的憂鬱症和憂鬱症的強度。此外，資料集標籤中存在不準確的情況。在這項研究工作中，使用基於詞彙標籤的 Twitter 資料庫中的推文預測了五種類型的憂鬱症（雙極型、重度、精神病型、非典型和產後）。可解釋的 AI 用於透過強調代表憂鬱症類型的推文部分來提供推理。從 Transformers（BERT）中提取的雙向編碼器表示用於特徵提取和訓練。機器學習和深度學習方法用於訓練模型。BERT 模型呈現出最有希望的結果，達到 0.96 的整體準確度。

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

摘要：深度学习正大幅轉變醫學影像和放射線學領域，能辨識醫學影像中的病理，包括電腦斷層掃描 (CT) 和 X 光掃描。然而，深度學習模型的效能，特別是在分割任務中，常常受到廣泛註解資料集需求的限制。為了應對此挑戰，透過可解釋 AI 和反事實解釋的產生，探索弱監督語意分割的能力。本研究的範圍是開發一種新的反事實內插方法 (COIN)，該方法使用生成模型將預測的分類標籤從異常翻轉為正常。例如，如果分類器將輸入的醫學影像 X 視為異常，表示存在病理，則生成模型旨在內插異常區域，從而逆轉分類器的原始預測標籤。此方法使我們能夠產生病理的精確分割，而無需依賴於預先存在的分割遮罩。至關重要的是，利用影像層級標籤，這比建立詳細的分割遮罩容易取得。該方法的有效性透過分割合成目標和從愛沙尼亞塔爾圖大學醫院取得的 CT 影像中的實際腎臟腫瘤來證明。研究結果表明，COIN 遠遠超過已建立的歸因方法，例如 RISE、ScoreCAM 和 LayerCAM，以及 Singla 等人提出的另一種反事實解釋方法。此證據表明，COIN 是一種很有前途的 CT 影像中腫瘤語意分割方法，並在醫療保健中讓深度學習應用更易於取得和更有效率邁進一步，其中註解資料很稀少。

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

摘要：在本文中，我們探討數位人文學科 (DH) 作為一門學科與混合智能 (HI) 作為一個研究典範之間的協同作用。在 DH 研究中，數位方法的使用，特別是人工智慧的使用，受到一系列要求和限制。我們認為這些要求和限制獲得 HI 的能力和目標的充分支持。我們的貢獻包括找出五個這樣的 DH 要求：成功的 AI 系統需要能夠 1) 與（人類）學者合作；2) 支援資料批評；3) 支援工具批評；4) 察覺並迎合各種觀點；5) 支援遠距和近距離閱讀。我們將混合智能的 CARE 原則（協作、適應、負責和可解釋）作為理論架構，並將這些原則對應到 DH 要求。在此對應中，我們納入範例研究專案。最後，我們探討如何將 DH 的見解應用於 HI，並討論結合這兩個學科的開放挑戰。

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

摘要：基礎模型 (FM) 具有徹底改變醫學影像的巨大潛力。然而，它們在現實世界臨床環境中的部署需要廣泛的倫理考量。本文旨在強調與 FM 相關的倫理問題，並提出一個框架來指導它們在醫學中的負責任開發和實施。我們仔細審查了倫理問題，例如患者數據隱私、偏差緩解、演算法透明度、可解釋性和問責制。所提出的框架旨在優先考慮患者福利、減輕潛在風險，並培養對 AI 輔助醫療保健的信任。

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

摘要：甲狀腺癌是一種日益嚴重的全球健康問題，需要先進的診斷方法。本篇評論探討了人工智能與放射特徵分析在甲狀腺癌診斷中的應用。在符合 PRISMA 指南的情況下，對多個資料庫進行了回顧，直到 2023 年 10 月。通過結合關鍵字，發現了一篇關於甲狀腺癌和相關主題的英文學術出版物。在移除 109 篇重複文獻後，原始搜尋共回傳 267 篇論文。在根據預先確定的標準，淘汰了 124 篇文章的摘要和標題後，選出了相關研究。在進行全面分析後，額外排除了六項研究。在納入的 28 項研究中，結合超音波 (US) 影像的放射特徵分析，證明了其在診斷甲狀腺癌方面的有效性。研究結果不一，有些研究提出了優於現狀的新策略。文獻強調了人工智能模型面臨的各種挑戰，包括可解釋性問題、資料集限制和操作員依賴性。28 項納入研究的綜合發現提到，需要標準化工作和前瞻性多中心研究來解決這些問題。此外，還確定了克服這些障礙的方法，例如可解釋人工智能技術和個人化醫療技術的進步。本篇評論重點探討了人工智能和放射特徵分析如何轉變甲狀腺癌的診斷和治療。儘管存在挑戰，但未來對多學科合作、臨床適用性驗證和演算法改進的研究，仍有潛力改善甲狀腺癌治療中的患者預後和診斷精準度。

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

摘要：<paragraph>近年來，乳癌的盛行率迅速增加，使其成為全球主要的死亡原因之一。在所有癌症中，乳癌迄今為止是最常見的。手動診斷此疾病需要大量的時間和專業知識。由於乳癌的檢測過程耗時，因此透過建立機器學習模型來預測，有助於防止其進一步擴散。機器學習和可解釋 AI 在分類中至關重要，因為它們不僅可以提供準確的預測，還可以深入了解模型如何做出決策，有助於理解和信賴分類結果。在此研究中，我們評估並比較了五種不同的機器學習方法的分類準確度、精確度、召回率和 F1 分數，使用了一個主要的資料集（達卡醫學院醫院的 500 名患者）。五種不同的監督式機器學習技術，包括決策樹、隨機森林、邏輯迴歸、朴素貝氏和 XGBoost，已用於在我們的資料集上取得最佳結果。此外，本研究將 SHAP 分析應用於 XGBoost 模型，以解釋模型的預測並了解每個特徵對模型輸出的影響。我們比較了幾種演算法對資料進行分類的準確度，並與該領域的其他文獻進行對比。在最後評估後，本研究發現 XGBoost 達到了最佳的模型準確度，為 97%。</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

摘要：深度學習 (DL) 用於從乳房攝影術影像診斷乳癌的模型通常以「黑盒子」方式運作，這使得醫療保健專業人員難以信任和理解其決策過程。本研究提出一個整合架構，結合卷積神經網路 (CNN) 和可解釋人工智慧 (XAI)，以使用 CBIS-DDSM 資料集增強乳癌的診斷。方法包含一個精細的資料前處理管線和進階資料擴充技術，以對抗資料集限制，並採用預先訓練的網路（例如 VGG-16、Inception-V3 和 ResNet）進行遷移學習。我們研究的重點是評估 XAI 在解釋模型預測中的有效性，重點利用豪斯多夫測度量化評估 AI 生成的解釋和專家註解之間的一致性。這種方法對於 XAI 在促進 AI 輔助診斷中的可信度和倫理公平性至關重要。我們研究的發現說明了 CNN 和 XAI 在推進乳癌診斷方法中的有效協作，從而促進了先進 AI 技術在臨床環境中的更順暢整合。透過增強 AI 驅動決策的可解釋性，這項工作為 AI 系統和醫療從業人員之間的改善協作奠定了基礎，最終豐富了患者照護。此外，我們研究的影響遠遠超出了目前的技術。它鼓勵進一步研究如何結合多模式資料並改善 AI 解釋，以滿足臨床實務的需求。

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

摘要：本研究提出了一種創新的多模態數據融合方法，用於疼痛行為識別，將統計相關分析與以人為中心的見解相結合。我們的做法引入了兩項關鍵創新：1) 將數據驅動的統計相關權重整合到融合策略中，以有效利用來自異質模態的補充信息，以及 2) 將以人為中心的運動特徵納入多模態表示學習中，以詳細建模疼痛行為。我們的模型在各種深度學習架構中得到驗證，展示了卓越的性能和廣泛的適用性。我們提出了一個可自定義的框架，根據統計顯著性將每個模態與合適的分類器對齊，推進個性化和有效的多模態融合。此外，我們的模型提供對多模態數據的可解釋分析，有助於醫療保健中的可解釋和可解釋 AI。通過強調數據多樣性和模態特定表示的重要性，我們增強了傳統的融合技術，並為識別複雜的疼痛行為設定了新的標準。我們的發現對促進以患者為中心的醫療保健干預和支持可解釋的臨床決策制定具有重要意義。

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

摘要：以人为本的可解释 AI (HCXAI) 倡导将社会层面整合到 AI 解释中。HCXAI 话语的核心是社会透明度 (ST) 框架，其目标是让 AI 系统的社会组织背景对用户来说是可理解的。在这项工作中，我们建议扩展 ST 框架以解决大型语言模型 (LLM) 中社会错误归因的风险，尤其是在心理健康等敏感领域。事实上，LLM 能够出色地模拟角色和人格，这可能导致设计者的意图和用户对社会属性的认知之间出现错配，从而有风险促进情绪操纵和危险行为、认知不公正和不合理的信任。为了解决这些问题，我们建议用第五个“W 问题”来增强 ST 框架，以明确设计者和用户赋予 LLM 的具体社会属性。此补充旨在弥合 LLM 能力和用户认知之间的差距，促进基于 LLM 的技术在道德上负责任地开发和使用。

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

摘要：<paragraph>背景：氣胸是一種因肺部與胸壁之間異常集氣所引起的急性胸腔疾病。為了解決深度學習（DL）模型經常伴隨的不透明性，可解釋人工智慧（XAI）方法已被引入，用於概述與 DL 模型做出的氣胸診斷相關的區域。然而，這些解釋有時會與實際病灶區域有所出入，突顯出進一步改進的必要性。方法：我們提出了一種模板引導式方法，將氣胸的臨床知識納入 XAI 方法產生的模型解釋中，從而提升這些解釋的品質。利用放射科醫師建立的病灶描繪，我們的做法首先產生一個模板，用於表示氣胸可能發生的區域。然後將此模板疊加在模型解釋上，以篩選出超出模板邊界的無關解釋。為了驗證其效力，我們對三種 XAI 方法進行了比較分析，在兩個真實世界資料集中解釋兩個 DL 模型時，分別採用和不採用我們的模板引導。結果：所提出的方法在建立於三種 XAI 方法、兩個 DL 模型和兩個資料集的十二種基準情境中，始終改善了基準 XAI 方法。在比較模型解釋和真實病灶區域時，透過基準效能的效能改進計算出的平均增量百分比為交集比（IoU）的 97.8% 和骰子相似性係數（DSC）的 94.1%。結論：在氣胸診斷的背景下，我們提出了一種模板引導式方法，用於改善 AI 解釋。我們預期我們的模板引導將透過整合臨床領域專業知識，為闡明 AI 模型建立一種新方法。</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by Séamus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

摘要：<paragraph>在當前機器翻譯 (MT) 領域中，Transformer 架構脫穎而出，成為黃金標準，特別是對於高資源語言對。本研究探討其對低資源語言對的效能，包括英語↔愛爾蘭語和英語↔馬拉地語語言對。值得注意的是，本研究識別出最佳超參數和子詞模型類型，以顯著提高 Transformer 模型對低資源語言對的翻譯品質。
低資源語言的平行資料集的稀缺會阻礙 MT 的發展。為了解決這個問題，開發了 gaHealth，這是愛爾蘭語的第一個雙語健康資料語料庫。專注於健康領域，使用此域內資料集開發的模型在 BLEU 得分方面表現出非常顯著的進步，與 LoResMT2021 共享任務中的模型相比。隨後使用多維品質指標錯誤分類法進行的人工評估顯示，與基於 RNN 的對應模型相比，Transformer 系統在減少準確性和流暢性錯誤方面表現出優異的性能。
此外，本論文介紹了 adaptNMT 和 adaptMLLM，這兩個開源應用程式簡化了神經機器翻譯模型的開發、微調和部署。這些工具大幅簡化了設定和評估流程，讓 MT 更容易讓開發人員和翻譯人員使用。值得注意的是，adaptNMT 以 OpenNMT 生態系統為基礎，通過強調模型開發的環境足跡來促進生態友好的自然語言處理研究。與 LoResMT2021 共享任務中的基準相比，adaptMLLM 對 MLLM 的微調證明了英語↔愛爾蘭語和英語↔馬拉地語這兩個低資源語言對的翻譯性能進步。</paragraph>

##### **Cause and Effect: Can Large Language Models Truly Understand Causality?**
2402.18139v3 by Swagata Ashwani, Kshiteesh Hegde, Nishith Reddy Mannuru, Mayank Jindal, Dushyant Singh Sengar, Krishna Chaitanya Rao Kathala, Dishant Banga, Vinija Jain, Aman Chadha

With the rise of Large Language Models(LLMs), it has become crucial to
understand their capabilities and limitations in deciphering and explaining the
complex web of causal relationships that language entails. Current methods use
either explicit or implicit causal reasoning, yet there is a strong need for a
unified approach combining both to tackle a wide array of causal relationships
more effectively. This research proposes a novel architecture called Context
Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to
enhance causal reasoning and explainability. The proposed framework
incorporates an explicit causal detection module with ConceptNet and
counterfactual statements, as well as implicit causal detection through LLMs.
Our framework goes one step further with a layer of counterfactual explanations
to accentuate LLMs understanding of causality. The knowledge from ConceptNet
enhances the performance of multiple causal reasoning tasks such as causal
discovery, causal identification and counterfactual reasoning. The
counterfactual sentences add explicit knowledge of the not caused by scenarios.
By combining these powerful modules, our model aims to provide a deeper
understanding of causal relationships, enabling enhanced interpretability.
Evaluation of benchmark datasets shows improved performance across all metrics,
such as accuracy, precision, recall, and F1 scores. We also introduce
CausalNet, a new dataset accompanied by our code, to facilitate further
research in this domain.

摘要：隨著大型語言模型 (LLM) 的興起，了解它們在解碼和解釋語言所蘊含的複雜因果關係網路中的能力和限制變得至關重要。目前的技術使用明確或隱含的因果推理，但強烈需要一種統一的方法，結合兩者以更有效地處理廣泛的因果關係。本研究提出了一種稱為情境感知推理增強與反事實分析 (CARE CA) 框架的新架構，以增強因果推理和可解釋性。提出的框架結合了使用 ConceptNet 和反事實陳述的明確因果檢測模組，以及透過 LLM 進行的隱含因果檢測。我們的框架更進一步，加入一層反事實解釋，以強調 LLM 對因果關係的理解。來自 ConceptNet 的知識增強了多項因果推理任務的執行，例如因果發現、因果識別和反事實推理。反事實句加入了未由情境造成的明確知識。透過結合這些強大的模組，我們的模型旨在提供對因果關係更深入的理解，實現增強的可解釋性。基準資料集的評估顯示在所有指標（例如準確度、精確度、召回率和 F1 分數）上都有所提升。我們還引入了 CausalNet，一個新的資料集，並附上了我們的程式碼，以促進在這個領域的進一步研究。

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

摘要：糖尿病（DM）使患者容易出現血管併發症。
視網膜影像和血管反映身體的微血管和巨血管健康狀況。它們可用於診斷糖尿病併發症，包括糖尿病視網膜病變（DR）、神經病變、腎病和動脈粥樣硬化性心血管疾病，以及預測心血管事件的風險。為使用數位化視網膜影像進行高通量 DR 檢測而開發的人工智慧（AI）啟用系統已在臨床採用。除了 DR 篩檢外，AI 整合也具有巨大的潛力來應對與糖尿病患者整體照護相關的挑戰。在這項工作中，我們旨在全面回顧基於視網膜影像的 AI 應用相關研究的文獻，這些研究與糖尿病的診斷、預後和管理有關。我們將描述整體 AI 輔助糖尿病照護的發現，包括但不限於 DR 篩檢，並討論實施此類系統的障礙，包括與倫理、資料隱私、公平存取和可解釋性有關的問題。透過評估患者的健康狀況，同時考量糖尿病併發症以及未來心血管併發症的風險預後，AI 輔助視網膜影像分析有潛力成為糖尿病患者現代化個人化醫療的中心工具。

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

摘要：這項研究從多個利害關係人的角度探討不同的人工智慧 (AI) 應用在教育上的可接受性，包括學生、老師和家長。承認 AI 在教育上的轉型潛力，它解決了與資料隱私、AI 代理、透明度、可解釋性和 AI 的道德部署相關的疑慮。透過小插曲方法，參與者被呈現了四種情境，其中 AI 的代理、透明度、可解釋性和隱私受到操縱。在每個情境後，參與者完成了一項調查，該調查捕捉了他們對 AI 的整體效用、個人效用、正義、信心、風險和如果可用，使用每個情境的 AI 的意圖的看法。資料蒐集包含來自合作機構和社群媒體活動的 1198 位多利害關係人參與者的最終樣本，並專注於對四個 AI 使用案例的個別回應。對資料的調解分析表明，對 AI 的接受度和信任在利害關係人團體之間有顯著差異。我們發現，AI 的代理、透明度和可解釋性高低程度之間的關鍵調解者，以及使用不同教育 AI 的意圖，包括感知到的整體效用、正義和信心。這項研究強調，接受 AI 在教育上的應用是一個微妙且多面向的問題，除了不同的利害關係人的看法外，還需要仔細考慮具體的 AI 應用及其特徵。

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

摘要：<paragraph>基於可穿戴式單導程心電圖 (ECG) 裝置的遠端病患監測在早期偵測心臟疾病方面具有顯著的潛力，特別是與用於自動化心臟疾病偵測的人工智慧 (AI) 方法結合使用時。先前已有研究應用基於深度學習的 AI 方法進行心臟疾病偵測。然而，這些模型尚未被廣泛接受為臨床診斷的可靠輔助工具，部分原因在於圍繞許多 AI 演算法的當前黑箱感知。特別是，有必要找出有助於做出準確診斷的 ECG 訊號關鍵特徵，從而增強模型的可解釋性。在本研究中，我們開發了一種視覺轉換器方法，以根據單導程 ECG 資料找出心房顫動。殘差網路 (ResNet) 方法也已開發出來，以便與視覺轉換器方法進行比較。這些模型應用於 Chapman-Shaoxing 資料集，以分類心房顫動，以及另一種常見的心律不整，竇性心動過緩，和正常竇性心律的心跳。這些模型能夠找出決定最終分類的心跳關鍵區域，並強調 P 波和 T 波，以及心跳持續時間和訊號振幅在區分正常竇性心律與心房顫動和竇性心動過緩方面的重要性。</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

摘要：本文介紹了一種使用先進大型語言模型 (LLM) 進行憂鬱症偵測和治療的新模式：生成式預訓練Transformer 4 (GPT-4)、Llama 2 聊天機器人和 Gemini。這些 LLM 經過微調，具備專業提示，可診斷、解釋並建議憂鬱症的治療介入方法。一種獨特的少次提示方法增強了模型根據 DSM-5 標準分析和解釋憂鬱症狀的能力。在互動階段，這些模型會參與同理心對話管理，從 PsychDB 和認知行為療法 (CBT) 指南等資源中汲取，促進與經歷重度憂鬱症的人們的支持性互動。此外，這項研究還介紹了 Illuminate 資料庫，其中包含各種 CBT 模組，有助於個性化治療建議。這項研究使用 F1 分數、準確率、召回率、餘弦相似度和面向召回率的 Gisting 評估替身 (ROUGE) 等指標，在不同的測試集中評估 LLM 的表現，證明了它們的有效性。這種綜合方法結合了尖端的 AI 與既定的心理方法，為心理保健提供了新的可能性，並展示了 LLM 在革新憂鬱症診斷和治療策略方面的潛力。

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v6 by Timothée Schmude, Laura Koesten, Torsten Möller, Sebastian Tschiatschek

Every AI system that makes decisions about people has a group of stakeholders
that are personally affected by these decisions. However, explanations of AI
systems rarely address the information needs of this stakeholder group, who
often are AI novices. This creates a gap between conveyed information and
information that matters to those who are impacted by the system's decisions,
such as domain experts and decision subjects. To address this, we present the
"XAI Novice Question Bank," an extension of the XAI Question Bank containing a
catalog of information needs from AI novices in two use cases: employment
prediction and health monitoring. The catalog covers the categories of data,
system context, system usage, and system specifications. We gathered
information needs through task-based interviews where participants asked
questions about two AI systems to decide on their adoption and received verbal
explanations in response. Our analysis showed that participants' confidence
increased after receiving explanations but that their understanding faced
challenges. These included difficulties in locating information and in
assessing their own understanding, as well as attempts to outsource
understanding. Additionally, participants' prior perceptions of the systems'
risks and benefits influenced their information needs. Participants who
perceived high risks sought explanations about the intentions behind a system's
deployment, while those who perceived low risks rather asked about the system's
operation. Our work aims to support the inclusion of AI novices in
explainability efforts by highlighting their information needs, aims, and
challenges. We summarize our findings as five key implications that can inform
the design of future explanations for lay stakeholder audiences.

摘要：<paragraph>每個對人做出決定的 AI 系統都有一群利害關係人
受到這些決定的親身影響。然而，AI
系統的解釋很少能滿足這群利害關係人的資訊需求，而他們
通常都是 AI 新手。這造成了傳達資訊與
受到系統決策影響的人士（例如領域專家和決策主體）重視的資訊之間的落差。為了解決這個問題，我們提出了
「XAI 新手問題庫」，它是 XAI 問題庫的延伸，包含來自 AI 新手在兩個使用案例中的資訊需求目錄：就業
預測和健康監測。目錄涵蓋了資料、
系統背景、系統使用和系統規格等類別。我們透過任務型訪談收集資訊需求，參與者在訪談中詢問了兩個 AI 系統的問題，以決定是否採用它們，並收到口頭
解釋作為回應。我們的分析顯示，參與者在收到解釋後信心有所提升，但他們的理解卻面臨挑戰。這些挑戰包括難以找到資訊和評估自己的理解，以及試圖外包
理解。此外，參與者對系統風險和好處的先前回饋影響了他們的資訊需求。認為風險高的參與者尋求解釋系統部署背後的意圖，而認為風險低的人則詢問系統的
操作。我們的研究旨在透過強調 AI 新手的資訊需求、目標和
挑戰，來支持將 AI 新手納入可解釋性工作中。我們將我們的研究結果總結為五個關鍵啟示，這些啟示可以為未來針對非專業利害關係人受眾的解釋設計提供參考。</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet Gürkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

摘要：人工智慧 (AI) 的快速演進，尤其是在大型語言模型 (LLM) 和生成式 AI 的領域，為各個領域的應用開啟了新途徑，但其在商業教育中的角色仍未被充分探討。本研究首次引入了基準，用以評估七個主要 LLM 的效能，包括 OpenAI 的模型 (GPT-3.5 Turbo、GPT-4 和 GPT-4 Turbo)、Google 的模型 (PaLM 2、Gemini 1.0 Pro) 和 Anthropic 的模型 (Claude 2 和 Claude 2.1)，這些模型將用於研究生商業課程入學程序中的關鍵考試 GMAT。我們的分析顯示，大多數 LLM 的表現都優於人類考生，其中 GPT-4 Turbo 不僅優於其他模型，更超越了頂尖商學院的研究生平均分數。透過案例研究，本研究探討了 GPT-4 Turbo 在解釋答案、評估回應、辨識錯誤、調整說明和產生替代情境方面的能力。與前一代版本相比，最新的 LLM 版本 GPT-4 Turbo、Claude 2.1 和 Gemini 1.0 Pro 在推理任務方面有顯著的進步，凸顯了其在解決複雜問題方面的潛力。儘管 AI 在教育、評量和輔導方面的承諾很明確，但仍有挑戰存在。我們的研究不僅闡明了 LLM 的學術潛力，也強調了在教育中審慎開發和應用 AI 的必要性。隨著 AI 技術的進步，建立 AI 互動的架構和協定、驗證 AI 生成的內容的準確性、確保全球各地多元學習者的存取權，以及創造一個 AI 支持人類專業知識的教育環境至關重要。本研究為進一步探索負責任地使用 AI 來豐富教育體驗並改善考試準備和評量方法奠定了基礎。

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

摘要：預測加護病房 (ICU) 病患的院內死亡率是最終臨床結果的關鍵。AI 已展現出優異的準確度，但卻缺乏可解釋性。為了解決這個問題，本文提出了一個可解釋的多模式死亡率預測器 (X-MMP)，採用有效且可解釋的 AI 方式，藉由多模式 ICU 資料來預測院內死亡率。我們在架構中採用多模式學習，可以接收來自臨床資料的異質輸入並做出決策。此外，我們引入了一個可解釋的方法，也就是分層傳播至 Transformer，作為 LRP 方法適當地延伸至 Transformer，對多模式輸入產生解釋，並揭露歸因於預測的顯著特徵。此外，每個模式對臨床結果的貢獻可以視覺化，協助臨床醫師了解決策背後的理由。我們根據 MIMIC-III 和 MIMIC-III 波形資料庫比對子集建構了一個多模式資料集。在基準資料集上的全面實驗證明，我們提出的架構可以達成合理的詮釋，並具備競爭力的預測準確度。特別是，我們的架構可以輕鬆地轉移到其他臨床任務，這有助於在醫療保健研究中發現關鍵因素。

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian Geißler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, Björn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias Küster, André Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

摘要：在過去的十年中，病理學中的人工智慧 (AI) 方法已大幅進步。然而，由於許多挑戰，包括將研究結果轉化為臨床診斷產品在技術和法規方面的障礙，以及缺乏標準化介面，導致整合到常規臨床實務中進展緩慢。開放且與供應商無關的 EMPAIA 計畫應對了這些挑戰。在此，我們提供 EMPAIA 的成就和經驗教訓的概述。EMPAIA 整合了病理學 AI 生態系統的各個利害關係人，即病理學家、電腦科學家和產業。在密切合作下，我們制定了技術互通性標準、AI 測試和產品開發建議，以及可解釋性方法。我們實作了模組化且開放原始碼的 EMPAIA 平臺，並成功整合了來自 8 個不同供應商的 14 個基於 AI 的影像分析應用程式，展示了不同的應用程式如何使用單一的標準化介面。我們優先考慮需求，並評估了 AI 在歐洲和亞洲的 14 個不同病理實驗室中的實際臨床應用。除了技術開發外，我們還為所有利害關係人建立了一個論壇，以分享數位病理學和 AI 的資訊和經驗。商業、臨床和學術利害關係人現在可以採用 EMPAIA 的常見開放原始碼介面，這為大規模標準化和簡化流程提供了獨特的機會。需要進一步的努力才能有效且廣泛地建立例行實驗室使用中的 AI 輔助。為此，已成立非營利協會 EMPAIA International，以作為永續基礎架構，繼續進行標準化，並支援廣泛實作和倡導 AI 輔助數位病理學的未來。

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

摘要：反事實解釋 (CE) 技術已引起關注，作為一種為與 AI 系統互動的使用者提供見解的方法。雖然在醫學影像和自動駕駛汽車等領域廣泛研究，圖形反事實解釋 (GCE) 方法相對較少被探索。GCE 會產生一個類似於原始圖形的新圖形，並根據基礎預測模型產生不同的結果。在這些 GCE 技術中，儘管在其他領域（例如藝術風格和自然語言建模）中展現出令人印象深刻的成就，但植基於生成機制的技術獲得的關注相對有限。對生成式解釋器的偏好源於它們在推理期間產生反事實實例的能力，利用輸入圖形的自主獲取擾動。基於上述理由，我們的研究引入了 RSGG-CE，一種用於反事實解釋的新型穩健隨機圖形生成器，能夠從學習到的潛在空間中產生反事實範例，考慮部分有序的生成序列。此外，我們進行定量和定性分析，以比較 RSGG-CE 的效能與 SoA 生成式解釋器，強調其增強了產生合理解釋候選的能力。

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

摘要：可解釋 AI 的動機之一是讓人們在使用和部署 AI 模型時做出更好、更明智的決策。但需要仔細評估以評估是否已達到此預期。目前的評估主要集中在解釋的演算法特性，而涉及人類受試者的評估通常採用主觀問題來測試人類對解釋有用性的看法，而沒有基於客觀指標和測量。在這項工作中，我們評估解釋是否可以在機器學習模型開發的實際場景中改善人類決策制定。我們進行了一項涉及影像資料的混合方法使用者研究，以評估 SmoothGrad、GradCAM 和預言解釋在兩個任務中產生的顯著性圖：模型選擇和反事實模擬。令人驚訝的是，我們沒有發現任何顯著性圖（即使是設計為易於理解且高度指示答案的合成預言解釋）能讓使用者在這些任務上顯著改善的證據。儘管如此，解釋確實有助於使用者更準確地描述模型。這些發現提示我們要對基於顯著性的解釋中可能存在誤解的有用性保持謹慎。

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

摘要：可解釋性和安全性建立信任。這些需要一個模型來展示一致性和可靠性。為了實現這些，有必要使用和分析數據和知識，並使用與 AI 應用相關的統計和符號 AI 方法 - 單獨使用任何一種方法都不會奏效。因此，我們主張並試圖證明 NeuroSymbolic AI 方法更適合於使 AI 成為受信任的 AI 系統。我們提出了 CREST 框架，展示了一致性、可靠性、使用者層級的可解釋性和安全性是如何建立在 NeuroSymbolic 方法上的，該方法使用數據和知識來支持關鍵應用（例如健康和福祉）的要求。本文重點關注大型語言模型 (LLM)，因為它是 CREST 框架中選擇的 AI 系統。LLM 因其在處理廣泛的自然語言處理 (NLP) 場景方面的多功能性而備受研究人員的關注。例如，ChatGPT 和 Google 的 MedPaLM 已成為提供一般和健康相關查詢信息的極有希望的平台。儘管如此，這些模型仍然是黑盒子，儘管納入了人類反饋和指令引導的調整。例如，儘管制定了安全防護措施，ChatGPT 仍可能產生不安全的回應。CREST 提出了一種合理的方法，在 NeuroSymbolic 框架中利用程序和基於圖表的知識，以闡明與 LLM 相關的挑戰。

##### **Class-Discriminative Attention Maps for Vision Transformers**
2312.02364v3 by Lennart Brocki, Jakub Binda, Neo Christopher Chung

Importance estimators are explainability methods that quantify feature
importance for deep neural networks (DNN). In vision transformers (ViT), the
self-attention mechanism naturally leads to attention maps, which are sometimes
interpreted as importance scores that indicate which input features ViT models
are focusing on. However, attention maps do not account for signals from
downstream tasks. To generate explanations that are sensitive to downstream
tasks, we have developed class-discriminative attention maps (CDAM), a
gradient-based extension that estimates feature importance with respect to a
known class or a latent concept. CDAM scales attention scores by how relevant
the corresponding tokens are for the predictions of a classifier head. In
addition to targeting the supervised classifier, CDAM can explain an arbitrary
concept shared by selected samples by measuring similarity in the latent space
of ViT. Additionally, we introduce Smooth CDAM and Integrated CDAM, which
average a series of CDAMs with slightly altered tokens. Our quantitative
benchmarks include correctness, compactness, and class sensitivity, in
comparison to 7 other importance estimators. Vanilla, Smooth, and Integrated
CDAM excel across all three benchmarks. In particular, our results suggest that
existing importance estimators may not provide sufficient class-sensitivity. We
demonstrate the utility of CDAM in medical images by training and explaining
malignancy and biomarker prediction models based on lung Computed Tomography
(CT) scans. Overall, CDAM is shown to be highly class-discriminative and
semantically relevant, while providing compact explanations.

摘要：<paragraph>重要性估計器是一種可解釋性方法，用於量化深度神經網路 (DNN) 的特徵重要性。在視覺Transformer (ViT) 中，自我注意機制自然會導致注意力圖，有時會將其解釋為重要性分數，表示 ViT 模型關注哪些輸入特徵。然而，注意力圖並未考慮來自下游任務的信號。為了產生對下游任務敏感的解釋，我們開發了類別區分注意力圖 (CDAM)，這是一種基於梯度的擴充，用於估計相對於已知類別或潛在概念的特徵重要性。CDAM 根據對應的符號與分類器頭的預測相關程度，調整注意力分數。除了針對監督分類器外，CDAM 還可以通過測量 ViT 的潛在空間中的相似性來解釋選定樣本共有的任意概念。此外，我們引入了平滑 CDAM 和積分 CDAM，它們對一系列具有略微改變的符號的 CDAM 進行平均。我們的量化基準包括正確性、緊湊性和類別敏感性，與其他 7 個重要性估計器相比。香草、平滑和積分 CDAM 在所有三個基準中表現出色。特別是，我們的結果表明現有的重要性估計器可能無法提供足夠的類別敏感性。我們通過基於肺部電腦斷層掃描 (CT) 掃描訓練和解釋惡性腫瘤和生物標記預測模型，證明了 CDAM 在醫學影像中的效用。總的來說，CDAM 被證明具有高度類別區分性和語義相關性，同時提供簡潔的解釋。</paragraph>

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano, Stephen Glass, Ravi P. Ramachandran, Sharad Patel, Aaron J. Masino, Ghulam Rasool

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

摘要：本研究调查了在 COVID-19 疫情期间及以后预测死亡率时，已部署人工智能 (AI) 模型的性能、可解释性和稳健性。作为同类研究中的首例，我们发现贝叶斯神经网络 (BNN) 和智能训练技术让我们的模型在数据发生重大变化时仍能保持性能。我们的结果强调了开发稳健的 AI 模型的重要性，即使在具有挑战性的条件下，这些模型也能匹配或超越临床医生的预测。我们对模型可解释性的探索表明，随机模型会产生更多样化且个性化的解释，从而突出了在现实世界的临床环境中提供详细且个性化见解的 AI 模型的必要性。此外，我们强调了量化 AI 模型中不确定性的重要性，这使临床医生能够根据可靠的预测做出更明智的决策。我们的研究提倡在医疗保健的 AI 研究中优先考虑实施科学，并确保 AI 解决方案在现实世界的临床环境中实用、有益且可持续。通过解决医疗保健环境中的独特挑战和复杂性，研究人员可以开发出有效改善临床实践和患者预后的 AI 模型。

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel, Aaron Quyn, David Jayne, Samuel D. Relton

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

摘要：肺癌占英國癌症死亡人數的 21%，五年存活率很大程度取決於癌症被發現的階段。最近的研究已證明人工智能方法具有從例行掃描中準確及早診斷肺癌的能力。然而，此證據尚未轉化為臨床實務，其中一個障礙是缺乏可解釋的模型。本研究探討了應用變分自動編碼器 (VAE)，一種生成式人工智能模型，於肺癌病灶。將提出的模型訓練於從 LIDC-IDRI 公共數據集中提取的 3D 電腦斷層掃描病灶。通過聚類探索了 VAE 生成的 2D 切片的潛在向量表示，以證明其品質，並用於肺癌診斷的 MLP 分類器模型，最佳模型達到了 AUC 0.98 和 93.1% 準確度的最先進指標。聚類分析顯示，VAE 潛在空間根據有意義的特徵組成（包括腫瘤大小、形狀、患者和惡性類別）將惡性和良性病灶的數據集分開。我們還包括標準高斯 VAE (GVAE) 和更新的狄利克雷 VAE (DirVAE) 的比較分析，後者用狄利克雷分佈取代先驗，以促進具有解開特徵表示的更具可解釋性的潛在空間。最後，我們展示了與臨床有意義的特徵變化相應的潛在空間橫越的潛力。

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

摘要：現有的圖像分類器輸出解釋工具可分為依賴於模型內部存取權限的白盒，以及與模型無關的黑盒。隨著 AI 在醫療領域的使用增加，可解釋性工具的使用也隨之增加。現有醫學影像解釋的工作重點在於白盒工具，例如 gradcam。然而，切換到黑盒工具有明顯的優點，包括能夠與任何分類器一起使用，以及廣泛的黑盒工具可供選擇。在標準影像上，黑盒工具與白盒一樣精確。在本文中，我們比較了多種黑盒方法在腦癌 MRI 資料集上與 gradcam 的效能。我們證明大多數黑盒工具不適合解釋醫學影像分類，並詳細分析其缺點的原因。我們還表明一種黑盒工具，基於因果可解釋性的 rex，表現與 \gradcam 一樣好。

##### **Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**
2311.12573v3 by Robert Gorwa, Michael Veale

The AI development community is increasingly making use of hosting
intermediaries such as Hugging Face provide easy access to user-uploaded models
and training data. These model marketplaces lower technical deployment barriers
for hundreds of thousands of users, yet can be used in numerous potentially
harmful and illegal ways. In this article, we explain ways in which AI systems,
which can both `contain' content and be open-ended tools, present one of the
trickiest platform governance challenges seen to date. We provide case studies
of several incidents across three illustrative platforms -- Hugging Face,
GitHub and Civitai -- to examine how model marketplaces moderate models.
Building on this analysis, we outline important (and yet nevertheless limited)
practices that industry has been developing to respond to moderation demands:
licensing, access and use restrictions, automated content moderation, and open
policy development. While the policy challenge at hand is a considerable one,
we conclude with some ideas as to how platforms could better mobilize resources
to act as a careful, fair, and proportionate regulatory access point.

摘要：AI 開發社群日益利用 Hugging Face 等託管中介機構提供用戶上傳的模型和訓練資料的簡易存取權限。這些模型市集降低了數十萬名用戶的技術部署障礙，但可能會被用於許多潛在有害和非法的方式。在本文中，我們說明 AI 系統既可以「包含」內容，又可以作為開放式工具，這提出了迄今為止最棘手的平台治理挑戰之一。我們提供 Hugging Face、GitHub 和 Civitai 等三個說明性平台上數起事件的案例研究，以檢視模型市集如何審核模型。根據此分析，我們概述產業為回應審核需求而開發的重要（但仍有限）實務：授權、存取和使用限制、自動化內容審核和開放政策制定。雖然當前政策挑戰相當可觀，我們最後提出一些構想，說明平台如何能更好地動員資源，作為謹慎、公平且適度的法規存取點。

##### **Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**
2311.11932v1 by Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker

Background and objectives: By extracting this information, Machine or Deep
Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and
cancer researchers in discovering patterns and relationships from complex data
sets. Many DL-based analyses on ovarian cancer (OC) data have recently been
published. These analyses are highly diverse in various aspects of cancer
(e.g., subdomain(s) and cancer type they address) and data analysis features.
However, a comprehensive understanding of these analyses in terms of these
features and AI assurance (AIA) is currently lacking. This systematic review
aims to fill this gap by examining the existing literature and identifying
important aspects of OC data analysis using DL, explicitly focusing on the key
features and AI assurance perspectives. Methods: The PRISMA framework was used
to conduct comprehensive searches in three journal databases. Only studies
published between 2015 and 2023 in peer-reviewed journals were included in the
analysis. Results: In the review, a total of 96 DL-driven analyses were
examined. The findings reveal several important insights regarding DL-driven
ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on
detection and diagnosis, while no study addressed the prediction and prevention
of OC. - The analyses were predominantly based on samples from a non-diverse
population (75% (72/96 studies)), limited to a geographic location or country.
- Only a small proportion of studies (only 33% (32/96)) performed integrated
analyses, most of which used homogeneous data (clinical or omics). - Notably, a
mere 8.3% (8/96) of the studies validated their models using external and
diverse data sets, highlighting the need for enhanced model validation, and -
The inclusion of AIA in cancer data analysis is in a very early stage; only
2.1% (2/96) explicitly addressed AIA through explainability.

摘要：<paragraph>背景和目標：通過提取這些資訊，機器或深度學習 (ML/DL) 基於自主數據分析工具可以協助臨床醫生和癌症研究人員從複雜的數據集中發現模式和關係。最近已發表許多基於 DL 的卵巢癌 (OC) 數據分析。這些分析在癌症的各個方面（例如，它們涉及的子領域和癌症類型）和數據分析功能方面高度多樣化。然而，目前缺乏對這些分析在這些特徵和 AI 保證 (AIA) 方面的全面理解。這篇系統性回顧旨在通過檢視現有文獻並明確關注關鍵特徵和 AI 保證觀點，來填補這個空白。方法：使用 PRISMA 架構在三個期刊資料庫中進行全面搜尋。分析僅包括 2015 年至 2023 年間發表於同行評審期刊的研究。結果：在回顧中，總共檢視了 96 項由 DL 驅動的分析。研究結果揭示了幾個關於由 DL 驅動的卵巢癌數據分析的重要見解：- 大多數研究 71%（96 項中有 68 項）專注於檢測和診斷，而沒有研究探討 OC 的預測和預防。- 這些分析主要基於來自非多元族群的樣本（75%（96 項研究中的 72 項）），僅限於某個地理位置或國家。- 只有少部分研究（僅 33%（96 項研究中的 32 項）執行整合分析，其中大多數使用同質數據（臨床或組學）。- 值得注意的是，只有 8.3%（96 項研究中的 8 項）使用外部和多元數據集驗證了其模型，強調了加強模型驗證的必要性，以及- 將 AIA 納入癌症數據分析仍處於非常早期的階段；只有 2.1%（96 項研究中的 2 項）透過可解釋性明確探討了 AIA。</paragraph>

##### **Representing visual classification as a linear combination of words**
2311.10933v1 by Shobhit Agarwal, Yevgeniy R. Semenov, William Lotter

Explainability is a longstanding challenge in deep learning, especially in
high-stakes domains like healthcare. Common explainability methods highlight
image regions that drive an AI model's decision. Humans, however, heavily rely
on language to convey explanations of not only "where" but "what".
Additionally, most explainability approaches focus on explaining individual AI
predictions, rather than describing the features used by an AI model in
general. The latter would be especially useful for model and dataset auditing,
and potentially even knowledge generation as AI is increasingly being used in
novel tasks. Here, we present an explainability strategy that uses a
vision-language model to identify language-based descriptors of a visual
classification task. By leveraging a pre-trained joint embedding space between
images and text, our approach estimates a new classification task as a linear
combination of words, resulting in a weight for each word that indicates its
alignment with the vision-based classifier. We assess our approach using two
medical imaging classification tasks, where we find that the resulting
descriptors largely align with clinical knowledge despite a lack of
domain-specific language training. However, our approach also identifies the
potential for 'shortcut connections' in the public datasets used. Towards a
functional measure of explainability, we perform a pilot reader study where we
find that the AI-identified words can enable non-expert humans to perform a
specialized medical task at a non-trivial level. Altogether, our results
emphasize the potential of using multimodal foundational models to deliver
intuitive, language-based explanations of visual tasks.

摘要：<paragraph>解釋性是深度學習中長期的挑戰，特別是在醫療保健等高風險領域。常見的解釋性方法會強調驅動 AI 模型決策的影像區域。然而，人類很大程度依賴語言來傳達不僅是「在哪裡」，還有「是什麼」的解釋。此外，大多數解釋性方法都專注於解釋個別 AI 預測，而不是描述 AI 模型一般使用的特徵。後者對於模型和資料集稽核特別有用，甚至可能在 AI 愈來愈用於新穎任務時產生知識。在此，我們提出一個使用視覺語言模型來辨識視覺分類任務的語言描述符的解釋性策略。透過利用影像和文字之間預先訓練的聯合嵌入空間，我們的做法將新的分類任務估計為一個線性文字組合，導致每個文字都有權重，表示它與基於視覺的分類器對齊。我們使用兩個醫學影像分類任務來評估我們的做法，我們發現產生的描述符在很大程度上與臨床知識一致，儘管缺乏特定領域的語言訓練。然而，我們的做法也發現了所用公開資料集中的「捷徑連線」的可能性。為了達到解釋性的功能性衡量，我們進行了一項試驗讀者研究，發現 AI 識別的文字能讓非專家人類在非平凡的層級執行專業的醫療任務。總之，我們的結果強調了使用多模式基礎模型來提供直觀的、基於語言的視覺任務解釋的潛力。</paragraph>


### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-04**|**Intuitive Axial Augmentation Using Polar-Sine-Based Piecewise Distortion for Medical Slice-Wise Segmentation**|Yiqin Zhang et.al.|[2412.03352v1](http://arxiv.org/abs/2412.03352v1)|[link](https://github.com/mgamz/psbpd)|
|**2024-12-04**|**Detecting abnormal heart sound using mobile phones and on-device IConNet**|Linh Vu et.al.|[2412.03267v1](http://arxiv.org/abs/2412.03267v1)|null|
|**2024-12-04**|**MRNet: Multifaceted Resilient Networks for Medical Image-to-Image Translation**|Hyojeong Lee et.al.|[2412.03039v1](http://arxiv.org/abs/2412.03039v1)|null|
|**2024-12-04**|**Higher Order Transformers: Efficient Attention Mechanism for Tensor Structured Data**|Soroush Omranpour et.al.|[2412.02919v1](http://arxiv.org/abs/2412.02919v1)|null|
|**2024-12-03**|**A Novel Compact LLM Framework for Local, High-Privacy EHR Data Applications**|Yixiang Qu et.al.|[2412.02868v1](http://arxiv.org/abs/2412.02868v1)|null|
|**2024-12-03**|**Block MedCare: Advancing healthcare through blockchain integration with AI and IoT**|Oliver Simonoski et.al.|[2412.02851v1](http://arxiv.org/abs/2412.02851v1)|null|
|**2024-12-03**|**CNNSum: Exploring Long-Conext Summarization with Large Language Models in Chinese Novels**|Lingxiao Wei et.al.|[2412.02819v1](http://arxiv.org/abs/2412.02819v1)|null|
|**2024-12-03**|**Optimization of Transformer heart disease prediction model based on particle swarm optimization algorithm**|Peiyang Yu et.al.|[2412.02801v1](http://arxiv.org/abs/2412.02801v1)|null|
|**2024-12-03**|**Medical Multimodal Foundation Models in Clinical Diagnosis and Treatment: Applications, Challenges, and Future Directions**|Kai Sun et.al.|[2412.02621v1](http://arxiv.org/abs/2412.02621v1)|null|
|**2024-12-03**|**U-Net in Medical Image Segmentation: A Review of Its Applications Across Modalities**|Fnu Neha et.al.|[2412.02242v1](http://arxiv.org/abs/2412.02242v1)|null|
|**2024-12-03**|**Recovering implicit physics model under real-world constraints**|Ayan Banerjee et.al.|[2412.02215v1](http://arxiv.org/abs/2412.02215v1)|null|
|**2024-12-03**|**Comparative Performance of Machine Learning Algorithms for Early Genetic Disorder and Subclass Classification**|Abu Bakar Siddik et.al.|[2412.02189v1](http://arxiv.org/abs/2412.02189v1)|null|
|**2024-12-03**|**Anatomically-Grounded Fact Checking of Automated Chest X-ray Reports**|R. Mahmood et.al.|[2412.02177v1](http://arxiv.org/abs/2412.02177v1)|null|
|**2024-12-03**|**Keeping Experts in the Loop: Expert-Guided Optimization for Clinical Data Classification using Large Language Models**|Nader Karayanni et.al.|[2412.02173v1](http://arxiv.org/abs/2412.02173v1)|null|
|**2024-12-03**|**Construction and optimization of health behavior prediction model for the elderly in smart elderly care**|Qian Guo et.al.|[2412.02062v1](http://arxiv.org/abs/2412.02062v1)|null|
|**2024-12-02**|**INSIGHT: Explainable Weakly-Supervised Medical Image Analysis**|Wenbo Zhang et.al.|[2412.02012v1](http://arxiv.org/abs/2412.02012v1)|null|
|**2024-12-02**|**The use of large language models to enhance cancer clinical trial educational materials**|Mingye Gao et.al.|[2412.01955v2](http://arxiv.org/abs/2412.01955v2)|null|
|**2024-12-02**|**Recurrent Neural Network on PICTURE Model**|Weihan Xu et.al.|[2412.01933v1](http://arxiv.org/abs/2412.01933v1)|null|
|**2024-12-02**|**ECG-SleepNet: Deep Learning-Based Comprehensive Sleep Stage Classification Using ECG Signals**|Poorya Aghaomidi et.al.|[2412.01929v1](http://arxiv.org/abs/2412.01929v1)|null|
|**2024-12-02**|**Deep Guess acceleration for explainable image reconstruction in sparse-view CT**|Elena Loli Piccolomini et.al.|[2412.01703v1](http://arxiv.org/abs/2412.01703v1)|[link](https://github.com/devangelista2/DeepGuess)|
|**2024-12-02**|**Digital Epidemiology: Leveraging Social Media for Insight into Epilepsy and Mental Health**|Liza Dahiya et.al.|[2412.01692v1](http://arxiv.org/abs/2412.01692v1)|null|
|**2024-12-02**|**Medchain: Bridging the Gap Between LLM Agents and Clinical Practice through Interactive Sequential Benchmarking**|Jie Liu et.al.|[2412.01605v1](http://arxiv.org/abs/2412.01605v1)|null|
|**2024-12-02**|**NCDD: Nearest Centroid Distance Deficit for Out-Of-Distribution Detection in Gastrointestinal Vision**|Sandesh Pokhrel et.al.|[2412.01590v1](http://arxiv.org/abs/2412.01590v1)|[link](https://github.com/bhattarailab/ncdd)|
|**2024-12-02**|**MambaU-Lite: A Lightweight Model based on Mamba and Integrated Channel-Spatial Attention for Skin Lesion Segmentation**|Thi-Nhu-Quynh Nguyen et.al.|[2412.01405v1](http://arxiv.org/abs/2412.01405v1)|[link](https://github.com/nqnguyen812/mambau-lite)|
|**2024-12-02**|**Su-RoBERTa: A Semi-supervised Approach to Predicting Suicide Risk through Social Media using Base Language Models**|Chayan Tank et.al.|[2412.01353v1](http://arxiv.org/abs/2412.01353v1)|null|
|**2024-12-02**|**Multimodal Medical Disease Classification with LLaMA II**|Christian Gapp et.al.|[2412.01306v1](http://arxiv.org/abs/2412.01306v1)|null|
|**2024-12-02**|**Best Practices for Large Language Models in Radiology**|Christian Bluethgen et.al.|[2412.01233v1](http://arxiv.org/abs/2412.01233v1)|null|
|**2024-12-02**|**Object Tracking in a $360^o$ View: A Novel Perspective on Bridging the Gap to Biomedical Advancements**|Mojtaba S. Fazli et.al.|[2412.01119v1](http://arxiv.org/abs/2412.01119v1)|null|
|**2024-12-02**|**Evaluating Automated Radiology Report Quality through Fine-Grained Phrasal Grounding of Clinical Findings**|Razi Mahmood et.al.|[2412.01031v1](http://arxiv.org/abs/2412.01031v1)|null|
|**2024-12-01**|**Generative Language Models Potential for Requirement Engineering Applications: Insights into Current Strengths and Limitations**|Summra Saleem et.al.|[2412.00959v1](http://arxiv.org/abs/2412.00959v1)|null|
|**2024-12-01**|**TSUBF-Net: Trans-Spatial UNet-like Network with Bi-direction Fusion for Segmentation of Adenoid Hypertrophy in CT**|Rulin Zhou et.al.|[2412.00787v1](http://arxiv.org/abs/2412.00787v1)|null|
|**2024-12-01**|**Automating Feedback Analysis in Surgical Training: Detection, Categorization, and Assessment**|Firdavs Nasriddinov et.al.|[2412.00760v1](http://arxiv.org/abs/2412.00760v1)|[link](https://github.com/firdavsn/SurgicalFeedbackAI)|
|**2024-11-30**|**Fairness at Every Intersection: Uncovering and Mitigating Intersectional Biases in Multimodal Clinical Predictions**|Resmi Ramachandranpillai et.al.|[2412.00606v1](http://arxiv.org/abs/2412.00606v1)|null|
|**2024-11-30**|**Opus: A Large Work Model for Complex Workflow Generation**|Théo Fagnoni et.al.|[2412.00573v1](http://arxiv.org/abs/2412.00573v1)|null|
|**2024-11-30**|**Polish Medical Exams: A new dataset for cross-lingual medical knowledge transfer assessment**|Łukasz Grzybowski et.al.|[2412.00559v1](http://arxiv.org/abs/2412.00559v1)|null|
|**2024-11-30**|**Unveiling Performance Challenges of Large Language Models in Low-Resource Healthcare: A Demographic Fairness Perspective**|Yue Zhou et.al.|[2412.00554v1](http://arxiv.org/abs/2412.00554v1)|null|
|**2024-11-30**|**2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**|Jim Solomon et.al.|[2412.00372v1](http://arxiv.org/abs/2412.00372v1)|null|
|**2024-11-30**|**One Model for One Graph: A New Perspective for Pretraining with Cross-domain Graphs**|Jingzhe Liu et.al.|[2412.00315v1](http://arxiv.org/abs/2412.00315v1)|null|
|**2024-11-30**|**BOTS: Batch Bayesian Optimization of Extended Thompson Sampling for Severely Episode-Limited RL Settings**|Karine Karine et.al.|[2412.00308v1](http://arxiv.org/abs/2412.00308v1)|null|
|**2024-11-29**|**Fine Tuning Large Language Models to Deliver CBT for Depression**|Talha Tahir et.al.|[2412.00251v1](http://arxiv.org/abs/2412.00251v1)|null|
|**2024-11-29**|**Integrating Social Determinants of Health into Knowledge Graphs: Evaluating Prediction Bias and Fairness in Healthcare**|Tianqi Shang et.al.|[2412.00245v1](http://arxiv.org/abs/2412.00245v1)|null|
|**2024-11-29**|**Dynamic EEG-fMRI mapping: Revealing the relationship between brain connectivity and cognitive state**|Guiran Liu et.al.|[2411.19922v1](http://arxiv.org/abs/2411.19922v1)|null|
|**2024-11-29**|**Graph Neural Networks for Heart Failure Prediction on an EHR-Based Patient Similarity Graph**|Heloisa Oss Boll et.al.|[2411.19742v1](http://arxiv.org/abs/2411.19742v1)|[link](https://github.com/hossboll/patient-gnn)|
|**2024-11-29**|**Multimodal Whole Slide Foundation Model for Pathology**|Tong Ding et.al.|[2411.19666v1](http://arxiv.org/abs/2411.19666v1)|[link](https://github.com/mahmoodlab/titan)|
|**2024-11-29**|**SkelMamba: A State Space Model for Efficient Skeleton Action Recognition of Neurological Disorders**|Niki Martinel et.al.|[2411.19544v1](http://arxiv.org/abs/2411.19544v1)|null|
|**2024-11-29**|**Knowledge-Data Fusion Based Source-Free Semi-Supervised Domain Adaptation for Seizure Subtype Classification**|Ruimin Peng et.al.|[2411.19502v1](http://arxiv.org/abs/2411.19502v1)|null|
|**2024-11-29**|**Adaptive Interactive Segmentation for Multimodal Medical Imaging via Selection Engine**|Zhi Li et.al.|[2411.19447v1](http://arxiv.org/abs/2411.19447v1)|[link](https://github.com/RicoLeehdu/SISeg)|
|**2024-11-28**|**Libra: Leveraging Temporal Images for Biomedical Radiology Analysis**|Xi Zhang et.al.|[2411.19378v1](http://arxiv.org/abs/2411.19378v1)|[link](https://github.com/X-iZhang/Libra)|
|**2024-11-28**|**Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**|Philipp Brauner et.al.|[2411.19356v1](http://arxiv.org/abs/2411.19356v1)|null|
|**2024-11-28**|**FonTS: Text Rendering with Typography and Style Controls**|Wenda Shi et.al.|[2412.00136v1](http://arxiv.org/abs/2412.00136v1)|null|
|**2024-11-28**|**Pre-Training Graph Contrastive Masked Autoencoders are Strong Distillers for EEG**|Xinxu Wei et.al.|[2411.19230v1](http://arxiv.org/abs/2411.19230v1)|null|
|**2024-11-28**|**Open-Sora Plan: Open-Source Large Video Generation Model**|Bin Lin et.al.|[2412.00131v1](http://arxiv.org/abs/2412.00131v1)|[link](https://github.com/pku-yuangroup/open-sora-plan)|
|**2024-11-28**|**A Unified Platform for At-Home Post-Stroke Rehabilitation Enabled by Wearable Technologies and Artificial Intelligence**|Chenyu Tang et.al.|[2411.19000v1](http://arxiv.org/abs/2411.19000v1)|null|
|**2024-11-28**|**Devising a Set of Compact and Explainable Spoken Language Feature for Screening Alzheimer's Disease**|Junan Li et.al.|[2411.18922v1](http://arxiv.org/abs/2411.18922v1)|null|
|**2024-11-27**|**LLM-ABBA: Understanding time series via symbolic approximation**|Erin Carson et.al.|[2411.18506v2](http://arxiv.org/abs/2411.18506v2)|null|
|**2024-11-27**|**MvKeTR: Chest CT Report Generation with Multi-View Perception and Knowledge Enhancement**|Xiwei Deng et.al.|[2411.18309v1](http://arxiv.org/abs/2411.18309v1)|null|
|**2024-11-27**|**Wearable intelligent throat enables natural speech in stroke patients with dysarthria**|Chenyu Tang et.al.|[2411.18266v2](http://arxiv.org/abs/2411.18266v2)|null|
|**2024-11-27**|**Multimodal Integration of Longitudinal Noninvasive Diagnostics for Survival Prediction in Immunotherapy Using Deep Learning**|Melda Yeghaian et.al.|[2411.18253v1](http://arxiv.org/abs/2411.18253v1)|null|
|**2024-11-27**|**Randomized-Grid Search for Hyperparameter Tuning in Decision Tree Model to Improve Performance of Cardiovascular Disease Classification**|Abhay Kumar Pathak et.al.|[2411.18234v1](http://arxiv.org/abs/2411.18234v1)|null|
|**2024-11-27**|**The Return of Pseudosciences in Artificial Intelligence: Have Machine Learning and Deep Learning Forgotten Lessons from Statistics and History?**|Jérémie Sublime et.al.|[2411.18656v1](http://arxiv.org/abs/2411.18656v1)|null|
|**2024-11-27**|**Visual Error Patterns in Multi-Modal AI: A Statistical Approach**|Ching-Yi Wang et.al.|[2412.00083v1](http://arxiv.org/abs/2412.00083v1)|null|
|**2024-11-27**|**Graph Neural Network for Cerebral Blood Flow Prediction With Clinical Datasets**|Seungyeon Kim et.al.|[2411.17971v1](http://arxiv.org/abs/2411.17971v1)|null|
|**2024-11-26**|**Evaluating Generative AI-Enhanced Content: A Conceptual Framework Using Qualitative, Quantitative, and Mixed-Methods Approaches**|Saman Sarraf et.al.|[2411.17943v1](http://arxiv.org/abs/2411.17943v1)|null|
|**2024-11-26**|**Automating grapevine LAI features estimation with UAV imagery and machine learning**|Muhammad Waseem Akram et.al.|[2411.17897v1](http://arxiv.org/abs/2411.17897v1)|null|
|**2024-11-26**|**HOPPR Medical-Grade Platform for Medical Imaging AI**|Kalina P. Slavkova et.al.|[2411.17891v1](http://arxiv.org/abs/2411.17891v1)|null|
|**2024-11-26**|**Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**|Yujie Dai et.al.|[2411.17645v1](http://arxiv.org/abs/2411.17645v1)|null|
|**2024-11-26**|**DapPep: Domain Adaptive Peptide-agnostic Learning for Universal T-cell Receptor-antigen Binding Affinity Prediction**|Jiangbin Zheng et.al.|[2411.17798v1](http://arxiv.org/abs/2411.17798v1)|null|
|**2024-11-26**|**Learning Explainable Treatment Policies with Clinician-Informed Representations: A Practical Approach**|Johannes O. Ferstad et.al.|[2411.17570v1](http://arxiv.org/abs/2411.17570v1)|[link](https://github.com/jferstad/ml4h-explainable-policies)|
|**2024-11-26**|**A Bilayer Segmentation-Recombination Network for Accurate Segmentation of Overlapping C. elegans**|Mengqian Dinga et.al.|[2411.17557v1](http://arxiv.org/abs/2411.17557v1)|null|
|**2024-11-26**|**AI-Augmented Ethical Hacking: A Practical Examination of Manual Exploitation and Privilege Escalation in Linux Environments**|Haitham S. Al-Sinani et.al.|[2411.17539v1](http://arxiv.org/abs/2411.17539v1)|null|
|**2024-11-26**|**ShowUI: One Vision-Language-Action Model for GUI Visual Agent**|Kevin Qinghong Lin et.al.|[2411.17465v1](http://arxiv.org/abs/2411.17465v1)|[link](https://github.com/showlab/showui)|
|**2024-11-26**|**Social Distancing Induced Coronavirus Optimization Algorithm (COVO): Application to Multimodal Function Optimization and Noise Removal**|Om Ramakisan Varma et.al.|[2411.17282v1](http://arxiv.org/abs/2411.17282v1)|null|
|**2024-11-26**|**Semantic Data Augmentation for Long-tailed Facial Expression Recognition**|Zijian Li et.al.|[2411.17254v1](http://arxiv.org/abs/2411.17254v1)|null|
|**2024-11-26**|**GraphSubDetector: Time Series Subsequence Anomaly Detection via Density-Aware Adaptive Graph Neural Network**|Weiqi Chen et.al.|[2411.17218v1](http://arxiv.org/abs/2411.17218v1)|null|
|**2024-11-26**|**Strategic Prompting for Conversational Tasks: A Comparative Analysis of Large Language Models Across Diverse Conversational Tasks**|Ratnesh Kumar Joshi et.al.|[2411.17204v2](http://arxiv.org/abs/2411.17204v2)|null|
|**2024-11-25**|**Contrastive Deep Learning Reveals Age Biomarkers in Histopathological Skin Biopsies**|Kaustubh Chakradeo et.al.|[2411.16956v1](http://arxiv.org/abs/2411.16956v1)|null|
|**2024-11-25**|**Enabling Adoption of Regenerative Agriculture through Soil Carbon Copilots**|Margaret Capetz et.al.|[2411.16872v2](http://arxiv.org/abs/2411.16872v2)|null|
|**2024-11-25**|**Enhancing In-Hospital Mortality Prediction Using Multi-Representational Learning with LLM-Generated Expert Summaries**|Harshavardhan Battula et.al.|[2411.16818v1](http://arxiv.org/abs/2411.16818v1)|null|
|**2024-11-25**|**Will an AI with Private Information Allow Itself to Be Switched Off?**|Andrew Garber et.al.|[2411.17749v1](http://arxiv.org/abs/2411.17749v1)|null|
|**2024-11-25**|**Privacy-Preserving Federated Foundation Model for Generalist Ultrasound Artificial Intelligence**|Yuncheng Jiang et.al.|[2411.16380v1](http://arxiv.org/abs/2411.16380v1)|null|
|**2024-11-25**|**GEMeX: A Large-Scale, Groundable, and Explainable Medical VQA Benchmark for Chest X-ray Diagnosis**|Bo Liu et.al.|[2411.16778v1](http://arxiv.org/abs/2411.16778v1)|null|
|**2024-11-25**|**Med-PerSAM: One-Shot Visual Prompt Tuning for Personalized Segment Anything Model in Medical Domain**|Hangyul Yoon et.al.|[2411.16123v1](http://arxiv.org/abs/2411.16123v1)|[link](https://github.com/facebookresearch/segment-anything)|
|**2024-11-25**|**Why the Agent Made that Decision: Explaining Deep Reinforcement Learning with Vision Masks**|Rui Zuo et.al.|[2411.16120v1](http://arxiv.org/abs/2411.16120v1)|null|
|**2024-11-24**|**DRIVE: Dual-Robustness via Information Variability and Entropic Consistency in Source-Free Unsupervised Domain Adaptation**|Ruiqiang Xiao et.al.|[2411.15976v1](http://arxiv.org/abs/2411.15976v1)|null|
|**2024-11-24**|**Improving Medical Diagnostics with Vision-Language Models: Convex Hull-Based Uncertainty Analysis**|Ferhat Ozgur Catak et.al.|[2412.00056v1](http://arxiv.org/abs/2412.00056v1)|null|
|**2024-11-24**|**Uncertainty-Aware Regularization for Image-to-Image Translation**|Anuja Vats et.al.|[2412.01705v1](http://arxiv.org/abs/2412.01705v1)|null|
|**2024-11-24**|**Creating Scalable AGI: the Open General Intelligence Framework**|Daniel A. Dollinger et.al.|[2411.15832v2](http://arxiv.org/abs/2411.15832v2)|null|
|**2024-11-24**|**Medical Slice Transformer: Improved Diagnosis and Explainability on 3D Medical Images with DINOv2**|Gustav Müller-Franzes et.al.|[2411.15802v1](http://arxiv.org/abs/2411.15802v1)|[link](https://github.com/mueller-franzes/mst)|
|**2024-11-24**|**Enhancing the automatic segmentation and analysis of 3D liver vasculature models**|Yassine Machta et.al.|[2411.15778v2](http://arxiv.org/abs/2411.15778v2)|null|
|**2024-11-24**|**RAMIE: Retrieval-Augmented Multi-task Information Extraction with Large Language Models on Dietary Supplements**|Zaifu Zhan et.al.|[2411.15700v1](http://arxiv.org/abs/2411.15700v1)|null|
|**2024-11-23**|**Ontology-Constrained Generation of Domain-Specific Clinical Summaries**|Gaya Mehenni et.al.|[2411.15666v1](http://arxiv.org/abs/2411.15666v1)|[link](https://github.com/lama-west/ontology-based-decoding_ekaw2024)|
|**2024-11-23**|**A Survey on LLM-as-a-Judge**|Jiawei Gu et.al.|[2411.15594v1](http://arxiv.org/abs/2411.15594v1)|[link](https://github.com/idea-finai/llm-as-evaluator)|
|**2024-11-23**|**Large Language Model with Region-guided Referring and Grounding for CT Report Generation**|Zhixuan Chen et.al.|[2411.15539v1](http://arxiv.org/abs/2411.15539v1)|null|
|**2024-11-23**|**GeoAI-Enhanced Community Detection on Spatial Networks with Graph Deep Learning**|Yunlei Liang et.al.|[2411.15428v1](http://arxiv.org/abs/2411.15428v1)|[link](https://github.com/geods/region2vec-gat)|
|**2024-11-23**|**The Decoy Dilemma in Online Medical Information Evaluation: A Comparative Study of Credibility Assessments by LLM and Human Judges**|Jiqun Liu et.al.|[2411.15396v1](http://arxiv.org/abs/2411.15396v1)|null|
|**2024-11-22**|**Regulator-Manufacturer AI Agents Modeling: Mathematical Feedback-Driven Multi-Agent LLM Framework**|Yu Han et.al.|[2411.15356v1](http://arxiv.org/abs/2411.15356v1)|null|
|**2024-11-22**|**Health AI Developer Foundations**|Atilla P. Kiraly et.al.|[2411.15128v2](http://arxiv.org/abs/2411.15128v2)|null|
|**2024-11-22**|**ReXrank: A Public Leaderboard for AI-Powered Radiology Report Generation**|Xiaoman Zhang et.al.|[2411.15122v1](http://arxiv.org/abs/2411.15122v1)|null|
|**2024-11-22**|**Feature-interactive Siamese graph encoder-based image analysis to predict STAS from histopathology images in lung cancer**|Liangrui Pan et.al.|[2411.15274v1](http://arxiv.org/abs/2411.15274v1)|null|
|**2024-11-22**|**Purrfessor: A Fine-tuned Multimodal LLaVA Diet Health Chatbot**|Linqi Lu et.al.|[2411.14925v1](http://arxiv.org/abs/2411.14925v1)|null|

#### Abstracts
##### **Intuitive Axial Augmentation Using Polar-Sine-Based Piecewise Distortion for Medical Slice-Wise Segmentation**
2412.03352v1 by Yiqin Zhang, Qingkui Chen, Chen Huang, Zhengjie Zhang, Meiling Chen, Zhibing Fu

Most data-driven models for medical image analysis rely on universal
augmentations to improve performance. Experimental evidence has confirmed their
effectiveness, but the unclear mechanism underlying them poses a barrier to the
widespread acceptance and trust in such methods within the medical community.
We revisit and acknowledge the unique characteristics of medical images apart
from traditional digital images, and consequently, proposed a medical-specific
augmentation algorithm that is more elastic and aligns well with radiology scan
procedure. The method performs piecewise affine with sinusoidal distorted ray
according to radius on polar coordinates, thus simulating uncertain postures of
human lying flat on the scanning table. Our method could generate human
visceral distribution without affecting the fundamental relative position on
axial plane. Two non-adaptive algorithms, namely Meta-based Scan Table Removal
and Similarity-Guided Parameter Search, are introduced to bolster robustness of
our augmentation method. Experiments show our method improves accuracy across
multiple famous segmentation frameworks without requiring more data samples.
Our preview code is available in: https://github.com/MGAMZ/PSBPD.

摘要：大多數用於醫學影像分析的資料驅動模型仰賴通用擴充功能來提升效能。實驗證據已證實其有效性，但其背後不明確的機制對醫學界廣泛接受和信任此類方法構成阻礙。我們重新檢視並承認醫學影像與傳統數位影像的獨特特性，因此提出更具彈性且與放射線掃描程序密切配合的醫學特定擴充演算法。該方法根據極座標上的半徑執行正弦扭曲射線的逐段仿射，從而模擬人平躺在掃描台上時的不確定姿勢。我們的方法可以在不影響軸向平面上基本相對位置的情況下生成人體內臟分佈。引入了兩種非自適應演算法，即基於 Meta 的掃描台移除和相似性導引參數搜尋，以加強我們擴充方法的穩健性。實驗表明，我們的演算法在不需要更多資料樣本的情況下，就能提升多個著名分割架構的準確性。我們的預覽程式碼可在 https://github.com/MGAMZ/PSBPD 中取得。

##### **Detecting abnormal heart sound using mobile phones and on-device IConNet**
2412.03267v1 by Linh Vu, Thu Tran

Given the global prevalence of cardiovascular diseases, there is a pressing
need for easily accessible early screening methods. Typically, this requires
medical practitioners to investigate heart auscultations for irregular sounds,
followed by echocardiography and electrocardiography tests. To democratize
early diagnosis, we present a user-friendly solution for abnormal heart sound
detection, utilizing mobile phones and a lightweight neural network optimized
for on-device inference. Unlike previous approaches reliant on specialized
stethoscopes, our method directly analyzes audio recordings, facilitated by a
novel architecture known as IConNet. IConNet, an Interpretable Convolutional
Neural Network, harnesses insights from audio signal processing, enhancing
efficiency and providing transparency in neural pattern extraction from raw
waveform signals. This is a significant step towards trustworthy AI in
healthcare, aiding in remote health monitoring efforts.

摘要：鉴于心血管疾病在全球的普遍性，迫切需要容易获取的早期筛查方法。通常，这需要医疗从业人员检查心脏听诊是否有不规则的声音，然后进行超声心动图和心电图检查。为了使早期诊断民主化，我们提出了一种用户友好的解决方案，用于检测异常心脏声音，利用移动电话和一个轻量级神经网络，该神经网络针对设备内推理进行了优化。与以前依赖于专用听诊器的做法不同，我们的方法直接分析音频记录，这得益于一种称为 IConNet 的新颖架构。IConNet 是一种可解释的卷积神经网络，利用音频信号处理的见解，提高效率，并提供从原始波形信号中提取神经模式的透明性。这是朝向医疗保健中可信赖的人工智能迈出的重要一步，有助于远程健康监测工作。

##### **MRNet: Multifaceted Resilient Networks for Medical Image-to-Image Translation**
2412.03039v1 by Hyojeong Lee, Youngwan Jo, Inpyo Hong, Sanghyun Park

We propose a Multifaceted Resilient Network(MRNet), a novel architecture
developed for medical image-to-image translation that outperforms
state-of-the-art methods in MRI-to-CT and MRI-to-MRI conversion. MRNet
leverages the Segment Anything Model (SAM) to exploit frequency-based features
to build a powerful method for advanced medical image transformation. The
architecture extracts comprehensive multiscale features from diverse datasets
using a powerful SAM image encoder and performs resolution-aware feature fusion
that consistently integrates U-Net encoder outputs with SAM-derived features.
This fusion optimizes the traditional U-Net skip connection while leveraging
transformer-based contextual analysis. The translation is complemented by an
innovative dual-mask configuration incorporating dynamic attention patterns and
a specialized loss function designed to address regional mapping mismatches,
preserving both the gross anatomy and tissue details. Extensive validation
studies have shown that MRNet outperforms state-of-the-art architectures,
particularly in maintaining anatomical fidelity and minimizing translation
artifacts.

摘要：我們提出一個多方面的彈性網路 (MRNet)，這是一個創新的架構，
開發用於醫學影像轉影像的翻譯，其優於 MRI 轉 CT 和 MRI 轉 MRI 轉換的最新方法。MRNet
利用 Segment Anything Model (SAM) 來利用基於頻率的特徵，以建立一種強大的方法，用於先進的醫學影像轉換。此
架構使用強大的 SAM 影像編碼器從不同的資料集提取全面的多尺度特徵，並執行解析度感知特徵融合，持續將 U-Net 編碼器輸出與 SAM 衍生的特徵整合在一起。
此融合最佳化傳統的 U-Net 跳躍連接，同時利用基於Transformer的上下文分析。翻譯由一個創新的雙遮罩配置補充，它結合了動態注意模式和一個專門的損失函數，旨在解決區域對應不匹配的問題，同時保留了整體解剖結構和組織細節。廣泛的驗證研究顯示，MRNet 優於最先進的架構，特別是在維持解剖保真度和最小化轉換偽影方面。

##### **Higher Order Transformers: Efficient Attention Mechanism for Tensor Structured Data**
2412.02919v1 by Soroush Omranpour, Guillaume Rabusseau, Reihaneh Rabbany

Transformers are now ubiquitous for sequence modeling tasks, but their
extension to multi-dimensional data remains a challenge due to the quadratic
cost of the attention mechanism. In this paper, we propose Higher-Order
Transformers (HOT), a novel architecture designed to efficiently process data
with more than two axes, i.e. higher-order tensors. To address the
computational challenges associated with high-order tensor attention, we
introduce a novel Kronecker factorized attention mechanism that reduces the
attention cost to quadratic in each axis' dimension, rather than quadratic in
the total size of the input tensor. To further enhance efficiency, HOT
leverages kernelized attention, reducing the complexity to linear. This
strategy maintains the model's expressiveness while enabling scalable attention
computation. We validate the effectiveness of HOT on two high-dimensional
tasks, including multivariate time series forecasting, and 3D medical image
classification. Experimental results demonstrate that HOT achieves competitive
performance while significantly improving computational efficiency, showcasing
its potential for tackling a wide range of complex, multi-dimensional data.

摘要：變形金剛現在普遍用於序列建模任務，但由於注意力機制的二次方成本，它們擴展到多維數據仍然是一個挑戰。在本文中，我們提出了高階變形金剛 (HOT)，這是一種新穎的架構，旨在有效處理具有兩個以上軸線的數據，即高階張量。為了應對與高階張量注意力相關的計算挑戰，我們引入了一種新穎的克羅內克分解注意力機制，該機制將注意力成本降低到每個軸線維度的二次方，而不是輸入張量的總大小的二次方。為了進一步提高效率，HOT 利用核化注意力，將複雜度降低到線性。此策略保持了模型的表現力，同時實現了可擴展的注意力計算。我們在兩個高維任務上驗證了 HOT 的有效性，包括多元時間序列預測和 3D 醫學影像分類。實驗結果表明，HOT 在顯著提高計算效率的同時實現了競爭力的效能，展示了其應對各種複雜的多維數據的潛力。

##### **A Novel Compact LLM Framework for Local, High-Privacy EHR Data Applications**
2412.02868v1 by Yixiang Qu, Yifan Dai, Shilin Yu, Pradham Tanikella, Travis Schrank, Trevor Hackman, Didong Li, Di Wu

Large Language Models (LLMs) have shown impressive capabilities in natural
language processing, yet their use in sensitive domains like healthcare,
particularly with Electronic Health Records (EHR), faces significant challenges
due to privacy concerns and limited computational resources. This paper
presents a compact LLM framework designed for local deployment in settings with
strict privacy requirements and limited access to high-performance GPUs. We
introduce a novel preprocessing technique that uses information extraction
methods, e.g., regular expressions, to filter and emphasize critical
information in clinical notes, enhancing the performance of smaller LLMs on EHR
data. Our framework is evaluated using zero-shot and few-shot learning
paradigms on both private and publicly available (MIMIC-IV) datasets, and we
also compare its performance with fine-tuned LLMs on the MIMIC-IV dataset. The
results demonstrate that our preprocessing approach significantly boosts the
prediction accuracy of smaller LLMs, making them suitable for high-privacy,
resource-constrained applications. This study offers valuable insights into
optimizing LLM performance for sensitive, data-intensive tasks while addressing
computational and privacy limitations.

摘要：大型語言模型 (LLM) 在自然語言處理方面展現出令人印象深刻的能力，然而它們在醫療保健等敏感領域的使用，特別是電子健康紀錄 (EHR)，由於隱私問題和有限的運算資源而面臨重大挑戰。本文提出了一個緊湊的 LLM 框架，旨在在具有嚴格隱私要求和有限使用高性能 GPU 的環境中進行本地部署。我們引入了一種新穎的預處理技術，它使用資訊萃取方法，例如正規表示法，來過濾和強調臨床筆記中的關鍵資訊，增強較小 LLM 在 EHR 資料上的效能。我們的框架使用零次學習和少次學習範例在私人和公開可用的 (MIMIC-IV) 資料集上進行評估，我們也比較它在 MIMIC-IV 資料集上與微調 LLM 的效能。結果表明，我們的預處理方法顯著提升了較小 LLM 的預測準確度，使其適用於高度隱私、資源受限的應用程式。這項研究提供了寶貴的見解，用於最佳化 LLM 效能以應對敏感、資料密集型任務，同時解決運算和隱私限制。

##### **Block MedCare: Advancing healthcare through blockchain integration with AI and IoT**
2412.02851v1 by Oliver Simonoski, Dijana Capeska Bogatinoska

This research explores the integration of blockchain technology in
healthcare, focusing on enhancing the security and efficiency of Electronic
Health Record (EHR) management. We propose a novel Ethereum-based system that
empowers patients with secure control over their medical data. Our approach
addresses key challenges in healthcare blockchain implementation, including
scalability, privacy, and regulatory compliance. The system incorporates
digital signatures, Role-Based Access Control, and a multi-layered architecture
to ensure secure, controlled access. We developed a decentralized application
(dApp) with user-friendly interfaces for patients, doctors, and administrators,
demonstrating the practical application of our solution. A survey among
healthcare professionals and IT experts revealed strong interest in blockchain
adoption, while also highlighting concerns about integration costs. The study
explores future enhancements, including integration with IoT devices and
AI-driven analytics, contributing to the evolution of secure, efficient, and
interoperable healthcare systems that leverage cutting-edge technologies for
improved patient care.

摘要：本研究探討區塊鏈技術在醫療保健中的整合，專注於提升電子健康紀錄 (EHR) 管理的安全性與效率。我們提出一個創新的以太坊系統，賦予患者安全地控制其醫療數據的權力。我們的做法解決了醫療保健區塊鏈實作中的主要挑戰，包括可擴充性、隱私和法規遵循。該系統整合了數位簽章、基於角色的存取控制和多層架構，以確保安全且受控的存取。我們開發了一個具有使用者友善介面的去中心化應用程式 (dApp)，適用於患者、醫生和管理員，展示了我們解決方案的實際應用。在醫療保健專業人員和 IT 專家之間進行的一項調查顯示，他們對區塊鏈的採用有濃厚興趣，但也強調了對整合成本的擔憂。該研究探討了未來的強化，包括與 IoT 裝置整合和 AI 驅動的分析，有助於安全、高效且可互操作的醫療保健系統的演進，該系統利用尖端技術改善患者照護。

##### **CNNSum: Exploring Long-Conext Summarization with Large Language Models in Chinese Novels**
2412.02819v1 by Lingxiao Wei, He Yan, Xiangju Lu, Junmin Zhu, Jun Wang, Wei Zhang

Large Language Models (LLMs) have been well-researched in many long-context
tasks. However, due to high annotation costs, high-quality long-context summary
datasets for training or evaluation are scarce, limiting further research. In
this work, we introduce CNNSum, a new multi-scale Chinese long-context novel
summarization benchmark, including four subsets, length covering
16k\textasciitilde128k, 695 samples in total, the annotations are human-driven.
We evaluate commercial and open-source models on CNNSum and conduct a detailed
analysis. Based on the observations, we further conduct fine-tuning exploration
with short-context summary data. In our study: (1) GPT-4o underperformed, due
to excessive subjective commentary. (2) Currently, long-context summarization
mainly relies on memory ability, small LLMs with stable longer context lengths
are the most cost-effective. Using long data concatenated from short-context
summaries makes a significant improvement. (3) Prompt templates may cause a
large performance gap but can be mitigated through fine-tuning. (4) Fine-tuned
Chat or Instruction versions may harm the Base model and further fine-tuning
cannot bridge performance gap. (5) while models with RoPE base scaling exhibit
strong extrapolation potential, their performance may vary significantly when
combined with other interpolation methods and need careful selection. (6)
CNNSum provides more reliable and insightful evaluation results than other
benchmarks. We release CNNSum to advance research in this field.

摘要：<paragraph>大型語言模型 (LLM) 已在許多長語境任務中獲得充分研究。然而，由於標註成本高昂，用於訓練或評估的高品質長語境摘要資料集稀少，限制了進一步的研究。在這項工作中，我們介紹了 CNNSum，一個新的多尺度中文長語境小說摘要基準，包括四個子集，長度涵蓋 16k\textasciitilde128k，總共 695 個樣本，標註是由人工驅動的。我們評估了 CNNSum 上的商業和開源模型，並進行了詳細的分析。根據觀察結果，我們進一步使用短語境摘要資料進行微調探索。在我們的研究中：(1) GPT-4o 表現不佳，因為過度的主觀評論。(2) 目前，長語境摘要主要依賴記憶能力，具有穩定較長語境長度的小型 LLM 最具成本效益。使用從短語境摘要串接而成的長資料可以顯著提升。(3) 提示範本可能會導致很大的效能差距，但可以透過微調來減輕。(4) 微調的聊天或指令版本可能會損害基礎模型，進一步的微調無法彌合效能差距。(5) 雖然具有 RoPE 基礎縮放的模型展現出強大的外推潛力，但它們與其他內插方法結合使用時，效能可能會顯著變化，需要仔細選擇。(6) CNNSum 提供比其他基準更可靠且有見地的評估結果。我們發布 CNNSum 以推動此領域的研究。</paragraph>

##### **Optimization of Transformer heart disease prediction model based on particle swarm optimization algorithm**
2412.02801v1 by Peiyang Yu, Jingyuan Yi, Tianyi Huang, Zeqiu Xu, Xiaochuan Xu

Aiming at the latest particle swarm optimization algorithm, this paper
proposes an improved Transformer model to improve the accuracy of heart disease
prediction and provide a new algorithm idea. We first use three mainstream
machine learning classification algorithms - decision tree, random forest and
XGBoost, and then output the confusion matrix of these three models. The
results showed that the random forest model had the best performance in
predicting the classification of heart disease, with an accuracy of 92.2%.
Then, we apply the Transformer model based on particle swarm optimization (PSO)
algorithm to the same dataset for classification experiment. The results show
that the classification accuracy of the model is as high as 96.5%, 4.3
percentage points higher than that of random forest, which verifies the
effectiveness of PSO in optimizing Transformer model. From the above research,
we can see that particle swarm optimization significantly improves Transformer
performance in heart disease prediction. Improving the ability to predict heart
disease is a global priority with benefits for all humankind. Accurate
prediction can enhance public health, optimize medical resources, and reduce
healthcare costs, leading to healthier populations and more productive
societies worldwide. This advancement paves the way for more efficient health
management and supports the foundation of a healthier, more resilient global
community.

摘要：針對最新的粒子群最佳化演算法，本文提出一個改良的 Transformer 模型，以提升心臟病預測的準確度，並提供一個新的演算法思維。我們首先使用三個主流的機器學習分類演算法——決策樹、隨機森林和 XGBoost，再輸出這三個模型的混淆矩陣。結果顯示，隨機森林模型在預測心臟病分類的表現最佳，準確率達 92.2%。接著，我們將基於粒子群最佳化 (PSO) 演算法的 Transformer 模型套用於相同的資料集，進行分類實驗。結果顯示，該模型的分類準確率高達 96.5%，比隨機森林高出 4.3 個百分點，驗證了 PSO 在最佳化 Transformer 模型上的有效性。從以上研究中，我們可以看出粒子群最佳化顯著提升了 Transformer 在心臟病預測上的表現。提升預測心臟病的能力是一項全球性的優先要務，對全人類都有益處。準確的預測可以增進公共衛生、優化醫療資源，並降低醫療保健成本，進而讓全球人口更健康、社會更具生產力。這項進展為更有效率的健康管理鋪路，並支持建立一個更健康、更具韌性的全球社群。

##### **Medical Multimodal Foundation Models in Clinical Diagnosis and Treatment: Applications, Challenges, and Future Directions**
2412.02621v1 by Kai Sun, Siyan Xue, Fuchun Sun, Haoran Sun, Yu Luo, Ling Wang, Siyuan Wang, Na Guo, Lei Liu, Tian Zhao, Xinzhou Wang, Lei Yang, Shuo Jin, Jun Yan, Jiahong Dong

Recent advancements in deep learning have significantly revolutionized the
field of clinical diagnosis and treatment, offering novel approaches to improve
diagnostic precision and treatment efficacy across diverse clinical domains,
thus driving the pursuit of precision medicine. The growing availability of
multi-organ and multimodal datasets has accelerated the development of
large-scale Medical Multimodal Foundation Models (MMFMs). These models, known
for their strong generalization capabilities and rich representational power,
are increasingly being adapted to address a wide range of clinical tasks, from
early diagnosis to personalized treatment strategies. This review offers a
comprehensive analysis of recent developments in MMFMs, focusing on three key
aspects: datasets, model architectures, and clinical applications. We also
explore the challenges and opportunities in optimizing multimodal
representations and discuss how these advancements are shaping the future of
healthcare by enabling improved patient outcomes and more efficient clinical
workflows.

摘要：深度學習的最新進展大幅革新了臨床診斷和治療領域，提供了改善各種臨床領域診斷精準度和治療效果的新方法，進而推動精準醫療的追求。多器官和多模態資料集的可用性日益增加，加速了大規模醫療多模態基礎模型 (MMFM) 的發展。這些模型以其強大的概化能力和豐富的表徵能力而聞名，正日益被改編以解決廣泛的臨床任務，從早期診斷到個人化治療策略。本篇評論提供了對 MMFM 近期發展的全面分析，重點關注三個關鍵面向：資料集、模型架構和臨床應用。我們也探討了最佳化多模態表徵的挑戰和機會，並討論這些進展如何透過改善患者預後和更有效率的臨床工作流程，形塑醫療保健的未來。

##### **U-Net in Medical Image Segmentation: A Review of Its Applications Across Modalities**
2412.02242v1 by Fnu Neha, Deepshikha Bhati, Deepak Kumar Shukla, Sonavi Makarand Dalvi, Nikolaos Mantzou, Safa Shubbar

Medical imaging is essential in healthcare to provide key insights into
patient anatomy and pathology, aiding in diagnosis and treatment. Non-invasive
techniques such as X-ray, Magnetic Resonance Imaging (MRI), Computed Tomography
(CT), and Ultrasound (US), capture detailed images of organs, tissues, and
abnormalities. Effective analysis of these images requires precise segmentation
to delineate regions of interest (ROI), such as organs or lesions. Traditional
segmentation methods, relying on manual feature-extraction, are labor-intensive
and vary across experts. Recent advancements in Artificial Intelligence (AI)
and Deep Learning (DL), particularly convolutional models such as U-Net and its
variants (U-Net++ and U-Net 3+), have transformed medical image segmentation
(MIS) by automating the process and enhancing accuracy. These models enable
efficient, precise pixel-wise classification across various imaging modalities,
overcoming the limitations of manual segmentation. This review explores various
medical imaging techniques, examines the U-Net architectures and their
adaptations, and discusses their application across different modalities. It
also identifies common challenges in MIS and proposes potential solutions.

摘要：醫療影像在醫療保健中至關重要，可提供患者解剖結構和病理學的重要見解，有助於診斷和治療。X 光、磁振造影 (MRI)、電腦斷層掃描 (CT) 和超音波 (US) 等非侵入式技術，可捕捉器官、組織和異常的詳細影像。有效分析這些影像需要精確的分割，以描繪感興趣區域 (ROI)，例如器官或病灶。傳統的分割方法依賴於手動特徵萃取，既費時又因專家而異。人工智慧 (AI) 和深度學習 (DL) 的最新進展，特別是 U-Net 和其變體 (U-Net++ 和 U-Net 3+) 等卷積模型，已透過自動化流程和提高準確度，轉變了醫療影像分割 (MIS)。這些模型能跨越各種影像模式進行有效且精確的逐像素分類，克服了手動分割的限制。本篇評論探討了各種醫療影像技術，審查了 U-Net 架構及其改編，並討論了它們在不同模式中的應用。它也找出了 MIS 中常見的挑戰，並提出了潛在的解決方案。

##### **Recovering implicit physics model under real-world constraints**
2412.02215v1 by Ayan Banerjee, Sandeep K. S. Gupta

Recovering a physics-driven model, i.e. a governing set of equations of the
underlying dynamical systems, from the real-world data has been of recent
interest. Most existing methods either operate on simulation data with
unrealistically high sampling rates or require explicit measurements of all
system variables, which is not amenable in real-world deployments. Moreover,
they assume the timestamps of external perturbations to the physical system are
known a priori, without uncertainty, implicitly discounting any sensor
time-synchronization or human reporting errors. In this paper, we propose a
novel liquid time constant neural network (LTC-NN) based architecture to
recover underlying model of physical dynamics from real-world data. The
automatic differentiation property of LTC-NN nodes overcomes problems
associated with low sampling rates, the input dependent time constant in the
forward pass of the hidden layer of LTC-NN nodes creates a massive search space
of implicit physical dynamics, the physics model solver based data
reconstruction loss guides the search for the correct set of implicit dynamics,
and the use of the dropout regularization in the dense layer ensures extraction
of the sparsest model. Further, to account for the perturbation timing error,
we utilize dense layer nodes to search through input shifts that results in the
lowest reconstruction loss. Experiments on four benchmark dynamical systems,
three with simulation data and one with the real-world data show that the
LTC-NN architecture is more accurate in recovering implicit physics model
coefficients than the state-of-the-art sparse model recovery approaches. We
also introduce four additional case studies (total eight) on real-life medical
examples in simulation and with real-world clinical data to show effectiveness
of our approach in recovering underlying model in practice.

摘要：<paragraph>從真實世界資料中還原物理驅動模型，即基礎動態系統的控制方程式組，一直是近期的研究重點。現有方法大多在具有非現實高取樣率的模擬資料上執行，或需要所有系統變數的明確測量值，這在真實世界的部署中並不可行。此外，這些方法假設對物理系統的外部擾動的時間戳是先驗已知的，且沒有不確定性，隱含地忽略了任何感測器時間同步或人為回報錯誤。在本文中，我們提出了一種基於新穎液態時間常數神經網路 (LTC-NN) 的架構，以從真實世界資料中還原物理動態的基礎模型。LTC-NN 節點的自動微分特性克服了與低取樣率相關的問題，LTC-NN 節點隱藏層的前向傳遞中輸入依賴的時間常數會產生一個巨大的隱式物理動態搜尋空間，基於物理模型求解器的資料重建損失引導了對正確隱式動態集的搜尋，並且在稠密層中使用中斷正則化確保了最稀疏模型的提取。此外，為了考慮擾動計時錯誤，我們利用稠密層節點來搜尋輸入位移，這將導致最低的重建損失。在四個基準動態系統（三個使用模擬資料，一個使用真實世界資料）上的實驗表明，LTC-NN 架構在恢復隱式物理模型係數方面比最先進的稀疏模型恢復方法更準確。我們還介紹了四個額外的案例研究（總共八個），這些研究涉及模擬中的真實醫療範例和真實世界的臨床資料，以展示我們的做法在實務中恢復基礎模型的有效性。</paragraph>

##### **Comparative Performance of Machine Learning Algorithms for Early Genetic Disorder and Subclass Classification**
2412.02189v1 by Abu Bakar Siddik, Faisal R. Badal, Afroza Islam

A great deal of effort has been devoted to discovering a particular genetic
disorder, but its classification across a broad spectrum of disorder classes
and types remains elusive. Early diagnosis of genetic disorders enables timely
interventions and improves outcomes. This study implements machine learning
models using basic clinical indicators measurable at birth or infancy to enable
diagnosis in preliminary life stages. Supervised learning algorithms were
implemented on a dataset of 22083 instances with 42 features like family
history, newborn metrics, and basic lab tests. Extensive hyperparameter tuning,
feature engineering, and selection were undertaken. Two multi-class classifiers
were developed: one for predicting disorder classes (mitochondrial,
multifactorial, and single-gene) and one for subtypes (9 disorders).
Performance was evaluated using accuracy, precision, recall, and the F1-score.
The CatBoost classifier achieved the highest accuracy of 77% for predicting
genetic disorder classes. For subtypes, SVM attained a maximum accuracy of 80%.
The study demonstrates the feasibility of using basic clinical data in machine
learning models for early categorization and diagnosis across various genetic
disorders. Applying ML with basic clinical indicators can enable timely
interventions once validated on larger datasets. It is necessary to conduct
further studies to improve model performance on this dataset.

摘要：<paragraph>許多研究致力於發現特定遺傳性疾病，但其在廣泛的疾病類型和分類中的分類仍然難以捉摸。遺傳性疾病的早期診斷能及時介入並改善結果。本研究實作機器學習模型，使用出生或嬰兒時期可測量的基本臨床指標，以在生命的早期階段進行診斷。監督式學習演算法實作在一個包含 22083 個實例的資料集上，其中包含 42 個特徵，例如家族史、新生兒指標和基本實驗室檢驗。進行了廣泛的超參數調整、特徵工程和選擇。開發了兩個多類別分類器：一個用於預測疾病類型（粒線體、多因素和單基因），另一個用於預測亞型（9 種疾病）。使用準確度、精確度、召回率和 F1 分數評估效能。CatBoost 分類器在預測遺傳性疾病類型方面達到了 77% 的最高準確度。對於亞型，SVM 達到了 80% 的最高準確度。本研究證明了在機器學習模型中使用基本臨床資料進行早期分類和診斷各種遺傳性疾病的可行性。將機器學習應用於基本臨床指標，可以在較大的資料集上驗證後及時進行干預。有必要進行進一步的研究以改善此資料集上的模型效能。</paragraph>

##### **Anatomically-Grounded Fact Checking of Automated Chest X-ray Reports**
2412.02177v1 by R. Mahmood, K. C. L. Wong, D. M. Reyes, N. D'Souza, L. Shi, J. Wu, P. Kaviani, M. Kalra, G. Wang, P. Yan, T. Syeda-Mahmood

With the emergence of large-scale vision-language models, realistic radiology
reports may be generated using only medical images as input guided by simple
prompts. However, their practical utility has been limited due to the factual
errors in their description of findings. In this paper, we propose a novel
model for explainable fact-checking that identifies errors in findings and
their locations indicated through the reports. Specifically, we analyze the
types of errors made by automated reporting methods and derive a new synthetic
dataset of images paired with real and fake descriptions of findings and their
locations from a ground truth dataset. A new multi-label cross-modal
contrastive regression network is then trained on this datsaset. We evaluate
the resulting fact-checking model and its utility in correcting reports
generated by several SOTA automated reporting tools on a variety of benchmark
datasets with results pointing to over 40\% improvement in report quality
through such error detection and correction.

摘要：隨著大規模視覺語言模型的出現，僅使用醫療影像作為輸入，並透過簡單提示引導，即可產生逼真的放射科報告。然而，由於其對發現的描述有事實上的錯誤，因此其實際效用受到限制。在本文中，我們提出了一個用於可解釋事實查核的新模型，該模型可識別報告中發現的錯誤及其位置。具體來說，我們分析了自動化報告方法所產生的錯誤類型，並從真實資料集中衍生出一個新的合成影像資料集，其中配對了發現及其位置的真實和虛假描述。然後在這個資料集上訓練一個新的多標籤跨模態對比回歸網路。我們評估了產生的事實查核模型及其在更正由多個 SOTA 自動化報告工具在各種基準資料集上產生的報告中的效用，結果表明透過這種錯誤偵測和更正，報告品質獲得了超過 40% 的提升。

##### **Keeping Experts in the Loop: Expert-Guided Optimization for Clinical Data Classification using Large Language Models**
2412.02173v1 by Nader Karayanni, Aya Awwad, Chein-Lien Hsiao, Surish P Shanmugam

Since the emergence of Large Language Models (LLMs), the challenge of
effectively leveraging their potential in healthcare has taken center stage. A
critical barrier to using LLMs for extracting insights from unstructured
clinical notes lies in the prompt engineering process. Despite its pivotal role
in determining task performance, a clear framework for prompt optimization
remains absent. Current methods to address this gap take either a manual prompt
refinement approach, where domain experts collaborate with prompt engineers to
create an optimal prompt, which is time-intensive and difficult to scale, or
through employing automatic prompt optimizing approaches, where the value of
the input of domain experts is not fully realized. To address this, we propose
StructEase, a novel framework that bridges the gap between automation and the
input of human expertise in prompt engineering. A core innovation of the
framework is SamplEase, an iterative sampling algorithm that identifies
high-value cases where expert feedback drives significant performance
improvements. This approach minimizes expert intervention, to effectively
enhance classification outcomes. This targeted approach reduces labeling
redundancy, mitigates human error, and enhances classification outcomes. We
evaluated the performance of StructEase using a dataset of de-identified
clinical narratives from the US National Electronic Injury Surveillance System
(NEISS), demonstrating significant gains in classification performance compared
to current methods. Our findings underscore the value of expert integration in
LLM workflows, achieving notable improvements in F1 score while maintaining
minimal expert effort. By combining transparency, flexibility, and scalability,
StructEase sets the foundation for a framework to integrate expert input into
LLM workflows in healthcare and beyond.

摘要：自大型語言模型 (LLM) 出現以來，有效利用其在醫療保健中的潛力的挑戰已成為重中之重。使用 LLM 從非結構化臨床筆記中提取見解的一個關鍵障礙在於提示工程過程。儘管它在確定任務績效中扮演著舉足輕重的角色，但仍缺乏明確的提示最佳化框架。目前解決此差距的方法採用手動提示優化方法，其中領域專家與提示工程師合作建立最佳提示，這非常耗時且難以擴展，或透過採用自動提示最佳化方法，其中領域專家的輸入價值並未充分實現。為了解決這個問題，我們提出了 StructEase，這是一個新穎的框架，它彌合了自動化與提示工程中人類專業知識輸入之間的差距。該框架的核心創新是 SamplEase，這是一種迭代式抽樣演算法，它識別出專家回饋能顯著提升績效的高價值案例。這種方法將專家介入降到最低，以有效提升分類結果。這種有針對性的方法減少了標籤冗餘，減輕了人為錯誤，並提升了分類結果。我們使用來自美國國家電子傷害監測系統 (NEISS) 的去識別化臨床敘述資料集評估了 StructEase 的績效，與目前的方法相比，分類績效有了顯著的提升。我們的研究結果強調了專家整合在 LLM 工作流程中的價值，在維持最少專家工作量的同時，達到了 F1 分數的顯著提升。透過結合透明度、彈性和可擴展性，StructEase 為一個框架奠定了基礎，將專家輸入整合到醫療保健及其他領域的 LLM 工作流程中。

##### **Construction and optimization of health behavior prediction model for the elderly in smart elderly care**
2412.02062v1 by Qian Guo, Peiyuan Chen

With the intensification of global aging, health management of the elderly
has become a focus of social attention. This study designs and implements a
smart elderly care service model to address issues such as data diversity,
health status complexity, long-term dependence and data loss, sudden changes in
behavior, and data privacy in the prediction of health behaviors of the
elderly. The model achieves accurate prediction and dynamic management of
health behaviors of the elderly through modules such as multimodal data fusion,
data loss processing, nonlinear prediction, emergency detection, and privacy
protection. In the experimental design, based on multi-source data sets and
market research results, the model demonstrates excellent performance in health
behavior prediction, emergency detection, and personalized services. The
experimental results show that the model can effectively improve the accuracy
and robustness of health behavior prediction and meet the actual application
needs in the field of smart elderly care. In the future, with the integration
of more data and further optimization of technology, the model will provide
more powerful technical support for smart elderly care services.

摘要：隨著全球高齡化加劇，老年人的健康管理已成為社會關注的焦點。本研究設計並實作一個智慧老人照護服務模型，以解決老人健康行為預測中的資料異質性、健康狀態複雜性、長期依賴性與資料流失、行為突變、資料隱私等問題。該模型透過多模態資料融合、資料流失處理、非線性預測、緊急事件偵測、隱私保護等模組，達到老人健康行為的精準預測與動態管理。在實驗設計上，基於多來源資料集與市場調查結果，該模型在健康行為預測、緊急事件偵測、個人化服務等方面均展現出優異的表現。實驗結果顯示，該模型能有效提升健康行為預測的準確性與魯棒性，並滿足智慧老人照護領域的實際應用需求。未來隨著更多資料的整合與技術的進一步優化，該模型將為智慧老人照護服務提供更強大的技術支撐。

##### **INSIGHT: Explainable Weakly-Supervised Medical Image Analysis**
2412.02012v1 by Wenbo Zhang, Junyu Chen, Christopher Kanan

Due to their large sizes, volumetric scans and whole-slide pathology images
(WSIs) are often processed by extracting embeddings from local regions and then
an aggregator makes predictions from this set. However, current methods require
post-hoc visualization techniques (e.g., Grad-CAM) and often fail to localize
small yet clinically crucial details. To address these limitations, we
introduce INSIGHT, a novel weakly-supervised aggregator that integrates heatmap
generation as an inductive bias. Starting from pre-trained feature maps,
INSIGHT employs a detection module with small convolutional kernels to capture
fine details and a context module with a broader receptive field to suppress
local false positives. The resulting internal heatmap highlights diagnostically
relevant regions. On CT and WSI benchmarks, INSIGHT achieves state-of-the-art
classification results and high weakly-labeled semantic segmentation
performance. Project website and code are available at:
https://zhangdylan83.github.io/ewsmia/

摘要：由於體積龐大，體積掃描和全玻片病理圖像 (WSI) 通常會透過從局部區域擷取嵌入式處理，然後聚合器會根據這組資料進行預測。然而，目前的方法需要事後視覺化技術（例如 Grad-CAM），而且往往無法定位雖然細微但臨床上至關重要的細節。為了解決這些限制，我們引入了 INSIGHT，這是一種新穎的弱監督聚合器，可將熱圖生成整合為歸納偏差。INSIGHT 從預先訓練好的特徵圖開始，採用具有小型卷積核的偵測模組來擷取精細的細節，並採用具有較廣泛感受野的內容模組來抑制局部誤判。產生的內部熱圖突顯了診斷相關的區域。在 CT 和 WSI 基準上，INSIGHT 達到了最先進的分類結果，並具備高度弱標記語意分割效能。專案網站和程式碼可於下列網址取得：
https://zhangdylan83.github.io/ewsmia/

##### **The use of large language models to enhance cancer clinical trial educational materials**
2412.01955v2 by Mingye Gao, Aman Varshney, Shan Chen, Vikram Goddla, Jack Gallifant, Patrick Doyle, Claire Novack, Maeve Dillon-Martin, Teresia Perkins, Xinrong Correia, Erik Duhaime, Howard Isenstein, Elad Sharon, Lisa Soleymani Lehmann, David Kozono, Brian Anthony, Dmitriy Dligach, Danielle S. Bitterman

Cancer clinical trials often face challenges in recruitment and engagement
due to a lack of participant-facing informational and educational resources.
This study investigated the potential of Large Language Models (LLMs),
specifically GPT4, in generating patient-friendly educational content from
clinical trial informed consent forms. Using data from ClinicalTrials.gov, we
employed zero-shot learning for creating trial summaries and one-shot learning
for developing multiple-choice questions, evaluating their effectiveness
through patient surveys and crowdsourced annotation. Results showed that
GPT4-generated summaries were both readable and comprehensive, and may improve
patients' understanding and interest in clinical trials. The multiple-choice
questions demonstrated high accuracy and agreement with crowdsourced
annotators. For both resource types, hallucinations were identified that
require ongoing human oversight. The findings demonstrate the potential of LLMs
"out-of-the-box" to support the generation of clinical trial education
materials with minimal trial-specific engineering, but implementation with a
human-in-the-loop is still needed to avoid misinformation risks.

摘要：癌症臨床試驗由於缺乏面向參與者的資訊和教育資源，常常在招募和參與方面面臨挑戰。本研究探討了大型語言模型 (LLM)，特別是 GPT4，從臨床試驗知情同意書中產生對患者友善的教育內容的潛力。我們使用來自 ClinicalTrials.gov 的資料，採用零次學習來建立試驗摘要，以及一次學習來開發多選題，並透過患者調查和群眾外包註解來評估其有效性。結果顯示，GPT4 生成的摘要具有可讀性和全面性，並且可能提高患者對臨床試驗的理解和興趣。多選題展示出很高的準確度，並且與群眾外包註解者達成共識。對於這兩種資源類型，我們發現了需要持續的人工監督的幻覺。這些發現展示了 LLM「開箱即用」的潛力，可以用最少的試驗特定工程來支援臨床試驗教育材料的產生，但仍需要採用有人在迴路中的實作來避免錯誤資訊的風險。

##### **Recurrent Neural Network on PICTURE Model**
2412.01933v1 by Weihan Xu

Intensive Care Units (ICUs) provide critical care and life support for most
severely ill and injured patients in the hospital. With the need for ICUs
growing rapidly and unprecedentedly, especially during COVID-19, accurately
identifying the most critical patients helps hospitals to allocate resources
more efficiently and save more lives. The Predicting Intensive Care Transfers
and Other Unforeseen Events (PICTURE) model predicts patient deterioration by
separating those at high risk for imminent intensive care unit transfer,
respiratory failure, or death from those at lower risk. This study aims to
implement a deep learning model to benchmark the performance from the XGBoost
model, an existing model which has competitive results on prediction.

摘要：加護病房 (ICU) 提供重症照護和生命支持，給予醫院中病情最嚴重和受傷最嚴重的患者。由於對加護病房的需求快速且空前地增長，特別是在 COVID-19 期間，準確找出病情最危急的患者有助於醫院更有效地分配資源並挽救更多生命。預測加護病房轉診和其他無法預見事件 (PICTURE) 模型透過將面臨迫在眉睫的加護病房轉診、呼吸衰竭或死亡的高風險患者與風險較低的患者區分開來，預測患者惡化。本研究旨在實作深度學習模型，以基準化 XGBoost 模型的效能，後者是一種在預測方面具有競爭力的現有模型。

##### **ECG-SleepNet: Deep Learning-Based Comprehensive Sleep Stage Classification Using ECG Signals**
2412.01929v1 by Poorya Aghaomidi, Ge Wang

Accurate sleep stage classification is essential for understanding sleep
disorders and improving overall health. This study proposes a novel three-stage
approach for sleep stage classification using ECG signals, offering a more
accessible alternative to traditional methods that often rely on complex
modalities like EEG. In Stages 1 and 2, we initialize the weights of two
networks, which are then integrated in Stage 3 for comprehensive
classification. In the first phase, we estimate key features using Feature
Imitating Networks (FINs) to achieve higher accuracy and faster convergence.
The second phase focuses on identifying the N1 sleep stage through the
time-frequency representation of ECG signals. Finally, the third phase
integrates models from the previous stages and employs a Kolmogorov-Arnold
Network (KAN) to classify five distinct sleep stages. Additionally, data
augmentation techniques, particularly SMOTE, are used in enhancing
classification capabilities for underrepresented stages like N1. Our results
demonstrate significant improvements in the classification performance, with an
overall accuracy of 80.79% an overall kappa of 0.73. The model achieves
specific accuracies of 86.70% for Wake, 60.36% for N1, 83.89% for N2, 84.85%
for N3, and 87.16% for REM. This study emphasizes the importance of weight
initialization and data augmentation in optimizing sleep stage classification
with ECG signals.

摘要：精準的睡眠分期分類對於了解睡眠障礙和改善整體健康至關重要。本研究提出一個新的三階段方法，使用 ECG 訊號進行睡眠分期分類，提供了一個更易於取得的替代方案，傳統方法通常依賴於 EEG 等複雜的模式。在第 1 和第 2 階段，我們初始化兩個網路的權重，然後在第 3 階段整合它們以進行全面的分類。在第一階段，我們使用特徵模仿網路 (FIN) 估計關鍵特徵，以實現更高的準確度和更快的收斂。第二階段專注於透過 ECG 訊號的時頻表示來識別 N1 睡眠階段。最後，第三階段整合前一階段的模型，並採用 Kolmogorov-Arnold 網路 (KAN) 來分類五個不同的睡眠階段。此外，資料擴充技術，特別是 SMOTE，用於增強對 N1 等代表性不足階段的分類能力。我們的結果證明了分類效能有顯著的改善，整體準確度為 80.79%，整體 kappa 為 0.73。該模型對清醒、N1、N2、N3 和 REM 的特定準確度分別為 86.70%、60.36%、83.89%、84.85% 和 87.16%。本研究強調了權重初始化和資料擴充在使用 ECG 訊號最佳化睡眠分期分類中的重要性。

##### **Deep Guess acceleration for explainable image reconstruction in sparse-view CT**
2412.01703v1 by Elena Loli Piccolomini, Davide Evangelista, Elena Morotti

Sparse-view Computed Tomography (CT) is an emerging protocol designed to
reduce X-ray dose radiation in medical imaging. Traditional Filtered Back
Projection algorithm reconstructions suffer from severe artifacts due to sparse
data. In contrast, Model-Based Iterative Reconstruction (MBIR) algorithms,
though better at mitigating noise through regularization, are too
computationally costly for clinical use. This paper introduces a novel
technique, denoted as the Deep Guess acceleration scheme, using a trained
neural network both to quicken the regularized MBIR and to enhance the
reconstruction accuracy. We integrate state-of-the-art deep learning tools to
initialize a clever starting guess for a proximal algorithm solving a
non-convex model and thus computing an interpretable solution image in a few
iterations. Experimental results on real CT images demonstrate the Deep Guess
effectiveness in (very) sparse tomographic protocols, where it overcomes its
mere variational counterpart and many data-driven approaches at the state of
the art. We also consider a ground truth-free implementation and test the
robustness of the proposed framework to noise.

摘要：稀疏視圖電腦斷層掃描 (CT) 是一種新興的協定，旨在減少醫療影像中的 X 射線劑量輻射。傳統的濾波反向投影演算法重建因稀疏資料而導致嚴重的偽影。相比之下，基於模型的迭代重建 (MBIR) 演算法，雖然透過正則化在減輕雜訊方面表現得更好，但對於臨床使用而言，其計算成本過高。本文介紹了一種創新的技術，稱為 Deep Guess 加速方案，它使用訓練過的類神經網路來加速正則化的 MBIR 並增強重建準確度。我們整合了最先進的深度學習工具，為求解非凸模型的近端演算法初始化一個聰明的起始猜測，從而僅在幾次迭代中計算出可解釋的解影像。在真實 CT 影像上的實驗結果證明了 Deep Guess 在（非常）稀疏斷層攝影協定中的有效性，在該協定中，它克服了其單純的變分對應物和許多最先進的資料驅動方法。我們還考慮了無真實依據的實作，並測試了所提出的架構對雜訊的穩健性。

##### **Digital Epidemiology: Leveraging Social Media for Insight into Epilepsy and Mental Health**
2412.01692v1 by Liza Dahiya, Rachit Bagga

Social media platforms, particularly Reddit's r/Epilepsy community, offer a
unique perspective into the experiences of individuals with epilepsy (PWE) and
their caregivers. This study analyzes 57k posts and 533k comments to explore
key themes across demographics such as age, gender, and relationships. Our
findings highlight significant discussions on epilepsy-related challenges,
including depression (with 39.75\% of posts indicating severe symptoms),
driving restrictions, workplace concerns, and pregnancy-related issues in women
with epilepsy. We introduce a novel engagement metric, F(P), which incorporates
post length, sentiment scores, and readability to quantify community
interaction. This analysis underscores the importance of integrated care
addressing both neurological and mental health challenges faced by PWE. The
insights from this study inform strategies for targeted support and awareness
interventions.

摘要：社群媒體平台，特別是 Reddit 的 r/Epilepsy 社群，提供了癲癇患者 (PWE) 及其照顧者的經驗獨特觀點。這項研究分析了 57k 則貼文和 533k 則留言，探討不同人口統計資料（例如年齡、性別和關係）中的主要主題。我們的發現強調了關於癲癇相關挑戰的重要討論，包括憂鬱症（39.75% 的貼文表示有嚴重症狀）、駕駛限制、職場問題和癲癇女性的懷孕相關問題。我們引進了一項創新的參與度指標 F(P)，它結合了貼文長度、情緒分數和可讀性，以量化社群互動。這項分析強調了整合性照護的重要性，它能同時解決 PWE 面臨的神經和心理健康挑戰。這項研究的見解提供了針對性支持和意識介入策略。

##### **Medchain: Bridging the Gap Between LLM Agents and Clinical Practice through Interactive Sequential Benchmarking**
2412.01605v1 by Jie Liu, Wenxuan Wang, Zizhan Ma, Guolin Huang, Yihang SU, Kao-Jung Chang, Wenting Chen, Haoliang Li, Linlin Shen, Michael Lyu

Clinical decision making (CDM) is a complex, dynamic process crucial to
healthcare delivery, yet it remains a significant challenge for artificial
intelligence systems. While Large Language Model (LLM)-based agents have been
tested on general medical knowledge using licensing exams and knowledge
question-answering tasks, their performance in the CDM in real-world scenarios
is limited due to the lack of comprehensive testing datasets that mirror actual
medical practice. To address this gap, we present MedChain, a dataset of 12,163
clinical cases that covers five key stages of clinical workflow. MedChain
distinguishes itself from existing benchmarks with three key features of
real-world clinical practice: personalization, interactivity, and
sequentiality. Further, to tackle real-world CDM challenges, we also propose
MedChain-Agent, an AI system that integrates a feedback mechanism and a
MCase-RAG module to learn from previous cases and adapt its responses.
MedChain-Agent demonstrates remarkable adaptability in gathering information
dynamically and handling sequential clinical tasks, significantly outperforming
existing approaches. The relevant dataset and code will be released upon
acceptance of this paper.

摘要：臨床決策制定 (CDM) 是一個複雜、動態的過程，對於醫療保健的提供至關重要，然而對於人工智慧系統來說，它仍然是一項重大的挑戰。雖然大型語言模型 (LLM) 基礎代理已使用執照考試和知識問答任務對一般醫療知識進行了測試，但它們在實際場景中的 CDM 中的表現受到缺乏反映實際醫療實務的綜合測試資料集的限制。為了解決這個差距，我們提出了 MedChain，這是一個包含 12,163 個臨床案例的資料集，涵蓋了臨床工作流程的五個關鍵階段。MedChain 以現實世界臨床實務的三個關鍵特徵區別於現有的基準：個人化、互動性和順序性。此外，為了應對現實世界的 CDM 挑戰，我們還提出了 MedChain-Agent，這是一個整合了回饋機制和 MCase-RAG 模組的人工智慧系統，用於從先前的案例中學習並調整其回應。MedChain-Agent 在動態收集資訊和處理順序性臨床任務方面展現了顯著的適應性，顯著優於現有方法。相關的資料集和程式碼將在本文被接受後發布。

##### **NCDD: Nearest Centroid Distance Deficit for Out-Of-Distribution Detection in Gastrointestinal Vision**
2412.01590v1 by Sandesh Pokhrel, Sanjay Bhandari, Sharib Ali, Tryphon Lambrou, Anh Nguyen, Yash Raj Shrestha, Angus Watson, Danail Stoyanov, Prashnna Gyawali, Binod Bhattarai

The integration of deep learning tools in gastrointestinal vision holds the
potential for significant advancements in diagnosis, treatment, and overall
patient care. A major challenge, however, is these tools' tendency to make
overconfident predictions, even when encountering unseen or newly emerging
disease patterns, undermining their reliability.
  We address this critical issue of reliability by framing it as an
out-of-distribution (OOD) detection problem, where previously unseen and
emerging diseases are identified as OOD examples. However, gastrointestinal
images pose a unique challenge due to the overlapping feature representations
between in- Distribution (ID) and OOD examples. Existing approaches often
overlook this characteristic, as they are primarily developed for natural image
datasets, where feature distinctions are more apparent. Despite the overlap, we
hypothesize that the features of an in-distribution example will cluster closer
to the centroids of their ground truth class, resulting in a shorter distance
to the nearest centroid. In contrast, OOD examples maintain an equal distance
from all class centroids. Based on this observation, we propose a novel
nearest-centroid distance deficit (NCCD) score in the feature space for
gastrointestinal OOD detection.
  Evaluations across multiple deep learning architectures and two publicly
available benchmarks, Kvasir2 and Gastrovision, demonstrate the effectiveness
of our approach compared to several state-of-the-art methods. The code and
implementation details are publicly available at:
https://github.com/bhattarailab/NCDD

摘要：深度學習工具整合在胃腸道視覺中，在診斷、治療和整體病人照護方面具有顯著進展的潛力。然而，一個重大的挑戰是，這些工具傾向於做出過度自信的預測，即使在遇到未見或新出現的疾病模式時，也會破壞其可靠性。
我們將此可靠性的關鍵問題，架構為一個異常分佈 (OOD) 偵測問題，其中以前未見和新出現的疾病被視為 OOD 範例。然而，由於分佈內 (ID) 和 OOD 範例之間的重疊特徵表示，胃腸道影像構成了一項獨特的挑戰。現有的方法通常忽略此特性，因為它們主要是為自然影像資料集而開發，其中特徵區別較為明顯。儘管有重疊，我們假設分佈內範例的特徵會聚集在其真實類別的質心附近，導致到最近質心的距離較短。相反地，OOD 範例與所有類別質心的距離相等。基於此觀察，我們在特徵空間中提出了一個用於胃腸道 OOD 偵測的新穎最近質心距離差 (NCCD) 分數。
在多個深度學習架構和兩個公開基準 Kvasir2 和 Gastrovision 中的評估，證明了我們的方法與幾種最先進的方法相比的有效性。程式碼和實作細節公開於：
https://github.com/bhattarailab/NCDD

##### **MambaU-Lite: A Lightweight Model based on Mamba and Integrated Channel-Spatial Attention for Skin Lesion Segmentation**
2412.01405v1 by Thi-Nhu-Quynh Nguyen, Quang-Huy Ho, Duy-Thai Nguyen, Hoang-Minh-Quang Le, Van-Truong Pham, Thi-Thao Tran

Early detection of skin abnormalities plays a crucial role in diagnosing and
treating skin cancer. Segmentation of affected skin regions using AI-powered
devices is relatively common and supports the diagnostic process. However,
achieving high performance remains a significant challenge due to the need for
high-resolution images and the often unclear boundaries of individual lesions.
At the same time, medical devices require segmentation models to have a small
memory foot-print and low computational cost. Based on these requirements, we
introduce a novel lightweight model called MambaU-Lite, which combines the
strengths of Mamba and CNN architectures, featuring just over 400K parameters
and a computational cost of more than 1G flops. To enhance both global context
and local feature extraction, we propose the P-Mamba block, a novel component
that incorporates VSS blocks along-side multiple pooling layers, enabling the
model to effectively learn multiscale features and enhance segmentation
performance. We evaluate the model's performance on two skin datasets, ISIC2018
and PH2, yielding promising results. Our source code will be made publicly
available at: https://github.com/nqnguyen812/MambaU-Lite.

摘要：早期皮膚異常偵測在診斷和治療皮膚癌中扮演著至關重要的角色。使用 AI 驅動的裝置分割受影響的皮膚區域相對常見，並支援診斷流程。然而，由於需要高解析度影像和個別病灶通常不明確的邊界，要達成高性能仍是一項重大的挑戰。同時，醫療裝置要求分割模型具有小的記憶體佔用空間和低運算成本。基於這些需求，我們引進了一種名為 MambaU-Lite 的新型輕量級模型，它結合了 Mamba 和 CNN 架構的優點，特點是只有超過 400K 個參數和超過 1G flops 的運算成本。為了增強全局背景和局部特徵萃取，我們提出了 P-Mamba 塊，這是一個新的組成部分，它結合了 VSS 塊和多個池化層，使模型能夠有效地學習多尺度特徵並增強分割性能。我們在兩個皮膚資料集 ISIC2018 和 PH2 上評估了模型的性能，產生了有希望的結果。我們的原始程式碼將公開於：https://github.com/nqnguyen812/MambaU-Lite。

##### **Su-RoBERTa: A Semi-supervised Approach to Predicting Suicide Risk through Social Media using Base Language Models**
2412.01353v1 by Chayan Tank, Shaina Mehta, Sarthak Pol, Vinayak Katoch, Avinash Anand, Raj Jaiswal, Rajiv Ratn Shah

In recent times, more and more people are posting about their mental states
across various social media platforms. Leveraging this data, AI-based systems
can be developed that help in assessing the mental health of individuals, such
as suicide risk. This paper is a study done on suicidal risk assessments using
Reddit data leveraging Base language models to identify patterns from social
media posts. We have demonstrated that using smaller language models, i.e.,
less than 500M parameters, can also be effective in contrast to LLMs with
greater than 500M parameters. We propose Su-RoBERTa, a fine-tuned RoBERTa on
suicide risk prediction task that utilized both the labeled and unlabeled
Reddit data and tackled class imbalance by data augmentation using GPT-2 model.
Our Su-RoBERTa model attained a 69.84% weighted F1 score during the Final
evaluation. This paper demonstrates the effectiveness of Base language models
for the analysis of the risk factors related to mental health with an efficient
computation pipeline

摘要：近來，愈來愈多人於各種社群媒體平台發布其心理狀態。利用此資料，可以開發出基於 AI 的系統，用於評估個人的心理健康，例如自殺風險。本文是一項針對自殺風險評估的研究，利用 Reddit 資料，並利用基礎語言模型來識別社群媒體貼文的模式。我們已經證明，使用較小的語言模型（即小於 5 億個參數）也可以有效，這與參數大於 5 億個的 LLM 相比。我們提出 Su-RoBERTa，一個針對自殺風險預測任務進行微調的 RoBERTa，它利用標記和未標記的 Reddit 資料，並透過使用 GPT-2 模型進行資料擴充來解決類別不平衡的問題。我們的 Su-RoBERTa 模型在最終評估期間獲得了 69.84% 的加權 F1 分數。本文證明了基礎語言模型在分析與心理健康相關的風險因子方面的有效性，並具備高效的運算管道

##### **Multimodal Medical Disease Classification with LLaMA II**
2412.01306v1 by Christian Gapp, Elias Tappeiner, Martin Welk, Rainer Schubert

Medical patient data is always multimodal. Images, text, age, gender,
histopathological data are only few examples for different modalities in this
context. Processing and integrating this multimodal data with deep learning
based methods is of utmost interest due to its huge potential for medical
procedure such as diagnosis and patient treatment planning. In this work we
retrain a multimodal transformer-based model for disease classification. To
this end we use the text-image pair dataset from OpenI consisting of 2D chest
X-rays associated with clinical reports. Our focus is on fusion methods for
merging text and vision information extracted from medical datasets. Different
architecture structures with a LLaMA II backbone model are tested. Early fusion
of modality specific features creates better results with the best model
reaching 97.10% mean AUC than late fusion from a deeper level of the
architecture (best model: 96.67% mean AUC). Both outperform former
classification models tested on the same multimodal dataset. The newly
introduced multimodal architecture can be applied to other multimodal datasets
with little effort and can be easily adapted for further research, especially,
but not limited to, the field of medical AI.

摘要：醫療病患資料總是多模態的。影像、文字、年齡、性別、組織病理學資料只是此脈絡下不同模態的幾個例子。處理和整合這些多模態資料，並使用深度學習方法，由於其在醫療程序（例如診斷和病患治療計畫）的龐大潛力，因此至關重要。在這項工作中，我們重新訓練一個多模態Transformer基礎模型，用於疾病分類。為此，我們使用來自 OpenI 的文字影像配對資料集，其中包含與臨床報告相關的 2D 胸部 X 光。我們的重點在於融合方法，用於合併從醫療資料集提取的文字和影像資訊。測試了具有 LLaMA II 主幹模型的不同架構結構。特定於模態特徵的早期融合會產生更好的結果，最佳模型達到 97.10% 的平均 AUC，高於從架構更深層次進行的後期融合（最佳模型：96.67% 的平均 AUC）。兩者都優於在相同多模態資料集上測試的前分類模型。新推出的多模態架構可以毫不費力地應用於其他多模態資料集，並且可以輕鬆改編以進行進一步的研究，特別是（但不限於）醫療 AI 領域。

##### **Best Practices for Large Language Models in Radiology**
2412.01233v1 by Christian Bluethgen, Dave Van Veen, Cyril Zakka, Katherine Link, Aaron Fanous, Roxana Daneshjou, Thomas Frauenfelder, Curtis Langlotz, Sergios Gatidis, Akshay Chaudhari

At the heart of radiological practice is the challenge of integrating complex
imaging data with clinical information to produce actionable insights. Nuanced
application of language is key for various activities, including managing
requests, describing and interpreting imaging findings in the context of
clinical data, and concisely documenting and communicating the outcomes. The
emergence of large language models (LLMs) offers an opportunity to improve the
management and interpretation of the vast data in radiology. Despite being
primarily general-purpose, these advanced computational models demonstrate
impressive capabilities in specialized language-related tasks, even without
specific training. Unlocking the potential of LLMs for radiology requires basic
understanding of their foundations and a strategic approach to navigate their
idiosyncrasies. This review, drawing from practical radiology and machine
learning expertise and recent literature, provides readers insight into the
potential of LLMs in radiology. It examines best practices that have so far
stood the test of time in the rapidly evolving landscape of LLMs. This includes
practical advice for optimizing LLM characteristics for radiology practices
along with limitations, effective prompting, and fine-tuning strategies.

摘要：放射學實務的核心挑戰，在於整合複雜的影像資料與臨床資訊，以產生可行的見解。語言的細緻運用是各種活動的關鍵，包括管理請求、描述和解讀影像結果的臨床資料，以及簡潔地記錄和傳達結果。大型語言模型 (LLM) 的出現，提供了一個機會來改善放射學中大量資料的管理和解讀。儘管主要是一般用途，這些先進的計算模型在專業的語言相關任務中展現出令人印象深刻的能力，即使沒有特定的訓練。要解鎖 LLM 在放射學中的潛力，需要基本了解其基礎，以及應對其獨特之處的策略性方法。這篇評論從實務放射學和機器學習專業知識以及近期文獻中汲取，為讀者提供 LLM 在放射學中的潛力的見解。它檢視了迄今為止在 LLM 快速演變的領域中經得起時間考驗的最佳實務。這包括針對放射學實務最佳化 LLM 特性的實務建議，以及限制、有效的提示和微調策略。

##### **Object Tracking in a $360^o$ View: A Novel Perspective on Bridging the Gap to Biomedical Advancements**
2412.01119v1 by Mojtaba S. Fazli, Shannon Quinn

Object tracking is a fundamental tool in modern innovation, with applications
in defense systems, autonomous vehicles, and biomedical research. It enables
precise identification, monitoring, and spatiotemporal analysis of objects
across sequential frames, providing insights into dynamic behaviors. In cell
biology, object tracking is vital for uncovering cellular mechanisms, such as
migration, interactions, and responses to drugs or pathogens. These insights
drive breakthroughs in understanding disease progression and therapeutic
interventions.
  Over time, object tracking methods have evolved from traditional
feature-based approaches to advanced machine learning and deep learning
frameworks. While classical methods are reliable in controlled settings, they
struggle in complex environments with occlusions, variable lighting, and high
object density. Deep learning models address these challenges by delivering
greater accuracy, adaptability, and robustness.
  This review categorizes object tracking techniques into traditional,
statistical, feature-based, and machine learning paradigms, with a focus on
biomedical applications. These methods are essential for tracking cells and
subcellular structures, advancing our understanding of health and disease. Key
performance metrics, including accuracy, efficiency, and adaptability, are
discussed. The paper explores limitations of current methods and highlights
emerging trends to guide the development of next-generation tracking systems
for biomedical research and broader scientific domains.

摘要：物件追蹤是現代創新中的一項基本工具，應用於國防系統、自動駕駛車輛和生物醫學研究中。它能精準地辨識、監控和時空分析連續畫面中的物件，提供動態行為的見解。在細胞生物學中，物件追蹤對於揭露細胞機制至關重要，例如遷移、交互作用和對藥物或病原體的反應。這些見解推動了對疾病進程和治療干預的理解的突破。
隨著時間的推移，物件追蹤方法已從傳統的基於特徵的方法演變為先進的機器學習和深度學習架構。雖然傳統方法在受控環境中是可靠的，但它們在有遮擋、光線變化和物件密度高的複雜環境中會遇到困難。深度學習模型通過提供更高的準確性、適應性和魯棒性來應對這些挑戰。
本綜述將物件追蹤技術分為傳統、統計、基於特徵和機器學習範例，重點關注生物醫學應用。這些方法對於追蹤細胞和亞細胞結構至關重要，促進了我們對健康和疾病的理解。討論了關鍵的效能指標，包括準確性、效率和適應性。本文探討了當前方法的局限性，並重點介紹了新興趨勢，以指導下一代生物醫學研究和更廣泛的科學領域追蹤系統的開發。

##### **Evaluating Automated Radiology Report Quality through Fine-Grained Phrasal Grounding of Clinical Findings**
2412.01031v1 by Razi Mahmood, Pingkun Yan, Diego Machado Reyes, Ge Wang, Mannudeep K. Kalra, Parisa Kaviani, Joy T. Wu, Tanveer Syeda-Mahmood

Several evaluation metrics have been developed recently to automatically
assess the quality of generative AI reports for chest radiographs based only on
textual information using lexical, semantic, or clinical named entity
recognition methods. In this paper, we develop a new method of report quality
evaluation by first extracting fine-grained finding patterns capturing the
location, laterality, and severity of a large number of clinical findings. We
then performed phrasal grounding to localize their associated anatomical
regions on chest radiograph images. The textual and visual measures are then
combined to rate the quality of the generated reports. We present results that
compare this evaluation metric with other textual metrics on a gold standard
dataset derived from the MIMIC collection and show its robustness and
sensitivity to factual errors.

摘要：最近已开发出几种评估指标，以仅使用词汇、语义或临床命名实体识别方法，根据文本信息自动评估胸部 X 光片的生成式 AI 报告的质量。在本文中，我们开发了一种新的报告质量评估方法，首先提取细粒度的发现模式，捕捉大量临床发现的位置、侧向性和严重性。然后，我们执行短语接地以定位其在胸部 X 光片图像上的相关解剖区域。然后将文本和视觉测量值结合起来，对生成的报告的质量进行评分。我们展示了将此评估指标与其他文本指标在从 MIMIC 集合中得出的黄金标准数据集上的比较结果，并展示了其对事实错误的稳健性和敏感性。

##### **Generative Language Models Potential for Requirement Engineering Applications: Insights into Current Strengths and Limitations**
2412.00959v1 by Summra Saleem, Muhammad Nabeel Asim, Ludger Van Elst, Andreas Dengel

Traditional language models have been extensively evaluated for software
engineering domain, however the potential of ChatGPT and Gemini have not been
fully explored. To fulfill this gap, the paper in hand presents a comprehensive
case study to investigate the potential of both language models for development
of diverse types of requirement engineering applications. It deeply explores
impact of varying levels of expert knowledge prompts on the prediction
accuracies of both language models. Across 4 different public benchmark
datasets of requirement engineering tasks, it compares performance of both
language models with existing task specific machine/deep learning predictors
and traditional language models. Specifically, the paper utilizes 4 benchmark
datasets; Pure (7,445 samples, requirements extraction),PROMISE (622 samples,
requirements classification), REQuestA (300 question answer (QA) pairs) and
Aerospace datasets (6347 words, requirements NER tagging). Our experiments
reveal that, in comparison to ChatGPT, Gemini requires more careful prompt
engineering to provide accurate predictions. Moreover, across requirement
extraction benchmark dataset the state-of-the-art F1-score is 0.86 while
ChatGPT and Gemini achieved 0.76 and 0.77,respectively. The State-of-the-art
F1-score on requirements classification dataset is 0.96 and both language
models 0.78. In name entity recognition (NER) task the state-of-the-art
F1-score is 0.92 and ChatGPT managed to produce 0.36, and Gemini 0.25.
Similarly, across question answering dataset the state-of-the-art F1-score is
0.90 and ChatGPT and Gemini managed to produce 0.91 and 0.88 respectively. Our
experiments show that Gemini requires more precise prompt engineering than
ChatGPT. Except for question-answering, both models under-perform compared to
current state-of-the-art predictors across other tasks.

摘要：傳統語言模型已廣泛評估軟體工程領域，但 ChatGPT 和 Gemini 的潛力尚未被完全探索。為了填補這個差距，本文提出了全面的案例研究，以探討這兩種語言模型在開發各種需求工程應用程式方面的潛力。它深入探討了不同層級專家知識提示對這兩種語言模型預測精度的影響。在 4 個不同的需求工程任務公共基準資料集，它比較了這兩種語言模型與現有任務特定機器/深度學習預測器和傳統語言模型的效能。具體來說，本文利用 4 個基準資料集；Pure（7,445 個樣本，需求萃取）、PROMISE（622 個樣本，需求分類）、REQuestA（300 個問答 (QA) 對）和航太資料集（6347 個字，需求 NER 標記）。我們的實驗顯示，與 ChatGPT 相比，Gemini 需要更仔細的提示工程才能提供準確的預測。此外，在需求萃取基準資料集，最先進的 F1 分數為 0.86，而 ChatGPT 和 Gemini 分別達到 0.76 和 0.77。需求分類資料集的最先進 F1 分數為 0.96，而這兩種語言模型都為 0.78。在命名實體識別 (NER) 任務中，最先進的 F1 分數為 0.92，而 ChatGPT 產生 0.36，Gemini 產生 0.25。類似地，在問答資料集，最先進的 F1 分數為 0.90，而 ChatGPT 和 Gemini 分別產生 0.91 和 0.88。我們的實驗表明，Gemini 需要比 ChatGPT 更精確的提示工程。除了問答之外，這兩個模型在其他任務的表現都低於目前的最新預測器。

##### **TSUBF-Net: Trans-Spatial UNet-like Network with Bi-direction Fusion for Segmentation of Adenoid Hypertrophy in CT**
2412.00787v1 by Rulin Zhou, Yingjie Feng, Guankun Wang, Xiaopin Zhong, Zongze Wu, Qiang Wu, Xi Zhang

Adenoid hypertrophy stands as a common cause of obstructive sleep
apnea-hypopnea syndrome in children. It is characterized by snoring, nasal
congestion, and growth disorders. Computed Tomography (CT) emerges as a pivotal
medical imaging modality, utilizing X-rays and advanced computational
techniques to generate detailed cross-sectional images. Within the realm of
pediatric airway assessments, CT imaging provides an insightful perspective on
the shape and volume of enlarged adenoids. Despite the advances of deep
learning methods for medical imaging analysis, there remains an emptiness in
the segmentation of adenoid hypertrophy in CT scans. To address this research
gap, we introduce TSUBF-Nett (Trans-Spatial UNet-like Network based on
Bi-direction Fusion), a 3D medical image segmentation framework. TSUBF-Net is
engineered to effectively discern intricate 3D spatial interlayer features in
CT scans and enhance the extraction of boundary-blurring features. Notably, we
propose two innovative modules within the U-shaped network architecture:the
Trans-Spatial Perception module (TSP) and the Bi-directional Sampling
Collaborated Fusion module (BSCF).These two modules are in charge of operating
during the sampling process and strategically fusing down-sampled and
up-sampled features, respectively. Furthermore, we introduce the Sobel loss
term, which optimizes the smoothness of the segmentation results and enhances
model accuracy. Extensive 3D segmentation experiments are conducted on several
datasets. TSUBF-Net is superior to the state-of-the-art methods with the lowest
HD95: 7.03, IoU:85.63, and DSC: 92.26 on our own AHSD dataset. The results in
the other two public datasets also demonstrate that our methods can robustly
and effectively address the challenges of 3D segmentation in CT scans.

摘要：腺樣體肥大是兒童阻塞性睡眠呼吸中止低通氣綜合徵的常見原因。其特徵為打鼾、鼻塞和生長障礙。電腦斷層掃描 (CT) 是一種重要的醫學影像模式，利用 X 射線和先進的計算技術生成詳細的橫斷面影像。在小兒氣道評估領域，CT 影像提供了腺樣體肥大的形狀和體積的深刻見解。儘管深度學習方法在醫學影像分析方面取得了進展，但 CT 掃描中腺樣體肥大的分割仍存在空缺。為了解決這個研究差距，我們引入了 TSUBF-Nett（基於雙向融合的 Trans-Spatial UNet 類網路），這是一個 3D 醫學影像分割框架。TSUBF-Net 被設計為有效識別 CT 掃描中複雜的 3D 空間互層特徵，並增強邊界模糊特徵的提取。值得注意的是，我們在 U 形網路架構中提出了兩個創新的模組：Trans-Spatial 感知模組 (TSP) 和雙向採樣協作融合模組 (BSCF)。這兩個模組負責在採樣過程中運作，並分別策略性地融合下採樣和上採樣特徵。此外，我們引入了 Sobel 損失項，它優化了分割結果的平滑度並增強了模型的準確性。在多個資料集上進行了廣泛的 3D 分割實驗。TSUBF-Net 優於最先進的方法，在我們自己的 AHSD 資料集上具有最低的 HD95：7.03、IoU：85.63 和 DSC：92.26。其他兩個公共資料集中的結果也表明，我們的模型可以穩健有效地解決 CT 掃描中 3D 分割的挑戰。

##### **Automating Feedback Analysis in Surgical Training: Detection, Categorization, and Assessment**
2412.00760v1 by Firdavs Nasriddinov, Rafal Kocielnik, Arushi Gupta, Cherine Yang, Elyssa Wong, Anima Anandkumar, Andrew Hung

This work introduces the first framework for reconstructing surgical dialogue
from unstructured real-world recordings, which is crucial for characterizing
teaching tasks. In surgical training, the formative verbal feedback that
trainers provide to trainees during live surgeries is crucial for ensuring
safety, correcting behavior immediately, and facilitating long-term skill
acquisition. However, analyzing and quantifying this feedback is challenging
due to its unstructured and specialized nature. Automated systems are essential
to manage these complexities at scale, allowing for the creation of structured
datasets that enhance feedback analysis and improve surgical education. Our
framework integrates voice activity detection, speaker diarization, and
automated speech recaognition, with a novel enhancement that 1) removes
hallucinations (non-existent utterances generated during speech recognition
fueled by noise in the operating room) and 2) separates speech from trainers
and trainees using few-shot voice samples. These aspects are vital for
reconstructing accurate surgical dialogues and understanding the roles of
operating room participants. Using data from 33 real-world surgeries, we
demonstrated the system's capability to reconstruct surgical teaching dialogues
and detect feedback instances effectively (F1 score of 0.79+/-0.07). Moreover,
our hallucination removal step improves feedback detection performance by ~14%.
Evaluation on downstream clinically relevant tasks of predicting Behavioral
Adjustment of trainees and classifying Technical feedback, showed performances
comparable to manual annotations with F1 scores of 0.82+/0.03 and 0.81+/0.03
respectively. These results highlight the effectiveness of our framework in
supporting clinically relevant tasks and improving over manual methods.

摘要：<paragraph>這項工作介紹了第一個用於重建手術對話的架構，該架構來自非結構化的真實世界錄音，這對於描述教學任務至關重要。在外科培訓中，培訓者在現場手術期間向受訓者提供的形成性言語回饋對於確保安全、立即糾正行為和促進長期技能習得至關重要。然而，由於其非結構化和專業性質，對此回饋進行分析和量化具有挑戰性。自動化系統對於大規模管理這些複雜性至關重要，允許創建結構化的資料集，以增強回饋分析並改善外科教育。我們的架構整合了語音活動偵測、說話者日記和自動語音識別，並具有一個新穎的增強功能，該功能 1) 消除了幻覺（在手術室的噪音引發語音識別期間產生的不存在的語句）和 2) 使用少數語音樣本將培訓者和受訓者的語音分開。這些方面對於重建準確的手術對話和理解手術室參與者的角色至關重要。使用來自 33 次真實手術的資料，我們展示了該系統重建手術教學對話和有效檢測回饋實例的能力（F1 分數為 0.79+/-0.07）。此外，我們的幻覺消除步驟將回饋檢測效能提升了約 14%。在預測受訓者的行為調整和分類技術回饋的下游臨床相關任務的評估中，顯示出與 F1 分數分別為 0.82+/0.03 和 0.81+/0.03 的手動標註相當的效能。這些結果突顯了我們的架構在支援臨床相關任務和改進手動方法方面的有效性。</paragraph>

##### **Fairness at Every Intersection: Uncovering and Mitigating Intersectional Biases in Multimodal Clinical Predictions**
2412.00606v1 by Resmi Ramachandranpillai, Kishore Sampath, Ayaazuddin Mohammad, Malihe Alikhani

Biases in automated clinical decision-making using Electronic Healthcare
Records (EHR) impose significant disparities in patient care and treatment
outcomes. Conventional approaches have primarily focused on bias mitigation
strategies stemming from single attributes, overlooking intersectional
subgroups -- groups formed across various demographic intersections (such as
race, gender, ethnicity, etc.). Rendering single-attribute mitigation
strategies to intersectional subgroups becomes statistically irrelevant due to
the varying distribution and bias patterns across these subgroups. The
multimodal nature of EHR -- data from various sources such as combinations of
text, time series, tabular, events, and images -- adds another layer of
complexity as the influence on minority groups may fluctuate across modalities.
In this paper, we take the initial steps to uncover potential intersectional
biases in predictions by sourcing extensive multimodal datasets, MIMIC-Eye1 and
MIMIC-IV ED, and propose mitigation at the intersectional subgroup level. We
perform and benchmark downstream tasks and bias evaluation on the datasets by
learning a unified text representation from multimodal sources, harnessing the
enormous capabilities of the pre-trained clinical Language Models (LM),
MedBERT, Clinical BERT, and Clinical BioBERT. Our findings indicate that the
proposed sub-group-specific bias mitigation is robust across different
datasets, subgroups, and embeddings, demonstrating effectiveness in addressing
intersectional biases in multimodal settings.

摘要：電子病歷 (EHR) 中自動化臨床決策的偏差會對患者照護和治療結果造成顯著的差異。傳統方法主要專注於單一屬性的偏差緩解策略，忽略了交叉群體——在各種人口統計交叉點（例如種族、性別、種族等）形成的群體。由於這些子群的分布和偏差模式不同，將單一屬性緩解策略應用於交叉子群在統計上變得無關緊要。EHR 的多模態性質——來自各種來源的數據，例如文本、時間序列、表格、事件和圖像的組合——增加了另一層複雜性，因為對少數群體的影響可能會在不同模式之間波動。在本文中，我們採取了初步步驟，通過採集廣泛的多模態數據集 MIMIC-Eye1 和 MIMIC-IV ED 來揭示預測中的潛在交叉偏差，並提出在交叉子群級別進行緩解。我們通過從多模態來源學習統一的文本表示，利用預訓練的臨床語言模型 (LM)、MedBERT、Clinical BERT 和 Clinical BioBERT 的強大功能，對數據集執行並基準下游任務和偏差評估。我們的研究結果表明，所提出的子群特定偏差緩解在不同的數據集、子群和嵌入中都是穩健的，證明了在多模態設置中解決交叉偏差的有效性。

##### **Opus: A Large Work Model for Complex Workflow Generation**
2412.00573v1 by Théo Fagnoni, Bellinda Mesbah, Mahsun Altin, Phillip Kingston

This paper introduces Opus, a novel framework for generating and optimizing
Workflows tailored to complex Business Process Outsourcing (BPO) use cases,
focusing on cost reduction and quality enhancement while adhering to
established industry processes and operational constraints. Our approach
generates executable Workflows from Intention, defined as the alignment of
Client Input, Client Output, and Process Context. These Workflows are
represented as Directed Acyclic Graphs (DAGs), with nodes as Tasks consisting
of sequences of executable Instructions, including tools and human expert
reviews. We adopt a two-phase methodology: Workflow Generation and Workflow
Optimization. In the Generation phase, Workflows are generated using a Large
Work Model (LWM) informed by a Work Knowledge Graph (WKG) that encodes
domain-specific procedural and operational knowledge. In the Optimization
phase, Workflows are transformed into Workflow Graphs (WFGs), where optimal
Workflows are determined through path optimization. Our experiments demonstrate
that state-of-the-art Large Language Models (LLMs) face challenges in reliably
retrieving detailed process data as well as generating industry-compliant
workflows. The key contributions of this paper include: - The integration of a
Work Knowledge Graph (WKG) into a Large Work Model (LWM), enabling the
generation of context-aware, semantically aligned, structured and auditable
Workflows. - A two-phase approach that combines Workflow Generation from
Intention with graph-based Workflow Optimization. - Opus Alpha 1 Large and Opus
Alpha 1 Small, models that outperform state-of-the-art LLMs by 38\% and 29\%
respectively in Workflow Generation for a Medical Coding use case.

摘要：<paragraph>這篇論文介紹了 Opus，一個用於產生和最佳化工作流程的新穎架構，專為複雜的業務流程外包 (BPO) 使用案例而設計，專注於在遵守既定的產業流程和營運限制的情況下，降低成本並提升品質。我們的做法是根據意圖產生可執行的工作流程，定義為客戶輸入、客戶輸出和流程背景的一致性。這些工作流程表示為有向無環圖 (DAG)，其中節點為任務，包含可執行指令的順序，包括工具和人類專家審查。我們採用兩階段方法：工作流程產生和工作流程最佳化。在產生階段，工作流程使用大型工作模型 (LWM) 產生，該模型由編碼特定領域程序和運作知識的工作知識圖 (WKG) 提供資訊。在最佳化階段，工作流程轉換為工作流程圖 (WFG)，其中最佳工作流程透過路徑最佳化來確定。我們的實驗證明，最先進的大語言模型 (LLM) 在可靠地擷取詳細的流程資料以及產生符合產業規範的工作流程方面面臨挑戰。本文的主要貢獻包括：- 將工作知識圖 (WKG) 整合到大型工作模型 (LWM) 中，讓產生有脈絡感知、語意對齊、結構化且可稽核的工作流程成為可能。- 一種結合意圖工作流程產生與基於圖形的工作流程最佳化的兩階段方法。- Opus Alpha 1 大型和 Opus Alpha 1 小型，在醫療編碼使用案例中，其工作流程產生表現分別優於最先進的 LLM 38% 和 29%。</paragraph>

##### **Polish Medical Exams: A new dataset for cross-lingual medical knowledge transfer assessment**
2412.00559v1 by Łukasz Grzybowski, Jakub Pokrywka, Michał Ciesiółka, Jeremi I. Kaczmarek, Marek Kubis

Large Language Models (LLMs) have demonstrated significant potential in
handling specialized tasks, including medical problem-solving. However, most
studies predominantly focus on English-language contexts. This study introduces
a novel benchmark dataset based on Polish medical licensing and specialization
exams (LEK, LDEK, PES) taken by medical doctor candidates and practicing
doctors pursuing specialization. The dataset was web-scraped from publicly
available resources provided by the Medical Examination Center and the Chief
Medical Chamber. It comprises over 24,000 exam questions, including a subset of
parallel Polish-English corpora, where the English portion was professionally
translated by the examination center for foreign candidates. By creating a
structured benchmark from these existing exam questions, we systematically
evaluate state-of-the-art LLMs, including general-purpose, domain-specific, and
Polish-specific models, and compare their performance against human medical
students. Our analysis reveals that while models like GPT-4o achieve near-human
performance, significant challenges persist in cross-lingual translation and
domain-specific understanding. These findings underscore disparities in model
performance across languages and medical specialties, highlighting the
limitations and ethical considerations of deploying LLMs in clinical practice.

摘要：大型語言模型 (LLM) 已展現出在處理專業任務（包括醫療問題解決）方面具有的顯著潛力。然而，大多數研究主要關注於英語語境。本研究引入了基於波蘭醫學許可和專科考試 (LEK、LDEK、PES) 的新基準資料集，由醫學博士候選人和從事專科的執業醫生參加。該資料集從醫學考試中心和首席醫學部門提供的公開資源中進行網路抓取。它包含超過 24,000 個考試題目，包括波蘭語-英語語料庫的子集，其中英語部分由考試中心為外籍考生專業翻譯。通過根據這些現有考試題目建立結構化基準，我們系統性地評估了最先進的 LLM，包括通用、特定領域和特定於波蘭的模型，並將其性能與人類醫學生進行比較。我們的分析表明，儘管 GPT-4o 等模型達到了接近人類的性能，但跨語言翻譯和特定領域理解中仍然存在重大挑戰。這些發現強調了跨語言和醫學專業的模型性能差異，突顯了在臨床實踐中部署 LLM 的局限性和倫理考量。

##### **Unveiling Performance Challenges of Large Language Models in Low-Resource Healthcare: A Demographic Fairness Perspective**
2412.00554v1 by Yue Zhou, Barbara Di Eugenio, Lu Cheng

This paper studies the performance of large language models (LLMs),
particularly regarding demographic fairness, in solving real-world healthcare
tasks. We evaluate state-of-the-art LLMs with three prevalent learning
frameworks across six diverse healthcare tasks and find significant challenges
in applying LLMs to real-world healthcare tasks and persistent fairness issues
across demographic groups. We also find that explicitly providing demographic
information yields mixed results, while LLM's ability to infer such details
raises concerns about biased health predictions. Utilizing LLMs as autonomous
agents with access to up-to-date guidelines does not guarantee performance
improvement. We believe these findings reveal the critical limitations of LLMs
in healthcare fairness and the urgent need for specialized research in this
area.

摘要：本文探討大型語言模型 (LLM) 的效能，特別是在人口統計公平性方面，以解決現實世界的醫療保健任務。我們評估了最先進的 LLM，採用三個流行的學習架構，涵蓋六項不同的醫療保健任務，發現將 LLM 應用於現實世界的醫療保健任務時會面臨重大挑戰，並且在不同人口統計群體中存在持續的公平性問題。我們還發現，明確提供人口統計資訊會產生不同的結果，而 LLM 推斷此類細節的能力引發了對有偏見的健康預測的擔憂。利用 LLM 作為具有存取最新指南的自主代理並不能保證效能提升。我們相信這些發現揭示了 LLM 在醫療保健公平性方面的重大限制，以及對此領域進行專門研究的迫切需要。

##### **2-Factor Retrieval for Improved Human-AI Decision Making in Radiology**
2412.00372v1 by Jim Solomon, Laleh Jalilian, Alexander Vilesov, Meryl Mathew, Tristan Grogan, Arash Bedayat, Achuta Kadambi

Human-machine teaming in medical AI requires us to understand to what degree
a trained clinician should weigh AI predictions. While previous work has shown
the potential of AI assistance at improving clinical predictions, existing
clinical decision support systems either provide no explainability of their
predictions or use techniques like saliency and Shapley values, which do not
allow for physician-based verification. To address this gap, this study
compares previously used explainable AI techniques with a newly proposed
technique termed '2-factor retrieval (2FR)', which is a combination of
interface design and search retrieval that returns similarly labeled data
without processing this data. This results in a 2-factor security blanket
where: (a) correct images need to be retrieved by the AI; and (b) humans should
associate the retrieved images with the current pathology under test. We find
that when tested on chest X-ray diagnoses, 2FR leads to increases in clinician
accuracy, with particular improvements when clinicians are radiologists and
have low confidence in their decision. Our results highlight the importance of
understanding how different modes of human-AI decision making may impact
clinician accuracy in clinical decision support systems.

摘要：人機協作在醫療 AI 中，需要我們理解受過訓練的臨床醫生在多大程度上應重視 AI 預測。雖然先前的研究顯示 AI 輔助在改善臨床預測方面的潛力，但現有的臨床決策支援系統，要不就沒有提供預測的可解釋性，要不就是使用像顯著性和 Shapley 值之類的技術，這些技術不允許基於醫生的驗證。為了解決這個差距，本研究將先前使用的可解釋 AI 技術與一種新提出的稱為「2 因子檢索 (2FR)」的技術進行比較，後者是一種介面設計和搜尋檢索的組合，它會傳回標籤相似的資料，而不會處理這些資料。這會產生一個 2 因子安全機制，其中：(a) 正確的影像需要由 AI 檢索；(b) 人類應將檢索的影像與正在測試中的病理聯想起來。我們發現，當在胸部 X 光診斷上進行測試時，2FR 會提高臨床醫生的準確度，特別是在臨床醫生是放射科醫生且對其決策信心不足時，會有顯著的改善。我們的結果強調了理解人機決策的不同模式如何影響臨床醫生在臨床決策支援系統中的準確性的重要性。

##### **One Model for One Graph: A New Perspective for Pretraining with Cross-domain Graphs**
2412.00315v1 by Jingzhe Liu, Haitao Mao, Zhikai Chen, Wenqi Fan, Mingxuan Ju, Tong Zhao, Neil Shah, Jiliang Tang

Graph Neural Networks (GNNs) have emerged as a powerful tool to capture
intricate network patterns, achieving success across different domains.
However, existing GNNs require careful domain-specific architecture designs and
training from scratch on each dataset, leading to an expertise-intensive
process with difficulty in generalizing across graphs from different domains.
Therefore, it can be hard for practitioners to infer which GNN model can
generalize well to graphs from their domains. To address this challenge, we
propose a novel cross-domain pretraining framework, "one model for one graph,"
which overcomes the limitations of previous approaches that failed to use a
single GNN to capture diverse graph patterns across domains with significant
gaps. Specifically, we pretrain a bank of expert models, with each one
corresponding to a specific dataset. When inferring to a new graph, gating
functions choose a subset of experts to effectively integrate prior model
knowledge while avoiding negative transfer. Extensive experiments consistently
demonstrate the superiority of our proposed method on both link prediction and
node classification tasks.

摘要：圖形神經網路 (GNN) 已成為捕捉複雜網路模式的強大工具，在不同領域皆取得成功。
然而，現有的 GNN 需要仔細的特定於領域的架構設計，並針對每個資料集從頭開始訓練，導致專業知識密集的過程，難以概括來自不同領域的圖形。
因此，從業者很難推斷哪個 GNN 模型可以很好地概括到其領域的圖形。為了應對這一挑戰，我們提出了一個新穎的跨領域預訓練框架，「一個模型對應一個圖形」，它克服了先前方法的限制，這些限制無法使用單個 GNN 來捕捉跨越具有顯著差距的領域的不同圖形模式。具體來說，我們預訓練了一組專家模型，每一個都對應一個特定資料集。在推論到一個新圖形時，閘控函數會選擇一個專家子集，以有效整合先前的模型知識，同時避免負面傳遞。廣泛的實驗持續證明了我們提出的方法在連結預測和節點分類任務上的優越性。

##### **BOTS: Batch Bayesian Optimization of Extended Thompson Sampling for Severely Episode-Limited RL Settings**
2412.00308v1 by Karine Karine, Susan A. Murphy, Benjamin M. Marlin

In settings where the application of reinforcement learning (RL) requires
running real-world trials, including the optimization of adaptive health
interventions, the number of episodes available for learning can be severely
limited due to cost or time constraints. In this setting, the bias-variance
trade-off of contextual bandit methods can be significantly better than that of
more complex full RL methods. However, Thompson sampling bandits are limited to
selecting actions based on distributions of immediate rewards. In this paper,
we extend the linear Thompson sampling bandit to select actions based on a
state-action utility function consisting of the Thompson sampler's estimate of
the expected immediate reward combined with an action bias term. We use batch
Bayesian optimization over episodes to learn the action bias terms with the
goal of maximizing the expected return of the extended Thompson sampler. The
proposed approach is able to learn optimal policies for a strictly broader
class of Markov decision processes (MDPs) than standard Thompson sampling.
Using an adaptive intervention simulation environment that captures key aspects
of behavioral dynamics, we show that the proposed method can significantly
out-perform standard Thompson sampling in terms of total return, while
requiring significantly fewer episodes than standard value function and policy
gradient methods.

摘要：在需要使用強化學習 (RL) 進行實際世界試驗，包括最佳化適應性健康干預措施的設定中，可用於學習的回合數可能會因為成本或時間限制而受到嚴重限制。在此設定中，情境強盜方法的偏差變異取捨會顯著優於更複雜的完整 RL 方法。不過，湯普森抽樣強盜只能根據立即獎勵的分配來選擇行動。在本文中，我們延伸線性湯普森抽樣強盜，以根據狀態行動效用函數選擇行動，該函數包含湯普森採樣器對預期立即獎勵的估計值，以及動作偏差項。我們使用批次貝氏最佳化在回合中學習動作偏差項，目標是最大化延伸湯普森採樣器的預期回報。提出的方法能夠為比標準湯普森抽樣更廣泛的馬可夫決策程序 (MDP) 類別學習最佳策略。使用捕捉行為動態關鍵層面的適應性干預模擬環境，我們證明所提出的方法在總回報方面可以顯著優於標準湯普森抽樣，同時所需回合數遠少於標準價值函數和策略梯度方法。

##### **Fine Tuning Large Language Models to Deliver CBT for Depression**
2412.00251v1 by Talha Tahir

Cognitive Behavioral Therapy (CBT) is a well-established, evidence-based
treatment for Major Depressive Disorder. Unfortunately, there exist significant
barriers to individuals accessing CBT, including cost, scarcity of therapists
and stigma. This study explores the feasibility of fine-tuning small open
weight large language models (LLMs) to deliver CBT for depression. Using 58
sets of synthetic CBT transcripts generated by the Nous Research fine-tune of
Llama 3.1 405b, we fine-tuned three models: Mistral 7b v0.3, Qwen 2.5 7b, and
Llama 3.1 8b. CBT fidelity was evaluated through a modified Cognitive Therapy
Rating Scale (CTRS). All fine-tuned models were compared against each other, as
well as their instruct-tuned variants. Simulated patient transcripts were
generated for the purpose of evaluating model performance, with the instruct
and CBT-tuned models acting as the therapist and DeepSeek-V2.5 acting as the
patient. These simulated transcripts were evaluated on a modified CTRS by
Gemini 1.5 Pro-002. Our findings demonstrated that the CBT-tuned models
significantly outperformed their instruct-tuned counterparts, with an average
improvement of 11.33 points (p < 0.001) on total CTRS score. Llama 3.1 8b had
the strongest performance (mean CTRS score 67.86 +/- 7.24), followed by Qwen
2.5 7b (64.28 +/- 9.55) and Mistral 7b v0.3 (64.17 +/- 9.79), with these
differences between models being statistically significant. The CBT-tuned
models were competent in implementing core CBT techniques and providing
empathetic responses, however, there were limitations observed in agenda
adherence, exploration depth and long-context coherence. This study establishes
that CBT specific fine-tuning can effectively encode therapeutic competencies
in small LLMs, though significant technical and ethical considerations must be
resolved prior to clinical deployment.

摘要：<paragraph>認知行為療法 (CBT) 是一種治療重度憂鬱症的完善且有實證基礎的療法。不幸的是，個人接受 CBT 仍存在重大障礙，包括費用、治療師稀缺和汙名化。本研究探討微調小型開放式權重大型語言模型 (LLM) 以提供 CBT 治療憂鬱症的可行性。使用 Nous Research 微調 Llama 3.1 405b 所產生的 58 組合成 CBT 謄本，我們微調了三個模型：Mistral 7b v0.3、Qwen 2.5 7b 和 Llama 3.1 8b。CBT 保真度透過修正後的認知治療評分量表 (CTRS) 進行評估。所有微調模型彼此比較，以及它們的指令微調變體。模擬患者謄本是為了評估模型效能而產生的，指令和 CBT 微調模型扮演治療師，而 DeepSeek-V2.5 扮演患者。這些模擬謄本由 Gemini 1.5 Pro-002 使用修正後的 CTRS 進行評估。我們的研究結果顯示，CBT 微調模型顯著優於其指令微調模型，CTRS 總分平均提升 11.33 分 (p < 0.001)。Llama 3.1 8b 效能最強 (CTRS 平均分數 67.86 +/- 7.24)，其次是 Qwen 2.5 7b (64.28 +/- 9.55) 和 Mistral 7b v0.3 (64.17 +/- 9.79)，這些模型之間的差異具有統計顯著性。CBT 微調模型在實施核心 CBT 技術和提供同理回應方面表現得很好，然而在議程遵循、探索深度和長脈絡連貫性方面仍有觀察到的限制。本研究證實，特定於 CBT 的微調可以有效地將治療能力編碼到小型 LLM 中，儘管在臨床部署之前必須解決重大的技術和倫理考量。</paragraph>

##### **Integrating Social Determinants of Health into Knowledge Graphs: Evaluating Prediction Bias and Fairness in Healthcare**
2412.00245v1 by Tianqi Shang, Weiqing He, Tianlong Chen, Ying Ding, Huanmei Wu, Kaixiong Zhou, Li Shen

Social determinants of health (SDoH) play a crucial role in patient health
outcomes, yet their integration into biomedical knowledge graphs remains
underexplored. This study addresses this gap by constructing an SDoH-enriched
knowledge graph using the MIMIC-III dataset and PrimeKG. We introduce a novel
fairness formulation for graph embeddings, focusing on invariance with respect
to sensitive SDoH information. Via employing a heterogeneous-GCN model for
drug-disease link prediction, we detect biases related to various SDoH factors.
To mitigate these biases, we propose a post-processing method that
strategically reweights edges connected to SDoHs, balancing their influence on
graph representations. This approach represents one of the first comprehensive
investigations into fairness issues within biomedical knowledge graphs
incorporating SDoH. Our work not only highlights the importance of considering
SDoH in medical informatics but also provides a concrete method for reducing
SDoH-related biases in link prediction tasks, paving the way for more equitable
healthcare recommendations. Our code is available at
\url{https://github.com/hwq0726/SDoH-KG}.

摘要：社會健康決定因素（SDoH）在患者健康結果中扮演著至關重要的角色，但它們整合到生物醫學知識圖譜中的部分仍有待探討。本研究透過使用 MIMIC-III 資料集和 PrimeKG 建構一個 SDoH 豐富的知識圖譜來解決這個差距。我們針對圖形嵌入引入一個新的公平性公式，專注於對敏感的 SDoH 資訊保持不變性。透過採用異質 GCN 模型進行藥物疾病連結預測，我們偵測到與各種 SDoH 因子相關的偏差。為了減輕這些偏差，我們提出一個後處理方法，該方法策略性地重新加權連接到 SDoH 的邊緣，平衡它們對圖表表示的影響。此方法代表了將 SDoH 納入生物醫學知識圖譜中公平性問題的第一個全面調查之一。我們的研究不僅強調了在醫學資訊學中考量 SDoH 的重要性，也提供了一個具體的方法來減少連結預測任務中與 SDoH 相關的偏差，為更公平的醫療保健建議鋪路。我們的程式碼可在 \url{https://github.com/hwq0726/SDoH-KG} 取得。

##### **Dynamic EEG-fMRI mapping: Revealing the relationship between brain connectivity and cognitive state**
2411.19922v1 by Guiran Liu, Binrong Zhu

This study investigated the dynamic connectivity patterns between EEG and
fMRI modalities, contributing to our understanding of brain network
interactions. By employing a comprehensive approach that integrated static and
dynamic analyses of EEG-fMRI data, we were able to uncover distinct
connectivity states and characterize their temporal fluctuations. The results
revealed modular organization within the intrinsic connectivity networks (ICNs)
of the brain, highlighting the significant roles of sensory systems and the
default mode network. The use of a sliding window technique allowed us to
assess how functional connectivity varies over time, further elucidating the
transient nature of brain connectivity. Additionally, our findings align with
previous literature, reinforcing the notion that cognitive states can be
effectively identified through short-duration data, specifically within the
30-60 second timeframe. The established relationships between connectivity
strength and cognitive processes, particularly during different visual states,
underscore the relevance of our approach for future research into brain
dynamics. Overall, this study not only enhances our understanding of the
interplay between EEG and fMRI signals but also paves the way for further
exploration into the neural correlates of cognitive functions and their
implications in clinical settings. Future research should focus on refining
these methodologies and exploring their applications in various cognitive and
clinical contexts.

摘要：本研究調查了腦電圖和功能性磁振造影之間的動態連接模式，有助於我們了解腦網路互動。透過採用整合靜態和動態腦電圖功能性磁振造影資料分析的綜合方法，我們得以揭示不同的連接狀態並描述其時間波動。結果顯示腦部內在連接網路 (ICN) 中的模組化組織，突顯了感官系統和預設模式網路的重要角色。滑動視窗技術的使用讓我們得以評估功能性連接如何隨時間變化，進一步闡明腦部連接的暫時性。此外，我們的研究結果與先前的文獻一致，強化了透過短時資料（特別是在 30-60 秒的時間範圍內）可以有效識別認知狀態的概念。連接強度和認知過程之間建立的關係，特別是在不同的視覺狀態下，強調了我們的途徑與未來腦部動態研究相關性。整體而言，本研究不僅增強了我們對腦電圖和功能性磁振造影訊號之間交互作用的理解，也為進一步探索認知功能的神經相關性及其在臨床環境中的意義鋪路。未來的研究應專注於優化這些方法並探討其在各種認知和臨床背景中的應用。

##### **Graph Neural Networks for Heart Failure Prediction on an EHR-Based Patient Similarity Graph**
2411.19742v1 by Heloisa Oss Boll, Ali Amirahmadi, Amira Soliman, Stefan Byttner, Mariana Recamonde-Mendoza

Objective: In modern healthcare, accurately predicting diseases is a crucial
matter. This study introduces a novel approach using graph neural networks
(GNNs) and a Graph Transformer (GT) to predict the incidence of heart failure
(HF) on a patient similarity graph at the next hospital visit. Materials and
Methods: We used electronic health records (EHR) from the MIMIC-III dataset and
applied the K-Nearest Neighbors (KNN) algorithm to create a patient similarity
graph using embeddings from diagnoses, procedures, and medications. Three
models - GraphSAGE, Graph Attention Network (GAT), and Graph Transformer (GT) -
were implemented to predict HF incidence. Model performance was evaluated using
F1 score, AUROC, and AUPRC metrics, and results were compared against baseline
algorithms. An interpretability analysis was performed to understand the
model's decision-making process. Results: The GT model demonstrated the best
performance (F1 score: 0.5361, AUROC: 0.7925, AUPRC: 0.5168). Although the
Random Forest (RF) baseline achieved a similar AUPRC value, the GT model
offered enhanced interpretability due to the use of patient relationships in
the graph structure. A joint analysis of attention weights, graph connectivity,
and clinical features provided insight into model predictions across different
classification groups. Discussion and Conclusion: Graph-based approaches such
as GNNs provide an effective framework for predicting HF. By leveraging a
patient similarity graph, GNNs can capture complex relationships in EHR data,
potentially improving prediction accuracy and clinical interpretability.

摘要：<paragraph>目標：在現代醫療保健中，準確預測疾病是一項至關重要的問題。本研究介紹了一種使用圖神經網絡 (GNN) 和圖形轉換器 (GT) 的新方法，用於預測下次醫院就診時患者相似圖表上的心臟衰竭 (HF) 發生率。材料和方法：我們使用了 MIMIC-III 資料集中的電子健康記錄 (EHR)，並應用 K-最近鄰 (KNN) 演算法，使用來自診斷、程序和藥物的嵌入來建立患者相似圖表。實作了三個模型 - GraphSAGE、圖形注意力網路 (GAT) 和圖形轉換器 (GT) - 來預測 HF 發生率。使用 F1 分數、AUROC 和 AUPRC 指標評估模型效能，並將結果與基準演算法進行比較。執行了解釋性分析以了解模型的決策過程。結果：GT 模型表現出最佳效能 (F1 分數：0.5361，AUROC：0.7925，AUPRC：0.5168)。儘管隨機森林 (RF) 基準達到了類似的 AUPRC 值，但由於在圖形結構中使用了患者關係，因此 GT 模型提供了增強的解釋性。對注意力權重、圖形連通性和臨床特徵的聯合分析提供了對不同分類群組中模型預測的見解。討論和結論：基於圖形的方法（例如 GNN）提供了預測 HF 的有效框架。透過利用患者相似圖形，GNN 可以擷取 EHR 資料中的複雜關係，進而可能提高預測準確度和臨床解釋性。</paragraph>

##### **Multimodal Whole Slide Foundation Model for Pathology**
2411.19666v1 by Tong Ding, Sophia J. Wagner, Andrew H. Song, Richard J. Chen, Ming Y. Lu, Andrew Zhang, Anurag J. Vaidya, Guillaume Jaume, Muhammad Shaban, Ahrong Kim, Drew F. K. Williamson, Bowen Chen, Cristina Almagro-Perez, Paul Doucet, Sharifa Sahai, Chengkuan Chen, Daisuke Komura, Akihiro Kawabe, Shumpei Ishikawa, Georg Gerber, Tingying Peng, Long Phi Le, Faisal Mahmood

The field of computational pathology has been transformed with recent
advances in foundation models that encode histopathology region-of-interests
(ROIs) into versatile and transferable feature representations via
self-supervised learning (SSL). However, translating these advancements to
address complex clinical challenges at the patient and slide level remains
constrained by limited clinical data in disease-specific cohorts, especially
for rare clinical conditions. We propose TITAN, a multimodal whole slide
foundation model pretrained using 335,645 WSIs via visual self-supervised
learning and vision-language alignment with corresponding pathology reports and
423,122 synthetic captions generated from a multimodal generative AI copilot
for pathology. Without any finetuning or requiring clinical labels, TITAN can
extract general-purpose slide representations and generate pathology reports
that generalize to resource-limited clinical scenarios such as rare disease
retrieval and cancer prognosis. We evaluate TITAN on diverse clinical tasks and
find that TITAN outperforms both ROI and slide foundation models across machine
learning settings such as linear probing, few-shot and zero-shot
classification, rare cancer retrieval and cross-modal retrieval, and pathology
report generation.

摘要：計算病理學領域已因基礎模型的最新進展而轉型，這些模型透過自監督學習 (SSL) 將組織病理學感興趣區域 (ROI) 編碼成多功能且可轉移的特徵表示。然而，要解決患者和切片層面的複雜臨床挑戰，將這些進展轉化為解決方案仍受限於特定疾病群體中有限的臨床資料，尤其是罕見的臨床情況。我們提出 TITAN，這是一個多模態全切片基礎模型，使用 335,645 個 WSI 透過視覺自監督學習和與對應病理報告的視覺語言對齊，以及由多模態生成式 AI 輔助員為病理學生成的 423,122 個合成標題進行預訓練。在沒有任何微調或需要臨床標籤的情況下，TITAN 可以提取通用切片表示，並生成病理報告，以概括到資源有限的臨床場景，例如罕見疾病檢索和癌症預後。我們在不同的臨床任務上評估 TITAN，發現 TITAN 在機器學習設定中優於 ROI 和切片基礎模型，例如線性探查、少次學習和零次學習分類、罕見癌症檢索和跨模態檢索，以及病理報告生成。

##### **SkelMamba: A State Space Model for Efficient Skeleton Action Recognition of Neurological Disorders**
2411.19544v1 by Niki Martinel, Mariano Serrao, Christian Micheloni

We introduce a novel state-space model (SSM)-based framework for
skeleton-based human action recognition, with an anatomically-guided
architecture that improves state-of-the-art performance in both clinical
diagnostics and general action recognition tasks. Our approach decomposes
skeletal motion analysis into spatial, temporal, and spatio-temporal streams,
using channel partitioning to capture distinct movement characteristics
efficiently. By implementing a structured, multi-directional scanning strategy
within SSMs, our model captures local joint interactions and global motion
patterns across multiple anatomical body parts. This anatomically-aware
decomposition enhances the ability to identify subtle motion patterns critical
in medical diagnosis, such as gait anomalies associated with neurological
conditions. On public action recognition benchmarks, i.e., NTU RGB+D, NTU RGB+D
120, and NW-UCLA, our model outperforms current state-of-the-art methods,
achieving accuracy improvements up to $3.2\%$ with lower computational
complexity than previous leading transformer-based models. We also introduce a
novel medical dataset for motion-based patient neurological disorder analysis
to validate our method's potential in automated disease diagnosis.

摘要：<paragraph>我們提出一個新穎的基於狀態空間模型 (SSM) 的框架，用於基於骨架的人類動作識別，它具有解剖學指導架構，可改善臨床診斷和一般動作識別任務的最新技術性能。我們的做法將骨骼運動分析分解為空間、時間和時空流，使用通道分割來有效捕捉不同的運動特徵。通過在 SSM 中實施結構化、多向掃描策略，我們的模型捕捉到多個解剖身體部位的局部關節交互和整體運動模式。這種解剖學感知分解增強了識別微妙運動模式的能力，這些模式在醫學診斷中至關重要，例如與神經系統疾病相關的步態異常。在公共動作識別基準上，即 NTU RGB+D、NTU RGB+D 120 和 NW-UCLA，我們的模型優於當前最先進的方法，與以前領先的基於Transformer的模型相比，在較低的計算複雜度下實現了高達 3.2% 的準確度改進。我們還引入了一個新的醫學數據集，用於基於運動的患者神經系統疾病分析，以驗證我們的方法在自動疾病診斷中的潛力。</paragraph>

##### **Knowledge-Data Fusion Based Source-Free Semi-Supervised Domain Adaptation for Seizure Subtype Classification**
2411.19502v1 by Ruimin Peng, Jiayu An, Dongrui Wu

Electroencephalogram (EEG)-based seizure subtype classification enhances
clinical diagnosis efficiency. Source-free semi-supervised domain adaptation
(SF-SSDA), which transfers a pre-trained model to a new dataset with no source
data and limited labeled target data, can be used for privacy-preserving
seizure subtype classification. This paper considers two challenges in SF-SSDA
for EEG-based seizure subtype classification: 1) How to effectively fuse both
raw EEG data and expert knowledge in classifier design? 2) How to align the
source and target domain distributions for SF-SSDA? We propose a Knowledge-Data
Fusion based SF-SSDA approach, KDF-MutualSHOT, for EEG-based seizure subtype
classification. In source model training, KDF uses Jensen-Shannon Divergence to
facilitate mutual learning between a feature-driven Decision Tree-based model
and a data-driven Transformer-based model. To adapt KDF to a new target
dataset, an SF-SSDA algorithm, MutualSHOT, is developed, which features a
consistency-based pseudo-label selection strategy. Experiments on the public
TUSZ and CHSZ datasets demonstrated that KDF-MutualSHOT outperformed other
supervised and source-free domain adaptation approaches in cross-subject
seizure subtype classification.

摘要：基於腦電圖 (EEG) 的癲癇亞型分類可提升臨床診斷效率。無來源半監督領域適應 (SF-SSDA) 可將預先訓練的模型轉移至沒有來源資料且標籤目標資料有限的新資料集，可用於隱私保護的癲癇亞型分類。本文探討 SF-SSDA 在基於 EEG 的癲癇亞型分類中的兩個挑戰：1) 如何有效融合原始 EEG 資料和分類器設計中的專家知識？2) 如何調整 SF-SSDA 的來源和目標網域分佈？我們提出一個基於知識資料融合的 SF-SSDA 方法，KDF-MutualSHOT，用於基於 EEG 的癲癇亞型分類。在來源模型訓練中，KDF 使用 Jensen-Shannon 距離促進特徵驅動的決策樹模型和資料驅動的 Transformer 模型之間的相互學習。為了將 KDF 調整至新的目標資料集，開發了一個 SF-SSDA 演算法，MutualSHOT，其特點是基於一致性的偽標籤選擇策略。在公開的 TUSZ 和 CHSZ 資料集上的實驗表明，KDF-MutualSHOT 在跨受試者癲癇亞型分類中優於其他監督式和無來源領域適應方法。

##### **Adaptive Interactive Segmentation for Multimodal Medical Imaging via Selection Engine**
2411.19447v1 by Zhi Li, Kai Zhao, Yaqi Wang, Shuai Wang

In medical image analysis, achieving fast, efficient, and accurate
segmentation is essential for automated diagnosis and treatment. Although
recent advancements in deep learning have significantly improved segmentation
accuracy, current models often face challenges in adaptability and
generalization, particularly when processing multi-modal medical imaging data.
These limitations stem from the substantial variations between imaging
modalities and the inherent complexity of medical data. To address these
challenges, we propose the Strategy-driven Interactive Segmentation Model
(SISeg), built on SAM2, which enhances segmentation performance across various
medical imaging modalities by integrating a selection engine. To mitigate
memory bottlenecks and optimize prompt frame selection during the inference of
2D image sequences, we developed an automated system, the Adaptive Frame
Selection Engine (AFSE). This system dynamically selects the optimal prompt
frames without requiring extensive prior medical knowledge and enhances the
interpretability of the model's inference process through an interactive
feedback mechanism. We conducted extensive experiments on 10 datasets covering
7 representative medical imaging modalities, demonstrating the SISeg model's
robust adaptability and generalization in multi-modal tasks. The project page
and code will be available at: [URL].

摘要：在医学影像分析中，实现快速、高效和准确的分割对于自动化诊断和治疗至关重要。尽管深度学习的最新进展显著提高了分割准确性，但当前模型在适应性和泛化性方面常常面临挑战，尤其是在处理多模态医学影像数据时。这些限制源于影像方式之间的巨大差异和医学数据的固有复杂性。为了应对这些挑战，我们提出了基于 SAM2 的策略驱动交互式分割模型 (SISeg)，它通过集成选择引擎来增强各种医学影像方式的分割性能。为了缓解内存瓶颈并优化 2D 图像序列推理期间的提示帧选择，我们开发了一个自动化系统，即自适应帧选择引擎 (AFSE)。该系统在无需广泛的先前医学知识的情况下动态选择最佳提示帧，并通过交互式反馈机制增强模型推理过程的可解释性。我们在涵盖 7 种代表性医学影像方式的 10 个数据集上进行了广泛的实验，展示了 SISeg 模型在多模态任务中的鲁棒适应性和泛化性。项目页面和代码将提供在：[URL]。

##### **Libra: Leveraging Temporal Images for Biomedical Radiology Analysis**
2411.19378v1 by Xi Zhang, Zaiqiao Meng, Jake Lever, Edmond S. L. Ho

Radiology report generation (RRG) is a challenging task, as it requires a
thorough understanding of medical images, integration of multiple temporal
inputs, and accurate report generation. Effective interpretation of medical
images, such as chest X-rays (CXRs), demands sophisticated visual-language
reasoning to map visual findings to structured reports. Recent studies have
shown that multimodal large language models (MLLMs) can acquire multimodal
capabilities by aligning with pre-trained vision encoders. However, current
approaches predominantly focus on single-image analysis or utilise rule-based
symbolic processing to handle multiple images, thereby overlooking the
essential temporal information derived from comparing current images with prior
ones. To overcome this critical limitation, we introduce Libra, a
temporal-aware MLLM tailored for CXR report generation using temporal images.
Libra integrates a radiology-specific image encoder with a MLLM and utilises a
novel Temporal Alignment Connector to capture and synthesise temporal
information of images across different time points with unprecedented
precision. Extensive experiments show that Libra achieves new state-of-the-art
performance among the same parameter scale MLLMs for RRG tasks on the
MIMIC-CXR. Specifically, Libra improves the RadCliQ metric by 12.9% and makes
substantial gains across all lexical metrics compared to previous models.

摘要：放射學報告生成 (RRG) 是一項具有挑戰性的任務，因為它需要透徹了解醫學影像、整合多個時間輸入以及準確的報告生成。有效解讀醫學影像，例如胸部 X 光 (CXR)，需要複雜的視覺語言推理才能將視覺發現對應到結構化的報告中。最近的研究表明，多模態大型語言模型 (MLLM) 可以透過與預先訓練的視覺編碼器對齊來獲得多模態能力。然而，目前的方法主要專注於單一影像分析或利用基於規則的符號處理來處理多個影像，從而忽略了從比較當前影像與先前影像中得出的基本時間資訊。為了克服這個關鍵限制，我們引入了 Libra，一個專為使用時間影像進行 CXR 報告生成的時態感知 MLLM。Libra 將放射學專用影像編碼器與 MLLM 整合在一起，並利用一個新穎的時間對齊連接器來擷取和合成不同時間點影像的時間資訊，並具有前所未有的精確度。廣泛的實驗表明，Libra 在 MIMIC-CXR 的 RRG 任務中，在同參數規模的 MLLM 中取得了新的最先進效能。具體來說，Libra 將 RadCliQ 指標提升了 12.9%，並在所有詞彙指標方面都比以前的模型取得了顯著進步。

##### **Mapping Public Perception of Artificial Intelligence: Expectations, Risk-Benefit Tradeoffs, and Value As Determinants for Societal Acceptance**
2411.19356v1 by Philipp Brauner, Felix Glawe, Gian Luca Liehner, Luisa Vervier, Martina Ziefle

Understanding public perception of artificial intelligence (AI) and the
tradeoffs between potential risks and benefits is crucial, as these perceptions
might shape policy decisions, influence innovation trajectories for successful
market strategies, and determine individual and societal acceptance of AI
technologies. Using a representative sample of 1100 participants from Germany,
this study examines mental models of AI. Participants quantitatively evaluated
71 statements about AI's future capabilities (e.g., autonomous driving, medical
care, art, politics, warfare, and societal divides), assessing the expected
likelihood of occurrence, perceived risks, benefits, and overall value. We
present rankings of these projections alongside visual mappings illustrating
public risk-benefit tradeoffs. While many scenarios were deemed likely,
participants often associated them with high risks, limited benefits, and low
overall value. Across all scenarios, 96.4% ($r^2=96.4\%$) of the variance in
value assessment can be explained by perceived risks ($\beta=-.504$) and
perceived benefits ($\beta=+.710$), with no significant relation to expected
likelihood. Demographics and personality traits influenced perceptions of
risks, benefits, and overall evaluations, underscoring the importance of
increasing AI literacy and tailoring public information to diverse user needs.
These findings provide actionable insights for researchers, developers, and
policymakers by highlighting critical public concerns and individual factors
essential to align AI development with individual values.

摘要：<paragraph>了解公眾對人工智慧 (AI) 的認知以及潛在風險與好處之間的權衡至關重要，因為這些認知可能會影響政策決策、影響成功市場策略的創新軌跡，並決定個人和社會對 AI 技術的接受度。本研究使用來自德國的 1100 名參與者的代表性樣本，探討了 AI 的心智模型。參與者對 71 項關於 AI 未來能力的陳述（例如，自動駕駛、醫療保健、藝術、政治、戰爭和社會分歧）進行了定量評估，評估預期的發生可能性、感知風險、好處和整體價值。我們展示了這些預測的排名，並附上視覺化映射，說明了公眾的風險收益權衡。儘管許多場景被認為是可能的，但參與者通常將它們與高風險、有限的好處和低整體價值聯繫起來。在所有場景中，96.4% ($r^2=96.4\%$) 的價值評估差異可以用感知風險 ($\beta=-.504$) 和感知好處 ($\beta=+.710$) 來解釋，與預期的可能性沒有顯著關係。人口統計和人格特質影響了對風險、好處和整體評估的看法，這凸顯了提高 AI 素養和根據不同的使用者需求調整公共資訊的重要性。這些發現通過強調關鍵的公共關注和與個人價值觀一致的 AI 開發必不可少的個人因素，為研究人員、開發人員和政策制定者提供了可行的見解。</paragraph>

##### **FonTS: Text Rendering with Typography and Style Controls**
2412.00136v1 by Wenda Shi, Yiren Song, Dengming Zhang, Jiaming Liu, Xingxing Zou

Visual text images are prevalent in various applications, requiring careful
font selection and typographic choices. Recent advances in Diffusion
Transformer (DiT)-based text-to-image (T2I) models show promise in automating
these processes. However, these methods still face challenges such as
inconsistent fonts, style variation, and limited fine-grained control,
particularly at the word level. This paper proposes a two-stage DiT-based
pipeline to address these issues by enhancing controllability over typography
and style in text rendering. We introduce Typography Control (TC) finetuning,
an efficient parameter fine-tuning method, and enclosing typography control
tokens (ETC-tokens), which enable precise word-level application of typographic
features. To further enhance style control, we present a Style Control Adapter
(SCA) that injects style information through image inputs independent of text
prompts. Through comprehensive experiments, we demonstrate the effectiveness of
our approach in achieving superior word-level typographic control, font
consistency, and style consistency in Basic and Artistic Text Rendering (BTR
and ATR) tasks. Our results mark a significant advancement in the precision and
adaptability of T2I models, presenting new possibilities for creative
applications and design-oriented tasks.

摘要：視覺文字圖像在各種應用中很普遍，需要仔細選擇字體和排版選項。最近在基於擴散轉換器 (DiT) 的文字轉圖像 (T2I) 模型的進展顯示出自動化這些程序的潛力。然而，這些方法仍然面臨諸如字體不一致、樣式變化和有限的細粒度控制等挑戰，特別是在文字層級。本文提出了一個基於 DiT 的兩階段管道來解決這些問題，方法是增強對文字渲染中的排版和樣式的可控性。我們引入了排版控制 (TC) 微調，一種高效的參數微調方法，以及封裝排版控制代幣 (ETC 代幣)，它能精確地應用字體功能在文字層級。為了進一步增強樣式控制，我們提出了一個樣式控制適配器 (SCA)，它通過圖像輸入注入樣式資訊，而與文字提示無關。透過全面的實驗，我們證明了我們的方法在實現優異的文字層級排版控制、字體一致性和基本和藝術文字渲染 (BTR 和 ATR) 任務中的樣式一致性方面的有效性。我們的結果標誌著 T2I 模型的精確度和適應性的重大進展，為創意應用和設計導向任務提供了新的可能性。

##### **Pre-Training Graph Contrastive Masked Autoencoders are Strong Distillers for EEG**
2411.19230v1 by Xinxu Wei, Kanhao Zhao, Yong Jiao, Nancy B. Carlisle, Hua Xie, Yu Zhang

Effectively utilizing extensive unlabeled high-density EEG data to improve
performance in scenarios with limited labeled low-density EEG data presents a
significant challenge. In this paper, we address this by framing it as a graph
transfer learning and knowledge distillation problem. We propose a Unified
Pre-trained Graph Contrastive Masked Autoencoder Distiller, named EEG-DisGCMAE,
to bridge the gap between unlabeled/labeled and high/low-density EEG data. To
fully leverage the abundant unlabeled EEG data, we introduce a novel unified
graph self-supervised pre-training paradigm, which seamlessly integrates Graph
Contrastive Pre-training and Graph Masked Autoencoder Pre-training. This
approach synergistically combines contrastive and generative pre-training
techniques by reconstructing contrastive samples and contrasting the
reconstructions. For knowledge distillation from high-density to low-density
EEG data, we propose a Graph Topology Distillation loss function, allowing a
lightweight student model trained on low-density data to learn from a teacher
model trained on high-density data, effectively handling missing electrodes
through contrastive distillation. To integrate transfer learning and
distillation, we jointly pre-train the teacher and student models by
contrasting their queries and keys during pre-training, enabling robust
distillers for downstream tasks. We demonstrate the effectiveness of our method
on four classification tasks across two clinical EEG datasets with abundant
unlabeled data and limited labeled data. The experimental results show that our
approach significantly outperforms contemporary methods in both efficiency and
accuracy.

摘要：<paragraph>有效利用大量未標籤的高密度腦電圖資料，以改善標籤資料有限的低密度腦電圖資料情境中的效能，是一項重大的挑戰。在本文中，我們將其視為圖形傳輸學習與知識萃取問題來探討。我們提出一個統一的預訓練圖形對比遮罩自動編碼器萃取器，稱為 EEG-DisGCMAE，以彌合未標籤/標籤和高/低密度腦電圖資料之間的差距。為了充分利用大量的未標籤腦電圖資料，我們引入了一個新穎的統一圖形自我監督預訓練範例，它無縫整合了圖形對比預訓練和圖形遮罩自動編碼器預訓練。此方法透過重建對比樣本和對比重建結果，協同結合了對比和生成預訓練技術。對於從高密度到低密度腦電圖資料的知識萃取，我們提出了一個圖形拓撲萃取損失函數，允許在低密度資料上訓練的輕量級學生模型從在高密度資料上訓練的老師模型中學習，透過對比萃取有效處理遺失的電極。為了整合傳輸學習和萃取，我們透過在預訓練期間對比它們的查詢和金鑰，共同預訓練老師和學生模型，為下游任務啟用穩健的萃取器。我們在兩個臨床腦電圖資料集上展示了我們的方法在四個分類任務中的有效性，這些資料集具有大量的未標籤資料和有限的標籤資料。實驗結果表明，我們的做法在效率和準確性方面都顯著優於當代方法。</paragraph>

##### **Open-Sora Plan: Open-Source Large Video Generation Model**
2412.00131v1 by Bin Lin, Yunyang Ge, Xinhua Cheng, Zongjian Li, Bin Zhu, Shaodong Wang, Xianyi He, Yang Ye, Shenghai Yuan, Liuhan Chen, Tanghui Jia, Junwu Zhang, Zhenyu Tang, Yatian Pang, Bin She, Cen Yan, Zhiheng Hu, Xiaoyi Dong, Lin Chen, Zhang Pan, Xing Zhou, Shaoling Dong, Yonghong Tian, Li Yuan

We introduce Open-Sora Plan, an open-source project that aims to contribute a
large generation model for generating desired high-resolution videos with long
durations based on various user inputs. Our project comprises multiple
components for the entire video generation process, including a Wavelet-Flow
Variational Autoencoder, a Joint Image-Video Skiparse Denoiser, and various
condition controllers. Moreover, many assistant strategies for efficient
training and inference are designed, and a multi-dimensional data curation
pipeline is proposed for obtaining desired high-quality data. Benefiting from
efficient thoughts, our Open-Sora Plan achieves impressive video generation
results in both qualitative and quantitative evaluations. We hope our careful
design and practical experience can inspire the video generation research
community. All our codes and model weights are publicly available at
\url{https://github.com/PKU-YuanGroup/Open-Sora-Plan}.

摘要：我們推出 Open-Sora Plan，這是一個開放原始碼專案，旨在為根據各種使用者輸入來產生所需的高解析度影片提供一個大型生成模型，並具備長時間的持續時間。我們的專案包含了整個影片生成處理流程的多個組成部分，包括小波流變分自動編碼器、聯合影像影片 Skiparse 去雜訊器，以及各種條件控制器。此外，還設計了許多用於高效訓練與推論的輔助策略，並提出了一個多維資料策展管道，用於取得所需的高品質資料。受益於高效的想法，我們的 Open-Sora Plan 在定性和定量評估中都達到了令人印象深刻的影片生成結果。我們希望我們仔細的設計和實務經驗可以激勵影片生成研究社群。我們所有的程式碼和模型權重都公開在 \url{https://github.com/PKU-YuanGroup/Open-Sora-Plan}。

##### **A Unified Platform for At-Home Post-Stroke Rehabilitation Enabled by Wearable Technologies and Artificial Intelligence**
2411.19000v1 by Chenyu Tang, Ruizhi Zhang, Shuo Gao, Zihe Zhao, Zibo Zhang, Jiaqi Wang, Cong Li, Junliang Chen, Yanning Dai, Shengbo Wang, Ruoyu Juan, Qiaoying Li, Ruimou Xie, Xuhang Chen, Xinkai Zhou, Yunjia Xia, Jianan Chen, Fanghao Lu, Xin Li, Ninglli Wang, Peter Smielewski, Yu Pan, Hubin Zhao, Luigi G. Occhipinti

At-home rehabilitation for post-stroke patients presents significant
challenges, as continuous, personalized care is often limited outside clinical
settings. Additionally, the absence of comprehensive solutions addressing
diverse rehabilitation needs in home environments complicates recovery efforts.
Here, we introduce a smart home platform that integrates wearable sensors,
ambient monitoring, and large language model (LLM)-powered assistance to
provide seamless health monitoring and intelligent support. The system
leverages machine learning enabled plantar pressure arrays for motor recovery
assessment (94% classification accuracy), a wearable eye-tracking module for
cognitive evaluation, and ambient sensors for precise smart home control (100%
operational success, <1 s latency). Additionally, the LLM-powered agent,
Auto-Care, offers real-time interventions, such as health reminders and
environmental adjustments, enhancing user satisfaction by 29%. This work
establishes a fully integrated platform for long-term, personalized
rehabilitation, offering new possibilities for managing chronic conditions and
supporting aging populations.

摘要：居家復健對於中風患者來說是一大挑戰，因為持續且個人化的照護通常在臨床環境之外受到限制。此外，缺乏解決居家環境中多元復健需求的全面性解決方案，讓復原工作更形複雜。在此，我們介紹一個整合穿戴式感測器、環境監控和大型語言模型 (LLM) 驅動協助的智慧居家平台，提供無縫的健康監控和智慧支援。此系統利用機器學習啟用的足底壓力陣列進行運動復原評估 (94% 分類準確度)、穿戴式眼球追蹤模組進行認知評估，以及環境感測器進行精準的智慧居家控制 (100% 操作成功，<1 秒延遲)。此外，LLM 驅動的代理程式 Auto-Care 提供即時介入措施，例如健康提醒和環境調整，將使用者滿意度提升 29%。這項工作建立了一個長期、個人化的復健全整合平台，為管理慢性疾病和支持高齡人口提供了新的可能性。

##### **Devising a Set of Compact and Explainable Spoken Language Feature for Screening Alzheimer's Disease**
2411.18922v1 by Junan Li, Yunxiang Li, Yuren Wang, Xixin Wu, Helen Meng

Alzheimer's disease (AD) has become one of the most significant health
challenges in an aging society. The use of spoken language-based AD detection
methods has gained prevalence due to their scalability due to their
scalability. Based on the Cookie Theft picture description task, we devised an
explainable and effective feature set that leverages the visual capabilities of
a large language model (LLM) and the Term Frequency-Inverse Document Frequency
(TF-IDF) model. Our experimental results show that the newly proposed features
consistently outperform traditional linguistic features across two different
classifiers with high dimension efficiency. Our new features can be well
explained and interpreted step by step which enhance the interpretability of
automatic AD screening.

摘要：阿茲海默症 (AD) 已成為高齡化社會中最重要的健康挑戰之一。基於其可擴充性，使用基於口語的 AD 檢測方法已獲得普遍使用。根據 Cookie Theft 圖片描述任務，我們設計了一個可解釋且有效的特徵集，它利用大型語言模型 (LLM) 的視覺功能和詞頻-逆向文件頻率 (TF-IDF) 模型。我們的實驗結果表明，新提出的特徵在兩個不同分類器中始終優於傳統語言特徵，且具有高維度效率。我們的特徵可以很好地解釋和逐步詮釋，這增強了自動 AD 篩檢的可解釋性。

##### **LLM-ABBA: Understanding time series via symbolic approximation**
2411.18506v2 by Erin Carson, Xinye Chen, Cheng Kang

The success of large language models (LLMs) for time series has been
demonstrated in previous work. Utilizing a symbolic time series representation,
one can efficiently bridge the gap between LLMs and time series. However, the
remaining challenge is to exploit the semantic information hidden in time
series by using symbols or existing tokens of LLMs, while aligning the
embedding space of LLMs according to the hidden information of time series. The
symbolic time series approximation (STSA) method called adaptive Brownian
bridge-based symbolic aggregation (ABBA) shows outstanding efficacy in
preserving salient time series features by modeling time series patterns in
terms of amplitude and period while using existing tokens of LLMs.
  In this paper, we introduce a method, called LLM-ABBA, that integrates ABBA
into large language models for various downstream time series tasks. By
symbolizing time series, LLM-ABBA compares favorably to the recent
state-of-the-art (SOTA) in UCR and three medical time series classification
tasks. Meanwhile, a fixed-polygonal chain trick in ABBA is introduced to
\kc{avoid obvious drifting} during prediction tasks by significantly mitigating
the effects of cumulative error arising from misused symbols during the
transition from symbols to numerical values. In time series regression tasks,
LLM-ABBA achieves the new SOTA on Time Series Extrinsic Regression (TSER)
benchmarks. LLM-ABBA also shows competitive prediction capability compared to
recent SOTA time series prediction results. We believe this framework can also
seamlessly extend to other time series tasks.

摘要：大型語言模型 (LLM) 在時間序列方面的成功已在先前的研究中得到證明。利用符號時間序列表示法，可以有效地縮小 LLM 和時間序列之間的差距。然而，剩下的挑戰是利用符號或 LLM 的現有標記來利用隱藏在時間序列中的語義資訊，同時根據時間序列的隱藏資訊調整 LLM 的嵌入空間。稱為自適應布朗橋符號聚合 (ABBA) 的符號時間序列近似 (STSA) 方法在通過振幅和週期對時間序列模式進行建模，同時使用 LLM 的現有標記，在保留顯著時間序列特徵方面表現出傑出的功效。
在本文中，我們介紹一種稱為 LLM-ABBA 的方法，它將 ABBA 整合到大型語言模型中，以用於各種下游時間序列任務。通過符號化時間序列，LLM-ABBA 與 UCR 和三個醫學時間序列分類任務中的最新技術 (SOTA) 相比更具優勢。同時，在 ABBA 中引入了一個固定多邊形鏈技巧，通過顯著減輕從符號過渡到數值時誤用符號產生的累積誤差的影響，來避免在預測任務期間出現明顯的漂移。在時間序列迴歸任務中，LLM-ABBA 在時間序列外在迴歸 (TSER) 基準上實現了新的 SOTA。與最近的 SOTA 時間序列預測結果相比，LLM-ABBA 也表現出競爭力的預測能力。我們相信這個框架也可以無縫地擴展到其他時間序列任務。

##### **MvKeTR: Chest CT Report Generation with Multi-View Perception and Knowledge Enhancement**
2411.18309v1 by Xiwei Deng, Xianchun He, Yudan Zhou, Shuhui Cai, Congbo Cai, Zhong Chen

CT report generation (CTRG) aims to automatically generate diagnostic reports
for 3D volumes, relieving clinicians' workload and improving patient care.
Despite clinical value, existing works fail to effectively incorporate
diagnostic information from multiple anatomical views and lack related clinical
expertise essential for accurate and reliable diagnosis. To resolve these
limitations, we propose a novel Multi-view perception Knowledge-enhanced
Tansformer (MvKeTR) to mimic the diagnostic workflow of clinicians. Just as
radiologists first examine CT scans from multiple planes, a Multi-View
Perception Aggregator (MVPA) with view-aware attention effectively synthesizes
diagnostic information from multiple anatomical views. Then, inspired by how
radiologists further refer to relevant clinical records to guide diagnostic
decision-making, a Cross-Modal Knowledge Enhancer (CMKE) retrieves the most
similar reports based on the query volume to incorporate domain knowledge into
the diagnosis procedure. Furthermore, instead of traditional MLPs, we employ
Kolmogorov-Arnold Networks (KANs) with learnable nonlinear activation functions
as the fundamental building blocks of both modules to better capture intricate
diagnostic patterns in CT interpretation. Extensive experiments on the public
CTRG-Chest-548K dataset demonstrate that our method outpaces prior
state-of-the-art models across all metrics.

摘要：電腦斷層報告生成（CTRG）旨在自動生成 3D 體積的診斷報告，減輕臨床醫師的工作量並改善患者照護。
儘管具有臨床價值，現有研究無法有效整合來自多個解剖視圖的診斷資訊，並且缺乏準確且可靠診斷所必需的相關臨床專業知識。為了解決這些限制，我們提出了一種新穎的多視覺感知知識增強轉換器 (MvKeTR) 來模擬臨床醫師的診斷工作流程。正如放射科醫師首先從多個平面檢查電腦斷層掃描，具有視圖感知注意力的多視覺感知聚合器 (MVPA) 有效地綜合了來自多個解剖視圖的診斷資訊。接著，受到放射科醫師如何進一步參考相關臨床記錄來指導診斷決策的啟發，跨模態知識增強器 (CMKE) 基於查詢體積擷取最相似的報告，以將領域知識納入診斷程序。此外，我們採用具有可學習非線性啟用函數的 Kolmogorov-Arnold 網路 (KAN) 作為兩個模組的基本建構模組，而不是傳統的多層感知器，以在電腦斷層詮釋中更好地擷取複雜的診斷模式。在公共 CTRG-Chest-548K 資料集上的廣泛實驗證明，我們的模型在所有指標上都超越了先前的最先進模型。

##### **Wearable intelligent throat enables natural speech in stroke patients with dysarthria**
2411.18266v2 by Chenyu Tang, Shuo Gao, Cong Li, Wentian Yi, Yuxuan Jin, Xiaoxue Zhai, Sixuan Lei, Hongbei Meng, Zibo Zhang, Muzi Xu, Shengbo Wang, Xuhang Chen, Chenxi Wang, Hongyun Yang, Ningli Wang, Wenyu Wang, Jin Cao, Xiaodong Feng, Peter Smielewski, Yu Pan, Wenhui Song, Martin Birchall, Luigi G. Occhipinti

Wearable silent speech systems hold significant potential for restoring
communication in patients with speech impairments. However, seamless, coherent
speech remains elusive, and clinical efficacy is still unproven. Here, we
present an AI-driven intelligent throat (IT) system that integrates throat
muscle vibrations and carotid pulse signal sensors with large language model
(LLM) processing to enable fluent, emotionally expressive communication. The
system utilizes ultrasensitive textile strain sensors to capture high-quality
signals from the neck area and supports token-level processing for real-time,
continuous speech decoding, enabling seamless, delay-free communication. In
tests with five stroke patients with dysarthria, IT's LLM agents intelligently
corrected token errors and enriched sentence-level emotional and logical
coherence, achieving low error rates (4.2% word error rate, 2.9% sentence error
rate) and a 55% increase in user satisfaction. This work establishes a
portable, intuitive communication platform for patients with dysarthria with
the potential to be applied broadly across different neurological conditions
and in multi-language support systems.

摘要：可穿戴式无声语音系统在恢复言语障碍患者的沟通能力方面具有重大潜力。然而，无缝、连贯的语音仍然难以实现，临床疗效仍未得到证实。在此，我们提出了一种人工智能驱动的智能喉咙 (IT) 系统，它将喉咙肌肉振动和颈动脉脉冲信号传感器与大语言模型 (LLM) 处理相结合，以实现流畅、富有情感表现力的沟通。该系统利用超灵敏纺织品应变传感器从颈部区域捕获高质量信号，并支持令牌级处理，以进行实时、连续的语音解码，从而实现无缝、无延迟的通信。在对五名患有构音障碍的中风患者进行的测试中，IT 的 LLM 代理智能地纠正了令牌错误，并丰富了句子级别的语义和逻辑连贯性，实现了较低的错误率（4.2% 的单词错误率，2.9% 的句子错误率）和 55% 的用户满意度提升。这项工作为构音障碍患者建立了一个便携、直观的沟通平台，有可能广泛应用于不同的神经系统疾病和多语言支持系统。

##### **Multimodal Integration of Longitudinal Noninvasive Diagnostics for Survival Prediction in Immunotherapy Using Deep Learning**
2411.18253v1 by Melda Yeghaian, Zuhir Bodalal, Daan van den Broek, John B A G Haanen, Regina G H Beets-Tan, Stefano Trebeschi, Marcel A J van Gerven

Purpose: Analyzing noninvasive longitudinal and multimodal data using
artificial intelligence could potentially transform immunotherapy for cancer
patients, paving the way towards precision medicine. Methods: In this study, we
integrated pre- and on-treatment blood measurements, prescribed medications and
CT-based volumes of organs from a large pan-cancer cohort of 694 patients
treated with immunotherapy to predict short and long-term overall survival. By
leveraging a combination of recent developments, different variants of our
extended multimodal transformer-based simple temporal attention (MMTSimTA)
network were trained end-to-end to predict mortality at three, six, nine and
twelve months. These models were also compared to baseline methods
incorporating intermediate and late fusion based integration methods. Results:
The strongest prognostic performance was demonstrated using the extended
transformer-based multimodal model with area under the curves (AUCs) of $0.84
\pm $0.04, $0.83 \pm $0.02, $0.82 \pm $0.02, $0.81 \pm $0.03 for 3-, 6-, 9-,
and 12-month survival prediction, respectively. Conclusion: Our findings
suggest that analyzing integrated early treatment data has potential for
predicting survival of immunotherapy patients. Integrating complementary
noninvasive modalities into a jointly trained model, using our extended
transformer-based architecture, demonstrated an improved multimodal prognostic
performance, especially in short term survival prediction.

摘要：<paragraph>目的：使用人工智能分析非侵入性纵向多模态数据可能会改变癌症患者的免疫治疗，为精准医疗铺平道路。方法：在这项研究中，我们整合了 694 名接受免疫治疗的癌症患者队列的治疗前和治疗中的血液测量值、处方药和基于 CT 的器官体积，以预测短期和长期总体生存率。通过利用最近发展的组合，我们扩展的多模态基于 Transformer 的简单时间注意力 (MMTSimTA) 网络的不同变体经过端到端训练，以预测三个、六个、九个和十二个月的死亡率。这些模型还与结合了基于中间融合和后期融合的集成方法的基线方法进行了比较。结果：使用扩展的基于 Transformer 的多模态模型展示了最强的预后表现，曲线下面积 (AUC) 分别为 3 个、6 个、9 个和 12 个月的生存预测为 0.84 ± 0.04、0.83 ± 0.02、0.82 ± 0.02、0.81 ± 0.03。结论：我们的研究结果表明，分析整合的早期治疗数据有可能预测免疫治疗患者的生存率。使用我们扩展的基于 Transformer 的架构，将互补的非侵入性方式整合到一个联合训练的模型中，展示了改进的多模态预后表现，尤其是在短期生存预测中。</paragraph>

##### **Randomized-Grid Search for Hyperparameter Tuning in Decision Tree Model to Improve Performance of Cardiovascular Disease Classification**
2411.18234v1 by Abhay Kumar Pathak, Mrityunjay Chaubey, Manjari Gupta

Cardiovascular disease refers to any critical condition that impacts the
heart. Because heart diseases can be life-threatening. Researchers are focusing
on designing smart systems to accurately diagnose them based on electronic
health data, with the aid of machine learning algorithms. Heart disease
classification using machine learning (ML) algorithms such as Support Vector
Machine(SVM), Na\"ive Bayes(NB), Decision Trees (DTs) and Random Forests (RFs)
are often hindered by overfitting. These ML algorithms need extensive
hyperparameter tuning. Random Search offers a faster, and, more efficient
exploration of hyperparameter space, but, it may overlook optimal regions. Grid
Search, though exhaustive, but, it is computationally expensive and
inefficient, particularly with high-dimensional data. To address these
limitations, Randomized-Grid Search, a novel hybrid optimization method is
proposed that combines the global exploration strengths of Random Search with
the focused, and, exhaustive search of Grid Search in the most promising
regions. This hybrid approach efficiently balances exploration and
exploitation. The proposed model optimizes the hyperparameter for Decision Tree
model. The proposed model is applied to UCI heart disease dataset for
classification. It enhances model performance, provides improved accuracy,
generalization, and computational efficiency. Experimental results demonstrate
that Randomized-Grid Search outperforms traditional methods by significant
margins. The proposed model provides a more effective solution for machine
learning applications in healthcare diagnosis.

摘要：心血管疾病是指任何影响心脏的危急状况。由于心脏疾病可能危及生命。研究人员正专注于设计智能系统，以借助机器学习算法根据电子健康数据准确诊断心脏疾病。使用机器学习 (ML) 算法（如支持向量机 (SVM)、朴素贝叶斯 (NB)、决策树 (DT) 和随机森林 (RF)）进行心脏病分类通常会受到过度拟合的阻碍。这些 ML 算法需要广泛的超参数调整。随机搜索提供了对超参数空间更快速、更高效的探索，但它可能会忽略最优区域。网格搜索虽然详尽，但计算成本高且效率低下，尤其是在处理高维数据时。为了解决这些限制，提出了一种新颖的混合优化方法随机网格搜索，它将随机搜索的全局探索优势与网格搜索在最有希望的区域中的集中和详尽搜索相结合。这种混合方法有效地平衡了探索和利用。所提出的模型优化了决策树模型的超参数。所提出的模型应用于 UCI 心脏病数据集进行分类。它增强了模型性能，提高了准确性、泛化能力和计算效率。实验结果表明，随机网格搜索以显著的优势优于传统方法。所提出的模型为医疗诊断中的机器学习应用提供了更有效的解决方案。

##### **The Return of Pseudosciences in Artificial Intelligence: Have Machine Learning and Deep Learning Forgotten Lessons from Statistics and History?**
2411.18656v1 by Jérémie Sublime

In today's world, AI programs powered by Machine Learning are ubiquitous, and
have achieved seemingly exceptional performance across a broad range of tasks,
from medical diagnosis and credit rating in banking, to theft detection via
video analysis, and even predicting political or sexual orientation from facial
images. These predominantly deep learning methods excel due to their
extraordinary capacity to process vast amounts of complex data to extract
complex correlations and relationship from different levels of features.
  In this paper, we contend that the designers and final users of these ML
methods have forgotten a fundamental lesson from statistics: correlation does
not imply causation. Not only do most state-of-the-art methods neglect this
crucial principle, but by doing so they often produce nonsensical or flawed
causal models, akin to social astrology or physiognomy. Consequently, we argue
that current efforts to make AI models more ethical by merely reducing biases
in the training data are insufficient. Through examples, we will demonstrate
that the potential for harm posed by these methods can only be mitigated by a
complete rethinking of their core models, improved quality assessment metrics
and policies, and by maintaining humans oversight throughout the process.

摘要：在當今世界，由機器學習驅動的人工智慧程式無處不在，並且在廣泛的任務中實現了看似卓越的效能，從醫療診斷和銀行業信用評分，到透過影片分析進行竊盜偵測，甚至從臉部影像預測政治或性取向。這些主要深度學習方法之所以出色，是因為它們具有非凡的處理大量複雜資料的能力，從不同層級的特徵中提取複雜的關聯性和關係。
在本文中，我們認為這些機器學習方法的設計者和最終使用者忘記了統計學中的基本教訓：相關性並不意味著因果關係。最先進的方法不僅忽略了這項關鍵原則，而且這麼做時，它們通常會產生荒謬或有缺陷的因果模型，類似於社會占星學或面相學。因此，我們認為當前透過僅減少訓練資料中的偏差來讓人工智慧模型更具倫理的做法是不夠的。透過範例，我們將證明這些方法造成的潛在危害只能透過徹底重新思考其核心模型、改善品質評估指標和政策，以及在整個過程中維持人類監督來減輕。

##### **Visual Error Patterns in Multi-Modal AI: A Statistical Approach**
2412.00083v1 by Ching-Yi Wang

Artificial Intelligence (AI) has achieved transformative success across a
wide range of domains, revolutionizing fields such as healthcare, education,
and human-computer interaction. However, the mechanisms driving AI's
performance often remain opaque, particularly in the context of large language
models (LLMs), which have advanced at an unprecedented pace in recent years.
Multi-modal large language models (MLLMs) like GPT-4o exemplify this evolution,
integrating text, audio, and visual inputs to enable interaction across diverse
domains. Despite their remarkable capabilities, these models remain largely
"black boxes," offering limited insight into how they process multi-modal
information internally. This lack of transparency poses significant challenges,
including systematic biases, flawed associations, and unintended behaviors,
which require careful investigation. Understanding the decision-making
processes of MLLMs is both beneficial and essential for mitigating these
challenges and ensuring their reliable deployment in critical applications.
GPT-4o was chosen as the focus of this study for its advanced multi-modal
capabilities, which allow simultaneous processing of textual and visual
information. These capabilities make it an ideal model for investigating the
parallels and distinctions between machine-driven and human-driven visual
perception. While GPT-4o performs effectively in tasks involving structured and
complete data, its reliance on bottom-up processing, which involves a
feature-by-feature analysis of sensory inputs, presents challenges when
interpreting complex or ambiguous stimuli. This limitation contrasts with human
vision, which is remarkably adept at resolving ambiguity and reconstructing
incomplete information through high-level cognitive processes.

摘要：人工智慧 (AI) 已在廣泛的領域中取得變革性的成功，徹底改變了醫療保健、教育和人機互動等領域。然而，推動 AI 效能的機制通常仍然不透明，特別是在大型語言模型 (LLM) 的情況下，LLM 近年來以空前的速度發展。GPT-4o 等多模態大型語言模型 (MLLM) 便是此演進的範例，它整合文字、音訊和視覺輸入，以實現跨不同領域的互動。儘管這些模型擁有非凡的能力，但它們在很大程度上仍是「黑盒子」，無法深入了解它們在內部如何處理多模態資訊。這種缺乏透明度帶來了重大挑戰，包括系統性偏差、有缺陷的關聯和意外行為，這些都需要仔細調查。了解 MLLM 的決策過程既有益又對於減輕這些挑戰和確保它們在關鍵應用中的可靠部署至關重要。GPT-4o 被選為本研究的重點，在於其先進的多模態能力，它允許同時處理文字和視覺資訊。這些能力使其成為研究機器驅動和人類驅動視覺感知之間的相似性和區別的理想模型。雖然 GPT-4o 在涉及結構化和完整資料的任務中表現得很好，但它依賴於自下而上的處理，其中涉及感官輸入的逐項特徵分析，在解釋複雜或模稜兩可的刺激時會造成挑戰。這種限制與人類視覺形成對比，人類視覺非常擅長透過高層次認知過程解決歧義並重建不完整資訊。

##### **Graph Neural Network for Cerebral Blood Flow Prediction With Clinical Datasets**
2411.17971v1 by Seungyeon Kim, Wheesung Lee, Sung-Ho Ahn, Do-Eun Lee, Tae-Rin Lee

Accurate prediction of cerebral blood flow is essential for the diagnosis and
treatment of cerebrovascular diseases. Traditional computational methods,
however, often incur significant computational costs, limiting their
practicality in real-time clinical applications. This paper proposes a graph
neural network (GNN) to predict blood flow and pressure in previously unseen
cerebral vascular network structures that were not included in training data.
The GNN was developed using clinical datasets from patients with stenosis,
featuring complex and abnormal vascular geometries. Additionally, the GNN model
was trained on data incorporating a wide range of inflow conditions, vessel
topologies, and network connectivities to enhance its generalization
capability. The approach achieved Pearson's correlation coefficients of 0.727
for pressure and 0.824 for flow rate, with sufficient training data. These
findings demonstrate the potential of the GNN for real-time cerebrovascular
diagnostics, particularly in handling intricate and pathological vascular
networks.

摘要：準確預測腦部血流對於腦血管疾病的診斷和治療至關重要。然而，傳統的計算方法通常會產生大量的計算成本，限制了它們在臨床應用中的實用性。本文提出了一個圖形神經網路 (GNN) 來預測先前未見過的腦血管網路結構中的血流和壓力，這些結構未包含在訓練資料中。GNN 是使用來自狹窄症患者的臨床資料集開發的，這些資料集具有複雜且異常的血管幾何形狀。此外，GNN 模型是在包含各種流入條件、血管拓撲和網路連接性的資料上訓練的，以增強其泛化能力。該方法在有足夠的訓練資料的情況下，壓力達到 0.727 的皮爾森相關係數，流速達到 0.824。這些發現證明了 GNN 在實時腦血管診斷中的潛力，特別是在處理複雜且病理性的血管網路方面。

##### **Evaluating Generative AI-Enhanced Content: A Conceptual Framework Using Qualitative, Quantitative, and Mixed-Methods Approaches**
2411.17943v1 by Saman Sarraf

Generative AI (GenAI) has revolutionized content generation, offering
transformative capabilities for improving language coherence, readability, and
overall quality. This manuscript explores the application of qualitative,
quantitative, and mixed-methods research approaches to evaluate the performance
of GenAI models in enhancing scientific writing. Using a hypothetical use case
involving a collaborative medical imaging manuscript, we demonstrate how each
method provides unique insights into the impact of GenAI. Qualitative methods
gather in-depth feedback from expert reviewers, analyzing their responses using
thematic analysis tools to capture nuanced improvements and identify
limitations. Quantitative approaches employ automated metrics such as BLEU,
ROUGE, and readability scores, as well as user surveys, to objectively measure
improvements in coherence, fluency, and structure. Mixed-methods research
integrates these strengths, combining statistical evaluations with detailed
qualitative insights to provide a comprehensive assessment. These research
methods enable quantifying improvement levels in GenAI-generated content,
addressing critical aspects of linguistic quality and technical accuracy. They
also offer a robust framework for benchmarking GenAI tools against traditional
editing processes, ensuring the reliability and effectiveness of these
technologies. By leveraging these methodologies, researchers can evaluate the
performance boost driven by GenAI, refine its applications, and guide its
responsible adoption in high-stakes domains like healthcare and scientific
research. This work underscores the importance of rigorous evaluation
frameworks for advancing trust and innovation in GenAI.

摘要：生成式 AI (GenAI) 徹底改變了內容生成，提供了變革性的能力來改善語言的連貫性、可讀性和整體品質。這份手稿探討了運用定性、定量和混合方法研究方法來評估 GenAI 模型在提升科學寫作方面的表現。使用涉及協作醫學影像手稿的假設用例，我們展示了每種方法如何提供對 GenAI 影響的獨特見解。定性方法從專家審查員收集深入的回饋，使用主題分析工具分析他們的回應，以捕捉細微的改進並找出限制。定量方法採用自動化指標，例如 BLEU、ROUGE 和可讀性評分，以及使用者調查，以客觀地衡量連貫性、流暢性和結構的改進。混合方法研究整合了這些優勢，結合統計評估和詳細的定性見解，以提供全面的評估。這些研究方法能夠量化 GenAI 生成的內容的改進程度，解決語言品質和技術準確性的關鍵面向。它們還提供了一個穩健的架構，用於將 GenAI 工具與傳統的編輯流程進行基準比較，確保這些技術的可靠性和有效性。透過運用這些方法，研究人員可以評估 GenAI 帶來的效能提升，優化其應用，並指導其在醫療保健和科學研究等高風險領域中的負責任採用。這項工作強調了嚴謹評估架構對於提升 GenAI 的信任和創新的重要性。

##### **Automating grapevine LAI features estimation with UAV imagery and machine learning**
2411.17897v1 by Muhammad Waseem Akram, Marco Vannucci, Giorgio Buttazzo, Valentina Colla, Stefano Roccella, Andrea Vannini, Giovanni Caruso, Simone Nesi, Alessandra Francini, Luca Sebastiani

The leaf area index determines crop health and growth. Traditional methods
for calculating it are time-consuming, destructive, costly, and limited to a
scale. In this study, we automate the index estimation method using drone image
data of grapevine plants and a machine learning model. Traditional feature
extraction and deep learning methods are used to obtain helpful information
from the data and enhance the performance of the different machine learning
models employed for the leaf area index prediction. The results showed that
deep learning based feature extraction is more effective than traditional
methods. The new approach is a significant improvement over old methods,
offering a faster, non-destructive, and cost-effective leaf area index
calculation, which enhances precision agriculture practices.

摘要：葉面積指數決定作物的健康和生長。傳統計算方法耗時、具破壞性、昂貴且僅限於某一規模。在本研究中，我們使用葡萄藤植株的無人機影像資料和機器學習模型自動化指數估計方法。傳統特徵提取和深度學習方法用於從資料中獲取有用的資訊，並提升用於葉面積指數預測的不同機器學習模型的效能。結果顯示，基於深度學習的特徵提取比傳統方法更有效。新方法比舊方法有顯著的改進，提供更快速、非破壞性且具成本效益的葉面積指數計算，進而提升精準農業實務。

##### **HOPPR Medical-Grade Platform for Medical Imaging AI**
2411.17891v1 by Kalina P. Slavkova, Melanie Traughber, Oliver Chen, Robert Bakos, Shayna Goldstein, Dan Harms, Bradley J. Erickson, Khan M. Siddiqui

Technological advances in artificial intelligence (AI) have enabled the
development of large vision language models (LVLMs) that are trained on
millions of paired image and text samples. Subsequent research efforts have
demonstrated great potential of LVLMs to achieve high performance in medical
imaging use cases (e.g., radiology report generation), but there remain
barriers that hinder the ability to deploy these solutions broadly. These
include the cost of extensive computational requirements for developing large
scale models, expertise in the development of sophisticated AI models, and the
difficulty in accessing substantially large, high-quality datasets that
adequately represent the population in which the LVLM solution is to be
deployed. The HOPPR Medical-Grade Platform addresses these barriers by
providing powerful computational infrastructure, a suite of foundation models
on top of which developers can fine-tune for their specific use cases, and a
robust quality management system that sets a standard for evaluating fine-tuned
models for deployment in clinical settings. The HOPPR Platform has access to
millions of imaging studies and text reports sourced from hundreds of imaging
centers from diverse populations to pretrain foundation models and enable use
case-specific cohorts for fine-tuning. All data are deidentified and securely
stored for HIPAA compliance. Additionally, developers can securely host models
on the HOPPR platform and access them via an API to make inferences using these
models within established clinical workflows. With the Medical-Grade Platform,
HOPPR's mission is to expedite the deployment of LVLM solutions for medical
imaging and ultimately optimize radiologist's workflows and meet the growing
demands of the field.

摘要：人工智能 (AI) 的技術進展使大型視覺語言模型 (LVLMs) 的開發成為可能，這些模型經過數百萬配對圖像和文本範例的訓練。後續的研究工作已證明 LVLMs 在醫學影像使用案例（例如放射學報告生成）中實現高性能的巨大潛力，但仍存在阻礙這些解決方案廣泛部署的能力的障礙。這些障礙包括開發大型模型的廣泛計算需求的成本、開發複雜 AI 模型的專業知識，以及難以存取充分龐大、高品質的資料集，這些資料集充分代表了 LVLM 解決方案將要部署的人群。HOPPR 醫療級平台透過提供強大的運算基礎架構、一套基礎模型（開發人員可以在其上針對其特定使用案例進行微調）以及一套健全的品質管理系統來解決這些障礙，為評估微調模型在臨床環境中部署設定標準。HOPPR 平台可以存取數百萬份影像研究和來自不同族群的數百個影像中心的文字報告，以預先訓練基礎模型並針對特定使用案例啟用微調的群組。所有資料均已去識別化並安全儲存，以符合 HIPAA 規範。此外，開發人員可以在 HOPPR 平台上安全地主機模型，並透過 API 存取這些模型，以便在既定的臨床工作流程中使用這些模型進行推論。HOPPR 的使命是透過醫療級平台加速部署用於醫學影像的 LVLM 解決方案，並最終最佳化放射科醫師的工作流程，以滿足該領域不斷增長的需求。

##### **Explainable AI for Classifying UTI Risk Groups Using a Real-World Linked EHR and Pathology Lab Dataset**
2411.17645v1 by Yujie Dai, Brian Sullivan, Axel Montout, Amy Dillon, Chris Waller, Peter Acs, Rachel Denholm, Philip Williams, Alastair D Hay, Raul Santos-Rodriguez, Andrew Dowsey

The use of machine learning and AI on electronic health records (EHRs) holds
substantial potential for clinical insight. However, this approach faces
significant challenges due to data heterogeneity, sparsity, temporal
misalignment, and limited labeled outcomes. In this context, we leverage a
linked EHR dataset of approximately one million de-identified individuals from
Bristol, North Somerset, and South Gloucestershire, UK, to characterize urinary
tract infections (UTIs) and develop predictive models focused on data quality,
fairness and transparency. A comprehensive data pre-processing and curation
pipeline transforms the raw EHR data into a structured format suitable for AI
modeling. Given the limited availability and biases of ground truth UTI
outcomes, we introduce a UTI risk estimation framework informed by clinical
expertise to estimate UTI risk across individual patient timelines. Using this
framework, we built pairwise XGBoost models to differentiate UTI risk
categories with explainable AI techniques to identify key predictors while
ensuring interpretability. Our findings reveal differences in clinical and
demographic factors across risk groups, offering insights into UTI risk
stratification and progression. This study demonstrates the added value of
AI-driven insights into UTI clinical decision-making while prioritizing
interpretability, transparency, and fairness, underscoring the importance of
sound data practices in advancing health outcomes.

摘要：機器學習和人工智慧在電子健康紀錄 (EHR) 上的應用具有
臨床見解的巨大潛力。然而，這種方法由於資料異質性、稀疏性、時間錯位和標記結果有限，因此面臨重大挑戰。在此背景下，我們利用來自英國布里斯托、北薩默塞特郡和南格洛斯特郡的大約一百萬名去識別化個人的連結式 EHR 資料集，以描述泌尿道感染 (UTI) 並開發專注於資料品質、公平性和透明度的預測模型。全面的資料前處理和整理管道將原始 EHR 資料轉換為適合 AI 建模的結構化格式。鑑於實際 UTI 結果的可用性有限和偏見，我們引入了一個由臨床專業知識提供資訊的 UTI 風險評估架構，以估計個人患者時間線上的 UTI 風險。使用此架構，我們建立了成對的 XGBoost 模型，以區分 UTI 風險類別，並使用可解釋的 AI 技術來識別關鍵預測因子，同時確保可解釋性。我們的研究結果揭示了不同風險群組的臨床和人口統計因素的差異，提供了對 UTI 風險分層和進展的見解。本研究展示了 AI 驅動的見解在 UTI 臨床決策中的附加價值，同時優先考慮可解釋性、透明度和公平性，強調了健全資料實務在促進健康結果中的重要性。

##### **DapPep: Domain Adaptive Peptide-agnostic Learning for Universal T-cell Receptor-antigen Binding Affinity Prediction**
2411.17798v1 by Jiangbin Zheng, Qianhui Xu, Ruichen Xia, Stan Z. Li

Identifying T-cell receptors (TCRs) that interact with antigenic peptides
provides the technical basis for developing vaccines and immunotherapies. The
emergent deep learning methods excel at learning antigen binding patterns from
known TCRs but struggle with novel or sparsely represented antigens. However,
binding specificity for unseen antigens or exogenous peptides is critical. We
introduce a domain-adaptive peptide-agnostic learning framework DapPep for
universal TCR-antigen binding affinity prediction to address this challenge.
The lightweight self-attention architecture combines a pre-trained protein
language model with an inner-loop self-supervised regime to enable robust
TCR-peptide representations. Extensive experiments on various benchmarks
demonstrate that DapPep consistently outperforms existing tools, showcasing
robust generalization capability, especially for data-scarce settings and
unseen peptides. Moreover, DapPep proves effective in challenging clinical
tasks such as sorting reactive T cells in tumor neoantigen therapy and
identifying key positions in 3D structures.

摘要：识别与抗原肽相互作用的 T 细胞受体 (TCR) 为开发疫苗和免疫疗法提供了技术基础。新兴的深度学习方法擅长从已知的 TCR 中学习抗原结合模式，但在新颖或稀疏表示的抗原方面却有困难。然而，对未见抗原或外源肽的结合特异性至关重要。我们引入了一个域自适应肽不可知学习框架 DapPep，用于通用的 TCR 抗原结合亲和力预测，以应对这一挑战。轻量级自注意力架构将预训练的蛋白质语言模型与内部循环自监督机制相结合，以启用鲁棒的 TCR 肽表示。在各种基准上的广泛实验表明，DapPep 始终优于现有工具，展示了强大的泛化能力，尤其是在数据稀缺的设置和未见肽中。此外，DapPep 被证明在具有挑战性的临床任务中是有效的，例如在肿瘤新抗原治疗中对反应性 T 细胞进行分类，以及识别 3D 结构中的关键位置。

##### **Learning Explainable Treatment Policies with Clinician-Informed Representations: A Practical Approach**
2411.17570v1 by Johannes O. Ferstad, Emily B. Fox, David Scheinker, Ramesh Johari

Digital health interventions (DHIs) and remote patient monitoring (RPM) have
shown great potential in improving chronic disease management through
personalized care. However, barriers like limited efficacy and workload
concerns hinder adoption of existing DHIs; while limited sample sizes and lack
of interpretability limit the effectiveness and adoption of purely black-box
algorithmic DHIs. In this paper, we address these challenges by developing a
pipeline for learning explainable treatment policies for RPM-enabled DHIs. We
apply our approach in the real-world setting of RPM using a DHI to improve
glycemic control of youth with type 1 diabetes. Our main contribution is to
reveal the importance of clinical domain knowledge in developing state and
action representations for effective, efficient, and interpretable targeting
policies. We observe that policies learned from clinician-informed
representations are significantly more efficacious and efficient than policies
learned from black-box representations. This work emphasizes the importance of
collaboration between ML researchers and clinicians for developing effective
DHIs in the real world.

摘要：數位健康干預（DHI）和遠距病人監控（RPM）已顯示出透過個人化照護改善慢性疾病管理的巨大潛力。然而，諸如成效有限和工作負擔等障礙阻礙了現有 DHI 的採用；而樣本量有限和缺乏可解釋性則限制了純黑盒演算法 DHI 的有效性和採用。在本文中，我們透過開發一個用於學習 RPM 支援 DHI 的可解釋治療政策的管道來解決這些挑戰。我們在使用 DHI 改善第一型糖尿病青少年的血糖控制的 RPM 實例中應用我們的做法。我們的貢獻重點在於揭露臨床領域知識在開發有效、高效且可解釋的目標政策的狀態和動作表示中的重要性。我們觀察到，從臨床醫師提供的表示中學習到的政策顯著比從黑盒表示中學習到的政策更有效且更有效率。這項工作強調了 ML 研究人員和臨床醫師之間的合作對於在現實世界中開發有效的 DHI 的重要性。

##### **A Bilayer Segmentation-Recombination Network for Accurate Segmentation of Overlapping C. elegans**
2411.17557v1 by Mengqian Dinga, Jun Liua, Yang Luo, Jinshan Tang

Caenorhabditis elegans (C. elegans) is an excellent model organism because of
its short lifespan and high degree of homology with human genes, and it has
been widely used in a variety of human health and disease models. However, the
segmentation of C. elegans remains challenging due to the following reasons: 1)
the activity trajectory of C. elegans is uncontrollable, and multiple nematodes
often overlap, resulting in blurred boundaries of C. elegans. This makes it
impossible to clearly study the life trajectory of a certain nematode; and 2)
in the microscope images of overlapping C. elegans, the translucent tissues at
the edges obscure each other, leading to inaccurate boundary segmentation. To
solve these problems, a Bilayer Segmentation-Recombination Network (BR-Net) for
the segmentation of C. elegans instances is proposed. The network consists of
three parts: A Coarse Mask Segmentation Module (CMSM), a Bilayer Segmentation
Module (BSM), and a Semantic Consistency Recombination Module (SCRM). The CMSM
is used to extract the coarse mask, and we introduce a Unified Attention Module
(UAM) in CMSM to make CMSM better aware of nematode instances. The Bilayer
Segmentation Module (BSM) segments the aggregated C. elegans into overlapping
and non-overlapping regions. This is followed by integration by the SCRM, where
semantic consistency regularization is introduced to segment nematode instances
more accurately. Finally, the effectiveness of the method is verified on the C.
elegans dataset. The experimental results show that BR-Net exhibits good
competitiveness and outperforms other recently proposed instance segmentation
methods in processing C. elegans occlusion images.

摘要：秀麗隱桿線蟲 (C. elegans) 是一種極佳的模式生物，原因在於其壽命短且與人類基因有高度同源性，且已廣泛用於各種人類健康與疾病模式中。然而，C. elegans 的分割仍然具有挑戰性，原因如下：1) C. elegans 的活動軌跡無法控制，且多個線蟲經常重疊，導致 C. elegans 的邊界模糊。這使得無法清楚地研究某個線蟲的生命軌跡；2) 在重疊的 C. elegans 的顯微鏡影像中，邊緣的半透明組織彼此遮蔽，導致邊界分割不準確。為了解決這些問題，提出了一個用於分割 C. elegans 個體的雙層分割重組網路 (BR-Net)。該網路包含三個部分：粗略遮罩分割模組 (CMSM)、雙層分割模組 (BSM) 和語意一致性重組模組 (SCRM)。CMSM 用於提取粗略遮罩，我們在 CMSM 中引入了一個統一注意力模組 (UAM)，以使 CMSM 更能感知線蟲個體。雙層分割模組 (BSM) 將聚集的 C. elegans 分割成重疊和非重疊區域。接著由 SCRM 整合，其中引入了語意一致性正則化，以更準確地分割線蟲個體。最後，在 C. elegans 資料集上驗證了該方法的有效性。實驗結果顯示，BR-Net 展現出良好的競爭力，且在處理 C. elegans 遮蔽影像時優於其他最近提出的個體分割方法。

##### **AI-Augmented Ethical Hacking: A Practical Examination of Manual Exploitation and Privilege Escalation in Linux Environments**
2411.17539v1 by Haitham S. Al-Sinani, Chris J. Mitchell

This study explores the application of generative AI (GenAI) within manual
exploitation and privilege escalation tasks in Linux-based penetration testing
environments, two areas critical to comprehensive cybersecurity assessments.
Building on previous research into the role of GenAI in the ethical hacking
lifecycle, this paper presents a hands-on experimental analysis conducted in a
controlled virtual setup to evaluate the utility of GenAI in supporting these
crucial, often manual, tasks. Our findings demonstrate that GenAI can
streamline processes, such as identifying potential attack vectors and parsing
complex outputs for sensitive data during privilege escalation. The study also
identifies key benefits and challenges associated with GenAI, including
enhanced efficiency and scalability, alongside ethical concerns related to data
privacy, unintended discovery of vulnerabilities, and potential for misuse.
This work contributes to the growing field of AI-assisted cybersecurity by
emphasising the importance of human-AI collaboration, especially in contexts
requiring careful decision-making, rather than the complete replacement of
human input.

摘要：本研究探討了在以 Linux 為基礎的滲透測試環境中，將生成式 AI (GenAI) 應用於手動漏洞利用和權限提升任務，這兩個領域對於全面的網路安全評估至關重要。本論文建立於先前的研究，探討 GenAI 在道德駭客生命週期中的角色，並提出在受控虛擬設定中進行的實作實驗分析，以評估 GenAI 在支援這些關鍵且通常手動執行的任務中的效用。我們的研究結果顯示，GenAI 可以簡化流程，例如在權限提升期間識別潛在的攻擊媒介，並分析複雜的輸出以取得敏感資料。本研究也找出與 GenAI 相關的主要好處和挑戰，包括增強效率和可擴充性，以及與資料隱私、意外發現漏洞和潛在濫用相關的道德疑慮。這項工作透過強調人機協作的重要性，為 AI 輔助網路安全這個不斷成長的領域做出貢獻，特別是在需要謹慎決策制定，而非完全取代人類輸入的脈絡中。

##### **ShowUI: One Vision-Language-Action Model for GUI Visual Agent**
2411.17465v1 by Kevin Qinghong Lin, Linjie Li, Difei Gao, Zhengyuan Yang, Shiwei Wu, Zechen Bai, Weixian Lei, Lijuan Wang, Mike Zheng Shou

Building Graphical User Interface (GUI) assistants holds significant promise
for enhancing human workflow productivity. While most agents are
language-based, relying on closed-source API with text-rich meta-information
(e.g., HTML or accessibility tree), they show limitations in perceiving UI
visuals as humans do, highlighting the need for GUI visual agents. In this
work, we develop a vision-language-action model in digital world, namely
ShowUI, which features the following innovations: (i) UI-Guided Visual Token
Selection to reduce computational costs by formulating screenshots as an UI
connected graph, adaptively identifying their redundant relationship and serve
as the criteria for token selection during self-attention blocks; (ii)
Interleaved Vision-Language-Action Streaming that flexibly unifies diverse
needs within GUI tasks, enabling effective management of visual-action history
in navigation or pairing multi-turn query-action sequences per screenshot to
enhance training efficiency; (iii) Small-scale High-quality GUI
Instruction-following Datasets by careful data curation and employing a
resampling strategy to address significant data type imbalances. With above
components, ShowUI, a lightweight 2B model using 256K data, achieves a strong
75.1% accuracy in zero-shot screenshot grounding. Its UI-guided token selection
further reduces 33% of redundant visual tokens during training and speeds up
the performance by 1.4x. Navigation experiments across web Mind2Web, mobile
AITW, and online MiniWob environments further underscore the effectiveness and
potential of our model in advancing GUI visual agents. The models are available
at https://github.com/showlab/ShowUI.

摘要：<paragraph>建構圖形使用者介面 (GUI) 助理極有望提升人類工作流程的生產力。雖然大多數代理都是基於語言，仰賴具有豐富文字元資訊封閉原始碼 API（例如 HTML 或無障礙樹），但它們在感知使用者介面視覺效果方面顯示出限制，這凸顯了對 GUI 視覺代理的需求。在這項工作中，我們在數位世界中開發了一個視覺語言動作模型，即 ShowUI，其具有以下創新功能：(i) UI 引導視覺代幣選擇，透過將螢幕截圖表述為 UI 連接圖，自適應地識別其冗餘關係，並作為自注意力區塊中代幣選擇的準則，以降低運算成本；(ii) 交錯視覺語言動作串流，靈活地統一 GUI 任務中的各種需求，在導覽中有效管理視覺動作歷程，或配對每個螢幕截圖的多輪查詢動作序列，以提升訓練效率；(iii) 小規模高品質 GUI 指令遵循資料集，透過仔細的資料整理和採用再抽樣策略，來解決顯著的資料類型不平衡。ShowUI 是一個使用 256K 資料的輕量級 2B 模型，具備上述組成部分，在零次方螢幕截圖接地中達到強勁的 75.1% 精確度。其 UI 引導代幣選擇進一步減少了訓練期間 33% 的冗餘視覺代幣，並將效能提升了 1.4 倍。跨網路 Mind2Web、行動 AITW 和線上 MiniWob 環境的導覽實驗進一步強調了我們的模型在推進 GUI 視覺代理方面的有效性和潛力。這些模型可在 https://github.com/showlab/ShowUI 取得。</paragraph>

##### **Social Distancing Induced Coronavirus Optimization Algorithm (COVO): Application to Multimodal Function Optimization and Noise Removal**
2411.17282v1 by Om Ramakisan Varma, Mala Kalra

The metaheuristic optimization technique attained more awareness for handling
complex optimization problems. Over the last few years, numerous optimization
techniques have been developed that are inspired by natural phenomena.
Recently, the propagation of the new COVID-19 implied a burden on the public
health system to suffer several deaths. Vaccination, masks, and social
distancing are the major steps taken to minimize the spread of the deadly
COVID-19 virus. Considering the social distance to combat the coronavirus
epidemic, a novel bio-inspired metaheuristic optimization model is proposed in
this work, and it is termed as Social Distancing Induced Coronavirus
Optimization Algorithm (COVO). The pace of propagation of the coronavirus can
indeed be slowed by maintaining social distance. Thirteen benchmark functions
are used to evaluate the COVO performance for discrete, continuous, and complex
problems, and the COVO model performance is compared with other well-known
optimization algorithms. The main motive of COVO optimization is to obtain a
global solution to various applications by solving complex problems with faster
convergence. At last, the validated results depict that the proposed COVO
optimization has a reasonable and acceptable performance.

摘要：元启发式优化技术在处理复杂优化问题方面获得了更多的关注。在过去的几年中，已经开发出许多受自然现象启发的优化技术。最近，新型冠状病毒肺炎的传播给公共卫生系统带来了沉重负担，导致多人死亡。接种疫苗、戴口罩和保持社交距离是为最大程度减少致命的新冠病毒传播而采取的主要措施。考虑到保持社交距离以对抗冠状病毒疫情，这项工作提出了一种新的受生物启发的元启发式优化模型，并将其称为社交距离诱导冠状病毒优化算法 (COVO)。保持社交距离确实可以减缓冠状病毒的传播速度。十三项基准函数用于评估 COVO 在离散、连续和复杂问题上的性能，并将 COVO 模型的性能与其他众所周知的优化算法进行了比较。COVO 优化算法的主要目的是通过解决复杂问题以更快的收敛速度为各种应用获取全局解决方案。最后，验证结果表明，所提出的 COVO 优化算法具有合理且可接受的性能。

##### **Semantic Data Augmentation for Long-tailed Facial Expression Recognition**
2411.17254v1 by Zijian Li, Yan Wang, Bowen Guan, JianKai Yin

Facial Expression Recognition has a wide application prospect in social
robotics, health care, driver fatigue monitoring, and many other practical
scenarios. Automatic recognition of facial expressions has been extensively
studied by the Computer Vision research society. But Facial Expression
Recognition in real-world is still a challenging task, partially due to the
long-tailed distribution of the dataset. Many recent studies use data
augmentation for Long-Tailed Recognition tasks. In this paper, we propose a
novel semantic augmentation method. By introducing randomness into the encoding
of the source data in the latent space of VAE-GAN, new samples are generated.
Then, for facial expression recognition in RAF-DB dataset, we use our
augmentation method to balance the long-tailed distribution. Our method can be
used in not only FER tasks, but also more diverse data-hungry scenarios.

摘要：人臉表情辨識在社交機器人、醫療保健、駕駛疲勞監控以及許多其他實際場景中具有廣泛的應用前景。電腦視覺研究學會已廣泛研究人臉表情的自動辨識。但現實世界中的人臉表情辨識仍是一項具有挑戰性的任務，部分原因是資料集的長尾分佈。許多近期研究使用資料擴充進行長尾辨識任務。在本文中，我們提出了一種新穎的語義擴充方法。透過將隨機性引入 VAE-GAN 潛在空間中原始資料的編碼，產生新的樣本。然後，對於 RAF-DB 資料集中的面部表情辨識，我們使用擴充方法平衡長尾分佈。我們的這種方法不僅可用於 FER 任務，還可用於更多樣化的資料密集場景。

##### **GraphSubDetector: Time Series Subsequence Anomaly Detection via Density-Aware Adaptive Graph Neural Network**
2411.17218v1 by Weiqi Chen, Zhiqiang Zhou, Qingsong Wen, Liang Sun

Time series subsequence anomaly detection is an important task in a large
variety of real-world applications ranging from health monitoring to AIOps, and
is challenging due to the following reasons: 1) how to effectively learn
complex dynamics and dependencies in time series; 2) diverse and complicated
anomalous subsequences as well as the inherent variance and noise of normal
patterns; 3) how to determine the proper subsequence length for effective
detection, which is a required parameter for many existing algorithms. In this
paper, we present a novel approach to subsequence anomaly detection, namely
GraphSubDetector. First, it adaptively learns the appropriate subsequence
length with a length selection mechanism that highlights the characteristics of
both normal and anomalous patterns. Second, we propose a density-aware adaptive
graph neural network (DAGNN), which can generate further robust representations
against variance of normal data for anomaly detection by message passing
between subsequences. The experimental results demonstrate the effectiveness of
the proposed algorithm, which achieves superior performance on multiple time
series anomaly benchmark datasets compared to state-of-the-art algorithms.

摘要：時間序列子序列異常偵測在各種實際應用中是一項重要的任務，從健康監控到 AIOps，由於以下原因而具有挑戰性：1) 如何有效地學習時間序列中的複雜動態和依賴性；2) 多樣且複雜的異常子序列以及正常模式固有的變異和雜訊；3) 如何確定適當的子序列長度以進行有效偵測，這是許多現有演算法的必要參數。在本文中，我們提出了一個用於子序列異常偵測的新穎方法，即 GraphSubDetector。首先，它使用長度選擇機制自適應地學習適當的子序列長度，該機制突出了正常模式和異常模式的特徵。其次，我們提出了一個密度感知自適應圖神經網路 (DAGNN)，它可以通過子序列之間的訊息傳遞，針對正常資料的變異產生更強大的表示，以進行異常偵測。實驗結果證明了所提出的演算法的有效性，與最先進的演算法相比，它在多個時間序列異常基準資料集上實現了卓越的效能。

##### **Strategic Prompting for Conversational Tasks: A Comparative Analysis of Large Language Models Across Diverse Conversational Tasks**
2411.17204v2 by Ratnesh Kumar Joshi, Priyanshu Priya, Vishesh Desai, Saurav Dudhate, Siddhant Senapati, Asif Ekbal, Roshni Ramnani, Anutosh Maitra, Shubhashis Sengupta

Given the advancements in conversational artificial intelligence, the
evaluation and assessment of Large Language Models (LLMs) play a crucial role
in ensuring optimal performance across various conversational tasks. In this
paper, we present a comprehensive study that thoroughly evaluates the
capabilities and limitations of five prevalent LLMs: Llama, OPT, Falcon,
Alpaca, and MPT. The study encompasses various conversational tasks, including
reservation, empathetic response generation, mental health and legal
counseling, persuasion, and negotiation. To conduct the evaluation, an
extensive test setup is employed, utilizing multiple evaluation criteria that
span from automatic to human evaluation. This includes using generic and
task-specific metrics to gauge the LMs' performance accurately. From our
evaluation, no single model emerges as universally optimal for all tasks.
Instead, their performance varies significantly depending on the specific
requirements of each task. While some models excel in certain tasks, they may
demonstrate comparatively poorer performance in others. These findings
emphasize the importance of considering task-specific requirements and
characteristics when selecting the most suitable LM for conversational
applications.

摘要：隨著對話式人工智慧的進步，大型語言模型 (LLM) 的評估與評量在確保各種對話式任務的最佳效能中扮演著至關重要的角色。在本文中，我們提出了一項全面的研究，徹底評估了五種常見 LLM 的能力和限制：Llama、OPT、Falcon、Alpaca 和 MPT。這項研究涵蓋了各種對話式任務，包括預約、同理心回應產生、心理健康和法律諮詢、說服和協商。為了進行評估，採用了廣泛的測試設定，利用了從自動評估到人工評估的多重評估標準。這包括使用通用和特定於任務的指標來準確評量 LLM 的效能。從我們的評估中，沒有單一模型在所有任務中都表現得普遍最佳。相反地，它們的效能會根據每個任務的特定需求而有顯著差異。雖然某些模型在某些任務中表現出色，但在其他任務中它們可能會表現出相對較差的效能。這些發現強調了在為對話式應用程式選擇最合適的 LLM 時，考量特定於任務的需求和特性的重要性。

##### **Contrastive Deep Learning Reveals Age Biomarkers in Histopathological Skin Biopsies**
2411.16956v1 by Kaustubh Chakradeo, Pernille Nielsen, Lise Mette Rahbek Gjerdrum, Gry Sahl Hansen, David A Duchêne, Laust H Mortensen, Majken K Jensen, Samir Bhatt

As global life expectancy increases, so does the burden of chronic diseases,
yet individuals exhibit considerable variability in the rate at which they age.
Identifying biomarkers that distinguish fast from slow ageing is crucial for
understanding the biology of ageing, enabling early disease detection, and
improving prevention strategies. Using contrastive deep learning, we show that
skin biopsy images alone are sufficient to determine an individual's age. We
then use visual features in histopathology slides of the skin biopsies to
construct a novel biomarker of ageing. By linking with comprehensive health
registers in Denmark, we demonstrate that visual features in histopathology
slides of skin biopsies predict mortality and the prevalence of chronic
age-related diseases. Our work highlights how routinely collected health data
can provide additional value when used together with deep learning, by creating
a new biomarker for ageing which can be actively used to determine mortality
over time.

摘要：隨著全球預期壽命的增加，慢性疾病的負擔也隨之增加，
但個人衰老的速度卻有相當大的差異。
找出能區分快速和緩慢衰老的生物標記，對於了解衰老的生物學、
早期疾病偵測和改善預防策略至關重要。我們使用對比深度學習，
證明僅皮膚切片圖像就足以確定個人的年齡。我們
接著使用皮膚切片活組織切片中可視化的特徵來
建構一個新的衰老生物標記。透過與丹麥的綜合健康註冊資料連結，我們
證明皮膚切片活組織切片中可視化的特徵可以預測死亡率和慢性
年齡相關疾病的盛行率。我們的研究強調，常規收集的健康資料
與深度學習結合使用時，可以提供額外的價值，透過建立一個新的衰老生物標記，
可以積極用於確定隨著時間推移的死亡率。

##### **Enabling Adoption of Regenerative Agriculture through Soil Carbon Copilots**
2411.16872v2 by Margaret Capetz, Swati Sharma, Rafael Padilha, Peder Olsen, Jessica Wolk, Emre Kiciman, Ranveer Chandra

Mitigating climate change requires transforming agriculture to minimize
environ mental impact and build climate resilience. Regenerative agricultural
practices enhance soil organic carbon (SOC) levels, thus improving soil health
and sequestering carbon. A challenge to increasing regenerative agriculture
practices is cheaply measuring SOC over time and understanding how SOC is
affected by regenerative agricultural practices and other environmental factors
and farm management practices. To address this challenge, we introduce an
AI-driven Soil Organic Carbon Copilot that automates the ingestion of complex
multi-resolution, multi-modal data to provide large-scale insights into soil
health and regenerative practices. Our data includes extreme weather event data
(e.g., drought and wildfire incidents), farm management data (e.g., cropland
information and tillage predictions), and SOC predictions. We find that
integrating public data and specialized models enables large-scale, localized
analysis for sustainable agriculture. In comparisons of agricultural practices
across California counties, we find evidence that diverse agricultural activity
may mitigate the negative effects of tillage; and that while extreme weather
conditions heavily affect SOC, composting may mitigate SOC loss. Finally,
implementing role-specific personas empowers agronomists, farm consultants,
policymakers, and other stakeholders to implement evidence-based strategies
that promote sustainable agriculture and build climate resilience.

摘要：減緩氣候變遷需要轉型農業，以將環境影響降到最低並建立氣候韌性。再生農業實務能提升土壤有機碳 (SOC) 含量，進而改善土壤健康並封存碳。擴大再生農業實務的一項挑戰在於在一段時間內以低成本測量 SOC，並了解 SOC 如何受到再生農業實務和其他環境因素與農場管理實務影響。為了應對這項挑戰，我們推出了一款 AI 驅動的土壤有機碳副駕駛，自動導入複雜的多解析度、多模式資料，以提供大規模的土壤健康與再生實務見解。我們的資料包含極端天氣事件資料（例如乾旱和野火事件）、農場管理資料（例如農田資訊和耕作預測），以及 SOC 預測。我們發現，整合公開資料和專業模型能針對永續農業進行大規模、在地化的分析。在比較加州各郡的農業實務後，我們發現證據顯示，多元的農業活動可以減輕耕作的負面影響；而且儘管極端天氣條件會嚴重影響 SOC，堆肥可能會減輕 SOC 流失。最後，實施角色特定的角色能讓農藝學家、農場顧問、政策制定者和其他利害關係人實施以證據為基礎的策略，以促進永續農業並建立氣候韌性。

##### **Enhancing In-Hospital Mortality Prediction Using Multi-Representational Learning with LLM-Generated Expert Summaries**
2411.16818v1 by Harshavardhan Battula, Jiacheng Liu, Jaideep Srivastava

In-hospital mortality (IHM) prediction for ICU patients is critical for
timely interventions and efficient resource allocation. While structured
physiological data provides quantitative insights, clinical notes offer
unstructured, context-rich narratives. This study integrates these modalities
with Large Language Model (LLM)-generated expert summaries to improve IHM
prediction accuracy. Using the MIMIC-III database, we analyzed time-series
physiological data and clinical notes from the first 48 hours of ICU admission.
Clinical notes were concatenated chronologically for each patient and
transformed into expert summaries using Med42-v2 70B. A multi-representational
learning framework was developed to integrate these data sources, leveraging
LLMs to enhance textual data while mitigating direct reliance on LLM
predictions, which can introduce challenges in uncertainty quantification and
interpretability. The proposed model achieved an AUPRC of 0.6156 (+36.41%) and
an AUROC of 0.8955 (+7.64%) compared to a time-series-only baseline. Expert
summaries outperformed clinical notes or time-series data alone, demonstrating
the value of LLM-generated knowledge. Performance gains were consistent across
demographic groups, with notable improvements in underrepresented populations,
underscoring the framework's equitable application potential. By integrating
LLM-generated summaries with structured and unstructured data, the framework
captures complementary patient information, significantly improving predictive
performance. This approach showcases the potential of LLMs to augment critical
care prediction models, emphasizing the need for domain-specific validation and
advanced integration strategies for broader clinical adoption.

摘要：<paragraph>對於 ICU 病患，院內死亡率 (IHM) 預測對於及時介入和有效資源分配至關重要。雖然結構化的生理數據提供了定量的見解，但臨床筆記提供了非結構化的、豐富的背景資訊。本研究整合了這些模式與大型語言模型 (LLM) 生成的專家摘要，以提高 IHM 預測準確度。使用 MIMIC-III 資料庫，我們分析了 ICU 入院前 48 小時的生理數據和臨床筆記的時間序列。每個病患的臨床筆記按時間順序串接，並使用 Med42-v2 70B 轉換成專家摘要。開發了一個多重表徵學習架構來整合這些數據來源，利用 LLM 來增強文本數據，同時減輕對 LLM 預測的直接依賴，這可能會在不確定性量化和可解釋性方面造成挑戰。與僅限時間序列的基準線相比，所提出的模型達到了 0.6156 (+36.41%) 的 AUPRC 和 0.8955 (+7.64%) 的 AUROC。專家摘要優於僅有的臨床筆記或時間序列數據，證明了 LLM 生成的知識的價值。在不同的人口統計群組中，效能提升是一致的，在代表性不足的族群中也有顯著的改善，強調了該架構公平應用潛力。透過整合 LLM 生成的摘要與結構化和非結構化數據，該架構擷取了互補的病患資訊，顯著改善了預測效能。此方法展示了 LLM 擴充重症照護預測模型的潛力，強調了特定領域驗證和進階整合策略對於更廣泛的臨床採用的必要性。</paragraph>

##### **Will an AI with Private Information Allow Itself to Be Switched Off?**
2411.17749v1 by Andrew Garber, Rohan Subramani, Linus Luu, Mark Bedaywi, Stuart Russell, Scott Emmons

A wide variety of goals could cause an AI to disable its off switch because
"you can't fetch the coffee if you're dead" (Russell 2019). Prior theoretical
work on this shutdown problem assumes that humans know everything that AIs do.
In practice, however, humans have only limited information. Moreover, in many
of the settings where the shutdown problem is most concerning, AIs might have
vast amounts of private information. To capture these differences in knowledge,
we introduce the Partially Observable Off-Switch Game (POSG), a game-theoretic
model of the shutdown problem with asymmetric information. Unlike when the
human has full observability, we find that in optimal play, even AI agents
assisting perfectly rational humans sometimes avoid shutdown. As expected,
increasing the amount of communication or information available always
increases (or leaves unchanged) the agents' expected common payoff. But
counterintuitively, introducing bounded communication can make the AI defer to
the human less in optimal play even though communication mitigates information
asymmetry. In particular, communication sometimes enables new optimal behavior
requiring strategic AI deference to achieve outcomes that were previously
inaccessible. Thus, designing safe artificial agents in the presence of
asymmetric information requires careful consideration of the tradeoffs between
maximizing payoffs (potentially myopically) and maintaining AIs' incentives to
defer to humans.

摘要：由於「如果你死了，你就無法去拿咖啡」（羅素，2019 年），各種目標都可能導致 AI 關閉其關閉開關。先前關於此關閉問題的理論研究假設人類知道 AI 所做的一切。然而，在實務上，人類只有有限的資訊。此外，在關閉問題最令人擔憂的許多情況下，AI 可能擁有大量的私人資訊。為了掌握這些知識差異，我們引入了部分可觀察關閉開關遊戲 (POSG)，這是關閉問題的博弈論模型，其中資訊不對稱。與人類擁有完全可觀察性不同，我們發現，在最佳博弈中，即使協助完全理性的 AI 代理有時也會避免關閉。正如預期的那樣，增加可用的溝通或資訊量總是會增加（或保持不變）代理的預期共同報酬。但反直覺的是，即使溝通可以減輕資訊不對稱，引入有界溝通也會讓 AI 在最佳博弈中較少服從人類。特別是，溝通有時會促成新的最佳行為，需要策略性 AI 服從才能達成以前無法達成的結果。因此，在存在資訊不對稱的情況下設計安全的 AI 代理，需要仔細考量在最大化報酬（可能近視）和維持 AI 服從人類的誘因之間的取捨。

##### **Privacy-Preserving Federated Foundation Model for Generalist Ultrasound Artificial Intelligence**
2411.16380v1 by Yuncheng Jiang, Chun-Mei Feng, Jinke Ren, Jun Wei, Zixun Zhang, Yiwen Hu, Yunbi Liu, Rui Sun, Xuemei Tang, Juan Du, Xiang Wan, Yong Xu, Bo Du, Xin Gao, Guangyu Wang, Shaohua Zhou, Shuguang Cui, Rick Siow Mong Goh, Yong Liu, Zhen Li

Ultrasound imaging is widely used in clinical diagnosis due to its
non-invasive nature and real-time capabilities. However, conventional
ultrasound diagnostics face several limitations, including high dependence on
physician expertise and suboptimal image quality, which complicates
interpretation and increases the likelihood of diagnostic errors. Artificial
intelligence (AI) has emerged as a promising solution to enhance clinical
diagnosis, particularly in detecting abnormalities across various biomedical
imaging modalities. Nonetheless, current AI models for ultrasound imaging face
critical challenges. First, these models often require large volumes of labeled
medical data, raising concerns over patient privacy breaches. Second, most
existing models are task-specific, which restricts their broader clinical
utility. To overcome these challenges, we present UltraFedFM, an innovative
privacy-preserving ultrasound foundation model. UltraFedFM is collaboratively
pre-trained using federated learning across 16 distributed medical institutions
in 9 countries, leveraging a dataset of over 1 million ultrasound images
covering 19 organs and 10 ultrasound modalities. This extensive and diverse
data, combined with a secure training framework, enables UltraFedFM to exhibit
strong generalization and diagnostic capabilities. It achieves an average area
under the receiver operating characteristic curve of 0.927 for disease
diagnosis and a dice similarity coefficient of 0.878 for lesion segmentation.
Notably, UltraFedFM surpasses the diagnostic accuracy of mid-level
ultrasonographers and matches the performance of expert-level sonographers in
the joint diagnosis of 8 common systemic diseases. These findings indicate that
UltraFedFM can significantly enhance clinical diagnostics while safeguarding
patient privacy, marking an advancement in AI-driven ultrasound imaging for
future clinical applications.

摘要：超音波影像因其非侵入性與即時性廣泛應用於臨床診斷。然而，傳統超音波診斷面臨數項限制，包括高度依賴醫師專業知識和次佳影像品質，這使得影像判讀更為複雜，並增加診斷錯誤的可能性。人工智慧 (AI) 已成為增強臨床診斷的潛在解決方案，特別是在偵測各種生物醫學影像模式中的異常。儘管如此，目前用於超音波影像的 AI 模型面臨嚴峻挑戰。首先，這些模型通常需要大量的標籤醫學資料，這引發了對病患隱私遭侵犯的疑慮。其次，現有的大部分模型都是針對特定任務而設計，這限制了它們在更廣泛的臨床應用。為了解決這些挑戰，我們提出了 UltraFedFM，一個創新的隱私保護超音波基礎模型。UltraFedFM 透過 9 個國家/地區的 16 個分散式醫療機構的聯合學習進行協作預訓練，利用包含超過 100 萬張超音波影像的資料集，涵蓋 19 個器官和 10 種超音波模式。這些廣泛且多樣化的資料，結合安全的訓練架構，使 UltraFedFM 能夠展現強大的概化和診斷能力。在疾病診斷方面，其受試者工作特徵曲線下的平均面積達到 0.927，在病灶分割方面，其 Dice 相似係數為 0.878。值得注意的是，UltraFedFM 超越了中階超音波檢查員的診斷準確性，並在 8 種常見全身性疾病的聯合診斷中達到專家級超音波檢查員的水準。這些發現表明，UltraFedFM 可以顯著增強臨床診斷，同時保護病患隱私，這標誌著 AI 驅動超音波影像在未來臨床應用中的一項進步。

##### **GEMeX: A Large-Scale, Groundable, and Explainable Medical VQA Benchmark for Chest X-ray Diagnosis**
2411.16778v1 by Bo Liu, Ke Zou, Liming Zhan, Zexin Lu, Xiaoyu Dong, Yidi Chen, Chengqiang Xie, Jiannong Cao, Xiao-Ming Wu, Huazhu Fu

Medical Visual Question Answering (VQA) is an essential technology that
integrates computer vision and natural language processing to automatically
respond to clinical inquiries about medical images. However, current medical
VQA datasets exhibit two significant limitations: (1) they often lack visual
and textual explanations for answers, which impedes their ability to satisfy
the comprehension needs of patients and junior doctors; (2) they typically
offer a narrow range of question formats, inadequately reflecting the diverse
requirements encountered in clinical scenarios. These limitations pose
significant challenges to the development of a reliable and user-friendly
Med-VQA system. To address these challenges, we introduce a large-scale,
Groundable, and Explainable Medical VQA benchmark for chest X-ray diagnosis
(GEMeX), featuring several innovative components: (1) A multi-modal
explainability mechanism that offers detailed visual and textual explanations
for each question-answer pair, thereby enhancing answer comprehensibility; (2)
Four distinct question types, open-ended, closed-ended, single-choice, and
multiple-choice, that better reflect diverse clinical needs. We evaluated 10
representative large vision language models on GEMeX and found that they
underperformed, highlighting the dataset's complexity. However, after
fine-tuning a baseline model using the training set, we observed a significant
performance improvement, demonstrating the dataset's effectiveness. The project
is available at www.med-vqa.com/GEMeX.

摘要：醫療視覺問答 (VQA) 是一項整合了電腦視覺和自然語言處理技術，用於自動回覆醫療影像相關臨床問題的基本技術。然而，現有的醫療 VQA 資料集有兩個主要的限制：(1) 它們通常缺乏答案的視覺和文字說明，這會阻礙它們滿足患者和初級醫師的理解需求；(2) 它們通常只提供狹窄範圍的問題格式，無法充分反映臨床場景中遇到的各種需求。這些限制對可靠且使用者友善的 Med-VQA 系統的開發構成了重大挑戰。為了應對這些挑戰，我們針對胸部 X 光診斷引入了大規模、可依據和可解釋的醫療 VQA 基準 (GEMeX)，它包含了幾個創新的組成部分：(1) 一種多模式可解釋性機制，它為每個問答對提供詳細的視覺和文字說明，從而增強答案的可理解性；(2) 四種不同的問題類型，開放式、封閉式、單選和多選，它們能更好地反映不同的臨床需求。我們在 GEMeX 中評估了 10 個具有代表性的大型視覺語言模型，發現它們的表現不佳，這凸顯了該資料集的複雜性。然而，在使用訓練集微調基準模型後，我們觀察到性能顯著提升，這證明了該資料集的有效性。該專案可在 www.med-vqa.com/GEMeX 找到。

##### **Med-PerSAM: One-Shot Visual Prompt Tuning for Personalized Segment Anything Model in Medical Domain**
2411.16123v1 by Hangyul Yoon, Doohyuk Jang, Jungeun Kim, Eunho Yang

Leveraging pre-trained models with tailored prompts for in-context learning
has proven highly effective in NLP tasks. Building on this success, recent
studies have applied a similar approach to the Segment Anything Model (SAM)
within a ``one-shot" framework, where only a single reference image and its
label are employed. However, these methods face limitations in the medical
domain, primarily due to SAM's essential requirement for visual prompts and the
over-reliance on pixel similarity for generating them. This dependency may lead
to (1) inaccurate prompt generation and (2) clustering of point prompts,
resulting in suboptimal outcomes. To address these challenges, we introduce
\textbf{Med-PerSAM}, a novel and straightforward one-shot framework designed
for the medical domain. Med-PerSAM uses only visual prompt engineering and
eliminates the need for additional training of the pretrained SAM or human
intervention, owing to our novel automated prompt generation process. By
integrating our lightweight warping-based prompt tuning model with SAM, we
enable the extraction and iterative refinement of visual prompts, enhancing the
performance of the pre-trained SAM. This advancement is particularly meaningful
in the medical domain, where creating visual prompts poses notable challenges
for individuals lacking medical expertise. Our model outperforms various
foundational models and previous SAM-based approaches across diverse 2D medical
imaging datasets.

摘要：利用預先訓練的模型，並針對特定提示進行情境學習，已證明在自然語言處理任務中非常有效。在此成功基礎上，最近的研究已將類似方法應用於「片段任何模型」(SAM)，採用「一次性」架構，其中僅使用單一參考影像及其標籤。然而，這些方法在醫療領域面臨限制，主要是由於 SAM 對視覺提示的基本需求，以及過度依賴像素相似性來產生它們。這種依賴性可能會導致 (1) 提示產生不準確，以及 (2) 點提示群集，導致結果次佳。為了應對這些挑戰，我們引入了 \textbf{Med-PerSAM}，這是一個專為醫療領域設計的新穎且直接的一次性架構。Med-PerSAM 僅使用視覺提示工程，並消除了對預訓練 SAM 或人為干預的額外訓練需求，這要歸功於我們新穎的自動化提示產生流程。透過將我們輕量級基於變形的提示調整模型與 SAM 整合，我們能夠提取和反覆改善視覺提示，增強預訓練 SAM 的效能。這項進展在醫療領域特別有意義，因為對於缺乏醫療專業知識的人來說，建立視覺提示會構成顯著的挑戰。我們的模型在各種 2D 醫學影像資料集上優於各種基礎模型和先前的基於 SAM 的方法。

##### **Why the Agent Made that Decision: Explaining Deep Reinforcement Learning with Vision Masks**
2411.16120v1 by Rui Zuo, Zifan Wang, Simon Khan, Garrett Ethan Katz, Qinru Qiu

Due to the inherent lack of transparency in deep neural networks, it is
challenging for deep reinforcement learning (DRL) agents to gain trust and
acceptance from users, especially in safety-critical applications such as
medical diagnosis and military operations. Existing methods for explaining an
agent's decision either require to retrain the agent using models that support
explanation generation or rely on perturbation-based techniques to reveal the
significance of different input features in the decision making process.
However, retraining the agent may compromise its integrity and performance,
while perturbation-based methods have limited performance and lack knowledge
accumulation or learning capabilities. Moreover, since each perturbation is
performed independently, the joint state of the perturbed inputs may not be
physically meaningful. To address these challenges, we introduce
$\textbf{VisionMask}$, a standalone explanation model trained end-to-end to
identify the most critical regions in the agent's visual input that can explain
its actions. VisionMask is trained in a self-supervised manner without relying
on human-generated labels. Importantly, its training does not alter the agent
model, hence preserving the agent's performance and integrity. We evaluate
VisionMask on Super Mario Bros (SMB) and three Atari games. Compared to
existing methods, VisionMask achieves a 14.9% higher insertion accuracy and a
30.08% higher F1-Score in reproducing original actions from the selected visual
explanations. We also present examples illustrating how VisionMask can be used
for counterfactual analysis.

摘要：<paragraph>由於深度神經網路缺乏透明度，深度強化學習 (DRL) 代理程式要獲得使用者的信任和認可是一項挑戰，特別是在安全關鍵的應用程式中，例如醫療診斷和軍事行動。現有的方法用於解釋代理程式的決策，需要使用支援解釋產生的模型重新訓練代理程式，或依賴於基於擾動的技術來揭示不同輸入特徵在決策制定過程中的重要性。然而，重新訓練代理程式可能會損害其完整性和效能，而基於擾動的方法效能有限，且缺乏知識累積或學習能力。此外，由於每個擾動都是獨立執行的，因此擾動輸入的聯合狀態可能沒有實際意義。為了應對這些挑戰，我們引入了 $\textbf{VisionMask}$，這是一個獨立的解釋模型，經過端對端的訓練，以識別代理程式視覺輸入中最關鍵的區域，這些區域可以解釋其動作。VisionMask 以自監督的方式進行訓練，而不依賴於人為產生的標籤。重要的是，其訓練不會改變代理程式模型，因此可以保留代理程式的效能和完整性。我們在 Super Mario Bros (SMB) 和三款 Atari 遊戲上評估了 VisionMask。與現有方法相比，VisionMask 在根據所選的視覺解釋複製原始動作時，插入準確率提高了 14.9%，F1 分數提高了 30.08%。我們還提供了範例來說明如何使用 VisionMask 進行反事實分析。</paragraph>

##### **DRIVE: Dual-Robustness via Information Variability and Entropic Consistency in Source-Free Unsupervised Domain Adaptation**
2411.15976v1 by Ruiqiang Xiao, Songning Lai, Yijun Yang, Jiemin Wu, Yutao Yue, Lei Zhu

Adapting machine learning models to new domains without labeled data,
especially when source data is inaccessible, is a critical challenge in
applications like medical imaging, autonomous driving, and remote sensing. This
task, known as Source-Free Unsupervised Domain Adaptation (SFUDA), involves
adapting a pre-trained model to a target domain using only unlabeled target
data, which can lead to issues such as overfitting, underfitting, and poor
generalization due to domain discrepancies and noise. Existing SFUDA methods
often rely on single-model architectures, struggling with uncertainty and
variability in the target domain. To address these challenges, we propose DRIVE
(Dual-Robustness through Information Variability and Entropy), a novel SFUDA
framework leveraging a dual-model architecture. The two models, initialized
with identical weights, work in parallel to capture diverse target domain
characteristics. One model is exposed to perturbations via projection gradient
descent (PGD) guided by mutual information, focusing on high-uncertainty
regions. We also introduce an entropy-aware pseudo-labeling strategy that
adjusts label weights based on prediction uncertainty, ensuring the model
focuses on reliable data while avoiding noisy regions. The adaptation process
has two stages: the first aligns the models on stable features using a mutual
information consistency loss, and the second dynamically adjusts the
perturbation level based on the loss from the first stage, encouraging the
model to explore a broader range of the target domain while preserving existing
performance. This enhances generalization capabilities and robustness against
interference. Evaluations on standard SFUDA benchmarks show that DRIVE
consistently outperforms previous methods, delivering improved adaptation
accuracy and stability across complex target domains.

摘要：<paragraph>在沒有標籤資料的情況下將機器學習模型調整到新的領域，特別是在無法取得原始資料時，是醫療影像、自動駕駛和遙測等應用中的一項關鍵挑戰。這項任務稱為無來源非監督領域適應 (SFUDA)，涉及使用僅有的未標籤目標資料將預先訓練的模型調整到目標領域，這可能會導致過度擬合、欠擬合和因領域差異和雜訊而導致的概化不良等問題。現有的 SFUDA 方法通常依賴於單一模型架構，難以應對目標領域中的不確定性和變異性。為了應對這些挑戰，我們提出了 DRIVE（透過資訊變異性和熵的雙重穩健性），一種利用雙模型架構的新穎 SFUDA 架構。這兩個模型以相同的權重初始化，並行工作以擷取不同的目標領域特徵。其中一個模型透過由互資訊引導的投影梯度下降 (PGD) 暴露於擾動，重點在於高度不確定的區域。我們還引入了一種熵感知偽標籤策略，該策略根據預測不確定性調整標籤權重，確保模型專注於可靠的資料，同時避免雜訊區域。適應過程分為兩個階段：第一個階段使用互資訊一致性損失在穩定特徵上對齊模型，第二個階段根據第一個階段的損失動態調整擾動級別，鼓勵模型探索目標領域的更廣泛範圍，同時保留現有的效能。這增強了概化能力和對干擾的穩健性。在標準 SFUDA 基準上的評估顯示，DRIVE 持續優於先前的各種方法，在複雜的目標領域中提供改善的適應準確性和穩定性。</paragraph>

##### **Improving Medical Diagnostics with Vision-Language Models: Convex Hull-Based Uncertainty Analysis**
2412.00056v1 by Ferhat Ozgur Catak, Murat Kuzlu, Taylor Patrick

In recent years, vision-language models (VLMs) have been applied to various
fields, including healthcare, education, finance, and manufacturing, with
remarkable performance. However, concerns remain regarding VLMs' consistency
and uncertainty, particularly in critical applications such as healthcare,
which demand a high level of trust and reliability. This paper proposes a novel
approach to evaluate uncertainty in VLMs' responses using a convex hull
approach on a healthcare application for Visual Question Answering (VQA).
LLM-CXR model is selected as the medical VLM utilized to generate responses for
a given prompt at different temperature settings, i.e., 0.001, 0.25, 0.50,
0.75, and 1.00. According to the results, the LLM-CXR VLM shows a high
uncertainty at higher temperature settings. Experimental outcomes emphasize the
importance of uncertainty in VLMs' responses, especially in healthcare
applications.

摘要：近年來，視覺語言模型 (VLM) 已應用於各種領域，包括醫療保健、教育、金融和製造業，並展現出卓越的效能。然而，對於 VLM 的一致性和不確定性仍有疑慮，特別是在醫療保健等關鍵應用中，這些應用需要高度的信任和可靠性。本文提出了一種新方法，使用凸包方法在視覺問答 (VQA) 的醫療保健應用中評估 VLM 回應的不確定性。LLM-CXR 模型被選為用於產生不同溫度設定下特定提示回應的醫療 VLM，即 0.001、0.25、0.50、0.75 和 1.00。根據結果，LLM-CXR VLM 在較高的溫度設定下顯示出高度的不確定性。實驗結果強調了 VLM 回應中不確定性的重要性，特別是在醫療保健應用中。

##### **Uncertainty-Aware Regularization for Image-to-Image Translation**
2412.01705v1 by Anuja Vats, Ivar Farup, Marius Pedersen, Kiran Raja

The importance of quantifying uncertainty in deep networks has become
paramount for reliable real-world applications. In this paper, we propose a
method to improve uncertainty estimation in medical Image-to-Image (I2I)
translation. Our model integrates aleatoric uncertainty and employs
Uncertainty-Aware Regularization (UAR) inspired by simple priors to refine
uncertainty estimates and enhance reconstruction quality. We show that by
leveraging simple priors on parameters, our approach captures more robust
uncertainty maps, effectively refining them to indicate precisely where the
network encounters difficulties, while being less affected by noise. Our
experiments demonstrate that UAR not only improves translation performance, but
also provides better uncertainty estimations, particularly in the presence of
noise and artifacts. We validate our approach using two medical imaging
datasets, showcasing its effectiveness in maintaining high confidence in
familiar regions while accurately identifying areas of uncertainty in
novel/ambiguous scenarios.

摘要：量化深度網路中的不確定性對於可靠的真實世界應用程式來說至關重要。在本文中，我們提出了一種方法來改善醫學影像轉影像 (I2I) 翻譯中的不確定性估計。我們的模型整合了隨機不確定性，並採用受簡單先驗啟發的不確定性感知正規化 (UAR) 來改善不確定性估計並增強重建品質。我們證明，透過利用參數上的簡單先驗，我們的做法能捕捉到更穩健的不確定性圖，並有效地改善這些圖，以精確地指出網路遭遇困難的地方，同時較不受雜訊影響。我們的實驗證明，UAR 不僅改善了翻譯效能，還提供了更好的不確定性估計，特別是在有雜訊和人工製品的情況下。我們使用兩個醫學影像資料集驗證了我們的做法，展示了它在維持熟悉區域的高信心，同時準確識別新穎/模糊場景中的不確定性區域方面的效能。

##### **Creating Scalable AGI: the Open General Intelligence Framework**
2411.15832v2 by Daniel A. Dollinger, Michael Singleton

Recent advancements in Artificial Intelligence (AI), particularly with Large
Language Models (LLMs), have led to significant progress in narrow tasks such
as image classification, language translation, coding, and writing. However,
these models face limitations in reliability and scalability due to their
siloed architectures, which are designed to handle only one data modality (data
type) at a time. This single modal approach hinders their ability to integrate
the complex set of data points required for real-world challenges and
problem-solving tasks like medical diagnosis, quality assurance, equipment
troubleshooting, and financial decision-making. Addressing these real-world
challenges requires a more capable Artificial General Intelligence (AGI)
system. Our primary contribution is the development of the Open General
Intelligence (OGI) framework, a novel systems architecture that serves as a
macro design reference for AGI. The OGI framework adopts a modular approach to
the design of intelligent systems, based on the premise that cognition must
occur across multiple specialized modules that can seamlessly operate as a
single system. OGI integrates these modules using a dynamic processing system
and a fabric interconnect, enabling real-time adaptability, multi-modal
integration, and scalable processing. The OGI framework consists of three key
components: (1) Overall Macro Design Guidance that directs operational design
and processing, (2) a Dynamic Processing System that controls routing, primary
goals, instructions, and weighting, and (3) Framework Areas, a set of
specialized modules that operate cohesively to form a unified cognitive system.
By incorporating known principles from human cognition into AI systems, the OGI
framework aims to overcome the challenges observed in today's intelligent
systems, paving the way for more holistic and context-aware problem-solving
capabilities.

摘要：<paragraph>人工智能（AI）的最新進展，特別是大型語言模型（LLM），在圖像分類、語言翻譯、編碼和寫作等狹義任務上取得了重大進展。然而，這些模型由於其孤立的架構而面臨可靠性和可擴展性限制，這些架構被設計為一次只能處理一種數據模式（數據類型）。這種單一模式方法阻礙了它們整合現實世界挑戰和問題解決任務（如醫療診斷、品質保證、設備故障排除和財務決策制定）所需的複雜數據點集的能力。解決這些現實世界的挑戰需要一個更強大的通用人工智能（AGI）系統。我們的首要貢獻是開發開放通用智能（OGI）框架，這是一種新穎的系統架構，可用作 AGI 的宏觀設計參考。OGI 框架採用模組化方法來設計智慧系統，基於認知必須發生在多個專門模組中，這些模組可以無縫地作為單一系統運作的前提。OGI 使用動態處理系統和結構互連整合這些模組，實現即時適應性、多模態整合和可擴展處理。OGI 框架包含三個關鍵組成部分：(1) 指導操作設計和處理的整體宏觀設計指導，(2) 控制路由、主要目標、指令和加權的動態處理系統，以及 (3) 框架領域，一組專門模組協同運作以形成統一的認知系統。通過將人類認知的已知原理整合到 AI 系統中，OGI 框架旨在克服當今智慧系統中觀察到的挑戰，為更全面和具備情境感知的問題解決能力鋪路。</paragraph>

##### **Medical Slice Transformer: Improved Diagnosis and Explainability on 3D Medical Images with DINOv2**
2411.15802v1 by Gustav Müller-Franzes, Firas Khader, Robert Siepmann, Tianyu Han, Jakob Nikolas Kather, Sven Nebelung, Daniel Truhn

MRI and CT are essential clinical cross-sectional imaging techniques for
diagnosing complex conditions. However, large 3D datasets with annotations for
deep learning are scarce. While methods like DINOv2 are encouraging for 2D
image analysis, these methods have not been applied to 3D medical images.
Furthermore, deep learning models often lack explainability due to their
"black-box" nature. This study aims to extend 2D self-supervised models,
specifically DINOv2, to 3D medical imaging while evaluating their potential for
explainable outcomes. We introduce the Medical Slice Transformer (MST)
framework to adapt 2D self-supervised models for 3D medical image analysis. MST
combines a Transformer architecture with a 2D feature extractor, i.e., DINOv2.
We evaluate its diagnostic performance against a 3D convolutional neural
network (3D ResNet) across three clinical datasets: breast MRI (651 patients),
chest CT (722 patients), and knee MRI (1199 patients). Both methods were tested
for diagnosing breast cancer, predicting lung nodule dignity, and detecting
meniscus tears. Diagnostic performance was assessed by calculating the Area
Under the Receiver Operating Characteristic Curve (AUC). Explainability was
evaluated through a radiologist's qualitative comparison of saliency maps based
on slice and lesion correctness. P-values were calculated using Delong's test.
MST achieved higher AUC values compared to ResNet across all three datasets:
breast (0.94$\pm$0.01 vs. 0.91$\pm$0.02, P=0.02), chest (0.95$\pm$0.01 vs.
0.92$\pm$0.02, P=0.13), and knee (0.85$\pm$0.04 vs. 0.69$\pm$0.05, P=0.001).
Saliency maps were consistently more precise and anatomically correct for MST
than for ResNet. Self-supervised 2D models like DINOv2 can be effectively
adapted for 3D medical imaging using MST, offering enhanced diagnostic accuracy
and explainability compared to convolutional neural networks.

摘要：<paragraph>MRI 和 CT 是诊断复杂疾病的重要临床横断面成像技术。然而，用于深度学习的大型 3D 数据集和注释却很稀缺。虽然诸如 DINOv2 之类的方法对 2D 图像分析很有帮助，但这些方法尚未应用于 3D 医学图像。此外，深度学习模型通常缺乏可解释性，因为它们具有“黑匣子”的性质。本研究旨在将 2D 自监督模型（特别是 DINOv2）扩展到 3D 医学成像，同时评估其对可解释结果的潜力。我们引入了医学切片转换器 (MST) 框架，以将 2D 自监督模型用于 3D 医学图像分析。MST 将 Transformer 架构与 2D 特征提取器（即 DINOv2）相结合。我们评估了其针对三个临床数据集（乳腺 MRI（651 名患者）、胸部 CT（722 名患者）和膝部 MRI（1199 名患者））的诊断性能，与 3D 卷积神经网络 (3D ResNet) 进行了对比。两种方法均经过测试，用于诊断乳腺癌、预测肺结节性质和检测半月板撕裂。通过计算受试者工作特征曲线下面积 (AUC) 来评估诊断性能。可解释性通过放射科医生对基于切片和病变正确性的显着性图的定性比较来评估。P 值使用 Delong 的检验计算。与所有三个数据集中的 ResNet 相比，MST 获得了更高的 AUC 值：乳腺（0.94±0.01 vs. 0.91±0.02，P=0.02）、胸部（0.95±0.01 vs. 0.92±0.02，P=0.13）和膝部（0.85±0.04 vs. 0.69±0.05，P=0.001）。与 ResNet 相比，MST 的显着性图始终更加精确且解剖学上更正确。诸如 DINOv2 之类的自监督 2D 模型可以使用 MST 有效地适应 3D 医学成像，与卷积神经网络相比，提供了增强的诊断准确性和可解释性。</paragraph>

##### **Enhancing the automatic segmentation and analysis of 3D liver vasculature models**
2411.15778v2 by Yassine Machta, Omar Ali, Kevin Hakkakian, Ana Vlasceanu, Amaury Facque, Nicolas Golse, Irene Vignon-Clementel

Surgical assessment of liver cancer patients requires identification of the
vessel trees from medical images. Specifically, the venous trees - the portal
(perfusing) and the hepatic (draining) trees are important for understanding
the liver anatomy and disease state, and perform surgery planning. This
research aims to improve the 3D segmentation, skeletonization, and subsequent
analysis of vessel trees, by creating an automatic pipeline based on deep
learning and image processing techniques.
  The first part of this work explores the impact of differentiable
skeletonization methods such as ClDice and morphological skeletonization loss,
on the overall liver vessel segmentation performance. To this aim, it studies
how to improve vessel tree connectivity.
  The second part of this study converts a single class vessel segmentation
into multi-class ones, separating the two venous trees. It builds on the
previous two-class vessel segmentation model, which vessel tree outputs might
be entangled, and on connected components and skeleton analyses of the trees.
  After providing sub-labeling of the specific anatomical branches of each
venous tree, these algorithms also enable a morphometric analysis of the vessel
trees by extracting various geometrical markers.
  In conclusion, we propose a method that successfully improves current
skeletonization methods, for extensive vascular trees that contain vessels of
different calibers. The separation algorithm creates a clean multi-class
segmentation of the vessels, validated by surgeons to provide low error. A new,
publicly shared high-quality liver vessel dataset of 77 cases is thus created.
Finally a method to annotate vessel trees according to anatomy is provided,
enabling a unique liver vessel morphometry analysis.

摘要：<paragraph>肝癌患者的手術評估需要從醫學影像中辨識血管樹。具體來說，靜脈樹 - 門靜脈（灌注）和肝靜脈（引流）樹對於了解肝臟解剖和疾病狀態以及執行手術規劃非常重要。本研究旨在通過建立基於深度學習和影像處理技術的自動化管道，改善血管樹的 3D 分割、骨架化和後續分析。
本工作的**第一部分**探討了可微分骨架化方法（例如 ClDice 和形態骨架化損失）對整體肝臟血管分割性能的影響。為此，它研究了如何改善血管樹連通性。
本研究的**第二部分**將單類別血管分割轉換為多類別血管分割，將兩棵靜脈樹分開。它建立在先前的兩類別血管分割模型之上，血管樹輸出可能糾纏在一起，並建立在樹的連接組成和骨架分析之上。
在對每個靜脈樹的特定解剖分支進行子標記後，這些算法還可以通過提取各種幾何標記對血管樹進行形態測量分析。
總之，我們提出了一種方法，可以成功改進當前的骨架化方法，適用於包含不同口徑血管的廣泛血管樹。分離算法創建了一個乾淨的多類別血管分割，經外科醫生驗證可提供低誤差。由此創建了一個新的、公開共享的 77 例高品質肝臟血管數據集。最後，提供了一種根據解剖標記血管樹的方法，能夠進行獨特的肝臟血管形態測量分析。</paragraph>

##### **RAMIE: Retrieval-Augmented Multi-task Information Extraction with Large Language Models on Dietary Supplements**
2411.15700v1 by Zaifu Zhan, Shuang Zhou, Mingchen Li, Rui Zhang

\textbf{Objective:} We aimed to develop an advanced multi-task large language
model (LLM) framework to extract multiple types of information about dietary
supplements (DS) from clinical records.
  \textbf{Methods:} We used four core DS information extraction tasks - namely,
named entity recognition (NER: 2,949 clinical sentences), relation extraction
(RE: 4,892 sentences), triple extraction (TE: 2,949 sentences), and usage
classification (UC: 2,460 sentences) as our multitasks. We introduced a novel
Retrieval-Augmented Multi-task Information Extraction (RAMIE) Framework,
including: 1) employed instruction fine-tuning techniques with task-specific
prompts, 2) trained LLMs for multiple tasks with improved storage efficiency
and lower training costs, and 3) incorporated retrieval augmentation generation
(RAG) techniques by retrieving similar examples from the training set. We
compared RAMIE's performance to LLMs with instruction fine-tuning alone and
conducted an ablation study to assess the contributions of multi-task learning
and RAG to improved multitasking performance.
  \textbf{Results:} With the aid of the RAMIE framework, Llama2-13B achieved an
F1 score of 87.39 (3.51\% improvement) on the NER task and demonstrated
outstanding performance on the RE task with an F1 score of 93.74 (1.15\%
improvement). For the TE task, Llama2-7B scored 79.45 (14.26\% improvement),
and MedAlpaca-7B achieved the highest F1 score of 93.45 (0.94\% improvement) on
the UC task. The ablation study revealed that while MTL increased efficiency
with a slight trade-off in performance, RAG significantly boosted overall
accuracy.
  \textbf{Conclusion:} This study presents a novel RAMIE framework that
demonstrates substantial improvements in multi-task information extraction for
DS-related data from clinical records. Our framework can potentially be applied
to other domains.

摘要：<paragraph>**目的：**我們旨在開發一個先進的多任務大型語言模型 (LLM) 架構，從臨床記錄中提取多種類型的膳食補充品 (DS) 資訊。
**方法：**我們使用了四項核心 DS 資訊提取任務，即命名實體識別 (NER：2,949 個臨床句子)、關係提取 (RE：4,892 個句子)、三元組提取 (TE：2,949 個句子) 和使用分類 (UC：2,460 個句子) 作為我們的多任務。我們引入了一個新的檢索增強多任務資訊提取 (RAMIE) 架構，包括：1) 使用任務特定提示的指令微調技術，2) 以更高的儲存效率和更低的訓練成本訓練多任務的 LLM，以及 3) 通過從訓練集中檢索類似範例，整合檢索增強生成 (RAG) 技術。我們將 RAMIE 的效能與僅使用指令微調的 LLM 進行比較，並進行消融研究，評估多任務學習和 RAG 對改善多任務效能的貢獻。
**結果：**在 RAMIE 架構的幫助下，Llama2-13B 在 NER 任務上取得了 87.39 的 F1 分數（提升了 3.51%），並在 RE 任務上表現出色，F1 分數為 93.74（提升了 1.15%）。對於 TE 任務，Llama2-7B 得分為 79.45（提升了 14.26%），而 MedAlpaca-7B 在 UC 任務上取得了最高的 F1 分數 93.45（提升了 0.94%）。消融研究表明，儘管 MTL 以略微犧牲效能為代價提高了效率，但 RAG 顯著提升了整體準確度。
**結論：**本研究提出了一個新的 RAMIE 架構，展示了從臨床記錄中提取與 DS 相關資料的多任務資訊的顯著改進。我們的架構有可能應用於其他領域。</paragraph>

##### **Ontology-Constrained Generation of Domain-Specific Clinical Summaries**
2411.15666v1 by Gaya Mehenni, Amal Zouaq

Large Language Models (LLMs) offer promising solutions for text
summarization. However, some domains require specific information to be
available in the summaries. Generating these domain-adapted summaries is still
an open challenge. Similarly, hallucinations in generated content is a major
drawback of current approaches, preventing their deployment. This study
proposes a novel approach that leverages ontologies to create domain-adapted
summaries both structured and unstructured. We employ an ontology-guided
constrained decoding process to reduce hallucinations while improving
relevance. When applied to the medical domain, our method shows potential in
summarizing Electronic Health Records (EHRs) across different specialties,
allowing doctors to focus on the most relevant information to their domain.
Evaluation on the MIMIC-III dataset demonstrates improvements in generating
domain-adapted summaries of clinical notes and hallucination reduction.

摘要：大型語言模型 (LLM) 為文字摘要提供了有前景的解決方案。然而，某些領域需要摘要中提供特定資訊。產生這些領域適應型摘要仍然是一項公開挑戰。同樣地，產生式內容中的幻覺是當前方法的一大缺點，阻礙了它們的部署。本研究提出了一種新穎的方法，利用本体論來建立結構化和非結構化的領域適應型摘要。我們採用本体論引導約束式解碼程序，以減少幻覺，同時提高相關性。當應用於醫學領域時，我們的這項方法顯示了跨不同專業領域摘要電子健康記錄 (EHR) 的潛力，讓醫生可以專注於與其領域最相關的資訊。在 MIMIC-III 資料集上的評估證明，在產生臨床筆記的領域適應型摘要和減少幻覺方面都有所改進。

##### **A Survey on LLM-as-a-Judge**
2411.15594v1 by Jiawei Gu, Xuhui Jiang, Zhichao Shi, Hexiang Tan, Xuehao Zhai, Chengjin Xu, Wei Li, Yinghan Shen, Shengjie Ma, Honghao Liu, Yuanzhuo Wang, Jian Guo

Accurate and consistent evaluation is crucial for decision-making across
numerous fields, yet it remains a challenging task due to inherent
subjectivity, variability, and scale. Large Language Models (LLMs) have
achieved remarkable success across diverse domains, leading to the emergence of
"LLM-as-a-Judge," where LLMs are employed as evaluators for complex tasks. With
their ability to process diverse data types and provide scalable,
cost-effective, and consistent assessments, LLMs present a compelling
alternative to traditional expert-driven evaluations. However, ensuring the
reliability of LLM-as-a-Judge systems remains a significant challenge that
requires careful design and standardization. This paper provides a
comprehensive survey of LLM-as-a-Judge, addressing the core question: How can
reliable LLM-as-a-Judge systems be built? We explore strategies to enhance
reliability, including improving consistency, mitigating biases, and adapting
to diverse assessment scenarios. Additionally, we propose methodologies for
evaluating the reliability of LLM-as-a-Judge systems, supported by a novel
benchmark designed for this purpose. To advance the development and real-world
deployment of LLM-as-a-Judge systems, we also discussed practical applications,
challenges, and future directions. This survey serves as a foundational
reference for researchers and practitioners in this rapidly evolving field.

摘要：<paragraph>準確且一致的評估對於各領域的決策制定至關重要，但由於固有的主觀性、變異性和規模，這仍然是一項具有挑戰性的任務。大型語言模型 (LLM) 已在不同領域取得顯著成功，導致「LLM 作為評審」的出現，其中 LLM 被用作複雜任務的評估者。憑藉處理各種數據類型並提供可擴充、經濟高效且一致的評估的能力，LLM 為傳統的專家驅動評估提供了令人信服的替代方案。然而，確保 LLM 作為評審系統的可靠性仍然是一個重大挑戰，需要仔細設計和標準化。本文對 LLM 作為評審進行了全面的調查，解決了核心問題：如何構建可靠的 LLM 作為評審系統？我們探討了提高可靠性的策略，包括提高一致性、減輕偏差和適應不同的評估場景。此外，我們提出了評估 LLM 作為評審系統可靠性的方法，並由為此目的設計的新基準測試提供支持。為了推進 LLM 作為評審系統的開發和實際部署，我們還討論了實際應用、挑戰和未來方向。本調查作為該快速發展領域的研究人員和從業人員的基本參考。</paragraph>

##### **Large Language Model with Region-guided Referring and Grounding for CT Report Generation**
2411.15539v1 by Zhixuan Chen, Yequan Bie, Haibo Jin, Hao Chen

Computed tomography (CT) report generation is crucial to assist radiologists
in interpreting CT volumes, which can be time-consuming and labor-intensive.
Existing methods primarily only consider the global features of the entire
volume, making it struggle to focus on specific regions and potentially missing
abnormalities. To address this issue, we propose Reg2RG, the first
region-guided referring and grounding framework for CT report generation, which
enhances diagnostic performance by focusing on anatomical regions within the
volume. Specifically, we utilize masks from a universal segmentation module to
capture local features for each referring region. A local feature decoupling
(LFD) strategy is proposed to preserve the local high-resolution details with
little computational overhead. Then the local features are integrated with
global features to capture inter-regional relationships within a cohesive
context. Moreover, we propose a novel region-report alignment (RRA) training
strategy. It leverages the recognition of referring regions to guide the
generation of region-specific reports, enhancing the model's referring and
grounding capabilities while also improving the report's interpretability. A
large language model (LLM) is further employed as the language decoder to
generate reports from integrated visual features, facilitating region-level
comprehension. Extensive experiments on two large-scale chest CT-report
datasets demonstrate the superiority of our method, which outperforms several
state-of-the-art methods in terms of both natural language generation and
clinical efficacy metrics while preserving promising interpretability. The code
will be made publicly available.

摘要：電腦斷層掃描 (CT) 報告生成對於協助放射科醫師判讀 CT 影像體積至關重要，而這項工作可能耗時且費力。現有方法主要只考量整個影像體積的全局特徵，導致難以聚焦於特定區域，並可能遺漏異常。為了解決這個問題，我們提出 Reg2RG，這是第一個針對 CT 報告生成的區域引導參照和基礎架構，透過聚焦於影像體積內的解剖區域，來增強診斷效能。具體來說，我們利用通用分割模組中的遮罩，來擷取每個參照區域的局部特徵。我們提出局部特徵解耦 (LFD) 策略，以在運算負擔不大的情況下保留局部高解析度細節。接著，局部特徵與全局特徵整合，以在一個有凝聚力的脈絡中擷取區域間的關係。此外，我們提出一個新穎的區域報告對齊 (RRA) 訓練策略。它利用參照區域的辨識來引導區域特定報告的生成，同時增強模型的參照和基礎能力，並改善報告的可解讀性。大型語言模型 (LLM) 進一步用作語言解碼器，以從整合的視覺特徵中生成報告，促進區域層級的理解。在兩個大規模胸部 CT 報告資料集上進行的廣泛實驗，證明了我們方法的優越性，在自然語言生成和臨床效能指標方面都優於多種最先進的方法，同時保留了良好的可解讀性。此程式碼將公開提供。

##### **GeoAI-Enhanced Community Detection on Spatial Networks with Graph Deep Learning**
2411.15428v1 by Yunlei Liang, Jiawei Zhu, Wen Ye, Song Gao

Spatial networks are useful for modeling geographic phenomena where spatial
interaction plays an important role. To analyze the spatial networks and their
internal structures, graph-based methods such as community detection have been
widely used. Community detection aims to extract strongly connected components
from the network and reveal the hidden relationships between nodes, but they
usually do not involve the attribute information. To consider edge-based
interactions and node attributes together, this study proposed a family of
GeoAI-enhanced unsupervised community detection methods called region2vec based
on Graph Attention Networks (GAT) and Graph Convolutional Networks (GCN). The
region2vec methods generate node neural embeddings based on attribute
similarity, geographic adjacency and spatial interactions, and then extract
network communities based on node embeddings using agglomerative clustering.
The proposed GeoAI-based methods are compared with multiple baselines and
perform the best when one wants to maximize node attribute similarity and
spatial interaction intensity simultaneously within the spatial network
communities. It is further applied in the shortage area delineation problem in
public health and demonstrates its promise in regionalization problems.

摘要：空間網路對於建模空間互動扮演重要角色的地理現象很有用。為了分析空間網路及其內部結構，基於圖形的方法，例如社群偵測已廣泛使用。社群偵測旨在從網路中提取強連結元件，並揭示節點之間的隱藏關係，但它們通常不涉及屬性資訊。為了同時考慮基於邊緣的互動和節點屬性，本研究提出了一系列稱為 region2vec 的 GeoAI 增強式非監督式社群偵測方法，該方法基於圖形注意力網路 (GAT) 和圖形卷積網路 (GCN)。region2vec 方法根據屬性相似性、地理鄰接性和空間互動產生節點神經嵌入，然後使用凝聚式分群根據節點嵌入提取網路社群。將提出的基於 GeoAI 的方法與多個基線進行比較，並在希望同時最大化空間網路社群中的節點屬性相似性和空間互動強度時執行最佳。進一步應用於公共衛生的短缺區域描繪問題中，並證明其在區域化問題中的前景。

##### **The Decoy Dilemma in Online Medical Information Evaluation: A Comparative Study of Credibility Assessments by LLM and Human Judges**
2411.15396v1 by Jiqun Liu, Jiangen He

Can AI be cognitively biased in automated information judgment tasks? Despite
recent progresses in measuring and mitigating social and algorithmic biases in
AI and large language models (LLMs), it is not clear to what extent LLMs behave
"rationally", or if they are also vulnerable to human cognitive bias triggers.
To address this open problem, our study, consisting of a crowdsourcing user
experiment and a LLM-enabled simulation experiment, compared the credibility
assessments by LLM and human judges under potential decoy effects in an
information retrieval (IR) setting, and empirically examined the extent to
which LLMs are cognitively biased in COVID-19 medical (mis)information
assessment tasks compared to traditional human assessors as a baseline. The
results, collected from a between-subject user experiment and a LLM-enabled
replicate experiment, demonstrate that 1) Larger and more recent LLMs tend to
show a higher level of consistency and accuracy in distinguishing credible
information from misinformation. However, they are more likely to give higher
ratings for misinformation due to the presence of a more salient, decoy
misinformation result; 2) While decoy effect occurred in both human and LLM
assessments, the effect is more prevalent across different conditions and
topics in LLM judgments compared to human credibility ratings. In contrast to
the generally assumed "rationality" of AI tools, our study empirically confirms
the cognitive bias risks embedded in LLM agents, evaluates the decoy impact on
LLMs against human credibility assessments, and thereby highlights the
complexity and importance of debiasing AI agents and developing
psychology-informed AI audit techniques and policies for automated judgment
tasks and beyond.

摘要：大型語言模型 (LLM) 是否會在自動化資訊判斷任務中產生認知偏差？儘管最近在衡量和減輕 AI 和大型語言模型 (LLM) 中的社會和演算法偏差方面取得了進展，但尚不清楚 LLM 在何種程度上表現出「理性」，或者它們是否也容易受到人類認知偏差觸發因素的影響。為了解決這個開放性問題，我們的研究包含群眾外包使用者實驗和 LLM 啟用的模擬實驗，比較了 LLM 和人類評審員在資訊檢索 (IR) 設定中的潛在誘餌效應下的可信度評估，並實證檢驗了 LLM 在 COVID-19 醫療 (錯誤) 資訊評估任務中與傳統人類評估員相比在認知偏差的程度。從受試者之間的使用者實驗和 LLM 啟用的複製實驗中收集的結果顯示，1) 較大且較新的 LLM 往往在區分可信資訊和錯誤資訊時表現出較高程度的一致性和準確性。然而，由於存在更顯著的誘餌錯誤資訊結果，它們更有可能對錯誤資訊給予較高的評分；2) 雖然誘餌效應發生在人類和 LLM 評估中，但與人類可信度評分相比，該效應在 LLM 判斷的不同條件和主題中更為普遍。與一般假設的 AI 工具「理性」相反，我們的研究實證證實了 LLM 代理中嵌入的認知偏差風險，評估了誘餌對 LLM 的影響，並根據人類可信度評估，從而突顯了消除 AI 代理偏差和開發心理學資訊 AI 稽核技術和政策的複雜性和重要性，以用於自動化判斷任務及其他任務。

##### **Regulator-Manufacturer AI Agents Modeling: Mathematical Feedback-Driven Multi-Agent LLM Framework**
2411.15356v1 by Yu Han, Zekun Guo

The increasing complexity of regulatory updates from global authorities
presents significant challenges for medical device manufacturers, necessitating
agile strategies to sustain compliance and maintain market access.
Concurrently, regulatory bodies must effectively monitor manufacturers'
responses and develop strategic surveillance plans. This study employs a
multi-agent modeling approach, enhanced with Large Language Models (LLMs), to
simulate regulatory dynamics and examine the adaptive behaviors of key actors,
including regulatory bodies, manufacturers, and competitors. These agents
operate within a simulated environment governed by regulatory flow theory,
capturing the impacts of regulatory changes on compliance decisions, market
adaptation, and innovation strategies. Our findings illuminate the influence of
regulatory shifts on industry behaviour and identify strategic opportunities
for improving regulatory practices, optimizing compliance, and fostering
innovation. By leveraging the integration of multi-agent systems and LLMs, this
research provides a novel perspective and offers actionable insights for
stakeholders navigating the evolving regulatory landscape of the medical device
industry.

摘要：隨著全球主管機關法規更新的日益複雜，醫療器材製造商面臨重大挑戰，需要靈活的策略來維持合規並保持市場准入。同時，法規機構必須有效監控製造商的回應，並制定策略性監控計畫。本研究採用多重代理人建模方法，並透過大型語言模型 (LLM) 加以強化，以模擬法規動態並檢視主要參與者（包括法規機構、製造商和競爭者）的適應行為。這些代理人運作在受法規流動理論支配的模擬環境中，捕捉法規變更對合規決策、市場適應和創新策略的影響。我們的研究結果闡明法規變動對產業行為的影響，並找出改善法規實務、最佳化合規和促進創新的策略性機會。透過整合多重代理人系統和 LLM，本研究提供一個新穎觀點，並為利害關係人提供可行的見解，以因應醫療器材產業不斷變遷的法規環境。

##### **Health AI Developer Foundations**
2411.15128v2 by Atilla P. Kiraly, Sebastien Baur, Kenneth Philbrick, Fereshteh Mahvar, Liron Yatziv, Tiffany Chen, Bram Sterling, Nick George, Fayaz Jamil, Jing Tang, Kai Bailey, Faruk Ahmed, Akshay Goel, Abbi Ward, Lin Yang, Andrew Sellergren, Yossi Matias, Avinatan Hassidim, Shravya Shetty, Daniel Golden, Shekoofeh Azizi, David F. Steiner, Yun Liu, Tim Thelin, Rory Pilgrim, Can Kirmizibayrak

Robust medical Machine Learning (ML) models have the potential to
revolutionize healthcare by accelerating clinical research, improving workflows
and outcomes, and producing novel insights or capabilities. Developing such ML
models from scratch is cost prohibitive and requires substantial compute, data,
and time (e.g., expert labeling). To address these challenges, we introduce
Health AI Developer Foundations (HAI-DEF), a suite of pre-trained,
domain-specific foundation models, tools, and recipes to accelerate building ML
for health applications. The models cover various modalities and domains,
including radiology (X-rays and computed tomography), histopathology,
dermatological imaging, and audio. These models provide domain specific
embeddings that facilitate AI development with less labeled data, shorter
training times, and reduced computational costs compared to traditional
approaches. In addition, we utilize a common interface and style across these
models, and prioritize usability to enable developers to integrate HAI-DEF
efficiently. We present model evaluations across various tasks and conclude
with a discussion of their application and evaluation, covering the importance
of ensuring efficacy, fairness, and equity. Finally, while HAI-DEF and
specifically the foundation models lower the barrier to entry for ML in
healthcare, we emphasize the importance of validation with problem- and
population-specific data for each desired usage setting. This technical report
will be updated over time as more modalities and features are added.

摘要：強大的醫療機器學習 (ML) 模型具有透過加速臨床研究、改善工作流程和成果，以及產生新見解或功能來革新醫療保健的潛力。從頭開發此類 ML 模型成本過高，且需要大量運算、資料和時間（例如，專家標記）。為了應對這些挑戰，我們引入了 Health AI Developer Foundations (HAI-DEF)，這是一套預先訓練好的、特定於領域的基礎模型、工具和食譜，用於加速建置醫療保健應用程式的 ML。這些模型涵蓋各種方式和領域，包括放射科（X 光和電腦斷層掃描）、組織病理學、皮膚影像和音訊。這些模型提供特定於領域的嵌入，與傳統方法相比，這些嵌入有助於使用較少標記資料、縮短訓練時間和降低運算成本來進行 AI 開發。此外，我們在這些模型中使用通用介面和樣式，並優先考慮可用性，以使開發人員能夠有效整合 HAI-DEF。我們針對各種任務提出模型評估，並在最後討論其應用和評估，涵蓋確保效能、公平性和公正性的重要性。最後，雖然 HAI-DEF 和特別是基礎模型降低了醫療保健中 ML 的進入門檻，但我們強調驗證對於每個所需的用法設定來說具有問題和特定於族群資料的重要性。隨著更多方式和功能的加入，這份技術報告將會隨著時間更新。

##### **ReXrank: A Public Leaderboard for AI-Powered Radiology Report Generation**
2411.15122v1 by Xiaoman Zhang, Hong-Yu Zhou, Xiaoli Yang, Oishi Banerjee, Julián N. Acosta, Josh Miller, Ouwen Huang, Pranav Rajpurkar

AI-driven models have demonstrated significant potential in automating
radiology report generation for chest X-rays. However, there is no standardized
benchmark for objectively evaluating their performance. To address this, we
present ReXrank, https://rexrank.ai, a public leaderboard and challenge for
assessing AI-powered radiology report generation. Our framework incorporates
ReXGradient, the largest test dataset consisting of 10,000 studies, and three
public datasets (MIMIC-CXR, IU-Xray, CheXpert Plus) for report generation
assessment. ReXrank employs 8 evaluation metrics and separately assesses models
capable of generating only findings sections and those providing both findings
and impressions sections. By providing this standardized evaluation framework,
ReXrank enables meaningful comparisons of model performance and offers crucial
insights into their robustness across diverse clinical settings. Beyond its
current focus on chest X-rays, ReXrank's framework sets the stage for
comprehensive evaluation of automated reporting across the full spectrum of
medical imaging.

摘要：人工智能驅動的模型已證明在自動化胸部 X 射線放射報告生成方面具有顯著的潛力。然而，沒有標準化的基準來客觀評估其性能。為了解決這個問題，我們提出了 ReXrank，https://rexrank.ai，一個公共排行榜和挑戰，用於評估 AI 驅動的放射報告生成。我們的框架包含 ReXGradient，這是由 10,000 項研究組成的最大測試數據集，以及三個公共數據集（MIMIC-CXR、IU-Xray、CheXpert Plus），用於報告生成評估。ReXrank 採用 8 項評估指標，並分別評估只能生成結果部分的模型和同時提供結果和印象部分的模型。通過提供這個標準化的評估框架，ReXrank 能夠對模型性能進行有意義的比較，並提供對其在不同臨床環境中穩健性的關鍵見解。除了目前關注胸部 X 射線之外，ReXrank 的框架還為跨越整個醫學影像範圍的自動化報告的全面評估奠定了基礎。

##### **Feature-interactive Siamese graph encoder-based image analysis to predict STAS from histopathology images in lung cancer**
2411.15274v1 by Liangrui Pan, Qingchun Liang, Wenwu Zeng, Yijun Peng, Zhenyu Zhao, Yiyi Liang, Jiadi Luo, Xiang Wang, Shaoliang Peng

Spread through air spaces (STAS) is a distinct invasion pattern in lung
cancer, crucial for prognosis assessment and guiding surgical decisions.
Histopathology is the gold standard for STAS detection, yet traditional methods
are subjective, time-consuming, and prone to misdiagnosis, limiting large-scale
applications. We present VERN, an image analysis model utilizing a
feature-interactive Siamese graph encoder to predict STAS from lung cancer
histopathological images. VERN captures spatial topological features with
feature sharing and skip connections to enhance model training. Using 1,546
histopathology slides, we built a large single-cohort STAS lung cancer dataset.
VERN achieved an AUC of 0.9215 in internal validation and AUCs of 0.8275 and
0.8829 in frozen and paraffin-embedded test sections, respectively,
demonstrating clinical-grade performance. Validated on a single-cohort and
three external datasets, VERN showed robust predictive performance and
generalizability, providing an open platform (http://plr.20210706.xyz:5000/) to
enhance STAS diagnosis efficiency and accuracy.

摘要：<paragraph>經由空氣腔（STAS）擴散是一種肺癌中獨特的侵襲模式，對於預後評估和引導手術決策至關重要。組織病理學是 STAS 檢測的黃金標準，但傳統方法主觀、耗時且容易誤診，限制了大規模應用。我們提出 VERN，一種利用特徵互動式連體圖編碼器從肺癌組織病理學影像預測 STAS 的影像分析模型。VERN 通過特徵共享和跳躍連接捕獲空間拓撲特徵，以增強模型訓練。使用 1,546 張組織病理學切片，我們建立了一個大型單一隊列 STAS 肺癌數據集。VERN 在內部驗證中達到 0.9215 的 AUC，在冷凍和石蠟包埋的試驗切片中分別達到 0.8275 和 0.8829 的 AUC，證明了臨床級的性能。在單一隊列和三個外部數據集上進行驗證，VERN 表現出穩健的預測性能和泛化能力，提供了一個開放平台 (http://plr.20210706.xyz:5000/)，以提高 STAS 診斷效率和準確性。</paragraph>

##### **Purrfessor: A Fine-tuned Multimodal LLaVA Diet Health Chatbot**
2411.14925v1 by Linqi Lu, Yifan Deng, Chuan Tian, Sijia Yang, Dhavan Shah

This study introduces Purrfessor, an innovative AI chatbot designed to
provide personalized dietary guidance through interactive, multimodal
engagement. Leveraging the Large Language-and-Vision Assistant (LLaVA) model
fine-tuned with food and nutrition data and a human-in-the-loop approach,
Purrfessor integrates visual meal analysis with contextual advice to enhance
user experience and engagement. We conducted two studies to evaluate the
chatbot's performance and user experience: (a) simulation assessments and human
validation were conducted to examine the performance of the fine-tuned model;
(b) a 2 (Profile: Bot vs. Pet) by 3 (Model: GPT-4 vs. LLaVA vs. Fine-tuned
LLaVA) experiment revealed that Purrfessor significantly enhanced users'
perceptions of care ($\beta = 1.59$, $p = 0.04$) and interest ($\beta = 2.26$,
$p = 0.01$) compared to the GPT-4 bot. Additionally, user interviews
highlighted the importance of interaction design details, emphasizing the need
for responsiveness, personalization, and guidance to improve user engagement.

摘要：本研究介紹了 Purrfessor，這是一種創新的 AI 聊天機器人，旨在透過互動式多模式參與提供個人化的飲食指導。Purrfessor 採用經過食物和營養資料微調的大語言和視覺助理 (LLaVA) 模型，以及人工介入的方式，將視覺化餐點分析與情境建議整合，以增強使用者體驗和參與度。我們進行了兩項研究，以評估聊天機器人的效能和使用者體驗：(a) 進行模擬評估和人工驗證，以檢驗微調模型的效能；(b) 一項 2 (個人資料：機器人與寵物) x 3 (模型：GPT-4 與 LLaVA 與微調 LLaVA) 實驗顯示，與 GPT-4 機器人相比，Purrfessor 大幅提升了使用者對於關懷 ($\beta = 1.59$，$p = 0.04$) 和興趣 ($\beta = 2.26$，$p = 0.01$) 的觀感。此外，使用者訪談強調了互動設計細節的重要性，強調需要回應性、個人化和指導，以提升使用者參與度。


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-04**|**Navigation World Models**|Amir Bar et.al.|[2412.03572v1](http://arxiv.org/abs/2412.03572v1)|null|
|**2024-12-04**|**The Matrix: Infinite-Horizon World Generation with Real-Time Moving Control**|Ruili Feng et.al.|[2412.03568v1](http://arxiv.org/abs/2412.03568v1)|null|
|**2024-12-04**|**From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents**|Xinyi Mou et.al.|[2412.03563v1](http://arxiv.org/abs/2412.03563v1)|null|
|**2024-12-04**|**FLAIR: VLM with Fine-grained Language-informed Image Representations**|Rui Xiao et.al.|[2412.03561v1](http://arxiv.org/abs/2412.03561v1)|[link](https://github.com/explainableml/flair)|
|**2024-12-04**|**Best-of-N Jailbreaking**|John Hughes et.al.|[2412.03556v1](http://arxiv.org/abs/2412.03556v1)|null|
|**2024-12-04**|**Perception Tokens Enhance Visual Reasoning in Multimodal Language Models**|Mahtab Bigverdi et.al.|[2412.03548v1](http://arxiv.org/abs/2412.03548v1)|null|
|**2024-12-04**|**NODE-AdvGAN: Improving the transferability and perceptual similarity of adversarial examples by dynamic-system-driven adversarial generative model**|Xinheng Xie et.al.|[2412.03539v1](http://arxiv.org/abs/2412.03539v1)|null|
|**2024-12-04**|**Evaluating Gender Bias Transfer between Pre-trained and Prompt-Adapted Language Models**|Natalie Mackraz et.al.|[2412.03537v1](http://arxiv.org/abs/2412.03537v1)|null|
|**2024-12-04**|**A Review on Scientific Knowledge Extraction using Large Language Models in Biomedical Sciences**|Gabriel Lino Garcia et.al.|[2412.03531v1](http://arxiv.org/abs/2412.03531v1)|null|
|**2024-12-04**|**FANAL -- Financial Activity News Alerting Language Modeling Framework**|Urjitkumar Patel et.al.|[2412.03527v1](http://arxiv.org/abs/2412.03527v1)|null|
|**2024-12-04**|**Feed-Forward Bullet-Time Reconstruction of Dynamic Scenes from Monocular Videos**|Hanxue Liang et.al.|[2412.03526v1](http://arxiv.org/abs/2412.03526v1)|null|
|**2024-12-04**|**You're (Not) My Type -- Can LLMs Generate Feedback of Specific Types for Introductory Programming Tasks?**|Dominic Lohr et.al.|[2412.03516v1](http://arxiv.org/abs/2412.03516v1)|null|
|**2024-12-04**|**KKLIP: Knowledge Distillation Exploiting K-means Clustering for Language-Image Pre-Training**|Kuei-Chun Kao et.al.|[2412.03513v1](http://arxiv.org/abs/2412.03513v1)|null|
|**2024-12-04**|**A Bidirectional Siamese Recurrent Neural Network for Accurate Gait Recognition Using Body Landmarks**|Proma Hossain Progga et.al.|[2412.03498v1](http://arxiv.org/abs/2412.03498v1)|null|
|**2024-12-04**|**Flow Matching with General Discrete Paths: A Kinetic-Optimal Perspective**|Neta Shaul et.al.|[2412.03487v1](http://arxiv.org/abs/2412.03487v1)|null|
|**2024-12-04**|**Training-Free Mitigation of Language Reasoning Degradation After Multimodal Instruction Tuning**|Neale Ratzlaff et.al.|[2412.03467v1](http://arxiv.org/abs/2412.03467v1)|null|
|**2024-12-04**|**From Words to Workflows: Automating Business Processes**|Laura Minkova et.al.|[2412.03446v1](http://arxiv.org/abs/2412.03446v1)|null|
|**2024-12-04**|**PBP: Post-training Backdoor Purification for Malware Classifiers**|Dung Thuy Nguyen et.al.|[2412.03441v1](http://arxiv.org/abs/2412.03441v1)|[link](https://github.com/judydnguyen/pbp-backdoor-purification-official)|
|**2024-12-04**|**BIMCaP: BIM-based AI-supported LiDAR-Camera Pose Refinement**|Miguel Arturo Vega Torres et.al.|[2412.03434v1](http://arxiv.org/abs/2412.03434v1)|[link](https://github.com/migvega/bimcap)|
|**2024-12-04**|**Automated Test-Case Generation for REST APIs Using Model Inference Search Heuristic**|Clinton Cao et.al.|[2412.03420v1](http://arxiv.org/abs/2412.03420v1)|null|
|**2024-12-04**|**Benchmarking Pretrained Attention-based Models for Real-Time Recognition in Robot-Assisted Esophagectomy**|Ronald L. P. D. de Jong et.al.|[2412.03401v1](http://arxiv.org/abs/2412.03401v1)|null|
|**2024-12-04**|**RedStone: Curating General, Code, Math, and QA Data for Large Language Models**|Yaoyao Chang et.al.|[2412.03398v1](http://arxiv.org/abs/2412.03398v1)|null|
|**2024-12-04**|**Enhancing Supply Chain Visibility with Generative AI: An Exploratory Case Study on Relationship Prediction in Knowledge Graphs**|Ge Zheng et.al.|[2412.03390v1](http://arxiv.org/abs/2412.03390v1)|null|
|**2024-12-04**|**DiffStyleTTS: Diffusion-based Hierarchical Prosody Modeling for Text-to-Speech with Diverse and Controllable Styles**|Jiaxuan Liu et.al.|[2412.03388v1](http://arxiv.org/abs/2412.03388v1)|null|
|**2024-12-04**|**WiS Platform: Enhancing Evaluation of LLM-Based Multi-Agent Systems Through Game-Based Analysis**|Chengwei Hu et.al.|[2412.03359v1](http://arxiv.org/abs/2412.03359v1)|null|
|**2024-12-04**|**Intuitive Axial Augmentation Using Polar-Sine-Based Piecewise Distortion for Medical Slice-Wise Segmentation**|Yiqin Zhang et.al.|[2412.03352v1](http://arxiv.org/abs/2412.03352v1)|[link](https://github.com/mgamz/psbpd)|
|**2024-12-04**|**DIVE: Taming DINO for Subject-Driven Video Editing**|Yi Huang et.al.|[2412.03347v1](http://arxiv.org/abs/2412.03347v1)|null|
|**2024-12-04**|**Improving Linguistic Diversity of Large Language Models with Possibility Exploration Fine-Tuning**|Long Mai et.al.|[2412.03343v1](http://arxiv.org/abs/2412.03343v1)|[link](https://github.com/mailong25/peft_diversity)|
|**2024-12-04**|**AI-Driven Day-to-Day Route Choice**|Leizhen Wang et.al.|[2412.03338v1](http://arxiv.org/abs/2412.03338v1)|null|
|**2024-12-04**|**Yankari: A Monolingual Yoruba Dataset**|Maro Akpobi et.al.|[2412.03334v1](http://arxiv.org/abs/2412.03334v1)|null|
|**2024-12-04**|**LuxEmbedder: A Cross-Lingual Approach to Enhanced Luxembourgish Sentence Embeddings**|Fred Philippy et.al.|[2412.03331v1](http://arxiv.org/abs/2412.03331v1)|null|
|**2024-12-04**|**Grounded Language Design for Lightweight Diagramming for Formal Methods**|Siddhartha Prasad et.al.|[2412.03310v1](http://arxiv.org/abs/2412.03310v1)|null|
|**2024-12-04**|**Contextual Data Integration for Bike-sharing Demand Prediction with Graph Neural Networks in Degraded Weather Conditions**|Romain Rochas et.al.|[2412.03307v1](http://arxiv.org/abs/2412.03307v1)|null|
|**2024-12-04**|**Global MMLU: Understanding and Addressing Cultural and Linguistic Biases in Multilingual Evaluation**|Shivalika Singh et.al.|[2412.03304v1](http://arxiv.org/abs/2412.03304v1)|null|
|**2024-12-04**|**Integrating Generative AI into Art Therapy: A Technical Showcase**|Yannis Valentin Schmutz et.al.|[2412.03287v1](http://arxiv.org/abs/2412.03287v1)|[link](https://github.com/bfh-ami/sds24)|
|**2024-12-04**|**Black-Box Forgery Attacks on Semantic Watermarks for Diffusion Models**|Andreas Müller et.al.|[2412.03283v1](http://arxiv.org/abs/2412.03283v1)|null|
|**2024-12-04**|**AntLM: Bridging Causal and Masked Language Models**|Xinru Yu et.al.|[2412.03275v1](http://arxiv.org/abs/2412.03275v1)|null|
|**2024-12-04**|**Intent-driven In-context Learning for Few-shot Dialogue State Tracking**|Zihao Yi et.al.|[2412.03270v1](http://arxiv.org/abs/2412.03270v1)|null|
|**2024-12-04**|**Alignment at Pre-training! Towards Native Alignment for Arabic LLMs**|Juhao Liang et.al.|[2412.03253v1](http://arxiv.org/abs/2412.03253v1)|[link](https://github.com/freedomintelligence/acegpt-v2)|
|**2024-12-04**|**AIM: Adaptive Inference of Multi-Modal LLMs via Token Merging and Pruning**|Yiwu Zhong et.al.|[2412.03248v1](http://arxiv.org/abs/2412.03248v1)|[link](https://github.com/lavi-lab/aim)|
|**2024-12-04**|**Benchmarking terminology building capabilities of ChatGPT on an English-Russian Fashion Corpus**|Anastasiia Bezobrazova et.al.|[2412.03242v1](http://arxiv.org/abs/2412.03242v1)|null|
|**2024-12-04**|**Does Safety Training of LLMs Generalize to Semantically Related Natural Prompts?**|Sravanti Addepalli et.al.|[2412.03235v1](http://arxiv.org/abs/2412.03235v1)|null|
|**2024-12-04**|**PERL: Pinyin Enhanced Rephrasing Language Model for Chinese ASR N-best Error Correction**|Junhong Liang et.al.|[2412.03230v1](http://arxiv.org/abs/2412.03230v1)|null|
|**2024-12-04**|**Linq-Embed-Mistral Technical Report**|Chanyeol Choi et.al.|[2412.03223v1](http://arxiv.org/abs/2412.03223v1)|null|
|**2024-12-04**|**ClusterKV: Manipulating LLM KV Cache in Semantic Space for Recallable Compression**|Guangda Liu et.al.|[2412.03213v1](http://arxiv.org/abs/2412.03213v1)|null|
|**2024-12-04**|**U-MATH: A University-Level Benchmark for Evaluating Mathematical Skills in LLMs**|Konstantin Chernyshev et.al.|[2412.03205v1](http://arxiv.org/abs/2412.03205v1)|null|
|**2024-12-04**|**Semi-decentralized Training of Spatio-Temporal Graph Neural Networks for Traffic Prediction**|Ivan Kralj et.al.|[2412.03188v1](http://arxiv.org/abs/2412.03188v1)|null|
|**2024-12-04**|**Weighted-Reward Preference Optimization for Implicit Model Fusion**|Ziyi Yang et.al.|[2412.03187v1](http://arxiv.org/abs/2412.03187v1)|[link](https://github.com/SLIT-AI/WRPO)|
|**2024-12-04**|**Optimizing Dense Visual Predictions Through Multi-Task Coherence and Prioritization**|Maxime Fontana et.al.|[2412.03179v1](http://arxiv.org/abs/2412.03179v1)|null|
|**2024-12-04**|**Towards Understanding and Quantifying Uncertainty for Text-to-Image Generation**|Gianni Franchi et.al.|[2412.03178v1](http://arxiv.org/abs/2412.03178v1)|null|
|**2024-12-04**|**Automatic detection of diseases in Spanish clinical notes combining medical language models and ontologies**|Leon-Paul Schaub Torre et.al.|[2412.03176v1](http://arxiv.org/abs/2412.03176v1)|null|
|**2024-12-04**|**Physics-Informed Deep Inverse Operator Networks for Solving PDE Inverse Problems**|Sung Woong Cho et.al.|[2412.03161v1](http://arxiv.org/abs/2412.03161v1)|null|
|**2024-12-04**|**Byte BPE Tokenization as an Inverse string Homomorphism**|Saibo Geng et.al.|[2412.03160v1](http://arxiv.org/abs/2412.03160v1)|null|
|**2024-12-04**|**Testing Neural Network Verifiers: A Soundness Benchmark with Hidden Counterexamples**|Xingjian Zhou et.al.|[2412.03154v1](http://arxiv.org/abs/2412.03154v1)|[link](https://github.com/mvp-harry/soundnessbench)|
|**2024-12-04**|**Large Language Models show both individual and collective creativity comparable to humans**|Luning Sun et.al.|[2412.03151v1](http://arxiv.org/abs/2412.03151v1)|null|
|**2024-12-04**|**Fine-Grained Behavior Simulation with Role-Playing Large Language Model on Social Media**|Kun Li et.al.|[2412.03148v1](http://arxiv.org/abs/2412.03148v1)|[link](https://github.com/linkseed18612254945/finerob)|
|**2024-12-04**|**Robust Multi-bit Text Watermark with LLM-based Paraphrasers**|Xiaojun Xu et.al.|[2412.03123v1](http://arxiv.org/abs/2412.03123v1)|[link](https://github.com/xiaojunxu/multi-bit-text-watermark)|
|**2024-12-04**|**Experience-driven discovery of planning strategies**|Ruiqi He et.al.|[2412.03111v1](http://arxiv.org/abs/2412.03111v1)|null|
|**2024-12-04**|**CredID: Credible Multi-Bit Watermark for Large Language Models Identification**|Haoyu Jiang et.al.|[2412.03107v1](http://arxiv.org/abs/2412.03107v1)|null|
|**2024-12-04**|**ChatTS: Aligning Time Series with LLMs via Synthetic Data for Enhanced Understanding and Reasoning**|Zhe Xie et.al.|[2412.03104v1](http://arxiv.org/abs/2412.03104v1)|null|
|**2024-12-04**|**A surprisal oracle for when every layer counts**|Xudong Hong et.al.|[2412.03098v1](http://arxiv.org/abs/2412.03098v1)|[link](https://github.com/asayeed/activebaby)|
|**2024-12-04**|**TOOL-ED: Enhancing Empathetic Response Generation with the Tool Calling Capability of LLM**|Huiying Cao et.al.|[2412.03096v1](http://arxiv.org/abs/2412.03096v1)|null|
|**2024-12-04**|**Revolve: Optimizing AI Systems by Tracking Response Evolution in Textual Optimization**|Peiyan Zhang et.al.|[2412.03092v1](http://arxiv.org/abs/2412.03092v1)|[link](https://github.com/peiyance/revolve)|
|**2024-12-04**|**ASR-EC Benchmark: Evaluating Large Language Models on Chinese ASR Error Correction**|Victor Junqiu Wei et.al.|[2412.03075v1](http://arxiv.org/abs/2412.03075v1)|null|
|**2024-12-04**|**Analytic Study of Text-Free Speech Synthesis for Raw Audio using a Self-Supervised Learning Model**|Joonyong Park et.al.|[2412.03074v1](http://arxiv.org/abs/2412.03074v1)|null|
|**2024-12-04**|**Preference-based opponent shaping in differentiable games**|Xinyu Qiao et.al.|[2412.03072v1](http://arxiv.org/abs/2412.03072v1)|null|
|**2024-12-04**|**UTSD: Unified Time Series Diffusion Model**|Xiangkai Ma et.al.|[2412.03068v1](http://arxiv.org/abs/2412.03068v1)|null|
|**2024-12-04**|**Point-GN: A Non-Parametric Network Using Gaussian Positional Encoding for Point Cloud Classification**|Marzieh Mohammadi et.al.|[2412.03056v1](http://arxiv.org/abs/2412.03056v1)|null|
|**2024-12-04**|**Less is More: A Stealthy and Efficient Adversarial Attack Method for DRL-based Autonomous Driving Policies**|Junchao Fan et.al.|[2412.03051v1](http://arxiv.org/abs/2412.03051v1)|null|
|**2024-12-04**|**MRNet: Multifaceted Resilient Networks for Medical Image-to-Image Translation**|Hyojeong Lee et.al.|[2412.03039v1](http://arxiv.org/abs/2412.03039v1)|null|
|**2024-12-04**|**MILLION: A General Multi-Objective Framework with Controllable Risk for Portfolio Management**|Liwei Deng et.al.|[2412.03038v1](http://arxiv.org/abs/2412.03038v1)|null|
|**2024-12-04**|**Specification Generation for Neural Networks in Systems**|Isha Chaudhary et.al.|[2412.03028v1](http://arxiv.org/abs/2412.03028v1)|null|
|**2024-12-04**|**Human Variability vs. Machine Consistency: A Linguistic Analysis of Texts Generated by Humans and Large Language Models**|Sergio E. Zanotto et.al.|[2412.03025v1](http://arxiv.org/abs/2412.03025v1)|null|
|**2024-12-04**|**PEMF-VVTO: Point-Enhanced Video Virtual Try-on via Mask-free Paradigm**|Tianyu Chang et.al.|[2412.03021v1](http://arxiv.org/abs/2412.03021v1)|null|
|**2024-12-04**|**Human Multi-View Synthesis from a Single-View Model:Transferred Body and Face Representations**|Yu Feng et.al.|[2412.03011v1](http://arxiv.org/abs/2412.03011v1)|null|
|**2024-12-04**|**Advancing Conversational Psychotherapy: Integrating Privacy, Dual-Memory, and Domain Expertise with Large Language Models**|XiuYu Zhang et.al.|[2412.02987v1](http://arxiv.org/abs/2412.02987v1)|null|
|**2024-12-04**|**Surveying the Effects of Quality, Diversity, and Complexity in Synthetic Data From Large Language Models**|Alex Havrilla et.al.|[2412.02980v1](http://arxiv.org/abs/2412.02980v1)|null|
|**2024-12-04**|**Theoretical limitations of multi-layer Transformer**|Lijie Chen et.al.|[2412.02975v1](http://arxiv.org/abs/2412.02975v1)|null|
|**2024-12-04**|**3D Interaction Geometric Pre-training for Molecular Relational Learning**|Namkyeong Lee et.al.|[2412.02957v1](http://arxiv.org/abs/2412.02957v1)|null|
|**2024-12-04**|**Curriculum-style Data Augmentation for LLM-based Metaphor Detection**|Kaidi Jia et.al.|[2412.02956v1](http://arxiv.org/abs/2412.02956v1)|null|
|**2024-12-04**|**Who Brings the Frisbee: Probing Hidden Hallucination Factors in Large Vision-Language Model via Causality Analysis**|Po-Hsuan Huang et.al.|[2412.02946v1](http://arxiv.org/abs/2412.02946v1)|null|
|**2024-12-04**|**STDCformer: A Transformer-Based Model with a Spatial-Temporal Causal De-Confounding Strategy for Crowd Flow Prediction**|Silu He et.al.|[2412.02942v1](http://arxiv.org/abs/2412.02942v1)|null|
|**2024-12-04**|**Dynamic Graph Neural Ordinary Differential Equation Network for Multi-modal Emotion Recognition in Conversation**|Yuntao Shou et.al.|[2412.02935v1](http://arxiv.org/abs/2412.02935v1)|null|
|**2024-12-04**|**Panoptic Diffusion Models: co-generation of images and segmentation maps**|Yinghan Long et.al.|[2412.02929v1](http://arxiv.org/abs/2412.02929v1)|null|
|**2024-12-04**|**Higher Order Transformers: Efficient Attention Mechanism for Tensor Structured Data**|Soroush Omranpour et.al.|[2412.02919v1](http://arxiv.org/abs/2412.02919v1)|null|
|**2024-12-03**|**Single-Cell Omics Arena: A Benchmark Study for Large Language Models on Cell Type Annotation Using Single-Cell Data**|Junhao Liu et.al.|[2412.02915v1](http://arxiv.org/abs/2412.02915v1)|null|
|**2024-12-03**|**Does Few-Shot Learning Help LLM Performance in Code Synthesis?**|Derek Xu et.al.|[2412.02906v1](http://arxiv.org/abs/2412.02906v1)|null|
|**2024-12-03**|**Enhancing Trust in Large Language Models with Uncertainty-Aware Fine-Tuning**|Ranganath Krishnan et.al.|[2412.02904v1](http://arxiv.org/abs/2412.02904v1)|null|
|**2024-12-03**|**MLD-EA: Check and Complete Narrative Coherence by Introducing Emotions and Actions**|Jinming Zhang et.al.|[2412.02897v1](http://arxiv.org/abs/2412.02897v1)|null|
|**2024-12-03**|**Removing Spurious Correlation from Neural Network Interpretations**|Milad Fotouhi et.al.|[2412.02893v1](http://arxiv.org/abs/2412.02893v1)|null|
|**2024-12-03**|**TDD-Bench Verified: Can LLMs Generate Tests for Issues Before They Get Resolved?**|Toufique Ahmed et.al.|[2412.02883v1](http://arxiv.org/abs/2412.02883v1)|null|
|**2024-12-03**|**Modeling and Discovering Direct Causes for Predictive Models**|Yizuo Chen et.al.|[2412.02878v1](http://arxiv.org/abs/2412.02878v1)|null|
|**2024-12-03**|**Constrained Identifiability of Causal Effects**|Yizuo Chen et.al.|[2412.02869v1](http://arxiv.org/abs/2412.02869v1)|null|
|**2024-12-03**|**A Novel Compact LLM Framework for Local, High-Privacy EHR Data Applications**|Yixiang Qu et.al.|[2412.02868v1](http://arxiv.org/abs/2412.02868v1)|null|
|**2024-12-03**|**Unpaired Modality Translation for Pseudo Labeling of Histology Images**|Arthur Boschet et.al.|[2412.02858v1](http://arxiv.org/abs/2412.02858v1)|null|
|**2024-12-03**|**FLAME 3 Dataset: Unleashing the Power of Radiometric Thermal UAV Imagery for Wildfire Management**|Bryce Hopkins et.al.|[2412.02831v1](http://arxiv.org/abs/2412.02831v1)|null|
|**2024-12-03**|**RARE: Retrieval-Augmented Reasoning Enhancement for Large Language Models**|Hieu Tran et.al.|[2412.02830v1](http://arxiv.org/abs/2412.02830v1)|null|
|**2024-12-03**|**Minimization of Boolean Complexity in In-Context Concept Learning**|Leroy Z. Wang et.al.|[2412.02823v1](http://arxiv.org/abs/2412.02823v1)|null|
|**2024-12-03**|**CNNSum: Exploring Long-Conext Summarization with Large Language Models in Chinese Novels**|Lingxiao Wei et.al.|[2412.02819v1](http://arxiv.org/abs/2412.02819v1)|null|
|**2024-12-03**|**Gaussian Splatting Under Attack: Investigating Adversarial Noise in 3D Objects**|Abdurrahman Zeybey et.al.|[2412.02803v1](http://arxiv.org/abs/2412.02803v1)|null|

#### Abstracts
##### **Navigation World Models**
2412.03572v1 by Amir Bar, Gaoyue Zhou, Danny Tran, Trevor Darrell, Yann LeCun

Navigation is a fundamental skill of agents with visual-motor capabilities.
We introduce a Navigation World Model (NWM), a controllable video generation
model that predicts future visual observations based on past observations and
navigation actions. To capture complex environment dynamics, NWM employs a
Conditional Diffusion Transformer (CDiT), trained on a diverse collection of
egocentric videos of both human and robotic agents, and scaled up to 1 billion
parameters. In familiar environments, NWM can plan navigation trajectories by
simulating them and evaluating whether they achieve the desired goal. Unlike
supervised navigation policies with fixed behavior, NWM can dynamically
incorporate constraints during planning. Experiments demonstrate its
effectiveness in planning trajectories from scratch or by ranking trajectories
sampled from an external policy. Furthermore, NWM leverages its learned visual
priors to imagine trajectories in unfamiliar environments from a single input
image, making it a flexible and powerful tool for next-generation navigation
systems.

摘要：導航是具備視覺運動能力的代理人的一項基本技能。
我們引入導航世界模型 (NWM)，這是一個可控制的影片生成模型，它基於過去的觀察和導航動作來預測未來的視覺觀察。為了捕捉複雜的環境動態，NWM 採用條件擴散轉換器 (CDiT)，它在人類和機器人代理人的各種以自我為中心影片的集合上進行訓練，並擴展到 10 億個參數。在熟悉的環境中，NWM 可以透過模擬導航軌跡並評估它們是否達成所需目標，來規劃導航軌跡。與具有固定行為的監督式導航策略不同，NWM 可以動態地將限制納入規劃中。實驗證明了它在從頭開始規劃軌跡或從外部策略中取樣軌跡並對其進行排名方面的有效性。此外，NWM 利用其學習的視覺先驗，從單一輸入影像想像在不熟悉環境中的軌跡，這使其成為下一代導航系統的靈活且強大的工具。

##### **The Matrix: Infinite-Horizon World Generation with Real-Time Moving Control**
2412.03568v1 by Ruili Feng, Han Zhang, Zhantao Yang, Jie Xiao, Zhilei Shu, Zhiheng Liu, Andy Zheng, Yukun Huang, Yu Liu, Hongyang Zhang

We present The Matrix, the first foundational realistic world simulator
capable of generating continuous 720p high-fidelity real-scene video streams
with real-time, responsive control in both first- and third-person
perspectives, enabling immersive exploration of richly dynamic environments.
Trained on limited supervised data from AAA games like Forza Horizon 5 and
Cyberpunk 2077, complemented by large-scale unsupervised footage from
real-world settings like Tokyo streets, The Matrix allows users to traverse
diverse terrains -- deserts, grasslands, water bodies, and urban landscapes --
in continuous, uncut hour-long sequences. Operating at 16 FPS, the system
supports real-time interactivity and demonstrates zero-shot generalization,
translating virtual game environments to real-world contexts where collecting
continuous movement data is often infeasible. For example, The Matrix can
simulate a BMW X3 driving through an office setting--an environment present in
neither gaming data nor real-world sources. This approach showcases the
potential of AAA game data to advance robust world models, bridging the gap
between simulations and real-world applications in scenarios with limited data.

摘要：我們展示了 The Matrix，這是第一個基礎性的逼真世界模擬器
能夠產生連續的 720p 高保真實場景影片串流
在第一人稱和第三人稱
視角中進行即時、靈敏的控制，讓身歷其境的探索豐富動態的環境。
使用來自 AAA 遊戲（例如 Forza Horizon 5 和
Cyberpunk 2077）的有限監督數據進行訓練，並輔以來自
東京街頭等真實世界場景的大規模無監督片段，The Matrix 允許使用者穿越
各種地形——沙漠、草原、水體和城市景觀——
在連續、未剪輯的一小時序列中。系統以 16 FPS 運作
支援即時互動，並展示零次學習泛化，
將虛擬遊戲環境轉換為真實世界的環境，在其中收集
連續的移動數據通常不可行。例如，The Matrix 可以
模擬 BMW X3 在辦公室環境中行駛——一個既不在遊戲數據中也不在真實世界來源中的環境。這種方法展示了
AAA 遊戲數據在推進強健世界模型方面的潛力，縮小了
模擬和真實世界應用之間的差距，在資料有限的情況下。

##### **From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents**
2412.03563v1 by Xinyi Mou, Xuanwen Ding, Qi He, Liang Wang, Jingcong Liang, Xinnong Zhang, Libo Sun, Jiayu Lin, Jie Zhou, Xuanjing Huang, Zhongyu Wei

Traditional sociological research often relies on human participation, which,
though effective, is expensive, challenging to scale, and with ethical
concerns. Recent advancements in large language models (LLMs) highlight their
potential to simulate human behavior, enabling the replication of individual
responses and facilitating studies on many interdisciplinary studies. In this
paper, we conduct a comprehensive survey of this field, illustrating the recent
progress in simulation driven by LLM-empowered agents. We categorize the
simulations into three types: (1) Individual Simulation, which mimics specific
individuals or demographic groups; (2) Scenario Simulation, where multiple
agents collaborate to achieve goals within specific contexts; and (3) Society
Simulation, which models interactions within agent societies to reflect the
complexity and variety of real-world dynamics. These simulations follow a
progression, ranging from detailed individual modeling to large-scale societal
phenomena. We provide a detailed discussion of each simulation type, including
the architecture or key components of the simulation, the classification of
objectives or scenarios and the evaluation method. Afterward, we summarize
commonly used datasets and benchmarks. Finally, we discuss the trends across
these three types of simulation. A repository for the related sources is at
{\url{https://github.com/FudanDISC/SocialAgent}}.

摘要：傳統的社會學研究通常依賴於人類參與，儘管有效，但代價高昂、難以擴展，且有道德上的疑慮。大型語言模型 (LLM) 的最新進展突顯了它們模擬人類行為的潛力，能夠複製個別反應並促進許多跨領域研究的研究。在本文中，我們對這個領域進行全面調查，說明由 LLM 賦能的代理驅動的模擬的最新進展。我們將模擬分類為三種類型：(1) 個體模擬，模擬特定個人或人口群體；(2) 情境模擬，其中多個代理協作在特定情境中達成目標；(3) 社會模擬，模擬代理社會中的互動，以反映現實世界動態的複雜性和多樣性。這些模擬遵循一個進程，從詳細的個體建模到大型社會現象。我們對每種類型的模擬進行詳細討論，包括模擬的架構或關鍵組成部分、目標或情境的分類以及評估方法。之後，我們總結常用資料集和基準。最後，我們討論這三種類型模擬的趨勢。相關資源的存放庫位於 {\url{https://github.com/FudanDISC/SocialAgent}}。

##### **FLAIR: VLM with Fine-grained Language-informed Image Representations**
2412.03561v1 by Rui Xiao, Sanghwan Kim, Mariana-Iuliana Georgescu, Zeynep Akata, Stephan Alaniz

CLIP has shown impressive results in aligning images and texts at scale.
However, its ability to capture detailed visual features remains limited
because CLIP matches images and texts at a global level. To address this issue,
we propose FLAIR, Fine-grained Language-informed Image Representations, an
approach that utilizes long and detailed image descriptions to learn localized
image embeddings. By sampling diverse sub-captions that describe fine-grained
details about an image, we train our vision-language model to produce not only
global embeddings but also text-specific image representations. Our model
introduces text-conditioned attention pooling on top of local image tokens to
produce fine-grained image representations that excel at retrieving detailed
image content. We achieve state-of-the-art performance on both, existing
multimodal retrieval benchmarks, as well as, our newly introduced fine-grained
retrieval task which evaluates vision-language models' ability to retrieve
partial image content. Furthermore, our experiments demonstrate the
effectiveness of FLAIR trained on 30M image-text pairs in capturing
fine-grained visual information, including zero-shot semantic segmentation,
outperforming models trained on billions of pairs. Code is available at
https://github.com/ExplainableML/flair .

摘要：CLIP 在大規模影像和文字比對上展現令人印象深刻的成果。
然而，它擷取詳細視覺特徵的能力仍然有限，
因為 CLIP 在全球層級上比對影像和文字。為了解決這個問題，
我們提出 FLAIR，一種精細化的語言資訊影像表徵，一種
利用長而詳細的影像描述來學習區域化
影像嵌入的方法。透過取樣描述影像精細化
細節的多樣化子標題，我們訓練我們的視覺語言模型，不僅產生
整體嵌入，也產生特定文字的影像表徵。我們的模型
在區域影像標記上引進文字條件注意池化，以
產生精細化的影像表徵，這些表徵擅長擷取詳細
影像內容。我們在現有的
多模態檢索基準上以及我們新推出的精細化
檢索任務上達成最先進的表現，該任務評估視覺語言模型擷取
部分影像內容的能力。此外，我們的實驗證明，在 30M 影像文字對上訓練的 FLAIR 在擷取
精細化的視覺資訊上很有效，包括零次學習語意分割，
表現優於在數十億對上訓練的模型。程式碼可在
https://github.com/ExplainableML/flair 取得。

##### **Best-of-N Jailbreaking**
2412.03556v1 by John Hughes, Sara Price, Aengus Lynch, Rylan Schaeffer, Fazl Barez, Sanmi Koyejo, Henry Sleight, Erik Jones, Ethan Perez, Mrinank Sharma

We introduce Best-of-N (BoN) Jailbreaking, a simple black-box algorithm that
jailbreaks frontier AI systems across modalities. BoN Jailbreaking works by
repeatedly sampling variations of a prompt with a combination of augmentations
- such as random shuffling or capitalization for textual prompts - until a
harmful response is elicited. We find that BoN Jailbreaking achieves high
attack success rates (ASRs) on closed-source language models, such as 89% on
GPT-4o and 78% on Claude 3.5 Sonnet when sampling 10,000 augmented prompts.
Further, it is similarly effective at circumventing state-of-the-art
open-source defenses like circuit breakers. BoN also seamlessly extends to
other modalities: it jailbreaks vision language models (VLMs) such as GPT-4o
and audio language models (ALMs) like Gemini 1.5 Pro, using modality-specific
augmentations. BoN reliably improves when we sample more augmented prompts.
Across all modalities, ASR, as a function of the number of samples (N),
empirically follows power-law-like behavior for many orders of magnitude. BoN
Jailbreaking can also be composed with other black-box algorithms for even more
effective attacks - combining BoN with an optimized prefix attack achieves up
to a 35% increase in ASR. Overall, our work indicates that, despite their
capability, language models are sensitive to seemingly innocuous changes to
inputs, which attackers can exploit across modalities.

摘要：<paragraph>我們推出 Best-of-N (BoN) 越獄，這是一種簡單的黑盒子演算法，可以越獄跨模態的邊界 AI 系統。BoN 越獄透過重複抽樣提示的變異，並結合增強功能（例如隨機洗牌或對文字提示進行大小寫變換），直到引發有害回應為止。我們發現 BoN 越獄在封閉原始碼語言模型上達到很高的攻擊成功率 (ASR)，例如在抽樣 10,000 個增強提示時，GPT-4o 上為 89%，而 Claude 3.5 Sonnet 上為 78%。此外，它在規避電路中斷器等最先進的開源防禦方面也同樣有效。BoN 也能無縫延伸到其他模態：它透過使用特定於模態的增強功能，越獄了視覺語言模型 (VLM)，例如 GPT-4o，以及音訊語言模型 (ALM)，例如 Gemini 1.5 Pro。當我們抽樣更多增強提示時，BoN 會可靠地提升。在所有模態中，ASR 作為樣本數 (N) 的函數，在許多數量級上都經驗性地遵循冪律行為。BoN 越獄也可以與其他黑盒子演算法結合，以進行更有效的攻擊 - 將 BoN 與最佳化字首攻擊結合，可將 ASR 提升多達 35%。總體而言，我們的研究指出，儘管語言模型具有能力，但它們對輸入的看似無害變更很敏感，而攻擊者可以跨模態利用這一點。</paragraph>

##### **Perception Tokens Enhance Visual Reasoning in Multimodal Language Models**
2412.03548v1 by Mahtab Bigverdi, Zelun Luo, Cheng-Yu Hsieh, Ethan Shen, Dongping Chen, Linda G. Shapiro, Ranjay Krishna

Multimodal language models (MLMs) still face challenges in fundamental visual
perception tasks where specialized models excel. Tasks requiring reasoning
about 3D structures benefit from depth estimation, and reasoning about 2D
object instances benefits from object detection. Yet, MLMs can not produce
intermediate depth or boxes to reason over. Finetuning MLMs on relevant data
doesn't generalize well and outsourcing computation to specialized vision tools
is too compute-intensive and memory-inefficient. To address this, we introduce
Perception Tokens, intrinsic image representations designed to assist reasoning
tasks where language is insufficient. Perception tokens act as auxiliary
reasoning tokens, akin to chain-of-thought prompts in language models. For
example, in a depth-related task, an MLM augmented with perception tokens can
reason by generating a depth map as tokens, enabling it to solve the problem
effectively. We propose AURORA, a training method that augments MLMs with
perception tokens for improved reasoning over visual inputs. AURORA leverages a
VQVAE to transform intermediate image representations, such as depth maps into
a tokenized format and bounding box tokens, which is then used in a multi-task
training framework. AURORA achieves notable improvements across counting
benchmarks: +10.8% on BLINK, +11.3% on CVBench, and +8.3% on SEED-Bench,
outperforming finetuning approaches in generalization across datasets. It also
improves on relative depth: over +6% on BLINK. With perception tokens, AURORA
expands the scope of MLMs beyond language-based reasoning, paving the way for
more effective visual reasoning capabilities.

摘要：多模态语言模型 (MLM) 在专门模型表现优异的基本视觉感知任务中仍然面临挑战。需要对 3D 结构进行推理的任务受益于深度估计，而对 2D 对象实例进行推理受益于对象检测。然而，MLM 无法产生中间深度或框来进行推理。针对相关数据微调 MLM 在泛化能力方面表现不佳，而将计算外包给专门的视觉工具则过于计算密集且内存效率低下。为了解决这个问题，我们引入了感知标记，这是旨在辅助语言不足的推理任务的内在图像表示。感知标记充当辅助推理标记，类似于语言模型中的思想链提示。例如，在与深度相关的任务中，使用感知标记增强后的 MLM 可以通过生成深度图作为标记来进行推理，从而有效地解决问题。我们提出了 AURORA，这是一种训练方法，它使用感知标记增强 MLM，以改进对视觉输入的推理。AURORA 利用 VQVAE 将中间图像表示（例如深度图）转换为标记化格式和边界框标记，然后在多任务训练框架中使用。AURORA 在计数基准测试中取得了显着改进：BLINK 提高了 +10.8%，CVBench 提高了 +11.3%，SEED-Bench 提高了 +8.3%，在数据集中的泛化能力方面优于微调方法。它还改进了相对深度：BLINK 提高了 +6% 以上。有了感知标记，AURORA 将 MLM 的范围扩展到了基于语言的推理之外，为更有效的视觉推理能力铺平了道路。

##### **NODE-AdvGAN: Improving the transferability and perceptual similarity of adversarial examples by dynamic-system-driven adversarial generative model**
2412.03539v1 by Xinheng Xie, Yue Wu, Cuiyu He

Understanding adversarial examples is crucial for improving the model's
robustness, as they introduce imperceptible perturbations that deceive models.
Effective adversarial examples, therefore, offer the potential to train more
robust models by removing their singularities. We propose NODE-AdvGAN, a novel
approach that treats adversarial generation as a continuous process and employs
a Neural Ordinary Differential Equation (NODE) for simulating the dynamics of
the generator. By mimicking the iterative nature of traditional gradient-based
methods, NODE-AdvGAN generates smoother and more precise perturbations that
preserve high perceptual similarity when added to benign images. We also
propose a new training strategy, NODE-AdvGAN-T, which enhances transferability
in black-box attacks by effectively tuning noise parameters during training.
Experiments demonstrate that NODE-AdvGAN and NODE-AdvGAN-T generate more
effective adversarial examples that achieve higher attack success rates while
preserving better perceptual quality than traditional GAN-based methods.

摘要：了解對抗性範例對於提升模型的穩健性至關重要，因為它們引入了難以察覺的擾動，欺騙了模型。因此，有效的對抗性範例提供了透過移除其奇異性來訓練更穩健模型的潛力。我們提出了 NODE-AdvGAN，這是一種新穎的方法，將對抗性生成視為一個連續的過程，並採用神經常微分方程式 (NODE) 來模擬生成器的動態。透過模仿傳統基於梯度的迭代方法，NODE-AdvGAN 產生更平滑且更精確的擾動，在添加到良性影像時，仍能保持高度的感知相似性。我們也提出了新的訓練策略 NODE-AdvGAN-T，它透過在訓練期間有效地調整雜訊參數，增強了黑盒攻擊中的可傳遞性。實驗證明，NODE-AdvGAN 和 NODE-AdvGAN-T 產生的對抗性範例更有效，在保持比傳統基於 GAN 的方法更好的感知品質的同時，達到了更高的攻擊成功率。

##### **Evaluating Gender Bias Transfer between Pre-trained and Prompt-Adapted Language Models**
2412.03537v1 by Natalie Mackraz, Nivedha Sivakumar, Samira Khorshidi, Krishna Patel, Barry-John Theobald, Luca Zappella, Nicholas Apostoloff

Large language models (LLMs) are increasingly being adapted to achieve
task-specificity for deployment in real-world decision systems. Several
previous works have investigated the bias transfer hypothesis (BTH) by studying
the effect of the fine-tuning adaptation strategy on model fairness to find
that fairness in pre-trained masked language models have limited effect on the
fairness of models when adapted using fine-tuning. In this work, we expand the
study of BTH to causal models under prompt adaptations, as prompting is an
accessible, and compute-efficient way to deploy models in real-world systems.
In contrast to previous works, we establish that intrinsic biases in
pre-trained Mistral, Falcon and Llama models are strongly correlated (rho >=
0.94) with biases when the same models are zero- and few-shot prompted, using a
pronoun co-reference resolution task. Further, we find that bias transfer
remains strongly correlated even when LLMs are specifically prompted to exhibit
fair or biased behavior (rho >= 0.92), and few-shot length and stereotypical
composition are varied (rho >= 0.97). Our findings highlight the importance of
ensuring fairness in pre-trained LLMs, especially when they are later used to
perform downstream tasks via prompt adaptation.

摘要：大型语言模型 (LLM) 正越来越多地被调整为实现任务特异性，以便部署在现实世界的决策系统中。一些以前的作品通过研究微调调整策略对模型公平性的影响来调查偏差转移假设 (BTH)，发现预先训练的掩蔽语言模型中的公平性对使用微调调整后的模型公平性影响有限。在这项工作中，我们将 BTH 的研究扩展到提示调整下的因果模型，因为提示是一种可访问且计算高效的方法，可以将模型部署到现实世界系统中。与以前的作品相反，我们确定预先训练的 Mistral、Falcon 和 Llama 模型中的内在偏差与使用代词共指解析任务对相同模型进行零次和少次提示时的偏差密切相关（rho >= 0.94）。此外，我们发现，即使 LLM 被明确提示表现出公平或有偏差的行为（rho >= 0.92），并且少次提示长度和刻板印象成分有所不同（rho >= 0.97），偏差转移仍然密切相关。我们的研究结果突出了确保预先训练的 LLM 公平性的重要性，尤其是在它们后来通过提示调整用于执行下游任务时。

##### **A Review on Scientific Knowledge Extraction using Large Language Models in Biomedical Sciences**
2412.03531v1 by Gabriel Lino Garcia, João Renato Ribeiro Manesco, Pedro Henrique Paiola, Lucas Miranda, Maria Paola de Salvo, João Paulo Papa

The rapid advancement of large language models (LLMs) has opened new
boundaries in the extraction and synthesis of medical knowledge, particularly
within evidence synthesis. This paper reviews the state-of-the-art applications
of LLMs in the biomedical domain, exploring their effectiveness in automating
complex tasks such as evidence synthesis and data extraction from a biomedical
corpus of documents. While LLMs demonstrate remarkable potential, significant
challenges remain, including issues related to hallucinations, contextual
understanding, and the ability to generalize across diverse medical tasks. We
highlight critical gaps in the current research literature, particularly the
need for unified benchmarks to standardize evaluations and ensure reliability
in real-world applications. In addition, we propose directions for future
research, emphasizing the integration of state-of-the-art techniques such as
retrieval-augmented generation (RAG) to enhance LLM performance in evidence
synthesis. By addressing these challenges and utilizing the strengths of LLMs,
we aim to improve access to medical literature and facilitate meaningful
discoveries in healthcare.

摘要：大型語言模型 (LLM) 的快速進展開啟了醫療知識萃取和綜合的新領域，特別是在證據綜合中。本文回顧了 LLM 在生物醫學領域的最新應用，探討了它們在自動化複雜任務（例如從生物醫學文件語料庫中進行證據綜合和數據萃取）方面的效能。儘管 LLM 展現了顯著的潛力，但仍有重大的挑戰，包括與幻覺、脈絡理解以及在不同醫療任務中概括的能力相關的問題。我們強調了當前研究文獻中的關鍵差距，特別是需要統一的基準來標準化評估並確保實際應用中的可靠性。此外，我們提出了未來研究的方向，強調整合最先進的技術，例如檢索增強生成 (RAG)，以增強 LLM 在證據綜合中的表現。透過解決這些挑戰並利用 LLM 的優勢，我們旨在改善對醫學文獻的取得，並促進醫療保健中的有意義發現。

##### **FANAL -- Financial Activity News Alerting Language Modeling Framework**
2412.03527v1 by Urjitkumar Patel, Fang-Chun Yeh, Chinmay Gondhalekar, Hari Nalluri

In the rapidly evolving financial sector, the accurate and timely
interpretation of market news is essential for stakeholders needing to navigate
unpredictable events. This paper introduces FANAL (Financial Activity News
Alerting Language Modeling Framework), a specialized BERT-based framework
engineered for real-time financial event detection and analysis, categorizing
news into twelve distinct financial categories. FANAL leverages silver-labeled
data processed through XGBoost and employs advanced fine-tuning techniques,
alongside ORBERT (Odds Ratio BERT), a novel variant of BERT fine-tuned with
ORPO (Odds Ratio Preference Optimization) for superior class-wise probability
calibration and alignment with financial event relevance. We evaluate FANAL's
performance against leading large language models, including GPT-4o, Llama-3.1
8B, and Phi-3, demonstrating its superior accuracy and cost efficiency. This
framework sets a new standard for financial intelligence and responsiveness,
significantly outstripping existing models in both performance and
affordability.

摘要：在快速變化的金融領域中，準確及時地解讀市場新聞對於需要應對不可預測事件的利益相關者至關重要。本文介紹 FANAL（金融活動新聞警示語言建模框架），這是一個基於 BERT 的專用框架，專門設計用於實時金融事件檢測和分析，將新聞歸類為十二個不同的金融類別。FANAL 利用通過 XGBoost 處理的銀標籤數據，並採用先進的微調技術，以及 ORBERT（機率比 BERT），這是一種新的 BERT 變體，經過 ORPO（機率比偏好最佳化）微調，以實現優越的類別機率校準和與金融事件相關性的對齊。我們評估了 FANAL 與領先的大語言模型的效能，包括 GPT-4o、Llama-3.1 8B 和 Phi-3，證明了其優越的準確性和成本效益。這個框架為金融情報和響應能力設定了新的標準，在效能和負擔能力方面都遠遠超過現有的模型。

##### **Feed-Forward Bullet-Time Reconstruction of Dynamic Scenes from Monocular Videos**
2412.03526v1 by Hanxue Liang, Jiawei Ren, Ashkan Mirzaei, Antonio Torralba, Ziwei Liu, Igor Gilitschenski, Sanja Fidler, Cengiz Oztireli, Huan Ling, Zan Gojcic, Jiahui Huang

Recent advancements in static feed-forward scene reconstruction have
demonstrated significant progress in high-quality novel view synthesis.
However, these models often struggle with generalizability across diverse
environments and fail to effectively handle dynamic content. We present BTimer
(short for BulletTimer), the first motion-aware feed-forward model for
real-time reconstruction and novel view synthesis of dynamic scenes. Our
approach reconstructs the full scene in a 3D Gaussian Splatting representation
at a given target ('bullet') timestamp by aggregating information from all the
context frames. Such a formulation allows BTimer to gain scalability and
generalization by leveraging both static and dynamic scene datasets. Given a
casual monocular dynamic video, BTimer reconstructs a bullet-time scene within
150ms while reaching state-of-the-art performance on both static and dynamic
scene datasets, even compared with optimization-based approaches.

摘要：最近靜態前饋場景重建的進展已證明在高品質的新視圖合成方面取得重大進展。
然而，這些模型通常難以適應各種環境，且無法有效處理動態內容。我們提出 BTimer（BulletTimer 的縮寫），這是第一個具有動態感知的前饋模型，用於動態場景的即時重建和新視圖合成。我們的做法是透過彙整所有內容畫面的資訊，在給定的目標（「子彈」）時間戳記中，以 3D 高斯濺射表示法重建整個場景。這種公式化讓 BTimer 能夠透過利用靜態和動態場景資料集來獲得可擴充性和概括性。給定一個隨意的單眼動態影片，BTimer 能在 150 毫秒內重建一個子彈時間場景，同時在靜態和動態場景資料集上達到最先進的效能，即使與基於最佳化的做法相比也是如此。

##### **You're (Not) My Type -- Can LLMs Generate Feedback of Specific Types for Introductory Programming Tasks?**
2412.03516v1 by Dominic Lohr, Hieke Keuning, Natalie Kiesler

Background: Feedback as one of the most influential factors for learning has
been subject to a great body of research. It plays a key role in the
development of educational technology systems and is traditionally rooted in
deterministic feedback defined by experts and their experience. However, with
the rise of generative AI and especially Large Language Models (LLMs), we
expect feedback as part of learning systems to transform, especially for the
context of programming. In the past, it was challenging to automate feedback
for learners of programming. LLMs may create new possibilities to provide
richer, and more individual feedback than ever before.
  Objectives: This paper aims to generate specific types of feedback for
introductory programming tasks using LLMs. We revisit existing feedback
taxonomies to capture the specifics of the generated feedback, such as
randomness, uncertainty, and degrees of variation.
  Methods: We iteratively designed prompts for the generation of specific
feedback types (as part of existing feedback taxonomies) in response to
authentic student programs. We then evaluated the generated output and
determined to what extent it reflected certain feedback types.
  Results and Conclusion: The present work provides a better understanding of
different feedback dimensions and characteristics. The results have
implications for future feedback research with regard to, for example, feedback
effects and learners' informational needs. It further provides a basis for the
development of new tools and learning systems for novice programmers including
feedback generated by AI.

摘要：**背景：**回饋作為學習中最具影響力的因素之一，
一直是許多研究的主題。它在教育科技系統的發展中扮演著關鍵角色，
並且傳統上根植於由專家及其經驗定義的確定性回饋。然而，
隨著生成式 AI 和特別是大語言模型 (LLM) 的興起，我們預期回饋
作為學習系統的一部分會轉型，特別是在程式設計的背景下。在過去，
自動化程式設計學習者的回饋是一項挑戰。LLM 可能創造新的可能性，
提供比以往更豐富、更個人化的回饋。

**目標：**本文旨在使用 LLM 為入門程式設計任務產生特定類型的回饋。我們重新審視現有的回饋分類法，
以擷取所產生回饋的具體特徵，例如隨機性、不確定性和變異程度。

**方法：**我們反覆設計提示，以產生特定回饋類型（作為現有回饋分類法的一部分），
以回應真實的學生程式。然後，我們評估產生的輸出，
並確定它在多大程度上反映了某些回饋類型。

**結果和結論：**目前的研究提供了對不同回饋面向和特徵的更深入了解。這些結果
對未來的回饋研究具有影響，例如回饋效果和學習者的資訊需求。它進一步為
開發新的工具和學習系統奠定了基礎，這些系統包括由 AI 生成的回饋，
適用於新手程式設計師。

##### **KKLIP: Knowledge Distillation Exploiting K-means Clustering for Language-Image Pre-Training**
2412.03513v1 by Kuei-Chun Kao

Recently, CLIP has emerged as a valuable model for aligning image and text
information in multi-modal scenarios. However, researchers have observed
limitations in the ability of CLIP's text and image encoders to extract
detailed knowledge from caption-image pairs. In response, this paper introduces
KKLIP, a novel approach designed to enhance the quality of CLIP by
incorporating a new knowledge distillation (KD) method derived from Llama 2.
Our method comprises three objectives: Text Embedding Distillation, Concept
Learning, and Contrastive Learning. Firstly, Text Embedding Distillation
involves training the KKLIP text encoder to emulate the teacher model, Llama 2.
Secondly, Concept Learning assigns a soft concept label to each caption-image
pair through offline k-means clustering of text information from Llama 2,
allowing KKLIP to learn from these soft concept labels. Finally, Contrastive
Learning harmonizes text and image embeddings. Our experimental results
demonstrate that KKLIP enhances the quality of both text and image encoders.

摘要：最近，CLIP 已成为一种有价值的模型，用于在多模态场景中对齐图像和文本信息。然而，研究人员已经观察到 CLIP 的文本和图像编码器从标题图像对中提取详细知识的能力存在局限性。对此，本文介绍了 KKLIP，这是一种新颖的方法，旨在通过整合源自 Llama 2 的新知识蒸馏 (KD) 方法来增强 CLIP 的质量。我们的方法包括三个目标：文本嵌入蒸馏、概念学习和对比学习。首先，文本嵌入蒸馏涉及训练 KKLIP 文本编码器以模拟教师模型 Llama 2。其次，概念学习通过离线对来自 Llama 2 的文本信息进行 k 均值聚类，为每个标题图像对分配一个软概念标签，从而允许 KKLIP 从这些软概念标签中学习。最后，对比学习协调文本和图像嵌入。我们的实验结果表明，KKLIP 增强了文本和图像编码器的质量。

##### **A Bidirectional Siamese Recurrent Neural Network for Accurate Gait Recognition Using Body Landmarks**
2412.03498v1 by Proma Hossain Progga, Md. Jobayer Rahman, Swapnil Biswas, Md. Shakil Ahmed, Arif Reza Anwary, Swakkhar Shatabda

Gait recognition is a significant biometric technique for person
identification, particularly in scenarios where other physiological biometrics
are impractical or ineffective. In this paper, we address the challenges
associated with gait recognition and present a novel approach to improve its
accuracy and reliability. The proposed method leverages advanced techniques,
including sequential gait landmarks obtained through the Mediapipe pose
estimation model, Procrustes analysis for alignment, and a Siamese
biGRU-dualStack Neural Network architecture for capturing temporal
dependencies. Extensive experiments were conducted on large-scale cross-view
datasets to demonstrate the effectiveness of the approach, achieving high
recognition accuracy compared to other models. The model demonstrated
accuracies of 95.7%, 94.44%, 87.71%, and 86.6% on CASIA-B, SZU RGB-D, OU-MVLP,
and Gait3D datasets respectively. The results highlight the potential
applications of the proposed method in various practical domains, indicating
its significant contribution to the field of gait recognition.

摘要：步態辨識是一種重要的生物特徵技術，用於個人識別，特別是在其他生理生物特徵不切實際或無效的情況下。在本文中，我們探討了與步態辨識相關的挑戰，並提出了一種新的方法來提高其準確性和可靠性。所提出的方法利用了先進的技術，包括通過 Mediapipe 姿勢估計模型獲得的序列步態地標、用於對齊的 Procrustes 分析，以及用於捕捉時間依賴性的 Siamese biGRU-dualStack 神經網路架構。在大型跨視圖數據集上進行了廣泛的實驗，以證明該方法的有效性，與其他模型相比，實現了很高的識別準確率。該模型在 CASIA-B、SZU RGB-D、OU-MVLP 和 Gait3D 數據集上分別展示了 95.7%、94.44%、87.71% 和 86.6% 的準確率。結果突出了所提出方法在各種實際領域的潛在應用，表明其對步態辨識領域做出了重大貢獻。

##### **Flow Matching with General Discrete Paths: A Kinetic-Optimal Perspective**
2412.03487v1 by Neta Shaul, Itai Gat, Marton Havasi, Daniel Severo, Anuroop Sriram, Peter Holderrieth, Brian Karrer, Yaron Lipman, Ricky T. Q. Chen

The design space of discrete-space diffusion or flow generative models are
significantly less well-understood than their continuous-space counterparts,
with many works focusing only on a simple masked construction. In this work, we
aim to take a holistic approach to the construction of discrete generative
models based on continuous-time Markov chains, and for the first time, allow
the use of arbitrary discrete probability paths, or colloquially, corruption
processes. Through the lens of optimizing the symmetric kinetic energy, we
propose velocity formulas that can be applied to any given probability path,
completely decoupling the probability and velocity, and giving the user the
freedom to specify any desirable probability path based on expert knowledge
specific to the data domain. Furthermore, we find that a special construction
of mixture probability paths optimizes the symmetric kinetic energy for the
discrete case. We empirically validate the usefulness of this new design space
across multiple modalities: text generation, inorganic material generation, and
image generation. We find that we can outperform the mask construction even in
text with kinetic-optimal mixture paths, while we can make use of
domain-specific constructions of the probability path over the visual domain.

摘要：離散空間擴散或流動生成模型的設計空間，與其連續空間的對應物相比，顯著地不甚明瞭，許多作品僅專注於簡單的遮罩構造。在這項工作中，我們旨在採用整體方法來建構基於連續時間馬可夫鏈的離散生成模型，並首次允許使用任意離散機率路徑，或通俗地說，損壞程序。透過最佳化對稱動能的觀點，我們提出可以應用於任何給定機率路徑的速度公式，完全解耦機率和速度，並讓使用者能夠根據特定於資料領域的專家知識，指定任何理想的機率路徑。此外，我們發現混合機率路徑的特殊構造，會最佳化離散情況的對稱動能。我們透過多種方式驗證此新設計空間的效用：文字生成、無機材料生成和影像生成。我們發現，即使在具有動能最佳混合路徑的文字中，我們也可以優於遮罩構造，同時我們可以在視覺領域中使用機率路徑的特定於領域的構造。

##### **Training-Free Mitigation of Language Reasoning Degradation After Multimodal Instruction Tuning**
2412.03467v1 by Neale Ratzlaff, Man Luo, Xin Su, Vasudev Lal, Phillip Howard

Multimodal models typically combine a powerful large language model (LLM)
with a vision encoder and are then trained on multimodal data via instruction
tuning. While this process adapts LLMs to multimodal settings, it remains
unclear whether this adaptation compromises their original language reasoning
capabilities. In this work, we explore the effects of multimodal instruction
tuning on language reasoning performance. We focus on LLaVA, a leading
multimodal framework that integrates LLMs such as Vicuna or Mistral with the
CLIP vision encoder. We compare the performance of the original LLMs with their
multimodal-adapted counterparts across eight language reasoning tasks. Our
experiments yield several key insights. First, the impact of multimodal
learning varies between Vicuna and Mistral: we observe a degradation in
language reasoning for Mistral but improvements for Vicuna across most tasks.
Second, while multimodal instruction learning consistently degrades performance
on mathematical reasoning tasks (e.g., GSM8K), it enhances performance on
commonsense reasoning tasks (e.g., CommonsenseQA). Finally, we demonstrate that
a training-free model merging technique can effectively mitigate the language
reasoning degradation observed in multimodal-adapted Mistral and even improve
performance on visual tasks.

摘要：多模态模型通常将强大的大型语言模型 (LLM) 与视觉编码器结合起来，然后通过指令微调在多模态数据上进行训练。虽然此过程使 LLM 适应多模态设置，但尚不清楚这种适应是否会损害其原始语言推理能力。在这项工作中，我们探讨了多模态指令微调对语言推理性能的影响。我们专注于 LLaVA，这是一个领先的多模态框架，它将 Vicuna 或 Mistral 等 LLM 与 CLIP 视觉编码器集成在一起。我们比较了原始 LLM 与其多模态适应对应项在八个语言推理任务中的性能。我们的实验产生了几个关键见解。首先，多模态学习的影响在 Vicuna 和 Mistral 之间有所不同：我们观察到 Mistral 的语言推理能力下降，但大多数任务中 Vicuna 的语言推理能力都有所提高。其次，虽然多模态指令学习持续降低数学推理任务（例如 GSM8K）的性能，但它增强了常识推理任务（例如 CommonsenseQA）的性能。最后，我们证明了一种无训练模型合并技术可以有效缓解在多模态适应的 Mistral 中观察到的语言推理退化，甚至可以提高视觉任务的性能。

##### **From Words to Workflows: Automating Business Processes**
2412.03446v1 by Laura Minkova, Jessica López Espejel, Taki Eddine Toufik Djaidja, Walid Dahhane, El Hassane Ettifouri

As businesses increasingly rely on automation to streamline operations, the
limitations of Robotic Process Automation (RPA) have become apparent,
particularly its dependence on expert knowledge and inability to handle complex
decision-making tasks. Recent advancements in Artificial Intelligence (AI),
particularly Generative AI (GenAI) and Large Language Models (LLMs), have paved
the way for Intelligent Automation (IA), which integrates cognitive
capabilities to overcome the shortcomings of RPA. This paper introduces
Text2Workflow, a novel method that automatically generates workflows from
natural language user requests. Unlike traditional automation approaches,
Text2Workflow offers a generalized solution for automating any business
process, translating user inputs into a sequence of executable steps
represented in JavaScript Object Notation (JSON) format. Leveraging the
decision-making and instruction-following capabilities of LLMs, this method
provides a scalable, adaptable framework that enables users to visualize and
execute workflows with minimal manual intervention. This research outlines the
Text2Workflow methodology and its broader implications for automating complex
business processes.

摘要：<paragraph>隨著企業日益依賴自動化來簡化營運，機器人流程自動化 (RPA) 的限制已變得明顯，特別是其依賴專家知識以及無法處理複雜決策任務。人工智慧 (AI) 的最新進展，特別是生成式 AI (GenAI) 和大型語言模型 (LLM)，已為智慧自動化 (IA) 鋪路，整合認知能力以克服 RPA 的缺點。本文介紹 Text2Workflow，一種從自然語言使用者要求中自動產生工作流程的新方法。與傳統的自動化方法不同，Text2Workflow 提供了一個通用的解決方案，用於自動化任何業務流程，將使用者輸入轉換為以 JavaScript 物件表示法 (JSON) 格式表示的可執行步驟序列。利用 LLM 的決策制定和遵循指令的能力，此方法提供了一個可擴充、可適應的框架，使用戶能夠以最少的 人工干預視覺化和執行工作流程。本研究概述了 Text2Workflow 方法及其對自動化複雜業務流程的更廣泛影響。</paragraph>

##### **PBP: Post-training Backdoor Purification for Malware Classifiers**
2412.03441v1 by Dung Thuy Nguyen, Ngoc N. Tran, Taylor T. Johnson, Kevin Leach

In recent years, the rise of machine learning (ML) in cybersecurity has
brought new challenges, including the increasing threat of backdoor poisoning
attacks on ML malware classifiers. For instance, adversaries could inject
malicious samples into public malware repositories, contaminating the training
data and potentially misclassifying malware by the ML model. Current
countermeasures predominantly focus on detecting poisoned samples by leveraging
disagreements within the outputs of a diverse set of ensemble models on
training data points. However, these methods are not suitable for scenarios
where Machine Learning-as-a-Service (MLaaS) is used or when users aim to remove
backdoors from a model after it has been trained. Addressing this scenario, we
introduce PBP, a post-training defense for malware classifiers that mitigates
various types of backdoor embeddings without assuming any specific backdoor
embedding mechanism. Our method exploits the influence of backdoor attacks on
the activation distribution of neural networks, independent of the
trigger-embedding method. In the presence of a backdoor attack, the activation
distribution of each layer is distorted into a mixture of distributions. By
regulating the statistics of the batch normalization layers, we can guide a
backdoored model to perform similarly to a clean one. Our method demonstrates
substantial advantages over several state-of-the-art methods, as evidenced by
experiments on two datasets, two types of backdoor methods, and various attack
configurations. Notably, our approach requires only a small portion of the
training data -- only 1\% -- to purify the backdoor and reduce the attack
success rate from 100\% to almost 0\%, a 100-fold improvement over the baseline
methods. Our code is available at
\url{https://github.com/judydnguyen/pbp-backdoor-purification-official}.

摘要：近年來，機器學習 (ML) 在網路安全的崛起帶來了新的挑戰，包括針對 ML 惡意軟體分類器越來越嚴重的後門投毒攻擊威脅。例如，攻擊者可以將惡意樣本注入公共惡意軟體儲存庫，污染訓練資料，並可能導致 ML 模型錯誤分類惡意軟體。目前的對策主要集中於透過利用一組多元集成模型在訓練資料點上輸出的分歧來偵測中毒樣本。然而，這些方法不適用於使用機器學習即服務 (MLaaS) 或使用者在訓練模型後希望從模型中移除後門的場景。為了處理這種場景，我們引入了 PBP，這是一種針對惡意軟體分類器的訓練後防禦機制，它能減輕各種類型的後門嵌入，而無需假設任何特定後門嵌入機制。我們的方法利用後門攻擊對神經網路啟用分佈的影響，與觸發嵌入方法無關。在後門攻擊的情況下，每一層的啟用分佈會扭曲成混合分佈。透過調節批次標準化層的統計資料，我們可以引導後門模型執行類似於乾淨模型的任務。我們的模型展現出優於多種最先進方法的顯著優勢，這在兩個資料集、兩種後門方法和各種攻擊配置的實驗中得到證明。值得注意的是，我們的模型僅需要一小部分訓練資料 (僅 1%) 就能淨化後門，並將攻擊成功率從 100% 降低到幾乎 0%，比基準方法提升了 100 倍。我們的程式碼可於以下網址取得：\url{https://github.com/judydnguyen/pbp-backdoor-purification-official}。

##### **BIMCaP: BIM-based AI-supported LiDAR-Camera Pose Refinement**
2412.03434v1 by Miguel Arturo Vega Torres, Anna Ribic, Borja García de Soto, André Borrmann

This paper introduces BIMCaP, a novel method to integrate mobile 3D sparse
LiDAR data and camera measurements with pre-existing building information
models (BIMs), enhancing fast and accurate indoor mapping with affordable
sensors. BIMCaP refines sensor poses by leveraging a 3D BIM and employing a
bundle adjustment technique to align real-world measurements with the model.
Experiments using real-world open-access data show that BIMCaP achieves
superior accuracy, reducing translational error by over 4 cm compared to
current state-of-the-art methods. This advancement enhances the accuracy and
cost-effectiveness of 3D mapping methodologies like SLAM. BIMCaP's improvements
benefit various fields, including construction site management and emergency
response, by providing up-to-date, aligned digital maps for better
decision-making and productivity. Link to the repository:
https://github.com/MigVega/BIMCaP

摘要：這篇論文介紹了 BIMCaP，一種新穎的方法，用於整合行動 3D 稀疏 LiDAR 資料和相機測量，以及預先存在的建築資訊模型 (BIM)，藉由經濟實惠的感測器加強快速且精準的室內建構。BIMCaP 透過利用 3D BIM，並採用束調整技術，將真實世界測量與模型對齊，進而優化感測器姿勢。使用真實世界開放取用資料的實驗顯示，與目前最先進的方法相比，BIMCaP 達到更高的精確度，將平移誤差減少超過 4 公分。此項進展提升了 3D 建構方法（例如 SLAM）的精確度和成本效益。BIMCaP 的改進使各種領域受益，包括建築工地管理和緊急應變，藉由提供最新的對齊數位地圖，以利於更好的決策制定和生產力。儲存庫連結：https://github.com/MigVega/BIMCaP

##### **Automated Test-Case Generation for REST APIs Using Model Inference Search Heuristic**
2412.03420v1 by Clinton Cao, Annibale Panichella, Sicco Verwer

The rising popularity of the microservice architectural style has led to a
growing demand for automated testing approaches tailored to these systems.
EvoMaster is a state-of-the-art tool that uses Evolutionary Algorithms (EAs) to
automatically generate test cases for microservices' REST APIs. One limitation
of these EAs is the use of unit-level search heuristics, such as branch
distances, which focus on fine-grained code coverage and may not effectively
capture the complex, interconnected behaviors characteristic of system-level
testing. To address this limitation, we propose a new search heuristic (MISH)
that uses real-time automaton learning to guide the test case generation
process. We capture the sequential call patterns exhibited by a test case by
learning an automaton from the stream of log events outputted by different
microservices within the same system. Therefore, MISH learns a representation
of the systemwide behavior, allowing us to define the fitness of a test case
based on the path it traverses within the inferred automaton. We empirically
evaluate MISH's effectiveness on six real-world benchmark microservice
applications and compare it against a state-of-the-art technique, MOSA, for
testing REST APIs. Our evaluation shows promising results for using MISH to
guide the automated test case generation within EvoMaster.

摘要：微服務架構風格日益普及，導致對針對這些系統量身打造的自動化測試方法的需求不斷增長。EvoMaster 是一款最先進的工具，它使用演算法 (EA) 自動產生微服務 REST API 的測試案例。這些 EA 的一個限制是使用單元層級的搜尋啟發法，例如分支距離，這種方法專注於精細的程式碼覆蓋率，可能無法有效捕捉系統層級測試特有的複雜、相互關聯的行為。為了解決這個限制，我們提出一個新的搜尋啟發法 (MISH)，它使用即時自動機學習來引導測試案例產生程序。我們透過從同一個系統中不同微服務輸出的日誌事件串流學習自動機，來捕捉測試案例展現的順序呼叫模式。因此，MISH 會學習系統範圍行為的表示，讓我們可以根據測試案例在推論的自動機中所走訪的路徑來定義其適應度。我們對六個真實世界的基準微服務應用程式實證評估了 MISH 的有效性，並將其與最先進的 REST API 測試技術 MOSA 進行比較。我們的評估顯示，使用 MISH 來引導 EvoMaster 中的自動化測試案例產生，具有令人振奮的結果。

##### **Benchmarking Pretrained Attention-based Models for Real-Time Recognition in Robot-Assisted Esophagectomy**
2412.03401v1 by Ronald L. P. D. de Jong, Yasmina al Khalil, Tim J. M. Jaspers, Romy C. van Jaarsveld, Gino M. Kuiper, Yiping Li, Richard van Hillegersberg, Jelle P. Ruurda, Marcel Breeuwer, Fons van der Sommen

Esophageal cancer is among the most common types of cancer worldwide. It is
traditionally treated using open esophagectomy, but in recent years,
robot-assisted minimally invasive esophagectomy (RAMIE) has emerged as a
promising alternative. However, robot-assisted surgery can be challenging for
novice surgeons, as they often suffer from a loss of spatial orientation.
Computer-aided anatomy recognition holds promise for improving surgical
navigation, but research in this area remains limited. In this study, we
developed a comprehensive dataset for semantic segmentation in RAMIE, featuring
the largest collection of vital anatomical structures and surgical instruments
to date. Handling this diverse set of classes presents challenges, including
class imbalance and the recognition of complex structures such as nerves. This
study aims to understand the challenges and limitations of current
state-of-the-art algorithms on this novel dataset and problem. Therefore, we
benchmarked eight real-time deep learning models using two pretraining
datasets. We assessed both traditional and attention-based networks,
hypothesizing that attention-based networks better capture global patterns and
address challenges such as occlusion caused by blood or other tissues. The
benchmark includes our RAMIE dataset and the publicly available CholecSeg8k
dataset, enabling a thorough assessment of surgical segmentation tasks. Our
findings indicate that pretraining on ADE20k, a dataset for semantic
segmentation, is more effective than pretraining on ImageNet. Furthermore,
attention-based models outperform traditional convolutional neural networks,
with SegNeXt and Mask2Former achieving higher Dice scores, and Mask2Former
additionally excelling in average symmetric surface distance.

摘要：食道癌是全球最常見的癌症類型之一。傳統上使用開胸食道切除術進行治療，但近年來，機器人輔助微創食道切除術 (RAMIE) 已成為一種有前景的替代方案。然而，對於新手外科醫生來說，機器人輔助手術可能具有挑戰性，因為他們經常會喪失空間定位能力。電腦輔助解剖識別有望改善手術導航，但這方面的研究仍然有限。在這項研究中，我們為 RAMIE 中的語義分割開發了一個全面的數據集，其中包含迄今為止最大的重要解剖結構和手術器械集合。處理這一組不同的類別會帶來挑戰，包括類別不平衡以及對神經等複雜結構的識別。本研究旨在了解當前最先進演算法在這個新數據集和問題上的挑戰和限制。因此，我們使用兩個預訓練數據集對八個實時深度學習模型進行了基準測試。我們評估了傳統和基於注意力的網路，假設基於注意力的網路可以更好地捕捉全局模式，並解決因血液或其他組織引起的遮擋等挑戰。基準測試包括我們的 RAMIE 數據集和公開的 CholecSeg8k 數據集，可以對外科分割任務進行全面評估。我們的研究結果表明，在 ADE20k（一個用於語義分割的數據集）上進行預訓練比在 ImageNet 上進行預訓練更有效。此外，基於注意力的模型優於傳統的卷積神經網路，其中 SegNeXt 和 Mask2Former 獲得了更高的 Dice 分數，而 Mask2Former 在平均對稱表面距離方面也表現出色。

##### **RedStone: Curating General, Code, Math, and QA Data for Large Language Models**
2412.03398v1 by Yaoyao Chang, Lei Cui, Li Dong, Shaohan Huang, Yangyu Huang, Yupan Huang, Scarlett Li, Tengchao Lv, Shuming Ma, Qinzheng Sun, Wenhui Wang, Furu Wei, Ying Xin, Mao Yang, Qiufeng Yin, Xingxing Zhang

Pre-training Large Language Models (LLMs) on high-quality, meticulously
curated datasets is widely recognized as critical for enhancing their
performance and generalization capabilities. This study explores the untapped
potential of Common Crawl as a comprehensive and flexible resource for
pre-training LLMs, addressing both general-purpose language understanding and
specialized domain knowledge. We introduce RedStone, an innovative and scalable
pipeline engineered to extract and process data from Common Crawl, facilitating
the creation of extensive and varied pre-training datasets. Unlike traditional
datasets, which often require expensive curation and domain-specific expertise,
RedStone leverages the breadth of Common Crawl to deliver datasets tailored to
a wide array of domains. In this work, we exemplify its capability by
constructing pre-training datasets across multiple fields, including general
language understanding, code, mathematics, and question-answering tasks. The
flexibility of RedStone allows for easy adaptation to other specialized
domains, significantly lowering the barrier to creating valuable
domain-specific datasets. Our findings demonstrate that Common Crawl, when
harnessed through effective pipelines like RedStone, can serve as a rich,
renewable source of pre-training data, unlocking new avenues for domain
adaptation and knowledge discovery in LLMs. This work also underscores the
importance of innovative data acquisition strategies and highlights the role of
web-scale data as a powerful resource in the continued evolution of LLMs.
RedStone code and data samples will be publicly available at
\url{https://aka.ms/redstone}.

摘要：<paragraph>在高品質、經過仔細整理的資料集上預先訓練大型語言模型 (LLM) 被廣泛認為對於提升其效能和概化能力至關重要。本研究探討了 Common Crawl 作為一個全面且彈性的資源，在預先訓練 LLM 方面的未開發潛力，同時解決一般用途的語言理解和專業領域知識。我們介紹了 RedStone，這是一個創新且可擴充的管道，設計用於從 Common Crawl 擷取和處理資料，促進建立廣泛且多樣的預先訓練資料集。與傳統資料集不同，傳統資料集通常需要昂貴的整理和特定領域的專業知識，RedStone 利用 Common Crawl 的廣度來提供適合各種領域的資料集。在這項工作中，我們透過建構跨多個領域的預先訓練資料集來證明其能力，包括一般語言理解、程式碼、數學和問答任務。RedStone 的彈性允許輕鬆適應其他專業領域，大幅降低建立有價值的特定領域資料集的門檻。我們的研究結果證明，當透過像 RedStone 這樣的有效管道利用 Common Crawl 時，它可以用作豐富、可再生的預先訓練資料來源，為 LLM 中的領域適應和知識發現開啟新途徑。這項工作也強調了創新資料擷取策略的重要性，並突顯了網路規模資料在 LLM 持續演進中作為強大資源的角色。RedStone 程式碼和資料範例將在 \url{https://aka.ms/redstone} 公開提供。</paragraph>

##### **Enhancing Supply Chain Visibility with Generative AI: An Exploratory Case Study on Relationship Prediction in Knowledge Graphs**
2412.03390v1 by Ge Zheng, Alexandra Brintrup

A key stumbling block in effective supply chain risk management for companies
and policymakers is a lack of visibility on interdependent supply network
relationships. Relationship prediction, also called link prediction is an
emergent area of supply chain surveillance research that aims to increase the
visibility of supply chains using data-driven techniques. Existing methods have
been successful for predicting relationships but struggle to extract the
context in which these relationships are embedded - such as the products being
supplied or locations they are supplied from. Lack of context prevents
practitioners from distinguishing transactional relations from established
supply chain relations, hindering accurate estimations of risk. In this work,
we develop a new Generative Artificial Intelligence (Gen AI) enhanced machine
learning framework that leverages pre-trained language models as embedding
models combined with machine learning models to predict supply chain
relationships within knowledge graphs. By integrating Generative AI techniques,
our approach captures the nuanced semantic relationships between entities,
thereby improving supply chain visibility and facilitating more precise risk
management. Using data from a real case study, we show that GenAI-enhanced link
prediction surpasses all benchmarks, and demonstrate how GenAI models can be
explored and effectively used in supply chain risk management.

摘要：供應鏈風險管理中的一個關鍵障礙在於企業和政策制定者缺乏對相互依存供應網路關係的能見度。關係預測，也稱為連結預測，是供應鏈監控研究中一個新興領域，旨在使用資料驅動技術提高供應鏈的能見度。現有方法已成功預測關係，但難以提取這些關係所嵌入的背景，例如所供應的產品或供應地點。缺乏背景會妨礙從業者區分交易關係和既定的供應鏈關係，進而阻礙風險的準確評估。在這項工作中，我們開發了一個新的生成式人工智慧 (Gen AI) 增強機器學習架構，它利用預先訓練的語言模型作為嵌入模型，並結合機器學習模型來預測知識圖譜中的供應鏈關係。透過整合生成式 AI 技術，我們的做法捕捉到實體之間細微的語義關係，從而提高供應鏈能見度並促進更精確的風險管理。使用來自真實案例研究的資料，我們證明 GenAI 增強連結預測優於所有基準，並展示如何探索和有效地在供應鏈風險管理中使用 GenAI 模型。

##### **DiffStyleTTS: Diffusion-based Hierarchical Prosody Modeling for Text-to-Speech with Diverse and Controllable Styles**
2412.03388v1 by Jiaxuan Liu, Zhaoci Liu, Yajun Hu, Yingying Gao, Shilei Zhang, Zhenhua Ling

Human speech exhibits rich and flexible prosodic variations. To address the
one-to-many mapping problem from text to prosody in a reasonable and flexible
manner, we propose DiffStyleTTS, a multi-speaker acoustic model based on a
conditional diffusion module and an improved classifier-free guidance, which
hierarchically models speech prosodic features, and controls different prosodic
styles to guide prosody prediction. Experiments show that our method
outperforms all baselines in naturalness and achieves superior synthesis speed
compared to three diffusion-based baselines. Additionally, by adjusting the
guiding scale, DiffStyleTTS effectively controls the guidance intensity of the
synthetic prosody.

摘要：人類的語音展現出豐富且靈活的韻律變化。為了以合理且靈活的方式解決文字到韻律的一對多對應問題，我們提出 DiffStyleTTS，這是一個基於條件擴散模組和改進的無分類器引導的多重說話者聲學模型，它以階層方式建構語音韻律特徵，並控制不同的韻律風格以引導韻律預測。實驗顯示，與自然度中的所有基準相比，我們的模型表現優異，並且與三個基於擴散的基準相比，達到了更佳的合成速度。此外，透過調整引導比例，DiffStyleTTS 能有效地控制合成韻律的引導強度。

##### **WiS Platform: Enhancing Evaluation of LLM-Based Multi-Agent Systems Through Game-Based Analysis**
2412.03359v1 by Chengwei Hu, Jianhui Zheng, Yancheng He, Hangyu Guo, Junguang Jiang, Han Zhu, Kai Sun, Yuning Jiang, Wenbo Su, Bo Zheng

Recent advancements in autonomous multi-agent systems (MAS) based on large
language models (LLMs) have enhanced the application scenarios and improved the
capability of LLMs to handle complex tasks. Despite demonstrating
effectiveness, existing studies still evidently struggle to evaluate, analysis,
and reproducibility of LLM-based MAS. In this paper, to facilitate the research
on LLM-based MAS, we introduce an open, scalable, and real-time updated
platform for accessing and analyzing the LLM-based MAS based on the games Who
is Spy?" (WiS). Our platform is featured with three main worths: (1) a unified
model evaluate interface that supports models available on Hugging Face; (2)
real-time updated leaderboard for model evaluation; (3) a comprehensive
evaluation covering game-winning rates, attacking, defense strategies, and
reasoning of LLMs. To rigorously test WiS, we conduct extensive experiments
coverage of various open- and closed-source LLMs, we find that different agents
exhibit distinct and intriguing behaviors in the game. The experimental results
demonstrate the effectiveness and efficiency of our platform in evaluating
LLM-based MAS. Our platform and its documentation are publicly available at
\url{https://whoisspy.ai/}

摘要：<paragraph>基於大型語言模型 (LLM) 的自主多智能體系統 (MAS) 近期的進展，擴展了應用場景，並提升了 LLM 處理複雜任務的能力。儘管證明了其有效性，但現有研究仍明顯難以評估、分析和重現基於 LLM 的 MAS。在本文中，為了促進對基於 LLM 的 MAS 的研究，我們介紹了一個開放、可擴充且即時更新的平台，用於存取和分析基於遊戲「誰是間諜？」(WiS) 的基於 LLM 的 MAS。我們的平台具有三個主要價值：(1) 統一的模型評估介面，支援 Hugging Face 上可用的模型；(2) 即時更新的模型評估排行榜；(3) 全面的評估，涵蓋遊戲獲勝率、攻擊、防禦策略和 LLM 的推理。為了嚴格測試 WiS，我們對各種開源和閉源 LLM 進行廣泛的實驗，我們發現不同的智能體在遊戲中表現出截然不同且有趣的行為。實驗結果證明了我們的平台在評估基於 LLM 的 MAS 時的有效性和效率。我們的平台及其文件在 \url{https://whoisspy.ai/} 公開提供</paragraph>

##### **Intuitive Axial Augmentation Using Polar-Sine-Based Piecewise Distortion for Medical Slice-Wise Segmentation**
2412.03352v1 by Yiqin Zhang, Qingkui Chen, Chen Huang, Zhengjie Zhang, Meiling Chen, Zhibing Fu

Most data-driven models for medical image analysis rely on universal
augmentations to improve performance. Experimental evidence has confirmed their
effectiveness, but the unclear mechanism underlying them poses a barrier to the
widespread acceptance and trust in such methods within the medical community.
We revisit and acknowledge the unique characteristics of medical images apart
from traditional digital images, and consequently, proposed a medical-specific
augmentation algorithm that is more elastic and aligns well with radiology scan
procedure. The method performs piecewise affine with sinusoidal distorted ray
according to radius on polar coordinates, thus simulating uncertain postures of
human lying flat on the scanning table. Our method could generate human
visceral distribution without affecting the fundamental relative position on
axial plane. Two non-adaptive algorithms, namely Meta-based Scan Table Removal
and Similarity-Guided Parameter Search, are introduced to bolster robustness of
our augmentation method. Experiments show our method improves accuracy across
multiple famous segmentation frameworks without requiring more data samples.
Our preview code is available in: https://github.com/MGAMZ/PSBPD.

摘要：大多數用於醫學影像分析的資料驅動模型仰賴通用擴充功能來提升效能。實驗證據已證實其有效性，但其背後不明確的機制對醫學界廣泛接受和信任此類方法構成阻礙。我們重新檢視並承認醫學影像與傳統數位影像的獨特特性，因此提出更具彈性且與放射線掃描程序密切配合的醫學特定擴充演算法。該方法根據極座標上的半徑執行正弦扭曲射線的逐段仿射，從而模擬人平躺在掃描台上時的不確定姿勢。我們的方法可以在不影響軸向平面上基本相對位置的情況下生成人體內臟分佈。引入了兩種非自適應演算法，即基於 Meta 的掃描台移除和相似性導引參數搜尋，以加強我們擴充方法的穩健性。實驗表明，我們的演算法在不需要更多資料樣本的情況下，就能提升多個著名分割架構的準確性。我們的預覽程式碼可在 https://github.com/MGAMZ/PSBPD 中取得。

##### **DIVE: Taming DINO for Subject-Driven Video Editing**
2412.03347v1 by Yi Huang, Wei Xiong, He Zhang, Chaoqi Chen, Jianzhuang Liu, Mingfu Yan, Shifeng Chen

Building on the success of diffusion models in image generation and editing,
video editing has recently gained substantial attention. However, maintaining
temporal consistency and motion alignment still remains challenging. To address
these issues, this paper proposes DINO-guided Video Editing (DIVE), a framework
designed to facilitate subject-driven editing in source videos conditioned on
either target text prompts or reference images with specific identities. The
core of DIVE lies in leveraging the powerful semantic features extracted from a
pretrained DINOv2 model as implicit correspondences to guide the editing
process. Specifically, to ensure temporal motion consistency, DIVE employs DINO
features to align with the motion trajectory of the source video. Extensive
experiments on diverse real-world videos demonstrate that our framework can
achieve high-quality editing results with robust motion consistency,
highlighting the potential of DINO to contribute to video editing. For precise
subject editing, DIVE incorporates the DINO features of reference images into a
pretrained text-to-image model to learn Low-Rank Adaptations (LoRAs),
effectively registering the target subject's identity. Project page:
https://dino-video-editing.github.io

摘要：建立在擴散模型在影像生成和編輯上的成功，影片編輯最近獲得了大量的關注。然而，維持時間一致性和動作對齊仍然具有挑戰性。為了解決這些問題，本文提出了 DINO 引導的影片編輯 (DIVE)，一個旨在促進以主題為導向的編輯，在來源影片中以目標文字提示或具有特定身分的參考影像為條件。DIVE 的核心在於利用從預訓練的 DINOv2 模型中提取的強大語義特徵，作為隱含對應來引導編輯過程。具體來說，為了確保時間動作一致性，DIVE 使用 DINO 特徵與來源影片的動作軌跡對齊。在各種真實世界影片上的大量實驗表明，我們的框架可以在強大的動作一致性下實現高品質的編輯結果，突顯了 DINO 對影片編輯的潛在貢獻。對於精確的主題編輯，DIVE 將參考影像的 DINO 特徵整合到預訓練的文字轉影像模型中，以學習低秩適應 (LoRAs)，有效註冊目標主題的身分。專案頁面：https://dino-video-editing.github.io

##### **Improving Linguistic Diversity of Large Language Models with Possibility Exploration Fine-Tuning**
2412.03343v1 by Long Mai, Julie Carson-Berndsen

While Large Language Models (LLMs) have made significant strides in
replicating human-like abilities, there are concerns about a reduction in the
linguistic diversity of their outputs. This results in the homogenization of
viewpoints and perspectives, as well as the underrepresentation of specific
demographic groups. Although several fine-tuning and prompting techniques have
been suggested to tackle the issue, they are often tailored to specific tasks
or come with a substantial increase in computational cost and latency. This
makes them challenging to apply to applications that demand very low latency,
such as chatbots and virtual assistants. We propose Possibility Exploration
Fine-Tuning (PEFT), a task-agnostic framework that enhances the text diversity
of LLMs without increasing latency or computational cost. Given the same
prompt, models fine-tuned with PEFT can simultaneously generate multiple
diverse responses, each corresponding with a controllable possibility number.
Experiments on dialogue and story generation tasks demonstrate that PEFT
significantly enhances the diversity of LLM outputs, as evidenced by lower
similarity between candidate responses. Since PEFT emphasizes semantic
diversity over lexical diversity, it can also notably reduce demographic bias
in dialogue systems. The implementations and datasets are available in our
repository: https://github.com/mailong25/peft_diversity

摘要：雖然大型語言模型 (LLM) 已在複製類似人類的能力方面取得重大進展，但人們擔憂其輸出的語言多樣性會下降。這導致觀點和觀念的同質化，以及特定人口群體的代表性不足。儘管已提出幾種微調和提示技術來解決此問題，但它們通常針對特定任務進行調整，或伴隨著計算成本和延遲的大幅增加。這使得它們難以應用於需要非常低延遲的應用程式，例如聊天機器人和虛擬助理。我們提出可能性探索微調 (PEFT)，這是一個與任務無關的架構，它可以增強 LLM 的文字多樣性，而不會增加延遲或計算成本。在給定相同的提示下，使用 PEFT 微調的模型可以同時產生多種不同的回應，每個回應都對應一個可控的可能性數字。對話和故事生成任務的實驗表明，PEFT 可以顯著提高 LLM 輸出的多樣性，候選回應之間的相似性較低，即可證明這一點。由於 PEFT 強調語義多樣性而非詞彙多樣性，因此它也可以顯著減少對話系統中的人口統計偏見。實作和資料集可在我們的儲存庫中取得：https://github.com/mailong25/peft_diversity

##### **AI-Driven Day-to-Day Route Choice**
2412.03338v1 by Leizhen Wang, Peibo Duan, Zhengbing He, Cheng Lyu, Xin Chen, Nan Zheng, Li Yao, Zhenliang Ma

Understanding travelers' route choices can help policymakers devise optimal
operational and planning strategies for both normal and abnormal circumstances.
However, existing choice modeling methods often rely on predefined assumptions
and struggle to capture the dynamic and adaptive nature of travel behavior.
Recently, Large Language Models (LLMs) have emerged as a promising alternative,
demonstrating remarkable ability to replicate human-like behaviors across
various fields. Despite this potential, their capacity to accurately simulate
human route choice behavior in transportation contexts remains doubtful. To
satisfy this curiosity, this paper investigates the potential of LLMs for route
choice modeling by introducing an LLM-empowered agent, "LLMTraveler." This
agent integrates an LLM as its core, equipped with a memory system that learns
from past experiences and makes decisions by balancing retrieved data and
personality traits. The study systematically evaluates the LLMTraveler's
ability to replicate human-like decision-making through two stages: (1)
analyzing its route-switching behavior in single origin-destination (OD) pair
congestion game scenarios, where it demonstrates patterns align with laboratory
data but are not fully explained by traditional models, and (2) testing its
capacity to model day-to-day (DTD) adaptive learning behaviors on the Ortuzar
and Willumsen (OW) network, producing results comparable to Multinomial Logit
(MNL) and Reinforcement Learning (RL) models. These experiments demonstrate
that the framework can partially replicate human-like decision-making in route
choice while providing natural language explanations for its decisions. This
capability offers valuable insights for transportation policymaking, such as
simulating traveler responses to new policies or changes in the network.

摘要：<paragraph>了解旅客的路線選擇有助於政策制定者為正常和異常情況制定最佳營運和規劃策略。然而，現有的選擇模型方法通常依賴於預定義的假設，並且難以捕捉旅遊行為的動態和適應性。最近，大型語言模型 (LLM) 已成為一種有希望的替代方案，展示了在各種領域複製類人行為的非凡能力。儘管有這種潛力，它們在運輸環境中準確模擬人類路線選擇行為的能力仍然令人懷疑。為了滿足這種好奇心，本文通過引入 LLM 賦能的代理「LLMTraveler」來探討 LLM 在路線選擇建模中的潛力。此代理整合 LLM 作為其核心，配備一個記憶系統，從過去的經驗中學習，並通過平衡檢索的數據和人格特質來做出決策。該研究系統地評估了 LLMTraveler 通過兩個階段複製類人決策的能力：(1) 分析其在單一起點-目的地 (OD) 對擁塞博弈場景中的路線切換行為，它展示的模式與實驗室數據一致，但無法完全由傳統模型解釋，以及 (2) 測試其在 Ortuzar 和 Willumsen (OW) 網路上對日復一日 (DTD) 適應性學習行為進行建模的能力，產生的結果與多項式 Logit (MNL) 和強化學習 (RL) 模型相當。這些實驗表明，該框架可以部分複製類人路線選擇中的決策，同時為其決策提供自然語言解釋。這種能力為交通政策制定提供了有價值的見解，例如模擬旅客對新政策或網路變化的反應。</paragraph>

##### **Yankari: A Monolingual Yoruba Dataset**
2412.03334v1 by Maro Akpobi

This paper presents Yankari, a large-scale monolingual dataset for the Yoruba
language, aimed at addressing the critical gap in Natural Language Processing
(NLP) resources for this important West African language. Despite being spoken
by over 30 million people, Yoruba has been severely underrepresented in NLP
research and applications. We detail our methodology for creating this dataset,
which includes careful source selection, automated quality control, and
rigorous data cleaning processes. The Yankari dataset comprises 51,407
documents from 13 diverse sources, totaling over 30 million tokens. Our
approach focuses on ethical data collection practices, avoiding problematic
sources and addressing issues prevalent in existing datasets. We provide
thorough automated evaluations of the dataset, demonstrating its quality
compared to existing resources. The Yankari dataset represents a significant
advancement in Yoruba language resources, providing a foundation for developing
more accurate NLP models, supporting comparative linguistic studies, and
contributing to the digital accessibility of the Yoruba language.

摘要：這篇論文提出了 Yankari，一個針對約魯巴語的大型單語資料集，旨在解決這個重要的西非語言在自然語言處理 (NLP) 資源中的關鍵差距。儘管超過 3000 萬人使用約魯巴語，但它在 NLP 研究和應用中嚴重不足。我們詳細說明了建立這個資料集的方法，其中包括仔細的來源選擇、自動化的品質控管和嚴謹的資料清理程序。Yankari 資料集包含來自 13 個不同來源的 51,407 份文件，總計超過 3000 萬個詞彙。我們的做法著重於符合道德的資料收集實務，避免有問題的來源並解決現有資料集中普遍存在的問題。我們提供資料集的徹底自動化評估，證明其品質優於現有資源。Yankari 資料集代表約魯巴語資源的重大進展，為開發更精確的 NLP 模型、支援比較語言學研究和促進約魯巴語的數位可及性奠定基礎。

##### **LuxEmbedder: A Cross-Lingual Approach to Enhanced Luxembourgish Sentence Embeddings**
2412.03331v1 by Fred Philippy, Siwen Guo, Jacques Klein, Tegawendé F. Bissyandé

Sentence embedding models play a key role in various Natural Language
Processing tasks, such as in Topic Modeling, Document Clustering and
Recommendation Systems. However, these models rely heavily on parallel data,
which can be scarce for many low-resource languages, including Luxembourgish.
This scarcity results in suboptimal performance of monolingual and
cross-lingual sentence embedding models for these languages. To address this
issue, we compile a relatively small but high-quality human-generated
cross-lingual parallel dataset to train \tool, an enhanced sentence embedding
model for Luxembourgish with strong cross-lingual capabilities. Additionally,
we present evidence suggesting that including low-resource languages in
parallel training datasets can be more advantageous for other low-resource
languages than relying solely on high-resource language pairs. Furthermore,
recognizing the lack of sentence embedding benchmarks for low-resource
languages, we create a paraphrase detection benchmark specifically for
Luxembourgish, aiming to partially fill this gap and promote further research.

摘要：句子嵌入模型在各種自然語言處理任務中扮演著關鍵角色，例如主題建模、文件分群和推薦系統。然而，這些模型高度依賴平行資料，而這對於許多低資源語言來說可能很稀少，包括盧森堡語。這種稀少性導致了這些語言的單語和跨語言句子嵌入模型的次優性能。為了解決這個問題，我們編制了一個相對較小但高品質的人類生成的跨語言平行資料集，以訓練 \tool，一個具有強大跨語言能力的盧森堡語增強句子嵌入模型。此外，我們提出證據表明，在平行訓練資料集中包含低資源語言對其他低資源語言來說可能比僅依賴於高資源語言對更有利。此外，認識到低資源語言缺乏句子嵌入基準，我們專門為盧森堡語創建了一個同義詞偵測基準，旨在部分填補這一空白並促進進一步的研究。

##### **Grounded Language Design for Lightweight Diagramming for Formal Methods**
2412.03310v1 by Siddhartha Prasad, Ben Greenman, Tim Nelson, Shriram Krishnamurthi

Model finding, as embodied by SAT solvers and similar tools, is used widely,
both in embedding settings and as a tool in its own right. For instance, tools
like Alloy target SAT to enable users to incrementally define, explore, verify,
and diagnose sophisticated specifications for a large number of complex
systems.
  These tools critically include a visualizer that lets users graphically
explore these generated models. As we show, however, default visualizers, which
know nothing about the domain, are unhelpful and even actively violate
presentational and cognitive principles. At the other extreme, full-blown
visualizations require significant effort as well as knowledge a specifier
might not possess; they can also exhibit bad failure modes (including silent
failure). Instead, we need a language to capture essential domain information
for lightweight diagramming. We ground our language design in both the
cognitive science literature on diagrams and on a large number of example
custom visualizations. This identifies the key elements of lightweight
diagrams. We distill these into a small set of orthogonal primitives. We extend
an Alloy-like tool to support these primitives. We evaluate the effectiveness
of the produced diagrams, finding them good for reasoning. We then compare this
against many other drawing languages and tools to show that this work defines a
new niche that is lightweight, effective, and driven by sound principles.

摘要：模型尋找，例如 SAT 解決器和類似工具，被廣泛使用，
既用於嵌入式設定，也作為一種獨立的工具。例如，
Alloy 等工具以 SAT 為目標，使用戶能夠逐步定義、探索、驗證，
並診斷大量複雜系統的高級規格。
這些工具至關重要的是包括一個可視化器，讓用戶以圖形方式
探索這些生成的模型。然而，我們展示了默認的可視化器，
對領域一無所知，沒有幫助，甚至主動違反
展示和認知原則。在另一個極端，全面的
可視化需要大量的精力以及說明者可能不具備的知識；它們也可以表現出不良的故障模式（包括靜默
故障）。相反，我們需要一種語言來捕捉基本領域信息
用於輕量級圖表。我們將我們的語言設計建立在
關於圖表的認知科學文獻和大量示例
自定義可視化。這確定了輕量級
圖表的關鍵元素。我們將這些提煉成一組小的正交基元。我們擴展
一個類似 Alloy 的工具來支持這些基元。我們評估產生的圖表的有效性，發現它們對推理有益。然後我們比較這
與許多其他繪圖語言和工具，以表明這項工作定義了一個
新的利基，它輕量、有效且由合理的原則驅動。

##### **Contextual Data Integration for Bike-sharing Demand Prediction with Graph Neural Networks in Degraded Weather Conditions**
2412.03307v1 by Romain Rochas, Angelo Furno, Nour-Eddin El Faouzi

Demand for bike sharing is impacted by various factors, such as weather
conditions, events, and the availability of other transportation modes. This
impact remains elusive due to the complex interdependence of these factors or
locationrelated user behavior variations. It is also not clear which factor is
additional information which are not already contained in the historical
demand. Intermodal dependencies between bike-sharing and other modes are also
underexplored, and the value of this information has not been studied in
degraded situations. The proposed study analyzes the impact of adding
contextual data, such as weather, time embedding, and road traffic flow, to
predict bike-sharing Origin-Destination (OD) flows in atypical weather
situations Our study highlights a mild relationship between prediction quality
of bike-sharing demand and road traffic flow, while the introduced time
embedding allows outperforming state-of-the-art results, particularly in the
case of degraded weather conditions. Including weather data as an additional
input further improves our model with respect to the basic ST-ED-RMGC
prediction model by reducing of more than 20% the prediction error in degraded
weather condition.

摘要：自行車共享的需求會受到各種因素的影響，例如天氣狀況、活動和其它交通方式的可用性。由於這些因素的複雜相互依賴性或與位置相關的使用者行為變化，這種影響仍然難以捉摸。目前也不清楚哪個因素是歷史需求中尚未包含的附加資訊。自行車共享與其它方式之間的跨模式依賴性也尚未充分探討，而且在惡劣情況下，此資訊的價值尚未獲得研究。所提出的研究分析加入背景資料（例如天氣、時間嵌入和道路交通流量）對預測非典型天氣狀況下的自行車共享起迄點 (OD) 流量的影響。我們的研究強調自行車共享需求預測品質與道路交通流量之間的輕微關係，而所引入的時間嵌入允許超越最先進的結果，特別是在惡劣天氣條件的情況下。將天氣資料作為附加輸入，進一步改善我們的模型，相較於基本的 ST-ED-RMGC 預測模型，在惡劣天氣條件下將預測誤差降低超過 20%。

##### **Global MMLU: Understanding and Addressing Cultural and Linguistic Biases in Multilingual Evaluation**
2412.03304v1 by Shivalika Singh, Angelika Romanou, Clémentine Fourrier, David I. Adelani, Jian Gang Ngui, Daniel Vila-Suero, Peerat Limkonchotiwat, Kelly Marchisio, Wei Qi Leong, Yosephine Susanto, Raymond Ng, Shayne Longpre, Wei-Yin Ko, Madeline Smith, Antoine Bosselut, Alice Oh, Andre F. T. Martins, Leshem Choshen, Daphne Ippolito, Enzo Ferrante, Marzieh Fadaee, Beyza Ermis, Sara Hooker

Cultural biases in multilingual datasets pose significant challenges for
their effectiveness as global benchmarks. These biases stem not only from
language but also from the cultural knowledge required to interpret questions,
reducing the practical utility of translated datasets like MMLU. Furthermore,
translation often introduces artifacts that can distort the meaning or clarity
of questions in the target language. A common practice in multilingual
evaluation is to rely on machine-translated evaluation sets, but simply
translating a dataset is insufficient to address these challenges. In this
work, we trace the impact of both of these issues on multilingual evaluations
and ensuing model performances. Our large-scale evaluation of state-of-the-art
open and proprietary models illustrates that progress on MMLU depends heavily
on learning Western-centric concepts, with 28% of all questions requiring
culturally sensitive knowledge. Moreover, for questions requiring geographic
knowledge, an astounding 84.9% focus on either North American or European
regions. Rankings of model evaluations change depending on whether they are
evaluated on the full portion or the subset of questions annotated as
culturally sensitive, showing the distortion to model rankings when blindly
relying on translated MMLU. We release Global-MMLU, an improved MMLU with
evaluation coverage across 42 languages -- with improved overall quality by
engaging with compensated professional and community annotators to verify
translation quality while also rigorously evaluating cultural biases present in
the original dataset. This comprehensive Global-MMLU set also includes
designated subsets labeled as culturally sensitive and culturally agnostic to
allow for more holistic, complete evaluation.

摘要：多語系資料集中的文化偏見對其作為全球基準的有效性構成重大挑戰。這些偏見不僅源自語言，也源自詮釋問題所需的文化知識，降低了 MMLU 等翻譯資料集的實際效用。此外，翻譯通常會引入人工製品，可能扭曲目標語言中問題的意義或清晰度。多語系評估中的一種常見做法是依賴機器翻譯的評估集，但僅翻譯資料集不足以應對這些挑戰。在這項工作中，我們追蹤了這兩個問題對多語系評估和後續模型效能的影響。我們對最先進的開放和專有模型進行大規模評估，說明 MMLU 的進展在很大程度上取決於學習以西方為中心的觀念，其中 28% 的問題需要文化敏感的知識。此外，對於需要地理知識的問題，驚人的 84.9% 專注於北美或歐洲地區。模型評估的排名會根據它們是在全部部分還是標註為文化敏感的子集問題上進行評估而改變，顯示出在盲目依賴翻譯的 MMLU 時對模型排名的扭曲。我們發布了 Global-MMLU，這是一個改進的 MMLU，其評估涵蓋 42 種語言——透過與獲得報酬的專業和社群註解員合作，驗證翻譯品質，同時嚴格評估原始資料集中存在的文化偏見，從而提高整體品質。這個全面的 Global-MMLU 集還包括標示為文化敏感和文化不可知論的指定子集，以進行更全面、完整的評估。

##### **Integrating Generative AI into Art Therapy: A Technical Showcase**
2412.03287v1 by Yannis Valentin Schmutz, Tetiana Kravchenko, Souhir Ben Souissi, Mascha Kurpicz-Briki

This paper explores the integration of generative AI into the field of art
therapy. Leveraging proven text-to-image models, we introduce a novel technical
design to complement art therapy. The resulting AI-based tools shall enable
patients to refine and customize their creative work, opening up new avenues of
expression and accessibility. Using three illustrative examples, we demonstrate
potential outputs of our solution and evaluate them qualitatively. Furthermore,
we discuss the current limitations and ethical considerations associated with
this integration and provide an outlook into future research efforts. Our
implementations are publicly available at https://github.com/BFH-AMI/sds24.

摘要：本論文探討生成式 AI 與藝術治療領域的整合。利用經過驗證的文字轉圖像模型，我們引進了一種新穎的技術設計，作為藝術治療的補充。所產生的基於 AI 的工具將能讓患者精進並客製化他們的創作，開啟表達和取得管道的新途徑。我們使用三個說明性範例，展示我們解決方案的潛在產出，並對其進行定性評估。此外，我們討論與此整合相關的現有限制和倫理考量，並提供未來研究工作的展望。我們的實作已公開於 https://github.com/BFH-AMI/sds24。

##### **Black-Box Forgery Attacks on Semantic Watermarks for Diffusion Models**
2412.03283v1 by Andreas Müller, Denis Lukovnikov, Jonas Thietke, Asja Fischer, Erwin Quiring

Integrating watermarking into the generation process of latent diffusion
models (LDMs) simplifies detection and attribution of generated content.
Semantic watermarks, such as Tree-Rings and Gaussian Shading, represent a novel
class of watermarking techniques that are easy to implement and highly robust
against various perturbations. However, our work demonstrates a fundamental
security vulnerability of semantic watermarks. We show that attackers can
leverage unrelated models, even with different latent spaces and architectures
(UNet vs DiT), to perform powerful and realistic forgery attacks. Specifically,
we design two watermark forgery attacks. The first imprints a targeted
watermark into real images by manipulating the latent representation of an
arbitrary image in an unrelated LDM to get closer to the latent representation
of a watermarked image. We also show that this technique can be used for
watermark removal. The second attack generates new images with the target
watermark by inverting a watermarked image and re-generating it with an
arbitrary prompt. Both attacks just need a single reference image with the
target watermark. Overall, our findings question the applicability of semantic
watermarks by revealing that attackers can easily forge or remove these
watermarks under realistic conditions.

摘要：將浮水印整合到潛在擴散模型 (LDM) 的生成過程中，簡化了生成內容的偵測和歸因。語義浮水印，例如樹狀環和高斯陰影，代表了一種新穎的浮水印技術，易於實作且對各種擾動具有高度的穩健性。然而，我們的研究展示了語義浮水印的基本安全性漏洞。我們展示攻擊者可以利用不相關的模型，即使它們具有不同的潛在空間和架構 (UNet 與 DiT)，來執行強大且逼真的偽造攻擊。具體來說，我們設計了兩種浮水印偽造攻擊。第一個通過在不相關的 LDM 中操縱任意影像的潛在表示，將目標浮水印印記到真實影像中，以更接近水印影像的潛在表示。我們也展示了此技術可被用於浮水印移除。第二個攻擊透過反轉水印影像並使用任意提示重新生成它，來生成具有目標浮水印的新影像。兩種攻擊都只需要一個具有目標浮水印的參考影像。總的來說，我們的發現質疑了語義浮水印的適用性，揭示了攻擊者可以在現實條件下輕鬆偽造或移除這些浮水印。

##### **AntLM: Bridging Causal and Masked Language Models**
2412.03275v1 by Xinru Yu, Bin Guo, Shiwei Luo, Jie Wang, Tao Ji, Yuanbin Wu

Causal Language Modeling (CLM) and Masked Language Modeling (MLM) are two
mainstream learning paradigms based on Transformer networks, specifically the
Decoder-only and Encoder-only architectures. The strengths of each paradigm in
downstream tasks have shown a mix of advantages and disadvantages. In the past
BabyLM Challenge 2023, although the MLM paradigm achieved the best average
performance, the CLM paradigm demonstrated significantly faster convergence
rates. For the BabyLM Challenge 2024, we propose a novel language modeling
paradigm named $\textbf{AntLM}$, which integrates both CLM and MLM to leverage
the advantages of these two classic paradigms. We chose the strict-small track
and conducted experiments on two foundation models: BabyLlama, representing
CLM, and LTG-BERT, representing MLM. During the training process for specific
foundation models, we alternate between applying CLM or MLM training objectives
and causal or bidirectional attention masks. Experimental results show that
combining the two pretraining objectives leverages their strengths, enhancing
overall training performance. Under the same epochs, $AntLM_{BabyLlama}$
improves Macro-average by 1%, and $AntLM_{LTG-BERT}$ achieves a 2.2% increase
over the baselines.

摘要：因果语言模型 (CLM) 和遮蔽语言模型 (MLM) 是基于 Transformer 网络的两种主流学习范例，特别是仅解码器和仅编码器架构。每种范例在下游任务中的优势都表现出优势和劣势的结合。在过去的 BabyLM Challenge 2023 中，尽管 MLM 范例取得了最佳的平均性能，但 CLM 范例却表现出明显更快的收敛速度。对于 BabyLM Challenge 2024，我们提出了一种名为 $\textbf{AntLM}$ 的新语言建模范例，它整合了 CLM 和 MLM 以利用这两种经典范例的优势。我们选择了严格的小型轨道，并在两个基础模型上进行了实验：代表 CLM 的 BabyLlama 和代表 MLM 的 LTG-BERT。在特定基础模型的训练过程中，我们在应用 CLM 或 MLM 训练目标和因果或双向注意力掩码之间交替进行。实验结果表明，结合这两个预训练目标可以利用它们的优势，从而增强整体训练性能。在相同的 epoch 下，$AntLM_{BabyLlama}$ 将宏平均提高了 1%，而 $AntLM_{LTG-BERT}$ 比基线提高了 2.2%。

##### **Intent-driven In-context Learning for Few-shot Dialogue State Tracking**
2412.03270v1 by Zihao Yi, Zhe Xu, Ying Shen

Dialogue state tracking (DST) plays an essential role in task-oriented
dialogue systems. However, user's input may contain implicit information,
posing significant challenges for DST tasks. Additionally, DST data includes
complex information, which not only contains a large amount of noise unrelated
to the current turn, but also makes constructing DST datasets expensive. To
address these challenges, we introduce Intent-driven In-context Learning for
Few-shot DST (IDIC-DST). By extracting user's intent, we propose an
Intent-driven Dialogue Information Augmentation module to augment the dialogue
information, which can track dialogue states more effectively. Moreover, we
mask noisy information from DST data and rewrite user's input in the
Intent-driven Examples Retrieval module, where we retrieve similar examples. We
then utilize a pre-trained large language model to update the dialogue state
using the augmented dialogue information and examples. Experimental results
demonstrate that IDIC-DST achieves state-of-the-art performance in few-shot
settings on MultiWOZ 2.1 and MultiWOZ 2.4 datasets.

摘要：對話狀態追蹤 (DST) 在任務導向對話系統中扮演著重要的角色。然而，使用者的輸入可能包含隱含資訊，對 DST 任務造成重大的挑戰。此外，DST 資料包含複雜的資訊，不僅包含大量與目前輪次無關的雜訊，也讓建構 DST 資料集變得昂貴。為了應對這些挑戰，我們引入了意圖驅動的脈絡中學習，用於少量 DST (IDIC-DST)。透過提取使用者的意圖，我們提出了一個意圖驅動的對話資訊擴充模組來擴充對話資訊，可以更有效地追蹤對話狀態。此外，我們遮蔽 DST 資料中的雜訊資訊，並在意圖驅動的範例擷取模組中改寫使用者的輸入，在其中我們擷取類似的範例。接著，我們利用預先訓練的大語言模型，使用擴充的對話資訊和範例來更新對話狀態。實驗結果顯示，IDIC-DST 在 MultiWOZ 2.1 和 MultiWOZ 2.4 資料集上的少量設定中，達到了最先進的效能。

##### **Alignment at Pre-training! Towards Native Alignment for Arabic LLMs**
2412.03253v1 by Juhao Liang, Zhenyang Cai, Jianqing Zhu, Huang Huang, Kewei Zong, Bang An, Mosen Alharthi, Juncai He, Lian Zhang, Haizhou Li, Benyou Wang, Jinchao Xu

The alignment of large language models (LLMs) is critical for developing
effective and safe language models. Traditional approaches focus on aligning
models during the instruction tuning or reinforcement learning stages, referred
to in this paper as `post alignment'. We argue that alignment during the
pre-training phase, which we term `native alignment', warrants investigation.
Native alignment aims to prevent unaligned content from the beginning, rather
than relying on post-hoc processing. This approach leverages extensively
aligned pre-training data to enhance the effectiveness and usability of
pre-trained models. Our study specifically explores the application of native
alignment in the context of Arabic LLMs. We conduct comprehensive experiments
and ablation studies to evaluate the impact of native alignment on model
performance and alignment stability. Additionally, we release open-source
Arabic LLMs that demonstrate state-of-the-art performance on various
benchmarks, providing significant benefits to the Arabic LLM community.

摘要：大型語言模型（LLM）的對齊對於開發有效且安全的語言模型至關重要。傳統方法著重於在指令微調或強化學習階段對齊模型，本文稱之為「後對齊」。我們認為，在預訓練階段進行對齊（我們稱之為「原生對齊」）值得探討。原生對齊旨在從一開始就防止未對齊的內容，而不是依賴事後處理。這種方法充分利用經過大量對齊的預訓練資料，以增強預訓練模型的有效性和可用性。我們的研究特別探討了原生對齊在阿拉伯語 LLM 中的應用。我們進行了全面的實驗和消融研究，以評估原生對齊對模型效能和對齊穩定性的影響。此外，我們發布了開放原始碼的阿拉伯語 LLM，這些 LLM 在各種基準測試中表現出最先進的效能，為阿拉伯語 LLM 社群帶來顯著的好處。

##### **AIM: Adaptive Inference of Multi-Modal LLMs via Token Merging and Pruning**
2412.03248v1 by Yiwu Zhong, Zhuoming Liu, Yin Li, Liwei Wang

Large language models (LLMs) have enabled the creation of multi-modal LLMs
that exhibit strong comprehension of visual data such as images and videos.
However, these models usually rely on extensive visual tokens from visual
encoders, leading to high computational demands, which limits their
applicability in resource-constrained environments and for long-context tasks.
In this work, we propose a training-free adaptive inference method for
multi-modal LLMs that can accommodate a broad range of efficiency requirements
with a minimum performance drop. Our method consists of a) iterative token
merging based on embedding similarity before LLMs, and b) progressive token
pruning within LLM layers based on multi-modal importance. With a minimalist
design, our method can be applied to both video and image LLMs. Extensive
experiments on diverse video and image benchmarks demonstrate that, our method
substantially reduces computation load (e.g., a $\textbf{7-fold}$ reduction in
FLOPs) while preserving the performance of video and image LLMs. Further, under
a similar computational cost, our method outperforms the state-of-the-art
methods in long video understanding (e.g., $\textbf{+4.6}$ on MLVU).
Additionally, our in-depth analysis provides insights into token redundancy and
LLM layer behaviors, offering guidance for future research in designing
efficient multi-modal LLMs. Our code will be available at
https://github.com/LaVi-Lab/AIM.

摘要：<paragraph>大型語言模型 (LLM) 已能建立多模態 LLM，能對視覺資料（例如影像和影片）展現強大的理解力。
然而，這些模型通常仰賴視覺編碼器的廣泛視覺符號，導致高運算需求，限制其在資源受限環境和長脈絡任務中的應用。
在這項工作中，我們為多模態 LLM 提出一個免訓練的自適應推論方法，能以最小的效能下降來適應廣泛的效率需求。我們的做法包括 a) 在 LLM 之前根據嵌入相似性進行反覆符號合併，以及 b) 根據多模態重要性在 LLM 層中進行漸進符號修剪。我們的做法採用極簡設計，可應用於影片和影像 LLM。在各種影片和影像基準上的廣泛實驗證明，我們的做法大幅降低運算負載（例如，FLOP 減少了 $\textbf{7 倍}$），同時保留影片和影像 LLM 的效能。此外，在類似的運算成本下，我們的做法在長影片理解方面優於現有技術（例如，在 MLVU 上 $\textbf{+4.6}$）。
此外，我們的深入分析提供了符號冗餘和 LLM 層行為的見解，為未來設計高效多模態 LLM 的研究提供指導。我們的程式碼將於 https://github.com/LaVi-Lab/AIM 上提供。</paragraph>

##### **Benchmarking terminology building capabilities of ChatGPT on an English-Russian Fashion Corpus**
2412.03242v1 by Anastasiia Bezobrazova, Miriam Seghiri, Constantin Orasan

This paper compares the accuracy of the terms extracted using SketchEngine,
TBXTools and ChatGPT. In addition, it evaluates the quality of the definitions
produced by ChatGPT for these terms. The research is carried out on a
comparable corpus of fashion magazines written in English and Russian collected
from the web. A gold standard for the fashion terminology was also developed by
identifying web pages that can be harvested automatically and contain
definitions of terms from the fashion domain in English and Russian. This gold
standard was used to evaluate the quality of the extracted terms and of the
definitions produced. Our evaluation shows that TBXTools and SketchEngine,
while capable of high recall, suffer from reduced precision as the number of
terms increases, which affects their overall performance. Conversely, ChatGPT
demonstrates superior performance, maintaining or improving precision as more
terms are considered. Analysis of the definitions produced by ChatGPT for 60
commonly used terms in English and Russian shows that ChatGPT maintains a
reasonable level of accuracy and fidelity across languages, but sometimes the
definitions in both languages miss crucial specifics and include unnecessary
deviations. Our research reveals that no single tool excels universally; each
has strengths suited to particular aspects of terminology extraction and
application.

摘要：本文比較了使用 SketchEngine、TBXTools 和 ChatGPT 提取術語的準確性。此外，它還評估了 ChatGPT 為這些術語產生的定義的品質。研究是在從網路收集的以英語和俄語寫成的時尚雜誌的同類語料庫上進行的。還通過識別可以自動擷取並包含英語和俄語時尚領域術語定義的網頁，制定了時尚術語的黃金標準。這個黃金標準用於評估提取的術語和產生的定義的品質。我們的評估顯示，TBXTools 和 SketchEngine 雖然具有很高的召回率，但隨著術語數量的增加，它們的準確度會降低，這會影響它們的整體效能。相反，ChatGPT 表現出優異的效能，在考慮更多術語時，它能維持或提高準確度。對 ChatGPT 為英語和俄語中 60 個常用術語產生的定義進行分析，結果顯示 ChatGPT 在不同語言之間維持合理的準確度和保真度，但有時兩種語言的定義都會遺漏關鍵的具體資訊，並包含不必要的偏差。我們的研究表明，沒有單一的工具能普遍勝出；每個工具都有適合術語提取和應用特定方面的優勢。

##### **Does Safety Training of LLMs Generalize to Semantically Related Natural Prompts?**
2412.03235v1 by Sravanti Addepalli, Yerram Varun, Arun Suggala, Karthikeyan Shanmugam, Prateek Jain

Large Language Models (LLMs) are known to be susceptible to crafted
adversarial attacks or jailbreaks that lead to the generation of objectionable
content despite being aligned to human preferences using safety fine-tuning
methods. While the large dimensionality of input token space makes it
inevitable to find adversarial prompts that can jailbreak these models, we aim
to evaluate whether safety fine-tuned LLMs are safe against natural prompts
which are semantically related to toxic seed prompts that elicit safe responses
after alignment. We surprisingly find that popular aligned LLMs such as GPT-4
can be compromised using naive prompts that are NOT even crafted with an
objective of jailbreaking the model. Furthermore, we empirically show that
given a seed prompt that elicits a toxic response from an unaligned model, one
can systematically generate several semantically related natural prompts that
can jailbreak aligned LLMs. Towards this, we propose a method of Response
Guided Question Augmentation (ReG-QA) to evaluate the generalization of safety
aligned LLMs to natural prompts, that first generates several toxic answers
given a seed question using an unaligned LLM (Q to A), and further leverages an
LLM to generate questions that are likely to produce these answers (A to Q). We
interestingly find that safety fine-tuned LLMs such as GPT-4o are vulnerable to
producing natural jailbreak questions from unsafe content (without denial) and
can thus be used for the latter (A to Q) step. We obtain attack success rates
that are comparable to/ better than leading adversarial attack methods on the
JailbreakBench leaderboard, while being significantly more stable against
defenses such as Smooth-LLM and Synonym Substitution, which are effective
against existing all attacks on the leaderboard.

摘要：大型语言模型 (LLM) 已知容易受到精心设计的对抗性攻击或越狱攻击，尽管使用安全微调方法与人类偏好保持一致，但这些攻击或越狱攻击会导致生成令人反感的内容。虽然输入标记空间的大维度使得找到可以越狱这些模型的对抗性提示不可避免，但我们的目标是评估经过安全微调的 LLM 是否可以防止与语义相关的自然提示，这些提示与引发对齐后安全响应的有毒种子提示相关。我们惊讶地发现，诸如 GPT-4 等流行的对齐 LLM 可以使用天真的提示来破坏，甚至这些提示并不是为了越狱模型而设计的。此外，我们凭经验表明，给定一个从未对齐的模型引发出有毒反应的种子提示，人们可以系统地生成几个语义相关的自然提示，这些提示可以越狱对齐的 LLM。为此，我们提出了一种响应引导问题增强 (ReG-QA) 方法来评估安全对齐的 LLM 对自然提示的泛化，该方法首先使用未对齐的 LLM (Q 到 A) 给定一个种子问题生成几个有毒答案，并进一步利用 LLM 生成可能产生这些答案的问题 (A 到 Q)。我们有趣地发现，诸如 GPT-4o 等经过安全微调的 LLM 容易从不安全内容（没有否认）中产生自然的越狱问题，因此可以用于后者（A 到 Q）步骤。我们获得的攻击成功率与 JailbreakBench 排行榜上的领先对抗性攻击方法相当/更好，同时对平滑 LLM 和同义词替换等防御措施的稳定性明显更高，而这些防御措施对排行榜上的所有现有攻击都是有效的。

##### **PERL: Pinyin Enhanced Rephrasing Language Model for Chinese ASR N-best Error Correction**
2412.03230v1 by Junhong Liang

ASR correction methods have predominantly focused on general datasets and
have not effectively utilized Pinyin information, unique to the Chinese
language. In this study, we address this gap by proposing a Pinyin Enhanced
Rephrasing Language Model (PERL), specifically designed for N-best correction
scenarios. Additionally, we implement a length predictor module to address the
variable-length problem. We conduct experiments on the Aishell-1 dataset and
our newly proposed DoAD dataset. The results show that our approach outperforms
baseline methods, achieving a 29.11% reduction in Character Error Rate (CER) on
Aishell-1 and around 70% CER reduction on domain-specific datasets.
Furthermore, our approach leverages Pinyin similarity at the token level,
providing an advantage over baselines and leading to superior performance.

摘要：語音辨識校正方法主要集中在一般資料集，且尚未有效利用中文特有的注音符號資訊。在本研究中，我們透過提出專門設計用於 N-best 校正情境的注音符號增強改述語言模型 (PERL) 來解決此差距。此外，我們實作長度預測模組來解決長度變異的問題。我們在 Aishell-1 資料集和我們新提出的 DoAD 資料集上進行實驗。結果顯示，我們的做法優於基線方法，在 Aishell-1 上將字元錯誤率 (CER) 降低了 29.11%，在特定領域的資料集上將 CER 降低了約 70%。此外，我們的做法在符號層級中利用注音符號相似性，相較於基線方法具有優勢，並帶來更優異的效能。

##### **Linq-Embed-Mistral Technical Report**
2412.03223v1 by Chanyeol Choi, Junseong Kim, Seolhwa Lee, Jihoon Kwon, Sangmo Gu, Yejin Kim, Minkyung Cho, Jy-yong Sohn

This report explores the enhancement of text retrieval performance using
advanced data refinement techniques. We develop
Linq-Embed-Mistral\footnote{\url{https://huggingface.co/Linq-AI-Research/Linq-Embed-Mistral}}
by building on the E5-mistral and Mistral-7B-v0.1 models, focusing on
sophisticated data crafting, data filtering, and negative mining methods, which
are highly tailored to each task, applied to both existing benchmark dataset
and highly tailored synthetic dataset generated via large language models
(LLMs). Linq-Embed-Mistral excels in the MTEB benchmarks (as of May 29, 2024),
achieving an average score of 68.2 across 56 datasets, and ranks 1st among all
models for retrieval tasks on the MTEB leaderboard with a performance score of
60.2. This performance underscores its superior capability in enhancing search
precision and reliability. Our contributions include advanced data refinement
methods that significantly improve model performance on benchmark and synthetic
datasets, techniques for homogeneous task ordering and mixed task fine-tuning
to enhance model generalization and stability, and a streamlined evaluation
process using 4-bit precision and a light retrieval evaluation set, which
accelerates validation without sacrificing accuracy.

摘要：本報告探討使用進階資料精煉技術來提升文字檢索效能。我們在 E5-mistral 和 Mistral-7B-v0.1 模型的基礎上開發 Linq-Embed-Mistral\footnote{\url{https://huggingface.co/Linq-AI-Research/Linq-Embed-Mistral}}，專注於精密的資料製作、資料篩選和負面挖掘方法，這些方法針對每個任務量身打造，應用於現有的基準資料集和透過大型語言模型 (LLM) 生成的量身打造合成資料集。截至 2024 年 5 月 29 日，Linq-Embed-Mistral 在 MTEB 基準中表現出色，在 56 個資料集中取得平均 68.2 分，在 MTEB 排行榜上，檢索任務的所有模型中排名第 1，效能分數為 60.2。此效能突顯其在提升搜尋精準度和可靠度方面的優異能力。我們的貢獻包括進階資料精煉方法，可大幅提升基準和合成資料集上的模型效能、同質任務排序和混合任務微調技術，以提升模型概化和穩定性，以及使用 4 位元精準度和輕量檢索評估集的簡化評估流程，這能在不犧牲精準度的情況下加速驗證。

##### **ClusterKV: Manipulating LLM KV Cache in Semantic Space for Recallable Compression**
2412.03213v1 by Guangda Liu, Chengwei Li, Jieru Zhao, Chenqi Zhang, Minyi Guo

Large Language Models (LLMs) have been widely deployed in a variety of
applications, and the context length is rapidly increasing to handle tasks such
as long-document QA and complex logical reasoning. However, long context poses
significant challenges for inference efficiency, including high memory costs of
key-value (KV) cache and increased latency due to extensive memory accesses.
Recent works have proposed compressing KV cache to approximate computation, but
these methods either evict tokens permanently, never recalling them for later
inference, or recall previous tokens at the granularity of pages divided by
textual positions. Both approaches degrade the model accuracy and output
quality. To achieve efficient and accurate recallable KV cache compression, we
introduce ClusterKV, which recalls tokens at the granularity of semantic
clusters. We design and implement efficient algorithms and systems for
clustering, selection, indexing and caching. Experiment results show that
ClusterKV attains negligible accuracy loss across various tasks with 32k
context lengths, using only a 1k to 2k KV cache budget, and achieves up to a
2$\times$ speedup in latency and a 2.5$\times$ improvement in decoding
throughput. Compared to SoTA recallable KV compression methods, ClusterKV
demonstrates higher model accuracy and output quality, while maintaining or
exceeding inference efficiency.

摘要：大型語言模型 (LLM) 已廣泛部署於各種應用程式中，且背景長度迅速增加，以處理長文件問答和複雜邏輯推理等任務。然而，長背景對推論效率構成重大挑戰，包括鍵值 (KV) 快取的高記憶體成本，以及由於大量記憶體存取而增加的延遲。最近的研究已提出壓縮 KV 快取以近似計算，但這些方法會永久驅逐權杖，永遠不會在後續推論中提取它們，或在由文字位置劃分的頁面粒度中提取先前的權杖。這兩種方法都會降低模型準確度和輸出品質。為了達成有效且準確的可提取 KV 快取壓縮，我們引入了 ClusterKV，它在語義叢集的粒度中提取權杖。我們設計並實作了用於叢集、選擇、索引和快取的有效演算法和系統。實驗結果顯示，ClusterKV 在各種任務中獲得極小的準確度損失，背景長度為 32k，僅使用 1k 到 2k 的 KV 快取預算，並在延遲中實現了高達 2 倍的加速，以及在解碼處理量中實現了 2.5 倍的提升。與 SoTA 可提取 KV 壓縮方法相比，ClusterKV 展示了更高的模型準確度和輸出品質，同時維持或超越推論效率。

##### **U-MATH: A University-Level Benchmark for Evaluating Mathematical Skills in LLMs**
2412.03205v1 by Konstantin Chernyshev, Vitaliy Polshkov, Ekaterina Artemova, Alex Myasnikov, Vlad Stepanov, Alexei Miasnikov, Sergei Tilga

The current evaluation of mathematical skills in LLMs is limited, as existing
benchmarks are either relatively small, primarily focus on elementary and
high-school problems, or lack diversity in topics. Additionally, the inclusion
of visual elements in tasks remains largely under-explored.
  To address these gaps, we introduce U-MATH, a novel benchmark of 1,100
unpublished open-ended university-level problems sourced from teaching
materials. It is balanced across six core subjects, with 20% of multimodal
problems. Given the open-ended nature of U-MATH problems, we employ an LLM to
judge the correctness of generated solutions. To this end, we release
$\mu$-MATH, a dataset to evaluate the LLMs' capabilities in judging solutions.
  The evaluation of general domain, math-specific, and multimodal LLMs
highlights the challenges presented by U-MATH. Our findings reveal that LLMs
achieve a maximum accuracy of only 63% on text-based tasks, with even lower 45%
on visual problems. The solution assessment proves challenging for LLMs, with
the best LLM judge having an F1-score of 80% on $\mu$-MATH.

摘要：現有評估 LLM 數學技能的標準有限，因為現有基準要不規模較小、主要著重於小學和高中問題，要不缺乏主題多元性。此外，任務中包含視覺元素的部分仍未得到充分探討。
為了解決這些差距，我們引入了 U-MATH，這是一個由教學材料中蒐集的 1,100 個未發表的開放式大學程度問題的新基準。它涵蓋六個核心科目，20% 為多模態問題。鑑於 U-MATH 問題的開放式性質，我們採用 LLM 來判斷所產生解法的正確性。為此，我們發布了 $\mu$-MATH，一個用於評估 LLM 判斷解題能力的資料集。
對一般領域、特定數學和多模態 LLM 的評估突顯了 U-MATH 所帶來的挑戰。我們的研究結果顯示，LLM 在基於文字的任務上僅達到 63% 的最高準確度，在視覺問題上甚至更低，只有 45%。解題評估對 LLM 來說具有挑戰性，最佳 LLM 評審在 $\mu$-MATH 上的 F1 分數為 80%。

##### **Semi-decentralized Training of Spatio-Temporal Graph Neural Networks for Traffic Prediction**
2412.03188v1 by Ivan Kralj, Lodovico Giaretta, Gordan Ježić, Ivana Podnar Žarko, Šarūnas Girdzijauskas

In smart mobility, large networks of geographically distributed sensors
produce vast amounts of high-frequency spatio-temporal data that must be
processed in real time to avoid major disruptions. Traditional centralized
approaches are increasingly unsuitable to this task, as they struggle to scale
with expanding sensor networks, and reliability issues in central components
can easily affect the whole deployment. To address these challenges, we explore
and adapt semi-decentralized training techniques for Spatio-Temporal Graph
Neural Networks (ST-GNNs) in smart mobility domain. We implement a simulation
framework where sensors are grouped by proximity into multiple cloudlets, each
handling a subgraph of the traffic graph, fetching node features from other
cloudlets to train its own local ST-GNN model, and exchanging model updates
with other cloudlets to ensure consistency, enhancing scalability and removing
reliance on a centralized aggregator. We perform extensive comparative
evaluation of four different ST-GNN training setups -- centralized, traditional
FL, server-free FL, and Gossip Learning -- on large-scale traffic datasets, the
METR-LA and PeMS-BAY datasets, for short-, mid-, and long-term vehicle speed
predictions. Experimental results show that semi-decentralized setups are
comparable to centralized approaches in performance metrics, while offering
advantages in terms of scalability and fault tolerance. In addition, we
highlight often overlooked issues in existing literature for distributed
ST-GNNs, such as the variation in model performance across different
geographical areas due to region-specific traffic patterns, and the significant
communication overhead and computational costs that arise from the large
receptive field of GNNs, leading to substantial data transfers and increased
computation of partial embeddings.

摘要：<paragraph>在智慧行動領域中，由地理分散感測器組成的龐大網路會產生大量的時空高頻率資料，這些資料必須即時處理，才能避免重大中斷。傳統的集中式方法愈來愈不適合這項任務，因為它們在擴展感測器網路時難以擴充，而中央組件的可靠性問題也可能輕易影響整個部署。為了應對這些挑戰，我們探索並調整了智慧行動領域中時空圖形神經網路 (ST-GNN) 的半分散式訓練技術。我們實作了一個模擬架構，其中感測器會依據接近性分組到多個雲端中，每個雲端處理交通圖形的一個子圖，從其他雲端擷取節點特徵來訓練其自己的局部 ST-GNN 模型，並與其他雲端交換模型更新以確保一致性，進而提升擴充性並消除對集中式彙總器的依賴。我們對四種不同的 ST-GNN 訓練設定進行廣泛的比較評估，包括集中式、傳統 FL、無伺服器 FL 和八卦學習，這些評估是在大規模交通資料集（METR-LA 和 PeMS-BAY 資料集）上進行，用於短期、中期和長期車輛速度預測。實驗結果顯示，半分散式設定在效能指標上可與集中式方法相提並論，同時在擴充性和容錯性方面具有優勢。此外，我們強調了現有分散式 ST-GNN 文獻中經常被忽略的問題，例如由於區域特定交通模式而導致不同地理區域的模型效能差異，以及由於 GNN 的大感受野而產生的顯著通訊開銷和運算成本，導致大量資料傳輸和局部嵌入運算增加。</paragraph>

##### **Weighted-Reward Preference Optimization for Implicit Model Fusion**
2412.03187v1 by Ziyi Yang, Fanqi Wan, Longguang Zhong, Tianyuan Shi, Xiaojun Quan

While fusing heterogeneous open-source LLMs with varying architectures and
sizes can potentially integrate the strengths of different models, existing
fusion methods face significant challenges, such as vocabulary alignment and
merging distribution matrices. These procedures are not only complex but also
prone to introducing noise and errors. In this paper, we propose an implicit
fusion method, Weighted-Reward Preference Optimization (WRPO), which leverages
preference optimization between the source LLMs and the target LLM to transfer
their capabilities effectively. WRPO eliminates the need for vocabulary
alignment and matrix fusion and can be efficiently scaled to accommodate
various LLMs. To address distributional deviations between the source and
target LLMs, WRPO introduces a progressive adaptation strategy that gradually
shifts reliance on preferred examples from the target LLM to the source LLMs.
Extensive experiments on the MT-Bench, AlpacaEval-2, and Arena-Hard benchmarks
demonstrate that WRPO consistently outperforms existing knowledge fusion
methods and various fine-tuning baselines. When applied to LLaMA3-8B-Instruct
as the target model, WRPO achieves a length-controlled win rate of 55.9%
against GPT-4-Preview-1106 on AlpacaEval-2 and a win rate of 46.2% against
GPT-4-0314 on Arena-Hard. Our code is available at
\url{https://github.com/SLIT-AI/WRPO}.

摘要：<paragraph>雖然融合異質開放原始碼 LLM，其架構和規模各異，有整合不同模型優勢的潛力，現有的融合方法卻面臨諸多挑戰，例如詞彙比對和合併分佈矩陣。這些程序不僅複雜，還容易引入雜訊和錯誤。在本文中，我們提出了一種隱式融合方法，即加權獎勵偏好最佳化 (WRPO)，它利用原始 LLM 和目標 LLM 之間的偏好最佳化來有效轉移它們的能力。WRPO 消除了詞彙比對和矩陣融合的需要，並且可以有效擴展以容納各種 LLM。為了解決原始和目標 LLM 之間的分配偏差，WRPO 引入了一種漸進適應策略，逐漸將對目標 LLM 的偏好範例的依賴轉移到原始 LLM。在 MT-Bench、AlpacaEval-2 和 Arena-Hard 基準上的廣泛實驗表明，WRPO 持續優於現有的知識融合方法和各種微調基準。當應用於 LLaMA3-8B-Instruct 作為目標模型時，WRPO 在 AlpacaEval-2 上對 GPT-4-Preview-1106 達到了 55.9% 的長度控制獲勝率，在 Arena-Hard 上對 GPT-4-0314 達到了 46.2% 的獲勝率。我們的程式碼可在以下網址取得：\url{https://github.com/SLIT-AI/WRPO}。</paragraph>

##### **Optimizing Dense Visual Predictions Through Multi-Task Coherence and Prioritization**
2412.03179v1 by Maxime Fontana, Michael Spratling, Miaojing Shi

Multi-Task Learning (MTL) involves the concurrent training of multiple tasks,
offering notable advantages for dense prediction tasks in computer vision. MTL
not only reduces training and inference time as opposed to having multiple
single-task models, but also enhances task accuracy through the interaction of
multiple tasks. However, existing methods face limitations. They often rely on
suboptimal cross-task interactions, resulting in task-specific predictions with
poor geometric and predictive coherence. In addition, many approaches use
inadequate loss weighting strategies, which do not address the inherent
variability in task evolution during training. To overcome these challenges, we
propose an advanced MTL model specifically designed for dense vision tasks. Our
model leverages state-of-the-art vision transformers with task-specific
decoders. To enhance cross-task coherence, we introduce a trace-back method
that improves both cross-task geometric and predictive features. Furthermore,
we present a novel dynamic task balancing approach that projects task losses
onto a common scale and prioritizes more challenging tasks during training.
Extensive experiments demonstrate the superiority of our method, establishing
new state-of-the-art performance across two benchmark datasets. The code is
available at:https://github.com/Klodivio355/MT-CP

摘要：多任務學習 (MTL) 涉及多個任務的並發訓練，為電腦視覺中的密集預測任務提供了顯著優勢。MTL 不僅減少了訓練和推理時間，與擁有多個單任務模型相比，還通過多個任務的交互增強了任務準確性。然而，現有方法面臨限制。它們通常依賴於次優的跨任務交互，導致任務特定的預測具有較差的幾何和預測一致性。此外，許多方法使用不充分的損失加權策略，這無法解決訓練過程中任務演化的固有變異性。為了克服這些挑戰，我們提出了一個專門為密集視覺任務設計的高級 MTL 模型。我們的模型利用了最先進的視覺變換器和任務特定的解碼器。為了增強跨任務一致性，我們引入了一種追溯方法，它改進了跨任務幾何和預測特徵。此外，我們提出了一種新穎的動態任務平衡方法，它將任務損失投影到一個公共尺度上，並在訓練過程中優先考慮更具挑戰性的任務。廣泛的實驗證明了我們方法的優越性，在兩個基準數據集上建立了新的最先進性能。代碼可在以下位置獲得：https://github.com/Klodivio355/MT-CP

##### **Towards Understanding and Quantifying Uncertainty for Text-to-Image Generation**
2412.03178v1 by Gianni Franchi, Dat Nguyen Trong, Nacim Belkhir, Guoxuan Xia, Andrea Pilzer

Uncertainty quantification in text-to-image (T2I) generative models is
crucial for understanding model behavior and improving output reliability. In
this paper, we are the first to quantify and evaluate the uncertainty of T2I
models with respect to the prompt. Alongside adapting existing approaches
designed to measure uncertainty in the image space, we also introduce
Prompt-based UNCertainty Estimation for T2I models (PUNC), a novel method
leveraging Large Vision-Language Models (LVLMs) to better address uncertainties
arising from the semantics of the prompt and generated images. PUNC utilizes a
LVLM to caption a generated image, and then compares the caption with the
original prompt in the more semantically meaningful text space. PUNC also
enables the disentanglement of both aleatoric and epistemic uncertainties via
precision and recall, which image-space approaches are unable to do. Extensive
experiments demonstrate that PUNC outperforms state-of-the-art uncertainty
estimation techniques across various settings. Uncertainty quantification in
text-to-image generation models can be used on various applications including
bias detection, copyright protection, and OOD detection. We also introduce a
comprehensive dataset of text prompts and generation pairs to foster further
research in uncertainty quantification for generative models. Our findings
illustrate that PUNC not only achieves competitive performance but also enables
novel applications in evaluating and improving the trustworthiness of
text-to-image models.

摘要：在文本到图像 (T2I) 生成模型中量化不确定性对于理解模型行为和提高输出可靠性至关重要。在本文中，我们首次量化和评估了 T2I 模型相对于提示的不确定性。除了调整旨在测量图像空间中不确定性的现有方法外，我们还引入了基于提示的不确定性估计用于 T2I 模型 (PUNC)，这是一种利用大型视觉语言模型 (LVLMs) 来更好地解决源自提示语义和生成图像的不确定性。PUNC 利用 LVLM 为生成的图像添加标题，然后在语义上更有意义的文本空间中将标题与原始提示进行比较。PUNC 还能够通过精度和召回率来解开偶然不确定性和认知不确定性，这是图像空间方法无法做到的。大量的实验表明，PUNC 在各种设置下都优于最先进的不确定性估计技术。文本到图像生成模型中的不确定性量化可用于各种应用，包括偏差检测、版权保护和 OOD 检测。我们还引入了一个包含文本提示和生成对的综合数据集，以促进对生成模型不确定性量化的进一步研究。我们的研究结果表明，PUNC 不仅实现了有竞争力的性能，而且还能够在评估和提高文本到图像模型的可信度方面实现新应用。

##### **Automatic detection of diseases in Spanish clinical notes combining medical language models and ontologies**
2412.03176v1 by Leon-Paul Schaub Torre, Pelayo Quiros, Helena Garcia Mieres

In this paper we present a hybrid method for the automatic detection of
dermatological pathologies in medical reports. We use a large language model
combined with medical ontologies to predict, given a first appointment or
follow-up medical report, the pathology a person may suffer from. The results
show that teaching the model to learn the type, severity and location on the
body of a dermatological pathology, as well as in which order it has to learn
these three features, significantly increases its accuracy. The article
presents the demonstration of state-of-the-art results for classification of
medical texts with a precision of 0.84, micro and macro F1-score of 0.82 and
0.75, and makes both the method and the data set used available to the
community.

摘要：在本文中，我們提出了一種混合方法，用於自動檢測醫療報告中的皮膚病理。我們使用大型語言模型結合醫學本体，預測給定初診或後續醫療報告，一個人可能患有的病理。結果表明，教授模型學習皮膚病理的類型、嚴重程度和身體位置，以及按何種順序學習這三個特徵，可以顯著提高其準確性。本文展示了醫學文本分類的最新結果，精確度為 0.84，微觀和巨觀 F1 分數為 0.82 和 0.75，並將方法和數據集提供給社區。

##### **Physics-Informed Deep Inverse Operator Networks for Solving PDE Inverse Problems**
2412.03161v1 by Sung Woong Cho, Hwijae Son

Inverse problems involving partial differential equations (PDEs) can be seen
as discovering a mapping from measurement data to unknown quantities, often
framed within an operator learning approach. However, existing methods
typically rely on large amounts of labeled training data, which is impractical
for most real-world applications. Moreover, these supervised models may fail to
capture the underlying physical principles accurately. To address these
limitations, we propose a novel architecture called Physics-Informed Deep
Inverse Operator Networks (PI-DIONs), which can learn the solution operator of
PDE-based inverse problems without labeled training data. We extend the
stability estimates established in the inverse problem literature to the
operator learning framework, thereby providing a robust theoretical foundation
for our method. These estimates guarantee that the proposed model, trained on a
finite sample and grid, generalizes effectively across the entire domain and
function space. Extensive experiments are conducted to demonstrate that
PI-DIONs can effectively and accurately learn the solution operators of the
inverse problems without the need for labeled data.

摘要：涉及偏微分方程 (PDE) 的反問題可以視為從測量數據中找出對應未知數的對應關係，通常會在運算子學習方法中建構。不過，現有方法通常仰賴大量標籤訓練資料，這在多數真實世界的應用中並不切實際。此外，這些監督式模型可能無法精準捕捉到底層的物理原理。為了解決這些限制，我們提出了一種稱為物理訊息深度反運算子網路 (PI-DION) 的新架構，它可以在沒有標籤訓練資料的情況下學習基於 PDE 的反問題的解運算子。我們將反問題文獻中已建立的穩定性估計值延伸到運算子學習架構中，進而為我們的模型提供穩健的理論基礎。這些估計值保證了所提出的模型在有限樣本和網格上訓練後，可以在整個網域和函數空間中有效地進行概化。我們進行了大量的實驗，以證明 PI-DION 可以有效且精準地學習反問題的解運算子，而且不需要標籤資料。

##### **Byte BPE Tokenization as an Inverse string Homomorphism**
2412.03160v1 by Saibo Geng, Sankalp Gambhir, Chris Wendler, Robert West

Tokenization is an important preprocessing step in the training and inference
of large language models (LLMs). While there has been extensive research on the
expressive power of the neural achitectures used in LLMs, the impact of
tokenization has not been well understood. In this work, we demonstrate that
tokenization, irrespective of the algorithm used, acts as an inverse
homomorphism between strings and tokens. This suggests that the character space
of the source language and the token space of the tokenized language are
homomorphic, preserving the structural properties of the source language.
Additionally, we explore the concept of proper tokenization, which refers to an
unambiguous tokenization returned from the tokenizer. Our analysis reveals that
the expressiveness of neural architectures in recognizing context-free
languages is not affected by tokenization.

摘要：分詞是訓練和推論大型語言模型 (LLM) 中一個重要的預處理步驟。雖然對於 LLM 中使用的神經架構的表現力已有廣泛的研究，但分詞的影響尚未被充分理解。在這項工作中，我們證明了分詞，無論使用何種演算法，都充當字串和符號之間的反同態。這表明原始語言的字元空間和分詞語言的符號空間是同態的，保留了原始語言的結構特性。此外，我們探討了適當分詞的概念，這指的是從分詞器返回的明確分詞。我們的分析表明，神經架構在識別上下文無關語言中的表現力不受分詞的影響。

##### **Testing Neural Network Verifiers: A Soundness Benchmark with Hidden Counterexamples**
2412.03154v1 by Xingjian Zhou, Hongji Xu, Andy Xu, Zhouxing Shi, Cho-Jui Hsieh, Huan Zhang

In recent years, many neural network (NN) verifiers have been developed to
formally verify certain properties of neural networks such as robustness.
Although many benchmarks have been constructed to evaluate the performance of
NN verifiers, they typically lack a ground-truth for hard instances where no
current verifier can verify and no counterexample can be found, which makes it
difficult to check the soundness of a new verifier if it claims to verify hard
instances which no other verifier can do. We propose to develop a soundness
benchmark for NN verification. Our benchmark contains instances with
deliberately inserted counterexamples while we also try to hide the
counterexamples from regular adversarial attacks which can be used for finding
counterexamples. We design a training method to produce neural networks with
such hidden counterexamples. Our benchmark aims to be used for testing the
soundness of NN verifiers and identifying falsely claimed verifiability when it
is known that hidden counterexamples exist. We systematically construct our
benchmark and generate instances across diverse model architectures, activation
functions, input sizes, and perturbation radii. We demonstrate that our
benchmark successfully identifies bugs in state-of-the-art NN verifiers, as
well as synthetic bugs, providing a crucial step toward enhancing the
reliability of testing NN verifiers. Our code is available at
https://github.com/MVP-Harry/SoundnessBench and our benchmark is available at
https://huggingface.co/datasets/SoundnessBench/SoundnessBench.

摘要：近年来，许多神经网络 (NN) 验证器被开发出来，以正式验证神经网络的某些属性，例如鲁棒性。虽然已经构建了许多基准来评估 NN 验证器的性能，但它们通常缺乏难以验证的实例的基本事实，而当前没有验证器可以验证并且找不到反例，这使得如果声称验证其他验证器无法验证的困难实例，则难以检查新验证器的健全性。我们建议为 NN 验证开发一个健全性基准。我们的基准包含故意插入反例的实例，而我们也尝试将反例隐藏在常规对抗性攻击中，该攻击可用于查找反例。我们设计了一种训练方法来生成具有此类隐藏反例的神经网络。我们的基准旨在用于测试 NN 验证器的健全性，并在已知存在隐藏反例的情况下识别错误声称的可验证性。我们系统地构建基准，并在不同的模型架构、激活函数、输入大小和扰动半径中生成实例。我们证明了我们的基准成功地识别了最先进的 NN 验证器中的错误，以及合成的错误，为提高 NN 验证器测试的可靠性提供了至关重要的一步。我们的代码可在 https://github.com/MVP-Harry/SoundnessBench 获得，我们的基准可在 https://huggingface.co/datasets/SoundnessBench/SoundnessBench 获得。

##### **Large Language Models show both individual and collective creativity comparable to humans**
2412.03151v1 by Luning Sun, Yuzhuo Yuan, Yuan Yao, Yanyan Li, Hao Zhang, Xing Xie, Xiting Wang, Fang Luo, David Stillwell

Artificial intelligence has, so far, largely automated routine tasks, but
what does it mean for the future of work if Large Language Models (LLMs) show
creativity comparable to humans? To measure the creativity of LLMs
holistically, the current study uses 13 creative tasks spanning three domains.
We benchmark the LLMs against individual humans, and also take a novel approach
by comparing them to the collective creativity of groups of humans. We find
that the best LLMs (Claude and GPT-4) rank in the 52nd percentile against
humans, and overall LLMs excel in divergent thinking and problem solving but
lag in creative writing. When questioned 10 times, an LLM's collective
creativity is equivalent to 8-10 humans. When more responses are requested, two
additional responses of LLMs equal one extra human. Ultimately, LLMs, when
optimally applied, may compete with a small group of humans in the future of
work.

摘要：目前為止，人工智慧已經自動化了大量的例行工作，但如果大型語言模型 (LLM) 展現出與人類相當的創造力，這對工作的未來而言代表什麼意義？為了全面衡量 LLM 的創造力，目前的研究使用了涵蓋三個領域的 13 項創造力任務。我們以個別人類為基準來評量 LLM，並採用創新的方法，將它們與人類群體的集體創造力進行比較。我們發現，最佳的 LLM（Claude 和 GPT-4）在與人類的比較中排名第 52 個百分位，整體而言，LLM 在發散性思考和問題解決方面表現出色，但在創意寫作方面則落後。當被詢問 10 次時，LLM 的集體創造力等於 8-10 個人類。當要求提供更多回應時，LLM 的兩個額外回應等於一個額外的人類。最終，在最佳應用時，LLM 可能在未來的職場中與一小群人類競爭。

##### **Fine-Grained Behavior Simulation with Role-Playing Large Language Model on Social Media**
2412.03148v1 by Kun Li, Chenwei Dai, Wei Zhou, Songlin Hu

Large language models (LLMs) have demonstrated impressive capabilities in
role-playing tasks. However, there is limited research on whether LLMs can
accurately simulate user behavior in real-world scenarios, such as social
media. This requires models to effectively analyze a user's history and
simulate their role. In this paper, we introduce \textbf{FineRob}, a novel
fine-grained behavior simulation dataset. We collect the complete behavioral
history of 1,866 distinct users across three social media platforms. Each
behavior is decomposed into three fine-grained elements: object, type, and
content, resulting in 78.6k QA records. Based on FineRob, we identify two
dominant reasoning patterns in LLMs' behavior simulation processes and propose
the \textbf{OM-CoT} fine-tuning method to enhance the capability. Through
comprehensive experiments, we conduct an in-depth analysis of key factors of
behavior simulation and also demonstrate the effectiveness of OM-CoT
approach\footnote{Code and dataset are available at
\url{https://github.com/linkseed18612254945/FineRob}}

摘要：大型語言模型 (LLM) 已在角色扮演任務中展示了令人印象深刻的能力。然而，關於 LLM 是否可以在現實世界場景中準確模擬使用者行為（例如社交媒體）的研究有限。這需要模型有效分析使用者的歷史記錄並模擬其角色。在本文中，我們介紹了 FineRob，這是一個新穎的細粒度行為模擬數據集。我們收集了 1,866 個不同使用者在三個社交媒體平台上的完整行為歷史記錄。每個行為被分解為三個細粒度元素：對象、類型和內容，產生了 78.6k 個問答記錄。基於 FineRob，我們在 LLM 的行為模擬過程中識別了兩種主要的推理模式，並提出了 OM-CoT 微調方法來增強能力。通過全面的實驗，我們對行為模擬的關鍵因素進行了深入分析，並展示了 OM-CoT 方法的有效性。

##### **Robust Multi-bit Text Watermark with LLM-based Paraphrasers**
2412.03123v1 by Xiaojun Xu, Jinghan Jia, Yuanshun Yao, Yang Liu, Hang Li

We propose an imperceptible multi-bit text watermark embedded by paraphrasing
with LLMs. We fine-tune a pair of LLM paraphrasers that are designed to behave
differently so that their paraphrasing difference reflected in the text
semantics can be identified by a trained decoder. To embed our multi-bit
watermark, we use two paraphrasers alternatively to encode the pre-defined
binary code at the sentence level. Then we use a text classifier as the decoder
to decode each bit of the watermark. Through extensive experiments, we show
that our watermarks can achieve over 99.99\% detection AUC with small (1.1B)
text paraphrasers while keeping the semantic information of the original
sentence. More importantly, our pipeline is robust under word substitution and
sentence paraphrasing perturbations and generalizes well to
out-of-distributional data. We also show the stealthiness of our watermark with
LLM-based evaluation. We open-source the code:
https://github.com/xiaojunxu/multi-bit-text-watermark.

摘要：我們提出一個由 LLM 釋義嵌入的難以察覺的多位元文字浮水印。我們微調了一對 LLM 釋義器，它們被設計成表現不同，這樣它們的釋義差異反映在文字語意中，就能被一個訓練過的解碼器識別。為了嵌入我們的多位元浮水印，我們交替使用兩個釋義器，在句子層級編碼預定義的二進位碼。然後我們使用文字分類器作為解碼器，解碼浮水印的每一比特。透過廣泛的實驗，我們證明我們的浮水印可以達到超過 99.99% 的偵測 AUC，文字釋義器很小（1.1B），同時保留原始句子的語意資訊。更重要的是，我們的管道在詞彙替換和句子釋義擾動下具有穩健性，並且可以很好地概括到分布外資料。我們還展示了我們浮水印的隱密性，並使用基於 LLM 的評估。我們開放原始碼：
https://github.com/xiaojunxu/multi-bit-text-watermark。

##### **Experience-driven discovery of planning strategies**
2412.03111v1 by Ruiqi He, Falk Lieder

One explanation for how people can plan efficiently despite limited cognitive
resources is that we possess a set of adaptive planning strategies and know
when and how to use them. But how are these strategies acquired? While previous
research has studied how individuals learn to choose among existing strategies,
little is known about the process of forming new planning strategies. In this
work, we propose that new planning strategies are discovered through
metacognitive reinforcement learning. To test this, we designed a novel
experiment to investigate the discovery of new planning strategies. We then
present metacognitive reinforcement learning models and demonstrate their
capability for strategy discovery as well as show that they provide a better
explanation of human strategy discovery than alternative learning mechanisms.
However, when fitted to human data, these models exhibit a slower discovery
rate than humans, leaving room for improvement.

摘要：人們儘管認知資源有限，卻能有效率地規劃，其中一個解釋是我們擁有一組適應性規劃策略，並知道何時以及如何使用它們。但這些策略是如何習得的呢？雖然先前的研究探討了個人如何學習在既有策略中做出選擇，但對於形成新規劃策略的過程所知甚少。在這項研究中，我們提出新的規劃策略是透過元認知強化學習而發現的。為了測試這一點，我們設計了一項新穎的實驗來研究新規劃策略的發現。接著，我們提出元認知強化學習模型，並展示它們發現策略的能力，以及它們比其他學習機制更能解釋人類的策略發現。然而，當這些模型套用於人類資料時，它們表現出比人類更慢的發現率，因此有進步的空間。

##### **CredID: Credible Multi-Bit Watermark for Large Language Models Identification**
2412.03107v1 by Haoyu Jiang, Xuhong Wang, Ping Yi, Shanzhe Lei, Yilun Lin

Large Language Models (LLMs) are widely used in complex natural language
processing tasks but raise privacy and security concerns due to the lack of
identity recognition. This paper proposes a multi-party credible watermarking
framework (CredID) involving a trusted third party (TTP) and multiple LLM
vendors to address these issues. In the watermark embedding stage, vendors
request a seed from the TTP to generate watermarked text without sending the
user's prompt. In the extraction stage, the TTP coordinates each vendor to
extract and verify the watermark from the text. This provides a credible
watermarking scheme while preserving vendor privacy. Furthermore, current
watermarking algorithms struggle with text quality, information capacity, and
robustness, making it challenging to meet the diverse identification needs of
LLMs. Thus, we propose a novel multi-bit watermarking algorithm and an
open-source toolkit to facilitate research. Experiments show our CredID
enhances watermark credibility and efficiency without compromising text
quality. Additionally, we successfully utilized this framework to achieve
highly accurate identification among multiple LLM vendors.

摘要：大型語言模型 (LLM) 廣泛用於複雜的自然語言處理任務，但由於缺乏身分識別，因此引發了隱私和安全問題。本文提出了一個多方可信浮水印架構 (CredID)，其中涉及一個受信任的第三方 (TTP) 和多個 LLM 供應商，以解決這些問題。在浮水印嵌入階段，供應商會向 TTP 要求一個種子，以產生浮水印文字，而不用傳送使用者的提示。在萃取階段，TTP 會協調每個供應商，以從文字中萃取和驗證浮水印。這提供了一個可信的浮水印架構，同時保護供應商的隱私。此外，目前的浮水印演算法在文字品質、資訊容量和穩健性方面都面臨挑戰，這使得難以滿足 LLM 多樣化的識別需求。因此，我們提出了一種新穎的多位元浮水印演算法和一個開源工具包，以利於研究。實驗顯示，我們的 CredID 增強了浮水印的可信度和效率，同時不損害文字品質。此外，我們成功地利用這個架構，在多個 LLM 供應商之間達到了高度準確的識別。

##### **ChatTS: Aligning Time Series with LLMs via Synthetic Data for Enhanced Understanding and Reasoning**
2412.03104v1 by Zhe Xie, Zeyan Li, Xiao He, Longlong Xu, Xidao Wen, Tieying Zhang, Jianjun Chen, Rui Shi, Dan Pei

Understanding time series is crucial for its application in real-world
scenarios. Recently, large language models (LLMs) have been increasingly
applied to time series tasks, leveraging their strong language capabilities to
enhance various applications. However, research on multimodal LLMs (MLLMs) for
time series understanding and reasoning remains limited, primarily due to the
scarcity of high-quality datasets that align time series with textual
information. This paper introduces ChatTS, a novel MLLM designed for time
series analysis. ChatTS treats time series as a modality, similar to how vision
MLLMs process images, enabling it to perform both understanding and reasoning
with time series. To address the scarcity of training data, we propose an
attribute-based method for generating synthetic time series with detailed
attribute descriptions. We further introduce Time Series Evol-Instruct, a novel
approach that generates diverse time series Q&As, enhancing the model's
reasoning capabilities. To the best of our knowledge, ChatTS is the first MLLM
that takes multivariate time series as input, which is fine-tuned exclusively
on synthetic datasets. We evaluate its performance using benchmark datasets
with real-world data, including six alignment tasks and four reasoning tasks.
Our results show that ChatTS significantly outperforms existing vision-based
MLLMs (e.g., GPT-4o) and text/agent-based LLMs, achieving a 46.0% improvement
in alignment tasks and a 25.8% improvement in reasoning tasks.

摘要：<paragraph>了解時間序列對於其在現實世界中的應用至關重要。最近，大型語言模型 (LLM) 已越來越多地應用於時間序列任務，利用其強大的語言能力來增強各種應用。然而，針對時間序列理解和推理的多模態 LLM (MLLM) 的研究仍然有限，這主要是因為缺乏將時間序列與文本信息對齊的高品質數據集。本文介紹了 ChatTS，這是一種專為時間序列分析設計的新型 MLLM。ChatTS 將時間序列視為一種模態，類似於視覺 MLLM 處理圖像的方式，使其能夠對時間序列進行理解和推理。為了解決訓練數據的稀缺性，我們提出了一種基於屬性的方法，用於生成具有詳細屬性描述的合成時間序列。我們進一步引入了時間序列 Evol-Instruct，這是一種生成多樣化時間序列問答的新方法，增強了模型的推理能力。據我們所知，ChatTS 是第一個將多變量時間序列作為輸入的 MLLM，它專門針對合成數據集進行微調。我們使用包含真實世界數據的基準數據集評估其性能，包括六個對齊任務和四個推理任務。我們的結果表明，ChatTS 明顯優於現有的基於視覺的 MLLM（例如 GPT-4o）和基於文本/代理的 LLM，在對齊任務中改進了 46.0%，在推理任務中改進了 25.8%。</paragraph>

##### **A surprisal oracle for when every layer counts**
2412.03098v1 by Xudong Hong, Sharid Loáiciga, Asad Sayeed

Active Curriculum Language Modeling (ACLM; Hong et al., 2023) is a learner
directed approach to training a language model. We proposed the original
version of this process in our submission to the BabyLM 2023 task, and now we
propose an updated ACLM process for the BabyLM 2024 task. ACLM involves an
iteratively- and dynamically-constructed curriculum informed over the training
process by a model of uncertainty; other training items that are similarly
uncertain to a least certain candidate item are prioritized. Our new process
improves the similarity model so that it is more dynamic, and we run ACLM over
the most successful model from the BabyLM 2023 task: ELC-BERT (Charpentier and
Samuel, 2023). We find that while our models underperform on fine-grained
grammatical inferences, they outperform the BabyLM 2024 official base-lines on
common-sense and world-knowledge tasks. We make our code available at https:
//github.com/asayeed/ActiveBaby.

摘要：主動式課程語言模型 (ACLM；Hong 等人，2023) 是一種由學習者引導，用於訓練語言模型的方法。我們在提交給 BabyLM 2023 任務時提出了這個流程的原始版本，現在我們為 BabyLM 2024 任務提出一個更新的 ACLM 流程。ACLM 涉及一個反覆且動態建構的課程，並在訓練過程中由一個不確定性模型提供資訊；其他訓練項目與至少一個最不確定的候選項目相似的不確定項目會被優先處理。我們的流程改進了相似性模型，使其更具動態性，我們在 BabyLM 2023 任務中最成功的模型：ELC-BERT (Charpentier 和 Samuel，2023) 上執行 ACLM。我們發現，儘管我們的模型在細微的語法推論上表現不佳，但它們在常識和世界知識任務上優於 BabyLM 2024 官方基準線。我們在 https://github.com/asayeed/ActiveBaby 上提供我們的程式碼。

##### **TOOL-ED: Enhancing Empathetic Response Generation with the Tool Calling Capability of LLM**
2412.03096v1 by Huiying Cao, Yiqun Zhang, Shi Feng, Xiaocui Yang, Daling Wang, Yifei Zhang

Empathetic conversation is a crucial characteristic in daily conversations
between individuals. Nowadays, Large Language models (LLMs) have shown
outstanding performance in generating empathetic responses. Knowledge bases
like COMET can assist LLMs in mitigating illusions and enhancing the
understanding of users' intentions and emotions. However, models remain heavily
reliant on fixed knowledge bases and unrestricted incorporation of external
knowledge can introduce noise. Tool learning is a flexible end-to-end approach
that assists LLMs in handling complex problems. In this paper, we propose
Emotional Knowledge Tool Calling (EKTC) framework, which encapsulates the
commonsense knowledge bases as empathetic tools, enabling LLMs to integrate
external knowledge flexibly through tool calling. In order to adapt the models
to the new task, we construct a novel dataset TOOL-ED based on the
EMPATHETICMPATHETIC DIALOGUE (ED) dataset. We validate EKTC on the ED dataset,
and the experimental results demonstrate that our framework can enhance the
ability of LLMs to generate empathetic responses effectively.

摘要：同理心對話是個人日常對話中至關重要的特質。如今，大型語言模型 (LLM) 在產生同理心回應方面表現傑出。像 COMET 這樣的知識庫可以協助 LLM 減輕錯覺，並增強對使用者意圖和情緒的理解。然而，模型依舊高度依賴固定知識庫，而外部知識的不受限納入可能會引入雜訊。工具學習是一種靈活的端對端方法，可協助 LLM 處理複雜的問題。在本文中，我們提出情緒知識工具呼叫 (EKTC) 架構，它將常識知識庫封裝為同理心工具，讓 LLM 能夠透過工具呼叫靈活地整合外部知識。為了讓模型適應新任務，我們根據同理心對話 (ED) 資料集建構了一個新穎的資料集 TOOL-ED。我們在 ED 資料集上驗證 EKTC，而實驗結果證明我們的架構可以有效增強 LLM 產生同理心回應的能力。

##### **Revolve: Optimizing AI Systems by Tracking Response Evolution in Textual Optimization**
2412.03092v1 by Peiyan Zhang, Haibo Jin, Leyang Hu, Xinnuo Li, Liying Kang, Man Luo, Yangqiu Song, Haohan Wang

Recent advancements in large language models (LLMs) have significantly
enhanced the ability of LLM-based systems to perform complex tasks through
natural language processing and tool interaction. However, optimizing these
LLM-based systems for specific tasks remains challenging, often requiring
manual interventions like prompt engineering and hyperparameter tuning.
Existing automatic optimization methods, such as textual feedback-based
techniques (e.g., TextGrad), tend to focus on immediate feedback, analogous to
using immediate derivatives in traditional numerical gradient descent. However,
relying solely on such feedback can be limited when the adjustments made in
response to this feedback are either too small or fluctuate irregularly,
potentially slowing down or even stalling the optimization process. To overcome
these challenges, more adaptive methods are needed, especially in situations
where the system's response is evolving slowly or unpredictably. In this paper,
we introduce REVOLVE, an optimization method that tracks how "R"esponses
"EVOLVE" across iterations in LLM systems. By focusing on the evolution of
responses over time, REVOLVE enables more stable and effective optimization by
making thoughtful, progressive adjustments at each step. Experimental results
demonstrate that REVOLVE outperforms competitive baselines, achieving a 7.8%
improvement in prompt optimization, a 20.72% gain in solution refinement, and a
29.17% increase in code optimization. Additionally, REVOLVE converges in fewer
iterations, resulting in significant computational savings. These advantages
highlight its adaptability and efficiency, positioning REVOLVE as a valuable
tool for optimizing LLM-based systems and accelerating the development of
next-generation AI technologies. Code is available at:
https://github.com/Peiyance/REVOLVE.

摘要：<paragraph>大型語言模型 (LLM) 的最新進展顯著提升了 LLM 基於系統透過自然語言處理和工具互動執行複雜任務的能力。然而，針對特定任務最佳化這些 LLM 基於系統仍然具有挑戰性，通常需要手動介入，例如提示工程和超參數調整。現有的自動最佳化方法，例如基於文字回饋的技術 (例如 TextGrad)，傾向於關注立即回饋，類似於在傳統數值梯度下降中使用立即導數。然而，僅依賴此類回饋可能會受到限制，當根據此回饋進行的調整過小或不規則波動時，可能會減慢甚至停止最佳化程序。為了克服這些挑戰，需要更多適應性方法，特別是在系統回應緩慢或難以預測的情況下。在本文中，我們介紹 REVOLVE，這是一種最佳化方法，它追蹤 LLM 系統中「R」esponses 如何在迭代中「EVOLVE」。透過關注回應隨時間的演變，REVOLVE 能夠在每個步驟進行深思熟慮的漸進式調整，進而實現更穩定且有效的最佳化。實驗結果證明 REVOLVE 優於競爭基準，在提示最佳化方面提升了 7.8%，在解決方案精煉方面提升了 20.72%，在程式碼最佳化方面提升了 29.17%。此外，REVOLVE 在較少迭代中收斂，從而節省了大量的運算。這些優點突顯了它的適應性和效率，將 REVOLVE 定位為最佳化 LLM 基於系統和加速下一代 AI 技術發展的寶貴工具。程式碼可在以下位置取得：https://github.com/Peiyance/REVOLVE。</paragraph>

##### **ASR-EC Benchmark: Evaluating Large Language Models on Chinese ASR Error Correction**
2412.03075v1 by Victor Junqiu Wei, Weicheng Wang, Di Jiang, Yuanfeng Song, Lu Wang

Automatic speech Recognition (ASR) is a fundamental and important task in the
field of speech and natural language processing. It is an inherent building
block in many applications such as voice assistant, speech translation, etc.
Despite the advancement of ASR technologies in recent years, it is still
inevitable for modern ASR systems to have a substantial number of erroneous
recognition due to environmental noise, ambiguity, etc. Therefore, the error
correction in ASR is crucial.
  Motivated by this, this paper studies ASR error correction in the Chinese
language, which is one of the most popular languages and enjoys a large number
of users in the world. We first create a benchmark dataset named \emph{ASR-EC}
that contains a wide spectrum of ASR errors generated by industry-grade ASR
systems. To the best of our knowledge, it is the first Chinese ASR error
correction benchmark. Then, inspired by the recent advances in \emph{large
language models (LLMs)}, we investigate how to harness the power of LLMs to
correct ASR errors. We apply LLMs to ASR error correction in three paradigms.
The first paradigm is prompting, which is further categorized as zero-shot,
few-shot, and multi-step. The second paradigm is finetuning, which finetunes
LLMs with ASR error correction data. The third paradigm is multi-modal
augmentation, which collectively utilizes the audio and ASR transcripts for
error correction. Extensive experiments reveal that prompting is not effective
for ASR error correction. Finetuning is effective only for a portion of LLMs.
Multi-modal augmentation is the most effective method for error correction and
achieves state-of-the-art performance.

摘要：<paragraph>自動語音辨識 (ASR) 是語音與自然語言處理領域中的一項基本且重要的任務。它是許多應用程式中固有的組成部分，例如語音助理、語音翻譯等。儘管近年來 ASR 技術進步，但現代 ASR 系統仍難免會因環境噪音、歧義等因素產生大量錯誤辨識。因此，ASR 中的錯誤校正至關重要。
受此啟發，本文研究了中文 ASR 錯誤校正，中文是最流行的語言之一，在全球擁有大量的使用者。我們首先建立了一個名為 \emph{ASR-EC} 的基準資料集，其中包含由產業級 ASR 系統產生的各種 ASR 錯誤。據我們所知，這是第一個中文 ASR 錯誤校正基準。接著，受到 \emph{大型語言模型 (LLM)} 近期進展的啟發，我們探討如何利用 LLM 的力量來校正 ASR 錯誤。我們將 LLM 應用於 ASR 錯誤校正的三種範例。第一個範例是提示，進一步分類為零次學習、少次學習和多步驟。第二個範例是微調，使用 ASR 錯誤校正資料微調 LLM。第三個範例是多模式擴充，共同利用音訊和 ASR 轉錄進行錯誤校正。大量的實驗顯示，提示對於 ASR 錯誤校正無效。微調僅對部分 LLM 有效。多模式擴充是錯誤校正最有效的方法，並達到了最先進的效能。</paragraph>

##### **Analytic Study of Text-Free Speech Synthesis for Raw Audio using a Self-Supervised Learning Model**
2412.03074v1 by Joonyong Park, Daisuke Saito, Nobuaki Minematsu

We examine the text-free speech representations of raw audio obtained from a
self-supervised learning (SSL) model by analyzing the synthesized speech using
the SSL representations instead of conventional text representations. Since raw
audio does not have paired speech representations as transcribed texts do,
obtaining speech representations from unpaired speech is crucial for augmenting
available datasets for speech synthesis. Specifically, the proposed speech
synthesis is conducted using discrete symbol representations from the SSL model
in comparison with text representations, and analytical examinations of the
synthesized speech have been carried out. The results empirically show that
using text representations is advantageous for preserving semantic information,
while using discrete symbol representations is superior for preserving acoustic
content, including prosodic and intonational information.

摘要：我們透過分析合成語音，使用 SSL 表示法而非傳統文字表示法，來檢視從自監督式學習 (SSL) 模型取得的無文字語音表示法。由於原始音訊沒有像轉錄文字那樣的配對語音表示法，因此從未配對的語音中取得語音表示法對於擴充語音合成的可用資料集至關重要。具體來說，建議的語音合成是使用來自 SSL 模型的離散符號表示法，並與文字表示法進行比較，並對合成語音進行分析檢視。結果經驗性地顯示，使用文字表示法有利於保留語意資訊，而使用離散符號表示法則優於保留音響內容，包括韻律和語調資訊。

##### **Preference-based opponent shaping in differentiable games**
2412.03072v1 by Xinyu Qiao, Yudong Hu, Congying Han, Weiyan Wu, Tiande Guo

Strategy learning in game environments with multi-agent is a challenging
problem. Since each agent's reward is determined by the joint strategy, a
greedy learning strategy that aims to maximize its own reward may fall into a
local optimum. Recent studies have proposed the opponent modeling and shaping
methods for game environments. These methods enhance the efficiency of strategy
learning by modeling the strategies and updating processes of other agents.
However, these methods often rely on simple predictions of opponent strategy
changes. Due to the lack of modeling behavioral preferences such as cooperation
and competition, they are usually applicable only to predefined scenarios and
lack generalization capabilities. In this paper, we propose a novel
Preference-based Opponent Shaping (PBOS) method to enhance the strategy
learning process by shaping agents' preferences towards cooperation. We
introduce the preference parameter, which is incorporated into the agent's loss
function, thus allowing the agent to directly consider the opponent's loss
function when updating the strategy. We update the preference parameters
concurrently with strategy learning to ensure that agents can adapt to any
cooperative or competitive game environment. Through a series of experiments,
we verify the performance of PBOS algorithm in a variety of differentiable
games. The experimental results show that the PBOS algorithm can guide the
agent to learn the appropriate preference parameters, so as to achieve better
reward distribution in multiple game environments.

摘要：在具有多智能體的遊戲環境中進行策略學習是一個具有挑戰性的問題。由於每個智能體的獎勵是由聯合策略決定的，因此旨在最大化自身獎勵的貪婪學習策略可能會陷入局部最優。最近的研究提出了對手建模和塑造遊戲環境的方法。這些方法通過對其他智能體的策略和更新過程進行建模，提高了策略學習的效率。然而，這些方法通常依賴於對對手策略變化的簡單預測。由於缺乏對合作和競爭等行為偏好的建模，它們通常僅適用於預定義的場景，並且缺乏泛化能力。在本文中，我們提出了一種新的基於偏好的對手塑造 (PBOS) 方法，通過塑造智能體對合作的偏好來增強策略學習過程。我們引入了偏好參數，該參數被納入智能體的損失函數中，從而允許智能體在更新策略時直接考慮對手的損失函數。我們與策略學習同時更新偏好參數，以確保智能體可以適應任何合作或競爭的遊戲環境。通過一系列實驗，我們驗證了 PBOS 演算法在各種可微分遊戲中的性能。實驗結果表明，PBOS 演算法可以引導智能體學習適當的偏好參數，從而在多個遊戲環境中實現更好的獎勵分配。

##### **UTSD: Unified Time Series Diffusion Model**
2412.03068v1 by Xiangkai Ma, Xiaobin Hong, Wenzhong Li, Sanglu Lu

Transformer-based architectures have achieved unprecedented success in time
series analysis. However, facing the challenge of across-domain modeling,
existing studies utilize statistical prior as prompt engineering fails under
the huge distribution shift among various domains. In this paper, a Unified
Time Series Diffusion (UTSD) model is established for the first time to model
the multi-domain probability distribution, utilizing the powerful probability
distribution modeling ability of Diffusion. Unlike the autoregressive models
that capture the conditional probabilities of the prediction horizon to the
historical sequence, we use a diffusion denoising process to model the mixture
distribution of the cross-domain data and generate the prediction sequence for
the target domain directly utilizing conditional sampling. The proposed UTSD
contains three pivotal designs: (1) The condition network captures the
multi-scale fluctuation patterns from the observation sequence, which are
utilized as context representations to guide the denoising network to generate
the prediction sequence; (2) Adapter-based fine-tuning strategy, the
multi-domain universal representation learned in the pretraining stage is
utilized for downstream tasks in target domains; (3) The diffusion and
denoising process on the actual sequence space, combined with the improved
classifier free guidance as the conditional generation strategy, greatly
improves the stability and accuracy of the downstream task. We conduct
extensive experiments on mainstream benchmarks, and the pre-trained UTSD
outperforms existing foundation models on all data domains, exhibiting superior
zero-shot generalization ability. After training from scratch, UTSD achieves
comparable performance against domain-specific proprietary models. The
empirical results validate the potential of UTSD as a time series foundational
model.

摘要：<paragraph>基於 Transformer 的架構在時間序列分析中獲得了前所未有的成功。然而，面對跨域建模的挑戰，現有的研究利用統計先驗作為提示工程，在各種域之間的巨大分佈轉移下會失敗。在本文中，首次建立了統一時間序列擴散 (UTSD) 模型來對多域機率分佈進行建模，利用擴散的強大機率分佈建模能力。與捕捉預測範圍到歷史序列條件機率的自迴歸模型不同，我們使用擴散去噪程序對跨域資料的混合分佈進行建模，並直接利用條件抽樣為目標域產生預測序列。所提出的 UTSD 包含三個關鍵設計：(1) 條件網路從觀察序列中捕捉多尺度波動模式，這些模式被用作上下文表示，以引導去噪網路產生預測序列；(2) 基於適配器的微調策略，在預訓練階段學習的多域通用表示用於目標域的下游任務；(3) 在實際序列空間上的擴散和去噪程序，結合作為條件生成策略的改良分類器自由引導，極大地提高了下游任務的穩定性和準確性。我們在主流基準上進行了廣泛的實驗，預先訓練的 UTSD 在所有資料域上都優於現有的基礎模型，展現出卓越的零次方泛化能力。從頭開始訓練後，UTSD 在與特定於域的專有模型相比時，達到了相當的效能。實證結果驗證了 UTSD 作為時間序列基礎模型的潛力。</paragraph>

##### **Point-GN: A Non-Parametric Network Using Gaussian Positional Encoding for Point Cloud Classification**
2412.03056v1 by Marzieh Mohammadi, Amir Salarpour

This paper introduces Point-GN, a novel non-parametric network for efficient
and accurate 3D point cloud classification. Unlike conventional deep learning
models that rely on a large number of trainable parameters, Point-GN leverages
non-learnable components-specifically, Farthest Point Sampling (FPS), k-Nearest
Neighbors (k-NN), and Gaussian Positional Encoding (GPE)-to extract both local
and global geometric features. This design eliminates the need for additional
training while maintaining high performance, making Point-GN particularly
suited for real-time, resource-constrained applications. We evaluate Point-GN
on two benchmark datasets, ModelNet40 and ScanObjectNN, achieving
classification accuracies of 85.29% and 85.89%, respectively, while
significantly reducing computational complexity. Point-GN outperforms existing
non-parametric methods and matches the performance of fully trained models, all
with zero learnable parameters. Our results demonstrate that Point-GN is a
promising solution for 3D point cloud classification in practical, real-time
environments.

摘要：本文介紹 Point-GN，一種用於高效且準確的 3D 點雲分類的新型非參數網路。與依賴大量可訓練參數的傳統深度學習模型不同，Point-GN 利用不可學習的元件（具體來說，最遠點取樣 (FPS)、k 最近鄰 (k-NN) 和高斯位置編碼 (GPE)）來提取局部和全局幾何特徵。此設計消除了額外訓練的需求，同時維持高性能，使 Point-GN 特別適合於即時、資源受限的應用程式。我們在兩個基準資料集 ModelNet40 和 ScanObjectNN 上評估 Point-GN，分別達到 85.29% 和 85.89% 的分類準確度，同時大幅降低運算複雜度。Point-GN 優於現有的非參數方法，並與完全訓練模型的性能相匹配，所有這些都無需可學習參數。我們的結果表明，Point-GN 是在實際即時環境中進行 3D 點雲分類的有前途的解決方案。

##### **Less is More: A Stealthy and Efficient Adversarial Attack Method for DRL-based Autonomous Driving Policies**
2412.03051v1 by Junchao Fan, Xuyang Lei, Xiaolin Chang, Jelena Mišić, Vojislav B. Mišić

Despite significant advancements in deep reinforcement learning (DRL)-based
autonomous driving policies, these policies still exhibit vulnerability to
adversarial attacks. This vulnerability poses a formidable challenge to the
practical deployment of these policies in autonomous driving. Designing
effective adversarial attacks is an indispensable prerequisite for enhancing
the robustness of these policies. In view of this, we present a novel stealthy
and efficient adversarial attack method for DRL-based autonomous driving
policies. Specifically, we introduce a DRL-based adversary designed to trigger
safety violations (e.g., collisions) by injecting adversarial samples at
critical moments. We model the attack as a mixed-integer optimization problem
and formulate it as a Markov decision process. Then, we train the adversary to
learn the optimal policy for attacking at critical moments without domain
knowledge. Furthermore, we introduce attack-related information and a
trajectory clipping method to enhance the learning capability of the adversary.
Finally, we validate our method in an unprotected left-turn scenario across
different traffic densities. The experimental results show that our method
achieves more than 90% collision rate within three attacks in most cases.
Furthermore, our method achieves more than 130% improvement in attack
efficiency compared to the unlimited attack method.

摘要：儘管在基於深度強化學習 (DRL) 的自動駕駛政策方面取得了顯著進展，但這些政策仍然容易受到對抗性攻擊。這種脆弱性對在自動駕駛中實際部署這些政策構成了巨大的挑戰。設計有效的對抗性攻擊是增強這些政策穩健性的必要先決條件。有鑑於此，我們提出了一種針對基於 DRL 的自動駕駛政策的新型隱蔽且有效的對抗性攻擊方法。具體來說，我們引入了一個基於 DRL 的對手，旨在通過在關鍵時刻注入對抗性樣本來觸發安全違規（例如碰撞）。我們將攻擊建模為一個混合整數優化問題，並將其表述為馬可夫決策過程。然後，我們訓練對手在沒有領域知識的情況下學習在關鍵時刻攻擊的最佳策略。此外，我們引入了攻擊相關信息和軌跡剪輯方法，以增強對手的學習能力。最後，我們在不同的交通密度下，在一個不受保護的左轉場景中驗證了我們的模型。實驗結果表明，在大多數情況下，我們的模型在三次攻擊中實現了超過 90% 的碰撞率。此外，與無限制攻擊方法相比，我們的模型在攻擊效率方面實現了超過 130% 的改進。

##### **MRNet: Multifaceted Resilient Networks for Medical Image-to-Image Translation**
2412.03039v1 by Hyojeong Lee, Youngwan Jo, Inpyo Hong, Sanghyun Park

We propose a Multifaceted Resilient Network(MRNet), a novel architecture
developed for medical image-to-image translation that outperforms
state-of-the-art methods in MRI-to-CT and MRI-to-MRI conversion. MRNet
leverages the Segment Anything Model (SAM) to exploit frequency-based features
to build a powerful method for advanced medical image transformation. The
architecture extracts comprehensive multiscale features from diverse datasets
using a powerful SAM image encoder and performs resolution-aware feature fusion
that consistently integrates U-Net encoder outputs with SAM-derived features.
This fusion optimizes the traditional U-Net skip connection while leveraging
transformer-based contextual analysis. The translation is complemented by an
innovative dual-mask configuration incorporating dynamic attention patterns and
a specialized loss function designed to address regional mapping mismatches,
preserving both the gross anatomy and tissue details. Extensive validation
studies have shown that MRNet outperforms state-of-the-art architectures,
particularly in maintaining anatomical fidelity and minimizing translation
artifacts.

摘要：我們提出一個多方面的彈性網路 (MRNet)，這是一個創新的架構，
開發用於醫學影像轉影像的翻譯，其優於 MRI 轉 CT 和 MRI 轉 MRI 轉換的最新方法。MRNet
利用 Segment Anything Model (SAM) 來利用基於頻率的特徵，以建立一種強大的方法，用於先進的醫學影像轉換。此
架構使用強大的 SAM 影像編碼器從不同的資料集提取全面的多尺度特徵，並執行解析度感知特徵融合，持續將 U-Net 編碼器輸出與 SAM 衍生的特徵整合在一起。
此融合最佳化傳統的 U-Net 跳躍連接，同時利用基於Transformer的上下文分析。翻譯由一個創新的雙遮罩配置補充，它結合了動態注意模式和一個專門的損失函數，旨在解決區域對應不匹配的問題，同時保留了整體解剖結構和組織細節。廣泛的驗證研究顯示，MRNet 優於最先進的架構，特別是在維持解剖保真度和最小化轉換偽影方面。

##### **MILLION: A General Multi-Objective Framework with Controllable Risk for Portfolio Management**
2412.03038v1 by Liwei Deng, Tianfu Wang, Yan Zhao, Kai Zheng

Portfolio management is an important yet challenging task in AI for FinTech,
which aims to allocate investors' budgets among different assets to balance the
risk and return of an investment. In this study, we propose a general
Multi-objectIve framework with controLLable rIsk for pOrtfolio maNagement
(MILLION), which consists of two main phases, i.e., return-related maximization
and risk control. Specifically, in the return-related maximization phase, we
introduce two auxiliary objectives, i.e., return rate prediction, and return
rate ranking, combined with portfolio optimization to remit the overfitting
problem and improve the generalization of the trained model to future markets.
Subsequently, in the risk control phase, we propose two methods, i.e.,
portfolio interpolation and portfolio improvement, to achieve fine-grained risk
control and fast risk adaption to a user-specified risk level. For the
portfolio interpolation method, we theoretically prove that the risk can be
perfectly controlled if the to-be-set risk level is in a proper interval. In
addition, we also show that the return rate of the adjusted portfolio after
portfolio interpolation is no less than that of the min-variance optimization,
as long as the model in the reward maximization phase is effective.
Furthermore, the portfolio improvement method can achieve greater return rates
while keeping the same risk level compared to portfolio interpolation.
Extensive experiments are conducted on three real-world datasets. The results
demonstrate the effectiveness and efficiency of the proposed framework.

摘要：投資組合管理是金融科技中人工智能的一項重要且具有挑戰性的任務，其目的是在不同的資產之間分配投資者的預算，以平衡投資的風險和報酬。在本研究中，我們提出了一個具有可控風險的多目標投資組合管理框架 (MILLION)，它包含兩個主要階段，即報酬相關最大化和風險控制。具體來說，在報酬相關最大化階段，我們引入了兩個輔助目標，即報酬率預測和報酬率排名，並結合投資組合最佳化來解決過度擬合問題，並提高訓練模型對未來市場的泛化能力。隨後，在風險控制階段，我們提出了兩種方法，即投資組合插值和投資組合改善，以實現細粒度的風險控制和快速風險適應使用者指定的風險水準。對於投資組合插值方法，我們從理論上證明，如果待設定的風險水準在適當的區間內，則風險可以得到完美的控制。此外，我們還表明，只要報酬最大化階段中的模型是有效的，那麼投資組合插值後調整後的投資組合的報酬率不會低於最小變異數最佳化。此外，與投資組合插值相比，投資組合改善方法可以在保持相同風險水準的同時實現更高的報酬率。在三個真實世界資料集上進行了廣泛的實驗。結果證明了所提出的框架的有效性和效率。

##### **Specification Generation for Neural Networks in Systems**
2412.03028v1 by Isha Chaudhary, Shuyi Lin, Cheng Tan, Gagandeep Singh

Specifications - precise mathematical representations of correct
domain-specific behaviors - are crucial to guarantee the trustworthiness of
computer systems. With the increasing development of neural networks as
computer system components, specifications gain more importance as they can be
used to regulate the behaviors of these black-box models. Traditionally,
specifications are designed by domain experts based on their intuition of
correct behavior. However, this is labor-intensive and hence not a scalable
approach as computer system applications diversify. We hypothesize that the
traditional (aka reference) algorithms that neural networks replace for higher
performance can act as effective proxies for correct behaviors of the models,
when available. This is because they have been used and tested for long enough
to encode several aspects of the trustworthy/correct behaviors in the
underlying domain. Driven by our hypothesis, we develop a novel automated
framework, SpecTRA to generate specifications for neural networks using
references. We formulate specification generation as an optimization problem
and solve it with observations of reference behaviors. SpecTRA clusters similar
observations into compact specifications. We present specifications generated
by SpecTRA for neural networks in adaptive bit rate and congestion control
algorithms. Our specifications show evidence of being correct and matching
intuition. Moreover, we use our specifications to show several unknown
vulnerabilities of the SOTA models for computer systems.

摘要：規範 - 正確的特定領域行為的精確數學表示 - 對保證電腦系統的值得信賴性至關重要。隨著神經網路作為電腦系統組件的發展越來越廣泛，規範變得越來越重要，因為它們可用於規範這些黑盒模型的行為。傳統上，規範是由領域專家根據他們對正確行為的直覺設計的。然而，這需要大量的人力，因此隨著電腦系統應用程式多元化，這並非一個可擴充的方法。我們假設神經網路用以替代以獲得更高效能的傳統（又稱參考）演算法，在有需要時可以作為模型正確行為的有效代理。這是因為它們已經被使用和測試了足夠長的時間，足以編碼可信/正確行為的幾個面向在基礎領域中。在我們的假設驅使下，我們開發了一個新穎的自動化框架 SpecTRA，使用參考為神經網路產生規範。我們將規範產生表述為一個最佳化問題，並透過觀察參考行為來解決它。SpecTRA 將類似的觀察結果分群為精簡的規範。我們提供 SpecTRA 為自適應位元率和壅塞控制演算法中的神經網路產生的規範。我們的規範顯示有正確且符合直覺的證據。此外，我們使用我們的規範來顯示電腦系統的 SOTA 模型的幾個未知漏洞。

##### **Human Variability vs. Machine Consistency: A Linguistic Analysis of Texts Generated by Humans and Large Language Models**
2412.03025v1 by Sergio E. Zanotto, Segun Aroyehun

The rapid advancements in large language models (LLMs) have significantly
improved their ability to generate natural language, making texts generated by
LLMs increasingly indistinguishable from human-written texts. Recent research
has predominantly focused on using LLMs to classify text as either
human-written or machine-generated. In our study, we adopt a different approach
by profiling texts spanning four domains based on 250 distinct linguistic
features. We select the M4 dataset from the Subtask B of SemEval 2024 Task 8.
We automatically calculate various linguistic features with the LFTK tool and
additionally measure the average syntactic depth, semantic similarity, and
emotional content for each document. We then apply a two-dimensional PCA
reduction to all the calculated features. Our analyses reveal significant
differences between human-written texts and those generated by LLMs,
particularly in the variability of these features, which we find to be
considerably higher in human-written texts. This discrepancy is especially
evident in text genres with less rigid linguistic style constraints. Our
findings indicate that humans write texts that are less cognitively demanding,
with higher semantic content, and richer emotional content compared to texts
generated by LLMs. These insights underscore the need for incorporating
meaningful linguistic features to enhance the understanding of textual outputs
of LLMs.

摘要：大型語言模型 (LLM) 的快速進展顯著提升了它們生成自然語言的能力，讓 LLM 生成的文字越來越難以與人類寫的文字區分。最近的研究主要集中於使用 LLM 將文字分類為人類寫的或機器生成的。在我們的研究中，我們採用不同的方法，根據 250 個不同的語言特徵對跨越四個領域的文字進行分析。我們從 SemEval 2024 任務 8 的子任務 B 中選取 M4 資料集。我們使用 LFTK 工具自動計算各種語言特徵，並另外測量每個文件的平均句法深度、語義相似度和情緒內容。然後，我們對所有計算出的特徵應用二維 PCA 降維。我們的分析揭示了人類寫的文字和 LLM 生成的文字之間的顯著差異，特別是在這些特徵的可變性方面，我們發現人類寫的文字的可變性顯著較高。這種差異在語言風格約束較少的文字類型中尤其明顯。我們的研究結果表明，人類寫的文字認知要求較低，語義內容較高，與 LLM 生成的文字相比，情緒內容也更豐富。這些見解強調了納入有意義的語言特徵以增強對 LLM 文本輸出的理解的必要性。

##### **PEMF-VVTO: Point-Enhanced Video Virtual Try-on via Mask-free Paradigm**
2412.03021v1 by Tianyu Chang, Xiaohao Chen. Zhichao Wei, Xuanpu Zhang, Qing-Guo Chen, Weihua Luo, Xun Yang

Video Virtual Try-on aims to fluently transfer the garment image to a
semantically aligned try-on area in the source person video. Previous methods
leveraged the inpainting mask to remove the original garment in the source
video, thus achieving accurate garment transfer on simple model videos.
However, when these methods are applied to realistic video data with more
complex scene changes and posture movements, the overly large and incoherent
agnostic masks will destroy the essential spatial-temporal information of the
original video, thereby inhibiting the fidelity and coherence of the try-on
video. To alleviate this problem, %avoid the inherent deficiencies of
mask-based try-on paradigm, we propose a novel point-enhanced mask-free video
virtual try-on framework (PEMF-VVTO). Specifically, we first leverage the
pre-trained mask-based try-on model to construct large-scale paired training
data (pseudo-person samples). Training on these mask-free data enables our
model to perceive the original spatial-temporal information while realizing
accurate garment transfer. Then, based on the pre-acquired sparse frame-cloth
and frame-frame point alignments, we design the point-enhanced spatial
attention (PSA) and point-enhanced temporal attention (PTA) to further improve
the try-on accuracy and video coherence of the mask-free model. Concretely, PSA
explicitly guides the garment transfer to desirable locations through the
sparse semantic alignments of video frames and cloth. PTA exploits the temporal
attention on sparse point correspondences to enhance the smoothness of
generated videos. Extensive qualitative and quantitative experiments clearly
illustrate that our PEMF-VVTO can generate more natural and coherent try-on
videos than existing state-of-the-art methods.

摘要：<paragraph>影片虛擬試穿旨在流暢地將服飾影像傳輸到來源人物影片中語義對齊的試穿區域。先前的做法利用填色遮罩移除來源影片中的原始服飾，進而於簡單的模型影片上實現精準的服飾傳輸。然而，當這些做法套用於場景變換和姿勢動作更複雜的寫實影片資料時，過於龐大且不連貫的非特定遮罩會破壞原始影片中重要的時空資訊，進而抑制試穿影片的保真度和連貫性。為了減輕這個問題，避免基於遮罩的試穿範例中固有的缺點，我們提出一個新穎的點增強無遮罩影片虛擬試穿架構 (PEMF-VVTO)。具體來說，我們首先利用預先訓練的基於遮罩的試穿模型建立大規模配對訓練資料（擬人樣本）。在這些無遮罩資料上進行訓練，能讓我們的模型感知原始時空資訊，同時實現精準的服飾傳輸。然後，根據預先取得的稀疏幀布料和幀幀點對齊，我們設計點增強空間注意力 (PSA) 和點增強時間注意力 (PTA)，進一步提升無遮罩模型的試穿精準度和影片連貫性。具體而言，PSA 透過影片幀和布料的稀疏語義對齊，明確引導服飾傳輸到理想位置。PTA 利用稀疏點對應的時序注意力，提升生成影片的流暢度。廣泛的定性和定量實驗清楚顯示，我們的 PEMF-VVTO 能產生比現有最先進方法更自然且連貫的試穿影片。</paragraph>

##### **Human Multi-View Synthesis from a Single-View Model:Transferred Body and Face Representations**
2412.03011v1 by Yu Feng, Shunsi Zhang, Jian Shu, Hanfeng Zhao, Guoliang Pang, Chi Zhang, Hao Wang

Generating multi-view human images from a single view is a complex and
significant challenge. Although recent advancements in multi-view object
generation have shown impressive results with diffusion models, novel view
synthesis for humans remains constrained by the limited availability of 3D
human datasets. Consequently, many existing models struggle to produce
realistic human body shapes or capture fine-grained facial details accurately.
To address these issues, we propose an innovative framework that leverages
transferred body and facial representations for multi-view human synthesis.
Specifically, we use a single-view model pretrained on a large-scale human
dataset to develop a multi-view body representation, aiming to extend the 2D
knowledge of the single-view model to a multi-view diffusion model.
Additionally, to enhance the model's detail restoration capability, we
integrate transferred multimodal facial features into our trained human
diffusion model. Experimental evaluations on benchmark datasets demonstrate
that our approach outperforms the current state-of-the-art methods, achieving
superior performance in multi-view human synthesis.

摘要：從單一視角生成多視角的人類影像是一項複雜且重大的挑戰。儘管最近在多視角物件生成方面的進展已在擴散模型中展現令人印象深刻的成果，但人類的新視角合成仍受到 3D 人類資料集有限的可用性所限制。因此，許多現有模型難以產生逼真的人體形狀或準確捕捉細緻的面部細節。為了解決這些問題，我們提出了一個創新的架構，該架構利用轉移的身體和面部表示來進行多視角人類合成。具體來說，我們使用在大型人類資料集上預先訓練的單視角模型來開發多視角身體表示，旨在將單視角模型的 2D 知識擴展到多視角擴散模型。此外，為了增強模型的細節還原能力，我們將轉移的多模態面部特徵整合到我們訓練的人類擴散模型中。在基準資料集上的實驗評估表明，我們的做法優於目前的最新方法，在多視角人類合成中取得了卓越的性能。

##### **Advancing Conversational Psychotherapy: Integrating Privacy, Dual-Memory, and Domain Expertise with Large Language Models**
2412.02987v1 by XiuYu Zhang, Zening Luo

Mental health has increasingly become a global issue that reveals the
limitations of traditional conversational psychotherapy, constrained by
location, time, expense, and privacy concerns. In response to these challenges,
we introduce SoulSpeak, a Large Language Model (LLM)-enabled chatbot designed
to democratize access to psychotherapy. SoulSpeak improves upon the
capabilities of standard LLM-enabled chatbots by incorporating a novel
dual-memory component that combines short-term and long-term context via
Retrieval Augmented Generation (RAG) to offer personalized responses while
ensuring the preservation of user privacy and intimacy through a dedicated
privacy module. In addition, it leverages a counseling chat dataset of
therapist-client interactions and various prompting techniques to align the
generated responses with psychotherapeutic methods. We introduce two fine-tuned
BERT models to evaluate the system against existing LLMs and human therapists:
the Conversational Psychotherapy Preference Model (CPPM) to simulate human
preference among responses and another to assess response relevance to user
input. CPPM is useful for training and evaluating psychotherapy-focused
language models independent from SoulSpeak, helping with the constrained
resources available for psychotherapy. Furthermore, the effectiveness of the
dual-memory component and the robustness of the privacy module are also
examined. Our findings highlight the potential and challenge of enhancing
mental health care by offering an alternative that combines the expertise of
traditional therapy with the advantages of LLMs, providing a promising way to
address the accessibility and personalization gap in current mental health
services.

摘要：心理健康已日益成為全球問題，暴露了傳統對話式心理治療的限制，受到地點、時間、費用和隱私問題的約束。為了應對這些挑戰，我們推出了 SoulSpeak，這是一款大型語言模型 (LLM) 啟用的聊天機器人，旨在實現心理治療的民主化。SoulSpeak 通過結合短期和長期語境的創新雙重記憶組件，通過檢索增強生成 (RAG) 來改進標準 LLM 啟用聊天機器人的能力，以提供個性化的回應，同時通過專用的隱私模組確保使用者隱私和親密性的保護。此外，它利用治療師與客戶互動的諮詢聊天資料集和各種提示技術，使生成的回應與心理治療方法保持一致。我們引入了兩個微調的 BERT 模型，以針對現有的 LLM 和人類治療師評估系統：對話式心理治療偏好模型 (CPPM) 用於模擬人類對回應的偏好，另一個用於評估對使用者輸入的回應相關性。CPPM 可用於訓練和評估與心理治療為重點的語言模型，而與 SoulSpeak 無關，有助於應對心理治療的受限資源。此外，還檢驗了雙重記憶組件的有效性及隱私模組的穩健性。我們的研究結果突出了通過提供結合傳統療法專業知識和 LLM 優勢的替代方案來增強心理保健的潛力和挑戰，為解決當前心理健康服務的可及性和個人化差距提供了一個有希望的方法。

##### **Surveying the Effects of Quality, Diversity, and Complexity in Synthetic Data From Large Language Models**
2412.02980v1 by Alex Havrilla, Andrew Dai, Laura O'Mahony, Koen Oostermeijer, Vera Zisler, Alon Albalak, Fabrizio Milo, Sharath Chandra Raparthy, Kanishk Gandhi, Baber Abbasi, Duy Phung, Maia Iyer, Dakota Mahan, Chase Blagden, Srishti Gureja, Mohammed Hamdy, Wen-Ding Li, Giovanni Paolini, Pawan Sasanka Ammanamanchi, Elliot Meyerson

Synthetic data generation with Large Language Models is a promising paradigm
for augmenting natural data over a nearly infinite range of tasks. Given this
variety, direct comparisons among synthetic data generation algorithms are
scarce, making it difficult to understand where improvement comes from and what
bottlenecks exist. We propose to evaluate algorithms via the makeup of
synthetic data generated by each algorithm in terms of data quality, diversity,
and complexity. We choose these three characteristics for their significance in
open-ended processes and the impact each has on the capabilities of downstream
models. We find quality to be essential for in-distribution model
generalization, diversity to be essential for out-of-distribution
generalization, and complexity to be beneficial for both. Further, we emphasize
the existence of Quality-Diversity trade-offs in training data and the
downstream effects on model performance. We then examine the effect of various
components in the synthetic data pipeline on each data characteristic. This
examination allows us to taxonomize and compare synthetic data generation
algorithms through the components they utilize and the resulting effects on
data QDC composition. This analysis extends into a discussion on the importance
of balancing QDC in synthetic data for efficient reinforcement learning and
self-improvement algorithms. Analogous to the QD trade-offs in training data,
often there exist trade-offs between model output quality and output diversity
which impact the composition of synthetic data. We observe that many models are
currently evaluated and optimized only for output quality, thereby limiting
output diversity and the potential for self-improvement. We argue that
balancing these trade-offs is essential to the development of future
self-improvement algorithms and highlight a number of works making progress in
this direction.

摘要：<paragraph>使用大型語言模型進行合成資料生成對於在幾乎無限範圍的任務中擴充自然資料而言是一種有前途的範例。鑒於此種多樣性，合成資料生成演算法之間的直接比較相當稀少，這使得難以理解進步的來源以及瓶頸在哪裡。我們提議透過每種演算法所產生的合成資料的組成，在資料品質、多樣性和複雜性方面評估演算法。我們選擇這三項特徵，是因為它們在開放式流程中具有重要意義，而且每項特徵都會對下游模型的能力產生影響。我們發現品質對於分配中模型的概化至關重要，多樣性對於分配外概化至關重要，而複雜性對於兩者都有利。此外，我們強調在訓練資料中存在品質多樣性權衡，以及對模型效能的下游影響。然後，我們檢查合成資料管道中各種組成對每個資料特徵的影響。此項檢查讓我們能夠透過它們所利用的組成和對資料 QDC 組成的影響，對合成資料生成演算法進行分類和比較。此分析延伸至討論在合成資料中平衡 QDC 以實現有效強化學習和自我改善演算法的重要性。類似於訓練資料中的 QD 權衡，模型輸出品質和輸出多樣性之間通常存在權衡，這會影響合成資料的組成。我們觀察到，目前許多模型僅針對輸出品質進行評估和最佳化，從而限制了輸出多樣性以及自我改善的潛力。我們認為，平衡這些權衡對於未來自我改善演算法的發展至關重要，並強調許多在這個方向上取得進展的作品。</paragraph>

##### **Theoretical limitations of multi-layer Transformer**
2412.02975v1 by Lijie Chen, Binghui Peng, Hongxun Wu

Transformers, especially the decoder-only variants, are the backbone of most
modern large language models; yet we do not have much understanding of their
expressive power except for the simple $1$-layer case.
  Due to the difficulty of analyzing multi-layer models, all previous work
relies on unproven complexity conjectures to show limitations for multi-layer
Transformers. In this work, we prove the first $\textit{unconditional}$ lower
bound against multi-layer decoder-only transformers. For any constant $L$, we
prove that any $L$-layer decoder-only transformer needs a polynomial model
dimension ($n^{\Omega(1)}$) to perform sequential composition of $L$ functions
over an input of $n$ tokens.
  As a consequence, our results give: (1) the first depth-width trade-off for
multi-layer transformers, exhibiting that the $L$-step composition task is
exponentially harder for $L$-layer models compared to $(L+1)$-layer ones; (2)
an unconditional separation between encoder and decoder, exhibiting a hard task
for decoders that can be solved by an exponentially shallower and smaller
encoder; (3) a provable advantage of chain-of-thought, exhibiting a task that
becomes exponentially easier with chain-of-thought.
  On the technical side, we propose the multi-party $\textit{autoregressive}$
$\textit{communication}$ $\textit{model}$ that captures the computation of a
decoder-only Transformer. We also introduce a new proof technique that finds a
certain $\textit{indistinguishable}$ $\textit{decomposition}$ of all possible
inputs iteratively for proving lower bounds in this model. We believe our new
communication model and proof technique will be helpful to further understand
the computational power of transformers.

摘要：<paragraph>Transformer，尤其是僅解碼器變體，是大多數現代大型語言模型的骨幹；然而，除了簡單的 $1$ 層案例之外，我們對它們的表達能力並沒有太多了解。
由於分析多層模型的難度，所有先前的研究都依賴於未經證實的複雜性猜想來顯示多層 Transformer 的限制。在這項研究中，我們證明了對於僅解碼器多層 Transformer 的第一個$\textit{無條件}$下界。對於任何常數 $L$，我們證明任何 $L$ 層僅解碼器 Transformer 需要多項式模型維度 ($n^{\Omega(1)}$) 來執行 $n$ 個 token 輸入的 $L$ 個函數的序列組成。
因此，我們的結果給出：(1) 多層 Transformer 的第一個深度寬度權衡，展示了對於 $L$ 層模型而言，$L$ 步驟組成任務比 $(L+1)$ 層模型難以指數級；(2) 編碼器和解碼器之間的無條件分離，展示了解碼器的一個困難任務，而這個任務可以通過指數級更淺和更小的編碼器來解決；(3) 思想鏈的可證明優勢，展示了一個隨著思想鏈而變得指數級更簡單的任務。
在技術方面，我們提出了多方$\textit{自迴歸}$$\textit{通信}$$\textit{模型}$，它捕獲了僅解碼器 Transformer 的計算。我們還引入了一種新的證明技術，該技術反覆尋找所有可能輸入的某個$\textit{不可區分}$$\textit{分解}$，以證明此模型中的下界。我們相信我們新的通信模型和證明技術有助於進一步了解 Transformer 的計算能力。</paragraph>

##### **3D Interaction Geometric Pre-training for Molecular Relational Learning**
2412.02957v1 by Namkyeong Lee, Yunhak Oh, Heewoong Noh, Gyoung S. Na, Minkai Xu, Hanchen Wang, Tianfan Fu, Chanyoung Park

Molecular Relational Learning (MRL) is a rapidly growing field that focuses
on understanding the interaction dynamics between molecules, which is crucial
for applications ranging from catalyst engineering to drug discovery. Despite
recent progress, earlier MRL approaches are limited to using only the 2D
topological structure of molecules, as obtaining the 3D interaction geometry
remains prohibitively expensive. This paper introduces a novel 3D geometric
pre-training strategy for MRL (3DMRL) that incorporates a 3D virtual
interaction environment, overcoming the limitations of costly traditional
quantum mechanical calculation methods. With the constructed 3D virtual
interaction environment, 3DMRL trains 2D MRL model to learn the overall 3D
geometric information of molecular interaction through contrastive learning.
Moreover, fine-grained interaction between molecules is learned through force
prediction loss, which is crucial in understanding the wide range of molecular
interaction processes. Extensive experiments on various tasks using real-world
datasets, including out-of-distribution and extrapolation scenarios,
demonstrate the effectiveness of 3DMRL, showing up to a 24.93\% improvement in
performance across 40 tasks.

摘要：分子關係學習 (MRL) 是快速成長的領域，專注於了解分子之間的互動動態，這對於從催化劑工程到藥物發現等應用至關重要。儘管最近有進展，但早期的 MRL 方法僅限於使用分子的 2D 拓撲結構，因為獲取 3D 交互幾何結構仍然非常昂貴。本文介紹了一種新穎的 3D 幾何預訓練策略，用於 MRL (3DMRL)，它結合了一個 3D 虛擬交互環境，克服了昂貴的傳統量子力學計算方法的限制。利用構建的 3D 虛擬交互環境，3DMRL 訓練 2D MRL 模型通過對比學習來學習分子交互的整體 3D 幾何資訊。此外，通過力預測損失學習分子之間的細粒度交互，這對於理解廣泛的分子交互過程至關重要。在使用真實世界資料集的各種任務上進行的廣泛實驗，包括分佈外和外推場景，證明了 3DMRL 的有效性，顯示在 40 個任務中的效能提升了 24.93%。

##### **Curriculum-style Data Augmentation for LLM-based Metaphor Detection**
2412.02956v1 by Kaidi Jia, Yanxia Wu, Rongsheng Li

Recently, utilizing large language models (LLMs) for metaphor detection has
achieved promising results. However, these methods heavily rely on the
capabilities of closed-source LLMs, which come with relatively high inference
costs and latency. To address this, we propose a method for metaphor detection
by fine-tuning open-source LLMs, effectively reducing inference costs and
latency with a single inference step. Furthermore, metaphor detection suffers
from a severe data scarcity problem, which hinders effective fine-tuning of
LLMs. To tackle this, we introduce Curriculum-style Data Augmentation (CDA).
Specifically, before fine-tuning, we evaluate the training data to identify
correctly predicted instances for fine-tuning, while incorrectly predicted
instances are used as seed data for data augmentation. This approach enables
the model to quickly learn simpler knowledge and progressively acquire more
complex knowledge, thereby improving performance incrementally. Experimental
results demonstrate that our method achieves state-of-the-art performance
across all baselines. Additionally, we provide detailed ablation studies to
validate the effectiveness of CDA.

摘要：<paragraph>最近，利用大型語言模型 (LLM) 進行隱喻偵測已獲得令人滿意的結果。然而，這些方法嚴重依賴閉源 LLM 的功能，而這會帶來相對高的推論成本和延遲。為了解決這個問題，我們提出了一種透過微調開源 LLM 來進行隱喻偵測的方法，有效地減少了單一推論步驟的推論成本和延遲。此外，隱喻偵測會遭受嚴重的資料稀少問題，這會阻礙 LLM 的有效微調。為了解決這個問題，我們引入了課程式資料擴充 (CDA)。具體來說，在微調之前，我們會評估訓練資料以找出正確預測的微調實例，而錯誤預測的實例則用作資料擴充的種子資料。這種方法讓模型能夠快速學習較簡單的知識，並逐步習得較複雜的知識，從而逐步提升效能。實驗結果證明，我們的模型在所有基準中都達到了最先進的效能。此外，我們提供了詳細的消融研究，以驗證 CDA 的有效性。</paragraph>

##### **Who Brings the Frisbee: Probing Hidden Hallucination Factors in Large Vision-Language Model via Causality Analysis**
2412.02946v1 by Po-Hsuan Huang, Jeng-Lin Li, Chin-Po Chen, Ming-Ching Chang, Wei-Chao Chen

Recent advancements in large vision-language models (LVLM) have significantly
enhanced their ability to comprehend visual inputs alongside natural language.
However, a major challenge in their real-world application is hallucination,
where LVLMs generate non-existent visual elements, eroding user trust. The
underlying mechanism driving this multimodal hallucination is poorly
understood. Minimal research has illuminated whether contexts such as sky,
tree, or grass field involve the LVLM in hallucinating a frisbee. We
hypothesize that hidden factors, such as objects, contexts, and semantic
foreground-background structures, induce hallucination. This study proposes a
novel causal approach: a hallucination probing system to identify these hidden
factors. By analyzing the causality between images, text prompts, and network
saliency, we systematically explore interventions to block these factors. Our
experimental findings show that a straightforward technique based on our
analysis can significantly reduce hallucinations. Additionally, our analyses
indicate the potential to edit network internals to minimize hallucinated
outputs.

摘要：大型視覺語言模型 (LVLM) 的最新進展顯著增強了它們理解自然語言和視覺輸入的能力。然而，在現實世界應用中的一個重大挑戰是幻覺，其中 LVLM 產生不存在的視覺元素，侵蝕了使用者的信任。驅動這種多模態幻覺的底層機制尚未被充分理解。很少有研究探討天空、樹木或草地等背景是否會讓 LVLM 產生飛盤的幻覺。我們假設物體、背景和語義前景背景結構等隱藏因素會誘發幻覺。本研究提出了一種新的因果方法：一種幻覺探測系統，用於識別這些隱藏因素。通過分析影像、文字提示和網路顯著性之間的因果關係，我們系統性地探索了阻止這些因素的干預措施。我們的實驗結果表明，基於我們分析的一種直接技術可以顯著減少幻覺。此外，我們的分析表明有潛力編輯網路內部結構以最小化產生幻覺的輸出。

##### **STDCformer: A Transformer-Based Model with a Spatial-Temporal Causal De-Confounding Strategy for Crowd Flow Prediction**
2412.02942v1 by Silu He, Peng Shen, Pingzhen Xu, Qinyao Luo, Haifeng Li

Existing works typically treat spatial-temporal prediction as the task of
learning a function $F$ to transform historical observations to future
observations. We further decompose this cross-time transformation into three
processes: (1) Encoding ($E$): learning the intrinsic representation of
observations, (2) Cross-Time Mapping ($M$): transforming past representations
into future representations, and (3) Decoding ($D$): reconstructing future
observations from the future representations. From this perspective,
spatial-temporal prediction can be viewed as learning $F = E \cdot M \cdot D$,
which includes learning the space transformations $\left\{{E},{D}\right\}$
between the observation space and the hidden representation space, as well as
the spatial-temporal mapping $M$ from future states to past states within the
representation space. This leads to two key questions: \textbf{Q1: What kind of
representation space allows for mapping the past to the future? Q2: How to
achieve map the past to the future within the representation space?} To address
Q1, we propose a Spatial-Temporal Backdoor Adjustment strategy, which learns a
Spatial-Temporal De-Confounded (STDC) representation space and estimates the
de-confounding causal effect of historical data on future data. This causal
relationship we captured serves as the foundation for subsequent
spatial-temporal mapping. To address Q2, we design a Spatial-Temporal Embedding
(STE) that fuses the information of temporal and spatial confounders, capturing
the intrinsic spatial-temporal characteristics of the representations.
Additionally, we introduce a Cross-Time Attention mechanism, which queries the
attention between the future and the past to guide spatial-temporal mapping.

摘要：<paragraph>現有的作品通常將時空預測視為學習函數 $F$ 的任務，以將歷史觀測值轉換為未來觀測值。我們進一步將這種跨時間轉換分解為三個過程：(1) 編碼 ($E$)：學習觀測值的內在表示，(2) 跨時間映射 ($M$)：將過去的表示轉換為未來的表示，以及 (3) 解碼 ($D$)：從未來的表示重建未來的觀測值。從這個角度來看，時空預測可以視為學習 $F = E \cdot M \cdot D$，其中包括學習觀測空間和隱藏表示空間之間的空間轉換 $\left\{{E},{D}\right\}$，以及表示空間內從未來狀態到過去狀態的時空映射 $M$。這導致了兩個關鍵問題：\textbf{Q1：哪種類型的表示空間允許將過去映射到未來？Q2：如何在表示空間內將過去映射到未來？} 為了回答 Q1，我們提出了時空後門調整策略，該策略學習時空去混淆 (STDC) 表示空間，並估計歷史數據對未來數據的去混淆因果效應。我們捕捉到的這種因果關係作為後續時空映射的基礎。為了回答 Q2，我們設計了一個時空嵌入 (STE)，它融合了時間和空間混淆因素的信息，捕捉了表示的內在時空特徵。此外，我們引入了一個跨時間注意力機制，它查詢未來和過去之間的注意力以指導時空映射。</paragraph>

##### **Dynamic Graph Neural Ordinary Differential Equation Network for Multi-modal Emotion Recognition in Conversation**
2412.02935v1 by Yuntao Shou, Tao Meng, Wei Ai, Keqin Li

Multimodal emotion recognition in conversation (MERC) refers to identifying
and classifying human emotional states by combining data from multiple
different modalities (e.g., audio, images, text, video, etc.). Most existing
multimodal emotion recognition methods use GCN to improve performance, but
existing GCN methods are prone to overfitting and cannot capture the temporal
dependency of the speaker's emotions. To address the above problems, we propose
a Dynamic Graph Neural Ordinary Differential Equation Network (DGODE) for MERC,
which combines the dynamic changes of emotions to capture the temporal
dependency of speakers' emotions, and effectively alleviates the overfitting
problem of GCNs. Technically, the key idea of DGODE is to utilize an adaptive
mixhop mechanism to improve the generalization ability of GCNs and use the
graph ODE evolution network to characterize the continuous dynamics of node
representations over time and capture temporal dependencies. Extensive
experiments on two publicly available multimodal emotion recognition datasets
demonstrate that the proposed DGODE model has superior performance compared to
various baselines. Furthermore, the proposed DGODE can also alleviate the
over-smoothing problem, thereby enabling the construction of a deep GCN
network.

摘要：多模态对话情感识别（MERC）是指通过结合来自多种不同模态（例如音频、图像、文本、视频等）的数据来识别和分类人类情感状态。大多数现有的多模态情感识别方法使用 GCN 来提高性能，但现有的 GCN 方法容易过拟合，并且无法捕捉说话人情感的时间依赖性。为了解决上述问题，我们提出了一种用于 MERC 的动态图神经常微分方程网络 (DGODE)，它结合了情感的动态变化来捕捉说话人情感的时间依赖性，并有效地缓解了 GCN 的过拟合问题。从技术上讲，DGODE 的关键思想是利用自适应混合机制来提高 GCN 的泛化能力，并使用图 ODE 演化网络来表征节点表示随时间变化的连续动态并捕捉时间依赖性。在两个公开的多模态情感识别数据集上进行的广泛实验表明，所提出的 DGODE 模型与各种基线相比具有优越的性能。此外，所提出的 DGODE 还可以缓解过度平滑问题，从而能够构建深度 GCN 网络。

##### **Panoptic Diffusion Models: co-generation of images and segmentation maps**
2412.02929v1 by Yinghan Long, Kaushik Roy

Recently, diffusion models have demonstrated impressive capabilities in
text-guided and image-conditioned image generation. However, existing diffusion
models cannot simultaneously generate a segmentation map of objects and a
corresponding image from the prompt. Previous attempts either generate
segmentation maps based on the images or provide maps as input conditions to
control image generation, limiting their functionality to given inputs.
Incorporating an inherent understanding of the scene layouts can improve the
creativity and realism of diffusion models. To address this limitation, we
present Panoptic Diffusion Model (PDM), the first model designed to generate
both images and panoptic segmentation maps concurrently. PDM bridges the gap
between image and text by constructing segmentation layouts that provide
detailed, built-in guidance throughout the generation process. This ensures the
inclusion of categories mentioned in text prompts and enriches the diversity of
segments within the background. We demonstrate the effectiveness of PDM across
two architectures: a unified diffusion transformer and a two-stream transformer
with a pretrained backbone. To facilitate co-generation with fewer sampling
steps, we incorporate a fast diffusion solver into PDM. Additionally, when
ground-truth maps are available, PDM can function as a text-guided
image-to-image generation model. Finally, we propose a novel metric for
evaluating the quality of generated maps and show that PDM achieves
state-of-the-art results in image generation with implicit scene control.

摘要：<paragraph>近期，扩散模型在文本引导和图像条件图像生成方面展示了令人印象深刻的能力。然而，现有的扩散模型无法同时从提示生成对象的分割图和对应的图像。先前的尝试要么基于图像生成分割图，要么将分割图作为输入条件来控制图像生成，从而将它们的功能限制在给定的输入上。
融入对场景布局的内在理解可以提高扩散模型的创造力和真实感。为了解决这一限制，我们提出了全景扩散模型（PDM），这是第一个旨在同时生成图像和全景分割图的模型。PDM 通过构建分割布局来弥合图像和文本之间的差距，这些布局在整个生成过程中提供了详细的内置指导。这确保了包含文本提示中提到的类别，并丰富了背景中片段的多样性。我们在两种架构中展示了 PDM 的有效性：一个统一的扩散转换器和一个具有预训练主干网络的两流转换器。为了促进使用更少的采样步骤进行共生成，我们在 PDM 中加入了一个快速扩散求解器。此外，当有 ground-truth 图时，PDM 可以用作文本引导的图像到图像生成模型。最后，我们提出了一种新颖的指标来评估生成图的质量，并表明 PDM 在图像生成中实现了最先进的结果，并具有隐式场景控制。</paragraph>

##### **Higher Order Transformers: Efficient Attention Mechanism for Tensor Structured Data**
2412.02919v1 by Soroush Omranpour, Guillaume Rabusseau, Reihaneh Rabbany

Transformers are now ubiquitous for sequence modeling tasks, but their
extension to multi-dimensional data remains a challenge due to the quadratic
cost of the attention mechanism. In this paper, we propose Higher-Order
Transformers (HOT), a novel architecture designed to efficiently process data
with more than two axes, i.e. higher-order tensors. To address the
computational challenges associated with high-order tensor attention, we
introduce a novel Kronecker factorized attention mechanism that reduces the
attention cost to quadratic in each axis' dimension, rather than quadratic in
the total size of the input tensor. To further enhance efficiency, HOT
leverages kernelized attention, reducing the complexity to linear. This
strategy maintains the model's expressiveness while enabling scalable attention
computation. We validate the effectiveness of HOT on two high-dimensional
tasks, including multivariate time series forecasting, and 3D medical image
classification. Experimental results demonstrate that HOT achieves competitive
performance while significantly improving computational efficiency, showcasing
its potential for tackling a wide range of complex, multi-dimensional data.

摘要：變形金剛現在普遍用於序列建模任務，但由於注意力機制的二次方成本，它們擴展到多維數據仍然是一個挑戰。在本文中，我們提出了高階變形金剛 (HOT)，這是一種新穎的架構，旨在有效處理具有兩個以上軸線的數據，即高階張量。為了應對與高階張量注意力相關的計算挑戰，我們引入了一種新穎的克羅內克分解注意力機制，該機制將注意力成本降低到每個軸線維度的二次方，而不是輸入張量的總大小的二次方。為了進一步提高效率，HOT 利用核化注意力，將複雜度降低到線性。此策略保持了模型的表現力，同時實現了可擴展的注意力計算。我們在兩個高維任務上驗證了 HOT 的有效性，包括多元時間序列預測和 3D 醫學影像分類。實驗結果表明，HOT 在顯著提高計算效率的同時實現了競爭力的效能，展示了其應對各種複雜的多維數據的潛力。

##### **Single-Cell Omics Arena: A Benchmark Study for Large Language Models on Cell Type Annotation Using Single-Cell Data**
2412.02915v1 by Junhao Liu, Siwei Xu, Lei Zhang, Jing Zhang

Over the past decade, the revolution in single-cell sequencing has enabled
the simultaneous molecular profiling of various modalities across thousands of
individual cells, allowing scientists to investigate the diverse functions of
complex tissues and uncover underlying disease mechanisms. Among all the
analytical steps, assigning individual cells to specific types is fundamental
for understanding cellular heterogeneity. However, this process is usually
labor-intensive and requires extensive expert knowledge. Recent advances in
large language models (LLMs) have demonstrated their ability to efficiently
process and synthesize vast corpora of text to automatically extract essential
biological knowledge, such as marker genes, potentially promoting more
efficient and automated cell type annotations. To thoroughly evaluate the
capability of modern instruction-tuned LLMs in automating the cell type
identification process, we introduce SOAR, a comprehensive benchmarking study
of LLMs for cell type annotation tasks in single-cell genomics. Specifically,
we assess the performance of 8 instruction-tuned LLMs across 11 datasets,
spanning multiple cell types and species. Our study explores the potential of
LLMs to accurately classify and annotate cell types in single-cell RNA
sequencing (scRNA-seq) data, while extending their application to multiomics
data through cross-modality translation. Additionally, we evaluate the
effectiveness of chain-of-thought (CoT) prompting techniques in generating
detailed biological insights during the annotation process. The results
demonstrate that LLMs can provide robust interpretations of single-cell data
without requiring additional fine-tuning, advancing the automation of cell type
annotation in genomics research.

摘要：<paragraph>在過去十年中，單細胞定序的革命性發展已經能夠
同時對數千個單一細胞進行各種模式的分子分析，讓科學家得以研究
複雜組織的多元功能並揭示潛在的疾病機制。在所有分析步驟中，
將單一細胞分配到特定類型對於了解細胞異質性至關重要。然而，
這個過程通常需要大量人力，並且需要廣泛的專業知識。大型語言
模型 (LLM) 的最新進展已證明它們能夠有效處理和綜合大量的文字
語料庫，以自動提取基本的生物知識，例如標記基因，潛在地促進更
有效率且自動化的細胞類型註解。為了徹底評估現代指令調整 LLM
在自動化細胞類型識別過程中的能力，我們引入了 SOAR，這是一項
針對單細胞基因組學中細胞類型註解任務的 LLM 全面基準研究。具體
來說，我們評估了 8 個指令調整 LLM 在 11 個數據集中的性能，涵蓋
多種細胞類型和物種。我們的研究探討了 LLM 在單細胞 RNA 定序
(scRNA-seq) 資料中準確分類和註解細胞類型的潛力，同時透過跨模
態轉譯將其應用擴展到多組學資料。此外，我們評估了思考鏈 (CoT)
提示技術在註解過程中產生詳細生物見解的有效性。結果表明，LLM
可以對單細胞資料提供強健的詮釋，而不需要額外的微調，推動了
基因組學研究中細胞類型註解的自動化。</paragraph>

##### **Does Few-Shot Learning Help LLM Performance in Code Synthesis?**
2412.02906v1 by Derek Xu, Tong Xie, Botao Xia, Haoyu Li, Yunsheng Bai, Yizhou Sun, Wei Wang

Large language models (LLMs) have made significant strides at code generation
through improved model design, training, and chain-of-thought. However,
prompt-level optimizations remain an important yet under-explored aspect of
LLMs for coding. This work focuses on the few-shot examples present in most
code generation prompts, offering a systematic study on whether few-shot
examples improve LLM's coding capabilities, which few-shot examples have the
largest impact, and how to select impactful examples. Our work offers 2
approaches for selecting few-shot examples, a model-free method,
CODEEXEMPLAR-FREE, and a model-based method, CODEEXEMPLAR-BASED. The 2 methods
offer a trade-off between improved performance and reliance on training data
and interpretability. Both methods significantly improve CodeLlama's coding
ability across the popular HumanEval+ coding benchmark. In summary, our work
provides valuable insights into how to pick few-shot examples in code
generation prompts to improve LLM code generation capabilities.

摘要：大型語言模型（LLM）透過改善模型設計、訓練和思考鏈，在程式碼生成方面取得重大進展。然而，提示層級最佳化仍然是 LLM 編碼的重要但尚未充分探索的方面。這項工作重點在於大多數程式碼生成提示中出現的少數範例，提供一項系統性研究，探討少數範例是否能提升 LLM 的編碼能力，哪些少數範例影響最大，以及如何選擇有影響力的範例。我們的研究提供 2 種選擇少數範例的方法，一種是無模型方法，CODEEXEMPLAR-FREE，一種是基於模型的方法，CODEEXEMPLAR-BASED。這 2 種方法在改善效能和依賴訓練資料及可解釋性之間取得權衡。這兩種方法都大幅提升 CodeLlama 在熱門 HumanEval+ 編碼基準中的編碼能力。總之，我們的研究提供有價值的見解，說明如何在程式碼生成提示中挑選少數範例，以提升 LLM 程式碼生成能力。

##### **Enhancing Trust in Large Language Models with Uncertainty-Aware Fine-Tuning**
2412.02904v1 by Ranganath Krishnan, Piyush Khanna, Omesh Tickoo

Large language models (LLMs) have revolutionized the field of natural
language processing with their impressive reasoning and question-answering
capabilities. However, these models are sometimes prone to generating
credible-sounding but incorrect information, a phenomenon known as LLM
hallucinations. Reliable uncertainty estimation in LLMs is essential for
fostering trust in their generated responses and serves as a critical tool for
the detection and prevention of erroneous or hallucinated outputs. To achieve
reliable and well-calibrated uncertainty quantification in open-ended and
free-form natural language generation, we propose an uncertainty-aware
fine-tuning approach for LLMs. This approach enhances the model's ability to
provide reliable uncertainty estimates without compromising accuracy, thereby
guiding them to produce more trustworthy responses. We introduce a novel
uncertainty-aware causal language modeling loss function, grounded in the
principles of decision theory. Through rigorous evaluation on multiple
free-form question-answering datasets and models, we demonstrate that our
uncertainty-aware fine-tuning approach yields better calibrated uncertainty
estimates in natural language generation tasks than fine-tuning with the
standard causal language modeling loss. Furthermore, the experimental results
show that the proposed method significantly improves the model's ability to
detect hallucinations and identify out-of-domain prompts.

摘要：大型語言模型 (LLM) 以其令人印象深刻的推理和問答能力，徹底改變了自然語言處理領域。然而，這些模型有時容易產生聽起來可信但錯誤的資訊，這種現象稱為 LLM 幻覺。LLM 中可靠的不確定性估計對於建立對其生成回應的信任至關重要，並作為檢測和預防錯誤或幻覺輸出的關鍵工具。為了在開放式和自由形式的自然語言生成中實現可靠且校準良好的不確定性量化，我們提出了一種針對 LLM 的不確定性感知微調方法。這種方法增強了模型提供可靠不確定性估計的能力，同時不影響準確性，從而引導它們產生更可信的回應。我們引入了一種新穎的不確定性感知因果語言建模損失函數，它基於決策理論的原理。通過對多個自由形式問答資料集和模型進行嚴格評估，我們證明了我們的不確定性感知微調方法在自然語言生成任務中產生了比使用標準因果語言建模損失進行微調更好的校準不確定性估計。此外，實驗結果表明，所提出的方法顯著提高了模型檢測幻覺和識別域外提示的能力。

##### **MLD-EA: Check and Complete Narrative Coherence by Introducing Emotions and Actions**
2412.02897v1 by Jinming Zhang, Yunfei Long

Narrative understanding and story generation are critical challenges in
natural language processing (NLP), with much of the existing research focused
on summarization and question-answering tasks. While previous studies have
explored predicting plot endings and generating extended narratives, they often
neglect the logical coherence within stories, leaving a significant gap in the
field. To address this, we introduce the Missing Logic Detector by Emotion and
Action (MLD-EA) model, which leverages large language models (LLMs) to identify
narrative gaps and generate coherent sentences that integrate seamlessly with
the story's emotional and logical flow. The experimental results demonstrate
that the MLD-EA model enhances narrative understanding and story generation,
highlighting LLMs' potential as effective logic checkers in story writing with
logical coherence and emotional consistency. This work fills a gap in NLP
research and advances border goals of creating more sophisticated and reliable
story-generation systems.

摘要：敘事理解和故事生成是自然語言處理 (NLP) 中的重大挑戰，現有許多研究專注於摘要和問答任務。儘管過往的研究已探討預測情節結局和生成延伸敘事，但它們常常忽略故事中的邏輯一致性，在這個領域中留下一個顯著的缺口。為了解決這個問題，我們引入了情緒和動作的遺失邏輯偵測器 (MLD-EA) 模型，它利用大型語言模型 (LLM) 來識別敘事缺口，並生成與故事的情緒和邏輯流暢整合的連貫句子。實驗結果證明，MLD-EA 模型增強了敘事理解和故事生成，突顯了 LLM 作為故事寫作中有效邏輯檢查器的潛力，具備邏輯一致性和情緒一致性。這項工作填補了 NLP 研究中的缺口，並推動了創造更精緻且可靠的故事生成系統的邊界目標。

##### **Removing Spurious Correlation from Neural Network Interpretations**
2412.02893v1 by Milad Fotouhi, Mohammad Taha Bahadori, Oluwaseyi Feyisetan, Payman Arabshahi, David Heckerman

The existing algorithms for identification of neurons responsible for
undesired and harmful behaviors do not consider the effects of confounders such
as topic of the conversation. In this work, we show that confounders can create
spurious correlations and propose a new causal mediation approach that controls
the impact of the topic. In experiments with two large language models, we
study the localization hypothesis and show that adjusting for the effect of
conversation topic, toxicity becomes less localized.

摘要：現有的用於識別對不良和有害行為負責的神經元演算法並未考慮混淆因素的影響，例如對話主題。在這項工作中，我們表明混淆因素會產生虛假的相關性，並提出了一種新的因果中介方法來控制主題的影響。在使用兩個大型語言模型進行的實驗中，我們研究了局部化假說，並表明調整對話主題的影響後，毒性會降低局部化。

##### **TDD-Bench Verified: Can LLMs Generate Tests for Issues Before They Get Resolved?**
2412.02883v1 by Toufique Ahmed, Martin Hirzel, Rangeet Pan, Avraham Shinnar, Saurabh Sinha

Test-driven development (TDD) is the practice of writing tests first and
coding later, and the proponents of TDD expound its numerous benefits. For
instance, given an issue on a source code repository, tests can clarify the
desired behavior among stake-holders before anyone writes code for the
agreed-upon fix. Although there has been a lot of work on automated test
generation for the practice "write code first, test later", there has been
little such automation for TDD. Ideally, tests for TDD should be fail-to-pass
(i.e., fail before the issue is resolved and pass after) and have good adequacy
with respect to covering the code changed during issue resolution. This paper
introduces TDD-Bench Verified, a high-quality benchmark suite of 449 issues
mined from real-world GitHub code repositories. The benchmark's evaluation
harness runs only relevant tests in isolation for simple yet accurate coverage
measurements, and the benchmark's dataset is filtered both by human judges and
by execution in the harness. This paper also presents Auto-TDD, an LLM-based
solution that takes as input an issue description and a codebase (prior to
issue resolution) and returns as output a test that can be used to validate the
changes made for resolving the issue. Our evaluation shows that Auto-TDD yields
a better fail-to-pass rate than the strongest prior work while also yielding
high coverage adequacy. Overall, we hope that this work helps make developers
more productive at resolving issues while simultaneously leading to more robust
fixes.

摘要：測試驅動開發 (TDD) 是一種先撰寫測試再編寫程式碼的做法，而 TDD 的支持者則闡述了它的許多好處。例如，給定原始程式碼儲存庫中的問題，測試可以在任何人為商定的修正程式撰寫程式碼之前，釐清利害關係人之間所需行為。儘管在「先撰寫程式碼，後測試」的做法中，已經有許多關於自動化測試產生的工作，但 TDD 的這種自動化卻很少。理想情況下，TDD 的測試應該是失敗到通過（即在問題解決之前失敗，之後通過），並且在涵蓋問題解決期間變更的程式碼方面具有良好的充分性。本文介紹了 TDD-Bench Verified，這是一個從真實世界的 GitHub 程式碼儲存庫中挖掘出的 449 個問題的高品質基準測試套件。基準測試的評估工具僅針對簡單但準確的涵蓋範圍測量，在隔離環境中執行相關測試，並且基準測試的資料集是由人工評審和在工具中執行所篩選出來的。本文還提出了 Auto-TDD，這是一個基於 LLM 的解決方案，它以問題描述和程式碼庫（在問題解決之前）作為輸入，並回傳一個可以用來驗證為了解決問題而進行的變更的測試。我們的評估顯示，Auto-TDD 產生比最強的前期工作更好的失敗到通過率，同時也產生了很高的涵蓋率。總的來說，我們希望這項工作有助於讓開發人員在解決問題時更有效率，同時也能帶來更強健的修正。

##### **Modeling and Discovering Direct Causes for Predictive Models**
2412.02878v1 by Yizuo Chen, Amit Bhatia

We introduce a causal modeling framework that captures the input-output
behavior of predictive models (e.g., machine learning models) by representing
it using causal graphs. The framework enables us to define and identify
features that directly cause the predictions, which has broad implications for
data collection and model evaluation. We show two assumptions under which the
direct causes can be discovered from data, one of which further simplifies the
discovery process. In addition to providing sound and complete algorithms, we
propose an optimization technique based on an independence rule that can be
integrated with the algorithms to speed up the discovery process both
theoretically and empirically.

摘要：我們引入一個因果模型架構，它透過使用因果圖表，來捕捉預測模型（例如機器學習模型）的輸入輸出行為。這個架構讓我們能夠定義和找出直接導致預測的功能，這對於資料收集和模型評估有廣泛的影響。我們展示了兩個假設，在這些假設下，可以直接從資料中找出原因，其中一個進一步簡化了發現的過程。除了提供健全且完整的演算法之外，我們還提出一個基於獨立性規則的最佳化技術，它可以與演算法整合，在理論上和經驗上加速發現的過程。

##### **Constrained Identifiability of Causal Effects**
2412.02869v1 by Yizuo Chen, Adnan Darwiche

We study the identification of causal effects in the presence of different
types of constraints (e.g., logical constraints) in addition to the causal
graph. These constraints impose restrictions on the models (parameterizations)
induced by the causal graph, reducing the set of models considered by the
identifiability problem. We formalize the notion of constrained
identifiability, which takes a set of constraints as another input to the
classical definition of identifiability. We then introduce a framework for
testing constrained identifiability by employing tractable Arithmetic Circuits
(ACs), which enables us to accommodate constraints systematically. We show that
this AC-based approach is at least as complete as existing algorithms (e.g.,
do-calculus) for testing classical identifiability, which only assumes the
constraint of strict positivity. We use examples to demonstrate the
effectiveness of this AC-based approach by showing that unidentifiable causal
effects may become identifiable under different types of constraints.

摘要：我們研究在因果圖之外，存在不同類型約束（例如邏輯約束）的情況下，因果效應的識別。這些約束對因果圖所引發的模型（參數化）施加限制，減少識別問題所考慮的模型集。我們將受約束識別的概念形式化，這將一組約束作為可識別性的經典定義的另一個輸入。然後，我們引入一個測試受約束識別的框架，通過使用易於處理的算術電路 (AC) 來實現，這使我們能夠系統地適應約束。我們表明，這種基於 AC 的方法至少與現有的演算法（例如，do 演算）一樣完整，用於測試經典可識別性，這僅假設嚴格正定的約束。我們使用範例來證明基於 AC 的方法的有效性，方法是表明不可識別的因果效應在不同類型的約束下可能變得可識別。

##### **A Novel Compact LLM Framework for Local, High-Privacy EHR Data Applications**
2412.02868v1 by Yixiang Qu, Yifan Dai, Shilin Yu, Pradham Tanikella, Travis Schrank, Trevor Hackman, Didong Li, Di Wu

Large Language Models (LLMs) have shown impressive capabilities in natural
language processing, yet their use in sensitive domains like healthcare,
particularly with Electronic Health Records (EHR), faces significant challenges
due to privacy concerns and limited computational resources. This paper
presents a compact LLM framework designed for local deployment in settings with
strict privacy requirements and limited access to high-performance GPUs. We
introduce a novel preprocessing technique that uses information extraction
methods, e.g., regular expressions, to filter and emphasize critical
information in clinical notes, enhancing the performance of smaller LLMs on EHR
data. Our framework is evaluated using zero-shot and few-shot learning
paradigms on both private and publicly available (MIMIC-IV) datasets, and we
also compare its performance with fine-tuned LLMs on the MIMIC-IV dataset. The
results demonstrate that our preprocessing approach significantly boosts the
prediction accuracy of smaller LLMs, making them suitable for high-privacy,
resource-constrained applications. This study offers valuable insights into
optimizing LLM performance for sensitive, data-intensive tasks while addressing
computational and privacy limitations.

摘要：大型語言模型 (LLM) 在自然語言處理方面展現出令人印象深刻的能力，然而它們在醫療保健等敏感領域的使用，特別是電子健康紀錄 (EHR)，由於隱私問題和有限的運算資源而面臨重大挑戰。本文提出了一個緊湊的 LLM 框架，旨在在具有嚴格隱私要求和有限使用高性能 GPU 的環境中進行本地部署。我們引入了一種新穎的預處理技術，它使用資訊萃取方法，例如正規表示法，來過濾和強調臨床筆記中的關鍵資訊，增強較小 LLM 在 EHR 資料上的效能。我們的框架使用零次學習和少次學習範例在私人和公開可用的 (MIMIC-IV) 資料集上進行評估，我們也比較它在 MIMIC-IV 資料集上與微調 LLM 的效能。結果表明，我們的預處理方法顯著提升了較小 LLM 的預測準確度，使其適用於高度隱私、資源受限的應用程式。這項研究提供了寶貴的見解，用於最佳化 LLM 效能以應對敏感、資料密集型任務，同時解決運算和隱私限制。

##### **Unpaired Modality Translation for Pseudo Labeling of Histology Images**
2412.02858v1 by Arthur Boschet, Armand Collin, Nishka Katoch, Julien Cohen-Adad

The segmentation of histological images is critical for various biomedical
applications, yet the lack of annotated data presents a significant challenge.
We propose a microscopy pseudo labeling pipeline utilizing unsupervised image
translation to address this issue. Our method generates pseudo labels by
translating between labeled and unlabeled domains without requiring prior
annotation in the target domain. We evaluate two pseudo labeling strategies
across three image domains increasingly dissimilar from the labeled data,
demonstrating their effectiveness. Notably, our method achieves a mean Dice
score of $0.736 \pm 0.005$ on a SEM dataset using the tutoring path, which
involves training a segmentation model on synthetic data created by translating
the labeled dataset (TEM) to the target modality (SEM). This approach aims to
accelerate the annotation process by providing high-quality pseudo labels as a
starting point for manual refinement.

摘要：組織切片影像的分割對於各種生物醫學應用至關重要，然而缺乏註解資料卻是一個重大的挑戰。
我們提出一個利用非監督式影像轉換的顯微鏡偽標籤處理流程來解決這個問題。我們的技術透過在標籤和未標籤網域間進行轉換來產生偽標籤，而不需要在目標網域中進行事先註解。我們在三個與標籤資料越來越不類似的影像網域中評估了兩種偽標籤策略，並證明了它們的有效性。值得注意的是，我們的技術在使用輔導路徑的 SEM 資料集上達到了平均 Dice 分數 $0.736 \pm 0.005$，這包括在合成資料上訓練分割模型，該合成資料是透過將標籤資料集 (TEM) 轉換到目標模式 (SEM) 而建立的。此方法旨在透過提供高品質的偽標籤作為人工精修的起點，來加速註解程序。

##### **FLAME 3 Dataset: Unleashing the Power of Radiometric Thermal UAV Imagery for Wildfire Management**
2412.02831v1 by Bryce Hopkins, Leo ONeill, Michael Marinaccio, Eric Rowell, Russell Parsons, Sarah Flanary, Irtija Nazim, Carl Seielstad, Fatemeh Afghah

The increasing accessibility of radiometric thermal imaging sensors for
unmanned aerial vehicles (UAVs) offers significant potential for advancing
AI-driven aerial wildfire management. Radiometric imaging provides per-pixel
temperature estimates, a valuable improvement over non-radiometric data that
requires irradiance measurements to be converted into visible images using RGB
color palettes. Despite its benefits, this technology has been underutilized
largely due to a lack of available data for researchers. This study addresses
this gap by introducing methods for collecting and processing synchronized
visual spectrum and radiometric thermal imagery using UAVs at prescribed fires.
The included imagery processing pipeline drastically simplifies and partially
automates each step from data collection to neural network input. Further, we
present the FLAME 3 dataset, the first comprehensive collection of side-by-side
visual spectrum and radiometric thermal imagery of wildland fires. Building on
our previous FLAME 1 and FLAME 2 datasets, FLAME 3 includes radiometric thermal
Tag Image File Format (TIFFs) and nadir thermal plots, providing a new data
type and collection method. This dataset aims to spur a new generation of
machine learning models utilizing radiometric thermal imagery, potentially
trivializing tasks such as aerial wildfire detection, segmentation, and
assessment. A single-burn subset of FLAME 3 for computer vision applications is
available on Kaggle with the full 6 burn set available to readers upon request.

摘要：無人機（UAV）的放射熱影像感測器越來越普及，為推進人工智慧驅動的空中野火管理提供了巨大的潛力。放射熱影像提供每個像素的溫度估計值，這比非放射熱數據的寶貴改進，後者需要將輻照度測量值轉換為使用 RGB 調色板的可見影像。儘管有這些優點，但由於研究人員缺乏可用的數據，這項技術的使用率一直偏低。本研究透過介紹使用無人機在規定的火災中收集和處理同步可見光譜和放射熱影像的方法來解決這個差距。所包含的影像處理管道大幅簡化並部分自動化從數據收集到神經網路輸入的每一個步驟。此外，我們展示了 FLAME 3 資料集，這是第一個並排收集野生火災的可見光譜和放射熱影像的綜合資料集。FLAME 3 建構在我們之前的 FLAME 1 和 FLAME 2 資料集之上，包含放射熱標籤影像檔案格式 (TIFF) 和天底熱區塊，提供新的資料類型和收集方法。此資料集旨在激發新一代機器學習模型，利用放射熱影像，潛在地簡化空中野火偵測、分割和評估等任務。FLAME 3 的單次燃燒子集可供電腦視覺應用程式在 Kaggle 上使用，而完整的 6 次燃燒設定可應讀者要求提供。

##### **RARE: Retrieval-Augmented Reasoning Enhancement for Large Language Models**
2412.02830v1 by Hieu Tran, Zonghai Yao, Junda Wang, Yifan Zhang, Zhichao Yang, Hong Yu

This work introduces RARE (Retrieval-Augmented Reasoning Enhancement), a
versatile extension to the mutual reasoning framework (rStar), aimed at
enhancing reasoning accuracy and factual integrity across large language models
(LLMs) for complex, knowledge-intensive tasks such as commonsense and medical
reasoning. RARE incorporates two innovative actions within the Monte Carlo Tree
Search (MCTS) framework: A6, which generates search queries based on the
initial problem statement, performs information retrieval using those queries,
and augments reasoning with the retrieved data to formulate the final answer;
and A7, which leverages information retrieval specifically for generated
sub-questions and re-answers these sub-questions with the relevant contextual
information. Additionally, a Retrieval-Augmented Factuality Scorer is proposed
to replace the original discriminator, prioritizing reasoning paths that meet
high standards of factuality. Experimental results with LLaMA 3.1 show that
RARE enables open-source LLMs to achieve competitive performance with top
open-source models like GPT-4 and GPT-4o. This research establishes RARE as a
scalable solution for improving LLMs in domains where logical coherence and
factual integrity are critical.

摘要：這項工作介紹了 RARE（檢索增強推理強化），這是對相互推理架構 (rStar) 的多功能擴充，旨在增強大型語言模型 (LLM) 在常識和醫學推理等複雜、知識密集型任務的推理準確性和事實完整性。RARE 在蒙地卡羅樹搜尋 (MCTS) 架構中包含兩個創新的動作：A6，它根據初始問題陳述產生搜尋查詢，使用這些查詢執行資訊檢索，並使用檢索到的資料擴充推理以制定最終答案；以及 A7，它特別針對生成的子問題利用資訊檢索，並使用相關的上下文資訊重新回答這些子問題。此外，還提出了檢索增強事實評分器來取代原始的判別器，優先考慮符合高事實標準的推理路徑。與 LLaMA 3.1 的實驗結果顯示，RARE 能讓開源 LLM 達到與 GPT-4 和 GPT-4o 等頂尖開源模型競爭的效能。這項研究將 RARE 建立為一個可擴充的解決方案，用於改善在邏輯連貫性和事實完整性至關重要的領域中的 LLM。

##### **Minimization of Boolean Complexity in In-Context Concept Learning**
2412.02823v1 by Leroy Z. Wang, R. Thomas McCoy, Shane Steinert-Threlkeld

What factors contribute to the relative success and corresponding
difficulties of in-context learning for Large Language Models (LLMs)? Drawing
on insights from the literature on human concept learning, we test LLMs on
carefully designed concept learning tasks, and show that task performance
highly correlates with the Boolean complexity of the concept. This suggests
that in-context learning exhibits a learning bias for simplicity in a way
similar to humans.

摘要：哪些因素促成了大型語言模型 (LLM) 的情境學習的相對成功和相應的難度？利用人類概念學習文獻中的見解，我們在精心設計的概念學習任務中測試了 LLM，並表明任務表現與概念的布林複雜度高度相關。這表明情境學習表現出類似於人類的簡化學習偏見。

##### **CNNSum: Exploring Long-Conext Summarization with Large Language Models in Chinese Novels**
2412.02819v1 by Lingxiao Wei, He Yan, Xiangju Lu, Junmin Zhu, Jun Wang, Wei Zhang

Large Language Models (LLMs) have been well-researched in many long-context
tasks. However, due to high annotation costs, high-quality long-context summary
datasets for training or evaluation are scarce, limiting further research. In
this work, we introduce CNNSum, a new multi-scale Chinese long-context novel
summarization benchmark, including four subsets, length covering
16k\textasciitilde128k, 695 samples in total, the annotations are human-driven.
We evaluate commercial and open-source models on CNNSum and conduct a detailed
analysis. Based on the observations, we further conduct fine-tuning exploration
with short-context summary data. In our study: (1) GPT-4o underperformed, due
to excessive subjective commentary. (2) Currently, long-context summarization
mainly relies on memory ability, small LLMs with stable longer context lengths
are the most cost-effective. Using long data concatenated from short-context
summaries makes a significant improvement. (3) Prompt templates may cause a
large performance gap but can be mitigated through fine-tuning. (4) Fine-tuned
Chat or Instruction versions may harm the Base model and further fine-tuning
cannot bridge performance gap. (5) while models with RoPE base scaling exhibit
strong extrapolation potential, their performance may vary significantly when
combined with other interpolation methods and need careful selection. (6)
CNNSum provides more reliable and insightful evaluation results than other
benchmarks. We release CNNSum to advance research in this field.

摘要：<paragraph>大型語言模型 (LLM) 已在許多長語境任務中獲得充分研究。然而，由於標註成本高昂，用於訓練或評估的高品質長語境摘要資料集稀少，限制了進一步的研究。在這項工作中，我們介紹了 CNNSum，一個新的多尺度中文長語境小說摘要基準，包括四個子集，長度涵蓋 16k\textasciitilde128k，總共 695 個樣本，標註是由人工驅動的。我們評估了 CNNSum 上的商業和開源模型，並進行了詳細的分析。根據觀察結果，我們進一步使用短語境摘要資料進行微調探索。在我們的研究中：(1) GPT-4o 表現不佳，因為過度的主觀評論。(2) 目前，長語境摘要主要依賴記憶能力，具有穩定較長語境長度的小型 LLM 最具成本效益。使用從短語境摘要串接而成的長資料可以顯著提升。(3) 提示範本可能會導致很大的效能差距，但可以透過微調來減輕。(4) 微調的聊天或指令版本可能會損害基礎模型，進一步的微調無法彌合效能差距。(5) 雖然具有 RoPE 基礎縮放的模型展現出強大的外推潛力，但它們與其他內插方法結合使用時，效能可能會顯著變化，需要仔細選擇。(6) CNNSum 提供比其他基準更可靠且有見地的評估結果。我們發布 CNNSum 以推動此領域的研究。</paragraph>

##### **Gaussian Splatting Under Attack: Investigating Adversarial Noise in 3D Objects**
2412.02803v1 by Abdurrahman Zeybey, Mehmet Ergezer, Tommy Nguyen

3D Gaussian Splatting has advanced radiance field reconstruction, enabling
high-quality view synthesis and fast rendering in 3D modeling. While
adversarial attacks on object detection models are well-studied for 2D images,
their impact on 3D models remains underexplored. This work introduces the
Masked Iterative Fast Gradient Sign Method (M-IFGSM), designed to generate
adversarial noise targeting the CLIP vision-language model. M-IFGSM
specifically alters the object of interest by focusing perturbations on masked
regions, degrading the performance of CLIP's zero-shot object detection
capability when applied to 3D models. Using eight objects from the Common
Objects 3D (CO3D) dataset, we demonstrate that our method effectively reduces
the accuracy and confidence of the model, with adversarial noise being nearly
imperceptible to human observers. The top-1 accuracy in original model renders
drops from 95.4\% to 12.5\% for train images and from 91.2\% to 35.4\% for test
images, with confidence levels reflecting this shift from true classification
to misclassification, underscoring the risks of adversarial attacks on 3D
models in applications such as autonomous driving, robotics, and surveillance.
The significance of this research lies in its potential to expose
vulnerabilities in modern 3D vision models, including radiance fields,
prompting the development of more robust defenses and security measures in
critical real-world applications.

摘要：<paragraph>3D 高斯散射提升了輻照場重建，實現了 3D 建模中的高品質視圖合成和快速渲染。儘管對物體檢測模型的對抗攻擊在 2D 圖像中得到了很好的研究，但它們對 3D 模型的影響仍未得到充分探索。這項工作引入了蒙版迭代快速梯度符號方法 (M-IFGSM)，旨在產生針對 CLIP 視覺語言模型的對抗噪聲。M-IFGSM 通過將擾動集中在蒙版區域來專門改變感興趣的物體，從而降低 CLIP 零次物體檢測能力在應用於 3D 模型時的性能。使用 Common Objects 3D (CO3D) 數據集中的八個物體，我們證明了我們的方法有效地降低了模型的準確性和置信度，而對抗噪聲對人類觀察者來說幾乎是不可察覺的。原始模型渲染中的前 1 準確率從訓練圖像的 95.4% 降至 12.5%，從測試圖像的 91.2% 降至 35.4%，置信度反映了這種從正確分類到錯誤分類的轉變，強調了對抗攻擊對 3D 的風險在自動駕駛、機器人和監控等應用中的模型。這項研究的意義在於它有可能揭示現代 3D 視覺模型（包括輻照場）中的漏洞，促使在關鍵的現實世界應用中開發更強大的防禦和安全措施。</paragraph>

