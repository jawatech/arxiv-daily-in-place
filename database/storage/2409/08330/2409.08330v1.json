{"2409.08330": {"publish_time": "2024-09-12", "title": "Real or Robotic? Assessing Whether LLMs Accurately Simulate Qualities of Human Responses in Dialogue", "paper_summary": "Studying and building datasets for dialogue tasks is both expensive and\ntime-consuming due to the need to recruit, train, and collect data from study\nparticipants. In response, much recent work has sought to use large language\nmodels (LLMs) to simulate both human-human and human-LLM interactions, as they\nhave been shown to generate convincingly human-like text in many settings.\nHowever, to what extent do LLM-based simulations \\textit{actually} reflect\nhuman dialogues? In this work, we answer this question by generating a\nlarge-scale dataset of 100,000 paired LLM-LLM and human-LLM dialogues from the\nWildChat dataset and quantifying how well the LLM simulations align with their\nhuman counterparts. Overall, we find relatively low alignment between\nsimulations and human interactions, demonstrating a systematic divergence along\nthe multiple textual properties, including style and content. Further, in\ncomparisons of English, Chinese, and Russian dialogues, we find that models\nperform similarly. Our results suggest that LLMs generally perform better when\nthe human themself writes in a way that is more similar to the LLM's own style.", "paper_summary_zh": "\u7814\u7a76\u548c\u5efa\u7acb\u5bf9\u8bdd\u4efb\u52a1\u7684\u6570\u636e\u96c6\u65e2\u6602\u8d35\u53c8\u8017\u65f6\uff0c\u8fd9\u662f\u56e0\u4e3a\u9700\u8981\u62db\u52df\u3001\u57f9\u8bad\u548c\u6536\u96c6\u7814\u7a76\u53c2\u4e0e\u8005\u7684\u6570\u636e\u3002\u5bf9\u6b64\uff0c\u8bb8\u591a\u8fd1\u671f\u5de5\u4f5c\u8bd5\u56fe\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6765\u6a21\u62df\u4eba\u4e0e\u4eba\u4ee5\u53ca\u4eba\u4e0e LLM \u4e4b\u95f4\u7684\u4e92\u52a8\uff0c\u56e0\u4e3a\u5b83\u4eec\u5df2\u88ab\u8bc1\u660e\u53ef\u4ee5\u5728\u8bb8\u591a\u8bbe\u7f6e\u4e2d\u751f\u6210\u4ee4\u4eba\u4fe1\u670d\u7684\u7c7b\u4eba\u6587\u672c\u3002\u7136\u800c\uff0c\u57fa\u4e8e LLM \u7684\u6a21\u62df\u5728\u591a\u5927\u7a0b\u5ea6\u4e0a\\textit{\u5b9e\u9645\u4e0a}\u53cd\u6620\u4e86\u4eba\u7c7b\u5bf9\u8bdd\uff1f\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u901a\u8fc7\u4ece WildChat \u6570\u636e\u96c6\u4e2d\u751f\u6210\u4e00\u4e2a\u5305\u542b 100,000 \u5bf9 LLM-LLM \u548c\u4eba\u673a\u5bf9\u8bdd\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u5e76\u91cf\u5316 LLM \u6a21\u62df\u4e0e\u5176\u4eba\u7c7b\u5bf9\u5e94\u9879\u7684\u5339\u914d\u7a0b\u5ea6\uff0c\u6765\u56de\u7b54\u8fd9\u4e2a\u95ee\u9898\u3002\u603b\u4f53\u800c\u8a00\uff0c\u6211\u4eec\u53d1\u73b0\u6a21\u62df\u4e0e\u4eba\u7c7b\u4e92\u52a8\u4e4b\u95f4\u7684\u5339\u914d\u5ea6\u76f8\u5bf9\u8f83\u4f4e\uff0c\u8fd9\u8bc1\u660e\u4e86\u5728\u5305\u62ec\u98ce\u683c\u548c\u5185\u5bb9\u5728\u5185\u7684\u591a\u79cd\u6587\u672c\u5c5e\u6027\u4e0a\u7684\u7cfb\u7edf\u6027\u5dee\u5f02\u3002\u6b64\u5916\uff0c\u5728\u5bf9\u82f1\u8bed\u3001\u4e2d\u6587\u548c\u4fc4\u8bed\u5bf9\u8bdd\u7684\u6bd4\u8f83\u4e2d\uff0c\u6211\u4eec\u53d1\u73b0\u6a21\u578b\u7684\u8868\u73b0\u76f8\u4f3c\u3002\u6211\u4eec\u7684\u7ed3\u679c\u8868\u660e\uff0c\u5f53\u4eba\u7c7b\u81ea\u5df1\u4ee5\u66f4\u7c7b\u4f3c\u4e8e LLM \u81ea\u8eab\u98ce\u683c\u7684\u65b9\u5f0f\u4e66\u5199\u65f6\uff0cLLM \u901a\u5e38\u8868\u73b0\u5f97\u66f4\u597d\u3002", "author": "Johnathan Ivey et.al.", "authors": "Johnathan Ivey, Shivani Kumar, Jiayu Liu, Hua Shen, Sushrita Rakshit, Rohan Raju, Haotian Zhang, Aparna Ananthasubramaniam, Junghwan Kim, Bowen Yi, Dustin Wright, Abraham Israeli, Anders Giovanni M\u00f8ller, Lechen Zhang, David Jurgens", "id": "2409.08330v1", "paper_url": "http://arxiv.org/abs/2409.08330v1", "repo": "https://github.com/davidjurgens/human-llm-similarity"}}