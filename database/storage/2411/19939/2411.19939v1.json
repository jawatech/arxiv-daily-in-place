{"2411.19939": {"publish_time": "2024-11-29", "title": "VLSBench: Unveiling Visual Leakage in Multimodal Safety", "paper_summary": "Safety concerns of Multimodal large language models (MLLMs) have gradually\nbecome an important problem in various applications. Surprisingly, previous\nworks indicate a counter-intuitive phenomenon that using textual unlearning to\nalign MLLMs achieves comparable safety performances with MLLMs trained with\nimage-text pairs. To explain such a counter-intuitive phenomenon, we discover a\nvisual safety information leakage (VSIL) problem in existing multimodal safety\nbenchmarks, i.e., the potentially risky and sensitive content in the image has\nbeen revealed in the textual query. In this way, MLLMs can easily refuse these\nsensitive text-image queries according to textual queries. However, image-text\npairs without VSIL are common in real-world scenarios and are overlooked by\nexisting multimodal safety benchmarks. To this end, we construct multimodal\nvisual leakless safety benchmark (VLSBench) preventing visual safety leakage\nfrom image to textual query with 2.4k image-text pairs. Experimental results\nindicate that VLSBench poses a significant challenge to both open-source and\nclose-source MLLMs, including LLaVA, Qwen2-VL, Llama3.2-Vision, and GPT-4o.\nThis study demonstrates that textual alignment is enough for multimodal safety\nscenarios with VSIL, while multimodal alignment is a more promising solution\nfor multimodal safety scenarios without VSIL. Please see our code and data at:\nhttp://hxhcreate.github.io/VLSBench", "paper_summary_zh": "\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b (MLLM) \u7684\u5b89\u5168\u6027\u95ee\u9898\u5df2\u9010\u6e10\u6210\u4e3a\u5404\u79cd\u5e94\u7528\u4e2d\u7684\u91cd\u8981\u95ee\u9898\u3002\u4ee4\u4eba\u60ca\u8bb6\u7684\u662f\uff0c\u5148\u524d\u7814\u7a76\u8868\u660e\uff0c\u4f7f\u7528\u6587\u672c\u5f0f\u53cd\u5b66\u4e60\u6765\u8c03\u6574 MLLM\uff0c\u53ef\u8fbe\u5230\u4e0e\u4f7f\u7528\u56fe\u50cf\u6587\u672c\u5bf9\u8bad\u7ec3\u7684 MLLM \u76f8\u5f53\u7684\u5b89\u5168\u6027\u8868\u73b0\u3002\u4e3a\u4e86\u89e3\u91ca\u8fd9\u79cd\u53cd\u76f4\u89c9\u73b0\u8c61\uff0c\u6211\u4eec\u53d1\u73b0\u73b0\u6709\u591a\u6a21\u6001\u5b89\u5168\u6027\u57fa\u51c6\u4e2d\u5b58\u5728\u89c6\u89c9\u5b89\u5168\u6027\u4fe1\u606f\u6cc4\u6f0f (VSIL) \u95ee\u9898\uff0c\u5373\u56fe\u50cf\u4e2d\u6f5c\u5728\u7684\u5371\u9669\u548c\u654f\u611f\u5185\u5bb9\u5df2\u5728\u6587\u672c\u67e5\u8be2\u4e2d\u63ed\u9732\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0cMLLM \u53ef\u4ee5\u6839\u636e\u6587\u672c\u67e5\u8be2\u8f7b\u677e\u62d2\u7edd\u8fd9\u4e9b\u654f\u611f\u7684\u6587\u672c\u56fe\u50cf\u67e5\u8be2\u3002\u7136\u800c\uff0c\u5728\u73b0\u5b9e\u4e16\u754c\u573a\u666f\u4e2d\uff0c\u6ca1\u6709 VSIL \u7684\u56fe\u50cf\u6587\u672c\u5bf9\u5f88\u5e38\u89c1\uff0c\u5e76\u4e14\u88ab\u73b0\u6709\u7684\u591a\u6a21\u6001\u5b89\u5168\u6027\u57fa\u51c6\u6240\u5ffd\u7565\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u6784\u5efa\u4e86\u591a\u6a21\u6001\u89c6\u89c9\u65e0\u6cc4\u6f0f\u5b89\u5168\u6027\u57fa\u51c6 (VLSBench)\uff0c\u9632\u6b62\u89c6\u89c9\u5b89\u5168\u6027\u4ece\u56fe\u50cf\u6cc4\u6f0f\u5230\u6587\u672c\u67e5\u8be2\uff0c\u5176\u4e2d\u5305\u542b 2.4k \u56fe\u50cf\u6587\u672c\u5bf9\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cVLSBench \u5bf9\u5f00\u6e90\u548c\u95ed\u6e90 MLLM \u6784\u6210\u4e86\u91cd\u5927\u6311\u6218\uff0c\u5305\u62ec LLaVA\u3001Qwen2-VL\u3001Llama3.2-Vision \u548c GPT-4o\u3002\u8fd9\u9879\u7814\u7a76\u8868\u660e\uff0c\u6587\u672c\u8c03\u6574\u5bf9\u4e8e\u5177\u6709 VSIL \u7684\u591a\u6a21\u6001\u5b89\u5168\u6027\u573a\u666f\u6765\u8bf4\u5df2\u7ecf\u8db3\u591f\uff0c\u800c\u591a\u6a21\u6001\u8c03\u6574\u5bf9\u4e8e\u6ca1\u6709 VSIL \u7684\u591a\u6a21\u6001\u5b89\u5168\u6027\u573a\u666f\u6765\u8bf4\u662f\u4e00\u4e2a\u66f4\u6709\u524d\u9014\u7684\u89e3\u51b3\u65b9\u6848\u3002\u8bf7\u53c2\u9605\u6211\u4eec\u7684\u4ee3\u7801\u548c\u6570\u636e\uff1ahttp://hxhcreate.github.io/VLSBench", "author": "Xuhao Hu et.al.", "authors": "Xuhao Hu, Dongrui Liu, Hao Li, Xuanjing Huang, Jing Shao", "id": "2411.19939v1", "paper_url": "http://arxiv.org/abs/2411.19939v1", "repo": "null"}}