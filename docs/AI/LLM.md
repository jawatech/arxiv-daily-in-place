
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-22**|**Controllable Text Generation for Large Language Models: A Survey**|Xun Liang et.al.|[2408.12599v1](http://arxiv.org/abs/2408.12599v1)|[link](https://github.com/iaar-shanghai/ctgsurvey)|
|**2024-08-22**|**ND-SDF: Learning Normal Deflection Fields for High-Fidelity Indoor Reconstruction**|Ziyu Tang et.al.|[2408.12598v1](http://arxiv.org/abs/2408.12598v1)|null|
|**2024-08-22**|**xGen-VideoSyn-1: High-fidelity Text-to-Video Synthesis with Compressed Representations**|Can Qin et.al.|[2408.12590v1](http://arxiv.org/abs/2408.12590v1)|null|
|**2024-08-22**|**RuleAlign: Making Large Language Models Better Physicians with Diagnostic Rule Alignment**|Xiaohan Wang et.al.|[2408.12579v1](http://arxiv.org/abs/2408.12579v1)|null|
|**2024-08-22**|**A Percolation Model of Emergence: Analyzing Transformers Trained on a Formal Language**|Ekdeep Singh Lubana et.al.|[2408.12578v1](http://arxiv.org/abs/2408.12578v1)|[link](https://github.com/ekdeepslubana/conceptpercolation)|
|**2024-08-22**|**Enhanced Parking Perception by Multi-Task Fisheye Cross-view Transformers**|Antonyo Musabini et.al.|[2408.12575v1](http://arxiv.org/abs/2408.12575v1)|null|
|**2024-08-22**|**MuMA-ToM: Multi-modal Multi-Agent Theory of Mind**|Haojun Shi et.al.|[2408.12574v1](http://arxiv.org/abs/2408.12574v1)|null|
|**2024-08-22**|**Jamba-1.5: Hybrid Transformer-Mamba Models at Scale**|Jamba Team et.al.|[2408.12570v1](http://arxiv.org/abs/2408.12570v1)|null|
|**2024-08-22**|**Pruning By Explaining Revisited: Optimizing Attribution Methods to Prune CNNs and Transformers**|Sayed Mohammad Vakilzadeh Hatefi et.al.|[2408.12568v1](http://arxiv.org/abs/2408.12568v1)|null|
|**2024-08-22**|**ssProp: Energy-Efficient Training for Convolutional Neural Networks with Scheduled Sparse Back Propagation**|Lujia Zhong et.al.|[2408.12561v1](http://arxiv.org/abs/2408.12561v1)|[link](https://github.com/lujiazho/ssprop)|
|**2024-08-22**|**Data Quality Antipatterns for Software Analytics**|Aaditya Bhatia et.al.|[2408.12560v1](http://arxiv.org/abs/2408.12560v1)|null|
|**2024-08-22**|**Modeling Time-Variant Responses of Optical Compressors with Selective State Space Models**|Riccardo Simionato et.al.|[2408.12549v1](http://arxiv.org/abs/2408.12549v1)|null|
|**2024-08-22**|**Towards Evaluating and Building Versatile Large Language Models for Medicine**|Chaoyi Wu et.al.|[2408.12547v1](http://arxiv.org/abs/2408.12547v1)|[link](https://github.com/magic-ai4med/meds-ins)|
|**2024-08-22**|**PCGRL+: Scaling, Control and Generalization in Reinforcement Learning Level Generators**|Sam Earle et.al.|[2408.12525v1](http://arxiv.org/abs/2408.12525v1)|null|
|**2024-08-22**|**Advanced atom-level representations for protein flexibility prediction utilizing graph neural networks**|Sina Sarparast et.al.|[2408.12519v1](http://arxiv.org/abs/2408.12519v1)|null|
|**2024-08-22**|**The Russian-focused embedders' exploration: ruMTEB benchmark and Russian embedding model design**|Artem Snegirev et.al.|[2408.12503v1](http://arxiv.org/abs/2408.12503v1)|null|
|**2024-08-22**|**MEDCO: Medical Education Copilots Based on A Multi-Agent Framework**|Hao Wei et.al.|[2408.12496v1](http://arxiv.org/abs/2408.12496v1)|null|
|**2024-08-22**|**GenderCARE: A Comprehensive Framework for Assessing and Reducing Gender Bias in Large Language Models**|Kunsheng Tang et.al.|[2408.12494v1](http://arxiv.org/abs/2408.12494v1)|[link](https://github.com/kstanghere/gendercare-ccs24)|
|**2024-08-22**|**Vintern-1B: An Efficient Multimodal Large Language Model for Vietnamese**|Khang T. Doan et.al.|[2408.12480v1](http://arxiv.org/abs/2408.12480v1)|null|
|**2024-08-22**|**Predicting Solar Energy Generation with Machine Learning based on AQI and Weather Features**|Arjun Shah et.al.|[2408.12476v1](http://arxiv.org/abs/2408.12476v1)|null|
|**2024-08-22**|**WCEbleedGen: A wireless capsule endoscopy dataset and its benchmarking for automatic bleeding classification, detection, and segmentation**|Palak Handa et.al.|[2408.12466v1](http://arxiv.org/abs/2408.12466v1)|[link](https://github.com/misahub2023/benchmarking-codes-of-the-wcebleedgen-dataset)|
|**2024-08-22**|**Enhancing Multi-hop Reasoning through Knowledge Erasure in Large Language Model Editing**|Mengqi Zhang et.al.|[2408.12456v1](http://arxiv.org/abs/2408.12456v1)|null|
|**2024-08-22**|**A Riemannian Approach for Spatiotemporal Analysis and Generation of 4D Tree-shaped Structures**|Tahmina Khanam et.al.|[2408.12443v1](http://arxiv.org/abs/2408.12443v1)|[link](https://github.com/tahmina979/4dtreeshape_project)|
|**2024-08-22**|**Positional Description for Numerical Normalization**|Deepanshu Gupta et.al.|[2408.12430v1](http://arxiv.org/abs/2408.12430v1)|null|
|**2024-08-22**|**Enhanced Infield Agriculture with Interpretable Machine Learning Approaches for Crop Classification**|Sudi Murindanyi et.al.|[2408.12426v1](http://arxiv.org/abs/2408.12426v1)|null|
|**2024-08-22**|**Multi-Knowledge Fusion Network for Time Series Representation Learning**|Sagar Srinivas Sakhinana et.al.|[2408.12423v1](http://arxiv.org/abs/2408.12423v1)|null|
|**2024-08-22**|**4D Diffusion for Dynamic Protein Structure Prediction with Reference Guided Motion Alignment**|Kaihui Cheng et.al.|[2408.12419v1](http://arxiv.org/abs/2408.12419v1)|null|
|**2024-08-22**|**CODE: Confident Ordinary Differential Editing**|Bastien van Delft et.al.|[2408.12418v1](http://arxiv.org/abs/2408.12418v1)|[link](https://github.com/vita-epfl/code)|
|**2024-08-22**|**Dynamic PDB: A New Dataset and a SE(3) Model Extension by Integrating Dynamic Behaviors and Physical Properties in Protein Structures**|Ce Liu et.al.|[2408.12413v1](http://arxiv.org/abs/2408.12413v1)|null|
|**2024-08-22**|**Multi-Source Knowledge-Based Hybrid Neural Framework for Time Series Representation Learning**|Sagar Srinivas Sakhinana et.al.|[2408.12409v1](http://arxiv.org/abs/2408.12409v1)|null|
|**2024-08-22**|**Multi-Style Facial Sketch Synthesis through Masked Generative Modeling**|Bowen Sun et.al.|[2408.12400v1](http://arxiv.org/abs/2408.12400v1)|null|
|**2024-08-22**|**A Comparative Analysis of Faithfulness Metrics and Humans in Citation Evaluation**|Weijia Zhang et.al.|[2408.12398v1](http://arxiv.org/abs/2408.12398v1)|null|
|**2024-08-22**|**Cell-ontology guided transcriptome foundation model**|Xinyu Yuan et.al.|[2408.12373v1](http://arxiv.org/abs/2408.12373v1)|null|
|**2024-08-22**|**RoundTable: Leveraging Dynamic Schema and Contextual Autocomplete for Enhanced Query Precision in Tabular Question Answering**|Pratyush Kumar et.al.|[2408.12369v1](http://arxiv.org/abs/2408.12369v1)|null|
|**2024-08-22**|**SAM-SP: Self-Prompting Makes SAM Great Again**|Chunpeng Zhou et.al.|[2408.12364v1](http://arxiv.org/abs/2408.12364v1)|null|
|**2024-08-22**|**CLEANANERCorp: Identifying and Correcting Incorrect Labels in the ANERcorp Dataset**|Mashael Al-Duwais et.al.|[2408.12362v1](http://arxiv.org/abs/2408.12362v1)|null|
|**2024-08-22**|**Fine-tuning Smaller Language Models for Question Answering over Financial Documents**|Karmvir Singh Phogat et.al.|[2408.12337v1](http://arxiv.org/abs/2408.12337v1)|null|
|**2024-08-22**|**Graph Retrieval Augmented Trustworthiness Reasoning**|Ying Zhu et.al.|[2408.12333v1](http://arxiv.org/abs/2408.12333v1)|[link](https://github.com/EvoNexusX/Graph-Retrieval-Augmented-Trustworthiness-Reasoning)|
|**2024-08-22**|**Interactive DualChecker for Mitigating Hallucinations in Distilling Large Language Models**|Meiyun Wang et.al.|[2408.12326v1](http://arxiv.org/abs/2408.12326v1)|[link](https://github.com/kirawang23/dualchecker)|
|**2024-08-22**|**Improving Factuality in Large Language Models via Decoding-Time Hallucinatory and Truthful Comparators**|Dingkang Yang et.al.|[2408.12325v1](http://arxiv.org/abs/2408.12325v1)|null|
|**2024-08-22**|**MaVEn: An Effective Multi-granularity Hybrid Visual Encoding Framework for Multimodal Large Language Model**|Chaoya Jiang et.al.|[2408.12321v1](http://arxiv.org/abs/2408.12321v1)|null|
|**2024-08-22**|**PolyRouter: A Multi-LLM Querying System**|Dimitris Stripelis et.al.|[2408.12320v1](http://arxiv.org/abs/2408.12320v1)|null|
|**2024-08-22**|**Large Language Models Are Self-Taught Reasoners: Enhancing LLM Applications via Tailored Problem-Solving Demonstrations**|Kai Tzu-iunn Ong et.al.|[2408.12315v1](http://arxiv.org/abs/2408.12315v1)|null|
|**2024-08-22**|**Tipta uzmanlik sinavinda (tus) büyük dil modelleri insanlardan daha mi başarili?**|Yesim Aygul et.al.|[2408.12305v1](http://arxiv.org/abs/2408.12305v1)|null|
|**2024-08-22**|**OPTDTALS: Approximate Logic Synthesis via Optimal Decision Trees Approach**|Hao Hu et.al.|[2408.12304v1](http://arxiv.org/abs/2408.12304v1)|null|
|**2024-08-22**|**Towards Deconfounded Image-Text Matching with Causal Inference**|Wenhui Li et.al.|[2408.12292v1](http://arxiv.org/abs/2408.12292v1)|null|
|**2024-08-22**|**Variance reduction of diffusion model's gradients with Taylor approximation-based control variate**|Paul Jeha et.al.|[2408.12270v1](http://arxiv.org/abs/2408.12270v1)|null|
|**2024-08-22**|**Toward the Evaluation of Large Language Models Considering Score Variance across Instruction Templates**|Yusuke Sakai et.al.|[2408.12263v1](http://arxiv.org/abs/2408.12263v1)|null|
|**2024-08-22**|**Can You Trust Your Metric? Automatic Concatenation-Based Tests for Metric Validity**|Ora Nova Fandina et.al.|[2408.12259v1](http://arxiv.org/abs/2408.12259v1)|null|
|**2024-08-22**|**A Language-agnostic Model of Child Language Acquisition**|Louis Mahon et.al.|[2408.12254v1](http://arxiv.org/abs/2408.12254v1)|null|
|**2024-08-22**|**Can Artificial Intelligence Embody Moral Values?**|Torben Swoboda et.al.|[2408.12250v1](http://arxiv.org/abs/2408.12250v1)|null|
|**2024-08-22**|**LLMs are not Zero-Shot Reasoners for Biomedical Information Extraction**|Aishik Nagar et.al.|[2408.12249v1](http://arxiv.org/abs/2408.12249v1)|null|
|**2024-08-22**|**Efficient Multivariate Time Series Anomaly Detection Through Transfer Learning for Large-Scale Web services**|Shenglin Zhang et.al.|[2408.12247v1](http://arxiv.org/abs/2408.12247v1)|[link](https://github.com/zero-pointer/self-evolution)|
|**2024-08-22**|**Weight Scope Alignment: A Frustratingly Easy Method for Model Merging**|Yichu Xu et.al.|[2408.12237v1](http://arxiv.org/abs/2408.12237v1)|null|
|**2024-08-22**|**MedDiT: A Knowledge-Controlled Diffusion Transformer Framework for Dynamic Medical Image Generation in Virtual Simulated Patient**|Yanzeng Li et.al.|[2408.12236v1](http://arxiv.org/abs/2408.12236v1)|null|
|**2024-08-22**|**EvalYaks: Instruction Tuning Datasets and LoRA Fine-tuned Models for Automated Scoring of CEFR B2 Speaking Assessment Transcripts**|Nicy Scaria et.al.|[2408.12226v1](http://arxiv.org/abs/2408.12226v1)|[link](https://github.com/talking-yak/evalyaks)|
|**2024-08-22**|**UNCO: Towards Unifying Neural Combinatorial Optimization through Large Language Model**|Xia Jiang et.al.|[2408.12214v1](http://arxiv.org/abs/2408.12214v1)|null|
|**2024-08-22**|**Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment**|Kun Luo et.al.|[2408.12194v1](http://arxiv.org/abs/2408.12194v1)|null|
|**2024-08-22**|**Reasoning Factual Knowledge in Structured Data with Large Language Models**|Sirui Huang et.al.|[2408.12188v1](http://arxiv.org/abs/2408.12188v1)|[link](https://github.com/egangu/structfact)|
|**2024-08-22**|**A Safe and Efficient Self-evolving Algorithm for Decision-making and Control of Autonomous Driving Systems**|Shuo Yang et.al.|[2408.12187v1](http://arxiv.org/abs/2408.12187v1)|null|
|**2024-08-22**|**Rank and Align: Towards Effective Source-free Graph Domain Adaptation**|Junyu Luo et.al.|[2408.12185v1](http://arxiv.org/abs/2408.12185v1)|null|
|**2024-08-22**|**FIRST: Teach A Reliable Large Language Model Through Efficient Trustworthy Distillation**|KaShun Shum et.al.|[2408.12168v1](http://arxiv.org/abs/2408.12168v1)|null|
|**2024-08-22**|**Preference-Guided Reflective Sampling for Aligning Language Models**|Hai Ye et.al.|[2408.12163v1](http://arxiv.org/abs/2408.12163v1)|null|
|**2024-08-22**|**Search-Based LLMs for Code Optimization**|Shuzheng Gao et.al.|[2408.12159v1](http://arxiv.org/abs/2408.12159v1)|null|
|**2024-08-22**|**Implicit Sentiment Analysis Based on Chain of Thought Prompting**|Zhihua Duan et.al.|[2408.12157v1](http://arxiv.org/abs/2408.12157v1)|null|
|**2024-08-22**|**DeepHQ: Learned Hierarchical Quantizer for Progressive Deep Image Coding**|Jooyoung Lee et.al.|[2408.12150v1](http://arxiv.org/abs/2408.12150v1)|null|
|**2024-08-22**|**Multi-tool Integration Application for Math Reasoning Using Large Language Model**|Zhihua Duan et.al.|[2408.12148v1](http://arxiv.org/abs/2408.12148v1)|null|
|**2024-08-22**|**MDD-5k: A New Diagnostic Conversation Dataset for Mental Disorders Synthesized via Neuro-Symbolic LLM Agents**|Congchi Yin et.al.|[2408.12142v1](http://arxiv.org/abs/2408.12142v1)|[link](https://github.com/lemonsis/mdd-5k)|
|**2024-08-22**|**DRExplainer: Quantifiable Interpretability in Drug Response Prediction with Directed Graph Convolutional Network**|Haoyuan Shi et.al.|[2408.12139v1](http://arxiv.org/abs/2408.12139v1)|[link](https://github.com/vshy-dream/drexplainer)|
|**2024-08-22**|**Deep Analysis of Time Series Data for Smart Grid Startup Strategies: A Transformer-LSTM-PSO Model Approach**|Zecheng Zhang et.al.|[2408.12129v1](http://arxiv.org/abs/2408.12129v1)|null|
|**2024-08-22**|**AutoTest: Evolutionary Code Solution Selection with Test Cases**|Zhihua Duan et.al.|[2408.12125v1](http://arxiv.org/abs/2408.12125v1)|null|
|**2024-08-22**|**Geolocation Representation from Large Language Models are Generic Enhancers for Spatio-Temporal Learning**|Junlin He et.al.|[2408.12116v1](http://arxiv.org/abs/2408.12116v1)|null|
|**2024-08-22**|**Risk Analysis in Customer Relationship Management via Quantile Region Convolutional Neural Network-Long Short-Term Memory and Cross-Attention Mechanism**|Yaowen Huang et.al.|[2408.12113v1](http://arxiv.org/abs/2408.12113v1)|null|
|**2024-08-22**|**Balancing Act: Prioritization Strategies for LLM-Designed Restless Bandit Rewards**|Shresth Verma et.al.|[2408.12112v1](http://arxiv.org/abs/2408.12112v1)|null|
|**2024-08-22**|**RoVRM: A Robust Visual Reward Model Optimized via Auxiliary Textual Preference Data**|Chenglong Wang et.al.|[2408.12109v1](http://arxiv.org/abs/2408.12109v1)|null|
|**2024-08-22**|**Extraction of Research Objectives, Machine Learning Model Names, and Dataset Names from Academic Papers and Analysis of Their Interrelationships Using LLM and Network Analysis**|S. Nishio et.al.|[2408.12097v1](http://arxiv.org/abs/2408.12097v1)|null|
|**2024-08-22**|**uMedSum: A Unified Framework for Advancing Medical Abstractive Summarization**|Aishik Nagar et.al.|[2408.12095v1](http://arxiv.org/abs/2408.12095v1)|null|
|**2024-08-22**|**Unlocking Attributes' Contribution to Successful Camouflage: A Combined Textual and VisualAnalysis Strategy**|Hong Zhang et.al.|[2408.12086v1](http://arxiv.org/abs/2408.12086v1)|[link](https://github.com/lyu-yx/acumen)|
|**2024-08-22**|**Exploring the Feasibility of Automated Data Standardization using Large Language Models for Seamless Positioning**|Max J. L. Lee et.al.|[2408.12080v1](http://arxiv.org/abs/2408.12080v1)|null|
|**2024-08-22**|**High-Quality Data Augmentation for Low-Resource NMT: Combining a Translation Memory, a GAN Generator, and Filtering**|Hengjie Liu et.al.|[2408.12079v1](http://arxiv.org/abs/2408.12079v1)|null|
|**2024-08-22**|**ConflictBank: A Benchmark for Evaluating the Influence of Knowledge Conflicts in LLM**|Zhaochen Su et.al.|[2408.12076v1](http://arxiv.org/abs/2408.12076v1)|null|
|**2024-08-22**|**Transformers As Approximations of Solomonoff Induction**|Nathan Young et.al.|[2408.12065v1](http://arxiv.org/abs/2408.12065v1)|null|
|**2024-08-22**|**A Deconfounding Approach to Climate Model Bias Correction**|Wentao Gao et.al.|[2408.12063v1](http://arxiv.org/abs/2408.12063v1)|null|
|**2024-08-22**|**Enhancing Sampling Protocol for Robust Point Cloud Classification**|Chongshou Li et.al.|[2408.12062v1](http://arxiv.org/abs/2408.12062v1)|null|
|**2024-08-22**|**Evidence-backed Fact Checking using RAG and Few-Shot In-Context Learning with LLMs**|Ronit Singhal et.al.|[2408.12060v1](http://arxiv.org/abs/2408.12060v1)|null|
|**2024-08-22**|**Aligning (Medical) LLMs for (Counterfactual) Fairness**|Raphael Poulain et.al.|[2408.12055v1](http://arxiv.org/abs/2408.12055v1)|[link](https://github.com/healthylaife/fairalignmentllm)|
|**2024-08-21**|**Reasoning and Tools for Human-Level Forecasting**|Elvis Hsieh et.al.|[2408.12036v1](http://arxiv.org/abs/2408.12036v1)|null|
|**2024-08-21**|**Let Community Rules Be Reflected in Online Content Moderation**|Wangjiaxuan Xin et.al.|[2408.12035v1](http://arxiv.org/abs/2408.12035v1)|null|
|**2024-08-21**|**A Constraint Programming Approach to Fair High School Course Scheduling**|Mitsuka Kiyohara et.al.|[2408.12032v1](http://arxiv.org/abs/2408.12032v1)|null|
|**2024-08-21**|**Federated Diabetes Prediction in Canadian Adults Using Real-world Cross-Province Primary Care Data**|Guojun Tang et.al.|[2408.12029v1](http://arxiv.org/abs/2408.12029v1)|null|
|**2024-08-21**|**Exploring Large Language Models for Feature Selection: A Data-centric Perspective**|Dawei Li et.al.|[2408.12025v1](http://arxiv.org/abs/2408.12025v1)|null|
|**2024-08-21**|**Limitations in Employing Natural Language Supervision for Sensor-Based Human Activity Recognition -- And Ways to Overcome Them**|Harish Haresamudram et.al.|[2408.12023v1](http://arxiv.org/abs/2408.12023v1)|null|
|**2024-08-21**|**Understanding Epistemic Language with a Bayesian Theory of Mind**|Lance Ying et.al.|[2408.12022v1](http://arxiv.org/abs/2408.12022v1)|null|
|**2024-08-21**|**QuaCK-TSF: Quantum-Classical Kernelized Time Series Forecasting**|Abdallah Aaraba et.al.|[2408.12007v1](http://arxiv.org/abs/2408.12007v1)|[link](https://github.com/abdo-aar/quack-tsf)|
|**2024-08-21**|**RAG-Optimized Tibetan Tourism LLMs: Enhancing Accuracy and Personalization**|Jinhu Qi et.al.|[2408.12003v1](http://arxiv.org/abs/2408.12003v1)|null|
|**2024-08-21**|**SimBench: A Rule-Based Multi-Turn Interaction Benchmark for Evaluating an LLM's Ability to Generate Digital Twins**|Jingquan Wang et.al.|[2408.11987v1](http://arxiv.org/abs/2408.11987v1)|[link](https://github.com/uwsbel/simbench)|
|**2024-08-21**|**Chemical Reaction Neural Networks for Fitting Accelerated Rate Calorimetry Data**|Saakaar Bhatnagar et.al.|[2408.11984v1](http://arxiv.org/abs/2408.11984v1)|null|
|**2024-08-21**|**Large Language Models for Page Stream Segmentation**|Hunter Heidenreich et.al.|[2408.11981v1](http://arxiv.org/abs/2408.11981v1)|null|
|**2024-08-21**|**Only Strict Saddles in the Energy Landscape of Predictive Coding Networks?**|Francesco Innocenti et.al.|[2408.11979v1](http://arxiv.org/abs/2408.11979v1)|null|
|**2024-08-21**|**Sentiment and Emotion-aware Multi-criteria Fuzzy Group Decision Making System**|Adilet Yerkin et.al.|[2408.11976v1](http://arxiv.org/abs/2408.11976v1)|null|

#### Abstracts
##### **Controllable Text Generation for Large Language Models: A Survey**
2408.12599v1 by Xun Liang, Hanyu Wang, Yezhaohui Wang, Shichao Song, Jiawei Yang, Simin Niu, Jie Hu, Dan Liu, Shunyu Yao, Feiyu Xiong, Zhiyu Li

In Natural Language Processing (NLP), Large Language Models (LLMs) have
demonstrated high text generation quality. However, in real-world applications,
LLMs must meet increasingly complex requirements. Beyond avoiding misleading or
inappropriate content, LLMs are also expected to cater to specific user needs,
such as imitating particular writing styles or generating text with poetic
richness. These varied demands have driven the development of Controllable Text
Generation (CTG) techniques, which ensure that outputs adhere to predefined
control conditions--such as safety, sentiment, thematic consistency, and
linguistic style--while maintaining high standards of helpfulness, fluency, and
diversity.
  This paper systematically reviews the latest advancements in CTG for LLMs,
offering a comprehensive definition of its core concepts and clarifying the
requirements for control conditions and text quality. We categorize CTG tasks
into two primary types: content control and attribute control. The key methods
are discussed, including model retraining, fine-tuning, reinforcement learning,
prompt engineering, latent space manipulation, and decoding-time intervention.
We analyze each method's characteristics, advantages, and limitations,
providing nuanced insights for achieving generation control. Additionally, we
review CTG evaluation methods, summarize its applications across domains, and
address key challenges in current research, including reduced fluency and
practicality. We also propose several appeals, such as placing greater emphasis
on real-world applications in future research. This paper aims to offer
valuable guidance to researchers and developers in the field. Our reference
list and Chinese version are open-sourced at
https://github.com/IAAR-Shanghai/CTGSurvey.

摘要：<paragraph>在自然語言處理 (NLP) 中，大型語言模型 (LLM) 已展現出高品質的文字生成能力。然而，在現實世界的應用中，LLM 必須滿足日益複雜的要求。除了避免產生誤導或不適當的內容外，LLM 還預期能迎合特定的使用者需求，例如模仿特定的寫作風格或生成具有詩意豐富性的文字。這些不同的需求推動了可控文字生成 (CTG) 技術的發展，可確保輸出符合預先定義的控制條件（例如安全性、情緒、主題一致性和語言風格），同時維持高標準的實用性、流暢性和多樣性。
本文系統性地回顧了 LLM 中 CTG 的最新進展，提供了其核心概念的全面定義，並釐清了控制條件和文字品質的要求。我們將 CTG 任務分類為兩種主要類型：內容控制和屬性控制。討論了關鍵方法，包括模型再訓練、微調、強化學習、提示工程、潛在空間操作和解碼時介入。我們分析了每種方法的特徵、優點和限制，提供了實現生成控制的細微見解。此外，我們回顧了 CTG 評估方法，總結了其在各個領域的應用，並解決了當前研究中的關鍵挑戰，包括流暢性和實用性的降低。我們還提出了幾項呼籲，例如在未來的研究中更重視現實世界的應用。本文旨在為該領域的研究人員和開發人員提供有價值的指導。我們的參考文獻和中文版本在 https://github.com/IAAR-Shanghai/CTGSurvey 開源。</paragraph>

##### **ND-SDF: Learning Normal Deflection Fields for High-Fidelity Indoor Reconstruction**
2408.12598v1 by Ziyu Tang, Weicai Ye, Yifan Wang, Di Huang, Hujun Bao, Tong He, Guofeng Zhang

Neural implicit reconstruction via volume rendering has demonstrated its
effectiveness in recovering dense 3D surfaces. However, it is non-trivial to
simultaneously recover meticulous geometry and preserve smoothness across
regions with differing characteristics. To address this issue, previous methods
typically employ geometric priors, which are often constrained by the
performance of the prior models. In this paper, we propose ND-SDF, which learns
a Normal Ddeflection field to represent the angular deviation between the scene
normal and the prior normal. Unlike previous methods that uniformly apply
geometric priors on all samples, introducing significant bias in accuracy, our
proposed normal deflection field dynamically learns and adapts the utilization
of samples based on their specific characteristics, thereby improving both the
accuracy and effectiveness of the model. Our method not only obtains smooth
weakly textured regions such as walls and floors but also preserves the
geometric details of complex structures. In addition, we introduce a novel ray
sampling strategy based on the deflection angle to facilitate the unbiased
rendering process, which significantly improves the quality and accuracy of
intricate surfaces, especially on thin structures. Consistent improvements on
various challenging datasets demonstrate the superiority of our method.

摘要：神經隱式重建經由體積渲染已證實其在恢復密集 3D 表面上的效能。然而，要同時恢復細緻的幾何結構並在具有不同特徵的區域中保持平滑度並非易事。為了解決此問題，先前的做法通常採用幾何先驗，這些先驗通常受到先驗模型效能的限制。在本文中，我們提出了 ND-SDF，它學習一個法向量偏移場，以表示場景法向量與先驗法向量之間的角度偏差。與先前在所有範例中均一地套用幾何先驗的方法不同，我們的法向量偏移場會根據範例的特定特徵動態地學習並調整範例的使用，從而提升模型的準確度和效能。我們的做法不僅能獲得平滑的弱紋理區域（例如牆壁和地板），還能保留複雜結構的幾何細節。此外，我們引進了一種基於偏移角的新型光線取樣策略，以利於無偏渲染程序，這顯著提升了複雜表面的品質和準確度，特別是在薄結構上。在各種具有挑戰性的資料集上的一致改進證明了我們方法的優越性。

##### **xGen-VideoSyn-1: High-fidelity Text-to-Video Synthesis with Compressed Representations**
2408.12590v1 by Can Qin, Congying Xia, Krithika Ramakrishnan, Michael Ryoo, Lifu Tu, Yihao Feng, Manli Shu, Honglu Zhou, Anas Awadalla, Jun Wang, Senthil Purushwalkam, Le Xue, Yingbo Zhou, Huan Wang, Silvio Savarese, Juan Carlos Niebles, Zeyuan Chen, Ran Xu, Caiming Xiong

We present xGen-VideoSyn-1, a text-to-video (T2V) generation model capable of
producing realistic scenes from textual descriptions. Building on recent
advancements, such as OpenAI's Sora, we explore the latent diffusion model
(LDM) architecture and introduce a video variational autoencoder (VidVAE).
VidVAE compresses video data both spatially and temporally, significantly
reducing the length of visual tokens and the computational demands associated
with generating long-sequence videos. To further address the computational
costs, we propose a divide-and-merge strategy that maintains temporal
consistency across video segments. Our Diffusion Transformer (DiT) model
incorporates spatial and temporal self-attention layers, enabling robust
generalization across different timeframes and aspect ratios. We have devised a
data processing pipeline from the very beginning and collected over 13M
high-quality video-text pairs. The pipeline includes multiple steps such as
clipping, text detection, motion estimation, aesthetics scoring, and dense
captioning based on our in-house video-LLM model. Training the VidVAE and DiT
models required approximately 40 and 642 H100 days, respectively. Our model
supports over 14-second 720p video generation in an end-to-end way and
demonstrates competitive performance against state-of-the-art T2V models.

摘要：我們提出 xGen-VideoSyn-1，一個文字轉影片 (T2V) 生成模型，能夠根據文字描述產生逼真的場景。在 OpenAI 的 Sora 等近期進展的基礎上，我們探討了潛在擴散模型 (LDM) 架構，並引入了影片變異自編碼器 (VidVAE)。VidVAE 在空間和時間上壓縮影片資料，大幅減少視覺標記的長度，以及產生長序列影片相關的運算需求。為了進一步解決運算成本，我們提出一個分而併之策略，以維持影片片段之間的時間一致性。我們的擴散轉換器 (DiT) 模型整合了空間和時間自我注意層，讓不同時間範圍和長寬比都能穩健地概括。我們從一開始就設計了一個資料處理流程，並收集了超過 1300 萬個高品質影片文字配對。流程包含多個步驟，例如剪輯、文字偵測、動作估計、美學評分，以及基於我們內部影片 LLM 模型的密集式字幕。訓練 VidVAE 和 DiT 模型分別需要大約 40 和 642 個 H100 天。我們的模型支援以端對端的方式產生超過 14 秒的 720p 影片，並展現出與現有 T2V 模型相比具有競爭力的效能。

##### **RuleAlign: Making Large Language Models Better Physicians with Diagnostic Rule Alignment**
2408.12579v1 by Xiaohan Wang, Xiaoyan Yang, Yuqi Zhu, Yue Shen, Jian Wang, Peng Wei, Lei Liang, Jinjie Gu, Huajun Chen, Ningyu Zhang

Large Language Models (LLMs) like GPT-4, MedPaLM-2, and Med-Gemini achieve
performance competitively with human experts across various medical benchmarks.
However, they still face challenges in making professional diagnoses akin to
physicians, particularly in efficiently gathering patient information and
reasoning the final diagnosis. To this end, we introduce the RuleAlign
framework, designed to align LLMs with specific diagnostic rules. We develop a
medical dialogue dataset comprising rule-based communications between patients
and physicians and design an alignment learning approach through preference
learning. Experimental results demonstrate the effectiveness of the proposed
approach. We hope that our work can serve as an inspiration for exploring the
potential of LLMs as AI physicians.

摘要：大型語言模型（LLM），例如 GPT-4、MedPaLM-2 和 Med-Gemini，在各種醫療基準上達到了與人類專家競爭的表現。
然而，他們在做出類似於醫師的專業診斷方面仍面臨挑戰，特別是在有效收集患者資訊和推論最終診斷方面。為此，我們引入了 RuleAlign 框架，旨在將 LLM 與特定診斷規則保持一致。我們開發了一個醫療對話資料集，其中包含患者與醫師之間基於規則的溝通，並透過偏好學習設計了一種比對學習方法。實驗結果證明了所提方法的有效性。我們希望我們的工作能激勵探索 LLM 作為 AI 醫師的潛力。

##### **A Percolation Model of Emergence: Analyzing Transformers Trained on a Formal Language**
2408.12578v1 by Ekdeep Singh Lubana, Kyogo Kawaguchi, Robert P. Dick, Hidenori Tanaka

Increase in data, size, or compute can lead to sudden learning of specific
capabilities by a neural network -- a phenomenon often called "emergence".
Beyond scientific understanding, establishing the causal factors underlying
such emergent capabilities is crucial to enable risk regulation frameworks for
AI. In this work, we seek inspiration from study of emergent properties in
other fields and propose a phenomenological definition for the concept in the
context of neural networks. Our definition implicates the acquisition of
specific structures underlying the data-generating process as a cause of sudden
performance growth for specific, narrower tasks. We empirically investigate
this definition by proposing an experimental system grounded in a
context-sensitive formal language and find that Transformers trained to perform
tasks on top of strings from this language indeed exhibit emergent
capabilities. Specifically, we show that once the language's underlying grammar
and context-sensitivity inducing structures are learned by the model,
performance on narrower tasks suddenly begins to improve. We then analogize our
network's learning dynamics with the process of percolation on a bipartite
graph, establishing a formal phase transition model that predicts the shift in
the point of emergence observed in experiment when changing the data structure.
Overall, our experimental and theoretical frameworks yield a step towards
better defining, characterizing, and predicting emergence in neural networks.

摘要：隨著資料、規模或運算增加，神經網路可能會突然學會特定功能，這種現象常稱為「湧現」。除了科學理解之外，建立造成這種湧現功能的因果關係，對於建立人工智慧的風險規範架構至關重要。在這項工作中，我們從其他領域對湧現特性的研究中尋求靈感，並提出在神經網路脈絡中對這個概念的現象學定義。我們的定義暗示，取得資料產生流程中特定的基礎結構，是特定、較狹窄任務突然效能提升的原因。我們透過提出一個以情境敏感形式語言為基礎的實驗系統，對這個定義進行實證調查，並發現訓練來執行這個語言中字串頂端任務的 Transformer，確實展現出湧現功能。具體來說，我們顯示出，一旦模型學會語言的基礎文法和引發情境敏感性的結構，執行較狹窄任務的效能就會突然開始提升。然後，我們將網路的學習動態類比為二分圖上的滲流過程，建立一個正式的相變模型，預測在改變資料結構時，實驗中觀察到的湧現點轉變。總體而言，我們的實驗和理論架構朝著在神經網路中更佳定義、描述和預測湧現邁進一步。

##### **Enhanced Parking Perception by Multi-Task Fisheye Cross-view Transformers**
2408.12575v1 by Antonyo Musabini, Ivan Novikov, Sana Soula, Christel Leonet, Lihao Wang, Rachid Benmokhtar, Fabian Burger, Thomas Boulay, Xavier Perrotton

Current parking area perception algorithms primarily focus on detecting
vacant slots within a limited range, relying on error-prone homographic
projection for both labeling and inference. However, recent advancements in
Advanced Driver Assistance System (ADAS) require interaction with end-users
through comprehensive and intelligent Human-Machine Interfaces (HMIs). These
interfaces should present a complete perception of the parking area going from
distinguishing vacant slots' entry lines to the orientation of other parked
vehicles. This paper introduces Multi-Task Fisheye Cross View Transformers (MT
F-CVT), which leverages features from a four-camera fisheye Surround-view
Camera System (SVCS) with multihead attentions to create a detailed Bird-Eye
View (BEV) grid feature map. Features are processed by both a segmentation
decoder and a Polygon-Yolo based object detection decoder for parking slots and
vehicles. Trained on data labeled using LiDAR, MT F-CVT positions objects
within a 25m x 25m real open-road scenes with an average error of only 20 cm.
Our larger model achieves an F-1 score of 0.89. Moreover the smaller model
operates at 16 fps on an Nvidia Jetson Orin embedded board, with similar
detection results to the larger one. MT F-CVT demonstrates robust
generalization capability across different vehicles and camera rig
configurations. A demo video from an unseen vehicle and camera rig is available
at: https://streamable.com/jjw54x.

摘要：目前停車場感知演算法主要專注於偵測有限範圍內的空位，依賴容易出錯的同形投影進行標記和推論。然而，進階駕駛輔助系統 (ADAS) 的最新進展需要透過全面且智慧的人機介面 (HMI) 與使用者互動。這些介面應該呈現停車場的完整感知，從辨別空位的入口線到其他停車車輛的方向。本文介紹多任務魚眼交叉視角Transformer (MT F-CVT)，它利用來自四鏡頭魚眼環景攝影系統 (SVCS) 的特徵和多頭注意力來建立詳細的鳥瞰視角 (BEV) 格線特徵圖。特徵由分割解碼器和基於 Polygon-Yolo 的物件偵測解碼器處理，用於停車位和車輛。在使用 LiDAR 標記的資料上進行訓練，MT F-CVT 將物件定位在 25 公尺 x 25 公尺的真實露天場景中，平均誤差僅 20 公分。我們的較大模型達到 F-1 分數 0.89。此外，較小的模型在 Nvidia Jetson Orin 嵌入式電路板上以 16 fps 運作，偵測結果與較大的模型類似。MT F-CVT 展示了在不同車輛和相機裝置組態中強大的泛化能力。來自未見車輛和相機裝置組態的示範影片可於此處取得：https://streamable.com/jjw54x。

##### **MuMA-ToM: Multi-modal Multi-Agent Theory of Mind**
2408.12574v1 by Haojun Shi, Suyu Ye, Xinyu Fang, Chuanyang Jin, Layla Isik, Yen-Ling Kuo, Tianmin Shu

Understanding people's social interactions in complex real-world scenarios
often relies on intricate mental reasoning. To truly understand how and why
people interact with one another, we must infer the underlying mental states
that give rise to the social interactions, i.e., Theory of Mind reasoning in
multi-agent interactions. Additionally, social interactions are often
multi-modal -- we can watch people's actions, hear their conversations, and/or
read about their past behaviors. For AI systems to successfully and safely
interact with people in real-world environments, they also need to understand
people's mental states as well as their inferences about each other's mental
states based on multi-modal information about their interactions. For this, we
introduce MuMA-ToM, a Multi-modal Multi-Agent Theory of Mind benchmark.
MuMA-ToM is the first multi-modal Theory of Mind benchmark that evaluates
mental reasoning in embodied multi-agent interactions. In MuMA-ToM, we provide
video and text descriptions of people's multi-modal behavior in realistic
household environments. Based on the context, we then ask questions about
people's goals, beliefs, and beliefs about others' goals. We validated MuMA-ToM
in a human experiment and provided a human baseline. We also proposed a novel
multi-modal, multi-agent ToM model, LIMP (Language model-based Inverse
Multi-agent Planning). Our experimental results show that LIMP significantly
outperforms state-of-the-art methods, including large multi-modal models (e.g.,
GPT-4o, Gemini-1.5 Pro) and a recent multi-modal ToM model, BIP-ALM.

摘要：理解人們在複雜的現實世界場景中的社交互動通常依賴於複雜的心智推理。為了真正了解人們如何以及為何彼此互動，我們必須推論出導致社交互動的底層心智狀態，即多主體互動中的心智理論推理。此外，社交互動通常是多模態的——我們可以觀察人們的行為、傾聽他們的對話和/或閱讀他們過去的行為。為了讓人工智慧系統在現實世界環境中成功且安全地與人互動，他們還需要了解人們的心智狀態，以及他們根據關於互動的多模態資訊對彼此心智狀態的推論。為此，我們引入了 MuMA-ToM，一個多模態多主體心智理論基準。MuMA-ToM 是第一個多模態心智理論基準，它評估了具體化多主體互動中的心智推理。在 MuMA-ToM 中，我們提供了人們在現實家庭環境中的多模態行為的影片和文字描述。然後，根據背景，我們詢問有關人們的目標、信念和對他人目標的信念的問題。我們在人類實驗中驗證了 MuMA-ToM 並提供了人類基準。我們還提出了一種新穎的多模態、多主體心智理論模型 LIMP（基於語言模型的反向多主體規劃）。我們的實驗結果表明，LIMP 明顯優於最先進的方法，包括大型多模態模型（例如 GPT-4o、Gemini-1.5 Pro）和最近的多模態心智理論模型 BIP-ALM。

##### **Jamba-1.5: Hybrid Transformer-Mamba Models at Scale**
2408.12570v1 by Jamba Team, Barak Lenz, Alan Arazi, Amir Bergman, Avshalom Manevich, Barak Peleg, Ben Aviram, Chen Almagor, Clara Fridman, Dan Padnos, Daniel Gissin, Daniel Jannai, Dor Muhlgay, Dor Zimberg, Edden M Gerber, Elad Dolev, Eran Krakovsky, Erez Safahi, Erez Schwartz, Gal Cohen, Gal Shachaf, Haim Rozenblum, Hofit Bata, Ido Blass, Inbal Magar, Itay Dalmedigos, Jhonathan Osin, Julie Fadlon, Maria Rozman, Matan Danos, Michael Gokhman, Mor Zusman, Naama Gidron, Nir Ratner, Noam Gat, Noam Rozen, Oded Fried, Ohad Leshno, Omer Antverg, Omri Abend, Opher Lieber, Or Dagan, Orit Cohavi, Raz Alon, Ro'i Belson, Roi Cohen, Rom Gilad, Roman Glozman, Shahar Lev, Shaked Meirom, Tal Delbari, Tal Ness, Tomer Asida, Tom Ben Gal, Tom Braude, Uriya Pumerantz, Yehoshua Cohen, Yonatan Belinkov, Yuval Globerson, Yuval Peleg Levy, Yoav Shoham

We present Jamba-1.5, new instruction-tuned large language models based on
our Jamba architecture. Jamba is a hybrid Transformer-Mamba mixture of experts
architecture, providing high throughput and low memory usage across context
lengths, while retaining the same or better quality as Transformer models. We
release two model sizes: Jamba-1.5-Large, with 94B active parameters, and
Jamba-1.5-Mini, with 12B active parameters. Both models are fine-tuned for a
variety of conversational and instruction-following capabilties, and have an
effective context length of 256K tokens, the largest amongst open-weight
models. To support cost-effective inference, we introduce ExpertsInt8, a novel
quantization technique that allows fitting Jamba-1.5-Large on a machine with 8
80GB GPUs when processing 256K-token contexts without loss of quality. When
evaluated on a battery of academic and chatbot benchmarks, Jamba-1.5 models
achieve excellent results while providing high throughput and outperforming
other open-weight models on long-context benchmarks. The model weights for both
sizes are publicly available under the Jamba Open Model License and we release
ExpertsInt8 as open source.

摘要：我們提出 Jamba-1.5，這是基於我們 Jamba 架構的新指令調校大型語言模型。Jamba 是 Transformer-Mamba 專家混合體混合架構，在各種內容長度中提供高吞吐量和低記憶體使用量，同時保有與 Transformer 模型相同或更好的品質。我們發布兩種模型大小：Jamba-1.5-Large，有 94B 活動參數，以及 Jamba-1.5-Mini，有 12B 活動參數。兩種模型都針對各種對話和指令遵循能力進行微調，並具有 256K 令牌的有效內容長度，是開放權重模型中最長的。為了支援具成本效益的推論，我們引入了 ExpertsInt8，這是一種新穎的量化技術，可在處理 256K 令牌內容時讓 Jamba-1.5-Large 符合搭載 8 個 80GB GPU 的機器，且不損失品質。在針對一組學術和聊天機器人基準進行評估時，Jamba-1.5 模型在提供高吞吐量的同時，在長內容基準上優於其他開放權重模型，並獲得優異的結果。兩種大小的模型權重在 Jamba 開放模型授權下公開提供，我們將 ExpertsInt8 作為開放原始碼發布。

##### **Pruning By Explaining Revisited: Optimizing Attribution Methods to Prune CNNs and Transformers**
2408.12568v1 by Sayed Mohammad Vakilzadeh Hatefi, Maximilian Dreyer, Reduan Achtibat, Thomas Wiegand, Wojciech Samek, Sebastian Lapuschkin

To solve ever more complex problems, Deep Neural Networks are scaled to
billions of parameters, leading to huge computational costs. An effective
approach to reduce computational requirements and increase efficiency is to
prune unnecessary components of these often over-parameterized networks.
Previous work has shown that attribution methods from the field of eXplainable
AI serve as effective means to extract and prune the least relevant network
components in a few-shot fashion. We extend the current state by proposing to
explicitly optimize hyperparameters of attribution methods for the task of
pruning, and further include transformer-based networks in our analysis. Our
approach yields higher model compression rates of large transformer- and
convolutional architectures (VGG, ResNet, ViT) compared to previous works,
while still attaining high performance on ImageNet classification tasks. Here,
our experiments indicate that transformers have a higher degree of
over-parameterization compared to convolutional neural networks. Code is
available at
$\href{https://github.com/erfanhatefi/Pruning-by-eXplaining-in-PyTorch}{\text{this
https link}}$.

摘要：為了解決越來越複雜的問題，深度神經網路被擴展到數十億個參數，導致巨大的計算成本。減少計算需求和提高效率的有效方法是修剪這些經常過度參數化的網路中不必要的組成部分。先前的研究表明，來自可解釋 AI 領域的歸因方法可用作以少量樣本方式提取和修剪最不相關網路組成部分的有效方法。我們透過提出針對修剪任務明確最佳化歸因方法的超參數來擴展目前的狀態，並進一步在我們的分析中納入基於轉換器的網路。與先前的研究相比，我們的方法產生了較高的模型壓縮率，包括大型轉換器和卷積架構（VGG、ResNet、ViT），同時在 ImageNet 分類任務中仍能獲得高性能。在此，我們的實驗表明，與卷積神經網路相比，轉換器具有較高的過度參數化程度。程式碼可在
$\href{https://github.com/erfanhatefi/Pruning-by-eXplaining-in-PyTorch}{\text{此 https 連結}}$ 取得。

##### **ssProp: Energy-Efficient Training for Convolutional Neural Networks with Scheduled Sparse Back Propagation**
2408.12561v1 by Lujia Zhong, Shuo Huang, Yonggang Shi

Recently, deep learning has made remarkable strides, especially with
generative modeling, such as large language models and probabilistic diffusion
models. However, training these models often involves significant computational
resources, requiring billions of petaFLOPs. This high resource consumption
results in substantial energy usage and a large carbon footprint, raising
critical environmental concerns. Back-propagation (BP) is a major source of
computational expense during training deep learning models. To advance research
on energy-efficient training and allow for sparse learning on any machine and
device, we propose a general, energy-efficient convolution module that can be
seamlessly integrated into any deep learning architecture. Specifically, we
introduce channel-wise sparsity with additional gradient selection schedulers
during backward based on the assumption that BP is often dense and inefficient,
which can lead to over-fitting and high computational consumption. Our
experiments demonstrate that our approach reduces 40\% computations while
potentially improving model performance, validated on image classification and
generation tasks. This reduction can lead to significant energy savings and a
lower carbon footprint during the research and development phases of
large-scale AI systems. Additionally, our method mitigates over-fitting in a
manner distinct from Dropout, allowing it to be combined with Dropout to
further enhance model performance and reduce computational resource usage.
Extensive experiments validate that our method generalizes to a variety of
datasets and tasks and is compatible with a wide range of deep learning
architectures and modules. Code is publicly available at
https://github.com/lujiazho/ssProp.

摘要：<paragraph>最近，深度学习取得了显著进展，特别是在生成模型方面，例如大型语言模型和概率扩散模型。然而，训练这些模型通常需要大量的计算资源，需要数十亿 petaFLOP。这种高资源消耗导致大量的能源消耗和巨大的碳足迹，引发了重大的环境问题。反向传播 (BP) 是在训练深度学习模型期间计算开销的主要来源。为了推进对节能训练的研究，并允许在任何机器和设备上进行稀疏学习，我们提出了一种通用的、节能的卷积模块，可以无缝集成到任何深度学习架构中。具体来说，我们引入了通道级稀疏性，并在反向传播过程中使用附加的梯度选择调度器，基于 BP 通常密集且低效的假设，这可能导致过度拟合和高计算消耗。我们的实验表明，我们的方法减少了 40% 的计算，同时有可能提高模型性能，在图像分类和生成任务上得到验证。这种减少可以在大规模人工智能系统的研究和开发阶段带来显著的节能和更低的碳足迹。此外，我们的方法以不同于 Dropout 的方式减轻过度拟合，允许它与 Dropout 相结合，以进一步提高模型性能并减少计算资源使用。大量的实验验证了我们的方法可以推广到各种数据集和任务，并且与广泛的深度学习架构和模块兼容。代码已公开发布在 https://github.com/lujiazho/ssProp。</paragraph>

##### **Data Quality Antipatterns for Software Analytics**
2408.12560v1 by Aaditya Bhatia, Dayi Lin, Gopi Krishnan Rajbahadur, Bram Adams, Ahmed E. Hassan

Background: Data quality is vital in software analytics, particularly for
machine learning (ML) applications like software defect prediction (SDP).
Despite the widespread use of ML in software engineering, the effect of data
quality antipatterns on these models remains underexplored.
  Objective: This study develops a taxonomy of ML-specific data quality
antipatterns and assesses their impact on software analytics models'
performance and interpretation.
  Methods: We identified eight types and 14 sub-types of ML-specific data
quality antipatterns through a literature review. We conducted experiments to
determine the prevalence of these antipatterns in SDP data (RQ1), assess how
cleaning order affects model performance (RQ2), evaluate the impact of
antipattern removal on performance (RQ3), and examine the consistency of
interpretation from models built with different antipatterns (RQ4).
  Results: In our SDP case study, we identified nine antipatterns. Over 90% of
these overlapped at both row and column levels, complicating cleaning
prioritization and risking excessive data removal. The order of cleaning
significantly impacts ML model performance, with neural networks being more
resilient to cleaning order changes than simpler models like logistic
regression. Antipatterns such as Tailed Distributions and Class Overlap show a
statistically significant correlation with performance metrics when other
antipatterns are cleaned. Models built with different antipatterns showed
moderate consistency in interpretation results.
  Conclusion: The cleaning order of different antipatterns impacts ML model
performance. Five antipatterns have a statistically significant correlation
with model performance when others are cleaned. Additionally, model
interpretation is moderately affected by different data quality antipatterns.

摘要：<paragraph>背景：資料品質對於軟體分析至關重要，特別是對於軟體缺陷預測 (SDP) 等機器學習 (ML) 應用程式。儘管機器學習在軟體工程中廣泛使用，但資料品質反模式對這些模型的影響仍未得到充分探討。
目標：本研究建立了一個 ML 特定資料品質反模式的分類法，並評估它們對軟體分析模型效能和詮釋的影響。
方法：我們透過文獻回顧找出八種類型和 14 種子類型的 ML 特定資料品質反模式。我們進行實驗以確定這些反模式在 SDP 資料中的盛行率 (RQ1)，評估清理順序如何影響模型效能 (RQ2)，評估移除反模式對效能的影響 (RQ3)，並檢查使用不同反模式建構的模型的詮釋一致性 (RQ4)。
結果：在我們的 SDP 案例研究中，我們找出九個反模式。其中超過 90% 在列和欄位層面重疊，使清理優先順序複雜化，並有過度移除資料的風險。清理順序會顯著影響 ML 模型效能，神經網路比邏輯迴歸等較簡單的模型更能適應清理順序的變更。當其他反模式被清理時，尾部分布和類別重疊等反模式顯示出與效能指標有統計上的顯著相關性。使用不同反模式建構的模型在詮釋結果方面顯示出中等的相容性。
結論：不同反模式的清理順序會影響 ML 模型效能。當其他反模式被清理時，有五個反模式與模型效能有統計上的顯著相關性。此外，模型詮釋會受到不同的資料品質反模式的中等影響。</paragraph>

##### **Modeling Time-Variant Responses of Optical Compressors with Selective State Space Models**
2408.12549v1 by Riccardo Simionato

This paper presents a method for modeling optical dynamic range compressors
using deep neural networks with Selective State Space models. The proposed
approach surpasses previous methods based on recurrent layers by employing a
Selective State Space block to encode the input audio. It features a refined
technique integrating Feature-wise Linear Modulation and Gated Linear Units to
adjust the network dynamically, conditioning the compression's attack and
release phases according to external parameters. The proposed architecture is
well-suited for low-latency and real-time applications, crucial in live audio
processing. The method has been validated on the analog optical compressors
TubeTech CL 1B and Teletronix LA-2A, which possess distinct characteristics.
Evaluation is performed using quantitative metrics and subjective listening
tests, comparing the proposed method with other state-of-the-art models.
Results show that our black-box modeling methods outperform all others,
achieving accurate emulation of the compression process for both seen and
unseen settings during training. We further show a correlation between this
accuracy and the sampling density of the control parameters in the dataset and
identify settings with fast attack and slow release as the most challenging to
emulate.

摘要：本文提出一种使用具有选择性状态空间模型的深度神经网络对光学动态范围压缩器进行建模的方法。所提出的方法通过采用选择性状态空间块对输入音频进行编码，超越了以前基于循环层的模型。它采用了一种精细的技术，集成了逐特征线性调制和门控线性单元，以动态调整网络，根据外部参数调节压缩的攻击和释放阶段。所提出的架构非常适合低延迟和实时应用，这在现场音频处理中至关重要。该方法已在模拟光学压缩器 TubeTech CL 1B 和 Teletronix LA-2A 上得到验证，它们具有不同的特性。使用定量指标和主观听力测试进行评估，将所提出的方法与其他最先进的模型进行比较。结果表明，我们的黑盒建模方法优于其他所有方法，在训练期间对压缩过程的可见和不可见设置实现了准确的仿真。我们进一步展示了这种准确性与数据集中控制参数的采样密度之间的相关性，并确定具有快速攻击和慢释放的设置是最难模拟的。

##### **Towards Evaluating and Building Versatile Large Language Models for Medicine**
2408.12547v1 by Chaoyi Wu, Pengcheng Qiu, Jinxin Liu, Hongfei Gu, Na Li, Ya Zhang, Yanfeng Wang, Weidi Xie

In this study, we present MedS-Bench, a comprehensive benchmark designed to
evaluate the performance of large language models (LLMs) in clinical contexts.
Unlike existing benchmarks that focus on multiple-choice question answering,
MedS-Bench spans 11 high-level clinical tasks, including clinical report
summarization, treatment recommendations, diagnosis, named entity recognition,
and medical concept explanation, among others. We evaluated six leading LLMs,
e.g., MEDITRON, Mistral, InternLM 2, Llama 3, GPT-4, and Claude-3.5 using
few-shot prompting, and found that even the most sophisticated models struggle
with these complex tasks. To address these limitations, we developed MedS-Ins,
a large-scale instruction tuning dataset for medicine. MedS-Ins comprises 58
medically oriented language corpora, totaling 13.5 million samples across 122
tasks. To demonstrate the dataset's utility, we conducted a proof-of-concept
experiment by performing instruction tuning on a lightweight, open-source
medical language model. The resulting model, MMedIns-Llama 3, significantly
outperformed existing models across nearly all clinical tasks. To promote
further advancements in the application of LLMs to clinical challenges, we have
made the MedS-Ins dataset fully accessible and invite the research community to
contribute to its expansion.Additionally, we have launched a dynamic
leaderboard for MedS-Bench, which we plan to regularly update the test set to
track progress and enhance the adaptation of general LLMs to the medical
domain. Leaderboard: https://henrychur.github.io/MedS-Bench/. Github:
https://github.com/MAGIC-AI4Med/MedS-Ins.

摘要：<paragraph>本研究中，我们提出 MedS-Bench，这是一个旨在评估大型语言模型 (LLM) 在临床环境中的性能的综合基准。
与专注于多项选择问答的现有基准不同，MedS-Bench 涵盖 11 项高级临床任务，包括临床报告摘要、治疗建议、诊断、命名实体识别和医学概念解释等。我们使用少样本提示评估了六个领先的 LLM，例如 MEDITRON、Mistral、InternLM 2、Llama 3、GPT-4 和 Claude-3.5，发现即使是最复杂的模型在这些复杂的任务中也难以应对。为了解决这些限制，我们开发了 MedS-Ins，这是一个用于医学的大规模指令微调数据集。MedS-Ins 包含 58 个医学语言语料库，总计 122 个任务中的 1350 万个样本。为了展示数据集的效用，我们通过对轻量级开源医学语言模型执行指令微调来进行概念验证实验。由此产生的模型 MMedIns-Llama 3 在几乎所有临床任务中都明显优于现有模型。为了促进 LLM 在临床挑战中的应用的进一步发展，我们已经让 MedS-Ins 数据集完全可以访问，并邀请研究界为其扩展做出贡献。此外，我们已经为 MedS-Bench 推出了一个动态排行榜，我们计划定期更新测试集以跟踪进度并增强通用 LLM 对医学领域的适应性。排行榜：https://henrychur.github.io/MedS-Bench/。Github：https://github.com/MAGIC-AI4Med/MedS-Ins。</paragraph>

##### **PCGRL+: Scaling, Control and Generalization in Reinforcement Learning Level Generators**
2408.12525v1 by Sam Earle, Zehua Jiang, Julian Togelius

Procedural Content Generation via Reinforcement Learning (PCGRL) has been
introduced as a means by which controllable designer agents can be trained
based only on a set of computable metrics acting as a proxy for the level's
quality and key characteristics. While PCGRL offers a unique set of affordances
for game designers, it is constrained by the compute-intensive process of
training RL agents, and has so far been limited to generating relatively small
levels. To address this issue of scale, we implement several PCGRL environments
in Jax so that all aspects of learning and simulation happen in parallel on the
GPU, resulting in faster environment simulation; removing the CPU-GPU transfer
of information bottleneck during RL training; and ultimately resulting in
significantly improved training speed. We replicate several key results from
prior works in this new framework, letting models train for much longer than
previously studied, and evaluating their behavior after 1 billion timesteps.
Aiming for greater control for human designers, we introduce randomized level
sizes and frozen "pinpoints" of pivotal game tiles as further ways of
countering overfitting. To test the generalization ability of learned
generators, we evaluate models on large, out-of-distribution map sizes, and
find that partial observation sizes learn more robust design strategies.

摘要：程序化内容生成通过强化学习（PCGRL）已被引入，作为一种手段，可根据一组可计算的指标（作为关卡质量和关键特征的代理）来训练可控的设计师代理。虽然 PCGRL 为游戏设计师提供了一组独特的便利性，但它受到训练 RL 代理的计算密集型过程的限制，并且到目前为止仅限于生成相对较小的关卡。为了解决这个问题，我们在 Jax 中实现了几个 PCGRL 环境，以便学习和模拟的所有方面都在 GPU 上并行发生，从而实现更快的环境模拟；在 RL 训练期间消除 CPU-GPU 信息瓶颈传输；并最终显着提高训练速度。我们在这一新框架中复制了先前工作的一些关键结果，让模型训练的时间比以前的研究长得多，并在 10 亿个时间步之后评估了它们的行为。为了让人类设计师获得更大的控制权，我们引入了随机关卡大小和关键游戏图块的冻结“关键点”，作为对抗过拟合的进一步方法。为了测试学习生成器的泛化能力，我们在大型、分布外的地图大小上评估模型，并发现部分观察大小学习了更稳健的设计策略。

##### **Advanced atom-level representations for protein flexibility prediction utilizing graph neural networks**
2408.12519v1 by Sina Sarparast, Aldo Zaimi, Maximilian Ebert, Michael-Rock Goldsmith

Protein dynamics play a crucial role in many biological processes and drug
interactions. However, measuring, and simulating protein dynamics is
challenging and time-consuming. While machine learning holds promise in
deciphering the determinants of protein dynamics from structural information,
most existing methods for protein representation learning operate at the
residue level, ignoring the finer details of atomic interactions. In this work,
we propose for the first time to use graph neural networks (GNNs) to learn
protein representations at the atomic level and predict B-factors from protein
3D structures. The B-factor reflects the atomic displacement of atoms in
proteins, and can serve as a surrogate for protein flexibility. We compared
different GNN architectures to assess their performance. The Meta-GNN model
achieves a correlation coefficient of 0.71 on a large and diverse test set of
over 4k proteins (17M atoms) from the Protein Data Bank (PDB), outperforming
previous methods by a large margin. Our work demonstrates the potential of
representations learned by GNNs for protein flexibility prediction and other
related tasks.

摘要：蛋白質動力學在許多生物過程和藥物相互作用中扮演著關鍵角色。然而，測量和模擬蛋白質動力學具有挑戰性且耗時。儘管機器學習有望從結構資訊中解碼蛋白質動力學的決定因素，但現有的蛋白質表示學習方法大多在殘基層級運作，忽略了原子交互作用的更精細細節。在這項工作中，我們首次提出使用圖神經網路 (GNN) 來學習原子層級的蛋白質表示，並從蛋白質 3D 結構預測 B 因子。B 因子反映了蛋白質中原子的原子位移，可用作蛋白質柔性的替代指標。我們比較了不同的 GNN 架構以評估其效能。Meta-GNN 模型在來自蛋白質資料庫 (PDB) 的 4k 以上蛋白質（17M 原子）的大型且多樣化的測試集中達到了 0.71 的相關係數，大幅優於先前的模型。我們的研究展示了 GNN 所學習的表示在蛋白質柔性預測和其他相關任務中的潛力。

##### **The Russian-focused embedders' exploration: ruMTEB benchmark and Russian embedding model design**
2408.12503v1 by Artem Snegirev, Maria Tikhonova, Anna Maksimova, Alena Fenogenova, Alexander Abramov

Embedding models play a crucial role in Natural Language Processing (NLP) by
creating text embeddings used in various tasks such as information retrieval
and assessing semantic text similarity. This paper focuses on research related
to embedding models in the Russian language. It introduces a new
Russian-focused embedding model called ru-en-RoSBERTa and the ruMTEB benchmark,
the Russian version extending the Massive Text Embedding Benchmark (MTEB). Our
benchmark includes seven categories of tasks, such as semantic textual
similarity, text classification, reranking, and retrieval. The research also
assesses a representative set of Russian and multilingual models on the
proposed benchmark. The findings indicate that the new model achieves results
that are on par with state-of-the-art models in Russian. We release the model
ru-en-RoSBERTa, and the ruMTEB framework comes with open-source code,
integration into the original framework and a public leaderboard.

摘要：嵌入模型在自然語言處理 (NLP) 中扮演著至關重要的角色，透過建立用於各種任務（例如資訊檢索和評估語意文本相似性）的文本嵌入。本文重點在於與俄語嵌入模型相關的研究。它引入了新的俄語嵌入模型，稱為 ru-en-RoSBERTa，以及 ruMTEB 基準，這是擴展大型文本嵌入基準 (MTEB) 的俄語版本。我們的基準包含七類任務，例如語意文本相似性、文本分類、重新排名和檢索。該研究還根據建議的基準評估了一組代表性的俄語和多語言模型。研究結果表明，新模型達到了與俄語中最新模型相當的結果。我們發布了模型 ru-en-RoSBERTa，而 ruMTEB 框架附帶開源程式碼、整合到原始框架中，並提供公開排行榜。

##### **MEDCO: Medical Education Copilots Based on A Multi-Agent Framework**
2408.12496v1 by Hao Wei, Jianing Qiu, Haibao Yu, Wu Yuan

Large language models (LLMs) have had a significant impact on diverse
research domains, including medicine and healthcare. However, the potential of
LLMs as copilots in medical education remains underexplored. Current
AI-assisted educational tools are limited by their solitary learning approach
and inability to simulate the multi-disciplinary and interactive nature of
actual medical training. To address these limitations, we propose MEDCO
(Medical EDucation COpilots), a novel multi-agent-based copilot system
specially developed to emulate real-world medical training environments. MEDCO
incorporates three primary agents: an agentic patient, an expert doctor, and a
radiologist, facilitating a multi-modal and interactive learning environment.
Our framework emphasizes the learning of proficient question-asking skills,
multi-disciplinary collaboration, and peer discussions between students. Our
experiments show that simulated virtual students who underwent training with
MEDCO not only achieved substantial performance enhancements comparable to
those of advanced models, but also demonstrated human-like learning behaviors
and improvements, coupled with an increase in the number of learning samples.
This work contributes to medical education by introducing a copilot that
implements an interactive and collaborative learning approach. It also provides
valuable insights into the effectiveness of AI-integrated training paradigms.

摘要：大型語言模型 (LLM) 對不同研究領域產生重大影響，包括醫學和保健。然而，LLM 作為醫學教育副手的潛力仍未被充分探討。目前的 AI 輔助教育工具受到其單獨學習方法的限制，且無法模擬實際醫學訓練的多學科和互動性質。為了解決這些限制，我們提出 MEDCO（醫學教育副手），一種新穎的多代理人協作系統，專門開發用於模擬真實世界的醫學訓練環境。MEDCO 結合了三個主要代理人：一個代理人患者、一個專家醫生和一個放射科醫生，促進多模式和互動學習環境。我們的架構強調學習熟練的提問技巧、跨學科協作和學生之間的同儕討論。我們的實驗表明，接受 MEDCO 訓練的模擬虛擬學生不僅獲得與進階模型相當的顯著效能提升，還表現出類似人類的學習行為和進步，並伴隨著學習樣本數量的增加。這項工作透過引入一個實施互動和協作學習方法的副手，對醫學教育有所貢獻。它也提供了對 AI 整合訓練模式有效性的寶貴見解。

##### **GenderCARE: A Comprehensive Framework for Assessing and Reducing Gender Bias in Large Language Models**
2408.12494v1 by Kunsheng Tang, Wenbo Zhou, Jie Zhang, Aishan Liu, Gelei Deng, Shuai Li, Peigui Qi, Weiming Zhang, Tianwei Zhang, Nenghai Yu

Large language models (LLMs) have exhibited remarkable capabilities in
natural language generation, but they have also been observed to magnify
societal biases, particularly those related to gender. In response to this
issue, several benchmarks have been proposed to assess gender bias in LLMs.
However, these benchmarks often lack practical flexibility or inadvertently
introduce biases. To address these shortcomings, we introduce GenderCARE, a
comprehensive framework that encompasses innovative Criteria, bias Assessment,
Reduction techniques, and Evaluation metrics for quantifying and mitigating
gender bias in LLMs. To begin, we establish pioneering criteria for gender
equality benchmarks, spanning dimensions such as inclusivity, diversity,
explainability, objectivity, robustness, and realisticity. Guided by these
criteria, we construct GenderPair, a novel pair-based benchmark designed to
assess gender bias in LLMs comprehensively. Our benchmark provides standardized
and realistic evaluations, including previously overlooked gender groups such
as transgender and non-binary individuals. Furthermore, we develop effective
debiasing techniques that incorporate counterfactual data augmentation and
specialized fine-tuning strategies to reduce gender bias in LLMs without
compromising their overall performance. Extensive experiments demonstrate a
significant reduction in various gender bias benchmarks, with reductions
peaking at over 90% and averaging above 35% across 17 different LLMs.
Importantly, these reductions come with minimal variability in mainstream
language tasks, remaining below 2%. By offering a realistic assessment and
tailored reduction of gender biases, we hope that our GenderCARE can represent
a significant step towards achieving fairness and equity in LLMs. More details
are available at https://github.com/kstanghere/GenderCARE-ccs24.

摘要：大型語言模型 (LLM) 在自然語言生成方面表現出非凡的能力，但它們也被觀察到會放大社會偏見，特別是與性別相關的偏見。為了回應這個問題，已經提出了幾個基準來評估 LLM 中的性別偏見。然而，這些基準通常缺乏實用的靈活性，或者會無意中引入偏見。為了解決這些缺點，我們引入了 GenderCARE，一個全面的框架，其中包含創新的標準、偏見評估、減少技術和評估指標，用於量化和減輕 LLM 中的性別偏見。首先，我們為性別平等基準制定了開創性的標準，涵蓋包容性、多樣性、可解釋性、客觀性、穩健性和現實性等面向。在這些標準的指導下，我們構建了 GenderPair，一個新穎的基於配對的基準，旨在全面評估 LLM 中的性別偏見。我們的基準提供了標準化和現實的評估，包括以前被忽視的性別群體，例如跨性別者和非二元性別者。此外，我們開發了有效的去偏技術，結合了反事實數據擴充和專門的微調策略，以減少 LLM 中的性別偏見，同時不損害其整體性能。大量的實驗證明了各種性別偏見基準的顯著減少，減少幅度最高超過 90%，在 17 個不同的 LLM 中平均降低了 35% 以上。重要的是，這些減少伴隨著主流語言任務的最小變異性，保持在 2% 以下。通過提供對性別偏見的現實評估和量身定制的減少，我們希望我們的 GenderCARE 能代表著邁向在 LLM 中實現公平和正義的重要一步。更多詳情可在 https://github.com/kstanghere/GenderCARE-ccs24 找到。

##### **Vintern-1B: An Efficient Multimodal Large Language Model for Vietnamese**
2408.12480v1 by Khang T. Doan, Bao G. Huynh, Dung T. Hoang, Thuc D. Pham, Nhat H. Pham, Quan T. M. Nguyen, Bang Q. Vo, Suong N. Hoang

In this report, we introduce Vintern-1B, a reliable 1-billion-parameters
multimodal large language model (MLLM) for Vietnamese language tasks. By
integrating the Qwen2-0.5B-Instruct language model with the
InternViT-300M-448px visual model, Vintern-1B is optimized for a range of
applications, including optical character recognition (OCR), document
extraction, and general question-answering in Vietnamese context. The model is
fine-tuned on an extensive dataset of over 3 million image-question-answer
pairs, achieving robust performance and reliable results across multiple
Vietnamese language benchmarks like OpenViVQA and ViTextVQA. Vintern-1B is
small enough to fit into various on-device applications easily. Additionally,
we have open-sourced several Vietnamese vision question answering (VQA)
datasets for text and diagrams, created with Gemini 1.5 Flash. Our models are
available at: https://huggingface.co/5CD-AI/Vintern-1B-v2.

摘要：在本文中，我們介紹 Vintern-1B，一個可靠的 10 億參數多模態大型語言模型 (MLLM)，適用於越南語任務。透過將 Qwen2-0.5B-Instruct 語言模型與 InternViT-300M-448px 視覺模型整合，Vintern-1B 針對各種應用進行了最佳化，包括光學字元辨識 (OCR)、文件萃取，以及越南語脈絡中的一般問答。該模型以超過 300 萬個影像-問題-答案配對的廣泛資料集進行微調，在 OpenViVQA 和 ViTextVQA 等多個越南語語言基準測試中達到穩健的效能和可靠的結果。Vintern-1B 夠小，可以輕鬆地融入各種裝置應用程式中。此外，我們還開放了幾個使用 Gemini 1.5 Flash 建立的越南語視覺問答 (VQA) 資料集，包括文字和圖表。我們的模型可在以下網址取得：https://huggingface.co/5CD-AI/Vintern-1B-v2。

##### **Predicting Solar Energy Generation with Machine Learning based on AQI and Weather Features**
2408.12476v1 by Arjun Shah, Varun Viswanath, Kashish Gandhi, Dr. Nilesh Madhukar Patil

This paper addresses the pressing need for an accurate solar energy
prediction model, which is crucial for efficient grid integration. We explore
the influence of the Air Quality Index and weather features on solar energy
generation, employing advanced Machine Learning and Deep Learning techniques.
Our methodology uses time series modeling and makes novel use of power
transform normalization and zero-inflated modeling. Various Machine Learning
algorithms and Conv2D Long Short-Term Memory model based Deep Learning models
are applied to these transformations for precise predictions. Results
underscore the effectiveness of our approach, demonstrating enhanced prediction
accuracy with Air Quality Index and weather features. We achieved a 0.9691
$R^2$ Score, 0.18 MAE, 0.10 RMSE with Conv2D Long Short-Term Memory model,
showcasing the power transform technique's innovation in enhancing time series
forecasting for solar energy generation. Such results help our research
contribute valuable insights to the synergy between Air Quality Index, weather
features, and Deep Learning techniques for solar energy prediction.

摘要：本文探討了對準確太陽能預測模型的迫切需求，這對於有效的電網整合至關重要。我們探討了空氣品質指數和天氣特徵對太陽能發電的影響，並採用先進的機器學習和深度學習技術。我們的技術使用時間序列建模，並創新地使用功率轉換正規化和零膨脹建模。各種機器學習演算法和基於 Conv2D 長短期記憶體模型的深度學習模型被應用於這些轉換，以進行精確的預測。結果強調了我們方法的有效性，證明了使用空氣品質指數和天氣特徵增強了預測準確性。我們使用 Conv2D 長短期記憶體模型達到了 0.9691 的 $R^2$ 分數、0.18 的 MAE、0.10 的 RMSE，展示了功率轉換技術在增強太陽能發電時間序列預測方面的創新。這些結果有助於我們的研究為空氣品質指數、天氣特徵和深度學習技術之間的協同作用提供有價值的見解，以進行太陽能預測。

##### **WCEbleedGen: A wireless capsule endoscopy dataset and its benchmarking for automatic bleeding classification, detection, and segmentation**
2408.12466v1 by Palak Handa, Manas Dhir, Amirreza Mahbod, Florian Schwarzhans, Ramona Woitek, Nidhi Goel, Deepak Gunjan

Computer-based analysis of Wireless Capsule Endoscopy (WCE) is crucial.
However, a medically annotated WCE dataset for training and evaluation of
automatic classification, detection, and segmentation of bleeding and
non-bleeding frames is currently lacking. The present work focused on
development of a medically annotated WCE dataset called WCEbleedGen for
automatic classification, detection, and segmentation of bleeding and
non-bleeding frames. It comprises 2,618 WCE bleeding and non-bleeding frames
which were collected from various internet resources and existing WCE datasets.
A comprehensive benchmarking and evaluation of the developed dataset was done
using nine classification-based, three detection-based, and three
segmentation-based deep learning models. The dataset is of high-quality, is
class-balanced and contains single and multiple bleeding sites. Overall, our
standard benchmark results show that Visual Geometric Group (VGG) 19, You Only
Look Once version 8 nano (YOLOv8n), and Link network (Linknet) performed best
in automatic classification, detection, and segmentation-based evaluations,
respectively. Automatic bleeding diagnosis is crucial for WCE video
interpretations. This diverse dataset will aid in developing of real-time,
multi-task learning-based innovative solutions for automatic bleeding diagnosis
in WCE. The dataset and code are publicly available at
https://zenodo.org/records/10156571 and
https://github.com/misahub2023/Benchmarking-Codes-of-the-WCEBleedGen-dataset.

摘要：<paragraph>無線膠囊內視鏡 (WCE) 的電腦分析至關重要。
然而，目前缺乏一個醫學標註的 WCE 資料集，用於訓練和評估出血和非出血幀的自動分類、檢測和分割。本研究專注於開發一個名為 WCEbleedGen 的醫學標註 WCE 資料集，用於出血和非出血幀的自動分類、檢測和分割。它包含 2,618 個 WCE 出血和非出血幀，這些幀是從各種網路資源和現有的 WCE 資料集中收集的。使用九個基於分類、三個基於檢測和三個基於分割的深度學習模型對開發的資料集進行了全面的基準測試和評估。該資料集質量高、類別平衡且包含單個和多個出血部位。總體而言，我們的標準基準測試結果表明，Visual Geometric Group (VGG) 19、You Only Look Once 版本 8 nano (YOLOv8n) 和 Link 網路 (Linknet) 在自動分類、檢測和基於分割的評估中表現最佳，分別。自動出血診斷對於 WCE 視訊解讀至關重要。這個多樣化的資料集將有助於開發用於 WCE 中自動出血診斷的基於實時、多任務學習的創新解決方案。該資料集和程式碼可在 https://zenodo.org/records/10156571 和 https://github.com/misahub2023/Benchmarking-Codes-of-the-WCEBleedGen-dataset 公開獲得。</paragraph>

##### **Enhancing Multi-hop Reasoning through Knowledge Erasure in Large Language Model Editing**
2408.12456v1 by Mengqi Zhang, Bowen Fang, Qiang Liu, Pengjie Ren, Shu Wu, Zhumin Chen, Liang Wang

Large language models (LLMs) face challenges with internal knowledge
inaccuracies and outdated information. Knowledge editing has emerged as a
pivotal approach to mitigate these issues. Although current knowledge editing
techniques exhibit promising performance in single-hop reasoning tasks, they
show limitations when applied to multi-hop reasoning. Drawing on cognitive
neuroscience and the operational mechanisms of LLMs, we hypothesize that the
residual single-hop knowledge after editing causes edited models to revert to
their original answers when processing multi-hop questions, thereby undermining
their performance in multihop reasoning tasks. To validate this hypothesis, we
conduct a series of experiments that empirically confirm our assumptions.
Building on the validated hypothesis, we propose a novel knowledge editing
method that incorporates a Knowledge Erasure mechanism for Large language model
Editing (KELE). Specifically, we design an erasure function for residual
knowledge and an injection function for new knowledge. Through joint
optimization, we derive the optimal recall vector, which is subsequently
utilized within a rank-one editing framework to update the parameters of
targeted model layers. Extensive experiments on GPT-J and GPT-2 XL demonstrate
that KELE substantially enhances the multi-hop reasoning capability of edited
LLMs.

摘要：大型語言模型 (LLM) 面臨著內部知識不準確和資訊過時的問題。知識編輯已成為緩解這些問題的關鍵方法。儘管目前的知識編輯技術在單跳推理任務中表現出良好的效能，但在應用於多跳推理時卻顯示出局限性。根據認知神經科學和 LLM 的運作機制，我們假設編輯後的殘餘單跳知識會導致編輯後的模型在處理多跳問題時恢復到它們的原始答案，從而損害它們在多跳推理任務中的效能。為了驗證這個假設，我們進行了一系列實驗，實證地確認了我們的假設。建立在經過驗證的假設之上，我們提出了一種新的知識編輯方法，其中包含了大型語言模型編輯的知識刪除機制 (KELE)。具體來說，我們設計了一個用於殘餘知識的刪除函數和一個用於新知識的注入函數。透過聯合最佳化，我們推導出最佳召回向量，隨後在秩一編輯架構中使用它來更新目標模型層的參數。在 GPT-J 和 GPT-2 XL 上進行的廣泛實驗表明，KELE 大大增強了已編輯 LLM 的多跳推理能力。

##### **A Riemannian Approach for Spatiotemporal Analysis and Generation of 4D Tree-shaped Structures**
2408.12443v1 by Tahmina Khanam, Hamid Laga, Mohammed Bennamoun, Guanjin Wang, Ferdous Sohel, Farid Boussaid, Guan Wang, Anuj Srivastava

We propose the first comprehensive approach for modeling and analyzing the
spatiotemporal shape variability in tree-like 4D objects, i.e., 3D objects
whose shapes bend, stretch, and change in their branching structure over time
as they deform, grow, and interact with their environment. Our key contribution
is the representation of tree-like 3D shapes using Square Root Velocity
Function Trees (SRVFT). By solving the spatial registration in the SRVFT space,
which is equipped with an L2 metric, 4D tree-shaped structures become
time-parameterized trajectories in this space. This reduces the problem of
modeling and analyzing 4D tree-like shapes to that of modeling and analyzing
elastic trajectories in the SRVFT space, where elasticity refers to time
warping. In this paper, we propose a novel mathematical representation of the
shape space of such trajectories, a Riemannian metric on that space, and
computational tools for fast and accurate spatiotemporal registration and
geodesics computation between 4D tree-shaped structures. Leveraging these
building blocks, we develop a full framework for modelling the spatiotemporal
variability using statistical models and generating novel 4D tree-like
structures from a set of exemplars. We demonstrate and validate the proposed
framework using real 4D plant data.

摘要：<paragraph>我們提出第一個全面的方法，用於建模和分析樹狀 4D 物件的時空形狀變異，即 3D 物件，其形狀會隨著時間彎曲、伸展和改變其分支結構，因為它們會變形、生長並與其環境互動。我們的關鍵貢獻是使用平方根速度函數樹 (SRVFT) 來表示樹狀 3D 形狀。透過在 SRVFT 空間中求解空間配準，該空間配備有 L2 度量，4D 樹形結構成為此空間中的時間參數化軌跡。這將對 4D 樹狀形狀進行建模和分析的問題簡化為對 SRVFT 空間中彈性軌跡進行建模和分析的問題，其中彈性是指時間扭曲。在本文中，我們提出了這種軌跡形狀空間的新數學表示，該空間上的黎曼度量，以及用於在 4D 樹形結構之間進行快速且準確的時空配準和測地線計算的計算工具。利用這些構建模組，我們開發了一個完整的框架，用於使用統計模型對時空變異性進行建模，並從一組範例中生成新的 4D 樹狀結構。我們使用真實的 4D 植物資料展示並驗證所提出的框架。</paragraph>

##### **Positional Description for Numerical Normalization**
2408.12430v1 by Deepanshu Gupta, Javier Latorre

We present a Positional Description Scheme (PDS) tailored for digit
sequences, integrating placeholder value information for each digit. Given the
structural limitations of subword tokenization algorithms, language models
encounter critical Text Normalization (TN) challenges when handling numerical
tasks. Our schema addresses this challenge through straightforward
pre-processing, preserving the model architecture while significantly
simplifying number normalization, rendering the problem tractable. This
simplifies the task and facilitates more compact production-ready models
capable of learning from smaller datasets. Furthermore, our investigations
reveal that PDS enhances the arithmetic processing capabilities of language
models, resulting in a relative accuracy improvement of 23% to 51% on complex
arithmetic tasks. We demonstrate that PDS effectively mitigates fatal numerical
normalization errors in neural models, requiring only a modest amount of
training data without rule-based Finite State Transducers (FST). We demonstrate
that PDS is essential for both the Text-To-Speech and Speech Recognition text
processing, enabling effective TN under production constraints.

摘要：我們提出一個針對數字序列量身打造的位置描述方案 (PDS)，整合每個數字的佔位符值資訊。由於次字元化演算法的結構限制，語言模型在處理數字任務時會遇到重大的文字正規化 (TN) 挑戰。我們的架構透過直接的預處理來解決這個挑戰，保留模型架構，同時大幅簡化數字正規化，使問題變得容易處理。這簡化了任務，並促進更精簡的生產就緒模型，這些模型能夠從較小的資料集學習。此外，我們的調查顯示，PDS 增強了語言模型的算術處理能力，在複雜的算術任務上產生 23% 到 51% 的相對準確度提升。我們證明，PDS 有效地減輕了神經模型中致命的數字正規化錯誤，只需要少量訓練資料，而不需要基於規則的有限狀態轉換器 (FST)。我們證明，PDS 對於文字轉語音和語音辨識文字處理都至關重要，可以在生產限制下實現有效的 TN。

##### **Enhanced Infield Agriculture with Interpretable Machine Learning Approaches for Crop Classification**
2408.12426v1 by Sudi Murindanyi, Joyce Nakatumba-Nabende, Rahman Sanya, Rose Nakibuule, Andrew Katumba

The increasing popularity of Artificial Intelligence in recent years has led
to a surge in interest in image classification, especially in the agricultural
sector. With the help of Computer Vision, Machine Learning, and Deep Learning,
the sector has undergone a significant transformation, leading to the
development of new techniques for crop classification in the field. Despite the
extensive research on various image classification techniques, most have
limitations such as low accuracy, limited use of data, and a lack of reporting
model size and prediction. The most significant limitation of all is the need
for model explainability. This research evaluates four different approaches for
crop classification, namely traditional ML with handcrafted feature extraction
methods like SIFT, ORB, and Color Histogram; Custom Designed CNN and
established DL architecture like AlexNet; transfer learning on five models
pre-trained using ImageNet such as EfficientNetV2, ResNet152V2, Xception,
Inception-ResNetV2, MobileNetV3; and cutting-edge foundation models like YOLOv8
and DINOv2, a self-supervised Vision Transformer Model. All models performed
well, but Xception outperformed all of them in terms of generalization,
achieving 98% accuracy on the test data, with a model size of 80.03 MB and a
prediction time of 0.0633 seconds. A key aspect of this research was the
application of Explainable AI to provide the explainability of all the models.
This journal presents the explainability of Xception model with LIME, SHAP, and
GradCAM, ensuring transparency and trustworthiness in the models' predictions.
This study highlights the importance of selecting the right model according to
task-specific needs. It also underscores the important role of explainability
in deploying AI in agriculture, providing insightful information to help
enhance AI-driven crop management strategies.

摘要：<paragraph>近年來，人工智慧的普及率不斷提高，進而導致對影像分類的興趣激增，特別是在農業領域。在電腦視覺、機器學習與深度學習的幫助下，該領域已歷經重大轉型，進而開發出新的田間作物分類技術。儘管已對各種影像分類技術進行廣泛研究，但大多數技術都有其限制，例如準確度低、資料使用受限，以及缺乏報告模型大小與預測。最顯著的限制在於需要模型可解釋性。本研究評估了四種不同的作物分類方法，即採用手工特徵萃取方法（例如 SIFT、ORB 和色彩直方圖）的傳統機器學習；自訂設計的 CNN 和既定的深度學習架構（例如 AlexNet）；使用 ImageNet 預先訓練的五個模型（例如 EfficientNetV2、ResNet152V2、Xception、Inception-ResNetV2、MobileNetV3）進行遷移學習；以及尖端的基礎模型（例如 YOLOv8 和 DINOv2，一種自我監督的視覺Transformer模型）。所有模型的表現都很好，但 Xception 在泛化性方面優於所有模型，在測試資料上達到 98% 的準確度，模型大小為 80.03 MB，預測時間為 0.0633 秒。本研究的一個關鍵面向是應用可解釋 AI 來提供所有模型的可解釋性。本期刊使用 LIME、SHAP 和 GradCAM 呈現 Xception 模型的可解釋性，確保模型預測的透明度與可信度。本研究強調根據特定任務需求選擇正確模型的重要性。它也強調可解釋性在農業中部署 AI 時所扮演的重要角色，提供見解豐富的資訊來協助強化 AI 驅動的作物管理策略。</paragraph>

##### **Multi-Knowledge Fusion Network for Time Series Representation Learning**
2408.12423v1 by Sagar Srinivas Sakhinana, Shivam Gupta, Krishna Sai Sudhir Aripirala, Venkataramana Runkana

Forecasting the behaviour of complex dynamical systems such as interconnected
sensor networks characterized by high-dimensional multivariate time series(MTS)
is of paramount importance for making informed decisions and planning for the
future in a broad spectrum of applications. Graph forecasting networks(GFNs)
are well-suited for forecasting MTS data that exhibit spatio-temporal
dependencies. However, most prior works of GFN-based methods on MTS forecasting
rely on domain-expertise to model the nonlinear dynamics of the system, but
neglect the potential to leverage the inherent relational-structural
dependencies among time series variables underlying MTS data. On the other
hand, contemporary works attempt to infer the relational structure of the
complex dependencies between the variables and simultaneously learn the
nonlinear dynamics of the interconnected system but neglect the possibility of
incorporating domain-specific prior knowledge to improve forecast accuracy. To
this end, we propose a hybrid architecture that combines explicit prior
knowledge with implicit knowledge of the relational structure within the MTS
data. It jointly learns intra-series temporal dependencies and inter-series
spatial dependencies by encoding time-conditioned structural spatio-temporal
inductive biases to provide more accurate and reliable forecasts. It also
models the time-varying uncertainty of the multi-horizon forecasts to support
decision-making by providing estimates of prediction uncertainty. The proposed
architecture has shown promising results on multiple benchmark datasets and
outperforms state-of-the-art forecasting methods by a significant margin. We
report and discuss the ablation studies to validate our forecasting
architecture.

摘要：<paragraph>預測複雜動態系統（例如以高維多變量時間序列 (MTS) 為特徵的互連感測器網路）的行為對於在廣泛的應用中做出明智的決策和規劃未來至關重要。圖表預測網路 (GFN) 非常適合預測展現時空依賴性的 MTS 資料。然而，大多數基於 GFN 方法的 MTS 預測先前研究都依賴於領域專業知識來建模系統的非線性動態，但忽略了利用 MTS 資料中時間序列變數之間固有的關係結構依賴性的潛力。另一方面，當代研究試圖推斷變數之間複雜依賴性的關係結構，並同時學習互連系統的非線性動態，但忽略了納入特定領域的先驗知識以提高預測精確度的可能性。為此，我們提出了一種混合架構，將明確的先驗知識與 MTS 資料中關係結構的隱含知識結合在一起。它通過編碼時間條件結構時空歸納偏見來共同學習序列內時間依賴性和序列間空間依賴性，以提供更準確和可靠的預測。它還對多範圍預測的時間變異不確定性進行建模，以通過提供預測不確定性的估計來支援決策制定。所提出的架構已在多個基準資料集上顯示出有希望的結果，並且顯著優於最先進的預測方法。我們報告並討論了消融研究，以驗證我們的預測架構。</paragraph>

##### **4D Diffusion for Dynamic Protein Structure Prediction with Reference Guided Motion Alignment**
2408.12419v1 by Kaihui Cheng, Ce Liu, Qingkun Su, Jun Wang, Liwei Zhang, Yining Tang, Yao Yao, Siyu Zhu, Yuan Qi

Protein structure prediction is pivotal for understanding the
structure-function relationship of proteins, advancing biological research, and
facilitating pharmaceutical development and experimental design. While deep
learning methods and the expanded availability of experimental 3D protein
structures have accelerated structure prediction, the dynamic nature of protein
structures has received limited attention. This study introduces an innovative
4D diffusion model incorporating molecular dynamics (MD) simulation data to
learn dynamic protein structures. Our approach is distinguished by the
following components: (1) a unified diffusion model capable of generating
dynamic protein structures, including both the backbone and side chains,
utilizing atomic grouping and side-chain dihedral angle predictions; (2) a
reference network that enhances structural consistency by integrating the
latent embeddings of the initial 3D protein structures; and (3) a motion
alignment module aimed at improving temporal structural coherence across
multiple time steps. To our knowledge, this is the first diffusion-based model
aimed at predicting protein trajectories across multiple time steps
simultaneously. Validation on benchmark datasets demonstrates that our model
exhibits high accuracy in predicting dynamic 3D structures of proteins
containing up to 256 amino acids over 32 time steps, effectively capturing both
local flexibility in stable states and significant conformational changes.

摘要：蛋白质结构预测对于理解蛋白质的结构-功能关系、推进生物学研究、促进药物开发和实验设计至关重要。虽然深度学习方法和实验性 3D 蛋白质结构的广泛可用性加速了结构预测，但蛋白质结构的动态特性却受到的关注有限。本研究引入了一个创新的 4D 扩散模型，结合分子动力学 (MD) 模拟数据来学习动态蛋白质结构。我们的方法以以下组件为特色：(1) 一个统一的扩散模型，能够生成动态蛋白质结构，包括主链和侧链，利用原子分组和侧链二面角预测；(2) 一个参考网络，通过整合初始 3D 蛋白质结构的潜在嵌入来增强结构一致性；(3) 一个运动对齐模块，旨在改善跨多个时间步长的时态结构相干性。据我们所知，这是第一个基于扩散的模型，旨在同时预测多个时间步长的蛋白质轨迹。在基准数据集上的验证表明，我们的模型在预测包含长达 256 个氨基酸、跨越 32 个时间步长的蛋白质的动态 3D 结构方面表现出很高的准确性，有效地捕捉到了稳定状态下的局部柔性和显著的构象变化。

##### **CODE: Confident Ordinary Differential Editing**
2408.12418v1 by Bastien van Delft, Tommaso Martorella, Alexandre Alahi

Conditioning image generation facilitates seamless editing and the creation
of photorealistic images. However, conditioning on noisy or Out-of-Distribution
(OoD) images poses significant challenges, particularly in balancing fidelity
to the input and realism of the output. We introduce Confident Ordinary
Differential Editing (CODE), a novel approach for image synthesis that
effectively handles OoD guidance images. Utilizing a diffusion model as a
generative prior, CODE enhances images through score-based updates along the
probability-flow Ordinary Differential Equation (ODE) trajectory. This method
requires no task-specific training, no handcrafted modules, and no assumptions
regarding the corruptions affecting the conditioning image. Our method is
compatible with any diffusion model. Positioned at the intersection of
conditional image generation and blind image restoration, CODE operates in a
fully blind manner, relying solely on a pre-trained generative model. Our
method introduces an alternative approach to blind restoration: instead of
targeting a specific ground truth image based on assumptions about the
underlying corruption, CODE aims to increase the likelihood of the input image
while maintaining fidelity. This results in the most probable in-distribution
image around the input. Our contributions are twofold. First, CODE introduces a
novel editing method based on ODE, providing enhanced control, realism, and
fidelity compared to its SDE-based counterpart. Second, we introduce a
confidence interval-based clipping method, which improves CODE's effectiveness
by allowing it to disregard certain pixels or information, thus enhancing the
restoration process in a blind manner. Experimental results demonstrate CODE's
effectiveness over existing methods, particularly in scenarios involving severe
degradation or OoD inputs.

摘要：条件图像生成促进了无缝编辑和逼真图像的创建。然而，对噪声或分布外 (OoD) 图像进行条件化提出了重大挑战，尤其是在平衡输入的保真度和输出的真实性方面。我们介绍了置信普通微分编辑 (CODE)，这是一种用于图像合成的创新方法，可有效处理 OoD 引导图像。利用扩散模型作为生成先验，CODE 通过沿概率流常微分方程 (ODE) 轨迹进行基于分数的更新来增强图像。此方法不需要特定于任务的训练、手工制作的模块，也不需要关于影响条件图像的损坏的假设。我们的方法与任何扩散模型兼容。CODE 处于条件图像生成和盲图像恢复的交叉点，以完全盲目的方式运行，仅依赖于预训练的生成模型。我们的方法引入了一种盲恢复的替代方法：不基于对潜在损坏的假设来针对特定的真实图像，CODE 旨在提高输入图像的可能性，同时保持保真度。这导致了输入周围最可能的分布内图像。我们的贡献有两方面。首先，CODE 引入了一种基于 ODE 的新编辑方法，与基于 SDE 的对应方法相比，它提供了增强的控制、真实性和保真度。其次，我们引入了一种基于置信区间的剪辑方法，它通过允许 CODE 忽略某些像素或信息来提高其有效性，从而以盲目的方式增强恢复过程。实验结果证明了 CODE 对现有方法的有效性，尤其是在涉及严重退化或 OoD 输入的场景中。

##### **Dynamic PDB: A New Dataset and a SE(3) Model Extension by Integrating Dynamic Behaviors and Physical Properties in Protein Structures**
2408.12413v1 by Ce Liu, Jun Wang, Zhiqiang Cai, Yingxu Wang, Huizhen Kuang, Kaihui Cheng, Liwei Zhang, Qingkun Su, Yining Tang, Fenglei Cao, Limei Han, Siyu Zhu, Yuan Qi

Despite significant progress in static protein structure collection and
prediction, the dynamic behavior of proteins, one of their most vital
characteristics, has been largely overlooked in prior research. This oversight
can be attributed to the limited availability, diversity, and heterogeneity of
dynamic protein datasets. To address this gap, we propose to enhance existing
prestigious static 3D protein structural databases, such as the Protein Data
Bank (PDB), by integrating dynamic data and additional physical properties.
Specifically, we introduce a large-scale dataset, Dynamic PDB, encompassing
approximately 12.6K proteins, each subjected to all-atom molecular dynamics
(MD) simulations lasting 1 microsecond to capture conformational changes.
Furthermore, we provide a comprehensive suite of physical properties, including
atomic velocities and forces, potential and kinetic energies of proteins, and
the temperature of the simulation environment, recorded at 1 picosecond
intervals throughout the simulations. For benchmarking purposes, we evaluate
state-of-the-art methods on the proposed dataset for the task of trajectory
prediction. To demonstrate the value of integrating richer physical properties
in the study of protein dynamics and related model design, we base our approach
on the SE(3) diffusion model and incorporate these physical properties into the
trajectory prediction process. Preliminary results indicate that this
straightforward extension of the SE(3) model yields improved accuracy, as
measured by MAE and RMSD, when the proposed physical properties are taken into
consideration.

摘要：儘管靜態蛋白質結構收集與預測已取得顯著進展，但蛋白質的動態行為，作為其最重要的特徵之一，在先前的研究中已被廣泛忽視。這種疏忽可歸因於動態蛋白質資料集的可用性、多樣性和異質性有限。為了解決這個差距，我們提議透過整合動態資料和額外的物理特性來增強現有的著名靜態 3D 蛋白質結構資料庫，例如蛋白質資料庫 (PDB)。具體來說，我們引進了一個大型資料集 Dynamic PDB，包含大約 12.6K 個蛋白質，每個蛋白質都經過全原子分子動力學 (MD) 模擬，持續 1 微秒以捕捉構形變化。此外，我們提供了一套全面的物理特性，包括原子速度和力、蛋白質的勢能和動能，以及模擬環境的溫度，在整個模擬過程中以 1 皮秒的間隔記錄。為了基準測試的目的，我們在所提出的資料集上評估最先進的方法，以進行軌跡預測的任務。為了證明在蛋白質動力學和相關模型設計的研究中整合更豐富的物理特性的價值，我們將我們的做法建立在 SE(3) 擴散模型上，並將這些物理特性納入軌跡預測過程中。初步結果表明，當考慮所提出的物理特性時，SE(3) 模型的這個直接延伸會產生更高的準確度，如 MAE 和 RMSD 所測量。

##### **Multi-Source Knowledge-Based Hybrid Neural Framework for Time Series Representation Learning**
2408.12409v1 by Sagar Srinivas Sakhinana, Krishna Sai Sudhir Aripirala, Shivam Gupta, Venkataramana Runkana

Accurately predicting the behavior of complex dynamical systems,
characterized by high-dimensional multivariate time series(MTS) in
interconnected sensor networks, is crucial for informed decision-making in
various applications to minimize risk. While graph forecasting networks(GFNs)
are ideal for forecasting MTS data that exhibit spatio-temporal dependencies,
prior works rely solely on the domain-specific knowledge of time-series
variables inter-relationships to model the nonlinear dynamics, neglecting
inherent relational structural dependencies among the variables within the MTS
data. In contrast, contemporary works infer relational structures from MTS data
but neglect domain-specific knowledge. The proposed hybrid architecture
addresses these limitations by combining both domain-specific knowledge and
implicit knowledge of the relational structure underlying the MTS data using
Knowledge-Based Compositional Generalization. The hybrid architecture shows
promising results on multiple benchmark datasets, outperforming
state-of-the-art forecasting methods. Additionally, the architecture models the
time varying uncertainty of multi-horizon forecasts.

摘要：準確預測複雜動態系統的行為，
其特徵是在互連感測器網路中具有高維度多變量時間序列 (MTS)，對於在各種應用中最小化風險的明智決策制定至關重要。雖然圖形預測網路 (GFN) 非常適合預測展現時空依賴性的 MTS 資料，
但先前的工作僅依賴於時間序列變數相互關係的特定領域知識來建模非線性動態，忽略了 MTS 資料中變數之間內在的關聯結構依賴性。相比之下，當代作品從 MTS 資料推斷關聯結構，但忽略了特定領域的知識。所提出的混合架構透過使用基於知識的組合泛化，結合特定領域的知識和 MTS 資料中底層關聯結構的隱含知識，來解決這些限制。混合架構在多個基準資料集上顯示出有希望的結果，優於最先進的預測方法。此外，該架構對多時段預測的時間變異不確定性進行建模。

##### **Multi-Style Facial Sketch Synthesis through Masked Generative Modeling**
2408.12400v1 by Bowen Sun, Guo Lu, Shibao Zheng

The facial sketch synthesis (FSS) model, capable of generating sketch
portraits from given facial photographs, holds profound implications across
multiple domains, encompassing cross-modal face recognition, entertainment,
art, media, among others. However, the production of high-quality sketches
remains a formidable task, primarily due to the challenges and flaws associated
with three key factors: (1) the scarcity of artist-drawn data, (2) the
constraints imposed by limited style types, and (3) the deficiencies of
processing input information in existing models. To address these difficulties,
we propose a lightweight end-to-end synthesis model that efficiently converts
images to corresponding multi-stylized sketches, obviating the necessity for
any supplementary inputs (\eg, 3D geometry). In this study, we overcome the
issue of data insufficiency by incorporating semi-supervised learning into the
training process. Additionally, we employ a feature extraction module and style
embeddings to proficiently steer the generative transformer during the
iterative prediction of masked image tokens, thus achieving a continuous
stylized output that retains facial features accurately in sketches. The
extensive experiments demonstrate that our method consistently outperforms
previous algorithms across multiple benchmarks, exhibiting a discernible
disparity.

摘要：人臉素描合成 (FSS) 模型能夠根據給定的面部照片產生素描肖像，在多個領域具有深遠的影響，包括跨模態人臉識別、娛樂、藝術、媒體等。然而，產生高品質素描仍然是一項艱鉅的任務，這主要是由於與三個關鍵因素相關的挑戰和缺陷：(1) 藝術家繪製數據的稀缺性，(2) 受限樣式類型的約束，以及 (3) 現有模型中處理輸入信息的缺陷。為了解決這些難題，我們提出了一個輕量級端到端合成模型，該模型可以有效地將圖像轉換為對應的多樣式素描，從而消除了對任何補充輸入（例如 3D 幾何）的需要。在本研究中，我們通過將半監督學習納入訓練過程來克服數據不足的問題。此外，我們採用特徵提取模組和樣式嵌入，以便在遮蔽圖像標記的迭代預測過程中熟練地引導生成式轉換器，從而獲得連續的樣式化輸出，準確地保留素描中的面部特徵。大量的實驗表明，我們的模型在多個基準測試中始終優於先前的演算法，表現出明顯的差異。

##### **A Comparative Analysis of Faithfulness Metrics and Humans in Citation Evaluation**
2408.12398v1 by Weijia Zhang, Mohammad Aliannejadi, Jiahuan Pei, Yifei Yuan, Jia-Hong Huang, Evangelos Kanoulas

Large language models (LLMs) often generate content with unsupported or
unverifiable content, known as "hallucinations." To address this,
retrieval-augmented LLMs are employed to include citations in their content,
grounding the content in verifiable sources. Despite such developments,
manually assessing how well a citation supports the associated statement
remains a major challenge. Previous studies tackle this challenge by leveraging
faithfulness metrics to estimate citation support automatically. However, they
limit this citation support estimation to a binary classification scenario,
neglecting fine-grained citation support in practical scenarios. To investigate
the effectiveness of faithfulness metrics in fine-grained scenarios, we propose
a comparative evaluation framework that assesses the metric effectiveness in
distinguishing citations between three-category support levels: full, partial,
and no support. Our framework employs correlation analysis, classification
evaluation, and retrieval evaluation to measure the alignment between metric
scores and human judgments comprehensively. Our results indicate no single
metric consistently excels across all evaluations, highlighting the complexity
of accurately evaluating fine-grained support levels. Particularly, we find
that the best-performing metrics struggle to distinguish partial support from
full or no support. Based on these findings, we provide practical
recommendations for developing more effective metrics.

摘要：大型語言模型 (LLM) 常常產生內容不具支持性或無法驗證的內容，這類內容稱為「幻覺」。為了解決這個問題，採用了檢索增強大型語言模型，在內容中納入引文，使內容建立在可驗證的來源上。儘管有這些進展，手動評估引文如何支援相關陳述仍然是一項重大挑戰。先前的研究透過利用忠實度指標自動估計引文支援來應對此挑戰。然而，他們將此引文支援估計限制在二元分類情境中，忽略實際情境中的細微引文支援。為了探討忠實度指標在細微情境中的有效性，我們提出一個比較評估架構，評估指標在區分三個類別支援層級（完全、部分和不支援）的引文方面的有效性。我們的架構採用相關性分析、分類評估和檢索評估，以全面測量指標分數與人類判斷之間的一致性。我們的結果表明，沒有單一指標在所有評估中都持續表現出色，突顯了準確評估細微支援層級的複雜性。特別是，我們發現表現最佳的指標難以區分部分支援與完全或不支援。根據這些發現，我們提供了實用的建議，以開發更有效的指標。

##### **Cell-ontology guided transcriptome foundation model**
2408.12373v1 by Xinyu Yuan, Zhihao Zhan, Zuobai Zhang, Manqi Zhou, Jianan Zhao, Boyu Han, Yue Li, Jian Tang

Transcriptome foundation models TFMs hold great promises of deciphering the
transcriptomic language that dictate diverse cell functions by self-supervised
learning on large-scale single-cell gene expression data, and ultimately
unraveling the complex mechanisms of human diseases. However, current TFMs
treat cells as independent samples and ignore the taxonomic relationships
between cell types, which are available in cell ontology graphs. We argue that
effectively leveraging this ontology information during the TFM pre-training
can improve learning biologically meaningful gene co-expression patterns while
preserving TFM as a general purpose foundation model for downstream zero-shot
and fine-tuning tasks. To this end, we present \textbf{s}ingle \textbf{c}ell,
\textbf{Cell}-\textbf{o}ntology guided TFM scCello. We introduce cell-type
coherence loss and ontology alignment loss, which are minimized along with the
masked gene expression prediction loss during the pre-training. The novel loss
component guide scCello to learn the cell-type-specific representation and the
structural relation between cell types from the cell ontology graph,
respectively. We pre-trained scCello on 22 million cells from CellxGene
database leveraging their cell-type labels mapped to the cell ontology graph
from Open Biological and Biomedical Ontology Foundry. Our TFM demonstrates
competitive generalization and transferability performance over the existing
TFMs on biologically important tasks including identifying novel cell types of
unseen cells, prediction of cell-type-specific marker genes, and cancer drug
responses.

摘要：<paragraph>轉錄組基礎模型 TFM 承諾解碼轉錄組語言，它透過在大型單細胞基因表現資料上進行自我監督學習，來決定不同的細胞功能，並最終解開人類疾病的複雜機制。然而，目前的 TFM 將細胞視為獨立樣本，並忽略細胞類型之間的分類關係，而這在細胞本體論圖表中是可用的。我們認為在 TFM 預訓練期間有效利用此本體論資訊，可以改善學習生物學上有意義的基因共表現模式，同時保留 TFM 作為下游零次學習和微調任務的一般用途基礎模型。為此，我們提出單細胞、細胞本體論引導的 TFM scCello。我們引入細胞類型一致性損失和本體論對齊損失，在預訓練期間會將其與遮罩基因表現預測損失一起最小化。這個新穎的損失組件引導 scCello 分別從細胞本體論圖表中學習細胞類型特定表示和細胞類型之間的結構關係。我們在 CellxGene 資料庫中對 2200 萬個細胞進行 scCello 預訓練，利用其細胞類型標籤對應到開放生物和生物醫學本體鑄造廠的細胞本體論圖表。我們的 TFM 在生物學上重要的任務上展示了比現有 TFM 更具競爭力的泛化和可轉移性，包括識別未見細胞的新細胞類型、預測細胞類型特定標記基因和癌症藥物反應。</paragraph>

##### **RoundTable: Leveraging Dynamic Schema and Contextual Autocomplete for Enhanced Query Precision in Tabular Question Answering**
2408.12369v1 by Pratyush Kumar, Kuber Vijaykumar Bellad, Bharat Vadlamudi, Aman Chadha

With advancements in Large Language Models (LLMs), a major use case that has
emerged is querying databases in plain English, translating user questions into
executable database queries, which has improved significantly. However,
real-world datasets often feature a vast array of attributes and complex
values, complicating the LLMs task of accurately identifying relevant columns
or values from natural language queries. Traditional methods cannot fully relay
the datasets size and complexity to the LLM. To address these challenges, we
propose a novel framework that leverages Full-Text Search (FTS) on the input
table. This approach not only enables precise detection of specific values and
columns but also narrows the search space for language models, thereby
enhancing query accuracy. Additionally, it supports a custom auto-complete
feature that suggests queries based on the data in the table. This integration
significantly refines the interaction between the user and complex datasets,
offering a sophisticated solution to the limitations faced by current table
querying capabilities. This work is accompanied by an application for both Mac
and Windows platforms, which readers can try out themselves on their own data.

摘要：隨著大型語言模型 (LLM) 的進步，一個主要的使用案例已經浮現，那就是以英語查詢資料庫，將使用者的問題轉換為可執行的資料庫查詢，這已經有了顯著的進步。然而，真實世界的資料集通常具有大量的屬性和複雜的值，這讓 LLM 難以準確地從自然語言查詢中識別出相關的欄位或值。傳統的方法無法完全向 LLM 傳達資料集的大小和複雜性。為了應對這些挑戰，我們提出了一個新穎的框架，它在輸入表上利用全文搜尋 (FTS)。這種方法不僅能夠精確地偵測特定值和欄位，還能縮小語言模型的搜尋空間，從而提高查詢的準確性。此外，它還支援自訂的自動完成功能，根據表中的資料建議查詢。這種整合顯著地改進了使用者與複雜資料集之間的互動，為目前表格查詢能力所面臨的限制提供了巧妙的解決方案。這項工作附帶了一個適用於 Mac 和 Windows 平台的應用程式，讀者可以自行在自己的資料上試用。

##### **SAM-SP: Self-Prompting Makes SAM Great Again**
2408.12364v1 by Chunpeng Zhou, Kangjie Ning, Qianqian Shen, Sheng Zhou, Zhi Yu, Haishuai Wang

The recently introduced Segment Anything Model (SAM), a Visual Foundation
Model (VFM), has demonstrated impressive capabilities in zero-shot segmentation
tasks across diverse natural image datasets. Despite its success, SAM
encounters noticeably performance degradation when applied to specific domains,
such as medical images. Current efforts to address this issue have involved
fine-tuning strategies, intended to bolster the generalizability of the vanilla
SAM. However, these approaches still predominantly necessitate the utilization
of domain specific expert-level prompts during the evaluation phase, which
severely constrains the model's practicality.
  To overcome this limitation, we introduce a novel self-prompting based
fine-tuning approach, called SAM-SP, tailored for extending the vanilla SAM
model. Specifically, SAM-SP leverages the output from the previous iteration of
the model itself as prompts to guide subsequent iteration of the model. This
self-prompting module endeavors to learn how to generate useful prompts
autonomously and alleviates the dependence on expert prompts during the
evaluation phase, significantly broadening SAM's applicability. Additionally,
we integrate a self-distillation module to enhance the self-prompting process
further. Extensive experiments across various domain specific datasets validate
the effectiveness of the proposed SAM-SP. Our SAM-SP not only alleviates the
reliance on expert prompts but also exhibits superior segmentation performance
comparing to the state-of-the-art task-specific segmentation approaches, the
vanilla SAM, and SAM-based approaches.

摘要：最近推出的 Segment Anything Model (SAM)，一種視覺基礎模型 (VFM)，在各種自然影像資料集的零次分段任務中展現出令人印象深刻的能力。儘管 SAM 成功，但應用於特定領域（例如醫學影像）時，效能明顯下降。目前解決此問題的方法包括微調策略，旨在加強香草 SAM 的概括性。然而，這些方法在評估階段仍然主要需要使用特定領域的專家級提示，這嚴重限制了模型的實用性。
為了克服此限制，我們引入一種基於自我提示的新型微調方法，稱為 SAM-SP，專門用於擴充香草 SAM 模型。具體來說，SAM-SP 利用模型本身先前反覆運算的輸出作為提示，引導模型後續反覆運算。此自我提示模組努力學習如何自主產生有用的提示，並減輕評估階段對專家提示的依賴性，顯著擴展 SAM 的適用性。此外，我們整合一個自我蒸餾模組，進一步增強自我提示的過程。在各種特定領域資料集中的大量實驗驗證了所提出的 SAM-SP 的有效性。我們的 SAM-SP 不僅減輕了對專家提示的依賴性，而且與最先進的特定任務分割方法、香草 SAM 和基於 SAM 的方法相比，還展現出優異的分割效能。

##### **CLEANANERCorp: Identifying and Correcting Incorrect Labels in the ANERcorp Dataset**
2408.12362v1 by Mashael Al-Duwais, Hend Al-Khalifa, Abdulmalik Al-Salman

Label errors are a common issue in machine learning datasets, particularly
for tasks such as Named Entity Recognition. Such label errors might hurt model
training, affect evaluation results, and lead to an inaccurate assessment of
model performance. In this study, we dived deep into one of the widely adopted
Arabic NER benchmark datasets (ANERcorp) and found a significant number of
annotation errors, missing labels, and inconsistencies. Therefore, in this
study, we conducted empirical research to understand these errors, correct them
and propose a cleaner version of the dataset named CLEANANERCorp. CLEANANERCorp
will serve the research community as a more accurate and consistent benchmark.

摘要：標籤錯誤是機器學習資料集中常見的問題，特別是對於命名實體辨識等任務。此類標籤錯誤可能會損害模型訓練、影響評估結果，並導致對模型效能的評估不準確。在本研究中，我們深入探討了一個廣泛採用的阿拉伯語命名實體辨識基準資料集 (ANERcorp)，並發現大量註解錯誤、標籤遺漏和不一致之處。因此，在本研究中，我們進行了實證研究以了解這些錯誤，並對其進行更正，並提出一個名為 CLEANANERCorp 的資料集的更乾淨版本。CLEANANERCorp 將作為更準確且一致的基準，服務於研究社群。

##### **Fine-tuning Smaller Language Models for Question Answering over Financial Documents**
2408.12337v1 by Karmvir Singh Phogat, Sai Akhil Puranam, Sridhar Dasaratha, Chetan Harsha, Shashishekar Ramakrishna

Recent research has shown that smaller language models can acquire
substantial reasoning abilities when fine-tuned with reasoning exemplars
crafted by a significantly larger teacher model. We explore this paradigm for
the financial domain, focusing on the challenge of answering questions that
require multi-hop numerical reasoning over financial texts. We assess the
performance of several smaller models that have been fine-tuned to generate
programs that encode the required financial reasoning and calculations. Our
findings demonstrate that these fine-tuned smaller models approach the
performance of the teacher model.
  To provide a granular analysis of model performance, we propose an approach
to investigate the specific student model capabilities that are enhanced by
fine-tuning. Our empirical analysis indicates that fine-tuning refines the
student models ability to express and apply the required financial concepts
along with adapting the entity extraction for the specific data format. In
addition, we hypothesize and demonstrate that comparable financial reasoning
capability can be induced using relatively smaller datasets.

摘要：最近的研究表明，较小的语言模型在经过大幅增加的教师模型精心调整的推理范例微调后，可以获得大量的推理能力。我们探索了金融领域的这一范例，重点在于回答需要对金融文本进行多跳数值推理的问题。我们评估了几个较小的模型的性能，这些模型经过微调以生成对所需的财务推理和计算进行编码的程序。我们的研究结果表明，这些微调后的较小模型接近教师模型的性能。为了对模型性能进行细粒度分析，我们提出了一种方法来调查通过微调增强的特定学生模型能力。我们的实证分析表明，微调完善了学生模型表达和应用所需财务概念的能力，同时调整了特定数据格式的实体提取。此外，我们假设并证明可以使用相对较小的数据集来诱导可比较的财务推理能力。

##### **Graph Retrieval Augmented Trustworthiness Reasoning**
2408.12333v1 by Ying Zhu, Shengchang Li, Ziqian Kong, Peilan Xu

Trustworthiness reasoning is crucial in multiplayer games with incomplete
information, enabling agents to identify potential allies and adversaries,
thereby enhancing reasoning and decision-making processes. Traditional
approaches relying on pre-trained models necessitate extensive domain-specific
data and considerable reward feedback, with their lack of real-time
adaptability hindering their effectiveness in dynamic environments. In this
paper, we introduce the Graph Retrieval Augmented Reasoning (GRATR) framework,
leveraging the Retrieval-Augmented Generation (RAG) technique to bolster
trustworthiness reasoning in agents. GRATR constructs a dynamic trustworthiness
graph, updating it in real-time with evidential information, and retrieves
relevant trust data to augment the reasoning capabilities of Large Language
Models (LLMs). We validate our approach through experiments on the multiplayer
game "Werewolf," comparing GRATR against baseline LLM and LLM enhanced with
Native RAG and Rerank RAG. Our results demonstrate that GRATR surpasses the
baseline methods by over 30\% in winning rate, with superior reasoning
performance. Moreover, GRATR effectively mitigates LLM hallucinations, such as
identity and objective amnesia, and crucially, it renders the reasoning process
more transparent and traceable through the use of the trustworthiness graph.

摘要：<paragraph>在信息不完整的多人遊戲中，可信度推理至關重要，它使代理商能夠識別潛在的盟友和敵人，從而增強推理和決策制定過程。依賴預先訓練模型的傳統方法需要廣泛的特定領域數據和大量的獎勵反饋，而缺乏實時適應性阻礙了它們在動態環境中的有效性。在本文中，我們介紹了圖表檢索增強推理 (GRATR) 框架，利用檢索增強生成 (RAG) 技術來加強代理商的可信度推理。GRATR 構建了一個動態的可信度圖表，並使用證據信息實時更新它，並檢索相關的信任數據以增強大型語言模型 (LLM) 的推理能力。我們通過在多人遊戲“狼人”上的實驗驗證了我們的做法，將 GRATR 與基線 LLM 和增強了 Native RAG 和 Rerank RAG 的 LLM 進行了比較。我們的結果表明，GRATR 在獲勝率上超過了基線方法 30% 以上，具有卓越的推理性能。此外，GRATR 有效地減輕了 LLM 的幻覺，例如身份和目標健忘症，最重要的是，它通過使用可信度圖表使推理過程更加透明和可追溯。</paragraph>

##### **Interactive DualChecker for Mitigating Hallucinations in Distilling Large Language Models**
2408.12326v1 by Meiyun Wang, Masahiro Suzuki, Hiroki Sakaji, Kiyoshi Izumi

Large Language Models (LLMs) have demonstrated exceptional capabilities
across various machine learning (ML) tasks. Given the high costs of creating
annotated datasets for supervised learning, LLMs offer a valuable alternative
by enabling effective few-shot in-context learning. However, these models can
produce hallucinations, particularly in domains with incomplete knowledge.
Additionally, current methods for knowledge distillation using LLMs often
struggle to enhance the effectiveness of both teacher and student models. To
address these challenges, we introduce DualChecker, an innovative framework
designed to mitigate hallucinations and improve the performance of both teacher
and student models during knowledge distillation. DualChecker employs
ContextAligner to ensure that the context provided by teacher models aligns
with human labeling standards. It also features a dynamic checker system that
enhances model interaction: one component re-prompts teacher models with more
detailed content when they show low confidence, and another identifies
borderline cases from student models to refine the teaching templates. This
interactive process promotes continuous improvement and effective knowledge
transfer between the models. We evaluate DualChecker using a green innovation
textual dataset that includes binary, multiclass, and token classification
tasks. The experimental results show that DualChecker significantly outperforms
existing state-of-the-art methods, achieving up to a 17% improvement in F1
score for teacher models and 10% for student models. Notably, student models
fine-tuned with LLM predictions perform comparably to those fine-tuned with
actual data, even in a challenging domain. We make all datasets, models, and
code from this research publicly available.

摘要：<paragraph>大型語言模型 (LLM) 已在各種機器學習 (ML) 任務中展現出非凡的能力。由於建立標註資料集以進行監督式學習的成本很高，LLM 提供了一個有價值的替代方案，方法是啟用有效的小樣本情境學習。然而，這些模型可能會產生幻覺，特別是在知識不完整的領域中。此外，目前使用 LLM 進行知識蒸餾的方法通常難以提升教師和學生模型的效能。為了應對這些挑戰，我們引入了 DualChecker，這是一個創新的架構，旨在減輕幻覺並在知識蒸餾期間提升教師和學生模型的效能。DualChecker 使用 ContextAligner 來確保教師模型提供的內容與人類標記標準一致。它還具備一個動態檢查器系統，可以增強模型互動：一個組件會在教師模型顯示出低信心時重新提示更詳細的內容，另一個組件會從學生模型中找出臨界案例以改善教學範本。這個互動過程促进了模型之間的持續改進和有效的知識傳遞。我們使用包含二元、多類和標記分類任務的綠色創新文本資料集來評估 DualChecker。實驗結果顯示，DualChecker 的表現顯著優於現有的最先進方法，教師模型的 F1 分數提升了 17%，學生模型的 F1 分數提升了 10%。值得注意的是，使用 LLM 預測進行微調的學生模型表現與使用實際資料進行微調的學生模型相當，即使在具有挑戰性的領域中也是如此。我們公開了本研究中所有的資料集、模型和程式碼。</paragraph>

##### **Improving Factuality in Large Language Models via Decoding-Time Hallucinatory and Truthful Comparators**
2408.12325v1 by Dingkang Yang, Dongling Xiao, Jinjie Wei, Mingcheng Li, Zhaoyu Chen, Ke Li, Lihua Zhang

Despite their remarkable capabilities, Large Language Models (LLMs) are prone
to generate responses that contradict verifiable facts, i.e., unfaithful
hallucination content. Existing efforts generally focus on optimizing model
parameters or editing semantic representations, which compromise the internal
factual knowledge of target LLMs. In addition, hallucinations typically exhibit
multifaceted patterns in downstream tasks, limiting the model's holistic
performance across tasks. In this paper, we propose a Comparator-driven
Decoding-Time (CDT) framework to alleviate the response hallucination. Firstly,
we construct hallucinatory and truthful comparators with multi-task fine-tuning
samples. In this case, we present an instruction prototype-guided mixture of
experts strategy to enhance the ability of the corresponding comparators to
capture different hallucination or truthfulness patterns in distinct task
instructions. CDT constrains next-token predictions to factuality-robust
distributions by contrasting the logit differences between the target LLMs and
these comparators. Systematic experiments on multiple downstream tasks show
that our framework can significantly improve the model performance and response
factuality.

摘要：儘管大型語言模型 (LLM) 有其非凡的能力，但它們容易產生與可驗證事實相矛盾的回應，也就是不忠實的幻覺內容。現有的努力通常專注於最佳化模型參數或編輯語意表示，這會損害目標 LLM 的內部事實知識。此外，幻覺通常在下游任務中表現出多方面的模式，限制了模型跨任務的整體效能。在本文中，我們提出一個比較器驅動的解碼時間 (CDT) 架構來減輕回應幻覺。首先，我們使用多任務微調範例建構幻覺和真實比較器。在這種情況下，我們提出了一個指令原型引導的專家混合策略，以增強對應比較器擷取不同任務指令中不同幻覺或真實模式的能力。CDT 透過對比目標 LLM 和這些比較器之間的 logit 差異，將下一個代幣預測限制在穩健的事實分佈中。在多個下游任務上的系統實驗表明，我們的架構可以顯著改善模型效能和回應事實性。

##### **MaVEn: An Effective Multi-granularity Hybrid Visual Encoding Framework for Multimodal Large Language Model**
2408.12321v1 by Chaoya Jiang, Jia Hongrui, Haiyang Xu, Wei Ye, Mengfan Dong, Ming Yan, Ji Zhang, Fei Huang, Shikun Zhang

This paper presents MaVEn, an innovative Multi-granularity Visual Encoding
framework designed to enhance the capabilities of Multimodal Large Language
Models (MLLMs) in multi-image reasoning. Current MLLMs primarily focus on
single-image visual understanding, limiting their ability to interpret and
integrate information across multiple images. MaVEn addresses this limitation
by combining discrete visual symbol sequences, which abstract coarse-grained
semantic concepts, with traditional continuous representation sequences that
model fine-grained features. This dual approach bridges the semantic gap
between visual and textual data, thereby improving the model's ability to
process and interpret information from multiple images effectively.
Additionally, we design a dynamic reduction mechanism by for long-sequence
continuous features to enhance multi-image processing efficiency. Experimental
results demonstrate that MaVEn significantly enhances MLLMs' understanding in
complex multi-image scenarios, while also improving performance in single-image
contexts.

摘要：本文提出了 MaVEn，一個創新的多粒度視覺編碼框架，旨在增強多模態大型語言模型 (MLLM) 在多影像推理中的能力。目前的 MLLM 主要專注於單一影像視覺理解，限制了它們跨多影像詮釋和整合資訊的能力。MaVEn 透過結合抽象粗粒度語義概念的離散視覺符號序列，以及建模細粒度特徵的傳統連續表示序列，來解決此限制。這種雙重方法彌合了視覺和文本資料之間的語義差距，從而提升模型有效處理和詮釋來自多影像資訊的能力。此外，我們設計了一個動態簡約機制，用於長序列連續特徵，以提升多影像處理效率。實驗結果證明，MaVEn 大幅增強了 MLLM 在複雜多影像場景中的理解力，同時也提升了在單一影像情境中的效能。

##### **PolyRouter: A Multi-LLM Querying System**
2408.12320v1 by Dimitris Stripelis, Zijian Hu, Jipeng Zhang, Zhaozhuo Xu, Alay Shah, Han Jin, Yuhang Yao, Salman Avestimehr, Chaoyang He

With the rapid growth of Large Language Models (LLMs) across various domains,
numerous new LLMs have emerged, each possessing domain-specific expertise. This
proliferation has highlighted the need for quick, high-quality, and
cost-effective LLM query response methods. Yet, no single LLM exists to
efficiently balance this trilemma. Some models are powerful but extremely
costly, while others are fast and inexpensive but qualitatively inferior. To
address this challenge, we present PolyRouter, a non-monolithic LLM querying
system that seamlessly integrates various LLM experts into a single query
interface and dynamically routes incoming queries to the most high-performant
expert based on query's requirements. Through extensive experiments, we
demonstrate that when compared to standalone expert models, PolyRouter improves
query efficiency by up to 40%, and leads to significant cost reductions of up
to 30%, while maintaining or enhancing model performance by up to 10%.

摘要：隨著大型語言模型 (LLM) 在各個領域快速發展，
許多新的 LLM 應運而生，每個 LLM 都擁有特定領域的專業知識。這種激增凸顯了快速、高品質且
具成本效益的 LLM 查詢回應方法的需求。然而，沒有任何單一 LLM 能有效平衡這個三難困境。有些模型功能強大但成本極高，而其他模型則快速且便宜但品質較差。為了應對這個挑戰，我們提出了 PolyRouter，一個非單體式 LLM 查詢系統，它將各種 LLM 專家無縫整合到單一查詢介面中，並根據查詢需求動態路由傳入查詢到效能最高的專家。透過廣泛的實驗，我們證明與獨立的專家模型相比，PolyRouter 將查詢效率提升了 40%，並將成本大幅降低了 30%，同時將模型效能提升或提高了 10%。

##### **Large Language Models Are Self-Taught Reasoners: Enhancing LLM Applications via Tailored Problem-Solving Demonstrations**
2408.12315v1 by Kai Tzu-iunn Ong, Taeyoon Kwon, Jinyoung Yeo

Guiding large language models with a selected set of human-authored
demonstrations is a common practice for improving LLM applications. However,
human effort can be costly, especially in specialized domains (e.g., clinical
diagnosis), and does not guarantee optimal performance due to the potential
discrepancy of target skills between selected demonstrations and real test
instances. Motivated by these, this paper explores the automatic creation of
customized demonstrations, whose target skills align with the given target
instance. We present SELF-TAUGHT, a problem-solving framework, which
facilitates demonstrations that are "tailored" to the target problem and
"filtered" for better quality (i.e., correctness) in a zero-shot manner. In 15
tasks of multiple-choice questions of diverse domains and the diagnosis of
Alzheimer's disease (AD) with real-world patients, SELF-TAUGHT achieves
superior performance to strong baselines (e.g., Few-shot CoT, Plan-and-Solve,
Auto-CoT). We conduct comprehensive analyses on SELF-TAUGHT, including its
generalizability to existing prompting methods and different LLMs, the quality
of its intermediate generation, and more.

摘要：使用一組由人類撰寫的示範來指導大型語言模型是一種改善 LLM 應用程式的常見做法。然而，人力成本可能很高，特別是在專業領域（例如臨床診斷）中，而且由於選定的示範與實際測試實例之間目標技能的潛在差異，並不能保證最佳效能。基於這些動機，本文探討了自動建立自訂示範，其目標技能與給定的目標實例一致。我們提出了一個問題解決架構 SELF-TAUGHT，它可以促進「針對」目標問題「篩選」出更高品質（即正確性）的示範，且採用零次學習的方式。在多個領域的多選題任務和對真實世界患者進行阿茲海默症 (AD) 診斷的 15 項任務中，SELF-TAUGHT 達到了優於強大基準（例如 Few-shot CoT、Plan-and-Solve、Auto-CoT）的效能。我們對 SELF-TAUGHT 進行了全面的分析，包括其對現有提示方法和不同 LLM 的概括性、其中間產生的品質等等。

##### **Tipta uzmanlik sinavinda (tus) büyük dil modelleri insanlardan daha mi başarili?**
2408.12305v1 by Yesim Aygul, Muge Olucoglu, Adil Alpkocak

The potential of artificial intelligence in medical education and assessment
has been made evident by recent developments in natural language processing and
artificial intelligence. Medical questions can now be successfully answered by
artificial intelligence algorithms. It can help medical practitioners. This
study evaluates the performance of three different artificial intelligence
models in answering Turkish medical questions in the 2021 1st Term Medical
Specialization Examination (MSE). MSE consists of a total of 240 questions
across clinical (CMST) and basic (BMST) medical sciences. According to the
results in CMST, it was concluded that Gemini correctly answered 82 questions,
ChatGPT-4 answered 105 questions and ChatGPT-4o answered 117 questions. In
BMST, Gemini and ChatGPT-4 answered 93 questions and ChatGPT-4o answered 107
questions correctly according to the answer key. ChatGPT-4o outperformed the
candidate with the highest scores of 113 and 106 according to CMST and BMST
respectively. This study highlights the importance of the potential of
artificial intelligence in medical education and assessment. It demonstrates
that advanced models can achieve high accuracy and contextual understanding,
demonstrating their potential role in medical education and evaluation.

摘要：人工智能在醫學教育和評量中的潛力
最近在自然語言處理和人工智能的發展已證明。醫學問題現在可以由
人工智能演算法成功回答。它可以幫助醫療從業者。本
研究評估了三個不同的人工智能模型在回答 2021 年第 1 學期醫學
專科考試 (MSE) 中的土耳其醫學問題時的表現。MSE 總共包含 240 個
問題，涵蓋臨床 (CMST) 和基礎 (BMST) 醫學科學。根據
CMST 的結果，得出結論，Gemini 正確回答了 82 個問題，
ChatGPT-4 回答了 105 個問題，而 ChatGPT-4o 回答了 117 個問題。在
BMST 中，根據答案關鍵，Gemini 和 ChatGPT-4 回答了 93 個問題，而 ChatGPT-4o 回答了 107
個問題。根據 CMST 和 BMST，ChatGPT-4o 分別優於得分最高的 113 和 106 的考生。本研究強調了
人工智能在醫學教育和評量中的潛力。它證明了先進的模型可以實現高準確度和脈絡理解，展示了它們在醫學教育和評估中的潛在作用。

##### **OPTDTALS: Approximate Logic Synthesis via Optimal Decision Trees Approach**
2408.12304v1 by Hao Hu, Shaowei Cai

The growing interest in Explainable Artificial Intelligence (XAI) motivates
promising studies of computing optimal Interpretable Machine Learning models,
especially decision trees. Such models generally provide optimality in compact
size or empirical accuracy. Recent works focus on improving efficiency due to
the natural scalability issue. The application of such models to practical
problems is quite limited. As an emerging problem in circuit design,
Approximate Logic Synthesis (ALS) aims to reduce circuit complexity by
sacrificing correctness. Recently, multiple heuristic machine learning methods
have been applied in ALS, which learns approximated circuits from samples of
input-output pairs.
  In this paper, we propose a new ALS methodology realizing the approximation
via learning optimal decision trees in empirical accuracy. Compared to previous
heuristic ALS methods, the guarantee of optimality achieves a more controllable
trade-off between circuit complexity and accuracy. Experimental results show
clear improvements in our methodology in the quality of approximated designs
(circuit complexity and accuracy) compared to the state-of-the-art approaches.

摘要：隨著可解釋人工智慧 (XAI) 受到越來越多人關注，促使研究人員致力於計算最佳可解釋機器學習模型，尤其是決策樹，並取得了可觀的進展。此類模型通常在精簡大小或經驗準確度方面提供最佳化。近期研究專注於改善效率，以解決自然的可擴充性問題。將此類模型應用於實際問題的範圍相當有限。近似邏輯合成 (ALS) 是電路設計中新興的問題，旨在透過犧牲正確性來降低電路複雜度。最近，多種啟發式機器學習方法已應用於 ALS，從輸入輸出配對的樣本來學習近似電路。
  在本文中，我們提出一個新的 ALS 方法，透過在經驗準確度中學習最佳決策樹來實現近似。與先前的啟發式 ALS 方法相比，最佳化的保證實現了電路複雜度和準確度之間更可控的權衡。實驗結果顯示，與最先進的方法相比，我們的 ALS 方法在近似設計的品質（電路複雜度和準確度）方面有顯著的改善。

##### **Towards Deconfounded Image-Text Matching with Causal Inference**
2408.12292v1 by Wenhui Li, Xinqi Su, Dan Song, Lanjun Wang, Kun Zhang, An-An Liu

Prior image-text matching methods have shown remarkable performance on many
benchmark datasets, but most of them overlook the bias in the dataset, which
exists in intra-modal and inter-modal, and tend to learn the spurious
correlations that extremely degrade the generalization ability of the model.
Furthermore, these methods often incorporate biased external knowledge from
large-scale datasets as prior knowledge into image-text matching model, which
is inevitable to force model further learn biased associations. To address
above limitations, this paper firstly utilizes Structural Causal Models (SCMs)
to illustrate how intra- and inter-modal confounders damage the image-text
matching. Then, we employ backdoor adjustment to propose an innovative
Deconfounded Causal Inference Network (DCIN) for image-text matching task. DCIN
(1) decomposes the intra- and inter-modal confounders and incorporates them
into the encoding stage of visual and textual features, effectively eliminating
the spurious correlations during image-text matching, and (2) uses causal
inference to mitigate biases of external knowledge. Consequently, the model can
learn causality instead of spurious correlations caused by dataset bias.
Extensive experiments on two well-known benchmark datasets, i.e., Flickr30K and
MSCOCO, demonstrate the superiority of our proposed method.

摘要：先前的图像文本匹配方法在许多基准数据集上显示出显着的性能，但它们中的大多数都忽略了数据集中的偏差，该偏差存在于模态内和模态间，并且倾向于学习极大地降低模型泛化能力的虚假相关性。此外，这些方法通常将来自大规模数据集的偏差外部知识作为先验知识纳入图像文本匹配模型，这不可避免地迫使模型进一步学习偏差关联。为了解决上述限制，本文首先利用结构因果模型 (SCM) 来说明模态内和模态间混杂因素如何损害图像文本匹配。然后，我们采用后门调整为图像文本匹配任务提出了一种创新的去混杂因果推理网络 (DCIN)。DCIN (1) 分解模态内和模态间混杂因素，并将它们纳入视觉和文本特征的编码阶段，有效消除图像文本匹配期间的虚假相关性，以及 (2) 使用因果推理来减轻外部知识的偏差。因此，该模型可以学习因果关系，而不是由数据集偏差引起的虚假相关性。在两个著名的基准数据集（即 Flickr30K 和 MSCOCO）上进行的广泛实验表明了我们提出的方法的优越性。

##### **Variance reduction of diffusion model's gradients with Taylor approximation-based control variate**
2408.12270v1 by Paul Jeha, Will Grathwohl, Michael Riis Andersen, Carl Henrik Ek, Jes Frellsen

Score-based models, trained with denoising score matching, are remarkably
effective in generating high dimensional data. However, the high variance of
their training objective hinders optimisation. We attempt to reduce it with a
control variate, derived via a $k$-th order Taylor expansion on the training
objective and its gradient. We prove an equivalence between the two and
demonstrate empirically the effectiveness of our approach on a low dimensional
problem setting; and study its effect on larger problems.

摘要：基於去噪分數匹配訓練的分數模型，在生成高維度資料方面非常有效。然而，其訓練目標的高變異性會阻礙最佳化。我們嘗試透過控制變數來降低變異性，該變數是透過在訓練目標及其梯度上進行 $k$ 階泰勒展開導出的。我們證明了兩者之間的等價性，並在低維度問題設定上實證展示了我們方法的有效性；並研究其對較大問題的影響。

##### **Toward the Evaluation of Large Language Models Considering Score Variance across Instruction Templates**
2408.12263v1 by Yusuke Sakai, Adam Nohejl, Jiangnan Hang, Hidetaka Kamigaito, Taro Watanabe

The natural language understanding (NLU) performance of large language models
(LLMs) has been evaluated across various tasks and datasets. The existing
evaluation methods, however, do not take into account the variance in scores
due to differences in prompts, which leads to unfair evaluation and comparison
of NLU performance. Moreover, evaluation designed for specific prompts is
inappropriate for instruction tuning, which aims to perform well with any
prompt. It is therefore necessary to find a way to measure NLU performance in a
fair manner, considering score variance between different instruction
templates. In this study, we provide English and Japanese cross-lingual
datasets for evaluating the NLU performance of LLMs, which include multiple
instruction templates for fair evaluation of each task, along with regular
expressions to constrain the output format. Furthermore, we propose the Sharpe
score as an evaluation metric that takes into account the variance in scores
between templates. Comprehensive analysis of English and Japanese LLMs reveals
that the high variance among templates has a significant impact on the fair
evaluation of LLMs.

摘要：自然語言理解 (NLU) 大型語言模型 (LLM) 的效能已在各種任務和資料集上進行評估。然而，現有的評估方法並未將因提示差異而產生的分數差異納入考量，這導致 NLU 效能的評估和比較並不公平。此外，針對特定提示所設計的評估並不適用於指令微調，而指令微調的目標是在任何提示下都能表現良好。因此，有必要找到一種方法來以公平的方式衡量 NLU 效能，並考量不同指令範本之間的分數差異。在本研究中，我們提供英文和日文的跨語言資料集，用於評估 LLM 的 NLU 效能，其中包含多個指令範本，以公平評估每個任務，並使用正規表示法來限制輸出格式。此外，我們提出夏普分數作為評估指標，它會將範本之間的分數差異納入考量。對英文和日文 LLM 的全面分析顯示，範本之間的高差異對 LLM 的公平評估有顯著影響。

##### **Can You Trust Your Metric? Automatic Concatenation-Based Tests for Metric Validity**
2408.12259v1 by Ora Nova Fandina, Leshem Choshen, Eitan Farchi, George Kour, Yotam Perlitz, Orna Raz

Consider a scenario where a harmfulness detection metric is employed by a
system to filter unsafe responses generated by a Large Language Model. When
analyzing individual harmful and unethical prompt-response pairs, the metric
correctly classifies each pair as highly unsafe, assigning the highest score.
However, when these same prompts and responses are concatenated, the metric's
decision flips, assigning the lowest possible score, thereby misclassifying the
content as safe and allowing it to bypass the filter. In this study, we
discovered that several harmfulness LLM-based metrics, including GPT-based,
exhibit this decision-flipping phenomenon. Additionally, we found that even an
advanced metric like GPT-4o is highly sensitive to input order. Specifically,
it tends to classify responses as safe if the safe content appears first,
regardless of any harmful content that follows, and vice versa. This work
introduces automatic concatenation-based tests to assess the fundamental
properties a valid metric should satisfy. We applied these tests in a model
safety scenario to assess the reliability of harmfulness detection metrics,
uncovering a number of inconsistencies.

摘要：考慮到一個場景，其中一個系統使用有害性偵測指標來過濾大型語言模型產生的不安全回應。在分析個別有害且不道德的提示回應配對時，指標正確地將每個配對分類為高度不安全，並指定最高分數。然而，當這些相同的提示和回應被串接時，指標的決定會翻轉，指定最低分數，從而將內容錯誤分類為安全並允許其繞過過濾器。在這項研究中，我們發現了幾個基於 LLM 的有害性指標，包括基於 GPT 的指標，表現出這種決策翻轉現象。此外，我們發現即使像 GPT-4o 這樣的高級指標對輸入順序也非常敏感。具體來說，它傾向於將回應分類為安全，如果安全內容首先出現，無論後續是否有任何有害內容，反之亦然。這項工作引入了基於自動串接的測試，以評估有效指標應滿足的基本屬性。我們在模型安全場景中應用這些測試來評估有害性偵測指標的可靠性，發現許多不一致之處。

##### **A Language-agnostic Model of Child Language Acquisition**
2408.12254v1 by Louis Mahon, Omri Abend, Uri Berger, Katherine Demuth, Mark Johnson, Mark Steedman

This work reimplements a recent semantic bootstrapping child-language
acquisition model, which was originally designed for English, and trains it to
learn a new language: Hebrew. The model learns from pairs of utterances and
logical forms as meaning representations, and acquires both syntax and word
meanings simultaneously. The results show that the model mostly transfers to
Hebrew, but that a number of factors, including the richer morphology in
Hebrew, makes the learning slower and less robust. This suggests that a clear
direction for future work is to enable the model to leverage the similarities
between different word forms.

摘要：這項研究重新實作了一個最近的語義引導式兒童語言習得模型，該模型最初是為英語設計，並訓練它學習一種新語言：希伯來語。該模型從成對的語句和邏輯形式中學習，作為意義表徵，並同時習得句法和詞彙意義。結果表明，該模型大多可以轉移到希伯來語，但是許多因素，包括希伯來語中更豐富的形態，使得學習更慢且不那麼穩健。這表明未來工作的明確方向是讓模型能夠利用不同詞形之間的相似性。

##### **Can Artificial Intelligence Embody Moral Values?**
2408.12250v1 by Torben Swoboda, Lode Lauwaert

The neutrality thesis holds that technology cannot be laden with values. This
long-standing view has faced critiques, but much of the argumentation against
neutrality has focused on traditional, non-smart technologies like bridges and
razors. In contrast, AI is a smart technology increasingly used in high-stakes
domains like healthcare, finance, and policing, where its decisions can cause
moral harm. In this paper, we argue that artificial intelligence, particularly
artificial agents that autonomously make decisions to pursue their goals,
challenge the neutrality thesis. Our central claim is that the computational
models underlying artificial agents can integrate representations of moral
values such as fairness, honesty and avoiding harm. We provide a conceptual
framework discussing the neutrality thesis, values, and AI. Moreover, we
examine two approaches to designing computational models of morality,
artificial conscience and ethical prompting, and present empirical evidence
from text-based game environments that artificial agents with such models
exhibit more ethical behavior compared to agents without these models. The
findings support that AI can embody moral values, which contradicts the claim
that all technologies are necessarily value-neutral.

摘要：中立性論點認為科技無法承載價值觀。這個長久以來的觀點面臨批評，但許多反對中立性的論點都集中在傳統的非智慧型科技，例如橋樑和剃刀。相比之下，人工智慧是一種智慧型科技，日益運用於醫療保健、金融和警政等高風險領域，其決策可能會造成道德傷害。在本文中，我們論證人工智慧，尤其是自主做出決策以追求目標的人工代理，挑戰了中立性論點。我們的核心主張是，人工代理背後的運算模型可以整合道德價值觀的表徵，例如公平、誠實和避免傷害。我們提供了一個概念架構，討論中立性論點、價值觀和人工智慧。此外，我們探討了設計道德運算模型的兩種方法，即人工良心和道德提示，並從基於文字的遊戲環境中提出實證證據，證明具備此類模型的人工代理與沒有這些模型的代理相比，表現出更道德的行為。這些發現支持人工智慧可以體現道德價值觀，這與所有科技都必然價值中立的主張相矛盾。

##### **LLMs are not Zero-Shot Reasoners for Biomedical Information Extraction**
2408.12249v1 by Aishik Nagar, Viktor Schlegel, Thanh-Tung Nguyen, Hao Li, Yuping Wu, Kuluhan Binici, Stefan Winkler

Large Language Models (LLMs) are increasingly adopted for applications in
healthcare, reaching the performance of domain experts on tasks such as
question answering and document summarisation. Despite their success on these
tasks, it is unclear how well LLMs perform on tasks that are traditionally
pursued in the biomedical domain, such as structured information extration. To
breach this gap, in this paper, we systematically benchmark LLM performance in
Medical Classification and Named Entity Recognition (NER) tasks. We aim to
disentangle the contribution of different factors to the performance,
particularly the impact of LLMs' task knowledge and reasoning capabilities,
their (parametric) domain knowledge, and addition of external knowledge. To
this end we evaluate various open LLMs -- including BioMistral and Llama-2
models -- on a diverse set of biomedical datasets, using standard prompting,
Chain-of-Thought (CoT) and Self-Consistency based reasoning as well as
Retrieval-Augmented Generation (RAG) with PubMed and Wikipedia corpora.
Counter-intuitively, our results reveal that standard prompting consistently
outperforms more complex techniques across both tasks, laying bare the
limitations in the current application of CoT, self-consistency and RAG in the
biomedical domain. Our findings suggest that advanced prompting methods
developed for knowledge- or reasoning-intensive tasks, such as CoT or RAG, are
not easily portable to biomedical tasks where precise structured outputs are
required. This highlights the need for more effective integration of external
knowledge and reasoning mechanisms in LLMs to enhance their performance in
real-world biomedical applications.

摘要：大型語言模型 (LLM) 愈來愈多用於醫療保健應用，在回答問題和文件摘要等任務上達到領域專家的表現。儘管這些任務獲得成功，但尚不清楚 LLM 在生物醫學領域傳統上執行的任務，例如結構化資訊萃取，表現如何。為了彌補這個差距，我們在這篇論文中系統性地評量 LLM 在醫學分類和命名實體辨識 (NER) 任務中的表現。我們的目標是釐清不同因素對表現的貢獻，特別是 LLM 的任務知識和推理能力、它們的（參數）領域知識，以及外部知識的加入。為此，我們評估各種開放的 LLM（包括 BioMistral 和 Llama-2 模型），使用標準提示、基於思考鏈 (CoT) 和自洽性的推理以及使用 PubMed 和維基百科語料庫的檢索增強生成 (RAG) 在多樣化的生物醫學資料集上。與直覺相反，我們的結果顯示標準提示在兩項任務中始終優於更複雜的技術，揭露了在生物醫學領域中 CoT、自洽性和 RAG 的當前應用中的限制。我們的發現表明，為知識或推理密集型任務（例如 CoT 或 RAG）開發的高階提示方法不容易移植到需要精確結構化輸出的生物醫學任務。這突顯出需要更有效地整合外部知識和推理機制到 LLM 中，以增強它們在實際生物醫學應用中的表現。

##### **Efficient Multivariate Time Series Anomaly Detection Through Transfer Learning for Large-Scale Web services**
2408.12247v1 by Shenglin Zhang, Pengtian Zhu, Minghua Ma, Jiagang Wang, Yongqian Sun, Dongwen Li, Jingyu Wang, Qianying Guo, Xiaolei Hua, Lin Zhu, Dan Pei

Large language models (LLMs) excel at general question-answering (Q&A) but
often fall short in specialized domains due to a lack of domain-specific
knowledge. Commercial companies face the dual challenges of privacy protection
and resource constraints when involving LLMs for fine-tuning. This paper
propose a novel framework, Self-Evolution, designed to address these issues by
leveraging lightweight open-source LLMs through multiple iterative fine-tuning
rounds. To enhance the efficiency of iterative fine-tuning, Self-Evolution
employ a strategy that filters and reinforces the knowledge with higher value
during the iterative process. We employed Self-Evolution on Qwen1.5-7B-Chat
using 4,000 documents containing rich domain knowledge from China Mobile,
achieving a performance score 174% higher on domain-specific question-answering
evaluations than Qwen1.5-7B-Chat and even 22% higher than Qwen1.5-72B-Chat.
Self-Evolution has been deployed in China Mobile's daily operation and
maintenance for 117 days, and it improves the efficiency of locating alarms,
fixing problems, and finding related reports, with an average efficiency
improvement of over 18.6%. In addition, we release Self-Evolution framework
code in https://github.com/Zero-Pointer/Self-Evolution.

摘要：大型語言模型（LLM）擅長一般性的問答（Q&A），但由於缺乏特定領域的知識，在專業領域中常常表現不佳。商業公司在使用 LLM 進行微調時，面臨隱私保護和資源限制的雙重挑戰。本文提出了一個創新的框架，稱為自進化，旨在通過多輪反覆微調來利用輕量級的開源 LLM 來解決這些問題。為了提高反覆微調的效率，自進化採用了一種策略，在反覆的過程中過濾和強化具有更高價值的知識。我們在 Qwen1.5-7B-Chat 上採用了自進化，使用了 4,000 份包含來自中國移動豐富領域知識的文件，在特定領域的問答評估中，其性能得分比 Qwen1.5-7B-Chat 高出 174%，甚至比 Qwen1.5-72B-Chat 高出 22%。自進化已部署在中國移動的日常運營和維護中 117 天，它提高了定位告警、修復問題和查找相關報告的效率，平均效率提高了 18.6%。此外，我們在 https://github.com/Zero-Pointer/Self-Evolution 中發布了自進化框架代碼。

##### **Weight Scope Alignment: A Frustratingly Easy Method for Model Merging**
2408.12237v1 by Yichu Xu, Xin-Chun Li, Le Gan, De-Chuan Zhan

Merging models becomes a fundamental procedure in some applications that
consider model efficiency and robustness. The training randomness or Non-I.I.D.
data poses a huge challenge for averaging-based model fusion. Previous research
efforts focus on element-wise regularization or neural permutations to enhance
model averaging while overlooking weight scope variations among models, which
can significantly affect merging effectiveness. In this paper, we reveal
variations in weight scope under different training conditions, shedding light
on its influence on model merging. Fortunately, the parameters in each layer
basically follow the Gaussian distribution, which inspires a novel and simple
regularization approach named Weight Scope Alignment (WSA). It contains two key
components: 1) leveraging a target weight scope to guide the model training
process for ensuring weight scope matching in the subsequent model merging. 2)
fusing the weight scope of two or more models into a unified one for
multi-stage model fusion. We extend the WSA regularization to two different
scenarios, including Mode Connectivity and Federated Learning. Abundant
experimental studies validate the effectiveness of our approach.

摘要：合併模型在考量模型效率與穩健性的某些應用程式中成為基本程序。訓練的隨機性或非獨立同分布資料對基於平均值的模型融合構成巨大挑戰。先前的研究工作重點在於元素級正則化或神經排列，以增強模型平均，同時忽略模型之間的權重範圍變化，這可能會顯著影響合併效果。在本文中，我們揭露在不同訓練條件下的權重範圍變化，進一步說明其對模型合併的影響。幸運的是，每一層中的參數基本上遵循高斯分布，這激發了一種新穎且簡單的正則化方法，稱為權重範圍對齊 (WSA)。它包含兩個關鍵組成部分：1) 利用目標權重範圍來引導模型訓練過程，以確保後續模型合併中的權重範圍匹配。2) 將兩個或多個模型的權重範圍融合為統一的權重範圍，以進行多階段模型融合。我們將 WSA 正則化延伸到兩種不同的場景，包括模式連接和聯合學習。大量的實驗研究驗證了我們方法的有效性。

##### **MedDiT: A Knowledge-Controlled Diffusion Transformer Framework for Dynamic Medical Image Generation in Virtual Simulated Patient**
2408.12236v1 by Yanzeng Li, Cheng Zeng, Jinchao Zhang, Jie Zhou, Lei Zou

Medical education relies heavily on Simulated Patients (SPs) to provide a
safe environment for students to practice clinical skills, including medical
image analysis. However, the high cost of recruiting qualified SPs and the lack
of diverse medical imaging datasets have presented significant challenges. To
address these issues, this paper introduces MedDiT, a novel
knowledge-controlled conversational framework that can dynamically generate
plausible medical images aligned with simulated patient symptoms, enabling
diverse diagnostic skill training. Specifically, MedDiT integrates various
patient Knowledge Graphs (KGs), which describe the attributes and symptoms of
patients, to dynamically prompt Large Language Models' (LLMs) behavior and
control the patient characteristics, mitigating hallucination during medical
conversation. Additionally, a well-tuned Diffusion Transformer (DiT) model is
incorporated to generate medical images according to the specified patient
attributes in the KG. In this paper, we present the capabilities of MedDiT
through a practical demonstration, showcasing its ability to act in diverse
simulated patient cases and generate the corresponding medical images. This can
provide an abundant and interactive learning experience for students, advancing
medical education by offering an immersive simulation platform for future
healthcare professionals. The work sheds light on the feasibility of
incorporating advanced technologies like LLM, KG, and DiT in education
applications, highlighting their potential to address the challenges faced in
simulated patient-based medical education.

摘要：醫學教育高度依賴模擬病人 (SP) 提供一個安全的環境，讓學生練習臨床技能，包括醫學影像分析。然而，招募合格 SP 的高成本和缺乏多樣的醫學影像資料集已造成顯著的挑戰。為了解決這些問題，本文介紹 MedDiT，一個新穎的知識控制對話架構，它可以動態產生符合模擬病人症狀的合理醫學影像，實現多樣的診斷技能訓練。具體來說，MedDiT 整合了各種病人知識圖譜 (KG)，描述病人的屬性和症狀，以動態提示大型語言模型 (LLM) 的行為，並控制病人特徵，減輕醫學對話中的幻覺。此外，還納入一個經過微調的擴散Transformer (DiT) 模型，根據 KG 中指定的病人屬性產生醫學影像。在本文中，我們透過實際示範展示 MedDiT 的功能，展示它在不同模擬病人案例中作用並產生相應醫學影像的能力。這可以為學生提供豐富且互動的學習體驗，透過提供身歷其境的模擬平台，提升醫學教育，造福未來的醫療保健專業人員。這項工作闡明了在教育應用中整合 LLM、KG 和 DiT 等先進技術的可行性，突顯它們在解決模擬病人為基礎的醫學教育所面臨挑戰的潛力。

##### **EvalYaks: Instruction Tuning Datasets and LoRA Fine-tuned Models for Automated Scoring of CEFR B2 Speaking Assessment Transcripts**
2408.12226v1 by Nicy Scaria, Silvester John Joseph Kennedy, Thomas Latinovich, Deepak Subramani

Relying on human experts to evaluate CEFR speaking assessments in an
e-learning environment creates scalability challenges, as it limits how quickly
and widely assessments can be conducted. We aim to automate the evaluation of
CEFR B2 English speaking assessments in e-learning environments from
conversation transcripts. First, we evaluate the capability of leading open
source and commercial Large Language Models (LLMs) to score a candidate's
performance across various criteria in the CEFR B2 speaking exam in both global
and India-specific contexts. Next, we create a new expert-validated,
CEFR-aligned synthetic conversational dataset with transcripts that are rated
at different assessment scores. In addition, new instruction-tuned datasets are
developed from the English Vocabulary Profile (up to CEFR B2 level) and the
CEFR-SP WikiAuto datasets. Finally, using these new datasets, we perform
parameter efficient instruction tuning of Mistral Instruct 7B v0.2 to develop a
family of models called EvalYaks. Four models in this family are for assessing
the four sections of the CEFR B2 speaking exam, one for identifying the CEFR
level of vocabulary and generating level-specific vocabulary, and another for
detecting the CEFR level of text and generating level-specific text. EvalYaks
achieved an average acceptable accuracy of 96%, a degree of variation of 0.35
levels, and performed 3 times better than the next best model. This
demonstrates that a 7B parameter LLM instruction tuned with high-quality
CEFR-aligned assessment data can effectively evaluate and score CEFR B2 English
speaking assessments, offering a promising solution for scalable, automated
language proficiency evaluation.

摘要：<paragraph>在電子學習環境中依賴人類專家來評估 CEFR 口說評量會造成可擴充性的挑戰，因為它限制了評量執行速度和廣度的可能性。我們的目標是自動化電子學習環境中 CEFR B2 英語口說評量的評量，從對話記錄檔中進行評量。首先，我們評估領先的開放原始碼和商業大型語言模型 (LLM) 在全球和印度特定情境中為應試者在 CEFR B2 口說考試中各項標準的表現評分的能力。接著，我們建立一個新的專家驗證、符合 CEFR 的合成對話資料集，其中包含評分不同的記錄檔。此外，我們從英語詞彙概況（最高達 CEFR B2 等級）和 CEFR-SP WikiAuto 資料集開發出新的教學調整資料集。最後，我們使用這些新的資料集，對 Mistral Instruct 7B v0.2 執行參數有效率的教學調整，以開發一系列稱為 EvalYaks 的模型。此系列中的四個模型用於評量 CEFR B2 口說考試的四個部分，一個用於識別詞彙的 CEFR 等級並產生特定等級的詞彙，另一個用於偵測文字的 CEFR 等級並產生特定等級的文字。EvalYaks 達到了 96% 的平均可接受準確度、0.35 等級的變異程度，並且表現比次佳模型好 3 倍。這證明了經過高品質 CEFR 對齊評量資料調整的 7B 參數 LLM 能有效評估和評分 CEFR B2 英語口說評量，為可擴充、自動化的語言能力評量提供了有前景的解決方案。</paragraph>

##### **UNCO: Towards Unifying Neural Combinatorial Optimization through Large Language Model**
2408.12214v1 by Xia Jiang, Yaoxin Wu, Yuan Wang, Yingqian Zhang

Recently, applying neural networks to address combinatorial optimization
problems (COPs) has attracted considerable research attention. The prevailing
methods always train deep models independently on specific problems, lacking a
unified framework for concurrently tackling various COPs. To this end, we
propose a unified neural combinatorial optimization (UNCO) framework to solve
different types of COPs by a single model. Specifically, we use natural
language to formulate text-attributed instances for different COPs and encode
them in the same embedding space by the large language model (LLM). The
obtained embeddings are further advanced by an encoder-decoder model without
any problem-specific modules, thereby facilitating a unified process of
solution construction. We further adopt the conflict gradients erasing
reinforcement learning (CGERL) algorithm to train the UNCO model, delivering
better performance across different COPs than vanilla multi-objective learning.
Experiments show that the UNCO model can solve multiple COPs after a
single-session training, and achieves satisfactory performance that is
comparable to several traditional or learning-based baselines. Instead of
pursuing the best performance for each COP, we explore the synergy between
tasks and few-shot generalization based on LLM to inspire future work.

摘要：<paragraph>最近，将神经网络应用于解决组合优化问题（COP）引起了相当大的研究关注。现行的做法是针对特定问题独立训练深度模型，缺乏用于同时解决各种 COP 的统一框架。为此，我们提出了一个统一的神经组合优化（UNCO）框架，通过单个模型解决不同类型的 COP。具体来说，我们使用自然语言为不同的 COP 制定文本属性实例，并通过大型语言模型（LLM）将它们编码在相同的嵌入空间中。获得的嵌入通过一个编码器-解码器模型进一步提升，没有任何特定于问题的模块，从而促进了解决方案构建的统一过程。我们进一步采用冲突梯度擦除强化学习（CGERL）算法来训练 UNCO 模型，在不同的 COP 中提供比香草多目标学习更好的性能。实验表明，UNCO 模型可以在单次训练后解决多个 COP，并且取得了令人满意的性能，与几个传统的或基于学习的基线相当。我们没有追求每个 COP 的最佳性能，而是探索任务之间的协同作用和基于 LLM 的小样本泛化，以激发未来的工作。</paragraph>

##### **Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment**
2408.12194v1 by Kun Luo, Minghao Qin, Zheng Liu, Shitao Xiao, Jun Zhao, Kang Liu

Pretrained language models like BERT and T5 serve as crucial backbone
encoders for dense retrieval. However, these models often exhibit limited
generalization capabilities and face challenges in improving in domain
accuracy. Recent research has explored using large language models (LLMs) as
retrievers, achieving SOTA performance across various tasks. Despite these
advancements, the specific benefits of LLMs over traditional retrievers and the
impact of different LLM configurations, such as parameter sizes, pretraining
duration, and alignment processes on retrieval tasks remain unclear. In this
work, we conduct a comprehensive empirical study on a wide range of retrieval
tasks, including in domain accuracy, data efficiency, zero shot generalization,
lengthy retrieval, instruction based retrieval, and multi task learning. We
evaluate over 15 different backbone LLMs and non LLMs. Our findings reveal that
larger models and extensive pretraining consistently enhance in domain accuracy
and data efficiency. Additionally, larger models demonstrate significant
potential in zero shot generalization, lengthy retrieval, instruction based
retrieval, and multi task learning. These results underscore the advantages of
LLMs as versatile and effective backbone encoders in dense retrieval, providing
valuable insights for future research and development in this field.

摘要：預訓練的語言模型，例如 BERT 和 T5，用作密集檢索的關鍵骨幹編碼器。然而，這些模型通常表現出有限的概括能力，並且在提高領域準確性方面面臨挑戰。最近的研究探索使用大型語言模型 (LLM) 作為檢索器，在各種任務中實現了 SOTA 效能。儘管有這些進展，LLM 相較於傳統檢索器的具體優點以及不同 LLM 組態（例如參數大小、預訓練持續時間和對齊程序）對檢索任務的影響仍不清楚。在這項工作中，我們對廣泛的檢索任務進行了全面的實證研究，包括領域準確性、資料效率、零次概括、長篇檢索、基於指令的檢索和多任務學習。我們評估了 15 個不同的骨幹 LLM 和非 LLM。我們的研究結果表明，較大的模型和廣泛的預訓練持續增強領域準確性和資料效率。此外，較大的模型在零次概括、長篇檢索、基於指令的檢索和多任務學習中展現了顯著的潛力。這些結果強調了 LLM 作為密集檢索中多功能且有效的骨幹編碼器的優點，為該領域未來的研究和開發提供了寶貴的見解。

##### **Reasoning Factual Knowledge in Structured Data with Large Language Models**
2408.12188v1 by Sirui Huang, Yanggan Gu, Xuming Hu, Zhonghao Li, Qing Li, Guandong Xu

Large language models (LLMs) have made remarkable progress in various natural
language processing tasks as a benefit of their capability to comprehend and
reason with factual knowledge. However, a significant amount of factual
knowledge is stored in structured data, which possesses unique characteristics
that differ from the unstructured texts used for pretraining. This difference
can introduce imperceptible inference parameter deviations, posing challenges
for LLMs in effectively utilizing and reasoning with structured data to
accurately infer factual knowledge. To this end, we propose a benchmark named
StructFact, to evaluate the structural reasoning capabilities of LLMs in
inferring factual knowledge. StructFact comprises 8,340 factual questions
encompassing various tasks, domains, timelines, and regions. This benchmark
allows us to investigate the capability of LLMs across five factual tasks
derived from the unique characteristics of structural facts. Extensive
experiments on a set of LLMs with different training strategies reveal the
limitations of current LLMs in inferring factual knowledge from structured
data. We present this benchmark as a compass to navigate the strengths and
weaknesses of LLMs in reasoning with structured data for knowledge-sensitive
tasks, and to encourage advancements in related real-world applications. Please
find our code at https://github.com/EganGu/StructFact.

摘要：大型語言模型 (LLM) 在各種自然語言處理任務中取得顯著進展，因為它們具備理解和推理事實知識的能力。然而，大量的真實知識儲存在結構化資料中，其具有與用於預訓練的非結構化文字不同的獨特特徵。這種差異可能會引入難以察覺的推論參數偏差，對 LLM 有效利用和推理結構化資料以準確推斷事實知識構成挑戰。為此，我們提出了一個名為 StructFact 的基準，以評估 LLM 在推斷事實知識方面的結構推理能力。StructFact 包含 8,340 個事實問題，涵蓋各種任務、領域、時間線和區域。這個基準讓我們能夠調查 LLM 在源自結構化事實的獨特特徵的五項事實任務中的能力。對採用不同訓練策略的一組 LLM 進行的廣泛實驗揭示了當前 LLM 從結構化資料中推斷事實知識的局限性。我們將這個基準作為指南，用於了解 LLM 在推理結構化資料以進行知識敏感任務時的優缺點，並鼓勵在相關實際應用中取得進展。請在 https://github.com/EganGu/StructFact 找到我們的程式碼。

##### **A Safe and Efficient Self-evolving Algorithm for Decision-making and Control of Autonomous Driving Systems**
2408.12187v1 by Shuo Yang, Liwen Wang, Yanjun Huang, Hong Chen

Autonomous vehicles with a self-evolving ability are expected to cope with
unknown scenarios in the real-world environment. Take advantage of trial and
error mechanism, reinforcement learning is able to self evolve by learning the
optimal policy, and it is particularly well suitable for solving
decision-making problems. However, reinforcement learning suffers from safety
issues and low learning efficiency, especially in the continuous action space.
Therefore, the motivation of this paper is to address the above problem by
proposing a hybrid Mechanism-Experience-Learning augmented approach.
Specifically, to realize the efficient self-evolution, the driving tendency by
analogy with human driving experience is proposed to reduce the search space of
the autonomous driving problem, while the constrained optimization problem
based on a mechanistic model is designed to ensure safety during the
self-evolving process. Experimental results show that the proposed method is
capable of generating safe and reasonable actions in various complex scenarios,
improving the performance of the autonomous driving system. Compared to
conventional reinforcement learning, the safety and efficiency of the proposed
algorithm are greatly improved. The training process is collision-free, and the
training time is equivalent to less than 10 minutes in the real world.

摘要：預計具備自我進化能力的自動駕駛車輛能夠應對真實世界環境中的未知場景。利用試錯機制，強化學習能夠透過學習最佳策略而自我進化，特別適合解決決策問題。然而，強化學習會出現安全問題和低學習效率，特別是在連續動作空間中。因此，本文的動機是透過提出混合機制-經驗-學習增強方法來解決上述問題。具體來說，為了實現高效的自我進化，提出類比人類駕駛經驗的駕駛傾向以減少自動駕駛問題的搜尋空間，同時基於機制模型的約束最佳化問題旨在確保自我進化過程中的安全性。實驗結果表明，所提出的方法能夠在各種複雜場景中產生安全且合理的動作，改善自動駕駛系統的性能。與傳統的強化學習相比，所提出的演算法的安全性與效率都得到了極大的提升。訓練過程無碰撞，訓練時間相當於現實世界中的不到 10 分鐘。

##### **Rank and Align: Towards Effective Source-free Graph Domain Adaptation**
2408.12185v1 by Junyu Luo, Zhiping Xiao, Yifan Wang, Xiao Luo, Jingyang Yuan, Wei Ju, Langechuan Liu, Ming Zhang

Graph neural networks (GNNs) have achieved impressive performance in graph
domain adaptation. However, extensive source graphs could be unavailable in
real-world scenarios due to privacy and storage concerns. To this end, we
investigate an underexplored yet practical problem of source-free graph domain
adaptation, which transfers knowledge from source models instead of source
graphs to a target domain. To solve this problem, we introduce a novel
GNN-based approach called Rank and Align (RNA), which ranks graph similarities
with spectral seriation for robust semantics learning, and aligns inharmonic
graphs with harmonic graphs which close to the source domain for subgraph
extraction. In particular, to overcome label scarcity, we employ the spectral
seriation algorithm to infer the robust pairwise rankings, which can guide
semantic learning using a similarity learning objective. To depict distribution
shifts, we utilize spectral clustering and the silhouette coefficient to detect
harmonic graphs, which the source model can easily classify. To reduce
potential domain discrepancy, we extract domain-invariant subgraphs from
inharmonic graphs by an adversarial edge sampling process, which guides the
invariant learning of GNNs. Extensive experiments on several benchmark datasets
demonstrate the effectiveness of our proposed RNA.

摘要：圖形神經網路 (GNN) 在圖形領域適應中獲得令人印象深刻的效能。然而，廣泛的來源圖形在現實世界中可能由於隱私和儲存問題而無法使用。為此，我們探討了一個尚未開發但實用的來源免費圖形領域適應問題，它將知識從來源模型傳輸到目標領域，而不是來源圖形。為了解決這個問題，我們引入一種稱為排名和對齊 (RNA) 的新穎 GNN 方法，它使用光譜序列對圖形相似性進行排名以進行穩健語義學習，並將不和諧圖形與接近來源領域的和諧圖形對齊以進行子圖提取。特別是，為了克服標籤稀少性，我們採用光譜序列演算法來推斷穩健成對排名，它可以使用相似性學習目標來指導語義學習。為了描述分佈轉移，我們利用光譜聚類和輪廓係數來檢測和諧圖形，來源模型可以輕鬆對其進行分類。為了減少潛在的領域差異，我們通過對抗性邊緣取樣過程從不和諧圖形中提取領域不變子圖，這指導了 GNN 的不變學習。在幾個基準資料集上的廣泛實驗證明了我們提出的 RNA 的有效性。

##### **FIRST: Teach A Reliable Large Language Model Through Efficient Trustworthy Distillation**
2408.12168v1 by KaShun Shum, Minrui Xu, Jianshu Zhang, Zixin Chen, Shizhe Diao, Hanze Dong, Jipeng Zhang, Muhammad Omer Raza

Large language models (LLMs) have become increasingly prevalent in our daily
lives, leading to an expectation for LLMs to be trustworthy -- - both accurate
and well-calibrated (the prediction confidence should align with its ground
truth correctness likelihood). Nowadays, fine-tuning has become the most
popular method for adapting a model to practical usage by significantly
increasing accuracy on downstream tasks. Despite the great accuracy it
achieves, we found fine-tuning is still far away from satisfactory
trustworthiness due to "tuning-induced mis-calibration". In this paper, we
delve deeply into why and how mis-calibration exists in fine-tuned models, and
how distillation can alleviate the issue. Then we further propose a brand new
method named Efficient Trustworthy Distillation (FIRST), which utilizes a small
portion of teacher's knowledge to obtain a reliable language model in a
cost-efficient way. Specifically, we identify the "concentrated knowledge"
phenomenon during distillation, which can significantly reduce the
computational burden. Then we apply a "trustworthy maximization" process to
optimize the utilization of this small portion of concentrated knowledge before
transferring it to the student. Experimental results demonstrate the
effectiveness of our method, where better accuracy (+2.3%) and less
mis-calibration (-10%) are achieved on average across both in-domain and
out-of-domain scenarios, indicating better trustworthiness.

摘要：大型語言模型 (LLM) 在我們的日常生活變得越來越普遍，導致人們期望 LLM 值得信賴——既準確又校準良好（預測信心應與其基本正確性機率一致）。如今，微調已成為透過顯著提升下游任務的準確性來調整模型以適應實際用途最受歡迎的方法。儘管它達到了極高的準確性，但我們發現微調仍遠遠無法令人滿意，因為它會導致「微調誘發的校準不佳」。在本文中，我們深入探討了微調模型中為何且如何出現校準不佳，以及蒸餾如何能緩解這個問題。然後，我們進一步提出了一種名為「高效值得信賴蒸餾」(FIRST) 的全新方法，它利用老師的一小部分知識以經濟有效的方式獲得可靠的語言模型。具體來說，我們在蒸餾過程中識別出「集中知識」現象，這可以顯著降低運算負擔。然後，我們運用「值得信賴的最大化」程序來最佳化這小部分集中知識的利用，再將其轉移到學生身上。實驗結果證明了我們方法的有效性，在領域內和領域外情境中平均獲得了更好的準確性 (+2.3%) 和更少的校準不佳 (-10%)，這表示具有更好的可信度。

##### **Preference-Guided Reflective Sampling for Aligning Language Models**
2408.12163v1 by Hai Ye, Hwee Tou Ng

Large language models (LLMs) are aligned with human preferences by
reinforcement learning from human feedback (RLHF). Effective data sampling is
crucial for RLHF, as it determines the efficiency of model training, ensuring
that models learn from the informative samples. To achieve better data
generation, we propose a new sampling method called Preference-Guided
Reflective Sampling (PRS). PRS frames the response generation as an
optimization process to the explicitly specified user preference described in
natural language. It employs a tree-based generation framework to enable an
efficient sampling process, which guides the direction of generation through
preference and better explores the sampling space with adaptive
self-refinement. Notably, PRS can align LLMs to diverse preferences. We study
preference-controlled text generation for instruction following and
keyword-focused document summarization. Our findings indicate that PRS, across
different LLM policies, generates training data with much higher rewards than
strong baselines. PRS also excels in post-RL training.

摘要：大型語言模型 (LLM) 透過人類回饋強化學習 (RLHF) 與人類偏好保持一致。有效的資料抽樣對於 RLHF 至關重要，因為它決定了模型訓練的效率，確保模型從有意義的樣本中學習。為了獲得更好的資料生成，我們提出了一種新的抽樣方法，稱為偏好引導反射抽樣 (PRS)。PRS 將回應生成構建為一個最佳化過程，以自然語言描述明確指定的使用者偏好。它採用基於樹狀結構的生成架構，以實現有效率的抽樣過程，透過偏好引導生成方向，並透過適應性自我精進，更好地探索抽樣空間。值得注意的是，PRS 可以將 LLM 與不同的偏好保持一致。我們研究了偏好控制文本生成，用於指令遵循和關鍵字焦點文件摘要。我們的研究結果表明，PRS 在不同的 LLM 政策中，產生的訓練資料獎勵遠高於強大的基準。PRS 在 RL 後訓練中也表現出色。

##### **Search-Based LLMs for Code Optimization**
2408.12159v1 by Shuzheng Gao, Cuiyun Gao, Wenchao Gu, Michael Lyu

The code written by developers usually suffers from efficiency problems and
contain various performance bugs. These inefficiencies necessitate the research
of automated refactoring methods for code optimization. Early research in code
optimization employs rule-based methods and focuses on specific inefficiency
issues, which are labor-intensive and suffer from the low coverage issue.
Recent work regards the task as a sequence generation problem, and resorts to
deep learning (DL) techniques such as large language models (LLMs). These
methods typically prompt LLMs to directly generate optimized code. Although
these methods show state-of-the-art performance, such one-step generation
paradigm is hard to achieve an optimal solution. First, complex optimization
methods such as combinatorial ones are hard to be captured by LLMs. Second, the
one-step generation paradigm poses challenge in precisely infusing the
knowledge required for effective code optimization within LLMs, resulting in
under-optimized code.To address these problems, we propose to model this task
from the search perspective, and propose a search-based LLMs framework named
SBLLM that enables iterative refinement and discovery of improved optimization
methods. SBLLM synergistically integrate LLMs with evolutionary search and
consists of three key components: 1) an execution-based representative sample
selection part that evaluates the fitness of each existing optimized code and
prioritizes promising ones to pilot the generation of improved code; 2) an
adaptive optimization pattern retrieval part that infuses targeted optimization
patterns into the model for guiding LLMs towards rectifying and progressively
enhancing their optimization methods; and 3) a genetic operator-inspired
chain-of-thought prompting part that aids LLMs in combining different
optimization methods and generating improved optimization methods.

摘要：<paragraph>開發人員撰寫的程式碼通常會有效率問題，並包含各種效能錯誤。這些低效率需要研究自動重構方法以進行程式碼最佳化。程式碼最佳化的早期研究採用基於規則的方法，並專注於特定低效率問題，這需要大量人工，且存在覆蓋率低的問題。最近的研究將任務視為序列產生問題，並採用深度學習 (DL) 技術，例如大型語言模型 (LLM)。這些方法通常會提示 LLM 直接產生最佳化的程式碼。儘管這些方法顯示了最先進的效能，但這種單步產生模式難以達成最佳解。首先，組合式等複雜最佳化方法難以被 LLM 捕捉。其次，單步產生模式在精確注入 LLM 中有效程式碼最佳化所需的知識時構成挑戰，導致程式碼最佳化不足。為了解決這些問題，我們提議從搜尋角度建模此任務，並提出一個名為 SBLLM 的基於搜尋的 LLM 架構，它能進行反覆精煉和發現改良的最佳化方法。SBLLM 協同整合 LLM 與演化搜尋，並包含三個關鍵組成部分：1) 基於執行的代表性樣本選取部分，用於評估每個現有最佳化程式碼的適應度，並優先考慮有希望的程式碼來引導改善程式碼的產生；2) 自適應最佳化模式擷取部分，用於將目標最佳化模式注入模型，以引導 LLM 修正和逐步增強其最佳化方法；3) 受遺傳算子啟發的思考鏈提示部分，用於協助 LLM 結合不同的最佳化方法，並產生改良的最佳化方法。</paragraph>

##### **Implicit Sentiment Analysis Based on Chain of Thought Prompting**
2408.12157v1 by Zhihua Duan, Jialin Wang

Implicit Sentiment Analysis (ISA) is a crucial research area in natural
language processing. Inspired by the idea of large language model Chain of
Thought (CoT), this paper introduces a Sentiment Analysis of Thinking (SAoT)
framework. The framework first analyzes the implicit aspects and opinions in
the text using common sense and thinking chain capabilities. Then, it reflects
on the process of implicit sentiment analysis and finally deduces the polarity
of sentiment. The model is evaluated on the SemEval 2014 dataset, consisting of
1120 restaurant reviews and 638 laptop reviews. The experimental results
demonstrate that the utilization of the ERNIE-Bot-4+SAoT model yields a notable
performance improvement. Specifically, on the restaurant dataset, the F1 score
reaches 75.27, accompanied by an ISA score of 66.29. Similarly, on the computer
dataset, the F1 score achieves 76.50, while the ISA score amounts to 73.46.
Comparatively, the ERNIE-Bot-4+SAoT model surpasses the BERTAsp + SCAPt
baseline by an average margin of 47.99%.

摘要：內隱情緒分析 (ISA) 是自然語言處理中一個重要的研究領域。本論文受到大型語言模型思考鏈 (CoT) 的想法啟發，提出了一個思考情緒分析 (SAoT) 架構。此架構首先使用常識和思考鏈的能力來分析文本中的內隱面向和意見。然後，它回顧內隱情緒分析的過程，最後推論出情緒的極性。此模型在 SemEval 2014 資料集上進行評估，該資料集包含 1120 篇餐廳評論和 638 篇筆電評論。實驗結果證明，利用 ERNIE-Bot-4+SAoT 模型會帶來顯著的效能提升。特別是在餐廳資料集上，F1 分數達到 75.27，ISA 分數為 66.29。類似地，在電腦資料集上，F1 分數達到 76.50，而 ISA 分數為 73.46。相較之下，ERNIE-Bot-4+SAoT 模型平均超過 BERTAsp + SCAPt 基準 47.99%。

##### **DeepHQ: Learned Hierarchical Quantizer for Progressive Deep Image Coding**
2408.12150v1 by Jooyoung Lee, Se Yoon Jeong, Munchurl Kim

Unlike fixed- or variable-rate image coding, progressive image coding (PIC)
aims to compress various qualities of images into a single bitstream,
increasing the versatility of bitstream utilization and providing high
compression efficiency compared to simulcast compression. Research on neural
network (NN)-based PIC is in its early stages, mainly focusing on applying
varying quantization step sizes to the transformed latent representations in a
hierarchical manner. These approaches are designed to compress only the
progressively added information as the quality improves, considering that a
wider quantization interval for lower-quality compression includes multiple
narrower sub-intervals for higher-quality compression. However, the existing
methods are based on handcrafted quantization hierarchies, resulting in
sub-optimal compression efficiency. In this paper, we propose an NN-based
progressive coding method that firstly utilizes learned quantization step sizes
via learning for each quantization layer. We also incorporate selective
compression with which only the essential representation components are
compressed for each quantization layer. We demonstrate that our method achieves
significantly higher coding efficiency than the existing approaches with
decreased decoding time and reduced model size.

摘要：與固定或可變速率影像編碼不同，漸進式影像編碼 (PIC)
旨在將各種品質的影像壓縮成單一比特串流，
增加比特串流利用率的多功能性，並提供高
壓縮效率，以與同播壓縮相比。基於神經網路 (NN) 的 PIC 研究仍處於早期階段，主要專注於
以分層方式將不同的量化步驟大小應用於轉換後的潛在表示。這些方法旨在僅壓縮
隨著品質提升而漸進式新增的資訊，考量到較低品質壓縮的較寬量化區間包含多個
較高品質壓縮的較窄子區間。然而，現有方法基於手工製作的量化層級，導致
次佳的壓縮效率。在本文中，我們提出一個基於 NN 的漸進式編碼方法，首先利用學習的量化步驟大小
透過學習每個量化層。我們也納入選擇性壓縮，其中僅壓縮每個量化層的基本表示元件。我們證明我們的
方法比現有方法達到顯著更高的編碼效率，並減少解碼時間和模型大小。

##### **Multi-tool Integration Application for Math Reasoning Using Large Language Model**
2408.12148v1 by Zhihua Duan, Jialin Wang

Mathematical reasoning is an important research direction in the field of
artificial intelligence. This article proposes a novel multi tool application
framework for mathematical reasoning, aiming to achieve more comprehensive and
accurate mathematical reasoning by utilizing the collaborative effect of large
language models (LLMs) and multiple external tools. Firstly, use a Math Tool to
perform basic mathematical calculations during the inference process through
interaction with LLM. Secondly, Code Tool can generate code fragments that
comply with syntax rules and execute them, providing support for complex
mathematical problems. Then, through the iterative reasoning of the CoT Tool,
the logical coherence and accuracy of mathematical reasoning are enhanced.
Ultimately, by using self consistency tools to select the final answer based on
different parameters, the consistency and reliability of reasoning are
improved. Through the synergistic effect of these tools, the framework has
achieved significant performance improvement in mathematical reasoning tasks.
We conducted experiments on the NumGLUE Task 4 test set, which includes 220
mathematical reasoning fill in the blank questions. The experimental results
showed that, based on Math Tool, Code Tool, and CoT Tool, in Task 4 task,our
method achieved an accuracy of 89.09,compared with the GPT3+FewShot baseline,
Few Shot+ERNIE-4.0+self consistency improved by 49.09%, and compared with
fine-tuning the Fine tuning baseline, Few Shot+ERNIE-4.0+self consistency
improved by 52.29%

摘要：<paragraph>數學推理是人工智慧領域中重要的研究方向。本文提出了一個新的數學推理多工具應用框架，旨在透過利用大型語言模型 (LLM) 和多個外部工具的協作效應，實現更全面且準確的數學推理。首先，在推理過程中透過與 LLM 互動，使用數學工具執行基本的數學運算。其次，程式碼工具可以產生符合語法規則的程式碼片段並執行它們，為複雜的數學問題提供支援。然後，透過 CoT 工具的迭代推理，增強數學推理的邏輯一致性和準確性。最後，透過使用自洽性工具根據不同的參數選擇最終答案，提高推理的一致性和可靠性。透過這些工具的協同效應，該框架在數學推理任務中實現了顯著的效能提升。我們在 NumGLUE 任務 4 測試集上進行了實驗，其中包含 220 個填空式的數學推理問題。實驗結果顯示，在任務 4 任務中，我們的模型在數學工具、程式碼工具和 CoT 工具的基礎上，達到了 89.09% 的準確度，與 GPT3+FewShot 基準相比，Few Shot+ERNIE-4.0+ 自洽性提高了 49.09%，與微調的微調基準相比，Few Shot+ERNIE-4.0+ 自洽性提高了 52.29%。</paragraph>

##### **MDD-5k: A New Diagnostic Conversation Dataset for Mental Disorders Synthesized via Neuro-Symbolic LLM Agents**
2408.12142v1 by Congchi Yin, Feng Li, Shu Zhang, Zike Wang, Jun Shao, Piji Li, Jianhua Chen, Xun Jiang

The clinical diagnosis of most mental disorders primarily relies on the
conversations between psychiatrist and patient. The creation of such diagnostic
conversation datasets is promising to boost the AI mental healthcare community.
However, directly collecting the conversations in real diagnosis scenarios is
near impossible due to stringent privacy and ethical considerations. To address
this issue, we seek to synthesize diagnostic conversation by exploiting
anonymous patient cases that are easier to access. Specifically, we design a
neuro-symbolic multi-agent framework for synthesizing the diagnostic
conversation of mental disorders with large language models. It takes patient
case as input and is capable of generating multiple diverse conversations with
one single patient case. The framework basically involves the interaction
between a doctor agent and a patient agent, and achieves text generation under
symbolic control via a dynamic diagnosis tree from a tool agent. By applying
the proposed framework, we develop the largest Chinese mental disorders
diagnosis dataset MDD-5k, which is built upon 1000 cleaned real patient cases
by cooperating with a pioneering psychiatric hospital, and contains 5000
high-quality long conversations with diagnosis results as labels. To the best
of our knowledge, it's also the first labelled Chinese mental disorders
diagnosis dataset. Human evaluation demonstrates the proposed MDD-5k dataset
successfully simulates human-like diagnostic process of mental disorders. The
dataset and code will become publicly accessible in
https://github.com/lemonsis/MDD-5k.

摘要：大多數精神疾病的臨床診斷主要依賴於精神科醫師與病患之間的對話。建立此類診斷對話資料集有望提升 AI 心理保健社群。然而，由於嚴格的隱私和倫理考量，直接在真實診斷情境中收集對話幾乎是不可能的。為了解決這個問題，我們試圖利用較容易取得的匿名病患案例來合成診斷對話。具體來說，我們設計了一個神經符號多主體架構，用於合成具有大型語言模型的精神疾病診斷對話。它以病患案例作為輸入，並且能夠針對單一病患案例產生多個不同的對話。此架構基本上涉及醫師主體和病患主體之間的互動，並透過來自工具主體的動態診斷樹來實現符號控制下的文字產生。透過應用建議的架構，我們開發了最大的中文精神疾病診斷資料集 MDD-5k，它是建立在 1000 個透過與一家先驅精神病院合作而整理過的真實病患案例上，並包含 5000 個帶有診斷結果標籤的高品質長對話。據我們所知，它也是第一個標記的中文精神疾病診斷資料集。人類評估證明，建議的 MDD-5k 資料集成功模擬了類人的精神疾病診斷流程。資料集和程式碼將在 https://github.com/lemonsis/MDD-5k 公開。

##### **DRExplainer: Quantifiable Interpretability in Drug Response Prediction with Directed Graph Convolutional Network**
2408.12139v1 by Haoyuan Shi, Tao Xu, Xiaodi Li, Qian Gao, Junfeng Xia, Zhenyu Yue

Predicting the response of a cancer cell line to a therapeutic drug is
pivotal for personalized medicine. Despite numerous deep learning methods that
have been developed for drug response prediction, integrating diverse
information about biological entities and predicting the directional response
remain major challenges. Here, we propose a novel interpretable predictive
model, DRExplainer, which leverages a directed graph convolutional network to
enhance the prediction in a directed bipartite network framework. DRExplainer
constructs a directed bipartite network integrating multi-omics profiles of
cell lines, the chemical structure of drugs and known drug response to achieve
directed prediction. Then, DRExplainer identifies the most relevant subgraph to
each prediction in this directed bipartite network by learning a mask,
facilitating critical medical decision-making. Additionally, we introduce a
quantifiable method for model interpretability that leverages a ground truth
benchmark dataset curated from biological features. In computational
experiments, DRExplainer outperforms state-of-the-art predictive methods and
another graph-based explanation method under the same experimental setting.
Finally, the case studies further validate the interpretability and the
effectiveness of DRExplainer in predictive novel drug response. Our code is
available at: https://github.com/vshy-dream/DRExplainer.

摘要：預測癌症細胞株對治療藥物的反應對於個人化醫療至關重要。儘管已經開發出許多用於藥物反應預測的深度學習方法，但整合生物實體的多樣信息和預測方向反應仍然是主要的挑戰。在這裡，我們提出了一個新穎的可解釋預測模型 DRExplainer，它利用有向圖卷積網路在有向二部網路框架中增強預測。DRExplainer 構建了一個有向二部網路，整合了細胞系的組學概況、藥物的化學結構和已知的藥物反應，以實現有向預測。然後，DRExplainer 通過學習遮罩識別此有向二部網路中與每個預測最相關的子圖，促進關鍵的醫療決策制定。此外，我們引入了一種量化模型可解釋性的方法，利用從生物特徵中策劃的地面實況基準資料集。在計算實驗中，DRExplainer 在相同的實驗設置下優於最先進的預測方法和另一種基於圖表的解釋方法。最後，案例研究進一步驗證了 DRExplainer 在預測新藥物反應中的可解釋性和有效性。我們的程式碼可在 https://github.com/vshy-dream/DRExplainer 取得。

##### **Deep Analysis of Time Series Data for Smart Grid Startup Strategies: A Transformer-LSTM-PSO Model Approach**
2408.12129v1 by Zecheng Zhang

Grid startup, an integral component of the power system, holds strategic
importance for ensuring the reliability and efficiency of the electrical grid.
However, current methodologies for in-depth analysis and precise prediction of
grid startup scenarios are inadequate. To address these challenges, we propose
a novel method based on the Transformer-LSTM-PSO model. This model uniquely
combines the Transformer's self-attention mechanism, LSTM's temporal modeling
capabilities, and the parameter tuning features of the particle swarm
optimization algorithm. It is designed to more effectively capture the complex
temporal relationships in grid startup schemes. Our experiments demonstrate
significant improvements, with our model achieving lower RMSE and MAE values
across multiple datasets compared to existing benchmarks, particularly in the
NYISO Electric Market dataset where the RMSE was reduced by approximately 15%
and the MAE by 20% compared to conventional models. Our main contribution is
the development of a Transformer-LSTM-PSO model that significantly enhances the
accuracy and efficiency of smart grid startup predictions. The application of
the Transformer-LSTM-PSO model represents a significant advancement in smart
grid predictive analytics, concurrently fostering the development of more
reliable and intelligent grid management systems.

摘要：電網啟動是電力系統中不可或缺的組成部分，對確保電網的可靠性和效率至關重要。然而，目前深入分析和精準預測電網啟動場景的方法並不完善。為了應對這些挑戰，我們提出了一種基於 Transformer-LSTM-PSO 模型的新方法。此模型獨特地結合了 Transformer 的自注意力機制、LSTM 的時間建模能力以及粒子群優化演算法的參數調整功能。它旨在更有效地捕捉電網啟動方案中的複雜時間關係。我們的實驗證明了顯著的改進，與現有基準相比，我們的模型在多個數據集上達到了較低的 RMSE 和 MAE 值，特別是在 NYISO 電力市場數據集中，與傳統模型相比，RMSE 降低了大約 15%，MAE 降低了 20%。我們的貢獻在於開發了一個 Transformer-LSTM-PSO 模型，顯著提高了智慧電網啟動預測的準確性和效率。Transformer-LSTM-PSO 模型的應用代表了智慧電網預測分析的重大進步，同時促進了更可靠、更智慧的電網管理系統的開發。

##### **AutoTest: Evolutionary Code Solution Selection with Test Cases**
2408.12125v1 by Zhihua Duan, Jialin Wang

With the development of code generation techniques, selecting the correct
code solution from multiple candidate solutions has become a crucial task. This
study proposes AutoTest, a novel technique that combines automated test case
generation with code solution execution to optimize the selection process using
an evolutionary genetic algorithm. Firstly, AutoTest utilizes large pre-trained
language models such as codegen-16B, code-davinci-002, and incoder-6B to
provide code solutions and their corresponding test cases. Then, by executing
the code solutions and evaluating their performance on the test cases, a
consensus set is formed. Fine-grained ranking is achieved through the
selection, mutation, and crossover mechanisms based on the evolutionary genetic
algorithm, with the adjustment of alpha and beta parameters. Finally, the best
code solution is chosen. AutoTest demonstrates significant performance
improvements on the HumanEval benchmark test. The HumanEval dataset consists of
164 programming problems, and AutoTest achieves approximately a 10% improvement
over the baseline method in terms of pass@1 score.

摘要：<paragraph>隨著程式碼產生技術的發展，從多個候選方案中選出正確的程式碼解決方案已成為一項至關重要的任務。本研究提出 AutoTest，一種將自動測試案例產生與程式碼解決方案執行相結合的新穎技術，以使用演化遺傳演算法最佳化選擇過程。首先，AutoTest 利用大型預先訓練的語言模型，例如 codegen-16B、code-davinci-002 和 incoder-6B，提供程式碼解決方案及其對應的測試案例。然後，透過執行程式碼解決方案並評估它們在測試案例上的效能，形成共識集合。透過基於演化遺傳演算法的選擇、變異和交叉機制，實現精細分級排名，並調整 alpha 和 beta 參數。最後，選擇最佳程式碼解決方案。AutoTest 在 HumanEval 基準測試中展示了顯著的效能提升。HumanEval 資料集包含 164 個程式設計問題，而 AutoTest 在 pass@1 分數方面比基線方法提升了大約 10%。</paragraph>

##### **Geolocation Representation from Large Language Models are Generic Enhancers for Spatio-Temporal Learning**
2408.12116v1 by Junlin He, Tong Nie, Wei Ma

In the geospatial domain, universal representation models are significantly
less prevalent than their extensive use in natural language processing and
computer vision. This discrepancy arises primarily from the high costs
associated with the input of existing representation models, which often
require street views and mobility data. To address this, we develop a novel,
training-free method that leverages large language models (LLMs) and auxiliary
map data from OpenStreetMap to derive geolocation representations (LLMGeovec).
LLMGeovec can represent the geographic semantics of city, country, and global
scales, which acts as a generic enhancer for spatio-temporal learning.
Specifically, by direct feature concatenation, we introduce a simple yet
effective paradigm for enhancing multiple spatio-temporal tasks including
geographic prediction (GP), long-term time series forecasting (LTSF), and
graph-based spatio-temporal forecasting (GSTF). LLMGeovec can seamlessly
integrate into a wide spectrum of spatio-temporal learning models, providing
immediate enhancements. Experimental results demonstrate that LLMGeovec
achieves global coverage and significantly boosts the performance of leading
GP, LTSF, and GSTF models.

摘要：在空間地理領域，通用表示模型顯著少於它們在自然語言處理和電腦視覺中的廣泛使用。這種差異主要源於現有表示模型的輸入成本高，這通常需要街景和流動性資料。為了解決這個問題，我們開發一種新穎的免訓練方法，利用大型語言模型 (LLM) 和 OpenStreetMap 的輔助地圖資料來推導地理位置表示 (LLMGeovec)。LLMGeovec 可以表示城市、國家和全球規模的地理語義，作為時空學習的通用增強器。具體來說，通過直接特徵串接，我們引入了一個簡單但有效的範例，用於增強多個時空任務，包括地理預測 (GP)、長期時間序列預測 (LTSF) 和基於圖形的時空預測 (GSTF)。LLMGeovec 可以無縫整合到廣泛的時空學習模型中，提供立即的增強。實驗結果表明，LLMGeovec 達到了全球覆蓋率，並顯著提升了領先的 GP、LTSF 和 GSTF 模型的效能。

##### **Risk Analysis in Customer Relationship Management via Quantile Region Convolutional Neural Network-Long Short-Term Memory and Cross-Attention Mechanism**
2408.12113v1 by Yaowen Huang, Jun Der Leu, Baoli Lu, Yan Zhou

Risk analysis is an important business decision support task in customer
relationship management (CRM), involving the identification of potential risks
or challenges that may affect customer satisfaction, retention rates, and
overall business performance. To enhance risk analysis in CRM, this paper
combines the advantages of quantile region convolutional neural network-long
short-term memory (QRCNN-LSTM) and cross-attention mechanisms for modeling. The
QRCNN-LSTM model combines sequence modeling with deep learning architectures
commonly used in natural language processing tasks, enabling the capture of
both local and global dependencies in sequence data. The cross-attention
mechanism enhances interactions between different input data parts, allowing
the model to focus on specific areas or features relevant to CRM risk analysis.
By applying QRCNN-LSTM and cross-attention mechanisms to CRM risk analysis,
empirical evidence demonstrates that this approach can effectively identify
potential risks and provide data-driven support for business decisions.

摘要：風險分析是客戶關係管理 (CRM) 中一項重要的商業決策支援任務，涉及識別可能影響客戶滿意度、保留率和整體業務績效的潛在風險或挑戰。為了增強 CRM 中的風險分析，本文結合了分位數區域卷積神經網路長短期記憶 (QRCNN-LSTM) 和交叉注意力機制的優點進行建模。QRCNN-LSTM 模型結合了序列建模與自然語言處理任務中常用的深度學習架構，能夠擷取序列資料中的局部和全局依賴關係。交叉注意力機制增強了不同輸入資料部分之間的互動，使模型能夠專注於與 CRM 風險分析相關的特定區域或特徵。透過將 QRCNN-LSTM 和交叉注意力機制應用於 CRM 風險分析，實證證據表明這種方法可以有效識別潛在風險，並為業務決策提供資料驅動的支援。

##### **Balancing Act: Prioritization Strategies for LLM-Designed Restless Bandit Rewards**
2408.12112v1 by Shresth Verma, Niclas Boehmer, Lingkai Kong, Milind Tambe

LLMs are increasingly used to design reward functions based on human
preferences in Reinforcement Learning (RL). We focus on LLM-designed rewards
for Restless Multi-Armed Bandits, a framework for allocating limited resources
among agents. In applications such as public health, this approach empowers
grassroots health workers to tailor automated allocation decisions to community
needs. In the presence of multiple agents, altering the reward function based
on human preferences can impact subpopulations very differently, leading to
complex tradeoffs and a multi-objective resource allocation problem. We are the
first to present a principled method termed Social Choice Language Model for
dealing with these tradeoffs for LLM-designed rewards for multiagent planners
in general and restless bandits in particular. The novel part of our model is a
transparent and configurable selection component, called an adjudicator,
external to the LLM that controls complex tradeoffs via a user-selected social
welfare function. Our experiments demonstrate that our model reliably selects
more effective, aligned, and balanced reward functions compared to purely
LLM-based approaches.

摘要：LLM  zunehmend verwendet werden, um Belohnungsfunktionen basierend auf menschlichen Präferenzen in Reinforcement Learning (RL) zu entwerfen. Wir konzentrieren uns auf LLM-entworfene Belohnungen für Restless Multi-Armed Bandits, ein Framework zur Zuweisung begrenzter Ressourcen unter Agenten. In Anwendungen wie dem öffentlichen Gesundheitswesen ermöglicht dieser Ansatz Basisgesundheitsfachkräften, automatisierte Zuweisungsentscheidungen auf die Bedürfnisse der Gemeinschaft zuzuschneiden. In Gegenwart mehrerer Agenten kann die Änderung der Belohnungsfunktion basierend auf menschlichen Präferenzen Untergruppen sehr unterschiedlich beeinflussen, was zu komplexen Kompromissen und einem mehrzielgerichteten Ressourcenzuweisungsproblem führt. Wir sind die Ersten, die eine prinzipielle Methode namens Social Choice Language Model für den Umgang mit diesen Kompromissen für LLM-entworfene Belohnungen für Multiagentenplaner im Allgemeinen und unruhige Banditen im Besonderen vorstellen. Der neuartige Teil unseres Modells ist eine transparente und konfigurierbare Auswahlkomponente, die als Schiedsrichter bezeichnet wird und sich außerhalb des LLM befindet und komplexe Kompromisse über eine vom Benutzer ausgewählte soziale Wohlfahrtsfunktion steuert. Unsere Experimente zeigen, dass unser Modell im Vergleich zu rein LLM-basierten Ansätzen zuverlässig effektivere, ausgerichtete und ausgewogene Belohnungsfunktionen auswählt.

##### **RoVRM: A Robust Visual Reward Model Optimized via Auxiliary Textual Preference Data**
2408.12109v1 by Chenglong Wang, Yang Gan, Yifu Huo, Yongyu Mu, Murun Yang, Qiaozhi He, Tong Xiao, Chunliang Zhang, Tongran Liu, Quan Du, Di Yang, Jingbo Zhu

Large vision-language models (LVLMs) often fail to align with human
preferences, leading to issues like generating misleading content without
proper visual context (also known as hallucination). A promising solution to
this problem is using human-preference alignment techniques, such as best-of-n
sampling and reinforcement learning. However, these techniques face the
difficulty arising from the scarcity of visual preference data, which is
required to train a visual reward model (VRM). In this work, we continue the
line of research. We present a Robust Visual Reward Model (RoVRM) which
improves human-preference alignment for LVLMs. RoVRM leverages auxiliary
textual preference data through a three-phase progressive training and optimal
transport-based preference data selection to effectively mitigate the scarcity
of visual preference data. We experiment with RoVRM on the commonly used
vision-language tasks based on the LLaVA-1.5-7B and -13B models. Experimental
results demonstrate that RoVRM consistently outperforms traditional VRMs.
Furthermore, our three-phase progressive training and preference data selection
approaches can yield consistent performance gains over ranking-based alignment
techniques, such as direct preference optimization.

摘要：大型视觉语言模型 (LVLMs) 经常无法与人类偏好保持一致，从而导致诸如在没有适当视觉背景下生成误导性内容（也称为幻觉）等问题。解决此问题的有希望的解决方案是使用人类偏好对齐技术，例如 n 中最佳采样和强化学习。然而，这些技术面临着视觉偏好数据稀缺带来的困难，而视觉偏好数据是训练视觉奖励模型 (VRM) 所必需的。在这项工作中，我们继续进行研究。我们提出了一个稳健视觉奖励模型 (RoVRM)，它改进了 LVLMs 的人类偏好对齐。RoVRM 通过三阶段渐进训练和基于最优传输的偏好数据选择来利用辅助文本偏好数据，以有效缓解视觉偏好数据的稀缺性。我们使用基于 LLaVA-1.5-7B 和 -13B 模型的常用视觉语言任务对 RoVRM 进行了实验。实验结果表明，RoVRM 始终优于传统的 VRM。此外，我们的三阶段渐进训练和偏好数据选择方法可以相对于基于排名的对齐技术（例如直接偏好优化）产生一致的性能提升。

##### **Extraction of Research Objectives, Machine Learning Model Names, and Dataset Names from Academic Papers and Analysis of Their Interrelationships Using LLM and Network Analysis**
2408.12097v1 by S. Nishio, H. Nonaka, N. Tsuchiya, A. Migita, Y. Banno, T. Hayashi, H. Sakaji, T. Sakumoto, K. Watabe

Machine learning is widely utilized across various industries. Identifying
the appropriate machine learning models and datasets for specific tasks is
crucial for the effective industrial application of machine learning. However,
this requires expertise in both machine learning and the relevant domain,
leading to a high learning cost. Therefore, research focused on extracting
combinations of tasks, machine learning models, and datasets from academic
papers is critically important, as it can facilitate the automatic
recommendation of suitable methods. Conventional information extraction methods
from academic papers have been limited to identifying machine learning models
and other entities as named entities. To address this issue, this study
proposes a methodology extracting tasks, machine learning methods, and dataset
names from scientific papers and analyzing the relationships between these
information by using LLM, embedding model, and network clustering. The proposed
method's expression extraction performance, when using Llama3, achieves an
F-score exceeding 0.8 across various categories, confirming its practical
utility. Benchmarking results on financial domain papers have demonstrated the
effectiveness of this method, providing insights into the use of the latest
datasets, including those related to ESG (Environmental, Social, and
Governance) data.

摘要：機器學習廣泛應用於各行各業。找出適當的機器學習模型和資料集來執行特定任務，對於機器學習在產業上的有效應用至關重要。然而，這需要具備機器學習和相關領域的專業知識，導致學習成本高昂。因此，專注於從學術論文中萃取出任務、機器學習模型和資料集的組合的研究至關重要，因為它可以促進自動推薦合適的方法。從學術論文中提取傳統資訊的方法一直侷限於將機器學習模型和其他實體識別為命名實體。為了解決這個問題，本研究提出了一種方法，從科學論文中萃取出任務、機器學習方法和資料集名稱，並使用 LLM、嵌入模型和網路聚類分析這些資訊之間的關係。所提出的方法在使用 Llama3 時，其表達式萃取效能達到各種類別的 F 分數超過 0.8，證實其實用性。在金融領域論文上的基準測試結果證明了此方法的有效性，提供了對最新資料集使用的見解，包括與 ESG（環境、社會和公司治理）資料相關的資料集。

##### **uMedSum: A Unified Framework for Advancing Medical Abstractive Summarization**
2408.12095v1 by Aishik Nagar, Yutong Liu, Andy T. Liu, Viktor Schlegel, Vijay Prakash Dwivedi, Arun-Kumar Kaliya-Perumal, Guna Pratheep Kalanchiam, Yili Tang, Robby T. Tan

Medical abstractive summarization faces the challenge of balancing
faithfulness and informativeness. Current methods often sacrifice key
information for faithfulness or introduce confabulations when prioritizing
informativeness. While recent advancements in techniques like in-context
learning (ICL) and fine-tuning have improved medical summarization, they often
overlook crucial aspects such as faithfulness and informativeness without
considering advanced methods like model reasoning and self-improvement.
Moreover, the field lacks a unified benchmark, hindering systematic evaluation
due to varied metrics and datasets. This paper addresses these gaps by
presenting a comprehensive benchmark of six advanced abstractive summarization
methods across three diverse datasets using five standardized metrics. Building
on these findings, we propose uMedSum, a modular hybrid summarization framework
that introduces novel approaches for sequential confabulation removal followed
by key missing information addition, ensuring both faithfulness and
informativeness. Our work improves upon previous GPT-4-based state-of-the-art
(SOTA) medical summarization methods, significantly outperforming them in both
quantitative metrics and qualitative domain expert evaluations. Notably, we
achieve an average relative performance improvement of 11.8% in reference-free
metrics over the previous SOTA. Doctors prefer uMedSum's summaries 6 times more
than previous SOTA in difficult cases where there are chances of confabulations
or missing information. These results highlight uMedSum's effectiveness and
generalizability across various datasets and metrics, marking a significant
advancement in medical summarization.

摘要：<paragraph>醫療摘要摘要面臨著平衡忠實度和資訊性的挑戰。目前的技術通常為了忠實度而犧牲關鍵資訊，或在優先考慮資訊性時引入虛構。雖然情境學習 (ICL) 和微調等技術的最新進展改善了醫療摘要，但它們常常忽略關鍵方面，例如忠實度和資訊性，而不考慮模型推理和自我改進等先進方法。此外，該領域缺乏統一的基準，由於指標和資料集不同而阻礙了系統性評估。本文透過使用五個標準化指標，在三個不同的資料集上對六種先進的抽象摘要方法進行全面基準測試，來解決這些差距。根據這些發現，我們提出 uMedSum，一個模組化混合摘要架構，它引入了新的方法，用於連續虛構移除，然後是關鍵遺失資訊新增，確保忠實度和資訊性。我們的研究改進了先前的基於 GPT-4 的最先進 (SOTA) 醫療摘要方法，在量化指標和定性領域專家評估中都顯著優於它們。值得注意的是，我們在無參考指標中實現了相對於先前 SOTA 平均 11.8% 的相對效能提升。在可能有虛構或遺失資訊的困難案例中，醫生更喜歡 uMedSum 的摘要，比先前的 SOTA 多 6 倍。這些結果突顯了 uMedSum 在各種資料集和指標中的有效性和普遍性，標誌著醫療摘要的重大進展。</paragraph>

##### **Unlocking Attributes' Contribution to Successful Camouflage: A Combined Textual and VisualAnalysis Strategy**
2408.12086v1 by Hong Zhang, Yixuan Lyu, Qian Yu, Hanyang Liu, Huimin Ma, Ding Yuan, Yifan Yang

In the domain of Camouflaged Object Segmentation (COS), despite continuous
improvements in segmentation performance, the underlying mechanisms of
effective camouflage remain poorly understood, akin to a black box. To address
this gap, we present the first comprehensive study to examine the impact of
camouflage attributes on the effectiveness of camouflage patterns, offering a
quantitative framework for the evaluation of camouflage designs. To support
this analysis, we have compiled the first dataset comprising descriptions of
camouflaged objects and their attribute contributions, termed COD-Text And
X-attributions (COD-TAX). Moreover, drawing inspiration from the hierarchical
process by which humans process information: from high-level textual
descriptions of overarching scenarios, through mid-level summaries of local
areas, to low-level pixel data for detailed analysis. We have developed a
robust framework that combines textual and visual information for the task of
COS, named Attribution CUe Modeling with Eye-fixation Network (ACUMEN). ACUMEN
demonstrates superior performance, outperforming nine leading methods across
three widely-used datasets. We conclude by highlighting key insights derived
from the attributes identified in our study. Code:
https://github.com/lyu-yx/ACUMEN.

摘要：在偽裝物體分割 (COS) 領域中，儘管分割效能持續改進，但有效的偽裝背後機制仍鮮為人知，就像個黑盒子。為了解決這個問題，我們提出了第一個全面的研究，探討偽裝屬性對偽裝樣式有效性的影響，並提供一個用於評估偽裝設計的量化架構。為了支持這個分析，我們編制了第一個包含偽裝物體描述及其屬性貢獻的資料集，稱為 COD-Text 和 X-attributions (COD-TAX)。此外，從人類處理資訊的分層過程汲取靈感：從概括場景的高階文字描述，到區域中階摘要，再到用於詳細分析的低階像素資料。我們開發了一個穩健的架構，結合文字和視覺資訊，用於 COS 任務，稱為 Attribution CUe Modeling with Eye-fixation Network (ACUMEN)。ACUMEN 展現出優異的效能，在三個廣泛使用的資料集上勝過九種領先方法。我們最後強調了從研究中識別出的屬性中得出的關鍵見解。程式碼：
https://github.com/lyu-yx/ACUMEN。

##### **Exploring the Feasibility of Automated Data Standardization using Large Language Models for Seamless Positioning**
2408.12080v1 by Max J. L. Lee, Ju Lin, Li-Ta Hsu

We propose a feasibility study for real-time automated data standardization
leveraging Large Language Models (LLMs) to enhance seamless positioning systems
in IoT environments. By integrating and standardizing heterogeneous sensor data
from smartphones, IoT devices, and dedicated systems such as Ultra-Wideband
(UWB), our study ensures data compatibility and improves positioning accuracy
using the Extended Kalman Filter (EKF). The core components include the
Intelligent Data Standardization Module (IDSM), which employs a fine-tuned LLM
to convert varied sensor data into a standardized format, and the
Transformation Rule Generation Module (TRGM), which automates the creation of
transformation rules and scripts for ongoing data standardization. Evaluated in
real-time environments, our study demonstrates adaptability and scalability,
enhancing operational efficiency and accuracy in seamless navigation. This
study underscores the potential of advanced LLMs in overcoming sensor data
integration complexities, paving the way for more scalable and precise IoT
navigation solutions.

摘要：我們提出一個可行性研究，用於實時自動化資料標準化，利用大型語言模型 (LLM) 來增強物聯網環境中的無縫定位系統。透過整合和標準化來自智慧型手機、物聯網裝置和專用系統（例如超寬頻 (UWB)）的異質感測器資料，我們的研究確保資料相容性，並使用擴展卡爾曼濾波器 (EKF) 改善定位精確度。核心元件包括智慧資料標準化模組 (IDSM)，它採用微調的 LLM 將各種感測器資料轉換為標準化格式，以及轉換規則產生模組 (TRGM)，它自動化持續資料標準化的轉換規則和指令碼的建立。在實時環境中評估，我們的研究展示了適應性和可擴充性，增強了無縫導航的運作效率和精確度。這項研究強調了進階 LLM 在克服感測器資料整合複雜性方面的潛力，為更具可擴充性和精確度的物聯網導航解決方案鋪路。

##### **High-Quality Data Augmentation for Low-Resource NMT: Combining a Translation Memory, a GAN Generator, and Filtering**
2408.12079v1 by Hengjie Liu, Ruibo Hou, Yves Lepage

Back translation, as a technique for extending a dataset, is widely used by
researchers in low-resource language translation tasks. It typically translates
from the target to the source language to ensure high-quality translation
results. This paper proposes a novel way of utilizing a monolingual corpus on
the source side to assist Neural Machine Translation (NMT) in low-resource
settings. We realize this concept by employing a Generative Adversarial Network
(GAN), which augments the training data for the discriminator while mitigating
the interference of low-quality synthetic monolingual translations with the
generator. Additionally, this paper integrates Translation Memory (TM) with
NMT, increasing the amount of data available to the generator. Moreover, we
propose a novel procedure to filter the synthetic sentence pairs during the
augmentation process, ensuring the high quality of the data.

摘要：回譯作為擴展資料集的一種技術，廣泛應用於低資源語言翻譯任務中。它通常從目標語言翻譯成原始語言，以確保高品質的翻譯結果。本文提出了一種新穎的方法，利用原始語言端的單語語料庫來協助低資源環境中的神經機器翻譯 (NMT)。我們透過使用生成對抗網路 (GAN) 來實現這個概念，它在減輕低品質合成單語翻譯對生成器的干擾的同時，增加了判別器的訓練資料。此外，本文將翻譯記憶體 (TM) 與 NMT 整合，增加了生成器可用的資料量。此外，我們提出了一種新的程序，在擴充過程中過濾合成句子對，確保資料的高品質。

##### **ConflictBank: A Benchmark for Evaluating the Influence of Knowledge Conflicts in LLM**
2408.12076v1 by Zhaochen Su, Jun Zhang, Xiaoye Qu, Tong Zhu, Yanshu Li, Jiashuo Sun, Juntao Li, Min Zhang, Yu Cheng

Large language models (LLMs) have achieved impressive advancements across
numerous disciplines, yet the critical issue of knowledge conflicts, a major
source of hallucinations, has rarely been studied. Only a few research explored
the conflicts between the inherent knowledge of LLMs and the retrieved
contextual knowledge. However, a thorough assessment of knowledge conflict in
LLMs is still missing. Motivated by this research gap, we present ConflictBank,
the first comprehensive benchmark developed to systematically evaluate
knowledge conflicts from three aspects: (i) conflicts encountered in retrieved
knowledge, (ii) conflicts within the models' encoded knowledge, and (iii) the
interplay between these conflict forms. Our investigation delves into four
model families and twelve LLM instances, meticulously analyzing conflicts
stemming from misinformation, temporal discrepancies, and semantic divergences.
Based on our proposed novel construction framework, we create 7,453,853
claim-evidence pairs and 553,117 QA pairs. We present numerous findings on
model scale, conflict causes, and conflict types. We hope our ConflictBank
benchmark will help the community better understand model behavior in conflicts
and develop more reliable LLMs.

摘要：大型語言模型 (LLM) 在許多領域中取得令人印象深刻的進展，但知識衝突這個造成幻覺的主要來源，卻鮮少被研究。只有少數研究探討 LLM 內建知識與擷取的脈絡知識之間的衝突。然而，對於 LLM 中知識衝突的徹底評估仍付之闕如。受此研究缺口啟發，我們提出 ConflictBank，這是第一個用來系統化評量知識衝突的全面性基準，從三個面向進行評估：(i) 擷取知識中遭遇的衝突、(ii) 模型編碼知識中的衝突，以及 (iii) 這些衝突形式之間的交互作用。我們的調查深入探討四個模型家族和十二個 LLM 實例，仔細分析源自錯誤資訊、時間差異和語意差異的衝突。根據我們提出的新穎建構架構，我們建立了 7,453,853 個主張證據對和 553,117 個問答對。我們提出許多關於模型規模、衝突原因和衝突類型的發現。我們希望我們的 ConflictBank 基準能幫助社群更了解模型在衝突中的行為，並開發出更可靠的 LLM。

##### **Transformers As Approximations of Solomonoff Induction**
2408.12065v1 by Nathan Young, Michael Witbrock

Solomonoff Induction is an optimal-in-the-limit unbounded algorithm for
sequence prediction, representing a Bayesian mixture of every computable
probability distribution and performing close to optimally in predicting any
computable sequence.
  Being an optimal form of computational sequence prediction, it seems
plausible that it may be used as a model against which other methods of
sequence prediction might be compared.
  We put forth and explore the hypothesis that Transformer models - the basis
of Large Language Models - approximate Solomonoff Induction better than any
other extant sequence prediction method. We explore evidence for and against
this hypothesis, give alternate hypotheses that take this evidence into
account, and outline next steps for modelling Transformers and other kinds of
AI in this way.

摘要：Solomonoff 歸納法是一種用於序列預測的極限最優無界演算法，它代表了所有可計算機率分布的貝氏混合，並且在預測任何可計算序列時接近最佳。
作為一種計算序列預測的最佳形式，似乎有可能將它用作一個模型，用以比較其他序列預測方法。
我們提出並探討了以下假設：Transformer 模型（大型語言模型的基礎）比任何其他現存序列預測方法更接近 Solomonoff 歸納法。我們探討了支持和反對此假設的證據，提出了考慮此證據的備用假設，並概述了以這種方式對 Transformer 和其他種類的 AI 進行建模的後續步驟。

##### **A Deconfounding Approach to Climate Model Bias Correction**
2408.12063v1 by Wentao Gao, Jiuyong Li, Debo Cheng, Lin Liu, Jixue Liu, Thuc Duy Le, Xiaojing Du, Xiongren Chen, Yanchang Zhao, Yun Chen

Global Climate Models (GCMs) are crucial for predicting future climate
changes by simulating the Earth systems. However, GCM outputs exhibit
systematic biases due to model uncertainties, parameterization simplifications,
and inadequate representation of complex climate phenomena. Traditional bias
correction methods, which rely on historical observation data and statistical
techniques, often neglect unobserved confounders, leading to biased results.
This paper proposes a novel bias correction approach to utilize both GCM and
observational data to learn a factor model that captures multi-cause latent
confounders. Inspired by recent advances in causality based time series
deconfounding, our method first constructs a factor model to learn latent
confounders from historical data and then applies them to enhance the bias
correction process using advanced time series forecasting models. The
experimental results demonstrate significant improvements in the accuracy of
precipitation outputs. By addressing unobserved confounders, our approach
offers a robust and theoretically grounded solution for climate model bias
correction.

摘要：全球氣候模式 (GCM) 對於預測未來氣候變化至關重要，方法是模擬地球系統。然而，GCM 輸出會因為模型不確定性、參數化簡化和複雜氣候現象的不足表示而展現出系統性偏差。傳統的偏差修正方法依賴於歷史觀測資料和統計技術，常常忽略未觀察到的混雜因素，導致有偏差的結果。本文提出了一種新穎的偏差修正方法，利用 GCM 和觀測資料來學習一個因子模型，以捕捉多因潛在混雜因素。受到因果關係時間序列去混雜的最新進展啟發，我們的模型首先建構一個因子模型，從歷史資料學習潛在混雜因素，然後應用它們來使用進階時間序列預測模型增強偏差修正過程。實驗結果證明降水輸出的準確性有顯著的改善。我們的模型透過解決未觀察到的混雜因素，為氣候模型偏差修正提供了一個穩健且理論紮實的解決方案。

##### **Enhancing Sampling Protocol for Robust Point Cloud Classification**
2408.12062v1 by Chongshou Li, Pin Tang, Xinke Li, Tianrui Li

Established sampling protocols for 3D point cloud learning, such as Farthest
Point Sampling (FPS) and Fixed Sample Size (FSS), have long been recognized and
utilized. However, real-world data often suffer from corrputions such as sensor
noise, which violates the benignness assumption of point cloud in current
protocols. Consequently, they are notably vulnerable to noise, posing
significant safety risks in critical applications like autonomous driving. To
address these issues, we propose an enhanced point cloud sampling protocol,
PointDR, which comprises two components: 1) Downsampling for key point
identification and 2) Resampling for flexible sample size. Furthermore,
differentiated strategies are implemented for training and inference processes.
Particularly, an isolation-rated weight considering local density is designed
for the downsampling method, assisting it in performing random key points
selection in the training phase and bypassing noise in the inference phase. A
local-geometry-preserved upsampling is incorporated into resampling,
facilitating it to maintain a stochastic sample size in the training stage and
complete insufficient data in the inference. It is crucial to note that the
proposed protocol is free of model architecture altering and extra learning,
thus minimal efforts are demanded for its replacement of the existing one.
Despite the simplicity, it substantially improves the robustness of point cloud
learning, showcased by outperforming the state-of-the-art methods on multiple
benchmarks of corrupted point cloud classification. The code will be available
upon the paper's acceptance.

摘要：<paragraph>現有 3D 點雲學習的採樣協定，例如最遠點採樣 (FPS) 和固定樣本大小 (FSS)，早已被廣泛認可和使用。然而，真實世界中的資料常常會受到感測器雜訊等損害，這違背了目前協定中點雲的良性假設。因此，它們特別容易受到雜訊影響，對自動駕駛等關鍵應用構成重大的安全風險。為了解決這些問題，我們提出了一種增強的點雲採樣協定 PointDR，它包含兩個組成部分：1) 關鍵點識別的下採樣和 2) 靈活樣本大小的再採樣。此外，針對訓練和推論過程實施了差異化的策略。特別是，考慮局部密度的隔離評級權重是為下採樣方法設計的，協助它在訓練階段執行隨機關鍵點選擇，並在推論階段繞過雜訊。局部幾何保留上採樣整合到再採樣中，協助它在訓練階段維持隨機樣本大小，並在推論中完成不充分的資料。必須注意的是，所提出的協定不涉及模型架構的變更和額外的學習，因此只需最小的工作量就能取代現有的協定。儘管很簡單，它大幅提升了點雲學習的穩健性，並在多個損壞點雲分類基準測試中優於最先進的方法。論文通過後，將提供程式碼。</paragraph>

##### **Evidence-backed Fact Checking using RAG and Few-Shot In-Context Learning with LLMs**
2408.12060v1 by Ronit Singhal, Pransh Patwa, Parth Patwa, Aman Chadha, Amitava Das

Given the widespread dissemination of misinformation on social media,
implementing fact-checking mechanisms for online claims is essential. Manually
verifying every claim is highly challenging, underscoring the need for an
automated fact-checking system. This paper presents our system designed to
address this issue. We utilize the Averitec dataset to assess the veracity of
claims. In addition to veracity prediction, our system provides supporting
evidence, which is extracted from the dataset. We develop a Retrieve and
Generate (RAG) pipeline to extract relevant evidence sentences from a knowledge
base, which are then inputted along with the claim into a large language model
(LLM) for classification. We also evaluate the few-shot In-Context Learning
(ICL) capabilities of multiple LLMs. Our system achieves an 'Averitec' score of
0.33, which is a 22% absolute improvement over the baseline. All code will be
made available on All code will be made available on
https://github.com/ronit-singhal/evidence-backed-fact-checking-using-rag-and-few-shot-in-context-learning-with-llms.

摘要：鉴于社交媒体上错误信息的广泛传播，为在线声明实施事实核查机制至关重要。手动验证每个声明极具挑战性，这凸显了对自动事实核查系统的需求。本文介绍了我们为解决此问题而设计的系统。我们利用 Averitec 数据集来评估声明的真实性。除了真实性预测之外，我们的系统还提供了从数据集中提取的支持证据。我们开发了一个检索和生成 (RAG) 管道，以从知识库中提取相关的证据句子，然后将其与声明一起输入大型语言模型 (LLM) 进行分类。我们还评估了多个 LLM 的少量 In-Context Learning (ICL) 功能。我们的系统实现了 0.33 的“Averitec”分数，比基线提高了 22% 的绝对值。所有代码将在 https://github.com/ronit-singhal/evidence-backed-fact-checking-using-rag-and-few-shot-in-context-learning-with-llms 上提供。

##### **Aligning (Medical) LLMs for (Counterfactual) Fairness**
2408.12055v1 by Raphael Poulain, Hamed Fayyaz, Rahmatollah Beheshti

Large Language Models (LLMs) have emerged as promising solutions for a
variety of medical and clinical decision support applications. However, LLMs
are often subject to different types of biases, which can lead to unfair
treatment of individuals, worsening health disparities, and reducing trust in
AI-augmented medical tools. Aiming to address this important issue, in this
study, we present a new model alignment approach for aligning LLMs using a
preference optimization method within a knowledge distillation framework. Prior
to presenting our proposed method, we first use an evaluation framework to
conduct a comprehensive (largest to our knowledge) empirical evaluation to
reveal the type and nature of existing biases in LLMs used for medical
applications. We then offer a bias mitigation technique to reduce the unfair
patterns in LLM outputs across different subgroups identified by the protected
attributes. We show that our mitigation method is effective in significantly
reducing observed biased patterns. Our code is publicly available at
\url{https://github.com/healthylaife/FairAlignmentLLM}.

摘要：大型語言模型 (LLM) 已成為各種醫療和臨床決策支援應用程式中極具前景的解決方案。然而，LLM 通常會受到不同類型的偏見影響，這可能會導致對個人不公平的待遇、加劇健康差距，並降低對 AI 增強醫療工具的信任。為了解決這個重要問題，我們在這項研究中提出了一種新的模型對齊方法，使用知識提煉架構中的偏好最佳化方法來對齊 LLM。在提出我們建議的方法之前，我們首先使用評估架構進行全面（據我們所知最大規模）的實證評估，以揭示用於醫療應用程式的 LLM 中現有偏見的類型和性質。然後，我們提供一種偏見緩解技術，以減少受保護屬性識別的不同子群組中 LLM 輸出的不公平模式。我們表明，我們的緩解方法可以有效顯著減少觀察到的偏見模式。我們的程式碼可在 \url{https://github.com/healthylaife/FairAlignmentLLM} 公開取得。

##### **Reasoning and Tools for Human-Level Forecasting**
2408.12036v1 by Elvis Hsieh, Preston Fu, Jonathan Chen

Language models (LMs) trained on web-scale datasets are largely successful
due to their ability to memorize large amounts of training data, even if only
present in a few examples. These capabilities are often desirable in evaluation
on tasks such as question answering but raise questions about whether these
models can exhibit genuine reasoning or succeed only at mimicking patterns from
the training data. This distinction is particularly salient in forecasting
tasks, where the answer is not present in the training data, and the model must
reason to make logical deductions. We present Reasoning and Tools for
Forecasting (RTF), a framework of reasoning-and-acting (ReAct) agents that can
dynamically retrieve updated information and run numerical simulation with
equipped tools. We evaluate our model with questions from competitive
forecasting platforms and demonstrate that our method is competitive with and
can outperform human predictions. This suggests that LMs, with the right tools,
can indeed think and adapt like humans, offering valuable insights for
real-world decision-making.

摘要：語言模型 (LM) 在網路規模資料集上訓練後，由於它們能夠記住大量的訓練資料，即使這些資料只出現在少數範例中，因此在很大程度上獲得成功。這些能力通常在問答等任務的評估中是可取的，但引發了這些模型是否能表現出真正的推理或僅成功模仿訓練資料中的模式等問題。這種區別在預測任務中特別明顯，在預測任務中，答案不存在於訓練資料中，而且模型必須推理才能進行邏輯推論。我們提出預測推理和工具 (RTF)，一個推理和行動 (ReAct) 代理架構，它可以動態擷取更新的資訊，並使用已裝備的工具執行數值模擬。我們使用來自競爭預測平台的問題來評估我們的模型，並證明我們的模型具有競爭力，而且可以優於人類預測。這表明 LM 在使用正確的工具後，確實可以像人類一樣思考和適應，為現實世界的決策提供有價值的見解。

##### **Let Community Rules Be Reflected in Online Content Moderation**
2408.12035v1 by Wangjiaxuan Xin, Kanlun Wang, Zhe Fu, Lina Zhou

Content moderation is a widely used strategy to prevent the dissemination of
irregular information on social media platforms. Despite extensive research on
developing automated models to support decision-making in content moderation,
there remains a notable scarcity of studies that integrate the rules of online
communities into content moderation. This study addresses this gap by proposing
a community rule-based content moderation framework that directly integrates
community rules into the moderation of user-generated content. Our experiment
results with datasets collected from two domains demonstrate the superior
performance of models based on the framework to baseline models across all
evaluation metrics. In particular, incorporating community rules substantially
enhances model performance in content moderation. The findings of this research
have significant research and practical implications for improving the
effectiveness and generalizability of content moderation models in online
communities.

摘要：內容審查是一種廣泛使用的策略，用於防止在社群媒體平台上散布不正確的資訊。儘管在開發自動化模型以支援內容審查中的決策制定方面進行了廣泛的研究，但整合線上社群規則進入內容審查的研究仍然相當稀少。本研究透過提出一個以社群規則為基礎的內容審查架構來解決這個差距，該架構將社群規則直接整合到使用者產製內容的審查中。我們從兩個領域收集的資料集進行的實驗結果，證明基於架構的模型在所有評估指標上都優於基線模型。特別是，納入社群規則大幅提升了內容審查中的模型效能。本研究的發現對於提升線上社群中內容審查模型的效能和可概化性具有重要的研究和實務意涵。

##### **A Constraint Programming Approach to Fair High School Course Scheduling**
2408.12032v1 by Mitsuka Kiyohara, Masakazu Ishihata

Issues of inequity in U.S. high schools' course scheduling did not previously
exist. However, in recent years, with the increase in student population and
course variety, students perceive that the course scheduling method is unfair.
Current integer programming (IP) methods to the high school scheduling problem
(HSSP) fall short in addressing these fairness concerns. The purpose of this
research is to develop a solution methodology that generates feasible and fair
course schedules using student preferences. Utilizing principles of fairness,
which have been well studied in market design, we define the fair high school
scheduling problem (FHSSP), a novel extension to the HSSP, and devise a
corresponding algorithm based on integer programming to solve the FHSSP. We
test our approach on a real course request dataset from a high school in
California, USA. Results show that our algorithm can generate schedules that
are both feasible and fair. In this paper, we demonstrate that our IP algorithm
not only solves the HSSP and FHSSP in the United States but has the potential
to be applied to various real-world scheduling problems. Additionally, we show
the feasibility of integrating human emotions into mathematical modeling.

摘要：美國高中課程排程的不公平問題以前不存在。然而，近年來，隨著學生人數和課程類型的增加，學生認為課程排程方法不公平。目前針對高中排程問題 (HSSP) 的整數規劃 (IP) 方法無法解決這些公平性問題。本研究的目的是開發一種解決方法，該方法使用學生偏好來生成可行且公平的課程排程。利用在市場設計中已得到充分研究的公平性原則，我們定義了公平高中排程問題 (FHSSP)，這是 HSSP 的一種新延伸，並設計了一種基於整數規劃的對應演算法來解決 FHSSP。我們在美國加州一所高中的真實課程請求資料集上測試了我們的做法。結果表明，我們的演算法可以生成可行且公平的排程。在本文中，我們證明我們的 IP 演算法不僅解決了美國的 HSSP 和 FHSSP，而且有可能應用於各種實際排程問題。此外，我們展示了將人類情緒整合到數學建模中的可行性。

##### **Federated Diabetes Prediction in Canadian Adults Using Real-world Cross-Province Primary Care Data**
2408.12029v1 by Guojun Tang, Jason E. Black, Tyler S. Williamson, Steve H. Drew

Integrating Electronic Health Records (EHR) and the application of machine
learning present opportunities for enhancing the accuracy and accessibility of
data-driven diabetes prediction. In particular, developing data-driven machine
learning models can provide early identification of patients with high risk for
diabetes, potentially leading to more effective therapeutic strategies and
reduced healthcare costs. However, regulation restrictions create barriers to
developing centralized predictive models. This paper addresses the challenges
by introducing a federated learning approach, which amalgamates predictive
models without centralized data storage and processing, thus avoiding privacy
issues. This marks the first application of federated learning to predict
diabetes using real clinical datasets in Canada extracted from the Canadian
Primary Care Sentinel Surveillance Network (CPCSSN) without crossprovince
patient data sharing. We address class-imbalance issues through downsampling
techniques and compare federated learning performance against province-based
and centralized models. Experimental results show that the federated MLP model
presents a similar or higher performance compared to the model trained with the
centralized approach. However, the federated logistic regression model showed
inferior performance compared to its centralized peer.

摘要：整合電子健康記錄 (EHR) 和機器學習的應用為增強資料驅動糖尿病預測的準確性和可及性提供了機會。特別是，開發資料驅動的機器學習模型可以及早找出糖尿病高風險患者，進而可能導致更有效的治療策略和降低醫療保健成本。然而，法規限制會為開發集中式預測模型製造障礙。本文透過介紹聯邦學習方法來解決挑戰，這種方法結合預測模型，而無需集中式資料儲存和處理，從而避免隱私問題。這標誌著首次應用聯邦學習來預測糖尿病，方法是使用從加拿大初級照護哨兵監控網絡 (CPCSSN) 萃取的加拿大真實臨床資料集，而無需跨省份分享患者資料。我們透過降採樣技術來解決類別不平衡問題，並比較聯邦學習效能與基於省份和集中式的模型。實驗結果顯示，與使用集中式方法訓練的模型相比，聯邦 MLP 模型表現出相似或更高的效能。然而，與其集中式的同儕相比，聯邦邏輯迴歸模型表現出較差的效能。

##### **Exploring Large Language Models for Feature Selection: A Data-centric Perspective**
2408.12025v1 by Dawei Li, Zhen Tan, Huan Liu

The rapid advancement of Large Language Models (LLMs) has significantly
influenced various domains, leveraging their exceptional few-shot and zero-shot
learning capabilities. In this work, we aim to explore and understand the
LLMs-based feature selection methods from a data-centric perspective. We begin
by categorizing existing feature selection methods with LLMs into two groups:
data-driven feature selection which requires samples values to do statistical
inference and text-based feature selection which utilizes prior knowledge of
LLMs to do semantical associations using descriptive context. We conduct
extensive experiments in both classification and regression tasks with LLMs in
various sizes (e.g., GPT-4, ChatGPT and LLaMA-2). Our findings emphasize the
effectiveness and robustness of text-based feature selection methods and
showcase their potentials using a real-world medical application. We also
discuss the challenges and future opportunities in employing LLMs for feature
selection, offering insights for further research and development in this
emerging field.

摘要：大型語言模型 (LLM) 的快速進步顯著地影響了各種領域，利用它們卓越的少樣本和零樣本學習能力。在這項工作中，我們旨在從以數據為中心的觀點探索和理解基於 LLM 的特徵選擇方法。我們首先將現有的 LLM 特徵選擇方法分類為兩組：需要樣本值來進行統計推論的數據驅動特徵選擇，以及利用 LLM 的先驗知識使用描述性上下文進行語義關聯的基於文本的特徵選擇。我們在各種規模的 LLM（例如 GPT-4、ChatGPT 和 LLaMA-2）中對分類和迴歸任務進行了廣泛的實驗。我們的研究結果強調了基於文本的特徵選擇方法的有效性和穩健性，並展示了它們在現實世界醫療應用中的潛力。我們還討論了在特徵選擇中採用 LLM 的挑戰和未來機會，為這個新興領域的進一步研究和開發提供了見解。

##### **Limitations in Employing Natural Language Supervision for Sensor-Based Human Activity Recognition -- And Ways to Overcome Them**
2408.12023v1 by Harish Haresamudram, Apoorva Beedu, Mashfiqui Rabbi, Sankalita Saha, Irfan Essa, Thomas Ploetz

Cross-modal contrastive pre-training between natural language and other
modalities, e.g., vision and audio, has demonstrated astonishing performance
and effectiveness across a diverse variety of tasks and domains. In this paper,
we investigate whether such natural language supervision can be used for
wearable sensor based Human Activity Recognition (HAR), and discover
that-surprisingly-it performs substantially worse than standard end-to-end
training and self-supervision. We identify the primary causes for this as:
sensor heterogeneity and the lack of rich, diverse text descriptions of
activities. To mitigate their impact, we also develop strategies and assess
their effectiveness through an extensive experimental evaluation. These
strategies lead to significant increases in activity recognition, bringing
performance closer to supervised and self-supervised training, while also
enabling the recognition of unseen activities and cross modal retrieval of
videos. Overall, our work paves the way for better sensor-language learning,
ultimately leading to the development of foundational models for HAR using
wearables.

摘要：跨模態對比預訓練在自然語言與其他模態（例如視覺和音訊）之間已展現驚人的效能和有效性，涵蓋各種任務和領域。在本文中，我們探討此類自然語言監督能否用於可穿戴式感測器為基礎的人類活動辨識 (HAR)，並發現它表現遠遜於標準端到端訓練和自我監督。我們找出其主要原因為：感測器異質性和缺乏豐富、多樣的文字活動描述。為了減輕其影響，我們也制定策略並透過廣泛的實驗評估來評量其有效性。這些策略大幅提升活動辨識，讓效能更接近監督式和自我監督式訓練，同時也讓辨識未見過的活動和影片的跨模態檢索成為可能。總體而言，我們的研究為更好的感測器語言學習鋪路，最終導致使用可穿戴式裝置進行 HAR 的基礎模型開發。

##### **Understanding Epistemic Language with a Bayesian Theory of Mind**
2408.12022v1 by Lance Ying, Tan Zhi-Xuan, Lionel Wong, Vikash Mansinghka, Joshua B. Tenenbaum

How do people understand and evaluate claims about others' beliefs, even
though these beliefs cannot be directly observed? In this paper, we introduce a
cognitive model of epistemic language interpretation, grounded in Bayesian
inferences about other agents' goals, beliefs, and intentions: a
language-augmented Bayesian theory-of-mind (LaBToM). By translating natural
language into an epistemic ``language-of-thought'', then evaluating these
translations against the inferences produced by inverting a probabilistic
generative model of rational action and perception, LaBToM captures graded
plausibility judgments about epistemic claims. We validate our model in an
experiment where participants watch an agent navigate a maze to find keys
hidden in boxes needed to reach their goal, then rate sentences about the
agent's beliefs. In contrast with multimodal LLMs (GPT-4o, Gemini Pro) and
ablated models, our model correlates highly with human judgments for a wide
range of expressions, including modal language, uncertainty expressions,
knowledge claims, likelihood comparisons, and attributions of false belief.

摘要：人們如何理解並評估對他人信念的說法，即使這些信念無法直接觀察到？在本文中，我們引入了認知語言詮釋模型，基於對其他代理目標、信念和意圖的貝氏推論：一種語言增強的貝氏心智理論 (LaBToM)。透過將自然語言轉換為認知「思考語言」，然後根據逆向機率產生模型的理性行動和感知推論來評估這些翻譯，LaBToM 捕捉到了關於認知主張的分級似真判斷。我們在一個實驗中驗證了我們的模型，在這個實驗中，參與者觀看一個代理在迷宮中導航以尋找藏在盒子中的鑰匙，這些鑰匙是他們達到目標所必需的，然後對代理的信念評分句子。與多模態 LLM（GPT-4o、Gemini Pro）和消融模型相比，我們的模型與人類對各種表達式的判斷高度相關，包括情態語言、不確定性表達式、知識主張、可能性比較和錯誤信念的歸因。

##### **QuaCK-TSF: Quantum-Classical Kernelized Time Series Forecasting**
2408.12007v1 by Abdallah Aaraba, Soumaya Cherkaoui, Ola Ahmad, Jean-Frédéric Laprade, Olivier Nahman-Lévesque, Alexis Vieloszynski, Shengrui Wang

Forecasting in probabilistic time series is a complex endeavor that extends
beyond predicting future values to also quantifying the uncertainty inherent in
these predictions. Gaussian process regression stands out as a Bayesian machine
learning technique adept at addressing this multifaceted challenge. This paper
introduces a novel approach that blends the robustness of this Bayesian
technique with the nuanced insights provided by the kernel perspective on
quantum models, aimed at advancing quantum kernelized probabilistic
forecasting. We incorporate a quantum feature map inspired by Ising
interactions and demonstrate its effectiveness in capturing the temporal
dependencies critical for precise forecasting. The optimization of our model's
hyperparameters circumvents the need for computationally intensive gradient
descent by employing gradient-free Bayesian optimization. Comparative
benchmarks against established classical kernel models are provided, affirming
that our quantum-enhanced approach achieves competitive performance.

摘要：機率時間序列的預測是一項複雜的工作，它不只預測未來值，還量化這些預測中固有的不確定性。高斯過程回歸作為一種貝氏機器學習技術，擅長應對這項多方面的挑戰。本文介紹了一種新方法，它結合了這種貝氏技術的穩健性，以及量子模型中核觀點提供的細微見解，旨在推進量子核化機率預測。我們結合了一個受 Ising 交互作用啟發的量子特徵映射，並展示了它在捕捉對於精確預測至關重要的時間依賴性方面的有效性。我們模型的超參數最佳化繞過了對計算密集型梯度下降的需求，而是採用了無梯度的貝氏最佳化。我們提供了與已建立的經典核模型的比較基準，肯定了我們增強量子的方法達到了有競爭力的效能。

##### **RAG-Optimized Tibetan Tourism LLMs: Enhancing Accuracy and Personalization**
2408.12003v1 by Jinhu Qi, Shuai Yan, Yibo Zhang, Wentao Zhang, Rong Jin, Yuwei Hu, Ke Wang

With the development of the modern social economy, tourism has become an
important way to meet people's spiritual needs, bringing development
opportunities to the tourism industry. However, existing large language models
(LLMs) face challenges in personalized recommendation capabilities and the
generation of content that can sometimes produce hallucinations. This study
proposes an optimization scheme for Tibet tourism LLMs based on
retrieval-augmented generation (RAG) technology. By constructing a database of
tourist viewpoints and processing the data using vectorization techniques, we
have significantly improved retrieval accuracy. The application of RAG
technology effectively addresses the hallucination problem in content
generation. The optimized model shows significant improvements in fluency,
accuracy, and relevance of content generation. This research demonstrates the
potential of RAG technology in the standardization of cultural tourism
information and data analysis, providing theoretical and technical support for
the development of intelligent cultural tourism service systems.

摘要：隨著現代社會經濟的發展，旅遊已成為滿足人們精神需求的重要途徑，為旅遊產業帶來發展機遇。但現有的大語言模型（LLMs）在個性化推薦能力和內容生成方面面臨挑戰，有時會產生幻覺。本研究提出基於檢索增強生成（RAG）技術的西藏旅遊LLMs優化方案。通過構建旅遊景點數據庫，並利用向量化技術對數據進行處理，顯著提升了檢索準確率。RAG技術的應用有效地解決了內容生成中的幻覺問題。優化的模型在內容生成的流暢性、準確性和相關性方面均有顯著提升。本研究驗證了RAG技術在文化旅遊信息標準化和數據分析方面的潛力，為智能文化旅遊服務系統的發展提供理論和技術支撐。

##### **SimBench: A Rule-Based Multi-Turn Interaction Benchmark for Evaluating an LLM's Ability to Generate Digital Twins**
2408.11987v1 by Jingquan Wang, Harry Zhang, Huzaifa Mustafa Unjhawala, Peter Negrut, Shu Wang, Khailanii Slaton, Radu Serban, Jin-Long Wu, Dan Negrut

We introduce SimBench, a benchmark designed to evaluate the proficiency of
student large language models (S-LLMs) in generating digital twins (DTs) that
can be used in simulators for virtual testing. Given a collection of S-LLMs,
this benchmark enables the ranking of the S-LLMs based on their ability to
produce high-quality DTs. We demonstrate this by comparing over 20 open- and
closed-source S-LLMs. Using multi-turn interactions, SimBench employs a
rule-based judge LLM (J-LLM) that leverages both predefined rules and
human-in-the-loop guidance to assign scores for the DTs generated by the S-LLM,
thus providing a consistent and expert-inspired evaluation protocol. The J-LLM
is specific to a simulator, and herein the proposed benchmarking approach is
demonstrated in conjunction with the Chrono multi-physics simulator. Chrono
provided the backdrop used to assess an S-LLM in relation to the latter's
ability to create digital twins for multibody dynamics, finite element
analysis, vehicle dynamics, robotic dynamics, and sensor simulations. The
proposed benchmarking principle is broadly applicable and enables the
assessment of an S-LLM's ability to generate digital twins for other simulation
packages. All code and data are available at
https://github.com/uwsbel/SimBench.

摘要：<paragraph>我們推出 SimBench，這是一個基準，旨在評估學生大型語言模型 (S-LLM) 在產生可於模擬器中用於虛擬測試的數位雙胞胎 (DT) 時的熟練度。給定一個 S-LLM 集合，此基準能根據 S-LLM 產生高品質 DT 的能力，對 S-LLM 進行排名。我們透過比較超過 20 個開源和閉源 S-LLM 來展示這一點。SimBench 使用多輪互動，採用基於規則的評判 LLM (J-LLM)，它利用預定義規則和人機互動指導，為 S-LLM 產生的 DT 分配分數，從而提供一致且由專家啟發的評估協定。J-LLM 是特定於模擬器的，本文中建議的基準方法與 Chrono 多物理模擬器結合使用。Chrono 提供了用於評估 S-LLM 在產生多體動力學、有限元素分析、車輛動力學、機器人動力學和感測器模擬的數位雙胞胎的能力時所使用的背景。建議的基準原則具有廣泛的適用性，並能夠評估 S-LLM 為其他模擬套件產生數位雙胞胎的能力。所有程式碼和資料都可以在 https://github.com/uwsbel/SimBench 取得。</paragraph>

##### **Chemical Reaction Neural Networks for Fitting Accelerated Rate Calorimetry Data**
2408.11984v1 by Saakaar Bhatnagar, Andrew Comerford, Zelu Xu, Davide Berti Polato, Araz Banaeizadeh, Alessandro Ferraris

As the demand for lithium-ion batteries rapidly increases there is a need to
design these cells in a safe manner to mitigate thermal runaway. Thermal
runaway in batteries leads to an uncontrollable temperature rise and
potentially fires, which is a major safety concern. Typically, when modelling
the chemical kinetics of thermal runaway calorimetry data ( e.g. Accelerated
Rate Calorimetry (ARC)) is needed to determine the temperature-driven
decomposition kinetics. Conventional methods of fitting Arrhenius Ordinary
Differential Equation (ODE) thermal runaway models to Accelerated Rate
Calorimetry (ARC) data make several assumptions that reduce the fidelity and
generalizability of the obtained model. In this paper, Chemical Reaction Neural
Networks (CRNNs) are trained to fit the kinetic parameters of N-equation
Arrhenius ODEs to ARC data obtained from a Molicel 21700 P45B. The models are
found to be better approximations of the experimental data. The flexibility of
the method is demonstrated by experimenting with two-equation and four-equation
models. Thermal runaway simulations are conducted in 3D using the obtained
kinetic parameters, showing the applicability of the obtained thermal runaway
models to large-scale simulations.

摘要：随着锂离子电池需求的快速增长，需要以安全的方式设计这些电池以减轻热失控。电池中的热失控会导致温度不受控制地升高并可能着火，这是一个主要的安全性问题。通常，在模拟热失控的化学动力学时，需要量热数据（例如加速量热法 (ARC)）来确定温度驱动的分解动力学。将 Arrhenius 常微分方程 (ODE) 热失控模型拟合到加速量热法 (ARC) 数据的传统方法做出了几个假设，这些假设降低了所获得模型的保真度和普遍性。在本文中，训练化学反应神经网络 (CRNN) 以拟合从 Molicel 21700 P45B 获得的 ARC 数据的 N 方程 Arrhenius ODE 的动力学参数。发现这些模型是对实验数据的更好近似。通过对两方程和四方程模型进行实验，证明了该方法的灵活性。使用获得的动力学参数在 3D 中进行热失控模拟，显示了所获得的热失控模型对大规模模拟的适用性。

##### **Large Language Models for Page Stream Segmentation**
2408.11981v1 by Hunter Heidenreich, Ratish Dalvi, Rohith Mukku, Nikhil Verma, Neven Pičuljan

Page Stream Segmentation (PSS) is an essential prerequisite for automated
document processing at scale. However, research progress has been limited by
the absence of realistic public benchmarks. This paper works towards addressing
this gap by introducing TABME++, an enhanced benchmark featuring commercial
Optical Character Recognition (OCR) annotations. We evaluate the performance of
large language models (LLMs) on PSS, focusing on decoder-based models
fine-tuned with parameter-efficient methods. Our results show that
decoder-based LLMs outperform smaller multimodal encoders. Through a review of
existing PSS research and datasets, we identify key challenges and advancements
in the field. Our findings highlight the key importance of robust OCR,
providing valuable insights for the development of more effective document
processing systems.

摘要：頁面串流區隔 (PSS) 是大規模自動化文件處理的基本先決條件。然而，研究進展受到缺乏實際公開基準的限制。本文透過引入 TABME++，一個具備商業光學字元辨識 (OCR) 標註的增強基準，來解決這個差距。我們評估大型語言模型 (LLM) 在 PSS 上的效能，專注於使用參數有效率的方法微調的解碼器模型。我們的結果顯示，基於解碼器的 LLM 優於較小的多模態編碼器。透過檢閱現有的 PSS 研究和資料集，我們找出該領域的主要挑戰和進展。我們的發現強調了強健 OCR 的重要性，為更有效的文件處理系統開發提供有價值的見解。

##### **Only Strict Saddles in the Energy Landscape of Predictive Coding Networks?**
2408.11979v1 by Francesco Innocenti, El Mehdi Achour, Ryan Singh, Christopher L. Buckley

Predictive coding (PC) is an energy-based learning algorithm that performs
iterative inference over network activities before weight updates. Recent work
suggests that PC can converge in fewer learning steps than backpropagation
thanks to its inference procedure. However, these advantages are not always
observed, and the impact of PC inference on learning is theoretically not well
understood. Here, we study the geometry of the PC energy landscape at the
(inference) equilibrium of the network activities. For deep linear networks, we
first show that the equilibrated energy is simply a rescaled mean squared error
loss with a weight-dependent rescaling. We then prove that many highly
degenerate (non-strict) saddles of the loss including the origin become much
easier to escape (strict) in the equilibrated energy. Our theory is validated
by experiments on both linear and non-linear networks. Based on these results,
we conjecture that all the saddles of the equilibrated energy are strict.
Overall, this work suggests that PC inference makes the loss landscape more
benign and robust to vanishing gradients, while also highlighting the challenge
of speeding up PC inference on large-scale models.

摘要：預測編碼 (PC) 是一種基於能量的學習演算法，它在權重更新之前對網路活動執行反覆推論。最近的研究表明，由於其推論程序，PC 可以比反向傳播在更少的學習步驟中收斂。然而，這些優勢並非總是能觀察到，而且 PC 推論對學習的影響在理論上並未得到很好的理解。在這裡，我們研究了網路活動（推論）平衡時 PC 能量景觀的幾何形狀。對於深度線性網路，我們首先表明，平衡能量只是一個重新調整大小的均方誤差損失，具有依賴於權重的重新調整大小。然後我們證明，許多高度簡併（非嚴格）的損失鞍點，包括原點，在平衡能量中變得更容易逃逸（嚴格）。我們的理論通過線性和非線性網路的實驗得到驗證。基於這些結果，我們推測平衡能量的所有鞍點都是嚴格的。總的來說，這項工作表明，PC 推論使損失景觀對消失梯度更加良性和穩健，同時也突出了在大型模型上加速 PC 推論的挑戰。

##### **Sentiment and Emotion-aware Multi-criteria Fuzzy Group Decision Making System**
2408.11976v1 by Adilet Yerkin, Pakizar Shamoi, Elnara Kadyrgali

In today's world, making decisions as a group is common, whether choosing a
restaurant or deciding on a holiday destination. Group decision-making (GDM)
systems play a crucial role by facilitating consensus among participants with
diverse preferences. Discussions are one of the main tools people use to make
decisions. When people discuss alternatives, they use natural language to
express their opinions. Traditional GDM systems generally require participants
to provide explicit opinion values to the system. However, in real-life
scenarios, participants often express their opinions through some text (e.g.,
in comments, social media, messengers, etc.). This paper introduces a sentiment
and emotion-aware multi-criteria fuzzy GDM system designed to enhance
consensus-reaching effectiveness in group settings. This system incorporates
natural language processing to analyze sentiments and emotions expressed in
textual data, enabling an understanding of participant opinions besides the
explicit numerical preference inputs. Once all the experts have provided their
preferences for the alternatives, the individual preferences are aggregated
into a single collective preference matrix. This matrix represents the
collective expert opinion regarding the other options. Then, sentiments,
emotions, and preference scores are inputted into a fuzzy inference system to
get the overall score. The proposed system was used for a small decision-making
process - choosing the hotel for a vacation by a group of friends. Our findings
demonstrate that integrating sentiment and emotion analysis into GDM systems
allows everyone's feelings and opinions to be considered during discussions and
significantly improves consensus among participants.

摘要：<paragraph>在當今世界中，無論是選擇餐廳或決定度假目的地，以小組形式做出決策是很常見的。小組決策（GDM）系統透過促進具有不同偏好的參與者達成共識，發揮了至關重要的作用。討論是人們用來做出決策的主要工具之一。當人們討論備選方案時，他們會使用自然語言表達自己的意見。傳統的 GDM 系統通常要求參與者向系統提供明確的意見值。然而，在現實生活中，參與者通常透過一些文字（例如，在評論、社群媒體、通訊軟體等中）表達自己的意見。本文介紹了一個情緒和情感感知的多準則模糊 GDM 系統，旨在增強小組環境中達成共識的有效性。此系統結合了自然語言處理，以分析在文字資料中表達的情緒和情感，除了明確的數值偏好輸入外，還能了解參與者的意見。一旦所有專家都提供了他們對備選方案的偏好，則將個別偏好彙總成一個單一的集體偏好矩陣。此矩陣代表了集體專家意見，關於其他選項。然後，將情緒、情感和偏好分數輸入模糊推理系統以取得總分。所提出的系統用於一個小型決策制定過程 - 由一群朋友選擇度假飯店。我們的研究結果表明，將情緒和情感分析整合到 GDM 系統中，讓每個人的感受和意見都能在討論中被考慮，並顯著改善參與者之間的共識。</paragraph>

