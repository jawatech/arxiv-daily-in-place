{"2411.03883": {"publish_time": "2024-11-06", "title": "MEG: Medical Knowledge-Augmented Large Language Models for Question Answering", "paper_summary": "Question answering is a natural language understanding task that involves\nreasoning over both explicit context and unstated, relevant domain knowledge.\nLarge language models (LLMs), which underpin most contemporary question\nanswering systems, struggle to induce how concepts relate in specialized\ndomains such as medicine. Existing medical LLMs are also costly to train. In\nthis work, we present MEG, a parameter-efficient approach for medical\nknowledge-augmented LLMs. MEG uses a lightweight mapping network to integrate\ngraph embeddings into the LLM, enabling it to leverage external knowledge in a\ncost-effective way. We evaluate our method on four popular medical\nmultiple-choice datasets and show that LLMs greatly benefit from the factual\ngrounding provided by knowledge graph embeddings. MEG attains an average of\n+10.2% accuracy over the Mistral-Instruct baseline, and +6.7% over specialized\nmodels like BioMistral. We also show results based on Llama-3. Finally, we show\nthat MEG's performance remains robust to the choice of graph encoder.", "paper_summary_zh": "\u554f\u7b54\u662f\u4e00\u7a2e\u81ea\u7136\u8a9e\u8a00\u7406\u89e3\u4efb\u52d9\uff0c\u6d89\u53ca\u5c0d\u660e\u78ba\u7684\u8a9e\u5883\u548c\u672a\u8aaa\u660e\u7684\u76f8\u95dc\u9818\u57df\u77e5\u8b58\u9032\u884c\u63a8\u7406\u3002\u652f\u6490\u5927\u591a\u6578\u7576\u4ee3\u554f\u7b54\u7cfb\u7d71\u7684\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u96e3\u4ee5\u63a8\u8ad6\u51fa\u6982\u5ff5\u5728\u91ab\u5b78\u7b49\u5c08\u696d\u9818\u57df\u4e2d\u7684\u95dc\u806f\u6027\u3002\u73fe\u6709\u7684\u91ab\u5b78 LLM \u8a13\u7df4\u6210\u672c\u4e5f\u5f88\u9ad8\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86 MEG\uff0c\u9019\u662f\u4e00\u7a2e\u7528\u65bc\u91ab\u5b78\u77e5\u8b58\u589e\u5f37 LLM \u7684\u53c3\u6578\u9ad8\u6548\u65b9\u6cd5\u3002MEG \u4f7f\u7528\u8f15\u91cf\u7d1a\u5c0d\u61c9\u7db2\u8def\u5c07\u5716\u5f62\u5d4c\u5165\u6574\u5408\u5230 LLM \u4e2d\uff0c\u4f7f\u5176\u80fd\u5920\u4ee5\u7d93\u6fdf\u6709\u6548\u7684\u65b9\u5f0f\u5229\u7528\u5916\u90e8\u77e5\u8b58\u3002\u6211\u5011\u5728\u56db\u500b\u6d41\u884c\u7684\u91ab\u5b78\u591a\u9078\u984c\u8cc7\u6599\u96c6\u4e0a\u8a55\u4f30\u4e86\u6211\u5011\u7684\u65b9\u6cd5\uff0c\u4e26\u8868\u660e LLM \u5f9e\u77e5\u8b58\u5716\u5f62\u5d4c\u5165\u63d0\u4f9b\u7684\u5be6\u969b\u4f9d\u64da\u4e2d\u53d7\u76ca\u532a\u6dfa\u3002MEG \u5728 Mistral-Instruct \u57fa\u6e96\u4e0a\u5e73\u5747\u63d0\u9ad8\u4e86 +10.2% \u7684\u6e96\u78ba\u7387\uff0c\u5728 BioMistral \u7b49\u5c08\u7528\u6a21\u578b\u4e0a\u63d0\u9ad8\u4e86 +6.7%\u3002\u6211\u5011\u9084\u5c55\u793a\u4e86\u57fa\u65bc Llama-3 \u7684\u7d50\u679c\u3002\u6700\u5f8c\uff0c\u6211\u5011\u8868\u660e MEG \u7684\u6027\u80fd\u5c0d\u5716\u5f62\u7de8\u78bc\u5668\u7684\u9078\u64c7\u4fdd\u6301\u7a69\u5065\u3002", "author": "Laura Cabello et.al.", "authors": "Laura Cabello, Carmen Martin-Turrero, Uchenna Akujuobi, Anders S\u00f8gaard, Carlos Bobed", "id": "2411.03883v1", "paper_url": "http://arxiv.org/abs/2411.03883v1", "repo": "https://github.com/lautel/meg"}}