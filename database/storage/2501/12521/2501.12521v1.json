{"2501.12521": {"publish_time": "2025-01-21", "title": "An Empirically-grounded tool for Automatic Prompt Linting and Repair: A Case Study on Bias, Vulnerability, and Optimization in Developer Prompts", "paper_summary": "The tidal wave of advancements in Large Language Models (LLMs) has led to\ntheir swift integration into application-level logic. Many software systems now\nuse prompts to interact with these black-box models, combining natural language\nwith dynamic values interpolated at runtime, to perform tasks ranging from\nsentiment analysis to question answering. Due to the programmatic and\nstructured natural language aspects of these prompts, we refer to them as\nDeveloper Prompts. Unlike traditional software artifacts, Dev Prompts blend\nnatural language instructions with artificial languages such as programming and\nmarkup languages, thus requiring specialized tools for analysis, distinct from\nclassical software evaluation methods.\n  In response to this need, we introduce PromptDoctor, a tool explicitly\ndesigned to detect and correct issues of Dev Prompts. PromptDoctor identifies\nand addresses problems related to bias, vulnerability, and sub-optimal\nperformance in Dev Prompts, helping mitigate their possible harms. In our\nanalysis of 2,173 Dev Prompts, selected as a representative sample of 40,573\nDev Prompts, we found that 3.46% contained one or more forms of bias, 10.75%\nwere vulnerable to prompt injection attacks. Additionally, 3,310 were amenable\nto automated prompt optimization. To address these issues, we applied\nPromptDoctor to the flawed Dev Prompts we discovered. PromptDoctor de-biased\n68.29% of the biased Dev Prompts, hardened 41.81% of the vulnerable Dev\nPrompts, and improved the performance of 37.1% sub-optimal Dev Prompts.\nFinally, we developed a PromptDoctor VSCode extension, enabling developers to\neasily enhance Dev Prompts in their existing development workflows. The data\nand source code for this work are available at", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u9032\u5c55\u6d6a\u6f6e\u5c0e\u81f4\u5b83\u5011\u8fc5\u901f\u6574\u5408\u5230\u61c9\u7528\u7a0b\u5f0f\u5c64\u7d1a\u908f\u8f2f\u4e2d\u3002\u8a31\u591a\u8edf\u9ad4\u7cfb\u7d71\u73fe\u5728\u4f7f\u7528\u63d0\u793a\u8207\u9019\u4e9b\u9ed1\u76d2\u6a21\u578b\u4e92\u52d5\uff0c\u7d50\u5408\u81ea\u7136\u8a9e\u8a00\u8207\u57f7\u884c\u6642\u5167\u63d2\u7684\u52d5\u614b\u503c\uff0c\u4ee5\u57f7\u884c\u5f9e\u60c5\u7dd2\u5206\u6790\u5230\u554f\u984c\u89e3\u7b54\u7684\u5404\u7a2e\u4efb\u52d9\u3002\u7531\u65bc\u9019\u4e9b\u63d0\u793a\u5177\u6709\u7a0b\u5f0f\u5316\u548c\u7d50\u69cb\u5316\u7684\u81ea\u7136\u8a9e\u8a00\u65b9\u9762\uff0c\u6211\u5011\u5c07\u5b83\u5011\u7a31\u70ba\u958b\u767c\u4eba\u54e1\u63d0\u793a\u3002\u8207\u50b3\u7d71\u8edf\u9ad4\u4eba\u5de5\u88fd\u54c1\u4e0d\u540c\uff0c\u958b\u767c\u4eba\u54e1\u63d0\u793a\u5c07\u81ea\u7136\u8a9e\u8a00\u6307\u4ee4\u8207\u4eba\u5de5\u8a9e\u8a00\uff08\u4f8b\u5982\u7a0b\u5f0f\u8a2d\u8a08\u548c\u6a19\u8a18\u8a9e\u8a00\uff09\u6df7\u5408\u5728\u4e00\u8d77\uff0c\u56e0\u6b64\u9700\u8981\u5c08\u9580\u7684\u5206\u6790\u5de5\u5177\uff0c\u4e0d\u540c\u65bc\u50b3\u7d71\u7684\u8edf\u9ad4\u8a55\u4f30\u65b9\u6cd5\u3002\n\u70ba\u4e86\u6eff\u8db3\u9019\u500b\u9700\u6c42\uff0c\u6211\u5011\u5f15\u5165\u4e86 PromptDoctor\uff0c\u9019\u662f\u4e00\u500b\u5c08\u9580\u8a2d\u8a08\u7528\u65bc\u5075\u6e2c\u548c\u4fee\u6b63\u958b\u767c\u4eba\u54e1\u63d0\u793a\u554f\u984c\u7684\u5de5\u5177\u3002PromptDoctor \u8b58\u5225\u4e26\u89e3\u6c7a\u8207\u958b\u767c\u4eba\u54e1\u63d0\u793a\u4e2d\u7684\u504f\u5dee\u3001\u6f0f\u6d1e\u548c\u6b21\u4f73\u6548\u80fd\u76f8\u95dc\u7684\u554f\u984c\uff0c\u6709\u52a9\u65bc\u6e1b\u8f15\u5176\u53ef\u80fd\u7684\u5371\u5bb3\u3002\u5728\u6211\u5011\u5c0d 2,173 \u500b\u958b\u767c\u4eba\u54e1\u63d0\u793a\u7684\u5206\u6790\u4e2d\uff0c\u9019\u4e9b\u63d0\u793a\u88ab\u9078\u70ba 40,573 \u500b\u958b\u767c\u4eba\u54e1\u63d0\u793a\u7684\u4ee3\u8868\u6027\u6a23\u672c\uff0c\u6211\u5011\u767c\u73fe 3.46% \u5305\u542b\u4e00\u7a2e\u6216\u591a\u7a2e\u5f62\u5f0f\u7684\u504f\u5dee\uff0c10.75% \u5bb9\u6613\u53d7\u5230\u63d0\u793a\u6ce8\u5165\u653b\u64ca\u3002\u6b64\u5916\uff0c3,310 \u500b\u63d0\u793a\u53ef\u4ee5\u9032\u884c\u81ea\u52d5\u5316\u63d0\u793a\u6700\u4f73\u5316\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u5c07 PromptDoctor \u61c9\u7528\u65bc\u6211\u5011\u767c\u73fe\u7684\u932f\u8aa4\u958b\u767c\u4eba\u54e1\u63d0\u793a\u3002PromptDoctor \u6d88\u9664\u4e86 68.29% \u6709\u504f\u5dee\u7684\u958b\u767c\u4eba\u54e1\u63d0\u793a\u7684\u504f\u5dee\uff0c\u5f37\u5316\u4e86 41.81% \u5bb9\u6613\u53d7\u5230\u653b\u64ca\u7684\u958b\u767c\u4eba\u54e1\u63d0\u793a\uff0c\u4e26\u6539\u5584\u4e86 37.1% \u6b21\u4f73\u958b\u767c\u4eba\u54e1\u63d0\u793a\u7684\u6548\u80fd\u3002\u6700\u5f8c\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b PromptDoctor VSCode \u64f4\u5145\u529f\u80fd\uff0c\u8b93\u958b\u767c\u4eba\u54e1\u53ef\u4ee5\u8f15\u9b06\u5730\u5728\u73fe\u6709\u7684\u958b\u767c\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u589e\u5f37\u958b\u767c\u4eba\u54e1\u63d0\u793a\u3002\u9019\u9805\u5de5\u4f5c\u7684\u8cc7\u6599\u548c\u539f\u59cb\u78bc\u53ef\u5728", "author": "Dhia Elhaq Rzig et.al.", "authors": "Dhia Elhaq Rzig, Dhruba Jyoti Paul, Kaiser Pister, Jordan Henkel, Foyzul Hassan", "id": "2501.12521v1", "paper_url": "http://arxiv.org/abs/2501.12521v1", "repo": "null"}}