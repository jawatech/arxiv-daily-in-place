{"2405.03939": {"publish_time": "2024-05-07", "title": "Long Context Alignment with Short Instructions and Synthesized Positions", "paper_summary": "Effectively handling instructions with extremely long context remains a\nchallenge for Large Language Models (LLMs), typically necessitating\nhigh-quality long data and substantial computational resources. This paper\nintroduces Step-Skipping Alignment (SkipAlign), a new technique designed to\nenhance the long-context capabilities of LLMs in the phase of alignment without\nthe need for additional efforts beyond training with original data length.\nSkipAlign is developed on the premise that long-range dependencies are\nfundamental to enhancing an LLM's capacity of long context. Departing from\nmerely expanding the length of input samples, SkipAlign synthesizes long-range\ndependencies from the aspect of positions indices. This is achieved by the\nstrategic insertion of skipped positions within instruction-following samples,\nwhich utilizes the semantic structure of the data to effectively expand the\ncontext. Through extensive experiments on base models with a variety of context\nwindow sizes, SkipAlign demonstrates its effectiveness across a spectrum of\nlong-context tasks. Particularly noteworthy is that with a careful selection of\nthe base model and alignment datasets, SkipAlign with only 6B parameters\nachieves it's best performance and comparable with strong baselines like\nGPT-3.5-Turbo-16K on LongBench.", "paper_summary_zh": "\u6709\u6548\u5730\u8655\u7406\u6975\u9577\u8a9e\u5883\u7684\u6307\u4ee4\u4ecd\u7136\u662f\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u4e00\u9805\u6311\u6230\uff0c\u901a\u5e38\u9700\u8981\u9ad8\u54c1\u8cea\u7684\u9577\u6578\u64da\u548c\u5927\u91cf\u7684\u8a08\u7b97\u8cc7\u6e90\u3002\u672c\u6587\u4ecb\u7d39\u4e86\u8df3\u6b65\u5c0d\u9f4a (SkipAlign)\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u6280\u8853\uff0c\u65e8\u5728\u589e\u5f37 LLM \u5728\u5c0d\u9f4a\u968e\u6bb5\u7684\u9577\u8a9e\u5883\u80fd\u529b\uff0c\u800c\u7121\u9700\u9664\u4e86\u4f7f\u7528\u539f\u59cb\u6578\u64da\u9577\u5ea6\u9032\u884c\u8a13\u7df4\u4e4b\u5916\u7684\u984d\u5916\u5de5\u4f5c\u3002\nSkipAlign \u662f\u57fa\u65bc\u9577\u8ddd\u96e2\u4f9d\u8cf4\u95dc\u4fc2\u5c0d\u65bc\u589e\u5f37 LLM \u7684\u9577\u8a9e\u5883\u80fd\u529b\u81f3\u95dc\u91cd\u8981\u7684\u524d\u63d0\u800c\u958b\u767c\u7684\u3002\u8207\u50c5\u50c5\u64f4\u5c55\u8f38\u5165\u6a23\u672c\u7684\u9577\u5ea6\u4e0d\u540c\uff0cSkipAlign \u5f9e\u4f4d\u7f6e\u7d22\u5f15\u7684\u89d2\u5ea6\u7d9c\u5408\u4e86\u9577\u8ddd\u96e2\u4f9d\u8cf4\u95dc\u4fc2\u3002\u9019\u662f\u901a\u904e\u5728\u9075\u5faa\u6307\u4ee4\u7684\u6a23\u672c\u4e2d\u7b56\u7565\u6027\u5730\u63d2\u5165\u8df3\u904e\u7684\u7d22\u5f15\u4f4d\u7f6e\u4f86\u5be6\u73fe\u7684\uff0c\u5b83\u5229\u7528\u6578\u64da\u7684\u8a9e\u7fa9\u7d50\u69cb\u4f86\u6709\u6548\u5730\u64f4\u5c55\u8a9e\u5883\u3002\u901a\u904e\u5c0d\u5177\u6709\u5404\u7a2e\u8a9e\u5883\u7a97\u53e3\u5927\u5c0f\u7684\u57fa\u672c\u6a21\u578b\u9032\u884c\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0cSkipAlign \u5c55\u793a\u4e86\u5176\u5728\u5404\u7a2e\u9577\u8a9e\u5883\u4efb\u52d9\u4e2d\u7684\u6709\u6548\u6027\u3002\u7279\u5225\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u901a\u904e\u4ed4\u7d30\u9078\u64c7\u57fa\u672c\u6a21\u578b\u548c\u5c0d\u9f4a\u6578\u64da\u96c6\uff0c\u53ea\u6709 6B \u53c3\u6578\u7684 SkipAlign \u5c31\u80fd\u9054\u5230\u5176\u6700\u4f73\u6027\u80fd\uff0c\u4e26\u4e14\u5728 LongBench \u4e0a\u8207 GPT-3.5-Turbo-16K \u7b49\u5f37\u5927\u7684\u57fa\u6e96\u76f8\u7576\u3002", "author": "Wenhao Wu et.al.", "authors": "Wenhao Wu, Yizhong Wang, Yao Fu, Xiang Yue, Dawei Zhu, Sujian Li", "id": "2405.03939v1", "paper_url": "http://arxiv.org/abs/2405.03939v1", "repo": "null"}}