{"2407.00541": {"publish_time": "2024-06-29", "title": "Answering real-world clinical questions using large language model based systems", "paper_summary": "Evidence to guide healthcare decisions is often limited by a lack of relevant\nand trustworthy literature as well as difficulty in contextualizing existing\nresearch for a specific patient. Large language models (LLMs) could potentially\naddress both challenges by either summarizing published literature or\ngenerating new studies based on real-world data (RWD). We evaluated the ability\nof five LLM-based systems in answering 50 clinical questions and had nine\nindependent physicians review the responses for relevance, reliability, and\nactionability. As it stands, general-purpose LLMs (ChatGPT-4, Claude 3 Opus,\nGemini Pro 1.5) rarely produced answers that were deemed relevant and\nevidence-based (2% - 10%). In contrast, retrieval augmented generation\n(RAG)-based and agentic LLM systems produced relevant and evidence-based\nanswers for 24% (OpenEvidence) to 58% (ChatRWD) of questions. Only the agentic\nChatRWD was able to answer novel questions compared to other LLMs (65% vs.\n0-9%). These results suggest that while general-purpose LLMs should not be used\nas-is, a purpose-built system for evidence summarization based on RAG and one\nfor generating novel evidence working synergistically would improve\navailability of pertinent evidence for patient care.", "paper_summary_zh": "\u91ab\u7642\u4fdd\u5065\u6c7a\u7b56\u7684\u6307\u5c0e\u8b49\u64da\u901a\u5e38\u53d7\u5230\u7f3a\u4e4f\u76f8\u95dc\u4e14\u53ef\u4fe1\u8cf4\u6587\u737b\u7684\u9650\u5236\uff0c\u4ee5\u53ca\u96e3\u4ee5\u5c07\u73fe\u6709\u7814\u7a76\u80cc\u666f\u5316\u4ee5\u9069\u7528\u65bc\u7279\u5b9a\u60a3\u8005\u3002\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6f5b\u5728\u53ef\u900f\u904e\u6458\u8981\u5df2\u767c\u8868\u7684\u6587\u737b\u6216\u6839\u64da\u771f\u5be6\u4e16\u754c\u8cc7\u6599 (RWD) \u7522\u751f\u65b0\u7684\u7814\u7a76\u4f86\u89e3\u6c7a\u9019\u5169\u500b\u6311\u6230\u3002\u6211\u5011\u8a55\u4f30\u4e86\u4e94\u500b\u57fa\u65bc LLM \u7684\u7cfb\u7d71\u56de\u7b54 50 \u500b\u81e8\u5e8a\u554f\u984c\u7684\u80fd\u529b\uff0c\u4e26\u8b93\u4e5d\u4f4d\u7368\u7acb\u7684\u91ab\u5e2b\u6aa2\u8996\u56de\u61c9\u7684\u76f8\u95dc\u6027\u3001\u53ef\u9760\u6027\uff0c\u4ee5\u53ca\u53ef\u884c\u6027\u3002\u76ee\u524d\uff0c\u901a\u7528 LLM\uff08ChatGPT-4\u3001Claude 3 Opus\u3001Gemini Pro 1.5\uff09\u5f88\u5c11\u7522\u751f\u88ab\u8a8d\u70ba\u76f8\u95dc\u4e14\u57fa\u65bc\u8b49\u64da\u7684\u7b54\u6848\uff082% - 10%\uff09\u3002\u76f8\u53cd\u5730\uff0c\u57fa\u65bc\u6aa2\u7d22\u589e\u5f37\u751f\u6210\uff08RAG\uff09\u548c\u4ee3\u7406 LLM \u7cfb\u7d71\u7522\u751f\u7684\u7b54\u6848\uff0c\u6709 24%\uff08OpenEvidence\uff09\u81f3 58%\uff08ChatRWD\uff09\u7684\u554f\u984c\u662f\u76f8\u95dc\u4e14\u57fa\u65bc\u8b49\u64da\u7684\u3002\u8207\u5176\u4ed6 LLM \u76f8\u6bd4\uff0c\u53ea\u6709\u4ee3\u7406 ChatRWD \u80fd\u5920\u56de\u7b54\u65b0\u554f\u984c\uff0865% \u5c0d 0-9%\uff09\u3002\u9019\u4e9b\u7d50\u679c\u8868\u660e\uff0c\u96d6\u7136\u4e0d\u61c9\u6309\u539f\u6a23\u4f7f\u7528\u901a\u7528 LLM\uff0c\u4f46\u4e00\u500b\u57fa\u65bc RAG \u7684\u5c08\u9580\u5efa\u7f6e\u7cfb\u7d71\uff0c\u7528\u65bc\u8b49\u64da\u6458\u8981\uff0c\u4ee5\u53ca\u4e00\u500b\u7528\u65bc\u7522\u751f\u65b0\u8b49\u64da\u7684\u7cfb\u7d71\uff0c\u5354\u540c\u904b\u4f5c\uff0c\u5c07\u53ef\u6539\u5584\u8207\u60a3\u8005\u7167\u8b77\u76f8\u95dc\u8b49\u64da\u7684\u53ef\u7528\u6027\u3002", "author": "Yen Sia Low et.al.", "authors": "Yen Sia Low, Michael L. Jackson, Rebecca J. Hyde, Robert E. Brown, Neil M. Sanghavi, Julian D. Baldwin, C. William Pike, Jananee Muralidharan, Gavin Hui, Natasha Alexander, Hadeel Hassan, Rahul V. Nene, Morgan Pike, Courtney J. Pokrzywa, Shivam Vedak, Adam Paul Yan, Dong-han Yao, Amy R. Zipursky, Christina Dinh, Philip Ballentine, Dan C. Derieg, Vladimir Polony, Rehan N. Chawdry, Jordan Davies, Brigham B. Hyde, Nigam H. Shah, Saurabh Gombar", "id": "2407.00541v1", "paper_url": "http://arxiv.org/abs/2407.00541v1", "repo": "null"}}