{"2411.13053": {"publish_time": "2024-11-20", "title": "MEGL: Multimodal Explanation-Guided Learning", "paper_summary": "Explaining the decision-making processes of Artificial Intelligence (AI)\nmodels is crucial for addressing their \"black box\" nature, particularly in\ntasks like image classification. Traditional eXplainable AI (XAI) methods\ntypically rely on unimodal explanations, either visual or textual, each with\ninherent limitations. Visual explanations highlight key regions but often lack\nrationale, while textual explanations provide context without spatial\ngrounding. Further, both explanation types can be inconsistent or incomplete,\nlimiting their reliability. To address these challenges, we propose a novel\nMultimodal Explanation-Guided Learning (MEGL) framework that leverages both\nvisual and textual explanations to enhance model interpretability and improve\nclassification performance. Our Saliency-Driven Textual Grounding (SDTG)\napproach integrates spatial information from visual explanations into textual\nrationales, providing spatially grounded and contextually rich explanations.\nAdditionally, we introduce Textual Supervision on Visual Explanations to align\nvisual explanations with textual rationales, even in cases where ground truth\nvisual annotations are missing. A Visual Explanation Distribution Consistency\nloss further reinforces visual coherence by aligning the generated visual\nexplanations with dataset-level patterns, enabling the model to effectively\nlearn from incomplete multimodal supervision. We validate MEGL on two new\ndatasets, Object-ME and Action-ME, for image classification with multimodal\nexplanations. Experimental results demonstrate that MEGL outperforms previous\napproaches in prediction accuracy and explanation quality across both visual\nand textual domains. Our code will be made available upon the acceptance of the\npaper.", "paper_summary_zh": "<paragraph>\u89e3\u91cb\u4eba\u5de5\u667a\u6167\uff08AI\uff09\u6a21\u578b\u7684\u6c7a\u7b56\u904e\u7a0b\u5c0d\u65bc\u89e3\u6c7a\u5176\u300c\u9ed1\u76d2\u5b50\u300d\u6027\u8cea\u81f3\u95dc\u91cd\u8981\uff0c\u7279\u5225\u662f\u5728\u5f71\u50cf\u5206\u985e\u7b49\u4efb\u52d9\u4e2d\u3002\u50b3\u7d71\u7684\u53ef\u89e3\u91cb AI\uff08XAI\uff09\u65b9\u6cd5\u901a\u5e38\u4f9d\u8cf4\u65bc\u55ae\u6a21\u614b\u89e3\u91cb\uff0c\u7121\u8ad6\u662f\u8996\u89ba\u6216\u6587\u5b57\uff0c\u6bcf\u7a2e\u89e3\u91cb\u90fd\u6709\u5176\u56fa\u6709\u7684\u9650\u5236\u3002\u8996\u89ba\u89e3\u91cb\u91cd\u9ede\u5f37\u8abf\u95dc\u9375\u5340\u57df\uff0c\u4f46\u901a\u5e38\u7f3a\u4e4f\u4f9d\u64da\uff0c\u800c\u6587\u5b57\u89e3\u91cb\u5247\u63d0\u4f9b\u80cc\u666f\uff0c\u537b\u6c92\u6709\u7a7a\u9593\u4f9d\u64da\u3002\u6b64\u5916\uff0c\u9019\u5169\u7a2e\u89e3\u91cb\u985e\u578b\u90fd\u53ef\u80fd\u4e0d\u4e00\u81f4\u6216\u4e0d\u5b8c\u6574\uff0c\u9650\u5236\u4e86\u5176\u53ef\u9760\u6027\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u5275\u65b0\u7684\u591a\u6a21\u614b\u89e3\u91cb\u5f15\u5c0e\u5b78\u7fd2\uff08MEGL\uff09\u67b6\u69cb\uff0c\u5b83\u5229\u7528\u8996\u89ba\u548c\u6587\u5b57\u89e3\u91cb\u4f86\u589e\u5f37\u6a21\u578b\u7684\u53ef\u89e3\u91cb\u6027\uff0c\u4e26\u63d0\u9ad8\u5206\u985e\u6548\u80fd\u3002\u6211\u5011\u7684\u986f\u8457\u6027\u9a45\u52d5\u6587\u5b57\u57fa\u790e\uff08SDTG\uff09\u65b9\u6cd5\u5c07\u4f86\u81ea\u8996\u89ba\u89e3\u91cb\u7684\u7a7a\u9593\u8cc7\u8a0a\u6574\u5408\u5230\u6587\u5b57\u4f9d\u64da\u4e2d\uff0c\u63d0\u4f9b\u5177\u6709\u7a7a\u9593\u4f9d\u64da\u4e14\u5167\u5bb9\u8c50\u5bcc\u7684\u89e3\u91cb\u3002\u6b64\u5916\uff0c\u6211\u5011\u5728\u8996\u89ba\u89e3\u91cb\u4e2d\u5f15\u5165\u4e86\u6587\u5b57\u76e3\u7763\uff0c\u5373\u4f7f\u5728\u7f3a\u5c11\u5730\u9762\u771f\u5be6\u8996\u89ba\u8a3b\u89e3\u7684\u60c5\u6cc1\u4e0b\uff0c\u4e5f\u80fd\u5c07\u8996\u89ba\u89e3\u91cb\u8207\u6587\u5b57\u4f9d\u64da\u5c0d\u9f4a\u3002\u8996\u89ba\u89e3\u91cb\u5206\u4f48\u4e00\u81f4\u6027\u640d\u5931\u9032\u4e00\u6b65\u52a0\u5f37\u4e86\u8996\u89ba\u4e00\u81f4\u6027\uff0c\u65b9\u6cd5\u662f\u5c07\u7522\u751f\u7684\u8996\u89ba\u89e3\u91cb\u8207\u8cc7\u6599\u96c6\u5c64\u7d1a\u6a21\u5f0f\u5c0d\u9f4a\uff0c\u4f7f\u6a21\u578b\u80fd\u5920\u6709\u6548\u5730\u5f9e\u4e0d\u5b8c\u6574\u7684\u591a\u6a21\u614b\u76e3\u7763\u4e2d\u5b78\u7fd2\u3002\u6211\u5011\u5728\u5169\u500b\u65b0\u8cc7\u6599\u96c6 Object-ME \u548c Action-ME \u4e0a\u9a57\u8b49\u4e86 MEGL\uff0c\u7528\u65bc\u5177\u6709\u591a\u6a21\u614b\u89e3\u91cb\u7684\u5f71\u50cf\u5206\u985e\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u5728\u8996\u89ba\u548c\u6587\u5b57\u9818\u57df\u4e2d\uff0cMEGL \u5728\u9810\u6e2c\u6e96\u78ba\u6027\u548c\u89e3\u91cb\u54c1\u8cea\u65b9\u9762\u90fd\u512a\u65bc\u5148\u524d\u7684\u505a\u6cd5\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u5c07\u5728\u8ad6\u6587\u88ab\u63a5\u53d7\u5f8c\u63d0\u4f9b\u3002</paragraph>", "author": "Yifei Zhang et.al.", "authors": "Yifei Zhang, Tianxu Jiang, Bo Pan, Jingyu Wang, Guangji Bai, Liang Zhao", "id": "2411.13053v1", "paper_url": "http://arxiv.org/abs/2411.13053v1", "repo": "null"}}