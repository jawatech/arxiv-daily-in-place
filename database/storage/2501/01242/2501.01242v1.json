{"2501.01242": {"publish_time": "2025-01-02", "title": "An Efficient Attention Mechanism for Sequential Recommendation Tasks: HydraRec", "paper_summary": "Transformer based models are increasingly being used in various domains\nincluding recommender systems (RS). Pretrained transformer models such as BERT\nhave shown good performance at language modelling. With the greater ability to\nmodel sequential tasks, variants of Encoder-only models (like BERT4Rec, SASRec\netc.) have found success in sequential RS problems. Computing dot-product\nattention in traditional transformer models has quadratic complexity in\nsequence length. This is a bigger problem with RS because unlike language\nmodels, new items are added to the catalogue every day. User buying history is\na dynamic sequence which depends on multiple factors. Recently, various linear\nattention models have tried to solve this problem by making the model linear in\nsequence length (token dimensions). Hydra attention is one such linear\ncomplexity model proposed for vision transformers which reduces the complexity\nof attention for both the number of tokens as well as model embedding\ndimensions. Building on the idea of Hydra attention, we introduce an efficient\nTransformer based Sequential RS (HydraRec) which significantly improves\ntheoretical complexity of computing attention for longer sequences and bigger\ndatasets while preserving the temporal context. Extensive experiments are\nconducted to evaluate other linear transformer-based RS models and compared\nwith HydraRec across various evaluation metrics. HydraRec outperforms other\nlinear attention-based models as well as dot-product based attention models\nwhen used with causal masking for sequential recommendation next item\nprediction tasks. For bi-directional models its performance is comparable to\nthe BERT4Rec model with an improvement in running time.", "paper_summary_zh": "<paragraph>\u57fa\u65bc Transformer \u7684\u6a21\u578b\u6108\u4f86\u6108\u591a\u5730\u7528\u65bc\u5404\u7a2e\u9818\u57df\uff0c\u5305\u62ec\u63a8\u85a6\u7cfb\u7d71 (RS)\u3002\u9810\u8a13\u7df4\u7684 Transformer \u6a21\u578b\uff0c\u4f8b\u5982 BERT\uff0c\u5df2\u5728\u8a9e\u8a00\u5efa\u6a21\u65b9\u9762\u5c55\u73fe\u51fa\u826f\u597d\u7684\u6548\u80fd\u3002\u96a8\u8457\u5c0d\u5e8f\u5217\u4efb\u52d9\u5efa\u6a21\u80fd\u529b\u7684\u63d0\u5347\uff0c\u50c5\u7de8\u78bc\u5668\u6a21\u578b\u7684\u8b8a\u9ad4\uff08\u4f8b\u5982 BERT4Rec\u3001SASRec \u7b49\uff09\u5df2\u5728\u5e8f\u5217 RS \u554f\u984c\u4e2d\u7372\u5f97\u6210\u529f\u3002\u5728\u50b3\u7d71 Transformer \u6a21\u578b\u4e2d\u8a08\u7b97\u9ede\u7a4d\u6ce8\u610f\u529b\u6642\uff0c\u5176\u5e8f\u5217\u9577\u5ea6\u5177\u6709\u4e8c\u6b21\u8907\u96dc\u5ea6\u3002\u9019\u5c0d\u65bc RS \u4f86\u8aaa\u662f\u4e00\u500b\u66f4\u5927\u7684\u554f\u984c\uff0c\u56e0\u70ba\u8207\u8a9e\u8a00\u6a21\u578b\u4e0d\u540c\uff0c\u6bcf\u5929\u90fd\u6703\u6709\u65b0\u7684\u9805\u76ee\u65b0\u589e\u5230\u76ee\u9304\u4e2d\u3002\u4f7f\u7528\u8005\u7684\u8cfc\u8cb7\u8a18\u9304\u662f\u4e00\u500b\u52d5\u614b\u5e8f\u5217\uff0c\u53d6\u6c7a\u65bc\u591a\u91cd\u56e0\u7d20\u3002\u6700\u8fd1\uff0c\u5404\u7a2e\u7dda\u6027\u6ce8\u610f\u529b\u6a21\u578b\u5df2\u5617\u8a66\u901a\u904e\u4f7f\u6a21\u578b\u5728\u5e8f\u5217\u9577\u5ea6\uff08\u6a19\u8a18\u7dad\u5ea6\uff09\u4e2d\u7dda\u6027\u5316\u4f86\u89e3\u6c7a\u6b64\u554f\u984c\u3002Hydra \u6ce8\u610f\u529b\u662f\u4e00\u7a2e\u91dd\u5c0d\u8996\u89ba Transformer \u63d0\u51fa\u3001\u5177\u6709\u6b64\u985e\u7dda\u6027\u8907\u96dc\u5ea6\u7684\u6a21\u578b\uff0c\u5b83\u964d\u4f4e\u4e86\u5c0d\u6a19\u8a18\u6578\u91cf\u548c\u6a21\u578b\u5d4c\u5165\u7dad\u5ea6\u7684\u6ce8\u610f\u529b\u7684\u8907\u96dc\u5ea6\u3002\u57fa\u65bc Hydra \u6ce8\u610f\u529b\u7684\u6982\u5ff5\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u500b\u9ad8\u6548\u7684\u57fa\u65bc Transformer \u7684\u5e8f\u5217 RS\uff08HydraRec\uff09\uff0c\u5b83\u986f\u8457\u6539\u5584\u4e86\u8a08\u7b97\u8f03\u9577\u5e8f\u5217\u548c\u8f03\u5927\u8cc7\u6599\u96c6\u6ce8\u610f\u529b\u7684\u7406\u8ad6\u8907\u96dc\u5ea6\uff0c\u540c\u6642\u4fdd\u7559\u4e86\u6642\u9593\u8108\u7d61\u3002\u6211\u5011\u9032\u884c\u4e86\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0c\u4ee5\u8a55\u4f30\u5176\u4ed6\u57fa\u65bc\u7dda\u6027 Transformer \u7684 RS \u6a21\u578b\uff0c\u4e26\u5728\u5404\u7a2e\u8a55\u4f30\u6307\u6a19\u4e2d\u5c07\u5176\u8207 HydraRec \u9032\u884c\u4e86\u6bd4\u8f03\u3002\u5728\u7528\u65bc\u5e8f\u5217\u63a8\u85a6\u4e0b\u4e00\u500b\u9805\u76ee\u9810\u6e2c\u4efb\u52d9\u7684\u56e0\u679c\u906e\u7f69\u6642\uff0cHydraRec \u512a\u65bc\u5176\u4ed6\u57fa\u65bc\u7dda\u6027\u6ce8\u610f\u529b\u7684\u6a21\u578b\u4ee5\u53ca\u57fa\u65bc\u9ede\u7a4d\u7684\u6ce8\u610f\u529b\u6a21\u578b\u3002\u5c0d\u65bc\u96d9\u5411\u6a21\u578b\uff0c\u5176\u6548\u80fd\u53ef\u8207 BERT4Rec \u6a21\u578b\u76f8\u5ab2\u7f8e\uff0c\u540c\u6642\u7e2e\u77ed\u4e86\u57f7\u884c\u6642\u9593\u3002</paragraph>", "author": "Uzma Mushtaque et.al.", "authors": "Uzma Mushtaque", "id": "2501.01242v1", "paper_url": "http://arxiv.org/abs/2501.01242v1", "repo": "null"}}