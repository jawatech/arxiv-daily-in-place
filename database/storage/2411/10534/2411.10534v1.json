{"2411.10534": {"publish_time": "2024-11-15", "title": "Chain of Alignment: Integrating Public Will with Expert Intelligence for Language Model Alignment", "paper_summary": "We introduce a method to measure the alignment between public will and\nlanguage model (LM) behavior that can be applied to fine-tuning, online\noversight, and pre-release safety checks. Our `chain of alignment' (CoA)\napproach produces a rule based reward (RBR) by creating model behavior\n$\\textit{rules}$ aligned to normative $\\textit{objectives}$ aligned to\n$\\textit{public will}$. This factoring enables a nonexpert public to directly\nspecify their will through the normative objectives, while expert intelligence\nis used to figure out rules entailing model behavior that best achieves those\nobjectives. We validate our approach by applying it across three different\ndomains of LM prompts related to mental health. We demonstrate a public input\nprocess built on collective dialogues and bridging-based ranking that reliably\nproduces normative objectives supported by at least $96\\% \\pm 2\\%$ of the US\npublic. We then show that rules developed by mental health experts to achieve\nthose objectives enable a RBR that evaluates an LM response's alignment with\nthe objectives similarly to human experts (Pearson's $r=0.841$, $AUC=0.964$).\nBy measuring alignment with objectives that have near unanimous public support,\nthese CoA RBRs provide an approximate measure of alignment between LM behavior\nand public will.", "paper_summary_zh": "<paragraph>\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b9\u6cd5\u4f86\u8861\u91cf\u516c\u773e\u610f\u9858\u8207\u8a9e\u8a00\u6a21\u578b (LM) \u884c\u70ba\u4e4b\u9593\u7684\u4e00\u81f4\u6027\uff0c\u9019\u7a2e\u65b9\u6cd5\u53ef\u4ee5\u61c9\u7528\u65bc\u5fae\u8abf\u3001\u7dda\u4e0a\u76e3\u7763\u548c\u9810\u767c\u4f48\u5b89\u5168\u6aa2\u67e5\u3002\u6211\u5011\u7684\u300c\u4e00\u81f4\u6027\u93c8\u300d(CoA) \u65b9\u6cd5\u900f\u904e\u5efa\u7acb\u6a21\u578b\u884c\u70ba $\\textit{\u898f\u5247}$\uff0c\u4f7f\u5176\u8207\u898f\u7bc4\u6027 $\\textit{\u76ee\u6a19}$ \u4fdd\u6301\u4e00\u81f4\uff0c\u9032\u800c\u8207 $\\textit{\u516c\u773e\u610f\u9858}$ \u4fdd\u6301\u4e00\u81f4\uff0c\u5f9e\u800c\u7522\u751f\u57fa\u65bc\u898f\u5247\u7684\u734e\u52f5 (RBR)\u3002\u9019\u7a2e\u5206\u89e3\u4f7f\u975e\u5c08\u5bb6\u516c\u773e\u80fd\u5920\u900f\u904e\u898f\u7bc4\u6027\u76ee\u6a19\u76f4\u63a5\u8868\u9054\u4ed6\u5011\u7684\u610f\u9858\uff0c\u800c\u5c08\u5bb6\u667a\u6167\u5247\u7528\u65bc\u627e\u51fa\u860a\u542b\u6a21\u578b\u884c\u70ba\u7684\u898f\u5247\uff0c\u9019\u4e9b\u898f\u5247\u6700\u80fd\u5be6\u73fe\u9019\u4e9b\u76ee\u6a19\u3002\u6211\u5011\u900f\u904e\u5c07\u65b9\u6cd5\u61c9\u7528\u5728\u8207\u5fc3\u7406\u5065\u5eb7\u76f8\u95dc\u7684 LM \u63d0\u793a\u7684\u4e09\u500b\u4e0d\u540c\u9818\u57df\u4f86\u9a57\u8b49\u6211\u5011\u7684\u505a\u6cd5\u3002\u6211\u5011\u5c55\u793a\u4e86\u4e00\u500b\u5efa\u7acb\u5728\u96c6\u9ad4\u5c0d\u8a71\u548c\u57fa\u65bc\u6a4b\u63a5\u7684\u6392\u540d\u4e0a\u7684\u516c\u773e\u610f\u898b\u8f38\u5165\u6d41\u7a0b\uff0c\u8a72\u6d41\u7a0b\u53ef\u9760\u5730\u7522\u751f\u81f3\u5c11\u6709 $96\\% \\pm 2\\%$ \u7684\u7f8e\u570b\u516c\u773e\u652f\u6301\u7684\u898f\u7bc4\u6027\u76ee\u6a19\u3002\u7136\u5f8c\u6211\u5011\u5c55\u793a\u7531\u5fc3\u7406\u5065\u5eb7\u5c08\u5bb6\u5236\u5b9a\u4ee5\u5be6\u73fe\u9019\u4e9b\u76ee\u6a19\u7684\u898f\u5247\uff0c\u4f7f RBR \u80fd\u5920\u8a55\u4f30 LM \u56de\u61c9\u8207\u76ee\u6a19\u7684\u4e00\u81f4\u6027\uff0c\u5176\u65b9\u5f0f\u8207\u4eba\u985e\u5c08\u5bb6\u985e\u4f3c\uff08Pearson's $r=0.841$\uff0c$AUC=0.964$\uff09\u3002\u900f\u904e\u8861\u91cf\u8207\u7372\u5f97\u8fd1\u4e4e\u4e00\u81f4\u516c\u773e\u652f\u6301\u7684\u76ee\u6a19\u7684\u4e00\u81f4\u6027\uff0c\u9019\u4e9b CoA RBR \u63d0\u4f9b\u4e86 LM \u884c\u70ba\u8207\u516c\u773e\u610f\u9858\u4e4b\u9593\u4e00\u81f4\u6027\u7684\u8fd1\u4f3c\u8861\u91cf\u6a19\u6e96\u3002</paragraph>", "author": "Andrew Konya et.al.", "authors": "Andrew Konya, Aviv Ovadya, Kevin Feng, Quan Ze Chen, Lisa Schirch, Colin Irwin, Amy X. Zhang", "id": "2411.10534v1", "paper_url": "http://arxiv.org/abs/2411.10534v1", "repo": "null"}}