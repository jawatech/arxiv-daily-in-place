
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-07**|**Influences on LLM Calibration: A Study of Response Agreement, Loss Functions, and Prompt Styles**|Yuxi Xia et.al.|[2501.03991v1](http://arxiv.org/abs/2501.03991v1)|null|
|**2025-01-07**|**Semantically Cohesive Word Grouping in Indian Languages**|N J Karthika et.al.|[2501.03988v1](http://arxiv.org/abs/2501.03988v1)|null|
|**2025-01-07**|**VLM-driven Behavior Tree for Context-aware Task Planning**|Naoki Wake et.al.|[2501.03968v1](http://arxiv.org/abs/2501.03968v1)|null|
|**2025-01-07**|**Localizing AI: Evaluating Open-Weight Language Models for Languages of Baltic States**|Jurgita Kapočiūtė-Dzikienė et.al.|[2501.03952v1](http://arxiv.org/abs/2501.03952v1)|null|
|**2025-01-07**|**Synthetic Data Privacy Metrics**|Amy Steier et.al.|[2501.03941v1](http://arxiv.org/abs/2501.03941v1)|null|
|**2025-01-07**|**Not all tokens are created equal: Perplexity Attention Weighted Networks for AI generated text detection**|Pablo Miralles-González et.al.|[2501.03940v1](http://arxiv.org/abs/2501.03940v1)|null|
|**2025-01-07**|**From Newswire to Nexus: Using text-based actor embeddings and transformer networks to forecast conflict dynamics**|Mihai Croicu et.al.|[2501.03928v1](http://arxiv.org/abs/2501.03928v1)|null|
|**2025-01-07**|**Exploring the Potential of Large Language Models in Public Transportation: San Antonio Case Study**|Ramya Jonnala et.al.|[2501.03904v1](http://arxiv.org/abs/2501.03904v1)|null|
|**2025-01-07**|**LLaVA-Mini: Efficient Image and Video Large Multimodal Models with One Vision Token**|Shaolei Zhang et.al.|[2501.03895v1](http://arxiv.org/abs/2501.03895v1)|[link](https://github.com/ictnlp/llava-mini)|
|**2025-01-07**|**Neural DNF-MT: A Neuro-symbolic Approach for Learning Interpretable and Editable Policies**|Kexin Gu Baugh et.al.|[2501.03888v1](http://arxiv.org/abs/2501.03888v1)|null|
|**2025-01-07**|**AlphaPO -- Reward shape matters for LLM alignment**|Aman Gupta et.al.|[2501.03884v1](http://arxiv.org/abs/2501.03884v1)|null|
|**2025-01-07**|**CL3DOR: Contrastive Learning for 3D Large Multimodal Models via Odds Ratio on High-Resolution Point Clouds**|Keonwoo Kim et.al.|[2501.03879v1](http://arxiv.org/abs/2501.03879v1)|null|
|**2025-01-07**|**Add Noise, Tasks, or Layers? MaiNLP at the VarDial 2025 Shared Task on Norwegian Dialectal Slot and Intent Detection**|Verena Blaschke et.al.|[2501.03870v1](http://arxiv.org/abs/2501.03870v1)|null|
|**2025-01-07**|**Improving Dialectal Slot and Intent Detection with Auxiliary Tasks: A Multi-Dialectal Bavarian Case Study**|Xaver Maria Krückl et.al.|[2501.03863v1](http://arxiv.org/abs/2501.03863v1)|[link](https://github.com/mainlp/auxtasks-bavarian-sid)|
|**2025-01-07**|**Progressive Document-level Text Simplification via Large Language Models**|Dengzhao Fang et.al.|[2501.03857v1](http://arxiv.org/abs/2501.03857v1)|null|
|**2025-01-07**|**BabyLMs for isiXhosa: Data-Efficient Language Modelling in a Low-Resource Context**|Alexis Matzopoulos et.al.|[2501.03855v1](http://arxiv.org/abs/2501.03855v1)|null|
|**2025-01-07**|**Diffusion as Shader: 3D-aware Video Diffusion for Versatile Video Generation Control**|Zekai Gu et.al.|[2501.03847v1](http://arxiv.org/abs/2501.03847v1)|[link](https://github.com/igl-hkust/diffusionasshader)|
|**2025-01-07**|**BERTopic for Topic Modeling of Hindi Short Texts: A Comparative Study**|Atharva Mutsaddi et.al.|[2501.03843v1](http://arxiv.org/abs/2501.03843v1)|null|
|**2025-01-07**|**SCC-YOLO: An Improved Object Detector for Assisting in Brain Tumor Diagnosis**|Runci Bai et.al.|[2501.03836v1](http://arxiv.org/abs/2501.03836v1)|null|
|**2025-01-07**|**Three-dimensional attention Transformer for state evaluation in real-time strategy games**|Yanqing Ye et.al.|[2501.03832v1](http://arxiv.org/abs/2501.03832v1)|null|
|**2025-01-07**|**Investigating the Impact of Data Selection Strategies on Language Model Performance**|Jiayao Gu et.al.|[2501.03826v1](http://arxiv.org/abs/2501.03826v1)|[link](https://github.com/jgu13/hir-hybrid-importance-resampling-for-language-models)|
|**2025-01-07**|**Deep Sylvester Posterior Inference for Adaptive Compressed Sensing in Ultrasound Imaging**|Simon W. Penninga et.al.|[2501.03825v1](http://arxiv.org/abs/2501.03825v1)|null|
|**2025-01-07**|**Online Reinforcement Learning-Based Dynamic Adaptive Evaluation Function for Real-Time Strategy Tasks**|Weilong Yang et.al.|[2501.03824v1](http://arxiv.org/abs/2501.03824v1)|null|
|**2025-01-07**|**Detecting the Undetectable: Assessing the Efficacy of Current Spoof Detection Methods Against Seamless Speech Edits**|Sung-Feng Huang et.al.|[2501.03805v1](http://arxiv.org/abs/2501.03805v1)|null|
|**2025-01-07**|**Self-Adaptive ERP: Embedding NLP into Petri-Net creation and Model Matching**|Ahmed Maged et.al.|[2501.03795v1](http://arxiv.org/abs/2501.03795v1)|null|
|**2025-01-07**|**How to Select Pre-Trained Code Models for Reuse? A Learning Perspective**|Zhangqian Bi et.al.|[2501.03783v1](http://arxiv.org/abs/2501.03783v1)|null|
|**2025-01-07**|**SelectiveFinetuning: Enhancing Transfer Learning in Sleep Staging through Selective Domain Alignment**|Siyuan Zhao et.al.|[2501.03764v1](http://arxiv.org/abs/2501.03764v1)|null|
|**2025-01-07**|**Context-Alignment: Activating and Enhancing LLM Capabilities in Time Series**|Yuxiao Hu et.al.|[2501.03747v1](http://arxiv.org/abs/2501.03747v1)|null|
|**2025-01-07**|**Self-adaptive vision-language model for 3D segmentation of pulmonary artery and vein**|Xiaotong Guo et.al.|[2501.03722v1](http://arxiv.org/abs/2501.03722v1)|null|
|**2025-01-07**|**Unsupervised Speech Segmentation: A General Approach Using Speech Language Models**|Avishai Elmakies et.al.|[2501.03711v1](http://arxiv.org/abs/2501.03711v1)|[link](https://github.com/avishaielmakies/unsupervised_speech_segmentation_using_slm)|
|**2025-01-07**|**AuxDepthNet: Real-Time Monocular 3D Object Detection with Depth-Sensitive Features**|Ruochen Zhang et.al.|[2501.03700v1](http://arxiv.org/abs/2501.03700v1)|null|
|**2025-01-07**|**Exploring Molecule Generation Using Latent Space Graph Diffusion**|Prashanth Pombala et.al.|[2501.03696v1](http://arxiv.org/abs/2501.03696v1)|[link](https://github.com/prashanth-pombala/molecule-generation-using-latent-space-graph-diffusion)|
|**2025-01-07**|**MAJL: A Model-Agnostic Joint Learning Framework for Music Source Separation and Pitch Estimation**|Haojie Wei et.al.|[2501.03689v1](http://arxiv.org/abs/2501.03689v1)|null|
|**2025-01-07**|**SLAM: Towards Efficient Multilingual Reasoning via Selective Language Alignment**|Yuchun Fan et.al.|[2501.03681v1](http://arxiv.org/abs/2501.03681v1)|null|
|**2025-01-07**|**SALE-Based Offline Reinforcement Learning with Ensemble Q-Networks**|Zheng Chun et.al.|[2501.03676v1](http://arxiv.org/abs/2501.03676v1)|null|
|**2025-01-07**|**Action Quality Assessment via Hierarchical Pose-guided Multi-stage Contrastive Regression**|Mengshi Qi et.al.|[2501.03674v1](http://arxiv.org/abs/2501.03674v1)|null|
|**2025-01-07**|**A Diversity-Enhanced Knowledge Distillation Model for Practical Math Word Problem Solving**|Yi Zhang et.al.|[2501.03670v1](http://arxiv.org/abs/2501.03670v1)|[link](https://github.com/a773938364/divkd)|
|**2025-01-07**|**Effective and Efficient Mixed Precision Quantization of Speech Foundation Models**|Haoning Xu et.al.|[2501.03643v1](http://arxiv.org/abs/2501.03643v1)|null|
|**2025-01-07**|**MHGNet: Multi-Heterogeneous Graph Neural Network for Traffic Prediction**|Mei Wu et.al.|[2501.03635v1](http://arxiv.org/abs/2501.03635v1)|[link](https://github.com/meiwu5/mhgnet)|
|**2025-01-07**|**LlaMADRS: Prompting Large Language Models for Interview-Based Depression Assessment**|Gaoussou Youssouf Kebe et.al.|[2501.03624v1](http://arxiv.org/abs/2501.03624v1)|null|
|**2025-01-07**|**STContext: A Multifaceted Dataset for Developing Context-aware Spatio-temporal Crowd Mobility Prediction Models**|Liyue Chen et.al.|[2501.03583v1](http://arxiv.org/abs/2501.03583v1)|[link](https://github.com/liyue-chen/stcontext)|
|**2025-01-07**|**Cosmos World Foundation Model Platform for Physical AI**|NVIDIA et.al.|[2501.03575v1](http://arxiv.org/abs/2501.03575v1)|[link](https://github.com/nvidia/cosmos)|
|**2025-01-07**|**From Code to Compliance: Assessing ChatGPT's Utility in Designing an Accessible Webpage -- A Case Study**|Ammar Ahmed et.al.|[2501.03572v1](http://arxiv.org/abs/2501.03572v1)|null|
|**2025-01-07**|**Applying Large Language Models in Knowledge Graph-based Enterprise Modeling: Challenges and Opportunities**|Benedikt Reitemeyer et.al.|[2501.03566v1](http://arxiv.org/abs/2501.03566v1)|null|
|**2025-01-07**|**KG-TRICK: Unifying Textual and Relational Information Completion of Knowledge for Multilingual Knowledge Graphs**|Zelin Zhou et.al.|[2501.03560v1](http://arxiv.org/abs/2501.03560v1)|null|
|**2025-01-07**|**Beyond Factual Accuracy: Evaluating Coverage of Diverse Factual Information in Long-form Text Generation**|Chris Samarinas et.al.|[2501.03545v1](http://arxiv.org/abs/2501.03545v1)|null|
|**2025-01-07**|**PromptGuard: Soft Prompt-Guided Unsafe Content Moderation for Text-to-Image Models**|Lingzhi Yuan et.al.|[2501.03544v1](http://arxiv.org/abs/2501.03544v1)|null|
|**2025-01-07**|**Deep Learning within Tabular Data: Foundations, Challenges, Advances and Future Directions**|Weijieying Ren et.al.|[2501.03540v1](http://arxiv.org/abs/2501.03540v1)|null|
|**2025-01-07**|**SenseRAG: Constructing Environmental Knowledge Bases with Proactive Querying for LLM-Based Autonomous Driving**|Xuewen Luo et.al.|[2501.03535v1](http://arxiv.org/abs/2501.03535v1)|null|
|**2025-01-07**|**A Sequential Optimal Learning Approach to Automated Prompt Engineering in Large Language Models**|Shuyang Wang et.al.|[2501.03508v1](http://arxiv.org/abs/2501.03508v1)|null|
|**2025-01-07**|**Can Deep Learning Trigger Alerts from Mobile-Captured Images?**|Pritisha Sarkar et.al.|[2501.03499v1](http://arxiv.org/abs/2501.03499v1)|null|
|**2025-01-07**|**Can LLMs Design Good Questions Based on Context?**|Yueheng Zhang et.al.|[2501.03491v1](http://arxiv.org/abs/2501.03491v1)|[link](https://github.com/colearn-dev/llmqg)|
|**2025-01-07**|**Align-Pro: A Principled Approach to Prompt Optimization for LLM Alignment**|Prashant Trivedi et.al.|[2501.03486v1](http://arxiv.org/abs/2501.03486v1)|null|
|**2025-01-07**|**Women, Infamous, and Exotic Beings: What Honorific Usages in Wikipedia Reveal about the Socio-Cultural Norms**|Sourabrata Mukherjee et.al.|[2501.03479v1](http://arxiv.org/abs/2501.03479v1)|null|
|**2025-01-07**|**Reading with Intent -- Neutralizing Intent**|Benjamin Reichman et.al.|[2501.03475v1](http://arxiv.org/abs/2501.03475v1)|null|
|**2025-01-07**|**MTRAG: A Multi-Turn Conversational Benchmark for Evaluating Retrieval-Augmented Generation Systems**|Yannis Katsis et.al.|[2501.03468v1](http://arxiv.org/abs/2501.03468v1)|[link](https://github.com/ibm/mt-rag-benchmark)|
|**2025-01-07**|**LHGNN: Local-Higher Order Graph Neural Networks For Audio Classification and Tagging**|Shubhr Singh et.al.|[2501.03464v1](http://arxiv.org/abs/2501.03464v1)|null|
|**2025-01-07**|**ISSR: Iterative Selection with Self-Review for Vocabulary Test Distractor Generation**|Yu-Cheng Liu et.al.|[2501.03462v1](http://arxiv.org/abs/2501.03462v1)|null|
|**2025-01-07**|**Radar Signal Recognition through Self-Supervised Learning and Domain Adaptation**|Zi Huang et.al.|[2501.03461v1](http://arxiv.org/abs/2501.03461v1)|[link](https://github.com/abcxyzi/radcharssl)|
|**2025-01-07**|**Activating Associative Disease-Aware Vision Token Memory for LLM-Based X-ray Report Generation**|Xiao Wang et.al.|[2501.03458v1](http://arxiv.org/abs/2501.03458v1)|[link](https://github.com/event-ahu/medical_image_analysis)|
|**2025-01-07**|**Text to Band Gap: Pre-trained Language Models as Encoders for Semiconductor Band Gap Prediction**|Ying-Ting Yeh et.al.|[2501.03456v1](http://arxiv.org/abs/2501.03456v1)|null|
|**2025-01-07**|**Finding A Voice: Evaluating African American Dialect Generation for Chatbot Technology**|Sarah E. Finch et.al.|[2501.03441v1](http://arxiv.org/abs/2501.03441v1)|null|
|**2025-01-06**|**DAMAGE: Detecting Adversarially Modified AI Generated Text**|Elyas Masrour et.al.|[2501.03437v1](http://arxiv.org/abs/2501.03437v1)|null|
|**2025-01-06**|**SALT: Sales Autocompletion Linked Business Tables Dataset**|Tassilo Klein et.al.|[2501.03413v1](http://arxiv.org/abs/2501.03413v1)|[link](https://github.com/sap-samples/salt)|
|**2025-01-06**|**BoundingDocs: a Unified Dataset for Document Question Answering with Spatial Annotations**|Simone Giovannini et.al.|[2501.03403v1](http://arxiv.org/abs/2501.03403v1)|null|
|**2025-01-06**|**Over-the-Air Fair Federated Learning via Multi-Objective Optimization**|Shayan Mohajer Hamidi et.al.|[2501.03392v1](http://arxiv.org/abs/2501.03392v1)|[link](https://github.com/shayanmohajer/ota-ffl)|
|**2025-01-06**|**Existential Crisis: A Social Robot's Reason for Being**|Dora Medgyesy et.al.|[2501.03376v1](http://arxiv.org/abs/2501.03376v1)|null|
|**2025-01-06**|**License Plate Images Generation with Diffusion Models**|Mariia Shpir et.al.|[2501.03374v1](http://arxiv.org/abs/2501.03374v1)|null|
|**2025-01-06**|**Advanced Machine Learning Techniques for Social Support Detection on Social Media**|Olga Kolesnikova et.al.|[2501.03370v1](http://arxiv.org/abs/2501.03370v1)|null|
|**2025-01-06**|**FTA-FTL: A Fine-Tuned Aggregation Federated Transfer Learning Scheme for Lithology Microscopic Image Classification**|Keyvan RahimiZadeh et.al.|[2501.03349v1](http://arxiv.org/abs/2501.03349v1)|[link](https://github.com/ahmadtaheri2021/lithology-microscopic-images-mini-dataset)|
|**2025-01-06**|**Analyzing Bias in Swiss Federal Supreme Court Judgments Using Facebook's Holistic Bias Dataset: Implications for Language Model Training**|Sabine Wehnert et.al.|[2501.03324v1](http://arxiv.org/abs/2501.03324v1)|null|
|**2025-01-06**|**Gaussian Masked Autoencoders**|Jathushan Rajasegaran et.al.|[2501.03229v1](http://arxiv.org/abs/2501.03229v1)|null|
|**2025-01-06**|**LightGNN: Simple Graph Neural Network for Recommendation**|Guoxuan Chen et.al.|[2501.03228v2](http://arxiv.org/abs/2501.03228v2)|null|
|**2025-01-06**|**BoostStep: Boosting mathematical capability of Large Language Models via improved single-step reasoning**|Beichen Zhang et.al.|[2501.03226v1](http://arxiv.org/abs/2501.03226v1)|[link](https://github.com/beichenzbc/booststep)|
|**2025-01-06**|**Automated Generation of Challenging Multiple-Choice Questions for Vision Language Model Evaluation**|Yuhui Zhang et.al.|[2501.03225v1](http://arxiv.org/abs/2501.03225v1)|[link](https://github.com/yuhui-zh15/autoconverter)|
|**2025-01-06**|**Leveraging Explainable AI for LLM Text Attribution: Differentiating Human-Written and Multiple LLMs-Generated Text**|Ayat Najjar et.al.|[2501.03212v1](http://arxiv.org/abs/2501.03212v1)|null|
|**2025-01-06**|**Detecting AI-Generated Text in Educational Content: Leveraging Machine Learning and Explainable AI for Academic Integrity**|Ayat A. Najjar et.al.|[2501.03203v1](http://arxiv.org/abs/2501.03203v1)|null|
|**2025-01-06**|**The FACTS Grounding Leaderboard: Benchmarking LLMs' Ability to Ground Responses to Long-Form Input**|Alon Jacovi et.al.|[2501.03200v1](http://arxiv.org/abs/2501.03200v1)|null|
|**2025-01-06**|**CLIX: Cross-Lingual Explanations of Idiomatic Expressions**|Aaron Gluck et.al.|[2501.03191v1](http://arxiv.org/abs/2501.03191v1)|null|
|**2025-01-06**|**Turn-based Multi-Agent Reinforcement Learning Model Checking**|Dennis Gross et.al.|[2501.03187v1](http://arxiv.org/abs/2501.03187v1)|null|
|**2025-01-06**|**GLiREL -- Generalist Model for Zero-Shot Relation Extraction**|Jack Boylan et.al.|[2501.03172v1](http://arxiv.org/abs/2501.03172v1)|null|
|**2025-01-06**|**Semantic Captioning: Benchmark Dataset and Graph-Aware Few-Shot In-Context Learning for SQL2Text**|Ali Al-Lawati et.al.|[2501.03166v1](http://arxiv.org/abs/2501.03166v1)|[link](https://github.com/aliwister/ast-icl)|
|**2025-01-06**|**The Scaling Law for LoRA Base on Mutual Information Upper Bound**|Jing Zhang et.al.|[2501.03152v1](http://arxiv.org/abs/2501.03152v1)|null|
|**2025-01-06**|**Large language models for artificial general intelligence (AGI): A survey of foundational principles and approaches**|Alhassan Mumuni et.al.|[2501.03151v1](http://arxiv.org/abs/2501.03151v1)|null|
|**2025-01-06**|**Co-Activation Graph Analysis of Safety-Verified and Explainable Deep Reinforcement Learning Policies**|Dennis Gross et.al.|[2501.03142v1](http://arxiv.org/abs/2501.03142v1)|null|
|**2025-01-06**|**VicSim: Enhancing Victim Simulation with Emotional and Linguistic Fidelity**|Yerong Li et.al.|[2501.03139v1](http://arxiv.org/abs/2501.03139v1)|null|
|**2025-01-06**|**PRMBench: A Fine-grained and Challenging Benchmark for Process-Level Reward Models**|Mingyang Song et.al.|[2501.03124v2](http://arxiv.org/abs/2501.03124v2)|[link](https://github.com/ssmisya/PRMBench)|
|**2025-01-06**|**From Models to Network Topologies: A Topology Inference Attack in Decentralized Federated Learning**|Chao Feng et.al.|[2501.03119v1](http://arxiv.org/abs/2501.03119v1)|null|
|**2025-01-06**|**LangFair: A Python Package for Assessing Bias and Fairness in Large Language Model Use Cases**|Dylan Bouchard et.al.|[2501.03112v1](http://arxiv.org/abs/2501.03112v1)|[link](https://github.com/cvs-health/langfair)|
|**2025-01-06**|**Sentiment-guided Commonsense-aware Response Generation for Mental Health Counseling**|Aseem Srivastava et.al.|[2501.03088v1](http://arxiv.org/abs/2501.03088v1)|null|
|**2025-01-06**|**Personalized Fashion Recommendation with Image Attributes and Aesthetics Assessment**|Chongxian Chen et.al.|[2501.03085v1](http://arxiv.org/abs/2501.03085v1)|null|
|**2025-01-06**|**Rethinking Byzantine Robustness in Federated Recommendation from Sparse Aggregation Perspective**|Zhongjian Zhang et.al.|[2501.03301v1](http://arxiv.org/abs/2501.03301v1)|null|
|**2025-01-06**|**Trust Modeling in Counseling Conversations: A Benchmark Study**|Aseem Srivastava et.al.|[2501.03064v1](http://arxiv.org/abs/2501.03064v1)|null|
|**2025-01-06**|**Survival Analysis Revisited: Understanding and Unifying Poisson, Exponential, and Cox Models in Fall Risk Analysis**|Tianhua Chen et.al.|[2501.03058v1](http://arxiv.org/abs/2501.03058v1)|null|
|**2025-01-06**|**Single-Channel Distance-Based Source Separation for Mobile GPU in Outdoor and Indoor Environments**|Hanbin Bae et.al.|[2501.03045v1](http://arxiv.org/abs/2501.03045v1)|null|
|**2025-01-06**|**ChronoSense: Exploring Temporal Understanding in Large Language Models with Time Intervals of Events**|Duygu Sezen Islakoglu et.al.|[2501.03040v1](http://arxiv.org/abs/2501.03040v1)|null|
|**2025-01-06**|**Piano Transcription by Hierarchical Language Modeling with Pretrained Roll-based Encoders**|Dichucheng Li et.al.|[2501.03038v2](http://arxiv.org/abs/2501.03038v2)|null|
|**2025-01-06**|**Quantization Meets Reasoning: Exploring LLM Low-Bit Quantization Degradation for Mathematical Reasoning**|Zhen Li et.al.|[2501.03035v1](http://arxiv.org/abs/2501.03035v1)|null|
|**2025-01-06**|**Putnam's Critical and Explanatory Tendencies Interpreted from a Machine Learning Perspective**|Sheldon Z. Soudin et.al.|[2501.03026v1](http://arxiv.org/abs/2501.03026v1)|null|
|**2025-01-06**|**Analyzing Fine-tuning Representation Shift for Multimodal LLMs Steering alignment**|Pegah Khayatan et.al.|[2501.03012v1](http://arxiv.org/abs/2501.03012v1)|[link](https://github.com/mshukor/xl-vlms)|

#### Abstracts
##### **Influences on LLM Calibration: A Study of Response Agreement, Loss Functions, and Prompt Styles**
2501.03991v1 by Yuxi Xia, Pedro Henrique Luz de Araujo, Klim Zaporojets, Benjamin Roth

Calibration, the alignment between model confidence and prediction accuracy,
is critical for the reliable deployment of large language models (LLMs).
Existing works neglect to measure the generalization of their methods to other
prompt styles and different sizes of LLMs. To address this, we define a
controlled experimental setting covering 12 LLMs and four prompt styles. We
additionally investigate if incorporating the response agreement of multiple
LLMs and an appropriate loss function can improve calibration performance.
Concretely, we build Calib-n, a novel framework that trains an auxiliary model
for confidence estimation that aggregates responses from multiple LLMs to
capture inter-model agreement. To optimize calibration, we integrate focal and
AUC surrogate losses alongside binary cross-entropy. Experiments across four
datasets demonstrate that both response agreement and focal loss improve
calibration from baselines. We find that few-shot prompts are the most
effective for auxiliary model-based methods, and auxiliary models demonstrate
robust calibration performance across accuracy variations, outperforming LLMs'
internal probabilities and verbalized confidences. These insights deepen the
understanding of influence factors in LLM calibration, supporting their
reliable deployment in diverse applications.

摘要：校準，模型信心與預測準確度之間的對齊，對於大型語言模型 (LLM) 的可靠部署至關重要。現有研究忽略了衡量其方法對其他提示樣式和不同規模 LLM 的概括性。為了解決這個問題，我們定義了一個受控實驗設定，涵蓋 12 個 LLM 和四種提示樣式。我們進一步研究了是否納入多個 LLM 的回應協議和適當的損失函數可以改善校準性能。具體來說，我們構建了 Calib-n，一個新穎的框架，用於訓練一個輔助模型以進行信心估計，該模型彙總來自多個 LLM 的回應以捕捉模型間協議。為了優化校準，我們整合了焦點和 AUC 替代損失以及二元交叉熵。在四個數據集上的實驗表明，回應協議和焦點損失都改善了基準校準。我們發現，少次提示對於基於輔助模型的方法最有效，並且輔助模型在準確性變化中展示了穩健的校準性能，優於 LLM 的內部概率和言語化信心。這些見解加深了對 LLM 校準中影響因素的理解，支持了它們在各種應用中的可靠部署。

##### **Semantically Cohesive Word Grouping in Indian Languages**
2501.03988v1 by N J Karthika, Adyasha Patra, Nagasai Saketh Naidu, Arnab Bhattacharya, Ganesh Ramakrishnan, Chaitali Dangarikar

Indian languages are inflectional and agglutinative and typically follow
clause-free word order. The structure of sentences across most major Indian
languages are similar when their dependency parse trees are considered. While
some differences in the parsing structure occur due to peculiarities of a
language or its preferred natural way of conveying meaning, several apparent
differences are simply due to the granularity of representation of the smallest
semantic unit of processing in a sentence. The semantic unit is typically a
word, typographically separated by whitespaces. A single whitespace-separated
word in one language may correspond to a group of words in another. Hence,
grouping of words based on semantics helps unify the parsing structure of
parallel sentences across languages and, in the process, morphology. In this
work, we propose word grouping as a major preprocessing step for any
computational or linguistic processing of sentences for Indian languages. Among
Indian languages, since Hindi is one of the least agglutinative, we expect it
to benefit the most from word-grouping. Hence, in this paper, we focus on Hindi
to study the effects of grouping. We perform quantitative assessment of our
proposal with an intrinsic method that perturbs sentences by shuffling words as
well as an extrinsic evaluation that verifies the importance of word grouping
for the task of Machine Translation (MT) using decomposed prompting. We also
qualitatively analyze certain aspects of the syntactic structure of sentences.
Our experiments and analyses show that the proposed grouping technique brings
uniformity in the syntactic structures, as well as aids underlying NLP tasks.

摘要：<paragraph>印度語言是屈折的和黏著的，通常遵循無子句的詞序。當考慮其依存句法分析樹時，大多數主要印度語言的句子結構是相似的。雖然由於語言的特殊性或其傳達含義的自然方式而導致分析結構上存在一些差異，但幾個明顯的差異僅僅是句子中最小的語義處理單元的表示粒度。語義單元通常是一個詞，在排版上由空白分隔。一種語言中單獨的空白分隔詞可能對應於另一種語言中的一組詞。因此，基於語義對詞進行分組有助於統一跨語言的並行句子的分析結構，並在此過程中統一形態。在這項工作中，我們提出詞組作為印度語言的句子進行任何計算或語言處理的主要預處理步驟。在印度語言中，由於印地語是最不黏著的語言之一，我們預計它將從詞組中受益最多。因此，在本文中，我們專注於印地語來研究分組的影響。我們使用一種通過打亂詞彙來擾動句子的內在方法對我們的提案進行定量評估，以及一種驗證詞組對於使用分解提示的機器翻譯 (MT) 任務的重要性。我們還定性地分析了句子的句法結構的某些方面。我們的實驗和分析表明，所提出的分組技術為句法結構帶來了統一性，並有助於 NLP 的基礎任務。</paragraph>

##### **VLM-driven Behavior Tree for Context-aware Task Planning**
2501.03968v1 by Naoki Wake, Atsushi Kanehira, Jun Takamatsu, Kazuhiro Sasabuchi, Katsushi Ikeuchi

The use of Large Language Models (LLMs) for generating Behavior Trees (BTs)
has recently gained attention in the robotics community, yet remains in its
early stages of development. In this paper, we propose a novel framework that
leverages Vision-Language Models (VLMs) to interactively generate and edit BTs
that address visual conditions, enabling context-aware robot operations in
visually complex environments. A key feature of our approach lies in the
conditional control through self-prompted visual conditions. Specifically, the
VLM generates BTs with visual condition nodes, where conditions are expressed
as free-form text. Another VLM process integrates the text into its prompt and
evaluates the conditions against real-world images during robot execution. We
validated our framework in a real-world cafe scenario, demonstrating both its
feasibility and limitations.

摘要：大型語言模型 (LLM) 用於生成行為樹 (BT) 最近在機器人社群中引起關注，但仍處於發展的早期階段。在本文中，我們提出了一個新穎的架構，利用視覺語言模型 (VLM) 來互動式生成和編輯 BT，以處理視覺條件，並在視覺複雜的環境中實現具備情境感知能力的機器人操作。我們方法的一個關鍵特點在於透過自我提示的視覺條件進行條件控制。具體來說，VLM 會生成帶有視覺條件節點的 BT，其中條件以自由形式文字表示。另一個 VLM 程序會將文字整合到提示中，並在機器人執行期間針對真實世界的影像評估條件。我們在真實世界的咖啡廳場景中驗證了我們的架構，證明了它的可行性和限制。

##### **Localizing AI: Evaluating Open-Weight Language Models for Languages of Baltic States**
2501.03952v1 by Jurgita Kapočiūtė-Dzikienė, Toms Bergmanis, Mārcis Pinnis

Although large language models (LLMs) have transformed our expectations of
modern language technologies, concerns over data privacy often restrict the use
of commercially available LLMs hosted outside of EU jurisdictions. This limits
their application in governmental, defence, and other data-sensitive sectors.
In this work, we evaluate the extent to which locally deployable open-weight
LLMs support lesser-spoken languages such as Lithuanian, Latvian, and Estonian.
We examine various size and precision variants of the top-performing
multilingual open-weight models, Llama~3, Gemma~2, Phi, and NeMo, on machine
translation, multiple-choice question answering, and free-form text generation.
The results indicate that while certain models like Gemma~2 perform close to
the top commercially available models, many LLMs struggle with these languages.
Most surprisingly, however, we find that these models, while showing close to
state-of-the-art translation performance, are still prone to lexical
hallucinations with errors in at least 1 in 20 words for all open-weight
multilingual LLMs.

摘要：儘管大型語言模型 (LLM) 已轉變我們對現代語言科技的期待，但對於資料隱私的疑慮經常限制了在歐盟管轄區外託管的商業化 LLM 的使用。這限制了它們在政府、國防和其他資料敏感產業的應用。在這項工作中，我們評估了可本地部署的開放權重 LLM 對立陶宛語、拉脫維亞語和愛沙尼亞語等較少人使用的語言的支援程度。我們檢視了表現最佳的多語言開放權重模型 Llama~3、Gemma~2、Phi 和 NeMo 的各種規模和精準度變體，針對機器翻譯、多選題問答和自由形式文字生成。結果顯示，儘管某些模型（例如 Gemma~2）的表現接近頂尖的商業化模型，但許多 LLM 在處理這些語言時仍有困難。然而，最令人驚訝的是，我們發現這些模型在展現接近最先進的翻譯表現同時，仍容易出現詞彙幻覺，所有開放權重的多語言 LLM 每 20 個字中至少有 1 個字出現錯誤。

##### **Synthetic Data Privacy Metrics**
2501.03941v1 by Amy Steier, Lipika Ramaswamy, Andre Manoel, Alexa Haushalter

Recent advancements in generative AI have made it possible to create
synthetic datasets that can be as accurate as real-world data for training AI
models, powering statistical insights, and fostering collaboration with
sensitive datasets while offering strong privacy guarantees. Effectively
measuring the empirical privacy of synthetic data is an important step in the
process. However, while there is a multitude of new privacy metrics being
published every day, there currently is no standardization. In this paper, we
review the pros and cons of popular metrics that include simulations of
adversarial attacks. We also review current best practices for amending
generative models to enhance the privacy of the data they create (e.g.
differential privacy).

摘要：生成式 AI 近期取得的进步使得创建合成数据集成为可能，这些数据集可以与真实世界数据一样准确，用于训练 AI 模型，为统计洞察力提供支持，并促进对敏感数据集的协作，同时提供强有力的隐私保障。有效衡量合成数据的经验隐私是该过程中的重要一步。然而，虽然每天都会发布大量新的隐私指标，但目前还没有标准化。在本文中，我们回顾了包括对抗攻击模拟在内的流行指标的优点和缺点。我们还回顾了当前为修改生成模型以增强其创建的数据的隐私（例如差分隐私）的最佳实践。

##### **Not all tokens are created equal: Perplexity Attention Weighted Networks for AI generated text detection**
2501.03940v1 by Pablo Miralles-González, Javier Huertas-Tato, Alejandro Martín, David Camacho

The rapid advancement in large language models (LLMs) has significantly
enhanced their ability to generate coherent and contextually relevant text,
raising concerns about the misuse of AI-generated content and making it
critical to detect it. However, the task remains challenging, particularly in
unseen domains or with unfamiliar LLMs. Leveraging LLM next-token distribution
outputs offers a theoretically appealing approach for detection, as they
encapsulate insights from the models' extensive pre-training on diverse
corpora. Despite its promise, zero-shot methods that attempt to operationalize
these outputs have met with limited success. We hypothesize that one of the
problems is that they use the mean to aggregate next-token distribution metrics
across tokens, when some tokens are naturally easier or harder to predict and
should be weighted differently. Based on this idea, we propose the Perplexity
Attention Weighted Network (PAWN), which uses the last hidden states of the LLM
and positions to weight the sum of a series of features based on metrics from
the next-token distribution across the sequence length. Although not zero-shot,
our method allows us to cache the last hidden states and next-token
distribution metrics on disk, greatly reducing the training resource
requirements. PAWN shows competitive and even better performance
in-distribution than the strongest baselines (fine-tuned LMs) with a fraction
of their trainable parameters. Our model also generalizes better to unseen
domains and source models, with smaller variability in the decision boundary
across distribution shifts. It is also more robust to adversarial attacks, and
if the backbone has multilingual capabilities, it presents decent
generalization to languages not seen during supervised training, with LLaMA3-1B
reaching a mean macro-averaged F1 score of 81.46% in cross-validation with nine
languages.

摘要：大型語言模型 (LLM) 的快速進步大幅提升了它們生成連貫且與語境相關文字的能力，引發了對 AI 生成的內容被濫用的擔憂，並使其偵測變得至關重要。然而，這項任務仍然具有挑戰性，尤其是在未見過的領域或不熟悉的 LLM 中。利用 LLM 下一個代幣分佈輸出提供了一個理論上對偵測有吸引力的方法，因為它們概括了模型在各種語料庫上進行廣泛預訓練的見解。儘管有這樣的承諾，但試圖將這些輸出操作化的零次學習方法卻只獲得了有限的成功。我們假設其中一個問題是它們使用平均值來彙總代幣的下一代幣分佈指標，而有些代幣在預測上自然比較容易或困難，並且應該賦予不同的權重。基於這個想法，我們提出了困惑度注意力加權網路 (PAWN)，它使用 LLM 的最後隱藏狀態和位置來根據序列長度中下一代幣分佈的指標加權一系列特徵的總和。儘管不是零次學習，但我們的這種方法允許我們將最後的隱藏狀態和下一代幣分佈指標快取到磁碟中，大幅減少訓練資源需求。PAWN 在分佈中顯示出比最強的基準（微調語言模型）更具競爭力甚至更好的效能，而其可訓練參數只佔它們的一小部分。我們的模型對於未見過的領域和原始模型也有更好的泛化能力，在分佈轉移中決策邊界的變異較小。它對對抗性攻擊也更強健，而且如果主幹具有多語言能力，它會對在監督訓練期間未見過的語言呈現出良好的泛化能力，其中 LLaMA3-1B 在與九種語言的交叉驗證中達到平均巨觀 F1 分數 81.46%。

##### **From Newswire to Nexus: Using text-based actor embeddings and transformer networks to forecast conflict dynamics**
2501.03928v1 by Mihai Croicu, Simon Polichinel von der Maase

This study advances the field of conflict forecasting by using text-based
actor embeddings with transformer models to predict dynamic changes in violent
conflict patterns at the actor level. More specifically, we combine newswire
texts with structured conflict event data and leverage recent advances in
Natural Language Processing (NLP) techniques to forecast escalations and
de-escalations among conflicting actors, such as governments, militias,
separatist movements, and terrorists. This new approach accurately and promptly
captures the inherently volatile patterns of violent conflicts, which existing
methods have not been able to achieve. To create this framework, we began by
curating and annotating a vast international newswire corpus, leveraging
hand-labeled event data from the Uppsala Conflict Data Program. By using this
hybrid dataset, our models can incorporate the textual context of news sources
along with the precision and detail of structured event data. This combination
enables us to make both dynamic and granular predictions about conflict
developments. We validate our approach through rigorous back-testing against
historical events, demonstrating superior out-of-sample predictive power. We
find that our approach is quite effective in identifying and predicting phases
of conflict escalation and de-escalation, surpassing the capabilities of
traditional models. By focusing on actor interactions, our explicit goal is to
provide actionable insights to policymakers, humanitarian organizations, and
peacekeeping operations in order to enable targeted and effective intervention
strategies.

摘要：本研究透過使用基於文字的演員嵌入與轉換器模型來預測演員層級暴力衝突模式的動態變化，推進了衝突預測領域。更具體地說，我們結合新聞電文與結構化的衝突事件資料，並利用自然語言處理 (NLP) 技術的最新進展來預測衝突行為者（例如政府、民兵、分離主義運動和恐怖分子）之間的升級和降級。這種新方法準確且及時地捕捉了暴力衝突固有的不穩定模式，這是現有方法無法達到的。為了建立這個架構，我們首先整理並註解了一個龐大的國際新聞電文語料庫，利用烏普薩拉衝突資料計畫的手動標記事件資料。透過使用這個混合資料集，我們的模型可以結合新聞來源的文字脈絡以及結構化事件資料的精確性和細節。這種組合使我們能夠對衝突發展做出動態且細緻的預測。我們透過針對歷史事件進行嚴格的反向測試來驗證我們的方法，展示了卓越的樣本外預測能力。我們發現，我們的方法在識別和預測衝突升級和降級階段方面非常有效，超越了傳統模型的能力。透過專注於演員互動，我們的明確目標是為政策制定者、人道主義組織和維和行動提供可行的見解，以便制定有針對性和有效的干預策略。

##### **Exploring the Potential of Large Language Models in Public Transportation: San Antonio Case Study**
2501.03904v1 by Ramya Jonnala, Gongbo Liang, Jeong Yang, Izzat Alsmadi

The integration of large language models (LLMs) into public transit systems
presents a transformative opportunity to enhance urban mobility. This study
explores the potential of LLMs to revolutionize public transportation
management within the context of San Antonio's transit system. Leveraging the
capabilities of LLMs in natural language processing and data analysis, we
investigate their capabilities to optimize route planning, reduce wait times,
and provide personalized travel assistance. By utilizing the General Transit
Feed Specification (GTFS) and other relevant data, this research aims to
demonstrate how LLMs can potentially improve resource allocation, elevate
passenger satisfaction, and inform data-driven decision-making in transit
operations. A comparative analysis of different ChatGPT models was conducted to
assess their ability to understand transportation information, retrieve
relevant data, and provide comprehensive responses. Findings from this study
suggest that while LLMs hold immense promise for public transit, careful
engineering and fine-tuning are essential to realizing their full potential.
San Antonio serves as a case study to inform the development of LLM-powered
transit systems in other urban environments.

摘要：大型語言模型 (LLM) 整合到公共交通系統中，為提升城市流動性帶來轉型契機。本研究探討 LLM 在聖安東尼奧交通系統脈絡下，革新大眾運輸管理的潛力。利用 LLM 在自然語言處理和資料分析方面的能力，我們探討其在優化路線規劃、縮短等候時間，以及提供個人化旅遊協助方面的能力。透過利用通用大眾運輸資料規範 (GTFS) 和其他相關資料，本研究旨在證明 LLM 如何潛在提升資源配置、提升乘客滿意度，以及在交通營運中提供資料驅動的決策。針對不同的 ChatGPT 模型進行比較分析，以評估其理解交通資訊、擷取相關資料，以及提供全面回應的能力。本研究的發現顯示，儘管 LLM 對大眾運輸極具前景，但精密的工程和微調對於實現其全部潛力至關重要。聖安東尼奧作為一個案例研究，為在其他都市環境中開發由 LLM 驅動的交通系統提供參考。

##### **LLaVA-Mini: Efficient Image and Video Large Multimodal Models with One Vision Token**
2501.03895v1 by Shaolei Zhang, Qingkai Fang, Zhe Yang, Yang Feng

The advent of real-time large multimodal models (LMMs) like GPT-4o has
sparked considerable interest in efficient LMMs. LMM frameworks typically
encode visual inputs into vision tokens (continuous representations) and
integrate them and textual instructions into the context of large language
models (LLMs), where large-scale parameters and numerous context tokens
(predominantly vision tokens) result in substantial computational overhead.
Previous efforts towards efficient LMMs always focus on replacing the LLM
backbone with smaller models, while neglecting the crucial issue of token
quantity. In this paper, we introduce LLaVA-Mini, an efficient LMM with minimal
vision tokens. To achieve a high compression ratio of vision tokens while
preserving visual information, we first analyze how LMMs understand vision
tokens and find that most vision tokens only play a crucial role in the early
layers of LLM backbone, where they mainly fuse visual information into text
tokens. Building on this finding, LLaVA-Mini introduces modality pre-fusion to
fuse visual information into text tokens in advance, thereby facilitating the
extreme compression of vision tokens fed to LLM backbone into one token.
LLaVA-Mini is a unified large multimodal model that can support the
understanding of images, high-resolution images, and videos in an efficient
manner. Experiments across 11 image-based and 7 video-based benchmarks
demonstrate that LLaVA-Mini outperforms LLaVA-v1.5 with just 1 vision token
instead of 576. Efficiency analyses reveal that LLaVA-Mini can reduce FLOPs by
77%, deliver low-latency responses within 40 milliseconds, and process over
10,000 frames of video on the GPU hardware with 24GB of memory.

摘要：隨著 GPT-4o 等即時大型多模態模型 (LMM) 的出現，對於高效能 LMM 的興趣也大幅提升。LMM 架構通常會將視覺輸入編碼成視覺符號（連續表示），並將其與文字說明整合到大型語言模型 (LLM) 的脈絡中，其中大規模參數和大量的脈絡符號（主要是視覺符號）會造成大量的運算負擔。先前對於高效能 LMM 的努力總是專注於用較小的模型取代 LLM 主幹，而忽略了符號數量這個關鍵問題。在本文中，我們將介紹 LLaVA-Mini，這是一個符號數量最少的 LMM。為了在保留視覺資訊的同時，達成視覺符號的高壓縮率，我們首先分析 LMM 如何理解視覺符號，並發現大部分的視覺符號只在 LLM 主幹的早期層中扮演關鍵角色，在這些層中，它們主要將視覺資訊融合到文字符號中。基於這個發現，LLaVA-Mini 引入了模態預融合，以預先將視覺資訊融合到文字符號中，從而促進將輸入 LLM 主幹的視覺符號極度壓縮成一個符號。LLaVA-Mini 是一個統一的大型多模態模型，能夠以一種高效能的方式理解影像、高解析度影像和影片。在 11 個基於影像的基準和 7 個基於影片的基準的實驗中，證明 LLaVA-Mini 的效能優於 LLaVA-v1.5，僅使用 1 個視覺符號，而非 576 個。效率分析顯示，LLaVA-Mini 可以減少 77% 的 FLOP，在 40 毫秒內提供低延遲的回應，並在配備 24GB 記憶體的 GPU 硬體上處理超過 10,000 幀的影片。

##### **Neural DNF-MT: A Neuro-symbolic Approach for Learning Interpretable and Editable Policies**
2501.03888v1 by Kexin Gu Baugh, Luke Dickens, Alessandra Russo

Although deep reinforcement learning has been shown to be effective, the
model's black-box nature presents barriers to direct policy interpretation. To
address this problem, we propose a neuro-symbolic approach called neural DNF-MT
for end-to-end policy learning. The differentiable nature of the neural DNF-MT
model enables the use of deep actor-critic algorithms for training. At the same
time, its architecture is designed so that trained models can be directly
translated into interpretable policies expressed as standard (bivalent or
probabilistic) logic programs. Moreover, additional layers can be included to
extract abstract features from complex observations, acting as a form of
predicate invention. The logic representations are highly interpretable, and we
show how the bivalent representations of deterministic policies can be edited
and incorporated back into a neural model, facilitating manual intervention and
adaptation of learned policies. We evaluate our approach on a range of tasks
requiring learning deterministic or stochastic behaviours from various forms of
observations. Our empirical results show that our neural DNF-MT model performs
at the level of competing black-box methods whilst providing interpretable
policies.

摘要：儘管深度強化學習已被證明有效，但模型的黑箱性質對直接政策詮釋造成了障礙。為了解決這個問題，我們提出了一種稱為神經符號方法的神經 DNF-MT，用於端對端政策學習。神經 DNF-MT 模型的可微分特性使得能夠使用深度動作者-評論家演算法進行訓練。同時，其架構被設計成訓練好的模型可以直接轉換為可解釋的政策，表示為標準（二值或機率）邏輯程式。此外，可以包含額外的層級，從複雜的觀察中提取抽象特徵，作為一種謂詞發明的形式。邏輯表示高度可解釋，我們展示了確定性政策的二值表示如何被編輯並整合回神經模型中，促進手動介入和學習政策的適應。我們在各種任務上評估我們的方法，這些任務需要從各種形式的觀察中學習確定性或隨機行為。我們的經驗結果表明，我們的神經 DNF-MT 模型在競爭黑箱方法的層級上執行，同時提供可解釋的政策。

##### **AlphaPO -- Reward shape matters for LLM alignment**
2501.03884v1 by Aman Gupta, Shao Tang, Qingquan Song, Sirou Zhu, Jiwoo Hong, Ankan Saha, Viral Gupta, Noah Lee, Eunki Kim, Jason Zhu, Natesh Pillai, S. Sathiya Keerthi

Reinforcement Learning with Human Feedback (RLHF) and its variants have made
huge strides toward the effective alignment of large language models (LLMs) to
follow instructions and reflect human values. More recently, Direct Alignment
Algorithms (DAAs) have emerged in which the reward modeling stage of RLHF is
skipped by characterizing the reward directly as a function of the policy being
learned. Examples include Direct Preference Optimization (DPO) and Simple
Preference Optimization (SimPO). These methods often suffer from likelihood
displacement, a phenomenon by which the probabilities of preferred responses
are often reduced undesirably.
  In this paper, we argue that, for DAAs the reward (function) shape matters.
We introduce AlphaPO, a new DAA method that leverages an $\alpha$-parameter to
help change the shape of the reward function beyond the standard log reward.
AlphaPO helps maintain fine-grained control over likelihood displacement and
over-optimization. Compared to SimPO, one of the best performing DAAs, AlphaPO
leads to about 7\% to 10\% relative improvement in alignment performance for
the instruct versions of Mistral-7B and Llama3-8B. The analysis and results
presented highlight the importance of the reward shape, and how one can
systematically change it to affect training dynamics, as well as improve
alignment performance.

摘要：人類回饋強化學習 (RLHF) 及其變體已在大型語言模型 (LLM) 的有效對齊方面取得重大進展，以遵循指令並反映人類價值觀。最近，直接對齊演算法 (DAA) 已出現，其中 RLHF 的獎勵模型階段透過將獎勵直接表徵為正在學習的政策的函數來跳過。範例包括直接偏好最佳化 (DPO) 和簡單偏好最佳化 (SimPO)。這些方法通常會受到似然位移的影響，這是一種現象，其中偏好回應的機率通常會不必要地降低。
在本文中，我們論證，對於 DAA，獎勵（函數）形狀很重要。我們引入了 AlphaPO，這是一種新的 DAA 方法，它利用 $\alpha$-參數來幫助改變獎勵函數的形狀，超越標準的對數獎勵。AlphaPO 有助於維持對似然位移和過度最佳化的細緻控制。與表現最好的 DAA 之一 SimPO 相比，AlphaPO 導致 Mistral-7B 和 Llama3-8B 的指令版本在對齊效能方面相對改善了約 7% 到 10%。所呈現的分析和結果突出了獎勵形狀的重要性，以及如何系統地改變它以影響訓練動態，以及改善對齊效能。

##### **CL3DOR: Contrastive Learning for 3D Large Multimodal Models via Odds Ratio on High-Resolution Point Clouds**
2501.03879v1 by Keonwoo Kim, Yeongjae Cho, Taebaek Hwang, Minsoo Jo, Sangdo Han

Recent research has demonstrated that Large Language Models (LLMs) are not
limited to text-only tasks but can also function as multimodal models across
various modalities, including audio, images, and videos. In particular,
research on 3D Large Multimodal Models (3D LMMs) is making notable strides,
driven by the potential of processing higher-dimensional data like point
clouds. However, upon closer examination, we find that the visual and textual
content within each sample of existing training datasets lacks both high
informational granularity and clarity, which serve as a bottleneck for precise
cross-modal understanding. To address these issues, we propose CL3DOR,
Contrastive Learning for 3D large multimodal models via Odds ratio on
high-Resolution point clouds, designed to ensure greater specificity and
clarity in both visual and textual content. Specifically, we increase the
density of point clouds per object and construct informative hard negative
responses in the training dataset to penalize unwanted responses. To leverage
hard negative responses, we incorporate the odds ratio as an auxiliary term for
contrastive learning into the conventional language modeling loss. CL3DOR
achieves state-of-the-art performance in 3D scene understanding and reasoning
benchmarks. Additionally, we demonstrate the effectiveness of CL3DOR's key
components through extensive experiments.

摘要：最近的研究表明，大语言模型 (LLM) 不仅限于纯文本任务，还可以跨越各种模式（包括音频、图像和视频）作为多模态模型发挥作用。特别是，3D 大多模态模型 (3D LMM) 的研究正在取得显著进展，这得益于处理点云等高维数据的潜力。然而，经过仔细检查，我们发现现有训练数据集的每个样本中的视觉和文本内容都缺乏高信息粒度和清晰度，这成为精确跨模态理解的瓶颈。为了解决这些问题，我们提出了 CL3DOR，即通过高分辨率点云上的比值对 3D 大多模态模型进行对比学习，旨在确保视觉和文本内容具有更高的特异性和清晰度。具体来说，我们增加了每个对象的点云密度，并在训练数据集中构建信息丰富的硬负面响应，以惩罚不需要的响应。为了利用硬负面响应，我们将比值作为对比学习的辅助项纳入传统的语言建模损失中。CL3DOR 在 3D 场景理解和推理基准测试中取得了最先进的性能。此外，我们通过大量的实验展示了 CL3DOR 关键组件的有效性。

##### **Add Noise, Tasks, or Layers? MaiNLP at the VarDial 2025 Shared Task on Norwegian Dialectal Slot and Intent Detection**
2501.03870v1 by Verena Blaschke, Felicia Körner, Barbara Plank

Slot and intent detection (SID) is a classic natural language understanding
task. Despite this, research has only more recently begun focusing on SID for
dialectal and colloquial varieties. Many approaches for low-resource scenarios
have not yet been applied to dialectal SID data, or compared to each other on
the same datasets. We participate in the VarDial 2025 shared task on slot and
intent detection in Norwegian varieties, and compare multiple set-ups: varying
the training data (English, Norwegian, or dialectal Norwegian), injecting
character-level noise, training on auxiliary tasks, and applying Layer
Swapping, a technique in which layers of models fine-tuned on different
datasets are assembled into a model. We find noise injection to be beneficial
while the effects of auxiliary tasks are mixed. Though some experimentation was
required to successfully assemble a model from layers, it worked surprisingly
well; a combination of models trained on English and small amounts of dialectal
data produced the most robust slot predictions. Our best models achieve 97.6%
intent accuracy and 85.6% slot F1 in the shared task.

摘要：時隙和意圖偵測 (SID) 是經典的自然語言理解任務。儘管如此，研究直到最近才開始專注於方言和口語變體的 SID。許多低資源場景的方法尚未應用於方言 SID 資料，或在同一資料集上進行相互比較。我們參與了 VarDial 2025 共享任務，針對挪威語變體的時隙和意圖偵測，並比較多種設定：變更訓練資料 (英語、挪威語或挪威方言)、注入字元層級雜訊、針對輔助任務進行訓練，以及套用層交換，這是一種將針對不同資料集微調的模型層組裝成一個模型的技術。我們發現雜訊注入有益，而輔助任務的效果則好壞參半。儘管需要一些實驗才能成功從各層組裝模型，但效果卻出人意料地好；針對英語和小量方言資料訓練的模型組合產生了最穩健的時隙預測。我們最佳的模型在共享任務中達到了 97.6% 的意圖準確度和 85.6% 的時隙 F1 分數。

##### **Improving Dialectal Slot and Intent Detection with Auxiliary Tasks: A Multi-Dialectal Bavarian Case Study**
2501.03863v1 by Xaver Maria Krückl, Verena Blaschke, Barbara Plank

Reliable slot and intent detection (SID) is crucial in natural language
understanding for applications like digital assistants. Encoder-only
transformer models fine-tuned on high-resource languages generally perform well
on SID. However, they struggle with dialectal data, where no standardized form
exists and training data is scarce and costly to produce. We explore zero-shot
transfer learning for SID, focusing on multiple Bavarian dialects, for which we
release a new dataset for the Munich dialect. We evaluate models trained on
auxiliary tasks in Bavarian, and compare joint multi-task learning with
intermediate-task training. We also compare three types of auxiliary tasks:
token-level syntactic tasks, named entity recognition (NER), and language
modelling. We find that the included auxiliary tasks have a more positive
effect on slot filling than intent classification (with NER having the most
positive effect), and that intermediate-task training yields more consistent
performance gains. Our best-performing approach improves intent classification
performance on Bavarian dialects by 5.1 and slot filling F1 by 8.4 percentage
points.

摘要：可靠的槽位和意图检测 (SID) 在自然语言理解中至关重要，例如数位助理应用程序。仅编码器转换器模型经过微调，在高资源语言上通常在 SID 上表现良好。然而，它们难以处理方言数据，其中不存在标准化形式，并且训练数据稀缺且制作成本高昂。我们探索了 SID 的零次学习迁移学习，重点关注多种巴伐利亚方言，为此我们发布了慕尼黑方言的新数据集。我们评估了在巴伐利亚辅助任务中训练的模型，并将联合多任务学习与中间任务训练进行比较。我们还比较了三种类型的辅助任务：标记级句法任务、命名实体识别 (NER) 和语言建模。我们发现包含的辅助任务对槽位填充的影响比意图分类更积极（NER 影响最积极），并且中间任务训练产生了更一致的性能提升。我们表现最好的方法将巴伐利亚方言的意图分类性能提高了 5.1，槽位填充 F1 提高了 8.4 个百分点。

##### **Progressive Document-level Text Simplification via Large Language Models**
2501.03857v1 by Dengzhao Fang, Jipeng Qiang, Yi Zhu, Yunhao Yuan, Wei Li, Yan Liu

Research on text simplification has primarily focused on lexical and
sentence-level changes. Long document-level simplification (DS) is still
relatively unexplored. Large Language Models (LLMs), like ChatGPT, have
excelled in many natural language processing tasks. However, their performance
on DS tasks is unsatisfactory, as they often treat DS as merely document
summarization. For the DS task, the generated long sequences not only must
maintain consistency with the original document throughout, but complete
moderate simplification operations encompassing discourses, sentences, and
word-level simplifications. Human editors employ a hierarchical complexity
simplification strategy to simplify documents. This study delves into
simulating this strategy through the utilization of a multi-stage collaboration
using LLMs. We propose a progressive simplification method (ProgDS) by
hierarchically decomposing the task, including the discourse-level,
topic-level, and lexical-level simplification. Experimental results demonstrate
that ProgDS significantly outperforms existing smaller models or direct
prompting with LLMs, advancing the state-of-the-art in the document
simplification task.

摘要：文本簡化的研究主要集中在詞彙和句子層級的改變。長篇文件層級的簡化（DS）仍相對未被探討。大型語言模型（LLM），例如 ChatGPT，在許多自然語言處理任務中表現出色。然而，它們在 DS 任務上的表現並不令人滿意，因為它們常常將 DS 視為單純的文件摘要。對於 DS 任務，產生的長序列不僅必須始終與原始文件保持一致，而且必須包含涵蓋語篇、句子和詞彙層級簡化的適度簡化操作。人工編輯採用階層式複雜性簡化策略來簡化文件。本研究深入探討透過利用 LLM 的多階段協作來模擬此策略。我們提出了一種漸進簡化方法（ProgDS），透過階層式分解任務，包括語篇層級、主題層級和詞彙層級的簡化。實驗結果證明，ProgDS 明顯優於現有的較小模型或使用 LLM 直接提示，推動了文件簡化任務的最新技術。

##### **BabyLMs for isiXhosa: Data-Efficient Language Modelling in a Low-Resource Context**
2501.03855v1 by Alexis Matzopoulos, Charl Hendriks, Hishaam Mahomed, Francois Meyer

The BabyLM challenge called on participants to develop sample-efficient
language models. Submissions were pretrained on a fixed English corpus, limited
to the amount of words children are exposed to in development (<100m). The
challenge produced new architectures for data-efficient language modelling,
which outperformed models trained on trillions of words. This is promising for
low-resource languages, where available corpora are limited to much less than
100m words. In this paper, we explore the potential of BabyLMs for low-resource
languages, using the isiXhosa language as a case study. We pretrain two BabyLM
architectures, ELC-BERT and MLSM, on an isiXhosa corpus. They outperform a
vanilla pretrained model on POS tagging and NER, achieving notable gains (+3.2
F1) for the latter. In some instances, the BabyLMs even outperform XLM-R. Our
findings show that data-efficient models are viable for low-resource languages,
but highlight the continued importance, and lack of, high-quality pretraining
data. Finally, we visually analyse how BabyLM architectures encode isiXhosa.

摘要：BabyLM 挑戰要求參與者開發出樣本效率語言模型。提交的模型在固定的英語語料庫上進行預訓練，並限制在兒童在發展過程中接觸到的詞彙量（<100m）。該挑戰產生了用於資料效率語言建模的新架構，其效能優於在數兆個詞彙上訓練的模型。這對於低資源語言來說很有希望，因為可用的語料庫限制在遠少於 100m 個詞彙。在本文中，我們探討了 BabyLM 在低資源語言中的潛力，並以 isiXhosa 語言作為案例研究。我們在 isiXhosa 語料庫上預訓練了兩個 BabyLM 架構，ELC-BERT 和 MLSM。它們在詞性標記和 NER 上的表現優於香草預訓練模型，後者獲得了顯著的增益（+3.2 F1）。在某些情況下，BabyLM 甚至優於 XLM-R。我們的研究結果表明，資料效率模型對於低資源語言是可行的，但強調了高品質預訓練資料的持續重要性和缺乏。最後，我們視覺化分析了 BabyLM 架構如何編碼 isiXhosa。

##### **Diffusion as Shader: 3D-aware Video Diffusion for Versatile Video Generation Control**
2501.03847v1 by Zekai Gu, Rui Yan, Jiahao Lu, Peng Li, Zhiyang Dou, Chenyang Si, Zhen Dong, Qifeng Liu, Cheng Lin, Ziwei Liu, Wenping Wang, Yuan Liu

Diffusion models have demonstrated impressive performance in generating
high-quality videos from text prompts or images. However, precise control over
the video generation process, such as camera manipulation or content editing,
remains a significant challenge. Existing methods for controlled video
generation are typically limited to a single control type, lacking the
flexibility to handle diverse control demands. In this paper, we introduce
Diffusion as Shader (DaS), a novel approach that supports multiple video
control tasks within a unified architecture. Our key insight is that achieving
versatile video control necessitates leveraging 3D control signals, as videos
are fundamentally 2D renderings of dynamic 3D content. Unlike prior methods
limited to 2D control signals, DaS leverages 3D tracking videos as control
inputs, making the video diffusion process inherently 3D-aware. This innovation
allows DaS to achieve a wide range of video controls by simply manipulating the
3D tracking videos. A further advantage of using 3D tracking videos is their
ability to effectively link frames, significantly enhancing the temporal
consistency of the generated videos. With just 3 days of fine-tuning on 8 H800
GPUs using less than 10k videos, DaS demonstrates strong control capabilities
across diverse tasks, including mesh-to-video generation, camera control,
motion transfer, and object manipulation.

摘要：擴散模型已展現出令人印象深刻的效能，能從文字提示或影像產生高品質的影片。然而，對於影片產生流程的精準控制，例如相機操作或內容編輯，仍然是一項重大的挑戰。現有的受控影片產生方法通常僅限於單一控制類型，缺乏處理多樣控制需求的彈性。在本文中，我們介紹了擴散作為著色器 (DaS)，這是一種新穎的方法，可在統一的架構中支援多項影片控制任務。我們的關鍵見解是，要實現多功能影片控制，必須利用 3D 控制訊號，因為影片基本上是動態 3D 內容的 2D 渲染。與僅限於 2D 控制訊號的先前方法不同，DaS 利用 3D 追蹤影片作為控制輸入，使影片擴散過程本質上具備 3D 感知能力。此創新讓 DaS 能透過簡單地操作 3D 追蹤影片來達成廣泛的影片控制。使用 3D 追蹤影片的另一個優點是它們能有效地連結影格，大幅提升產生影片的時間一致性。DaS 僅在 8 個 H800 GPU 上進行 3 天的微調，使用不到 10k 個影片，便展現出在各種任務中的強大控制能力，包括網格轉影片產生、相機控制、動作轉移和物件操作。

##### **BERTopic for Topic Modeling of Hindi Short Texts: A Comparative Study**
2501.03843v1 by Atharva Mutsaddi, Anvi Jamkhande, Aryan Thakre, Yashodhara Haribhakta

As short text data in native languages like Hindi increasingly appear in
modern media, robust methods for topic modeling on such data have gained
importance. This study investigates the performance of BERTopic in modeling
Hindi short texts, an area that has been under-explored in existing research.
Using contextual embeddings, BERTopic can capture semantic relationships in
data, making it potentially more effective than traditional models, especially
for short and diverse texts. We evaluate BERTopic using 6 different document
embedding models and compare its performance against 8 established topic
modeling techniques, such as Latent Dirichlet Allocation (LDA), Non-negative
Matrix Factorization (NMF), Latent Semantic Indexing (LSI), Additive
Regularization of Topic Models (ARTM), Probabilistic Latent Semantic Analysis
(PLSA), Embedded Topic Model (ETM), Combined Topic Model (CTM), and Top2Vec.
The models are assessed using coherence scores across a range of topic counts.
Our results reveal that BERTopic consistently outperforms other models in
capturing coherent topics from short Hindi texts.

摘要：由於印地語等原生的語言中短文本資料越來越常出現在現代媒體中，因此在這些資料上進行主題建模的強健方法變得越來越重要。本研究探討了 BERTopic 在建模印地語短文本中的表現，這是一個現有研究中尚未充分探討的領域。透過使用脈絡嵌入，BERTopic 能夠擷取資料中的語義關係，使其潛在效能優於傳統模型，特別是對於簡短且多樣化的文本。我們使用 6 個不同的文件嵌入模型評估 BERTopic，並將其效能與 8 種已建立的主題建模技術進行比較，例如隱含狄利克雷配置 (LDA)、非負矩陣分解 (NMF)、潛在語義索引 (LSI)、主題模型的加成正則化 (ARTM)、機率潛在語義分析 (PLSA)、嵌入式主題模型 (ETM)、組合式主題模型 (CTM) 和 Top2Vec。這些模型會使用不同主題計數的相干性分數進行評估。我們的結果顯示，BERTopic 在從印地語短文本中擷取相干主題方面始終優於其他模型。

##### **SCC-YOLO: An Improved Object Detector for Assisting in Brain Tumor Diagnosis**
2501.03836v1 by Runci Bai

Brain tumors can result in neurological dysfunction, alterations in cognitive
and psychological states, increased intracranial pressure, and the occurrence
of seizures, thereby presenting a substantial risk to human life and health.
The You Only Look Once(YOLO) series models have demonstrated superior accuracy
in object detection for medical imaging. In this paper, we develop a novel
SCC-YOLO architecture by integrating the SCConv attention mechanism into
YOLOv9. The SCConv module reconstructs an efficient convolutional module by
reducing spatial and channel redundancy among features, thereby enhancing the
learning of image features. We investigate the impact of intergrating different
attention mechanisms with the YOLOv9 model on brain tumor image detection using
both the Br35H dataset and our self-made dataset(Brain_Tumor_Dataset).
Experimental results show that on the Br35H dataset, SCC-YOLO achieved a 0.3%
improvement in mAp50 compared to YOLOv9, while on our self-made dataset,
SCC-YOLO exhibited a 0.5% improvement over YOLOv9. SCC-YOLO has reached
state-of-the-art performance in brain tumor detection. Source code is available
at : https://jihulab.com/healthcare-information-studio/SCC-YOLO/-/tree/master

摘要：腦瘤可能導致神經功能障礙、認知和心理狀態改變、顱內壓升高，以及癲癇發作，因此對人類生命和健康構成重大風險。You Only Look Once (YOLO) 系列模型已證明在醫學影像的物件偵測中具有優異的準確度。在本文中，我們透過將 SCConv 注意力機制整合到 YOLOv9 中，開發出新穎的 SCC-YOLO 架構。SCConv 模組透過減少特徵中的空間和通道冗餘來重建一個高效的卷積模組，從而增強影像特徵的學習。我們使用 Br35H 資料集和我們自製的資料集 (Brain_Tumor_Dataset) 探討了將不同的注意力機制與 YOLOv9 模型整合對腦瘤影像偵測的影響。實驗結果顯示，在 Br35H 資料集上，SCC-YOLO 在 mAp50 方面比 YOLOv9 提升了 0.3%，而在我們自製的資料集上，SCC-YOLO 比 YOLOv9 提升了 0.5%。SCC-YOLO 已在腦瘤偵測方面達到最先進的效能。原始碼可於以下網址取得：https://jihulab.com/healthcare-information-studio/SCC-YOLO/-/tree/master

##### **Three-dimensional attention Transformer for state evaluation in real-time strategy games**
2501.03832v1 by Yanqing Ye, Weilong Yang, Kai Qiu, Jie Zhang

Situation assessment in Real-Time Strategy (RTS) games is crucial for
understanding decision-making in complex adversarial environments. However,
existing methods remain limited in processing multi-dimensional feature
information and temporal dependencies. Here we propose a tri-dimensional
Space-Time-Feature Transformer (TSTF Transformer) architecture, which
efficiently models battlefield situations through three independent but
cascaded modules: spatial attention, temporal attention, and feature attention.
On a dataset comprising 3,150 adversarial experiments, the 8-layer TSTF
Transformer demonstrates superior performance: achieving 58.7% accuracy in the
early game (~4% progress), significantly outperforming the conventional
Timesformer's 41.8%; reaching 97.6% accuracy in the mid-game (~40% progress)
while maintaining low performance variation (standard deviation 0.114).
Meanwhile, this architecture requires fewer parameters (4.75M) compared to the
baseline model (5.54M). Our study not only provides new insights into situation
assessment in RTS games but also presents an innovative paradigm for
Transformer-based multi-dimensional temporal modeling.

摘要：在即時戰略 (RTS) 遊戲中，情境評估對於理解在複雜對抗環境中的決策至關重要。然而，現有方法在處理多維特徵資訊和時間依賴性方面仍然有限。在此，我們提出一個三維時空特徵轉換器 (TSTF Transformer) 架構，它透過三個獨立但串聯的模組有效地模擬戰場情境：空間注意力、時間注意力和特徵注意力。在包含 3,150 個對抗實驗的資料集上，8 層 TSTF Transformer 展現出優異的效能：在遊戲初期獲得 58.7% 的準確度（進步約 4%），明顯優於傳統 Timesformer 的 41.8%；在遊戲中期達到 97.6% 的準確度（進步約 40%），同時維持低效能變異（標準差 0.114）。同時，與基線模型（5.54M）相比，此架構需要的參數更少（4.75M）。我們的研究不僅為 RTS 遊戲中的情境評估提供了新的見解，也為基於 Transformer 的多維時間建模提出了創新的典範。

##### **Investigating the Impact of Data Selection Strategies on Language Model Performance**
2501.03826v1 by Jiayao Gu, Liting Chen, Yihong Li

Data selection is critical for enhancing the performance of language models,
particularly when aligning training datasets with a desired target
distribution. This study explores the effects of different data selection
methods and feature types on model performance. We evaluate whether selecting
data subsets can influence downstream tasks, whether n-gram features improve
alignment with target distributions, and whether embedding-based neural
features provide complementary benefits. Through comparative experiments using
baseline random selection methods and distribution aligned approaches, we
provide insights into the interplay between data selection strategies and model
training efficacy. All code for this study can be found on
\href{https://github.com/jgu13/HIR-Hybrid-Importance-Resampling-for-Language-Models}{github
repository}.

摘要：資料選擇對於增強語言模型的效能至關重要，特別是在將訓練資料集與目標目標分佈對齊時。本研究探討不同資料選擇方法和特徵類型對模型效能的影響。我們評估選擇資料子集是否會影響下游任務，n-gram 特徵是否會改善與目標分佈的對齊，以及基於嵌入的神經特徵是否提供額外的優點。透過使用基準隨機選擇方法和分佈對齊方法進行比較實驗，我們深入了解資料選擇策略和模型訓練效能之間的交互作用。本研究的所有程式碼都可以在
\href{https://github.com/jgu13/HIR-Hybrid-Importance-Resampling-for-Language-Models}{github 儲存庫}中找到。

##### **Deep Sylvester Posterior Inference for Adaptive Compressed Sensing in Ultrasound Imaging**
2501.03825v1 by Simon W. Penninga, Hans van Gorp, Ruud J. G. van Sloun

Ultrasound images are commonly formed by sequential acquisition of
beam-steered scan-lines. Minimizing the number of required scan-lines can
significantly enhance frame rate, field of view, energy efficiency, and data
transfer speeds. Existing approaches typically use static subsampling schemes
in combination with sparsity-based or, more recently, deep-learning-based
recovery. In this work, we introduce an adaptive subsampling method that
maximizes intrinsic information gain in-situ, employing a Sylvester Normalizing
Flow encoder to infer an approximate Bayesian posterior under partial
observation in real-time. Using the Bayesian posterior and a deep generative
model for future observations, we determine the subsampling scheme that
maximizes the mutual information between the subsampled observations, and the
next frame of the video. We evaluate our approach using the EchoNet cardiac
ultrasound video dataset and demonstrate that our active sampling method
outperforms competitive baselines, including uniform and variable-density
random sampling, as well as equidistantly spaced scan-lines, improving mean
absolute reconstruction error by 15%. Moreover, posterior inference and the
sampling scheme generation are performed in just 0.015 seconds (66Hz), making
it fast enough for real-time 2D ultrasound imaging applications.

摘要：超音波影像通常是由逐行掃描線的序列取得。最小化所需掃描線的數量可以顯著地增強畫面更新率、視野、能源效率以及資料傳輸速度。現有的方法通常使用靜態子取樣方案，結合基於稀疏性或最近基於深度學習的復原。在這項工作中，我們引入了一種適應性子取樣方法，它最大化內在資訊的獲取，採用 Sylvester 正規化流編碼器，以在部分觀察下推斷近似貝氏後驗。使用貝氏後驗和一個用於未來觀察的深度生成模型，我們決定了子取樣方案，它最大化子取樣觀察和影片的下一幀之間的互信息。我們使用 EchoNet 心臟超音波影片資料集評估我們的做法，並證明我們的主動取樣方法優於競爭基準，包括均勻和變數密度隨機取樣，以及等距的掃描線，將平均絕對重建誤差改善了 15%。此外，後驗推論和取樣方案生成僅在 0.015 秒（66Hz）中執行，使其足夠快，可以用於即時 2D 超音波影像應用程式。

##### **Online Reinforcement Learning-Based Dynamic Adaptive Evaluation Function for Real-Time Strategy Tasks**
2501.03824v1 by Weilong Yang, Jie Zhang, Xunyun Liu, Yanqing Ye

Effective evaluation of real-time strategy tasks requires adaptive mechanisms
to cope with dynamic and unpredictable environments. This study proposes a
method to improve evaluation functions for real-time responsiveness to
battle-field situation changes, utilizing an online reinforcement
learning-based dynam-ic weight adjustment mechanism within the real-time
strategy game. Building on traditional static evaluation functions, the method
employs gradient descent in online reinforcement learning to update weights
dynamically, incorporating weight decay techniques to ensure stability.
Additionally, the AdamW optimizer is integrated to adjust the learning rate and
decay rate of online reinforcement learning in real time, further reducing the
dependency on manual parameter tun-ing. Round-robin competition experiments
demonstrate that this method signifi-cantly enhances the application
effectiveness of the Lanchester combat model evaluation function, Simple
evaluation function, and Simple Sqrt evaluation function in planning algorithms
including IDABCD, IDRTMinimax, and Port-folio AI. The method achieves a notable
improvement in scores, with the en-hancement becoming more pronounced as the
map size increases. Furthermore, the increase in evaluation function
computation time induced by this method is kept below 6% for all evaluation
functions and planning algorithms. The pro-posed dynamic adaptive evaluation
function demonstrates a promising approach for real-time strategy task
evaluation.

摘要：<paragraph>有效評估即時策略任務需要適應機制來應對動態且不可預測的環境。本研究提出了一種方法，用於改善即時響應戰場狀況變化的評估函數，利用即時策略遊戲中的基於線上強化學習的動態權重調整機制。在傳統靜態評估函數的基礎上，該方法採用線上強化學習中的梯度下降法動態更新權重，並結合權重衰減技術來確保穩定性。此外，AdamW 優化器被整合用於調整線上強化學習的學習率和衰減率，進一步降低了對手動參數調整的依賴性。輪詢競爭實驗表明，這種方法顯著提高了蘭徹斯特戰鬥模型評估函數、簡單評估函數和簡單平方根評估函數在包括 IDABCD、IDRTMinimax 和組合 AI 在內的規劃演算法中的應用效果。該方法在分數上取得了顯著的改進，隨著地圖大小的增加，這種改進變得更加明顯。此外，該方法引起的評估函數計算時間增加對於所有評估函數和規劃演算法都保持在 6% 以下。所提出的動態自適應評估函數展示了即時策略任務評估的有前景的方法。</paragraph>

##### **Detecting the Undetectable: Assessing the Efficacy of Current Spoof Detection Methods Against Seamless Speech Edits**
2501.03805v1 by Sung-Feng Huang, Heng-Cheng Kuo, Zhehuai Chen, Xuesong Yang, Chao-Han Huck Yang, Yu Tsao, Yu-Chiang Frank Wang, Hung-yi Lee, Szu-Wei Fu

Neural speech editing advancements have raised concerns about their misuse in
spoofing attacks. Traditional partially edited speech corpora primarily focus
on cut-and-paste edits, which, while maintaining speaker consistency, often
introduce detectable discontinuities. Recent methods, like
A\textsuperscript{3}T and Voicebox, improve transitions by leveraging
contextual information. To foster spoofing detection research, we introduce the
Speech INfilling Edit (SINE) dataset, created with Voicebox. We detailed the
process of re-implementing Voicebox training and dataset creation. Subjective
evaluations confirm that speech edited using this novel technique is more
challenging to detect than conventional cut-and-paste methods. Despite human
difficulty, experimental results demonstrate that self-supervised-based
detectors can achieve remarkable performance in detection, localization, and
generalization across different edit methods. The dataset and related models
will be made publicly available.

摘要：神經語音編輯的進展引發了人們對其在欺騙攻擊中被濫用的擔憂。傳統的部分編輯語音語料庫主要集中在剪貼編輯上，儘管保持了說話者的一致性，但通常會引入可檢測的不連續性。最近的方法，如 A\textsuperscript{3}T 和 Voicebox，通過利用上下文信息改進了過渡。為了促進欺騙檢測研究，我們引入了使用 Voicebox 創建的語音填充編輯 (SINE) 數據集。我們詳細介紹了重新實現 Voicebox 訓練和數據集創建的過程。主觀評估證實，使用這種新技術編輯的語音比傳統的剪貼方法更難檢測。儘管人類有困難，但實驗結果表明，基於自監督的檢測器可以在不同編輯方法的檢測、定位和泛化中實現顯著的性能。該數據集和相關模型將公開提供。

##### **Self-Adaptive ERP: Embedding NLP into Petri-Net creation and Model Matching**
2501.03795v1 by Ahmed Maged, Gamal Kassem

Enterprise Resource Planning (ERP) consultants play a vital role in
customizing systems to meet specific business needs by processing large amounts
of data and adapting functionalities. However, the process is
resource-intensive, time-consuming, and requires continuous adjustments as
business demands evolve. This research introduces a Self-Adaptive ERP Framework
that automates customization using enterprise process models and system usage
analysis. It leverages Artificial Intelligence (AI) & Natural Language
Processing (NLP) for Petri nets to transform business processes into adaptable
models, addressing both structural and functional matching. The framework,
built using Design Science Research (DSR) and a Systematic Literature Review
(SLR), reduces reliance on manual adjustments, improving ERP customization
efficiency and accuracy while minimizing the need for consultants.

摘要：企業資源規劃 (ERP) 顧問扮演著重要的角色，透過處理大量資料並調整功能，客製化系統以滿足特定的業務需求。然而，此程序需要大量資源、耗時，且隨著業務需求的演變，需要持續調整。本研究提出了一個自適應 ERP 架構，它使用企業流程模型和系統使用分析自動化客製化。它利用人工智慧 (AI) 和自然語言處理 (NLP) 讓 Petri 網路將業務流程轉換為可適應的模型，解決結構和功能匹配的問題。此架構使用設計科學研究 (DSR) 和系統化文獻回顧 (SLR) 建立，降低對手動調整的依賴，提升 ERP 客製化的效率和準確度，同時將顧問的需求降到最低。

##### **How to Select Pre-Trained Code Models for Reuse? A Learning Perspective**
2501.03783v1 by Zhangqian Bi, Yao Wan, Zhaoyang Chu, Yufei Hu, Junyi Zhang, Hongyu Zhang, Guandong Xu, Hai Jin

Pre-training a language model and then fine-tuning it has shown to be an
efficient and effective technique for a wide range of code intelligence tasks,
such as code generation, code summarization, and vulnerability detection.
However, pretraining language models on a large-scale code corpus is
computationally expensive. Fortunately, many off-the-shelf Pre-trained Code
Models (PCMs), such as CodeBERT, CodeT5, CodeGen, and Code Llama, have been
released publicly. These models acquire general code understanding and
generation capability during pretraining, which enhances their performance on
downstream code intelligence tasks. With an increasing number of these public
pre-trained models, selecting the most suitable one to reuse for a specific
task is essential. In this paper, we systematically investigate the reusability
of PCMs. We first explore three intuitive model selection methods that select
by size, training data, or brute-force fine-tuning. Experimental results show
that these straightforward techniques either perform poorly or suffer high
costs. Motivated by these findings, we explore learning-based model selection
strategies that utilize pre-trained models without altering their parameters.
Specifically, we train proxy models to gauge the performance of pre-trained
models, and measure the distribution deviation between a model's latent
features and the task's labels, using their closeness as an indicator of model
transferability. We conduct experiments on 100 widely-used opensource PCMs for
code intelligence tasks, with sizes ranging from 42.5 million to 3 billion
parameters. The results demonstrate that learning-based selection methods
reduce selection time to 100 seconds, compared to 2,700 hours with brute-force
fine-tuning, with less than 6% performance degradation across related tasks.

摘要：<paragraph>預先訓練語言模型，然後微調它，已被證明是一種高效且有效的技術，可應用于各種程式碼智能任務，例如程式碼生成、程式碼摘要和漏洞偵測。
然而，在大型程式碼語料庫上預訓練語言模型在計算上非常昂貴。幸運的是，許多現成的預訓練程式碼模型 (PCM)，例如 CodeBERT、CodeT5、CodeGen 和 Code Llama，已經公開發布。這些模型在預訓練期間獲得了通用的程式碼理解和生成能力，這增強了它們在下游程式碼智能任務上的效能。隨著這些公開預訓練模型數量的不斷增加，選擇最適合特定任務重複使用的模型至關重要。在本文中，我們系統地研究了 PCM 的可重複使用性。我們首先探討了三種直觀的模型選擇方法，它們通過大小、訓練資料或蠻力微調進行選擇。實驗結果表明，這些直接技術要么執行得很差，要么成本很高。受這些發現的啟發，我們探索了基於學習的模型選擇策略，它們利用預訓練模型而不改變它們的參數。具體來說，我們訓練代理模型來評估預訓練模型的效能，並使用它們的接近程度作為模型可傳輸性的指標，來衡量模型潛在特徵和任務標籤之間的分布偏差。我們對 100 個廣泛使用的開源 PCM 進行了程式碼智能任務的實驗，其規模從 4250 萬到 30 億個參數不等。結果表明，與蠻力微調的 2700 小時相比，基於學習的選擇方法將選擇時間減少到 100 秒，而相關任務的效能下降不到 6%。</paragraph>

##### **SelectiveFinetuning: Enhancing Transfer Learning in Sleep Staging through Selective Domain Alignment**
2501.03764v1 by Siyuan Zhao, Chenyu Liu, Yi Ding, Xinliang Zhou

In practical sleep stage classification, a key challenge is the variability
of EEG data across different subjects and environments. Differences in
physiology, age, health status, and recording conditions can lead to domain
shifts between data. These domain shifts often result in decreased model
accuracy and reliability, particularly when the model is applied to new data
with characteristics different from those it was originally trained on, which
is a typical manifestation of negative transfer. To address this, we propose
SelectiveFinetuning in this paper. Our method utilizes a pretrained Multi
Resolution Convolutional Neural Network (MRCNN) to extract EEG features,
capturing the distinctive characteristics of different sleep stages. To
mitigate the effect of domain shifts, we introduce a domain aligning mechanism
that employs Earth Mover Distance (EMD) to evaluate and select source domain
data closely matching the target domain. By finetuning the model with selective
source data, our SelectiveFinetuning enhances the model's performance on target
domain that exhibits domain shifts compared to the data used for training.
Experimental results show that our method outperforms existing baselines,
offering greater robustness and adaptability in practical scenarios where data
distributions are often unpredictable.

摘要：在實際的睡眠階段分類中，一個關鍵的挑戰是腦電圖數據在不同受試者和環境中的變異性。生理、年齡、健康狀況和記錄條件的差異可能導致數據之間的領域偏移。這些領域偏移通常會導致模型準確度和可靠性下降，特別是當模型應用於與其最初訓練時不同的特徵的新數據時，這是負遷移的典型表現。為了解決這個問題，我們在本文中提出選擇性微調。我們的模型利用預訓練的多解析度卷積神經網路 (MRCNN) 來提取腦電圖特徵，捕捉不同睡眠階段的獨特特徵。為了減輕領域偏移的影響，我們引入了一個領域對齊機制，它採用地球移動距離 (EMD) 來評估和選擇與目標領域緊密匹配的源領域數據。通過使用選擇性源數據微調模型，我們的選擇性微調增強了模型在與用於訓練的數據相比表現出領域偏移的目標領域上的性能。實驗結果表明，我們的模型優於現有的基準，在數據分佈通常不可預測的實際場景中提供了更大的穩健性和適應性。

##### **Context-Alignment: Activating and Enhancing LLM Capabilities in Time Series**
2501.03747v1 by Yuxiao Hu, Qian Li, Dongxiao Zhang, Jinyue Yan, Yuntian Chen

Recently, leveraging pre-trained Large Language Models (LLMs) for time series
(TS) tasks has gained increasing attention, which involves activating and
enhancing LLMs' capabilities. Many methods aim to activate LLMs' capabilities
based on token-level alignment but overlook LLMs' inherent strength on natural
language processing -- their deep understanding of linguistic logic and
structure rather than superficial embedding processing. We propose
Context-Alignment, a new paradigm that aligns TS with a linguistic component in
the language environments familiar to LLMs to enable LLMs to contextualize and
comprehend TS data, thereby activating their capabilities. Specifically, such
context-level alignment comprises structural alignment and logical alignment,
which is achieved by a Dual-Scale Context-Alignment GNNs (DSCA-GNNs) applied to
TS-language multimodal inputs. Structural alignment utilizes dual-scale nodes
to describe hierarchical structure in TS-language, enabling LLMs treat long TS
data as a whole linguistic component while preserving intrinsic token features.
Logical alignment uses directed edges to guide logical relationships, ensuring
coherence in the contextual semantics. Demonstration examples prompt are
employed to construct Demonstration Examples based Context-Alignment (DECA)
following DSCA-GNNs framework. DECA can be flexibly and repeatedly integrated
into various layers of pre-trained LLMs to improve awareness of logic and
structure, thereby enhancing performance. Extensive experiments show the
effectiveness of DECA and the importance of Context-Alignment across tasks,
particularly in few-shot and zero-shot forecasting, confirming that
Context-Alignment provide powerful prior knowledge on context.

摘要：<paragraph>最近，利用预先训练的大语言模型 (LLM) 来执行时间序列 (TS) 任务备受关注，这涉及激活和增强 LLM 的功能。许多方法旨在基于标记级别的对齐来激活 LLM 的功能，但忽略了 LLM 在自然语言处理方面的固有优势——它们对语言逻辑和结构的深刻理解，而不是表面的嵌入式处理。我们提出了语境对齐，这是一种新范例，它将时间序列与 LLM 熟悉的语言环境中的语言组件对齐，使 LLM 能够对时间序列数据进行语境化和理解，从而激活它们的功能。具体来说，这种语境级别的对齐包括结构对齐和逻辑对齐，这是通过应用于时间序列语言多模态输入的双尺度语境对齐 GNN（DSCA-GNN）实现的。结构对齐利用双尺度节点来描述时间序列语言中的层次结构，使 LLM 能够将长的时间序列数据作为一个整体的语言组件来处理，同时保留固有的标记特征。逻辑对齐使用有向边来指导逻辑关系，确保语境语义中的一致性。演示示例提示被用来构建基于语境对齐的演示示例 (DECA)，遵循 DSCA-GNN 框架。DECA 可以灵活且重复地集成到预训练 LLM 的各个层中，以提高对逻辑和结构的认识，从而增强性能。大量的实验表明了 DECA 的有效性以及语境对齐在各个任务中的重要性，特别是在少样本和零样本预测中，证实了语境对齐为语境提供了强大的先验知识。</paragraph>

##### **Self-adaptive vision-language model for 3D segmentation of pulmonary artery and vein**
2501.03722v1 by Xiaotong Guo, Deqian Yang, Dan Wang, Haochen Zhao, Yuan Li, Zhilin Sui, Tao Zhou, Lijun Zhang, Yanda Meng

Accurate segmentation of pulmonary structures iscrucial in clinical
diagnosis, disease study, and treatment planning. Significant progress has been
made in deep learning-based segmentation techniques, but most require much
labeled data for training. Consequently, developing precise segmentation
methods that demand fewer labeled datasets is paramount in medical image
analysis. The emergence of pre-trained vision-language foundation models, such
as CLIP, recently opened the door for universal computer vision tasks.
Exploiting the generalization ability of these pre-trained foundation models on
downstream tasks, such as segmentation, leads to unexpected performance with a
relatively small amount of labeled data. However, exploring these models for
pulmonary artery-vein segmentation is still limited. This paper proposes a
novel framework called Language-guided self-adaptive Cross-Attention Fusion
Framework. Our method adopts pre-trained CLIP as a strong feature extractor for
generating the segmentation of 3D CT scans, while adaptively aggregating the
cross-modality of text and image representations. We propose a s pecially
designed adapter module to fine-tune pre-trained CLIP with a self-adaptive
learning strategy to effectively fuse the two modalities of embeddings. We
extensively validate our method on a local dataset, which is the largest
pulmonary artery-vein CT dataset to date and consists of 718 labeled data in
total. The experiments show that our method outperformed other state-of-the-art
methods by a large margin. Our data and code will be made publicly available
upon acceptance.

摘要：精確分割肺部結構在臨床診斷、疾病研究和治療計畫中至關重要。基於深度學習的分割技術已取得重大進展，但大多數技術在訓練時需要大量的標記資料。因此，開發精確的分割方法，以減少標記資料集的需求，在醫學影像分析中至關重要。預訓練的視覺語言基礎模型（例如 CLIP）的出現，最近為通用電腦視覺任務開啟了大門。利用這些預訓練基礎模型在分割等下游任務中的泛化能力，即使標記資料量相對較少，也能產生意想不到的效能。然而，探索這些模型在肺動脈靜脈分割中的應用仍然有限。本文提出了一個名為語言引導自適應交叉注意力融合框架的新框架。我們的模型採用預訓練的 CLIP 作為強大的特徵萃取器，用於產生 3D 電腦斷層掃描的分割，同時自適應地聚合文本和影像表徵的跨模態。我們提出了一個特別設計的適配器模組，以自適應學習策略微調預訓練的 CLIP，以有效融合兩種嵌入模態。我們在一個本地資料集上廣泛驗證了我們的模型，這是迄今為止最大的肺動脈靜脈電腦斷層掃描資料集，總共包含 718 個標記資料。實驗表明，我們的模型以大幅優於其他最先進模型。我們的資料和程式碼將在獲得接受後公開。

##### **Unsupervised Speech Segmentation: A General Approach Using Speech Language Models**
2501.03711v1 by Avishai Elmakies, Omri Abend, Yossi Adi

In this paper, we introduce an unsupervised approach for Speech Segmentation,
which builds on previously researched approaches, e.g., Speaker Diarization,
while being applicable to an inclusive set of acoustic-semantic distinctions,
paving a path towards a general Unsupervised Speech Segmentation approach.
Unlike traditional speech and audio segmentation, which mainly focuses on
spectral changes in the input signal, e.g., phone segmentation, our approach
tries to segment the spoken utterance into chunks with differing
acoustic-semantic styles, focusing on acoustic-semantic information that does
not translate well into text, e.g., emotion or speaker. While most Speech
Segmentation tasks only handle one style change, e.g., emotion diarization, our
approach tries to handle multiple acoustic-semantic style changes. Leveraging
recent advances in Speech Language Models (SLMs), we propose a simple
unsupervised method to segment a given speech utterance. We empirically
demonstrate the effectiveness of the proposed approach by considering several
setups. Results suggest that the proposed method is superior to the evaluated
baselines on boundary detection, segment purity, and over-segmentation. Code is
available at
https://github.com/avishaiElmakies/unsupervised_speech_segmentation_using_slm.

摘要：在本文中，我們介紹了一種用於語音分割的非監督式方法，
這建立在先前研究的方法之上，例如說話者區分，
同時適用於一組包容性的聲學語義區別，
為通用的非監督式語音分割方法鋪平道路。
與傳統的語音和音訊分割不同，傳統的語音和音訊分割主要關注
輸入訊號中的頻譜變化，例如音素分割，我們的做法
試圖將口語語句分割成具有不同
聲學語義風格的區塊，專注於無法順利轉換為文字的聲學語義資訊，例如情緒或說話者。雖然大多數語音
分割任務只處理一種風格變化，例如情緒區分，我們的
方法試圖處理多種聲學語義風格變化。利用
語音語言模型 (SLM) 的最新進展，我們提出一個簡單的
非監督式方法來分割給定的語音語句。我們透過考慮數個
設定，以經驗方式證明所提出方法的有效性。結果表明，所提出的方法在邊界偵測、區段純度和過度分割方面優於評估的基準。程式碼可在
https://github.com/avishaiElmakies/unsupervised_speech_segmentation_using_slm 取得。

##### **AuxDepthNet: Real-Time Monocular 3D Object Detection with Depth-Sensitive Features**
2501.03700v1 by Ruochen Zhang, Hyeung-Sik Choi, Dongwook Jung, Phan Huy Nam Anh, Sang-Ki Jeong, Zihao Zhu

Monocular 3D object detection is a challenging task in autonomous systems due
to the lack of explicit depth information in single-view images. Existing
methods often depend on external depth estimators or expensive sensors, which
increase computational complexity and hinder real-time performance. To overcome
these limitations, we propose AuxDepthNet, an efficient framework for real-time
monocular 3D object detection that eliminates the reliance on external depth
maps or pre-trained depth models. AuxDepthNet introduces two key components:
the Auxiliary Depth Feature (ADF) module, which implicitly learns
depth-sensitive features to improve spatial reasoning and computational
efficiency, and the Depth Position Mapping (DPM) module, which embeds depth
positional information directly into the detection process to enable accurate
object localization and 3D bounding box regression. Leveraging the DepthFusion
Transformer architecture, AuxDepthNet globally integrates visual and
depth-sensitive features through depth-guided interactions, ensuring robust and
efficient detection. Extensive experiments on the KITTI dataset show that
AuxDepthNet achieves state-of-the-art performance, with $\text{AP}_{3D}$ scores
of 24.72\% (Easy), 18.63\% (Moderate), and 15.31\% (Hard), and
$\text{AP}_{\text{BEV}}$ scores of 34.11\% (Easy), 25.18\% (Moderate), and
21.90\% (Hard) at an IoU threshold of 0.7.

摘要：單目 3D 物件偵測由於單視圖影像中缺乏明確的深度資訊，因此在自駕系統中是一項具有挑戰性的任務。現有方法通常依賴外部深度估測器或昂貴的感測器，這會增加運算複雜度並阻礙即時效能。為了克服這些限制，我們提出 AuxDepthNet，一個用於即時單目 3D 物件偵測的高效架構，它消除了對外部深度圖或預先訓練深度模型的依賴。AuxDepthNet 導入兩個關鍵元件：輔助深度特徵 (ADF) 模組，它隱式學習深度敏感特徵以改善空間推理和運算效率，以及深度位置對應 (DPM) 模組，它將深度位置資訊直接嵌入偵測流程中，以實現準確的物件定位和 3D 邊界框回歸。透過利用 DepthFusion Transformer 架構，AuxDepthNet 透過深度引導互動，將視覺和深度敏感特徵在全球整合，確保穩健且高效的偵測。在 KITTI 資料集上的大量實驗顯示，AuxDepthNet 達到了最先進的效能，在 IoU 閾值為 0.7 時，$\text{AP}_{3D}$ 分數分別為 24.72%（容易）、18.63%（中等）和 15.31%（困難），而 $\text{AP}_{\text{BEV}}$ 分數分別為 34.11%（容易）、25.18%（中等）和 21.90%（困難）。

##### **Exploring Molecule Generation Using Latent Space Graph Diffusion**
2501.03696v1 by Prashanth Pombala, Gerrit Grossmann, Verena Wolf

Generating molecular graphs is a challenging task due to their discrete
nature and the competitive objectives involved. Diffusion models have emerged
as SOTA approaches in data generation across various modalities. For molecular
graphs, graph neural networks (GNNs) as a diffusion backbone have achieved
impressive results. Latent space diffusion, where diffusion occurs in a
low-dimensional space via an autoencoder, has demonstrated computational
efficiency. However, the literature on latent space diffusion for molecular
graphs is scarce, and no commonly accepted best practices exist. In this work,
we explore different approaches and hyperparameters, contrasting generative
flow models (denoising diffusion, flow matching, heat dissipation) and
architectures (GNNs and E(3)-equivariant GNNs). Our experiments reveal a high
sensitivity to the choice of approach and design decisions. Code is made
available at
github.com/Prashanth-Pombala/Molecule-Generation-using-Latent-Space-Graph-Diffusion.

摘要：生成分子圖是一個具有挑戰性的任務，因為它們的離散性質和涉及的競爭目標。擴散模型已成為各種模態中資料生成的 SOTA 方法。對於分子圖，作為擴散主幹的圖神經網路 (GNN) 已獲得令人印象深刻的結果。潛在空間擴散，其中擴散通過自動編碼器在低維空間中發生，已證明了計算效率。然而，關於分子圖的潛在空間擴散的文獻很少，而且沒有公認的最佳實務。在這項工作中，我們探討了不同的方法和超參數，對比生成流模型（去噪擴散、流匹配、熱耗散）和架構（GNN 和 E(3)-等變 GNN）。我們的實驗揭示了對方法和設計決策選擇的高度敏感性。程式碼可在 github.com/Prashanth-Pombala/Molecule-Generation-using-Latent-Space-Graph-Diffusion 取得。

##### **MAJL: A Model-Agnostic Joint Learning Framework for Music Source Separation and Pitch Estimation**
2501.03689v1 by Haojie Wei, Jun Yuan, Rui Zhang, Quanyu Dai, Yueguo Chen

Music source separation and pitch estimation are two vital tasks in music
information retrieval. Typically, the input of pitch estimation is obtained
from the output of music source separation. Therefore, existing methods have
tried to perform these two tasks simultaneously, so as to leverage the mutually
beneficial relationship between both tasks. However, these methods still face
two critical challenges that limit the improvement of both tasks: the lack of
labeled data and joint learning optimization. To address these challenges, we
propose a Model-Agnostic Joint Learning (MAJL) framework for both tasks. MAJL
is a generic framework and can use variant models for each task. It includes a
two-stage training method and a dynamic weighting method named Dynamic Weights
on Hard Samples (DWHS), which addresses the lack of labeled data and joint
learning optimization, respectively. Experimental results on public music
datasets show that MAJL outperforms state-of-the-art methods on both tasks,
with significant improvements of 0.92 in Signal-to-Distortion Ratio (SDR) for
music source separation and 2.71% in Raw Pitch Accuracy (RPA) for pitch
estimation. Furthermore, comprehensive studies not only validate the
effectiveness of each component of MAJL, but also indicate the great generality
of MAJL in adapting to different model architectures.

摘要：音樂來源分離和音高估計是音樂資訊檢索中的兩項重要任務。通常，音高估計的輸入來自音樂來源分離的輸出。因此，現有方法已嘗試同時執行這兩項任務，以便利用這兩項任務之間的互利關係。然而，這些方法仍然面臨兩個關鍵挑戰，限制了這兩項任務的改進：標籤數據和聯合學習優化的缺乏。為了應對這些挑戰，我們提出了這兩個任務的模型不可知聯合學習 (MAJL) 框架。MAJL 是通用框架，可以使用每個任務的變體模型。它包括一個兩階段訓練方法和一個名為難樣本動態權重 (DWHS) 的動態加權方法，分別解決了標籤數據的缺乏和聯合學習優化。公共音樂資料集上的實驗結果表明，MAJL 在這兩項任務上都優於最先進的方法，音樂來源分離的信噪比 (SDR) 有 0.92 的顯著提高，音高估計的原始音高準確度 (RPA) 有 2.71% 的提高。此外，綜合研究不僅驗證了 MAJL 各個組成的有效性，還表明了 MAJL 在適應不同模型架構方面的廣泛性。

##### **SLAM: Towards Efficient Multilingual Reasoning via Selective Language Alignment**
2501.03681v1 by Yuchun Fan, Yongyu Mu, Yilin Wang, Lei Huang, Junhao Ruan, Bei Li, Tong Xiao, Shujian Huang, Xiaocheng Feng, Jingbo Zhu

Despite the significant improvements achieved by large language models (LLMs)
in English reasoning tasks, these models continue to struggle with multilingual
reasoning. Recent studies leverage a full-parameter and two-stage training
paradigm to teach models to first understand non-English questions and then
reason. However, this method suffers from both substantial computational
resource computing and catastrophic forgetting. The fundamental cause is that,
with the primary goal of enhancing multilingual comprehension, an excessive
number of irrelevant layers and parameters are tuned during the first stage.
Given our findings that the representation learning of languages is merely
conducted in lower-level layers, we propose an efficient multilingual reasoning
alignment approach that precisely identifies and fine-tunes the layers
responsible for handling multilingualism. Experimental results show that our
method, SLAM, only tunes 6 layers' feed-forward sub-layers including 6.5-8% of
all parameters within 7B and 13B LLMs, achieving superior average performance
than all strong baselines across 10 languages. Meanwhile, SLAM only involves
one training stage, reducing training time by 4.1-11.9 compared to the
two-stage method.

摘要：儘管大型語言模型 (LLM) 在英文推理任務中取得顯著進展，這些模型在多語言推理中仍面臨挑戰。最近的研究利用全參數和兩階段訓練範例，教導模型先理解非英文問題，然後推理。然而，此方法既需要大量的運算資源，又會發生災難性遺忘。根本原因在於，由於主要目標是增強多語言理解，因此在第一階段調整了過多的無關層和參數。鑑於我們的研究結果表明，語言的表徵學習僅在較低層級進行，我們提出了一種高效的多語言推理對齊方法，可以精確識別並微調負責處理多語言的層級。實驗結果顯示，我們的 SLAM 方法僅微調 6 個層級的前饋子層，包括 7B 和 13B LLM 中 6.5-8% 的所有參數，在 10 種語言中達到優於所有強大基準的平均效能。與此同時，SLAM 只涉及一個訓練階段，與兩階段方法相比，訓練時間減少了 4.1-11.9 倍。

##### **SALE-Based Offline Reinforcement Learning with Ensemble Q-Networks**
2501.03676v1 by Zheng Chun

In this work, we build upon the offline reinforcement learning algorithm TD7,
which incorporates State-Action Learned Embeddings (SALE) and LAP, and propose
a model-free actor-critic algorithm that integrates ensemble Q-networks and a
gradient diversity penalty from EDAC. The ensemble Q-networks effectively
address the challenge of out-of-distribution actions by introducing penalties
that guide the actor network to focus on in-distribution actions. Meanwhile,
the gradient diversity penalty encourages diverse Q-value gradients, further
suppressing overestimation for out-of-distribution actions. Additionally, our
method retains an adjustable behavior cloning (BC) term that directs the actor
network toward dataset actions during early training stages, while gradually
reducing its influence as the precision of the Q-ensemble improves. These
enhancements work synergistically to improve training stability and accuracy.
Experimental results on the D4RL MuJoCo benchmarks demonstrate that our
algorithm achieves superior convergence speed, stability, and performance
compared to existing methods.

摘要：在此工作中，我们建立在离线强化学习算法 TD7 之上，该算法结合了状态动作学习嵌入 (SALE) 和 LAP，并提出了一个无模型的 actor-critic 算法，该算法集成了 ensemble Q 网络和 EDAC 的梯度多样性惩罚。ensemble Q 网络通过引入惩罚来有效应对分布外动作的挑战，这些惩罚引导 actor 网络专注于分布内动作。同时，梯度多样性惩罚鼓励不同的 Q 值梯度，进一步抑制对分布外动作的过高估计。此外，我们的方法保留了一个可调整的行为克隆 (BC) 项，该项在早期训练阶段将 actor 网络引导至数据集动作，同时随着 Q ensemble 精度的提高逐渐减少其影响。这些增强功能协同工作，以提高训练稳定性和准确性。D4RL MuJoCo 基准上的实验结果表明，与现有方法相比，我们的算法实现了卓越的收敛速度、稳定性和性能。

##### **Action Quality Assessment via Hierarchical Pose-guided Multi-stage Contrastive Regression**
2501.03674v1 by Mengshi Qi, Hao Ye, Jiaxuan Peng, Huadong Ma

Action Quality Assessment (AQA), which aims at automatic and fair evaluation
of athletic performance, has gained increasing attention in recent years.
However, athletes are often in rapid movement and the corresponding visual
appearance variances are subtle, making it challenging to capture fine-grained
pose differences and leading to poor estimation performance. Furthermore, most
common AQA tasks, such as diving in sports, are usually divided into multiple
sub-actions, each of which contains different durations. However, existing
methods focus on segmenting the video into fixed frames, which disrupts the
temporal continuity of sub-actions resulting in unavoidable prediction errors.
To address these challenges, we propose a novel action quality assessment
method through hierarchically pose-guided multi-stage contrastive regression.
Firstly, we introduce a multi-scale dynamic visual-skeleton encoder to capture
fine-grained spatio-temporal visual and skeletal features. Then, a procedure
segmentation network is introduced to separate different sub-actions and obtain
segmented features. Afterwards, the segmented visual and skeletal features are
both fed into a multi-modal fusion module as physics structural priors, to
guide the model in learning refined activity similarities and variances.
Finally, a multi-stage contrastive learning regression approach is employed to
learn discriminative representations and output prediction results. In
addition, we introduce a newly-annotated FineDiving-Pose Dataset to improve the
current low-quality human pose labels. In experiments, the results on
FineDiving and MTL-AQA datasets demonstrate the effectiveness and superiority
of our proposed approach. Our source code and dataset are available at
https://github.com/Lumos0507/HP-MCoRe.

摘要：動作品質評估 (AQA) 旨在自動且公平地評估運動表現，近年來備受關注。
然而，運動員經常處於快速移動狀態，且對應的視覺外觀差異細微，導致難以捕捉細微的姿勢差異，並導致估計表現不佳。此外，大多數常見的 AQA 任務（例如運動中的跳水）通常分為多個子動作，每個子動作包含不同的持續時間。然而，現有方法專注於將影片分割成固定幀，這會破壞子動作的時間連續性，導致不可避免的預測誤差。
為了應對這些挑戰，我們提出了一種新的動作品質評估方法，透過分層姿勢引導的多階段對比回歸。
首先，我們引入多尺度動態視覺骨架編碼器，以捕捉細粒度的時空視覺和骨架特徵。然後，引入一個程序分割網路，以分離不同的子動作並取得分割的特徵。之後，分割的視覺和骨架特徵都被輸入到多模式融合模組中，作為物理結構先驗，以引導模型學習精緻的活動相似性和差異性。
最後，採用多階段對比學習回歸方法來學習辨別式表示並輸出預測結果。此外，我們引入了新標註的 FineDiving-Pose 資料集，以改善目前低品質的人類姿勢標籤。在實驗中，FineDiving 和 MTL-AQA 資料集上的結果證明了我們提出的方法的有效性和優越性。我們的原始碼和資料集可以在 https://github.com/Lumos0507/HP-MCoRe 取得。

##### **A Diversity-Enhanced Knowledge Distillation Model for Practical Math Word Problem Solving**
2501.03670v1 by Yi Zhang, Guangyou Zhou, Zhiwen Xie, Jinjin Ma, Jimmy Xiangji Huang

Math Word Problem (MWP) solving is a critical task in natural language
processing, has garnered significant research interest in recent years. Various
recent studies heavily rely on Seq2Seq models and their extensions (e.g.,
Seq2Tree and Graph2Tree) to generate mathematical equations. While effective,
these models struggle to generate diverse but counterpart solution equations,
limiting their generalization across various math problem scenarios. In this
paper, we introduce a novel Diversity-enhanced Knowledge Distillation (DivKD)
model for practical MWP solving. Our approach proposes an adaptive diversity
distillation method, in which a student model learns diverse equations by
selectively transferring high-quality knowledge from a teacher model.
Additionally, we design a diversity prior-enhanced student model to better
capture the diversity distribution of equations by incorporating a conditional
variational auto-encoder. Extensive experiments on {four} MWP benchmark
datasets demonstrate that our approach achieves higher answer accuracy than
strong baselines while maintaining high efficiency for practical applications.

摘要：數學文字題 (MWP) 求解是自然語言處理中的一項重要任務，近年來已引起重大的研究興趣。各種最近的研究大量依賴 Seq2Seq 模型及其擴充套件（例如 Seq2Tree 和 Graph2Tree）來產生數學方程式。儘管有效，但這些模型難以產生多樣化但對應的解方程式，這限制了它們在各種數學問題情境中的泛化能力。在本文中，我們介紹了一個新穎的多樣性增強知識蒸餾 (DivKD) 模型，用於實用的 MWP 求解。我們的做法提出了一種自適應的多樣性蒸餾方法，其中學生模型透過選擇性地從教師模型傳輸高品質知識來學習多樣化的方程式。此外，我們設計了一個多樣性先驗增強學生模型，透過結合條件變異自動編碼器來更好地捕捉方程式的多樣性分佈。在 {四個} MWP 基準資料集上的大量實驗證明，我們的做法比強大的基準線實現了更高的答案準確度，同時在實用應用中保持了高效率。

##### **Effective and Efficient Mixed Precision Quantization of Speech Foundation Models**
2501.03643v1 by Haoning Xu, Zhaoqing Li, Zengrui Jin, Huimeng Wang, Youjun Chen, Guinan Li, Mengzhe Geng, Shujie Hu, Jiajun Deng, Xunying Liu

This paper presents a novel mixed-precision quantization approach for speech
foundation models that tightly integrates mixed-precision learning and
quantized model parameter estimation into one single model compression stage.
Experiments conducted on LibriSpeech dataset with fine-tuned wav2vec2.0-base
and HuBERT-large models suggest the resulting mixed-precision quantized models
increased the lossless compression ratio by factors up to 1.7x and 1.9x over
the respective uniform-precision and two-stage mixed-precision quantized
baselines that perform precision learning and model parameters quantization in
separate and disjointed stages, while incurring no statistically word error
rate (WER) increase over the 32-bit full-precision models. The system
compression time of wav2vec2.0-base and HuBERT-large models is reduced by up to
1.9 and 1.5 times over the two-stage mixed-precision baselines, while both
produce lower WERs. The best-performing 3.5-bit mixed-precision quantized
HuBERT-large model produces a lossless compression ratio of 8.6x over the
32-bit full-precision system.

摘要：本文提出了一种新颖的混合精度量化方法，用于语音基础模型，将混合精度学习和量化模型参数估计紧密集成到一个模型压缩阶段。在经过微调的 wav2vec2.0-base 和 HuBERT-large 模型上进行的 LibriSpeech 数据集实验表明，由此产生的混合精度量化模型将无损压缩比提高了 1.7 倍和 1.9 倍，分别高于执行精度学习和模型参数量化的统一精度和两阶段混合精度量化基线。在单独和不连续的阶段，同时不会增加 32 位全精度模型的统计词错误率 (WER)。wav2vec2.0-base 和 HuBERT-large 模型的系统压缩时间比两阶段混合精度基线减少了 1.9 倍和 1.5 倍，同时两者都产生了较低的 WER。性能最好的 3.5 位混合精度量化 HuBERT-large 模型对 32 位全精度系统产生了 8.6 倍的无损压缩比。

##### **MHGNet: Multi-Heterogeneous Graph Neural Network for Traffic Prediction**
2501.03635v1 by Mei Wu, Yiqian Lin, Tianfan Jiang, Wenchao Weng

In recent years, traffic flow prediction has played a crucial role in the
management of intelligent transportation systems. However, traditional
forecasting methods often model non-Euclidean low-dimensional traffic data as a
simple graph with single-type nodes and edges, failing to capture similar
trends among nodes of the same type. To address this limitation, this paper
proposes MHGNet, a novel framework for modeling spatiotemporal
multi-heterogeneous graphs. Within this framework, the STD Module decouples
single-pattern traffic data into multi-pattern traffic data through feature
mappings of timestamp embedding matrices and node embedding matrices.
Subsequently, the Node Clusterer leverages the Euclidean distance between nodes
and different types of limit points to perform clustering with O(N) time
complexity. The nodes within each cluster undergo residual subgraph convolution
within the spatiotemporal fusion subgraphs generated by the DSTGG Module,
followed by processing in the SIE Module for node repositioning and
redistribution of weights. To validate the effectiveness of MHGNet, this paper
conducts extensive ablation studies and quantitative evaluations on four widely
used benchmarks, demonstrating its superior performance.

摘要：近年来，交通流量预测在智能交通系统管理中发挥了至关重要的作用。然而，传统的预测方法通常将非欧几里得低维交通数据建模为具有单类型节点和边的简单图，未能捕获同类型节点之间的相似趋势。为了解决这一限制，本文提出了 MHGNet，这是一个用于建模时空多异构图的新框架。在这个框架内，STD 模块通过时间戳嵌入矩阵和节点嵌入矩阵的特征映射，将单模式交通数据解耦为多模式交通数据。随后，节点聚类器利用节点之间的欧几里得距离和不同类型的限制点来执行 O(N) 时间复杂度的聚类。每个簇中的节点在 DSTGG 模块生成的时空融合子图中进行残差子图卷积，然后在 SIE 模块中进行节点重新定位和权重重新分配的处理。为了验证 MHGNet 的有效性，本文对四个广泛使用的基准进行了广泛的消融研究和定量评估，证明了其优越的性能。

##### **LlaMADRS: Prompting Large Language Models for Interview-Based Depression Assessment**
2501.03624v1 by Gaoussou Youssouf Kebe, Jeffrey M. Girard, Einat Liebenthal, Justin Baker, Fernando De la Torre, Louis-Philippe Morency

This study introduces LlaMADRS, a novel framework leveraging open-source
Large Language Models (LLMs) to automate depression severity assessment using
the Montgomery-Asberg Depression Rating Scale (MADRS). We employ a zero-shot
prompting strategy with carefully designed cues to guide the model in
interpreting and scoring transcribed clinical interviews. Our approach, tested
on 236 real-world interviews from the Context-Adaptive Multimodal Informatics
(CAMI) dataset, demonstrates strong correlations with clinician assessments.
The Qwen 2.5--72b model achieves near-human level agreement across most MADRS
items, with Intraclass Correlation Coefficients (ICC) closely approaching those
between human raters. We provide a comprehensive analysis of model performance
across different MADRS items, highlighting strengths and current limitations.
Our findings suggest that LLMs, with appropriate prompting, can serve as
efficient tools for mental health assessment, potentially increasing
accessibility in resource-limited settings. However, challenges remain,
particularly in assessing symptoms that rely on non-verbal cues, underscoring
the need for multimodal approaches in future work.

摘要：這項研究介紹了 LlaMADRS，一個利用開放原始碼大型語言模型 (LLM) 自動評估憂鬱症嚴重程度的創新架構，使用蒙哥馬利-阿斯伯格憂鬱評分量表 (MADRS)。我們採用零次學習提示策略，使用精心設計的提示來引導模型詮釋和評分轉錄的臨床訪談。我們的方法在 Context-Adaptive Multimodal Informatics (CAMI) 資料集的 236 個真實訪談中進行測試，證實與臨床醫師評估有很強的相關性。Qwen 2.5--72b 模型在大部分 MADRS 項目中達到接近人類的評分一致性，類內相關係數 (ICC) 接近人類評分者之間的評分一致性。我們提供模型在不同 MADRS 項目中表現的全面分析，強調優點和目前的限制。我們的研究結果表明，LLM 在適當的提示下，可用作心理健康評估的有效工具，有可能在資源有限的環境中提高可及性。然而，挑戰仍然存在，特別是在評估依賴於非語言提示的症狀時，強調未來工作中需要多模態方法。

##### **STContext: A Multifaceted Dataset for Developing Context-aware Spatio-temporal Crowd Mobility Prediction Models**
2501.03583v1 by Liyue Chen, Jiangyi Fang, Tengfei Liu, Fangyuan Gao, Leye Wang

In smart cities, context-aware spatio-temporal crowd flow prediction (STCFP)
models leverage contextual features (e.g., weather) to identify unusual crowd
mobility patterns and enhance prediction accuracy. However, the best practice
for incorporating contextual features remains unclear due to inconsistent usage
of contextual features in different papers. Developing a multifaceted dataset
with rich types of contextual features and STCFP scenarios is crucial for
establishing a principled context modeling paradigm. Existing open crowd flow
datasets lack an adequate range of contextual features, which poses an urgent
requirement to build a multifaceted dataset to fill these research gaps. To
this end, we create STContext, a multifaceted dataset for developing
context-aware STCFP models. Specifically, STContext provides nine
spatio-temporal datasets across five STCFP scenarios and includes ten
contextual features, including weather, air quality index, holidays, points of
interest, road networks, etc. Besides, we propose a unified workflow for
incorporating contextual features into deep STCFP methods, with steps including
feature transformation, dependency modeling, representation fusion, and
training strategies. Through extensive experiments, we have obtained several
useful guidelines for effective context modeling and insights for future
research. The STContext is open-sourced at
https://github.com/Liyue-Chen/STContext.

摘要：在智慧城市中，感知语境时空人群流动预测 (STCFP) 模型利用语境特征（例如天气）来识别异常人群流动模式并提高预测准确性。然而，由于不同论文中语境特征的使用不一致，因此纳入语境特征的最佳实践仍不清楚。开发一个具有丰富语境特征类型和 STCFP 场景的多方面数据集对于建立一个有原则的语境建模范例至关重要。现有的开放人群流动数据集缺乏足够范围的语境特征，这提出了构建一个多方面数据集以填补这些研究空白的迫切要求。为此，我们创建了 STContext，这是一个用于开发感知语境 STCFP 模型的多方面数据集。具体来说，STContext 提供了跨越五个 STCFP 场景的九个时空数据集，并包括十个语境特征，包括天气、空气质量指数、节假日、兴趣点、道路网络等。此外，我们提出了一个统一的工作流程，用于将语境特征纳入深度 STCFP 方法，其中包括特征转换、依赖建模、表示融合和训练策略。通过广泛的实验，我们获得了几个用于有效语境建模的有用准则和对未来研究的见解。STContext 在 https://github.com/Liyue-Chen/STContext 开源。

##### **Cosmos World Foundation Model Platform for Physical AI**
2501.03575v1 by NVIDIA, :, Niket Agarwal, Arslan Ali, Maciej Bala, Yogesh Balaji, Erik Barker, Tiffany Cai, Prithvijit Chattopadhyay, Yongxin Chen, Yin Cui, Yifan Ding, Daniel Dworakowski, Jiaojiao Fan, Michele Fenzi, Francesco Ferroni, Sanja Fidler, Dieter Fox, Songwei Ge, Yunhao Ge, Jinwei Gu, Siddharth Gururani, Ethan He, Jiahui Huang, Jacob Huffman, Pooya Jannaty, Jingyi Jin, Seung Wook Kim, Gergely Klár, Grace Lam, Shiyi Lan, Laura Leal-Taixe, Anqi Li, Zhaoshuo Li, Chen-Hsuan Lin, Tsung-Yi Lin, Huan Ling, Ming-Yu Liu, Xian Liu, Alice Luo, Qianli Ma, Hanzi Mao, Kaichun Mo, Arsalan Mousavian, Seungjun Nah, Sriharsha Niverty, David Page, Despoina Paschalidou, Zeeshan Patel, Lindsey Pavao, Morteza Ramezanali, Fitsum Reda, Xiaowei Ren, Vasanth Rao Naik Sabavat, Ed Schmerling, Stella Shi, Bartosz Stefaniak, Shitao Tang, Lyne Tchapmi, Przemek Tredak, Wei-Cheng Tseng, Jibin Varghese, Hao Wang, Haoxiang Wang, Heng Wang, Ting-Chun Wang, Fangyin Wei, Xinyue Wei, Jay Zhangjie Wu, Jiashu Xu, Wei Yang, Lin Yen-Chen, Xiaohui Zeng, Yu Zeng, Jing Zhang, Qinsheng Zhang, Yuxuan Zhang, Qingqing Zhao, Artur Zolkowski

Physical AI needs to be trained digitally first. It needs a digital twin of
itself, the policy model, and a digital twin of the world, the world model. In
this paper, we present the Cosmos World Foundation Model Platform to help
developers build customized world models for their Physical AI setups. We
position a world foundation model as a general-purpose world model that can be
fine-tuned into customized world models for downstream applications. Our
platform covers a video curation pipeline, pre-trained world foundation models,
examples of post-training of pre-trained world foundation models, and video
tokenizers. To help Physical AI builders solve the most critical problems of
our society, we make our platform open-source and our models open-weight with
permissive licenses available via https://github.com/NVIDIA/Cosmos.

摘要：物理 AI 首先需要进行数字训练。它需要一个自身的数字孪生、策略模型，以及一个世界的数字孪生、世界模型。在本文中，我们提出了 Cosmos 世界基础模型平台，以帮助开发者为其物理 AI 设置构建定制的世界模型。我们将世界基础模型定位为一个通用世界模型，可以微调为下游应用程序的定制世界模型。我们的平台涵盖了一个视频整理管道、预先训练的世界基础模型、预先训练的世界基础模型的后期训练示例以及视频标记器。为了帮助物理 AI 构建者解决我们社会中最关键的问题，我们让我们的平台开源，并通过 https://github.com/NVIDIA/Cosmos 提供具有宽松许可的开放权重模型。

##### **From Code to Compliance: Assessing ChatGPT's Utility in Designing an Accessible Webpage -- A Case Study**
2501.03572v1 by Ammar Ahmed, Margarida Fresco, Fredrik Forsberg, Hallvard Grotli

Web accessibility ensures that individuals with disabilities can access and
interact with digital content without barriers, yet a significant majority of
most used websites fail to meet accessibility standards. This study evaluates
ChatGPT's (GPT-4o) ability to generate and improve web pages in line with Web
Content Accessibility Guidelines (WCAG). While ChatGPT can effectively address
accessibility issues when prompted, its default code often lacks compliance,
reflecting limitations in its training data and prevailing inaccessible web
practices. Automated and manual testing revealed strengths in resolving simple
issues but challenges with complex tasks, requiring human oversight and
additional iterations. Unlike prior studies, we incorporate manual evaluation,
dynamic elements, and use the visual reasoning capability of ChatGPT along with
the prompts to fix accessibility issues. Providing screenshots alongside
prompts enhances the LLM's ability to address accessibility issues by allowing
it to analyze surrounding components, such as determining appropriate contrast
colors. We found that effective prompt engineering, such as providing concise,
structured feedback and incorporating visual aids, significantly enhances
ChatGPT's performance. These findings highlight the potential and limitations
of large language models for accessible web development, offering practical
guidance for developers to create more inclusive websites.

摘要：網路無障礙可確保身障人士無障礙地存取和互動數位內容，但多數最常使用的網站都無法達到無障礙標準。本研究評估 ChatGPT（GPT-4o）產生和改善網頁的能力，使其符合網路內容無障礙指引（WCAG）。雖然 ChatGPT 在收到提示時能有效解決無障礙問題，但其預設程式碼常常欠缺相容性，反映其訓練資料的限制，以及普遍存在於網路上的無障礙實務。自動化和手動測試顯示，ChatGPT 在解決簡單問題上表現優異，但在處理複雜任務時則有困難，需要人工監督和額外的反覆運算。與先前的研究不同，我們納入手動評估、動態元素，並使用 ChatGPT 的視覺推理能力，以及提示來修正無障礙問題。在提示中提供螢幕截圖可增強 LLM 解決無障礙問題的能力，因為它可以分析周圍的組成部分，例如判斷適當的對比色。我們發現，有效的提示工程，例如提供簡潔、結構化的回饋，並納入視覺輔助工具，可顯著提升 ChatGPT 的效能。這些發現突顯大型語言模型在無障礙網頁開發上的潛力和限制，並提供實務指引，供開發人員建立更具包容性的網站。

##### **Applying Large Language Models in Knowledge Graph-based Enterprise Modeling: Challenges and Opportunities**
2501.03566v1 by Benedikt Reitemeyer, Hans-Georg Fill

The role of large language models (LLMs) in enterprise modeling has recently
started to shift from academic research to that of industrial applications.
Thereby, LLMs represent a further building block for the machine-supported
generation of enterprise models. In this paper we employ a knowledge
graph-based approach for enterprise modeling and investigate the potential
benefits of LLMs in this context. In addition, the findings of an expert survey
and ChatGPT-4o-based experiments demonstrate that LLM-based model generations
exhibit minimal variability, yet remain constrained to specific tasks, with
reliability declining for more intricate tasks. The survey results further
suggest that the supervision and intervention of human modeling experts are
essential to ensure the accuracy and integrity of the generated models.

摘要：大型語言模型 (LLM) 在企業建模中的角色最近已開始從學術研究轉變為產業應用。因此，LLM 代表了機器支援的企業模型生成的進一步建構模組。在本文中，我們採用基於知識圖表的企業建模方法，並探討 LLM 在此脈絡中的潛在效益。此外，專家調查和基於 ChatGPT-4o 的實驗結果表明，基於 LLM 的模型生成展現最小的可變性，但仍侷限於特定任務，而可靠性會隨著任務的複雜性而下降。調查結果進一步表明，人類建模專家的監督和介入對於確保生成模型的準確性和完整性至關重要。

##### **KG-TRICK: Unifying Textual and Relational Information Completion of Knowledge for Multilingual Knowledge Graphs**
2501.03560v1 by Zelin Zhou, Simone Conia, Daniel Lee, Min Li, Shenglei Huang, Umar Farooq Minhas, Saloni Potdar, Henry Xiao, Yunyao Li

Multilingual knowledge graphs (KGs) provide high-quality relational and
textual information for various NLP applications, but they are often
incomplete, especially in non-English languages. Previous research has shown
that combining information from KGs in different languages aids either
Knowledge Graph Completion (KGC), the task of predicting missing relations
between entities, or Knowledge Graph Enhancement (KGE), the task of predicting
missing textual information for entities. Although previous efforts have
considered KGC and KGE as independent tasks, we hypothesize that they are
interdependent and mutually beneficial. To this end, we introduce KG-TRICK, a
novel sequence-to-sequence framework that unifies the tasks of textual and
relational information completion for multilingual KGs. KG-TRICK demonstrates
that: i) it is possible to unify the tasks of KGC and KGE into a single
framework, and ii) combining textual information from multiple languages is
beneficial to improve the completeness of a KG. As part of our contributions,
we also introduce WikiKGE10++, the largest manually-curated benchmark for
textual information completion of KGs, which features over 25,000 entities
across 10 diverse languages.

摘要：多語言知識圖譜 (KG) 為各種 NLP 應用程式提供高品質的關係和文字資訊，但它們通常是不完整的，特別是非英語語言。先前的研究顯示，結合不同語言中 KG 的資訊有助於知識圖譜完成功能 (KGC)，即預測實體之間遺失的關係，或知識圖譜增強 (KGE)，即預測實體遺失的文字資訊。儘管先前的努力將 KGC 和 KGE 視為獨立的任務，我們假設它們是相互依賴且互利的。為此，我們引入了 KG-TRICK，一個新穎的序列到序列架構，它統一了多語言 KG 的文字和關係資訊完成任務。KG-TRICK 證明：i) 可以將 KGC 和 KGE 的任務統一到單一架構中，以及 ii) 結合多種語言的文字資訊有助於提高 KG 的完整性。作為我們貢獻的一部分，我們還引入了 WikiKGE10++，這是 KG 文字資訊完成最大的手動整理基準，其特點是超過 10 種不同語言中的 25,000 個實體。

##### **Beyond Factual Accuracy: Evaluating Coverage of Diverse Factual Information in Long-form Text Generation**
2501.03545v1 by Chris Samarinas, Alexander Krubner, Alireza Salemi, Youngwoo Kim, Hamed Zamani

This paper presents ICAT, an evaluation framework for measuring coverage of
diverse factual information in long-form text generation. ICAT breaks down a
long output text into a list of atomic claims and not only verifies each claim
through retrieval from a (reliable) knowledge source, but also computes the
alignment between the atomic factual claims and various aspects expected to be
presented in the output. We study three implementations of the ICAT framework,
each with a different assumption on the availability of aspects and alignment
method. By adopting data from the diversification task in the TREC Web Track
and the ClueWeb corpus, we evaluate the ICAT framework. We demonstrate strong
correlation with human judgments and provide comprehensive evaluation across
multiple state-of-the-art LLMs. Our framework further offers interpretable and
fine-grained analysis of diversity and coverage. Its modular design allows for
easy adaptation to different domains and datasets, making it a valuable tool
for evaluating the qualitative aspects of long-form responses produced by LLMs.

摘要：本論文提出 ICAT，一個用於衡量長篇文字生成中多元事實資訊涵蓋範圍的評估架構。ICAT 將長篇輸出文字分解成一個原子斷言清單，並不僅透過從（可靠的）知識來源中擷取來驗證每個斷言，還計算原子事實斷言與預期會出現在輸出中的各個面向之間的對齊程度。我們研究了 ICAT 架構的三個實作，每個實作對於面向的可用性與對齊方法都有不同的假設。透過採用 TREC 網路軌跡中的多元化任務資料和 ClueWeb 語料庫，我們評估了 ICAT 架構。我們展示了與人類判斷的強相關性，並在多個最先進的 LLM 上提供了全面的評估。我們的架構進一步提供了可解釋且細緻的多元性和涵蓋範圍分析。其模組化設計允許輕鬆適應不同的領域和資料集，使其成為評估 LLM 產生的長篇回應的品質面向的寶貴工具。

##### **PromptGuard: Soft Prompt-Guided Unsafe Content Moderation for Text-to-Image Models**
2501.03544v1 by Lingzhi Yuan, Xinfeng Li, Chejian Xu, Guanhong Tao, Xiaojun Jia, Yihao Huang, Wei Dong, Yang Liu, XiaoFeng Wang, Bo Li

Text-to-image (T2I) models have been shown to be vulnerable to misuse,
particularly in generating not-safe-for-work (NSFW) content, raising serious
ethical concerns. In this work, we present PromptGuard, a novel content
moderation technique that draws inspiration from the system prompt mechanism in
large language models (LLMs) for safety alignment. Unlike LLMs, T2I models lack
a direct interface for enforcing behavioral guidelines. Our key idea is to
optimize a safety soft prompt that functions as an implicit system prompt
within the T2I model's textual embedding space. This universal soft prompt (P*)
directly moderates NSFW inputs, enabling safe yet realistic image generation
without altering the inference efficiency or requiring proxy models. Extensive
experiments across three datasets demonstrate that PromptGuard effectively
mitigates NSFW content generation while preserving high-quality benign outputs.
PromptGuard achieves 7.8 times faster than prior content moderation methods,
surpassing eight state-of-the-art defenses with an optimal unsafe ratio down to
5.84%.

摘要：文字轉圖像 (T2I) 模型已被證明容易被濫用，特別是在產生不適合工作 (NSFW) 內容時，引發了嚴重的道德問題。在這項工作中，我們提出了 PromptGuard，這是一種新穎的內容審核技術，從大型語言模型 (LLM) 中的系統提示機制中汲取靈感，以進行安全對齊。與 LLM 不同，T2I 模型缺乏強制執行行為準則的直接介面。我們的關鍵想法是最佳化一個安全軟提示，它在 T2I 模型的文字嵌入空間中作為一個隱式系統提示運作。這個通用軟提示 (P*) 直接審核 NSFW 輸入，在不改變推理效率或不需要代理模型的情況下，實現安全且逼真的圖像生成。跨越三個資料集的廣泛實驗證明，PromptGuard 有效地減輕了 NSFW 內容的產生，同時保留了高品質的良性輸出。PromptGuard 的速度比先前的內容審核方法快 7.8 倍，超越了八種最先進的防禦措施，將最佳不安全比率降至 5.84%。

##### **Deep Learning within Tabular Data: Foundations, Challenges, Advances and Future Directions**
2501.03540v1 by Weijieying Ren, Tianxiang Zhao, Yuqing Huang, Vasant Honavar

Tabular data remains one of the most prevalent data types across a wide range
of real-world applications, yet effective representation learning for this
domain poses unique challenges due to its irregular patterns, heterogeneous
feature distributions, and complex inter-column dependencies. This survey
provides a comprehensive review of state-of-the-art techniques in tabular data
representation learning, structured around three foundational design elements:
training data, neural architectures, and learning objectives. Unlike prior
surveys that focus primarily on either architecture design or learning
strategies, we adopt a holistic perspective that emphasizes the universality
and robustness of representation learning methods across diverse downstream
tasks. We examine recent advances in data augmentation and generation,
specialized neural network architectures tailored to tabular data, and
innovative learning objectives that enhance representation quality.
Additionally, we highlight the growing influence of self-supervised learning
and the adaptation of transformer-based foundation models for tabular data. Our
review is based on a systematic literature search using rigorous inclusion
criteria, encompassing 127 papers published since 2020 in top-tier conferences
and journals. Through detailed analysis and comparison, we identify emerging
trends, critical gaps, and promising directions for future research, aiming to
guide the development of more generalizable and effective tabular data
representation methods.

摘要：表格資料仍然是廣泛實際應用中最普遍的資料類型之一，但由於其不規則模式、異質特徵分布和複雜的欄位間依賴關係，有效的表示學習對此領域提出了獨特挑戰。這份調查提供了表格資料表示學習中最新技術的全面回顧，其結構圍繞三個基本設計元素：訓練資料、神經架構和學習目標。與先前主要關注架構設計或學習策略的調查不同，我們採用整體觀點，強調表示學習方法在不同下游任務中的普遍性和穩健性。我們審查了資料擴充和生成的最新進展、專門針對表格資料的神經網路架構，以及增強表示品質的創新學習目標。此外，我們強調了自監督學習日益增長的影響力，以及基於 Transformer 的基礎模型對於表格資料的適應。我們的回顧基於系統性的文獻檢索，採用嚴謹的納入標準，涵蓋了自 2020 年以來發表於頂尖會議和期刊中的 127 篇論文。透過詳細的分析和比較，我們找出新興趨勢、關鍵差距和未來研究的有希望方向，旨在引導更具概括性和有效性的表格資料表示方法的發展。

##### **SenseRAG: Constructing Environmental Knowledge Bases with Proactive Querying for LLM-Based Autonomous Driving**
2501.03535v1 by Xuewen Luo, Fan Ding, Fengze Yang, Yang Zhou, Junnyong Loo, Hwa Hui Tew, Chenxi Liu

This study addresses the critical need for enhanced situational awareness in
autonomous driving (AD) by leveraging the contextual reasoning capabilities of
large language models (LLMs). Unlike traditional perception systems that rely
on rigid, label-based annotations, it integrates real-time, multimodal sensor
data into a unified, LLMs-readable knowledge base, enabling LLMs to dynamically
understand and respond to complex driving environments. To overcome the
inherent latency and modality limitations of LLMs, a proactive
Retrieval-Augmented Generation (RAG) is designed for AD, combined with a
chain-of-thought prompting mechanism, ensuring rapid and context-rich
understanding. Experimental results using real-world Vehicle-to-everything
(V2X) datasets demonstrate significant improvements in perception and
prediction performance, highlighting the potential of this framework to enhance
safety, adaptability, and decision-making in next-generation AD systems.

摘要：本研究透過運用大型語言模型 (LLM) 的情境推理能力，探討自駕車 (AD) 中加強情境感知的關鍵需求。與依賴於僵化的基於標籤的註解的傳統感知系統不同，它將即時的多模態感測器資料整合到統一的、LLM 可讀的知識庫中，使 LLM 能夠動態理解和回應複雜的駕駛環境。為了克服 LLM 固有的延遲和模態限制，設計了一個主動的檢索增強生成 (RAG) 用於 AD，結合了思維鏈提示機制，確保快速且內容豐富的理解。使用真實世界車聯網 (V2X) 資料集的實驗結果證明了感知和預測效能的顯著提升，突顯了此架構在提升下一代 AD 系統安全性、適應性和決策制定方面的潛力。

##### **A Sequential Optimal Learning Approach to Automated Prompt Engineering in Large Language Models**
2501.03508v1 by Shuyang Wang, Somayeh Moazeni, Diego Klabjan

Designing effective prompts is essential to guiding large language models
(LLMs) toward desired responses. Automated prompt engineering aims to reduce
reliance on manual effort by streamlining the design, refinement, and
optimization of natural language prompts. This paper proposes an optimal
learning framework for automated prompt engineering, designed to sequentially
identify effective prompt features while efficiently allocating a limited
evaluation budget. We introduce a feature-based method to express prompts,
which significantly broadens the search space. Bayesian regression is employed
to utilize correlations among similar prompts, accelerating the learning
process. To efficiently explore the large space of prompt features for a high
quality prompt, we adopt the forward-looking Knowledge-Gradient (KG) policy for
sequential optimal learning. The KG policy is computed efficiently by solving
mixed-integer second-order cone optimization problems, making it scalable and
capable of accommodating prompts characterized only through constraints. We
demonstrate that our method significantly outperforms a set of benchmark
strategies assessed on instruction induction tasks. The results highlight the
advantages of using the KG policy for prompt learning given a limited
evaluation budget. Our framework provides a solution to deploying automated
prompt engineering in a wider range applications where prompt evaluation is
costly.

摘要：設計有效的提示對於引導大型語言模型 (LLM) 朝向預期的回應至關重要。自動提示工程旨在透過簡化自然語言提示的設計、精煉和最佳化來減少對人工工作的依賴。本文提出了一個用於自動提示工程的最佳學習架構，旨在按順序識別有效的提示特徵，同時有效分配有限的評估預算。我們引入了一種基於特徵的方法來表達提示，這顯著地擴展了搜尋空間。貝氏迴歸用於利用相似提示之間的相關性，加速學習過程。為了有效地探索大量的高品質提示特徵空間，我們採用了前瞻性的知識梯度 (KG) 策略進行順序最佳學習。KG 策略透過解決混合整數二階錐優化問題來有效計算，使其具有可擴充性，並且能夠容納僅透過約束條件來表徵的提示。我們證明了我們的方法顯著優於評估指令誘導任務的一組基準策略。結果突顯了在有限的評估預算下使用 KG 策略進行提示學習的優點。我們的框架提供了一個解決方案，可以在提示評估成本較高的更廣泛應用中部署自動提示工程。

##### **Can Deep Learning Trigger Alerts from Mobile-Captured Images?**
2501.03499v1 by Pritisha Sarkar, Duranta Durbaar Vishal Saha, Mousumi Saha

Our research presents a comprehensive approach to leveraging mobile camera
image data for real-time air quality assessment and recommendation. We develop
a regression-based Convolutional Neural Network model and tailor it explicitly
for air quality prediction by exploiting the inherent relationship between
output parameters. As a result, the Mean Squared Error of 0.0077 and 0.0112
obtained for 2 and 5 pollutants respectively outperforms existing models.
Furthermore, we aim to verify the common practice of augmenting the original
dataset with a view to introducing more variation in the training phase. It is
one of our most significant contributions that our experimental results
demonstrate minimal accuracy differences between the original and augmented
datasets. Finally, a real-time, user-friendly dashboard is implemented which
dynamically displays the Air Quality Index and pollutant values derived from
captured mobile camera images. Users' health conditions are considered to
recommend whether a location is suitable based on current air quality metrics.
Overall, this research contributes to verification of data augmentation
techniques, CNN-based regression modelling for air quality prediction, and
user-centric air quality monitoring through mobile technology. The proposed
system offers practical solutions for individuals to make informed
environmental health and well-being decisions.

摘要：我們的研究提出了一種利用行動裝置相機影像資料進行即時空氣品質評估和建議的全面性方法。我們開發了一種基於迴歸的卷積神經網路模型，並透過利用輸出參數之間的內在關係，針對空氣品質預測量身打造。因此，分別針對 2 和 5 種污染物取得的平均平方誤差為 0.0077 和 0.0112，優於現有的模型。此外，我們旨在驗證擴充原始資料集的常見做法，以期在訓練階段引入更多變異。我們的實驗結果顯示原始資料集和擴充資料集之間的準確度差異極小，這是我們最重要的貢獻之一。最後，我們實作了一個即時、使用者友善的儀表板，可動態顯示從擷取的行動裝置相機影像中衍生的空氣品質指數和污染物數值。考量使用者的健康狀況，建議是否根據目前的空氣品質指標選擇適合的地點。整體而言，這項研究有助於驗證資料擴充技術、基於 CNN 的迴歸模型（用於空氣品質預測）以及透過行動技術進行以使用者為中心的空氣品質監控。所提出的系統為個人提供實際的解決方案，以便做出明智的環境健康和福祉決策。

##### **Can LLMs Design Good Questions Based on Context?**
2501.03491v1 by Yueheng Zhang, Xiaoyuan Liu, Yiyou Sun, Atheer Alharbi, Hend Alzahrani, Basel Alomair, Dawn Song

This paper evaluates questions generated by LLMs from context, comparing them
to human-generated questions across six dimensions. We introduce an automated
LLM-based evaluation method, focusing on aspects like question length, type,
context coverage, and answerability. Our findings highlight unique
characteristics of LLM-generated questions, contributing insights that can
support further research in question quality and downstream applications.

摘要：這篇論文評估了 LLM 從上下文中產生的問題，並在六個面向與人類產生的問題進行比較。我們提出了一種自動化的 LLM 評估方法，重點關注問題長度、類型、脈絡涵蓋範圍和可回答性等面向。我們的研究結果突出了 LLM 產生的問題的獨特特徵，並提供了見解，可支援在問題品質和下游應用中進行進一步的研究。

##### **Align-Pro: A Principled Approach to Prompt Optimization for LLM Alignment**
2501.03486v1 by Prashant Trivedi, Souradip Chakraborty, Avinash Reddy, Vaneet Aggarwal, Amrit Singh Bedi, George K. Atia

The alignment of large language models (LLMs) with human values is critical
as these models become increasingly integrated into various societal and
decision-making processes. Traditional methods, such as reinforcement learning
from human feedback (RLHF), achieve alignment by fine-tuning model parameters,
but these approaches are often computationally expensive and impractical when
models are frozen or inaccessible for parameter modification. In contrast,
prompt optimization is a viable alternative to RLHF for LLM alignment. While
the existing literature has shown empirical promise of prompt optimization, its
theoretical underpinning remains under-explored. We address this gap by
formulating prompt optimization as an optimization problem and try to provide
theoretical insights into the optimality of such a framework. To analyze the
performance of the prompt optimization, we study theoretical suboptimality
bounds and provide insights in terms of how prompt optimization depends upon
the given prompter and target model. We also provide empirical validation
through experiments on various datasets, demonstrating that prompt optimization
can effectively align LLMs, even when parameter fine-tuning is not feasible.

摘要：大型語言模型 (LLM) 與人類價值觀的契合度至關重要，因為這些模型正逐漸整合到各種社會和決策制定過程中。傳統方法，例如人類回饋強化學習 (RLHF)，透過微調模型參數來達成契合度，但這些方法在模型凍結或無法存取參數修改時，通常在運算上很昂貴且不切實際。相比之下，提示最佳化是 LLM 契合度 RLHF 的可行替代方案。儘管現有文獻顯示提示最佳化的經驗承諾，但其理論基礎仍未充分探討。我們透過將提示最佳化制定為最佳化問題來解決此差距，並試圖提供此類架構最佳性的理論見解。為了分析提示最佳化的效能，我們研究了理論次最佳性界限，並提供提示最佳化如何依賴於給定的提示者和目標模型的見解。我們也透過在各種資料集上進行實驗提供經驗驗證，證明即使無法進行參數微調，提示最佳化也能有效契合 LLM。

##### **Women, Infamous, and Exotic Beings: What Honorific Usages in Wikipedia Reveal about the Socio-Cultural Norms**
2501.03479v1 by Sourabrata Mukherjee, Soumya Teotia, Sougata Saha, Monojit Choudhury

Honorifics serve as powerful linguistic markers that reflect social
hierarchies and cultural values. This paper presents a large-scale,
cross-linguistic exploration of usage of honorific pronouns in Bengali and
Hindi Wikipedia articles, shedding light on how socio-cultural factors shape
language. Using LLM (GPT-4o), we annotated 10, 000 articles of real and
fictional beings in each language for several sociodemographic features such as
gender, age, fame, and exoticness, and the use of honorifics. We find that
across all feature combinations, use of honorifics is consistently more common
in Bengali than Hindi. For both languages, the use non-honorific pronouns is
more commonly observed for infamous, juvenile, and exotic beings. Notably, we
observe a gender bias in use of honorifics in Hindi, with men being more
commonly referred to with honorifics than women.

摘要：敬語作為強而有力的語言標記，反映了社會階層和文化價值觀。本文提出了一個大規模的、跨語言的探索，探討了孟加拉語和印地語維基百科文章中敬語代詞的使用，揭示了社會文化因素如何塑造語言。使用 LLM (GPT-4o)，我們為每種語言中 10,000 篇真實和虛構人物的文章註釋了幾個社會人口特徵，例如性別、年齡、名聲和異國情調，以及敬語的使用。我們發現，在所有特徵組合中，孟加拉語中使用敬語的情況普遍比印地語中更常見。對於兩種語言來說，非敬語代詞的使用更常出現在聲名狼藉、年輕和異國情調的人物身上。值得注意的是，我們觀察到印地語中使用敬語存在性別偏見，男性比女性更常被稱為敬語。

##### **Reading with Intent -- Neutralizing Intent**
2501.03475v1 by Benjamin Reichman, Adar Avsian, Larry Heck

Queries to large language models (LLMs) can be divided into two parts: the
instruction/question and the accompanying context. The context for
retrieval-augmented generation (RAG) systems in most benchmarks comes from
Wikipedia or Wikipedia-like texts which are written in a neutral and factual
tone. However, when RAG systems retrieve internet-based content, they encounter
text with diverse tones and linguistic styles, introducing challenges for
downstream tasks. The Reading with Intent task addresses this issue by
evaluating how varying tones in context passages affect model performance.
Building on prior work that focused on sarcasm, we extend this paradigm by
constructing a dataset where context passages are transformed to $11$ distinct
emotions using a better synthetic data generation approach. Using this dataset,
we train an emotion translation model to systematically adapt passages to
specified emotional tones. The human evaluation shows that the LLM fine-tuned
to become the emotion-translator benefited from the synthetically generated
data. Finally, the emotion-translator is used in the Reading with Intent task
to transform the passages to a neutral tone. By neutralizing the passages, it
mitigates the challenges posed by sarcastic passages and improves overall
results on this task by about $3\%$.

摘要：大型語言模型 (LLM) 的查詢可以分為兩部分：指令/問題和附帶的內容。在大多數基準測試中，用於檢索增強生成 (RAG) 系統的內容來自維基百科或類似維基百科的文本，這些文本以中立且客觀的語氣撰寫。然而，當 RAG 系統檢索基於網路的內容時，它們會遇到語氣和語言風格多樣的文字，對下游任務造成挑戰。閱讀意圖任務透過評估語境段落中的不同語氣如何影響模型效能來解決這個問題。在專注於諷刺的先前工作基礎上，我們透過建構一個資料集來延伸這個範例，其中語境段落使用更好的合成資料生成方法轉換為 11 種不同的情緒。使用這個資料集，我們訓練一個情緒翻譯模型來系統性地調整段落以符合指定的情緒語氣。人類評估顯示，經過微調以成為情緒翻譯器的 LLM 受益於合成產生的資料。最後，情緒翻譯器用於閱讀意圖任務，將段落轉換為中立語氣。透過中和段落，它減輕了諷刺段落帶來的挑戰，並將此任務的整體結果提升了約 3%。

##### **MTRAG: A Multi-Turn Conversational Benchmark for Evaluating Retrieval-Augmented Generation Systems**
2501.03468v1 by Yannis Katsis, Sara Rosenthal, Kshitij Fadnis, Chulaka Gunasekara, Young-Suk Lee, Lucian Popa, Vraj Shah, Huaiyu Zhu, Danish Contractor, Marina Danilevsky

Retrieval-augmented generation (RAG) has recently become a very popular task
for Large Language Models (LLMs). Evaluating them on multi-turn RAG
conversations, where the system is asked to generate a response to a question
in the context of a preceding conversation is an important and often overlooked
task with several additional challenges. We present MTRAG: an end-to-end
human-generated multi-turn RAG benchmark that reflects several real-world
properties across diverse dimensions for evaluating the full RAG pipeline.
MTRAG contains 110 conversations averaging 7.7 turns each across four domains
for a total of 842 tasks. We also explore automation paths via synthetic data
and LLM-as-a-Judge evaluation. Our human and automatic evaluations show that
even state-of-the-art LLM RAG systems struggle on MTRAG. We demonstrate the
need for strong retrieval and generation systems that can handle later turns,
unanswerable questions, non-standalone questions, and multiple domains. MTRAG
is available at https://github.com/ibm/mt-rag-benchmark.

摘要：檢索增強生成 (RAG) 近期已成為大型語言模型 (LLM) 中非常熱門的任務。在多輪 RAG 對話中評估它們，系統會在先前提出的對話內容中產生對問題的回應，這是一項重要且經常被忽略的任務，同時也帶來許多額外的挑戰。我們提出 MTRAG：一個端對端的、由人類產生的多輪 RAG 基準，它反映了各種維度中多項真實世界的屬性，用於評估完整的 RAG 管線。MTRAG 包含 110 場對話，平均每場對話有 7.7 輪，涵蓋四個領域，總共有 842 個任務。我們也透過合成資料和 LLM 作為評審的評估，探索自動化路徑。我們的人類和自動評估顯示，即使是目前最先進的 LLM RAG 系統在 MTRAG 上也難以應付。我們證明了對強大的檢索和生成系統的需求，這些系統可以處理後續輪次、無法回答的問題、非獨立問題和多個領域。MTRAG 可在 https://github.com/ibm/mt-rag-benchmark 取得。

##### **LHGNN: Local-Higher Order Graph Neural Networks For Audio Classification and Tagging**
2501.03464v1 by Shubhr Singh, Emmanouil Benetos, Huy Phan, Dan Stowell

Transformers have set new benchmarks in audio processing tasks, leveraging
self-attention mechanisms to capture complex patterns and dependencies within
audio data. However, their focus on pairwise interactions limits their ability
to process the higher-order relations essential for identifying distinct audio
objects. To address this limitation, this work introduces the Local- Higher
Order Graph Neural Network (LHGNN), a graph based model that enhances feature
understanding by integrating local neighbourhood information with higher-order
data from Fuzzy C-Means clusters, thereby capturing a broader spectrum of audio
relationships. Evaluation of the model on three publicly available audio
datasets shows that it outperforms Transformer-based models across all
benchmarks while operating with substantially fewer parameters. Moreover, LHGNN
demonstrates a distinct advantage in scenarios lacking ImageNet pretraining,
establishing its effectiveness and efficiency in environments where extensive
pretraining data is unavailable.

摘要：Transformer在音訊處理任務中樹立了新的基準，利用自注意力機制來擷取音訊資料中的複雜模式和依賴性。然而，它們專注於成對互動，限制了它們處理識別不同音訊物件時不可或缺的高階關係的能力。為了解決這個限制，本研究引入了局部高階圖形神經網路 (LHGNN)，一個基於圖形的模型，透過整合局部鄰域資訊與來自模糊 C 均值聚類的高階資料來增強特徵理解，從而擷取更廣泛的音訊關係。在三個公開可用的音訊資料集上對模型進行評估，結果顯示它在所有基準上都優於基於Transformer的模型，同時運作的參數卻少得多。此外，LHGNN 在缺乏 ImageNet 預訓練的場景中展現出顯著的優勢，確立了它在無法取得大量預訓練資料的環境中，其有效性和效率。

##### **ISSR: Iterative Selection with Self-Review for Vocabulary Test Distractor Generation**
2501.03462v1 by Yu-Cheng Liu, An-Zi Yen

Vocabulary acquisition is essential to second language learning, as it
underpins all core language skills. Accurate vocabulary assessment is
particularly important in standardized exams, where test items evaluate
learners' comprehension and contextual use of words. Previous research has
explored methods for generating distractors to aid in the design of English
vocabulary tests. However, current approaches often rely on lexical databases
or predefined rules, and frequently produce distractors that risk invalidating
the question by introducing multiple correct options. In this study, we focus
on English vocabulary questions from Taiwan's university entrance exams. We
analyze student response distributions to gain insights into the
characteristics of these test items and provide a reference for future
research. Additionally, we identify key limitations in how large language
models (LLMs) support teachers in generating distractors for vocabulary test
design. To address these challenges, we propose the iterative selection with
self-review (ISSR) framework, which makes use of a novel LLM-based self-review
mechanism to ensure that the distractors remain valid while offering diverse
options. Experimental results show that ISSR achieves promising performance in
generating plausible distractors, and the self-review mechanism effectively
filters out distractors that could invalidate the question.

摘要：詞彙習得對於第二語言學習至關重要，因為它是所有核心語言技能的基礎。準確的詞彙評量在標準化考試中特別重要，考試項目評量學習者的理解力與詞彙的語境使用。先前的研究已探討產生干擾項以協助設計英語詞彙測驗的方法。然而，目前的做法通常依賴詞彙資料庫或預先定義的規則，而且經常產生干擾項，可能會因為引進多個正確選項而使問題無效。在本研究中，我們專注於台灣大學入學考試中的英語詞彙題目。我們分析學生的答題分佈，以深入了解這些考試項目的特徵，並為未來的研究提供參考。此外，我們找出大型語言模型 (LLM) 在支援教師產生詞彙測驗設計的干擾項時的主要限制。為了應對這些挑戰，我們提出具有自評功能的迭代選擇 (ISSR) 架構，它利用一種新穎的基於 LLM 的自評機制，以確保干擾項保持有效，同時提供多樣化的選項。實驗結果顯示，ISSR 在產生合理的干擾項方面表現出色，而自評機制有效過濾掉可能使問題無效的干擾項。

##### **Radar Signal Recognition through Self-Supervised Learning and Domain Adaptation**
2501.03461v1 by Zi Huang, Akila Pemasiri, Simon Denman, Clinton Fookes, Terrence Martin

Automatic radar signal recognition (RSR) plays a pivotal role in electronic
warfare (EW), as accurately classifying radar signals is critical for informing
decision-making processes. Recent advances in deep learning have shown
significant potential in improving RSR performance in domains with ample
annotated data. However, these methods fall short in EW scenarios where
annotated RF data are scarce or impractical to obtain. To address these
challenges, we introduce a self-supervised learning (SSL) method which utilises
masked signal modelling and RF domain adaption to enhance RSR performance in
environments with limited RF samples and labels. Specifically, we investigate
pre-training masked autoencoders (MAE) on baseband in-phase and quadrature
(I/Q) signals from various RF domains and subsequently transfer the learned
representation to the radar domain, where annotated data are limited. Empirical
results show that our lightweight self-supervised ResNet model with domain
adaptation achieves up to a 17.5\% improvement in 1-shot classification
accuracy when pre-trained on in-domain signals (i.e., radar signals) and up to
a 16.31\% improvement when pre-trained on out-of-domain signals (i.e., comm
signals), compared to its baseline without SSL. We also provide reference
results for several MAE designs and pre-training strategies, establishing a new
benchmark for few-shot radar signal classification.

摘要：自動雷達訊號辨識 (RSR) 在電子戰 (EW) 中扮演著舉足輕重的角色，因為準確分類雷達訊號對於提供決策制定流程的資訊至關重要。深度學習的最新進展已展現出大幅提升 RSR 在具備充足註解資料領域中表現的潛力。然而，這些方法在 EW 情境中表現不佳，因為註解 RF 資料稀少或難以取得。為了應對這些挑戰，我們提出了一種自我監督式學習 (SSL) 方法，它利用遮罩訊號建模和 RF 領域適應來提升 RSR 在具有有限 RF 樣本和標籤的環境中的表現。具體來說，我們探討在來自不同 RF 領域的基頻同相正交 (I/Q) 訊號上預訓練遮罩自動編碼器 (MAE)，並隨後將學習到的表示轉移到註解資料有限的雷達領域。實證結果顯示，我們的輕量級自我監督 ResNet 模型搭配領域適應，在以領域內訊號（即雷達訊號）預訓練時，1 次分類準確度最高提升 17.5%，而在以領域外訊號（即通訊訊號）預訓練時，最高提升 16.31%，與沒有 SSL 的基準相比。我們也提供了多種 MAE 設計和預訓練策略的參考結果，為少量雷達訊號分類建立新的基準。

##### **Activating Associative Disease-Aware Vision Token Memory for LLM-Based X-ray Report Generation**
2501.03458v1 by Xiao Wang, Fuling Wang, Haowen Wang, Bo Jiang, Chuanfu Li, Yaowei Wang, Yonghong Tian, Jin Tang

X-ray image based medical report generation achieves significant progress in
recent years with the help of the large language model, however, these models
have not fully exploited the effective information in visual image regions,
resulting in reports that are linguistically sound but insufficient in
describing key diseases. In this paper, we propose a novel associative
memory-enhanced X-ray report generation model that effectively mimics the
process of professional doctors writing medical reports. It considers both the
mining of global and local visual information and associates historical report
information to better complete the writing of the current report. Specifically,
given an X-ray image, we first utilize a classification model along with its
activation maps to accomplish the mining of visual regions highly associated
with diseases and the learning of disease query tokens. Then, we employ a
visual Hopfield network to establish memory associations for disease-related
tokens, and a report Hopfield network to retrieve report memory information.
This process facilitates the generation of high-quality reports based on a
large language model and achieves state-of-the-art performance on multiple
benchmark datasets, including the IU X-ray, MIMIC-CXR, and Chexpert Plus. The
source code of this work is released on
\url{https://github.com/Event-AHU/Medical_Image_Analysis}.

摘要：近年來，在大型語言模型的幫助下，基於 X 光影像的醫療報告生成取得了顯著進展，然而，這些模型並未充分利用視覺影像區域中的有效資訊，導致報告在語言上雖然流暢，但在描述關鍵疾病方面卻不足。在本文中，我們提出了一個新穎的聯想式記憶增強 X 光報告生成模型，有效地模擬專業醫生撰寫醫療報告的過程。它同時考慮了對全局和局部視覺資訊的挖掘，並聯繫歷史報告資訊，以更好地完成當前報告的撰寫。具體來說，給定一張 X 光影像，我們首先利用分類模型及其激活映射來完成與疾病高度相關的視覺區域的挖掘和疾病查詢令牌的學習。然後，我們採用視覺霍普菲爾德網路來建立與疾病相關的令牌的記憶聯繫，並採用報告霍普菲爾德網路來檢索報告記憶資訊。這個過程有助於基於大型語言模型生成高品質的報告，並在包括 IU X 射線、MIMIC-CXR 和 Chexpert Plus 在內的多個基準資料集上實現了最先進的效能。此項工作的原始碼已發佈在\url{https://github.com/Event-AHU/Medical_Image_Analysis}。

##### **Text to Band Gap: Pre-trained Language Models as Encoders for Semiconductor Band Gap Prediction**
2501.03456v1 by Ying-Ting Yeh, Janghoon Ock, Amir Barati Farimani

In this study, we explore the use of a transformer-based language model as an
encoder to predict the band gaps of semiconductor materials directly from their
text descriptions. Quantum chemistry simulations, including Density Functional
Theory (DFT), are computationally intensive and time-consuming, which limits
their practicality for high-throughput material screening, particularly for
complex systems. Shallow machine learning (ML) models, while effective, often
require extensive data preprocessing to convert non-numerical material
properties into numerical inputs. In contrast, our approach leverages textual
data directly, bypassing the need for complex feature engineering. We generate
material descriptions in two formats: formatted strings combining features and
natural language text generated using the ChatGPT API. We demonstrate that the
RoBERTa model, pre-trained on natural language processing tasks, performs
effectively as an encoder for prediction tasks. With minimal fine-tuning, it
achieves a mean absolute error (MAE) of approximately 0.33 eV, performing
better than shallow machine learning models such as Support Vector Regression,
Random Forest, and XGBoost. Even when only the linear regression head is
trained while keeping the RoBERTa encoder layers frozen, the accuracy remains
nearly identical to that of the fully trained model. This demonstrates that the
pre-trained RoBERTa encoder is highly adaptable for processing domain-specific
text related to material properties, such as the band gap, significantly
reducing the need for extensive retraining. This study highlights the potential
of transformer-based language models to serve as efficient and versatile
encoders for semiconductor materials property prediction tasks.

摘要：<paragraph>在本研究中，我們探討使用基於Transformer的語言模型作為編碼器，從半導體材料的文本描述中直接預測其能隙。量子化學模擬，包括密度泛函理論 (DFT)，計算量大且耗時，這限制了它們在高通量材料篩選中的實用性，特別是對於複雜系統。淺層機器學習 (ML) 模型雖然有效，但通常需要廣泛的資料預處理，才能將非數值的材料屬性轉換為數值輸入。相比之下，我們的做法直接利用文本資料，繞過了對複雜特徵工程的需求。我們使用兩種格式產生材料描述：結合特徵的格式化字串和使用 ChatGPT API 生成的自然語言文字。我們證明了在自然語言處理任務上經過預訓練的 RoBERTa 模型，作為預測任務的編碼器時表現得很有效。在經過最小的微調後，它達到了約 0.33 eV 的平均絕對誤差 (MAE)，效能優於支持向量回歸、隨機森林和 XGBoost 等淺層機器學習模型。即使在保持 RoBERTa 編碼器層凍結的同時只訓練線性回歸頭，其準確度仍然與完全訓練的模型幾乎相同。這表明預訓練的 RoBERTa 編碼器非常適合處理與材料屬性（如能隙）相關的特定領域文字，大大減少了廣泛重新訓練的需求。本研究強調了基於Transformer的語言模型作為半導體材料屬性預測任務的高效且通用的編碼器的潛力。</paragraph>

##### **Finding A Voice: Evaluating African American Dialect Generation for Chatbot Technology**
2501.03441v1 by Sarah E. Finch, Ellie S. Paek, Sejung Kwon, Ikseon Choi, Jessica Wells, Rasheeta Chandler, Jinho D. Choi

As chatbots become increasingly integrated into everyday tasks, designing
systems that accommodate diverse user populations is crucial for fostering
trust, engagement, and inclusivity. This study investigates the ability of
contemporary Large Language Models (LLMs) to generate African American
Vernacular English (AAVE) and evaluates the impact of AAVE usage on user
experiences in chatbot applications. We analyze the performance of three LLM
families (Llama, GPT, and Claude) in producing AAVE-like utterances at varying
dialect intensities and assess user preferences across multiple domains,
including healthcare and education. Despite LLMs' proficiency in generating
AAVE-like language, findings indicate that AAVE-speaking users prefer Standard
American English (SAE) chatbots, with higher levels of AAVE correlating with
lower ratings for a variety of characteristics, including chatbot
trustworthiness and role appropriateness. These results highlight the
complexities of creating inclusive AI systems and underscore the need for
further exploration of diversity to enhance human-computer interactions.

摘要：隨著聊天機器人越來越融入日常任務，設計能適應多元使用者群體的系統對於培養信任、參與度和包容性至關重要。本研究探討當代大型語言模型 (LLM) 生成非裔美國人方言英語 (AAVE) 的能力，並評估 AAVE 使用對聊天機器人應用程式中使用者體驗的影響。我們分析了三個 LLM 家族 (Llama、GPT 和 Claude) 在產生不同方言強度的類 AAVE 語句時的表現，並評估使用者在多個領域（包括醫療保健和教育）中的偏好。儘管 LLM 在生成類 AAVE 語言方面表現出色，但研究結果表明，說 AAVE 的使用者偏好標準美式英語 (SAE) 聊天機器人，較高的 AAVE 水平與各種特徵的評分較低相關，包括聊天機器人可信度和角色適當性。這些結果突顯了建立包容性 AI 系統的複雜性，並強調需要進一步探索多元性以增強人機互動。

##### **DAMAGE: Detecting Adversarially Modified AI Generated Text**
2501.03437v1 by Elyas Masrour, Bradley Emi, Max Spero

AI humanizers are a new class of online software tools meant to paraphrase
and rewrite AI-generated text in a way that allows them to evade AI detection
software. We study 19 AI humanizer and paraphrasing tools and qualitatively
assess their effects and faithfulness in preserving the meaning of the original
text. We show that many existing AI detectors fail to detect humanized text.
Finally, we demonstrate a robust model that can detect humanized AI text while
maintaining a low false positive rate using a data-centric augmentation
approach. We attack our own detector, training our own fine-tuned model
optimized against our detector's predictions, and show that our detector's
cross-humanizer generalization is sufficient to remain robust to this attack.

摘要：AI 人性化工具是一種新的線上軟體工具，旨在以一種讓它們能夠規避 AI 偵測軟體的方式，來改寫 AI 生成的文字。我們研究了 19 種 AI 人性化和改寫工具，並定性評估它們在保留原始文字意義方面的效果和忠實度。我們證明許多現有的 AI 偵測器無法偵測到人性化的文字。最後，我們展示了一個強健的模型，它可以在使用以資料為中心的擴充方法的同時，偵測到人性化的 AI 文字，並維持低誤判率。我們攻擊我們自己的偵測器，訓練我們自己的微調模型，針對我們偵測器的預測進行最佳化，並證明我們偵測器的跨人性化概化足以對這種攻擊保持強健。

##### **SALT: Sales Autocompletion Linked Business Tables Dataset**
2501.03413v1 by Tassilo Klein, Clemens Biehl, Margarida Costa, Andre Sres, Jonas Kolk, Johannes Hoffart

Foundation models, particularly those that incorporate Transformer
architectures, have demonstrated exceptional performance in domains such as
natural language processing and image processing. Adapting these models to
structured data, like tables, however, introduces significant challenges. These
difficulties are even more pronounced when addressing multi-table data linked
via foreign key, which is prevalent in the enterprise realm and crucial for
empowering business use cases. Despite its substantial impact, research
focusing on such linked business tables within enterprise settings remains a
significantly important yet underexplored domain. To address this, we introduce
a curated dataset sourced from an Enterprise Resource Planning (ERP) system,
featuring extensive linked tables. This dataset is specifically designed to
support research endeavors in table representation learning. By providing
access to authentic enterprise data, our goal is to potentially enhance the
effectiveness and applicability of models for real-world business contexts.

摘要：基礎模型，尤其是那些結合Transformer架構的模型，已在自然語言處理和影像處理等領域展現出卓越效能。然而，將這些模型調整到結構化資料（如表格）時，會產生重大挑戰。在處理透過外來鍵連結的多表格資料時，這些困難更為明顯，而這在企業領域中很常見，且對於強化商業用例至關重要。儘管其影響力很大，但專注於企業環境中此類連結的商業表格的研究仍是一個非常重要但尚未充分探索的領域。為了解決這個問題，我們引進一個從企業資源規劃 (ERP) 系統中取得的精選資料集，其中包含廣泛的連結表格。此資料集特別設計用於支援表格表示學習的研究工作。透過提供對真實企業資料的存取，我們的目標是潛在地提升模型在實際商業情境中的效能和適用性。

##### **BoundingDocs: a Unified Dataset for Document Question Answering with Spatial Annotations**
2501.03403v1 by Simone Giovannini, Fabio Coppini, Andrea Gemelli, Simone Marinai

We present a unified dataset for document Question-Answering (QA), which is
obtained combining several public datasets related to Document AI and visually
rich document understanding (VRDU). Our main contribution is twofold: on the
one hand we reformulate existing Document AI tasks, such as Information
Extraction (IE), into a Question-Answering task, making it a suitable resource
for training and evaluating Large Language Models; on the other hand, we
release the OCR of all the documents and include the exact position of the
answer to be found in the document image as a bounding box. Using this dataset,
we explore the impact of different prompting techniques (that might include
bounding box information) on the performance of open-weight models, identifying
the most effective approaches for document comprehension.

摘要：我們提供一個統一的資料集，用於文件問答 (QA)，這是
透過結合幾個與文件人工智慧和視覺豐富文件理解 (VRDU) 相關的公開資料集而獲得的。我們的貢獻主要有兩個方面：一方面，我們將現有的文件人工智慧任務，例如資訊萃取 (IE)，重新制定成問答任務，使其成為訓練和評估大型語言模型的合適資源；另一方面，我們釋出所有文件的 OCR，並將答案在文件影像中的確切位置包含在邊界框中。使用這個資料集，我們探討了不同的提示技術（可能包括邊界框資訊）對開放權重模型效能的影響，找出最有效的文件理解方法。

##### **Over-the-Air Fair Federated Learning via Multi-Objective Optimization**
2501.03392v1 by Shayan Mohajer Hamidi, Ali Bereyhi, Saba Asaad, H. Vincent Poor

In federated learning (FL), heterogeneity among the local dataset
distributions of clients can result in unsatisfactory performance for some,
leading to an unfair model. To address this challenge, we propose an
over-the-air fair federated learning algorithm (OTA-FFL), which leverages
over-the-air computation to train fair FL models. By formulating FL as a
multi-objective minimization problem, we introduce a modified Chebyshev
approach to compute adaptive weighting coefficients for gradient aggregation in
each communication round. To enable efficient aggregation over the multiple
access channel, we derive analytical solutions for the optimal transmit scalars
at the clients and the de-noising scalar at the parameter server. Extensive
experiments demonstrate the superiority of OTA-FFL in achieving fairness and
robust performance compared to existing methods.

摘要：在联邦学习 (FL) 中，客户端本地数据集分布的异质性可能导致某些客户端的性能不佳，从而产生不公平的模型。为了应对这一挑战，我们提出了一种空中公平联邦学习算法 (OTA-FFL)，它利用空中计算来训练公平的 FL 模型。通过将 FL 表述为一个多目标最小化问题，我们引入了一种改进的切比雪夫方法来计算梯度聚合的适应性加权系数，用于每一轮通信。为了在多址信道上实现高效聚合，我们推导出了客户端的最佳传输标量和参数服务器的去噪标量的解析解。大量的实验表明，与现有方法相比，OTA-FFL 在实现公平性和稳健性能方面具有优越性。

##### **Existential Crisis: A Social Robot's Reason for Being**
2501.03376v1 by Dora Medgyesy, Joella Galas, Julian van Pol, Rustam Eynaliyev, Thijs Vollebregt

As Robots become ever more important in our daily lives there's growing need
for understanding how they're perceived by people. This study aims to
investigate how the user perception of robots is influenced by displays of
personality. Using LLMs and speech to text technology, we designed a
within-subject study to compare two conditions: a personality-driven robot and
a purely task-oriented, personality-neutral robot. Twelve participants,
recruited from Socially Intelligent Robotics course at Vrije Universiteit
Amsterdam, interacted with a robot Nao tasked with asking them a set of medical
questions under both conditions. After completing both interactions, the
participants completed a user experience questionnaire measuring their
emotional states and robot perception using standardized questionnaires from
the SRI and Psychology literature.

摘要：隨著機器人在我們日常生活中的重要性日益提升，對於了解人們如何感知機器人的需求也日益增加。本研究旨在探討機器人的使用者感知如何受到人格表現的影響。我們使用大型語言模型 (LLM) 和語音轉文字技術，設計了一項受試者內研究，以比較兩種情況：一種是人格驅動的機器人，另一種是純粹以任務為導向、人格中立的機器人。我們從阿姆斯特丹自由大學的社交智能機器人課程中招募了 12 名參與者，他們與機器人 Nao 互動，在兩種情況下都向他們詢問一系列醫療問題。在完成這兩種互動後，參與者完成了一份使用者體驗問卷，使用來自 SRI 和心理學文獻的標準化問卷測量他們的情緒狀態和機器人感知。

##### **License Plate Images Generation with Diffusion Models**
2501.03374v1 by Mariia Shpir, Nadiya Shvai, Amir Nakib

Despite the evident practical importance of license plate recognition (LPR),
corresponding research is limited by the volume of publicly available datasets
due to privacy regulations such as the General Data Protection Regulation
(GDPR). To address this challenge, synthetic data generation has emerged as a
promising approach. In this paper, we propose to synthesize realistic license
plates (LPs) using diffusion models, inspired by recent advances in image and
video generation. In our experiments a diffusion model was successfully trained
on a Ukrainian LP dataset, and 1000 synthetic images were generated for
detailed analysis. Through manual classification and annotation of the
generated images, we performed a thorough study of the model output, such as
success rate, character distributions, and type of failures. Our contributions
include experimental validation of the efficacy of diffusion models for LP
synthesis, along with insights into the characteristics of the generated data.
Furthermore, we have prepared a synthetic dataset consisting of 10,000 LP
images, publicly available at https://zenodo.org/doi/10.5281/zenodo.13342102.
Conducted experiments empirically confirm the usefulness of synthetic data for
the LPR task. Despite the initial performance gap between the model trained
with real and synthetic data, the expansion of the training data set with
pseudolabeled synthetic data leads to an improvement in LPR accuracy by 3%
compared to baseline.

摘要：儘管車牌辨識（LPR）在實務上顯然相當重要，但由於《一般資料保護規範》（GDPR）等隱私法規，對應的研究受到公開可用資料集容量的限制。為了應對這項挑戰，合成資料產生已成為一種前景看好的方法。在本文中，我們提議使用擴散模型來合成逼真的車牌（LP），靈感來自於影像和影片產生技術的最新進展。在我們的實驗中，一個擴散模型已成功訓練於一個烏克蘭車牌資料集，並產生 1000 張合成影像以進行詳細分析。透過手動分類和標註產生的影像，我們對模型輸出進行了徹底的研究，例如成功率、字元分佈和失敗類型。我們的貢獻包括擴散模型在車牌合成方面的效能實驗驗證，以及對產生資料特性的見解。此外，我們已準備了一個由 10,000 張車牌影像組成的合成資料集，並公開於 https://zenodo.org/doi/10.5281/zenodo.13342102。所進行的實驗經驗證實了合成資料對於 LPR 任務的效用。儘管使用真實和合成資料訓練的模型之間存在著最初的效能差距，但使用偽標籤合成資料擴充訓練資料集，可使 LPR 準確度提升 3%，優於基準。

##### **Advanced Machine Learning Techniques for Social Support Detection on Social Media**
2501.03370v1 by Olga Kolesnikova, Moein Shahiki Tash, Zahra Ahani, Ameeta Agrawal, Raul Monroy, Grigori Sidorov

The widespread use of social media highlights the need to understand its
impact, particularly the role of online social support. This study uses a
dataset focused on online social support, which includes binary and multiclass
classifications of social support content on social media. The classification
of social support is divided into three tasks. The first task focuses on
distinguishing between supportive and non-supportive. The second task aims to
identify whether the support is directed toward an individual or a group. The
third task categorizes the specific type of social support, grouping it into
categories such as Nation, LGBTQ, Black people, Women, Religion, and Other (if
it does not fit into the previously mentioned categories). To address data
imbalances in these tasks, we employed K-means clustering for balancing the
dataset and compared the results with the original unbalanced data. Using
advanced machine learning techniques, including transformers and zero-shot
learning approaches with GPT3, GPT4, and GPT4-o, we predict social support
levels in various contexts. The effectiveness of the dataset is evaluated using
baseline models across different learning approaches, with transformer-based
methods demonstrating superior performance. Additionally, we achieved a 0.4\%
increase in the macro F1 score for the second task and a 0.7\% increase for the
third task, compared to previous work utilizing traditional machine learning
with psycholinguistic and unigram-based TF-IDF values.

摘要：社群媒體的廣泛使用，凸顯出了解其影響的必要性，特別是在線社群支持的角色。本研究使用專注於在線社群支持的資料集，其中包括社群媒體上社群支持內容的二元和多類別分類。社群支持的分類分為三個任務。第一個任務專注於區分支持和非支持。第二個任務旨在識別支持是針對個人還是群體。第三個任務對具體的社群支持類型進行分類，將其分組到國家、LGBTQ、黑人、女性、宗教和其他類別（如果它不屬於前面提到的類別）。為了解決這些任務中的資料不平衡問題，我們採用 K 平均群集來平衡資料集，並將結果與原始未平衡資料進行比較。使用先進的機器學習技術，包括Transformer和零次學習方法與 GPT3、GPT4 和 GPT4-o，我們預測各種情境中的社群支持水準。資料集的有效性使用不同學習方法的基準模型進行評估，基於Transformer的模型表現出優異的效能。此外，與先前利用傳統機器學習、心理語言學和基於單字的 TF-IDF 值的工作相比，我們在第二個任務中將巨集 F1 分數提高了 0.4%，在第三個任務中提高了 0.7%。

##### **FTA-FTL: A Fine-Tuned Aggregation Federated Transfer Learning Scheme for Lithology Microscopic Image Classification**
2501.03349v1 by Keyvan RahimiZadeh, Ahmad Taheri, Jan Baumbach, Esmael Makarian, Abbas Dehghani, Bahman Ravaei, Bahman Javadi, Amin Beheshti

Lithology discrimination is a crucial activity in characterizing oil
reservoirs, and processing lithology microscopic images is an essential
technique for investigating fossils and minerals and geological assessment of
shale oil exploration. In this way, Deep Learning (DL) technique is a powerful
approach for building robust classifier models. However, there is still a
considerable challenge to collect and produce a large dataset.
Transfer-learning and data augmentation techniques have emerged as popular
approaches to tackle this problem. Furthermore, due to different reasons,
especially data privacy, individuals, organizations, and industry companies
often are not willing to share their sensitive data and information. Federated
Learning (FL) has emerged to train a highly accurate central model across
multiple decentralized edge servers without transferring sensitive data,
preserving sensitive data, and enhancing security. This study involves two
phases; the first phase is to conduct Lithology microscopic image
classification on a small dataset using transfer learning. In doing so, various
pre-trained DL model architectures are comprehensively compared for the
classification task. In the second phase, we formulated the classification task
to a Federated Transfer Learning (FTL) scheme and proposed a Fine-Tuned
Aggregation strategy for Federated Learning (FTA-FTL). In order to perform a
comprehensive experimental study, several metrics such as accuracy, f1 score,
precision, specificity, sensitivity (recall), and confusion matrix are taken
into account. The results are in excellent agreement and confirm the efficiency
of the proposed scheme, and show that the proposed FTA-FTL algorithm is capable
enough to achieve approximately the same results obtained by the centralized
implementation for Lithology microscopic images classification task.

摘要：岩性判別是描述油藏的重要活動，而處理岩性顯微鏡影像則是研究化石和礦物以及評估頁岩油勘探的重要技術。因此，深度學習 (DL) 技術是建立強健分類器模型的強大方法。然而，收集和產生大型資料集仍然是一項相當大的挑戰。遷移學習和資料擴充技術已成為解決此問題的熱門方法。此外，由於各種原因，特別是資料隱私，個人、組織和產業公司通常不願意分享其敏感資料和資訊。聯邦學習 (FL) 已應運而生，可以在多個分散式邊緣伺服器上訓練高度準確的中央模型，而無需傳輸敏感資料、保護敏感資料並增強安全性。本研究包含兩個階段；第一階段是使用遷移學習對小型資料集進行岩性顯微鏡影像分類。在這樣做的過程中，全面比較了各種預訓練的 DL 模型架構以進行分類任務。在第二階段，我們將分類任務制定為聯邦遷移學習 (FTL) 架構，並提出了聯邦學習的微調聚合策略 (FTA-FTL)。為了執行全面的實驗研究，考慮了準確度、f1 分數、精確度、特異性、敏感度 (召回率) 和混淆矩陣等多項指標。結果非常吻合，證實了所提出架構的效率，並顯示所提出的 FTA-FTL 演算法有能力達成與岩性顯微鏡影像分類任務的集中式實作所獲得的結果大致相同。

##### **Analyzing Bias in Swiss Federal Supreme Court Judgments Using Facebook's Holistic Bias Dataset: Implications for Language Model Training**
2501.03324v1 by Sabine Wehnert, Muhammet Ertas, Ernesto William De Luca

Natural Language Processing (NLP) is vital for computers to process and
respond accurately to human language. However, biases in training data can
introduce unfairness, especially in predicting legal judgment. This study
focuses on analyzing biases within the Swiss Judgment Prediction Dataset
(SJP-Dataset). Our aim is to ensure unbiased factual descriptions essential for
fair decision making by NLP models in legal contexts. We analyze the dataset
using social bias descriptors from the Holistic Bias dataset and employ
advanced NLP techniques, including attention visualization, to explore the
impact of dispreferred descriptors on model predictions. The study identifies
biases and examines their influence on model behavior. Challenges include
dataset imbalance and token limits affecting model performance.

摘要：自然語言處理 (NLP) 對於電腦處理和準確回應人類語言至關重要。然而，訓練資料中的偏差可能會導致不公平，特別是在預測法律判決時。本研究專注於分析瑞士判決預測資料集 (SJP-Dataset) 中的偏差。我們的目標是確保無偏見的事實描述，這對於法律背景中 NLP 模型的公平決策至關重要。我們使用 Holistic Bias 資料集中的社會偏差描述符分析資料集，並採用先進的 NLP 技術，包括注意力視覺化，以探討不受歡迎的描述符對模型預測的影響。本研究識別偏差並檢視其對模型行為的影響。挑戰包括影響模型效能的資料集不平衡和標記限制。

##### **Gaussian Masked Autoencoders**
2501.03229v1 by Jathushan Rajasegaran, Xinlei Chen, Rulilong Li, Christoph Feichtenhofer, Jitendra Malik, Shiry Ginosar

This paper explores Masked Autoencoders (MAE) with Gaussian Splatting. While
reconstructive self-supervised learning frameworks such as MAE learns good
semantic abstractions, it is not trained for explicit spatial awareness. Our
approach, named Gaussian Masked Autoencoder, or GMAE, aims to learn semantic
abstractions and spatial understanding jointly. Like MAE, it reconstructs the
image end-to-end in the pixel space, but beyond MAE, it also introduces an
intermediate, 3D Gaussian-based representation and renders images via
splatting. We show that GMAE can enable various zero-shot learning capabilities
of spatial understanding (e.g., figure-ground segmentation, image layering,
edge detection, etc.) while preserving the high-level semantics of
self-supervised representation quality from MAE. To our knowledge, we are the
first to employ Gaussian primitives in an image representation learning
framework beyond optimization-based single-scene reconstructions. We believe
GMAE will inspire further research in this direction and contribute to
developing next-generation techniques for modeling high-fidelity visual data.
More details at https://brjathu.github.io/gmae

摘要：這篇論文探討了具有高斯潑點的遮罩式自動編碼器 (MAE)。雖然像 MAE 這樣的重建式自我監督學習架構學習了良好的語義抽象，但它並未針對明確的空間感知進行訓練。我們的方法稱為高斯遮罩式自動編碼器或 GMAE，旨在共同學習語義抽象和空間理解。它與 MAE 一樣，在像素空間中端對端重建影像，但除此之外，它還引入了中間的 3D 高斯表示，並透過潑點渲染影像。我們展示了 GMAE 能夠啟用各種空間理解的零次學習能力（例如，圖形分割、影像分層、邊緣檢測等），同時保留 MAE 自我監督表示品質的高階語義。據我們所知，我們是第一個在影像表示學習架構中採用高斯基元，而這超越了基於最佳化的單一場景重建。我們相信 GMAE 將激勵此方向的進一步研究，並有助於開發新一代的高保真視覺資料建模技術。更多詳情請見 https://brjathu.github.io/gmae

##### **LightGNN: Simple Graph Neural Network for Recommendation**
2501.03228v2 by Guoxuan Chen, Lianghao Xia, Chao Huang

Graph neural networks (GNNs) have demonstrated superior performance in
collaborative recommendation through their ability to conduct high-order
representation smoothing, effectively capturing structural information within
users' interaction patterns. However, existing GNN paradigms face significant
challenges in scalability and robustness when handling large-scale, noisy, and
real-world datasets. To address these challenges, we present LightGNN, a
lightweight and distillation-based GNN pruning framework designed to
substantially reduce model complexity while preserving essential collaboration
modeling capabilities. Our LightGNN framework introduces a computationally
efficient pruning module that adaptively identifies and removes redundant edges
and embedding entries for model compression. The framework is guided by a
resource-friendly hierarchical knowledge distillation objective, whose
intermediate layer augments the observed graph to maintain performance,
particularly in high-rate compression scenarios. Extensive experiments on
public datasets demonstrate LightGNN's effectiveness, significantly improving
both computational efficiency and recommendation accuracy. Notably, LightGNN
achieves an 80% reduction in edge count and 90% reduction in embedding entries
while maintaining performance comparable to more complex state-of-the-art
baselines. The implementation of our LightGNN framework is available at the
github repository: https://github.com/HKUDS/LightGNN.

摘要：圖形神經網路 (GNN) 已在協作推薦中展現優異的效能，原因在於其能夠執行高階表示平滑，有效擷取使用者互動模式中的結構資訊。然而，現有的 GNN 典範在處理大規模、有雜訊和真實世界的資料集時，在可擴充性和穩健性方面面臨重大挑戰。為了應對這些挑戰，我們提出了 LightGNN，這是一個輕量級且基於蒸餾的 GNN 修剪框架，旨在大幅降低模型複雜度，同時保留必要的協作建模能力。我們的 LightGNN 框架引入了計算效率高的修剪模組，可自適應地識別並移除多餘的邊緣和嵌入項目，以進行模型壓縮。該框架由資源友善的分層知識蒸餾目標引導，其中間層會擴充觀察到的圖形以維持效能，特別是在高壓縮情境中。在公開資料集上進行的廣泛實驗證明了 LightGNN 的有效性，顯著改善了運算效率和推薦準確度。值得注意的是，LightGNN 在邊緣數量上減少了 80%，嵌入項目減少了 90%，同時維持與更複雜的最新基準相當的效能。我們的 LightGNN 框架實作可在 github 存放庫中取得：https://github.com/HKUDS/LightGNN。

##### **BoostStep: Boosting mathematical capability of Large Language Models via improved single-step reasoning**
2501.03226v1 by Beichen Zhang, Yuhong Liu, Xiaoyi Dong, Yuhang Zang, Pan Zhang, Haodong Duan, Yuhang Cao, Dahua Lin, Jiaqi Wang

Cutting-edge large language models (LLMs) demonstrate promising performance
in solving complex math problems with a divide-and-conquer pipeline and the
assistance of in-context learning (ICL) examples. However, their potential for
improvement is limited by two critical problems within their ICL examples:
granularity-mismatch and the ensuing negative-effect noise problem.
Specifically, the LLMs are capable of the dividing process yet mostly failed by
inaccurate reasoning within a few conquer steps, while the ICL examples
retrieved in question-grained sometimes lack relevant steps for a specific
challenging reasoning step. Further, this disconnect may hinder the correct
reasoning due to its irrelevance. To this end, we focus on improving the
reasoning quality within each step and present BoostStep. BoostStep aligns the
granularity between the retrieving and reasoning on step grained, and provides
highly related ICL examples for each reasoning step with a novel `first-try'
strategy. BoostStep provides more relevant examples than the coarse
question-grained strategy, enhancing the model reasoning quality within each
step steadily. BoostStep is a general and robust reasoning-enhancing method
that not only improves standalone reasoning performance but also integrates
seamlessly with Monte Carlo Tree Search methods (MCTS) to refine both candidate
generation and decision-making. Quantitatively, it improves GPT-4o and
Qwen2.5-Math-72B by 3.6\% and 2.0\% respectively on various mathematical
benchmarks, and 7.5\% gain combined with MCTS.

摘要：尖端的巨量語言模型 (LLM) 在解決複雜的數學問題上展現了有前途的表現，採用分而治之的管道和情境學習 (ICL) 範例的協助。然而，它們的進步潛力受到 ICL 範例中兩個關鍵問題的限制：粒度不匹配和隨之而來的負面效應噪音問題。具體來說，LLM 有能力進行分隔處理，但在幾個征服步驟中的不準確推理大多失敗，而以問題粒度檢索的 ICL 範例有時缺乏特定挑戰性推理步驟的相关步驟。此外，這種脫節可能會因其無關性而阻礙正確的推理。為此，我們專注於提高每個步驟中的推理品質，並提出 BoostStep。BoostStep 在步驟粒度上調整檢索和推理之間的粒度，並使用新穎的「首次嘗試」策略為每個推理步驟提供高度相關的 ICL 範例。BoostStep 提供比粗略的問題粒度策略更相關的範例，穩步提升每個步驟中的模型推理品質。BoostStep 是一種通用且強大的推理增強方法，不僅改善獨立推理表現，還能與蒙地卡羅樹狀搜尋方法 (MCTS) 無縫整合，以改善候選產生和決策制定。在量化方面，它分別在各種數學基準上將 GPT-4o 和 Qwen2.5-Math-72B 提升了 3.6% 和 2.0%，並結合 MCTS 獲得了 7.5% 的增益。

##### **Automated Generation of Challenging Multiple-Choice Questions for Vision Language Model Evaluation**
2501.03225v1 by Yuhui Zhang, Yuchang Su, Yiming Liu, Xiaohan Wang, James Burgess, Elaine Sui, Chenyu Wang, Josiah Aklilu, Alejandro Lozano, Anjiang Wei, Ludwig Schmidt, Serena Yeung-Levy

The rapid development of vision language models (VLMs) demands rigorous and
reliable evaluation. However, current visual question answering (VQA)
benchmarks often depend on open-ended questions, making accurate evaluation
difficult due to the variability in natural language responses. To address
this, we introduce AutoConverter, an agentic framework that automatically
converts these open-ended questions into multiple-choice format, enabling
objective evaluation while reducing the costly question creation process. Our
experiments demonstrate that AutoConverter can generate correct and challenging
multiple-choice questions, with VLMs demonstrating consistently similar or
lower accuracy on these questions compared to human-created ones. Using
AutoConverter, we construct VMCBench, a benchmark created by transforming 20
existing VQA datasets into a unified multiple-choice format, totaling 9,018
questions. We comprehensively evaluate 33 state-of-the-art VLMs on VMCBench,
setting a new standard for scalable, consistent, and reproducible VLM
evaluation.

摘要：視覺語言模型 (VLM) 的快速發展需要嚴謹且可靠的評估。然而，目前的視覺問答 (VQA) 基準通常依賴於開放式問題，由於自然語言回應的可變性，導致精確評估變得困難。為了解決這個問題，我們引入了 AutoConverter，一個自動將這些開放式問題轉換成多選題格式的代理框架，在降低成本高昂的問題建立過程的同時，實現客觀評估。我們的實驗證明，AutoConverter 可以產生正確且具有挑戰性的多選題，與人類建立的問題相比，VLM 在這些問題上表現出持續相似或較低的準確度。使用 AutoConverter，我們建立了 VMCBench，一個通過將 20 個現有的 VQA 資料集轉換成統一的多選題格式而建立的基準，總計 9,018 個問題。我們在 VMCBench 上全面評估了 33 個最先進的 VLM，為可擴展、一致且可重現的 VLM 評估設定了新標準。

##### **Leveraging Explainable AI for LLM Text Attribution: Differentiating Human-Written and Multiple LLMs-Generated Text**
2501.03212v1 by Ayat Najjar, Huthaifa I. Ashqar, Omar Darwish, Eman Hammad

The development of Generative AI Large Language Models (LLMs) raised the
alarm regarding identifying content produced through generative AI or humans.
In one case, issues arise when students heavily rely on such tools in a manner
that can affect the development of their writing or coding skills. Other issues
of plagiarism also apply. This study aims to support efforts to detect and
identify textual content generated using LLM tools. We hypothesize that
LLMs-generated text is detectable by machine learning (ML), and investigate ML
models that can recognize and differentiate texts generated by multiple LLMs
tools. We leverage several ML and Deep Learning (DL) algorithms such as Random
Forest (RF), and Recurrent Neural Networks (RNN), and utilized Explainable
Artificial Intelligence (XAI) to understand the important features in
attribution. Our method is divided into 1) binary classification to
differentiate between human-written and AI-text, and 2) multi classification,
to differentiate between human-written text and the text generated by the five
different LLM tools (ChatGPT, LLaMA, Google Bard, Claude, and Perplexity).
Results show high accuracy in the multi and binary classification. Our model
outperformed GPTZero with 98.5\% accuracy to 78.3\%. Notably, GPTZero was
unable to recognize about 4.2\% of the observations, but our model was able to
recognize the complete test dataset. XAI results showed that understanding
feature importance across different classes enables detailed author/source
profiles. Further, aiding in attribution and supporting plagiarism detection by
highlighting unique stylistic and structural elements ensuring robust content
originality verification.

摘要：生成式 AI 大型语言模型 (LLM) 的发展引起了人们对识别通过生成式 AI 或人类产生的内容的警觉。
在一种情况下，当学生严重依赖此类工具时，可能会出现影响其写作或编码技能发展的问题。其他抄袭问题也适用。本研究旨在支持检测和识别使用 LLM 工具生成的文本内容的努力。我们假设 LLM 生成的文本可通过机器学习 (ML) 检测，并研究能够识别和区分由多个 LLM 工具生成的文本的 ML 模型。我们利用了多种 ML 和深度学习 (DL) 算法，例如随机森林 (RF) 和循环神经网络 (RNN)，并利用可解释人工智能 (XAI) 来理解归因中的重要特征。我们的方法分为 1) 二元分类，以区分人写文本和 AI 文本，以及 2) 多分类，以区分人写文本和由五种不同的 LLM 工具（ChatGPT、LLaMA、Google Bard、Claude 和 Perplexity）生成的文本。结果显示在多分类和二元分类中具有很高的准确性。我们的模型以 98.5% 的准确率优于 GPTZero，达到 78.3%。值得注意的是，GPTZero 无法识别约 4.2% 的观察结果，但我们的模型能够识别完整的测试数据集。XAI 结果表明，理解不同类别的特征重要性可以实现详细的作者/来源概况。此外，通过突出独特的风格和结构元素来辅助归因并支持抄袭检测，确保内容原创性验证的稳健性。

##### **Detecting AI-Generated Text in Educational Content: Leveraging Machine Learning and Explainable AI for Academic Integrity**
2501.03203v1 by Ayat A. Najjar, Huthaifa I. Ashqar, Omar A. Darwish, Eman Hammad

This study seeks to enhance academic integrity by providing tools to detect
AI-generated content in student work using advanced technologies. The findings
promote transparency and accountability, helping educators maintain ethical
standards and supporting the responsible integration of AI in education. A key
contribution of this work is the generation of the CyberHumanAI dataset, which
has 1000 observations, 500 of which are written by humans and the other 500
produced by ChatGPT. We evaluate various machine learning (ML) and deep
learning (DL) algorithms on the CyberHumanAI dataset comparing human-written
and AI-generated content from Large Language Models (LLMs) (i.e., ChatGPT).
Results demonstrate that traditional ML algorithms, specifically XGBoost and
Random Forest, achieve high performance (83% and 81% accuracies respectively).
Results also show that classifying shorter content seems to be more challenging
than classifying longer content. Further, using Explainable Artificial
Intelligence (XAI) we identify discriminative features influencing the ML
model's predictions, where human-written content tends to use a practical
language (e.g., use and allow). Meanwhile AI-generated text is characterized by
more abstract and formal terms (e.g., realm and employ). Finally, a comparative
analysis with GPTZero show that our narrowly focused, simple, and fine-tuned
model can outperform generalized systems like GPTZero. The proposed model
achieved approximately 77.5% accuracy compared to GPTZero's 48.5% accuracy when
tasked to classify Pure AI, Pure Human, and mixed class. GPTZero showed a
tendency to classify challenging and small-content cases as either mixed or
unrecognized while our proposed model showed a more balanced performance across
the three classes.

摘要：<paragraph>本研究旨在透過提供工具來偵測學生作業中使用進階技術產生的 AI 內容，以提升學術誠信。研究結果促進透明度和問責制，協助教育工作者維持倫理標準，並支持負責任地將 AI 整合到教育中。這項研究的一項重要貢獻是產生 CyberHumanAI 資料集，其中包含 1000 個觀察結果，其中 500 個是由人類撰寫，另外 500 個是由 ChatGPT 產生。我們在 CyberHumanAI 資料集上評估各種機器學習 (ML) 和深度學習 (DL) 演算法，比較人類撰寫的內容和大型語言模型 (LLM)（即 ChatGPT）產生的 AI 內容。結果顯示，傳統的 ML 演算法，特別是 XGBoost 和隨機森林，能達到高準確度（分別為 83% 和 81%）。結果還顯示，對較短內容進行分類似乎比對較長內容進行分類更具挑戰性。此外，透過使用可解釋人工智慧 (XAI)，我們找出影響 ML 模型預測的區別性特徵，其中人類撰寫的內容傾向於使用實用的語言（例如，使用和允許）。與此同時，AI 生成的文字的特徵是使用更抽象和正式的術語（例如，領域和使用）。最後，與 GPTZero 進行比較分析顯示，我們狹義聚焦、簡單且經過微調的模型可以勝過 GPTZero 等通用系統。在對純 AI、純人類和混合類別進行分類時，建議的模型達到約 77.5% 的準確度，而 GPTZero 的準確度為 48.5%。GPTZero 傾向於將具挑戰性和小內容的案例分類為混合或無法辨識，而我們建議的模型在三個類別中表現出更平衡的效能。</paragraph>

##### **The FACTS Grounding Leaderboard: Benchmarking LLMs' Ability to Ground Responses to Long-Form Input**
2501.03200v1 by Alon Jacovi, Andrew Wang, Chris Alberti, Connie Tao, Jon Lipovetz, Kate Olszewska, Lukas Haas, Michelle Liu, Nate Keating, Adam Bloniarz, Carl Saroufim, Corey Fry, Dror Marcus, Doron Kukliansky, Gaurav Singh Tomar, James Swirhun, Jinwei Xing, Lily Wang, Madhu Gurumurthy, Michael Aaron, Moran Ambar, Rachana Fellinger, Rui Wang, Zizhao Zhang, Sasha Goldshtein, Dipanjan Das

We introduce FACTS Grounding, an online leaderboard and associated benchmark
that evaluates language models' ability to generate text that is factually
accurate with respect to given context in the user prompt. In our benchmark,
each prompt includes a user request and a full document, with a maximum length
of 32k tokens, requiring long-form responses. The long-form responses are
required to be fully grounded in the provided context document while fulfilling
the user request. Models are evaluated using automated judge models in two
phases: (1) responses are disqualified if they do not fulfill the user request;
(2) they are judged as accurate if the response is fully grounded in the
provided document. The automated judge models were comprehensively evaluated
against a held-out test-set to pick the best prompt template, and the final
factuality score is an aggregate of multiple judge models to mitigate
evaluation bias. The FACTS Grounding leaderboard will be actively maintained
over time, and contains both public and private splits to allow for external
participation while guarding the integrity of the leaderboard. It can be found
at https://www.kaggle.com/facts-leaderboard.

摘要：我們引入了 FACTS Grounding，這是一個線上排行榜和相關基準，用於評估語言模型根據使用者提示中提供的背景，產生事實上準確的文本的能力。在我們的基準中，每個提示都包含一個使用者請求和一個完整文件，最大長度為 32k 個符號，需要長篇回應。長篇回應必須完全建立在提供的背景文件中，同時滿足使用者的請求。模型使用自動評分模型在兩個階段進行評估：(1) 如果回應不滿足使用者的請求，則取消資格；(2) 如果回應完全建立在提供的文件中，則判斷為準確。自動評分模型根據保留的測試集進行全面評估，以選擇最佳提示範本，最終的事實分數是多個評分模型的總和，以減輕評估偏差。FACTS Grounding 排行榜將隨著時間積極維護，並包含公開和私人拆分，以允許外部參與，同時保護排行榜的完整性。它可以在 https://www.kaggle.com/facts-leaderboard 找到。

##### **CLIX: Cross-Lingual Explanations of Idiomatic Expressions**
2501.03191v1 by Aaron Gluck, Katharina von der Wense, Maria Pacheco

Automated definition generation systems have been proposed to support
vocabulary expansion for language learners. The main barrier to the success of
these systems is that learners often struggle to understand definitions due to
the presence of potentially unfamiliar words and grammar, particularly when
non-standard language is involved. To address these challenges, we propose
CLIX, the task of Cross-Lingual explanations of Idiomatic eXpressions. We
explore the capabilities of current NLP models for this task, and observe that
while it remains challenging, large language models show promise. Finally, we
perform a detailed error analysis to highlight the key challenges that need to
be addressed before we can reliably incorporate these systems into educational
tools.

摘要：自動定義產生系統已被提議用於支援語言學習者的詞彙擴充。這些系統成功的最大障礙是，學習者經常難以理解定義，原因在於存在潛在不熟悉的字詞和文法，特別是在涉及非標準語言時。為了應對這些挑戰，我們提出 CLIX，即慣用語的跨語言解釋任務。我們探討了當前 NLP 模型對此任務的能力，並觀察到儘管這仍然具有挑戰性，但大型語言模型展現了前景。最後，我們執行詳細的錯誤分析，以強調在我們能夠將這些系統可靠地整合到教育工具之前需要應對的主要挑戰。

##### **Turn-based Multi-Agent Reinforcement Learning Model Checking**
2501.03187v1 by Dennis Gross

In this paper, we propose a novel approach for verifying the compliance of
turn-based multi-agent reinforcement learning (TMARL) agents with complex
requirements in stochastic multiplayer games. Our method overcomes the
limitations of existing verification approaches, which are inadequate for
dealing with TMARL agents and not scalable to large games with multiple agents.
Our approach relies on tight integration of TMARL and a verification technique
referred to as model checking. We demonstrate the effectiveness and scalability
of our technique through experiments in different types of environments. Our
experiments show that our method is suited to verify TMARL agents and scales
better than naive monolithic model checking.

摘要：在本文中，我們提出了一種新穎的方法來驗證基於回合的多智能體強化學習 (TMARL) 代理是否符合隨機多玩家遊戲中的複雜需求。我們的這種方法克服了現有驗證方法的限制，而這些限制不足以應對 TMARL 代理，並且無法擴展到具有多個代理的大型遊戲。我們的這種方法依賴於 TMARL 和一種稱為模型檢查的驗證技術的緊密整合。我們通過在不同類型的環境中進行實驗來證明我們的這種技術的有效性和可擴展性。我們的實驗表明，我們的這種方法適用於驗證 TMARL 代理，並且比單一的模型檢查擴展得更好。

##### **GLiREL -- Generalist Model for Zero-Shot Relation Extraction**
2501.03172v1 by Jack Boylan, Chris Hokamp, Demian Gholipour Ghalandari

We introduce GLiREL (Generalist Lightweight model for zero-shot Relation
Extraction), an efficient architecture and training paradigm for zero-shot
relation classification. Inspired by recent advancements in zero-shot named
entity recognition, this work presents an approach to efficiently and
accurately predict zero-shot relationship labels between multiple entities in a
single forward pass. Experiments using the FewRel and WikiZSL benchmarks
demonstrate that our approach achieves state-of-the-art results on the
zero-shot relation classification task. In addition, we contribute a protocol
for synthetically-generating datasets with diverse relation labels.

摘要：我們介紹 GLiREL（零次關係抽取的通才輕量級模型），這是一種用於零次關係分類的高效架構和訓練範例。受到近期零次命名實體辨識進展的啟發，本研究提出一個方法，可以在單次前向傳遞中，有效且準確地預測多個實體之間的零次關係標籤。使用 FewRel 和 WikiZSL 基準所做的實驗證明，我們的做法在零次關係分類任務中取得了最先進的成果。此外，我們提供了一個使用多元關係標籤合成產生資料集的協定。

##### **Semantic Captioning: Benchmark Dataset and Graph-Aware Few-Shot In-Context Learning for SQL2Text**
2501.03166v1 by Ali Al-Lawati, Jason Lucas, Prasenjit Mitra

Large Language Models (LLMs) have demonstrated remarkable performance in
various NLP tasks, including semantic parsing, which trans lates natural
language into formal code representations. However, the reverse process,
translating code into natural language, termed semantic captioning, has
received less attention. This task is becoming increasingly important as LLMs
are integrated into platforms for code generation, security analysis, and
educational purposes. In this paper, we focus on the captioning of SQL query
(SQL2Text) to address the critical need for understanding and explaining SQL
queries in an era where LLM-generated code poses potential security risks. We
repurpose Text2SQL datasets for SQL2Text by introducing an iterative ICL prompt
using GPT-4o to generate multiple additional utterances, which enhances the
robustness of the datasets for the reverse task. We conduct our experiments
using in-context learning (ICL) based on different sample selection methods,
emphasizing smaller, more computationally efficient LLMs. Our findings
demonstrate that leveraging the inherent graph properties of SQL for ICL sample
selection significantly outperforms random selection by up to 39% on BLEU score
and provides better results than alternative methods. Dataset and codes are
published: \url{https://github.com/aliwister/ast-icl}.

摘要：大型語言模型 (LLM) 已在各種 NLP 任務中展現出驚人的效能，包括語意分析，它將自然語言轉換為正式的程式碼表示。然而，反向過程，將程式碼轉換為自然語言，稱為語意標題，則較少受到關注。隨著 LLM 整合到程式碼產生、安全性分析和教育目的的平台中，這項任務正變得越來越重要。在本文中，我們專注於 SQL 查詢的標題 (SQL2Text)，以滿足在 LLM 產生的程式碼構成潛在安全風險的時代中，理解和解釋 SQL 查詢的關鍵需求。我們透過使用 GPT-4o 導入反覆的 ICL 提示來產生多個額外的語句，重新調整 Text2SQL 資料集以用於 SQL2Text，這增強了資料集對反向任務的穩健性。我們使用基於不同範例選取方法的情境學習 (ICL) 進行實驗，強調較小、計算效率較高的 LLM。我們的研究結果證明，利用 SQL 的內在圖形屬性進行 ICL 範例選取，在 BLEU 分數上顯著優於隨機選取，最多可達 39%，並提供比其他方法更好的結果。資料集和程式碼已發布：\url{https://github.com/aliwister/ast-icl}。

##### **The Scaling Law for LoRA Base on Mutual Information Upper Bound**
2501.03152v1 by Jing Zhang, Hui Gao, Peng Zhang, Shuzhen Sun, Chang Yang, Yuexian Hou

LoRA (Low-Rank Adaptation) is a widely used model fine-tuning method. In
fine-tuning, the law among model performance, model parameters, and data
complexity has been a focal issue in the field. Existing methods often leverage
external metrics (such as cross-entropy or perplexity) to evaluate model
performance. In the fine-tuning process for large models, two types of
knowledge are typically involved: the frozen, general knowledge acquired by the
model during pre-training and the new knowledge learned through the LoRA module
from the current data. Generally, the less LoRA's learned knowledge relies on
the large model, the more it captures the specific knowledge of new data,
thereby enhancing its adaptability to new tasks. However, external metrics do
not readily capture the dependency relationship between these two types of
knowledge. Therefore, we designed an internal metric based on the Mutual
Information Upper Bound (MIUB) theory to investigate the scaling law of
large-model LoRA fine-tuning. In our experiments, we validated this approach on
benchmark datasets, using the Llama3-8B and Phi3-3B models. The results show
that the proposed MIUB metric aligns more accurately and stably with the
scaling law of LoRA fine-tuning compared to cross-entropy and perplexity.

摘要：LoRA（低秩適應）是一種廣泛使用的模型微調方法。在微調中，模型效能、模型參數和資料複雜度之間的定律一直是該領域的焦點議題。現有方法通常利用外部指標（例如交叉熵或困惑度）來評估模型效能。在大型模型的微調過程中，通常涉及兩種知識：模型在預訓練期間獲得的凍結式一般知識，以及透過 LoRA 模組從當前資料中學習到的新知識。一般來說，LoRA 學習到的知識越不依賴於大型模型，它擷取新資料的特定知識就越多，從而增強其對新任務的適應性。然而，外部指標並不能輕易擷取這兩種知識之間的依賴關係。因此，我們根據互資訊上限 (MIUB) 理論設計了一個內部指標，來探討大型模型 LoRA 微調的規模定律。在我們的實驗中，我們使用 Llama3-8B 和 Phi3-3B 模型，在基準資料集上驗證了這種方法。結果表明，與交叉熵和困惑度相比，所提出的 MIUB 指標與 LoRA 微調的規模定律更準確且穩定地對齊。

##### **Large language models for artificial general intelligence (AGI): A survey of foundational principles and approaches**
2501.03151v1 by Alhassan Mumuni, Fuseini Mumuni

Generative artificial intelligence (AI) systems based on large-scale
pretrained foundation models (PFMs) such as vision-language models, large
language models (LLMs), diffusion models and vision-language-action (VLA)
models have demonstrated the ability to solve complex and truly non-trivial AI
problems in a wide variety of domains and contexts. Multimodal large language
models (MLLMs), in particular, learn from vast and diverse data sources,
allowing rich and nuanced representations of the world and, thereby, providing
extensive capabilities, including the ability to reason, engage in meaningful
dialog; collaborate with humans and other agents to jointly solve complex
problems; and understand social and emotional aspects of humans. Despite this
impressive feat, the cognitive abilities of state-of-the-art LLMs trained on
large-scale datasets are still superficial and brittle. Consequently, generic
LLMs are severely limited in their generalist capabilities. A number of
foundational problems -- embodiment, symbol grounding, causality and memory --
are required to be addressed for LLMs to attain human-level general
intelligence. These concepts are more aligned with human cognition and provide
LLMs with inherent human-like cognitive properties that support the realization
of physically-plausible, semantically meaningful, flexible and more
generalizable knowledge and intelligence. In this work, we discuss the
aforementioned foundational issues and survey state-of-the art approaches for
implementing these concepts in LLMs. Specifically, we discuss how the
principles of embodiment, symbol grounding, causality and memory can be
leveraged toward the attainment of artificial general intelligence (AGI) in an
organic manner.

摘要：<paragraph>基於大規模預訓練基礎模型 (PFM) 的生成式人工智慧 (AI) 系統，例如視覺語言模型、大型語言模型 (LLM)、擴散模型和視覺語言動作 (VLA) 模型，已展現了解決各種領域和情境中複雜且真正非平凡的人工智慧問題的能力。特別是多模態大型語言模型 (MLLM)，從廣泛且多樣化的資料來源學習，能豐富且細緻地呈現世界，因此提供了廣泛的能力，包括推理、進行有意義的對話；與人類和其他代理人合作，共同解決複雜的問題；以及了解人類的社會和情緒面向。儘管有此令人印象深刻的壯舉，在大型資料集上訓練的最先進 LLM 的認知能力仍然膚淺且脆弱。因此，通用 LLM 的通才能力受到嚴重限制。LLM 要達到人類層級的通用智慧，需要解決許多基礎問題，包括具身化、符號接地、因果關係和記憶。這些概念更符合人類認知，並為 LLM 提供了內在的人類認知特性，支持實現物理上合理、語義上意義重大、靈活且更具概括性的知識和智慧。在這項工作中，我們討論了上述基礎問題，並探討了在 LLM 中實施這些概念的最先進方法。具體來說，我們討論了如何利用具身化、符號接地、因果關係和記憶的原則，以有機的方式實現人工通用智慧 (AGI)。</paragraph>

##### **Co-Activation Graph Analysis of Safety-Verified and Explainable Deep Reinforcement Learning Policies**
2501.03142v1 by Dennis Gross, Helge Spieker

Deep reinforcement learning (RL) policies can demonstrate unsafe behaviors
and are challenging to interpret. To address these challenges, we combine RL
policy model checking--a technique for determining whether RL policies exhibit
unsafe behaviors--with co-activation graph analysis--a method that maps neural
network inner workings by analyzing neuron activation patterns--to gain insight
into the safe RL policy's sequential decision-making. This combination lets us
interpret the RL policy's inner workings for safe decision-making. We
demonstrate its applicability in various experiments.

摘要：深度強化學習 (RL) 政策可能會表現出不安全的行為，且難以解釋。為了應對這些挑戰，我們結合了 RL 政策模型檢查（一種用於確定 RL 政策是否表現出不安全行為的技術）和共激活圖形分析（一種透過分析神經元激活模式來繪製神經網路內部運作的方法），以深入了解安全的 RL 政策的順序決策制定。這種結合讓我們可以解釋 RL 政策的內部運作，以進行安全的決策制定。我們在各種實驗中展示了它的適用性。

##### **VicSim: Enhancing Victim Simulation with Emotional and Linguistic Fidelity**
2501.03139v1 by Yerong Li, Yiren Liu, Yun Huang

Scenario-based training has been widely adopted in many public service
sectors. Recent advancements in Large Language Models (LLMs) have shown promise
in simulating diverse personas to create these training scenarios. However,
little is known about how LLMs can be developed to simulate victims for
scenario-based training purposes. In this paper, we introduce VicSim (victim
simulator), a novel model that addresses three key dimensions of user
simulation: informational faithfulness, emotional dynamics, and language style
(e.g., grammar usage). We pioneer the integration of scenario-based victim
modeling with GAN-based training workflow and key-information-based prompting,
aiming to enhance the realism of simulated victims. Our adversarial training
approach teaches the discriminator to recognize grammar and emotional cues as
reliable indicators of synthetic content. According to evaluations by human
raters, the VicSim model outperforms GPT-4 in terms of human-likeness.

摘要：情境式訓練已廣泛應用於許多公共服務部門。大型語言模型 (LLM) 的最新進展已展現出模擬各種角色以建立這些訓練情境的潛力。然而，鮮少人了解如何開發 LLM 以模擬受害者，作為情境式訓練用途。在本文中，我們介紹了 VicSim（受害者模擬器），這是一種新穎的模型，可解決使用者模擬的三個關鍵面向：資訊真實性、情緒動態和語言風格（例如，語法使用）。我們率先將情境式受害者建模與基於 GAN 的訓練工作流程和基於關鍵資訊的提示整合在一起，旨在增強模擬受害者的真實性。我們的對抗式訓練方法教導辨識器將語法和情緒線索視為合成內容的可靠指標。根據人類評分者的評量，VicSim 模型在類人化方面優於 GPT-4。

##### **PRMBench: A Fine-grained and Challenging Benchmark for Process-Level Reward Models**
2501.03124v2 by Mingyang Song, Zhaochen Su, Xiaoye Qu, Jiawei Zhou, Yu Cheng

Process-level Reward Models (PRMs) are crucial for complex reasoning and
decision-making tasks, where each intermediate step plays an important role in
the reasoning process. Since language models are prone to various types of
errors during the reasoning process, PRMs are required to possess nuanced
capabilities for detecting various implicit error types in real-world
scenarios. However, current benchmarks primarily focus on step correctness,
failing to evaluate PRMs' performance systematically. To address this gap, we
introduce PRMBench, a process-level benchmark specifically designed to assess
the fine-grained error detection capabilities of PRMs. PRMBench comprises 6,216
carefully designed problems and 83,456 step-level labels, evaluating models
across multiple dimensions, including simplicity, soundness, and sensitivity.
In our experiments on 15 models, spanning both open-source PRMs and
closed-source large language models prompted as critic models, we uncover
significant weaknesses in current PRMs. These findings underscore the
challenges inherent in process-level evaluation and highlight key directions
for future research. We hope PRMBench can be a robust bench for advancing
research on PRM evaluation and development.

摘要：<paragraph>流程級獎勵模型 (PRM) 對複雜的推理和決策任務至關重要，其中每個中間步驟在推理過程中都扮演著重要的角色。由於語言模型在推理過程中容易出現各種類型的錯誤，因此需要 PRM 擁有細緻入微的能力來偵測現實世界場景中的各種隱含錯誤類型。然而，目前的基準主要關注於步驟正確性，無法系統性地評估 PRM 的效能。為了解決這個差距，我們引入了 PRMBench，一個專門設計用來評估 PRM 的細微錯誤偵測能力的流程級基準。PRMBench 包含 6,216 個精心設計的問題和 83,456 個步驟級標籤，從多個面向評估模型，包括簡潔性、健全性和敏感性。在我們對 15 個模型的實驗中，涵蓋了開放原始碼 PRM 和封閉原始碼大型語言模型，提示為批判模型，我們發現了當前 PRM 中的顯著弱點。這些發現強調了流程級評估中固有的挑戰，並突出了未來研究的主要方向。我們希望 PRMBench 能成為推進 PRM 評估和開發研究的強大基準。</paragraph>

##### **From Models to Network Topologies: A Topology Inference Attack in Decentralized Federated Learning**
2501.03119v1 by Chao Feng, Yuanzhe Gao, Alberto Huertas Celdran, Gerome Bovet, Burkhard Stiller

Federated Learning (FL) is widely recognized as a privacy-preserving machine
learning paradigm due to its model-sharing mechanism that avoids direct data
exchange. However, model training inevitably leaves exploitable traces that can
be used to infer sensitive information. In Decentralized FL (DFL), the overlay
topology significantly influences its models' convergence, robustness, and
security. This study explores the feasibility of inferring the overlay topology
of DFL systems based solely on model behavior, introducing a novel Topology
Inference Attack. A taxonomy of topology inference attacks is proposed,
categorizing them by the attacker's capabilities and knowledge. Practical
attack strategies are developed for different scenarios, and quantitative
experiments are conducted to identify key factors influencing the attack
effectiveness. Experimental results demonstrate that analyzing only the public
models of individual nodes can accurately infer the DFL topology, underscoring
the risk of sensitive information leakage in DFL systems. This finding offers
valuable insights for improving privacy preservation in decentralized learning
environments.

摘要：聯邦學習 (FL) 由於其避免直接資料交換的模型共享機制，被廣泛認為是一種保護隱私的機器學習範例。然而，模型訓練不可避免地會留下可利用的痕跡，可被用於推斷敏感資訊。在分散式 FL (DFL) 中，疊加拓撲結構顯著影響其模型的收斂性、穩健性和安全性。本研究探討僅根據模型行為推斷 DFL 系統疊加拓撲結構的可行性，並引入了一種新型的拓撲推斷攻擊。提出了一種拓撲推斷攻擊分類法，根據攻擊者的能力和知識對其進行分類。針對不同的場景制定了實用的攻擊策略，並進行了定量實驗以找出影響攻擊有效性的關鍵因素。實驗結果表明，僅分析個別節點的公開模型就可以準確推斷出 DFL 拓撲結構，這強調了 DFL 系統中敏感資訊洩漏的風險。這一發現為改善分散式學習環境中的隱私保護提供了寶貴的見解。

##### **LangFair: A Python Package for Assessing Bias and Fairness in Large Language Model Use Cases**
2501.03112v1 by Dylan Bouchard, Mohit Singh Chauhan, David Skarbrevik, Viren Bajaj, Zeya Ahmad

Large Language Models (LLMs) have been observed to exhibit bias in numerous
ways, potentially creating or worsening outcomes for specific groups identified
by protected attributes such as sex, race, sexual orientation, or age. To help
address this gap, we introduce LangFair, an open-source Python package that
aims to equip LLM practitioners with the tools to evaluate bias and fairness
risks relevant to their specific use cases. The package offers functionality to
easily generate evaluation datasets, comprised of LLM responses to
use-case-specific prompts, and subsequently calculate applicable metrics for
the practitioner's use case. To guide in metric selection, LangFair offers an
actionable decision framework.

摘要：大型語言模型 (LLM) 已被觀察到以各種方式表現出偏見，可能會對由受保護屬性（例如性別、種族、性取向或年齡）識別的特定群體造成或惡化結果。為了幫助解決這個差距，我們引入了 LangFair，這是一個開源的 Python 套件，旨在為 LLM 從業者提供評估偏見和與其特定用例相關的公平性風險的工具。該套件提供功能，可輕鬆產生評估資料集，其中包含 LLM 對特定用例提示的回應，並隨後計算適用於從業者用例的指標。為了指導指標選擇，LangFair 提供了一個可行的決策架構。

##### **Sentiment-guided Commonsense-aware Response Generation for Mental Health Counseling**
2501.03088v1 by Aseem Srivastava, Gauri Naik, Alison Cerezo, Tanmoy Chakraborty, Md. Shad Akhtar

The crisis of mental health issues is escalating. Effective counseling serves
as a critical lifeline for individuals suffering from conditions like PTSD,
stress, etc. Therapists forge a crucial therapeutic bond with clients, steering
them towards positivity. Unfortunately, the massive shortage of professionals,
high costs, and mental health stigma pose significant barriers to consulting
therapists. As a substitute, Virtual Mental Health Assistants (VMHAs) have
emerged in the digital healthcare space. However, most existing VMHAs lack the
commonsense to understand the nuanced sentiments of clients to generate
effective responses. To this end, we propose EmpRes, a novel sentiment-guided
mechanism incorporating commonsense awareness for generating responses. By
leveraging foundation models and harnessing commonsense knowledge, EmpRes aims
to generate responses that effectively shape the client's sentiment towards
positivity. We evaluate the performance of EmpRes on HOPE, a benchmark
counseling dataset, and observe a remarkable performance improvement compared
to the existing baselines across a suite of qualitative and quantitative
metrics. Moreover, our extensive empirical analysis and human evaluation show
that the generation ability of EmpRes is well-suited and, in some cases,
surpasses the gold standard. Further, we deploy EmpRes as a chat interface for
users seeking mental health support. We address the deployed system's
effectiveness through an exhaustive user study with a significant positive
response. Our findings show that 91% of users find the system effective, 80%
express satisfaction, and over 85.45% convey a willingness to continue using
the interface and recommend it to others, demonstrating the practical
applicability of EmpRes in addressing the pressing challenges of mental health
support, emphasizing user feedback, and ethical considerations in a real-world
context.

摘要：心理健康問題的危機正在升高。有效的諮詢服務對患有創傷後壓力症候群、壓力等狀況的個人來說，是一個重要的生命線。治療師與個案建立重要的治療連結，引導他們走向正向。不幸的是，專業人員的大量短缺、高成本和心理健康污名化，對諮詢治療師造成重大的障礙。作為替代方案，虛擬心理健康助理 (VMHA) 已出現在數位醫療保健領域。然而，大多數現有的 VMHA 缺乏常識，無法理解個案細微的情緒，以產生有效的回應。為此，我們提出了 EmpRes，這是一種創新的情緒引導機制，結合常識意識來產生回應。透過利用基礎模型和運用常識知識，EmpRes 旨在產生有效塑造個案情緒走向正向的回應。我們在 HOPE，一個基準諮詢資料集上評估 EmpRes 的表現，並觀察到與現有基線相比，在各種定性和定量指標上都有顯著的表現提升。此外，我們廣泛的實證分析和人為評估顯示，EmpRes 的生成能力非常合適，在某些情況下，甚至超越了黃金標準。此外，我們將 EmpRes 部署為一個聊天介面，供尋求心理健康支持的使用者使用。我們透過一項詳盡的使用者研究，以顯著正向的回應，來探討已部署系統的有效性。我們的研究結果顯示，91% 的使用者認為該系統有效，80% 表示滿意，超過 85.45% 的人表示願意繼續使用該介面並推薦給其他人，這證明了 EmpRes 在解決心理健康支持的迫切挑戰、強調使用者回饋和在現實世界中的倫理考量方面的實際適用性。

##### **Personalized Fashion Recommendation with Image Attributes and Aesthetics Assessment**
2501.03085v1 by Chongxian Chen, Fan Mo, Xin Fan, Hayato Yamana

Personalized fashion recommendation is a difficult task because 1) the
decisions are highly correlated with users' aesthetic appetite, which previous
work frequently overlooks, and 2) many new items are constantly rolling out
that cause strict cold-start problems in the popular identity (ID)-based
recommendation methods. These new items are critical to recommend because of
trend-driven consumerism. In this work, we aim to provide more accurate
personalized fashion recommendations and solve the cold-start problem by
converting available information, especially images, into two attribute graphs
focusing on optimized image utilization and noise-reducing user modeling.
Compared with previous methods that separate image and text as two components,
the proposed method combines image and text information to create a richer
attributes graph. Capitalizing on the advancement of large language and vision
models, we experiment with extracting fine-grained attributes efficiently and
as desired using two different prompts. Preliminary experiments on the IQON3000
dataset have shown that the proposed method achieves competitive accuracy
compared with baselines.

摘要：客製化時尚推薦是一項困難的任務，因為 1) 決策與使用者的美學喜好高度相關，而先前的研究經常忽略這一點，以及 2) 許多新商品不斷推出，這會在流行的身分 (ID) 為基礎的推薦方法中造成嚴重的冷啟動問題。這些新商品對於推薦至關重要，因為它們會引領消費趨勢。在這項研究中，我們旨在提供更準確的客製化時尚推薦，並透過將可用資訊（尤其是圖片）轉換成兩個屬性圖表來解決冷啟動問題，重點在於最佳化圖片使用和降低雜訊的使用者建模。與將圖片和文字分開為兩個組成的先前方法相比，所提出的方法結合圖片和文字資訊，以建立更豐富的屬性圖表。利用大型語言和視覺模型的進步，我們嘗試使用兩種不同的提示有效率且如預期般地萃取細緻的屬性。在 IQON3000 資料集上的初步實驗顯示，與基準相比，所提出的方法達到了競爭力的準確度。

##### **Rethinking Byzantine Robustness in Federated Recommendation from Sparse Aggregation Perspective**
2501.03301v1 by Zhongjian Zhang, Mengmei Zhang, Xiao Wang, Lingjuan Lyu, Bo Yan, Junping Du, Chuan Shi

To preserve user privacy in recommender systems, federated recommendation
(FR) based on federated learning (FL) emerges, keeping the personal data on the
local client and updating a model collaboratively. Unlike FL, FR has a unique
sparse aggregation mechanism, where the embedding of each item is updated by
only partial clients, instead of full clients in a dense aggregation of general
FL. Recently, as an essential principle of FL, model security has received
increasing attention, especially for Byzantine attacks, where malicious clients
can send arbitrary updates. The problem of exploring the Byzantine robustness
of FR is particularly critical since in the domains applying FR, e.g.,
e-commerce, malicious clients can be injected easily by registering new
accounts. However, existing Byzantine works neglect the unique sparse
aggregation of FR, making them unsuitable for our problem. Thus, we make the
first effort to investigate Byzantine attacks on FR from the perspective of
sparse aggregation, which is non-trivial: it is not clear how to define
Byzantine robustness under sparse aggregations and design Byzantine attacks
under limited knowledge/capability. In this paper, we reformulate the Byzantine
robustness under sparse aggregation by defining the aggregation for a single
item as the smallest execution unit. Then we propose a family of effective
attack strategies, named Spattack, which exploit the vulnerability in sparse
aggregation and are categorized along the adversary's knowledge and capability.
Extensive experimental results demonstrate that Spattack can effectively
prevent convergence and even break down defenses under a few malicious clients,
raising alarms for securing FR systems.

摘要：<paragraph>為了在推薦系統中保護使用者隱私，基於聯合學習 (FL) 的聯合推薦 (FR) 應運而生，它將個人資料保留在本地用戶端，並協作更新模型。與 FL 不同的是，FR 有一種獨特的稀疏聚合機制，其中每個項目的嵌入僅由部分用戶端更新，而不是在一般 FL 的密集聚合中由所有用戶端更新。最近，作為 FL 的一項基本原則，模型安全性備受關注，特別是對於拜占庭攻擊，其中惡意用戶端可以發送任意更新。探索 FR 的拜占庭魯棒性的問題尤其關鍵，因為在應用 FR 的領域中，例如電子商務，惡意用戶端可以通過註冊新帳戶輕鬆注入。然而，現有的拜占庭研究忽略了 FR 獨特的稀疏聚合，這使得它們不適合我們的問題。因此，我們從稀疏聚合的角度對 FR 的拜占庭攻擊進行了首次研究，這並非易事：在稀疏聚合下定義拜占庭魯棒性以及在有限的知識/能力下設計拜占庭攻擊尚不清楚。在本文中，我們通過將單一項目的聚合定義為最小的執行單元，重新制定了稀疏聚合下的拜占庭魯棒性。然後，我們提出了一系列有效的攻擊策略，稱為 Spattack，它利用了稀疏聚合中的漏洞，並根據對手的知識和能力進行分類。大量的實驗結果表明，Spattack 可以有效防止收斂，甚至在幾個惡意用戶端下破壞防禦，為保護 FR 系統敲響警鐘。</paragraph>

##### **Trust Modeling in Counseling Conversations: A Benchmark Study**
2501.03064v1 by Aseem Srivastava, Zuhair Hasan Shaik, Tanmoy Chakraborty, Md Shad Akhtar

In mental health counseling, a variety of earlier studies have focused on
dialogue modeling. However, most of these studies give limited to no emphasis
on the quality of interaction between a patient and a therapist. The
therapeutic bond between a patient and a therapist directly correlates with
effective mental health counseling. It involves developing the patient's trust
on the therapist over the course of counseling. To assess the therapeutic bond
in counseling, we introduce trust as a therapist-assistive metric. Our
definition of trust involves patients' willingness and openness to express
themselves and, consequently, receive better care. We conceptualize it as a
dynamic trajectory observable through textual interactions during the
counseling. To facilitate trust modeling, we present MENTAL-TRUST, a novel
counseling dataset comprising manual annotation of 212 counseling sessions with
first-of-its-kind seven expert-verified ordinal trust levels. We project our
problem statement as an ordinal classification task for trust quantification
and propose a new benchmark, TrustBench, comprising a suite of classical and
state-of-the-art language models on MENTAL-TRUST. We evaluate the performance
across a suite of metrics and lay out an exhaustive set of findings. Our study
aims to unfold how trust evolves in therapeutic interactions.

摘要：在心理健康諮商中，許多早期的研究都專注於對話建模。然而，這些研究大多僅強調或不強調患者與治療師之間互動的品質。患者與治療師之間的治療關係與有效的心理健康諮商直接相關。這涉及在諮商過程中建立患者對治療師的信任。為了評估諮商中的治療關係，我們將信任引入作為治療師輔助指標。我們對信任的定義包括患者表達自己的意願和開放性，並因此獲得更好的照護。我們將其概念化為在諮商期間透過文字互動可以觀察到的動態軌跡。為了促進信任建模，我們提出 MENTAL-TRUST，這是一個新穎的諮商資料集，包含 212 個諮商會談的手動註解，以及首創的七個由專家驗證的序數信任等級。我們將我們的問題陳述投射為信任量化的序數分類任務，並提出一個新的基準 TrustBench，其中包含一組 MENTAL-TRUST 上的經典和最先進的語言模型。我們評估了一系列指標的效能，並列出詳盡的發現。我們的研究旨在探討信任如何在治療互動中演變。

##### **Survival Analysis Revisited: Understanding and Unifying Poisson, Exponential, and Cox Models in Fall Risk Analysis**
2501.03058v1 by Tianhua Chen

This paper explores foundational and applied aspects of survival analysis,
using fall risk assessment as a case study. It revisits key time-related
probability distributions and statistical methods, including logistic
regression, Poisson regression, Exponential regression, and the Cox
Proportional Hazards model, offering a unified perspective on their
relationships within the survival analysis framework. A contribution of this
work is the step-by-step derivation and clarification of the relationships
among these models, particularly demonstrating that Poisson regression in the
survival context is a specific case of the Cox model. These insights address
gaps in understanding and reinforce the simplicity and interpretability of
survival models. The paper also emphasizes the practical utility of survival
analysis by connecting theoretical insights with real-world applications. In
the context of fall detection, it demonstrates how these models can
simultaneously predict fall risk, analyze contributing factors, and estimate
time-to-event outcomes within a single streamlined framework. In contrast,
advanced deep learning methods often require complex post-hoc interpretation
and separate training for different tasks particularly when working with
structured numerical data. This highlights the enduring relevance of classical
statistical frameworks and makes survival models especially valuable in
healthcare settings, where explainability and robustness are critical. By
unifying foundational concepts and offering a cohesive perspective on
time-to-event analysis, this work serves as an accessible resource for
understanding survival models and applying them effectively to diverse
analytical challenges.

摘要：本文探討生存分析的基本和應用面向，並以跌倒風險評估作為案例研究。本文回顧了與時間相關的主要機率分佈和統計方法，包括邏輯迴歸、泊松迴歸、指數迴歸和考克斯比例風險模型，並提供了一個統一的觀點，說明它們在生存分析架構中的關係。這項工作的貢獻在於逐步推導和釐清這些模型之間的關係，特別是證明生存背景下的泊松迴歸是考克斯模型的特定情況。這些見解解決了理解上的差距，並強化了生存模型的簡潔性和可解釋性。本文也強調了生存分析的實用性，它將理論見解與真實世界的應用連結起來。在跌倒偵測的背景下，本文示範了這些模型如何同時預測跌倒風險、分析促成因素，並在單一簡化的架構內估計事件發生時間的結果。相比之下，進階深度學習方法通常需要複雜的事後解釋，而且在處理結構化數值資料時，需要針對不同的任務進行個別訓練。這突顯了傳統統計架構的持續相關性，並使生存模型在醫療保健環境中特別有價值，因為在醫療保健環境中，可解釋性和穩健性至關重要。透過統一基本概念，並對事件發生時間分析提供一個有凝聚力的觀點，這項工作作為一個可存取的資源，協助理解生存模型並有效地將它們應用於各種分析挑戰。

##### **Single-Channel Distance-Based Source Separation for Mobile GPU in Outdoor and Indoor Environments**
2501.03045v1 by Hanbin Bae, Byungjun Kang, Jiwon Kim, Jaeyong Hwang, Hosang Sung, Hoon-Young Cho

This study emphasizes the significance of exploring distance-based source
separation (DSS) in outdoor environments. Unlike existing studies that
primarily focus on indoor settings, the proposed model is designed to capture
the unique characteristics of outdoor audio sources. It incorporates advanced
techniques, including a two-stage conformer block, a linear relation-aware
self-attention (RSA), and a TensorFlow Lite GPU delegate. While the linear RSA
may not capture physical cues as explicitly as the quadratic RSA, the linear
RSA enhances the model's context awareness, leading to improved performance on
the DSS that requires an understanding of physical cues in outdoor and indoor
environments. The experimental results demonstrated that the proposed model
overcomes the limitations of existing approaches and considerably enhances
energy efficiency and real-time inference speed on mobile devices.

摘要：本研究強調在戶外環境中探索基於距離的來源分離 (DSS) 的重要性。有別於現有主要專注於室內設定的研究，所提出的模型旨在捕捉戶外音訊來源的獨特特徵。它結合了先進的技術，包括兩階段共形器區塊、線性關係感知自注意力 (RSA) 和 TensorFlow Lite GPU 委派。雖然線性 RSA 可能無法像二次 RSA 那樣明確地捕捉物理線索，但線性 RSA 增強了模型的背景感知，從而提高了對 DSS 的效能，DSS 要求理解戶外和室內環境中的物理線索。實驗結果表明，所提出的模型克服了現有方法的限制，並顯著提高了行動裝置上的能源效率和即時推論速度。

##### **ChronoSense: Exploring Temporal Understanding in Large Language Models with Time Intervals of Events**
2501.03040v1 by Duygu Sezen Islakoglu, Jan-Christoph Kalo

Large Language Models (LLMs) have achieved remarkable success in various NLP
tasks, yet they still face significant challenges in reasoning and arithmetic.
Temporal reasoning, a critical component of natural language understanding, has
raised increasing research attention. However, comprehensive testing of Allen's
interval relations (e.g., before, after, during) -- a fundamental framework for
temporal relationships -- remains underexplored. To fill this gap, we present
ChronoSense, a new benchmark for evaluating LLMs' temporal understanding. It
includes 16 tasks, focusing on identifying the Allen relation between two
temporal events and temporal arithmetic, using both abstract events and
real-world data from Wikidata. We assess the performance of seven recent LLMs
using this benchmark and the results indicate that models handle Allen
relations, even symmetrical ones, quite differently. Moreover, the findings
suggest that the models may rely on memorization to answer time-related
questions. Overall, the models' low performance highlights the need for
improved temporal understanding in LLMs and ChronoSense offers a robust
framework for future research in this area. Our dataset and the source code are
available at https://github.com/duyguislakoglu/chronosense.

摘要：大型語言模型 (LLM) 在各種自然語言處理 (NLP) 任務中取得了顯著的成功，但它們在推理和算術方面仍然面臨著重大的挑戰。
時間推理是自然語言理解的關鍵組成部分，引起了越來越多的研究關注。然而，艾倫的區間關係（例如，之前、之後、期間）的全面測試——時間關係的基本框架——仍然未得到充分探索。為了填補這一空白，我們提出了 ChronoSense，這是一個用於評估 LLM 時間理解的新基準。它包括 16 項任務，重點是識別兩個時間事件之間的艾倫關係和時間算術，同時使用抽象事件和來自 Wikidata 的真實世界數據。我們使用此基準評估了七個最近的 LLM 的性能，結果表明模型處理艾倫關係（甚至是對稱關係）的方式截然不同。此外，研究結果表明，這些模型可能依賴於記憶來回答與時間相關的問題。總的來說，模型的低性能突顯了需要改進 LLM 中的時間理解，而 ChronoSense 為這一領域的未來研究提供了一個穩健的框架。我們的數據集和源代碼可以在 https://github.com/duyguislakoglu/chronosense 獲得。

##### **Piano Transcription by Hierarchical Language Modeling with Pretrained Roll-based Encoders**
2501.03038v2 by Dichucheng Li, Yongyi Zang, Qiuqiang Kong

Automatic Music Transcription (AMT), aiming to get musical notes from raw
audio, typically uses frame-level systems with piano-roll outputs or language
model (LM)-based systems with note-level predictions. However, frame-level
systems require manual thresholding, while the LM-based systems struggle with
long sequences. In this paper, we propose a hybrid method combining pre-trained
roll-based encoders with an LM decoder to leverage the strengths of both
methods. Besides, our approach employs a hierarchical prediction strategy,
first predicting onset and pitch, then velocity, and finally offset. The
hierarchical prediction strategy reduces computational costs by breaking down
long sequences into different hierarchies. Evaluated on two benchmark
roll-based encoders, our method outperforms traditional piano-roll outputs 0.01
and 0.022 in onset-offset-velocity F1 score, demonstrating its potential as a
performance-enhancing plug-in for arbitrary roll-based music transcription
encoder.

摘要：自動音樂轉錄 (AMT) 旨在從原始音訊中取得音符，通常會使用具備鋼琴捲軸輸出的幀級系統或具備音符層級預測的基於語言模型 (LM) 的系統。然而，幀級系統需要手動閾值設定，而基於 LM 的系統則難以處理長序列。在本文中，我們提出了一種混合方法，將預訓練的基於捲軸編碼器與 LM 解碼器結合，以利用這兩種方法的優點。此外，我們的做法採用分層預測策略，首先預測起始和音高，然後預測速度，最後預測偏移。分層預測策略透過將長序列分解為不同的層級來降低運算成本。在兩個基準捲軸編碼器上進行評估，我們的模型在起始-偏移-速度 F1 分數上優於傳統鋼琴捲軸輸出 0.01 和 0.022，證明其作為任意基於捲軸的音樂轉錄編碼器的效能提升外掛程式的潛力。

##### **Quantization Meets Reasoning: Exploring LLM Low-Bit Quantization Degradation for Mathematical Reasoning**
2501.03035v1 by Zhen Li, Yupeng Su, Runming Yang, Zhongwei Xie, Ngai Wong, Hongxia Yang

Large language models have achieved significant advancements in complex
mathematical reasoning benchmarks, such as MATH. However, their substantial
computational requirements present challenges for practical deployment. Model
quantization has emerged as an effective strategy to reduce memory usage and
computational costs by employing lower precision and bit-width representations.
In this study, we systematically evaluate the impact of quantization on
mathematical reasoning tasks. We introduce a multidimensional evaluation
framework that qualitatively assesses specific capability dimensions and
conduct quantitative analyses on the step-by-step outputs of various
quantization methods. Our results demonstrate that quantization differentially
affects numerical computation and reasoning planning abilities, identifying key
areas where quantized models experience performance degradation.

摘要：大型語言模型在複雜數學推理基準中取得顯著進展，例如 MATH。然而，它們大量的運算需求對實際部署提出了挑戰。模型量化已成為一種有效的策略，透過採用較低精度和位寬表示來減少記憶體用量和運算成本。在本研究中，我們系統性地評估量化對數學推理任務的影響。我們引入了一個多維評估框架，定性評估特定的能力維度，並對各種量化方法的逐步輸出進行定量分析。我們的結果表明，量化對數值計算和推理規劃能力有不同的影響，找出量化模型效能下降的主要領域。

##### **Putnam's Critical and Explanatory Tendencies Interpreted from a Machine Learning Perspective**
2501.03026v1 by Sheldon Z. Soudin

Making sense of theory choice in normal and across extraordinary science is
central to philosophy of science. The emergence of machine learning models has
the potential to act as a wrench in the gears of current debates. In this
paper, I will attempt to reconstruct the main movements that lead to and came
out of Putnam's critical and explanatory tendency distinction, argue for the
biconditional necessity of the tendencies, and conceptualize that wrench
through a machine learning interpretation of my claim.

摘要：在正常和非凡科學中，理論選擇的意義是科學哲學的核心。機器學習模型的出現有可能成為當前辯論中的關鍵因素。在本文中，我將嘗試重建導致普特南的批判性和解釋性趨勢區分的關鍵運動，並論證這些趨勢的雙重必要性，並通過機器學習對我的主張的解釋來概念化該關鍵因素。

##### **Analyzing Fine-tuning Representation Shift for Multimodal LLMs Steering alignment**
2501.03012v1 by Pegah Khayatan, Mustafa Shukor, Jayneel Parekh, Matthieu Cord

Multimodal LLMs have reached remarkable levels of proficiency in
understanding multimodal inputs, driving extensive research to develop
increasingly powerful models. However, much less attention has been paid to
understanding and explaining the underlying mechanisms of these models. Most
existing explainability research examines these models only in their final
states, overlooking the dynamic representational shifts that occur during
training. In this work, we systematically analyze the evolution of hidden state
representations to reveal how fine-tuning alters the internal structure of a
model to specialize in new multimodal tasks. Using a concept-based approach, we
map hidden states to interpretable visual and textual concepts, enabling us to
trace changes in encoded concepts across modalities as training progresses. We
also demonstrate the use of shift vectors to capture these concepts changes.
These shift vectors allow us to recover fine-tuned concepts by shifting those
in the original model. Finally, we explore the practical impact of our findings
on model steering, showing that we can adjust multimodal LLMs behaviors without
any training, such as modifying answer types, captions style, or biasing the
model toward specific responses. Our work sheds light on how multimodal
representations evolve through fine-tuning and offers a new perspective for
interpreting model adaptation in multimodal tasks. The code for this project is
publicly available at https://github.com/mshukor/xl-vlms.

摘要：多模态 LLM 已在理解多模态输入方面达到了显着的熟练程度，推动了广泛的研究，以开发功能越来越强大的模型。然而，对理解和解释这些模型的底层机制的关注却少得多。大多数现有的可解释性研究仅在最终状态下检查这些模型，而忽略了在训练期间发生的动态表征转换。在这项工作中，我们系统地分析了隐藏状态表示的演变，以揭示微调如何改变模型的内部结构，以便专门用于新的多模态任务。使用基于概念的方法，我们将隐藏状态映射到可解释的视觉和文本概念，使我们能够追踪训练过程中跨模态编码概念的变化。我们还演示了使用转换向量来捕获这些概念变化。这些转换向量使我们能够通过转换原始模型中的那些概念来恢复微调的概念。最后，我们探讨了我们的发现对模型引导的实际影响，表明我们可以调整多模态 LLM 行为，而无需任何训练，例如修改答案类型、标题样式或使模型偏向特定响应。我们的工作阐明了多模态表示如何通过微调演变，并为解释多模态任务中的模型适应提供了一个新的视角。该项目的代码可在 https://github.com/mshukor/xl-vlms 公开获取。

