{"2412.03841": {"publish_time": "2024-12-05", "title": "LL-ICM: Image Compression for Low-level Machine Vision via Large Vision-Language Model", "paper_summary": "Image Compression for Machines (ICM) aims to compress images for machine\nvision tasks rather than human viewing. Current works predominantly concentrate\non high-level tasks like object detection and semantic segmentation. However,\nthe quality of original images is usually not guaranteed in the real world,\nleading to even worse perceptual quality or downstream task performance after\ncompression. Low-level (LL) machine vision models, like image restoration\nmodels, can help improve such quality, and thereby their compression\nrequirements should also be considered. In this paper, we propose a pioneered\nICM framework for LL machine vision tasks, namely LL-ICM. By jointly optimizing\ncompression and LL tasks, the proposed LL-ICM not only enriches its encoding\nability in generalizing to versatile LL tasks but also optimizes the processing\nability of down-stream LL task models, achieving mutual adaptation for image\ncodecs and LL task models. Furthermore, we integrate large-scale\nvision-language models into the LL-ICM framework to generate more universal and\ndistortion-robust feature embeddings for LL vision tasks. Therefore, one LL-ICM\ncodec can generalize to multiple tasks. We establish a solid benchmark to\nevaluate LL-ICM, which includes extensive objective experiments by using both\nfull and no-reference image quality assessments. Experimental results show that\nLL-ICM can achieve 22.65% BD-rate reductions over the state-of-the-art methods.", "paper_summary_zh": "\u6a5f\u5668\u5f71\u50cf\u58d3\u7e2e (ICM) \u65e8\u5728\u58d3\u7e2e\u5f71\u50cf\u4ee5\u9032\u884c\u6a5f\u5668\u8996\u89ba\u4efb\u52d9\uff0c\u800c\u975e\u4eba\u985e\u89c0\u770b\u3002\u76ee\u524d\u7684\u8457\u4f5c\u4e3b\u8981\u96c6\u4e2d\u65bc\u9ad8\u968e\u4efb\u52d9\uff0c\u4f8b\u5982\u7269\u9ad4\u5075\u6e2c\u8207\u8a9e\u610f\u5206\u5272\u3002\u7136\u800c\uff0c\u5728\u771f\u5be6\u4e16\u754c\u4e2d\uff0c\u539f\u59cb\u5f71\u50cf\u7684\u54c1\u8cea\u901a\u5e38\u7121\u6cd5\u4fdd\u8b49\uff0c\u5c0e\u81f4\u58d3\u7e2e\u5f8c\u7522\u751f\u66f4\u5dee\u7684\u611f\u77e5\u54c1\u8cea\u6216\u4e0b\u6e38\u4efb\u52d9\u6548\u80fd\u3002\u4f4e\u968e (LL) \u6a5f\u5668\u8996\u89ba\u6a21\u578b\uff0c\u4f8b\u5982\u5f71\u50cf\u4fee\u5fa9\u6a21\u578b\uff0c\u6709\u52a9\u65bc\u63d0\u5347\u54c1\u8cea\uff0c\u56e0\u6b64\u4e5f\u61c9\u8003\u91cf\u5176\u58d3\u7e2e\u9700\u6c42\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u91dd\u5c0d LL \u6a5f\u5668\u8996\u89ba\u4efb\u52d9\u7684\u5148\u9a45 ICM \u67b6\u69cb\uff0c\u5373 LL-ICM\u3002\u900f\u904e\u806f\u5408\u6700\u4f73\u5316\u58d3\u7e2e\u8207 LL \u4efb\u52d9\uff0c\u6240\u63d0\u51fa\u7684 LL-ICM \u4e0d\u50c5\u8c50\u5bcc\u5176\u7de8\u78bc\u80fd\u529b\u4ee5\u6982\u5316\u5230\u591a\u6a23\u7684 LL \u4efb\u52d9\uff0c\u540c\u6642\u4e5f\u6700\u4f73\u5316\u4e0b\u6e38 LL \u4efb\u52d9\u6a21\u578b\u7684\u8655\u7406\u80fd\u529b\uff0c\u9054\u6210\u5f71\u50cf\u7de8\u89e3\u78bc\u5668\u8207 LL \u4efb\u52d9\u6a21\u578b\u7684\u76f8\u4e92\u9069\u61c9\u3002\u6b64\u5916\uff0c\u6211\u5011\u5c07\u5927\u898f\u6a21\u8996\u89ba\u8a9e\u8a00\u6a21\u578b\u6574\u5408\u5230 LL-ICM \u67b6\u69cb\u4e2d\uff0c\u4ee5\u7522\u751f\u66f4\u901a\u7528\u7684\u4e14\u6297\u5931\u771f\u7684\u7279\u5fb5\u5d4c\u5165\uff0c\u9069\u7528\u65bc LL \u8996\u89ba\u4efb\u52d9\u3002\u56e0\u6b64\uff0c\u4e00\u500b LL-ICM \u7de8\u89e3\u78bc\u5668\u53ef\u4ee5\u6982\u5316\u5230\u591a\u9805\u4efb\u52d9\u3002\u6211\u5011\u5efa\u7acb\u4e00\u500b\u7a69\u56fa\u7684\u57fa\u6e96\u4f86\u8a55\u4f30 LL-ICM\uff0c\u5176\u4e2d\u5305\u542b\u5ee3\u6cdb\u7684\u5ba2\u89c0\u5be6\u9a57\uff0c\u540c\u6642\u4f7f\u7528\u5b8c\u6574\u548c\u7121\u53c3\u8003\u5f71\u50cf\u54c1\u8cea\u8a55\u4f30\u3002\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0c\u8207\u76ee\u524d\u6700\u5148\u9032\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0cLL-ICM \u53ef\u6e1b\u5c11 22.65% \u7684 BD \u901f\u7387\u3002", "author": "Yuan Xue et.al.", "authors": "Yuan Xue, Qi Zhang, Chuanmin Jia, Shiqi Wang", "id": "2412.03841v1", "paper_url": "http://arxiv.org/abs/2412.03841v1", "repo": "null"}}