{"2412.17242": {"publish_time": "2024-12-23", "title": "On the Generalization Ability of Machine-Generated Text Detectors", "paper_summary": "The rise of large language models (LLMs) has raised concerns about\nmachine-generated text (MGT), including ethical and practical issues like\nplagiarism and misinformation. Building a robust and highly generalizable MGT\ndetection system has become increasingly important. This work investigates the\ngeneralization capabilities of MGT detectors in three aspects: First, we\nconstruct MGTAcademic, a large-scale dataset focused on academic writing,\nfeaturing human-written texts (HWTs) and MGTs across STEM, Humanities, and\nSocial Sciences, paired with an extensible code framework for efficient\nbenchmarking. Second, we investigate the transferability of detectors across\ndomains and LLMs, leveraging fine-grained datasets to reveal insights into\ndomain transferring and implementing few-shot techniques to improve the\nperformance by roughly 13.2%. Third, we introduce a novel attribution task\nwhere models must adapt to new classes over time without (or with very limited)\naccess to prior training data and benchmark detectors. We implement several\nadapting techniques to improve the performance by roughly 10% and highlight the\ninherent complexity of the task. Our findings provide insights into the\ngeneralization ability of MGT detectors across diverse scenarios and lay the\nfoundation for building robust, adaptive detection systems.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u8208\u8d77\u5f15\u767c\u4e86\u5c0d\u6a5f\u5668\u7522\u751f\u7684\u6587\u672c (MGT) \u7684\u64d4\u6182\uff0c\u5305\u62ec\u6284\u8972\u548c\u932f\u8aa4\u8cc7\u8a0a\u7b49\u9053\u5fb7\u548c\u5be6\u52d9\u554f\u984c\u3002\u5efa\u69cb\u4e00\u500b\u5f37\u5065\u4e14\u9ad8\u5ea6\u53ef\u6982\u62ec\u7684 MGT \u5075\u6e2c\u7cfb\u7d71\u8b8a\u5f97\u8d8a\u4f86\u8d8a\u91cd\u8981\u3002\u9019\u9805\u7814\u7a76\u5f9e\u4e09\u500b\u65b9\u9762\u63a2\u8a0e MGT \u5075\u6e2c\u5668\u7684\u6982\u62ec\u80fd\u529b\uff1a\u9996\u5148\uff0c\u6211\u5011\u5efa\u69cb\u4e86 MGTAcademic\uff0c\u4e00\u500b\u5c08\u6ce8\u65bc\u5b78\u8853\u5beb\u4f5c\u7684\u5927\u898f\u6a21\u8cc7\u6599\u96c6\uff0c\u5176\u4e2d\u5305\u542b STEM\u3001\u4eba\u6587\u5b78\u79d1\u548c\u793e\u6703\u79d1\u5b78\u9818\u57df\u7684\u4eba\u985e\u64b0\u5beb\u6587\u672c (HWT) \u548c MGT\uff0c\u4e26\u914d\u5099\u53ef\u5ef6\u4f38\u7684\u7a0b\u5f0f\u78bc\u67b6\u69cb\u4ee5\u9032\u884c\u6709\u6548\u57fa\u6e96\u6e2c\u8a66\u3002\u5176\u6b21\uff0c\u6211\u5011\u63a2\u8a0e\u5075\u6e2c\u5668\u5728\u4e0d\u540c\u9818\u57df\u548c LLM \u4e4b\u9593\u7684\u53ef\u8f49\u79fb\u6027\uff0c\u5229\u7528\u7d30\u7c92\u5ea6\u7684\u8cc7\u6599\u96c6\u63ed\u9732\u9818\u57df\u8f49\u79fb\u7684\u898b\u89e3\uff0c\u4e26\u5be6\u4f5c\u5c11\u91cf\u6a23\u672c\u6280\u8853\uff0c\u5c07\u6548\u80fd\u63d0\u5347\u7d04 13.2%\u3002\u7b2c\u4e09\uff0c\u6211\u5011\u5f15\u5165\u4e00\u9805\u65b0\u7a4e\u7684\u6b78\u56e0\u4efb\u52d9\uff0c\u5176\u4e2d\u6a21\u578b\u5fc5\u9808\u96a8\u8457\u6642\u9593\u9069\u61c9\u65b0\u985e\u5225\uff0c\u800c\u4e0d\u6703\uff08\u6216\u50c5\u80fd\u975e\u5e38\u6709\u9650\u5730\uff09\u5b58\u53d6\u5148\u524d\u7684\u8a13\u7df4\u8cc7\u6599\u548c\u57fa\u6e96\u5075\u6e2c\u5668\u3002\u6211\u5011\u5be6\u4f5c\u4e86\u591a\u7a2e\u9069\u61c9\u6280\u8853\uff0c\u5c07\u6548\u80fd\u63d0\u5347\u7d04 10%\uff0c\u4e26\u5f37\u8abf\u4e86\u9019\u9805\u4efb\u52d9\u7684\u5167\u5728\u8907\u96dc\u6027\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u63d0\u4f9b\u4e86\u5c0d MGT \u5075\u6e2c\u5668\u5728\u4e0d\u540c\u5834\u666f\u4e2d\u7684\u6982\u62ec\u80fd\u529b\u7684\u898b\u89e3\uff0c\u4e26\u70ba\u5efa\u69cb\u5f37\u5065\u7684\u9069\u61c9\u6027\u5075\u6e2c\u7cfb\u7d71\u5960\u5b9a\u4e86\u57fa\u790e\u3002", "author": "Yule Liu et.al.", "authors": "Yule Liu, Zhiyuan Zhong, Yifan Liao, Zhen Sun, Jingyi Zheng, Jiaheng Wei, Qingyuan Gong, Fenghua Tong, Yang Chen, Yang Zhang, Xinlei He", "id": "2412.17242v1", "paper_url": "http://arxiv.org/abs/2412.17242v1", "repo": "https://github.com/Y-L-LIU/MGTBench-2.0"}}