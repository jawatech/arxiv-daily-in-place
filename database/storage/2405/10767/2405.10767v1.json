{"2405.10767": {"publish_time": "2024-05-17", "title": "Evaluating Saliency Explanations in NLP by Crowdsourcing", "paper_summary": "Deep learning models have performed well on many NLP tasks. However, their\ninternal mechanisms are typically difficult for humans to understand. The\ndevelopment of methods to explain models has become a key issue in the\nreliability of deep learning models in many important applications. Various\nsaliency explanation methods, which give each feature of input a score\nproportional to the contribution of output, have been proposed to determine the\npart of the input which a model values most. Despite a considerable body of\nwork on the evaluation of saliency methods, whether the results of various\nevaluation metrics agree with human cognition remains an open question. In this\nstudy, we propose a new human-based method to evaluate saliency methods in NLP\nby crowdsourcing. We recruited 800 crowd workers and empirically evaluated\nseven saliency methods on two datasets with the proposed method. We analyzed\nthe performance of saliency methods, compared our results with existing\nautomated evaluation methods, and identified notable differences between NLP\nand computer vision (CV) fields when using saliency methods. The instance-level\ndata of our crowdsourced experiments and the code to reproduce the explanations\nare available at https://github.com/xtlu/lreccoling_evaluation.", "paper_summary_zh": "\u6df1\u5ea6\u5b78\u7fd2\u6a21\u578b\u5728\u8a31\u591a NLP \u4efb\u52d9\u4e0a\u8868\u73fe\u826f\u597d\u3002\u7136\u800c\uff0c\u4eba\u985e\u901a\u5e38\u96e3\u4ee5\u7406\u89e3\u5176\u5167\u90e8\u6a5f\u5236\u3002\u5728\u8a31\u591a\u91cd\u8981\u61c9\u7528\u4e2d\uff0c\u958b\u767c\u89e3\u91cb\u6a21\u578b\u7684\u65b9\u6cd5\u5df2\u6210\u70ba\u6df1\u5ea6\u5b78\u7fd2\u6a21\u578b\u53ef\u9760\u6027\u7684\u95dc\u9375\u554f\u984c\u3002\u5df2\u7d93\u63d0\u51fa\u5404\u7a2e\u986f\u8457\u6027\u89e3\u91cb\u65b9\u6cd5\uff0c\u9019\u4e9b\u65b9\u6cd5\u70ba\u8f38\u5165\u7684\u6bcf\u500b\u7279\u5fb5\u8ce6\u4e88\u4e00\u500b\u8207\u8f38\u51fa\u8ca2\u737b\u6210\u6b63\u6bd4\u7684\u5206\u6578\uff0c\u4ee5\u78ba\u5b9a\u6a21\u578b\u6700\u91cd\u8996\u8f38\u5165\u7684\u54ea\u4e00\u90e8\u5206\u3002\u5118\u7ba1\u5728\u986f\u8457\u6027\u65b9\u6cd5\u7684\u8a55\u4f30\u65b9\u9762\u6709\u5927\u91cf\u7684\u5de5\u4f5c\uff0c\u4f46\u5404\u7a2e\u8a55\u4f30\u6307\u6a19\u7684\u7d50\u679c\u662f\u5426\u8207\u4eba\u985e\u8a8d\u77e5\u4e00\u81f4\u4ecd\u7136\u662f\u4e00\u500b\u958b\u653e\u7684\u554f\u984c\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u57fa\u65bc\u4eba\u985e\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u904e\u773e\u5305\u4f86\u8a55\u4f30 NLP \u4e2d\u7684\u986f\u8457\u6027\u65b9\u6cd5\u3002\u6211\u5011\u62db\u52df\u4e86 800 \u540d\u7fa4\u773e\u5de5\u4f5c\u8005\uff0c\u4e26\u4f7f\u7528\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5169\u500b\u6578\u64da\u96c6\u4e0a\u5c0d\u4e03\u7a2e\u986f\u8457\u6027\u65b9\u6cd5\u9032\u884c\u4e86\u7d93\u9a57\u8a55\u4f30\u3002\u6211\u5011\u5206\u6790\u4e86\u986f\u8457\u6027\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u5c07\u6211\u5011\u7684\u7d50\u679c\u8207\u73fe\u6709\u7684\u81ea\u52d5\u8a55\u4f30\u65b9\u6cd5\u9032\u884c\u4e86\u6bd4\u8f03\uff0c\u4e26\u5728\u4f7f\u7528\u986f\u8457\u6027\u65b9\u6cd5\u6642\u767c\u73fe\u4e86 NLP \u548c\u8a08\u7b97\u6a5f\u8996\u89ba (CV) \u9818\u57df\u4e4b\u9593\u7684\u986f\u8457\u5dee\u7570\u3002\u6211\u5011\u773e\u5305\u5be6\u9a57\u7684\u5be6\u4f8b\u7d1a\u5225\u6578\u64da\u548c\u91cd\u73fe\u89e3\u91cb\u7684\u4ee3\u78bc\u53ef\u5728 https://github.com/xtlu/lreccoling_evaluation \u4e2d\u7372\u5f97\u3002", "author": "Xiaotian Lu et.al.", "authors": "Xiaotian Lu, Jiyi Li, Zhen Wan, Xiaofeng Lin, Koh Takeuchi, Hisashi Kashima", "id": "2405.10767v1", "paper_url": "http://arxiv.org/abs/2405.10767v1", "repo": "https://github.com/xtlu/lreccoling_evaluation"}}