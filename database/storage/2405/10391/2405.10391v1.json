{"2405.10391": {"publish_time": "2024-05-16", "title": "Vision Transformers for End-to-End Vision-Based Quadrotor Obstacle Avoidance", "paper_summary": "We demonstrate the capabilities of an attention-based end-to-end approach for\nhigh-speed quadrotor obstacle avoidance in dense, cluttered environments, with\ncomparison to various state-of-the-art architectures. Quadrotor unmanned aerial\nvehicles (UAVs) have tremendous maneuverability when flown fast; however, as\nflight speed increases, traditional vision-based navigation via independent\nmapping, planning, and control modules breaks down due to increased sensor\nnoise, compounding errors, and increased processing latency. Thus,\nlearning-based, end-to-end planning and control networks have shown to be\neffective for online control of these fast robots through cluttered\nenvironments. We train and compare convolutional, U-Net, and recurrent\narchitectures against vision transformer models for depth-based end-to-end\ncontrol, in a photorealistic, high-physics-fidelity simulator as well as in\nhardware, and observe that the attention-based models are more effective as\nquadrotor speeds increase, while recurrent models with many layers provide\nsmoother commands at lower speeds. To the best of our knowledge, this is the\nfirst work to utilize vision transformers for end-to-end vision-based quadrotor\ncontrol.", "paper_summary_zh": "\u6211\u5011\u5c55\u793a\u4e86\u57fa\u65bc\u6ce8\u610f\u529b\u7684\u7aef\u5c0d\u7aef\u65b9\u6cd5\u5728\u5bc6\u96c6\u3001\u6df7\u4e82\u74b0\u5883\u4e2d\u9ad8\u901f\u56db\u65cb\u7ffc\u969c\u7919\u7269\u907f\u969c\u7684\u80fd\u529b\uff0c\u4e26\u8207\u5404\u7a2e\u6700\u5148\u9032\u7684\u67b6\u69cb\u9032\u884c\u4e86\u6bd4\u8f03\u3002\u56db\u65cb\u7ffc\u7121\u4eba\u6a5f (UAV) \u5728\u5feb\u901f\u98db\u884c\u6642\u5177\u6709\u6975\u5927\u7684\u6a5f\u52d5\u6027\uff1b\u7136\u800c\uff0c\u96a8\u8457\u98db\u884c\u901f\u5ea6\u7684\u589e\u52a0\uff0c\u7531\u65bc\u50b3\u611f\u5668\u566a\u8072\u589e\u52a0\u3001\u8aa4\u5dee\u7d2f\u7a4d\u548c\u8655\u7406\u5ef6\u9072\u589e\u52a0\uff0c\u57fa\u65bc\u50b3\u7d71\u8996\u89ba\u7684\u5c0e\u822a\u901a\u904e\u7368\u7acb\u7684\u6620\u5c04\u3001\u898f\u5283\u548c\u63a7\u5236\u6a21\u584a\u6703\u5d29\u6f70\u3002\u56e0\u6b64\uff0c\u57fa\u65bc\u5b78\u7fd2\u7684\u7aef\u5230\u7aef\u898f\u5283\u548c\u63a7\u5236\u7db2\u8def\u5df2\u88ab\u8b49\u660e\u53ef\u4ee5\u6709\u6548\u5730\u5c0d\u9019\u4e9b\u5feb\u901f\u6a5f\u5668\u4eba\u5728\u6df7\u4e82\u7684\u74b0\u5883\u4e2d\u9032\u884c\u7dda\u4e0a\u63a7\u5236\u3002\u6211\u5011\u91dd\u5c0d\u6df1\u5ea6\u7aef\u5230\u7aef\u63a7\u5236\u8a13\u7df4\u4e26\u6bd4\u8f03\u4e86\u5377\u7a4d\u3001U-Net \u548c\u905e\u8ff4\u67b6\u69cb\u8207\u8996\u89baTransformer\u6a21\u578b\uff0c\u5728\u903c\u771f\u7684\u9ad8\u7269\u7406\u4fdd\u771f\u5ea6\u6a21\u64ec\u5668\u548c\u786c\u9ad4\u4e2d\uff0c\u4e26\u89c0\u5bdf\u5230\u57fa\u65bc\u6ce8\u610f\u529b\u7684\u6a21\u578b\u5728\u56db\u65cb\u7ffc\u901f\u5ea6\u589e\u52a0\u6642\u66f4\u6709\u6548\uff0c\u800c\u5177\u6709\u591a\u5c64\u7684\u905e\u8ff4\u6a21\u578b\u5728\u8f03\u4f4e\u901f\u5ea6\u4e0b\u63d0\u4f9b\u66f4\u5e73\u6ed1\u7684\u6307\u4ee4\u3002\u64da\u6211\u5011\u6240\u77e5\uff0c\u9019\u662f\u7b2c\u4e00\u500b\u5229\u7528\u8996\u89baTransformer\u9032\u884c\u7aef\u5230\u7aef\u57fa\u65bc\u8996\u89ba\u7684\u56db\u65cb\u7ffc\u63a7\u5236\u7684\u5de5\u4f5c\u3002", "author": "Anish Bhattacharya et.al.", "authors": "Anish Bhattacharya, Nishanth Rao, Dhruv Parikh, Pratik Kunapuli, Nikolai Matni, Vijay Kumar", "id": "2405.10391v1", "paper_url": "http://arxiv.org/abs/2405.10391v1", "repo": "null"}}