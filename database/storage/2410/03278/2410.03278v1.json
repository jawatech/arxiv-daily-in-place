{"2410.03278": {"publish_time": "2024-10-04", "title": "What do Large Language Models Need for Machine Translation Evaluation?", "paper_summary": "Leveraging large language models (LLMs) for various natural language\nprocessing tasks has led to superlative claims about their performance. For the\nevaluation of machine translation (MT), existing research shows that LLMs are\nable to achieve results comparable to fine-tuned multilingual pre-trained\nlanguage models. In this paper, we explore what translation information, such\nas the source, reference, translation errors and annotation guidelines, is\nneeded for LLMs to evaluate MT quality. In addition, we investigate prompting\ntechniques such as zero-shot, Chain of Thought (CoT) and few-shot prompting for\neight language pairs covering high-, medium- and low-resource languages,\nleveraging varying LLM variants. Our findings indicate the importance of\nreference translations for an LLM-based evaluation. While larger models do not\nnecessarily fare better, they tend to benefit more from CoT prompting, than\nsmaller models. We also observe that LLMs do not always provide a numerical\nscore when generating evaluations, which poses a question on their reliability\nfor the task. Our work presents a comprehensive analysis for\nresource-constrained and training-less LLM-based evaluation of machine\ntranslation. We release the accrued prompt templates, code and data publicly\nfor reproducibility.", "paper_summary_zh": "<paragraph>\u5229\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u57f7\u884c\u5404\u7a2e\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4efb\u52d9\uff0c\u5c0d\u5176\u6548\u80fd\u5df2\u7522\u751f\u6975\u4f73\u7684\u8a55\u50f9\u3002\u91dd\u5c0d\u6a5f\u5668\u7ffb\u8b6f (MT) \u7684\u8a55\u4f30\uff0c\u73fe\u6709\u7814\u7a76\u986f\u793a\uff0cLLM \u80fd\u5920\u9054\u6210\u8207\u5fae\u8abf\u591a\u8a9e\u8a00\u9810\u8a13\u7df4\u8a9e\u8a00\u6a21\u578b\u76f8\u7576\u7684\u7d50\u679c\u3002\u5728\u9019\u7bc7\u8ad6\u6587\u4e2d\uff0c\u6211\u5011\u63a2\u8a0e LLM \u8a55\u4f30 MT \u54c1\u8cea\u6240\u9700\u7684\u7ffb\u8b6f\u8cc7\u8a0a\uff0c\u4f8b\u5982\u4f86\u6e90\u3001\u53c3\u8003\u3001\u7ffb\u8b6f\u932f\u8aa4\u548c\u8a3b\u89e3\u6307\u5357\u3002\u6b64\u5916\uff0c\u6211\u5011\u7814\u7a76\u63d0\u793a\u6280\u8853\uff0c\u4f8b\u5982\u96f6\u6b21\u5b78\u7fd2\u3001\u601d\u8003\u93c8 (CoT) \u548c\u5c11\u6b21\u5b78\u7fd2\u63d0\u793a\uff0c\u6db5\u84cb\u9ad8\u3001\u4e2d\u548c\u4f4e\u8cc7\u6e90\u8a9e\u8a00\u7684\u516b\u7a2e\u8a9e\u8a00\u5c0d\uff0c\u4e26\u5229\u7528\u5404\u7a2e LLM \u8b8a\u9ad4\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u986f\u793a\u53c3\u8003\u7ffb\u8b6f\u5c0d\u57fa\u65bc LLM \u7684\u8a55\u4f30\u975e\u5e38\u91cd\u8981\u3002\u96d6\u7136\u8f03\u5927\u7684\u6a21\u578b\u4e0d\u898b\u5f97\u8868\u73fe\u8f03\u597d\uff0c\u4f46\u5b83\u5011\u5f80\u5f80\u6bd4\u8f03\u5c0f\u7684\u6a21\u578b\u66f4\u80fd\u53d7\u76ca\u65bc CoT \u63d0\u793a\u3002\u6211\u5011\u4e5f\u89c0\u5bdf\u5230\uff0cLLM \u5728\u7522\u751f\u8a55\u4f30\u6642\u4e26\u4e0d\u7e3d\u662f\u63d0\u4f9b\u6578\u5b57\u5206\u6578\uff0c\u9019\u5c0d\u5176\u4efb\u52d9\u53ef\u9760\u6027\u63d0\u51fa\u4e86\u7591\u554f\u3002\u6211\u5011\u7684\u7814\u7a76\u91dd\u5c0d\u8cc7\u6e90\u53d7\u9650\u548c\u7121\u9700\u8a13\u7df4\u7684\u57fa\u65bc LLM \u7684\u6a5f\u5668\u7ffb\u8b6f\u8a55\u4f30\uff0c\u63d0\u51fa\u5168\u9762\u7684\u5206\u6790\u3002\u6211\u5011\u516c\u958b\u767c\u5e03\u7d2f\u7a4d\u7684\u63d0\u793a\u7bc4\u672c\u3001\u7a0b\u5f0f\u78bc\u548c\u8cc7\u6599\uff0c\u4ee5\u5229\u91cd\u73fe\u3002</paragraph>", "author": "Shenbin Qian et.al.", "authors": "Shenbin Qian, Archchana Sindhujan, Minnie Kabra, Diptesh Kanojia, Constantin Or\u0103san, Tharindu Ranasinghe, Fr\u00e9d\u00e9ric Blain", "id": "2410.03278v1", "paper_url": "http://arxiv.org/abs/2410.03278v1", "repo": "null"}}