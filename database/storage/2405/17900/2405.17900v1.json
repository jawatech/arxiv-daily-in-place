{"2405.17900": {"publish_time": "2024-05-28", "title": "Enhancing Emotion Recognition in Conversation through Emotional Cross-Modal Fusion and Inter-class Contrastive Learning", "paper_summary": "The purpose of emotion recognition in conversation (ERC) is to identify the\nemotion category of an utterance based on contextual information. Previous ERC\nmethods relied on simple connections for cross-modal fusion and ignored the\ninformation differences between modalities, resulting in the model being unable\nto focus on modality-specific emotional information. At the same time, the\nshared information between modalities was not processed to generate emotions.\nInformation redundancy problem. To overcome these limitations, we propose a\ncross-modal fusion emotion prediction network based on vector connections. The\nnetwork mainly includes two stages: the multi-modal feature fusion stage based\non connection vectors and the emotion classification stage based on fused\nfeatures. Furthermore, we design a supervised inter-class contrastive learning\nmodule based on emotion labels. Experimental results confirm the effectiveness\nof the proposed method, demonstrating excellent performance on the IEMOCAP and\nMELD datasets.", "paper_summary_zh": "\u5c0d\u8a71\u4e2d\u60c5\u7dd2\u8fa8\u8b58\uff08ERC\uff09\u7684\u76ee\u7684\u662f\u6839\u64da\u8108\u7d61\u8cc7\u8a0a\u8fa8\u8b58\u767c\u8a71\u7684\u60c5\u7dd2\u985e\u5225\u3002\u5148\u524d ERC \u65b9\u6cd5\u4ef0\u8cf4\u7c21\u55ae\u7684\u9023\u7d50\u9032\u884c\u8de8\u6a21\u614b\u878d\u5408\uff0c\u4e14\u5ffd\u7565\u4e86\u6a21\u614b\u4e4b\u9593\u8cc7\u8a0a\u7684\u5dee\u7570\uff0c\u5c0e\u81f4\u6a21\u578b\u7121\u6cd5\u5c08\u6ce8\u65bc\u6a21\u614b\u7279\u5b9a\u7684\u60c5\u7dd2\u8cc7\u8a0a\u3002\u540c\u6642\uff0c\u6a21\u614b\u4e4b\u9593\u7684\u5171\u7528\u8cc7\u8a0a\u4e26\u672a\u7d93\u904e\u8655\u7406\u4ee5\u7522\u751f\u60c5\u7dd2\uff0c\u9020\u6210\u8cc7\u8a0a\u5197\u9918\u554f\u984c\u3002\u70ba\u4e86\u514b\u670d\u9019\u4e9b\u9650\u5236\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u57fa\u65bc\u5411\u91cf\u9023\u7d50\u7684\u8de8\u6a21\u614b\u878d\u5408\u60c5\u7dd2\u9810\u6e2c\u7db2\u8def\u3002\u8a72\u7db2\u8def\u4e3b\u8981\u5305\u542b\u5169\u500b\u968e\u6bb5\uff1a\u57fa\u65bc\u9023\u7d50\u5411\u91cf\u7684\u591a\u6a21\u614b\u7279\u5fb5\u878d\u5408\u968e\u6bb5\uff0c\u4ee5\u53ca\u57fa\u65bc\u878d\u5408\u7279\u5fb5\u7684\u60c5\u7dd2\u5206\u985e\u968e\u6bb5\u3002\u6b64\u5916\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u57fa\u65bc\u60c5\u7dd2\u6a19\u7c64\u7684\u76e3\u7763\u5f0f\u985e\u9593\u5c0d\u6bd4\u5b78\u7fd2\u6a21\u7d44\u3002\u5be6\u9a57\u7d50\u679c\u8b49\u5be6\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5728 IEMOCAP \u548c MELD \u8cc7\u6599\u96c6\u4e0a\u5c55\u73fe\u51fa\u512a\u7570\u7684\u6548\u80fd\u3002", "author": "Haoxiang Shi et.al.", "authors": "Haoxiang Shi, Xulong Zhang, Ning Cheng, Yong Zhang, Jun Yu, Jing Xiao, Jianzong Wang", "id": "2405.17900v1", "paper_url": "http://arxiv.org/abs/2405.17900v1", "repo": "null"}}