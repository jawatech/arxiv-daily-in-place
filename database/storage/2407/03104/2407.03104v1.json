{"2407.03104": {"publish_time": "2024-07-03", "title": "KeyVideoLLM: Towards Large-scale Video Keyframe Selection", "paper_summary": "Recently, with the rise of web videos, managing and understanding large-scale\nvideo datasets has become increasingly important. Video Large Language Models\n(VideoLLMs) have emerged in recent years due to their strong video\nunderstanding capabilities. However, training and inference processes for\nVideoLLMs demand vast amounts of data, presenting significant challenges to\ndata management, particularly regarding efficiency, robustness, and\neffectiveness. In this work, we present KeyVideoLLM, a text-video frame\nsimilarity-based keyframe selection method designed to manage VideoLLM data\nefficiently, robustly, and effectively. Specifically, KeyVideoLLM achieves a\nremarkable data compression rate of up to 60.9 times, substantially lowering\ndisk space requirements, which proves its high efficiency. Additionally, it\nmaintains a 100% selection success rate across all video formats and scales,\nenhances processing speed by up to 200 times compared to existing keyframe\nselection methods, and does not require hyperparameter tuning. Beyond its\noutstanding efficiency and robustness, KeyVideoLLM further improves model\nperformance in video question-answering tasks during both training and\ninference stages. Notably, it consistently achieved the state-of-the-art (SoTA)\nexperimental results on diverse datasets.", "paper_summary_zh": "<paragraph>\u6700\u8fd1\uff0c\u968f\u7740\u7f51\u7edc\u89c6\u9891\u7684\u5174\u8d77\uff0c\u7ba1\u7406\u548c\u7406\u89e3\u5927\u89c4\u6a21\u89c6\u9891\u6570\u636e\u96c6\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002\u89c6\u9891\u5927\u8bed\u8a00\u6a21\u578b (VideoLLM) \u8fd1\u5e74\u6765\u56e0\u5176\u5f3a\u5927\u7684\u89c6\u9891\u7406\u89e3\u80fd\u529b\u800c\u5174\u8d77\u3002\u7136\u800c\uff0cVideoLLM \u7684\u8bad\u7ec3\u548c\u63a8\u7406\u8fc7\u7a0b\u9700\u8981\u5927\u91cf\u6570\u636e\uff0c\u5bf9\u6570\u636e\u7ba1\u7406\u63d0\u51fa\u4e86\u91cd\u5927\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u6548\u7387\u3001\u9c81\u68d2\u6027\u548c\u6709\u6548\u6027\u65b9\u9762\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 KeyVideoLLM\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u6587\u672c-\u89c6\u9891\u5e27\u76f8\u4f3c\u6027\u7684\u5173\u952e\u5e27\u9009\u62e9\u65b9\u6cd5\uff0c\u65e8\u5728\u9ad8\u6548\u3001\u9c81\u68d2\u4e14\u6709\u6548\u5730\u7ba1\u7406 VideoLLM \u6570\u636e\u3002\u5177\u4f53\u6765\u8bf4\uff0cKeyVideoLLM \u5b9e\u73b0\u4e86\u9ad8\u8fbe 60.9 \u500d\u7684\u663e\u7740\u6570\u636e\u538b\u7f29\u7387\uff0c\u5927\u5e45\u964d\u4f4e\u4e86\u78c1\u76d8\u7a7a\u95f4\u9700\u6c42\uff0c\u8fd9\u8bc1\u660e\u4e86\u5176\u9ad8\u6548\u7387\u3002\u6b64\u5916\uff0c\u5b83\u5728\u6240\u6709\u89c6\u9891\u683c\u5f0f\u548c\u89c4\u6a21\u4e0a\u4fdd\u6301 100% \u7684\u9009\u62e9\u6210\u529f\u7387\uff0c\u4e0e\u73b0\u6709\u7684\u5173\u952e\u5e27\u9009\u62e9\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5904\u7406\u901f\u5ea6\u63d0\u9ad8\u4e86 200 \u500d\uff0c\u5e76\u4e14\u4e0d\u9700\u8981\u8d85\u53c2\u6570\u8c03\u6574\u3002\u9664\u4e86\u51fa\u8272\u7684\u6548\u7387\u548c\u9c81\u68d2\u6027\u4e4b\u5916\uff0cKeyVideoLLM \u8fd8\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u6a21\u578b\u5728\u89c6\u9891\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5b83\u5728\u4e0d\u540c\u7684\u6570\u636e\u96c6\u4e0a\u6301\u7eed\u53d6\u5f97\u4e86\u6700\u5148\u8fdb (SoTA) \u7684\u5b9e\u9a8c\u7ed3\u679c\u3002</paragraph>", "author": "Hao Liang et.al.", "authors": "Hao Liang, Jiapeng Li, Tianyi Bai, Chong Chen, Conghui He, Bin Cui, Wentao Zhang", "id": "2407.03104v1", "paper_url": "http://arxiv.org/abs/2407.03104v1", "repo": "null"}}