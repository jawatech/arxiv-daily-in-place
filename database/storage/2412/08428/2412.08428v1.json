{"2412.08428": {"publish_time": "2024-12-11", "title": "SwarmGPT-Primitive: A Language-Driven Choreographer for Drone Swarms Using Safe Motion Primitive Composition", "paper_summary": "Catalyzed by advancements in hardware and software, drone performances are\nincreasingly making their mark in the entertainment industry. However,\ndesigning smooth and safe choreographies for drone swarms is complex and often\nrequires expert domain knowledge. In this work, we introduce\nSwarmGPT-Primitive, a language-based choreographer that integrates the\nreasoning capabilities of large language models (LLMs) with safe motion\nplanning to facilitate deployable drone swarm choreographies. The LLM composes\nchoreographies for a given piece of music by utilizing a library of motion\nprimitives; the language-based choreographer is augmented with an\noptimization-based safety filter, which certifies the choreography for\nreal-world deployment by making minimal adjustments when feasibility and safety\nconstraints are violated. The overall SwarmGPT-Primitive framework decouples\nchoreographic design from safe motion planning, which allows non-expert users\nto re-prompt and refine compositions without concerns about compliance with\nconstraints such as avoiding collisions or downwash effects or satisfying\nactuation limits. We demonstrate our approach through simulations and\nexperiments with swarms of up to 20 drones performing choreographies designed\nbased on various songs, highlighting the system's ability to generate effective\nand synchronized drone choreographies for real-world deployment.", "paper_summary_zh": "\u5728\u786c\u9ad4\u548c\u8edf\u9ad4\u9032\u6b65\u7684\u50ac\u5316\u4e0b\uff0c\u7121\u4eba\u6a5f\u8868\u6f14\u5728\u5a1b\u6a02\u7522\u696d\u4e2d\u8d8a\u4f86\u8d8a\u53d7\u5230\u91cd\u8996\u3002\u7136\u800c\uff0c\u70ba\u7121\u4eba\u6a5f\u7fa4\u8a2d\u8a08\u6d41\u66a2\u4e14\u5b89\u5168\u7684\u7de8\u821e\u5f88\u8907\u96dc\uff0c\u800c\u4e14\u901a\u5e38\u9700\u8981\u5c08\u5bb6\u7684\u9818\u57df\u77e5\u8b58\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 SwarmGPT-Primitive\uff0c\u9019\u662f\u4e00\u7a2e\u57fa\u65bc\u8a9e\u8a00\u7684\u7de8\u821e\u5668\uff0c\u5b83\u5c07\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u63a8\u7406\u80fd\u529b\u8207\u5b89\u5168\u7684\u52d5\u4f5c\u898f\u5283\u76f8\u7d50\u5408\uff0c\u4ee5\u4fc3\u9032\u53ef\u90e8\u7f72\u7684\u7121\u4eba\u6a5f\u7fa4\u7de8\u821e\u3002LLM \u5229\u7528\u52d5\u4f5c\u57fa\u5143\u7684\u5eab\u70ba\u7d66\u5b9a\u7684\u97f3\u6a02\u5275\u4f5c\u7de8\u821e\uff1b\u57fa\u65bc\u8a9e\u8a00\u7684\u7de8\u821e\u5668\u6703\u64f4\u5145\u4e00\u500b\u57fa\u65bc\u6700\u4f73\u5316\u7684\u5b89\u5168\u904e\u6ffe\u5668\uff0c\u900f\u904e\u5728\u53ef\u884c\u6027\u548c\u5b89\u5168\u6027\u7d04\u675f\u906d\u5230\u7834\u58de\u6642\u9032\u884c\u6700\u5c0f\u7684\u8abf\u6574\uff0c\u4f86\u8a8d\u8b49\u7de8\u821e\u4ee5\u9032\u884c\u5be6\u969b\u90e8\u7f72\u3002\u6574\u9ad4\u7684 SwarmGPT-Primitive \u6846\u67b6\u5c07\u7de8\u821e\u8a2d\u8a08\u8207\u5b89\u5168\u7684\u52d5\u4f5c\u898f\u5283\u5206\u958b\uff0c\u9019\u5141\u8a31\u975e\u5c08\u5bb6\u4f7f\u7528\u8005\u91cd\u65b0\u63d0\u793a\u548c\u8abf\u6574\u69cb\u5716\uff0c\u800c\u7121\u9700\u64d4\u5fc3\u662f\u5426\u7b26\u5408\u7d04\u675f\uff0c\u4f8b\u5982\u907f\u514d\u78b0\u649e\u6216\u4e0b\u964d\u6c23\u6d41\u6548\u61c9\uff0c\u6216\u6eff\u8db3\u81f4\u52d5\u9650\u5236\u3002\u6211\u5011\u900f\u904e\u6a21\u64ec\u548c\u5be6\u9a57\u4f86\u5c55\u793a\u6211\u5011\u7684\u505a\u6cd5\uff0c\u5176\u4e2d\u6709\u6700\u591a 20 \u67b6\u7121\u4eba\u6a5f\u8868\u6f14\u57fa\u65bc\u5404\u7a2e\u6b4c\u66f2\u8a2d\u8a08\u7684\u7de8\u821e\uff0c\u7a81\u986f\u4e86\u7cfb\u7d71\u70ba\u5be6\u969b\u90e8\u7f72\u7522\u751f\u6709\u6548\u4e14\u540c\u6b65\u7684\u7121\u4eba\u6a5f\u7de8\u821e\u7684\u80fd\u529b\u3002", "author": "Vedant Vyas et.al.", "authors": "Vedant Vyas, Martin Schuck, Dinushka O. Dahanaggamaarachchi, Siqi Zhou, Angela P. Schoellig", "id": "2412.08428v1", "paper_url": "http://arxiv.org/abs/2412.08428v1", "repo": "null"}}