{"2408.03617": {"publish_time": "2024-08-07", "title": "Is Child-Directed Speech Effective Training Data for Language Models?", "paper_summary": "While high-performing language models are typically trained on hundreds of\nbillions of words, human children become fluent language users with a much\nsmaller amount of data. What are the features of the data they receive, and how\ndo these features support language modeling objectives? To investigate this\nquestion, we train GPT-2 models on 29M words of English-language child-directed\nspeech and a new matched, synthetic dataset (TinyDialogues), comparing to a\nheterogeneous blend of datasets from the BabyLM challenge. We evaluate both the\nsyntactic and semantic knowledge of these models using developmentally-inspired\nevaluations. Through pretraining experiments, we test whether the global\ndevelopmental ordering or the local discourse ordering of children's training\ndata support high performance relative to other datasets. The local properties\nof the data affect model results, but somewhat surprisingly, global properties\ndo not. Further, child language input is not uniquely valuable for training\nlanguage models. These findings support the hypothesis that, rather than\nproceeding from better data, children's learning is instead substantially more\nefficient than current language modeling techniques.", "paper_summary_zh": "\u5118\u7ba1\u9ad8\u6027\u80fd\u8a9e\u8a00\u6a21\u578b\u901a\u5e38\u6703\u5728\u6578\u767e\u5104\u500b\u55ae\u5b57\u4e0a\u9032\u884c\u8a13\u7df4\uff0c\u4f46\u4eba\u985e\u5b69\u7ae5\u53ea\u9700\u4f7f\u7528\u66f4\u5c11\u91cf\u7684\u8cc7\u6599\uff0c\u5c31\u80fd\u6210\u70ba\u6d41\u5229\u7684\u8a9e\u8a00\u4f7f\u7528\u8005\u3002\u4ed6\u5011\u63a5\u6536\u7684\u8cc7\u6599\u6709\u54ea\u4e9b\u7279\u5fb5\uff0c\u9019\u4e9b\u7279\u5fb5\u5982\u4f55\u652f\u63f4\u8a9e\u8a00\u5efa\u6a21\u76ee\u6a19\uff1f\u70ba\u4e86\u63a2\u8a0e\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u5728 2900 \u842c\u500b\u55ae\u5b57\u7684\u82f1\u8a9e\u5152\u7ae5\u5c0e\u5411\u8a9e\u8a00\u548c\u4e00\u500b\u65b0\u7684\u5339\u914d\u5f0f\u5408\u6210\u8cc7\u6599\u96c6 (TinyDialogues) \u4e0a\u8a13\u7df4 GPT-2 \u6a21\u578b\uff0c\u4e26\u8207 BabyLM \u6311\u6230\u4e2d\u5404\u7a2e\u7570\u8cea\u8cc7\u6599\u96c6\u9032\u884c\u6bd4\u8f03\u3002\u6211\u5011\u4f7f\u7528\u767c\u5c55\u9748\u611f\u8a55\u4f30\u4f86\u8a55\u4f30\u9019\u4e9b\u6a21\u578b\u7684\u53e5\u6cd5\u548c\u8a9e\u7fa9\u77e5\u8b58\u3002\u900f\u904e\u9810\u8a13\u7df4\u5be6\u9a57\uff0c\u6211\u5011\u6e2c\u8a66\u5152\u7ae5\u8a13\u7df4\u8cc7\u6599\u7684\u6574\u9ad4\u767c\u5c55\u9806\u5e8f\u6216\u5c40\u90e8\u8a9e\u7bc7\u9806\u5e8f\u662f\u5426\u76f8\u5c0d\u65bc\u5176\u4ed6\u8cc7\u6599\u96c6\u652f\u63f4\u9ad8\u6027\u80fd\u3002\u8cc7\u6599\u7684\u5c40\u90e8\u5c6c\u6027\u6703\u5f71\u97ff\u6a21\u578b\u7d50\u679c\uff0c\u4f46\u4ee4\u4eba\u9a5a\u8a1d\u7684\u662f\uff0c\u6574\u9ad4\u5c6c\u6027\u4e26\u4e0d\u6703\u3002\u6b64\u5916\uff0c\u5152\u7ae5\u8a9e\u8a00\u8f38\u5165\u4e26\u975e\u8a13\u7df4\u8a9e\u8a00\u6a21\u578b\u7684\u552f\u4e00\u6709\u50f9\u503c\u8cc7\u6599\u3002\u9019\u4e9b\u767c\u73fe\u652f\u6301\u4ee5\u4e0b\u5047\u8a2d\uff1a\u5152\u7ae5\u7684\u5b78\u7fd2\u4e26\u975e\u4f86\u81ea\u66f4\u597d\u7684\u8cc7\u6599\uff0c\u800c\u662f\u6bd4\u76ee\u524d\u7684\u8a9e\u8a00\u5efa\u6a21\u6280\u8853\u6709\u6548\u7387\u8a31\u591a\u3002", "author": "Steven Y. Feng et.al.", "authors": "Steven Y. Feng, Noah D. Goodman, Michael C. Frank", "id": "2408.03617v1", "paper_url": "http://arxiv.org/abs/2408.03617v1", "repo": "null"}}