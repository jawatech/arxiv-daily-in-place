
### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-06-26**|**Stable Diffusion Segmentation for Biomedical Images with Single-step Reverse Process**|Tianyu Lin et.al.|[2406.18361v1](http://arxiv.org/abs/2406.18361v1)|[link](https://github.com/lin-tianyu/stable-diffusion-seg)|
|**2024-06-26**|**EHR-Based Mobile and Web Platform for Chronic Disease Risk Prediction Using Large Language Multimodal Models**|Chun-Chieh Liao et.al.|[2406.18087v1](http://arxiv.org/abs/2406.18087v1)|null|
|**2024-06-26**|**Few-Shot Medical Image Segmentation with High-Fidelity Prototypes**|Song Tang et.al.|[2406.18074v1](http://arxiv.org/abs/2406.18074v1)|null|
|**2024-06-26**|**Improving Entity Recognition Using Ensembles of Deep Learning and Fine-tuned Large Language Models: A Case Study on Adverse Event Extraction from Multiple Sources**|Yiming Li et.al.|[2406.18049v1](http://arxiv.org/abs/2406.18049v1)|null|
|**2024-06-26**|**Automated Clinical Data Extraction with Knowledge Conditioned LLMs**|Diya Li et.al.|[2406.18027v1](http://arxiv.org/abs/2406.18027v1)|null|
|**2024-06-26**|**AutoOPE: Automated Off-Policy Estimator Selection**|Nicolò Felicioni et.al.|[2406.18022v1](http://arxiv.org/abs/2406.18022v1)|null|
|**2024-06-26**|**Multi-step Knowledge Retrieval and Inference over Unstructured Data**|Aditya Kalyanpur et.al.|[2406.17987v1](http://arxiv.org/abs/2406.17987v1)|null|
|**2024-06-25**|**Domain Adaptation of Echocardiography Segmentation Via Reinforcement Learning**|Arnaud Judge et.al.|[2406.17902v1](http://arxiv.org/abs/2406.17902v1)|null|
|**2024-06-25**|**CTBench: A Comprehensive Benchmark for Evaluating Language Model Capabilities in Clinical Trial Design**|Nafis Neehal et.al.|[2406.17888v1](http://arxiv.org/abs/2406.17888v1)|null|
|**2024-06-25**|**BayTTA: Uncertainty-aware medical image classification with optimized test-time augmentation using Bayesian model averaging**|Zeinab Sherkatghanad et.al.|[2406.17640v1](http://arxiv.org/abs/2406.17640v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-25**|**On the consistency of hyper-parameter selection in value-based deep reinforcement learning**|Johan Obando-Ceron et.al.|[2406.17523v1](http://arxiv.org/abs/2406.17523v1)|null|
|**2024-06-25**|**TSynD: Targeted Synthetic Data Generation for Enhanced Medical Image Classification**|Joshua Niemeijer et.al.|[2406.17473v1](http://arxiv.org/abs/2406.17473v1)|null|
|**2024-06-25**|**AI for the prediction of early stages of Alzheimer's disease from neuroimaging biomarkers -- A narrative review of a growing field**|Thorsten Rudroff et.al.|[2406.17822v1](http://arxiv.org/abs/2406.17822v1)|null|
|**2024-06-25**|**Task-Agnostic Federated Learning**|Zhengtao Yao et.al.|[2406.17235v1](http://arxiv.org/abs/2406.17235v1)|null|
|**2024-06-24**|**Scalable Artificial Intelligence for Science: Perspectives, Methods and Exemplars**|Wesley Brewer et.al.|[2406.17812v1](http://arxiv.org/abs/2406.17812v1)|null|
|**2024-06-24**|**PIC2O-Sim: A Physics-Inspired Causality-Aware Dynamic Convolutional Neural Operator for Ultra-Fast Photonic Device FDTD Simulation**|Pingchuan Ma et.al.|[2406.17810v1](http://arxiv.org/abs/2406.17810v1)|null|
|**2024-06-24**|**The Responsible Foundation Model Development Cheatsheet: A Review of Tools & Resources**|Shayne Longpre et.al.|[2406.16746v2](http://arxiv.org/abs/2406.16746v2)|null|
|**2024-06-24**|**Evaluation of Language Models in the Medical Context Under Resource-Constrained Settings**|Andrea Posada et.al.|[2406.16611v1](http://arxiv.org/abs/2406.16611v1)|[link](https://github.com/anpoc/language-models-in-medicine)|
|**2024-06-24**|**Guardrails for avoiding harmful medical product recommendations and off-label promotion in generative AI models**|Daniel Lopez-Martinez et.al.|[2406.16455v1](http://arxiv.org/abs/2406.16455v1)|null|
|**2024-06-24**|**A large language model for predicting T cell receptor-antigen binding specificity**|Xing Fang et.al.|[2406.16995v1](http://arxiv.org/abs/2406.16995v1)|[link](https://github.com/hliulab/tcrlm)|
|**2024-06-24**|**Graph-Augmented LLMs for Personalized Health Insights: A Case Study in Sleep Analysis**|Ajan Subramanian et.al.|[2406.16252v2](http://arxiv.org/abs/2406.16252v2)|null|
|**2024-06-23**|**Continuous Output Personality Detection Models via Mixed Strategy Training**|Rong Wang et.al.|[2406.16223v1](http://arxiv.org/abs/2406.16223v1)|null|
|**2024-06-23**|**On Instabilities of Unsupervised Denoising Diffusion Models in Magnetic Resonance Imaging Reconstruction**|Tianyu Han et.al.|[2406.16983v1](http://arxiv.org/abs/2406.16983v1)|null|
|**2024-06-23**|**Research on Disease Prediction Model Construction Based on Computer AI deep Learning Technology**|Yang Lin et.al.|[2406.16982v1](http://arxiv.org/abs/2406.16982v1)|null|
|**2024-06-23**|**Towards Open Respiratory Acoustic Foundation Models: Pretraining and Benchmarking**|Yuwei Zhang et.al.|[2406.16148v1](http://arxiv.org/abs/2406.16148v1)|[link](https://github.com/evelyn0414/opera)|
|**2024-06-23**|**Predicting Individual Depression Symptoms from Acoustic Features During Speech**|Sebastian Rodriguez et.al.|[2406.16000v1](http://arxiv.org/abs/2406.16000v1)|null|
|**2024-06-23**|**Evaluating the Effectiveness of the Foundational Models for Q&A Classification in Mental Health care**|Hassan Alhuzali et.al.|[2406.15966v1](http://arxiv.org/abs/2406.15966v1)|null|
|**2024-06-22**|**SEDMamba: Enhancing Selective State Space Modelling with Bottleneck Mechanism and Fine-to-Coarse Temporal Fusion for Efficient Error Detection in Robot-Assisted Surgery**|Jialang Xu et.al.|[2406.15920v1](http://arxiv.org/abs/2406.15920v1)|null|
|**2024-06-22**|**Real-time Speech Summarization for Medical Conversations**|Khai Le-Duc et.al.|[2406.15888v1](http://arxiv.org/abs/2406.15888v1)|[link](https://github.com/leduckhai/multimed)|
|**2024-06-21**|**Automated radiotherapy treatment planning guided by GPT-4Vision**|Sheng Liu et.al.|[2406.15609v1](http://arxiv.org/abs/2406.15609v1)|null|
|**2024-06-21**|**Privacy Preserved Blood Glucose Level Cross-Prediction: An Asynchronous Decentralized Federated Learning Approach**|Chengzhe Piao et.al.|[2406.15346v1](http://arxiv.org/abs/2406.15346v1)|[link](https://github.com/chengzhepiao/coldstartbglp)|
|**2024-06-21**|**Exploring the Efficacy of Robotic Assistants with ChatGPT and Claude in Enhancing ADHD Therapy: Innovating Treatment Paradigms**|Santiago Berrezueta-Guzman et.al.|[2406.15198v1](http://arxiv.org/abs/2406.15198v1)|null|
|**2024-06-21**|**This actually looks like that: Proto-BagNets for local and global interpretability-by-design**|Kerol Djoumessi et.al.|[2406.15168v2](http://arxiv.org/abs/2406.15168v2)|[link](https://github.com/kdjoumessi/proto-bagnets)|
|**2024-06-21**|**FA-Net: A Fuzzy Attention-aided Deep Neural Network for Pneumonia Detection in Chest X-Rays**|Ayush Roy et.al.|[2406.15117v1](http://arxiv.org/abs/2406.15117v1)|[link](https://github.com/ayushroy2001/fa-net)|
|**2024-06-21**|**Tri-VQA: Triangular Reasoning Medical Visual Question Answering for Multi-Attribute Analysis**|Lin Fan et.al.|[2406.15050v1](http://arxiv.org/abs/2406.15050v1)|null|
|**2024-06-21**|**Human-AI collectives produce the most accurate differential diagnoses**|N. Zöller et.al.|[2406.14981v1](http://arxiv.org/abs/2406.14981v1)|null|
|**2024-06-21**|**Deep Imbalanced Regression to Estimate Vascular Age from PPG Data: a Novel Digital Biomarker for Cardiovascular Health**|Guangkun Nie et.al.|[2406.14953v1](http://arxiv.org/abs/2406.14953v1)|null|
|**2024-06-21**|**Extraction of 3D trajectories of mandibular condyles from 2D real-time MRI**|Karyna Isaieva et.al.|[2406.14925v1](http://arxiv.org/abs/2406.14925v1)|null|
|**2024-06-21**|**AI-based Anomaly Detection for Clinical-Grade Histopathological Diagnostics**|Jonas Dippel et.al.|[2406.14866v1](http://arxiv.org/abs/2406.14866v1)|null|
|**2024-06-20**|**ACR: A Benchmark for Automatic Cohort Retrieval**|Dung Ngoc Thai et.al.|[2406.14780v1](http://arxiv.org/abs/2406.14780v1)|null|
|**2024-06-20**|**A Large Language Model Outperforms Other Computational Approaches to the High-Throughput Phenotyping of Physician Notes**|Syed I. Munzir et.al.|[2406.14757v1](http://arxiv.org/abs/2406.14757v1)|null|
|**2024-06-20**|**An updated overview of radiomics-based artificial intelligence (AI) methods in breast cancer screening and diagnosis**|Reza Elahi et.al.|[2406.14735v1](http://arxiv.org/abs/2406.14735v1)|null|
|**2024-06-20**|**This Looks Better than That: Better Interpretable Models with ProtoPNeXt**|Frank Willard et.al.|[2406.14675v1](http://arxiv.org/abs/2406.14675v1)|null|
|**2024-06-20**|**Computation-Efficient Semi-Supervised Learning for ECG-based Cardiovascular Diseases Detection**|Rushuang Zhou et.al.|[2406.14377v1](http://arxiv.org/abs/2406.14377v1)|null|
|**2024-06-20**|**Automatic Labels are as Effective as Manual Labels in Biomedical Images Classification with Deep Learning**|Niccolò Marini et.al.|[2406.14351v1](http://arxiv.org/abs/2406.14351v1)|null|
|**2024-06-20**|**Infusing clinical knowledge into tokenisers for language models**|Abul Hasan et.al.|[2406.14312v1](http://arxiv.org/abs/2406.14312v1)|null|
|**2024-06-20**|**Enhancing robustness of data-driven SHM models: adversarial training with circle loss**|Xiangli Yang et.al.|[2406.14232v1](http://arxiv.org/abs/2406.14232v1)|null|
|**2024-06-20**|**A Data-Driven Guided Decoding Mechanism for Diagnostic Captioning**|Panagiotis Kaliosis et.al.|[2406.14164v1](http://arxiv.org/abs/2406.14164v1)|[link](https://github.com/nlpaueb/dmmcs)|
|**2024-06-20**|**Resource-efficient Medical Image Analysis with Self-adapting Forward-Forward Networks**|Johanna P. Müller et.al.|[2406.14038v1](http://arxiv.org/abs/2406.14038v1)|null|
|**2024-06-20**|**Reasoning Like a Doctor: Improving Medical Dialogue Systems via Diagnostic Reasoning Process Alignment**|Kaishuai Xu et.al.|[2406.13934v1](http://arxiv.org/abs/2406.13934v1)|[link](https://github.com/kaishxu/emulation)|
|**2024-06-19**|**ClinicalLab: Aligning Agents for Multi-Departmental Clinical Diagnostics in the Real World**|Weixiang Yan et.al.|[2406.13890v1](http://arxiv.org/abs/2406.13890v1)|[link](https://github.com/weixiangyan/clinicallab)|
|**2024-06-19**|**MAMA-MIA: A Large-Scale Multi-Center Breast Cancer DCE-MRI Benchmark Dataset with Expert Segmentations**|Lidia Garrucho et.al.|[2406.13844v1](http://arxiv.org/abs/2406.13844v1)|[link](https://github.com/lidiagarrucho/mama-mia)|
|**2024-06-19**|**IoT-Based Preventive Mental Health Using Knowledge Graphs and Standards for Better Well-Being**|Amelie Gyrard et.al.|[2406.13791v1](http://arxiv.org/abs/2406.13791v1)|null|
|**2024-06-19**|**BEACON: Balancing Convenience and Nutrition in Meals With Long-Term Group Recommendations and Reasoning on Multimodal Recipes**|Vansh Nagpal et.al.|[2406.13714v1](http://arxiv.org/abs/2406.13714v1)|null|
|**2024-06-19**|**EndoUIC: Promptable Diffusion Transformer for Unified Illumination Correction in Capsule Endoscopy**|Long Bai et.al.|[2406.13705v1](http://arxiv.org/abs/2406.13705v1)|[link](https://github.com/longbai1006/endouic)|
|**2024-06-19**|**Leveraging Large Language Models for Patient Engagement: The Power of Conversational AI in Digital Health**|Bo Wen et.al.|[2406.13659v1](http://arxiv.org/abs/2406.13659v1)|null|
|**2024-06-19**|**Enhance the Image: Super Resolution using Artificial Intelligence in MRI**|Ziyu Li et.al.|[2406.13625v1](http://arxiv.org/abs/2406.13625v1)|null|
|**2024-06-19**|**Optimizing Psychological Counseling with Instruction-Tuned Large Language Models**|Wenjie Li et.al.|[2406.13617v1](http://arxiv.org/abs/2406.13617v1)|null|
|**2024-06-19**|**Certificates of Differential Privacy and Unlearning for Gradient-Based Training**|Matthew Wicker et.al.|[2406.13433v1](http://arxiv.org/abs/2406.13433v1)|[link](https://github.com/psosnin/AbstractGradientTraining)|
|**2024-06-19**|**Explainable by-design Audio Segmentation through Non-Negative Matrix Factorization and Probing**|Martin Lebourdais et.al.|[2406.13385v1](http://arxiv.org/abs/2406.13385v1)|[link](https://github.com/Lebourdais/3MAS)|
|**2024-06-19**|**Biomedical Visual Instruction Tuning with Clinician Preference Alignment**|Hejie Cui et.al.|[2406.13173v1](http://arxiv.org/abs/2406.13173v1)|null|
|**2024-06-19**|**Cardiac Copilot: Automatic Probe Guidance for Echocardiography with World Model**|Haojun Jiang et.al.|[2406.13165v1](http://arxiv.org/abs/2406.13165v1)|null|
|**2024-06-19**|**Oralytics Reinforcement Learning Algorithm**|Anna L. Trella et.al.|[2406.13127v1](http://arxiv.org/abs/2406.13127v1)|[link](https://github.com/StatisticalReinforcementLearningLab/oralytics_algorithm_design)|
|**2024-06-18**|**Accelerating Complex Disease Treatment through Network Medicine and GenAI: A Case Study on Drug Repurposing for Breast Cancer**|Ahmed Abdeen Hamed et.al.|[2406.13106v2](http://arxiv.org/abs/2406.13106v2)|null|
|**2024-06-18**|**Deriving Hematological Disease Classes Using Fuzzy Logic and Expert Knowledge: A Comprehensive Machine Learning Approach with CBC Parameters**|Salem Ameen et.al.|[2406.13015v1](http://arxiv.org/abs/2406.13015v1)|null|
|**2024-06-18**|**Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation**|Nikolas Koutsoubis et.al.|[2406.12815v1](http://arxiv.org/abs/2406.12815v1)|[link](https://github.com/niko-k98/awesome-list-federated-learning-review)|
|**2024-06-18**|**Probabilistic Temporal Prediction of Continuous Disease Trajectories and Treatment Effects Using Neural SDEs**|Joshua Durso-Finley et.al.|[2406.12807v1](http://arxiv.org/abs/2406.12807v1)|null|
|**2024-06-18**|**Large Language Model as a Universal Clinical Multi-task Decoder**|Yujiang Wu et.al.|[2406.12738v1](http://arxiv.org/abs/2406.12738v1)|null|
|**2024-06-18**|**Online-Adaptive Anomaly Detection for Defect Identification in Aircraft Assembly**|Siddhant Shete et.al.|[2406.12698v1](http://arxiv.org/abs/2406.12698v1)|null|
|**2024-06-18**|**Transforming Surgical Interventions with Embodied Intelligence for Ultrasound Robotics**|Huan Xu et.al.|[2406.12651v1](http://arxiv.org/abs/2406.12651v1)|null|
|**2024-06-18**|**An Empirical Study on the Fairness of Foundation Models for Multi-Organ Image Segmentation**|Qin Li et.al.|[2406.12646v1](http://arxiv.org/abs/2406.12646v1)|null|
|**2024-06-18**|**Retrieval-Augmented Generation for Generative Artificial Intelligence in Medicine**|Rui Yang et.al.|[2406.12449v1](http://arxiv.org/abs/2406.12449v1)|null|
|**2024-06-18**|**Adversarial Attacks on Large Language Models in Medicine**|Yifan Yang et.al.|[2406.12259v1](http://arxiv.org/abs/2406.12259v1)|null|
|**2024-06-18**|**Enhancing Diagnostic Reliability of Foundation Model with Uncertainty Estimation in OCT Images**|Yuanyuan Peng et.al.|[2406.16942v1](http://arxiv.org/abs/2406.16942v1)|null|
|**2024-06-18**|**Time Series Modeling for Heart Rate Prediction: From ARIMA to Transformers**|Haowei Ni et.al.|[2406.12199v1](http://arxiv.org/abs/2406.12199v1)|null|
|**2024-06-18**|**Aqulia-Med LLM: Pioneering Full-Process Open-Source Medical Language Models**|Lulu Zhao et.al.|[2406.12182v1](http://arxiv.org/abs/2406.12182v1)|null|
|**2024-06-17**|**Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**|Vincent Olesen et.al.|[2406.12142v1](http://arxiv.org/abs/2406.12142v1)|null|
|**2024-06-17**|**WellDunn: On the Robustness and Explainability of Language Models and Large Language Models in Identifying Wellness Dimensions**|Seyedali Mohammadi et.al.|[2406.12058v2](http://arxiv.org/abs/2406.12058v2)|null|
|**2024-06-17**|**MedCalc-Bench: Evaluating Large Language Models for Medical Calculations**|Nikhil Khandekar et.al.|[2406.12036v2](http://arxiv.org/abs/2406.12036v2)|[link](https://github.com/ncbi-nlp/medcalc-bench)|
|**2024-06-17**|**Socially Interactive Agents for Robotic Neurorehabilitation Training: Conceptualization and Proof-of-concept Study**|Rhythm Arora et.al.|[2406.12035v1](http://arxiv.org/abs/2406.12035v1)|null|
|**2024-06-17**|**Improving Quality Control of Whole Slide Images by Explicit Artifact Augmentation**|Artur Jurgas et.al.|[2406.11538v1](http://arxiv.org/abs/2406.11538v1)|null|
|**2024-06-17**|**FlexCare: Leveraging Cross-Task Synergy for Flexible Multimodal Healthcare Prediction**|Muhao Xu et.al.|[2406.11928v1](http://arxiv.org/abs/2406.11928v1)|[link](https://github.com/mhxu1998/flexcare)|
|**2024-06-17**|**Formally Certified Approximate Model Counting**|Yong Kiam Tan et.al.|[2406.11414v2](http://arxiv.org/abs/2406.11414v2)|null|
|**2024-06-17**|**Adversarial Style Augmentation via Large Language Model for Robust Fake News Detection**|Sungwon Park et.al.|[2406.11260v1](http://arxiv.org/abs/2406.11260v1)|null|
|**2024-06-17**|**Scorecards for Synthetic Medical Data Evaluation and Reporting**|Ghada Zamzmi et.al.|[2406.11143v1](http://arxiv.org/abs/2406.11143v1)|null|
|**2024-06-17**|**Diffusion Models in Low-Level Vision: A Survey**|Chunming He et.al.|[2406.11138v1](http://arxiv.org/abs/2406.11138v1)|null|
|**2024-06-17**|**Towards Understanding Emotions for Engaged Mental Health Conversations**|Kellie Yu Hui Sim et.al.|[2406.11135v1](http://arxiv.org/abs/2406.11135v1)|null|
|**2024-06-16**|**Boosting Medical Image Classification with Segmentation Foundation Model**|Pengfei Gu et.al.|[2406.11026v1](http://arxiv.org/abs/2406.11026v1)|null|
|**2024-06-16**|**WundtGPT: Shaping Large Language Models To Be An Empathetic, Proactive Psychologist**|Chenyu Ren et.al.|[2406.15474v1](http://arxiv.org/abs/2406.15474v1)|null|
|**2024-06-16**|**ALPS: An Auto-Labeling and Pre-training Scheme for Remote Sensing Segmentation With Segment Anything Model**|Song Zhang et.al.|[2406.10855v1](http://arxiv.org/abs/2406.10855v1)|[link](https://github.com/strivezs/alps)|
|**2024-06-15**|**A Comprehensive Survey of Foundation Models in Medicine**|Wasif Khan et.al.|[2406.10729v1](http://arxiv.org/abs/2406.10729v1)|null|
|**2024-06-15**|**SyntheT2C: Generating Synthetic Data for Fine-Tuning Large Language Models on the Text2Cypher Task**|Ziije Zhong et.al.|[2406.10710v1](http://arxiv.org/abs/2406.10710v1)|null|
|**2024-06-15**|**Intertwining CP and NLP: The Generation of Unreasonably Constrained Sentences**|Alexandre Bonlarron et.al.|[2406.15473v1](http://arxiv.org/abs/2406.15473v1)|null|
|**2024-06-15**|**Applications of Generative AI in Healthcare: algorithmic, ethical, legal and societal considerations**|Onyekachukwu R. Okonji et.al.|[2406.10632v1](http://arxiv.org/abs/2406.10632v1)|null|
|**2024-06-15**|**Public Computer Vision Datasets for Precision Livestock Farming: A Systematic Survey**|Anil Bhujel et.al.|[2406.10628v1](http://arxiv.org/abs/2406.10628v1)|null|
|**2024-06-15**|**Mental Disorder Classification via Temporal Representation of Text**|Raja Kumar et.al.|[2406.15470v1](http://arxiv.org/abs/2406.15470v1)|null|
|**2024-06-15**|**Self Pre-training with Topology- and Spatiality-aware Masked Autoencoders for 3D Medical Image Segmentation**|Pengfei Gu et.al.|[2406.10519v1](http://arxiv.org/abs/2406.10519v1)|null|
|**2024-06-14**|**A Benchmark for Maximum Cut: Towards Standardization of the Evaluation of Learned Heuristics for Combinatorial Optimization**|Ankur Nath et.al.|[2406.11897v1](http://arxiv.org/abs/2406.11897v1)|[link](https://github.com/ankurnath/maxcut-bench)|
|**2024-06-14**|**Biomarker based Cancer Classification using an Ensemble with Pre-trained Models**|Chongmin Lee et.al.|[2406.10087v1](http://arxiv.org/abs/2406.10087v1)|null|

#### Abstracts
##### **Stable Diffusion Segmentation for Biomedical Images with Single-step Reverse Process**
2406.18361v1 by Tianyu Lin, Zhiguang Chen, Zhonghao Yan, Fudan Zheng, Weijiang Yu

Diffusion models have demonstrated their effectiveness across various
generative tasks. However, when applied to medical image segmentation, these
models encounter several challenges, including significant resource and time
requirements. They also necessitate a multi-step reverse process and multiple
samples to produce reliable predictions. To address these challenges, we
introduce the first latent diffusion segmentation model, named SDSeg, built
upon stable diffusion (SD). SDSeg incorporates a straightforward latent
estimation strategy to facilitate a single-step reverse process and utilizes
latent fusion concatenation to remove the necessity for multiple samples.
Extensive experiments indicate that SDSeg surpasses existing state-of-the-art
methods on five benchmark datasets featuring diverse imaging modalities.
Remarkably, SDSeg is capable of generating stable predictions with a solitary
reverse step and sample, epitomizing the model's stability as implied by its
name. The code is available at
https://github.com/lin-tianyu/Stable-Diffusion-Seg

摘要：擴散模型已證明其在各種生成任務中的有效性。然而，當應用於醫學影像分割時，這些模型會遇到一些挑戰，包括顯著的資源和時間需求。它們還需要多步驟的反向處理和多個樣本來產生可靠的預測。為了應對這些挑戰，我們引入了第一個潛在擴散分割模型，名為 SDSeg，它建立在穩定擴散 (SD) 之上。SDSeg 結合了一個直接的潛在估計策略，以促進單步反向處理，並利用潛在融合串接來消除對多個樣本的必要性。廣泛的實驗表明，SDSeg 在具有不同影像模式的五個基準資料集上超越了現有的最先進方法。值得注意的是，SDSeg 能夠通過單一的反向步驟和樣本來產生穩定的預測，體現了模型的穩定性，正如其名稱所暗示的那樣。程式碼可在 https://github.com/lin-tianyu/Stable-Diffusion-Seg 取得

##### **EHR-Based Mobile and Web Platform for Chronic Disease Risk Prediction Using Large Language Multimodal Models**
2406.18087v1 by Chun-Chieh Liao, Wei-Ting Kuo, I-Hsuan Hu, Yen-Chen Shih, Jun-En Ding, Feng Liu, Fang-Ming Hung

Traditional diagnosis of chronic diseases involves in-person consultations
with physicians to identify the disease. However, there is a lack of research
focused on predicting and developing application systems using clinical notes
and blood test values. We collected five years of Electronic Health Records
(EHRs) from Taiwan's hospital database between 2017 and 2021 as an AI database.
Furthermore, we developed an EHR-based chronic disease prediction platform
utilizing Large Language Multimodal Models (LLMMs), successfully integrating
with frontend web and mobile applications for prediction. This prediction
platform can also connect to the hospital's backend database, providing
physicians with real-time risk assessment diagnostics. The demonstration link
can be found at https://www.youtube.com/watch?v=oqmL9DEDFgA.

摘要：傳統慢性病的診斷涉及親自諮詢醫師以找出疾病。然而，缺乏針對使用臨床筆記和血液檢驗值來預測和開發應用系統的研究。我們從2017年到2021年間收集了台灣醫院資料庫中五年的電子健康記錄（EHR）作為AI資料庫。此外，我們開發了一個基於EHR的慢性病預測平台，利用大型語言多模態模型（LLMM），成功整合前端網路和行動應用程式進行預測。這個預測平台也可以連接到醫院的後端資料庫，為醫師提供即時風險評估診斷。示範連結可以在https://www.youtube.com/watch?v=oqmL9DEDFgA找到。

##### **Few-Shot Medical Image Segmentation with High-Fidelity Prototypes**
2406.18074v1 by Song Tang, Shaxu Yan, Xiaozhi Qi, Jianxin Gao, Mao Ye, Jianwei Zhang, Xiatian Zhu

Few-shot Semantic Segmentation (FSS) aims to adapt a pretrained model to new
classes with as few as a single labelled training sample per class. Despite the
prototype based approaches have achieved substantial success, existing models
are limited to the imaging scenarios with considerably distinct objects and not
highly complex background, e.g., natural images. This makes such models
suboptimal for medical imaging with both conditions invalid. To address this
problem, we propose a novel Detail Self-refined Prototype Network (DSPNet) to
constructing high-fidelity prototypes representing the object foreground and
the background more comprehensively. Specifically, to construct global
semantics while maintaining the captured detail semantics, we learn the
foreground prototypes by modelling the multi-modal structures with clustering
and then fusing each in a channel-wise manner. Considering that the background
often has no apparent semantic relation in the spatial dimensions, we integrate
channel-specific structural information under sparse channel-aware regulation.
Extensive experiments on three challenging medical image benchmarks show the
superiority of DSPNet over previous state-of-the-art methods.

摘要：少样本语义分割 (FSS) 旨在以每类仅一个标记训练样本的方式将预训练模型调整到新类。尽管基于原型的办法已取得重大成功，但现有模型仅限于对象明显不同且背景不太复杂的成像场景，例如自然图像。这使得此类模型不适用于同时不满足这两个条件的医学影像。为了解决这个问题，我们提出了一种新颖的细节自精炼原型网络 (DSPNet)，以构建高保真原型，更全面地表示对象前景和背景。具体来说，为了在保持捕获的细节语义的同时构建全局语义，我们通过使用聚类对多模态结构进行建模，然后以逐通道的方式融合每个结构，从而学习前景原型。考虑到背景在空间维度上通常没有明显的语义关系，我们在稀疏通道感知调节下整合特定于通道的结构信息。在三个极具挑战性的医学影像基准上进行的广泛实验表明，DSPNet 优于以前最先进的方法。

##### **Improving Entity Recognition Using Ensembles of Deep Learning and Fine-tuned Large Language Models: A Case Study on Adverse Event Extraction from Multiple Sources**
2406.18049v1 by Yiming Li, Deepthi Viswaroopan, William He, Jianfu Li, Xu Zuo, Hua Xu, Cui Tao

Adverse event (AE) extraction following COVID-19 vaccines from text data is
crucial for monitoring and analyzing the safety profiles of immunizations.
Traditional deep learning models are adept at learning intricate feature
representations and dependencies in sequential data, but often require
extensive labeled data. In contrast, large language models (LLMs) excel in
understanding contextual information, but exhibit unstable performance on named
entity recognition tasks, possibly due to their broad but unspecific training.
This study aims to evaluate the effectiveness of LLMs and traditional deep
learning models in AE extraction, and to assess the impact of ensembling these
models on performance. In this study, we utilized reports and posts from the
VAERS (n=621), Twitter (n=9,133), and Reddit (n=131) as our corpora. Our goal
was to extract three types of entities: "vaccine", "shot", and "ae". We
explored and fine-tuned (except GPT-4) multiple LLMs, including GPT-2, GPT-3.5,
GPT-4, and Llama-2, as well as traditional deep learning models like RNN and
BioBERT. To enhance performance, we created ensembles of the three models with
the best performance. For evaluation, we used strict and relaxed F1 scores to
evaluate the performance for each entity type, and micro-average F1 was used to
assess the overall performance. The ensemble model achieved the highest
performance in "vaccine", "shot", and "ae" with strict F1-scores of 0.878,
0.930, and 0.925, respectively, along with a micro-average score of 0.903. In
conclusion, this study demonstrates the effectiveness and robustness of
ensembling fine-tuned traditional deep learning models and LLMs, for extracting
AE-related information. This study contributes to the advancement of biomedical
natural language processing, providing valuable insights into improving AE
extraction from text data for pharmacovigilance and public health surveillance.

摘要：從文本資料中擷取 COVID-19 疫苗的不良事件 (AE) 對於監控和分析免疫的安全性非常重要。傳統深度學習模型擅長學習序列資料中的複雜特徵表示和依賴關係，但通常需要大量的標籤資料。相比之下，大型語言模型 (LLM) 擅長理解上下文資訊，但在命名實體識別任務上的表現不穩定，這可能是因為它們的訓練範圍廣泛但缺乏針對性。本研究旨在評估 LLM 和傳統深度學習模型在 AE 擷取中的有效性，並評估將這些模型組成的影響。在本研究中，我們利用 VAERS (n=621)、Twitter (n=9,133) 和 Reddit (n=131) 的報告和文章作為語料庫。我們的目標是擷取三種類型的實體：「疫苗」、「注射」和「不良事件」。我們探索並微調了多個 LLM，包括 GPT-2、GPT-3.5、GPT-4 和 Llama-2，以及傳統深度學習模型，例如 RNN 和 BioBERT（GPT-4 除外）。為了提升效能，我們建立了表現最佳的三個模型的集合。在評估方面，我們使用嚴格和放寬的 F1 分數來評估每個實體類型的效能，並使用微平均 F1 來評估整體效能。組合模型在「疫苗」、「注射」和「不良事件」中分別以 0.878、0.930 和 0.925 的嚴格 F1 分數獲得最高效能，微平均分數為 0.903。結論是，本研究證明了微調後的傳統深度學習模型和 LLM 的集合在擷取與 AE 相關的資訊方面的有效性和穩健性。本研究有助於促進生物醫學自然語言處理，並提供有價值的見解，以改善藥物警戒和公共衛生監測中從文本資料中擷取 AE 的方式。

##### **Automated Clinical Data Extraction with Knowledge Conditioned LLMs**
2406.18027v1 by Diya Li, Asim Kadav, Aijing Gao, Rui Li, Richard Bourgon

The extraction of lung lesion information from clinical and medical imaging
reports is crucial for research on and clinical care of lung-related diseases.
Large language models (LLMs) can be effective at interpreting unstructured text
in reports, but they often hallucinate due to a lack of domain-specific
knowledge, leading to reduced accuracy and posing challenges for use in
clinical settings. To address this, we propose a novel framework that aligns
generated internal knowledge with external knowledge through in-context
learning (ICL). Our framework employs a retriever to identify relevant units of
internal or external knowledge and a grader to evaluate the truthfulness and
helpfulness of the retrieved internal-knowledge rules, to align and update the
knowledge bases. Our knowledge-conditioned approach also improves the accuracy
and reliability of LLM outputs by addressing the extraction task in two stages:
(i) lung lesion finding detection and primary structured field parsing,
followed by (ii) further parsing of lesion description text into additional
structured fields. Experiments with expert-curated test datasets demonstrate
that this ICL approach can increase the F1 score for key fields (lesion size,
margin and solidity) by an average of 12.9% over existing ICL methods.

摘要：從臨床和醫學影像報告中萃取肺部病灶資訊對於肺部相關疾病的研究和臨床照護至關重要。大型語言模型 (LLM) 可以有效解讀報告中的非結構化文字，但由於缺乏特定領域知識，它們經常會出現幻覺，導致準確度降低，並對在臨床環境中使用帶來挑戰。為了解決這個問題，我們提出了一個創新的框架，透過脈絡中學習 (ICL) 將產生的內部知識與外部知識對齊。我們的框架採用檢索器來識別內部或外部知識的相关單元，並採用評分器來評估檢索到的內部知識規則的真實性和有益性，以對齊和更新知識庫。我們以知識為條件的方法也透過以下兩個階段來處理萃取任務，進而提高 LLM 輸出的準確性和可靠性：(i) 肺部病灶發現偵測和主要結構化欄位分析，接著是 (ii) 進一步將病灶描述文字分析為其他結構化欄位。使用專家策展的測試資料集進行的實驗證明，這個 ICL 方法可以將關鍵欄位 (病灶大小、邊緣和實心度) 的 F1 分數平均提高 12.9%，優於現有的 ICL 方法。

##### **AutoOPE: Automated Off-Policy Estimator Selection**
2406.18022v1 by Nicolò Felicioni, Michael Benigni, Maurizio Ferrari Dacrema

The Off-Policy Evaluation (OPE) problem consists of evaluating the
performance of counterfactual policies with data collected by another one. This
problem is of utmost importance for various application domains, e.g.,
recommendation systems, medical treatments, and many others. To solve the OPE
problem, we resort to estimators, which aim to estimate in the most accurate
way possible the performance that the counterfactual policies would have had if
they were deployed in place of the logging policy. In the literature, several
estimators have been developed, all with different characteristics and
theoretical guarantees. Therefore, there is no dominant estimator, and each
estimator may be the best one for different OPE problems, depending on the
characteristics of the dataset at hand. While the selection of the estimator is
a crucial choice for an accurate OPE, this problem has been widely overlooked
in the literature. We propose an automated data-driven OPE estimator selection
method based on machine learning. In particular, the core idea we propose in
this paper is to create several synthetic OPE tasks and use a machine learning
model trained to predict the best estimator for those synthetic tasks. We
empirically show how our method is able to generalize to unseen tasks and make
a better estimator selection compared to a baseline method on several
real-world datasets, with a computational cost significantly lower than the one
of the baseline.

摘要：離線策略評估 (OPE) 問題包含使用由其他政策收集的資料評估反事實政策的效能。此問題對於各種應用領域至關重要，例如推薦系統、醫療治療等。為了解決 OPE 問題，我們求助於估計器，其目標是以最精確的方式估計反事實政策在部署於記錄政策時所具備的效能。在文獻中，已經開發出多個估計器，每個估計器都具有不同的特性和理論保證。因此，沒有主導估計器，每個估計器可能是不同 OPE 問題的最佳估計器，具體取決於手邊資料集的特徵。雖然估計器的選擇對於準確的 OPE 至關重要，但這個問題在文獻中已被廣泛忽視。我們提出一個基於機器學習的自動化資料驅動 OPE 估計器選擇方法。特別是，我們在這篇論文中提出的核心概念是建立幾個合成 OPE 任務，並使用機器學習模型訓練來預測這些合成任務的最佳估計器。我們以實證方式說明我們的模型如何能夠概化為未見任務，並在幾個真實世界資料集上與基線方法相比，做出更好的估計器選擇，且運算成本遠低於基線方法。

##### **Multi-step Knowledge Retrieval and Inference over Unstructured Data**
2406.17987v1 by Aditya Kalyanpur, Kailash Saravanakumar, Victor Barres, CJ McFate, Lori Moon, Nati Seifu, Maksim Eremeev, Jose Barrera, Eric Brown, David Ferrucci

The advent of Large Language Models (LLMs) and Generative AI has
revolutionized natural language applications across various domains. However,
high-stakes decision-making tasks in fields such as medical, legal and finance
require a level of precision, comprehensiveness, and logical consistency that
pure LLM or Retrieval-Augmented-Generation (RAG) approaches often fail to
deliver. At Elemental Cognition (EC), we have developed a neuro-symbolic AI
platform to tackle these problems. The platform integrates fine-tuned LLMs for
knowledge extraction and alignment with a robust symbolic reasoning engine for
logical inference, planning and interactive constraint solving. We describe
Cora, a Collaborative Research Assistant built on this platform, that is
designed to perform complex research and discovery tasks in high-stakes
domains. This paper discusses the multi-step inference challenges inherent in
such domains, critiques the limitations of existing LLM-based methods, and
demonstrates how Cora's neuro-symbolic approach effectively addresses these
issues. We provide an overview of the system architecture, key algorithms for
knowledge extraction and formal reasoning, and present preliminary evaluation
results that highlight Cora's superior performance compared to well-known LLM
and RAG baselines.

摘要：大型語言模型 (LLM) 和生成式 AI 的出現徹底改變了各個領域的自然語言應用。然而，醫療、法律和金融等領域的高風險決策制定任務需要精確度、全面性和邏輯一致性，而純粹的 LLM 或檢索增強生成 (RAG) 方法通常無法提供。在 Elemental Cognition (EC)，我們開發了一個神經符號 AI 平台來解決這些問題。該平台整合了經過微調的 LLM，用於知識提取和與強大的符號推理引擎對齊，用於邏輯推理、規劃和互動約束求解。我們描述了 Cora，一個建立在這個平台上的協作研究助理，它被設計用於在高風險領域執行複雜的研究和發現任務。本文討論了此類領域中固有的多步驟推理挑戰，批評了現有基於 LLM 的方法的局限性，並展示了 Cora 的神經符號方法如何有效地解決這些問題。我們概述了系統架構、知識提取和形式推理的關鍵演算法，並提供了初步評估結果，突出了 Cora 與眾所周知的 LLM 和 RAG 基準相比的優異性能。

##### **Domain Adaptation of Echocardiography Segmentation Via Reinforcement Learning**
2406.17902v1 by Arnaud Judge, Thierry Judge, Nicolas Duchateau, Roman A. Sandler, Joseph Z. Sokol, Olivier Bernard, Pierre-Marc Jodoin

Performance of deep learning segmentation models is significantly challenged
in its transferability across different medical imaging domains, particularly
when aiming to adapt these models to a target domain with insufficient
annotated data for effective fine-tuning. While existing domain adaptation (DA)
methods propose strategies to alleviate this problem, these methods do not
explicitly incorporate human-verified segmentation priors, compromising the
potential of a model to produce anatomically plausible segmentations. We
introduce RL4Seg, an innovative reinforcement learning framework that reduces
the need to otherwise incorporate large expertly annotated datasets in the
target domain, and eliminates the need for lengthy manual human review. Using a
target dataset of 10,000 unannotated 2D echocardiographic images, RL4Seg not
only outperforms existing state-of-the-art DA methods in accuracy but also
achieves 99% anatomical validity on a subset of 220 expert-validated subjects
from the target domain. Furthermore, our framework's reward network offers
uncertainty estimates comparable with dedicated state-of-the-art uncertainty
methods, demonstrating the utility and effectiveness of RL4Seg in overcoming
domain adaptation challenges in medical image segmentation.

摘要：深度學習分割模型的效能，在不同醫學影像領域的轉移性上受到顯著的挑戰，特別是在目標領域的適應，資料不足以進行有效微調時。現有的領域適應 (DA) 方法提出策略來緩解此問題，但這些方法並未明確納入人為驗證的分割先驗，這會影響模型產生解剖學上合理的分割的可能性。我們引進 RL4Seg，一種創新的強化學習架構，它減少了在目標領域中納入大量專家註解資料集的需求，並消除了冗長的、手動的人工審查需求。使用包含 10,000 個未註解的 2D 超音波影像的目標資料集，RL4Seg 不僅在準確性上優於現有的最先進的 DA 方法，而且在目標領域中，220 個專家驗證的受試者的子集中，解剖學效度達到 99%。此外，我們架構的獎勵網路提供了與專門的最先進的不確定性方法相當的不確定性估計，這證明了 RL4Seg 在克服醫學影像分割中的領域適應挑戰方面的效用和有效性。

##### **CTBench: A Comprehensive Benchmark for Evaluating Language Model Capabilities in Clinical Trial Design**
2406.17888v1 by Nafis Neehal, Bowen Wang, Shayom Debopadhaya, Soham Dan, Keerthiram Murugesan, Vibha Anand, Kristin P. Bennett

CTBench is introduced as a benchmark to assess language models (LMs) in
aiding clinical study design. Given study-specific metadata, CTBench evaluates
AI models' ability to determine the baseline features of a clinical trial (CT),
which include demographic and relevant features collected at the trial's start
from all participants. These baseline features, typically presented in CT
publications (often as Table 1), are crucial for characterizing study cohorts
and validating results. Baseline features, including confounders and
covariates, are also necessary for accurate treatment effect estimation in
studies involving observational data. CTBench consists of two datasets:
"CT-Repo," containing baseline features from 1,690 clinical trials sourced from
clinicaltrials.gov, and "CT-Pub," a subset of 100 trials with more
comprehensive baseline features gathered from relevant publications. Two
LM-based evaluation methods are developed to compare the actual baseline
feature lists against LM-generated responses. "ListMatch-LM" and
"ListMatch-BERT" use GPT-4o and BERT scores (at various thresholds),
respectively, for evaluation. To establish baseline results, advanced prompt
engineering techniques using LLaMa3-70B-Instruct and GPT-4o in zero-shot and
three-shot learning settings are applied to generate potential baseline
features. The performance of GPT-4o as an evaluator is validated through
human-in-the-loop evaluations on the CT-Pub dataset, where clinical experts
confirm matches between actual and LM-generated features. The results highlight
a promising direction with significant potential for improvement, positioning
CTBench as a useful tool for advancing research on AI in CT design and
potentially enhancing the efficacy and robustness of CTs.

摘要：CTBench 被引入作為一個基準，用於評估語言模型 (LM) 在幫助臨床研究設計中的作用。CTBench 會評估 AI 模型在給定特定研究的元數據後，決定臨床試驗 (CT) 基線特徵的能力，其中包括在試驗開始時從所有參與者收集的人口統計和相關特徵。這些基線特徵通常會在 CT 出版物中呈現（通常是表格 1），對於表徵研究群組和驗證結果至關重要。基線特徵（包括混淆因子和協變量）對於準確估計涉及觀察數據的研究中的治療效果也很有必要。CTBench 包含兩個數據集：「CT-Repo」，其中包含來自 clinicaltrials.gov 的 1,690 個臨床試驗的基線特徵，以及「CT-Pub」，一個包含 100 個試驗的子集，其中包含從相關出版物收集的更全面的基線特徵。開發了兩種基於 LM 的評估方法，用於比較實際的基線特徵列表和 LM 生成的回應。「ListMatch-LM」和「ListMatch-BERT」分別使用 GPT-4o 和 BERT 分數（在各種閾值下）進行評估。為了建立基線結果，在零次學習和三次學習設置中使用 LLaMa3-70B-Instruct 和 GPT-4o 的進階提示工程技術，用於生成潛在的基線特徵。GPT-4o 作為評估器的性能通過在 CT-Pub 數據集上進行人機交互評估得到驗證，在該評估中，臨床專家確認實際特徵和 LM 生成的特徵之間的匹配。結果突顯了一個有希望的方向，具有顯著的改進潛力，將 CTBench 定位為促進 CT 設計中 AI 研究的有用工具，並有可能提高 CT 的功效和穩健性。

##### **BayTTA: Uncertainty-aware medical image classification with optimized test-time augmentation using Bayesian model averaging**
2406.17640v1 by Zeinab Sherkatghanad, Moloud Abdar, Mohammadreza Bakhtyari, Vladimir Makarenkov

Test-time augmentation (TTA) is a well-known technique employed during the
testing phase of computer vision tasks. It involves aggregating multiple
augmented versions of input data. Combining predictions using a simple average
formulation is a common and straightforward approach after performing TTA. This
paper introduces a novel framework for optimizing TTA, called BayTTA
(Bayesian-based TTA), which is based on Bayesian Model Averaging (BMA). First,
we generate a model list associated with different variations of the input data
created through TTA. Then, we use BMA to combine model predictions weighted by
their respective posterior probabilities. Such an approach allows one to take
into account model uncertainty, and thus to enhance the predictive performance
of the related machine learning or deep learning model. We evaluate the
performance of BayTTA on various public data, including three medical image
datasets comprising skin cancer, breast cancer, and chest X-ray images and two
well-known gene editing datasets, CRISPOR and GUIDE-seq. Our experimental
results indicate that BayTTA can be effectively integrated into
state-of-the-art deep learning models used in medical image analysis as well as
into some popular pre-trained CNN models such as VGG-16, MobileNetV2,
DenseNet201, ResNet152V2, and InceptionRes-NetV2, leading to the enhancement in
their accuracy and robustness performance.

摘要：測試時間擴充 (TTA) 是一種在電腦視覺任務的測試階段中廣泛使用的技術。它涉及聚合輸入資料的許多擴充版本。在執行 TTA 之後，使用簡單平均公式組合預測是一種常見且直接的方法。本文介紹了一個用於最佳化 TTA 的新框架，稱為 BayTTA（基於貝氏的 TTA），它基於貝氏模型平均 (BMA)。首先，我們產生一個與輸入資料的不同變異相關的模型清單，這些變異是透過 TTA 建立的。然後，我們使用 BMA 來組合模型預測，其權重由它們各自的後驗機率決定。這種方法允許考慮模型的不確定性，從而增強相關機器學習或深度學習模型的預測性能。我們在各種公開資料上評估 BayTTA 的性能，包括三個醫學影像資料集，其中包含皮膚癌、乳癌和胸部 X 光影像，以及兩個著名的基因編輯資料集，CRISPOR 和 GUIDE-seq。我們的實驗結果表明，BayTTA 可以有效整合到用於醫學影像分析的最新深度學習模型中，以及一些流行的預訓練 CNN 模型中，例如 VGG-16、MobileNetV2、DenseNet201、ResNet152V2 和 InceptionRes-NetV2，從而提升它們的準確度和健壯性表現。

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

摘要：<paragraph>人工智慧（AI）目前在很大程度上依賴於缺乏可解釋性的黑盒機器學習模型。可解釋性人工智慧（XAI）領域致力於解決這個主要問題，這在金融、法律和健康等高風險領域至關重要。
我們提出了一種基於範疇論定義 AI 模型及其可解釋性的方法。為此，我們採用組合模型的概念，它以形式弦圖的形式看待模型，這些弦圖捕獲了模型的抽象結構及其具體實現。這種綜合觀點包含了確定性、概率性和量子模型。我們將各種 AI 模型作為組合模型進行比較，包括線性和基於規則的模型、（遞迴）神經網路、Transformer、VAE，以及因果和 DisCoCirc 模型。
接下來，我們根據模型的組合結構給出模型解釋的定義，展示如何分析模型的可解釋性，並使用它來澄清 XAI 中的常見主題。我們發現，讓標準的「內在可解釋」模型如此透明的原因在圖表中表現得最為清楚。這引導我們得出更一般的組合可解釋（CI）模型概念，它另外還包括因果、概念空間和 DisCoCirc 模型。
接下來，我們展示了 CI 模型的可解釋性優勢。首先，它們的組合結構允許計算其他感興趣的量，並可能通過匹配模型的結構來促進從模型到被建模現象的推理。其次，它們允許對其行為進行圖解說明，這些說明基於影響約束、圖解手術和重寫說明。最後，我們討論了這種方法的許多未來方向，提出了如何在實踐中學習這種有意義的結構化模型的問題。</paragraph>

##### **On the consistency of hyper-parameter selection in value-based deep reinforcement learning**
2406.17523v1 by Johan Obando-Ceron, João G. M. Araújo, Aaron Courville, Pablo Samuel Castro

Deep reinforcement learning (deep RL) has achieved tremendous success on
various domains through a combination of algorithmic design and careful
selection of hyper-parameters. Algorithmic improvements are often the result of
iterative enhancements built upon prior approaches, while hyper-parameter
choices are typically inherited from previous methods or fine-tuned
specifically for the proposed technique. Despite their crucial impact on
performance, hyper-parameter choices are frequently overshadowed by algorithmic
advancements. This paper conducts an extensive empirical study focusing on the
reliability of hyper-parameter selection for value-based deep reinforcement
learning agents, including the introduction of a new score to quantify the
consistency and reliability of various hyper-parameters. Our findings not only
help establish which hyper-parameters are most critical to tune, but also help
clarify which tunings remain consistent across different training regimes.

摘要：深度強化學習（深度 RL）透過演算法設計與仔細選擇超參數的結合，在各種領域取得巨大的成功。演算法的改進通常是建立在先前方法上的反覆增強的結果，而超參數的選擇通常承襲自先前的技術，或針對建議的技術進行微調。儘管超參數的選擇對效能有決定性的影響，但它經常被演算法的進步所掩蓋。本文進行一項廣泛的實證研究，重點在於基於價值的深度強化學習代理程式超參數選擇的可靠性，包括引入一個新的評分，用於量化各種超參數的一致性和可靠性。我們的發現不僅有助於確定哪些超參數最需要調整，還有助於釐清哪些調整在不同的訓練機制中保持一致。

##### **TSynD: Targeted Synthetic Data Generation for Enhanced Medical Image Classification**
2406.17473v1 by Joshua Niemeijer, Jan Ehrhardt, Hristina Uzunova, Heinz Handels

The usage of medical image data for the training of large-scale machine
learning approaches is particularly challenging due to its scarce availability
and the costly generation of data annotations, typically requiring the
engagement of medical professionals. The rapid development of generative models
allows towards tackling this problem by leveraging large amounts of realistic
synthetically generated data for the training process. However, randomly
choosing synthetic samples, might not be an optimal strategy.
  In this work, we investigate the targeted generation of synthetic training
data, in order to improve the accuracy and robustness of image classification.
Therefore, our approach aims to guide the generative model to synthesize data
with high epistemic uncertainty, since large measures of epistemic uncertainty
indicate underrepresented data points in the training set. During the image
generation we feed images reconstructed by an auto encoder into the classifier
and compute the mutual information over the class-probability distribution as a
measure for uncertainty.We alter the feature space of the autoencoder through
an optimization process with the objective of maximizing the classifier
uncertainty on the decoded image. By training on such data we improve the
performance and robustness against test time data augmentations and adversarial
attacks on several classifications tasks.

摘要：由於醫療影像資料的取得不易，且資料標註的產生成本高昂，通常需要醫療專業人員參與，因此使用醫療影像資料來訓練大型機器學習方法特別具有挑戰性。生成式模型的快速發展，允許透過利用大量逼真的合成資料來訓練流程，以解決此問題。然而，隨機選擇合成樣本可能不是最佳策略。
  在這項工作中，我們研究合成訓練資料的目標生成，以提高影像分類的準確性和穩健性。因此，我們的方法旨在引導生成式模型合成具有高認識論不確定性的資料，因為認識論不確定性的高指標表示訓練集中代表性不足的資料點。在影像生成過程中，我們將自動編碼器重建的影像輸入分類器，並計算類別機率分佈的互資訊作為不確定性的指標。我們透過優化流程來改變自動編碼器的特徵空間，目標是最大化解碼影像上分類器的未確定性。透過訓練此類資料，我們改善了在多項分類任務中對測試時間資料擴充和對抗攻擊的效能和穩健性。

##### **AI for the prediction of early stages of Alzheimer's disease from neuroimaging biomarkers -- A narrative review of a growing field**
2406.17822v1 by Thorsten Rudroff, Oona Rainio, Riku Klén

Objectives: The objectives of this narrative review are to summarize the
current state of AI applications in neuroimaging for early Alzheimer's disease
(AD) prediction and to highlight the potential of AI techniques in improving
early AD diagnosis, prognosis, and management.
  Methods: We conducted a narrative review of studies using AI techniques
applied to neuroimaging data for early AD prediction. We examined
single-modality studies using structural MRI and PET imaging, as well as
multi-modality studies integrating multiple neuroimaging techniques and
biomarkers. Furthermore, they reviewed longitudinal studies that model AD
progression and identify individuals at risk of rapid decline.
  Results: Single-modality studies using structural MRI and PET imaging have
demonstrated high accuracy in classifying AD and predicting progression from
mild cognitive impairment (MCI) to AD. Multi-modality studies, integrating
multiple neuroimaging techniques and biomarkers, have shown improved
performance and robustness compared to single-modality approaches. Longitudinal
studies have highlighted the value of AI in modeling AD progression and
identifying individuals at risk of rapid decline. However, challenges remain in
data standardization, model interpretability, generalizability, clinical
integration, and ethical considerations.
  Conclusion: AI techniques applied to neuroimaging data have the potential to
improve early AD diagnosis, prognosis, and management. Addressing challenges
related to data standardization, model interpretability, generalizability,
clinical integration, and ethical considerations is crucial for realizing the
full potential of AI in AD research and clinical practice. Collaborative
efforts among researchers, clinicians, and regulatory agencies are needed to
develop reliable, robust, and ethical AI tools that can benefit AD patients and
society.

摘要：<paragraph>目標：本敘述性回顧的目標是總結 AI 應用於神經影像學以進行阿茲海默症 (AD) 早期預測的現況，並強調 AI 技術在改善 AD 早期診斷、預後和管理方面的潛力。
方法：我們對使用 AI 技術應用於神經影像學數據以進行早期 AD 預測的研究進行了敘述性回顧。我們檢視了使用結構性 MRI 和 PET 影像的單一方式研究，以及整合多種神經影像學技術和生物標記的多方式研究。此外，他們回顧了對 AD 進程建模並找出快速惡化風險個體的縱向研究。
結果：使用結構性 MRI 和 PET 影像的單一方式研究已證明在分類 AD 和預測從輕度認知障礙 (MCI) 到 AD 的進程方面具有很高的準確性。整合多種神經影像學技術和生物標記的多方式研究已顯示出與單一方式方法相比，改進的效能和穩健性。縱向研究強調了 AI 在對 AD 進程建模和找出快速惡化風險個體方面的價值。然而，數據標準化、模型可解釋性、可概化性、臨床整合和倫理考量仍存在挑戰。
結論：應用於神經影像學數據的 AI 技術有潛力改善 AD 早期診斷、預後和管理。解決與數據標準化、模型可解釋性、可概化性、臨床整合和倫理考量相關的挑戰對於實現 AI 在 AD 研究和臨床實務中的全部潛力至關重要。研究人員、臨床醫生和法規機構之間的合作努力對於開發可靠、穩健且符合倫理的 AI 工具是必要的，這些工具可以使 AD 患者和社會受益。</paragraph>

##### **Task-Agnostic Federated Learning**
2406.17235v1 by Zhengtao Yao, Hong Nguyen, Ajitesh Srivastava, Jose Luis Ambite

In the realm of medical imaging, leveraging large-scale datasets from various
institutions is crucial for developing precise deep learning models, yet
privacy concerns frequently impede data sharing. federated learning (FL)
emerges as a prominent solution for preserving privacy while facilitating
collaborative learning. However, its application in real-world scenarios faces
several obstacles, such as task & data heterogeneity, label scarcity,
non-identically distributed (non-IID) data, computational vaiation, etc. In
real-world, medical institutions may not want to disclose their tasks to FL
server and generalization challenge of out-of-network institutions with un-seen
task want to join the on-going federated system. This study address
task-agnostic and generalization problem on un-seen tasks by adapting
self-supervised FL framework. Utilizing Vision Transformer (ViT) as consensus
feature encoder for self-supervised pre-training, no initial labels required,
the framework enabling effective representation learning across diverse
datasets and tasks. Our extensive evaluations, using various real-world non-IID
medical imaging datasets, validate our approach's efficacy, retaining 90\% of
F1 accuracy with only 5\% of the training data typically required for
centralized approaches and exhibiting superior adaptability to
out-of-distribution task. The result indicate that federated learning
architecture can be a potential approach toward multi-task foundation modeling.

摘要：在医学影像领域，利用来自不同机构的大规模数据集对于开发精确的深度学习模型至关重要，但隐私问题经常阻碍数据共享。联邦学习 (FL) 作为一种既能保护隐私又能促进协作学习的突出解决方案而出现。然而，其在现实场景中的应用面临着一些障碍，例如任务和数据异构性、标签稀缺性、非同分布（非 IID）数据、计算变异等。在现实世界中，医疗机构可能不想向 FL 服务器透露其任务，并且网络外机构在遇到未见任务时想要加入正在进行的联邦系统的泛化挑战。本研究通过采用自监督 FL 框架来解决与任务无关和未见任务的泛化问题。利用视觉 Transformer (ViT) 作为自监督预训练的共识特征编码器，无需初始标签，该框架能够在不同的数据集和任务中进行有效的表示学习。我们使用各种现实世界非 IID 医学影像数据集进行的广泛评估验证了我们方法的有效性，仅使用集中式方法通常所需的 5% 的训练数据就保留了 90% 的 F1 准确度，并且表现出对分布外任务的卓越适应性。结果表明，联邦学习架构可以成为多任务基础建模的潜在方法。

##### **Scalable Artificial Intelligence for Science: Perspectives, Methods and Exemplars**
2406.17812v1 by Wesley Brewer, Aditya Kashi, Sajal Dash, Aristeidis Tsaris, Junqi Yin, Mallikarjun Shankar, Feiyi Wang

In a post-ChatGPT world, this paper explores the potential of leveraging
scalable artificial intelligence for scientific discovery. We propose that
scaling up artificial intelligence on high-performance computing platforms is
essential to address such complex problems. This perspective focuses on
scientific use cases like cognitive simulations, large language models for
scientific inquiry, medical image analysis, and physics-informed approaches.
The study outlines the methodologies needed to address such challenges at scale
on supercomputers or the cloud and provides exemplars of such approaches
applied to solve a variety of scientific problems.

摘要：在 ChatGPT 後的世界中，本文探討了利用可擴充的人工智慧進行科學發現的潛力。我們提出，在高性能運算平台上擴充人工智慧對於解決這些複雜問題至關重要。此觀點著重於科學用例，例如認知模擬、用於科學探究的大型語言模型、醫學影像分析和物理資訊方法。本研究概述了解決這些挑戰所需的技術，以便在超級電腦或雲端擴充，並提供此類方法的範例，以解決各種科學問題。

##### **PIC2O-Sim: A Physics-Inspired Causality-Aware Dynamic Convolutional Neural Operator for Ultra-Fast Photonic Device FDTD Simulation**
2406.17810v1 by Pingchuan Ma, Haoyu Yang, Zhengqi Gao, Duane S. Boning, Jiaqi Gu

The finite-difference time-domain (FDTD) method, which is important in
photonic hardware design flow, is widely adopted to solve time-domain Maxwell
equations. However, FDTD is known for its prohibitive runtime cost, taking
minutes to hours to simulate a single device. Recently, AI has been applied to
realize orders-of-magnitude speedup in partial differential equation (PDE)
solving. However, AI-based FDTD solvers for photonic devices have not been
clearly formulated. Directly applying off-the-shelf models to predict the
optical field dynamics shows unsatisfying fidelity and efficiency since the
model primitives are agnostic to the unique physical properties of Maxwell
equations and lack algorithmic customization. In this work, we thoroughly
investigate the synergy between neural operator designs and the physical
property of Maxwell equations and introduce a physics-inspired AI-based FDTD
prediction framework PIC2O-Sim which features a causality-aware dynamic
convolutional neural operator as its backbone model that honors the space-time
causality constraints via careful receptive field configuration and explicitly
captures the permittivity-dependent light propagation behavior via an efficient
dynamic convolution operator. Meanwhile, we explore the trade-offs among
prediction scalability, fidelity, and efficiency via a multi-stage partitioned
time-bundling technique in autoregressive prediction. Multiple key techniques
have been introduced to mitigate iterative error accumulation while maintaining
efficiency advantages during autoregressive field prediction. Extensive
evaluations on three challenging photonic device simulation tasks have shown
the superiority of our PIC2O-Sim method, showing 51.2% lower roll-out
prediction error, 23.5 times fewer parameters than state-of-the-art neural
operators, providing 300-600x higher simulation speed than an open-source FDTD
numerical solver.

摘要：時域有限差分法 (FDTD) は、光ハードウェア設計フローにおいて重要な手法で、時領域マクスウェル方程式を解くために広く採用されています。ただし、FDTD はその膨大なランタイムコストで知られており、1 つのデバイスをシミュレートするのに数分から数時間かかります。最近、AI が偏微分方程式 (PDE) の解法における桁違いの高速化を実現するために適用されています。しかし、光デバイス向けの AI ベースの FDTD ソルバーは明確に定式化されていません。市販のモデルをそのまま適用して光場のダイナミクスを予測すると、モデルの基本要素がマクスウェル方程式の固有の物理特性に無関係でアルゴリズムのカスタマイズが欠如しているため、忠実度と効率が不十分になります。この研究では、ニューラル演算子の設計とマクスウェル方程式の物理特性との相乗効果を徹底的に調査し、物理学に基づく AI ベースの FDTD 予測フレームワーク PIC2O-Sim を導入します。PIC2O-Sim は、慎重な受容野構成によって時空間因果律制約を尊重し、効率的な動的畳み込み演算子によって誘電率依存の光伝搬挙動を明示的に捉える、因果律を認識する動的畳み込みニューラル演算子をバックボーンモデルとして備えています。その一方で、自己回帰予測におけるマルチステージパーティション時間バンドリング手法によって、予測のスケーラビリティ、忠実度、効率の間のトレードオフを調査します。自己回帰場の予測中に効率の利点を維持しながら反復的な誤りの蓄積を軽減するために、複数の主要な手法が導入されました。3 つの困難な光デバイスシミュレーションタスクに関する広範な評価により、PIC2O-Sim 手法の優位性が示され、51.2% 低いロールアウト予測誤差、最先端のニューラル演算子よりも 23.5 倍少ないパラメーター、オープンソース FDTD 数値ソルバーよりも 300 ～ 600 倍高速なシミュレーション速度が提供されています。

##### **The Responsible Foundation Model Development Cheatsheet: A Review of Tools & Resources**
2406.16746v2 by Shayne Longpre, Stella Biderman, Alon Albalak, Hailey Schoelkopf, Daniel McDuff, Sayash Kapoor, Kevin Klyman, Kyle Lo, Gabriel Ilharco, Nay San, Maribeth Rauh, Aviya Skowron, Bertie Vidgen, Laura Weidinger, Arvind Narayanan, Victor Sanh, David Adelani, Percy Liang, Rishi Bommasani, Peter Henderson, Sasha Luccioni, Yacine Jernite, Luca Soldaini

Foundation model development attracts a rapidly expanding body of
contributors, scientists, and applications. To help shape responsible
development practices, we introduce the Foundation Model Development
Cheatsheet: a growing collection of 250+ tools and resources spanning text,
vision, and speech modalities. We draw on a large body of prior work to survey
resources (e.g. software, documentation, frameworks, guides, and practical
tools) that support informed data selection, processing, and understanding,
precise and limitation-aware artifact documentation, efficient model training,
advance awareness of the environmental impact from training, careful model
evaluation of capabilities, risks, and claims, as well as responsible model
release, licensing and deployment practices. We hope this curated collection of
resources helps guide more responsible development. The process of curating
this list, enabled us to review the AI development ecosystem, revealing what
tools are critically missing, misused, or over-used in existing practices. We
find that (i) tools for data sourcing, model evaluation, and monitoring are
critically under-serving ethical and real-world needs, (ii) evaluations for
model safety, capabilities, and environmental impact all lack reproducibility
and transparency, (iii) text and particularly English-centric analyses continue
to dominate over multilingual and multi-modal analyses, and (iv) evaluation of
systems, rather than just models, is needed so that capabilities and impact are
assessed in context.

摘要：基礎模型開發吸引了迅速擴展的貢獻者、科學家和應用程式主體。為了協助塑造負責任的開發實務，我們引進了「基礎模型開發秘笈」：一個包含超過 250 個工具和資源的成長中集合，涵蓋文字、視覺和語音模式。我們利用大量的先前工作來調查資源（例如軟體、文件、架構、指南和實用工具），這些資源支援明智的資料選擇、處理和理解、精確且具備限制意識的人工產出文件、有效率的模型訓練、提前了解訓練對環境的影響、仔細評估模型的能力、風險和聲明，以及負責任的模型發布、授權和部署實務。我們希望這個經過整理的資源集合有助於引導更負責任的開發。整理這個清單的過程讓我們得以檢視 AI 開發生態系統，揭露現有實務中哪些工具嚴重不足、使用不當或過度使用。我們發現：(i) 資料來源、模型評估和監控的工具嚴重無法滿足道德和現實世界的需求，(ii) 模型安全性、能力和環境影響的評估都缺乏可複製性和透明度，(iii) 文字和特別是英語為中心的分析持續主導多語言和多模式分析，而且 (iv) 需要評估系統，而不仅仅是模型，以便在上下文中評估能力和影響。

##### **Evaluation of Language Models in the Medical Context Under Resource-Constrained Settings**
2406.16611v1 by Andrea Posada, Daniel Rueckert, Felix Meissen, Philip Müller

Since the emergence of the Transformer architecture, language model
development has increased, driven by their promising potential. However,
releasing these models into production requires properly understanding their
behavior, particularly in sensitive domains such as medicine. Despite this
need, the medical literature still lacks technical assessments of pre-trained
language models, which are especially valuable in resource-constrained settings
in terms of computational power or limited budget. To address this gap, we
provide a comprehensive survey of language models in the medical domain. In
addition, we selected a subset of these models for thorough evaluation,
focusing on classification and text generation tasks. Our subset encompasses 53
models, ranging from 110 million to 13 billion parameters, spanning the three
families of Transformer-based models and from diverse knowledge domains. This
study employs a series of approaches for text classification together with
zero-shot prompting instead of model training or fine-tuning, which closely
resembles the limited resource setting in which many users of language models
find themselves. Encouragingly, our findings reveal remarkable performance
across various tasks and datasets, underscoring the latent potential of certain
models to contain medical knowledge, even without domain specialization.
Consequently, our study advocates for further exploration of model applications
in medical contexts, particularly in resource-constrained settings. The code is
available on https://github.com/anpoc/Language-models-in-medicine.

摘要：自 Transformer 架構問世以來，語言模型在潛力備受看好下，發展如火如荼。然而，將這些模型應用於生產環境，需要適當地了解其行為，特別是在醫學等敏感領域。儘管有此需求，醫學文獻仍缺乏對預先訓練語言模型的技術評估，而這在運算能力或預算有限的資源受限環境中特別有價值。為了彌補這個缺口，我們對醫學領域的語言模型進行了全面的調查。此外，我們挑選了其中一部分模型進行徹底評估，重點在於分類和文字生成任務。我們的子集涵蓋 53 個模型，參數從 1.1 億到 130 億不等，橫跨 Transformer 為基礎的模型的三個系列，且涵蓋多元的知識領域。本研究採用一系列文字分類方法，並搭配零次提示，而非模型訓練或微調，這與許多語言模型使用者身處的資源受限環境非常類似。令人振奮的是，我們的發現顯示在各種任務和資料集上都有傑出的表現，強調了某些模型在沒有領域專業知識的情況下，蘊含醫學知識的潛力。因此，我們的研究主張進一步探討模型在醫療環境中的應用，特別是在資源受限的環境中。程式碼可在 https://github.com/anpoc/Language-models-in-medicine 取得。

##### **Guardrails for avoiding harmful medical product recommendations and off-label promotion in generative AI models**
2406.16455v1 by Daniel Lopez-Martinez

Generative AI (GenAI) models have demonstrated remarkable capabilities in a
wide variety of medical tasks. However, as these models are trained using
generalist datasets with very limited human oversight, they can learn uses of
medical products that have not been adequately evaluated for safety and
efficacy, nor approved by regulatory agencies. Given the scale at which GenAI
may reach users, unvetted recommendations pose a public health risk. In this
work, we propose an approach to identify potentially harmful product
recommendations, and demonstrate it using a recent multimodal large language
model.

摘要：生成式 AI (GenAI) 模型在各种医疗任務中展示出非凡的能力。然而，由於這些模型是使用非常有限的人類監督的一般資料集進行訓練，因此它們可以學習尚未充分評估其安全性和有效性，也未經監管機構批准的醫療產品用途。鑑於 GenAI 可能接觸使用者的規模，未經審查的建議會構成公共健康風險。在這項工作中，我們提出了一種識別潛在有害產品建議的方法，並使用最近的多模態大型語言模型進行示範。

##### **A large language model for predicting T cell receptor-antigen binding specificity**
2406.16995v1 by Xing Fang, Chenpeng Yu, Shiye Tian, Hui Liu

The human immune response depends on the binding of T-cell receptors (TCRs)
to antigens (pTCR), which elicits the T cells to eliminate viruses, tumor
cells, and other pathogens. The ability of human immunity system responding to
unknown viruses and bacteria stems from the TCR diversity. However, this vast
diversity poses challenges on the TCR-antigen binding prediction methods. In
this study, we propose a Masked Language Model (MLM), referred to as tcrLM, to
overcome limitations in model generalization. Specifically, we randomly masked
sequence segments and train tcrLM to infer the masked segment, thereby extract
expressive feature from TCR sequences. Meanwhile, we introduced virtual
adversarial training techniques to enhance the model's robustness. We built the
largest TCR CDR3 sequence dataset to date (comprising 2,277,773,840 residuals),
and pre-trained tcrLM on this dataset. Our extensive experimental results
demonstrate that tcrLM achieved AUC values of 0.937 and 0.933 on independent
test sets and external validation sets, respectively, which remarkably
outperformed four previously published prediction methods. On a large-scale
COVID-19 pTCR binding test set, our method outperforms the current
state-of-the-art method by at least 8%, highlighting the generalizability of
our method. Furthermore, we validated that our approach effectively predicts
immunotherapy response and clinical outcomes on a clinical cohorts. These
findings clearly indicate that tcrLM exhibits significant potential in
predicting antigenic immunogenicity.

摘要：人體免疫反應取決於 T 細胞受體 (TCR) 與抗原 (pTCR) 的結合，這會引發 T 細胞消除病毒、腫瘤細胞和其他病原體。人體免疫系統對未知病毒和細菌做出反應的能力源於 TCR 的多樣性。然而，這種廣泛的多樣性對 TCR-抗原結合預測方法提出了挑戰。在這項研究中，我們提出了一個稱為 tcrLM 的遮罩語言模型 (MLM)，以克服模型概括中的限制。具體來說，我們隨機遮罩序列片段並訓練 tcrLM 推斷遮罩片段，從而從 TCR 序列中提取表達特徵。同時，我們引入了虛擬對抗訓練技術來增強模型的魯棒性。我們建立了迄今為止最大的 TCR CDR3 序列數據集（包含 2,277,773,840 個殘基），並在該數據集上預訓練了 tcrLM。我們廣泛的實驗結果表明，tcrLM 在獨立測試集和外部驗證集上分別實現了 0.937 和 0.933 的 AUC 值，這顯著優於四種先前發表的預測方法。在一個大規模的 COVID-19 pTCR 結合測試集中，我們的模型比當前最先進的模型至少高出 8%，突出了我們模型的概括性。此外，我們驗證了我們的模型有效預測了臨床人群的免疫治療反應和臨床結果。這些發現明確表明 tcrLM 在預測抗原免疫原性方面具有顯著的潛力。

##### **Graph-Augmented LLMs for Personalized Health Insights: A Case Study in Sleep Analysis**
2406.16252v2 by Ajan Subramanian, Zhongqi Yang, Iman Azimi, Amir M. Rahmani

Health monitoring systems have revolutionized modern healthcare by enabling
the continuous capture of physiological and behavioral data, essential for
preventive measures and early health intervention. While integrating this data
with Large Language Models (LLMs) has shown promise in delivering interactive
health advice, traditional methods like Retrieval-Augmented Generation (RAG)
and fine-tuning often fail to fully utilize the complex, multi-dimensional, and
temporally relevant data from wearable devices. These conventional approaches
typically provide limited actionable and personalized health insights due to
their inadequate capacity to dynamically integrate and interpret diverse health
data streams. In response, this paper introduces a graph-augmented LLM
framework designed to significantly enhance the personalization and clarity of
health insights. Utilizing a hierarchical graph structure, the framework
captures inter and intra-patient relationships, enriching LLM prompts with
dynamic feature importance scores derived from a Random Forest Model. The
effectiveness of this approach is demonstrated through a sleep analysis case
study involving 20 college students during the COVID-19 lockdown, highlighting
the potential of our model to generate actionable and personalized health
insights efficiently. We leverage another LLM to evaluate the insights for
relevance, comprehensiveness, actionability, and personalization, addressing
the critical need for models that process and interpret complex health data
effectively. Our findings show that augmenting prompts with our framework
yields significant improvements in all 4 criteria. Through our framework, we
can elicit well-crafted, more thoughtful responses tailored to a specific
patient.

摘要：健康監控系統透過持續收集生理和行為資料，徹底改變了現代醫療保健，這些資料對於預防措施和早期健康干預至關重要。雖然將這些資料與大型語言模型 (LLM) 整合，已展現出提供互動式健康建議的潛力，但傳統方法（例如檢索擴充生成 (RAG) 和微調）通常無法充分利用穿戴式裝置中複雜、多面向且與時間相關的資料。這些傳統方法通常會提供有限的可行且個人化的健康見解，因為它們無法動態整合和詮釋不同的健康資料串流。為了解決這個問題，本文介紹了一個圖形擴充 LLM 架構，旨在大幅提升健康見解的個人化和清晰度。這個架構利用階層式圖形結構，擷取患者之間和患者內部的關係，並使用從 Random Forest 模型衍生的動態特徵重要性評分，豐富 LLM 提示。透過一項睡眠分析案例研究（在 COVID-19 封鎖期間針對 20 名大學生進行）證明了這個方法的有效性，突顯了我們的模型在有效產生可行且個人化的健康見解方面的潛力。我們利用另一個 LLM 評估見解的相關性、全面性、可行性和個人化，滿足了模型有效處理和詮釋複雜健康資料的關鍵需求。我們的研究結果顯示，使用我們的架構擴充提示，可以在所有 4 個標準中大幅改善。透過我們的架構，我們可以引發精心設計、更周全的回應，針對特定患者量身打造。

##### **Continuous Output Personality Detection Models via Mixed Strategy Training**
2406.16223v1 by Rong Wang, Kun Sun

The traditional personality models only yield binary results. This paper
presents a novel approach for training personality detection models that
produce continuous output values, using mixed strategies. By leveraging the
PANDORA dataset, which includes extensive personality labeling of Reddit
comments, we developed models that predict the Big Five personality traits with
high accuracy. Our approach involves fine-tuning a RoBERTa-base model with
various strategies such as Multi-Layer Perceptron (MLP) integration, and
hyperparameter tuning. The results demonstrate that our models significantly
outperform traditional binary classification methods, offering precise
continuous outputs for personality traits, thus enhancing applications in AI,
psychology, human resources, marketing and health care fields.

摘要：傳統的人格模型只產生二進制結果。本文提出了一種新穎的方法，用混合策略訓練人格檢測模型，以產生連續的輸出值。通過利用 PANDORA 數據集，其中包括對 Reddit 評論的廣泛人格標籤，我們開發了可以高精度預測五大性格特質的模型。我們的做法涉及使用多層感知器 (MLP) 集成和超參數調整等各種策略來微調 RoBERTa 基礎模型。結果表明，我們的模型明顯優於傳統的二元分類方法，為人格特質提供了精確的連續輸出，從而增強了在 AI、心理學、人力資源、營銷和醫療保健領域的應用。

##### **On Instabilities of Unsupervised Denoising Diffusion Models in Magnetic Resonance Imaging Reconstruction**
2406.16983v1 by Tianyu Han, Sven Nebelung, Firas Khader, Jakob Nikolas Kather, Daniel Truhn

Denoising diffusion models offer a promising approach to accelerating
magnetic resonance imaging (MRI) and producing diagnostic-level images in an
unsupervised manner. However, our study demonstrates that even tiny worst-case
potential perturbations transferred from a surrogate model can cause these
models to generate fake tissue structures that may mislead clinicians. The
transferability of such worst-case perturbations indicates that the robustness
of image reconstruction may be compromised due to MR system imperfections or
other sources of noise. Moreover, at larger perturbation strengths, diffusion
models exhibit Gaussian noise-like artifacts that are distinct from those
observed in supervised models and are more challenging to detect. Our results
highlight the vulnerability of current state-of-the-art diffusion-based
reconstruction models to possible worst-case perturbations and underscore the
need for further research to improve their robustness and reliability in
clinical settings.

摘要：去噪擴散模型提供了一種有前景的方法，可以加速磁共振成像 (MRI) 並以無監督的方式產生診斷級別的影像。然而，我們的研究表明，即使是從代理模型傳輸的極小最壞情況潛在擾動，也會導致這些模型產生可能誤導臨床醫生的假組織結構。這種最壞情況擾動的可傳遞性表明，由於 MR 系統缺陷或其他雜訊來源，影像重建的穩健性可能會受到損害。此外，在較大的擾動強度下，擴散模型會表現出與監督模型中觀察到的不同的高斯雜訊樣式的人工製品，並且更難以檢測。我們的結果突顯了當前最先進的基於擴散的重建模型對可能的最壞情況擾動的脆弱性，並強調需要進一步研究以提高其在臨床環境中的穩健性和可靠性。

##### **Research on Disease Prediction Model Construction Based on Computer AI deep Learning Technology**
2406.16982v1 by Yang Lin, Muqing Li, Ziyi Zhu, Yinqiu Feng, Lingxi Xiao, Zexi Chen

The prediction of disease risk factors can screen vulnerable groups for
effective prevention and treatment, so as to reduce their morbidity and
mortality. Machine learning has a great demand for high-quality labeling
information, and labeling noise in medical big data poses a great challenge to
efficient disease risk warning methods. Therefore, this project intends to
study the robust learning algorithm and apply it to the early warning of
infectious disease risk. A dynamic truncated loss model is proposed, which
combines the traditional mutual entropy implicit weight feature with the mean
variation feature. It is robust to label noise. A lower bound on training loss
is constructed, and a method based on sampling rate is proposed to reduce the
gradient of suspected samples to reduce the influence of noise on training
results. The effectiveness of this method under different types of noise was
verified by using a stroke screening data set as an example. This method
enables robust learning of data containing label noise.

摘要：疾病風險因子的預測可以篩選出脆弱族群，進行有效的預防和治療，以降低其罹病率和死亡率。機器學習對於高品質的標籤資訊有極大的需求，而醫療大數據中的標籤雜訊對於疾病風險預警方法的有效性造成極大的挑戰。因此，本計畫擬探討對抗式學習演算法，並將其應用於傳染病風險的預警。提出一個動態截斷損失模型，將傳統的互資訊隱含權重特徵與平均變異特徵結合，對標籤雜訊具有魯棒性。建構訓練損失的下界，並提出基於抽樣率的方法，降低疑似樣本的梯度，以降低雜訊對訓練結果的影響。以中風篩檢資料集為例，驗證此方法在不同型態雜訊下的有效性。此方法能對含有標籤雜訊的資料進行魯棒學習。

##### **Towards Open Respiratory Acoustic Foundation Models: Pretraining and Benchmarking**
2406.16148v1 by Yuwei Zhang, Tong Xia, Jing Han, Yu Wu, Georgios Rizos, Yang Liu, Mohammed Mosuily, Jagmohan Chauhan, Cecilia Mascolo

Respiratory audio, such as coughing and breathing sounds, has predictive
power for a wide range of healthcare applications, yet is currently
under-explored. The main problem for those applications arises from the
difficulty in collecting large labeled task-specific data for model
development. Generalizable respiratory acoustic foundation models pretrained
with unlabeled data would offer appealing advantages and possibly unlock this
impasse. However, given the safety-critical nature of healthcare applications,
it is pivotal to also ensure openness and replicability for any proposed
foundation model solution. To this end, we introduce OPERA, an OPEn Respiratory
Acoustic foundation model pretraining and benchmarking system, as the first
approach answering this need. We curate large-scale respiratory audio datasets
(~136K samples, 440 hours), pretrain three pioneering foundation models, and
build a benchmark consisting of 19 downstream respiratory health tasks for
evaluation. Our pretrained models demonstrate superior performance (against
existing acoustic models pretrained with general audio on 16 out of 19 tasks)
and generalizability (to unseen datasets and new respiratory audio modalities).
This highlights the great promise of respiratory acoustic foundation models and
encourages more studies using OPERA as an open resource to accelerate research
on respiratory audio for health. The system is accessible from
https://github.com/evelyn0414/OPERA.

摘要：呼吸音訊，例如咳嗽和呼吸聲，對於廣泛的醫療保健應用具有預測能力，但目前仍未得到充分的探討。對於這些應用來說，主要問題在於難以收集用於模型開發的大量標記特定任務資料。使用未標記資料預先訓練的可概化呼吸聲學基礎模型將提供有吸引力的優勢，並有可能打破這種僵局。然而，鑑於醫療保健應用的安全性至關重要，因此對於任何提出的基礎模型解決方案，確保開放性和可複製性也至關重要。為此，我們引入了 OPERA，一個開放的呼吸聲學基礎模型預訓練和基準系統，作為滿足此需求的第一種方法。我們策劃了大規模的呼吸音訊資料集（約 136K 個樣本，440 小時），預先訓練了三個開創性的基礎模型，並建立了一個基準，其中包含 19 個下游呼吸健康任務以供評估。我們的預訓練模型展示出卓越的效能（在 19 個任務中有 16 個任務優於使用一般音訊預先訓練的現有聲學模型）和概化能力（對未見過的資料集和新的呼吸音訊方式）。這突顯了呼吸聲學基礎模型的巨大前景，並鼓勵更多研究使用 OPERA 作為開放資源，以加速呼吸音訊在健康方面的研究。該系統可從 https://github.com/evelyn0414/OPERA 取得。

##### **Predicting Individual Depression Symptoms from Acoustic Features During Speech**
2406.16000v1 by Sebastian Rodriguez, Sri Harsha Dumpala, Katerina Dikaios, Sheri Rempel, Rudolf Uher, Sageev Oore

Current automatic depression detection systems provide predictions directly
without relying on the individual symptoms/items of depression as denoted in
the clinical depression rating scales. In contrast, clinicians assess each item
in the depression rating scale in a clinical setting, thus implicitly providing
a more detailed rationale for a depression diagnosis. In this work, we make a
first step towards using the acoustic features of speech to predict individual
items of the depression rating scale before obtaining the final depression
prediction. For this, we use convolutional (CNN) and recurrent (long short-term
memory (LSTM)) neural networks. We consider different approaches to learning
the temporal context of speech. Further, we analyze two variants of voting
schemes for individual item prediction and depression detection. We also
include an animated visualization that shows an example of item prediction over
time as the speech progresses.

摘要：現有的自動憂鬱症偵測系統會直接提供預測，而不依賴臨床憂鬱症評分量表中所表示的個別症狀/項目。相較之下，臨床醫生會在臨床環境中評估憂鬱症評分量表中的每個項目，因此會隱含提供憂鬱症診斷的更詳細依據。在這項工作中，我們踏出第一步，使用語音的音訊特徵來預測憂鬱症評分量表的個別項目，然後再取得最終的憂鬱症預測。為此，我們使用卷積 (CNN) 和遞迴 (長短期記憶 (LSTM)) 神經網路。我們考慮不同的方法來學習語音的時間脈絡。此外，我們分析兩種投票方案的變體，用於個別項目預測和憂鬱症偵測。我們也包含一個動畫視覺化，顯示隨著語音進展，項目預測的一個範例。

##### **Evaluating the Effectiveness of the Foundational Models for Q&A Classification in Mental Health care**
2406.15966v1 by Hassan Alhuzali, Ashwag Alasmari

Pre-trained Language Models (PLMs) have the potential to transform mental
health support by providing accessible and culturally sensitive resources.
However, despite this potential, their effectiveness in mental health care and
specifically for the Arabic language has not been extensively explored. To
bridge this gap, this study evaluates the effectiveness of foundational models
for classification of Questions and Answers (Q&A) in the domain of mental
health care. We leverage the MentalQA dataset, an Arabic collection featuring
Q&A interactions related to mental health. In this study, we conducted
experiments using four different types of learning approaches: traditional
feature extraction, PLMs as feature extractors, Fine-tuning PLMs and prompting
large language models (GPT-3.5 and GPT-4) in zero-shot and few-shot learning
settings. While traditional feature extractors combined with Support Vector
Machines (SVM) showed promising performance, PLMs exhibited even better results
due to their ability to capture semantic meaning. For example, MARBERT achieved
the highest performance with a Jaccard Score of 0.80 for question
classification and a Jaccard Score of 0.86 for answer classification. We
further conducted an in-depth analysis including examining the effects of
fine-tuning versus non-fine-tuning, the impact of varying data size, and
conducting error analysis. Our analysis demonstrates that fine-tuning proved to
be beneficial for enhancing the performance of PLMs, and the size of the
training data played a crucial role in achieving high performance. We also
explored prompting, where few-shot learning with GPT-3.5 yielded promising
results. There was an improvement of 12% for question and classification and
45% for answer classification. Based on our findings, it can be concluded that
PLMs and prompt-based approaches hold promise for mental health support in
Arabic.

摘要：<paragraph>預訓練語言模型 (PLM) 有潛力透過提供可存取且具文化敏感度的資源來轉化心理健康支持。
然而，儘管有此潛力，它們在心理保健中的有效性，特別是對於阿拉伯語，尚未廣泛探討。為了彌補此差距，本研究評估基礎模型在心理保健領域中對問題與解答 (Q&A) 進行分類的有效性。我們利用 MentalQA 資料集，這是一個以阿拉伯語為特色的集合，包含與心理健康相關的 Q&A 互動。在本研究中，我們使用四種不同類型的學習方法進行實驗：傳統特徵萃取、PLM 作為特徵萃取器、微調 PLM，以及在零次學習和少次學習設定中提示大型語言模型 (GPT-3.5 和 GPT-4)。雖然傳統特徵萃取器結合支援向量機 (SVM) 顯示出有希望的效能，但 PLM 由於能夠擷取語義意義，因此表現得更好。例如，MARBERT 在問題分類中達到最高效能，Jaccard 得分為 0.80，在答案分類中 Jaccard 得分為 0.86。我們進一步進行深入分析，包括檢查微調與非微調的影響、不同資料大小的影響，以及進行錯誤分析。我們的分析表明，微調被證明有助於提升 PLM 的效能，而訓練資料的大小在達成高效能中扮演至關重要的角色。我們也探討了提示，其中使用 GPT-3.5 的少次學習產生有希望的結果。問題與分類進步了 12%，答案分類進步了 45%。根據我們的發現，可以得出結論，PLM 和基於提示的方法有望為阿拉伯語的心理健康提供支持。</paragraph>

##### **SEDMamba: Enhancing Selective State Space Modelling with Bottleneck Mechanism and Fine-to-Coarse Temporal Fusion for Efficient Error Detection in Robot-Assisted Surgery**
2406.15920v1 by Jialang Xu, Nazir Sirajudeen, Matthew Boal, Nader Francis, Danail Stoyanov, Evangelos Mazomenos

Automated detection of surgical errors can improve robotic-assisted surgery.
Despite promising progress, existing methods still face challenges in capturing
rich temporal context to establish long-term dependencies while maintaining
computational efficiency. In this paper, we propose a novel hierarchical model
named SEDMamba, which incorporates the selective state space model (SSM) into
surgical error detection, facilitating efficient long sequence modelling with
linear complexity. SEDMamba enhances selective SSM with bottleneck mechanism
and fine-to-coarse temporal fusion (FCTF) to detect and temporally localize
surgical errors in long videos. The bottleneck mechanism compresses and
restores features within their spatial dimension, thereby reducing
computational complexity. FCTF utilizes multiple dilated 1D convolutional
layers to merge temporal information across diverse scale ranges, accommodating
errors of varying durations. Besides, we deploy an established observational
clinical human reliability assessment tool (OCHRA) to annotate the errors of
suturing tasks in an open-source radical prostatectomy dataset (SAR-RARP50),
constructing the first frame-level in-vivo surgical error detection dataset to
support error detection in real-world scenarios. Experimental results
demonstrate that our SEDMamba outperforms state-of-the-art methods with at
least 1.82% AUC and 3.80% AP performance gain with significantly reduced
computational complexity.

摘要：自動偵測手術錯誤可以改善機器人輔助手術。
儘管有令人振奮的進展，現有方法在捕捉豐富的時間背景以建立長期依賴關係的同時，在維持運算效率方面仍面臨挑戰。在本文中，我們提出一個名為 SEDMamba 的新分層模型，它將選擇性狀態空間模型 (SSM) 納入手術錯誤偵測中，促進具有線性複雜度的有效長序列建模。SEDMamba 以瓶頸機制和精細到粗略的時間融合 (FCTF) 增強選擇性 SSM，以偵測和暫時定位長影片中的手術錯誤。瓶頸機制在它們的空間維度內壓縮和還原特徵，從而降低運算複雜度。FCTF 使用多個膨脹的 1D 捲積層來合併不同範圍的時間資訊，容納不同持續時間的錯誤。此外，我們部署一個已建立的觀察性臨床人類可靠性評估工具 (OCHRA) 來註解開源根治性前列腺切除術資料集 (SAR-RARP50) 中縫合任務的錯誤，建構第一個幀級別的體內手術錯誤偵測資料集，以支援在真實世界場景中偵測錯誤。實驗結果表明，我們的 SEDMamba 以至少 1.82% AUC 和 3.80% AP 效能提升，優於最先進的方法，同時大幅降低運算複雜度。

##### **Real-time Speech Summarization for Medical Conversations**
2406.15888v1 by Khai Le-Duc, Khai-Nguyen Nguyen, Long Vo-Dang, Truong-Son Hy

In doctor-patient conversations, identifying medically relevant information
is crucial, posing the need for conversation summarization. In this work, we
propose the first deployable real-time speech summarization system for
real-world applications in industry, which generates a local summary after
every N speech utterances within a conversation and a global summary after the
end of a conversation. Our system could enhance user experience from a business
standpoint, while also reducing computational costs from a technical
perspective. Secondly, we present VietMed-Sum which, to our knowledge, is the
first speech summarization dataset for medical conversations. Thirdly, we are
the first to utilize LLM and human annotators collaboratively to create gold
standard and synthetic summaries for medical conversation summarization.
Finally, we present baseline results of state-of-the-art models on VietMed-Sum.
All code, data (English-translated and Vietnamese) and models are available
online: https://github.com/leduckhai/MultiMed

摘要：在醫生和病人的對話中，識別與醫療相關的資訊至關重要，這提出了對話摘要的需求。在這項工作中，我們提出了第一個可部署的即時語音摘要系統，用於產業中的真實世界應用，它會在對話中的每 N 個語音發話後產生一個局部摘要，並在對話結束後產生一個全局摘要。我們的系統可以從商業角度提升使用者體驗，同時從技術角度降低運算成本。其次，我們提出了 VietMed-Sum，據我們所知，這是第一個針對醫療對話的語音摘要資料集。第三，我們是第一個利用 LLM 和人工標註者協作，為醫療對話摘要建立黃金標準和合成摘要。最後，我們提出了 VietMed-Sum 上最先進模型的基準結果。所有程式碼、資料（已翻譯成英文和越南語）和模型都可以在線上取得：https://github.com/leduckhai/MultiMed

##### **Automated radiotherapy treatment planning guided by GPT-4Vision**
2406.15609v1 by Sheng Liu, Oscar Pastor-Serrano, Yizheng Chen, Matthew Gopaulchan, Weixing Liang, Mark Buyyounouski, Erqi Pollom, Quynh-Thu Le, Michael Gensheimer, Peng Dong, Yong Yang, James Zou, Lei Xing

Radiotherapy treatment planning is a time-consuming and potentially
subjective process that requires the iterative adjustment of model parameters
to balance multiple conflicting objectives. Recent advancements in large
foundation models offer promising avenues for addressing the challenges in
planning and clinical decision-making. This study introduces GPT-RadPlan, a
fully automated treatment planning framework that harnesses prior radiation
oncology knowledge encoded in multi-modal large language models, such as
GPT-4Vision (GPT-4V) from OpenAI. GPT-RadPlan is made aware of planning
protocols as context and acts as an expert human planner, capable of guiding a
treatment planning process. Via in-context learning, we incorporate clinical
protocols for various disease sites as prompts to enable GPT-4V to acquire
treatment planning domain knowledge. The resulting GPT-RadPlan agent is
integrated into our in-house inverse treatment planning system through an API.
The efficacy of the automated planning system is showcased using multiple
prostate and head & neck cancer cases, where we compared GPT-RadPlan results to
clinical plans. In all cases, GPT-RadPlan either outperformed or matched the
clinical plans, demonstrating superior target coverage and organ-at-risk
sparing. Consistently satisfying the dosimetric objectives in the clinical
protocol, GPT-RadPlan represents the first multimodal large language model
agent that mimics the behaviors of human planners in radiation oncology
clinics, achieving remarkable results in automating the treatment planning
process without the need for additional training.

摘要：放射治療計畫是一個耗時且可能主觀的過程，需要反覆調整模型參數以平衡多重衝突的目標。大型基礎模型的最新進展為解決規劃和臨床決策中的挑戰提供了有希望的途徑。本研究介紹了 GPT-RadPlan，這是一個全自動化的治療計畫框架，利用了編碼在多模態大型語言模型（例如 OpenAI 的 GPT-4Vision (GPT-4V)）中的先前的放射腫瘤知識。GPT-RadPlan 意識到規劃協定作為背景，並扮演一位專家人類規劃者的角色，能夠指導治療計畫的過程。透過情境學習，我們將各種疾病部位的臨床協定納入提示中，讓 GPT-4V 獲取治療計畫領域的知識。產生的 GPT-RadPlan 代理透過 API 整合到我們內部的逆向治療計畫系統中。自動化規劃系統的效力透過多個前列腺和頭頸癌案例展示，我們將 GPT-RadPlan 的結果與臨床計畫進行比較。在所有案例中，GPT-RadPlan 都優於或符合臨床計畫，展現出優異的目標覆蓋率和器官在風險中的保護。GPT-RadPlan 持續滿足臨床協定中的劑量測量目標，代表了第一個多模態大型語言模型代理，它模擬了放射腫瘤診所中人類規劃者的行為，在無需額外訓練的情況下，在自動化治療計畫過程中取得了顯著的成果。

##### **Privacy Preserved Blood Glucose Level Cross-Prediction: An Asynchronous Decentralized Federated Learning Approach**
2406.15346v1 by Chengzhe Piao, Taiyu Zhu, Yu Wang, Stephanie E Baldeweg, Paul Taylor, Pantelis Georgiou, Jiahao Sun, Jun Wang, Kezhi Li

Newly diagnosed Type 1 Diabetes (T1D) patients often struggle to obtain
effective Blood Glucose (BG) prediction models due to the lack of sufficient BG
data from Continuous Glucose Monitoring (CGM), presenting a significant "cold
start" problem in patient care. Utilizing population models to address this
challenge is a potential solution, but collecting patient data for training
population models in a privacy-conscious manner is challenging, especially
given that such data is often stored on personal devices. Considering the
privacy protection and addressing the "cold start" problem in diabetes care, we
propose "GluADFL", blood Glucose prediction by Asynchronous Decentralized
Federated Learning. We compared GluADFL with eight baseline methods using four
distinct T1D datasets, comprising 298 participants, which demonstrated its
superior performance in accurately predicting BG levels for cross-patient
analysis. Furthermore, patients' data might be stored and shared across various
communication networks in GluADFL, ranging from highly interconnected (e.g.,
random, performs the best among others) to more structured topologies (e.g.,
cluster and ring), suitable for various social networks. The asynchronous
training framework supports flexible participation. By adjusting the ratios of
inactive participants, we found it remains stable if less than 70% are
inactive. Our results confirm that GluADFL offers a practical,
privacy-preserving solution for BG prediction in T1D, significantly enhancing
the quality of diabetes management.

摘要：新診斷的 1 型糖尿病 (T1D) 患者由於缺乏來自連續血糖監測 (CGM) 的足夠血糖 (BG) 資料，因此常常難以取得有效的血糖預測模型，這在患者照護中呈現出顯著的「冷啟動」問題。利用族群模型來應對此挑戰是一種潛在的解決方案，但以注重隱私的方式收集患者資料來訓練族群模型具有挑戰性，特別是在此類資料通常儲存在個人裝置中。考量到隱私保護並解決糖尿病照護中的「冷啟動」問題，我們提出「GluADFL」，透過非同步分散式聯合學習來預測血糖。我們使用四個不同的 T1D 資料集（包含 298 位參與者）將 GluADFL 與八種基準方法進行比較，這證明了其在準確預測跨患者分析的 BG 值方面的優異效能。此外，患者的資料可能儲存在 GluADFL 中並透過各種通訊網路分享，範圍從高度互連（例如，隨機，在其他網路中表現最佳）到更結構化的拓撲（例如，叢集和環），適用於各種社群網路。非同步訓練架構支援彈性參與。透過調整非活躍參與者的比率，我們發現如果非活躍參與者少於 70%，它仍然保持穩定。我們的結果證實 GluADFL 提供了一個實用的、保護隱私的 T1D BG 預測解決方案，大幅提升了糖尿病管理的品質。

##### **Exploring the Efficacy of Robotic Assistants with ChatGPT and Claude in Enhancing ADHD Therapy: Innovating Treatment Paradigms**
2406.15198v1 by Santiago Berrezueta-Guzman, Mohanad Kandil, María-Luisa Martín-Ruiz, Iván Pau-de-la-Cruz, Stephan Krusche

Attention Deficit Hyperactivity Disorder (ADHD) is a neurodevelopmental
condition characterized by inattention, hyperactivity, and impulsivity, which
can significantly impact an individual's daily functioning and quality of life.
Occupational therapy plays a crucial role in managing ADHD by fostering the
development of skills needed for daily living and enhancing an individual's
ability to participate fully in school, home, and social situations. Recent
studies highlight the potential of integrating Large Language Models (LLMs)
like ChatGPT and Socially Assistive Robots (SAR) to improve psychological
treatments. This integration aims to overcome existing limitations in mental
health therapy by providing tailored support and adapting to the unique needs
of this sensitive group. However, there remains a significant gap in research
exploring the combined use of these advanced technologies in ADHD therapy,
suggesting an opportunity for novel therapeutic approaches.
  Thus, we integrated two advanced language models, ChatGPT-4 Turbo and
Claude-3 Opus, into a robotic assistant to explore how well each model performs
in robot-assisted interactions. Additionally, we have compared their
performance in a simulated therapy scenario to gauge their effectiveness
against a clinically validated customized model. The results of this study show
that ChatGPT-4 Turbo excelled in performance and responsiveness, making it
suitable for time-sensitive applications. Claude-3 Opus, on the other hand,
showed strengths in understanding, coherence, and ethical considerations,
prioritizing safe and engaging interactions. Both models demonstrated
innovation and adaptability, but ChatGPT-4 Turbo offered greater ease of
integration and broader language support. The selection between them hinges on
the specific demands of ADHD therapy.

摘要：注意力不足過動症 (ADHD) 是一種神經發展狀況，其特徵為注意力不集中、過動和衝動，可能會對個人的日常生活功能和生活品質造成重大影響。職能治療在管理 ADHD 方面發揮著至關重要的作用，通過培養日常生活所需的技能並增強個人在學校、家庭和社交場合充分參與的能力。最近的研究強調了整合大型語言模型 (LLM)（如 ChatGPT）和社交輔助機器人 (SAR) 以改善心理治療的潛力。這種整合旨在通過提供量身定制的支持並適應這一敏感群體的獨特需求，來克服心理健康治療中現有的限制。然而，在探索這些先進技術在 ADHD 治療中的綜合應用方面，研究仍存在顯著差距，這表明有機會採用新的治療方法。因此，我們將兩個先進的語言模型 ChatGPT-4 Turbo 和 Claude-3 Opus 整合到機器人助手，以探索每個模型在機器人輔助互動中的表現。此外，我們比較了它們在模擬治療場景中的表現，以評估它們對臨床驗證的自訂模型的有效性。本研究的結果表明，ChatGPT-4 Turbo 在性能和響應能力方面表現出色，使其適用於對時間敏感的應用。另一方面，Claude-3 Opus 在理解、連貫性和道德考量方面表現出優勢，優先考慮安全和引人入勝的互動。這兩個模型都展示了創新和適應性，但 ChatGPT-4 Turbo 提供了更輕鬆的整合和更廣泛的語言支持。它們之間的選擇取決於 ADHD 治療的具體需求。

##### **This actually looks like that: Proto-BagNets for local and global interpretability-by-design**
2406.15168v2 by Kerol Djoumessi, Bubacarr Bah, Laura Kühlewein, Philipp Berens, Lisa Koch

Interpretability is a key requirement for the use of machine learning models
in high-stakes applications, including medical diagnosis. Explaining black-box
models mostly relies on post-hoc methods that do not faithfully reflect the
model's behavior. As a remedy, prototype-based networks have been proposed, but
their interpretability is limited as they have been shown to provide coarse,
unreliable, and imprecise explanations. In this work, we introduce
Proto-BagNets, an interpretable-by-design prototype-based model that combines
the advantages of bag-of-local feature models and prototype learning to provide
meaningful, coherent, and relevant prototypical parts needed for accurate and
interpretable image classification tasks. We evaluated the Proto-BagNet for
drusen detection on publicly available retinal OCT data. The Proto-BagNet
performed comparably to the state-of-the-art interpretable and
non-interpretable models while providing faithful, accurate, and clinically
meaningful local and global explanations. The code is available at
https://github.com/kdjoumessi/Proto-BagNets.

摘要：可解釋性是機器學習模型在高風險應用（包括醫療診斷）中使用的關鍵要求。解釋黑盒模型主要依賴於事後方法，而這些方法無法忠實地反映模型的行為。作為補救措施，已經提出了基於原型的網路，但由於它們已被證明會提供粗略、不可靠且不精確的解釋，因此它們的可解釋性受到限制。在這項工作中，我們引入了 Proto-BagNets，這是一個可解釋的基於設計的原型模型，它結合了局部特徵模型和原型學習的優點，以提供準確且可解釋的影像分類任務所需的、有意義、連貫且相關的原型部分。我們評估了 Proto-BagNet 在公開可用的視網膜 OCT 資料上的黃斑點檢測。Proto-BagNet 的表現與最先進的可解釋和不可解釋模型相當，同時提供了忠實、準確且在臨床上有意義的局部和整體解釋。程式碼可在 https://github.com/kdjoumessi/Proto-BagNets 取得。

##### **FA-Net: A Fuzzy Attention-aided Deep Neural Network for Pneumonia Detection in Chest X-Rays**
2406.15117v1 by Ayush Roy, Anurag Bhattacharjee, Diego Oliva, Oscar Ramos-Soto, Francisco J. Alvarez-Padilla, Ram Sarkar

Pneumonia is a respiratory infection caused by bacteria, fungi, or viruses.
It affects many people, particularly those in developing or underdeveloped
nations with high pollution levels, unhygienic living conditions, overcrowding,
and insufficient medical infrastructure. Pneumonia can cause pleural effusion,
where fluids fill the lungs, leading to respiratory difficulty. Early diagnosis
is crucial to ensure effective treatment and increase survival rates. Chest
X-ray imaging is the most commonly used method for diagnosing pneumonia.
However, visual examination of chest X-rays can be difficult and subjective. In
this study, we have developed a computer-aided diagnosis system for automatic
pneumonia detection using chest X-ray images. We have used DenseNet-121 and
ResNet50 as the backbone for the binary class (pneumonia and normal) and
multi-class (bacterial pneumonia, viral pneumonia, and normal) classification
tasks, respectively. We have also implemented a channel-specific spatial
attention mechanism, called Fuzzy Channel Selective Spatial Attention Module
(FCSSAM), to highlight the specific spatial regions of relevant channels while
removing the irrelevant channels of the extracted features by the backbone. We
evaluated the proposed approach on a publicly available chest X-ray dataset,
using binary and multi-class classification setups. Our proposed method
achieves accuracy rates of 97.15\% and 79.79\% for the binary and multi-class
classification setups, respectively. The results of our proposed method are
superior to state-of-the-art (SOTA) methods. The code of the proposed model
will be available at: https://github.com/AyushRoy2001/FA-Net.

摘要：肺炎是一種由細菌、真菌或病毒引起的呼吸道感染。
它影響許多人，特別是發展中國家或未開發國家，這些國家污染程度高、生活條件不衛生、人口過於稠密，且醫療基礎設施不足。肺炎會導致胸腔積液，液體會充滿肺部，導致呼吸困難。早期診斷對於確保有效治療和提高存活率至關重要。胸部 X 光影像檢查是診斷肺炎最常用的方法。
然而，胸部 X 光的視覺檢查可能困難且主觀。在本研究中，我們開發了一個電腦輔助診斷系統，用於使用胸部 X 光影像自動偵測肺炎。我們使用 DenseNet-121 和 ResNet50 作為二元類別（肺炎和正常）和多類別（細菌性肺炎、病毒性肺炎和正常）分類任務的主幹。我們還實作了一個通道特定的空間注意力機制，稱為模糊通道選擇性空間注意力模組 (FCSSAM)，以突顯相關通道的特定空間區域，同時移除主幹提取特徵的無關通道。我們在公開的胸部 X 光資料集上評估所提出的方法，使用二元和多類別分類設定。我們提出的方法在二元和多類別分類設定中分別達到 97.15% 和 79.79% 的準確率。我們提出的方法的結果優於最先進 (SOTA) 的方法。所提出模型的程式碼將可在以下位置取得：https://github.com/AyushRoy2001/FA-Net。

##### **Tri-VQA: Triangular Reasoning Medical Visual Question Answering for Multi-Attribute Analysis**
2406.15050v1 by Lin Fan, Xun Gong, Cenyang Zheng, Yafei Ou

The intersection of medical Visual Question Answering (Med-VQA) is a
challenging research topic with advantages including patient engagement and
clinical expert involvement for second opinions. However, existing Med-VQA
methods based on joint embedding fail to explain whether their provided results
are based on correct reasoning or coincidental answers, which undermines the
credibility of VQA answers. In this paper, we investigate the construction of a
more cohesive and stable Med-VQA structure. Motivated by causal effect, we
propose a novel Triangular Reasoning VQA (Tri-VQA) framework, which constructs
reverse causal questions from the perspective of "Why this answer?" to
elucidate the source of the answer and stimulate more reasonable forward
reasoning processes. We evaluate our method on the Endoscopic Ultrasound (EUS)
multi-attribute annotated dataset from five centers, and test it on medical VQA
datasets. Experimental results demonstrate the superiority of our approach over
existing methods. Our codes and pre-trained models are available at
https://anonymous.4open.science/r/Tri_VQA.

摘要：醫學視覺問答 (Med-VQA) 的交叉領域是一個具有挑戰性的研究主題，其優點包括患者參與和臨床專家的參與以提供第二意見。然而，現有的基於聯合嵌入的 Med-VQA 方法無法解釋其提供的結果是基於正確的推理還是巧合的答案，這會損害 VQA 答案的可信度。在本文中，我們探討了構建更緊密且穩定的 Med-VQA 結構。受到因果關係的啟發，我們提出了一個新穎的三角推理 VQA (Tri-VQA) 框架，該框架從「為什麼這個答案？」的角度構建反向因果問題，以闡明答案的來源並激發更合理的正向推理過程。我們在來自五個中心的內視鏡超音波 (EUS) 多屬性註釋資料集上評估了我們的模型，並在醫學 VQA 資料集上對其進行測試。實驗結果證明了我們的方法優於現有方法。我們的程式碼和預先訓練的模型可在 https://anonymous.4open.science/r/Tri_VQA 取得。

##### **Human-AI collectives produce the most accurate differential diagnoses**
2406.14981v1 by N. Zöller, J. Berger, I. Lin, N. Fu, J. Komarneni, G. Barabucci, K. Laskowski, V. Shia, B. Harack, E. A. Chu, V. Trianni, R. H. J. M. Kurvers, S. M. Herzog

Artificial intelligence systems, particularly large language models (LLMs),
are increasingly being employed in high-stakes decisions that impact both
individuals and society at large, often without adequate safeguards to ensure
safety, quality, and equity. Yet LLMs hallucinate, lack common sense, and are
biased - shortcomings that may reflect LLMs' inherent limitations and thus may
not be remedied by more sophisticated architectures, more data, or more human
feedback. Relying solely on LLMs for complex, high-stakes decisions is
therefore problematic. Here we present a hybrid collective intelligence system
that mitigates these risks by leveraging the complementary strengths of human
experience and the vast information processed by LLMs. We apply our method to
open-ended medical diagnostics, combining 40,762 differential diagnoses made by
physicians with the diagnoses of five state-of-the art LLMs across 2,133
medical cases. We show that hybrid collectives of physicians and LLMs
outperform both single physicians and physician collectives, as well as single
LLMs and LLM ensembles. This result holds across a range of medical specialties
and professional experience, and can be attributed to humans' and LLMs'
complementary contributions that lead to different kinds of errors. Our
approach highlights the potential for collective human and machine intelligence
to improve accuracy in complex, open-ended domains like medical diagnostics.

摘要：人工智慧系統，尤其是大型語言模型 (LLM)，
越來越常被用於影響個人和整個社會的高風險決策，但通常沒有足夠的防護措施來確保
安全、品質和公平性。然而，LLM 會產生幻覺、缺乏常識，並且有偏見 - 這些缺點可能反映出 LLM 固有的限制，因此可能無法透過更精密的架構、更多資料或更多人類回饋來補救。因此，僅依賴 LLM 來做出複雜、高風險的決策是有問題的。在此，我們提出一個混合集體智慧系統，透過利用人類經驗和 LLM 處理的龐大資訊的互補優勢來降低這些風險。我們將方法應用於開放式醫療診斷，結合醫師做出的 40,762 個鑑別診斷，以及五個最先進的 LLM 在 2,133 個醫療案例中的診斷。我們證明，醫師和 LLM 的混合集體優於單一醫師和醫師集體，以及單一 LLM 和 LLM 整合。這個結果適用於各種醫療專科和專業經驗，並且可以歸因於人類和 LLM 的互補貢獻，導致不同類型的錯誤。我們的做法突顯了集體人類和機器智慧在改善醫療診斷等複雜、開放式領域中的準確性的潛力。

##### **Deep Imbalanced Regression to Estimate Vascular Age from PPG Data: a Novel Digital Biomarker for Cardiovascular Health**
2406.14953v1 by Guangkun Nie, Qinghao Zhao, Gongzheng Tang, Jun Li, Shenda Hong

Photoplethysmography (PPG) is emerging as a crucial tool for monitoring human
hemodynamics, with recent studies highlighting its potential in assessing
vascular aging through deep learning. However, real-world age distributions are
often imbalanced, posing significant challenges for deep learning models. In
this paper, we introduce a novel, simple, and effective loss function named the
Dist Loss to address deep imbalanced regression tasks. We trained a
one-dimensional convolutional neural network (Net1D) incorporating the Dist
Loss on the extensive UK Biobank dataset (n=502,389) to estimate vascular age
from PPG signals and validate its efficacy in characterizing cardiovascular
health. The model's performance was validated on a 40% held-out test set,
achieving state-of-the-art results, especially in regions with small sample
sizes. Furthermore, we divided the population into three subgroups based on the
difference between predicted vascular age and chronological age: less than -10
years, between -10 and 10 years, and greater than 10 years. We analyzed the
relationship between predicted vascular age and several cardiovascular events
over a follow-up period of up to 10 years, including death, coronary heart
disease, and heart failure. Our results indicate that the predicted vascular
age has significant potential to reflect an individual's cardiovascular health
status. Our code will be available at https://github.com/Ngk03/AI-vascular-age.

摘要：光電容積描記法 (PPG) 正逐漸成為監測人體血流動力學的一項重要工具，最近的研究強調其透過深度學習評估血管老化的潛力。然而，真實世界的年齡分佈通常不平衡，對深度學習模型構成重大挑戰。在本文中，我們引入一個新穎、簡單且有效的損失函數，稱為 Dist Loss，以解決深度不平衡迴歸任務。我們在龐大的英國生物銀行資料集 (n=502,389) 上訓練了一個一維卷積神經網路 (Net1D)，結合 Dist Loss 從 PPG 訊號估計血管年齡，並驗證其在表徵心血管健康的效能。該模型的效能經過 40% 的留出測試集驗證，獲得了最先進的結果，特別是在樣本量小的區域。此外，我們根據預測的血管年齡和實際年齡之間的差異將人群分為三個子群：小於 -10 歲、介於 -10 到 10 歲之間，以及大於 10 歲。我們分析了預測的血管年齡與後續長達 10 年的數個心血管事件之間的關係，包括死亡、冠心病和心衰竭。我們的結果表明，預測的血管年齡具有反映個人心血管健康狀況的顯著潛力。我們的程式碼將在 https://github.com/Ngk03/AI-vascular-age 提供。

##### **Extraction of 3D trajectories of mandibular condyles from 2D real-time MRI**
2406.14925v1 by Karyna Isaieva, Justine Leclère, Guillaume Paillart, Guillaume Drouot, Jacques Felblinger, Xavier Dubernard, Pierre-André Vuissoz

Computing the trajectories of mandibular condyles directly from MRI could
provide a comprehensive examination, allowing for the extraction of both
anatomical and kinematic details. This study aimed to investigate the
feasibility of extracting 3D condylar trajectories from 2D real-time MRI and to
assess their precision.Twenty healthy subjects underwent real-time MRI while
opening and closing their jaws. One axial and two sagittal slices were
segmented using a U-Net-based algorithm. The centers of mass of the resulting
masks were projected onto the coordinate system based on anatomical markers and
temporally adjusted using a common projection. The quality of the computed
trajectories was evaluated using metrics designed to estimate movement
reproducibility, head motion, and slice placement symmetry.The segmentation of
the axial slices demonstrated good-to-excellent quality; however, the
segmentation of the sagittal slices required some fine-tuning. The movement
reproducibility was acceptable for most cases; nevertheless, head motion
displaced the trajectories by 1 mm on average. The difference in the
superior-inferior coordinate of the condyles in the closed jaw position was 1.7
mm on average.Despite limitations in precision, real-time MRI enables the
extraction of condylar trajectories with sufficient accuracy for evaluating
clinically relevant parameters such as condyle displacement, trajectories
aspect, and symmetry.

摘要：透過 MRI 直接計算下顎髁的軌跡可以提供全面的檢查，並允許提取解剖和運動細節。本研究旨在探討從 2D 即時 MRI 中提取 3D 髁狀軌跡的可行性，並評估其準確度。二十位健康受試者在張閉下顎時接受即時 MRI。使用基於 U-Net 的演算法分割一個軸向切片和兩個矢狀切片。將所得遮罩的質心投影到基於解剖標記的座標系統上，並使用共同投影進行時間調整。計算軌跡的品質使用指標進行評估，這些指標旨在估計運動重現性、頭部運動和切片放置對稱性。軸向切片的分割顯示出良好到極佳的品質；然而，矢狀切片的分割需要一些微調。在多數情況下，運動重現性是可以接受的；然而，頭部運動平均將軌跡移位 1 mm。閉合下顎位置中髁狀突的上下座標差異平均為 1.7 mm。儘管準確度有其限制，即時 MRI 能夠提取髁狀軌跡，其準確度足以評估下顎髁位移、軌跡外觀和對稱性等臨床相關參數。

##### **AI-based Anomaly Detection for Clinical-Grade Histopathological Diagnostics**
2406.14866v1 by Jonas Dippel, Niklas Prenißl, Julius Hense, Philipp Liznerski, Tobias Winterhoff, Simon Schallenberg, Marius Kloft, Oliver Buchstab, David Horst, Maximilian Alber, Lukas Ruff, Klaus-Robert Müller, Frederick Klauschen

While previous studies have demonstrated the potential of AI to diagnose
diseases in imaging data, clinical implementation is still lagging behind. This
is partly because AI models require training with large numbers of examples
only available for common diseases. In clinical reality, however, only few
diseases are common, whereas the majority of diseases are less frequent
(long-tail distribution). Current AI models overlook or misclassify these
diseases. We propose a deep anomaly detection approach that only requires
training data from common diseases to detect also all less frequent diseases.
We collected two large real-world datasets of gastrointestinal biopsies, which
are prototypical of the problem. Herein, the ten most common findings account
for approximately 90% of cases, whereas the remaining 10% contained 56 disease
entities, including many cancers. 17 million histological images from 5,423
cases were used for training and evaluation. Without any specific training for
the diseases, our best-performing model reliably detected a broad spectrum of
infrequent ("anomalous") pathologies with 95.0% (stomach) and 91.0% (colon)
AUROC and generalized across scanners and hospitals. By design, the proposed
anomaly detection can be expected to detect any pathological alteration in the
diagnostic tail of gastrointestinal biopsies, including rare primary or
metastatic cancers. This study establishes the first effective clinical
application of AI-based anomaly detection in histopathology that can flag
anomalous cases, facilitate case prioritization, reduce missed diagnoses and
enhance the general safety of AI models, thereby driving AI adoption and
automation in routine diagnostics and beyond.

摘要：儘管先前的研究已經證明 AI 在影像資料中診斷疾病的潛力，但臨床實務仍落後許多。這是部分原因在於 AI 模型需要大量範例進行訓練，而這些範例僅適用於常見疾病。然而，在臨床現實中，只有少數疾病是常見的，而大多數疾病較不常見（長尾分佈）。目前的 AI 模型會忽略或錯誤分類這些疾病。我們提出一個深度異常偵測方法，它只需要來自常見疾病的訓練資料，就能偵測所有較不常見的疾病。我們收集了兩個大型的胃腸道切片真實世界資料集，它們是此問題的典型範例。在此，最常見的十種發現約佔病例的 90%，而其餘 10% 則包含 56 種疾病實體，包括許多癌症。1700 萬張來自 5,423 個病例的組織學影像用於訓練和評估。我們的最佳效能模型在沒有針對這些疾病進行任何特定訓練的情況下，可靠地偵測到廣泛的罕見（「異常」）病理，其 AUROC 分別為 95.0%（胃）和 91.0%（結腸），並廣泛應用於掃描儀和醫院。依據設計，所提出的異常偵測預計可以偵測胃腸道切片診斷尾端的任何病理性改變，包括罕見的原發性或轉移性癌症。這項研究建立了第一個有效的 AI 異常偵測臨床應用，它可以在組織病理學中標記異常病例、促進病例優先順序、減少漏診並提升 AI 模型的整體安全性，從而推動 AI 在常規診斷及其他領域的採用和自動化。

##### **ACR: A Benchmark for Automatic Cohort Retrieval**
2406.14780v1 by Dung Ngoc Thai, Victor Ardulov, Jose Ulises Mena, Simran Tiwari, Gleb Erofeev, Ramy Eskander, Karim Tarabishy, Ravi B Parikh, Wael Salloum

Identifying patient cohorts is fundamental to numerous healthcare tasks,
including clinical trial recruitment and retrospective studies. Current cohort
retrieval methods in healthcare organizations rely on automated queries of
structured data combined with manual curation, which are time-consuming,
labor-intensive, and often yield low-quality results. Recent advancements in
large language models (LLMs) and information retrieval (IR) offer promising
avenues to revolutionize these systems. Major challenges include managing
extensive eligibility criteria and handling the longitudinal nature of
unstructured Electronic Medical Records (EMRs) while ensuring that the solution
remains cost-effective for real-world application. This paper introduces a new
task, Automatic Cohort Retrieval (ACR), and evaluates the performance of LLMs
and commercial, domain-specific neuro-symbolic approaches. We provide a
benchmark task, a query dataset, an EMR dataset, and an evaluation framework.
Our findings underscore the necessity for efficient, high-quality ACR systems
capable of longitudinal reasoning across extensive patient databases.

摘要：識別患者群體是許多醫療保健任務的基礎，包括臨床試驗招募和回顧性研究。當前醫療保健組織中的群體檢索方法依賴於結構化數據的自動化查詢，並結合人工整理，這既耗時又費力，而且常常會產生低品質的結果。大型語言模型 (LLM) 和資訊檢索 (IR) 的最新進展為革新這些系統提供了有前景的途徑。主要的挑戰包括管理廣泛的資格標準，以及處理非結構化電子病歷 (EMR) 的縱向性質，同時確保解決方案在現實世界的應用中仍然具有成本效益。本文介紹了一項新任務，自動群體檢索 (ACR)，並評估了 LLM 和商業、特定領域的神經符號方法的效能。我們提供了一個基準任務、一個查詢資料集、一個 EMR 資料集和一個評估架構。我們的研究結果強調了對有效、高品質的 ACR 系統的必要性，這些系統能夠跨廣泛的患者資料庫進行縱向推理。

##### **A Large Language Model Outperforms Other Computational Approaches to the High-Throughput Phenotyping of Physician Notes**
2406.14757v1 by Syed I. Munzir, Daniel B. Hier, Chelsea Oommen, Michael D. Carrithers

High-throughput phenotyping, the automated mapping of patient signs and
symptoms to standardized ontology concepts, is essential to gaining value from
electronic health records (EHR) in the support of precision medicine. Despite
technological advances, high-throughput phenotyping remains a challenge. This
study compares three computational approaches to high-throughput phenotyping: a
Large Language Model (LLM) incorporating generative AI, a Natural Language
Processing (NLP) approach utilizing deep learning for span categorization, and
a hybrid approach combining word vectors with machine learning. The approach
that implemented GPT-4 (a Large Language Model) demonstrated superior
performance, suggesting that Large Language Models are poised to be the
preferred method for high-throughput phenotyping of physician notes.

摘要：高通量表型分析，將患者症狀和體徵自動對應到標準化本體概念，對於在精準醫療中獲取電子健康紀錄（EHR）的價值至關重要。儘管有技術進展，高通量表型分析仍然是一個挑戰。本研究比較了三種高通量表型分析的計算方法：一個結合生成式 AI 的大型語言模型（LLM）、一個利用深度學習進行跨度分類的自然語言處理（NLP）方法，以及一個結合詞向量與機器學習的混合方法。實作 GPT-4（一個大型語言模型）的方法表現出優異的效能，這表示大型語言模型有望成為醫師備忘錄的高通量表型分析首選方法。

##### **An updated overview of radiomics-based artificial intelligence (AI) methods in breast cancer screening and diagnosis**
2406.14735v1 by Reza Elahi, Mahdis Nazari

Current imaging methods for diagnosing BC are associated with limited
sensitivity and specificity and modest positive predictive power. The recent
progress in image analysis using artificial intelligence (AI) has created great
promise to improve breast cancer (BC) diagnosis and subtype differentiation. In
this case, novel quantitative computational methods, such as radiomics, have
been developed to improve the sensitivity and specificity of early BC diagnosis
and classification. The potential of radiomics in improving the diagnostic
efficacy of imaging studies has been shown in several studies. In this review
article, we discuss the radiomics workflow and current hand-crafted radiomics
methods in the diagnosis and classification of BC based on most recent studies
on different imaging modalities, e.g. MRI, mammography, contrast-enhanced
spectral mammography (CESM), ultrasound imaging, and digital breast
tumosynthesis (DBT). We also discuss current challenges and potential
strategies to improve the specificity and sensitivity of radiomics in breast
cancer to help achieve a higher level of BC classification and diagnosis in the
clinical setting. The growing field of AI incorporation with imaging
information has opened a great opportunity to provide a higher level of care
for BC patients.

摘要：目前用於診斷乳癌的影像方法與有限的敏感度和特異度以及適度的陽性預測能力有關。近期使用人工智慧 (AI) 的影像分析進展為改善乳癌 (BC) 診斷和亞型區分創造了極大的希望。在這種情況下，已經開發出新的定量計算方法（例如放射特徵組學）來提高早期乳癌診斷和分類的敏感度和特異度。放射特徵組學在提高影像研究診斷效能的潛力已在多項研究中得到證實。在這篇評論文章中，我們根據不同影像模式（例如 MRI、乳房攝影、對比增強光譜乳房攝影 (CESM)、超音波影像和數位乳房斷層合成 (DBT)）的最新研究，討論放射特徵組學工作流程和目前手工製作的放射特徵組學方法在乳癌診斷和分類中的應用。我們也討論了當前挑戰和潛在策略，以提高放射特徵組學在乳癌中的特異度和敏感度，以協助在臨床環境中達到更高層級的乳癌分類和診斷。將 AI 納入影像資訊的領域正在成長，這為提供更高層級的乳癌患者照護開啟了一個絕佳機會。

##### **This Looks Better than That: Better Interpretable Models with ProtoPNeXt**
2406.14675v1 by Frank Willard, Luke Moffett, Emmanuel Mokel, Jon Donnelly, Stark Guo, Julia Yang, Giyoung Kim, Alina Jade Barnett, Cynthia Rudin

Prototypical-part models are a popular interpretable alternative to black-box
deep learning models for computer vision. However, they are difficult to train,
with high sensitivity to hyperparameter tuning, inhibiting their application to
new datasets and our understanding of which methods truly improve their
performance. To facilitate the careful study of prototypical-part networks
(ProtoPNets), we create a new framework for integrating components of
prototypical-part models -- ProtoPNeXt. Using ProtoPNeXt, we show that applying
Bayesian hyperparameter tuning and an angular prototype similarity metric to
the original ProtoPNet is sufficient to produce new state-of-the-art accuracy
for prototypical-part models on CUB-200 across multiple backbones. We further
deploy this framework to jointly optimize for accuracy and prototype
interpretability as measured by metrics included in ProtoPNeXt. Using the same
resources, this produces models with substantially superior semantics and
changes in accuracy between +1.3% and -1.5%. The code and trained models will
be made publicly available upon publication.

摘要：原型部分模型是计算机视觉中一种流行的可解释的黑盒深度学习模型替代方案。然而，它们很难训练，对超参数调整高度敏感，这抑制了它们在新数据集上的应用，以及我们对真正提高其性能的方法的理解。为了促进对原型部分网络 (ProtoPNets) 的仔细研究，我们创建了一个新的框架来集成原型部分模型的组件——ProtoPNeXt。使用 ProtoPNeXt，我们表明对原始 ProtoPNet 应用贝叶斯超参数调整和角度原型相似性度量足以在多个骨干网上为 CUB-200 上的原型部分模型产生新的最先进的准确性。我们进一步部署此框架以根据 ProtoPNeXt 中包含的指标共同优化准确性和原型可解释性。使用相同的资源，这会产生具有明显优越的语义和准确性变化的模型，介于 +1.3% 和 -1.5% 之间。代码和训练好的模型将在发布后公开。

##### **Computation-Efficient Semi-Supervised Learning for ECG-based Cardiovascular Diseases Detection**
2406.14377v1 by Rushuang Zhou, Zijun Liu, Lei Clifton, David A. Clifton, Kannie W. Y. Chan, Yuan-Ting Zhang, Yining Dong

Label scarcity problem is the main challenge that hinders the wide
application of deep learning systems in automatic cardiovascular diseases
(CVDs) detection using electrocardiography (ECG). Tuning pre-trained models
alleviates this problem by transferring knowledge learned from large datasets
to downstream small datasets. However, bottlenecks in computational efficiency
and CVDs detection performance limit its clinical applications. It is difficult
to improve the detection performance without significantly sacrificing model
computational efficiency. Here, we propose a computation-efficient
semi-supervised learning paradigm (FastECG) for robust and
computation-efficient CVDs detection using ECG. It enables a robust adaptation
of pre-trained models on downstream datasets with limited supervision and high
computational efficiency. First, a random-deactivation technique is developed
to achieve robust and fast low-rank adaptation of pre-trained weights.
Subsequently, we propose a one-shot rank allocation module to determine the
optimal ranks for the update matrices of the pre-trained weights. Finally, a
lightweight semi-supervised learning pipeline is introduced to enhance model
performance by leveraging labeled and unlabeled data with high computational
efficiency. Extensive experiments on four downstream ECG datasets demonstrate
that FastECG not only outperforms the state-of-the-art methods in multi-label
CVDs detection but also consumes fewer GPU footprints, training time, and
parameter storage space. As such, this paradigm provides an effective solution
for achieving high computational efficiency and robust detection performance in
the clinical applications of pre-trained models under limited supervision.

摘要：標籤稀缺問題是阻礙深度學習系統在自動心血管疾病 (CVD) 使用心電圖 (ECG) 檢測中廣泛應用之主要挑戰。調整預訓練模型透過將從大型資料集學到的知識轉移到下游小型資料集，來緩解此問題。然而，運算效率和 CVD 檢測效能的瓶頸限制了其臨床應用。在不顯著犧牲模型運算效率的情況下，難以改善檢測效能。在此，我們提出一個運算效率的半監督學習範例 (FastECG)，用於使用 ECG 進行穩健且運算效率高的 CVD 檢測。它能讓預訓練模型在監督有限且運算效率高的下游資料集上進行穩健的調整。首先，開發出一種隨機停用技術，以達成預訓練權重的穩健且快速的低秩調整。接著，我們提出一個一次性秩配置模組，用於確定預訓練權重的更新矩陣之最佳秩。最後，引入一個輕量級的半監督學習管線，以利用標籤和未標籤資料，並在高運算效率下提升模型效能。在四個下游 ECG 資料集上的廣泛實驗證明，FastECG 不僅在多標籤 CVD 檢測中優於最先進的方法，而且消耗更少的 GPU 占用空間、訓練時間和參數儲存空間。因此，此範例提供了一個有效的解決方案，用於在監督有限的情況下，於預訓練模型的臨床應用中達成高運算效率和穩健的檢測效能。

##### **Automatic Labels are as Effective as Manual Labels in Biomedical Images Classification with Deep Learning**
2406.14351v1 by Niccolò Marini, Stefano Marchesin, Lluis Borras Ferris, Simon Püttmann, Marek Wodzinski, Riccardo Fratti, Damian Podareanu, Alessandro Caputo, Svetla Boytcheva, Simona Vatrano, Filippo Fraggetta, Iris Nagtegaal, Gianmaria Silvello, Manfredo Atzori, Henning Müller

The increasing availability of biomedical data is helping to design more
robust deep learning (DL) algorithms to analyze biomedical samples. Currently,
one of the main limitations to train DL algorithms to perform a specific task
is the need for medical experts to label data. Automatic methods to label data
exist, however automatic labels can be noisy and it is not completely clear
when automatic labels can be adopted to train DL models. This paper aims to
investigate under which circumstances automatic labels can be adopted to train
a DL model on the classification of Whole Slide Images (WSI). The analysis
involves multiple architectures, such as Convolutional Neural Networks (CNN)
and Vision Transformer (ViT), and over 10000 WSIs, collected from three use
cases: celiac disease, lung cancer and colon cancer, which one including
respectively binary, multiclass and multilabel data. The results allow
identifying 10% as the percentage of noisy labels that lead to train
competitive models for the classification of WSIs. Therefore, an algorithm
generating automatic labels needs to fit this criterion to be adopted. The
application of the Semantic Knowledge Extractor Tool (SKET) algorithm to
generate automatic labels leads to performance comparable to the one obtained
with manual labels, since it generates a percentage of noisy labels between
2-5%. Automatic labels are as effective as manual ones, reaching solid
performance comparable to the one obtained training models with manual labels.

摘要：隨著生物醫學資料的日益普及，有助於設計更穩健的深度學習 (DL) 演算法來分析生物醫學樣本。目前，訓練 DL 演算法執行特定任務的主要限制之一在於醫學專家標記資料的需求。標記資料的自動化方法確實存在，然而自動化標籤可能會產生雜訊，而且尚不清楚何時可以採用自動化標籤來訓練 DL 模型。本文旨在探討在何種情況下可以採用自動化標籤來訓練 DL 模型對全切片影像 (WSI) 進行分類。分析涉及多種架構，例如卷積神經網路 (CNN) 和視覺Transformer (ViT)，以及超過 10000 個 WSI，這些 WSI 來自三種使用案例：乳糜瀉、肺癌和結腸癌，其中一個分別包括二元、多類和多標籤資料。結果可以將產生雜訊標籤的比例確定為 10%，這將導致訓練出具有競爭力的 WSI 分類模型。因此，產生自動化標籤的演算法需要符合此準則才能被採用。將語義知識萃取工具 (SKET) 演算法應用於產生自動化標籤，其效能可與使用人工標籤獲得的效能相媲美，因為它產生的雜訊標籤比例在 2-5% 之間。自動化標籤與人工標籤一樣有效，可達到與使用人工標籤訓練模型所獲得的效能相當的穩健效能。

##### **Infusing clinical knowledge into tokenisers for language models**
2406.14312v1 by Abul Hasan, Jinge Wu, Quang Ngoc Nguyen, Salomé Andres, Imane Guellil, Huayu Zhang, Arlene Casey, Beatrice Alex, Bruce Guthrie, Honghan Wu

This study introduces a novel knowledge enhanced tokenisation mechanism,
K-Tokeniser, for clinical text processing. Technically, at initialisation
stage, K-Tokeniser populates global representations of tokens based on semantic
types of domain concepts (such as drugs or diseases) from either a domain
ontology like Unified Medical Language System or the training data of the task
related corpus. At training or inference stage, sentence level localised
context will be utilised for choosing the optimal global token representation
to realise the semantic-based tokenisation. To avoid pretraining using the new
tokeniser, an embedding initialisation approach is proposed to generate
representations for new tokens. Using three transformer-based language models,
a comprehensive set of experiments are conducted on four real-world datasets
for evaluating K-Tokeniser in a wide range of clinical text analytics tasks
including clinical concept and relation extraction, automated clinical coding,
clinical phenotype identification, and clinical research article
classification. Overall, our models demonstrate consistent improvements over
their counterparts in all tasks. In particular, substantial improvements are
observed in the automated clinical coding task with 13\% increase on Micro
$F_1$ score. Furthermore, K-Tokeniser also shows significant capacities in
facilitating quicker converge of language models. Specifically, using
K-Tokeniser, the language models would only require 50\% of the training data
to achieve the best performance of the baseline tokeniser using all training
data in the concept extraction task and less than 20\% of the data for the
automated coding task. It is worth mentioning that all these improvements
require no pre-training process, making the approach generalisable.

摘要：本研究引入一種新穎的知識增強標記化機制，K-Tokeniser，用於臨床文本處理。技術上，在初始化階段，K-Tokeniser 會根據來自領域概念（例如藥物或疾病）的語義類型，從統一醫學語言系統或任務相關語料庫的訓練資料中，填充標記的全局表示。在訓練或推論階段，句子級別的局部化上下文將被用於選擇最佳的全局標記表示，以實現基於語義的標記化。為了避免使用新的標記化器進行預訓練，提出了一種嵌入初始化方法，以產生新標記的表示。使用三種基於Transformer的語言模型，對四個真實世界數據集進行了一組全面的實驗，以評估 K-Tokeniser 在廣泛的臨床文本分析任務中的表現，包括臨床概念和關係提取、自動臨床編碼、臨床表型識別和臨床研究文章分類。總體而言，我們的模型在所有任務中都展示出比其對應模型更一致的改進。特別是，在自動臨床編碼任務中觀察到了顯著的改進，Micro $F_1$ 得分提高了 13%。此外，K-Tokeniser 還顯示出顯著的能力，可以促進語言模型更快的收斂。具體來說，使用 K-Tokeniser，語言模型只需要 50% 的訓練數據即可在概念提取任務中達到基線標記化器使用所有訓練數據的最佳性能，而自動編碼任務則不到 20% 的數據。值得一提的是，所有這些改進都不需要預訓練過程，這使得該方法具有普遍性。

##### **Enhancing robustness of data-driven SHM models: adversarial training with circle loss**
2406.14232v1 by Xiangli Yang, Xijie Deng, Hanwei Zhang, Yang Zou, Jianxi Yang

Structural health monitoring (SHM) is critical to safeguarding the safety and
reliability of aerospace, civil, and mechanical infrastructure. Machine
learning-based data-driven approaches have gained popularity in SHM due to
advancements in sensors and computational power. However, machine learning
models used in SHM are vulnerable to adversarial examples -- even small changes
in input can lead to different model outputs. This paper aims to address this
problem by discussing adversarial defenses in SHM. In this paper, we propose an
adversarial training method for defense, which uses circle loss to optimize the
distance between features in training to keep examples away from the decision
boundary. Through this simple yet effective constraint, our method demonstrates
substantial improvements in model robustness, surpassing existing defense
mechanisms.

摘要：結構健康監測 (SHM) 對保障航太、土木和機械基礎設施的安全和可靠性至關重要。機器學習為基礎的資料驅動方法由於感測器和計算能力的進步，在 SHM 中獲得普及。然而，用於 SHM 的機器學習模型容易受到對抗性範例的影響——輸入的微小變更甚至可能導致不同的模型輸出。本文旨在透過討論 SHM 中的對抗性防禦來解決此問題。在本文中，我們提出了一種用於防禦的對抗性訓練方法，該方法使用圓形損失來最佳化訓練中特徵之間的距離，以使範例遠離決策邊界。透過這個簡單但有效的約束，我們的模型展示了模型穩健性的顯著改善，超越了現有的防禦機制。

##### **A Data-Driven Guided Decoding Mechanism for Diagnostic Captioning**
2406.14164v1 by Panagiotis Kaliosis, John Pavlopoulos, Foivos Charalampakos, Georgios Moschovis, Ion Androutsopoulos

Diagnostic Captioning (DC) automatically generates a diagnostic text from one
or more medical images (e.g., X-rays, MRIs) of a patient. Treated as a draft,
the generated text may assist clinicians, by providing an initial estimation of
the patient's condition, speeding up and helping safeguard the diagnostic
process. The accuracy of a diagnostic text, however, strongly depends on how
well the key medical conditions depicted in the images are expressed. We
propose a new data-driven guided decoding method that incorporates medical
information, in the form of existing tags capturing key conditions of the
image(s), into the beam search of the diagnostic text generation process. We
evaluate the proposed method on two medical datasets using four DC systems that
range from generic image-to-text systems with CNN encoders and RNN decoders to
pre-trained Large Language Models. The latter can also be used in few- and
zero-shot learning scenarios. In most cases, the proposed mechanism improves
performance with respect to all evaluation measures. We provide an open-source
implementation of the proposed method at https://github.com/nlpaueb/dmmcs.

摘要：診斷標題 (DC) 會自動從一位或多位病患的醫療影像 (例如 X 光、磁振造影) 中產生一則診斷文字。產生的文字視為草稿，可協助臨床醫生提供病患狀況的初步估計，加速並協助保障診斷程序。然而，診斷文字的準確性高度仰賴影像中所描繪的主要醫療狀況如何表達。我們提出一個新的資料驅動引導解碼方法，該方法將醫療資訊以現有標籤的形式納入診斷文字產生過程的波束搜尋中，用以擷取影像的主要狀況。我們使用四個 DC 系統在兩個醫療資料集上評估所提出的方法，這些系統的範圍從具備 CNN 編碼器和 RNN 解碼器的通用影像轉文字系統到預先訓練的大型語言模型。後者也可在少樣本和零樣本學習情境中使用。在大部分情況下，所提出的機制在所有評量指標方面均提升了效能。我們在 https://github.com/nlpaueb/dmmcs 中提供了所提出方法的開源實作。

##### **Resource-efficient Medical Image Analysis with Self-adapting Forward-Forward Networks**
2406.14038v1 by Johanna P. Müller, Bernhard Kainz

We introduce a fast Self-adapting Forward-Forward Network (SaFF-Net) for
medical imaging analysis, mitigating power consumption and resource
limitations, which currently primarily stem from the prevalent reliance on
back-propagation for model training and fine-tuning. Building upon the recently
proposed Forward-Forward Algorithm (FFA), we introduce the Convolutional
Forward-Forward Algorithm (CFFA), a parameter-efficient reformulation that is
suitable for advanced image analysis and overcomes the speed and generalisation
constraints of the original FFA. To address hyper-parameter sensitivity of FFAs
we are also introducing a self-adapting framework SaFF-Net fine-tuning
parameters during warmup and training in parallel. Our approach enables more
effective model training and eliminates the previously essential requirement
for an arbitrarily chosen Goodness function in FFA. We evaluate our approach on
several benchmarking datasets in comparison with standard Back-Propagation (BP)
neural networks showing that FFA-based networks with notably fewer parameters
and function evaluations can compete with standard models, especially, in
one-shot scenarios and large batch sizes. The code will be available at the
time of the conference.

摘要：<paragraph>我們介紹一種用於醫療影像分析的快速自適應前饋前饋網路 (SaFF-Net)，以減輕目前主要源自於過度依賴反向傳播進行模型訓練和微調的功耗和資源限制。在最近提出的前饋前饋演算法 (FFA) 的基礎上，我們介紹了卷積前饋前饋演算法 (CFFA)，這是一種參數有效率的重新制定，適用於進階影像分析，並克服了原始 FFA 的速度和概括限制。為了解決 FFA 的超參數敏感性，我們還在熱身和訓練期間並行引入了自適應架構 SaFF-Net 微調參數。我們的做法能更有效地進行模型訓練，並消除了 FFA 中先前對任意選擇的優良函數的基本需求。我們在幾個基準資料集上評估我們的做法，並與標準反向傳播 (BP) 神經網路進行比較，結果顯示基於 FFA 的網路具有明顯較少的參數和函數評估，可以與標準模型競爭，特別是在單次場景和大批次大小中。程式碼將在會議期間提供。</paragraph>

##### **Reasoning Like a Doctor: Improving Medical Dialogue Systems via Diagnostic Reasoning Process Alignment**
2406.13934v1 by Kaishuai Xu, Yi Cheng, Wenjun Hou, Qiaoyu Tan, Wenjie Li

Medical dialogue systems have attracted significant attention for their
potential to act as medical assistants. Enabling these medical systems to
emulate clinicians' diagnostic reasoning process has been the long-standing
research focus. Previous studies rudimentarily realized the simulation of
clinicians' diagnostic process by fine-tuning language models on high-quality
dialogue datasets. Nonetheless, they overly focus on the outcomes of the
clinician's reasoning process while ignoring their internal thought processes
and alignment with clinician preferences. Our work aims to build a medical
dialogue system that aligns with clinicians' diagnostic reasoning processes. We
propose a novel framework, Emulation, designed to generate an appropriate
response that relies on abductive and deductive diagnostic reasoning analyses
and aligns with clinician preferences through thought process modeling.
Experimental results on two datasets confirm the efficacy of Emulation.
Crucially, our framework furnishes clear explanations for the generated
responses, enhancing its transparency in medical consultations.

摘要：醫療對話系統因其作為醫療助理的潛力而備受關注。讓這些醫療系統模擬臨床醫生的診斷推理過程一直是長期的研究重點。先前的研究通過微調高品質對話資料集上的語言模型，初步實現了對臨床醫生診斷過程的模擬。儘管如此，他們過於關注臨床醫生推理過程的結果，而忽視了他們的內部思考過程以及與臨床醫生偏好的對齊。我們的研究旨在建立一個與臨床醫生的診斷推理過程保持一致的醫療對話系統。我們提出了一個新穎的框架，稱為 Emulation，旨在產生適當的回應，這些回應依賴於演繹和歸納診斷推理分析，並通過思考過程建模與臨床醫生的偏好保持一致。在兩個資料集上的實驗結果證實了 Emulation 的功效。至關重要的是，我們的框架為生成的回應提供了清晰的解釋，增強了其在醫療諮詢中的透明度。

##### **ClinicalLab: Aligning Agents for Multi-Departmental Clinical Diagnostics in the Real World**
2406.13890v1 by Weixiang Yan, Haitian Liu, Tengxiao Wu, Qian Chen, Wen Wang, Haoyuan Chai, Jiayi Wang, Weishan Zhao, Yixin Zhang, Renjun Zhang, Li Zhu

LLMs have achieved significant performance progress in various NLP
applications. However, LLMs still struggle to meet the strict requirements for
accuracy and reliability in the medical field and face many challenges in
clinical applications. Existing clinical diagnostic evaluation benchmarks for
evaluating medical agents powered by LLMs have severe limitations. Firstly,
most existing medical evaluation benchmarks face the risk of data leakage or
contamination. Secondly, existing benchmarks often neglect the characteristics
of multiple departments and specializations in modern medical practice.
Thirdly, existing evaluation methods are limited to multiple-choice questions,
which do not align with the real-world diagnostic scenarios. Lastly, existing
evaluation methods lack comprehensive evaluations of end-to-end real clinical
scenarios. These limitations in benchmarks in turn obstruct advancements of
LLMs and agents for medicine. To address these limitations, we introduce
ClinicalLab, a comprehensive clinical diagnosis agent alignment suite.
ClinicalLab includes ClinicalBench, an end-to-end multi-departmental clinical
diagnostic evaluation benchmark for evaluating medical agents and LLMs.
ClinicalBench is based on real cases that cover 24 departments and 150
diseases. ClinicalLab also includes four novel metrics (ClinicalMetrics) for
evaluating the effectiveness of LLMs in clinical diagnostic tasks. We evaluate
17 LLMs and find that their performance varies significantly across different
departments. Based on these findings, in ClinicalLab, we propose ClinicalAgent,
an end-to-end clinical agent that aligns with real-world clinical diagnostic
practices. We systematically investigate the performance and applicable
scenarios of variants of ClinicalAgent on ClinicalBench. Our findings
demonstrate the importance of aligning with modern medical practices in
designing medical agents.

摘要：大型語言模型在各種自然語言處理應用中取得顯著的進展。然而，大型語言模型仍難以滿足醫療領域對準確性和可靠性的嚴格要求，並在臨床應用中面臨許多挑戰。現有的臨床診斷評估基準用於評估由大型語言模型驅動的醫療代理，但存在嚴重的限制。首先，現有的醫療評估基準大多面臨數據洩露或污染的風險。其次，現有的基準通常忽略現代醫療實務中多個部門和專科的特徵。第三，現有的評估方法僅限於選擇題，與現實世界的診斷情境不符。最後，現有的評估方法缺乏對端到端真實臨床情境的全面評估。基準的這些限制反過來阻礙了大型語言模型和醫學代理的進步。為了解決這些限制，我們引入了 ClinicalLab，一個全面的臨床診斷代理對齊套件。ClinicalLab 包含 ClinicalBench，一個端到端的多部門臨床診斷評估基準，用於評估醫療代理和大型語言模型。ClinicalBench 基於涵蓋 24 個部門和 150 種疾病的真實案例。ClinicalLab 還包括四項新指標（ClinicalMetrics），用於評估大型語言模型在臨床診斷任務中的有效性。我們評估了 17 個大型語言模型，發現它們在不同部門的表現差異很大。根據這些發現，我們在 ClinicalLab 中提出了 ClinicalAgent，一個與現實世界臨床診斷實務相符的端到端臨床代理。我們系統地研究了 ClinicalAgent 變體在 ClinicalBench 上的效能和適用情境。我們的發現證明了在設計醫療代理時與現代醫療實務相符的重要性。

##### **MAMA-MIA: A Large-Scale Multi-Center Breast Cancer DCE-MRI Benchmark Dataset with Expert Segmentations**
2406.13844v1 by Lidia Garrucho, Claire-Anne Reidel, Kaisar Kushibar, Smriti Joshi, Richard Osuala, Apostolia Tsirikoglou, Maciej Bobowicz, Javier del Riego, Alessandro Catanese, Katarzyna Gwoździewicz, Maria-Laura Cosaka, Pasant M. Abo-Elhoda, Sara W. Tantawy, Shorouq S. Sakrana, Norhan O. Shawky-Abdelfatah, Amr Muhammad Abdo-Salem, Androniki Kozana, Eugen Divjak, Gordana Ivanac, Katerina Nikiforaki, Michail E. Klontzas, Rosa García-Dosdá, Meltem Gulsun-Akpinar, Oğuz Lafcı, Ritse Mann, Carlos Martín-Isla, Fred Prior, Kostas Marias, Martijn P. A. Starmans, Fredrik Strand, Oliver Díaz, Laura Igual, Karim Lekadir

Current research in breast cancer Magnetic Resonance Imaging (MRI),
especially with Artificial Intelligence (AI), faces challenges due to the lack
of expert segmentations. To address this, we introduce the MAMA-MIA dataset,
comprising 1506 multi-center dynamic contrast-enhanced MRI cases with expert
segmentations of primary tumors and non-mass enhancement areas. These cases
were sourced from four publicly available collections in The Cancer Imaging
Archive (TCIA). Initially, we trained a deep learning model to automatically
segment the cases, generating preliminary segmentations that significantly
reduced expert segmentation time. Sixteen experts, averaging 9 years of
experience in breast cancer, then corrected these segmentations, resulting in
the final expert segmentations. Additionally, two radiologists conducted a
visual inspection of the automatic segmentations to support future quality
control studies. Alongside the expert segmentations, we provide 49 harmonized
demographic and clinical variables and the pretrained weights of the well-known
nnUNet architecture trained using the DCE-MRI full-images and expert
segmentations. This dataset aims to accelerate the development and benchmarking
of deep learning models and foster innovation in breast cancer diagnostics and
treatment planning.

摘要：乳腺癌磁共振成像 (MRI) 的現今研究，特別是與人工智慧 (AI) 相關的研究，由於缺乏專家分段而面臨挑戰。為了解決此問題，我們引入了 MAMA-MIA 資料集，其中包含 1506 例多中心動態對比增強 MRI 案例，以及原發腫瘤和非腫塊增強區域的專家分段。這些案例來自癌症影像檔案館 (TCIA) 中的四個公開可取得的集合。最初，我們訓練了一個深度學習模型來自動分段案例，產生初步分段，大幅減少了專家分段時間。16 位專家，平均擁有 9 年乳腺癌經驗，然後修正這些分段，產生最終的專家分段。此外，兩位放射科醫師對自動分段進行視覺檢查，以支援未來的品質控管研究。除了專家分段外，我們還提供了 49 個調和的人口統計和臨床變數，以及使用 DCE-MRI 全影像和專家分段訓練的著名 nnUNet 架構的預訓練權重。此資料集旨在加速深度學習模型的開發和基準測試，並促進乳腺癌診斷和治療計畫的創新。

##### **IoT-Based Preventive Mental Health Using Knowledge Graphs and Standards for Better Well-Being**
2406.13791v1 by Amelie Gyrard, Seyedali Mohammadi, Manas Gaur, Antonio Kung

Sustainable Development Goals (SDGs) give the UN a road map for development
with Agenda 2030 as a target. SDG3 "Good Health and Well-Being" ensures healthy
lives and promotes well-being for all ages. Digital technologies can support
SDG3. Burnout and even depression could be reduced by encouraging better
preventive health. Due to the lack of patient knowledge and focus to take care
of their health, it is necessary to help patients before it is too late. New
trends such as positive psychology and mindfulness are highly encouraged in the
USA. Digital Twin (DT) can help with the continuous monitoring of emotion using
physiological signals (e.g., collected via wearables). Digital twins facilitate
monitoring and provide constant health insight to improve quality of life and
well-being with better personalization. Healthcare DT challenges are
standardizing data formats, communication protocols, and data exchange
mechanisms. To achieve those data integration and knowledge challenges, we
designed the Mental Health Knowledge Graph (ontology and dataset) to boost
mental health. The Knowledge Graph (KG) acquires knowledge from ontology-based
mental health projects classified within the LOV4IoT ontology catalog (Emotion,
Depression, and Mental Health). Furthermore, the KG is mapped to standards
(e.g., ontologies) when possible. Standards from ETSI SmartM2M, ITU/WHO, ISO,
W3C, NIST, and IEEE are relevant to mental health.

摘要：永續發展目標（SDG）為聯合國提供了一個發展路線圖，目標為 2030 年議程。SDG3「良好健康與福祉」確保所有年齡層的健康生活並促進福祉。數位科技可以支援 SDG3。透過鼓勵更好的預防性保健，可以減少倦怠甚至憂鬱症。由於患者缺乏健康知識和關注自身健康的焦點，因此有必要在為時已晚之前幫助患者。積極心理學和正念等新趨勢在美國受到高度鼓勵。數位雙胞胎（DT）可以透過生理訊號（例如透過穿戴式裝置收集）協助持續監控情緒。數位雙胞胎促進監控並提供持續的健康見解，以透過更好的個人化改善生活品質和福祉。醫療保健 DT 的挑戰在於標準化資料格式、通訊協定和資料交換機制。為了達成這些資料整合和知識挑戰，我們設計了心理健康知識圖譜（本体和資料集）來提升心理健康。知識圖譜（KG）從 LOV4IoT 本体目錄（情緒、憂鬱症和心理健康）中分類的基於本体的心理健康專案中獲取知識。此外，KG 盡可能對應到標準（例如本体）。ETSI SmartM2M、ITU/WHO、ISO、W3C、NIST 和 IEEE 的標準與心理健康相關。

##### **BEACON: Balancing Convenience and Nutrition in Meals With Long-Term Group Recommendations and Reasoning on Multimodal Recipes**
2406.13714v1 by Vansh Nagpal, Siva Likitha Valluru, Kausik Lakkaraju, Biplav Srivastava

A common, yet regular, decision made by people, whether healthy or with any
health condition, is to decide what to have in meals like breakfast, lunch, and
dinner, consisting of a combination of foods for appetizer, main course, side
dishes, desserts, and beverages. However, often this decision is seen as a
trade-off between nutritious choices (e.g., low salt and sugar) or convenience
(e.g., inexpensive, fast to prepare/obtain, taste better). In this preliminary
work, we present a data-driven approach for the novel meal recommendation
problem that can explore and balance choices for both considerations while also
reasoning about a food's constituents and cooking process. Beyond the problem
formulation, our contributions also include a goodness measure, a recipe
conversion method from text to the recently introduced multimodal rich recipe
representation (R3) format, and learning methods using contextual bandits that
show promising results.

摘要：人們常規且定期做出的決定，無論是健康的人或是有任何健康狀況的人，就是決定早餐、午餐和晚餐要吃什麼，包括開胃菜、主菜、配菜、甜點和飲料等食物的組合。然而，這個決定通常被視為營養選擇（例如低鹽和低糖）或便利性（例如便宜、快速準備/取得、味道較好）之間的權衡。在這項初步工作中，我們提出了一種資料驅動的方法，用於新穎的餐點推薦問題，該方法可以探索和平衡這兩方面的選擇，同時也能推理食物的成分和烹飪過程。除了問題的表述外，我們的貢獻還包括一個優良度量度、一種從文字轉換為最近推出的多模態豐富食譜表示法 (R3) 格式的食譜轉換方法，以及使用情境強盜的學習方法，這些方法顯示出有希望的結果。

##### **EndoUIC: Promptable Diffusion Transformer for Unified Illumination Correction in Capsule Endoscopy**
2406.13705v1 by Long Bai, Qiaozhi Tan, Tong Chen, Wan Jun Nah, Yanheng Li, Zhicheng He, Sishen Yuan, Zhen Chen, Jinlin Wu, Mobarakol Islam, Zhen Li, Hongbin Liu, Hongliang Ren

Wireless Capsule Endoscopy (WCE) is highly valued for its non-invasive and
painless approach, though its effectiveness is compromised by uneven
illumination from hardware constraints and complex internal dynamics, leading
to overexposed or underexposed images. While researchers have discussed the
challenges of low-light enhancement in WCE, the issue of correcting for
different exposure levels remains underexplored. To tackle this, we introduce
EndoUIC, a WCE unified illumination correction solution using an end-to-end
promptable diffusion transformer (DFT) model. In our work, the illumination
prompt module shall navigate the model to adapt to different exposure levels
and perform targeted image enhancement, in which the Adaptive Prompt
Integration (API) and Global Prompt Scanner (GPS) modules shall further boost
the concurrent representation learning between the prompt parameters and
features. Besides, the U-shaped restoration DFT model shall capture the
long-range dependencies and contextual information for unified illumination
restoration. Moreover, we present a novel Capsule-endoscopy Exposure Correction
(CEC) dataset, including ground-truth and corrupted image pairs annotated by
expert photographers. Extensive experiments against a variety of
state-of-the-art (SOTA) methods on four datasets showcase the effectiveness of
our proposed method and components in WCE illumination restoration, and the
additional downstream experiments further demonstrate its utility for clinical
diagnosis and surgical assistance.

摘要：無線膠囊內視鏡（WCE）因其非侵入性和無痛的方法而備受重視，儘管其有效性受到硬體限制和複雜內部動力學導致照明不均的影響，導致影像曝光過度或曝光不足。儘管研究人員已討論 WCE 中低光增強的挑戰，但針對不同曝光等級進行校正的問題仍未得到充分探討。為了解決這個問題，我們引入了 EndoUIC，這是一個使用端到端可提示擴散轉換器 (DFT) 模型的 WCE 統一照明校正解決方案。在我們的研究中，照明提示模組應引導模型適應不同的曝光等級並執行目標影像增強，其中自適應提示整合 (API) 和全局提示掃描器 (GPS) 模組應進一步提升提示參數和特徵之間的並發表示學習。此外，U 形復原 DFT 模型應捕捉長距離依賴關係和脈絡資訊，以進行統一照明復原。此外，我們提出了創新的膠囊內視鏡曝光校正 (CEC) 資料集，其中包括由專業攝影師註解的真實和損壞影像對。針對四個資料集的各種最新 (SOTA) 方法進行的廣泛實驗展示了我們提出的方法和組成在 WCE 照明復原中的有效性，而額外的下游實驗進一步證明了其在臨床診斷和手術輔助中的效用。

##### **Leveraging Large Language Models for Patient Engagement: The Power of Conversational AI in Digital Health**
2406.13659v1 by Bo Wen, Raquel Norel, Julia Liu, Thaddeus Stappenbeck, Farhana Zulkernine, Huamin Chen

The rapid advancements in large language models (LLMs) have opened up new
opportunities for transforming patient engagement in healthcare through
conversational AI. This paper presents an overview of the current landscape of
LLMs in healthcare, specifically focusing on their applications in analyzing
and generating conversations for improved patient engagement. We showcase the
power of LLMs in handling unstructured conversational data through four case
studies: (1) analyzing mental health discussions on Reddit, (2) developing a
personalized chatbot for cognitive engagement in seniors, (3) summarizing
medical conversation datasets, and (4) designing an AI-powered patient
engagement system. These case studies demonstrate how LLMs can effectively
extract insights and summarizations from unstructured dialogues and engage
patients in guided, goal-oriented conversations. Leveraging LLMs for
conversational analysis and generation opens new doors for many
patient-centered outcomes research opportunities. However, integrating LLMs
into healthcare raises important ethical considerations regarding data privacy,
bias, transparency, and regulatory compliance. We discuss best practices and
guidelines for the responsible development and deployment of LLMs in healthcare
settings. Realizing the full potential of LLMs in digital health will require
close collaboration between the AI and healthcare professionals communities to
address technical challenges and ensure these powerful tools' safety, efficacy,
and equity.

摘要：大型語言模型 (LLM) 的快速進展為透過對話式 AI 轉變醫療保健中的患者參與度開啟了新的機會。本文概述了醫療保健中 LLM 的現況，特別專注於它們在分析和產生對話以改善患者參與度的應用。我們透過四個案例研究展示了 LLM 在處理非結構化對話資料方面的能力：(1) 分析 Reddit 上的心理健康討論，(2) 為老年人的認知參與開發個人化聊天機器人，(3) 總結醫療對話資料集，以及 (4) 設計 AI 驅動的患者參與系統。這些案例研究展示了 LLM 如何從非結構化對話中有效地提取見解和摘要，並讓患者參與有指導性的、以目標為導向的對話。利用 LLM 進行對話分析和產生為以患者為中心的成果研究機會開啟了新的途徑。然而，將 LLM 整合到醫療保健中會引發有關資料隱私、偏差、透明度和法規遵循的重要倫理考量。我們討論了在醫療保健環境中負責任地開發和部署 LLM 的最佳實務和準則。要實現 LLM 在數位健康中的全部潛力，需要 AI 和醫療保健專業人員社群密切合作，以應對技術挑戰並確保這些強大工具的安全、效能和公平性。

##### **Enhance the Image: Super Resolution using Artificial Intelligence in MRI**
2406.13625v1 by Ziyu Li, Zihan Li, Haoxiang Li, Qiuyun Fan, Karla L. Miller, Wenchuan Wu, Akshay S. Chaudhari, Qiyuan Tian

This chapter provides an overview of deep learning techniques for improving
the spatial resolution of MRI, ranging from convolutional neural networks,
generative adversarial networks, to more advanced models including
transformers, diffusion models, and implicit neural representations. Our
exploration extends beyond the methodologies to scrutinize the impact of
super-resolved images on clinical and neuroscientific assessments. We also
cover various practical topics such as network architectures, image evaluation
metrics, network loss functions, and training data specifics, including
downsampling methods for simulating low-resolution images and dataset
selection. Finally, we discuss existing challenges and potential future
directions regarding the feasibility and reliability of deep learning-based MRI
super-resolution, with the aim to facilitate its wider adoption to benefit
various clinical and neuroscientific applications.

摘要：本章概述了用於改善 MRI 空間解析度的深度學習技術，涵蓋了從卷積神經網路、生成對抗網路到更先進的模型，包括Transformer、擴散模型和隱式神經表示。我們的探討不僅限於方法論，還審查了超解析影像對臨床和神經科學評估的影響。我們也涵蓋了各種實務主題，例如網路架構、影像評估指標、網路損失函數和訓練資料規範，包括用於模擬低解析度影像的下採樣方法和資料集選擇。最後，我們討論了基於深度學習的 MRI 超解析技術的可行性和可靠性方面的現有挑戰和潛在未來方向，目的是促進其更廣泛的採用，以造福各種臨床和神經科學應用。

##### **Optimizing Psychological Counseling with Instruction-Tuned Large Language Models**
2406.13617v1 by Wenjie Li, Tianyu Sun, Kun Qian, Wenhong Wang

The advent of large language models (LLMs) has significantly advanced various
fields, including natural language processing and automated dialogue systems.
This paper explores the application of LLMs in psychological counseling,
addressing the increasing demand for mental health services. We present a
method for instruction tuning LLMs with specialized prompts to enhance their
performance in providing empathetic, relevant, and supportive responses. Our
approach involves developing a comprehensive dataset of counseling-specific
prompts, refining them through feedback from professional counselors, and
conducting rigorous evaluations using both automatic metrics and human
assessments. The results demonstrate that our instruction-tuned model
outperforms several baseline LLMs, highlighting its potential as a scalable and
accessible tool for mental health support.

摘要：大型語言模型 (LLM) 的出現顯著提升了各種領域，包括自然語言處理和自動對話系統。這篇論文探討了 LLM 在心理諮商中的應用，以解決對心理健康服務日益增長的需求。我們提出了一種使用專門提示來調整 LLM 指令的方法，以增強它們在提供同理、相關和支持性回應方面的表現。我們的做法包括開發一個全面的諮商特定提示資料集，透過專業諮商師的回饋來改善提示，並使用自動化指標和人工評估進行嚴謹的評估。結果表明，我們調整指令的模型優於幾個基準 LLM，突顯了它作為心理健康支援的可擴充且可存取工具的潛力。

##### **Certificates of Differential Privacy and Unlearning for Gradient-Based Training**
2406.13433v1 by Matthew Wicker, Philip Sosnin, Adrianna Janik, Mark N. Müller, Adrian Weller, Calvin Tsay

Proper data stewardship requires that model owners protect the privacy of
individuals' data used during training. Whether through anonymization with
differential privacy or the use of unlearning in non-anonymized settings, the
gold-standard techniques for providing privacy guarantees can come with
significant performance penalties or be too weak to provide practical
assurances. In part, this is due to the fact that the guarantee provided by
differential privacy represents the worst-case privacy leakage for any
individual, while the true privacy leakage of releasing the prediction for a
given individual might be substantially smaller or even, as we show,
non-existent. This work provides a novel framework based on convex relaxations
and bounds propagation that can compute formal guarantees (certificates) that
releasing specific predictions satisfies $\epsilon=0$ privacy guarantees or do
not depend on data that is subject to an unlearning request. Our framework
offers a new verification-centric approach to privacy and unlearning
guarantees, that can be used to further engender user trust with tighter
privacy guarantees, provide formal proofs of robustness to certain membership
inference attacks, identify potentially vulnerable records, and enhance current
unlearning approaches. We validate the effectiveness of our approach on tasks
from financial services, medical imaging, and natural language processing.

摘要：適當的資料管理要求模型擁有者保護個人在訓練期間所使用資料的隱私。無論是透過具有差分隱私的匿名化或是在非匿名化設定中使用忘記，提供隱私保證的黃金標準技術都可能伴隨著顯著的效能損失，或過於薄弱而無法提供實際保證。部分原因在於，差分隱私提供的保證代表任何個人的最差情況隱私洩漏，而釋出給定個人預測的真實隱私洩漏可能大幅減少，甚至如我們所展示的，不存在。這項工作提供一個新的架構，基於凸弛豫和邊界傳播，可以計算形式化保證（證明），釋出特定預測滿足 $\epsilon=0$ 隱私保證，或不依賴於受忘記要求約束的資料。我們的架構提供一個新的以驗證為中心的隱私和忘記保證方法，可用於進一步提升使用者對更嚴格隱私保證的信任，提供對特定成員推論攻擊的正式穩健性證明，識別潛在的脆弱記錄，並增強目前的忘記方法。我們在金融服務、醫學影像和自然語言處理的任務中驗證了我們方法的有效性。

##### **Explainable by-design Audio Segmentation through Non-Negative Matrix Factorization and Probing**
2406.13385v1 by Martin Lebourdais, Théo Mariotte, Antonio Almudévar, Marie Tahon, Alfonso Ortega

Audio segmentation is a key task for many speech technologies, most of which
are based on neural networks, usually considered as black boxes, with
high-level performances. However, in many domains, among which health or
forensics, there is not only a need for good performance but also for
explanations about the output decision. Explanations derived directly from
latent representations need to satisfy "good" properties, such as
informativeness, compactness, or modularity, to be interpretable. In this
article, we propose an explainable-by-design audio segmentation model based on
non-negative matrix factorization (NMF) which is a good candidate for the
design of interpretable representations. This paper shows that our model
reaches good segmentation performances, and presents deep analyses of the
latent representation extracted from the non-negative matrix. The proposed
approach opens new perspectives toward the evaluation of interpretable
representations according to "good" properties.

摘要：音訊區段化是許多語音技術的關鍵任務，其中大部分基於神經網路，通常被視為黑盒子，具有高階效能。然而，在許多領域中，其中包含健康或法醫學，不僅需要良好的效能，也需要對輸出決策進行說明。直接從潛在表徵中衍生的說明需要滿足「良好」的特性，例如資訊性、緊湊性或模組化，才能被解釋。在本文中，我們提出一個可解釋的音訊區段化模型，該模型基於非負矩陣分解 (NMF)，這是非負表徵設計的良好候選者。本文顯示我們的模型達到良好的區段化效能，並對從非負矩陣中提取的潛在表徵進行深入分析。所提出的方法為根據「良好」特性評估可解釋的表徵開啟新的觀點。

##### **Biomedical Visual Instruction Tuning with Clinician Preference Alignment**
2406.13173v1 by Hejie Cui, Lingjun Mao, Xin Liang, Jieyu Zhang, Hui Ren, Quanzheng Li, Xiang Li, Carl Yang

Recent advancements in multimodal foundation models have showcased impressive
capabilities in understanding and reasoning with visual and textual
information. Adapting these foundation models trained for general usage to
specialized domains like biomedicine requires large-scale domain-specific
instruction datasets. While existing works have explored curating such datasets
automatically, the resultant datasets are not explicitly aligned with domain
expertise. In this work, we propose a data-centric framework, Biomedical Visual
Instruction Tuning with Clinician Preference Alignment (BioMed-VITAL), that
incorporates clinician preferences into both stages of generating and selecting
instruction data for tuning biomedical multimodal foundation models. First,
during the generation stage, we prompt the GPT-4V generator with a diverse set
of clinician-selected demonstrations for preference-aligned data candidate
generation. Then, during the selection phase, we train a separate selection
model, which explicitly distills clinician and policy-guided model preferences
into a rating function to select high-quality data for medical instruction
tuning. Results show that the model tuned with the instruction-following data
from our method demonstrates a significant improvement in open visual chat
(18.5% relatively) and medical VQA (win rate up to 81.73%). Our
instruction-following data and models are available at BioMed-VITAL.github.io.

摘要：多模态基础模型的最新进展展示了令人印象深刻的能力，能够理解和推理视觉和文本信息。将这些针对一般用途训练的基础模型调整到生物医学等专业领域需要大规模的特定领域指导数据集。虽然现有工作已经探索了自动整理此类数据集，但结果数据集并未明确与领域专业知识保持一致。在这项工作中，我们提出了一个以数据为中心框架，即生物医学视觉指令调整与临床医生偏好对齐 (BioMed-VITAL)，它将临床医生偏好纳入生成和选择用于调整生物医学多模态基础模型的指令数据的两个阶段。首先，在生成阶段，我们使用一组由临床医生选择的演示提示 GPT-4V 生成器，以生成偏好对齐的数据候选。然后，在选择阶段，我们训练一个单独的选择模型，该模型明确地将临床医生和政策指导的模型偏好提炼成一个评级函数，以选择用于医学指令调整的高质量数据。结果表明，使用我们方法中的指令遵循数据调整的模型在开放式视觉聊天（相对提高 18.5%）和医学 VQA（获胜率高达 81.73%）方面表现出显着提升。我们的指令遵循数据和模型可在 BioMed-VITAL.github.io 获得。

##### **Cardiac Copilot: Automatic Probe Guidance for Echocardiography with World Model**
2406.13165v1 by Haojun Jiang, Zhenguo Sun, Ning Jia, Meng Li, Yu Sun, Shaqi Luo, Shiji Song, Gao Huang

Echocardiography is the only technique capable of real-time imaging of the
heart and is vital for diagnosing the majority of cardiac diseases. However,
there is a severe shortage of experienced cardiac sonographers, due to the
heart's complex structure and significant operational challenges. To mitigate
this situation, we present a Cardiac Copilot system capable of providing
real-time probe movement guidance to assist less experienced sonographers in
conducting freehand echocardiography. This system can enable non-experts,
especially in primary departments and medically underserved areas, to perform
cardiac ultrasound examinations, potentially improving global healthcare
delivery. The core innovation lies in proposing a data-driven world model,
named Cardiac Dreamer, for representing cardiac spatial structures. This world
model can provide structure features of any cardiac planes around the current
probe position in the latent space, serving as an precise navigation map for
autonomous plane localization. We train our model with real-world ultrasound
data and corresponding probe motion from 110 routine clinical scans with 151K
sample pairs by three certified sonographers. Evaluations on three standard
planes with 37K sample pairs demonstrate that the world model can reduce
navigation errors by up to 33\% and exhibit more stable performance.

摘要：超音波心動圖是唯一能即時影像化心臟的技術，對於診斷大部分的心臟疾病至關重要。然而，由於心臟結構複雜且操作上有相當的挑戰，因此經驗豐富的心臟超音波檢查員嚴重短缺。為了緩解這種情況，我們提出了一套心臟輔助駕駛系統，能夠提供即時的探頭移動引導，協助經驗較少的超音波檢查員進行徒手超音波心動圖檢查。此系統讓非專家，特別是在基層部門和醫療資源不足的地區，也能執行心臟超音波檢查，有潛力改善全球的醫療保健服務。核心的創新在於提出一個資料驅動的世界模型，稱為心臟夢幻家，用於表示心臟的空間結構。此世界模型能提供任何心臟平面的結構特徵，圍繞著潛在空間中的當前探頭位置，作為自主平面定位的精確導航地圖。我們利用 110 次例行臨床掃描的真實世界超音波數據和對應的探頭運動，由三位認證的超音波檢查員提供 151K 個樣本對，來訓練我們的模型。在三個標準平面上，使用 37K 個樣本對進行的評估顯示，世界模型可以將導航誤差減少多達 33%，且表現出更穩定的效能。

##### **Oralytics Reinforcement Learning Algorithm**
2406.13127v1 by Anna L. Trella, Kelly W. Zhang, Stephanie M. Carpenter, David Elashoff, Zara M. Greer, Inbal Nahum-Shani, Dennis Ruenger, Vivek Shetty, Susan A. Murphy

Dental disease is still one of the most common chronic diseases in the United
States. While dental disease is preventable through healthy oral self-care
behaviors (OSCB), this basic behavior is not consistently practiced. We have
developed Oralytics, an online, reinforcement learning (RL) algorithm that
optimizes the delivery of personalized intervention prompts to improve OSCB. In
this paper, we offer a full overview of algorithm design decisions made using
prior data, domain expertise, and experiments in a simulation test bed. The
finalized RL algorithm was deployed in the Oralytics clinical trial, conducted
from fall 2023 to summer 2024.

摘要：牙科疾病仍然是美國最常見的慢性疾病之一。雖然牙科疾病可透過健康的口腔自我保健行為（OSCB）預防，但這種基本行為並未持續實行。我們開發出 Oralytics，一種線上強化學習（RL）演算法，可最佳化個人化介入提示的傳遞，以改善 OSCB。在本文中，我們將全面概述演算法設計決策，這些決策是使用先前的資料、領域專業知識和模擬測試平台中的實驗所做出的。最終的 RL 演算法已部署在 Oralytics 臨床試驗中，該試驗於 2023 年秋季至 2024 年夏季進行。

##### **Accelerating Complex Disease Treatment through Network Medicine and GenAI: A Case Study on Drug Repurposing for Breast Cancer**
2406.13106v2 by Ahmed Abdeen Hamed, Tamer E. Fandy

The objective of this research is to introduce a network specialized in
predicting drugs that can be repurposed by investigating real-world evidence
sources, such as clinical trials and biomedical literature. Specifically, it
aims to generate drug combination therapies for complex diseases (e.g., cancer,
Alzheimer's). We present a multilayered network medicine approach, empowered by
a highly configured ChatGPT prompt engineering system, which is constructed on
the fly to extract drug mentions in clinical trials. Additionally, we introduce
a novel algorithm that connects real-world evidence with disease-specific
signaling pathways (e.g., KEGG database). This sheds light on the
repurposability of drugs if they are found to bind with one or more protein
constituents of a signaling pathway. To demonstrate, we instantiated the
framework for breast cancer and found that, out of 46 breast cancer signaling
pathways, the framework identified 38 pathways that were covered by at least
two drugs. This evidence signals the potential for combining those drugs.
Specifically, the most covered signaling pathway, ID hsa:2064, was covered by
108 drugs, some of which can be combined. Conversely, the signaling pathway ID
hsa:1499 was covered by only two drugs, indicating a significant gap for
further research. Our network medicine framework, empowered by GenAI, shows
promise in identifying drug combinations with a high degree of specificity,
knowing the exact signaling pathways and proteins that serve as targets. It is
noteworthy that ChatGPT successfully accelerated the process of identifying
drug mentions in clinical trials, though further investigations are required to
determine the relationships among the drug mentions.

摘要：本研究的目標是介紹一個專門用於預測藥物，可透過研究實際證據來源（例如臨床試驗和生物醫學文獻）重新利用的網路。具體來說，其目標是為複雜疾病（例如癌症、阿茲海默症）產生藥物組合療法。我們提出一個多層網路醫學方法，由一個高度配置的 ChatGPT 提示工程系統強化，該系統在執行中建構，用於萃取臨床試驗中的藥物提及。此外，我們介紹一種新的演算法，將實際證據與疾病特定訊號傳遞路徑（例如 KEGG 資料庫）連結起來。如果發現藥物與訊號傳遞路徑的一個或多個蛋白質成分結合，這將有助於了解藥物的再利用性。為了示範，我們為乳癌實例化架構，發現出 46 條乳癌訊號傳遞路徑中，該架構識別出 38 條至少被兩種藥物涵蓋的路徑。此證據表明結合這些藥物的可能性。具體來說，涵蓋最廣的訊號傳遞路徑 ID hsa:2064，涵蓋了 108 種藥物，其中一些可以合併。相反地，訊號傳遞路徑 ID hsa:1499 僅涵蓋兩種藥物，這表示有重大差距需要進一步研究。我們的網路醫學架構由 GenAI 強化，在識別具有高度特異性的藥物組合方面顯示出前景，了解作為目標的精確訊號傳遞路徑和蛋白質。值得注意的是，ChatGPT 成功加速了識別臨床試驗中藥物提及的過程，儘管需要進一步調查以確定藥物提及之間的關係。

##### **Deriving Hematological Disease Classes Using Fuzzy Logic and Expert Knowledge: A Comprehensive Machine Learning Approach with CBC Parameters**
2406.13015v1 by Salem Ameen, Ravivarman Balachandran, Theodoros Theodoridis

In the intricate field of medical diagnostics, capturing the subtle
manifestations of diseases remains a challenge. Traditional methods, often
binary in nature, may not encapsulate the nuanced variances that exist in
real-world clinical scenarios. This paper introduces a novel approach by
leveraging Fuzzy Logic Rules to derive disease classes based on expert domain
knowledge from a medical practitioner. By recognizing that diseases do not
always fit into neat categories, and that expert knowledge can guide the
fuzzification of these boundaries, our methodology offers a more sophisticated
and nuanced diagnostic tool.
  Using a dataset procured from a prominent hospital, containing detailed
patient blood count records, we harness Fuzzy Logic Rules, a computational
technique celebrated for its ability to handle ambiguity. This approach, moving
through stages of fuzzification, rule application, inference, and ultimately
defuzzification, produces refined diagnostic predictions. When combined with
the Random Forest classifier, the system adeptly predicts hematological
conditions using Complete Blood Count (CBC) parameters.
  Preliminary results showcase high accuracy levels, underscoring the
advantages of integrating fuzzy logic into the diagnostic process. When
juxtaposed with traditional diagnostic techniques, it becomes evident that
Fuzzy Logic, especially when guided by medical expertise, offers significant
advancements in the realm of hematological diagnostics. This paper not only
paves the path for enhanced patient care but also beckons a deeper dive into
the potentialities of fuzzy logic in various medical diagnostic applications.

摘要：在複雜的醫療診斷領域中，捕捉疾病的細微表現仍是一項挑戰。傳統方法通常本質上是二元的，可能無法概括現實世界臨床情境中存在的細微差異。本文透過利用模糊邏輯規則，根據醫療從業人員的專業領域知識推導疾病類別，引入了一種新穎的方法。我們的做法承認疾病並不總是符合明確的類別，而且專家知識可以指導這些邊界的模糊化，從而提供更精緻且細緻的診斷工具。
使用從一家知名醫院取得的資料集，其中包含詳細的患者血球計數記錄，我們利用模糊邏輯規則，這是一種以處理模糊性能力而著稱的計算技術。這種方法經過模糊化、規則應用、推論和最終去模糊化的階段，產生精煉的診斷預測。與隨機森林分類器結合使用時，該系統使用全血細胞計數 (CBC) 參數熟練地預測血液學狀況。
初步結果展示了高準確度，強調了將模糊邏輯整合到診斷過程中的優點。與傳統診斷技術並置時，顯然模糊邏輯，尤其是在醫療專業知識的指導下，為血液學診斷領域提供了顯著的進展。本文不僅為增強的患者照護鋪平了道路，也呼籲更深入地探討模糊邏輯在各種醫療診斷應用中的潛力。

##### **Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation**
2406.12815v1 by Nikolas Koutsoubis, Yasin Yilmaz, Ravi P. Ramachandran, Matthew Schabath, Ghulam Rasool

Machine learning (ML) and Artificial Intelligence (AI) have fueled remarkable
advancements, particularly in healthcare. Within medical imaging, ML models
hold the promise of improving disease diagnoses, treatment planning, and
post-treatment monitoring. Various computer vision tasks like image
classification, object detection, and image segmentation are poised to become
routine in clinical analysis. However, privacy concerns surrounding patient
data hinder the assembly of large training datasets needed for developing and
training accurate, robust, and generalizable models. Federated Learning (FL)
emerges as a compelling solution, enabling organizations to collaborate on ML
model training by sharing model training information (gradients) rather than
data (e.g., medical images). FL's distributed learning framework facilitates
inter-institutional collaboration while preserving patient privacy. However,
FL, while robust in privacy preservation, faces several challenges. Sensitive
information can still be gleaned from shared gradients that are passed on
between organizations during model training. Additionally, in medical imaging,
quantifying model confidence\uncertainty accurately is crucial due to the noise
and artifacts present in the data. Uncertainty estimation in FL encounters
unique hurdles due to data heterogeneity across organizations. This paper
offers a comprehensive review of FL, privacy preservation, and uncertainty
estimation, with a focus on medical imaging. Alongside a survey of current
research, we identify gaps in the field and suggest future directions for FL
research to enhance privacy and address noisy medical imaging data challenges.

摘要：機器學習 (ML) 和人工智慧 (AI) 已推動顯著的進展，特別是在醫療保健方面。在醫學影像中，ML 模型有望改善疾病診斷、治療規劃和治療後監控。各種電腦視覺任務，例如影像分類、物件偵測和影像分割，都準備好在臨床分析中成為常規。然而，圍繞患者資料的隱私問題阻礙了組建大型訓練資料集，而這對於開發和訓練準確、強健且可概化的模型是必要的。聯邦學習 (FL) 成為一個引人注目的解決方案，使組織能夠透過分享模型訓練資訊 (梯度) 而不是資料（例如醫學影像）來協作進行 ML 模型訓練。FL 的分散式學習架構促進了機構間的協作，同時保護了患者隱私。然而，FL 雖然在隱私保護方面很強大，但仍面臨許多挑戰。敏感資訊仍然可以從組織在模型訓練期間傳遞的共享梯度中收集。此外，在醫學影像中，由於資料中存在雜訊和人工製品，因此準確量化模型信心/不確定性至關重要。由於組織間資料異質性，FL 中的不確定性估計會遇到獨特障礙。本文全面回顧了 FL、隱私保護和不確定性估計，重點放在醫學影像上。除了對當前研究進行調查外，我們還找出該領域的差距，並提出 FL 研究的未來方向，以增強隱私並解決雜訊醫學影像資料的挑戰。

##### **Probabilistic Temporal Prediction of Continuous Disease Trajectories and Treatment Effects Using Neural SDEs**
2406.12807v1 by Joshua Durso-Finley, Berardino Barile, Jean-Pierre Falet, Douglas L. Arnold, Nick Pawlowski, Tal Arbel

Personalized medicine based on medical images, including predicting future
individualized clinical disease progression and treatment response, would have
an enormous impact on healthcare and drug development, particularly for
diseases (e.g. multiple sclerosis (MS)) with long term, complex, heterogeneous
evolutions and no cure. In this work, we present the first stochastic causal
temporal framework to model the continuous temporal evolution of disease
progression via Neural Stochastic Differential Equations (NSDE). The proposed
causal inference model takes as input the patient's high dimensional images
(MRI) and tabular data, and predicts both factual and counterfactual
progression trajectories on different treatments in latent space. The NSDE
permits the estimation of high-confidence personalized trajectories and
treatment effects. Extensive experiments were performed on a large,
multi-centre, proprietary dataset of patient 3D MRI and clinical data acquired
during several randomized clinical trials for MS treatments. Our results
present the first successful uncertainty-based causal Deep Learning (DL) model
to: (a) accurately predict future patient MS disability evolution (e.g. EDSS)
and treatment effects leveraging baseline MRI, and (b) permit the discovery of
subgroups of patients for which the model has high confidence in their response
to treatment even in clinical trials which did not reach their clinical
endpoints.

摘要：基於醫學影像的個人化醫療，包括預測未來個人化臨床疾病進程和治療反應，將對醫療保健和藥物開發產生巨大影響，特別是對於長期、複雜、異質性演化且無法治癒的疾病（例如多發性硬化症 (MS)）。在這項工作中，我們提出了第一個隨機因果時間框架，透過神經隨機微分方程式 (NSDE) 對疾病進程的連續時間演化進行建模。所提出的因果推論模型以病患的高維度影像（MRI）和表格資料作為輸入，並預測潛在空間中不同治療的實際和反事實進程軌跡。NSDE 允許估計高可信度的個人化軌跡和治療效果。在針對 MS 治療進行的幾項隨機臨床試驗中，對一個大型、多中心、專有資料集的病患 3D MRI 和臨床資料進行了廣泛的實驗。我們的結果展示了第一個成功的基於不確定性的因果深度學習 (DL) 模型：(a) 準確預測未來的病患 MS 殘疾演化（例如 EDSS）和利用基線 MRI 的治療效果，以及 (b) 允許發現即使在未達到臨床終點的臨床試驗中，模型對其治療反應具有高度信心的病患子群。

##### **Large Language Model as a Universal Clinical Multi-task Decoder**
2406.12738v1 by Yujiang Wu, Hongjian Song, Jiawen Zhang, Xumeng Wen, Shun Zheng, Jiang Bian

The development of effective machine learning methodologies for enhancing the
efficiency and accuracy of clinical systems is crucial. Despite significant
research efforts, managing a plethora of diversified clinical tasks and
adapting to emerging new tasks remain significant challenges. This paper
presents a novel paradigm that employs a pre-trained large language model as a
universal clinical multi-task decoder. This approach leverages the flexibility
and diversity of language expressions to handle task topic variations and
associated arguments. The introduction of a new task simply requires the
addition of a new instruction template. We validate this framework across
hundreds of tasks, demonstrating its robustness in facilitating multi-task
predictions, performing on par with traditional multi-task learning and
single-task learning approaches. Moreover, it shows exceptional adaptability to
new tasks, with impressive zero-shot performance in some instances and superior
data efficiency in few-shot scenarios. This novel approach offers a unified
solution to manage a wide array of new and emerging tasks in clinical
applications.

摘要：<paragraph>開發有效的機器學習方法，以提升臨床系統的效率和準確性至關重要。儘管研究付出相當大的努力，管理大量多樣化的臨床任務和適應新興任務仍然是重大的挑戰。本文提出了一種新的範例，採用預先訓練的大型語言模型作為通用的臨床多任務解碼器。此方法利用語言表達的靈活性與多樣性來處理任務主題變化和相關論點。引入新任務只需要新增一個新的指令範本。我們驗證了這個架構在數百個任務中，證明了它在促進多任務預測方面的穩健性，執行與傳統多任務學習和單任務學習方法相當。此外，它展現出對新任務的卓越適應性，在某些情況下具有令人印象深刻的零次學習效能，在少量學習場景中具有優異的資料效率。這種新方法提供了一個統一的解決方案，來管理臨床應用中各種新的和新興任務。</paragraph>

##### **Online-Adaptive Anomaly Detection for Defect Identification in Aircraft Assembly**
2406.12698v1 by Siddhant Shete, Dennis Mronga, Ankita Jadhav, Frank Kirchner

Anomaly detection deals with detecting deviations from established patterns
within data. It has various applications like autonomous driving, predictive
maintenance, and medical diagnosis. To improve anomaly detection accuracy,
transfer learning can be applied to large, pre-trained models and adapt them to
the specific application context. In this paper, we propose a novel framework
for online-adaptive anomaly detection using transfer learning. The approach
adapts to different environments by selecting visually similar training images
and online fitting a normality model to EfficientNet features extracted from
the training subset. Anomaly detection is then performed by computing the
Mahalanobis distance between the normality model and the test image features.
Different similarity measures (SIFT/FLANN, Cosine) and normality models (MVG,
OCSVM) are employed and compared with each other. We evaluate the approach on
different anomaly detection benchmarks and data collected in controlled
laboratory settings. Experimental results showcase a detection accuracy
exceeding 0.975, outperforming the state-of-the-art ET-NET approach.

摘要：異常偵測處理偵測資料中既有模式的偏差。它有各種應用，例如自動駕駛、預測性維護和醫療診斷。為了改善異常偵測的準確性，轉移學習可以應用於大型預訓練模型，並將它們適應到特定的應用情境中。在本文中，我們提出了一個新的框架，用於使用轉移學習進行線上自適應異常偵測。此方法透過選擇視覺上相似的訓練影像，並線上擬合一個常態模型到從訓練子集中萃取的 EfficientNet 特徵，來適應不同的環境。然後透過計算常態模型和測試影像特徵之間的馬氏距離來執行異常偵測。採用不同的相似性度量（SIFT/FLANN、餘弦）和常態模型（MVG、OCSVM），並相互比較。我們在不同的異常偵測基準和受控實驗室設定中收集的資料上評估此方法。實驗結果顯示偵測準確度超過 0.975，優於最先進的 ET-NET 方法。

##### **Transforming Surgical Interventions with Embodied Intelligence for Ultrasound Robotics**
2406.12651v1 by Huan Xu, Jinlin Wu, Guanglin Cao, Zhen Chen, Zhen Lei, Hongbin Liu

Ultrasonography has revolutionized non-invasive diagnostic methodologies,
significantly enhancing patient outcomes across various medical domains.
Despite its advancements, integrating ultrasound technology with robotic
systems for automated scans presents challenges, including limited command
understanding and dynamic execution capabilities. To address these challenges,
this paper introduces a novel Ultrasound Embodied Intelligence system that
synergistically combines ultrasound robots with large language models (LLMs)
and domain-specific knowledge augmentation, enhancing ultrasound robots'
intelligence and operational efficiency. Our approach employs a dual strategy:
firstly, integrating LLMs with ultrasound robots to interpret doctors' verbal
instructions into precise motion planning through a comprehensive understanding
of ultrasound domain knowledge, including APIs and operational manuals;
secondly, incorporating a dynamic execution mechanism, allowing for real-time
adjustments to scanning plans based on patient movements or procedural errors.
We demonstrate the effectiveness of our system through extensive experiments,
including ablation studies and comparisons across various models, showcasing
significant improvements in executing medical procedures from verbal commands.
Our findings suggest that the proposed system improves the efficiency and
quality of ultrasound scans and paves the way for further advancements in
autonomous medical scanning technologies, with the potential to transform
non-invasive diagnostics and streamline medical workflows.

摘要：超音波徹底改變了非侵入性診斷方法，大幅提升各種醫療領域的患者治療成果。儘管有這些進展，但將超音波技術與機器人系統整合以進行自動化掃描會產生挑戰，包括有限的指令理解和動態執行能力。為了應對這些挑戰，本文介紹了一種創新的超音波具身智慧系統，該系統將超音波機器人與大型語言模型 (LLM) 和特定領域的知識擴充結合在一起，增強超音波機器人的智慧和操作效率。我們的做法採用雙重策略：首先，將 LLM 與超音波機器人整合，透過全面理解超音波領域知識（包括 API 和操作手冊），將醫生的口頭指示轉換為精確的動作規劃；其次，加入動態執行機制，允許根據患者移動或程序錯誤即時調整掃描計畫。我們透過廣泛的實驗（包括消融研究和各種模型的比較）證明了我們系統的有效性，展示了根據口頭指令執行醫療程序的顯著進步。我們的研究結果表明，所提出的系統改善了超音波掃描的效率和品質，並為自主醫療掃描技術的進一步發展鋪路，有潛力轉型非侵入性診斷並簡化醫療工作流程。

##### **An Empirical Study on the Fairness of Foundation Models for Multi-Organ Image Segmentation**
2406.12646v1 by Qin Li, Yizhe Zhang, Yan Li, Jun Lyu, Meng Liu, Longyu Sun, Mengting Sun, Qirong Li, Wenyue Mao, Xinran Wu, Yajing Zhang, Yinghua Chu, Shuo Wang, Chengyan Wang

The segmentation foundation model, e.g., Segment Anything Model (SAM), has
attracted increasing interest in the medical image community. Early pioneering
studies primarily concentrated on assessing and improving SAM's performance
from the perspectives of overall accuracy and efficiency, yet little attention
was given to the fairness considerations. This oversight raises questions about
the potential for performance biases that could mirror those found in
task-specific deep learning models like nnU-Net. In this paper, we explored the
fairness dilemma concerning large segmentation foundation models. We
prospectively curate a benchmark dataset of 3D MRI and CT scans of the organs
including liver, kidney, spleen, lung and aorta from a total of 1056 healthy
subjects with expert segmentations. Crucially, we document demographic details
such as gender, age, and body mass index (BMI) for each subject to facilitate a
nuanced fairness analysis. We test state-of-the-art foundation models for
medical image segmentation, including the original SAM, medical SAM and SAT
models, to evaluate segmentation efficacy across different demographic groups
and identify disparities. Our comprehensive analysis, which accounts for
various confounding factors, reveals significant fairness concerns within these
foundational models. Moreover, our findings highlight not only disparities in
overall segmentation metrics, such as the Dice Similarity Coefficient but also
significant variations in the spatial distribution of segmentation errors,
offering empirical evidence of the nuanced challenges in ensuring fairness in
medical image segmentation.

摘要：例如，任何分割模型（SAM）等分割基础模型在医学影像社群中已引起越来越多的兴趣。早期开创性研究主要集中于从整体准确性和效率的角度评估和改进 SAM 的性能，但很少关注公平性考量。这种疏忽引起了人们对性能偏差的质疑，这些偏差可能反映在 nnU-Net 等特定任务深度学习模型中发现的偏差。在本文中，我们探讨了与大型分割基础模型有关的公平性困境。我们前瞻性地整理了一个基准数据集，其中包含来自 1056 名健康受试者的器官（包括肝脏、肾脏、脾脏、肺和主动脉）的 3D MRI 和 CT 扫描，并由专家进行分割。至关重要的是，我们记录了每个受试者的性别、年龄和体重指数 (BMI) 等人口统计详细信息，以促进细致入微的公平性分析。我们测试了用于医学图像分割的最新基础模型，包括原始 SAM、医学 SAM 和 SAT 模型，以评估不同人口群体的分割效果并找出差异。我们的综合分析考虑了各种混杂因素，揭示了这些基础模型中存在的重大公平性问题。此外，我们的研究结果不仅突出了整体分割指标（例如骰子相似系数）的差异，还突出了分割错误的空间分布的显着差异，为确保医学图像分割中的公平性提供了细微挑战的经验证据。

##### **Retrieval-Augmented Generation for Generative Artificial Intelligence in Medicine**
2406.12449v1 by Rui Yang, Yilin Ning, Emilia Keppo, Mingxuan Liu, Chuan Hong, Danielle S Bitterman, Jasmine Chiat Ling Ong, Daniel Shu Wei Ting, Nan Liu

Generative artificial intelligence (AI) has brought revolutionary innovations
in various fields, including medicine. However, it also exhibits limitations.
In response, retrieval-augmented generation (RAG) provides a potential
solution, enabling models to generate more accurate contents by leveraging the
retrieval of external knowledge. With the rapid advancement of generative AI,
RAG can pave the way for connecting this transformative technology with medical
applications and is expected to bring innovations in equity, reliability, and
personalization to health care.

摘要：生成式人工智能 (AI) 已為包括醫學在內的各個領域帶來革命性的創新。然而，它也表現出局限性。為了解決這個問題，檢索增強生成 (RAG) 提供了一個潛在的解決方案，使模型能夠透過利用外部知識的檢索來產生更準確的內容。隨著生成式 AI 的快速進展，RAG 可以為將這項轉型技術與醫療應用相連鋪路，並有望為醫療保健帶來公平性、可靠性和個人化的創新。

##### **Adversarial Attacks on Large Language Models in Medicine**
2406.12259v1 by Yifan Yang, Qiao Jin, Furong Huang, Zhiyong Lu

The integration of Large Language Models (LLMs) into healthcare applications
offers promising advancements in medical diagnostics, treatment
recommendations, and patient care. However, the susceptibility of LLMs to
adversarial attacks poses a significant threat, potentially leading to harmful
outcomes in delicate medical contexts. This study investigates the
vulnerability of LLMs to two types of adversarial attacks in three medical
tasks. Utilizing real-world patient data, we demonstrate that both open-source
and proprietary LLMs are susceptible to manipulation across multiple tasks.
This research further reveals that domain-specific tasks demand more
adversarial data in model fine-tuning than general domain tasks for effective
attack execution, especially for more capable models. We discover that while
integrating adversarial data does not markedly degrade overall model
performance on medical benchmarks, it does lead to noticeable shifts in
fine-tuned model weights, suggesting a potential pathway for detecting and
countering model attacks. This research highlights the urgent need for robust
security measures and the development of defensive mechanisms to safeguard LLMs
in medical applications, to ensure their safe and effective deployment in
healthcare settings.

摘要：大型語言模型 (LLM) 整合到醫療保健應用程式中，在醫療診斷、治療建議和病人照護方面提供了有希望的進展。然而，LLM 對對抗性攻擊的敏感性構成重大威脅，可能導致在微妙的醫療環境中造成有害的後果。本研究調查了 LLM 在三項醫療任務中對兩種對抗性攻擊的脆弱性。利用真實世界的病人資料，我們證明開源和專有 LLM 都容易受到多項任務的操縱。這項研究進一步揭示，與一般領域任務相比，特定領域任務需要在模型微調中更多對抗性資料才能有效執行攻擊，特別是對於功能更強大的模型。我們發現，雖然整合對抗性資料並不會顯著降低醫療基準上的整體模型效能，但它確實會導致微調模型權重發生明顯的轉變，這表明有潛在途徑可以偵測和反制模型攻擊。本研究強調了對健全安全措施和防禦機制開發的迫切需求，以保護醫療應用程式中的 LLM，確保它們在醫療保健環境中安全有效地部署。

##### **Enhancing Diagnostic Reliability of Foundation Model with Uncertainty Estimation in OCT Images**
2406.16942v1 by Yuanyuan Peng, Aidi Lin, Meng Wang, Tian Lin, Ke Zou, Yinglin Cheng, Tingkun Shi, Xulong Liao, Lixia Feng, Zhen Liang, Xinjian Chen, Huazhu Fu, Haoyu Chen

Inability to express the confidence level and detect unseen classes has
limited the clinical implementation of artificial intelligence in the
real-world. We developed a foundation model with uncertainty estimation (FMUE)
to detect 11 retinal conditions on optical coherence tomography (OCT). In the
internal test set, FMUE achieved a higher F1 score of 96.76% than two
state-of-the-art algorithms, RETFound and UIOS, and got further improvement
with thresholding strategy to 98.44%. In the external test sets obtained from
other OCT devices, FMUE achieved an accuracy of 88.75% and 92.73% before and
after thresholding. Our model is superior to two ophthalmologists with a higher
F1 score (95.17% vs. 61.93% &71.72%). Besides, our model correctly predicts
high uncertainty scores for samples with ambiguous features, of
non-target-category diseases, or with low-quality to prompt manual checks and
prevent misdiagnosis. FMUE provides a trustworthy method for automatic retinal
anomalies detection in the real-world clinical open set environment.

摘要：無法表達信心等級和偵測未見類別已限制了人工智慧在現實世界中的臨床實施。我們開發了一個具有不確定性估計 (FMUE) 的基礎模型，以在光學相干斷層掃描 (OCT) 上偵測 11 種視網膜疾病。在內部測試集中，FMUE 達到了比兩種最先進的演算法 RETFound 和 UIOS 更高的 F1 分數 96.76%，並通過閾值策略進一步提升至 98.44%。在從其他 OCT 設備獲得的外部測試集中，FMUE 在閾值處理前後分別達到了 88.75% 和 92.73% 的準確度。我們的模型優於兩位眼科醫生，具有更高的 F1 分數（95.17% 對比 61.93% 和 71.72%）。此外，我們的模型可以正確預測具有模稜兩可特徵、非目標類別疾病或低品質的樣本的高不確定性分數，以提示手動檢查並防止誤診。FMUE 為在現實世界臨床開放集環境中自動檢測視網膜異常提供了一種值得信賴的方法。

##### **Time Series Modeling for Heart Rate Prediction: From ARIMA to Transformers**
2406.12199v1 by Haowei Ni, Shuchen Meng, Xieming Geng, Panfeng Li, Zhuoying Li, Xupeng Chen, Xiaotong Wang, Shiyao Zhang

Cardiovascular disease (CVD) is a leading cause of death globally,
necessitating precise forecasting models for monitoring vital signs like heart
rate, blood pressure, and ECG. Traditional models, such as ARIMA and Prophet,
are limited by their need for manual parameter tuning and challenges in
handling noisy, sparse, and highly variable medical data. This study
investigates advanced deep learning models, including LSTM, and
transformer-based architectures, for predicting heart rate time series from the
MIT-BIH Database. Results demonstrate that deep learning models, particularly
PatchTST, significantly outperform traditional models across multiple metrics,
capturing complex patterns and dependencies more effectively. This research
underscores the potential of deep learning to enhance patient monitoring and
CVD management, suggesting substantial clinical benefits. Future work should
extend these findings to larger, more diverse datasets and real-world clinical
applications to further validate and optimize model performance.

摘要：心血管疾病 (CVD) 是全球主要的死亡原因，
需要精準的預測模型來監控心率、血壓和心電圖等生命徵象。傳統模型，例如 ARIMA 和 Prophet，
受到手動參數調整需求和處理雜訊、稀疏和高度變異的醫療資料的挑戰所限制。本研究
探討進階深度學習模型，包括 LSTM 和
基於轉換器的架構，用於從
MIT-BIH 資料庫預測心率時間序列。結果表明，深度學習模型，特別是
PatchTST，在多項指標上顯著優於傳統模型，更有效地捕捉複雜模式和依賴關係。這項研究
強調了深度學習在增強患者監控和
CVD 管理方面的潛力，表明了顯著的臨床益處。未來的研究應將這些發現擴展到更大、更多樣化的資料集和真實世界的臨床
應用，以進一步驗證和最佳化模型效能。

##### **Aqulia-Med LLM: Pioneering Full-Process Open-Source Medical Language Models**
2406.12182v1 by Lulu Zhao, Weihao Zeng, Xiaofeng Shi, Hua Zhou, Donglin Hao, Yonghua Lin

Recently, both closed-source LLMs and open-source communities have made
significant strides, outperforming humans in various general domains. However,
their performance in specific professional fields such as medicine, especially
within the open-source community, remains suboptimal due to the complexity of
medical knowledge. We propose Aquila-Med, a bilingual medical LLM based on
Aquila, addressing these challenges through continue pre-training, supervised
fine-tuning (SFT), and reinforcement learning from human feedback (RLHF). We
construct a large-scale Chinese and English medical dataset for continue
pre-training and a high-quality SFT dataset, covering extensive medical
specialties. Additionally, we develop a high-quality Direct Preference
Optimization (DPO) dataset for further alignment. Aquila-Med achieves notable
results across single-turn, multi-turn dialogues, and medical multiple-choice
questions, demonstrating the effectiveness of our approach. We open-source the
datasets and the entire training process, contributing valuable resources to
the research community. Our models and datasets will released at
https://huggingface.co/BAAI/AquilaMed-RL.

摘要：近来，闭源 LLM 和开源社区都取得了重大进展，在各种通用领域的表现都优于人类。然而，它们在医学等特定专业领域的性能，尤其是在开源社区中，由于医学知识的复杂性，仍然不够理想。我们提出了 Aquila-Med，一个基于 Aquila 的双语医学 LLM，通过持续预训练、监督微调 (SFT) 和人类反馈强化学习 (RLHF) 来应对这些挑战。我们构建了一个大规模的中英文医学数据集，用于持续预训练和高质量的 SFT 数据集，涵盖广泛的医学专业。此外，我们开发了一个高质量的直接偏好优化 (DPO) 数据集，以进一步对齐。Aquila-Med 在单轮、多轮对话和医学多项选择题中取得了显著的成果，证明了我们方法的有效性。我们开源数据集和整个训练过程，为研究社区贡献了宝贵的资源。我们的模型和数据集将在 https://huggingface.co/BAAI/AquilaMed-RL 发布。

##### **Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**
2406.12142v1 by Vincent Olesen, Nina Weng, Aasa Feragen, Eike Petersen

Machine learning models have achieved high overall accuracy in medical image
analysis. However, performance disparities on specific patient groups pose
challenges to their clinical utility, safety, and fairness. This can affect
known patient groups - such as those based on sex, age, or disease subtype - as
well as previously unknown and unlabeled groups. Furthermore, the root cause of
such observed performance disparities is often challenging to uncover,
hindering mitigation efforts. In this paper, to address these issues, we
leverage Slice Discovery Methods (SDMs) to identify interpretable
underperforming subsets of data and formulate hypotheses regarding the cause of
observed performance disparities. We introduce a novel SDM and apply it in a
case study on the classification of pneumothorax and atelectasis from chest
x-rays. Our study demonstrates the effectiveness of SDMs in hypothesis
formulation and yields an explanation of previously observed but unexplained
performance disparities between male and female patients in widely used chest
X-ray datasets and models. Our findings indicate shortcut learning in both
classification tasks, through the presence of chest drains and ECG wires,
respectively. Sex-based differences in the prevalence of these shortcut
features appear to cause the observed classification performance gap,
representing a previously underappreciated interaction between shortcut
learning and model fairness analyses.

摘要：機器學習模型在醫學影像分析中獲得了很高的整體準確度。然而，特定患者群體的效能差異對其臨床效用、安全性與公平性構成挑戰。這可能會影響已知的患者群體（例如基於性別、年齡或疾病亞型）以及先前未知和未標記的群體。此外，這種觀察到的效能差異的根本原因通常難以發現，阻礙了改善措施。在本文中，為了解決這些問題，我們利用切片發現方法 (SDM) 來識別可解釋的資料效能不佳的子集，並針對觀察到的效能差異原因制定假設。我們引入了一種新的 SDM，並在胸部 X 光片中肺炎和肺不張的分類案例研究中應用它。我們的研究證明了 SDM 在假設制定中的有效性，並對在廣泛使用的胸部 X 光片資料集和模型中男性和女性患者之間先前觀察到但無法解釋的效能差異提供了解釋。我們的研究結果表明，在分類任務中，透過胸腔引流管和 ECG 線路的存在，存在捷徑學習。這些捷徑特徵在患病率上的基於性別的差異似乎導致了觀察到的分類效能差距，這代表了捷徑學習和模型公平性分析之間先前未被重視的交互作用。

##### **WellDunn: On the Robustness and Explainability of Language Models and Large Language Models in Identifying Wellness Dimensions**
2406.12058v2 by Seyedali Mohammadi, Edward Raff, Jinendra Malekar, Vedant Palit, Francis Ferraro, Manas Gaur

Language Models (LMs) are being proposed for mental health applications where
the heightened risk of adverse outcomes means predictive performance may not be
a sufficient litmus test of a model's utility in clinical practice. A model
that can be trusted for practice should have a correspondence between
explanation and clinical determination, yet no prior research has examined the
attention fidelity of these models and their effect on ground truth
explanations. We introduce an evaluation design that focuses on the robustness
and explainability of LMs in identifying Wellness Dimensions (WD). We focus on
two mental health and well-being datasets: (a) Multi-label Classification-based
MultiWD, and (b) WellXplain for evaluating attention mechanism veracity against
expert-labeled explanations. The labels are based on Halbert Dunn's theory of
wellness, which gives grounding to our evaluation. We reveal four surprising
results about LMs/LLMs: (1) Despite their human-like capabilities, GPT-3.5/4
lag behind RoBERTa, and MedAlpaca, a fine-tuned LLM fails to deliver any
remarkable improvements in performance or explanations. (2) Re-examining LMs'
predictions based on a confidence-oriented loss function reveals a significant
performance drop. (3) Across all LMs/LLMs, the alignment between attention and
explanations remains low, with LLMs scoring a dismal 0.0. (4) Most mental
health-specific LMs/LLMs overlook domain-specific knowledge and undervalue
explanations, causing these discrepancies. This study highlights the need for
further research into their consistency and explanations in mental health and
well-being.

摘要：語言模型 (LM) 已被提議用於心理健康應用，在這些應用中，不良結果的風險升高意味著預測性表現可能不足以作為臨床實務中模型效用的試金石。可信賴實務的模型應在解釋和臨床判斷之間有對應關係，但沒有先前的研究探討過這些模型的注意力保真度及其對真實解釋的影響。我們介紹了一種評估設計，專注於 LM 在識別健康維度 (WD) 時的穩健性和可解釋性。我們專注於兩個心理健康和福祉數據集：(a) 基於多標籤分類的多 WD，以及 (b) WellXplain，用於評估注意力機制真實性與專家標記的解釋。這些標籤基於 Halbert Dunn 的健康理論，為我們的評估提供了依據。我們揭示了有關 LM/LLM 的四個驚人結果：(1) 儘管具有類人的能力，GPT-3.5/4 仍落後於 RoBERTa 和 MedAlpaca，而微調的 LLM 在效能或解釋方面並未帶來任何顯著的進步。(2) 根據以信心為導向的損失函數重新檢查 LM 的預測，顯示效能大幅下降。(3) 在所有 LM/LLM 中，注意力和解釋之間的一致性仍然很低，LLM 的得分慘不忍睹，僅為 0.0。(4) 大多數心理健康專用 LM/LLM 忽視特定領域的知識，並低估解釋，導致這些差異。本研究強調需要進一步研究它們在心理健康和福祉方面的一致性和解釋。

##### **MedCalc-Bench: Evaluating Large Language Models for Medical Calculations**
2406.12036v2 by Nikhil Khandekar, Qiao Jin, Guangzhi Xiong, Soren Dunn, Serina S Applebaum, Zain Anwar, Maame Sarfo-Gyamfi, Conrad W Safranek, Abid A Anwar, Andrew Zhang, Aidan Gilson, Maxwell B Singer, Amisha Dave, Andrew Taylor, Aidong Zhang, Qingyu Chen, Zhiyong Lu

As opposed to evaluating computation and logic-based reasoning, current
benchmarks for evaluating large language models (LLMs) in medicine are
primarily focused on question-answering involving domain knowledge and
descriptive reasoning. While such qualitative capabilities are vital to medical
diagnosis, in real-world scenarios, doctors frequently use clinical calculators
that follow quantitative equations and rule-based reasoning paradigms for
evidence-based decision support. To this end, we propose MedCalc-Bench, a
first-of-its-kind dataset focused on evaluating the medical calculation
capability of LLMs. MedCalc-Bench contains an evaluation set of over 1000
manually reviewed instances from 55 different medical calculation tasks. Each
instance in MedCalc-Bench consists of a patient note, a question requesting to
compute a specific medical value, a ground truth answer, and a step-by-step
explanation showing how the answer is obtained. While our evaluation results
show the potential of LLMs in this area, none of them are effective enough for
clinical settings. Common issues include extracting the incorrect entities, not
using the correct equation or rules for a calculation task, or incorrectly
performing the arithmetic for the computation. We hope our study highlights the
quantitative knowledge and reasoning gaps in LLMs within medical settings,
encouraging future improvements of LLMs for various clinical calculation tasks.

摘要：與評估運算和基於邏輯的推理相反，目前用於評估醫學領域大型語言模型 (LLM) 的基準主要集中於涉及領域知識和描述性推理的問答。雖然這些定性能力對於醫療診斷至關重要，但在現實情況中，醫生經常使用遵循定量方程式和基於規則的推理範例的臨床計算器，以進行循證決策支持。為此，我們提出 MedCalc-Bench，這是第一個專注於評估 LLM 醫療計算能力的同類數據集。MedCalc-Bench 包含一個評估集，其中包含來自 55 個不同醫療計算任務的 1000 多個手動審查實例。MedCalc-Bench 中的每個實例都包含一個患者備註、一個要求計算特定醫療值的提問、一個真實答案，以及一個逐步說明如何獲得答案的解釋。儘管我們的評估結果顯示了 LLM 在這個領域的潛力，但沒有任何一個 LLM 對臨床設置足夠有效。常見問題包括提取不正確的實體、未針對計算任務使用正確的方程式或規則，或錯誤執行運算的算術。我們希望我們的研究能突顯 LLM 在醫療設置中存在的定量知識和推理差距，並鼓勵未來針對各種臨床計算任務改善 LLM。

##### **Socially Interactive Agents for Robotic Neurorehabilitation Training: Conceptualization and Proof-of-concept Study**
2406.12035v1 by Rhythm Arora, Pooja Prajod, Matteo Lavit Nicora, Daniele Panzeri, Giovanni Tauro, Rocco Vertechy, Matteo Malosio, Elisabeth André, Patrick Gebhard

Individuals with diverse motor abilities often benefit from intensive and
specialized rehabilitation therapies aimed at enhancing their functional
recovery. Nevertheless, the challenge lies in the restricted availability of
neurorehabilitation professionals, hindering the effective delivery of the
necessary level of care. Robotic devices hold great potential in reducing the
dependence on medical personnel during therapy but, at the same time, they
generally lack the crucial human interaction and motivation that traditional
in-person sessions provide. To bridge this gap, we introduce an AI-based system
aimed at delivering personalized, out-of-hospital assistance during
neurorehabilitation training. This system includes a rehabilitation training
device, affective signal classification models, training exercises, and a
socially interactive agent as the user interface. With the assistance of a
professional, the envisioned system is designed to be tailored to accommodate
the unique rehabilitation requirements of an individual patient. Conceptually,
after a preliminary setup and instruction phase, the patient is equipped to
continue their rehabilitation regimen autonomously in the comfort of their
home, facilitated by a socially interactive agent functioning as a virtual
coaching assistant. Our approach involves the integration of an interactive
socially-aware virtual agent into a neurorehabilitation robotic framework, with
the primary objective of recreating the social aspects inherent to in-person
rehabilitation sessions. We also conducted a feasibility study to test the
framework with healthy patients. The results of our preliminary investigation
indicate that participants demonstrated a propensity to adapt to the system.
Notably, the presence of the interactive agent during the proposed exercises
did not act as a source of distraction; instead, it positively impacted users'
engagement.

摘要：肢體能力不同的個人往往受益於密集且專業的復健療法，目的是增進其功能性復原。儘管如此，挑戰在於神經復健專業人員數量有限，阻礙了必要照護等級的有效提供。機器人裝置在降低治療期間對醫療人員的依賴方面具有極大的潛力，但同時，它們通常缺乏傳統面對面療程提供的關鍵人際互動和動機。為了彌補這個差距，我們引進了一個基於人工智慧的系統，旨在於神經復健訓練期間提供個人化、院外的協助。此系統包含復健訓練裝置、情感訊號分類模型、訓練練習和一個作為使用者介面的社會互動代理人。在專業人員的協助下，預想中的系統旨在量身打造，以適應個別病患獨特的神經復健需求。在概念上，在初步設定和說明階段後，病患具備在舒適的家中自主持續其復健計畫的條件，並由一個作為虛擬教練助理的社會互動代理人提供協助。我們的做法涉及將一個互動且具社會意識的虛擬代理人整合到神經復健機器人架構中，其主要目的是重建面對面復健療程中固有的社會面向。我們也進行了一項可行性研究，以健康病患測試此架構。我們初步調查的結果顯示，參與者表現出適應此系統的傾向。值得注意的是，在所建議的練習期間，互動代理人的存在並未成為分心的來源；相反地，它對使用者的參與產生了正面的影響。

##### **Improving Quality Control of Whole Slide Images by Explicit Artifact Augmentation**
2406.11538v1 by Artur Jurgas, Marek Wodzinski, Marina D'Amato, Jeroen van der Laak, Manfredo Atzori, Henning Müller

The problem of artifacts in whole slide image acquisition, prevalent in both
clinical workflows and research-oriented settings, necessitates human
intervention and re-scanning. Overcoming this challenge requires developing
quality control algorithms, that are hindered by the limited availability of
relevant annotated data in histopathology. The manual annotation of
ground-truth for artifact detection methods is expensive and time-consuming.
This work addresses the issue by proposing a method dedicated to augmenting
whole slide images with artifacts. The tool seamlessly generates and blends
artifacts from an external library to a given histopathology dataset. The
augmented datasets are then utilized to train artifact classification methods.
The evaluation shows their usefulness in classification of the artifacts, where
they show an improvement from 0.10 to 0.01 AUROC depending on the artifact
type. The framework, model, weights, and ground-truth annotations are freely
released to facilitate open science and reproducible research.

摘要：在臨床上或研究中，全幻燈片影像擷取時產生的偽像問題，需要人為介入和重新掃描。克服這個挑戰需要開發品質控管演算法，但組織病理學中相關註解資料有限，阻礙了演算法的發展。人工註解偽像偵測方法的真實情況既昂貴又費時。本研究提出一個方法來解決這個問題，這個方法專門用來增加全幻燈片影像中的偽像。這個工具可以無縫地從外部資料庫產生並混合偽像到給定的組織病理學資料集。然後使用擴充後的資料集來訓練偽像分類方法。評估顯示出它們在偽像分類中的效用，在不同的偽像類型中，它們的 AUROC 從 0.10 進步到 0.01。這個架構、模型、權重和真實註解是免費釋出的，以利於開放科學和可重製的研究。

##### **FlexCare: Leveraging Cross-Task Synergy for Flexible Multimodal Healthcare Prediction**
2406.11928v1 by Muhao Xu, Zhenfeng Zhu, Youru Li, Shuai Zheng, Yawei Zhao, Kunlun He, Yao Zhao

Multimodal electronic health record (EHR) data can offer a holistic
assessment of a patient's health status, supporting various predictive
healthcare tasks. Recently, several studies have embraced the multitask
learning approach in the healthcare domain, exploiting the inherent
correlations among clinical tasks to predict multiple outcomes simultaneously.
However, existing methods necessitate samples to possess complete labels for
all tasks, which places heavy demands on the data and restricts the flexibility
of the model. Meanwhile, within a multitask framework with multimodal inputs,
how to comprehensively consider the information disparity among modalities and
among tasks still remains a challenging problem. To tackle these issues, a
unified healthcare prediction model, also named by \textbf{FlexCare}, is
proposed to flexibly accommodate incomplete multimodal inputs, promoting the
adaption to multiple healthcare tasks. The proposed model breaks the
conventional paradigm of parallel multitask prediction by decomposing it into a
series of asynchronous single-task prediction. Specifically, a task-agnostic
multimodal information extraction module is presented to capture decorrelated
representations of diverse intra- and inter-modality patterns. Taking full
account of the information disparities between different modalities and
different tasks, we present a task-guided hierarchical multimodal fusion module
that integrates the refined modality-level representations into an individual
patient-level representation. Experimental results on multiple tasks from
MIMIC-IV/MIMIC-CXR/MIMIC-NOTE datasets demonstrate the effectiveness of the
proposed method. Additionally, further analysis underscores the feasibility and
potential of employing such a multitask strategy in the healthcare domain. The
source code is available at https://github.com/mhxu1998/FlexCare.

摘要：多模态电子健康记录（EHR）数据可以提供患者健康状况的全面评估，支持各种预测性医疗保健任务。最近，一些研究采用了医疗保健领域的多分任务学习方法，利用临床任务之间固有的相关性来同时预测多个结果。然而，现有方法需要样本为所有任务都拥有完整的标签，这对数据提出了很高的要求，并限制了模型的灵活性。同时，在具有多模态输入的多任务框架中，如何全面考虑模态之间和任务之间的信息差异仍然是一个具有挑战性的问题。为了解决这些问题，提出了一个统一的医疗保健预测模型，也称为\textbf{FlexCare}，以灵活地适应不完整的多模态输入，促进对多个医疗保健任务的适应。所提出的模型打破了并行多任务预测的传统范式，将其分解为一系列异步单任务预测。具体而言，提出了一种与任务无关的多模态信息提取模块，以捕获不同模态内和模态间模式的去相关表示。充分考虑不同模态和不同任务之间信息差异，我们提出了一个任务指导的分层多模态融合模块，将精炼的模态级表示集成到一个单独的患者级表示中。MIMIC-IV/MIMIC-CXR/MIMIC-NOTE 数据集中多个任务的实验结果证明了所提出方法的有效性。此外，进一步的分析强调了在医疗保健领域采用这种多任务策略的可行性和潜力。源代码可在 https://github.com/mhxu1998/FlexCare 获得。

##### **Formally Certified Approximate Model Counting**
2406.11414v2 by Yong Kiam Tan, Jiong Yang, Mate Soos, Magnus O. Myreen, Kuldeep S. Meel

Approximate model counting is the task of approximating the number of
solutions to an input Boolean formula. The state-of-the-art approximate model
counter for formulas in conjunctive normal form (CNF), ApproxMC, provides a
scalable means of obtaining model counts with probably approximately correct
(PAC)-style guarantees. Nevertheless, the validity of ApproxMC's approximation
relies on a careful theoretical analysis of its randomized algorithm and the
correctness of its highly optimized implementation, especially the latter's
stateful interactions with an incremental CNF satisfiability solver capable of
natively handling parity (XOR) constraints.
  We present the first certification framework for approximate model counting
with formally verified guarantees on the quality of its output approximation.
Our approach combines: (i) a static, once-off, formal proof of the algorithm's
PAC guarantee in the Isabelle/HOL proof assistant; and (ii) dynamic, per-run,
verification of ApproxMC's calls to an external CNF-XOR solver using proof
certificates. We detail our general approach to establish a rigorous connection
between these two parts of the verification, including our blueprint for
turning the formalized, randomized algorithm into a verified proof checker, and
our design of proof certificates for both ApproxMC and its internal CNF-XOR
solving steps. Experimentally, we show that certificate generation adds little
overhead to an approximate counter implementation, and that our certificate
checker is able to fully certify $84.7\%$ of instances with generated
certificates when given the same time and memory limits as the counter.

摘要：近似模型计数是近似输入布林公式的解的数量的任务。针对合取范式 (CNF) 中的公式的最新近似模型计数器 ApproxMC，提供了一种可扩展的方法来获取具有近似正确 (PAC) 风格保证的模型计数。然而，ApproxMC 的近似的有效性依赖于对其随机算法的仔细理论分析以及其高度优化的实现的正确性，特别是后者与能够原生处理奇偶校验 (XOR) 约束的增量 CNF 可满足性求解器的有状态交互。
我们提出了第一个近似模型计数认证框架，对输出近似的质量提供形式验证的保证。我们的方法结合了：(i) 算法的 PAC 保证在 Isabelle/HOL 证明助手中的静态、一次性、形式证明；以及 (ii) 使用证明证书对 ApproxMC 对外部 CNF-XOR 求解器的调用进行动态、每次运行验证。我们详细介绍了我们建立验证这两部分之间严格联系的一般方法，包括我们用于将形式化的随机算法转换为经过验证的证明检查器的蓝图，以及我们为 ApproxMC 及其内部 CNF-XOR 求解步骤设计的证明证书。在实验中，我们表明证书生成几乎不会给近似计数器实现增加开销，并且我们的证书检查器能够在与计数器相同的时间和内存限制下完全验证 84.7% 的具有生成证书的实例。

##### **Adversarial Style Augmentation via Large Language Model for Robust Fake News Detection**
2406.11260v1 by Sungwon Park, Sungwon Han, Meeyoung Cha

The spread of fake news negatively impacts individuals and is regarded as a
significant social challenge that needs to be addressed. A number of
algorithmic and insightful features have been identified for detecting fake
news. However, with the recent LLMs and their advanced generation capabilities,
many of the detectable features (e.g., style-conversion attacks) can be
altered, making it more challenging to distinguish from real news. This study
proposes adversarial style augmentation, AdStyle, to train a fake news detector
that remains robust against various style-conversion attacks. Our model's key
mechanism is the careful use of LLMs to automatically generate a diverse yet
coherent range of style-conversion attack prompts. This improves the generation
of prompts that are particularly difficult for the detector to handle.
Experiments show that our augmentation strategy improves robustness and
detection performance when tested on fake news benchmark datasets.

摘要：假新聞的散布對個人造成負面影響，並被視為需要解決的重大社會挑戰。已經找出許多演算法和有見地的功能來偵測假新聞。然而，隨著近期大型語言模型 (LLM) 及其先進的產生能力，許多可偵測的功能（例如風格轉換攻擊）都可能被改變，使得與真實新聞的區別更具挑戰性。本研究提出對抗式風格擴充，AdStyle，來訓練一個對各種風格轉換攻擊保持穩健的假新聞偵測器。我們模型的關鍵機制是小心地使用 LLM 自動產生多樣且連貫的風格轉換攻擊提示範圍。這改善了提示的產生，特別是對於偵測器難以處理的提示。實驗顯示，當在假新聞基準資料集上進行測試時，我們的擴充策略改善了穩健性和偵測效能。

##### **Scorecards for Synthetic Medical Data Evaluation and Reporting**
2406.11143v1 by Ghada Zamzmi, Adarsh Subbaswamy, Elena Sizikova, Edward Margerrison, Jana Delfino, Aldo Badano

The growing utilization of synthetic medical data (SMD) in training and
testing AI-driven tools in healthcare necessitates a systematic framework for
assessing SMD quality. The current lack of a standardized methodology to
evaluate SMD, particularly in terms of its applicability in various medical
scenarios, is a significant hindrance to its broader acceptance and utilization
in healthcare applications. Here, we outline an evaluation framework designed
to meet the unique requirements of medical applications, and introduce the
concept of SMD scorecards, which can serve as comprehensive reports that
accompany artificially generated datasets. This can help standardize evaluation
and enable SMD developers to assess and further enhance the quality of SMDs by
identifying areas in need of attention and ensuring that the synthetic data
more accurately approximate patient data.

摘要：隨著合成醫療資料 (SMD) 在訓練和測試醫療保健中的人工智慧驅動工具的利用率日益提高，需要一個系統性的架構來評估 SMD 的品質。目前缺乏標準化的評估 SMD 的方法，特別是在其於各種醫療場景中的適用性方面，這嚴重阻礙了其在醫療保健應用中的更廣泛接受和利用。在此，我們概述了一個評估架構，旨在滿足醫療應用的獨特需求，並引入了 SMD 記分卡的概念，它可以作為人工生成資料集的綜合報告。這有助於標準化評估，並使 SMD 開發人員能夠評估和進一步提高 SMD 的品質，方法是找出需要關注的領域，並確保合成資料更準確地近似於患者資料。

##### **Diffusion Models in Low-Level Vision: A Survey**
2406.11138v1 by Chunming He, Yuqi Shen, Chengyu Fang, Fengyang Xiao, Longxiang Tang, Yulun Zhang, Wangmeng Zuo, Zhenhua Guo, Xiu Li

Deep generative models have garnered significant attention in low-level
vision tasks due to their generative capabilities. Among them, diffusion
model-based solutions, characterized by a forward diffusion process and a
reverse denoising process, have emerged as widely acclaimed for their ability
to produce samples of superior quality and diversity. This ensures the
generation of visually compelling results with intricate texture information.
Despite their remarkable success, a noticeable gap exists in a comprehensive
survey that amalgamates these pioneering diffusion model-based works and
organizes the corresponding threads. This paper proposes the comprehensive
review of diffusion model-based techniques. We present three generic diffusion
modeling frameworks and explore their correlations with other deep generative
models, establishing the theoretical foundation. Following this, we introduce a
multi-perspective categorization of diffusion models, considering both the
underlying framework and the target task. Additionally, we summarize extended
diffusion models applied in other tasks, including medical, remote sensing, and
video scenarios. Moreover, we provide an overview of commonly used benchmarks
and evaluation metrics. We conduct a thorough evaluation, encompassing both
performance and efficiency, of diffusion model-based techniques in three
prominent tasks. Finally, we elucidate the limitations of current diffusion
models and propose seven intriguing directions for future research. This
comprehensive examination aims to facilitate a profound understanding of the
landscape surrounding denoising diffusion models in the context of low-level
vision tasks. A curated list of diffusion model-based techniques in over 20
low-level vision tasks can be found at
https://github.com/ChunmingHe/awesome-diffusion-models-in-low-level-vision.

摘要：深度生成模型在低层次视觉任务中获得了显著的关注，因为它们具有生成能力。其中，以正向扩散过程和反向去噪过程为特征的基于扩散模型的解决方案，因其生成更高质量和多样性样本的能力而备受赞誉。这确保了生成视觉上引人注目的结果，并具有复杂纹理信息。尽管取得了显著的成功，但在将这些开创性的基于扩散模型的工作汇集起来并组织相应的线程的综合调查中，仍然存在明显的差距。本文提出了基于扩散模型的技术的全面综述。我们提出了三个通用的扩散建模框架，并探讨了它们与其他深度生成模型的相关性，建立了理论基础。在此基础上，我们介绍了扩散模型的多视角分类，同时考虑了底层框架和目标任务。此外，我们总结了应用于其他任务的扩展扩散模型，包括医学、遥感和视频场景。此外，我们概述了常用的基准和评估指标。我们对基于扩散模型的技术在三个突出的任务中的性能和效率进行了彻底的评估。最后，我们阐明了当前扩散模型的局限性，并提出了七个未来研究的有趣方向。这次全面检查旨在促进对低层次视觉任务背景下去噪扩散模型周围环境的深入理解。可以在 https://github.com/ChunmingHe/awesome-diffusion-models-in-low-level-vision 找到超过 20 个低层次视觉任务中基于扩散模型的技术的精选列表。

##### **Towards Understanding Emotions for Engaged Mental Health Conversations**
2406.11135v1 by Kellie Yu Hui Sim, Kohleen Tijing Fortuno, Kenny Tsu Wei Choo

Providing timely support and intervention is crucial in mental health
settings. As the need to engage youth comfortable with texting increases,
mental health providers are exploring and adopting text-based media such as
chatbots, community-based forums, online therapies with licensed professionals,
and helplines operated by trained responders. To support these text-based media
for mental health--particularly for crisis care--we are developing a system to
perform passive emotion-sensing using a combination of keystroke dynamics and
sentiment analysis. Our early studies of this system posit that the analysis of
short text messages and keyboard typing patterns can provide emotion
information that may be used to support both clients and responders. We use our
preliminary findings to discuss the way forward for applying AI to support
mental health providers in providing better care.

摘要：在心理健康環境中提供及時的支援和介入至關重要。隨著與青少年互動時，使用文字訊息的需求增加，心理健康服務提供者正在探索和採用基於文字訊息的媒體，例如聊天機器人、社群論壇、由持照專業人員提供的線上療法，以及由受過訓練的回應者營運的求助專線。為了支援這些用於心理健康的基於文字訊息的媒體——特別是危機照護——我們正在開發一個系統，使用按鍵動力學和情緒分析的組合來執行被動情緒感測。我們對這個系統的早期研究假設，對簡短文字訊息和鍵盤輸入模式的分析可以提供情緒資訊，可用於支援個案和回應者。我們使用我們的初步發現來討論將 AI 應用於支援心理健康服務提供者提供更好照護的未來方向。

##### **Boosting Medical Image Classification with Segmentation Foundation Model**
2406.11026v1 by Pengfei Gu, Zihan Zhao, Hongxiao Wang, Yaopeng Peng, Yizhe Zhang, Nishchal Sapkota, Chaoli Wang, Danny Z. Chen

The Segment Anything Model (SAM) exhibits impressive capabilities in
zero-shot segmentation for natural images. Recently, SAM has gained a great
deal of attention for its applications in medical image segmentation. However,
to our best knowledge, no studies have shown how to harness the power of SAM
for medical image classification. To fill this gap and make SAM a true
``foundation model'' for medical image analysis, it is highly desirable to
customize SAM specifically for medical image classification. In this paper, we
introduce SAMAug-C, an innovative augmentation method based on SAM for
augmenting classification datasets by generating variants of the original
images. The augmented datasets can be used to train a deep learning
classification model, thereby boosting the classification performance.
Furthermore, we propose a novel framework that simultaneously processes raw and
SAMAug-C augmented image input, capitalizing on the complementary information
that is offered by both. Experiments on three public datasets validate the
effectiveness of our new approach.

摘要：任何區段模型 (SAM) 在自然影像的零發射區段中展現令人印象深刻的能力。最近，SAM 因其在醫學影像區段中的應用而備受關注。然而，據我們所知，沒有研究顯示如何利用 SAM 的力量進行醫學影像分類。為了填補這個空白，並讓 SAM 成為醫學影像分析的真正「基礎模型」，非常希望針對醫學影像分類客製化 SAM。在本文中，我們介紹 SAMAug-C，一種創新的擴充方法，基於 SAM，透過產生原始影像的變體來擴充分類資料集。擴充的資料集可用於訓練深度學習分類模型，從而提升分類效能。此外，我們提出一個新穎的架構，同時處理原始和 SAMAug-C 擴充影像輸入，利用兩者提供的互補資訊。在三個公開資料集上的實驗驗證了我們新方法的有效性。

##### **WundtGPT: Shaping Large Language Models To Be An Empathetic, Proactive Psychologist**
2406.15474v1 by Chenyu Ren, Yazhou Zhang, Daihai He, Jing Qin

Large language models (LLMs) are raging over the medical domain, and their
momentum has carried over into the mental health domain, leading to the
emergence of few mental health LLMs. Although such mental health LLMs could
provide reasonable suggestions for psychological counseling, how to develop an
authentic and effective doctor-patient relationship (DPR) through LLMs is still
an important problem. To fill this gap, we dissect DPR into two key attributes,
i.e., the psychologist's empathy and proactive guidance. We thus present
WundtGPT, an empathetic and proactive mental health large language model that
is acquired by fine-tuning it with instruction and real conversation between
psychologists and patients. It is designed to assist psychologists in diagnosis
and help patients who are reluctant to communicate face-to-face understand
their psychological conditions. Its uniqueness lies in that it could not only
pose purposeful questions to guide patients in detailing their symptoms but
also offer warm emotional reassurance. In particular, WundtGPT incorporates
Collection of Questions, Chain of Psychodiagnosis, and Empathy Constraints into
a comprehensive prompt for eliciting LLMs' questions and diagnoses.
Additionally, WundtGPT proposes a reward model to promote alignment with
empathetic mental health professionals, which encompasses two key factors:
cognitive empathy and emotional empathy. We offer a comprehensive evaluation of
our proposed model. Based on these outcomes, we further conduct the manual
evaluation based on proactivity, effectiveness, professionalism and coherence.
We notice that WundtGPT can offer professional and effective consultation. The
model is available at huggingface.

摘要：大型語言模型 (LLM) 在醫療領域掀起熱潮，其發展動能也延燒到心理健康領域，催生出少數的心理健康 LLM。儘管此類心理健康 LLM 能為心理諮商提供合理的建議，但如何透過 LLM 建立真實且有效的醫病關係 (DPR) 仍是一項重要課題。為了解決此問題，我們將 DPR 分解成兩個關鍵屬性，即心理師的同理心和主動引導。因此，我們提出 WundtGPT，這是一個同理且主動的心理健康大型語言模型，透過微調心理師與患者之間的指導和真實對話而獲得。它旨在協助心理師進行診斷，並幫助不願意面對面溝通的患者了解自己的心理狀況。它的獨特之處在於，它不僅可以提出有目的性的問題來引導患者詳細說明他們的症狀，還能提供溫暖的情緒支持。具體來說，WundtGPT 將問題收集、心理診斷鏈和同理心約束整合到一個綜合提示中，用於引發 LLM 的問題和診斷。此外，WundtGPT 提出了一個獎勵模型，以促進與同理心心理健康專業人員的一致性，其中包含兩個關鍵因素：認知同理心和情緒同理心。我們對所提出的模型進行了全面的評估。根據這些結果，我們進一步根據主動性、有效性、專業性和一致性進行手動評估。我們注意到 WundtGPT 可以提供專業且有效的諮詢。此模型可在 huggingface 取得。

##### **ALPS: An Auto-Labeling and Pre-training Scheme for Remote Sensing Segmentation With Segment Anything Model**
2406.10855v1 by Song Zhang, Qingzhong Wang, Junyi Liu, Haoyi Xiong

In the fast-growing field of Remote Sensing (RS) image analysis, the gap
between massive unlabeled datasets and the ability to fully utilize these
datasets for advanced RS analytics presents a significant challenge. To fill
the gap, our work introduces an innovative auto-labeling framework named ALPS
(Automatic Labeling for Pre-training in Segmentation), leveraging the Segment
Anything Model (SAM) to predict precise pseudo-labels for RS images without
necessitating prior annotations or additional prompts. The proposed pipeline
significantly reduces the labor and resource demands traditionally associated
with annotating RS datasets. By constructing two comprehensive pseudo-labeled
RS datasets via ALPS for pre-training purposes, our approach enhances the
performance of downstream tasks across various benchmarks, including iSAID and
ISPRS Potsdam. Experiments demonstrate the effectiveness of our framework,
showcasing its ability to generalize well across multiple tasks even under the
scarcity of extensively annotated datasets, offering a scalable solution to
automatic segmentation and annotation challenges in the field. In addition, the
proposed a pipeline is flexible and can be applied to medical image
segmentation, remarkably boosting the performance. Note that ALPS utilizes
pre-trained SAM to semi-automatically annotate RS images without additional
manual annotations. Though every component in the pipeline has bee well
explored, integrating clustering algorithms with SAM and novel pseudo-label
alignment significantly enhances RS segmentation, as an off-the-shelf tool for
pre-training data preparation. Our source code is available at:
https://github.com/StriveZs/ALPS.

摘要：<paragraph>在快速發展的遙感 (RS) 影像分析領域中，海量未標籤資料集與充分利用這些資料集進行進階 RS 分析的能力之間的差距，是一個重大的挑戰。為了填補這個差距，我們的研究引入了名為 ALPS (分段預訓練自動標籤) 的創新自動標籤框架，利用任何分段模型 (SAM) 來預測 RS 影像的精確偽標籤，而不需要事先註解或額外的提示。所提出的管線大幅減少了傳統上與註解 RS 資料集相關的人力和資源需求。透過 ALPS 為預訓練目的建構兩個全面的偽標籤 RS 資料集，我們的做法增強了各種基準（包括 iSAID 和 ISPRS Potsdam）中下游任務的效能。實驗證明了我們框架的有效性，展示了其即使在廣泛註解資料集稀缺的情況下，也能跨多個任務進行良好概化的能力，為該領域的自動分段和註解挑戰提供了可擴充的解決方案。此外，所提出的管線具有彈性，且可應用於醫學影像分段，顯著提升效能。請注意，ALPS 利用預訓練的 SAM 來半自動註解 RS 影像，而不需要額外的標籤。儘管管線中的每個元件都已充分探討，但將分群演算法與 SAM 整合，以及新穎的偽標籤比對，顯著增強了 RS 分段，作為預訓練資料準備的現成工具。我們的原始程式碼可在以下網址取得：https://github.com/StriveZs/ALPS。</paragraph>

##### **A Comprehensive Survey of Foundation Models in Medicine**
2406.10729v1 by Wasif Khan, Seowung Leem, Kyle B. See, Joshua K. Wong, Shaoting Zhang, Ruogu Fang

Foundation models (FMs) are large-scale deep-learning models trained on
extensive datasets using self-supervised techniques. These models serve as a
base for various downstream tasks, including healthcare. FMs have been adopted
with great success across various domains within healthcare, including natural
language processing (NLP), computer vision, graph learning, biology, and omics.
Existing healthcare-based surveys have not yet included all of these domains.
Therefore, this survey provides a comprehensive overview of FMs in healthcare.
We focus on the history, learning strategies, flagship models, applications,
and challenges of FMs. We explore how FMs such as the BERT and GPT families are
reshaping various healthcare domains, including clinical large language models,
medical image analysis, and omics data. Furthermore, we provide a detailed
taxonomy of healthcare applications facilitated by FMs, such as clinical NLP,
medical computer vision, graph learning, and other biology-related tasks.
Despite the promising opportunities FMs provide, they also have several
associated challenges, which are explained in detail. We also outline potential
future directions to provide researchers and practitioners with insights into
the potential and limitations of FMs in healthcare to advance their deployment
and mitigate associated risks.

摘要：基礎模型 (FM) 是使用自我監督技術在廣泛數據集上訓練的大規模深度學習模型。這些模型作為各種下游任務的基礎，包括醫療保健。FM 已在醫療保健的各種領域中被廣泛採用，包括自然語言處理 (NLP)、電腦視覺、圖形學習、生物學和組學。現有的基於醫療保健的調查尚未涵蓋所有這些領域。因此，本調查提供了 FM 在醫療保健中的全面概述。我們專注於 FM 的歷史、學習策略、旗艦模型、應用和挑戰。我們探討了 BERT 和 GPT 家族等 FM 如何重塑各種醫療保健領域，包括臨床大型語言模型、醫學影像分析和組學數據。此外，我們提供了由 FM 促進的醫療保健應用詳細分類法，例如臨床 NLP、醫學電腦視覺、圖形學習和其他與生物相關的任務。儘管 FM 提供了有希望的機會，但它們也面臨著一些相關的挑戰，這些挑戰在文中都有詳細說明。我們還概述了潛在的未來方向，為研究人員和從業者提供有關 FM 在醫療保健中的潛力和局限性的見解，以推進其部署並減輕相關風險。

##### **SyntheT2C: Generating Synthetic Data for Fine-Tuning Large Language Models on the Text2Cypher Task**
2406.10710v1 by Ziije Zhong, Linqing Zhong, Zhaoze Sun, Qingyun Jin, Zengchang Qin, Xiaofan Zhang

Integrating Large Language Models (LLMs) with existing Knowledge Graph (KG)
databases presents a promising avenue for enhancing LLMs' efficacy and
mitigating their "hallucinations". Given that most KGs reside in graph
databases accessible solely through specialized query languages (e.g., Cypher),
there exists a critical need to bridge the divide between LLMs and KG databases
by automating the translation of natural language into Cypher queries (commonly
termed the "Text2Cypher" task). Prior efforts tried to bolster LLMs'
proficiency in Cypher generation through Supervised Fine-Tuning. However, these
explorations are hindered by the lack of annotated datasets of Query-Cypher
pairs, resulting from the labor-intensive and domain-specific nature of
annotating such datasets. In this study, we propose SyntheT2C, a methodology
for constructing a synthetic Query-Cypher pair dataset, comprising two distinct
pipelines: (1) LLM-based prompting and (2) template-filling. SyntheT2C
facilitates the generation of extensive Query-Cypher pairs with values sampled
from an underlying Neo4j graph database. Subsequently, SyntheT2C is applied to
two medical databases, culminating in the creation of a synthetic dataset,
MedT2C. Comprehensive experiments demonstrate that the MedT2C dataset
effectively enhances the performance of backbone LLMs on the Text2Cypher task.
Both the SyntheT2C codebase and the MedT2C dataset will be released soon.

摘要：<paragraph>將大型語言模型 (LLM) 與現有的知識圖譜 (KG) 資料庫整合，提供了一個提升 LLM 效能並減輕其「幻覺」的途徑。由於大多數 KG 都存在於僅能透過專用查詢語言（例如 Cypher）存取的圖形資料庫中，因此迫切需要自動化將自然語言轉換為 Cypher 查詢，以彌合 LLM 與 KG 資料庫之間的鴻溝（通常稱為「Text2Cypher」任務）。先前的努力嘗試透過監督微調來提升 LLM 在 Cypher 生成方面的能力。然而，這些探索受到缺乏查詢-Cypher 配對的註解資料集的阻礙，這是因為此類資料集的註解需要大量人力且具有特定領域的性質。在本研究中，我們提出了 SyntheT2C，這是一種用於建構合成查詢-Cypher 配對資料集的方法，包含兩個不同的管道：(1) 基於 LLM 的提示和 (2) 範本填寫。SyntheT2C 促進了大量查詢-Cypher 配對的產生，其值取樣自基礎的 Neo4j 圖形資料庫。隨後，將 SyntheT2C 應用於兩個醫療資料庫，最終建立了一個合成資料集 MedT2C。全面的實驗證明，MedT2C 資料集有效提升了主幹 LLM 在 Text2Cypher 任務上的效能。SyntheT2C 程式碼庫和 MedT2C 資料集都將很快釋出。</paragraph>

##### **Intertwining CP and NLP: The Generation of Unreasonably Constrained Sentences**
2406.15473v1 by Alexandre Bonlarron, Jean-Charles Régin

Constrained text generation remains a challenging task, particularly when
dealing with hard constraints. Traditional Natural Language Processing (NLP)
approaches prioritize generating meaningful and coherent output. Also, the
current state-of-the-art methods often lack the expressiveness and constraint
satisfaction capabilities to handle such tasks effectively. This paper presents
the Constraints First Framework to remedy this issue. This framework considers
a constrained text generation problem as a discrete combinatorial optimization
problem. It is solved by a constraint programming method that combines
linguistic properties (e.g., n-grams or language level) with other more
classical constraints (e.g., the number of characters, syllables, or words).
Eventually, a curation phase allows for selecting the best-generated sentences
according to perplexity using a large language model. The effectiveness of this
approach is demonstrated by tackling a new more tediously constrained text
generation problem: the iconic RADNER sentences problem. This problem aims to
generate sentences respecting a set of quite strict rules defined by their use
in vision and clinical research. Thanks to our CP-based approach, many new
strongly constrained sentences have been successfully generated in an automatic
manner. This highlights the potential of our approach to handle unreasonably
constrained text generation scenarios.

摘要：受限文本生成仍然是一项具有挑战性的任务，尤其是在处理硬约束时。传统的自然语言处理 (NLP) 方法优先生成有意义且连贯的输出。此外，当前最先进的方法通常缺乏处理此类任务所需的表达能力和约束满足能力。本文提出了约束优先框架来解决此问题。此框架将受限文本生成问题视为离散组合优化问题。它通过约束编程方法解决，该方法将语言属性（例如 n-gram 或语言级别）与其他更经典的约束（例如字符、音节或单词的数量）结合起来。最终，一个整理阶段允许根据困惑度使用大型语言模型选择生成最好的句子。通过解决一个新的、更繁琐的受限文本生成问题：标志性的 RADNER 句子问题，证明了这种方法的有效性。此问题旨在生成符合一组非常严格规则的句子，这些规则由其在视觉和临床研究中的使用定义。得益于我们基于 CP 的方法，许多新的强约束句子已经成功地以自动化的方式生成。这突出了我们方法处理不合理的受限文本生成场景的潜力。

##### **Applications of Generative AI in Healthcare: algorithmic, ethical, legal and societal considerations**
2406.10632v1 by Onyekachukwu R. Okonji, Kamol Yunusov, Bonnie Gordon

Generative AI is rapidly transforming medical imaging and text analysis,
offering immense potential for enhanced diagnosis and personalized care.
However, this transformative technology raises crucial ethical, societal, and
legal questions. This paper delves into these complexities, examining issues of
accuracy, informed consent, data privacy, and algorithmic limitations in the
context of generative AI's application to medical imaging and text. We explore
the legal landscape surrounding liability and accountability, emphasizing the
need for robust regulatory frameworks. Furthermore, we dissect the algorithmic
challenges, including data biases, model limitations, and workflow integration.
By critically analyzing these challenges and proposing responsible solutions,
we aim to foster a roadmap for ethical and responsible implementation of
generative AI in healthcare, ensuring its transformative potential serves
humanity with utmost care and precision.

摘要：生成式 AI 正在快速轉變醫學影像和文字分析，
提供增強診斷和個人化照護的巨大潛力。
然而，這項變革性技術提出了關鍵的倫理、社會和
法律問題。本文深入探討這些複雜性，審查準確性、知情同意、資料隱私和演算法限制等問題
在生成式 AI 應用於醫學影像和文字的背景下。我們探討
責任和問責的法律環境，強調健全監管架構的必要性。此外，我們剖析演算法
挑戰，包括資料偏差、模型限制和工作流程整合。
通過批判性分析這些挑戰並提出負責任的解決方案，
我們旨在培養生成式 AI 在醫療保健中道德和負責任實施的路線圖，確保其變革潛力服務
人類以最大的關懷和精確度。

##### **Public Computer Vision Datasets for Precision Livestock Farming: A Systematic Survey**
2406.10628v1 by Anil Bhujel, Yibin Wang, Yuzhen Lu, Daniel Morris, Mukesh Dangol

Technology-driven precision livestock farming (PLF) empowers practitioners to
monitor and analyze animal growth and health conditions for improved
productivity and welfare. Computer vision (CV) is indispensable in PLF by using
cameras and computer algorithms to supplement or supersede manual efforts for
livestock data acquisition. Data availability is crucial for developing
innovative monitoring and analysis systems through artificial
intelligence-based techniques. However, data curation processes are tedious,
time-consuming, and resource intensive. This study presents the first
systematic survey of publicly available livestock CV datasets
(https://github.com/Anil-Bhujel/Public-Computer-Vision-Dataset-A-Systematic-Survey).
Among 58 public datasets identified and analyzed, encompassing different
species of livestock, almost half of them are for cattle, followed by swine,
poultry, and other animals. Individual animal detection and color imaging are
the dominant application and imaging modality for livestock. The
characteristics and baseline applications of the datasets are discussed,
emphasizing the implications for animal welfare advocates. Challenges and
opportunities are also discussed to inspire further efforts in developing
livestock CV datasets. This study highlights that the limited quantity of
high-quality annotated datasets collected from diverse environments, animals,
and applications, the absence of contextual metadata, are a real bottleneck in
PLF.

摘要：<paragraph>以科技為主的精準畜牧養殖 (PLF) 讓從業人員得以監控和分析動物的生長和健康狀況，以提高生產力和福利。電腦視覺 (CV) 在 PLF 中不可或缺，它利用相機和電腦演算法來補充或取代人工收集畜牧資料的工作。資料取得對於透過人工智慧技術開發創新的監控和分析系統至關重要。然而，資料整理的程序繁瑣、耗時且耗費資源。本研究提出公開取得的畜牧 CV 資料集的首次系統性調查 (https://github.com/Anil-Bhujel/Public-Computer-Vision-Dataset-A-Systematic-Survey)。在辨識和分析的 58 個公開資料集中，涵蓋不同種類的牲畜，其中將近一半是牛隻，其次是豬隻、家禽和其他動物。個別動物偵測和彩色影像處理是畜牧業中主要的應用和影像模式。本文討論了這些資料集的特徵和基礎應用，並強調其對動物福利倡導者的意義。也討論了挑戰和機會，以激勵進一步開發畜牧 CV 資料集。本研究強調，從各種環境、動物和應用中收集的高品質註解資料集數量有限，以及缺乏脈絡性元資料，是 PLF 中真正的瓶頸。</paragraph>

##### **Mental Disorder Classification via Temporal Representation of Text**
2406.15470v1 by Raja Kumar, Kishan Maharaj, Ashita Saxena, Pushpak Bhattacharyya

Mental disorders pose a global challenge, aggravated by the shortage of
qualified mental health professionals. Mental disorder prediction from social
media posts by current LLMs is challenging due to the complexities of
sequential text data and the limited context length of language models. Current
language model-based approaches split a single data instance into multiple
chunks to compensate for limited context size. The predictive model is then
applied to each chunk individually, and the most voted output is selected as
the final prediction. This results in the loss of inter-post dependencies and
important time variant information, leading to poor performance. We propose a
novel framework which first compresses the large sequence of chronologically
ordered social media posts into a series of numbers. We then use this time
variant representation for mental disorder classification. We demonstrate the
generalization capabilities of our framework by outperforming the current SOTA
in three different mental conditions: depression, self-harm, and anorexia, with
an absolute improvement of 5% in the F1 score. We investigate the situation
where current data instances fall within the context length of language models
and present empirical results highlighting the importance of temporal
properties of textual data. Furthermore, we utilize the proposed framework for
a cross-domain study, exploring commonalities across disorders and the
possibility of inter-domain data usage.

摘要：心理疾病構成全球性挑戰，而合格的心理健康專業人員短缺加劇了這一挑戰。由於序列文字資料的複雜性和語言模型的背景長度有限，當前 LLM 從社群媒體貼文中預測心理疾病具有挑戰性。當前基於語言模型的方法會將單一資料個體拆分成多個區塊，以彌補有限的背景大小。然後將預測模型分別套用於每個區塊，並選出票數最多的輸出作為最終預測。這會導致失去貼文間的依賴關係和重要的時間變異資訊，進而導致效能不佳。我們提出一個創新的架構，它會先將按時間順序排列的大量社群媒體貼文壓縮成一系列數字。然後我們使用這個時間變異表徵進行心理疾病分類。我們透過在三種不同的心理狀態（憂鬱症、自殘和厭食症）中表現優於當前 SOTA，證明了我們架構的概化能力，F1 分數絕對提升了 5%。我們探討了當前資料個體落在語言模型背景長度中的情況，並提出實證結果，強調文字資料的時間屬性的重要性。此外，我們利用所提出的架構進行跨領域研究，探討不同疾病的共通點和領域間資料使用的可能性。

##### **Self Pre-training with Topology- and Spatiality-aware Masked Autoencoders for 3D Medical Image Segmentation**
2406.10519v1 by Pengfei Gu, Yejia Zhang, Huimin Li, Hongxiao Wang, Yizhe Zhang, Chaoli Wang, Danny Z. Chen

Masked Autoencoders (MAEs) have been shown to be effective in pre-training
Vision Transformers (ViTs) for natural and medical image analysis problems. By
reconstructing missing pixel/voxel information in visible patches, a ViT
encoder can aggregate contextual information for downstream tasks. But,
existing MAE pre-training methods, which were specifically developed with the
ViT architecture, lack the ability to capture geometric shape and spatial
information, which is critical for medical image segmentation tasks. In this
paper, we propose a novel extension of known MAEs for self pre-training (i.e.,
models pre-trained on the same target dataset) for 3D medical image
segmentation. (1) We propose a new topological loss to preserve geometric shape
information by computing topological signatures of both the input and
reconstructed volumes, learning geometric shape information. (2) We introduce a
pre-text task that predicts the positions of the centers and eight corners of
3D crops, enabling the MAE to aggregate spatial information. (3) We extend the
MAE pre-training strategy to a hybrid state-of-the-art (SOTA) medical image
segmentation architecture and co-pretrain it alongside the ViT. (4) We develop
a fine-tuned model for downstream segmentation tasks by complementing the
pre-trained ViT encoder with our pre-trained SOTA model. Extensive experiments
on five public 3D segmentation datasets show the effectiveness of our new
approach.

摘要：蒙面自動編碼器 (MAE) 已被證明可有效用於自然和醫學影像分析問題的 Vision Transformer (ViT) 預訓練。透過重建可見補丁中遺失的像素/體素資訊，ViT 編碼器可以彙總下游任務的脈絡資訊。但是，專門針對 ViT 架構開發的現有 MAE 預訓練方法缺乏擷取幾何形狀和空間資訊的能力，而這對於醫學影像分割任務至關重要。在本文中，我們提出已知 MAE 的新延伸，用於 3D 醫學影像分割的自預訓練（即在同一目標資料集上預訓練的模型）。（1）我們提出新的拓撲損失來保留幾何形狀資訊，方法是計算輸入和重建體積的拓撲特徵，學習幾何形狀資訊。（2）我們引入預文本任務，用於預測 3D 裁剪的中心和八個角的位置，使 MAE 能夠彙總空間資訊。（3）我們將 MAE 預訓練策略延伸到混合的最新 (SOTA) 醫學影像分割架構，並與 ViT 一起預訓練它。（4）我們透過補充預訓練的 ViT 編碼器與我們的預訓練 SOTA 模型，為下游分割任務開發微調模型。在五個公開 3D 分割資料集上進行的廣泛實驗顯示了我們新方法的有效性。

##### **A Benchmark for Maximum Cut: Towards Standardization of the Evaluation of Learned Heuristics for Combinatorial Optimization**
2406.11897v1 by Ankur Nath, Alan Kuhnle

Recently, there has been much work on the design of general heuristics for
graph-based, combinatorial optimization problems via the incorporation of Graph
Neural Networks (GNNs) to learn distribution-specific solution
structures.However, there is a lack of consistency in the evaluation of these
heuristics, in terms of the baselines and instances chosen, which makes it
difficult to assess the relative performance of the algorithms. In this paper,
we propose an open-source benchmark suite MaxCut-Bench dedicated to the NP-hard
Maximum Cut problem in both its weighted and unweighted variants, based on a
careful selection of instances curated from diverse graph datasets. The suite
offers a unified interface to various heuristics, both traditional and machine
learning-based. Next, we use the benchmark in an attempt to systematically
corroborate or reproduce the results of several, popular learning-based
approaches, including S2V-DQN [31], ECO-DQN [4], among others, in terms of
three dimensions: objective value, generalization, and scalability. Our
empirical results show that several of the learned heuristics fail to
outperform a naive greedy algorithm, and that only one of them consistently
outperforms Tabu Search, a simple, general heuristic based upon local search.
Furthermore, we find that the performance of ECO-DQN remains the same or is
improved if the GNN is replaced by a simple linear regression on a subset of
the features that are related to Tabu Search. Code, data, and pretrained models
are available at: \url{https://github.com/ankurnath/MaxCut-Bench}.

摘要：<paragraph>最近，通过整合图神经网络 (GNN) 来学习特定于分布的解决方案结构，在基于图的组合优化问题的通用启发式设计的相关研究中取得了许多进展。然而，在评估这些启发式算法时，在所选基准和实例方面缺乏一致性，这使得难以评估算法的相对性能。在本文中，我们提出了一套开源基准测试套件 MaxCut-Bench，专门用于 NP 困难的最大切割问题，包括其加权和未加权变体，该套件基于从各种图数据集精心挑选的实例。该套件为各种启发式算法提供了一个统一的界面，包括传统的和基于机器学习的启发式算法。接下来，我们尝试使用该基准系统地证实或重现几种流行的基于学习的方法的结果，包括 S2V-DQN [31]、ECO-DQN [4] 等，涉及三个维度：目标值、泛化和可扩展性。我们的经验结果表明，一些学习到的启发式算法未能优于朴素的贪婪算法，并且其中只有一个算法始终优于基于局部搜索的简单通用启发式算法 Tabu Search。此外，我们发现，如果用一个简单的线性回归模型（该模型基于与 Tabu Search 相关的部分特征）来替换 GNN，则 ECO-DQN 的性能将保持不变或得到改善。代码、数据和预训练模型可在此处获得：\url{https://github.com/ankurnath/MaxCut-Bench}。</paragraph>

##### **Biomarker based Cancer Classification using an Ensemble with Pre-trained Models**
2406.10087v1 by Chongmin Lee, Jihie Kim

Certain cancer types, namely pancreatic cancer is difficult to detect at an
early stage; sparking the importance of discovering the causal relationship
between biomarkers and cancer to identify cancer efficiently. By allowing for
the detection and monitoring of specific biomarkers through a non-invasive
method, liquid biopsies enhance the precision and efficacy of medical
interventions, advocating the move towards personalized healthcare. Several
machine learning algorithms such as Random Forest, SVM are utilized for
classification, yet causing inefficiency due to the need for conducting
hyperparameter tuning. We leverage a meta-trained Hyperfast model for
classifying cancer, accomplishing the highest AUC of 0.9929 and simultaneously
achieving robustness especially on highly imbalanced datasets compared to other
ML algorithms in several binary classification tasks (e.g. breast invasive
carcinoma; BRCA vs. non-BRCA). We also propose a novel ensemble model combining
pre-trained Hyperfast model, XGBoost, and LightGBM for multi-class
classification tasks, achieving an incremental increase in accuracy (0.9464)
while merely using 500 PCA features; distinguishable from previous studies
where they used more than 2,000 features for similar results.

摘要：某些类型的癌症，例如胰臟癌，在早期階段難以檢測出來；這點凸顯了找出生物標記與癌症之間的因果關係以有效辨識癌症的重要性。液態切片透過非侵入性方法檢測和監控特定生物標記，進而提升醫療介入的精準度和效能，並倡導朝向個人化醫療保健邁進。隨機森林、SVM 等多種機器學習演算法用於分類，但由於需要進行超參數調整，因此造成效率不彰。我們利用經過元訓練的 Hyperfast 模型來分類癌症，達到了 0.9929 的最高 AUC，同時在多項二元分類任務中（例如乳房浸潤性癌；BRCA 與非 BRCA）實現了穩健性，特別是在高度不平衡的資料集上，優於其他 ML 演算法。我們還提出了一個新穎的整合模型，結合預先訓練的 Hyperfast 模型、XGBoost 和 LightGBM，用於多類別分類任務，僅使用 500 個 PCA 特徵便達到了精準度的增量提升（0.9464）；這點有別於先前的研究，它們使用超過 2,000 個特徵來獲得類似的結果。

