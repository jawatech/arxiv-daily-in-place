{"2502.01968": {"publish_time": "2025-02-04", "title": "Token Cleaning: Fine-Grained Data Selection for LLM Supervised Fine-Tuning", "paper_summary": "Recent studies show that in supervised fine-tuning (SFT) of large language\nmodels (LLMs), data quality matters more than quantity. While most data\ncleaning methods concentrate on filtering entire samples, the quality of\nindividual tokens within a sample can vary significantly. After pre-training,\neven in high-quality samples, patterns or phrases that are not task-related can\nbe redundant or uninformative. Continuing to fine-tune on these patterns may\noffer limited benefit and even degrade downstream task performance. In this\npaper, we investigate token quality from a noisy-label perspective and propose\na generic token cleaning pipeline for SFT tasks. Our method filters out\nuninformative tokens while preserving those carrying key task-specific\ninformation. Specifically, we first evaluate token quality by examining the\ninfluence of model updates on each token, then apply a threshold-based\nseparation. The token influence can be measured in a single pass with a fixed\nreference model or iteratively with self-evolving reference models. The\nbenefits and limitations of both methods are analyzed theoretically by error\nupper bounds. Extensive experiments show that our framework consistently\nimproves performance across multiple downstream tasks.", "paper_summary_zh": "\u6700\u8fd1\u7684\u7814\u7a76\u8868\u660e\uff0c\u5728\u5927\u8bed\u8a00\u6a21\u578b (LLM) \u7684\u76d1\u7763\u5fae\u8c03 (SFT) \u4e2d\uff0c\u6570\u636e\u8d28\u91cf\u6bd4\u6570\u91cf\u66f4\u91cd\u8981\u3002\u867d\u7136\u5927\u591a\u6570\u6570\u636e\u6e05\u7406\u65b9\u6cd5\u4e13\u6ce8\u4e8e\u8fc7\u6ee4\u6574\u4e2a\u6837\u672c\uff0c\u4f46\u6837\u672c\u4e2d\u5404\u4e2a\u6807\u8bb0\u7684\u8d28\u91cf\u53ef\u80fd\u5dee\u5f02\u5f88\u5927\u3002\u7ecf\u8fc7\u9884\u8bad\u7ec3\u540e\uff0c\u5373\u4f7f\u5728\u9ad8\u8d28\u91cf\u6837\u672c\u4e2d\uff0c\u4e0e\u4efb\u52a1\u65e0\u5173\u7684\u6a21\u5f0f\u6216\u77ed\u8bed\u4e5f\u53ef\u80fd\u662f\u5197\u4f59\u6216\u65e0\u4fe1\u606f\u7684\u3002\u7ee7\u7eed\u5bf9\u8fd9\u4e9b\u6a21\u5f0f\u8fdb\u884c\u5fae\u8c03\u53ef\u80fd\u53ea\u4f1a\u5e26\u6765\u6709\u9650\u7684\u597d\u5904\uff0c\u751a\u81f3\u4f1a\u964d\u4f4e\u4e0b\u6e38\u4efb\u52a1\u7684\u6027\u80fd\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u4ece\u566a\u58f0\u6807\u7b7e\u7684\u89d2\u5ea6\u7814\u7a76\u6807\u8bb0\u8d28\u91cf\uff0c\u5e76\u4e3a SFT \u4efb\u52a1\u63d0\u51fa\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u6807\u8bb0\u6e05\u7406\u7ba1\u9053\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u8fc7\u6ee4\u6389\u65e0\u4fe1\u606f\u7684\u6807\u8bb0\uff0c\u540c\u65f6\u4fdd\u7559\u90a3\u4e9b\u643a\u5e26\u5173\u952e\u4efb\u52a1\u7279\u5b9a\u4fe1\u606f\u7684\u6807\u8bb0\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u9996\u5148\u901a\u8fc7\u68c0\u67e5\u6a21\u578b\u66f4\u65b0\u5bf9\u6bcf\u4e2a\u6807\u8bb0\u7684\u5f71\u54cd\u6765\u8bc4\u4f30\u6807\u8bb0\u8d28\u91cf\uff0c\u7136\u540e\u5e94\u7528\u57fa\u4e8e\u9608\u503c\u7684\u5206\u5272\u3002\u6807\u8bb0\u5f71\u54cd\u53ef\u4ee5\u901a\u8fc7\u4f7f\u7528\u56fa\u5b9a\u53c2\u8003\u6a21\u578b\u5355\u6b21\u6d4b\u91cf\uff0c\u6216\u4f7f\u7528\u81ea\u8fdb\u5316\u53c2\u8003\u6a21\u578b\u8fed\u4ee3\u6d4b\u91cf\u3002\u901a\u8fc7\u8bef\u5dee\u4e0a\u9650\u5bf9\u8fd9\u4e24\u79cd\u65b9\u6cd5\u7684\u4f18\u70b9\u548c\u5c40\u9650\u6027\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\u3002\u5927\u91cf\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6211\u4eec\u7684\u6846\u67b6\u5728\u591a\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e2d\u59cb\u7ec8\u5982\u4e00\u5730\u63d0\u9ad8\u4e86\u6027\u80fd\u3002", "author": "Jinlong Pang et.al.", "authors": "Jinlong Pang, Na Di, Zhaowei Zhu, Jiaheng Wei, Hao Cheng, Chen Qian, Yang Liu", "id": "2502.01968v1", "paper_url": "http://arxiv.org/abs/2502.01968v1", "repo": "null"}}