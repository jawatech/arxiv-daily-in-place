{"2408.04619": {"publish_time": "2024-08-08", "title": "Transformer Explainer: Interactive Learning of Text-Generative Models", "paper_summary": "Transformers have revolutionized machine learning, yet their inner workings\nremain opaque to many. We present Transformer Explainer, an interactive\nvisualization tool designed for non-experts to learn about Transformers through\nthe GPT-2 model. Our tool helps users understand complex Transformer concepts\nby integrating a model overview and enabling smooth transitions across\nabstraction levels of mathematical operations and model structures. It runs a\nlive GPT-2 instance locally in the user's browser, empowering users to\nexperiment with their own input and observe in real-time how the internal\ncomponents and parameters of the Transformer work together to predict the next\ntokens. Our tool requires no installation or special hardware, broadening the\npublic's education access to modern generative AI techniques. Our open-sourced\ntool is available at https://poloclub.github.io/transformer-explainer/. A video\ndemo is available at https://youtu.be/ECR4oAwocjs.", "paper_summary_zh": "Transformer \u5fb9\u5e95\u6539\u8b8a\u4e86\u6a5f\u5668\u5b78\u7fd2\uff0c\u4f46\u5176\u5167\u90e8\u904b\u4f5c\u5c0d\u8a31\u591a\u4eba\u4f86\u8aaa\u4ecd\u7136\u4e0d\u900f\u660e\u3002\u6211\u5011\u5c55\u793a Transformer Explainer\uff0c\u9019\u662f\u4e00\u500b\u4e92\u52d5\u5f0f\u8996\u89ba\u5316\u5de5\u5177\uff0c\u5c08\u70ba\u975e\u5c08\u5bb6\u8a2d\u8a08\uff0c\u900f\u904e GPT-2 \u6a21\u578b\u4f86\u4e86\u89e3 Transformer\u3002\u6211\u5011\u7684\u5de5\u5177\u900f\u904e\u6574\u5408\u6a21\u578b\u6982\u89c0\u4e26\u5728\u6578\u5b78\u904b\u7b97\u548c\u6a21\u578b\u7d50\u69cb\u7684\u62bd\u8c61\u5c64\u7d1a\u4e4b\u9593\u5be6\u73fe\u5e73\u6ed1\u904e\u6e21\uff0c\u5e6b\u52a9\u4f7f\u7528\u8005\u4e86\u89e3\u8907\u96dc\u7684 Transformer \u6982\u5ff5\u3002\u5b83\u5728\u4f7f\u7528\u8005\u7684\u700f\u89bd\u5668\u4e2d\u672c\u5730\u57f7\u884c\u4e00\u500b\u5373\u6642\u7684 GPT-2 \u57f7\u884c\u500b\u9ad4\uff0c\u4f7f\u7528\u6236\u80fd\u5920\u4f7f\u7528\u81ea\u5df1\u7684\u8f38\u5165\u9032\u884c\u5be6\u9a57\uff0c\u4e26\u5373\u6642\u89c0\u5bdf Transformer \u7684\u5167\u90e8\u7d44\u4ef6\u548c\u53c3\u6578\u5982\u4f55\u5354\u540c\u904b\u4f5c\u4f86\u9810\u6e2c\u4e0b\u4e00\u500b\u4ee3\u5e63\u3002\u6211\u5011\u7684\u5de5\u5177\u4e0d\u9700\u8981\u5b89\u88dd\u6216\u7279\u6b8a\u786c\u9ad4\uff0c\u64f4\u5927\u4e86\u5927\u773e\u5c0d\u73fe\u4ee3\u751f\u6210\u5f0f AI \u6280\u8853\u7684\u6559\u80b2\u7ba1\u9053\u3002\u6211\u5011\u7684\u958b\u6e90\u5de5\u5177\u53ef\u5728 https://poloclub.github.io/transformer-explainer/ \u53d6\u5f97\u3002\u5f71\u7247\u793a\u7bc4\u53ef\u5728 https://youtu.be/ECR4oAwocjs \u53d6\u5f97\u3002", "author": "Aeree Cho et.al.", "authors": "Aeree Cho, Grace C. Kim, Alexander Karpekov, Alec Helbling, Zijie J. Wang, Seongmin Lee, Benjamin Hoover, Duen Horng Chau", "id": "2408.04619v1", "paper_url": "http://arxiv.org/abs/2408.04619v1", "repo": "null"}}