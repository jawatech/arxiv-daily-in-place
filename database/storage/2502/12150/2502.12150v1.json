{"2502.12150": {"publish_time": "2025-02-17", "title": "Idiosyncrasies in Large Language Models", "paper_summary": "In this work, we unveil and study idiosyncrasies in Large Language Models\n(LLMs) -- unique patterns in their outputs that can be used to distinguish the\nmodels. To do so, we consider a simple classification task: given a particular\ntext output, the objective is to predict the source LLM that generates the\ntext. We evaluate this synthetic task across various groups of LLMs and find\nthat simply fine-tuning existing text embedding models on LLM-generated texts\nyields excellent classification accuracy. Notably, we achieve 97.1% accuracy on\nheld-out validation data in the five-way classification problem involving\nChatGPT, Claude, Grok, Gemini, and DeepSeek. Our further investigation reveals\nthat these idiosyncrasies are rooted in word-level distributions. These\npatterns persist even when the texts are rewritten, translated, or summarized\nby an external LLM, suggesting that they are also encoded in the semantic\ncontent. Additionally, we leverage LLM as judges to generate detailed,\nopen-ended descriptions of each model's idiosyncrasies. Finally, we discuss the\nbroader implications of our findings, particularly for training on synthetic\ndata and inferring model similarity. Code is available at\nhttps://github.com/locuslab/llm-idiosyncrasies.", "paper_summary_zh": "\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63ed\u793a\u4e26\u7814\u7a76\u4e86\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4e2d\u7684\u7279\u6b8a\u6027\uff0c\u4e5f\u5c31\u662f\u5176\u8f38\u51fa\u4e2d\u53ef\u5340\u5206\u6a21\u578b\u7684\u7368\u7279\u6a21\u5f0f\u3002\u70ba\u6b64\uff0c\u6211\u5011\u8003\u616e\u4e86\u4e00\u9805\u7c21\u55ae\u7684\u5206\u985e\u4efb\u52d9\uff1a\u7d66\u5b9a\u4e00\u500b\u7279\u5b9a\u6587\u672c\u8f38\u51fa\uff0c\u76ee\u6a19\u662f\u9810\u6e2c\u7522\u751f\u8a72\u6587\u672c\u7684\u4f86\u6e90 LLM\u3002\u6211\u5011\u5728\u5404\u7a2e LLM \u7d44\u5408\u4e2d\u8a55\u4f30\u9019\u500b\u5408\u6210\u4efb\u52d9\uff0c\u4e26\u767c\u73fe\u50c5\u5fae\u8abf\u73fe\u6709\u7684\u6587\u672c\u5d4c\u5165\u6a21\u578b\u5728 LLM \u751f\u6210\u7684\u6587\u672c\u4e0a\u5373\u53ef\u7522\u751f\u6975\u4f73\u7684\u5206\u985e\u6e96\u78ba\u5ea6\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5728\u6d89\u53ca ChatGPT\u3001Claude\u3001Grok\u3001Gemini \u548c DeepSeek \u7684\u4e94\u5411\u5206\u985e\u554f\u984c\u4e2d\uff0c\u6211\u5011\u5728\u7559\u5b58\u9a57\u8b49\u8cc7\u6599\u4e0a\u9054\u5230\u4e86 97.1% \u7684\u6e96\u78ba\u5ea6\u3002\u6211\u5011\u7684\u9032\u4e00\u6b65\u8abf\u67e5\u986f\u793a\uff0c\u9019\u4e9b\u7279\u6b8a\u6027\u6839\u690d\u65bc\u8a5e\u5f59\u5c64\u7d1a\u7684\u5206\u5e03\u3002\u5373\u4f7f\u6587\u672c\u662f\u7531\u5916\u90e8 LLM \u6539\u5beb\u3001\u7ffb\u8b6f\u6216\u6458\u8981\uff0c\u9019\u4e9b\u6a21\u5f0f\u4ecd\u7136\u5b58\u5728\uff0c\u9019\u8868\u660e\u5b83\u5011\u4e5f\u7de8\u78bc\u5728\u8a9e\u7fa9\u5167\u5bb9\u4e2d\u3002\u6b64\u5916\uff0c\u6211\u5011\u5229\u7528 LLM \u4f5c\u70ba\u8a55\u5be9\uff0c\u70ba\u6bcf\u500b\u6a21\u578b\u7684\u7279\u6b8a\u6027\u7522\u751f\u8a73\u7d30\u3001\u958b\u653e\u5f0f\u7684\u63cf\u8ff0\u3002\u6700\u5f8c\uff0c\u6211\u5011\u8a0e\u8ad6\u4e86\u6211\u5011\u767c\u73fe\u7684\u66f4\u5ee3\u6cdb\u542b\u610f\uff0c\u7279\u5225\u662f\u5c0d\u65bc\u5408\u6210\u8cc7\u6599\u7684\u8a13\u7df4\u548c\u63a8\u65b7\u6a21\u578b\u76f8\u4f3c\u6027\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/locuslab/llm-idiosyncrasies \u53d6\u5f97\u3002", "author": "Mingjie Sun et.al.", "authors": "Mingjie Sun, Yida Yin, Zhiqiu Xu, J. Zico Kolter, Zhuang Liu", "id": "2502.12150v1", "paper_url": "http://arxiv.org/abs/2502.12150v1", "repo": "null"}}