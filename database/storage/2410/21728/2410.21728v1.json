{"2410.21728": {"publish_time": "2024-10-29", "title": "Let's Be Self-generated via Step by Step: A Curriculum Learning Approach to Automated Reasoning with Large Language Models", "paper_summary": "While Chain of Thought (CoT) prompting approaches have significantly\nconsolidated the reasoning capabilities of large language models (LLMs), they\nstill face limitations that require extensive human effort or have performance\nneeds to be improved. Existing endeavors have focused on bridging these gaps;\nhowever, these approaches either hinge on external data and cannot completely\neliminate manual effort, or they fall short in effectively directing LLMs to\ngenerate high-quality exemplary prompts. To address the said pitfalls, we\npropose a novel prompt approach for automatic reasoning named \\textbf{LBS3},\ninspired by curriculum learning which better reflects human learning habits.\nSpecifically, LBS3 initially steers LLMs to recall easy-to-hard proxy queries\nthat are pertinent to the target query. Following this, it invokes a\nprogressive strategy that utilizes exemplary prompts stemmed from easy-proxy\nqueries to direct LLMs in solving hard-proxy queries, enabling the high-quality\nof the proxy solutions. Finally, our extensive experiments in various\nreasoning-intensive tasks with varying open- and closed-source LLMs show that\nLBS3 achieves strongly competitive performance compared to the SOTA baselines.", "paper_summary_zh": "\u96d6\u7136\u601d\u8003\u93c8 (CoT) \u63d0\u793a\u65b9\u6cd5\u5927\u5e45\u6574\u5408\u4e86\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5b83\u5011\u4ecd\u7136\u9762\u81e8\u9700\u8981\u5927\u91cf\u4eba\u529b\u6216\u9700\u8981\u6539\u9032\u6548\u80fd\u7684\u9650\u5236\u3002\u73fe\u6709\u7684\u52aa\u529b\u5c08\u6ce8\u65bc\u5f4c\u88dc\u9019\u4e9b\u5dee\u8ddd\uff1b\u7136\u800c\uff0c\u9019\u4e9b\u65b9\u6cd5\u4f9d\u8cf4\u65bc\u5916\u90e8\u8cc7\u6599\uff0c\u7121\u6cd5\u5b8c\u5168\u6d88\u9664\u624b\u52d5\u5de5\u4f5c\uff0c\u6216\u8005\u7121\u6cd5\u6709\u6548\u5f15\u5c0e LLM \u7522\u751f\u9ad8\u54c1\u8cea\u7684\u7bc4\u4f8b\u63d0\u793a\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u7f3a\u9ede\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u540d\u70ba \\textbf{LBS3} \u7684\u81ea\u52d5\u63a8\u7406\u65b0\u63d0\u793a\u65b9\u6cd5\uff0c\u5176\u9748\u611f\u4f86\u81ea\u66f4\u80fd\u53cd\u6620\u4eba\u985e\u5b78\u7fd2\u7fd2\u6163\u7684\u8ab2\u7a0b\u5b78\u7fd2\u3002\u5177\u9ad4\u4f86\u8aaa\uff0cLBS3 \u6700\u521d\u5f15\u5c0e LLM \u56de\u61b6\u8207\u76ee\u6a19\u67e5\u8a62\u76f8\u95dc\u7684\u6613\u5230\u96e3\u4ee3\u7406\u67e5\u8a62\u3002\u5728\u6b64\u4e4b\u5f8c\uff0c\u5b83\u6703\u63a1\u7528\u4e00\u7a2e\u6f38\u9032\u7b56\u7565\uff0c\u5229\u7528\u6e90\u81ea\u65bc\u7c21\u55ae\u4ee3\u7406\u67e5\u8a62\u7684\u7bc4\u4f8b\u63d0\u793a\u4f86\u5f15\u5c0e LLM \u89e3\u6c7a\u56f0\u96e3\u7684\u4ee3\u7406\u67e5\u8a62\uff0c\u5f9e\u800c\u63d0\u9ad8\u4ee3\u7406\u89e3\u6c7a\u65b9\u6848\u7684\u54c1\u8cea\u3002\u6700\u5f8c\uff0c\u6211\u5011\u5728\u5404\u7a2e\u63a8\u7406\u5bc6\u96c6\u578b\u4efb\u52d9\u4e2d\u5c0d\u5404\u7a2e\u958b\u6e90\u548c\u9589\u6e90 LLM \u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u8868\u660e\uff0c\u8207 SOTA \u57fa\u6e96\u76f8\u6bd4\uff0cLBS3 \u7372\u5f97\u4e86\u6975\u5177\u7af6\u722d\u529b\u7684\u6548\u80fd\u3002", "author": "Kangyang Luo et.al.", "authors": "Kangyang Luo, Zichen Ding, Zhenmin Weng, Lingfeng Qiao, Meng Zhao, Xiang Li, Di Yin, Jinlong Shu", "id": "2410.21728v1", "paper_url": "http://arxiv.org/abs/2410.21728v1", "repo": "null"}}