{"2406.04879": {"publish_time": "2024-06-07", "title": "A Deep Dive into the Trade-Offs of Parameter-Efficient Preference Alignment Techniques", "paper_summary": "Large language models are first pre-trained on trillions of tokens and then\ninstruction-tuned or aligned to specific preferences. While pre-training\nremains out of reach for most researchers due to the compute required,\nfine-tuning has become affordable thanks to parameter-efficient methods such as\nLoRA and QLoRA. Alignment is known to be sensitive to the many factors\ninvolved, including the quantity and quality of data, the alignment method, and\nthe adapter rank. However, there has not yet been an extensive study of their\neffect on downstream performance. To address this gap, we conduct an in-depth\ninvestigation of the impact of popular choices for three crucial axes: (i) the\nalignment dataset (HH-RLHF and BeaverTails), (ii) the alignment technique (SFT\nand DPO), and (iii) the model (LLaMA-1, Vicuna-v1.3, Mistral-7b, and\nMistral-7b-Instruct). Our extensive setup spanning over 300 experiments reveals\nconsistent trends and unexpected findings. We observe how more informative data\nhelps with preference alignment, cases where supervised fine-tuning outperforms\npreference optimization, and how aligning to a distinct preference boosts\nperformance on downstream tasks. Through our in-depth analyses, we put forward\nkey guidelines to help researchers perform more effective parameter-efficient\nLLM alignment.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u9996\u5148\u5728\u6578\u5146\u500b\u4ee3\u5e63\u4e0a\u9032\u884c\u9810\u8a13\u7df4\uff0c\u7136\u5f8c\u9032\u884c\u6307\u4ee4\u8abf\u6574\u6216\u91dd\u5c0d\u7279\u5b9a\u504f\u597d\u9032\u884c\u8abf\u6574\u3002\u96d6\u7136\u9810\u8a13\u7df4\u7531\u65bc\u6240\u9700\u7684\u904b\u7b97\u800c\u5c0d\u5927\u591a\u6578\u7814\u7a76\u4eba\u54e1\u4f86\u8aaa\u9059\u4e0d\u53ef\u53ca\uff0c\u4f46\u7531\u65bc\u53c3\u6578\u9ad8\u6548\u7684\u65b9\u6cd5\uff08\u4f8b\u5982 LoRA \u548c QLoRA\uff09\uff0c\u5fae\u8abf\u5df2\u8b8a\u5f97\u8ca0\u64d4\u5f97\u8d77\u3002\u773e\u6240\u5468\u77e5\uff0c\u5c0d\u9f4a\u5c0d\u6240\u6d89\u53ca\u7684\u8a31\u591a\u56e0\u7d20\u5f88\u654f\u611f\uff0c\u5305\u62ec\u6578\u64da\u7684\u6578\u91cf\u548c\u8cea\u91cf\u3001\u5c0d\u9f4a\u65b9\u6cd5\u548c\u9069\u914d\u5668\u7b49\u7d1a\u3002\u7136\u800c\uff0c\u5c1a\u672a\u5c0d\u5b83\u5011\u5c0d\u4e0b\u6e38\u6027\u80fd\u7684\u5f71\u97ff\u9032\u884c\u5ee3\u6cdb\u7684\u7814\u7a76\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e00\u5dee\u8ddd\uff0c\u6211\u5011\u5c0d\u4e09\u9805\u95dc\u9375\u8ef8\u7684\u6d41\u884c\u9078\u64c7\u7684\u5f71\u97ff\u9032\u884c\u4e86\u6df1\u5165\u8abf\u67e5\uff1a(i) \u5c0d\u9f4a\u6578\u64da\u96c6\uff08HH-RLHF \u548c BeaverTails\uff09\uff0c(ii) \u5c0d\u9f4a\u6280\u8853\uff08SFT \u548c DPO\uff09\uff0c\u4ee5\u53ca (iii) \u6a21\u578b\uff08LLaMA-1\u3001Vicuna-v1.3\u3001Mistral-7b \u548c Mistral-7b-Instruct\uff09\u3002\u6211\u5011\u6db5\u84cb 300 \u591a\u500b\u5be6\u9a57\u7684\u5ee3\u6cdb\u8a2d\u7f6e\u63ed\u793a\u4e86\u4e00\u81f4\u7684\u8da8\u52e2\u548c\u610f\u5916\u7684\u767c\u73fe\u3002\u6211\u5011\u89c0\u5bdf\u5230\u66f4\u591a\u4fe1\u606f\u8c50\u5bcc\u7684\u6578\u64da\u5982\u4f55\u5e6b\u52a9\u504f\u597d\u5c0d\u9f4a\u3001\u76e3\u7763\u5fae\u8abf\u512a\u65bc\u504f\u597d\u512a\u5316\u7684\u6848\u4f8b\uff0c\u4ee5\u53ca\u5c0d\u9f4a\u4e0d\u540c\u7684\u504f\u597d\u5982\u4f55\u63d0\u5347\u4e0b\u6e38\u4efb\u52d9\u7684\u6027\u80fd\u3002\u901a\u904e\u6211\u5011\u7684\u6df1\u5165\u5206\u6790\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u95dc\u9375\u6307\u5357\uff0c\u4ee5\u5e6b\u52a9\u7814\u7a76\u4eba\u54e1\u57f7\u884c\u66f4\u6709\u6548\u7684\u53c3\u6578\u9ad8\u6548 LLM \u5c0d\u9f4a\u3002", "author": "Megh Thakkar et.al.", "authors": "Megh Thakkar, Quentin Fournier, Matthew D Riemer, Pin-Yu Chen, Amal Zouaq, Payel Das, Sarath Chandar", "id": "2406.04879v1", "paper_url": "http://arxiv.org/abs/2406.04879v1", "repo": "null"}}