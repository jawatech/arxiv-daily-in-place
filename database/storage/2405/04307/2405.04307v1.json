{"2405.04307": {"publish_time": "2024-05-07", "title": "Improving Offline Reinforcement Learning with Inaccurate Simulators", "paper_summary": "Offline reinforcement learning (RL) provides a promising approach to avoid\ncostly online interaction with the real environment. However, the performance\nof offline RL highly depends on the quality of the datasets, which may cause\nextrapolation error in the learning process. In many robotic applications, an\ninaccurate simulator is often available. However, the data directly collected\nfrom the inaccurate simulator cannot be directly used in offline RL due to the\nwell-known exploration-exploitation dilemma and the dynamic gap between\ninaccurate simulation and the real environment. To address these issues, we\npropose a novel approach to combine the offline dataset and the inaccurate\nsimulation data in a better manner. Specifically, we pre-train a generative\nadversarial network (GAN) model to fit the state distribution of the offline\ndataset. Given this, we collect data from the inaccurate simulator starting\nfrom the distribution provided by the generator and reweight the simulated data\nusing the discriminator. Our experimental results in the D4RL benchmark and a\nreal-world manipulation task confirm that our method can benefit more from both\ninaccurate simulator and limited offline datasets to achieve better performance\nthan the state-of-the-art methods.", "paper_summary_zh": "\u96e2\u7dda\u5f37\u5316\u5b78\u7fd2 (RL) \u63d0\u4f9b\u4e00\u7a2e\u6709\u524d\u9014\u7684\u65b9\u6cd5\u4f86\u907f\u514d\u8207\u771f\u5be6\u74b0\u5883\u9032\u884c\u4ee3\u50f9\u9ad8\u6602\u7684\u7dda\u4e0a\u4e92\u52d5\u3002\u7136\u800c\uff0c\u96e2\u7dda RL \u7684\u6548\u80fd\u9ad8\u5ea6\u4f9d\u8cf4\u65bc\u8cc7\u6599\u96c6\u7684\u54c1\u8cea\uff0c\u9019\u53ef\u80fd\u6703\u5728\u5b78\u7fd2\u904e\u7a0b\u4e2d\u5c0e\u81f4\u5916\u63a8\u8aa4\u5dee\u3002\u5728\u8a31\u591a\u6a5f\u5668\u4eba\u61c9\u7528\u4e2d\uff0c\u901a\u5e38\u53ef\u4ee5\u4f7f\u7528\u4e0d\u6e96\u78ba\u7684\u6a21\u64ec\u5668\u3002\u7136\u800c\uff0c\u7531\u65bc\u773e\u6240\u5468\u77e5\u7684\u63a2\u7d22\u958b\u767c\u5169\u96e3\u56f0\u5883\u548c\u4e0d\u6e96\u78ba\u7684\u6a21\u64ec\u8207\u771f\u5be6\u74b0\u5883\u4e4b\u9593\u7684\u52d5\u614b\u5dee\u8ddd\uff0c\u7121\u6cd5\u76f4\u63a5\u5728\u96e2\u7dda RL \u4e2d\u4f7f\u7528\u5f9e\u4e0d\u6e96\u78ba\u7684\u6a21\u64ec\u5668\u76f4\u63a5\u6536\u96c6\u7684\u8cc7\u6599\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u65b9\u6cd5\uff0c\u4ee5\u66f4\u597d\u7684\u65b9\u5f0f\u7d50\u5408\u96e2\u7dda\u8cc7\u6599\u96c6\u548c\u4e0d\u6e96\u78ba\u7684\u6a21\u64ec\u8cc7\u6599\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u9810\u5148\u8a13\u7df4\u4e00\u500b\u751f\u6210\u5c0d\u6297\u7db2\u8def (GAN) \u6a21\u578b\u4f86\u64ec\u5408\u96e2\u7dda\u8cc7\u6599\u96c6\u7684\u72c0\u614b\u5206\u4f48\u3002\u6709\u9451\u65bc\u6b64\uff0c\u6211\u5011\u5f9e\u7522\u751f\u5668\u63d0\u4f9b\u7684\u5206\u4f48\u958b\u59cb\uff0c\u5f9e\u4e0d\u6e96\u78ba\u7684\u6a21\u64ec\u5668\u6536\u96c6\u8cc7\u6599\uff0c\u4e26\u4f7f\u7528\u8fa8\u5225\u5668\u91cd\u65b0\u52a0\u6b0a\u6a21\u64ec\u8cc7\u6599\u3002\u6211\u5011\u5728 D4RL \u57fa\u6e96\u548c\u771f\u5be6\u4e16\u754c\u64cd\u4f5c\u4efb\u52d9\u4e2d\u7684\u5be6\u9a57\u7d50\u679c\u8b49\u5be6\uff0c\u8207\u6700\u5148\u9032\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6211\u5011\u7684\u6a21\u578b\u53ef\u4ee5\u5f9e\u4e0d\u6e96\u78ba\u7684\u6a21\u64ec\u5668\u548c\u6709\u9650\u7684\u96e2\u7dda\u8cc7\u6599\u96c6\u4e2d\u53d7\u76ca\u66f4\u591a\uff0c\u4ee5\u5be6\u73fe\u66f4\u597d\u7684\u6548\u80fd\u3002", "author": "Yiwen Hou et.al.", "authors": "Yiwen Hou, Haoyuan Sun, Jinming Ma, Feng Wu", "id": "2405.04307v1", "paper_url": "http://arxiv.org/abs/2405.04307v1", "repo": "null"}}