{"2501.05717": {"publish_time": "2025-01-10", "title": "Zero-shot Shark Tracking and Biometrics from Aerial Imagery", "paper_summary": "The recent widespread adoption of drones for studying marine animals provides\nopportunities for deriving biological information from aerial imagery. The\nlarge scale of imagery data acquired from drones is well suited for machine\nlearning (ML) analysis. Development of ML models for analyzing marine animal\naerial imagery has followed the classical paradigm of training, testing, and\ndeploying a new model for each dataset, requiring significant time, human\neffort, and ML expertise. We introduce Frame Level ALIgment and tRacking\n(FLAIR), which leverages the video understanding of Segment Anything Model 2\n(SAM2) and the vision-language capabilities of Contrastive Language-Image\nPre-training (CLIP). FLAIR takes a drone video as input and outputs\nsegmentation masks of the species of interest across the video. Notably, FLAIR\nleverages a zero-shot approach, eliminating the need for labeled data, training\na new model, or fine-tuning an existing model to generalize to other species.\nWith a dataset of 18,000 drone images of Pacific nurse sharks, we trained\nstate-of-the-art object detection models to compare against FLAIR. We show that\nFLAIR massively outperforms these object detectors and performs competitively\nagainst two human-in-the-loop methods for prompting SAM2, achieving a Dice\nscore of 0.81. FLAIR readily generalizes to other shark species without\nadditional human effort and can be combined with novel heuristics to\nautomatically extract relevant information including length and tailbeat\nfrequency. FLAIR has significant potential to accelerate aerial imagery\nanalysis workflows, requiring markedly less human effort and expertise than\ntraditional machine learning workflows, while achieving superior accuracy. By\nreducing the effort required for aerial imagery analysis, FLAIR allows\nscientists to spend more time interpreting results and deriving insights about\nmarine ecosystems.", "paper_summary_zh": "\u7121\u4eba\u6a5f\u5ee3\u6cdb\u7528\u65bc\u7814\u7a76\u6d77\u6d0b\u52d5\u7269\uff0c\u63d0\u4f9b\u4e86\u5f9e\u822a\u62cd\u5f71\u50cf\u4e2d\u7372\u53d6\u751f\u7269\u8cc7\u8a0a\u7684\u6a5f\u6703\u3002\u5f9e\u7121\u4eba\u6a5f\u53d6\u5f97\u7684\u5927\u898f\u6a21\u5f71\u50cf\u8cc7\u6599\u975e\u5e38\u9069\u5408\u9032\u884c\u6a5f\u5668\u5b78\u7fd2 (ML) \u5206\u6790\u3002\u958b\u767c\u7528\u65bc\u5206\u6790\u6d77\u6d0b\u52d5\u7269\u822a\u62cd\u5f71\u50cf\u7684 ML \u6a21\u578b\u9075\u5faa\u8a13\u7df4\u3001\u6e2c\u8a66\u548c\u90e8\u7f72\u65b0\u6a21\u578b\u7684\u50b3\u7d71\u7bc4\u4f8b\uff0c\u9700\u8981\u5927\u91cf\u6642\u9593\u3001\u4eba\u529b\u548c ML \u5c08\u696d\u77e5\u8b58\u3002\u6211\u5011\u5f15\u5165\u4e86 Frame Level ALIgment and tRacking (FLAIR)\uff0c\u5b83\u5229\u7528\u4e86 Segment Anything Model 2 (SAM2) \u7684\u8996\u8a0a\u7406\u89e3\u548c\u5c0d\u6bd4\u8a9e\u8a00\u5f71\u50cf\u9810\u8a13\u7df4 (CLIP) \u7684\u8996\u89ba\u8a9e\u8a00\u529f\u80fd\u3002FLAIR \u4ee5\u7121\u4eba\u6a5f\u8996\u8a0a\u70ba\u8f38\u5165\uff0c\u4e26\u8f38\u51fa\u8996\u8a0a\u4e2d\u611f\u8208\u8da3\u7269\u7a2e\u7684\u5206\u5272\u906e\u7f69\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0cFLAIR \u5229\u7528\u96f6\u6b21\u5b78\u7fd2\u65b9\u6cd5\uff0c\u6d88\u9664\u4e86\u5c0d\u6a19\u7c64\u8cc7\u6599\u3001\u8a13\u7df4\u65b0\u6a21\u578b\u6216\u5fae\u8abf\u73fe\u6709\u6a21\u578b\u4ee5\u63a8\u5ee3\u5230\u5176\u4ed6\u7269\u7a2e\u7684\u9700\u6c42\u3002\u4f7f\u7528\u5305\u542b 18,000 \u5f35\u592a\u5e73\u6d0b\u8b77\u58eb\u9bca\u7121\u4eba\u6a5f\u5f71\u50cf\u7684\u8cc7\u6599\u96c6\uff0c\u6211\u5011\u8a13\u7df4\u4e86\u6700\u5148\u9032\u7684\u7269\u4ef6\u5075\u6e2c\u6a21\u578b\uff0c\u4ee5\u8207 FLAIR \u9032\u884c\u6bd4\u8f03\u3002\u6211\u5011\u8868\u660e FLAIR \u5927\u5e45\u512a\u65bc\u9019\u4e9b\u7269\u4ef6\u5075\u6e2c\u5668\uff0c\u4e26\u91dd\u5c0d\u5169\u7a2e\u63d0\u793a SAM2 \u7684\u4eba\u6a5f\u4e92\u52d5\u65b9\u6cd5\u9032\u884c\u7af6\u722d\uff0c\u9054\u5230 0.81 \u7684 Dice \u5206\u6578\u3002FLAIR \u53ef\u4ee5\u8f15\u9b06\u63a8\u5ee3\u5230\u5176\u4ed6\u9bca\u9b5a\u7269\u7a2e\uff0c\u800c\u7121\u9700\u984d\u5916\u7684\u4eba\u529b\uff0c\u4e26\u4e14\u53ef\u4ee5\u8207\u65b0\u7a4e\u7684\u555f\u767c\u5f0f\u65b9\u6cd5\u76f8\u7d50\u5408\uff0c\u4ee5\u81ea\u52d5\u63d0\u53d6\u76f8\u95dc\u8cc7\u8a0a\uff0c\u5305\u62ec\u9577\u5ea6\u548c\u5c3e\u9c2d\u62cd\u52d5\u983b\u7387\u3002FLAIR \u5177\u6709\u986f\u8457\u7684\u6f5b\u529b\uff0c\u53ef\u4ee5\u52a0\u901f\u822a\u62cd\u5f71\u50cf\u5206\u6790\u5de5\u4f5c\u6d41\u7a0b\uff0c\u8207\u50b3\u7d71\u6a5f\u5668\u5b78\u7fd2\u5de5\u4f5c\u6d41\u7a0b\u76f8\u6bd4\uff0c\u6240\u9700\u7684\u4eba\u529b\u548c\u5c08\u696d\u77e5\u8b58\u660e\u986f\u6e1b\u5c11\uff0c\u540c\u6642\u9084\u80fd\u5be6\u73fe\u66f4\u9ad8\u7684\u6e96\u78ba\u5ea6\u3002\u900f\u904e\u6e1b\u5c11\u822a\u62cd\u5f71\u50cf\u5206\u6790\u6240\u9700\u7684\u5de5\u4f5c\uff0cFLAIR \u8b93\u79d1\u5b78\u5bb6\u53ef\u4ee5\u82b1\u66f4\u591a\u6642\u9593\u8a6e\u91cb\u7d50\u679c\u4e26\u5f9e\u6d77\u6d0b\u751f\u614b\u7cfb\u7d71\u4e2d\u7372\u53d6\u898b\u89e3\u3002", "author": "Chinmay K Lalgudi et.al.", "authors": "Chinmay K Lalgudi, Mark E Leone, Jaden V Clark, Sergio Madrigal-Mora, Mario Espinoza", "id": "2501.05717v1", "paper_url": "http://arxiv.org/abs/2501.05717v1", "repo": "null"}}