{"2405.02996": {"publish_time": "2024-05-05", "title": "RepAugment: Input-Agnostic Representation-Level Augmentation for Respiratory Sound Classification", "paper_summary": "Recent advancements in AI have democratized its deployment as a healthcare\nassistant. While pretrained models from large-scale visual and audio datasets\nhave demonstrably generalized to this task, surprisingly, no studies have\nexplored pretrained speech models, which, as human-originated sounds,\nintuitively would share closer resemblance to lung sounds. This paper explores\nthe efficacy of pretrained speech models for respiratory sound classification.\nWe find that there is a characterization gap between speech and lung sound\nsamples, and to bridge this gap, data augmentation is essential. However, the\nmost widely used augmentation technique for audio and speech, SpecAugment,\nrequires 2-dimensional spectrogram format and cannot be applied to models\npretrained on speech waveforms. To address this, we propose RepAugment, an\ninput-agnostic representation-level augmentation technique that outperforms\nSpecAugment, but is also suitable for respiratory sound classification with\nwaveform pretrained models. Experimental results show that our approach\noutperforms the SpecAugment, demonstrating a substantial improvement in the\naccuracy of minority disease classes, reaching up to 7.14%.", "paper_summary_zh": "", "author": "June-Woo Kim et.al.", "authors": "June-Woo Kim,Miika Toikkanen,Sangmin Bae,Minseok Kim,Ho-Young Jung", "id": "2405.02996v1", "paper_url": "http://arxiv.org/abs/2405.02996v1", "repo": "null"}}