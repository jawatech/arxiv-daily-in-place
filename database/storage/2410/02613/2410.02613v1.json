{"2410.02613": {"publish_time": "2024-10-03", "title": "NL-Eye: Abductive NLI for Images", "paper_summary": "Will a Visual Language Model (VLM)-based bot warn us about slipping if it\ndetects a wet floor? Recent VLMs have demonstrated impressive capabilities, yet\ntheir ability to infer outcomes and causes remains underexplored. To address\nthis, we introduce NL-Eye, a benchmark designed to assess VLMs' visual\nabductive reasoning skills. NL-Eye adapts the abductive Natural Language\nInference (NLI) task to the visual domain, requiring models to evaluate the\nplausibility of hypothesis images based on a premise image and explain their\ndecisions. NL-Eye consists of 350 carefully curated triplet examples (1,050\nimages) spanning diverse reasoning categories: physical, functional, logical,\nemotional, cultural, and social. The data curation process involved two steps -\nwriting textual descriptions and generating images using text-to-image models,\nboth requiring substantial human involvement to ensure high-quality and\nchallenging scenes. Our experiments show that VLMs struggle significantly on\nNL-Eye, often performing at random baseline levels, while humans excel in both\nplausibility prediction and explanation quality. This demonstrates a deficiency\nin the abductive reasoning capabilities of modern VLMs. NL-Eye represents a\ncrucial step toward developing VLMs capable of robust multimodal reasoning for\nreal-world applications, including accident-prevention bots and generated video\nverification.", "paper_summary_zh": "\u57fa\u65bc\u8996\u89ba\u8a9e\u8a00\u6a21\u578b (VLM) \u7684\u6a5f\u5668\u4eba\u5982\u679c\u5075\u6e2c\u5230\u6fd5\u6ed1\u7684\u5730\u677f\uff0c\u6703\u8b66\u544a\u6211\u5011\u6ed1\u5012\u55ce\uff1f\u6700\u8fd1\u7684 VLM \u5df2\u5c55\u73fe\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u80fd\u529b\uff0c\u4f46\u5b83\u5011\u63a8\u8ad6\u7d50\u679c\u548c\u539f\u56e0\u7684\u80fd\u529b\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u5f15\u9032 NL-Eye\uff0c\u9019\u662f\u4e00\u500b\u57fa\u6e96\u6e2c\u8a66\uff0c\u65e8\u5728\u8a55\u4f30 VLM \u7684\u8996\u89ba\u6f14\u7e79\u63a8\u7406\u6280\u80fd\u3002NL-Eye \u5c07\u6f14\u7e79\u81ea\u7136\u8a9e\u8a00\u63a8\u7406 (NLI) \u4efb\u52d9\u8abf\u6574\u5230\u8996\u89ba\u9818\u57df\uff0c\u8981\u6c42\u6a21\u578b\u6839\u64da\u524d\u63d0\u5f71\u50cf\u8a55\u4f30\u5047\u8a2d\u5f71\u50cf\u7684\u53ef\u80fd\u6027\uff0c\u4e26\u8aaa\u660e\u5b83\u5011\u7684\u6c7a\u5b9a\u3002NL-Eye \u5305\u542b 350 \u500b\u7d93\u904e\u4ed4\u7d30\u7b56\u5c55\u7684\u4e09\u5143\u7d44\u7bc4\u4f8b\uff081,050 \u5f35\u5f71\u50cf\uff09\uff0c\u6db5\u84cb\u5404\u7a2e\u63a8\u7406\u985e\u5225\uff1a\u7269\u7406\u3001\u529f\u80fd\u3001\u908f\u8f2f\u3001\u60c5\u7dd2\u3001\u6587\u5316\u548c\u793e\u6703\u3002\u8cc7\u6599\u7b56\u5c55\u904e\u7a0b\u5305\u542b\u5169\u500b\u6b65\u9a5f - \u64b0\u5beb\u6587\u5b57\u63cf\u8ff0\u548c\u4f7f\u7528\u6587\u5b57\u8f49\u5f71\u50cf\u6a21\u578b\u7522\u751f\u5f71\u50cf\uff0c\u9019\u5169\u500b\u6b65\u9a5f\u90fd\u9700\u8981\u5927\u91cf\u4eba\u70ba\u53c3\u8207\uff0c\u4ee5\u78ba\u4fdd\u5834\u666f\u7684\u9ad8\u54c1\u8cea\u548c\u6311\u6230\u6027\u3002\u6211\u5011\u7684\u5be6\u9a57\u986f\u793a\uff0cVLM \u5728 NL-Eye \u4e0a\u986f\u5f97\u76f8\u7576\u5403\u529b\uff0c\u901a\u5e38\u8868\u73fe\u5f97\u50cf\u96a8\u6a5f\u57fa\u7dda\u5c64\u7d1a\uff0c\u800c\u4eba\u985e\u5247\u5728\u53ef\u80fd\u6027\u9810\u6e2c\u548c\u89e3\u91cb\u54c1\u8cea\u65b9\u9762\u90fd\u5f88\u51fa\u8272\u3002\u9019\u986f\u793a\u51fa\u73fe\u4ee3 VLM \u5728\u6f14\u7e79\u63a8\u7406\u80fd\u529b\u4e0a\u7684\u4e0d\u8db3\u3002NL-Eye \u4ee3\u8868\u8457\u671d\u5411\u958b\u767c\u5177\u5099\u5f37\u5065\u591a\u6a21\u614b\u63a8\u7406\u80fd\u529b\u7684 VLM \u9081\u51fa\u7684\u95dc\u9375\u4e00\u6b65\uff0c\u9069\u7528\u65bc\u9810\u9632\u4e8b\u6545\u6a5f\u5668\u4eba\u548c\u7522\u751f\u7684\u5f71\u7247\u9a57\u8b49\u7b49\u5be6\u969b\u61c9\u7528\u3002", "author": "Mor Ventura et.al.", "authors": "Mor Ventura, Michael Toker, Nitay Calderon, Zorik Gekhman, Yonatan Bitton, Roi Reichart", "id": "2410.02613v1", "paper_url": "http://arxiv.org/abs/2410.02613v1", "repo": "null"}}