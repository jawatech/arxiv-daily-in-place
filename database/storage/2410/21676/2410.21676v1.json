{"2410.21676": {"publish_time": "2024-10-29", "title": "How Does Critical Batch Size Scale in Pre-training?", "paper_summary": "Training large-scale models under given resources requires careful design of\nparallelism strategies. In particular, the efficiency notion of critical batch\nsize, concerning the compromise between time and compute, marks the threshold\nbeyond which greater data parallelism leads to diminishing returns. To\noperationalize it, we propose a measure of CBS and pre-train a series of\nauto-regressive language models, ranging from 85 million to 1.2 billion\nparameters, on the C4 dataset. Through extensive hyper-parameter sweeps and\ncareful control on factors such as batch size, momentum, and learning rate\nalong with its scheduling, we systematically investigate the impact of scale on\nCBS. Then we fit scaling laws with respect to model and data sizes to decouple\ntheir effects. Overall, our results demonstrate that CBS scales primarily with\ndata size rather than model size, a finding we justify theoretically through\nthe analysis of infinite-width limits of neural networks and\ninfinite-dimensional least squares regression. Of independent interest, we\nhighlight the importance of common hyper-parameter choices and strategies for\nstudying large-scale pre-training beyond fixed training durations.", "paper_summary_zh": "\u5728\u65e2\u5b9a\u8cc7\u6e90\u4e0b\u8a13\u7df4\u5927\u578b\u6a21\u578b\u9700\u8981\u4ed4\u7d30\u8a2d\u8a08\u5e73\u884c\u8655\u7406\u7b56\u7565\u3002\u7279\u5225\u662f\uff0c\u95dc\u9375\u6279\u6b21\u5927\u5c0f\u7684\u6548\u7387\u6982\u5ff5\uff0c\u6d89\u53ca\u6642\u9593\u548c\u904b\u7b97\u4e4b\u9593\u7684\u6298\u8877\uff0c\u6a19\u8a8c\u8457\u8d85\u8d8a\u6b64\u81e8\u754c\u9ede\u5f8c\uff0c\u66f4\u5927\u7684\u8cc7\u6599\u5e73\u884c\u8655\u7406\u5c07\u5c0e\u81f4\u5831\u916c\u905e\u6e1b\u3002\u70ba\u4e86\u5c07\u5176\u4ed8\u8af8\u5be6\u65bd\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b CBS \u91cf\u5ea6\uff0c\u4e26\u9810\u5148\u8a13\u7df4\u4e00\u7cfb\u5217\u81ea\u8ff4\u6b78\u8a9e\u8a00\u6a21\u578b\uff0c\u7bc4\u570d\u5f9e 8500 \u842c\u5230 12 \u5104\u500b\u53c3\u6578\uff0c\u5728 C4 \u8cc7\u6599\u96c6\u4e0a\u3002\u900f\u904e\u5ee3\u6cdb\u7684\u8d85\u53c3\u6578\u6383\u63cf\u548c\u4ed4\u7d30\u63a7\u5236\u6279\u6b21\u5927\u5c0f\u3001\u52d5\u91cf\u548c\u5b78\u7fd2\u7387\u7b49\u56e0\u7d20\u4ee5\u53ca\u5176\u6392\u7a0b\uff0c\u6211\u5011\u7cfb\u7d71\u6027\u5730\u7814\u7a76\u898f\u6a21\u5c0d CBS \u7684\u5f71\u97ff\u3002\u7136\u5f8c\uff0c\u6211\u5011\u64ec\u5408\u95dc\u65bc\u6a21\u578b\u548c\u8cc7\u6599\u5927\u5c0f\u7684\u7e2e\u653e\u5b9a\u5f8b\uff0c\u4ee5\u5206\u96e2\u5b83\u5011\u7684\u5f71\u97ff\u3002\u7e3d\u9ad4\u800c\u8a00\uff0c\u6211\u5011\u7684\u7d50\u679c\u8868\u660e CBS \u4e3b\u8981\u96a8\u8457\u8cc7\u6599\u5927\u5c0f\u800c\u4e0d\u662f\u6a21\u578b\u5927\u5c0f\u800c\u7e2e\u653e\uff0c\u6211\u5011\u900f\u904e\u5c0d\u795e\u7d93\u7db2\u8def\u7684\u7121\u9650\u5bec\u5ea6\u9650\u5236\u548c\u7121\u9650\u7dad\u6700\u5c0f\u4e8c\u4e58\u8ff4\u6b78\u7684\u5206\u6790\uff0c\u5728\u7406\u8ad6\u4e0a\u8b49\u660e\u4e86\u9019\u4e00\u767c\u73fe\u3002\u7368\u7acb\u7684\u8208\u8da3\u662f\uff0c\u6211\u5011\u5f37\u8abf\u4e86\u901a\u7528\u8d85\u53c3\u6578\u9078\u64c7\u548c\u7b56\u7565\u7684\u91cd\u8981\u6027\uff0c\u7528\u65bc\u7814\u7a76\u8d85\u8d8a\u56fa\u5b9a\u8a13\u7df4\u6301\u7e8c\u6642\u9593\u7684\u5927\u898f\u6a21\u9810\u8a13\u7df4\u3002", "author": "Hanlin Zhang et.al.", "authors": "Hanlin Zhang, Depen Morwani, Nikhil Vyas, Jingfeng Wu, Difan Zou, Udaya Ghai, Dean Foster, Sham Kakade", "id": "2410.21676v1", "paper_url": "http://arxiv.org/abs/2410.21676v1", "repo": "null"}}