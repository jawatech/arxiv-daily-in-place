{"2405.20139": {"publish_time": "2024-05-30", "title": "GNN-RAG: Graph Neural Retrieval for Large Language Model Reasoning", "paper_summary": "Knowledge Graphs (KGs) represent human-crafted factual knowledge in the form\nof triplets (head, relation, tail), which collectively form a graph. Question\nAnswering over KGs (KGQA) is the task of answering natural questions grounding\nthe reasoning to the information provided by the KG. Large Language Models\n(LLMs) are the state-of-the-art models for QA tasks due to their remarkable\nability to understand natural language. On the other hand, Graph Neural\nNetworks (GNNs) have been widely used for KGQA as they can handle the complex\ngraph information stored in the KG. In this work, we introduce GNN-RAG, a novel\nmethod for combining language understanding abilities of LLMs with the\nreasoning abilities of GNNs in a retrieval-augmented generation (RAG) style.\nFirst, a GNN reasons over a dense KG subgraph to retrieve answer candidates for\na given question. Second, the shortest paths in the KG that connect question\nentities and answer candidates are extracted to represent KG reasoning paths.\nThe extracted paths are verbalized and given as input for LLM reasoning with\nRAG. In our GNN-RAG framework, the GNN acts as a dense subgraph reasoner to\nextract useful graph information, while the LLM leverages its natural language\nprocessing ability for ultimate KGQA. Furthermore, we develop a retrieval\naugmentation (RA) technique to further boost KGQA performance with GNN-RAG.\nExperimental results show that GNN-RAG achieves state-of-the-art performance in\ntwo widely used KGQA benchmarks (WebQSP and CWQ), outperforming or matching\nGPT-4 performance with a 7B tuned LLM. In addition, GNN-RAG excels on multi-hop\nand multi-entity questions outperforming competing approaches by 8.9--15.5%\npoints at answer F1.", "paper_summary_zh": "<paragraph>\u77e5\u8b58\u5716\u8b5c (KG) \u4ee5\u4e09\u5143\u7d44 (\u4e3b\u8a5e\u3001\u95dc\u4fc2\u3001\u8cd3\u8a5e) \u7684\u5f62\u5f0f\u8868\u793a\u4eba\u5de5\u5efa\u7acb\u7684\u4e8b\u5be6\u77e5\u8b58\uff0c\u9019\u4e9b\u4e09\u5143\u7d44\u5171\u540c\u5f62\u6210\u4e00\u500b\u5716\u5f62\u3002\u5728 KG \u4e0a\u9032\u884c\u554f\u7b54 (KGQA) \u662f\u56de\u7b54\u81ea\u7136\u554f\u984c\u7684\u4efb\u52d9\uff0c\u5c07\u63a8\u7406\u57fa\u790e\u5efa\u7acb\u5728 KG \u63d0\u4f9b\u7684\u8cc7\u8a0a\u4e0a\u3002\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7531\u65bc\u5176\u7406\u89e3\u81ea\u7136\u8a9e\u8a00\u7684\u975e\u51e1\u80fd\u529b\uff0c\u6210\u70ba\u554f\u7b54\u4efb\u52d9\u7684\u6700\u65b0\u6280\u8853\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u5716\u5f62\u795e\u7d93\u7db2\u8def (GNN) \u5df2\u5ee3\u6cdb\u7528\u65bc KGQA\uff0c\u56e0\u70ba\u5b83\u5011\u53ef\u4ee5\u8655\u7406\u5132\u5b58\u5728 KG \u4e2d\u7684\u8907\u96dc\u5716\u5f62\u8cc7\u8a0a\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 GNN-RAG\uff0c\u9019\u662f\u4e00\u7a2e\u65b0\u65b9\u6cd5\uff0c\u7d50\u5408\u4e86 LLM \u7684\u8a9e\u8a00\u7406\u89e3\u80fd\u529b\u548c GNN \u7684\u63a8\u7406\u80fd\u529b\uff0c\u63a1\u7528\u6aa2\u7d22\u589e\u5f37\u751f\u6210 (RAG) \u7684\u65b9\u5f0f\u3002\u9996\u5148\uff0cGNN \u5728\u4e00\u500b\u5bc6\u96c6\u7684 KG \u5b50\u5716\u4e2d\u9032\u884c\u63a8\u7406\uff0c\u4ee5\u6aa2\u7d22\u7d66\u5b9a\u554f\u984c\u7684\u7b54\u6848\u5019\u9078\u3002\u5176\u6b21\uff0c\u63d0\u53d6 KG \u4e2d\u9023\u63a5\u554f\u984c\u5be6\u9ad4\u548c\u7b54\u6848\u5019\u9078\u7684\u6700\u77ed\u8def\u5f91\uff0c\u4ee5\u8868\u793a KG \u63a8\u7406\u8def\u5f91\u3002\u63d0\u53d6\u7684\u8def\u5f91\u6703\u88ab\u53e3\u982d\u5316\uff0c\u4e26\u4f5c\u70ba\u8f38\u5165\u63d0\u4f9b\u7d66 LLM\uff0c\u4ee5\u4fbf\u4f7f\u7528 RAG \u9032\u884c\u63a8\u7406\u3002\u5728\u6211\u5011\u7684 GNN-RAG \u6846\u67b6\u4e2d\uff0cGNN \u4f5c\u70ba\u4e00\u500b\u5bc6\u96c6\u5b50\u5716\u63a8\u7406\u5668\uff0c\u7528\u65bc\u63d0\u53d6\u6709\u7528\u7684\u5716\u5f62\u8cc7\u8a0a\uff0c\u800c LLM \u5247\u5229\u7528\u5176\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u80fd\u529b\u9032\u884c\u6700\u7d42\u7684 KGQA\u3002\u6b64\u5916\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u7a2e\u6aa2\u7d22\u589e\u5f37 (RA) \u6280\u8853\uff0c\u4ee5\u9032\u4e00\u6b65\u63d0\u5347 GNN-RAG \u7684 KGQA \u6548\u80fd\u3002\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0cGNN-RAG \u5728\u5169\u500b\u5ee3\u6cdb\u4f7f\u7528\u7684 KGQA \u57fa\u6e96 (WebQSP \u548c CWQ) \u4e2d\u9054\u5230\u4e86\u6700\u5148\u9032\u7684\u6548\u80fd\uff0c\u5728\u4f7f\u7528 7B \u8abf\u6574\u5f8c\u7684 LLM \u4e2d\u8d85\u8d8a\u6216\u5339\u914d GPT-4 \u7684\u6548\u80fd\u3002\u6b64\u5916\uff0cGNN-RAG \u5728\u591a\u8df3\u548c\u591a\u5be6\u9ad4\u554f\u984c\u4e0a\u8868\u73fe\u51fa\u8272\uff0c\u5728\u7b54\u6848 F1 \u4e0a\u6bd4\u7af6\u722d\u65b9\u6cd5\u9ad8\u51fa 8.9--15.5%\u3002</paragraph>", "author": "Costas Mavromatis et.al.", "authors": "Costas Mavromatis, George Karypis", "id": "2405.20139v1", "paper_url": "http://arxiv.org/abs/2405.20139v1", "repo": "null"}}