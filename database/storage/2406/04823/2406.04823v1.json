{"2406.04823": {"publish_time": "2024-06-07", "title": "BERTs are Generative In-Context Learners", "paper_summary": "This paper explores the in-context learning capabilities of masked language\nmodels, challenging the common view that this ability does not 'emerge' in\nthem. We present an embarrassingly simple inference technique that enables\nDeBERTa to operate as a generative model without any additional training. Our\nfindings demonstrate that DeBERTa can match and even surpass GPT-3, its\ncontemporary that famously introduced the paradigm of in-context learning. The\ncomparative analysis reveals that the masked and causal language models behave\nvery differently, as they clearly outperform each other on different categories\nof tasks. This suggests that there is great potential for a hybrid training\napproach that takes advantage of the strengths of both training objectives.", "paper_summary_zh": "\u672c\u6587\u63a2\u8a0e\u4e86\u906e\u853d\u8a9e\u8a00\u6a21\u578b\u7684\u8a9e\u5883\u5b78\u7fd2\u80fd\u529b\uff0c\u6311\u6230\u4e86\u6b64\u9805\u80fd\u529b\u4e26\u672a\u300c\u6d6e\u73fe\u300d\u65bc\u6b64\u985e\u6a21\u578b\u4e2d\u7684\u666e\u904d\u89c0\u9ede\u3002\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u4ee4\u4eba\u5c37\u5c2c\u7684\u7c21\u55ae\u63a8\u8ad6\u6280\u8853\uff0c\u8b93 DeBERTa \u80fd\u5920\u5728\u6c92\u6709\u4efb\u4f55\u984d\u5916\u8a13\u7df4\u7684\u60c5\u6cc1\u4e0b\u4f5c\u70ba\u751f\u6210\u6a21\u578b\u904b\u4f5c\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u8b49\u660e\uff0cDeBERTa \u80fd\u5920\u5339\u6575\u751a\u81f3\u8d85\u8d8a GPT-3\uff0c\u5f8c\u8005\u662f\u8457\u540d\u7684\u8a9e\u5883\u5b78\u7fd2\u5178\u7bc4\u3002\u6bd4\u8f03\u5206\u6790\u986f\u793a\uff0c\u906e\u853d\u8a9e\u8a00\u6a21\u578b\u548c\u56e0\u679c\u8a9e\u8a00\u6a21\u578b\u7684\u884c\u70ba\u975e\u5e38\u4e0d\u540c\uff0c\u56e0\u70ba\u5b83\u5011\u5728\u4e0d\u540c\u985e\u5225\u7684\u4efb\u52d9\u4e0a\u660e\u986f\u8868\u73fe\u5f97\u6bd4\u5c0d\u65b9\u51fa\u8272\u3002\u9019\u8868\u660e\uff0c\u4e00\u7a2e\u5229\u7528\u5169\u7a2e\u8a13\u7df4\u76ee\u6a19\u512a\u52e2\u7684\u6df7\u5408\u8a13\u7df4\u65b9\u6cd5\u5177\u6709\u5de8\u5927\u7684\u6f5b\u529b\u3002", "author": "David Samuel et.al.", "authors": "David Samuel", "id": "2406.04823v1", "paper_url": "http://arxiv.org/abs/2406.04823v1", "repo": "https://github.com/ltgoslo/bert-in-context"}}