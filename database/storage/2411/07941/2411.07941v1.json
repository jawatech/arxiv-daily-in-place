{"2411.07941": {"publish_time": "2024-11-12", "title": "DuoLift-GAN:Reconstructing CT from Single-view and Biplanar X-Rays with Generative Adversarial Networks", "paper_summary": "Computed tomography (CT) provides highly detailed three-dimensional (3D)\nmedical images but is costly, time-consuming, and often inaccessible in\nintraoperative settings (Organization et al. 2011). Recent advancements have\nexplored reconstructing 3D chest volumes from sparse 2D X-rays, such as\nsingle-view or orthogonal double-view images. However, current models tend to\nprocess 2D images in a planar manner, prioritizing visual realism over\nstructural accuracy. In this work, we introduce DuoLift Generative Adversarial\nNetworks (DuoLift-GAN), a novel architecture with dual branches that\nindependently elevate 2D images and their features into 3D representations.\nThese 3D outputs are merged into a unified 3D feature map and decoded into a\ncomplete 3D chest volume, enabling richer 3D information capture. We also\npresent a masked loss function that directs reconstruction towards critical\nanatomical regions, improving structural accuracy and visual quality. This\npaper demonstrates that DuoLift-GAN significantly enhances reconstruction\naccuracy while achieving superior visual realism compared to existing methods.", "paper_summary_zh": "\u96fb\u8166\u65b7\u5c64\u6383\u63cf (CT) \u80fd\u63d0\u4f9b\u9ad8\u5ea6\u8a73\u7d30\u7684\u4e09\u7dad (3D) \u91ab\u5b78\u5f71\u50cf\uff0c\u4f46\u6602\u8cb4\u3001\u8017\u6642\u4e14\u5728\u8853\u4e2d\u74b0\u5883\u4e2d\u901a\u5e38\u7121\u6cd5\u53d6\u5f97 (Organization et al. 2011)\u3002\u6700\u8fd1\u7684\u9032\u5c55\u63a2\u7d22\u5f9e\u7a00\u758f\u7684 2D X \u5149\u91cd\u5efa 3D \u80f8\u90e8\u9ad4\u7a4d\uff0c\u4f8b\u5982\u55ae\u8996\u5716\u6216\u6b63\u4ea4\u96d9\u8996\u5716\u5f71\u50cf\u3002\u7136\u800c\uff0c\u76ee\u524d\u7684\u6a21\u578b\u50be\u5411\u65bc\u4ee5\u5e73\u9762\u65b9\u5f0f\u8655\u7406 2D \u5f71\u50cf\uff0c\u512a\u5148\u8003\u616e\u8996\u89ba\u771f\u5be6\u6027\u800c\u975e\u7d50\u69cb\u6e96\u78ba\u6027\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 DuoLift \u751f\u6210\u5c0d\u6297\u7db2\u8def (DuoLift-GAN)\uff0c\u4e00\u7a2e\u5177\u6709\u96d9\u5206\u652f\u7684\u65b0\u7a4e\u67b6\u69cb\uff0c\u53ef\u7368\u7acb\u5730\u5c07 2D \u5f71\u50cf\u53ca\u5176\u7279\u5fb5\u63d0\u5347\u5230 3D \u8868\u73fe\u5f62\u5f0f\u3002\u9019\u4e9b 3D \u8f38\u51fa\u6703\u5408\u4f75\u6210\u4e00\u500b\u7d71\u4e00\u7684 3D \u7279\u5fb5\u5716\uff0c\u4e26\u89e3\u78bc\u6210\u4e00\u500b\u5b8c\u6574\u7684 3D \u80f8\u90e8\u9ad4\u7a4d\uff0c\u5f9e\u800c\u80fd\u5920\u64f7\u53d6\u66f4\u8c50\u5bcc\u7684 3D \u8cc7\u8a0a\u3002\u6211\u5011\u4e5f\u63d0\u51fa\u4e86\u4e00\u500b\u906e\u7f69\u640d\u5931\u51fd\u6578\uff0c\u5c07\u91cd\u5efa\u5c0e\u5411\u95dc\u9375\u89e3\u5256\u5340\u57df\uff0c\u6539\u5584\u7d50\u69cb\u6e96\u78ba\u6027\u548c\u8996\u89ba\u54c1\u8cea\u3002\u9019\u7bc7\u8ad6\u6587\u8b49\u660e\u4e86 DuoLift-GAN \u8207\u73fe\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u986f\u8457\u63d0\u5347\u4e86\u91cd\u5efa\u6e96\u78ba\u6027\uff0c\u540c\u6642\u9054\u5230\u4e86\u5353\u8d8a\u7684\u8996\u89ba\u771f\u5be6\u6027\u3002", "author": "Zhaoxi Zhang et.al.", "authors": "Zhaoxi Zhang, Yueliang Ying", "id": "2411.07941v1", "paper_url": "http://arxiv.org/abs/2411.07941v1", "repo": "null"}}