{"2412.06849": {"publish_time": "2024-12-08", "title": "GL-Fusion: Rethinking the Combination of Graph Neural Network and Large Language model", "paper_summary": "Recent research on integrating Large Language Models (LLMs) with Graph Neural\nNetworks (GNNs) typically follows two approaches: LLM-centered models, which\nconvert graph data into tokens for LLM processing, and GNN-centered models,\nwhich use LLMs to encode text features into node and edge representations for\nGNN input. LLM-centered models often struggle to capture graph structures\neffectively, while GNN-centered models compress variable-length textual data\ninto fixed-size vectors, limiting their ability to understand complex\nsemantics. Additionally, GNN-centered approaches require converting tasks into\na uniform, manually-designed format, restricting them to classification tasks\nand preventing language output. To address these limitations, we introduce a\nnew architecture that deeply integrates GNN with LLM, featuring three key\ninnovations: (1) Structure-Aware Transformers, which incorporate GNN's\nmessage-passing capabilities directly into LLM's transformer layers, allowing\nsimultaneous processing of textual and structural information and generating\noutputs from both GNN and LLM; (2) Graph-Text Cross-Attention, which processes\nfull, uncompressed text from graph nodes and edges, ensuring complete semantic\nintegration; and (3) GNN-LLM Twin Predictor, enabling LLM's flexible\nautoregressive generation alongside GNN's scalable one-pass prediction.\nGL-Fusion achieves outstand performance on various tasks. Notably, it achieves\nstate-of-the-art performance on OGBN-Arxiv and OGBG-Code2.", "paper_summary_zh": "<paragraph>\u5c07\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8207\u5716\u795e\u7d93\u7db2\u8def (GNN) \u6574\u5408\u7684\u6700\u65b0\u7814\u7a76\u901a\u5e38\u9075\u5faa\u5169\u7a2e\u65b9\u6cd5\uff1a\u4ee5 LLM \u70ba\u4e2d\u5fc3\u7684\u6a21\u578b\uff0c\u5c07\u5716\u5f62\u8cc7\u6599\u8f49\u63db\u70ba LLM \u8655\u7406\u7684\u7b26\u865f\uff0c\u4ee5\u53ca\u4ee5 GNN \u70ba\u4e2d\u5fc3\u7684\u6a21\u578b\uff0c\u4f7f\u7528 LLM \u5c07\u6587\u5b57\u7279\u5fb5\u7de8\u78bc\u6210\u7bc0\u9ede\u548c\u908a\u7de3\u8868\u793a\uff0c\u4f5c\u70ba GNN \u8f38\u5165\u3002\u4ee5 LLM \u70ba\u4e2d\u5fc3\u7684\u6a21\u578b\u901a\u5e38\u96e3\u4ee5\u6709\u6548\u64f7\u53d6\u5716\u5f62\u7d50\u69cb\uff0c\u800c\u4ee5 GNN \u70ba\u4e2d\u5fc3\u7684\u6a21\u578b\u6703\u5c07\u8b8a\u9577\u6587\u5b57\u8cc7\u6599\u58d3\u7e2e\u6210\u56fa\u5b9a\u5927\u5c0f\u7684\u5411\u91cf\uff0c\u9650\u5236\u5b83\u5011\u7406\u89e3\u8907\u96dc\u8a9e\u610f\u7684\u80fd\u529b\u3002\u6b64\u5916\uff0c\u4ee5 GNN \u70ba\u4e2d\u5fc3\u7684\u6a21\u578b\u9700\u8981\u5c07\u4efb\u52d9\u8f49\u63db\u6210\u7d71\u4e00\u7684\u624b\u52d5\u8a2d\u8a08\u683c\u5f0f\uff0c\u9650\u5236\u5b83\u5011\u53ea\u80fd\u9032\u884c\u5206\u985e\u4efb\u52d9\uff0c\u4e14\u7121\u6cd5\u7522\u751f\u8a9e\u8a00\u8f38\u51fa\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u9650\u5236\uff0c\u6211\u5011\u5f15\u5165\u4e00\u7a2e\u65b0\u7684\u67b6\u69cb\uff0c\u5c07 GNN \u8207 LLM \u6df1\u5ea6\u6574\u5408\uff0c\u5177\u5099\u4e09\u5927\u95dc\u9375\u5275\u65b0\uff1a(1) \u7d50\u69cb\u611f\u77e5Transformer\uff0c\u5c07 GNN \u7684\u8a0a\u606f\u50b3\u905e\u529f\u80fd\u76f4\u63a5\u6574\u5408\u5230 LLM \u7684Transformer\u5c64\u4e2d\uff0c\u5141\u8a31\u540c\u6642\u8655\u7406\u6587\u5b57\u548c\u7d50\u69cb\u8cc7\u8a0a\uff0c\u4e26\u5f9e GNN \u548c LLM \u7522\u751f\u8f38\u51fa\uff1b(2) \u5716\u5f62\u6587\u5b57\u4ea4\u53c9\u6ce8\u610f\u529b\uff0c\u8655\u7406\u4f86\u81ea\u5716\u5f62\u7bc0\u9ede\u548c\u908a\u7de3\u7684\u5b8c\u6574\u672a\u58d3\u7e2e\u6587\u5b57\uff0c\u78ba\u4fdd\u5b8c\u6574\u7684\u8a9e\u7fa9\u6574\u5408\uff1b(3) GNN-LLM \u96d9\u91cd\u9810\u6e2c\u5668\uff0c\u555f\u7528 LLM \u7684\u5f48\u6027\u81ea\u8ff4\u6b78\u7522\u751f\uff0c\u4ee5\u53ca GNN \u7684\u53ef\u64f4\u5145\u55ae\u6b21\u9810\u6e2c\u3002GL-Fusion \u5728\u5404\u7a2e\u4efb\u52d9\u4e2d\u9054\u6210\u5091\u51fa\u7684\u6548\u80fd\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5b83\u5728 OGBN-Arxiv \u548c OGBG-Code2 \u4e0a\u9054\u5230\u4e86\u6700\u5148\u9032\u7684\u6548\u80fd\u3002</paragraph>", "author": "Haotong Yang et.al.", "authors": "Haotong Yang, Xiyuan Wang, Qian Tao, Shuxian Hu, Zhouchen Lin, Muhan Zhang", "id": "2412.06849v1", "paper_url": "http://arxiv.org/abs/2412.06849v1", "repo": "null"}}