{"2405.11647": {"publish_time": "2024-05-19", "title": "Hummer: Towards Limited Competitive Preference Dataset", "paper_summary": "Preference datasets are essential for incorporating human preferences into\npre-trained language models, playing a key role in the success of Reinforcement\nLearning from Human Feedback. However, these datasets often demonstrate\nconflicting alignment objectives, leading to increased vulnerability to\njailbreak attacks and challenges in adapting downstream tasks to prioritize\nspecific alignment objectives without negatively impacting others. In this\nwork, we introduce a novel statistical metric, Alignment Dimension Conflict, to\nquantify the degree of conflict within preference datasets. We then present\n\\texttt{Hummer} and its fine-grained variant, \\texttt{Hummer-F}, as innovative\npairwise preference datasets with reduced-conflict alignment objectives.\n\\texttt{Hummer} is built based on UltraFeedback and is enhanced by AI feedback\nfrom GPT-4, marking as the first preference dataset aimed at reducing the\ncompetition between alignment objectives. Furthermore, we develop reward\nmodels, HummerRM and HummerRM-F, which employ a hybrid sampling approach to\nbalance diverse alignment objectives effectively. This sampling method\npositions HummerRM as an ideal model for domain-specific further fine-tuning\nand reducing vulnerabilities to attacks.", "paper_summary_zh": "\u504f\u597d\u6570\u636e\u96c6\u5bf9\u4e8e\u5c06\u4eba\u7c7b\u504f\u597d\u7eb3\u5165\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u81f3\u5173\u91cd\u8981\uff0c\u5728\u4eba\u7c7b\u53cd\u9988\u5f3a\u5316\u5b66\u4e60\u7684\u6210\u529f\u4e2d\u53d1\u6325\u7740\u5173\u952e\u4f5c\u7528\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u6570\u636e\u96c6\u901a\u5e38\u8868\u73b0\u51fa\u76f8\u4e92\u51b2\u7a81\u7684\u5bf9\u9f50\u76ee\u6807\uff0c\u5bfc\u81f4\u66f4\u5bb9\u6613\u53d7\u5230\u8d8a\u72f1\u653b\u51fb\uff0c\u5e76\u4e14\u96be\u4ee5\u8c03\u6574\u4e0b\u6e38\u4efb\u52a1\u4ee5\u4f18\u5148\u8003\u8651\u7279\u5b9a\u5bf9\u9f50\u76ee\u6807\uff0c\u800c\u4e0d\u4f1a\u5bf9\u5176\u4ed6\u76ee\u6807\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u7edf\u8ba1\u6307\u6807\uff0c\u5373\u5bf9\u9f50\u7ef4\u5ea6\u51b2\u7a81\uff0c\u4ee5\u91cf\u5316\u504f\u597d\u6570\u636e\u96c6\u4e2d\u7684\u51b2\u7a81\u7a0b\u5ea6\u3002\u7136\u540e\uff0c\u6211\u4eec\u63d0\u51fa \\texttt{Hummer} \u53ca\u5176\u7ec6\u7c92\u5ea6\u53d8\u4f53 \\texttt{Hummer-F}\uff0c\u4f5c\u4e3a\u5177\u6709\u51cf\u5c11\u51b2\u7a81\u5bf9\u9f50\u76ee\u6807\u7684\u521b\u65b0\u6210\u5bf9\u504f\u597d\u6570\u636e\u96c6\u3002\\texttt{Hummer} \u57fa\u4e8e UltraFeedback \u6784\u5efa\uff0c\u5e76\u901a\u8fc7 GPT-4 \u7684 AI \u53cd\u9988\u8fdb\u884c\u589e\u5f3a\uff0c\u6807\u5fd7\u7740\u7b2c\u4e00\u4e2a\u65e8\u5728\u51cf\u5c11\u5bf9\u9f50\u76ee\u6807\u4e4b\u95f4\u7ade\u4e89\u7684\u504f\u597d\u6570\u636e\u96c6\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5f00\u53d1\u4e86\u5956\u52b1\u6a21\u578b HummerRM \u548c HummerRM-F\uff0c\u5b83\u4eec\u91c7\u7528\u6df7\u5408\u91c7\u6837\u65b9\u6cd5\u6765\u6709\u6548\u5e73\u8861\u4e0d\u540c\u7684\u5bf9\u9f50\u76ee\u6807\u3002\u8fd9\u79cd\u91c7\u6837\u65b9\u6cd5\u5c06 HummerRM \u5b9a\u4f4d\u4e3a\u7279\u5b9a\u9886\u57df\u8fdb\u4e00\u6b65\u5fae\u8c03\u548c\u51cf\u5c11\u653b\u51fb\u6f0f\u6d1e\u7684\u7406\u60f3\u6a21\u578b\u3002", "author": "Li Jiang et.al.", "authors": "Li Jiang, Yusen Wu, Junwu Xiong, Jingqing Ruan, Yichuan Ding, Qingpei Guo, Zujie Wen, Jun Zhou, Xiaotie Deng", "id": "2405.11647v1", "paper_url": "http://arxiv.org/abs/2405.11647v1", "repo": "null"}}