{"2410.03568": {"publish_time": "2024-10-04", "title": "Towards Linguistically-Aware and Language-Independent Tokenization for Large Language Models (LLMs)", "paper_summary": "This paper presents a comprehensive study on the tokenization techniques\nemployed by state-of-the-art large language models (LLMs) and their\nimplications on the cost and availability of services across different\nlanguages, especially low resource languages. The analysis considers multiple\nLLMs, including GPT-4 (using cl100k_base embeddings), GPT-3 (with p50k_base\nembeddings), and DaVinci (employing r50k_base embeddings), as well as the\nwidely used BERT base tokenizer. The study evaluates the tokenization\nvariability observed across these models and investigates the challenges of\nlinguistic representation in subword tokenization. The research underscores the\nimportance of fostering linguistically-aware development practices, especially\nfor languages that are traditionally under-resourced. Moreover, this paper\nintroduces case studies that highlight the real-world implications of\ntokenization choices, particularly in the context of electronic health record\n(EHR) systems. This research aims to promote generalizable Internationalization\n(I18N) practices in the development of AI services in this domain and beyond,\nwith a strong emphasis on inclusivity, particularly for languages traditionally\nunderrepresented in AI applications.", "paper_summary_zh": "\u672c\u6587\u5c0d\u6700\u5148\u9032\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6240\u63a1\u7528\u7684\u6a19\u8a18\u5316\u6280\u8853\u9032\u884c\u4e86\u5168\u9762\u7814\u7a76\uff0c\u4e26\u63a2\u8a0e\u4e86\u9019\u4e9b\u6280\u8853\u5c0d\u4e0d\u540c\u8a9e\u8a00\uff08\u5c24\u5176\u662f\u4f4e\u8cc7\u6e90\u8a9e\u8a00\uff09\u670d\u52d9\u7684\u6210\u672c\u548c\u53ef\u7528\u6027\u7684\u5f71\u97ff\u3002\u5206\u6790\u8003\u91cf\u4e86\u591a\u500b LLM\uff0c\u5305\u62ec GPT-4\uff08\u4f7f\u7528 cl100k_base \u5d4c\u5165\uff09\u3001GPT-3\uff08\u4f7f\u7528 p50k_base \u5d4c\u5165\uff09\u548c DaVinci\uff08\u4f7f\u7528 r50k_base \u5d4c\u5165\uff09\uff0c\u4ee5\u53ca\u5ee3\u6cdb\u4f7f\u7528\u7684 BERT \u57fa\u790e\u6a19\u8a18\u5668\u3002\u7814\u7a76\u8a55\u4f30\u4e86\u9019\u4e9b\u6a21\u578b\u4e2d\u89c0\u5bdf\u5230\u7684\u6a19\u8a18\u5316\u8b8a\u7570\u6027\uff0c\u4e26\u63a2\u8a0e\u4e86\u8a5e\u5f59\u5316\u6a19\u8a18\u5316\u4e2d\u8a9e\u8a00\u8868\u793a\u7684\u6311\u6230\u3002\u7814\u7a76\u5f37\u8abf\u4e86\u57f9\u990a\u8a9e\u8a00\u611f\u77e5\u958b\u767c\u5be6\u52d9\u7684\u91cd\u8981\u6027\uff0c\u7279\u5225\u662f\u5c0d\u65bc\u50b3\u7d71\u4e0a\u8cc7\u6e90\u4e0d\u8db3\u7684\u8a9e\u8a00\u3002\u6b64\u5916\uff0c\u672c\u6587\u4ecb\u7d39\u4e86\u6848\u4f8b\u7814\u7a76\uff0c\u91cd\u9ede\u8aaa\u660e\u6a19\u8a18\u5316\u9078\u64c7\u7684\u5be6\u969b\u5f71\u97ff\uff0c\u7279\u5225\u662f\u5728\u96fb\u5b50\u5065\u5eb7\u7d00\u9304 (EHR) \u7cfb\u7d71\u7684\u80cc\u666f\u4e0b\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a8\u5ee3\u6b64\u9818\u57df\uff08\u53ca\u5176\u4ed6\u9818\u57df\uff09AI \u670d\u52d9\u958b\u767c\u4e2d\u53ef\u6982\u5316\u7684\u570b\u969b\u5316 (I18N) \u5be6\u52d9\uff0c\u4e26\u7279\u5225\u5f37\u8abf\u5305\u5bb9\u6027\uff0c\u7279\u5225\u662f\u5c0d\u65bc\u50b3\u7d71\u4e0a\u5728 AI \u61c9\u7528\u4e2d\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u8a9e\u8a00\u3002", "author": "Abrar Rahman et.al.", "authors": "Abrar Rahman, Garry Bowlin, Binit Mohanty, Sean McGunigal", "id": "2410.03568v1", "paper_url": "http://arxiv.org/abs/2410.03568v1", "repo": "null"}}