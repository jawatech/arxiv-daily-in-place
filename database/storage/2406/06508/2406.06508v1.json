{"2406.06508": {"publish_time": "2024-06-10", "title": "Monkey See, Monkey Do: Harnessing Self-attention in Motion Diffusion for Zero-shot Motion Transfer", "paper_summary": "Given the remarkable results of motion synthesis with diffusion models, a\nnatural question arises: how can we effectively leverage these models for\nmotion editing? Existing diffusion-based motion editing methods overlook the\nprofound potential of the prior embedded within the weights of pre-trained\nmodels, which enables manipulating the latent feature space; hence, they\nprimarily center on handling the motion space. In this work, we explore the\nattention mechanism of pre-trained motion diffusion models. We uncover the\nroles and interactions of attention elements in capturing and representing\nintricate human motion patterns, and carefully integrate these elements to\ntransfer a leader motion to a follower one while maintaining the nuanced\ncharacteristics of the follower, resulting in zero-shot motion transfer.\nEditing features associated with selected motions allows us to confront a\nchallenge observed in prior motion diffusion approaches, which use general\ndirectives (e.g., text, music) for editing, ultimately failing to convey subtle\nnuances effectively. Our work is inspired by how a monkey closely imitates what\nit sees while maintaining its unique motion patterns; hence we call it Monkey\nSee, Monkey Do, and dub it MoMo. Employing our technique enables accomplishing\ntasks such as synthesizing out-of-distribution motions, style transfer, and\nspatial editing. Furthermore, diffusion inversion is seldom employed for\nmotions; as a result, editing efforts focus on generated motions, limiting the\neditability of real ones. MoMo harnesses motion inversion, extending its\napplication to both real and generated motions. Experimental results show the\nadvantage of our approach over the current art. In particular, unlike methods\ntailored for specific applications through training, our approach is applied at\ninference time, requiring no training. Our webpage is at\nhttps://monkeyseedocg.github.io.", "paper_summary_zh": "<paragraph>\u9274\u4e8e\u6269\u6563\u6a21\u578b\u5728\u8fd0\u52a8\u5408\u6210\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6210\u679c\uff0c\u4e00\u4e2a\u81ea\u7136\u800c\u7136\u7684\u95ee\u9898\u51fa\u73b0\u4e86\uff1a\u6211\u4eec\u5982\u4f55\u6709\u6548\u5730\u5229\u7528\u8fd9\u4e9b\u6a21\u578b\u8fdb\u884c\u8fd0\u52a8\u7f16\u8f91\uff1f\u73b0\u6709\u7684\u57fa\u4e8e\u6269\u6563\u7684\u8fd0\u52a8\u7f16\u8f91\u65b9\u6cd5\u5ffd\u7565\u4e86\u9884\u8bad\u7ec3\u6a21\u578b\u6743\u91cd\u4e2d\u5d4c\u5165\u7684\u5148\u9a8c\u7684\u5de8\u5927\u6f5c\u529b\uff0c\u800c\u8fd9\u4f7f\u5f97\u64cd\u7eb5\u6f5c\u5728\u7279\u5f81\u7a7a\u95f4\u6210\u4e3a\u53ef\u80fd\uff1b\u56e0\u6b64\uff0c\u5b83\u4eec\u4e3b\u8981\u96c6\u4e2d\u4e8e\u5904\u7406\u8fd0\u52a8\u7a7a\u95f4\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u63a2\u7d22\u4e86\u9884\u8bad\u7ec3\u8fd0\u52a8\u6269\u6563\u6a21\u578b\u7684\u6ce8\u610f\u529b\u673a\u5236\u3002\u6211\u4eec\u63ed\u793a\u4e86\u6ce8\u610f\u529b\u5143\u7d20\u5728\u6355\u6349\u548c\u8868\u793a\u590d\u6742\u7684\u4eba\u7c7b\u8fd0\u52a8\u6a21\u5f0f\u4e2d\u7684\u4f5c\u7528\u548c\u4ea4\u4e92\uff0c\u5e76\u4ed4\u7ec6\u6574\u5408\u8fd9\u4e9b\u5143\u7d20\uff0c\u5c06\u4e00\u4e2a\u5f15\u5bfc\u8005\u7684\u8fd0\u52a8\u8f6c\u79fb\u7ed9\u4e00\u4e2a\u8ddf\u968f\u8005\uff0c\u540c\u65f6\u4fdd\u6301\u8ddf\u968f\u8005\u7684\u7ec6\u5fae\u7279\u5f81\uff0c\u4ece\u800c\u5b9e\u73b0\u96f6\u6b21\u8fd0\u52a8\u8f6c\u79fb\u3002\u7f16\u8f91\u4e0e\u6240\u9009\u52a8\u4f5c\u76f8\u5173\u7684\u7279\u5f81\u4f7f\u6211\u4eec\u80fd\u591f\u5e94\u5bf9\u5148\u524d\u8fd0\u52a8\u6269\u6563\u65b9\u6cd5\u4e2d\u89c2\u5bdf\u5230\u7684\u4e00\u4e2a\u6311\u6218\uff0c\u8be5\u65b9\u6cd5\u4f7f\u7528\u4e00\u822c\u6307\u4ee4\uff08\u4f8b\u5982\uff0c\u6587\u672c\u3001\u97f3\u4e50\uff09\u8fdb\u884c\u7f16\u8f91\uff0c\u6700\u7ec8\u65e0\u6cd5\u6709\u6548\u4f20\u8fbe\u5fae\u5999\u7684\u7ec6\u5fae\u5dee\u522b\u3002\u6211\u4eec\u7684\u5de5\u4f5c\u7075\u611f\u6765\u81ea\u4e8e\u7334\u5b50\u5728\u4fdd\u6301\u5176\u72ec\u7279\u8fd0\u52a8\u6a21\u5f0f\u7684\u540c\u65f6\u5bc6\u5207\u6a21\u4eff\u5b83\u6240\u770b\u5230\u7684\u4e1c\u897f\uff1b\u56e0\u6b64\uff0c\u6211\u4eec\u79f0\u4e4b\u4e3a Monkey See\uff0cMonkey Do\uff0c\u5e76\u79f0\u4e4b\u4e3a MoMo\u3002\u91c7\u7528\u6211\u4eec\u7684\u6280\u672f\u53ef\u4ee5\u5b8c\u6210\u8bf8\u5982\u5408\u6210\u5206\u5e03\u5916\u8fd0\u52a8\u3001\u98ce\u683c\u8fc1\u79fb\u548c\u7a7a\u95f4\u7f16\u8f91\u7b49\u4efb\u52a1\u3002\u6b64\u5916\uff0c\u6269\u6563\u53cd\u6f14\u5f88\u5c11\u7528\u4e8e\u8fd0\u52a8\uff1b\u56e0\u6b64\uff0c\u7f16\u8f91\u5de5\u4f5c\u96c6\u4e2d\u5728\u751f\u6210\u7684\u8fd0\u52a8\u4e0a\uff0c\u9650\u5236\u4e86\u771f\u5b9e\u8fd0\u52a8\u7684\u53ef\u7f16\u8f91\u6027\u3002MoMo \u5229\u7528\u8fd0\u52a8\u53cd\u6f14\uff0c\u5c06\u5176\u5e94\u7528\u6269\u5c55\u5230\u771f\u5b9e\u8fd0\u52a8\u548c\u751f\u6210\u8fd0\u52a8\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u4e86\u6211\u4eec\u7684\u65b9\u6cd5\u4f18\u4e8e\u5f53\u524d\u6280\u672f\u3002\u7279\u522b\u662f\uff0c\u4e0e\u901a\u8fc7\u8bad\u7ec3\u9488\u5bf9\u7279\u5b9a\u5e94\u7528\u7a0b\u5e8f\u7684\u65b9\u6cd5\u4e0d\u540c\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5e94\u7528\u4e8e\u63a8\u7406\u65f6\u95f4\uff0c\u4e0d\u9700\u8981\u8bad\u7ec3\u3002\u6211\u4eec\u7684\u7f51\u9875\u4f4d\u4e8e https://monkeyseedocg.github.io\u3002</paragraph>", "author": "Sigal Raab et.al.", "authors": "Sigal Raab, Inbar Gat, Nathan Sala, Guy Tevet, Rotem Shalev-Arkushin, Ohad Fried, Amit H. Bermano, Daniel Cohen-Or", "id": "2406.06508v1", "paper_url": "http://arxiv.org/abs/2406.06508v1", "repo": "https://github.com/monkeyseedocg/momo-code"}}