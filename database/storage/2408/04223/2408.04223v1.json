{"2408.04223": {"publish_time": "2024-08-08", "title": "VideoQA in the Era of LLMs: An Empirical Study", "paper_summary": "Video Large Language Models (Video-LLMs) are flourishing and has advanced\nmany video-language tasks. As a golden testbed, Video Question Answering\n(VideoQA) plays pivotal role in Video-LLM developing. This work conducts a\ntimely and comprehensive study of Video-LLMs' behavior in VideoQA, aiming to\nelucidate their success and failure modes, and provide insights towards more\nhuman-like video understanding and question answering. Our analyses demonstrate\nthat Video-LLMs excel in VideoQA; they can correlate contextual cues and\ngenerate plausible responses to questions about varied video contents. However,\nmodels falter in handling video temporality, both in reasoning about temporal\ncontent ordering and grounding QA-relevant temporal moments. Moreover, the\nmodels behave unintuitively - they are unresponsive to adversarial video\nperturbations while being sensitive to simple variations of candidate answers\nand questions. Also, they do not necessarily generalize better. The findings\ndemonstrate Video-LLMs' QA capability in standard condition yet highlight their\nsevere deficiency in robustness and interpretability, suggesting the urgent\nneed on rationales in Video-LLM developing.", "paper_summary_zh": "\u5f71\u7247\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08Video-LLM\uff09\u84ec\u52c3\u767c\u5c55\uff0c\u4e26\u63d0\u5347\u4e86\u8a31\u591a\u5f71\u7247\u8a9e\u8a00\u4efb\u52d9\u3002\u5f71\u7247\u554f\u7b54\uff08VideoQA\uff09\u4f5c\u70ba\u4e00\u500b\u9ec3\u91d1\u6e2c\u8a66\u5e73\u53f0\uff0c\u5728 Video-LLM \u7684\u767c\u5c55\u4e2d\u626e\u6f14\u8457\u8209\u8db3\u8f15\u91cd\u7684\u89d2\u8272\u3002\u9019\u9805\u5de5\u4f5c\u5c0d Video-LLM \u5728 VideoQA \u4e2d\u7684\u884c\u70ba\u9032\u884c\u53ca\u6642\u4e14\u5168\u9762\u7684\u7814\u7a76\uff0c\u65e8\u5728\u95e1\u660e\u5b83\u5011\u7684\u6210\u529f\u8207\u5931\u6557\u6a21\u5f0f\uff0c\u4e26\u63d0\u4f9b\u6d1e\u898b\u4ee5\u671d\u5411\u66f4\u985e\u4f3c\u4eba\u985e\u7684\u5f71\u7247\u7406\u89e3\u548c\u554f\u984c\u89e3\u7b54\u3002\u6211\u5011\u7684\u5206\u6790\u8b49\u660e Video-LLM \u5728 VideoQA \u4e2d\u8868\u73fe\u51fa\u8272\uff1b\u5b83\u5011\u53ef\u4ee5\u95dc\u806f\u8108\u7d61\u7dda\u7d22\uff0c\u4e26\u5c0d\u5404\u7a2e\u5f71\u7247\u5167\u5bb9\u7684\u554f\u984c\u7522\u751f\u5408\u7406\u7684\u56de\u61c9\u3002\u7136\u800c\uff0c\u6a21\u578b\u5728\u8655\u7406\u5f71\u7247\u6642\u9593\u6027\u65b9\u9762\u8868\u73fe\u4e0d\u4f73\uff0c\u7121\u8ad6\u662f\u5728\u63a8\u8ad6\u6642\u9593\u5167\u5bb9\u6392\u5e8f\uff0c\u9084\u662f\u5efa\u7acb\u8207 QA \u76f8\u95dc\u7684\u6642\u9593\u9ede\u65b9\u9762\u3002\u6b64\u5916\uff0c\u9019\u4e9b\u6a21\u578b\u7684\u884c\u70ba\u4e0d\u76f4\u89c0\u2014\u2014\u5b83\u5011\u5c0d\u5c0d\u6297\u6027\u5f71\u7247\u64fe\u52d5\u6c92\u6709\u53cd\u61c9\uff0c\u4f46\u5c0d\u5019\u9078\u7b54\u6848\u548c\u554f\u984c\u7684\u7c21\u55ae\u8b8a\u5316\u5f88\u654f\u611f\u3002\u6b64\u5916\uff0c\u5b83\u5011\u4e0d\u4e00\u5b9a\u80fd\u9032\u884c\u66f4\u597d\u7684\u6982\u62ec\u3002\u9019\u4e9b\u767c\u73fe\u8b49\u660e\u4e86 Video-LLM \u5728\u6a19\u6e96\u689d\u4ef6\u4e0b\u7684 QA \u80fd\u529b\uff0c\u4f46\u4e5f\u7a81\u51fa\u4e86\u5b83\u5011\u5728\u7a69\u5065\u6027\u548c\u53ef\u89e3\u91cb\u6027\u65b9\u9762\u7684\u56b4\u91cd\u4e0d\u8db3\uff0c\u9019\u8868\u660e\u5728 Video-LLM \u958b\u767c\u4e2d\u8feb\u5207\u9700\u8981\u4f9d\u64da\u3002", "author": "Junbin Xiao et.al.", "authors": "Junbin Xiao, Nanxin Huang, Hangyu Qin, Dongyang Li, Yicong Li, Fengbin Zhu, Zhulin Tao, Jianxing Yu, Liang Lin, Tat-Seng Chua, Angela Yao", "id": "2408.04223v1", "paper_url": "http://arxiv.org/abs/2408.04223v1", "repo": "null"}}