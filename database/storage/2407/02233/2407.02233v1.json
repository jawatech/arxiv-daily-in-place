{"2407.02233": {"publish_time": "2024-07-02", "title": "Synthetic Multimodal Question Generation", "paper_summary": "Multimodal Retrieval Augmented Generation (MMRAG) is a powerful approach to\nquestion-answering over multimodal documents. A key challenge with evaluating\nMMRAG is the paucity of high-quality datasets matching the question styles and\nmodalities of interest. In light of this, we propose SMMQG, a synthetic data\ngeneration framework. SMMQG leverages interplay between a retriever, large\nlanguage model (LLM) and large multimodal model (LMM) to generate question and\nanswer pairs directly from multimodal documents, with the questions conforming\nto specified styles and modalities. We use SMMQG to generate an MMRAG dataset\nof 1024 questions over Wikipedia documents and evaluate state-of-the-art models\nusing it, revealing insights into model performance that are attainable only\nthrough style- and modality-specific evaluation data. Next, we measure the\nquality of data produced by SMMQG via a human study. We find that the quality\nof our synthetic data is on par with the quality of the crowdsourced benchmark\nMMQA and that downstream evaluation results using both datasets strongly\nconcur.", "paper_summary_zh": "\u591a\u6a21\u6001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08MMRAG\uff09\u662f\u4e00\u79cd\u9488\u5bf9\u591a\u6a21\u6001\u6587\u6863\u8fdb\u884c\u95ee\u7b54\u7684\u5f3a\u5927\u65b9\u6cd5\u3002MMRAG \u8bc4\u4f30\u7684\u4e00\u4e2a\u4e3b\u8981\u6311\u6218\u662f\u7f3a\u4e4f\u4e0e\u95ee\u9898\u6837\u5f0f\u548c\u611f\u5174\u8da3\u6a21\u5f0f\u76f8\u5339\u914d\u7684\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u3002\u6709\u9274\u4e8e\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 SMMQG\uff0c\u4e00\u79cd\u5408\u6210\u6570\u636e\u751f\u6210\u6846\u67b6\u3002SMMQG \u5229\u7528\u68c0\u7d22\u5668\u3001\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u548c\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b (LMM) \u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u76f4\u63a5\u4ece\u591a\u6a21\u6001\u6587\u6863\u4e2d\u751f\u6210\u95ee\u9898\u548c\u7b54\u6848\u5bf9\uff0c\u5176\u4e2d\u95ee\u9898\u7b26\u5408\u6307\u5b9a\u7684\u6837\u5f0f\u548c\u6a21\u5f0f\u3002\u6211\u4eec\u4f7f\u7528 SMMQG \u751f\u6210\u4e00\u4e2a\u5305\u542b 1024 \u4e2a\u95ee\u9898\u7684 MMRAG \u6570\u636e\u96c6\uff0c\u8fd9\u4e9b\u95ee\u9898\u6765\u81ea\u7ef4\u57fa\u767e\u79d1\u6587\u6863\uff0c\u5e76\u4f7f\u7528\u8be5\u6570\u636e\u96c6\u8bc4\u4f30\u6700\u5148\u8fdb\u7684\u6a21\u578b\uff0c\u63ed\u793a\u4e86\u53ea\u6709\u901a\u8fc7\u7279\u5b9a\u4e8e\u6837\u5f0f\u548c\u6a21\u5f0f\u7684\u8bc4\u4f30\u6570\u636e\u624d\u80fd\u83b7\u5f97\u7684\u6a21\u578b\u6027\u80fd\u89c1\u89e3\u3002\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u901a\u8fc7\u4e00\u9879\u4eba\u4e3a\u7814\u7a76\u6765\u8861\u91cf SMMQG \u751f\u6210\u7684\u6570\u636e\u8d28\u91cf\u3002\u6211\u4eec\u53d1\u73b0\u6211\u4eec\u5408\u6210\u6570\u636e\u7684\u8d28\u91cf\u4e0e\u4f17\u5305\u57fa\u51c6 MMQA \u7684\u8d28\u91cf\u76f8\u5f53\uff0c\u5e76\u4e14\u4f7f\u7528\u4e24\u4e2a\u6570\u636e\u96c6\u7684\u4e0b\u6e38\u8bc4\u4f30\u7ed3\u679c\u5f3a\u70c8\u4e00\u81f4\u3002", "author": "Ian Wu et.al.", "authors": "Ian Wu, Sravan Jayanthi, Vijay Viswanathan, Simon Rosenberg, Sina Pakazad, Tongshuang Wu, Graham Neubig", "id": "2407.02233v1", "paper_url": "http://arxiv.org/abs/2407.02233v1", "repo": "null"}}