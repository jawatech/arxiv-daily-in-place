{"2407.11855": {"publish_time": "2024-07-16", "title": "Scaling Sign Language Translation", "paper_summary": "Sign language translation (SLT) addresses the problem of translating\ninformation from a sign language in video to a spoken language in text.\nExisting studies, while showing progress, are often limited to narrow domains\nand/or few sign languages and struggle with open-domain tasks. In this paper,\nwe push forward the frontier of SLT by scaling pretraining data, model size,\nand number of translation directions. We perform large-scale SLT pretraining on\ndifferent data including 1) noisy multilingual YouTube SLT data, 2) parallel\ntext corpora, and 3) SLT data augmented by translating video captions to other\nlanguages with off-the-shelf machine translation models. We unify different\npretraining tasks with task-specific prompts under the encoder-decoder\narchitecture, and initialize the SLT model with pretrained (m/By)T5 models\nacross model sizes. SLT pretraining results on How2Sign and FLEURS-ASL#0 (ASL\nto 42 spoken languages) demonstrate the significance of data/model scaling and\ncross-lingual cross-modal transfer, as well as the feasibility of zero-shot\nSLT. We finetune the pretrained SLT models on 5 downstream open-domain SLT\nbenchmarks covering 5 sign languages. Experiments show substantial quality\nimprovements over the vanilla baselines, surpassing the previous\nstate-of-the-art (SOTA) by wide margins.", "paper_summary_zh": "\u624b\u8a9e\u7ffb\u8b6f (SLT) \u89e3\u6c7a\u4e86\u5c07\u5f71\u7247\u4e2d\u7684\u624b\u8a9e\u8cc7\u8a0a\u7ffb\u8b6f\u6210\u6587\u5b57\u4e2d\u7684\u53e3\u8a9e\u554f\u984c\u3002\u73fe\u6709\u7814\u7a76\u96d6\u7136\u986f\u793a\u9032\u5c55\uff0c\u4f46\u901a\u5e38\u50c5\u9650\u65bc\u72f9\u7a84\u7684\u9818\u57df\u548c/\u6216\u5c11\u6578\u624b\u8a9e\uff0c\u4e14\u96e3\u4ee5\u61c9\u4ed8\u958b\u653e\u9818\u57df\u4efb\u52d9\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u900f\u904e\u64f4\u5145\u9810\u8a13\u7df4\u8cc7\u6599\u3001\u6a21\u578b\u5927\u5c0f\u548c\u7ffb\u8b6f\u65b9\u5411\u6578\u91cf\uff0c\u63a8\u52d5 SLT \u7684\u524d\u6cbf\u3002\u6211\u5011\u5c0d\u4e0d\u540c\u8cc7\u6599\u57f7\u884c\u5927\u898f\u6a21 SLT \u9810\u8a13\u7df4\uff0c\u5176\u4e2d\u5305\u62ec 1) \u5608\u96dc\u7684\u591a\u8a9e\u8a00 YouTube SLT \u8cc7\u6599\u30012) \u5e73\u884c\u6587\u5b57\u8a9e\u6599\u5eab\uff0c\u4ee5\u53ca 3) \u900f\u904e\u4f7f\u7528\u73fe\u6210\u7684\u6a5f\u5668\u7ffb\u8b6f\u6a21\u578b\u5c07\u5f71\u7247\u5b57\u5e55\u7ffb\u8b6f\u6210\u5176\u4ed6\u8a9e\u8a00\u800c\u64f4\u5145\u7684 SLT \u8cc7\u6599\u3002\u6211\u5011\u5728\u7de8\u78bc\u5668-\u89e3\u78bc\u5668\u67b6\u69cb\u4e0b\uff0c\u4f7f\u7528\u7279\u5b9a\u65bc\u4efb\u52d9\u7684\u63d0\u793a\u7d71\u4e00\u4e0d\u540c\u7684\u9810\u8a13\u7df4\u4efb\u52d9\uff0c\u4e26\u4f7f\u7528\u8de8\u6a21\u578b\u5927\u5c0f\u7684\u9810\u8a13\u7df4 (m/By)T5 \u6a21\u578b\u521d\u59cb\u5316 SLT \u6a21\u578b\u3002How2Sign \u548c FLEURS-ASL#0 (ASL \u5230 42 \u7a2e\u53e3\u8a9e) \u4e0a\u7684 SLT \u9810\u8a13\u7df4\u7d50\u679c\u8b49\u660e\u4e86\u8cc7\u6599/\u6a21\u578b\u64f4\u5145\u548c\u8de8\u8a9e\u8a00\u8de8\u6a21\u5f0f\u8f49\u79fb\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u53ca\u96f6\u6b21\u5b78\u7fd2 SLT \u7684\u53ef\u884c\u6027\u3002\u6211\u5011\u5fae\u8abf\u9810\u8a13\u7df4\u7684 SLT \u6a21\u578b\uff0c\u91dd\u5c0d\u6db5\u84cb 5 \u7a2e\u624b\u8a9e\u7684 5 \u500b\u4e0b\u6e38\u958b\u653e\u9818\u57df SLT \u8a55\u91cf\u6a19\u6e96\u9032\u884c\u5fae\u8abf\u3002\u5be6\u9a57\u986f\u793a\uff0c\u8207\u9999\u8349\u57fa\u7dda\u76f8\u6bd4\u6709\u986f\u8457\u7684\u54c1\u8cea\u63d0\u5347\uff0c\u5927\u5e45\u8d85\u8d8a\u5148\u524d\u7684\u6280\u8853\u6c34\u6e96 (SOTA)\u3002", "author": "Biao Zhang et.al.", "authors": "Biao Zhang, Garrett Tanzer, Orhan Firat", "id": "2407.11855v1", "paper_url": "http://arxiv.org/abs/2407.11855v1", "repo": "null"}}