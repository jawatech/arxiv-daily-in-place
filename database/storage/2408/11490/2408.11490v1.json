{"2408.11490": {"publish_time": "2024-08-21", "title": "DocTabQA: Answering Questions from Long Documents Using Tables", "paper_summary": "We study a new problem setting of question answering (QA), referred to as\nDocTabQA. Within this setting, given a long document, the goal is to respond to\nquestions by organizing the answers into structured tables derived directly\nfrom the document's content. Unlike traditional QA approaches which\npredominantly rely on unstructured text to formulate responses, DocTabQA aims\nto leverage structured tables as answers to convey information clearly and\nsystematically, thereby enhancing user comprehension and highlighting\nrelationships between data points. To the best of our knowledge, this problem\nhas not been previously explored. In this paper, we introduce the QTabA\ndataset, encompassing 300 financial documents, accompanied by manually\nannotated 1.5k question-table pairs. Initially, we leverage Large Language\nModels (LLMs) such as GPT-4 to establish a baseline. However, it is widely\nacknowledged that LLMs encounter difficulties when tasked with generating\nintricate, structured outputs from long input sequences. To overcome these\nchallenges, we present a two-stage framework, called DocTabTalk, which\ninitially retrieves relevant sentences from extensive documents and\nsubsequently generates hierarchical tables based on these identified sentences.\nDocTabTalk incorporates two key technological innovations: AlignLLaMA and\nTabTalk, which are specifically tailored to assist GPT-4 in tackling DocTabQA,\nenabling it to generate well-structured, hierarchical tables with improved\norganization and clarity. Comprehensive experimental evaluations conducted on\nboth QTabA and RotoWire datasets demonstrate that our DocTabTalk significantly\nenhances the performances of the GPT-4 in our proposed DocTabQA task and the\ntable generation task. The code and dataset are available at\nhttps://github.com/SmileWHC/DocTabQA for further research.", "paper_summary_zh": "<paragraph>\u6211\u5011\u7814\u7a76\u4e86\u4e00\u500b\u65b0\u7684\u554f\u984c\u8a2d\u5b9a\uff0c\u5373\u554f\u7b54\uff08QA\uff09\uff0c\u7a31\u70ba DocTabQA\u3002\u5728\u6b64\u8a2d\u5b9a\u4e2d\uff0c\u7d66\u5b9a\u4e00\u500b\u9577\u6587\u6a94\uff0c\u76ee\u6a19\u662f\u901a\u904e\u5c07\u7b54\u6848\u7d44\u7e54\u6210\u76f4\u63a5\u5f9e\u6587\u6a94\u5167\u5bb9\u4e2d\u5f97\u51fa\u7684\u7d50\u69cb\u5316\u8868\u683c\u4f86\u56de\u7b54\u554f\u984c\u3002\u8207\u50b3\u7d71\u7684 QA \u65b9\u6cd5\u4e0d\u540c\uff0c\u50b3\u7d71\u7684 QA \u65b9\u6cd5\u4e3b\u8981\u4f9d\u8cf4\u975e\u7d50\u69cb\u5316\u6587\u672c\u4f86\u5236\u5b9a\u56de\u61c9\uff0c\u800c DocTabQA \u65e8\u5728\u5229\u7528\u7d50\u69cb\u5316\u8868\u683c\u4f5c\u70ba\u7b54\u6848\u4f86\u6e05\u6670\u7cfb\u7d71\u5730\u50b3\u9054\u4fe1\u606f\uff0c\u5f9e\u800c\u589e\u5f37\u7528\u6236\u7406\u89e3\u4e26\u7a81\u51fa\u6578\u64da\u9ede\u4e4b\u9593\u7684\u95dc\u4fc2\u3002\u64da\u6211\u5011\u6240\u77e5\uff0c\u9019\u500b\u554f\u984c\u4ee5\u524d\u6c92\u6709\u88ab\u63a2\u7d22\u904e\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 QTabA \u6578\u64da\u96c6\uff0c\u5176\u4e2d\u5305\u542b 300 \u4efd\u8ca1\u52d9\u6587\u4ef6\uff0c\u4e26\u9644\u6709\u624b\u52d5\u8a3b\u91cb\u7684 1.5k \u500b\u554f\u984c\u8868\u5c0d\u3002\u6700\u521d\uff0c\u6211\u5011\u5229\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)\uff0c\u4f8b\u5982 GPT-4 \u4f86\u5efa\u7acb\u57fa\u6e96\u3002\u7136\u800c\uff0c\u4eba\u5011\u666e\u904d\u8a8d\u70ba\uff0cLLM \u5728\u5f9e\u9577\u8f38\u5165\u5e8f\u5217\u751f\u6210\u8907\u96dc\u7684\u7d50\u69cb\u5316\u8f38\u51fa\u6642\u6703\u9047\u5230\u56f0\u96e3\u3002\u70ba\u4e86\u514b\u670d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u7a31\u70ba DocTabTalk \u7684\u5169\u968e\u6bb5\u6846\u67b6\uff0c\u8a72\u6846\u67b6\u6700\u521d\u5f9e\u5ee3\u6cdb\u7684\u6587\u6a94\u4e2d\u6aa2\u7d22\u76f8\u95dc\u53e5\u5b50\uff0c\u7136\u5f8c\u6839\u64da\u9019\u4e9b\u5df2\u8b58\u5225\u7684\u53e5\u5b50\u751f\u6210\u5206\u5c64\u8868\u683c\u3002DocTabTalk \u7d50\u5408\u4e86\u5169\u9805\u95dc\u9375\u6280\u8853\u5275\u65b0\uff1aAlignLLaMA \u548c TabTalk\uff0c\u5b83\u5011\u5c08\u9580\u5b9a\u5236\u70ba\u5354\u52a9 GPT-4 \u8655\u7406 DocTabQA\uff0c\u4f7f\u5176\u80fd\u5920\u751f\u6210\u7d50\u69cb\u826f\u597d\u3001\u5206\u5c64\u6e05\u6670\u4e14\u7d44\u7e54\u6027\u66f4\u5f37\u7684\u8868\u683c\u3002\u5728 QTabA \u548c RotoWire \u6578\u64da\u96c6\u4e0a\u9032\u884c\u7684\u7d9c\u5408\u5be6\u9a57\u8a55\u4f30\u8868\u660e\uff0c\u6211\u5011\u7684 DocTabTalk \u5728\u6211\u5011\u63d0\u51fa\u7684 DocTabQA \u4efb\u52d9\u548c\u8868\u683c\u751f\u6210\u4efb\u52d9\u4e2d\u986f\u8457\u63d0\u5347\u4e86 GPT-4 \u7684\u6027\u80fd\u3002\u4ee3\u78bc\u548c\u6578\u64da\u96c6\u53ef\u5728 https://github.com/SmileWHC/DocTabQA \u4e0a\u7372\u5f97\uff0c\u4ee5\u4f9b\u9032\u4e00\u6b65\u7814\u7a76\u3002</paragraph>", "author": "Haochen Wang et.al.", "authors": "Haochen Wang, Kai Hu, Haoyu Dong, Liangcai Gao", "id": "2408.11490v1", "paper_url": "http://arxiv.org/abs/2408.11490v1", "repo": "null"}}