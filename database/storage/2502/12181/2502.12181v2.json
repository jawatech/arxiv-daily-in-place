{"2502.12181": {"publish_time": "2025-02-14", "title": "3D ReX: Causal Explanations in 3D Neuroimaging Classification", "paper_summary": "Explainability remains a significant problem for AI models in medical\nimaging, making it challenging for clinicians to trust AI-driven predictions.\nWe introduce 3D ReX, the first causality-based post-hoc explainability tool for\n3D models. 3D ReX uses the theory of actual causality to generate\nresponsibility maps which highlight the regions most crucial to the model's\ndecision. We test 3D ReX on a stroke detection model, providing insight into\nthe spatial distribution of features relevant to stroke.", "paper_summary_zh": "<paragraph>\u53ef\u89e3\u91cb\u6027\u4ecd\u7136\u662f\u91ab\u5b78\u5f71\u50cf\u4e2d AI \u6a21\u578b\u7684\u4e00\u500b\u91cd\u5927\u554f\u984c\uff0c\u9019\u4f7f\u5f97\u81e8\u5e8a\u91ab\u751f\u96e3\u4ee5\u4fe1\u4efb AI \u9a45\u52d5\u7684\u9810\u6e2c\u3002\u6211\u5011\u4ecb\u7d39 3D ReX\uff0c\u9019\u662f\u7b2c\u4e00\u500b\u57fa\u65bc\u56e0\u679c\u95dc\u4fc2\u7684 3D \u6a21\u578b\u4e8b\u5f8c\u53ef\u89e3\u91cb\u6027\u5de5\u5177\u30023D ReX \u4f7f\u7528\u5be6\u969b\u56e0\u679c\u95dc\u4fc2\u7406\u8ad6\u4f86\u751f\u6210\u8cac\u4efb\u5716\uff0c\u7a81\u51fa\u986f\u793a\u5c0d\u6a21\u578b\u6c7a\u7b56\u6700\u91cd\u8981\u7684\u5340\u57df\u3002\u6211\u5011\u5728\u4e2d\u98a8\u6aa2\u6e2c\u6a21\u578b\u4e0a\u6e2c\u8a66\u4e86 3D ReX\uff0c\u63d0\u4f9b\u4e86\u8207\u4e2d\u98a8\u76f8\u95dc\u7684\u7279\u5fb5\u7a7a\u9593\u5206\u4f48\u7684\u6d1e\u5bdf\u3002</paragraph>\n", "author": "Melane Navaratnarajah et.al.", "authors": "Melane Navaratnarajah, Sophie A. Martin, David A. Kelly, Nathan Blake, Hana Chockler", "id": "2502.12181v2", "paper_url": "http://arxiv.org/abs/2502.12181v2", "repo": "null"}}