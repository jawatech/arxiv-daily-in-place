{"2405.02750": {"publish_time": "2024-05-04", "title": "Enhancing Contextual Understanding in Large Language Models through Contrastive Decoding", "paper_summary": "Large language models (LLMs) tend to inadequately integrate input context\nduring text generation, relying excessively on encoded prior knowledge in model\nparameters, potentially resulting in generated text with factual\ninconsistencies or contextually unfaithful content. LLMs utilize two primary\nknowledge sources: 1) prior (parametric) knowledge from pretraining, and 2)\ncontextual (non-parametric) knowledge from input prompts. The study addresses\nthe open question of how LLMs effectively balance these knowledge sources\nduring the generation process, specifically in the context of open-domain\nquestion answering. To address this issue, we introduce a novel approach\nintegrating contrastive decoding with adversarial irrelevant passages as\nnegative samples to enhance robust context grounding during generation.\nNotably, our method operates at inference time without requiring further\ntraining. We conduct comprehensive experiments to demonstrate its applicability\nand effectiveness, providing empirical evidence showcasing its superiority over\nexisting methodologies. Our code is publicly available at:\nhttps://github.com/amazon-science/ContextualUnderstanding-ContrastiveDecoding.", "paper_summary_zh": "", "author": "Zheng Zhao et.al.", "authors": "Zheng Zhao,Emilio Monti,Jens Lehmann,Haytham Assem", "id": "2405.02750v1", "paper_url": "http://arxiv.org/abs/2405.02750v1", "repo": "https://github.com/amazon-science/contextualunderstanding-contrastivedecoding"}}