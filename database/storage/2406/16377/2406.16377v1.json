{"2406.16377": {"publish_time": "2024-06-24", "title": "On the Transformations across Reward Model, Parameter Update, and In-Context Prompt", "paper_summary": "Despite the general capabilities of pre-trained large language models (LLMs),\nthey still need further adaptation to better serve practical applications. In\nthis paper, we demonstrate the interchangeability of three popular and distinct\nadaptation tools: parameter updating, reward modeling, and in-context\nprompting. This interchangeability establishes a triangular framework with six\ntransformation directions, each of which facilitates a variety of applications.\nOur work offers a holistic view that unifies numerous existing studies and\nsuggests potential research directions. We envision our work as a useful\nroadmap for future research on LLMs.", "paper_summary_zh": "\u5118\u7ba1\u9810\u5148\u8a13\u7df4\u7684\u5927\u8a9e\u8a00\u6a21\u578b (LLM) \u5177\u6709\u666e\u904d\u529f\u80fd\uff0c\n\u5b83\u5011\u4ecd\u9700\u8981\u9032\u4e00\u6b65\u8abf\u6574\u624d\u80fd\u66f4\u597d\u5730\u670d\u52d9\u65bc\u5be6\u969b\u61c9\u7528\u3002\u5728\n\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5c55\u793a\u4e86\u4e09\u500b\u6d41\u884c\u4e14\u4e0d\u540c\u7684\u8abf\u6574\u5de5\u5177\u7684\u53ef\u4e92\u63db\u6027\uff1a\u53c3\u6578\u66f4\u65b0\u3001\u734e\u52f5\u5efa\u6a21\u548c\u60c5\u5883\u5167\n\u63d0\u793a\u3002\u9019\u7a2e\u53ef\u4e92\u63db\u6027\u5efa\u7acb\u4e86\u4e00\u500b\u4e09\u89d2\u5f62\u6846\u67b6\uff0c\u5176\u4e2d\u5305\u542b\u516d\u500b\u8f49\u63db\u65b9\u5411\uff0c\u6bcf\u500b\u65b9\u5411\u90fd\u4fc3\u9032\u4e86\u5404\u7a2e\u61c9\u7528\u3002\n\u6211\u5011\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u500b\u6574\u9ad4\u89c0\u9ede\uff0c\u7d71\u4e00\u4e86\u8a31\u591a\u73fe\u6709\u7814\u7a76\uff0c\n\u4e26\u63d0\u51fa\u4e86\u6f5b\u5728\u7684\u7814\u7a76\u65b9\u5411\u3002\u6211\u5011\u5c07\u6211\u5011\u7684\u7814\u7a76\u8996\u70ba\u672a\u4f86 LLM \u7814\u7a76\u7684\u6709\u7528\u8def\u7dda\u5716\u3002", "author": "Deng Cai et.al.", "authors": "Deng Cai, Huayang Li, Tingchen Fu, Siheng Li, Weiwen Xu, Shuaiyi Li, Bowen Cao, Zhisong Zhang, Xinting Huang, Leyang Cui, Yan Wang, Lemao Liu, Taro Watanabe, Shuming Shi", "id": "2406.16377v1", "paper_url": "http://arxiv.org/abs/2406.16377v1", "repo": "null"}}