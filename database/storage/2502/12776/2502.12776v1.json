{"2502.12776": {"publish_time": "2025-02-18", "title": "Portable Reward Tuning: Towards Reusable Fine-Tuning across Different Pretrained Models", "paper_summary": "While foundation models have been exploited for various expert tasks through\nfine-tuning, any foundation model will become outdated due to its old knowledge\nor limited capability. Thus the underlying foundation model should be\neventually replaced by new ones, which leads to repeated cost of fine-tuning\nthese new models. Existing work addresses this problem by inference-time\ntuning, i.e., modifying the output probabilities from the new foundation model\nwith the outputs from the old foundation model and its fine-tuned model, which\ninvolves an additional overhead in inference by the latter two models. In this\npaper, we propose a new fine-tuning principle, Portable Reward Tuning (PRT),\nthat reduces the inference overhead by its nature, based on the reformulation\nof fine-tuning as the reward maximization. Specifically, instead of fine-tuning\nparameters of the foundation models, PRT trains the reward model explicitly\nthrough the same loss function as in fine-tuning. During inference, the reward\nmodel can be used with any foundation model (with the same set of vocabularies\nor labels) through the formulation of reward maximization. Experimental\nresults, covering both vision and language models, demonstrate that the\nPRT-trained model can achieve comparable accuracy to the existing work of\ninference-time tuning, with less inference cost.", "paper_summary_zh": "\u5118\u7ba1\u57fa\u790e\u6a21\u578b\u5df2\u900f\u904e\u5fae\u8abf\u7528\u65bc\u5404\u7a2e\u5c08\u5bb6\u4efb\u52d9\uff0c\u4efb\u4f55\u57fa\u790e\u6a21\u578b\u90fd\u5c07\u56e0\u5176\u820a\u77e5\u8b58\u6216\u6709\u9650\u529f\u80fd\u800c\u904e\u6642\u3002\u56e0\u6b64\uff0c\u57fa\u790e\u6a21\u578b\u6700\u7d42\u61c9\u7531\u65b0\u6a21\u578b\u53d6\u4ee3\uff0c\u9019\u5c0e\u81f4\u91cd\u8907\u5fae\u8abf\u9019\u4e9b\u65b0\u6a21\u578b\u7684\u6210\u672c\u3002\u73fe\u6709\u5de5\u4f5c\u900f\u904e\u63a8\u8ad6\u6642\u9593\u8abf\u6574\u4f86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u5373\u4f7f\u7528\u820a\u57fa\u790e\u6a21\u578b\u53ca\u5176\u5fae\u8abf\u6a21\u578b\u7684\u8f38\u51fa\u4fee\u6539\u65b0\u57fa\u790e\u6a21\u578b\u7684\u8f38\u51fa\u6a5f\u7387\uff0c\u9019\u6d89\u53ca\u5f8c\u5169\u500b\u6a21\u578b\u5728\u63a8\u8ad6\u4e2d\u7684\u984d\u5916\u958b\u92b7\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u65b0\u7684\u5fae\u8abf\u539f\u5247\uff0c\u53ef\u651c\u5f0f\u734e\u52f5\u8abf\u6574 (PRT)\uff0c\u5b83\u672c\u8cea\u4e0a\u6703\u6e1b\u5c11\u63a8\u8ad6\u958b\u92b7\uff0c\u57fa\u65bc\u5c07\u5fae\u8abf\u91cd\u65b0\u8868\u8ff0\u70ba\u734e\u52f5\u6700\u5927\u5316\u3002\u5177\u9ad4\u4f86\u8aaa\uff0cPRT \u4e0d\u662f\u5fae\u8abf\u57fa\u790e\u6a21\u578b\u7684\u53c3\u6578\uff0c\u800c\u662f\u900f\u904e\u8207\u5fae\u8abf\u4e2d\u76f8\u540c\u7684\u640d\u5931\u51fd\u6578\u660e\u78ba\u8a13\u7df4\u734e\u52f5\u6a21\u578b\u3002\u5728\u63a8\u8ad6\u671f\u9593\uff0c\u734e\u52f5\u6a21\u578b\u53ef\u900f\u904e\u734e\u52f5\u6700\u5927\u5316\u7684\u516c\u5f0f\u8207\u4efb\u4f55\u57fa\u790e\u6a21\u578b\uff08\u5177\u6709\u76f8\u540c\u7684\u8a5e\u5f59\u6216\u6a19\u7c64\u7d44\uff09\u4e00\u8d77\u4f7f\u7528\u3002\u6db5\u84cb\u8996\u89ba\u548c\u8a9e\u8a00\u6a21\u578b\u7684\u5be6\u9a57\u7d50\u679c\u8b49\u660e\uff0cPRT \u8a13\u7df4\u7684\u6a21\u578b\u53ef\u4ee5\u9054\u5230\u8207\u73fe\u6709\u63a8\u8ad6\u6642\u9593\u8abf\u6574\u5de5\u4f5c\u76f8\u7576\u7684\u6e96\u78ba\u5ea6\uff0c\u4e14\u63a8\u8ad6\u6210\u672c\u8f03\u4f4e\u3002", "author": "Daiki Chijiwa et.al.", "authors": "Daiki Chijiwa, Taku Hasegawa, Kyosuke Nishida, Kuniko Saito, Susumu Takeuchi", "id": "2502.12776v1", "paper_url": "http://arxiv.org/abs/2502.12776v1", "repo": "null"}}