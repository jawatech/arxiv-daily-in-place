{"2408.01156": {"publish_time": "2024-08-02", "title": "TCR-GPT: Integrating Autoregressive Model and Reinforcement Learning for T-Cell Receptor Repertoires Generation", "paper_summary": "T-cell receptors (TCRs) play a crucial role in the immune system by\nrecognizing and binding to specific antigens presented by infected or cancerous\ncells. Understanding the sequence patterns of TCRs is essential for developing\ntargeted immune therapies and designing effective vaccines. Language models,\nsuch as auto-regressive transformers, offer a powerful solution to this problem\nby learning the probability distributions of TCR repertoires, enabling the\ngeneration of new TCR sequences that inherit the underlying patterns of the\nrepertoire. We introduce TCR-GPT, a probabilistic model built on a decoder-only\ntransformer architecture, designed to uncover and replicate sequence patterns\nin TCR repertoires. TCR-GPT demonstrates an accuracy of 0.953 in inferring\nsequence probability distributions measured by Pearson correlation coefficient.\nFurthermore, by leveraging Reinforcement Learning(RL), we adapted the\ndistribution of TCR sequences to generate TCRs capable of recognizing specific\npeptides, offering significant potential for advancing targeted immune\ntherapies and vaccine development. With the efficacy of RL, fine-tuned\npretrained TCR-GPT models demonstrated the ability to produce TCR repertoires\nlikely to bind specific peptides, illustrating RL's efficiency in enhancing the\nmodel's adaptability to the probability distributions of biologically relevant\nTCR sequences.", "paper_summary_zh": "T \u7d30\u80de\u53d7\u9ad4 (TCR) \u5728\u514d\u75ab\u7cfb\u7d71\u4e2d\u626e\u6f14\u8457\u81f3\u95dc\u91cd\u8981\u7684\u89d2\u8272\uff0c\n\u900f\u904e\u8fa8\u8b58\u4e26\u7d50\u5408\u53d7\u611f\u67d3\u6216\u764c\u7d30\u80de\u5448\u73fe\u51fa\u7684\u7279\u5b9a\u6297\u539f\u3002\u4e86\u89e3 TCR \u7684\u5e8f\u5217\u6a21\u5f0f\u5c0d\u65bc\u958b\u767c\u6a19\u9776\u514d\u75ab\u7642\u6cd5\u548c\u8a2d\u8a08\u6709\u6548\u75ab\u82d7\u81f3\u95dc\u91cd\u8981\u3002\u8a9e\u8a00\u6a21\u578b\uff0c\n\u4f8b\u5982\u81ea\u8ff4\u6b78\u8f49\u63db\u5668\uff0c\u63d0\u4f9b\u4e86\u4e00\u500b\u5f37\u5927\u7684\u89e3\u6c7a\u65b9\u6848\u4f86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\n\u900f\u904e\u5b78\u7fd2 TCR \u5eab\u7684\u6a5f\u7387\u5206\u4f48\uff0c\u80fd\u5920\u7522\u751f\u7e7c\u627f\u5eab\u4e2d\u6f5b\u5728\u6a21\u5f0f\u7684\u65b0 TCR \u5e8f\u5217\u3002\u6211\u5011\u5f15\u9032 TCR-GPT\uff0c\u4e00\u500b\u5efa\u7acb\u5728\u50c5\u89e3\u78bc\u5668\u8f49\u63db\u5668\u67b6\u69cb\u4e0a\u7684\u6a5f\u7387\u6a21\u578b\uff0c\u65e8\u5728\u63ed\u793a\u548c\u8907\u88fd TCR \u5eab\u4e2d\u7684\u5e8f\u5217\u6a21\u5f0f\u3002TCR-GPT \u5728\u63a8\u8ad6\u5e8f\u5217\u6a5f\u7387\u5206\u4f48\u6642\u5c55\u73fe\u51fa 0.953 \u7684\u6e96\u78ba\u5ea6\uff0c\u900f\u904e\u76ae\u723e\u68ee\u76f8\u95dc\u4fc2\u6578\u6e2c\u91cf\u3002\u6b64\u5916\uff0c\u900f\u904e\u5229\u7528\u5f37\u5316\u5b78\u7fd2 (RL)\uff0c\u6211\u5011\u8abf\u6574\u4e86 TCR \u5e8f\u5217\u7684\u5206\u914d\uff0c\u4ee5\u7522\u751f\u80fd\u5920\u8fa8\u8b58\u7279\u5b9a\u80dc\u80bd\u7684 TCR\uff0c\u70ba\u6a19\u9776\u514d\u75ab\u7642\u6cd5\u548c\u75ab\u82d7\u958b\u767c\u7684\u9032\u6b65\u63d0\u4f9b\u4e86\u986f\u8457\u7684\u6f5b\u529b\u3002\u900f\u904e RL \u7684\u529f\u6548\uff0c\u5fae\u8abf\u5f8c\u7684\u9810\u8a13\u7df4 TCR-GPT \u6a21\u578b\u5c55\u73fe\u51fa\u7522\u751f\u53ef\u80fd\u7d50\u5408\u7279\u5b9a\u80dc\u80bd\u7684 TCR \u5eab\u7684\u80fd\u529b\uff0c\u8aaa\u660e\u4e86 RL \u5728\u589e\u5f37\u6a21\u578b\u5c0d\u751f\u7269\u76f8\u95dc TCR \u5e8f\u5217\u6a5f\u7387\u5206\u4f48\u7684\u9069\u61c9\u6027\u65b9\u9762\u7684\u6548\u7387\u3002", "author": "Yicheng Lin et.al.", "authors": "Yicheng Lin, Dandan Zhang, Yun Liu", "id": "2408.01156v1", "paper_url": "http://arxiv.org/abs/2408.01156v1", "repo": "null"}}