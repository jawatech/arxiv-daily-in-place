{"2404.19296": {"publish_time": "2024-04-30", "title": "Octopus v4: Graph of language models", "paper_summary": "Language models have been effective in a wide range of applications, yet the\nmost sophisticated models are often proprietary. For example, GPT-4 by OpenAI\nand various models by Anthropic are expensive and consume substantial energy.\nIn contrast, the open-source community has produced competitive models, like\nLlama3. Furthermore, niche-specific smaller language models, such as those\ntailored for legal, medical or financial tasks, have outperformed their\nproprietary counterparts. This paper introduces a novel approach that employs\n\\textit{functional tokens} to integrate \\textbf{multiple open-source models},\neach optimized for particular tasks. Our newly developed Octopus v4 model\nleverages \\textit{functional tokens} to intelligently direct user queries to\nthe most appropriate vertical model and reformat the query to achieve the best\nperformance. Octopus v4, an evolution of the Octopus v1, v2, and v3 models,\nexcels in selection and parameter understanding and reformatting. Additionally,\nwe explore the use of graph as a versatile data structure that effectively\ncoordinates multiple open-source models by harnessing the capabilities of the\nOctopus model and \\textit{functional tokens}. Use our open-sourced GitHub\n(\\url{https://www.nexa4ai.com/}) to try Octopus v4 models\n(\\url{https://huggingface.co/NexaAIDev/Octopus-v4}), and contrite to a larger\ngraph of language models. By activating models less than 10B parameters, we\nachieved SOTA MMLU score of 74.8 among the same level models.", "paper_summary_zh": "\u8a9e\u8a00\u6a21\u578b\u5728\u5ee3\u6cdb\u7684\u61c9\u7528\u4e2d\u975e\u5e38\u6709\u6548\uff0c\u4f46\u6700\u7cbe\u5bc6\u7684\u6a21\u578b\u901a\u5e38\u662f\u5c08\u6709\u7684\u3002\u4f8b\u5982\uff0cOpenAI \u7684 GPT-4 \u548c Anthropic \u7684\u5404\u7a2e\u6a21\u578b\u50f9\u683c\u6602\u8cb4\u4e14\u6d88\u8017\u5927\u91cf\u80fd\u6e90\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u958b\u6e90\u793e\u7fa4\u5df2\u7d93\u7522\u51fa\u5177\u6709\u7af6\u722d\u529b\u7684\u6a21\u578b\uff0c\u4f8b\u5982 Llama3\u3002\u6b64\u5916\uff0c\u91dd\u5c0d\u7279\u5b9a\u9818\u57df\u7684\u5c0f\u578b\u8a9e\u8a00\u6a21\u578b\uff0c\u4f8b\u5982\u70ba\u6cd5\u5f8b\u3001\u91ab\u7642\u6216\u8ca1\u52d9\u4efb\u52d9\u91cf\u8eab\u6253\u9020\u7684\u6a21\u578b\uff0c\u5df2\u7d93\u8d85\u8d8a\u4e86\u5b83\u5011\u7684\u5c08\u6709\u5c0d\u61c9\u6a21\u578b\u3002\u672c\u6587\u4ecb\u7d39\u4e00\u7a2e\u65b0\u65b9\u6cd5\uff0c\u5b83\u63a1\u7528\u300c\u529f\u80fd\u6027\u6a19\u8a18\u300d\u4f86\u6574\u5408\u300c\u591a\u500b\u958b\u6e90\u6a21\u578b\u300d\uff0c\u6bcf\u500b\u6a21\u578b\u90fd\u91dd\u5c0d\u7279\u5b9a\u4efb\u52d9\u9032\u884c\u6700\u4f73\u5316\u3002\u6211\u5011\u65b0\u958b\u767c\u7684 Octopus v4 \u6a21\u578b\u5229\u7528\u300c\u529f\u80fd\u6027\u6a19\u8a18\u300d\u5c07\u4f7f\u7528\u8005\u67e5\u8a62\u667a\u80fd\u5c0e\u5411\u6700\u5408\u9069\u7684\u5782\u76f4\u6a21\u578b\uff0c\u4e26\u91cd\u65b0\u683c\u5f0f\u5316\u67e5\u8a62\u4ee5\u9054\u6210\u6700\u4f73\u6548\u80fd\u3002Octopus v4 \u662f Octopus v1\u3001v2 \u548c v3 \u6a21\u578b\u7684\u9032\u5316\u7248\u672c\uff0c\u5728\u9078\u64c7\u3001\u53c3\u6578\u7406\u89e3\u548c\u91cd\u65b0\u683c\u5f0f\u5316\u65b9\u9762\u8868\u73fe\u512a\u7570\u3002\u6b64\u5916\uff0c\u6211\u5011\u63a2\u8a0e\u5c07\u5716\u5f62\u7528\u4f5c\u901a\u7528\u8cc7\u6599\u7d50\u69cb\uff0c\u5b83\u900f\u904e\u5229\u7528 Octopus \u6a21\u578b\u548c\u300c\u529f\u80fd\u6027\u6a19\u8a18\u300d\u7684\u80fd\u529b\uff0c\u6709\u6548\u5730\u5354\u8abf\u591a\u500b\u958b\u6e90\u6a21\u578b\u3002\u4f7f\u7528\u6211\u5011\u7684\u958b\u6e90 GitHub (\\url{https://www.nexa4ai.com/}) \u4f86\u8a66\u7528 Octopus v4 \u6a21\u578b (\\url{https://huggingface.co/NexaAIDev/Octopus-v4})\uff0c\u4e26\u70ba\u66f4\u5927\u7684\u8a9e\u8a00\u6a21\u578b\u5716\u5f62\u505a\u51fa\u8ca2\u737b\u3002\u900f\u904e\u555f\u7528\u53c3\u6578\u5c0f\u65bc 10B \u7684\u6a21\u578b\uff0c\u6211\u5011\u5728\u540c\u7d1a\u5225\u6a21\u578b\u4e2d\u9054\u5230\u4e86 74.8 \u7684 SOTA MMLU \u5206\u6578\u3002", "author": "Wei Chen et.al.", "authors": "Wei Chen, Zhiyuan Li", "id": "2404.19296v1", "paper_url": "http://arxiv.org/abs/2404.19296v1", "repo": "null"}}