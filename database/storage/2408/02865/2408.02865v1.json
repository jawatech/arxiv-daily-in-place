{"2408.02865": {"publish_time": "2024-08-05", "title": "VisionUnite: A Vision-Language Foundation Model for Ophthalmology Enhanced with Clinical Knowledge", "paper_summary": "The need for improved diagnostic methods in ophthalmology is acute,\nespecially in the less developed regions with limited access to specialists and\nadvanced equipment. Therefore, we introduce VisionUnite, a novel\nvision-language foundation model for ophthalmology enhanced with clinical\nknowledge. VisionUnite has been pretrained on an extensive dataset comprising\n1.24 million image-text pairs, and further refined using our proposed MMFundus\ndataset, which includes 296,379 high-quality fundus image-text pairs and\n889,137 simulated doctor-patient dialogue instances. Our experiments indicate\nthat VisionUnite outperforms existing generative foundation models such as\nGPT-4V and Gemini Pro. It also demonstrates diagnostic capabilities comparable\nto junior ophthalmologists. VisionUnite performs well in various clinical\nscenarios including open-ended multi-disease diagnosis, clinical explanation,\nand patient interaction, making it a highly versatile tool for initial\nophthalmic disease screening. VisionUnite can also serve as an educational aid\nfor junior ophthalmologists, accelerating their acquisition of knowledge\nregarding both common and rare ophthalmic conditions. VisionUnite represents a\nsignificant advancement in ophthalmology, with broad implications for\ndiagnostics, medical education, and understanding of disease mechanisms.", "paper_summary_zh": "\u773c\u79d1\u8a3a\u65b7\u65b9\u6cd5\u6539\u826f\u7684\u5fc5\u8981\u6027\u5341\u5206\u8feb\u5207\uff0c\u7279\u5225\u662f\u5728\u8f03\u4e0d\u767c\u9054\u5730\u5340\uff0c\u90a3\u88e1\u5c08\u79d1\u91ab\u5e2b\u548c\u5148\u9032\u8a2d\u5099\u53d6\u5f97\u4e0d\u6613\u3002\u56e0\u6b64\uff0c\u6211\u5011\u5f15\u9032 VisionUnite\uff0c\u4e00\u7a2e\u65b0\u7a4e\u7684\u8996\u89ba\u8a9e\u8a00\u57fa\u790e\u6a21\u578b\uff0c\u4e26\u4ee5\u81e8\u5e8a\u77e5\u8b58\u5f37\u5316\u773c\u79d1\u3002VisionUnite \u5df2\u5728\u5305\u542b 124 \u842c\u5f35\u5f71\u50cf\u6587\u5b57\u5c0d\u7684\u5927\u578b\u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u9810\u8a13\u7df4\uff0c\u4e26\u900f\u904e\u6211\u5011\u5efa\u8b70\u7684 MMFundus \u8cc7\u6599\u96c6\u9032\u4e00\u6b65\u512a\u5316\uff0c\u5176\u4e2d\u5305\u542b 296,379 \u5f35\u9ad8\u54c1\u8cea\u773c\u5e95\u5f71\u50cf\u6587\u5b57\u5c0d\u548c 889,137 \u500b\u6a21\u64ec\u7684\u91ab\u5e2b\u75c5\u60a3\u5c0d\u8a71\u5be6\u4f8b\u3002\u6211\u5011\u7684\u5be6\u9a57\u6307\u51fa VisionUnite \u512a\u65bc\u73fe\u6709\u7684\u751f\u6210\u5f0f\u57fa\u790e\u6a21\u578b\uff0c\u4f8b\u5982 GPT-4V \u548c Gemini Pro\u3002\u5b83\u4e5f\u5c55\u73fe\u51fa\u8207\u521d\u968e\u773c\u79d1\u91ab\u5e2b\u76f8\u7576\u7684\u8a3a\u65b7\u80fd\u529b\u3002VisionUnite \u5728\u5404\u7a2e\u81e8\u5e8a\u60c5\u5883\u4e2d\u8868\u73fe\u826f\u597d\uff0c\u5305\u62ec\u958b\u653e\u5f0f\u591a\u75be\u75c5\u8a3a\u65b7\u3001\u81e8\u5e8a\u8aaa\u660e\u548c\u75c5\u60a3\u4e92\u52d5\uff0c\u4f7f\u5176\u6210\u70ba\u521d\u6b65\u773c\u79d1\u75be\u75c5\u7be9\u6aa2\u7684\u9ad8\u5ea6\u591a\u529f\u80fd\u5de5\u5177\u3002VisionUnite \u4e5f\u53ef\u7528\u4f5c\u521d\u968e\u773c\u79d1\u91ab\u5e2b\u7684\u6559\u80b2\u8f14\u52a9\u5de5\u5177\uff0c\u52a0\u901f\u4ed6\u5011\u5c0d\u65bc\u5e38\u898b\u548c\u7f55\u898b\u773c\u79d1\u75be\u75c5\u77e5\u8b58\u7684\u7fd2\u5f97\u3002VisionUnite \u4ee3\u8868\u4e86\u773c\u79d1\u7684\u91cd\u5927\u9032\u5c55\uff0c\u5c0d\u8a3a\u65b7\u3001\u91ab\u5b78\u6559\u80b2\u548c\u75be\u75c5\u6a5f\u8f49\u7684\u7406\u89e3\u5177\u6709\u5ee3\u6cdb\u7684\u5f71\u97ff\u3002", "author": "Zihan Li et.al.", "authors": "Zihan Li, Diping Song, Zefeng Yang, Deming Wang, Fei Li, Xiulan Zhang, Paul E. Kinahan, Yu Qiao", "id": "2408.02865v1", "paper_url": "http://arxiv.org/abs/2408.02865v1", "repo": "null"}}