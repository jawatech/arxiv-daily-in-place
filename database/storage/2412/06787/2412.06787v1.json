{"2412.06787": {"publish_time": "2024-12-09", "title": "[MASK] is All You Need", "paper_summary": "In generative models, two paradigms have gained attraction in various\napplications: next-set prediction-based Masked Generative Models and next-noise\nprediction-based Non-Autoregressive Models, e.g., Diffusion Models. In this\nwork, we propose using discrete-state models to connect them and explore their\nscalability in the vision domain. First, we conduct a step-by-step analysis in\na unified design space across two types of models including\ntimestep-independence, noise schedule, temperature, guidance strength, etc in a\nscalable manner. Second, we re-cast typical discriminative tasks, e.g., image\nsegmentation, as an unmasking process from [MASK]tokens on a discrete-state\nmodel. This enables us to perform various sampling processes, including\nflexible conditional sampling by only training once to model the joint\ndistribution. All aforementioned explorations lead to our framework named\nDiscrete Interpolants, which enables us to achieve state-of-the-art or\ncompetitive performance compared to previous discrete-state based methods in\nvarious benchmarks, like ImageNet256, MS COCO, and video dataset FaceForensics.\nIn summary, by leveraging [MASK] in discrete-state models, we can bridge Masked\nGenerative and Non-autoregressive Diffusion models, as well as generative and\ndiscriminative tasks.", "paper_summary_zh": "\u5728\u751f\u6210\u6a21\u578b\u4e2d\uff0c\u6709\u5169\u7a2e\u7bc4\u4f8b\u5728\u5404\u7a2e\u61c9\u7528\u7a0b\u5f0f\u4e2d\u7372\u5f97\u95dc\u6ce8\uff1a\u57fa\u65bc\u4e0b\u4e00\u500b\u96c6\u5408\u9810\u6e2c\u7684\u906e\u7f69\u751f\u6210\u6a21\u578b\u548c\u57fa\u65bc\u4e0b\u4e00\u500b\u96dc\u8a0a\u9810\u6e2c\u7684\u975e\u81ea\u8ff4\u6b78\u6a21\u578b\uff0c\u4f8b\u5982\u64f4\u6563\u6a21\u578b\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5efa\u8b70\u4f7f\u7528\u96e2\u6563\u72c0\u614b\u6a21\u578b\u5c07\u5b83\u5011\u9023\u63a5\u8d77\u4f86\uff0c\u4e26\u63a2\u7d22\u5b83\u5011\u5728\u8996\u89ba\u9818\u57df\u7684\u53ef\u64f4\u5145\u6027\u3002\u9996\u5148\uff0c\u6211\u5011\u5728\u4e00\u500b\u7d71\u4e00\u7684\u8a2d\u8a08\u7a7a\u9593\u4e2d\u5c0d\u5169\u7a2e\u6a21\u578b\u985e\u578b\u9032\u884c\u9010\u6b65\u5206\u6790\uff0c\u5305\u62ec\u6642\u9593\u6b65\u9577\u7368\u7acb\u6027\u3001\u96dc\u8a0a\u6392\u7a0b\u3001\u6eab\u5ea6\u3001\u5f15\u5c0e\u5f37\u5ea6\u7b49\uff0c\u4e26\u4ee5\u53ef\u64f4\u5145\u7684\u65b9\u5f0f\u9032\u884c\u3002\u5176\u6b21\uff0c\u6211\u5011\u5c07\u5178\u578b\u7684\u5340\u5206\u4efb\u52d9\uff08\u4f8b\u5982\u5f71\u50cf\u5206\u5272\uff09\u91cd\u65b0\u8f49\u63db\u70ba\u96e2\u6563\u72c0\u614b\u6a21\u578b\u4e0a [MASK] \u4ee4\u724c\u7684\u53d6\u6d88\u906e\u7f69\u7a0b\u5e8f\u3002\u9019\u4f7f\u6211\u5011\u80fd\u5920\u57f7\u884c\u5404\u7a2e\u62bd\u6a23\u7a0b\u5e8f\uff0c\u5305\u62ec\u50c5\u900f\u904e\u8a13\u7df4\u4e00\u6b21\u4f86\u5efa\u6a21\u806f\u5408\u5206\u914d\u7684\u5f48\u6027\u689d\u4ef6\u62bd\u6a23\u3002\u6240\u6709\u4e0a\u8ff0\u63a2\u8a0e\u90fd\u5c0e\u81f4\u6211\u5011\u67b6\u69cb\u7a31\u70ba\u96e2\u6563\u5167\u63d2\uff0c\u5b83\u4f7f\u6211\u5011\u80fd\u5920\u5728\u5404\u7a2e\u57fa\u6e96\u4e2d\uff08\u4f8b\u5982 ImageNet256\u3001MS COCO \u548c\u5f71\u7247\u8cc7\u6599\u96c6 FaceForensics\uff09\u5be6\u73fe\u8207\u5148\u524d\u57fa\u65bc\u96e2\u6563\u72c0\u614b\u7684\u65b9\u6cd5\u76f8\u6bd4\u6700\u5148\u9032\u6216\u6709\u7af6\u722d\u529b\u7684\u6548\u80fd\u3002\u7e3d\u4e4b\uff0c\u900f\u904e\u5229\u7528\u96e2\u6563\u72c0\u614b\u6a21\u578b\u4e2d\u7684 [MASK]\uff0c\u6211\u5011\u53ef\u4ee5\u6a4b\u63a5\u906e\u7f69\u751f\u6210\u548c\u975e\u81ea\u8ff4\u6b78\u64f4\u6563\u6a21\u578b\uff0c\u4ee5\u53ca\u751f\u6210\u548c\u5340\u5206\u4efb\u52d9\u3002", "author": "Vincent Tao Hu et.al.", "authors": "Vincent Tao Hu, Bj\u00f6rn Ommer", "id": "2412.06787v1", "paper_url": "http://arxiv.org/abs/2412.06787v1", "repo": "null"}}