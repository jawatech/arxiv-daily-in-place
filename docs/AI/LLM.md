
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-06**|**Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?**|Daniel P. Jeong et.al.|[2411.04118v1](http://arxiv.org/abs/2411.04118v1)|null|
|**2024-11-06**|**Fed-EC: Bandwidth-Efficient Clustering-Based Federated Learning For Autonomous Visual Robot Navigation**|Shreya Gummadi et.al.|[2411.04112v1](http://arxiv.org/abs/2411.04112v1)|null|
|**2024-11-06**|**Self-Consistency Preference Optimization**|Archiki Prasad et.al.|[2411.04109v1](http://arxiv.org/abs/2411.04109v1)|null|
|**2024-11-06**|**How Transformers Solve Propositional Logic Problems: A Mechanistic Analysis**|Guan Zhe Hong et.al.|[2411.04105v1](http://arxiv.org/abs/2411.04105v1)|null|
|**2024-11-06**|**RaVL: Discovering and Mitigating Spurious Correlations in Fine-Tuned Vision-Language Models**|Maya Varma et.al.|[2411.04097v1](http://arxiv.org/abs/2411.04097v1)|[link](https://github.com/stanford-aimi/ravl)|
|**2024-11-06**|**Summarization of Opinionated Political Documents with Varied Perspectives**|Nicholas Deas et.al.|[2411.04093v1](http://arxiv.org/abs/2411.04093v1)|null|
|**2024-11-06**|**A Collaborative Content Moderation Framework for Toxicity Detection based on Conformalized Estimates of Annotation Disagreement**|Guillermo Villate-Castillo et.al.|[2411.04090v1](http://arxiv.org/abs/2411.04090v1)|[link](https://github.com/themrguiller/collaborative-content-moderation)|
|**2024-11-06**|**M3SciQA: A Multi-Modal Multi-Document Scientific QA Benchmark for Evaluating Foundation Models**|Chuhan Li et.al.|[2411.04075v1](http://arxiv.org/abs/2411.04075v1)|null|
|**2024-11-06**|**Non-Stationary Learning of Neural Networks with Automatic Soft Parameter Reset**|Alexandre Galashov et.al.|[2411.04034v1](http://arxiv.org/abs/2411.04034v1)|null|
|**2024-11-06**|**Beemo: Benchmark of Expert-edited Machine-generated Outputs**|Ekaterina Artemova et.al.|[2411.04032v1](http://arxiv.org/abs/2411.04032v1)|null|
|**2024-11-06**|**Prompt Engineering Using GPT for Word-Level Code-Mixed Language Identification in Low-Resource Dravidian Languages**|Aniket Deroy et.al.|[2411.04025v1](http://arxiv.org/abs/2411.04025v1)|null|
|**2024-11-06**|**Predicting and Publishing Accurate Imbalance Prices Using Monte Carlo Tree Search**|Fabio Pavirani et.al.|[2411.04011v1](http://arxiv.org/abs/2411.04011v1)|null|
|**2024-11-06**|**Aligning Characteristic Descriptors with Images for Human-Expert-like Explainability**|Bharat Chandra Yalavarthi et.al.|[2411.04008v1](http://arxiv.org/abs/2411.04008v1)|null|
|**2024-11-06**|**Select2Plan: Training-Free ICL-Based Planning through VQA and Memory Retrieval**|Davide Buoso et.al.|[2411.04006v1](http://arxiv.org/abs/2411.04006v1)|null|
|**2024-11-06**|**Towards Resource-Efficient Federated Learning in Industrial IoT for Multivariate Time Series Analysis**|Alexandros Gkillas et.al.|[2411.03996v1](http://arxiv.org/abs/2411.03996v1)|null|
|**2024-11-06**|**WorryWords: Norms of Anxiety Association for over 44k English Words**|Saif M. Mohammad et.al.|[2411.03966v1](http://arxiv.org/abs/2411.03966v1)|null|
|**2024-11-06**|**What Really is Commonsense Knowledge?**|Quyet V. Do et.al.|[2411.03964v1](http://arxiv.org/abs/2411.03964v1)|null|
|**2024-11-06**|**How Does A Text Preprocessing Pipeline Affect Ontology Syntactic Matching?**|Zhangcheng Qiang et.al.|[2411.03962v1](http://arxiv.org/abs/2411.03962v1)|null|
|**2024-11-06**|**Energy Score-based Pseudo-Label Filtering and Adaptive Loss for Imbalanced Semi-supervised SAR target recognition**|Xinzheng Zhang et.al.|[2411.03959v1](http://arxiv.org/abs/2411.03959v1)|null|
|**2024-11-06**|**Fine-Grained Guidance for Retrievers: Leveraging LLMs' Feedback in Retrieval-Augmented Generation**|Yuhang Liu et.al.|[2411.03957v1](http://arxiv.org/abs/2411.03957v1)|null|
|**2024-11-06**|**Long-Form Text-to-Music Generation with Adaptive Prompts: A Case of Study in Tabletop Role-Playing Games Soundtracks**|Felipe Marra et.al.|[2411.03948v1](http://arxiv.org/abs/2411.03948v1)|null|
|**2024-11-06**|**Can Custom Models Learn In-Context? An Exploration of Hybrid Architecture Performance on In-Context Learning Tasks**|Ryan Campbell et.al.|[2411.03945v1](http://arxiv.org/abs/2411.03945v1)|null|
|**2024-11-06**|**Fine-tuning -- a Transfer Learning approach**|Joseph Arul Raj et.al.|[2411.03941v1](http://arxiv.org/abs/2411.03941v1)|null|
|**2024-11-06**|**Interactions Across Blocks in Post-Training Quantization of Large Language Models**|Khasmamad Shabanovi et.al.|[2411.03934v1](http://arxiv.org/abs/2411.03934v1)|null|
|**2024-11-06**|**Evaluation data contamination in LLMs: how do we measure it and (when) does it matter?**|Aaditya K. Singh et.al.|[2411.03923v1](http://arxiv.org/abs/2411.03923v1)|null|
|**2024-11-06**|**RAGulator: Lightweight Out-of-Context Detectors for Grounded Text Generation**|Ian Poey et.al.|[2411.03920v1](http://arxiv.org/abs/2411.03920v1)|null|
|**2024-11-06**|**Lexicalization Is All You Need: Examining the Impact of Lexical Knowledge in a Compositional QALD System**|David Maria Schmidt et.al.|[2411.03906v1](http://arxiv.org/abs/2411.03906v1)|null|
|**2024-11-06**|**Computational Analysis of Gender Depiction in the Comedias of Calder√≥n de la Barca**|Allison Keith et.al.|[2411.03895v1](http://arxiv.org/abs/2411.03895v1)|null|
|**2024-11-06**|**Multi3Hate: Multimodal, Multilingual, and Multicultural Hate Speech Detection with Vision-Language Models**|Minh Duc Bui et.al.|[2411.03888v1](http://arxiv.org/abs/2411.03888v1)|[link](https://github.com/minhducbui/multi3hate)|
|**2024-11-06**|**Polynomial Composition Activations: Unleashing the Dynamics of Large Language Models**|Zhijian Zhuo et.al.|[2411.03884v1](http://arxiv.org/abs/2411.03884v1)|null|
|**2024-11-06**|**MEG: Medical Knowledge-Augmented Large Language Models for Question Answering**|Laura Cabello et.al.|[2411.03883v1](http://arxiv.org/abs/2411.03883v1)|[link](https://github.com/lautel/meg)|
|**2024-11-06**|**Performance evaluation of SLAM-ASR: The Good, the Bad, the Ugly, and the Way Forward**|Shashi Kumar et.al.|[2411.03866v1](http://arxiv.org/abs/2411.03866v1)|null|
|**2024-11-06**|**AdaSociety: An Adaptive Environment with Social Structures for Multi-Agent Decision-Making**|Yizhe Huang et.al.|[2411.03865v1](http://arxiv.org/abs/2411.03865v1)|[link](https://github.com/bigai-ai/adasociety)|
|**2024-11-06**|**ROBIN: Robust and Invisible Watermarks for Diffusion Models with Adversarial Optimization**|Huayang Huang et.al.|[2411.03862v1](http://arxiv.org/abs/2411.03862v1)|[link](https://github.com/hannah1102/robin)|
|**2024-11-06**|**UniTraj: Universal Human Trajectory Modeling from Billion-Scale Worldwide Traces**|Yuanshao Zhu et.al.|[2411.03859v1](http://arxiv.org/abs/2411.03859v1)|null|
|**2024-11-06**|**MambaPEFT: Exploring Parameter-Efficient Fine-Tuning for Mamba**|Masakazu Yoshimura et.al.|[2411.03855v1](http://arxiv.org/abs/2411.03855v1)|null|
|**2024-11-06**|**A Novel Access Control and Privacy-Enhancing Approach for Models in Edge Computing**|Peihao Li et.al.|[2411.03847v1](http://arxiv.org/abs/2411.03847v1)|null|
|**2024-11-06**|**Reconsidering the Performance of GAE in Link Prediction**|Weishuo Ma et.al.|[2411.03845v1](http://arxiv.org/abs/2411.03845v1)|[link](https://github.com/graphpku/refined-gae)|
|**2024-11-06**|**Both Text and Images Leaked! A Systematic Analysis of Multimodal LLM Data Contamination**|Dingjie Song et.al.|[2411.03823v1](http://arxiv.org/abs/2411.03823v1)|null|
|**2024-11-06**|**From Novice to Expert: LLM Agent Policy Optimization via Step-wise Reinforcement Learning**|Zhirui Deng et.al.|[2411.03817v1](http://arxiv.org/abs/2411.03817v1)|null|
|**2024-11-06**|**MRJ-Agent: An Effective Jailbreak Agent for Multi-Round Dialogue**|Fengxiang Wang et.al.|[2411.03814v1](http://arxiv.org/abs/2411.03814v1)|null|
|**2024-11-06**|**The natural stability of autonomous morphology**|Erich Round et.al.|[2411.03811v1](http://arxiv.org/abs/2411.03811v1)|null|
|**2024-11-06**|**GS2Pose: Tow-stage 6D Object Pose Estimation Guided by Gaussian Splatting**|Jilan Mei et.al.|[2411.03807v1](http://arxiv.org/abs/2411.03807v1)|null|
|**2024-11-06**|**Understanding the Effects of Human-written Paraphrases in LLM-generated Text Detection**|Hiu Ting Lau et.al.|[2411.03806v1](http://arxiv.org/abs/2411.03806v1)|null|
|**2024-11-06**|**A Comparative Study of Recent Large Language Models on Generating Hospital Discharge Summaries for Lung Cancer Patients**|Yiming Li et.al.|[2411.03805v1](http://arxiv.org/abs/2411.03805v1)|null|
|**2024-11-06**|**Overcoming label shift in targeted federated learning**|Edvin Listo Zec et.al.|[2411.03799v1](http://arxiv.org/abs/2411.03799v1)|null|
|**2024-11-06**|**VQA$^2$:Visual Question Answering for Video Quality Assessment**|Ziheng Jia et.al.|[2411.03795v1](http://arxiv.org/abs/2411.03795v1)|null|
|**2024-11-06**|**Navigating the landscape of multimodal AI in medicine: a scoping review on technical challenges and clinical applications**|Daan Schouten et.al.|[2411.03782v1](http://arxiv.org/abs/2411.03782v1)|null|
|**2024-11-06**|**No Culture Left Behind: ArtELingo-28, a Benchmark of WikiArt with Captions in 28 Languages**|Youssef Mohamed et.al.|[2411.03769v1](http://arxiv.org/abs/2411.03769v1)|null|
|**2024-11-06**|**Number Cookbook: Number Understanding of Language Models and How to Improve It**|Haotong Yang et.al.|[2411.03766v1](http://arxiv.org/abs/2411.03766v1)|[link](https://github.com/graphpku/number_cookbook)|
|**2024-11-06**|**Sub-DM:Subspace Diffusion Model with Orthogonal Decomposition for MRI Reconstruction**|Yu Guan et.al.|[2411.03758v1](http://arxiv.org/abs/2411.03758v1)|null|
|**2024-11-06**|**Optimal Defenses Against Gradient Reconstruction Attacks**|Yuxiao Chen et.al.|[2411.03746v1](http://arxiv.org/abs/2411.03746v1)|[link](https://github.com/cyx78/optimal_defenses_against_gradient_reconstruction_attacks)|
|**2024-11-06**|**Automating Exploratory Proteomics Research via Language Models**|Ning Ding et.al.|[2411.03743v1](http://arxiv.org/abs/2411.03743v1)|null|
|**2024-11-06**|**Adaptive Consensus Gradients Aggregation for Scaled Distributed Training**|Yoni Choukroun et.al.|[2411.03742v1](http://arxiv.org/abs/2411.03742v1)|null|
|**2024-11-06**|**Relation Learning and Aggregate-attention for Multi-person Motion Prediction**|Kehua Qu et.al.|[2411.03729v1](http://arxiv.org/abs/2411.03729v1)|null|
|**2024-11-06**|**PropNEAT -- Efficient GPU-Compatible Backpropagation over NeuroEvolutionary Augmenting Topology Networks**|Michael Merry et.al.|[2411.03726v1](http://arxiv.org/abs/2411.03726v1)|null|
|**2024-11-06**|**Fine-Tuning Vision-Language Model for Automated Engineering Drawing Information Extraction**|Muhammad Tayyab Khan et.al.|[2411.03707v1](http://arxiv.org/abs/2411.03707v1)|null|
|**2024-11-06**|**The Root Shapes the Fruit: On the Persistence of Gender-Exclusive Harms in Aligned Language Models**|Anaelia Ovalle et.al.|[2411.03700v1](http://arxiv.org/abs/2411.03700v1)|null|
|**2024-11-06**|**Beyond Model Adaptation at Test Time: A Survey**|Zehao Xiao et.al.|[2411.03687v1](http://arxiv.org/abs/2411.03687v1)|[link](https://github.com/zzzx1224/beyond-model-adaptation-at-test-time-papers)|
|**2024-11-06**|**QUILL: Quotation Generation Enhancement of Large Language Models**|Jin Xiao et.al.|[2411.03675v1](http://arxiv.org/abs/2411.03675v1)|[link](https://github.com/gracexiaoo/quill)|
|**2024-11-06**|**Towards 3D Semantic Scene Completion for Autonomous Driving: A Meta-Learning Framework Empowered by Deformable Large-Kernel Attention and Mamba Model**|Yansong Qu et.al.|[2411.03672v1](http://arxiv.org/abs/2411.03672v1)|null|
|**2024-11-06**|**Evaluating Moral Beliefs across LLMs through a Pluralistic Framework**|Xuelin Liu et.al.|[2411.03665v1](http://arxiv.org/abs/2411.03665v1)|[link](https://github.com/mumu-lily/moral-beliefs)|
|**2024-11-06**|**Deploying Multi-task Online Server with Large Language Model**|Yincen Qu et.al.|[2411.03644v1](http://arxiv.org/abs/2411.03644v1)|null|
|**2024-11-06**|**RTify: Aligning Deep Neural Networks with Human Behavioral Decisions**|Yu-Ang Cheng et.al.|[2411.03630v1](http://arxiv.org/abs/2411.03630v1)|null|
|**2024-11-06**|**StreamingBench: Assessing the Gap for MLLMs to Achieve Streaming Video Understanding**|Junming Lin et.al.|[2411.03628v1](http://arxiv.org/abs/2411.03628v1)|null|
|**2024-11-06**|**Fully Hyperbolic Rotation for Knowledge Graph Embedding**|Qiuyu Liang et.al.|[2411.03622v1](http://arxiv.org/abs/2411.03622v1)|null|
|**2024-11-06**|**Cross Feature Fusion of Fundus Image and Generated Lesion Map for Referable Diabetic Retinopathy Classification**|Dahyun Mok et.al.|[2411.03618v1](http://arxiv.org/abs/2411.03618v1)|null|
|**2024-11-06**|**From Medprompt to o1: Exploration of Run-Time Strategies for Medical Challenge Problems and Beyond**|Harsha Nori et.al.|[2411.03590v1](http://arxiv.org/abs/2411.03590v1)|null|
|**2024-11-06**|**An Experimental Study on Decomposition-Based Deep Ensemble Learning for Traffic Flow Forecasting**|Qiyuan Zhu et.al.|[2411.03588v1](http://arxiv.org/abs/2411.03588v1)|null|
|**2024-11-06**|**Towards Personalized Federated Learning via Comprehensive Knowledge Distillation**|Pengju Wang et.al.|[2411.03569v1](http://arxiv.org/abs/2411.03569v1)|null|
|**2024-11-06**|**The American Sign Language Knowledge Graph: Infusing ASL Models with Linguistic Knowledge**|Lee Kezar et.al.|[2411.03568v1](http://arxiv.org/abs/2411.03568v1)|null|
|**2024-11-05**|**Large Language Models Orchestrating Structured Reasoning Achieve Kaggle Grandmaster Level**|Antoine Grosnit et.al.|[2411.03562v1](http://arxiv.org/abs/2411.03562v1)|null|
|**2024-11-05**|**Learning to Write Rationally: How Information Is Distributed in Non-Native Speakers' Essays**|Zixin Tang et.al.|[2411.03550v1](http://arxiv.org/abs/2411.03550v1)|null|
|**2024-11-05**|**Exploring the Benefits of Domain-Pretraining of Generative Large Language Models for Chemistry**|Anurag Acharya et.al.|[2411.03542v1](http://arxiv.org/abs/2411.03542v1)|null|
|**2024-11-05**|**Long Context RAG Performance of Large Language Models**|Quinn Leng et.al.|[2411.03538v1](http://arxiv.org/abs/2411.03538v1)|null|
|**2024-11-05**|**Two-Stage Pretraining for Molecular Property Prediction in the Wild**|Kevin Tirta Wijaya et.al.|[2411.03537v1](http://arxiv.org/abs/2411.03537v1)|null|
|**2024-11-05**|**Personalized Video Summarization by Multimodal Video Understanding**|Brian Chen et.al.|[2411.03531v1](http://arxiv.org/abs/2411.03531v1)|null|
|**2024-11-05**|**Exploring the Potentials and Challenges of Using Large Language Models for the Analysis of Transcriptional Regulation of Long Non-coding RNAs**|Wei Wang et.al.|[2411.03522v1](http://arxiv.org/abs/2411.03522v1)|null|
|**2024-11-05**|**AI Metropolis: Scaling Large Language Model-based Multi-Agent Simulation with Out-of-order Execution**|Zhiqiang Xie et.al.|[2411.03519v1](http://arxiv.org/abs/2411.03519v1)|null|
|**2024-11-05**|**Change Is the Only Constant: Dynamic LLM Slicing based on Layer Redundancy**|Razvan-Gabriel Dumitru et.al.|[2411.03513v1](http://arxiv.org/abs/2411.03513v1)|[link](https://github.com/razvandu/dynamicslicing)|
|**2024-11-05**|**Uncertainty Quantification for Clinical Outcome Predictions with (Large) Language Models**|Zizhang Chen et.al.|[2411.03497v1](http://arxiv.org/abs/2411.03497v1)|null|
|**2024-11-05**|**Automatic Generation of Question Hints for Mathematics Problems using Large Language Models in Educational Technology**|Junior Cedric Tonga et.al.|[2411.03495v1](http://arxiv.org/abs/2411.03495v1)|null|
|**2024-11-05**|**LASER: Attention with Exponential Transformation**|Sai Surya Duvvuri et.al.|[2411.03493v1](http://arxiv.org/abs/2411.03493v1)|null|
|**2024-11-05**|**LLM Generated Distribution-Based Prediction of US Electoral Results, Part I**|Caleb Bradshaw et.al.|[2411.03486v1](http://arxiv.org/abs/2411.03486v1)|null|
|**2024-11-05**|**MetRex: A Benchmark for Verilog Code Metric Reasoning Using LLMs**|Manar Abdelatty et.al.|[2411.03471v1](http://arxiv.org/abs/2411.03471v1)|null|
|**2024-11-05**|**Watson: A Cognitive Observability Framework for the Reasoning of Foundation Model-Powered Agents**|Benjamin Rombaut et.al.|[2411.03455v1](http://arxiv.org/abs/2411.03455v1)|null|
|**2024-11-05**|**Solving Trojan Detection Competitions with Linear Weight Classification**|Todd Huster et.al.|[2411.03445v1](http://arxiv.org/abs/2411.03445v1)|null|
|**2024-11-05**|**MME-Finance: A Multimodal Finance Benchmark for Expert-level Understanding and Reasoning**|Ziliang Gan et.al.|[2411.03314v1](http://arxiv.org/abs/2411.03314v1)|null|
|**2024-11-05**|**Usefulness of LLMs as an Author Checklist Assistant for Scientific Papers: NeurIPS'24 Experiment**|Alexander Goldberg et.al.|[2411.03417v1](http://arxiv.org/abs/2411.03417v1)|null|
|**2024-11-05**|**Inference Optimal VLMs Need Only One Visual Token but Larger Models**|Kevin Y. Li et.al.|[2411.03312v1](http://arxiv.org/abs/2411.03312v1)|[link](https://github.com/locuslab/llava-token-compression)|
|**2024-11-05**|**STEER: Flexible Robotic Manipulation via Dense Language Grounding**|Laura Smith et.al.|[2411.03409v1](http://arxiv.org/abs/2411.03409v1)|null|
|**2024-11-05**|**SAUCE: Synchronous and Asynchronous User-Customizable Environment for Multi-Agent LLM Interaction**|Shlomo Neuberger et.al.|[2411.03397v1](http://arxiv.org/abs/2411.03397v1)|[link](https://github.com/deep-cognition-lab/sauce)|
|**2024-11-05**|**Exploring Large Language Models for Specialist-level Oncology Care**|Anil Palepu et.al.|[2411.03395v1](http://arxiv.org/abs/2411.03395v1)|null|
|**2024-11-05**|**Neurons for Neutrons: A Transformer Model for Computation Load Estimation on Domain-Decomposed Neutron Transport Problems**|Alexander Mote et.al.|[2411.03389v1](http://arxiv.org/abs/2411.03389v1)|null|
|**2024-11-05**|**LLMs for Domain Generation Algorithm Detection**|Reynier Leyva La O et.al.|[2411.03307v1](http://arxiv.org/abs/2411.03307v1)|null|
|**2024-11-05**|**VERITAS: A Unified Approach to Reliability Evaluation**|Rajkumar Ramamurthy et.al.|[2411.03300v1](http://arxiv.org/abs/2411.03300v1)|null|
|**2024-11-05**|**Interaction2Code: How Far Are We From Automatic Interactive Webpage Generation?**|Jingyu Xiao et.al.|[2411.03292v1](http://arxiv.org/abs/2411.03292v1)|null|
|**2024-11-05**|**The Future of Intelligent Healthcare: A Systematic Analysis and Discussion on the Integration and Impact of Robots Using Large Language Models for Healthcare**|Souren Pashangpour et.al.|[2411.03287v1](http://arxiv.org/abs/2411.03287v1)|null|
|**2024-11-05**|**SMoA: Improving Multi-agent Large Language Models with Sparse Mixture-of-Agents**|Dawei Li et.al.|[2411.03284v1](http://arxiv.org/abs/2411.03284v1)|[link](https://github.com/david-li0406/smoa)|
|**2024-11-05**|**Causal Responsibility Attribution for Human-AI Collaboration**|Yahang Qi et.al.|[2411.03275v1](http://arxiv.org/abs/2411.03275v1)|[link](https://github.com/yahang-qi/Causal-Attr-Human-AI)|

#### Abstracts
##### **Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?**
2411.04118v1 by Daniel P. Jeong, Saurabh Garg, Zachary C. Lipton, Michael Oberst

Several recent works seek to develop foundation models specifically for
medical applications, adapting general-purpose large language models (LLMs) and
vision-language models (VLMs) via continued pretraining on publicly available
biomedical corpora. These works typically claim that such domain-adaptive
pretraining (DAPT) improves performance on downstream medical tasks, such as
answering medical licensing exam questions. In this paper, we compare seven
public "medical" LLMs and two VLMs against their corresponding base models,
arriving at a different conclusion: all medical VLMs and nearly all medical
LLMs fail to consistently improve over their base models in the zero-/few-shot
prompting regime for medical question-answering (QA) tasks. For instance,
across the tasks and model pairs we consider in the 3-shot setting, medical
LLMs only outperform their base models in 12.1% of cases, reach a (statistical)
tie in 49.8% of cases, and are significantly worse than their base models in
the remaining 38.2% of cases. Our conclusions are based on (i) comparing each
medical model head-to-head, directly against the corresponding base model; (ii)
optimizing the prompts for each model separately; and (iii) accounting for
statistical uncertainty in comparisons. While these basic practices are not
consistently adopted in the literature, our ablations show that they
substantially impact conclusions. Our findings suggest that state-of-the-art
general-domain models may already exhibit strong medical knowledge and
reasoning capabilities, and offer recommendations to strengthen the conclusions
of future studies.

ÊëòË¶ÅÔºö<paragraph>ËøëÊúüÁöÑÂπæÈ†ÖÁ†îÁ©∂Ëá¥ÂäõÊñºÂ∞àÈñÄÈáùÂ∞çÈÜ´ÁôÇÊáâÁî®ÈñãÁôºÂü∫Á§éÊ®°ÂûãÔºåÈÄèÈÅéÂú®ÂÖ¨ÈñãÁöÑÁîüÁâ©ÈÜ´Â≠∏Ë™ûÊñôÂ∫´‰∏äÊåÅÁ∫åÈ†êË®ìÁ∑¥ÔºåË™øÊï¥ÈÄöÁî®ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM)„ÄÇÈÄô‰∫õÁ†îÁ©∂ÈÄöÂ∏∏ËÅ≤Á®±ÔºåÈÄôÁ®ÆÈ†òÂüüÈÅ©ÊáâÊÄßÈ†êË®ìÁ∑¥ (DAPT) ËÉΩÊîπÂñÑ‰∏ãÊ∏∏ÈÜ´ÁôÇ‰ªªÂãôÁöÑÊïàËÉΩÔºå‰æãÂ¶ÇÂõûÁ≠îÈÜ´ÁôÇÂü∑ÁÖßËÄÉË©¶È°åÁõÆ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊØîËºÉ‰∫Ü‰∏ÉÂÄãÂÖ¨ÈñãÁöÑ„ÄåÈÜ´ÁôÇ„ÄçLLM ÂíåÂÖ©ÂÄã VLM ËàáÂÆÉÂÄëÂ∞çÊáâÁöÑÂü∫Êú¨Ê®°ÂûãÔºå‰∏¶ÂæóÂá∫‰∏çÂêåÁöÑÁµêË´ñÔºöÂú®ÈÜ´ÁôÇÂïèÈ°åÂõûÁ≠î (QA) ‰ªªÂãôÁöÑÈõ∂Ê¨°ÔºèÂ∞èÊ®£Êú¨ÊèêÁ§∫Ê©üÂà∂‰∏≠ÔºåÊâÄÊúâÈÜ´ÁôÇ VLM ÂíåÂπæ‰πéÊâÄÊúâÈÜ´ÁôÇ LLM ÈÉΩÁÑ°Ê≥ïÊåÅÁ∫åÂÑ™ÊñºÂÆÉÂÄëÁöÑÂü∫Êú¨Ê®°Âûã„ÄÇ‰æãÂ¶ÇÔºåÂú®ÊàëÂÄëÂú® 3 Ê¨°ÊèêÁ§∫Ë®≠ÂÆö‰∏≠ËÄÉÊÖÆÁöÑ‰ªªÂãôÂíåÊ®°ÂûãÈÖçÂ∞ç‰∏≠ÔºåÈÜ´ÁôÇ LLM ÂÉÖÂú® 12.1% ÁöÑÊÉÖÊ≥Å‰∏ãÂÑ™ÊñºÂÆÉÂÄëÁöÑÂü∫Êú¨Ê®°ÂûãÔºåÂú® 49.8% ÁöÑÊÉÖÊ≥Å‰∏ãÈÅîÂà∞ÔºàÁµ±Ë®àÔºâÂπ≥ÊâãÔºåËÄåÂú®ÂÖ∂È§ò 38.2% ÁöÑÊÉÖÊ≥Å‰∏ãÈ°ØËëó‰ΩéÊñºÂÆÉÂÄëÁöÑÂü∫Êú¨Ê®°Âûã„ÄÇÊàëÂÄëÁöÑÁµêË´ñÂü∫Êñº (i) Áõ¥Êé•ÈáùÂ∞çÂ∞çÊáâÁöÑÂü∫Êú¨Ê®°ÂûãÔºåÈÄê‰∏ÄÊØîËºÉÊØèÂÄãÈÜ´ÁôÇÊ®°ÂûãÔºõ(ii) ÂàÜÂà•ÈáùÂ∞çÊØèÂÄãÊ®°ÂûãÊúÄ‰Ω≥ÂåñÊèêÁ§∫Ôºõ‰ª•Âèä (iii) ËÄÉÊÖÆÊØîËºÉ‰∏≠ÁöÑÁµ±Ë®à‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÈõñÁÑ∂ÈÄô‰∫õÂü∫Êú¨ÂÅöÊ≥ï‰∏¶Êú™ÊåÅÁ∫åÊé°Áî®Âú®ÊñáÁçª‰∏≠Ôºå‰ΩÜÊàëÂÄëÁöÑÊ∂àËûçÁ†îÁ©∂Ë°®ÊòéÔºåÂÆÉÂÄëÊúÉÂ§ßÂπÖÂΩ±ÈüøÁµêË´ñ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÊúÄÂÖàÈÄ≤ÁöÑÈÄöÁî®È†òÂüüÊ®°ÂûãÂèØËÉΩÂ∑≤Á∂ìÂ±ïÁèæÂá∫Âº∑Â§ßÁöÑÈÜ´ÁôÇÁü•Ë≠òÂíåÊé®ÁêÜËÉΩÂäõÔºå‰∏¶ÊèêÂá∫Âª∫Ë≠∞‰ª•Âº∑ÂåñÊú™‰æÜÁ†îÁ©∂ÁöÑÁµêË´ñ„ÄÇ</paragraph>

##### **Fed-EC: Bandwidth-Efficient Clustering-Based Federated Learning For Autonomous Visual Robot Navigation**
2411.04112v1 by Shreya Gummadi, Mateus V. Gasparino, Deepak Vasisht, Girish Chowdhary

Centralized learning requires data to be aggregated at a central server,
which poses significant challenges in terms of data privacy and bandwidth
consumption. Federated learning presents a compelling alternative, however,
vanilla federated learning methods deployed in robotics aim to learn a single
global model across robots that works ideally for all. But in practice one
model may not be well suited for robots deployed in various environments. This
paper proposes Federated-EmbedCluster (Fed-EC), a clustering-based federated
learning framework that is deployed with vision based autonomous robot
navigation in diverse outdoor environments. The framework addresses the key
federated learning challenge of deteriorating model performance of a single
global model due to the presence of non-IID data across real-world robots.
Extensive real-world experiments validate that Fed-EC reduces the communication
size by 23x for each robot while matching the performance of centralized
learning for goal-oriented navigation and outperforms local learning. Fed-EC
can transfer previously learnt models to new robots that join the cluster.

ÊëòË¶ÅÔºöÈõÜ‰∏≠ÂºèÂ≠∏ÁøíÈúÄË¶ÅÂ∞áË≥áÊñôÂΩôÊï¥Ëá≥‰∏≠Â§Æ‰º∫ÊúçÂô®ÔºåÈÄôÂú®Ë≥áÊñôÈö±ÁßÅÂíåÈ†ªÂØ¨Ê∂àËÄóÊñπÈù¢ÈÄ†ÊàêÈáçÂ§ßÊåëÊà∞„ÄÇÁÑ∂ËÄåÔºåËÅØÈÇ¶ÂºèÂ≠∏ÁøíÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂº∑ÊúâÂäõÁöÑÊõø‰ª£ÊñπÊ°àÔºå‰∏çÈÅéÔºåÁî®ÊñºÊ©üÂô®‰∫∫ÁöÑÈ¶ôËçâËÅØÈÇ¶ÂºèÂ≠∏ÁøíÊñπÊ≥ïÊó®Âú®Â≠∏ÁøíÊâÄÊúâÊ©üÂô®‰∫∫ÈÉΩÁêÜÊÉ≥ÈÅã‰ΩúÁöÑÂñÆ‰∏ÄÂÖ®ÁêÉÊ®°Âûã„ÄÇ‰ΩÜÂú®ÂØ¶Âãô‰∏äÔºåÂñÆ‰∏ÄÊ®°ÂûãÂèØËÉΩ‰∏çÈÅ©ÂêàÈÉ®ÁΩ≤Âú®ÂêÑÁ®ÆÁí∞Â¢É‰∏≠ÁöÑÊ©üÂô®‰∫∫„ÄÇÊú¨ÊñáÊèêÂá∫‰ª•Áæ§ÈõÜÁÇ∫Âü∫Á§éÁöÑËÅØÈÇ¶ÂºèÂ≠∏ÁøíÊû∂Êßã Federated-EmbedCluster (Fed-EC)ÔºåË©≤Êû∂ÊßãËàáÂü∫ÊñºË¶ñË¶∫ÁöÑËá™‰∏ªÊ©üÂô®‰∫∫Â∞éËà™‰∏ÄËµ∑ÈÉ®ÁΩ≤Âú®Â§öÊ®£ÂåñÁöÑÊà∂Â§ñÁí∞Â¢É‰∏≠„ÄÇË©≤Êû∂ÊßãËß£Ê±∫‰∫ÜËÅØÈÇ¶ÂºèÂ≠∏ÁøíÁöÑ‰∏ÄÈ†ÖÈóúÈçµÊåëÊà∞ÔºåÂç≥Áî±ÊñºÁèæÂØ¶‰∏ñÁïåÊ©üÂô®‰∫∫‰∏≠Â≠òÂú®Èùû IID Ë≥áÊñôÔºåÂ∞éËá¥ÂñÆ‰∏ÄÂÖ®ÁêÉÊ®°ÂûãÁöÑÊ®°ÂûãÊïàËÉΩ‰∏ãÈôç„ÄÇÂª£Ê≥õÁöÑÁúüÂØ¶‰∏ñÁïåÂØ¶È©óÈ©óË≠â‰∫Ü Fed-EC Â∞áÊØèÂÄãÊ©üÂô®‰∫∫ÁöÑÈÄöË®äÂ§ßÂ∞èÊ∏õÂ∞ë‰∫Ü 23 ÂÄçÔºåÂêåÊôÇÁ¨¶ÂêàÁõÆÊ®ôÂ∞éÂêëÂ∞éËà™ÁöÑÈõÜ‰∏≠ÂºèÂ≠∏ÁøíÊïàËÉΩÔºå‰∏¶ÂÑ™ÊñºÂ±ÄÈÉ®Â≠∏Áøí„ÄÇFed-EC ÂèØ‰ª•Â∞áÂÖàÂâçÂ≠∏ÁøíÁöÑÊ®°ÂûãËΩâÁßªÂà∞Âä†ÂÖ•Áæ§ÈõÜÁöÑÊñ∞Ê©üÂô®‰∫∫„ÄÇ

##### **Self-Consistency Preference Optimization**
2411.04109v1 by Archiki Prasad, Weizhe Yuan, Richard Yuanzhe Pang, Jing Xu, Maryam Fazel-Zarandi, Mohit Bansal, Sainbayar Sukhbaatar, Jason Weston, Jane Yu

Self-alignment, whereby models learn to improve themselves without human
annotation, is a rapidly growing research area. However, existing techniques
often fail to improve complex reasoning tasks due to the difficulty of
assigning correct rewards. An orthogonal approach that is known to improve
correctness is self-consistency, a method applied at inference time based on
multiple sampling in order to find the most consistent answer. In this work, we
extend the self-consistency concept to help train models. We thus introduce
self-consistency preference optimization (ScPO), which iteratively trains
consistent answers to be preferred over inconsistent ones on unsupervised new
problems. We show ScPO leads to large improvements over conventional reward
model training on reasoning tasks such as GSM8K and MATH, closing the gap with
supervised training with gold answers or preferences, and that combining ScPO
with standard supervised learning improves results even further. On ZebraLogic,
ScPO finetunes Llama-3 8B to be superior to Llama-3 70B, Gemma-2 27B, and
Claude-3 Haiku.

ÊëòË¶ÅÔºöËá™ÊàëÂ∞çÈΩäÔºåÂç≥Ê®°ÂûãÂú®Ê≤íÊúâ‰∫∫Â∑•Ê®ôË®ªÁöÑÊÉÖÊ≥Å‰∏ãÂ≠∏ÊúÉËá™ÊàëÊîπÈÄ≤ÔºåÊòØ‰∏ÄÂÄãÂø´ÈÄüÁôºÂ±ïÁöÑÁ†îÁ©∂È†òÂüü„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÊäÄË°ìÁî±ÊñºÈõ£‰ª•ÂàÜÈÖçÊ≠£Á¢∫ÁöÑÁçéÂãµÔºåÂ∏∏Â∏∏ÁÑ°Ê≥ïÊîπÈÄ≤Ë§áÈõúÁöÑÊé®ÁêÜ‰ªªÂãô„ÄÇ‰∏ÄÁ®ÆÂ∑≤Áü•ÂèØ‰ª•ÊèêÈ´òÊ≠£Á¢∫ÊÄßÁöÑÊ≠£‰∫§ÊñπÊ≥ïÊòØËá™‰∏ÄËá¥ÊÄßÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂú®Êé®ÁêÜÊôÇÈñìÊáâÁî®ÊñºÂ§öÈáçÊäΩÊ®£ÁöÑÔºåÁî®ÊñºÊâæÂà∞ÊúÄ‰∏ÄËá¥Á≠îÊ°àÁöÑÊñπÊ≥ï„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂ∞áËá™‰∏ÄËá¥ÊÄßÊ¶ÇÂøµÂª∂‰º∏Âà∞Âπ´Âä©Ë®ìÁ∑¥Ê®°Âûã„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜËá™‰∏ÄËá¥ÊÄßÂÅèÂ•ΩÂÑ™ÂåñÔºàScPOÔºâÔºåÂÆÉÂèçË¶ÜË®ìÁ∑¥‰∏ÄËá¥ÁöÑÁ≠îÊ°àÔºå‰ΩøÂÖ∂Âú®ÁÑ°Áõ£Áù£ÁöÑÊñ∞ÂïèÈ°å‰∏äÊØî‰∏ç‰∏ÄËá¥ÁöÑÁ≠îÊ°àÊõ¥ÂèóÈùíÁùû„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫Ü ScPO Âú®Êé®ÁêÜ‰ªªÂãôÔºà‰æãÂ¶Ç GSM8K Âíå MATHÔºâ‰∏äÊØîÂÇ≥Áµ±ÁçéÂãµÊ®°ÂûãË®ìÁ∑¥Êúâ‰∫ÜÂæàÂ§ßÊîπÈÄ≤ÔºåÁ∏ÆÂ∞è‰∫ÜËàá‰ΩøÁî®ÈªÉÈáëÁ≠îÊ°àÊàñÂÅèÂ•ΩÁöÑÁõ£Áù£Ë®ìÁ∑¥ÁöÑÂ∑ÆË∑ùÔºå‰∏¶‰∏îÂ∞á ScPO ËàáÊ®ôÊ∫ñÁõ£Áù£Â≠∏ÁøíÁõ∏ÁµêÂêàÈÄ≤‰∏ÄÊ≠•ÊîπÈÄ≤‰∫ÜÁµêÊûú„ÄÇÂú® ZebraLogic ‰∏äÔºåScPO Â∞ç Llama-3 8B ÈÄ≤Ë°åÂæÆË™øÔºå‰ΩøÂÖ∂ÂÑ™Êñº Llama-3 70B„ÄÅGemma-2 27B Âíå Claude-3 Haiku„ÄÇ

##### **How Transformers Solve Propositional Logic Problems: A Mechanistic Analysis**
2411.04105v1 by Guan Zhe Hong, Nishanth Dikkala, Enming Luo, Cyrus Rashtchian, Rina Panigrahy

Large language models (LLMs) have shown amazing performance on tasks that
require planning and reasoning. Motivated by this, we investigate the internal
mechanisms that underpin a network's ability to perform complex logical
reasoning. We first construct a synthetic propositional logic problem that
serves as a concrete test-bed for network training and evaluation. Crucially,
this problem demands nontrivial planning to solve, but we can train a small
transformer to achieve perfect accuracy. Building on our set-up, we then pursue
an understanding of precisely how a three-layer transformer, trained from
scratch, solves this problem. We are able to identify certain "planning" and
"reasoning" circuits in the network that necessitate cooperation between the
attention blocks to implement the desired logic. To expand our findings, we
then study a larger model, Mistral 7B. Using activation patching, we
characterize internal components that are critical in solving our logic
problem. Overall, our work systemically uncovers novel aspects of small and
large transformers, and continues the study of how they plan and reason.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÈúÄË¶ÅË¶èÂäÉÂíåÊé®ÁêÜÁöÑ‰ªªÂãô‰∏äË°®ÁèæÂá∫Ëâ≤„ÄÇÂèóÊ≠§ÂïüÁôºÔºåÊàëÂÄëÁ†îÁ©∂‰∫ÜÊîØÊíêÁ∂≤Ë∑ØÂü∑Ë°åË§áÈõúÈÇèËºØÊé®ÁêÜËÉΩÂäõÁöÑÂÖßÈÉ®Ê©üÂà∂„ÄÇÊàëÂÄëÈ¶ñÂÖàÊßãÂª∫‰∫Ü‰∏ÄÂÄãÂêàÊàêÂëΩÈ°åÈÇèËºØÂïèÈ°åÔºå‰ΩúÁÇ∫Á∂≤Ë∑ØË®ìÁ∑¥ÂíåË©ï‰º∞ÁöÑÂÖ∑È´îÊ∏¨Ë©¶Âπ≥Âè∞„ÄÇËá≥ÈóúÈáçË¶ÅÁöÑÊòØÔºåÈÄôÂÄãÂïèÈ°åÈúÄË¶ÅÈùûÂπ≥Âá°ÁöÑË¶èÂäÉÊâçËÉΩËß£Ê±∫Ôºå‰ΩÜÊàëÂÄëÂèØ‰ª•Ë®ìÁ∑¥‰∏ÄÂÄãÂ∞èÂûãTransformer‰æÜÂØ¶ÁèæÂÆåÁæéÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÂª∫Á´ãÂú®ÊàëÂÄëÁöÑË®≠ÁΩÆ‰πã‰∏äÔºåÊàëÂÄëÊé•ËëóÊé¢Ë®é‰∏ÄÂÄãÂæûÈ†≠Ë®ìÁ∑¥ÁöÑ‰∏âÂ±§TransformerÂ¶Ç‰ΩïËß£Ê±∫ÈÄôÂÄãÂïèÈ°å„ÄÇÊàëÂÄëËÉΩÂ§†Ë≠òÂà•Á∂≤Ë∑Ø‰∏≠Êüê‰∫õ„ÄåË¶èÂäÉ„ÄçÂíå„ÄåÊé®ÁêÜ„ÄçÈõªË∑ØÔºåÂÆÉÂÄëÈúÄË¶ÅÊ≥®ÊÑèÂäõÂçÄÂ°ä‰πãÈñìÁöÑÂêà‰Ωú‰æÜÂØ¶ÁèæÊâÄÈúÄÁöÑÈÇèËºØ„ÄÇÁÇ∫‰∫ÜÊì¥Â±ïÊàëÂÄëÁöÑÁôºÁèæÔºåÊàëÂÄëÊé•ËëóÁ†îÁ©∂‰∏ÄÂÄãÊõ¥Â§ßÁöÑÊ®°ÂûãÔºåMistral 7B„ÄÇ‰ΩøÁî®ÊøÄÊ¥ª‰øÆË£úÔºåÊàëÂÄëÊèèËø∞‰∫ÜÂú®Ëß£Ê±∫ÊàëÂÄëÁöÑÈÇèËºØÂïèÈ°å‰∏≠Ëá≥ÈóúÈáçË¶ÅÁöÑÂÖßÈÉ®ÁµÑ‰ª∂„ÄÇÁ∏ΩÁöÑ‰æÜË™™ÔºåÊàëÂÄëÁöÑÁ†îÁ©∂Á≥ªÁµ±Âú∞Êè≠Á§∫‰∫ÜÂ∞èÂûãÂíåÂ§ßÂûãTransformerÁöÑÊñ∞ÊñπÈù¢Ôºå‰∏¶ÁπºÁ∫åÁ†îÁ©∂ÂÆÉÂÄëÊòØÂ¶Ç‰ΩïË¶èÂäÉÂíåÊé®ÁêÜÁöÑ„ÄÇ

##### **RaVL: Discovering and Mitigating Spurious Correlations in Fine-Tuned Vision-Language Models**
2411.04097v1 by Maya Varma, Jean-Benoit Delbrouck, Zhihong Chen, Akshay Chaudhari, Curtis Langlotz

Fine-tuned vision-language models (VLMs) often capture spurious correlations
between image features and textual attributes, resulting in degraded zero-shot
performance at test time. Existing approaches for addressing spurious
correlations (i) primarily operate at the global image-level rather than
intervening directly on fine-grained image features and (ii) are predominantly
designed for unimodal settings. In this work, we present RaVL, which takes a
fine-grained perspective on VLM robustness by discovering and mitigating
spurious correlations using local image features rather than operating at the
global image level. Given a fine-tuned VLM, RaVL first discovers spurious
correlations by leveraging a region-level clustering approach to identify
precise image features contributing to zero-shot classification errors. Then,
RaVL mitigates the identified spurious correlation with a novel region-aware
loss function that enables the VLM to focus on relevant regions and ignore
spurious relationships during fine-tuning. We evaluate RaVL on 654 VLMs with
various model architectures, data domains, and learned spurious correlations.
Our results show that RaVL accurately discovers (191% improvement over the
closest baseline) and mitigates (8.2% improvement on worst-group image
classification accuracy) spurious correlations. Qualitative evaluations on
general-domain and medical-domain VLMs confirm our findings.

ÊëòË¶ÅÔºöÂæÆË∞ÉÁöÑËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºàVLMÔºâÈÄöÂ∏∏‰ºöÊçïÊçâÂõæÂÉèÁâπÂæÅÂíåÊñáÊú¨Â±ûÊÄß‰πãÈó¥ÁöÑËôöÂÅáÁõ∏ÂÖ≥ÊÄßÔºåÂØºËá¥Âú®ÊµãËØïÊó∂Èõ∂Ê†∑Êú¨ÊÄßËÉΩ‰∏ãÈôç„ÄÇÁé∞ÊúâÁöÑËß£ÂÜ≥ËôöÂÅáÁõ∏ÂÖ≥ÊÄßÁöÑÊñπÊ≥ïÔºàiÔºâ‰∏ªË¶ÅÂú®ÂÖ®Â±ÄÂõæÂÉèÁ∫ßÂà´Êìç‰ΩúÔºåËÄå‰∏çÊòØÁõ¥Êé•Âπ≤È¢ÑÁªÜÁ≤íÂ∫¶ÁöÑÂõæÂÉèÁâπÂæÅÔºåÂπ∂‰∏îÔºàiiÔºâ‰∏ªË¶ÅËÆæËÆ°Áî®‰∫éÂçïÊ®°ÊÄÅËÆæÁΩÆ„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü RaVLÔºåÂÆÉÈÄöËøá‰ΩøÁî®Â±ÄÈÉ®ÂõæÂÉèÁâπÂæÅËÄå‰∏çÊòØÂú®ÂÖ®Â±ÄÂõæÂÉèÁ∫ßÂà´Êìç‰ΩúÊù•ÂèëÁé∞ÂíåÂáèËΩªËôöÂÅáÁõ∏ÂÖ≥ÊÄßÔºå‰ªéËÄåÂØπ VLM È≤ÅÊ£íÊÄßÈááÂèñ‰∫ÜÁªÜÁ≤íÂ∫¶ÁöÑËßÜËßí„ÄÇÁªôÂÆö‰∏Ä‰∏™ÂæÆË∞ÉÁöÑ VLMÔºåRaVL È¶ñÂÖàÈÄöËøáÂà©Áî®Âå∫ÂüüÁ∫ßËÅöÁ±ªÊñπÊ≥ïÂèëÁé∞ËôöÂÅáÁõ∏ÂÖ≥ÊÄßÔºå‰ª•ËØÜÂà´ÂØºËá¥Èõ∂Ê†∑Êú¨ÂàÜÁ±ªÈîôËØØÁöÑÁ≤æÁ°ÆÂõæÂÉèÁâπÂæÅ„ÄÇÁÑ∂ÂêéÔºåRaVL ‰ΩøÁî®‰∏ÄÁßçÊñ∞È¢ñÁöÑÂå∫ÂüüÊÑüÁü•ÊçüÂ§±ÂáΩÊï∞Êù•ÂáèËΩªÂ∑≤ËØÜÂà´ÁöÑËôöÂÅáÁõ∏ÂÖ≥ÊÄßÔºåËØ•ÊçüÂ§±ÂáΩÊï∞‰Ωø VLM ËÉΩÂ§üÂú®ÂæÆË∞ÉÊúüÈó¥ÂÖ≥Ê≥®Áõ∏ÂÖ≥Âå∫ÂüüÂπ∂ÂøΩÁï•ËôöÂÅáÂÖ≥Á≥ª„ÄÇÊàë‰ª¨‰ΩøÁî® 654 ‰∏™ VLM ÂØπ RaVL ËøõË°å‰∫ÜËØÑ‰º∞ÔºåËøô‰∫õ VLM ÂÖ∑ÊúâÂêÑÁßçÊ®°ÂûãÊû∂ÊûÑ„ÄÅÊï∞ÊçÆÂüüÂíåÂ≠¶‰π†Âà∞ÁöÑËôöÂÅáÁõ∏ÂÖ≥ÊÄß„ÄÇÊàë‰ª¨ÁöÑÁªìÊûúË°®ÊòéÔºåRaVL ÂáÜÁ°ÆÂú∞ÂèëÁé∞‰∫ÜÔºàÊØîÊúÄÊé•ËøëÁöÑÂü∫Á∫øÊèêÈ´ò‰∫Ü 191%ÔºâÂíåÂáèËΩª‰∫ÜÔºàÂú®ÊúÄÂ∑ÆÁªÑÂõæÂÉèÂàÜÁ±ªÂáÜÁ°ÆÊÄß‰∏äÊèêÈ´ò‰∫Ü 8.2%ÔºâËôöÂÅáÁõ∏ÂÖ≥ÊÄß„ÄÇÂØπÈÄöÁî®ÂüüÂíåÂåªÂ≠¶Âüü VLM ÁöÑÂÆöÊÄßËØÑ‰º∞ËØÅÂÆû‰∫ÜÊàë‰ª¨ÁöÑÂèëÁé∞„ÄÇ

##### **Summarization of Opinionated Political Documents with Varied Perspectives**
2411.04093v1 by Nicholas Deas, Kathleen McKeown

Global partisan hostility and polarization has increased, and this
polarization is heightened around presidential elections. Models capable of
generating accurate summaries of diverse perspectives can help reduce such
polarization by exposing users to alternative perspectives. In this work, we
introduce a novel dataset and task for independently summarizing each political
perspective in a set of passages from opinionated news articles. For this task,
we propose a framework for evaluating different dimensions of perspective
summary performance. We benchmark 10 models of varying sizes and architectures
through both automatic and human evaluation. While recent models like GPT-4o
perform well on this task, we find that all models struggle to generate
summaries faithful to the intended perspective. Our analysis of summaries
focuses on how extraction behavior depends on the features of the input
documents.

ÊëòË¶ÅÔºöÂÖ®ÁêÉÈª®Ê¥æÊïµÊÑèÂíåÂÖ©Ê•µÂàÜÂåñÂä†ÂäáÔºåËÄåÈÄôÁ®ÆÂÖ©Ê•µÂàÜÂåñÂú®Á∏ΩÁµ±ÈÅ∏Ëàâ‰∏≠Â∞§ÁÇ∫ÊòéÈ°Ø„ÄÇËÉΩÂ§†Áî¢Áîü‰∏çÂêåËßÄÈªûÁöÑÊ∫ñÁ¢∫ÊëòË¶ÅÁöÑÊ®°ÂûãÔºåÂèØ‰ª•ÈÄèÈÅéËÆì‰ΩøÁî®ËÄÖÊé•Ëß∏‰∏çÂêåÁöÑËßÄÈªûÔºå‰æÜÂπ´Âä©Ê∏õÂ∞ëÈÄôÁ®ÆÂÖ©Ê•µÂàÜÂåñ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑË≥áÊñôÈõÜÂíå‰ªªÂãôÔºåÁî®ÊñºÁç®Á´ãÊëòË¶ÅÊÑèË¶ãÊÄßÊñ∞ËÅûÊñáÁ´†‰∏≠ÁöÑ‰∏ÄÁµÑÊÆµËêΩ‰∏≠ÁöÑÊØè‰∏ÄÂÄãÊîøÊ≤ªËßÄÈªû„ÄÇÂ∞çÊñºÈÄôÂÄã‰ªªÂãôÔºåÊàëÂÄëÊèêÂá∫‰∫ÜË©ï‰º∞ËßÄÈªûÊëòË¶ÅË°®Áèæ‰∏çÂêåÈù¢ÂêëÁöÑÊû∂Êßã„ÄÇÊàëÂÄëÈÄèÈÅéËá™ÂãïÂíå‰∫∫Â∑•Ë©ï‰º∞ÔºåÂ∞ç 10 ÂÄã‰∏çÂêåÂ§ßÂ∞èÂíåÊû∂ÊßãÁöÑÊ®°ÂûãÈÄ≤Ë°åÂü∫Ê∫ñÊ∏¨Ë©¶„ÄÇÈõñÁÑ∂ÂÉè GPT-4o ÈÄôÊ®£ÁöÑÊúÄÊñ∞Ê®°ÂûãÂú®ÈÄôÈ†Ö‰ªªÂãô‰∏≠Ë°®ÁèæËâØÂ•ΩÔºå‰ΩÜÊàëÂÄëÁôºÁèæÊâÄÊúâÊ®°ÂûãÈÉΩÂæàÈõ£Áî¢ÁîüÂø†ÊñºÈ†êÊúüËßÄÈªûÁöÑÊëòË¶Å„ÄÇÊàëÂÄëÂ∞çÊëòË¶ÅÁöÑÂàÜÊûêÈáçÈªûÂú®ÊñºÊèêÂèñË°åÁÇ∫Â¶Ç‰ΩïÂèñÊ±∫ÊñºËº∏ÂÖ•Êñá‰ª∂ÁöÑÂäüËÉΩ„ÄÇ

##### **A Collaborative Content Moderation Framework for Toxicity Detection based on Conformalized Estimates of Annotation Disagreement**
2411.04090v1 by Guillermo Villate-Castillo, Javier Del Ser, Borja Sanz

Content moderation typically combines the efforts of human moderators and
machine learning models.However, these systems often rely on data where
significant disagreement occurs during moderation, reflecting the subjective
nature of toxicity perception.Rather than dismissing this disagreement as
noise, we interpret it as a valuable signal that highlights the inherent
ambiguity of the content,an insight missed when only the majority label is
considered.In this work, we introduce a novel content moderation framework that
emphasizes the importance of capturing annotation disagreement. Our approach
uses multitask learning, where toxicity classification serves as the primary
task and annotation disagreement is addressed as an auxiliary
task.Additionally, we leverage uncertainty estimation techniques, specifically
Conformal Prediction, to account for both the ambiguity in comment annotations
and the model's inherent uncertainty in predicting toxicity and
disagreement.The framework also allows moderators to adjust thresholds for
annotation disagreement, offering flexibility in determining when ambiguity
should trigger a review.We demonstrate that our joint approach enhances model
performance, calibration, and uncertainty estimation, while offering greater
parameter efficiency and improving the review process in comparison to
single-task methods.

ÊëòË¶ÅÔºöÂÖßÂÆπÂØ©Ê†∏ÈÄöÂ∏∏ÁµêÂêà‰∫∫Â∑•ÂØ©Ê†∏Âì°ÂíåÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÁöÑÂä™Âäõ„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÁ≥ªÁµ±Á∂ìÂ∏∏‰æùË≥¥ÊñºÂú®ÂØ©Ê†∏ÈÅéÁ®ã‰∏≠ÁôºÁîüÈáçÂ§ßÂàÜÊ≠ßÁöÑË≥áÊñôÔºåÂèçÊò†Âá∫ÊØíÊÄßË™çÁü•ÁöÑ‰∏ªËßÄÊÄßË≥™„ÄÇÊàëÂÄë‰∏çÂ∞áÈÄôÁ®ÆÂàÜÊ≠ßË¶ñÁÇ∫ÈõúË®äÔºåËÄåÊòØÂ∞áÂÖ∂Ëß£ÈáãÁÇ∫‰∏ÄÂÄãÊúâÂÉπÂÄºÁöÑË®äËôüÔºåÂÆÉÁ™ÅÂá∫‰∫ÜÂÖßÂÆπÂõ∫ÊúâÁöÑÊ®°Á≥äÊÄßÔºåÈÄôÊòØÂÉÖËÄÉÊÖÆÂ§öÊï∏Ê®ôÁ±§ÊôÇÊâÄÂøΩÁï•ÁöÑË¶ãËß£„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÂÖßÂÆπÂØ©Ê†∏Ê°ÜÊû∂ÔºåÂº∑Ë™ø‰∫ÜÊçïÊçâË®ªËß£ÂàÜÊ≠ßÁöÑÈáçË¶ÅÊÄß„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊé°Áî®Â§ö‰ªªÂãôÂ≠∏ÁøíÔºåÂÖ∂‰∏≠ÊØíÊÄßÂàÜÈ°û‰ΩúÁÇ∫‰∏ªË¶Å‰ªªÂãôÔºåËÄåË®ªËß£ÂàÜÊ≠ßÂâá‰ΩúÁÇ∫ËºîÂä©‰ªªÂãô„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂà©Áî®‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÊäÄË°ìÔºåÁâπÂà•ÊòØÂÖ±ÂΩ¢È†êÊ∏¨Ôºå‰æÜËÄÉÈáèË©ïË´ñË®ªËß£‰∏≠ÁöÑÊ®°Á≥äÊÄßÔºå‰ª•ÂèäÊ®°ÂûãÂú®È†êÊ∏¨ÊØíÊÄßÂíåÂàÜÊ≠ßÊôÇÂõ∫ÊúâÁöÑ‰∏çÁ¢∫ÂÆöÊÄß„ÄÇË©≤Ê°ÜÊû∂ÈÇÑÂÖÅË®±ÂØ©Ê†∏Âì°Ë™øÊï¥Ë®ªËß£ÂàÜÊ≠ßÁöÑÈñæÂÄºÔºåÂú®Á¢∫ÂÆö‰ΩïÊôÇÊ®°Á≥äÊÄßÊáâËß∏ÁôºÂØ©Êü•ÊôÇÊèê‰æõÈùàÊ¥ªÊÄß„ÄÇÊàëÂÄëË≠âÊòé‰∫ÜÊàëÂÄëÁöÑËÅØÂêàÊñπÊ≥ïÂ¢ûÂº∑‰∫ÜÊ®°ÂûãÊïàËÉΩ„ÄÅÊ†°Ê∫ñÂíå‰∏çÁ¢∫ÂÆöÊÄß‰º∞Ë®àÔºåÂêåÊôÇÊèê‰æõ‰∫ÜÊõ¥È´òÁöÑÂèÉÊï∏ÊïàÁéáÔºå‰∏¶ÊîπÂñÑ‰∫ÜËàáÂñÆ‰∏Ä‰ªªÂãôÊñπÊ≥ïÁõ∏ÊØîÁöÑÂØ©Êü•ÊµÅÁ®ã„ÄÇ

##### **M3SciQA: A Multi-Modal Multi-Document Scientific QA Benchmark for Evaluating Foundation Models**
2411.04075v1 by Chuhan Li, Ziyao Shangguan, Yilun Zhao, Deyuan Li, Yixin Liu, Arman Cohan

Existing benchmarks for evaluating foundation models mainly focus on
single-document, text-only tasks. However, they often fail to fully capture the
complexity of research workflows, which typically involve interpreting
non-textual data and gathering information across multiple documents. To
address this gap, we introduce M3SciQA, a multi-modal, multi-document
scientific question answering benchmark designed for a more comprehensive
evaluation of foundation models. M3SciQA consists of 1,452 expert-annotated
questions spanning 70 natural language processing paper clusters, where each
cluster represents a primary paper along with all its cited documents,
mirroring the workflow of comprehending a single paper by requiring multi-modal
and multi-document data. With M3SciQA, we conduct a comprehensive evaluation of
18 foundation models. Our results indicate that current foundation models still
significantly underperform compared to human experts in multi-modal information
retrieval and in reasoning across multiple scientific documents. Additionally,
we explore the implications of these findings for the future advancement of
applying foundation models in multi-modal scientific literature analysis.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÂü∫Á§éÊ®°ÂûãË©ï‰º∞Âü∫Ê∫ñ‰∏ªË¶ÅÂ∞àÊ≥®ÊñºÂñÆ‰∏ÄÊñá‰ª∂„ÄÅÁ¥îÊñáÂ≠ó‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÈÄöÂ∏∏ÁÑ°Ê≥ïÂÆåÂÖ®ÊçïÊçâÁ†îÁ©∂Â∑•‰ΩúÊµÅÁ®ãÁöÑË§áÈõúÊÄßÔºåËÄåÈÄôÈÄöÂ∏∏Ê∂âÂèäËß£Ë≠ØÈùûÊñáÂ≠óË≥áÊñôÂíåË∑®Â§öÂÄãÊñá‰ª∂Êî∂ÈõÜË≥áË®ä„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü M3SciQAÔºå‰∏ÄÂÄãÂ§öÊ®°ÊÖã„ÄÅÂ§öÊñá‰ª∂ÁßëÂ≠∏ÂïèÈ°åËß£Á≠îÂü∫Ê∫ñÔºåÊó®Âú®Â∞çÂü∫Á§éÊ®°ÂûãÈÄ≤Ë°åÊõ¥ÂÖ®Èù¢ÁöÑË©ï‰º∞„ÄÇM3SciQA ÂåÖÂê´ 1,452 ÂÄãÁî±Â∞àÂÆ∂Ë®ªÈáãÁöÑÂïèÈ°åÔºåÊ∂µËìã 70 ÂÄãËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜË´ñÊñáÂè¢ÈõÜÔºåÂÖ∂‰∏≠ÊØèÂÄãÂè¢ÈõÜ‰ª£Ë°®‰∏ÄÁØá‰∏ªË¶ÅË´ñÊñáÂèäÂÖ∂ÊâÄÊúâÂºïÊñáÊñá‰ª∂ÔºåÂèçÊò†‰∫ÜÈÄèÈÅéË¶ÅÊ±ÇÂ§öÊ®°ÊÖãÂíåÂ§öÊñá‰ª∂Ë≥áÊñô‰æÜÁêÜËß£ÂñÆ‰∏ÄË´ñÊñáÁöÑÂ∑•‰ΩúÊµÅÁ®ã„ÄÇÈÄèÈÅé M3SciQAÔºåÊàëÂÄëÂ∞ç 18 ÂÄãÂü∫Á§éÊ®°ÂûãÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑË©ï‰º∞„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåËàáÂú®Â§öÊ®°ÊÖãË≥áË®äÊ™¢Á¥¢ÂíåË∑®Â§öÂÄãÁßëÂ≠∏Êñá‰ª∂Êé®ÁêÜÁöÑ‰∫∫È°ûÂ∞àÂÆ∂Áõ∏ÊØîÔºåÁï∂ÂâçÁöÑÂü∫Á§éÊ®°Âûã‰ªçÁÑ∂Ë°®ÁèæÂæóÈ°ØËëó‰∏çË∂≥„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÈÄô‰∫õÁôºÁèæÂ∞çÊú™‰æÜÂ∞áÂü∫Á§éÊ®°ÂûãÊáâÁî®ÊñºÂ§öÊ®°ÊÖãÁßëÂ≠∏ÊñáÁçªÂàÜÊûêÁöÑÂΩ±Èüø„ÄÇ

##### **Non-Stationary Learning of Neural Networks with Automatic Soft Parameter Reset**
2411.04034v1 by Alexandre Galashov, Michalis K. Titsias, Andr√°s Gy√∂rgy, Clare Lyle, Razvan Pascanu, Yee Whye Teh, Maneesh Sahani

Neural networks are traditionally trained under the assumption that data come
from a stationary distribution. However, settings which violate this assumption
are becoming more popular; examples include supervised learning under
distributional shifts, reinforcement learning, continual learning and
non-stationary contextual bandits. In this work we introduce a novel learning
approach that automatically models and adapts to non-stationarity, via an
Ornstein-Uhlenbeck process with an adaptive drift parameter. The adaptive drift
tends to draw the parameters towards the initialisation distribution, so the
approach can be understood as a form of soft parameter reset. We show
empirically that our approach performs well in non-stationary supervised and
off-policy reinforcement learning settings.

ÊëòË¶ÅÔºöÁ•ûÁ∂ìÁ∂≤Ë∑ØÂÇ≥Áµ±‰∏äÊòØÂú®ÂÅáË®≠Ë≥áÊñô‰æÜËá™Âõ∫ÂÆöÂàÜ‰ΩàÁöÑÊ¢ù‰ª∂‰∏ãË®ìÁ∑¥ÁöÑ„ÄÇÁÑ∂ËÄåÔºåÈÅïÂèçÊ≠§ÂÅáË®≠ÁöÑË®≠ÂÆöÊ≠£ËÆäÂæóË∂ä‰æÜË∂äÊôÆÈÅçÔºõÁØÑ‰æãÂåÖÊã¨ÂàÜ‰ΩàËΩâÁßª‰∏ãÁöÑÁõ£Áù£ÂºèÂ≠∏Áøí„ÄÅÂº∑ÂåñÂ≠∏Áøí„ÄÅÊåÅÁ∫åÂ≠∏ÁøíÂíåÈùûÂõ∫ÂÆöÊÉÖÂ¢ÉÂº∑Áõú„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂ≠∏ÁøíÊñπÊ≥ïÔºåÂÆÉÈÄèÈÅéÂÖ∑ÊúâÈÅ©ÊáâÊÄßÊºÇÁßªÂèÉÊï∏ÁöÑ Ornstein-Uhlenbeck ÈÅéÁ®ãÔºåËá™ÂãïÂ∞çÈùûÂõ∫ÂÆöÊÄßÈÄ≤Ë°åÂª∫Ê®°ÂíåÈÅ©Êáâ„ÄÇÈÅ©ÊáâÊÄßÊºÇÁßªÂÇæÂêëÊñºÂ∞áÂèÉÊï∏ÊãâÂêëÂàùÂßãÂåñÂàÜ‰ΩàÔºåÂõ†Ê≠§ÂèØ‰ª•Â∞áÊ≠§ÊñπÊ≥ïÁêÜËß£ÁÇ∫‰∏ÄÁ®ÆËªüÂèÉÊï∏ÈáçË®≠ÂΩ¢Âºè„ÄÇÊàëÂÄëÈÄèÈÅéÂØ¶Ë≠âÈ°ØÁ§∫ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®ÈùûÂõ∫ÂÆöÁõ£Áù£ÂºèÂíåÈùûÁ≠ñÁï•Âº∑ÂåñÂ≠∏ÁøíË®≠ÂÆö‰∏≠Ë°®ÁèæËâØÂ•Ω„ÄÇ

##### **Beemo: Benchmark of Expert-edited Machine-generated Outputs**
2411.04032v1 by Ekaterina Artemova, Jason Lucas, Saranya Venkatraman, Jooyoung Lee, Sergei Tilga, Adaku Uchendu, Vladislav Mikhailov

The rapid proliferation of large language models (LLMs) has increased the
volume of machine-generated texts (MGTs) and blurred text authorship in various
domains. However, most existing MGT benchmarks include single-author texts
(human-written and machine-generated). This conventional design fails to
capture more practical multi-author scenarios, where the user refines the LLM
response for natural flow, coherence, and factual correctness. Our paper
introduces the Benchmark of Expert-edited Machine-generated Outputs (Beemo),
which includes 6.5k texts written by humans, generated by ten
instruction-finetuned LLMs, and edited by experts for various use cases,
ranging from creative writing to summarization. Beemo additionally comprises
13.1k machine-generated and LLM-edited texts, allowing for diverse MGT
detection evaluation across various edit types. We document Beemo's creation
protocol and present the results of benchmarking 33 configurations of MGT
detectors in different experimental setups. We find that expert-based editing
evades MGT detection, while LLM-edited texts are unlikely to be recognized as
human-written. Beemo and all materials are publicly available.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂø´ÈÄüÊì¥Êï£Â¢ûÂä†‰∫ÜÊ©üÂô®Áî¢ÁîüÁöÑÊñáÊú¨ (MGT) ÁöÑÊï∏ÈáèÔºå‰∏¶Ê®°Á≥ä‰∫ÜÂêÑÁ®ÆÈ†òÂüü‰∏≠ÁöÑÊñáÂ≠ó‰ΩúËÄÖË∫´‰ªΩ„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑ MGT Âü∫Ê∫ñÂ§ßÂ§öÂåÖÂê´ÂñÆ‰∏Ä‰ΩúËÄÖÁöÑÊñáÊú¨Ôºà‰∫∫Â∑•Êí∞ÂØ´ÂíåÊ©üÂô®Áî¢ÁîüÁöÑÔºâ„ÄÇÈÄôÁ®ÆÂÇ≥Áµ±ÁöÑË®≠Ë®àÁÑ°Ê≥ïÊçïÊçâÂà∞Êõ¥ÂØ¶ÈöõÁöÑÂ§ö‰ΩúËÄÖÂ†¥ÊôØÔºåÂú®ÈÄôÁ®ÆÂ†¥ÊôØ‰∏≠Ôºå‰ΩøÁî®ËÄÖÊúÉ‰øÆÊîπ LLM ÂõûÊáâ‰ª•Áç≤ÂæóËá™ÁÑ∂ÁöÑÊµÅÊö¢ÊÄß„ÄÅÈÄ£Ë≤´ÊÄßÂíå‰∫ãÂØ¶Ê≠£Á¢∫ÊÄß„ÄÇÊàëÂÄëÁöÑË´ñÊñá‰ªãÁ¥π‰∫ÜÁî±Â∞àÂÆ∂Á∑®ËºØÁöÑÊ©üÂô®Áî¢ÁîüÁöÑËº∏Âá∫Âü∫Ê∫ñ (Beemo)ÔºåÂÖ∂‰∏≠ÂåÖÊã¨ 6.5k ÁØáÁî±‰∫∫È°ûÊí∞ÂØ´„ÄÅÁî±ÂçÅÂÄãÊåá‰ª§ÂæÆË™øÁöÑ LLM ÁîüÊàêÁöÑÊñáÊú¨Ôºå‰ª•ÂèäÁî±Â∞àÂÆ∂ÈáùÂ∞çÂêÑÁ®ÆÁî®‰æãÔºàÂæûÂâµÊÑèÂØ´‰ΩúÂà∞ÊëòË¶ÅÔºâÁ∑®ËºØÁöÑÊñáÊú¨„ÄÇÊ≠§Â§ñÔºåBeemo ÈÇÑÂåÖÂê´ 13.1k ÁØáÊ©üÂô®Áî¢ÁîüÁöÑÂíå LLM Á∑®ËºØÁöÑÊñáÊú¨ÔºåÂÖÅË®±Â∞çÂêÑÁ®ÆÁ∑®ËºØÈ°ûÂûãÈÄ≤Ë°åÂ§öÊ®£ÂåñÁöÑ MGT Ê™¢Ê∏¨Ë©ï‰º∞„ÄÇÊàëÂÄëË®òÈåÑ‰∫Ü Beemo ÁöÑÂâµÂª∫ÂçîË≠∞Ôºå‰∏¶Â±ïÁ§∫‰∫ÜÂú®‰∏çÂêåÂØ¶È©óË®≠ÁΩÆ‰∏≠Â∞ç 33 Á®ÆÈÖçÁΩÆÁöÑ MGT Ê™¢Ê∏¨Âô®ÈÄ≤Ë°åÂü∫Ê∫ñÊ∏¨Ë©¶ÁöÑÁµêÊûú„ÄÇÊàëÂÄëÁôºÁèæÂü∫ÊñºÂ∞àÂÆ∂ÁöÑÁ∑®ËºØÂèØ‰ª•Ë¶èÈÅø MGT Ê™¢Ê∏¨ÔºåËÄå LLM Á∑®ËºØÁöÑÊñáÊú¨‰∏çÂ§™ÂèØËÉΩË¢´Ë≠òÂà•ÁÇ∫‰∫∫Â∑•Êí∞ÂØ´ÁöÑ„ÄÇBeemo ÂíåÊâÄÊúâÊùêÊñôÈÉΩÂÖ¨ÈñãÊèê‰æõ„ÄÇ

##### **Prompt Engineering Using GPT for Word-Level Code-Mixed Language Identification in Low-Resource Dravidian Languages**
2411.04025v1 by Aniket Deroy, Subhankar Maity

Language Identification (LI) is crucial for various natural language
processing tasks, serving as a foundational step in applications such as
sentiment analysis, machine translation, and information retrieval. In
multilingual societies like India, particularly among the youth engaging on
social media, text often exhibits code-mixing, blending local languages with
English at different linguistic levels. This phenomenon presents formidable
challenges for LI systems, especially when languages intermingle within single
words. Dravidian languages, prevalent in southern India, possess rich
morphological structures yet suffer from under-representation in digital
platforms, leading to the adoption of Roman or hybrid scripts for
communication. This paper introduces a prompt based method for a shared task
aimed at addressing word-level LI challenges in Dravidian languages. In this
work, we leveraged GPT-3.5 Turbo to understand whether the large language
models is able to correctly classify words into correct categories. Our
findings show that the Kannada model consistently outperformed the Tamil model
across most metrics, indicating a higher accuracy and reliability in
identifying and categorizing Kannada language instances. In contrast, the Tamil
model showed moderate performance, particularly needing improvement in
precision and recall.

ÊëòË¶ÅÔºöË™ûË®ÄËæ®Ë≠ò (LI) Â∞çÊñºÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãôËá≥ÈóúÈáçË¶ÅÔºåÊòØÊÉÖÁ∑íÂàÜÊûê„ÄÅÊ©üÂô®ÁøªË≠ØÂíåË≥áË®äÊ™¢Á¥¢Á≠âÊáâÁî®‰∏≠ÁöÑÂü∫Á§éÊ≠•È©ü„ÄÇÂú®Âç∞Â∫¶Á≠âÂ§öË™ûË®ÄÁ§æÊúÉ‰∏≠ÔºåÁâπÂà•ÊòØÂú®ÂèÉËàáÁ§æÁæ§Â™íÈ´îÁöÑÂπ¥Ëºï‰∫∫‰∏≠ÔºåÊñáÂ≠óÁ∂ìÂ∏∏Ë°®ÁèæÂá∫Ê∑∑ÂêàË™ûË®ÄÔºåÂú®‰∏çÂêåÁöÑË™ûË®ÄÂ±§Á¥ö‰∏≠ËûçÂêà‰∫ÜÁï∂Âú∞Ë™ûË®ÄÂíåËã±Ë™û„ÄÇÈÄôÁ®ÆÁèæË±°Â∞ç LI Á≥ªÁµ±ÊßãÊàêÂö¥Â≥ªÁöÑÊåëÊà∞ÔºåÁâπÂà•ÊòØÂú®Ë™ûË®ÄÂú®ÂñÆË©û‰∏≠Ê∑∑ÂêàÊôÇ„ÄÇÂú®Âç∞Â∫¶ÂçóÈÉ®ÊµÅË°åÁöÑÈÅîÁæÖÊØóËçºË™ûÊìÅÊúâË±êÂØåÁöÑÂΩ¢ÊÖãÁµêÊßãÔºå‰ΩÜÂú®Êï∏‰ΩçÂπ≥Âè∞‰∏äÂçªÁº∫‰πè‰ª£Ë°®ÊÄßÔºåÂ∞éËá¥Êé°Áî®ÁæÖÈ¶¨ÊàñÊ∑∑ÂêàÊñáÂ≠óÈÄ≤Ë°åÊ∫ùÈÄö„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºÊèêÁ§∫ÁöÑÊñπÊ≥ïÔºåÁî®ÊñºËß£Ê±∫ÈÅîÁæÖÊØóËçºË™û‰∏≠ÂñÆË©ûÂ±§Á¥ö LI ÊåëÊà∞ÁöÑÂÖ±‰∫´‰ªªÂãô„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂà©Áî® GPT-3.5 Turbo ‰æÜ‰∫ÜËß£Â§ßÂûãË™ûË®ÄÊ®°ÂûãÊòØÂê¶ËÉΩÂ§†Â∞áÂñÆË©ûÊ≠£Á¢∫ÂàÜÈ°ûÂà∞Ê≠£Á¢∫ÁöÑÈ°ûÂà•‰∏≠„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåKannada Ê®°ÂûãÂú®Â§ßÂ§öÊï∏ÊåáÊ®ô‰∏äÂßãÁµÇÂÑ™Êñº Tamil Ê®°ÂûãÔºåÈÄôË°®ÊòéÂú®Ë≠òÂà•ÂíåÂàÜÈ°û Kannada Ë™ûË®ÄÂØ¶‰æãÊôÇÂÖ∑ÊúâÊõ¥È´òÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÂèØÈù†ÊÄß„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåTamil Ê®°ÂûãË°®ÁèæÊôÆÈÄöÔºåÁâπÂà•ÈúÄË¶ÅÂú®Á≤æÁ¢∫Â∫¶ÂíåÂè¨ÂõûÁéáÊñπÈù¢ÈÄ≤Ë°åÊîπÈÄ≤„ÄÇ

##### **Predicting and Publishing Accurate Imbalance Prices Using Monte Carlo Tree Search**
2411.04011v1 by Fabio Pavirani, Jonas Van Gompel, Seyed Soroush Karimi Madahi, Bert Claessens, Chris Develder

The growing reliance on renewable energy sources, particularly solar and
wind, has introduced challenges due to their uncontrollable production. This
complicates maintaining the electrical grid balance, prompting some
transmission system operators in Western Europe to implement imbalance tariffs
that penalize unsustainable power deviations. These tariffs create an implicit
demand response framework to mitigate grid instability. Yet, several challenges
limit active participation. In Belgium, for example, imbalance prices are only
calculated at the end of each 15-minute settlement period, creating high risk
due to price uncertainty. This risk is further amplified by the inherent
volatility of imbalance prices, discouraging participation. Although
transmission system operators provide minute-based price predictions, the
system imbalance volatility makes accurate price predictions challenging to
obtain and requires sophisticated techniques. Moreover, publishing price
estimates can prompt participants to adjust their schedules, potentially
affecting the system balance and the final price, adding further complexity. To
address these challenges, we propose a Monte Carlo Tree Search method that
publishes accurate imbalance prices while accounting for potential response
actions. Our approach models the system dynamics using a neural network
forecaster and a cluster of virtual batteries controlled by reinforcement
learning agents. Compared to Belgium's current publication method, our
technique improves price accuracy by 20.4% under ideal conditions and by 12.8%
in more realistic scenarios. This research addresses an unexplored, yet crucial
problem, positioning this paper as a pioneering work in analyzing the potential
of more advanced imbalance price publishing techniques.

ÊëòË¶ÅÔºöÈö®ËëóÂÜçÁîüËÉΩÊ∫êÔºåÁâπÂà•ÊòØÂ§™ÈôΩËÉΩÂíåÈ¢®ËÉΩÁöÑ‰ΩøÁî®Êó•Áõä‰æùË≥¥ÔºåÁî±ÊñºÂÖ∂‰∏çÂèØÊéßÁöÑÁîüÁî¢ËÄåÁî¢Áîü‰∫ÜÊåëÊà∞„ÄÇÈÄô‰ΩøÂæóÈõªÁ∂≤Âπ≥Ë°°ÁöÑÁ∂≠Ë≠∑ËÆäÂæóË§áÈõúÔºå‰øÉ‰ΩøË•øÊ≠êÁöÑ‰∏Ä‰∫õËº∏ÈõªÁ≥ªÁµ±ÈÅãÁáüÂïÜÂØ¶ÊñΩ‰∏çÂπ≥Ë°°ÈóúÁ®ÖÔºå‰ª•Êá≤ÁΩ∞‰∏çÂèØÊåÅÁ∫åÁöÑÈõªÂäõÂÅèÂ∑Æ„ÄÇÈÄô‰∫õÈóúÁ®ÖÂâµÈÄ†‰∫Ü‰∏ÄÂÄãÈö±Âê´ÁöÑÈúÄÊ±ÇÈüøÊáâÊ°ÜÊû∂Ôºå‰ª•Ê∏õËºïÈõªÁ∂≤‰∏çÁ©©ÂÆöÊÄß„ÄÇÁÑ∂ËÄåÔºå‰∏Ä‰∫õÊåëÊà∞ÈôêÂà∂‰∫ÜÁ©çÊ•µÂèÉËàá„ÄÇ‰æãÂ¶ÇÔºåÂú®ÊØîÂà©ÊôÇÔºå‰∏çÂπ≥Ë°°ÂÉπÊ†ºÂÉÖÂú®ÊØè 15 ÂàÜÈêòÁµêÁÆóÊúüÁµêÊùüÊôÇË®àÁÆóÔºåÁî±ÊñºÂÉπÊ†º‰∏çÁ¢∫ÂÆöÊÄßËÄåÈÄ†ÊàêÈ´òÈ¢®Èö™„ÄÇ‰∏çÂπ≥Ë°°ÂÉπÊ†ºÂõ∫ÊúâÁöÑÊ≥¢ÂãïÊÄßÈÄ≤‰∏ÄÊ≠•ÊîæÂ§ß‰∫ÜÈÄôÁ®ÆÈ¢®Èö™ÔºåÈòªÁ§ô‰∫ÜÂèÉËàá„ÄÇÂÑòÁÆ°Ëº∏ÈõªÁ≥ªÁµ±ÈÅãÁáüÂïÜÊèê‰æõ‰∫ÜÂü∫ÊñºÂàÜÈêòÁöÑÂÉπÊ†ºÈ†êÊ∏¨Ôºå‰ΩÜÁ≥ªÁµ±‰∏çÂπ≥Ë°°ÁöÑÊ≥¢ÂãïÊÄß‰ΩøÂæóÊ∫ñÁ¢∫ÁöÑÂÉπÊ†ºÈ†êÊ∏¨Èõ£‰ª•Áç≤ÂæóÔºå‰∏¶‰∏îÈúÄË¶ÅË§áÈõúÁöÑÊäÄË°ì„ÄÇÊ≠§Â§ñÔºåÁôºÂ∏ÉÂÉπÊ†º‰º∞Ë®àÊúÉ‰øÉ‰ΩøÂèÉËàáËÄÖË™øÊï¥ÂÖ∂ÊôÇÈñìË°®ÔºåÈÄôÂèØËÉΩÊúÉÂΩ±ÈüøÁ≥ªÁµ±Âπ≥Ë°°ÂíåÊúÄÁµÇÂÉπÊ†ºÔºåÂæûËÄåÂ¢ûÂä†ÈÄ≤‰∏ÄÊ≠•ÁöÑË§áÈõúÊÄß„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆËíôÁâπÂç°ÁæÖÊ®πÊêúÁ¥¢ÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÂú®ËÄÉÊÖÆÊΩõÂú®ÈüøÊáâÊé™ÊñΩÁöÑÂêåÊôÇÁôºÂ∏ÉÊ∫ñÁ¢∫ÁöÑ‰∏çÂπ≥Ë°°ÂÉπÊ†º„ÄÇÊàëÂÄëÁöÑËß£Ê±∫ÊñπÊ°à‰ΩøÁî®Á•ûÁ∂ìÁ∂≤Ë∑ØÈ†êÊ∏¨Âô®ÂíåÁî±Âº∑ÂåñÂ≠∏Áøí‰ª£ÁêÜÊéßÂà∂ÁöÑ‰∏ÄÁµÑËôõÊì¨ÈõªÊ±†Â∞çÁ≥ªÁµ±ÂãïÊÖãÈÄ≤Ë°åÂª∫Ê®°„ÄÇËàáÊØîÂà©ÊôÇÁõÆÂâçÁöÑÁôºÂ∏ÉÊñπÊ≥ïÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÊäÄË°ìÂú®ÁêÜÊÉ≥Ê¢ù‰ª∂‰∏ãÂ∞áÂÉπÊ†ºÊ∫ñÁ¢∫Â∫¶ÊèêÈ´ò‰∫Ü 20.4%ÔºåÂú®Êõ¥ÁèæÂØ¶ÁöÑÂ†¥ÊôØ‰∏≠ÊèêÈ´ò‰∫Ü 12.8%„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Ëß£Ê±∫‰∫Ü‰∏ÄÂÄãÂ∞öÊú™Êé¢Á¥¢‰ΩÜËá≥ÈóúÈáçË¶ÅÂïèÈ°åÔºåÂ∞áÊú¨ÊñáÂÆö‰ΩçÁÇ∫ÂàÜÊûêÊõ¥ÂÖàÈÄ≤ÁöÑ‰∏çÂπ≥Ë°°ÂÉπÊ†ºÁôºÂ∏ÉÊäÄË°ìÊΩõÂäõÁöÑÈñãÂâµÊÄßÂ∑•‰Ωú„ÄÇ

##### **Aligning Characteristic Descriptors with Images for Human-Expert-like Explainability**
2411.04008v1 by Bharat Chandra Yalavarthi, Nalini Ratha

In mission-critical domains such as law enforcement and medical diagnosis,
the ability to explain and interpret the outputs of deep learning models is
crucial for ensuring user trust and supporting informed decision-making.
Despite advancements in explainability, existing methods often fall short in
providing explanations that mirror the depth and clarity of those given by
human experts. Such expert-level explanations are essential for the dependable
application of deep learning models in law enforcement and medical contexts.
Additionally, we recognize that most explanations in real-world scenarios are
communicated primarily through natural language. Addressing these needs, we
propose a novel approach that utilizes characteristic descriptors to explain
model decisions by identifying their presence in images, thereby generating
expert-like explanations. Our method incorporates a concept bottleneck layer
within the model architecture, which calculates the similarity between image
and descriptor encodings to deliver inherent and faithful explanations. Through
experiments in face recognition and chest X-ray diagnosis, we demonstrate that
our approach offers a significant contrast over existing techniques, which are
often limited to the use of saliency maps. We believe our approach represents a
significant step toward making deep learning systems more accountable,
transparent, and trustworthy in the critical domains of face recognition and
medical diagnosis.

ÊëòË¶ÅÔºöÂú®ÊâßÊ≥ïÂíåÂåªÁñóËØäÊñ≠Á≠â‰ªªÂä°ÂÖ≥ÈîÆÂûãÈ¢ÜÂüüÔºå
Ëß£ÈáäÂíåËØ†ÈáäÊ∑±Â∫¶Â≠¶‰π†Ê®°ÂûãÁöÑËæìÂá∫ÂØπ‰∫éÁ°Æ‰øùÁî®Êà∑‰ø°‰ªªÂíåÊîØÊåÅÁü•ÊÉÖÂÜ≥Á≠ñËá≥ÂÖ≥ÈáçË¶Å„ÄÇ
Â∞ΩÁÆ°ÂèØËß£ÈáäÊÄßÊñπÈù¢ÂèñÂæó‰∫ÜËøõÊ≠•Ôºå‰ΩÜÁé∞ÊúâÊñπÊ≥ïÂú®Êèê‰æõËß£ÈáäÊó∂ÂæÄÂæÄËææ‰∏çÂà∞‰∫∫Á±ª‰∏ìÂÆ∂ÁªôÂá∫ÁöÑÊ∑±Â∫¶ÂíåÊ∏ÖÊô∞Â∫¶„ÄÇËøôÁßç‰∏ìÂÆ∂Á∫ßÂà´ÁöÑËß£ÈáäÂØπ‰∫éÂú®ÊâßÊ≥ïÂíåÂåªÁñóÁéØÂ¢É‰∏≠ÂèØÈù†Âú∞Â∫îÁî®Ê∑±Â∫¶Â≠¶‰π†Ê®°ÂûãËá≥ÂÖ≥ÈáçË¶Å„ÄÇ
Ê≠§Â§ñÔºåÊàë‰ª¨ËÆ§ËØÜÂà∞ÔºåÂú®Áé∞ÂÆû‰∏ñÁïåÂú∫ÊôØ‰∏≠ÔºåÂ§ßÂ§öÊï∞Ëß£Èáä‰∏ªË¶ÅÊòØÈÄöËøáËá™ÁÑ∂ËØ≠Ë®ÄËøõË°å‰∫§ÊµÅÁöÑ„ÄÇ‰∏∫‰∫ÜÊª°Ë∂≥Ëøô‰∫õÈúÄÊ±ÇÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÊñπÊ≥ïÔºåËØ•ÊñπÊ≥ïÂà©Áî®ÁâπÂæÅÊèèËø∞Á¨¶ÈÄöËøáËØÜÂà´ÂõæÂÉè‰∏≠ÁöÑÁâπÂæÅÊèèËø∞Á¨¶ÁöÑÂ≠òÂú®Êù•Ëß£ÈáäÊ®°ÂûãÂÜ≥Á≠ñÔºå‰ªéËÄåÁîüÊàêÁ±ª‰ºº‰∏ìÂÆ∂ÁöÑËß£Èáä„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®Ê®°ÂûãÊû∂ÊûÑ‰∏≠Âä†ÂÖ•‰∫Ü‰∏Ä‰∏™Ê¶ÇÂøµÁì∂È¢àÂ±ÇÔºåËØ•Â±ÇËÆ°ÁÆóÂõæÂÉèÂíåÊèèËø∞Á¨¶ÁºñÁ†Å‰πãÈó¥ÁöÑÁõ∏‰ººÊÄßÔºå‰ª•Êèê‰æõÂÜÖÂú®‰∏îÂèØÈù†ÁöÑËß£Èáä„ÄÇÈÄöËøáÈù¢ÈÉ®ËØÜÂà´ÂíåËÉ∏ÈÉ® X Â∞ÑÁ∫øËØäÊñ≠ÁöÑÂÆûÈ™åÔºåÊàë‰ª¨ËØÅÊòé‰∫ÜÊàë‰ª¨ÁöÑÊñπÊ≥ï‰∏éÁé∞ÊúâÊäÄÊúØÁõ∏ÊØîÂÖ∑ÊúâÊòæÁùÄ‰ºòÂäøÔºåËÄåÁé∞ÊúâÊäÄÊúØÈÄöÂ∏∏‰ªÖÈôê‰∫é‰ΩøÁî®ÊòæÁùÄÊÄßÂõæ„ÄÇÊàë‰ª¨Áõ∏‰ø°ÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ï‰ª£Ë°®‰∫ÜÊúùÁùÄ‰ΩøÊ∑±Â∫¶Â≠¶‰π†Á≥ªÁªüÂú®Èù¢ÈÉ®ËØÜÂà´ÂíåÂåªÁñóËØäÊñ≠ÁöÑÂÖ≥ÈîÆÈ¢ÜÂüüÊõ¥Âä†Ë¥üË¥£„ÄÅÈÄèÊòéÂíåÂÄºÂæó‰ø°ËµñËøàÂá∫ÁöÑÈáçË¶Å‰∏ÄÊ≠•„ÄÇ

##### **Select2Plan: Training-Free ICL-Based Planning through VQA and Memory Retrieval**
2411.04006v1 by Davide Buoso, Luke Robinson, Giuseppe Averta, Philip Torr, Tim Franzmeyer, Daniele De Martini

This study explores the potential of off-the-shelf Vision-Language Models
(VLMs) for high-level robot planning in the context of autonomous navigation.
Indeed, while most of existing learning-based approaches for path planning
require extensive task-specific training/fine-tuning, we demonstrate how such
training can be avoided for most practical cases. To do this, we introduce
Select2Plan (S2P), a novel training-free framework for high-level robot
planning which completely eliminates the need for fine-tuning or specialised
training. By leveraging structured Visual Question-Answering (VQA) and
In-Context Learning (ICL), our approach drastically reduces the need for data
collection, requiring a fraction of the task-specific data typically used by
trained models, or even relying only on online data. Our method facilitates the
effective use of a generally trained VLM in a flexible and cost-efficient way,
and does not require additional sensing except for a simple monocular camera.
We demonstrate its adaptability across various scene types, context sources,
and sensing setups. We evaluate our approach in two distinct scenarios:
traditional First-Person View (FPV) and infrastructure-driven Third-Person View
(TPV) navigation, demonstrating the flexibility and simplicity of our method.
Our technique significantly enhances the navigational capabilities of a
baseline VLM of approximately 50% in TPV scenario, and is comparable to trained
models in the FPV one, with as few as 20 demonstrations.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÁèæÊàêÁöÑË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) Âú®Ëá™‰∏ªÂ∞éËà™ËÉåÊôØ‰∏ãÁî®ÊñºÈ´òÈöéÊ©üÂô®‰∫∫Ë¶èÂäÉÁöÑÊΩõÂäõ„ÄÇÁöÑÁ¢∫ÔºåÈõñÁÑ∂ÁèæÊúâÁöÑÂü∫ÊñºÂ≠∏ÁøíÁöÑË∑ØÂæëË¶èÂäÉÊñπÊ≥ïÂ§ßÂ§öÈúÄË¶ÅÂ§ßÈáèÁöÑÁâπÂÆö‰ªªÂãôË®ìÁ∑¥/ÂæÆË™øÔºå‰ΩÜÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂú®Â§ßÈÉ®ÂàÜÂØ¶ÈöõÊ°à‰æã‰∏≠Â¶Ç‰ΩïÈÅøÂÖçÈÄôÁ®ÆË®ìÁ∑¥„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü Select2Plan (S2P)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÁî®ÊñºÈ´òÈöéÊ©üÂô®‰∫∫Ë¶èÂäÉÁöÑÊñ∞ÂûãÂÖçË®ìÁ∑¥Ê°ÜÊû∂ÔºåÂÆÉÂÆåÂÖ®Ê∂àÈô§‰∫ÜÂæÆË™øÊàñÂ∞àÈñÄË®ìÁ∑¥ÁöÑÈúÄË¶Å„ÄÇÈÄöÈÅéÂà©Áî®ÁµêÊßãÂåñÁöÑË¶ñË¶∫ÂïèÁ≠î (VQA) ÂíåË™ûÂ¢ÉÂ≠∏Áøí (ICL)ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂ§ßÂπÖÊ∏õÂ∞ë‰∫ÜÂ∞çÊï∏ÊìöÊî∂ÈõÜÁöÑÈúÄÊ±ÇÔºåÂè™ÈúÄË¶ÅË®ìÁ∑¥Ê®°ÂûãÈÄöÂ∏∏‰ΩøÁî®ÁöÑÁâπÂÆö‰ªªÂãôÊï∏ÊìöÁöÑ‰∏ÄÂ∞èÈÉ®ÂàÜÔºåÁîöËá≥Âè™‰æùË≥¥ÊñºÂú®Á∑öÊï∏Êìö„ÄÇÊàëÂÄëÁöÑËæ¶Ê≥ï‰øÉÈÄ≤‰∫Ü‰ª•ÈùàÊ¥ª‰∏îÂÖ∑ÊúâÊàêÊú¨ÊïàÁõäÁöÑÊñπÂºèÊúâÊïà‰ΩøÁî®Á∂ìÈÅé‰∏ÄËà¨Ë®ìÁ∑¥ÁöÑ VLMÔºå‰∏¶‰∏îÈô§‰∫ÜÁ∞°ÂñÆÁöÑÂñÆÁõÆÁõ∏Ê©üÂ§ñÔºå‰∏çÈúÄË¶ÅÈ°çÂ§ñÁöÑÊÑüÊ∏¨„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂÆÉÂ∞çÂêÑÁ®ÆÂ†¥ÊôØÈ°ûÂûã„ÄÅ‰∏ä‰∏ãÊñá‰æÜÊ∫êÂíåÊÑüÊ∏¨Ë®≠ÂÆöÁöÑÈÅ©ÊáâÊÄß„ÄÇÊàëÂÄëÂú®ÂÖ©Á®Æ‰∏çÂêåÁöÑÂ†¥ÊôØ‰∏≠Ë©ï‰º∞‰∫ÜÊàëÂÄëÁöÑÂÅöÊ≥ïÔºöÂÇ≥Áµ±ÁöÑÁ¨¨‰∏Ä‰∫∫Á®±Ë¶ñËßí (FPV) ÂíåÂü∫Á§éË®≠ÊñΩÈ©ÖÂãïÁöÑÁ¨¨‰∏â‰∫∫Á®±Ë¶ñËßí (TPV) Â∞éËà™ÔºåÂ±ïÁ§∫‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÈùàÊ¥ªÊÄßËàáÁ∞°ÊΩîÊÄß„ÄÇÊàëÂÄëÁöÑÊäÄË°ìÈ°ØËëóÂ¢ûÂº∑‰∫Ü TPV Â†¥ÊôØ‰∏≠Á¥Ñ 50% ÁöÑÂü∫Ê∫ñ VLM ÁöÑÂ∞éËà™ËÉΩÂäõÔºå‰∏¶‰∏îÂú® FPV Â†¥ÊôØ‰∏≠ËàáË®ìÁ∑¥Ê®°ÂûãÁõ∏Áï∂ÔºåÂÉÖÈúÄ 20 Ê¨°Á§∫ÁØÑ„ÄÇ

##### **Towards Resource-Efficient Federated Learning in Industrial IoT for Multivariate Time Series Analysis**
2411.03996v1 by Alexandros Gkillas, Aris Lalos

Anomaly and missing data constitute a thorny problem in industrial
applications. In recent years, deep learning enabled anomaly detection has
emerged as a critical direction, however the improved detection accuracy is
achieved with the utilization of large neural networks, increasing their
storage and computational cost. Moreover, the data collected in edge devices
contain user privacy, introducing challenges that can be successfully addressed
by the privacy-preserving distributed paradigm, known as federated learning
(FL). This framework allows edge devices to train and exchange models
increasing also the communication cost. Thus, to deal with the increased
communication, processing and storage challenges of the FL based deep anomaly
detection NN pruning is expected to have significant benefits towards reducing
the processing, storage and communication complexity. With this focus, a novel
compression-based optimization problem is proposed at the server-side of a FL
paradigm that fusses the received local models broadcast and performs pruning
generating a more compressed model. Experiments in the context of anomaly
detection and missing value imputation demonstrate that the proposed FL
scenario along with the proposed compressed-based method are able to achieve
high compression rates (more than $99.7\%$) with negligible performance losses
(less than $1.18\%$ ) as compared to the centralized solutions.

ÊëòË¶ÅÔºöÁï∞Â∏∏ÂíåÈÅ∫Â§±Ë≥áÊñôÂú®Â∑•Ê•≠ÊáâÁî®‰∏≠ÊßãÊàêÊ£òÊâãÁöÑÂïèÈ°å„ÄÇËøëÂπ¥‰æÜÔºåÊ∑±Â∫¶Â≠∏ÁøíÂïüÁî®ÁöÑÁï∞Â∏∏ÂÅµÊ∏¨Â∑≤ÊàêÁÇ∫‰∏ÄÂÄãÈáçË¶ÅÁöÑÊñπÂêëÔºåÁÑ∂ËÄåÔºåÊîπÈÄ≤ÁöÑÂÅµÊ∏¨Ê∫ñÁ¢∫Â∫¶ÊòØÈÄèÈÅéÂà©Áî®Â§ßÂûãÁ•ûÁ∂ìÁ∂≤Ë∑Ø‰æÜÂØ¶ÁèæÔºåÂ¢ûÂä†‰∫ÜÂÆÉÂÄëÁöÑÂÑ≤Â≠òÂíåÈÅãÁÆóÊàêÊú¨„ÄÇÊ≠§Â§ñÔºåÂú®ÈÇäÁ∑£Ë£ùÁΩÆ‰∏≠Êî∂ÈõÜÁöÑË≥áÊñôÂåÖÂê´‰ΩøÁî®ËÄÖÈö±ÁßÅÔºåÂºïÂÖ•‰∫ÜÊåëÊà∞ÔºåÈÄô‰∫õÊåëÊà∞ÂèØÈÄèÈÅéÁ®±ÁÇ∫ËÅØÂêàÂ≠∏Áøí (FL) ÁöÑÈö±ÁßÅ‰øùË≠∑ÂàÜÊï£ÂºèÁØÑ‰æã‰æÜÊàêÂäüËß£Ê±∫„ÄÇÊ≠§Êû∂ÊßãÂÖÅË®±ÈÇäÁ∑£Ë£ùÁΩÆË®ìÁ∑¥Âíå‰∫§ÊèõÊ®°ÂûãÔºåÂêåÊôÇ‰πüÂ¢ûÂä†‰∫ÜÈÄöË®äÊàêÊú¨„ÄÇÂõ†Ê≠§ÔºåÁÇ∫‰∫ÜÊáâÂ∞ç FL Âü∫ÊñºÊ∑±Â∫¶Áï∞Â∏∏ÂÅµÊ∏¨ÁöÑÈÄöË®ä„ÄÅËôïÁêÜÂíåÂÑ≤Â≠òÊåëÊà∞ÔºåÈ†êË®à NN Ââ™ÊûùÂ∞áÂ∞çÈôç‰ΩéËôïÁêÜ„ÄÅÂÑ≤Â≠òÂíåÈÄöË®äË§áÈõúÂ∫¶ÊúâÈ°ØËëóÁöÑÂ•ΩËôï„ÄÇÂü∫ÊñºÊ≠§ÈáçÈªûÔºåÂú® FL ÁØÑ‰æãÁöÑ‰º∫ÊúçÂô®Á´ØÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂü∫ÊñºÂ£ìÁ∏ÆÁöÑÊúÄ‰Ω≥ÂåñÂïèÈ°åÔºåÂÆÉÊúÉÊ∑∑Ê∑ÜÊé•Êî∂Âà∞ÁöÑÊú¨Âú∞Ê®°ÂûãÂª£Êí≠‰∏¶Âü∑Ë°åÂâ™ÊûùÔºåÁî¢Áîü‰∏ÄÂÄãÊõ¥Â£ìÁ∏ÆÁöÑÊ®°Âûã„ÄÇÂú®Áï∞Â∏∏ÂÅµÊ∏¨ÂíåÈÅ∫Â§±ÂÄºÂ°´Ë£úÁöÑËÉåÊôØ‰∏ãÈÄ≤Ë°åÁöÑÂØ¶È©óË≠âÊòéÔºåÊâÄÊèêÂá∫ÁöÑ FL Â†¥ÊôØÈÄ£ÂêåÊâÄÊèêÂá∫ÁöÑÂü∫ÊñºÂ£ìÁ∏ÆÁöÑÊñπÊ≥ïËÉΩÂ§†ÂØ¶ÁèæÈ´òÂ£ìÁ∏ÆÁéáÔºàË∂ÖÈÅé 99.7%ÔºâÔºåËÄåÊïàËÉΩÊêçÂ§±ÂèØ‰ª•ÂøΩÁï•‰∏çË®àÔºàÂ∞èÊñº 1.18%ÔºâÔºåËàáÈõÜ‰∏≠ÂºèËß£Ê±∫ÊñπÊ°àÁõ∏ÊØî„ÄÇ

##### **WorryWords: Norms of Anxiety Association for over 44k English Words**
2411.03966v1 by Saif M. Mohammad

Anxiety, the anticipatory unease about a potential negative outcome, is a
common and beneficial human emotion. However, there is still much that is not
known, such as how anxiety relates to our body and how it manifests in
language. This is especially pertinent given the increasing impact of
anxiety-related disorders. In this work, we introduce WorryWords, the first
large-scale repository of manually derived word--anxiety associations for over
44,450 English words. We show that the anxiety associations are highly
reliable. We use WorryWords to study the relationship between anxiety and other
emotion constructs, as well as the rate at which children acquire anxiety words
with age. Finally, we show that using WorryWords alone, one can accurately
track the change of anxiety in streams of text. The lexicon enables a wide
variety of anxiety-related research in psychology, NLP, public health, and
social sciences. WorryWords (and its translations to over 100 languages) is
freely available. http://saifmohammad.com/worrywords.html

ÊëòË¶ÅÔºöÁÑ¶ÊÖÆÔºåÂ∞çÊΩõÂú®Ë≤†Èù¢ÁµêÊûúÁöÑÈ†êÊúü‰∏çÂÆâÔºåÊòØ‰∏ÄÁ®ÆÂ∏∏Ë¶ã‰∏îÊúâÁõäÁöÑ‰∫∫È°ûÊÉÖÁ∑í„ÄÇÁÑ∂ËÄåÔºå‰ªçÊúâË®±Â§öÊú™Áü•Ôºå‰æãÂ¶ÇÁÑ¶ÊÖÆÂ¶Ç‰ΩïËàáÊàëÂÄëÁöÑË∫´È´îÁõ∏ÈóúÔºå‰ª•ÂèäÂÆÉÂ¶Ç‰ΩïÂú®Ë™ûË®Ä‰∏≠Ë°®ÁèæÂá∫‰æÜ„ÄÇÈÄô‰∏ÄÈªûÂ∞§ÂÖ∂ÈáçË¶ÅÔºåÂõ†ÁÇ∫ËàáÁÑ¶ÊÖÆÁõ∏ÈóúÁöÑÁñæÁóÖÂΩ±ÈüøË∂ä‰æÜË∂äÂ§ß„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü WorryWordsÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂ§ßË¶èÊ®°ÁöÑ‰∫∫Â∑•Ê¥æÁîüË©ûÂΩô‚Äî‚ÄîÁÑ¶ÊÖÆÈóúËÅØÂÑ≤Â≠òÂ∫´ÔºåÂåÖÂê´Ë∂ÖÈÅé 44,450 ÂÄãËã±ÊñáÂñÆÂ≠ó„ÄÇÊàëÂÄëË≠âÊòé‰∫ÜÁÑ¶ÊÖÆÈóúËÅØÂÖ∑ÊúâÈ´òÂ∫¶ÂèØÈù†ÊÄß„ÄÇÊàëÂÄë‰ΩøÁî® WorryWords ‰æÜÁ†îÁ©∂ÁÑ¶ÊÖÆËàáÂÖ∂‰ªñÊÉÖÁ∑íÂª∫Êßã‰πãÈñìÁöÑÈóú‰øÇÔºå‰ª•ÂèäÂÖíÁ´•Èö®ËëóÂπ¥ÈΩ°Â¢ûÈï∑ËÄåÁøíÂæóÁÑ¶ÊÖÆË©ûÂΩôÁöÑÈÄüÂ∫¶„ÄÇÊúÄÂæåÔºåÊàëÂÄëË≠âÊòé‰∫ÜÂÉÖ‰ΩøÁî® WorryWordsÔºåÂ∞±ÂèØ‰ª•Ê∫ñÁ¢∫ËøΩËπ§ÊñáÂ≠ó‰∏≤ÊµÅ‰∏≠ÁöÑÁÑ¶ÊÖÆËÆäÂåñ„ÄÇÊ≠§Ë©ûÂΩôË°®‰ΩøÂøÉÁêÜÂ≠∏„ÄÅËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ„ÄÅÂÖ¨ÂÖ±Ë°õÁîüÂíåÁ§æÊúÉÁßëÂ≠∏‰∏≠ÂêÑÁ®ÆËàáÁÑ¶ÊÖÆÁõ∏ÈóúÁöÑÁ†îÁ©∂ÊàêÁÇ∫ÂèØËÉΩ„ÄÇWorryWordsÔºàÂèäÂÖ∂ÁøªË≠ØÊàê 100 Â§öÁ®ÆË™ûË®ÄÔºâÊòØÂÖçË≤ªÊèê‰æõÁöÑ„ÄÇhttp://saifmohammad.com/worrywords.html

##### **What Really is Commonsense Knowledge?**
2411.03964v1 by Quyet V. Do, Junze Li, Tung-Duong Vuong, Zhaowei Wang, Yangqiu Song, Xiaojuan Ma

Commonsense datasets have been well developed in Natural Language Processing,
mainly through crowdsource human annotation. However, there are debates on the
genuineness of commonsense reasoning benchmarks. In specific, a significant
portion of instances in some commonsense benchmarks do not concern commonsense
knowledge. That problem would undermine the measurement of the true commonsense
reasoning ability of evaluated models. It is also suggested that the problem
originated from a blurry concept of commonsense knowledge, as distinguished
from other types of knowledge. To demystify all of the above claims, in this
study, we survey existing definitions of commonsense knowledge, ground into the
three frameworks for defining concepts, and consolidate them into a
multi-framework unified definition of commonsense knowledge (so-called
consolidated definition). We then use the consolidated definition for
annotations and experiments on the CommonsenseQA and CommonsenseQA 2.0 datasets
to examine the above claims. Our study shows that there exists a large portion
of non-commonsense-knowledge instances in the two datasets, and a large
performance gap on these two subsets where Large Language Models (LLMs) perform
worse on commonsense-knowledge instances.

ÊëòË¶ÅÔºöÂ∏∏ËØÜÊï∞ÊçÆÈõÜÂú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ‰∏≠ÂæóÂà∞ÂæàÂ•ΩÁöÑÂèëÂ±ïÔºå‰∏ªË¶ÅÊòØÈÄöËøá‰ºóÂåÖ‰∫∫Â∑•Ê≥®Èáä„ÄÇÁÑ∂ËÄåÔºåÂÖ≥‰∫éÂ∏∏ËØÜÊé®ÁêÜÂü∫ÂáÜÁöÑÁúüÂÆûÊÄßÂ≠òÂú®‰∫âËÆ∫„ÄÇÂÖ∑‰ΩìÊù•ËØ¥Ôºå‰∏Ä‰∫õÂ∏∏ËØÜÂü∫ÂáÜ‰∏≠ÁöÑÂ§ßÈáèÂÆû‰æãÂπ∂‰∏çÊ∂âÂèäÂ∏∏ËØÜÁü•ËØÜ„ÄÇËØ•ÈóÆÈ¢òÂ∞ÜÊçüÂÆ≥ÂØπËØÑ‰º∞Ê®°ÂûãÁöÑÁúüÂÆûÂ∏∏ËØÜÊé®ÁêÜËÉΩÂäõÁöÑË°°Èáè„ÄÇËøòÊèêÂá∫ÔºåËØ•ÈóÆÈ¢òÊ∫ê‰∫éÂØπÂ∏∏ËØÜÁü•ËØÜÁöÑÊ®°Á≥äÊ¶ÇÂøµÔºå‰∏éÂÖ∂‰ªñÁ±ªÂûãÁöÑÁü•ËØÜÁõ∏Âå∫Âà´„ÄÇ‰∏∫‰∫ÜÊè≠ÂºÄ‰∏äËø∞ÊâÄÊúâËØ¥Ê≥ïÁöÑÁ•ûÁßòÈù¢Á∫±ÔºåÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàë‰ª¨Ë∞ÉÊü•‰∫ÜÂ∏∏ËØÜÁü•ËØÜÁöÑÁé∞ÊúâÂÆö‰πâÔºåÂ∞ÜÂÖ∂ÂΩíÁ∫≥‰∏∫ÂÆö‰πâÊ¶ÇÂøµÁöÑ‰∏â‰∏™Ê°ÜÊû∂ÔºåÂπ∂Â∞ÜÂÆÉ‰ª¨Êï¥ÂêàÂà∞Â∏∏ËØÜÁü•ËØÜÁöÑÂ§öÊ°ÜÊû∂Áªü‰∏ÄÂÆö‰πâ‰∏≠ÔºàÂç≥ÊâÄË∞ìÁöÑÁªºÂêàÂÆö‰πâÔºâ„ÄÇÁÑ∂ÂêéÔºåÊàë‰ª¨ÂØπ CommonsenseQA Âíå CommonsenseQA 2.0 Êï∞ÊçÆÈõÜ‰ΩøÁî®ÁªºÂêàÂÆö‰πâËøõË°åÊ≥®ÈáäÂíåÂÆûÈ™åÔºå‰ª•Ê£ÄÈ™å‰∏äËø∞ËØ¥Ê≥ï„ÄÇÊàë‰ª¨ÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåËøô‰∏§‰∏™Êï∞ÊçÆÈõÜ‰∏≠Â≠òÂú®Â§ßÈáèÁöÑÈùûÂ∏∏ËØÜÁü•ËØÜÂÆû‰æãÔºåÂπ∂‰∏îÂú®Ëøô‰∏§‰∏™Â≠êÈõÜ‰∏äÂ≠òÂú®ËæÉÂ§ßÁöÑÊÄßËÉΩÂ∑ÆË∑ùÔºåÂÖ∂‰∏≠Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) Âú®Â∏∏ËØÜÁü•ËØÜÂÆû‰æã‰∏äÁöÑË°®Áé∞ËæÉÂ∑Æ„ÄÇ

##### **How Does A Text Preprocessing Pipeline Affect Ontology Syntactic Matching?**
2411.03962v1 by Zhangcheng Qiang, Kerry Taylor, Weiqing Wang

The generic text preprocessing pipeline, comprising Tokenisation,
Normalisation, Stop Words Removal, and Stemming/Lemmatisation, has been
implemented in many ontology matching (OM) systems. However, the lack of
standardisation in text preprocessing creates diversity in mapping results. In
this paper, we investigate the effect of the text preprocessing pipeline on OM
tasks at syntactic levels. Our experiments on 8 Ontology Alignment Evaluation
Initiative (OAEI) track repositories with 49 distinct alignments indicate: (1)
Tokenisation and Normalisation are currently more effective than Stop Words
Removal and Stemming/Lemmatisation; and (2) The selection of Lemmatisation and
Stemming is task-specific. We recommend standalone Lemmatisation or Stemming
with post-hoc corrections. We find that (3) Porter Stemmer and Snowball Stemmer
perform better than Lancaster Stemmer; and that (4) Part-of-Speech (POS)
Tagging does not help Lemmatisation. To repair less effective Stop Words
Removal and Stemming/Lemmatisation used in OM tasks, we propose a novel
context-based pipeline repair approach that significantly improves matching
correctness and overall matching performance. We also discuss the use of text
preprocessing pipeline in the new era of large language models (LLMs).

ÊëòË¶ÅÔºöÈÄöÁî®ÁöÑÊñáÂ≠óÈ†êËôïÁêÜÁÆ°Á∑öÔºåÂåÖÂê´Êñ∑Ë©û„ÄÅÊ≠£Ë¶èÂåñ„ÄÅÂÅúÁî®Ë©ûÁßªÈô§Ôºå‰ª•ÂèäË©ûÂππÂåñ/Ë©ûÂΩ¢ÈÇÑÂéüÔºåÂ∑≤Âú®Ë®±Â§öÊú¨‰ΩìÂ∞çÊáâ (OM) Á≥ªÁµ±‰∏≠ÂØ¶‰Ωú„ÄÇÁÑ∂ËÄåÔºåÊñáÂ≠óÈ†êËôïÁêÜÁº∫‰πèÊ®ôÊ∫ñÂåñÔºåÂ∞éËá¥Â∞çÊáâÁµêÊûúÂá∫ÁèæÂ∑ÆÁï∞ÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éÊñáÂ≠óÈ†êËôïÁêÜÁÆ°Á∑öÂ∞çÂè•Ê≥ïÂ±§Á¥ö OM ‰ªªÂãôÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÈáùÂ∞ç 8 ÂÄãÊú¨‰ΩìÂ∞çÈΩäË©ï‰º∞Ë®àÁï´ (OAEI) ËøΩËπ§ÂÑ≤Â≠òÂ∫´ÈÄ≤Ë°åÂØ¶È©óÔºåÂÖ∂‰∏≠ÂåÖÂê´ 49 ÂÄã‰∏çÂêåÁöÑÂ∞çÈΩäÔºåÁµêÊûúÈ°ØÁ§∫Ôºö(1) Êñ∑Ë©ûÂíåÊ≠£Ë¶èÂåñÁõÆÂâçÊØîÂÅúÁî®Ë©ûÁßªÈô§ÂíåË©ûÂππÂåñ/Ë©ûÂΩ¢ÈÇÑÂéüÊõ¥ÊúâÊïàÔºõ(2) Ë©ûÂΩ¢ÈÇÑÂéüÂíåË©ûÂππÂåñÁöÑÈÅ∏ÊìáÂèñÊ±∫Êñº‰ªªÂãô„ÄÇÊàëÂÄëÂª∫Ë≠∞‰ΩøÁî®Áç®Á´ãÁöÑË©ûÂΩ¢ÈÇÑÂéüÊàñË©ûÂππÂåñÔºå‰∏¶ÈÄ≤Ë°å‰∫ãÂæå‰øÆÊ≠£„ÄÇÊàëÂÄëÁôºÁèæÔºö(3) Porter Ë©ûÂππÂàÜÊûêÂô®Âíå Snowball Ë©ûÂππÂàÜÊûêÂô®ÁöÑË°®ÁèæÊØî Lancaster Ë©ûÂππÂàÜÊûêÂô®Â•ΩÔºõ(4) Ë©ûÊÄßÊ®ôË®òÂ∞çË©ûÂΩ¢ÈÇÑÂéüÊ≤íÊúâÂπ´Âä©„ÄÇÁÇ∫‰∫Ü‰øÆÂæ©Âú® OM ‰ªªÂãô‰∏≠‰ΩøÁî®ÊïàÊûúËºÉÂ∑ÆÁöÑÂÅúÁî®Ë©ûÁßªÈô§ÂíåË©ûÂππÂåñ/Ë©ûÂΩ¢ÈÇÑÂéüÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÂü∫ÊñºËÑàÁµ°ÁöÑÁÆ°Á∑ö‰øÆÂæ©ÊñπÊ≥ïÔºåÂèØÈ°ØËëóÊèêÂçáÂ∞çÊáâÊ≠£Á¢∫ÊÄßÂíåÊï¥È´îÂ∞çÊáâÊïàËÉΩ„ÄÇÊàëÂÄë‰πüË®éË´ñ‰∫ÜÂú®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊñ∞ÊôÇ‰ª£‰∏≠ÔºåÊñáÂ≠óÈ†êËôïÁêÜÁÆ°Á∑öÁöÑÊáâÁî®„ÄÇ

##### **Energy Score-based Pseudo-Label Filtering and Adaptive Loss for Imbalanced Semi-supervised SAR target recognition**
2411.03959v1 by Xinzheng Zhang, Yuqing Luo, Guopeng Li

Automatic target recognition (ATR) is an important use case for synthetic
aperture radar (SAR) image interpretation. Recent years have seen significant
advancements in SAR ATR technology based on semi-supervised learning. However,
existing semi-supervised SAR ATR algorithms show low recognition accuracy in
the case of class imbalance. This work offers a non-balanced semi-supervised
SAR target recognition approach using dynamic energy scores and adaptive loss.
First, an energy score-based method is developed to dynamically select
unlabeled samples near to the training distribution as pseudo-labels during
training, assuring pseudo-label reliability in long-tailed distribution
circumstances. Secondly, loss functions suitable for class imbalances are
proposed, including adaptive margin perception loss and adaptive hard triplet
loss, the former offsets inter-class confusion of classifiers, alleviating the
imbalance issue inherent in pseudo-label generation. The latter effectively
tackles the model's preference for the majority class by focusing on complex
difficult samples during training. Experimental results on extremely imbalanced
SAR datasets demonstrate that the proposed method performs well under the dual
constraints of scarce labels and data imbalance, effectively overcoming the
model bias caused by data imbalance and achieving high-precision target
recognition.

ÊëòË¶ÅÔºöËá™ÂãïÁõÆÊ®ôËæ®Ë≠ò (ATR) ÊòØÂêàÊàêÂ≠îÂæëÈõ∑ÈÅî (SAR) ÂΩ±ÂÉèÂà§ËÆÄÁöÑÈáçË¶Å‰ΩøÁî®Ê°à‰æã„ÄÇËøëÂπ¥‰æÜÔºåÂü∫ÊñºÂçäÁõ£Áù£Â≠∏ÁøíÁöÑ SAR ATR ÊäÄË°ìÊúâÈ°ØËëóÈÄ≤Â±ï„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÂçäÁõ£Áù£ SAR ATR ÊºîÁÆóÊ≥ïÂú®È°ûÂà•‰∏çÂπ≥Ë°°ÁöÑÊÉÖÊ≥Å‰∏ãÔºåËæ®Ë≠òÊ∫ñÁ¢∫Â∫¶‰Ωé„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄã‰ΩøÁî®ÂãïÊÖãËÉΩÈáèÂàÜÊï∏ÂíåËá™ÈÅ©ÊáâÊêçÂ§±ÁöÑÈùûÂπ≥Ë°°ÂçäÁõ£Áù£ SAR ÁõÆÊ®ôËæ®Ë≠òÊñπÊ≥ï„ÄÇÈ¶ñÂÖàÔºåÈñãÁôº‰∏ÄÂÄãÂü∫ÊñºËÉΩÈáèÂàÜÊï∏ÁöÑÊñπÊ≥ïÔºåÂú®Ë®ìÁ∑¥ÈÅéÁ®ã‰∏≠ÂãïÊÖãÈÅ∏ÊìáÊé•ËøëË®ìÁ∑¥ÂàÜ‰ΩàÁöÑÊú™Ê®ôÁ±§Ê®£Êú¨‰ΩúÁÇ∫ÂÅΩÊ®ôÁ±§ÔºåÁ¢∫‰øùÂú®Èï∑Â∞æÂàÜ‰ΩàÊÉÖÊ≥Å‰∏ãÂÅΩÊ®ôÁ±§ÁöÑÂèØÈù†ÊÄß„ÄÇÂÖ∂Ê¨°ÔºåÊèêÂá∫ÈÅ©Áî®ÊñºÈ°ûÂà•‰∏çÂπ≥Ë°°ÁöÑÊêçÂ§±ÂáΩÊï∏ÔºåÂåÖÊã¨Ëá™ÈÅ©ÊáâÈÇäÈöõÊÑüÁü•ÊêçÂ§±ÂíåËá™ÈÅ©ÊáâÁ°¨‰∏âÂÖÉÁµÑÊêçÂ§±ÔºåÂâçËÄÖÊäµÊ∂àÂàÜÈ°ûÂô®ÁöÑÈ°ûÈñìÊ∑∑Ê∑ÜÔºåÁ∑©Ëß£ÂÅΩÊ®ôÁ±§ÁîüÊàê‰∏≠Âõ∫ÊúâÁöÑ‰∏çÂπ≥Ë°°ÂïèÈ°å„ÄÇÂæåËÄÖÈÄèÈÅéÂú®Ë®ìÁ∑¥ÈÅéÁ®ã‰∏≠Â∞àÊ≥®ÊñºË§áÈõúÁöÑÂõ∞Èõ£Ê®£Êú¨ÔºåÊúâÊïàËß£Ê±∫Ê®°ÂûãÂ∞çÂ§öÊï∏È°ûÂà•ÁöÑÂÅèÂ•Ω„ÄÇÂú®Ê•µÂ∫¶‰∏çÂπ≥Ë°°ÁöÑ SAR Ë≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®Ê®ôÁ±§Á®ÄÂ∞ëÂíåË≥áÊñô‰∏çÂπ≥Ë°°ÁöÑÈõôÈáçÁ¥ÑÊùü‰∏ãË°®ÁèæËâØÂ•ΩÔºåÊúâÊïàÂÖãÊúçË≥áÊñô‰∏çÂπ≥Ë°°ÈÄ†ÊàêÁöÑÊ®°ÂûãÂÅèË™§Ôºå‰∏¶ÂØ¶ÁèæÈ´òÁ≤æÂ∫¶ÁöÑÁõÆÊ®ôËæ®Ë≠ò„ÄÇ

##### **Fine-Grained Guidance for Retrievers: Leveraging LLMs' Feedback in Retrieval-Augmented Generation**
2411.03957v1 by Yuhang Liu, Xueyu Hu, Shengyu Zhang, Jingyuan Chen, Fan Wu, Fei Wu

Retrieval-Augmented Generation (RAG) has proven to be an effective method for
mitigating hallucination issues inherent in large language models (LLMs).
Previous approaches typically train retrievers based on semantic similarity,
lacking optimization for RAG. More recent works have proposed aligning
retrievers with the preference signals of LLMs. However, these preference
signals are often difficult for dense retrievers, which typically have weaker
language capabilities, to understand and learn effectively. Drawing inspiration
from pedagogical theories like Guided Discovery Learning, we propose a novel
framework, FiGRet (Fine-grained Guidance for Retrievers), which leverages the
language capabilities of LLMs to construct examples from a more granular,
information-centric perspective to guide the learning of retrievers.
Specifically, our method utilizes LLMs to construct easy-to-understand examples
from samples where the retriever performs poorly, focusing on three learning
objectives highly relevant to the RAG scenario: relevance, comprehensiveness,
and purity. These examples serve as scaffolding to ultimately align the
retriever with the LLM's preferences. Furthermore, we employ a dual curriculum
learning strategy and leverage the reciprocal feedback between LLM and
retriever to further enhance the performance of the RAG system. A series of
experiments demonstrate that our proposed framework enhances the performance of
RAG systems equipped with different retrievers and is applicable to various
LLMs.

ÊëòË¶ÅÔºöÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàê (RAG) Â∑≤Ë¢´Ë≠âÊòéÊòØ‰∏ÄÁ®ÆÊúâÊïàÁöÑÊñπÊ≥ïÔºåÂèØÊ∏õËºïÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠Âõ∫ÊúâÁöÑÂπªË¶∫ÂïèÈ°å„ÄÇ
ÂÖàÂâçÁöÑÂÅöÊ≥ïÈÄöÂ∏∏Ê†πÊìöË™ûÁæ©Áõ∏‰ººÊÄßË®ìÁ∑¥Ê™¢Á¥¢Âô®ÔºåÁº∫Â∞ëÈáùÂ∞ç RAG ÁöÑÊúÄ‰Ω≥Âåñ„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Â∑≤ÊèêË≠∞Â∞áÊ™¢Á¥¢Âô®Ëàá LLM ÁöÑÂÅèÂ•Ω‰ø°ËôüÂ∞çÈΩä„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÂÅèÂ•Ω‰ø°ËôüÈÄöÂ∏∏Èõ£‰ª•ËÆìÈÄöÂ∏∏ÂÖ∑ÊúâËºÉÂº±Ë™ûË®ÄËÉΩÂäõÁöÑÁ®†ÂØÜÊ™¢Á¥¢Âô®ÁêÜËß£‰∏¶ÊúâÊïàÂ≠∏Áøí„ÄÇÂæûÊåáÂ∞éÁôºÁèæÂ≠∏ÁøíÁ≠âÊïôÂ≠∏ÁêÜË´ñ‰∏≠Ê±≤ÂèñÈùàÊÑüÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Ê°ÜÊû∂ FiGRetÔºàÊ™¢Á¥¢Âô®ÁöÑÁ¥∞Á≤íÂ∫¶ÊåáÂ∞éÔºâÔºåÂÆÉÂà©Áî® LLM ÁöÑË™ûË®ÄËÉΩÂäõÂæûÊõ¥Á≤æÁ¥∞„ÄÅ‰ª•Ë≥áË®äÁÇ∫‰∏≠ÂøÉÁöÑËßíÂ∫¶ÊßãÂª∫ÁØÑ‰æãÔºå‰ª•ÊåáÂ∞éÊ™¢Á¥¢Âô®ÁöÑÂ≠∏Áøí„ÄÇ
ÂÖ∑È´îËÄåË®ÄÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÂà©Áî® LLM ÂæûÊ™¢Á¥¢Âô®Ë°®Áèæ‰∏ç‰Ω≥ÁöÑÁØÑ‰æã‰∏≠ÊßãÂª∫ÊòìÊñºÁêÜËß£ÁöÑÁØÑ‰æãÔºåÂ∞àÊ≥®ÊñºËàá RAG ÊÉÖÂ¢ÉÈ´òÂ∫¶Áõ∏ÈóúÁöÑ‰∏âÂÄãÂ≠∏ÁøíÁõÆÊ®ôÔºöÁõ∏ÈóúÊÄß„ÄÅÂÖ®Èù¢ÊÄßÂíåÁ¥îÂ∫¶„ÄÇÈÄô‰∫õÁØÑ‰æã‰ΩúÁÇ∫ËÖ≥ÊâãÊû∂ÔºåÊúÄÁµÇÂ∞áÊ™¢Á¥¢Âô®Ëàá LLM ÁöÑÂÅèÂ•ΩÂ∞çÈΩä„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé°Áî®ÈõôË™≤Á®ãÂ≠∏ÁøíÁ≠ñÁï•Ôºå‰∏¶Âà©Áî® LLM ÂíåÊ™¢Á¥¢Âô®‰πãÈñìÁöÑÁõ∏‰∫íÂõûÈ•ãÔºåÈÄ≤‰∏ÄÊ≠•Â¢ûÂº∑ RAG Á≥ªÁµ±ÁöÑÊïàËÉΩ„ÄÇ‰∏ÄÁ≥ªÂàóÂØ¶È©óË≠âÊòéÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊ°ÜÊû∂Â¢ûÂº∑‰∫ÜÈÖçÂÇô‰∏çÂêåÊ™¢Á¥¢Âô®ÁöÑ RAG Á≥ªÁµ±ÁöÑÊïàËÉΩÔºå‰∏¶‰∏îÈÅ©Áî®ÊñºÂêÑÁ®Æ LLM„ÄÇ

##### **Long-Form Text-to-Music Generation with Adaptive Prompts: A Case of Study in Tabletop Role-Playing Games Soundtracks**
2411.03948v1 by Felipe Marra, Lucas N. Ferreira

This paper investigates the capabilities of text-to-audio music generation
models in producing long-form music with prompts that change over time,
focusing on soundtrack generation for Tabletop Role-Playing Games (TRPGs). We
introduce Babel Bardo, a system that uses Large Language Models (LLMs) to
transform speech transcriptions into music descriptions for controlling a
text-to-music model. Four versions of Babel Bardo were compared in two TRPG
campaigns: a baseline using direct speech transcriptions, and three LLM-based
versions with varying approaches to music description generation. Evaluations
considered audio quality, story alignment, and transition smoothness. Results
indicate that detailed music descriptions improve audio quality while
maintaining consistency across consecutive descriptions enhances story
alignment and transition smoothness.

ÊëòË¶ÅÔºöÊú¨ÊñáÊé¢Ë®éÊñáÊú¨ËΩâÈü≥Ë®äÈü≥Ê®ÇÁîüÊàêÊ®°ÂûãÂú®Áî¢ÁîüÈö®ËëóÊôÇÈñìÊé®ÁßªËÄåËÆäÂåñÁöÑÈï∑ÁØáÈü≥Ê®ÇÁöÑËÉΩÂäõÔºåÈáçÈªûÂú®ÊñºÊ°å‰∏äËßíËâ≤ÊâÆÊºîÈÅäÊà≤ (TRPG) ÁöÑÈÖçÊ®ÇÁîüÊàê„ÄÇÊàëÂÄë‰ªãÁ¥π Babel BardoÔºå‰∏ÄÂÄã‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∞áË™ûÈü≥ËΩâÈåÑËΩâÊèõÁÇ∫Èü≥Ê®ÇÊèèËø∞ÁöÑÁ≥ªÁµ±ÔºåÁî®ÊñºÊéßÂà∂ÊñáÊú¨ËΩâÈü≥Ê®ÇÊ®°Âûã„ÄÇÂú®ÂÖ©ÂÄã TRPG Êà∞ÂΩπ‰∏≠ÊØîËºÉ‰∫ÜÂõõÂÄãÁâàÊú¨ÁöÑ Babel BardoÔºö‰ΩøÁî®Áõ¥Êé•Ë™ûÈü≥ËΩâÈåÑÁöÑÂü∫Ê∫ñÔºå‰ª•Âèä‰∏âÂÄãÊé°Áî®‰∏çÂêåÈü≥Ê®ÇÊèèËø∞ÁîüÊàêÊñπÊ≥ïÁöÑÂü∫Êñº LLM ÁöÑÁâàÊú¨„ÄÇË©ï‰º∞ËÄÉÊÖÆ‰∫ÜÈü≥Ë®äÂìÅË≥™„ÄÅÊïÖ‰∫ãÂ∞çÈΩäÂíåËΩâÂ†¥ÊµÅÊö¢Â∫¶„ÄÇÁµêÊûúË°®ÊòéÔºåË©≥Á¥∞ÁöÑÈü≥Ê®ÇÊèèËø∞ÊîπÂñÑ‰∫ÜÈü≥Ë®äÂìÅË≥™ÔºåËÄåÈÄ£Á∫åÊèèËø∞‰πãÈñì‰øùÊåÅ‰∏ÄËá¥ÊÄßÂâáÂ¢ûÂº∑‰∫ÜÊïÖ‰∫ãÂ∞çÈΩäÂíåËΩâÂ†¥ÊµÅÊö¢Â∫¶„ÄÇ

##### **Can Custom Models Learn In-Context? An Exploration of Hybrid Architecture Performance on In-Context Learning Tasks**
2411.03945v1 by Ryan Campbell, Nelson Lojo, Kesava Viswanadha, Christoffer Grondal Tryggestad, Derrick Han Sun, Sriteja Vijapurapu, August Rolfsen, Anant Sahai

In-Context Learning (ICL) is a phenomenon where task learning occurs through
a prompt sequence without the necessity of parameter updates. ICL in
Multi-Headed Attention (MHA) with absolute positional embedding has been the
focus of more study than other sequence model varieties. We examine
implications of architectural differences between GPT-2 and LLaMa as well as
LlaMa and Mamba. We extend work done by Garg et al. (2022) and Park et al.
(2024) to GPT-2/LLaMa hybrid and LLaMa/Mamba hybrid models - examining the
interplay between sequence transformation blocks and regressive performance
in-context. We note that certain architectural changes cause degraded training
efficiency/ICL accuracy by converging to suboptimal predictors or converging
slower. We also find certain hybrids showing optimistic performance
improvements, informing potential future ICL-focused architecture
modifications. Additionally, we propose the "ICL regression score", a scalar
metric describing a model's whole performance on a specific task. Compute
limitations impose restrictions on our architecture-space, training duration,
number of training runs, function class complexity, and benchmark complexity.
To foster reproducible and extensible research, we provide a typed, modular,
and extensible Python package on which we run all experiments.

ÊëòË¶ÅÔºöÊÉÖÂ¢ÉÂ≠∏Áøí (ICL) ÊòØ‰∏ÄÁ®ÆÁèæË±°ÔºåÂÖ∂‰∏≠‰ªªÂãôÂ≠∏ÁøíÈÄèÈÅéÊèêÁ§∫Â∫èÂàóÁôºÁîüÔºåËÄåÁÑ°ÈúÄÂèÉÊï∏Êõ¥Êñ∞„ÄÇÂÖ∑ÊúâÁµïÂ∞ç‰ΩçÁΩÆÂµåÂÖ•ÁöÑÂ§öÈ†≠Ê≥®ÊÑèÂäõ (MHA) ‰∏≠ÁöÑ ICL ‰∏ÄÁõ¥ÊØîÂÖ∂‰ªñÂ∫èÂàóÊ®°ÂûãÁ®ÆÈ°ûÂèóÂà∞Êõ¥Â§öÁ†îÁ©∂ÁöÑÈóúÊ≥®„ÄÇÊàëÂÄëÊé¢Ë®é‰∫Ü GPT-2 Âíå LLaMa ‰πãÈñìÁöÑÊû∂ÊßãÂ∑ÆÁï∞‰ª•Âèä LLaMa Âíå Mamba ‰πãÈñìÁöÑÊû∂ÊßãÂ∑ÆÁï∞ÁöÑÂê´Áæ©„ÄÇÊàëÂÄëÂ∞á Garg Á≠â‰∫∫ (2022) Âíå Park Á≠â‰∫∫ (2024) ÊâÄÂÅöÁöÑÂ∑•‰ΩúÊì¥Â±ïÂà∞ GPT-2/LLaMa Ê∑∑ÂêàÊ®°ÂûãÂíå LLaMa/Mamba Ê∑∑ÂêàÊ®°ÂûãÔºåÊé¢Ë®é‰∫ÜÂ∫èÂàóËΩâÊèõÂçÄÂ°äÂíåÊÉÖÂ¢É‰∏≠ÂõûÊ≠∏ÊïàËÉΩ‰πãÈñìÁöÑ‰∫§‰∫í‰ΩúÁî®„ÄÇÊàëÂÄëÊ≥®ÊÑèÂà∞Êüê‰∫õÊû∂ÊßãËÆäÊõ¥ÊúÉÂ∞éËá¥Ë®ìÁ∑¥ÊïàÁéá/ICL Ê∫ñÁ¢∫Â∫¶‰∏ãÈôçÔºåÈÄôÊòØÂõ†ÁÇ∫ÂÆÉÂÄëÊî∂ÊñÇÂà∞Ê¨°‰Ω≥È†êÊ∏¨Âô®ÊàñÊî∂ÊñÇÈÄüÂ∫¶ËºÉÊÖ¢„ÄÇÊàëÂÄëÈÇÑÁôºÁèæÊüê‰∫õÊ∑∑ÂêàÊ®°ÂûãÈ°ØÁ§∫Ê®ÇËßÄÁöÑÊïàËÉΩÊîπÂñÑÔºåÈÄôÁÇ∫ÊΩõÂú®ÁöÑÊú™‰æÜ‰ª• ICL ÁÇ∫ÈáçÈªûÁöÑÊû∂Êßã‰øÆÊîπÊèê‰æõ‰∫ÜË≥áË®ä„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü„ÄåICL ÂõûÊ≠∏ÂàÜÊï∏„ÄçÔºåÈÄôÊòØ‰∏ÄÂÄãÊèèËø∞Ê®°ÂûãÂú®ÁâπÂÆö‰ªªÂãô‰∏äÁöÑÊï¥È´îÊïàËÉΩÁöÑÊ®ôÈáèÊåáÊ®ô„ÄÇÈÅãÁÆóÈôêÂà∂Â∞çÊàëÂÄëÁöÑÊû∂ÊßãÁ©∫Èñì„ÄÅË®ìÁ∑¥ÊåÅÁ∫åÊôÇÈñì„ÄÅË®ìÁ∑¥Âü∑Ë°åÊ¨°Êï∏„ÄÅÂáΩÊï∏È°ûÂà•Ë§áÈõúÂ∫¶ÂíåÂü∫Ê∫ñË§áÈõúÂ∫¶ÊñΩÂä†‰∫ÜÈôêÂà∂„ÄÇÁÇ∫‰∫Ü‰øÉÈÄ≤ÂèØË§áË£Ω‰∏îÂèØÊì¥ÂÖÖÁöÑÁ†îÁ©∂ÔºåÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãÈ°ûÂûãÂåñ„ÄÅÊ®°ÁµÑÂåñ‰∏îÂèØÊì¥ÂÖÖÁöÑ Python Â•ó‰ª∂ÔºåÊàëÂÄëÂú®ÂÖ∂‰∏≠Âü∑Ë°åÊâÄÊúâÂØ¶È©ó„ÄÇ

##### **Fine-tuning -- a Transfer Learning approach**
2411.03941v1 by Joseph Arul Raj, Linglong Qian, Zina Ibrahim

Secondary research use of Electronic Health Records (EHRs) is often hampered
by the abundance of missing data in this valuable resource. Missingness in EHRs
occurs naturally as a result of the data recording practices during routine
clinical care, but handling it is crucial to the precision of medical analysis
and the decision-making that follows. The literature contains a variety of
imputation methodologies based on deep neural networks. Those aim to overcome
the dynamic, heterogeneous and multivariate missingness patterns of EHRs, which
cannot be handled by classical and statistical imputation methods. However, all
existing deep imputation methods rely on end-to-end pipelines that incorporate
both imputation and downstream analyses, e.g. classification. This coupling
makes it difficult to assess the quality of imputation and takes away the
flexibility of re-using the imputer for a different task. Furthermore, most
end-to-end deep architectures tend to use complex networks to perform the
downstream task, in addition to the already sophisticated deep imputation
network. We, therefore ask if the high performance reported in the literature
is due to the imputer or the classifier and further ask if an optimised
state-of-the-art imputer is used, a simpler classifier can achieve comparable
performance. This paper explores the development of a modular, deep
learning-based imputation and classification pipeline, specifically built to
leverage the capabilities of state-of-the-art imputation models for downstream
classification tasks. Such a modular approach enables a) objective assessment
of the quality of the imputer and classifier independently, and b) enables the
exploration of the performance of simpler classification architectures using an
optimised imputer.

ÊëòË¶ÅÔºöÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) ÁöÑ‰∫åÊ¨°Á†îÁ©∂Áî®ÈÄîÁ∂ìÂ∏∏ÂèóÂà∞Ê≠§ÂØ∂Ë≤¥Ë≥áÊ∫ê‰∏≠Â§ßÈáèÈÅ∫Â§±Ë≥áÊñôÁöÑÈòªÁ§ô„ÄÇEHR ‰∏≠ÁöÑÈÅ∫Â§±Ë≥áÊñôÊúÉÂú®‰æãË°åËá®Â∫äÁÖßË≠∑ÊúüÈñìÁöÑË≥áÊñôË®òÈåÑÂØ¶Âãô‰∏≠Ëá™ÁÑ∂ÁôºÁîüÔºå‰ΩÜËôïÁêÜÈÅ∫Â§±Ë≥áÊñôÂ∞çÊñºÈÜ´ÁôÇÂàÜÊûêÁöÑÁ≤æÁ¢∫Â∫¶ÂíåÂæåÁ∫åÊ±∫Á≠ñËá≥ÈóúÈáçË¶Å„ÄÇÊñáÁçª‰∏≠ÂåÖÂê´ÂêÑÁ®ÆÂü∫ÊñºÊ∑±Â∫¶Á•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÂÖßÊèíÊñπÊ≥ï„ÄÇÈÄô‰∫õÊñπÊ≥ïÊó®Âú®ÂÖãÊúç EHR ‰∏≠ÂãïÊÖã„ÄÅÁï∞Ë≥™‰∏îÂ§öËÆäÈáèÁöÑÈÅ∫Â§±Ë≥áÊñôÊ®°ÂºèÔºåËÄåÈÄôÁÑ°Ê≥ïÈÄèÈÅéÂÇ≥Áµ±ÂíåÁµ±Ë®àÂÖßÊèíÊñπÊ≥ï‰æÜËôïÁêÜ„ÄÇÁÑ∂ËÄåÔºåÊâÄÊúâÁèæÊúâÁöÑÊ∑±Â∫¶ÂÖßÊèíÊñπÊ≥ïÈÉΩ‰æùË≥¥ÊñºÂ∞áÂÖßÊèíÂíå‰∏ãÊ∏∏ÂàÜÊûêÔºà‰æãÂ¶ÇÂàÜÈ°ûÔºâÁµêÂêàÂú®‰∏ÄËµ∑ÁöÑÁ´ØÂà∞Á´ØÁÆ°ÈÅì„ÄÇÈÄôÁ®ÆÁµêÂêà‰ΩøÂæóÈõ£‰ª•Ë©ï‰º∞ÂÖßÊèíÁöÑÂìÅË≥™Ôºå‰∏¶Ê∂àÈô§‰∫ÜÈáçÊñ∞‰ΩøÁî®ÂÖßÊèíÂô®ÈÄ≤Ë°å‰∏çÂêå‰ªªÂãôÁöÑÈùàÊ¥ªÊÄß„ÄÇÊ≠§Â§ñÔºåÂ§ßÂ§öÊï∏Á´ØÂà∞Á´ØÊ∑±Â∫¶Êû∂ÊßãÂÇæÂêëÊñº‰ΩøÁî®Ë§áÈõúÁöÑÁ∂≤Ë∑Ø‰æÜÂü∑Ë°å‰∏ãÊ∏∏‰ªªÂãôÔºåÈô§‰∫ÜÂ∑≤Á∂ìÂæàË§áÈõúÁöÑÊ∑±Â∫¶ÂÖßÊèíÁ∂≤Ë∑Ø‰πãÂ§ñ„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëË©¢ÂïèÊñáÁçª‰∏≠Â†±Â∞éÁöÑÈ´òÊïàËÉΩÊòØÁî±ÊñºÂÖßÊèíÂô®ÈÇÑÊòØÂàÜÈ°ûÂô®Ôºå‰∏¶ÈÄ≤‰∏ÄÊ≠•Ë©¢ÂïèÊòØÂê¶‰ΩøÁî®‰∫ÜÊúÄ‰Ω≥ÂåñÁöÑÊúÄÊñ∞ÂÖßÊèíÂô®ÔºåËºÉÁ∞°ÂñÆÁöÑÂàÜÈ°ûÂô®ÊòØÂê¶ÂèØ‰ª•ÈÅîÂà∞Áõ∏ËøëÁöÑÊïàËÉΩ„ÄÇÊú¨ÊñáÊé¢Ë®éÊ®°ÁµÑÂåñ„ÄÅÂü∫ÊñºÊ∑±Â∫¶Â≠∏ÁøíÁöÑÂÖßÊèíÂíåÂàÜÈ°ûÁÆ°ÈÅìÁöÑÈñãÁôºÔºåÁâπÂà•ÊòØÂª∫Êßã‰æÜÂà©Áî®ÊúÄÊñ∞ÂÖßÊèíÊ®°ÂûãÁöÑËÉΩÂäõÔºå‰ª•ÈÄ≤Ë°å‰∏ãÊ∏∏ÂàÜÈ°û‰ªªÂãô„ÄÇÈÄôÁ®ÆÊ®°ÁµÑÂåñÊñπÊ≥ïËÉΩ a) ÂÆ¢ËßÄË©ï‰º∞ÂÖßÊèíÂô®ÂíåÂàÜÈ°ûÂô®ÁöÑÂìÅË≥™Ôºå‰ª•Âèä b) ËÉΩÂ§†‰ΩøÁî®ÊúÄ‰Ω≥ÂåñÁöÑÂÖßÊèíÂô®‰æÜÊé¢Ë®éËºÉÁ∞°ÂñÆÂàÜÈ°ûÊû∂ÊßãÁöÑÊïàËÉΩ„ÄÇ

##### **Interactions Across Blocks in Post-Training Quantization of Large Language Models**
2411.03934v1 by Khasmamad Shabanovi, Lukas Wiest, Vladimir Golkov, Daniel Cremers, Thomas Pfeil

Post-training quantization is widely employed to reduce the computational
demands of neural networks. Typically, individual substructures, such as layers
or blocks of layers, are quantized with the objective of minimizing
quantization errors in their pre-activations by fine-tuning the corresponding
weights. Deriving this local objective from the global objective of minimizing
task loss involves two key simplifications: assuming substructures are mutually
independent and ignoring the knowledge of subsequent substructures as well as
the task loss. In this work, we assess the effects of these simplifications on
weight-only quantization of large language models. We introduce two multi-block
fine-tuning strategies and compare them against the baseline of fine-tuning
single transformer blocks. The first captures correlations of weights across
blocks by jointly optimizing multiple quantized blocks. The second incorporates
knowledge of subsequent blocks by minimizing the error in downstream
pre-activations rather than focusing solely on the quantized block. Our
findings indicate that the effectiveness of these methods depends on the
specific network model, with no impact on some models but demonstrating
significant benefits for others.

ÊëòË¶ÅÔºöË®ìÁ∑¥ÂæåÈáèÂåñÂª£Ê≥õÁî®ÊñºÊ∏õÂ∞ëÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑÈÅãÁÆóÈúÄÊ±Ç„ÄÇÈÄöÂ∏∏ÔºåÂÄãÂà•Â≠êÁµêÊßãÔºà‰æãÂ¶ÇÂ±§ÊàñÂ±§Â°äÔºâÊúÉÈáèÂåñÔºåÁõÆÁöÑÊòØÈÄèÈÅéÂæÆË™øÂ∞çÊáâÁöÑÊ¨äÈáç‰æÜÊúÄÂ∞èÂåñÂÖ∂È†êÊøÄÊ¥ª‰∏≠ÁöÑÈáèÂåñË™§Â∑Æ„ÄÇÂæûÊúÄÂ∞èÂåñ‰ªªÂãôÊêçÂ§±ÁöÑÊï¥È´îÁõÆÊ®ô‰∏≠Êé®Â∞éÂá∫ÈÄôÂÄãÂ±ÄÈÉ®ÁõÆÊ®ôÊ∂âÂèäÂÖ©ÂÄãÈóúÈçµÁ∞°ÂåñÔºöÂÅáË®≠Â≠êÁµêÊßãÁõ∏‰∫íÁç®Á´ãÔºå‰∏¶ÂøΩÁï•ÂæåÁ∫åÂ≠êÁµêÊßã‰ª•Âèä‰ªªÂãôÊêçÂ§±ÁöÑÁü•Ë≠ò„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëË©ï‰º∞ÈÄô‰∫õÁ∞°ÂåñÂ∞çÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÂÉÖÊ¨äÈáçÈáèÂåñÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÂºïÂÖ•‰∫ÜÂÖ©Á®ÆÂ§öÂçÄÂ°äÂæÆË™øÁ≠ñÁï•Ôºå‰∏¶Â∞áÂÆÉÂÄëËàáÂæÆË™øÂñÆ‰∏ÄTransformerÂçÄÂ°äÁöÑÂü∫Ê∫ñÈÄ≤Ë°åÊØîËºÉ„ÄÇÁ¨¨‰∏ÄÂÄãÈÄèÈÅéÂÖ±ÂêåÊúÄ‰Ω≥ÂåñÂ§öÂÄãÈáèÂåñÂçÄÂ°ä‰æÜÊì∑ÂèñË∑®ÂçÄÂ°äÁöÑÊ¨äÈáçÁõ∏ÈóúÊÄß„ÄÇÁ¨¨‰∫åÂÄãÈÄèÈÅéÊúÄÂ∞èÂåñ‰∏ãÊ∏∏È†êÊøÄÊ¥ª‰∏≠ÁöÑË™§Â∑ÆÔºàËÄåÈùûÂÉÖÂ∞àÊ≥®ÊñºÈáèÂåñÂçÄÂ°äÔºâ‰æÜÁ¥çÂÖ•ÂæåÁ∫åÂçÄÂ°äÁöÑÁü•Ë≠ò„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÈÄô‰∫õÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÂèñÊ±∫ÊñºÁâπÂÆöÁöÑÁ∂≤Ë∑ØÊ®°ÂûãÔºåÂ∞çÊüê‰∫õÊ®°ÂûãÊ≤íÊúâÂΩ±ÈüøÔºå‰ΩÜÂ∞çÂÖ∂‰ªñÊ®°ÂûãÂâáÂ±ïÁèæÂá∫È°ØËëóÁöÑÂÑ™Èªû„ÄÇ

##### **Evaluation data contamination in LLMs: how do we measure it and (when) does it matter?**
2411.03923v1 by Aaditya K. Singh, Muhammed Yusuf Kocyigit, Andrew Poulton, David Esiobu, Maria Lomeli, Gergely Szilvasy, Dieuwke Hupkes

Hampering the interpretation of benchmark scores, evaluation data
contamination has become a growing concern in the evaluation of LLMs, and an
active area of research studies its effects. While evaluation data
contamination is easily understood intuitively, it is surprisingly difficult to
define precisely which samples should be considered contaminated and,
consequently, how it impacts benchmark scores. We propose that these questions
should be addressed together and that contamination metrics can be assessed
based on whether models benefit from the examples they mark contaminated. We
propose a novel analysis method called ConTAM, and show with a large scale
survey of existing and novel n-gram based contamination metrics across 13
benchmarks and 7 models from 2 different families that ConTAM can be used to
better understand evaluation data contamination and its effects. We find that
contamination may have a much larger effect than reported in recent LLM
releases and benefits models differently at different scales. We also find that
considering only the longest contaminated substring provides a better signal
than considering a union of all contaminated substrings, and that doing model
and benchmark specific threshold analysis greatly increases the specificity of
the results. Lastly, we investigate the impact of hyperparameter choices,
finding that, among other things, both using larger values of n and
disregarding matches that are infrequent in the pre-training data lead to many
false negatives. With ConTAM, we provide a method to empirically ground
evaluation data contamination metrics in downstream effects. With our
exploration, we shed light on how evaluation data contamination can impact LLMs
and provide insight into the considerations important when doing contamination
analysis. We end our paper by discussing these in more detail and providing
concrete suggestions for future work.

ÊëòË¶ÅÔºöÂü∫Ê∫ñÂàÜÊï∏ÁöÑË©ÆÈáãÂèóÂà∞ÈòªÁ§ôÔºåË©ïÈáèË≥áÊñôÁöÑÊ±°ÊüìÂ∑≤ÊàêÁÇ∫ LLM Ë©ïÈáè‰∏≠Êó•ÁõäÂö¥ÈáçÁöÑÂïèÈ°åÔºåËÄåÁ†îÁ©∂ÂÖ∂ÂΩ±Èüø‰πüÊàêÁÇ∫Á†îÁ©∂È†òÂüüÁöÑÁÜ±ÈñÄË≠∞È°å„ÄÇÈõñÁÑ∂Ë©ïÈáèË≥áÊñôÊ±°ÊüìÂú®Áõ¥Ë¶∫‰∏äÂæàÂÆπÊòìÁêÜËß£Ôºå‰ΩÜË¶ÅÁ≤æÁ¢∫ÂÆöÁæ©Âì™‰∫õÁØÑ‰æãÊáâË¢´Ë¶ñÁÇ∫ÂèóÂà∞Ê±°ÊüìÔºå‰ª•ÂèäÂæåÁ∫åÂ∞çÂü∫Ê∫ñÂàÜÊï∏ÁöÑÂΩ±ÈüøÔºåÂçªÊÑèÂ§ñÂú∞Âõ∞Èõ£„ÄÇÊàëÂÄëÂª∫Ë≠∞ÊáâÂêåÊôÇÊé¢Ë®éÈÄô‰∫õÂïèÈ°åÔºå‰∏¶ÂèØÊ†πÊìöÊ®°ÂûãÊòØÂê¶ÂæûÂÖ∂Ê®ôË®òÁÇ∫ÂèóÊ±°ÊüìÁöÑÁØÑ‰æã‰∏≠ÂèóÁõä‰æÜË©ï‰º∞Ê±°ÊüìÊåáÊ®ô„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂêçÁÇ∫ ConTAM ÁöÑÊñ∞Á©éÂàÜÊûêÊñπÊ≥ïÔºå‰∏¶ÈÄèÈÅéÈáùÂ∞ç 13 ÂÄãÂü∫Ê∫ñÂíå‰æÜËá™ 2 ÂÄã‰∏çÂêåÁ≥ªÂàóÁöÑ 7 ÂÄãÊ®°ÂûãÈÄ≤Ë°åÂ§ßË¶èÊ®°Ë™øÊü•ÔºåË≠âÊòé‰∫Ü ConTAM ÂèØÁî®ÊñºÊõ¥Ê∑±ÂÖ•‰∫ÜËß£Ë©ïÈáèË≥áÊñôÊ±°ÊüìÂèäÂÖ∂ÂΩ±Èüø„ÄÇÊàëÂÄëÁôºÁèæÔºåÊ±°ÊüìÁöÑÂΩ±ÈüøÂèØËÉΩÈÅ†Â§ßÊñºÊúÄËøë LLM ÁôºÂ∏ÉÊâÄÂ†±ÂëäÁöÑÂΩ±ÈüøÔºåËÄå‰∏îÂú®‰∏çÂêåË¶èÊ®°‰∏ãÂ∞çÊ®°ÂûãÁöÑÂΩ±Èüø‰πü‰∏çÂêå„ÄÇÊàëÂÄëÈÇÑÁôºÁèæÔºåÂÉÖËÄÉÊÖÆÊúÄÈï∑ÁöÑÂèóÊ±°ÊüìÂ≠êÂ≠ó‰∏≤ÊúÉÊèê‰æõÊØîËÄÉÊÖÆÊâÄÊúâÂèóÊ±°ÊüìÂ≠êÂ≠ó‰∏≤ÁöÑËÅØÈõÜÊõ¥Â•ΩÁöÑË®äËôüÔºåËÄå‰∏îÂü∑Ë°åÊ®°ÂûãÂíåÂü∫Ê∫ñÁâπÂÆöÁöÑÈñæÂÄºÂàÜÊûêÊúÉÂ§ßÂπÖÊèêÈ´òÁµêÊûúÁöÑÂ∞à‰∏ÄÊÄß„ÄÇÊúÄÂæåÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜË∂ÖÂèÉÊï∏ÈÅ∏ÊìáÁöÑÂΩ±ÈüøÔºåÁôºÁèæÈô§‰∫ÜÂÖ∂‰ªñÂõ†Á¥†Â§ñÔºå‰ΩøÁî®ËºÉÂ§ßÁöÑ n ÂÄºÂíåÂøΩÁï•È†êË®ìÁ∑¥Ë≥áÊñô‰∏≠‰∏çÈ†ªÁπÅÁöÑÊØîÂ∞çÈÉΩÊúÉÂ∞éËá¥Ë®±Â§öÂÅáÈô∞ÊÄß„ÄÇÈÄèÈÅé ConTAMÔºåÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÁ®ÆÊñπÊ≥ïÔºåÂèØ‰ª•Âú®‰∏ãÊ∏∏ÊïàÊáâ‰∏≠‰ª•Á∂ìÈ©óÁÇ∫Âü∫Á§éÂª∫Á´ãË©ïÈáèË≥áÊñôÊ±°ÊüìÊåáÊ®ô„ÄÇÈÄèÈÅéÊàëÂÄëÁöÑÊé¢Ë®éÔºåÊàëÂÄëÈó°Êòé‰∫ÜË©ïÈáèË≥áÊñôÊ±°ÊüìÂ¶Ç‰ΩïÂΩ±Èüø LLMÔºå‰∏¶Êèê‰æõ‰∫ÜÂú®ÈÄ≤Ë°åÊ±°ÊüìÂàÜÊûêÊôÇË¶ÅËÄÉÈáèÁöÑÈáçË¶ÅÂõ†Á¥†„ÄÇÊàëÂÄëÂú®Ë´ñÊñáÁöÑÊúÄÂæåÂ∞çÈÄô‰∫õÂõ†Á¥†ÈÄ≤Ë°åÊõ¥Ë©≥Á¥∞ÁöÑË®éË´ñÔºå‰∏¶ÈáùÂ∞çÊú™‰æÜÁöÑÁ†îÁ©∂Êèê‰æõÂÖ∑È´îÁöÑÂª∫Ë≠∞„ÄÇ

##### **RAGulator: Lightweight Out-of-Context Detectors for Grounded Text Generation**
2411.03920v1 by Ian Poey, Jiajun Liu, Qishuai Zhong, Adrien Chenailler

Real-time detection of out-of-context LLM outputs is crucial for enterprises
looking to safely adopt RAG applications. In this work, we train lightweight
models to discriminate LLM-generated text that is semantically out-of-context
from retrieved text documents. We preprocess a combination of summarisation and
semantic textual similarity datasets to construct training data using minimal
resources. We find that DeBERTa is not only the best-performing model under
this pipeline, but it is also fast and does not require additional text
preprocessing or feature engineering. While emerging work demonstrates that
generative LLMs can also be fine-tuned and used in complex data pipelines to
achieve state-of-the-art performance, we note that speed and resource limits
are important considerations for on-premise deployment.

ÊëòË¶ÅÔºöÂ∞çÊñºÂ∞ãÊ±ÇÂÆâÂÖ®Êé°Áî® RAG ÊáâÁî®Á®ãÂºèÁöÑ‰ºÅÊ•≠ËÄåË®ÄÔºåÂç≥ÊôÇÂÅµÊ∏¨Ë™ûÂ¢ÉÂ§ñ LLM Ëº∏Âá∫Ëá≥ÈóúÈáçË¶Å„ÄÇÂú®Ê≠§Â∑•‰Ωú‰∏≠ÔºåÊàëÂÄëË®ìÁ∑¥ËºïÈáèÁ¥öÊ®°Âûã‰æÜÂçÄÂàÜË™ûÁæ©‰∏äËàáÊ™¢Á¥¢ÁöÑÊñáÂ≠óÊñá‰ª∂ÁÑ°ÈóúÁöÑ LLM ÁîüÊàêÁöÑÊñáÂ≠ó„ÄÇÊàëÂÄëÈ†êËôïÁêÜÊëòË¶ÅÂíåË™ûÁæ©ÊñáÂ≠óÁõ∏‰ººÊÄßË≥áÊñôÈõÜÁöÑÁµÑÂêàÔºå‰ΩøÁî®ÊúÄÂ∞ëÁöÑË≥áÊ∫ê‰æÜÂª∫ÊßãË®ìÁ∑¥Ë≥áÊñô„ÄÇÊàëÂÄëÁôºÁèæ DeBERTa ‰∏çÂÉÖÊòØÊ≠§ÁÆ°ÈÅì‰∏ãÊïàËÉΩÊúÄÂ•ΩÁöÑÊ®°ÂûãÔºåËÄå‰∏îÈÄüÂ∫¶Âø´Ôºå‰∏î‰∏çÈúÄË¶ÅÈ°çÂ§ñÁöÑÊñáÂ≠óÈ†êËôïÁêÜÊàñÁâπÂæµÂ∑•Á®ã„ÄÇÈõñÁÑ∂Êñ∞ËààÂ∑•‰ΩúË≠âÊòéÔºåÁîüÊàêÂºè LLM ‰πüÂèØ‰ª•ÈÄ≤Ë°åÂæÆË™øÔºå‰∏¶Áî®ÊñºË§áÈõúÁöÑË≥áÊñôÁÆ°ÈÅì‰∏≠Ôºå‰ª•ÈÅîÊàêÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºå‰ΩÜÊàëÂÄëÊ≥®ÊÑèÂà∞ÈÄüÂ∫¶ÂíåË≥áÊ∫êÈôêÂà∂ÊòØÂÖßÈÉ®ÈÉ®ÁΩ≤ÁöÑÈáçË¶ÅËÄÉÈáèÂõ†Á¥†„ÄÇ

##### **Lexicalization Is All You Need: Examining the Impact of Lexical Knowledge in a Compositional QALD System**
2411.03906v1 by David Maria Schmidt, Mohammad Fazleh Elahi, Philipp Cimiano

In this paper, we examine the impact of lexicalization on Question Answering
over Linked Data (QALD). It is well known that one of the key challenges in
interpreting natural language questions with respect to SPARQL lies in bridging
the lexical gap, that is mapping the words in the query to the correct
vocabulary elements. We argue in this paper that lexicalization, that is
explicit knowledge about the potential interpretations of a word with respect
to the given vocabulary, significantly eases the task and increases the
performance of QA systems. Towards this goal, we present a compositional QA
system that can leverage explicit lexical knowledge in a compositional manner
to infer the meaning of a question in terms of a SPARQL query. We show that
such a system, given lexical knowledge, has a performance well beyond current
QA systems, achieving up to a $35.8\%$ increase in the micro $F_1$ score
compared to the best QA system on QALD-9. This shows the importance and
potential of including explicit lexical knowledge. In contrast, we show that
LLMs have limited abilities to exploit lexical knowledge, with only marginal
improvements compared to a version without lexical knowledge. This shows that
LLMs have no ability to compositionally interpret a question on the basis of
the meaning of its parts, a key feature of compositional approaches. Taken
together, our work shows new avenues for QALD research, emphasizing the
importance of lexicalization and compositionality.

ÊëòË¶ÅÔºö<paragraph>Âú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜË©ûÂΩôÂåñÂ∞çÈèàÁµêË≥áÊñôÂïèÁ≠î (QALD) ÁöÑÂΩ±Èüø„ÄÇÁúæÊâÄÂë®Áü•ÔºåÂú®Â∞áËá™ÁÑ∂Ë™ûË®ÄÂïèÈ°åËß£ÈáãÁÇ∫ SPARQL ÊôÇÔºåÈóúÈçµÊåëÊà∞‰πã‰∏ÄÂú®ÊñºÂΩåÂêàË©ûÂΩôÂ∑ÆË∑ùÔºå‰πüÂ∞±ÊòØÂ∞áÊü•Ë©¢‰∏≠ÁöÑË©ûÂΩôÂ∞çÊáâÂà∞Ê≠£Á¢∫ÁöÑË©ûÂΩôÂÖÉÁ¥†„ÄÇÊàëÂÄëÂú®Êú¨Êñá‰∏≠Ë´ñË≠âÔºåË©ûÂΩôÂåñÔºå‰πüÂ∞±ÊòØÈóúÊñºË©ûÂΩôÂ∞çÊáâÂà∞ÁâπÂÆöË©ûÂΩôÁöÑÊΩõÂú®Ëß£ÈáãÁöÑÊòéÁ¢∫Áü•Ë≠òÔºåÂèØ‰ª•Â§ßÂπÖÁ∞°Âåñ‰ªªÂãô‰∏¶ÊèêÂçáÂïèÁ≠îÁ≥ªÁµ±ÁöÑÊïàËÉΩ„ÄÇÁÇ∫‰∫ÜÈÅîÊàêÈÄôÂÄãÁõÆÊ®ôÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÁµÑÂêàÂºèÂïèÁ≠îÁ≥ªÁµ±ÔºåÂèØ‰ª•‰ª•ÁµÑÂêàÂºèÁöÑÊñπÂºèÂà©Áî®ÊòéÁ¢∫ÁöÑË©ûÂΩôÁü•Ë≠òÔºå‰ª• SPARQL Êü•Ë©¢ÁöÑÂΩ¢ÂºèÊé®Ë´ñÂïèÈ°åÁöÑÊÑèÁæ©„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÈÄôÊ®£ÁöÑÁ≥ªÁµ±ÔºåÂú®Áµ¶ÂÆöË©ûÂΩôÁü•Ë≠òÁöÑÊÉÖÊ≥Å‰∏ãÔºåÊïàËÉΩÈÅ†ÈÅ†Ë∂ÖÈÅéÁèæÊúâÁöÑÂïèÁ≠îÁ≥ªÁµ±ÔºåËàá QALD-9 ‰∏äÊúÄ‰Ω≥ÂïèÁ≠îÁ≥ªÁµ±Áõ∏ÊØîÔºåÂæÆÂûã $F_1$ ÂæóÂàÜÊèêÂçá‰∫Ü $35.8\%$„ÄÇÈÄôÈ°ØÁ§∫‰∫ÜÁ¥çÂÖ•ÊòéÁ¢∫Ë©ûÂΩôÁü•Ë≠òÁöÑÈáçË¶ÅÊÄßËàáÊΩõÂäõ„ÄÇÁõ∏ÂèçÂú∞ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü LLM ÂÉÖËÉΩÊúâÈôêÂú∞ÈÅãÁî®Ë©ûÂΩôÁü•Ë≠òÔºåËàáÊ≤íÊúâË©ûÂΩôÁü•Ë≠òÁöÑÁâàÊú¨Áõ∏ÊØîÔºåÂÉÖÊúâÈÇäÈöõÊîπÂñÑ„ÄÇÈÄôÈ°ØÁ§∫‰∫Ü LLM ÁÑ°Ê≥ïÊ†πÊìöÂÖ∂ÁµÑÊàêÈÉ®ÂàÜÁöÑÊÑèÁæ©ÁµÑÂêàÂºèÂú∞Ëß£ÈáãÂïèÈ°åÔºåÈÄôÊòØÁµÑÂêàÂºèÊñπÊ≥ïÁöÑ‰∏ÄÂÄãÈóúÈçµÁâπÂæµ„ÄÇÁ∂úÂêàËÄåË®ÄÔºåÊàëÂÄëÁöÑÁ†îÁ©∂ÁÇ∫ QALD Á†îÁ©∂Â±ïÁ§∫‰∫ÜÊñ∞ÁöÑÈÄîÂæëÔºåÂº∑Ë™ø‰∫ÜË©ûÂΩôÂåñÂíåÁµÑÂêàÊÄßÁöÑÈáçË¶ÅÊÄß„ÄÇ</paragraph>

##### **Computational Analysis of Gender Depiction in the Comedias of Calder√≥n de la Barca**
2411.03895v1 by Allison Keith, Antonio Rojas Castro, Sebastian Pad√≥

In theatre, playwrights use the portrayal of characters to explore culturally
based gender norms. In this paper, we develop quantitative methods to study
gender depiction in the non-religious works (comedias) of Pedro Calder\'on de
la Barca, a prolific Spanish 17th century author. We gather insights from a
corpus of more than 100 plays by using a gender classifier and applying model
explainability (attribution) methods to determine which text features are most
influential in the model's decision to classify speech as 'male' or 'female',
indicating the most gendered elements of dialogue in Calder\'on's comedias in a
human accessible manner. We find that female and male characters are portrayed
differently and can be identified by the gender prediction model at practically
useful accuracies (up to f=0.83). Analysis reveals semantic aspects of gender
portrayal, and demonstrates that the model is even useful in providing a
relatively accurate scene-by-scene prediction of cross-dressing characters.

ÊëòË¶ÅÔºöÂú®Êà≤Âäá‰∏≠ÔºåÂäá‰ΩúÂÆ∂ÊúÉÂà©Áî®ËßíËâ≤ÁöÑÊèèÂØ´‰æÜÊé¢Ë®éÊñáÂåñ‰∏≠ÁöÑÊÄßÂà•Ë¶èÁØÑ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁôºÂ±ïÂá∫ÂÆöÈáèÊñπÊ≥ï‰æÜÁ†îÁ©∂ÊÄßÂà•Âú®‰Ω©Âæ∑ÁæÖ¬∑Âç°ÁàæÂæ∑ÈöÜ¬∑Âæ∑¬∑Êãâ¬∑Â∑¥Âç°ÁöÑÈùûÂÆóÊïô‰ΩúÂìÅÔºàÂñúÂäáÔºâ‰∏≠ÁöÑÊèèÁπ™Ôºå‰ªñÊòØ 17 ‰∏ñÁ¥ÄË•øÁè≠ÁâôÁöÑ‰∏Ä‰ΩçÂ§öÁî¢‰ΩúÂÆ∂„ÄÇÊàëÂÄëÂæûË∂ÖÈÅé 100 ÈÉ®Êà≤ÂäáÁöÑË™ûÊñôÂ∫´‰∏≠Êî∂ÈõÜË¶ãËß£Ôºå‰ΩøÁî®ÊÄßÂà•ÂàÜÈ°ûÂô®‰∏¶ÊáâÁî®Ê®°ÂûãÂèØËß£ÈáãÊÄßÔºàÊ≠∏Âõ†ÔºâÊñπÊ≥ï‰æÜÁ¢∫ÂÆöÂì™‰∫õÊñáÂ≠óÁâπÂæµÊúÄËÉΩÂΩ±ÈüøÊ®°ÂûãÂ∞áË™ûË®ÄÂàÜÈ°ûÁÇ∫„ÄåÁî∑ÊÄß„ÄçÊàñ„ÄåÂ•≥ÊÄß„ÄçÁöÑÊ±∫ÂÆöÔºå‰ª•‰∫∫È°ûÂèØÁêÜËß£ÁöÑÊñπÂºèÊåáÂá∫Âç°ÁàæÂæ∑ÈöÜÂñúÂäá‰∏≠Â∞çË©±‰∏≠ÊúÄÂÖ∑ÊÄßÂà•ÁâπË≥™ÁöÑÂÖÉÁ¥†„ÄÇÊàëÂÄëÁôºÁèæÂ•≥ÊÄßÂíåÁî∑ÊÄßËßíËâ≤ÁöÑÊèèÁπ™‰∏çÂêåÔºåËÄå‰∏îÊÄßÂà•È†êÊ∏¨Ê®°ÂûãÂèØ‰ª•‰ª•ÂØ¶Áî®ÁöÑÊ∫ñÁ¢∫Â∫¶ÔºàÈ´òÈÅî f=0.83ÔºâËæ®Ë≠òÂá∫ÈÄô‰∫õËßíËâ≤„ÄÇÂàÜÊûêÊè≠Á§∫‰∫ÜÊÄßÂà•ÊèèÁπ™ÁöÑË™ûÁæ©Èù¢ÂêëÔºå‰∏¶Ë≠âÊòé‰∫ÜË©≤Ê®°ÂûãÁîöËá≥ÂèØ‰ª•Áõ∏Áï∂Ê∫ñÁ¢∫Âú∞È†êÊ∏¨Âñ¨Ë£ùËßíËâ≤ÁöÑÂ†¥ÊôØ„ÄÇ

##### **Multi3Hate: Multimodal, Multilingual, and Multicultural Hate Speech Detection with Vision-Language Models**
2411.03888v1 by Minh Duc Bui, Katharina von der Wense, Anne Lauscher

Warning: this paper contains content that may be offensive or upsetting
  Hate speech moderation on global platforms poses unique challenges due to the
multimodal and multilingual nature of content, along with the varying cultural
perceptions. How well do current vision-language models (VLMs) navigate these
nuances? To investigate this, we create the first multimodal and multilingual
parallel hate speech dataset, annotated by a multicultural set of annotators,
called Multi3Hate. It contains 300 parallel meme samples across 5 languages:
English, German, Spanish, Hindi, and Mandarin. We demonstrate that cultural
background significantly affects multimodal hate speech annotation in our
dataset. The average pairwise agreement among countries is just 74%,
significantly lower than that of randomly selected annotator groups. Our
qualitative analysis indicates that the lowest pairwise label agreement-only
67% between the USA and India-can be attributed to cultural factors. We then
conduct experiments with 5 large VLMs in a zero-shot setting, finding that
these models align more closely with annotations from the US than with those
from other cultures, even when the memes and prompts are presented in the
dominant language of the other culture. Code and dataset are available at
https://github.com/MinhDucBui/Multi3Hate.

ÊëòË¶ÅÔºöË≠¶ÂëäÔºöÊú¨ÊñáÂåÖÂê´ÂèØËÉΩ‰ª§‰∫∫ÂèçÊÑüÊàñ‰∏çÂÆâÁöÑÂÖßÂÆπ
Áî±ÊñºÂÖßÂÆπÁöÑÂ§öÊ®°ÊÖãÂíåÂ§öË™ûË®ÄÊÄßË≥™‰ª•Âèä‰∏çÂêåÁöÑÊñáÂåñËßÄÂøµÔºåÂú®ÂÖ®ÁêÉÂπ≥Âè∞‰∏äÂ∞ç‰ªáÊÅ®Ë®ÄË´ñÈÄ≤Ë°åÂØ©Ê†∏ÊúÉÂ∏∂‰æÜÁç®ÁâπÊåëÊà∞„ÄÇÁï∂ÂâçÁöÑË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) Âú®ËôïÁêÜÈÄô‰∫õÁ¥∞ÂæÆÂ∑ÆÂà•ÊñπÈù¢Ë°®ÁèæÂ¶Ç‰ΩïÔºüÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÊàëÂÄëÂª∫Á´ã‰∫ÜÁ¨¨‰∏ÄÂÄãÁî±Â§öÂÖÉÊñáÂåñÊ®ôË®ªËÄÖÊ®ôË®ªÁöÑÂ§öÊ®°ÊÖãÂíåÂ§öË™ûË®ÄÂπ≥Ë°å‰ªáÊÅ®Ë®ÄË´ñÊï∏ÊìöÈõÜÔºåÁ®±ÁÇ∫ Multi3Hate„ÄÇÂÆÉÂåÖÂê´ 5 Á®ÆË™ûË®ÄÁöÑ 300 ÂÄãÂπ≥Ë°åËø∑Âõ†Ê®£Êú¨ÔºöËã±Ë™û„ÄÅÂæ∑Ë™û„ÄÅË•øÁè≠ÁâôË™û„ÄÅÂç∞Âú∞Ë™ûÂíåÊôÆÈÄöË©±„ÄÇÊàëÂÄëË≠âÊòéÔºåÊñáÂåñËÉåÊôØÊúÉÈ°ØËëóÂΩ±ÈüøÊàëÂÄëÊï∏ÊìöÈõÜ‰∏≠Â∞çÂ§öÊ®°ÊÖã‰ªáÊÅ®Ë®ÄË´ñÁöÑÊ®ôË®ª„ÄÇÂêÑÂúã‰πãÈñìÁöÑÂπ≥ÂùáÊàêÂ∞ç‰∏ÄËá¥ÊÄßÂÉÖÁÇ∫ 74%ÔºåÈ°ØËëó‰ΩéÊñºÈö®Ê©üÈÅ∏ÊìáÁöÑÊ®ôË®ªËÄÖÁµÑ„ÄÇÊàëÂÄëÁöÑÂÆöÊÄßÂàÜÊûêË°®ÊòéÔºåÊúÄ‰ΩéÁöÑÊàêÂ∞çÊ®ôÁ±§‰∏ÄËá¥ÊÄß‚Äî‚ÄîÁæéÂúãÂíåÂç∞Â∫¶‰πãÈñìÂÉÖÁÇ∫ 67%‚Äî‚ÄîÂèØÊ≠∏Âõ†ÊñºÊñáÂåñÂõ†Á¥†„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂú®Èõ∂Ê¨°Â≠∏ÁøíË®≠ÁΩÆ‰∏≠Â∞ç 5 ÂÄãÂ§ßÂûã VLM ÈÄ≤Ë°å‰∫ÜÂØ¶È©óÔºåÁôºÁèæÈÄô‰∫õÊ®°ÂûãËàáÁæéÂúãÁöÑÊ®ôË®ªÊõ¥‰∏ÄËá¥ÔºåËÄå‰∏çÊòØËàáÂÖ∂‰ªñÊñáÂåñÁöÑÊ®ôË®ªÊõ¥‰∏ÄËá¥ÔºåÂç≥‰ΩøËø∑Âõ†ÂíåÊèêÁ§∫‰ª•ÂÖ∂‰ªñÊñáÂåñÁöÑË™ûË®ÄÂëàÁèæ„ÄÇÁ®ãÂºèÁ¢ºÂíåÊï∏ÊìöÈõÜÂèØÂú® https://github.com/MinhDucBui/Multi3Hate ÊâæÂà∞„ÄÇ

##### **Polynomial Composition Activations: Unleashing the Dynamics of Large Language Models**
2411.03884v1 by Zhijian Zhuo, Ya Wang, Yutao Zeng, Xiaoqing Li, Xun Zhou, Jinwen Ma

Transformers have found extensive applications across various domains due to
the powerful fitting capabilities. This success can be partially attributed to
their inherent nonlinearity. Thus, in addition to the ReLU function employed in
the original transformer architecture, researchers have explored alternative
modules such as GeLU and SwishGLU to enhance nonlinearity and thereby augment
representational capacity. In this paper, we propose a novel category of
polynomial composition activations (PolyCom), designed to optimize the dynamics
of transformers. Theoretically, we provide a comprehensive mathematical
analysis of PolyCom, highlighting its enhanced expressivity and efficacy
relative to other activation functions. Notably, we demonstrate that networks
incorporating PolyCom achieve the $\textbf{optimal approximation rate}$,
indicating that PolyCom networks require minimal parameters to approximate
general smooth functions in Sobolev spaces. We conduct empirical experiments on
the pre-training configurations of large language models (LLMs), including both
dense and sparse architectures. By substituting conventional activation
functions with PolyCom, we enable LLMs to capture higher-order interactions
within the data, thus improving performance metrics in terms of accuracy and
convergence rates. Extensive experimental results demonstrate the effectiveness
of our method, showing substantial improvements over other activation
functions. Code is available at https://github.com/BryceZhuo/PolyCom.

ÊëòË¶ÅÔºöTransformerÂõ†ÂÖ∂Âº∑Â§ßÁöÑÊì¨ÂêàËÉΩÂäõÔºåÂú®ÂêÑÂÄãÈ†òÂüü‰∏≠Â∑≤Âª£Ê≥õÊáâÁî®„ÄÇÈÄôÁ®ÆÊàêÂäüÈÉ®ÂàÜÊ≠∏ÂäüÊñºÂÖ∂Âõ∫ÊúâÁöÑÈùûÁ∑öÊÄß„ÄÇÂõ†Ê≠§ÔºåÈô§‰∫ÜÂéüÂßãTransformerÊû∂Êßã‰∏≠‰ΩøÁî®ÁöÑ ReLU ÂáΩÊï∏Â§ñÔºåÁ†îÁ©∂‰∫∫Âì°ÈÇÑÊé¢Á¥¢‰∫Ü GeLU Âíå SwishGLU Á≠âÊõø‰ª£Ê®°ÁµÑÔºå‰ª•Â¢ûÂº∑ÈùûÁ∑öÊÄßÔºåÂæûËÄåÊì¥ÂÖÖË°®Á§∫ËÉΩÂäõ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÈ°ûÊñ∞ÁöÑÂ§öÈ†ÖÂºèÁµÑÂêàÊøÄÊ¥ªÂáΩÊï∏ (PolyCom)ÔºåÊó®Âú®ÊúÄ‰Ω≥ÂåñTransformerÁöÑÂãïÊÖã„ÄÇÂú®ÁêÜË´ñ‰∏äÔºåÊàëÂÄëÊèê‰æõ‰∫Ü PolyCom ÁöÑÂÖ®Èù¢Êï∏Â≠∏ÂàÜÊûêÔºåÁ™ÅÂá∫‰∫ÜÂÖ∂Áõ∏Â∞çÊñºÂÖ∂‰ªñÊøÄÊ¥ªÂáΩÊï∏ÁöÑÂ¢ûÂº∑Ë°®ÈÅîÂäõÂíåÊïàËÉΩ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊàëÂÄëË≠âÊòé‰∫ÜÁµêÂêà PolyCom ÁöÑÁ∂≤Ë∑ØÂèØÈÅîÂà∞ÊúÄ‰Ω≥Ëøë‰ººÁéáÔºåÈÄôË°®Á§∫ PolyCom Á∂≤Ë∑ØÂè™ÈúÄË¶ÅÊúÄÂ∞ëÁöÑÂèÉÊï∏ÔºåÂç≥ÂèØÈÄºËøë Sobolev Á©∫Èñì‰∏≠ÁöÑ‰∏ÄËà¨Âπ≥ÊªëÂáΩÊï∏„ÄÇÊàëÂÄëÂ∞çÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈ†êË®ìÁ∑¥ÁµÑÊÖãÈÄ≤Ë°å‰∫ÜÂØ¶Ë≠âÂØ¶È©óÔºåÂåÖÊã¨Á®†ÂØÜÂíåÁ®ÄÁñèÊû∂Êßã„ÄÇÈÄèÈÅéÁî® PolyCom Âèñ‰ª£ÂÇ≥Áµ±ÁöÑÊøÄÊ¥ªÂáΩÊï∏ÔºåÊàëÂÄëËÆì LLM ËÉΩÂ§†Êì∑ÂèñË≥áÊñô‰∏≠ÁöÑÈ´òÈöé‰∫íÂãïÔºåÂæûËÄåÊèêÂçáÊ∫ñÁ¢∫Â∫¶ÂíåÊî∂ÊñÇÁéáÁ≠âÊïàËÉΩÊåáÊ®ô„ÄÇÂ§ßÈáèÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåÈ°ØÁ§∫Âá∫Áõ∏ËºÉÊñºÂÖ∂‰ªñÊøÄÊ¥ªÂáΩÊï∏ÊúâÈ°ØËëóÁöÑÈÄ≤Ê≠•„ÄÇÁ®ãÂºèÁ¢ºÂèØÊñº https://github.com/BryceZhuo/PolyCom ÂèñÂæó„ÄÇ

##### **MEG: Medical Knowledge-Augmented Large Language Models for Question Answering**
2411.03883v1 by Laura Cabello, Carmen Martin-Turrero, Uchenna Akujuobi, Anders S√∏gaard, Carlos Bobed

Question answering is a natural language understanding task that involves
reasoning over both explicit context and unstated, relevant domain knowledge.
Large language models (LLMs), which underpin most contemporary question
answering systems, struggle to induce how concepts relate in specialized
domains such as medicine. Existing medical LLMs are also costly to train. In
this work, we present MEG, a parameter-efficient approach for medical
knowledge-augmented LLMs. MEG uses a lightweight mapping network to integrate
graph embeddings into the LLM, enabling it to leverage external knowledge in a
cost-effective way. We evaluate our method on four popular medical
multiple-choice datasets and show that LLMs greatly benefit from the factual
grounding provided by knowledge graph embeddings. MEG attains an average of
+10.2% accuracy over the Mistral-Instruct baseline, and +6.7% over specialized
models like BioMistral. We also show results based on Llama-3. Finally, we show
that MEG's performance remains robust to the choice of graph encoder.

ÊëòË¶ÅÔºöÂïèÁ≠îÊòØ‰∏ÄÁ®ÆËá™ÁÑ∂Ë™ûË®ÄÁêÜËß£‰ªªÂãôÔºåÊ∂âÂèäÂ∞çÊòéÁ¢∫ÁöÑË™ûÂ¢ÉÂíåÊú™Ë™™ÊòéÁöÑÁõ∏ÈóúÈ†òÂüüÁü•Ë≠òÈÄ≤Ë°åÊé®ÁêÜ„ÄÇÊîØÊíêÂ§ßÂ§öÊï∏Áï∂‰ª£ÂïèÁ≠îÁ≥ªÁµ±ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Èõ£‰ª•Êé®Ë´ñÂá∫Ê¶ÇÂøµÂú®ÈÜ´Â≠∏Á≠âÂ∞àÊ•≠È†òÂüü‰∏≠ÁöÑÈóúËÅØÊÄß„ÄÇÁèæÊúâÁöÑÈÜ´Â≠∏ LLM Ë®ìÁ∑¥ÊàêÊú¨‰πüÂæàÈ´ò„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü MEGÔºåÈÄôÊòØ‰∏ÄÁ®ÆÁî®ÊñºÈÜ´Â≠∏Áü•Ë≠òÂ¢ûÂº∑ LLM ÁöÑÂèÉÊï∏È´òÊïàÊñπÊ≥ï„ÄÇMEG ‰ΩøÁî®ËºïÈáèÁ¥öÂ∞çÊáâÁ∂≤Ë∑ØÂ∞áÂúñÂΩ¢ÂµåÂÖ•Êï¥ÂêàÂà∞ LLM ‰∏≠Ôºå‰ΩøÂÖ∂ËÉΩÂ§†‰ª•Á∂ìÊøüÊúâÊïàÁöÑÊñπÂºèÂà©Áî®Â§ñÈÉ®Áü•Ë≠ò„ÄÇÊàëÂÄëÂú®ÂõõÂÄãÊµÅË°åÁöÑÈÜ´Â≠∏Â§öÈÅ∏È°åË≥áÊñôÈõÜ‰∏äË©ï‰º∞‰∫ÜÊàëÂÄëÁöÑÊñπÊ≥ïÔºå‰∏¶Ë°®Êòé LLM ÂæûÁü•Ë≠òÂúñÂΩ¢ÂµåÂÖ•Êèê‰æõÁöÑÂØ¶Èöõ‰æùÊìö‰∏≠ÂèóÁõäÂå™Ê∑∫„ÄÇMEG Âú® Mistral-Instruct Âü∫Ê∫ñ‰∏äÂπ≥ÂùáÊèêÈ´ò‰∫Ü +10.2% ÁöÑÊ∫ñÁ¢∫ÁéáÔºåÂú® BioMistral Á≠âÂ∞àÁî®Ê®°Âûã‰∏äÊèêÈ´ò‰∫Ü +6.7%„ÄÇÊàëÂÄëÈÇÑÂ±ïÁ§∫‰∫ÜÂü∫Êñº Llama-3 ÁöÑÁµêÊûú„ÄÇÊúÄÂæåÔºåÊàëÂÄëË°®Êòé MEG ÁöÑÊÄßËÉΩÂ∞çÂúñÂΩ¢Á∑®Á¢ºÂô®ÁöÑÈÅ∏Êìá‰øùÊåÅÁ©©ÂÅ•„ÄÇ

##### **Performance evaluation of SLAM-ASR: The Good, the Bad, the Ugly, and the Way Forward**
2411.03866v1 by Shashi Kumar, Iuliia Thorbecke, Sergio Burdisso, Esa√∫ Villatoro-Tello, Manjunath K E, Kadri Hacioƒülu, Pradeep Rangappa, Petr Motlicek, Aravind Ganapathiraju, Andreas Stolcke

Recent research has demonstrated that training a linear connector between
speech foundation encoders and large language models (LLMs) enables this
architecture to achieve strong ASR capabilities. Despite the impressive
results, it remains unclear whether these simple approaches are robust enough
across different scenarios and speech conditions, such as domain shifts and
different speech perturbations. In this paper, we address these questions by
conducting various ablation experiments using a recent and widely adopted
approach called SLAM-ASR. We present novel empirical findings that offer
insights on how to effectively utilize the SLAM-ASR architecture across a wide
range of settings. Our main findings indicate that the SLAM-ASR exhibits poor
performance in cross-domain evaluation settings. Additionally, speech
perturbations within in-domain data, such as changes in speed or the presence
of additive noise, can significantly impact performance. Our findings offer
critical insights for fine-tuning and configuring robust LLM-based ASR models,
tailored to different data characteristics and computational resources.

ÊëòË¶ÅÔºöÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÂú®ËØ≠Èü≥Âü∫Á°ÄÁºñÁ†ÅÂô®ÂíåÂ§ßËØ≠Ë®ÄÊ®°Âûã (LLM) ‰πãÈó¥ËÆ≠ÁªÉÁ∫øÊÄßËøûÊé•Âô®Ôºå‰ΩøËøôÁßçÊû∂ÊûÑËÉΩÂ§üÂÆûÁé∞Âº∫Â§ßÁöÑ ASR ÂäüËÉΩ„ÄÇÂ∞ΩÁÆ°ÂèñÂæó‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÁªìÊûúÔºå‰ΩÜÂ∞ö‰∏çÊ∏ÖÊ•öËøô‰∫õÁÆÄÂçïÁöÑÊñπÊ≥ïÊòØÂê¶Ë∂≥Â§üÁ®≥ÂÅ•ÔºåÂèØ‰ª•Âú®‰∏çÂêåÁöÑÂú∫ÊôØÂíåËØ≠Èü≥Êù°‰ª∂‰∏ã‰ΩøÁî®Ôºå‰æãÂ¶ÇÂüüËΩ¨Êç¢Âíå‰∏çÂêåÁöÑËØ≠Èü≥Êâ∞Âä®„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨ÈÄöËøá‰ΩøÁî®‰∏ÄÁßçÊúÄËøëË¢´ÂπøÊ≥õÈááÁî®ÁöÑÁß∞‰∏∫ SLAM-ASR ÁöÑÊñπÊ≥ïÊù•ËøõË°åÂêÑÁßçÊ∂àËûçÂÆûÈ™åÔºåÊù•Ëß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢ò„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫ÜÊñ∞È¢ñÁöÑÁªèÈ™åÂèëÁé∞ÔºåÊèê‰æõ‰∫ÜÊúâÂÖ≥Â¶Ç‰ΩïÂú®ÂêÑÁßçËÆæÁΩÆ‰∏≠ÊúâÊïàÂà©Áî® SLAM-ASR Êû∂ÊûÑÁöÑËßÅËß£„ÄÇÊàë‰ª¨ÁöÑ‰∏ªË¶ÅÂèëÁé∞Ë°®ÊòéÔºåSLAM-ASR Âú®Ë∑®ÂüüËØÑ‰º∞ËÆæÁΩÆ‰∏≠Ë°®Áé∞‰∏ç‰Ω≥„ÄÇÊ≠§Â§ñÔºåÂüüÂÜÖÊï∞ÊçÆ‰∏≠ÁöÑËØ≠Èü≥Êâ∞Âä®Ôºå‰æãÂ¶ÇÈÄüÂ∫¶ÂèòÂåñÊàñÂä†ÊÄßÂô™Â£∞ÁöÑÂ≠òÂú®Ôºå‰ºö‰∏•ÈáçÂΩ±ÂìçÊÄßËÉΩ„ÄÇÊàë‰ª¨ÁöÑÂèëÁé∞‰∏∫ÂæÆË∞ÉÂíåÈÖçÁΩÆÂü∫‰∫é LLM ÁöÑÈ≤ÅÊ£í ASR Ê®°ÂûãÊèê‰æõ‰∫ÜÂÖ≥ÈîÆËßÅËß£ÔºåËøô‰∫õÊ®°ÂûãÈíàÂØπ‰∏çÂêåÁöÑÊï∞ÊçÆÁâπÂæÅÂíåËÆ°ÁÆóËµÑÊ∫êËøõË°å‰∫ÜÂÆöÂà∂„ÄÇ

##### **AdaSociety: An Adaptive Environment with Social Structures for Multi-Agent Decision-Making**
2411.03865v1 by Yizhe Huang, Xingbo Wang, Hao Liu, Fanqi Kong, Aoyang Qin, Min Tang, Xiaoxi Wang, Song-Chun Zhu, Mingjie Bi, Siyuan Qi, Xue Feng

Traditional interactive environments limit agents' intelligence growth with
fixed tasks. Recently, single-agent environments address this by generating new
tasks based on agent actions, enhancing task diversity. We consider the
decision-making problem in multi-agent settings, where tasks are further
influenced by social connections, affecting rewards and information access.
However, existing multi-agent environments lack a combination of adaptive
physical surroundings and social connections, hindering the learning of
intelligent behaviors. To address this, we introduce AdaSociety, a customizable
multi-agent environment featuring expanding state and action spaces, alongside
explicit and alterable social structures. As agents progress, the environment
adaptively generates new tasks with social structures for agents to undertake.
In AdaSociety, we develop three mini-games showcasing distinct social
structures and tasks. Initial results demonstrate that specific social
structures can promote both individual and collective benefits, though current
reinforcement learning and LLM-based algorithms show limited effectiveness in
leveraging social structures to enhance performance. Overall, AdaSociety serves
as a valuable research platform for exploring intelligence in diverse physical
and social settings. The code is available at
https://github.com/bigai-ai/AdaSociety.

ÊëòË¶ÅÔºöÂÇ≥Áµ±ÁöÑ‰∫íÂãïÂºèÁí∞Â¢ÉÈôêÂà∂‰∫Ü‰ª£ÁêÜÁöÑÊô∫ÊÖßÊàêÈï∑ÔºåÂõ†ÁÇ∫‰ªªÂãôÊòØÂõ∫ÂÆöÁöÑ„ÄÇÊúÄËøëÔºåÂñÆ‰∏Ä‰ª£ÁêÜÁí∞Â¢ÉÈÄèÈÅéÊ†πÊìö‰ª£ÁêÜÂãï‰ΩúÁî¢ÁîüÊñ∞‰ªªÂãô‰æÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÈÄ≤ËÄåÊèêÂçá‰ªªÂãôÂ§öÊ®£ÊÄß„ÄÇÊàëÂÄëËÄÉÊÖÆÂ§ö‰ª£ÁêÜË®≠ÂÆö‰∏≠ÁöÑÊ±∫Á≠ñÂïèÈ°åÔºåÂÖ∂‰∏≠‰ªªÂãôÈÄ≤‰∏ÄÊ≠•ÂèóÂà∞Á§æ‰∫§ÈÄ£ÁµêÁöÑÂΩ±ÈüøÔºåÈÄ≤ËÄåÂΩ±ÈüøÁçéÂãµÂíåË≥áË®äÂ≠òÂèñ„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÂ§ö‰ª£ÁêÜÁí∞Â¢ÉÁº∫‰πèÈÅ©ÊáâÊÄßÁâ©ÁêÜÁí∞Â¢ÉÂíåÁ§æ‰∫§ÈÄ£ÁµêÁöÑÁµÑÂêàÔºåÈÄôÈòªÁ§ô‰∫ÜÊô∫ÊÖßË°åÁÇ∫ÁöÑÂ≠∏Áøí„ÄÇÁÇ∫‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü AdaSocietyÔºåÈÄôÊòØ‰∏ÄÂÄãÂèØËá™Ë®ÇÁöÑÂ§ö‰ª£ÁêÜÁí∞Â¢ÉÔºåÂÖ∑ÊúâÊì¥ÂÖÖÁöÑÁãÄÊÖãÂíåÂãï‰ΩúÁ©∫ÈñìÔºå‰ª•ÂèäÊòéÁ¢∫‰∏îÂèØËÆäÊõ¥ÁöÑÁ§æ‰∫§ÁµêÊßã„ÄÇÈö®Ëëó‰ª£ÁêÜÁöÑÈÄ≤Â±ïÔºåÁí∞Â¢ÉÊúÉÈÅ©ÊáâÊÄßÂú∞Áî¢ÁîüÂÖ∑ÊúâÁ§æ‰∫§ÁµêÊßãÁöÑÊñ∞‰ªªÂãôÔºå‰æõ‰ª£ÁêÜÂü∑Ë°å„ÄÇÂú® AdaSociety ‰∏≠ÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏âÂÄãËø∑‰Ω†ÈÅäÊà≤ÔºåÂ±ïÁ§∫‰∫Ü‰∏çÂêåÁöÑÁ§æ‰∫§ÁµêÊßãÂíå‰ªªÂãô„ÄÇÂàùÊ≠•ÁµêÊûúÈ°ØÁ§∫ÔºåÁâπÂÆöÁöÑÁ§æ‰∫§ÁµêÊßãÂèØ‰ª•‰øÉÈÄ≤ÂÄã‰∫∫ÂíåÈõÜÈ´îÂà©ÁõäÔºåÂÑòÁÆ°ÁõÆÂâçÁöÑÂº∑ÂåñÂ≠∏ÁøíÂíåÂü∫Êñº LLM ÁöÑÊºîÁÆóÊ≥ïÂú®Âà©Áî®Á§æ‰∫§ÁµêÊßã‰æÜÊèêÂçáÊïàËÉΩÊñπÈù¢È°ØÁ§∫Âá∫ÊúâÈôêÁöÑÊïàÂäõ„ÄÇÁ∏ΩÁöÑ‰æÜË™™ÔºåAdaSociety ÂèØ‰ΩúÁÇ∫‰∏ÄÂÄãÊúâÂÉπÂÄºÁöÑÁ†îÁ©∂Âπ≥Âè∞ÔºåÁî®ÊñºÊé¢Á¥¢Âú®‰∏çÂêåÁöÑÁâ©ÁêÜÂíåÁ§æ‰∫§Ë®≠ÂÆö‰∏≠ÁöÑÊô∫ÊÖß„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/bigai-ai/AdaSociety ÂèñÂæó„ÄÇ

##### **ROBIN: Robust and Invisible Watermarks for Diffusion Models with Adversarial Optimization**
2411.03862v1 by Huayang Huang, Yu Wu, Qian Wang

Watermarking generative content serves as a vital tool for authentication,
ownership protection, and mitigation of potential misuse. Existing watermarking
methods face the challenge of balancing robustness and concealment. They
empirically inject a watermark that is both invisible and robust and passively
achieve concealment by limiting the strength of the watermark, thus reducing
the robustness. In this paper, we propose to explicitly introduce a watermark
hiding process to actively achieve concealment, thus allowing the embedding of
stronger watermarks. To be specific, we implant a robust watermark in an
intermediate diffusion state and then guide the model to hide the watermark in
the final generated image. We employ an adversarial optimization algorithm to
produce the optimal hiding prompt guiding signal for each watermark. The prompt
embedding is optimized to minimize artifacts in the generated image, while the
watermark is optimized to achieve maximum strength. The watermark can be
verified by reversing the generation process. Experiments on various diffusion
models demonstrate the watermark remains verifiable even under significant
image tampering and shows superior invisibility compared to other
state-of-the-art robust watermarking methods.

ÊëòË¶ÅÔºöÁîüÊàêÂºèÂÖßÂÆπÁöÑÊ∞¥Âç∞‰ΩúÁÇ∫È©óË≠â„ÄÅÊâÄÊúâÊ¨ä‰øùË≠∑ÂíåÊ∏õËºïÊΩõÂú®Ë™§Áî®ÁöÑÈáçË¶ÅÂ∑•ÂÖ∑„ÄÇ ÁèæÊúâÁöÑÊ∞¥Âç∞ÊñπÊ≥ïÈù¢Ëá®Âπ≥Ë°°Âº∑ÂÅ•ÊÄßÂíåÈö±ËóèÊÄßÁöÑÊåëÊà∞„ÄÇ ‰ªñÂÄëÊ†πÊìöÁ∂ìÈ©óÊ≥®ÂÖ•‰∏ÄÂÄãÊó¢‰∏çÂèØË¶ãÂèàÂº∑ÂÅ•ÁöÑÊ∞¥Âç∞Ôºå‰∏¶ÈÄöÈÅéÈôêÂà∂Ê∞¥Âç∞ÁöÑÂº∑Â∫¶‰æÜË¢´ÂãïÂØ¶ÁèæÈö±ËóèÔºåÂæûËÄåÈôç‰ΩéÂº∑ÂÅ•ÊÄß„ÄÇ Âú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂª∫Ë≠∞ÊòéÁ¢∫ÂºïÂÖ•Ê∞¥Âç∞Èö±ËóèÈÅéÁ®ã‰ª•‰∏ªÂãïÂØ¶ÁèæÈö±ËóèÔºåÂæûËÄåÂÖÅË®±ÂµåÂÖ•Êõ¥Âº∑ÁöÑÊ∞¥Âç∞„ÄÇ ÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂú®‰∏≠ÈñìÊì¥Êï£ÁãÄÊÖã‰∏≠Ê§çÂÖ•‰∏ÄÂÄãÂº∑ÂÅ•ÁöÑÊ∞¥Âç∞ÔºåÁÑ∂ÂæåÂºïÂ∞éÊ®°ÂûãÂú®ÊúÄÁµÇÁîüÊàêÁöÑÂúñÂÉè‰∏≠Èö±ËóèÊ∞¥Âç∞„ÄÇ ÊàëÂÄëÊé°Áî®Â∞çÊäóÊÄßÂÑ™ÂåñÊºîÁÆóÊ≥ïÁÇ∫ÊØèÂÄãÊ∞¥Âç∞Áî¢ÁîüÊúÄ‰Ω≥Èö±ËóèÊèêÁ§∫ÂºïÂ∞éË®äËôü„ÄÇ ÊèêÁ§∫ÂµåÂÖ•Á∂ìÈÅéÊúÄ‰Ω≥Âåñ‰ª•ÊúÄÂ∞èÂåñÁîüÊàêÂúñÂÉè‰∏≠ÁöÑÂÅΩÂÉèÔºåËÄåÊ∞¥Âç∞Á∂ìÈÅéÊúÄ‰Ω≥Âåñ‰ª•ÂØ¶ÁèæÊúÄÂ§ßÂº∑Â∫¶„ÄÇ ÂèØ‰ª•ÈÄöÈÅéÈÄÜËΩâÁîüÊàêÈÅéÁ®ã‰æÜÈ©óË≠âÊ∞¥Âç∞„ÄÇ ÂêÑÁ®ÆÊì¥Êï£Ê®°ÂûãÁöÑÂØ¶È©óË°®ÊòéÔºåÂç≥‰ΩøÂú®È°ØËëóÁöÑÂúñÂÉèÁØ°Êîπ‰∏ãÔºåÊ∞¥Âç∞‰ªçÁÑ∂ÂèØ‰ª•È©óË≠âÔºå‰∏¶‰∏îËàáÂÖ∂‰ªñÊúÄÂÖàÈÄ≤ÁöÑÂº∑ÂÅ•Ê∞¥Âç∞ÊñπÊ≥ïÁõ∏ÊØîÔºåÈ°ØÁ§∫Âá∫ÂÑ™Áï∞ÁöÑ‰∏çÂèØË¶ãÊÄß„ÄÇ

##### **UniTraj: Universal Human Trajectory Modeling from Billion-Scale Worldwide Traces**
2411.03859v1 by Yuanshao Zhu, James Jianqiao Yu, Xiangyu Zhao, Xuetao Wei, Yuxuan Liang

Human trajectory modeling is essential for deciphering movement patterns and
supporting advanced applications across various domains. However, existing
methods are often tailored to specific tasks and regions, resulting in
limitations related to task specificity, regional dependency, and data quality
sensitivity. Addressing these challenges requires a universal human trajectory
foundation model capable of generalizing and scaling across diverse tasks and
geographic contexts. To this end, we propose UniTraj, a Universal human
Trajectory foundation model that is task-adaptive, region-independent, and
highly generalizable. To further enhance performance, we construct WorldTrace,
the first large-scale, high-quality, globally distributed dataset sourced from
open web platforms, encompassing 2.45 million trajectories with billions of
points across 70 countries. Through multiple resampling and masking strategies
designed for pre-training, UniTraj effectively overcomes geographic and task
constraints, adapting to heterogeneous data quality. Extensive experiments
across multiple trajectory analysis tasks and real-world datasets demonstrate
that UniTraj consistently outperforms existing approaches in terms of
scalability and adaptability. These results underscore the potential of UniTraj
as a versatile, robust solution for a wide range of trajectory analysis
applications, with WorldTrace serving as an ideal but non-exclusive foundation
for training.

ÊëòË¶ÅÔºö‰∫∫È°ûËªåË∑°Ê®°ÂûãÂ∞çÊñºËß£Á¢ºÁßªÂãïÊ®°ÂºèÂíåÊîØÊè¥ÂêÑÂÄãÈ†òÂüüÁöÑÈÄ≤ÈöéÊáâÁî®Ëá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÊñπÊ≥ïÈÄöÂ∏∏ÊòØÈáùÂ∞çÁâπÂÆö‰ªªÂãôÂíåÂçÄÂüüÈáèË∫´ÊâìÈÄ†ÔºåÂ∞éËá¥Ëàá‰ªªÂãôÁâπÂÆöÊÄß„ÄÅÂçÄÂüü‰æùË≥¥ÊÄßÂíåË≥áÊñôÂìÅË≥™ÊïèÊÑüÊÄßÁõ∏ÈóúÁöÑÈôêÂà∂„ÄÇËß£Ê±∫ÈÄô‰∫õÊåëÊà∞ÈúÄË¶Å‰∏ÄÂÄãÈÄöÁî®ÁöÑËªåË∑°Âü∫Á§éÊ®°ÂûãÔºåËÉΩÂ§†Âú®‰∏çÂêåÁöÑ‰ªªÂãôÂíåÂú∞ÁêÜËÉåÊôØ‰∏ãÈÄ≤Ë°åÊ¶ÇÂåñÂíåÁ∏ÆÊîæ„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫ UniTrajÔºå‰∏ÄÂÄãÈÄöÁî®ÁöÑËªåË∑°Âü∫Á§éÊ®°ÂûãÔºåÂÆÉÂÖ∑Êúâ‰ªªÂãôÈÅ©ÊáâÊÄß„ÄÅÂçÄÂüüÁç®Á´ãÊÄßÂíåÈ´òÂ∫¶Ê¶ÇÊã¨ÊÄß„ÄÇÁÇ∫‰∫ÜÈÄ≤‰∏ÄÊ≠•ÊèêÂçáÊïàËÉΩÔºåÊàëÂÄëÊßãÂª∫‰∫Ü WorldTraceÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÂæûÈñãÊîæÁ∂≤Ë∑ØÂπ≥Âè∞ÂèñÂæóÁöÑÂ§ßË¶èÊ®°„ÄÅÈ´òÂìÅË≥™„ÄÅÂÖ®ÁêÉÂàÜ‰ΩàÁöÑË≥áÊñôÈõÜÔºåÂåÖÂê´‰æÜËá™ 70 ÂÄãÂúãÂÆ∂ÁöÑ 245 Ëê¨Ê¢ùËªåË∑°ÂíåÊï∏ÂçÅÂÑÑÂÄãÈªû„ÄÇÈÄèÈÅéÂ§öÈáçÈáçÊñ∞ÂèñÊ®£ÂíåÈÅÆÁΩ©Á≠ñÁï•ÔºåÂ∞àÁÇ∫È†êË®ìÁ∑¥ËÄåË®≠Ë®àÔºåUniTraj ÊúâÊïàÂú∞ÂÖãÊúç‰∫ÜÂú∞ÁêÜÂíå‰ªªÂãôÈôêÂà∂ÔºåÈÅ©ÊáâÁï∞Ë≥™ÁöÑË≥áÊñôÂìÅË≥™„ÄÇÂú®Â§öÂÄãËªåË∑°ÂàÜÊûê‰ªªÂãôÂíåÁúüÂØ¶‰∏ñÁïåË≥áÊñôÈõÜ‰∏≠ÁöÑÂª£Ê≥õÂØ¶È©óË°®ÊòéÔºåUniTraj Âú®ÂèØÊì¥ÂÖÖÊÄßÂíåÈÅ©ÊáâÊÄßÊñπÈù¢ÂßãÁµÇÂÑ™ÊñºÁèæÊúâÊñπÊ≥ï„ÄÇÈÄô‰∫õÁµêÊûúÂº∑Ë™ø‰∫Ü UniTraj ‰ΩúÁÇ∫ËªåË∑°ÂàÜÊûêÊáâÁî®Âª£Ê≥õËÄåÂº∑Â§ßÁöÑËß£Ê±∫ÊñπÊ°àÁöÑÊΩõÂäõÔºåËÄå WorldTrace Ââá‰ΩúÁÇ∫‰∏ÄÂÄãÁêÜÊÉ≥‰ΩÜÈùûÁç®ÂÆ∂ÁöÑË®ìÁ∑¥Âü∫Á§é„ÄÇ

##### **MambaPEFT: Exploring Parameter-Efficient Fine-Tuning for Mamba**
2411.03855v1 by Masakazu Yoshimura, Teruaki Hayashi, Yota Maeda

An ecosystem of Transformer-based models has been established by building
large models with extensive data. Parameter-efficient fine-tuning (PEFT) is a
crucial technology for deploying these models to downstream tasks with minimal
cost while achieving effective performance. Recently, Mamba, a State Space
Model (SSM)-based model, has attracted attention as a potential alternative to
Transformers. While many large-scale Mamba-based models have been proposed,
efficiently adapting pre-trained Mamba-based models to downstream tasks remains
unexplored. In this paper, we conduct an exploratory analysis of PEFT methods
for Mamba. We investigate the effectiveness of existing PEFT methods for
Transformers when applied to Mamba. We also modify these methods to better
align with the Mamba architecture. Additionally, we propose new Mamba-specific
PEFT methods that leverage the distinctive structure of Mamba. Our experiments
indicate that PEFT performs more effectively for Mamba than Transformers.
Lastly, we demonstrate how to effectively combine multiple PEFT methods and
provide a framework that outperforms previous works. To ensure reproducibility,
we will release the code after publication.

ÊëòË¶ÅÔºö<paragraph>Â∑≤Á∂ìÈÄèÈÅéÂª∫Á´ãÊìÅÊúâÂª£Ê≥õË≥áÊñôÁöÑÂ§ßÂûãÊ®°ÂûãÔºåÂª∫Á´ã‰∫ÜÂü∫Êñº Transformer ÁöÑÊ®°ÂûãÁîüÊÖãÁ≥ªÁµ±„ÄÇÂèÉÊï∏ÊúâÊïàÂæÆË™ø (PEFT) ÊòØ‰∏ÄÈ†ÖÈóúÈçµÊäÄË°ìÔºåÁî®Êñº‰ª•ÊúÄ‰ΩéÊàêÊú¨Â∞áÈÄô‰∫õÊ®°ÂûãÈÉ®ÁΩ≤Âà∞‰∏ãÊ∏∏‰ªªÂãôÔºåÂêåÊôÇÈÅîÂà∞ÊúâÊïàÊïàËÉΩ„ÄÇÊúÄËøëÔºå‰∏ÄÁ®ÆÂü∫ÊñºÁãÄÊÖãÁ©∫ÈñìÊ®°Âûã (SSM) ÁöÑÊ®°Âûã MambaÔºåÂõ†ÂÖ∂‰ΩúÁÇ∫ Transformer ÁöÑÊΩõÂú®Êõø‰ª£ÊñπÊ°àËÄåÂÇôÂèóÈóúÊ≥®„ÄÇÈõñÁÑ∂Â∑≤Á∂ìÊèêÂá∫Ë®±Â§öÂ§ßÂûãÂü∫Êñº Mamba ÁöÑÊ®°ÂûãÔºå‰ΩÜÊúâÊïàÂú∞Ë™øÊï¥È†êÂÖàË®ìÁ∑¥ÁöÑÂü∫Êñº Mamba ÁöÑÊ®°Âûã‰ª•ÈÅ©Êáâ‰∏ãÊ∏∏‰ªªÂãô‰ªçÊú™Ë¢´Êé¢Á¥¢„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞ç Mamba ÁöÑ PEFT ÊñπÊ≥ïÈÄ≤Ë°åÊé¢Á¥¢ÊÄßÂàÜÊûê„ÄÇÊàëÂÄëÊé¢Ë®é‰∫ÜÂ∞áÁèæÊúâÈáùÂ∞ç Transformer ÁöÑ PEFT ÊñπÊ≥ïÊáâÁî®Âà∞ Mamba ÊôÇÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄë‰πü‰øÆÊîπÈÄô‰∫õÊñπÊ≥ï‰ª•Êõ¥Â•ΩÂú∞Ëàá Mamba Êû∂ÊßãÂ∞çÈΩä„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫Êñ∞ÁöÑÁâπÂÆöÊñº Mamba ÁöÑ PEFT ÊñπÊ≥ïÔºåÈÄô‰∫õÊñπÊ≥ïÂà©Áî®‰∫Ü Mamba ÁöÑÁç®ÁâπÁµêÊßã„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË°®ÊòéÔºåPEFT Â∞ç Mamba ÁöÑÂü∑Ë°åÊØî Transformer Êõ¥ÊúâÊïà„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ±ïÁ§∫Â¶Ç‰ΩïÊúâÊïàÂú∞ÁµêÂêàÂ§öÁ®Æ PEFT ÊñπÊ≥ïÔºå‰∏¶Êèê‰æõ‰∏ÄÂÄãÂÑ™ÊñºÂÖàÂâçÂ∑•‰ΩúÁöÑÊû∂Êßã„ÄÇÁÇ∫‰∫ÜÁ¢∫‰øùÂèØË§áË£ΩÊÄßÔºåÊàëÂÄëÂ∞áÂú®ÁôºÂ∏ÉÂæåÈáãÂá∫Á®ãÂºèÁ¢º„ÄÇ</paragraph>

##### **A Novel Access Control and Privacy-Enhancing Approach for Models in Edge Computing**
2411.03847v1 by Peihao Li

With the widespread adoption of edge computing technologies and the
increasing prevalence of deep learning models in these environments, the
security risks and privacy threats to models and data have grown more acute.
Attackers can exploit various techniques to illegally obtain models or misuse
data, leading to serious issues such as intellectual property infringement and
privacy breaches. Existing model access control technologies primarily rely on
traditional encryption and authentication methods; however, these approaches
exhibit significant limitations in terms of flexibility and adaptability in
dynamic environments. Although there have been advancements in model
watermarking techniques for marking model ownership, they remain limited in
their ability to proactively protect intellectual property and prevent
unauthorized access. To address these challenges, we propose a novel model
access control method tailored for edge computing environments. This method
leverages image style as a licensing mechanism, embedding style recognition
into the model's operational framework to enable intrinsic access control.
Consequently, models deployed on edge platforms are designed to correctly infer
only on license data with specific style, rendering them ineffective on any
other data. By restricting the input data to the edge model, this approach not
only prevents attackers from gaining unauthorized access to the model but also
enhances the privacy of data on terminal devices. We conducted extensive
experiments on benchmark datasets, including MNIST, CIFAR-10, and FACESCRUB,
and the results demonstrate that our method effectively prevents unauthorized
access to the model while maintaining accuracy. Additionally, the model shows
strong resistance against attacks such as forged licenses and fine-tuning.
These results underscore the method's usability, security, and robustness.

ÊëòË¶ÅÔºöÈö®ËëóÈÇäÁ∑£ÈÅãÁÆóÊäÄË°ìÁöÑÂª£Ê≥õÊé°Áî®Ôºå‰ª•ÂèäÂú®ÈÄô‰∫õÁí∞Â¢É‰∏≠Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÁöÑÊó•ÁõäÊôÆÂèäÔºåÊ®°ÂûãÂíåË≥áÊñôÁöÑÂÆâÂÖ®ÊÄßÈ¢®Èö™ÂíåÈö±ÁßÅÂ®ÅËÑÖÂ∑≤ËÆäÂæóÊõ¥Âä†Âö¥Èáç„ÄÇÊîªÊìäËÄÖÂèØ‰ª•Âà©Áî®ÂêÑÁ®ÆÊäÄË°ìÈùûÊ≥ïÁç≤ÂèñÊ®°ÂûãÊàñÊø´Áî®Ë≥áÊñôÔºåÂ∞éËá¥Âö¥ÈáçÁöÑÂïèÈ°åÔºå‰æãÂ¶ÇÊô∫ÊÖßË≤°Áî¢Ê¨ä‰æµÊ¨äÂíåÈö±ÁßÅÊ¥©Èú≤„ÄÇÁèæÊúâÁöÑÊ®°ÂûãÂ≠òÂèñÊéßÂà∂ÊäÄË°ì‰∏ªË¶Å‰æùË≥¥ÂÇ≥Áµ±ÁöÑÂä†ÂØÜÂíåÈ©óË≠âÊñπÊ≥ïÔºõÁÑ∂ËÄåÔºåÈÄô‰∫õÊñπÊ≥ïÂú®ÂãïÊÖãÁí∞Â¢É‰∏≠ÁöÑÈùàÊ¥ªÊÄßÂíåÈÅ©ÊáâÊÄßÊñπÈù¢Ë°®ÁèæÂá∫È°ØËëóÁöÑÈôêÂà∂„ÄÇÂÑòÁÆ°Âú®Ê®ôË®òÊ®°ÂûãÊâÄÊúâÊ¨äÁöÑÊ®°ÂûãÊµÆÊ∞¥Âç∞ÊäÄË°ìÊñπÈù¢Â∑≤Á∂ìÂèñÂæóÈÄ≤Â±ïÔºå‰ΩÜÂÆÉÂÄëÂú®‰∏ªÂãï‰øùË≠∑Êô∫ÊÖßË≤°Áî¢Ê¨äÂíåÈò≤Ê≠¢Êú™Á∂ìÊéàÊ¨äÁöÑÂ≠òÂèñÊñπÈù¢‰ªçÁÑ∂ÊúâÈôê„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÈáùÂ∞çÈÇäÁ∑£ÈÅãÁÆóÁí∞Â¢ÉÈáèË∫´ÊâìÈÄ†ÁöÑÊñ∞ÂûãÊ®°ÂûãÂ≠òÂèñÊéßÂà∂ÊñπÊ≥ï„ÄÇÊ≠§ÊñπÊ≥ïÂà©Áî®ÂΩ±ÂÉèÈ¢®Ê†º‰ΩúÁÇ∫ÊéàÊ¨äÊ©üÂà∂ÔºåÂ∞áÈ¢®Ê†ºËæ®Ë≠òÂµåÂÖ•Ê®°ÂûãÁöÑÊìç‰ΩúÊû∂Êßã‰∏≠Ôºå‰ª•ÂïüÁî®ÂÖßÂú®ÁöÑÂ≠òÂèñÊéßÂà∂„ÄÇÂõ†Ê≠§ÔºåÈÉ®ÁΩ≤Âú®ÈÇäÁ∑£Âπ≥Âè∞‰∏äÁöÑÊ®°ÂûãÊó®Âú®ÂÉÖÂ∞çÂÖ∑ÊúâÁâπÂÆöÈ¢®Ê†ºÁöÑÊéàÊ¨äË≥áÊñôÈÄ≤Ë°åÊ≠£Á¢∫Êé®Ë´ñÔºåÂú®‰ªª‰ΩïÂÖ∂‰ªñË≥áÊñô‰∏äÈÉΩÁÑ°Ê≥ïÂü∑Ë°å„ÄÇÈÄèÈÅéÈôêÂà∂Ëº∏ÂÖ•Ë≥áÊñôÂà∞ÈÇäÁ∑£Ê®°ÂûãÔºåÊ≠§ÊñπÊ≥ï‰∏çÂÉÖÂèØ‰ª•Èò≤Ê≠¢ÊîªÊìäËÄÖÊú™Á∂ìÊéàÊ¨äÂ≠òÂèñÊ®°ÂûãÔºåÈÇÑÂèØ‰ª•Â¢ûÂº∑ÁµÇÁ´ØË£ùÁΩÆ‰∏äË≥áÊñôÁöÑÈö±ÁßÅÊÄß„ÄÇÊàëÂÄëÂ∞çÂü∫Ê∫ñË≥áÊñôÈõÜÔºàÂåÖÊã¨ MNIST„ÄÅCIFAR-10 Âíå FACESCRUBÔºâÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºåÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÊúâÊïàÂú∞Èò≤Ê≠¢‰∫ÜÊú™Á∂ìÊéàÊ¨äÂ≠òÂèñÊ®°ÂûãÔºåÂêåÊôÇ‰øùÊåÅÊ∫ñÁ¢∫ÊÄß„ÄÇÊ≠§Â§ñÔºåË©≤Ê®°ÂûãÂ∞çÂÅΩÈÄ†ÊéàÊ¨äÂíåÂæÆË™øÁ≠âÊîªÊìäË°®ÁèæÂá∫Âº∑Â§ßÁöÑÊäµÊäóÂäõ„ÄÇÈÄô‰∫õÁµêÊûúÂº∑Ë™ø‰∫ÜË©≤ÊñπÊ≥ïÁöÑÂèØÁî®ÊÄß„ÄÅÂÆâÂÖ®ÊÄßËàáÁ©©ÂÅ•ÊÄß„ÄÇ

##### **Reconsidering the Performance of GAE in Link Prediction**
2411.03845v1 by Weishuo Ma, Yanbo Wang, Xiyuan Wang, Muhan Zhang

Various graph neural networks (GNNs) with advanced training techniques and
model designs have been proposed for link prediction tasks. However, outdated
baseline models may lead to an overestimation of the benefits provided by these
novel approaches. To address this, we systematically investigate the potential
of Graph Autoencoders (GAE) by meticulously tuning hyperparameters and
utilizing the trick of orthogonal embedding and linear propagation. Our
findings reveal that a well-optimized GAE can match the performance of more
complex models while offering greater computational efficiency.

ÊëòË¶ÅÔºöÂêÑÁ®ÆÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) Â∑≤ÊèêÂá∫Êê≠ÈÖçÈÄ≤ÈöéË®ìÁ∑¥ÊäÄÂ∑ßÂíåÊ®°ÂûãË®≠Ë®àÔºåÁî®ÊñºÈÄ£ÁµêÈ†êÊ∏¨‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåÈÅéÊôÇÁöÑÂü∫Ê∫ñÊ®°ÂûãÂèØËÉΩÊúÉÈ´ò‰º∞ÈÄô‰∫õÊñ∞ÊñπÊ≥ïÊèê‰æõÁöÑÂÑ™Èªû„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÈÄèÈÅé‰ªîÁ¥∞Ë™øÊï¥Ë∂ÖÂèÉÊï∏ÂíåÂà©Áî®Ê≠£‰∫§ÂµåÂÖ•ÂíåÁ∑öÊÄßÂÇ≥Êí≠ÁöÑÊäÄÂ∑ßÔºåÁ≥ªÁµ±ÊÄßÂú∞Á†îÁ©∂ÂúñËá™Á∑®Á¢ºÂô® (GAE) ÁöÑÊΩõÂäõ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåÁ∂ìÈÅéËâØÂ•ΩÊúÄ‰Ω≥ÂåñÁöÑ GAE ÂèØÂåπÈÖçÊõ¥Ë§áÈõúÊ®°ÂûãÁöÑÊïàËÉΩÔºåÂêåÊôÇÊèê‰æõÊõ¥È´òÁöÑË®àÁÆóÊïàÁéá„ÄÇ

##### **Both Text and Images Leaked! A Systematic Analysis of Multimodal LLM Data Contamination**
2411.03823v1 by Dingjie Song, Sicheng Lai, Shunian Chen, Lichao Sun, Benyou Wang

The rapid progression of multimodal large language models (MLLMs) has
demonstrated superior performance on various multimodal benchmarks. However,
the issue of data contamination during training creates challenges in
performance evaluation and comparison. While numerous methods exist for
detecting dataset contamination in large language models (LLMs), they are less
effective for MLLMs due to their various modalities and multiple training
phases. In this study, we introduce a multimodal data contamination detection
framework, MM-Detect, designed for MLLMs. Our experimental results indicate
that MM-Detect is sensitive to varying degrees of contamination and can
highlight significant performance improvements due to leakage of the training
set of multimodal benchmarks. Furthermore, We also explore the possibility of
contamination originating from the pre-training phase of LLMs used by MLLMs and
the fine-tuning phase of MLLMs, offering new insights into the stages at which
contamination may be introduced.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) ÁöÑÂø´ÈÄüÈÄ≤Â±ïÂ∑≤Â±ïÁèæÂá∫Âú®ÂêÑÁ®ÆÂ§öÊ®°ÊÖãÂü∫Ê∫ñ‰∏äÁöÑÂçìË∂äÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåË®ìÁ∑¥ÊúüÈñìÁöÑË≥áÊñôÊ±°ÊüìÂïèÈ°åÁÇ∫ÊïàËÉΩË©ï‰º∞ËàáÊØîËºÉÂ∏∂‰æÜ‰∫ÜÊåëÊà∞„ÄÇÂÑòÁÆ°ÊúâË®±Â§öÊñπÊ≥ïÂèØ‰ª•ÂÅµÊ∏¨Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠ÁöÑË≥áÊñôÈõÜÊ±°ÊüìÔºå‰ΩÜÁî±ÊñºÂÖ∂Â§öÁ®ÆÊ®°ÊÖãÂíåÂ§öÈáçË®ìÁ∑¥ÈöéÊÆµÔºåÈÄô‰∫õÊñπÊ≥ïÂ∞ç MLLM ÁöÑÊïàÊûúËºÉÂ∑Æ„ÄÇÂú®ÈÄôÂÄãÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂºïÈÄ≤‰∫Ü‰∏ÄÂÄãÂ§öÊ®°ÊÖãË≥áÊñôÊ±°ÊüìÂÅµÊ∏¨Êû∂Êßã MM-DetectÔºåÂ∞àÈñÄÈáùÂ∞ç MLLM Ë®≠Ë®à„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåMM-Detect Â∞ç‰∏çÂêåÁ®ãÂ∫¶ÁöÑÊ±°ÊüìÂæàÊïèÊÑüÔºå‰∏¶‰∏îÂèØ‰ª•Âá∏È°ØÁî±ÊñºÂ§öÊ®°ÊÖãÂü∫Ê∫ñË®ìÁ∑¥ÁµÑÁöÑÊ¥©ÊºèËÄåÈÄ†ÊàêÁöÑÈ°ØËëóÊïàËÉΩÊèêÂçá„ÄÇÊ≠§Â§ñÔºåÊàëÂÄë‰πüÊé¢Ë®é‰∫Ü‰æÜËá™ MLLM ÊâÄ‰ΩøÁî®ÁöÑ LLM È†êË®ìÁ∑¥ÈöéÊÆµÂíå MLLM ÁöÑÂæÆË™øÈöéÊÆµÁöÑÊ±°ÊüìÂèØËÉΩÊÄßÔºåÁÇ∫Ê±°ÊüìÂèØËÉΩË¢´ÂºïÂÖ•ÁöÑÈöéÊÆµÊèê‰æõ‰∫ÜÊñ∞ÁöÑË¶ãËß£„ÄÇ

##### **From Novice to Expert: LLM Agent Policy Optimization via Step-wise Reinforcement Learning**
2411.03817v1 by Zhirui Deng, Zhicheng Dou, Yutao Zhu, Ji-Rong Wen, Ruibin Xiong, Mang Wang, Weipeng Chen

The outstanding capabilities of large language models (LLMs) render them a
crucial component in various autonomous agent systems. While traditional
methods depend on the inherent knowledge of LLMs without fine-tuning, more
recent approaches have shifted toward the reinforcement learning strategy to
further enhance agents' ability to solve complex interactive tasks with
environments and tools. However, previous approaches are constrained by the
sparse reward issue, where existing datasets solely provide a final scalar
reward for each multi-step reasoning chain, potentially leading to
ineffectiveness and inefficiency in policy learning. In this paper, we
introduce StepAgent, which utilizes step-wise reward to optimize the agent's
reinforcement learning process. Inheriting the spirit of novice-to-expert
theory, we first compare the actions of the expert and the agent to
automatically generate intermediate rewards for fine-grained optimization.
Additionally, we propose implicit-reward and inverse reinforcement learning
techniques to facilitate agent reflection and policy adjustment. Further
theoretical analysis demonstrates that the action distribution of the agent can
converge toward the expert action distribution over multiple training cycles.
Experimental results across various datasets indicate that StepAgent
outperforms existing baseline methods.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂÇëÂá∫ÂäüËÉΩËÆìÂÆÉÂÄëÊàêÁÇ∫ÂêÑÁ®ÆËá™‰∏ª‰ª£ÁêÜÁ≥ªÁµ±‰∏≠Ëá≥ÈóúÈáçË¶ÅÁöÑÁµÑÊàêÈÉ®ÂàÜ„ÄÇÈõñÁÑ∂ÂÇ≥Áµ±ÊñπÊ≥ï‰æùË≥¥Êñº LLM ÁöÑÂõ∫ÊúâÁü•Ë≠òËÄåÁÑ°ÈúÄÂæÆË™øÔºå‰ΩÜÊúÄËøëÁöÑÊñπÊ≥ïÂ∑≤ËΩâÂêëÂº∑ÂåñÂ≠∏ÁøíÁ≠ñÁï•Ôºå‰ª•ÈÄ≤‰∏ÄÊ≠•Â¢ûÂº∑‰ª£ÁêÜËß£Ê±∫Ë§áÈõú‰∫íÂãï‰ªªÂãôÁöÑËÉΩÂäõÔºåÂåÖÊã¨Áí∞Â¢ÉÂíåÂ∑•ÂÖ∑„ÄÇÁÑ∂ËÄåÔºåÂÖàÂâçÁöÑÂÅöÊ≥ïÂèóÂà∞Á®ÄÁñèÁçéÂãµÂïèÈ°åÁöÑÈôêÂà∂ÔºåÂÖ∂‰∏≠ÁèæÊúâË≥áÊñôÈõÜÂÉÖÁÇ∫ÊØèÂÄãÂ§öÊ≠•È©üÊé®ÁêÜÈèàÊèê‰æõÊúÄÁµÇÊ®ôÈáèÁçéÂãµÔºåÈÄôÂèØËÉΩÊúÉÂ∞éËá¥Á≠ñÁï•Â≠∏ÁøíÁöÑÁÑ°ÊïàÊÄßÂíå‰ΩéÊïàÁéá„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü StepAgentÔºåÂÆÉÂà©Áî®ÈÄêÊ≠•ÁçéÂãµ‰æÜÂÑ™Âåñ‰ª£ÁêÜÁöÑÂº∑ÂåñÂ≠∏ÁøíÈÅéÁ®ã„ÄÇÁπºÊâøÂàùÂ≠∏ËÄÖÂà∞Â∞àÂÆ∂ÁöÑÁêÜË´ñÁ≤æÁ•ûÔºåÊàëÂÄëÈ¶ñÂÖàÊØîËºÉÂ∞àÂÆ∂Âíå‰ª£ÁêÜÁöÑË°åÂãïÔºå‰ª•Ëá™ÂãïÁî¢ÁîüÁî®ÊñºÁ¥∞ÂåñÂÑ™ÂåñÁöÑ‰∏≠ÈñìÁçéÂãµ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÈö±ÂºèÁçéÂãµÂíåÈÄÜÂêëÂº∑ÂåñÂ≠∏ÁøíÊäÄË°ìÔºå‰ª•‰øÉÈÄ≤‰ª£ÁêÜÂèçÊÄùÂíåÁ≠ñÁï•Ë™øÊï¥„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑÁêÜË´ñÂàÜÊûêË°®ÊòéÔºå‰ª£ÁêÜÁöÑË°åÂãïÂàÜ‰ΩàÂèØ‰ª•Âú®Â§öÂÄãË®ìÁ∑¥ÈÄ±Êúü‰∏≠Êî∂ÊñÇÂà∞Â∞àÂÆ∂Ë°åÂãïÂàÜ‰Ωà„ÄÇË∑®ÂêÑÁ®ÆË≥áÊñôÈõÜÁöÑÂØ¶È©óÁµêÊûúË°®ÊòéÔºåStepAgent ÂÑ™ÊñºÁèæÊúâÁöÑÂü∫Ê∫ñÊñπÊ≥ï„ÄÇ

##### **MRJ-Agent: An Effective Jailbreak Agent for Multi-Round Dialogue**
2411.03814v1 by Fengxiang Wang, Ranjie Duan, Peng Xiao, Xiaojun Jia, YueFeng Chen, Chongwen Wang, Jialing Tao, Hang Su, Jun Zhu, Hui Xue

Large Language Models (LLMs) demonstrate outstanding performance in their
reservoir of knowledge and understanding capabilities, but they have also been
shown to be prone to illegal or unethical reactions when subjected to jailbreak
attacks. To ensure their responsible deployment in critical applications, it is
crucial to understand the safety capabilities and vulnerabilities of LLMs.
Previous works mainly focus on jailbreak in single-round dialogue, overlooking
the potential jailbreak risks in multi-round dialogues, which are a vital way
humans interact with and extract information from LLMs. Some studies have
increasingly concentrated on the risks associated with jailbreak in multi-round
dialogues. These efforts typically involve the use of manually crafted
templates or prompt engineering techniques. However, due to the inherent
complexity of multi-round dialogues, their jailbreak performance is limited. To
solve this problem, we propose a novel multi-round dialogue jailbreaking agent,
emphasizing the importance of stealthiness in identifying and mitigating
potential threats to human values posed by LLMs. We propose a risk
decomposition strategy that distributes risks across multiple rounds of queries
and utilizes psychological strategies to enhance attack strength. Extensive
experiments show that our proposed method surpasses other attack methods and
achieves state-of-the-art attack success rate. We will make the corresponding
code and dataset available for future research. The code will be released soon.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Áü•Ë≠òÂÑ≤ÂÇôÂíåÁêÜËß£ËÉΩÂäõÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤Ôºå‰ΩÜÁï∂ÂèóÂà∞Ë∂äÁçÑÊîªÊìäÊôÇÔºåÂÆÉÂÄë‰πüÂÆπÊòìÂá∫ÁèæÈÅïÊ≥ïÊàñ‰∏çÈÅìÂæ∑ÁöÑÂèçÊáâ„ÄÇÁÇ∫‰∫ÜÁ¢∫‰øùÂÆÉÂÄëÂú®ÈóúÈçµÊáâÁî®Á®ãÂºè‰∏≠ÁöÑË≤†Ë≤¨‰ªªÈÉ®ÁΩ≤Ôºå‰∫ÜËß£ LLM ÁöÑÂÆâÂÖ®ËÉΩÂäõÂíåÊºèÊ¥ûËá≥ÈóúÈáçË¶Å„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂‰∏ªË¶ÅÈóúÊ≥®ÂñÆËº™Â∞çË©±‰∏≠ÁöÑË∂äÁçÑÔºåÂøΩË¶ñ‰∫ÜÂ§öËº™Â∞çË©±‰∏≠ÁöÑÊΩõÂú®Ë∂äÁçÑÈ¢®Èö™ÔºåËÄåÂ§öËº™Â∞çË©±ÊòØ‰∫∫È°ûËàá LLM ‰∫íÂãï‰∏¶‰ªé‰∏≠ÊèêÂèñ‰ø°ÊÅØÁöÑÈáçË¶ÅÊñπÂºè„ÄÇ‰∏Ä‰∫õÁ†îÁ©∂Ë∂ä‰æÜË∂äÈóúÊ≥®Â§öËº™Â∞çË©±‰∏≠Ë∂äÁçÑÁõ∏ÈóúÁöÑÈ¢®Èö™„ÄÇÈÄô‰∫õÂä™ÂäõÈÄöÂ∏∏Ê∂âÂèä‰ΩøÁî®‰∫∫Â∑•Ë£Ω‰ΩúÁöÑÁØÑÊú¨ÊàñÊèêÁ§∫Â∑•Á®ãÊäÄË°ì„ÄÇÁÑ∂ËÄåÔºåÁî±ÊñºÂ§öËº™Â∞çË©±ÁöÑË§áÈõúÊÄßÔºåÂÆÉÂÄëÁöÑË∂äÁçÑÊÄßËÉΩÂèóÂà∞ÈôêÂà∂„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂ§öËº™Â∞çË©±Ë∂äÁçÑ‰ª£ÁêÜÔºåÂº∑Ë™øÂú®Ë≠òÂà•ÂíåÊ∏õËºï LLM Â∞ç‰∫∫È°ûÂÉπÂÄºËßÄÊßãÊàêÁöÑÊΩõÂú®Â®ÅËÑÖÊôÇÈö±ËîΩÊÄßÁöÑÈáçË¶ÅÊÄß„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÈ¢®Èö™ÂàÜËß£Á≠ñÁï•ÔºåÂ∞áÈ¢®Èö™ÂàÜ‰ΩàÂú®Â§öËº™Êü•Ë©¢‰∏≠Ôºå‰∏¶Âà©Áî®ÂøÉÁêÜÁ≠ñÁï•‰æÜÂ¢ûÂº∑ÊîªÊìäÂº∑Â∫¶„ÄÇÂ§ßÈáèÁöÑÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÂÑ™ÊñºÂÖ∂‰ªñÊîªÊìäÊñπÊ≥ïÔºå‰∏¶ÂØ¶Áèæ‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊîªÊìäÊàêÂäüÁéá„ÄÇÊàëÂÄëÂ∞áÊèê‰æõÁõ∏ÊáâÁöÑÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÈõÜÔºå‰æõÂ∞á‰æÜÁöÑÁ†îÁ©∂‰ΩøÁî®„ÄÇÁ®ãÂºèÁ¢ºÂ∞áÂæàÂø´ÁôºÂ∏É„ÄÇ

##### **The natural stability of autonomous morphology**
2411.03811v1 by Erich Round, Louise Esher, Sacha Beniamine

Autonomous morphology, such as inflection class systems and paradigmatic
distribution patterns, is widespread and diachronically resilient in natural
language. Why this should be so has remained unclear given that autonomous
morphology imposes learning costs, offers no clear benefit relative to its
absence and could easily be removed by the analogical forces which are
constantly reshaping it. Here we propose an explanation for the resilience of
autonomous morphology, in terms of a diachronic dynamic of attraction and
repulsion between morphomic categories, which emerges spontaneously from a
simple paradigm cell filling process. Employing computational evolutionary
models, our key innovation is to bring to light the role of `dissociative
evidence', i.e., evidence for inflectional distinctiveness which a rational
reasoner will have access to during analogical inference. Dissociative evidence
creates a repulsion dynamic which prevents morphomic classes from collapsing
together entirely, i.e., undergoing complete levelling. As we probe alternative
models, we reveal the limits of conditional entropy as a measure for
predictability in systems that are undergoing change. Finally, we demonstrate
that autonomous morphology, far from being `unnatural' (e.g.
\citealt{Aronoff1994}), is rather the natural (emergent) consequence of a
natural (rational) process of inference applied to inflectional systems.

ÊëòË¶ÅÔºö<paragraph>Ëá™‰∏ªÂΩ¢ÊÖãÂ≠∏Ôºå‰æãÂ¶ÇË©ûÂΩ¢ËÆäÂåñÈ°ûÂà•Á≥ªÁµ±ÂíåÁØÑ‰æãÂàÜ‰ΩàÊ®°ÂºèÔºåÂú®Ëá™ÁÑ∂Ë™ûË®Ä‰∏≠Âª£Ê≥õÂ≠òÂú®‰∏îÊ≠∑ÊôÇÊÄßÂº∑Èüå„ÄÇÁÇ∫‰ªÄÈ∫ºÊúÉÈÄôÊ®£‰∏ÄÁõ¥‰∏çÊòéÁ¢∫ÔºåÂõ†ÁÇ∫Ëá™‰∏ªÂΩ¢ÊÖãÂ≠∏Âº∑Âä†‰∫ÜÂ≠∏ÁøíÊàêÊú¨ÔºåÁõ∏Â∞çÊñºÂÖ∂‰∏çÂ≠òÂú®Ê≤íÊúâÊòéÈ°ØÁöÑÂÑ™Âã¢Ôºå‰∏¶‰∏îÂèØ‰ª•ÂæàÂÆπÊòìÂú∞ÈÄöÈÅé‰∏çÊñ∑ÈáçÂ°ëÂÆÉÁöÑÈ°ûÊØîÂäõÂéªÈô§„ÄÇÂú®ÈÄôË£°ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂ∞çËá™‰∏ªÂΩ¢ÊÖãÂ≠∏ÂΩàÊÄßÁöÑËß£ÈáãÔºåÂç≥ÂΩ¢ÊÖãÂ≠∏È°ûÂà•‰πãÈñìÁöÑÊ≠∑ÊôÇÊÄßÂê∏ÂºïÂíåÊéíÊñ•ÂãïÊÖãÔºåÂÆÉËá™ÁôºÂú∞Âæû‰∏ÄÂÄãÁ∞°ÂñÆÁöÑÁØÑ‰æãÂñÆÂÖÉÂ°´ÂÖÖÈÅéÁ®ã‰∏≠Âá∫Áèæ„ÄÇÊé°Áî®Ë®àÁÆóÊºîÂåñÊ®°ÂûãÔºåÊàëÂÄëÁöÑÈóúÈçµÂâµÊñ∞ÊòØÈó°Êòé„ÄåÂàÜÈõ¢Ë≠âÊìö„ÄçÁöÑ‰ΩúÁî®ÔºåÂç≥ÁêÜÊÄßÊé®ÁêÜËÄÖÂú®È°ûÊØîÊé®ÁêÜÈÅéÁ®ã‰∏≠ÂèØ‰ª•Áç≤ÂæóÁöÑË©ûÂΩ¢ËÆäÂåñÁç®ÁâπÊÄßË≠âÊìö„ÄÇÂàÜÈõ¢Ë≠âÊìöÂâµÈÄ†‰∫Ü‰∏ÄÂÄãÊéíÊñ•ÂãïÊÖãÔºåÈò≤Ê≠¢ÂΩ¢ÊÖãÂ≠∏È°ûÂà•ÂÆåÂÖ®Â¥©ÊΩ∞ÔºåÂç≥ÈÄ≤Ë°åÂÆåÂÖ®ÁöÑÂπ≥Ê∫ñÂåñ„ÄÇÁï∂ÊàëÂÄëÊé¢Á©∂Êõø‰ª£Ê®°ÂûãÊôÇÔºåÊàëÂÄëÊè≠Á§∫‰∫ÜÊ¢ù‰ª∂ÁÜµ‰ΩúÁÇ∫Ê≠£Âú®ÁôºÁîüËÆäÂåñÁöÑÁ≥ªÁµ±‰∏≠ÂèØÈ†êÊ∏¨ÊÄßÁöÑÊ∏¨ÈáèÊ•µÈôê„ÄÇÊúÄÂæåÔºåÊàëÂÄëË≠âÊòéËá™‰∏ªÂΩ¢ÊÖãÂ≠∏ÈÅ†Èùû„ÄåÈùûËá™ÁÑ∂„ÄçÔºà‰æãÂ¶Ç \citealt{Aronoff1994}ÔºâÔºåËÄåÊòØÊáâÁî®ÊñºË©ûÂΩ¢ËÆäÂåñÁ≥ªÁµ±ÁöÑËá™ÁÑ∂ÔºàÁêÜÊÄßÔºâÊé®ÁêÜÈÅéÁ®ãÁöÑËá™ÁÑ∂ÔºàÊπßÁèæÔºâÁµêÊûú„ÄÇ</paragraph>

##### **GS2Pose: Tow-stage 6D Object Pose Estimation Guided by Gaussian Splatting**
2411.03807v1 by Jilan Mei, Junbo Li, Cai Meng

This paper proposes a new method for accurate and robust 6D pose estimation
of novel objects, named GS2Pose. By introducing 3D Gaussian splatting, GS2Pose
can utilize the reconstruction results without requiring a high-quality CAD
model, which means it only requires segmented RGBD images as input.
Specifically, GS2Pose employs a two-stage structure consisting of coarse
estimation followed by refined estimation. In the coarse stage, a lightweight
U-Net network with a polarization attention mechanism, called Pose-Net, is
designed. By using the 3DGS model for supervised training, Pose-Net can
generate NOCS images to compute a coarse pose. In the refinement stage, GS2Pose
formulates a pose regression algorithm following the idea of reprojection or
Bundle Adjustment (BA), referred to as GS-Refiner. By leveraging Lie algebra to
extend 3DGS, GS-Refiner obtains a pose-differentiable rendering pipeline that
refines the coarse pose by comparing the input images with the rendered images.
GS-Refiner also selectively updates parameters in the 3DGS model to achieve
environmental adaptation, thereby enhancing the algorithm's robustness and
flexibility to illuminative variation, occlusion, and other challenging
disruptive factors. GS2Pose was evaluated through experiments conducted on the
LineMod dataset, where it was compared with similar algorithms, yielding highly
competitive results. The code for GS2Pose will soon be released on GitHub.

ÊëòË¶ÅÔºöÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊñπÊ≥ïÔºåÁî®ÊñºÊ∫ñÁ¢∫‰∏îÁ©©ÂÅ•Âú∞‰º∞Ë®àÊñ∞Áâ©È´îÁöÑ 6D ÂßøÂã¢ÔºåÁ®±ÁÇ∫ GS2Pose„ÄÇÈÄèÈÅéÂºïÂÖ• 3D È´òÊñØÂô¥Êø∫ÔºåGS2Pose ÂèØ‰ª•Âà©Áî®ÈáçÂª∫ÁµêÊûúÔºåËÄåÁÑ°ÈúÄÈ´òÂìÅË≥™ÁöÑ CAD Ê®°ÂûãÔºåÈÄôË°®Á§∫ÂÆÉÂè™ÈúÄË¶ÅÂàÜÂâ≤ÁöÑ RGBD ÂΩ±ÂÉè‰ΩúÁÇ∫Ëº∏ÂÖ•„ÄÇÂÖ∑È´î‰æÜË™™ÔºåGS2Pose ‰ΩøÁî®Áî±Á≤óÁï•‰º∞Ë®àÂíåÁ≤æÁ∑ª‰º∞Ë®àÁµÑÊàêÁöÑÂÖ©ÈöéÊÆµÁµêÊßã„ÄÇÂú®Á≤óÁï•ÈöéÊÆµÔºåË®≠Ë®à‰∫Ü‰∏ÄÂÄãÂÖ∑ÊúâÊ•µÂåñÊ≥®ÊÑèÂäõÊ©üÂà∂ÁöÑËºïÈáèÁ¥ö U-Net Á∂≤Ë∑ØÔºåÁ®±ÁÇ∫ Pose-Net„ÄÇÈÄèÈÅé‰ΩøÁî® 3DGS Ê®°ÂûãÈÄ≤Ë°åÁõ£Áù£Ë®ìÁ∑¥ÔºåPose-Net ÂèØ‰ª•Áî¢Áîü NOCS ÂΩ±ÂÉè‰æÜË®àÁÆóÁ≤óÁï•ÂßøÂã¢„ÄÇÂú®Á≤æÁ∑ªÈöéÊÆµÔºåGS2Pose Ê†πÊìöÈáçÊñ∞ÊäïÂΩ±ÊàñÊùüË™øÊï¥ (BA) ÁöÑÊ¶ÇÂøµÂà∂ÂÆö‰∫Ü‰∏ÄÂÄãÂßøÂã¢ÂõûÊ≠∏ÊºîÁÆóÊ≥ïÔºåÁ®±ÁÇ∫ GS-Refiner„ÄÇÈÄèÈÅéÂà©Áî®Êùé‰ª£Êï∏‰æÜÊì¥ÂÖÖ 3DGSÔºåGS-Refiner Áç≤Âæó‰∫Ü‰∏ÄÂÄãÂßøÂã¢ÂèØÂæÆÂàÜÊ∏≤ÊüìÁÆ°Á∑öÔºåÂÆÉÈÄèÈÅéÊØîËºÉËº∏ÂÖ•ÂΩ±ÂÉèËàáÊ∏≤ÊüìÂΩ±ÂÉè‰æÜÁ≤æÁ∑ªÁ≤óÁï•ÂßøÂã¢„ÄÇGS-Refiner ‰πüÈÅ∏ÊìáÊÄßÂú∞Êõ¥Êñ∞ 3DGS Ê®°Âûã‰∏≠ÁöÑÂèÉÊï∏Ôºå‰ª•ÂØ¶ÁèæÁí∞Â¢ÉÈÅ©ÊáâÔºåÂæûËÄåÂ¢ûÂº∑ÊºîÁÆóÊ≥ïÂ∞çÂÖâÁÖßËÆäÂåñ„ÄÅÈÅÆÊìãÂíåÂÖ∂‰ªñÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÁ†¥Â£ûÂõ†Á¥†ÁöÑÁ©©ÂÅ•ÊÄßÂíåÈùàÊ¥ªÊÄß„ÄÇGS2Pose ÈÄèÈÅéÂú® LineMod Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÁöÑÂØ¶È©óÈÄ≤Ë°åË©ï‰º∞ÔºåÂú®Ë©≤Ë≥áÊñôÈõÜ‰∏äÂ∞áÂÖ∂ËàáÈ°û‰ººÁöÑÊºîÁÆóÊ≥ïÈÄ≤Ë°åÊØîËºÉÔºåÁî¢Áîü‰∫ÜÊ•µÂÖ∑Á´∂Áà≠ÂäõÁöÑÁµêÊûú„ÄÇGS2Pose ÁöÑÁ®ãÂºèÁ¢ºÂ∞áÂæàÂø´Âú® GitHub ‰∏äÁôºÂ∏É„ÄÇ

##### **Understanding the Effects of Human-written Paraphrases in LLM-generated Text Detection**
2411.03806v1 by Hiu Ting Lau, Arkaitz Zubiaga

Natural Language Generation has been rapidly developing with the advent of
large language models (LLMs). While their usage has sparked significant
attention from the general public, it is important for readers to be aware when
a piece of text is LLM-generated. This has brought about the need for building
models that enable automated LLM-generated text detection, with the aim of
mitigating potential negative outcomes of such content. Existing LLM-generated
detectors show competitive performances in telling apart LLM-generated and
human-written text, but this performance is likely to deteriorate when
paraphrased texts are considered. In this study, we devise a new data
collection strategy to collect Human & LLM Paraphrase Collection (HLPC), a
first-of-its-kind dataset that incorporates human-written texts and
paraphrases, as well as LLM-generated texts and paraphrases. With the aim of
understanding the effects of human-written paraphrases on the performance of
state-of-the-art LLM-generated text detectors OpenAI RoBERTa and watermark
detectors, we perform classification experiments that incorporate human-written
paraphrases, watermarked and non-watermarked LLM-generated documents from GPT
and OPT, and LLM-generated paraphrases from DIPPER and BART. The results show
that the inclusion of human-written paraphrases has a significant impact of
LLM-generated detector performance, promoting TPR@1%FPR with a possible
trade-off of AUROC and accuracy.

ÊëòË¶ÅÔºö<paragraph>Èö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂá∫ÁèæÔºåËá™ÁÑ∂Ë™ûË®ÄÁîüÊàêÊäÄË°ìÁç≤Âæó‰∫ÜÂø´ÈÄüÁôºÂ±ï„ÄÇÂÑòÁÆ°ÂÖ∂‰ΩøÁî®ÂºïËµ∑‰∫ÜÂÖ¨ÁúæÁöÑÊ•µÂ§ßÈóúÊ≥®Ôºå‰ΩÜËÆÄËÄÖÂú®Èñ±ËÆÄ LLM ÁîüÊàêÁöÑÊñáÊú¨ÊôÇÔºå‰∫ÜËß£ÂÖ∂‰æÜÊ∫êÈùûÂ∏∏ÈáçË¶Å„ÄÇÈÄô‰ΩøÂæóÂª∫Á´ãÊ®°Âûã‰ª•ÂØ¶ÁèæËá™Âãï LLM ÁîüÊàêÁöÑÊñáÊú¨Ê™¢Ê∏¨ËÆäÂæóÂçÅÂàÜÂøÖË¶ÅÔºåÁõÆÁöÑÊòØÊ∏õËºïÊ≠§È°ûÂÖßÂÆπÊΩõÂú®ÁöÑË≤†Èù¢ÂΩ±Èüø„ÄÇÁèæÊúâÁöÑ LLM ÁîüÊàêÁöÑÊ™¢Ê∏¨Âô®Âú®ÂçÄÂàÜ LLM ÁîüÊàêÁöÑÊñáÊú¨Âíå‰∫∫È°ûÊí∞ÂØ´ÁöÑÊñáÊú¨ÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤Ôºå‰ΩÜÁï∂ËÄÉÊÖÆÂà∞ÊîπÂØ´ÁöÑÊñáÊú¨ÊôÇÔºåÈÄôÁ®ÆË°®ÁèæÂèØËÉΩÊúÉ‰∏ãÈôç„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊï∏ÊìöÊî∂ÈõÜÁ≠ñÁï•ÔºåÁî®ÊñºÊî∂ÈõÜ‰∫∫È°ûÂíå LLM ÊîπÂØ´Ë™ûÊñôÂ∫´ (HLPC)ÔºåÈÄôÊòØ‰∏ÄÂÄãÈ¶ñÂâµÁöÑÊï∏ÊìöÈõÜÔºåÂåÖÂê´‰∫∫È°ûÊí∞ÂØ´ÁöÑÊñáÊú¨ÂíåÊîπÂØ´Ôºå‰ª•Âèä LLM ÁîüÊàêÁöÑÊñáÊú¨ÂíåÊîπÂØ´„ÄÇÁÇ∫‰∫Ü‰∫ÜËß£‰∫∫È°ûÊí∞ÂØ´ÁöÑÊîπÂØ´Â∞çÊúÄÂÖàÈÄ≤ÁöÑ LLM ÁîüÊàêÁöÑÊñáÊú¨Ê™¢Ê∏¨Âô® OpenAI RoBERTa ÂíåÊ∞¥Âç∞Ê™¢Ê∏¨Âô®ÁöÑÊïàËÉΩÁöÑÂΩ±ÈüøÔºåÊàëÂÄëÈÄ≤Ë°å‰∫ÜÂàÜÈ°ûÂØ¶È©óÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∫∫È°ûÊí∞ÂØ´ÁöÑÊîπÂØ´„ÄÅÂ∏∂Ê∞¥Âç∞Âíå‰∏çÂ∏∂Ê∞¥Âç∞ÁöÑ GPT Âíå OPT ÁîüÊàêÁöÑ LLM Êñá‰ª∂Ôºå‰ª•Âèä DIPPER Âíå BART ÁîüÊàêÁöÑ LLM ÊîπÂØ´„ÄÇÁµêÊûúË°®ÊòéÔºåÂåÖÂê´‰∫∫È°ûÊí∞ÂØ´ÁöÑÊîπÂØ´Â∞ç LLM ÁîüÊàêÁöÑÊ™¢Ê∏¨Âô®ÊïàËÉΩÊúâÈ°ØËëóÂΩ±ÈüøÔºå‰ª•ÂèØËÉΩÁöÑ AUROC ÂíåÊ∫ñÁ¢∫ÊÄßÁöÑÊ¨äË°°‰æÜÊèêÂçá TPR@1%FPR„ÄÇ</paragraph>

##### **A Comparative Study of Recent Large Language Models on Generating Hospital Discharge Summaries for Lung Cancer Patients**
2411.03805v1 by Yiming Li, Fang Li, Kirk Roberts, Licong Cui, Cui Tao, Hua Xu

Generating discharge summaries is a crucial yet time-consuming task in
clinical practice, essential for conveying pertinent patient information and
facilitating continuity of care. Recent advancements in large language models
(LLMs) have significantly enhanced their capability in understanding and
summarizing complex medical texts. This research aims to explore how LLMs can
alleviate the burden of manual summarization, streamline workflow efficiencies,
and support informed decision-making in healthcare settings. Clinical notes
from a cohort of 1,099 lung cancer patients were utilized, with a subset of 50
patients for testing purposes, and 102 patients used for model fine-tuning.
This study evaluates the performance of multiple LLMs, including GPT-3.5,
GPT-4, GPT-4o, and LLaMA 3 8b, in generating discharge summaries. Evaluation
metrics included token-level analysis (BLEU, ROUGE-1, ROUGE-2, ROUGE-L) and
semantic similarity scores between model-generated summaries and
physician-written gold standards. LLaMA 3 8b was further tested on clinical
notes of varying lengths to examine the stability of its performance. The study
found notable variations in summarization capabilities among LLMs. GPT-4o and
fine-tuned LLaMA 3 demonstrated superior token-level evaluation metrics, while
LLaMA 3 consistently produced concise summaries across different input lengths.
Semantic similarity scores indicated GPT-4o and LLaMA 3 as leading models in
capturing clinical relevance. This study contributes insights into the efficacy
of LLMs for generating discharge summaries, highlighting LLaMA 3's robust
performance in maintaining clarity and relevance across varying clinical
contexts. These findings underscore the potential of automated summarization
tools to enhance documentation precision and efficiency, ultimately improving
patient care and operational capability in healthcare settings.

ÊëòË¶ÅÔºö<paragraph>ÁîüÊàêÂá∫Èô¢ÊëòË¶ÅÂú®Ëá®Â∫äÂØ¶Âãô‰∏≠ÊòØ‰∏ÄÈ†ÖËá≥ÈóúÈáçË¶ÅÁöÑ‰ªªÂãôÔºåÂçªÂèàÂçÅÂàÜËÄóÊôÇÔºåÂ∞çÊñºÂÇ≥ÈÅîÁõ∏ÈóúÁöÑÁóÖÊÇ£Ë≥áË®äÂíå‰øÉÈÄ≤ÁÖßË≠∑ÁöÑÈÄ£Á∫åÊÄßËá≥ÈóúÈáçË¶Å„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÈ°ØËëóÂ¢ûÂº∑‰∫ÜÂÆÉÂÄëÂú®ÁêÜËß£ÂíåÊëòË¶ÅË§áÈõúÈÜ´ÁôÇÊñáÊú¨ÊñπÈù¢ÁöÑËÉΩÂäõ„ÄÇÊú¨Á†îÁ©∂Êó®Âú®Êé¢Ë®é LLM Â¶Ç‰ΩïÊ∏õËºïÊâãÂãïÊëòË¶ÅÁöÑË≤†Êìî„ÄÅÁ∞°ÂåñÂ∑•‰ΩúÊµÅÁ®ãÊïàÁéáÔºå‰∏¶ÊîØÊè¥ÈÜ´ÁôÇ‰øùÂÅ•Áí∞Â¢É‰∏≠ÁöÑÊòéÊô∫Ê±∫Á≠ñÂà∂ÂÆö„ÄÇÂà©Áî®‰æÜËá™ 1,099 ÂêçËÇ∫ÁôåÊÇ£ËÄÖÁöÑËá®Â∫äÁ≠ÜË®òÔºåÂÖ∂‰∏≠ 50 ÂêçÊÇ£ËÄÖÁî®ÊñºÊ∏¨Ë©¶ÁõÆÁöÑÔºå102 ÂêçÊÇ£ËÄÖÁî®ÊñºÊ®°ÂûãÂæÆË™ø„ÄÇÊú¨Á†îÁ©∂Ë©ï‰º∞‰∫ÜÂ§öÂÄã LLM ÁöÑÊïàËÉΩÔºåÂåÖÊã¨ GPT-3.5„ÄÅGPT-4„ÄÅGPT-4o Âíå LLaMA 3 8bÔºåÂú®ÁîüÊàêÂá∫Èô¢ÊëòË¶ÅÊñπÈù¢ÁöÑË°®Áèæ„ÄÇË©ï‰º∞ÊåáÊ®ôÂåÖÊã¨Á¨¶ËôüÂ±§Á¥öÂàÜÊûê (BLEU„ÄÅROUGE-1„ÄÅROUGE-2„ÄÅROUGE-L) ÂíåÊ®°ÂûãÁî¢ÁîüÁöÑÊëòË¶ÅËàáÈÜ´Â∏´Êí∞ÂØ´ÁöÑÈáëÊ®ôÊ∫ñ‰πãÈñìÁöÑË™ûÊÑèÁõ∏‰ººÊÄßË©ïÂàÜ„ÄÇLLaMA 3 8b ÈÄ≤‰∏ÄÊ≠•Âú®‰∏çÂêåÈï∑Â∫¶ÁöÑËá®Â∫äÁ≠ÜË®ò‰∏äÈÄ≤Ë°åÊ∏¨Ë©¶Ôºå‰ª•Ê™¢Êü•ÂÖ∂ÊïàËÉΩÁöÑÁ©©ÂÆöÊÄß„ÄÇÁ†îÁ©∂ÁôºÁèæÔºåLLM ‰πãÈñìÁöÑÊëòË¶ÅËÉΩÂäõÂ≠òÂú®È°ØËëóÂ∑ÆÁï∞„ÄÇGPT-4o ÂíåÂæÆË™øÂæåÁöÑ LLaMA 3 Ë°®ÁèæÂá∫ÂÑ™Áï∞ÁöÑÁ¨¶ËôüÂ±§Á¥öË©ï‰º∞ÊåáÊ®ôÔºåËÄå LLaMA 3 Âú®‰∏çÂêåÁöÑËº∏ÂÖ•Èï∑Â∫¶‰∏ãÊåÅÁ∫åÁî¢ÁîüÁ∞°ÊΩîÁöÑÊëòË¶Å„ÄÇË™ûÊÑèÁõ∏‰ººÊÄßË©ïÂàÜÈ°ØÁ§∫ GPT-4o Âíå LLaMA 3 Âú®ÊçïÊçâËá®Â∫äÁõ∏ÈóúÊÄßÊñπÈù¢ÊòØÈ†òÂÖàÁöÑÊ®°Âûã„ÄÇÊú¨Á†îÁ©∂ÊúâÂä©ÊñºÊ∑±ÂÖ•‰∫ÜËß£ LLM Âú®ÁîüÊàêÂá∫Èô¢ÊëòË¶ÅÊñπÈù¢ÁöÑÊïàËÉΩÔºåÂº∑Ë™ø LLaMA 3 Âú®Á∂≠ÊåÅ‰∏çÂêåËá®Â∫äËÉåÊôØ‰∏ãÁöÑÊ∏ÖÊô∞Â∫¶ÂíåÁõ∏ÈóúÊÄßÊñπÈù¢ÁöÑÂº∑ÂÅ•Ë°®Áèæ„ÄÇÈÄô‰∫õÁôºÁèæÂº∑Ë™ø‰∫ÜËá™ÂãïÂåñÊëòË¶ÅÂ∑•ÂÖ∑Âú®ÊèêÂçáÊñá‰ª∂Ê∫ñÁ¢∫Â∫¶ÂíåÊïàÁéáÊñπÈù¢ÁöÑÊΩõÂäõÔºåÊúÄÁµÇÊîπÂñÑÈÜ´ÁôÇ‰øùÂÅ•Áí∞Â¢É‰∏≠ÁöÑÊÇ£ËÄÖÁÖßË≠∑ÂíåÁáüÈÅãËÉΩÂäõ„ÄÇ</paragraph>

##### **Overcoming label shift in targeted federated learning**
2411.03799v1 by Edvin Listo Zec, Adam Breitholtz, Fredrik D. Johansson

Federated learning enables multiple actors to collaboratively train models
without sharing private data. This unlocks the potential for scaling machine
learning to diverse applications. Existing algorithms for this task are
well-justified when clients and the intended target domain share the same
distribution of features and labels, but this assumption is often violated in
real-world scenarios. One common violation is label shift, where the label
distributions differ across clients or between clients and the target domain,
which can significantly degrade model performance. To address this problem, we
propose FedPALS, a novel model aggregation scheme that adapts to label shifts
by leveraging knowledge of the target label distribution at the central server.
Our approach ensures unbiased updates under stochastic gradient descent,
ensuring robust generalization across clients with diverse, label-shifted data.
Extensive experiments on image classification demonstrate that FedPALS
consistently outperforms standard baselines by aligning model aggregation with
the target domain. Our findings reveal that conventional federated learning
methods suffer severely in cases of extreme client sparsity, highlighting the
critical need for target-aware aggregation. FedPALS offers a principled and
practical solution to mitigate label distribution mismatch, ensuring models
trained in federated settings can generalize effectively to label-shifted
target domains.

ÊëòË¶ÅÔºöËÅØÈÇ¶Â≠∏Áøí‰ΩøÂ§öÂÄãÂèÉËàáËÄÖËÉΩÂ§†Âçî‰ΩúË®ìÁ∑¥Ê®°ÂûãÔºåËÄå‰∏çÈúÄÂÖ±‰∫´ÁßÅ‰∫∫Êï∏Êìö„ÄÇÈÄôËß£Èéñ‰∫ÜÂ∞áÊ©üÂô®Â≠∏ÁøíÊì¥Â±ïÂà∞ÂêÑÁ®ÆÊáâÁî®Á®ãÂºèÁöÑÊΩõÂäõ„ÄÇÁï∂ÂÆ¢Êà∂Á´ØÂíåÈ†êÊúüÁöÑÁõÆÊ®ôÁ∂≤ÂüüÂÖ±‰∫´Áõ∏ÂêåÁöÑÁâπÂæµÂíåÊ®ôÁ±§ÂàÜÂ∏ÉÊôÇÔºåÁèæÊúâÁöÑÊºîÁÆóÊ≥ïÂ∞çÊñºÈÄôÈ†Ö‰ªªÂãô‰æÜË™™ÊòØÂêàÁêÜÁöÑÔºå‰ΩÜÈÄôÂÄãÂÅáË®≠Âú®ÁúüÂØ¶‰∏ñÁïåÁöÑÂ†¥ÊôØ‰∏≠Â∏∏Â∏∏Ë¢´ÈÅïÂèç„ÄÇÊ®ôÁ±§ËΩâÁßªÊòØ‰∏ÄÂÄãÂ∏∏Ë¶ãÁöÑÈÅïÂèçÔºåÂÖ∂‰∏≠Ê®ôÁ±§ÂàÜÂ∏ÉÂú®ÂÆ¢Êà∂Á´Ø‰πãÈñìÊàñÂÆ¢Êà∂Á´ØÂíåÁõÆÊ®ôÁ∂≤Âüü‰πãÈñìÊúâÊâÄ‰∏çÂêåÔºåÈÄôÂèØËÉΩÊúÉÈ°ØËëóÈôç‰ΩéÊ®°ÂûãÊïàËÉΩ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü FedPALSÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊ®°ÂûãËÅöÂêàÊñπÊ°àÔºåÂÆÉÈÄèÈÅéÂà©Áî®‰∏≠Â§Æ‰º∫ÊúçÂô®‰∏äÁõÆÊ®ôÊ®ôÁ±§ÂàÜÂ∏ÉÁöÑÁü•Ë≠ò‰æÜÈÅ©ÊáâÊ®ôÁ±§ËΩâÁßª„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÁ¢∫‰øù‰∫ÜÈö®Ê©üÊ¢ØÂ∫¶‰∏ãÈôç‰∏ãÁöÑÁÑ°ÂÅèÊõ¥Êñ∞ÔºåÁ¢∫‰øù‰∫ÜÂú®ÂÖ∑Êúâ‰∏çÂêåÊ®ôÁ±§ËΩâÁßªÊï∏ÊìöÁöÑÂÆ¢Êà∂Á´Ø‰πãÈñìÁöÑÁ©©ÂÅ•Ê¶ÇÂåñ„ÄÇÂú®ÂΩ±ÂÉèÂàÜÈ°û‰∏äÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòéÔºåFedPALS ÈÄèÈÅéÂ∞áÊ®°ÂûãËÅöÂêàËàáÁõÆÊ®ôÁ∂≤ÂüüÂ∞çÈΩäÔºåÂßãÁµÇÂÑ™ÊñºÊ®ôÊ∫ñÂü∫Ê∫ñ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåÂÇ≥Áµ±ÁöÑËÅØÈÇ¶Â≠∏ÁøíÊñπÊ≥ïÂú®Ê•µÁ´ØÂÆ¢Êà∂Á´ØÁ®ÄÁñèÊÄßÁöÑÊÉÖÊ≥Å‰∏ãÊúÉÈÅ≠ÂèóÂö¥ÈáçÂΩ±ÈüøÔºåÁ™ÅÈ°Ø‰∫ÜÂ∞çÁõÆÊ®ôÊÑüÁü•ËÅöÂêàÁöÑÈóúÈçµÈúÄÊ±Ç„ÄÇFedPALS Êèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÂéüÂâá‰∏îÂØ¶Áî®ÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰ª•Ê∏õËºïÊ®ôÁ±§ÂàÜÂ∏É‰∏çÂåπÈÖçÔºåÁ¢∫‰øùÂú®ËÅØÈÇ¶Ë®≠ÂÆö‰∏≠Ë®ìÁ∑¥ÁöÑÊ®°ÂûãËÉΩÂ§†ÊúâÊïàÊ¶ÇÂåñÂà∞Ê®ôÁ±§ËΩâÁßªÁöÑÁõÆÊ®ôÁ∂≤Âüü„ÄÇ

##### **VQA$^2$:Visual Question Answering for Video Quality Assessment**
2411.03795v1 by Ziheng Jia, Zicheng Zhang, Jiaying Qian, Haoning Wu, Wei Sun, Chunyi Li, Xiaohong Liu, Weisi Lin, Guangtao Zhai, Xiongkuo Min

The advent and proliferation of large multi-modal models (LMMs) have
introduced a new paradigm to video-related computer vision fields, including
training and inference methods based on visual question answering (VQA). These
methods enable models to handle multiple downstream tasks robustly. Video
Quality Assessment (VQA), a classic field in low-level visual quality
evaluation, originally focused on quantitative video quality scoring. However,
driven by advances in LMMs, it is now evolving towards more comprehensive
visual quality understanding tasks. Visual question answering has significantly
improved low-level visual evaluation within the image domain recently. However,
related work is almost nonexistent in the video domain, leaving substantial
room for improvement. To address this gap, we introduce the VQA2 Instruction
Dataset the first visual question answering instruction dataset entirely
focuses on video quality assessment, and based on it, we propose the VQA2
series models The VQA2 Instruction Dataset consists of three stages and covers
various video types, containing 157,735 instruction question-answer pairs,
including both manually annotated and synthetic data. We conduct extensive
experiments on both video quality scoring and video quality understanding
tasks. Results demonstrate that the VQA2 series models achieve state-of-the-art
(SOTA) performance in quality scoring tasks, and their performance in visual
quality question answering surpasses the renowned GPT-4o. Additionally, our
final model, the VQA2-Assistant, performs well across both scoring and
question-answering tasks, validating its versatility.

ÊëòË¶ÅÔºöÂ§ßÂûãÂ§öÊ®°ÊÄÅÊ®°Âûã (LMM) ÁöÑÂá∫Áé∞ÂíåÊôÆÂèä‰∏∫ËßÜÈ¢ëÁõ∏ÂÖ≥ÁöÑËÆ°ÁÆóÊú∫ËßÜËßâÈ¢ÜÂüüÂºïÂÖ•‰∫Ü‰∏ÄÁßçÊñ∞ËåÉ‰æãÔºåÂåÖÊã¨Âü∫‰∫éËßÜËßâÈóÆÁ≠î (VQA) ÁöÑËÆ≠ÁªÉÂíåÊé®ÁêÜÊñπÊ≥ï„ÄÇËøô‰∫õÊñπÊ≥ï‰ΩøÊ®°ÂûãËÉΩÂ§üÁ®≥ÂÅ•Âú∞Â§ÑÁêÜÂ§ö‰∏™‰∏ãÊ∏∏‰ªªÂä°„ÄÇËßÜÈ¢ëË¥®ÈáèËØÑ‰º∞ (VQA) ÊòØ‰ΩéÁ∫ßËßÜËßâË¥®ÈáèËØÑ‰º∞‰∏≠ÁöÑ‰∏Ä‰∏™ÁªèÂÖ∏È¢ÜÂüüÔºåÊúÄÂàù‰∏ìÊ≥®‰∫éÂÆöÈáèËßÜÈ¢ëË¥®ÈáèËØÑÂàÜ„ÄÇÁÑ∂ËÄåÔºåÂú® LMM ÁöÑÊé®Âä®‰∏ãÔºåÂÆÉÁé∞Âú®Ê≠£ÊúùÁùÄÊõ¥ÂÖ®Èù¢ÁöÑËßÜËßâË¥®ÈáèÁêÜËß£‰ªªÂä°ÂèëÂ±ï„ÄÇËßÜËßâÈóÆÁ≠îÊúÄËøëÊòæÁùÄÊîπÂñÑ‰∫ÜÂõæÂÉèÂüü‰∏≠ÁöÑ‰ΩéÁ∫ßËßÜËßâËØÑ‰º∞„ÄÇÁÑ∂ËÄåÔºåÂú®ËßÜÈ¢ëÂüü‰∏≠Âá†‰πé‰∏çÂ≠òÂú®Áõ∏ÂÖ≥Â∑•‰ΩúÔºåÁïô‰∏ã‰∫ÜÂæàÂ§ßÁöÑÊîπËøõÁ©∫Èó¥„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏ÄÂ∑ÆË∑ùÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü VQA2 Êåá‰ª§Êï∞ÊçÆÈõÜÔºåËøôÊòØÁ¨¨‰∏Ä‰∏™ÂÆåÂÖ®‰∏ìÊ≥®‰∫éËßÜÈ¢ëË¥®ÈáèËØÑ‰º∞ÁöÑËßÜËßâÈóÆÁ≠îÊåá‰ª§Êï∞ÊçÆÈõÜÔºåÂπ∂Âú®Ê≠§Âü∫Á°Ä‰∏äÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü VQA2 Á≥ªÂàóÊ®°Âûã„ÄÇVQA2 Êåá‰ª§Êï∞ÊçÆÈõÜÂåÖÂê´‰∏â‰∏™Èò∂ÊÆµÔºåÊ∂µÁõñÂêÑÁßçËßÜÈ¢ëÁ±ªÂûãÔºåÂåÖÂê´ 157,735 ‰∏™Êåá‰ª§ÈóÆÁ≠îÂØπÔºåÂåÖÊã¨‰∫∫Â∑•Ê≥®ÈáäÊï∞ÊçÆÂíåÂêàÊàêÊï∞ÊçÆ„ÄÇÊàë‰ª¨ÂØπËßÜÈ¢ëË¥®ÈáèËØÑÂàÜÂíåËßÜÈ¢ëË¥®ÈáèÁêÜËß£‰ªªÂä°ËøõË°å‰∫ÜÂπøÊ≥õÁöÑÂÆûÈ™å„ÄÇÁªìÊûúË°®ÊòéÔºåVQA2 Á≥ªÂàóÊ®°ÂûãÂú®Ë¥®ÈáèËØÑÂàÜ‰ªªÂä°‰∏≠ÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõ (SOTA) ÁöÑÊÄßËÉΩÔºåÂπ∂‰∏îÂÆÉ‰ª¨Âú®ËßÜËßâË¥®ÈáèÈóÆÁ≠î‰∏≠ÁöÑÊÄßËÉΩË∂ÖËøá‰∫ÜËëóÂêçÁöÑ GPT-4o„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÁöÑÊúÄÁªàÊ®°Âûã VQA2-Assistant Âú®ËØÑÂàÜÂíåÈóÆÁ≠î‰ªªÂä°‰∏≠ÈÉΩË°®Áé∞ËâØÂ•ΩÔºåÈ™åËØÅ‰∫ÜÂÆÉÁöÑÂ§öÂäüËÉΩÊÄß„ÄÇ

##### **Navigating the landscape of multimodal AI in medicine: a scoping review on technical challenges and clinical applications**
2411.03782v1 by Daan Schouten, Giulia Nicoletti, Bas Dille, Catherine Chia, Pierpaolo Vendittelli, Megan Schuurmans, Geert Litjens, Nadieh Khalili

Recent technological advances in healthcare have led to unprecedented growth
in patient data quantity and diversity. While artificial intelligence (AI)
models have shown promising results in analyzing individual data modalities,
there is increasing recognition that models integrating multiple complementary
data sources, so-called multimodal AI, could enhance clinical decision-making.
This scoping review examines the landscape of deep learning-based multimodal AI
applications across the medical domain, analyzing 432 papers published between
2018 and 2024. We provide an extensive overview of multimodal AI development
across different medical disciplines, examining various architectural
approaches, fusion strategies, and common application areas. Our analysis
reveals that multimodal AI models consistently outperform their unimodal
counterparts, with an average improvement of 6.2 percentage points in AUC.
However, several challenges persist, including cross-departmental coordination,
heterogeneous data characteristics, and incomplete datasets. We critically
assess the technical and practical challenges in developing multimodal AI
systems and discuss potential strategies for their clinical implementation,
including a brief overview of commercially available multimodal AI models for
clinical decision-making. Additionally, we identify key factors driving
multimodal AI development and propose recommendations to accelerate the field's
maturation. This review provides researchers and clinicians with a thorough
understanding of the current state, challenges, and future directions of
multimodal AI in medicine.

ÊëòË¶ÅÔºöÈÜ´ÁôÇ‰øùÂÅ•È†òÂüüÁöÑËøëÊúüÁßëÊäÄÈÄ≤Â±ïÂ∞éËá¥ÁóÖÊÇ£Ë≥áÊñôÊï∏ÈáèÂíåÂ§öÊ®£ÊÄßÂâçÊâÄÊú™ÊúâÁöÑÊàêÈï∑„ÄÇÂÑòÁÆ°‰∫∫Â∑•Êô∫ÊÖß (AI) Ê®°ÂûãÂú®ÂàÜÊûêÂÄãÂà•Ë≥áÊñôÊ®°Âºè‰∏≠Â±ïÁèæÂá∫ÊúâÂâçÈÄîÁöÑÊàêÊûúÔºå‰ΩÜÊï¥ÂêàÂ§öÂÄã‰∫íË£úË≥áÊñô‰æÜÊ∫êÁöÑÊ®°ÂûãÔºåÂç≥ÊâÄË¨ÇÁöÑÂ§öÊ®°Âºè AIÔºåÂèØ‰ª•ÊèêÂçáËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆöÔºåÈÄôÈ†ÖË™çÁü•Ê≠£ËàáÊó•‰ø±Â¢û„ÄÇÈÄôÁØáÁØÑÂúçÊé¢Ë®éÂõûÈ°ßÁ†îÁ©∂Êé¢Ë®é‰∫ÜÊ∂µËìãÈÜ´ÁôÇÈ†òÂüüÁöÑÊ∑±Â∫¶Â≠∏ÁøíÂü∫Á§éÂ§öÊ®°Âºè AI ÊáâÁî®ÁèæÊ≥ÅÔºåÂàÜÊûê 2018 Âπ¥Ëá≥ 2024 Âπ¥ÈñìÁôºË°®ÁöÑ 432 ÁØáË´ñÊñá„ÄÇÊàëÂÄëÊèê‰æõ‰∫ÜÂ§öÊ®°Âºè AI ÁôºÂ±ïÁöÑÂª£Ê≥õÊ¶ÇËßÄÔºåÊ∂µËìã‰∏çÂêåÁöÑÈÜ´ÁôÇÈ†òÂüüÔºåÊé¢Ë®éÂêÑÁ®ÆÊû∂ÊßãÊñπÊ≥ï„ÄÅËûçÂêàÁ≠ñÁï•ÂíåÂ∏∏Ë¶ãÊáâÁî®È†òÂüü„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåÂ§öÊ®°Âºè AI Ê®°ÂûãÂßãÁµÇÂÑ™ÊñºÂÖ∂ÂñÆ‰∏ÄÊ®°ÂºèÁöÑÂ∞çÊáâÊ®°ÂûãÔºåAUC Âπ≥ÂùáÊîπÂñÑ 6.2 ÂÄãÁôæÂàÜÈªû„ÄÇÁÑ∂ËÄåÔºå‰ªçÊúâË®±Â§öÊåëÊà∞ÊåÅÁ∫åÂ≠òÂú®ÔºåÂåÖÊã¨Ë∑®ÈÉ®ÈñÄÂçîË™ø„ÄÅÁï∞Ë≥™Ë≥áÊñôÁâπÊÄßÂíå‰∏çÂÆåÊï¥Ë≥áÊñôÈõÜ„ÄÇÊàëÂÄëÊâπÂà§ÊÄßÂú∞Ë©ï‰º∞ÈñãÁôºÂ§öÊ®°Âºè AI Á≥ªÁµ±Âú®ÊäÄË°ìÂíåÂØ¶Âãô‰∏äÁöÑÊåëÊà∞Ôºå‰∏¶Ë®éË´ñÂÖ∂Ëá®Â∫äÂØ¶‰ΩúÁöÑÊΩõÂú®Á≠ñÁï•ÔºåÂåÖÊã¨Â∞çÂ∏ÇÂîÆÂ§öÊ®°Âºè AI Ê®°ÂûãÁöÑÁ∞°Ë¶ÅÊ¶ÇËø∞ÔºåÁî®ÊñºËá®Â∫äÊ±∫Á≠ñÂà∂ÂÆö„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊâæÂá∫Êé®ÂãïÂ§öÊ®°Âºè AI ÁôºÂ±ïÁöÑ‰∏ªË¶ÅÂõ†Á¥†Ôºå‰∏¶ÊèêÂá∫Âª∫Ë≠∞‰ª•Âä†ÈÄüË©≤È†òÂüüÁöÑÊàêÁÜü„ÄÇÊú¨ÂõûÈ°ßÁ†îÁ©∂ËÆìÁ†îÁ©∂‰∫∫Âì°ÂíåËá®Â∫äÈÜ´Â∏´Ê∑±ÂÖ•‰∫ÜËß£Â§öÊ®°Âºè AI Âú®ÈÜ´Â≠∏È†òÂüüÁöÑÁèæÊ≥Å„ÄÅÊåëÊà∞ÂíåÊú™‰æÜÊñπÂêë„ÄÇ

##### **No Culture Left Behind: ArtELingo-28, a Benchmark of WikiArt with Captions in 28 Languages**
2411.03769v1 by Youssef Mohamed, Runjia Li, Ibrahim Said Ahmad, Kilichbek Haydarov, Philip Torr, Kenneth Ward Church, Mohamed Elhoseiny

Research in vision and language has made considerable progress thanks to
benchmarks such as COCO. COCO captions focused on unambiguous facts in English;
ArtEmis introduced subjective emotions and ArtELingo introduced some
multilinguality (Chinese and Arabic). However we believe there should be more
multilinguality. Hence, we present ArtELingo-28, a vision-language benchmark
that spans $\textbf{28}$ languages and encompasses approximately
$\textbf{200,000}$ annotations ($\textbf{140}$ annotations per image).
Traditionally, vision research focused on unambiguous class labels, whereas
ArtELingo-28 emphasizes diversity of opinions over languages and cultures. The
challenge is to build machine learning systems that assign emotional captions
to images. Baseline results will be presented for three novel conditions:
Zero-Shot, Few-Shot and One-vs-All Zero-Shot. We find that cross-lingual
transfer is more successful for culturally-related languages. Data and code are
provided at www.artelingo.org.

ÊëòË¶ÅÔºö<paragraph>Âú® COCO Á≠âÂü∫Ê∫ñÁöÑÂπ´Âä©‰∏ãÔºåË¶ñË¶∫ÂíåË™ûË®ÄÁöÑÁ†îÁ©∂Â∑≤ÂèñÂæóÈ°ØËëóÈÄ≤Â±ï„ÄÇCOCO ÁöÑË™™ÊòéÊñáÂ≠óÂ∞àÊ≥®ÊñºËã±ÊñáÁöÑÊòéÁ¢∫‰∫ãÂØ¶ÔºõArtEmis ÂºïÂÖ•‰∫Ü‰∏ªËßÄÊÉÖÁ∑íÔºåArtELingo ÂâáÂºïÂÖ•‰∫ÜÈÉ®ÂàÜÂ§öË™ûË®ÄÊÄßÔºà‰∏≠ÊñáÂíåÈòøÊãâ‰ºØÊñáÔºâ„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëÁõ∏‰ø°ÊáâË©≤ÊúâÊõ¥Â§öË™ûË®Ä„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü ArtELingo-28Ôºå‰∏ÄÂÄãÊ©´Ë∑® $\textbf{28}$ Á®ÆË™ûË®Ä‰∏îÂåÖÂê´Â§ßÁ¥Ñ $\textbf{200,000}$ ÂÄãË®ªËß£ÔºàÊØèÂÄãÂúñÂÉè $\textbf{140}$ ÂÄãË®ªËß£ÔºâÁöÑË¶ñË¶∫Ë™ûË®ÄÂü∫Ê∫ñ„ÄÇÂÇ≥Áµ±‰∏äÔºåË¶ñË¶∫Á†îÁ©∂Â∞àÊ≥®ÊñºÊòéÁ¢∫ÁöÑÈ°ûÂà•Ê®ôÁ±§ÔºåËÄå ArtELingo-28 ÂâáÂº∑Ë™øË™ûË®ÄÂíåÊñáÂåñ‰πãÈñìÊÑèË¶ãÁöÑÂ§öÊ®£ÊÄß„ÄÇÊåëÊà∞Âú®ÊñºÂª∫Á´ãÂ∞áÊÉÖÁ∑íË™™ÊòéÊñáÂ≠óÂàÜÈÖçÁµ¶ÂúñÂÉèÁöÑÊ©üÂô®Â≠∏ÁøíÁ≥ªÁµ±„ÄÇÂ∞áÈáùÂ∞ç‰∏âÁ®ÆÊñ∞Ê¢ù‰ª∂ÂëàÁèæÂü∫Á∑öÁµêÊûúÔºöÈõ∂Ê¨°Â≠∏Áøí„ÄÅÂ∞èÊ®£Êú¨Â≠∏ÁøíÂíå‰∏ÄÂ∞çÂÖ®Èõ∂Ê¨°Â≠∏Áøí„ÄÇÊàëÂÄëÁôºÁèæÔºåË∑®Ë™ûË®ÄËΩâÁßªÂ∞çÊñºÊñáÂåñÁõ∏ÈóúË™ûË®Ä‰æÜË™™Êõ¥ÊàêÂäü„ÄÇË≥áÊñôÂíåÁ®ãÂºèÁ¢ºÂèØÂú® www.artelingo.org ‰∏≠ÂèñÂæó„ÄÇ</paragraph>

##### **Number Cookbook: Number Understanding of Language Models and How to Improve It**
2411.03766v1 by Haotong Yang, Yi Hu, Shijia Kang, Zhouchen Lin, Muhan Zhang

Large language models (LLMs) can solve an increasing number of complex
reasoning tasks while making surprising mistakes in basic numerical
understanding and processing (such as 9.11 > 9.9). The latter ability is
essential for tackling complex arithmetic and mathematical problems and serves
as a foundation for most reasoning tasks, but previous work paid little
attention to it or only discussed several restricted tasks (like integer
addition). In this paper, we comprehensively investigate the numerical
understanding and processing ability (NUPA) of LLMs. Firstly, we introduce a
benchmark covering four common numerical representations and 17 distinct
numerical tasks in four major categories, resulting in 41 meaningful
combinations in total. These tasks are derived from primary and secondary
education curricula, encompassing nearly all everyday numerical understanding
and processing scenarios, and the rules of these tasks are very simple and
clear. Through the benchmark, we find that current LLMs fail frequently in many
of the tasks. To study the problem, we train small models with existing and
potential techniques for enhancing NUPA (such as special tokenizers, PEs, and
number formats), comprehensively evaluating their effectiveness using our
testbed. We also finetune practical-scale LLMs on our proposed NUPA tasks and
find that 1) naive finetuning can improve NUPA a lot on many but not all tasks,
and 2) surprisingly, techniques designed to enhance NUPA prove ineffective for
finetuning pretrained models. We further explore the impact of chain-of-thought
techniques on NUPA. Our work takes a preliminary step towards understanding and
improving NUPA of LLMs. Our benchmark and code are released at
https://github.com/GraphPKU/number_cookbook.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂèØ‰ª•Ëß£Ê±∫Ë∂ä‰æÜË∂äÂ§öÁöÑË§áÈõúÊé®ÁêÜ‰ªªÂãôÔºåÂêåÊôÇÂú®Âü∫Êú¨ÁöÑÊï∏Â≠óÁêÜËß£ÂíåËôïÁêÜ‰∏äÁäØ‰∏ãÈ©ö‰∫∫ÁöÑÈåØË™§Ôºà‰æãÂ¶Ç 9.11 > 9.9Ôºâ„ÄÇÂæåËÄÖËÉΩÂäõÂ∞çÊñºËß£Ê±∫Ë§áÈõúÁöÑÁÆóË°ìÂíåÊï∏Â≠∏ÂïèÈ°åËá≥ÈóúÈáçË¶ÅÔºå‰∏¶‰∏î‰ΩúÁÇ∫Â§ßÂ§öÊï∏Êé®ÁêÜ‰ªªÂãôÁöÑÂü∫Á§éÔºå‰ΩÜÂÖàÂâçÁöÑÁ†îÁ©∂ÂæàÂ∞ëÈóúÊ≥®ÂÆÉÊàñÂè™Ë®éË´ñ‰∫ÜÂπæÂÄãÂèóÈôê‰ªªÂãôÔºà‰æãÂ¶ÇÊï¥Êï∏Âä†Ê≥ïÔºâ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂÖ®Èù¢Ë™øÊü•‰∫Ü LLM ÁöÑÊï∏Â≠óÁêÜËß£ÂíåËôïÁêÜËÉΩÂäõ (NUPA)„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂü∫Ê∫ñÔºåÊ∂µËìãÂõõÁ®ÆÂ∏∏Ë¶ãÁöÑÊï∏Â≠óË°®Á§∫ÂíåÂõõÂÄã‰∏ªË¶ÅÈ°ûÂà•‰∏≠ÁöÑ 17 ÂÄã‰∏çÂêåÁöÑÊï∏Â≠ó‰ªªÂãôÔºåÁ∏ΩÂÖ±Áî¢Áîü 41 ÂÄãÊúâÊÑèÁæ©ÁöÑÁµÑÂêà„ÄÇÈÄô‰∫õ‰ªªÂãôÊ∫êËá™‰∏≠Â∞èÂ≠∏ÊïôËÇ≤Ë™≤Á®ãÔºåÊ∂µËìã‰∫ÜÂπæ‰πéÊâÄÊúâÊó•Â∏∏Êï∏Â≠óÁêÜËß£ÂíåËôïÁêÜÂ†¥ÊôØÔºå‰∏¶‰∏îÈÄô‰∫õ‰ªªÂãôÁöÑË¶èÂâáÈùûÂ∏∏Á∞°ÂñÆÊòéÁû≠„ÄÇÈÄöÈÅéÂü∫Ê∫ñÔºåÊàëÂÄëÁôºÁèæÁï∂ÂâçÁöÑ LLM Âú®Ë®±Â§ö‰ªªÂãô‰∏≠Á∂ìÂ∏∏Â§±Êïó„ÄÇÁÇ∫‰∫ÜÁ†îÁ©∂ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄë‰ΩøÁî®ÁèæÊúâÂíåÊΩõÂú®ÁöÑÊäÄË°ìË®ìÁ∑¥Â∞èÊ®°Âûã‰æÜÂ¢ûÂº∑ NUPAÔºà‰æãÂ¶ÇÁâπÊÆäÂàÜË©ûÂô®„ÄÅPE ÂíåÊï∏Â≠óÊ†ºÂºèÔºâÔºå‰∏¶‰ΩøÁî®ÊàëÂÄëÁöÑÊ∏¨Ë©¶Âπ≥Âè∞ÂÖ®Èù¢Ë©ï‰º∞ÂÆÉÂÄëÁöÑÊúâÊïàÊÄß„ÄÇÊàëÂÄëÈÇÑÂú®ÊàëÂÄëÊèêÂá∫ÁöÑ NUPA ‰ªªÂãô‰∏äÂæÆË™ø‰∫ÜÂØ¶Áî®Ë¶èÊ®°ÁöÑ LLMÔºå‰∏¶ÁôºÁèæ 1) Ê®∏Á¥†ÁöÑÂæÆË™øÂèØ‰ª•Âú®Ë®±Â§ö‰ªªÂãôÔºà‰ΩÜ‰∏¶ÈùûÂÖ®ÈÉ®Ôºâ‰∏äÂ§ßÂπÖÊîπÂñÑ NUPAÔºå‰ª•Âèä 2) ‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºåÊó®Âú®Â¢ûÂº∑ NUPA ÁöÑÊäÄË°ìË¢´Ë≠âÊòéÂ∞çÂæÆË™øÈ†êË®ìÁ∑¥ÁöÑÊ®°ÂûãÁÑ°Êïà„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Êé¢Ë®é‰∫ÜÊÄùÊÉ≥ÈèàÊäÄË°ìÂ∞ç NUPA ÁöÑÂΩ±Èüø„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁÇ∫ÁêÜËß£ÂíåÊîπÈÄ≤ LLM ÁöÑ NUPA ÈÇÅÂá∫‰∫ÜÂàùÊ≠•‰∏ÄÊ≠•„ÄÇÊàëÂÄëÁöÑÂü∫Ê∫ñÂíå‰ª£Á¢ºÁôºÂ∏ÉÂú® https://github.com/GraphPKU/number_cookbook„ÄÇ

##### **Sub-DM:Subspace Diffusion Model with Orthogonal Decomposition for MRI Reconstruction**
2411.03758v1 by Yu Guan, Qinrong Cai, Wei Li, Qiuyun Fan, Dong Liang, Qiegen Liu

Diffusion model-based approaches recently achieved re-markable success in MRI
reconstruction, but integration into clinical routine remains challenging due
to its time-consuming convergence. This phenomenon is partic-ularly notable
when directly apply conventional diffusion process to k-space data without
considering the inherent properties of k-space sampling, limiting k-space
learning efficiency and image reconstruction quality. To tackle these
challenges, we introduce subspace diffusion model with orthogonal
decomposition, a method (referred to as Sub-DM) that restrict the diffusion
process via projections onto subspace as the k-space data distribution evolves
toward noise. Particularly, the subspace diffusion model circumvents the
inference challenges posed by the com-plex and high-dimensional characteristics
of k-space data, so the highly compact subspace ensures that diffusion process
requires only a few simple iterations to produce accurate prior information.
Furthermore, the orthogonal decomposition strategy based on wavelet transform
hin-ders the information loss during the migration of the vanilla diffusion
process to the subspace. Considering the strate-gy is approximately reversible,
such that the entire pro-cess can be reversed. As a result, it allows the
diffusion processes in different spaces to refine models through a mutual
feedback mechanism, enabling the learning of ac-curate prior even when dealing
with complex k-space data. Comprehensive experiments on different datasets
clearly demonstrate that the superiority of Sub-DM against state of-the-art
methods in terms of reconstruction speed and quality.

ÊëòË¶ÅÔºöÂü∫ÊñºÊì¥Êï£Ê®°ÂûãÁöÑÊñπÊ≥ïÊúÄËøëÂú® MRI ÈáçÂª∫‰∏≠ÂèñÂæó‰∫ÜÈ°ØËëóÁöÑÊàêÂäüÔºå‰ΩÜÁî±ÊñºÂÖ∂ËÄóÊôÇÁöÑÊî∂ÊñÇÊÄßÔºåÊï¥ÂêàÂà∞Ëá®Â∫äÂ∏∏Ë¶è‰∏≠‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÁï∂Áõ¥Êé•Â∞áÂÇ≥Áµ±Êì¥Êï£ÈÅéÁ®ãÊáâÁî®Âà∞ k-space Ë≥áÊñôÔºåËÄåÊ≤íÊúâËÄÉÊÖÆ k-space ÂèñÊ®£ÁöÑÂõ∫ÊúâÁâπÊÄßÊôÇÔºåÈÄôÁ®ÆÁèæË±°Â∞§ÂÖ∂ÊòéÈ°ØÔºåÈôêÂà∂‰∫Ü k-space Â≠∏ÁøíÊïàÁéáÂíåÂΩ±ÂÉèÈáçÂª∫ÂìÅË≥™„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂÖ∑ÊúâÊ≠£‰∫§ÂàÜËß£ÁöÑÂ≠êÁ©∫ÈñìÊì¥Êï£Ê®°ÂûãÔºå‰∏ÄÁ®ÆÊñπÊ≥ïÔºàÁ®±ÁÇ∫ Sub-DMÔºâÔºåÂÆÉÈÄöÈÅéÊäïÂΩ±Âà∞Â≠êÁ©∫Èñì‰æÜÈôêÂà∂Êì¥Êï£ÈÅéÁ®ãÔºåÂõ†ÁÇ∫ k-space Ë≥áÊñôÂàÜ‰ΩàÊúÉÊºîËÆäÊàêÈõúË®ä„ÄÇÁâπÂà•ÊòØÔºåÂ≠êÁ©∫ÈñìÊì¥Êï£Ê®°ÂûãËø¥ÈÅø‰∫Ü k-space Ë≥áÊñôÁöÑË§áÈõúÂíåÈ´òÁ∂≠ÁâπÂæµÊâÄÂ∏∂‰æÜÁöÑÊé®Ë´ñÊåëÊà∞ÔºåÂõ†Ê≠§È´òÂ∫¶Á∑äÊπäÁöÑÂ≠êÁ©∫ÈñìÁ¢∫‰øùÊì¥Êï£ÈÅéÁ®ãÂè™ÈúÄË¶ÅÂπæÂÄãÁ∞°ÂñÆÁöÑËø≠‰ª£Âç≥ÂèØÁî¢ÁîüÊ∫ñÁ¢∫ÁöÑÂÖàÈ©óË≥áË®ä„ÄÇÊ≠§Â§ñÔºåÂü∫ÊñºÂ∞èÊ≥¢ËΩâÊèõÁöÑÊ≠£‰∫§ÂàÜËß£Á≠ñÁï•ÈòªÁ§ô‰∫ÜÈ¶ôËçâÊì¥Êï£ÈÅéÁ®ãÈÅ∑ÁßªÂà∞Â≠êÁ©∫ÈñìÊúüÈñìÁöÑË≥áË®äÈÅ∫Â§±„ÄÇËÄÉÊÖÆÂà∞Ë©≤Á≠ñÁï•Ëøë‰ººÂèØÈÄÜÔºåÂõ†Ê≠§Êï¥ÂÄãÈÅéÁ®ãÂèØ‰ª•ÈÄÜËΩâ„ÄÇÂõ†Ê≠§ÔºåÂÆÉÂÖÅË®±‰∏çÂêåÁ©∫Èñì‰∏≠ÁöÑÊì¥Êï£ÈÅéÁ®ãÈÄöÈÅéÁõ∏‰∫íÂõûÈ•ãÊ©üÂà∂‰æÜÂÑ™ÂåñÊ®°ÂûãÔºåÂç≥‰ΩøÂú®ËôïÁêÜË§áÈõúÁöÑ k-space Ë≥áÊñôÊôÇ‰πüËÉΩÂ≠∏ÁøíÊ∫ñÁ¢∫ÁöÑÂÖàÈ©ó„ÄÇÂú®‰∏çÂêåË≥áÊñôÈõÜ‰∏äÁöÑÂÖ®Èù¢ÂØ¶È©óÊ∏ÖÊ•öÂú∞Ë≠âÊòé‰∫Ü Sub-DM Âú®ÈáçÂª∫ÈÄüÂ∫¶ÂíåÂìÅË≥™ÊñπÈù¢ÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ï„ÄÇ

##### **Optimal Defenses Against Gradient Reconstruction Attacks**
2411.03746v1 by Yuxiao Chen, Gamze G√ºrsoy, Qi Lei

Federated Learning (FL) is designed to prevent data leakage through
collaborative model training without centralized data storage. However, it
remains vulnerable to gradient reconstruction attacks that recover original
training data from shared gradients. To optimize the trade-off between data
leakage and utility loss, we first derive a theoretical lower bound of
reconstruction error (among all attackers) for the two standard methods: adding
noise, and gradient pruning. We then customize these two defenses to be
parameter- and model-specific and achieve the optimal trade-off between our
obtained reconstruction lower bound and model utility. Experimental results
validate that our methods outperform Gradient Noise and Gradient Pruning by
protecting the training data better while also achieving better utility.

ÊëòË¶ÅÔºöËÅØÈÇ¶Â≠∏Áøí (FL) Êó®Âú®ÈÄèÈÅéÂçî‰ΩúÊ®°ÂûãË®ìÁ∑¥‰æÜÈò≤Ê≠¢Ë≥áÊñôÂ§ñÊ¥©ÔºåËÄåÁÑ°ÈúÄÈõÜ‰∏≠ÂºèË≥áÊñôÂÑ≤Â≠ò„ÄÇ‰ΩÜÊòØÔºåÂÆÉ‰ªçÁÑ∂ÂÆπÊòìÂèóÂà∞Ê¢ØÂ∫¶ÈáçÂª∫ÊîªÊìäÔºåË©≤ÊîªÊìäÊúÉÂæûÂÖ±‰∫´Ê¢ØÂ∫¶‰∏≠ÊÅ¢Âæ©ÂéüÂßãË®ìÁ∑¥Ë≥áÊñô„ÄÇÁÇ∫‰∫ÜÊúÄ‰Ω≥ÂåñË≥áÊñôÂ§ñÊ¥©ÂíåÊïàÁî®ÊêçÂ§±‰πãÈñìÁöÑÊäòË°∑ÔºåÊàëÂÄëÈ¶ñÂÖàÈáùÂ∞çÈÄôÂÖ©Á®ÆÊ®ôÊ∫ñÊñπÊ≥ïÊé®Â∞éÂá∫ÈáçÂª∫Ë™§Â∑ÆÁöÑÁêÜË´ñ‰∏ãÈôêÔºàÂú®ÊâÄÊúâÊîªÊìäËÄÖ‰∏≠ÔºâÔºöÂä†ÂÖ•ÈõúË®äÂíåÊ¢ØÂ∫¶‰øÆÂâ™„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëËá™Ë®ÇÈÄôÂÖ©Á®ÆÈò≤Á¶¶Êé™ÊñΩÔºå‰ΩøÂÖ∂ÁâπÂÆöÊñºÂèÉÊï∏ÂíåÊ®°ÂûãÔºå‰∏¶Âú®ÊàëÂÄëÁç≤ÂæóÁöÑÈáçÂª∫‰∏ãÈôêÂíåÊ®°ÂûãÊïàÁî®‰πãÈñìÂèñÂæóÊúÄ‰Ω≥ÊäòË°∑„ÄÇÂØ¶È©óÁµêÊûúÈ©óË≠âÊàëÂÄëÁöÑÊ®°ÂûãÈÄèÈÅéÊõ¥‰Ω≥Âú∞‰øùË≠∑Ë®ìÁ∑¥Ë≥áÊñôÔºåÂêåÊôÇ‰πüËÉΩÈÅîÂà∞Êõ¥Â•ΩÁöÑÊïàÁî®ÔºåÂæûËÄåÂÑ™ÊñºÊ¢ØÂ∫¶ÈõúË®äÂíåÊ¢ØÂ∫¶‰øÆÂâ™„ÄÇ

##### **Automating Exploratory Proteomics Research via Language Models**
2411.03743v1 by Ning Ding, Shang Qu, Linhai Xie, Yifei Li, Zaoqu Liu, Kaiyan Zhang, Yibai Xiong, Yuxin Zuo, Zhangren Chen, Ermo Hua, Xingtai Lv, Youbang Sun, Yang Li, Dong Li, Fuchu He, Bowen Zhou

With the development of artificial intelligence, its contribution to science
is evolving from simulating a complex problem to automating entire research
processes and producing novel discoveries. Achieving this advancement requires
both specialized general models grounded in real-world scientific data and
iterative, exploratory frameworks that mirror human scientific methodologies.
In this paper, we present PROTEUS, a fully automated system for scientific
discovery from raw proteomics data. PROTEUS uses large language models (LLMs)
to perform hierarchical planning, execute specialized bioinformatics tools, and
iteratively refine analysis workflows to generate high-quality scientific
hypotheses. The system takes proteomics datasets as input and produces a
comprehensive set of research objectives, analysis results, and novel
biological hypotheses without human intervention. We evaluated PROTEUS on 12
proteomics datasets collected from various biological samples (e.g. immune
cells, tumors) and different sample types (single-cell and bulk), generating
191 scientific hypotheses. These were assessed using both automatic LLM-based
scoring on 5 metrics and detailed reviews from human experts. Results
demonstrate that PROTEUS consistently produces reliable, logically coherent
results that align well with existing literature while also proposing novel,
evaluable hypotheses. The system's flexible architecture facilitates seamless
integration of diverse analysis tools and adaptation to different proteomics
data types. By automating complex proteomics analysis workflows and hypothesis
generation, PROTEUS has the potential to considerably accelerate the pace of
scientific discovery in proteomics research, enabling researchers to
efficiently explore large-scale datasets and uncover biological insights.

ÊëòË¶ÅÔºö<paragraph>Èö®Ëëó‰∫∫Â∑•Êô∫ÊÖßÁöÑÁôºÂ±ïÔºåÂÖ∂Â∞çÁßëÂ≠∏ÁöÑË≤¢ÁçªÂæûÊ®°Êì¨Ë§áÈõúÁöÑÂïèÈ°åÊºîËÆäÊàêËá™ÂãïÂåñÊï¥ÂÄãÁ†îÁ©∂ÊµÅÁ®ãÂíåÁî¢ÁîüÊñ∞ÁôºÁèæ„ÄÇÂØ¶ÁèæÈÄôÈ†ÖÈÄ≤Â±ïÈúÄË¶ÅÂª∫Á´ãÂú®ÁúüÂØ¶‰∏ñÁïåÁßëÂ≠∏Êï∏ÊìöÂü∫Á§é‰∏äÁöÑÂ∞àÈñÄÈÄöÁî®Ê®°ÂûãÔºå‰ª•ÂèäÂèçÊò†‰∫∫È°ûÁßëÂ≠∏ÊñπÊ≥ïÁöÑËø≠‰ª£ÂºèÊé¢Á¥¢Ê°ÜÊû∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü PROTEUSÔºåÈÄôÊòØ‰∏ÄÂÄãÂæûÂéüÂßãËõãÁôΩË¥®ÁªÑÂ≠¶Êï∏Êìö‰∏≠ÈÄ≤Ë°åÁßëÂ≠∏ÁôºÁèæÁöÑÂÖ®Ëá™ÂãïÁ≥ªÁµ±„ÄÇPROTEUS ‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜÂü∑Ë°åÈöéÂ±§ÂºèË¶èÂäÉ„ÄÅÂü∑Ë°åÂ∞àÈñÄÁöÑÁîüÁâ©‰ø°ÊÅØÂ≠∏Â∑•ÂÖ∑Ôºå‰∏¶ÂèçË¶ÜÂÑ™ÂåñÂàÜÊûêÂ∑•‰ΩúÊµÅÁ®ã‰ª•Áî¢ÁîüÈ´òÂìÅË≥™ÁöÑÁßëÂ≠∏ÂÅáË®≠„ÄÇË©≤Á≥ªÁµ±‰ª•ËõãÁôΩË¥®ÁªÑÂ≠¶Êï∏ÊìöÈõÜ‰ΩúÁÇ∫Ëº∏ÂÖ•Ôºå‰∏¶Áî¢Áîü‰∏ÄÁµÑÂÖ®Èù¢ÁöÑÁ†îÁ©∂ÁõÆÊ®ô„ÄÅÂàÜÊûêÁµêÊûúÂíåÊñ∞Á©éÁöÑÁîüÁâ©ÂÅáË®≠ÔºåÁÑ°ÈúÄ‰∫∫Â∑•Âπ≤È†ê„ÄÇÊàëÂÄëÂú®ÂæûÂêÑÁ®ÆÁîüÁâ©Ê®£Êú¨Ôºà‰æãÂ¶ÇÂÖçÁñ´Á¥∞ËÉû„ÄÅËÖ´Áò§ÔºâÂíå‰∏çÂêåÊ®£Êú¨È°ûÂûãÔºàÂñÆÁ¥∞ËÉûÂíåÊï¥È´îÔºâÊî∂ÈõÜÁöÑ 12 ÂÄãËõãÁôΩË¥®ÁªÑÂ≠¶Êï∏ÊìöÈõÜ‰∏äË©ï‰º∞‰∫Ü PROTEUSÔºåÁî¢Áîü‰∫Ü 191 ÂÄãÁßëÂ≠∏ÂÅáË®≠„ÄÇÈÄô‰∫õÂÅáË®≠‰ΩøÁî®Âü∫Êñº LLM ÁöÑËá™ÂãïË©ïÂàÜÔºà‰ΩøÁî® 5 ÂÄãÊåáÊ®ôÔºâÂíå‰∫∫È°ûÂ∞àÂÆ∂ÁöÑË©≥Á¥∞Ë©ï‰º∞ÈÄ≤Ë°åË©ï‰º∞„ÄÇÁµêÊûúË°®ÊòéÔºåPROTEUS ÊåÅÁ∫åÁî¢ÁîüÂèØÈù†„ÄÅÈÇèËºØ‰∏äÈÄ£Ë≤´ÁöÑÁµêÊûúÔºåÈÄô‰∫õÁµêÊûúËàáÁèæÊúâÊñáÁçªÈùûÂ∏∏ÂêªÂêàÔºåÂêåÊôÇ‰πüÊèêÂá∫‰∫ÜÊñ∞Á©é„ÄÅÂèØË©ï‰º∞ÁöÑÂÅáË®≠„ÄÇË©≤Á≥ªÁµ±ÁöÑÈùàÊ¥ªÊû∂Êßã‰øÉÈÄ≤‰∫Ü‰∏çÂêåÂàÜÊûêÂ∑•ÂÖ∑ÁöÑÁÑ°Á∏´Êï¥ÂêàÔºå‰∏¶ÈÅ©Êáâ‰∫Ü‰∏çÂêåÁöÑËõãÁôΩË¥®ÁªÑÂ≠¶Êï∏ÊìöÈ°ûÂûã„ÄÇÈÄöÈÅéËá™ÂãïÂåñË§áÈõúÁöÑËõãÁôΩË¥®ÁªÑÂ≠¶ÂàÜÊûêÂ∑•‰ΩúÊµÅÁ®ãÂíåÂÅáË®≠ÁîüÊàêÔºåPROTEUS ÊúâÂèØËÉΩÂ§ßÂπÖÂä†Âø´ËõãÁôΩË¥®ÁªÑÂ≠¶Á†îÁ©∂‰∏≠ÁßëÂ≠∏ÁôºÁèæÁöÑÊ≠•‰ºêÔºå‰ΩøÁ†îÁ©∂‰∫∫Âì°ËÉΩÂ§†ÊúâÊïàÂú∞Êé¢Á¥¢Â§ßË¶èÊ®°Êï∏ÊìöÈõÜ‰∏¶ÁôºÁèæÁîüÁâ©Â≠∏Ë¶ãËß£„ÄÇ</paragraph>

##### **Adaptive Consensus Gradients Aggregation for Scaled Distributed Training**
2411.03742v1 by Yoni Choukroun, Shlomi Azoulay, Pavel Kisilev

Distributed machine learning has recently become a critical paradigm for
training large models on vast datasets. We examine the stochastic optimization
problem for deep learning within synchronous parallel computing environments
under communication constraints. While averaging distributed gradients is the
most widely used method for gradient estimation, whether this is the optimal
strategy remains an open question. In this work, we analyze the distributed
gradient aggregation process through the lens of subspace optimization. By
formulating the aggregation problem as an objective-aware subspace optimization
problem, we derive an efficient weighting scheme for gradients, guided by
subspace coefficients. We further introduce subspace momentum to accelerate
convergence while maintaining statistical unbiasedness in the aggregation. Our
method demonstrates improved performance over the ubiquitous gradient averaging
on multiple MLPerf tasks while remaining extremely efficient in both
communicational and computational complexity.

ÊëòË¶ÅÔºöÂàÜÂ∏ÉÂºèÊ©üÂô®Â≠∏ÁøíÊúÄËøëÂ∑≤ÊàêÁÇ∫Âú®ÈæêÂ§ßË≥áÊñôÈõÜ‰∏äË®ìÁ∑¥Â§ßÂûãÊ®°ÂûãÁöÑÈáçË¶ÅÁØÑ‰æã„ÄÇÊàëÂÄëÂú®ÈÄöË®äÁ¥ÑÊùü‰∏ãÔºåÊé¢Ë®éÂêåÊ≠•‰∏¶Ë°åÈÅãÁÆóÁí∞Â¢É‰∏≠Ê∑±Â∫¶Â≠∏ÁøíÁöÑÈö®Ê©üÊúÄ‰Ω≥ÂåñÂïèÈ°å„ÄÇÈõñÁÑ∂Âπ≥ÂùáÂàÜ‰ΩàÂºèÊ¢ØÂ∫¶ÊòØÊ¢ØÂ∫¶‰º∞Ë®àÊúÄÂª£Ê≥õ‰ΩøÁî®ÁöÑÊñπÊ≥ïÔºå‰ΩÜÈÄôÊòØÂê¶ÊòØÊúÄ‰Ω≥Á≠ñÁï•‰ªçÊòØ‰∏ÄÂÄãÈñãÊîæÊÄßÁöÑÂïèÈ°å„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÈÄèÈÅéÂ≠êÁ©∫ÈñìÊúÄ‰Ω≥ÂåñÁöÑËßíÂ∫¶ÂàÜÊûêÂàÜ‰ΩàÂºèÊ¢ØÂ∫¶ËÅöÂêàÈÅéÁ®ã„ÄÇÈÄèÈÅéÂ∞áËÅöÂêàÂïèÈ°åÂà∂ÂÆöÁÇ∫ÁõÆÊ®ôÊÑüÁü•Â≠êÁ©∫ÈñìÊúÄ‰Ω≥ÂåñÂïèÈ°åÔºåÊàëÂÄëÂ∞éÂá∫‰∏ÄÂÄãÊúâÊïàÁöÑÊ¢ØÂ∫¶Âä†Ê¨äÊ©üÂà∂ÔºåÁî±Â≠êÁ©∫Èñì‰øÇÊï∏ÂºïÂ∞é„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÂºïÂÖ•Â≠êÁ©∫ÈñìÂãïÈáè‰æÜÂä†ÈÄüÊî∂ÊñÇÔºåÂêåÊôÇÂú®ËÅöÂêà‰∏≠Á∂≠ÊåÅÁµ±Ë®àÁÑ°ÂÅèÊÄß„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂú®Â§öÂÄã MLPerf ‰ªªÂãô‰∏äÂ±ïÁèæÂá∫ÂÑ™ÊñºÊôÆÈÅçÊ¢ØÂ∫¶Âπ≥ÂùáÁöÑÊïàËÉΩÔºåÂêåÊôÇÂú®ÈÄöË®äÂíåÈÅãÁÆóË§áÈõúÂ∫¶ÊñπÈù¢‰øùÊåÅÊ•µÈ´òÁöÑÊïàÁéá„ÄÇ

##### **Relation Learning and Aggregate-attention for Multi-person Motion Prediction**
2411.03729v1 by Kehua Qu, Rui Ding, Jin Tang

Multi-person motion prediction is an emerging and intricate task with broad
real-world applications. Unlike single person motion prediction, it considers
not just the skeleton structures or human trajectories but also the
interactions between others. Previous methods use various networks to achieve
impressive predictions but often overlook that the joints relations within an
individual (intra-relation) and interactions among groups (inter-relation) are
distinct types of representations. These methods often lack explicit
representation of inter&intra-relations, and inevitably introduce undesired
dependencies. To address this issue, we introduce a new collaborative framework
for multi-person motion prediction that explicitly modeling these relations:a
GCN-based network for intra-relations and a novel reasoning network for
inter-relations.Moreover, we propose a novel plug-and-play aggregation module
called the Interaction Aggregation Module (IAM), which employs an
aggregate-attention mechanism to seamlessly integrate these relations.
Experiments indicate that the module can also be applied to other dual-path
models. Extensive experiments on the 3DPW, 3DPW-RC, CMU-Mocap, MuPoTS-3D, as
well as synthesized datasets Mix1 & Mix2 (9 to 15 persons), demonstrate that
our method achieves state-of-the-art performance.

ÊëòË¶ÅÔºöÂ§ö‰∫∫Âãï‰ΩúÈ†êÊ∏¨ÊòØ‰∏ÄÈ†ÖÊñ∞Ëàà‰∏îË§áÈõúÁöÑ‰ªªÂãôÔºåÂú®ÁèæÂØ¶‰∏ñÁïå‰∏≠ÊúâÂª£Ê≥õÁöÑÊáâÁî®„ÄÇÂÆÉ‰∏çÂêåÊñºÂñÆ‰∫∫Âãï‰ΩúÈ†êÊ∏¨ÔºåÂÆÉ‰∏çÂÉÖËÄÉÊÖÆÈ™®Êû∂ÁµêÊßãÊàñ‰∫∫È´îËªåË∑°ÔºåÈÇÑËÄÉÊÖÆ‰∫∫Ëàá‰∫∫‰πãÈñìÁöÑ‰∫íÂãï„ÄÇÂÖàÂâçÁöÑÂêÑÁ®ÆÊñπÊ≥ï‰ΩøÁî®ÂêÑÁ®ÆÁ∂≤Ë∑Ø‰æÜÂØ¶Áèæ‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÈ†êÊ∏¨Ôºå‰ΩÜÂ∏∏Â∏∏ÂøΩË¶ñÂÄã‰∫∫ÂÖßÈÉ®ÁöÑÈóúÁØÄÈóú‰øÇÔºàÂÖßÈÉ®Èóú‰øÇÔºâÂíåÁæ§ÁµÑ‰πãÈñìÁöÑ‰∫íÂãïÔºàÁõ∏‰∫íÈóú‰øÇÔºâÊòØ‰∏çÂêåÈ°ûÂûãÁöÑË°®Á§∫„ÄÇÈÄô‰∫õÊñπÊ≥ïÈÄöÂ∏∏Áº∫‰πèÂ∞çÂÖßÈÉ®ÂíåÂ§ñÈÉ®Èóú‰øÇÁöÑÊòéÁ¢∫Ë°®Á§∫Ôºå‰∏¶‰∏çÂèØÈÅøÂÖçÂú∞ÂºïÂÖ•‰∫Ü‰∏çÈúÄË¶ÅÁöÑ‰æùË≥¥Èóú‰øÇ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂçî‰ΩúÊ°ÜÊû∂ÔºåÁî®ÊñºÂ§ö‰∫∫Âì°Âãï‰ΩúÈ†êÊ∏¨ÔºåË©≤Ê°ÜÊû∂ÊòéÁ¢∫Âú∞Â∞çÈÄô‰∫õÈóú‰øÇÂª∫Ê®°Ôºö‰∏ÄÂÄãÂü∫Êñº GCN ÁöÑÁ∂≤Ë∑ØÁî®ÊñºÂÖßÈÉ®Èóú‰øÇÔºå‰∏ÄÂÄãÊñ∞ÁöÑÊé®ÁêÜÁ∂≤Ë∑ØÁî®ÊñºÁõ∏‰∫íÈóú‰øÇ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÂç≥ÊèíÂç≥Áî®ËÅöÂêàÊ®°ÁµÑÔºåÁ®±ÁÇ∫‰∫íÂãïËÅöÂêàÊ®°ÁµÑ (IAM)ÔºåÂÆÉÊé°Áî®ËÅöÂêàÊ≥®ÊÑèÂäõÊ©üÂà∂‰æÜÁÑ°Á∏´Êï¥ÂêàÈÄô‰∫õÈóú‰øÇ„ÄÇÂØ¶È©óË°®ÊòéÔºåË©≤Ê®°ÁµÑ‰πüÂèØ‰ª•ÊáâÁî®ÊñºÂÖ∂‰ªñÈõôË∑ØÂæëÊ®°Âûã„ÄÇÂú® 3DPW„ÄÅ3DPW-RC„ÄÅCMU-Mocap„ÄÅMuPoTS-3D ‰ª•ÂèäÂêàÊàêË≥áÊñôÈõÜ Mix1 Âíå Mix2Ôºà9 Âà∞ 15 ‰∫∫Ôºâ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑÊ®°ÂûãÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇ

##### **PropNEAT -- Efficient GPU-Compatible Backpropagation over NeuroEvolutionary Augmenting Topology Networks**
2411.03726v1 by Michael Merry, Patricia Riddle, Jim Warren

We introduce PropNEAT, a fast backpropagation implementation of NEAT that
uses a bidirectional mapping of the genome graph to a layer-based architecture
that preserves the NEAT genomes whilst enabling efficient GPU backpropagation.
We test PropNEAT on 58 binary classification datasets from the Penn Machine
Learning Benchmarks database, comparing the performance against logistic
regression, dense neural networks and random forests, as well as a densely
retrained variant of the final PropNEAT model. PropNEAT had the second best
overall performance, behind Random Forest, though the difference between the
models was not statistically significant apart from between Random Forest in
comparison with logistic regression and the PropNEAT retrain models. PropNEAT
was substantially faster than a naive backpropagation method, and both were
substantially faster and had better performance than the original NEAT
implementation. We demonstrate that the per-epoch training time for PropNEAT
scales linearly with network depth, and is efficient on GPU implementations for
backpropagation. This implementation could be extended to support reinforcement
learning or convolutional networks, and is able to find sparser and smaller
networks with potential for applications in low-power contexts.

ÊëòË¶ÅÔºöÊàëÂÄë‰ªãÁ¥π‰∫Ü PropNEATÔºå‰∏ÄÁ®Æ NEAT ÁöÑÂø´ÈÄüÂèçÂêëÂÇ≥Êí≠ÂØ¶‰ΩúÔºåÂÆÉ‰ΩøÁî®Âü∫Âõ†ÁµÑÂúñÂΩ¢Âà∞Âü∫ÊñºÂ±§ÁöÑÊû∂ÊßãÁöÑÈõôÂêëÊò†Â∞ÑÔºåÂú®‰øùÁïô NEAT Âü∫Âõ†ÁµÑÁöÑÂêåÊôÇÔºåËÉΩÂ§†ÈÄ≤Ë°åÈ´òÊïàÁöÑ GPU ÂèçÂêëÂÇ≥Êí≠„ÄÇÊàëÂÄëÂú® Penn Machine Learning Benchmarks Ë≥áÊñôÂ∫´‰∏≠ÁöÑ 58 ÂÄã‰∫åÂÖÉÂàÜÈ°ûË≥áÊñôÈõÜ‰∏äÊ∏¨Ë©¶‰∫Ü PropNEATÔºå‰∏¶Â∞áÂÖ∂ÊïàËÉΩËàáÈÇèËºØËø¥Ê≠∏„ÄÅÁ®†ÂØÜÁ•ûÁ∂ìÁ∂≤Ë∑ØÂíåÈö®Ê©üÊ£ÆÊûóÔºå‰ª•ÂèäÊúÄÁµÇ PropNEAT Ê®°ÂûãÁöÑÂØÜÈõÜÈáçÊñ∞Ë®ìÁ∑¥ËÆäÈ´îÈÄ≤Ë°åÊØîËºÉ„ÄÇPropNEAT ÊìÅÊúâÁ¨¨‰∫åÂ•ΩÁöÑÊï¥È´îÊïàËÉΩÔºåÂÉÖÊ¨°ÊñºÈö®Ê©üÊ£ÆÊûóÔºåÂÑòÁÆ°Èô§‰∫ÜÈö®Ê©üÊ£ÆÊûóËàáÈÇèËºØËø¥Ê≠∏Âíå PropNEAT ÈáçÊñ∞Ë®ìÁ∑¥Ê®°ÂûãÁöÑÊØîËºÉ‰πãÂ§ñÔºåÊ®°Âûã‰πãÈñìÁöÑÂ∑ÆÁï∞‰∏¶ÁÑ°Áµ±Ë®àÊÑèÁæ©„ÄÇPropNEAT ÊØî‰∏ÄÂÄãÂ§©ÁúüÁöÑÂèçÂêëÂÇ≥Êí≠ÊñπÊ≥ïÂø´ÂæóÂ§öÔºåËÄå‰∏îÂÖ©ËÄÖÈÉΩÊØîÂéüÂßã NEAT ÂØ¶‰ΩúÂø´ÂæóÂ§öÔºåËÄå‰∏îÊïàËÉΩÊõ¥Â•Ω„ÄÇÊàëÂÄëË≠âÊòé‰∫Ü PropNEAT ÁöÑÊØèÂÄãÊôÇÊúüË®ìÁ∑¥ÊôÇÈñìËàáÁ∂≤Ë∑ØÊ∑±Â∫¶ÊàêÁ∑öÊÄßÊØî‰æãÔºå‰∏¶‰∏îÂú®ÂèçÂêëÂÇ≥Êí≠ÁöÑ GPU ÂØ¶‰Ωú‰∏≠ÂæàÊúâÊïàÁéá„ÄÇÊ≠§ÂØ¶‰ΩúÂèØ‰ª•Êì¥ÂÖÖÊîØÊè¥Âº∑ÂåñÂ≠∏ÁøíÊàñÂç∑Á©çÁ∂≤Ë∑ØÔºå‰∏¶‰∏îËÉΩÂ§†ÊâæÂà∞Êõ¥Á®ÄÁñè„ÄÅÊõ¥Â∞èÁöÑÁ∂≤Ë∑ØÔºåÂÖ∑ÊúâÂú®‰ΩéÂäüËÄóÁí∞Â¢É‰∏≠ÊáâÁî®ÁöÑÊΩõÂäõ„ÄÇ

##### **Fine-Tuning Vision-Language Model for Automated Engineering Drawing Information Extraction**
2411.03707v1 by Muhammad Tayyab Khan, Lequn Chen, Ye Han Ng, Wenhe Feng, Nicholas Yew Jin Tan, Seung Ki Moon

Geometric Dimensioning and Tolerancing (GD&T) plays a critical role in
manufacturing by defining acceptable variations in part features to ensure
component quality and functionality. However, extracting GD&T information from
2D engineering drawings is a time-consuming and labor-intensive task, often
relying on manual efforts or semi-automated tools. To address these challenges,
this study proposes an automated and computationally efficient GD&T extraction
method by fine-tuning Florence-2, an open-source vision-language model (VLM).
The model is trained on a dataset of 400 drawings with ground truth annotations
provided by domain experts. For comparison, two state-of-the-art closed-source
VLMs, GPT-4o and Claude-3.5-Sonnet, are evaluated on the same dataset. All
models are assessed using precision, recall, F1-score, and hallucination
metrics. Due to the computational cost and impracticality of fine-tuning large
closed-source VLMs for domain-specific tasks, GPT-4o and Claude-3.5-Sonnet are
evaluated in a zero-shot setting. In contrast, Florence-2, a smaller model with
0.23 billion parameters, is optimized through full-parameter fine-tuning across
three distinct experiments, each utilizing datasets augmented to different
levels. The results show that Florence-2 achieves a 29.95% increase in
precision, a 37.75% increase in recall, a 52.40% improvement in F1-score, and a
43.15% reduction in hallucination rate compared to the best-performing
closed-source model. These findings highlight the effectiveness of fine-tuning
smaller, open-source VLMs like Florence-2, offering a practical and efficient
solution for automated GD&T extraction to support downstream manufacturing
tasks.

ÊëòË¶ÅÔºöÂπæ‰ΩïÂ∞∫ÂØ∏ËàáÂÖ¨Â∑Æ (GD&T) Âú®Ë£ΩÈÄ†Ê•≠‰∏≠ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤ÔºåÈÄèÈÅéÂÆöÁæ©Èõ∂‰ª∂ÁâπÂæµÁöÑÂèØÊé•ÂèóËÆäÁï∞Ôºå‰ª•Á¢∫‰øùÁµÑ‰ª∂ÂìÅË≥™ËàáÂäüËÉΩ„ÄÇÁÑ∂ËÄåÔºåÂæû 2D Â∑•Á®ãÂúñ‰∏≠ËêÉÂèñ GD&T Ë≥áË®äÊòØ‰∏ÄÈ†ÖËÄóÊôÇ‰∏îÂãûÂäõÂØÜÈõÜÁöÑ‰ªªÂãôÔºåÈÄöÂ∏∏‰ª∞Ë≥¥‰∫∫Â∑•Êìç‰ΩúÊàñÂçäËá™ÂãïÂåñÂ∑•ÂÖ∑„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊú¨Á†îÁ©∂ÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆËá™ÂãïÂåñ‰∏îË®àÁÆóÊïàÁéáÈ´òÁöÑ GD&T ËêÉÂèñÊñπÊ≥ïÔºåÈÄèÈÅéÂæÆË™øÈñãÊ∫êÁöÑË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) Florence-2„ÄÇË©≤Ê®°ÂûãÂú®‰∏ÄÂÄãÁî±È†òÂüüÂ∞àÂÆ∂Êèê‰æõÁúüÂØ¶Ê®ôË®ªÁöÑ 400 ÂºµÂúñÈù¢Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åË®ìÁ∑¥„ÄÇÁÇ∫‰∫ÜÊØîËºÉÔºåÂÖ©ÂÄãÊúÄÂÖàÈÄ≤ÁöÑÈñâÊ∫ê VLMÔºåGPT-4o Âíå Claude-3.5-SonnetÔºå‰πüÂú®Áõ∏ÂêåÁöÑË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åË©ï‰º∞„ÄÇÊâÄÊúâÊ®°ÂûãÂùá‰ΩøÁî®Á≤æÁ¢∫Â∫¶„ÄÅÂè¨ÂõûÁéá„ÄÅF1 ÂàÜÊï∏ÂíåÂπªË¶∫ÊåáÊ®ôÈÄ≤Ë°åË©ï‰º∞„ÄÇÁî±ÊñºÂæÆË™øÂ§ßÂûãÈñâÊ∫ê VLM ÈÄ≤Ë°åÁâπÂÆöÈ†òÂüü‰ªªÂãôÁöÑË®àÁÆóÊàêÊú¨È´ò‰∏î‰∏çÂàáÂØ¶ÈöõÔºåÂõ†Ê≠§ GPT-4o Âíå Claude-3.5-Sonnet Âú®Èõ∂Ê®£Êú¨Â≠∏ÁøíÁöÑË®≠ÂÆö‰∏ãÈÄ≤Ë°åË©ï‰º∞„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåFlorence-2 ÊòØÂÄãËºÉÂ∞èÁöÑÊ®°ÂûãÔºåÂÖ∑Êúâ 0.23 ÂÑÑÂÄãÂèÉÊï∏ÔºåÈÄèÈÅé‰∏âÂÄã‰∏çÂêåÁöÑÂØ¶È©óÈÄ≤Ë°åÂÖ®ÂèÉÊï∏ÂæÆË™øÈÄ≤Ë°åÊúÄ‰Ω≥ÂåñÔºåÊØèÂÄãÂØ¶È©óÈÉΩ‰ΩøÁî®Êì¥ÂÖÖÂà∞‰∏çÂêåÁ®ãÂ∫¶ÁöÑË≥áÊñôÈõÜ„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåËàáÊïàËÉΩÊúÄ‰Ω≥ÁöÑÈñâÊ∫êÊ®°ÂûãÁõ∏ÊØîÔºåFlorence-2 Âú®Á≤æÁ¢∫Â∫¶ÊèêÂçá‰∫Ü 29.95%ÔºåÂè¨ÂõûÁéáÊèêÂçá‰∫Ü 37.75%ÔºåF1 ÂàÜÊï∏ÊèêÂçá‰∫Ü 52.40%ÔºåÂπªË¶∫ÁéáÈôç‰Ωé‰∫Ü 43.15%„ÄÇÈÄô‰∫õÁôºÁèæÁ™ÅÈ°Ø‰∫ÜÂæÆË™øËºÉÂ∞èÁöÑÈñãÊ∫ê VLMÔºà‰æãÂ¶Ç Florence-2ÔºâÁöÑÊúâÊïàÊÄßÔºåÁÇ∫Ëá™ÂãïÂåñ GD&T ËêÉÂèñÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂØ¶Áî®‰∏îÈ´òÊïàÁöÑËß£Ê±∫ÊñπÊ°àÔºå‰ª•ÊîØÊè¥‰∏ãÊ∏∏Ë£ΩÈÄ†‰ªªÂãô„ÄÇ

##### **The Root Shapes the Fruit: On the Persistence of Gender-Exclusive Harms in Aligned Language Models**
2411.03700v1 by Anaelia Ovalle, Krunoslav Lehman Pavasovic, Louis Martin, Luke Zettlemoyer, Eric Michael Smith, Adina Williams, Levent Sagun

Natural-language assistants are designed to provide users with helpful
responses while avoiding harmful outputs, largely achieved through alignment to
human preferences. Yet there is limited understanding of whether alignment
techniques may inadvertently perpetuate or even amplify harmful biases
inherited from their pre-aligned base models. This issue is compounded by the
choice of bias evaluation benchmarks in popular preference-finetuned models,
which predominantly focus on dominant social categories, such as binary gender,
thereby limiting insights into biases affecting underrepresented groups.
Towards addressing this gap, we center transgender, nonbinary, and other
gender-diverse identities to investigate how alignment procedures interact with
pre-existing gender-diverse bias in LLMs. Our key contributions include: 1) a
comprehensive survey of bias evaluation modalities across leading
preference-finetuned LLMs, highlighting critical gaps in gender-diverse
representation, 2) systematic evaluation of gender-diverse biases across 12
models spanning Direct Preference Optimization (DPO) stages, uncovering harms
popular bias benchmarks fail to detect, and 3) a flexible framework for
measuring harmful biases in implicit reward signals applicable to other social
contexts. Our findings reveal that DPO-aligned models are particularly
sensitive to supervised finetuning (SFT), and can amplify two forms of
real-world gender-diverse harms from their base models: stigmatization and
gender non-affirmative language. We conclude with recommendations tailored to
DPO and broader alignment practices, advocating for the adoption of
community-informed bias evaluation frameworks to more effectively identify and
address underrepresented harms in LLMs.

ÊëòË¶ÅÔºöËá™ÁÑ∂Ë™ûË®ÄÂä©ÁêÜÊó®Âú®ÁÇ∫‰ΩøÁî®ËÄÖÊèê‰æõÊúâÁî®ÁöÑÂõûÊáâÔºåÂêåÊôÇÈÅøÂÖçÊúâÂÆ≥ÁöÑËº∏Âá∫ÔºåÈÄô‰∏ªË¶ÅÊòØÈÄèÈÅéËàá‰∫∫È°ûÂÅèÂ•Ω‰øùÊåÅ‰∏ÄËá¥‰æÜÂØ¶ÁèæÁöÑ„ÄÇÁÑ∂ËÄåÔºåÂ∞çÊñºÂ∞çÈΩäÊäÄË°ìÊòØÂê¶ÊúÉÁÑ°ÊÑè‰∏≠Âª∂Á∫åÁîöËá≥ÊîæÂ§ßÂæûÂÖ∂È†êÂÖàÂ∞çÈΩäÁöÑÂü∫Êú¨Ê®°Âûã‰∏≠ÁπºÊâøÁöÑÊúâÂÆ≥ÂÅèË¶ãÔºåÁõÆÂâç‰∫ÜËß£ÊúâÈôê„ÄÇÈÄôÂÄãÂïèÈ°åÊòØÁî±ÊµÅË°åÁöÑÂÅèÂ•ΩÂæÆË™øÊ®°Âûã‰∏≠ÂÅèË¶ãË©ï‰º∞Âü∫Ê∫ñÁöÑÈÅ∏ÊìáÊâÄÂä†ÂäáÔºåÈÄô‰∫õÂü∫Ê∫ñ‰∏ªË¶ÅÈóúÊ≥®‰∏ªË¶ÅÁöÑÁ§æÊúÉÈ°ûÂà•Ôºå‰æãÂ¶Ç‰∫åÂÖÉÊÄßÂà•ÔºåÂæûËÄåÈôêÂà∂‰∫ÜÂ∞çÂΩ±Èüø‰ª£Ë°®ÊÄß‰∏çË∂≥ÁöÑÁæ§È´îÁöÑÂÅèË¶ãÁöÑÊ∑±ÂÖ•‰∫ÜËß£„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄë‰ª•Ë∑®ÊÄßÂà•„ÄÅÈùû‰∫åÂÖÉÊÄßÂà•ÂíåÂÖ∂‰ªñÊÄßÂà•Â§öÂÖÉË∫´ÂàÜÁÇ∫‰∏≠ÂøÉÔºåÊé¢Ë®éÂ∞çÈΩäÁ®ãÂ∫èÂ¶Ç‰ΩïËàá LLM ‰∏≠Â∑≤Â≠òÂú®ÁöÑÊÄßÂà•Â§öÂÖÉÂÅèË¶ãÁõ∏‰∫í‰ΩúÁî®„ÄÇÊàëÂÄëÁöÑÈóúÈçµË≤¢ÁçªÂåÖÊã¨Ôºö1) Â∞çÈ†òÂÖàÁöÑÂÅèÂ•ΩÂæÆË™ø LLM ‰∏≠ÁöÑÂÅèË¶ãË©ï‰º∞ÊñπÂºèÈÄ≤Ë°åÂÖ®Èù¢Ë™øÊü•ÔºåÂº∑Ë™øÊÄßÂà•Â§öÂÖÉ‰ª£Ë°®ÊÄßÁöÑÈóúÈçµÂ∑ÆË∑ùÔºå2) Â∞çË∑®Ë∂äÁõ¥Êé•ÂÅèÂ•ΩÊúÄ‰Ω≥Âåñ (DPO) ÈöéÊÆµÁöÑ 12 ÂÄãÊ®°ÂûãÈÄ≤Ë°åÊÄßÂà•Â§öÂÖÉÂÅèË¶ãÁöÑÁ≥ªÁµ±ÊÄßË©ï‰º∞ÔºåÊè≠Èú≤ÊµÅË°åÁöÑÂÅèË¶ãÂü∫Ê∫ñÊú™ËÉΩÂÅµÊ∏¨Âà∞ÁöÑÂç±ÂÆ≥Ôºå‰ª•Âèä 3) ‰∏ÄÂÄãÈùàÊ¥ªÁöÑÊû∂ÊßãÔºåÁî®ÊñºË°°ÈáèÈÅ©Áî®ÊñºÂÖ∂‰ªñÁ§æÊúÉËÉåÊôØÁöÑÈö±Âê´ÁçéÂãµ‰ø°Ëôü‰∏≠ÁöÑÊúâÂÆ≥ÂÅèË¶ã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåDPO Â∞çÈΩäÊ®°ÂûãÁâπÂà•ÂÆπÊòìÂèóÂà∞Áõ£Áù£ÂæÆË™ø (SFT) ÁöÑÂΩ±ÈüøÔºå‰∏¶‰∏îÂèØ‰ª•ÊîæÂ§ßÂÖ∂Âü∫Êú¨Ê®°Âûã‰∏≠ÁöÑÂÖ©Á®ÆÂΩ¢ÂºèÁöÑÁèæÂØ¶‰∏ñÁïåÊÄßÂà•Â§öÂÖÉÂç±ÂÆ≥ÔºöÊ±°ÂêçÂåñÂíåÊÄßÂà•ÈùûËÇØÂÆöË™ûË®Ä„ÄÇÊàëÂÄëÊúÄÂæåÊèêÂá∫ÈáùÂ∞ç DPO ÂíåÊõ¥Âª£Ê≥õÂ∞çÈΩäÂØ¶ÂãôÁöÑÂª∫Ë≠∞ÔºåÊèêÂÄ°Êé°Áî®Áî±Á§æÁæ§Êèê‰æõÁöÑÂÅèË¶ãË©ï‰º∞Êû∂ÊßãÔºå‰ª•Êõ¥ÊúâÊïàÂú∞Ë≠òÂà•ÂíåËß£Ê±∫ LLM ‰∏≠‰ª£Ë°®ÊÄß‰∏çË∂≥ÁöÑÂç±ÂÆ≥„ÄÇ

##### **Beyond Model Adaptation at Test Time: A Survey**
2411.03687v1 by Zehao Xiao, Cees G. M. Snoek

Machine learning algorithms have achieved remarkable success across various
disciplines, use cases and applications, under the prevailing assumption that
training and test samples are drawn from the same distribution. Consequently,
these algorithms struggle and become brittle even when samples in the test
distribution start to deviate from the ones observed during training. Domain
adaptation and domain generalization have been studied extensively as
approaches to address distribution shifts across test and train domains, but
each has its limitations. Test-time adaptation, a recently emerging learning
paradigm, combines the benefits of domain adaptation and domain generalization
by training models only on source data and adapting them to target data during
test-time inference. In this survey, we provide a comprehensive and systematic
review on test-time adaptation, covering more than 400 recent papers. We
structure our review by categorizing existing methods into five distinct
categories based on what component of the method is adjusted for test-time
adaptation: the model, the inference, the normalization, the sample, or the
prompt, providing detailed analysis of each. We further discuss the various
preparation and adaptation settings for methods within these categories,
offering deeper insights into the effective deployment for the evaluation of
distribution shifts and their real-world application in understanding images,
video and 3D, as well as modalities beyond vision. We close the survey with an
outlook on emerging research opportunities for test-time adaptation.

ÊëòË¶ÅÔºöÊ©üÂô®Â≠∏ÁøíÊºîÁÆóÊ≥ïÂú®ÂêÑÁ®ÆÈ†òÂüü„ÄÅ‰ΩøÁî®Ê°à‰æãÂíåÊáâÁî®‰∏≠ÈÉΩÂèñÂæó‰∫ÜÈ°ØËëóÁöÑÊàêÂäüÔºåÂÖ∂ÂâçÊèêÂÅáË®≠ÊòØË®ìÁ∑¥ÂíåÊ∏¨Ë©¶Ê®£Êú¨‰æÜËá™Áõ∏ÂêåÁöÑÂàÜÂ∏É„ÄÇÂõ†Ê≠§ÔºåÂç≥‰ΩøÊ∏¨Ë©¶ÂàÜÂ∏É‰∏≠ÁöÑÊ®£Êú¨ÈñãÂßãÂÅèÈõ¢Ë®ìÁ∑¥ÊúüÈñìËßÄÂØüÂà∞ÁöÑÊ®£Êú¨ÔºåÈÄô‰∫õÊºîÁÆóÊ≥ï‰πüÊúÉÈô∑ÂÖ•Âõ∞Â¢É‰∏¶ËÆäÂæóËÑÜÂº±„ÄÇÈ†òÂüüÈÅ©ÊáâÂíåÈ†òÂüüÊ≥õÂåñÂ∑≤Ë¢´Âª£Ê≥õÁ†îÁ©∂ÁÇ∫Ëß£Ê±∫Ê∏¨Ë©¶ÂíåË®ìÁ∑¥È†òÂüü‰πãÈñìÂàÜ‰ΩàËΩâÁßªÁöÑÊñπÊ≥ïÔºå‰ΩÜÊØèÁ®ÆÊñπÊ≥ïÈÉΩÊúâÂÖ∂Â±ÄÈôêÊÄß„ÄÇÊ∏¨Ë©¶ÊôÇÈÅ©ÊáâÊòØ‰∏ÄÁ®ÆÊúÄËøëÊñ∞ËààÁöÑÂ≠∏ÁøíÁØÑ‰æãÔºåÂÆÉÁµêÂêà‰∫ÜÈ†òÂüüÈÅ©ÊáâÂíåÈ†òÂüüÊ≥õÂåñÁöÑÂÑ™ÈªûÔºåÂÉÖ‰ΩøÁî®‰æÜÊ∫êË≥áÊñôË®ìÁ∑¥Ê®°ÂûãÔºå‰∏¶Âú®Ê∏¨Ë©¶ÊôÇÊé®ÁêÜÊúüÈñìÂ∞áÂÖ∂ÈÅ©ÊáâÂà∞ÁõÆÊ®ôË≥áÊñô„ÄÇÂú®Êú¨Ê¨°Ë™øÊü•‰∏≠ÔºåÊàëÂÄëÊèê‰æõ‰∫ÜÂ∞çÊ∏¨Ë©¶ÊôÇÈÅ©ÊáâÁöÑÂÖ®Èù¢‰∏îÁ≥ªÁµ±ÊÄßÁöÑÂõûÈ°ßÔºåÊ∂µËìã‰∫Ü 400 Â§öÁØáËøëÊúüË´ñÊñá„ÄÇÊàëÂÄëÊ†πÊìöÊñπÊ≥ïÁöÑÂì™ÂÄãÁµÑÊàêÈÉ®ÂàÜÁ∂ìÈÅéË™øÊï¥‰ª•ÈÄ≤Ë°åÊ∏¨Ë©¶ÊôÇÈÅ©ÊáâÔºåÂ∞áÁèæÊúâÊñπÊ≥ïÂàÜÈ°ûÁÇ∫‰∫îÂÄã‰∏çÂêåÁöÑÈ°ûÂà•‰æÜÊû∂ÊßãÊàëÂÄëÁöÑÂõûÈ°ßÔºöÊ®°Âûã„ÄÅÊé®ÁêÜ„ÄÅÊ≠£Ë¶èÂåñ„ÄÅÊ®£Êú¨ÊàñÊèêÁ§∫Ôºå‰∏¶Â∞çÊØèÂÄãÈ°ûÂà•Êèê‰æõË©≥Á¥∞ÂàÜÊûê„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Ë®éË´ñ‰∫ÜÈÄô‰∫õÈ°ûÂà•‰∏≠ÊñπÊ≥ïÁöÑÂêÑÁ®ÆÊ∫ñÂÇôÂíåÈÅ©ÊáâË®≠ÂÆöÔºåÊèê‰æõÊõ¥Ê∑±ÂÖ•ÁöÑË¶ãËß£Ôºå‰ª•ÊúâÊïàÈÉ®ÁΩ≤‰æÜË©ï‰º∞ÂàÜ‰ΩàËΩâÁßªÂèäÂÖ∂Âú®ÁêÜËß£ÂΩ±ÂÉè„ÄÅÂΩ±ÁâáÂíå 3D ‰∏≠ÁöÑÂØ¶ÈöõÊáâÁî®Ôºå‰ª•ÂèäË∂ÖË∂äË¶ñË¶∫ÁöÑÊ®°ÊÖã„ÄÇÊàëÂÄë‰ª•Â∞çÊ∏¨Ë©¶ÊôÇÈÅ©ÊáâÁöÑÊñ∞ËààÁ†îÁ©∂Ê©üÊúÉÁöÑÂ±ïÊúõ‰ΩúÁÇ∫Êú¨Ê¨°Ë™øÊü•ÁöÑÁµêÂ∞æ„ÄÇ

##### **QUILL: Quotation Generation Enhancement of Large Language Models**
2411.03675v1 by Jin Xiao, Bowei Zhang, Qianyu He, Jiaqing Liang, Feng Wei, Jinglei Chen, Zujie Liang, Deqing Yang, Yanghua Xiao

While Large language models (LLMs) have become excellent writing assistants,
they still struggle with quotation generation. This is because they either
hallucinate when providing factual quotations or fail to provide quotes that
exceed human expectations. To bridge the gap, we systematically study how to
evaluate and improve LLMs' performance in quotation generation tasks. We first
establish a holistic and automatic evaluation system for quotation generation
task, which consists of five criteria each with corresponding automatic metric.
To improve the LLMs' quotation generation abilities, we construct a bilingual
knowledge base that is broad in scope and rich in dimensions, containing up to
32,022 quotes. Moreover, guided by our critiria, we further design a
quotation-specific metric to rerank the retrieved quotations from the knowledge
base. Extensive experiments show that our metrics strongly correlate with human
preferences. Existing LLMs struggle to generate desired quotes, but our
quotation knowledge base and reranking metric help narrow this gap. Our dataset
and code are publicly available at https://github.com/GraceXiaoo/QUILL.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤ÊàêÁÇ∫ÂÑ™ÁßÄÁöÑÂØ´‰ΩúÂä©ÁêÜÔºå
ÂÆÉÂÄëÂú®ÂºïÊñáÁî¢ÁîüÊñπÈù¢‰ªçÊúâÂõ∞Èõ£„ÄÇÈÄôÊòØÂõ†ÁÇ∫ÂÆÉÂÄëÂú®Êèê‰æõ‰∫ãÂØ¶ÂºïÊñáÊôÇÊúÉÂá∫ÁèæÂπªË¶∫ÔºåÊàñÁÑ°Ê≥ïÊèê‰æõË∂ÖÂá∫‰∫∫È°ûÈ†êÊúüÁöÑÂºïÊñá„ÄÇÁÇ∫‰∫ÜÂΩåË£úÂ∑ÆË∑ùÔºåÊàëÂÄëÁ≥ªÁµ±ÊÄßÂú∞Á†îÁ©∂Â¶Ç‰ΩïË©ï‰º∞ÂíåÊîπÂñÑ LLM Âú®ÂºïÊñáÁî¢Áîü‰ªªÂãô‰∏≠ÁöÑË°®Áèæ„ÄÇÊàëÂÄëÈ¶ñÂÖàÁÇ∫ÂºïÊñáÁî¢Áîü‰ªªÂãôÂª∫Á´ã‰∏ÄÂÄãÊï¥È´î‰∏îËá™ÂãïÂåñÁöÑË©ï‰º∞Á≥ªÁµ±ÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∫îÂÄãÊ®ôÊ∫ñÔºåÊØèÂÄãÊ®ôÊ∫ñÈÉΩÊúâÁõ∏ÊáâÁöÑËá™ÂãïÂåñÊåáÊ®ô„ÄÇÁÇ∫‰∫ÜÊèêÂçá LLM ÁöÑÂºïÊñáÁî¢ÁîüËÉΩÂäõÔºåÊàëÂÄëÊßãÂª∫‰∫Ü‰∏ÄÂÄãÁØÑÂúçÂª£Ê≥õ‰∏îÁ∂≠Â∫¶Ë±êÂØåÁöÑÈõôË™ûÁü•Ë≠òÂ∫´ÔºåÂÖ∂‰∏≠ÂåÖÂê´Â§öÈÅî 32,022 ÂÄãÂºïÊñá„ÄÇÊ≠§Â§ñÔºåÂú®ÊàëÂÄëÊ®ôÊ∫ñÁöÑÊåáÂ∞é‰∏ãÔºåÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Ë®≠Ë®à‰∫Ü‰∏ÄÂÄãÁâπÂÆöÊñºÂºïÊñáÁöÑÊåáÊ®ôÔºå‰ª•ÈáçÊñ∞ÊéíÂàóÂæûÁü•Ë≠òÂ∫´‰∏≠Êì∑ÂèñÁöÑÂºïÊñá„ÄÇÂ§ßÈáèÁöÑÂØ¶È©óË°®ÊòéÔºåÊàëÂÄëÁöÑÊåáÊ®ôËàá‰∫∫È°ûÂÅèÂ•ΩÊúâÂæàÂº∑ÁöÑÁõ∏ÈóúÊÄß„ÄÇÁèæÊúâÁöÑ LLM Èõ£‰ª•Áî¢ÁîüÊâÄÈúÄÁöÑÂºïÊñáÔºå‰ΩÜÊàëÂÄëÁöÑÂºïÊñáÁü•Ë≠òÂ∫´ÂíåÈáçÊñ∞ÊéíÂàóÊåáÊ®ôÊúâÂä©ÊñºÁ∏ÆÂ∞èÂ∑ÆË∑ù„ÄÇÊàëÂÄëÁöÑÊï∏ÊìöÈõÜÂíåÁ®ãÂºèÁ¢ºÂ∑≤ÂÖ¨ÈñãÁôºÂ∏ÉÊñº https://github.com/GraceXiaoo/QUILL„ÄÇ

##### **Towards 3D Semantic Scene Completion for Autonomous Driving: A Meta-Learning Framework Empowered by Deformable Large-Kernel Attention and Mamba Model**
2411.03672v1 by Yansong Qu, Zilin Huang, Zihao Sheng, Tiantian Chen, Sikai Chen

Semantic scene completion (SSC) is essential for achieving comprehensive
perception in autonomous driving systems. However, existing SSC methods often
overlook the high deployment costs in real-world applications. Traditional
architectures, such as 3D Convolutional Neural Networks (3D CNNs) and
self-attention mechanisms, face challenges in efficiently capturing long-range
dependencies within 3D voxel grids, limiting their effectiveness. To address
these issues, we introduce MetaSSC, a novel meta-learning-based framework for
SSC that leverages deformable convolution, large-kernel attention, and the
Mamba (D-LKA-M) model. Our approach begins with a voxel-based semantic
segmentation (SS) pretraining task, aimed at exploring the semantics and
geometry of incomplete regions while acquiring transferable meta-knowledge.
Using simulated cooperative perception datasets, we supervise the perception
training of a single vehicle using aggregated sensor data from multiple nearby
connected autonomous vehicles (CAVs), generating richer and more comprehensive
labels. This meta-knowledge is then adapted to the target domain through a
dual-phase training strategy that does not add extra model parameters, enabling
efficient deployment. To further enhance the model's capability in capturing
long-sequence relationships within 3D voxel grids, we integrate Mamba blocks
with deformable convolution and large-kernel attention into the backbone
network. Extensive experiments demonstrate that MetaSSC achieves
state-of-the-art performance, significantly outperforming competing models
while also reducing deployment costs.

ÊëòË¶ÅÔºöË™ûÊÑèÂ†¥ÊôØÂÆåÊàê (SSC) Â∞çÊñºÂú®Ëá™ÂãïÈßïÈßõÁ≥ªÁµ±‰∏≠ÂØ¶ÁèæÂÖ®Èù¢ÊÑüÁü•Ëá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑ SSC ÊñπÊ≥ïÈÄöÂ∏∏ÂøΩÁï•‰∫ÜÂú®ÂØ¶ÈöõÊáâÁî®‰∏≠ÁöÑÈ´òÈÉ®ÁΩ≤ÊàêÊú¨„ÄÇÂÇ≥Áµ±Êû∂ÊßãÔºå‰æãÂ¶Ç 3D Êç≤Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (3D CNN) ÂíåËá™ÊàëÊ≥®ÊÑèÊ©üÂà∂ÔºåÂú®ÊúâÊïàÊì∑Âèñ 3D È´îÁ¥†Á∂≤Ê†ºÂÖßÁöÑÈï∑Á®ã‰æùË≥¥Èóú‰øÇÊôÇÈù¢Ëá®ÊåëÊà∞ÔºåÈôêÂà∂‰∫ÜÂÆÉÂÄëÁöÑÊïàËÉΩ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü MetaSSCÔºå‰∏ÄÂÄãÁî®Êñº SSC ÁöÑÊñ∞ÂÖÉÂ≠∏ÁøíÂü∫Á§éÊû∂ÊßãÔºåÂÆÉÂà©Áî®ÂèØËÆäÂΩ¢Âç∑Á©ç„ÄÅÂ§ßÊ†∏Ê≥®ÊÑèÂäõÂíå Mamba (D-LKA-M) Ê®°Âûã„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂæû‰∏ÄÂÄãÂü∫ÊñºÈ´îÁ¥†ÁöÑË™ûÊÑèÂàÜÂâ≤ (SS) È†êË®ìÁ∑¥‰ªªÂãôÈñãÂßãÔºåÊó®Âú®Êé¢Á¥¢‰∏çÂÆåÊï¥ÂçÄÂüüÁöÑË™ûÊÑèÂíåÂπæ‰ΩïÂΩ¢ÁãÄÔºåÂêåÊôÇÁç≤ÂèñÂèØËΩâÁßªÁöÑÂÖÉÁü•Ë≠ò„ÄÇ‰ΩøÁî®Ê®°Êì¨Âçî‰ΩúÊÑüÁü•Ë≥áÊñôÈõÜÔºåÊàëÂÄë‰ΩøÁî®‰æÜËá™Â§öÂÄãÈôÑËøëÈÄ£Êé•Ëá™ÂãïÈßïÈßõËªäËºõ (CAV) ÁöÑËÅöÂêàÊÑüÊ∏¨Âô®Ë≥áÊñôÁõ£Áù£ÂñÆ‰∏ÄËªäËºõÁöÑÊÑüÁü•Ë®ìÁ∑¥ÔºåÁî¢ÁîüÊõ¥Ë±êÂØå„ÄÅÊõ¥ÂÖ®Èù¢ÁöÑÊ®ôÁ±§„ÄÇÁÑ∂ÂæåÈÄèÈÅé‰∏ÄÁ®Æ‰∏çÂ¢ûÂä†È°çÂ§ñÊ®°ÂûãÂèÉÊï∏ÁöÑÈõôÈöéÊÆµË®ìÁ∑¥Á≠ñÁï•Â∞áÊ≠§ÂÖÉÁü•Ë≠òË™øÊï¥Âà∞ÁõÆÊ®ôÈ†òÂüüÔºåÂæûËÄåÂØ¶ÁèæÈ´òÊïàÈÉ®ÁΩ≤„ÄÇÁÇ∫‰∫ÜÈÄ≤‰∏ÄÊ≠•Â¢ûÂº∑Ê®°ÂûãÂú®Êì∑Âèñ 3D È´îÁ¥†Á∂≤Ê†ºÂÖßÁöÑÈï∑Â∫èÂàóÈóú‰øÇÊñπÈù¢ÁöÑËÉΩÂäõÔºåÊàëÂÄëÂ∞á Mamba Á©çÊú®ËàáÂèØËÆäÂΩ¢Âç∑Á©çÂíåÂ§ßÊ†∏Ê≥®ÊÑèÂäõÊï¥ÂêàÂà∞‰∏ªÂππÁ∂≤Ë∑Ø‰∏≠„ÄÇÂ§ßÈáèÁöÑÂØ¶È©óË≠âÊòéÔºåMetaSSC ÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºåÈ°ØËëóÂÑ™ÊñºÁ´∂Áà≠Ê®°ÂûãÔºåÂêåÊôÇ‰πüÈôç‰Ωé‰∫ÜÈÉ®ÁΩ≤ÊàêÊú¨„ÄÇ

##### **Evaluating Moral Beliefs across LLMs through a Pluralistic Framework**
2411.03665v1 by Xuelin Liu, Yanfei Zhu, Shucheng Zhu, Pengyuan Liu, Ying Liu, Dong Yu

Proper moral beliefs are fundamental for language models, yet assessing these
beliefs poses a significant challenge. This study introduces a novel
three-module framework to evaluate the moral beliefs of four prominent large
language models. Initially, we constructed a dataset containing 472 moral
choice scenarios in Chinese, derived from moral words. The decision-making
process of the models in these scenarios reveals their moral principle
preferences. By ranking these moral choices, we discern the varying moral
beliefs held by different language models. Additionally, through moral debates,
we investigate the firmness of these models to their moral choices. Our
findings indicate that English language models, namely ChatGPT and Gemini,
closely mirror moral decisions of the sample of Chinese university students,
demonstrating strong adherence to their choices and a preference for
individualistic moral beliefs. In contrast, Chinese models such as Ernie and
ChatGLM lean towards collectivist moral beliefs, exhibiting ambiguity in their
moral choices and debates. This study also uncovers gender bias embedded within
the moral beliefs of all examined language models. Our methodology offers an
innovative means to assess moral beliefs in both artificial and human
intelligence, facilitating a comparison of moral values across different
cultures.

ÊëòË¶ÅÔºöÈÅ©Áï∂ÁöÑÈÅìÂæ∑‰ø°ÂøµÂ∞çÊñºË™ûË®ÄÊ®°ÂûãËá≥ÈóúÈáçË¶ÅÔºåÁÑ∂ËÄåË©ï‰º∞ÈÄô‰∫õ‰ø°ÂøµÂçªÊòØ‰∏ÄÈ†ÖÈáçÂ§ßÊåëÊà∞„ÄÇÊú¨Á†îÁ©∂ÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑ‰∏âÊ®°ÁµÑÊû∂Êßã‰æÜË©ï‰º∞ÂõõÂÄãÂÇëÂá∫ÁöÑÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÈÅìÂæ∑‰ø°Âøµ„ÄÇÊúÄÂàùÔºåÊàëÂÄëÊßãÂª∫‰∫Ü‰∏ÄÂÄãÂåÖÂê´ 472 ÂÄãÈÅìÂæ∑ÈÅ∏ÊìáÊÉÖÂ¢ÉÁöÑ‰∏≠ÊñáË≥áÊñôÈõÜÔºåÈÄô‰∫õÊÉÖÂ¢ÉÊ∫êËá™ÈÅìÂæ∑Ë©ûÂΩô„ÄÇÊ®°ÂûãÂú®ÈÄô‰∫õÊÉÖÂ¢É‰∏≠ÁöÑÊ±∫Á≠ñÈÅéÁ®ãÊè≠Á§∫‰∫ÜÂÆÉÂÄëÁöÑÈÅìÂæ∑ÂéüÂâáÂÅèÂ•Ω„ÄÇÈÄèÈÅéÂ∞çÈÄô‰∫õÈÅìÂæ∑ÈÅ∏ÊìáÈÄ≤Ë°åÊéíÂêçÔºåÊàëÂÄëËæ®Âà•‰∫Ü‰∏çÂêåË™ûË®ÄÊ®°ÂûãÊâÄÊåÅÊúâÁöÑ‰∏çÂêåÈÅìÂæ∑‰ø°Âøµ„ÄÇÊ≠§Â§ñÔºåÈÄèÈÅéÈÅìÂæ∑ËæØË´ñÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÈÄô‰∫õÊ®°ÂûãÂ∞çÂÖ∂ÈÅìÂæ∑ÈÅ∏ÊìáÁöÑÂ†ÖÂÆöÁ®ãÂ∫¶„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåËã±Ë™ûË™ûË®ÄÊ®°ÂûãÔºåÂç≥ ChatGPT Âíå GeminiÔºåËàá‰∏≠ÂúãÂ§ßÂ≠∏ÁîüÊ®£Êú¨ÁöÑÈÅìÂæ∑Ê±∫Á≠ñÈùûÂ∏∏Áõ∏‰ººÔºåË°®ÊòéÂÆÉÂÄëÂ†ÖÂÆöÂú∞Â†ÖÊåÅËá™Â∑±ÁöÑÈÅ∏ÊìáÔºå‰∏¶‰∏îÂÅèÂ•ΩÂÄã‰∫∫‰∏ªÁæ©ÈÅìÂæ∑‰ø°Âøµ„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåErnie Âíå ChatGLM Á≠â‰∏≠ÊñáÊ®°ÂûãÂâáÂÇæÂêëÊñºÈõÜÈ´î‰∏ªÁæ©ÈÅìÂæ∑‰ø°ÂøµÔºåÂú®‰ªñÂÄëÁöÑÈÅìÂæ∑ÈÅ∏ÊìáÂíåËæØË´ñ‰∏≠Ë°®ÁèæÂá∫Ê®°Á®úÂÖ©ÂèØÁöÑÊÖãÂ∫¶„ÄÇÊú¨Á†îÁ©∂ÈÇÑÊè≠Á§∫‰∫ÜÊâÄÊúâÂèóÊ™¢Ë™ûË®ÄÊ®°ÂûãÁöÑÈÅìÂæ∑‰ø°Âøµ‰∏≠Â≠òÂú®ÁöÑÊÄßÂà•ÂÅèË¶ã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÊñπÊ≥ïÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂâµÊñ∞ÁöÑÊñπÂºè‰æÜË©ï‰º∞‰∫∫Â∑•Âíå‰∫∫È°ûÊô∫ÊÖß‰∏≠ÁöÑÈÅìÂæ∑‰ø°ÂøµÔºåÂæûËÄå‰øÉÈÄ≤‰∏çÂêåÊñáÂåñ‰πãÈñìÈÅìÂæ∑ÂÉπÂÄºËßÄÁöÑÊØîËºÉ„ÄÇ

##### **Deploying Multi-task Online Server with Large Language Model**
2411.03644v1 by Yincen Qu, Chao Ma, Yiting Wu, Xiangying Dai, Hui Zhou, Hengyue Liu

In the industry, numerous tasks are deployed online. Traditional approaches
often tackle each task separately by its own network, which leads to excessive
costs for developing and scaling models, especially in the context of large
language models. Although multi-task methods can save costs through parameter
sharing, they often struggle to outperform single-task methods in real-world
applications. To tackle these challenges, we present a three-stage multi-task
learning framework for large language models. It involves task filtering,
followed by fine-tuning on high-resource tasks, and finally fine-tuning on all
tasks. We conducted comprehensive experiments in single-task and multi-task
settings. Our approach, exemplified on different benchmarks, demonstrates that
it is able to achieve performance comparable to the single-task method while
reducing up to 90.9\% of its overhead.

ÊëòË¶ÅÔºöÂú®Áî¢Ê•≠‰∏≠ÔºåË®±Â§ö‰ªªÂãôÊòØÂú®Á∑ö‰∏äÈÉ®ÁΩ≤ÁöÑ„ÄÇÂÇ≥Áµ±ÊñπÊ≥ïÈÄöÂ∏∏Áî±ÂÖ∂Ëá™Â∑±ÁöÑÁ∂≤Ë∑ØÂàÜÂà•ËôïÁêÜÊØèÂÄã‰ªªÂãôÔºåÈÄôÊúÉÂ∞éËá¥ÈñãÁôºÂíåÊì¥ÂÖÖÊ®°ÂûãÁöÑÊàêÊú¨ÈÅéÈ´òÔºåÁâπÂà•ÊòØÂú®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÊÉÖÊ≥Å‰∏ã„ÄÇÂÑòÁÆ°Â§ö‰ªªÂãôÊñπÊ≥ïÂèØ‰ª•ÈÄèÈÅéÂèÉÊï∏ÂÖ±‰∫´‰æÜÁØÄÁúÅÊàêÊú¨Ôºå‰ΩÜÂÆÉÂÄëÈÄöÂ∏∏Èõ£‰ª•Âú®ÁúüÂØ¶‰∏ñÁïåÁöÑÊáâÁî®‰∏≠Ë∂ÖË∂äÂñÆ‰ªªÂãôÊñπÊ≥ï„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÈáùÂ∞çÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑ‰∏âÈöéÊÆµÂ§ö‰ªªÂãôÂ≠∏ÁøíÊû∂Êßã„ÄÇÂÆÉÂåÖÂê´‰ªªÂãôÁØ©ÈÅ∏ÔºåÊé•ËëóÂú®È´òË≥áÊ∫ê‰ªªÂãô‰∏äÈÄ≤Ë°åÂæÆË™øÔºåÊúÄÂæåÂú®ÊâÄÊúâ‰ªªÂãô‰∏äÈÄ≤Ë°åÂæÆË™ø„ÄÇÊàëÂÄëÂú®ÂñÆ‰ªªÂãôÂíåÂ§ö‰ªªÂãôË®≠ÂÆö‰∏≠ÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑÂØ¶È©ó„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ï‰ª•‰∏çÂêåÁöÑÂü∫Ê∫ñÁÇ∫‰æãÔºåË≠âÊòéÂÆÉËÉΩÂ§†Âú®Ê∏õÂ∞ëÈ´òÈÅî 90.9% ÁöÑÈñãÈä∑‰∏ãÔºåÈÅîÂà∞ËàáÂñÆ‰ªªÂãôÊñπÊ≥ïÁõ∏Áï∂ÁöÑÊïàËÉΩ„ÄÇ

##### **RTify: Aligning Deep Neural Networks with Human Behavioral Decisions**
2411.03630v1 by Yu-Ang Cheng, Ivan Felipe Rodriguez, Sixuan Chen, Kohitij Kar, Takeo Watanabe, Thomas Serre

Current neural network models of primate vision focus on replicating overall
levels of behavioral accuracy, often neglecting perceptual decisions' rich,
dynamic nature. Here, we introduce a novel computational framework to model the
dynamics of human behavioral choices by learning to align the temporal dynamics
of a recurrent neural network (RNN) to human reaction times (RTs). We describe
an approximation that allows us to constrain the number of time steps an RNN
takes to solve a task with human RTs. The approach is extensively evaluated
against various psychophysics experiments. We also show that the approximation
can be used to optimize an "ideal-observer" RNN model to achieve an optimal
tradeoff between speed and accuracy without human data. The resulting model is
found to account well for human RT data. Finally, we use the approximation to
train a deep learning implementation of the popular Wong-Wang decision-making
model. The model is integrated with a convolutional neural network (CNN) model
of visual processing and evaluated using both artificial and natural image
stimuli. Overall, we present a novel framework that helps align current vision
models with human behavior, bringing us closer to an integrated model of human
vision.

ÊëòË¶ÅÔºöÁõÆÂâçÈùàÈï∑È°ûË¶ñË¶∫ÁöÑÁ•ûÁ∂ìÁ∂≤Ë∑ØÊ®°ÂûãËëóÈáçÊñºË§áË£ΩÊï¥È´îË°åÁÇ∫Ê∫ñÁ¢∫Â∫¶ÁöÑÂ±§Á¥öÔºåÁ∂ìÂ∏∏ÂøΩÁï•Áü•Ë¶∫Ê±∫Á≠ñÁöÑË±êÂØå„ÄÅÂãïÊÖãÊú¨Ë≥™„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÂºïÂÖ•‰∏ÄÂÄãÊñ∞Á©éÁöÑË®àÁÆóÊû∂ÊßãÔºåÈÄèÈÅéÂ≠∏ÁøíÂ∞áÈÅûËø¥Á•ûÁ∂ìÁ∂≤Ë∑Ø (RNN) ÁöÑÊôÇÈñìÂãïÊÖãËàá‰∫∫È°ûÂèçÊáâÊôÇÈñì (RT) Â∞çÈΩäÔºå‰æÜÂª∫Ê®°‰∫∫È°ûË°åÁÇ∫ÈÅ∏ÊìáÁöÑÂãïÊÖã„ÄÇÊàëÂÄëÊèèËø∞‰∫Ü‰∏ÄÂÄãËøë‰ººÂÄºÔºåËÆìÊàëÂÄëÂæó‰ª•ÈôêÂà∂ RNN Ëß£Ê±∫‰ªªÂãôÊâÄÈúÄÁöÑÊôÇÈñìÊ≠•Êï∏Ôºå‰∏¶ÂÖ∑ÂÇô‰∫∫È°ûÁöÑ RT„ÄÇÊ≠§ÊñπÊ≥ïÂ∑≤ÈáùÂ∞çÂêÑÁ®ÆÂøÉÁêÜÁâ©ÁêÜÂØ¶È©óÈÄ≤Ë°åÂª£Ê≥õË©ï‰º∞„ÄÇÊàëÂÄë‰πüÈ°ØÁ§∫ÔºåË©≤Ëøë‰ººÂÄºÂèØÁî®ÊñºÊúÄ‰Ω≥Âåñ„ÄåÁêÜÊÉ≥ËßÄÂØüËÄÖ„ÄçRNN Ê®°ÂûãÔºå‰ª•Âú®Ê≤íÊúâ‰∫∫È°ûË≥áÊñôÁöÑÊÉÖÊ≥Å‰∏ãÔºåÈÅîÊàêÈÄüÂ∫¶ÂíåÊ∫ñÁ¢∫Â∫¶‰πãÈñìÁöÑÊúÄ‰Ω≥ÊäòË°∑„ÄÇÁôºÁèæÊâÄÂæóÊ®°ÂûãËÉΩÂÖÖÂàÜË™™Êòé‰∫∫È°û RT Ë≥áÊñô„ÄÇÊúÄÂæåÔºåÊàëÂÄë‰ΩøÁî®Ëøë‰ººÂÄº‰æÜË®ìÁ∑¥ Wong-Wang Ê±∫Á≠ñÂà∂ÂÆöÊ®°ÂûãÁöÑÊ∑±Â∫¶Â≠∏ÁøíÂØ¶‰Ωú„ÄÇÊ≠§Ê®°ÂûãËàáË¶ñË¶∫ËôïÁêÜÁöÑÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑Ø (CNN) Ê®°ÂûãÊï¥ÂêàÔºå‰∏¶‰ΩøÁî®‰∫∫Â∑•ÂíåËá™ÁÑ∂ÂΩ±ÂÉèÂà∫ÊøÄÈÄ≤Ë°åË©ï‰º∞„ÄÇÁ∏ΩÁöÑ‰æÜË™™ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÊû∂ÊßãÔºåÊúâÂä©ÊñºÂ∞áÁõÆÂâçÁöÑË¶ñË¶∫Ê®°ÂûãËàá‰∫∫È°ûË°åÁÇ∫Â∞çÈΩäÔºåËÆìÊàëÂÄëÊõ¥Êé•Ëøë‰∫∫È°ûË¶ñË¶∫ÁöÑÊï¥ÂêàÊ®°Âûã„ÄÇ

##### **StreamingBench: Assessing the Gap for MLLMs to Achieve Streaming Video Understanding**
2411.03628v1 by Junming Lin, Zheng Fang, Chi Chen, Zihao Wan, Fuwen Luo, Peng Li, Yang Liu, Maosong Sun

The rapid development of Multimodal Large Language Models (MLLMs) has
expanded their capabilities from image comprehension to video understanding.
However, most of these MLLMs focus primarily on offline video comprehension,
necessitating extensive processing of all video frames before any queries can
be made. This presents a significant gap compared to the human ability to
watch, listen, think, and respond to streaming inputs in real time,
highlighting the limitations of current MLLMs. In this paper, we introduce
StreamingBench, the first comprehensive benchmark designed to evaluate the
streaming video understanding capabilities of MLLMs. StreamingBench assesses
three core aspects of streaming video understanding: (1) real-time visual
understanding, (2) omni-source understanding, and (3) contextual understanding.
The benchmark consists of 18 tasks, featuring 900 videos and 4,500
human-curated QA pairs. Each video features five questions presented at
different time points to simulate a continuous streaming scenario. We conduct
experiments on StreamingBench with 13 open-source and proprietary MLLMs and
find that even the most advanced proprietary MLLMs like Gemini 1.5 Pro and
GPT-4o perform significantly below human-level streaming video understanding
capabilities. We hope our work can facilitate further advancements for MLLMs,
empowering them to approach human-level video comprehension and interaction in
more realistic scenarios.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) ÁöÑÂø´ÈÄüÁôºÂ±ïÂ∑≤Â∞áÂÖ∂ËÉΩÂäõÂæûÂΩ±ÂÉèÁêÜËß£Êì¥Â±ïÂà∞ÂΩ±ÁâáÁêÜËß£„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õ MLLM Â§ßÂ§ö‰∏ªË¶ÅÂ∞àÊ≥®ÊñºÈõ¢Á∑öÂΩ±ÁâáÁêÜËß£ÔºåÂú®ÈÄ≤Ë°å‰ªª‰ΩïÊü•Ë©¢‰πãÂâçÈúÄË¶ÅÂ∞çÊâÄÊúâÂΩ±ÁâáÂπÄÈÄ≤Ë°åÂª£Ê≥õÁöÑËôïÁêÜ„ÄÇÈÄôËàá‰∫∫È°ûËßÄÁúã„ÄÅËÅÜËÅΩ„ÄÅÊÄùËÄÉÂíåÂç≥ÊôÇÂõûÊáâ‰∏≤ÊµÅËº∏ÂÖ•ÁöÑËÉΩÂäõÁõ∏ÊØîÔºåÂ≠òÂú®È°ØËëóÁöÑÂ∑ÆË∑ùÔºåÁ™ÅÈ°Ø‰∫ÜÁï∂Ââç MLLM ÁöÑÈôêÂà∂„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü StreamingBenchÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãÊó®Âú®Ë©ï‰º∞ MLLM ‰∏≤ÊµÅÂΩ±ÁâáÁêÜËß£ËÉΩÂäõÁöÑÁ∂úÂêàÂü∫Ê∫ñÊ∏¨Ë©¶„ÄÇStreamingBench Ë©ï‰º∞‰∏≤ÊµÅÂΩ±ÁâáÁêÜËß£ÁöÑ‰∏â‰∏™Ê†∏ÂøÉÊñπÈù¢Ôºö(1) Âç≥ÊôÇË¶ñË¶∫ÁêÜËß£Ôºå(2) ÂÖ®Ê∫êÁêÜËß£Ôºå‰ª•Âèä (3) ËÉåÊôØÁêÜËß£„ÄÇÂü∫Ê∫ñÊ∏¨Ë©¶ÂåÖÂê´ 18 È†Ö‰ªªÂãôÔºåÁâπÈªûÊòØ 900 ÈÉ®ÂΩ±ÁâáÂíå 4,500 ÂÄãÁî±‰∫∫Â∑•Á≠ñÂäÉÁöÑÂïèÁ≠îÈÖçÂ∞ç„ÄÇÊØèÈÉ®ÂΩ±ÁâáÈÉΩÊúâ‰∫îÂÄãÂïèÈ°åÂú®‰∏çÂêåÁöÑÊôÇÈñìÈªûÊèêÂá∫Ôºå‰ª•Ê®°Êì¨ÈÄ£Á∫å‰∏≤ÊµÅÂ†¥ÊôØ„ÄÇÊàëÂÄë‰ΩøÁî® 13 ÂÄãÈñãÊ∫êÂíåÂ∞àÊúâ MLLM Â∞ç StreamingBench ÈÄ≤Ë°åÂØ¶È©óÔºåÁôºÁèæÂç≥‰ΩøÊòØÊúÄÂÖàÈÄ≤ÁöÑÂ∞àÊúâ MLLMÔºåÂ¶Ç Gemini 1.5 Pro Âíå GPT-4oÔºåÂú®‰∏≤ÊµÅÂΩ±ÁâáÁêÜËß£ËÉΩÂäõÊñπÈù¢‰πüÈ°ØËëó‰ΩéÊñº‰∫∫È°ûÊ∞¥Ê∫ñ„ÄÇÊàëÂÄëÂ∏åÊúõÊàëÂÄëÁöÑÁ†îÁ©∂ËÉΩ‰øÉÈÄ≤ MLLM ÁöÑÈÄ≤‰∏ÄÊ≠•ÁôºÂ±ïÔºåËÆìÂÆÉÂÄëËÉΩÂ§†Âú®Êõ¥ÈÄºÁúüÁöÑÂ†¥ÊôØ‰∏≠Êé•Ëøë‰∫∫È°ûÊ∞¥Ê∫ñÁöÑÂΩ±ÁâáÁêÜËß£Âíå‰∫íÂãï„ÄÇ

##### **Fully Hyperbolic Rotation for Knowledge Graph Embedding**
2411.03622v1 by Qiuyu Liang, Weihua Wang, Feilong Bao, Guanglai Gao

Hyperbolic rotation is commonly used to effectively model knowledge graphs
and their inherent hierarchies. However, existing hyperbolic rotation models
rely on logarithmic and exponential mappings for feature transformation. These
models only project data features into hyperbolic space for rotation, limiting
their ability to fully exploit the hyperbolic space. To address this problem,
we propose a novel fully hyperbolic model designed for knowledge graph
embedding. Instead of feature mappings, we define the model directly in
hyperbolic space with the Lorentz model. Our model considers each relation in
knowledge graphs as a Lorentz rotation from the head entity to the tail entity.
We adopt the Lorentzian version distance as the scoring function for measuring
the plausibility of triplets. Extensive results on standard knowledge graph
completion benchmarks demonstrated that our model achieves competitive results
with fewer parameters. In addition, our model get the state-of-the-art
performance on datasets of CoDEx-s and CoDEx-m, which are more diverse and
challenging than before. Our code is available at
https://github.com/llqy123/FHRE.

ÊëòË¶ÅÔºöÈõôÊõ≤ÊóãËΩâÈÄöÂ∏∏Áî®ÊñºÊúâÊïàÂª∫Ê®°Áü•Ë≠òÂúñË≠úÂèäÂÖ∂ÂÖßÂú®Â±§Á¥öÁµêÊßã„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÈõôÊõ≤ÊóãËΩâÊ®°Âûã‰æùË≥¥ÊñºÂ∞çÊï∏ÂíåÊåáÊï∏Êò†Â∞Ñ‰æÜÈÄ≤Ë°åÁâπÂæµËΩâÊèõ„ÄÇÈÄô‰∫õÊ®°ÂûãÂÉÖÂ∞áÊï∏ÊìöÁâπÂæµÊäïÂΩ±Âà∞ÈõôÊõ≤Á©∫Èñì‰∏≠ÈÄ≤Ë°åÊóãËΩâÔºåÈôêÂà∂‰∫ÜÂÆÉÂÄëÂÖÖÂàÜÂà©Áî®ÈõôÊõ≤Á©∫ÈñìÁöÑËÉΩÂäõ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂÆåÂÖ®ÈõôÊõ≤Ê®°ÂûãÔºåÂ∞àÈñÄÁî®ÊñºÁü•Ë≠òÂúñË≠úÂµåÂÖ•„ÄÇÊàëÂÄëÊ≤íÊúâ‰ΩøÁî®ÁâπÂæµÊò†Â∞ÑÔºåËÄåÊòØÁõ¥Êé•Âú®ÈõôÊõ≤Á©∫Èñì‰∏≠‰ΩøÁî®Ê¥õÂÄ´Ëå≤Ê®°ÂûãÂÆöÁæ©Ê®°Âûã„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂ∞áÁü•Ë≠òÂúñË≠ú‰∏≠ÁöÑÊØèÂÄãÈóú‰øÇË¶ñÁÇ∫ÂæûÈ†≠ÂØ¶È´îÂà∞Â∞æÂØ¶È´îÁöÑÊ¥õÂÄ´Ëå≤ÊóãËΩâ„ÄÇÊàëÂÄëÊé°Áî®Ê¥õÂÄ´Ëå≤Ë∑ùÈõ¢ÁâàÊú¨‰ΩúÁÇ∫Ë©ïÂàÜÂáΩÊï∏ÔºåÁî®ÊñºÊ∏¨Èáè‰∏âÂÖÉÁµÑÁöÑÂèØ‰ø°Â∫¶„ÄÇÂú®Ê®ôÊ∫ñÁü•Ë≠òÂúñË≠úÂÆåÊàêÂü∫Ê∫ñ‰∏äÁöÑÂ§ßÈáèÁµêÊûúË°®ÊòéÔºåÊàëÂÄëÁöÑÊ®°Âûã‰ª•Êõ¥Â∞ëÁöÑÂèÉÊï∏ÂØ¶Áèæ‰∫ÜÊúâÁ´∂Áà≠ÂäõÁöÑÁµêÊûú„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂú® CoDEx-s Âíå CoDEx-m ÁöÑÊï∏ÊìöÈõÜ‰∏äÂèñÂæó‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊÄßËÉΩÔºåÈÄô‰∫õÊï∏ÊìöÈõÜÊØî‰ª•ÂâçÊõ¥Âä†Â§öÊ®£Âåñ‰∏îÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÊàëÂÄëÁöÑ‰ª£Á¢ºÂèØÂú® https://github.com/llqy123/FHRE Áç≤Âæó„ÄÇ

##### **Cross Feature Fusion of Fundus Image and Generated Lesion Map for Referable Diabetic Retinopathy Classification**
2411.03618v1 by Dahyun Mok, Junghyun Bum, Le Duc Tai, Hyunseung Choo

Diabetic Retinopathy (DR) is a primary cause of blindness, necessitating
early detection and diagnosis. This paper focuses on referable DR
classification to enhance the applicability of the proposed method in clinical
practice. We develop an advanced cross-learning DR classification method
leveraging transfer learning and cross-attention mechanisms. The proposed
method employs the Swin U-Net architecture to segment lesion maps from DR
fundus images. The Swin U-Net segmentation model, enriched with DR lesion
insights, is transferred to generate a lesion map. Both the fundus image and
its segmented lesion map are used as complementary inputs for the
classification model. A cross-attention mechanism is deployed to improve the
model's ability to capture fine-grained details from the input pairs. Our
experiments, utilizing two public datasets, FGADR and EyePACS, demonstrate a
superior accuracy of 94.6%, surpassing current state-of-the-art methods by
4.4%. To this end, we aim for the proposed method to be seamlessly integrated
into clinical workflows, enhancing accuracy and efficiency in identifying
referable DR.

ÊëòË¶ÅÔºöÁ≥ñÂ∞øÁóÖË¶ñÁ∂≤ËÜúÁóÖËÆä (DR) ÊòØÂ§±ÊòéÁöÑÈ¶ñË¶ÅÂéüÂõ†ÔºåÈúÄË¶ÅÊó©ÊúüÊ™¢Ê∏¨ÂíåË®∫Êñ∑„ÄÇÊú¨ÊñáÈáçÈªûÈóúÊ≥®ÂèØËΩâË®∫ÁöÑ DR ÂàÜÈ°ûÔºå‰ª•Â¢ûÂº∑ÊâÄÊèêÂá∫ÊñπÊ≥ïÂú®Ëá®Â∫äÂØ¶Âãô‰∏≠ÁöÑÈÅ©Áî®ÊÄß„ÄÇÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÂÖàÈÄ≤ÁöÑ‰∫§ÂèâÂ≠∏Áøí DR ÂàÜÈ°ûÊñπÊ≥ïÔºåÂà©Áî®ÈÅ∑ÁßªÂ≠∏ÁøíÂíå‰∫§ÂèâÊ≥®ÊÑèÊ©üÂà∂„ÄÇÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÊé°Áî® Swin U-Net Êû∂ÊßãÔºåÂæû DR ÁúºÂ∫ïÂúñÂÉè‰∏≠ÂàÜÂâ≤ÁóÖÁÅ∂Âúñ„ÄÇË±êÂØå‰∫Ü DR ÁóÖÁÅ∂Ë¶ãËß£ÁöÑ Swin U-Net ÂàÜÂâ≤Ê®°ÂûãË¢´ËΩâÁßª‰ª•ÁîüÊàêÁóÖÁÅ∂Âúñ„ÄÇÁúºÂ∫ïÂúñÂÉèÂèäÂÖ∂ÂàÜÂâ≤ÁöÑÁóÖÁÅ∂ÂúñÈÉΩË¢´Áî®‰ΩúÂàÜÈ°ûÊ®°ÂûãÁöÑË£úÂÖÖËº∏ÂÖ•„ÄÇÈÉ®ÁΩ≤‰∫§ÂèâÊ≥®ÊÑèÊ©üÂà∂‰ª•ÊèêÈ´òÊ®°ÂûãÂæûËº∏ÂÖ•Â∞ç‰∏≠Êì∑ÂèñÁ¥∞Á≤íÂ∫¶Á¥∞ÁØÄÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÂà©Áî®‰∫ÜÂÖ©ÂÄãÂÖ¨ÈñãÊï∏ÊìöÈõÜÔºåFGADR Âíå EyePACSÔºåÂ±ïÁ§∫‰∫Ü 94.6% ÁöÑÂÑ™Áï∞Ê∫ñÁ¢∫ÁéáÔºåÊØîÁï∂ÂâçÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÈ´òÂá∫ 4.4%„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂ∏åÊúõÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïËÉΩÁÑ°Á∏´Êï¥ÂêàÂà∞Ëá®Â∫äÂ∑•‰ΩúÊµÅÁ®ã‰∏≠ÔºåÊèêÈ´òÊ∫ñÁ¢∫Â∫¶ÂíåÊïàÁéáÔºå‰ª•Ë≠òÂà•ÂèØËΩâË®∫ÁöÑ DR„ÄÇ

##### **From Medprompt to o1: Exploration of Run-Time Strategies for Medical Challenge Problems and Beyond**
2411.03590v1 by Harsha Nori, Naoto Usuyama, Nicholas King, Scott Mayer McKinney, Xavier Fernandes, Sheng Zhang, Eric Horvitz

Run-time steering strategies like Medprompt are valuable for guiding large
language models (LLMs) to top performance on challenging tasks. Medprompt
demonstrates that a general LLM can be focused to deliver state-of-the-art
performance on specialized domains like medicine by using a prompt to elicit a
run-time strategy involving chain of thought reasoning and ensembling. OpenAI's
o1-preview model represents a new paradigm, where a model is designed to do
run-time reasoning before generating final responses. We seek to understand the
behavior of o1-preview on a diverse set of medical challenge problem
benchmarks. Following on the Medprompt study with GPT-4, we systematically
evaluate the o1-preview model across various medical benchmarks. Notably, even
without prompting techniques, o1-preview largely outperforms the GPT-4 series
with Medprompt. We further systematically study the efficacy of classic prompt
engineering strategies, as represented by Medprompt, within the new paradigm of
reasoning models. We found that few-shot prompting hinders o1's performance,
suggesting that in-context learning may no longer be an effective steering
approach for reasoning-native models. While ensembling remains viable, it is
resource-intensive and requires careful cost-performance optimization. Our cost
and accuracy analysis across run-time strategies reveals a Pareto frontier,
with GPT-4o representing a more affordable option and o1-preview achieving
state-of-the-art performance at higher cost. Although o1-preview offers top
performance, GPT-4o with steering strategies like Medprompt retains value in
specific contexts. Moreover, we note that the o1-preview model has reached
near-saturation on many existing medical benchmarks, underscoring the need for
new, challenging benchmarks. We close with reflections on general directions
for inference-time computation with LLMs.

ÊëòË¶ÅÔºö<paragraph>Medprompt Á≠âËøêË°åÊó∂ÂØºÂºïÁ≠ñÁï•ÂØπ‰∫éÂºïÂØºÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã (LLM) Âú®ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑ‰ªªÂä°‰∏≠ËææÂà∞ÊúÄ‰Ω≥ÊÄßËÉΩÂæàÊúâ‰ª∑ÂÄº„ÄÇMedprompt ËØÅÊòéÔºåÂèØ‰ª•ÈÄöËøá‰ΩøÁî®ÊèêÁ§∫Êù•ÂºïÂèëÊ∂âÂèäÊÄùÁª¥ÈìæÊé®ÁêÜÂíåÈõÜÊàêËøêË°åÊó∂Á≠ñÁï•ÔºåÂ∞ÜÈÄöÁî® LLM ÈõÜ‰∏≠Ëµ∑Êù•Ôºå‰ª•Âú®ÂåªÂ≠¶Á≠â‰∏ì‰∏öÈ¢ÜÂüüÊèê‰æõÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇOpenAI ÁöÑ o1-preview Ê®°Âûã‰ª£Ë°®‰∫Ü‰∏ÄÁßçÊñ∞ËåÉ‰æãÔºåÂÖ∂‰∏≠Ê®°ÂûãË¢´ËÆæËÆ°‰∏∫Âú®ÁîüÊàêÊúÄÁªàÂìçÂ∫î‰πãÂâçËøõË°åËøêË°åÊó∂Êé®ÁêÜ„ÄÇÊàë‰ª¨ÂØªÊ±Ç‰∫ÜËß£ o1-preview Âú®ÂêÑÁßçÂåªÂ≠¶ÊåëÊàòÈóÆÈ¢òÂü∫ÂáÜ‰∏äÁöÑË°å‰∏∫„ÄÇÂú®‰ΩøÁî® GPT-4 ËøõË°å Medprompt Á†îÁ©∂ÂêéÔºåÊàë‰ª¨Á≥ªÁªüÂú∞ËØÑ‰º∞‰∫Ü o1-preview Ê®°ÂûãÂú®ÂêÑÁßçÂåªÂ≠¶Âü∫ÂáÜ‰∏äÁöÑË°®Áé∞„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂç≥‰ΩøÊ≤°ÊúâÊèêÁ§∫ÊäÄÊúØÔºåo1-preview Âú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰πü‰ºò‰∫éÂ∏¶Êúâ Medprompt ÁöÑ GPT-4 Á≥ªÂàó„ÄÇÊàë‰ª¨Ëøõ‰∏ÄÊ≠•Á≥ªÁªüÂú∞Á†îÁ©∂‰∫ÜÁªèÂÖ∏ÊèêÁ§∫Â∑•Á®ãÁ≠ñÁï•Ôºà‰ª• Medprompt ‰∏∫‰ª£Ë°®ÔºâÂú®Êñ∞ËåÉ‰æãÊé®ÁêÜÊ®°Âûã‰∏≠ÁöÑÂäüÊïà„ÄÇÊàë‰ª¨ÂèëÁé∞ÔºåÂ∞ëÈáèÊèêÁ§∫ÈòªÁ¢ç‰∫Ü o1 ÁöÑÊÄßËÉΩÔºåËøôË°®Êòé‰∏ä‰∏ãÊñáÂ≠¶‰π†ÂèØËÉΩ‰∏çÂÜçÊòØÊé®ÁêÜÂéüÁîüÊ®°ÂûãÁöÑÊúâÊïàÂØºÂêëÊñπÊ≥ï„ÄÇËôΩÁÑ∂ÈõÜÊàê‰ªçÁÑ∂ÂèØË°åÔºå‰ΩÜÂÆÉÈúÄË¶ÅÂ§ßÈáèËµÑÊ∫êÔºåÂπ∂‰∏îÈúÄË¶Å‰ªîÁªÜËøõË°åÊàêÊú¨ÊÄßËÉΩ‰ºòÂåñ„ÄÇÊàë‰ª¨ÂØπËøêË°åÊó∂Á≠ñÁï•ÁöÑÊàêÊú¨ÂíåÂáÜÁ°ÆÊÄßÂàÜÊûêÊè≠Á§∫‰∫ÜÂ∏ïÁ¥ØÊâòÂâçÊ≤øÔºåÂÖ∂‰∏≠ GPT-4o ‰ª£Ë°®‰∫Ü‰∏Ä‰∏™Êõ¥ÂÆûÊÉ†ÁöÑÈÄâÊã©ÔºåËÄå o1-preview ‰ª•Êõ¥È´òÁöÑÊàêÊú¨ÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇËôΩÁÑ∂ o1-preview Êèê‰æõ‰∫ÜÈ°∂Á∫ßÊÄßËÉΩÔºå‰ΩÜÈááÁî® Medprompt Á≠âÂØºÂêëÁ≠ñÁï•ÁöÑ GPT-4o Âú®ÁâπÂÆöÊÉÖÂÜµ‰∏ã‰ªçÂÖ∑Êúâ‰ª∑ÂÄº„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨Ê≥®ÊÑèÂà∞ o1-preview Ê®°ÂûãÂú®ËÆ∏Â§öÁé∞ÊúâÁöÑÂåªÂ≠¶Âü∫ÂáÜ‰∏äÂ∑≤Êé•ËøëÈ•±ÂíåÔºåËøôÂº∫Ë∞É‰∫ÜÂØπÊñ∞ÁöÑ„ÄÅÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÂü∫ÂáÜÁöÑÈúÄÊ±Ç„ÄÇÊàë‰ª¨‰ª•ÂØπ‰ΩøÁî® LLM ËøõË°åÊé®ÁêÜÊó∂Èó¥ËÆ°ÁÆóÁöÑ‰∏ÄËà¨ÊñπÂêëÁöÑÊÄùËÄÉ‰Ωú‰∏∫ÁªìÊùü„ÄÇ</paragraph>

##### **An Experimental Study on Decomposition-Based Deep Ensemble Learning for Traffic Flow Forecasting**
2411.03588v1 by Qiyuan Zhu, A. K. Qin, Hussein Dia, Adriana-Simona Mihaita, Hanna Grzybowska

Traffic flow forecasting is a crucial task in intelligent transport systems.
Deep learning offers an effective solution, capturing complex patterns in
time-series traffic flow data to enable the accurate prediction. However, deep
learning models are prone to overfitting the intricate details of flow data,
leading to poor generalisation. Recent studies suggest that decomposition-based
deep ensemble learning methods may address this issue by breaking down a time
series into multiple simpler signals, upon which deep learning models are built
and ensembled to generate the final prediction. However, few studies have
compared the performance of decomposition-based ensemble methods with
non-decomposition-based ones which directly utilise raw time-series data. This
work compares several decomposition-based and non-decomposition-based deep
ensemble learning methods. Experimental results on three traffic datasets
demonstrate the superiority of decomposition-based ensemble methods, while also
revealing their sensitivity to aggregation strategies and forecasting horizons.

ÊëòË¶ÅÔºö‰∫§ÈÄöÊµÅÈáèÈ†êÊ∏¨ÊòØÊô∫ÊÖßÈÅãËº∏Á≥ªÁµ±‰∏≠ÁöÑ‰∏ÄÈ†ÖÈáçË¶Å‰ªªÂãô„ÄÇ
Ê∑±Â∫¶Â≠∏ÁøíÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊúâÊïàÁöÑËß£Ê±∫ÊñπÊ°àÔºåÊçïÊçâÊôÇÂ∫è‰∫§ÈÄöÊµÅÈáèË≥áÊñô‰∏≠ÁöÑË§áÈõúÊ®°ÂºèÔºå‰ª•ÂØ¶ÁèæÊ∫ñÁ¢∫È†êÊ∏¨„ÄÇÁÑ∂ËÄåÔºåÊ∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂÆπÊòìÈÅéÂ∫¶Êì¨ÂêàÊµÅÈáèË≥áÊñôÁöÑË§áÈõúÁ¥∞ÁØÄÔºåÂ∞éËá¥Ê≥õÂåñËÉΩÂäõ‰∏ç‰Ω≥„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÂü∫ÊñºÂàÜËß£ÁöÑÊ∑±Â∫¶ÈõÜÊàêÂ≠∏ÁøíÊñπÊ≥ïÂèØ‰ª•ÈÄöÈÅéÂ∞áÊôÇÂ∫èÂàÜËß£ÁÇ∫Â§öÂÄãËºÉÁ∞°ÂñÆÁöÑ‰ø°Ëôü‰æÜËß£Ê±∫Ê≠§ÂïèÈ°åÔºåÁÑ∂ÂæåÂª∫Á´ãÊ∑±Â∫¶Â≠∏ÁøíÊ®°Âûã‰∏¶ÈõÜÊàêÂÆÉÂÄë‰ª•Áî¢ÁîüÊúÄÁµÇÈ†êÊ∏¨„ÄÇÁÑ∂ËÄåÔºåÂæàÂ∞ëÊúâÁ†îÁ©∂ÊØîËºÉÂü∫ÊñºÂàÜËß£ÁöÑÈõÜÊàêÊñπÊ≥ïËàáÁõ¥Êé•Âà©Áî®ÂéüÂßãÊôÇÂ∫èË≥áÊñôÁöÑÈùûÂü∫ÊñºÂàÜËß£ÊñπÊ≥ïÁöÑÊïàËÉΩ„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊØîËºÉ‰∫ÜÂπæÁ®ÆÂü∫ÊñºÂàÜËß£ÂíåÈùûÂü∫ÊñºÂàÜËß£ÁöÑÊ∑±Â∫¶ÈõÜÊàêÂ≠∏ÁøíÊñπÊ≥ï„ÄÇÂú®‰∏âÂÄã‰∫§ÈÄöË≥áÊñôÈõÜ‰∏äÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé‰∫ÜÂü∫ÊñºÂàÜËß£ÁöÑÈõÜÊàêÊñπÊ≥ïÁöÑÂÑ™Ë∂äÊÄßÔºåÂêåÊôÇ‰πüÊè≠Á§∫‰∫ÜÂÆÉÂÄëÂ∞çËÅöÂêàÁ≠ñÁï•ÂíåÈ†êÊ∏¨ÁØÑÂúçÁöÑÊïèÊÑüÊÄß„ÄÇ

##### **Towards Personalized Federated Learning via Comprehensive Knowledge Distillation**
2411.03569v1 by Pengju Wang, Bochao Liu, Weijia Guo, Yong Li, Shiming Ge

Federated learning is a distributed machine learning paradigm designed to
protect data privacy. However, data heterogeneity across various clients
results in catastrophic forgetting, where the model rapidly forgets previous
knowledge while acquiring new knowledge. To address this challenge,
personalized federated learning has emerged to customize a personalized model
for each client. However, the inherent limitation of this mechanism is its
excessive focus on personalization, potentially hindering the generalization of
those models. In this paper, we present a novel personalized federated learning
method that uses global and historical models as teachers and the local model
as the student to facilitate comprehensive knowledge distillation. The
historical model represents the local model from the last round of client
training, containing historical personalized knowledge, while the global model
represents the aggregated model from the last round of server aggregation,
containing global generalized knowledge. By applying knowledge distillation, we
effectively transfer global generalized knowledge and historical personalized
knowledge to the local model, thus mitigating catastrophic forgetting and
enhancing the general performance of personalized models. Extensive
experimental results demonstrate the significant advantages of our method.

ÊëòË¶ÅÔºöËÅØÈÇ¶Â≠∏ÁøíÊòØ‰∏ÄÁ®ÆÂàÜÊï£ÂºèÊ©üÂô®Â≠∏ÁøíÁØÑ‰æãÔºåÊó®Âú®‰øùË≠∑Ë≥áÊñôÈö±ÁßÅ„ÄÇÁÑ∂ËÄåÔºå‰∏çÂêåÁî®Êà∂Á´Ø‰πãÈñìÁöÑË≥áÊñôÁï∞Ë≥™ÊÄßÊúÉÂ∞éËá¥ÁÅΩÈõ£ÊÄßÈÅ∫ÂøòÔºåÊ®°ÂûãÂú®Áç≤ÂèñÊñ∞Áü•Ë≠òÁöÑÂêåÊôÇÊúÉËøÖÈÄüÈÅ∫ÂøòÂÖàÂâçÁöÑÁü•Ë≠ò„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∏ÄÊåëÊà∞ÔºåÂÄãÊÄßÂåñËÅØÈÇ¶Â≠∏ÁøíÊáâÈÅãËÄåÁîüÔºåÁÇ∫ÊØèÂÄãÁî®Êà∂Á´ØËá™Ë®ÇÂÄãÊÄßÂåñÊ®°Âûã„ÄÇÁÑ∂ËÄåÔºåÈÄôÁ®ÆÊ©üÂà∂ÁöÑÂõ∫ÊúâÈôêÂà∂Âú®ÊñºÈÅéÂ∫¶ÈáçË¶ñÂÄãÊÄßÂåñÔºåÂèØËÉΩÊúÉÈòªÁ§ôÈÄô‰∫õÊ®°ÂûãÁöÑÊ≥õÂåñ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂÄãÊÄßÂåñËÅØÈÇ¶Â≠∏ÁøíÊñπÊ≥ïÔºåÂÆÉ‰ΩøÁî®ÂÖ®Â±ÄÊ®°ÂûãÂíåÊ≠∑Âè≤Ê®°Âûã‰ΩúÁÇ∫ÊïôÂ∏´Ôºå‰∏¶Â∞áÊú¨Âú∞Ê®°Âûã‰ΩúÁÇ∫Â≠∏ÁîüÔºå‰ª•‰øÉÈÄ≤ÂÖ®Èù¢ÁöÑÁü•Ë≠òËí∏È§æ„ÄÇÊ≠∑Âè≤Ê®°ÂûãË°®Á§∫‰æÜËá™‰∏äÊ¨°Áî®Êà∂Á´ØË®ìÁ∑¥ÁöÑÊú¨Âú∞Ê®°ÂûãÔºåÂåÖÂê´Ê≠∑Âè≤ÂÄãÊÄßÂåñÁü•Ë≠òÔºåËÄåÂÖ®Â±ÄÊ®°ÂûãË°®Á§∫‰æÜËá™‰∏äÊ¨°‰º∫ÊúçÂô®ËÅöÂêàÁöÑËÅöÂêàÊ®°ÂûãÔºåÂåÖÂê´ÂÖ®Â±ÄÊ¶ÇÂåñÁü•Ë≠ò„ÄÇÈÄöÈÅéÊáâÁî®Áü•Ë≠òËí∏È§æÔºåÊàëÂÄëÊúâÊïàÂú∞Â∞áÂÖ®Â±ÄÊ¶ÇÂåñÁü•Ë≠òÂíåÊ≠∑Âè≤ÂÄãÊÄßÂåñÁü•Ë≠òÂÇ≥ÈÅûÂà∞Êú¨Âú∞Ê®°ÂûãÔºåÂæûËÄåÊ∏õËºïÁÅΩÈõ£ÊÄßÈÅ∫Âøò‰∏¶Â¢ûÂº∑ÂÄãÊÄßÂåñÊ®°ÂûãÁöÑÊï¥È´îÊïàËÉΩ„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÈ°ØËëóÂÑ™Âã¢„ÄÇ

##### **The American Sign Language Knowledge Graph: Infusing ASL Models with Linguistic Knowledge**
2411.03568v1 by Lee Kezar, Nidhi Munikote, Zian Zeng, Zed Sehyr, Naomi Caselli, Jesse Thomason

Language models for American Sign Language (ASL) could make language
technologies substantially more accessible to those who sign. To train models
on tasks such as isolated sign recognition (ISR) and ASL-to-English
translation, datasets provide annotated video examples of ASL signs. To
facilitate the generalizability and explainability of these models, we
introduce the American Sign Language Knowledge Graph (ASLKG), compiled from
twelve sources of expert linguistic knowledge. We use the ASLKG to train
neuro-symbolic models for 3 ASL understanding tasks, achieving accuracies of
91% on ISR, 14% for predicting the semantic features of unseen signs, and 36%
for classifying the topic of Youtube-ASL videos.

ÊëòË¶ÅÔºöÁæéÂúãÊâãË™û (ASL) ÁöÑË™ûË®ÄÊ®°ÂûãÂèØ‰ª•ËÆìË™ûË®ÄÊäÄË°ìÂ∞çÊâãË™û‰ΩøÁî®ËÄÖÊõ¥ÊòìÊñº‰ΩøÁî®„ÄÇÁÇ∫‰∫ÜË®ìÁ∑¥Ê®°ÂûãÂü∑Ë°åÊâãË™ûËæ®Ë≠ò (ISR) Âíå ASL ËΩâÊèõÊàêËã±ÊñáÁ≠â‰ªªÂãôÔºåË≥áÊñôÈõÜÊèê‰æõ ASL ÊâãÂã¢ÁöÑË®ªËß£ÂΩ±ÁâáÁØÑ‰æã„ÄÇÁÇ∫‰∫Ü‰øÉÈÄ≤ÈÄô‰∫õÊ®°ÂûãÁöÑÊ¶ÇÊã¨ÊÄßÂíåÂèØËß£ÈáãÊÄßÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÁæéÂúãÊâãË™ûÁü•Ë≠òÂúñË≠ú (ASLKG)ÔºåÂÆÉÊòØÁî±ÂçÅ‰∫åÂÄãÂ∞àÂÆ∂Ë™ûË®ÄÁü•Ë≠ò‰æÜÊ∫êÁ∑®Ë≠ØËÄåÊàêÁöÑ„ÄÇÊàëÂÄë‰ΩøÁî® ASLKG Ë®ìÁ∑¥Á•ûÁ∂ìÁ¨¶ËôüÊ®°Âûã‰æÜÂü∑Ë°å 3 È†Ö ASL ÁêÜËß£‰ªªÂãôÔºåÂú® ISR ‰∏äÈÅîÂà∞ 91% ÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÅÂú®È†êÊ∏¨Êú™Ë¶ãÊâãÂã¢ÁöÑË™ûÁæ©ÁâπÂæµ‰∏äÈÅîÂà∞ 14%Ôºå‰ª•ÂèäÂú®ÂàÜÈ°û YouTube-ASL ÂΩ±Áâá‰∏ªÈ°å‰∏äÈÅîÂà∞ 36%„ÄÇ

##### **Large Language Models Orchestrating Structured Reasoning Achieve Kaggle Grandmaster Level**
2411.03562v1 by Antoine Grosnit, Alexandre Maraval, James Doran, Giuseppe Paolo, Albert Thomas, Refinath Shahul Hameed Nabeezath Beevi, Jonas Gonzalez, Khyati Khandelwal, Ignacio Iacobacci, Abdelhakim Benechehab, Hamza Cherkaoui, Youssef Attia El-Hili, Kun Shao, Jianye Hao, Jun Yao, Balazs Kegl, Haitham Bou-Ammar, Jun Wang

We introduce Agent K v1.0, an end-to-end autonomous data science agent
designed to automate, optimise, and generalise across diverse data science
tasks. Fully automated, Agent K v1.0 manages the entire data science life cycle
by learning from experience. It leverages a highly flexible structured
reasoning framework to enable it to dynamically process memory in a nested
structure, effectively learning from accumulated experience stored to handle
complex reasoning tasks. It optimises long- and short-term memory by
selectively storing and retrieving key information, guiding future decisions
based on environmental rewards. This iterative approach allows it to refine
decisions without fine-tuning or backpropagation, achieving continuous
improvement through experiential learning. We evaluate our agent's apabilities
using Kaggle competitions as a case study. Following a fully automated
protocol, Agent K v1.0 systematically addresses complex and multimodal data
science tasks, employing Bayesian optimisation for hyperparameter tuning and
feature engineering. Our new evaluation framework rigorously assesses Agent K
v1.0's end-to-end capabilities to generate and send submissions starting from a
Kaggle competition URL. Results demonstrate that Agent K v1.0 achieves a 92.5\%
success rate across tasks, spanning tabular, computer vision, NLP, and
multimodal domains. When benchmarking against 5,856 human Kaggle competitors by
calculating Elo-MMR scores for each, Agent K v1.0 ranks in the top 38\%,
demonstrating an overall skill level comparable to Expert-level users. Notably,
its Elo-MMR score falls between the first and third quartiles of scores
achieved by human Grandmasters. Furthermore, our results indicate that Agent K
v1.0 has reached a performance level equivalent to Kaggle Grandmaster, with a
record of 6 gold, 3 silver, and 7 bronze medals, as defined by Kaggle's
progression system.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÊé®Âá∫ Agent K v1.0Ôºå‰∏ÄÂÄãÁ´ØÂà∞Á´ØÁöÑËá™‰∏ªË≥áÊñôÁßëÂ≠∏‰ª£ÁêÜÁ®ãÂºèÔºå
Êó®Âú®Ëá™ÂãïÂåñ„ÄÅÊúÄ‰Ω≥ÂåñÔºå‰∏¶Ê¶ÇÊã¨ÂêÑÁ®ÆË≥áÊñôÁßëÂ≠∏‰ªªÂãô„ÄÇAgent K v1.0 ÂÖ®Ëá™ÂãïÂåñÁÆ°ÁêÜÊï¥ÂÄãË≥áÊñôÁßëÂ≠∏ÁîüÂëΩÈÄ±ÊúüÔºå
ÈÄèÈÅéÂæûÁ∂ìÈ©ó‰∏≠Â≠∏Áøí„ÄÇÂÆÉÂà©Áî®È´òÂ∫¶ÈùàÊ¥ªÁöÑÁµêÊßãÂåñÊé®ÁêÜÊ°ÜÊû∂Ôºå‰ΩøÂÖ∂ËÉΩÂ§†ÂãïÊÖãËôïÁêÜÂ∑¢ÁãÄÁµêÊßã‰∏≠ÁöÑË®òÊÜ∂È´îÔºåÊúâÊïàÂú∞ÂæûÂÑ≤Â≠òÁöÑÁ¥ØÁ©çÁ∂ìÈ©ó‰∏≠Â≠∏ÁøíÔºå‰ª•ËôïÁêÜË§áÈõúÁöÑÊé®ÁêÜ‰ªªÂãô„ÄÇÂÆÉÈÄèÈÅéÈÅ∏ÊìáÊÄßÂÑ≤Â≠òÂíåÊì∑ÂèñÈóúÈçµË≥áË®äÔºåÊúÄ‰Ω≥ÂåñÈï∑ÊúüÂíåÁü≠ÊúüË®òÊÜ∂È´îÔºåÊ†πÊìöÁí∞Â¢ÉÁçéÂãµÂºïÂ∞éÊú™‰æÜÁöÑÊ±∫Á≠ñ„ÄÇÈÄôÁ®ÆËø≠‰ª£ÊñπÊ≥ïÂÖÅË®±ÂÆÉÂú®‰∏çÈÄ≤Ë°åÂæÆË™øÊàñÂèçÂêëÂÇ≥Êí≠ÁöÑÊÉÖÊ≥Å‰∏ãÊîπÂñÑÊ±∫Á≠ñÔºåÈÄèÈÅéÈ´îÈ©óÂºèÂ≠∏ÁøíÂØ¶ÁèæÊåÅÁ∫åÊîπÈÄ≤„ÄÇÊàëÂÄë‰ΩøÁî® Kaggle Á´∂Ë≥Ω‰ΩúÁÇ∫Ê°à‰æãÁ†îÁ©∂ÔºåË©ï‰º∞ÊàëÂÄë‰ª£ÁêÜÁ®ãÂºèÁöÑÂäüËÉΩ„ÄÇÈÅµÂæ™ÂÖ®Ëá™ÂãïÂåñÂçîÂÆöÔºåAgent K v1.0 Á≥ªÁµ±ÊÄßÂú∞ËôïÁêÜË§áÈõú‰∏îÂ§öÊ®°ÊÖãÁöÑË≥áÊñôÁßëÂ≠∏‰ªªÂãôÔºåÊé°Áî®Ë≤ùÊ∞èÊúÄ‰Ω≥ÂåñÈÄ≤Ë°åË∂ÖÂèÉÊï∏Ë™øÊï¥ÂíåÁâπÂæµÂ∑•Á®ã„ÄÇÊàëÂÄëÊñ∞ÁöÑË©ï‰º∞Ê°ÜÊû∂Âö¥Ê†ºË©ï‰º∞ Agent K v1.0 ÁöÑÁ´ØÂà∞Á´ØÂäüËÉΩÔºåÂæû Kaggle Á´∂Ë≥Ω URL ÈñãÂßãÁî¢Áîü‰∏¶ÁôºÈÄÅÊèê‰∫§„ÄÇÁµêÊûúË°®ÊòéÔºåAgent K v1.0 Âú®ÂêÑÈ†Ö‰ªªÂãô‰∏≠ÂØ¶Áèæ‰∫Ü 92.5% ÁöÑÊàêÂäüÁéáÔºåÊ∂µËìãË°®Ê†º„ÄÅÈõªËÖ¶Ë¶ñË¶∫„ÄÅNLP ÂíåÂ§öÊ®°ÊÖãÈ†òÂüü„ÄÇÈÄèÈÅéË®àÁÆóÊØèÂÄã‰∫∫ÁöÑ Elo-MMR ÂàÜÊï∏ÔºåÂú®Ëàá 5,856 Âêç‰∫∫È°û Kaggle Á´∂Áà≠ËÄÖÈÄ≤Ë°åÂü∫Ê∫ñÊØîËºÉÊôÇÔºåAgent K v1.0 ÊéíÂêçÂâç 38%ÔºåË°®ÁèæÂá∫ËàáÂ∞àÂÆ∂Á¥ö‰ΩøÁî®ËÄÖÁõ∏Áï∂ÁöÑÊï¥È´îÊäÄËÉΩÊ∞¥Ê∫ñ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂÆÉÁöÑ Elo-MMR ÂàÜÊï∏‰ªãÊñº‰∫∫È°ûÂ§ßÂ∏´ÊâÄÁç≤ÂæóÂàÜÊï∏ÁöÑÁ¨¨‰∏ÄÂíåÁ¨¨‰∏âÂÄãÂõõÂàÜ‰ΩçÊï∏‰πãÈñì„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåAgent K v1.0 Â∑≤ÈÅîÂà∞Ëàá Kaggle Â§ßÂ∏´ÂêåÁ≠âÁöÑÊïàËÉΩÊ∞¥Ê∫ñÔºåÊ†πÊìö Kaggle ÁöÑÈÄ≤Â∫¶Á≥ªÁµ±ÂÆöÁæ©ÔºåÊìÅÊúâ 6 Èù¢ÈáëÁâå„ÄÅ3 Èù¢ÈäÄÁâåÂíå 7 Èù¢ÈäÖÁâåÁöÑÁ¥ÄÈåÑ„ÄÇ</paragraph>

##### **Learning to Write Rationally: How Information Is Distributed in Non-Native Speakers' Essays**
2411.03550v1 by Zixin Tang, Janet G. van Hell

People tend to distribute information evenly in language production for
better and clearer communication. In this study, we compared essays written by
second language learners with various native language (L1) backgrounds to
investigate how they distribute information in their non-native language (L2)
production. Analyses of surprisal and constancy of entropy rate indicated that
writers with higher L2 proficiency can reduce the expected uncertainty of
language production while still conveying informative content. However, the
uniformity of information distribution showed less variability among different
groups of L2 speakers, suggesting that this feature may be universal in L2
essay writing and less affected by L2 writers' variability in L1 background and
L2 proficiency.

ÊëòË¶ÅÔºö‰∫∫ÂÄëÂÇæÂêëÊñºÂú®Ë™ûË®ÄÁî¢Âá∫‰∏≠ÂùáÂãªÂú∞ÂàÜÈÖçË≥áË®äÔºå‰ª•ÈÄ≤Ë°åÊõ¥‰Ω≥‰∏îÊõ¥Ê∏ÖÊô∞ÁöÑÊ∫ùÈÄö„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊØîËºÉ‰∫ÜÁî±Á¨¨‰∫åË™ûË®ÄÂ≠∏ÁøíËÄÖÊâÄÂØ´ÁöÑË´ñÊñáÔºåÂÖ∂ÊØçË™û (L1) ËÉåÊôØÂêÑ‰∏çÁõ∏ÂêåÔºå‰ª•Êé¢Ë®é‰ªñÂÄëÂ¶Ç‰ΩïÂú®ÈùûÊØçË™û (L2) Áî¢Âá∫‰∏≠ÂàÜÈÖçË≥áË®ä„ÄÇÈ©öË®ùÂ∫¶ËàáÁÜµÁéáÊÅÜÂÆöÁöÑÂàÜÊûêÊåáÂá∫ÔºåL2 ÁÜüÁ∑¥Â∫¶ËºÉÈ´òÁöÑÂØ´‰ΩúËÄÖÂèØ‰ª•Âú®ÂÇ≥ÈÅîÊúâÊÑèÁæ©ÁöÑÂÖßÂÆπÁöÑÂêåÊôÇÔºåÈôç‰ΩéË™ûË®ÄÁî¢Âá∫ÁöÑÈ†êÊúü‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÁÑ∂ËÄåÔºåË≥áË®äÂàÜÈÖçÁöÑÂùáÂãªÊÄßÂú®‰∏çÂêåÁöÑ L2 Ë™™Ë©±ËÄÖÁæ§È´î‰∏≠È°ØÁ§∫Âá∫ËºÉÂ∞ëÁöÑËÆäÁï∞ÊÄßÔºåÈÄôË°®Á§∫Ê≠§ÁâπÂæµÂèØËÉΩÂú® L2 Ë´ñÊñáÂØ´‰Ωú‰∏≠ÂÖ∑ÊúâÊôÆÈÅçÊÄßÔºå‰∏îËºÉ‰∏çÂèó L2 ÂØ´‰ΩúËÄÖÂú® L1 ËÉåÊôØÂíå L2 ÁÜüÁ∑¥Â∫¶‰∏äÁöÑËÆäÁï∞ÊÄßÂΩ±Èüø„ÄÇ

##### **Exploring the Benefits of Domain-Pretraining of Generative Large Language Models for Chemistry**
2411.03542v1 by Anurag Acharya, Shivam Sharma, Robin Cosbey, Megha Subramanian, Scott Howland, Maria Glenski

A proliferation of Large Language Models (the GPT series, BLOOM, LLaMA, and
more) are driving forward novel development of multipurpose AI for a variety of
tasks, particularly natural language processing (NLP) tasks. These models
demonstrate strong performance on a range of tasks; however, there has been
evidence of brittleness when applied to more niche or narrow domains where
hallucinations or fluent but incorrect responses reduce performance. Given the
complex nature of scientific domains, it is prudent to investigate the
trade-offs of leveraging off-the-shelf versus more targeted foundation models
for scientific domains. In this work, we examine the benefits of in-domain
pre-training for a given scientific domain, chemistry, and compare these to
open-source, off-the-shelf models with zero-shot and few-shot prompting. Our
results show that not only do in-domain base models perform reasonably well on
in-domain tasks in a zero-shot setting but that further adaptation using
instruction fine-tuning yields impressive performance on chemistry-specific
tasks such as named entity recognition and molecular formula generation.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàGPT Á≥ªÂàó„ÄÅBLOOM„ÄÅLLaMA Á≠âÔºâÁöÑÊøÄÂ¢ûÊé®Âãï‰∫ÜÂ§öÂäüËÉΩ AI ÁöÑÊñ∞Á©éÁôºÂ±ïÔºåÈÅ©Áî®ÊñºÂêÑÁ®Æ‰ªªÂãôÔºåÁâπÂà•ÊòØËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰ªªÂãô„ÄÇÈÄô‰∫õÊ®°ÂûãÂú®ÂêÑÁ®Æ‰ªªÂãô‰∏äË°®ÁèæÂá∫Ëâ≤ÔºõÁÑ∂ËÄåÔºåÊúâË≠âÊìöË°®ÊòéÔºåÁï∂ÊáâÁî®ÊñºÊõ¥Âà©Âü∫ÊàñÁãπÁ™ÑÁöÑÈ†òÂüüÊôÇÔºåÂÆÉÂÄëÊúÉÂá∫ÁèæËÑÜÂº±ÊÄßÔºåÂú®ÈÄô‰∫õÈ†òÂüü‰∏≠ÔºåÂπªË¶∫ÊàñÊµÅÊö¢‰ΩÜÈåØË™§ÁöÑÂèçÊáâÊúÉÈôç‰ΩéÊÄßËÉΩ„ÄÇÈëëÊñºÁßëÂ≠∏È†òÂüüÁöÑË§áÈõúÊÄßÔºåÂØ©ÊÖéË™øÊü•Âà©Áî®ÁèæÊàêÁöÑÂü∫Á§éÊ®°ÂûãËàáÈáùÂ∞çÁßëÂ≠∏È†òÂüüÁöÑÊõ¥ÂÖ∑ÈáùÂ∞çÊÄßÁöÑÂü∫Á§éÊ®°Âûã‰πãÈñìÁöÑÊ¨äË°°ÂèñÊç®ÊòØÊòéÊô∫ÁöÑ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂú®ÁâπÂÆöÁßëÂ≠∏È†òÂüüÔºàÂåñÂ≠∏Ôºâ‰∏≠ÈÄ≤Ë°åÈ†òÂüüÂÖßÈ†êË®ìÁ∑¥ÁöÑÂ•ΩËôïÔºå‰∏¶Â∞áÈÄô‰∫õÂ•ΩËôïËàáÈõ∂Ê¨°Â≠∏ÁøíÂíåÂ∞ëÊ¨°Â≠∏ÁøíÊèêÁ§∫ÁöÑÈñãÊ∫êÁèæÊàêÊ®°ÂûãÈÄ≤Ë°åÊØîËºÉ„ÄÇÊàëÂÄëÁöÑÁµêÊûúË°®ÊòéÔºåÈ†òÂüüÂÖßÂü∫Á§éÊ®°Âûã‰∏çÂÉÖÂú®Èõ∂Ê¨°Â≠∏ÁøíË®≠ÁΩÆ‰∏≠Âú®È†òÂüüÂÖß‰ªªÂãô‰∏äË°®ÁèæÂæóÁõ∏Áï∂Â•ΩÔºåËÄå‰∏î‰ΩøÁî®Êåá‰ª§ÂæÆË™øÈÄ≤‰∏ÄÊ≠•ÈÅ©ÊáâÂú®ÂåñÂ≠∏ÁâπÂÆö‰ªªÂãôÔºà‰æãÂ¶ÇÂëΩÂêçÂØ¶È´îË≠òÂà•ÂíåÂàÜÂ≠êÂºèÁîüÊàêÔºâ‰∏äÁî¢Áîü‰∫Ü‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊÄßËÉΩ„ÄÇ

##### **Long Context RAG Performance of Large Language Models**
2411.03538v1 by Quinn Leng, Jacob Portes, Sam Havens, Matei Zaharia, Michael Carbin

Retrieval Augmented Generation (RAG) has emerged as a crucial technique for
enhancing the accuracy of Large Language Models (LLMs) by incorporating
external information. With the advent of LLMs that support increasingly longer
context lengths, there is a growing interest in understanding how these models
perform in RAG scenarios. Can these new long context models improve RAG
performance? This paper presents a comprehensive study of the impact of
increased context length on RAG performance across 20 popular open source and
commercial LLMs. We ran RAG workflows while varying the total context length
from 2,000 to 128,000 tokens (and 2 million tokens when possible) on three
domain-specific datasets, and report key insights on the benefits and
limitations of long context in RAG applications. Our findings reveal that while
retrieving more documents can improve performance, only a handful of the most
recent state of the art LLMs can maintain consistent accuracy at long context
above 64k tokens. We also identify distinct failure modes in long context
scenarios, suggesting areas for future research.

ÊëòË¶ÅÔºöÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÔºàRAGÔºâÂ∑≤ÊàêÁÇ∫‰∏ÄÁ®ÆËá≥ÈóúÈáçË¶ÅÁöÑÊäÄË°ìÔºåÂÆÉÈÄèÈÅéÁ¥çÂÖ•Â§ñÈÉ®Ë≥áË®ä‰æÜÊèêÂçáÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÈö®ËëóÊîØÊè¥Ë∂ä‰æÜË∂äÈï∑ËÑàÁµ°Èï∑Â∫¶ÁöÑ LLM ÁöÑÂá∫ÁèæÔºå‰∫∫ÂÄëË∂ä‰æÜË∂äÊúâËààË∂£‰∫ÜËß£ÈÄô‰∫õÊ®°ÂûãÂú® RAG Â†¥ÊôØ‰∏≠ÁöÑË°®Áèæ„ÄÇÈÄô‰∫õÊñ∞ÁöÑÈï∑ËÑàÁµ°Ê®°ÂûãËÉΩÂ§†ÊèêÂçá RAG ÁöÑÊïàËÉΩÂóéÔºüÊú¨ÊñáÈáùÂ∞ç 20 ÂÄãÊµÅË°åÁöÑÈñãÊîæÂéüÂßãÁ¢ºÂíåÂïÜÊ•≠ LLMÔºåÂ∞çÂ¢ûÂä†ËÑàÁµ°Èï∑Â∫¶Â∞ç RAG ÊïàËÉΩÁöÑÂΩ±ÈüøÈÄ≤Ë°åÂÖ®Èù¢ÁöÑÁ†îÁ©∂„ÄÇÊàëÂÄëÂú®‰∏âÂÄãÁâπÂÆöÈ†òÂüüÁöÑË≥áÊñôÈõÜ‰∏äÂü∑Ë°å RAG Â∑•‰ΩúÊµÅÁ®ãÔºåÂêåÊôÇÂ∞áÁ∏ΩËÑàÁµ°Èï∑Â∫¶Âæû 2,000 ÂÄã‰ª£Âπ£ËÆäÊõ¥ÁÇ∫ 128,000 ÂÄã‰ª£Âπ£ÔºàÂú®ÂèØËÉΩÁöÑÊÉÖÊ≥Å‰∏ãÁÇ∫ 200 Ëê¨ÂÄã‰ª£Âπ£ÔºâÔºå‰∏¶ÈáùÂ∞ç RAG ÊáâÁî®‰∏≠Èï∑ËÑàÁµ°ÁöÑÂÑ™ÈªûÂíåÈôêÂà∂Â†±ÂëäÈóúÈçµË¶ãËß£„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåÈõñÁÑ∂Ê™¢Á¥¢Êõ¥Â§öÊñá‰ª∂ÂèØ‰ª•ÊèêÂçáÊïàËÉΩÔºå‰ΩÜÂè™ÊúâÂ∞ëÊï∏ÊúÄÂÖàÈÄ≤ÁöÑ LLM ËÉΩÂ§†Âú® 64k ÂÄã‰ª£Âπ£‰ª•‰∏äÁöÑÈï∑ËÑàÁµ°‰∏≠Á∂≠ÊåÅ‰∏ÄËá¥ÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇÊàëÂÄë‰πüÂú®Èï∑ËÑàÁµ°Â†¥ÊôØ‰∏≠ÊâæÂá∫‰∏çÂêåÁöÑÂ§±ÊïóÊ®°ÂºèÔºåÊèêÂá∫Êú™‰æÜÁ†îÁ©∂ÁöÑÊñπÂêë„ÄÇ

##### **Two-Stage Pretraining for Molecular Property Prediction in the Wild**
2411.03537v1 by Kevin Tirta Wijaya, Minghao Guo, Michael Sun, Hans-Peter Seidel, Wojciech Matusik, Vahid Babaei

Accurate property prediction is crucial for accelerating the discovery of new
molecules. Although deep learning models have achieved remarkable success,
their performance often relies on large amounts of labeled data that are
expensive and time-consuming to obtain. Thus, there is a growing need for
models that can perform well with limited experimentally-validated data. In
this work, we introduce MoleVers, a versatile pretrained model designed for
various types of molecular property prediction in the wild, i.e., where
experimentally-validated molecular property labels are scarce. MoleVers adopts
a two-stage pretraining strategy. In the first stage, the model learns
molecular representations from large unlabeled datasets via masked atom
prediction and dynamic denoising, a novel task enabled by a new branching
encoder architecture. In the second stage, MoleVers is further pretrained using
auxiliary labels obtained with inexpensive computational methods, enabling
supervised learning without the need for costly experimental data. This
two-stage framework allows MoleVers to learn representations that generalize
effectively across various downstream datasets. We evaluate MoleVers on a new
benchmark comprising 22 molecular datasets with diverse types of properties,
the majority of which contain 50 or fewer training labels reflecting real-world
conditions. MoleVers achieves state-of-the-art results on 20 out of the 22
datasets, and ranks second among the remaining two, highlighting its ability to
bridge the gap between data-hungry models and real-world conditions where
practically-useful labels are scarce.

ÊëòË¶ÅÔºöÊ∫ñÁ¢∫ÁöÑÂ±¨ÊÄßÈ†êÊ∏¨Â∞çÊñºÂä†ÈÄüÊñ∞ÂàÜÂ≠êÁöÑÁôºÁèæËá≥ÈóúÈáçË¶Å„ÄÇÂÑòÁÆ°Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÂ∑≤ÂèñÂæóÈ°ØËëóÊàêÂäüÔºå‰ΩÜÂÆÉÂÄëÁöÑÊÄßËÉΩÈÄöÂ∏∏‰æùË≥¥ÊñºÂ§ßÈáèÁöÑÊ®ôÁ±§Êï∏ÊìöÔºåËÄåÈÄô‰∫õÊï∏ÊìöÁöÑÂèñÂæóÊó¢ÊòÇË≤¥ÂèàËÄóÊôÇ„ÄÇÂõ†Ê≠§ÔºåË∂ä‰æÜË∂äÈúÄË¶ÅËÉΩÂ§†Âú®Á∂ìÈÅéÂØ¶È©óÈ©óË≠âÁöÑÊï∏ÊìöÊúâÈôêÁöÑÊÉÖÊ≥Å‰∏ãË°®ÁèæËâØÂ•ΩÁöÑÊ®°Âûã„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü MoleVersÔºåÈÄôÊòØ‰∏ÄÂÄãÂ§öÂäüËÉΩÁöÑÈ†êË®ìÁ∑¥Ê®°ÂûãÔºåÊó®Âú®ÈáùÂ∞çÂêÑÁ®ÆÈ°ûÂûãÁöÑÂàÜÂ≠êÂ±¨ÊÄßÈ†êÊ∏¨ÔºåÂç≥Âú®Á∂ìÈÅéÂØ¶È©óÈ©óË≠âÁöÑÂàÜÂ≠êÂ±¨ÊÄßÊ®ôÁ±§Á®ÄÁº∫ÁöÑÊÉÖÊ≥Å‰∏ã„ÄÇMoleVers Êé°Áî®ÂÖ©ÈöéÊÆµÈ†êË®ìÁ∑¥Á≠ñÁï•„ÄÇÂú®Á¨¨‰∏ÄÈöéÊÆµÔºåË©≤Ê®°ÂûãÈÄöÈÅéÊé©Á¢ºÂéüÂ≠êÈ†êÊ∏¨ÂíåÂãïÊÖãÂéªÂô™Ôºà‰∏ÄÈ†ÖÁî±Êñ∞ÁöÑÂàÜÊîØÁ∑®Á¢ºÂô®Êû∂ÊßãÂïüÁî®ÁöÑÊñ∞‰ªªÂãôÔºâÂæûÂ§ßÈáèÁöÑÊú™Ê®ôÁ±§Êï∏ÊìöÈõÜ‰∏≠Â≠∏ÁøíÂàÜÂ≠êË°®Á§∫„ÄÇÂú®Á¨¨‰∫åÈöéÊÆµÔºåMoleVers ‰ΩøÁî®ÈÄöÈÅéÂªâÂÉπË®àÁÆóÊñπÊ≥ïÁç≤ÂæóÁöÑËºîÂä©Ê®ôÁ±§ÈÄ≤Ë°åÈÄ≤‰∏ÄÊ≠•ÁöÑÈ†êË®ìÁ∑¥ÔºåÂæûËÄåÂØ¶ÁèæÁõ£Áù£Â≠∏ÁøíÔºåËÄåÁÑ°ÈúÄÊòÇË≤¥ÁöÑÂØ¶È©óÊï∏Êìö„ÄÇÈÄôÁ®ÆÂÖ©ÈöéÊÆµÊ°ÜÊû∂‰Ωø MoleVers ËÉΩÂ§†Â≠∏ÁøíË∑®ÂêÑÁ®Æ‰∏ãÊ∏∏Êï∏ÊìöÈõÜÊúâÊïàÊ≥õÂåñÁöÑË°®Á§∫„ÄÇÊàëÂÄëÂú®‰∏ÄÂÄãÊñ∞ÁöÑÂü∫Ê∫ñ‰∏äË©ï‰º∞ MoleVersÔºåË©≤Âü∫Ê∫ñÂåÖÂê´ 22 ÂÄãÂÖ∑Êúâ‰∏çÂêåÈ°ûÂûãÁöÑÂ±¨ÊÄßÁöÑÂàÜÂ≠êÊï∏ÊìöÈõÜÔºåÂÖ∂‰∏≠Â§ßÈÉ®ÂàÜÂåÖÂê´ 50 ÂÄãÊàñÊõ¥Â∞ëÁöÑË®ìÁ∑¥Ê®ôÁ±§ÔºåÂèçÊò†‰∫ÜÁúüÂØ¶‰∏ñÁïåÁöÑÊ¢ù‰ª∂„ÄÇMoleVers Âú® 22 ÂÄãÊï∏ÊìöÈõÜ‰∏≠Êúâ 20 ÂÄãÂèñÂæó‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÁµêÊûúÔºåËÄåÂú®Ââ©‰∏ãÁöÑÂÖ©ÂÄãÊï∏ÊìöÈõÜ‰∏≠ÊéíÂêçÁ¨¨‰∫åÔºåÁ™ÅÈ°Ø‰∫ÜÂÆÉÂΩåÂêàÊï∏ÊìöÂØÜÈõÜÂûãÊ®°ÂûãÂíåÂØ¶ÈöõÊáâÁî®‰∏≠ÂØ¶Áî®Ê®ôÁ±§Á®ÄÁº∫‰πãÈñìÂ∑ÆË∑ùÁöÑËÉΩÂäõ„ÄÇ

##### **Personalized Video Summarization by Multimodal Video Understanding**
2411.03531v1 by Brian Chen, Xiangyuan Zhao, Yingnan Zhu

Video summarization techniques have been proven to improve the overall user
experience when it comes to accessing and comprehending video content. If the
user's preference is known, video summarization can identify significant
information or relevant content from an input video, aiding them in obtaining
the necessary information or determining their interest in watching the
original video. Adapting video summarization to various types of video and user
preferences requires significant training data and expensive human labeling. To
facilitate such research, we proposed a new benchmark for video summarization
that captures various user preferences. Also, we present a pipeline called
Video Summarization with Language (VSL) for user-preferred video summarization
that is based on pre-trained visual language models (VLMs) to avoid the need to
train a video summarization system on a large training dataset. The pipeline
takes both video and closed captioning as input and performs semantic analysis
at the scene level by converting video frames into text. Subsequently, the
user's genre preference was used as the basis for selecting the pertinent
textual scenes. The experimental results demonstrate that our proposed pipeline
outperforms current state-of-the-art unsupervised video summarization models.
We show that our method is more adaptable across different datasets compared to
supervised query-based video summarization models. In the end, the runtime
analysis demonstrates that our pipeline is more suitable for practical use when
scaling up the number of user preferences and videos.

ÊëòË¶ÅÔºöÂΩ±ÁâáÊëòË¶ÅÊäÄË°ìÂ∑≤Ë¢´Ë≠âÊòéÂèØ‰ª•ÊîπÂñÑÊï¥È´î‰ΩøÁî®ËÄÖÈ´îÈ©óÔºåÁâπÂà•ÊòØÂú®Â≠òÂèñÂíåÁêÜËß£ÂΩ±ÁâáÂÖßÂÆπÊôÇ„ÄÇÂ¶ÇÊûúÂ∑≤Áü•‰ΩøÁî®ËÄÖÁöÑÂÅèÂ•ΩÔºåÂΩ±ÁâáÊëòË¶ÅÂèØ‰ª•ÂæûËº∏ÂÖ•ÂΩ±Áâá‰∏≠ÊâæÂá∫ÈáçË¶ÅÁöÑË≥áË®äÊàñÁõ∏ÈóúÂÖßÂÆπÔºåÂçîÂä©‰ªñÂÄëÂèñÂæóÂøÖË¶ÅÁöÑË≥áË®äÊàñÊ±∫ÂÆöÊòØÂê¶ÊúâËààË∂£ËßÄÁúãÂéüÂßãÂΩ±Áâá„ÄÇË¶ÅÂ∞áÂΩ±ÁâáÊëòË¶ÅÈÅ©ÊáâÂà∞ÂêÑÁ®ÆÂΩ±ÁâáÂíå‰ΩøÁî®ËÄÖÂÅèÂ•ΩÔºåÈúÄË¶ÅÂ§ßÈáèÁöÑË®ìÁ∑¥Ë≥áÊñôÂíåÊòÇË≤¥ÁöÑ‰∫∫Â∑•Ê®ôË®ò„ÄÇÁÇ∫‰∫Ü‰øÉÈÄ≤Ê≠§È°ûÁ†îÁ©∂ÔºåÊàëÂÄëÊèêÂá∫‰∫ÜÂΩ±ÁâáÊëòË¶ÅÁöÑÊñ∞Âü∫Ê∫ñÔºåÊ∂µËìã‰∫ÜÂêÑÁ®Æ‰ΩøÁî®ËÄÖÂÅèÂ•Ω„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÁ®±ÁÇ∫ÂΩ±ÁâáÊëòË¶ÅËàáË™ûË®Ä (VSL) ÁöÑÁÆ°ÈÅìÔºåÁî®Êñº‰ΩøÁî®ËÄÖÂÅèÂ•ΩÁöÑÂΩ±ÁâáÊëòË¶ÅÔºåÊ≠§ÁÆ°ÈÅìÂü∫ÊñºÈ†êÂÖàË®ìÁ∑¥Â•ΩÁöÑË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM)Ôºå‰ª•ÈÅøÂÖçÂú®Â§ßÂûãË®ìÁ∑¥Ë≥áÊñôÈõÜ‰∏äË®ìÁ∑¥ÂΩ±ÁâáÊëòË¶ÅÁ≥ªÁµ±ÁöÑÈúÄË¶Å„ÄÇÊ≠§ÁÆ°ÈÅìÂ∞áÂΩ±ÁâáÂíåÂ≠óÂπï‰ΩúÁÇ∫Ëº∏ÂÖ•Ôºå‰∏¶ÈÄèÈÅéÂ∞áÂΩ±ÁâáÊ†ºËΩâÊèõÁÇ∫ÊñáÂ≠óÔºåÂú®Â†¥ÊôØÂ±§Á¥öÂü∑Ë°åË™ûÊÑèÂàÜÊûê„ÄÇÈö®ÂæåÔºå‰ΩøÁî®‰ΩøÁî®ËÄÖÁöÑÈ°ûÂûãÂÅèÂ•Ω‰ΩúÁÇ∫ÈÅ∏ÊìáÁõ∏ÈóúÊñáÂ≠óÂ†¥ÊôØÁöÑÂü∫Á§é„ÄÇÂØ¶È©óÁµêÊûúË≠âÊòéÔºåÊàëÂÄëÊèêÂá∫ÁöÑÁÆ°ÈÅìÂÑ™ÊñºÁõÆÂâçÊúÄÂÖàÈÄ≤ÁöÑÁÑ°Áõ£Áù£ÂΩ±ÁâáÊëòË¶ÅÊ®°Âûã„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜËàáÁõ£Áù£ÂºèÊü•Ë©¢ÂºèÂΩ±ÁâáÊëòË¶ÅÊ®°ÂûãÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÊ®°ÂûãÊõ¥ËÉΩÈÅ©Êáâ‰∏çÂêåÁöÑË≥áÊñôÈõÜ„ÄÇÊúÄÂæåÔºåÂü∑Ë°åÊôÇÈñìÂàÜÊûêË≠âÊòéÔºåÁï∂Êì¥ÂÖÖ‰ΩøÁî®ËÄÖÂÅèÂ•ΩÂíåÂΩ±ÁâáÊï∏ÈáèÊôÇÔºåÊàëÂÄëÁöÑÁÆ°ÈÅìÊõ¥ÈÅ©ÂêàÂØ¶Èöõ‰ΩøÁî®„ÄÇ

##### **Exploring the Potentials and Challenges of Using Large Language Models for the Analysis of Transcriptional Regulation of Long Non-coding RNAs**
2411.03522v1 by Wei Wang, Zhichao Hou, Xiaorui Liu, Xinxia Peng

Research on long non-coding RNAs (lncRNAs) has garnered significant attention
due to their critical roles in gene regulation and disease mechanisms. However,
the complexity and diversity of lncRNA sequences, along with the limited
knowledge of their functional mechanisms and the regulation of their
expressions, pose significant challenges to lncRNA studies. Given the
tremendous success of large language models (LLMs) in capturing complex
dependencies in sequential data, this study aims to systematically explore the
potential and limitations of LLMs in the sequence analysis related to the
transcriptional regulation of lncRNA genes. Our extensive experiments
demonstrated promising performance of fine-tuned genome foundation models on
progressively complex tasks. Furthermore, we conducted an insightful analysis
of the critical impact of task complexity, model selection, data quality, and
biological interpretability for the studies of the regulation of lncRNA gene
expression.

ÊëòË¶ÅÔºöÈï∑ÈèàÈùûÁ∑®Á¢º RNA (lncRNA) ÁöÑÁ†îÁ©∂Âõ†ÂÖ∂Âú®Âü∫Âõ†Ë™øÊéßÂíåÁñæÁóÖÊ©üÂà∂‰∏≠ÊâÆÊºîÈóúÈçµËßíËâ≤ËÄåÂÇôÂèóÁüöÁõÆ„ÄÇÁÑ∂ËÄåÔºålncRNA Â∫èÂàóÁöÑË§áÈõúÊÄßÂíåÂ§öÊ®£ÊÄßÔºåÂä†‰∏äÊàëÂÄëÂ∞çÂÖ∂ÂäüËÉΩÊ©üÂà∂ÂíåË°®ÈÅîË™øÊéßÁöÑÁü•Ë≠òÊúâÈôêÔºåÂ∞ç lncRNA Á†îÁ©∂ÊßãÊàêÈáçÂ§ßÊåëÊà∞„ÄÇÈëëÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÊçïÊçâÂ∫èÂàóË≥áÊñô‰∏≠Ë§áÈõú‰æùÂ≠òÈóú‰øÇÁöÑÂ∑®Â§ßÊàêÂäüÔºåÊú¨Á†îÁ©∂Êó®Âú®Á≥ªÁµ±ÊÄßÂú∞Êé¢Ë®é LLM Âú®Ëàá lncRNA Âü∫Âõ†ËΩâÈåÑË™øÊéßÁõ∏ÈóúÁöÑÂ∫èÂàóÂàÜÊûê‰∏≠ÁöÑÊΩõÂäõÂíåÈôêÂà∂„ÄÇÊàëÂÄëÂª£Ê≥õÁöÑÂØ¶È©óË≠âÊòé‰∫ÜÂæÆË™øÂæåÁöÑÂü∫Âõ†ÁµÑÂü∫Á§éÊ®°ÂûãÂú®ÈÄêÊº∏Ë§áÈõúÁöÑ‰ªªÂãô‰∏≠Ë°®ÁèæÂá∫ËâØÂ•ΩÁöÑÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ∞ç‰ªªÂãôË§áÈõúÊÄß„ÄÅÊ®°ÂûãÈÅ∏Êìá„ÄÅË≥áÊñôÂìÅË≥™ÂíåÁîüÁâ©Â≠∏ÂèØËß£ÈáãÊÄßÂ∞ç lncRNA Âü∫Âõ†Ë°®ÁèæË™øÊéßÁ†îÁ©∂ÁöÑÈóúÈçµÂΩ±ÈüøÈÄ≤Ë°å‰∫ÜÊ∑±ÂÖ•ÂàÜÊûê„ÄÇ

##### **AI Metropolis: Scaling Large Language Model-based Multi-Agent Simulation with Out-of-order Execution**
2411.03519v1 by Zhiqiang Xie, Hao Kang, Ying Sheng, Tushar Krishna, Kayvon Fatahalian, Christos Kozyrakis

With more advanced natural language understanding and reasoning capabilities,
large language model (LLM)-powered agents are increasingly developed in
simulated environments to perform complex tasks, interact with other agents,
and exhibit emergent behaviors relevant to social science and gaming. However,
current multi-agent simulations frequently suffer from inefficiencies due to
the limited parallelism caused by false dependencies, resulting in performance
bottlenecks. In this paper, we introduce AI Metropolis, a simulation engine
that improves the efficiency of LLM agent simulations by incorporating
out-of-order execution scheduling. By dynamically tracking real dependencies
between agents, AI Metropolis minimizes false dependencies, enhancing
parallelism and enabling efficient hardware utilization. Our evaluations
demonstrate that AI Metropolis achieves speedups from 1.3x to 4.15x over
standard parallel simulation with global synchronization, approaching optimal
performance as the number of agents increases.

ÊëòË¶ÅÔºöÈö®ËëóÊõ¥ÈÄ≤ÈöéÁöÑËá™ÁÑ∂Ë™ûË®ÄÁêÜËß£ÂíåÊé®ÁêÜËÉΩÂäõÔºåÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) È©ÖÂãïÁöÑ‰ª£ÁêÜ‰∫∫Ë∂ä‰æÜË∂äÂ∏∏Âú®Ê®°Êì¨Áí∞Â¢É‰∏≠ÈñãÁôºÔºå‰ª•Âü∑Ë°åË§áÈõú‰ªªÂãô„ÄÅËàáÂÖ∂‰ªñ‰ª£ÁêÜ‰∫∫‰∫íÂãïÔºå‰∏¶Ë°®ÁèæÂá∫ËàáÁ§æÊúÉÁßëÂ≠∏ÂíåÈÅäÊà≤Áõ∏ÈóúÁöÑÊñ∞ËààË°åÁÇ∫„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑË®±Â§ö‰ª£ÁêÜ‰∫∫Ê®°Êì¨Á∂ìÂ∏∏ÊúÉÂõ†ÁÇ∫ËôõÂÅá‰æùË≥¥Èóú‰øÇÈÄ†ÊàêÁöÑ‰∏¶Ë°åÊÄßÂèóÈôêËÄåÂ∞éËá¥ÊïàÁéá‰Ωé‰∏ãÔºåÈÄ≤ËÄåÁî¢ÁîüÊïàËÉΩÁì∂È†∏„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞á‰ªãÁ¥π AI MetropolisÔºåÈÄôÊòØ‰∏ÄÂÄãÊ®°Êì¨ÂºïÊìéÔºåÈÄèÈÅéÁ¥çÂÖ•ÁÑ°Â∫èÂü∑Ë°åÊéíÁ®ã‰æÜÊèêÂçá LLM ‰ª£ÁêÜ‰∫∫Ê®°Êì¨ÁöÑÊïàÁéá„ÄÇÈÄèÈÅéÂãïÊÖãËøΩËπ§‰ª£ÁêÜ‰∫∫‰πãÈñìÁöÑÁúüÂØ¶‰æùË≥¥Èóú‰øÇÔºåAI Metropolis Â∞áËôõÂÅá‰æùË≥¥Èóú‰øÇÈôçÂà∞ÊúÄ‰ΩéÔºåÈÄ≤ËÄåÊèêÂçá‰∏¶Ë°åÊÄß‰∏¶ËÆìÁ°¨È´îÂæó‰ª•ÊúâÊïàÂà©Áî®„ÄÇÊàëÂÄëÁöÑË©ï‰º∞ÁµêÊûúÈ°ØÁ§∫ÔºåAI Metropolis Âú®ÂÖ®ÁêÉÂêåÊ≠•ÁöÑÊ®ôÊ∫ñÂπ≥Ë°åÊ®°Êì¨‰∏≠ÔºåÂèØÈÅîÂà∞ 1.3 ÂÄçÂà∞ 4.15 ÂÄçÁöÑÂä†ÈÄüÔºå‰∏¶Èö®Ëëó‰ª£ÁêÜ‰∫∫Êï∏ÈáèÂ¢ûÂä†ËÄåÊé•ËøëÊúÄ‰Ω≥ÊïàËÉΩ„ÄÇ

##### **Change Is the Only Constant: Dynamic LLM Slicing based on Layer Redundancy**
2411.03513v1 by Razvan-Gabriel Dumitru, Paul-Ioan Clotan, Vikas Yadav, Darius Peteleaza, Mihai Surdeanu

This paper introduces a novel model compression approach through dynamic
layer-specific pruning in Large Language Models (LLMs), enhancing the
traditional methodology established by SliceGPT. By transitioning from constant
to dynamic slicing, our method leverages the newly proposed Layer Redundancy
(LR) score, which assesses how much change each layer changes its input by
measuring the cosine similarity of the input to the output of the layer. We use
this score to prune parts of individual layers based on redundancy in such a
way that the average pruned percentage for all layers is a fixed value. We
conducted extensive experiments using models like Llama3-8B and Mistral-7B on
multiple datasets, evaluating different slicing bases and percentages to
determine optimal configurations that balance efficiency and performance. Our
findings show that our dynamic slicing approach not only maintains but, in many
cases, enhances model performance compared to the baseline established by
constant slicing methods. For instance, in several settings, we see performance
improvements of up to 5% over the SliceGPT baseline. Additionally, a perplexity
decrease by as much as 7% was observed across multiple benchmarks, validating
the effectiveness of our method. The code, model weights, and datasets are
open-sourced at https://github.com/RazvanDu/DynamicSlicing.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥π‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÊ®°ÂûãÂ£ìÁ∏ÆÊñπÊ≥ïÔºåÈÄèÈÅéÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠ÁöÑÂãïÊÖãÁâπÂÆöÂ±§Á¥ö‰øÆÂâ™ÔºåÂ¢ûÂº∑ SliceGPT ÊâÄÂª∫Á´ãÁöÑÂÇ≥Áµ±ÊñπÊ≥ï„ÄÇÈÄèÈÅéÂæûÂõ∫ÂÆöÂàáÁâáËΩâÊèõÁÇ∫ÂãïÊÖãÂàáÁâáÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂà©Áî®Êñ∞ÊèêÂá∫ÁöÑÂ±§Á¥öÂÜóÈ§ò (LR) ÂàÜÊï∏ÔºåÈÄèÈÅéÊ∏¨ÈáèËº∏ÂÖ•ËàáÂ±§Á¥öËº∏Âá∫ÁöÑÈ§òÂº¶Áõ∏‰ººÂ∫¶ÔºåË©ï‰º∞ÊØèÂÄãÂ±§Á¥öÊîπËÆäÂÖ∂Ëº∏ÂÖ•ÁöÑÁ®ãÂ∫¶„ÄÇÊàëÂÄë‰ΩøÁî®Ê≠§ÂàÜÊï∏‰æÜ‰øÆÂâ™ÂÄãÂà•Â±§Á¥öÁöÑÈÉ®ÂàÜÔºåÂü∫ÊñºÂÜóÈ§òÔºåÂπ≥Âùá‰øÆÂâ™ÁôæÂàÜÊØîÁÇ∫ÊâÄÊúâÂ±§Á¥öÁöÑÂõ∫ÂÆöÂÄº„ÄÇÊàëÂÄë‰ΩøÁî® Llama3-8B Âíå Mistral-7B Á≠âÊ®°ÂûãÂú®Â§öÂÄãË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©óÔºåË©ï‰º∞‰∏çÂêåÁöÑÂàáÁâáÂü∫Á§éÂíåÁôæÂàÜÊØîÔºå‰ª•Á¢∫ÂÆöÂπ≥Ë°°ÊïàÁéáÂíåÊïàËÉΩÁöÑÊúÄ‰Ω≥ÁµÑÊÖã„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåËàáÂõ∫ÂÆöÂàáÁâáÊñπÊ≥ïÊâÄÂª∫Á´ãÁöÑÂü∫Ê∫ñÁ∑öÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÂãïÊÖãÂàáÁâáÊñπÊ≥ï‰∏çÂÉÖÁ∂≠ÊåÅÔºåÂú®Ë®±Â§öÊÉÖÊ≥Å‰∏ãÔºåÈÇÑÂ¢ûÂº∑‰∫ÜÊ®°ÂûãÊïàËÉΩ„ÄÇ‰æãÂ¶ÇÔºåÂú®Â§öÂÄãË®≠ÂÆö‰∏≠ÔºåÊàëÂÄëÁúãÂà∞ÊïàËÉΩÊØî SliceGPT Âü∫Ê∫ñÁ∑öÊèêÂçáÂ§öÈÅî 5%„ÄÇÊ≠§Â§ñÔºåÂú®Â§öÂÄãÂü∫Ê∫ñÊ∏¨Ë©¶‰∏≠ËßÄÂØüÂà∞Âõ∞ÊÉëÂ∫¶Èôç‰ΩéÂ§öÈÅî 7%ÔºåÈ©óË≠â‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÁ®ãÂºèÁ¢º„ÄÅÊ®°ÂûãÊ¨äÈáçÂíåË≥áÊñôÈõÜÂú® https://github.com/RazvanDu/DynamicSlicing ÈñãÊ∫ê„ÄÇ

##### **Uncertainty Quantification for Clinical Outcome Predictions with (Large) Language Models**
2411.03497v1 by Zizhang Chen, Peizhao Li, Xiaomeng Dong, Pengyu Hong

To facilitate healthcare delivery, language models (LMs) have significant
potential for clinical prediction tasks using electronic health records (EHRs).
However, in these high-stakes applications, unreliable decisions can result in
high costs due to compromised patient safety and ethical concerns, thus
increasing the need for good uncertainty modeling of automated clinical
predictions. To address this, we consider the uncertainty quantification of LMs
for EHR tasks in white- and black-box settings. We first quantify uncertainty
in white-box models, where we can access model parameters and output logits. We
show that an effective reduction of model uncertainty can be achieved by using
the proposed multi-tasking and ensemble methods in EHRs. Continuing with this
idea, we extend our approach to black-box settings, including popular
proprietary LMs such as GPT-4. We validate our framework using longitudinal
clinical data from more than 6,000 patients in ten clinical prediction tasks.
Results show that ensembling methods and multi-task prediction prompts reduce
uncertainty across different scenarios. These findings increase the
transparency of the model in white-box and black-box settings, thus advancing
reliable AI healthcare.

ÊëòË¶ÅÔºöÁÇ∫‰∫Ü‰øÉÈÄ≤ÈÜ´ÁôÇ‰øùÂÅ•ÁöÑÊèê‰æõÔºåË™ûË®ÄÊ®°Âûã (LM) Âú®‰ΩøÁî®ÈõªÂ≠êÂÅ•Â∫∑Á¥ÄÈåÑ (EHR) ÁöÑËá®Â∫äÈ†êÊ∏¨‰ªªÂãô‰∏≠ÂÖ∑ÊúâÈ°ØËëóÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÂú®ÈÄô‰∫õÈ´òÈ¢®Èö™ÁöÑÊáâÁî®‰∏≠Ôºå‰∏çÂèØÈù†ÁöÑÊ±∫Á≠ñÂèØËÉΩÊúÉÁî±ÊñºÂç±ÂÆ≥ÁóÖÊÇ£ÂÆâÂÖ®ÂíåÈÅìÂæ∑ÂïèÈ°åËÄåÂ∞éËá¥È´òÊòÇÁöÑÊàêÊú¨ÔºåÂõ†Ê≠§ÊèêÈ´òËá™ÂãïÂåñËá®Â∫äÈ†êÊ∏¨ÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÂª∫Ê®°ÁöÑÈúÄÊ±ÇË∂ä‰æÜË∂äÈ´ò„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëËÄÉÊÖÆ‰∫ÜÂú®ÁôΩÁõíÂíåÈªëÁõíË®≠ÁΩÆ‰∏≠ LM ÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÈáèÂåñÔºåÁî®Êñº EHR ‰ªªÂãô„ÄÇÊàëÂÄëÈ¶ñÂÖàÈáèÂåñÁôΩÁõíÊ®°Âûã‰∏≠ÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÔºåÂú®ÂÖ∂‰∏≠ÊàëÂÄëÂèØ‰ª•Â≠òÂèñÊ®°ÂûãÂèÉÊï∏ÂíåËº∏Âá∫ logit„ÄÇÊàëÂÄëÈ°ØÁ§∫ÔºåÈÄèÈÅéÂú® EHR ‰∏≠‰ΩøÁî®ÊâÄÊèêÂá∫ÁöÑÂ§ö‰ªªÂãôÂíåÊï¥È´îÊñπÊ≥ïÔºåÂèØ‰ª•ÊúâÊïàÈôç‰ΩéÊ®°Âûã‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÂª∂Á∫åÈÄôÂÄãÊÉ≥Ê≥ïÔºåÊàëÂÄëÂ∞áÊàëÂÄëÁöÑÂÅöÊ≥ïÊì¥Â±ïÂà∞ÈªëÁõíË®≠ÁΩÆÔºåÂåÖÊã¨ÁÜ±ÈñÄÁöÑÂ∞àÊúâ LMÔºå‰æãÂ¶Ç GPT-4„ÄÇÊàëÂÄë‰ΩøÁî®‰æÜËá™Ë∂ÖÈÅé 6,000 ÂêçÁóÖÊÇ£ÁöÑÁ∏±ÂêëËá®Â∫äË≥áÊñôÔºåÂú®ÂçÅÈ†ÖËá®Â∫äÈ†êÊ∏¨‰ªªÂãô‰∏≠È©óË≠âÊàëÂÄëÁöÑÊû∂Êßã„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåÊï¥È´îÊñπÊ≥ïÂíåÂ§ö‰ªªÂãôÈ†êÊ∏¨ÊèêÁ§∫ÂèØÈôç‰Ωé‰∏çÂêåÊÉÖÂ¢É‰∏≠ÁöÑ‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÈÄô‰∫õÁôºÁèæÊèêÂçá‰∫ÜÁôΩÁõíÂíåÈªëÁõíË®≠ÁΩÆ‰∏≠Ê®°ÂûãÁöÑÈÄèÊòéÂ∫¶ÔºåÈÄ≤ËÄå‰øÉÈÄ≤ÂèØÈù†ÁöÑ‰∫∫Â∑•Êô∫ÊÖßÈÜ´ÁôÇ‰øùÂÅ•„ÄÇ

##### **Automatic Generation of Question Hints for Mathematics Problems using Large Language Models in Educational Technology**
2411.03495v1 by Junior Cedric Tonga, Benjamin Clement, Pierre-Yves Oudeyer

The automatic generation of hints by Large Language Models (LLMs) within
Intelligent Tutoring Systems (ITSs) has shown potential to enhance student
learning. However, generating pedagogically sound hints that address student
misconceptions and adhere to specific educational objectives remains
challenging. This work explores using LLMs (GPT-4o and Llama-3-8B-instruct) as
teachers to generate effective hints for students simulated through LLMs
(GPT-3.5-turbo, Llama-3-8B-Instruct, or Mistral-7B-instruct-v0.3) tackling math
exercises designed for human high-school students, and designed using cognitive
science principles. We present here the study of several dimensions: 1)
identifying error patterns made by simulated students on secondary-level math
exercises; 2) developing various prompts for GPT-4o as a teacher and evaluating
their effectiveness in generating hints that enable simulated students to
self-correct; and 3) testing the best-performing prompts, based on their
ability to produce relevant hints and facilitate error correction, with
Llama-3-8B-Instruct as the teacher, allowing for a performance comparison with
GPT-4o. The results show that model errors increase with higher temperature
settings. Notably, when hints are generated by GPT-4o, the most effective
prompts include prompts tailored to specific errors as well as prompts
providing general hints based on common mathematical errors. Interestingly,
Llama-3-8B-Instruct as a teacher showed better overall performance than GPT-4o.
Also the problem-solving and response revision capabilities of the LLMs as
students, particularly GPT-3.5-turbo, improved significantly after receiving
hints, especially at lower temperature settings. However, models like
Mistral-7B-Instruct demonstrated a decline in performance as the temperature
increased.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Êô∫ÊÖßÂûãÊïôÂ≠∏Á≥ªÁµ± (ITS) ‰∏≠Ëá™ÂãïÁî¢ÁîüÊèêÁ§∫ÔºåÂ∑≤È°ØÁ§∫Âá∫Â¢ûÈÄ≤Â≠∏ÁîüÂ≠∏ÁøíÁöÑÊΩõÂäõ„ÄÇÁÑ∂ËÄåÔºåÁî¢ÁîüÁ¨¶ÂêàÊïôÂ≠∏Ê≥ïÁöÑÊèêÁ§∫Ôºå‰ª•Ëß£Ê±∫Â≠∏ÁîüÁöÑË™§Ëß£‰∏¶ÈÅµÂæ™ÁâπÂÆöÁöÑÊïôËÇ≤ÁõÆÊ®ôÔºå‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÊé¢Ë®é‰ΩøÁî® LLMÔºàGPT-4o Âíå Llama-3-8B-instructÔºâ‰ΩúÁÇ∫ËÄÅÂ∏´ÔºåÁÇ∫Ê®°Êì¨ÈÄèÈÅé LLMÔºàGPT-3.5-turbo„ÄÅLlama-3-8B-Instruct Êàñ Mistral-7B-instruct-v0.3ÔºâËß£Ê±∫Â∞àÁÇ∫‰∫∫È°ûÈ´ò‰∏≠ÁîüË®≠Ë®àÁöÑÊï∏Â≠∏Á∑¥ÁøíÔºå‰∏¶‰ΩøÁî®Ë™çÁü•ÁßëÂ≠∏ÂéüÁêÜÈÄ≤Ë°åË®≠Ë®àÁöÑÂ≠∏ÁîüÁöÑÁî¢ÁîüÊúâÊïàÊèêÁ§∫„ÄÇÊàëÂÄëÂú®Ê≠§ÊèêÂá∫Â∞çÂπæÂÄãÈù¢ÂêëÁöÑÁ†îÁ©∂Ôºö1ÔºâÊâæÂá∫Ê®°Êì¨Â≠∏ÁîüÂú®‰∏≠Â≠∏Êï∏Â≠∏Á∑¥Áøí‰∏≠Áî¢ÁîüÁöÑÈåØË™§Ê®°ÂºèÔºõ2ÔºâÁÇ∫ GPT-4o ‰ΩúÁÇ∫ËÄÅÂ∏´ÈñãÁôºÂêÑÁ®ÆÊèêÁ§∫Ôºå‰∏¶Ë©ï‰º∞ÂÆÉÂÄëÂú®Áî¢ÁîüÊèêÁ§∫‰ª•‰ΩøÊ®°Êì¨Â≠∏ÁîüËÉΩÂ§†Ëá™Êàë‰øÆÊ≠£ÊñπÈù¢ÁöÑÊúâÊïàÊÄßÔºõ3ÔºâÊ∏¨Ë©¶Âü∫ÊñºÁî¢ÁîüÁõ∏ÈóúÊèêÁ§∫Âíå‰øÉÈÄ≤ÈåØË™§‰øÆÊ≠£ÁöÑËÉΩÂäõÔºåË°®ÁèæÊúÄ‰Ω≥ÁöÑÊèêÁ§∫ÔºåÁî± Llama-3-8B-Instruct ‰ΩúÁÇ∫ËÄÅÂ∏´ÔºåÂÖÅË®±Ëàá GPT-4o ÈÄ≤Ë°åÊïàËÉΩÊØîËºÉ„ÄÇÁµêÊûúÈ°ØÁ§∫ÔºåÊ®°ÂûãÈåØË™§ÊúÉÈö®ËëóËºÉÈ´òÁöÑÊ∫´Â∫¶Ë®≠ÂÆöËÄåÂ¢ûÂä†„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÁï∂ÊèêÁ§∫ÊòØÁî± GPT-4o Áî¢ÁîüÊôÇÔºåÊúÄÊúâÊïàÁöÑÊèêÁ§∫ÂåÖÊã¨ÈáùÂ∞çÁâπÂÆöÈåØË™§ÈáèË∫´ÊâìÈÄ†ÁöÑÊèêÁ§∫Ôºå‰ª•ÂèäÊ†πÊìöÂ∏∏Ë¶ãÊï∏Â≠∏ÈåØË™§Êèê‰æõ‰∏ÄËà¨ÊèêÁ§∫ÁöÑÊèêÁ§∫„ÄÇÊúâË∂£ÁöÑÊòØÔºå‰ΩúÁÇ∫ËÄÅÂ∏´ÁöÑ Llama-3-8B-Instruct È°ØÁ§∫Âá∫ÊØî GPT-4o Êõ¥Â•ΩÁöÑÊï¥È´îË°®Áèæ„ÄÇÊ≠§Â§ñÔºåÁâπÂà•ÊòØ GPT-3.5-turboÔºåLLM ‰ΩúÁÇ∫Â≠∏ÁîüÁöÑÂïèÈ°åËß£Ê±∫ÂíåÂõûÊáâ‰øÆÊ≠£ËÉΩÂäõÂú®Êî∂Âà∞ÊèêÁ§∫ÂæåÈ°ØËëóÊèêÂçáÔºåÂ∞§ÂÖ∂ÊòØÂú®ËºÉ‰ΩéÁöÑÊ∫´Â∫¶Ë®≠ÂÆö‰∏ã„ÄÇÁÑ∂ËÄåÔºåÈö®ËëóÊ∫´Â∫¶ÂçáÈ´òÔºåMistral-7B-Instruct Á≠âÊ®°ÂûãÁöÑÊïàËÉΩË°®ÁèæÂá∫‰∏ãÈôç„ÄÇ

##### **LASER: Attention with Exponential Transformation**
2411.03493v1 by Sai Surya Duvvuri, Inderjit S. Dhillon

Transformers have had tremendous impact for several sequence related tasks,
largely due to their ability to retrieve from any part of the sequence via
softmax based dot-product attention. This mechanism plays a crucial role in
Transformer's performance. We analyze the gradients backpropagated through the
softmax operation in the attention mechanism and observe that these gradients
can often be small. This poor gradient signal backpropagation can lead to
inefficient learning of parameters preceeding the attention operations. To this
end, we introduce a new attention mechanism called LASER, which we analytically
show to admit a larger gradient signal. We show that LASER Attention can be
implemented by making small modifications to existing attention
implementations. We conduct experiments on autoregressive large language models
(LLMs) with upto 2.2 billion parameters where we show upto 3.38% and an average
of ~1% improvement over standard attention on downstream evaluations. Using
LASER gives the following relative improvements in generalization performance
across a variety of tasks (vision, text and speech): 4.67% accuracy in Vision
Transformer (ViT) on Imagenet, 2.25% error rate in Conformer on the Librispeech
speech-to-text and 0.93% fraction of incorrect predictions in BERT with 2.2
billion parameters.

ÊëòË¶ÅÔºöTransformer Âú®Â§öÈ†ÖÂ∫èÂàóÁõ∏Èóú‰ªªÂãô‰∏≠Áî¢ÁîüÈáçÂ§ßÂΩ±ÈüøÔºå
ÈÄôÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÊòØÂõ†ÁÇ∫ÂÆÉÂÄëËÉΩÂ§†ÈÄèÈÅéÂü∫Êñº softmax ÁöÑ dot-product Ê≥®ÊÑèÂäõÊ©üÂà∂ÔºåÂæûÂ∫èÂàóÁöÑ‰ªª‰ΩïÈÉ®ÂàÜÊì∑ÂèñË≥áË®ä„ÄÇÈÄôÂÄãÊ©üÂà∂Âú® Transformer ÁöÑÊïàËÉΩ‰∏≠ÊâÆÊºîËëóÈóúÈçµËßíËâ≤„ÄÇÊàëÂÄëÂàÜÊûê‰∫ÜÂú®Ê≥®ÊÑèÂäõÊ©üÂà∂‰∏≠ÈÄèÈÅé softmax ÈÅãÁÆóÂèçÂêëÂÇ≥Êí≠ÁöÑÊ¢ØÂ∫¶Ôºå‰∏¶ËßÄÂØüÂà∞ÈÄô‰∫õÊ¢ØÂ∫¶ÈÄöÂ∏∏ÂæàÂ∞è„ÄÇÈÄôÁ®Æ‰∏ç‰Ω≥ÁöÑÊ¢ØÂ∫¶Ë®äËôüÂèçÂêëÂÇ≥Êí≠ÂèØËÉΩÊúÉÂ∞éËá¥Âú®Ê≥®ÊÑèÂäõÈÅãÁÆó‰πãÂâçÂèÉÊï∏Â≠∏ÁøíÊïàÁéá‰∏çÂΩ∞„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÂºïÈÄ≤‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫ LASER ÁöÑÊñ∞Ê≥®ÊÑèÂäõÊ©üÂà∂ÔºåÊàëÂÄëÂàÜÊûêÊÄßÂú∞Ë≠âÊòéÂÆÉÂÖÅË®±Êõ¥Â§ßÁöÑÊ¢ØÂ∫¶Ë®äËôü„ÄÇÊàëÂÄëË≠âÊòé LASER Ê≥®ÊÑèÂäõÂèØ‰ª•ÈÄèÈÅéÂ∞çÁèæÊúâÊ≥®ÊÑèÂäõÂØ¶‰ΩúÈÄ≤Ë°åÂ∞èÂπÖ‰øÆÊîπ‰æÜÂØ¶‰Ωú„ÄÇÊàëÂÄëÂú®ÂÖ∑ÊúâÂ§öÈÅî 22 ÂÑÑÂÄãÂèÉÊï∏ÁöÑËá™Ëø¥Ê≠∏Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏äÈÄ≤Ë°åÂØ¶È©óÔºåÂú®ÈÄô‰∫õÂØ¶È©ó‰∏≠ÔºåÊàëÂÄëÈ°ØÁ§∫Âá∫Âú®‰∏ãÊ∏∏Ë©ï‰º∞‰∏≠ÔºåÊ®ôÊ∫ñÊ≥®ÊÑèÂäõÁöÑÈÄ≤Ê≠•ÂπÖÂ∫¶ÊúÄÈ´òÁÇ∫ 3.38%ÔºåÂπ≥ÂùáÁ¥ÑÁÇ∫ 1%„ÄÇÂú®ÂêÑÁ®Æ‰ªªÂãôÔºàË¶ñË¶∫„ÄÅÊñáÂ≠óÂíåË™ûÈü≥Ôºâ‰∏≠‰ΩøÁî® LASER ÂèØÂ∏∂‰æÜ‰ª•‰∏ãÁõ∏Â∞çÁöÑÊ≥õÂåñÊïàËÉΩÊèêÂçáÔºöImagenet ‰∏äÁöÑË¶ñË¶∫ Transformer (ViT) Ê∫ñÁ¢∫Â∫¶ÊèêÂçá 4.67%ÔºåLibrispeech Ë™ûÈü≥ËΩâÊñáÂ≠ó‰∏äÁöÑ Conformer ÈåØË™§ÁéáÈôç‰Ωé 2.25%ÔºåBERT ‰∏≠‰∏çÊ≠£Á¢∫È†êÊ∏¨ÁöÑÊØî‰æãÈôç‰Ωé 0.93%ÔºåÂèÉÊï∏ÁÇ∫ 22 ÂÑÑ„ÄÇ

##### **LLM Generated Distribution-Based Prediction of US Electoral Results, Part I**
2411.03486v1 by Caleb Bradshaw, Caelen Miller, Sean Warnick

This paper introduces distribution-based prediction, a novel approach to
using Large Language Models (LLMs) as predictive tools by interpreting output
token probabilities as distributions representing the models' learned
representation of the world. This distribution-based nature offers an
alternative perspective for analyzing algorithmic fidelity, complementing the
approach used in silicon sampling. We demonstrate the use of distribution-based
prediction in the context of recent United States presidential election,
showing that this method can be used to determine task specific bias, prompt
noise, and algorithmic fidelity. This approach has significant implications for
assessing the reliability and increasing transparency of LLM-based predictions
across various domains.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥πÂü∫ÊñºÂàÜ‰ΩàÁöÑÈ†êÊ∏¨ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÂèØÈÄèÈÅéÂ∞áËº∏Âá∫‰ª£Âπ£Ê©üÁéáËß£ÈáãÁÇ∫‰ª£Ë°®Ê®°ÂûãÂ≠∏Áøí‰∏ñÁïåË°®ÂæµÁöÑÂàÜ‰ΩàÔºåÂ∞áÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Áî®‰ΩúÈ†êÊ∏¨Â∑•ÂÖ∑„ÄÇÈÄôÁ®ÆÂü∫ÊñºÂàÜ‰ΩàÁöÑÊÄßË≥™Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂàÜÊûêÊºîÁÆóÊ≥ï‰øùÁúüÂ∫¶ÁöÑÊõø‰ª£ËßÄÈªûÔºåË£úÂÖÖ‰∫ÜÂú®ÁüΩÊô∂ÁâáÊäΩÊ®£‰∏≠‰ΩøÁî®ÁöÑÊñπÊ≥ï„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂú®ÊúÄËøëÁæéÂúãÁ∏ΩÁµ±ÈÅ∏ËàâÁöÑËÉåÊôØ‰∏ã‰ΩøÁî®Âü∫ÊñºÂàÜ‰ΩàÁöÑÈ†êÊ∏¨ÔºåË°®ÊòéÊ≠§ÊñπÊ≥ïÂèØÁî®ÊñºÁ¢∫ÂÆöÁâπÂÆö‰ªªÂãôÁöÑÂÅèÂ∑Æ„ÄÅÊèêÁ§∫ÈõúË®äÂíåÊºîÁÆóÊ≥ï‰øùÁúüÂ∫¶„ÄÇÊ≠§ÊñπÊ≥ïÂ∞çË©ï‰º∞ LLM Âü∫ÊñºÈ†êÊ∏¨ÁöÑÂèØÈù†ÊÄß‰ª•ÂèäÊèêÈ´òÂÖ∂Âú®ÂêÑÂÄãÈ†òÂüüÁöÑÈÄèÊòéÂ∫¶ÂÖ∑ÊúâÈáçË¶ÅÊÑèÁæ©„ÄÇ

##### **MetRex: A Benchmark for Verilog Code Metric Reasoning Using LLMs**
2411.03471v1 by Manar Abdelatty, Jingxiao Ma, Sherief Reda

Large Language Models (LLMs) have been applied to various hardware design
tasks, including Verilog code generation, EDA tool scripting, and RTL bug
fixing. Despite this extensive exploration, LLMs are yet to be used for the
task of post-synthesis metric reasoning and estimation of HDL designs. In this
paper, we assess the ability of LLMs to reason about post-synthesis metrics of
Verilog designs. We introduce MetRex, a large-scale dataset comprising 25,868
Verilog HDL designs and their corresponding post-synthesis metrics, namely
area, delay, and static power. MetRex incorporates a Chain of Thought (CoT)
template to enhance LLMs' reasoning about these metrics. Extensive experiments
show that Supervised Fine-Tuning (SFT) boosts the LLM's reasoning capabilities
on average by 37.0\%, 25.3\%, and 25.7\% on the area, delay, and static power,
respectively. While SFT improves performance on our benchmark, it remains far
from achieving optimal results, especially on complex problems. Comparing to
state-of-the-art regression models, our approach delivers accurate
post-synthesis predictions for 17.4\% more designs (within a 5\% error margin),
in addition to offering a 1.7x speedup by eliminating the need for
pre-processing. This work lays the groundwork for advancing LLM-based Verilog
code metric reasoning.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤ÊáâÁî®ÊñºÂêÑÁ®ÆÁ°¨È´îË®≠Ë®à‰ªªÂãôÔºåÂåÖÊã¨ Verilog Á®ãÂºèÁ¢ºÁî¢Áîü„ÄÅEDA Â∑•ÂÖ∑ËÖ≥Êú¨Á∑®ÂØ´Âíå RTL ÈåØË™§‰øÆÊ≠£„ÄÇÂÑòÁÆ°ÊúâÂ¶ÇÊ≠§Âª£Ê≥õÁöÑÊé¢Á¥¢Ôºå‰ΩÜ LLM Â∞öÊú™Áî®ÊñºÂêàÊàêÂæåÊåáÊ®ôÊé®ÁêÜÂíå HDL Ë®≠Ë®à‰º∞Ë®àÁöÑ‰ªªÂãô„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëË©ï‰º∞‰∫Ü LLM Êé®ÁêÜ Verilog Ë®≠Ë®àÂêàÊàêÂæåÊåáÊ®ôÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÂºïÂÖ•‰∫Ü MetRexÔºåÈÄôÊòØ‰∏ÄÂÄãÂåÖÂê´ 25,868 ÂÄã Verilog HDL Ë®≠Ë®àÂèäÂÖ∂Â∞çÊáâÂêàÊàêÂæåÊåáÊ®ôÔºàÈù¢Á©ç„ÄÅÂª∂ÈÅ≤ÂíåÈùúÊÖãÂäüÁéáÔºâÁöÑÂ§ßË¶èÊ®°Ë≥áÊñôÈõÜ„ÄÇMetRex ÁµêÂêà‰∫ÜÊÄùËÄÉÈèà (CoT) ÁØÑÊú¨Ôºå‰ª•Â¢ûÂº∑ LLM Â∞çÈÄô‰∫õÊåáÊ®ôÁöÑÊé®ÁêÜ„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óË°®ÊòéÔºåÊúâÁõ£Áù£ÂæÆË™ø (SFT) Âπ≥ÂùáÊèêÂçá‰∫Ü LLM ÁöÑÊé®ÁêÜËÉΩÂäõÔºåÂàÜÂà•Âú®Èù¢Á©ç„ÄÅÂª∂ÈÅ≤ÂíåÈùúÊÖãÂäüÁéáÊñπÈù¢ÊèêÂçá‰∫Ü 37.0%„ÄÅ25.3% Âíå 25.7%„ÄÇÈõñÁÑ∂ SFT ÊîπÂñÑ‰∫ÜÊàëÂÄëÂü∫Ê∫ñÊ∏¨Ë©¶ÁöÑÊïàËÉΩÔºå‰ΩÜË∑ùÈõ¢ÈÅîÂà∞ÊúÄ‰Ω≥ÁµêÊûú‰ªçÊúâÂæàÂ§ßÂ∑ÆË∑ùÔºåÁâπÂà•ÊòØÂú®Ë§áÈõúÁöÑÂïèÈ°å‰∏ä„ÄÇËàáÊúÄÂÖàÈÄ≤ÁöÑËø¥Ê≠∏Ê®°ÂûãÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÊèê‰æõ‰∫ÜÊ∫ñÁ¢∫ÁöÑÂêàÊàêÂæåÈ†êÊ∏¨ÔºåÈÅ©Áî®ÊñºÂ§ö 17.4% ÁöÑË®≠Ë®àÔºàË™§Â∑ÆÁØÑÂúçÂú® 5% ‰ª•ÂÖßÔºâÔºåÊ≠§Â§ñÈÇÑÈÄöÈÅéÊ∂àÈô§È†êËôïÁêÜÁöÑÈúÄË¶Å‰æÜÊèê‰æõ 1.7 ÂÄçÁöÑÈÄüÂ∫¶ÊèêÂçá„ÄÇÈÄôÈ†ÖÂ∑•‰ΩúÁÇ∫Êé®ÈÄ≤Âü∫Êñº LLM ÁöÑ Verilog Á®ãÂºèÁ¢ºÊåáÊ®ôÊé®ÁêÜÂ•†ÂÆö‰∫ÜÂü∫Á§é„ÄÇ

##### **Watson: A Cognitive Observability Framework for the Reasoning of Foundation Model-Powered Agents**
2411.03455v1 by Benjamin Rombaut, Sogol Masoumzadeh, Kirill Vasilevski, Dayi Lin, Ahmed E. Hassan

As foundation models (FMs) play an increasingly prominent role in complex
software systems, such as FM-powered agentic software (i.e., Agentware), they
introduce significant challenges for developers regarding observability. Unlike
traditional software, agents operate autonomously, using extensive data and
opaque implicit reasoning, making it difficult to observe and understand their
behavior during runtime, especially when they take unexpected actions or
encounter errors. In this paper, we highlight the limitations of traditional
operational observability in the context of FM-powered software, and introduce
cognitive observability as a new type of required observability that has
emerged for such innovative systems. We then propose a novel framework that
provides cognitive observability into the implicit reasoning processes of
agents (a.k.a. reasoning observability), and demonstrate the effectiveness of
our framework in boosting the debuggability of Agentware and, in turn, the
abilities of an Agentware through a case study on AutoCodeRover, a cuttingedge
Agentware for autonomous program improvement.

ÊëòË¶ÅÔºöÈö®ËëóÂü∫Á§éÊ®°Âûã (FM) Âú®Ë§áÈõúËªüÈ´îÁ≥ªÁµ±‰∏≠ÊâÆÊºîË∂ä‰æÜË∂äÈáçË¶ÅÁöÑËßíËâ≤Ôºå‰æãÂ¶Ç FM È©ÖÂãïÁöÑ‰ª£ÁêÜËªüÈ´îÔºàÂç≥ AgentwareÔºâÔºåÂÆÉÂÄëÁÇ∫ÈñãÁôº‰∫∫Âì°Âú®ÂèØËßÄÂØüÊÄßÊñπÈù¢Â∏∂‰æÜ‰∫ÜÈáçÂ§ßÁöÑÊåëÊà∞„ÄÇËàáÂÇ≥Áµ±ËªüÈ´î‰∏çÂêåÔºå‰ª£ÁêÜËªüÈ´î‰ΩøÁî®Â§ßÈáèË≥áÊñôÂíå‰∏çÈÄèÊòéÁöÑÈö±Âê´Êé®ÁêÜÈÄ≤Ë°åËá™‰∏ªÈÅã‰ΩúÔºåÈÄô‰ΩøÂæóÂú®Âü∑Ë°åÊúüÈñìÈõ£‰ª•ËßÄÂØüÂíåÁêÜËß£ÂÆÉÂÄëÁöÑË°åÁÇ∫ÔºåÁâπÂà•ÊòØÂú®ÂÆÉÂÄëÊé°ÂèñÊÑèÂ§ñË°åÂãïÊàñÈÅáÂà∞ÈåØË™§ÊôÇ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂº∑Ë™ø‰∫ÜÂÇ≥Áµ±ÈÅã‰ΩúÂèØËßÄÂØüÊÄßÂú® FM È©ÖÂãïËªüÈ´î‰∏≠ÁöÑÈôêÂà∂Ôºå‰∏¶‰ªãÁ¥π‰∫ÜË™çÁü•ÂèØËßÄÂØüÊÄßÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞È°ûÂûãÁöÑÂøÖÈúÄÂèØËßÄÂØüÊÄßÔºåÂÆÉÂ∑≤Á∂ìÂá∫ÁèæÂú®ÈÄôÈ°ûÂâµÊñ∞Á≥ªÁµ±‰∏≠„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÊ°ÜÊû∂ÔºåÂÆÉÊèê‰æõ‰∫ÜÂ∞ç‰ª£ÁêÜËªüÈ´îÈö±Âê´Êé®ÁêÜÈÅéÁ®ãÁöÑË™çÁü•ÂèØËßÄÂØüÊÄßÔºàÂèàÁ®±Êé®ÁêÜÂèØËßÄÂØüÊÄßÔºâÔºå‰∏¶Â±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑÊ°ÜÊû∂Âú®ÊèêÂçá Agentware ÁöÑÈô§ÈåØËÉΩÂäõÊñπÈù¢ÁöÑÊúâÊïàÊÄßÔºåÈÄ≤ËÄåÈÄèÈÅé‰∏ÄÂÄãÈóúÊñº AutoCodeRover ÁöÑÊ°à‰æãÁ†îÁ©∂ÊèêÂçá‰∫Ü Agentware ÁöÑËÉΩÂäõÔºåAutoCodeRover ÊòØ‰∏ÄÁ®ÆÁî®ÊñºËá™‰∏ªÁ®ãÂºèÊîπÂñÑÁöÑÂ∞ñÁ´Ø Agentware„ÄÇ

##### **Solving Trojan Detection Competitions with Linear Weight Classification**
2411.03445v1 by Todd Huster, Peter Lin, Razvan Stefanescu, Emmanuel Ekwedike, Ritu Chadha

Neural networks can conceal malicious Trojan backdoors that allow a trigger
to covertly change the model behavior. Detecting signs of these backdoors,
particularly without access to any triggered data, is the subject of ongoing
research and open challenges. In one common formulation of the problem, we are
given a set of clean and poisoned models and need to predict whether a given
test model is clean or poisoned. In this paper, we introduce a detector that
works remarkably well across many of the existing datasets and domains. It is
obtained by training a binary classifier on a large number of models' weights
after performing a few different pre-processing steps including feature
selection and standardization, reference model weights subtraction, and model
alignment prior to detection. We evaluate this algorithm on a diverse set of
Trojan detection benchmarks and domains and examine the cases where the
approach is most and least effective.

ÊëòË¶ÅÔºöÁ•ûÁ∂ìÁ∂≤Ë∑ØÂèØ‰ª•Èö±ËóèÊÉ°ÊÑèÁöÑÊú®È¶¨ÂæåÈñÄÔºåÂÖÅË®±Ëß∏ÁôºÂô®ÁßòÂØÜÂú∞ÊîπËÆäÊ®°ÂûãË°åÁÇ∫„ÄÇÂÅµÊ∏¨ÈÄô‰∫õÂæåÈñÄÁöÑË∑°Ë±°ÔºåÁâπÂà•ÊòØÂú®ÁÑ°Ê≥ïÂ≠òÂèñ‰ªª‰ΩïËß∏ÁôºË≥áÊñôÁöÑÊÉÖÊ≥Å‰∏ãÔºåÊòØÊåÅÁ∫åÈÄ≤Ë°åÁöÑÁ†îÁ©∂ÂíåÂÖ¨ÈñãÁöÑÊåëÊà∞„ÄÇÂú®‰∏ÄÂÄãÂ∏∏Ë¶ãÁöÑÂïèÈ°åË°®Ëø∞‰∏≠ÔºåÊàëÂÄëÊúÉÂæóÂà∞‰∏ÄÁµÑ‰πæÊ∑®Âíå‰∏≠ÊØíÁöÑÊ®°ÂûãÔºå‰∏¶ÈúÄË¶ÅÈ†êÊ∏¨Áµ¶ÂÆöÁöÑÊ∏¨Ë©¶Ê®°ÂûãÊòØ‰πæÊ∑®ÈÇÑÊòØ‰∏≠ÊØí„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÂÅµÊ∏¨Âô®ÔºåÂÆÉÂú®Ë®±Â§öÁèæÊúâË≥áÊñôÈõÜÂíåÈ†òÂüü‰∏≠Ë°®ÁèæÂæóÈùûÂ∏∏Â•Ω„ÄÇÂÆÉÊòØÈÄöÈÅéÂú®Â§ßÈáèÊ®°ÂûãÊ¨äÈáç‰∏äË®ìÁ∑¥‰∏ÄÂÄã‰∫åÂÖÉÂàÜÈ°ûÂô®Áç≤ÂæóÁöÑÔºåÂú®Ë®ìÁ∑¥‰πãÂâçÂü∑Ë°å‰∫Ü‰∏Ä‰∫õ‰∏çÂêåÁöÑÈ†êËôïÁêÜÊ≠•È©üÔºåÂåÖÊã¨ÁâπÂæµÈÅ∏ÊìáÂíåÊ®ôÊ∫ñÂåñ„ÄÅÂèÉËÄÉÊ®°ÂûãÊ¨äÈáçÊ∏õÊ≥ïÂíåÊ®°ÂûãÂ∞çÈΩä„ÄÇÊàëÂÄëÂú®ÂêÑÁ®ÆÊú®È¶¨ÂÅµÊ∏¨Âü∫Ê∫ñÂíåÈ†òÂüü‰∏äË©ï‰º∞ÈÄôÂÄãÊºîÁÆóÊ≥ïÔºå‰∏¶Ê™¢Ë¶ñË©≤ÊñπÊ≥ïÊúÄÊúâÊïàÂíåÊúÄÁÑ°ÊïàÁöÑÊÉÖÊ≥Å„ÄÇ

##### **MME-Finance: A Multimodal Finance Benchmark for Expert-level Understanding and Reasoning**
2411.03314v1 by Ziliang Gan, Yu Lu, Dong Zhang, Haohan Li, Che Liu, Jian Liu, Ji Liu, Haipang Wu, Chaoyou Fu, Zenglin Xu, Rongjunchen Zhang, Yong Dai

In recent years, multimodal benchmarks for general domains have guided the
rapid development of multimodal models on general tasks. However, the financial
field has its peculiarities. It features unique graphical images (e.g.,
candlestick charts, technical indicator charts) and possesses a wealth of
specialized financial knowledge (e.g., futures, turnover rate). Therefore,
benchmarks from general fields often fail to measure the performance of
multimodal models in the financial domain, and thus cannot effectively guide
the rapid development of large financial models. To promote the development of
large financial multimodal models, we propose MME-Finance, an bilingual
open-ended and practical usage-oriented Visual Question Answering (VQA)
benchmark. The characteristics of our benchmark are finance and expertise,
which include constructing charts that reflect the actual usage needs of users
(e.g., computer screenshots and mobile photography), creating questions
according to the preferences in financial domain inquiries, and annotating
questions by experts with 10+ years of experience in the financial industry.
Additionally, we have developed a custom-designed financial evaluation system
in which visual information is first introduced in the multi-modal evaluation
process. Extensive experimental evaluations of 19 mainstream MLLMs are
conducted to test their perception, reasoning, and cognition capabilities. The
results indicate that models performing well on general benchmarks cannot do
well on MME-Finance; for instance, the top-performing open-source and
closed-source models obtain 65.69 (Qwen2VL-72B) and 63.18 (GPT-4o),
respectively. Their performance is particularly poor in categories most
relevant to finance, such as candlestick charts and technical indicator charts.
In addition, we propose a Chinese version, which helps compare performance of
MLLMs under a Chinese context.

ÊëòË¶ÅÔºö<paragraph>ËøëÂπ¥‰æÜÔºå‰∏ÄËà¨È†òÂüüÁöÑÂ§öÊ®°ÊÖãÂü∫Ê∫ñÂºïÂ∞éÂ§öÊ®°ÊÖãÊ®°ÂûãÂú®‰∏ÄËà¨‰ªªÂãô‰∏äÂø´ÈÄüÁôºÂ±ï„ÄÇÁÑ∂ËÄåÔºåÈáëËûçÈ†òÂüüÊúâÂÖ∂Áç®ÁâπÊÄß„ÄÇÂÆÉÂÖ∑ÊúâÁç®ÁâπÁöÑÂúñÂΩ¢ÂΩ±ÂÉèÔºà‰æãÂ¶ÇÔºåË†üÁá≠Âúñ„ÄÅÊäÄË°ìÊåáÊ®ôÂúñÔºâÔºå‰∏¶ÊìÅÊúâË±êÂØåÁöÑÂ∞àÊ•≠ÈáëËûçÁü•Ë≠òÔºà‰æãÂ¶ÇÔºåÊúüË≤®„ÄÅÊèõÊâãÁéáÔºâ„ÄÇÂõ†Ê≠§Ôºå‰∏ÄËà¨È†òÂüüÁöÑÂü∫Ê∫ñÂæÄÂæÄÁÑ°Ê≥ïË°°ÈáèÂ§öÊ®°ÊÖãÊ®°ÂûãÂú®ÈáëËûçÈ†òÂüüÁöÑË°®ÁèæÔºåÂæûËÄåÁÑ°Ê≥ïÊúâÊïàÂºïÂ∞éÂ§ßÂûãÈáëËûçÊ®°ÂûãÁöÑÂø´ÈÄüÁôºÂ±ï„ÄÇÁÇ∫‰∫Ü‰øÉÈÄ≤Â§ßÂûãÈáëËûçÂ§öÊ®°ÊÖãÊ®°ÂûãÁöÑÁôºÂ±ïÔºåÊàëÂÄëÊèêÂá∫‰∫Ü MME-FinanceÔºå‰∏ÄÂÄãÈõôË™ûÈñãÊîæÂºè‰∏îÂØ¶Áî®ÁöÑÈù¢Âêë‰ΩøÁî®ÊÉÖÂ¢ÉÁöÑË¶ñË¶∫ÂïèÁ≠îÔºàVQAÔºâÂü∫Ê∫ñ„ÄÇÊàëÂÄëÁöÑÂü∫Ê∫ñÁâπÈªûÁÇ∫ÈáëËûçÂíåÂ∞àÊ•≠ÔºåÂåÖÊã¨ÊßãÂª∫ÂèçÊò†‰ΩøÁî®ËÄÖÂØ¶Èöõ‰ΩøÁî®ÈúÄÊ±ÇÁöÑÂúñË°®Ôºà‰æãÂ¶ÇÔºåÈõªËÖ¶Êà™ÂúñÂíåÊâãÊ©üÊîùÂΩ±ÔºâÔºåÊ†πÊìöÈáëËûçÈ†òÂüüË©¢ÂïèÁöÑÂÅèÂ•ΩÂª∫Á´ãÂïèÈ°åÔºå‰∏¶Áî±ÂÖ∑Êúâ 10 Âπ¥‰ª•‰∏äÈáëËûçÁî¢Ê•≠Á∂ìÈ©óÁöÑÂ∞àÂÆ∂Ë®ªËß£ÂïèÈ°å„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄãÂÆ¢Ë£ΩÂåñÁöÑÈáëËûçË©ïÈáèÁ≥ªÁµ±ÔºåÂú®Â§öÊ®°ÊÖãË©ïÈáèÈÅéÁ®ã‰∏≠È¶ñÊ¨°Â∞éÂÖ•Ë¶ñË¶∫Ë≥áË®ä„ÄÇÂ∞ç 19 ÂÄã‰∏ªÊµÅ MLLM ÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©óË©ï‰º∞Ôºå‰ª•Ê∏¨Ë©¶ÂÆÉÂÄëÁöÑÊÑüÁü•„ÄÅÊé®ÁêÜÂíåË™çÁü•ËÉΩÂäõ„ÄÇÁµêÊûúË°®ÊòéÔºåÂú®‰∏ÄËà¨Âü∫Ê∫ñ‰∏äË°®ÁèæËâØÂ•ΩÁöÑÊ®°ÂûãÁÑ°Ê≥ïÂú® MME-Finance ‰∏äË°®ÁèæËâØÂ•ΩÔºõ‰æãÂ¶ÇÔºåË°®ÁèæÊúÄÂ•ΩÁöÑÈñãÊ∫êÂíåÈñâÊ∫êÊ®°ÂûãÂàÜÂà•Áç≤Âæó 65.69ÔºàQwen2VL-72BÔºâÂíå 63.18ÔºàGPT-4oÔºâ„ÄÇÂÆÉÂÄëÂú®ËàáÈáëËûçÊúÄÁõ∏ÈóúÁöÑÈ°ûÂà•Ôºà‰æãÂ¶ÇÔºåË†üÁá≠ÂúñÂíåÊäÄË°ìÊåáÊ®ôÂúñÔºâ‰∏≠ÁöÑË°®ÁèæÁâπÂà•Â∑Æ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏≠ÊñáÁâàÊú¨ÔºåÊúâÂä©ÊñºÂú®‰∏≠ÊñáË™ûÂ¢É‰∏ãÊØîËºÉ MLLM ÁöÑË°®Áèæ„ÄÇ</paragraph>

##### **Usefulness of LLMs as an Author Checklist Assistant for Scientific Papers: NeurIPS'24 Experiment**
2411.03417v1 by Alexander Goldberg, Ihsan Ullah, Thanh Gia Hieu Khuong, Benedictus Kent Rachmat, Zhen Xu, Isabelle Guyon, Nihar B. Shah

Large language models (LLMs) represent a promising, but controversial, tool
in aiding scientific peer review. This study evaluates the usefulness of LLMs
in a conference setting as a tool for vetting paper submissions against
submission standards. We conduct an experiment at the 2024 Neural Information
Processing Systems (NeurIPS) conference, where 234 papers were voluntarily
submitted to an "LLM-based Checklist Assistant." This assistant validates
whether papers adhere to the author checklist used by NeurIPS, which includes
questions to ensure compliance with research and manuscript preparation
standards. Evaluation of the assistant by NeurIPS paper authors suggests that
the LLM-based assistant was generally helpful in verifying checklist
completion. In post-usage surveys, over 70% of authors found the assistant
useful, and 70% indicate that they would revise their papers or checklist
responses based on its feedback. While causal attribution to the assistant is
not definitive, qualitative evidence suggests that the LLM contributed to
improving some submissions. Survey responses and analysis of re-submissions
indicate that authors made substantive revisions to their submissions in
response to specific feedback from the LLM. The experiment also highlights
common issues with LLMs: inaccuracy (20/52) and excessive strictness (14/52)
were the most frequent issues flagged by authors. We also conduct experiments
to understand potential gaming of the system, which reveal that the assistant
could be manipulated to enhance scores through fabricated justifications,
highlighting potential vulnerabilities of automated review tools.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊòØ‰∏ÄÁ®ÆÊúâÂâçÈÄî‰ΩÜÊúâÁà≠Ë≠∞ÁöÑÂ∑•ÂÖ∑ÔºåÊúâÂä©ÊñºÁßëÂ≠∏ÂêåË°åË©ïÂØ©„ÄÇÊú¨Á†îÁ©∂Ë©ï‰º∞‰∫Ü LLM Âú®ÊúÉË≠∞Áí∞Â¢É‰∏≠‰ΩúÁÇ∫ÂØ©Êü•Ë´ñÊñáÊèê‰∫§ÊòØÂê¶Á¨¶ÂêàÊèê‰∫§Ê®ôÊ∫ñÁöÑÂ∑•ÂÖ∑ÁöÑÊïàÁî®„ÄÇÊàëÂÄëÂú® 2024 Âπ¥Á•ûÁ∂ìË≥áË®äËôïÁêÜÁ≥ªÁµ± (NeurIPS) ÊúÉË≠∞‰∏äÈÄ≤Ë°å‰∫Ü‰∏ÄÈ†ÖÂØ¶È©óÔºåÂÖ∂‰∏≠ 234 ÁØáË´ñÊñáËá™È°òÊèê‰∫§Áµ¶„ÄåÂü∫Êñº LLM ÁöÑÊ†∏Â∞çÊ∏ÖÂñÆÂä©ÁêÜ„Äç„ÄÇÊ≠§Âä©ÁêÜÈ©óË≠âË´ñÊñáÊòØÂê¶Á¨¶Âêà NeurIPS ‰ΩøÁî®ÁöÑ‰ΩúËÄÖÊ†∏Â∞çÊ∏ÖÂñÆÔºåÂÖ∂‰∏≠ÂåÖÊã¨Á¢∫‰øùÁ¨¶ÂêàÁ†îÁ©∂ÂíåÊâãÁ®øÊ∫ñÂÇôÊ®ôÊ∫ñÁöÑÂïèÈ°å„ÄÇNeurIPS Ë´ñÊñá‰ΩúËÄÖÂ∞çÂä©ÁêÜÁöÑË©ï‰º∞Ë°®ÊòéÔºåÂü∫Êñº LLM ÁöÑÂä©ÁêÜÈÄöÂ∏∏ÊúâÂä©ÊñºÈ©óË≠âÊ†∏Â∞çÊ∏ÖÂñÆÂÆåÊàêÊÉÖÊ≥Å„ÄÇÂú®‰ΩøÁî®ÂæåË™øÊü•‰∏≠ÔºåË∂ÖÈÅé 70% ÁöÑ‰ΩúËÄÖÁôºÁèæË©≤Âä©ÁêÜÊúâÁî®ÔºåËÄå 70% Ë°®Á§∫‰ªñÂÄëÊúÉÊ†πÊìöÂÖ∂ÂõûÈ•ã‰øÆÊîπË´ñÊñáÊàñÊ†∏Â∞çÊ∏ÖÂñÆÂõûÊáâ„ÄÇÈõñÁÑ∂ÁÑ°Ê≥ïÊòéÁ¢∫Â∞áÂõ†ÊûúÈóú‰øÇÊ≠∏Âõ†ÊñºÂä©ÁêÜÔºå‰ΩÜÂÆöÊÄßË≠âÊìöË°®ÊòéÔºåLLM ÊúâÂä©ÊñºÊîπÂñÑÊüê‰∫õÊèê‰∫§„ÄÇË™øÊü•ÂõûÊáâÂíåÈáçÊñ∞Êèê‰∫§ÁöÑÂàÜÊûêË°®ÊòéÔºå‰ΩúËÄÖÊ†πÊìö LLM ÁöÑÂÖ∑È´îÂõûÈ•ãÂ∞çÂÖ∂Êèê‰∫§ÈÄ≤Ë°å‰∫ÜÂØ¶Ë≥™ÊÄß‰øÆÊîπ„ÄÇË©≤ÂØ¶È©óÈÇÑÁ™ÅÂá∫‰∫Ü LLM ÁöÑÂ∏∏Ë¶ãÂïèÈ°åÔºö‰∏çÊ∫ñÁ¢∫ (20/52) ÂíåÈÅéÂ∫¶Âö¥Ê†º (14/52) ÊòØ‰ΩúËÄÖÊ®ôË®òÁöÑÊúÄÂ∏∏Ë¶ãÂïèÈ°å„ÄÇÊàëÂÄëÈÇÑÈÄ≤Ë°åÂØ¶È©ó‰ª•‰∫ÜËß£Á≥ªÁµ±ÁöÑÊΩõÂú®ÂçöÂºàÔºåÈÄôË°®ÊòéÂèØ‰ª•ÈÄöÈÅéÊçèÈÄ†ÁöÑÁêÜÁî±‰æÜÊìçÁ∏±Âä©ÁêÜ‰ª•ÊèêÈ´òÂàÜÊï∏ÔºåÂº∑Ë™ø‰∫ÜËá™ÂãïÂåñÂØ©Êü•Â∑•ÂÖ∑ÁöÑÊΩõÂú®ÊºèÊ¥û„ÄÇ

##### **Inference Optimal VLMs Need Only One Visual Token but Larger Models**
2411.03312v1 by Kevin Y. Li, Sachin Goyal, Joao D. Semedo, J. Zico Kolter

Vision Language Models (VLMs) have demonstrated strong capabilities across
various visual understanding and reasoning tasks. However, their real-world
deployment is often constrained by high latency during inference due to
substantial compute required to process the large number of input tokens
(predominantly from the image) by the LLM. To reduce inference costs, one can
either downsize the LLM or reduce the number of input image-tokens, the latter
of which has been the focus of many recent works around token compression.
However, it is unclear what the optimal trade-off is, as both the factors
directly affect the VLM performance. We first characterize this optimal
trade-off between the number of visual tokens and LLM parameters by
establishing scaling laws that capture variations in performance with these two
factors. Our results reveal a surprising trend: for visual reasoning tasks, the
inference-optimal behavior in VLMs, i.e., minimum downstream error at any given
fixed inference compute, is achieved when using the largest LLM that fits
within the inference budget while minimizing visual token count - often to a
single token. While the token reduction literature has mainly focused on
maintaining base model performance by modestly reducing the token count (e.g.,
$5-10\times$), our results indicate that the compute-optimal inference regime
requires operating under even higher token compression ratios. Based on these
insights, we take some initial steps towards building approaches tailored for
high token compression settings. Code is available at
https://github.com/locuslab/llava-token-compression.

ÊëòË¶ÅÔºöË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) Â∑≤Âú®ÂêÑÁ®ÆË¶ñË¶∫ÁêÜËß£ÂíåÊé®ÁêÜ‰ªªÂãô‰∏≠Â±ïÁèæÂº∑Â§ßÁöÑËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåÁî±Êñº LLM ËôïÁêÜÂ§ßÈáèËº∏ÂÖ•‰ª£Á¢º (‰∏ªË¶Å‰æÜËá™ÂΩ±ÂÉè) ÊâÄÈúÄÁöÑÂ§ßÈáèÈÅãÁÆóÔºåÂÖ∂ÂØ¶ÈöõÈÉ®ÁΩ≤ÈÄöÂ∏∏ÊúÉÂèóÂà∞Êé®Ë´ñÊúüÈñìÁöÑÈ´òÂª∂ÈÅ≤ÊâÄÈôêÂà∂„ÄÇÁÇ∫‰∫ÜÈôç‰ΩéÊé®Ë´ñÊàêÊú¨ÔºåÂèØ‰ª•Á∏ÆÂ∞è LLM ÊàñÊ∏õÂ∞ëËº∏ÂÖ•ÂΩ±ÂÉè‰ª£Á¢ºÁöÑÊï∏ÈáèÔºåÂæåËÄÖ‰∏ÄÁõ¥ÊòØË®±Â§öËøëÊúü‰ª£Á¢ºÂ£ìÁ∏ÆÁõ∏ÈóúÂ∑•‰ΩúÁöÑÈáçÈªû„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÂ∞ö‰∏çÊ∏ÖÊ•öÊúÄ‰Ω≥ÁöÑÊäòË°∑ÊñπÊ°àÁÇ∫‰ΩïÔºåÂõ†ÁÇ∫ÈÄôÂÖ©ÂÄãÂõ†Á¥†ÈÉΩÊúÉÁõ¥Êé•ÂΩ±Èüø VLM ÊïàËÉΩ„ÄÇÊàëÂÄëÈ¶ñÂÖàÈÄèÈÅéÂª∫Á´ãÁ∏ÆÊîæÂÆöÂæã‰æÜÊèèËø∞Ë¶ñË¶∫‰ª£Á¢ºÊï∏ÈáèÂíå LLM ÂèÉÊï∏‰πãÈñìÁöÑÊúÄ‰Ω≥ÊäòË°∑Ôºå‰ª•ÊçïÊçâÈÄôÂÖ©ÂÄãÂõ†Á¥†ÊïàËÉΩÁöÑËÆäÂåñ„ÄÇÊàëÂÄëÁöÑÁµêÊûúÊè≠Á§∫‰∫Ü‰∏ÄÂÄã‰ª§‰∫∫È©öË®ùÁöÑË∂®Âã¢ÔºöÂ∞çÊñºË¶ñË¶∫Êé®ÁêÜ‰ªªÂãôÔºåVLM ‰∏≠ÁöÑÊé®Ë´ñÊúÄ‰Ω≥Ë°åÁÇ∫ÔºåÂç≥Âú®‰ªª‰ΩïÁµ¶ÂÆöÁöÑÂõ∫ÂÆöÊé®Ë´ñÈÅãÁÆó‰∏≠ÈÅîÂà∞ÊúÄÂ∞è‰∏ãÊ∏∏Ë™§Â∑ÆÔºåÊòØÂú®‰ΩøÁî®Á¨¶ÂêàÊé®Ë´ñÈ†êÁÆó‰∏îÂêåÊôÇÂ∞áË¶ñË¶∫‰ª£Á¢ºÊï∏ÈáèÈôçËá≥ÊúÄ‰Ωé (ÈÄöÂ∏∏ÁÇ∫ÂñÆ‰∏Ä‰ª£Á¢º) ÁöÑÊúÄÂ§ß LLM ÊôÇÂØ¶ÁèæÁöÑ„ÄÇÈõñÁÑ∂‰ª£Á¢ºÊ∏õÂ∞ëÊñáÁçª‰∏ªË¶ÅÈõÜ‰∏≠Âú®ÈÄèÈÅéÈÅ©Â∫¶Ê∏õÂ∞ë‰ª£Á¢ºÊï∏Èáè (‰æãÂ¶ÇÔºå5-10 ÂÄç) ‰æÜÁ∂≠ÊåÅÂü∫Á§éÊ®°ÂûãÊïàËÉΩÔºå‰ΩÜÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåÈÅãÁÆóÊúÄ‰Ω≥ÁöÑÊé®Ë´ñÊ©üÂà∂ÈúÄË¶ÅÂú®Êõ¥È´òÁöÑ‰ª£Á¢ºÂ£ìÁ∏ÆÊØî‰∏ãÊìç‰Ωú„ÄÇÊ†πÊìöÈÄô‰∫õË¶ãËß£ÔºåÊàëÂÄëÊé°Âèñ‰∫Ü‰∏Ä‰∫õÂàùÊ≠•Ê≠•È©ü‰æÜÂª∫ÊßãÈáùÂ∞çÈ´ò‰ª£Á¢ºÂ£ìÁ∏ÆË®≠ÂÆöÈáèË∫´ÊâìÈÄ†ÁöÑÊñπÊ≥ï„ÄÇÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/locuslab/llava-token-compression ÂèñÂæó„ÄÇ

##### **STEER: Flexible Robotic Manipulation via Dense Language Grounding**
2411.03409v1 by Laura Smith, Alex Irpan, Montserrat Gonzalez Arenas, Sean Kirmani, Dmitry Kalashnikov, Dhruv Shah, Ted Xiao

The complexity of the real world demands robotic systems that can
intelligently adapt to unseen situations. We present STEER, a robot learning
framework that bridges high-level, commonsense reasoning with precise, flexible
low-level control. Our approach translates complex situational awareness into
actionable low-level behavior through training language-grounded policies with
dense annotation. By structuring policy training around fundamental, modular
manipulation skills expressed in natural language, STEER exposes an expressive
interface for humans or Vision-Language Models (VLMs) to intelligently
orchestrate the robot's behavior by reasoning about the task and context. Our
experiments demonstrate the skills learned via STEER can be combined to
synthesize novel behaviors to adapt to new situations or perform completely new
tasks without additional data collection or training.

ÊëòË¶ÅÔºöÁèæÂØ¶‰∏ñÁïåÁöÑË§áÈõúÊÄßË¶ÅÊ±ÇÊ©üÂô®‰∫∫Á≥ªÁµ±ËÉΩÊô∫ÊÖßÂú∞ÈÅ©ÊáâÂâçÊâÄÊú™Ë¶ãÁöÑÊÉÖÊ≥Å„ÄÇÊàëÂÄëÊèêÂá∫ STEERÔºå‰∏ÄÂÄãÊ©üÂô®‰∫∫Â≠∏ÁøíÊû∂ÊßãÔºåÂÆÉÂ∞áÈ´òÂ±§Ê¨°ÁöÑÂ∏∏Ë≠òÊé®ÁêÜËàáÁ≤æÁ¢∫„ÄÅÈùàÊ¥ªÁöÑ‰ΩéÂ±§Ê¨°ÊéßÂà∂ÁµêÂêàËµ∑‰æÜ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÈÄèÈÅéË®ìÁ∑¥‰ª•Ë™ûË®ÄÁÇ∫Âü∫Á§éÁöÑÊîøÁ≠ñÂíåÂØÜÈõÜË®ªËß£ÔºåÂ∞áË§áÈõúÁöÑÊÉÖÂ¢ÉÊÑüÁü•ËΩâÂåñÁÇ∫ÂèØÊìç‰ΩúÁöÑ‰ΩéÂ±§Ê¨°Ë°åÁÇ∫„ÄÇÈÄèÈÅéÂ∞áÊîøÁ≠ñË®ìÁ∑¥Âª∫ÊßãÂú®‰ª•Ëá™ÁÑ∂Ë™ûË®ÄË°®ÈÅîÁöÑÂü∫Êú¨Ê®°ÁµÑÂåñÊìç‰ΩúÊäÄËÉΩ‰∏äÔºåSTEER Êè≠Èú≤‰∫Ü‰∏ÄÂÄãË°®ÁèæÂäõË±êÂØåÁöÑ‰ªãÈù¢Ôºå‰æõ‰∫∫È°ûÊàñË¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÔºàVLMÔºâÈÄèÈÅéÊé®ÁêÜ‰ªªÂãôÂíåÊÉÖÂ¢É‰æÜÊô∫ÊÖßÂú∞ÂçîË™øÊ©üÂô®‰∫∫ÁöÑË°åÁÇ∫„ÄÇÊàëÂÄëÁöÑÂØ¶È©óË≠âÊòéÈÄèÈÅé STEER Â≠∏Âà∞ÁöÑÊäÄËÉΩÂèØ‰ª•ÁµêÂêàËµ∑‰æÜÔºå‰ª•Á∂úÂêàÊñ∞ÁöÑË°åÁÇ∫Ôºå‰ª•ÈÅ©ÊáâÊñ∞ÁöÑÊÉÖÊ≥ÅÊàñÂü∑Ë°åÂÖ®Êñ∞ÁöÑ‰ªªÂãôÔºåËÄåÁÑ°ÈúÄÈ°çÂ§ñÁöÑË≥áÊñôÊî∂ÈõÜÊàñË®ìÁ∑¥„ÄÇ

##### **SAUCE: Synchronous and Asynchronous User-Customizable Environment for Multi-Agent LLM Interaction**
2411.03397v1 by Shlomo Neuberger, Niv Eckhaus, Uri Berger, Amir Taubenfeld, Gabriel Stanovsky, Ariel Goldstein

Many human interactions, such as political debates, are carried out in group
settings, where there are arbitrarily many participants, each with different
views and agendas. To explore such complex social settings, we present SAUCE: a
customizable Python platform, allowing researchers to plug-and-play various
LLMs participating in discussions on any topic chosen by the user. Our platform
takes care of instantiating the models, scheduling their responses, managing
the discussion history, and producing a comprehensive output log, all
customizable through configuration files, requiring little to no coding skills.
A novel feature of SAUCE is our asynchronous communication feature, where
models decide when to speak in addition to what to say, thus modeling an
important facet of human communication. We show SAUCE's attractiveness in two
initial experiments, and invite the community to use it in simulating various
group simulations.

ÊëòË¶ÅÔºöË®±Â§ö‰∫∫È°û‰∫íÂãïÔºå‰æãÂ¶ÇÊîøÊ≤ªËæØË´ñÔºåÈÉΩÂú®Áæ§ÁµÑÁí∞Â¢É‰∏≠ÈÄ≤Ë°åÔºåÂÖ∂‰∏≠Êúâ‰ªªÊÑèÂ§öÂêçÂèÉËàáËÄÖÔºåÊØèÂÄã‰∫∫ÈÉΩÊúâ‰∏çÂêåÁöÑËßÄÈªûÂíåË≠∞Á®ã„ÄÇÁÇ∫‰∫ÜÊé¢Á¥¢Â¶ÇÊ≠§Ë§áÈõúÁöÑÁ§æÊúÉÁí∞Â¢ÉÔºåÊàëÂÄëÊèêÂá∫‰∫Ü SAUCEÔºö‰∏ÄÂÄãÂèØËá™Ë®ÇÁöÑ Python Âπ≥Âè∞ÔºåËÆìÁ†îÁ©∂‰∫∫Âì°ÂèØ‰ª•Âç≥ÊèíÂç≥Áî®ÂêÑÁ®Æ LLMÔºåÂèÉËàá‰ΩøÁî®ËÄÖÈÅ∏ÊìáÁöÑ‰ªª‰Ωï‰∏ªÈ°åË®éË´ñ„ÄÇÊàëÂÄëÁöÑÂπ≥Âè∞Ë≤†Ë≤¨ÂØ¶‰æãÂåñÊ®°Âûã„ÄÅÂÆâÊéíÂÖ∂ÂõûÊáâ„ÄÅÁÆ°ÁêÜË®éË´ñË®òÈåÑÔºå‰∏¶Áî¢ÁîüÂÖ®Èù¢ÁöÑËº∏Âá∫Ë®òÈåÑÔºåÊâÄÊúâÈÄô‰∫õÈÉΩÂèØ‰ª•ÈÄèÈÅéÁµÑÊÖãÊ™îËá™Ë®ÇÔºåÂπæ‰πé‰∏çÈúÄË¶ÅÁ∑®Á¢ºÊäÄËÉΩ„ÄÇSAUCE ÁöÑ‰∏ÄÈ†ÖÊñ∞ÂäüËÉΩÊòØÊàëÂÄëÁöÑÈùûÂêåÊ≠•ÈÄöË®äÂäüËÉΩÔºåÂÖ∂‰∏≠Ê®°ÂûãÈô§‰∫ÜÊ±∫ÂÆöË¶ÅË™™‰ªÄÈ∫º‰πãÂ§ñÔºåÈÇÑÊúÉÊ±∫ÂÆö‰ΩïÊôÇÁôºË®ÄÔºåÂæûËÄåÊ®°Êì¨‰∫∫È°ûÊ∫ùÈÄöÁöÑ‰∏ÄÂÄãÈáçË¶ÅÊñπÈù¢„ÄÇÊàëÂÄëÂú®ÂÖ©ÂÄãÂàùÂßãÂØ¶È©ó‰∏≠Â±ïÁ§∫‰∫Ü SAUCE ÁöÑÂê∏ÂºïÂäõÔºå‰∏¶ÈÇÄË´ãÁ§æÁæ§‰ΩøÁî®ÂÆÉ‰æÜÊ®°Êì¨ÂêÑÁ®ÆÁæ§ÁµÑÊ®°Êì¨„ÄÇ

##### **Exploring Large Language Models for Specialist-level Oncology Care**
2411.03395v1 by Anil Palepu, Vikram Dhillon, Polly Niravath, Wei-Hung Weng, Preethi Prasad, Khaled Saab, Ryutaro Tanno, Yong Cheng, Hanh Mai, Ethan Burns, Zainub Ajmal, Kavita Kulkarni, Philip Mansfield, Dale Webster, Joelle Barral, Juraj Gottweis, Mike Schaekermann, S. Sara Mahdavi, Vivek Natarajan, Alan Karthikesalingam, Tao Tu

Large language models (LLMs) have shown remarkable progress in encoding
clinical knowledge and responding to complex medical queries with appropriate
clinical reasoning. However, their applicability in subspecialist or complex
medical settings remains underexplored. In this work, we probe the performance
of AMIE, a research conversational diagnostic AI system, in the subspecialist
domain of breast oncology care without specific fine-tuning to this challenging
domain. To perform this evaluation, we curated a set of 50 synthetic breast
cancer vignettes representing a range of treatment-naive and
treatment-refractory cases and mirroring the key information available to a
multidisciplinary tumor board for decision-making (openly released with this
work). We developed a detailed clinical rubric for evaluating management plans,
including axes such as the quality of case summarization, safety of the
proposed care plan, and recommendations for chemotherapy, radiotherapy, surgery
and hormonal therapy. To improve performance, we enhanced AMIE with the
inference-time ability to perform web search retrieval to gather relevant and
up-to-date clinical knowledge and refine its responses with a multi-stage
self-critique pipeline. We compare response quality of AMIE with internal
medicine trainees, oncology fellows, and general oncology attendings under both
automated and specialist clinician evaluations. In our evaluations, AMIE
outperformed trainees and fellows demonstrating the potential of the system in
this challenging and important domain. We further demonstrate through
qualitative examples, how systems such as AMIE might facilitate conversational
interactions to assist clinicians in their decision making. However, AMIE's
performance was overall inferior to attending oncologists suggesting that
further research is needed prior to consideration of prospective uses.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Á∑®Á¢ºËá®Â∫äÁü•Ë≠òÂíå‰ª•ÈÅ©Áï∂ÁöÑËá®Â∫äÊé®ÁêÜÂõûÊáâË§áÈõúÁöÑÈÜ´ÁôÇÊü•Ë©¢ÊñπÈù¢Â∑≤Â±ïÁèæÂá∫È°ØËëóÁöÑÈÄ≤Â±ï„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÂú®Ê¨°Â∞àÁßëÊàñË§áÈõúÁöÑÈÜ´ÁôÇÁí∞Â¢É‰∏≠ÁöÑÈÅ©Áî®ÊÄß‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Ë®é„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫Ü AMIE ÁöÑË°®ÁèæÔºåÈÄôÊòØ‰∏ÄÂÄãÁ†îÁ©∂Â∞çË©±ÂºèË®∫Êñ∑ AI Á≥ªÁµ±ÔºåÂú®Ê≤íÊúâÈáùÂ∞çÈÄôÂÄãÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÈ†òÂüüÈÄ≤Ë°åÁâπÂÆöÂæÆË™øÁöÑÊÉÖÊ≥Å‰∏ãÔºåÂú®‰π≥ÊàøËÖ´Áò§Â≠∏Ë≠∑ÁêÜÁöÑÊ¨°Â∞àÁßëÈ†òÂüü‰∏≠„ÄÇÁÇ∫‰∫ÜÂü∑Ë°åÊ≠§Ë©ï‰º∞ÔºåÊàëÂÄëÁ≠ñÂäÉ‰∫Ü‰∏ÄÁµÑ 50 ÂÄãÂêàÊàê‰π≥ÁôåÂ∞èÊèíÊõ≤Ôºå‰ª£Ë°®‰∏ÄÁ≥ªÂàóÊú™Êé•ÂèóÊ≤ªÁôÇÂíåÈõ£Ê≤ªÁöÑÁóÖ‰æãÔºå‰∏¶ÂèçÊò†‰∫ÜÂ§öÂ≠∏ÁßëËÖ´Áò§ÂßîÂì°ÊúÉÂú®Ê±∫Á≠ñÊôÇÂèØÁç≤ÂæóÁöÑÈóúÈçµË≥áË®äÔºàÂÖ¨ÈñãÁôºÂ∏ÉÊ≠§Â∑•‰ΩúÔºâ„ÄÇÊàëÂÄëÂà∂ÂÆö‰∫Ü‰∏ÄÂÄãË©≥Á¥∞ÁöÑËá®Â∫äÊ∫ñÂâáÔºåÁî®ÊñºË©ï‰º∞ÁÆ°ÁêÜË®àÁï´ÔºåÂåÖÊã¨ÁóÖ‰æãÊëòË¶ÅÁöÑÂìÅË≥™„ÄÅÊâÄÂª∫Ë≠∞ÁÖßË≠∑Ë®àÁï´ÁöÑÂÆâÂÖ®ÊÄßÔºå‰ª•ÂèäÂåñÁôÇ„ÄÅÊîæÂ∞ÑÊ≤ªÁôÇ„ÄÅÊâãË°ìÂíåËç∑ÁàæËíôÊ≤ªÁôÇÁöÑÂª∫Ë≠∞Á≠âÈù¢Âêë„ÄÇÁÇ∫‰∫ÜÊèêÂçáË°®ÁèæÔºåÊàëÂÄëÈÄèÈÅéÊé®Ë´ñÊôÇÈñìËÉΩÂäõÂ¢ûÂº∑ AMIEÔºå‰ª•Âü∑Ë°åÁ∂≤Ë∑ØÊêúÂ∞ãÊ™¢Á¥¢ÔºåÊî∂ÈõÜÁõ∏Èóú‰∏îÊúÄÊñ∞ÁöÑËá®Â∫äÁü•Ë≠òÔºå‰∏¶ÈÄèÈÅéÂ§öÈöéÊÆµËá™ÊàëÊâπÂà§ÁÆ°ÈÅìÊîπÂñÑÂÖ∂ÂõûÊáâ„ÄÇÊàëÂÄëÂ∞á AMIE ÁöÑÂõûÊáâÂìÅË≥™ËàáÂÖßÁßë‰ΩèÈô¢ÈÜ´Â∏´„ÄÅËÖ´Áò§ÁßëÁ†îÁ©∂Âì°Âíå‰∏ÄËà¨ËÖ´Áò§Áßë‰∏ªÊ≤ªÈÜ´Â∏´ÈÄ≤Ë°åÊØîËºÉÔºåÂú®Ëá™ÂãïÂåñÂíåÂ∞àÁßëËá®Â∫äÈÜ´Â∏´Ë©ï‰º∞‰∏ãÈÄ≤Ë°å„ÄÇÂú®ÊàëÂÄëÁöÑË©ï‰º∞‰∏≠ÔºåAMIE ÁöÑË°®ÁèæÂÑ™Êñº‰ΩèÈô¢ÈÜ´Â∏´ÂíåÁ†îÁ©∂Âì°ÔºåË≠âÊòé‰∫ÜÁ≥ªÁµ±Âú®ÈÄôÂÄãÂÖ∑ÊúâÊåëÊà∞ÊÄßÂíåÈáçË¶ÅÁöÑÈ†òÂüü‰∏≠ÁöÑÊΩõÂäõ„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÈÄèÈÅéÂÆöÊÄßÁØÑ‰æãË™™ÊòéÔºåÂÉè AMIE ÈÄôÊ®£ÁöÑÁ≥ªÁµ±Â¶Ç‰Ωï‰øÉÈÄ≤Â∞çË©±‰∫íÂãïÔºå‰ª•ÂçîÂä©Ëá®Â∫äÈÜ´Â∏´ÈÄ≤Ë°åÊ±∫Á≠ñ„ÄÇÁÑ∂ËÄåÔºåAMIE ÁöÑË°®ÁèæÊï¥È´îËÄåË®Ä‰∏çÂ¶Ç‰∏ªÊ≤ªËÖ´Áò§ÁßëÈÜ´Â∏´ÔºåÈÄôË°®Á§∫Âú®ËÄÉÊÖÆÊΩõÂú®Áî®ÈÄî‰πãÂâçÔºåÈúÄË¶ÅÈÄ≤Ë°åÈÄ≤‰∏ÄÊ≠•ÁöÑÁ†îÁ©∂„ÄÇ

##### **Neurons for Neutrons: A Transformer Model for Computation Load Estimation on Domain-Decomposed Neutron Transport Problems**
2411.03389v1 by Alexander Mote, Todd Palmer, Lizhong Chen

Domain decomposition is a technique used to reduce memory overhead on large
neutron transport problems. Currently, the optimal load-balanced processor
allocation for these domains is typically determined through small-scale
simulations of the problem, which can be time-consuming for researchers and
must be repeated anytime a problem input is changed. We propose a Transformer
model with a unique 3D input embedding, and input representations designed for
domain-decomposed neutron transport problems, which can predict the subdomain
computation loads generated by small-scale simulations. We demonstrate that
such a model trained on domain-decomposed Small Modular Reactor (SMR)
simulations achieves 98.2% accuracy while being able to skip the small-scale
simulation step entirely. Tests of the model's robustness on variant fuel
assemblies, other problem geometries, and changes in simulation parameters are
also discussed.

ÊëòË¶ÅÔºöÈ†òÂüüÂàÜËß£ÊòØ‰∏ÄÁ®ÆÁî®ÊñºÈôç‰ΩéÂ§ßÂûã‰∏≠Â≠êÂÇ≥Ëº∏ÂïèÈ°åÁöÑË®òÊÜ∂È´îÈñãÈä∑ÁöÑÊäÄË°ì„ÄÇÁõÆÂâçÔºåÈÄô‰∫õÈ†òÂüüÁöÑÊúÄ‰Ω≥Ë≤†ËºâÂπ≥Ë°°ËôïÁêÜÂô®ÈÖçÁΩÆÈÄöÂ∏∏ÈÄèÈÅéÂïèÈ°åÁöÑÂ∞èË¶èÊ®°Ê®°Êì¨‰æÜÊ±∫ÂÆöÔºåÈÄôÂ∞çÁ†îÁ©∂‰∫∫Âì°‰æÜË™™ÂèØËÉΩÂæàËÄóÊôÇÔºåËÄå‰∏îÂøÖÈ†àÂú®ÂïèÈ°åËº∏ÂÖ•Ë¢´ËÆäÊõ¥ÊôÇÈáçË§áÈÄ≤Ë°å„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂÖ∑ÊúâÁç®Áâπ 3D Ëº∏ÂÖ•ÂµåÂÖ•ÂíåËº∏ÂÖ•Ë°®Á§∫ÁöÑ Transformer Ê®°ÂûãÔºåË©≤Ê®°ÂûãÂ∞àÁÇ∫È†òÂüüÂàÜËß£‰∏≠Â≠êÂÇ≥Ëº∏ÂïèÈ°åËÄåË®≠Ë®àÔºåÂèØ‰ª•È†êÊ∏¨Â∞èË¶èÊ®°Ê®°Êì¨Áî¢ÁîüÁöÑÂ≠êÈ†òÂüüË®àÁÆóË≤†Ëºâ„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂú®È†òÂüüÂàÜËß£Â∞èÂûãÊ®°ÁµÑÂåñÂèçÊáâÁàê (SMR) Ê®°Êì¨‰∏äË®ìÁ∑¥ÁöÑÊ≠§È°ûÊ®°ÂûãÂèØÈÅîÂà∞ 98.2% ÁöÑÊ∫ñÁ¢∫Â∫¶ÔºåÂêåÊôÇËÉΩÂ§†ÂÆåÂÖ®Ë∑≥ÈÅéÂ∞èË¶èÊ®°Ê®°Êì¨Ê≠•È©ü„ÄÇÈÇÑË®éË´ñ‰∫ÜÊ®°ÂûãÂ∞çËÆäÁï∞ÁáÉÊñôÁµÑ‰ª∂„ÄÅÂÖ∂‰ªñÂïèÈ°åÂπæ‰ΩïÂΩ¢ÁãÄÂíåÊ®°Êì¨ÂèÉÊï∏ËÆäÂåñÁöÑÈ≠ØÊ£íÊÄßÊ∏¨Ë©¶„ÄÇ

##### **LLMs for Domain Generation Algorithm Detection**
2411.03307v1 by Reynier Leyva La O, Carlos A. Catania, Tatiana Parlanti

This work analyzes the use of large language models (LLMs) for detecting
domain generation algorithms (DGAs). We perform a detailed evaluation of two
important techniques: In-Context Learning (ICL) and Supervised Fine-Tuning
(SFT), showing how they can improve detection. SFT increases performance by
using domain-specific data, whereas ICL helps the detection model to quickly
adapt to new threats without requiring much retraining. We use Meta's Llama3 8B
model, on a custom dataset with 68 malware families and normal domains,
covering several hard-to-detect schemes, including recent word-based DGAs.
Results proved that LLM-based methods can achieve competitive results in DGA
detection. In particular, the SFT-based LLM DGA detector outperforms
state-of-the-art models using attention layers, achieving 94% accuracy with a
4% false positive rate (FPR) and excelling at detecting word-based DGA domains.

ÊëòË¶ÅÔºöÈÄôÈ†ÖÂ∑•‰ΩúÂàÜÊûê‰∫Ü‰ΩøÁî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜÂÅµÊ∏¨Á∂≤ÂüüÂêçÁ®±Áî¢ÁîüÊºîÁÆóÊ≥ï (DGA) ÁöÑÊñπÂºè„ÄÇÊàëÂÄëÂ∞çÂÖ©Á®ÆÈáçË¶ÅÊäÄË°ìÂü∑Ë°åË©≥Á¥∞Ë©ï‰º∞ÔºöË™ûÂ¢ÉÂ≠∏Áøí (ICL) ÂíåÁõ£Áù£ÂæÆË™ø (SFT)ÔºåË™™ÊòéÂÆÉÂÄëÂ¶Ç‰ΩïÊèêÂçáÂÅµÊ∏¨ËÉΩÂäõ„ÄÇSFT ÈÄèÈÅé‰ΩøÁî®ÁâπÂÆöÁ∂≤ÂüüÁöÑË≥áÊñô‰æÜÊèêÂçáÊïàËÉΩÔºåËÄå ICL ÂâáÂçîÂä©ÂÅµÊ∏¨Ê®°ÂûãÂø´ÈÄüÈÅ©ÊáâÊñ∞ÁöÑÂ®ÅËÑÖÔºåËÄåÁÑ°ÈúÄÈÄ≤Ë°åÂ§ßÈáèÈáçÊñ∞Ë®ìÁ∑¥„ÄÇÊàëÂÄëÂú®Ëá™Ë®ÇË≥áÊñôÈõÜ‰∏ä‰ΩøÁî® Meta ÁöÑ Llama3 8B Ê®°ÂûãÔºåË©≤Ë≥áÊñôÈõÜÂåÖÂê´ 68 ÂÄãÊÉ°ÊÑèËªüÈ´îÂÆ∂ÊóèÂíåÊ≠£Â∏∏Á∂≤ÂüüÔºåÊ∂µËìãÂ§öÁ®ÆÈõ£‰ª•ÂÅµÊ∏¨ÁöÑÊñπÊ°àÔºåÂåÖÊã¨ÊúÄËøëÁöÑÂü∫ÊñºÂ≠óË©ûÁöÑ DGA„ÄÇÁµêÊûúË≠âÊòéÔºåÂü∫Êñº LLM ÁöÑÊñπÊ≥ïÂèØ‰ª•Âú® DGA ÂÅµÊ∏¨‰∏≠ÂèñÂæóÂÖ∑Á´∂Áà≠ÂäõÁöÑÁµêÊûú„ÄÇÁâπÂà•ÊòØÔºåÂü∫Êñº SFT ÁöÑ LLM DGA ÂÅµÊ∏¨Âô®ÂÑ™Êñº‰ΩøÁî®Ê≥®ÊÑèÂäõÂ±§ÁöÑÁèæÊúâÊäÄË°ìÔºåÂú® 4% ÁöÑÂÅΩÈôΩÊÄßÁéá (FPR) ‰∏ãÈÅîÂà∞ 94% ÁöÑÊ∫ñÁ¢∫Â∫¶Ôºå‰∏¶‰∏îÊìÖÈï∑ÂÅµÊ∏¨Âü∫ÊñºÂ≠óË©ûÁöÑ DGA Á∂≤Âüü„ÄÇ

##### **VERITAS: A Unified Approach to Reliability Evaluation**
2411.03300v1 by Rajkumar Ramamurthy, Meghana Arakkal Rajeev, Oliver Molenschot, James Zou, Nazneen Rajani

Large language models (LLMs) often fail to synthesize information from their
context to generate an accurate response. This renders them unreliable in
knowledge intensive settings where reliability of the output is key. A critical
component for reliable LLMs is the integration of a robust fact-checking system
that can detect hallucinations across various formats. While several
open-access fact-checking models are available, their functionality is often
limited to specific tasks, such as grounded question-answering or entailment
verification, and they perform less effectively in conversational settings. On
the other hand, closed-access models like GPT-4 and Claude offer greater
flexibility across different contexts, including grounded dialogue
verification, but are hindered by high costs and latency. In this work, we
introduce VERITAS, a family of hallucination detection models designed to
operate flexibly across diverse contexts while minimizing latency and costs.
VERITAS achieves state-of-the-art results considering average performance on
all major hallucination detection benchmarks, with $10\%$ increase in average
performance when compared to similar-sized models and get close to the
performance of GPT4 turbo with LLM-as-a-judge setting.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∏∏Â∏∏ÁÑ°Ê≥ïÂæûÂÖ∂ËÉåÊôØ‰∏≠Á∂úÂêàË≥áË®ä‰æÜÁî¢ÁîüÊ∫ñÁ¢∫ÁöÑÂõûÊáâ„ÄÇÈÄô‰ΩøÂæóÂÆÉÂÄëÂú®Áü•Ë≠òÂØÜÈõÜÂûãÁí∞Â¢É‰∏≠‰∏çÂèØÈù†ÔºåËÄåËº∏Âá∫ÂèØÈù†ÊÄßÊòØÈóúÈçµ„ÄÇÂèØÈù† LLM ÁöÑ‰∏ÄÂÄãÈóúÈçµÁµÑÊàêÈÉ®ÂàÜÊòØÊï¥Âêà‰∏ÄÂÄãÂº∑Â§ßÁöÑ‰∫ãÂØ¶Êü•Ê†∏Á≥ªÁµ±ÔºåÂÆÉÂèØ‰ª•Ë∑®ÂêÑÁ®ÆÊ†ºÂºèÊ™¢Ê∏¨ÂπªË¶∫„ÄÇÈõñÁÑ∂ÊúâÂπæÂÄãÈñãÊîæÁç≤ÂèñÁöÑ‰∫ãÂØ¶Êü•Ê†∏Ê®°ÂûãÂèØÁî®Ôºå‰ΩÜÂÆÉÂÄëÁöÑÂäüËÉΩÈÄöÂ∏∏ÂÉÖÈôêÊñºÁâπÂÆö‰ªªÂãôÔºå‰æãÂ¶ÇÊúâÊ†πÊìöÁöÑÂïèÈ°åËß£Á≠îÊàñËòäÊ∂µÈ©óË≠âÔºå‰∏¶‰∏îÂÆÉÂÄëÂú®Â∞çË©±Áí∞Â¢É‰∏≠ÁöÑË°®ÁèæËºÉÂ∑Æ„ÄÇÂè¶‰∏ÄÊñπÈù¢ÔºåÂÉè GPT-4 Âíå Claude ÈÄôÊ®£ÁöÑÂ∞ÅÈñâË®™ÂïèÊ®°ÂûãÂú®‰∏çÂêåËÉåÊôØ‰∏ãÊèê‰æõ‰∫ÜÊõ¥Â§ßÁöÑÈùàÊ¥ªÊÄßÔºåÂåÖÊã¨ÊúâÊ†πÊìöÁöÑÂ∞çË©±È©óË≠âÔºå‰ΩÜÂèóÂà∞È´òÊàêÊú¨ÂíåÂª∂ÈÅ≤ÁöÑÈòªÁ§ô„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü VERITASÔºåÈÄôÊòØ‰∏ÄÂÄãÂπªË¶∫Ê™¢Ê∏¨Ê®°ÂûãÁ≥ªÂàóÔºåÊó®Âú®ÈùàÊ¥ªÂú∞Âú®‰∏çÂêåËÉåÊôØ‰∏ãÈÅã‰ΩúÔºåÂêåÊôÇÊúÄÂ§ßÈôêÂ∫¶Âú∞Ê∏õÂ∞ëÂª∂ÈÅ≤ÂíåÊàêÊú¨„ÄÇVERITAS Âú®ÊâÄÊúâ‰∏ªË¶ÅÂπªË¶∫Ê™¢Ê∏¨Âü∫Ê∫ñ‰∏äËÄÉÊÖÆÂπ≥ÂùáÊÄßËÉΩËÄåÁç≤ÂæóÊúÄÂÖàÈÄ≤ÁöÑÁµêÊûúÔºåËàáÈ°û‰ººÂ§ßÂ∞èÁöÑÊ®°ÂûãÁõ∏ÊØîÔºåÂπ≥ÂùáÊÄßËÉΩÊèêÈ´ò‰∫Ü 10%Ôºå‰∏¶‰∏îÊé•ËøëÂú® LLM ‰ΩúÁÇ∫Ë©ïÂØ©Ë®≠ÂÆö‰∏ã‰ΩøÁî® GPT4 turbo ÁöÑÊÄßËÉΩ„ÄÇ

##### **Interaction2Code: How Far Are We From Automatic Interactive Webpage Generation?**
2411.03292v1 by Jingyu Xiao, Yuxuan Wan, Yintong Huo, Zhiyao Xu, Michael R. Lyu

Converting webpage design into functional UI code is a critical step for
building websites, which can be labor-intensive and time-consuming. To automate
this design-to-code transformation process, various automated methods using
learning-based networks and multi-modal large language models (MLLMs) have been
proposed. However, these studies were merely evaluated on a narrow range of
static web pages and ignored dynamic interaction elements, making them less
practical for real-world website deployment.
  To fill in the blank, we present the first systematic investigation of MLLMs
in generating interactive webpages. Specifically, we first formulate the
Interaction-to-Code task and build the Interaction2Code benchmark that contains
97 unique web pages and 213 distinct interactions, spanning 15 webpage types
and 30 interaction categories. We then conduct comprehensive experiments on
three state-of-the-art (SOTA) MLLMs using both automatic metrics and human
evaluations, thereby summarizing six findings accordingly. Our experimental
results highlight the limitations of MLLMs in generating fine-grained
interactive features and managing interactions with complex transformations and
subtle visual modifications. We further analyze failure cases and their
underlying causes, identifying 10 common failure types and assessing their
severity. Additionally, our findings reveal three critical influencing factors,
i.e., prompts, visual saliency, and textual descriptions, that can enhance the
interaction generation performance of MLLMs. Based on these findings, we elicit
implications for researchers and developers, providing a foundation for future
advancements in this field. Datasets and source code are available at
https://github.com/WebPAI/Interaction2Code.

ÊëòË¶ÅÔºö<paragraph>Â∞áÁ∂≤È†ÅË®≠Ë®àËΩâÊèõÁÇ∫ÂäüËÉΩÊÄß UI Á®ãÂºèÁ¢ºÊòØÂª∫ÁΩÆÁ∂≤Á´ôÁöÑÈóúÈçµÊ≠•È©üÔºåÈÄôÂèØËÉΩÊòØÈúÄË¶ÅÂ§ßÈáè‰∫∫Âäõ‰∏îËÄóÊôÇÁöÑ„ÄÇÁÇ∫‰∫ÜËá™ÂãïÂåñÊ≠§Ë®≠Ë®àÂà∞Á®ãÂºèÁ¢ºÁöÑËΩâÊèõÁ®ãÂ∫èÔºåÂ∑≤ÊèêÂá∫ÂêÑÁ®Æ‰ΩøÁî®Âü∫ÊñºÂ≠∏ÁøíÁöÑÁ∂≤Ë∑ØÂíåÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) ÁöÑËá™ÂãïÂåñÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÁ†îÁ©∂ÂÉÖÈáùÂ∞çÁØÑÂúçÁãπÁ™ÑÁöÑÈùúÊÖãÁ∂≤È†ÅÈÄ≤Ë°åË©ï‰º∞Ôºå‰∏¶ÂøΩÁï•ÂãïÊÖã‰∫íÂãïÂÖÉÁ¥†ÔºåÈÄô‰ΩøÂæóÂÆÉÂÄëÂ∞çÊñºÂØ¶Èöõ‰∏ñÁïåÁöÑÁ∂≤Á´ôÈÉ®ÁΩ≤ËÄåË®ÄËºÉ‰∏çÂØ¶Áî®„ÄÇ
ÁÇ∫‰∫ÜÂ°´Ë£úÁ©∫ÁôΩÔºåÊàëÂÄëÊèêÂá∫Á¨¨‰∏ÄÂÄãÁ≥ªÁµ±ÊÄßÂú∞Ë™øÊü• MLLM Âú®Áî¢Áîü‰∫íÂãïÂºèÁ∂≤È†Å‰∏≠ÁöÑÁ†îÁ©∂„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÈ¶ñÂÖàÂà∂ÂÆö‰∫íÂãïÂà∞Á®ãÂºèÁ¢º‰ªªÂãôÔºå‰∏¶Âª∫ÁΩÆÂåÖÂê´ 97 ÂÄãÁç®ÁâπÁ∂≤È†ÅÂíå 213 ÂÄã‰∏çÂêå‰∫íÂãïÁöÑ Interaction2Code Âü∫Ê∫ñÔºåÊ∂µËìã 15 ÂÄãÁ∂≤È†ÅÈ°ûÂûãÂíå 30 ÂÄã‰∫íÂãïÈ°ûÂà•„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄë‰ΩøÁî®Ëá™ÂãïÂåñÊåáÊ®ôÂíå‰∫∫Â∑•Ë©ï‰º∞Â∞ç‰∏âÂÄãÊúÄÂÖàÈÄ≤ (SOTA) ÁöÑ MLLM ÈÄ≤Ë°åÂÖ®Èù¢ÂØ¶È©óÔºå‰∏¶ÊìöÊ≠§Á∏ΩÁµêÂÖ≠È†ÖÁôºÁèæ„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúÁ™ÅÈ°ØÂá∫ MLLM Âú®Áî¢ÁîüÁ¥∞Á∑ªÁöÑ‰∫íÂãïÂºèÂäüËÉΩ‰ª•ÂèäÁÆ°ÁêÜËàáË§áÈõúËΩâÊèõÂíåÂæÆÂ¶ôË¶ñË¶∫‰øÆÊîπÁöÑ‰∫íÂãïÊñπÈù¢ÁöÑÈôêÂà∂„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÂàÜÊûêÂ§±ÊïóÊ°à‰æãÂèäÂÖ∂Ê†πÊú¨ÂéüÂõ†ÔºåÊâæÂá∫ 10 Á®ÆÂ∏∏Ë¶ãÁöÑÂ§±ÊïóÈ°ûÂûã‰∏¶Ë©ï‰º∞ÂÖ∂Âö¥ÈáçÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÁôºÁèæÊè≠Á§∫‰∫Ü‰∏âÂÄãÈóúÈçµÁöÑÂΩ±ÈüøÂõ†Á¥†ÔºåÂç≥ÊèêÁ§∫„ÄÅË¶ñË¶∫È°ØËëóÊÄßÂíåÊñáÂ≠óÊèèËø∞ÔºåÂÆÉÂÄëÂèØ‰ª•Â¢ûÂº∑ MLLM ÁöÑ‰∫íÂãïÁî¢ÁîüÊïàËÉΩ„ÄÇÊ†πÊìöÈÄô‰∫õÁôºÁèæÔºåÊàëÂÄëÂºïÂá∫Â∞çÁ†îÁ©∂‰∫∫Âì°ÂíåÈñãÁôº‰∫∫Âì°ÁöÑÂïüÁ§∫ÔºåÁÇ∫Ê≠§È†òÂüüÁöÑÊú™‰æÜÈÄ≤Â±ïÂ•†ÂÆöÂü∫Á§é„ÄÇË≥áÊñôÈõÜÂíåÂéüÂßãÁ®ãÂºèÁ¢ºÂèØÂú® https://github.com/WebPAI/Interaction2Code ÂèñÂæó„ÄÇ</paragraph>

##### **The Future of Intelligent Healthcare: A Systematic Analysis and Discussion on the Integration and Impact of Robots Using Large Language Models for Healthcare**
2411.03287v1 by Souren Pashangpour, Goldie Nejat

The potential use of large language models (LLMs) in healthcare robotics can
help address the significant demand put on healthcare systems around the world
with respect to an aging demographic and a shortage of healthcare
professionals. Even though LLMs have already been integrated into medicine to
assist both clinicians and patients, the integration of LLMs within healthcare
robots has not yet been explored for clinical settings. In this perspective
paper, we investigate the groundbreaking developments in robotics and LLMs to
uniquely identify the needed system requirements for designing health specific
LLM based robots in terms of multi modal communication through human robot
interactions (HRIs), semantic reasoning, and task planning. Furthermore, we
discuss the ethical issues, open challenges, and potential future research
directions for this emerging innovative field.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÈÜ´ÁôÇ‰øùÂÅ•Ê©üÂô®‰∫∫‰∏≠ÊΩõÂú®ÁöÑÊáâÁî®ÔºåÊúâÂä©ÊñºÊªøË∂≥ÂÖ®ÁêÉÈÜ´ÁôÇ‰øùÂÅ•Á≥ªÁµ±Â∞çÊáâËÄÅÈΩ°Âåñ‰∫∫Âè£ÂíåÈÜ´ÁôÇ‰øùÂÅ•Â∞àÊ•≠‰∫∫Âì°Áü≠Áº∫ÂïèÈ°åÁöÑÈáçÂ§ßÈúÄÊ±Ç„ÄÇÂÑòÁÆ° LLM Â∑≤Êï¥ÂêàÂà∞ÈÜ´ÁôÇÈ†òÂüü‰∏≠Ôºå‰ª•ÂçîÂä©Ëá®Â∫äÈÜ´ÁîüÂíåÊÇ£ËÄÖÔºå‰ΩÜ LLM Âú®ÈÜ´ÁôÇ‰øùÂÅ•Ê©üÂô®‰∫∫‰∏≠ÁöÑÊï¥ÂêàÂ∞öÊú™ÈáùÂ∞çËá®Â∫äÁí∞Â¢ÉÈÄ≤Ë°åÊé¢Ë®é„ÄÇÂú®Ê≠§ËßÄÈªûË´ñÊñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éÊ©üÂô®‰∫∫Âíå LLM ÁöÑÂâµÊñ∞ÁôºÂ±ïÔºå‰ª•Áç®ÁâπÂú∞ÊâæÂá∫Ë®≠Ë®àÁâπÂÆöÊñºÂÅ•Â∫∑ÁöÑ LLM Ê©üÂô®‰∫∫ÁöÑÁ≥ªÁµ±ÈúÄÊ±ÇÔºåÂåÖÊã¨ÈÄèÈÅé‰∫∫Ê©ü‰∫íÂãï (HRI)„ÄÅË™ûÁæ©Êé®ÁêÜÂíå‰ªªÂãôË¶èÂäÉÁöÑÂ§öÊ®°ÂºèÊ∫ùÈÄö„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË®éË´ñ‰∫ÜÈÄôÂÄãÊñ∞ËààÂâµÊñ∞È†òÂüüÁöÑÂÄ´ÁêÜË≠∞È°å„ÄÅÈñãÊîæÊÄßÊåëÊà∞ÂíåÊΩõÂú®ÁöÑÊú™‰æÜÁ†îÁ©∂ÊñπÂêë„ÄÇ

##### **SMoA: Improving Multi-agent Large Language Models with Sparse Mixture-of-Agents**
2411.03284v1 by Dawei Li, Zhen Tan, Peijia Qian, Yifan Li, Kumar Satvik Chaudhary, Lijie Hu, Jiayi Shen

While multi-agent systems have been shown to significantly enhance the
performance of Large Language Models (LLMs) across various tasks and
applications, the dense interaction between scaling agents potentially hampers
their efficiency and diversity. To address these challenges, we draw
inspiration from the sparse mixture-of-agents (SMoE) and propose a sparse
mixture-of-agents (SMoA) framework to improve the efficiency and diversity of
multi-agent LLMs. Unlike completely connected structures, SMoA introduces novel
Response Selection and Early Stopping mechanisms to sparsify information flows
among individual LLM agents, striking a balance between performance and
efficiency. Additionally, inspired by the expert diversity principle in SMoE
frameworks for workload balance between experts, we assign distinct role
descriptions to each LLM agent, fostering diverse and divergent thinking.
Extensive experiments on reasoning, alignment, and fairness benchmarks
demonstrate that SMoA achieves performance comparable to traditional
mixture-of-agents approaches but with significantly lower computational costs.
Further analysis reveals that SMoA is more stable, has a greater capacity to
scale, and offers considerable potential through hyper-parameter optimization.
Code and data will be available at: https://github.com/David-Li0406/SMoA.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§öÊô∫ËÉΩÈ´îÁ≥ªÁµ±Â∑≤Ë¢´Ë≠âÊòéËÉΩÈ°ØËëóÊèêÂçáÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂêÑÁ®Æ‰ªªÂãôÂíåÊáâÁî®‰∏≠ÁöÑÊïàËÉΩÔºå‰ΩÜÊì¥ÂÖÖÊô∫ËÉΩÈ´î‰πãÈñìÁöÑÂØÜÈõÜ‰∫íÂãïÊΩõÂú®ÊúÉÈòªÁ§ôÂÖ∂ÊïàÁéáÂíåÂ§öÊ®£ÊÄß„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÊàëÂÄëÂæûÁ®ÄÁñèÊ∑∑ÂêàÊô∫ËÉΩÈ´î (SMoE) Ê±≤ÂèñÈùàÊÑüÔºå‰∏¶ÊèêÂá∫‰∏ÄÂÄãÁ®ÄÁñèÊ∑∑ÂêàÊô∫ËÉΩÈ´î (SMoA) Êû∂Êßã‰æÜÊèêÂçáÂ§öÊô∫ËÉΩÈ´î LLM ÁöÑÊïàÁéáÂíåÂ§öÊ®£ÊÄß„ÄÇËàáÂÆåÂÖ®ÈÄ£Êé•ÁöÑÁµêÊßã‰∏çÂêåÔºåSMoA ÂºïÈÄ≤‰∫ÜÊñ∞Á©éÁöÑÂõûÊáâÈÅ∏ÊìáÂíåÊèêÂâçÂÅúÊ≠¢Ê©üÂà∂Ôºå‰ª•Á®ÄÁñèÂåñÂÄãÂà• LLM Êô∫ËÉΩÈ´î‰πãÈñìÁöÑË≥áË®äÊµÅÔºåÂú®ÊïàËÉΩÂíåÊïàÁéá‰πãÈñìÂèñÂæóÂπ≥Ë°°„ÄÇÊ≠§Â§ñÔºåÂú® SMoE Êû∂Êßã‰∏≠ÂèóÂà∞Â∞àÂÆ∂Â§öÊ®£ÊÄßÂéüÂâáÁöÑÂïüÁôºÔºå‰ª•Âπ≥Ë°°Â∞àÂÆ∂‰πãÈñìÁöÑÂ∑•‰ΩúË≤†ËºâÔºåÊàëÂÄëÁÇ∫ÊØèÂÄã LLM Êô∫ËÉΩÈ´îÂàÜÈÖç‰∫Ü‰∏çÂêåÁöÑËßíËâ≤ÊèèËø∞Ôºå‰ª•‰øÉÈÄ≤Â§öÊ®£ÂåñÂíåÁôºÊï£ÊÄßÊÄùËÄÉ„ÄÇÂú®Êé®ÁêÜ„ÄÅÂ∞çÈΩäÂíåÂÖ¨Âπ≥Âü∫Ê∫ñ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòéÔºåSMoA ÈÅîÂà∞‰∫ÜËàáÂÇ≥Áµ±Ê∑∑ÂêàÊô∫ËÉΩÈ´îÊñπÊ≥ïÁõ∏Áï∂ÁöÑÊïàËÉΩÔºå‰ΩÜË®àÁÆóÊàêÊú¨ÂçªÈ°ØËëóÈôç‰Ωé„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑÂàÜÊûêÈ°ØÁ§∫ÔºåSMoA Êõ¥Âä†Á©©ÂÆöÔºåÂÖ∑ÊúâÊõ¥Â§ßÁöÑÊì¥ÂÖÖËÉΩÂäõÔºå‰∏¶ÈÄèÈÅéË∂ÖÂèÉÊï∏ÊúÄ‰Ω≥ÂåñÊèê‰æõ‰∫ÜÂèØËßÄÁöÑÊΩõÂäõ„ÄÇÁ®ãÂºèÁ¢ºÂíåË≥áÊñôÂ∞áÊñº‰ª•‰∏ãÁ∂≤ÂùÄÊèê‰æõÔºöhttps://github.com/David-Li0406/SMoA„ÄÇ

##### **Causal Responsibility Attribution for Human-AI Collaboration**
2411.03275v1 by Yahang Qi, Bernhard Sch√∂lkopf, Zhijing Jin

As Artificial Intelligence (AI) systems increasingly influence
decision-making across various fields, the need to attribute responsibility for
undesirable outcomes has become essential, though complicated by the complex
interplay between humans and AI. Existing attribution methods based on actual
causality and Shapley values tend to disproportionately blame agents who
contribute more to an outcome and rely on real-world measures of
blameworthiness that may misalign with responsible AI standards. This paper
presents a causal framework using Structural Causal Models (SCMs) to
systematically attribute responsibility in human-AI systems, measuring overall
blameworthiness while employing counterfactual reasoning to account for agents'
expected epistemic levels. Two case studies illustrate the framework's
adaptability in diverse human-AI collaboration scenarios.

ÊëòË¶ÅÔºöÈö®Ëëó‰∫∫Â∑•Êô∫ÊÖß (AI) Á≥ªÁµ±Ë∂ä‰æÜË∂äÂΩ±ÈüøÂêÑÂÄãÈ†òÂüüÁöÑÊ±∫Á≠ñÂà∂ÂÆöÔºåÁÇ∫‰∏çËâØÂæåÊûúÊ≠∏Â±¨Ë≤¨‰ªªÁöÑÈúÄÊ±ÇÂ∑≤ËÆäÂæóËá≥ÈóúÈáçË¶ÅÔºåÂÑòÁÆ°‰∫∫È°ûËàá AI ‰πãÈñìÁöÑË§áÈõú‰∫§‰∫í‰ΩúÁî®ËÆìÈÄô‰ª∂‰∫ãËÆäÂæóË§áÈõú„ÄÇÁèæÊúâÁöÑÊ≠∏Âõ†ÊñπÊ≥ïÂü∫ÊñºÂØ¶ÈöõÂõ†ÊûúÈóú‰øÇÂíå Shapley ÂÄºÔºåÂæÄÂæÄÊúÉÂ∞çÂ∞çÁµêÊûúË≤¢ÁçªËºÉÂ§öÁöÑ‰ª£ÁêÜ‰∫∫ÈÅéÂ∫¶Ê≠∏ÂíéÔºå‰∏¶‰æùË≥¥ÊñºÂèØËÉΩËàáË≤†Ë≤¨‰ªªÁöÑ AI Ê®ôÊ∫ñ‰∏çÁ¨¶ÁöÑÁèæÂØ¶‰∏ñÁïåË≤¨Èõ£Á®ãÂ∫¶Ë°°Èáè„ÄÇÊú¨ÊñáÊèêÂá∫‰∏ÄÂÄã‰ΩøÁî®ÁµêÊßãÂõ†ÊûúÊ®°Âûã (SCM) ÁöÑÂõ†ÊûúÊ°ÜÊû∂Ôºå‰ª•Á≥ªÁµ±ÊÄßÂú∞Â∞áË≤¨‰ªªÊ≠∏Âõ†Êñº‰∫∫È°û AI Á≥ªÁµ±ÔºåË°°ÈáèÊï¥È´îË≤¨Èõ£Á®ãÂ∫¶ÔºåÂêåÊôÇÊé°Áî®Âèç‰∫ãÂØ¶Êé®ÁêÜ‰æÜËÄÉÈáè‰ª£ÁêÜ‰∫∫ÁöÑÈ†êÊúüË™çË≠òÂ±§Á¥ö„ÄÇÂÖ©ÂÄãÊ°à‰æãÁ†îÁ©∂Ë™™Êòé‰∫ÜË©≤Ê°ÜÊû∂Âú®‰∏çÂêå‰∫∫È°û AI Âçî‰ΩúÊÉÖÂ¢É‰∏≠ÁöÑÈÅ©ÊáâÊÄß„ÄÇ

