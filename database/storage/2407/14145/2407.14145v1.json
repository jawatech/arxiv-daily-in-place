{"2407.14145": {"publish_time": "2024-07-19", "title": "PassTSL: Modeling Human-Created Passwords through Two-Stage Learning", "paper_summary": "Textual passwords are still the most widely used user authentication\nmechanism. Due to the close connections between textual passwords and natural\nlanguages, advanced technologies in natural language processing (NLP) and\nmachine learning (ML) could be used to model passwords for different purposes\nsuch as studying human password-creation behaviors and developing more advanced\npassword cracking methods for informing better defence mechanisms. In this\npaper, we propose PassTSL (modeling human-created Passwords through Two-Stage\nLearning), inspired by the popular pretraining-finetuning framework in NLP and\ndeep learning (DL). We report how different pretraining settings affected\nPassTSL and proved its effectiveness by applying it to six large leaked\npassword databases. Experimental results showed that it outperforms five\nstate-of-the-art (SOTA) password cracking methods on password guessing by a\nsignificant margin ranging from 4.11% to 64.69% at the maximum point. Based on\nPassTSL, we also implemented a password strength meter (PSM), and our\nexperiments showed that it was able to estimate password strength more\naccurately, causing fewer unsafe errors (overestimating the password strength)\nthan two other SOTA PSMs when they produce the same rate of safe errors\n(underestimating the password strength): a neural-network based method and\nzxcvbn. Furthermore, we explored multiple finetuning settings, and our\nevaluations showed that, even a small amount of additional training data, e.g.,\nonly 0.1% of the pretrained data, can lead to over 3% improvement in password\nguessing on average. We also proposed a heuristic approach to selecting\nfinetuning passwords based on JS (Jensen-Shannon) divergence and experimental\nresults validated its usefulness. In summary, our contributions demonstrate the\npotential and feasibility of applying advanced NLP and ML methods to password\nmodeling and cracking.", "paper_summary_zh": "\u6587\u5b57\u5bc6\u78bc\u4ecd\u662f\u6700\u5ee3\u6cdb\u4f7f\u7528\u7684\u4f7f\u7528\u8005\u9a57\u8b49\u6a5f\u5236\u3002\u7531\u65bc\u6587\u5b57\u5bc6\u78bc\u8207\u81ea\u7136\u8a9e\u8a00\u4e4b\u9593\u7684\u7dca\u5bc6\u95dc\u806f\uff0c\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u548c\u6a5f\u5668\u5b78\u7fd2 (ML) \u7684\u5148\u9032\u6280\u8853\u53ef\u7528\u65bc\u5efa\u6a21\u5bc6\u78bc\uff0c\u4ee5\u9054\u6210\u4e0d\u540c\u7684\u76ee\u7684\uff0c\u4f8b\u5982\u7814\u7a76\u4eba\u985e\u5bc6\u78bc\u5efa\u7acb\u884c\u70ba\uff0c\u4ee5\u53ca\u958b\u767c\u66f4\u9032\u968e\u7684\u5bc6\u78bc\u7834\u89e3\u65b9\u6cd5\uff0c\u4ee5\u63d0\u4f9b\u66f4\u4f73\u7684\u9632\u79a6\u6a5f\u5236\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa PassTSL\uff08\u900f\u904e\u5169\u968e\u6bb5\u5b78\u7fd2\u5efa\u6a21\u4eba\u985e\u5efa\u7acb\u7684\u5bc6\u78bc\uff09\uff0c\u5176\u9748\u611f\u4f86\u81ea NLP \u548c\u6df1\u5ea6\u5b78\u7fd2 (DL) \u4e2d\u5ee3\u6cdb\u4f7f\u7528\u7684\u9810\u8a13\u7df4\u5fae\u8abf\u67b6\u69cb\u3002\u6211\u5011\u5831\u544a\u4e86\u4e0d\u540c\u7684\u9810\u8a13\u7df4\u8a2d\u5b9a\u5982\u4f55\u5f71\u97ff PassTSL\uff0c\u4e26\u900f\u904e\u5c07\u5176\u61c9\u7528\u65bc\u516d\u500b\u5927\u578b\u5916\u6d29\u5bc6\u78bc\u8cc7\u6599\u5eab\u4f86\u8b49\u660e\u5176\u6709\u6548\u6027\u3002\u5be6\u9a57\u7d50\u679c\u986f\u793a\uff0c\u5b83\u5728\u5bc6\u78bc\u731c\u6e2c\u65b9\u9762\u512a\u65bc\u4e94\u7a2e\u6700\u5148\u9032 (SOTA) \u7684\u5bc6\u78bc\u7834\u89e3\u65b9\u6cd5\uff0c\u6700\u5927\u9ede\u7684\u986f\u8457\u5e45\u5ea6\u4ecb\u65bc 4.11% \u5230 64.69%\u3002\u57fa\u65bc PassTSL\uff0c\u6211\u5011\u4e5f\u5be6\u4f5c\u4e86\u4e00\u500b\u5bc6\u78bc\u5f37\u5ea6\u8a08 (PSM)\uff0c\u800c\u6211\u5011\u7684\u5be6\u9a57\u986f\u793a\uff0c\u5b83\u80fd\u5920\u66f4\u6e96\u78ba\u5730\u4f30\u8a08\u5bc6\u78bc\u5f37\u5ea6\uff0c\u7576\u7522\u751f\u76f8\u540c\u6bd4\u7387\u7684\u5b89\u5168\u932f\u8aa4\uff08\u4f4e\u4f30\u5bc6\u78bc\u5f37\u5ea6\uff09\u6642\uff0c\u9020\u6210\u7684\u975e\u5b89\u5168\u932f\u8aa4\uff08\u9ad8\u4f30\u5bc6\u78bc\u5f37\u5ea6\uff09\u6bd4\u5176\u4ed6\u5169\u500b SOTA PSM \u5c11\uff1a\u4e00\u7a2e\u57fa\u65bc\u795e\u7d93\u7db2\u8def\u7684\u65b9\u6cd5\u548c zxcvbn\u3002\u6b64\u5916\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u591a\u7a2e\u5fae\u8abf\u8a2d\u5b9a\uff0c\u800c\u6211\u5011\u7684\u8a55\u4f30\u986f\u793a\uff0c\u5373\u4f7f\u5c11\u91cf\u7684\u984d\u5916\u8a13\u7df4\u8cc7\u6599\uff0c\u4f8b\u5982\u50c5\u70ba\u9810\u8a13\u7df4\u8cc7\u6599\u7684 0.1%\uff0c\u5e73\u5747\u800c\u8a00\u4e5f\u80fd\u8b93\u5bc6\u78bc\u731c\u6e2c\u7684\u6e96\u78ba\u7387\u63d0\u5347\u8d85\u904e 3%\u3002\u6211\u5011\u4e5f\u63d0\u51fa\u4e86\u4e00\u7a2e\u555f\u767c\u5f0f\u65b9\u6cd5\u4f86\u6839\u64da JS\uff08Jensen-Shannon\uff09\u8ddd\u96e2\u9078\u64c7\u5fae\u8abf\u5bc6\u78bc\uff0c\u800c\u5be6\u9a57\u7d50\u679c\u9a57\u8b49\u4e86\u5176\u6548\u7528\u3002\u7e3d\u4e4b\uff0c\u6211\u5011\u7684\u8ca2\u737b\u8b49\u660e\u4e86\u5c07\u5148\u9032\u7684 NLP \u548c ML \u65b9\u6cd5\u61c9\u7528\u65bc\u5bc6\u78bc\u5efa\u6a21\u548c\u7834\u89e3\u7684\u53ef\u80fd\u6027\u548c\u53ef\u884c\u6027\u3002", "author": "Yangde Wang et.al.", "authors": "Yangde Wang, Haozhang Li, Weidong Qiu, Shujun Li, Peng Tang", "id": "2407.14145v1", "paper_url": "http://arxiv.org/abs/2407.14145v1", "repo": "null"}}