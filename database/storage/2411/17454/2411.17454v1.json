{"2411.17454": {"publish_time": "2024-11-26", "title": "FLEX-CLIP: Feature-Level GEneration Network Enhanced CLIP for X-shot Cross-modal Retrieval", "paper_summary": "Given a query from one modality, few-shot cross-modal retrieval (CMR)\nretrieves semantically similar instances in another modality with the target\ndomain including classes that are disjoint from the source domain. Compared\nwith classical few-shot CMR methods, vision-language pretraining methods like\nCLIP have shown great few-shot or zero-shot learning performance. However, they\nstill suffer challenges due to (1) the feature degradation encountered in the\ntarget domain and (2) the extreme data imbalance. To tackle these issues, we\npropose FLEX-CLIP, a novel Feature-level Generation Network Enhanced CLIP.\nFLEX-CLIP includes two training stages. In multimodal feature generation, we\npropose a composite multimodal VAE-GAN network to capture real feature\ndistribution patterns and generate pseudo samples based on CLIP features,\naddressing data imbalance. For common space projection, we develop a gate\nresidual network to fuse CLIP features with projected features, reducing\nfeature degradation in X-shot scenarios. Experimental results on four benchmark\ndatasets show a 7%-15% improvement over state-of-the-art methods, with ablation\nstudies demonstrating enhancement of CLIP features.", "paper_summary_zh": "\u7ed9\u5b9a\u4e00\u4e2a\u6765\u81ea\u4e00\u4e2a\u6a21\u6001\u7684\u67e5\u8be2\uff0c\u5c11\u6837\u672c\u8de8\u6a21\u6001\u68c0\u7d22\uff08CMR\uff09\n\u5728\u53e6\u4e00\u4e2a\u6a21\u6001\u4e2d\u68c0\u7d22\u8bed\u4e49\u76f8\u4f3c\u7684\u5b9e\u4f8b\uff0c\u76ee\u6807\n\u57df\u5305\u62ec\u4e0e\u6e90\u57df\u4e0d\u76f8\u4ea4\u7684\u7c7b\u522b\u3002\u4e0e\u7ecf\u5178\u7684\u5c11\u6837\u672c CMR \u65b9\u6cd5\u76f8\u6bd4\uff0c\u89c6\u89c9\u8bed\u8a00\u9884\u8bad\u7ec3\u65b9\u6cd5\uff08\u5982\nCLIP\uff09\u5df2\u7ecf\u5c55\u793a\u4e86\u6781\u597d\u7684\u5c11\u6837\u672c\u6216\u96f6\u6837\u672c\u5b66\u4e60\u6027\u80fd\u3002\u7136\u800c\uff0c\u5b83\u4eec\n\u4ecd\u7136\u9762\u4e34\u6311\u6218\uff0c\u539f\u56e0\u5728\u4e8e\uff081\uff09\u5728\u76ee\u6807\u57df\u4e2d\u9047\u5230\u7684\u7279\u5f81\u9000\u5316\u548c\uff082\uff09\u6781\u7aef\u7684\u6570\u636e\u4e0d\u5e73\u8861\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u6211\u4eec\n\u63d0\u51fa\u4e86 FLEX-CLIP\uff0c\u4e00\u79cd\u65b0\u9896\u7684\u7279\u5f81\u7ea7\u751f\u6210\u7f51\u7edc\u589e\u5f3a CLIP\u3002\nFLEX-CLIP \u5305\u62ec\u4e24\u4e2a\u8bad\u7ec3\u9636\u6bb5\u3002\u5728\u591a\u6a21\u6001\u7279\u5f81\u751f\u6210\u4e2d\uff0c\u6211\u4eec\n\u63d0\u51fa\u4e86\u4e00\u79cd\u590d\u5408\u591a\u6a21\u6001 VAE-GAN \u7f51\u7edc\u6765\u6355\u83b7\u771f\u5b9e\u7684\u7279\u5f81\n\u5206\u5e03\u6a21\u5f0f\u5e76\u57fa\u4e8e CLIP \u7279\u5f81\u751f\u6210\u4f2a\u6837\u672c\uff0c\u89e3\u51b3\u6570\u636e\u4e0d\u5e73\u8861\u3002\u5bf9\u4e8e\u516c\u5171\u7a7a\u95f4\u6295\u5f71\uff0c\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u4e2a\u95e8\n\u6b8b\u5dee\u7f51\u7edc\u6765\u878d\u5408 CLIP \u7279\u5f81\u548c\u6295\u5f71\u7279\u5f81\uff0c\u51cf\u5c11\n\u5728 X-shot \u573a\u666f\u4e2d\u7684\u7279\u5f81\u9000\u5316\u3002\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u51fa\u6bd4\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u6709 7%-15% \u7684\u6539\u8fdb\uff0c\u6d88\u878d\n\u7814\u7a76\u8bc1\u660e\u4e86 CLIP \u7279\u5f81\u7684\u589e\u5f3a\u3002", "author": "Jingyou Xie et.al.", "authors": "Jingyou Xie, Jiayi Kuang, Zhenzhou Lin, Jiarui Ouyang, Zishuo Zhao, Ying Shen", "id": "2411.17454v1", "paper_url": "http://arxiv.org/abs/2411.17454v1", "repo": "null"}}