{"2410.11235": {"publish_time": "2024-10-15", "title": "Unleashing the Power of LLMs as Multi-Modal Encoders for Text and Graph-Structured Data", "paper_summary": "Graph-structured information offers rich contextual information that can\nenhance language models by providing structured relationships and hierarchies,\nleading to more expressive embeddings for various applications such as\nretrieval, question answering, and classification. However, existing methods\nfor integrating graph and text embeddings, often based on Multi-layer\nPerceptrons (MLPs) or shallow transformers, are limited in their ability to\nfully exploit the heterogeneous nature of these modalities. To overcome this,\nwe propose Janus, a simple yet effective framework that leverages Large\nLanguage Models (LLMs) to jointly encode text and graph data. Specifically,\nJanus employs an MLP adapter to project graph embeddings into the same space as\ntext embeddings, allowing the LLM to process both modalities jointly. Unlike\nprior work, we also introduce contrastive learning to align the graph and text\nspaces more effectively, thereby improving the quality of learned joint\nembeddings. Empirical results across six datasets spanning three tasks,\nknowledge graph-contextualized question answering, graph-text pair\nclassification, and retrieval, demonstrate that Janus consistently outperforms\nexisting baselines, achieving significant improvements across multiple\ndatasets, with gains of up to 11.4% in QA tasks. These results highlight\nJanus's effectiveness in integrating graph and text data. Ablation studies\nfurther validate the effectiveness of our method.", "paper_summary_zh": "\u5716\u5f62\u7d50\u69cb\u5316\u8cc7\u8a0a\u63d0\u4f9b\u8c50\u5bcc\u7684\u8108\u7d61\u8cc7\u8a0a\uff0c\u53ef\u4ee5\u900f\u904e\u63d0\u4f9b\u7d50\u69cb\u5316\u7684\u95dc\u4fc2\u548c\u968e\u5c64\u4f86\u589e\u5f37\u8a9e\u8a00\u6a21\u578b\uff0c\u9032\u800c\u70ba\u5404\u7a2e\u61c9\u7528\u7a0b\u5f0f\uff08\u4f8b\u5982\u6aa2\u7d22\u3001\u554f\u7b54\u548c\u5206\u985e\uff09\u7522\u751f\u66f4\u5177\u8868\u73fe\u529b\u7684\u5d4c\u5165\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684\u5716\u5f62\u548c\u6587\u5b57\u5d4c\u5165\u6574\u5408\u65b9\u6cd5\uff0c\u901a\u5e38\u57fa\u65bc\u591a\u5c64\u611f\u77e5\u5668 (MLP) \u6216\u6dfa\u5c64\u8f49\u63db\u5668\uff0c\u5728\u5145\u5206\u5229\u7528\u9019\u4e9b\u6a21\u614b\u7684\u7570\u8cea\u6027\u65b9\u9762\u80fd\u529b\u6709\u9650\u3002\u70ba\u4e86\u514b\u670d\u9019\u4e00\u9ede\uff0c\u6211\u5011\u63d0\u51fa\u4e86 Janus\uff0c\u4e00\u500b\u7c21\u55ae\u4f46\u6709\u6548\u7684\u6846\u67b6\uff0c\u5b83\u5229\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4f86\u806f\u5408\u7de8\u78bc\u6587\u5b57\u548c\u5716\u5f62\u8cc7\u6599\u3002\u5177\u9ad4\u4f86\u8aaa\uff0cJanus \u4f7f\u7528 MLP \u9069\u914d\u5668\u5c07\u5716\u5f62\u5d4c\u5165\u6295\u5f71\u5230\u8207\u6587\u5b57\u5d4c\u5165\u76f8\u540c\u7684\u7a7a\u9593\uff0c\u5141\u8a31 LLM \u806f\u5408\u8655\u7406\u9019\u5169\u7a2e\u6a21\u614b\u3002\u8207\u5148\u524d\u7684\u7814\u7a76\u4e0d\u540c\uff0c\u6211\u5011\u9084\u5f15\u5165\u4e86\u5c0d\u6bd4\u5b78\u7fd2\uff0c\u4ee5\u66f4\u6709\u6548\u5730\u5c0d\u9f4a\u5716\u5f62\u548c\u6587\u5b57\u7a7a\u9593\uff0c\u5f9e\u800c\u63d0\u9ad8\u5b78\u7fd2\u5230\u7684\u806f\u5408\u5d4c\u5165\u7684\u54c1\u8cea\u3002\u8de8\u8d8a\u516d\u500b\u8cc7\u6599\u96c6\u7684\u5be6\u8b49\u7d50\u679c\u6db5\u84cb\u4e86\u4e09\u500b\u4efb\u52d9\uff0c\u77e5\u8b58\u5716\u8b5c\u8108\u7d61\u5316\u554f\u7b54\u3001\u5716\u5f62\u6587\u5b57\u5c0d\u5206\u985e\u548c\u6aa2\u7d22\uff0c\u8b49\u660e Janus \u6301\u7e8c\u512a\u65bc\u73fe\u6709\u57fa\u6e96\uff0c\u5728\u591a\u500b\u8cc7\u6599\u96c6\u4e0a\u53d6\u5f97\u986f\u8457\u9032\u6b65\uff0c\u5728 QA \u4efb\u52d9\u4e2d\u7372\u5f97\u9ad8\u9054 11.4% \u7684\u63d0\u5347\u3002\u9019\u4e9b\u7d50\u679c\u7a81\u986f\u4e86 Janus \u5728\u6574\u5408\u5716\u5f62\u548c\u6587\u5b57\u8cc7\u6599\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u6d88\u878d\u7814\u7a76\u9032\u4e00\u6b65\u9a57\u8b49\u4e86\u6211\u5011\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "author": "Jiacheng Lin et.al.", "authors": "Jiacheng Lin, Kun Qian, Haoyu Han, Nurendra Choudhary, Tianxin Wei, Zhongruo Wang, Sahika Genc, Edward W Huang, Sheng Wang, Karthik Subbian, Danai Koutra, Jimeng Sun", "id": "2410.11235v1", "paper_url": "http://arxiv.org/abs/2410.11235v1", "repo": "null"}}