{"2410.22446": {"publish_time": "2024-10-29", "title": "Do Large Language Models Align with Core Mental Health Counseling Competencies?", "paper_summary": "The rapid evolution of Large Language Models (LLMs) offers promising\npotential to alleviate the global scarcity of mental health professionals.\nHowever, LLMs' alignment with essential mental health counseling competencies\nremains understudied. We introduce CounselingBench, a novel NCMHCE-based\nbenchmark evaluating LLMs across five key mental health counseling\ncompetencies. Testing 22 general-purpose and medical-finetuned LLMs, we find\nfrontier models exceed minimum thresholds but fall short of expert-level\nperformance, with significant variations: they excel in Intake, Assessment &\nDiagnosis yet struggle with Core Counseling Attributes and Professional\nPractice & Ethics. Medical LLMs surprisingly underperform generalist models\naccuracy-wise, while at the same time producing slightly higher-quality\njustifications but making more context-related errors. Our findings highlight\nthe complexities of developing AI systems for mental health counseling,\nparticularly for competencies requiring empathy and contextual understanding.\nWe found that frontier LLMs perform at a level exceeding the minimal required\nlevel of aptitude for all key mental health counseling competencies, but fall\nshort of expert-level performance, and that current medical LLMs do not\nsignificantly improve upon generalist models in mental health counseling\ncompetencies. This underscores the critical need for specialized, mental health\ncounseling-specific fine-tuned LLMs that rigorously aligns with core\ncompetencies combined with appropriate human supervision before any responsible\nreal-world deployment can be considered.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5feb\u901f\u767c\u5c55\uff0c\u63d0\u4f9b\u4e86\u7de9\u89e3\u5168\u7403\u5fc3\u7406\u5065\u5eb7\u5c08\u696d\u4eba\u54e1\u77ed\u7f3a\u7684\u6f5b\u5728\u5e0c\u671b\u3002\n\u7136\u800c\uff0cLLM \u8207\u57fa\u672c\u5fc3\u7406\u5065\u5eb7\u8aee\u5546\u80fd\u529b\u7684\u5c0d\u9f4a\u7a0b\u5ea6\uff0c\u4ecd\u672a\u7372\u5f97\u5145\u5206\u7814\u7a76\u3002\u6211\u5011\u5f15\u5165\u4e86 CounselingBench\uff0c\u4e00\u500b\u57fa\u65bc NCMHCE \u7684\u65b0\u57fa\u6e96\uff0c\u7528\u65bc\u8a55\u4f30 LLM \u5728\u4e94\u9805\u95dc\u9375\u5fc3\u7406\u5065\u5eb7\u8aee\u5546\u80fd\u529b\u4e0a\u7684\u8868\u73fe\u3002\u6211\u5011\u6e2c\u8a66\u4e86 22 \u500b\u901a\u7528\u548c\u91ab\u5b78\u5fae\u8abf\u7684 LLM\uff0c\u767c\u73fe\u524d\u6cbf\u6a21\u578b\u8d85\u904e\u4e86\u6700\u4f4e\u9580\u6abb\uff0c\u4f46\u672a\u9054\u5230\u5c08\u5bb6\u7d1a\u5225\u7684\u8868\u73fe\uff0c\u4e14\u5dee\u7570\u986f\u8457\uff1a\u5b83\u5011\u5728\u300c\u651d\u53d6\u3001\u8a55\u4f30\u548c\u8a3a\u65b7\u300d\u65b9\u9762\u8868\u73fe\u51fa\u8272\uff0c\u4f46\u5728\u300c\u6838\u5fc3\u8aee\u5546\u5c6c\u6027\u300d\u548c\u300c\u5c08\u696d\u5be6\u52d9\u548c\u502b\u7406\u300d\u65b9\u9762\u537b\u6709\u56f0\u96e3\u3002\u4ee4\u4eba\u9a5a\u8a1d\u7684\u662f\uff0c\u91ab\u7642 LLM \u5728\u6e96\u78ba\u6027\u65b9\u9762\u8868\u73fe\u4e0d\u5982\u901a\u7528\u6a21\u578b\uff0c\u4f46\u540c\u6642\u7522\u751f\u7684\u7406\u7531\u54c1\u8cea\u7565\u9ad8\uff0c\u4f46\u7522\u751f\u66f4\u591a\u8207\u8108\u7d61\u76f8\u95dc\u7684\u932f\u8aa4\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u7a81\u51fa\u4e86\u70ba\u5fc3\u7406\u5065\u5eb7\u8aee\u5546\u958b\u767c AI \u7cfb\u7d71\u7684\u8907\u96dc\u6027\uff0c\u7279\u5225\u662f\u5c0d\u65bc\u9700\u8981\u540c\u7406\u5fc3\u548c\u8108\u7d61\u7406\u89e3\u7684\u80fd\u529b\u3002\u6211\u5011\u767c\u73fe\uff0c\u524d\u6cbf LLM \u7684\u8868\u73fe\u6c34\u5e73\u8d85\u904e\u4e86\u6240\u6709\u95dc\u9375\u5fc3\u7406\u5065\u5eb7\u8aee\u5546\u80fd\u529b\u6240\u9700\u7684\u6700\u4f4e\u80fd\u529b\u6c34\u6e96\uff0c\u4f46\u672a\u9054\u5230\u5c08\u5bb6\u7d1a\u5225\u7684\u8868\u73fe\uff0c\u800c\u4e14\u76ee\u524d\u7684\u91ab\u7642 LLM \u4e26\u672a\u986f\u8457\u6539\u5584\u901a\u7528\u6a21\u578b\u5728\u5fc3\u7406\u5065\u5eb7\u8aee\u5546\u80fd\u529b\u4e0a\u7684\u8868\u73fe\u3002\u9019\u5f37\u8abf\u4e86\u5c0d\u5c08\u9580\u7684\u3001\u91dd\u5c0d\u5fc3\u7406\u5065\u5eb7\u8aee\u8a62\u7684\u5fae\u8abf LLM \u7684\u8feb\u5207\u9700\u6c42\uff0c\u9019\u4e9b LLM \u5fc5\u9808\u56b4\u683c\u7b26\u5408\u6838\u5fc3\u80fd\u529b\uff0c\u4e26\u7d50\u5408\u9069\u7576\u7684\u4eba\u985e\u76e3\u7763\uff0c\u624d\u80fd\u8003\u616e\u4efb\u4f55\u8ca0\u8cac\u4efb\u7684\u5be6\u969b\u90e8\u7f72\u3002", "author": "Viet Cuong Nguyen et.al.", "authors": "Viet Cuong Nguyen, Mohammad Taher, Dongwan Hong, Vinicius Konkolics Possobom, Vibha Thirunellayi Gopalakrishnan, Ekta Raj, Zihang Li, Heather J. Soled, Michael L. Birnbaum, Srijan Kumar, Munmun De Choudhury", "id": "2410.22446v1", "paper_url": "http://arxiv.org/abs/2410.22446v1", "repo": "null"}}