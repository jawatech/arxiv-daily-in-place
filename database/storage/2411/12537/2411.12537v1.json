{"2411.12537": {"publish_time": "2024-11-19", "title": "Unlocking State-Tracking in Linear RNNs Through Negative Eigenvalues", "paper_summary": "Linear Recurrent Neural Networks (LRNNs) such as Mamba, RWKV, GLA, mLSTM, and\nDeltaNet have emerged as efficient alternatives to Transformers in large\nlanguage modeling, offering linear scaling with sequence length and improved\ntraining efficiency. However, LRNNs struggle to perform state-tracking which\nmay impair performance in tasks such as code evaluation or tracking a chess\ngame. Even parity, the simplest state-tracking task, which non-linear RNNs like\nLSTM handle effectively, cannot be solved by current LRNNs. Recently, Sarrof et\nal. (2024) demonstrated that the failure of LRNNs like Mamba to solve parity\nstems from restricting the value range of their diagonal state-transition\nmatrices to $[0, 1]$ and that incorporating negative values can resolve this\nissue. We extend this result to non-diagonal LRNNs, which have recently shown\npromise in models such as DeltaNet. We prove that finite precision LRNNs with\nstate-transition matrices having only positive eigenvalues cannot solve parity,\nwhile complex eigenvalues are needed to count modulo $3$. Notably, we also\nprove that LRNNs can learn any regular language when their state-transition\nmatrices are products of identity minus vector outer product matrices, each\nwith eigenvalues in the range $[-1, 1]$. Our empirical results confirm that\nextending the eigenvalue range of models like Mamba and DeltaNet to include\nnegative values not only enables them to solve parity but consistently improves\ntheir performance on state-tracking tasks. Furthermore, pre-training LRNNs with\nan extended eigenvalue range for language modeling achieves comparable\nperformance and stability while showing promise on code and math data. Our work\nenhances the expressivity of modern LRNNs, broadening their applicability\nwithout changing the cost of training or inference.", "paper_summary_zh": "\u7dda\u6027\u905e\u8ff4\u795e\u7d93\u7db2\u8def (LRNN)\uff0c\u4f8b\u5982 Mamba\u3001RWKV\u3001GLA\u3001mLSTM \u548c DeltaNet \u5df2\u6210\u70ba\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u4e2d Transformer \u7684\u9ad8\u6548\u66ff\u4ee3\u65b9\u6848\uff0c\u63d0\u4f9b\u8207\u5e8f\u5217\u9577\u5ea6\u6210\u7dda\u6027\u6bd4\u4f8b\u7684\u7e2e\u653e\u548c\u6539\u5584\u7684\u8a13\u7df4\u6548\u7387\u3002\u7136\u800c\uff0cLRNN \u96e3\u4ee5\u57f7\u884c\u72c0\u614b\u8ffd\u8e64\uff0c\u9019\u53ef\u80fd\u6703\u640d\u5bb3\u7a0b\u5f0f\u78bc\u8a55\u4f30\u6216\u8ffd\u8e64\u897f\u6d0b\u68cb\u904a\u6232\u7b49\u4efb\u52d9\u7684\u6548\u80fd\u3002\u5373\u4f7f\u662f LSTM \u7b49\u975e\u7dda\u6027 RNN \u80fd\u6709\u6548\u8655\u7406\u7684\u6700\u7c21\u55ae\u72c0\u614b\u8ffd\u8e64\u4efb\u52d9\u5947\u5076\u9a57\u8b49\uff0c\u4e5f\u7121\u6cd5\u7531\u76ee\u524d\u7684 LRNN \u89e3\u6c7a\u3002\u6700\u8fd1\uff0cSarrof \u7b49\u4eba (2024) \u8b49\u660e\u4e86\u50cf Mamba \u9019\u6a23\u7684 LRNN \u7121\u6cd5\u89e3\u6c7a\u5947\u5076\u9a57\u8b49\u7684\u554f\u984c\uff0c\u6e90\u65bc\u5c07\u5176\u5c0d\u89d2\u72c0\u614b\u8f49\u79fb\u77e9\u9663\u7684\u503c\u7bc4\u570d\u9650\u5236\u5728 [0, 1]\uff0c\u800c\u7d0d\u5165\u8ca0\u503c\u53ef\u4ee5\u89e3\u6c7a\u9019\u500b\u554f\u984c\u3002\u6211\u5011\u5c07\u6b64\u7d50\u679c\u5ef6\u4f38\u5230\u975e\u5c0d\u89d2 LRNN\uff0c\u9019\u5728 DeltaNet \u7b49\u6a21\u578b\u4e2d\u6700\u8fd1\u5df2\u5c55\u73fe\u6f5b\u529b\u3002\u6211\u5011\u8b49\u660e\u4e86\u72c0\u614b\u8f49\u79fb\u77e9\u9663\u50c5\u5177\u6709\u6b63\u7279\u5fb5\u503c\u7684\u6709\u9650\u7cbe\u5ea6 LRNN \u7121\u6cd5\u89e3\u6c7a\u5947\u5076\u9a57\u8b49\uff0c\u800c\u9700\u8981\u8907\u6578\u7279\u5fb5\u503c\u4f86\u8a08\u7b97\u6a21\u6578 3\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u6211\u5011\u9084\u8b49\u660e\u4e86\u7576 LRNN \u7684\u72c0\u614b\u8f49\u79fb\u77e9\u9663\u662f\u55ae\u4f4d\u77e9\u9663\u6e1b\u53bb\u5411\u91cf\u5916\u7a4d\u77e9\u9663\u7684\u4e58\u7a4d\u6642\uff0cLRNN \u53ef\u4ee5\u5b78\u7fd2\u4efb\u4f55\u6b63\u5247\u8a9e\u8a00\uff0c\u6bcf\u500b\u77e9\u9663\u7684\u7279\u5fb5\u503c\u90fd\u5728\u7bc4\u570d [-1, 1] \u5167\u3002\u6211\u5011\u7684\u5be6\u8b49\u7d50\u679c\u8b49\u5be6\uff0c\u5c07 Mamba \u548c DeltaNet \u7b49\u6a21\u578b\u7684\u7279\u5fb5\u503c\u7bc4\u570d\u64f4\u5c55\u5230\u5305\u62ec\u8ca0\u503c\uff0c\u4e0d\u50c5\u4f7f\u5b83\u5011\u80fd\u5920\u89e3\u6c7a\u5947\u5076\u9a57\u8b49\uff0c\u800c\u4e14\u6301\u7e8c\u6539\u5584\u5b83\u5011\u5728\u72c0\u614b\u8ffd\u8e64\u4efb\u52d9\u4e0a\u7684\u6548\u80fd\u3002\u6b64\u5916\uff0c\u4f7f\u7528\u64f4\u5c55\u7684\u7279\u5fb5\u503c\u7bc4\u570d\u9810\u8a13\u7df4 LRNN \u9032\u884c\u8a9e\u8a00\u6a21\u578b\uff0c\u5728\u5c55\u73fe\u7a0b\u5f0f\u78bc\u548c\u6578\u5b78\u8cc7\u6599\u7684\u6f5b\u529b\u6642\uff0c\u9054\u5230\u4e86\u53ef\u6bd4\u8f03\u7684\u6548\u80fd\u548c\u7a69\u5b9a\u6027\u3002\u6211\u5011\u7684\u7814\u7a76\u589e\u5f37\u4e86\u73fe\u4ee3 LRNN \u7684\u8868\u73fe\u529b\uff0c\u64f4\u5927\u4e86\u5b83\u5011\u7684\u9069\u7528\u6027\uff0c\u800c\u4e0d\u6703\u6539\u8b8a\u8a13\u7df4\u6216\u63a8\u8ad6\u7684\u6210\u672c\u3002", "author": "Riccardo Grazzi et.al.", "authors": "Riccardo Grazzi, Julien Siems, J\u00f6rg K. H. Franke, Arber Zela, Frank Hutter, Massimiliano Pontil", "id": "2411.12537v1", "paper_url": "http://arxiv.org/abs/2411.12537v1", "repo": "null"}}