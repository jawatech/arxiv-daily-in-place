{"2411.13407": {"publish_time": "2024-11-20", "title": "Transformer-Based Contextualized Language Models Joint with Neural Networks for Natural Language Inference in Vietnamese", "paper_summary": "Natural Language Inference (NLI) is a task within Natural Language Processing\n(NLP) that holds value for various AI applications. However, there have been\nlimited studies on Natural Language Inference in Vietnamese that explore the\nconcept of joint models. Therefore, we conducted experiments using various\ncombinations of contextualized language models (CLM) and neural networks. We\nuse CLM to create contextualized work presentations and use Neural Networks for\nclassification. Furthermore, we have evaluated the strengths and weaknesses of\neach joint model and identified the model failure points in the Vietnamese\ncontext. The highest F1 score in this experiment, up to 82.78\\% in the\nbenchmark dataset (ViNLI). By conducting experiments with various models, the\nmost considerable size of the CLM is XLM-R (355M). That combination has\nconsistently demonstrated superior performance compared to fine-tuning strong\npre-trained language models like PhoBERT (+6.58\\%), mBERT (+19.08\\%), and XLM-R\n(+0.94\\%) in terms of F1-score. This article aims to introduce a novel approach\nor model that attains improved performance for Vietnamese NLI. Overall, we find\nthat the joint approach of CLM and neural networks is simple yet capable of\nachieving high-quality performance, which makes it suitable for applications\nthat require efficient resource utilization.", "paper_summary_zh": "\u81ea\u7136\u8a9e\u8a00\u63a8\u7406 (NLI) \u662f\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u4e2d\u7684\u4e00\u9805\u4efb\u52d9\uff0c\u5c0d\u5404\u7a2e AI \u61c9\u7528\u5177\u6709\u50f9\u503c\u3002\u7136\u800c\uff0c\u95dc\u65bc\u8d8a\u5357\u8a9e\u81ea\u7136\u8a9e\u8a00\u63a8\u7406\u7684\u7814\u7a76\u6709\u9650\uff0c\u63a2\u7d22\u4e86\u806f\u5408\u6a21\u578b\u7684\u6982\u5ff5\u3002\u56e0\u6b64\uff0c\u6211\u5011\u4f7f\u7528\u5404\u7a2e\u80cc\u666f\u5316\u8a9e\u8a00\u6a21\u578b (CLM) \u548c\u795e\u7d93\u7db2\u8def\u7684\u7d44\u5408\u9032\u884c\u4e86\u5be6\u9a57\u3002\u6211\u5011\u4f7f\u7528 CLM \u4f86\u5efa\u7acb\u80cc\u666f\u5316\u7684\u5de5\u4f5c\u7c21\u5831\uff0c\u4e26\u4f7f\u7528\u795e\u7d93\u7db2\u8def\u9032\u884c\u5206\u985e\u3002\u6b64\u5916\uff0c\u6211\u5011\u8a55\u4f30\u4e86\u6bcf\u500b\u806f\u5408\u6a21\u578b\u7684\u512a\u7f3a\u9ede\uff0c\u4e26\u627e\u51fa\u8d8a\u5357\u8a9e\u74b0\u5883\u4e2d\u7684\u6a21\u578b\u5931\u6557\u9ede\u3002\u5728\u9019\u500b\u5be6\u9a57\u4e2d\uff0c\u57fa\u51c6\u8cc7\u6599\u96c6 (ViNLI) \u4e2d\u6700\u9ad8 F1 \u5206\u6578\u9054 82.78%\u3002\u901a\u904e\u5c0d\u5404\u7a2e\u6a21\u578b\u9032\u884c\u5be6\u9a57\uff0cCLM \u4e2d\u6700\u986f\u8457\u7684\u5927\u5c0f\u662f XLM-R (355M)\u3002\u8207\u5fae\u8abf\u5f37\u5927\u7684\u9810\u8a13\u7df4\u8a9e\u8a00\u6a21\u578b\uff08\u4f8b\u5982 PhoBERT (+6.58%)\u3001mBERT (+19.08%) \u548c XLM-R (+0.94%) \u76f8\u6bd4\uff0c\u9019\u7a2e\u7d44\u5408\u5728 F1 \u5206\u6578\u65b9\u9762\u59cb\u7d42\u8868\u73fe\u51fa\u512a\u7570\u7684\u6548\u80fd\u3002\u672c\u6587\u65e8\u5728\u4ecb\u7d39\u4e00\u7a2e\u65b0\u7a4e\u7684\u65b9\u6cd5\u6216\u6a21\u578b\uff0c\u4ee5\u63d0\u5347\u8d8a\u5357\u8a9e NLI \u7684\u6548\u80fd\u3002\u7e3d\u9ad4\u800c\u8a00\uff0c\u6211\u5011\u767c\u73fe CLM \u548c\u795e\u7d93\u7db2\u8def\u7684\u806f\u5408\u65b9\u6cd5\u65e2\u7c21\u55ae\u53c8\u80fd\u5920\u9054\u5230\u9ad8\u54c1\u8cea\u7684\u6548\u80fd\uff0c\u9019\u4f7f\u5176\u9069\u7528\u65bc\u9700\u8981\u6709\u6548\u5229\u7528\u8cc7\u6e90\u7684\u61c9\u7528\u7a0b\u5f0f\u3002", "author": "Dat Van-Thanh Nguyen et.al.", "authors": "Dat Van-Thanh Nguyen, Tin Van Huynh, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen", "id": "2411.13407v1", "paper_url": "http://arxiv.org/abs/2411.13407v1", "repo": "null"}}