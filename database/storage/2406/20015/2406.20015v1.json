{"2406.20015": {"publish_time": "2024-06-28", "title": "ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for Tool-Augmented Large Language Models", "paper_summary": "Tool-augmented large language models (LLMs) are rapidly being integrated into\nreal-world applications. Due to the lack of benchmarks, the community still\nneeds to fully understand the hallucination issues within these models. To\naddress this challenge, we introduce a comprehensive diagnostic benchmark,\nToolBH. Specifically, we assess the LLM's hallucinations through two\nperspectives: depth and breadth. In terms of depth, we propose a multi-level\ndiagnostic process, including (1) solvability detection, (2) solution planning,\nand (3) missing-tool analysis. For breadth, we consider three scenarios based\non the characteristics of the toolset: missing necessary tools, potential\ntools, and limited functionality tools. Furthermore, we developed seven tasks\nand collected 700 evaluation samples through multiple rounds of manual\nannotation. The results show the significant challenges presented by the ToolBH\nbenchmark. The current advanced models Gemini-1.5-Pro and GPT-4o only achieve a\ntotal score of 45.3 and 37.0, respectively, on a scale of 100. In this\nbenchmark, larger model parameters do not guarantee better performance; the\ntraining data and response strategies also play a crucial role in tool-enhanced\nLLM scenarios. Our diagnostic analysis indicates that the primary reason for\nmodel errors lies in assessing task solvability. Additionally, open-weight\nmodels suffer from performance drops with verbose replies, whereas proprietary\nmodels excel with longer reasoning.", "paper_summary_zh": "\u5de5\u5177\u589e\u5f3a\u7684\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6b63\u8fc5\u901f\u6574\u5408\u5230\u5b9e\u9645\u5e94\u7528\u4e2d\u3002\u7531\u4e8e\u7f3a\u4e4f\u57fa\u51c6\uff0c\u793e\u533a\u4ecd\u9700\u8981\u5145\u5206\u4e86\u89e3\u8fd9\u4e9b\u6a21\u578b\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\uff0c\u6211\u4eec\u5f15\u5165\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u8bca\u65ad\u57fa\u51c6 ToolBH\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u4ece\u6df1\u5ea6\u548c\u5e7f\u5ea6\u7684\u4e24\u4e2a\u89d2\u5ea6\u8bc4\u4f30 LLM \u7684\u5e7b\u89c9\u3002\u5728\u6df1\u5ea6\u65b9\u9762\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u5c42\u6b21\u7684\u8bca\u65ad\u8fc7\u7a0b\uff0c\u5305\u62ec\uff081\uff09\u53ef\u89e3\u51b3\u6027\u68c0\u6d4b\uff0c\uff082\uff09\u89e3\u51b3\u65b9\u6848\u89c4\u5212\u548c\uff083\uff09\u7f3a\u5931\u5de5\u5177\u5206\u6790\u3002\u5728\u5e7f\u5ea6\u65b9\u9762\uff0c\u6211\u4eec\u57fa\u4e8e\u5de5\u5177\u96c6\u7684\u7279\u6027\u8003\u8651\u4e86\u4e09\u79cd\u573a\u666f\uff1a\u7f3a\u5c11\u5fc5\u8981\u7684\u5de5\u5177\u3001\u6f5c\u5728\u7684\u5de5\u5177\u548c\u529f\u80fd\u53d7\u9650\u7684\u5de5\u5177\u3002\u6b64\u5916\uff0c\u6211\u4eec\u5236\u5b9a\u4e86\u4e03\u9879\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7\u591a\u8f6e\u4eba\u5de5\u6ce8\u91ca\u6536\u96c6\u4e86 700 \u4e2a\u8bc4\u4f30\u6837\u672c\u3002\u7ed3\u679c\u663e\u793a\u4e86 ToolBH \u57fa\u51c6\u63d0\u51fa\u7684\u91cd\u5927\u6311\u6218\u3002\u5f53\u524d\u7684\u5148\u8fdb\u6a21\u578b Gemini-1.5-Pro \u548c GPT-4o \u5728 100 \u5206\u5236\u4e2d\u4ec5\u5206\u522b\u8fbe\u5230 45.3 \u548c 37.0 \u7684\u603b\u5206\u3002\u5728\u6b64\u57fa\u51c6\u4e2d\uff0c\u8f83\u5927\u7684\u6a21\u578b\u53c2\u6570\u5e76\u4e0d\u80fd\u4fdd\u8bc1\u66f4\u597d\u7684\u6027\u80fd\uff1b\u8bad\u7ec3\u6570\u636e\u548c\u54cd\u5e94\u7b56\u7565\u5728\u5de5\u5177\u589e\u5f3a\u7684 LLM \u573a\u666f\u4e2d\u4e5f\u8d77\u7740\u81f3\u5173\u91cd\u8981\u7684\u4f5c\u7528\u3002\u6211\u4eec\u7684\u8bca\u65ad\u5206\u6790\u8868\u660e\uff0c\u6a21\u578b\u9519\u8bef\u7684\u4e3b\u8981\u539f\u56e0\u5728\u4e8e\u8bc4\u4f30\u4efb\u52a1\u7684\u53ef\u89e3\u51b3\u6027\u3002\u6b64\u5916\uff0c\u5f00\u653e\u6743\u91cd\u6a21\u578b\u5728\u5197\u957f\u7684\u56de\u590d\u4e2d\u4f1a\u51fa\u73b0\u6027\u80fd\u4e0b\u964d\uff0c\u800c\u4e13\u6709\u6a21\u578b\u5219\u5728\u66f4\u957f\u7684\u63a8\u7406\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "author": "Yuxiang Zhang et.al.", "authors": "Yuxiang Zhang, Jing Chen, Junjie Wang, Yaxin Liu, Cheng Yang, Chufan Shi, Xinyu Zhu, Zihao Lin, Hanwen Wan, Yujiu Yang, Tetsuya Sakai, Tian Feng, Hayato Yamana", "id": "2406.20015v1", "paper_url": "http://arxiv.org/abs/2406.20015v1", "repo": "https://github.com/toolbehonest/toolbehonest"}}