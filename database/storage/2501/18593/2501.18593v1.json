{"2501.18593": {"publish_time": "2025-01-30", "title": "Diffusion Autoencoders are Scalable Image Tokenizers", "paper_summary": "Tokenizing images into compact visual representations is a key step in\nlearning efficient and high-quality image generative models. We present a\nsimple diffusion tokenizer (DiTo) that learns compact visual representations\nfor image generation models. Our key insight is that a single learning\nobjective, diffusion L2 loss, can be used for training scalable image\ntokenizers. Since diffusion is already widely used for image generation, our\ninsight greatly simplifies training such tokenizers. In contrast, current\nstate-of-the-art tokenizers rely on an empirically found combination of\nheuristics and losses, thus requiring a complex training recipe that relies on\nnon-trivially balancing different losses and pretrained supervised models. We\nshow design decisions, along with theoretical grounding, that enable us to\nscale DiTo for learning competitive image representations. Our results show\nthat DiTo is a simpler, scalable, and self-supervised alternative to the\ncurrent state-of-the-art image tokenizer which is supervised. DiTo achieves\ncompetitive or better quality than state-of-the-art in image reconstruction and\ndownstream image generation tasks.", "paper_summary_zh": "\u5c07\u5f71\u50cf\u6a19\u8a18\u5316\u70ba\u7cbe\u7c21\u7684\u8996\u89ba\u8868\u5fb5\u662f\u5b78\u7fd2\u6709\u6548\u7387\u4e14\u9ad8\u54c1\u8cea\u5f71\u50cf\u751f\u6210\u6a21\u578b\u7684\u95dc\u9375\u6b65\u9a5f\u3002\u6211\u5011\u63d0\u51fa\u4e00\u500b\u7c21\u55ae\u7684\u64f4\u6563\u6a19\u8a18\u5316\u5668 (DiTo)\uff0c\u53ef\u5b78\u7fd2\u5f71\u50cf\u751f\u6210\u6a21\u578b\u7684\u7cbe\u7c21\u8996\u89ba\u8868\u5fb5\u3002\u6211\u5011\u7684\u95dc\u9375\u898b\u89e3\u662f\uff0c\u55ae\u4e00\u7684\u5b78\u7fd2\u76ee\u6a19\uff0c\u64f4\u6563 L2 \u640d\u5931\uff0c\u53ef\u7528\u65bc\u8a13\u7df4\u53ef\u64f4\u5145\u7684\u5f71\u50cf\u6a19\u8a18\u5316\u5668\u3002\u7531\u65bc\u64f4\u6563\u5df2\u5ee3\u6cdb\u7528\u65bc\u5f71\u50cf\u751f\u6210\uff0c\u6211\u5011\u7684\u898b\u89e3\u5927\u5e45\u7c21\u5316\u4e86\u6b64\u985e\u6a19\u8a18\u5316\u5668\u7684\u8a13\u7df4\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u76ee\u524d\u7684\u5148\u9032\u6a19\u8a18\u5316\u5668\u4f9d\u8cf4\u65bc\u7d93\u9a57\u6cd5\u5247\u548c\u640d\u5931\u7684\u7d93\u9a57\u7d44\u5408\uff0c\u56e0\u6b64\u9700\u8981\u8907\u96dc\u7684\u8a13\u7df4\u914d\u65b9\uff0c\u4f9d\u8cf4\u65bc\u975e\u5e73\u51e1\u5730\u5e73\u8861\u4e0d\u540c\u7684\u640d\u5931\u548c\u9810\u5148\u8a13\u7df4\u7684\u76e3\u7763\u6a21\u578b\u3002\u6211\u5011\u8aaa\u660e\u8a2d\u8a08\u6c7a\u7b56\uff0c\u4ee5\u53ca\u7406\u8ad6\u4f9d\u64da\uff0c\u4f7f\u6211\u5011\u80fd\u5920\u64f4\u5145 DiTo \u4ee5\u5b78\u7fd2\u6709\u7af6\u722d\u529b\u7684\u5f71\u50cf\u8868\u5fb5\u3002\u6211\u5011\u7684\u7d50\u679c\u986f\u793a\uff0cDiTo \u662f\u6bd4\u76ee\u524d\u5148\u9032\u7684\u5f71\u50cf\u6a19\u8a18\u5316\u5668\u66f4\u7c21\u55ae\u3001\u53ef\u64f4\u5145\u4e14\u81ea\u6211\u76e3\u7763\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u800c\u5f8c\u8005\u662f\u76e3\u7763\u7684\u3002DiTo \u5728\u5f71\u50cf\u91cd\u5efa\u548c\u4e0b\u6e38\u5f71\u50cf\u751f\u6210\u4efb\u52d9\u4e2d\uff0c\u9054\u5230\u6709\u7af6\u722d\u529b\u6216\u512a\u65bc\u5148\u9032\u6280\u8853\u7684\u54c1\u8cea\u3002", "author": "Yinbo Chen et.al.", "authors": "Yinbo Chen, Rohit Girdhar, Xiaolong Wang, Sai Saketh Rambhatla, Ishan Misra", "id": "2501.18593v1", "paper_url": "http://arxiv.org/abs/2501.18593v1", "repo": "null"}}