{"2404.16627": {"publish_time": "2024-04-25", "title": "Incorporating Lexical and Syntactic Knowledge for Unsupervised Cross-Lingual Transfer", "paper_summary": "Unsupervised cross-lingual transfer involves transferring knowledge between\nlanguages without explicit supervision. Although numerous studies have been\nconducted to improve performance in such tasks by focusing on cross-lingual\nknowledge, particularly lexical and syntactic knowledge, current approaches are\nlimited as they only incorporate syntactic or lexical information. Since each\ntype of information offers unique advantages and no previous attempts have\ncombined both, we attempt to explore the potential of this approach. In this\npaper, we present a novel framework called \"Lexicon-Syntax Enhanced\nMultilingual BERT\" that combines both lexical and syntactic knowledge.\nSpecifically, we use Multilingual BERT (mBERT) as the base model and employ two\ntechniques to enhance its learning capabilities. The code-switching technique\nis used to implicitly teach the model lexical alignment information, while a\nsyntactic-based graph attention network is designed to help the model encode\nsyntactic structure. To integrate both types of knowledge, we input\ncode-switched sequences into both the syntactic module and the mBERT base model\nsimultaneously. Our extensive experimental results demonstrate this framework\ncan consistently outperform all baselines of zero-shot cross-lingual transfer,\nwith the gains of 1.0~3.7 points on text classification, named entity\nrecognition (ner), and semantic parsing tasks. Keywords:cross-lingual transfer,\nlexicon, syntax, code-switching, graph attention network", "paper_summary_zh": "\u7121\u76e3\u7763\u8de8\u8a9e\u8a00\u8f49\u79fb\u6d89\u53ca\u5728\u8a9e\u8a00\u4e4b\u9593\u50b3\u905e\u77e5\u8b58\uff0c\u800c\u7121\u9700\u660e\u78ba\u76e3\u7763\u3002\u5118\u7ba1\u5df2\u9032\u884c\u8a31\u591a\u7814\u7a76\uff0c\u5c08\u6ce8\u65bc\u8de8\u8a9e\u8a00\u77e5\u8b58\uff08\u7279\u5225\u662f\u8a5e\u5f59\u548c\u53e5\u6cd5\u77e5\u8b58\uff09\u4f86\u6539\u5584\u6b64\u985e\u4efb\u52d9\u7684\u6027\u80fd\uff0c\u4f46\u76ee\u524d\u7684\u505a\u6cd5\u53d7\u5230\u9650\u5236\uff0c\u56e0\u70ba\u5b83\u5011\u50c5\u5305\u542b\u53e5\u6cd5\u6216\u8a5e\u5f59\u4fe1\u606f\u3002\u7531\u65bc\u6bcf\u7a2e\u985e\u578b\u7684\u4fe1\u606f\u90fd\u63d0\u4f9b\u7368\u7279\u7684\u512a\u52e2\uff0c\u4e26\u4e14\u4ee5\u524d\u6c92\u6709\u5617\u8a66\u5c07\u5169\u8005\u7d50\u5408\u8d77\u4f86\uff0c\u56e0\u6b64\u6211\u5011\u5617\u8a66\u63a2\u7d22\u9019\u7a2e\u65b9\u6cd5\u7684\u6f5b\u529b\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u540d\u70ba\u300c\u8a5e\u5f59\u53e5\u6cd5\u589e\u5f37\u591a\u8a9e\u8a00 BERT\u300d\u7684\u65b0\u6846\u67b6\uff0c\u7d50\u5408\u4e86\u8a5e\u5f59\u548c\u53e5\u6cd5\u77e5\u8b58\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u4f7f\u7528\u591a\u8a9e\u8a00 BERT (mBERT) \u4f5c\u70ba\u57fa\u790e\u6a21\u578b\uff0c\u4e26\u63a1\u7528\u5169\u7a2e\u6280\u8853\u4f86\u589e\u5f37\u5176\u5b78\u7fd2\u80fd\u529b\u3002\u4ee3\u78bc\u5207\u63db\u6280\u8853\u7528\u65bc\u96b1\u5f0f\u6559\u6388\u6a21\u578b\u8a5e\u5f59\u5c0d\u9f4a\u4fe1\u606f\uff0c\u800c\u57fa\u65bc\u53e5\u6cd5\u7684\u5716\u6ce8\u610f\u529b\u7db2\u8def\u65e8\u5728\u5e6b\u52a9\u6a21\u578b\u7de8\u78bc\u53e5\u6cd5\u7d50\u69cb\u3002\u70ba\u4e86\u6574\u5408\u9019\u5169\u7a2e\u77e5\u8b58\u985e\u578b\uff0c\u6211\u5011\u540c\u6642\u5c07\u4ee3\u78bc\u5207\u63db\u5e8f\u5217\u8f38\u5165\u53e5\u6cd5\u6a21\u7d44\u548c mBERT \u57fa\u790e\u6a21\u578b\u3002\u6211\u5011\u5ee3\u6cdb\u7684\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u9019\u500b\u6846\u67b6\u53ef\u4ee5\u6301\u7e8c\u512a\u65bc\u6240\u6709\u96f6\u6b21\u8de8\u8a9e\u8a00\u8f49\u79fb\u57fa\u6e96\uff0c\u5728\u6587\u672c\u5206\u985e\u3001\u547d\u540d\u5be6\u9ad4\u8b58\u5225 (ner) \u548c\u8a9e\u7fa9\u89e3\u6790\u4efb\u52d9\u4e0a\u7372\u5f97 1.0~3.7 \u5206\u7684\u589e\u76ca\u3002\u95dc\u9375\u5b57\uff1a\u8de8\u8a9e\u8a00\u8f49\u79fb\u3001\u8a5e\u5f59\u3001\u53e5\u6cd5\u3001\u4ee3\u78bc\u5207\u63db\u3001\u5716\u6ce8\u610f\u529b\u7db2\u8def", "author": "Jianyu Zheng et.al.", "authors": "Jianyu Zheng, Fengfei Fan, Jianquan Li", "id": "2404.16627v1", "paper_url": "http://arxiv.org/abs/2404.16627v1", "repo": "https://github.com/tian14267/ls_mbert"}}