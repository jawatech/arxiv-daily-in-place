
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-25**|**The Potential and Value of AI Chatbot in Personalized Cognitive Training**|Zilong Wang et.al.|[2410.19733v1](http://arxiv.org/abs/2410.19733v1)|null|
|**2024-10-25**|**Rethinking Visual Dependency in Long-Context Reasoning for Large Vision-Language Models**|Yucheng Zhou et.al.|[2410.19732v1](http://arxiv.org/abs/2410.19732v1)|null|
|**2024-10-25**|**Counting Ability of Large Language Models and Impact of Tokenization**|Xiang Zhang et.al.|[2410.19730v1](http://arxiv.org/abs/2410.19730v1)|null|
|**2024-10-25**|**FISHNET: Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert Swarms, and Task Planning**|Nicole Cho et.al.|[2410.19727v1](http://arxiv.org/abs/2410.19727v1)|null|
|**2024-10-25**|**Sparse Decomposition of Graph Neural Networks**|Yaochen Hu et.al.|[2410.19723v1](http://arxiv.org/abs/2410.19723v1)|null|
|**2024-10-25**|**2D-DPO: Scaling Direct Preference Optimization with 2-Dimensional Supervision**|Shilong Li et.al.|[2410.19720v1](http://arxiv.org/abs/2410.19720v1)|null|
|**2024-10-25**|**Arabic Music Classification and Generation using Deep Learning**|Mohamed Elshaarawy et.al.|[2410.19719v1](http://arxiv.org/abs/2410.19719v1)|null|
|**2024-10-25**|**Adversarial Environment Design via Regret-Guided Diffusion Models**|Hojun Chung et.al.|[2410.19715v1](http://arxiv.org/abs/2410.19715v1)|null|
|**2024-10-25**|**TimeSuite: Improving MLLMs for Long Video Understanding via Grounded Tuning**|Xiangyu Zeng et.al.|[2410.19702v1](http://arxiv.org/abs/2410.19702v1)|null|
|**2024-10-25**|**IPPON: Common Sense Guided Informative Path Planning for Object Goal Navigation**|Kaixian Qu et.al.|[2410.19697v1](http://arxiv.org/abs/2410.19697v1)|null|
|**2024-10-25**|**Less is More: Extreme Gradient Boost Rank-1 Adaption for Efficient Finetuning of LLMs**|Yifei Zhang et.al.|[2410.19694v1](http://arxiv.org/abs/2410.19694v1)|null|
|**2024-10-25**|**AGENT-CQ: Automatic Generation and Evaluation of Clarifying Questions for Conversational Search with LLMs**|Clemencia Siro et.al.|[2410.19692v1](http://arxiv.org/abs/2410.19692v1)|null|
|**2024-10-25**|**Impact of Leakage on Data Harmonization in Machine Learning Pipelines in Class Imbalance Across Sites**|Nicolás Nieto et.al.|[2410.19643v1](http://arxiv.org/abs/2410.19643v1)|null|
|**2024-10-25**|**VARS: Vision-based Assessment of Risk in Security Systems**|Pranav Gupta et.al.|[2410.19642v1](http://arxiv.org/abs/2410.19642v1)|null|
|**2024-10-25**|**Planning-Aware Diffusion Networks for Enhanced Motion Forecasting in Autonomous Driving**|Liu Yunhao et.al.|[2410.19639v1](http://arxiv.org/abs/2410.19639v1)|null|
|**2024-10-25**|**A distributional simplicity bias in the learning dynamics of transformers**|Riccardo Rende et.al.|[2410.19637v1](http://arxiv.org/abs/2410.19637v1)|null|
|**2024-10-25**|**Knowledge Graph Enhanced Language Agents for Recommendation**|Taicheng Guo et.al.|[2410.19627v1](http://arxiv.org/abs/2410.19627v1)|null|
|**2024-10-25**|**OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization**|Hongliang He et.al.|[2410.19609v1](http://arxiv.org/abs/2410.19609v1)|[link](https://github.com/minorjerry/openwebvoyager)|
|**2024-10-25**|**CoqPilot, a plugin for LLM-based generation of proofs**|Andrei Kozyrev et.al.|[2410.19605v1](http://arxiv.org/abs/2410.19605v1)|[link](https://github.com/jetbrains-research/coqpilot)|
|**2024-10-25**|**Take Caution in Using LLMs as Human Surrogates: Scylla Ex Machina**|Yuan Gao et.al.|[2410.19599v1](http://arxiv.org/abs/2410.19599v1)|null|
|**2024-10-25**|**ChunkRAG: Novel LLM-Chunk Filtering Method for RAG Systems**|Ritvik Aggarwal Ishneet Sukhvinder Singh Ibrahim Allahverdiyev et.al.|[2410.19572v1](http://arxiv.org/abs/2410.19572v1)|null|
|**2024-10-25**|**On Occlusions in Video Action Detection: Benchmark Datasets And Training Recipes**|Rajat Modi et.al.|[2410.19553v1](http://arxiv.org/abs/2410.19553v1)|[link](https://github.com/rajatmodi62/occludedactionbenchmark)|
|**2024-10-25**|**DeMuVGN: Effective Software Defect Prediction Model by Learning Multi-view Software Dependency via Graph Neural Networks**|Yu Qiao et.al.|[2410.19550v1](http://arxiv.org/abs/2410.19550v1)|null|
|**2024-10-25**|**Mirror Matrix on the Wall: coding and vector notation as tools for introspection**|Leonardo Araújo et.al.|[2410.19549v1](http://arxiv.org/abs/2410.19549v1)|null|
|**2024-10-25**|**Bongard in Wonderland: Visual Puzzles that Still Make AI Go Mad?**|Antonia Wüst et.al.|[2410.19546v1](http://arxiv.org/abs/2410.19546v1)|[link](https://github.com/ml-research/bongard-in-wonderland)|
|**2024-10-25**|**PMM-Net: Single-stage Multi-agent Trajectory Prediction with Patching-based Embedding and Explicit Modal Modulation**|Huajian Liu et.al.|[2410.19544v1](http://arxiv.org/abs/2410.19544v1)|null|
|**2024-10-25**|**Brain-like Functional Organization within Large Language Models**|H. Sun et.al.|[2410.19542v1](http://arxiv.org/abs/2410.19542v1)|null|
|**2024-10-25**|**Detection of Human and Machine-Authored Fake News in Urdu**|Muhammad Zain Ali et.al.|[2410.19517v1](http://arxiv.org/abs/2410.19517v1)|null|
|**2024-10-25**|**DMT-HI: MOE-based Hyperbolic Interpretable Deep Manifold Transformation for Unspervised Dimensionality Reduction**|Zelin Zang et.al.|[2410.19504v1](http://arxiv.org/abs/2410.19504v1)|null|
|**2024-10-25**|**SWITCH: Studying with Teacher for Knowledge Distillation of Large Language Models**|Jahyun Koo et.al.|[2410.19503v1](http://arxiv.org/abs/2410.19503v1)|null|
|**2024-10-25**|**Introducing MAPO: Momentum-Aided Gradient Descent Prompt Optimization**|Anthony Cui et.al.|[2410.19499v1](http://arxiv.org/abs/2410.19499v1)|null|
|**2024-10-25**|**Graph Linearization Methods for Reasoning on Graphs with Large Language Models**|Christos Xypolopoulos et.al.|[2410.19494v1](http://arxiv.org/abs/2410.19494v1)|null|
|**2024-10-25**|**A Debate-Driven Experiment on LLM Hallucinations and Accuracy**|Ray Li et.al.|[2410.19485v1](http://arxiv.org/abs/2410.19485v1)|null|
|**2024-10-25**|**Peter Parker or Spiderman? Disambiguating Multiple Class Labels**|Nuthan Mummani et.al.|[2410.19479v1](http://arxiv.org/abs/2410.19479v1)|null|
|**2024-10-25**|**Improving Inverse Folding for Peptide Design with Diversity-regularized Direct Preference Optimization**|Ryan Park et.al.|[2410.19471v1](http://arxiv.org/abs/2410.19471v1)|null|
|**2024-10-25**|**Unified Causality Analysis Based on the Degrees of Freedom**|András Telcs et.al.|[2410.19469v1](http://arxiv.org/abs/2410.19469v1)|null|
|**2024-10-25**|**EDGE: Enhanced Grounded GUI Understanding with Enriched Multi-Granularity Synthetic Data**|Xuetian Chen et.al.|[2410.19461v1](http://arxiv.org/abs/2410.19461v1)|null|
|**2024-10-25**|**ShifCon: Enhancing Non-Dominant Language Capabilities with a Shift-based Contrastive Framework**|Hengyuan Zhang et.al.|[2410.19453v1](http://arxiv.org/abs/2410.19453v1)|null|
|**2024-10-25**|**NeuroClips: Towards High-fidelity and Smooth fMRI-to-Video Reconstruction**|Zixuan Gong et.al.|[2410.19452v1](http://arxiv.org/abs/2410.19452v1)|[link](https://github.com/gongzix/neuroclips)|
|**2024-10-25**|**Intelligent Understanding of Large Language Models in Traditional Chinese Medicine Based on Prompt Engineering Framework**|Yirui Chen et.al.|[2410.19451v1](http://arxiv.org/abs/2410.19451v1)|null|
|**2024-10-25**|**Gradient Descent Efficiency Index**|Aviral Dhingra et.al.|[2410.19448v1](http://arxiv.org/abs/2410.19448v1)|null|
|**2024-10-25**|**Expose Before You Defend: Unifying and Enhancing Backdoor Defenses via Exposed Models**|Yige Li et.al.|[2410.19427v1](http://arxiv.org/abs/2410.19427v1)|[link](https://github.com/bboylyg/expose-before-you-defend)|
|**2024-10-25**|**KAHANI: Culturally-Nuanced Visual Storytelling Pipeline for Non-Western Cultures**|Hamna et.al.|[2410.19419v1](http://arxiv.org/abs/2410.19419v1)|null|
|**2024-10-25**|**Robust Time Series Causal Discovery for Agent-Based Model Validation**|Gene Yu et.al.|[2410.19412v1](http://arxiv.org/abs/2410.19412v1)|null|
|**2024-10-25**|**CLAP. I. Resolving miscalibration for deep learning-based galaxy photometric redshift estimation**|Qiufan Lin et.al.|[2410.19390v1](http://arxiv.org/abs/2410.19390v1)|[link](https://github.com/QiufanLin/CLAP-I)|
|**2024-10-25**|**Investigating the Role of Prompting and External Tools in Hallucination Rates of Large Language Models**|Liam Barkley et.al.|[2410.19385v1](http://arxiv.org/abs/2410.19385v1)|null|
|**2024-10-25**|**Multi-Agent Reinforcement Learning with Selective State-Space Models**|Jemma Daniel et.al.|[2410.19382v1](http://arxiv.org/abs/2410.19382v1)|null|
|**2024-10-25**|**BitPipe: Bidirectional Interleaved Pipeline Parallelism for Accelerating Large Models Training**|Houming Wu et.al.|[2410.19367v1](http://arxiv.org/abs/2410.19367v1)|[link](https://github.com/wuhouming/bitpipe)|
|**2024-10-25**|**LArctan-SKAN: Simple and Efficient Single-Parameterized Kolmogorov-Arnold Networks using Learnable Trigonometric Function**|Zhijie Chen et.al.|[2410.19360v1](http://arxiv.org/abs/2410.19360v1)|[link](https://github.com/chikkkit/larctan-skan)|
|**2024-10-25**|**Interleaving Text and Number Embeddings to Solve Mathemathics Problems**|Marvin Alberts et.al.|[2410.19353v1](http://arxiv.org/abs/2410.19353v1)|null|
|**2024-10-25**|**Interpreting Neural Networks through Mahalanobis Distance**|Alan Oursland et.al.|[2410.19352v1](http://arxiv.org/abs/2410.19352v1)|null|
|**2024-10-25**|**AgentSense: Benchmarking Social Intelligence of Language Agents through Interactive Scenarios**|Xinyi Mou et.al.|[2410.19346v1](http://arxiv.org/abs/2410.19346v1)|null|
|**2024-10-25**|**High Resolution Seismic Waveform Generation using Denoising Diffusion**|Andreas Bergmeister et.al.|[2410.19343v1](http://arxiv.org/abs/2410.19343v1)|null|
|**2024-10-25**|**Two are better than one: Context window extension with multi-grained self-injection**|Wei Han et.al.|[2410.19318v1](http://arxiv.org/abs/2410.19318v1)|[link](https://github.com/clement25/sharedllm)|
|**2024-10-25**|**FairMT-Bench: Benchmarking Fairness for Multi-turn Dialogue in Conversational LLMs**|Zhiting Fan et.al.|[2410.19317v1](http://arxiv.org/abs/2410.19317v1)|null|
|**2024-10-25**|**A prescriptive theory for brain-like inference**|Hadi Vafaii et.al.|[2410.19315v1](http://arxiv.org/abs/2410.19315v1)|null|
|**2024-10-25**|**Revealing and Reducing Gender Biases in Vision and Language Assistants (VLAs)**|Leander Girrbach et.al.|[2410.19314v1](http://arxiv.org/abs/2410.19314v1)|null|
|**2024-10-25**|**COAT: Compressing Optimizer states and Activation for Memory-Efficient FP8 Training**|Haocheng Xi et.al.|[2410.19313v1](http://arxiv.org/abs/2410.19313v1)|null|
|**2024-10-25**|**Flow Generator Matching**|Zemin Huang et.al.|[2410.19310v1](http://arxiv.org/abs/2410.19310v1)|null|
|**2024-10-25**|**TEARS: Textual Representations for Scrutable Recommendations**|Emiliano Penaloza et.al.|[2410.19302v1](http://arxiv.org/abs/2410.19302v1)|null|
|**2024-10-25**|**Any Other Thoughts, Hedgehog? Linking Deliberation Chains in Collaborative Dialogues**|Abhijnan Nath et.al.|[2410.19301v1](http://arxiv.org/abs/2410.19301v1)|null|
|**2024-10-25**|**A Stock Price Prediction Approach Based on Time Series Decomposition and Multi-Scale CNN using OHLCT Images**|Zhiyuan Pei et.al.|[2410.19291v1](http://arxiv.org/abs/2410.19291v1)|null|
|**2024-10-25**|**Fictitious Synthetic Data Can Improve LLM Factuality via Prerequisite Learning**|Yujian Liu et.al.|[2410.19290v1](http://arxiv.org/abs/2410.19290v1)|[link](https://github.com/ucsb-nlp-chang/prereq_tune)|
|**2024-10-25**|**ST-NeRP: Spatial-Temporal Neural Representation Learning with Prior Embedding for Patient-specific Imaging Study**|Liang Qiu et.al.|[2410.19283v1](http://arxiv.org/abs/2410.19283v1)|null|
|**2024-10-25**|**UbiHR: Resource-efficient Long-range Heart Rate Sensing on Ubiquitous Devices**|Haoyu Bian et.al.|[2410.19279v1](http://arxiv.org/abs/2410.19279v1)|null|
|**2024-10-25**|**Applying sparse autoencoders to unlearn knowledge in language models**|Eoin Farrell et.al.|[2410.19278v1](http://arxiv.org/abs/2410.19278v1)|null|
|**2024-10-25**|**Ripple: Accelerating LLM Inference on Smartphones with Correlation-Aware Neuron Management**|Tuowei Wang et.al.|[2410.19274v1](http://arxiv.org/abs/2410.19274v1)|null|
|**2024-10-25**|**Autonomous Building Cyber-Physical Systems Using Decentralized Autonomous Organizations, Digital Twins, and Large Language Model**|Reachsak Ly et.al.|[2410.19262v1](http://arxiv.org/abs/2410.19262v1)|null|
|**2024-10-25**|**Not All Heads Matter: A Head-Level KV Cache Compression Method with Integrated Retrieval and Reasoning**|Yu Fu et.al.|[2410.19258v1](http://arxiv.org/abs/2410.19258v1)|null|
|**2024-10-25**|**The Reopening of Pandora's Box: Analyzing the Role of LLMs in the Evolving Battle Against AI-Generated Fake News**|Xinyu Wang et.al.|[2410.19250v1](http://arxiv.org/abs/2410.19250v1)|null|
|**2024-10-25**|**Designing LLM-Agents with Personalities: A Psychometric Approach**|Muhua Huang et.al.|[2410.19238v1](http://arxiv.org/abs/2410.19238v1)|null|
|**2024-10-25**|**Learning Diffusion Policies from Demonstrations For Compliant Contact-rich Manipulation**|Malek Aburub et.al.|[2410.19235v1](http://arxiv.org/abs/2410.19235v1)|null|
|**2024-10-25**|**Developing a Tutoring Dialog Dataset to Optimize LLMs for Educational Use**|Menna Fateen et.al.|[2410.19231v1](http://arxiv.org/abs/2410.19231v1)|null|
|**2024-10-25**|**Humanizing the Machine: Proxy Attacks to Mislead LLM Detectors**|Tianchun Wang et.al.|[2410.19230v1](http://arxiv.org/abs/2410.19230v1)|null|
|**2024-10-25**|**Hierarchical Mixture of Experts: Generalizable Learning for High-Level Synthesis**|Weikai Li et.al.|[2410.19225v1](http://arxiv.org/abs/2410.19225v1)|null|
|**2024-10-25**|**Integrating Large Language Models with Internet of Things Applications**|Mingyu Zong et.al.|[2410.19223v1](http://arxiv.org/abs/2410.19223v1)|null|
|**2024-10-25**|**Can Stories Help LLMs Reason? Curating Information Space Through Narrative**|Vahid Sadiri Javadi et.al.|[2410.19221v1](http://arxiv.org/abs/2410.19221v1)|null|
|**2024-10-25**|**Robot Behavior Personalization from Sparse User Feedback**|Maithili Patel et.al.|[2410.19219v1](http://arxiv.org/abs/2410.19219v1)|null|
|**2024-10-24**|**No Free Lunch: Fundamental Limits of Learning Non-Hallucinating Generative Models**|Changlong Wu et.al.|[2410.19217v1](http://arxiv.org/abs/2410.19217v1)|null|
|**2024-10-24**|**Inference time LLM alignment in single and multidomain preference spectrum**|Sadat Shahriar et.al.|[2410.19206v1](http://arxiv.org/abs/2410.19206v1)|null|
|**2024-10-24**|**An Inverse Modeling Constrained Multi-Objective Evolutionary Algorithm Based on Decomposition**|Lucas R. C. Farias et.al.|[2410.19203v1](http://arxiv.org/abs/2410.19203v1)|null|
|**2024-10-24**|**Making Social Platforms Accessible: Emotion-Aware Speech Generation with Integrated Text Analysis**|Suparna De et.al.|[2410.19199v1](http://arxiv.org/abs/2410.19199v1)|null|
|**2024-10-24**|**Label Set Optimization via Activation Distribution Kurtosis for Zero-shot Classification with Generative Models**|Yue Li et.al.|[2410.19195v1](http://arxiv.org/abs/2410.19195v1)|null|
|**2024-10-24**|**Enriching GNNs with Text Contextual Representations for Detecting Disinformation Campaigns on Social Media**|Bruno Croso Cunha da Silva et.al.|[2410.19193v1](http://arxiv.org/abs/2410.19193v1)|null|
|**2024-10-24**|**Tailored-LLaMA: Optimizing Few-Shot Learning in Pruned LLaMA Models with Task-Specific Prompts**|Danyal Aftab et.al.|[2410.19185v1](http://arxiv.org/abs/2410.19185v1)|null|
|**2024-10-24**|**No Argument Left Behind: Overlapping Chunks for Faster Processing of Arbitrarily Long Legal Texts**|Israel Fama et.al.|[2410.19184v1](http://arxiv.org/abs/2410.19184v1)|null|
|**2024-10-24**|**Indication Finding: a novel use case for representation learning**|Maren Eckhoff et.al.|[2410.19174v1](http://arxiv.org/abs/2410.19174v1)|null|
|**2024-10-24**|**MMAU: A Massive Multi-Task Audio Understanding and Reasoning Benchmark**|S Sakshi et.al.|[2410.19168v1](http://arxiv.org/abs/2410.19168v1)|null|
|**2024-10-24**|**Adversarial Attacks on Large Language Models Using Regularized Relaxation**|Samuel Jacob Chacko et.al.|[2410.19160v1](http://arxiv.org/abs/2410.19160v1)|null|
|**2024-10-24**|**Lived Experience Not Found: LLMs Struggle to Align with Experts on Addressing Adverse Drug Reactions from Psychiatric Medication Use**|Mohit Chandra et.al.|[2410.19155v1](http://arxiv.org/abs/2410.19155v1)|null|
|**2024-10-24**|**A Test of Time: Predicting the Sustainable Success of Online Collaboration in Wikipedia**|Abraham Israeli et.al.|[2410.19150v1](http://arxiv.org/abs/2410.19150v1)|null|
|**2024-10-24**|**Visual Text Matters: Improving Text-KVQA with Visual Text Entity Knowledge-aware Large Multimodal Assistant**|Abhirama Subramanyam Penamakuri et.al.|[2410.19144v1](http://arxiv.org/abs/2410.19144v1)|[link](https://github.com/vl2g/KaLMA)|
|**2024-10-24**|**PDL: A Declarative Prompt Programming Language**|Mandana Vaziri et.al.|[2410.19135v1](http://arxiv.org/abs/2410.19135v1)|null|
|**2024-10-24**|**AlignCap: Aligning Speech Emotion Captioning to Human Preferences**|Ziqi Liang et.al.|[2410.19134v1](http://arxiv.org/abs/2410.19134v1)|null|
|**2024-10-24**|**Hybrid Preferences: Learning to Route Instances for Human vs. AI Feedback**|Lester James V. Miranda et.al.|[2410.19133v1](http://arxiv.org/abs/2410.19133v1)|[link](https://github.com/allenai/hybrid-preferences)|
|**2024-10-24**|**Research on Key Technologies for Cross-Cloud Federated Training of Large Language Models**|Haowei Yang et.al.|[2410.19130v1](http://arxiv.org/abs/2410.19130v1)|null|
|**2024-10-24**|**Retrieving Implicit and Explicit Emotional Events Using Large Language Models**|Guimin Hu et.al.|[2410.19128v1](http://arxiv.org/abs/2410.19128v1)|null|
|**2024-10-24**|**Read-ME: Refactorizing LLMs as Router-Decoupled Mixture of Experts with System Co-Design**|Ruisi Cai et.al.|[2410.19123v1](http://arxiv.org/abs/2410.19123v1)|null|
|**2024-10-24**|**LLM Tree Search**|Dylan Wilson et.al.|[2410.19117v1](http://arxiv.org/abs/2410.19117v1)|null|
|**2024-10-24**|**Bio2Token: All-atom tokenization of any biomolecular structure with Mamba**|Andrew Liu et.al.|[2410.19110v1](http://arxiv.org/abs/2410.19110v1)|null|

#### Abstracts
##### **The Potential and Value of AI Chatbot in Personalized Cognitive Training**
2410.19733v1 by Zilong Wang, Nan Chen, Luna K. Qiu, Ling Yue, Geli Guo, Yang Ou, Shiqi Jiang, Yuqing Yang, Lili Qiu

In recent years, the rapid aging of the global population has led to an
increase in cognitive disorders, such as Alzheimer's disease, presenting
significant public health challenges. Although no effective treatments
currently exist to reverse Alzheimer's, prevention and early intervention,
including cognitive training, are critical. This report explores the potential
of AI chatbots in enhancing personalized cognitive training. We introduce ReMe,
a web-based framework designed to create AI chatbots that facilitate cognitive
training research, specifically targeting episodic memory tasks derived from
personal life logs. By leveraging large language models, ReMe provides enhanced
user-friendly, interactive, and personalized training experiences. Case studies
demonstrate ReMe's effectiveness in engaging users through life recall and
open-ended language puzzles, highlighting its potential to improve cognitive
training design. Despite promising results, further research is needed to
validate training effectiveness through large-scale studies that include
cognitive ability evaluations. Overall, ReMe offers a promising approach to
personalized cognitive training, utilizing AI capabilities to meet the growing
demand for non-pharmacological interventions in cognitive health, with future
research aiming to expand its applications and efficacy.

摘要：近年来，全球人口快速老龄化，导致阿尔茨海默病等认知障碍症患者数量增加，给公共卫生带来了重大挑战。尽管目前还没有有效的治疗方法可以逆转阿尔茨海默病，但预防和早期干预（包括认知训练）至关重要。本报告探讨了人工智能聊天机器人增强个性化认知训练的潜力。我们介绍了 ReMe，这是一个基于网络的框架，旨在创建人工智能聊天机器人，促进认知训练研究，特别是针对源自个人生活日志的情景记忆任务。通过利用大型语言模型，ReMe 提供了增强型用户友好、互动且个性化的训练体验。案例研究展示了 ReMe 通过生活回忆和开放式语言谜题吸引用户的有效性，突出了它在改善认知训练设计方面的潜力。尽管结果很有希望，但仍需要进一步的研究，通过包括认知能力评估的大规模研究来验证训练的有效性。总体而言，ReMe 为个性化认知训练提供了一种有前景的方法，利用人工智能功能来满足对认知健康中非药物干预措施不断增长的需求，未来的研究旨在扩展其应用和疗效。

##### **Rethinking Visual Dependency in Long-Context Reasoning for Large Vision-Language Models**
2410.19732v1 by Yucheng Zhou, Zhi Rao, Jun Wan, Jianbing Shen

Large Vision-Language Models (LVLMs) excel in cross-model tasks but
experience performance declines in long-context reasoning due to overreliance
on textual information and reduced visual dependency. In this study, we
empirically analyze LVLMs in long-context reasoning, revealing that increased
context length leads to a higher dependence on language at the expense of
visual dependency. To address this issue, we propose a novel training-free
context pruning method that selectively removes less critical textual
information. Our approach enhances visual dependency and reduces textual noise,
thereby improving LVLM performance in long-context reasoning. We validate our
method by constructing a long-context dataset, demonstrating its effectiveness
across various LVLMs. Moreover, further analysis confirms the robustness of
different token pruning strategies and preliminary explores scaling laws
between pruning rates and context length.

摘要：大型視覺語言模型 (LVLMs) 在跨模型任務中表現出色，但由於過度依賴文字資訊和視覺依賴性降低，在長語境推理中會出現效能下降。在本研究中，我們實證分析了 LVLMs 在長語境推理中的表現，發現語境長度增加會導致對語言的依賴性升高，而視覺依賴性則會降低。為了解決這個問題，我們提出了一種新穎的免訓練語境修剪方法，可以選擇性地移除較不重要的文字資訊。我們的做法增強了視覺依賴性並減少了文字雜訊，進而改善了 LVLM 在長語境推理中的效能。我們透過建構一個長語境資料集來驗證我們的做法，證明其在各種 LVLMs 中的有效性。此外，進一步的分析證實了不同權杖修剪策略的穩健性，並初步探討了修剪率和語境長度之間的規模定律。

##### **Counting Ability of Large Language Models and Impact of Tokenization**
2410.19730v1 by Xiang Zhang, Juntai Cao, Chenyu You

Transformers, the backbone of modern large language models (LLMs), face
inherent architectural limitations that impede their reasoning capabilities.
Unlike recurrent networks, Transformers lack recurrent connections, confining
them to constant-depth computation. This restriction places them in the
complexity class TC$^0$, making them theoretically incapable of solving tasks
that demand increasingly deep reasoning as input length grows. Counting, a
fundamental component of many reasoning tasks, also requires reasoning depth to
grow linearly to be performed inductively. While previous studies have
established the upper limits of counting ability in Transformer-based expert
models (i.e., models specifically trained for counting tasks), these findings
do not directly extend to general-purpose LLMs due to differences in reasoning
mechanisms. Recent work has highlighted how Chain of Thought (CoT) reasoning
can help alleviate some of the architectural limitations of Transformers in
counting tasks. However, little attention has been paid to the role of
tokenization in these models. Unlike expert models that often use
character-level tokenization, LLMs typically rely on byte-level (BPE)
tokenizers, which fundamentally alters the way reasoning is processed. Our work
investigates the impact of tokenization on the counting abilities of LLMs,
uncovering substantial performance variations based on input tokenization
differences. We provide both theoretical and experimental analyses, offering
insights into how tokenization choices can undermine models' theoretical
computability, thereby inspiring the design of new tokenization methods to
enhance reasoning in LLMs.

摘要：<paragraph>作為現代大型語言模型 (LLM) 的骨幹，Transformer 面臨固有的架構限制，這會阻礙其推理能力。與遞迴網路不同，Transformer 缺少遞迴連接，將其限制在恆定深度計算中。這種限制將它們置於複雜度類別 TC$^0$ 中，從理論上來說，它們無法解決隨著輸入長度增長而需要越來越深入推理的任務。作為許多推理任務的基本組成部分，計數也需要推理深度以線性增長才能歸納執行。雖然先前的研究已經確定了基於 Transformer 的專家模型（即專門針對計數任務訓練的模型）中的計數能力的上限，但由於推理機制的差異，這些發現並不能直接延伸到通用 LLM。最近的研究強調了思想鏈 (CoT) 推理如何有助於緩解 Transformer 在計數任務中的某些架構限制。然而，很少有人關注這些模型中標記化的作用。與通常使用字元級標記化的專家模型不同，LLM 通常依賴於位元組級 (BPE) 標記化器，這從根本上改變了推理處理的方式。我們的研究調查了標記化對 LLM 計數能力的影響，根據輸入標記化的差異揭示了大量的效能變化。我們提供了理論和實驗分析，深入了解標記化選擇如何損害模型的理論可計算性，從而激勵設計新的標記化方法以增強 LLM 中的推理。</paragraph>

##### **FISHNET: Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert Swarms, and Task Planning**
2410.19727v1 by Nicole Cho, Nishan Srishankar, Lucas Cecchi, William Watson

Financial intelligence generation from vast data sources has typically relied
on traditional methods of knowledge-graph construction or database engineering.
Recently, fine-tuned financial domain-specific Large Language Models (LLMs),
have emerged. While these advancements are promising, limitations such as high
inference costs, hallucinations, and the complexity of concurrently analyzing
high-dimensional financial data, emerge. This motivates our invention FISHNET
(Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning,
Expert swarming, and Task planning), an agentic architecture that accomplishes
highly complex analytical tasks for more than 98,000 regulatory filings that
vary immensely in terms of semantics, data hierarchy, or format. FISHNET shows
remarkable performance for financial insight generation (61.8% success rate
over 5.0% Routing, 45.6% RAG R-Precision). We conduct rigorous ablations to
empirically prove the success of FISHNET, each agent's importance, and the
optimized performance of assembling all agents. Our modular architecture can be
leveraged for a myriad of use-cases, enabling scalability, flexibility, and
data integrity that are critical for financial tasks.

摘要：財務情報生成通常依賴於傳統的知識圖表建構或資料庫工程方法，這些方法來自於龐大的資料來源。最近，針對財務領域進行微調的大型語言模型 (LLM) 已應運而生。儘管這些進展令人振奮，但仍存在一些限制，例如高推理成本、幻覺，以及同時分析高維度財務資料的複雜性。這促使我們發明了 FISHNET（來自子查詢、協調、神經條件化、專家群集和任務規劃的財務情報），這是一種代理架構，可針對超過 98,000 份法規文件執行高度複雜的分析任務，而這些文件在語義、資料階層或格式方面差異極大。FISHNET 在產生財務見解方面表現出色（成功率為 61.8%，路由率為 5.0%，RAG R-Precision 為 45.6%）。我們進行了嚴格的消融，以實證證明 FISHNET 的成功、每個代理的重要性，以及組裝所有代理的最佳化效能。我們模組化的架構可運用於各種使用案例，提供財務任務至關重要的可擴充性、彈性和資料完整性。

##### **Sparse Decomposition of Graph Neural Networks**
2410.19723v1 by Yaochen Hu, Mai Zeng, Ge Zhang, Pavel Rumiantsev, Liheng Ma, Yingxue Zhang, Mark Coates

Graph Neural Networks (GNN) exhibit superior performance in graph
representation learning, but their inference cost can be high, due to an
aggregation operation that can require a memory fetch for a very large number
of nodes. This inference cost is the major obstacle to deploying GNN models
with \emph{online prediction} to reflect the potentially dynamic node features.
To address this, we propose an approach to reduce the number of nodes that are
included during aggregation. We achieve this through a sparse decomposition,
learning to approximate node representations using a weighted sum of linearly
transformed features of a carefully selected subset of nodes within the
extended neighbourhood. The approach achieves linear complexity with respect to
the average node degree and the number of layers in the graph neural network.
We introduce an algorithm to compute the optimal parameters for the sparse
decomposition, ensuring an accurate approximation of the original GNN model,
and present effective strategies to reduce the training time and improve the
learning process. We demonstrate via extensive experiments that our method
outperforms other baselines designed for inference speedup, achieving
significant accuracy gains with comparable inference times for both node
classification and spatio-temporal forecasting tasks.

摘要：圖形神經網路 (GNN) 在圖形表示學習中展現出優異的效能，但由於需要為大量節點擷取記憶體的聚合運算，因此推論成本可能很高。這個推論成本是部署 GNN 模型以進行「線上預測」以反映潛在動態節點特徵的主要障礙。為了解決這個問題，我們提出了一種減少在聚合期間包含的節點數量的方法。我們透過稀疏分解來達成此目的，學習使用經過仔細挑選的延伸鄰域中節點的線性轉換特徵的加權總和來近似節點表示。這個方法在圖形神經網路中對於平均節點度數和層數來說，達到了線性複雜度。我們介紹了一種演算法來計算稀疏分解的最佳參數，確保準確近似原始的 GNN 模型，並提出有效的策略來減少訓練時間並改善學習過程。我們透過廣泛的實驗證明，我們的模型優於其他針對推論加速而設計的基準，在節點分類和時空預測任務中，以相近的推論時間獲得顯著的準確度提升。

##### **2D-DPO: Scaling Direct Preference Optimization with 2-Dimensional Supervision**
2410.19720v1 by Shilong Li, Yancheng He, Hui Huang, Xingyuan Bu, Jiaheng Liu, Hangyu Guo, Weixun Wang, Jihao Gu, Wenbo Su, Bo Zheng

Recent advancements in Direct Preference Optimization (DPO) have
significantly enhanced the alignment of Large Language Models (LLMs) with human
preferences, owing to its simplicity and effectiveness. However, existing
methods typically optimize a scalar score or ranking reward, thereby
overlooking the multi-dimensional nature of human preferences. In this work, we
propose to extend the preference of DPO to two dimensions: segments and
aspects. We first introduce a 2D supervision dataset called HelpSteer-2D. For
the segment dimension, we divide the response into sentences and assign scores
to each segment. For the aspect dimension, we meticulously design several
criteria covering the response quality rubrics. With the 2-dimensional signals
as feedback, we develop a 2D-DPO framework, decomposing the overall objective
into multi-segment and multi-aspect objectives. Extensive experiments on
popular benchmarks demonstrate that 2D-DPO performs better than methods that
optimize for scalar or 1-dimensional preferences.

摘要：近期在直接偏好最佳化（DPO）上的進展大幅提升了大型語言模型（LLM）與人類偏好的對齊，這歸功於其簡潔性和有效性。然而，現有的方法通常最佳化標量分數或排名獎勵，因而忽略了人類偏好的多維度本質。在這項研究中，我們提議將 DPO 的偏好延伸至兩個面向：片段和面向。我們首先引入一個稱為 HelpSteer-2D 的 2D 監督資料集。對於片段面向，我們將回應劃分為句子，並為每個片段指派分數。對於面向面向，我們仔細設計了涵蓋回應品質評分標準的數個準則。利用 2 維訊號作為回饋，我們開發了一個 2D-DPO 架構，將整體目標分解為多片段和多面向目標。在熱門基準上的廣泛實驗證明，2D-DPO 的表現優於最佳化標量或 1 維偏好的方法。

##### **Arabic Music Classification and Generation using Deep Learning**
2410.19719v1 by Mohamed Elshaarawy, Ashrakat Saeed, Mariam Sheta, Abdelrahman Said, Asem Bakr, Omar Bahaa, Walid Gomaa

This paper proposes a machine learning approach for classifying classical and
new Egyptian music by composer and generating new similar music. The proposed
system utilizes a convolutional neural network (CNN) for classification and a
CNN autoencoder for generation. The dataset used in this project consists of
new and classical Egyptian music pieces composed by different composers.
  To classify the music by composer, each sample is normalized and transformed
into a mel spectrogram. The CNN model is trained on the dataset using the mel
spectrograms as input features and the composer labels as output classes. The
model achieves 81.4\% accuracy in classifying the music by composer,
demonstrating the effectiveness of the proposed approach.
  To generate new music similar to the original pieces, a CNN autoencoder is
trained on a similar dataset. The model is trained to encode the mel
spectrograms of the original pieces into a lower-dimensional latent space and
then decode them back into the original mel spectrogram. The generated music is
produced by sampling from the latent space and decoding the samples back into
mel spectrograms, which are then transformed into audio.
  In conclusion, the proposed system provides a promising approach to
classifying and generating classical Egyptian music, which can be applied in
various musical applications, such as music recommendation systems, music
production, and music education.

摘要：<paragraph>這篇論文提出了一種機器學習方法，用於根據作曲家對古典和新埃及音樂進行分類，並生成類似的音樂。所提出的系統利用卷積神經網路 (CNN) 進行分類，並使用 CNN 自動編碼器進行生成。此專案中使用的資料集包含由不同作曲家創作的新古典埃及音樂作品。
若要根據作曲家對音樂進行分類，會將每個樣本正規化並轉換成梅爾頻譜圖。CNN 模型會使用梅爾頻譜圖作為輸入特徵，並使用作曲家標籤作為輸出類別，在資料集上進行訓練。此模型在根據作曲家對音樂進行分類時，達到了 81.4% 的準確度，證明了所提出方法的有效性。
若要生成與原始作品類似的音樂，會在類似的資料集上訓練 CNN 自動編碼器。此模型會訓練將原始作品的梅爾頻譜圖編碼成較低維度的潛在空間，然後再將其解碼回原始的梅爾頻譜圖。生成的音樂會透過在潛在空間中取樣，並將樣本解碼回梅爾頻譜圖，然後轉換成音訊。
結論來說，所提出的系統提供了一種有前途的方法，用於對古典埃及音樂進行分類和生成，可用於各種音樂應用中，例如音樂推薦系統、音樂製作和音樂教育。</paragraph>

##### **Adversarial Environment Design via Regret-Guided Diffusion Models**
2410.19715v1 by Hojun Chung, Junseo Lee, Minsoo Kim, Dohyeong Kim, Songhwai Oh

Training agents that are robust to environmental changes remains a
significant challenge in deep reinforcement learning (RL). Unsupervised
environment design (UED) has recently emerged to address this issue by
generating a set of training environments tailored to the agent's capabilities.
While prior works demonstrate that UED has the potential to learn a robust
policy, their performance is constrained by the capabilities of the environment
generation. To this end, we propose a novel UED algorithm, adversarial
environment design via regret-guided diffusion models (ADD). The proposed
method guides the diffusion-based environment generator with the regret of the
agent to produce environments that the agent finds challenging but conducive to
further improvement. By exploiting the representation power of diffusion
models, ADD can directly generate adversarial environments while maintaining
the diversity of training environments, enabling the agent to effectively learn
a robust policy. Our experimental results demonstrate that the proposed method
successfully generates an instructive curriculum of environments, outperforming
UED baselines in zero-shot generalization across novel, out-of-distribution
environments. Project page: https://github.com/rllab-snu.github.io/projects/ADD

摘要：在深度强化學習 (RL) 中，訓練出對環境變化具有魯棒性的代理仍然是一項重大挑戰。無監督環境設計 (UED) 最近興起，透過產生一套針對代理能力量身打造的訓練環境來解決此問題。雖然先前的研究表明 UED 有可能學習到穩健的策略，但其效能受到環境產生能力的限制。為此，我們提出了一種新穎的 UED 演算法，透過後悔引導擴散模型 (ADD) 進行對抗性環境設計。所提出的方法以代理的後悔為指導，引導基於擴散的環境產生器，產生代理覺得具有挑戰性但有助於進一步改進的環境。透過利用擴散模型的表示能力，ADD 可以直接產生對抗性環境，同時維持訓練環境的多樣性，使代理能夠有效地學習穩健的策略。我們的實驗結果表明，所提出的方法成功地產生了一套具有指導性的環境課程，在對新穎的、分布外環境進行零次學習泛化方面優於 UED 基準。專案頁面：https://github.com/rllab-snu.github.io/projects/ADD

##### **TimeSuite: Improving MLLMs for Long Video Understanding via Grounded Tuning**
2410.19702v1 by Xiangyu Zeng, Kunchang Li, Chenting Wang, Xinhao Li, Tianxiang Jiang, Ziang Yan, Songze Li, Yansong Shi, Zhengrong Yue, Yi Wang, Yali Wang, Yu Qiao, Limin Wang

Multimodal Large Language Models (MLLMs) have demonstrated impressive
performance in short video understanding. However, understanding long-form
videos still remains challenging for MLLMs. This paper proposes TimeSuite, a
collection of new designs to adapt the existing short-form video MLLMs for long
video understanding, including a simple yet efficient framework to process long
video sequence, a high-quality video dataset for grounded tuning of MLLMs, and
a carefully-designed instruction tuning task to explicitly incorporate the
grounding supervision in the traditional QA format. Specifically, based on
VideoChat, we propose our long-video MLLM, coined as VideoChat-T, by
implementing a token shuffling to compress long video tokens and introducing
Temporal Adaptive Position Encoding (TAPE) to enhance the temporal awareness of
visual representation. Meanwhile, we introduce the TimePro, a comprehensive
grounding-centric instruction tuning dataset composed of 9 tasks and 349k
high-quality grounded annotations. Notably, we design a new instruction tuning
task type, called Temporal Grounded Caption, to peform detailed video
descriptions with the corresponding time stamps prediction. This explicit
temporal location prediction will guide MLLM to correctly attend on the visual
content when generating description, and thus reduce the hallucination risk
caused by the LLMs. Experimental results demonstrate that our TimeSuite
provides a successful solution to enhance the long video understanding
capability of short-form MLLM, achieving improvement of 5.6% and 6.8% on the
benchmarks of Egoschema and VideoMME, respectively. In addition, VideoChat-T
exhibits robust zero-shot temporal grounding capabilities, significantly
outperforming the existing state-of-the-art MLLMs. After fine-tuning, it
performs on par with the traditional supervised expert models.

摘要：多模态大型语言模型 (MLLM) 已在短视频理解中展现了令人印象深刻的性能。然而，理解长篇视频对于 MLLM 来说仍然具有挑战性。本文提出了 TimeSuite，这是一组新设计，用于调整现有的短篇视频 MLLM 以理解长视频，包括一个简单但高效的框架来处理长视频序列、一个用于 MLLM 的基础微调的高质量视频数据集，以及一个精心设计的指令微调任务，以明确地将基础监督纳入传统的问答格式。具体来说，基于 VideoChat，我们提出了我们的长视频 MLLM，称为 VideoChat-T，通过实现令牌改组来压缩长视频令牌，并引入时间自适应位置编码 (TAPE) 来增强视觉表示的时间感知。同时，我们引入了 TimePro，这是一个全面的以基础为中心的指令微调数据集，由 9 个任务和 349k 个高质量的基础注释组成。值得注意的是，我们设计了一种新的指令微调任务类型，称为时间基础字幕，用于执行详细的视频描述，并预测相应的时间戳。这种明确的时间位置预测将指导 MLLM 在生成描述时正确关注视觉内容，从而降低由 LLM 引起的幻觉风险。实验结果表明，我们的 TimeSuite 提供了一个成功的解决方案，可以增强短篇 MLLM 的长视频理解能力，分别在 Egoschema 和 VideoMME 的基准上实现了 5.6% 和 6.8% 的改进。此外，VideoChat-T 展示了强大的零样本时间基础能力，明显优于现有的最先进的 MLLM。经过微调后，它的性能与传统的监督专家模型相当。

##### **IPPON: Common Sense Guided Informative Path Planning for Object Goal Navigation**
2410.19697v1 by Kaixian Qu, Jie Tan, Tingnan Zhang, Fei Xia, Cesar Cadena, Marco Hutter

Navigating efficiently to an object in an unexplored environment is a
critical skill for general-purpose intelligent robots. Recent approaches to
this object goal navigation problem have embraced a modular strategy,
integrating classical exploration algorithms-notably frontier exploration-with
a learned semantic mapping/exploration module. This paper introduces a novel
informative path planning and 3D object probability mapping approach. The
mapping module computes the probability of the object of interest through
semantic segmentation and a Bayes filter. Additionally, it stores probabilities
for common objects, which semantically guides the exploration based on common
sense priors from a large language model. The planner terminates when the
current viewpoint captures enough voxels identified with high confidence as the
object of interest. Although our planner follows a zero-shot approach, it
achieves state-of-the-art performance as measured by the Success weighted by
Path Length (SPL) and Soft SPL in the Habitat ObjectNav Challenge 2023,
outperforming other works by more than 20%. Furthermore, we validate its
effectiveness on real robots. Project webpage: https://ippon-paper.github.io/

摘要：在未探索的环境中有效导航到一个物体是通用智能机器人的一项关键技能。最近针对此物体目标导航问题的方法采用了模块化策略，将经典探索算法（尤其是边界探索）与学习的语义映射/探索模块相结合。本文介绍了一种新颖的信息路径规划和 3D 对象概率映射方法。映射模块通过语义分割和贝叶斯滤波器计算目标对象的概率。此外，它存储常见对象的概率，这些概率基于大语言模型的常识先验语义地指导探索。当当前视点捕获到足够多被高置信度识别为目标对象的体素时，规划器会终止。虽然我们的规划器遵循零次学习方法，但它在 Habitat ObjectNav Challenge 2023 中以路径长度加权成功率 (SPL) 和软 SPL 衡量时，实现了最先进的性能，比其他工作高出 20% 以上。此外，我们在真实机器人上验证了它的有效性。项目网页：https://ippon-paper.github.io/

##### **Less is More: Extreme Gradient Boost Rank-1 Adaption for Efficient Finetuning of LLMs**
2410.19694v1 by Yifei Zhang, Hao Zhu, Aiwei Liu, Han Yu, Piotr Koniusz, Irwin King

Fine-tuning Large Language Models (LLMs) has become a crucial technique for
adapting pre-trained models to downstream tasks. However, the enormous size of
LLMs poses significant challenges in terms of computational complexity and
resource requirements. Low-Rank Adaptation (LoRA) has emerged as a promising
solution. However, there exists a gap between the practical performance of
low-rank adaptations and its theoretical optimum. In this work, we propose
eXtreme Gradient Boosting LoRA (XGBLoRA), a novel framework that bridges this
gap by leveraging the power of ensemble learning. Inspired by gradient
boosting, XGBLoRA iteratively learns and merges a sequence of LoRA adaptations
to refine model predictions. It achieves better performance than the standard
LoRA, while enjoying the computational efficiency of rank-1 adaptations. We
provide theoretical analysis to show the convergence and optimality of our
approach, and conduct extensive experiments on a range of natural language
processing tasks. The results demonstrate that XGBLoRA consistently outperforms
standard LoRA and achieves performance comparable to full fine-tuning with
significantly fewer trainable parameters. This work advances
parameter-efficient fine-tuning for LLMs, and offers a promising solution for
adapting LLMs to downstream tasks while optimizing performance and efficiency.

摘要：微调大型语言模型 (LLM) 已成为将预训练模型调整至下游任务的关键技术。然而，LLM 的庞大规模在计算复杂度和资源需求方面带来了严峻挑战。低秩自适应 (LoRA) 已成为一项颇具前景的解决方案。然而，低秩自适应的实际性能与其理论最优值之间存在差距。在这项工作中，我们提出了 XGBLoRA（eXtreme Gradient Boosting LoRA），这是一个新颖的框架，它通过利用集成学习的力量来弥合这一差距。受梯度提升的启发，XGBLoRA 迭代学习并合并一系列 LoRA 自适应来优化模型预测。它比标准 LoRA 取得了更好的性能，同时享受 1 级自适应的计算效率。我们提供了理论分析来展示我们方法的收敛性和最优性，并在各种自然语言处理任务上进行了广泛的实验。结果表明，XGBLoRA 始终优于标准 LoRA，并且实现了与完全微调相当的性能，同时可训练参数明显更少。这项工作推进了 LLM 的参数高效微调，并为在优化性能和效率的同时将 LLM 调整至下游任务提供了有前景的解决方案。

##### **AGENT-CQ: Automatic Generation and Evaluation of Clarifying Questions for Conversational Search with LLMs**
2410.19692v1 by Clemencia Siro, Yifei Yuan, Mohammad Aliannejadi, Maarten de Rijke

Generating diverse and effective clarifying questions is crucial for
improving query understanding and retrieval performance in open-domain
conversational search (CS) systems. We propose AGENT-CQ (Automatic GENeration,
and evaluaTion of Clarifying Questions), an end-to-end LLM-based framework
addressing the challenges of scalability and adaptability faced by existing
methods that rely on manual curation or template-based approaches. AGENT-CQ
consists of two stages: a generation stage employing LLM prompting strategies
to generate clarifying questions, and an evaluation stage (CrowdLLM) that
simulates human crowdsourcing judgments using multiple LLM instances to assess
generated questions and answers based on comprehensive quality metrics.
Extensive experiments on the ClariQ dataset demonstrate CrowdLLM's
effectiveness in evaluating question and answer quality. Human evaluation and
CrowdLLM show that the AGENT-CQ - generation stage, consistently outperforms
baselines in various aspects of question and answer quality. In retrieval-based
evaluation, LLM-generated questions significantly enhance retrieval
effectiveness for both BM25 and cross-encoder models compared to
human-generated questions.

摘要：生成多樣且有效的澄清問題對於改善開放領域對話式搜尋 (CS) 系統中的查詢理解和檢索成效至關重要。我們提出 AGENT-CQ（自動生成和評估澄清問題），一種端到端的基於 LLM 的架構，解決現有方法所面臨的可擴充性和適應性挑戰，這些方法依賴於手動策劃或基於範本的方法。AGENT-CQ 包含兩個階段：一個生成階段，使用 LLM 提示策略來生成澄清問題，以及一個評估階段 (CrowdLLM)，使用多個 LLM 實例模擬人工眾包判斷，以根據全面的品質指標評估產生的問題和答案。在 ClariQ 資料集上進行的廣泛實驗證明了 CrowdLLM 在評估問題和答案品質方面的有效性。人工評估和 CrowdLLM 顯示，AGENT-CQ - 生成階段在問題和答案品質的各個方面始終優於基準。在基於檢索的評估中，與人工產生的問題相比，LLM 生成的問題顯著提升了 BM25 和交叉編碼模型的檢索成效。

##### **Impact of Leakage on Data Harmonization in Machine Learning Pipelines in Class Imbalance Across Sites**
2410.19643v1 by Nicolás Nieto, Simon B. Eickhoff, Christian Jung, Martin Reuter, Kersten Diers, Malte Kelm, Artur Lichtenberg, Federico Raimondo, Kaustubh R. Patil

Machine learning (ML) models benefit from large datasets. Collecting data in
biomedical domains is costly and challenging, hence, combining datasets has
become a common practice. However, datasets obtained under different conditions
could present undesired site-specific variability. Data harmonization methods
aim to remove site-specific variance while retaining biologically relevant
information. This study evaluates the effectiveness of popularly used
ComBat-based methods for harmonizing data in scenarios where the class balance
is not equal across sites. We find that these methods struggle with data
leakage issues. To overcome this problem, we propose a novel approach
PrettYharmonize, designed to harmonize data by pretending the target labels. We
validate our approach using controlled datasets designed to benchmark the
utility of harmonization. Finally, using real-world MRI and clinical data, we
compare leakage-prone methods with PrettYharmonize and show that it achieves
comparable performance while avoiding data leakage, particularly in
site-target-dependence scenarios.

摘要：機器學習 (ML) 模型受益於大型資料集。在生物醫學領域中收集資料既昂貴又具有挑戰性，因此，合併資料集已成為一種常見的做法。然而，在不同條件下獲得的資料集可能會出現不希望的特定於場域的可變性。資料調和方法旨在消除特定於場域的差異，同時保留生物學相關資訊。本研究評估了在類別平衡在不同場域中不均衡的情況下，廣泛使用的基於 ComBat 的方法調和資料的有效性。我們發現這些方法在資料外洩問題上遇到困難。為了克服這個問題，我們提出了一種新穎的方法 PrettYharmonize，旨在透過假裝目標標籤來調和資料。我們使用旨在基準化調和效用的受控資料集來驗證我們的做法。最後，使用真實世界的 MRI 和臨床資料，我們將容易洩漏的方法與 PrettYharmonize 進行比較，並證明它在避免資料洩漏的同時實現了可比較的效能，特別是在場域目標依賴的情況下。

##### **VARS: Vision-based Assessment of Risk in Security Systems**
2410.19642v1 by Pranav Gupta, Pratham Gohil, Sridhar S

The accurate prediction of danger levels in video content is critical for
enhancing safety and security systems, particularly in environments where quick
and reliable assessments are essential. In this study, we perform a comparative
analysis of various machine learning and deep learning models to predict danger
ratings in a custom dataset of 100 videos, each containing 50 frames, annotated
with human-rated danger scores ranging from 0 to 10. The danger ratings are
further classified into three categories: no alert (less than 7)and high alert
(greater than equal to 7). Our evaluation covers classical machine learning
models, such as Support Vector Machines, as well as Neural Networks, and
transformer-based models. Model performance is assessed using standard metrics
such as accuracy, F1-score, and mean absolute error (MAE), and the results are
compared to identify the most robust approach. This research contributes to
developing a more accurate and generalizable danger assessment framework for
video-based risk detection.

摘要：準確預測影片內容的危險等級對於提升安全系統至關重要，特別是在需要快速且可靠評估的環境中。在本研究中，我們針對各種機器學習和深度學習模型進行比較分析，以預測一個自訂資料集中的危險評分，該資料集包含 100 部影片，每部影片包含 50 個影格，並附有人類評定的危險分數，範圍從 0 到 10。危險評分進一步分為三類：無警示（小於 7）、中度警示（等於或大於 7）、高度警示（等於或大於 7）。我們的評估涵蓋了經典機器學習模型，例如支援向量機，以及神經網路和基於轉換器的模型。模型效能使用標準指標進行評估，例如準確度、F1 分數和平均絕對誤差 (MAE)，並比較結果以找出最穩健的方法。這項研究有助於開發一個更準確且可概括的危險評估架構，用於基於影片的風險偵測。

##### **Planning-Aware Diffusion Networks for Enhanced Motion Forecasting in Autonomous Driving**
2410.19639v1 by Liu Yunhao, Ding Hong, Zhang Ziming, Wang Huixin, Liu Jinzhao, Xi Suyang

Autonomous driving technology has seen significant advancements, but existing
models often fail to fully capture the complexity of multi-agent environments,
where interactions between dynamic agents are critical. To address this, we
propose the Planning-Integrated Forecasting Model (PIFM), a novel framework
inspired by neural mechanisms governing decision-making and multi-agent
coordination in the brain. PIFM leverages rich contextual information,
integrating road structures, traffic rules, and the behavior of surrounding
vehicles to improve both the accuracy and interpretability of predictions. By
adopting a diffusion-based architecture, akin to neural diffusion processes
involved in predicting and planning, PIFM is able to forecast future
trajectories of all agents within a scenario. This architecture enhances model
transparency, as it parallels the brain's method of dynamically adjusting
predictions based on external stimuli and other agents'behaviors. Extensive
experiments validate PIFM's capacity to provide interpretable,
neuroscience-driven solutions for safer and more efficient autonomous driving
systems, with an extremely low number of parameters.

摘要：自動駕駛技術已取得顯著進展，但現有模型通常無法完全掌握多主體環境的複雜性，其中動態主體之間的互動至關重要。為了解決這個問題，我們提出了規劃整合預測模型 (PIFM)，這是一個新穎的框架，靈感來自於控制大腦中決策制定和多主體協調的神經機制。PIFM 利用豐富的上下文資訊，整合道路結構、交通規則和周圍車輛的行為，以提高預測的準確性和可解釋性。透過採用基於擴散的架構，類似於預測和規劃中涉及的神經擴散過程，PIFM 能夠預測場景中所有主體的未來軌跡。這種架構增強了模型的透明度，因為它與大腦根據外部刺激和其它主體行為動態調整預測的方法相平行。廣泛的實驗驗證了 PIFM 提供可解釋、由神經科學驅動的解決方案的能力，以實現更安全、更有效率的自動駕駛系統，且參數數量極低。

##### **A distributional simplicity bias in the learning dynamics of transformers**
2410.19637v1 by Riccardo Rende, Federica Gerace, Alessandro Laio, Sebastian Goldt

The remarkable capability of over-parameterised neural networks to generalise
effectively has been explained by invoking a ``simplicity bias'': neural
networks prevent overfitting by initially learning simple classifiers before
progressing to more complex, non-linear functions. While simplicity biases have
been described theoretically and experimentally in feed-forward networks for
supervised learning, the extent to which they also explain the remarkable
success of transformers trained with self-supervised techniques remains
unclear. In our study, we demonstrate that transformers, trained on natural
language data, also display a simplicity bias. Specifically, they sequentially
learn many-body interactions among input tokens, reaching a saturation point in
the prediction error for low-degree interactions while continuing to learn
high-degree interactions. To conduct this analysis, we develop a procedure to
generate \textit{clones} of a given natural language data set, which rigorously
capture the interactions between tokens up to a specified order. This approach
opens up the possibilities of studying how interactions of different orders in
the data affect learning, in natural language processing and beyond.

摘要：過度參數化神經網路能夠有效泛化的顯著能力，已透過援用「簡潔偏差」來解釋：神經網路會在進展到更複雜的非線性函數之前，先學習簡單的分類器來防止過度擬合。雖然簡潔偏差已在監督式學習的前饋網路中在理論上和實驗上得到描述，但它們在多大程度上也能解釋使用自監督技術訓練的Transformer獲得顯著成功，這一點仍不清楚。在我們的研究中，我們證明了在自然語言資料上訓練的Transformer也顯示出簡潔偏差。具體來說，它們會依序學習輸入標記之間的多體交互作用，在低階交互作用的預測誤差達到飽和點時，會繼續學習高階交互作用。為了進行此分析，我們開發了一個程序來產生特定自然語言資料集的「複製」，該程序嚴謹地擷取最多到指定順序的標記之間的交互作用。這種方法開啟了研究資料中不同順序的交互作用如何影響學習的可能性，這不僅限於自然語言處理。

##### **Knowledge Graph Enhanced Language Agents for Recommendation**
2410.19627v1 by Taicheng Guo, Chaochun Liu, Hai Wang, Varun Mannam, Fang Wang, Xin Chen, Xiangliang Zhang, Chandan K. Reddy

Language agents have recently been used to simulate human behavior and
user-item interactions for recommendation systems. However, current language
agent simulations do not understand the relationships between users and items,
leading to inaccurate user profiles and ineffective recommendations. In this
work, we explore the utility of Knowledge Graphs (KGs), which contain extensive
and reliable relationships between users and items, for recommendation. Our key
insight is that the paths in a KG can capture complex relationships between
users and items, eliciting the underlying reasons for user preferences and
enriching user profiles. Leveraging this insight, we propose Knowledge Graph
Enhanced Language Agents(KGLA), a framework that unifies language agents and KG
for recommendation systems. In the simulated recommendation scenario, we
position the user and item within the KG and integrate KG paths as natural
language descriptions into the simulation. This allows language agents to
interact with each other and discover sufficient rationale behind their
interactions, making the simulation more accurate and aligned with real-world
cases, thus improving recommendation performance. Our experimental results show
that KGLA significantly improves recommendation performance (with a 33%-95%
boost in NDCG@1 among three widely used benchmarks) compared to the previous
best baseline method.

摘要：語言代理最近已被用於模擬人類行為和推薦系統中的使用者項目互動。然而，目前的語言代理模擬並未了解使用者和項目之間的關係，導致使用者輪廓不準確和推薦效果不佳。在這項工作中，我們探討了知識圖譜 (KG) 的效用，其中包含使用者和項目之間廣泛且可靠的關係，以供推薦。我們的關鍵見解是，KG 中的路徑可以捕捉使用者和項目之間的複雜關係，引出使用者偏好的根本原因並豐富使用者輪廓。利用此見解，我們提出了知識圖譜增強語言代理 (KGLA)，一個統一語言代理和 KG 以用於推薦系統的架構。在模擬推薦情境中，我們將使用者和項目定位在 KG 中，並將 KG 路徑整合為自然語言描述到模擬中。這允許語言代理彼此互動並發現其互動背後的充分依據，使模擬更準確且與實際案例相符，從而改善推薦效能。我們的實驗結果顯示，與先前最佳基準方法相比，KGLA 大幅改善了推薦效能（在三個廣泛使用的基準中，NDCG@1 提升了 33%-95%）。

##### **OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization**
2410.19609v1 by Hongliang He, Wenlin Yao, Kaixin Ma, Wenhao Yu, Hongming Zhang, Tianqing Fang, Zhenzhong Lan, Dong Yu

The rapid development of large language and multimodal models has sparked
significant interest in using proprietary models, such as GPT-4o, to develop
autonomous agents capable of handling real-world scenarios like web navigation.
Although recent open-source efforts have tried to equip agents with the ability
to explore environments and continuously improve over time, they are building
text-only agents in synthetic environments where the reward signals are clearly
defined. Such agents struggle to generalize to realistic settings that require
multimodal perception abilities and lack ground-truth signals. In this paper,
we introduce an open-source framework designed to facilitate the development of
multimodal web agent that can autonomously conduct real-world exploration and
improve itself. We first train the base model with imitation learning to gain
the basic abilities. We then let the agent explore the open web and collect
feedback on its trajectories. After that, it further improves its policy by
learning from well-performing trajectories judged by another general-purpose
model. This exploration-feedback-optimization cycle can continue for several
iterations. Experimental results show that our web agent successfully improves
itself after each iteration, demonstrating strong performance across multiple
test sets.

摘要：大型語言和多模態模型的快速發展引起了人們對使用專有模型（例如 GPT-4o）開發自主代理的濃厚興趣，這些模型能夠處理像網路導航這樣的真實世界場景。儘管最近的開源工作已嘗試讓代理具備探索環境和隨著時間推移持續改進的能力，但它們正在合成環境中建立純文字代理，其中獎勵訊號被清楚地定義。此類代理難以推廣到需要多模態感知能力且缺乏基本事實訊號的現實設定。在本文中，我們介紹了一個開源框架，旨在促進多模態網路代理的開發，該代理可以自主進行真實世界的探索並自我改進。我們首先使用模仿學習訓練基礎模型，以獲得基本能力。然後，我們讓代理探索開放網路並收集其軌跡的回饋。在那之後，它進一步改善其政策，方法是從另一個通用模型判斷的表現良好的軌跡中學習。這種探索-回饋-最佳化循環可以持續進行多次迭代。實驗結果表明，我們的網路代理在每次迭代後都能成功改進自己，在多個測試集中展示出強勁的效能。

##### **CoqPilot, a plugin for LLM-based generation of proofs**
2410.19605v1 by Andrei Kozyrev, Gleb Solovev, Nikita Khramov, Anton Podkopaev

We present CoqPilot, a VS Code extension designed to help automate writing of
Coq proofs. The plugin collects the parts of proofs marked with the admit
tactic in a Coq file, i.e., proof holes, and combines LLMs along with
non-machine-learning methods to generate proof candidates for the holes. Then,
CoqPilot checks if each proof candidate solves the given subgoal and, if
successful, replaces the hole with it. The focus of CoqPilot is twofold.
Firstly, we want to allow users to seamlessly combine multiple Coq generation
approaches and provide a zero-setup experience for our tool. Secondly, we want
to deliver a platform for LLM-based experiments on Coq proof generation. We
developed a benchmarking system for Coq generation methods, available in the
plugin, and conducted an experiment using it, showcasing the framework's
possibilities. Demo of CoqPilot is available at: https://youtu.be/oB1Lx-So9Lo.
Code at: https://github.com/JetBrains-Research/coqpilot

摘要：我們展示了 CoqPilot，一個 VS Code 擴充功能，旨在幫助自動化 Coq 證明撰寫。外掛程式會收集 Coq 檔案中標記為 admit 戰術的證明部分，也就是證明漏洞，並結合 LLM 與非機器學習方法，為這些漏洞產生證明候選。然後，CoqPilot 會檢查每個證明候選是否解決了給定的子目標，如果成功，就會用它取代漏洞。CoqPilot 的重點有兩個方面。首先，我們希望允許使用者無縫結合多種 Coq 產生方法，並為我們的工具提供零設定體驗。其次，我們希望提供一個基於 LLM 的 Coq 證明產生實驗平台。我們開發了一個基準系統，可用於外掛程式中的 Coq 產生方法，並使用它進行了一個實驗，展示了這個架構的可能性。CoqPilot 的示範可以在這裡找到：https://youtu.be/oB1Lx-So9Lo。程式碼在這裡：https://github.com/JetBrains-Research/coqpilot

##### **Take Caution in Using LLMs as Human Surrogates: Scylla Ex Machina**
2410.19599v1 by Yuan Gao, Dokyun Lee, Gordon Burtch, Sina Fazelpour

Recent studies suggest large language models (LLMs) can exhibit human-like
reasoning, aligning with human behavior in economic experiments, surveys, and
political discourse. This has led many to propose that LLMs can be used as
surrogates for humans in social science research. However, LLMs differ
fundamentally from humans, relying on probabilistic patterns, absent the
embodied experiences or survival objectives that shape human cognition. We
assess the reasoning depth of LLMs using the 11-20 money request game. Almost
all advanced approaches fail to replicate human behavior distributions across
many models, except in one case involving fine-tuning using a substantial
amount of human behavior data. Causes of failure are diverse, relating to input
language, roles, and safeguarding. These results caution against using LLMs to
study human behaviors or as human surrogates.

摘要：近期研究表明大型語言模型（LLM）可以表現出類人的推理能力，在經濟實驗、調查和政治論述中與人類行為一致。這導致許多人提出 LLM 可以作為社會科學研究中人類的替代品。然而，LLM 與人類有根本上的不同，它們依賴於機率模式，缺乏塑造人類認知的具體經驗或生存目標。我們使用 11-20 美元請求遊戲評估 LLM 的推理深度。除了在一個涉及使用大量人類行為數據進行微調的情況外，幾乎所有先進的方法都無法複製多個模型中的人類行為分佈。失敗的原因是多方面的，涉及輸入語言、角色和保障。這些結果警告我們不要使用 LLM 來研究人類行為或作為人類的替代品。

##### **ChunkRAG: Novel LLM-Chunk Filtering Method for RAG Systems**
2410.19572v1 by Ritvik Aggarwal Ishneet Sukhvinder Singh Ibrahim Allahverdiyev, Muhammad Taha, Aslihan Akalin, Kevin Zhu

Retrieval-Augmented Generation (RAG) systems using large language models
(LLMs) often generate inaccurate responses due to the retrieval of irrelevant
or loosely related information. Existing methods, which operate at the document
level, fail to effectively filter out such content. We propose LLM-driven chunk
filtering, ChunkRAG, a framework that enhances RAG systems by evaluating and
filtering retrieved information at the chunk level. Our approach employs
semantic chunking to divide documents into coherent sections and utilizes
LLM-based relevance scoring to assess each chunk's alignment with the user's
query. By filtering out less pertinent chunks before the generation phase, we
significantly reduce hallucinations and improve factual accuracy. Experiments
show that our method outperforms existing RAG models, achieving higher accuracy
on tasks requiring precise information retrieval. This advancement enhances the
reliability of RAG systems, making them particularly beneficial for
applications like fact-checking and multi-hop reasoning.

摘要：檢索增強生成（RAG）系統使用大型語言模型（LLM），通常會因檢索到不相關或關聯性較低資訊而產生不準確的回應。現有方法在文件層級運作，無法有效濾除此類內容。我們提出 LLM 驅動的區塊過濾，ChunkRAG，一個透過在區塊層級評估和過濾檢索資訊來增強 RAG 系統的架構。我們的做法使用語意區塊化將文件分割成連貫的區段，並利用基於 LLM 的相關性評分來評估每個區塊與使用者查詢的一致性。透過在生成階段之前過濾掉較不相關的區塊，我們大幅減少幻覺並提升事實準確性。實驗顯示，我們的做法優於現有的 RAG 模型，在需要精確資訊檢索的任務中達成更高的準確性。這項進展增強了 RAG 系統的可靠性，使其特別有利於事實查核和多跳推理等應用。

##### **On Occlusions in Video Action Detection: Benchmark Datasets And Training Recipes**
2410.19553v1 by Rajat Modi, Vibhav Vineet, Yogesh Singh Rawat

This paper explores the impact of occlusions in video action detection. We
facilitate this study by introducing five new benchmark datasets namely O-UCF
and O-JHMDB consisting of synthetically controlled static/dynamic occlusions,
OVIS-UCF and OVIS-JHMDB consisting of occlusions with realistic motions and
Real-OUCF for occlusions in realistic-world scenarios. We formally confirm an
intuitive expectation: existing models suffer a lot as occlusion severity is
increased and exhibit different behaviours when occluders are static vs when
they are moving. We discover several intriguing phenomenon emerging in neural
nets: 1) transformers can naturally outperform CNN models which might have even
used occlusion as a form of data augmentation during training 2) incorporating
symbolic-components like capsules to such backbones allows them to bind to
occluders never even seen during training and 3) Islands of agreement can
emerge in realistic images/videos without instance-level supervision,
distillation or contrastive-based objectives2(eg. video-textual training). Such
emergent properties allow us to derive simple yet effective training recipes
which lead to robust occlusion models inductively satisfying the first two
stages of the binding mechanism (grouping/segregation). Models leveraging these
recipes outperform existing video action-detectors under occlusion by 32.3% on
O-UCF, 32.7% on O-JHMDB & 2.6% on Real-OUCF in terms of the vMAP metric. The
code for this work has been released at
https://github.com/rajatmodi62/OccludedActionBenchmark.

摘要：這篇論文探討遮擋對影片動作偵測的影響。我們透過引入五個新的基準資料集來促進這項研究，分別是 O-UCF 和 O-JHMDB，包含合成控制的靜態/動態遮擋，OVIS-UCF 和 OVIS-JHMDB，包含具有逼真動作的遮擋，以及 Real-OUCF，用於逼真世界場景中的遮擋。我們正式確認一個直覺的預期：現有模型在遮擋嚴重性增加時會受到很大影響，並且在遮擋物靜止與移動時表現出不同的行為。我們發現神經網路中出現了幾個有趣的現象：1) Transformer模型自然可以優於 CNN 模型，後者甚至可能在訓練期間使用遮擋作為一種資料擴充形式 2) 將像膠囊一樣的符號組件整合到這些主幹中，讓它們可以與在訓練期間從未見過的遮擋物結合，並且 3) 島嶼一致性可以在沒有實例級別監督、蒸餾或對比式目標的情況下在逼真的影像/影片中出現 (例如影片文字訓練)。這些新興屬性讓我們可以推導出簡單但有效的訓練方法，這些方法會產生穩健的遮擋模型，以歸納方式滿足結合機制的最初兩個階段 (群組化/隔離)。利用這些方法的模型在遮擋下優於現有的影片動作偵測器，在 vMAP 指標方面，O-UCF 上優於 32.3%，O-JHMDB 上優於 32.7%，Real-OUCF 上優於 2.6%。這項工作的程式碼已在 https://github.com/rajatmodi62/OccludedActionBenchmark 發布。

##### **DeMuVGN: Effective Software Defect Prediction Model by Learning Multi-view Software Dependency via Graph Neural Networks**
2410.19550v1 by Yu Qiao, Lina Gong, Yu Zhao, Yongwei Wang, Mingqiang Wei

Software defect prediction (SDP) aims to identify high-risk defect modules in
software development, optimizing resource allocation. While previous studies
show that dependency network metrics improve defect prediction, most methods
focus on code-based dependency graphs, overlooking developer factors. Current
metrics, based on handcrafted features like ego and global network metrics,
fail to fully capture defect-related information. To address this, we propose
DeMuVGN, a defect prediction model that learns multi-view software dependency
via graph neural networks. We introduce a Multi-view Software Dependency Graph
(MSDG) that integrates data, call, and developer dependencies. DeMuVGN also
leverages the Synthetic Minority Oversampling Technique (SMOTE) to address
class imbalance and enhance defect module identification. In a case study of
eight open-source projects across 20 versions, DeMuVGN demonstrates significant
improvements: i) models based on multi-view graphs improve F1 scores by 11.1%
to 12.1% over single-view models; ii) DeMuVGN improves F1 scores by 17.4% to
45.8% in within-project contexts and by 17.9% to 41.0% in cross-project
contexts. Additionally, DeMuVGN excels in software evolution, showing more
improvement in later-stage software versions. Its strong performance across
different projects highlights its generalizability. We recommend future
research focus on multi-view dependency graphs for defect prediction in both
mature and newly developed projects.

摘要：<paragraph>軟體缺陷預測 (SDP) 旨在識別軟體開發中的高風險缺陷模組，最佳化資源配置。雖然先前的研究顯示相依網路指標改善了缺陷預測，但大多數方法都專注於基於程式碼的相依圖，忽略了開發人員因素。當前指標基於手工特徵（例如自我和全域網路指標），無法完全擷取與缺陷相關的資訊。為了解決這個問題，我們提出了 DeMuVGN，一個透過圖神經網路學習多視圖軟體相依性的缺陷預測模型。我們引入了整合資料、呼叫和開發人員相依性的多視圖軟體相依圖 (MSDG)。DeMuVGN 也利用合成少數過採樣技術 (SMOTE) 來解決類別不平衡，並增強缺陷模組識別。在八個跨 20 個版本的開源專案案例研究中，DeMuVGN 展示了顯著的改進：i) 基於多視圖圖形的模型將 F1 分數提高了 11.1% 至 12.1%，高於單一視圖模型；ii) DeMuVGN 將專案內情境的 F1 分數提高了 17.4% 至 45.8%，跨專案情境的 F1 分數提高了 17.9% 至 41.0%。此外，DeMuVGN 在軟體演化中表現出色，在後期的軟體版本中顯示出更大的改進。它在不同專案中的強勁效能突顯了它的泛化性。我們建議未來的研究專注於多視圖相依圖，以進行成熟和新開發專案的缺陷預測。</paragraph>

##### **Mirror Matrix on the Wall: coding and vector notation as tools for introspection**
2410.19549v1 by Leonardo Araújo

The vector notation adopted by GNU Octave plays a significant role as a tool
for introspection, aligning itself with the vision of Kenneth E. Iverson. He
believed that, just like mathematics, a programming language should be an
effective thinking tool for representing and reasoning about problems we wish
to address. This work aims to explore the use of vector notation in GNU Octave
through the analysis of operators and functions, providing a closer alignment
with mathematical notation and enhancing code efficiency. We will delve into
fundamental concepts such as indexing, broadcasting, and function handles, and
present case studies for a deeper understanding of these concepts. By adopting
vector notation, GNU Octave becomes a powerful tool for mathematicians,
scientists and engineers, enabling them to express and solve complex problems
more effectively and intuitively.

摘要：GNU Octave 所採用的向量表示法扮演著一個重要的角色，作為一個內省的工具，與 Kenneth E. Iverson 的願景相符。他相信，就像數學一樣，一門程式語言應該是一個有效的思考工具，用於表示和推理我們想要解決的問題。這項工作旨在透過分析運算子和函數，探討在 GNU Octave 中使用向量表示法，提供與數學表示法更緊密的結合，並增強程式碼效率。我們將深入探討基本概念，例如索引、廣播和函數句柄，並提出案例研究，以更深入地理解這些概念。透過採用向量表示法，GNU Octave 成為數學家、科學家和工程師的強大工具，使他們能夠更有效率且直觀地表達和解決複雜的問題。

##### **Bongard in Wonderland: Visual Puzzles that Still Make AI Go Mad?**
2410.19546v1 by Antonia Wüst, Tim Tobiasch, Lukas Helff, Devendra S. Dhami, Constantin A. Rothkopf, Kristian Kersting

Recently, newly developed Vision-Language Models (VLMs), such as OpenAI's
GPT-4o, have emerged, seemingly demonstrating advanced reasoning capabilities
across text and image modalities. Yet, the depth of these advances in
language-guided perception and abstract reasoning remains underexplored, and it
is unclear whether these models can truly live up to their ambitious promises.
To assess the progress and identify shortcomings, we enter the wonderland of
Bongard problems, a set of classical visual reasoning puzzles that require
human-like abilities of pattern recognition and abstract reasoning. While VLMs
occasionally succeed in identifying discriminative concepts and solving some of
the problems, they frequently falter, failing to understand and reason about
visual concepts. Surprisingly, even elementary concepts that may seem trivial
to humans, such as simple spirals, pose significant challenges. Moreover, even
when asked to explicitly focus on and analyze these concepts, they continue to
falter, suggesting not only a lack of understanding of these elementary visual
concepts but also an inability to generalize to unseen concepts. These
observations underscore the current limitations of VLMs, emphasize that a
significant gap remains between human-like visual reasoning and machine
cognition, and highlight the ongoing need for innovation in this area.

摘要：最近，新开发的视觉语言模型 (VLM)，例如 OpenAI 的 GPT-4o，已应运而生，似乎展示了跨文本和图像模式的高级推理能力。然而，语言引导感知和抽象推理的这些进步的深度仍未得到充分探索，并且目前尚不清楚这些模型是否真正能够兑现其雄心勃勃的承诺。为了评估进展并找出不足之处，我们进入了邦加德问题的神奇世界，这是一组经典的视觉推理难题，需要人类般的模式识别和抽象推理能力。虽然 VLM 偶尔能够成功识别辨别性概念并解决其中一些问题，但它们经常出现失误，无法理解和推理视觉概念。令人惊讶的是，即使是人类看来微不足道的基本概念，例如简单的螺旋，也构成了重大挑战。此外，即使要求它们明确关注并分析这些概念，它们仍然会失误，这不仅表明它们缺乏对这些基本视觉概念的理解，还表明它们无法推广到看不见的概念。这些观察结果强调了 VLM 当前的局限性，强调人类般的视觉推理和机器认知之间仍然存在巨大差距，并突出了在这个领域持续创新的必要性。

##### **PMM-Net: Single-stage Multi-agent Trajectory Prediction with Patching-based Embedding and Explicit Modal Modulation**
2410.19544v1 by Huajian Liu, Wei Dong, Kunpeng Fan, Chao Wang, Yongzhuo Gao

Analyzing and forecasting trajectories of agents like pedestrians plays a
pivotal role for embodied intelligent applications. The inherent indeterminacy
of human behavior and complex social interaction among a rich variety of agents
make this task more challenging than common time-series forecasting. In this
letter, we aim to explore a distinct formulation for multi-agent trajectory
prediction framework. Specifically, we proposed a patching-based temporal
feature extraction module and a graph-based social feature extraction module,
enabling effective feature extraction and cross-scenario generalization.
Moreover, we reassess the role of social interaction and present a novel method
based on explicit modality modulation to integrate temporal and social
features, thereby constructing an efficient single-stage inference pipeline.
Results on public benchmark datasets demonstrate the superior performance of
our model compared with the state-of-the-art methods. The code is available at:
github.com/TIB-K330/pmm-net.

摘要：分析和預測行人等代理軌跡對於具身智能應用扮演著至關重要的角色。人類行為的內在不確定性和豐富多樣的代理之間的複雜社會互動，使得這項任務比常見的時間序列預測更具挑戰性。在此信中，我們旨在探索一個用於多代理軌跡預測框架的不同表述。具體來說，我們提出了一個基於修補的時間特徵提取模組和一個基於圖形的社會特徵提取模組，實現有效的特徵提取和跨場景概化。此外，我們重新評估了社會互動的作用，並提出了一種基於顯式模態調製的新方法，以整合時間和社會特徵，從而構建一個高效的單階段推論管道。在公共基準資料集上的結果證明了我們的模型與最先進的方法相比具有優越的效能。程式碼可在以下位置取得：github.com/TIB-K330/pmm-net。

##### **Brain-like Functional Organization within Large Language Models**
2410.19542v1 by H. Sun, L. Zhao, Z. Wu, X. Gao, Y. Hu, M. Zuo, W. Zhang, J. Han, T. Liu, X. Hu

The human brain has long inspired the pursuit of artificial intelligence
(AI). Recently, neuroimaging studies provide compelling evidence of alignment
between the computational representation of artificial neural networks (ANNs)
and the neural responses of the human brain to stimuli, suggesting that ANNs
may employ brain-like information processing strategies. While such alignment
has been observed across sensory modalities--visual, auditory, and
linguistic--much of the focus has been on the behaviors of artificial neurons
(ANs) at the population level, leaving the functional organization of
individual ANs that facilitates such brain-like processes largely unexplored.
In this study, we bridge this gap by directly coupling sub-groups of artificial
neurons with functional brain networks (FBNs), the foundational organizational
structure of the human brain. Specifically, we extract representative patterns
from temporal responses of ANs in large language models (LLMs), and use them as
fixed regressors to construct voxel-wise encoding models to predict brain
activity recorded by functional magnetic resonance imaging (fMRI). This
framework links the AN sub-groups to FBNs, enabling the delineation of
brain-like functional organization within LLMs. Our findings reveal that LLMs
(BERT and Llama 1-3) exhibit brain-like functional architecture, with
sub-groups of artificial neurons mirroring the organizational patterns of
well-established FBNs. Notably, the brain-like functional organization of LLMs
evolves with the increased sophistication and capability, achieving an improved
balance between the diversity of computational behaviors and the consistency of
functional specializations. This research represents the first exploration of
brain-like functional organization within LLMs, offering novel insights to
inform the development of artificial general intelligence (AGI) with human
brain principles.

摘要：人類大腦長期以來一直激勵著人們追求人工智慧 (AI)。最近，神經影像研究提供了令人信服的證據，證明人工神經網路 (ANN) 的計算表示與人類大腦對刺激的神經反應之間存在一致性，這表明 ANN 可能採用類腦資訊處理策略。雖然這種一致性已在視覺、聽覺和語言等感官模式中被觀察到，但大部分的焦點都放在群體層級的人工神經元 (AN) 行為上，而鮮少探討促成此類類腦過程的個別 AN 功能組織。在這項研究中，我們透過直接將人工神經元的子群與功能性腦網路 (FBN)（人類大腦的基本組織結構）相結合，來彌合這個差距。具體來說，我們從大型語言模型 (LLM) 中的人工神經元時間反應中提取代表性模式，並將它們用作固定回歸變數來建構體素編碼模型，以預測功能性磁共振造影 (fMRI) 記錄的大腦活動。這個架構將 AN 子群連結到 FBN，能夠描繪出 LLM 內部的類腦功能組織。我們的研究結果顯示，LLM（BERT 和 Llama 1-3）展現出類腦功能架構，人工神經元的子群反映出已建立良好的 FBN 的組織模式。值得注意的是，LLM 的類腦功能組織會隨著複雜性和能力的提升而演化，在計算行為的多樣性和功能專門化的穩定性之間取得更好的平衡。這項研究代表了首次探索 LLM 內部的類腦功能組織，提供了新的見解，有助於根據人類大腦原理來開發人工通用智慧 (AGI)。

##### **Detection of Human and Machine-Authored Fake News in Urdu**
2410.19517v1 by Muhammad Zain Ali, Yuxia Wang, Bernhard Pfahringer, Tony Smith

The rise of social media has amplified the spread of fake news, now further
complicated by large language models (LLMs) like ChatGPT, which ease the
generation of highly convincing, error-free misinformation, making it
increasingly challenging for the public to discern truth from falsehood.
Traditional fake news detection methods relying on linguistic cues also becomes
less effective. Moreover, current detectors primarily focus on binary
classification and English texts, often overlooking the distinction between
machine-generated true vs. fake news and the detection in low-resource
languages. To this end, we updated detection schema to include
machine-generated news with focus on the Urdu language. We further propose a
hierarchical detection strategy to improve the accuracy and robustness.
Experiments show its effectiveness across four datasets in various settings.

摘要：社交媒體的興起擴大了假新聞的傳播，現在進一步受到類比 ChatGPT 的大型語言模型 (LLM) 的影響，這些模型簡化了極具說服力、沒有錯誤的錯誤訊息的產生，這使得大眾越來越難以辨別真假。依賴語言線索的傳統假新聞偵測方法也變得不那麼有效。此外，目前的偵測器主要專注於二元分類和英文文字，常常忽略機器產生的真假新聞之間的區別，以及在低資源語言中的偵測。為此，我們更新了偵測架構，以包含機器產生的新聞，重點放在烏爾都語上。我們進一步提出了一種分層偵測策略，以提高準確性和穩健性。實驗顯示了它在各種設定中跨四個資料集的有效性。

##### **DMT-HI: MOE-based Hyperbolic Interpretable Deep Manifold Transformation for Unspervised Dimensionality Reduction**
2410.19504v1 by Zelin Zang, Yuhao Wang, Jinlin Wu, Hong Liu, Yue Shen, Stan. Z Li, Zhen Lei

Dimensionality reduction (DR) plays a crucial role in various fields,
including data engineering and visualization, by simplifying complex datasets
while retaining essential information. However, the challenge of balancing DR
accuracy and interpretability remains crucial, particularly for users dealing
with high-dimensional data. Traditional DR methods often face a trade-off
between precision and transparency, where optimizing for performance can lead
to reduced interpretability, and vice versa. This limitation is especially
prominent in real-world applications such as image, tabular, and text data
analysis, where both accuracy and interpretability are critical. To address
these challenges, this work introduces the MOE-based Hyperbolic Interpretable
Deep Manifold Transformation (DMT-HI). The proposed approach combines
hyperbolic embeddings, which effectively capture complex hierarchical
structures, with Mixture of Experts (MOE) models, which dynamically allocate
tasks based on input features. DMT-HI enhances DR accuracy by leveraging
hyperbolic embeddings to represent the hierarchical nature of data, while also
improving interpretability by explicitly linking input data, embedding
outcomes, and key features through the MOE structure. Extensive experiments
demonstrate that DMT-HI consistently achieves superior performance in both DR
accuracy and model interpretability, making it a robust solution for complex
data analysis. The code is available at
\url{https://github.com/zangzelin/code_dmthi}.

摘要：降維度 (DR) 在各種領域中扮演著至關重要的角色，包括資料工程和視覺化，它透過簡化複雜的資料集，同時保留必要的資訊來達成。然而，平衡 DR 的準確度和可解釋性的挑戰仍然至關重要，特別是對於處理高維度資料的使用者來說。傳統的 DR 方法通常會在精準度和透明度之間面臨取捨，其中最佳化效能可能會導致可解釋性降低，反之亦然。這種限制在影像、表格和文字資料分析等真實世界應用中特別明顯，其中準確度和可解釋性都至關重要。為了應對這些挑戰，這項工作引入了基於 MOE 的雙曲可解釋深度流形轉換 (DMT-HI)。所提出的方法結合了雙曲嵌入，有效擷取複雜的階層結構，以及專家混合 (MOE) 模型，根據輸入特徵動態分配任務。DMT-HI 透過利用雙曲嵌入來表示資料的階層性質，進而提升 DR 準確度，同時也透過 MOE 結構明確連結輸入資料、嵌入結果和關鍵特徵，進而改善可解釋性。廣泛的實驗證明，DMT-HI 在 DR 準確度和模型可解釋性方面始終都能達到優異的效能，使其成為複雜資料分析的強大解決方案。程式碼可於以下網址取得：\url{https://github.com/zangzelin/code_dmthi}。

##### **SWITCH: Studying with Teacher for Knowledge Distillation of Large Language Models**
2410.19503v1 by Jahyun Koo, Yerin Hwang, Yongil Kim, Taegwan Kang, Hyunkyung Bae, Kyomin Jung

Despite the success of Large Language Models (LLMs), they still face
challenges related to high inference costs and memory requirements. To address
these issues, Knowledge Distillation (KD) has emerged as a popular method for
model compression, with student-generated outputs (SGOs) being particularly
notable for reducing the mismatch between training and inference. However, SGOs
often produce noisy and biased sequences, which can lead to misguidance from
the teacher model, especially in long sequences. To mitigate these challenges,
we propose SWITCH (Studying WIth TeaCHer for Knowledge Distillation), a novel
approach that strategically incorporates the teacher model during the student's
sequence generation. SWITCH identifies discrepancies between the token
probabilities of the teacher and student models, allowing the teacher to
intervene selectively, particularly in long sequences that are more prone to
teacher misguidance. Extensive experimental results across three model families
and five instruction-following datasets show that SWITCH surpasses traditional
KD methods, particularly excelling in the generation of long sequential data.

摘要：儘管大型語言模型 (LLM) 已取得成功，但它們仍面臨與高推論成本和記憶體需求相關的挑戰。為了解決這些問題，知識蒸餾 (KD) 已成為一種流行的模型壓縮方法，其中學生產生的輸出 (SGO) 特別值得注意，因為它可以減少訓練和推論之間的不匹配。然而，SGO 經常產生雜訊和有偏差的序列，這可能會導致教師模型的誤導，特別是在長序列中。為了減輕這些挑戰，我們提出 SWITCH（與教師共同學習知識蒸餾），這是一種新穎的方法，可以在學生的序列生成過程中策略性地納入教師模型。SWITCH 識別教師和學生模型的標記機率之間的差異，允許教師選擇性地介入，特別是在較長的序列中，這些序列更容易受到教師誤導。在三個模型系列和五個指令遵循資料集中的廣泛實驗結果顯示，SWITCH 超越了傳統的 KD 方法，特別是在生成長序列資料方面表現出色。

##### **Introducing MAPO: Momentum-Aided Gradient Descent Prompt Optimization**
2410.19499v1 by Anthony Cui, Pranav Nandyalam, Kevin Zhu

Momentum-Aided Prompt Optimization (MAPO) enhances the efficiency and
efficacy of prompt optimization for Large Language Models (LLMs). Building on
ProTeGi, MAPO uses positive natural language "gradients" and a momentum-based
extension to refine prompts effectively. By tracking gradient history, MAPO
avoids local minima and oscillations. It also utilizes beam search and an Upper
Confidence Bound (UCB) algorithm for balanced candidate expansion and
selection. Benchmark testing shows that MAPO achieves faster convergence time
with fewer API calls and higher F1 scores than ProTeGi, proving it as a robust
and scalable solution for automated prompt engineering in LLMs.

摘要：動能輔助提示最佳化 (MAPO) 提升了大型語言模型 (LLM) 的提示最佳化的效率和效能。MAPO 建立在 ProTeGi 上，使用正向自然語言「梯度」和基於動能的延伸來有效改善提示。透過追蹤梯度記錄，MAPO 避免了局部最小值和振盪。它還利用波束搜尋和上界置信 (UCB) 演算法，進行平衡的候選擴充和選擇。基準測試顯示，MAPO 達到了比 ProTeGi 更快的收斂時間，API 呼叫次數更少，F1 分數更高，證明了它是一種強健且可擴充的 LLM 自動提示工程解決方案。

##### **Graph Linearization Methods for Reasoning on Graphs with Large Language Models**
2410.19494v1 by Christos Xypolopoulos, Guokan Shang, Xiao Fei, Giannis Nikolentzos, Hadi Abdine, Iakovos Evdaimon, Michail Chatzianastasis, Giorgos Stamou, Michalis Vazirgiannis

Large language models have evolved to process multiple modalities beyond
text, such as images and audio, which motivates us to explore how to
effectively leverage them for graph machine learning tasks. The key question,
therefore, is how to transform graphs into linear sequences of tokens, a
process we term graph linearization, so that LLMs can handle graphs naturally.
We consider that graphs should be linearized meaningfully to reflect certain
properties of natural language text, such as local dependency and global
alignment, in order to ease contemporary LLMs, trained on trillions of textual
tokens, better understand graphs. To achieve this, we developed several graph
linearization methods based on graph centrality, degeneracy, and node
relabeling schemes. We then investigated their effect on LLM performance in
graph reasoning tasks. Experimental results on synthetic graphs demonstrate the
effectiveness of our methods compared to random linearization baselines. Our
work introduces novel graph representations suitable for LLMs, contributing to
the potential integration of graph machine learning with the trend of
multi-modal processing using a unified transformer model.

摘要：大型語言模型已演化為處理文字之外的多種模式，例如影像和音訊，這促使我們探索如何有效地運用它們於圖形機器學習任務。因此，關鍵問題在於如何將圖形轉換為線性序列的代幣，這是一個我們稱為圖形線性化的過程，讓 LLM 能自然地處理圖形。我們認為圖形應有意義地進行線性化，以反映自然語言文字的特定屬性，例如局部依賴性和全局對齊，以便讓在數兆個文字代幣上訓練的當代 LLM 更能理解圖形。為達成此目的，我們開發了幾種基於圖形中心性、簡併性和節點重新標籤架構的圖形線性化方法。接著，我們探討它們對 LLM 在圖形推理任務中的效能影響。合成圖形上的實驗結果證明了我們的方法比隨機線性化基準更有效。我們的研究引入了適合 LLM 的新穎圖形表示法，有助於將圖形機器學習與使用統一Transformer模型的多模式處理趨勢整合起來。

##### **A Debate-Driven Experiment on LLM Hallucinations and Accuracy**
2410.19485v1 by Ray Li, Tanishka Bagade, Kevin Martinez, Flora Yasmin, Grant Ayala, Michael Lam, Kevin Zhu

Large language models (LLMs) have achieved a degree of success in generating
coherent and contextually relevant text, yet they remain prone to a significant
challenge known as hallucination: producing information that is not
substantiated by the input or external knowledge. Previous efforts to mitigate
hallucinations have focused on techniques such as fine-tuning models on
high-quality datasets, incorporating fact-checking mechanisms, and developing
adversarial training methods. While these approaches have shown some promise,
they often address the issue at the level of individual model outputs, leaving
unexplored the effects of inter-model interactions on hallucination. This study
investigates the phenomenon of hallucination in LLMs through a novel
experimental framework where multiple instances of GPT-4o-Mini models engage in
a debate-like interaction prompted with questions from the TruthfulQA dataset.
One model is deliberately instructed to generate plausible but false answers
while the other models are asked to respond truthfully. The experiment is
designed to assess whether the introduction of misinformation by one model can
challenge the truthful majority to better justify their reasoning, improving
performance on the TruthfulQA benchmark. The findings suggest that inter-model
interactions can offer valuable insights into improving the accuracy and
robustness of LLM outputs, complementing existing mitigation strategies.

摘要：大型語言模型 (LLM) 在產生連貫且與語境相關的文字方面已取得一定程度的成功，但它們仍然容易出現一個稱為幻覺的重大挑戰：產生未經輸入或外部知識證實的資訊。先前減輕幻覺的努力集中在技術上，例如在高品質資料集上微調模型、納入事實查核機制以及開發對抗性訓練方法。雖然這些方法顯示出一些前景，但它們通常在個別模型輸出的層級上解決問題，而沒有探討模型間互動對幻覺的影響。本研究透過一個新穎的實驗架構探討 LLM 中幻覺的現象，其中 GPT-4o-Mini 模型的多次執行參與辯論式的互動，並提示來自 TruthfulQA 資料集的問題。一個模型被故意指示產生看似合理但錯誤的答案，而其他模型則被要求誠實地回答。此實驗旨在評估由一個模型引入的錯誤資訊是否能挑戰誠實的多數，以更好地證明其推理，進而提升 TruthfulQA 基準的效能。研究結果表明，模型間互動可以提供有價值的見解，以改善 LLM 輸出的準確性和穩健性，並補充現有的緩解策略。

##### **Peter Parker or Spiderman? Disambiguating Multiple Class Labels**
2410.19479v1 by Nuthan Mummani, Simran Ketha, Venkatakrishnan Ramaswamy

In the supervised classification setting, during inference, deep networks
typically make multiple predictions. For a pair of such predictions (that are
in the top-k predictions), two distinct possibilities might occur. On the one
hand, each of the two predictions might be primarily driven by two distinct
sets of entities in the input. On the other hand, it is possible that there is
a single entity or set of entities that is driving the prediction for both the
classes in question. This latter case, in effect, corresponds to the network
making two separate guesses about the identity of a single entity type.
Clearly, both the guesses cannot be true, i.e. both the labels cannot be
present in the input. Current techniques in interpretability research do not
readily disambiguate these two cases, since they typically consider input
attributions for one class label at a time. Here, we present a framework and
method to do so, leveraging modern segmentation and input attribution
techniques. Notably, our framework also provides a simple counterfactual
"proof" of each case, which can be verified for the input on the model (i.e.
without running the method again). We demonstrate that the method performs well
for a number of samples from the ImageNet validation set and on multiple
models.

摘要：在監督式分類設定中，在推論期間，深度網路通常會做出多個預測。對於這樣一對預測（在 top-k 預測中），可能會出現兩種不同的可能性。一方面，這兩個預測中的每一個都可能主要由輸入中兩組不同的實體驅動。另一方面，也可能存在一個實體或實體集，驅動著對問題中兩個類別的預測。後一種情況實際上對應於網路對單一實體類型的身份做出兩個不同的猜測。顯然，這兩個猜測都不可能是真的，即兩個標籤都不可能存在於輸入中。可解釋性研究中的當前技術並不能輕易地區分這兩種情況，因為它們通常一次考慮一個類別標籤的輸入歸因。在這裡，我們提出了一個框架和方法來這樣做，利用現代分割和輸入歸因技術。值得注意的是，我們的框架還提供了每種情況的簡單反事實“證明”，可以在模型上的輸入中驗證（即無需再次運行方法）。我們證明了該方法對來自 ImageNet 驗證集和多個模型的許多樣本執行良好。

##### **Improving Inverse Folding for Peptide Design with Diversity-regularized Direct Preference Optimization**
2410.19471v1 by Ryan Park, Darren J. Hsu, C. Brian Roland, Maria Korshunova, Chen Tessler, Shie Mannor, Olivia Viessmann, Bruno Trentini

Inverse folding models play an important role in structure-based design by
predicting amino acid sequences that fold into desired reference structures.
Models like ProteinMPNN, a message-passing encoder-decoder model, are trained
to reliably produce new sequences from a reference structure. However, when
applied to peptides, these models are prone to generating repetitive sequences
that do not fold into the reference structure. To address this, we fine-tune
ProteinMPNN to produce diverse and structurally consistent peptide sequences
via Direct Preference Optimization (DPO). We derive two enhancements to DPO:
online diversity regularization and domain-specific priors. Additionally, we
develop a new understanding on improving diversity in decoder models. When
conditioned on OpenFold generated structures, our fine-tuned models achieve
state-of-the-art structural similarity scores, improving base ProteinMPNN by at
least 8%. Compared to standard DPO, our regularized method achieves up to 20%
higher sequence diversity with no loss in structural similarity score.

摘要：逆向折叠模型在基于结构的设计中扮演着重要角色，通过预测氨基酸序列来折叠成期望的参考结构。像 ProteinMPNN 这样的消息传递编码器-解码器模型，经过训练可以从参考结构中可靠地产生新的序列。然而，当应用于肽时，这些模型容易产生不会折叠到参考结构中的重复序列。为了解决这个问题，我们微调 ProteinMPNN 以通过直接偏好优化 (DPO) 产生多样化且结构一致的肽序列。我们对 DPO 进行了两项增强：在线多样性正则化和特定于域的先验。此外，我们还对提高解码器模型中的多样性有了新的理解。当以 OpenFold 生成的结构为条件时，我们微调的模型实现了最先进的结构相似性得分，至少比基础 ProteinMPNN 提高了 8%。与标准 DPO 相比，我们的正则化方法在结构相似性得分没有损失的情况下，实现了高达 20% 的更高序列多样性。

##### **Unified Causality Analysis Based on the Degrees of Freedom**
2410.19469v1 by András Telcs, Marcell T. Kurbucz, Antal Jakovác

Temporally evolving systems are typically modeled by dynamic equations. A key
challenge in accurate modeling is understanding the causal relationships
between subsystems, as well as identifying the presence and influence of
unobserved hidden drivers on the observed dynamics. This paper presents a
unified method capable of identifying fundamental causal relationships between
pairs of systems, whether deterministic or stochastic. Notably, the method also
uncovers hidden common causes beyond the observed variables. By analyzing the
degrees of freedom in the system, our approach provides a more comprehensive
understanding of both causal influence and hidden confounders. This unified
framework is validated through theoretical models and simulations,
demonstrating its robustness and potential for broader application.

摘要：時間演化系統通常由動態方程式建模。準確建模的一個關鍵挑戰是了解子系統之間的因果關係，以及識別未觀察到的隱藏驅動因素的存在和影響。本文提出了一種統一的方法，能夠識別系統對之間的根本因果關係，無論是確定性的還是隨機的。值得注意的是，該方法還揭示了觀察變量之外的隱藏共同原因。通過分析系統中的自由度，我們的做法提供了對因果影響和隱藏混雜因素的更全面理解。通過理論模型和模擬驗證了這個統一框架，證明了其穩健性和更廣泛應用。

##### **EDGE: Enhanced Grounded GUI Understanding with Enriched Multi-Granularity Synthetic Data**
2410.19461v1 by Xuetian Chen, Hangcheng Li, Jiaqing Liang, Sihang Jiang, Deqing Yang

Autonomous agents operating on the graphical user interfaces (GUIs) of
various applications hold immense practical value. Unlike the large language
model (LLM)-based methods which rely on structured texts and customized
backends, the approaches using large vision-language models (LVLMs) are more
intuitive and adaptable as they can visually perceive and directly interact
with screens, making them indispensable in general scenarios without text
metadata and tailored backends. Given the lack of high-quality training data
for GUI-related tasks in existing work, this paper aims to enhance the GUI
understanding and interacting capabilities of LVLMs through a data-driven
approach. We propose EDGE, a general data synthesis framework that
automatically generates large-scale, multi-granularity training data from
webpages across the Web. Evaluation results on various GUI and agent benchmarks
demonstrate that the model trained with the dataset generated through EDGE
exhibits superior webpage understanding capabilities, which can then be easily
transferred to previously unseen desktop and mobile environments. Our approach
significantly reduces the dependence on manual annotations, empowering
researchers to harness the vast public resources available on the Web to
advance their work. Our source code, the dataset and the model are available at
https://anonymous.4open.science/r/EDGE-1CDB.

摘要：<paragraph>在各種應用程式的圖形使用者介面 (GUI) 上運作的自主代理，具有極大的實用價值。與依賴結構化文字和自訂後端的基於大型語言模型 (LLM) 的方法不同，使用大型視覺語言模型 (LVLMs) 的方法更直觀且具有適應性，因為它們可以視覺感知並直接與螢幕互動，這使得它們在沒有文字元資料和自訂後端的通用場景中不可或缺。鑑於現有工作中缺乏用於 GUI 相關任務的高品質訓練資料，本文旨在透過資料驅動的方法增強 LVLMs 的 GUI 理解和互動能力。我們提出 EDGE，這是一個通用的資料合成架構，可以自動從網際網路上的網頁產生大規模、多粒度的訓練資料。在各種 GUI 和代理基準上的評估結果表明，使用透過 EDGE 產生的資料集訓練的模型展現出優異的網頁理解能力，然後可以輕鬆地轉移到以前未見的桌面和行動環境。我們的做法大幅減少了對手動註解的依賴，讓研究人員能夠利用網際網路上大量的公開資源來推進他們的進度。我們的原始碼、資料集和模型可在 https://anonymous.4open.science/r/EDGE-1CDB 取得。</paragraph>

##### **ShifCon: Enhancing Non-Dominant Language Capabilities with a Shift-based Contrastive Framework**
2410.19453v1 by Hengyuan Zhang, Chenming Shang, Sizhe Wang, Dongdong Zhang, Feng Yao, Renliang Sun, Yiyao Yu, Yujiu Yang, Furu Wei

Although fine-tuning Large Language Models (LLMs) with multilingual data can
rapidly enhance the multilingual capabilities of LLMs, they still exhibit a
performance gap between the dominant language (e.g., English) and non-dominant
ones due to the imbalance of training data across languages. To further enhance
the performance of non-dominant languages, we propose ShifCon, a Shift-based
Contrastive framework that aligns the internal forward process of other
languages toward that of the dominant one. Specifically, it shifts the
representations of non-dominant languages into the dominant language subspace,
allowing them to access relatively rich information encoded in the model
parameters. The enriched representations are then shifted back into their
original language subspace before generation. Moreover, we introduce a subspace
distance metric to pinpoint the optimal layer area for shifting representations
and employ multilingual contrastive learning to further enhance the alignment
of representations within this area. Experiments demonstrate that our ShifCon
framework significantly enhances the performance of non-dominant languages,
particularly for low-resource ones. Further analysis offers extra insights to
verify the effectiveness of ShifCon and propel future research

摘要：雖然使用多語言資料微調大型語言模型 (LLM) 可以快速增強 LLM 的多語言能力，但由於訓練資料在語言之間的不平衡，它們仍然在主導語言（例如英語）與非主導語言之間表現出差距。為了進一步增強非主導語言的效能，我們提出 ShifCon，一個基於轉移的對比框架，它將其他語言的內部前向處理程序與主導語言的處理程序對齊。具體來說，它將非主導語言的表徵轉移到主導語言的子空間中，讓它們能夠存取模型參數中編碼的相對豐富資訊。然後在產生之前，將豐富的表徵轉移回它們原本的語言子空間。此外，我們引入一個子空間距離量度來精確定位轉移表徵的最佳層級區域，並採用多語言對比學習來進一步增強該區域內表徵的對齊。實驗證明，我們的 ShifCon 框架顯著增強了非主導語言的效能，特別是對於低資源語言。進一步的分析提供了額外的見解來驗證 ShifCon 的有效性並推動未來的研究

##### **NeuroClips: Towards High-fidelity and Smooth fMRI-to-Video Reconstruction**
2410.19452v1 by Zixuan Gong, Guangyin Bao, Qi Zhang, Zhongwei Wan, Duoqian Miao, Shoujin Wang, Lei Zhu, Changwei Wang, Rongtao Xu, Liang Hu, Ke Liu, Yu Zhang

Reconstruction of static visual stimuli from non-invasion brain activity fMRI
achieves great success, owning to advanced deep learning models such as CLIP
and Stable Diffusion. However, the research on fMRI-to-video reconstruction
remains limited since decoding the spatiotemporal perception of continuous
visual experiences is formidably challenging. We contend that the key to
addressing these challenges lies in accurately decoding both high-level
semantics and low-level perception flows, as perceived by the brain in response
to video stimuli. To the end, we propose NeuroClips, an innovative framework to
decode high-fidelity and smooth video from fMRI. NeuroClips utilizes a
semantics reconstructor to reconstruct video keyframes, guiding semantic
accuracy and consistency, and employs a perception reconstructor to capture
low-level perceptual details, ensuring video smoothness. During inference, it
adopts a pre-trained T2V diffusion model injected with both keyframes and
low-level perception flows for video reconstruction. Evaluated on a publicly
available fMRI-video dataset, NeuroClips achieves smooth high-fidelity video
reconstruction of up to 6s at 8FPS, gaining significant improvements over
state-of-the-art models in various metrics, e.g., a 128\% improvement in SSIM
and an 81\% improvement in spatiotemporal metrics. Our project is available at
https://github.com/gongzix/NeuroClips}{https://github.com/gongzix/NeuroClips.

摘要：<paragraph>透過非侵入性腦部活動 fMRI 重建靜態視覺刺激已獲得巨大的成功，這要歸功於 CLIP 和 Stable Diffusion 等先進的深度學習模型。然而，fMRI 轉影片重建的研究仍然有限，因為解碼連續視覺體驗的時空感知是一項極具挑戰性的任務。我們認為，解決這些挑戰的關鍵在於準確解碼大腦對影片刺激產生的高階語意和低階感知流。為此，我們提出了 NeuroClips，一個創新的架構，用於從 fMRI 解碼高保真且流暢的影片。NeuroClips 利用語意重建器重建影片關鍵影格，引導語意準確性和一致性，並採用感知重建器捕捉低階感知細節，確保影片流暢度。在推理過程中，它採用一個預先訓練好的 T2V 擴散模型，注入關鍵影格和低階感知流進行影片重建。在一個公開可用的 fMRI-影片資料集上進行評估，NeuroClips 以 8FPS 達到了長達 6 秒的流暢高保真影片重建，在各種指標上獲得了顯著的改進，例如 SSIM 提高了 128%，時空指標提高了 81%。我們的專案可以在 https://github.com/gongzix/NeuroClips 找到。</paragraph>

##### **Intelligent Understanding of Large Language Models in Traditional Chinese Medicine Based on Prompt Engineering Framework**
2410.19451v1 by Yirui Chen, Qinyu Xiao, Jia Yi, Jing Chen, Mengyang Wang

This paper explores the application of prompt engineering to enhance the
performance of large language models (LLMs) in the domain of Traditional
Chinese Medicine (TCM). We propose TCM-Prompt, a framework that integrates
various pre-trained language models (PLMs), templates, tokenization, and
verbalization methods, allowing researchers to easily construct and fine-tune
models for specific TCM-related tasks. We conducted experiments on disease
classification, syndrome identification, herbal medicine recommendation, and
general NLP tasks, demonstrating the effectiveness and superiority of our
approach compared to baseline methods. Our findings suggest that prompt
engineering is a promising technique for improving the performance of LLMs in
specialized domains like TCM, with potential applications in digitalization,
modernization, and personalized medicine.

摘要：本文探討了提示工程在增強大型語言模型 (LLM) 在中醫領域的效能之應用。我們提出中醫提示，一個整合了各種預訓練語言模型 (PLM)、範本、標記化和言語化方法的架構，讓研究人員可以輕鬆建構和微調特定中醫相關任務的模型。我們對疾病分類、症候群識別、草藥推薦和一般自然語言處理任務進行了實驗，證明了我們的方法與基準方法相比，具有顯著的有效性和優越性。我們的研究結果表明，提示工程是一種很有前途的技術，可以用於提升 LLM 在中醫等專業領域的效能，並具有在數位化、現代化和個人化醫療中的潛在應用。

##### **Gradient Descent Efficiency Index**
2410.19448v1 by Aviral Dhingra

Gradient descent is a widely used iterative algorithm for finding local
minima in multivariate functions. However, the final iterations often either
overshoot the minima or make minimal progress, making it challenging to
determine an optimal stopping point. This study introduces a new efficiency
metric, Ek, designed to quantify the effectiveness of each iteration. The
proposed metric accounts for both the relative change in error and the
stability of the loss function across iterations. This measure is particularly
valuable in resource-constrained environments, where costs are closely tied to
training time. Experimental validation across multiple datasets and models
demonstrates that Ek provides valuable insights into the convergence behavior
of gradient descent, complementing traditional performance metrics. The index
has the potential to guide more informed decisions in the selection and tuning
of optimization algorithms in machine learning applications and be used to
compare the "effectiveness" of models relative to each other.

摘要：梯度下降法是一種廣泛使用的反覆運算演算法，用於尋找多變量函數中的局部最小值。然而，最後的幾次反覆運算通常會超過最小值或進展極小，這使得難以確定最佳停止點。本研究引入了一個新的效率度量 Ek，旨在量化每次反覆運算的有效性。所提出的度量同時考慮了誤差的相對變化和損失函數在反覆運算中的穩定性。此測量在資源受限的環境中特別有價值，在這種環境中，成本與訓練時間密切相關。跨多個資料集和模型的實驗驗證表明，Ek 提供了對梯度下降收斂行為的寶貴見解，補充了傳統的效能度量。該指標有可能在機器學習應用中選擇和調整最佳化演算法時指導更明智的決策，並用於比較模型相對於彼此的「有效性」。

##### **Expose Before You Defend: Unifying and Enhancing Backdoor Defenses via Exposed Models**
2410.19427v1 by Yige Li, Hanxun Huang, Jiaming Zhang, Xingjun Ma, Yu-Gang Jiang

Backdoor attacks covertly implant triggers into deep neural networks (DNNs)
by poisoning a small portion of the training data with pre-designed backdoor
triggers. This vulnerability is exacerbated in the era of large models, where
extensive (pre-)training on web-crawled datasets is susceptible to compromise.
In this paper, we introduce a novel two-step defense framework named Expose
Before You Defend (EBYD). EBYD unifies existing backdoor defense methods into a
comprehensive defense system with enhanced performance. Specifically, EBYD
first exposes the backdoor functionality in the backdoored model through a
model preprocessing step called backdoor exposure, and then applies detection
and removal methods to the exposed model to identify and eliminate the backdoor
features. In the first step of backdoor exposure, we propose a novel technique
called Clean Unlearning (CUL), which proactively unlearns clean features from
the backdoored model to reveal the hidden backdoor features. We also explore
various model editing/modification techniques for backdoor exposure, including
fine-tuning, model sparsification, and weight perturbation. Using EBYD, we
conduct extensive experiments on 10 image attacks and 6 text attacks across 2
vision datasets (CIFAR-10 and an ImageNet subset) and 4 language datasets
(SST-2, IMDB, Twitter, and AG's News). The results demonstrate the importance
of backdoor exposure for backdoor defense, showing that the exposed models can
significantly benefit a range of downstream defense tasks, including backdoor
label detection, backdoor trigger recovery, backdoor model detection, and
backdoor removal. We hope our work could inspire more research in developing
advanced defense frameworks with exposed models. Our code is available at:
https://github.com/bboylyg/Expose-Before-You-Defend.

摘要：後門攻擊通過在訓練資料的少量部分中植入預先設計的後門觸發器，秘密地將觸發器植入深度神經網路 (DNN) 中。這種漏洞在大型模型時代變得更加嚴重，因為在網路上爬取的資料集上進行廣泛的 (預先) 訓練容易受到危害。在本文中，我們介紹了一個名為「在防禦前先揭露」 (EBYD) 的新穎兩步驟防禦架構。EBYD 將現有的後門防禦方法統一到一個全面的防禦系統中，並增強了效能。具體來說，EBYD 首先透過稱為後門揭露的模型預處理步驟，揭露後門模型中的後門功能，然後將偵測和移除方法應用到已揭露的模型，以識別並消除後門功能。在後門揭露的第一個步驟中，我們提出了一種名為「乾淨遺忘」(CUL) 的新穎技術，它主動從後門模型中遺忘乾淨的功能，以揭露隱藏的後門功能。我們還探索了各種模型編輯/修改技術，用於後門揭露，包括微調、模型稀疏化和權重擾動。使用 EBYD，我們對 2 個視覺資料集 (CIFAR-10 和 ImageNet 子集) 和 4 個語言資料集 (SST-2、IMDB、Twitter 和 AG's News) 中的 10 個圖像攻擊和 6 個文字攻擊進行了廣泛的實驗。結果證明了後門揭露對於後門防禦的重要性，表明已揭露的模型可以顯著受益於一系列下游防禦任務，包括後門標籤偵測、後門觸發器復原、後門模型偵測和後門移除。我們希望我們的研究能激勵更多人研究開發具有已揭露模型的先進防禦架構。我們的程式碼可在以下網址取得：https://github.com/bboylyg/Expose-Before-You-Defend。

##### **KAHANI: Culturally-Nuanced Visual Storytelling Pipeline for Non-Western Cultures**
2410.19419v1 by Hamna, Deepthi Sudharsan, Agrima Seth, Ritvik Budhiraja, Deepika Khullar, Vyshak Jain, Kalika Bali, Aditya Vashistha, Sameer Segal

Large Language Models (LLMs) and Text-To-Image (T2I) models have demonstrated
the ability to generate compelling text and visual stories. However, their
outputs are predominantly aligned with the sensibilities of the Global North,
often resulting in an outsider's gaze on other cultures. As a result,
non-Western communities have to put extra effort into generating culturally
specific stories. To address this challenge, we developed a visual storytelling
pipeline called KAHANI that generates culturally grounded visual stories for
non-Western cultures. Our pipeline leverages off-the-shelf models GPT-4 Turbo
and Stable Diffusion XL (SDXL). By using Chain of Thought (CoT) and T2I
prompting techniques, we capture the cultural context from user's prompt and
generate vivid descriptions of the characters and scene compositions. To
evaluate the effectiveness of KAHANI, we conducted a comparative user study
with ChatGPT-4 (with DALL-E3) in which participants from different regions of
India compared the cultural relevance of stories generated by the two tools.
Results from the qualitative and quantitative analysis performed on the user
study showed that KAHANI was able to capture and incorporate more Culturally
Specific Items (CSIs) compared to ChatGPT-4. In terms of both its cultural
competence and visual story generation quality, our pipeline outperformed
ChatGPT-4 in 27 out of the 36 comparisons.

摘要：大型語言模型 (LLM) 和文字轉圖像 (T2I) 模型已展現出生成引人入勝的文字和視覺故事的能力。然而，他們的輸出主要符合全球北方的思維，這通常導致對其他文化的外人觀點。因此，非西方社群必須付出額外的努力來產生具有文化特色的故事。為了應對這項挑戰，我們開發了一種名為 KAHANI 的視覺敘事管道，可為非西方文化產生具有文化基礎的視覺故事。我們的管道利用現成的模型 GPT-4 Turbo 和 Stable Diffusion XL (SDXL)。透過使用思考鏈 (CoT) 和 T2I 提示技巧，我們從使用者的提示中擷取文化背景，並產生角色和場景構圖的生動描述。為了評估 KAHANI 的效能，我們對 ChatGPT-4（搭配 DALL-E3）進行了一項比較使用者研究，其中來自印度不同地區的參與者比較了這兩個工具所產生故事的文化相關性。對使用者研究執行的定性和定量分析結果顯示，與 ChatGPT-4 相比，KAHANI 能夠擷取和納入更多文化特定項目 (CSI)。在文化能力和視覺故事生成品質方面，我們的管道在 36 次比較中勝過 ChatGPT-4 中的 27 次。

##### **Robust Time Series Causal Discovery for Agent-Based Model Validation**
2410.19412v1 by Gene Yu, Ce Guo, Wayne Luk

Agent-Based Model (ABM) validation is crucial as it helps ensuring the
reliability of simulations, and causal discovery has become a powerful tool in
this context. However, current causal discovery methods often face accuracy and
robustness challenges when applied to complex and noisy time series data, which
is typical in ABM scenarios. This study addresses these issues by proposing a
Robust Cross-Validation (RCV) approach to enhance causal structure learning for
ABM validation. We develop RCV-VarLiNGAM and RCV-PCMCI, novel extensions of two
prominent causal discovery algorithms. These aim to reduce the impact of noise
better and give more reliable causal relation results, even with
high-dimensional, time-dependent data. The proposed approach is then integrated
into an enhanced ABM validation framework, which is designed to handle diverse
data and model structures.
  The approach is evaluated using synthetic datasets and a complex simulated
fMRI dataset. The results demonstrate greater reliability in causal structure
identification. The study examines how various characteristics of datasets
affect the performance of established causal discovery methods. These
characteristics include linearity, noise distribution, stationarity, and causal
structure density. This analysis is then extended to the RCV method to see how
it compares in these different situations. This examination helps confirm
whether the results are consistent with existing literature and also reveals
the strengths and weaknesses of the novel approaches.
  By tackling key methodological challenges, the study aims to enhance ABM
validation with a more resilient valuation framework presented. These
improvements increase the reliability of model-driven decision making processes
in complex systems analysis.

摘要：基於代理的模型 (ABM) 驗證至關重要，因為它有助於確保模擬的可靠性，而因果發現已成為在此脈絡中強大的工具。然而，當應用於複雜且有雜訊的時間序列資料時，當前的因果發現方法通常會面臨準確度和穩健性的挑戰，這在 ABM 情境中很常見。本研究透過提出穩健交叉驗證 (RCV) 方法來解決這些問題，以加強 ABM 驗證的因果結構學習。我們開發了 RCV-VarLiNGAM 和 RCV-PCMCI，這是兩種傑出的因果發現演算法的新延伸。它們旨在更好地降低雜訊的影響，並提供更可靠的因果關係結果，即使在高維度、時間相關的資料中也是如此。然後將所提出的方法整合到增強的 ABM 驗證架構中，該架構旨在處理多樣化的資料和模型結構。
使用合成資料集和複雜的模擬 fMRI 資料集來評估該方法。結果證明因果結構識別的可靠性更高。本研究探討了資料集的各種特徵如何影響已建立的因果發現方法的效能。這些特徵包括線性、雜訊分佈、平穩性和因果結構密度。然後將此分析延伸到 RCV 方法，以了解它在這些不同情況下的比較情況。此檢查有助於確認結果是否與現有文獻一致，並揭示新方法的優點和缺點。
透過解決關鍵的方法論挑戰，本研究旨在透過提出的更具復原力的評估架構來增強 ABM 驗證。這些改進提高了在複雜系統分析中模型驅動決策制定程式的可靠性。

##### **CLAP. I. Resolving miscalibration for deep learning-based galaxy photometric redshift estimation**
2410.19390v1 by Qiufan Lin, Hengxin Ruan, Dominique Fouchez, Shupei Chen, Rui Li, Paulo Montero-Camacho, Nicola R. Napolitano, Yuan-Sen Ting, Wei Zhang

Obtaining well-calibrated photometric redshift probability densities for
galaxies without a spectroscopic measurement remains a challenge. Deep learning
discriminative models, typically fed with multi-band galaxy images, can produce
outputs that mimic probability densities and achieve state-of-the-art accuracy.
However, such models may be affected by miscalibration that would result in
discrepancies between the model outputs and the actual distributions of true
redshifts. Our work develops a novel method called the Contrastive Learning and
Adaptive KNN for Photometric Redshift (CLAP) that resolves this issue. It
leverages supervised contrastive learning (SCL) and k-nearest neighbours (KNN)
to construct and calibrate raw probability density estimates, and implements a
refitting procedure to resume end-to-end discriminative models ready to produce
final estimates for large-scale imaging data. The harmonic mean is adopted to
combine an ensemble of estimates from multiple realisations for improving
accuracy. Our experiments demonstrate that CLAP takes advantage of both deep
learning and KNN, outperforming benchmark methods on the calibration of
probability density estimates and retaining high accuracy and computational
efficiency. With reference to CLAP, we point out that miscalibration is
particularly sensitive to the method-induced excessive correlations among data
instances in addition to the unaccounted-for epistemic uncertainties. Reducing
the uncertainties may not guarantee the removal of miscalibration due to the
presence of such excessive correlations, yet this is a problem for conventional
deep learning methods rather than CLAP. These discussions underscore the
robustness of CLAP for obtaining photometric redshift probability densities
required by astrophysical and cosmological applications. This is the first
paper in our series on CLAP.

摘要：取得没有光谱测量的星系的校准良好的光度红移概率密度仍然是一个挑战。深度学习判别模型通常以多波段星系图像为食，可以产生模仿概率密度并达到最先进的精度的输出。然而，此类模型可能会受到错误校准的影响，这会导致模型输出与真实红移的实际分布之间出现差异。我们的工作开发了一种称为对比学习和自适应 KNN 光度红移 (CLAP) 的新方法来解决这个问题。它利用监督对比学习 (SCL) 和 k 最近邻 (KNN) 来构建和校准原始概率密度估计，并实施重新拟合程序以恢复端到端判别模型，以便为大规模成像数据生成最终估计。采用调和平均值来组合来自多个实现的估计集合以提高准确性。我们的实验表明，CLAP 同时利用了深度学习和 KNN，在概率密度估计的校准上优于基准方法，并保持了高精度和计算效率。参考 CLAP，我们指出校准不良对方法引起的除了未考虑的认知不确定性之外的数据实例之间的过度相关性特别敏感。减少不确定性并不能保证消除错误校准，因为存在这种过度相关性，但对于传统的深度学习方法来说这是一个问题，而不是 CLAP。这些讨论强调了 CLAP 在获取天体物理和宇宙学应用所需的红移概率密度方面的鲁棒性。这是我们关于 CLAP 的系列文章中的第一篇。

##### **Investigating the Role of Prompting and External Tools in Hallucination Rates of Large Language Models**
2410.19385v1 by Liam Barkley, Brink van der Merwe

Large Language Models (LLMs) are powerful computational models trained on
extensive corpora of human-readable text, enabling them to perform
general-purpose language understanding and generation. LLMs have garnered
significant attention in both industry and academia due to their exceptional
performance across various natural language processing (NLP) tasks. Despite
these successes, LLMs often produce inaccuracies, commonly referred to as
hallucinations. Prompt engineering, the process of designing and formulating
instructions for LLMs to perform specific tasks, has emerged as a key approach
to mitigating hallucinations. This paper provides a comprehensive empirical
evaluation of different prompting strategies and frameworks aimed at reducing
hallucinations in LLMs. Various prompting techniques are applied to a broad set
of benchmark datasets to assess the accuracy and hallucination rate of each
method. Additionally, the paper investigates the influence of tool-calling
agents (LLMs augmented with external tools to enhance their capabilities beyond
language generation) on hallucination rates in the same benchmarks. The
findings demonstrate that the optimal prompting technique depends on the type
of problem, and that simpler techniques often outperform more complex methods
in reducing hallucinations. Furthermore, it is shown that LLM agents can
exhibit significantly higher hallucination rates due to the added complexity of
external tool usage.

摘要：大型語言模型 (LLM) 是在大量人類可讀文本的語料庫上訓練的強大運算模型，使它們能夠執行通用語言理解和生成。LLM 在產業和學術界都獲得了顯著的關注，因為它們在各種自然語言處理 (NLP) 任務中表現出色。儘管有這些成功，LLM 經常產生不準確的結果，通常稱為幻覺。提示工程，也就是設計和制定 LLM 執行特定任務的指令的過程，已成為減輕幻覺的一種關鍵方法。本文提供了對不同提示策略和框架的全面實證評估，旨在減少 LLM 中的幻覺。將各種提示技術應用於廣泛的基準資料集，以評估每種方法的準確性和幻覺率。此外，本文還探討了工具呼叫代理（使用外部工具增強其語言生成能力的 LLM）對相同基準中的幻覺率的影響。研究結果表明，最佳提示技術取決於問題類型，而且較簡單的技術在減少幻覺方面通常優於較複雜的方法。此外，研究表明，由於外部工具使用的複雜性增加，LLM 代理可能會表現出顯著更高的幻覺率。

##### **Multi-Agent Reinforcement Learning with Selective State-Space Models**
2410.19382v1 by Jemma Daniel, Ruan de Kock, Louay Ben Nessir, Sasha Abramowitz, Omayma Mahjoub, Wiem Khlifi, Claude Formanek, Arnu Pretorius

The Transformer model has demonstrated success across a wide range of
domains, including in Multi-Agent Reinforcement Learning (MARL) where the
Multi-Agent Transformer (MAT) has emerged as a leading algorithm in the field.
The Transformer model has demonstrated success across a wide range of domains,
including in Multi-Agent Reinforcement Learning (MARL) where the Multi-Agent
Transformer (MAT) has emerged as a leading algorithm in the field. However, a
significant drawback of Transformer models is their quadratic computational
complexity relative to input size, making them computationally expensive when
scaling to larger inputs. This limitation restricts MAT's scalability in
environments with many agents. Recently, State-Space Models (SSMs) have gained
attention due to their computational efficiency, but their application in MARL
remains unexplored. In this work, we investigate the use of Mamba, a recent
SSM, in MARL and assess whether it can match the performance of MAT while
providing significant improvements in efficiency. We introduce a modified
version of MAT that incorporates standard and bi-directional Mamba blocks, as
well as a novel "cross-attention" Mamba block. Extensive testing shows that our
Multi-Agent Mamba (MAM) matches the performance of MAT across multiple standard
multi-agent environments, while offering superior scalability to larger agent
scenarios. This is significant for the MARL community, because it indicates
that SSMs could replace Transformers without compromising performance, whilst
also supporting more effective scaling to higher numbers of agents. Our project
page is available at https://sites.google.com/view/multi-agent-mamba .

摘要：Transformer 模型已在廣泛的領域中展現成功，包括在多智能體強化學習 (MARL) 中，其中 Multi-Agent Transformer (MAT) 已成為該領域的領先演算法。Transformer 模型已在廣泛的領域中展現成功，包括在多智能體強化學習 (MARL) 中，其中 Multi-Agent Transformer (MAT) 已成為該領域的領先演算法。然而，Transformer 模型的一項重大缺點是其二次計算複雜度相對於輸入大小，這使得它們在擴展到較大輸入時在計算上很昂貴。此限制限制了 MAT 在具有許多智能體的環境中的可擴充性。最近，狀態空間模型 (SSM) 因其計算效率而受到關注，但它們在 MARL 中的應用仍未被探索。在這項工作中，我們探討了在 MARL 中使用 Mamba（一種最近的 SSM），並評估它是否可以在提供顯著效率提升的同時，匹配 MAT 的效能。我們引進了一個修改版本的 MAT，其中包含標準和雙向 Mamba 區塊，以及一個新穎的「交叉注意力」Mamba 區塊。廣泛的測試表明，我們的 Multi-Agent Mamba (MAM) 在多個標準多智能體環境中與 MAT 的效能相匹配，同時為較大的智能體場景提供卓越的可擴充性。這對 MARL 社群來說很重要，因為這表示 SSM 可以取代 Transformer 而不會損害效能，同時還能支援更有效地擴展到更多數量的智能體。我們的專案頁面可在 https://sites.google.com/view/multi-agent-mamba 中取得。

##### **BitPipe: Bidirectional Interleaved Pipeline Parallelism for Accelerating Large Models Training**
2410.19367v1 by Houming Wu, Ling Chen, Wenjie Yu

With the increasing scale of models, the need for efficient distributed
training has become increasingly urgent. Recently, many synchronous pipeline
parallelism approaches have been proposed to improve training throughput.
However, these approaches still suffer from two major issues, i.e., pipeline
bubbles caused by periodic flushing and extra communication due to the
increasing number of pipeline stages. To this end, we propose BitPipe, a
bidirectional interleaved pipeline parallelism for accelerating large models
training. Specifically, a hybrid scheme of fusing interleaved pipelines with
bidirectional pipelines is proposed to reduce the computational time of each
single micro-batch and multiply the number of devices executing simultaneously.
A V-shaped schedule with eager gradient synchronization is introduced to reduce
and overlap the communication between devices. Experiments conducted on up to
32 GPUs show that BitPipe improves the training throughput of GPT-style and
BERT-style models by 1.05x-1.28x compared to the state-of-the-art synchronous
approaches. The code of our implementation is available at
https://github.com/wuhouming/BitPipe.

摘要：隨著模型規模的擴大，對於高效分布式訓練的需求變得越來越迫切。最近，已經提出了許多同步管道並行方法來改善訓練吞吐量。然而，這些方法仍然存在兩個主要問題，即由週期性沖洗引起的管道氣泡，以及由於管道階段數的增加而導致的額外通訊。為此，我們提出 BitPipe，這是一種雙向交錯管道並行方法，用於加速大型模型訓練。具體來說，提出了一種融合交錯管道和雙向管道的混合方案，以減少每個單一微批次的計算時間，並增加同時執行的設備數量。引入了帶有急切梯度同步的 V 形調度，以減少和重疊設備之間的通訊。在多達 32 個 GPU 上進行的實驗表明，與最先進的同步方法相比，BitPipe 將 GPT 風格和 BERT 風格模型的訓練吞吐量提高了 1.05 倍至 1.28 倍。我們的實現代碼可在 https://github.com/wuhouming/BitPipe 獲得。

##### **LArctan-SKAN: Simple and Efficient Single-Parameterized Kolmogorov-Arnold Networks using Learnable Trigonometric Function**
2410.19360v1 by Zhijie Chen, Xinglin Zhang

This paper proposes a novel approach for designing Single-Parameterized
Kolmogorov-Arnold Networks (SKAN) by utilizing a Single-Parameterized Function
(SFunc) constructed from trigonometric functions. Three new SKAN variants are
developed: LSin-SKAN, LCos-SKAN, and LArctan-SKAN. Experimental validation on
the MNIST dataset demonstrates that LArctan-SKAN excels in both accuracy and
computational efficiency. Specifically, LArctan-SKAN significantly improves
test set accuracy over existing models, outperforming all pure KAN variants
compared, including FourierKAN, LSS-SKAN, and Spl-KAN. It also surpasses mixed
MLP-based models such as MLP+rKAN and MLP+fKAN in accuracy. Furthermore,
LArctan-SKAN exhibits remarkable computational efficiency, with a training
speed increase of 535.01% and 49.55% compared to MLP+rKAN and MLP+fKAN,
respectively. These results confirm the effectiveness and potential of SKANs
constructed with trigonometric functions. The experiment code is available at
https://github.com/chikkkit/LArctan-SKAN .

摘要：本文提出了一個新的方法，利用由三角函數構造的單參數函數 (SFunc) 來設計單參數化 Kolmogorov-Arnold 網路 (SKAN)。開發了三個新的 SKAN 變體：LSin-SKAN、LCos-SKAN 和 LArctan-SKAN。在 MNIST 資料集上的實驗驗證表明，LArctan-SKAN 在準確性和計算效率方面都表現出色。具體來說，LArctan-SKAN 與現有模型相比，顯著提高了測試集的準確性，優於所有純粹的 KAN 變體，包括 FourierKAN、LSS-SKAN 和 Spl-KAN。它在準確性上也超越了基於 MLP 的混合模型，例如 MLP+rKAN 和 MLP+fKAN。此外，LArctan-SKAN 表現出顯著的計算效率，與 MLP+rKAN 和 MLP+fKAN 相比，訓練速度分別提高了 535.01% 和 49.55%。這些結果證實了使用三角函數構造的 SKAN 的有效性和潛力。實驗代碼可在 https://github.com/chikkkit/LArctan-SKAN 獲得。

##### **Interleaving Text and Number Embeddings to Solve Mathemathics Problems**
2410.19353v1 by Marvin Alberts, Gianmarco Gabrieli, Irina Espejo Morales

Integrating text and numbers effectively is a crucial step towards enhancing
Large Language Models (LLMs) capabilities in assisting in scientific tasks.
While most current approaches rely on discrete tokenization of numbers, for
instance, conversion to scientific notation or base 10-decomposition, a recent
approach proposed a continuous numerical encoding as an inductive bias. In this
paper, we build upon this approach by introducing more expressive numerical
embeddings. Our method addresses key shortcomings, including the elimination of
numerical artefacts and the ability to handle a wide range of magnitudes
without clipping.
  Our work presents two key contributions. First, we employ an MLP to assign
distinct directions in the embedding space to different numbers. Our second
contribution is the introduction of a routing layer that differentiates between
numerical and text embeddings. We hypothesise that this combined approach
enables the model to distinguish between text and number distributions while
maintaining its capacity for arithmetic operations.
  Using only a 45 M parameter encoder-decoder architecture our method achieves
a $R^2$=0.9988 over a wide range of magnitude ($10^{-3},10^{8}$). In addition,
we empirically observe a reduction of the numerical artefacts and biases
observed compared to the baselines.

摘要：有效整合文字和數字是提升大型語言模型 (LLM) 在科學任務中提供協助的能力的關鍵步驟。雖然目前大多數方法依賴數字的離散化標記，例如轉換為科學記號或 10 進位分解，但最近的方法提出連續數值編碼作為歸納偏差。在本文中，我們透過引入更具表達力的數值嵌入，建立在這個方法之上。我們的做法解決了關鍵缺點，包括消除數值人工製品，以及在不剪裁的情況下處理廣泛的數量級的能力。
我們的研究提出了兩個關鍵貢獻。首先，我們採用 MLP，在嵌入空間中為不同的數字指定不同的方向。我們的第二個貢獻是引入一個路由層，區分數值和文字嵌入。我們假設這種組合方法使模型能夠區分文字和數字分佈，同時保持其執行算術運算的能力。
僅使用 45M 參數編碼器-解碼器架構，我們的做法在廣泛的數量級 ($10^{-3},10^{8}$) 上達到了 $R^2$=0.9988。此外，我們根據經驗觀察到與基準相比，數值人工製品和偏差有所減少。

##### **Interpreting Neural Networks through Mahalanobis Distance**
2410.19352v1 by Alan Oursland

This paper introduces a theoretical framework that connects neural network
linear layers with the Mahalanobis distance, offering a new perspective on
neural network interpretability. While previous studies have explored
activation functions primarily for performance optimization, our work
interprets these functions through statistical distance measures, a less
explored area in neural network research. By establishing this connection, we
provide a foundation for developing more interpretable neural network models,
which is crucial for applications requiring transparency. Although this work is
theoretical and does not include empirical data, the proposed distance-based
interpretation has the potential to enhance model robustness, improve
generalization, and provide more intuitive explanations of neural network
decisions.

摘要：本文提出了一個理論架構，將神經網路線性層與馬氏距離連結起來，提供了神經網路可解釋性的新觀點。雖然先前的研究主要針對效能最佳化來探討激活函數，但我們的研究透過統計距離測量來詮釋這些函數，這是神經網路研究中較少探討的領域。透過建立此連結，我們為開發更具可解釋性的神經網路模型奠定基礎，這對於需要透明度的應用至關重要。儘管這項研究是理論性的，且不包含經驗數據，但所提出的基於距離的詮釋有潛力增強模型穩健性、改善泛化，並提供更直觀的神經網路決策說明。

##### **AgentSense: Benchmarking Social Intelligence of Language Agents through Interactive Scenarios**
2410.19346v1 by Xinyi Mou, Jingcong Liang, Jiayu Lin, Xinnong Zhang, Xiawei Liu, Shiyue Yang, Rong Ye, Lei Chen, Haoyu Kuang, Xuanjing Huang, Zhongyu Wei

Large language models (LLMs) are increasingly leveraged to empower autonomous
agents to simulate human beings in various fields of behavioral research.
However, evaluating their capacity to navigate complex social interactions
remains a challenge. Previous studies face limitations due to insufficient
scenario diversity, complexity, and a single-perspective focus. To this end, we
introduce AgentSense: Benchmarking Social Intelligence of Language Agents
through Interactive Scenarios. Drawing on Dramaturgical Theory, AgentSense
employs a bottom-up approach to create 1,225 diverse social scenarios
constructed from extensive scripts. We evaluate LLM-driven agents through
multi-turn interactions, emphasizing both goal completion and implicit
reasoning. We analyze goals using ERG theory and conduct comprehensive
experiments. Our findings highlight that LLMs struggle with goals in complex
social scenarios, especially high-level growth needs, and even GPT-4o requires
improvement in private information reasoning.

摘要：大型語言模型 (LLM) 愈來愈常被用於賦能自主代理，以模擬各個行為研究領域中的人類。然而，評估它們在複雜社會互動中導航的能力仍然是一個挑戰。先前的研究因情境多樣性、複雜性和單一觀點焦點不足而面臨限制。為此，我們引入了 AgentSense：透過互動情境對語言代理的社交智慧進行基準測試。AgentSense 借鑑戲劇理論，採用自下而上的方法，從廣泛的腳本中創建 1,225 個多樣化的社交情境。我們透過多輪互動評估由 LLM 驅動的代理，強調目標完成和隱含推理。我們使用 ERG 理論分析目標，並進行全面的實驗。我們的研究結果強調，LLM 在複雜的社會情境中難以達成目標，特別是高層次的成長需求，甚至 GPT-4o 也需要改進私人資訊推理。

##### **High Resolution Seismic Waveform Generation using Denoising Diffusion**
2410.19343v1 by Andreas Bergmeister, Kadek Hendrawan Palgunadi, Andrea Bosisio, Laura Ermert, Maria Koroni, Nathanaël Perraudin, Simon Dirmeier, Men-Andrin Meier

Accurate prediction and synthesis of seismic waveforms are crucial for
seismic hazard assessment and earthquake-resistant infrastructure design.
Existing prediction methods, such as Ground Motion Models and physics-based
simulations, often fail to capture the full complexity of seismic wavefields,
particularly at higher frequencies. This study introduces a novel, efficient,
and scalable generative model for high-frequency seismic waveform generation.
Our approach leverages a spectrogram representation of seismic waveform data,
which is reduced to a lower-dimensional submanifold via an autoencoder. A
state-of-the-art diffusion model is trained to generate this latent
representation, conditioned on key input parameters: earthquake magnitude,
recording distance, site conditions, and faulting type. The model generates
waveforms with frequency content up to 50 Hz. Any scalar ground motion
statistic, such as peak ground motion amplitudes and spectral accelerations,
can be readily derived from the synthesized waveforms. We validate our model
using commonly used seismological metrics, and performance metrics from image
generation studies. Our results demonstrate that our openly available model can
generate distributions of realistic high-frequency seismic waveforms across a
wide range of input parameters, even in data-sparse regions. For the scalar
ground motion statistics commonly used in seismic hazard and earthquake
engineering studies, we show that the model accurately reproduces both the
median trends of the real data and its variability. To evaluate and compare the
growing number of this and similar 'Generative Waveform Models' (GWM), we argue
that they should generally be openly available and that they should be included
in community efforts for ground motion model evaluations.

摘要：準確預測和合成地震波形對於地震災害評估和抗震基礎設施設計至關重要。
現有的預測方法，例如地面運動模型和基於物理的模擬，通常無法捕捉到地震波場的全部複雜性，特別是在較高頻率下。本研究引入了一個新穎、高效且可擴充的生成模型，用於高頻地震波形生成。
我們的做法利用了地震波形數據的頻譜圖表示，該表示通過自動編碼器簡化為低維子流形。最先進的擴散模型經過訓練，可以生成這種潛在表示，並根據關鍵輸入參數進行調整：地震震級、記錄距離、場址條件和斷層類型。該模型生成的波形頻率內容高達 50 Hz。任何標量地面運動統計數據，例如峰值地面運動幅度和光譜加速度，都可以很容易地從合成的波形中推導出來。我們使用常用的地震學指標和圖像生成研究中的性能指標來驗證我們的模型。我們的結果表明，我們開放獲取的模型可以在各種輸入參數下生成逼真的高頻地震波形分佈，即使在數據稀疏區域也是如此。對於地震災害和地震工程研究中常用的標量地面運動統計數據，我們表明該模型準確地再現了真實數據的中值趨勢及其變異性。為了評估和比較數量日益增加的此類「生成波形模型」(GWM)，我們認為它們通常應該是開放獲取的，並且應該包含在用於地面運動模型評估的社區工作中。

##### **Two are better than one: Context window extension with multi-grained self-injection**
2410.19318v1 by Wei Han, Pan Zhou, Soujanya Poria, Shuicheng Yan

The limited context window of contemporary large language models (LLMs)
remains a huge barrier to their broader application across various domains.
While continual pre-training on long-context data is a straightforward and
effective solution, it incurs substantial costs in terms of data acquisition
and computational resources. To alleviate this issue, we propose SharedLLM, a
novel approach grounded in the design philosophy of multi-grained context
compression and query-aware information retrieval. SharedLLM is composed of two
short-context LLMs such as LLaMA-2, termed upper model and lower model. The
lower model functions as a compressor while the upper model acts as a decoder.
The upper model receives compressed, multi-grained context information from the
lower model and performs context-aware modeling on the running text.
Information transfer between the compressor and decoder occurs only at the
lowest layers to refrain from long forward paths in the lower model and
redundant cross-attention modules in the upper model. Based on this
architecture, we introduce a specialized tree-style data structure to
efficiently encode, store and retrieve multi-grained contextual information for
text chunks. This structure, combined with a search algorithm, enables rapid
encoding and retrieval of relevant information from various levels of the tree
based on the input query. This entire process, wherein the sender and receiver
are derived from the same LLM layer, is referred to as self-injection.

摘要：當代大型語言模型 (LLM) 受限的上下文視窗，仍然是其在各種領域廣泛應用的巨大障礙。雖然持續在長文本資料上進行預訓練是一個直接且有效的方法，但它在資料取得和運算資源方面會產生大量的成本。為了緩解這個問題，我們提出 SharedLLM，一個建基於多粒度上下文壓縮和查詢感知資訊檢索的設計理念的新方法。SharedLLM 由兩個短文本 LLM 組成，例如 LLaMA-2，稱為上層模型和下層模型。下層模型作為壓縮器，而上層模型作為解碼器。上層模型從下層模型接收壓縮的多粒度上下文資訊，並對執行中的文字進行上下文感知建模。壓縮器和解碼器之間的資訊傳遞只發生在最底層，以避免下層模型中過長的正向路徑和上層模型中冗餘的交叉注意模組。基於這個架構，我們引入一個專門的樹狀資料結構，以有效編碼、儲存和檢索文字區塊的多粒度上下文資訊。這個結構與搜尋演算法相結合，可以根據輸入查詢快速編碼和檢索樹中不同層級的相關資訊。這個整個過程，其中發送者和接收者來自同一個 LLM 層，稱為自注入。

##### **FairMT-Bench: Benchmarking Fairness for Multi-turn Dialogue in Conversational LLMs**
2410.19317v1 by Zhiting Fan, Ruizhe Chen, Tianxiang Hu, Zuozhu Liu

The growing use of large language model (LLM)-based chatbots has raised
concerns about fairness. Fairness issues in LLMs can lead to severe
consequences, such as bias amplification, discrimination, and harm to
marginalized communities. While existing fairness benchmarks mainly focus on
single-turn dialogues, multi-turn scenarios, which in fact better reflect
real-world conversations, present greater challenges due to conversational
complexity and potential bias accumulation. In this paper, we propose a
comprehensive fairness benchmark for LLMs in multi-turn dialogue scenarios,
\textbf{FairMT-Bench}. Specifically, we formulate a task taxonomy targeting LLM
fairness capabilities across three stages: context understanding, user
interaction, and instruction trade-offs, with each stage comprising two tasks.
To ensure coverage of diverse bias types and attributes, we draw from existing
fairness datasets and employ our template to construct a multi-turn dialogue
dataset, \texttt{FairMT-10K}. For evaluation, GPT-4 is applied, alongside bias
classifiers including Llama-Guard-3 and human validation to ensure robustness.
Experiments and analyses on \texttt{FairMT-10K} reveal that in multi-turn
dialogue scenarios, current LLMs are more likely to generate biased responses,
and there is significant variation in performance across different tasks and
models. Based on this, we curate a challenging dataset, \texttt{FairMT-1K}, and
test 15 current state-of-the-art (SOTA) LLMs on this dataset. The results show
the current state of fairness in LLMs and showcase the utility of this novel
approach for assessing fairness in more realistic multi-turn dialogue contexts,
calling for future work to focus on LLM fairness improvement and the adoption
of \texttt{FairMT-1K} in such efforts.

摘要：<paragraph>大型語言模型 (LLM) 聊天機器人的使用日益廣泛，這引發了人們對公平性的擔憂。LLM 中的公平性問題可能會導致嚴重的後果，例如偏見擴大、歧視和對邊緣化社群造成傷害。現有的公平性基準主要集中在單輪對話上，而多輪對話場景實際上更能反映真實世界的對話，由於對話的複雜性和潛在的偏見累積，因此帶來了更大的挑戰。在本文中，我們為多輪對話場景中的 LLM 提出了一個全面的公平性基準，\textbf{FairMT-Bench}。具體來說，我們制定了一個任務分類法，針對 LLM 在三個階段的公平性能力：背景理解、使用者互動和指令權衡，每個階段包含兩個任務。為了確保涵蓋多種偏見類型和屬性，我們從現有的公平性資料集中汲取靈感，並使用我們的範本來構建多輪對話資料集，\texttt{FairMT-10K}。為了進行評估，我們應用 GPT-4，以及包括 Llama-Guard-3 在內的偏見分類器和人工驗證，以確保健全性。在 \texttt{FairMT-10K} 上進行的實驗和分析表明，在多輪對話場景中，當前的 LLM 更有可能產生有偏見的回應，並且不同任務和模型之間的效能差異很大。基於此，我們策劃了一個具有挑戰性的資料集，\texttt{FairMT-1K}，並在此資料集上測試了 15 個當前最先進 (SOTA) 的 LLM。結果顯示了 LLM 中公平性的現狀，並展示了這種新方法在更真實的多輪對話上下文中評估公平性的效用，呼籲未來的研究重點關注 LLM 公平性的改進，並在這些工作中採用 \texttt{FairMT-1K}。</paragraph>

##### **A prescriptive theory for brain-like inference**
2410.19315v1 by Hadi Vafaii, Dekel Galor, Jacob L. Yates

The Evidence Lower Bound (ELBO) is a widely used objective for training deep
generative models, such as Variational Autoencoders (VAEs). In the neuroscience
literature, an identical objective is known as the variational free energy,
hinting at a potential unified framework for brain function and machine
learning. Despite its utility in interpreting generative models, including
diffusion models, ELBO maximization is often seen as too broad to offer
prescriptive guidance for specific architectures in neuroscience or machine
learning. In this work, we show that maximizing ELBO under Poisson assumptions
for general sequence data leads to a spiking neural network that performs
Bayesian posterior inference through its membrane potential dynamics. The
resulting model, the iterative Poisson VAE (iP-VAE), has a closer connection to
biological neurons than previous brain-inspired predictive coding models based
on Gaussian assumptions. Compared to amortized and iterative VAEs, iP-VAElearns
sparser representations and exhibits superior generalization to
out-of-distribution samples. These findings suggest that optimizing ELBO,
combined with Poisson assumptions, provides a solid foundation for developing
prescriptive theories in NeuroAI.

摘要：證據下限 (ELBO) 是訓練深度生成模型（例如變異自動編碼器 (VAE)）時廣泛使用的目標。在神經科學文獻中，一個相同的目標稱為變異自由能，暗示了大腦功能和機器學習的潛在統一框架。儘管 ELBO 最大化在解釋生成模型（包括擴散模型）方面很有用，但它通常被視為太廣泛，無法為神經科學或機器學習中的特定架構提供規範指導。在這項工作中，我們表明在一般序列資料的泊松假設下最大化 ELBO 會導致一個尖峰神經網路，它透過其膜電位動態執行貝氏後驗推論。由此產生的模型，即迭代泊松 VAE (iP-VAE)，與基於高斯假設的先前受大腦啟發的預測編碼模型相比，與生物神經元有更緊密的聯繫。與攤銷和迭代 VAE 相比，iP-VAE 學習更稀疏的表示，並對分布外樣本表現出優異的泛化能力。這些發現表明，優化 ELBO，結合泊松假設，為在 NeuroAI 中開發規範理論提供了堅實的基礎。

##### **Revealing and Reducing Gender Biases in Vision and Language Assistants (VLAs)**
2410.19314v1 by Leander Girrbach, Yiran Huang, Stephan Alaniz, Trevor Darrell, Zeynep Akata

Pre-trained large language models (LLMs) have been reliably integrated with
visual input for multimodal tasks. The widespread adoption of instruction-tuned
image-to-text vision-language assistants (VLAs) like LLaVA and InternVL
necessitates evaluating gender biases. We study gender bias in 22 popular
open-source VLAs with respect to personality traits, skills, and occupations.
Our results show that VLAs replicate human biases likely present in the data,
such as real-world occupational imbalances. Similarly, they tend to attribute
more skills and positive personality traits to women than to men, and we see a
consistent tendency to associate negative personality traits with men. To
eliminate the gender bias in these models, we find that finetuning-based
debiasing methods achieve the best tradeoff between debiasing and retaining
performance on downstream tasks. We argue for pre-deploying gender bias
assessment in VLAs and motivate further development of debiasing strategies to
ensure equitable societal outcomes.

摘要：預訓練大型語言模型 (LLM) 已可靠地與視覺輸入整合，以執行多模態任務。廣泛採用 LLaVA 和 InternVL 等指令調整型影像轉文字視覺語言助理 (VLA)，因此有必要評估性別偏見。我們針對 22 種流行的開源 VLA 研究性別偏見，包括人格特質、技能和職業。我們的結果顯示，VLA 會複製可能存在於資料中的人類偏見，例如現實世界的職業失衡。同樣地，他們傾向於將更多技能和正面人格特質歸因於女性，而我們看到一種將負面人格特質與男性關聯起來的一致傾向。為了消除這些模型中的性別偏見，我們發現基於微調的去偏見方法在去偏見和保留下游任務效能之間取得最佳折衷。我們主張在 VLA 中預先部署性別偏見評估，並促使進一步發展去偏見策略，以確保公平的社會成果。

##### **COAT: Compressing Optimizer states and Activation for Memory-Efficient FP8 Training**
2410.19313v1 by Haocheng Xi, Han Cai, Ligeng Zhu, Yao Lu, Kurt Keutzer, Jianfei Chen, Song Han

FP8 training has emerged as a promising method for improving training
efficiency. Existing frameworks accelerate training by applying FP8 computation
to linear layers while leaving optimizer states and activations in higher
precision, which fails to fully optimize memory usage. This paper introduces
COAT (Compressing Optimizer States and Activations for FP8 Training), a novel
FP8 training framework designed to significantly reduce memory footprint when
training large models. COAT addresses current limitations through two key
innovations: (1) Dynamic Range Expansion, which aligns optimizer state
distributions more closely with the FP8 representation range, thereby reducing
quantization error, and (2) Mixed-Granularity Activation Quantization, which
optimizes activation memory using a combination of per-tensor and per-group
quantization strategies. Experiments demonstrate that COAT effectively reduces
end-to-end training memory footprint by 1.54x compared to BF16 while achieving
nearly lossless performance across various tasks, such as Large Language Model
pretraining and fine-tuning and Vision Language Model training. COAT also
achieves a 1.43x end-to-end training speedup compared to BF16, performing on
par with or surpassing TransformerEngine's speedup. COAT enables efficient
full-parameter training of large models on fewer GPUs, and facilitates doubling
the batch size in distributed training settings, providing a practical solution
for scaling large-scale model training. The code is available at
https://github.com/NVlabs/COAT.

摘要：FP8 訓練已成為改善訓練效率的有前途方法。現有框架透過將 FP8 計算應用於線性層，同時將優化器狀態和激活保留在較高精度，來加速訓練，這無法完全最佳化記憶體使用率。本文介紹 COAT（壓縮優化器狀態和激活以進行 FP8 訓練），這是一個新穎的 FP8 訓練框架，旨在在訓練大型模型時大幅減少記憶體使用量。COAT 透過兩項關鍵創新來解決當前的限制：(1) 動態範圍擴展，它讓優化器狀態分佈更接近 FP8 表示範圍，從而減少量化誤差，以及 (2) 混合粒度激活量化，它使用每個張量和每個群組量化策略的組合來最佳化激活記憶體。實驗證明，與 BF16 相比，COAT 有效地將端到端訓練記憶體使用量減少 1.54 倍，同時在各種任務中實現近乎無損失的效能，例如大型語言模型預訓練和微調，以及視覺語言模型訓練。與 BF16 相比，COAT 還實現了 1.43 倍的端到端訓練加速，效能與 TransformerEngine 的加速相當或超越。COAT 能讓大型模型在較少的 GPU 上進行有效率的全參數訓練，並有助於在分散式訓練設定中將批次大小加倍，為擴充大型模型訓練提供一個實用的解決方案。程式碼可於 https://github.com/NVlabs/COAT 取得。

##### **Flow Generator Matching**
2410.19310v1 by Zemin Huang, Zhengyang Geng, Weijian Luo, Guo-jun Qi

In the realm of Artificial Intelligence Generated Content (AIGC),
flow-matching models have emerged as a powerhouse, achieving success due to
their robust theoretical underpinnings and solid ability for large-scale
generative modeling. These models have demonstrated state-of-the-art
performance, but their brilliance comes at a cost. The process of sampling from
these models is notoriously demanding on computational resources, as it
necessitates the use of multi-step numerical ordinary differential equations
(ODEs). Against this backdrop, this paper presents a novel solution with
theoretical guarantees in the form of Flow Generator Matching (FGM), an
innovative approach designed to accelerate the sampling of flow-matching models
into a one-step generation, while maintaining the original performance. On the
CIFAR10 unconditional generation benchmark, our one-step FGM model achieves a
new record Fr\'echet Inception Distance (FID) score of 3.08 among few-step
flow-matching-based models, outperforming original 50-step flow-matching
models. Furthermore, we use the FGM to distill the Stable Diffusion 3, a
leading text-to-image flow-matching model based on the MM-DiT architecture. The
resulting MM-DiT-FGM one-step text-to-image model demonstrates outstanding
industry-level performance. When evaluated on the GenEval benchmark, MM-DiT-FGM
has delivered remarkable generating qualities, rivaling other multi-step models
in light of the efficiency of a single generation step.

摘要：在人工智能生成内容 (AIGC) 领域，
流匹配模型已成为一股强大力量，由于其稳健的理论基础和强大的大规模生成建模能力而取得成功。这些模型已展示出最先进的性能，但其卓越性也付出了代价。从这些模型中进行采样的过程对计算资源要求极高，因为它需要使用多步数值常微分方程 (ODE)。在此背景下，本文提出了一种具有理论保证的新颖解决方案，即流生成器匹配 (FGM)，这是一种旨在将流匹配模型的采样加速到一步生成，同时保持原始性能的创新方法。在 CIFAR10 无条件生成基准上，我们的单步 FGM 模型在基于流匹配的少数步模型中实现了 3.08 的新记录 Fr\'echet Inception Distance (FID) 分数，优于原始的 50 步流匹配模型。此外，我们使用 FGM 提炼了 Stable Diffusion 3，这是一种基于 MM-DiT 架构的领先文本到图像流匹配模型。由此产生的 MM-DiT-FGM 单步文本到图像模型展示了出色的行业级性能。在 GenEval 基准上进行评估时，MM-DiT-FGM 提供了卓越的生成质量，在单次生成步骤的效率方面与其他多步模型相媲美。

##### **TEARS: Textual Representations for Scrutable Recommendations**
2410.19302v1 by Emiliano Penaloza, Olivier Gouvert, Haolun Wu, Laurent Charlin

Traditional recommender systems rely on high-dimensional (latent) embeddings
for modeling user-item interactions, often resulting in opaque representations
that lack interpretability. Moreover, these systems offer limited control to
users over their recommendations. Inspired by recent work, we introduce TExtuAl
Representations for Scrutable recommendations (TEARS) to address these
challenges. Instead of representing a user's interests through a latent
embedding, TEARS encodes them in natural text, providing transparency and
allowing users to edit them. To do so, TEARS uses a modern LLM to generate user
summaries based on user preferences. We find the summaries capture user
preferences uniquely. Using these summaries, we take a hybrid approach where we
use an optimal transport procedure to align the summaries' representation with
the learned representation of a standard VAE for collaborative filtering. We
find this approach can surpass the performance of three popular VAE models
while providing user-controllable recommendations. We also analyze the
controllability of TEARS through three simulated user tasks to evaluate the
effectiveness of a user editing its summary.

摘要：傳統推薦系統依賴於高維度（潛在）嵌入，用於建模使用者與項目的互動，這通常會導致不透明的表示，缺乏可解釋性。此外，這些系統對使用者的推薦提供有限的控制。受到近期研究的啟發，我們引入了可理解推薦的文字表示（TEARS），以解決這些挑戰。TEARS 並非透過潛在嵌入表示使用者的興趣，而是將它們編碼成自然語言，提供透明度並允許使用者編輯它們。為此，TEARS 使用現代 LLM 根據使用者偏好產生使用者摘要。我們發現摘要獨特地擷取了使用者偏好。使用這些摘要，我們採取混合方法，使用最佳傳輸程序將摘要的表示與標準 VAE 的協同過濾學習表示對齊。我們發現這種方法可以超越三種流行 VAE 模型的效能，同時提供使用者可控的推薦。我們還透過三個模擬使用者任務分析 TEARS 的可控性，以評估使用者編輯其摘要的有效性。

##### **Any Other Thoughts, Hedgehog? Linking Deliberation Chains in Collaborative Dialogues**
2410.19301v1 by Abhijnan Nath, Videep Venkatesha, Mariah Bradford, Avyakta Chelle, Austin Youngren, Carlos Mabrey, Nathaniel Blanchard, Nikhil Krishnaswamy

Question-asking in collaborative dialogue has long been established as key to
knowledge construction, both in internal and collaborative problem solving. In
this work, we examine probing questions in collaborative dialogues: questions
that explicitly elicit responses from the speaker's interlocutors.
Specifically, we focus on modeling the causal relations that lead directly from
utterances earlier in the dialogue to the emergence of the probing question. We
model these relations using a novel graph-based framework of deliberation
chains, and reframe the problem of constructing such chains as a
coreference-style clustering problem. Our framework jointly models probing and
causal utterances and the links between them, and we evaluate on two
challenging collaborative task datasets: the Weights Task and DeliData. Our
results demonstrate the effectiveness of our theoretically-grounded approach
compared to both baselines and stronger coreference approaches, and establish a
standard of performance in this novel task.

摘要：在合作对话中提问早已被确立为建构知识的关键，无论是在内部还是在合作解决问题中。在这项工作中，我们研究了合作对话中的探测问题：明确引发说话者对话者的反应的问题。具体来说，我们专注于对导致对话中早期话语直接产生探测问题的因果关系进行建模。我们使用一种新颖的基于图表的审议链框架对这些关系进行建模，并将构建此类链的问题重新表述为一个指代风格的聚类问题。我们的框架共同对探测和因果话语以及它们之间的联系进行建模，并且我们在两个具有挑战性的协作任务数据集上进行评估：权重任务和 DeliData。我们的结果证明了我们基于理论的方法与基线和更强的共指方法相比的有效性，并在这一新任务中建立了绩效标准。

##### **A Stock Price Prediction Approach Based on Time Series Decomposition and Multi-Scale CNN using OHLCT Images**
2410.19291v1 by Zhiyuan Pei, Jianqi Yan, Jin Yan, Bailing Yang, Ziyuan Li, Lin Zhang, Xin Liu, Yang Zhang

Stock price fluctuations are influenced by a variety of factors, including
macroeconomic conditions, government policies, and market sentiment, which
together make price movements complex and difficult to predict. Despite many
studies aimed at enhancing stock price prediction models, challenges such as
data noise, model overfitting, and lack of interpretability are still
encountered. To address these issues and improve prediction accuracy, this
paper proposes a novel method, named Sequence-based Multiscale Fusion
Regression Convolutional Neural Network (SMSFR-CNN), for predicting stock price
movements in the China A-share market. By utilizing CNN to learn sequential
features and combining them with image features, we improve the accuracy of
stock trend prediction on the A-share market stock dataset. This approach
reduces the search space for image features, stabilizes, and accelerates the
training process. Extensive comparative experiments on 4,454 A-share stocks
show that the proposed model achieves 61.15% for positive predictive value and
63.37% for negative predictive value of the stock price trend over the next 5
days, resulting in a total profit of 165.09%.

摘要：股票價格波動受多種因素影響，包括宏觀經濟環境、政府政策和市場情緒，這些因素共同導致價格走勢複雜且難以預測。儘管有許多研究旨在增強股票價格預測模型，但仍會遇到諸如數據雜訊、模型過擬合和缺乏可解釋性等挑戰。為了解決這些問題並提高預測準確性，本文提出了一種名為基於序列的多尺度融合回歸卷積神經網路 (SMSFR-CNN) 的新方法，用於預測中國 A 股市場的股票價格走勢。通過利用 CNN 學習序列特徵並將其與影像特徵相結合，我們提高了對 A 股市場股票數據集的股票趨勢預測準確性。這種方法縮小了影像特徵的搜索空間，並穩定並加速了訓練過程。對 4,454 隻 A 股進行的廣泛比較實驗表明，所提出的模型對未來 5 天的股票價格趨勢的陽性預測值達到 61.15%，負面預測值達到 63.37%，總利潤達到 165.09%。

##### **Fictitious Synthetic Data Can Improve LLM Factuality via Prerequisite Learning**
2410.19290v1 by Yujian Liu, Shiyu Chang, Tommi Jaakkola, Yang Zhang

Recent studies have identified one aggravating factor of LLM hallucinations
as the knowledge inconsistency between pre-training and fine-tuning, where
unfamiliar fine-tuning data mislead the LLM to fabricate plausible but wrong
outputs. In this paper, we propose a novel fine-tuning strategy called
Prereq-Tune to address this knowledge inconsistency and reduce hallucinations.
Fundamentally, Prereq-Tune disentangles the learning of skills and knowledge,
so the model learns only the task skills without being impacted by the
knowledge inconsistency. To achieve this, Prereq-Tune introduces an additional
prerequisite learning stage to learn the necessary knowledge for SFT, allowing
subsequent SFT to focus only on task skills. Prereq-Tune can also be combined
with fictitious synthetic data to enhance the grounding of LLM outputs to their
internal knowledge. Experiments show that Prereq-Tune outperforms existing
baselines in improving LLM's factuality across short QA and long-form
generation tasks. It also opens new possibilities for knowledge-controlled
generation in LLMs. Our code is available at
https://github.com/UCSB-NLP-Chang/Prereq_tune.git.

摘要：最近的研究已找出 LLM 幻觉的一个加重因素，即预训练与微调之间的知识不一致，其中不熟悉的微调数据会误导 LLM 捏造似是而非但错误的输出。本文中，我们提出一种名为 Prereq-Tune 的新微调策略来解决此知识不一致并减少幻觉。从根本上，Prereq-Tune 解开技能和知识的学习，因此模型仅学习任务技能，而不会受到知识不一致的影响。为实现此目的，Prereq-Tune 引入一个额外的先决条件学习阶段来学习 SFT 所需的知识，从而允许后续 SFT 仅专注于任务技能。Prereq-Tune 还可以与虚构的合成数据结合使用，以增强 LLM 输出与其内部知识的基础。实验表明，Prereq-Tune 在改善 LLM 在短问答和长篇生成任务中的事实性方面优于现有的基准。它还为 LLM 中的知识控制生成开辟了新的可能性。我们的代码可在 https://github.com/UCSB-NLP-Chang/Prereq_tune.git 获得。

##### **ST-NeRP: Spatial-Temporal Neural Representation Learning with Prior Embedding for Patient-specific Imaging Study**
2410.19283v1 by Liang Qiu, Liyue Shen, Lianli Liu, Junyan Liu, Yizheng Chen, Lei Xing

During and after a course of therapy, imaging is routinely used to monitor
the disease progression and assess the treatment responses. Despite of its
significance, reliably capturing and predicting the spatial-temporal anatomic
changes from a sequence of patient-specific image series presents a
considerable challenge. Thus, the development of a computational framework
becomes highly desirable for a multitude of practical applications. In this
context, we propose a strategy of Spatial-Temporal Neural Representation
learning with Prior embedding (ST-NeRP) for patient-specific imaging study. Our
strategy involves leveraging an Implicit Neural Representation (INR) network to
encode the image at the reference time point into a prior embedding.
Subsequently, a spatial-temporally continuous deformation function is learned
through another INR network. This network is trained using the whole
patient-specific image sequence, enabling the prediction of deformation fields
at various target time points. The efficacy of the ST-NeRP model is
demonstrated through its application to diverse sequential image series,
including 4D CT and longitudinal CT datasets within thoracic and abdominal
imaging. The proposed ST-NeRP model exhibits substantial potential in enabling
the monitoring of anatomical changes within a patient throughout the
therapeutic journey.

摘要：在治療過程中和治療後，影像檢查會常規用於監控疾病進程和評估治療反應。儘管影像檢查很重要，但從一系列特定於患者的影像序列中可靠地擷取和預測時空解剖變化仍是一項重大挑戰。因此，開發一個運算框架對於許多實際應用而言非常有必要。在此脈絡下，我們提出了一個具有先驗嵌入的時空神經表示學習策略 (ST-NeRP)，用於特定於患者的影像研究。我們的策略涉及利用隱式神經表示 (INR) 網路將參考時間點的影像編碼成先驗嵌入。隨後，透過另一個 INR 網路學習時空連續變形函數。這個網路是使用整個特定於患者的影像序列進行訓練的，能夠預測各種目標時間點的變形場。ST-NeRP 模型的功效透過應用於不同的連續影像序列得到證明，包括胸部和腹部影像中的 4D CT 和縱向 CT 資料集。提出的 ST-NeRP 模型在整個治療過程中實現監控患者解剖變化方面展現出巨大的潛力。

##### **UbiHR: Resource-efficient Long-range Heart Rate Sensing on Ubiquitous Devices**
2410.19279v1 by Haoyu Bian, Bin Guo, Sicong Liu, Yasan Ding, Shanshan Gao, Zhiwen Yu

Ubiquitous on-device heart rate sensing is vital for high-stress individuals
and chronic patients. Non-contact sensing, compared to contact-based tools,
allows for natural user monitoring, potentially enabling more accurate and
holistic data collection. However, in open and uncontrolled mobile
environments, user movement and lighting introduce. Existing methods, such as
curve-based or short-range deep learning recognition based on adjacent frames,
strike the optimal balance between real-time performance and accuracy,
especially under limited device resources. In this paper, we present UbiHR, a
ubiquitous device-based heart rate sensing system. Key to UbiHR is a real-time
long-range spatio-temporal model enabling noise-independent heart rate
recognition and display on commodity mobile devices, along with a set of
mechanisms for prompt and energy-efficient sampling and preprocessing. Diverse
experiments and user studies involving four devices, four tasks, and 80
participants demonstrate UbiHR's superior performance, enhancing accuracy by up
to 74.2\% and reducing latency by 51.2\%.

摘要：無所不在的裝置上偵測心率對於高度緊繃的個人和慢性病患至關重要。與接觸式工具相較，非接觸式感測允許自然使用者監控，潛在能讓資料收集更準確且全面。然而，在開放且不受控的行動環境中，使用者移動和光線會造成影響。現有方法，例如基於鄰近影像的曲線式或短程深度學習辨識，在即時效能和準確度之間取得最佳平衡，尤其是在裝置資源受限的情況下。在本文中，我們提出 UbiHR，一個無所不在的基於裝置的心率感測系統。UbiHR 的關鍵在於一個即時的長程時空模型，能讓商品行動裝置辨識與顯示不受雜訊影響的心率，以及一組用於快速且節能的取樣和前處理機制。包含四個裝置、四個任務和 80 位參與者的各種實驗和使用者研究證明了 UbiHR 的卓越效能，將準確度提升多達 74.2%，並將延遲降低 51.2%。

##### **Applying sparse autoencoders to unlearn knowledge in language models**
2410.19278v1 by Eoin Farrell, Yeu-Tong Lau, Arthur Conmy

We investigate whether sparse autoencoders (SAEs) can be used to remove
knowledge from language models. We use the biology subset of the Weapons of
Mass Destruction Proxy dataset and test on the gemma-2b-it and gemma-2-2b-it
language models. We demonstrate that individual interpretable biology-related
SAE features can be used to unlearn biology-related knowledge with minimal
side-effects. Our results suggest that negative scaling of feature activations
is necessary and that zero ablating features is ineffective. We find that
intervening using multiple SAE features simultaneously can unlearn multiple
different topics, but with similar or larger unwanted side-effects than the
existing Representation Misdirection for Unlearning technique. Current SAE
quality or intervention techniques would need to improve to make SAE-based
unlearning comparable to the existing fine-tuning based techniques.

摘要：我們探討稀疏自動編碼器 (SAE) 是否可用於移除語言模型中的知識。我們使用大規模毀滅性武器代理資料集的生物子集，並在 gemma-2b-it 和 gemma-2-2b-it 語言模型上進行測試。我們證明個別可解釋的生物相關 SAE 特徵可用於取消學習生物相關知識，且副作用極小。我們的結果表明，特徵激活的負向縮放是必要的，而將特徵消零是無效的。我們發現，同時使用多個 SAE 特徵進行干預可以取消學習多個不同的主題，但與現有的取消學習技術「表示誤導」相比，副作用類似或更大。目前的 SAE 品質或干預技術需要改進，才能使基於 SAE 的取消學習與現有的基於微調的技術相媲美。

##### **Ripple: Accelerating LLM Inference on Smartphones with Correlation-Aware Neuron Management**
2410.19274v1 by Tuowei Wang, Ruwen Fan, Minxing Huang, Zixu Hao, Kun Li, Ting Cao, Youyou Lu, Yaoxue Zhang, Ju Ren

Large Language Models (LLMs) have achieved remarkable success across various
domains, yet deploying them on mobile devices remains an arduous challenge due
to their extensive computational and memory demands. While lightweight LLMs
have been developed to fit mobile environments, they suffer from degraded model
accuracy. In contrast, sparsity-based techniques minimize DRAM usage by
selectively transferring only relevant neurons to DRAM while retaining the full
model in external storage, such as flash. However, such approaches are
critically limited by numerous I/O operations, particularly on smartphones with
severe IOPS constraints.
  In this paper, we propose Ripple, a novel approach that accelerates LLM
inference on smartphones by optimizing neuron placement in flash memory. Ripple
leverages the concept of Neuron Co-Activation, where neurons frequently
activated together are linked to facilitate continuous read access and optimize
data transfer efficiency. Our approach incorporates a two-stage solution: an
offline stage that reorganizes neuron placement based on co-activation
patterns, and an online stage that employs tailored data access and caching
strategies to align well with hardware characteristics. Evaluations conducted
on a variety of smartphones and LLMs demonstrate that Ripple achieves up to
5.93x improvements in I/O latency compared to the state-of-the-art. As the
first solution to optimize storage placement under sparsity, Ripple explores a
new optimization space at the intersection of sparsity-driven algorithm and
storage-level system co-design in LLM inference.

摘要：大型語言模型 (LLM) 在各個領域都取得了顯著的成功，但由於其廣泛的計算和記憶體需求，將它們部署在行動裝置上仍然是一項艱鉅的挑戰。雖然已經開發出輕量級 LLM 以符合行動環境，但它們會造成模型精確度下降。相反，基於稀疏性的技術透過選擇性地僅將相關神經元傳輸到 DRAM，同時將完整模型保留在外接儲存裝置（例如快閃記憶體）中，以將 DRAM 使用量降至最低。然而，此類方法受到大量 I/O 作業的嚴重限制，特別是在 IOPS 限制嚴重的智慧型手機上。
  在本文中，我們提出 Ripple，這是一種新穎的方法，透過最佳化快閃記憶體中的神經元配置來加速智慧型手機上的 LLM 推論。Ripple 利用神經元共同啟動的概念，其中經常一起啟動的神經元會連結在一起，以利於連續讀取存取並最佳化資料傳輸效率。我們的做法包含一個兩階段解決方案：一個根據共同啟動模式重新組織神經元配置的離線階段，以及一個採用客製化資料存取和快取策略以與硬體特性良好對齊的線上階段。在各種智慧型手機和 LLM 上進行的評估顯示，與現有技術相比，Ripple 在 I/O 延遲方面獲得了高達 5.93 倍的改善。作為在稀疏性下最佳化儲存配置的第一個解決方案，Ripple 在稀疏性驅動演算法和儲存層級系統共同設計的 LLM 推論交集中探索了一個新的最佳化空間。

##### **Autonomous Building Cyber-Physical Systems Using Decentralized Autonomous Organizations, Digital Twins, and Large Language Model**
2410.19262v1 by Reachsak Ly, Alireza Shojaei

Current autonomous building research primarily focuses on energy efficiency
and automation. While traditional artificial intelligence has advanced
autonomous building research, it often relies on predefined rules and struggles
to adapt to complex, evolving building operations. Moreover, the centralized
organizational structures of facilities management hinder transparency in
decision-making, limiting true building autonomy. Research on decentralized
governance and adaptive building infrastructure, which could overcome these
challenges, remains relatively unexplored. This paper addresses these
limitations by introducing a novel Decentralized Autonomous Building
Cyber-Physical System framework that integrates Decentralized Autonomous
Organizations, Large Language Models, and digital twins to create a smart,
self-managed, operational, and financially autonomous building infrastructure.
This study develops a full-stack decentralized application to facilitate
decentralized governance of building infrastructure. An LLM-based artificial
intelligence assistant is developed to provide intuitive human-building
interaction for blockchain and building operation management-related tasks and
enable autonomous building operation. Six real-world scenarios were tested to
evaluate the autonomous building system's workability, including building
revenue and expense management, AI-assisted facility control, and autonomous
adjustment of building systems. Results indicate that the prototype
successfully executes these operations, confirming the framework's suitability
for developing building infrastructure with decentralized governance and
autonomous operation.

摘要：目前的自主建築研究主要集中在能源效率和自動化。雖然傳統的人工智慧已經推進了自主建築研究，但它通常依賴於預定義的規則，並且難以適應複雜、不斷變化的建築運作。此外，設施管理的集中式組織結構阻礙了決策的透明度，限制了真正的建築自主性。對於分散式治理和適應性建築基礎設施的研究，可以克服這些挑戰，但仍相對未被探索。本文通過引入一個新穎的分散式自主建築網路物理系統框架來解決這些限制，該框架整合了分散式自主組織、大型語言模型和數位雙胞胎，以建立一個智慧、自我管理、運作和財務自主的建築基礎設施。本研究開發了一個全堆疊式分散式應用程式，以利於建築基礎設施的分散式治理。開發了一個基於 LLM 的人工智慧助理，以提供直觀的人機互動，用於區塊鏈和建築運作管理相關任務，並實現自主建築運作。測試了六個真實世界的場景，以評估自主建築系統的可行性，包括建築收入和支出管理、AI 輔助設施控制和建築系統的自主調整。結果表明，原型成功執行這些操作，確認了該框架適用於開發具有分散式治理和自主運作的建築基礎設施。

##### **Not All Heads Matter: A Head-Level KV Cache Compression Method with Integrated Retrieval and Reasoning**
2410.19258v1 by Yu Fu, Zefan Cai, Abedelkadir Asi, Wayne Xiong, Yue Dong, Wen Xiao

Key-Value (KV) caching is a common technique to enhance the computational
efficiency of Large Language Models (LLMs), but its memory overhead grows
rapidly with input length. Prior work has shown that not all tokens are equally
important for text generation, proposing layer-level KV cache compression to
selectively retain key information. Recognizing the distinct roles of attention
heads in generation, we propose HeadKV, a head-level KV cache compression
method, and HeadKV-R2, which leverages a novel contextual reasoning ability
estimation for compression. Our approach operates at the level of individual
heads, estimating their importance for contextual QA tasks that require both
retrieval and reasoning capabilities. Extensive experiments across diverse
benchmarks (LongBench, LooGLE), model architectures (e.g., Llama-3-8B-Instruct,
Mistral-7B-Instruct), and long-context abilities tests demonstrate that our
head-level KV cache compression significantly outperforms strong baselines,
particularly in low-resource settings (KV size = 64 & 128). Notably, our method
retains just 1.5% of the KV cache while achieving 97% of the performance of the
full KV cache on the contextual question answering benchmark.

摘要：關鍵值 (KV) 快取是一種增強大型語言模型 (LLM) 計算效率的常見技術，但其記憶體開銷會隨著輸入長度快速增加。先前的研究顯示，並非所有權標對於文本產生同等重要，建議採用層級 KV 快取壓縮來選擇性保留關鍵資訊。我們了解注意力頭在產生中的不同角色，因此提出 HeadKV，一種頭級 KV 快取壓縮方法，以及 HeadKV-R2，它利用一種新穎的脈絡推理能力估計進行壓縮。我們的做法在個別頭的層級運作，估計它們對於需要擷取和推理能力的脈絡 QA 任務的重要性。在各種基準測試（LongBench、LooGLE）、模型架構（例如 Llama-3-8B-Instruct、Mistral-7B-Instruct）和長脈絡能力測試中進行的廣泛實驗證明，我們的頭級 KV 快取壓縮顯著優於強大的基線，特別是在低資源設定（KV 大小 = 64 和 128）中。值得注意的是，我們的做法僅保留 1.5% 的 KV 快取，同時在脈絡問題回答基準測試中達到完整 KV 快取效能的 97%。

##### **The Reopening of Pandora's Box: Analyzing the Role of LLMs in the Evolving Battle Against AI-Generated Fake News**
2410.19250v1 by Xinyu Wang, Wenbo Zhang, Sai Koneru, Hangzhi Guo, Bonam Mingole, S. Shyam Sundar, Sarah Rajtmajer, Amulya Yadav

With the rise of AI-generated content spewed at scale from large language
models (LLMs), genuine concerns about the spread of fake news have intensified.
The perceived ability of LLMs to produce convincing fake news at scale poses
new challenges for both human and automated fake news detection systems. To
address this gap, this work presents the findings from a university-level
competition which aimed to explore how LLMs can be used by humans to create
fake news, and to assess the ability of human annotators and AI models to
detect it. A total of 110 participants used LLMs to create 252 unique fake news
stories, and 84 annotators participated in the detection tasks. Our findings
indicate that LLMs are ~68% more effective at detecting real news than humans.
However, for fake news detection, the performance of LLMs and humans remains
comparable (~60% accuracy). Additionally, we examine the impact of visual
elements (e.g., pictures) in news on the accuracy of detecting fake news
stories. Finally, we also examine various strategies used by fake news creators
to enhance the credibility of their AI-generated content. This work highlights
the increasing complexity of detecting AI-generated fake news, particularly in
collaborative human-AI settings.

摘要：隨著大型語言模型 (LLM) 大規模噴發 AI 生成的內容，人們對假新聞傳播的真正擔憂也加劇了。
LLM 被認為具有大規模製作令人信服的假新聞的能力，這對人類和自動化假新聞偵測系統都帶來了新的挑戰。
為了解決這個差距，這項工作展示了大學層級競賽的結果，該競賽旨在探討人類如何使用 LLM 來製作假新聞，並評估人類註解者和 AI 模型偵測假新聞的能力。
總共有 110 位參與者使用 LLM 製作了 252 則獨特的假新聞故事，84 位註解者參與了偵測任務。
我們的研究結果表明，LLM 在偵測真實新聞方面的效果比人類高出約 68%。
然而，在假新聞偵測方面，LLM 和人類的表現仍然相當（約 60% 的準確度）。
此外，我們探討了新聞中的視覺元素（例如圖片）對偵測假新聞故事準確度的影響。
最後，我們也探討了假新聞創作者用來提升其 AI 生成的內容可信度的各種策略。
這項工作突顯了偵測 AI 生成的假新聞的複雜性日益增加，尤其是在人類與 AI 合作的環境中。

##### **Designing LLM-Agents with Personalities: A Psychometric Approach**
2410.19238v1 by Muhua Huang, Xijuan Zhang, Christopher Soto, James Evans

This research introduces a novel methodology for assigning quantifiable,
controllable and psychometrically validated personalities to Large Language
Models-Based Agents (Agents) using the Big Five personality framework. It seeks
to overcome the constraints of human subject studies, proposing Agents as an
accessible tool for social science inquiry. Through a series of four studies,
this research demonstrates the feasibility of assigning psychometrically valid
personality traits to Agents, enabling them to replicate complex human-like
behaviors. The first study establishes an understanding of personality
constructs and personality tests within the semantic space of an LLM. Two
subsequent studies -- using empirical and simulated data -- illustrate the
process of creating Agents and validate the results by showing strong
correspondence between human and Agent answers to personality tests. The final
study further corroborates this correspondence by using Agents to replicate
known human correlations between personality traits and decision-making
behaviors in scenarios involving risk-taking and ethical dilemmas, thereby
validating the effectiveness of the psychometric approach to design Agents and
its applicability to social and behavioral research.

摘要：本研究為大型語言模型代理（代理）引入了一種創新的方法，用於分配可量化、可控且經過心理測量驗證的人格，並使用五大性格架構。它旨在克服人類受試者研究的限制，提出代理作為社會科學探究的可及工具。通過一系列四項研究，本研究展示了將心理測量學上有效的人格特質分配給代理的可行性，使他們能夠複製複雜的人類行為。第一項研究建立了對 LLM 語義空間內人格結構和人格測試的理解。兩項後續研究——使用經驗和模擬數據——說明了創建代理的過程，並通過展示人類和代理對人格測試的答案之間的強烈對應關係來驗證結果。最後一項研究通過使用代理複製人格特質與風險承擔和道德困境情境中的決策行為之間已知的人類相關性，進一步證實了這種對應關係，從而驗證了心理測量方法在設計代理方面的有效性及其對社會和行為研究的適用性。

##### **Learning Diffusion Policies from Demonstrations For Compliant Contact-rich Manipulation**
2410.19235v1 by Malek Aburub, Cristian C. Beltran-Hernandez, Tatsuya Kamijo, Masashi Hamaya

Robots hold great promise for performing repetitive or hazardous tasks, but
achieving human-like dexterity, especially in contact-rich and dynamic
environments, remains challenging. Rigid robots, which rely on position or
velocity control, often struggle with maintaining stable contact and applying
consistent force in force-intensive tasks. Learning from Demonstration has
emerged as a solution, but tasks requiring intricate maneuvers, such as powder
grinding, present unique difficulties. This paper introduces Diffusion Policies
For Compliant Manipulation (DIPCOM), a novel diffusion-based framework designed
for compliant control tasks. By leveraging generative diffusion models, we
develop a policy that predicts Cartesian end-effector poses and adjusts arm
stiffness to maintain the necessary force. Our approach enhances force control
through multimodal distribution modeling, improves the integration of diffusion
policies in compliance control, and extends our previous work by demonstrating
its effectiveness in real-world tasks. We present a detailed comparison between
our framework and existing methods, highlighting the advantages and best
practices for deploying diffusion-based compliance control.

摘要：機器人極具執行重複性或危險性任務的潛力，但要實現類似人類的靈巧度，特別是在接觸豐富且動態的環境中，仍然具有挑戰性。依賴位置或速度控制的剛性機器人通常難以維持穩定的接觸並在需要力量的任務中施加一致的力量。從示範中學習已成為一種解決方案，但需要複雜操作的任務，例如粉末研磨，會產生獨特的困難。本文介紹了柔性操作的擴散策略 (DIPCOM)，這是一種新穎的基於擴散的框架，專為柔性控制任務而設計。通過利用生成擴散模型，我們制定了一項策略，該策略預測笛卡爾末端執行器的姿勢並調整手臂剛度以維持必要的力。我們的做法通過多模態分佈建模增強了力控制，改進了擴散策略在柔順控制中的整合，並通過展示其在現實世界任務中的有效性來擴展我們之前的工作。我們對我們的框架和現有方法進行了詳細比較，重點介紹了部署基於擴散的柔順控制的優點和最佳實務。

##### **Developing a Tutoring Dialog Dataset to Optimize LLMs for Educational Use**
2410.19231v1 by Menna Fateen, Tsunenori Mine

Recent advances in large language models (LLMs) have shown promise for
scalable educational applications, but their use in dialog-based tutoring
systems remains challenging due to the need for effective pedagogical
strategies and the high costs associated with expert-curated datasets. Our
study explores the use of smaller, more affordable LLMs for one-on-one tutoring
in the context of solving reading comprehension problems. We developed a
synthetic tutoring dialog dataset, evaluated by human teachers, and fine-tuned
a smaller LLM using this dataset. Furthermore, we conducted an interactive
experiment comparing the performance of the fine-tuned model with a larger
model in real-world tutoring scenarios. Our results show that the fine-tuned
model performs on par with the larger model but at a lower cost, demonstrating
a viable, cost-effective approach for implementing LLM-based tutoring systems
in educational settings.

摘要：大型語言模型 (LLM) 的最新進展已展現出可擴充教育應用的前景，但由於需要有效的教學策略以及與專家策展的資料集相關的高成本，它們在對話式輔導系統中的使用仍然具有挑戰性。我們的研究探討了在解決閱讀理解問題的背景下，使用較小、更經濟實惠的 LLM 進行一對一輔導。我們開發了一個由人類教師評估的合成輔導對話資料集，並使用此資料集微調了一個較小的 LLM。此外，我們進行了一項互動實驗，比較了微調模型與較大模型在真實輔導場景中的表現。我們的結果表明，微調模型的表現與較大模型相當，但成本較低，這證明了一種可行的、具有成本效益的方法，可用於在教育環境中實施基於 LLM 的輔導系統。

##### **Humanizing the Machine: Proxy Attacks to Mislead LLM Detectors**
2410.19230v1 by Tianchun Wang, Yuanzhou Chen, Zichuan Liu, Zhanwen Chen, Haifeng Chen, Xiang Zhang, Wei Cheng

The advent of large language models (LLMs) has revolutionized the field of
text generation, producing outputs that closely mimic human-like writing.
Although academic and industrial institutions have developed detectors to
prevent the malicious usage of LLM-generated texts, other research has doubt
about the robustness of these systems. To stress test these detectors, we
introduce a proxy-attack strategy that effortlessly compromises LLMs, causing
them to produce outputs that align with human-written text and mislead
detection systems. Our method attacks the source model by leveraging a
reinforcement learning (RL) fine-tuned humanized small language model (SLM) in
the decoding phase. Through an in-depth analysis, we demonstrate that our
attack strategy is capable of generating responses that are indistinguishable
to detectors, preventing them from differentiating between machine-generated
and human-written text. We conduct systematic evaluations on extensive datasets
using proxy-attacked open-source models, including Llama2-13B, Llama3-70B, and
Mixtral-8*7B in both white- and black-box settings. Our findings show that the
proxy-attack strategy effectively deceives the leading detectors, resulting in
an average AUROC drop of 70.4% across multiple datasets, with a maximum drop of
90.3% on a single dataset. Furthermore, in cross-discipline scenarios, our
strategy also bypasses these detectors, leading to a significant relative
decrease of up to 90.9%, while in cross-language scenario, the drop reaches
91.3%. Despite our proxy-attack strategy successfully bypassing the detectors
with such significant relative drops, we find that the generation quality of
the attacked models remains preserved, even within a modest utility budget,
when compared to the text produced by the original, unattacked source model.

摘要：大型語言模型 (LLM) 的出現徹底改變了文本生成領域，產生的輸出與人類寫作非常接近。儘管學術和產業機構已開發出偵測器，以防止惡意使用 LLM 生成的文本，但其他研究對這些系統的健全性表示懷疑。為了對這些偵測器進行壓力測試，我們引入了代理攻擊策略，該策略毫不費力地危害 LLM，導致它們產生的輸出與人類撰寫的文本一致，並誤導偵測系統。我們的攻擊方法透過在解碼階段利用強化學習 (RL) 微調的人性化小型語言模型 (SLM) 來攻擊原始模型。透過深入分析，我們證明我們的攻擊策略能夠產生與偵測器無法區分的回應，使它們無法區分機器產生的文本和人類撰寫的文本。我們在廣泛的資料集上使用代理攻擊的開源模型（包括 Llama2-13B、Llama3-70B 和 Mixtral-8*7B）進行系統評估，包括白盒和黑盒設定。我們的研究結果顯示，代理攻擊策略有效地欺騙了領先的偵測器，導致多個資料集的平均 AUROC 下降 70.4%，在單一資料集上的最大下降為 90.3%。此外，在跨學科場景中，我們的策略也繞過了這些偵測器，導致顯著的相對下降，最高達 90.9%，而在跨語言場景中，下降幅度達到 91.3%。儘管我們的代理攻擊策略成功地繞過了偵測器，並產生如此顯著的相對下降，但我們發現，與原始未攻擊的原始模型產生的文本相比，即使在適度的實用預算內，被攻擊模型的生成品質仍然保持不變。

##### **Hierarchical Mixture of Experts: Generalizable Learning for High-Level Synthesis**
2410.19225v1 by Weikai Li, Ding Wang, Zijian Ding, Atefeh Sohrabizadeh, Zongyue Qin, Jason Cong, Yizhou Sun

High-level synthesis (HLS) is a widely used tool in designing Field
Programmable Gate Array (FPGA). HLS enables FPGA design with software
programming languages by compiling the source code into an FPGA circuit. The
source code includes a program (called ``kernel'') and several pragmas that
instruct hardware synthesis, such as parallelization, pipeline, etc. While it
is relatively easy for software developers to design the program, it heavily
relies on hardware knowledge to design the pragmas, posing a big challenge for
software developers. Recently, different machine learning algorithms, such as
GNNs, have been proposed to automate the pragma design via performance
prediction. However, when applying the trained model on new kernels, the
significant domain shift often leads to unsatisfactory performance. We propose
a more domain-generalizable model structure: a two-level hierarchical Mixture
of Experts (MoE), that can be flexibly adapted to any GNN model. Different
expert networks can learn to deal with different regions in the representation
space, and they can utilize similar patterns between the old kernels and new
kernels. In the low-level MoE, we apply MoE on three natural granularities of a
program: node, basic block, and graph. The high-level MoE learns to aggregate
the three granularities for the final decision. To stably train the
hierarchical MoE, we further propose a two-stage training method. Extensive
experiments verify the effectiveness of the hierarchical MoE.

摘要：高階綜合（HLS）是設計現場可編程閘陣列（FPGA）中廣泛使用的工具。HLS 透過將原始碼編譯成 FPGA 電路，使用軟體程式語言進行 FPGA 設計。原始碼包含一個程式（稱為「核心」）和多個指導硬體綜合的指示，例如平行化、管線等。雖然軟體開發人員設計程式相對容易，但它極度依賴硬體知識來設計指示，這對軟體開發人員來說是一大挑戰。最近，不同的機器學習演算法，例如 GNN，已被提出用於透過效能預測自動進行指示設計。然而，在新的核心上應用訓練好的模型時，顯著的領域轉移通常會導致效能不佳。我們提出一個更具領域通用性的模型結構：一個二階層混合專家（MoE），它可以靈活地適應任何 GNN 模型。不同的專家網路可以學習處理表示空間中的不同區域，並且它們可以利用舊核心和新核心之間的相似模式。在低階 MoE 中，我們對程式的三個自然粒度應用 MoE：節點、基本區塊和圖。高階 MoE 學習彙總這三個粒度以做出最終決策。為了穩定訓練階層式 MoE，我們進一步提出一個二階段訓練方法。廣泛的實驗驗證了階層式 MoE 的有效性。

##### **Integrating Large Language Models with Internet of Things Applications**
2410.19223v1 by Mingyu Zong, Arvin Hekmati, Michael Guastalla, Yiyi Li, Bhaskar Krishnamachari

This paper identifies and analyzes applications in which Large Language
Models (LLMs) can make Internet of Things (IoT) networks more intelligent and
responsive through three case studies from critical topics: DDoS attack
detection, macroprogramming over IoT systems, and sensor data processing. Our
results reveal that the GPT model under few-shot learning achieves 87.6%
detection accuracy, whereas the fine-tuned GPT increases the value to 94.9%.
Given a macroprogramming framework, the GPT model is capable of writing scripts
using high-level functions from the framework to handle possible incidents.
Moreover, the GPT model shows efficacy in processing a vast amount of sensor
data by offering fast and high-quality responses, which comprise expected
results and summarized insights. Overall, the model demonstrates its potential
to power a natural language interface. We hope that researchers will find these
case studies inspiring to develop further.

摘要：本文透過三個關於關鍵主題的案例研究，找出並分析大型語言模型 (LLM) 能讓物聯網 (IoT) 網路更智慧且更具反應力的應用，這三個案例研究分別是：DDoS 攻擊偵測、IoT 系統巨程式設計，以及感測器資料處理。我們的結果顯示，在少次學習的情況下，GPT 模型能達到 87.6% 的偵測準確度，而微調後的 GPT 則將此值提升至 94.9%。在給定巨程式設計架構的情況下，GPT 模型能夠使用該架構的高階函式撰寫腳本，以處理可能的事件。此外，GPT 模型在處理大量感測器資料時展現出功效，能提供快速且高品質的回應，其中包含預期的結果和摘要見解。總體而言，該模型展示了其驅動自然語言介面的潛力。我們希望研究人員會發現這些案例研究具有啟發性，能進一步開發。

##### **Can Stories Help LLMs Reason? Curating Information Space Through Narrative**
2410.19221v1 by Vahid Sadiri Javadi, Johanne R. Trippas, Yash Kumar Lal, Lucie Flek

Narratives are widely recognized as a powerful tool for structuring
information and facilitating comprehension of complex ideas in various domains
such as science communication. This paper investigates whether incorporating
narrative elements can assist Large Language Models (LLMs) in solving complex
problems more effectively. We propose a novel approach, Story of Thought (SoT),
integrating narrative structures into prompting techniques for problem-solving.
This approach involves constructing narratives around problem statements and
creating a framework to identify and organize relevant information. Our
experiments show that using various LLMs with SoT consistently surpasses using
them with other techniques on physics, chemistry, math, and biology questions
in both the GPQA and JEEBench datasets. The narrative-based information
curation process in SoT enhances problem comprehension by contextualizing
critical in-domain information and highlighting causal relationships within the
problem space.

摘要：敘事被廣泛認為是建構資訊和促進理解各領域複雜概念的有力工具，例如科學傳播。本文探討結合敘事元素是否能協助大型語言模型 (LLM) 更有效地解決複雜問題。我們提出了一種新穎的方法，即思考的故事 (SoT)，將敘事結構融入問題解決的提示技巧中。此方法涉及建構圍繞問題陳述的敘事，並建立一個架構來識別和組織相關資訊。我們的實驗顯示，在物理、化學、數學和生物學問題上，使用各種 LLM 搭配 SoT 持續優於使用其他技巧，無論是在 GPQA 或 JEEBench 資料集上。SoT 中基於敘事的資訊策展過程透過將關鍵領域內資訊脈絡化，並強調問題空間內的因果關係，增強了問題理解。

##### **Robot Behavior Personalization from Sparse User Feedback**
2410.19219v1 by Maithili Patel, Sonia Chernova

As service robots become more general-purpose, they will need to adapt to
their users' preferences over a large set of all possible tasks that they can
perform. This includes preferences regarding which actions the users prefer to
delegate to robots as opposed to doing themselves. Existing personalization
approaches require task-specific data for each user. To handle diversity across
all household tasks and users, and nuances in user preferences across tasks, we
propose to learn a task adaptation function independently, which can be used in
tandem with any universal robot policy to customize robot behavior. We create
Task Adaptation using Abstract Concepts (TAACo) framework. TAACo can learn to
predict the user's preferred manner of assistance with any given task, by
mediating reasoning through a representation composed of abstract concepts
built based on user feedback. TAACo can generalize to an open set of household
tasks from small amount of user feedback and explain its inferences through
intuitive concepts. We evaluate our model on a dataset we collected of 5
people's preferences, and show that TAACo outperforms GPT-4 by 16% and a
rule-based system by 54%, on prediction accuracy, with 40 samples of user
feedback.

摘要：隨著服務機器人變得更加通用，它們需要適應用戶在所有可能執行任務的大型集合中的偏好。這包括關於用戶偏好委派給機器人或自己執行哪些動作的偏好。現有的個性化方法需要每個用戶的特定任務數據。為了處理所有家務和用戶的多樣性，以及用戶在任務中的偏好差異，我們建議獨立學習任務適應功能，該功能可以與任何通用機器人策略結合使用來自定義機器人行為。我們使用抽象概念（TAACo）框架創建任務適應。TAACo 可以通過調解通過基於用戶反饋構建的抽象概念組成的表示來推理，從而學會預測用戶在任何給定任務中的首選協助方式。TAACo 可以從少量用戶反饋中概化到一系列開放的家務任務，並通過直觀的概念解釋其推論。我們在我們收集的 5 人偏好數據集上評估我們的模型，並表明 TAACo 在預測準確率上比 GPT-4 高 16%，比基於規則的系統高 54%，有 40 個用戶反饋樣本。

##### **No Free Lunch: Fundamental Limits of Learning Non-Hallucinating Generative Models**
2410.19217v1 by Changlong Wu, Ananth Grama, Wojciech Szpankowski

Generative models have shown impressive capabilities in synthesizing
high-quality outputs across various domains. However, a persistent challenge is
the occurrence of "hallucinations", where the model produces outputs that are
plausible but invalid. While empirical strategies have been explored to
mitigate this issue, a rigorous theoretical understanding remains elusive. In
this paper, we develop a theoretical framework to analyze the learnability of
non-hallucinating generative models from a learning-theoretic perspective. Our
results reveal that non-hallucinating learning is statistically impossible when
relying solely on the training dataset, even for a hypothesis class of size two
and when the entire training set is truthful. To overcome these limitations, we
show that incorporating inductive biases aligned with the actual facts into the
learning process is essential. We provide a systematic approach to achieve this
by restricting the facts set to a concept class of finite VC-dimension and
demonstrate its effectiveness under various learning paradigms. Although our
findings are primarily conceptual, they represent a first step towards a
principled approach to addressing hallucinations in learning generative models.

摘要：生成模型在各種領域中合成高品質輸出已展現出令人印象深刻的能力。然而，一個持續存在的挑戰是「幻覺」的發生，其中模型產生的輸出合理但無效。雖然已探討經驗策略來減輕此問題，但嚴謹的理論理解仍然難以捉摸。在本文中，我們開發了一個理論框架，從學習理論的角度分析非幻覺生成模型的可學習性。我們的結果表明，僅依賴訓練資料集時，非幻覺學習在統計上是不可能的，即使對於大小為 2 的假設類別，且整個訓練集都是真實的。為了克服這些限制，我們表明將與實際事實一致的歸納偏差納入學習過程中至關重要。我們提供了一種系統方法來實現此目的，方法是將事實集限制為有限 VC 維度的概念類別，並證明其在各種學習範例下的有效性。儘管我們的發現主要是概念性的，但它們代表了朝著解決生成模型學習中的幻覺的原則性方法邁出的第一步。

##### **Inference time LLM alignment in single and multidomain preference spectrum**
2410.19206v1 by Sadat Shahriar, Zheng Qi, Nikolaos Pappas, Srikanth Doss, Monica Sunkara, Kishaloy Halder, Manuel Mager, Yassine Benajiba

Aligning Large Language Models (LLM) to address subjectivity and nuanced
preference levels requires adequate flexibility and control, which can be a
resource-intensive and time-consuming procedure. Existing training-time
alignment methods require full re-training when a change is needed and
inference-time ones typically require access to the reward model at each
inference step. To address these limitations, we introduce inference-time model
alignment method that learns encoded representations of preference dimensions,
called \textit{Alignment Vectors} (AV). These representations are computed by
subtraction of the base model from the aligned model as in model editing
enabling dynamically adjusting the model behavior during inference through
simple linear operations. Even though the preference dimensions can span
various granularity levels, here we focus on three gradual response levels
across three specialized domains: medical, legal, and financial, exemplifying
its practical potential. This new alignment paradigm introduces adjustable
preference knobs during inference, allowing users to tailor their LLM outputs
while reducing the inference cost by half compared to the prompt engineering
approach. Additionally, we find that AVs are transferable across different
fine-tuning stages of the same model, demonstrating their flexibility. AVs also
facilitate multidomain, diverse preference alignment, making the process 12x
faster than the retraining approach.

摘要：大型語言模型 (LLM) 對齊以解決主觀性和細微的偏好層級需要足夠的靈活性與控制，這可能是一個耗費資源且耗時的程序。現有的訓練時間對齊方法需要在需要變更時完全重新訓練，而推論時間方法通常需要在每個推論步驟存取獎勵模型。為了解決這些限制，我們引入了推論時間模型對齊方法，它學習偏好維度的編碼表示，稱為「對齊向量」(AV)。這些表示是透過從對齊模型中減去基本模型來計算的，就像在模型編輯中一樣，能夠在推論期間透過簡單的線性運算動態調整模型行為。儘管偏好維度可以跨越各種粒度層級，但我們在此專注於三個專業領域（醫療、法律和金融）中的三個漸進回應層級，說明其實際潛力。這種新的對齊範例在推論期間引入了可調整的偏好旋鈕，使用戶能夠調整其 LLM 輸出，同時將推論成本與提示工程方法相比減少一半。此外，我們發現 AV 可以轉移到同一個模型的不同微調階段，證明了它們的靈活性。AV 也促進了多領域、多樣化的偏好對齊，使這個過程比重新訓練方法快了 12 倍。

##### **An Inverse Modeling Constrained Multi-Objective Evolutionary Algorithm Based on Decomposition**
2410.19203v1 by Lucas R. C. Farias, Aluizio F. R. Araújo

This paper introduces the inverse modeling constrained multi-objective
evolutionary algorithm based on decomposition (IM-C-MOEA/D) for addressing
constrained real-world optimization problems. Our research builds upon the
advancements made in evolutionary computing-based inverse modeling, and it
strategically bridges the gaps in applying inverse models based on
decomposition to problem domains with constraints. The proposed approach is
experimentally evaluated on diverse real-world problems (RWMOP1-35), showing
superior performance to state-of-the-art constrained multi-objective
evolutionary algorithms (CMOEAs). The experimental results highlight the
robustness of the algorithm and its applicability in real-world constrained
optimization scenarios.

摘要：本文介紹了基於分解的逆向建模約束多目標演化演算法（IM-C-MOEA/D），用於解決受約束的真實世界最佳化問題。我們的研究建立在基於演化運算的逆向建模所做的進展之上，並且策略性地彌補了將基於分解的逆向模型應用於具有約束的題目領域的差距。所提出的方法在不同的真實世界問題（RWMOP1-35）上經過實驗評估，顯示出優於最先進的約束多目標演化演算法（CMOEAs）。實驗結果突出了演算法的穩健性及其在真實世界約束最佳化場景中的適用性。

##### **Making Social Platforms Accessible: Emotion-Aware Speech Generation with Integrated Text Analysis**
2410.19199v1 by Suparna De, Ionut Bostan, Nishanth Sastry

Recent studies have outlined the accessibility challenges faced by blind or
visually impaired, and less-literate people, in interacting with social
networks, in-spite of facilitating technologies such as monotone text-to-speech
(TTS) screen readers and audio narration of visual elements such as emojis.
Emotional speech generation traditionally relies on human input of the expected
emotion together with the text to synthesise, with additional challenges around
data simplification (causing information loss) and duration inaccuracy, leading
to lack of expressive emotional rendering. In real-life communications, the
duration of phonemes can vary since the same sentence might be spoken in a
variety of ways depending on the speakers' emotional states or accents
(referred to as the one-to-many problem of text to speech generation). As a
result, an advanced voice synthesis system is required to account for this
unpredictability. We propose an end-to-end context-aware Text-to-Speech (TTS)
synthesis system that derives the conveyed emotion from text input and
synthesises audio that focuses on emotions and speaker features for natural and
expressive speech, integrating advanced natural language processing (NLP) and
speech synthesis techniques for real-time applications. Our system also
showcases competitive inference time performance when benchmarked against the
state-of-the-art TTS models, making it suitable for real-time accessibility
applications.

摘要：近期的研究概述了盲人或視障人士以及識字能力較差的人在使用社群網路時所面臨的無障礙挑戰，儘管有單調文字轉語音 (TTS) 螢幕朗讀程式和視覺元素（例如表情符號）的語音旁白等輔助技術。情緒化語音生成傳統上依賴人類輸入預期的情緒以及要合成的文字，並在資料簡化（導致資訊遺失）和持續時間不準確方面面臨額外挑戰，導致缺乏表現力豐富的情緒渲染。在現實生活中的溝通中，音素的持續時間可能會有所不同，因為相同的句子可能會以各種方式說出，具體取決於說話者的情緒狀態或口音（稱為文字轉語音生成的一對多問題）。因此，需要一個進階的語音合成系統來應對這種不可預測性。我們提出了一個端到端的語境感知文字轉語音 (TTS) 合成系統，它從文字輸入中推導出傳達的情緒，並合成以情緒和說話者特徵為重點的音訊，以實現自然且富有表現力的語音，整合進階的自然語言處理 (NLP) 和語音合成技術，以用於即時應用程式。我們的系統在與最先進的 TTS 模型進行基準測試時，也展示了具有競爭力的推論時間效能，使其適用於即時無障礙應用程式。

##### **Label Set Optimization via Activation Distribution Kurtosis for Zero-shot Classification with Generative Models**
2410.19195v1 by Yue Li, Zhixue Zhao, Carolina Scarton

In-context learning (ICL) performance is known to be sensitive to the prompt
design, yet the impact of class label options in zero-shot classification has
been largely overlooked. This study presents the first comprehensive empirical
study investigating how label option (e.g., lexical choice, order, and
elaboration) influences zero-shot ICL classification performance. Our findings
reveal that lexical choices for label names (e.g., agree vs.support in stance
classification) play an important role, with effects also linked to label
orders. An analysis of the model internal states further shows that optimal
label names tend to activate fewer outlier neurons in the feed forward network.
Based on this observation, we propose Label set Optimization via Activation
Distribution kurtosiS (LOADS), a post-hoc approach requiring no gradient
propagation. LOADS not only demonstrates effectiveness with only 100 unlabelled
samples across different model types and sizes, but also shows cross-lingual
transferability.

摘要：<paragraph>已知语境学习 (ICL) 效能对于提示设计很敏感，但类别标签选项在零次分类中的影响却在很大程度上被忽视了。本研究提出了第一个全面的经验研究，调查标签选项（例如词汇选择、顺序和详细说明）如何影响零次 ICL 分类效能。我们的研究结果表明，标签名称的词汇选择（例如，立场分类中的同意与支持）起着重要作用，其影响还与标签顺序相关。对模型内部状态的分析进一步表明，最佳标签名称倾向于在前馈网络中激活较少的离群神经元。基于这一观察，我们提出了通过激活分布峰度 (LOADS) 进行标签集优化，这是一种无需梯度传播的后验方法。LOADS 不仅在不同模型类型和大小中仅使用 100 个未标记样本就证明了其有效性，还显示了跨语言的可传递性。</paragraph>

##### **Enriching GNNs with Text Contextual Representations for Detecting Disinformation Campaigns on Social Media**
2410.19193v1 by Bruno Croso Cunha da Silva, Thomas Palmeira Ferraz, Roseli De Deus Lopes

Disinformation on social media poses both societal and technical challenges.
While previous studies have integrated textual information into propagation
networks, they have yet to fully leverage the advancements in Transformer-based
language models for high-quality contextual text representations. This work
investigates the impact of incorporating textual features into Graph Neural
Networks (GNNs) for fake news detection. Our experiments demonstrate that
contextual representations improve performance by 9.3% in Macro F1 over static
ones and 33.8% over GNNs without textual features. However, noisy data
augmentation degrades performance and increases instability. We expect our
methodology to open avenues for further research, and all code is made publicly
available.

摘要：社群媒體上的錯誤訊息造成社會和技術層面的挑戰。
儘管過往的研究已將文字資訊整合到傳播網路中，但尚未充分利用基於 Transformer 的語言模型在高品質脈絡文字表徵上的進展。這項研究探討將文字特徵納入圖形神經網路 (GNN) 中對於假新聞偵測的影響。我們的實驗結果顯示，脈絡表徵將巨觀 F1 的效能提升了 9.3%，優於靜態表徵，並比沒有文字特徵的 GNN 提升了 33.8%。然而，有雜訊的資料擴充會降低效能並增加不穩定性。我們預期我們的研究方法將開啟進一步研究的途徑，所有程式碼皆公開提供。

##### **Tailored-LLaMA: Optimizing Few-Shot Learning in Pruned LLaMA Models with Task-Specific Prompts**
2410.19185v1 by Danyal Aftab, Steven Davy

Large language models demonstrate impressive proficiency in language
understanding and generation. Nonetheless, training these models from scratch,
even the least complex billion-parameter variant demands significant
computational resources rendering it economically impractical for many
organizations. With large language models functioning as general-purpose task
solvers, this paper investigates their task-specific fine-tuning. We employ
task-specific datasets and prompts to fine-tune two pruned LLaMA models having
5 billion and 4 billion parameters. This process utilizes the pre-trained
weights and focuses on a subset of weights using the LoRA method. One challenge
in fine-tuning the LLaMA model is crafting a precise prompt tailored to the
specific task. To address this, we propose a novel approach to fine-tune the
LLaMA model under two primary constraints: task specificity and prompt
effectiveness. Our approach, Tailored LLaMA initially employs structural
pruning to reduce the model sizes from 7B to 5B and 4B parameters.
Subsequently, it applies a carefully designed prompt specific to the task and
utilizes the LoRA method to accelerate the fine-tuning process. Moreover,
fine-tuning a model pruned by 50\% for less than one hour restores the mean
accuracy of classification tasks to 95.68\% at a 20\% compression ratio and to
86.54\% at a 50\% compression ratio through few-shot learning with 50 shots.
Our validation of Tailored LLaMA on these two pruned variants demonstrates that
even when compressed to 50\%, the models maintain over 65\% of the baseline
model accuracy in few-shot classification and generation tasks. These findings
highlight the efficacy of our tailored approach in maintaining high performance
with significantly reduced model sizes.

摘要：大型語言模型在語言理解和生成方面表現出令人印象深刻的能力。儘管如此，從頭訓練這些模型，即使是最不複雜的十億參數變體，也需要大量的運算資源，對許多組織來說在經濟上不切實際。隨著大型語言模型作為通用任務解決方案發揮作用，本文探討了它們特定於任務的微調。我們採用特定於任務的數據集和提示來微調兩個已修剪的 LLaMA 模型，它們分別有 50 億和 40 億個參數。此過程利用預先訓練的權重，並使用 LoRA 方法專注於權重的子集。微調 LLaMA 模型的一個挑戰是針對特定任務制定精確的提示。為了解決這個問題，我們提出了一種新的方法來微調 LLaMA 模型，它受兩個主要約束：任務具體性和提示有效性。我們的 Tailored LLaMA 方法最初採用結構修剪，將模型大小從 7B 減少到 5B 和 4B 參數。隨後，它應用了一個針對任務仔細設計的提示，並利用 LoRA 方法來加速微調過程。此外，通過少次學習和 50 次嘗試，微調一個修剪了 50% 的模型不到一個小時，就可以將分類任務的平均準確率恢復到 95.68%，壓縮率為 20%，恢復到 86.54%，壓縮率為 50%。我們在兩個修剪變體上對 Tailored LLaMA 進行驗證，證明即使壓縮到 50%，這些模型在少次分類和生成任務中的準確率仍保持在基準模型準確率的 65% 以上。這些發現突顯了我們量身定制的方法在顯著減少模型大小的同時保持高性能的有效性。

##### **No Argument Left Behind: Overlapping Chunks for Faster Processing of Arbitrarily Long Legal Texts**
2410.19184v1 by Israel Fama, Bárbara Bueno, Alexandre Alcoforado, Thomas Palmeira Ferraz, Arnold Moya, Anna Helena Reali Costa

In a context where the Brazilian judiciary system, the largest in the world,
faces a crisis due to the slow processing of millions of cases, it becomes
imperative to develop efficient methods for analyzing legal texts. We introduce
uBERT, a hybrid model that combines Transformer and Recurrent Neural Network
architectures to effectively handle long legal texts. Our approach processes
the full text regardless of its length while maintaining reasonable
computational overhead. Our experiments demonstrate that uBERT achieves
superior performance compared to BERT+LSTM when overlapping input is used and
is significantly faster than ULMFiT for processing long legal documents.

摘要：<paragraph>在巴西司法系統（全球最大）因數百萬件案件處理緩慢而面臨危機的背景下，開發用於分析法律文本的高效方法勢在必行。我們介紹了 uBERT，這是一種混合模型，結合了 Transformer 和遞迴神經網路架構，可以有效處理冗長的法律文本。我們的做法處理了全文，而不管其長度如何，同時保持合理的計算開銷。我們的實驗表明，與使用重疊輸入時相比，uBERT 的表現優於 BERT+LSTM，並且在處理冗長的法律文件時顯著快於 ULMFiT。</paragraph>

##### **Indication Finding: a novel use case for representation learning**
2410.19174v1 by Maren Eckhoff, Valmir Selimi, Alexander Aranovitch, Ian Lyons, Emily Briggs, Jennifer Hou, Alex Devereson, Matej Macak, David Champagne, Chris Anagnostopoulos

Many therapies are effective in treating multiple diseases. We present an
approach that leverages methods developed in natural language processing and
real-world data to prioritize potential, new indications for a mechanism of
action (MoA). We specifically use representation learning to generate
embeddings of indications and prioritize them based on their proximity to the
indications with the strongest available evidence for the MoA. We demonstrate
the successful deployment of our approach for anti-IL-17A using embeddings
generated with SPPMI and present an evaluation framework to determine the
quality of indication finding results and the derived embeddings.

摘要：許多療法可有效治療多種疾病。我們提出了一種方法，利用自然語言處理和真實世界資料中開發的方法，來優先考慮作用機制 (MoA) 的潛在新適應症。我們特別使用表徵學習來產生適應症的嵌入，並根據它們與證據最充分的適應症的接近程度來對它們進行優先排序。我們展示了使用 SPPMI 生成的嵌入成功部署我們針對抗 IL-17A 的方法，並提出了一個評估框架來確定適應症發現結果和衍生的嵌入的品質。

##### **MMAU: A Massive Multi-Task Audio Understanding and Reasoning Benchmark**
2410.19168v1 by S Sakshi, Utkarsh Tyagi, Sonal Kumar, Ashish Seth, Ramaneswaran Selvakumar, Oriol Nieto, Ramani Duraiswami, Sreyan Ghosh, Dinesh Manocha

The ability to comprehend audio--which includes speech, non-speech sounds,
and music--is crucial for AI agents to interact effectively with the world. We
present MMAU, a novel benchmark designed to evaluate multimodal audio
understanding models on tasks requiring expert-level knowledge and complex
reasoning. MMAU comprises 10k carefully curated audio clips paired with
human-annotated natural language questions and answers spanning speech,
environmental sounds, and music. It includes information extraction and
reasoning questions, requiring models to demonstrate 27 distinct skills across
unique and challenging tasks. Unlike existing benchmarks, MMAU emphasizes
advanced perception and reasoning with domain-specific knowledge, challenging
models to tackle tasks akin to those faced by experts. We assess 18 open-source
and proprietary (Large) Audio-Language Models, demonstrating the significant
challenges posed by MMAU. Notably, even the most advanced Gemini Pro v1.5
achieves only 52.97% accuracy, and the state-of-the-art open-source Qwen2-Audio
achieves only 52.50%, highlighting considerable room for improvement. We
believe MMAU will drive the audio and multimodal research community to develop
more advanced audio understanding models capable of solving complex audio
tasks.

摘要：理解音訊（包括語音、非語音聲音和音樂）的能力對於 AI 代理程式與世界有效互動至關重要。我們提出 MMAU，這是一個新穎的基準，旨在評估多模態音訊理解模型在需要專家級知識和複雜推理任務上的表現。MMAU 包含 10k 個經過仔細策劃的音訊片段，並搭配人工標註的自然語言問題和答案，涵蓋語音、環境音和音樂。它包括資訊萃取和推理問題，要求模型在獨特且具有挑戰性的任務中展現 27 項不同的技能。與現有的基準不同，MMAU 強調進階感知和具備特定領域知識的推理，挑戰模型處理類似專家所面對任務。我們評估了 18 個開源和專有（大型）音訊語言模型，證明了 MMAU 構成的重大挑戰。值得注意的是，即使是最先進的 Gemini Pro v1.5 也僅達到 52.97% 的準確度，而最先進的開源 Qwen2-Audio 也僅達到 52.50%，突顯出有很大的改進空間。我們相信 MMAU 將驅動音訊和多模態研究社群開發更先進的音訊理解模型，能夠解決複雜的音訊任務。

##### **Adversarial Attacks on Large Language Models Using Regularized Relaxation**
2410.19160v1 by Samuel Jacob Chacko, Sajib Biswas, Chashi Mahiul Islam, Fatema Tabassum Liza, Xiuwen Liu

As powerful Large Language Models (LLMs) are now widely used for numerous
practical applications, their safety is of critical importance. While alignment
techniques have significantly improved overall safety, LLMs remain vulnerable
to carefully crafted adversarial inputs. Consequently, adversarial attack
methods are extensively used to study and understand these vulnerabilities.
However, current attack methods face significant limitations. Those relying on
optimizing discrete tokens suffer from limited efficiency, while continuous
optimization techniques fail to generate valid tokens from the model's
vocabulary, rendering them impractical for real-world applications. In this
paper, we propose a novel technique for adversarial attacks that overcomes
these limitations by leveraging regularized gradients with continuous
optimization methods. Our approach is two orders of magnitude faster than the
state-of-the-art greedy coordinate gradient-based method, significantly
improving the attack success rate on aligned language models. Moreover, it
generates valid tokens, addressing a fundamental limitation of existing
continuous optimization methods. We demonstrate the effectiveness of our attack
on five state-of-the-art LLMs using four datasets.

摘要：隨著強大的大型語言模型 (LLM) 現在廣泛用於許多實際應用，它們的安全至關重要。雖然對齊技術已顯著提高整體安全性，但 LLM 仍然容易受到精心設計的對抗性輸入的攻擊。因此，對抗性攻擊方法被廣泛用於研究和了解這些漏洞。然而，目前的攻擊方法面臨著重大的限制。那些依賴於優化離散符號的方法效率有限，而連續優化技術無法從模型的詞彙中生成有效的符號，這使得它們不適用於實際應用。在本文中，我們提出了一種新的對抗性攻擊技術，它通過利用正則化梯度和連續優化方法克服了這些限制。我們的做法比最先進的貪婪坐標梯度下降法快兩個數量級，顯著提高了對齊語言模型的攻擊成功率。此外，它生成了有效的符號，解決了現有連續優化方法的基本限制。我們使用四個數據集證明了我們對五個最先進的 LLM 的攻擊的有效性。

##### **Lived Experience Not Found: LLMs Struggle to Align with Experts on Addressing Adverse Drug Reactions from Psychiatric Medication Use**
2410.19155v1 by Mohit Chandra, Siddharth Sriraman, Gaurav Verma, Harneet Singh Khanuja, Jose Suarez Campayo, Zihang Li, Michael L. Birnbaum, Munmun De Choudhury

Adverse Drug Reactions (ADRs) from psychiatric medications are the leading
cause of hospitalizations among mental health patients. With healthcare systems
and online communities facing limitations in resolving ADR-related issues,
Large Language Models (LLMs) have the potential to fill this gap. Despite the
increasing capabilities of LLMs, past research has not explored their
capabilities in detecting ADRs related to psychiatric medications or in
providing effective harm reduction strategies. To address this, we introduce
the Psych-ADR benchmark and the Adverse Drug Reaction Response Assessment
(ADRA) framework to systematically evaluate LLM performance in detecting ADR
expressions and delivering expert-aligned mitigation strategies. Our analyses
show that LLMs struggle with understanding the nuances of ADRs and
differentiating between types of ADRs. While LLMs align with experts in terms
of expressed emotions and tone of the text, their responses are more complex,
harder to read, and only 70.86% aligned with expert strategies. Furthermore,
they provide less actionable advice by a margin of 12.32% on average. Our work
provides a comprehensive benchmark and evaluation framework for assessing LLMs
in strategy-driven tasks within high-risk domains.

摘要：精神科藥物的藥物不良反應 (ADR) 是精神健康患者住院的主要原因。由於醫療保健系統和線上社群在解決 ADR 相關問題上存在限制，大型語言模型 (LLM) 有可能填補這項缺口。儘管 LLM 的功能越來越強大，但過去的研究尚未探討其在檢測與精神科藥物相關的 ADR 或提供有效的減害策略方面的能力。為了解決這個問題，我們引入了 Psych-ADR 基準和藥物不良反應反應評估 (ADRA) 架構，以系統性地評估 LLM 在檢測 ADR 表達和提供專家一致的緩解策略方面的表現。我們的分析顯示，LLM 在理解 ADR 的細微差別和區分不同類型的 ADR 方面有困難。雖然 LLM 在表達的情緒和文字語氣方面與專家一致，但他們的反應更複雜、更難閱讀，而且只有 70.86% 與專家策略一致。此外，他們提供的可操作建議平均減少了 12.32%。我們的研究提供了一個全面的基準和評估架構，用於評估 LLM 在高風險領域中的策略驅動任務。

##### **A Test of Time: Predicting the Sustainable Success of Online Collaboration in Wikipedia**
2410.19150v1 by Abraham Israeli, David Jurgens, Daniel Romero

The Internet has significantly expanded the potential for global
collaboration, allowing millions of users to contribute to collective projects
like Wikipedia. While prior work has assessed the success of online
collaborations, most approaches are time-agnostic, evaluating success without
considering its longevity. Research on the factors that ensure the long-term
preservation of high-quality standards in online collaboration is scarce. In
this study, we address this gap. We propose a novel metric, `Sustainable
Success,' which measures the ability of collaborative efforts to maintain their
quality over time. Using Wikipedia as a case study, we introduce the
SustainPedia dataset, which compiles data from over 40K Wikipedia articles,
including each article's sustainable success label and more than 300
explanatory features such as edit history, user experience, and team
composition. Using this dataset, we develop machine learning models to predict
the sustainable success of Wikipedia articles. Our best-performing model
achieves a high AU-ROC score of 0.88 on average. Our analysis reveals important
insights. For example, we find that the longer an article takes to be
recognized as high-quality, the more likely it is to maintain that status over
time (i.e., be sustainable). Additionally, user experience emerged as the most
critical predictor of sustainability. Our analysis provides insights into
broader collective actions beyond Wikipedia (e.g., online activism,
crowdsourced open-source software), where the same social dynamics that drive
success on Wikipedia might play a role. We make all data and code used for this
study publicly available for further research.

摘要：<paragraph>網際網路大幅擴展了全球協作的可能性，允許數百萬使用者貢獻於像維基百科這樣的集體專案。雖然先前的研究評估了線上協作的成功，但大多數方法並不考慮時間，在評估成功時並未考量其延續性。關於確保線上協作中高品質標準長期保存的因素的研究很少。在本研究中，我們探討了這個差距。我們提出一個新的指標「永續成功」，用來衡量協作工作隨著時間推移而維持其品質的能力。我們以維基百科為案例研究，引入了 SustainPedia 資料集，其中彙編了超過 40K 篇維基百科條目的資料，包括每篇文章的永續成功標籤和 300 多個解釋性特徵，例如編輯記錄、使用者體驗和團隊組成。使用此資料集，我們開發了機器學習模型來預測維基百科條目的永續成功。我們效能最佳的模型平均達到了 0.88 的高 AU-ROC 分數。我們的分析揭示了重要的見解。例如，我們發現一篇文章被認定為高品質的時間越長，隨著時間推移而維持該狀態（即永續）的可能性就越高。此外，使用者體驗成為永續性的最重要預測指標。我們的分析提供了對維基百科以外的更廣泛集體行動的見解（例如，線上行動主義、群眾外包的開源軟體），在這些行動中，推動維基百科成功的相同社會動態可能發揮作用。我們讓本研究中使用的所有資料和程式碼都公開可用，以供進一步研究。</paragraph>

##### **Visual Text Matters: Improving Text-KVQA with Visual Text Entity Knowledge-aware Large Multimodal Assistant**
2410.19144v1 by Abhirama Subramanyam Penamakuri, Anand Mishra

We revisit knowledge-aware text-based visual question answering, also known
as Text-KVQA, in the light of modern advancements in large multimodal models
(LMMs), and make the following contributions: (i) We propose VisTEL - a
principled approach to perform visual text entity linking. The proposed VisTEL
module harnesses a state-of-the-art visual text recognition engine and the
power of a large multimodal model to jointly reason using textual and visual
context obtained using surrounding cues in the image to link the visual text
entity to the correct knowledge base entity. (ii) We present KaLMA - a
knowledge-aware large multimodal assistant that augments an LMM with knowledge
associated with visual text entity in the image to arrive at an accurate
answer. Further, we provide a comprehensive experimental analysis and
comparison of our approach with traditional visual question answering,
pre-large multimodal models, and large multimodal models, as well as prior
top-performing approaches. Averaging over three splits of Text-KVQA, our
proposed approach surpasses the previous best approach by a substantial 23.3%
on an absolute scale and establishes a new state of the art. We make our
implementation publicly available.

摘要：<paragraph>我們在大型多模態模型 (LMM) 的現代進步的基礎上，重新探討了知識感知的基於文字的視覺問題解答，也稱為 Text-KVQA，並做出以下貢獻：(i) 我們提出 VisTEL - 一種執行視覺文字實體連結的原則性方法。提出的 VisTEL 模組利用最先進的視覺文字辨識引擎和大型多模態模型的力量，使用圖像中周圍線索取得的文字和視覺脈絡，共同推論，將視覺文字實體連結到正確的知識庫實體。(ii) 我們提出 KaLMA - 一種知識感知的大型多模態助理，它擴充了一個 LMM，結合了圖像中視覺文字實體相關的知識，以得出準確的答案。此外，我們提供了一個全面的實驗分析，並將我們的方法與傳統的視覺問題解答、大型多模態模型之前和大型多模態模型以及之前的頂尖方法進行比較。在 Text-KVQA 的三個分割平均值中，我們提出的方法在絕對規模上超越了之前的最佳方法，達到了 23.3%，並建立了新的技術水準。我們公開了我們的實作。</paragraph>

##### **PDL: A Declarative Prompt Programming Language**
2410.19135v1 by Mandana Vaziri, Louis Mandel, Claudio Spiess, Martin Hirzel

Large language models (LLMs) have taken the world by storm by making many
previously difficult uses of AI feasible. LLMs are controlled via highly
expressive textual prompts and return textual answers. Unfortunately, this
unstructured text as input and output makes LLM-based applications brittle.
This motivates the rise of prompting frameworks, which mediate between LLMs and
the external world. However, existing prompting frameworks either have a high
learning curve or take away control over the exact prompts from the developer.
To overcome this dilemma, this paper introduces the Prompt Declaration Language
(PDL). PDL is a simple declarative data-oriented language that puts prompts at
the forefront, based on YAML. PDL works well with many LLM platforms and LLMs.
It supports writing interactive applications that call LLMs and tools, and
makes it easy to implement common use-cases such as chatbots, RAG, or agents.
We hope PDL will make prompt programming simpler, less brittle, and more
enjoyable.

摘要：大型語言模型 (LLM) 透過讓許多先前難以執行的 AI 用途變得可行，在全球掀起熱潮。LLM 是透過高度表達的文字提示來控制，並回傳文字答案。不幸的是，這種非結構化的文字作為輸入和輸出，會讓基於 LLM 的應用程式變得脆弱。這促使提示框架的興起，在 LLM 和外部世界之間進行調解。然而，現有的提示框架要不學習曲線高，要不就是剝奪開發人員對確切提示的控制權。為了克服這個困境，本文介紹了提示宣告語言 (PDL)。PDL 是一種簡單的宣告式資料導向語言，基於 YAML，將提示放在最前線。PDL 與許多 LLM 平台和 LLM 合作良好。它支援撰寫呼叫 LLM 和工具的互動式應用程式，並讓實作常見的使用案例變得容易，例如聊天機器人、RAG 或代理程式。我們希望 PDL 能讓提示程式設計變得更簡單、更不容易出錯，而且更令人愉悅。

##### **AlignCap: Aligning Speech Emotion Captioning to Human Preferences**
2410.19134v1 by Ziqi Liang, Haoxiang Shi, Hanhui Chen

Speech Emotion Captioning (SEC) has gradually become an active research task.
The emotional content conveyed through human speech are often complex, and
classifying them into fixed categories may not be enough to fully capture
speech emotions. Describing speech emotions through natural language may be a
more effective approach. However, existing SEC methods often produce
hallucinations and lose generalization on unseen speech. To overcome these
problems, we propose AlignCap, which Aligning Speech Emotion Captioning to
Human Preferences based on large language model (LLM) with two properties: 1)
Speech-Text Alignment, which minimizing the divergence between the LLM's
response prediction distributions for speech and text inputs using knowledge
distillation (KD) Regularization. 2) Human Preference Alignment, where we
design Preference Optimization (PO) Regularization to eliminate factuality and
faithfulness hallucinations. We also extract emotional clues as a prompt for
enriching fine-grained information under KD-Regularization. Experiments
demonstrate that AlignCap presents stronger performance to other
state-of-the-art methods on Zero-shot SEC task.

摘要：語音情緒標題 (SEC) 已逐漸成為一項活躍的研究任務。
人類言語傳達的情緒內容通常很複雜，
將其分類為固定類別可能不足以完全捕捉
言語情緒。透過自然語言描述言語情緒可能是
一種更有效的方法。然而，現有的 SEC 方法經常產生
幻覺，並在未見過的言語上失去概括性。為了克服這些
問題，我們提出了 AlignCap，它基於具有兩個特性的
大型語言模型 (LLM) 將言語情緒標題與人類偏好對齊：1)
言語文字對齊，它使用知識提煉 (KD) 正則化最小化 LLM
的回應預測分佈與言語和文字輸入之間的差異。2) 人類偏好對齊，
我們設計了偏好最佳化 (PO) 正則化來消除事實性和
忠實度幻覺。我們還提取情緒線索作為提示，以豐富
KD 正則化下的細粒度資訊。實驗證明，AlignCap 在
零次 SEC 任務上表現出比其他最先進方法更強的效能。

##### **Hybrid Preferences: Learning to Route Instances for Human vs. AI Feedback**
2410.19133v1 by Lester James V. Miranda, Yizhong Wang, Yanai Elazar, Sachin Kumar, Valentina Pyatkin, Faeze Brahman, Noah A. Smith, Hannaneh Hajishirzi, Pradeep Dasigi

Learning from human feedback has enabled the alignment of language models
(LMs) with human preferences. However, directly collecting human preferences
can be expensive, time-consuming, and can have high variance. An appealing
alternative is to distill preferences from LMs as a source of synthetic
annotations as they are more consistent, cheaper, and scale better than human
annotation; however, they are also prone to biases and errors. In this work, we
introduce a routing framework that combines inputs from humans and LMs to
achieve better annotation quality, while reducing the total cost of human
annotation. The crux of our approach is to identify preference instances that
will benefit from human annotations. We formulate this as an optimization
problem: given a preference dataset and an evaluation metric, we train a
performance prediction model to predict a reward model's performance on an
arbitrary combination of human and LM annotations and employ a routing strategy
that selects a combination that maximizes predicted performance. We train the
performance prediction model on MultiPref, a new preference dataset with 10K
instances paired with human and LM labels. We show that the selected hybrid
mixture of LM and direct human preferences using our routing framework achieves
better reward model performance compared to using either one exclusively. We
simulate selective human preference collection on three other datasets and show
that our method generalizes well to all three. We analyze features from the
routing model to identify characteristics of instances that can benefit from
human feedback, e.g., prompts with a moderate safety concern or moderate intent
complexity. We release the dataset, annotation platform, and source code used
in this study to foster more efficient and accurate preference collection in
the future.

摘要：<paragraph>從人類回饋中學習已能使語言模型 (LM) 與人類偏好保持一致。然而，直接收集人類偏好可能很昂貴、耗時且變異性高。一個有吸引力的替代方案是從 LM 中提取偏好，作為合成註解的來源，因為它們比人類註解更一致、更便宜且擴展性更好；然而，它們也容易出現偏差和錯誤。在這項工作中，我們引入了一個路由框架，結合人類和 LM 的輸入，以實現更好的註解品質，同時降低人類註解的總成本。我們方法的核心是識別將受益於人類註解的偏好實例。我們將其表述為一個最佳化問題：給定一個偏好資料集和一個評估指標，我們訓練一個效能預測模型，以預測獎勵模型在人類和 LM 註解的任意組合上的效能，並採用一種路由策略，選擇一個組合，以最大化預測效能。我們在 MultiPref 上訓練效能預測模型，MultiPref 是個新的偏好資料集，包含 10K 個與人類和 LM 標籤配對的實例。我們證明，使用我們的路由框架選擇的 LM 和直接人類偏好的混合混合，與僅使用其中一種相比，可達成更好的獎勵模型效能。我們在其他三個資料集上模擬選擇性人類偏好收集，並證明我們的方法能很好地概括到所有這三個資料集。我們分析路由模型中的特徵，以識別可從人類回饋中受益的實例特徵，例如，具有適度安全疑慮或適度意圖複雜性的提示。我們發布本研究中使用的資料集、註解平台和原始碼，以促進未來更有效率且準確的偏好收集。</paragraph>

##### **Research on Key Technologies for Cross-Cloud Federated Training of Large Language Models**
2410.19130v1 by Haowei Yang, Mingxiu Sui, Shaobo Liu, Xinyue Qian, Zhaoyang Zhang, Bingying Liu

With the rapid development of natural language processing technology, large
language models have demonstrated exceptional performance in various
application scenarios. However, training these models requires significant
computational resources and data processing capabilities. Cross-cloud federated
training offers a new approach to addressing the resource bottlenecks of a
single cloud platform, allowing the computational resources of multiple clouds
to collaboratively complete the training tasks of large models. This study
analyzes the key technologies of cross-cloud federated training, including data
partitioning and distribution, communication optimization, model aggregation
algorithms, and the compatibility of heterogeneous cloud platforms.
Additionally, the study examines data security and privacy protection
strategies in cross-cloud training, particularly the application of data
encryption and differential privacy techniques. Through experimental
validation, the proposed technical framework demonstrates enhanced training
efficiency, ensured data security, and reduced training costs, highlighting the
broad application prospects of cross-cloud federated training.

摘要：隨著自然語言處理技術的快速發展，大型語言模型在各類應用場景中展現出卓越的表現。然而，訓練這些模型需要大量的計算資源和資料處理能力。跨雲端聯合訓練提供了一種新的方法來解決單一雲端平台的資源瓶頸，讓多個雲端的計算資源可以協同完成大型模型的訓練任務。本研究分析了跨雲端聯合訓練的關鍵技術，包括資料分割與分配、通訊最佳化、模型聚合演算法，以及異質雲端平台的相容性。此外，本研究探討了跨雲端訓練中的資料安全與隱私保護策略，特別是資料加密和差分隱私技術的應用。透過實驗驗證，所提出的技術架構展現出提升的訓練效率、確保資料安全，以及降低訓練成本，突顯了跨雲端聯合訓練廣泛的應用前景。

##### **Retrieving Implicit and Explicit Emotional Events Using Large Language Models**
2410.19128v1 by Guimin Hu

Large language models (LLMs) have garnered significant attention in recent
years due to their impressive performance. While considerable research has
evaluated these models from various perspectives, the extent to which LLMs can
perform implicit and explicit emotion retrieval remains largely unexplored. To
address this gap, this study investigates LLMs' emotion retrieval capabilities
in commonsense. Through extensive experiments involving multiple models, we
systematically evaluate the ability of LLMs on emotion retrieval. Specifically,
we propose a supervised contrastive probing method to verify LLMs' performance
for implicit and explicit emotion retrieval, as well as the diversity of the
emotional events they retrieve. The results offer valuable insights into the
strengths and limitations of LLMs in handling emotion retrieval.

摘要：近年來，由於大型語言模型 (LLM) 令人印象深刻的效能，因此備受關注。儘管有大量的研究從各種角度評估這些模型，但 LLM 能執行內隱和外顯情緒擷取的程度仍未被廣泛探討。為了解決這個差距，本研究探討 LLM 在常識中的情緒擷取能力。透過涉及多個模型的廣泛實驗，我們系統性地評估 LLM 在情緒擷取上的能力。具體來說，我們提出一個監督對比探測方法來驗證 LLM 在內隱和外顯情緒擷取上的效能，以及他們擷取的情緒事件的多樣性。研究結果為 LLM 在處理情緒擷取時的優缺點提供了有價值的見解。

##### **Read-ME: Refactorizing LLMs as Router-Decoupled Mixture of Experts with System Co-Design**
2410.19123v1 by Ruisi Cai, Yeonju Ro, Geon-Woo Kim, Peihao Wang, Babak Ehteshami Bejnordi, Aditya Akella, Zhangyang Wang

The proliferation of large language models (LLMs) has led to the adoption of
Mixture-of-Experts (MoE) architectures that dynamically leverage specialized
subnetworks for improved efficiency and performance. Despite their benefits,
MoE models face significant challenges during inference, including inefficient
memory management and suboptimal batching, due to misaligned design choices
between the model architecture and the system policies. Furthermore, the
conventional approach of training MoEs from scratch is increasingly prohibitive
in terms of cost. In this paper, we propose a novel framework Read-ME that
transforms pre-trained dense LLMs into smaller MoE models (in contrast to
"upcycling" generalist MoEs), avoiding the high costs of ground-up training.
Our approach employs activation sparsity to extract experts. To compose
experts, we examine the widely-adopted layer-wise router design and show its
redundancy, and thus we introduce the pre-gating router decoupled from the MoE
backbone that facilitates system-friendly pre-computing and lookahead
scheduling, enhancing expert-aware batching and caching. Our codesign therefore
addresses critical gaps on both the algorithmic and system fronts, establishing
a scalable and efficient alternative for LLM inference in resource-constrained
settings. Read-ME outperforms other popular open-source dense models of similar
scales, achieving improvements of up to 10.1% on MMLU, and improving mean
end-to-end latency up to 6.1%. Codes are available at:
https://github.com/VITA-Group/READ-ME.

摘要：<paragraph>大型語言模型 (LLM) 的激增導致採用混合專家 (MoE) 架構，該架構動態利用專業子網路來提高效率和效能。儘管有其優點，MoE 模型在推論期間仍面臨重大挑戰，包括由於模型架構和系統政策之間的設計選擇不一致，導致記憶體管理效率低下和批次處理次佳。此外，從頭訓練 MoE 的傳統方法在成本方面越來越令人望而卻步。在本文中，我們提出一個新穎的框架 Read-ME，將預先訓練的密集 LLM 轉換成較小的 MoE 模型（與「升級」通才 MoE 相反），避免從頭訓練的高昂成本。我們的做法採用激活稀疏性來提取專家。為了組成專家，我們檢視廣泛採用的逐層路由器設計並顯示其冗餘，因此我們引入了與 MoE 主幹分離的預閘門路由器，它有助於系統友善的預先運算和前瞻排程，增強專家感知的批次處理和快取。因此，我們的共同設計解決了演算法和系統方面的關鍵差距，為資源受限設定中的 LLM 推論建立了一個可擴充且高效的替代方案。Read-ME 優於其他流行的類似規模開源密集模型，在 MMLU 上實現高達 10.1% 的改進，並將平均端到端延遲時間改善高達 6.1%。程式碼可在以下位置取得：
https://github.com/VITA-Group/READ-ME。</paragraph>

##### **LLM Tree Search**
2410.19117v1 by Dylan Wilson

This project aims to investigate a novel sequence generation method inspired
by the AlphaGo paradigm, adapting it for use with large language models (LLMs).
The proposed approach involves creating search trees of different possible
completions and evaluating these completions based on model confidence. By
considering various paths in the search tree and scoring them according to the
model's confidence in each completion, we can generate diverse and high-quality
sequences. This research explores the implementation of this paradigm by using
confidence as a proxy for response quality akin to beam search
\citep{vijayakumar2016diverse}. The primary goal of this paper is to outline
the paradigm and demonstrate its potential, rather than focusing on achieving
perfect results. The paper will outline the reasons why we believe this
paradigm has the potential to improve LLMs in the following manners: 1)
increase output quality, 2) decrease errors, 3) eliminate or reduce the
compound error problems, 4) generate diverse and creative completions, 5) allow
for iterative problem-solving, and 6) self-training. We expect this approach to
yield a set of diverse and coherent sequences, offering insights into balancing
exploration and exploitation in sequence generation. Potential applications
include creative text generation tasks, such as storytelling and content
creation, as well as other natural language processing domains, like machine
translation and automated summarization. The goal is that the model will be far
more effective as it will be able to consider many possible variations allowing
it to find the ideal completion. This research aims to contribute to the
understanding of effective search strategies in sequence generation and their
impact on generating high-quality, varied textual outputs.

摘要：這個專案旨在研究一種新的序列生成方法，靈感來自 AlphaGo 典範，並調整其以用於大型語言模型 (LLM)。提議的方法包括建立不同可能完成項目的搜尋樹，並根據模型信心評估這些完成項目。藉由考慮搜尋樹中的各種路徑，並根據模型對每個完成項目的信心對其進行評分，我們可以產生多樣且高品質的序列。這項研究探索了實作此典範的方法，方法是使用信心作為反應品質的代理，類似於光束搜尋 \citep{vijayakumar2016diverse}。這篇論文的主要目標是概述此典範並展示其潛力，而不是專注於達成完美的結果。這篇論文將概述我們相信此典範有潛力改善 LLM 的原因，如下：1) 提升輸出品質，2) 減少錯誤，3) 消除或減少複合錯誤問題，4) 產生多樣且有創意的完成項目，5) 允許迭代問題解決，以及 6) 自我訓練。我們預期這種方法將產生一組多樣且連貫的序列，提供見解以平衡序列生成中的探索和利用。潛在應用包括創意文字生成任務，例如說故事和內容創作，以及其他自然語言處理領域，例如機器翻譯和自動摘要。目標是模型將更有效，因為它將能夠考慮許多可能的變化，使它能夠找到理想的完成項目。這項研究旨在促進對序列生成中有效搜尋策略的理解，以及它們對產生高品質、多樣化的文字輸出的影響。

##### **Bio2Token: All-atom tokenization of any biomolecular structure with Mamba**
2410.19110v1 by Andrew Liu, Axel Elaldi, Nathan Russell, Olivia Viessmann

Efficient encoding and representation of large 3D molecular structures with
high fidelity is critical for biomolecular design applications. Despite this,
many representation learning approaches restrict themselves to modeling smaller
systems or use coarse-grained approximations of the systems, for example
modeling proteins at the resolution of amino acid residues rather than at the
level of individual atoms. To address this, we develop quantized auto-encoders
that learn atom-level tokenizations of complete proteins, RNA and small
molecule structures with reconstruction accuracies below and around 1 Angstrom.
We demonstrate that the Mamba state space model architecture employed is
comparatively efficient, requiring a fraction of the training data, parameters
and compute needed to reach competitive accuracies and can scale to systems
with almost 100,000 atoms. The learned structure tokens of bio2token may serve
as the input for all-atom language models in the future.

摘要：有效編碼和表示大型 3D 分子結構並具有高保真度，對於生物分子設計應用至關重要。儘管如此，許多表示學習方法都將自己限制在建模較小的系統或使用系統的粗略近似值，例如以胺基酸殘基解析度而非個別原子層級建模蛋白質。為了解決這個問題，我們開發了量化的自動編碼器，它可以學習完整蛋白質、RNA 和小分子結構的原子級標記化，其重建準確度低於或約為 1 埃。我們證明所採用的 Mamba 狀態空間模型架構具有比較高的效率，只需要訓練數據、參數和計算的一小部分即可達到具有競爭力的準確度，並且可以擴展到擁有將近 100,000 個原子的系統。bio2token 學習的結構標記未來可能會作為全原子語言模型的輸入。

