{"2406.20086": {"publish_time": "2024-06-28", "title": "Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs", "paper_summary": "LLMs process text as sequences of tokens that roughly correspond to words,\nwhere less common words are represented by multiple tokens. However, individual\ntokens are often semantically unrelated to the meanings of the words/concepts\nthey comprise. For example, Llama-2-7b's tokenizer splits the word\n\"northeastern\" into the tokens ['_n', 'ort', 'he', 'astern'], none of which\ncorrespond to semantically meaningful units like \"north\" or \"east.\" Similarly,\nthe overall meanings of named entities like \"Neil Young\" and multi-word\nexpressions like \"break a leg\" cannot be directly inferred from their\nconstituent tokens. Mechanistically, how do LLMs convert such arbitrary groups\nof tokens into useful higher-level representations? In this work, we find that\nlast token representations of named entities and multi-token words exhibit a\npronounced \"erasure\" effect, where information about previous and current\ntokens is rapidly forgotten in early layers. Using this observation, we propose\na method to \"read out\" the implicit vocabulary of an autoregressive LLM by\nexamining differences in token representations across layers, and present\nresults of this method for Llama-2-7b and Llama-3-8B. To our knowledge, this is\nthe first attempt to probe the implicit vocabulary of an LLM.", "paper_summary_zh": "LLM \u5c07\u6587\u5b57\u8655\u7406\u6210\u5927\u81f4\u5c0d\u61c9\u65bc\u55ae\u5b57\u7684\u7b26\u865f\u5e8f\u5217\uff0c\u5176\u4e2d\u4e0d\u5e38\u898b\u7684\u55ae\u5b57\u6703\u4ee5\u591a\u500b\u7b26\u865f\u8868\u793a\u3002\u7136\u800c\uff0c\u500b\u5225\u7b26\u865f\u901a\u5e38\u5728\u8a9e\u610f\u4e0a\u8207\u5b83\u5011\u6240\u7d44\u6210\u7684\u55ae\u5b57/\u6982\u5ff5\u7684\u610f\u7fa9\u7121\u95dc\u3002\u4f8b\u5982\uff0cLlama-2-7b \u7684\u7b26\u865f\u5316\u5668\u5c07\u55ae\u5b57\u300cnortheastern\u300d\u62c6\u5206\u70ba\u7b26\u865f ['_n', 'ort', 'he', 'astern']\uff0c\u5176\u4e2d\u6c92\u6709\u4e00\u500b\u7b26\u865f\u5c0d\u61c9\u65bc\u300cnorth\u300d\u6216\u300ceast\u300d\u7b49\u6709\u8a9e\u610f\u610f\u7fa9\u7684\u55ae\u4f4d\u3002\u540c\u6a23\u5730\uff0c\u50cf\u300cNeil Young\u300d\u9019\u6a23\u7684\u547d\u540d\u5be6\u9ad4\u548c\u50cf\u300cbreak a leg\u300d\u9019\u6a23\u7684\u591a\u5b57\u8a5e\u8868\u9054\u5f0f\u7684\u6574\u9ad4\u610f\u7fa9\u7121\u6cd5\u76f4\u63a5\u5f9e\u5b83\u5011\u7684\u7d44\u6210\u7b26\u865f\u63a8\u65b7\u51fa\u4f86\u3002\u5f9e\u6a5f\u5236\u4e0a\u4f86\u8aaa\uff0cLLM \u5982\u4f55\u5c07\u9019\u4e9b\u4efb\u610f\u7b26\u865f\u7fa4\u8f49\u63db\u70ba\u6709\u7528\u7684\u8f03\u9ad8\u5c64\u7d1a\u8868\u5fb5\uff1f\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u767c\u73fe\u547d\u540d\u5be6\u9ad4\u548c\u591a\u7b26\u865f\u55ae\u5b57\u7684\u6700\u5f8c\u4e00\u500b\u7b26\u865f\u8868\u5fb5\u8868\u73fe\u51fa\u660e\u986f\u7684\u300c\u62b9\u9664\u300d\u6548\u61c9\uff0c\u5728\u65e9\u671f\u5c64\u7d1a\u4e2d\uff0c\u95dc\u65bc\u5148\u524d\u548c\u7576\u524d\u7b26\u865f\u7684\u8cc7\u8a0a\u6703\u8fc5\u901f\u88ab\u907a\u5fd8\u3002\u5229\u7528\u9019\u500b\u89c0\u5bdf\u7d50\u679c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b9\u6cd5\uff0c\u900f\u904e\u6aa2\u67e5\u7b26\u865f\u8868\u5fb5\u5728\u4e0d\u540c\u5c64\u7d1a\u4e4b\u9593\u7684\u5dee\u7570\u4f86\u300c\u8b80\u51fa\u300d\u81ea\u8ff4\u6b78 LLM \u7684\u96b1\u542b\u8a5e\u5f59\uff0c\u4e26\u91dd\u5c0d Llama-2-7b \u548c Llama-3-8B \u63d0\u51fa\u6b64\u65b9\u6cd5\u7684\u7d50\u679c\u3002\u64da\u6211\u5011\u6240\u77e5\uff0c\u9019\u662f\u9996\u6b21\u5617\u8a66\u63a2\u6e2c LLM \u7684\u96b1\u542b\u8a5e\u5f59\u3002", "author": "Sheridan Feucht et.al.", "authors": "Sheridan Feucht, David Atkinson, Byron Wallace, David Bau", "id": "2406.20086v1", "paper_url": "http://arxiv.org/abs/2406.20086v1", "repo": "null"}}