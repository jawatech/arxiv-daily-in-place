{"2503.09969": {"publish_time": "2025-03-13", "title": "Detecting Dataset Bias in Medical AI: A Generalized and Modality-Agnostic Auditing Framework", "paper_summary": "Data-driven AI is establishing itself at the center of evidence-based\nmedicine. However, reports of shortcomings and unexpected behavior are growing\ndue to AI's reliance on association-based learning. A major reason for this\nbehavior: latent bias in machine learning datasets can be amplified during\ntraining and/or hidden during testing. We present a data modality-agnostic\nauditing framework for generating targeted hypotheses about sources of bias\nwhich we refer to as Generalized Attribute Utility and Detectability-Induced\nbias Testing (G-AUDIT) for datasets. Our method examines the relationship\nbetween task-level annotations and data properties including protected\nattributes (e.g., race, age, sex) and environment and acquisition\ncharacteristics (e.g., clinical site, imaging protocols). G-AUDIT automatically\nquantifies the extent to which the observed data attributes may enable shortcut\nlearning, or in the case of testing data, hide predictions made based on\nspurious associations. We demonstrate the broad applicability and value of our\nmethod by analyzing large-scale medical datasets for three distinct modalities\nand learning tasks: skin lesion classification in images, stigmatizing language\nclassification in Electronic Health Records (EHR), and mortality prediction for\nICU tabular data. In each setting, G-AUDIT successfully identifies subtle\nbiases commonly overlooked by traditional qualitative methods that focus\nprimarily on social and ethical objectives, underscoring its practical value in\nexposing dataset-level risks and supporting the downstream development of\nreliable AI systems. Our method paves the way for achieving deeper\nunderstanding of machine learning datasets throughout the AI development\nlife-cycle from initial prototyping all the way to regulation, and creates\nopportunities to reduce model bias, enabling safer and more trustworthy AI\nsystems.", "paper_summary_zh": "<paragraph>\u6578\u64da\u9a45\u52d5\u7684 AI \u6b63\u9010\u6f38\u78ba\u7acb\u5176\u5728\u5faa\u8b49\u91ab\u5b78\u4e2d\u7684\u6838\u5fc3\u5730\u4f4d\u3002\u7136\u800c\uff0c\u7531\u65bc AI \u4f9d\u8cf4\u65bc\u57fa\u65bc\u95dc\u806f\u7684\u5b78\u7fd2\uff0c\u95dc\u65bc\u5176\u7f3a\u9677\u548c\u610f\u5916\u884c\u70ba\u7684\u5831\u544a\u4e5f\u8d8a\u4f86\u8d8a\u591a\u3002\u9020\u6210\u9019\u7a2e\u73fe\u8c61\u7684\u4e00\u500b\u4e3b\u8981\u539f\u56e0\u662f\uff1a\u6a5f\u5668\u5b78\u7fd2\u6578\u64da\u96c6\u4e2d\u6f5b\u5728\u7684\u504f\u5dee\u6703\u5728\u8a13\u7df4\u904e\u7a0b\u4e2d\u88ab\u653e\u5927\uff0c\u4e26\u4e14/\u6216\u8005\u5728\u6e2c\u8a66\u904e\u7a0b\u4e2d\u88ab\u96b1\u85cf\u3002\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u8207\u6578\u64da\u6a21\u614b\u7121\u95dc\u7684\u5be9\u8a08\u6846\u67b6\uff0c\u7528\u65bc\u751f\u6210\u95dc\u65bc\u504f\u5dee\u4f86\u6e90\u7684\u76ee\u6a19\u5047\u8a2d\uff0c\u6211\u5011\u5c07\u5176\u7a31\u70ba\u901a\u7528\u5c6c\u6027\u6548\u7528\u548c\u53ef\u6aa2\u6e2c\u6027\u8a98\u5c0e\u504f\u5dee\u6e2c\u8a66 (G-AUDIT)\u3002\u6211\u5011\u7684\u65b9\u6cd5\u6aa2\u67e5\u4e86\u4efb\u52d9\u7d1a\u8a3b\u91cb\u8207\u6578\u64da\u5c6c\u6027\u4e4b\u9593\u7684\u95dc\u4fc2\uff0c\u5305\u62ec\u53d7\u4fdd\u8b77\u7684\u5c6c\u6027\uff08\u4f8b\u5982\u7a2e\u65cf\u3001\u5e74\u9f61\u3001\u6027\u5225\uff09\u4ee5\u53ca\u74b0\u5883\u548c\u63a1\u96c6\u7279\u5fb5\uff08\u4f8b\u5982\u81e8\u5e8a\u5730\u9ede\u3001\u6210\u50cf\u5354\u8b70\uff09\u3002G-AUDIT \u81ea\u52d5\u91cf\u5316\u89c0\u5bdf\u5230\u7684\u6578\u64da\u5c6c\u6027\u53ef\u80fd\u5c0e\u81f4\u6377\u5f91\u5b78\u7fd2\u7684\u7a0b\u5ea6\uff0c\u6216\u8005\u5728\u6e2c\u8a66\u6578\u64da\u7684\u60c5\u6cc1\u4e0b\uff0c\u96b1\u85cf\u57fa\u65bc\u865b\u5047\u95dc\u806f\u505a\u51fa\u7684\u9810\u6e2c\u7684\u7a0b\u5ea6\u3002\u6211\u5011\u901a\u904e\u5206\u6790\u7528\u65bc\u4e09\u7a2e\u4e0d\u540c\u6a21\u614b\u548c\u5b78\u7fd2\u4efb\u52d9\u7684\u5927\u898f\u6a21\u91ab\u5b78\u6578\u64da\u96c6\u4f86\u8b49\u660e\u6211\u5011\u65b9\u6cd5\u7684\u5ee3\u6cdb\u9069\u7528\u6027\u548c\u50f9\u503c\uff1a\u5716\u50cf\u4e2d\u7684\u76ae\u819a\u75c5\u8b8a\u5206\u985e\u3001\u96fb\u5b50\u5065\u5eb7\u8a18\u9304 (EHR) \u4e2d\u7684\u6c61\u540d\u5316\u8a9e\u8a00\u5206\u985e\u4ee5\u53ca ICU \u8868\u683c\u6578\u64da\u7684\u6b7b\u4ea1\u7387\u9810\u6e2c\u3002\u5728\u6bcf\u7a2e\u60c5\u6cc1\u4e0b\uff0cG-AUDIT \u90fd\u6210\u529f\u5730\u8b58\u5225\u51fa\u50b3\u7d71\u5b9a\u6027\u65b9\u6cd5\u901a\u5e38\u6703\u5ffd\u7565\u7684\u7d30\u5fae\u504f\u5dee\uff0c\u9019\u4e9b\u65b9\u6cd5\u4e3b\u8981\u95dc\u6ce8\u793e\u6703\u548c\u502b\u7406\u76ee\u6a19\uff0c\u9019\u7a81\u986f\u4e86\u5b83\u5728\u63ed\u793a\u6578\u64da\u96c6\u7d1a\u98a8\u96aa\u548c\u652f\u6301\u4e0b\u6e38\u53ef\u9760 AI \u7cfb\u7d71\u958b\u767c\u65b9\u9762\u7684\u5be6\u7528\u50f9\u503c\u3002\u6211\u5011\u7684\u65b9\u6cd5\u70ba\u5728\u6574\u500b AI \u958b\u767c\u751f\u547d\u9031\u671f\uff08\u5f9e\u521d\u59cb\u539f\u578b\u8a2d\u8a08\u5230\u76e3\u7ba1\uff09\u4e2d\u66f4\u6df1\u5165\u5730\u7406\u89e3\u6a5f\u5668\u5b78\u7fd2\u6578\u64da\u96c6\u92ea\u5e73\u4e86\u9053\u8def\uff0c\u4e26\u5275\u9020\u4e86\u6e1b\u5c11\u6a21\u578b\u504f\u5dee\u7684\u6a5f\u6703\uff0c\u5f9e\u800c\u5be6\u73fe\u66f4\u5b89\u5168\u3001\u66f4\u503c\u5f97\u4fe1\u8cf4\u7684 AI \u7cfb\u7d71\u3002</paragraph>\n", "author": "Nathan Drenkow et.al.", "authors": "Nathan Drenkow, Mitchell Pavlak, Keith Harrigian, Ayah Zirikly, Adarsh Subbaswamy, Mathias Unberath", "id": "2503.09969v1", "paper_url": "http://arxiv.org/abs/2503.09969v1", "repo": "null"}}