{"2410.14231": {"publish_time": "2024-10-18", "title": "Unveiling Large Language Models Generated Texts: A Multi-Level Fine-Grained Detection Framework", "paper_summary": "Large language models (LLMs) have transformed human writing by enhancing\ngrammar correction, content expansion, and stylistic refinement. However, their\nwidespread use raises concerns about authorship, originality, and ethics, even\npotentially threatening scholarly integrity. Existing detection methods, which\nmainly rely on single-feature analysis and binary classification, often fail to\neffectively identify LLM-generated text in academic contexts. To address these\nchallenges, we propose a novel Multi-level Fine-grained Detection (MFD)\nframework that detects LLM-generated text by integrating low-level structural,\nhigh-level semantic, and deep-level linguistic features, while conducting\nsentence-level evaluations of lexicon, grammar, and syntax for comprehensive\nanalysis. To improve detection of subtle differences in LLM-generated text and\nenhance robustness against paraphrasing, we apply two mainstream evasion\ntechniques to rewrite the text. These variations, along with original texts,\nare used to train a text encoder via contrastive learning, extracting\nhigh-level semantic features of sentence to boost detection generalization.\nFurthermore, we leverage advanced LLM to analyze the entire text and extract\ndeep-level linguistic features, enhancing the model's ability to capture\ncomplex patterns and nuances while effectively incorporating contextual\ninformation. Extensive experiments on public datasets show that the MFD model\noutperforms existing methods, achieving an MAE of 0.1346 and an accuracy of\n88.56%. Our research provides institutions and publishers with an effective\nmechanism to detect LLM-generated text, mitigating risks of compromised\nauthorship. Educators and editors can use the model's predictions to refine\nverification and plagiarism prevention protocols, ensuring adherence to\nstandards.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u900f\u904e\u589e\u5f37\u6587\u6cd5\u4fee\u6b63\u3001\u5167\u5bb9\u64f4\u5145\u548c\u6587\u9ad4\u6f64\u98fe\uff0c\u8f49\u8b8a\u4e86\u4eba\u985e\u5beb\u4f5c\u65b9\u5f0f\u3002\u7136\u800c\uff0c\u5b83\u5011\u7684\u5ee3\u6cdb\u4f7f\u7528\u5f15\u767c\u4e86\u95dc\u65bc\u4f5c\u8005\u8eab\u4efd\u3001\u539f\u5275\u6027\u8207\u9053\u5fb7\u7684\u7591\u616e\uff0c\u751a\u81f3\u6f5b\u5728\u5a01\u8105\u5230\u5b78\u8853\u7684\u5b8c\u6574\u6027\u3002\u73fe\u6709\u7684\u5075\u6e2c\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8cf4\u65bc\u55ae\u4e00\u7279\u5fb5\u5206\u6790\u548c\u4e8c\u5143\u5206\u985e\uff0c\u5f80\u5f80\u7121\u6cd5\u5728\u5b78\u8853\u8108\u7d61\u4e2d\u6709\u6548\u8b58\u5225 LLM \u751f\u6210\u7684\u6587\u5b57\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u65b0\u7a4e\u7684\u591a\u5c64\u7d1a\u7d30\u7c92\u5ea6\u5075\u6e2c (MFD) \u67b6\u69cb\uff0c\u900f\u904e\u6574\u5408\u4f4e\u5c64\u7d1a\u7d50\u69cb\u3001\u9ad8\u5c64\u7d1a\u8a9e\u610f\u548c\u6df1\u5c64\u7d1a\u8a9e\u8a00\u7279\u5fb5\u4f86\u5075\u6e2c LLM \u751f\u6210\u7684\u6587\u5b57\uff0c\u540c\u6642\u5c0d\u8a5e\u5f59\u3001\u6587\u6cd5\u548c\u53e5\u6cd5\u9032\u884c\u53e5\u5b50\u5c64\u7d1a\u7684\u8a55\u4f30\uff0c\u4ee5\u9032\u884c\u5168\u9762\u7684\u5206\u6790\u3002\u70ba\u4e86\u6539\u5584\u5c0d LLM \u751f\u6210\u7684\u6587\u5b57\u4e2d\u7d30\u5fae\u5dee\u7570\u7684\u5075\u6e2c\uff0c\u4e26\u589e\u5f37\u5c0d\u6539\u5beb\u7684\u5065\u58ef\u6027\uff0c\u6211\u5011\u63a1\u7528\u4e86\u5169\u7a2e\u4e3b\u6d41\u7684\u898f\u907f\u6280\u8853\u4f86\u6539\u5beb\u6587\u5b57\u3002\u9019\u4e9b\u8b8a\u9ad4\u9023\u540c\u539f\u59cb\u6587\u5b57\uff0c\u7528\u65bc\u900f\u904e\u5c0d\u6bd4\u5b78\u7fd2\u8a13\u7df4\u6587\u5b57\u7de8\u78bc\u5668\uff0c\u63d0\u53d6\u53e5\u5b50\u7684\u9ad8\u5c64\u7d1a\u8a9e\u610f\u7279\u5fb5\uff0c\u4ee5\u63d0\u5347\u5075\u6e2c\u7684\u6982\u5316\u80fd\u529b\u3002\u6b64\u5916\uff0c\u6211\u5011\u5229\u7528\u5148\u9032\u7684 LLM \u4f86\u5206\u6790\u6574\u500b\u6587\u5b57\u4e26\u63d0\u53d6\u6df1\u5c64\u7d1a\u8a9e\u8a00\u7279\u5fb5\uff0c\u589e\u5f37\u6a21\u578b\u6355\u6349\u8907\u96dc\u6a21\u5f0f\u548c\u7d30\u5fae\u5dee\u522b\u7684\u80fd\u529b\uff0c\u540c\u6642\u6709\u6548\u5730\u7d0d\u5165\u4e0a\u4e0b\u6587\u8cc7\u8a0a\u3002\u5728\u516c\u5171\u8cc7\u6599\u96c6\u4e0a\u9032\u884c\u7684\u5ee3\u6cdb\u5be6\u9a57\u986f\u793a\uff0cMFD \u6a21\u578b\u512a\u65bc\u73fe\u6709\u65b9\u6cd5\uff0cMAE \u9054\u5230 0.1346\uff0c\u6e96\u78ba\u7387\u9054\u5230 88.56%\u3002\u6211\u5011\u7684\u7814\u7a76\u70ba\u6a5f\u69cb\u548c\u51fa\u7248\u5546\u63d0\u4f9b\u4e86\u5075\u6e2c LLM \u751f\u6210\u7684\u6587\u5b57\u7684\u6709\u6548\u6a5f\u5236\uff0c\u964d\u4f4e\u4e86\u4f5c\u8005\u8eab\u4efd\u53d7\u640d\u7684\u98a8\u96aa\u3002\u6559\u80b2\u5de5\u4f5c\u8005\u548c\u7de8\u8f2f\u53ef\u4ee5\u4f7f\u7528\u6a21\u578b\u7684\u9810\u6e2c\u4f86\u6539\u5584\u9a57\u8b49\u548c\u9810\u9632\u6284\u8972\u7684\u5354\u5b9a\uff0c\u78ba\u4fdd\u9075\u5b88\u6a19\u6e96\u3002", "author": "Zhen Tao et.al.", "authors": "Zhen Tao, Zhiyu Li, Runyu Chen, Dinghao Xi, Wei Xu", "id": "2410.14231v1", "paper_url": "http://arxiv.org/abs/2410.14231v1", "repo": "null"}}