{"2411.17438": {"publish_time": "2024-11-26", "title": "Object-centric proto-symbolic behavioural reasoning from pixels", "paper_summary": "Autonomous intelligent agents must bridge computational challenges at\ndisparate levels of abstraction, from the low-level spaces of sensory input and\nmotor commands to the high-level domain of abstract reasoning and planning. A\nkey question in designing such agents is how best to instantiate the\nrepresentational space that will interface between these two levels -- ideally\nwithout requiring supervision in the form of expensive data annotations. These\nobjectives can be efficiently achieved by representing the world in terms of\nobjects (grounded in perception and action). In this work, we present a novel,\nbrain-inspired, deep-learning architecture that learns from pixels to\ninterpret, control, and reason about its environment, using object-centric\nrepresentations. We show the utility of our approach through tasks in synthetic\nenvironments that require a combination of (high-level) logical reasoning and\n(low-level) continuous control. Results show that the agent can learn emergent\nconditional behavioural reasoning, such as $(A \\to B) \\land (\\neg A \\to C)$, as\nwell as logical composition $(A \\to B) \\land (A \\to C) \\vdash A \\to (B \\land\nC)$ and XOR operations, and successfully controls its environment to satisfy\nobjectives deduced from these logical rules. The agent can adapt online to\nunexpected changes in its environment and is robust to mild violations of its\nworld model, thanks to dynamic internal desired goal generation. While the\npresent results are limited to synthetic settings (2D and 3D activated versions\nof dSprites), which fall short of real-world levels of complexity, the proposed\narchitecture shows how to manipulate grounded object representations, as a key\ninductive bias for unsupervised learning, to enable behavioral reasoning.", "paper_summary_zh": "\u81ea\u4e3b\u667a\u80fd\u4ee3\u7406\u5fc5\u9808\u5f4c\u5408\u4e0d\u540c\u62bd\u8c61\u5c64\u7d1a\u7684\u8a08\u7b97\u6311\u6230\uff0c\u5f9e\u611f\u5b98\u8f38\u5165\u548c\u904b\u52d5\u547d\u4ee4\u7684\u4f4e\u968e\u5c64\u7d1a\u7a7a\u9593\u5230\u62bd\u8c61\u63a8\u7406\u548c\u898f\u5283\u7684\u9ad8\u968e\u5c64\u7d1a\u9818\u57df\u3002\u5728\u8a2d\u8a08\u6b64\u985e\u4ee3\u7406\u6642\uff0c\u4e00\u500b\u95dc\u9375\u554f\u984c\u662f\u5982\u4f55\u6700\u4f73\u5be6\u4f8b\u5316\u4ecb\u65bc\u9019\u5169\u500b\u5c64\u7d1a\u4e4b\u9593\u7684\u8868\u5fb5\u7a7a\u9593\uff0c\u7406\u60f3\u60c5\u6cc1\u4e0b\u4e0d\u9700\u8981\u4ee5\u6602\u8cb4\u7684\u8cc7\u6599\u8a3b\u91cb\u5f62\u5f0f\u9032\u884c\u76e3\u7763\u3002\u9019\u4e9b\u76ee\u6a19\u53ef\u900f\u904e\u4ee5\u7269\u4ef6\uff08\u4ee5\u611f\u77e5\u548c\u52d5\u4f5c\u70ba\u57fa\u790e\uff09\u4f86\u8868\u5fb5\u4e16\u754c\u4f86\u6709\u6548\u9054\u6210\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u65b0\u7a4e\u3001\u53d7\u5927\u8166\u555f\u767c\u7684\u6df1\u5ea6\u5b78\u7fd2\u67b6\u69cb\uff0c\u5b83\u5f9e\u50cf\u7d20\u5b78\u7fd2\u4f86\u8a6e\u91cb\u3001\u63a7\u5236\u548c\u63a8\u7406\u5176\u74b0\u5883\uff0c\u4f7f\u7528\u4ee5\u7269\u4ef6\u70ba\u4e2d\u5fc3\u7684\u8868\u5fb5\u3002\u6211\u5011\u900f\u904e\u5408\u6210\u74b0\u5883\u4e2d\u7684\u4efb\u52d9\u5c55\u793a\u6211\u5011\u65b9\u6cd5\u7684\u6548\u7528\uff0c\u9019\u4e9b\u4efb\u52d9\u9700\u8981\uff08\u9ad8\u968e\uff09\u908f\u8f2f\u63a8\u7406\u548c\uff08\u4f4e\u968e\uff09\u9023\u7e8c\u63a7\u5236\u7684\u7d44\u5408\u3002\u7d50\u679c\u986f\u793a\u4ee3\u7406\u53ef\u4ee5\u5b78\u7fd2\u65b0\u8208\u7684\u689d\u4ef6\u884c\u70ba\u63a8\u7406\uff0c\u4f8b\u5982 $(A \\to B) \\land (\\neg A \\to C)$\uff0c\u4ee5\u53ca\u908f\u8f2f\u7d44\u5408 $(A \\to B) \\land (A \\to C) \\vdash A \\to (B \\land C)$ \u548c XOR \u904b\u7b97\uff0c\u4e26\u6210\u529f\u63a7\u5236\u5176\u74b0\u5883\u4ee5\u6eff\u8db3\u5f9e\u9019\u4e9b\u908f\u8f2f\u898f\u5247\u63a8\u5c0e\u51fa\u7684\u76ee\u6a19\u3002\u4ee3\u7406\u53ef\u4ee5\u7dda\u4e0a\u9069\u61c9\u5176\u74b0\u5883\u4e2d\u7684\u610f\u5916\u8b8a\u5316\uff0c\u4e26\u4e14\u7531\u65bc\u52d5\u614b\u7684\u5167\u90e8\u76ee\u6a19\u7522\u751f\uff0c\u56e0\u6b64\u5c0d\u5176\u4e16\u754c\u6a21\u578b\u7684\u8f15\u5fae\u9055\u898f\u5177\u6709\u9b6f\u68d2\u6027\u3002\u96d6\u7136\u76ee\u524d\u7684\u7d50\u679c\u50c5\u9650\u65bc\u5408\u6210\u8a2d\u5b9a\uff08dSprites \u7684 2D \u548c 3D \u555f\u52d5\u7248\u672c\uff09\uff0c\u5176\u8907\u96dc\u6027\u4f4e\u65bc\u771f\u5be6\u4e16\u754c\uff0c\u4f46\u6240\u63d0\u51fa\u7684\u67b6\u69cb\u5c55\u793a\u4e86\u5982\u4f55\u64cd\u4f5c\u63a5\u5730\u7684\u7269\u4ef6\u8868\u5fb5\uff0c\u4f5c\u70ba\u7121\u76e3\u7763\u5b78\u7fd2\u7684\u4e3b\u8981\u6b78\u7d0d\u504f\u5dee\uff0c\u4ee5\u5be6\u73fe\u884c\u70ba\u63a8\u7406\u3002", "author": "Ruben van Bergen et.al.", "authors": "Ruben van Bergen, Justus H\u00fcbotter, Pablo Lanillos", "id": "2411.17438v1", "paper_url": "http://arxiv.org/abs/2411.17438v1", "repo": "https://github.com/neuro-ai-robotics/OBR"}}