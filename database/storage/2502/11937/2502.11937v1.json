{"2502.11937": {"publish_time": "2025-02-17", "title": "FitLight: Federated Imitation Learning for Plug-and-Play Autonomous Traffic Signal Control", "paper_summary": "Although Reinforcement Learning (RL)-based Traffic Signal Control (TSC)\nmethods have been extensively studied, their practical applications still raise\nsome serious issues such as high learning cost and poor generalizability. This\nis because the ``trial-and-error'' training style makes RL agents extremely\ndependent on the specific traffic environment, which also requires a long\nconvergence time. To address these issues, we propose a novel Federated\nImitation Learning (FIL)-based framework for multi-intersection TSC, named\nFitLight, which allows RL agents to plug-and-play for any traffic environment\nwithout additional pre-training cost. Unlike existing imitation learning\napproaches that rely on pre-training RL agents with demonstrations, FitLight\nallows real-time imitation learning and seamless transition to reinforcement\nlearning. Due to our proposed knowledge-sharing mechanism and novel hybrid\npressure-based agent design, RL agents can quickly find a best control policy\nwith only a few episodes. Moreover, for resource-constrained TSC scenarios,\nFitLight supports model pruning and heterogeneous model aggregation, such that\nRL agents can work on a micro-controller with merely 16{\\it KB} RAM and 32{\\it\nKB} ROM. Extensive experiments demonstrate that, compared to state-of-the-art\nmethods, FitLight not only provides a superior starting point but also\nconverges to a better final solution on both real-world and synthetic datasets,\neven under extreme resource limitations.", "paper_summary_zh": "\u5118\u7ba1\u57fa\u65bc\u5f37\u5316\u5b78\u7fd2 (RL) \u7684\u4ea4\u901a\u865f\u8a8c\u63a7\u5236 (TSC) \u65b9\u6cd5\u5df2\u7d93\u5ee3\u6cdb\u7814\u7a76\uff0c\u4f46\u5176\u5be6\u969b\u61c9\u7528\u4ecd\u6703\u7522\u751f\u4e00\u4e9b\u56b4\u91cd\u7684\u554f\u984c\uff0c\u4f8b\u5982\u5b78\u7fd2\u6210\u672c\u9ad8\u548c\u6cdb\u5316\u80fd\u529b\u5dee\u3002\u9019\u662f\u56e0\u70ba\u300c\u8a66\u932f\u6cd5\u300d\u8a13\u7df4\u98a8\u683c\u8b93 RL \u4ee3\u7406\u6975\u5ea6\u4f9d\u8cf4\u7279\u5b9a\u7684\u4ea4\u901a\u74b0\u5883\uff0c\u9019\u4e5f\u9700\u8981\u5f88\u9577\u7684\u6536\u6582\u6642\u9593\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u540d\u70ba FitLight \u7684\u57fa\u65bc\u806f\u90a6\u6a21\u4eff\u5b78\u7fd2 (FIL) \u7684\u591a\u8def\u53e3 TSC \u6846\u67b6\uff0c\u8b93 RL \u4ee3\u7406\u53ef\u4ee5\u5373\u63d2\u5373\u7528\u65bc\u4efb\u4f55\u4ea4\u901a\u74b0\u5883\uff0c\u800c\u7121\u9700\u984d\u5916\u7684\u9810\u8a13\u7df4\u6210\u672c\u3002\u8207\u4f9d\u8cf4\u4f7f\u7528\u793a\u7bc4\u9810\u8a13\u7df4 RL \u4ee3\u7406\u7684\u73fe\u6709\u6a21\u4eff\u5b78\u7fd2\u65b9\u6cd5\u4e0d\u540c\uff0cFitLight \u5141\u8a31\u5373\u6642\u6a21\u4eff\u5b78\u7fd2\u548c\u7121\u7e2b\u904e\u6e21\u5230\u5f37\u5316\u5b78\u7fd2\u3002\u7531\u65bc\u6211\u5011\u63d0\u51fa\u7684\u77e5\u8b58\u5171\u4eab\u6a5f\u5236\u548c\u65b0\u7a4e\u7684\u57fa\u65bc\u58d3\u529b\u7684\u6df7\u5408\u4ee3\u7406\u8a2d\u8a08\uff0cRL \u4ee3\u7406\u53ea\u9700\u5e7e\u500b\u56de\u5408\u5373\u53ef\u5feb\u901f\u627e\u5230\u6700\u4f73\u63a7\u5236\u7b56\u7565\u3002\u6b64\u5916\uff0c\u5c0d\u65bc\u8cc7\u6e90\u53d7\u9650\u7684 TSC \u5834\u666f\uff0cFitLight \u652f\u63f4\u6a21\u578b\u526a\u679d\u548c\u7570\u8cea\u6a21\u578b\u805a\u5408\uff0c\u8b93 RL \u4ee3\u7406\u53ef\u4ee5\u5728\u50c5\u6709 16{\\it KB} RAM \u548c 32{\\it KB} ROM \u7684\u5fae\u63a7\u5236\u5668\u4e0a\u904b\u884c\u3002\u5ee3\u6cdb\u7684\u5be6\u9a57\u8b49\u660e\uff0c\u8207\u6700\u5148\u9032\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0cFitLight \u4e0d\u50c5\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u8d77\u9ede\uff0c\u800c\u4e14\u5728\u5be6\u969b\u548c\u5408\u6210\u8cc7\u6599\u96c6\u4e0a\u90fd\u80fd\u6536\u6582\u5230\u66f4\u597d\u7684\u6700\u7d42\u89e3\u6c7a\u65b9\u6848\uff0c\u5373\u4f7f\u5728\u6975\u7aef\u7684\u8cc7\u6e90\u9650\u5236\u4e0b\u4e5f\u662f\u5982\u6b64\u3002", "author": "Yutong Ye et.al.", "authors": "Yutong Ye, Yingbo Zhou, Zhusen Liu, Xiao Du, Hao Zhou, Xiang Lian, Mingsong Chen", "id": "2502.11937v1", "paper_url": "http://arxiv.org/abs/2502.11937v1", "repo": "null"}}