{"2405.07667": {"publish_time": "2024-05-13", "title": "Backdoor Removal for Generative Large Language Models", "paper_summary": "With rapid advances, generative large language models (LLMs) dominate various\nNatural Language Processing (NLP) tasks from understanding to reasoning. Yet,\nlanguage models' inherent vulnerabilities may be exacerbated due to increased\naccessibility and unrestricted model training on massive textual data from the\nInternet. A malicious adversary may publish poisoned data online and conduct\nbackdoor attacks on the victim LLMs pre-trained on the poisoned data.\nBackdoored LLMs behave innocuously for normal queries and generate harmful\nresponses when the backdoor trigger is activated. Despite significant efforts\npaid to LLMs' safety issues, LLMs are still struggling against backdoor\nattacks. As Anthropic recently revealed, existing safety training strategies,\nincluding supervised fine-tuning (SFT) and Reinforcement Learning from Human\nFeedback (RLHF), fail to revoke the backdoors once the LLM is backdoored during\nthe pre-training stage. In this paper, we present Simulate and Eliminate\n(SANDE) to erase the undesired backdoored mappings for generative LLMs. We\ninitially propose Overwrite Supervised Fine-tuning (OSFT) for effective\nbackdoor removal when the trigger is known. Then, to handle the scenarios where\nthe trigger patterns are unknown, we integrate OSFT into our two-stage\nframework, SANDE. Unlike previous works that center on the identification of\nbackdoors, our safety-enhanced LLMs are able to behave normally even when the\nexact triggers are activated. We conduct comprehensive experiments to show that\nour proposed SANDE is effective against backdoor attacks while bringing minimal\nharm to LLMs' powerful capability without any additional access to unbackdoored\nclean models. We will release the reproducible code.", "paper_summary_zh": "<paragraph>\u96a8\u8457\u5feb\u901f\u9032\u5c55\uff0c\u751f\u6210\u5f0f\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4e3b\u5c0e\u8457\u5f9e\u7406\u89e3\u5230\u63a8\u7406\u7684\u5404\u7a2e\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u4efb\u52d9\u3002\u7136\u800c\uff0c\u7531\u65bc\u5f9e\u7db2\u969b\u7db2\u8def\u4e0a\u53d6\u5f97\u5927\u91cf\u6587\u672c\u8cc7\u6599\u7684\u4fbf\u5229\u6027\u589e\u52a0\uff0c\u4ee5\u53ca\u6a21\u578b\u8a13\u7df4\u4e0d\u53d7\u9650\u5236\uff0c\u8a9e\u8a00\u6a21\u578b\u56fa\u6709\u7684\u6f0f\u6d1e\u53ef\u80fd\u6703\u56e0\u6b64\u800c\u60e1\u5316\u3002\u60e1\u610f\u653b\u64ca\u8005\u53ef\u80fd\u6703\u5728\u7db2\u8def\u4e0a\u767c\u5e03\u4e2d\u6bd2\u8cc7\u6599\uff0c\u4e26\u5c0d\u9810\u5148\u8a13\u7df4\u904e\u4e2d\u6bd2\u8cc7\u6599\u7684\u53d7\u5bb3 LLM \u9032\u884c\u5f8c\u9580\u653b\u64ca\u3002\u5f8c\u9580 LLM \u5c0d\u4e00\u822c\u67e5\u8a62\u8868\u73fe\u5f97\u7121\u5bb3\uff0c\u4f46\u5728\u5f8c\u9580\u89f8\u767c\u5668\u555f\u52d5\u6642\u6703\u7522\u751f\u6709\u5bb3\u7684\u56de\u61c9\u3002\u5118\u7ba1\u5df2\u5c0d LLM \u7684\u5b89\u5168\u6027\u554f\u984c\u4ed8\u51fa\u4e86\u76f8\u7576\u5927\u7684\u52aa\u529b\uff0c\u4f46 LLM \u4ecd\u7136\u96e3\u4ee5\u62b5\u79a6\u5f8c\u9580\u653b\u64ca\u3002\u6b63\u5982 Anthropic \u6700\u8fd1\u63ed\u9732\u7684\uff0c\u73fe\u6709\u7684\u5b89\u5168\u8a13\u7df4\u7b56\u7565\uff0c\u5305\u62ec\u76e3\u7763\u5fae\u8abf (SFT) \u548c\u4eba\u985e\u56de\u994b\u5f37\u5316\u5b78\u7fd2 (RLHF)\uff0c\u4e00\u65e6 LLM \u5728\u9810\u8a13\u7df4\u968e\u6bb5\u906d\u5230\u5f8c\u9580\u653b\u64ca\uff0c\u5c31\u7121\u6cd5\u64a4\u92b7\u5f8c\u9580\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u6a21\u64ec\u548c\u6d88\u9664 (SANDE) \u4f86\u6d88\u9664\u751f\u6210\u5f0f LLM \u4e2d\u4e0d\u9700\u8981\u7684\u5f8c\u9580\u5c0d\u61c9\u3002\u6211\u5011\u6700\u521d\u63d0\u51fa\u8986\u5beb\u76e3\u7763\u5fae\u8abf (OSFT)\uff0c\u4ee5\u4fbf\u5728\u5df2\u77e5\u89f8\u767c\u5668\u6642\u6709\u6548\u79fb\u9664\u5f8c\u9580\u3002\u7136\u5f8c\uff0c\u70ba\u4e86\u8655\u7406\u89f8\u767c\u5668\u6a21\u5f0f\u672a\u77e5\u7684\u60c5\u6cc1\uff0c\u6211\u5011\u5c07 OSFT \u6574\u5408\u5230\u6211\u5011\u7684\u5169\u968e\u6bb5\u67b6\u69cb SANDE \u4e2d\u3002\u8207\u4e4b\u524d\u5c08\u6ce8\u65bc\u8b58\u5225\u5f8c\u9580\u7684\u8457\u4f5c\u4e0d\u540c\uff0c\u6211\u5011\u7684\u5b89\u5168\u589e\u5f37 LLM \u80fd\u5920\u5728\u6e96\u78ba\u7684\u89f8\u767c\u5668\u555f\u52d5\u6642\u6b63\u5e38\u904b\u4f5c\u3002\u6211\u5011\u9032\u884c\u4e86\u5168\u9762\u7684\u5be6\u9a57\uff0c\u4ee5\u8b49\u660e\u6211\u5011\u63d0\u51fa\u7684 SANDE \u80fd\u6709\u6548\u62b5\u79a6\u5f8c\u9580\u653b\u64ca\uff0c\u540c\u6642\u5c07\u5c0d LLM \u5f37\u5927\u529f\u80fd\u7684\u5371\u5bb3\u964d\u5230\u6700\u4f4e\uff0c\u800c\u7121\u9700\u984d\u5916\u53d6\u5f97\u672a\u53d7\u5f8c\u9580\u653b\u64ca\u7684\u4e7e\u6de8\u6a21\u578b\u3002\u6211\u5011\u5c07\u91cb\u51fa\u53ef\u91cd\u88fd\u7684\u7a0b\u5f0f\u78bc\u3002</paragraph>", "author": "Haoran Li et.al.", "authors": "Haoran Li, Yulin Chen, Zihao Zheng, Qi Hu, Chunkit Chan, Heshan Liu, Yangqiu Song", "id": "2405.07667v1", "paper_url": "http://arxiv.org/abs/2405.07667v1", "repo": "null"}}