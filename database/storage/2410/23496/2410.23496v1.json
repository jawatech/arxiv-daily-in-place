{"2410.23496": {"publish_time": "2024-10-30", "title": "Smaller Large Language Models Can Do Moral Self-Correction", "paper_summary": "Self-correction is one of the most amazing emerging capabilities of Large\nLanguage Models (LLMs), enabling LLMs to self-modify an inappropriate output\ngiven a natural language feedback which describes the problems of that output.\nMoral self-correction is a post-hoc approach correcting unethical generations\nwithout requiring a gradient update, making it both computationally lightweight\nand capable of preserving the language modeling ability. Previous works have\nshown that LLMs can self-debias, and it has been reported that small models,\ni.e., those with less than 22B parameters, are not capable of moral\nself-correction. However, there is no direct proof as to why such smaller\nmodels fall short of moral self-correction, though previous research\nhypothesizes that larger models are skilled in following instructions and\nunderstanding abstract social norms. In this paper, we empirically validate\nthis hypothesis in the context of social stereotyping, through meticulous\nprompting. Our experimental results indicate that (i) surprisingly, 3.8B LLMs\nwith proper safety alignment fine-tuning can achieve very good moral\nself-correction performance, highlighting the significant effects of safety\nalignment; and (ii) small LLMs are indeed weaker than larger-scale models in\nterms of comprehending social norms and self-explanation through CoT, but all\nscales of LLMs show bad self-correction performance given unethical\ninstructions.", "paper_summary_zh": "\u81ea\u6211\u4fee\u6b63\u662f\u5927\u8bed\u8a00\u6a21\u578b (LLM) \u6700\u4ee4\u4eba\u60ca\u53f9\u7684\u65b0\u5174\u529f\u80fd\u4e4b\u4e00\uff0c\u5b83\u4f7f LLM \u80fd\u591f\u6839\u636e\u63cf\u8ff0\u8be5\u8f93\u51fa\u95ee\u9898\u7684\u81ea\u7136\u8bed\u8a00\u53cd\u9988\u6765\u81ea\u6211\u4fee\u6539\u4e0d\u5f53\u7684\u8f93\u51fa\u3002\u9053\u5fb7\u81ea\u6211\u4fee\u6b63\u662f\u4e00\u79cd\u4e8b\u540e\u65b9\u6cd5\uff0c\u65e0\u9700\u68af\u5ea6\u66f4\u65b0\u5373\u53ef\u4fee\u6b63\u4e0d\u9053\u5fb7\u7684\u751f\u6210\uff0c\u4f7f\u5176\u65e2\u8ba1\u7b97\u91cf\u8f7b\u5de7\uff0c\u53c8\u80fd\u4fdd\u7559\u8bed\u8a00\u5efa\u6a21\u80fd\u529b\u3002\u5148\u524d\u7684\u7814\u7a76\u8868\u660e\uff0cLLM \u53ef\u4ee5\u81ea\u6211\u53bb\u504f\uff0c\u636e\u62a5\u9053\uff0c\u5c0f\u6a21\u578b\uff08\u5373\u53c2\u6570\u5c11\u4e8e 22B \u7684\u6a21\u578b\uff09\u65e0\u6cd5\u8fdb\u884c\u9053\u5fb7\u81ea\u6211\u4fee\u6b63\u3002\u7136\u800c\uff0c\u5bf9\u4e8e\u4e3a\u4ec0\u4e48\u8fd9\u4e9b\u8f83\u5c0f\u7684\u6a21\u578b\u65e0\u6cd5\u8fdb\u884c\u9053\u5fb7\u81ea\u6211\u4fee\u6b63\uff0c\u76ee\u524d\u8fd8\u6ca1\u6709\u76f4\u63a5\u7684\u8bc1\u636e\uff0c\u5c3d\u7ba1\u5148\u524d\u7684\u7814\u7a76\u5047\u8bbe\u8f83\u5927\u7684\u6a21\u578b\u5584\u4e8e\u9075\u5faa\u6307\u793a\u5e76\u7406\u89e3\u62bd\u8c61\u7684\u793e\u4f1a\u89c4\u8303\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u901a\u8fc7\u7ec6\u81f4\u7684\u63d0\u793a\uff0c\u5728\u793e\u4f1a\u523b\u677f\u5370\u8c61\u7684\u80cc\u666f\u4e0b\u5bf9\u8fd9\u4e00\u5047\u8bbe\u8fdb\u884c\u4e86\u5b9e\u8bc1\u9a8c\u8bc1\u3002\u6211\u4eec\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff1a(i) \u51fa\u4eba\u610f\u6599\u7684\u662f\uff0c\u5177\u6709\u9002\u5f53\u5b89\u5168\u5bf9\u9f50\u5fae\u8c03\u7684 3.8B LLM \u53ef\u4ee5\u5b9e\u73b0\u975e\u5e38\u597d\u7684\u9053\u5fb7\u81ea\u6211\u4fee\u6b63\u6027\u80fd\uff0c\u7a81\u51fa\u4e86\u5b89\u5168\u5bf9\u9f50\u7684\u663e\u7740\u5f71\u54cd\uff1b(ii) \u5728\u7406\u89e3\u793e\u4f1a\u89c4\u8303\u548c\u901a\u8fc7 CoT \u8fdb\u884c\u81ea\u6211\u89e3\u91ca\u65b9\u9762\uff0c\u5c0f\u578b LLM \u786e\u5b9e\u6bd4\u5927\u89c4\u6a21\u6a21\u578b\u5f31\uff0c\u4f46\u6240\u6709\u89c4\u6a21\u7684 LLM \u5728\u7ed9\u5b9a\u4e0d\u9053\u5fb7\u6307\u4ee4\u65f6\u90fd\u8868\u73b0\u51fa\u8f83\u5dee\u7684\u81ea\u6211\u4fee\u6b63\u6027\u80fd\u3002", "author": "Guangliang Liu et.al.", "authors": "Guangliang Liu, Zhiyu Xue, Rongrong Wang, Kristen Marie Johnson", "id": "2410.23496v1", "paper_url": "http://arxiv.org/abs/2410.23496v1", "repo": "null"}}