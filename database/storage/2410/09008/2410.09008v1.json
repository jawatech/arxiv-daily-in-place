{"2410.09008": {"publish_time": "2024-10-11", "title": "SuperCorrect: Supervising and Correcting Language Models with Error-Driven Insights", "paper_summary": "Large language models (LLMs) like GPT-4, PaLM, and LLaMA have shown\nsignificant improvements in various reasoning tasks. However, smaller models\nsuch as Llama-3-8B and DeepSeekMath-Base still struggle with complex\nmathematical reasoning because they fail to effectively identify and correct\nreasoning errors. Recent reflection-based methods aim to address these issues\nby enabling self-reflection and self-correction, but they still face challenges\nin independently detecting errors in their reasoning steps. To overcome these\nlimitations, we propose SuperCorrect, a novel two-stage framework that uses a\nlarge teacher model to supervise and correct both the reasoning and reflection\nprocesses of a smaller student model. In the first stage, we extract\nhierarchical high-level and detailed thought templates from the teacher model\nto guide the student model in eliciting more fine-grained reasoning thoughts.\nIn the second stage, we introduce cross-model collaborative direct preference\noptimization (DPO) to enhance the self-correction abilities of the student\nmodel by following the teacher's correction traces during training. This\ncross-model DPO approach teaches the student model to effectively locate and\nresolve erroneous thoughts with error-driven insights from the teacher model,\nbreaking the bottleneck of its thoughts and acquiring new skills and knowledge\nto tackle challenging problems. Extensive experiments consistently demonstrate\nour superiority over previous methods. Notably, our SuperCorrect-7B model\nsignificantly surpasses powerful DeepSeekMath-7B by 7.8%/5.3% and\nQwen2.5-Math-7B by 15.1%/6.3% on MATH/GSM8K benchmarks, achieving new SOTA\nperformance among all 7B models. Code:\nhttps://github.com/YangLing0818/SuperCorrect-llm", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u4f8b\u5982 GPT-4\u3001PaLM \u548c LLaMA\uff0c\u5df2\u5728\u5404\u7a2e\u63a8\u7406\u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u986f\u8457\u7684\u9032\u6b65\u3002\u7136\u800c\uff0c\u8f03\u5c0f\u7684\u6a21\u578b\uff0c\u4f8b\u5982 Llama-3-8B \u548c DeepSeekMath-Base \u4ecd\u96e3\u4ee5\u61c9\u5c0d\u8907\u96dc\u7684\u6578\u5b78\u63a8\u7406\uff0c\u56e0\u70ba\u5b83\u5011\u7121\u6cd5\u6709\u6548\u8b58\u5225\u548c\u7cfe\u6b63\u63a8\u7406\u932f\u8aa4\u3002\u6700\u8fd1\u57fa\u65bc\u53cd\u601d\u7684\u65b9\u6cd5\u65e8\u5728\u901a\u904e\u555f\u7528\u81ea\u6211\u53cd\u601d\u548c\u81ea\u6211\u7cfe\u6b63\u4f86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u4f46\u5b83\u5011\u5728\u7368\u7acb\u6aa2\u6e2c\u63a8\u7406\u6b65\u9a5f\u4e2d\u7684\u932f\u8aa4\u6642\u4ecd\u9762\u81e8\u6311\u6230\u3002\u70ba\u4e86\u514b\u670d\u9019\u4e9b\u9650\u5236\uff0c\u6211\u5011\u63d0\u51fa\u4e86 SuperCorrect\uff0c\u9019\u662f\u4e00\u500b\u65b0\u7a4e\u7684\u5169\u968e\u6bb5\u67b6\u69cb\uff0c\u5b83\u4f7f\u7528\u4e00\u500b\u5927\u578b\u6559\u5e2b\u6a21\u578b\u4f86\u76e3\u7763\u548c\u7cfe\u6b63\u8f03\u5c0f\u5b78\u751f\u6a21\u578b\u7684\u63a8\u7406\u548c\u53cd\u601d\u904e\u7a0b\u3002\u5728\u7b2c\u4e00\u968e\u6bb5\uff0c\u6211\u5011\u5f9e\u6559\u5e2b\u6a21\u578b\u4e2d\u63d0\u53d6\u5206\u5c64\u7684\u9ad8\u7d1a\u548c\u8a73\u7d30\u7684\u601d\u8003\u7bc4\u672c\uff0c\u4ee5\u6307\u5c0e\u5b78\u751f\u6a21\u578b\u5f15\u767c\u66f4\u7d30\u7dfb\u7684\u63a8\u7406\u601d\u8003\u3002\u5728\u7b2c\u4e8c\u968e\u6bb5\uff0c\u6211\u5011\u5f15\u5165\u4e86\u8de8\u6a21\u578b\u5354\u4f5c\u76f4\u63a5\u504f\u597d\u6700\u4f73\u5316\uff08DPO\uff09\uff0c\u4ee5\u901a\u904e\u5728\u8a13\u7df4\u671f\u9593\u9075\u5faa\u6559\u5e2b\u7684\u4fee\u6b63\u8ecc\u8de1\u4f86\u589e\u5f37\u5b78\u751f\u6a21\u578b\u7684\u81ea\u6211\u4fee\u6b63\u80fd\u529b\u3002\u9019\u7a2e\u8de8\u6a21\u578b DPO \u65b9\u6cd5\u6559\u5c0e\u5b78\u751f\u6a21\u578b\u6709\u6548\u5730\u5b9a\u4f4d\u548c\u89e3\u6c7a\u932f\u8aa4\u7684\u601d\u8003\uff0c\u4e26\u5f9e\u6559\u5e2b\u6a21\u578b\u4e2d\u7372\u5f97\u932f\u8aa4\u9a45\u52d5\u7684\u898b\u89e3\uff0c\u7a81\u7834\u5176\u601d\u8003\u7684\u74f6\u9838\uff0c\u4e26\u7372\u5f97\u89e3\u6c7a\u5177\u6709\u6311\u6230\u6027\u554f\u984c\u7684\u65b0\u6280\u80fd\u548c\u77e5\u8b58\u3002\u5ee3\u6cdb\u7684\u5be6\u9a57\u6301\u7e8c\u8b49\u660e\u4e86\u6211\u5011\u512a\u65bc\u5148\u524d\u65b9\u6cd5\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u6211\u5011\u7684 SuperCorrect-7B \u6a21\u578b\u5728 MATH/GSM8K \u57fa\u6e96\u6e2c\u8a66\u4e2d\u986f\u8457\u8d85\u8d8a\u4e86\u5f37\u5927\u7684 DeepSeekMath-7B 7.8%/5.3% \u548c Qwen2.5-Math-7B 15.1%/6.3%\uff0c\u5728\u6240\u6709 7B \u6a21\u578b\u4e2d\u5be6\u73fe\u4e86\u65b0\u7684 SOTA \u6548\u80fd\u3002\u7a0b\u5f0f\u78bc\uff1a\nhttps://github.com/YangLing0818/SuperCorrect-llm", "author": "Ling Yang et.al.", "authors": "Ling Yang, Zhaochen Yu, Tianjun Zhang, Minkai Xu, Joseph E. Gonzalez, Bin Cui, Shuicheng Yan", "id": "2410.09008v1", "paper_url": "http://arxiv.org/abs/2410.09008v1", "repo": "https://github.com/yangling0818/supercorrect-llm"}}