{"2410.19419": {"publish_time": "2024-10-25", "title": "KAHANI: Culturally-Nuanced Visual Storytelling Pipeline for Non-Western Cultures", "paper_summary": "Large Language Models (LLMs) and Text-To-Image (T2I) models have demonstrated\nthe ability to generate compelling text and visual stories. However, their\noutputs are predominantly aligned with the sensibilities of the Global North,\noften resulting in an outsider's gaze on other cultures. As a result,\nnon-Western communities have to put extra effort into generating culturally\nspecific stories. To address this challenge, we developed a visual storytelling\npipeline called KAHANI that generates culturally grounded visual stories for\nnon-Western cultures. Our pipeline leverages off-the-shelf models GPT-4 Turbo\nand Stable Diffusion XL (SDXL). By using Chain of Thought (CoT) and T2I\nprompting techniques, we capture the cultural context from user's prompt and\ngenerate vivid descriptions of the characters and scene compositions. To\nevaluate the effectiveness of KAHANI, we conducted a comparative user study\nwith ChatGPT-4 (with DALL-E3) in which participants from different regions of\nIndia compared the cultural relevance of stories generated by the two tools.\nResults from the qualitative and quantitative analysis performed on the user\nstudy showed that KAHANI was able to capture and incorporate more Culturally\nSpecific Items (CSIs) compared to ChatGPT-4. In terms of both its cultural\ncompetence and visual story generation quality, our pipeline outperformed\nChatGPT-4 in 27 out of the 36 comparisons.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u548c\u6587\u5b57\u8f49\u5716\u50cf (T2I) \u6a21\u578b\u5df2\u5c55\u73fe\u51fa\u751f\u6210\u5f15\u4eba\u5165\u52dd\u7684\u6587\u5b57\u548c\u8996\u89ba\u6545\u4e8b\u7684\u80fd\u529b\u3002\u7136\u800c\uff0c\u4ed6\u5011\u7684\u8f38\u51fa\u4e3b\u8981\u7b26\u5408\u5168\u7403\u5317\u65b9\u7684\u601d\u7dad\uff0c\u9019\u901a\u5e38\u5c0e\u81f4\u5c0d\u5176\u4ed6\u6587\u5316\u7684\u5916\u4eba\u89c0\u9ede\u3002\u56e0\u6b64\uff0c\u975e\u897f\u65b9\u793e\u7fa4\u5fc5\u9808\u4ed8\u51fa\u984d\u5916\u7684\u52aa\u529b\u4f86\u7522\u751f\u5177\u6709\u6587\u5316\u7279\u8272\u7684\u6545\u4e8b\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u9805\u6311\u6230\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u7a2e\u540d\u70ba KAHANI \u7684\u8996\u89ba\u6558\u4e8b\u7ba1\u9053\uff0c\u53ef\u70ba\u975e\u897f\u65b9\u6587\u5316\u7522\u751f\u5177\u6709\u6587\u5316\u57fa\u790e\u7684\u8996\u89ba\u6545\u4e8b\u3002\u6211\u5011\u7684\u7ba1\u9053\u5229\u7528\u73fe\u6210\u7684\u6a21\u578b GPT-4 Turbo \u548c Stable Diffusion XL (SDXL)\u3002\u900f\u904e\u4f7f\u7528\u601d\u8003\u93c8 (CoT) \u548c T2I \u63d0\u793a\u6280\u5de7\uff0c\u6211\u5011\u5f9e\u4f7f\u7528\u8005\u7684\u63d0\u793a\u4e2d\u64f7\u53d6\u6587\u5316\u80cc\u666f\uff0c\u4e26\u7522\u751f\u89d2\u8272\u548c\u5834\u666f\u69cb\u5716\u7684\u751f\u52d5\u63cf\u8ff0\u3002\u70ba\u4e86\u8a55\u4f30 KAHANI \u7684\u6548\u80fd\uff0c\u6211\u5011\u5c0d ChatGPT-4\uff08\u642d\u914d DALL-E3\uff09\u9032\u884c\u4e86\u4e00\u9805\u6bd4\u8f03\u4f7f\u7528\u8005\u7814\u7a76\uff0c\u5176\u4e2d\u4f86\u81ea\u5370\u5ea6\u4e0d\u540c\u5730\u5340\u7684\u53c3\u8207\u8005\u6bd4\u8f03\u4e86\u9019\u5169\u500b\u5de5\u5177\u6240\u7522\u751f\u6545\u4e8b\u7684\u6587\u5316\u76f8\u95dc\u6027\u3002\u5c0d\u4f7f\u7528\u8005\u7814\u7a76\u57f7\u884c\u7684\u5b9a\u6027\u548c\u5b9a\u91cf\u5206\u6790\u7d50\u679c\u986f\u793a\uff0c\u8207 ChatGPT-4 \u76f8\u6bd4\uff0cKAHANI \u80fd\u5920\u64f7\u53d6\u548c\u7d0d\u5165\u66f4\u591a\u6587\u5316\u7279\u5b9a\u9805\u76ee (CSI)\u3002\u5728\u6587\u5316\u80fd\u529b\u548c\u8996\u89ba\u6545\u4e8b\u751f\u6210\u54c1\u8cea\u65b9\u9762\uff0c\u6211\u5011\u7684\u7ba1\u9053\u5728 36 \u6b21\u6bd4\u8f03\u4e2d\u52dd\u904e ChatGPT-4 \u4e2d\u7684 27 \u6b21\u3002", "author": "Hamna et.al.", "authors": "Hamna, Deepthi Sudharsan, Agrima Seth, Ritvik Budhiraja, Deepika Khullar, Vyshak Jain, Kalika Bali, Aditya Vashistha, Sameer Segal", "id": "2410.19419v1", "paper_url": "http://arxiv.org/abs/2410.19419v1", "repo": "null"}}