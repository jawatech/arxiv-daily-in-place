{"2303.04731": {"publish_time": "2023-03-08", "title": "Towards Trust of Explainable AI in Thyroid Nodule Diagnosis", "paper_summary": "The ability to explain the prediction of deep learning models to end-users is\nan important feature to leverage the power of artificial intelligence (AI) for\nthe medical decision-making process, which is usually considered\nnon-transparent and challenging to comprehend. In this paper, we apply\nstate-of-the-art eXplainable artificial intelligence (XAI) methods to explain\nthe prediction of the black-box AI models in the thyroid nodule diagnosis\napplication. We propose new statistic-based XAI methods, namely Kernel Density\nEstimation and Density map, to explain the case of no nodule detected. XAI\nmethods' performances are considered under a qualitative and quantitative\ncomparison as feedback to improve the data quality and the model performance.\nFinally, we survey to assess doctors' and patients' trust in XAI explanations\nof the model's decisions on thyroid nodule images.", "paper_summary_zh": "", "author": "Truong Thanh Hung Nguyen et.al.", "authors": "Truong Thanh Hung Nguyen,Van Binh Truong,Vo Thanh Khang Nguyen,Quoc Hung Cao,Quoc Khanh Nguyen", "id": "2303.04731v1", "paper_url": "http://arxiv.org/abs/2303.04731v1", "repo": "https://github.com/hungntt/xai_thyroid"}}