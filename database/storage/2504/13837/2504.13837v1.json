{"2504.13837": {"publish_time": "2025-04-18", "title": "Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?", "paper_summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently\ndemonstrated notable success in enhancing the reasoning capabilities of LLMs,\nparticularly in mathematics and programming tasks. It is widely believed that\nRLVR enables LLMs to continuously self-improve, thus acquiring novel reasoning\nabilities that exceed corresponding base models' capacity. In this study,\nhowever, we critically re-examines this assumption by measuring the\npass@\\textit{k} metric with large values of \\textit{k} to explore the reasoning\ncapability boundary of the models across a wide range of model families and\nbenchmarks. Surprisingly, the RL does \\emph{not}, in fact, elicit fundamentally\nnew reasoning patterns. While RL-trained models outperform their base models at\nsmaller values of $k$ (\\eg, $k$=1), base models can achieve a comparable or\neven higher pass@$k$ score compared to their RL counterparts at large $k$\nvalues. The reasoning paths generated by RL-trained models are already included\nin the base models' sampling distribution, suggesting that most reasoning\nabilities manifested in RL-trained models are already obtained by base models.\nFurther analysis shows that RL training boosts the performance by biasing the\nmodel's output distribution toward paths that are more likely to yield rewards,\ntherefore sampling correct responses more efficiently. But this also results in\na narrower reasoning capability boundary compared to base models. Similar\nresults are observed in visual reasoning tasks trained with RLVR. Moreover, we\nfind that distillation can genuinely introduce new knowledge into the model,\ndifferent from RLVR. These findings underscore a critical limitation of RLVR in\nadvancing LLM reasoning abilities which requires us to fundamentally rethink\nthe impact of RL training in reasoning LLMs and the need of a better paradigm.\nProject Page: https://limit-of-RLVR.github.io", "paper_summary_zh": "<paragraph>\u4f7f\u7528\u53ef\u9a57\u8b49\u734e\u52f5\u7684\u5f37\u5316\u5b78\u7fd2 (RLVR) \u8fd1\u671f\u5728\u589e\u5f37\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u63a8\u7406\u80fd\u529b\u65b9\u9762\u5c55\u73fe\u4e86\u986f\u8457\u7684\u6210\u529f\uff0c\u5c24\u5176\u662f\u5728\u6578\u5b78\u548c\u7a0b\u5f0f\u8a2d\u8a08\u4efb\u52d9\u4e2d\u3002\u666e\u904d\u8a8d\u70ba\uff0cRLVR \u4f7f LLM \u80fd\u5920\u6301\u7e8c\u81ea\u6211\u6539\u9032\uff0c\u5f9e\u800c\u7372\u5f97\u8d85\u8d8a\u76f8\u61c9\u57fa\u790e\u6a21\u578b\u80fd\u529b\u7684\u65b0\u63a8\u7406\u80fd\u529b\u3002\u7136\u800c\uff0c\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u900f\u904e\u6e2c\u91cf\u5177\u6709\u8f03\u5927 \\textit{k} \u503c\u7684 pass@\\textit{k} \u6307\u6a19\uff0c\u4ee5\u63a2\u7d22\u5404\u7a2e\u6a21\u578b\u7cfb\u5217\u548c\u57fa\u6e96\u6e2c\u8a66\u4e2d\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u908a\u754c\uff0c\u6279\u5224\u6027\u5730\u91cd\u65b0\u5be9\u8996\u4e86\u9019\u4e00\u5047\u8a2d\u3002\u4ee4\u4eba\u9a5a\u8a1d\u7684\u662f\uff0c\u5f37\u5316\u5b78\u7fd2\u5be6\u969b\u4e0a\\emph{\u4e26\u672a} \u5f15\u767c\u6839\u672c\u4e0a\u7684\u65b0\u63a8\u7406\u6a21\u5f0f\u3002\u96d6\u7136\u7d93\u904e\u5f37\u5316\u5b78\u7fd2\u8a13\u7df4\u7684\u6a21\u578b\u5728\u8f03\u5c0f\u7684 $k$ \u503c\uff08\u4f8b\u5982 $k$=1\uff09\u4e0b\u8868\u73fe\u512a\u65bc\u5176\u57fa\u790e\u6a21\u578b\uff0c\u4f46\u5728\u8f03\u5927\u7684 $k$ \u503c\u4e0b\uff0c\u57fa\u790e\u6a21\u578b\u53ef\u4ee5\u9054\u5230\u8207\u5176\u5f37\u5316\u5b78\u7fd2\u5c0d\u61c9\u6a21\u578b\u76f8\u7576\u751a\u81f3\u66f4\u9ad8\u7684 pass@$k$ \u5206\u6578\u3002\u5f37\u5316\u5b78\u7fd2\u8a13\u7df4\u6a21\u578b\u7522\u751f\u7684\u63a8\u7406\u8def\u5f91\u5df2\u5305\u542b\u5728\u57fa\u790e\u6a21\u578b\u7684\u63a1\u6a23\u5206\u4f48\u4e2d\uff0c\u9019\u8868\u660e\u5f37\u5316\u5b78\u7fd2\u8a13\u7df4\u6a21\u578b\u4e2d\u9ad4\u73fe\u7684\u5927\u591a\u6578\u63a8\u7406\u80fd\u529b\u5df2\u7531\u57fa\u790e\u6a21\u578b\u7372\u5f97\u3002\u9032\u4e00\u6b65\u7684\u5206\u6790\u8868\u660e\uff0c\u5f37\u5316\u5b78\u7fd2\u8a13\u7df4\u900f\u904e\u5c07\u6a21\u578b\u7684\u8f38\u51fa\u5206\u4f48\u504f\u5411\u66f4\u6709\u53ef\u80fd\u7522\u751f\u734e\u52f5\u7684\u8def\u5f91\u4f86\u63d0\u9ad8\u6548\u80fd\uff0c\u5f9e\u800c\u66f4\u6709\u6548\u5730\u63a1\u6a23\u6b63\u78ba\u7684\u97ff\u61c9\u3002\u4f46\u9019\u4e5f\u5c0e\u81f4\u8207\u57fa\u790e\u6a21\u578b\u76f8\u6bd4\uff0c\u63a8\u7406\u80fd\u529b\u908a\u754c\u66f4\u7a84\u3002\u5728\u4f7f\u7528 RLVR \u8a13\u7df4\u7684\u8996\u89ba\u63a8\u7406\u4efb\u52d9\u4e2d\u4e5f\u89c0\u5bdf\u5230\u4e86\u985e\u4f3c\u7684\u7d50\u679c\u3002\u6b64\u5916\uff0c\u6211\u5011\u767c\u73fe\u84b8\u993e\u53ef\u4ee5\u771f\u6b63\u5730\u5c07\u65b0\u77e5\u8b58\u5f15\u5165\u6a21\u578b\u4e2d\uff0c\u9019\u8207 RLVR \u4e0d\u540c\u3002\u9019\u4e9b\u767c\u73fe\u7a81\u986f\u4e86 RLVR \u5728\u63d0\u5347 LLM \u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u4e00\u500b\u95dc\u9375\u9650\u5236\uff0c\u9019\u9700\u8981\u6211\u5011\u5f9e\u6839\u672c\u4e0a\u91cd\u65b0\u601d\u8003\u5f37\u5316\u5b78\u7fd2\u8a13\u7df4\u5c0d\u63a8\u7406 LLM \u7684\u5f71\u97ff\u4ee5\u53ca\u5c0d\u66f4\u597d\u7bc4\u5f0f\u7684\u9700\u6c42\u3002\u5c08\u6848\u9801\u9762\uff1ahttps://limit-of-RLVR.github.io</paragraph>\n", "author": "Yang Yue et.al.", "authors": "Yang Yue, Zhiqi Chen, Rui Lu, Andrew Zhao, Zhaokai Wang, Yang Yue, Shiji Song, Gao Huang", "id": "2504.13837v1", "paper_url": "http://arxiv.org/abs/2504.13837v1", "repo": "null"}}