{"2410.08669": {"publish_time": "2024-10-11", "title": "SmartPretrain: Model-Agnostic and Dataset-Agnostic Representation Learning for Motion Prediction", "paper_summary": "Predicting the future motion of surrounding agents is essential for\nautonomous vehicles (AVs) to operate safely in dynamic, human-robot-mixed\nenvironments. However, the scarcity of large-scale driving datasets has\nhindered the development of robust and generalizable motion prediction models,\nlimiting their ability to capture complex interactions and road geometries.\nInspired by recent advances in natural language processing (NLP) and computer\nvision (CV), self-supervised learning (SSL) has gained significant attention in\nthe motion prediction community for learning rich and transferable scene\nrepresentations. Nonetheless, existing pre-training methods for motion\nprediction have largely focused on specific model architectures and single\ndataset, limiting their scalability and generalizability. To address these\nchallenges, we propose SmartPretrain, a general and scalable SSL framework for\nmotion prediction that is both model-agnostic and dataset-agnostic. Our\napproach integrates contrastive and reconstructive SSL, leveraging the\nstrengths of both generative and discriminative paradigms to effectively\nrepresent spatiotemporal evolution and interactions without imposing\narchitectural constraints. Additionally, SmartPretrain employs a\ndataset-agnostic scenario sampling strategy that integrates multiple datasets,\nenhancing data volume, diversity, and robustness. Extensive experiments on\nmultiple datasets demonstrate that SmartPretrain consistently improves the\nperformance of state-of-the-art prediction models across datasets, data splits\nand main metrics. For instance, SmartPretrain significantly reduces the\nMissRate of Forecast-MAE by 10.6%. These results highlight SmartPretrain's\neffectiveness as a unified, scalable solution for motion prediction, breaking\nfree from the limitations of the small-data regime. Codes are available at\nhttps://github.com/youngzhou1999/SmartPretrain", "paper_summary_zh": "<paragraph>\u5c0d\u65bc\u81ea\u99d5\u8eca (AV) \u5728\u52d5\u614b\u3001\u4eba\u6a5f\u6df7\u5408\u74b0\u5883\u4e2d\u5b89\u5168\u904b\u4f5c\u800c\u8a00\uff0c\u9810\u6e2c\u5468\u570d\u4ee3\u7406\u4eba\u7684\u672a\u4f86\u52d5\u4f5c\u81f3\u95dc\u91cd\u8981\u3002\u7136\u800c\uff0c\u5927\u898f\u6a21\u99d5\u99db\u8cc7\u6599\u96c6\u7684\u7a00\u7f3a\u963b\u7919\u4e86\u7a69\u5065\u4e14\u53ef\u6982\u5316\u7684\u52d5\u4f5c\u9810\u6e2c\u6a21\u578b\u7684\u958b\u767c\uff0c\u9650\u5236\u4e86\u5b83\u5011\u6355\u6349\u8907\u96dc\u4e92\u52d5\u548c\u9053\u8def\u5e7e\u4f55\u5f62\u72c0\u7684\u80fd\u529b\u3002\u5728\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u548c\u96fb\u8166\u8996\u89ba (CV) \u7684\u6700\u65b0\u9032\u5c55\u7684\u555f\u767c\u4e0b\uff0c\u81ea\u76e3\u7763\u5b78\u7fd2 (SSL) \u5728\u52d5\u4f5c\u9810\u6e2c\u793e\u7fa4\u4e2d\u7372\u5f97\u4e86\u986f\u8457\u95dc\u6ce8\uff0c\u7528\u65bc\u5b78\u7fd2\u8c50\u5bcc\u4e14\u53ef\u8f49\u79fb\u7684\u5834\u666f\u8868\u793a\u3002\u5118\u7ba1\u5982\u6b64\uff0c\u73fe\u6709\u7684\u52d5\u4f5c\u9810\u6e2c\u9810\u8a13\u7df4\u65b9\u6cd5\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u5c08\u6ce8\u65bc\u7279\u5b9a\u6a21\u578b\u67b6\u69cb\u548c\u55ae\u4e00\u8cc7\u6599\u96c6\uff0c\u9650\u5236\u4e86\u5b83\u5011\u7684\u53ef\u64f4\u5145\u6027\u548c\u53ef\u6982\u5316\u6027\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa\u4e86 SmartPretrain\uff0c\u4e00\u500b\u901a\u7528\u4e14\u53ef\u64f4\u5145\u7684 SSL \u6846\u67b6\uff0c\u7528\u65bc\u52d5\u4f5c\u9810\u6e2c\uff0c\u5b83\u65e2\u8207\u6a21\u578b\u7121\u95dc\u53c8\u8207\u8cc7\u6599\u96c6\u7121\u95dc\u3002\u6211\u5011\u7684\u505a\u6cd5\u6574\u5408\u4e86\u5c0d\u6bd4\u548c\u91cd\u5efa SSL\uff0c\u5229\u7528\u751f\u6210\u7bc4\u4f8b\u548c\u5224\u5225\u7bc4\u4f8b\u7684\u512a\u52e2\uff0c\u6709\u6548\u5730\u8868\u793a\u6642\u7a7a\u6f14\u5316\u548c\u4ea4\u4e92\uff0c\u800c\u4e0d\u6703\u65bd\u52a0\u67b6\u69cb\u7d04\u675f\u3002\u6b64\u5916\uff0cSmartPretrain \u63a1\u7528\u8207\u8cc7\u6599\u96c6\u7121\u95dc\u7684\u5834\u666f\u62bd\u6a23\u7b56\u7565\uff0c\u6574\u5408\u591a\u500b\u8cc7\u6599\u96c6\uff0c\u589e\u5f37\u8cc7\u6599\u91cf\u3001\u591a\u6a23\u6027\u548c\u7a69\u5065\u6027\u3002\u5728\u591a\u500b\u8cc7\u6599\u96c6\u4e0a\u7684\u5ee3\u6cdb\u5be6\u9a57\u8868\u660e\uff0cSmartPretrain \u6301\u7e8c\u6539\u5584\u4e86\u6700\u5148\u9032\u9810\u6e2c\u6a21\u578b\u5728\u8cc7\u6599\u96c6\u3001\u8cc7\u6599\u5206\u5272\u548c\u4e3b\u8981\u6307\u6a19\u4e0a\u7684\u6548\u80fd\u3002\u4f8b\u5982\uff0cSmartPretrain \u5c07 Forecast-MAE \u7684 MissRate \u5927\u5e45\u964d\u4f4e\u4e86 10.6%\u3002\u9019\u4e9b\u7d50\u679c\u7a81\u51fa\u4e86 SmartPretrain \u4f5c\u70ba\u52d5\u4f5c\u9810\u6e2c\u7684\u7d71\u4e00\u3001\u53ef\u64f4\u5145\u89e3\u6c7a\u65b9\u6848\u7684\u6709\u6548\u6027\uff0c\u64fa\u812b\u4e86\u5c0f\u8cc7\u6599\u96c6\u5236\u5ea6\u7684\u9650\u5236\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/youngzhou1999/SmartPretrain \u53d6\u5f97</paragraph>", "author": "Yang Zhou et.al.", "authors": "Yang Zhou, Hao Shao, Letian Wang, Steven L. Waslander, Hongsheng Li, Yu Liu", "id": "2410.08669v1", "paper_url": "http://arxiv.org/abs/2410.08669v1", "repo": "https://github.com/youngzhou1999/smartpretrain"}}