{"2408.11049": {"publish_time": "2024-08-20", "title": "MagicDec: Breaking the Latency-Throughput Tradeoff for Long Context Generation with Speculative Decoding", "paper_summary": "Large Language Models (LLMs) have become more prevalent in long-context\napplications such as interactive chatbots, document analysis, and agent\nworkflows, but it is challenging to serve long-context requests with low\nlatency and high throughput. Speculative decoding (SD) is a widely used\ntechnique to reduce latency without sacrificing performance but the\nconventional wisdom suggests that its efficacy is limited to small batch sizes.\nIn MagicDec, we show that surprisingly SD can achieve speedup even for a high\nthroughput inference regime for moderate to long sequences. More interestingly,\nan intelligent drafting strategy can achieve better speedup with increasing\nbatch size based on our rigorous analysis. MagicDec first identifies the\nbottleneck shifts with increasing batch size and sequence length, and uses\nthese insights to deploy speculative decoding more effectively for high\nthroughput inference. Then, it leverages draft models with sparse KV cache to\naddress the KV bottleneck that scales with both sequence length and batch size.\nThis finding underscores the broad applicability of speculative decoding in\nlong-context serving, as it can enhance throughput and reduce latency without\ncompromising accuracy. For moderate to long sequences, we demonstrate up to 2x\nspeedup for LLaMA-2-7B-32K and 1.84x speedup for LLaMA-3.1-8B when serving\nbatch sizes ranging from 32 to 256 on 8 NVIDIA A100 GPUs. The code is available\nat https://github.com/Infini-AI-Lab/MagicDec/.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4e92\u52d5\u5f0f\u804a\u5929\u6a5f\u5668\u4eba\u3001\u6587\u4ef6\u5206\u6790\u548c\u4ee3\u7406\u5de5\u4f5c\u6d41\u7a0b\u7b49\u9577\u8a9e\u5883\u61c9\u7528\u4e2d\u8b8a\u5f97\u8d8a\u4f86\u8d8a\u666e\u904d\uff0c\u4f46\u8981\u4ee5\u4f4e\u5ef6\u9072\u548c\u9ad8\u901a\u91cf\u63d0\u4f9b\u9577\u8a9e\u5883\u8acb\u6c42\u537b\u662f\u4e00\u9805\u6311\u6230\u3002\u63a8\u6e2c\u6027\u89e3\u78bc\uff08SD\uff09\u662f\u4e00\u7a2e\u5ee3\u6cdb\u4f7f\u7528\u7684\u6280\u8853\uff0c\u53ef\u4ee5\u5728\u4e0d\u72a7\u7272\u6548\u80fd\u7684\u60c5\u6cc1\u4e0b\u6e1b\u5c11\u5ef6\u9072\uff0c\u4f46\u50b3\u7d71\u89c0\u5ff5\u8a8d\u70ba\u5176\u6548\u529b\u50c5\u9650\u65bc\u5c0f\u6279\u6b21\u5927\u5c0f\u3002\u5728 MagicDec \u4e2d\uff0c\u6211\u5011\u5c55\u793a\u51fa\u4ee4\u4eba\u9a5a\u8a1d\u7684\u662f\uff0c\u5373\u4f7f\u5c0d\u65bc\u4e2d\u7b49\u81f3\u9577\u5e8f\u5217\u7684\u9ad8\u901a\u91cf\u63a8\u8ad6\u6a5f\u5236\uff0cSD \u4e5f\u53ef\u4ee5\u5be6\u73fe\u52a0\u901f\u3002\u66f4\u6709\u8da3\u7684\u662f\uff0c\u6839\u64da\u6211\u5011\u56b4\u8b39\u7684\u5206\u6790\uff0c\u4e00\u7a2e\u667a\u6167\u8d77\u8349\u7b56\u7565\u53ef\u4ee5\u96a8\u8457\u6279\u6b21\u5927\u5c0f\u7684\u589e\u52a0\u800c\u5be6\u73fe\u66f4\u597d\u7684\u52a0\u901f\u3002MagicDec \u9996\u5148\u627e\u51fa\u96a8\u8457\u6279\u6b21\u5927\u5c0f\u548c\u5e8f\u5217\u9577\u5ea6\u7684\u589e\u52a0\u800c\u7522\u751f\u7684\u74f6\u9838\u8f49\u79fb\uff0c\u4e26\u5229\u7528\u9019\u4e9b\u898b\u89e3\u66f4\u6709\u6548\u5730\u90e8\u7f72\u63a8\u6e2c\u6027\u89e3\u78bc\u4ee5\u9032\u884c\u9ad8\u901a\u91cf\u63a8\u8ad6\u3002\u7136\u5f8c\uff0c\u5b83\u5229\u7528\u5177\u6709\u7a00\u758f KV \u5feb\u53d6\u7684\u8349\u7a3f\u6a21\u578b\u4f86\u89e3\u6c7a KV \u74f6\u9838\uff0c\u800c\u8a72\u74f6\u9838\u6703\u96a8\u8457\u5e8f\u5217\u9577\u5ea6\u548c\u6279\u6b21\u5927\u5c0f\u800c\u64f4\u5c55\u3002\u9019\u4e00\u767c\u73fe\u5f37\u8abf\u4e86\u63a8\u6e2c\u6027\u89e3\u78bc\u5728\u9577\u8a9e\u5883\u670d\u52d9\u4e2d\u7684\u5ee3\u6cdb\u9069\u7528\u6027\uff0c\u56e0\u70ba\u5b83\u53ef\u4ee5\u5728\u4e0d\u5f71\u97ff\u6e96\u78ba\u6027\u7684\u60c5\u6cc1\u4e0b\u63d0\u9ad8\u901a\u91cf\u4e26\u6e1b\u5c11\u5ef6\u9072\u3002\u5c0d\u65bc\u4e2d\u7b49\u81f3\u9577\u5e8f\u5217\uff0c\u6211\u5011\u5c55\u793a\u4e86 LLaMA-2-7B-32K \u7684\u52a0\u901f\u6700\u9ad8\u9054 2 \u500d\uff0c\u4ee5\u53ca LLaMA-3.1-8B \u7684\u52a0\u901f\u6700\u9ad8\u9054 1.84 \u500d\uff0c\u540c\u6642\u5728 8 \u500b NVIDIA A100 GPU \u4e0a\u63d0\u4f9b 32 \u5230 256 \u7684\u6279\u6b21\u5927\u5c0f\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/Infini-AI-Lab/MagicDec/ \u53d6\u5f97\u3002", "author": "Jian Chen et.al.", "authors": "Jian Chen, Vashisth Tiwari, Ranajoy Sadhukhan, Zhuoming Chen, Jinyuan Shi, Ian En-Hsu Yen, Beidi Chen", "id": "2408.11049v2", "paper_url": "http://arxiv.org/abs/2408.11049v2", "repo": "null"}}