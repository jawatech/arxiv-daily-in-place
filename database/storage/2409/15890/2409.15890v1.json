{"2409.15890": {"publish_time": "2024-09-24", "title": "HLB: Benchmarking LLMs' Humanlikeness in Language Use", "paper_summary": "As synthetic data becomes increasingly prevalent in training language models,\nparticularly through generated dialogue, concerns have emerged that these\nmodels may deviate from authentic human language patterns, potentially losing\nthe richness and creativity inherent in human communication. This highlights\nthe critical need to assess the humanlikeness of language models in real-world\nlanguage use. In this paper, we present a comprehensive humanlikeness benchmark\n(HLB) evaluating 20 large language models (LLMs) using 10 psycholinguistic\nexperiments designed to probe core linguistic aspects, including sound, word,\nsyntax, semantics, and discourse (see\nhttps://huggingface.co/spaces/XufengDuan/HumanLikeness). To anchor these\ncomparisons, we collected responses from over 2,000 human participants and\ncompared them to outputs from the LLMs in these experiments.\n  For rigorous evaluation, we developed a coding algorithm that accurately\nidentified language use patterns, enabling the extraction of response\ndistributions for each task. By comparing the response distributions between\nhuman participants and LLMs, we quantified humanlikeness through distributional\nsimilarity. Our results reveal fine-grained differences in how well LLMs\nreplicate human responses across various linguistic levels. Importantly, we\nfound that improvements in other performance metrics did not necessarily lead\nto greater humanlikeness, and in some cases, even resulted in a decline. By\nintroducing psycholinguistic methods to model evaluation, this benchmark offers\nthe first framework for systematically assessing the humanlikeness of LLMs in\nlanguage use.", "paper_summary_zh": "\u96a8\u8457\u5408\u6210\u8cc7\u6599\u5728\u8a13\u7df4\u8a9e\u8a00\u6a21\u578b\u4e2d\u8b8a\u5f97\u8d8a\u4f86\u8d8a\u666e\u904d\uff0c\u7279\u5225\u662f\u900f\u904e\u7522\u751f\u7684\u5c0d\u8a71\uff0c\u4eba\u5011\u958b\u59cb\u64d4\u5fc3\u9019\u4e9b\u6a21\u578b\u53ef\u80fd\u6703\u504f\u96e2\u771f\u5be6\u7684\u4eba\u985e\u8a9e\u8a00\u6a21\u5f0f\uff0c\u6f5b\u5728\u55aa\u5931\u4eba\u985e\u6e9d\u901a\u4e2d\u56fa\u6709\u7684\u8c50\u5bcc\u6027\u548c\u5275\u9020\u529b\u3002\u9019\u51f8\u986f\u4e86\u5728\u73fe\u5be6\u4e16\u754c\u7684\u8a9e\u8a00\u4f7f\u7528\u4e2d\u8a55\u4f30\u8a9e\u8a00\u6a21\u578b\u7684\u4eba\u985e\u76f8\u4f3c\u6027\u7684\u95dc\u9375\u9700\u6c42\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u5168\u9762\u7684\u985e\u4eba\u57fa\u6e96 (HLB)\uff0c\u4f7f\u7528 10 \u500b\u5fc3\u7406\u8a9e\u8a00\u5b78\u5be6\u9a57\u8a55\u4f30 20 \u500b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)\uff0c\u9019\u4e9b\u5be6\u9a57\u65e8\u5728\u63a2\u8a0e\u6838\u5fc3\u8a9e\u8a00\u5b78\u65b9\u9762\uff0c\u5305\u62ec\u8072\u97f3\u3001\u8a5e\u5f59\u3001\u53e5\u6cd5\u3001\u8a9e\u7fa9\u548c\u8a9e\u7bc7\uff08\u8acb\u53c3\u95b1 https://huggingface.co/spaces/XufengDuan/HumanLikeness\uff09\u3002\u70ba\u4e86\u56fa\u5b9a\u9019\u4e9b\u6bd4\u8f03\uff0c\u6211\u5011\u6536\u96c6\u4e86\u4f86\u81ea 2,000 \u591a\u540d\u4eba\u985e\u53c3\u8207\u8005\u7684\u56de\u61c9\uff0c\u4e26\u5728\u9019\u4e9b\u5be6\u9a57\u4e2d\u5c07\u5b83\u5011\u8207 LLM \u7684\u8f38\u51fa\u9032\u884c\u6bd4\u8f03\u3002\u70ba\u4e86\u9032\u884c\u56b4\u8b39\u7684\u8a55\u4f30\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u7a2e\u7de8\u78bc\u6f14\u7b97\u6cd5\uff0c\u53ef\u4ee5\u6e96\u78ba\u8b58\u5225\u8a9e\u8a00\u4f7f\u7528\u6a21\u5f0f\uff0c\u5f9e\u800c\u80fd\u5920\u63d0\u53d6\u6bcf\u500b\u4efb\u52d9\u7684\u56de\u61c9\u5206\u4f48\u3002\u900f\u904e\u6bd4\u8f03\u4eba\u985e\u53c3\u8207\u8005\u548c LLM \u4e4b\u9593\u7684\u56de\u61c9\u5206\u4f48\uff0c\u6211\u5011\u900f\u904e\u5206\u4f48\u76f8\u4f3c\u6027\u91cf\u5316\u4e86\u985e\u4eba\u5ea6\u3002\u6211\u5011\u7684\u7d50\u679c\u63ed\u793a\u4e86 LLM \u5728\u4e0d\u540c\u8a9e\u8a00\u5c64\u7d1a\u8907\u88fd\u4eba\u985e\u56de\u61c9\u7684\u7d30\u5fae\u5dee\u7570\u3002\u91cd\u8981\u7684\u662f\uff0c\u6211\u5011\u767c\u73fe\u5176\u4ed6\u6548\u80fd\u6307\u6a19\u7684\u6539\u9032\u4e26\u4e0d\u4e00\u5b9a\u6703\u5c0e\u81f4\u66f4\u9ad8\u7684\u985e\u4eba\u5ea6\uff0c\u5728\u67d0\u4e9b\u60c5\u6cc1\u4e0b\uff0c\u751a\u81f3\u6703\u5c0e\u81f4\u4e0b\u964d\u3002\u900f\u904e\u5c07\u5fc3\u7406\u8a9e\u8a00\u5b78\u65b9\u6cd5\u5f15\u5165\u6a21\u578b\u8a55\u4f30\uff0c\u6b64\u57fa\u6e96\u63d0\u4f9b\u4e86\u7b2c\u4e00\u500b\u7cfb\u7d71\u6027\u8a55\u4f30 LLM \u5728\u8a9e\u8a00\u4f7f\u7528\u4e2d\u985e\u4eba\u5ea6\u7684\u67b6\u69cb\u3002", "author": "Xufeng Duan et.al.", "authors": "Xufeng Duan, Bei Xiao, Xuemei Tang, Zhenguang G. Cai", "id": "2409.15890v1", "paper_url": "http://arxiv.org/abs/2409.15890v1", "repo": "null"}}