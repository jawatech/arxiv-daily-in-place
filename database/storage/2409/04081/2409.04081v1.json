{"2409.04081": {"publish_time": "2024-09-06", "title": "UI-JEPA: Towards Active Perception of User Intent through Onscreen User Activity", "paper_summary": "Generating user intent from a sequence of user interface (UI) actions is a\ncore challenge in comprehensive UI understanding. Recent advancements in\nmultimodal large language models (MLLMs) have led to substantial progress in\nthis area, but their demands for extensive model parameters, computing power,\nand high latency makes them impractical for scenarios requiring lightweight,\non-device solutions with low latency or heightened privacy. Additionally, the\nlack of high-quality datasets has hindered the development of such lightweight\nmodels. To address these challenges, we propose UI-JEPA, a novel framework that\nemploys masking strategies to learn abstract UI embeddings from unlabeled data\nthrough self-supervised learning, combined with an LLM decoder fine-tuned for\nuser intent prediction. We also introduce two new UI-grounded multimodal\ndatasets, \"Intent in the Wild\" (IIW) and \"Intent in the Tame\" (IIT), designed\nfor few-shot and zero-shot UI understanding tasks. IIW consists of 1.7K videos\nacross 219 intent categories, while IIT contains 914 videos across 10\ncategories. We establish the first baselines for these datasets, showing that\nrepresentations learned using a JEPA-style objective, combined with an LLM\ndecoder, can achieve user intent predictions that match the performance of\nstate-of-the-art large MLLMs, but with significantly reduced annotation and\ndeployment resources. Measured by intent similarity scores, UI-JEPA outperforms\nGPT-4 Turbo and Claude 3.5 Sonnet by 10.0% and 7.2% respectively, averaged\nacross two datasets. Notably, UI-JEPA accomplishes the performance with a 50.5x\nreduction in computational cost and a 6.6x improvement in latency in the IIW\ndataset. These results underscore the effectiveness of UI-JEPA, highlighting\nits potential for lightweight, high-performance UI understanding.", "paper_summary_zh": "<paragraph>\u5f9e\u4f7f\u7528\u8005\u4ecb\u9762 (UI) \u52d5\u4f5c\u5e8f\u5217\u4e2d\u7522\u751f\u4f7f\u7528\u8005\u610f\u5716\uff0c\u662f\u5168\u9762\u7406\u89e3 UI \u7684\u6838\u5fc3\u6311\u6230\u3002\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM) \u7684\u6700\u65b0\u9032\u5c55\u5df2\u4fc3\u4f7f\u6b64\u9818\u57df\u53d6\u5f97\u5be6\u8cea\u9032\u5c55\uff0c\u4f46\u5176\u5c0d\u5927\u91cf\u6a21\u578b\u53c3\u6578\u3001\u904b\u7b97\u80fd\u529b\u548c\u9ad8\u5ef6\u9072\u6027\u7684\u9700\u6c42\uff0c\u4f7f\u5176\u4e0d\u9069\u7528\u65bc\u9700\u8981\u8f15\u91cf\u7d1a\u3001\u4f4e\u5ef6\u9072\u6216\u9ad8\u5ea6\u96b1\u79c1\u7684\u88dd\u7f6e\u89e3\u6c7a\u65b9\u6848\u3002\u6b64\u5916\uff0c\u7f3a\u4e4f\u9ad8\u54c1\u8cea\u8cc7\u6599\u96c6\u5df2\u963b\u7919\u6b64\u985e\u8f15\u91cf\u7d1a\u6a21\u578b\u7684\u958b\u767c\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u63d0\u51fa\u4e86 UI-JEPA\uff0c\u9019\u662f\u4e00\u500b\u65b0\u7a4e\u7684\u67b6\u69cb\uff0c\u63a1\u7528\u906e\u7f69\u7b56\u7565\uff0c\u900f\u904e\u81ea\u76e3\u7763\u5b78\u7fd2\u5f9e\u672a\u6a19\u8a3b\u7684\u8cc7\u6599\u4e2d\u5b78\u7fd2\u62bd\u8c61 UI \u5167\u5d4c\uff0c\u4e26\u7d50\u5408\u4e00\u500b\u91dd\u5c0d\u4f7f\u7528\u8005\u610f\u5716\u9810\u6e2c\u9032\u884c\u5fae\u8abf\u7684 LLM \u89e3\u78bc\u5668\u3002\u6211\u5011\u9084\u5f15\u5165\u4e86\u5169\u500b\u65b0\u7684 UI \u57fa\u790e\u591a\u6a21\u614b\u8cc7\u6599\u96c6\uff0c\u300cIntent in the Wild\u300d(IIW) \u548c\u300cIntent in the Tame\u300d(IIT)\uff0c\u5c08\u70ba\u5c11\u91cf\u6a23\u672c\u548c\u96f6\u6a23\u672c UI \u7406\u89e3\u4efb\u52d9\u800c\u8a2d\u8a08\u3002IIW \u5305\u542b 219 \u500b\u610f\u5716\u985e\u5225\u4e2d\u7684 1.7K \u500b\u5f71\u7247\uff0c\u800c IIT \u5247\u5305\u542b 10 \u500b\u985e\u5225\u4e2d\u7684 914 \u500b\u5f71\u7247\u3002\u6211\u5011\u70ba\u9019\u4e9b\u8cc7\u6599\u96c6\u5efa\u7acb\u4e86\u7b2c\u4e00\u500b\u57fa\u6e96\uff0c\u8868\u660e\u4f7f\u7528 JEPA \u98a8\u683c\u76ee\u6a19\u5b78\u7fd2\u7684\u8868\u5fb5\uff0c\u7d50\u5408 LLM \u89e3\u78bc\u5668\uff0c\u53ef\u4ee5\u9054\u6210\u8207\u6700\u5148\u9032\u7684\u5927\u578b MLLM \u76f8\u5339\u914d\u7684\u4f7f\u7528\u8005\u610f\u5716\u9810\u6e2c\uff0c\u4f46\u6a19\u8a3b\u548c\u90e8\u7f72\u8cc7\u6e90\u537b\u5927\u5e45\u6e1b\u5c11\u3002\u4ee5\u610f\u5716\u76f8\u4f3c\u6027\u5206\u6578\u8861\u91cf\uff0cUI-JEPA \u5728\u5169\u500b\u8cc7\u6599\u96c6\u7684\u5e73\u5747\u8868\u73fe\u512a\u65bc GPT-4 Turbo \u548c Claude 3.5 Sonnet\uff0c\u5206\u5225\u9ad8\u51fa 10.0% \u548c 7.2%\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0cUI-JEPA \u4ee5 50.5 \u500d\u7684\u904b\u7b97\u6210\u672c\u964d\u4f4e\u548c 6.6 \u500d\u7684 IIW \u8cc7\u6599\u96c6\u5ef6\u9072\u6027\u6539\u5584\uff0c\u9054\u5230\u4e86\u6b64\u6548\u80fd\u3002\u9019\u4e9b\u7d50\u679c\u5f37\u8abf\u4e86 UI-JEPA \u7684\u6709\u6548\u6027\uff0c\u7a81\u986f\u5176\u5728\u8f15\u91cf\u7d1a\u3001\u9ad8\u6027\u80fd UI \u7406\u89e3\u65b9\u9762\u7684\u6f5b\u529b\u3002</paragraph>", "author": "Yicheng Fu et.al.", "authors": "Yicheng Fu, Raviteja Anantha, Prabal Vashisht, Jianpeng Cheng, Etai Littwin", "id": "2409.04081v1", "paper_url": "http://arxiv.org/abs/2409.04081v1", "repo": "null"}}