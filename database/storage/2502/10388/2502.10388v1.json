{"2502.10388": {"publish_time": "2025-02-14", "title": "Aspect-Oriented Summarization for Psychiatric Short-Term Readmission Prediction", "paper_summary": "Recent progress in large language models (LLMs) has enabled the automated\nprocessing of lengthy documents even without supervised training on a\ntask-specific dataset. Yet, their zero-shot performance in complex tasks as\nopposed to straightforward information extraction tasks remains suboptimal. One\nfeasible approach for tasks with lengthy, complex input is to first summarize\nthe document and then apply supervised fine-tuning to the summary. However, the\nsummarization process inevitably results in some loss of information. In this\nstudy we present a method for processing the summaries of long documents aimed\nto capture different important aspects of the original document. We hypothesize\nthat LLM summaries generated with different aspect-oriented prompts contain\ndifferent \\textit{information signals}, and we propose methods to measure these\ndifferences. We introduce approaches to effectively integrate signals from\nthese different summaries for supervised training of transformer models. We\nvalidate our hypotheses on a high-impact task -- 30-day readmission prediction\nfrom a psychiatric discharge -- using real-world data from four hospitals, and\nshow that our proposed method increases the prediction performance for the\ncomplex task of predicting patient outcome.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u6700\u65b0\u9032\u5c55\u4f7f\u5f97\u5373\u4f7f\u6c92\u6709\u91dd\u5c0d\u7279\u5b9a\u4efb\u52d9\u8cc7\u6599\u96c6\u9032\u884c\u76e3\u7763\u5f0f\u8a13\u7df4\uff0c\u4e5f\u80fd\u81ea\u52d5\u8655\u7406\u5197\u9577\u7684\u6587\u6a94\u3002\u7136\u800c\uff0c\u5b83\u5011\u5728\u8907\u96dc\u4efb\u52d9\u4e2d\u7684\u96f6\u6b21\u5b78\u7fd2\u8868\u73fe\uff0c\u8207\u76f4\u63a5\u7684\u8cc7\u8a0a\u8403\u53d6\u4efb\u52d9\u76f8\u6bd4\uff0c\u4ecd\u7136\u4e0d\u662f\u6700\u4f73\u7684\u3002\u5c0d\u65bc\u6709\u5197\u9577\u3001\u8907\u96dc\u8f38\u5165\u7684\u4efb\u52d9\uff0c\u4e00\u7a2e\u53ef\u884c\u7684\u505a\u6cd5\u662f\u5148\u6458\u8981\u6587\u4ef6\uff0c\u7136\u5f8c\u5c0d\u6458\u8981\u9032\u884c\u76e3\u7763\u5f0f\u5fae\u8abf\u3002\u7136\u800c\uff0c\u6458\u8981\u904e\u7a0b\u4e0d\u53ef\u907f\u514d\u6703\u5c0e\u81f4\u4e00\u4e9b\u8cc7\u8a0a\u907a\u5931\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u8655\u7406\u9577\u6587\u6458\u8981\u7684\u65b9\u6cd5\uff0c\u65e8\u5728\u64f7\u53d6\u539f\u59cb\u6587\u4ef6\u4e2d\u7684\u4e0d\u540c\u91cd\u8981\u9762\u5411\u3002\u6211\u5011\u5047\u8a2d\u4f7f\u7528\u4e0d\u540c\u9762\u5411\u63d0\u793a\u7522\u751f\u7684 LLM \u6458\u8981\u5305\u542b\u4e0d\u540c\u7684\u300c\u8cc7\u8a0a\u8a0a\u865f\u300d\uff0c\u4e26\u4e14\u6211\u5011\u63d0\u51fa\u65b9\u6cd5\u4f86\u8861\u91cf\u9019\u4e9b\u5dee\u7570\u3002\u6211\u5011\u5f15\u5165\u4e86\u6709\u6548\u6574\u5408\u4f86\u81ea\u9019\u4e9b\u4e0d\u540c\u6458\u8981\u7684\u8a0a\u865f\uff0c\u4ee5\u9032\u884cTransformer\u6a21\u578b\u7684\u76e3\u7763\u5f0f\u8a13\u7df4\u7684\u65b9\u6cd5\u3002\u6211\u5011\u5728\u4e00\u500b\u9ad8\u5f71\u97ff\u529b\u7684\u4efb\u52d9\u4e0a\u9a57\u8b49\u4e86\u6211\u5011\u7684\u5047\u8a2d\u2014\u2014\u5f9e\u7cbe\u795e\u79d1\u51fa\u9662\u9810\u6e2c 30 \u5929\u518d\u5165\u9662\u2014\u2014\u4f7f\u7528\u4f86\u81ea\u56db\u5bb6\u91ab\u9662\u7684\u771f\u5be6\u4e16\u754c\u8cc7\u6599\uff0c\u4e26\u8b49\u660e\u6211\u5011\u63d0\u51fa\u7684\u65b9\u6cd5\u589e\u52a0\u4e86\u9810\u6e2c\u8907\u96dc\u7684\u60a3\u8005\u9810\u5f8c\u4efb\u52d9\u7684\u9810\u6e2c\u6548\u80fd\u3002", "author": "WonJin Yoon et.al.", "authors": "WonJin Yoon, Boyu Ren, Spencer Thomas, Chanwhi Kim, Guergana Savova, Mei-Hua Hall, Timothy Miller", "id": "2502.10388v1", "paper_url": "http://arxiv.org/abs/2502.10388v1", "repo": "null"}}