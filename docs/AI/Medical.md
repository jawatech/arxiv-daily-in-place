
### Medical
|Publish Date|Title|Authors|PDF|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-04-26**|**Domain Adaptive and Fine-grained Anomaly Detection for Single-cell Sequencing Data and Beyond**|Kaichen Xu et.al.|[2404.17454v1](http://arxiv.org/abs/2404.17454v1)|[link](https://github.com/catchxu/acsleuth)|
|**2024-04-26**|**M3BAT: Unsupervised Domain Adaptation for Multimodal Mobile Sensing with Multi-Branch Adversarial Training**|Lakmal Meegahapola et.al.|[2404.17391v1](http://arxiv.org/abs/2404.17391v1)|null|
|**2024-04-26**|**Prevalent Frequency of Emotional and Physical Symptoms in Social Anxiety using Zero Shot Classification: An Observational Study**|Muhammad Rizwan et.al.|[2404.17183v1](http://arxiv.org/abs/2404.17183v1)|null|
|**2024-04-26**|**Deep Evidential Learning for Dose Prediction**|Hai Siong Tan et.al.|[2404.17126v1](http://arxiv.org/abs/2404.17126v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-25**|**Taming False Positives in Out-of-Distribution Detection with Human Feedback**|Harit Vishwakarma et.al.|[2404.16954v1](http://arxiv.org/abs/2404.16954v1)|[link](https://github.com/2454511550lin/tamefalsepositives-ood)|
|**2024-04-25**|**Features Fusion for Dual-View Mammography Mass Detection**|Arina Varlamova et.al.|[2404.16718v1](http://arxiv.org/abs/2404.16718v1)|null|
|**2024-04-25**|**Report on Candidate Computational Indicators for Conscious Valenced Experience**|Andres Campero et.al.|[2404.16696v1](http://arxiv.org/abs/2404.16696v1)|null|
|**2024-04-25**|**ProbGate at EHRSQL 2024: Enhancing SQL Query Generation Accuracy through Probabilistic Threshold Filtering and Error Handling**|Sangryul Kim et.al.|[2404.16659v1](http://arxiv.org/abs/2404.16659v1)|[link](https://github.com/venzino-han/probgate_ehrsql)|
|**2024-04-25**|**Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare**|Emre Can Acikgoz et.al.|[2404.16621v1](http://arxiv.org/abs/2404.16621v1)|null|
|**2024-04-25**|**DiffSeg: A Segmentation Model for Skin Lesions Based on Diffusion Difference**|Zhihao Shuai et.al.|[2404.16474v1](http://arxiv.org/abs/2404.16474v1)|null|
|**2024-04-25**|**Light-weight Retinal Layer Segmentation with Global Reasoning**|Xiang He et.al.|[2404.16346v1](http://arxiv.org/abs/2404.16346v1)|null|
|**2024-04-25**|**Semantic Segmentation Refiner for Ultrasound Applications with Zero-Shot Foundation Models**|Hedda Cohen Indelman et.al.|[2404.16325v1](http://arxiv.org/abs/2404.16325v1)|null|
|**2024-04-25**|**LLM-Based Section Identifiers Excel on Open Source but Stumble in Real World Applications**|Saranya Krishnamoorthy et.al.|[2404.16294v1](http://arxiv.org/abs/2404.16294v1)|[link](https://github.com/inqbator-evicore/llm_section_identifiers)|
|**2024-04-24**|**Investigating the prompt leakage effect and black-box defenses for multi-turn LLM interactions**|Divyansh Agarwal et.al.|[2404.16251v2](http://arxiv.org/abs/2404.16251v2)|null|
|**2024-04-24**|**ABCD: Trust enhanced Attention based Convolutional Autoencoder for Risk Assessment**|Sarala Naidu et.al.|[2404.16183v1](http://arxiv.org/abs/2404.16183v1)|null|
|**2024-04-24**|**Mamba-360: Survey of State Space Models as Transformer Alternative for Long Sequence Modelling: Methods, Applications, and Challenges**|Badri Narayana Patro et.al.|[2404.16112v1](http://arxiv.org/abs/2404.16112v1)|[link](https://github.com/badripatro/mamba360)|
|**2024-04-24**|**Mammo-CLIP: Leveraging Contrastive Language-Image Pre-training (CLIP) for Enhanced Breast Cancer Diagnosis with Multi-view Mammography**|Xuxin Chen et.al.|[2404.15946v1](http://arxiv.org/abs/2404.15946v1)|null|
|**2024-04-24**|**Assessing The Potential Of Mid-Sized Language Models For Clinical QA**|Elliot Bolton et.al.|[2404.15894v1](http://arxiv.org/abs/2404.15894v1)|null|
|**2024-04-24**|**Enhancing Diagnosis through AI-driven Analysis of Reflectance Confocal Microscopy**|Hong-Jun Yoon et.al.|[2404.16080v1](http://arxiv.org/abs/2404.16080v1)|null|
|**2024-04-24**|**Anomaly Detection for Incident Response at Scale**|Hanzhang Wang et.al.|[2404.16887v1](http://arxiv.org/abs/2404.16887v1)|null|
|**2024-04-23**|**Adapting an Artificial Intelligence Sexually Transmitted Diseases Symptom Checker Tool for Mpox Detection: The HeHealth Experience**|Rayner Kay Jin Tan et.al.|[2404.16885v1](http://arxiv.org/abs/2404.16885v1)|null|
|**2024-04-23**|**PRISM: Patient Records Interpretation for Semantic Clinical Trial Matching using Large Language Models**|Shashi Kant Gupta et.al.|[2404.15549v1](http://arxiv.org/abs/2404.15549v1)|null|
|**2024-04-23**|**Multi-scale Intervention Planning based on Generative Design**|Ioannis Kavouras et.al.|[2404.15492v1](http://arxiv.org/abs/2404.15492v1)|null|
|**2024-04-23**|**IryoNLP at MEDIQA-CORR 2024: Tackling the Medical Error Detection & Correction Task On the Shoulders of Medical Agents**|Jean-Philippe Corbeil et.al.|[2404.15488v1](http://arxiv.org/abs/2404.15488v1)|[link](https://github.com/microsoft/iryonlp-mediqa-corr-2024)|
|**2024-04-23**|**Machine Learning Techniques with Fairness for Prediction of Completion of Drug and Alcohol Rehabilitation**|Karen Roberts-Licklider et.al.|[2404.15418v1](http://arxiv.org/abs/2404.15418v1)|null|
|**2024-04-23**|**CT-GLIP: 3D Grounded Language-Image Pretraining with CT Scans and Radiology Reports for Full-Body Scenarios**|Jingyang Lin et.al.|[2404.15272v2](http://arxiv.org/abs/2404.15272v2)|null|
|**2024-04-23**|**A review of deep learning-based information fusion techniques for multimodal medical image classification**|Yihao Li et.al.|[2404.15022v1](http://arxiv.org/abs/2404.15022v1)|null|
|**2024-04-23**|**Clustering of timed sequences -- Application to the analysis of care pathways**|Thomas Guyet et.al.|[2404.15379v1](http://arxiv.org/abs/2404.15379v1)|null|
|**2024-04-23**|**Grounded Knowledge-Enhanced Medical VLP for Chest X-Ray**|Qiao Deng et.al.|[2404.14750v1](http://arxiv.org/abs/2404.14750v1)|null|
|**2024-04-22**|**DAIC-WOZ: On the Validity of Using the Therapist's prompts in Automatic Depression Detection from Clinical Interviews**|Sergio Burdisso et.al.|[2404.14463v1](http://arxiv.org/abs/2404.14463v1)|null|
|**2024-04-22**|**Adaptive Collaboration Strategy for LLMs in Medical Decision Making**|Yubin Kim et.al.|[2404.15155v1](http://arxiv.org/abs/2404.15155v1)|[link](https://github.com/mitmedialab/mdagents)|
|**2024-04-21**|**A Nasal Cytology Dataset for Object Detection and Deep Learning**|Mauro Camporeale et.al.|[2404.13745v1](http://arxiv.org/abs/2404.13745v1)|null|
|**2024-04-21**|**Bt-GAN: Generating Fair Synthetic Healthdata via Bias-transforming Generative Adversarial Networks**|Resmi Ramachandranpillai et.al.|[2404.13634v3](http://arxiv.org/abs/2404.13634v3)|null|
|**2024-04-21**|**SmartMem: Layout Transformation Elimination and Adaptation for Efficient DNN Execution on Mobile**|Wei Niu et.al.|[2404.13528v1](http://arxiv.org/abs/2404.13528v1)|null|
|**2024-04-21**|**Parameter Efficient Fine Tuning: A Comprehensive Analysis Across Applications**|Charith Chandra Sai Balne et.al.|[2404.13506v2](http://arxiv.org/abs/2404.13506v2)|null|
|**2024-04-20**|**SiNC+: Adaptive Camera-Based Vitals with Unsupervised Learning of Periodic Signals**|Jeremy Speth et.al.|[2404.13449v1](http://arxiv.org/abs/2404.13449v1)|null|
|**2024-04-20**|**MultiConfederated Learning: Inclusive Non-IID Data handling with Decentralized Federated Learning**|Michael Duchesne et.al.|[2404.13421v1](http://arxiv.org/abs/2404.13421v1)|null|
|**2024-04-20**|**UnibucLLM: Harnessing LLMs for Automated Prediction of Item Difficulty and Response Time for Multiple-Choice Questions**|Ana-Cristina Rogoz et.al.|[2404.13343v1](http://arxiv.org/abs/2404.13343v1)|[link](https://github.com/ana-rogoz/bea-2024)|
|**2024-04-20**|**Practical Battery Health Monitoring using Uncertainty-Aware Bayesian Neural Network**|Yunyi Zhao et.al.|[2404.14444v1](http://arxiv.org/abs/2404.14444v1)|null|
|**2024-04-19**|**Beyond Self-Consistency: Ensemble Reasoning Boosts Consistency and Accuracy of LLMs in Cancer Staging**|Chia-Hsuan Chang et.al.|[2404.13149v1](http://arxiv.org/abs/2404.13149v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Eye-tracking in Mixed Reality for Diagnosis of Neurodegenerative Diseases**|Mateusz Daniol et.al.|[2404.12984v1](http://arxiv.org/abs/2404.12984v1)|null|
|**2024-04-19**|**A Large-scale Medical Visual Task Adaptation Benchmark**|Shentong Mo et.al.|[2404.12876v1](http://arxiv.org/abs/2404.12876v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v1](http://arxiv.org/abs/2404.12832v1)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-19**|**DensePANet: An improved generative adversarial network for photoacoustic tomography image reconstruction from sparse data**|Hesam Hakimnejad et.al.|[2404.13101v1](http://arxiv.org/abs/2404.13101v1)|null|
|**2024-04-19**|**Transformer-Based Classification Outcome Prediction for Multimodal Stroke Treatment**|Danqing Ma et.al.|[2404.12634v1](http://arxiv.org/abs/2404.12634v1)|null|
|**2024-04-19**|**GluMarker: A Novel Predictive Modeling of Glycemic Control Through Digital Biomarkers**|Ziyi Zhou et.al.|[2404.12605v1](http://arxiv.org/abs/2404.12605v1)|null|
|**2024-04-18**|**DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era**|David Restrepo et.al.|[2404.12278v1](http://arxiv.org/abs/2404.12278v1)|null|
|**2024-04-18**|**Relationship Discovery for Drug Recommendation**|Xiang Li et.al.|[2404.12228v1](http://arxiv.org/abs/2404.12228v1)|null|
|**2024-04-18**|**A Symmetric Regressor for MRI-Based Assessment of Striatal Dopamine Transporter Uptake in Parkinson's Disease**|Walid Abdullah Al et.al.|[2404.11929v1](http://arxiv.org/abs/2404.11929v1)|[link](https://github.com/awjibon/mri_dat)|
|**2024-04-18**|**Cross-model Mutual Learning for Exemplar-based Medical Image Segmentation**|Qing En et.al.|[2404.11812v1](http://arxiv.org/abs/2404.11812v1)|null|
|**2024-04-17**|**A Secure and Trustworthy Network Architecture for Federated Learning Healthcare Applications**|Antonio Boiano et.al.|[2404.11698v1](http://arxiv.org/abs/2404.11698v1)|null|
|**2024-04-17**|**Towards Reliable Empirical Machine Unlearning Evaluation: A Game-Theoretic View**|Yiwen Tu et.al.|[2404.11577v1](http://arxiv.org/abs/2404.11577v1)|null|
|**2024-04-17**|**Prompt-Guided Generation of Structured Chest X-Ray Report Using a Pre-trained LLM**|Hongzhao Li et.al.|[2404.11209v1](http://arxiv.org/abs/2404.11209v1)|null|
|**2024-04-17**|**Explainable Machine Learning System for Predicting Chronic Kidney Disease in High-Risk Cardiovascular Patients**|Nantika Nguycharoen et.al.|[2404.11148v1](http://arxiv.org/abs/2404.11148v1)|null|
|**2024-04-17**|**AKGNet: Attribute Knowledge-Guided Unsupervised Lung-Infected Area Segmentation**|Qing En et.al.|[2404.11008v1](http://arxiv.org/abs/2404.11008v1)|null|
|**2024-04-17**|**Leveraging 3D LiDAR Sensors to Enable Enhanced Urban Safety and Public Health: Pedestrian Monitoring and Abnormal Activity Detection**|Nawfal Guefrachi et.al.|[2404.10978v1](http://arxiv.org/abs/2404.10978v1)|null|
|**2024-04-16**|**CrossGP: Cross-Day Glucose Prediction Excluding Physiological Information**|Ziyi Zhou et.al.|[2404.10901v1](http://arxiv.org/abs/2404.10901v1)|null|
|**2024-04-16**|**Mixed Prototype Consistency Learning for Semi-supervised Medical Image Segmentation**|Lijian Li et.al.|[2404.10717v1](http://arxiv.org/abs/2404.10717v1)|null|
|**2024-04-16**|**AAVDiff: Experimental Validation of Enhanced Viability and Diversity in Recombinant Adeno-Associated Virus (AAV) Capsids through Diffusion Generation**|Lijun Liu et.al.|[2404.10573v2](http://arxiv.org/abs/2404.10573v2)|null|
|**2024-04-16**|**A Sentiment Analysis of Medical Text Based on Deep Learning**|Yinan Chen et.al.|[2404.10503v1](http://arxiv.org/abs/2404.10503v1)|null|
|**2024-04-16**|**Integration of Self-Supervised BYOL in Semi-Supervised Medical Image Recognition**|Hao Feng et.al.|[2404.10405v1](http://arxiv.org/abs/2404.10405v1)|null|
|**2024-04-16**|**Generating Counterfactual Trajectories with Latent Diffusion Models for Concept Discovery**|Payal Varshney et.al.|[2404.10356v1](http://arxiv.org/abs/2404.10356v1)|null|
|**2024-04-16**|**CARE to Compare: A real-world dataset for anomaly detection in wind turbine data**|Christian Gück et.al.|[2404.10320v2](http://arxiv.org/abs/2404.10320v2)|null|
|**2024-04-16**|**Clustering and Data Augmentation to Improve Accuracy of Sleep Assessment and Sleep Individuality Analysis**|Shintaro Tamai et.al.|[2404.10299v1](http://arxiv.org/abs/2404.10299v1)|null|
|**2024-04-15**|**Emergent Language Symbolic Autoencoder (ELSA) with Weak Supervision to Model Hierarchical Brain Networks**|Ammar Ahmed Pallikonda Latheef et.al.|[2404.10031v1](http://arxiv.org/abs/2404.10031v1)|null|
|**2024-04-15**|**Harnessing GPT-4V(ision) for Insurance: A Preliminary Exploration**|Chenwei Lin et.al.|[2404.09690v1](http://arxiv.org/abs/2404.09690v1)|null|
|**2024-04-15**|**Privacy-Preserving Intrusion Detection using Convolutional Neural Networks**|Martin Kodys et.al.|[2404.09625v1](http://arxiv.org/abs/2404.09625v1)|null|
|**2024-04-15**|**Efficient and accurate neural field reconstruction using resistive memory**|Yifei Yu et.al.|[2404.09613v1](http://arxiv.org/abs/2404.09613v1)|null|
|**2024-04-15**|**WiTUnet: A U-Shaped Architecture Integrating CNN and Transformer for Improved Feature Alignment and Local Information Fusion**|Bin Wang et.al.|[2404.09533v1](http://arxiv.org/abs/2404.09533v1)|[link](https://github.com/woldier/witunet)|
|**2024-04-14**|**Weight Copy and Low-Rank Adaptation for Few-Shot Distillation of Vision Transformers**|Diana-Nicoleta Grigore et.al.|[2404.09326v2](http://arxiv.org/abs/2404.09326v2)|null|
|**2024-04-14**|**Characterizing Soft-Error Resiliency in Arm's Ethos-U55 Embedded Machine Learning Accelerator**|Abhishek Tyagi et.al.|[2404.09317v1](http://arxiv.org/abs/2404.09317v1)|null|
|**2024-04-14**|**TLDR at SemEval-2024 Task 2: T5-generated clinical-Language summaries for DeBERTa Report Analysis**|Spandan Das et.al.|[2404.09136v1](http://arxiv.org/abs/2404.09136v1)|[link](https://github.com/shahriarnz14/tldr-t5-generated-clinical-language-for-deberta-report-analysis)|
|**2024-04-13**|**Advanced Neural Network Architecture for Enhanced Multi-Lead ECG Arrhythmia Detection through Optimized Feature Extraction**|Bhavith Chandra Challagundla et.al.|[2404.15347v1](http://arxiv.org/abs/2404.15347v1)|null|
|**2024-04-13**|**Adapting Mental Health Prediction Tasks for Cross-lingual Learning via Meta-Training and In-context Learning with Large Language Model**|Zita Lifelo et.al.|[2404.09045v1](http://arxiv.org/abs/2404.09045v1)|null|
|**2024-04-13**|**A Fourier-enhanced multi-modal 3D small object optical mark recognition and positioning method for percutaneous abdominal puncture surgical navigation**|Zezhao Guo et.al.|[2404.08990v1](http://arxiv.org/abs/2404.08990v1)|null|
|**2024-04-13**|**Leveraging Large Language Model as Simulated Patients for Clinical Education**|Yanzeng Li et.al.|[2404.13066v2](http://arxiv.org/abs/2404.13066v2)|null|
|**2024-04-12**|**Is ChatGPT Transforming Academics' Writing Style?**|Mingmeng Geng et.al.|[2404.08627v1](http://arxiv.org/abs/2404.08627v1)|null|
|**2024-04-12**|**Automatic Quantification of Serial PET/CT Images for Pediatric Hodgkin Lymphoma Patients Using a Longitudinally-Aware Segmentation Network**|Xin Tie et.al.|[2404.08611v1](http://arxiv.org/abs/2404.08611v1)|[link](https://github.com/xtie97/las-net)|
|**2024-04-12**|**RLHF Deciphered: A Critical Analysis of Reinforcement Learning from Human Feedback for LLMs**|Shreyas Chaudhari et.al.|[2404.08555v2](http://arxiv.org/abs/2404.08555v2)|null|
|**2024-04-12**|**An improved tabular data generator with VAE-GMM integration**|Patricia A. Apellániz et.al.|[2404.08434v1](http://arxiv.org/abs/2404.08434v1)|null|
|**2024-04-12**|**Improving Health Question Answering with Reliable and Time-Aware Evidence Retrieval**|Juraj Vladika et.al.|[2404.08359v1](http://arxiv.org/abs/2404.08359v1)|[link](https://github.com/jvladika/improving-health-qa)|
|**2024-04-11**|**Generating Synthetic Satellite Imagery With Deep-Learning Text-to-Image Models -- Technical Challenges and Implications for Monitoring and Verification**|Tuong Vy Nguyen et.al.|[2404.07754v1](http://arxiv.org/abs/2404.07754v1)|null|
|**2024-04-11**|**Medical mT5: An Open-Source Multilingual Text-to-Text LLM for The Medical Domain**|Iker García-Ferrero et.al.|[2404.07613v1](http://arxiv.org/abs/2404.07613v1)|null|
|**2024-04-11**|**Contrastive-Based Deep Embeddings for Label Noise-Resilient Histopathology Image Classification**|Lucas Dedieu et.al.|[2404.07605v1](http://arxiv.org/abs/2404.07605v1)|[link](https://github.com/lucasdedieu/noiseresilienthistopathology)|
|**2024-04-11**|**Socially Pertinent Robots in Gerontological Healthcare**|Xavier Alameda-Pineda et.al.|[2404.07560v1](http://arxiv.org/abs/2404.07560v1)|null|
|**2024-04-11**|**Introducing L2M3, A Multilingual Medical Large Language Model to Advance Health Equity in Low-Resource Regions**|Agasthya Gangavarapu et.al.|[2404.08705v1](http://arxiv.org/abs/2404.08705v1)|null|
|**2024-04-10**|**Measuring proximity to standard planes during fetal brain ultrasound scanning**|Chiara Di Vece et.al.|[2404.07124v1](http://arxiv.org/abs/2404.07124v1)|null|
|**2024-04-10**|**Advancing Real-time Pandemic Forecasting Using Large Language Models: A COVID-19 Case Study**|Hongru Du et.al.|[2404.06962v1](http://arxiv.org/abs/2404.06962v1)|[link](https://github.com/miemieyanga/pandemicllm)|
|**2024-04-10**|**SleepPPG-Net2: Deep learning generalization for sleep staging from photoplethysmography**|Shirel Attia et.al.|[2404.06869v1](http://arxiv.org/abs/2404.06869v1)|null|
|**2024-04-10**|**Multi-Label Continual Learning for the Medical Domain: A Novel Benchmark**|Marina Ceccon et.al.|[2404.06859v2](http://arxiv.org/abs/2404.06859v2)|null|
|**2024-04-10**|**Accuracy of a Large Language Model in Distinguishing Anti- And Pro-vaccination Messages on Social Media: The Case of Human Papillomavirus Vaccination**|Soojong Kim et.al.|[2404.06731v1](http://arxiv.org/abs/2404.06731v1)|null|
|**2024-04-09**|**Federated learning model for predicting major postoperative complications**|Yonggi Park et.al.|[2404.06641v1](http://arxiv.org/abs/2404.06641v1)|null|
|**2024-04-09**|**Test-Time Adaptation with SaLIP: A Cascade of SAM and CLIP for Zero shot Medical Image Segmentation**|Sidra Aleem et.al.|[2404.06362v1](http://arxiv.org/abs/2404.06362v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-09**|**EPL: Evidential Prototype Learning for Semi-supervised Medical Image Segmentation**|Yuanpeng He et.al.|[2404.06181v1](http://arxiv.org/abs/2404.06181v1)|null|
|**2024-04-09**|**Uncertainty-aware Evidential Fusion-based Learning for Semi-supervised Medical Image Segmentation**|Yuanpeng He et.al.|[2404.06177v2](http://arxiv.org/abs/2404.06177v2)|null|
|**2024-04-09**|**Tackling Structural Hallucination in Image Translation with Local Diffusion**|Seunghoi Kim et.al.|[2404.05980v3](http://arxiv.org/abs/2404.05980v3)|null|

#### Abstracts
##### **Domain Adaptive and Fine-grained Anomaly Detection for Single-cell Sequencing Data and Beyond**
2404.17454v1 by Kaichen Xu,Yueyang Ding,Suyang Hou,Weiqiang Zhan,Nisang Chen,Jun Wang,Xiaobo Sun

Fined-grained anomalous cell detection from affected tissues is critical for
clinical diagnosis and pathological research. Single-cell sequencing data
provide unprecedented opportunities for this task. However, current anomaly
detection methods struggle to handle domain shifts prevalent in multi-sample
and multi-domain single-cell sequencing data, leading to suboptimal
performance. Moreover, these methods fall short of distinguishing anomalous
cells into pathologically distinct subtypes. In response, we propose ACSleuth,
a novel, reconstruction deviation-guided generative framework that integrates
the detection, domain adaptation, and fine-grained annotating of anomalous
cells into a methodologically cohesive workflow. Notably, we present the first
theoretical analysis of using reconstruction deviations output by generative
models for anomaly detection in lieu of domain shifts. This analysis informs us
to develop a novel and superior maximum mean discrepancy-based anomaly scorer
in ACSleuth. Extensive benchmarks over various single-cell data and other types
of tabular data demonstrate ACSleuth's superiority over the state-of-the-art
methods in identifying and subtyping anomalies in multi-sample and multi-domain
contexts. Our code is available at https://github.com/Catchxu/ACsleuth.

摘要：從受影響的組織中進行細粒度異常細胞檢測對於
臨床診斷和病理研究。單細胞定序數據
為這項任務提供了前所未有的機會。然而，目前的異常情況
檢測方法難以處理多樣本中普遍存在的域轉移
和多域單細胞定序數據，導致次優
表現。此外，這些方法無法區分異常
細胞分為病理上不同的亞型。作為回應，我們建議 ACSleuth，
一種新穎的、重建偏差引導的生成框架，整合了
異常的檢測、領域適應和細粒度註釋
細胞進入一個方法上有凝聚力的工作流程。值得注意的是，我們提出了第一個
利用生成式輸出重構偏差的理論分析
用於代替域轉移的異常檢測模型。這項分析告訴我們
開發一種新穎且卓越的基於最大平均差異的異常評分器
在 ACSleuth 中。針對各種單細胞數據和其他類型的廣泛基準
表格數據證明 ACSleuth 優於最先進的技術
多樣本和多域中的異常識別和分型方法
上下文。我們的程式碼可在 https://github.com/Catchxu/ACsleuth 取得。

##### **M3BAT: Unsupervised Domain Adaptation for Multimodal Mobile Sensing with Multi-Branch Adversarial Training**
2404.17391v1 by Lakmal Meegahapola,Hamza Hassoune,Daniel Gatica-Perez

Over the years, multimodal mobile sensing has been used extensively for
inferences regarding health and well being, behavior, and context. However, a
significant challenge hindering the widespread deployment of such models in
real world scenarios is the issue of distribution shift. This is the phenomenon
where the distribution of data in the training set differs from the
distribution of data in the real world, the deployment environment. While
extensively explored in computer vision and natural language processing, and
while prior research in mobile sensing briefly addresses this concern, current
work primarily focuses on models dealing with a single modality of data, such
as audio or accelerometer readings, and consequently, there is little research
on unsupervised domain adaptation when dealing with multimodal sensor data. To
address this gap, we did extensive experiments with domain adversarial neural
networks (DANN) showing that they can effectively handle distribution shifts in
multimodal sensor data. Moreover, we proposed a novel improvement over DANN,
called M3BAT, unsupervised domain adaptation for multimodal mobile sensing with
multi-branch adversarial training, to account for the multimodality of sensor
data during domain adaptation with multiple branches. Through extensive
experiments conducted on two multimodal mobile sensing datasets, three
inference tasks, and 14 source-target domain pairs, including both regression
and classification, we demonstrate that our approach performs effectively on
unseen domains. Compared to directly deploying a model trained in the source
domain to the target domain, the model shows performance increases up to 12%
AUC (area under the receiver operating characteristics curves) on
classification tasks, and up to 0.13 MAE (mean absolute error) on regression
tasks.

摘要：多年來，多模態移動感測已被廣泛應用於
關於健康和福祉、行為和背景的推論。然而，一個
阻礙此類模型廣泛部署的重大挑戰
現實世界的場景是分佈轉移的問題。這就是現象
其中訓練集中資料的分佈與
資料在現實世界的分佈、部署環境。儘管
在電腦視覺和自然語言處理方面進行了廣泛的探索，並且
雖然移動感測領域的先前研究簡要地解決了這個問題，但當前
工作主要集中於處理單一資料模態的模型，例如
作為音頻或加速度計讀數，因此，很少有研究
處理多模態感測器資料時的無監督域適應。到
為了解決這個差距，我們對領域對抗神經網路進行了廣泛的實驗
網路（DANN）表明他們可以有效地處理分佈變化
多模態感測器數據。此外，我們提出了對 DANN 的新穎改進，
稱為 M3BAT，用於多模態移動感測的無監督域自適應
多分支對抗訓練，考慮感測器的多模態
具有多個分支的域適應期間的資料。透過廣泛
在兩個多模態移動感測資料集、三個
推理任務，以及 14 個源-目標域對，包括迴歸
和分類，我們證明我們的方法在以下方面有效執行
未見的域。與直接部署在來源中訓練的模型相比
域到目標域，模型顯示效能提升高達 12%
AUC（受試者工作特徵曲線下面積）
分類任務，迴歸高達 0.13 MAE（平均絕對誤差）
任務。

##### **Prevalent Frequency of Emotional and Physical Symptoms in Social Anxiety using Zero Shot Classification: An Observational Study**
2404.17183v1 by Muhammad Rizwan,Jure Demšar

Social anxiety represents a prevalent challenge in modern society, affecting
individuals across personal and professional spheres. Left unaddressed, this
condition can yield substantial negative consequences, impacting social
interactions and performance. Further understanding its diverse physical and
emotional symptoms becomes pivotal for comprehensive diagnosis and tailored
therapeutic interventions. This study analyze prevalence and frequency of
social anxiety symptoms taken from Mayo Clinic, exploring diverse human
experiences from utilizing a large Reddit dataset dedicated to this issue.
Leveraging these platforms, the research aims to extract insights and examine a
spectrum of physical and emotional symptoms linked to social anxiety disorder.
Upholding ethical considerations, the study maintains strict user anonymity
within the dataset. By employing a novel approach, the research utilizes
BART-based multi-label zero-shot classification to identify and measure symptom
prevalence and significance in the form of probability score for each symptom
under consideration. Results uncover distinctive patterns: "Trembling" emerges
as a prevalent physical symptom, while emotional symptoms like "Fear of being
judged negatively" exhibit high frequencies. These findings offer insights into
the multifaceted nature of social anxiety, aiding clinical practices and
interventions tailored to its diverse expressions.

摘要：社交焦慮是現代社會普遍存在的挑戰，影響
個人和專業領域的個人。沒有解決，這個
這種情況可能會產生嚴重的負面後果，影響社會
交互和性能。進一步了解其多樣化的物理學和
情緒症狀成為綜合診斷和客製化的關鍵
治療幹預。本研究分析了盛行率和頻率
來自梅奧診所的社交焦慮症狀，探索不同的人類
利用專門解決此問題的大型 Reddit 資料集的經驗。
該研究旨在利用這些平台提取見解並檢驗
與社交焦慮症相關的一系列身體和情緒症狀。
出於道德考慮，該研究嚴格保持用戶匿名
在數據集中。透過採用一種新穎的方法，該研究利用
基於 BART 的多標籤零樣本分類來識別和測量症狀
每種症狀的機率評分形式的盛行率和重要性
在考慮中。結果揭示了獨特的模式：「顫抖」出現
作為一種普遍的身體症狀，而情緒症狀，如“害怕被
負面評價」表現出很高的頻率。這些發現提供了關於
社交焦慮的多方面性質，有助於臨床實踐和
針對其不同表現形式的介入措施。

##### **Deep Evidential Learning for Dose Prediction**
2404.17126v1 by Hai Siong Tan,Kuancheng Wang,Rafe Mcbeth

In this work, we present a novel application of an uncertainty-quantification
framework called Deep Evidential Learning in the domain of radiotherapy dose
prediction. Using medical images of the Open Knowledge-Based Planning Challenge
dataset, we found that this model can be effectively harnessed to yield
uncertainty estimates that inherited correlations with prediction errors upon
completion of network training. This was achieved only after reformulating the
original loss function for a stable implementation. We found that (i)epistemic
uncertainty was highly correlated with prediction errors, with various
association indices comparable or stronger than those for Monte-Carlo Dropout
and Deep Ensemble methods, (ii)the median error varied with uncertainty
threshold much more linearly for epistemic uncertainty in Deep Evidential
Learning relative to these other two conventional frameworks, indicative of a
more uniformly calibrated sensitivity to model errors, (iii)relative to
epistemic uncertainty, aleatoric uncertainty demonstrated a more significant
shift in its distribution in response to Gaussian noise added to CT intensity,
compatible with its interpretation as reflecting data noise. Collectively, our
results suggest that Deep Evidential Learning is a promising approach that can
endow deep-learning models in radiotherapy dose prediction with statistical
robustness. Towards enhancing its clinical relevance, we demonstrate how we can
use such a model to construct the predicted Dose-Volume-Histograms' confidence
intervals.

摘要：在這項工作中，我們提出了不確定性量化的新穎應用
放射治療劑量領域稱為深度證據學習的框架
預言。使用開放知識規劃挑戰賽的醫學影像
資料集，我們發現這個模型可以有效地利用來產生
不確定性估計繼承了與預測誤差的相關性
完成網路培訓。這是在重新制定後才實現的
用於穩定實現的原始損失函數。我們發現（i）認知
不確定性與預測誤差高度相關，
關聯指數與 Monte-Carlo Dropout 相當或更強
和深度集成方法，(ii)中位數誤差隨不確定性變化
深度證據中認知不確定性的閾值較為線性
相對於這另外兩個傳統框架的學習，表明
對模型誤差的更統一的校準敏感性，(iii)相對於
認知不確定性、任意不確定性表現出更顯著的影響
響應於 CT 強度添加的高斯噪聲，其分佈發生變化，
與其反映數據雜訊的解釋相容。總的來說，我們的
結果顯示深度證據學習是一種有前途的方法，可以
為放射治療劑量預測中的深度學習模型提供統計數據
穩健性.為了增強其臨床相關性，我們展示瞭如何能夠
使用這樣的模型來建立預測劑量體積直方圖的置信度
間隔。

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge,Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

摘要：人工智慧（AI）的普遍整合已經引入
如果出現以下情況，責任和問責制將面臨複雜的挑戰
涉及人工智慧系統的事件。這些系統的互連性，
人工智慧引發的事件的倫理問題以及人工智慧的不確定性
技術的進步和相應法規的缺失，使得傳統的
責任歸屬具有挑戰性。為此，本工作提出了
計算反射平衡（CRE）方法建立一個連貫的和
所有利害關係人在道德上可接受的責任歸屬框架。
計算方法提供了一種結構化分析，克服了
概念方法在處理動態和多方面問題時的局限性
場景，展示框架的可解釋性、連貫性和適應性
責任歸屬過程中的屬性。我們檢查關鍵的
與平衡狀態下的索賠相關的初始活化水準的作用
計算。以AI輔助醫療決策支援系統為例
研究中，我們說明了不同的初始化如何導致不同的結果
責任分配。該框架提供了寶貴的見解
人工智慧引發的事件的問責制，促進發展
透過持續監控、修訂和改進，實現可持續和有彈性的系統
反射。

##### **Taming False Positives in Out-of-Distribution Detection with Human Feedback**
2404.16954v1 by Harit Vishwakarma,Heguang Lin,Ramya Korlakai Vinayak

Robustness to out-of-distribution (OOD) samples is crucial for safely
deploying machine learning models in the open world. Recent works have focused
on designing scoring functions to quantify OOD uncertainty. Setting appropriate
thresholds for these scoring functions for OOD detection is challenging as OOD
samples are often unavailable up front. Typically, thresholds are set to
achieve a desired true positive rate (TPR), e.g., $95\%$ TPR. However, this can
lead to very high false positive rates (FPR), ranging from 60 to 96\%, as
observed in the Open-OOD benchmark. In safety-critical real-life applications,
e.g., medical diagnosis, controlling the FPR is essential when dealing with
various OOD samples dynamically. To address these challenges, we propose a
mathematically grounded OOD detection framework that leverages expert feedback
to \emph{safely} update the threshold on the fly. We provide theoretical
results showing that it is guaranteed to meet the FPR constraint at all times
while minimizing the use of human feedback. Another key feature of our
framework is that it can work with any scoring function for OOD uncertainty
quantification. Empirical evaluation of our system on synthetic and benchmark
OOD datasets shows that our method can maintain FPR at most $5\%$ while
maximizing TPR.

摘要：對分佈外 (OOD) 樣本的穩健性對於安全至關重要
在開放世界中部署機器學習模型。最近的作品主要集中在
設計評分函數來量化 OOD 不確定性。設定適當
OOD 檢測的這些評分函數的閾值具有挑戰性，因為 OOD
樣品通常無法預先獲得。通常，閾值設定為
達到所需的真陽性率 (TPR)，例如 $95\%$ TPR。然而，這可以
導致非常高的誤報率 (FPR)，範圍從 60% 到 96\%，如
在 Open-OOD 基準測試中觀察到。在安全關鍵的現實生活應用中，
例如，醫療診斷、處理 FPR 時至關重要
動態地提供各種 OOD 樣本。為了應對這些挑戰，我們提出了
基於數學的 OOD 檢測框架，利用專家回饋
\emph{安全地}動態更新閾值。我們提供理論
結果表明，保證始終滿足 FPR 約束
同時最大限度地減少人類回饋的使用。我們的另一個主要特點
框架的特點是它可以與任何 OOD 不確定性評分函數一起使用
量化。對我們的系統進行綜合和基準的實證評估
OOD 資料集表明，我們的方法最多可以將 FPR 維持在 $5\%$，而
最大化 TPR。

##### **Features Fusion for Dual-View Mammography Mass Detection**
2404.16718v1 by Arina Varlamova,Valery Belotsky,Grigory Novikov,Anton Konushin,Evgeny Sidorov

Detection of malignant lesions on mammography images is extremely important
for early breast cancer diagnosis. In clinical practice, images are acquired
from two different angles, and radiologists can fully utilize information from
both views, simultaneously locating the same lesion. However, for automatic
detection approaches such information fusion remains a challenge. In this
paper, we propose a new model called MAMM-Net, which allows the processing of
both mammography views simultaneously by sharing information not only on an
object level, as seen in existing works, but also on a feature level.
MAMM-Net's key component is the Fusion Layer, based on deformable attention and
designed to increase detection precision while keeping high recall. Our
experiments show superior performance on the public DDSM dataset compared to
the previous state-of-the-art model, while introducing new helpful features
such as lesion annotation on pixel-level and classification of lesions
malignancy.

摘要：乳房X光攝影影像上惡性病變的檢測極為重要
用於早期乳癌診斷。在臨床實務中，取得影像
從兩個不同的角度，放射科醫生可以充分利用來自
兩種視圖同時定位同一病變。然而，對於自動
這種資訊融合的檢測方法仍然是一個挑戰。在這個
在論文中，我們提出了一種稱為 MAMM-Net 的新模型，它允許處理
透過分享訊息，不僅可以同時取得乳房 X 光檢查視圖
物件級別，如現有作品中所見，而且還包括特徵級別。
MAMM-Net 的關鍵組件是融合層，基於可變形注意力和
旨在提高檢測精度，同時保持高召回率。我們的
實驗表明，與公共 DDSM 資料集相比，該資料集具有優越的效能
以前最先進的模型，同時引入新的實用功能
例如像素級的病灶標註和病灶分類
惡性腫瘤。

##### **Report on Candidate Computational Indicators for Conscious Valenced Experience**
2404.16696v1 by Andres Campero

This report enlists 13 functional conditions cashed out in computational
terms that have been argued to be constituent of conscious valenced experience.
These are extracted from existing empirical and theoretical literature on,
among others, animal sentience, medical disorders, anaesthetics, philosophy,
evolution, neuroscience, and artificial intelligence.

摘要：該報告列舉了 13 種透過計算實現的功能條件
被認為是有意識的價經驗的組成部分的術語。
這些是從現有的經驗和理論文獻中提取的，
其中包括動物感知、醫學疾病、麻醉學、哲學、
進化論、神經科學和人工智慧。

##### **ProbGate at EHRSQL 2024: Enhancing SQL Query Generation Accuracy through Probabilistic Threshold Filtering and Error Handling**
2404.16659v1 by Sangryul Kim,Donghee Han,Sehyun Kim

Recently, deep learning-based language models have significantly enhanced
text-to-SQL tasks, with promising applications in retrieving patient records
within the medical domain. One notable challenge in such applications is
discerning unanswerable queries. Through fine-tuning model, we demonstrate the
feasibility of converting medical record inquiries into SQL queries.
Additionally, we introduce an entropy-based method to identify and filter out
unanswerable results. We further enhance result quality by filtering
low-confidence SQL through log probability-based distribution, while
grammatical and schema errors are mitigated by executing queries on the actual
database. We experimentally verified that our method can filter unanswerable
questions, which can be widely utilized even when the parameters of the model
are not accessible, and that it can be effectively utilized in practice.

摘要：最近，基於深度學習的語言模型顯著增強了
文字到 SQL 任務，在檢索病患記錄方面具有廣泛的應用前景
在醫學領域內。此類應用中的一個顯著挑戰是
辨別無法回答的問題。透過微調模型，我們證明了
將病歷查詢轉換為 SQL 查詢的可行性。
此外，我們引入了一種基於熵的方法來識別和過濾掉
無法回答的結果。我們透過過濾進一步提高結果品質
透過基於日誌機率的分佈來降低置信度 SQL，同時
透過對實際資料執行查詢可以減少語法和模式錯誤
資料庫.我們實驗驗證了我們的方法可以過濾無法回答的
問題，即使模型的參數
是不可獲取的，並且可以在實踐中有效利用。

##### **Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare**
2404.16621v1 by Emre Can Acikgoz,Osman Batur İnce,Rayene Bench,Arda Anıl Boz,İlker Kesen,Aykut Erdem,Erkut Erdem

The integration of Large Language Models (LLMs) into healthcare promises to
transform medical diagnostics, research, and patient care. Yet, the progression
of medical LLMs faces obstacles such as complex training requirements, rigorous
evaluation demands, and the dominance of proprietary models that restrict
academic exploration. Transparent, comprehensive access to LLM resources is
essential for advancing the field, fostering reproducibility, and encouraging
innovation in healthcare AI. We present Hippocrates, an open-source LLM
framework specifically developed for the medical domain. In stark contrast to
previous efforts, it offers unrestricted access to its training datasets,
codebase, checkpoints, and evaluation protocols. This open approach is designed
to stimulate collaborative research, allowing the community to build upon,
refine, and rigorously evaluate medical LLMs within a transparent ecosystem.
Also, we introduce Hippo, a family of 7B models tailored for the medical
domain, fine-tuned from Mistral and LLaMA2 through continual pre-training,
instruction tuning, and reinforcement learning from human and AI feedback. Our
models outperform existing open medical LLMs models by a large-margin, even
surpassing models with 70B parameters. Through Hippocrates, we aspire to unlock
the full potential of LLMs not just to advance medical knowledge and patient
care but also to democratize the benefits of AI research in healthcare, making
them available across the globe.

摘要：將大型語言模型 (LLM) 整合到醫療保健領域有望
改變醫療診斷、研究和病患照護。然而，進展
的醫學LLM面臨複雜的訓練要求、嚴格的訓練等障礙
評估要求以及限制專有模型的主導地位
學術探索。對 LLM 資源的透明、全面的存取是
對於推進該領域、促進可重複性和鼓勵
醫療保健人工智慧的創新。我們介紹希波克拉底，一個開源LLM
專門為醫療領域所開發的框架。與之形成鮮明對比的是
與先前的努力相比，它提供了對其訓練資料集的無限制訪問，
程式碼庫、檢查點和評估協議。這種開放式方法的設計
促進合作研究，讓社區在此基礎上繼續發展，
在透明的生態系統中完善和嚴格評估醫學LLM。
此外，我們還推出了專為醫療行業量身定制的 7B 型號 Hippo 系列。
域，透過持續的預訓練從 Mistral 和 LLaMA2 進行微調，
指令調整以及來自人類和人工智慧回饋的強化學習。我們的
模型的表現遠優於現有的開放式醫學LLM模型，甚至
超越70B參數的模型。透過希波克拉底，我們渴望解鎖
LLM的全部潛力不僅可以促進醫學知識和病人的發展
也使人工智慧研究在醫療保健領域的好處民主化，使
它們在全球範圍內可用。

##### **DiffSeg: A Segmentation Model for Skin Lesions Based on Diffusion Difference**
2404.16474v1 by Zhihao Shuai,Yinan Chen,Shunqiang Mao,Yihan Zho,Xiaohong Zhang

Weakly supervised medical image segmentation (MIS) using generative models is
crucial for clinical diagnosis. However, the accuracy of the segmentation
results is often limited by insufficient supervision and the complex nature of
medical imaging. Existing models also only provide a single outcome, which does
not allow for the measurement of uncertainty. In this paper, we introduce
DiffSeg, a segmentation model for skin lesions based on diffusion difference
which exploits diffusion model principles to ex-tract noise-based features from
images with diverse semantic information. By discerning difference between
these noise features, the model identifies diseased areas. Moreover, its
multi-output capability mimics doctors' annotation behavior, facilitating the
visualization of segmentation result consistency and ambiguity. Additionally,
it quantifies output uncertainty using Generalized Energy Distance (GED),
aiding interpretability and decision-making for physicians. Finally, the model
integrates outputs through the Dense Conditional Random Field (DenseCRF)
algorithm to refine the segmentation boundaries by considering inter-pixel
correlations, which improves the accuracy and optimizes the segmentation
results. We demonstrate the effectiveness of DiffSeg on the ISIC 2018 Challenge
dataset, outperforming state-of-the-art U-Net-based methods.

摘要：使用生成模型的弱監督醫學影像分割（MIS）是
對臨床診斷至關重要。但分割的準確率
結果往往受到監督不足和複雜性的限制
醫學影像。現有模型也僅提供單一結果，這確實
不允許測量不確定度。在本文中，我們介紹
DiffSeg，一種基於擴散差的皮損分割模型
它利用擴散模型原理來提取基於噪音的特徵
具有多種語義資訊的圖像。透過辨別之間的差異
透過這些噪音特徵，模型可以識別患病區域。而且，其
多輸出能力模仿醫生的註釋行為，促進
分割結果一致性和模糊性的可視化。此外，
它使用廣義能量距離（GED）量化輸出不確定性，
幫助醫生進行解釋和決策。最後是模型
透過密集條件隨機場 (DenseCRF) 整合輸出
透過考慮像素間細化分割邊界的演算法
相關性，提高了準確性並優化了分割
結果。我們在 ISIC 2018 挑戰賽中展示了 DiffSeg 的有效性
數據集，優於最先進的基於 U-Net 的方法。

##### **Light-weight Retinal Layer Segmentation with Global Reasoning**
2404.16346v1 by Xiang He,Weiye Song,Yiming Wang,Fabio Poiesi,Ji Yi,Manishi Desai,Quanqing Xu,Kongzheng Yang,Yi Wan

Automatic retinal layer segmentation with medical images, such as optical
coherence tomography (OCT) images, serves as an important tool for diagnosing
ophthalmic diseases. However, it is challenging to achieve accurate
segmentation due to low contrast and blood flow noises presented in the images.
In addition, the algorithm should be light-weight to be deployed for practical
clinical applications. Therefore, it is desired to design a light-weight
network with high performance for retinal layer segmentation. In this paper, we
propose LightReSeg for retinal layer segmentation which can be applied to OCT
images. Specifically, our approach follows an encoder-decoder structure, where
the encoder part employs multi-scale feature extraction and a Transformer block
for fully exploiting the semantic information of feature maps at all scales and
making the features have better global reasoning capabilities, while the
decoder part, we design a multi-scale asymmetric attention (MAA) module for
preserving the semantic information at each encoder scale. The experiments show
that our approach achieves a better segmentation performance compared to the
current state-of-the-art method TransUnet with 105.7M parameters on both our
collected dataset and two other public datasets, with only 3.3M parameters.

摘要：使用醫學影像（例如光學影像）進行自動視網膜層分割
相干斷層掃描（OCT）影像是診斷的重要工具
眼科疾病。然而，要實現準確的
由於影像中呈現的低對比度和血流雜訊而導致的分割。
此外，該演算法應該是輕量級的，以便部署到實際中
臨床應用。因此，需要設計一種輕量化的
具有高效能的視網膜層分割網路。在本文中，我們
提出LightReSeg用於視網膜層分割，可應用於OCT
圖片。具體來說，我們的方法遵循編碼器-解碼器結構，其中
編碼器部分採用多尺度特徵提取和 Transformer 區塊
充分利用所有尺度的特徵圖的語意資訊和
使得特徵具有更好的全局推理能力，同時
解碼器部分，我們設計了一個多尺度非對稱注意力（MAA）模組
保留每個編碼器尺度的語意資訊。實驗表明
與之前的方法相比，我們的方法實現了更好的分割性能
目前最先進的方法 TransUnet 在我們的兩個平台上具有 105.7M 參數
收集的資料集和另外兩個公共資料集，只有 330 萬個參數。

##### **Semantic Segmentation Refiner for Ultrasound Applications with Zero-Shot Foundation Models**
2404.16325v1 by Hedda Cohen Indelman,Elay Dahan,Angeles M. Perez-Agosto,Carmit Shiran,Doron Shaked,Nati Daniel

Despite the remarkable success of deep learning in medical imaging analysis,
medical image segmentation remains challenging due to the scarcity of
high-quality labeled images for supervision. Further, the significant domain
gap between natural and medical images in general and ultrasound images in
particular hinders fine-tuning models trained on natural images to the task at
hand. In this work, we address the performance degradation of segmentation
models in low-data regimes and propose a prompt-less segmentation method
harnessing the ability of segmentation foundation models to segment abstract
shapes. We do that via our novel prompt point generation algorithm which uses
coarse semantic segmentation masks as input and a zero-shot prompt-able
foundation model as an optimization target. We demonstrate our method on a
segmentation findings task (pathologic anomalies) in ultrasound images. Our
method's advantages are brought to light in varying degrees of low-data regime
experiments on a small-scale musculoskeletal ultrasound images dataset,
yielding a larger performance gain as the training set size decreases.

摘要：儘管深度學習在醫學影像分析方面取得了顯著的成功，
由於缺乏數據，醫學影像分割仍然具有挑戰性
用於監督的高品質標記圖像。進一步地，顯著域
一般的自然影像和醫學影像與超音波影像之間的差距
特別是阻礙了在自然圖像上訓練的模型對任務的微調
手。在這項工作中，我們解決了分割的效能下降問題
在低數據情況下建模並提出一種無提示分割方法
利用分割基礎模型的能力分割摘要
形狀。我們透過新穎的提示點生成演算法來做到這一點，該演算法使用
粗略語義分割遮罩作為輸入和零樣本提示
基礎模型作為最佳化目標。我們在
超音波影像中的分割發現任務（病理異常）。我們的
此方法的優點在不同程度的低數據情況下得到體現
在小規模肌肉骨骼超音波影像資料集上進行的實驗，
隨著訓練集大小的減小，產生更大的效能增益。

##### **LLM-Based Section Identifiers Excel on Open Source but Stumble in Real World Applications**
2404.16294v1 by Saranya Krishnamoorthy,Ayush Singh,Shabnam Tafreshi

Electronic health records (EHR) even though a boon for healthcare
practitioners, are growing convoluted and longer every day. Sifting around
these lengthy EHRs is taxing and becomes a cumbersome part of physician-patient
interaction. Several approaches have been proposed to help alleviate this
prevalent issue either via summarization or sectioning, however, only a few
approaches have truly been helpful in the past. With the rise of automated
methods, machine learning (ML) has shown promise in solving the task of
identifying relevant sections in EHR. However, most ML methods rely on labeled
data which is difficult to get in healthcare. Large language models (LLMs) on
the other hand, have performed impressive feats in natural language processing
(NLP), that too in a zero-shot manner, i.e. without any labeled data. To that
end, we propose using LLMs to identify relevant section headers. We find that
GPT-4 can effectively solve the task on both zero and few-shot settings as well
as segment dramatically better than state-of-the-art methods. Additionally, we
also annotate a much harder real world dataset and find that GPT-4 struggles to
perform well, alluding to further research and harder benchmarks.

摘要：電子健康記錄 (EHR) 儘管對醫療保健有好處
實踐者們，每天都變得越來越複雜、越來越長。篩選
這些冗長的電子病歷非常繁重，並且成為醫病關係中的一個麻煩部分
相互作用。已經提出了幾種方法來幫助緩解這種情況
透過總結或分段來解決普遍存在的問題，但是，只有少數
過去的方法確實很有幫助。隨著自動化的興起
方法，機器學習（ML）在解決以下任務方面表現出了希望
確定電子病歷中的相關部分。然而，大多數機器學習方法依賴標記的
醫療保健領域很難獲得的數據。大型語言模型 (LLM)
另一方面，在自然語言處理方面取得了令人印象深刻的成就
（NLP），這也是零樣本方式，即沒有任何標記資料。對此
最後，我們建議使用LLM來識別相關的章節標題。我們發現
GPT-4 也可以有效解決零樣本和少樣本設定下的任務
作為細分市場，其性能比最先進的方法好得多。此外，我們
也註釋了一個更難的現實世界資料集，發現 GPT-4 很難
表現良好，暗示著進一步的研究和更嚴格的基準。

##### **Investigating the prompt leakage effect and black-box defenses for multi-turn LLM interactions**
2404.16251v2 by Divyansh Agarwal,Alexander R. Fabbri,Philippe Laban,Ben Risher,Shafiq Joty,Caiming Xiong,Chien-Sheng Wu

Prompt leakage in large language models (LLMs) poses a significant security
and privacy threat, particularly in retrieval-augmented generation (RAG)
systems. However, leakage in multi-turn LLM interactions along with mitigation
strategies has not been studied in a standardized manner. This paper
investigates LLM vulnerabilities against prompt leakage across 4 diverse
domains and 10 closed- and open-source LLMs. Our unique multi-turn threat model
leverages the LLM's sycophancy effect and our analysis dissects task
instruction and knowledge leakage in the LLM response. In a multi-turn setting,
our threat model elevates the average attack success rate (ASR) to 86.2%,
including a 99% leakage with GPT-4 and claude-1.3. We find that some black-box
LLMs like Gemini show variable susceptibility to leakage across domains - they
are more likely to leak contextual knowledge in the news domain compared to the
medical domain. Our experiments measure specific effects of 6 black-box defense
strategies, including a query-rewriter in the RAG scenario. Our proposed
multi-tier combination of defenses still has an ASR of 5.3% for black-box LLMs,
indicating room for enhancement and future direction for LLM security research.

摘要：大型語言模型 (LLM) 中的即時洩漏帶來了重大安全問題
和隱私威脅，特別是在檢索增強生成（RAG）中
系統。然而，多輪 LLM 互動中的洩漏以及緩解
策略尚未以標準化方式進行研究。這張紙
調查 LLM 漏洞，防止 4 個不同領域的即時洩漏
域和 10 個封閉和開源LLM。我們獨特的多回合威脅模型
利用LLM的阿諛奉承效應和我們的分析剖析任務
LLM 回答中的指導和知識外洩。在多圈設定中，
我們的威脅模型將平均攻擊成功率 (ASR) 提高到 86.2%，
包括 GPT-4 和 claude-1.3 的 99% 洩漏。我們發現一些黑盒子
像 Gemini 這樣的LLM對跨領域的洩漏表現出不同的敏感性 - 他們
與其他人相比，他們更有可能洩露新聞領域的背景知識
醫療領域。我們的實驗測量了 6 種黑盒子防禦的具體效果
策略，包括 RAG 場景中的查詢重寫器。我們提出的
對於黑盒LLM來說，多層防禦組合的 ASR 仍然為 5.3%，
顯示 LLM 安全研究的增強空間和未來方向。

##### **ABCD: Trust enhanced Attention based Convolutional Autoencoder for Risk Assessment**
2404.16183v1 by Sarala Naidu,Ning Xiong

Anomaly detection in industrial systems is crucial for preventing equipment
failures, ensuring risk identification, and maintaining overall system
efficiency. Traditional monitoring methods often rely on fixed thresholds and
empirical rules, which may not be sensitive enough to detect subtle changes in
system health and predict impending failures. To address this limitation, this
paper proposes, a novel Attention-based convolutional autoencoder (ABCD) for
risk detection and map the risk value derive to the maintenance planning. ABCD
learns the normal behavior of conductivity from historical data of a real-world
industrial cooling system and reconstructs the input data, identifying
anomalies that deviate from the expected patterns. The framework also employs
calibration techniques to ensure the reliability of its predictions. Evaluation
results demonstrate that with the attention mechanism in ABCD a 57.4% increase
in performance and a reduction of false alarms by 9.37% is seen compared to
without attention. The approach can effectively detect risks, the risk priority
rank mapped to maintenance, providing valuable insights for cooling system
designers and service personnel. Calibration error of 0.03% indicates that the
model is well-calibrated and enhances model's trustworthiness, enabling
informed decisions about maintenance strategies

摘要：工業系統中的異常檢測對於預防設備故障至關重要
故障，確保風險識別並維護整個系統
效率。傳統的監測方法往往依賴固定的閾值和
經驗規則，可能不夠敏感，無法偵測到細微的變化
系統健康狀況並預測即將發生的故障。為了解決這個限制，這
論文提出了一種新穎的基於注意力的捲積自動編碼器（ABCD）
風險偵測並將風險值對應到維護計劃。 A B C D
從現實世界的歷史資料中學習電導率的正常行為
工業冷卻系統並重建輸入數據，識別
偏離預期模式的異常現象。該框架還採用
校準技術以確保其預測的可靠性。評估
結果表明，ABCD 中的注意力機制提高了 57.4%
與之前相比，誤報率降低了 9.37%
不加註意。此方法能夠有效發現風險，並確定風險優先級
排名映射到維護，為冷卻系統提供有價值的見解
設計師和服務人員。 0.03% 的校準誤差表明
模型經過良好校準並增強了模型的可信度，使得
有關維護策略的明智決策

##### **Mamba-360: Survey of State Space Models as Transformer Alternative for Long Sequence Modelling: Methods, Applications, and Challenges**
2404.16112v1 by Badri Narayana Patro,Vijay Srinivas Agneeswaran

Sequence modeling is a crucial area across various domains, including Natural
Language Processing (NLP), speech recognition, time series forecasting, music
generation, and bioinformatics. Recurrent Neural Networks (RNNs) and Long Short
Term Memory Networks (LSTMs) have historically dominated sequence modeling
tasks like Machine Translation, Named Entity Recognition (NER), etc. However,
the advancement of transformers has led to a shift in this paradigm, given
their superior performance. Yet, transformers suffer from $O(N^2)$ attention
complexity and challenges in handling inductive bias. Several variations have
been proposed to address these issues which use spectral networks or
convolutions and have performed well on a range of tasks. However, they still
have difficulty in dealing with long sequences. State Space Models(SSMs) have
emerged as promising alternatives for sequence modeling paradigms in this
context, especially with the advent of S4 and its variants, such as S4nd,
Hippo, Hyena, Diagnol State Spaces (DSS), Gated State Spaces (GSS), Linear
Recurrent Unit (LRU), Liquid-S4, Mamba, etc. In this survey, we categorize the
foundational SSMs based on three paradigms namely, Gating architectures,
Structural architectures, and Recurrent architectures. This survey also
highlights diverse applications of SSMs across domains such as vision, video,
audio, speech, language (especially long sequence modeling), medical (including
genomics), chemical (like drug design), recommendation systems, and time series
analysis, including tabular data. Moreover, we consolidate the performance of
SSMs on benchmark datasets like Long Range Arena (LRA), WikiText, Glue, Pile,
ImageNet, Kinetics-400, sstv2, as well as video datasets such as Breakfast,
COIN, LVU, and various time series datasets. The project page for Mamba-360
work is available on this webpage.\url{https://github.com/badripatro/mamba360}.

摘要：序列建模是各領域的關鍵領域，包括自然領域
語言處理（NLP）、語音辨識、時間序列預測、音樂
生成和生物資訊學。循環神經網路 (RNN) 和長空
術語記憶網路 (LSTM) 歷來在序列建模中佔據主導地位
機器翻譯、命名實體辨識 (NER) 等任務。
鑑於變壓器的進步導致了這種範式的轉變
他們的卓越表現。然而，變形金剛卻受到了 $O(N^2)$ 的關注
處理歸納偏差的複雜性和挑戰。有幾種變體
建議使用頻譜網路或
卷積並在一系列任務上表現良好。然而，他們仍然
處理長序列有困難。狀態空間模型（SSM）有
成為序列建模範式的有前途的替代方案
上下文，特別是隨著 S4 及其變體（例如 S4nd）的出現，
Hippo、Hyena、診斷狀態空間 (DSS)、閘控狀態空間 (GSS)、線性
循環單元（LRU）、Liquid-S4、Mamba 等。
基於三種範式的基礎 SSM，即閘控架構、
結構架構和迴圈架構。這項調查還
重點介紹了 SSM 在視覺、視訊、
音訊、語音、語言（尤其是長序列建模）、醫學（包括
基因組學）、化學（如藥物設計）、推薦系統和時間序列
分析，包括表格數據。此外，我們也整合了
基準資料集上的 SSM，例如 Long Range Arena (LRA)、WikiText、Glue、Pile、
ImageNet、Kinetics-400、sstv2，以及早餐等影片資料集，
COIN、LVU 和各種時間序列資料集。 Mamba-360 的專案頁面
此網頁上提供了工作。

##### **Mammo-CLIP: Leveraging Contrastive Language-Image Pre-training (CLIP) for Enhanced Breast Cancer Diagnosis with Multi-view Mammography**
2404.15946v1 by Xuxin Chen,Yuheng Li,Mingzhe Hu,Ella Salari,Xiaoqian Chen,Richard L. J. Qiu,Bin Zheng,Xiaofeng Yang

Although fusion of information from multiple views of mammograms plays an
important role to increase accuracy of breast cancer detection, developing
multi-view mammograms-based computer-aided diagnosis (CAD) schemes still faces
challenges and no such CAD schemes have been used in clinical practice. To
overcome the challenges, we investigate a new approach based on Contrastive
Language-Image Pre-training (CLIP), which has sparked interest across various
medical imaging tasks. By solving the challenges in (1) effectively adapting
the single-view CLIP for multi-view feature fusion and (2) efficiently
fine-tuning this parameter-dense model with limited samples and computational
resources, we introduce Mammo-CLIP, the first multi-modal framework to process
multi-view mammograms and corresponding simple texts. Mammo-CLIP uses an early
feature fusion strategy to learn multi-view relationships in four mammograms
acquired from the CC and MLO views of the left and right breasts. To enhance
learning efficiency, plug-and-play adapters are added into CLIP image and text
encoders for fine-tuning parameters and limiting updates to about 1% of the
parameters. For framework evaluation, we assembled two datasets
retrospectively. The first dataset, comprising 470 malignant and 479 benign
cases, was used for few-shot fine-tuning and internal evaluation of the
proposed Mammo-CLIP via 5-fold cross-validation. The second dataset, including
60 malignant and 294 benign cases, was used to test generalizability of
Mammo-CLIP. Study results show that Mammo-CLIP outperforms the state-of-art
cross-view transformer in AUC (0.841 vs. 0.817, 0.837 vs. 0.807) on both
datasets. It also surpasses previous two CLIP-based methods by 20.3% and 14.3%.
This study highlights the potential of applying the finetuned vision-language
models for developing next-generation, image-text-based CAD schemes of breast
cancer.

摘要：儘管來自乳房 X 光檢查多個視圖的資訊融合發揮了重要作用
提高乳癌檢測準確性的重要作用，開發
基於多視圖乳房X光檢查的電腦輔助診斷（CAD）方案仍面臨挑戰
挑戰，並且尚未在臨床實踐中使用此類 CAD 方案。到
克服挑戰，我們研究了一種基於對比的新方法
語言-圖像預訓練（CLIP），引起了各領域的興趣
醫學影像任務。透過解決（1）中的挑戰，有效適應
用於多視圖特徵融合的單視圖 CLIP 以及 (2) 高效
用有限的樣本和計算量微調這個參數密集模型
資源，我們介紹了 Mammo-CLIP，第一個多模態框架來處理
多視圖乳房X光照片和對應的簡單文字。 Mammo-CLIP 使用早期
學習四張乳房X光照片中多視圖關係的特徵融合策略
從左乳房和右乳房的 CC 和 MLO 視圖獲得。加強
提高學習效率，CLIP圖文加入即插即用轉接器
用於微調參數並將更新限制為約 1% 的編碼器
參數。為了進行框架評估，我們組裝了兩個資料集
回顧起來。第一個資料集，包含 470 個惡性和 479 個良性
案例，用於小樣本微調和內部評估
透過 5 倍交叉驗證提出了 Mammo-CLIP。第二個資料集，包括
60 個惡性病例和 294 個良性病例用於檢驗
媽媽剪輯。研究結果顯示 Mammo-CLIP 的性能優於最先進的技術
兩者的 AUC 中的交叉視圖變換器（0.841 vs. 0.817、0.837 vs. 0.807）
數據集。它也超過了之前兩種基於 CLIP 的方法 20.3% 和 14.3%。
這項研究強調了應用微調視覺語言的潛力
用於開發下一代基於圖像文字的乳房 CAD 方案的模型
癌症。

##### **Assessing The Potential Of Mid-Sized Language Models For Clinical QA**
2404.15894v1 by Elliot Bolton,Betty Xiong,Vijaytha Muralidharan,Joel Schamroth,Vivek Muralidharan,Christopher D. Manning,Roxana Daneshjou

Large language models, such as GPT-4 and Med-PaLM, have shown impressive
performance on clinical tasks; however, they require access to compute, are
closed-source, and cannot be deployed on device. Mid-size models such as
BioGPT-large, BioMedLM, LLaMA 2, and Mistral 7B avoid these drawbacks, but
their capacity for clinical tasks has been understudied. To help assess their
potential for clinical use and help researchers decide which model they should
use, we compare their performance on two clinical question-answering (QA)
tasks: MedQA and consumer query answering. We find that Mistral 7B is the best
performing model, winning on all benchmarks and outperforming models trained
specifically for the biomedical domain. While Mistral 7B's MedQA score of 63.0%
approaches the original Med-PaLM, and it often can produce plausible responses
to consumer health queries, room for improvement still exists. This study
provides the first head-to-head assessment of open source mid-sized models on
clinical tasks.

摘要：大型語言模型，例如 GPT-4 和 Med-PaLM，已經表現出了令人印象深刻的表現
臨床任務的表現；然而，它們需要訪問計算，是
閉源，無法部署在設備上。中型型號，例如
BioGPT-large、BioMedLM、LLaMA 2 和 Mistral 7B 避免了這些缺點，但是
他們的臨床任務能力尚未被充分研究。幫助評估他們的
具有臨床使用的潛力並幫助研究人員決定他們應該使用哪種模型
使用，我們比較他們在兩個臨床問答（QA）上的表現
任務：MedQA 和消費者查詢回答。我們發現 Mistral 7B 是最好的
執行模型，在所有基準測試中獲勝並優於經過訓練的模型
專門針對生物醫學領域。而 Mistral 7B 的 MedQA 分數為 63.0%
接近原始的 Med-PaLM，並且通常可以產生合理的回應
對於消費者的健康查詢，仍有改進的空間。這項研究
首次對開源中型模型進行頭對頭評估
臨床任務。

##### **Enhancing Diagnosis through AI-driven Analysis of Reflectance Confocal Microscopy**
2404.16080v1 by Hong-Jun Yoon,Chris Keum,Alexander Witkowski,Joanna Ludzik,Tracy Petrie,Heidi A. Hanson,Sancy A. Leachman

Reflectance Confocal Microscopy (RCM) is a non-invasive imaging technique
used in biomedical research and clinical dermatology. It provides virtual
high-resolution images of the skin and superficial tissues, reducing the need
for physical biopsies. RCM employs a laser light source to illuminate the
tissue, capturing the reflected light to generate detailed images of
microscopic structures at various depths. Recent studies explored AI and
machine learning, particularly CNNs, for analyzing RCM images. Our study
proposes a segmentation strategy based on textural features to identify
clinically significant regions, empowering dermatologists in effective image
interpretation and boosting diagnostic confidence. This approach promises to
advance dermatological diagnosis and treatment.

摘要：反射共焦顯微鏡 (RCM) 是一種非侵入性成像技術
用於生物醫學研究和臨床皮膚病學。它提供虛擬
皮膚和淺表組織的高解析度影像，減少了需要
用於物理活檢。 RCM 以雷射光源照亮
組織，捕捉反射光以產生詳細的圖像
不同深度的微觀結構。最近的研究探索了人工智慧和
機器學習，特別是 CNN，用於分析 RCM 影像。我們的研究
提出了一種基於紋理特徵的分割策略來識別
臨床重要區域，使皮膚科醫生能夠獲得有效的影像
解釋並增強診斷信心。這種方法承諾
推進皮膚病診斷和治療。

##### **Anomaly Detection for Incident Response at Scale**
2404.16887v1 by Hanzhang Wang,Gowtham Kumar Tangirala,Gilkara Pranav Naidu,Charles Mayville,Arighna Roy,Joanne Sun,Ramesh Babu Mandava

We present a machine learning-based anomaly detection product, AI Detect and
Respond (AIDR), that monitors Walmart's business and system health in
real-time. During the validation over 3 months, the product served predictions
from over 3000 models to more than 25 application, platform, and operation
teams, covering 63\% of major incidents and reducing the mean-time-to-detect
(MTTD) by more than 7 minutes. Unlike previous anomaly detection methods, our
solution leverages statistical, ML and deep learning models while continuing to
incorporate rule-based static thresholds to incorporate domain-specific
knowledge. Both univariate and multivariate ML models are deployed and
maintained through distributed services for scalability and high availability.
AIDR has a feedback loop that assesses model quality with a combination of
drift detection algorithms and customer feedback. It also offers
self-onboarding capabilities and customizability. AIDR has achieved success
with various internal teams with lower time to detection and fewer false
positives than previous methods. As we move forward, we aim to expand incident
coverage and prevention, reduce noise, and integrate further with root cause
recommendation (RCR) to enable an end-to-end AIDR experience.

摘要：我們推出了基於機器學習的異常檢測產品 AI Detect 和
回應（AIDR），監控沃爾瑪的業務和系統健康狀況
即時的。在超過 3 個月的驗證過程中，該產品實現了預測
從超過 3000 個型號到超過 25 個應用程式、平台和操作
團隊，覆蓋 63% 的重大事件並縮短平均檢測時間
（MTTD）超過 7 分鐘。與先前的異常檢測方法不同，我們的
解決方案利用統計、機器學習和深度學習模型，同時繼續
合併基於規則的靜態閾值以合併特定於域的
知識。單變量和多變量 ML 模型均已部署並
透過分散式服務進行維護，以實現可擴展性和高可用性。
AIDR 有一個回饋循環，可以結合以下因素來評估模型品質：
漂移檢測演算法和客戶回饋。它還提供
自我入門能力和可自訂性。 AIDR取得了成功
與各個內部團隊合作，檢測時間更短，錯誤更少
比以前的方法有正面作用。隨著我們的前進，我們的目標是擴大事件範圍
覆蓋和預防，減少噪音，進一步結合根本原因
推薦（RCR）以實現端到端 AIDR 體驗。

##### **Adapting an Artificial Intelligence Sexually Transmitted Diseases Symptom Checker Tool for Mpox Detection: The HeHealth Experience**
2404.16885v1 by Rayner Kay Jin Tan,Dilruk Perera,Salomi Arasaratnam,Yudara Kularathne

Artificial Intelligence applications have shown promise in the management of
pandemics and have been widely used to assist the identification,
classification, and diagnosis of medical images. In response to the global
outbreak of Monkeypox (Mpox), the HeHealth.ai team leveraged an existing tool
to screen for sexually transmitted diseases to develop a digital screening test
for symptomatic Mpox through AI approaches. Prior to the global outbreak of
Mpox, the team developed a smartphone app, where app users can use their own
smartphone cameras to take pictures of their own penises to screen for
symptomatic STD. The AI model was initially developed using 5000 cases and use
a modified convolutional neural network to output prediction scores across
visually diagnosable penis pathologies including Syphilis, Herpes Simplex
Virus, and Human Papilloma Virus. From June 2022 to October 2022, a total of
about 22,000 users downloaded the HeHealth app, and about 21,000 images have
been analyzed using HeHealth AI technology. We then engaged in formative
research, stakeholder engagement, rapid consolidation images, a validation
study, and implementation of the tool from July 2022. From July 2022 to October
2022, a total of 1000 Mpox related images had been used to train the Mpox
symptom checker tool. Our digital symptom checker tool showed accuracy of 87%
to rule in Mpox and 90% to rule out symptomatic Mpox. Several hurdles
identified included issues of data privacy and security for app users, initial
lack of data to train the AI tool, and the potential generalizability of input
data. We offer several suggestions to help others get started on similar
projects in emergency situations, including engaging a wide range of
stakeholders, having a multidisciplinary team, prioritizing pragmatism, as well
as the concept that big data in fact is made up of small data.

摘要：人工智慧的應用在管理方面顯示出前景
流行病並已被廣泛用於協助識別，
醫學影像的分類和診斷。為回應全球
猴痘 (Mpox) 爆發時，HeHealth.ai 團隊利用現有工具
篩檢性傳染病 開發數位篩檢測試
透過人工智慧方法治療有症狀的 Mpox。在全球疫情爆發之前
Mpox，該團隊開發了一款智慧型手機應用程序，應用程式用戶可以使用自己的
智慧型手機相機可以拍攝自己的陰莖照片以供篩選
有症狀的性病。 AI模型最初是使用5000個案例開發的，並使用
改進的捲積神經網絡，用於輸出預測分數
可目視診斷的陰莖病變，包括梅毒、單純皰疹
病毒和人類乳突病毒。 2022年6月至2022年10月，共計
約 22,000 名用戶下載了 HeHealth 應用程序，並發布了約 21,000 張圖片
使用 HeHealth AI 技術進行分析。然後我們進行了形成性的
研究、利害關係人參與、快速整合影像、驗證
從 2022 年 7 月開始研究和實施該工具。
2022年，總共使用了1000張Mpox相關影像來訓練Mpox
症狀檢查工具。我們的數位症狀檢查工具顯示準確度為 87%
排除 Mpox，90% 排除有症狀的 Mpox。幾個障礙
確定的問題包括應用程式使用者的資料隱私和安全問題，初始
缺乏訓練人工智慧工具的數據以及輸入的潛在普遍性
數據。我們提供了一些建議來幫助其他人開始類似的工作
緊急情況下的項目，包括廣泛參與
利害關係人，擁有多學科團隊，優先考慮實用主義，以及
大數據其實是由小數據組成的概念。

##### **PRISM: Patient Records Interpretation for Semantic Clinical Trial Matching using Large Language Models**
2404.15549v1 by Shashi Kant Gupta,Aditya Basu,Mauro Nievas,Jerrin Thomas,Nathan Wolfrath,Adhitya Ramamurthi,Bradley Taylor,Anai N. Kothari,Therica M. Miller,Sorena Nadaf-Rahrov,Yanshan Wang,Hrituraj Singh

Clinical trial matching is the task of identifying trials for which patients
may be potentially eligible. Typically, this task is labor-intensive and
requires detailed verification of patient electronic health records (EHRs)
against the stringent inclusion and exclusion criteria of clinical trials. This
process is manual, time-intensive, and challenging to scale up, resulting in
many patients missing out on potential therapeutic options. Recent advancements
in Large Language Models (LLMs) have made automating patient-trial matching
possible, as shown in multiple concurrent research studies. However, the
current approaches are confined to constrained, often synthetic datasets that
do not adequately mirror the complexities encountered in real-world medical
data. In this study, we present the first, end-to-end large-scale empirical
evaluation of clinical trial matching using real-world EHRs. Our study
showcases the capability of LLMs to accurately match patients with appropriate
clinical trials. We perform experiments with proprietary LLMs, including GPT-4
and GPT-3.5, as well as our custom fine-tuned model called OncoLLM and show
that OncoLLM, despite its significantly smaller size, not only outperforms
GPT-3.5 but also matches the performance of qualified medical doctors. All
experiments were carried out on real-world EHRs that include clinical notes and
available clinical trials from a single cancer center in the United States.

摘要：臨床試驗配對是確定患者參與的試驗的任務
可能有資格。通常，這項任務是勞力密集的，
需要詳細驗證病患電子健康紀錄 (EHR)
違反臨床試驗嚴格的納入與排除標準。這
該過程是手動的，耗時且難以擴大規模，導致
許多患者錯過了潛在的治療選擇。最新進展
大型語言模型 (LLM) 已經實現了患者試驗匹配的自動化
正如多項同時進行的研究表明，這是可能的。但是，那
目前的方法僅限於受約束的、通常是合成的資料集
沒有充分反映現實世界醫療中所遇到的複雜性
數據。在這項研究中，我們提出了第一個端到端的大規模實證研究
使用真實世界的 EHR 評估臨床試驗配對。我們的研究
展示了LLM將患者與合適的患者準確匹配的能力
臨床試驗。我們使用專有的 LLM 進行實驗，包括 GPT-4
和 GPT-3.5，以及我們的客製化微調模型 OncoLLM 並顯示
儘管 OncoLLM 的尺寸小得多，但其性能不僅優於
GPT-3.5也符合合格醫師的表現。全部
實驗是在現實世界的 EHR 上進行的，其中包括臨床記錄和
來自美國單一癌症中心的可用臨床試驗。

##### **Multi-scale Intervention Planning based on Generative Design**
2404.15492v1 by Ioannis Kavouras,Ioannis Rallis,Emmanuel Sardis,Eftychios Protopapadakis,Anastasios Doulamis,Nikolaos Doulamis

The scarcity of green spaces, in urban environments, consists a critical
challenge. There are multiple adverse effects, impacting the health and
well-being of the citizens. Small scale interventions, e.g. pocket parks, is a
viable solution, but comes with multiple constraints, involving the design and
implementation over a specific area. In this study, we harness the capabilities
of generative AI for multi-scale intervention planning, focusing on nature
based solutions. By leveraging image-to-image and image inpainting algorithms,
we propose a methodology to address the green space deficit in urban areas.
Focusing on two alleys in Thessaloniki, where greenery is lacking, we
demonstrate the efficacy of our approach in visualizing NBS interventions. Our
findings underscore the transformative potential of emerging technologies in
shaping the future of urban intervention planning processes.

摘要：城市環境中綠色空間的稀缺是一個關鍵問題
挑戰。存在多種不良影響，影響健康
公民的福祉。小規模幹預措施，例如袖珍公園，是一個
可行的解決方案，但有許多限制，涉及設計和
特定領域的實施。在本研究中，我們利用以下能力
生成人工智慧用於多尺度幹預規劃，關注自然
基於的解決方案。透過利用圖像到圖像和圖像修復演算法，
我們提出了一種解決城市地區綠地不足的方法。
我們專注於塞薩洛尼基缺乏綠化的兩條小巷，
證明我們的方法在可視化 NBS 介入方面的有效性。我們的
研究結果強調了新興技術的變革潛力
塑造城市干預規劃流程的未來。

##### **IryoNLP at MEDIQA-CORR 2024: Tackling the Medical Error Detection & Correction Task On the Shoulders of Medical Agents**
2404.15488v1 by Jean-Philippe Corbeil

In natural language processing applied to the clinical domain, utilizing
large language models has emerged as a promising avenue for error detection and
correction on clinical notes, a knowledge-intensive task for which annotated
data is scarce. This paper presents MedReAct'N'MedReFlex, which leverages a
suite of four LLM-based medical agents. The MedReAct agent initiates the
process by observing, analyzing, and taking action, generating trajectories to
guide the search to target a potential error in the clinical notes.
Subsequently, the MedEval agent employs five evaluators to assess the targeted
error and the proposed correction. In cases where MedReAct's actions prove
insufficient, the MedReFlex agent intervenes, engaging in reflective analysis
and proposing alternative strategies. Finally, the MedFinalParser agent formats
the final output, preserving the original style while ensuring the integrity of
the error correction process. One core component of our method is our RAG
pipeline based on our ClinicalCorp corpora. Among other well-known sources
containing clinical guidelines and information, we preprocess and release the
open-source MedWiki dataset for clinical RAG application. Our results
demonstrate the central role of our RAG approach with ClinicalCorp leveraged
through the MedReAct'N'MedReFlex framework. It achieved the ninth rank on the
MEDIQA-CORR 2024 final leaderboard.

摘要：在應用於臨床領域的自然語言處理中，利用
大型語言模型已成為錯誤檢測和預測的有前途的途徑
臨床筆記的更正，這是一項知識密集型任務，其註釋
數據稀缺。本文介紹了 MedReAct'N'MedReFlex，它利用
由四位LLM醫療代理人組成的套件。 MedReAct 代理程式啟動
透過觀察、分析和採取行動來產生軌跡
指導搜尋以瞄準臨床記錄中的潛在錯誤。
隨後，MedEval 代理僱用五名評估員來評估目標
錯誤和建議的更正。如果 MedReAct 的行動證明
不足時，MedReFlex 代理人介入，進行反思分析
並提出替代策略。最後，MedFinalParser 代理格式
最終輸出，保留原始風格的同時保證完整性
糾錯過程。我們方法的核心組成部分是 RAG
基於我們的 ClinicalCorp 語料庫的管道。除其他知名來源外
包含臨床指南和訊息，我們預處理並發布
用於臨床 RAG 應用的開源 MedWiki 資料集。我們的成果
利用 ClinicalCorp 展示我們的 RAG 方法的核心作用
透過 MedReAct'N'MedReFlex 框架。並取得了第九名的好成績
MEDIQA-CORR 2024 年最終排行榜。

##### **Machine Learning Techniques with Fairness for Prediction of Completion of Drug and Alcohol Rehabilitation**
2404.15418v1 by Karen Roberts-Licklider,Theodore Trafalis

The aim of this study is to look at predicting whether a person will complete
a drug and alcohol rehabilitation program and the number of times a person
attends. The study is based on demographic data obtained from Substance Abuse
and Mental Health Services Administration (SAMHSA) from both admissions and
discharge data from drug and alcohol rehabilitation centers in Oklahoma.
Demographic data is highly categorical which led to binary encoding being used
and various fairness measures being utilized to mitigate bias of nine
demographic variables. Kernel methods such as linear, polynomial, sigmoid, and
radial basis functions were compared using support vector machines at various
parameter ranges to find the optimal values. These were then compared to
methods such as decision trees, random forests, and neural networks. Synthetic
Minority Oversampling Technique Nominal (SMOTEN) for categorical data was used
to balance the data with imputation for missing data. The nine bias variables
were then intersectionalized to mitigate bias and the dual and triple
interactions were integrated to use the probabilities to look at worst case
ratio fairness mitigation. Disparate Impact, Statistical Parity difference,
Conditional Statistical Parity Ratio, Demographic Parity, Demographic Parity
Ratio, Equalized Odds, Equalized Odds Ratio, Equal Opportunity, and Equalized
Opportunity Ratio were all explored at both the binary and multiclass
scenarios.

摘要：這項研究的目的是預測一個人是否會完成
戒毒和酗酒康復計劃以及一個人的次數
參加。該研究基於從藥物濫用獲得的人口統計數據
和心理健康服務管理局 (SAMHSA) 的招生和
俄克拉荷馬州戒毒和酗酒康復中心的出院數據。
人口統計資料高度分類，導致使用二進位編碼
以及利用各種公平措施來減輕九個面向的偏見
人口統計變數。核方法，例如線性、多項式、Sigmoid 和
使用支援向量機在不同的條件下比較徑向基底函數
參數範圍以找到最佳值。然後將這些與
決策樹、隨機森林和神經網路等方法。合成的
使用針對分類資料的少數過採樣技術標稱 (SMOTEN)
透過缺失資料的插補來平衡資料。九個偏差變數
然後交叉化以減輕偏差以及雙重和三重
整合互動以使用機率來查看最壞情況
比率公平性緩解。不同的影響，統計奇偶差異，
有條件統計奇偶比、人口奇偶、人口奇偶
比率、均等賠率、均等賠率比、均等機會及均等
機會比均在二元和多類別中進行了探討
場景。

##### **CT-GLIP: 3D Grounded Language-Image Pretraining with CT Scans and Radiology Reports for Full-Body Scenarios**
2404.15272v2 by Jingyang Lin,Yingda Xia,Jianpeng Zhang,Ke Yan,Le Lu,Jiebo Luo,Ling Zhang

Medical Vision-Language Pretraining (Med-VLP) establishes a connection
between visual content from medical images and the relevant textual
descriptions. Existing Med-VLP methods primarily focus on 2D images depicting a
single body part, notably chest X-rays. In this paper, we extend the scope of
Med-VLP to encompass 3D images, specifically targeting full-body scenarios, by
using a multimodal dataset of CT images and reports. Compared with the 2D
counterpart, 3D VLP is required to effectively capture essential semantics from
significantly sparser representation in 3D imaging. In this paper, we introduce
CT-GLIP (Grounded Language-Image Pretraining with CT scans), a novel method
that constructs organ-level image-text pairs to enhance multimodal contrastive
learning, aligning grounded visual features with precise diagnostic text.
Additionally, we developed an abnormality dictionary to augment contrastive
learning with diverse contrastive pairs. Our method, trained on a multimodal CT
dataset comprising 44,011 organ-level vision-text pairs from 17,702 patients
across 104 organs, demonstrates it can identify organs and abnormalities in a
zero-shot manner using natural languages. The performance of CT-GLIP is
validated on a separate test set of 1,130 patients, focusing on the 16 most
frequent abnormalities across 7 organs. The experimental results show our
model's superior performance over the standard CLIP framework across zero-shot
and fine-tuning scenarios, using both CNN and ViT architectures.

摘要：醫學視覺語言預訓練 (Med-VLP) 建立聯繫
醫學影像的視覺內容與相關文字之間
描述。現有的 Med-VLP 方法主要著重於描繪
單一身體部位，特別是胸部 X 光檢查。在本文中，我們擴展了範圍
Med-VLP 涵蓋 3D 影像，特別針對全身場景，透過
使用 CT 影像和報告的多模態資料集。與二維相比
對應地，需要 3D VLP 來有效地捕捉來自
3D 成像中的表示顯著稀疏。在本文中，我們介紹
CT-GLIP（基於 CT 掃描的接地語言影像預訓練），一種新方法
建構器官級影像文字對以增強多模態對比
學習，將基礎視覺特徵與精確的診斷文本結合。
此外，我們開發了異常字典來增強對比
與不同的對比組一起學習。我們的方法經過多模態 CT 訓練
資料集包含 17,702 名患者的 44,011 個器官級視覺文本對
跨越 104 個器官，證明它可以識別器官和異常情況
使用自然語言的零樣本方式。 CT-GLIP的性能為
在由 1,130 名患者組成的單獨測試集上進行驗證，重點關注 16 名最重要的患者
7個器官經常出現異常。實驗結果顯示我們
模型在零樣本中優於標準 CLIP 框架的性能
並使用 CNN 和 ViT 架構微調場景。

##### **A review of deep learning-based information fusion techniques for multimodal medical image classification**
2404.15022v1 by Yihao Li,Mostafa El Habib Daho,Pierre-Henri Conze,Rachid Zeghlache,Hugo Le Boité,Ramin Tadayoni,Béatrice Cochener,Mathieu Lamard,Gwenolé Quellec

Multimodal medical imaging plays a pivotal role in clinical diagnosis and
research, as it combines information from various imaging modalities to provide
a more comprehensive understanding of the underlying pathology. Recently, deep
learning-based multimodal fusion techniques have emerged as powerful tools for
improving medical image classification. This review offers a thorough analysis
of the developments in deep learning-based multimodal fusion for medical
classification tasks. We explore the complementary relationships among
prevalent clinical modalities and outline three main fusion schemes for
multimodal classification networks: input fusion, intermediate fusion
(encompassing single-level fusion, hierarchical fusion, and attention-based
fusion), and output fusion. By evaluating the performance of these fusion
techniques, we provide insight into the suitability of different network
architectures for various multimodal fusion scenarios and application domains.
Furthermore, we delve into challenges related to network architecture
selection, handling incomplete multimodal data management, and the potential
limitations of multimodal fusion. Finally, we spotlight the promising future of
Transformer-based multimodal fusion techniques and give recommendations for
future research in this rapidly evolving field.

摘要：多模態醫學影像在臨床診斷和治療中發揮關鍵作用
研究，因為它結合了來自各種成像方式的資訊來提供
對潛在病理學有更全面的了解。最近，深
基於學習的多模態融合技術已成為強大的工具
改進醫學影像分類。這篇評論提供了全面的分析
基於深度學習的醫學多模態融合的發展
分類任務。我們探索之間的互補關係
流行的臨床模式並概述了三種主要的融合方案
多模態分類網路：輸入融合、中間融合
（包括單層融合、分層融合和基於注意力的融合
融合），並輸出融合。透過評估這些融合的性能
技術，我們提供對不同網路的適用性的深入了解
適用於各種多模態融合場景和應用領域的架構。
此外，我們深入研究與網路架構相關的挑戰
選擇、處理不完整的多模式資料管理以及潛力
多模態融合的限制。最後，我們展望了未來的光明前景
基於Transformer的多模態融合技術並給予建議
這個快速發展的領域的未來研究。

##### **Clustering of timed sequences -- Application to the analysis of care pathways**
2404.15379v1 by Thomas Guyet,Pierre Pinson,Enoal Gesny

Improving the future of healthcare starts by better understanding the current
actual practices in hospitals. This motivates the objective of discovering
typical care pathways from patient data. Revealing homogeneous groups of care
pathways can be achieved through clustering. The difficulty in clustering care
pathways, represented by sequences of timestamped events, lies in defining a
semantically appropriate metric and clustering algorithms.
  In this article, we adapt two methods developed for time series to time
sequences: the drop-DTW metric and the DBA approach for the construction of
averaged time sequences. These methods are then applied in clustering
algorithms to propose original and sound clustering algorithms for timed
sequences.
  This approach is experimented with and evaluated on synthetic and real use
cases.

摘要：改善醫療保健的未來首先要更了解當前的情況
醫院的實際操作。這激發了發現的目標
來自病患資料的典型照護途徑。揭示同質護理群體
路徑可以透過聚類來實現。集群護理的困難
由帶有時間戳記的事件序列所表示的路徑在於定義
語意上適當的度量和聚類演算法。
  在本文中，我們將兩種為時間序列所開發的方法應用於時間
序列：drop-DTW 度量和用於建構的 DBA 方法
平均時間序列。然後將這些方法應用於聚類
提出原始且合理的定時聚類演算法的演算法
序列。
  這種方法在合成和實際使用中進行了實驗和評估
案例。

##### **Grounded Knowledge-Enhanced Medical VLP for Chest X-Ray**
2404.14750v1 by Qiao Deng,Zhongzhen Huang,Yunqi Wang,Zhichuan Wang,Zhao Wang,Xiaofan Zhang,Qi Dou,Yeung Yu Hui,Edward S. Hui

Medical vision-language pre-training has emerged as a promising approach for
learning domain-general representations of medical image and text. Current
algorithms that exploit the global and local alignment between medical image
and text could however be marred by the redundant information in medical data.
To address this issue, we propose a grounded knowledge-enhanced medical
vision-language pre-training (GK-MVLP) framework for chest X-ray. In this
framework, medical knowledge is grounded to the appropriate anatomical regions
by using a transformer-based grounded knowledge-enhanced module for
fine-grained alignment between anatomical region-level visual features and the
textural features of medical knowledge. The performance of GK-MVLP is
competitive with or exceeds the state of the art on downstream chest X-ray
disease classification, disease localization, report generation, and medical
visual question-answering tasks. Our results show the advantage of
incorporating grounding mechanism to remove biases and improve the alignment
between chest X-ray image and radiology report.

摘要：醫學視覺語言預訓練已成為一種有前途的方法
學習醫學影像和文字的領域通用表示。目前的
利用醫學影像之間的全局和局部對齊的演算法
然而，文字可能會因醫療資料中的冗餘資訊而受到損害。
為了解決這個問題，我們提出了一種紮根的知識增強醫學
胸部 X 光視覺語言預訓練 (GK-MVLP) 框架。在這個
框架中，醫學知識植根於適當的解剖區域
透過使用基於變壓器的接地知識增強模組
解剖區域級視覺特徵和
醫學知識的結構特徵。 GK-MVLP的性能為
在下游胸部 X 光檢查方面具有競爭力或超過現有技術水平
疾病分類、疾病定位、報告產生、醫療
視覺問答任務。我們的結果顯示了以下優勢
結合接地機制以消除偏差並改善對準
胸部 X 光影像和放射學報告之間的關係。

##### **DAIC-WOZ: On the Validity of Using the Therapist's prompts in Automatic Depression Detection from Clinical Interviews**
2404.14463v1 by Sergio Burdisso,Ernesto Reyes-Ramírez,Esaú Villatoro-Tello,Fernando Sánchez-Vega,Pastor López-Monroy,Petr Motlicek

Automatic depression detection from conversational data has gained
significant interest in recent years. The DAIC-WOZ dataset, interviews
conducted by a human-controlled virtual agent, has been widely used for this
task. Recent studies have reported enhanced performance when incorporating
interviewer's prompts into the model. In this work, we hypothesize that this
improvement might be mainly due to a bias present in these prompts, rather than
the proposed architectures and methods. Through ablation experiments and
qualitative analysis, we discover that models using interviewer's prompts learn
to focus on a specific region of the interviews, where questions about past
experiences with mental health issues are asked, and use them as discriminative
shortcuts to detect depressed participants. In contrast, models using
participant responses gather evidence from across the entire interview.
Finally, to highlight the magnitude of this bias, we achieve a 0.90 F1 score by
intentionally exploiting it, the highest result reported to date on this
dataset using only textual information. Our findings underline the need for
caution when incorporating interviewers' prompts into models, as they may
inadvertently learn to exploit targeted prompts, rather than learning to
characterize the language and behavior that are genuinely indicative of the
patient's mental health condition.

摘要：從對話數據中自動檢測憂鬱症已經取得了進展
近年來產生了重大興趣。 DAIC-WOZ 資料集，訪談
由人類控制的虛擬代理進行，已被廣泛用於此
任務。最近的研究報告稱，合併後性能提高
面試官的提示進入模型。在這項工作中，我們假設這
改進可能主要是由於這些提示中存在的偏見，而不是
所提出的架構和方法。透過消融實驗和
定性分析，我們發現模型使用訪談者的提示進行學習
重點關注訪談的特定區域，其中涉及過去的問題
詢問心理健康問題的經歷，並將其用作歧視性的
檢測抑鬱參與者的捷徑。相反，模型使用
參與者的回答從整個訪談中收集證據。
最後，為了強調這種偏差的嚴重程度，我們透過以下方式獲得了 0.90 F1 分數：
有意利用它，迄今為止報告的最高結果
僅使用文字資訊的資料集。我們的研究結果強調需要
將訪談員的提示納入模型時要小心，因為它們可能會
無意中學會利用有針對性的提示，而不是學會
描述真正代表的語言和行為
患者的心理健康狀況。

##### **Adaptive Collaboration Strategy for LLMs in Medical Decision Making**
2404.15155v1 by Yubin Kim,Chanwoo Park,Hyewon Jeong,Yik Siu Chan,Xuhai Xu,Daniel McDuff,Cynthia Breazeal,Hae Won Park

Foundation models have become invaluable in advancing the medical field.
Despite their promise, the strategic deployment of LLMs for effective utility
in complex medical tasks remains an open question. Our novel framework, Medical
Decision-making Agents (MDAgents) aims to address this gap by automatically
assigning the effective collaboration structure for LLMs. Assigned solo or
group collaboration structure is tailored to the complexity of the medical task
at hand, emulating real-world medical decision making processes. We evaluate
our framework and baseline methods with state-of-the-art LLMs across a suite of
challenging medical benchmarks: MedQA, MedMCQA, PubMedQA, DDXPlus, PMC-VQA,
Path-VQA, and MedVidQA, achieving the best performance in 5 out of 7 benchmarks
that require an understanding of multi-modal medical reasoning. Ablation
studies reveal that MDAgents excels in adapting the number of collaborating
agents to optimize efficiency and accuracy, showcasing its robustness in
diverse scenarios. We also explore the dynamics of group consensus, offering
insights into how collaborative agents could behave in complex clinical team
dynamics. Our code can be found at https://github.com/mitmedialab/MDAgents.

摘要：基礎模型對於推動醫學領域的發展具有無價的價值。
儘管他們做出了承諾，但為了有效利用LLM的策略部署
在複雜的醫療任務中的應用仍然是一個懸而未決的問題。我們的新穎框架，醫療
決策代理 (MDAgents) 旨在透過自動解決這一差距
為LLM分配有效的合作結構。指定獨奏或
小組協作結構根據醫療任務的複雜性量身定制
模擬現實世界的醫療決策過程。我們評估
我們的框架和基線方法以及跨一系列最先進的LLM
具挑戰性的醫療基準：MedQA、MedMCQA、PubMedQA、DDXPlus、PMC-VQA、
Path-VQA 和 MedVidQA，在 7 個基準測試中的 5 個中取得最佳效能
這需要了解多模式醫學推理。消融
研究表明，MDAgents 在調整協作數量方面表現出色
代理優化效率和準確性，展現其穩健性
多樣化的場景。我們也探索團體共識的動態，提供
深入了解協作代理如何在複雜的臨床團隊中表現
動力學。我們的程式碼可以在 https://github.com/mitmedialab/MDAgents 找到。

##### **A Nasal Cytology Dataset for Object Detection and Deep Learning**
2404.13745v1 by Mauro Camporeale,Giovanni Dimauro,Matteo Gelardi,Giorgia Iacobellis,Mattia Sebastiano Ladisa,Sergio Latrofa,Nunzia Lomonte

Nasal Cytology is a new and efficient clinical technique to diagnose rhinitis
and allergies that is not much widespread due to the time-consuming nature of
cell counting; that is why AI-aided counting could be a turning point for the
diffusion of this technique. In this article we present the first dataset of
rhino-cytological field images: the NCD (Nasal Cytology Dataset), aimed to
train and deploy Object Detection models to support physicians and biologists
during clinical practice. The real distribution of the cytotypes, populating
the nasal mucosa has been replicated, sampling images from slides of clinical
patients, and manually annotating each cell found on them. The correspondent
object detection task presents non'trivial issues associated with the strong
class imbalancement, involving the rarest cell types. This work contributes to
some of open challenges by presenting a novel machine learning-based approach
to aid the automated detection and classification of nasal mucosa cells: the
DETR and YOLO models shown good performance in detecting cells and classifying
them correctly, revealing great potential to accelerate the work of rhinology
experts.

摘要：鼻細胞學是診斷鼻炎的一種新的、有效的臨床技術
以及由於耗時的性質而不太普遍的過敏
細胞計數；這就是為什麼人工智慧輔助計數可能是一個轉捩點
這項技術的傳播。在本文中，我們展示了第一個資料集
鼻細胞學領域影像：NCD（鼻細胞學資料集），旨在
訓練和部署物件檢測模型來支援醫生和生物學家
在臨床實務過程中。細胞類型的真實分佈，填充
鼻黏膜已被複製，從臨床幻燈片中採樣影像
患者，並手動註釋在他們身上發現的每個細胞。通訊員
物體偵測任務提出了與強相關的重要問題
類別不平衡，涉及最稀有的細胞類型。這項工作有助於
透過提出一種新穎的基於機器學習的方法來應對一些開放的挑戰
幫助鼻粘膜細胞的自動檢測和分類：
DETR和YOLO模型在檢測細胞和分類方面表現出良好的性能
正確地揭示了加速鼻科學工作的巨大潛力
專家。

##### **Bt-GAN: Generating Fair Synthetic Healthdata via Bias-transforming Generative Adversarial Networks**
2404.13634v3 by Resmi Ramachandranpillai,Md Fahim Sikder,David Bergström,Fredrik Heintz

Synthetic data generation offers a promising solution to enhance the
usefulness of Electronic Healthcare Records (EHR) by generating realistic
de-identified data. However, the existing literature primarily focuses on the
quality of synthetic health data, neglecting the crucial aspect of fairness in
downstream predictions. Consequently, models trained on synthetic EHR have
faced criticism for producing biased outcomes in target tasks. These biases can
arise from either spurious correlations between features or the failure of
models to accurately represent sub-groups. To address these concerns, we
present Bias-transforming Generative Adversarial Networks (Bt-GAN), a GAN-based
synthetic data generator specifically designed for the healthcare domain. In
order to tackle spurious correlations (i), we propose an
information-constrained Data Generation Process that enables the generator to
learn a fair deterministic transformation based on a well-defined notion of
algorithmic fairness. To overcome the challenge of capturing exact sub-group
representations (ii), we incentivize the generator to preserve sub-group
densities through score-based weighted sampling. This approach compels the
generator to learn from underrepresented regions of the data manifold. We
conduct extensive experiments using the MIMIC-III database. Our results
demonstrate that Bt-GAN achieves SOTA accuracy while significantly improving
fairness and minimizing bias amplification. We also perform an in-depth
explainability analysis to provide additional evidence supporting the validity
of our study. In conclusion, our research introduces a novel and professional
approach to addressing the limitations of synthetic data generation in the
healthcare domain. By incorporating fairness considerations and leveraging
advanced techniques such as GANs, we pave the way for more reliable and
unbiased predictions in healthcare applications.

摘要：綜合數據生成提供了一個有前途的解決方案來增強
透過產生現實的電子醫療記錄（EHR）的有用性
去識別化數據。然而，現有文獻主要集中於
綜合健康數據的質量，忽略了公平性的關鍵方面
下游預測。因此，經過合成 EHR 訓練的模型已經
因在目標任務中產生偏差的結果而受到批評。這些偏見可以
源自於特徵之間的虛假相關性或失敗
模型來準確地表示子組。為了解決這些問題，我們
提出偏差轉換生成對抗網路（Bt-GAN），一種基於 GAN 的
專為醫療保健領域設計的合成資料產生器。在
為了解決虛假相關性 (i)，我們提出了
資訊受限的資料生成過程，使生成器能夠
學習基於明確定義的概念的公平確定性轉換
算法公平性。克服捕獲精確子組的挑戰
表示 (ii)，我們激勵生成器保留子組
透過基於分數的加權採樣來計算密度。這種方法迫使
生成器從資料流形的代表性不足的區域中學習。我們
使用 MIMIC-III 資料庫進行廣泛的實驗。我們的成果
證明 Bt-GAN 實現了 SOTA 精度，同時顯著提高了
公平性並最大限度地減少偏差放大。我們還進行了深入的
可解釋性分析以提供支持有效性的額外證據
我們的研究。總之，我們的研究引進了一種新穎且專業的方法
解決合成資料生成限制的方法
醫療保健領域。透過納入公平考量並利用
GAN 等先進技術，為更可靠、更可靠的技術鋪平了道路
醫療保健應用中的公正預測。

##### **SmartMem: Layout Transformation Elimination and Adaptation for Efficient DNN Execution on Mobile**
2404.13528v1 by Wei Niu,Md Musfiqur Rahman Sanim,Zhihao Shu,Jiexiong Guan,Xipeng Shen,Miao Yin,Gagan Agrawal,Bin Ren

This work is motivated by recent developments in Deep Neural Networks,
particularly the Transformer architectures underlying applications such as
ChatGPT, and the need for performing inference on mobile devices. Focusing on
emerging transformers (specifically the ones with computationally efficient
Swin-like architectures) and large models (e.g., Stable Diffusion and LLMs)
based on transformers, we observe that layout transformations between the
computational operators cause a significant slowdown in these applications.
This paper presents SmartMem, a comprehensive framework for eliminating most
layout transformations, with the idea that multiple operators can use the same
tensor layout through careful choice of layout and implementation of
operations. Our approach is based on classifying the operators into four
groups, and considering combinations of producer-consumer edges between the
operators. We develop a set of methods for searching such layouts. Another
component of our work is developing efficient memory layouts for 2.5
dimensional memory commonly seen in mobile devices. Our experimental results
show that SmartMem outperforms 5 state-of-the-art DNN execution frameworks on
mobile devices across 18 varied neural networks, including CNNs, Transformers
with both local and global attention, as well as LLMs. In particular, compared
to DNNFusion, SmartMem achieves an average speedup of 2.8$\times$, and
outperforms TVM and MNN with speedups of 6.9$\times$ and 7.9$\times$,
respectively, on average.

摘要：這項工作的動機是深度神經網路的最新發展，
特別是底層應用程式的 Transformer 架構，例如
ChatGPT，以及在行動裝置上執行推理的需要。專注於
新興的變壓器（特別是那些具有計算效率的變壓器）
Swin 式架構）和大型模型（例如穩定擴散和LLM）
基於變壓器，我們觀察到佈局之間的轉換
計算運算子會導致這些應用程式顯著變慢。
本文介紹了 SmartMem，這是一個用於消除大多數
佈局轉換，其想法是多個操作員可以使用相同的
張量佈局透過仔細選擇佈局和實現
營運.我們的方法是基於將操作員分為四類
群體，並考慮生產者-消費者之間的邊緣組合
運營商。我們開發了一套用於搜尋此類佈局的方法。其他
我們工作的一部分是為 2.5 開發高效的記憶體佈局
行動裝置中常見的維度記憶體。我們的實驗結果
顯示 SmartMem 在以下方面優於 5 個最先進的 DNN 執行框架
跨 18 個不同神經網路的行動設備，包括 CNN、Transformers
受到當地和全球的關注，以及LLM。特別是相比
相對於 DNNFusion，SmartMem 的平均加速比為 2.8$\times$，且
性能優於 TVM 和 MNN，加速分別為 6.9$\times$ 和 7.9$\times$，
分別為平均。

##### **Parameter Efficient Fine Tuning: A Comprehensive Analysis Across Applications**
2404.13506v2 by Charith Chandra Sai Balne,Sreyoshi Bhaduri,Tamoghna Roy,Vinija Jain,Aman Chadha

The rise of deep learning has marked significant progress in fields such as
computer vision, natural language processing, and medical imaging, primarily
through the adaptation of pre-trained models for specific tasks. Traditional
fine-tuning methods, involving adjustments to all parameters, face challenges
due to high computational and memory demands. This has led to the development
of Parameter Efficient Fine-Tuning (PEFT) techniques, which selectively update
parameters to balance computational efficiency with performance. This review
examines PEFT approaches, offering a detailed comparison of various strategies
highlighting applications across different domains, including text generation,
medical imaging, protein modeling, and speech synthesis. By assessing the
effectiveness of PEFT methods in reducing computational load, speeding up
training, and lowering memory usage, this paper contributes to making deep
learning more accessible and adaptable, facilitating its wider application and
encouraging innovation in model optimization. Ultimately, the paper aims to
contribute towards insights into PEFT's evolving landscape, guiding researchers
and practitioners in overcoming the limitations of conventional fine-tuning
approaches.

摘要：深度學習的興起標誌著以下領域取得了重大進展
主要是電腦視覺、自然語言處理和醫學成像
透過針對特定任務調整預先訓練的模型。傳統的
微調方法，涉及所有參數的調整，面臨挑戰
由於高計算和記憶體需求。這導致了發展
參數高效微調（PEFT）技術，選擇性更新
平衡計算效率與性能的參數。這篇評論
檢查 PEFT 方法，提供各種策略的詳細比較
強調跨不同領域的應用程序，包括文字生成，
醫學影像、蛋白質建模和語音合成。透過評估
PEFT 方法在減少計算負載、加速方面的有效性
訓練，並降低記憶體使用，本文有助於深度學習
學習更容易獲得和適應性更強，促進其更廣泛的應用和
鼓勵模型優化創新。最終，本文旨在
有助於深入了解 PEFT 不斷發展的格局，指導研究人員
和實踐者克服傳統微調的局限性
接近。

##### **SiNC+: Adaptive Camera-Based Vitals with Unsupervised Learning of Periodic Signals**
2404.13449v1 by Jeremy Speth,Nathan Vance,Patrick Flynn,Adam Czajka

Subtle periodic signals, such as blood volume pulse and respiration, can be
extracted from RGB video, enabling noncontact health monitoring at low cost.
Advancements in remote pulse estimation -- or remote photoplethysmography
(rPPG) -- are currently driven by deep learning solutions. However, modern
approaches are trained and evaluated on benchmark datasets with ground truth
from contact-PPG sensors. We present the first non-contrastive unsupervised
learning framework for signal regression to mitigate the need for labelled
video data. With minimal assumptions of periodicity and finite bandwidth, our
approach discovers the blood volume pulse directly from unlabelled videos. We
find that encouraging sparse power spectra within normal physiological
bandlimits and variance over batches of power spectra is sufficient for
learning visual features of periodic signals. We perform the first experiments
utilizing unlabelled video data not specifically created for rPPG to train
robust pulse rate estimators. Given the limited inductive biases, we
successfully applied the same approach to camera-based respiration by changing
the bandlimits of the target signal. This shows that the approach is general
enough for unsupervised learning of bandlimited quasi-periodic signals from
different domains. Furthermore, we show that the framework is effective for
finetuning models on unlabelled video from a single subject, allowing for
personalized and adaptive signal regressors.

摘要：微妙的周期性訊號，例如血液容量、脈搏和呼吸，可以被
從 RGB 影片中擷取，以低成本實現非接觸式健康監測。
遠程脈衝估計或遠程光電體積描記法的進展
(rPPG)－目前由深度學習解決方案驅動。然而，現代
方法在具有基本事實的基準資料集上進行訓練和評估
來自接觸式 PPG 感測器。我們提出了第一個非對比無監督
訊號迴歸的學習框架，以減輕標記的需要
視訊數據。在週期性和有限頻寬的最小假設下，我們的
方法直接從未標記的影片中發現血量脈衝。我們
發現在正常生理範圍內鼓勵稀疏功率譜
功率譜批次的帶限和方差足以
學習週期性訊號的視覺特徵。我們進行第一個實驗
利用並非專為 rPPG 創建的未標記視訊資料進行訓練
強大的脈搏率估計器。鑑於有限的歸納偏差，我們
透過改變，成功地將相同的方法應用於基於相機的呼吸
目標訊號的頻寬限制。這表明該方法具有通用性
足以進行有限準週期訊號的無監督學習
不同的域。此外，我們表明該框架對於
對來自單一主題的未標記影片進行微調模型，允許
個性化和自適應訊號回歸器。

##### **MultiConfederated Learning: Inclusive Non-IID Data handling with Decentralized Federated Learning**
2404.13421v1 by Michael Duchesne,Kaiwen Zhang,Chamseddine Talhi

Federated Learning (FL) has emerged as a prominent privacy-preserving
technique for enabling use cases like confidential clinical machine learning.
FL operates by aggregating models trained by remote devices which owns the
data. Thus, FL enables the training of powerful global models using
crowd-sourced data from a large number of learners, without compromising their
privacy. However, the aggregating server is a single point of failure when
generating the global model. Moreover, the performance of the model suffers
when the data is not independent and identically distributed (non-IID data) on
all remote devices. This leads to vastly different models being aggregated,
which can reduce the performance by as much as 50% in certain scenarios.
  In this paper, we seek to address the aforementioned issues while retaining
the benefits of FL. We propose MultiConfederated Learning: a decentralized FL
framework which is designed to handle non-IID data. Unlike traditional FL,
MultiConfederated Learning will maintain multiple models in parallel (instead
of a single global model) to help with convergence when the data is non-IID.
With the help of transfer learning, learners can converge to fewer models. In
order to increase adaptability, learners are allowed to choose which updates to
aggregate from their peers.

摘要：聯邦學習（FL）已成為一種突出的隱私保護方法
用於啟用機密臨床機器學習等用例的技術。
FL 透過聚合由遠端設備訓練的模型來運行，該遠端設備擁有
數據。因此，FL 能夠使用以下方法訓練強大的全局模型：
來自大量學習者的眾包數據，而不影響他們的學習
隱私。但是，聚合伺服器在以下情況下會出現單點故障：
產生全域模型。此外，模型的性能也會受到影響
當資料不是獨立同分佈（非 IID 資料）時
所有遠端設備。這導致了截然不同的模型被聚合，
在某些情況下，這可能會導致效能降低多達 50%。
  在本文中，我們尋求解決上述問題，同時保留
FL 的好處。我們提出 MultiConfederated Learning：去中心化的 FL
旨在處理非獨立同分佈資料的框架。與傳統的FL不同，
多聯合學習將並行維護多個模型（而不是
單一全域模型），以幫助資料非獨立同分佈時的收斂。
在遷移學習的幫助下，學習者可以收斂到更少的模型。在
為了提高適應性，學習者可以選擇要更新的內容
來自同行的總結。

##### **UnibucLLM: Harnessing LLMs for Automated Prediction of Item Difficulty and Response Time for Multiple-Choice Questions**
2404.13343v1 by Ana-Cristina Rogoz,Radu Tudor Ionescu

This work explores a novel data augmentation method based on Large Language
Models (LLMs) for predicting item difficulty and response time of retired USMLE
Multiple-Choice Questions (MCQs) in the BEA 2024 Shared Task. Our approach is
based on augmenting the dataset with answers from zero-shot LLMs (Falcon,
Meditron, Mistral) and employing transformer-based models based on six
alternative feature combinations. The results suggest that predicting the
difficulty of questions is more challenging. Notably, our top performing
methods consistently include the question text, and benefit from the
variability of LLM answers, highlighting the potential of LLMs for improving
automated assessment in medical licensing exams. We make our code available
https://github.com/ana-rogoz/BEA-2024.

摘要：這項工作探索了一種基於大語言的新型資料增強方法
用於預測退役 USMLE 專案難度和回應時間的模型 (LLM)
BEA 2024 共享任務中的多項選擇題 (MCQ)。我們的方法是
基於使用零樣本LLM（Falcon、
Meditron、Mistral）並採用基於變壓器的模型，該模型基於六個
替代功能組合。結果表明，預測
題目難度更具挑戰性。值得注意的是，我們表現得最好的
方法始終包含問題文本，並受益於
LLM答案的可變性，突顯了LLM提高水平的潛力
醫療執照考試的自動評估。我們提供我們的程式碼
https://github.com/ana-rogoz/BEA-2024。

##### **Practical Battery Health Monitoring using Uncertainty-Aware Bayesian Neural Network**
2404.14444v1 by Yunyi Zhao,Zhang Wei,Qingyu Yan,Man-Fai Ng,B. Sivaneasan,Cheng Xiang

Battery health monitoring and prediction are critically important in the era
of electric mobility with a huge impact on safety, sustainability, and economic
aspects. Existing research often focuses on prediction accuracy but tends to
neglect practical factors that may hinder the technology's deployment in
real-world applications. In this paper, we address these practical
considerations and develop models based on the Bayesian neural network for
predicting battery end-of-life. Our models use sensor data related to battery
health and apply distributions, rather than single-point, for each parameter of
the models. This allows the models to capture the inherent randomness and
uncertainty of battery health, which leads to not only accurate predictions but
also quantifiable uncertainty. We conducted an experimental study and
demonstrated the effectiveness of our proposed models, with a prediction error
rate averaging 13.9%, and as low as 2.9% for certain tested batteries.
Additionally, all predictions include quantifiable certainty, which improved by
66% from the initial to the mid-life stage of the battery. This research has
practical values for battery technologies and contributes to accelerating the
technology adoption in the industry.

摘要：電池健康監測和預測在這個時代至關重要
電動車對安全性、永續性和經濟性產生巨大影響
方面。現有的研究通常關注預測準確性，但傾向於
忽視可能阻礙該技術部署的實際因素
現實世界的應用程式。在本文中，我們解決了這些實際問題
考慮因素並開發基於貝葉斯神經網路的模型
預測電池壽命終止。我們的模型使用與電池相關的感測器數據
health 並對每個參數套用分佈，而不是單點
模型。這使得模型能夠捕捉到固有的隨機性並
電池健康狀況的不確定性，這不僅導致準確的預測，而且
還有可量化的不確定性。我們進行了一項實驗研究並
證明了我們提出的模型的有效性，但存在預測誤差
速率平均為 13.9%，某些測試電池的速率低至 2.9%。
此外，所有預測都包含可量化的確定性，其改善程度為
66%從電池的初始壽命到中期壽命階段。這項研究有
電池技術的實用價值，有助於加速
業界技術的採用。

##### **Beyond Self-Consistency: Ensemble Reasoning Boosts Consistency and Accuracy of LLMs in Cancer Staging**
2404.13149v1 by Chia-Hsuan Chang,Mary M. Lucas,Yeawon Lee,Christopher C. Yang,Grace Lu-Yao

Advances in large language models (LLMs) have encouraged their adoption in
the healthcare domain where vital clinical information is often contained in
unstructured notes. Cancer staging status is available in clinical reports, but
it requires natural language processing to extract the status from the
unstructured text. With the advance in clinical-oriented LLMs, it is promising
to extract such status without extensive efforts in training the algorithms.
Prompting approaches of the pre-trained LLMs that elicit a model's reasoning
process, such as chain-of-thought, may help to improve the trustworthiness of
the generated responses. Using self-consistency further improves model
performance, but often results in inconsistent generations across the multiple
reasoning paths. In this study, we propose an ensemble reasoning approach with
the aim of improving the consistency of the model generations. Using an open
access clinical large language model to determine the pathologic cancer stage
from real-world pathology reports, we show that the ensemble reasoning approach
is able to improve both the consistency and performance of the LLM in
determining cancer stage, thereby demonstrating the potential to use these
models in clinical or other domains where reliability and trustworthiness are
critical.

摘要：大語言模型（LLM）的進步鼓勵了它們在以下領域的採用：
通常包含重要臨床資訊的醫療保健領域
非結構化筆記。癌症分期狀態可在臨床報告中找到，但是
它需要自然語言處理來提取狀態
非結構化文字。隨著臨床導向的LLM的進步，它是有前途的
無需大量努力訓練演算法即可提取這種狀態。
預先訓練的LLM引發模型推理的提示方法
流程，例如思想鏈，可能有助於提高信任度
產生的響應。使用自一致性進一步改進模型
性能，但通常會導致多個世代之間的不一致
推理路徑。在這項研究中，我們提出了一種整合推理方法
目的是提高模型生成的一致性。使用開放式
訪問臨床大語言模型以確定病理癌症階段
從現實世界的病理報告中，我們表明整合推理方法
能夠提高LLM的一致性和表現
確定癌症階段，從而證明使用這些的潛力
可靠性和可信度較高的臨床或其他領域的模型
批判的。

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang,Xiaoyang Wang,Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

摘要：人工智慧透過預測為醫療保健專業人員提供支持
建模，大大改變了臨床決策。本研究解決
人工智慧應用程式對公平性和可解釋性的迫切需求
醫療保健，以確保不同患者群體的公平結果。經過
專注於敗血症相關死亡率的預測模型，我們提出了
學習性能優化的預測模型然後採用的方法
遷移學習過程以產生具有更好公平性的模型。我們的
該方法還引入了一種新穎的基於排列的特徵重要性演算法
旨在闡明每個特徵對增強公平性的貢獻
預測。與現有的可解釋性方法專注於解釋不同
特徵對預測表現的貢獻，我們提出的方法是獨一無二的
彌合了理解每個功能如何促進公平性的差距。這
鑑於膿毒症的顯著死亡率及其作用，進展至關重要
佔醫院死亡人數的三分之一。我們的方法不僅有助於識別和
減少預測模型中的偏差，同時也促進了人們之間的信任
透過提高模型的透明度和公平性來影響醫療保健利益相關者
預測，從而有助於更公平和值得信賴的醫療保健
送貨。

##### **Eye-tracking in Mixed Reality for Diagnosis of Neurodegenerative Diseases**
2404.12984v1 by Mateusz Daniol,Daria Hemmerling,Jakub Sikora,Pawel Jemiolo,Marek Wodzinski,Magdalena Wojcik-Pedziwiatr

Parkinson's disease ranks as the second most prevalent neurodegenerative
disorder globally. This research aims to develop a system leveraging Mixed
Reality capabilities for tracking and assessing eye movements. In this paper,
we present a medical scenario and outline the development of an application
designed to capture eye-tracking signals through Mixed Reality technology for
the evaluation of neurodegenerative diseases. Additionally, we introduce a
pipeline for extracting clinically relevant features from eye-gaze analysis,
describing the capabilities of the proposed system from a medical perspective.
The study involved a cohort of healthy control individuals and patients
suffering from Parkinson's disease, showcasing the feasibility and potential of
the proposed technology for non-intrusive monitoring of eye movement patterns
for the diagnosis of neurodegenerative diseases.
  Clinical relevance - Developing a non-invasive biomarker for Parkinson's
disease is urgently needed to accurately detect the disease's onset. This would
allow for the timely introduction of neuroprotective treatment at the earliest
stage and enable the continuous monitoring of intervention outcomes. The
ability to detect subtle changes in eye movements allows for early diagnosis,
offering a critical window for intervention before more pronounced symptoms
emerge. Eye tracking provides objective and quantifiable biomarkers, ensuring
reliable assessments of disease progression and cognitive function. The eye
gaze analysis using Mixed Reality glasses is wireless, facilitating convenient
assessments in both home and hospital settings. The approach offers the
advantage of utilizing hardware that requires no additional specialized
attachments, enabling examinations through personal eyewear.

摘要：帕金森氏症是第二常見的神經退化性疾病
全球混亂。本研究旨在開發一個利用混合的系統
追蹤和評估眼球運動的現實能力。在本文中，
我們提出一個醫療場景並概述應用程式的開發
旨在透過混合現實技術捕捉眼球追蹤訊號
神經退化性疾病的評估。此外，我們也介紹了一個
用於從眼睛注視分析中提取臨床相關特徵的管道，
從醫學角度描述所提議系統的功能。
該研究涉及一組健康對照個體和患者
患有帕金森氏症，展示了可行性和潛力
建議的眼球運動模式非侵入式監測技術
用於診斷神經退化性疾病。
  臨床相關性 - 開發帕金森氏症的非侵入性生物標記
迫切需要準確檢測疾病的發生。這個會
以便儘早及時採取神經保護治療
階段並能持續監測介入結果。這
檢測眼球運動的細微變化的能力可以進行早期診斷，
在出現更明顯的症狀之前提供一個關鍵的干預窗口
出現。眼動追蹤提供客觀且可量化的生物標記物，確保
對疾病進展和認知功能的可靠評估。眼
使用混合實境眼鏡進行無線視線分析，方便快捷
在家庭和醫院環境中進行評估。該方法提供了
利用不需要額外專門的硬體的優勢
附件，可透過個人眼鏡進行檢查。

##### **A Large-scale Medical Visual Task Adaptation Benchmark**
2404.12876v1 by Shentong Mo,Xufang Luo,Yansen Wang,Dongsheng Li

Visual task adaptation has been demonstrated to be effective in adapting
pre-trained Vision Transformers (ViTs) to general downstream visual tasks using
specialized learnable layers or tokens. However, there is yet a large-scale
benchmark to fully explore the effect of visual task adaptation on the
realistic and important medical domain, particularly across diverse medical
visual modalities, such as color images, X-ray, and CT. To close this gap, we
present Med-VTAB, a large-scale Medical Visual Task Adaptation Benchmark
consisting of 1.68 million medical images for diverse organs, modalities, and
adaptation approaches. Based on Med-VTAB, we explore the scaling law of medical
prompt tuning concerning tunable parameters and the generalizability of medical
visual adaptation using non-medical/medical pre-train weights. Besides, we
study the impact of patient ID out-of-distribution on medical visual
adaptation, which is a real and challenging scenario. Furthermore, results from
Med-VTAB indicate that a single pre-trained model falls short in medical task
adaptation. Therefore, we introduce GMoE-Adapter, a novel method that combines
medical and general pre-training weights through a gated mixture-of-experts
adapter, achieving state-of-the-art results in medical visual task adaptation.

摘要：視覺任務適應已被證明可以有效地適應
使用預先訓練的視覺變換器（ViT）來執行一般下游視覺任務
專門的可學習層或令牌。但目前還存在大規模的
充分探討視覺任務適應對視覺任務適應的影響
現實且重要的醫學領域，特別是跨不同的醫學領域
視覺方式，例如彩色影像、X 光和 CT。為了縮小這一差距，我們
提出 Med-VTAB，一個大規模的醫學視覺任務適應基準
由 168 萬張不同器官、模式和領域的醫學影像組成
適應方法。基於Med-VTAB，我們探討醫學的量表規律
及時調整可調參數和醫療的普遍性
使用非醫學/醫學預訓練權重進行視覺適應。除此之外，我們
研究病患 ID 分佈不均對醫學視覺的影響
適應，這是一個真實且具有挑戰性的場景。此外，結果來自
Med-VTAB 顯示單一預訓練模型在醫療任務中存在不足
適應。因此，我們引入了 GMoE-Adapter，一種結合了
透過專家組合進行醫療和一般預訓練重量
適配器，在醫學視覺任務適應方面取得了最先進的成果。

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat,Waseem Shahzad,Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

摘要：憂鬱症是當今的重要議題。根據世界衛生組織
世界衛生組織 (WHO) 預計，到 2023 年，將有超過 2.8 億人面臨
沮喪。這是一個龐大的數字；如果不認真對待，這些數字將
迅速增加。大約有 48.9 億人是社群媒體用戶。人們
在 Twitter、Facebook 等平台上表達自己的感受和情緒，
Reddit、Instagram 等。
用於研究目的。已經進行了大量的研究
各種社群媒體平台。然而，這些方法仍存在某些局限性
努力。特別是，先前的研究僅集中於檢測
憂鬱症以及推文中憂鬱症的強度。另外，還存在
資料集標籤不準確。在這項研究工作中，有五種類型
預測憂鬱症（躁鬱症、重度憂鬱、精神病性憂鬱、非典型憂鬱和產後憂鬱）
使用基於字典標籤的 Twitter 資料庫中的推文。可解釋的
人工智慧透過突出顯示推文中的某些部分來提供推理
代表憂鬱症的類型。雙向編碼器表示
Transformers (BERT) 用於特徵提取和訓練。機器
使用學習和深度學習方法來訓練模型。伯特
模型呈現最有希望的結果，整體精度達到
0.96。

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v1 by Dmytro Shvetsov,Joonas Ariva,Marharyta Domnich,Raul Vicente,Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

摘要：深度學習正在大幅改變醫學影像領域
放射學，能夠辨識醫學影像中的病理，
包括電腦斷層掃描 (CT) 和 X 光掃描。然而，性能
深度學習模型，特別是在分割任務中，通常受到以下限制：
需要大量帶註釋的資料集。為了應對這項挑戰，
透過以下方式探討弱監督語意分割的能力
可解釋人工智慧的鏡頭和反事實解釋的生成。
這項研究的範圍是開發一種新穎的反事實修復
方法（COIN）將預測的分類標籤從異常翻轉為
使用生成模型正常。例如，如果分類器認為
輸入醫學影像X為異常，表示存在病理，
生成模型旨在修復異常區域，從而扭轉
分類器的原始預測標籤。該方法使我們能夠生產
精確的病理分割，而不依賴預先存在的
分割掩模。至關重要的是，利用了圖像級標籤，它們是
比建立詳細的分割遮罩更容易取得。這
此方法的有效性透過分割合成目標來證明
來自塔爾圖大學醫院的 CT 影像中的實際腎臟腫瘤
愛沙尼亞。研究結果表明，COIN 大大超越了現有的
歸因方法，例如 RISE、ScoreCAM 和 LayerCAM，以及
Singla 等人提出的替代反事實解釋方法。這
證據顯示 COIN 是一種有前途的語意分割方法
CT 影像中的腫瘤，並在深度學習方面向前邁進了一步
醫療保健領域的應用程式更容易存取和更有效，其中帶有註釋的數據
是稀缺的。

##### **DensePANet: An improved generative adversarial network for photoacoustic tomography image reconstruction from sparse data**
2404.13101v1 by Hesam Hakimnejad,Zohreh Azimifar,Narjes Goshtasbi

Image reconstruction is an essential step of every medical imaging method,
including Photoacoustic Tomography (PAT), which is a promising modality of
imaging, that unites the benefits of both ultrasound and optical imaging
methods. Reconstruction of PAT images using conventional methods results in
rough artifacts, especially when applied directly to sparse PAT data. In recent
years, generative adversarial networks (GANs) have shown a powerful performance
in image generation as well as translation, rendering them a smart choice to be
applied to reconstruction tasks. In this study, we proposed an end-to-end
method called DensePANet to solve the problem of PAT image reconstruction from
sparse data. The proposed model employs a novel modification of UNet in its
generator, called FD-UNet++, which considerably improves the reconstruction
performance. We evaluated the method on various in-vivo and simulated datasets.
Quantitative and qualitative results show the better performance of our model
over other prevalent deep learning techniques.

摘要：影像重建是每種醫學影像方法的重要步驟，
包括光聲斷層掃描（PAT），這是一種很有前途的方法
成像，結合了超音波和光學成像的優點
方法。使用傳統方法重建 PAT 影像的結果是
粗糙的偽影，尤其是直接應用於稀疏 PAT 資料時。在最近
近年來，生成對抗網路（GAN）展現出了強大的效能
在圖像生成和翻譯方面，使它們成為明智的選擇
應用於重建任務。在這項研究中，我們提出了一種端到端的
稱為 DensePANet 的方法解決了 PAT 影像重建問題
稀疏資料。所提出的模型採用了 UNet 的新穎修改
稱為 FD-UNet++ 的生成器，可顯著改善重建
表現。我們在各種體內和模擬資料集上評估了該方法。
定量和定性結果表明我們的模型具有更好的性能
優於其他流行的深度學習技術。

##### **Transformer-Based Classification Outcome Prediction for Multimodal Stroke Treatment**
2404.12634v1 by Danqing Ma,Meng Wang,Ao Xiang,Zongqing Qi,Qin Yang

This study proposes a multi-modal fusion framework Multitrans based on the
Transformer architecture and self-attention mechanism. This architecture
combines the study of non-contrast computed tomography (NCCT) images and
discharge diagnosis reports of patients undergoing stroke treatment, using a
variety of methods based on Transformer architecture approach to predicting
functional outcomes of stroke treatment. The results show that the performance
of single-modal text classification is significantly better than single-modal
image classification, but the effect of multi-modal combination is better than
any single modality. Although the Transformer model only performs worse on
imaging data, when combined with clinical meta-diagnostic information, both can
learn better complementary information and make good contributions to
accurately predicting stroke treatment effects..

摘要：本研究提出了一個基於多模態融合架構Multitrans
Transformer 架構和自註意力機制。這種架構
結合了非對比電腦斷層掃描 (NCCT) 影像的研究和
接受中風治療的患者的出院診斷報告，使用
多種基於 Transformer 架構的方法進行預測
中風治療的功能結果。結果表明，性能
單模態文字分類明顯優於單模態文字分類
影像分類，但多模態組合的效果優於
任何單一模式。儘管 Transformer 模型僅在以下方面表現較差
影像數據與臨床元診斷資訊結合，都可以
學習更好的補充訊息，做出良好的貢獻
準確預測中風治療效果..

##### **GluMarker: A Novel Predictive Modeling of Glycemic Control Through Digital Biomarkers**
2404.12605v1 by Ziyi Zhou,Ming Cheng,Xingjian Diao,Yanjun Cui,Xiangling Li

The escalating prevalence of diabetes globally underscores the need for
diabetes management. Recent research highlights the growing focus on digital
biomarkers in diabetes management, with innovations in computational frameworks
and noninvasive monitoring techniques using personalized glucose metrics.
However, they predominantly focus on insulin dosing and specific glucose
values, or with limited attention given to overall glycemic control. This
leaves a gap in expanding the scope of digital biomarkers for overall glycemic
control in diabetes management. To address such a research gap, we propose
GluMarker -- an end-to-end framework for modeling digital biomarkers using
broader factors sources to predict glycemic control. Through the assessment and
refinement of various machine learning baselines, GluMarker achieves
state-of-the-art on Anderson's dataset in predicting next-day glycemic control.
Moreover, our research identifies key digital biomarkers for the next day's
glycemic control prediction. These identified biomarkers are instrumental in
illuminating the daily factors that influence glycemic management, offering
vital insights for diabetes care.

摘要：全球糖尿病盛行率的不斷上升凸顯了對糖尿病的必要性
糖尿病管理。最近的研究凸顯了人們對數位化日益增長的關注
糖尿病管理中的生物標誌物，以及計算框架的創新
以及使用個人化血糖指標的非侵入性監測技術。
然而，他們主要關注胰島素劑量和特定葡萄糖
數值，或對整體血糖控制的關注有限。這
在擴大整體血糖數位生物標記的範圍方面存在差距
糖尿病管理中的控制。為了解決這種研究空白，我們建議
GluMarker－一種用於數位生物標記建模的端到端框架
預測血糖控制的更廣泛的因素來源。透過評估和
各種機器學習基線的細化，GluMarker 實現
安德森資料集預測第二天血糖控制的最新技術。
此外，我們的研究還確定了第二天的關鍵數位生物標記
血糖控制預測。這些確定的生物標記有助於
闡明影響血糖管理的日常因素，提供
對糖尿病照護的重要見解。

##### **DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era**
2404.12278v1 by David Restrepo,Chenwei Wu,Constanza Vásquez-Venegas,Luis Filipe Nakayama,Leo Anthony Celi,Diego M López

In the big data era, integrating diverse data modalities poses significant
challenges, particularly in complex fields like healthcare. This paper
introduces a new process model for multimodal Data Fusion for Data Mining,
integrating embeddings and the Cross-Industry Standard Process for Data Mining
with the existing Data Fusion Information Group model. Our model aims to
decrease computational costs, complexity, and bias while improving efficiency
and reliability. We also propose "disentangled dense fusion", a novel embedding
fusion method designed to optimize mutual information and facilitate dense
inter-modality feature interaction, thereby minimizing redundant information.
  We demonstrate the model's efficacy through three use cases: predicting
diabetic retinopathy using retinal images and patient metadata, domestic
violence prediction employing satellite imagery, internet, and census data, and
identifying clinical and demographic features from radiography images and
clinical notes. The model achieved a Macro F1 score of 0.92 in diabetic
retinopathy prediction, an R-squared of 0.854 and sMAPE of 24.868 in domestic
violence prediction, and a macro AUC of 0.92 and 0.99 for disease prediction
and sex classification, respectively, in radiological analysis.
  These results underscore the Data Fusion for Data Mining model's potential to
significantly impact multimodal data processing, promoting its adoption in
diverse, resource-constrained settings.

摘要：在大數據時代，整合多元資料模式具有重要意義
挑戰，特別是在醫療保健等複雜領域。這張紙
引入了用於資料探勘的多模式資料融合的新流程模型，
整合嵌入和資料探勘的跨行業標準流程
與現有的資料融合資訊組模型。我們的模型旨在
降低計算成本、複雜性和偏差，同時提高效率
和可靠性。我們也提出了“解糾纏密集融合”，一種新穎的嵌入
融合方法旨在優化互資訊並促進密集
模態間特徵交互，從而最大限度地減少冗餘資訊。
  我們透過三個用例證明了該模型的功效：
使用視網膜影像和病患元資料的糖尿病視網膜病變，國內
利用衛星影像、網路和人口普查資料進行暴力預測，以及
從放射線照相影像中識別臨床和人口特徵
臨床筆記。該模型在糖尿病患者中的 Macro F1 得分為 0.92
視網膜病變預測，國內R平方為0.854，sMAPE為24.868
暴力預測，疾病預測的宏觀 AUC 分別為 0.92 和 0.99
和性別分類，分別在放射分析。
  這些結果強調了資料探勘模型的資料融合的潛力
顯著影響多模式資料處理，促進其在
多樣化、資源有限的環境。

##### **Relationship Discovery for Drug Recommendation**
2404.12228v1 by Xiang Li,Shunpan Liang,Yu Lei,Chen Li,Yulei Hou,Tengfei Ma

Medication recommendation systems are designed to deliver personalized drug
suggestions that are closely aligned with individual patient needs. Previous
studies have primarily concentrated on developing medication embeddings,
achieving significant progress. Nonetheless, these approaches often fall short
in accurately reflecting individual patient profiles, mainly due to challenges
in distinguishing between various patient conditions and the inability to
establish precise correlations between specific conditions and appropriate
medications. In response to these issues, we introduce DisMed, a model that
focuses on patient conditions to enhance personalization. DisMed employs causal
inference to discern clear, quantifiable causal links. It then examines patient
conditions in depth, recognizing and adapting to the evolving nuances of these
conditions, and mapping them directly to corresponding medications.
Additionally, DisMed leverages data from multiple patient visits to propose
combinations of medications. Comprehensive testing on real-world datasets
demonstrates that DisMed not only improves the customization of patient
profiles but also surpasses leading models in both precision and safety.

摘要：藥物推薦系統旨在提供個人化藥物
與患者個別需求密切相關的建議。以前的
研究主要集中在開發藥物嵌入，
取得重大進展。然而，這些方法往往達不到要求
準確反映個別患者概況，主要是由於挑戰
區分不同患者的情況和無法
在特定條件和適當的條件之間建立精確的關聯
藥物。針對這些問題，我們推出了 DisMed 這個模型
專注於患者狀況以增強個人化。 DisMed 採用因果關係
推斷以辨別清晰的、可量化的因果關係。然後它會檢查病人
深入了解情況，認識並適應這些不斷變化的細微差別
條件，並將它們直接映射到相應的藥物。
此外，DisMed 利用多次患者就診的數據來提出建議
藥物組合。對真實世界資料集的全面測試
表明 DisMed 不僅提高了患者的客製化
外形，但在精度和安全性方面也超越了領先型號。

##### **A Symmetric Regressor for MRI-Based Assessment of Striatal Dopamine Transporter Uptake in Parkinson's Disease**
2404.11929v1 by Walid Abdullah Al,Il Dong Yun,Yun Jung Bae

Dopamine transporter (DAT) imaging is commonly used for monitoring
Parkinson's disease (PD), where striatal DAT uptake amount is computed to
assess PD severity. However, DAT imaging has a high cost and the risk of
radiance exposure and is not available in general clinics. Recently, MRI patch
of the nigral region has been proposed as a safer and easier alternative. This
paper proposes a symmetric regressor for predicting the DAT uptake amount from
the nigral MRI patch. Acknowledging the symmetry between the right and left
nigrae, the proposed regressor incorporates a paired input-output model that
simultaneously predicts the DAT uptake amounts for both the right and left
striata. Moreover, it employs a symmetric loss that imposes a constraint on the
difference between right-to-left predictions, resembling the high correlation
in DAT uptake amounts in the two lateral sides. Additionally, we propose a
symmetric Monte-Carlo (MC) dropout method for providing a fruitful uncertainty
estimate of the DAT uptake prediction, which utilizes the above symmetry. We
evaluated the proposed approach on 734 nigral patches, which demonstrated
significantly improved performance of the symmetric regressor compared with the
standard regressors while giving better explainability and feature
representation. The symmetric MC dropout also gave precise uncertainty ranges
with a high probability of including the true DAT uptake amounts within the
range.

摘要：多巴胺轉運蛋白 (DAT) 影像通常用於監測
帕金森氏症 (PD)，其中紋狀體 DAT 攝取量計算為
評估 PD 嚴重程度。然而，DAT成像成本較高，且有以下風險：
輻射暴露，一般診所不提供。最近，MRI 補丁
黑格爾地區的區域被提議作為更安全和更容易的替代方案。這
論文提出了一個對稱迴歸器來預測 DAT 的吸收量
黑質 MRI 補丁。承認左右對稱
nigrae，所提出的迴歸器包含配對的輸入輸出模型，
同時預測左右兩側的 DAT 攝取量
紋狀體。此外，它採用對稱損失，對
從右到左預測之間的差異，類似於高相關性
兩側的 DAT 吸收量。此外，我們建議
對稱蒙特卡羅 (MC) 丟失方法提供了豐富的不確定性
DAT 攝取預測的估計，利用了上述對稱性。我們
對 734 個黑質斑塊評估了所提出的方法，結果表明
與對稱回歸器相比，顯著提高了性能
標準回歸器，同時提供更好的可解釋性和功能
表示。對稱 MC 壓差也給出了精確的不確定性範圍
很有可能將真實的 DAT 攝取量納入
範圍。

##### **Cross-model Mutual Learning for Exemplar-based Medical Image Segmentation**
2404.11812v1 by Qing En,Yuhong Guo

Medical image segmentation typically demands extensive dense annotations for
model training, which is both time-consuming and skill-intensive. To mitigate
this burden, exemplar-based medical image segmentation methods have been
introduced to achieve effective training with only one annotated image. In this
paper, we introduce a novel Cross-model Mutual learning framework for
Exemplar-based Medical image Segmentation (CMEMS), which leverages two models
to mutually excavate implicit information from unlabeled data at multiple
granularities. CMEMS can eliminate confirmation bias and enable collaborative
training to learn complementary information by enforcing consistency at
different granularities across models. Concretely, cross-model image
perturbation based mutual learning is devised by using weakly perturbed images
to generate high-confidence pseudo-labels, supervising predictions of strongly
perturbed images across models. This approach enables joint pursuit of
prediction consistency at the image granularity. Moreover, cross-model
multi-level feature perturbation based mutual learning is designed by letting
pseudo-labels supervise predictions from perturbed multi-level features with
different resolutions, which can broaden the perturbation space and enhance the
robustness of our framework. CMEMS is jointly trained using exemplar data,
synthetic data, and unlabeled data in an end-to-end manner. Experimental
results on two medical image datasets indicate that the proposed CMEMS
outperforms the state-of-the-art segmentation methods with extremely limited
supervision.

摘要：醫學影像分割通常需要大量密集註釋
模型訓練既耗時又需要技能。減輕
為了解決這個負擔，基於樣本的醫學影像分割方法已經被提出。
引入僅使用一張註釋的圖像即可實現有效的訓練。在這個
論文中，我們介紹了一個新穎的跨模型相互學習框架
基於範例的醫學影像分割 (CMEMS)，利用兩種模型
從多個未標記資料中相互挖掘隱含訊息
粒度。 CMEMS 可以消除確認偏誤並實現協作
透過加強一致性來學習補充資訊的培訓
跨模型的不同粒度。具體來說，跨模型影像
透過使用弱擾動圖像設計基於擾動的相互學習
產生高置信度的偽標籤，監督強烈的預測
跨模型的擾動影像。這種方法可以共同追求
影像粒度上的預測一致性。此外，跨模型
基於多層次特徵擾動的相互學習是透過讓
偽標籤監督來自擾動的多層次特徵的預測
不同的分辨率，可以拓寬攝動空間，增強
我們框架的穩健性。 CMEMS 使用範例資料進行聯合訓練，
以端到端的方式合成資料和未標記資料。實驗性的
兩個醫學影像資料集的結果表明，所提出的 CMEMS
在極度有限的情況下優於最先進的分割方法
監督。

##### **A Secure and Trustworthy Network Architecture for Federated Learning Healthcare Applications**
2404.11698v1 by Antonio Boiano,Marco Di Gennaro,Luca Barbieri,Michele Carminati,Monica Nicoli,Alessandro Redondi,Stefano Savazzi,Albert Sund Aillet,Diogo Reis Santos,Luigi Serio

Federated Learning (FL) has emerged as a promising approach for
privacy-preserving machine learning, particularly in sensitive domains such as
healthcare. In this context, the TRUSTroke project aims to leverage FL to
assist clinicians in ischemic stroke prediction. This paper provides an
overview of the TRUSTroke FL network infrastructure. The proposed architecture
adopts a client-server model with a central Parameter Server (PS). We introduce
a Docker-based design for the client nodes, offering a flexible solution for
implementing FL processes in clinical settings. The impact of different
communication protocols (HTTP or MQTT) on FL network operation is analyzed,
with MQTT selected for its suitability in FL scenarios. A control plane to
support the main operations required by FL processes is also proposed. The
paper concludes with an analysis of security aspects of the FL architecture,
addressing potential threats and proposing mitigation strategies to increase
the trustworthiness level.

摘要：聯邦學習（FL）已成為一種有前途的方法
保護隱私的機器學習，特別是在敏感領域，例如
衛生保健。在此背景下，TRUSTroke 計畫旨在利用 FL
協助臨床醫師預測缺血性中風。本文提供了一個
TRUSTroke FL 網路基礎設施概述。建議的架構
採用中央參數伺服器（PS）的客戶端-伺服器模型。我們介紹
基於Docker的客戶端節點設計，為客戶提供靈活的解決方案
在臨床環境中實施 FL 流程。不同的影響
分析 FL 網路操作上的通訊協定（HTTP 或 MQTT），
選擇 MQTT 是因為它適合 FL 場景。一個控制平面
也提出了支援 FL 流程所需的主要操作。這
本文最後對 FL 架構的安全性方面進行了分析，
解決潛在威脅並提出緩解策略，以增加
可信度等級。

##### **Towards Reliable Empirical Machine Unlearning Evaluation: A Game-Theoretic View**
2404.11577v1 by Yiwen Tu,Pingbang Hu,Jiaqi Ma

Machine unlearning is the process of updating machine learning models to
remove the information of specific training data samples, in order to comply
with data protection regulations that allow individuals to request the removal
of their personal data. Despite the recent development of numerous unlearning
algorithms, reliable evaluation of these algorithms remains an open research
question. In this work, we focus on membership inference attack (MIA) based
evaluation, one of the most common approaches for evaluating unlearning
algorithms, and address various pitfalls of existing evaluation metrics that
lack reliability. Specifically, we propose a game-theoretic framework that
formalizes the evaluation process as a game between unlearning algorithms and
MIA adversaries, measuring the data removal efficacy of unlearning algorithms
by the capability of the MIA adversaries. Through careful design of the game,
we demonstrate that the natural evaluation metric induced from the game enjoys
provable guarantees that the existing evaluation metrics fail to satisfy.
Furthermore, we propose a practical and efficient algorithm to estimate the
evaluation metric induced from the game, and demonstrate its effectiveness
through both theoretical analysis and empirical experiments. This work presents
a novel and reliable approach to empirically evaluating unlearning algorithms,
paving the way for the development of more effective unlearning techniques.

摘要：機器去學習是更新機器學習模型的過程
刪除特定訓練資料樣本的信息，以符合
資料保護法規允許個人請求刪除
他們的個人資料。儘管最近出現了許多不學習的情況
演算法，這些演算法的可靠評估仍然是一個開放的研究
問題。在這項工作中，我們專注於基於成員推理攻擊（MIA）
評估，評估遺忘最常見的方法之一
演算法，並解決現有評估指標的各種缺陷
缺乏可靠性。具體來說，我們提出了一個博弈論框架
將評估過程形式化為遺忘演算法和
MIA 對手，測量遺忘演算法的資料刪除效率
取決於 MIA 對手的能力。透過遊戲的精心設計，
我們證明了從遊戲中得出的自然評估指標享有
現有評估指標無法滿足的可證明保證。
此外，我們提出了一種實用且有效的演算法來估計
從遊戲中匯出評估指標，並證明其有效性
透過理論分析和實證實驗。這部作品呈現
一種新穎且可靠的方法來根據經驗評估遺忘演算法，
為開發更有效的忘卻技術鋪路。

##### **Prompt-Guided Generation of Structured Chest X-Ray Report Using a Pre-trained LLM**
2404.11209v1 by Hongzhao Li,Hongyu Wang,Xia Sun,Hua He,Jun Feng

Medical report generation automates radiology descriptions from images,
easing the burden on physicians and minimizing errors. However, current methods
lack structured outputs and physician interactivity for clear, clinically
relevant reports. Our method introduces a prompt-guided approach to generate
structured chest X-ray reports using a pre-trained large language model (LLM).
First, we identify anatomical regions in chest X-rays to generate focused
sentences that center on key visual elements, thereby establishing a structured
report foundation with anatomy-based sentences. We also convert the detected
anatomy into textual prompts conveying anatomical comprehension to the LLM.
Additionally, the clinical context prompts guide the LLM to emphasize
interactivity and clinical requirements. By integrating anatomy-focused
sentences and anatomy/clinical prompts, the pre-trained LLM can generate
structured chest X-ray reports tailored to prompted anatomical regions and
clinical contexts. We evaluate using language generation and clinical
effectiveness metrics, demonstrating strong performance.

摘要：醫療報告產生自動化影像的放射學描述，
減輕醫生的負擔並最大限度地減少錯誤。然而，目前的方法
缺乏清晰、臨床的結構化輸出和醫生互動
相關報道。我們的方法引入了一種提示引導的方法來生成
使用預先訓練的大語言模型 (LLM) 產生結構化胸部 X 光報告。
首先，我們識別胸部 X 光中的解剖區域以產生聚焦影像
以關鍵視覺元素為中心的句子，從而建立結構化的
報告基礎與基於解剖學的句子。我們還將檢測到的
將解剖學轉化為文本提示，將解剖學理解傳達給LLM。
此外，臨床背景提示引導LLM強調
互動性和臨床要求。透過整合以解剖學為中心的
句子和解剖學/臨床提示，預訓練的LLM可以生成
根據提示的解剖區域客製化結構化胸部 X 光報告
臨床背景。我們使用語言生成和臨床進行評估
有效性指標，展現強勁的績效。

##### **Explainable Machine Learning System for Predicting Chronic Kidney Disease in High-Risk Cardiovascular Patients**
2404.11148v1 by Nantika Nguycharoen

As the global population ages, the incidence of Chronic Kidney Disease (CKD)
is rising. CKD often remains asymptomatic until advanced stages, which
significantly burdens both the healthcare system and patient quality of life.
This research developed an explainable machine learning system for predicting
CKD in patients with cardiovascular risks, utilizing medical history and
laboratory data. The Random Forest model achieved the highest sensitivity of
88.2%. The study introduces a comprehensive explainability framework that
extends beyond traditional feature importance methods, incorporating global and
local interpretations, bias inspection, biomedical relevance, and safety
assessments. Key predictive features identified in global interpretation were
the use of diabetic and ACEI/ARB medications, and initial eGFR values. Local
interpretation provided model insights through counterfactual explanations,
which aligned with other system parts. After conducting a bias inspection, it
was found that the initial eGFR values and CKD predictions exhibited some bias,
but no significant gender bias was identified. The model's logic, extracted by
scoped rules, was confirmed to align with existing medical literature. The
safety assessment tested potentially dangerous cases and confirmed that the
model behaved safely. This system enhances the explainability, reliability, and
accountability of the model, promoting its potential integration into
healthcare settings and compliance with upcoming regulatory standards, and
showing promise for broader applications in healthcare machine learning.

摘要：隨著全球人口老化，慢性腎臟病（CKD）的發生率
正在崛起。 CKD 通常直到晚期才出現症狀，這
給醫療保健系統和患者的生活品質帶來了巨大的負擔。
這項研究開發了一個可解釋的機器學習系統來預測
CKD 患者有心血管風險，利用病史和
實驗室數據。隨機森林模型達到了最高靈敏度
88.2%。該研究引入了一個全面的可解釋性框架
超越了傳統的特徵重要性方法，融合了全球和
本地解釋、偏差檢查、生物醫學相關性和安全性
評估。全球解釋中確定的關鍵預測特徵是
糖尿病和 ACEI/ARB 藥物的使用，以及初始 eGFR 值。當地的
解釋透過反事實解釋提供了模型見解，
與其他系統部件對齊。進行偏差檢查後，
發現初始 eGFR 值和 CKD 預測有一定偏差，
但沒有發現明顯的性別偏見。模型的邏輯，透過提取
範圍規則被確認與現有醫學文獻一致。這
安全評估測試了潛在危險案例並確認
模型表現安全。該系統增強了可解釋性、可靠性和
此模型的問責制，促進其潛在融入
醫療保健環境和遵守即將到來的監管標準，以及
顯示出在醫療保健機器學習領域更廣泛應用的前景。

##### **AKGNet: Attribute Knowledge-Guided Unsupervised Lung-Infected Area Segmentation**
2404.11008v1 by Qing En,Yuhong Guo

Lung-infected area segmentation is crucial for assessing the severity of lung
diseases. However, existing image-text multi-modal methods typically rely on
labour-intensive annotations for model training, posing challenges regarding
time and expertise. To address this issue, we propose a novel attribute
knowledge-guided framework for unsupervised lung-infected area segmentation
(AKGNet), which achieves segmentation solely based on image-text data without
any mask annotation. AKGNet facilitates text attribute knowledge learning,
attribute-image cross-attention fusion, and high-confidence-based pseudo-label
exploration simultaneously. It can learn statistical information and capture
spatial correlations between image and text attributes in the embedding space,
iteratively refining the mask to enhance segmentation. Specifically, we
introduce a text attribute knowledge learning module by extracting attribute
knowledge and incorporating it into feature representations, enabling the model
to learn statistical information and adapt to different attributes. Moreover,
we devise an attribute-image cross-attention module by calculating the
correlation between attributes and images in the embedding space to capture
spatial dependency information, thus selectively focusing on relevant regions
while filtering irrelevant areas. Finally, a self-training mask improvement
process is employed by generating pseudo-labels using high-confidence
predictions to iteratively enhance the mask and segmentation. Experimental
results on a benchmark medical image dataset demonstrate the superior
performance of our method compared to state-of-the-art segmentation techniques
in unsupervised scenarios.

摘要：肺部感染區域分割對於評估肺部嚴重程度至關重要
疾病。然而，現有的圖像文字多模態方法通常依賴
模型訓練的勞力密集註釋，給以下方面帶來了挑戰
時間和專業知識。為了解決這個問題，我們提出了一個新的屬性
無監督肺部感染區域分割的知識引導框架
（AKGNet），僅基於圖文資料實現分割，無需
任何掩碼註釋。 AKGNet 促進文字屬性知識學習，
屬性-影像交叉注意力融合，以及基於高置信度的偽標籤
同時探索。它可以學習統計資訊並捕獲
嵌入空間中圖像和文字屬性之間的空間相關性，
迭代地細化掩模以增強分割。具體來說，我們
透過提取屬性引入文字屬性知識學習模組
知識並將其合併到特徵表示中，使模型成為可能
學習統計資訊並適應不同的屬性。而且，
我們透過計算屬性圖像交叉注意模組
嵌入空間中的屬性和影像之間的相關性要捕獲
空間依賴訊息，從而選擇性地關注相關區域
同時過濾掉不相關的區域。最後，自我訓練掩模的改進
透過使用高置信度產生偽標籤來採用該過程
迭代增強掩模和分割的預測。實驗性的
基準醫學影像資料集的結果證明了其優越性
我們的方法與最先進的分割技術相比的性能
在無人監督的場景中。

##### **Leveraging 3D LiDAR Sensors to Enable Enhanced Urban Safety and Public Health: Pedestrian Monitoring and Abnormal Activity Detection**
2404.10978v1 by Nawfal Guefrachi,Jian Shi,Hakim Ghazzai,Ahmad Alsharoa

The integration of Light Detection and Ranging (LiDAR) and Internet of Things
(IoT) technologies offers transformative opportunities for public health
informatics in urban safety and pedestrian well-being. This paper proposes a
novel framework utilizing these technologies for enhanced 3D object detection
and activity classification in urban traffic scenarios. By employing elevated
LiDAR, we obtain detailed 3D point cloud data, enabling precise pedestrian
activity monitoring. To overcome urban data scarcity, we create a specialized
dataset through simulated traffic environments in Blender, facilitating
targeted model training. Our approach employs a modified Point
Voxel-Region-based Convolutional Neural Network (PV-RCNN) for robust 3D
detection and PointNet for classifying pedestrian activities, significantly
benefiting urban traffic management and public health by offering insights into
pedestrian behavior and promoting safer urban environments. Our dual-model
approach not only enhances urban traffic management but also contributes
significantly to public health by providing insights into pedestrian behavior
and promoting safer urban environment.

摘要：光探測與測距（LiDAR）與物聯網的集成
（物聯網）科技為公共衛生提供變革機遇
城市安全和行人福祉的資訊學。本文提出了一個
利用這些技術增強 3D 物體檢測的新穎框架
以及城市交通場景中的活動分類。透過採用高位
LiDAR，我們取得詳細的3D點雲數據，實現精準行人
活動監控。為了克服城市數據稀缺的問題，我們創建了專門的
透過 Blender 中模擬交通環境的資料集，促進
有針對性的模型訓練。我們的方法採用了修改後的點
用於穩健 3D 的基於體素區域的捲積神經網路 (PV-RCNN)
偵測和 PointNet 用於對行人活動進行分類，顯著
透過提供以下方面的見解，有利於城市交通管理和公共衛生
行人行為並促進更安全的城市環境。我們的雙模
不僅加強了城市交通管理，也有助於
透過提供對行人行為的洞察，對公共健康產生重大影響
促進更安全的城市環境。

##### **CrossGP: Cross-Day Glucose Prediction Excluding Physiological Information**
2404.10901v1 by Ziyi Zhou,Ming Cheng,Yanjun Cui,Xingjian Diao,Zhaorui Ma

The increasing number of diabetic patients is a serious issue in society
today, which has significant negative impacts on people's health and the
country's financial expenditures. Because diabetes may develop into potential
serious complications, early glucose prediction for diabetic patients is
necessary for timely medical treatment. Existing glucose prediction methods
typically utilize patients' private data (e.g. age, gender, ethnicity) and
physiological parameters (e.g. blood pressure, heart rate) as reference
features for glucose prediction, which inevitably leads to privacy protection
concerns. Moreover, these models generally focus on either long-term
(monthly-based) or short-term (minute-based) predictions. Long-term prediction
methods are generally inaccurate because of the external uncertainties that can
greatly affect the glucose values, while short-term ones fail to provide timely
medical guidance. Based on the above issues, we propose CrossGP, a novel
machine-learning framework for cross-day glucose prediction solely based on the
patient's external activities without involving any physiological parameters.
Meanwhile, we implement three baseline models for comparison. Extensive
experiments on Anderson's dataset strongly demonstrate the superior performance
of CrossGP and prove its potential for future real-life applications.

摘要：糖尿病患者數量的不斷增加是一個嚴重的社會問題
今天，它對人們的健康和生活產生了重大的負面影響
國家的財政支出。因為糖尿病可能會發展成潛在的
嚴重併發症，糖尿病患者的早期血糖預測
需要及時就醫。現有的血糖預測方法
通常利用患者的私人資料（例如年齡、性別、種族）和
生理參數（如血壓、心率）作為參考
血糖預測的特徵，這不可避免地導致隱私保護
的擔憂。此外，這些模型通常側重於長期
（基於每月）或短期（基於分鐘）預測。長期預測
由於外部的不確定性，方法通常不準確
對血糖值影響很大，而短期的又不能及時提供
醫療指導。基於上述問題，我們提出了 CrossGP，一種新穎的
僅基於以下內容的跨日血糖預測的機器學習框架
患者的外部活動，不涉及任何生理參數。
同時，我們實現了三個基準模型進行比較。廣泛的
在 Anderson 資料集上的實驗有力地證明了其優越的性能
CrossGP 並證明其在未來現實生活應用中的潛力。

##### **Mixed Prototype Consistency Learning for Semi-supervised Medical Image Segmentation**
2404.10717v1 by Lijian Li

Recently, prototype learning has emerged in semi-supervised medical image
segmentation and achieved remarkable performance. However, the scarcity of
labeled data limits the expressiveness of prototypes in previous methods,
potentially hindering the complete representation of prototypes for class
embedding. To address this problem, we propose the Mixed Prototype Consistency
Learning (MPCL) framework, which includes a Mean Teacher and an auxiliary
network. The Mean Teacher generates prototypes for labeled and unlabeled data,
while the auxiliary network produces additional prototypes for mixed data
processed by CutMix. Through prototype fusion, mixed prototypes provide extra
semantic information to both labeled and unlabeled prototypes. High-quality
global prototypes for each class are formed by fusing two enhanced prototypes,
optimizing the distribution of hidden embeddings used in consistency learning.
Extensive experiments on the left atrium and type B aortic dissection datasets
demonstrate MPCL's superiority over previous state-of-the-art approaches,
confirming the effectiveness of our framework. The code will be released soon.

摘要：最近，原型學習在半監督醫學影像中出現
細分領域並取得了驕人的業績。然而，稀缺性
標記資料限制了先前方法中原型的表達能力，
可能會阻礙類原型的完整表示
嵌入。為了解決這個問題，我們提出了混合原型一致性
學習 (MPCL) 框架，其中包括平均教師和輔助教師
網路。 The Mean Teacher 為標記和未標記資料產生原型，
而輔助網路則為混合數據產生額外的原型
由 CutMix 處理。透過原型融合，混合原型提供了額外的
標記和未標記原型的語義資訊。高品質
每個類別的全局原型是透過融合兩個增強原型形成的，
優化一致性學習中使用的隱藏嵌入的分佈。
對左心房和 B 型主動脈剝離資​​料集進行大量實驗
證明 MPCL 相對於先前最先進方法的優越性，
確認我們框架的有效性。該代碼即將發布。

##### **AAVDiff: Experimental Validation of Enhanced Viability and Diversity in Recombinant Adeno-Associated Virus (AAV) Capsids through Diffusion Generation**
2404.10573v2 by Lijun Liu,Jiali Yang,Jianfei Song,Xinglin Yang,Lele Niu,Zeqi Cai,Hui Shi,Tingjun Hou,Chang-yu Hsieh,Weiran Shen,Yafeng Deng

Recombinant adeno-associated virus (rAAV) vectors have revolutionized gene
therapy, but their broad tropism and suboptimal transduction efficiency limit
their clinical applications. To overcome these limitations, researchers have
focused on designing and screening capsid libraries to identify improved
vectors. However, the large sequence space and limited resources present
challenges in identifying viable capsid variants. In this study, we propose an
end-to-end diffusion model to generate capsid sequences with enhanced
viability. Using publicly available AAV2 data, we generated 38,000 diverse AAV2
viral protein (VP) sequences, and evaluated 8,000 for viral selection. The
results attested the superiority of our model compared to traditional methods.
Additionally, in the absence of AAV9 capsid data, apart from one wild-type
sequence, we used the same model to directly generate a number of viable
sequences with up to 9 mutations. we transferred the remaining 30,000 samples
to the AAV9 domain. Furthermore, we conducted mutagenesis on AAV9 VP
hypervariable regions VI and V, contributing to the continuous improvement of
the AAV9 VP sequence. This research represents a significant advancement in the
design and functional validation of rAAV vectors, offering innovative solutions
to enhance specificity and transduction efficiency in gene therapy
applications.

摘要：重組腺相關病毒（rAAV）載體徹底改變了基因
療法，但其廣泛的趨向性和次優的轉導效率限制了
他們的臨床應用。為了克服這些限制，研究人員
專注於設計和篩選衣殼庫以識別改進的
向量。然而序列空間大、資源有限
識別可行衣殼變體的挑戰。在這項研究中，我們提出了一個
端對端擴散模型，用於產生具有增強功能的衣殼序列
可行性。使用公開的 AAV2 數據，我們產生了 38,000 個不同的 AAV2
病毒蛋白 (VP) 序列，並評估了 8,000 個病毒選擇。這
結果證明了我們的模型相對於傳統方法的優越性。
此外，在缺乏 AAV9 衣殼資料的情況下，除了一種野生型
序列，我們使用相同的模型直接產生多個可行的
最多有 9 個突變的序列。我們轉移了剩餘的30,000個樣本
到 AAV9 域。此外，我們對 AAV9 VP 進行了誘變
高變異區 VI 和 V，有助於持續改進
AAV9 VP 序列。這項研究代表了該領域的重大進步
rAAV 載體的設計與功能驗證，提供創新解決方案
提高基因治療的特異性與轉導效率
應用程式.

##### **A Sentiment Analysis of Medical Text Based on Deep Learning**
2404.10503v1 by Yinan Chen

The field of natural language processing (NLP) has made significant progress
with the rapid development of deep learning technologies. One of the research
directions in text sentiment analysis is sentiment analysis of medical texts,
which holds great potential for application in clinical diagnosis. However, the
medical field currently lacks sufficient text datasets, and the effectiveness
of sentiment analysis is greatly impacted by different model design approaches,
which presents challenges. Therefore, this paper focuses on the medical domain,
using bidirectional encoder representations from transformers (BERT) as the
basic pre-trained model and experimenting with modules such as convolutional
neural network (CNN), fully connected network (FCN), and graph convolutional
networks (GCN) at the output layer. Experiments and analyses were conducted on
the METS-CoV dataset to explore the training performance after integrating
different deep learning networks. The results indicate that CNN models
outperform other networks when trained on smaller medical text datasets in
combination with pre-trained models like BERT. This study highlights the
significance of model selection in achieving effective sentiment analysis in
the medical domain and provides a reference for future research to develop more
efficient model architectures.

摘要：自然語言處理（NLP）領域取得重大進展
隨著深度學習技術的快速發展。其中一項研究
文本情緒分析的方向是醫學文本的情緒分析，
在臨床診斷上具有巨大的應用潛力。但是，那
醫學領域目前缺乏足夠的文字資料集，有效性
情感分析的效果很大程度上受到不同模型設計方法的影響，
這帶來了挑戰。因此，本文主要關注醫學領域，
使用 Transformer (BERT) 的雙向編碼器表示作為
基本的預訓練模型並嘗試卷積等模組
神經網路 (CNN)、全連接網路 (FCN) 和圖卷積
輸出層的網路（GCN）。進行了實驗和分析
METS-CoV 資料集以探索整合後的訓練效能
不同的深度學習網路。結果顯示 CNN 模型
在較小的醫學文本資料集上進行訓練時，優於其他網絡
與 BERT 等預訓練模型結合。這項研究強調
模型選擇對於實現有效情感分析的重要性
為未來醫學領域的研究發展提供參考
高效的模型架構。

##### **Integration of Self-Supervised BYOL in Semi-Supervised Medical Image Recognition**
2404.10405v1 by Hao Feng,Yuanzhe Jia,Ruijia Xu,Mukesh Prasad,Ali Anaissi,Ali Braytee

Image recognition techniques heavily rely on abundant labeled data,
particularly in medical contexts. Addressing the challenges associated with
obtaining labeled data has led to the prominence of self-supervised learning
and semi-supervised learning, especially in scenarios with limited annotated
data. In this paper, we proposed an innovative approach by integrating
self-supervised learning into semi-supervised models to enhance medical image
recognition. Our methodology commences with pre-training on unlabeled data
utilizing the BYOL method. Subsequently, we merge pseudo-labeled and labeled
datasets to construct a neural network classifier, refining it through
iterative fine-tuning. Experimental results on three different datasets
demonstrate that our approach optimally leverages unlabeled data, outperforming
existing methods in terms of accuracy for medical image recognition.

摘要：影像辨識技術嚴重依賴豐富的標記數據，
特別是在醫療領域。解決相關挑戰
獲取標記數據導致了自我監督學習的重要性
和半監督學習，特別是在註釋有限的場景中
數據。在本文中，我們提出了一種創新方法，將
自監督學習到半監督模型以增強醫學影像
認出。我們的方法從未標記資料的預訓練開始
利用 BYOL 方法。隨後，我們合併偽標記和標記
資料集來建立神經網路分類器，並透過以下方式進行改進
迭代微調。三個不同資料集上的實驗結果
證明我們的方法可以最佳地利用未標記的數據，表現優於
現有方法在醫學影像辨識的準確性方面。

##### **Generating Counterfactual Trajectories with Latent Diffusion Models for Concept Discovery**
2404.10356v1 by Payal Varshney,Adriano Lucieri,Christoph Balada,Andreas Dengel,Sheraz Ahmed

Trustworthiness is a major prerequisite for the safe application of opaque
deep learning models in high-stakes domains like medicine. Understanding the
decision-making process not only contributes to fostering trust but might also
reveal previously unknown decision criteria of complex models that could
advance the state of medical research. The discovery of decision-relevant
concepts from black box models is a particularly challenging task. This study
proposes Concept Discovery through Latent Diffusion-based Counterfactual
Trajectories (CDCT), a novel three-step framework for concept discovery
leveraging the superior image synthesis capabilities of diffusion models. In
the first step, CDCT uses a Latent Diffusion Model (LDM) to generate a
counterfactual trajectory dataset. This dataset is used to derive a
disentangled representation of classification-relevant concepts using a
Variational Autoencoder (VAE). Finally, a search algorithm is applied to
identify relevant concepts in the disentangled latent space. The application of
CDCT to a classifier trained on the largest public skin lesion dataset revealed
not only the presence of several biases but also meaningful biomarkers.
Moreover, the counterfactuals generated within CDCT show better FID scores than
those produced by a previously established state-of-the-art method, while being
12 times more resource-efficient. Unsupervised concept discovery holds great
potential for the application of trustworthy AI and the further development of
human knowledge in various domains. CDCT represents a further step in this
direction.

摘要：可信是不透明安全應用的重要前提
醫學等高風險領域的深度學習模式。了解
決策過程不僅有助於培養信任，而且可能
揭示以前未知的複雜模型的決策標準，可以
推進醫學研究狀況。決策相關的發現
來自黑盒模型的概念是一項特別具有挑戰性的任務。這項研究
提出透過基於潛在擴散的反事實進行概念發現
軌跡（CDCT），一種新穎的概念發現三步驟框架
利用擴散模型的卓越影像合成能力。在
第一步，CDCT 使用潛在擴散模型 (LDM) 生成
反事實軌跡資料集。該數據集用於導出
使用分類相關概念的解纏結表示
變分自動編碼器（VAE）。最後，應用搜尋演算法
辨識解開的潛在空間中的相關概念。應用
揭示了在最大的公共皮膚病變資料集上訓練的分類器的 CDCT
不僅存在一些偏差，而且還存在有意義的生物標記。
此外，CDCT 中產生的反事實顯示出比 CDCT 更好的 FID 分數
那些透過先前建立的最先進方法生產的，同時
資源效率提高 12 倍。無監督的概念發現很有效
可信人工智慧的應用潛力與進一步發展
人類各領域的知識。 CDCT 代表這方面又邁出了一步
方向。

##### **CARE to Compare: A real-world dataset for anomaly detection in wind turbine data**
2404.10320v2 by Christian Gück,Cyriana M. A. Roelofs,Stefan Faulstich

Anomaly detection plays a crucial role in the field of predictive maintenance
for wind turbines, yet the comparison of different algorithms poses a difficult
task because domain specific public datasets are scarce. Many comparisons of
different approaches either use benchmarks composed of data from many different
domains, inaccessible data or one of the few publicly available datasets which
lack detailed information about the faults. Moreover, many publications
highlight a couple of case studies where fault detection was successful. With
this paper we publish a high quality dataset that contains data from 36 wind
turbines across 3 different wind farms as well as the most detailed fault
information of any public wind turbine dataset as far as we know. The new
dataset contains 89 years worth of real-world operating data of wind turbines,
distributed across 44 labeled time frames for anomalies that led up to faults,
as well as 51 time series representing normal behavior. Additionally, the
quality of training data is ensured by turbine-status-based labels for each
data point. Furthermore, we propose a new scoring method, called CARE
(Coverage, Accuracy, Reliability and Earliness), which takes advantage of the
information depth that is present in the dataset to identify a good all-around
anomaly detection model. This score considers the anomaly detection
performance, the ability to recognize normal behavior properly and the
capability to raise as few false alarms as possible while simultaneously
detecting anomalies early.

摘要：異常檢測在預測性維護領域發揮至關重要的作用
對於風力渦輪機來說，不同演算法的比較帶來了困難
任務，因為特定領域的公共資料集很少。許多比較
不同的方法要么使用由來自許多不同的數據組成的基準
網域、無法存取的資料或少數公開可用的資料集之一
缺乏有關故障的詳細資訊。此外，許多出版物
重點介紹幾個成功檢測故障的案例研究。和
本文我們發布了一個高品質的數據集，其中包含來自 36 個風的數據
跨越3個不同風電場的渦輪機以及最詳細的故障
據我們所知，任何公共風力渦輪機資料集的資訊。新的
數據集包​​含 89 年風力渦輪機的真實運轉數據，
分佈在 44 個標記時間範圍內導致故障的異常情況，
以及代表正常行為的 51 個時間序列。此外，
訓練資料的品質由每個渦輪機狀態的標籤來保證
數據點。此外，我們提出了一種新的評分方法，稱為 CARE
（覆蓋範圍、準確性、可靠性和早期性），它利用了
資料集中存在的資訊深度，用於識別良好的全能
異常檢測模型。此分數考慮了異常檢測
表現、正確辨識正常行為的能力、
能夠同時發出盡可能少的誤報
儘早發現異常狀況。

##### **Clustering and Data Augmentation to Improve Accuracy of Sleep Assessment and Sleep Individuality Analysis**
2404.10299v1 by Shintaro Tamai,Masayuki Numao,Ken-ichi Fukui

Recently, growing health awareness, novel methods allow individuals to
monitor sleep at home. Utilizing sleep sounds offers advantages over
conventional methods like smartwatches, being non-intrusive, and capable of
detecting various physiological activities. This study aims to construct a
machine learning-based sleep assessment model providing evidence-based
assessments, such as poor sleep due to frequent movement during sleep onset.
Extracting sleep sound events, deriving latent representations using VAE,
clustering with GMM, and training LSTM for subjective sleep assessment achieved
a high accuracy of 94.8% in distinguishing sleep satisfaction. Moreover,
TimeSHAP revealed differences in impactful sound event types and timings for
different individuals.

摘要：最近，隨著健康意識的增強，新的方法使個人能夠
監控家裡的睡眠狀況。使用睡眠聲音比使用睡眠聲音更有優勢
智慧手錶等傳統方法，非侵入性，並且能夠
檢測各種生理活動。本研究旨在建構一個
基於機器學習的睡眠評估模型提供以證據為基礎的睡眠評估模型
評估，例如由於入睡期間頻繁運動而導致睡眠品質不佳。
擷取睡眠聲音事件，使用 VAE 匯出潛在表示，
使用 GMM 進行聚類，並訓練 LSTM 進行主觀睡眠評估
區分睡眠滿意度的準確率高達 94.8%。而且，
TimeSHAP 揭示了有影響力的聲音事件類型和時間安排的差異
不同的個體。

##### **Emergent Language Symbolic Autoencoder (ELSA) with Weak Supervision to Model Hierarchical Brain Networks**
2404.10031v1 by Ammar Ahmed Pallikonda Latheef,Alberto Santamaria-Pang,Craig K Jones,Haris I Sair

Brain networks display a hierarchical organization, a complexity that poses a
challenge for existing deep learning models, often structured as flat
classifiers, leading to difficulties in interpretability and the 'black box'
issue. To bridge this gap, we propose a novel architecture: a symbolic
autoencoder informed by weak supervision and an Emergent Language (EL)
framework. This model moves beyond traditional flat classifiers by producing
hierarchical clusters and corresponding imagery, subsequently represented
through symbolic sentences to improve the clinical interpretability of
hierarchically organized data such as intrinsic brain networks, which can be
characterized using resting-state fMRI images. Our innovation includes a
generalized hierarchical loss function designed to ensure that both sentences
and images accurately reflect the hierarchical structure of functional brain
networks. This enables us to model functional brain networks from a broader
perspective down to more granular details. Furthermore, we introduce a
quantitative method to assess the hierarchical consistency of these symbolic
representations. Our qualitative analyses show that our model successfully
generates hierarchically organized, clinically interpretable images, a finding
supported by our quantitative evaluations. We find that our best performing
loss function leads to a hierarchical consistency of over 97% when identifying
images corresponding to brain networks. This approach not only advances the
interpretability of deep learning models in neuroimaging analysis but also
represents a significant step towards modeling the intricate hierarchical
nature of brain networks.

摘要：大腦網路顯示出一種層次結構，這種複雜性構成了
對現有深度學習模型的挑戰，通常結構為扁平化
分類器，導致解釋困難和“黑盒子”
問題。為了彌補這個差距，我們提出了一個新穎的架構：一個象徵性的架構
由弱監督和緊急語言（EL）通知的自動編碼器
框架。該模型超越了傳統的平面分類器，透過產生
分層集群和相應的圖像，隨後表示
透過象徵性句子來提高臨床可解釋性
分層組織的數據，例如內在的大腦網絡，可以
使用靜息態功能性磁振造影影像進行表徵。我們的創新包括
廣義層次損失函數旨在確保兩個句子
影像準確反映了大腦功能的層次結構
網路。這使我們能夠從更廣泛的角度對功能性大腦網路進行建模
透視到更細化的細節。此外，我們也介紹了一個
定量方法來評估這些符號的層次一致性
交涉。我們的定性分析顯示我們的模型成功
產生分層組織的、臨床可解釋的影像，這是一項發現
我們的定量評估支持。我們發現我們表現最好的
損失函數在辨識時導致層次一致性超過 97%
與大腦網路相對應的圖像。這種方法不僅推進了
深度學習模型在神經影像分析中的可解釋性
代表著邁向複雜的層次結構建模的重要一步
大腦網路的本質。

##### **Harnessing GPT-4V(ision) for Insurance: A Preliminary Exploration**
2404.09690v1 by Chenwei Lin,Hanjia Lyu,Jiebo Luo,Xian Xu

The emergence of Large Multimodal Models (LMMs) marks a significant milestone
in the development of artificial intelligence. Insurance, as a vast and complex
discipline, involves a wide variety of data forms in its operational processes,
including text, images, and videos, thereby giving rise to diverse multimodal
tasks. Despite this, there has been limited systematic exploration of
multimodal tasks specific to insurance, nor a thorough investigation into how
LMMs can address these challenges. In this paper, we explore GPT-4V's
capabilities in the insurance domain. We categorize multimodal tasks by
focusing primarily on visual aspects based on types of insurance (e.g., auto,
household/commercial property, health, and agricultural insurance) and
insurance stages (e.g., risk assessment, risk monitoring, and claims
processing). Our experiment reveals that GPT-4V exhibits remarkable abilities
in insurance-related tasks, demonstrating not only a robust understanding of
multimodal content in the insurance domain but also a comprehensive knowledge
of insurance scenarios. However, there are notable shortcomings: GPT-4V
struggles with detailed risk rating and loss assessment, suffers from
hallucination in image understanding, and shows variable support for different
languages. Through this work, we aim to bridge the insurance domain with
cutting-edge LMM technology, facilitate interdisciplinary exchange and
development, and provide a foundation for the continued advancement and
evolution of future research endeavors.

摘要：大型多模態模型 (LMM) 的出現標誌著一個重要的里程碑
在人工智慧的發展中。保險作為一個龐大而複雜的領域
學科，在其操作過程中涉及多種數據形式，
包括文字、圖像和視頻，從而產生多樣化的多模態
任務。儘管如此，對這方面的系統性探索仍然有限。
針對保險的多式聯運任務，也沒有徹底調查如何
LMM 可以應對這些挑戰。在本文中，我們探討了 GPT-4V
保險領域的能力。我們將多模式任務分類為
主要關注基於保險類型的視覺方面（例如汽車、
家庭/商業財產、健康和農業保險）和
保險階段（例如風險評估、風險監控和索賠
加工）。我們的實驗顯示 GPT-4V 表現出非凡的能力
在與保險相關的任務中，不僅表現出對
保險領域的多式聯運內容也是全面的知識
保險場景。然而，也有顯著的缺點：GPT-4V
難以進行詳細的風險評級和損失評估，遭受
圖像理解中的幻覺，並且對不同的情況顯示出不同的支持
語言。透過這項工作，我們的目標是在保險領域與
前沿的LMM技術，促進跨學科交流
的發展，為不斷進步奠定基礎
未來研究工作的演變。

##### **Privacy-Preserving Intrusion Detection using Convolutional Neural Networks**
2404.09625v1 by Martin Kodys,Zhongmin Dai,Vrizlynn L. L. Thing

Privacy-preserving analytics is designed to protect valuable assets. A common
service provision involves the input data from the client and the model on the
analyst's side. The importance of the privacy preservation is fuelled by legal
obligations and intellectual property concerns. We explore the use case of a
model owner providing an analytic service on customer's private data. No
information about the data shall be revealed to the analyst and no information
about the model shall be leaked to the customer. Current methods involve costs:
accuracy deterioration and computational complexity. The complexity, in turn,
results in a longer processing time, increased requirement on computing
resources, and involves data communication between the client and the server.
In order to deploy such service architecture, we need to evaluate the optimal
setting that fits the constraints. And that is what this paper addresses. In
this work, we enhance an attack detection system based on Convolutional Neural
Networks with privacy-preserving technology based on PriMIA framework that is
initially designed for medical data.

摘要：隱私保護分析旨在保護寶貴的資產。普通的
服務提供涉及來自客戶端的輸入資料和模型
分析師這邊。法律推動了隱私保護的重要性
義務和智慧財產權問題。我們探討了一個用例
模型所有者為客戶的私人資料提供分析服務。不
有關數據的資訊應向分析人員透露，並且不得透露任何信息
有關型號的資訊應洩漏給客戶。目前的方法涉及成本：
精度惡化和計算複雜性。反過來，複雜性
導致處理時間更長，對計算的要求增加
資源，並涉及客戶端和伺服器之間的資料通訊。
為了部署這樣的服務架構，我們需要評估最優的
符合約束條件的設定。這就是本文所要解決的問題。在
這項工作，我們增強了基於卷積神經網路的攻擊檢測系統
基於 PriMIA 框架的隱私保護技術網絡
最初是為醫療數據而設計的。

##### **Efficient and accurate neural field reconstruction using resistive memory**
2404.09613v1 by Yifei Yu,Shaocong Wang,Woyu Zhang,Xinyuan Zhang,Xiuzhe Wu,Yangu He,Jichang Yang,Yue Zhang,Ning Lin,Bo Wang,Xi Chen,Songqi Wang,Xumeng Zhang,Xiaojuan Qi,Zhongrui Wang,Dashan Shang,Qi Liu,Kwang-Ting Cheng,Ming Liu

Human beings construct perception of space by integrating sparse observations
into massively interconnected synapses and neurons, offering a superior
parallelism and efficiency. Replicating this capability in AI finds wide
applications in medical imaging, AR/VR, and embodied AI, where input data is
often sparse and computing resources are limited. However, traditional signal
reconstruction methods on digital computers face both software and hardware
challenges. On the software front, difficulties arise from storage
inefficiencies in conventional explicit signal representation. Hardware
obstacles include the von Neumann bottleneck, which limits data transfer
between the CPU and memory, and the limitations of CMOS circuits in supporting
parallel processing. We propose a systematic approach with software-hardware
co-optimizations for signal reconstruction from sparse inputs. Software-wise,
we employ neural field to implicitly represent signals via neural networks,
which is further compressed using low-rank decomposition and structured
pruning. Hardware-wise, we design a resistive memory-based computing-in-memory
(CIM) platform, featuring a Gaussian Encoder (GE) and an MLP Processing Engine
(PE). The GE harnesses the intrinsic stochasticity of resistive memory for
efficient input encoding, while the PE achieves precise weight mapping through
a Hardware-Aware Quantization (HAQ) circuit. We demonstrate the system's
efficacy on a 40nm 256Kb resistive memory-based in-memory computing macro,
achieving huge energy efficiency and parallelism improvements without
compromising reconstruction quality in tasks like 3D CT sparse reconstruction,
novel view synthesis, and novel view synthesis for dynamic scenes. This work
advances the AI-driven signal restoration technology and paves the way for
future efficient and robust medical AI and 3D vision applications.

摘要：人類透過整合稀疏的觀察來建構空間感知
成大規模互連的突觸和神經元，提供了優越的
並行性和效率。在人工智慧中複製這種能力發現了廣泛的應用
醫學影像、AR/VR 和嵌入式 AI 中的應用，其中輸入資料是
通常稀疏且計算資源有限。然而，傳統訊號
數位計算機的重構方法同時面向軟體和硬體
挑戰。在軟體方面，困難來自於存儲
傳統的顯式訊號表示效率低。硬體
障礙包括馮諾依曼瓶頸，它限制了資料傳輸
CPU 和記憶體之間的關係，以及 CMOS 電路在支援方面的局限性
並行處理。我們提出了一種軟體硬體系統化方法
從稀疏輸入進行訊號重建的協同優化。軟體方面，
我們使用神經場透過神經網路隱式表示訊號，
使用低秩分解進一步壓縮並結構化
修剪。硬體方面，我們設計了基於電阻記憶體的記憶體計算
(CIM) 平台，具有高斯編碼器 (GE) 和 MLP 處理引擎
（體育）。 GE 利用電阻記憶體固有的隨機性
高效率的輸入編碼，而PE透過以下方式實現精確的權重映射
硬體感知量化 (HAQ) 電路。我們展示了該系統的
基於 40nm 256Kb 電阻式記憶體的記憶體計算巨集的功效，
實現巨大的能源效率和並行性改進，而無需
影響 3D CT 稀疏重建等任務的重建質量，
新穎的視圖合成，以及動態場景的新穎的視圖合成。這部作品
推進人工智慧驅動的訊號恢復技術，為
未來高效、強大的醫療人工智慧和 3D 視覺應用。

##### **WiTUnet: A U-Shaped Architecture Integrating CNN and Transformer for Improved Feature Alignment and Local Information Fusion**
2404.09533v1 by Bin Wang,Fei Deng,Peifan Jiang,Shuang Wang,Xiao Han,Hongjie Zheng

Low-dose computed tomography (LDCT) has become the technology of choice for
diagnostic medical imaging, given its lower radiation dose compared to standard
CT, despite increasing image noise and potentially affecting diagnostic
accuracy. To address this, advanced deep learning-based LDCT denoising
algorithms have been developed, primarily using Convolutional Neural Networks
(CNNs) or Transformer Networks with the Unet architecture. This architecture
enhances image detail by integrating feature maps from the encoder and decoder
via skip connections. However, current methods often overlook enhancements to
the Unet architecture itself, focusing instead on optimizing encoder and
decoder structures. This approach can be problematic due to the significant
differences in feature map characteristics between the encoder and decoder,
where simple fusion strategies may not effectively reconstruct images.In this
paper, we introduce WiTUnet, a novel LDCT image denoising method that utilizes
nested, dense skip pathways instead of traditional skip connections to improve
feature integration. WiTUnet also incorporates a windowed Transformer structure
to process images in smaller, non-overlapping segments, reducing computational
load. Additionally, the integration of a Local Image Perception Enhancement
(LiPe) module in both the encoder and decoder replaces the standard multi-layer
perceptron (MLP) in Transformers, enhancing local feature capture and
representation. Through extensive experimental comparisons, WiTUnet has
demonstrated superior performance over existing methods in key metrics such as
Peak Signal-to-Noise Ratio (PSNR), Structural Similarity (SSIM), and Root Mean
Square Error (RMSE), significantly improving noise removal and image quality.

摘要：低劑量電腦斷層掃描（LDCT）已成為首選技術
診斷醫學影像，由於其輻射劑量低於標準
CT，儘管影像雜訊增加並可能影響診斷
準確性。為了解決這個問題，基於深度學習的先進 LDCT 去噪
演算法已經開發出來，主要使用卷積神經網絡
(CNN) 或具有 Unet 架構的 Transformer Networks。這種架構
透過整合編碼器和解碼器的特徵圖來增強影像細節
透過跳過連接。然而，目前的方法常常忽略了對
Unet 架構本身，而是專注於最佳化編碼器和
解碼器結構。由於顯著的
編碼器和解碼器之間特徵圖特徵的差異，
簡單的融合策略可能無法有效地重建影像。
論文中，我們介紹了 WiTUnet，一種新穎的 LDCT 影像去雜訊方法，該方法利用
嵌套的、密集的跳躍路徑而不是傳統的跳躍連結來改進
功能整合。 WiTUnet 也採用了視窗 Transformer 結構
以較小的、不重疊的片段處理影像，減少計算量
載入.此外，還整合了局部影像感知增強功能
編碼器和解碼器中的 (LiPe) 模組取代了標準多層
變形金剛中的感知器（MLP），增強局部特徵捕捉和
表示。透過大量的實驗比較，WiTUnet
在關鍵指標上表現出優於現有方法的性能，例如
峰值訊號雜訊比 (PSNR)、結構相似性 (SSIM) 和平均值根
平方誤差 (RMSE)，顯著提高雜訊去除和影像品質。

##### **Weight Copy and Low-Rank Adaptation for Few-Shot Distillation of Vision Transformers**
2404.09326v2 by Diana-Nicoleta Grigore,Mariana-Iuliana Georgescu,Jon Alvarez Justo,Tor Johansen,Andreea Iuliana Ionescu,Radu Tudor Ionescu

Few-shot knowledge distillation recently emerged as a viable approach to
harness the knowledge of large-scale pre-trained models, using limited data and
computational resources. In this paper, we propose a novel few-shot feature
distillation approach for vision transformers. Our approach is based on two key
steps. Leveraging the fact that vision transformers have a consistent
depth-wise structure, we first copy the weights from intermittent layers of
existing pre-trained vision transformers (teachers) into shallower
architectures (students), where the intermittence factor controls the
complexity of the student transformer with respect to its teacher. Next, we
employ an enhanced version of Low-Rank Adaptation (LoRA) to distill knowledge
into the student in a few-shot scenario, aiming to recover the information
processing carried out by the skipped teacher layers. We present comprehensive
experiments with supervised and self-supervised transformers as teachers, on
five data sets from various domains, including natural, medical and satellite
images. The empirical results confirm the superiority of our approach over
competitive baselines. Moreover, the ablation results demonstrate the
usefulness of each component of the proposed pipeline.

摘要：最近出現的小樣本知識蒸餾是可行的方法
利用有限的數據和大規模預訓練模型的知識
計算資源。在本文中，我們提出了一種新穎的少樣本特徵
視覺變壓器的蒸餾方法。我們的方法基於兩個關鍵
腳步。利用視覺轉換器具有一致的事實
深度結構，我們先從間歇層複製權重
將現有的預訓練視覺變換器（教師）轉化為更淺層的視覺變換器
架構（學生），其中間歇因子控制
學生變壓器相對於其老師的複雜性。接下來，我們
採用增強版的低秩適應 (LoRA) 來擷取知識
在幾次場景中進入學生，旨在恢復訊息
由跳過的教師層執行的處理。我們呈現全面的
以監督和自監督變壓器為教師的實驗
來自不同領域的五個資料集，包括自然、醫學和衛星
圖片。實證結果證實了我們的方法優於
競爭基線。此外，消融結果表明
擬議管道中每個組件的有用性。

##### **Characterizing Soft-Error Resiliency in Arm's Ethos-U55 Embedded Machine Learning Accelerator**
2404.09317v1 by Abhishek Tyagi,Reiley Jeyapaul,Chuteng Zhu,Paul Whatmough,Yuhao Zhu

As Neural Processing Units (NPU) or accelerators are increasingly deployed in
a variety of applications including safety critical applications such as
autonomous vehicle, and medical imaging, it is critical to understand the
fault-tolerance nature of the NPUs. We present a reliability study of Arm's
Ethos-U55, an important industrial-scale NPU being utilised in embedded and IoT
applications. We perform large scale RTL-level fault injections to characterize
Ethos-U55 against the Automotive Safety Integrity Level D (ASIL-D) resiliency
standard commonly used for safety-critical applications such as autonomous
vehicles. We show that, under soft errors, all four configurations of the NPU
fall short of the required level of resiliency for a variety of neural networks
running on the NPU. We show that it is possible to meet the ASIL-D level
resiliency without resorting to conventional strategies like Dual Core Lock
Step (DCLS) that has an area overhead of 100%. We achieve so through selective
protection, where hardware structures are selectively protected (e.g.,
duplicated, hardened) based on their sensitivity to soft errors and their
silicon areas. To identify the optimal configuration that minimizes the area
overhead while meeting the ASIL-D standard, the main challenge is the large
search space associated with the time-consuming RTL simulation. To address this
challenge, we present a statistical analysis tool that is validated against Arm
silicon and that allows us to quickly navigate hundreds of billions of fault
sites without exhaustive RTL fault injections. We show that by carefully
duplicating a small fraction of the functional blocks and hardening the Flops
in other blocks meets the ASIL-D safety standard while introducing an area
overhead of only 38%.

摘要：隨著神經處理單元 (NPU) 或加速器越來越多地部署在
各種應用，包括安全關鍵應用，例如
自動駕駛汽車和醫學成像，了解這一點至關重要
NPU 的容錯特性。我們提出了 Arm 的可靠性研究
Ethos-U55，一種重要的工業級 NPU，應用於嵌入式和物聯網
應用程式.我們執行大規模 RTL 級故障注入來表徵
Ethos-U55 針對汽車安全完整性等級 D (ASIL-D) 彈性
標準通常用於安全關鍵型應用，例如自動駕駛
汽車。我們證明，在軟錯誤下，NPU 的所有四種配置
達不到各種神經網路所需的彈性水平
運行在NPU上。我們證明可以達到 ASIL-D 級別
無需訴諸雙核鎖等傳統策略即可實現彈性
面積開銷為 100% 的步驟 (DCLS)。我們透過選擇性地實現這一目標
保護，其中硬體結構受到選擇性保護（例如，
重複的、硬化的）是基於它們對軟錯誤的敏感度及其
矽區域。確定最小化面積的最佳配置
在滿足 ASIL-D 標準的同時，主要挑戰是開銷大
與耗時的 RTL 模擬相關的搜尋空間。為了解決這個問題
挑戰，我們提出了一個針對 Arm 驗證的統計分析工具
矽使我們能夠快速解決數千億個故障
沒有詳盡的 RTL 故障注入的站點。我們透過仔細證明
複製一小部分功能塊並強化 Flops
其他區塊符合 ASIL-D 安全標準，同時引入一個區域
開銷僅38%。

##### **TLDR at SemEval-2024 Task 2: T5-generated clinical-Language summaries for DeBERTa Report Analysis**
2404.09136v1 by Spandan Das,Vinay Samuel,Shahriar Noroozizadeh

This paper introduces novel methodologies for the Natural Language Inference
for Clinical Trials (NLI4CT) task. We present TLDR (T5-generated
clinical-Language summaries for DeBERTa Report Analysis) which incorporates
T5-model generated premise summaries for improved entailment and contradiction
analysis in clinical NLI tasks. This approach overcomes the challenges posed by
small context windows and lengthy premises, leading to a substantial
improvement in Macro F1 scores: a 0.184 increase over truncated premises. Our
comprehensive experimental evaluation, including detailed error analysis and
ablations, confirms the superiority of TLDR in achieving consistency and
faithfulness in predictions against semantically altered inputs.

摘要：本文介紹了自然語言推理的新方法
臨床試驗（NLI4CT）任務。我們提出 TLDR（T5 產生的
DeBERTa 報告分析的臨床語言摘要）其中包含
T5 模型生成前提摘要以改善蘊涵和矛盾
臨床 NLI 任務中的分析。這種方法克服了以下挑戰
小上下文視窗和冗長的前提，導致大量
Macro F1 分數的改進：比截斷的前提提高了 0.184。我們的
全面的實驗評估，包括詳細的誤差分析和
消融，證實了 TLDR 在實現一致性和
對語意改變輸入的預測的忠實度。

##### **Advanced Neural Network Architecture for Enhanced Multi-Lead ECG Arrhythmia Detection through Optimized Feature Extraction**
2404.15347v1 by Bhavith Chandra Challagundla

Cardiovascular diseases are a pervasive global health concern, contributing
significantly to morbidity and mortality rates worldwide. Among these
conditions, arrhythmia, characterized by irregular heart rhythms, presents
formidable diagnostic challenges. This study introduces an innovative approach
utilizing deep learning techniques, specifically Convolutional Neural Networks
(CNNs), to address the complexities of arrhythmia classification. Leveraging
multi-lead Electrocardiogram (ECG) data, our CNN model, comprising six layers
with a residual block, demonstrates promising outcomes in identifying five
distinct heartbeat types: Left Bundle Branch Block (LBBB), Right Bundle Branch
Block (RBBB), Atrial Premature Contraction (APC), Premature Ventricular
Contraction (PVC), and Normal Beat. Through rigorous experimentation, we
highlight the transformative potential of our methodology in enhancing
diagnostic accuracy for cardiovascular arrhythmias. Arrhythmia diagnosis
remains a critical challenge in cardiovascular care, often relying on manual
interpretation of ECG signals, which can be time-consuming and prone to
subjectivity. To address these limitations, we propose a novel approach that
leverages deep learning algorithms to automate arrhythmia classification. By
employing advanced CNN architectures and multi-lead ECG data, our methodology
offers a robust solution for precise and efficient arrhythmia detection.
Through comprehensive evaluation, we demonstrate the effectiveness of our
approach in facilitating more accurate clinical decision-making, thereby
improving patient outcomes in managing cardiovascular arrhythmias.

摘要：心血管疾病是一個普遍存在的全球健康問題，
對全世界的發病率和死亡率有顯著影響。在這些當中
心律不整，以心律不整為特徵，表現為
巨大的診斷挑戰。這項研究引入了一種創新方法
利用深度學習技術，特別是卷積神經網絡
（CNN），解決心律不整分類的複雜性。槓桿作用
多導聯心電圖 (ECG) 數據，我們的 CNN 模型，包含六層
帶有殘餘塊，在識別五個方面展示了有希望的結果
不同的心跳類型：左束支傳導阻滯 (LBBB)、右束支傳導阻滯
傳導阻滯 (RBBB)、心房性早期心搏 (APC)、心室早期收縮
收縮 (PVC) 和正常節拍。透過嚴格的實驗，我們
強調我們的方法論在增強
心血管心律不整的診斷準確性。心律不整診斷
仍然是心血管護理的關鍵挑戰，通常依賴手動
解讀心電圖訊號，這可能非常耗時且容易
主觀性。為了解決這些限制，我們提出了一種新方法
利用深度學習演算法自動進行心律不整分類。經過
我們的方法採用先進的 CNN 架構和多導聯心電圖數據
為精確、高效的心律不整檢測提供強大的解決方案。
透過綜合評估，我們展示了我們的有效性
方法促進更準確的臨床決策，從而
改善心血管心律不整的患者治療效果。

##### **Adapting Mental Health Prediction Tasks for Cross-lingual Learning via Meta-Training and In-context Learning with Large Language Model**
2404.09045v1 by Zita Lifelo,Huansheng Ning,Sahraoui Dhelim

Timely identification is essential for the efficient handling of mental
health illnesses such as depression. However, the current research fails to
adequately address the prediction of mental health conditions from social media
data in low-resource African languages like Swahili. This study introduces two
distinct approaches utilising model-agnostic meta-learning and leveraging large
language models (LLMs) to address this gap. Experiments are conducted on three
datasets translated to low-resource language and applied to four mental health
tasks, which include stress, depression, depression severity and suicidal
ideation prediction. we first apply a meta-learning model with
self-supervision, which results in improved model initialisation for rapid
adaptation and cross-lingual transfer. The results show that our meta-trained
model performs significantly better than standard fine-tuning methods,
outperforming the baseline fine-tuning in macro F1 score with 18\% and 0.8\%
over XLM-R and mBERT. In parallel, we use LLMs' in-context learning
capabilities to assess their performance accuracy across the Swahili mental
health prediction tasks by analysing different cross-lingual prompting
approaches. Our analysis showed that Swahili prompts performed better than
cross-lingual prompts but less than English prompts. Our findings show that
in-context learning can be achieved through cross-lingual transfer through
carefully crafted prompt templates with examples and instructions.

摘要：及時識別對於有效處理心理問題至關重要
憂鬱症等健康疾病。然而，目前的研究未能
充分解決社群媒體對心理健康狀況的預測
斯瓦希里語等資源匱乏的非洲語言的資料。本研究介紹了兩個
利用與模型無關的元學習和利用大規模的不同方法
語言模型（LLM）可以彌補這一差距。實驗在三個上進行
資料集翻譯成低資源語言並應用於四種心理健康
任務，包括壓力、憂鬱、憂鬱嚴重程度和自殺傾向
構想預測。我們首先應用元學習模型
自我監督，從而改進模型初始化以實現快速
適應和跨語言遷移。結果顯示我們的元訓練
模型的性能明顯優於標準微調方法，
宏 F1 分數優於基線微調，分別為 18\% 與 0.8\%
超過 XLM-R 和 mBERT。同時，我們使用LLM的情境學習
評估他們在斯瓦希里語心理中的表現準確性的能力
透過分析不同的跨語言提示來完成健康預測任務
接近。我們的分析表明，斯瓦希里語提示的效果優於
跨語言提示但少於英文提示。我們的研究結果表明
情境學習可以透過跨語言遷移來實現
精心製作的提示模板，包含範例和說明。

##### **A Fourier-enhanced multi-modal 3D small object optical mark recognition and positioning method for percutaneous abdominal puncture surgical navigation**
2404.08990v1 by Zezhao Guo,Yanzhong Guo,Zhanfang Zhao

Navigation for thoracoabdominal puncture surgery is used to locate the needle
entry point on the patient's body surface. The traditional reflective ball
navigation method is difficult to position the needle entry point on the soft,
irregular, smooth chest and abdomen. Due to the lack of clear characteristic
points on the body surface using structured light technology, it is difficult
to identify and locate arbitrary needle insertion points. Based on the high
stability and high accuracy requirements of surgical navigation, this paper
proposed a novel method, a muti-modal 3D small object medical marker detection
method, which identifies the center of a small single ring as the needle
insertion point. Moreover, this novel method leverages Fourier transform
enhancement technology to augment the dataset, enrich image details, and
enhance the network's capability. The method extracts the Region of Interest
(ROI) of the feature image from both enhanced and original images, followed by
generating a mask map. Subsequently, the point cloud of the ROI from the depth
map is obtained through the registration of ROI point cloud contour fitting. In
addition, this method employs Tukey loss for optimal precision. The
experimental results show this novel method proposed in this paper not only
achieves high-precision and high-stability positioning, but also enables the
positioning of any needle insertion point.

摘要：胸腹穿刺手術中的導航用於定位針頭
患者體表的進入點。傳統反光球
導航方法很難將進針點定位在軟體上，
胸部和腹部不規則、光滑。由於缺乏明確的特徵
利用結構光技術在體表上點，很難
識別和定位任意針插入點。立足於高
手術導航的穩定性和高精度要求，本文
提出了一種新方法，多模態 3D 小物體醫學標記檢測
方法，將小單環的中心識別為針
插入點。此外，這種新穎的方法利用了傅立葉變換
增強技術來增強資料集、豐富影像細節，以及
提升網路能力。此方法提取感興趣區域
（ROI）來自增強影像和原始影像的特徵影像，然後是
生成掩模圖。隨後，深度的 ROI 的點雲
透過ROI點雲輪廓擬合配準得到地圖。在
此外，該方法採用 Tukey 損失來獲得最佳精確度。這
實驗結果顯示本文所提出的這種新方法不僅
實現了高精度、高穩定性的定位，同時也使得
任何針插入點的定位。

##### **Leveraging Large Language Model as Simulated Patients for Clinical Education**
2404.13066v2 by Yanzeng Li,Cheng Zeng,Jialun Zhong,Ruoyu Zhang,Minhao Zhang,Lei Zou

Simulated Patients (SPs) play a crucial role in clinical medical education by
providing realistic scenarios for student practice. However, the high cost of
training and hiring qualified SPs, along with the heavy workload and potential
risks they face in consistently portraying actual patients, limit students'
access to this type of clinical training. Consequently, the integration of
computer program-based simulated patients has emerged as a valuable educational
tool in recent years. With the rapid development of Large Language Models
(LLMs), their exceptional capabilities in conversational artificial
intelligence and role-playing have been demonstrated, making them a feasible
option for implementing Virtual Simulated Patient (VSP). In this paper, we
present an integrated model-agnostic framework called CureFun that harnesses
the potential of LLMs in clinical medical education. This framework facilitates
natural conversations between students and simulated patients, evaluates their
dialogue, and provides suggestions to enhance students' clinical inquiry
skills. Through comprehensive evaluations, our approach demonstrates more
authentic and professional SP-scenario dialogue flows compared to other
LLM-based chatbots, thus proving its proficiency in simulating patients.
Additionally, leveraging CureFun's evaluation ability, we assess several
medical LLMs and discuss the possibilities and limitations of using LLMs as
virtual doctors from the perspective of their diagnostic abilities.

摘要：模擬患者 (SP) 在臨床醫學教育中發揮著至關重要的作用
為學生練習提供真實的場景。然而，高昂的成本
培訓和聘用合格的SP，工作量大，潛力大
他們在持續描繪真實患者時面臨的風險，限制了學生的
獲得此類臨床培訓。因此，整合
基於電腦程式的模擬患者已成為一種有價值的教育手段
近年來的工具。隨著大型語言模式的快速發展
（LLM），他們在對話人工方面的卓越能力
智力和角色扮演已經被證明，使它們成為可行的
用於實施虛擬模擬患者 (VSP) 的選項。在本文中，我們
提出了一個名為 CureFun 的整合模型不可知框架，該框架利用
LLM在臨床醫學教育中的潛力。此框架有利於
學生和模擬患者之間的自然對話，評估他們的
對話，並為加強學生的臨床探究提供建議
技能。透過綜合評估，我們的方法展示了更多
與其他對話流程相比，真實且專業的SP場景對話流程
基於LLM的聊天機器人，從而證明了其在模擬患者方面的熟練程度。
此外，利用 CureFun 的評估能力，我們評估了幾個
醫學LLM並討論使用LLM作為
虛擬醫生從診斷能力的角度來看。

##### **Is ChatGPT Transforming Academics' Writing Style?**
2404.08627v1 by Mingmeng Geng,Roberto Trotta

Based on one million arXiv papers submitted from May 2018 to January 2024, we
assess the textual density of ChatGPT's writing style in their abstracts by
means of a statistical analysis of word frequency changes. Our model is
calibrated and validated on a mixture of real abstracts and ChatGPT-modified
abstracts (simulated data) after a careful noise analysis. We find that ChatGPT
is having an increasing impact on arXiv abstracts, especially in the field of
computer science, where the fraction of ChatGPT-revised abstracts is estimated
to be approximately 35%, if we take the output of one of the simplest prompts,
"revise the following sentences", as a baseline. We conclude with an analysis
of both positive and negative aspects of the penetration of ChatGPT into
academics' writing style.

摘要：基於 2018 年 5 月至 2024 年 1 月提交的 100 萬篇 arXiv 論文，我們
透過以下方式評估 ChatGPT 在摘要中的寫作風格的文本密度
對詞頻變化進行統計分析的手段。我們的模型是
在真實摘要和 ChatGPT 修改的混合物上進行校準和驗證
經過仔細的噪音分析後的摘要（模擬數據）。我們發現ChatGPT
對 arXiv 摘要的影響越來越大，尤其是在
計算機科學，估計 ChatGPT 修訂摘要的比例
如果我們採用最簡單的提示之一的輸出，則約為 35%，
“修改以下句子”，作為基線。我們透過分析得出結論
ChatGPT 滲透的正面和負面方面
學者的寫作風格。

##### **Automatic Quantification of Serial PET/CT Images for Pediatric Hodgkin Lymphoma Patients Using a Longitudinally-Aware Segmentation Network**
2404.08611v1 by Xin Tie,Muheon Shin,Changhee Lee,Scott B. Perlman,Zachary Huemann,Amy J. Weisman,Sharon M. Castellino,Kara M. Kelly,Kathleen M. McCarten,Adina L. Alazraki,Junjie Hu,Steve Y. Cho,Tyler J. Bradshaw

$\textbf{Purpose}$: Automatic quantification of longitudinal changes in PET
scans for lymphoma patients has proven challenging, as residual disease in
interim-therapy scans is often subtle and difficult to detect. Our goal was to
develop a longitudinally-aware segmentation network (LAS-Net) that can quantify
serial PET/CT images for pediatric Hodgkin lymphoma patients.
$\textbf{Materials and Methods}$: This retrospective study included baseline
(PET1) and interim (PET2) PET/CT images from 297 patients enrolled in two
Children's Oncology Group clinical trials (AHOD1331 and AHOD0831). LAS-Net
incorporates longitudinal cross-attention, allowing relevant features from PET1
to inform the analysis of PET2. Model performance was evaluated using Dice
coefficients for PET1 and detection F1 scores for PET2. Additionally, we
extracted and compared quantitative PET metrics, including metabolic tumor
volume (MTV) and total lesion glycolysis (TLG) in PET1, as well as qPET and
$\Delta$SUVmax in PET2, against physician measurements. We quantified their
agreement using Spearman's $\rho$ correlations and employed bootstrap
resampling for statistical analysis. $\textbf{Results}$: LAS-Net detected
residual lymphoma in PET2 with an F1 score of 0.606 (precision/recall:
0.615/0.600), outperforming all comparator methods (P<0.01). For baseline
segmentation, LAS-Net achieved a mean Dice score of 0.772. In PET
quantification, LAS-Net's measurements of qPET, $\Delta$SUVmax, MTV and TLG
were strongly correlated with physician measurements, with Spearman's $\rho$ of
0.78, 0.80, 0.93 and 0.96, respectively. The performance remained high, with a
slight decrease, in an external testing cohort. $\textbf{Conclusion}$: LAS-Net
achieved high performance in quantifying PET metrics across serial scans,
highlighting the value of longitudinal awareness in evaluating multi-time-point
imaging datasets.

摘要：$\textbf{目的}$：PET縱向變化的自動量化
事實證明，對淋巴瘤患者進行掃描具有挑戰性，因為殘留病灶
中期治療掃描通常很微妙且難以檢測。我們的目標是
發展一個縱向感知分割網路（LAS-Net），可以量化
兒科霍奇金淋巴瘤患者的一系列 PET/CT 影像。
$\textbf{材料和方法}$：這項回顧性研究包括基線
(PET1) 和中期 (PET2) PET/CT 影像，來自 297 名入組的患者
兒童腫瘤學組臨床試驗（AHOD1331 和 AHOD0831）。 LAS網絡
結合了縱向交叉注意力，允許來自 PET1 的相關特徵
為 PET2 的分析提供資訊。使用 Dice 評估模型性能
PET1 的係數和 PET2 的檢測 F1 分數。此外，我們
擷取並比較定量 PET 指標，包括代謝腫瘤
PET1 中的體積 (MTV) 和總病變糖解 (TLG)，以及 qPET 和
PET2 中的 $\Delta$SUVmax，與醫師測量結果相反。我們量化了他們的
使用 Spearman 的 $\rho$ 相關性並使用 bootstrap 達成協議
重新採樣以進行統計分析。 $\textbf{結果}$: 偵測到 LAS-Net
PET2 殘留淋巴瘤，F1 評分為 0.606（精確度/召回率：
0.615/0.600)，優於所有比較方法 (P<0.01)。對於基線
分割時，LAS-Net 的平均 Dice 得分為 0.772。在PET中
量化、LAS-Net 對 qPET、$\Delta$SUVmax、MTV 和 TLG 的測量
與醫生測量值密切相關，斯皮爾曼的 $\rho$ 為
分別為 0.78、0.80、0.93 和 0.96。業績仍保持高位，
在外部測試佇列中略有下降。 $\textbf{結論}$: LAS-Net
在連續掃描中量化 PET 指標方面取得了高效能，
強調縱向意識在評估多時間點的價值
成像資料集。

##### **RLHF Deciphered: A Critical Analysis of Reinforcement Learning from Human Feedback for LLMs**
2404.08555v2 by Shreyas Chaudhari,Pranjal Aggarwal,Vishvak Murahari,Tanmay Rajpurohit,Ashwin Kalyan,Karthik Narasimhan,Ameet Deshpande,Bruno Castro da Silva

State-of-the-art large language models (LLMs) have become indispensable tools
for various tasks. However, training LLMs to serve as effective assistants for
humans requires careful consideration. A promising approach is reinforcement
learning from human feedback (RLHF), which leverages human feedback to update
the model in accordance with human preferences and mitigate issues like
toxicity and hallucinations. Yet, an understanding of RLHF for LLMs is largely
entangled with initial design choices that popularized the method and current
research focuses on augmenting those choices rather than fundamentally
improving the framework. In this paper, we analyze RLHF through the lens of
reinforcement learning principles to develop an understanding of its
fundamentals, dedicating substantial focus to the core component of RLHF -- the
reward model. Our study investigates modeling choices, caveats of function
approximation, and their implications on RLHF training algorithms, highlighting
the underlying assumptions made about the expressivity of reward. Our analysis
improves the understanding of the role of reward models and methods for their
training, concurrently revealing limitations of the current methodology. We
characterize these limitations, including incorrect generalization, model
misspecification, and the sparsity of feedback, along with their impact on the
performance of a language model. The discussion and analysis are substantiated
by a categorical review of current literature, serving as a reference for
researchers and practitioners to understand the challenges of RLHF and build
upon existing efforts.

摘要：最先進的大型語言模型（LLM）已成為不可或缺的工具
用於各種任務。然而，培訓LLM作為有效的助手
人類需要仔細考慮。一個有希望的方法是強化
從人類回饋中學習（RLHF），它利用人類回饋來更新
該模型符合人類偏好並緩解諸如
中毒和幻覺。然而，LLM對 RLHF 的理解很大程度上是
與推廣該方法和當前的最初設計選擇糾纏在一起
研究的重點是增加這些選擇，而不是從根本上
完善框架。在本文中，我們透過以下視角來分析 RLHF：
強化學習原理以加深對其的理解
基本面，重點在於 RLHF 的核心組成部分——
獎勵模型。我們的研究調查了模型選擇、功能注意事項
近似值及其對 RLHF 訓練演算法的影響，強調
關於獎勵表現力的基本假設。我們的分析
提高對獎勵模型和方法的作用的理解
培訓，同時揭示目前方法的局限性。我們
描述這些局限性，包括不正確的概括、模型
錯誤指定和回饋的稀疏性及其對
語言模型的效能。討論和分析有依據
透過現有文獻的分類回顧，作為參考
研究人員和從業者了解 RLHF 的挑戰並建立
依靠現有的努力。

##### **An improved tabular data generator with VAE-GMM integration**
2404.08434v1 by Patricia A. Apellániz,Juan Parras,Santiago Zazo

The rising use of machine learning in various fields requires robust methods
to create synthetic tabular data. Data should preserve key characteristics
while addressing data scarcity challenges. Current approaches based on
Generative Adversarial Networks, such as the state-of-the-art CTGAN model,
struggle with the complex structures inherent in tabular data. These data often
contain both continuous and discrete features with non-Gaussian distributions.
Therefore, we propose a novel Variational Autoencoder (VAE)-based model that
addresses these limitations. Inspired by the TVAE model, our approach
incorporates a Bayesian Gaussian Mixture model (BGM) within the VAE
architecture. This avoids the limitations imposed by assuming a strictly
Gaussian latent space, allowing for a more accurate representation of the
underlying data distribution during data generation. Furthermore, our model
offers enhanced flexibility by allowing the use of various differentiable
distributions for individual features, making it possible to handle both
continuous and discrete data types. We thoroughly validate our model on three
real-world datasets with mixed data types, including two medically relevant
ones, based on their resemblance and utility. This evaluation demonstrates
significant outperformance against CTGAN and TVAE, establishing its potential
as a valuable tool for generating synthetic tabular data in various domains,
particularly in healthcare.

摘要：機器學習在各個領域的使用不斷增加需要強大的方法
建立合成表格資料。資料應保留關鍵特徵
同時解決數據稀缺的挑戰。目前的方法是基於
生成對抗網絡，例如最先進的 CTGAN 模型，
與表格資料​​固有的複雜結構作鬥爭。這些數據經常
包含具有非高斯分佈的連續和離散特徵。
因此，我們提出了一種新穎的基於變分自動編碼器（VAE）的模型
解決了這些限制。受 TVAE 模型的啟發，我們的方法
在 VAE 中結合了貝葉斯高斯混合模型 (BGM)
建築學。這避免了嚴格假設所施加的限制
高斯潛在空間，可以更準確地表示
資料生成期間的底層資料分佈。此外，我們的模型
透過允許使用各種可微分來提供增強的靈活性
單一特徵的分佈，使得處理這兩個特徵成為可能
連續和離散資料類型。我們在三個方面徹底驗證了我們的模型
具有混合資料類型的現實世界資料集，包括兩個醫學相關的資料集
的，基於它們的相似性和實用性。此次評估表明
顯著優於 CTGAN 和 TVAE，確立了其潛力
作為在各個領域生成合成表格數據的有價值的工具，
特別是在醫療保健領域。

##### **Improving Health Question Answering with Reliable and Time-Aware Evidence Retrieval**
2404.08359v1 by Juraj Vladika,Florian Matthes

In today's digital world, seeking answers to health questions on the Internet
is a common practice. However, existing question answering (QA) systems often
rely on using pre-selected and annotated evidence documents, thus making them
inadequate for addressing novel questions. Our study focuses on the open-domain
QA setting, where the key challenge is to first uncover relevant evidence in
large knowledge bases. By utilizing the common retrieve-then-read QA pipeline
and PubMed as a trustworthy collection of medical research documents, we answer
health questions from three diverse datasets. We modify different retrieval
settings to observe their influence on the QA pipeline's performance, including
the number of retrieved documents, sentence selection process, the publication
year of articles, and their number of citations. Our results reveal that
cutting down on the amount of retrieved documents and favoring more recent and
highly cited documents can improve the final macro F1 score up to 10%. We
discuss the results, highlight interesting examples, and outline challenges for
future research, like managing evidence disagreement and crafting user-friendly
explanations.

摘要：在當今的數位世界中，在網路上尋求健康問題的答案
這是常見的做法。然而，現有的問答（QA）系統通常
依靠使用預先選擇和註釋的證據文件，從而使它們
不足以解決新問題。我們的研究重點是開放域
QA 設置，其中的關鍵挑戰是首先發現相關證據
龐大的知識庫。透過利用常見的檢索然後讀取 QA 管道
和 PubMed 作為值得信賴的醫學研究文獻集合，我們回答
來自三個不同數據集的健康問題。我們修改不同的檢索
設定以觀察它們對 QA 管道性能的影響，包括
檢索到的文件數量、句子選擇過程、出版物
文章年份及其被引用次數。我們的結果表明
減少檢索到的文件數量並傾向於更新和更新
被高引用的文獻可以將最終的宏 F1 分數提高最多 10%。我們
討論結果，突出有趣的例子，並概述挑戰
未來的研究，例如管理證據分歧和設計用戶友好型
解釋。

##### **Generating Synthetic Satellite Imagery With Deep-Learning Text-to-Image Models -- Technical Challenges and Implications for Monitoring and Verification**
2404.07754v1 by Tuong Vy Nguyen,Alexander Glaser,Felix Biessmann

Novel deep-learning (DL) architectures have reached a level where they can
generate digital media, including photorealistic images, that are difficult to
distinguish from real data. These technologies have already been used to
generate training data for Machine Learning (ML) models, and large
text-to-image models like DALL-E 2, Imagen, and Stable Diffusion are achieving
remarkable results in realistic high-resolution image generation. Given these
developments, issues of data authentication in monitoring and verification
deserve a careful and systematic analysis: How realistic are synthetic images?
How easily can they be generated? How useful are they for ML researchers, and
what is their potential for Open Science? In this work, we use novel DL models
to explore how synthetic satellite images can be created using conditioning
mechanisms. We investigate the challenges of synthetic satellite image
generation and evaluate the results based on authenticity and state-of-the-art
metrics. Furthermore, we investigate how synthetic data can alleviate the lack
of data in the context of ML methods for remote-sensing. Finally we discuss
implications of synthetic satellite imagery in the context of monitoring and
verification.

摘要：新穎的深度學習 (DL) 架構已達到可實現的水平
產生難以產生的數位媒體，包括逼真的影像
與真實數據區別。這些技術已經被用於
為機器學習 (ML) 模型產生訓練數據，以及大型
DALL-E 2、Imagen 和 Stable Diffusion 等文字到圖像模型正在實現
在逼真的高解析度影像生成方面取得了顯著的成果。鑑於這些
監測和核查中資料認證的發展和問題
值得仔細、有系統的分析：合成影像有多真實？
它們的生成有多容易？它們對機器學習研究人員有多大用處，以及
他們在開放科學方面的潛力是什麼？在這項工作中，我們使用新穎的深度學習模型
探索如何使用條件創建合成衛星影像
機制。我們研究合成衛星圖像的挑戰
根據真實性和最新技術生成和評估結果
指標。此外，我們研究了合成數據如何緩解缺乏
遙感機器學習方法背景下的數據。最後我們討論
合成衛星影像在監測和監測方面的影響
確認。

##### **Medical mT5: An Open-Source Multilingual Text-to-Text LLM for The Medical Domain**
2404.07613v1 by Iker García-Ferrero,Rodrigo Agerri,Aitziber Atutxa Salazar,Elena Cabrio,Iker de la Iglesia,Alberto Lavelli,Bernardo Magnini,Benjamin Molinet,Johana Ramirez-Romero,German Rigau,Jose Maria Villa-Gonzalez,Serena Villata,Andrea Zaninello

Research on language technology for the development of medical applications
is currently a hot topic in Natural Language Understanding and Generation.
Thus, a number of large language models (LLMs) have recently been adapted to
the medical domain, so that they can be used as a tool for mediating in
human-AI interaction. While these LLMs display competitive performance on
automated medical texts benchmarks, they have been pre-trained and evaluated
with a focus on a single language (English mostly). This is particularly true
of text-to-text models, which typically require large amounts of
domain-specific pre-training data, often not easily accessible for many
languages. In this paper, we address these shortcomings by compiling, to the
best of our knowledge, the largest multilingual corpus for the medical domain
in four languages, namely English, French, Italian and Spanish. This new corpus
has been used to train Medical mT5, the first open-source text-to-text
multilingual model for the medical domain. Additionally, we present two new
evaluation benchmarks for all four languages with the aim of facilitating
multilingual research in this domain. A comprehensive evaluation shows that
Medical mT5 outperforms both encoders and similarly sized text-to-text models
for the Spanish, French, and Italian benchmarks, while being competitive with
current state-of-the-art LLMs in English.

摘要：醫學應用開發的語言技術研究
是目前自然語言理解和生成領域的熱門話題。
因此，許多大型語言模型（LLM）最近已適應
醫學領域，以便它們可以用作調解的工具
人機互動。雖然這些LLM在以下方面表現出有競爭力的表現
自動化醫學文本基準，它們已經過預先訓練和評估
專注於單一語言（主要是英語）。這一點尤其正確
文字到文字模型，通常需要大量
特定領域的預訓練數據，通常對許多人來說不容易訪問
語言。在本文中，我們透過編譯來解決這些缺點
據我們所知，醫學領域最大的多語言語料庫
四種語言，分別是英語、法語、義大利語和西班牙語。這個新語料庫
已用於訓練 Medical mT5，第一個開源文本到文本
醫學領域的多語言模型。此外，我們也推出了兩款新產品
所有四種語言的評估基準，旨在促進
該領域的多語言研究。綜合評估表明
醫療 mT5 的表現優於編碼器和類似大小的文字到文字模型
西班牙、法國和義大利基準，同時具有競爭力
目前最先進的英語LLM。

##### **Contrastive-Based Deep Embeddings for Label Noise-Resilient Histopathology Image Classification**
2404.07605v1 by Lucas Dedieu,Nicolas Nerrienet,Adrien Nivaggioli,Clara Simmat,Marceau Clavel,Arnaud Gauthier,Stéphane Sockeel,Rémy Peyret

Recent advancements in deep learning have proven highly effective in medical
image classification, notably within histopathology. However, noisy labels
represent a critical challenge in histopathology image classification, where
accurate annotations are vital for training robust deep learning models.
Indeed, deep neural networks can easily overfit label noise, leading to severe
degradations in model performance. While numerous public pathology foundation
models have emerged recently, none have evaluated their resilience to label
noise. Through thorough empirical analyses across multiple datasets, we exhibit
the label noise resilience property of embeddings extracted from foundation
models trained in a self-supervised contrastive manner. We demonstrate that
training with such embeddings substantially enhances label noise robustness
when compared to non-contrastive-based ones as well as commonly used
noise-resilient methods. Our results unequivocally underline the superiority of
contrastive learning in effectively mitigating the label noise challenge. Code
is publicly available at
https://github.com/LucasDedieu/NoiseResilientHistopathology.

摘要：深度學習的最新進展已被證明在醫學領域非常有效
影像分類，尤其是組織病理學領域的影像分類。然而，嘈雜的標籤
代表了組織病理學圖像分類中的一個關鍵挑戰，其中
準確的註釋對於訓練強大的深度學習模型至關重要。
事實上，深度神經網路很容易過度擬合標籤噪聲，導致嚴重的問題
模型性能下降。雖然許多公共病理學基金會
最近出現了一些模型，但沒有人評估它們的標籤適應能力
噪音。透過對多個資料集進行徹底的實證分析，我們展示了
從基礎中提取的嵌入的標籤雜訊恢復屬性
以自我監督對比方式訓練的模式。我們證明
使用這種嵌入進行訓練大大增強了標籤雜訊的穩健性
與非對比性的以及常用的相比
抗噪聲方法。我們的結果明確地強調了
對比學習有效緩解標籤噪音挑戰。程式碼
公開於
https://github.com/LucasDedieu/NoiseResilientHistopathology。

##### **Socially Pertinent Robots in Gerontological Healthcare**
2404.07560v1 by Xavier Alameda-Pineda,Angus Addlesee,Daniel Hernández García,Chris Reinke,Soraya Arias,Federica Arrigoni,Alex Auternaud,Lauriane Blavette,Cigdem Beyan,Luis Gomez Camara,Ohad Cohen,Alessandro Conti,Sébastien Dacunha,Christian Dondrup,Yoav Ellinson,Francesco Ferro,Sharon Gannot,Florian Gras,Nancie Gunson,Radu Horaud,Moreno D'Incà,Imad Kimouche,Séverin Lemaignan,Oliver Lemon,Cyril Liotard,Luca Marchionni,Mordehay Moradi,Tomas Pajdla,Maribel Pino,Michal Polic,Matthieu Py,Ariel Rado,Bin Ren,Elisa Ricci,Anne-Sophie Rigaud,Paolo Rota,Marta Romeo,Nicu Sebe,Weronika Sieińska,Pinchas Tandeitnik,Francesco Tonini,Nicolas Turro,Timothée Wintz,Yanchao Yu

Despite the many recent achievements in developing and deploying social
robotics, there are still many underexplored environments and applications for
which systematic evaluation of such systems by end-users is necessary. While
several robotic platforms have been used in gerontological healthcare, the
question of whether or not a social interactive robot with multi-modal
conversational capabilities will be useful and accepted in real-life facilities
is yet to be answered. This paper is an attempt to partially answer this
question, via two waves of experiments with patients and companions in a
day-care gerontological facility in Paris with a full-sized humanoid robot
endowed with social and conversational interaction capabilities. The software
architecture, developed during the H2020 SPRING project, together with the
experimental protocol, allowed us to evaluate the acceptability (AES) and
usability (SUS) with more than 60 end-users. Overall, the users are receptive
to this technology, especially when the robot perception and action skills are
robust to environmental clutter and flexible to handle a plethora of different
interactions.

摘要：儘管最近在開發和部署社會安全保障方面取得了許多成就
機器人技術仍有許多尚未開發的環境和應用
最終使用者對此類系統進行系統評估是必要的。儘管
多個機器人平台已用於老年保健、
社交互動機器人是否具有多模態的問題
對話功能將在現實生活設施中有用並被接受
尚待解答。本文試圖部分回答這個問題
透過對患者和同伴進行的兩波實驗來回答這個問題
巴黎的老人日間照顧中心配備全尺寸人形機器人
具有社交和對話互動能力。軟體
架構，在 H2020 SPRING 專案期間開發，與
實驗協議，使我們能夠評估可接受性（AES）和
可用性 (SUS) 超過 60 個最終使用者。整體來說，使用者的接受度還是不錯的
對於這項技術，尤其是當機器人的感知和動作技能
對環境雜亂具有穩健性，並且能夠靈活地處理多種不同的情況
互動。

##### **Introducing L2M3, A Multilingual Medical Large Language Model to Advance Health Equity in Low-Resource Regions**
2404.08705v1 by Agasthya Gangavarapu

Addressing the imminent shortfall of 10 million health workers by 2030,
predominantly in Low- and Middle-Income Countries (LMICs), this paper
introduces an innovative approach that harnesses the power of Large Language
Models (LLMs) integrated with machine translation models. This solution is
engineered to meet the unique needs of Community Health Workers (CHWs),
overcoming language barriers, cultural sensitivities, and the limited
availability of medical dialog datasets. I have crafted a model that not only
boasts superior translation capabilities but also undergoes rigorous
fine-tuning on open-source datasets to ensure medical accuracy and is equipped
with comprehensive safety features to counteract the risks of misinformation.
  Featuring a modular design, this approach is specifically structured for
swift adaptation across various linguistic and cultural contexts, utilizing
open-source components to significantly reduce healthcare operational costs.
This strategic innovation markedly improves the accessibility and quality of
healthcare services by providing CHWs with contextually appropriate medical
knowledge and diagnostic tools. This paper highlights the transformative impact
of this context-aware LLM, underscoring its crucial role in addressing the
global healthcare workforce deficit and propelling forward healthcare outcomes
in LMICs.

摘要：解決 2030 年即將面臨的 1,000 萬名衛生工作者短缺問題，
主要在低收入和中等收入國家 (LMIC)，本文
引進了一種利用大語言力量的創新方法
與機器翻譯模型整合的模型（LLM）。這個解決方案是
旨在滿足社區健康工作者 (CHW) 的獨特需求，
克服語言障礙、文化敏感度和有限性
醫療對話資料集的可用性。我製作了一個模型，不僅
擁有卓越的翻譯能力，但也經過嚴格的
對開源資料集進行微調，以確保醫療準確性並配備
具有全面的安全功能，可以抵消錯誤訊息的風險。
  此方法採用模組化設計，專門針對
快速適應不同的語言和文化背景，利用
開源元件可顯著降低醫療保健營運成本。
這項戰略創新顯著提高了訪問的可及性和質量
透過為社區健康工作者提供適合實際情況的醫療保健服務
知識和診斷工具。本文強調了變革性影響
這個情境意識的LLM，強調了它在解決問題中的關鍵作用
全球醫療保健勞動力短缺和推動醫療保健成果
在中低收入國家。

##### **Measuring proximity to standard planes during fetal brain ultrasound scanning**
2404.07124v1 by Chiara Di Vece,Antonio Cirigliano,Meala Le Lous,Raffaele Napolitano,Anna L. David,Donald Peebles,Pierre Jannin,Francisco Vasconcelos,Danail Stoyanov

This paper introduces a novel pipeline designed to bring ultrasound (US)
plane pose estimation closer to clinical use for more effective navigation to
the standard planes (SPs) in the fetal brain. We propose a semi-supervised
segmentation model utilizing both labeled SPs and unlabeled 3D US volume
slices. Our model enables reliable segmentation across a diverse set of fetal
brain images. Furthermore, the model incorporates a classification mechanism to
identify the fetal brain precisely. Our model not only filters out frames
lacking the brain but also generates masks for those containing it, enhancing
the relevance of plane pose regression in clinical settings. We focus on fetal
brain navigation from 2D ultrasound (US) video analysis and combine this model
with a US plane pose regression network to provide sensorless proximity
detection to SPs and non-SPs planes; we emphasize the importance of proximity
detection to SPs for guiding sonographers, offering a substantial advantage
over traditional methods by allowing earlier and more precise adjustments
during scanning. We demonstrate the practical applicability of our approach
through validation on real fetal scan videos obtained from sonographers of
varying expertise levels. Our findings demonstrate the potential of our
approach to complement existing fetal US technologies and advance prenatal
diagnostic practices.

摘要：本文介紹了一種新穎的管道，旨在將超音波（美國）
平面位姿估計更接近臨床使用，以便更有效地導航
胎兒大腦中的標準平面（SP）。我們提出一個半監督的
利用標記 SP 和未標記 3D US 體積的分割模型
切片。我們的模型能夠對不同的胎兒進行可靠的分割
大腦影像。此外，該模型還結合了分類機制
準確辨識胎兒大腦。我們的模型不僅過濾掉幀
缺乏大腦但也為那些含有大腦的人生成面具，增強
平面姿態迴歸在臨床環境中的相關性。我們專注於胎兒
透過 2D 超音波（美國）視訊分析進行大腦導航並結合該模型
與美國平面姿態回歸網路提供無感測器接近度
對 SP 和非 SP 平面的偵測；我們強調鄰近的重要性
對 SP 進行檢測以指導超音波檢查人員，提供了巨大的優勢
與傳統方法相比，允許更早、更精確的調整
掃描期間。我們展示了我們方法的實際適用性
透過對從超音波醫師那裡獲得的真實胎兒掃描影片進行驗證
不同的專業水平。我們的研究結果證明了我們的潛力
補充現有胎兒超音波技術並推進產前檢查的方法
診斷實踐。

##### **Advancing Real-time Pandemic Forecasting Using Large Language Models: A COVID-19 Case Study**
2404.06962v1 by Hongru Du,Jianan Zhao,Yang Zhao,Shaochong Xu,Xihong Lin,Yiran Chen,Lauren M. Gardner,Hao Frank Yang

Forecasting the short-term spread of an ongoing disease outbreak is a
formidable challenge due to the complexity of contributing factors, some of
which can be characterized through interlinked, multi-modality variables such
as epidemiological time series data, viral biology, population demographics,
and the intersection of public policy and human behavior. Existing forecasting
model frameworks struggle with the multifaceted nature of relevant data and
robust results translation, which hinders their performances and the provision
of actionable insights for public health decision-makers. Our work introduces
PandemicLLM, a novel framework with multi-modal Large Language Models (LLMs)
that reformulates real-time forecasting of disease spread as a text reasoning
problem, with the ability to incorporate real-time, complex, non-numerical
information that previously unattainable in traditional forecasting models.
This approach, through a unique AI-human cooperative prompt design and time
series representation learning, encodes multi-modal data for LLMs. The model is
applied to the COVID-19 pandemic, and trained to utilize textual public health
policies, genomic surveillance, spatial, and epidemiological time series data,
and is subsequently tested across all 50 states of the U.S. Empirically,
PandemicLLM is shown to be a high-performing pandemic forecasting framework
that effectively captures the impact of emerging variants and can provide
timely and accurate predictions. The proposed PandemicLLM opens avenues for
incorporating various pandemic-related data in heterogeneous formats and
exhibits performance benefits over existing models. This study illuminates the
potential of adapting LLMs and representation learning to enhance pandemic
forecasting, illustrating how AI innovations can strengthen pandemic responses
and crisis management in the future.

摘要：預測正在發生的疾病爆發的短期傳播是一個
由於影響因素的複雜性，一些
可以透過相互關聯的多模態變數來表徵，例如
如流行病學時間序列資料、病毒生物學、人口統計、
以及公共政策和人類行為的交叉點。現有預測
模型框架與相關數據的多方面性質作鬥爭，
強大的結果翻譯，這阻礙了他們的表現和規定
為公共衛生決策者提供可行的見解。我們的工作介紹
PandemicLLM，一種具有多模式大語言模型 (LLM) 的新穎框架
將疾病傳播的即時預測重新表述為文本推理
問題，能夠整合即時、複雜、非數位的
以前在傳統預測模型中無法獲得的資訊。
這種方法，透過獨特的AI-人類協作提示設計和時間
系列表示學習，為LLM編碼多模態資料。模型是
應用於 COVID-19 大流行，並接受過使用文本公共衛生的培訓
政策、基因組監測、空間和流行病學時間序列數據，
隨後在美國所有 50 個州進行了實證測試，
PandemicLLM 被證明是一個高效能的流行病預測框架
有效捕捉新興變體的影響，並可提供
及時準確的預測。擬議的 PandemicLLM 為
以異質格式整合各種流行病相關數據，
與現有型號相比表現出性能優勢。這項研究闡明了
調整LLM和代表性學習以增強流行病的潛力
預測，說明人工智慧創新如何加強流行病應對
以及未來的危機管理。

##### **SleepPPG-Net2: Deep learning generalization for sleep staging from photoplethysmography**
2404.06869v1 by Shirel Attia,Revital Shani Hershkovich,Alissa Tabakhov,Angeleene Ang,Sharon Haimov,Riva Tauman,Joachim A. Behar

Background: Sleep staging is a fundamental component in the diagnosis of
sleep disorders and the management of sleep health. Traditionally, this
analysis is conducted in clinical settings and involves a time-consuming
scoring procedure. Recent data-driven algorithms for sleep staging, using the
photoplethysmogram (PPG) time series, have shown high performance on local test
sets but lower performance on external datasets due to data drift. Methods:
This study aimed to develop a generalizable deep learning model for the task of
four class (wake, light, deep, and rapid eye movement (REM)) sleep staging from
raw PPG physiological time-series. Six sleep datasets, totaling 2,574 patients
recordings, were used. In order to create a more generalizable representation,
we developed and evaluated a deep learning model called SleepPPG-Net2, which
employs a multi-source domain training approach.SleepPPG-Net2 was benchmarked
against two state-of-the-art models. Results: SleepPPG-Net2 showed consistently
higher performance over benchmark approaches, with generalization performance
(Cohen's kappa) improving by up to 19%. Performance disparities were observed
in relation to age, sex, and sleep apnea severity. Conclusion: SleepPPG-Net2
sets a new standard for staging sleep from raw PPG time-series.

摘要：背景：睡眠分期是診斷的基本組成部分
睡眠障礙和睡眠健康管理。傳統上，這
分析是在臨床環境中進行的，涉及耗時的
評分程序。最近的數據驅動的睡眠分期演算法，使用
光電體積描記圖（PPG）時間序列，在本地測試中表現出高性能
集，但由於資料漂移，外部資料集的效能較低。方法：
本研究旨在發展一個可推廣的深度學習模型來完成以下任務：
四級（清醒、淺色、深度和快速動眼 (REM)）睡眠分期
原始 PPG 生理時間序列。六個睡眠資料集，總計 2,574 名患者
錄音，被使用。為了創建更通用的表示，
我們開發並評估了一個名為 SleepPPG-Net2 的深度學習模型，該模型
採用多源域訓練方法。
對抗兩種最先進的模型。結果：SleepPPG-Net2 顯示一致
比基準方法具有更高的性能，並具有泛化性能
（Cohen 的 kappa）提高高達 19%。觀察到績效差異
與年齡、性別和睡眠呼吸中止嚴重程度有關。結論：SleepPPG-Net2
為根據原始 PPG 時間序列劃分睡眠設定了新標準。

##### **Multi-Label Continual Learning for the Medical Domain: A Novel Benchmark**
2404.06859v2 by Marina Ceccon,Davide Dalle Pezze,Alessandro Fabris,Gian Antonio Susto

Multi-label image classification in dynamic environments is a problem that
poses significant challenges. Previous studies have primarily focused on
scenarios such as Domain Incremental Learning and Class Incremental Learning,
which do not fully capture the complexity of real-world applications. In this
paper, we study the problem of classification of medical imaging in the
scenario termed New Instances and New Classes, which combines the challenges of
both new class arrivals and domain shifts in a single framework. Unlike
traditional scenarios, it reflects the realistic nature of CL in domains such
as medical imaging, where updates may introduce both new classes and changes in
domain characteristics. To address the unique challenges posed by this complex
scenario, we introduce a novel approach called Pseudo-Label Replay. This method
aims to mitigate forgetting while adapting to new classes and domain shifts by
combining the advantages of the Replay and Pseudo-Label methods and solving
their limitations in the proposed scenario. We evaluate our proposed approach
on a challenging benchmark consisting of two datasets, seven tasks, and
nineteen classes, modeling a realistic Continual Learning scenario. Our
experimental findings demonstrate the effectiveness of Pseudo-Label Replay in
addressing the challenges posed by the complex scenario proposed. Our method
surpasses existing approaches, exhibiting superior performance while showing
minimal forgetting.

摘要：動態環境下的多標籤影像分類是一個問題
帶來重大挑戰。先前的研究主要集中在
領域增量學習、類別增量學習等場景，
它沒有完全捕捉現實世界應用程式的複雜性。在這個
論文中，我們研究了醫學影像的分類問題
稱為新實例和新類別的場景，它結合了以下挑戰
新班級的到來和領域的轉變都在一個框架中。不像
傳統場景，它反映了 CL 在以下領域的現實本質：
作為醫學成像，更新可能會引入新的類別和變化
域特徵。為了解決這個綜合體帶來的獨特挑戰
在場景中，我們引入了一種稱為偽標籤重播的新穎方法。這個方法
旨在減少遺忘，同時適應新的類別和領域的轉變
結合Replay和Pseudo-Label方法的優點並求解
他們在提議的場景中的局限性。我們評估我們提出的方法
在一個具有挑戰性的基準上，該基準由兩個資料集、七個任務和
十九個班級，模擬現實的持續學習場景。我們的
實驗結果證明了偽標籤重播的有效性
解決所提出的複雜場景所帶來的挑戰。我們的方法
超越現有方法，展現卓越性能，同時展現
最小的遺忘。

##### **Accuracy of a Large Language Model in Distinguishing Anti- And Pro-vaccination Messages on Social Media: The Case of Human Papillomavirus Vaccination**
2404.06731v1 by Soojong Kim,Kwanho Kim,Claire Wonjeong Jo

Objective. Vaccination has engendered a spectrum of public opinions, with
social media acting as a crucial platform for health-related discussions. The
emergence of artificial intelligence technologies, such as large language
models (LLMs), offers a novel opportunity to efficiently investigate public
discourses. This research assesses the accuracy of ChatGPT, a widely used and
freely available service built upon an LLM, for sentiment analysis to discern
different stances toward Human Papillomavirus (HPV) vaccination. Methods.
Messages related to HPV vaccination were collected from social media supporting
different message formats: Facebook (long format) and Twitter (short format). A
selection of 1,000 human-evaluated messages was input into the LLM, which
generated multiple response instances containing its classification results.
Accuracy was measured for each message as the level of concurrence between
human and machine decisions, ranging between 0 and 1. Results. Average accuracy
was notably high when 20 response instances were used to determine the machine
decision of each message: .882 (SE = .021) and .750 (SE = .029) for anti- and
pro-vaccination long-form; .773 (SE = .027) and .723 (SE = .029) for anti- and
pro-vaccination short-form, respectively. Using only three or even one instance
did not lead to a severe decrease in accuracy. However, for long-form messages,
the language model exhibited significantly lower accuracy in categorizing
pro-vaccination messages than anti-vaccination ones. Conclusions. ChatGPT shows
potential in analyzing public opinions on HPV vaccination using social media
content. However, understanding the characteristics and limitations of a
language model within specific public health contexts remains imperative.

摘要：客觀的。疫苗接種引發了一系列公眾輿論，其中
社群媒體是健康相關討論的重要平台。這
大語言等人工智慧技術的出現
模型（LLM），提供了有效調查公眾的新機會
話語。這項研究評估了 ChatGPT 的準確性，ChatGPT 是一種廣泛使用且
基於LLM的免費服務，用於情感分析以辨別
對人類乳突病毒（HPV）疫苗接種的不同立場。方法。
與 HPV 疫苗接種相關的資訊收集自社群媒體支持
不同的訊息格式：Facebook（長格式）和Twitter（短格式）。 A
選擇 1,000 個經過人工評估的訊息輸入到 LLM 中，其中
產生包含其分類結果的多個回應實例。
每個訊息的準確性是根據訊息之間的並發程度來衡量的
人類和機器的決策，範圍在 0 到 1 之間。平均準確度
當使用 20 個回應實例來確定機器時，該值非常高
每個訊息的決策： .882 (SE = .021) 和 .750 (SE = .029) 用於反和
支持疫苗接種的長格式； .773 (SE = .027) 和 .723 (SE = .029) 用於反和
分別是支持疫苗接種的縮寫。僅使用三個甚至一個實例
並沒有導致準確率的嚴重下降。然而，對於長消息，
語言模型的分類準確率明顯較低
支持疫苗接種的資訊多於反對疫苗接種的資訊。結論。 ChatGPT 顯示
使用社群媒體分析 HPV 疫苗接種的公眾意見的潛力
內容。然而，了解其特徵和局限性
特定公共衛生背景下的語言模式仍勢在必行。

##### **Federated learning model for predicting major postoperative complications**
2404.06641v1 by Yonggi Park,Yuanfang Ren,Benjamin Shickel,Ziyuan Guan,Ayush Patela,Yingbo Ma,Zhenhong Hu,Tyler J. Loftus,Parisa Rashidi,Tezcan Ozrazgat-Baslanti,Azra Bihorac

Background: The accurate prediction of postoperative complication risk using
Electronic Health Records (EHR) and artificial intelligence shows great
potential. Training a robust artificial intelligence model typically requires
large-scale and diverse datasets. In reality, collecting medical data often
encounters challenges surrounding privacy protection. Methods: This
retrospective cohort study includes adult patients who were admitted to UFH
Gainesville (GNV) (n = 79,850) and Jacksonville (JAX) (n = 28,636) for any type
of inpatient surgical procedure. Using perioperative and intraoperative
features, we developed federated learning models to predict nine major
postoperative complications (i.e., prolonged intensive care unit stay and
mechanical ventilation). We compared federated learning models with local
learning models trained on a single site and central learning models trained on
pooled dataset from two centers. Results: Our federated learning models
achieved the area under the receiver operating characteristics curve (AUROC)
values ranged from 0.81 for wound complications to 0.92 for prolonged ICU stay
at UFH GNV center. At UFH JAX center, these values ranged from 0.73-0.74 for
wound complications to 0.92-0.93 for hospital mortality. Federated learning
models achieved comparable AUROC performance to central learning models, except
for prolonged ICU stay, where the performance of federated learning models was
slightly higher than central learning models at UFH GNV center, but slightly
lower at UFH JAX center. In addition, our federated learning model obtained
comparable performance to the best local learning model at each center,
demonstrating strong generalizability. Conclusion: Federated learning is shown
to be a useful tool to train robust and generalizable models from large scale
data across multiple institutions where data protection barriers are high.

摘要：背景：利用模型準確預測術後併發症風險
電子健康記錄 (EHR) 和人工智慧表現出色
潛在的。訓練一個強大的人工智慧模型通常需要
大規模且多樣化的資料集。事實上，經常收集醫療數據
遇到隱私保護的挑戰。方法：這個
回顧性隊列研究包括入院和睦家醫院的成年患者
蓋恩斯維爾 (GNV) (n = 79,850) 和傑克遜維爾 (JAX) (n = 28,636) 對於任何類型
住院手術程序。圍手術期和術中使用
特徵，我們開發了聯邦學習模型來預測九個主要
術後併發症（即延長加護病房停留時間和
機械通氣）。我們將聯邦學習模式與本地學習模式進行了比較
在單一站點上訓練的學習模型和在
來自兩個中心的匯總資料集。結果：我們的聯邦學習模型
取得接受者操作特徵曲線下面積 (AUROC)
數值範圍從傷口併發症的 0.81 到延長 ICU 住院時間的 0.92
在 UFH GNV 中心。在 UFH JAX 中心，這些值的範圍為 0.73-0.74
傷口併發症的醫院死亡率為0.92-0.93。聯邦學習
模型實現了與中央學習模型相當的 AUROC 性能，除了
對於延長 ICU 住院時間，聯邦學習模型的表現
略高於和睦家 GNV 中心的中央學習模型，但略高
UFH JAX 中心較低。此外，我們的聯邦學習模式也獲得了
與每個中心的最佳本地學習模型的性能相當，
表現出強烈的普遍性。結論：聯邦學習如圖所示
成為訓練大規模穩健且可推廣模式的有用工具
資料保護壁壘較高的多個機構的資料。

##### **Test-Time Adaptation with SaLIP: A Cascade of SAM and CLIP for Zero shot Medical Image Segmentation**
2404.06362v1 by Sidra Aleem,Fangyijie Wang,Mayug Maniparambil,Eric Arazo,Julia Dietlmeier,Kathleen Curran,Noel E. O'Connor,Suzanne Little

The Segment Anything Model (SAM) and CLIP are remarkable vision foundation
models (VFMs). SAM, a prompt driven segmentation model, excels in segmentation
tasks across diverse domains, while CLIP is renowned for its zero shot
recognition capabilities. However, their unified potential has not yet been
explored in medical image segmentation. To adapt SAM to medical imaging,
existing methods primarily rely on tuning strategies that require extensive
data or prior prompts tailored to the specific task, making it particularly
challenging when only a limited number of data samples are available. This work
presents an in depth exploration of integrating SAM and CLIP into a unified
framework for medical image segmentation. Specifically, we propose a simple
unified framework, SaLIP, for organ segmentation. Initially, SAM is used for
part based segmentation within the image, followed by CLIP to retrieve the mask
corresponding to the region of interest (ROI) from the pool of SAM generated
masks. Finally, SAM is prompted by the retrieved ROI to segment a specific
organ. Thus, SaLIP is training and fine tuning free and does not rely on domain
expertise or labeled data for prompt engineering. Our method shows substantial
enhancements in zero shot segmentation, showcasing notable improvements in DICE
scores across diverse segmentation tasks like brain (63.46%), lung (50.11%),
and fetal head (30.82%), when compared to un prompted SAM. Code and text
prompts will be available online.

摘要：分段任意模型 (SAM) 和 CLIP 是卓越的視覺基礎
模型（VFM）。 SAM，一個提示驅動的分割模型，在分割方面表現出色
跨不同領域的任務，而 CLIP 以其零樣本而聞名
識別能力。然而，它們的統一潛力尚未發揮出來。
在醫學影像分割方面進行了探索。為了使 SAM 適應醫學影像，
現有的方法主要依賴需要大量的調整策略
針對特定任務量身定制的數據或先前提示，使其特別
當只有有限數量的數據樣本可用時，這具有挑戰性。這部作品
提出了將 SAM 和 CLIP 整合到統一的系統中的深入探索
醫學影像分割框架。具體來說，我們提出一個簡單的
用於器官分割的統一框架 SaLIP。最初，SAM 用於
影像內基於部分的分割，然後透過 CLIP 檢索掩模
對應於產生的 SAM 池中的興趣區域 (ROI)
面具。最後，SAM 根據檢索到的 ROI 來分割特定的
器官。因此，SaLIP 無需訓練和微調，且不依賴領域
用於快速工程的專業知識或標記資料。我們的方法顯示大量
零鏡頭分割的增強，展示了 DICE 的顯著改進
不同分割任務的得分，如大腦（63.46%）、肺（50.11%）、
與未提示的 SAM 相比，胎兒頭部 (30.82%)。程式碼和文字
提示將在線提供。

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi,Shadi Farabi Maleki,Ali Jafarizadeh,Mahya Ahmadpour Youshanlui,Aida Jafari,Siamak Pedrammehr,Roohallah Alizadehsani,Ryszard Tadeusiewicz,Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

摘要：甲狀腺癌是一個日益嚴重的全球健康問題，需要先進的技術
診斷方法。人工智慧和放射組學在甲狀腺癌的應用
本綜述對診斷進行了檢查。對多個資料庫的審查
到 2023 年 10 月為止，均依照 PRISMA 指南進行。
關鍵字組合發現了一份英文學術出版物
關於甲狀腺癌和相關主題。共收到 267 篇論文
刪除 109 個重複項後的原始搜尋。相關研究有
淘汰124篇文章後，依預定標準篩選
基於對其摘要和標題的檢查。綜合後
分析中，另外六項研究被排除。其中28個包括
研究、放射組學分析，其中結合了超音波（美國）影像，
證明了其在診斷甲狀腺癌方面的有效性。各種結果
有人指出，一些研究提出了優於現有策略的新策略
現狀。文獻強調了人工智慧面臨的各種挑戰
模型，包括可解釋性問題、資料集約束和運算符
依賴性。 28 篇納入研究的綜合結果提到
需要標準化工作和前瞻性多中心研究來解決
這些擔憂。此外，克服這些障礙的方法
確定的，例如可解釋的人工智慧技術和個人化的進步
醫學技術。該評論的重點是人工智慧和放射組學如何轉變
甲狀腺癌的診斷和治療。儘管面臨挑戰，但未來
多學科合作研究、臨床適用性驗證、
演算法的改進有可能改善患者的治療結果
甲狀腺癌治療中的診斷精確度。

##### **EPL: Evidential Prototype Learning for Semi-supervised Medical Image Segmentation**
2404.06181v1 by Yuanpeng He

Although current semi-supervised medical segmentation methods can achieve
decent performance, they are still affected by the uncertainty in unlabeled
data and model predictions, and there is currently a lack of effective
strategies that can explore the uncertain aspects of both simultaneously. To
address the aforementioned issues, we propose Evidential Prototype Learning
(EPL), which utilizes an extended probabilistic framework to effectively fuse
voxel probability predictions from different sources and achieves prototype
fusion utilization of labeled and unlabeled data under a generalized evidential
framework, leveraging voxel-level dual uncertainty masking. The uncertainty not
only enables the model to self-correct predictions but also improves the guided
learning process with pseudo-labels and is able to feed back into the
construction of hidden features. The method proposed in this paper has been
experimented on LA, Pancreas-CT and TBAD datasets, achieving the
state-of-the-art performance in three different labeled ratios, which strongly
demonstrates the effectiveness of our strategy.

摘要：雖然目前的半監督醫學分割方法可以實現
表現不錯，但他們仍然受到未標記的不確定性的影響
數據和模型預測，目前缺乏有效的
可以同時探索兩者不確定方面的策略。到
針對上述問題，我們提出證據原型學習
（EPL），它利用擴展的機率框架來有效地融合
來自不同來源的體素機率預測並實現原型
廣義證據下標記和未標記資料的融合利用
框架，利用體素級雙重不確定性掩蔽。不確定性不
不僅使模型能夠自我修正預測，而且還改進了引導
使用偽標籤進行學習過程，並且能夠回饋到
建構隱藏特徵。本文所提出的方法已
在 LA、Pancreas-CT 和 TBAD 資料集上進行了實驗，實現了
三種不同標記比例的最先進性能，這強烈
證明了我們策略的有效性。

##### **Uncertainty-aware Evidential Fusion-based Learning for Semi-supervised Medical Image Segmentation**
2404.06177v2 by Yuanpeng He,Lijian Li

Although the existing uncertainty-based semi-supervised medical segmentation
methods have achieved excellent performance, they usually only consider a
single uncertainty evaluation, which often fails to solve the problem related
to credibility completely. Therefore, based on the framework of evidential deep
learning, this paper integrates the evidential predictive results in the
cross-region of mixed and original samples to reallocate the confidence degree
and uncertainty measure of each voxel, which is realized by emphasizing
uncertain information of probability assignments fusion rule of traditional
evidence theory. Furthermore, we design a voxel-level asymptotic learning
strategy by introducing information entropy to combine with the fused
uncertainty measure to estimate voxel prediction more precisely. The model will
gradually pay attention to the prediction results with high uncertainty in the
learning process, to learn the features that are difficult to master. The
experimental results on LA, Pancreas-CT, ACDC and TBAD datasets demonstrate the
superior performance of our proposed method in comparison with the existing
state of the arts.

摘要：儘管現有的基於不確定性的半監督醫學分割
方法已經取得了優異的性能，他們通常只考慮
單一的不確定性評估往往無法解決相關問題
完全可信。因此，基於證據深層的框架
學習中，本文將證據預測結果整合到
混合樣本和原始樣本的跨區域重新分配置信度
以及每個體素的不確定性測量，這是透過強調來實現的
機率分配的不確定資訊 傳統的融合規則
證據理論。此外，我們設計了體素級漸近學習
透過引入資訊熵與融合的策略結合
更精確地估計體素預測的不確定性測量。該模型將
逐漸關注不確定性較高的預測結果
學習過程中，學習難以掌握的功能。這
LA、Pancreas-CT、ACDC 和 TBAD 資料集上的實驗結果表明
與現有方法相比，我們提出的方法具有優越的性能
藝術的狀態。

##### **Tackling Structural Hallucination in Image Translation with Local Diffusion**
2404.05980v3 by Seunghoi Kim,Chen Jin,Tom Diethe,Matteo Figini,Henry F. J. Tregidgo,Asher Mullokandov,Philip Teare,Daniel C. Alexander

Recent developments in diffusion models have advanced conditioned image
generation, yet they struggle with reconstructing out-of-distribution (OOD)
images, such as unseen tumors in medical images, causing "image hallucination"
and risking misdiagnosis. We hypothesize such hallucinations result from local
OOD regions in the conditional images. We verify that partitioning the OOD
region and conducting separate image generations alleviates hallucinations in
several applications. From this, we propose a training-free diffusion framework
that reduces hallucination with multiple Local Diffusion processes. Our
approach involves OOD estimation followed by two modules: a "branching" module
generates locally both within and outside OOD regions, and a "fusion" module
integrates these predictions into one. Our evaluation shows our method
mitigates hallucination over baseline models quantitatively and qualitatively,
reducing misdiagnosis by 40% and 25% in the real-world medical and natural
image datasets, respectively. It also demonstrates compatibility with various
pre-trained diffusion models.

摘要：擴散模型的最新發展促進了條件影像的發展
一代人，但他們仍在努力重建分佈外（OOD）
影像，例如醫學影像中看不見的腫瘤，引起“影像幻覺”
並冒著誤診的風險。我們假設這種幻覺是由當地的
條件影像中的 OOD 區域。我們驗證對 OOD 進行分區
區域並進行單獨的圖像生成減輕了幻覺
幾個應用程式。由此，我們提出了一個免訓練的擴散框架
透過多個局部擴散過程減少幻覺。我們的
方法涉及 OOD 估計，然後是兩個模組：「分支」模組
在 OOD 區域內外本地生成，以及「融合」模組
將這些預測整合為一。我們的評估展示了我們的方法
定量和定性地減輕對基線模型的幻覺，
現實醫學和自然領域的誤診率分別減少 40% 和 25%
影像資料集，分別。它還展示了與各種
預先訓練的擴散模型。

