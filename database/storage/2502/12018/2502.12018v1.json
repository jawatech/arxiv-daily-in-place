{"2502.12018": {"publish_time": "2025-02-17", "title": "Atom of Thoughts for Markov LLM Test-Time Scaling", "paper_summary": "Large Language Models (LLMs) achieve superior performance through\ntraining-time scaling, and test-time scaling further enhances their\ncapabilities by conducting effective reasoning during inference. However, as\nthe scale of reasoning increases, existing test-time scaling methods suffer\nfrom accumulated historical information, which not only wastes computational\nresources but also interferes with effective reasoning. To address this issue,\nwe observe that complex reasoning progress is often achieved by solving a\nsequence of independent subquestions, each being self-contained and verifiable.\nThese subquestions are essentially atomic questions, relying primarily on their\ncurrent state rather than accumulated history, similar to the memoryless\ntransitions in a Markov process. Based on this observation, we propose Atom of\nThoughts (AoT), where each state transition in the reasoning process consists\nof decomposing the current question into a dependency-based directed acyclic\ngraph and contracting its subquestions, forming a new atomic question state.\nThis iterative decomposition-contraction process continues until reaching\ndirectly solvable atomic questions, naturally realizing Markov transitions\nbetween question states. Furthermore, these atomic questions can be seamlessly\nintegrated into existing test-time scaling methods, enabling AoT to serve as a\nplug-in enhancement for improving reasoning capabilities. Experiments across\nsix benchmarks demonstrate the effectiveness of AoT both as a standalone\nframework and a plug-in enhancement. Notably, on HotpotQA, when applied to\ngpt-4o-mini, AoT achieves an 80.6% F1 score, surpassing o3-mini by 3.4% and\nDeepSeek-R1 by 10.6%. The code will be available at\nhttps://github.com/qixucen/atom.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u900f\u904e\u8a13\u7df4\u6642\u9593\u64f4\u5145\u4f86\u9054\u6210\u5353\u8d8a\u7684\u6548\u80fd\uff0c\u800c\u6e2c\u8a66\u6642\u9593\u64f4\u5145\u900f\u904e\u5728\u63a8\u8ad6\u671f\u9593\u9032\u884c\u6709\u6548\u7684\u63a8\u7406\uff0c\u9032\u4e00\u6b65\u63d0\u5347\u5176\u80fd\u529b\u3002\u7136\u800c\uff0c\u96a8\u8457\u63a8\u7406\u898f\u6a21\u7684\u64f4\u5927\uff0c\u73fe\u6709\u7684\u6e2c\u8a66\u6642\u9593\u64f4\u5145\u65b9\u6cd5\u6703\u53d7\u5230\u7d2f\u7a4d\u7684\u6b77\u53f2\u8cc7\u8a0a\u5f71\u97ff\uff0c\u9019\u4e0d\u50c5\u6703\u6d6a\u8cbb\u904b\u7b97\u8cc7\u6e90\uff0c\u9084\u6703\u5e72\u64fe\u6709\u6548\u7684\u63a8\u7406\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u89c0\u5bdf\u5230\u8907\u96dc\u7684\u63a8\u7406\u9032\u7a0b\u901a\u5e38\u662f\u900f\u904e\u89e3\u6c7a\u4e00\u7cfb\u5217\u7368\u7acb\u7684\u5b50\u554f\u984c\u4f86\u9054\u6210\uff0c\u6bcf\u500b\u5b50\u554f\u984c\u90fd\u662f\u7368\u7acb\u4e14\u53ef\u9a57\u8b49\u7684\u3002\u9019\u4e9b\u5b50\u554f\u984c\u672c\u8cea\u4e0a\u662f\u539f\u5b50\u554f\u984c\uff0c\u4e3b\u8981\u4f9d\u8cf4\u65bc\u5b83\u5011\u7684\u7576\u524d\u72c0\u614b\uff0c\u800c\u4e0d\u662f\u7d2f\u7a4d\u7684\u6b77\u53f2\uff0c\u985e\u4f3c\u65bc\u99ac\u53ef\u592b\u904e\u7a0b\u4e2d\u7684\u7121\u8a18\u61b6\u8f49\u63db\u3002\u57fa\u65bc\u9019\u500b\u89c0\u5bdf\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u601d\u60f3\u539f\u5b50 (AoT)\uff0c\u5176\u4e2d\u63a8\u7406\u904e\u7a0b\u4e2d\u6bcf\u500b\u72c0\u614b\u8f49\u63db\u90fd\u5305\u542b\u5c07\u7576\u524d\u554f\u984c\u5206\u89e3\u70ba\u57fa\u65bc\u4f9d\u8cf4\u95dc\u4fc2\u7684\u6709\u5411\u7121\u74b0\u5716\uff0c\u4e26\u6536\u7e2e\u5176\u5b50\u554f\u984c\uff0c\u5f62\u6210\u65b0\u7684\u539f\u5b50\u554f\u984c\u72c0\u614b\u3002\u9019\u500b\u53cd\u8986\u7684\u5206\u89e3\u6536\u7e2e\u904e\u7a0b\u6703\u6301\u7e8c\u9032\u884c\uff0c\u76f4\u5230\u9054\u5230\u53ef\u76f4\u63a5\u89e3\u6c7a\u7684\u539f\u5b50\u554f\u984c\uff0c\u81ea\u7136\u5730\u5be6\u73fe\u554f\u984c\u72c0\u614b\u4e4b\u9593\u7684\u99ac\u53ef\u592b\u8f49\u63db\u3002\u6b64\u5916\uff0c\u9019\u4e9b\u539f\u5b50\u554f\u984c\u53ef\u4ee5\u7121\u7e2b\u6574\u5408\u5230\u73fe\u6709\u7684\u6e2c\u8a66\u6642\u9593\u64f4\u5145\u65b9\u6cd5\u4e2d\uff0c\u8b93 AoT \u53ef\u4ee5\u4f5c\u70ba\u5916\u639b\u7a0b\u5f0f\u5f37\u5316\u529f\u80fd\uff0c\u4ee5\u6539\u5584\u63a8\u7406\u80fd\u529b\u3002\u6a6b\u8de8\u516d\u500b\u57fa\u6e96\u7684\u5be6\u9a57\u8b49\u660e\u4e86 AoT \u4f5c\u70ba\u7368\u7acb\u67b6\u69cb\u548c\u5916\u639b\u7a0b\u5f0f\u5f37\u5316\u7684\u6709\u6548\u6027\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5728 HotpotQA \u4e0a\uff0c\u7576\u61c9\u7528\u65bc gpt-4o-mini \u6642\uff0cAoT \u9054\u5230\u4e86 80.6% \u7684 F1 \u5206\u6578\uff0c\u6bd4 o3-mini \u9ad8\u51fa 3.4%\uff0c\u6bd4 DeepSeek-R1 \u9ad8\u51fa 10.6%\u3002\u7a0b\u5f0f\u78bc\u5c07\u5728 https://github.com/qixucen/atom \u4e0a\u63d0\u4f9b\u3002", "author": "Fengwei Teng et.al.", "authors": "Fengwei Teng, Zhaoyang Yu, Quan Shi, Jiayi Zhang, Chenglin Wu, Yuyu Luo", "id": "2502.12018v1", "paper_url": "http://arxiv.org/abs/2502.12018v1", "repo": "null"}}