{"2409.12186": {"publish_time": "2024-09-18", "title": "Qwen2.5-Coder Technical Report", "paper_summary": "In this report, we introduce the Qwen2.5-Coder series, a significant upgrade\nfrom its predecessor, CodeQwen1.5. This series includes two models:\nQwen2.5-Coder-1.5B and Qwen2.5-Coder-7B. As a code-specific model,\nQwen2.5-Coder is built upon the Qwen2.5 architecture and continues pretrained\non a vast corpus of over 5.5 trillion tokens. Through meticulous data cleaning,\nscalable synthetic data generation, and balanced data mixing, Qwen2.5-Coder\ndemonstrates impressive code generation capabilities while retaining general\nversatility. The model has been evaluated on a wide range of code-related\ntasks, achieving state-of-the-art (SOTA) performance across more than 10\nbenchmarks, including code generation, completion, reasoning, and repair,\nconsistently outperforming larger models of the same model size. We believe\nthat the release of the Qwen2.5-Coder series will not only push the boundaries\nof research in code intelligence but also, through its permissive licensing,\nencourage broader adoption by developers in real-world applications.", "paper_summary_zh": "\u5728\u672c\u6b21\u5831\u544a\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39 Qwen2.5-Coder \u7cfb\u5217\uff0c\u9019\u662f\u5176\u524d\u8eab CodeQwen1.5 \u7684\u91cd\u5927\u5347\u7d1a\u3002\u6b64\u7cfb\u5217\u5305\u542b\u5169\u500b\u6a21\u578b\uff1aQwen2.5-Coder-1.5B \u548c Qwen2.5-Coder-7B\u3002\u4f5c\u70ba\u4e00\u500b\u7279\u5b9a\u65bc\u7a0b\u5f0f\u78bc\u7684\u6a21\u578b\uff0cQwen2.5-Coder \u5efa\u69cb\u65bc Qwen2.5 \u67b6\u69cb\u4e4b\u4e0a\uff0c\u4e26\u6301\u7e8c\u5728\u8d85\u904e 5.5 \u5146\u500b token \u7684\u9f90\u5927\u8a9e\u6599\u5eab\u4e0a\u9032\u884c\u9810\u8a13\u7df4\u3002\u900f\u904e\u7d30\u5fc3\u7684\u8cc7\u6599\u6e05\u7406\u3001\u53ef\u64f4\u5145\u7684\u5408\u6210\u8cc7\u6599\u7522\u751f\uff0c\u4ee5\u53ca\u5e73\u8861\u7684\u8cc7\u6599\u6df7\u5408\uff0cQwen2.5-Coder \u5c55\u73fe\u4e86\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u7a0b\u5f0f\u78bc\u7522\u751f\u80fd\u529b\uff0c\u540c\u6642\u4fdd\u7559\u4e86\u901a\u7528\u7684\u591a\u529f\u80fd\u6027\u3002\u6b64\u6a21\u578b\u5df2\u5728\u5ee3\u6cdb\u7684\u7a0b\u5f0f\u78bc\u76f8\u95dc\u4efb\u52d9\u4e2d\u9032\u884c\u8a55\u4f30\uff0c\u5728\u8d85\u904e 10 \u500b\u57fa\u6e96\u6e2c\u8a66\u4e2d\uff08\u5305\u62ec\u7a0b\u5f0f\u78bc\u7522\u751f\u3001\u5b8c\u6210\u3001\u63a8\u7406\u548c\u4fee\u5fa9\uff09\u9054\u5230\u6700\u5148\u9032 (SOTA) \u7684\u6548\u80fd\uff0c\u6301\u7e8c\u512a\u65bc\u540c\u7b49\u6a21\u578b\u5927\u5c0f\u7684\u8f03\u5927\u578b\u6a21\u578b\u3002\u6211\u5011\u76f8\u4fe1\uff0cQwen2.5-Coder \u7cfb\u5217\u7684\u91cb\u51fa\u4e0d\u50c5\u6703\u63a8\u52d5\u7a0b\u5f0f\u78bc\u667a\u80fd\u7814\u7a76\u7684\u754c\u9650\uff0c\u800c\u4e14\u900f\u904e\u5176\u5bec\u9b06\u7684\u6388\u6b0a\uff0c\u4e5f\u6703\u9f13\u52f5\u958b\u767c\u4eba\u54e1\u5728\u5be6\u969b\u61c9\u7528\u4e2d\u66f4\u5ee3\u6cdb\u5730\u63a1\u7528\u3002", "author": "Binyuan Hui et.al.", "authors": "Binyuan Hui, Jian Yang, Zeyu Cui, Jiaxi Yang, Dayiheng Liu, Lei Zhang, Tianyu Liu, Jiajun Zhang, Bowen Yu, Kai Dang, An Yang, Rui Men, Fei Huang, Xingzhang Ren, Xuancheng Ren, Jingren Zhou, Junyang Lin", "id": "2409.12186v1", "paper_url": "http://arxiv.org/abs/2409.12186v1", "repo": "null"}}