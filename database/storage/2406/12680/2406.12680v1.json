{"2406.12680": {"publish_time": "2024-06-18", "title": "Measuring Psychological Depth in Language Models", "paper_summary": "Evaluations of creative stories generated by large language models (LLMs)\noften focus on objective properties of the text, such as its style, coherence,\nand toxicity. While these metrics are indispensable, they do not speak to a\nstory's subjective, psychological impact from a reader's perspective. We\nintroduce the Psychological Depth Scale (PDS), a novel framework rooted in\nliterary theory that measures an LLM's ability to produce authentic and\nnarratively complex stories that provoke emotion, empathy, and engagement. We\nempirically validate our framework by showing that humans can consistently\nevaluate stories based on PDS (0.72 Krippendorff's alpha). We also explore\ntechniques for automating the PDS to easily scale future analyses. GPT-4o,\ncombined with a novel Mixture-of-Personas (MoP) prompting strategy, achieves an\naverage Spearman correlation of $0.51$ with human judgment while Llama-3-70B\nscores as high as 0.68 for empathy. Finally, we compared the depth of stories\nauthored by both humans and LLMs. Surprisingly, GPT-4 stories either surpassed\nor were statistically indistinguishable from highly-rated human-written stories\nsourced from Reddit. By shifting the focus from text to reader, the\nPsychological Depth Scale is a validated, automated, and systematic means of\nmeasuring the capacity of LLMs to connect with humans through the stories they\ntell.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6240\u7522\u751f\u7684\u5275\u610f\u6545\u4e8b\u8a55\u91cf\uff0c\u901a\u5e38\u6703\u5c08\u6ce8\u65bc\u6587\u672c\u7684\u5ba2\u89c0\u5c6c\u6027\uff0c\u4f8b\u5982\u5176\u98a8\u683c\u3001\u9023\u8cab\u6027\u548c\u6bd2\u6027\u3002\u96d6\u7136\u9019\u4e9b\u6307\u6a19\u4e0d\u53ef\u6216\u7f3a\uff0c\u4f46\u5b83\u5011\u4e26\u672a\u8aaa\u660e\u5f9e\u8b80\u8005\u7684\u89d2\u5ea6\u4f86\u770b\uff0c\u6545\u4e8b\u7684\u4e3b\u89c0\u5fc3\u7406\u5f71\u97ff\u3002\u6211\u5011\u5f15\u5165\u4e86\u5fc3\u7406\u6df1\u5ea6\u91cf\u8868 (PDS)\uff0c\u9019\u662f\u4e00\u500b\u690d\u57fa\u65bc\u6587\u5b78\u7406\u8ad6\u7684\u65b0\u7a4e\u67b6\u69cb\uff0c\u7528\u65bc\u8861\u91cf LLM \u7522\u751f\u771f\u5be6\u4e14\u6558\u4e8b\u8907\u96dc\u7684\u6545\u4e8b\u7684\u80fd\u529b\uff0c\u9019\u4e9b\u6545\u4e8b\u80fd\u5f15\u8d77\u60c5\u7dd2\u3001\u540c\u7406\u5fc3\u548c\u6295\u5165\u611f\u3002\u6211\u5011\u900f\u904e\u5c55\u793a\u4eba\u985e\u80fd\u6839\u64da PDS \u6301\u7e8c\u8a55\u4f30\u6545\u4e8b\uff08Krippendorff's alpha \u70ba 0.72\uff09\u4f86\u9a57\u8b49\u6211\u5011\u7684\u67b6\u69cb\u3002\u6211\u5011\u4e5f\u63a2\u8a0e\u81ea\u52d5\u5316 PDS \u7684\u6280\u8853\uff0c\u4ee5\u4fbf\u8f15\u9b06\u64f4\u5145\u672a\u4f86\u7684\u5206\u6790\u3002GPT-4o \u7d50\u5408\u65b0\u7a4e\u7684\u6df7\u5408\u89d2\u8272 (MoP) \u63d0\u793a\u7b56\u7565\uff0c\u5728\u4eba\u985e\u5224\u65b7\u4e2d\u9054\u5230\u5e73\u5747 0.51 \u7684 Spearman \u76f8\u95dc\u6027\uff0c\u800c Llama-3-70B \u7684\u540c\u7406\u5fc3\u5206\u6578\u9ad8\u9054 0.68\u3002\u6700\u5f8c\uff0c\u6211\u5011\u6bd4\u8f03\u4e86\u4eba\u985e\u548c LLM \u5275\u4f5c\u7684\u6545\u4e8b\u6df1\u5ea6\u3002\u4ee4\u4eba\u9a5a\u8a1d\u7684\u662f\uff0cGPT-4 \u7684\u6545\u4e8b\u8d85\u8d8a\u6216\u5728\u7d71\u8a08\u4e0a\u8207\u53d6\u81ea Reddit \u7684\u9ad8\u8a55\u5206\u4eba\u985e\u64b0\u5beb\u6545\u4e8b\u7121\u7570\u3002\u900f\u904e\u5c07\u7126\u9ede\u5f9e\u6587\u672c\u8f49\u79fb\u5230\u8b80\u8005\uff0c\u5fc3\u7406\u6df1\u5ea6\u91cf\u8868\u662f\u4e00\u7a2e\u7d93\u904e\u9a57\u8b49\u3001\u81ea\u52d5\u5316\u4e14\u7cfb\u7d71\u5316\u7684\u65b9\u5f0f\uff0c\u7528\u65bc\u8861\u91cf LLM \u900f\u904e\u4ed6\u5011\u6240\u8ff0\u6545\u4e8b\u8207\u4eba\u985e\u5efa\u7acb\u806f\u7e6b\u7684\u80fd\u529b\u3002", "author": "Fabrice Harel-Canada et.al.", "authors": "Fabrice Harel-Canada, Hanyu Zhou, Sreya Mupalla, Zeynep Yildiz, Amit Sahai, Nanyun Peng", "id": "2406.12680v1", "paper_url": "http://arxiv.org/abs/2406.12680v1", "repo": "null"}}