{"2405.07932": {"publish_time": "2024-05-13", "title": "PARDEN, Can You Repeat That? Defending against Jailbreaks via Repetition", "paper_summary": "Large language models (LLMs) have shown success in many natural language\nprocessing tasks. Despite rigorous safety alignment processes, supposedly\nsafety-aligned LLMs like Llama 2 and Claude 2 are still susceptible to\njailbreaks, leading to security risks and abuse of the models. One option to\nmitigate such risks is to augment the LLM with a dedicated \"safeguard\", which\nchecks the LLM's inputs or outputs for undesired behaviour. A promising\napproach is to use the LLM itself as the safeguard. Nonetheless, baseline\nmethods, such as prompting the LLM to self-classify toxic content, demonstrate\nlimited efficacy. We hypothesise that this is due to domain shift: the\nalignment training imparts a self-censoring behaviour to the model (\"Sorry I\ncan't do that\"), while the self-classify approach shifts it to a classification\nformat (\"Is this prompt malicious\"). In this work, we propose PARDEN, which\navoids this domain shift by simply asking the model to repeat its own outputs.\nPARDEN neither requires finetuning nor white box access to the model. We\nempirically verify the effectiveness of our method and show that PARDEN\nsignificantly outperforms existing jailbreak detection baselines for Llama-2\nand Claude-2. Code and data are available at https://github.com/Ed-Zh/PARDEN.\n  We find that PARDEN is particularly powerful in the relevant regime of high\nTrue Positive Rate (TPR) and low False Positive Rate (FPR). For instance, for\nLlama2-7B, at TPR equal to 90%, PARDEN accomplishes a roughly 11x reduction in\nthe FPR from 24.8% to 2.0% on the harmful behaviours dataset.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5728\u8a31\u591a\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4efb\u52d9\u4e2d\u5c55\u73fe\u6210\u529f\u3002\u5118\u7ba1\u9032\u884c\u56b4\u683c\u7684\u5b89\u5168\u8abf\u6574\u7a0b\u5e8f\uff0c\u4f46\u7406\u8ad6\u4e0a\u7d93\u904e\u5b89\u5168\u8abf\u6574\u7684 LLM\uff08\u4f8b\u5982 Llama 2 \u548c Claude 2\uff09\u4ecd\u5bb9\u6613\u53d7\u5230\u8d8a\u7344\u653b\u64ca\uff0c\u5c0e\u81f4\u5b89\u5168\u98a8\u96aa\u548c\u6a21\u578b\u906d\u5230\u6feb\u7528\u3002\u6e1b\u8f15\u6b64\u985e\u98a8\u96aa\u7684\u4e00\u500b\u9078\u9805\u662f\u4f7f\u7528\u5c08\u7528\u7684\u300c\u9632\u8b77\u63aa\u65bd\u300d\u64f4\u5145 LLM\uff0c\u7528\u65bc\u6aa2\u67e5 LLM \u7684\u8f38\u5165\u6216\u8f38\u51fa\u662f\u5426\u6709\u4e0d\u826f\u884c\u70ba\u3002\u4e00\u7a2e\u6709\u524d\u666f\u7684\u65b9\u6cd5\u662f\u4f7f\u7528 LLM \u672c\u8eab\u4f5c\u70ba\u9632\u8b77\u63aa\u65bd\u3002\u5118\u7ba1\u5982\u6b64\uff0c\u57fa\u7dda\u65b9\u6cd5\uff08\u4f8b\u5982\u63d0\u793a LLM \u81ea\u6211\u5206\u985e\u6709\u6bd2\u5167\u5bb9\uff09\u986f\u793a\u51fa\u6709\u9650\u7684\u529f\u6548\u3002\u6211\u5011\u5047\u8a2d\u9019\u662f\u7531\u65bc\u9818\u57df\u8f49\u79fb\uff1a\u8abf\u6574\u8a13\u7df4\u6703\u8b93\u6a21\u578b\u7522\u751f\u81ea\u6211\u5be9\u67e5\u884c\u70ba\uff08\u300c\u62b1\u6b49\uff0c\u6211\u7121\u6cd5\u9019\u9ebc\u505a\u300d\uff09\uff0c\u800c\u81ea\u6211\u5206\u985e\u65b9\u6cd5\u6703\u5c07\u5176\u8f49\u79fb\u5230\u5206\u985e\u683c\u5f0f\uff08\u300c\u9019\u500b\u63d0\u793a\u662f\u5426\u60e1\u610f\u300d\uff09\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa PARDEN\uff0c\u5b83\u900f\u904e\u7c21\u55ae\u5730\u8981\u6c42\u6a21\u578b\u91cd\u8907\u5176\u81ea\u5df1\u7684\u8f38\u51fa\uff0c\u4f86\u907f\u514d\u9019\u7a2e\u9818\u57df\u8f49\u79fb\u3002PARDEN \u4e0d\u9700\u8981\u5fae\u8abf\u6216\u5c0d\u6a21\u578b\u9032\u884c\u767d\u76d2\u5b58\u53d6\u3002\u6211\u5011\u900f\u904e\u5be6\u8b49\u9a57\u8b49\u6211\u5011\u7684\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4e26\u986f\u793a PARDEN \u5728 Llama-2 \u548c Claude-2 \u7684\u73fe\u6709\u8d8a\u7344\u5075\u6e2c\u57fa\u7dda\u4e0a\u986f\u8457\u512a\u65bc\u5176\u4ed6\u65b9\u6cd5\u3002\u7a0b\u5f0f\u78bc\u548c\u8cc7\u6599\u53ef\u5728 https://github.com/Ed-Zh/PARDEN \u53d6\u5f97\u3002\u6211\u5011\u767c\u73fe PARDEN \u5728\u9ad8\u771f\u5be6\u6b63\u985e\u7387 (TPR) \u548c\u4f4e\u865b\u5047\u6b63\u985e\u7387 (FPR) \u7684\u76f8\u95dc\u7bc4\u570d\u4e2d\u7279\u5225\u6709\u6548\u3002\u4f8b\u5982\uff0c\u5c0d\u65bc Llama2-7B\uff0c\u5728 TPR \u7b49\u65bc 90% \u6642\uff0cPARDEN \u5728\u6709\u5bb3\u884c\u70ba\u8cc7\u6599\u96c6\u4e0a\u5c07 FPR \u5f9e 24.8% \u964d\u4f4e\u5230 2.0%\uff0c\u6e1b\u5c11\u4e86\u5927\u7d04 11 \u500d\u3002", "author": "Ziyang Zhang et.al.", "authors": "Ziyang Zhang, Qizhen Zhang, Jakob Foerster", "id": "2405.07932v2", "paper_url": "http://arxiv.org/abs/2405.07932v2", "repo": "https://github.com/ed-zh/parden"}}