{"2407.08995": {"publish_time": "2024-07-12", "title": "Self-Prompt Tuning: Enable Autonomous Role-Playing in LLMs", "paper_summary": "Recent advancements in LLMs have showcased their remarkable role-playing\ncapabilities, able to accurately simulate the dialogue styles and cognitive\nprocesses of various roles based on different instructions and contexts.\nStudies indicate that assigning LLMs the roles of experts, a strategy known as\nrole-play prompting, can enhance their performance in the corresponding\ndomains. However, the prompt needs to be manually designed for the given\nproblem, requiring certain expertise and iterative modifications. To this end,\nwe propose self-prompt tuning, making LLMs themselves generate role-play\nprompts through fine-tuning. Leveraging the LIMA dataset as our foundational\ncorpus, we employ GPT-4 to annotate role-play prompts for each data points,\nresulting in the creation of the LIMA-Role dataset. We then fine-tune LLMs like\nLlama-2-7B and Mistral-7B on LIMA-Role. Consequently, the self-prompt tuned\nLLMs can automatically generate expert role prompts for any given question. We\nextensively evaluate self-prompt tuned LLMs on widely used NLP benchmarks and\nopen-ended question test. Our empirical results illustrate that self-prompt\ntuned LLMs outperform standard instruction tuned baselines across most\ndatasets. This highlights the great potential of utilizing fine-tuning to\nenable LLMs to self-prompt, thereby automating complex prompting strategies. We\nrelease the dataset, models, and code at this\n\\href{https://anonymous.4open.science/r/Self-Prompt-Tuning-739E/}{url}.", "paper_summary_zh": "\u6700\u8fd1\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u4e0a\u7684\u8fdb\u6b65\u5c55\u793a\u4e86\u5176\u5353\u8d8a\u7684\u89d2\u8272\u626e\u6f14\u80fd\u529b\uff0c\u80fd\u591f\u6839\u636e\u4e0d\u540c\u7684\u6307\u4ee4\u548c\u8bed\u5883\u51c6\u786e\u6a21\u62df\u5404\u79cd\u89d2\u8272\u7684\u5bf9\u8bdd\u98ce\u683c\u548c\u8ba4\u77e5\u8fc7\u7a0b\u3002\u7814\u7a76\u8868\u660e\uff0c\u5c06\u4e13\u5bb6\u89d2\u8272\u5206\u914d\u7ed9 LLM\uff08\u4e00\u79cd\u79f0\u4e3a\u89d2\u8272\u626e\u6f14\u63d0\u793a\u7684\u7b56\u7565\uff09\u53ef\u4ee5\u63d0\u9ad8\u5176\u5728\u76f8\u5e94\u9886\u57df\u7684\u6027\u80fd\u3002\u7136\u800c\uff0c\u63d0\u793a\u9700\u8981\u9488\u5bf9\u7ed9\u5b9a\u7684\u95ee\u9898\u624b\u52a8\u8bbe\u8ba1\uff0c\u9700\u8981\u4e00\u5b9a\u7684\u4e13\u4e1a\u77e5\u8bc6\u548c\u8fed\u4ee3\u4fee\u6539\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u81ea\u63d0\u793a\u8c03\u6574\uff0c\u4f7f LLM \u672c\u8eab\u901a\u8fc7\u5fae\u8c03\u751f\u6210\u89d2\u8272\u626e\u6f14\u63d0\u793a\u3002\u5229\u7528 LIMA \u6570\u636e\u96c6\u4f5c\u4e3a\u6211\u4eec\u7684\u57fa\u7840\u8bed\u6599\u5e93\uff0c\u6211\u4eec\u4f7f\u7528 GPT-4 \u4e3a\u6bcf\u4e2a\u6570\u636e\u70b9\u6ce8\u91ca\u89d2\u8272\u626e\u6f14\u63d0\u793a\uff0c\u4ece\u800c\u521b\u5efa\u4e86 LIMA-Role \u6570\u636e\u96c6\u3002\u7136\u540e\uff0c\u6211\u4eec\u5728 LIMA-Role \u4e0a\u5bf9 Llama-2-7B \u548c Mistral-7B \u7b49 LLM \u8fdb\u884c\u5fae\u8c03\u3002\u56e0\u6b64\uff0c\u81ea\u63d0\u793a\u8c03\u6574\u7684 LLM \u53ef\u4ee5\u9488\u5bf9\u4efb\u4f55\u7ed9\u5b9a\u95ee\u9898\u81ea\u52a8\u751f\u6210\u4e13\u5bb6\u89d2\u8272\u63d0\u793a\u3002\u6211\u4eec\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684 NLP \u57fa\u51c6\u548c\u5f00\u653e\u5f0f\u95ee\u9898\u6d4b\u8bd5\u4e2d\u5bf9\u81ea\u63d0\u793a\u8c03\u6574\u7684 LLM \u8fdb\u884c\u4e86\u5e7f\u6cdb\u8bc4\u4f30\u3002\u6211\u4eec\u7684\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u81ea\u63d0\u793a\u8c03\u6574\u7684 LLM \u5728\u5927\u591a\u6570\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u6807\u51c6\u6307\u4ee4\u8c03\u6574\u7684\u57fa\u7ebf\u3002\u8fd9\u51f8\u663e\u4e86\u5229\u7528\u5fae\u8c03\u4f7f LLM \u81ea\u63d0\u793a\u7684\u5de8\u5927\u6f5c\u529b\uff0c\u4ece\u800c\u81ea\u52a8\u5316\u590d\u6742\u7684\u63d0\u793a\u7b56\u7565\u3002\u6211\u4eec\u5728\u6b64\u53d1\u5e03\u6570\u636e\u96c6\u3001\u6a21\u578b\u548c\u4ee3\u7801\uff1a\\href{https://anonymous.4open.science/r/Self-Prompt-Tuning-739E/}{url}\u3002", "author": "Aobo Kong et.al.", "authors": "Aobo Kong, Shiwan Zhao, Hao Chen, Qicheng Li, Yong Qin, Ruiqi Sun, Xin Zhou, Jiaming Zhou, Haoqin Sun", "id": "2407.08995v1", "paper_url": "http://arxiv.org/abs/2407.08995v1", "repo": "null"}}