{"2410.23180": {"publish_time": "2024-10-30", "title": "ReasoningRec: Bridging Personalized Recommendations and Human-Interpretable Explanations through LLM Reasoning", "paper_summary": "This paper presents ReasoningRec, a reasoning-based recommendation framework\nthat leverages Large Language Models (LLMs) to bridge the gap between\nrecommendations and human-interpretable explanations. In contrast to\nconventional recommendation systems that rely on implicit user-item\ninteractions, ReasoningRec employs LLMs to model users and items, focusing on\npreferences, aversions, and explanatory reasoning. The framework utilizes a\nlarger LLM to generate synthetic explanations for user preferences,\nsubsequently used to fine-tune a smaller LLM for enhanced recommendation\naccuracy and human-interpretable explanation. Our experimental study\ninvestigates the impact of reasoning and contextual information on personalized\nrecommendations, revealing that the quality of contextual and personalized data\nsignificantly influences the LLM's capacity to generate plausible explanations.\nEmpirical evaluations demonstrate that ReasoningRec surpasses state-of-the-art\nmethods by up to 12.5\\% in recommendation prediction while concurrently\nproviding human-intelligible explanations. The code is available here:\nhttps://github.com/millenniumbismay/reasoningrec.", "paper_summary_zh": "\u672c\u6587\u63d0\u51fa\u4e86 ReasoningRec\uff0c\u9019\u662f\u4e00\u500b\u57fa\u65bc\u63a8\u7406\u7684\u63a8\u85a6\u67b6\u69cb\uff0c\u5b83\u5229\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4f86\u5f4c\u5408\u5efa\u8b70\u548c\u4eba\u985e\u53ef\u89e3\u91cb\u7684\u8aaa\u660e\u4e4b\u9593\u7684\u5dee\u8ddd\u3002\u8207\u4f9d\u8cf4\u65bc\u96b1\u5f0f\u4f7f\u7528\u8005\u9805\u76ee\u4e92\u52d5\u7684\u50b3\u7d71\u63a8\u85a6\u7cfb\u7d71\u76f8\u53cd\uff0cReasoningRec \u4f7f\u7528 LLM \u5c0d\u4f7f\u7528\u8005\u548c\u9805\u76ee\u9032\u884c\u5efa\u6a21\uff0c\u8457\u91cd\u65bc\u504f\u597d\u3001\u53ad\u60e1\u548c\u8aaa\u660e\u6027\u63a8\u7406\u3002\u8a72\u67b6\u69cb\u5229\u7528\u4e00\u500b\u8f03\u5927\u7684 LLM \u70ba\u4f7f\u7528\u8005\u7684\u504f\u597d\u751f\u6210\u7d9c\u5408\u8aaa\u660e\uff0c\u7136\u5f8c\u7528\u65bc\u5fae\u8abf\u4e00\u500b\u8f03\u5c0f\u7684 LLM\uff0c\u4ee5\u589e\u5f37\u63a8\u85a6\u6e96\u78ba\u6027\u548c\u4eba\u985e\u53ef\u89e3\u91cb\u7684\u8aaa\u660e\u3002\u6211\u5011\u7684\u5be6\u9a57\u7814\u7a76\u63a2\u8a0e\u4e86\u63a8\u7406\u548c\u80cc\u666f\u8cc7\u8a0a\u5c0d\u500b\u4eba\u5316\u63a8\u85a6\u7684\u5f71\u97ff\uff0c\u63ed\u793a\u4e86\u80cc\u666f\u548c\u500b\u4eba\u5316\u8cc7\u6599\u7684\u54c1\u8cea\u6703\u986f\u8457\u5f71\u97ff LLM \u751f\u6210\u5408\u7406\u8aaa\u660e\u7684\u80fd\u529b\u3002\u7d93\u9a57\u8a55\u4f30\u8868\u660e\uff0cReasoningRec \u5728\u63a8\u85a6\u9810\u6e2c\u65b9\u9762\u8d85\u8d8a\u4e86\u6700\u5148\u9032\u7684\u65b9\u6cd5\uff0c\u9ad8\u9054 12.5%\uff0c\u540c\u6642\u63d0\u4f9b\u4e86\u4eba\u985e\u53ef\u4ee5\u7406\u89e3\u7684\u8aaa\u660e\u3002\u7a0b\u5f0f\u78bc\u5728\u6b64\u8655\u63d0\u4f9b\uff1ahttps://github.com/millenniumbismay/reasoningrec\u3002", "author": "Millennium Bismay et.al.", "authors": "Millennium Bismay, Xiangjue Dong, James Caverlee", "id": "2410.23180v1", "paper_url": "http://arxiv.org/abs/2410.23180v1", "repo": "https://github.com/millenniumbismay/reasoningrec"}}