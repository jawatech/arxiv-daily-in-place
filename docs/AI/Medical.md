
### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-10**|**The Human Factor in AI Red Teaming: Perspectives from Social and Collaborative Computing**|Alice Qian Zhang et.al.|[2407.07786v1](http://arxiv.org/abs/2407.07786v1)|null|
|**2024-07-10**|**A Proposed S.C.O.R.E. Evaluation Framework for Large Language Models : Safety, Consensus, Objectivity, Reproducibility and Explainability**|Ting Fang Tan et.al.|[2407.07666v1](http://arxiv.org/abs/2407.07666v1)|null|
|**2024-07-10**|**Boosting Medical Image Synthesis via Registration-guided Consistency and Disentanglement Learning**|Chuanpu Li et.al.|[2407.07660v1](http://arxiv.org/abs/2407.07660v1)|null|
|**2024-07-10**|**H-FCBFormer Hierarchical Fully Convolutional Branch Transformer for Occlusal Contact Segmentation with Articulating Paper**|Ryan Banks et.al.|[2407.07604v1](http://arxiv.org/abs/2407.07604v1)|[link](https://github.com/banksylel/h-fcbformer)|
|**2024-07-10**|**FLAIR: Feeding via Long-horizon AcquIsition of Realistic dishes**|Rajat Kumar Jenamani et.al.|[2407.07561v1](http://arxiv.org/abs/2407.07561v1)|null|
|**2024-07-10**|**Arabic Automatic Story Generation with Large Language Models**|Ahmed Oumar El-Shangiti et.al.|[2407.07551v1](http://arxiv.org/abs/2407.07551v1)|null|
|**2024-07-10**|**Weakly-supervised Medical Image Segmentation with Gaze Annotations**|Yuan Zhong et.al.|[2407.07406v1](http://arxiv.org/abs/2407.07406v1)|[link](https://github.com/med-air/gazemedseg)|
|**2024-07-10**|**Interpretable Differential Diagnosis with Dual-Inference Large Language Models**|Shuang Zhou et.al.|[2407.07330v1](http://arxiv.org/abs/2407.07330v1)|null|
|**2024-07-10**|**Large Language Model-Augmented Auto-Delineation of Treatment Target Volume in Radiation Therapy**|Praveenbalaji Rajendran et.al.|[2407.07296v1](http://arxiv.org/abs/2407.07296v1)|null|
|**2024-07-10**|**Causal Discovery in Semi-Stationary Time Series**|Shanyun Gao et.al.|[2407.07291v1](http://arxiv.org/abs/2407.07291v1)|[link](https://github.com/causalml-lab/pcmci-omega)|
|**2024-07-10**|**Causal Discovery-Driven Change Point Detection in Time Series**|Shanyun Gao et.al.|[2407.07290v1](http://arxiv.org/abs/2407.07290v1)|null|
|**2024-07-09**|**Lifestyle-Informed Personalized Blood Biomarker Prediction via Novel Representation Learning**|A. Ali Heydari et.al.|[2407.07277v1](http://arxiv.org/abs/2407.07277v1)|null|
|**2024-07-09**|**ProtoSAM -- One Shot Medical Image Segmentation With Foundational Models**|Lev Ayzenberg et.al.|[2407.07042v1](http://arxiv.org/abs/2407.07042v1)|null|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-09**|**Microsoft Cloud-based Digitization Workflow with Rich Metadata Acquisition for Cultural Heritage Objects**|Krzysztof Kutt et.al.|[2407.06972v1](http://arxiv.org/abs/2407.06972v1)|null|
|**2024-07-09**|**TE-SSL: Time and Event-aware Self Supervised Learning for Alzheimer's Disease Progression Analysis**|Jacob Thrasher et.al.|[2407.06852v1](http://arxiv.org/abs/2407.06852v1)|[link](https://github.com/jacob-thrasher/te-ssl)|
|**2024-07-09**|**VRDSynth: Synthesizing Programs for Multilingual Visually Rich Document Information Extraction**|Thanh-Dat Nguyen et.al.|[2407.06826v1](http://arxiv.org/abs/2407.06826v1)|null|
|**2024-07-09**|**iASiS: Towards Heterogeneous Big Data Analysis for Personalized Medicine**|Anastasia Krithara et.al.|[2407.06748v1](http://arxiv.org/abs/2407.06748v1)|null|
|**2024-07-09**|**TCKIN: A Novel Integrated Network Model for Predicting Mortality Risk in Sepsis Patients**|Fanglin Dong et.al.|[2407.06560v1](http://arxiv.org/abs/2407.06560v1)|null|
|**2024-07-08**|**AI-driven multi-omics integration for multi-scale predictive modeling of causal genotype-environment-phenotype relationships**|You Wu et.al.|[2407.06405v1](http://arxiv.org/abs/2407.06405v1)|null|
|**2024-07-08**|**Multimodal Chain-of-Thought Reasoning via ChatGPT to Protect Children from Age-Inappropriate Apps**|Chuanbo Hu et.al.|[2407.06309v1](http://arxiv.org/abs/2407.06309v1)|null|
|**2024-07-08**|**Hybrid X-Linker: Automated Data Generation and Extreme Multi-label Ranking for Biomedical Entity Linking**|Pedro Ruas et.al.|[2407.06292v1](http://arxiv.org/abs/2407.06292v1)|null|
|**2024-07-08**|**Depression Detection and Analysis using Large Language Models on Textual and Audio-Visual Modalities**|Avinash Anand et.al.|[2407.06125v1](http://arxiv.org/abs/2407.06125v1)|null|
|**2024-07-08**|**Igea: a Decoder-Only Language Model for Biomedical Text Generation in Italian**|Tommaso Mario Buonocore et.al.|[2407.06011v1](http://arxiv.org/abs/2407.06011v1)|null|
|**2024-07-08**|**Generation and De-Identification of Indian Clinical Discharge Summaries using LLMs**|Sanjeet Singh et.al.|[2407.05887v1](http://arxiv.org/abs/2407.05887v1)|null|
|**2024-07-08**|**Integrating AI in College Education: Positive yet Mixed Experiences with ChatGPT**|Xinrui Song et.al.|[2407.05810v1](http://arxiv.org/abs/2407.05810v1)|null|
|**2024-07-08**|**FedMRL: Data Heterogeneity Aware Federated Multi-agent Deep Reinforcement Learning for Medical Imaging**|Pranab Sahoo et.al.|[2407.05800v1](http://arxiv.org/abs/2407.05800v1)|[link](https://github.com/pranabiitp/fedmrl)|
|**2024-07-08**|**Large Language Models for Judicial Entity Extraction: A Comparative Study**|Atin Sakkeer Hussain et.al.|[2407.05786v1](http://arxiv.org/abs/2407.05786v1)|null|
|**2024-07-08**|**Potential of Multimodal Large Language Models for Data Mining of Medical Images and Free-text Reports**|Yutong Zhang et.al.|[2407.05758v1](http://arxiv.org/abs/2407.05758v1)|null|
|**2024-07-08**|**RadiomicsFill-Mammo: Synthetic Mammogram Mass Manipulation with Radiomics Features**|Inye Na et.al.|[2407.05683v1](http://arxiv.org/abs/2407.05683v1)|[link](https://github.com/nainye/radiomicsfill)|
|**2024-07-08**|**WSI-VQA: Interpreting Whole Slide Images by Generative Visual Question Answering**|Pingyi Chen et.al.|[2407.05603v1](http://arxiv.org/abs/2407.05603v1)|[link](https://github.com/cpystan/wsi-vqa)|
|**2024-07-07**|**Accelerating MRI Uncertainty Estimation with Mask-based Bayesian Neural Network**|Zehuan Zhang et.al.|[2407.05521v1](http://arxiv.org/abs/2407.05521v1)|null|
|**2024-07-07**|**A Survey of Models for Cognitive Diagnosis: New Developments and Future Directions**|Fei Wang et.al.|[2407.05458v1](http://arxiv.org/abs/2407.05458v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v1](http://arxiv.org/abs/2407.05440v1)|null|
|**2024-07-07**|**FM-OSD: Foundation Model-Enabled One-Shot Detection of Anatomical Landmarks**|Juzheng Miao et.al.|[2407.05412v1](http://arxiv.org/abs/2407.05412v1)|[link](https://github.com/juzhengmiao/fm-osd)|
|**2024-07-06**|**BadCLM: Backdoor Attack in Clinical Language Models for Electronic Health Records**|Weimin Lyu et.al.|[2407.05213v1](http://arxiv.org/abs/2407.05213v1)|null|
|**2024-07-06**|**RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models**|Peng Xia et.al.|[2407.05131v1](http://arxiv.org/abs/2407.05131v1)|[link](https://github.com/richard-peng-xia/rule)|
|**2024-07-06**|**Linear Attention Based Deep Nonlocal Means Filtering for Multiplicative Noise Removal**|Xiao Siyao et.al.|[2407.05087v1](http://arxiv.org/abs/2407.05087v1)|null|
|**2024-07-05**|**Brain Age Estimation with a Greedy Dual-Stream Model for Limited Datasets**|Iman Kianian et.al.|[2407.04808v1](http://arxiv.org/abs/2407.04808v1)|[link](https://github.com/iman2693/gdsm)|
|**2024-07-05**|**Entity Decomposition with Filtering: A Zero-Shot Clinical Named Entity Recognition Framework**|Reza Averly et.al.|[2407.04629v1](http://arxiv.org/abs/2407.04629v1)|null|
|**2024-07-05**|**Variational and Explanatory Neural Networks for Encoding Cancer Profiles and Predicting Drug Responses**|Tianshu Feng et.al.|[2407.04486v1](http://arxiv.org/abs/2407.04486v1)|null|
|**2024-07-05**|**Multi-modal Masked Siamese Network Improves Chest X-Ray Representation Learning**|Saeed Shurrab et.al.|[2407.04449v1](http://arxiv.org/abs/2407.04449v1)|[link](https://github.com/nyuad-cai/cxr-ehr-msn)|
|**2024-07-04**|**Query-Guided Self-Supervised Summarization of Nursing Notes**|Ya Gao et.al.|[2407.04125v1](http://arxiv.org/abs/2407.04125v1)|null|
|**2024-07-04**|**MiniGPT-Med: Large Language Model as a General Interface for Radiology Diagnosis**|Asma Alkhaldi et.al.|[2407.04106v1](http://arxiv.org/abs/2407.04106v1)|[link](https://github.com/vision-cair/minigpt-med)|
|**2024-07-04**|**Unsupervised Analysis of Alzheimer's Disease Signatures using 3D Deformable Autoencoders**|Mehmet Yigit Avci et.al.|[2407.03863v1](http://arxiv.org/abs/2407.03863v1)|[link](https://github.com/ci-ber/morphade)|
|**2024-07-04**|**Integrating Randomness in Large Language Models: A Linear Congruential Generator Approach for Generating Clinically Relevant Content**|Andrew Bouras et.al.|[2407.03582v1](http://arxiv.org/abs/2407.03582v1)|[link](https://github.com/andrewbouras/randomnesspaper)|
|**2024-07-03**|**Accelerated Proton Resonance Frequency-based Magnetic Resonance Thermometry by Optimized Deep Learning Method**|Sijie Xu et.al.|[2407.03308v1](http://arxiv.org/abs/2407.03308v1)|[link](https://github.com/minipuding/fastmrt)|
|**2024-07-03**|**MVGT: A Multi-view Graph Transformer Based on Spatial Relations for EEG Emotion Recognition**|Yanjie Cui et.al.|[2407.03131v2](http://arxiv.org/abs/2407.03131v2)|null|
|**2024-07-03**|**Effective Heterogeneous Federated Learning via Efficient Hypernetwork-based Weight Generation**|Yujin Shin et.al.|[2407.03086v1](http://arxiv.org/abs/2407.03086v1)|null|
|**2024-07-03**|**Attention Incorporated Network for Sharing Low-rank, Image and K-space Information during MR Image Reconstruction to Achieve Single Breath-hold Cardiac Cine Imaging**|Siying Xu et.al.|[2407.03034v1](http://arxiv.org/abs/2407.03034v1)|[link](https://github.com/midas-tum/a-liknet)|
|**2024-07-03**|**SemioLLM: Assessing Large Language Models for Semiological Analysis in Epilepsy Research**|Meghal Dani et.al.|[2407.03004v1](http://arxiv.org/abs/2407.03004v1)|null|
|**2024-07-03**|**MedPix 2.0: A Comprehensive Multimodal Biomedical Dataset for Advanced AI Applications**|Irene Siragusa et.al.|[2407.02994v1](http://arxiv.org/abs/2407.02994v1)|[link](https://github.com/chilab1/medpix-2.0)|
|**2024-07-03**|**Membership Inference Attacks Against Time-Series Models**|Noam Koren et.al.|[2407.02870v1](http://arxiv.org/abs/2407.02870v1)|null|
|**2024-07-03**|**Effect of a Process Mining based Pre-processing Step in Prediction of the Critical Health Outcomes**|Negin Ashrafi et.al.|[2407.02821v1](http://arxiv.org/abs/2407.02821v1)|null|
|**2024-07-03**|**MedVH: Towards Systematic Evaluation of Hallucination for Large Vision Language Models in the Medical Context**|Zishan Gu et.al.|[2407.02730v1](http://arxiv.org/abs/2407.02730v1)|[link](https://github.com/dongzizhu/medvh)|
|**2024-07-02**|**D-Rax: Domain-specific Radiologic assistant leveraging multi-modal data and eXpert model predictions**|Hareem Nisar et.al.|[2407.02604v1](http://arxiv.org/abs/2407.02604v1)|null|
|**2024-07-02**|**MMedAgent: Learning to Use Medical Tools with Multi-modal Agent**|Binxu Li et.al.|[2407.02483v1](http://arxiv.org/abs/2407.02483v1)|null|
|**2024-07-02**|**CALICO: Confident Active Learning with Integrated Calibration**|Lorenzo S. Querol et.al.|[2407.02335v1](http://arxiv.org/abs/2407.02335v1)|null|
|**2024-07-02**|**A Refreshed Similarity-based Upsampler for Direct High-Ratio Feature Upsampling**|Minghao Zhou et.al.|[2407.02283v1](http://arxiv.org/abs/2407.02283v1)|[link](https://github.com/zmhhmz/resfu)|
|**2024-07-02**|**FedIA: Federated Medical Image Segmentation with Heterogeneous Annotation Completeness**|Yangyang Xiang et.al.|[2407.02280v2](http://arxiv.org/abs/2407.02280v2)|[link](https://github.com/hustxyy/fedia)|
|**2024-07-02**|**Generative Monoculture in Large Language Models**|Fan Wu et.al.|[2407.02209v1](http://arxiv.org/abs/2407.02209v1)|[link](https://github.com/GeMoLLM/GeMO)|
|**2024-07-02**|**Abstract Dialectical Frameworks are Boolean Networks (full version)**|Jesse Heyninck et.al.|[2407.02055v1](http://arxiv.org/abs/2407.02055v1)|null|
|**2024-07-02**|**A Method to Facilitate Membership Inference Attacks in Deep Learning Models**|Zitao Chen et.al.|[2407.01919v1](http://arxiv.org/abs/2407.01919v1)|[link](https://github.com/DependableSystemsLab/code_poison_MIA)|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-07-01**|**Optimized Learning for X-Ray Image Classification for Multi-Class Disease Diagnoses with Accelerated Computing Strategies**|Sebastian A. Cruz Romero et.al.|[2407.01705v1](http://arxiv.org/abs/2407.01705v1)|null|
|**2024-07-01**|**Deep Dive into MRI: Exploring Deep Learning Applications in 0.55T and 7T MRI**|Ana Carolina Alves et.al.|[2407.01318v1](http://arxiv.org/abs/2407.01318v1)|null|
|**2024-07-01**|**MIRAI: Evaluating LLM Agents for Event Forecasting**|Chenchen Ye et.al.|[2407.01231v1](http://arxiv.org/abs/2407.01231v1)|null|
|**2024-07-01**|**Integrated feature analysis for deep learning interpretation and class activation maps**|Yanli Li et.al.|[2407.01142v1](http://arxiv.org/abs/2407.01142v1)|[link](https://github.com/yanlili27/ifa)|
|**2024-07-01**|**An Outline of Prognostics and Health Management Large Model: Concepts, Paradigms, and Challenges**|Laifa Tao et.al.|[2407.03374v1](http://arxiv.org/abs/2407.03374v1)|null|
|**2024-07-01**|**Embedded Prompt Tuning: Towards Enhanced Calibration of Pretrained Models for Medical Images**|Wenqiang Zu et.al.|[2407.01003v2](http://arxiv.org/abs/2407.01003v2)|null|
|**2024-07-01**|**Individual brain parcellation: Review of methods, validations and applications**|Chengyi Li et.al.|[2407.00984v1](http://arxiv.org/abs/2407.00984v1)|null|
|**2024-07-01**|**Hybrid RAG-empowered Multi-modal LLM for Secure Healthcare Data Management: A Diffusion-based Contract Theory Approach**|Cheng Su et.al.|[2407.00978v1](http://arxiv.org/abs/2407.00978v1)|null|
|**2024-07-01**|**Optimizing PM2.5 Forecasting Accuracy with Hybrid Meta-Heuristic and Machine Learning Models**|Parviz Ghafariasl et.al.|[2407.01647v1](http://arxiv.org/abs/2407.01647v1)|null|
|**2024-07-01**|**Deep learning for automated detection of breast cancer in deep ultraviolet fluorescence images with diffusion probabilistic model**|Sepehr Salem Ghahfarokhi et.al.|[2407.00967v1](http://arxiv.org/abs/2407.00967v1)|null|
|**2024-06-30**|**Characterizing Stereotypical Bias from Privacy-preserving Pre-Training**|Stefan Arnold et.al.|[2407.00764v1](http://arxiv.org/abs/2407.00764v1)|null|
|**2024-06-30**|**Chest-Diffusion: A Light-Weight Text-to-Image Model for Report-to-CXR Generation**|Peng Huang et.al.|[2407.00752v1](http://arxiv.org/abs/2407.00752v1)|null|
|**2024-06-30**|**Large Language Models Struggle in Token-Level Clinical Named Entity Recognition**|Qiuhao Lu et.al.|[2407.00731v1](http://arxiv.org/abs/2407.00731v1)|null|
|**2024-06-30**|**SCMIL: Sparse Context-aware Multiple Instance Learning for Predicting Cancer Survival Probability Distribution in Whole Slide Images**|Zekang Yang et.al.|[2407.00664v1](http://arxiv.org/abs/2407.00664v1)|[link](https://github.com/yang-ze-kang/scmil)|
|**2024-06-30**|**TrialBench: Multi-Modal Artificial Intelligence-Ready Clinical Trial Datasets**|Jintai Chen et.al.|[2407.00631v1](http://arxiv.org/abs/2407.00631v1)|[link](https://github.com/ml2health/ml2clinicaltrials)|
|**2024-06-29**|**Answering real-world clinical questions using large language model based systems**|Yen Sia Low et.al.|[2407.00541v1](http://arxiv.org/abs/2407.00541v1)|null|
|**2024-06-29**|**Privacy-Preserving and Trustworthy Deep Learning for Medical Imaging**|Kiarash Sedghighadikolaei et.al.|[2407.00538v1](http://arxiv.org/abs/2407.00538v1)|null|
|**2024-06-29**|**Interpreting Pretrained Speech Models for Automatic Speech Assessment of Voice Disorders**|Hok-Shing Lau et.al.|[2407.00531v1](http://arxiv.org/abs/2407.00531v1)|null|
|**2024-06-29**|**ConU: Conformal Uncertainty in Large Language Models with Correctness Coverage Guarantees**|Zhiyuan Wang et.al.|[2407.00499v1](http://arxiv.org/abs/2407.00499v1)|null|
|**2024-06-29**|**MH-pFLGB: Model Heterogeneous personalized Federated Learning via Global Bypass for Medical Image Analysis**|Luyuan Xie et.al.|[2407.00474v1](http://arxiv.org/abs/2407.00474v1)|null|
|**2024-06-29**|**pFLFE: Cross-silo Personalized Federated Learning via Feature Enhancement on Medical Image Segmentation**|Luyuan Xie et.al.|[2407.00462v1](http://arxiv.org/abs/2407.00462v1)|null|
|**2024-06-29**|**Is It Really Long Context if All You Need Is Retrieval? Towards Genuinely Difficult Long Context NLP**|Omer Goldman et.al.|[2407.00402v1](http://arxiv.org/abs/2407.00402v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-28**|**Predicting Elevated Risk of Hospitalization Following Emergency Department Discharges**|Dat Hong et.al.|[2407.00147v1](http://arxiv.org/abs/2407.00147v1)|null|
|**2024-06-28**|**BMW Agents -- A Framework For Task Automation Through Multi-Agent Collaboration**|Noel Crawford et.al.|[2406.20041v3](http://arxiv.org/abs/2406.20041v3)|null|
|**2024-06-28**|**Graph Neural Networks for Gut Microbiome Metaomic data: A preliminary work**|Christopher Irwin et.al.|[2407.00142v1](http://arxiv.org/abs/2407.00142v1)|null|
|**2024-06-28**|**Structure-aware World Model for Probe Guidance via Large-scale Self-supervised Pre-train**|Haojun Jiang et.al.|[2406.19756v1](http://arxiv.org/abs/2406.19756v1)|null|
|**2024-06-28**|**Multimodal Learning and Cognitive Processes in Radiology: MedGaze for Chest X-ray Scanpath Prediction**|Akash Awasthi et.al.|[2407.00129v1](http://arxiv.org/abs/2407.00129v1)|null|
|**2024-06-28**|**ACES: Automatic Cohort Extraction System for Event-Stream Datasets**|Justin Xu et.al.|[2406.19653v1](http://arxiv.org/abs/2406.19653v1)|[link](https://github.com/justin13601/aces)|
|**2024-06-28**|**Multimodal Data Integration for Precision Oncology: Challenges and Future Directions**|Huajun Zhou et.al.|[2406.19611v1](http://arxiv.org/abs/2406.19611v1)|null|
|**2024-06-27**|**PathAlign: A vision-language model for whole slide images in histopathology**|Faruk Ahmed et.al.|[2406.19578v1](http://arxiv.org/abs/2406.19578v1)|null|
|**2024-06-27**|**Automated Web-Based Malaria Detection System with Machine Learning and Deep Learning Techniques**|Abraham G Taye et.al.|[2407.00120v1](http://arxiv.org/abs/2407.00120v1)|[link](https://github.com/abrahamgenetu/Automated_Malaria_Detection_System)|
|**2024-06-27**|**HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale**|Junying Chen et.al.|[2406.19280v1](http://arxiv.org/abs/2406.19280v1)|[link](https://github.com/freedomintelligence/huatuogpt-vision)|
|**2024-06-27**|**Generative AI for Synthetic Data Across Multiple Medical Modalities: A Systematic Review of Recent Developments and Challenges**|Mahmoud Ibrahim et.al.|[2407.00116v2](http://arxiv.org/abs/2407.00116v2)|null|
|**2024-06-27**|**Segment Anything Model for automated image data annotation: empirical studies using text prompts from Grounding DINO**|Fuseini Mumuni et.al.|[2406.19057v2](http://arxiv.org/abs/2406.19057v2)|null|
|**2024-06-27**|**FedMap: Iterative Magnitude-Based Pruning for Communication-Efficient Federated Learning**|Alexander Herzog et.al.|[2406.19050v1](http://arxiv.org/abs/2406.19050v1)|null|

#### Abstracts
##### **The Human Factor in AI Red Teaming: Perspectives from Social and Collaborative Computing**
2407.07786v1 by Alice Qian Zhang, Ryland Shaw, Jacy Reese Anthis, Ashlee Milton, Emily Tseng, Jina Suh, Lama Ahmad, Ram Shankar Siva Kumar, Julian Posada, Benjamin Shestakofsky, Sarah T. Roberts, Mary L. Gray

Rapid progress in general-purpose AI has sparked significant interest in "red
teaming," a practice of adversarial testing originating in military and
cybersecurity applications. AI red teaming raises many questions about the
human factor, such as how red teamers are selected, biases and blindspots in
how tests are conducted, and harmful content's psychological effects on red
teamers. A growing body of HCI and CSCW literature examines related
practices-including data labeling, content moderation, and algorithmic
auditing. However, few, if any, have investigated red teaming itself. This
workshop seeks to consider the conceptual and empirical challenges associated
with this practice, often rendered opaque by non-disclosure agreements. Future
studies may explore topics ranging from fairness to mental health and other
areas of potential harm. We aim to facilitate a community of researchers and
practitioners who can begin to meet these challenges with creativity,
innovation, and thoughtful reflection.

摘要：一般用途 AI 的快速進展引發了對「紅隊」的濃厚興趣，紅隊是一種源自軍事和網路安全應用中的對抗性測試實務。AI 紅隊對人類因素提出了許多問題，例如紅隊成員如何選拔、測試執行方式中的偏見和盲點，以及有害內容對紅隊成員的心理影響。越來越多的人機互動和 CSCW 文獻探討了相關實務，包括資料標記、內容審核和演算法稽核。然而，鮮少有人探討紅隊本身。本工作坊旨在探討與此實務相關的概念和經驗挑戰，這些挑戰通常因保密協議而變得模糊不清。未來的研究可能會探討從公平性到心理健康和其他潛在危害領域的主題。我們的目標是促進研究人員和實務工作者的社群，他們可以開始運用創意、創新和深思熟慮的反思來應對這些挑戰。

##### **A Proposed S.C.O.R.E. Evaluation Framework for Large Language Models : Safety, Consensus, Objectivity, Reproducibility and Explainability**
2407.07666v1 by Ting Fang Tan, Kabilan Elangovan, Jasmine Ong, Nigam Shah, Joseph Sung, Tien Yin Wong, Lan Xue, Nan Liu, Haibo Wang, Chang Fu Kuo, Simon Chesterman, Zee Kin Yeong, Daniel SW Ting

A comprehensive qualitative evaluation framework for large language models
(LLM) in healthcare that expands beyond traditional accuracy and quantitative
metrics needed. We propose 5 key aspects for evaluation of LLMs: Safety,
Consensus, Objectivity, Reproducibility and Explainability (S.C.O.R.E.). We
suggest that S.C.O.R.E. may form the basis for an evaluation framework for
future LLM-based models that are safe, reliable, trustworthy, and ethical for
healthcare and clinical applications.

摘要：一個全面的定性評估架構，適用於醫療保健領域的大型語言模型 (LLM)，其範圍超越傳統的準確度和定量指標。我們提出用於評估 LLM 的 5 個關鍵面向：安全性、共識、客觀性、可複製性和可解釋性 (S.C.O.R.E.)。我們建議 S.C.O.R.E. 可以作為評估架構的基礎，適用於未來的基於 LLM 的模型，這些模型對於醫療保健和臨床應用來說是安全、可靠、值得信賴且合乎道德的。

##### **Boosting Medical Image Synthesis via Registration-guided Consistency and Disentanglement Learning**
2407.07660v1 by Chuanpu Li, Zeli Chen, Yiwen Zhang, Liming Zhong, Wei Yang

Medical image synthesis remains challenging due to misalignment noise during
training. Existing methods have attempted to address this challenge by
incorporating a registration-guided module. However, these methods tend to
overlook the task-specific constraints on the synthetic and registration
modules, which may cause the synthetic module to still generate spatially
aligned images with misaligned target images during training, regardless of the
registration module's function. Therefore, this paper proposes
registration-guided consistency and incorporates disentanglement learning for
medical image synthesis. The proposed registration-guided consistency
architecture fosters task-specificity within the synthetic and registration
modules by applying identical deformation fields before and after synthesis,
while enforcing output consistency through an alignment loss. Moreover, the
synthetic module is designed to possess the capability of disentangling
anatomical structures and specific styles across various modalities. An anatomy
consistency loss is introduced to further compel the synthetic module to
preserve geometrical integrity within latent spaces. Experiments conducted on
both an in-house abdominal CECT-CT dataset and a publicly available pelvic
MR-CT dataset have demonstrated the superiority of the proposed method.

摘要：由於訓練期間的錯位雜訊，醫學影像合成仍然具有挑戰性。現有方法已嘗試透過納入註冊導引模組來解決此挑戰。然而，這些方法往往忽略合成與註冊模組的特定任務約束，這可能會導致合成模組在訓練期間仍產生與錯位目標影像空間對齊的影像，而與註冊模組的功能無關。因此，本文提出註冊導引一致性，並結合解糾纏學習用於醫學影像合成。所提出的註冊導引一致性架構透過在合成前後應用相同的變形場，並透過對齊損失來強制執行輸出一致性，來促進合成與註冊模組中的任務特異性。此外，合成模組被設計為具備在各種模態中解開解剖結構和特定樣式的能力。引入了解剖一致性損失，以進一步強制合成模組在潛在空間中保留幾何完整性。在內部腹部 CECT-CT 資料集和公開可用的骨盆 MR-CT 資料集上進行的實驗已證明了所提出方法的優越性。

##### **H-FCBFormer Hierarchical Fully Convolutional Branch Transformer for Occlusal Contact Segmentation with Articulating Paper**
2407.07604v1 by Ryan Banks, Bernat Rovira-Lastra, Jordi Martinez-Gomis, Akhilanand Chaurasia, Yunpeng Li

Occlusal contacts are the locations at which the occluding surfaces of the
maxilla and the mandible posterior teeth meet. Occlusal contact detection is a
vital tool for restoring the loss of masticatory function and is a mandatory
assessment in the field of dentistry, with particular importance in
prosthodontics and restorative dentistry. The most common method for occlusal
contact detection is articulating paper. However, this method can indicate
significant medically false positive and medically false negative contact
areas, leaving the identification of true occlusal indications to clinicians.
To address this, we propose a multiclass Vision Transformer and Fully
Convolutional Network ensemble semantic segmentation model with a combination
hierarchical loss function, which we name as Hierarchical Fully Convolutional
Branch Transformer (H-FCBFormer). We also propose a method of generating
medically true positive semantic segmentation masks derived from expert
annotated articulating paper masks and gold standard masks. The proposed model
outperforms other machine learning methods evaluated at detecting medically
true positive contacts and performs better than dentists in terms of accurately
identifying object-wise occlusal contact areas while taking significantly less
time to identify them. Code is available at
https://github.com/Banksylel/H-FCBFormer.

摘要：咬合接觸是上顎和下顎後牙咬合面相遇的位置。咬合接觸偵測是恢復咀嚼功能喪失的必要工具，也是牙科領域中的一項強制性評估，特別是在贋復牙科和修復牙科中具有重要意義。最常見的咬合接觸偵測方法是使用咬合紙。然而，此方法可能會顯示出顯著的醫學假陽性和醫學假陰性接觸區域，讓臨床醫師難以找出真正的咬合跡象。為了解決這個問題，我們提出一個多類別的 Vision Transformer 和全卷積網路集合語意分割模型，並結合分層損失函數，我們將其命名為分層全卷積分支轉換器 (H-FCBFormer)。我們還提出了一種生成醫學真陽性語意分割遮罩的方法，該方法源自專家註解的咬合紙遮罩和金標準遮罩。所提出的模型在偵測醫學真陽性接觸方面優於其他機器學習方法，並且在準確識別物件式咬合接觸區域方面優於牙醫師，同時識別所需時間卻顯著減少。程式碼可在 https://github.com/Banksylel/H-FCBFormer 取得。

##### **FLAIR: Feeding via Long-horizon AcquIsition of Realistic dishes**
2407.07561v1 by Rajat Kumar Jenamani, Priya Sundaresan, Maram Sakr, Tapomayukh Bhattacharjee, Dorsa Sadigh

Robot-assisted feeding has the potential to improve the quality of life for
individuals with mobility limitations who are unable to feed themselves
independently. However, there exists a large gap between the homogeneous,
curated plates existing feeding systems can handle, and truly in-the-wild
meals. Feeding realistic plates is immensely challenging due to the sheer range
of food items that a robot may encounter, each requiring specialized
manipulation strategies which must be sequenced over a long horizon to feed an
entire meal. An assistive feeding system should not only be able to sequence
different strategies efficiently in order to feed an entire meal, but also be
mindful of user preferences given the personalized nature of the task. We
address this with FLAIR, a system for long-horizon feeding which leverages the
commonsense and few-shot reasoning capabilities of foundation models, along
with a library of parameterized skills, to plan and execute user-preferred and
efficient bite sequences. In real-world evaluations across 6 realistic plates,
we find that FLAIR can effectively tap into a varied library of skills for
efficient food pickup, while adhering to the diverse preferences of 42
participants without mobility limitations as evaluated in a user study. We
demonstrate the seamless integration of FLAIR with existing bite transfer
methods [19, 28], and deploy it across 2 institutions and 3 robots,
illustrating its adaptability. Finally, we illustrate the real-world efficacy
of our system by successfully feeding a care recipient with severe mobility
limitations. Supplementary materials and videos can be found at:
https://emprise.cs.cornell.edu/flair .

摘要：機器人輔助進食有潛力改善行動不便、無法自行進食的個人生活品質。然而，現有的進食系統所能處理的均質、精選餐盤與實際的餐點之間存在著很大的差距。進食實際的餐點極具挑戰性，因為機器人可能遇到的食物種類繁多，每種食物都需要特定的操作策略，而這些策略必須在一個長期的範圍內進行排序，才能進食一整餐。一個輔助進食系統不僅應該能夠有效地對不同的策略進行排序，以便進食一整餐，還應該在任務的個性化性質下，考量使用者的偏好。我們透過 FLAIR 來解決這個問題，FLAIR 是針對長時程進食的系統，它利用基礎模型的常識和少量推理能力，以及一個參數化技能庫，來規劃和執行使用者偏好且有效的進食順序。在 6 個實際餐盤的真實世界評估中，我們發現 FLAIR 可以有效地利用各種技能庫進行有效的食物取用，同時遵守 42 位行動不便參與者的不同偏好，這是在使用者研究中評估的。我們展示了 FLAIR 與現有進食轉移方法 [19, 28] 的無縫整合，並在 2 個機構和 3 個機器人中部署它，說明了它的適應性。最後，我們透過成功餵食一位行動不便的受照護者來說明我們系統在真實世界中的功效。補充材料和影片可以在這裡找到：https://emprise.cs.cornell.edu/flair。

##### **Arabic Automatic Story Generation with Large Language Models**
2407.07551v1 by Ahmed Oumar El-Shangiti, Fakhraddin Alwajih, Muhammad Abdul-Mageed

Large language models (LLMs) have recently emerged as a powerful tool for a
wide range of language generation tasks. Nevertheless, this progress has been
slower in Arabic. In this work, we focus on the task of generating stories from
LLMs. For our training, we use stories acquired through machine translation
(MT) as well as GPT-4. For the MT data, we develop a careful pipeline that
ensures we acquire high-quality stories. For our GPT-41 data, we introduce
crafted prompts that allow us to generate data well-suited to the Arabic
context in both Modern Standard Arabic (MSA) and two Arabic dialects (Egyptian
and Moroccan). For example, we generate stories tailored to various Arab
countries on a wide host of topics. Our manual evaluation shows that our model
fine-tuned on these training datasets can generate coherent stories that adhere
to our instructions. We also conduct an extensive automatic and human
evaluation comparing our models against state-of-the-art proprietary and
open-source models. Our datasets and models will be made publicly available at
https: //github.com/UBC-NLP/arastories.

摘要：大型語言模型（LLM）最近已成為各種語言生成任務的強大工具。儘管如此，這項進展在阿拉伯語中較為緩慢。在這項工作中，我們專注於從 LLM 生成故事的任務。對於我們的訓練，我們使用通過機器翻譯（MT）以及 GPT-4 獲得的故事。對於 MT 資料，我們開發了一個仔細的管道，以確保我們獲得高品質的故事。對於我們的 GPT-41 資料，我們引入了精心製作的提示，使我們能夠生成非常適合阿拉伯語環境的資料，包括現代標準阿拉伯語（MSA）和兩種阿拉伯語方言（埃及語和摩洛哥語）。例如，我們生成針對各種阿拉伯國家的故事，主題廣泛。我們的評估顯示，我們針對這些訓練資料集進行微調的模型可以生成符合我們指示的連貫故事。我們還進行了廣泛的自動和人工評估，將我們的模型與最先進的專有和開放原始碼模型進行比較。我們的資料集和模型將在 https: //github.com/UBC-NLP/arastories 公開。

##### **Weakly-supervised Medical Image Segmentation with Gaze Annotations**
2407.07406v1 by Yuan Zhong, Chenhui Tang, Yumeng Yang, Ruoxi Qi, Kang Zhou, Yuqi Gong, Pheng Ann Heng, Janet H. Hsiao, Qi Dou

Eye gaze that reveals human observational patterns has increasingly been
incorporated into solutions for vision tasks. Despite recent explorations on
leveraging gaze to aid deep networks, few studies exploit gaze as an efficient
annotation approach for medical image segmentation which typically entails
heavy annotating costs. In this paper, we propose to collect dense weak
supervision for medical image segmentation with a gaze annotation scheme. To
train with gaze, we propose a multi-level framework that trains multiple
networks from discriminative human attention, simulated with a set of
pseudo-masks derived by applying hierarchical thresholds on gaze heatmaps.
Furthermore, to mitigate gaze noise, a cross-level consistency is exploited to
regularize overfitting noisy labels, steering models toward clean patterns
learned by peer networks. The proposed method is validated on two public
medical datasets of polyp and prostate segmentation tasks. We contribute a
high-quality gaze dataset entitled GazeMedSeg as an extension to the popular
medical segmentation datasets. To the best of our knowledge, this is the first
gaze dataset for medical image segmentation. Our experiments demonstrate that
gaze annotation outperforms previous label-efficient annotation schemes in
terms of both performance and annotation time. Our collected gaze data and code
are available at: https://github.com/med-air/GazeMedSeg.

摘要：人类观察模式的眼球注视已越来越多地融入视觉任务的解决方案中。尽管最近探索了利用注视来辅助深度网络，但很少有研究利用注视作为医学图像分割的有效注释方法，这通常需要大量的注释成本。在本文中，我们提出收集密集的弱监督，用于具有凝视注释方案的医学图像分割。为了用注视进行训练，我们提出了一个多级框架，该框架从区分性人类注意力训练多个网络，并通过在凝视热图上应用分层阈值来模拟一组伪掩码。此外，为了减轻注视噪声，利用跨级一致性来正则化过度拟合的噪声标签，将模型引导至由对等网络学习的干净模式。所提出的方法已在两个公共医学数据集的多息肉和前列腺分割任务上得到验证。我们贡献了一个名为 GazeMedSeg 的高质量凝视数据集，作为流行医学分割数据集的扩展。据我们所知，这是医学图像分割的第一个凝视数据集。我们的实验表明，在性能和注释时间方面，凝视注释优于以前的标签高效注释方案。我们收集的凝视数据和代码可在以下位置获得：https://github.com/med-air/GazeMedSeg。

##### **Interpretable Differential Diagnosis with Dual-Inference Large Language Models**
2407.07330v1 by Shuang Zhou, Sirui Ding, Jiashuo Wang, Mingquan Lin, Genevieve B. Melton, Rui Zhang

Methodological advancements to automate the generation of differential
diagnosis (DDx) to predict a list of potential diseases as differentials given
patients' symptom descriptions are critical to clinical reasoning and
applications such as decision support. However, providing reasoning or
interpretation for these differential diagnoses is more meaningful.
Fortunately, large language models (LLMs) possess powerful language processing
abilities and have been proven effective in various related tasks. Motivated by
this potential, we investigate the use of LLMs for interpretable DDx. First, we
develop a new DDx dataset with expert-derived interpretation on 570 public
clinical notes. Second, we propose a novel framework, named Dual-Inf, that
enables LLMs to conduct bidirectional inference for interpretation. Both human
and automated evaluation demonstrate the effectiveness of Dual-Inf in
predicting differentials and diagnosis explanations. Specifically, the
performance improvement of Dual-Inf over the baseline methods exceeds 32%
w.r.t. BERTScore in DDx interpretation. Furthermore, experiments verify that
Dual-Inf (1) makes fewer errors in interpretation, (2) has great
generalizability, (3) is promising for rare disease diagnosis and explanation.

摘要：方法學的進展自動化生成差異診斷 (DDx)，以預測給定患者症狀描述的潛在疾病清單，對於臨床推理和決策支援等應用至關重要。然而，提供這些差異診斷的推理或解釋更有意義。幸運的是，大型語言模型 (LLM) 擁有強大的語言處理能力，並已被證明在各種相關任務中有效。受此潛力的激勵，我們研究了 LLM 在可解釋的 DDx 中的應用。首先，我們開發了一個新的 DDx 數據集，其中包含專家對 570 個公共臨床筆記的解釋。其次，我們提出了一個名為 Dual-Inf 的新框架，它使 LLM 能夠進行雙向推理以進行解釋。人類和自動化評估都證明了 Dual-Inf 在預測差異和診斷解釋方面的有效性。具體來說，Dual-Inf 在 DDx 解釋中超過基線方法的性能改進超過 32% w.r.t. BERTScore。此外，實驗驗證了 Dual-Inf (1) 在解釋中產生較少的錯誤，(2) 具有很好的概括性，(3) 對罕見疾病的診斷和解釋很有前景。

##### **Large Language Model-Augmented Auto-Delineation of Treatment Target Volume in Radiation Therapy**
2407.07296v1 by Praveenbalaji Rajendran, Yong Yang, Thomas R. Niedermayr, Michael Gensheimer, Beth Beadle, Quynh-Thu Le, Lei Xing, Xianjin Dai

Radiation therapy (RT) is one of the most effective treatments for cancer,
and its success relies on the accurate delineation of targets. However, target
delineation is a comprehensive medical decision that currently relies purely on
manual processes by human experts. Manual delineation is time-consuming,
laborious, and subject to interobserver variations. Although the advancements
in artificial intelligence (AI) techniques have significantly enhanced the
auto-contouring of normal tissues, accurate delineation of RT target volumes
remains a challenge. In this study, we propose a visual language model-based RT
target volume auto-delineation network termed Radformer. The Radformer utilizes
a hierarichal vision transformer as the backbone and incorporates large
language models to extract text-rich features from clinical data. We introduce
a visual language attention module (VLAM) for integrating visual and linguistic
features for language-aware visual encoding (LAVE). The Radformer has been
evaluated on a dataset comprising 2985 patients with head-and-neck cancer who
underwent RT. Metrics, including the Dice similarity coefficient (DSC),
intersection over union (IOU), and 95th percentile Hausdorff distance (HD95),
were used to evaluate the performance of the model quantitatively. Our results
demonstrate that the Radformer has superior segmentation performance compared
to other state-of-the-art models, validating its potential for adoption in RT
practice.

摘要：放射治療 (RT) 是最有效的癌症治療方法之一，其成功有賴於目標的準確描繪。然而，目標描繪是一項全面的醫療決策，目前完全依賴人類專家的手動程序。手動描繪耗時、費力，且受觀察者間差異影響。儘管人工智慧 (AI) 技術的進步已顯著增強正常組織的自動輪廓描繪，但 RT 目標體積的準確描繪仍是一項挑戰。在本研究中，我們提出一個基於視覺語言模型的 RT 目標體積自動描繪網路，稱為 Radformer。Radformer 利用階層式視覺Transformer作為主幹，並整合大型語言模型從臨床資料中提取豐富文字特徵。我們引入一個視覺語言注意力模組 (VLAM)，用於整合視覺和語言特徵，以進行語言感知視覺編碼 (LAVE)。Radformer 已在一個包含 2985 名接受 RT 治療的頭頸癌患者的資料集上進行評估。指標，包括 Dice 相似係數 (DSC)、聯集比 (IOU) 和第 95 個百分位數 Hausdorff 距離 (HD95)，用於定量評估模型的效能。我們的結果表明，與其他最先進的模型相比，Radformer 具有優異的分割效能，驗證了其在 RT 實務中應用的潛力。

##### **Causal Discovery in Semi-Stationary Time Series**
2407.07291v1 by Shanyun Gao, Raghavendra Addanki, Tong Yu, Ryan A. Rossi, Murat Kocaoglu

Discovering causal relations from observational time series without making
the stationary assumption is a significant challenge. In practice, this
challenge is common in many areas, such as retail sales, transportation
systems, and medical science. Here, we consider this problem for a class of
non-stationary time series. The structural causal model (SCM) of this type of
time series, called the semi-stationary time series, exhibits that a finite
number of different causal mechanisms occur sequentially and periodically
across time. This model holds considerable practical utility because it can
represent periodicity, including common occurrences such as seasonality and
diurnal variation. We propose a constraint-based, non-parametric algorithm for
discovering causal relations in this setting. The resulting algorithm,
PCMCI$_{\Omega}$, can capture the alternating and recurring changes in the
causal mechanisms and then identify the underlying causal graph with
conditional independence (CI) tests. We show that this algorithm is sound in
identifying causal relations on discrete time series. We validate the algorithm
with extensive experiments on continuous and discrete simulated data. We also
apply our algorithm to a real-world climate dataset.

摘要：在不作平穩假設的情況下從觀測時間序列中發現因果關係是一項重大挑戰。在實務中，這個挑戰在許多領域中很常見，例如零售銷售、運輸系統和醫學科學。在此，我們考慮非平穩時間序列類別的這個問題。這種類型的時間序列的結構因果模型 (SCM)，稱為半平穩時間序列，展示了有限數量的不同因果機制會隨著時間順序且週期性地發生。這個模型具有相當大的實用性，因為它可以表示週期性，包括季節性和晝夜變化等常見現象。我們提出了一個基於約束的非參數演算法，用於發現這個設定中的因果關係。產生的演算法 PCMCI$_{\Omega}$ 可以捕捉因果機制中的交替和重複變化，然後藉由條件獨立 (CI) 檢定來識別基礎因果圖。我們證明這個演算法在識別離散時間序列上的因果關係時是合理的。我們使用連續和離散模擬資料進行廣泛的實驗，以驗證演算法。我們也將我們的演算法應用於真實世界的氣候資料集。

##### **Causal Discovery-Driven Change Point Detection in Time Series**
2407.07290v1 by Shanyun Gao, Raghavendra Addanki, Tong Yu, Ryan A. Rossi, Murat Kocaoglu

Change point detection in time series seeks to identify times when the
probability distribution of time series changes. It is widely applied in many
areas, such as human-activity sensing and medical science. In the context of
multivariate time series, this typically involves examining the joint
distribution of high-dimensional data: If any one variable changes, the whole
time series is assumed to have changed. However, in practical applications, we
may be interested only in certain components of the time series, exploring
abrupt changes in their distributions in the presence of other time series.
Here, assuming an underlying structural causal model that governs the
time-series data generation, we address this problem by proposing a two-stage
non-parametric algorithm that first learns parts of the causal structure
through constraint-based discovery methods. The algorithm then uses conditional
relative Pearson divergence estimation to identify the change points. The
conditional relative Pearson divergence quantifies the distribution disparity
between consecutive segments in the time series, while the causal discovery
method enables a focus on the causal mechanism, facilitating access to
independent and identically distributed (IID) samples. Theoretically, the
typical assumption of samples being IID in conventional change point detection
methods can be relaxed based on the Causal Markov Condition. Through
experiments on both synthetic and real-world datasets, we validate the
correctness and utility of our approach.

摘要：時間序列的變異點偵測旨在找出時間序列的機率分佈改變的時間。它廣泛應用於許多領域，例如人類活動感測與醫學科學。在多變量時間序列的背景中，這通常涉及檢視高維度資料的聯合分佈：如果任何一個變數改變，則假設整個時間序列已經改變。然而，在實際應用中，我們可能只對時間序列的特定組成部分感興趣，探索它們的分佈在其他時間序列存在的情況下突然改變。在這裡，假設一個基礎的結構因果模型支配著時間序列資料的生成，我們透過提出一個兩階段非參數演算法來解決這個問題，該演算法首先透過基於約束的發現方法來學習因果結構的部分。然後，該演算法使用條件相對 Pearson 差異估計來找出變異點。條件相對 Pearson 差異量化時間序列中連續區段之間的分佈差異，而因果發現方法可以專注於因果機制，促進取得獨立且同分布 (IID) 的樣本。理論上，樣本為 IID 的典型假設在傳統變異點偵測方法中可以根據因果馬可夫條件放寬。透過在合成和真實世界資料集上進行實驗，我們驗證了我們方法的正確性和實用性。

##### **Lifestyle-Informed Personalized Blood Biomarker Prediction via Novel Representation Learning**
2407.07277v1 by A. Ali Heydari, Naghmeh Rezaei, Javier L. Prieto, Shwetak N. Patel, Ahmed A. Metwally

Blood biomarkers are an essential tool for healthcare providers to diagnose,
monitor, and treat a wide range of medical conditions. Current reference values
and recommended ranges often rely on population-level statistics, which may not
adequately account for the influence of inter-individual variability driven by
factors such as lifestyle and genetics. In this work, we introduce a novel
framework for predicting future blood biomarker values and define personalized
references through learned representations from lifestyle data (physical
activity and sleep) and blood biomarkers. Our proposed method learns a
similarity-based embedding space that captures the complex relationship between
biomarkers and lifestyle factors. Using the UK Biobank (257K participants), our
results show that our deep-learned embeddings outperform traditional and
current state-of-the-art representation learning techniques in predicting
clinical diagnosis. Using a subset of UK Biobank of 6440 participants who have
follow-up visits, we validate that the inclusion of these embeddings and
lifestyle factors directly in blood biomarker models improves the prediction of
future lab values from a single lab visit. This personalized modeling approach
provides a foundation for developing more accurate risk stratification tools
and tailoring preventative care strategies. In clinical settings, this
translates to the potential for earlier disease detection, more timely
interventions, and ultimately, a shift towards personalized healthcare.

摘要：血液生物標記是醫療保健提供者用於診斷、監測和治療各種疾病的重要工具。目前的參考值和建議範圍通常依賴於人群統計數據，而這些數據可能無法充分說明由生活方式和基因等因素驅動的個體間變異的影響。在這項工作中，我們引入了一個新的框架來預測未來的血液生物標記值，並通過從生活方式數據（身體活動和睡眠）和血液生物標記中學習到的表徵來定義個性化參考。我們提出的方法學習了一個基於相似性的嵌入空間，該空間捕捉了生物標記和生活方式因素之間的複雜關係。使用英國生物銀行（257K 參與者），我們的結果表明，我們深度學習的嵌入優於傳統和當前最先進的表徵學習技術，可以預測臨床診斷。使用擁有後續訪視的 6440 名參與者的英國生物銀行子集，我們驗證了在血液生物標記模型中直接包含這些嵌入和生活方式因素可以改善從單次實驗室訪問中預測未來實驗室值。這種個性化建模方法為開發更準確的風險分層工具和定制預防保健策略提供了基礎。在臨床環境中，這轉化為早期疾病檢測、更及時的干預，最終轉向個性化醫療保健的潛力。

##### **ProtoSAM -- One Shot Medical Image Segmentation With Foundational Models**
2407.07042v1 by Lev Ayzenberg, Raja Giryes, Hayit Greenspan

This work introduces a new framework, ProtoSAM, for one-shot medical image
segmentation. It combines the use of prototypical networks, known for few-shot
segmentation, with SAM - a natural image foundation model. The method proposed
creates an initial coarse segmentation mask using the ALPnet prototypical
network, augmented with a DINOv2 encoder. Following the extraction of an
initial mask, prompts are extracted, such as points and bounding boxes, which
are then input into the Segment Anything Model (SAM). State-of-the-art results
are shown on several medical image datasets and demonstrate automated
segmentation capabilities using a single image example (one shot) with no need
for fine-tuning of the foundation model.

摘要：本研究提出一個新的架構，ProtoSAM，用於一次性醫學影像分割。它結合了原型網路的使用，以進行少次分割，以及 SAM - 一個自然影像基礎模型。所提出的方法使用 ALPnet 原型網路建立一個初始的粗略分割遮罩，並使用 DINOv2 編碼器進行擴充。在提取初始遮罩後，會提取提示，例如點和邊界框，然後將其輸入到 Segment Anything Model (SAM) 中。在多個醫學影像資料集上顯示了最先進的結果，並展示了使用單一影像範例（一次性）的自動分割功能，無需微調基礎模型。

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

摘要：人工智能 (AI) 支持的決策制定是未來 6G 網路中的關鍵元素，其中將引入原生 AI 的概念。此外，AI 廣泛用於不同的關鍵應用中，例如自動駕駛和醫療診斷。在這些應用中，使用 AI 作為黑盒模型是有風險且具有挑戰性的。因此，理解和信任這些模型做出的決策至關重要。解決此問題的方法是開發可解釋 AI (XAI) 架構，旨在解釋黑盒模型行為背後的邏輯，從而確保其有效且安全的部署。最近，我們提出了一個新的基於擾動的 XAI-CHEST 框架，該框架面向無線通信中的信道估計。XAI-CHEST 框架的核心思想是通過在無關輸入上引入高噪聲來識別相關模型輸入。這份手稿提供了 XAI-CHEST 框架的詳細理論基礎。特別是，我們推導了 XAI-CHEST 損失函數和噪聲閾值微調優化問題的解析表達式。因此，設計的 XAI-CHEST 提供了一種智能輸入特徵選擇方法，可以在優化所用模型的架構的同時進一步提高整體性能。模擬結果表明，XAI-CHEST 框架提供了有效的解釋，在降低所需的計算複雜度的同時，提供了改進的比特錯誤率性能，而這與基於傳統 DL 的信道估計相比。

##### **Microsoft Cloud-based Digitization Workflow with Rich Metadata Acquisition for Cultural Heritage Objects**
2407.06972v1 by Krzysztof Kutt, Jakub Gomułka, Luiz do Valle Miranda, Grzegorz J. Nalepa

In response to several cultural heritage initiatives at the Jagiellonian
University, we have developed a new digitization workflow in collaboration with
the Jagiellonian Library (JL). The solution is based on easy-to-access
technological solutions -- Microsoft 365 cloud with MS Excel files as metadata
acquisition interfaces, Office Script for validation, and MS Sharepoint for
storage -- that allows metadata acquisition by domain experts (philologists,
historians, philosophers, librarians, archivists, curators, etc.) regardless of
their experience with information systems. The ultimate goal is to create a
knowledge graph that describes the analyzed holdings, linked to general
knowledge bases, as well as to other cultural heritage collections, so careful
attention is paid to the high accuracy of metadata and proper links to external
sources. The workflow has already been evaluated in two pilots in the DiHeLib
project focused on digitizing the so-called "Berlin Collection" and in two
workshops with international guests, which allowed for its refinement and
confirmation of its correctness and usability for JL. As the proposed workflow
does not interfere with existing systems or domain guidelines regarding
digitization and basic metadata collection in a given institution (e.g., file
type, image quality, use of Dublin Core/MARC-21), but extends them in order to
enable rich metadata collection, not previously possible, we believe that it
could be of interest to all GLAMs (galleries, libraries, archives, and
museums).

摘要：<paragraph>為回應 Jagiello 大學的數個文化遺產倡議，我們與 Jagiello 圖書館 (JL) 合作開發一個新的數位化工作流程。此解決方案基於易於存取的技術解決方案，包括：作為元資料擷取介面的 Microsoft 365 雲端與 MS Excel 檔案、用於驗證的 Office Script，以及用於儲存的 MS Sharepoint，它允許領域專家（語言學家、歷史學家、哲學家、圖書館員、檔案管理員、策展人等）擷取元資料，而無須具備資訊系統方面的經驗。最終目標是建立一個知識圖譜，用以描述所分析的館藏，並連結至一般知識庫，以及其他文化遺產館藏，因此我們非常重視元資料的高準確性，以及與外部來源的適當連結。此工作流程已在 DiHeLib 專案中兩個試點計畫中進行評估，該專案專注於數位化所謂的「柏林館藏」，以及與國際訪客進行的兩個工作坊，這讓我們得以改善工作流程，並確認其正確性，以及對 JL 的可用性。由於所提出的工作流程不會干擾既有系統或關於數位化和基本元資料蒐集的領域指南（例如，檔案類型、影像品質、使用 Dublin Core/MARC-21），而是擴充這些系統，以支援以前無法進行的豐富元資料蒐集，因此我們相信它可能會引起所有 GLAM（畫廊、圖書館、檔案館和博物館）的興趣。</paragraph>

##### **TE-SSL: Time and Event-aware Self Supervised Learning for Alzheimer's Disease Progression Analysis**
2407.06852v1 by Jacob Thrasher, Alina Devkota, Ahmed Tafti, Binod Bhattarai, Prashnna Gyawali

Alzheimer's Dementia (AD) represents one of the most pressing challenges in
the field of neurodegenerative disorders, with its progression analysis being
crucial for understanding disease dynamics and developing targeted
interventions. Recent advancements in deep learning and various representation
learning strategies, including self-supervised learning (SSL), have shown
significant promise in enhancing medical image analysis, providing innovative
ways to extract meaningful patterns from complex data. Notably, the computer
vision literature has demonstrated that incorporating supervisory signals into
SSL can further augment model performance by guiding the learning process with
additional relevant information. However, the application of such supervisory
signals in the context of disease progression analysis remains largely
unexplored. This gap is particularly pronounced given the inherent challenges
of incorporating both event and time-to-event information into the learning
paradigm. Addressing this, we propose a novel framework, Time and Even-aware
SSL (TE-SSL), which integrates time-to-event and event data as supervisory
signals to refine the learning process. Our comparative analysis with existing
SSL-based methods in the downstream task of survival analysis shows superior
performance across standard metrics.

摘要：阿茲海默症失智症 (AD) 是神經退化性疾病領域中最迫切的挑戰之一，其進程分析對於了解疾病動態和開發目標性干預措施至關重要。深度學習和各種表示學習策略（包括自監督學習 (SSL)）的最新進展，已在增強醫學影像分析方面展現顯著前景，提供從複雜資料中提取有意義模式的創新方法。值得注意的是，電腦視覺文獻已證明將監督訊號納入 SSL 可以透過提供額外相關資訊來指導學習過程，進一步增強模型效能。然而，此類監督訊號在疾病進程分析中的應用仍未得到充分探討。由於將事件和事件時間資訊納入學習範例的固有挑戰，此差距特別明顯。針對此問題，我們提出一個創新的架構，時間和事件感知 SSL (TE-SSL)，它整合事件時間和事件資料作為監督訊號，以優化學習過程。我們在生存分析的下游任務中，對其與現有基於 SSL 的方法進行比較分析，顯示其在標準指標上的效能優異。

##### **VRDSynth: Synthesizing Programs for Multilingual Visually Rich Document Information Extraction**
2407.06826v1 by Thanh-Dat Nguyen, Tung Do-Viet, Hung Nguyen-Duy, Tuan-Hai Luu, Hung Le, Bach Le, Patanamon, Thongtanunam

Businesses need to query visually rich documents (VRDs) like receipts,
medical records, and insurance forms to make decisions. Existing techniques for
extracting entities from VRDs struggle with new layouts or require extensive
pre-training data. We introduce VRDSynth, a program synthesis method to
automatically extract entity relations from multilingual VRDs without
pre-training data. To capture the complexity of VRD domain, we design a
domain-specific language (DSL) to capture spatial and textual relations to
describe the synthesized programs. Along with this, we also derive a new
synthesis algorithm utilizing frequent spatial relations, search space pruning,
and a combination of positive, negative, and exclusive programs to improve
coverage.
  We evaluate VRDSynth on the FUNSD and XFUND benchmarks for semantic entity
linking, consisting of 1,592 forms in 8 languages. VRDSynth outperforms
state-of-the-art pre-trained models (LayoutXLM, InfoXLMBase, and
XLMRobertaBase) in 5, 6, and 7 out of 8 languages, respectively, improving the
F1 score by 42% over LayoutXLM in English. To test the extensibility of the
model, we further improve VRDSynth with automated table recognition, creating
VRDSynth(Table), and compare it with extended versions of the pre-trained
models, InfoXLM(Large) and XLMRoberta(Large). VRDSynth(Table) outperforms these
baselines in 4 out of 8 languages and in average F1 score. VRDSynth also
significantly reduces memory footprint (1M and 380MB vs. 1.48GB and 3GB for
LayoutXLM) while maintaining similar time efficiency.

摘要：<paragraph>企業需要查詢視覺豐富的文件 (VRD)，例如收據、醫療記錄和保險單據，才能做出決策。現有的技術用於從 VRD 中提取實體，會遇到新的版面問題，或者需要大量的預訓練數據。我們介紹 VRDSynth，這是一種程式合成方法，可以在沒有預訓練數據的情況下自動從多語言 VRD 中提取實體關係。為了捕捉 VRD 領域的複雜性，我們設計了一個特定領域語言 (DSL)，用於捕捉空間和文字關係，以描述合成的程式。除此之外，我們還推導出一個新的合成演算法，利用頻繁的空間關係、搜尋空間剪枝，以及正、負和排他程式的組合，以改善涵蓋範圍。
我們在 FUNSD 和 XFUND 基準上評估 VRDSynth，用於語義實體連結，包含 8 種語言的 1,592 個表單。VRDSynth 在 8 種語言中的 5、6 和 7 種語言中優於最先進的預訓練模型 (LayoutXLM、InfoXLMBase 和 XLMRobertaBase)，分別將英文中的 F1 分數提高了 42%，高於 LayoutXLM。為了測試模型的可擴充性，我們進一步改進 VRDSynth，採用自動化表格識別，建立 VRDSynth(Table)，並將其與預訓練模型 InfoXLM(Large) 和 XLMRoberta(Large) 的延伸版本進行比較。VRDSynth(Table) 在 8 種語言中的 4 種語言和平均 F1 分數中優於這些基準。VRDSynth 還顯著減少了記憶體使用量 (1M 和 380MB，而 LayoutXLM 為 1.48GB 和 3GB)，同時維持類似的時間效率。</paragraph>

##### **iASiS: Towards Heterogeneous Big Data Analysis for Personalized Medicine**
2407.06748v1 by Anastasia Krithara, Fotis Aisopos, Vassiliki Rentoumi, Anastasios Nentidis, Konstantinos Bougatiotis, Maria-Esther Vidal, Ernestina Menasalvas, Alejandro Rodriguez-Gonzalez, Eleftherios G. Samaras, Peter Garrard, Maria Torrente, Mariano Provencio Pulla, Nikos Dimakopoulos, Rui Mauricio, Jordi Rambla De Argila, Gian Gaetano Tartaglia, George Paliouras

The vision of IASIS project is to turn the wave of big biomedical data
heading our way into actionable knowledge for decision makers. This is achieved
by integrating data from disparate sources, including genomics, electronic
health records and bibliography, and applying advanced analytics methods to
discover useful patterns. The goal is to turn large amounts of available data
into actionable information to authorities for planning public health
activities and policies. The integration and analysis of these heterogeneous
sources of information will enable the best decisions to be made, allowing for
diagnosis and treatment to be personalised to each individual. The project
offers a common representation schema for the heterogeneous data sources. The
iASiS infrastructure is able to convert clinical notes into usable data,
combine them with genomic data, related bibliography, image data and more, and
create a global knowledge base. This facilitates the use of intelligent methods
in order to discover useful patterns across different resources. Using semantic
integration of data gives the opportunity to generate information that is rich,
auditable and reliable. This information can be used to provide better care,
reduce errors and create more confidence in sharing data, thus providing more
insights and opportunities. Data resources for two different disease categories
are explored within the iASiS use cases, dementia and lung cancer.

摘要：IASIS 項目的願景是將朝我們而來的龐大生物醫學數據浪潮轉變為決策者的可行知識。這是透過整合來自不同來源的數據（包括基因組學、電子健康記錄和書目），並應用先進的分析方法來發現有用的模式來實現的。目標是將大量可用數據轉化為可行的資訊，供當局規劃公共衛生活動和政策。整合和分析這些異質的資訊來源將使最佳決策得以制定，並允許對每個人的診斷和治療進行個人化。該專案為異質數據來源提供了一個共同的表示架構。iASiS 基礎設施能夠將臨床筆記轉換為可用數據，將其與基因組數據、相關書目、影像數據等結合起來，並建立一個全球知識庫。這有助於使用智慧方法來發現不同資源之間的有用模式。使用數據的語義整合提供了產生豐富、可稽核且可靠資訊的機會。這些資訊可用於提供更好的照護、減少錯誤，並對資料共享建立更多信心，從而提供更多見解和機會。在 iASiS 的使用案例中，探討了兩種不同疾病類別的數據資源，即失智症和肺癌。

##### **TCKIN: A Novel Integrated Network Model for Predicting Mortality Risk in Sepsis Patients**
2407.06560v1 by Fanglin Dong

Sepsis poses a major global health threat, accounting for millions of deaths
annually and significant economic costs. Accurate predictions of mortality risk
in sepsis patients facilitate the efficient allocation of medical resources,
thereby enhancing patient survival and quality of life. Through precise risk
assessments, healthcare facilities can effectively distribute intensive care
beds, medical equipment, and staff, ensuring high-risk patients receive timely
and appropriate care. Early identification and intervention significantly
decrease mortality rates and improve patient outcomes. Current methods
typically utilize only one type of data--either constant, temporal, or ICD
codes. This study introduces the Time-Constant KAN Integrated Network(TCKIN),
an innovative model that enhances the accuracy of sepsis mortality risk
predictions by integrating both temporal and constant data from electronic
health records and ICD codes. Validated against the MIMIC-III and MIMIC-IV
datasets, TCKIN surpasses existing machine learning and deep learning methods
in accuracy, sensitivity, and specificity. Notably, TCKIN achieved AUCs of
87.76% and 88.07%, demonstrating superior capability in identifying high-risk
patients. Additionally, TCKIN effectively combats the prevalent issue of data
imbalance in clinical settings, improving the detection of patients at elevated
risk of mortality and facilitating timely interventions. These results confirm
the model's effectiveness and its potential to transform patient management and
treatment optimization in clinical practice. With this advanced risk assessment
tool, healthcare providers can devise more tailored treatment plans, optimize
resource utilization, and ultimately enhance survival rates and quality of life
for sepsis patients.

摘要：<paragraph>敗血症構成全球主要的健康威脅，每年造成數百萬人死亡，並帶來龐大的經濟成本。準確預測敗血症患者的死亡風險，有助於有效分配醫療資源，從而提升患者存活率和生活品質。透過精確的風險評估，醫療機構可以有效分配加護病房病床、醫療設備和人員，確保高風險患者能及時獲得適當的照護。早期發現和介入可以顯著降低死亡率，並改善患者預後。目前的方法通常僅使用一種類型的資料，例如常數、時間或 ICD 編碼。本研究引入了時間常數 KAN 整合網路 (TCKIN)，這是一個創新的模型，透過整合電子健康紀錄和 ICD 編碼中的時間和常數資料，來提升敗血症死亡風險預測的準確性。在 MIMIC-III 和 MIMIC-IV 資料集驗證下，TCKIN 在準確性、敏感性和特異性方面都超越了現有的機器學習和深度學習方法。值得注意的是，TCKIN 達到了 87.76% 和 88.07% 的 AUC，顯示出優異的識別高風險患者能力。此外，TCKIN 有效地解決了臨床環境中普遍存在的資料不平衡問題，改善了對死亡風險較高的患者的檢測，並促進及時介入。這些結果證實了該模型的有效性，以及其在臨床實務中轉化患者管理和優化治療的潛力。有了這個進階的風險評估工具，醫療保健提供者可以制定更客製化的治療計畫，最佳化資源利用，並最終提升敗血症患者的存活率和生活品質。</paragraph>

##### **AI-driven multi-omics integration for multi-scale predictive modeling of causal genotype-environment-phenotype relationships**
2407.06405v1 by You Wu, Lei Xie

Despite the wealth of single-cell multi-omics data, it remains challenging to
predict the consequences of novel genetic and chemical perturbations in the
human body. It requires knowledge of molecular interactions at all biological
levels, encompassing disease models and humans. Current machine learning
methods primarily establish statistical correlations between genotypes and
phenotypes but struggle to identify physiologically significant causal factors,
limiting their predictive power. Key challenges in predictive modeling include
scarcity of labeled data, generalization across different domains, and
disentangling causation from correlation. In light of recent advances in
multi-omics data integration, we propose a new artificial intelligence
(AI)-powered biology-inspired multi-scale modeling framework to tackle these
issues. This framework will integrate multi-omics data across biological
levels, organism hierarchies, and species to predict causal
genotype-environment-phenotype relationships under various conditions. AI
models inspired by biology may identify novel molecular targets, biomarkers,
pharmaceutical agents, and personalized medicines for presently unmet medical
needs.

摘要：儘管有豐富的單細胞多組學資料，但預測人體中新的遺傳和化學擾動的後果仍然具有挑戰性。這需要了解所有生物層級的分子交互作用，包括疾病模型和人類。目前的機器學習方法主要建立基因型和表型之間的統計相關性，但難以識別生理上重要的因果因素，從而限制了其預測能力。預測建模中的主要挑戰包括標記資料的稀缺性、跨不同領域的概化，以及將因果關係從相關性中解開。鑑於多組學資料整合的最新進展，我們提出了一個新的由人工智慧 (AI) 驅動的、受生物啟發的多尺度建模框架來解決這些問題。此框架將整合跨生物層級、生物體層級和物種的多組學資料，以預測在各種條件下的因果基因型-環境-表型關係。受生物啟發的 AI 模型可能會識別出新的分子靶標、生物標記、藥物和個性化藥物，以滿足目前尚未滿足的醫療需求。

##### **Multimodal Chain-of-Thought Reasoning via ChatGPT to Protect Children from Age-Inappropriate Apps**
2407.06309v1 by Chuanbo Hu, Bin Liu, Minglei Yin, Yilu Zhou, Xin Li

Mobile applications (Apps) could expose children to inappropriate themes such
as sexual content, violence, and drug use. Maturity rating offers a quick and
effective method for potential users, particularly guardians, to assess the
maturity levels of apps. Determining accurate maturity ratings for mobile apps
is essential to protect children's health in today's saturated digital
marketplace. Existing approaches to maturity rating are either inaccurate
(e.g., self-reported rating by developers) or costly (e.g., manual
examination). In the literature, there are few text-mining-based approaches to
maturity rating. However, each app typically involves multiple modalities,
namely app description in the text, and screenshots in the image. In this
paper, we present a framework for determining app maturity levels that utilize
multimodal large language models (MLLMs), specifically ChatGPT-4 Vision.
Powered by Chain-of-Thought (CoT) reasoning, our framework systematically
leverages ChatGPT-4 to process multimodal app data (i.e., textual descriptions
and screenshots) and guide the MLLM model through a step-by-step reasoning
pathway from initial content analysis to final maturity rating determination.
As a result, through explicitly incorporating CoT reasoning, our framework
enables ChatGPT to understand better and apply maturity policies to facilitate
maturity rating. Experimental results indicate that the proposed method
outperforms all baseline models and other fusion strategies.

摘要：行動應用程式 (App) 可能讓兒童接觸到不適當的主題，例如性內容、暴力和藥物使用。成熟度評分提供一種快速且有效的方法，讓潛在使用者，尤其是監護人，評估應用程式的成熟度等級。在當今飽和的數位市場中，為行動應用程式確定準確的成熟度評分對於保護兒童健康至關重要。現有的成熟度評分方法不是不準確（例如，開發人員自行報告的評分），就是成本高昂（例如，人工審查）。在文獻中，很少有基於文字探勘的方法來評估成熟度。然而，每個應用程式通常涉及多種模式，即文字中的應用程式說明和影像中的螢幕截圖。在本文中，我們提出一個框架，用於確定應用程式的成熟度等級，該框架利用多模態大型語言模型 (MLLM)，特別是 ChatGPT-4 Vision。我們的框架採用思維鏈 (CoT) 推理為基礎，系統性地利用 ChatGPT-4 處理多模態應用程式資料（即文字說明和螢幕截圖），並引導 MLLM 模型逐步進行推理路徑，從初始內容分析到最終成熟度評分確定。因此，透過明確納入 CoT 推理，我們的框架使 ChatGPT 能夠更深入地了解並應用成熟度政策來促進成熟度評分。實驗結果表明，所提出的方法優於所有基線模型和其他融合策略。

##### **Hybrid X-Linker: Automated Data Generation and Extreme Multi-label Ranking for Biomedical Entity Linking**
2407.06292v1 by Pedro Ruas, Fernando Gallego, Francisco J. Veredas, Francisco M. Couto

State-of-the-art deep learning entity linking methods rely on extensive
human-labelled data, which is costly to acquire. Current datasets are limited
in size, leading to inadequate coverage of biomedical concepts and diminished
performance when applied to new data. In this work, we propose to automatically
generate data to create large-scale training datasets, which allows the
exploration of approaches originally developed for the task of extreme
multi-label ranking in the biomedical entity linking task. We propose the
hybrid X-Linker pipeline that includes different modules to link disease and
chemical entity mentions to concepts in the MEDIC and the CTD-Chemical
vocabularies, respectively. X-Linker was evaluated on several biomedical
datasets: BC5CDR-Disease, BioRED-Disease, NCBI-Disease, BC5CDR-Chemical,
BioRED-Chemical, and NLM-Chem, achieving top-1 accuracies of 0.8307, 0.7969,
0.8271, 0.9511, 0.9248, and 0.7895, respectively. X-Linker demonstrated
superior performance in three datasets: BC5CDR-Disease, NCBI-Disease, and
BioRED-Chemical. In contrast, SapBERT outperformed X-Linker in the remaining
three datasets. Both models rely only on the mention string for their
operations. The source code of X-Linker and its associated data are publicly
available for performing biomedical entity linking without requiring
pre-labelled entities with identifiers from specific knowledge organization
systems.

摘要：最先進的深度學習實體連結方法依賴於大量的
人工標籤資料，而這類資料的取得成本很高。目前的資料集
大小有限，導致生物醫學概念涵蓋不足，在應用於新資料時效能降低。在這項工作中，我們提議自動
產生資料，以建立大規模的訓練資料集，這允許探索原本是為生物醫學實體連結任務中極端多標籤排名任務而開發的方法。我們提議混合 X-Linker 管線，其中包含不同的模組，分別將疾病和化學實體提及連結到 MEDIC 和 CTD-Chemical 字彙中的概念。X-Linker 已在多個生物醫學資料集上進行評估：BC5CDR-Disease、BioRED-Disease、NCBI-Disease、BC5CDR-Chemical、BioRED-Chemical 和 NLM-Chem，分別達到 0.8307、0.7969、0.8271、0.9511、0.9248 和 0.7895 的 top-1 準確度。X-Linker 在三個資料集：BC5CDR-Disease、NCBI-Disease 和 BioRED-Chemical 中表現出優異的效能。相反地，SapBERT 在其餘三個資料集中優於 X-Linker。兩個模型僅依賴於它們操作的提及字串。X-Linker 和其相關資料的原始程式碼公開提供，可執行生物醫學實體連結，而無需特定知識組織系統中識別符號的預先標籤實體。

##### **Depression Detection and Analysis using Large Language Models on Textual and Audio-Visual Modalities**
2407.06125v1 by Avinash Anand, Chayan Tank, Sarthak Pol, Vinayak Katoch, Shaina Mehta, Rajiv Ratn Shah

Depression has proven to be a significant public health issue, profoundly
affecting the psychological well-being of individuals. If it remains
undiagnosed, depression can lead to severe health issues, which can manifest
physically and even lead to suicide. Generally, Diagnosing depression or any
other mental disorder involves conducting semi-structured interviews alongside
supplementary questionnaires, including variants of the Patient Health
Questionnaire (PHQ) by Clinicians and mental health professionals. This
approach places significant reliance on the experience and judgment of trained
physicians, making the diagnosis susceptible to personal biases. Given that the
underlying mechanisms causing depression are still being actively researched,
physicians often face challenges in diagnosing and treating the condition,
particularly in its early stages of clinical presentation. Recently,
significant strides have been made in Artificial neural computing to solve
problems involving text, image, and speech in various domains. Our analysis has
aimed to leverage these state-of-the-art (SOTA) models in our experiments to
achieve optimal outcomes leveraging multiple modalities. The experiments were
performed on the Extended Distress Analysis Interview Corpus Wizard of Oz
dataset (E-DAIC) corpus presented in the Audio/Visual Emotion Challenge (AVEC)
2019 Challenge. The proposed solutions demonstrate better results achieved by
Proprietary and Open-source Large Language Models (LLMs), which achieved a Root
Mean Square Error (RMSE) score of 3.98 on Textual Modality, beating the AVEC
2019 challenge baseline results and current SOTA regression analysis
architectures. Additionally, the proposed solution achieved an accuracy of
71.43% in the classification task. The paper also includes a novel audio-visual
multi-modal network that predicts PHQ-8 scores with an RMSE of 6.51.

摘要：憂鬱症已被證實是一個重大的公共衛生議題，深刻影響個人心理健康。如果憂鬱症未經診斷，可能會導致嚴重的健康問題，這些問題可能在生理上顯現，甚至導致自殺。通常，診斷憂鬱症或任何其他精神疾病都涉及進行半結構化訪談，以及補充問卷，包括臨床醫生和心理健康專業人員所使用的患者健康問卷 (PHQ) 變體。這種方法非常依賴受過訓練的醫師的經驗和判斷，使診斷容易受到個人偏見的影響。由於導致憂鬱症的潛在機制仍在積極研究中，因此醫師在診斷和治療這種疾病時經常面臨挑戰，尤其是在臨床表現的早期階段。最近，人工神經運算在解決涉及文本、影像和語言的各種領域問題方面取得了重大進展。我們的分析旨在利用這些最先進 (SOTA) 模型在我們的實驗中，透過利用多種模式來達成最佳結果。這些實驗是在 Audio/Visual Emotion Challenge (AVEC) 2019 Challenge 中提出的 Extended Distress Analysis Interview Corpus Wizard of Oz 資料集 (E-DAIC) 語料庫上進行的。所提出的解決方案證明了專有和開放原始碼大型語言模型 (LLM) 所取得的較佳結果，這些模型在文本模式上達到了 3.98 的均方根誤差 (RMSE) 分數，優於 AVEC 2019 挑戰基準結果和目前的 SOTA 回歸分析架構。此外，所提出的解決方案在分類任務中達到了 71.43% 的準確率。本文還包括一個新穎的音訊視覺多模式網路，其使用 6.51 的 RMSE 預測 PHQ-8 分數。

##### **Igea: a Decoder-Only Language Model for Biomedical Text Generation in Italian**
2407.06011v1 by Tommaso Mario Buonocore, Simone Rancati, Enea Parimbelli

The development of domain-specific language models has significantly advanced
natural language processing applications in various specialized fields,
particularly in biomedicine. However, the focus has largely been on
English-language models, leaving a gap for less-resourced languages such as
Italian. This paper introduces Igea, the first decoder-only language model
designed explicitly for biomedical text generation in Italian. Built on the
Minerva model and continually pretrained on a diverse corpus of Italian medical
texts, Igea is available in three model sizes: 350 million, 1 billion, and 3
billion parameters. The models aim to balance computational efficiency and
performance, addressing the challenges of managing the peculiarities of medical
terminology in Italian. We evaluate Igea using a mix of in-domain biomedical
corpora and general-purpose benchmarks, highlighting its efficacy and retention
of general knowledge even after the domain-specific training. This paper
discusses the model's development and evaluation, providing a foundation for
future advancements in Italian biomedical NLP.

摘要：特定領域語言模型的發展已大幅提升了各種專業領域的自然語言處理應用，特別是在生物醫學領域。然而，目前的研究重點主要放在英語語言模型上，這對義大利語等資源較少的語言來說是一大缺憾。本文介紹了 Igea，這是第一個專門設計用於義大利語生物醫學文本生成的僅解碼器語言模型。Igea 建構在 Minerva 模型上，並持續在大量義大利醫學文本語料庫上進行預訓練，提供三種模型大小：3.5 億、10 億和 30 億個參數。這些模型旨在平衡運算效率和效能，解決處理義大利語醫學術語特性的挑戰。我們使用混合領域生物醫學語料庫和通用基準對 Igea 進行評估，強調了其功效和在特定領域訓練後仍能保留一般知識。本文探討了模型的開發和評估，為義大利語生物醫學自然語言處理的未來進展奠定了基礎。

##### **Generation and De-Identification of Indian Clinical Discharge Summaries using LLMs**
2407.05887v1 by Sanjeet Singh, Shreya Gupta, Niralee Gupta, Naimish Sharma, Lokesh Srivastava, Vibhu Agarwal, Ashutosh Modi

The consequences of a healthcare data breach can be devastating for the
patients, providers, and payers. The average financial impact of a data breach
in recent months has been estimated to be close to USD 10 million. This is
especially significant for healthcare organizations in India that are managing
rapid digitization while still establishing data governance procedures that
align with the letter and spirit of the law. Computer-based systems for
de-identification of personal information are vulnerable to data drift, often
rendering them ineffective in cross-institution settings. Therefore, a rigorous
assessment of existing de-identification against local health datasets is
imperative to support the safe adoption of digital health initiatives in India.
Using a small set of de-identified patient discharge summaries provided by an
Indian healthcare institution, in this paper, we report the nominal performance
of de-identification algorithms (based on language models) trained on publicly
available non-Indian datasets, pointing towards a lack of cross-institutional
generalization. Similarly, experimentation with off-the-shelf de-identification
systems reveals potential risks associated with the approach. To overcome data
scarcity, we explore generating synthetic clinical reports (using publicly
available and Indian summaries) by performing in-context learning over Large
Language Models (LLMs). Our experiments demonstrate the use of generated
reports as an effective strategy for creating high-performing de-identification
systems with good generalization capabilities.

摘要：醫療保健資料外洩的後果對患者、提供者和付款者來說可能是毀滅性的。最近幾個月資料外洩的平均財務影響估計接近 1,000 萬美元。這對印度的醫療保健組織來說尤其重要，這些組織在管理快速數位化的同時，仍在建立符合法律條文和精神的資料治理程序。用於去識別個人資訊的電腦系統容易受到資料漂移的影響，通常導致它們在跨機構設定中無效。因此，必須嚴格評估現有的去識別與當地健康資料集，才能支援印度安全採用數位健康計畫。本文使用印度醫療保健機構提供的一小組去識別患者出院摘要，報告了在公開可用的非印度資料集上訓練的去識別演算法（基於語言模型）的標稱效能，指出缺乏跨機構概化。同樣地，對現成的去識別系統進行實驗揭示了與該方法相關的潛在風險。為了克服資料稀少的問題，我們探討透過在大語言模型 (LLM) 上執行情境學習來產生合成臨床報告（使用公開可用的印度摘要）。我們的實驗證明了使用產生的報告作為建立具有良好概化能力的高效能去識別系統的有效策略。

##### **Integrating AI in College Education: Positive yet Mixed Experiences with ChatGPT**
2407.05810v1 by Xinrui Song, Jiajin Zhang, Pingkun Yan, Juergen Hahn, Uwe Kruger, Hisham Mohamed, Ge Wang

The integration of artificial intelligence (AI) chatbots into higher
education marks a shift towards a new generation of pedagogical tools,
mirroring the arrival of milestones like the internet. With the launch of
ChatGPT-4 Turbo in November 2023, we developed a ChatGPT-based teaching
application (https://chat.openai.com/g/g-1imx1py4K-chatge-medical-imaging) and
integrated it into our undergraduate medical imaging course in the Spring 2024
semester. This study investigates the use of ChatGPT throughout a semester-long
trial, providing insights into students' engagement, perception, and the
overall educational effectiveness of the technology. We systematically
collected and analyzed data concerning students' interaction with ChatGPT,
focusing on their attitudes, concerns, and usage patterns. The findings
indicate that ChatGPT offers significant advantages such as improved
information access and increased interactivity, but its adoption is accompanied
by concerns about the accuracy of the information provided and the necessity
for well-defined guidelines to optimize its use.

摘要：人工智能（AI）聊天機器人整合到高等教育中，標誌著新一代教學工具的轉變，反映了網路等里程碑的到來。隨著 ChatGPT-4 Turbo 在 2023 年 11 月推出，我們開發了一個基於 ChatGPT 的教學應用程式（https://chat.openai.com/g/g-1imx1py4K-chatge-medical-imaging），並在 2024 年春季學期將其整合到我們的醫學影像學本科課程中。本研究調查了在一個學期長的試驗中使用 ChatGPT 的情況，深入了解學生的參與度、看法和技術的整體教育效果。我們系統地收集和分析了有關學生與 ChatGPT 互動的資料，重點關注他們的態度、疑慮和使用模式。研究結果表明，ChatGPT 提供了顯著的優勢，例如改進資訊的取得和增加互動性，但其採用也伴隨著對所提供資訊準確性的疑慮，以及最佳化其使用的明確準則的必要性。

##### **FedMRL: Data Heterogeneity Aware Federated Multi-agent Deep Reinforcement Learning for Medical Imaging**
2407.05800v1 by Pranab Sahoo, Ashutosh Tripathi, Sriparna Saha, Samrat Mondal

Despite recent advancements in federated learning (FL) for medical image
diagnosis, addressing data heterogeneity among clients remains a significant
challenge for practical implementation. A primary hurdle in FL arises from the
non-IID nature of data samples across clients, which typically results in a
decline in the performance of the aggregated global model. In this study, we
introduce FedMRL, a novel federated multi-agent deep reinforcement learning
framework designed to address data heterogeneity. FedMRL incorporates a novel
loss function to facilitate fairness among clients, preventing bias in the
final global model. Additionally, it employs a multi-agent reinforcement
learning (MARL) approach to calculate the proximal term $(\mu)$ for the
personalized local objective function, ensuring convergence to the global
optimum. Furthermore, FedMRL integrates an adaptive weight adjustment method
using a Self-organizing map (SOM) on the server side to counteract distribution
shifts among clients' local data distributions. We assess our approach using
two publicly available real-world medical datasets, and the results demonstrate
that FedMRL significantly outperforms state-of-the-art techniques, showing its
efficacy in addressing data heterogeneity in federated learning. The code can
be found here~{\url{https://github.com/Pranabiitp/FedMRL}}.

摘要：儘管在用於醫學影像診斷的聯邦學習 (FL) 方面有近期的進展，但解決客戶端之間的資料異質性仍然是實際執行的重大挑戰。聯邦學習的主要障礙來自於客戶端之間資料樣本的非獨立同分布 (non-IID) 特性，這通常會導致彙總的全球模型效能下降。在本研究中，我們引入了 FedMRL，一個新穎的聯邦多智能體深度強化學習框架，旨在解決資料異質性。FedMRL 結合了一個新穎的損失函數，以促進客戶端之間的公平性，防止最終全球模型中的偏差。此外，它採用多智能體強化學習 (MARL) 方法來計算個性化局部目標函數的近端項 (μ)，確保收斂到全局最優值。此外，FedMRL 整合了一種自適應權重調整方法，在伺服器端使用自組織化對應 (SOM)，以抵消客戶端本地資料分佈之間的分布轉移。我們使用兩個公開可用的真實世界醫學資料集評估我們的做法，結果表明 FedMRL 明顯優於最先進的技術，顯示其在解決聯邦學習中資料異質性方面的效能。程式碼可以在這裡找到~{\url{https://github.com/Pranabiitp/FedMRL}}。

##### **Large Language Models for Judicial Entity Extraction: A Comparative Study**
2407.05786v1 by Atin Sakkeer Hussain, Anu Thomas

Domain-specific Entity Recognition holds significant importance in legal
contexts, serving as a fundamental task that supports various applications such
as question-answering systems, text summarization, machine translation,
sentiment analysis, and information retrieval specifically within case law
documents. Recent advancements have highlighted the efficacy of Large Language
Models in natural language processing tasks, demonstrating their capability to
accurately detect and classify domain-specific facts (entities) from
specialized texts like clinical and financial documents. This research
investigates the application of Large Language Models in identifying
domain-specific entities (e.g., courts, petitioner, judge, lawyer, respondents,
FIR nos.) within case law documents, with a specific focus on their aptitude
for handling domain-specific language complexity and contextual variations. The
study evaluates the performance of state-of-the-art Large Language Model
architectures, including Large Language Model Meta AI 3, Mistral, and Gemma, in
the context of extracting judicial facts tailored to Indian judicial texts.
Mistral and Gemma emerged as the top-performing models, showcasing balanced
precision and recall crucial for accurate entity identification. These findings
confirm the value of Large Language Models in judicial documents and
demonstrate how they can facilitate and quicken scientific research by
producing precise, organised data outputs that are appropriate for in-depth
examination.

摘要：領域特定實體辨識在法律脈絡中至關重要，作為支援各種應用程式的基礎任務，例如在案例法文件中進行問答系統、文字摘要、機器翻譯、情緒分析和資訊檢索。最近的進展突顯了大型語言模型在自然語言處理任務中的效能，展示了它們準確偵測和分類來自專業文本（例如臨床和財務文件）的領域特定事實（實體）的能力。本研究探討了大型語言模型在案例法文件中辨識領域特定實體（例如法院、請願人、法官、律師、答辯人、FIR 編號）的應用，特別關注它們處理領域特定語言複雜性和脈絡變化的能力。本研究評估了最先進的大型語言模型架構（包括 Large Language Model Meta AI 3、Mistral 和 Gemma）在提取針對印度司法文本量身打造的司法事實方面的效能。Mistral 和 Gemma 成為表現最佳的模型，展示了準確實體辨識至關重要的平衡精確度和召回率。這些發現證實了大型語言模型在司法文件中的價值，並展示了它們如何透過產生適用於深入檢驗的精確、有組織的資料輸出，來促進和加速科學研究。

##### **Potential of Multimodal Large Language Models for Data Mining of Medical Images and Free-text Reports**
2407.05758v1 by Yutong Zhang, Yi Pan, Tianyang Zhong, Peixin Dong, Kangni Xie, Yuxiao Liu, Hanqi Jiang, Zhengliang Liu, Shijie Zhao, Tuo Zhang, Xi Jiang, Dinggang Shen, Tianming Liu, Xin Zhang

Medical images and radiology reports are crucial for diagnosing medical
conditions, highlighting the importance of quantitative analysis for clinical
decision-making. However, the diversity and cross-source heterogeneity of these
data challenge the generalizability of current data-mining methods. Multimodal
large language models (MLLMs) have recently transformed many domains,
significantly affecting the medical field. Notably, Gemini-Vision-series
(Gemini) and GPT-4-series (GPT-4) models have epitomized a paradigm shift in
Artificial General Intelligence (AGI) for computer vision, showcasing their
potential in the biomedical domain. In this study, we evaluated the performance
of the Gemini, GPT-4, and 4 popular large models for an exhaustive evaluation
across 14 medical imaging datasets, including 5 medical imaging categories
(dermatology, radiology, dentistry, ophthalmology, and endoscopy), and 3
radiology report datasets. The investigated tasks encompass disease
classification, lesion segmentation, anatomical localization, disease
diagnosis, report generation, and lesion detection. Our experimental results
demonstrated that Gemini-series models excelled in report generation and lesion
detection but faces challenges in disease classification and anatomical
localization. Conversely, GPT-series models exhibited proficiency in lesion
segmentation and anatomical localization but encountered difficulties in
disease diagnosis and lesion detection. Additionally, both the Gemini series
and GPT series contain models that have demonstrated commendable generation
efficiency. While both models hold promise in reducing physician workload,
alleviating pressure on limited healthcare resources, and fostering
collaboration between clinical practitioners and artificial intelligence
technologies, substantial enhancements and comprehensive validations remain
imperative before clinical deployment.

摘要：<paragraph>醫學影像和放射科報告對診斷醫療狀況至關重要，突顯了定量分析在臨床決策中的重要性。然而，這些數據的多樣性和跨來源異質性挑戰了當前數據挖掘方法的概括性。多模態大型語言模型 (MLLM) 近來已轉變許多領域，對醫學領域影響重大。值得注意的是，Gemini-Vision 系列 (Gemini) 和 GPT-4 系列 (GPT-4) 模型已成為電腦視覺中人工通用智慧 (AGI) 的典範轉移，展示了它們在生物醫學領域的潛力。在這項研究中，我們評估了 Gemini、GPT-4 和 4 個熱門大型模型在 14 個醫療影像數據集上的廣泛評估表現，包括 5 個醫療影像類別（皮膚科、放射科、牙科、眼科和內視鏡檢查），以及 3 個放射科報告數據集。所調查的任務包括疾病分類、病灶分割、解剖定位、疾病診斷、報告生成和病灶檢測。我們的實驗結果表明，Gemini 系列模型在報告生成和病灶檢測方面表現出色，但在疾病分類和解剖定位方面面臨挑戰。相反，GPT 系列模型在病灶分割和解剖定位方面表現出熟練度，但在疾病診斷和病灶檢測方面遇到困難。此外，Gemini 系列和 GPT 系列都包含已證明具有可取生成效率的模型。儘管這兩種模型都有望減少醫師的工作量，減輕有限醫療保健資源的壓力，並促進臨床從業人員與人工智慧技術之間的合作，但在臨床部署之前，實質性的增強和全面的驗證仍然勢在必行。</paragraph>

##### **RadiomicsFill-Mammo: Synthetic Mammogram Mass Manipulation with Radiomics Features**
2407.05683v1 by Inye Na, Jonghun Kim, Eun Sook Ko, Hyunjin Park

Motivated by the question, "Can we generate tumors with desired attributes?''
this study leverages radiomics features to explore the feasibility of
generating synthetic tumor images. Characterized by its low-dimensional yet
biologically meaningful markers, radiomics bridges the gap between complex
medical imaging data and actionable clinical insights. We present
RadiomicsFill-Mammo, the first of the RadiomicsFill series, an innovative
technique that generates realistic mammogram mass images mirroring specific
radiomics attributes using masked images and opposite breast images, leveraging
a recent stable diffusion model. This approach also allows for the
incorporation of essential clinical variables, such as BI-RADS and breast
density, alongside radiomics features as conditions for mass generation.
Results indicate that RadiomicsFill-Mammo effectively generates diverse and
realistic tumor images based on various radiomics conditions. Results also
demonstrate a significant improvement in mass detection capabilities,
leveraging RadiomicsFill-Mammo as a strategy to generate simulated samples.
Furthermore, RadiomicsFill-Mammo not only advances medical imaging research but
also opens new avenues for enhancing treatment planning and tumor simulation.
Our code is available at https://github.com/nainye/RadiomicsFill.

摘要：<paragraph>本研究以「我們能生成具有所需屬性的腫瘤嗎？」這個問題為動機，利用放射特徵來探討生成合成腫瘤影像的可行性。放射特徵以其低維度且具有生物意義的標記為特徵，彌補了複雜醫學影像資料與可操作臨床見解之間的差距。我們提出 RadiomicsFill-Mammo，RadiomicsFill 系列的第一個，這是一種創新的技術，利用遮罩影像和對側乳房影像，並利用最近的穩定擴散模型，生成反映特定放射特徵屬性的逼真乳房攝影腫塊影像。這種方法還允許將基本臨床變數，例如 BI-RADS 和乳房密度，與放射特徵一起作為生成腫塊的條件。結果表明，RadiomicsFill-Mammo 能有效地根據各種放射條件生成多樣化且逼真的腫瘤影像。結果還證明了腫塊檢測能力的顯著提升，利用 RadiomicsFill-Mammo 作為生成模擬樣本的策略。此外，RadiomicsFill-Mammo 不僅推動了醫學影像研究，還為增強治療規劃和腫瘤模擬開闢了新途徑。我們的程式碼可在 https://github.com/nainye/RadiomicsFill 取得。</paragraph>

##### **WSI-VQA: Interpreting Whole Slide Images by Generative Visual Question Answering**
2407.05603v1 by Pingyi Chen, Chenglu Zhu, Sunyi Zheng, Honglin Li, Lin Yang

Whole slide imaging is routinely adopted for carcinoma diagnosis and
prognosis. Abundant experience is required for pathologists to achieve accurate
and reliable diagnostic results of whole slide images (WSI). The huge size and
heterogeneous features of WSIs make the workflow of pathological reading
extremely time-consuming. In this paper, we propose a novel framework (WSI-VQA)
to interpret WSIs by generative visual question answering. WSI-VQA shows
universality by reframing various kinds of slide-level tasks in a
question-answering pattern, in which pathologists can achieve
immunohistochemical grading, survival prediction, and tumor subtyping following
human-machine interaction. Furthermore, we establish a WSI-VQA dataset which
contains 8672 slide-level question-answering pairs with 977 WSIs. Besides the
ability to deal with different slide-level tasks, our generative model which is
named Wsi2Text Transformer (W2T) outperforms existing discriminative models in
medical correctness, which reveals the potential of our model to be applied in
the clinical scenario. Additionally, we also visualize the co-attention mapping
between word embeddings and WSIs as an intuitive explanation for diagnostic
results. The dataset and related code are available at
https://github.com/cpystan/WSI-VQA.

摘要：全切片影像通常用於癌症的診斷和預後。病理學家需要有豐富的經驗才能對全切片影像 (WSI) 做出準確且可靠的診斷結果。WSI 的尺寸龐大且特徵異質，使得病理學判讀的工作流程極為耗時。在本文中，我們提出了一個新的框架 (WSI-VQA)，透過生成式視覺問答來詮釋 WSI。WSI-VQA 透過在問答模式中重新定義各種切片層級任務，展現其通用性，病理學家可以在人機互動後，完成免疫組織化學分級、存活預測和腫瘤亞型分類。此外，我們建立了一個 WSI-VQA 資料集，其中包含 8672 個切片層級問答對，以及 977 個 WSI。除了能夠處理不同的切片層級任務外，我們名為 Wsi2Text Transformer (W2T) 的生成模型在醫學正確性方面優於現有的判別模型，這揭示了我們的模型在臨床場景中應用的潛力。此外，我們還將詞嵌入和 WSI 之間的共同注意映射視覺化，作為診斷結果的直觀解釋。資料集和相關程式碼可在 https://github.com/cpystan/WSI-VQA 取得。

##### **Accelerating MRI Uncertainty Estimation with Mask-based Bayesian Neural Network**
2407.05521v1 by Zehuan Zhang, Matej Genci, Hongxiang Fan, Andreas Wetscherek, Wayne Luk

Accurate and reliable Magnetic Resonance Imaging (MRI) analysis is
particularly important for adaptive radiotherapy, a recent medical advance
capable of improving cancer diagnosis and treatment. Recent studies have shown
that IVIM-NET, a deep neural network (DNN), can achieve high accuracy in MRI
analysis, indicating the potential of deep learning to enhance diagnostic
capabilities in healthcare. However, IVIM-NET does not provide calibrated
uncertainty information needed for reliable and trustworthy predictions in
healthcare. Moreover, the expensive computation and memory demands of IVIM-NET
reduce hardware performance, hindering widespread adoption in realistic
scenarios. To address these challenges, this paper proposes an
algorithm-hardware co-optimization flow for high-performance and reliable MRI
analysis. At the algorithm level, a transformation design flow is introduced to
convert IVIM-NET to a mask-based Bayesian Neural Network (BayesNN),
facilitating reliable and efficient uncertainty estimation. At the hardware
level, we propose an FPGA-based accelerator with several hardware
optimizations, such as mask-zero skipping and operation reordering.
Experimental results demonstrate that our co-design approach can satisfy the
uncertainty requirements of MRI analysis, while achieving 7.5 times and 32.5
times speedup on an Xilinx VU13P FPGA compared to GPU and CPU implementations
with reduced power consumption.

摘要：精準可靠的磁振造影 (MRI) 分析對於適應性放射治療特別重要，這是一種近期醫療進展，能夠改善癌症診斷和治療。最近的研究顯示，深度神經網路 (DNN) 的 IVIM-NET 能在 MRI 分析中達到高準確度，顯示深度學習有潛力增強醫療保健中的診斷能力。然而，IVIM-NET 沒有提供在醫療保健中進行可靠且值得信賴的預測所需的校準不確定性資訊。此外，IVIM-NET 昂貴的運算和記憶體需求降低了硬體效能，阻礙了在實際場景中的廣泛採用。為了解決這些挑戰，本文提出了一種演算法與硬體共同最佳化的流程，以進行高性能且可靠的 MRI 分析。在演算法層級，引入了轉換設計流程，將 IVIM-NET 轉換為基於遮罩的貝氏神經網路 (BayesNN)，促進可靠且有效的非確定性估計。在硬體層級，我們提出了一種基於 FPGA 的加速器，具備多項硬體最佳化，例如遮罩零跳過和運算重新排序。實驗結果證明，我們的共同設計方法可以滿足 MRI 分析的不確定性需求，同時在 Xilinx VU13P FPGA 上實現比 GPU 和 CPU 實作快上 7.5 倍和 32.5 倍的速度，且功耗降低。

##### **A Survey of Models for Cognitive Diagnosis: New Developments and Future Directions**
2407.05458v1 by Fei Wang, Weibo Gao, Qi Liu, Jiatong Li, Guanhao Zhao, Zheng Zhang, Zhenya Huang, Mengxiao Zhu, Shijin Wang, Wei Tong, Enhong Chen

Cognitive diagnosis has been developed for decades as an effective
measurement tool to evaluate human cognitive status such as ability level and
knowledge mastery. It has been applied to a wide range of fields including
education, sport, psychological diagnosis, etc. By providing better awareness
of cognitive status, it can serve as the basis for personalized services such
as well-designed medical treatment, teaching strategy and vocational training.
This paper aims to provide a survey of current models for cognitive diagnosis,
with more attention on new developments using machine learning-based methods.
By comparing the model structures, parameter estimation algorithms, model
evaluation methods and applications, we provide a relatively comprehensive
review of the recent trends in cognitive diagnosis models. Further, we discuss
future directions that are worthy of exploration. In addition, we release two
Python libraries: EduData for easy access to some relevant public datasets we
have collected, and EduCDM that implements popular CDMs to facilitate both
applications and research purposes.

摘要：認知診斷已發展數十年，作為評估人類認知狀態（例如能力水平和知識掌握）的有效測量工具。它已被應用於廣泛的領域，包括教育、體育、心理診斷等。透過提供對認知狀態的更好認識，它可以作為個人化服務的基礎，例如精心設計的醫療治療、教學策略和職業訓練。本文旨在提供認知診斷當前模型的綜述，並更關注使用基於機器學習的方法的新發展。透過比較模型結構、參數估計演算法、模型評估方法和應用，我們對認知診斷模型的最新趨勢提供了相對全面的回顧。此外，我們討論了值得探索的未來方向。此外，我們發布了兩個 Python 程式庫：EduData，用於輕鬆存取我們收集的一些相關公開資料集，以及 EduCDM，用於實作熱門的 CDM，以促進應用和研究目的。

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v1 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

摘要：<paragraph>本文提出了用于视网膜眼底图像疾病分类的扩张残差网络 (ResNet) 模型。扩张卷积滤波器用于替换 ResNet 模型较高层中的正常卷积滤波器（扩张 ResNet），以改善与用于疾病分类的正常 ResNet 模型相比的感受野。本研究介绍了采用深度学习的计算机辅助诊断工具，并通过可解释的 AI 技术进行了增强。这些技术旨在使该工具的决策过程透明化，从而使医疗专业人员能够理解和信任 AI 的诊断决策。它们在当今医疗保健领域尤为重要，因为对 AI 应用程序的透明度需求不断增长，以确保其可靠性和道德使用。扩张 ResNet 用作正常 ResNet 的替代品，以提高视网膜眼病的分类准确性并减少所需的计算时间。本工作中使用的数据集是 Ocular Disease Intelligent Recognition (ODIR) 数据集，这是一个结构化的眼科数据库，包含八类涵盖大多数常见视网膜眼病。本工作中使用的评估指标包括精确度、召回率、准确度和 F1 分数。在这项工作中，对正常 ResNet 模型和扩张 ResNet 模型在五个变体（即 ResNet-18、ResNet-34、ResNet-50、ResNet-101 和 ResNet-152）之间进行了比较研究。与正常 ResNet 相比，扩张 ResNet 模型显示出有希望的结果，在 ODIR 多类疾病分类中，上述各个变体的平均 F1 分数分别为 0.71、0.70、0.69、0.67 和 0.70。</paragraph>

##### **FM-OSD: Foundation Model-Enabled One-Shot Detection of Anatomical Landmarks**
2407.05412v1 by Juzheng Miao, Cheng Chen, Keli Zhang, Jie Chuai, Quanzheng Li, Pheng-Ann Heng

One-shot detection of anatomical landmarks is gaining significant attention
for its efficiency in using minimal labeled data to produce promising results.
However, the success of current methods heavily relies on the employment of
extensive unlabeled data to pre-train an effective feature extractor, which
limits their applicability in scenarios where a substantial amount of unlabeled
data is unavailable. In this paper, we propose the first foundation
model-enabled one-shot landmark detection (FM-OSD) framework for accurate
landmark detection in medical images by utilizing solely a single template
image without any additional unlabeled data. Specifically, we use the frozen
image encoder of visual foundation models as the feature extractor, and
introduce dual-branch global and local feature decoders to increase the
resolution of extracted features in a coarse to fine manner. The introduced
feature decoders are efficiently trained with a distance-aware similarity
learning loss to incorporate domain knowledge from the single template image.
Moreover, a novel bidirectional matching strategy is developed to improve both
robustness and accuracy of landmark detection in the case of scattered
similarity map obtained by foundation models. We validate our method on two
public anatomical landmark detection datasets. By using solely a single
template image, our method demonstrates significant superiority over strong
state-of-the-art one-shot landmark detection methods.

摘要：解剖標誌的一發偵測因其使用最少標籤資料產生有前景結果的效率而獲得顯著關注。然而，目前方法的成功極度依賴運用廣泛的未標籤資料來預先訓練一個有效特徵萃取器，這限制了其在大量未標籤資料不可用的情況下的適用性。在本文中，我們提出第一個基礎模型啟用的單發標誌偵測 (FM-OSD) 架構，藉由僅僅利用單一範本影像而無任何其他未標籤資料，在醫學影像中進行精確標誌偵測。具體來說，我們使用視覺基礎模型的凍結影像編碼器作為特徵萃取器，並引入雙分支全局和局部特徵解碼器，以粗到細的方式增加萃取特徵的分辨率。引入的特徵解碼器利用距離感知相似性學習損失函數進行有效訓練，以納入單一範本影像的領域知識。此外，開發了一種新穎的雙向匹配策略，以提高基礎模型取得的散佈相似性圖在標誌偵測中的穩健性和準確性。我們在兩個公開的解剖標誌偵測資料集驗證我們的模型。我們的模型僅使用單一範本影像，證明其優於現有技術中強大的單發標誌偵測方法。

##### **BadCLM: Backdoor Attack in Clinical Language Models for Electronic Health Records**
2407.05213v1 by Weimin Lyu, Zexin Bi, Fusheng Wang, Chao Chen

The advent of clinical language models integrated into electronic health
records (EHR) for clinical decision support has marked a significant
advancement, leveraging the depth of clinical notes for improved
decision-making. Despite their success, the potential vulnerabilities of these
models remain largely unexplored. This paper delves into the realm of backdoor
attacks on clinical language models, introducing an innovative attention-based
backdoor attack method, BadCLM (Bad Clinical Language Models). This technique
clandestinely embeds a backdoor within the models, causing them to produce
incorrect predictions when a pre-defined trigger is present in inputs, while
functioning accurately otherwise. We demonstrate the efficacy of BadCLM through
an in-hospital mortality prediction task with MIMIC III dataset, showcasing its
potential to compromise model integrity. Our findings illuminate a significant
security risk in clinical decision support systems and pave the way for future
endeavors in fortifying clinical language models against such vulnerabilities.

摘要：臨床語言模型整合到電子健康紀錄 (EHR) 中以進行臨床決策支援，標誌著一項重大的進展，利用臨床筆記的深度來改善決策制定。儘管這些模型取得了成功，但它們的潛在漏洞在很大程度上仍未得到探索。本文深入探討了針對臨床語言模型的後門攻擊領域，介紹了一種創新的基於注意力的後門攻擊方法 BadCLM（不良臨床語言模型）。這種技術秘密地在模型中嵌入了一個後門，導致它們在輸入中存在預定義觸發器時產生不正確的預測，而其他情況下則準確運作。我們通過使用 MIMIC III 資料集進行院內死亡率預測任務來證明 BadCLM 的效力，展示了其損害模型完整性的潛力。我們的發現揭示了臨床決策支援系統中的一個重大安全風險，並為未來加強臨床語言模型以應對此類漏洞的努力鋪平了道路。

##### **RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models**
2407.05131v1 by Peng Xia, Kangyu Zhu, Haoran Li, Hongtu Zhu, Yun Li, Gang Li, Linjun Zhang, Huaxiu Yao

The recent emergence of Medical Large Vision Language Models (Med-LVLMs) has
enhanced medical diagnosis. However, current Med-LVLMs frequently encounter
factual issues, often generating responses that do not align with established
medical facts. Retrieval-Augmented Generation (RAG), which utilizes external
knowledge, can improve the factual accuracy of these models but introduces two
major challenges. First, limited retrieved contexts might not cover all
necessary information, while excessive retrieval can introduce irrelevant and
inaccurate references, interfering with the model's generation. Second, in
cases where the model originally responds correctly, applying RAG can lead to
an over-reliance on retrieved contexts, resulting in incorrect answers. To
address these issues, we propose RULE, which consists of two components. First,
we introduce a provably effective strategy for controlling factuality risk
through the calibrated selection of the number of retrieved contexts. Second,
based on samples where over-reliance on retrieved contexts led to errors, we
curate a preference dataset to fine-tune the model, balancing its dependence on
inherent knowledge and retrieved contexts for generation. We demonstrate the
effectiveness of RULE on three medical VQA datasets, achieving an average
improvement of 20.8% in factual accuracy. We publicly release our benchmark and
code in https://github.com/richard-peng-xia/RULE.

摘要：最近出現的醫療大型語言模型 (Med-LVLMs) 提升了醫療診斷。然而，目前的 Med-LVLMs 經常遇到事實問題，通常會產生與已確立的醫療事實不符的回應。利用外部知識的檢索增強生成 (RAG) 可以改善這些模型的事實準確性，但引入了兩個主要挑戰。首先，有限的檢索內容可能無法涵蓋所有必要的資訊，而過度的檢索可能會引入不相關和不準確的參考，干擾模型的生成。其次，在模型原本正確回應的情況下，應用 RAG 可能會過度依賴檢索到的內容，導致不正確的答案。為了解決這些問題，我們提出了 RULE，它包含兩個組成部分。首先，我們引入了一種可證明有效的策略，透過校準檢索到的內容數量來控制事實風險。其次，根據過度依賴檢索到的內容導致錯誤的範例，我們策劃了一個偏好資料集來微調模型，平衡其在生成時對內在知識和檢索到的內容的依賴性。我們在三個醫療 VQA 資料集上展示了 RULE 的有效性，在事實準確性方面平均提升了 20.8%。我們在 https://github.com/richard-peng-xia/RULE 中公開發布我們的基準和程式碼。

##### **Linear Attention Based Deep Nonlocal Means Filtering for Multiplicative Noise Removal**
2407.05087v1 by Xiao Siyao, Huang Libing, Zhang Shunsheng

Multiplicative noise widely exists in radar images, medical images and other
important fields' images. Compared to normal noises, multiplicative noise has a
generally stronger effect on the visual expression of images. Aiming at the
denoising problem of multiplicative noise, we linearize the nonlocal means
algorithm with deep learning and propose a linear attention mechanism based
deep nonlocal means filtering (LDNLM). Starting from the traditional nonlocal
means filtering, we employ deep channel convolution neural networks to extract
the information of the neighborhood matrix and obtain representation vectors of
every pixel. Then we replace the similarity calculation and weighted averaging
processes with the inner operations of the attention mechanism. To reduce the
computational overhead, through the formula of similarity calculation and
weighted averaging, we derive a nonlocal filter with linear complexity.
Experiments on both simulated and real multiplicative noise demonstrate that
the LDNLM is more competitive compared with the state-of-the-art methods.
Additionally, we prove that the LDNLM possesses interpretability close to
traditional NLM.

摘要：乘性雜訊廣泛存在於雷達影像、醫學影像等重要領域的影像中。相較於一般雜訊，乘性雜訊對影像的視覺表現具有普遍更強的影響。針對乘性雜訊的去雜訊問題，我們以深度學習線性化非局部均值演算法，並提出基於線性注意力機制的深度非局部均值濾波（LDNLM）。從傳統非局部均值濾波出發，我們採用深度通道卷積神經網路提取鄰域矩陣的資訊，並取得每個畫素的表示向量。接著，我們以注意力機制的內部運算取代相似度計算與加權平均的程序。為了降低運算負擔，我們透過相似度計算與加權平均的公式，推導出具有線性複雜度的非局部濾波器。在模擬與真實乘性雜訊上的實驗均證實，LDNLM 與目前最先進的方法相比更具競爭力。此外，我們證明 LDNLM 具備接近傳統 NLM 的可解釋性。

##### **Brain Age Estimation with a Greedy Dual-Stream Model for Limited Datasets**
2407.04808v1 by Iman Kianian, Hedieh Sajedi

Brain age estimation involves predicting the biological age of individuals
from their brain images, which offers valuable insights into the aging process
and the progression of neurodegenerative diseases. Conducting large-scale
datasets for medical image analysis is a challenging and time-consuming task.
Existing approaches mostly depend on large datasets, which are hard to come by
and expensive. These approaches also require sophisticated, resource-intensive
models with a large number of parameters, necessitating a considerable amount
of processing power. As a result, there is a vital need to develop innovative
methods that can achieve robust performance with limited datasets and efficient
use of computational resources. This paper proposes a novel slice-based
dual-stream method called GDSM (Greedy Dual-Stream Model) for brain age
estimation. This method addresses the limitations of large dataset requirements
and computational resource intensiveness. The proposed method incorporates
local and global aspects of the brain, thereby refining the focus on specific
target regions. The approach employs four backbones to predict ages based on
local and global features, complemented by a final model for age correction.
Our method demonstrates a Mean Absolute Error (MAE) of 3.25 years on the test
set of IBID, which only contains 289 subjects. To demonstrate the robustness of
our approach for any small dataset, we analyzed the proposed method with the
IXI dataset and achieved an MAE of 4.18 years on the test set of IXI. By
leveraging dual-stream and greedy strategies, this approach achieves efficiency
and robust performance, making it comparable with other state-of-the-art
methods. The code for the GDSM model is available at
https://github.com/iman2693/GDSM.

摘要：大腦年齡估計涉及從大腦影像預測個體的生物年齡，這對老化過程和神經退化性疾病的進展提供了寶貴的見解。對醫學影像分析進行大規模的數據集處理是一項具有挑戰性且耗時的任務。現有的方法大多依賴於大型數據集，而這些數據集難以獲得且昂貴。這些方法還需要複雜的、資源密集型的模型，這些模型具有大量的參數，需要大量的處理能力。因此，迫切需要開發創新的方法，這些方法可以在有限的數據集和高效利用計算資源的情況下實現穩健的性能。本文提出了一種稱為 GDSM（貪婪雙流模型）的新型基於切片的雙流方法，用於大腦年齡估計。這種方法解決了對大型數據集需求和計算資源密集性的限制。所提出的方法結合了大腦的局部和全局方面，從而精確關注具體的目標區域。該方法採用四個主幹根據局部和全局特徵預測年齡，並輔以一個最終模型進行年齡校正。我們的模型在僅包含 289 個受試者的 IBID 測試集中展示了 3.25 年的平均絕對誤差 (MAE)。為了證明我們的模型對任何小型數據集的穩健性，我們使用 IXI 數據集分析了所提出的方法，並在 IXI 的測試集中實現了 4.18 年的 MAE。通過利用雙流和貪婪策略，這種方法實現了高效和穩健的性能，使其與其他最先進的方法相當。GDSM 模型的代碼可在 https://github.com/iman2693/GDSM 上獲得。

##### **Entity Decomposition with Filtering: A Zero-Shot Clinical Named Entity Recognition Framework**
2407.04629v1 by Reza Averly, Xia Ning

Clinical named entity recognition (NER) aims to retrieve important entities
within clinical narratives. Recent works have demonstrated that large language
models (LLMs) can achieve strong performance in this task. While previous works
focus on proprietary LLMs, we investigate how open NER LLMs, trained
specifically for entity recognition, perform in clinical NER. In this paper, we
aim to improve them through a novel framework, entity decomposition with
filtering, or EDF. Our key idea is to decompose the entity recognition task
into several retrievals of sub-entity types. We also introduce a filtering
mechanism to remove incorrect entities. Our experimental results demonstrate
the efficacy of our framework across all metrics, models, datasets, and entity
types. Our analysis reveals that entity decomposition can recognize previously
missed entities with substantial improvement. We further provide a
comprehensive evaluation of our framework and an in-depth error analysis to
pave future works.

摘要：臨床命名實體識別 (NER) 旨在擷取臨床敘述中的重要實體。最近的研究表明，大型語言模型 (LLM) 可以在此任務中實現強大的效能。雖然先前的研究專注於專有的 LLM，但我們探討了專門針對實體識別訓練的開放式 NER LLM 在臨床 NER 中的表現。在本文中，我們旨在透過一個新穎的架構來改善它們，即帶有過濾的實體分解，或 EDF。我們的關鍵想法是將實體識別任務分解為多個子實體類型的擷取。我們還引入了一個過濾機制來移除不正確的實體。我們的實驗結果證明了我們架構在所有指標、模型、資料集和實體類型中的效能。我們的分析顯示，實體分解可以識別先前遺漏的實體，並有顯著的改善。我們進一步提供了我們架構的全面評估和深入的錯誤分析，為未來的研究鋪路。

##### **Variational and Explanatory Neural Networks for Encoding Cancer Profiles and Predicting Drug Responses**
2407.04486v1 by Tianshu Feng, Rohan Gnanaolivu, Abolfazl Safikhani, Yuanhang Liu, Jun Jiang, Nicholas Chia, Alexander Partin, Priyanka Vasanthakumari, Yitan Zhu, Chen Wang

Human cancers present a significant public health challenge and require the
discovery of novel drugs through translational research. Transcriptomics
profiling data that describes molecular activities in tumors and cancer cell
lines are widely utilized for predicting anti-cancer drug responses. However,
existing AI models face challenges due to noise in transcriptomics data and
lack of biological interpretability. To overcome these limitations, we
introduce VETE (Variational and Explanatory Transcriptomics Encoder), a novel
neural network framework that incorporates a variational component to mitigate
noise effects and integrates traceable gene ontology into the neural network
architecture for encoding cancer transcriptomics data. Key innovations include
a local interpretability-guided method for identifying ontology paths, a
visualization tool to elucidate biological mechanisms of drug responses, and
the application of centralized large scale hyperparameter optimization. VETE
demonstrated robust accuracy in cancer cell line classification and drug
response prediction. Additionally, it provided traceable biological
explanations for both tasks and offers insights into the mechanisms underlying
its predictions. VETE bridges the gap between AI-driven predictions and
biologically meaningful insights in cancer research, which represents a
promising advancement in the field.

摘要：人類癌症對公共衛生構成重大挑戰，需要透過轉譯研究發現新藥物。描述腫瘤和癌細胞株分子活動的轉錄組學分析資料廣泛用於預測抗癌藥物反應。然而，現有的 AI 模型因轉錄組學資料中的雜訊和缺乏生物學可解釋性而面臨挑戰。為了克服這些限制，我們引入了 VETE（變異和解釋性轉錄組學編碼器），這是一種新穎的神經網路架構，它結合了變異組成以減輕雜訊效應，並將可追蹤的基因本體整合到神經網路架構中以編碼癌症轉錄組學資料。關鍵創新包括一種局部可解釋性引導方法，用於識別本體路徑，一種用於闡明藥物反應的生物機制的視覺化工具，以及集中式大規模超參數最佳化的應用。VETE 在癌細胞株分類和藥物反應預測方面表現出穩健的準確性。此外，它為這兩個任務提供了可追蹤的生物學解釋，並提供了對其預測背後機制的見解。VETE 彌合了 AI 驅動預測與癌症研究中具有生物學意義的見解之間的差距，這代表了該領域的一項有前途的進展。

##### **Multi-modal Masked Siamese Network Improves Chest X-Ray Representation Learning**
2407.04449v1 by Saeed Shurrab, Alejandro Guerra-Manzanares, Farah E. Shamout

Self-supervised learning methods for medical images primarily rely on the
imaging modality during pretraining. While such approaches deliver promising
results, they do not leverage associated patient or scan information collected
within Electronic Health Records (EHR). Here, we propose to incorporate EHR
data during self-supervised pretraining with a Masked Siamese Network (MSN) to
enhance the quality of chest X-ray representations. We investigate three types
of EHR data, including demographic, scan metadata, and inpatient stay
information. We evaluate our approach on three publicly available chest X-ray
datasets, MIMIC-CXR, CheXpert, and NIH-14, using two vision transformer (ViT)
backbones, specifically ViT-Tiny and ViT-Small. In assessing the quality of the
representations via linear evaluation, our proposed method demonstrates
significant improvement compared to vanilla MSN and state-of-the-art
self-supervised learning baselines. Our work highlights the potential of
EHR-enhanced self-supervised pre-training for medical imaging. The code is
publicly available at: https://github.com/nyuad-cai/CXR-EHR-MSN

摘要：用於醫學影像的自監督式學習方法主要依賴於預訓練期間的影像模式。雖然此類方法提供了有前景的結果，但它們並未利用電子健康記錄 (EHR) 中收集的相關患者或掃描資訊。在此，我們建議在使用蒙面連體網路 (MSN) 進行自監督預訓練期間納入 EHR 資料，以提升胸部 X 光片表徵的品質。我們探討三種類型的 EHR 資料，包括人口統計資料、掃描元資料和住院期間資訊。我們在三個公開的胸部 X 光片資料集（MIMIC-CXR、CheXpert 和 NIH-14）上評估我們的做法，使用兩個視覺轉換器 (ViT) 主幹，特別是 ViT-Tiny 和 ViT-Small。在透過線性評估來評量表徵的品質時，我們提出的方法與傳統 MSN 和最先進的自監督式學習基準相比，表現出顯著的進步。我們的研究重點說明了 EHR 增強的自監督預訓練在醫學影像方面的潛力。此程式碼可於以下網址公開取得：https://github.com/nyuad-cai/CXR-EHR-MSN

##### **Query-Guided Self-Supervised Summarization of Nursing Notes**
2407.04125v1 by Ya Gao, Hans Moen, Saila Koivusalo, Miika Koskinen, Pekka Marttinen

Nursing notes, an important component of Electronic Health Records (EHRs),
keep track of the progression of a patient's health status during a care
episode. Distilling the key information in nursing notes through text
summarization techniques can improve clinicians' efficiency in understanding
patients' conditions when reviewing nursing notes. However, existing
abstractive summarization methods in the clinical setting have often overlooked
nursing notes and require the creation of reference summaries for supervision
signals, which is time-consuming. In this work, we introduce QGSumm, a
query-guided self-supervised domain adaptation framework for nursing note
summarization. Using patient-related clinical queries as guidance, our approach
generates high-quality, patient-centered summaries without relying on reference
summaries for training. Through automatic and manual evaluation by an expert
clinician, we demonstrate the strengths of our approach compared to the
state-of-the-art Large Language Models (LLMs) in both zero-shot and few-shot
settings. Ultimately, our approach provides a new perspective on conditional
text summarization, tailored to the specific interests of clinical personnel.

摘要：護理記錄是電子健康紀錄 (EHR) 的重要組成部分，
在照護過程中追蹤病患的健康狀態進展。利用文字摘要技術提煉護理記錄中的關鍵資訊，可以提升臨床醫師在檢視護理記錄時了解病患狀況的效率。然而，現有的臨床摘要方法常常忽略護理記錄，且需要建立參考摘要作為監督訊號，這非常耗時。在這項工作中，我們提出 QGSumm，一個用於護理記錄摘要的查詢引導式自我監督領域適應架構。我們的做法使用與病患相關的臨床查詢作為指引，在訓練中不依賴參考摘要，就能產生高品質、以病患為中心的摘要。透過專家臨床醫師的自動和手動評估，我們展示了我們的方法與最先進的大語言模型 (LLM) 相比在零次學習和少次學習設定中的優勢。最終，我們的做法為條件式文字摘要提供了新的觀點，專門針對臨床人員的特定興趣量身打造。

##### **MiniGPT-Med: Large Language Model as a General Interface for Radiology Diagnosis**
2407.04106v1 by Asma Alkhaldi, Raneem Alnajim, Layan Alabdullatef, Rawan Alyahya, Jun Chen, Deyao Zhu, Ahmed Alsinan, Mohamed Elhoseiny

Recent advancements in artificial intelligence (AI) have precipitated
significant breakthroughs in healthcare, particularly in refining diagnostic
procedures. However, previous studies have often been constrained to limited
functionalities. This study introduces MiniGPT-Med, a vision-language model
derived from large-scale language models and tailored for medical applications.
MiniGPT-Med demonstrates remarkable versatility across various imaging
modalities, including X-rays, CT scans, and MRIs, enhancing its utility. The
model is capable of performing tasks such as medical report generation, visual
question answering (VQA), and disease identification within medical imagery.
Its integrated processing of both image and textual clinical data markedly
improves diagnostic accuracy. Our empirical assessments confirm MiniGPT-Med's
superior performance in disease grounding, medical report generation, and VQA
benchmarks, representing a significant step towards reducing the gap in
assisting radiology practice. Furthermore, it achieves state-of-the-art
performance on medical report generation, higher than the previous best model
by 19\% accuracy. MiniGPT-Med promises to become a general interface for
radiology diagnoses, enhancing diagnostic efficiency across a wide range of
medical imaging applications.

摘要：隨著人工智慧 (AI) 的最新進展，醫療保健領域出現了顯著的突破，特別是在改善診斷程序方面。然而，先前的研究通常僅限於有限的功能。這項研究引入了 MiniGPT-Med，這是一種源自大規模語言模型且專為醫療應用而設計的視覺語言模型。MiniGPT-Med 在各種影像模式中展現出非凡的多功能性，包括 X 光、電腦斷層掃描和 MRI，進而增強其效用。該模型能夠執行諸如醫療報告生成、視覺問答 (VQA) 和醫療影像中的疾病識別等任務。它將影像和文字臨床資料整合處理，顯著提高了診斷準確性。我們的實證評估證實了 MiniGPT-Med 在疾病基礎、醫療報告生成和 VQA 基準上的優異表現，這代表了縮小協助放射診斷實務差距的重要一步。此外，它在醫療報告生成方面達到了最先進的表現，比先前的最佳模型高出 19% 的準確度。MiniGPT-Med 有望成為放射診斷的通用介面，進而提升各種醫療影像應用中的診斷效率。

##### **Unsupervised Analysis of Alzheimer's Disease Signatures using 3D Deformable Autoencoders**
2407.03863v1 by Mehmet Yigit Avci, Emily Chan, Veronika Zimmer, Daniel Rueckert, Benedikt Wiestler, Julia A. Schnabel, Cosmin I. Bercea

With the increasing incidence of neurodegenerative diseases such as
Alzheimer's Disease (AD), there is a need for further research that enhances
detection and monitoring of the diseases. We present MORPHADE (Morphological
Autoencoders for Alzheimer's Disease Detection), a novel unsupervised learning
approach which uses deformations to allow the analysis of 3D T1-weighted brain
images. To the best of our knowledge, this is the first use of deformations
with deep unsupervised learning to not only detect, but also localize and
assess the severity of structural changes in the brain due to AD. We obtain
markedly higher anomaly scores in clinically important areas of the brain in
subjects with AD compared to healthy controls, showcasing that our method is
able to effectively locate AD-related atrophy. We additionally observe a visual
correlation between the severity of atrophy highlighted in our anomaly maps and
medial temporal lobe atrophy scores evaluated by a clinical expert. Finally,
our method achieves an AUROC of 0.80 in detecting AD, out-performing several
supervised and unsupervised baselines. We believe our framework shows promise
as a tool towards improved understanding, monitoring and detection of AD. To
support further research and application, we have made our code publicly
available at github.com/ci-ber/MORPHADE.

摘要：隨著神經退行性疾病（例如阿茲海默症）的發生率增加，需要進一步的研究來加強對這些疾病的偵測和監控。我們提出 MORPHADE（阿茲海默症偵測的形態自動編碼器），這是一種新穎的無監督學習方法，它使用變形來分析 3D T1 加權腦部影像。據我們所知，這是首次將變形與深度無監督學習結合使用，不僅可以偵測，還可以定位和評估阿茲海默症導致的腦部結構變化嚴重程度。我們在阿茲海默症受試者的腦部臨床上重要區域獲得顯著更高的異常分數，與健康對照組相比，顯示我們的模型能夠有效定位與阿茲海默症相關的萎縮。此外，我們觀察到異常圖中突出的萎縮嚴重程度與臨床專家評估的內側顳葉萎縮分數之間存在視覺相關性。最後，我們的模型在偵測阿茲海默症方面達到了 0.80 的 AUROC，優於多個監督式和無監督式基準。我們相信我們的架構顯示出有望成為改善阿茲海默症理解、監控和偵測的工具。為了支持進一步的研究和應用，我們已在 github.com/ci-ber/MORPHADE 公開我們的程式碼。

##### **Integrating Randomness in Large Language Models: A Linear Congruential Generator Approach for Generating Clinically Relevant Content**
2407.03582v1 by Andrew Bouras

Generating diverse, high-quality outputs from language models is crucial for
applications in education and content creation. Achieving true randomness and
avoiding repetition remains a significant challenge. This study uses the Linear
Congruential Generator method for systematic fact selection, combined with
AI-powered content generation. We ensured unique combinations of
gastrointestinal physiology and pathology facts across multiple rounds,
integrating these facts into prompts for GPT-4o to create clinically relevant,
vignette-style outputs. Over 14 rounds, 98 unique outputs were generated,
demonstrating LCG's effectiveness in producing diverse and high-quality
content. This method addresses key issues of randomness and repetition,
enhancing the quality and efficiency of language model-generated content for
various applications.

摘要：在教育和內容創作的應用中，從語言模型產生多樣化、高品質的輸出至關重要。實現真正的隨機性和避免重複仍然是一項重大的挑戰。本研究使用線性同餘產生器方法進行系統性事實選擇，並結合 AI 驅動的內容生成。我們確保了在多輪中胃腸生理和病理事實的獨特組合，將這些事實整合到 GPT-4o 的提示中，以創建具有臨床相關性的短篇故事風格輸出。在 14 輪中，生成了 98 個獨特輸出，證明了 LCG 在產生多樣化和高品質內容方面的有效性。此方法解決了隨機性和重複性的關鍵問題，提高了語言模型生成的內容在各種應用中的品質和效率。

##### **Accelerated Proton Resonance Frequency-based Magnetic Resonance Thermometry by Optimized Deep Learning Method**
2407.03308v1 by Sijie Xu, Shenyan Zong, Chang-Sheng Mei, Guofeng Shen, Yueran Zhao, He Wang

Proton resonance frequency (PRF) based MR thermometry is essential for
focused ultrasound (FUS) thermal ablation therapies. This work aims to enhance
temporal resolution in dynamic MR temperature map reconstruction using an
improved deep learning method. The training-optimized methods and five
classical neural networks were applied on the 2-fold and 4-fold under-sampling
k-space data to reconstruct the temperature maps. The enhanced training modules
included offline/online data augmentations, knowledge distillation, and the
amplitude-phase decoupling loss function. The heating experiments were
performed by a FUS transducer on phantom and ex vivo tissues, respectively.
These data were manually under-sampled to imitate acceleration procedures and
trained in our method to get the reconstruction model. The additional dozen or
so testing datasets were separately obtained for evaluating the real-time
performance and temperature accuracy. Acceleration factors of 1.9 and 3.7 were
found for 2 times and 4 times k-space under-sampling strategies and the
ResUNet-based deep learning reconstruction performed exceptionally well. In
2-fold acceleration scenario, the RMSE of temperature map patches provided the
values of 0.888 degree centigrade and 1.145 degree centigrade on phantom and ex
vivo testing datasets. The DICE value of temperature areas enclosed by 43
degree centigrade isotherm was 0.809, and the Bland-Altman analysis showed a
bias of -0.253 degree centigrade with the apart of plus or minus 2.16 degree
centigrade. In 4 times under-sampling case, these evaluating values decreased
by approximately 10%. This study demonstrates that deep learning-based
reconstruction can significantly enhance the accuracy and efficiency of MR
thermometry for clinical FUS thermal therapies.

摘要：基於質子共振頻率 (PRF) 的 MR 溫度測量對於聚焦超音波 (FUS) 熱消融療法至關重要。這項研究旨在透過改善深度學習方法，提升動態 MR 溫度圖重建中的時間解析度。在 2 倍和 4 倍的 k-space 資料不足採樣中，將訓練最佳化方法和五個傳統神經網路應用於重建溫度圖。增強的訓練模組包括離線/線上資料擴充、知識萃取，以及振幅相位解耦損失函數。加熱實驗分別由 FUS 換能器在模擬人體和離體組織上執行。這些資料經過手動不足採樣以模擬加速程序，並在我們的模型中進行訓練以取得重建模型。額外的十幾個測試資料集則另外取得，用於評估即時效能和溫度準確度。在 2 倍和 4 倍 k-space 不足採樣策略中，發現加速因子為 1.9 和 3.7，而基於 ResUNet 的深度學習重建表現得非常好。在 2 倍加速情境中，溫度圖區塊的 RMSE 在模擬人體和離體測試資料集上提供 0.888 度攝氏和 1.145 度攝氏的值。溫度區域的 DICE 值，以 43 度攝氏等溫線包覆，為 0.809，而 Bland-Altman 分析顯示偏差為 -0.253 度攝氏，加上或減去 2.16 度攝氏。在 4 倍不足採樣案例中，這些評估值減少了大約 10%。這項研究證明，基於深度學習的重建可以大幅提升臨床 FUS 熱療中 MR 溫度測量的準確度和效率。

##### **MVGT: A Multi-view Graph Transformer Based on Spatial Relations for EEG Emotion Recognition**
2407.03131v2 by Yanjie Cui, Xiaohong Liu, Jing Liang, Yamin Fu

Electroencephalography (EEG), a medical imaging technique that captures scalp
electrical activity of brain structures via electrodes, has been widely used in
affective computing. The spatial domain of EEG is rich in affective
information. However, few of the existing studies have simultaneously analyzed
EEG signals from multiple perspectives of geometric and anatomical structures
in spatial domain. In this paper, we propose a multi-view Graph Transformer
(MVGT) based on spatial relations, which integrates information from the
temporal, frequency and spatial domains, including geometric and anatomical
structures, so as to enhance the expressive power of the model comprehensively.
We incorporate the spatial information of EEG channels into the model as
encoding, thereby improving its ability to perceive the spatial structure of
the channels. Meanwhile, experimental results based on publicly available
datasets demonstrate that our proposed model outperforms state-of-the-art
methods in recent years. In addition, the results also show that the MVGT could
extract information from multiple domains and capture inter-channel
relationships in EEG emotion recognition tasks effectively.

摘要：腦電圖（EEG）是一種醫學影像技術，透過電極擷取頭皮上腦部結構的電氣活動，已廣泛用於情感運算中。EEG 的空間域蘊藏豐富的情感資訊。然而，現有的研究鮮少同時從空間域中的幾何結構和解剖結構等多重面向分析 EEG 訊號。本文提出一個基於空間關係的多視圖圖形轉換器（MVGT），它整合了時間、頻率和空間域（包括幾何結構和解剖結構）的資訊，以全面提升模型的表現力。我們將 EEG 通道的空間資訊編碼後納入模型中，進而提升其感知通道空間結構的能力。同時，基於公開資料集的實驗結果顯示，我們提出的模型優於近年來的現有技術。此外，結果也顯示 MVGT 能有效從多重域中擷取資訊，並在 EEG 情緒辨識任務中捕捉到通道間的關係。

##### **Effective Heterogeneous Federated Learning via Efficient Hypernetwork-based Weight Generation**
2407.03086v1 by Yujin Shin, Kichang Lee, Sungmin Lee, You Rim Choi, Hyung-Sin Kim, JeongGil Ko

While federated learning leverages distributed client resources, it faces
challenges due to heterogeneous client capabilities. This necessitates
allocating models suited to clients' resources and careful parameter
aggregation to accommodate this heterogeneity. We propose HypeMeFed, a novel
federated learning framework for supporting client heterogeneity by combining a
multi-exit network architecture with hypernetwork-based model weight
generation. This approach aligns the feature spaces of heterogeneous model
layers and resolves per-layer information disparity during weight aggregation.
To practically realize HypeMeFed, we also propose a low-rank factorization
approach to minimize computation and memory overhead associated with
hypernetworks. Our evaluations on a real-world heterogeneous device testbed
indicate that HypeMeFed enhances accuracy by 5.12% over FedAvg, reduces the
hypernetwork memory requirements by 98.22%, and accelerates its operations by
1.86 times compared to a naive hypernetwork approach. These results demonstrate
HypeMeFed's effectiveness in leveraging and engaging heterogeneous clients for
federated learning.

摘要：雖然聯合學習利用分散式用戶端資源，但由於用戶端能力異質，因此面臨挑戰。這需要分配適合用戶端資源的模型，並仔細參數聚合以容納這種異質性。我們提出 HypeMeFed，一種新的聯合學習框架，通過將多出口網路架構與基於超網路的模型權重生成相結合來支援用戶端異質性。此方法對齊異質模型層的特徵空間，並在權重聚合期間解決逐層資訊差異。為了實際實現 HypeMeFed，我們還提出了一種低秩分解方法，以最大限度地減少與超網路相關的計算和記憶體開銷。我們在真實世界異質設備測試平台上的評估表明，與 FedAvg 相比，HypeMeFed 將準確率提高了 5.12%，將超網路記憶體需求減少了 98.22%，並且與天真的超網路方法相比，其運算速度提高了 1.86 倍。這些結果證明了 HypeMeFed 在利用和吸引異質用戶端進行聯合學習方面的有效性。

##### **Attention Incorporated Network for Sharing Low-rank, Image and K-space Information during MR Image Reconstruction to Achieve Single Breath-hold Cardiac Cine Imaging**
2407.03034v1 by Siying Xu, Kerstin Hammernik, Andreas Lingg, Jens Kuebler, Patrick Krumm, Daniel Rueckert, Sergios Gatidis, Thomas Kuestner

Cardiac Cine Magnetic Resonance Imaging (MRI) provides an accurate assessment
of heart morphology and function in clinical practice. However, MRI requires
long acquisition times, with recent deep learning-based methods showing great
promise to accelerate imaging and enhance reconstruction quality. Existing
networks exhibit some common limitations that constrain further acceleration
possibilities, including single-domain learning, reliance on a single
regularization term, and equal feature contribution. To address these
limitations, we propose to embed information from multiple domains, including
low-rank, image, and k-space, in a novel deep learning network for MRI
reconstruction, which we denote as A-LIKNet. A-LIKNet adopts a parallel-branch
structure, enabling independent learning in the k-space and image domain.
Coupled information sharing layers realize the information exchange between
domains. Furthermore, we introduce attention mechanisms into the network to
assign greater weights to more critical coils or important temporal frames.
Training and testing were conducted on an in-house dataset, including 91
cardiovascular patients and 38 healthy subjects scanned with 2D cardiac Cine
using retrospective undersampling. Additionally, we evaluated A-LIKNet on the
real-time 8x prospectively undersampled data from the OCMR dataset. The results
demonstrate that our proposed A-LIKNet outperforms existing methods and
provides high-quality reconstructions. The network can effectively reconstruct
highly retrospectively undersampled dynamic MR images up to 24x accelerations,
indicating its potential for single breath-hold imaging.

摘要：<paragraph>心臟動態磁共振影像 (MRI) 提供了心臟形態和功能在臨床實務上的精準評估。然而，MRI 需要較長的擷取時間，而最近基於深度學習的方法顯示出極佳的潛力，用於加速影像並增強重建品質。現有的網路展現了一些常見的限制，限制了進一步的加速可能性，包括單一領域學習、依賴單一正則化項，以及相等的特徵貢獻。為了解決這些限制，我們提議將來自多個領域的資訊嵌入一個用於 MRI 重建的新穎深度學習網路中，包括低秩、影像，以及 k 空間，我們將其表示為 A-LIKNet。A-LIKNet 採用平行分支結構，在 k 空間和影像領域中實現獨立學習。耦合資訊共享層實現了領域之間的資訊交換。此外，我們將注意力機制引入網路中，以將較大的權重分配給更重要的線圈或重要的時間幀。訓練和測試是在內部資料集上進行的，其中包括 91 位心血管疾病患者和 38 位健康受試者，他們使用 2D 心臟動態影像進行掃描，並使用回溯式欠採樣。此外，我們在 OCMR 資料集中的即時 8 倍前瞻性欠採樣資料上評估了 A-LIKNet。結果證明，我們提出的 A-LIKNet 優於現有方法，並提供了高品質的重建。該網路可以有效重建高回溯性欠採樣的動態 MR 影像，加速率高達 24 倍，這表示其具有單次閉氣影像的潛力。</paragraph>

##### **SemioLLM: Assessing Large Language Models for Semiological Analysis in Epilepsy Research**
2407.03004v1 by Meghal Dani, Muthu Jeyanthi Prakash, Zeynep Akata, Stefanie Liebe

Large Language Models have shown promising results in their ability to encode
general medical knowledge in standard medical question-answering datasets.
However, their potential application in clinical practice requires evaluation
in domain-specific tasks, where benchmarks are largely missing. In this study
semioLLM, we test the ability of state-of-the-art LLMs (GPT-3.5, GPT-4, Mixtral
8x7B, and Qwen-72chat) to leverage their internal knowledge and reasoning for
epilepsy diagnosis. Specifically, we obtain likelihood estimates linking
unstructured text descriptions of seizures to seizure-generating brain regions,
using an annotated clinical database containing 1269 entries. We evaluate the
LLM's performance, confidence, reasoning, and citation abilities in comparison
to clinical evaluation. Models achieve above-chance classification performance
with prompt engineering significantly improving their outcome, with some models
achieving close-to-clinical performance and reasoning. However, our analyses
also reveal significant pitfalls with several models being overly confident
while showing poor performance, as well as exhibiting citation errors and
hallucinations. In summary, our work provides the first extensive benchmark
comparing current SOTA LLMs in the medical domain of epilepsy and highlights
their ability to leverage unstructured texts from patients' medical history to
aid diagnostic processes in health care.

摘要：大型語言模型在標準醫療問答資料集中編碼一般醫療知識的能力方面已展現出可觀的成果。然而，它們在臨床實務中的潛在應用需要在特定領域任務中進行評估，而基準量測在很大程度上仍付之闕如。在本研究 semioLLM 中，我們測試了最先進的 LLM（GPT-3.5、GPT-4、Mixtral 8x7B 和 Qwen-72chat）利用其內部知識和推理進行癲癇診斷的能力。具體來說，我們取得了連結癲癇發作非結構化文字描述至癲癇發作生成腦區的可能性估計值，使用包含 1269 個條目的註解式臨床資料庫。我們評估了 LLM 的表現、信心、推理和引述能力，並與臨床評估進行比較。模型達到了高於機率的分類表現，提示工程顯著改善了其結果，有些模型達到了接近臨床表現和推理。然而，我們的分析也揭露了幾個模型的重大缺陷，它們過度自信，同時表現不佳，並出現引述錯誤和幻覺。總之，我們的研究提供了第一個廣泛的基準，比較了癲癇醫療領域中目前的 SOTA LLM，並突出了它們利用患者病史中的非結構化文字來協助醫療保健中的診斷程序的能力。

##### **MedPix 2.0: A Comprehensive Multimodal Biomedical Dataset for Advanced AI Applications**
2407.02994v1 by Irene Siragusa, Salvatore Contino, Massimo La Ciura, Rosario Alicata, Roberto Pirrone

The increasing interest in developing Artificial Intelligence applications in
the medical domain, suffers from the lack of high-quality dataset, mainly due
to privacy-related issues. Moreover, the recent rising of Multimodal Large
Language Models (MLLM) leads to a need for multimodal medical datasets, where
clinical reports and findings are attached to the corresponding CT or MR scans.
This paper illustrates the entire workflow for building the data set MedPix
2.0. Starting from the well-known multimodal dataset
MedPix\textsuperscript{\textregistered}, mainly used by physicians, nurses and
healthcare students for Continuing Medical Education purposes, a semi-automatic
pipeline was developed to extract visual and textual data followed by a manual
curing procedure where noisy samples were removed, thus creating a MongoDB
database. Along with the dataset, we developed a GUI aimed at navigating
efficiently the MongoDB instance, and obtaining the raw data that can be easily
used for training and/or fine-tuning MLLMs. To enforce this point, we also
propose a CLIP-based model trained on MedPix 2.0 for scan classification tasks.

摘要：隨著在醫療領域開發人工智慧應用程式的興趣日益增加，但由於隱私相關問題，導致缺乏高品質的資料集。此外，多模態大型語言模型 (MLLM) 的興起，需要建立多模態醫療資料集，其中臨床報告和發現會附加到對應的電腦斷層掃描或核磁共振掃描。本文說明建立資料集 MedPix 2.0 的完整工作流程。從廣為人知的由醫師、護理師和醫療保健學生主要用於持續醫療教育目的的多模態資料集 MedPix\textsuperscript{\textregistered} 開始，開發了一個半自動化管道來萃取視覺和文字資料，接著進行手動清理程序移除雜訊樣本，進而建立一個 MongoDB 資料庫。隨著資料集，我們開發了一個 GUI，旨在有效率地瀏覽 MongoDB 執行個體，並取得可用於訓練和/或微調 MLLM 的原始資料。為了強調這一點，我們也提出一個在 MedPix 2.0 上訓練的基於 CLIP 的模型，用於掃描分類任務。

##### **Membership Inference Attacks Against Time-Series Models**
2407.02870v1 by Noam Koren, Abigail Goldsteen, Ariel Farkash, Guy Amit

Analyzing time-series data that may contain personal information,
particularly in the medical field, presents serious privacy concerns. Sensitive
health data from patients is often used to train machine-learning models for
diagnostics and ongoing care. Assessing the privacy risk of such models is
crucial to making knowledgeable decisions on whether to use a model in
production, share it with third parties, or deploy it in patients homes.
Membership Inference Attacks (MIA) are a key method for this kind of
evaluation, however time-series prediction models have not been thoroughly
studied in this context. We explore existing MIA techniques on time-series
models, and introduce new features, focusing on the seasonality and trend
components of the data. Seasonality is estimated using a multivariate Fourier
transform, and a low-degree polynomial is used to approximate trends. We
applied these techniques to various types of time-series models, using datasets
from the health domain. Our results demonstrate that these new features enhance
the effectiveness of MIAs in identifying membership, improving the
understanding of privacy risks in medical data applications.

摘要：分析可能包含个人信息的時間序列資料，特別是在醫療領域，會引發嚴重的隱私問題。病患的敏感健康資料經常被用於訓練機器學習模型，以進行診斷和持續照護。評估此類模型的隱私風險，對於在生產中使用模型、與第三方分享，或在病患家中部署模型時做出明智的決定至關重要。成員推論攻擊 (MIA) 是進行此類評估的一種關鍵方法，然而，在此背景下尚未徹底研究時序預測模型。我們探討了時序模型上現有的 MIA 技術，並引入了新的功能，重點關注資料的季節性和趨勢組成。季節性使用多變數傅立葉轉換來估計，低次多項式用於近似趨勢。我們將這些技術應用於各種類型的時序模型，使用來自健康領域的資料集。我們的結果表明，這些新功能增強了 MIA 在識別成員資格方面的效能，進而提升了對醫療資料應用中隱私風險的理解。

##### **Effect of a Process Mining based Pre-processing Step in Prediction of the Critical Health Outcomes**
2407.02821v1 by Negin Ashrafi, Armin Abdollahi, Greg Placencia, Maryam Pishgar

Predicting critical health outcomes such as patient mortality and hospital
readmission is essential for improving survivability. However, healthcare
datasets have many concurrences that create complexities, leading to poor
predictions. Consequently, pre-processing the data is crucial to improve its
quality. In this study, we use an existing pre-processing algorithm,
concatenation, to improve data quality by decreasing the complexity of
datasets. Sixteen healthcare datasets were extracted from two databases - MIMIC
III and University of Illinois Hospital - converted to the event logs, they
were then fed into the concatenation algorithm. The pre-processed event logs
were then fed to the Split Miner (SM) algorithm to produce a process model.
Process model quality was evaluated before and after concatenation using the
following metrics: fitness, precision, F-Measure, and complexity. The
pre-processed event logs were also used as inputs to the Decay Replay Mining
(DREAM) algorithm to predict critical outcomes. We compared predicted results
before and after applying the concatenation algorithm using Area Under the
Curve (AUC) and Confidence Intervals (CI). Results indicated that the
concatenation algorithm improved the quality of the process models and
predictions of the critical health outcomes.

摘要：預測病患死亡率和醫院再入院等重大的健康結果，對於提升存活率至關重要。然而，醫療保健資料集有許多同時發生的事件，會造成複雜性，導致預測不佳。因此，預先處理資料對於提升資料品質至關重要。在本研究中，我們使用現有的預先處理演算法，連接，藉由降低資料集的複雜性來提升資料品質。從兩個資料庫中萃取出十六個醫療保健資料集 - MIMIC III 和伊利諾大學醫院 - 轉換成事件記錄，然後將其輸入連接演算法。接著將預先處理的事件記錄輸入 Split Miner (SM) 演算法，以產生流程模型。使用以下指標評估連接前後的流程模型品質：適用性、精確度、F-量測和複雜性。預先處理的事件記錄也用作衰減重播探勘 (DREAM) 演算法的輸入，以預測重大的結果。我們使用曲線下面積 (AUC) 和信心區間 (CI) 比較套用連接演算法前後的預測結果。結果顯示連接演算法提升了流程模型的品質和對重大健康結果的預測。

##### **MedVH: Towards Systematic Evaluation of Hallucination for Large Vision Language Models in the Medical Context**
2407.02730v1 by Zishan Gu, Changchang Yin, Fenglin Liu, Ping Zhang

Large Vision Language Models (LVLMs) have recently achieved superior
performance in various tasks on natural image and text data, which inspires a
large amount of studies for LVLMs fine-tuning and training. Despite their
advancements, there has been scant research on the robustness of these models
against hallucination when fine-tuned on smaller datasets. In this study, we
introduce a new benchmark dataset, the Medical Visual Hallucination Test
(MedVH), to evaluate the hallucination of domain-specific LVLMs. MedVH
comprises five tasks to evaluate hallucinations in LVLMs within the medical
context, which includes tasks for comprehensive understanding of textual and
visual input, as well as long textual response generation. Our extensive
experiments with both general and medical LVLMs reveal that, although medical
LVLMs demonstrate promising performance on standard medical tasks, they are
particularly susceptible to hallucinations, often more so than the general
models, raising significant concerns about the reliability of these
domain-specific models. For medical LVLMs to be truly valuable in real-world
applications, they must not only accurately integrate medical knowledge but
also maintain robust reasoning abilities to prevent hallucination. Our work
paves the way for future evaluations of these studies.

摘要：大型視覺語言模型 (LVLMs) 最近在自然影像和文字資料的各種任務中取得了卓越的表現，這激勵了大量的研究進行 LVLMs 的微調和訓練。儘管它們進步了，但對於在較小的資料集上微調時，這些模型對幻覺的魯棒性卻鮮有研究。在這項研究中，我們引入了新的基準資料集，即醫學視覺幻覺測試 (MedVH)，以評估特定領域 LVLMs 的幻覺。MedVH 包含五項任務，用於評估醫學背景下 LVLMs 中的幻覺，其中包括全面理解文字和視覺輸入的任務，以及長文字回應生成。我們對一般和醫學 LVLMs 進行的廣泛實驗表明，儘管醫學 LVLMs 在標準醫學任務上表現出令人滿意的表現，但它們特別容易產生幻覺，通常比一般模型更容易產生幻覺，這引起了對這些特定領域模型的可靠性的重大疑慮。為了讓醫學 LVLMs 在現實世界的應用中真正有價值，它們不僅必須準確整合醫學知識，還必須具備強大的推理能力以防止幻覺。我們的研究為未來對這些研究的評估鋪平了道路。

##### **D-Rax: Domain-specific Radiologic assistant leveraging multi-modal data and eXpert model predictions**
2407.02604v1 by Hareem Nisar, Syed Muhammad Anwar, Zhifan Jiang, Abhijeet Parida, Vishwesh Nath, Holger R. Roth, Marius George Linguraru

Large vision language models (VLMs) have progressed incredibly from research
to applicability for general-purpose use cases. LLaVA-Med, a pioneering large
language and vision assistant for biomedicine, can perform multi-modal
biomedical image and data analysis to provide a natural language interface for
radiologists. While it is highly generalizable and works with multi-modal data,
it is currently limited by well-known challenges that exist in the large
language model space. Hallucinations and imprecision in responses can lead to
misdiagnosis which currently hinder the clinical adaptability of VLMs. To
create precise, user-friendly models in healthcare, we propose D-Rax -- a
domain-specific, conversational, radiologic assistance tool that can be used to
gain insights about a particular radiologic image. In this study, we enhance
the conversational analysis of chest X-ray (CXR) images to support radiological
reporting, offering comprehensive insights from medical imaging and aiding in
the formulation of accurate diagnosis. D-Rax is achieved by fine-tuning the
LLaVA-Med architecture on our curated enhanced instruction-following data,
comprising of images, instructions, as well as disease diagnosis and
demographic predictions derived from MIMIC-CXR imaging data, CXR-related visual
question answer (VQA) pairs, and predictive outcomes from multiple expert AI
models. We observe statistically significant improvement in responses when
evaluated for both open and close-ended conversations. Leveraging the power of
state-of-the-art diagnostic models combined with VLMs, D-Rax empowers
clinicians to interact with medical images using natural language, which could
potentially streamline their decision-making process, enhance diagnostic
accuracy, and conserve their time.

摘要：大型視覺語言模型（VLM）已從研究進展到可適用於一般用途案例。LLaVA-Med 是一個開創性的生物醫學大型語言和視覺助理，可以執行多模態生物醫學影像和資料分析，為放射科醫師提供自然語言介面。儘管它具有高度的概括性，並且適用於多模態資料，但目前受到大型語言模型空間中眾所周知挑戰的限制。回應中的幻覺和不精確可能會導致誤診，這會阻礙 VLM 的臨床適應性。為了在醫療保健中建立精確、使用者友善的模型，我們提出了 D-Rax——一種特定於領域的對話式放射協助工具，可用於深入了解特定放射影像。在這項研究中，我們增強了胸部 X 光（CXR）影像的對話式分析，以支援放射報告，從醫學影像中提供全面的見解，並協助制定準確的診斷。D-Rax 是透過微調 LLaVA-Med 架構在我們整理的增強式指令遵循資料上實現的，包括影像、指令，以及從 MIMIC-CXR 影像資料、CXR 相關視覺問答（VQA）配對和多個專家 AI 模型的預測結果中得出的疾病診斷和人口統計預測。我們觀察到，在針對開放式和封閉式對話進行評估時，回應有顯著的統計改善。透過結合最先進的診斷模型和 VLM 的力量，D-Rax 使臨床醫生能夠使用自然語言與醫學影像互動，這可能會簡化他們的決策過程、提高診斷準確性並節省他們的時間。

##### **MMedAgent: Learning to Use Medical Tools with Multi-modal Agent**
2407.02483v1 by Binxu Li, Tiankai Yan, Yuanting Pan, Zhe Xu, Jie Luo, Ruiyang Ji, Shilong Liu, Haoyu Dong, Zihao Lin, Yixin Wang

Multi-Modal Large Language Models (MLLMs), despite being successful, exhibit
limited generality and often fall short when compared to specialized models.
Recently, LLM-based agents have been developed to address these challenges by
selecting appropriate specialized models as tools based on user inputs.
However, such advancements have not been extensively explored within the
medical domain. To bridge this gap, this paper introduces the first agent
explicitly designed for the medical field, named \textbf{M}ulti-modal
\textbf{Med}ical \textbf{Agent} (MMedAgent). We curate an instruction-tuning
dataset comprising six medical tools solving seven tasks, enabling the agent to
choose the most suitable tools for a given task. Comprehensive experiments
demonstrate that MMedAgent achieves superior performance across a variety of
medical tasks compared to state-of-the-art open-source methods and even the
closed-source model, GPT-4o. Furthermore, MMedAgent exhibits efficiency in
updating and integrating new medical tools.

摘要：儘管多模態大型語言模型 (MLLM) 成功，但其普遍性有限，與專用模型相比時常有所不足。
最近，基於 LLM 的代理已被開發出來，以透過根據使用者輸入選擇適當的專用模型作為工具來解決這些挑戰。
然而，此類進展尚未在醫療領域中廣泛探討。為了彌補此差距，本文介紹了第一個專門為醫療領域設計的代理，名為**M**ulti-modal **Med**ical **Agent** (MMedAgent)。我們整理了一個由六種解決七項任務的醫療工具組成的指令調整資料集，讓代理能夠為特定任務選擇最合適的工具。全面的實驗證明，與最先進的開源方法，甚至閉源模型 GPT-4o 相比，MMedAgent 在各種醫療任務中都取得了優異的表現。此外，MMedAgent 在更新和整合新的醫療工具方面展現出效率。

##### **CALICO: Confident Active Learning with Integrated Calibration**
2407.02335v1 by Lorenzo S. Querol, Hajime Nagahara, Hideaki Hayashi

The growing use of deep learning in safety-critical applications, such as
medical imaging, has raised concerns about limited labeled data, where this
demand is amplified as model complexity increases, posing hurdles for domain
experts to annotate data. In response to this, active learning (AL) is used to
efficiently train models with limited annotation costs. In the context of deep
neural networks (DNNs), AL often uses confidence or probability outputs as a
score for selecting the most informative samples. However, modern DNNs exhibit
unreliable confidence outputs, making calibration essential. We propose an AL
framework that self-calibrates the confidence used for sample selection during
the training process, referred to as Confident Active Learning with Integrated
CalibratiOn (CALICO). CALICO incorporates the joint training of a classifier
and an energy-based model, instead of the standard softmax-based classifier.
This approach allows for simultaneous estimation of the input data distribution
and the class probabilities during training, improving calibration without
needing an additional labeled dataset. Experimental results showcase improved
classification performance compared to a softmax-based classifier with fewer
labeled samples. Furthermore, the calibration stability of the model is
observed to depend on the prior class distribution of the data.

摘要：深度學習在安全關鍵應用中使用日益廣泛，例如醫學影像，這引發了對標籤數據有限的擔憂，隨著模型複雜性的增加，這種需求會被放大，這對領域專家註解數據構成了障礙。為了應對這一問題，主動學習 (AL) 被用於以有限的註解成本有效地訓練模型。在深度神經網路 (DNN) 的背景下，AL 經常使用置信度或機率輸出作為選擇最有資訊性的樣本的分數。然而，現代 DNN 表現出不可靠的置信度輸出，這使得校準至關重要。我們提出了一個 AL 框架，它會在訓練過程中自行校準用於樣本選擇的置信度，稱為具有整合校準的自信主動學習 (CALICO)。CALICO 結合了分類器和基於能量的模型的聯合訓練，而不是標準的基於 softmax 的分類器。這種方法允許在訓練期間同時估計輸入數據分佈和類別機率，從而改進校準，而無需額外的標籤數據集。實驗結果表明，與基於 softmax 的分類器相比，在標籤樣本較少的情況下，分類性能得到了改善。此外，觀察到模型的校準穩定性取決於數據的先驗類別分佈。

##### **A Refreshed Similarity-based Upsampler for Direct High-Ratio Feature Upsampling**
2407.02283v1 by Minghao Zhou, Hong Wang, Yefeng Zheng, Deyu Meng

Feature upsampling is a fundamental and indispensable ingredient of almost
all current network structures for image segmentation tasks. Recently, a
popular similarity-based feature upsampling pipeline has been proposed, which
utilizes a high-resolution feature as guidance to help upsample the
low-resolution deep feature based on their local similarity. Albeit achieving
promising performance, this pipeline has specific limitations: 1) HR query and
LR key features are not well aligned; 2) the similarity between query-key
features is computed based on the fixed inner product form; 3) neighbor
selection is coarsely operated on LR features, resulting in mosaic artifacts.
These shortcomings make the existing methods along this pipeline primarily
applicable to hierarchical network architectures with iterative features as
guidance and they are not readily extended to a broader range of structures,
especially for a direct high-ratio upsampling. Against the issues, we
meticulously optimize every methodological design. Specifically, we firstly
propose an explicitly controllable query-key feature alignment from both
semantic-aware and detail-aware perspectives, and then construct a
parameterized paired central difference convolution block for flexibly
calculating the similarity between the well-aligned query-key features.
Besides, we develop a fine-grained neighbor selection strategy on HR features,
which is simple yet effective for alleviating mosaic artifacts. Based on these
careful designs, we systematically construct a refreshed similarity-based
feature upsampling framework named ReSFU. Extensive experiments substantiate
that our proposed ReSFU is finely applicable to various types of architectures
in a direct high-ratio upsampling manner, and consistently achieves
satisfactory performance on different segmentation applications, showing
superior generality and ease of deployment.

摘要：特徵上採樣是目前幾乎所有用於影像分割任務的網路結構中不可或缺的基本要素。最近，有人提出了一種基於相似度的特徵上採樣管道，它利用高解析度特徵作為指引，根據其局部相似度幫助上採樣低解析度深度特徵。儘管取得了有希望的效能，但此管道有特定的限制：1）HR 查詢和 LR 關鍵特徵未對齊；2）查詢鍵特徵之間的相似度是根據固定的內積形式計算的；3）鄰居選擇是粗略地對 LR 特徵進行操作，導致馬賽克偽影。這些缺點使得沿著此管道的現有方法主要適用於具有迭代特徵作為指引的分層網路架構，並且它們不容易擴充套件到更廣泛的結構，特別是對於直接的高比率上採樣。針對這些問題，我們仔細優化了每一個方法論設計。具體來說，我們首先提出了從語義感知和細節感知的角度進行明確可控的查詢鍵特徵對齊，然後構建一個參數化的配對中心差分卷積塊，以靈活地計算對齊良好的查詢鍵特徵之間的相似度。此外，我們在 HR 特徵上開發了一個細粒度的鄰居選擇策略，它對於減輕馬賽克偽影既簡單又有效。根據這些仔細的設計，我們系統地構建了一個名為 ReSFU 的更新的基於相似度的特徵上採樣框架。大量的實驗證實，我們提出的 ReSFU 精細地適用於各種類型的架構，採用直接的高比率上採樣方式，並且在不同的分割應用中始終如一地取得令人滿意的效能，展現出優越的通用性和易於部署性。

##### **FedIA: Federated Medical Image Segmentation with Heterogeneous Annotation Completeness**
2407.02280v2 by Yangyang Xiang, Nannan Wu, Li Yu, Xin Yang, Kwang-Ting Cheng, Zengqiang Yan

Federated learning has emerged as a compelling paradigm for medical image
segmentation, particularly in light of increasing privacy concerns. However,
most of the existing research relies on relatively stringent assumptions
regarding the uniformity and completeness of annotations across clients.
Contrary to this, this paper highlights a prevalent challenge in medical
practice: incomplete annotations. Such annotations can introduce incorrectly
labeled pixels, potentially undermining the performance of neural networks in
supervised learning. To tackle this issue, we introduce a novel solution, named
FedIA. Our insight is to conceptualize incomplete annotations as noisy data
(i.e., low-quality data), with a focus on mitigating their adverse effects. We
begin by evaluating the completeness of annotations at the client level using a
designed indicator. Subsequently, we enhance the influence of clients with more
comprehensive annotations and implement corrections for incomplete ones,
thereby ensuring that models are trained on accurate data. Our method's
effectiveness is validated through its superior performance on two extensively
used medical image segmentation datasets, outperforming existing solutions. The
code is available at https://github.com/HUSTxyy/FedIA.

摘要：联邦学习已成为医学图像分割中一种引人注目的范例，尤其是在隐私问题日益受到关注的情况下。然而，现有的大多数研究都依赖于关于跨客户端注释一致性和完整性的相对严格的假设。与此相反，本文重点介绍了医学实践中普遍存在的挑战：不完整的注释。此类注释可能会引入错误标记的像素，从而可能损害神经网络在监督学习中的性能。为了解决这个问题，我们引入了一种名为 FedIA 的新颖解决方案。我们的见解是将不完整的注释概念化为噪声数据（即低质量数据），重点在于减轻其不利影响。我们首先使用设计的指标评估客户端级别的注释完整性。随后，我们增强了具有更全面注释的客户端的影响力，并对不完整的注释实施了更正，从而确保模型在准确的数据上进行训练。我们方法的有效性通过其在两个广泛使用的医学图像分割数据集上的卓越性能得到验证，优于现有的解决方案。代码可在 https://github.com/HUSTxyy/FedIA 获得。

##### **Generative Monoculture in Large Language Models**
2407.02209v1 by Fan Wu, Emily Black, Varun Chandrasekaran

We introduce {\em generative monoculture}, a behavior observed in large
language models (LLMs) characterized by a significant narrowing of model output
diversity relative to available training data for a given task: for example,
generating only positive book reviews for books with a mixed reception. While
in some cases, generative monoculture enhances performance (e.g., LLMs more
often produce efficient code), the dangers are exacerbated in others (e.g.,
LLMs refuse to share diverse opinions). As LLMs are increasingly used in
high-impact settings such as education and web search, careful maintenance of
LLM output diversity is essential to ensure a variety of facts and perspectives
are preserved over time. We experimentally demonstrate the prevalence of
generative monoculture through analysis of book review and code generation
tasks, and find that simple countermeasures such as altering sampling or
prompting strategies are insufficient to mitigate the behavior. Moreover, our
results suggest that the root causes of generative monoculture are likely
embedded within the LLM's alignment processes, suggesting a need for developing
fine-tuning paradigms that preserve or promote diversity.

摘要：<paragraph>我們介紹了「生成單一文化」，這是一種在大型語言模型 (LLM) 中觀察到的行為，其特徵是模型輸出多樣性相對於給定任務的可用訓練資料顯著變窄：例如，只為評價褒貶不一的書籍生成正面的書評。雖然在某些情況下，生成單一文化會增強效能（例如，LLM 更常產生高效的程式碼），但其危險性在其他情況下會加劇（例如，LLM 拒絕分享不同的意見）。由於 LLM 愈來愈多地用於教育和網路搜尋等高影響力的環境中，仔細維護 LLM 輸出的多樣性對於確保隨著時間推移，各種事實和觀點都能被保留下來至關重要。我們透過分析書評和程式碼生成任務，以實驗方式證明了生成單一文化的普遍性，並發現簡單的對策，例如改變抽樣或提示策略，不足以減輕這種行為。此外，我們的結果表明，生成單一文化的根本原因可能存在於 LLM 的比對過程中，這表明需要開發能保留或促進多樣性的微調範例。</paragraph>

##### **Abstract Dialectical Frameworks are Boolean Networks (full version)**
2407.02055v1 by Jesse Heyninck, Matthias Knorr, João Leite

Dialectical frameworks are a unifying model of formal argumentation, where
argumentative relations between arguments are represented by assigning
acceptance conditions to atomic arguments. Their generality allow them to cover
a number of different approaches with varying forms of representing the
argumentation structure. Boolean regulatory networks are used to model the
dynamics of complex biological processes, taking into account the interactions
of biological compounds, such as proteins or genes. These models have proven
highly useful for comprehending such biological processes, allowing to
reproduce known behaviour and testing new hypotheses and predictions in silico,
for example in the context of new medical treatments. While both these
approaches stem from entirely different communities, it turns out that there
are striking similarities in their appearence. In this paper, we study the
relation between these two formalisms revealing their communalities as well as
their differences, and introducing a correspondence that allows to establish
novel results for the individual formalisms.

摘要：辯證框架是形式論證的統一模型，其中論證之間的論證關係是透過指派接受條件給原子論證來表示。它們的普遍性允許它們涵蓋許多不同的方法，並以不同的形式表示論證結構。布林法規網路用於模擬複雜生物過程的動態，考量生物化合物（例如蛋白質或基因）的交互作用。這些模型已被證明對於理解此類生物過程非常有用，允許複製已知的行為並在電腦模擬中測試新的假設和預測，例如在新的醫療治療的背景下。儘管這兩種方法完全來自不同的社群，但事實證明它們的外觀有驚人的相似性。在本文中，我們研究這兩種形式主義之間的關係，揭示它們的共性以及它們的差異，並引入一種對應關係，允許為個別形式主義建立新的結果。

##### **A Method to Facilitate Membership Inference Attacks in Deep Learning Models**
2407.01919v1 by Zitao Chen, Karthik Pattabiraman

Modern machine learning (ML) ecosystems offer a surging number of ML
frameworks and code repositories that can greatly facilitate the development of
ML models. Today, even ordinary data holders who are not ML experts can apply
off-the-shelf codebase to build high-performance ML models on their data, many
of which are sensitive in nature (e.g., clinical records).
  In this work, we consider a malicious ML provider who supplies model-training
code to the data holders, does not have access to the training process, and has
only black-box query access to the resulting model. In this setting, we
demonstrate a new form of membership inference attack that is strictly more
powerful than prior art. Our attack empowers the adversary to reliably
de-identify all the training samples (average >99% attack TPR@0.1% FPR), and
the compromised models still maintain competitive performance as their
uncorrupted counterparts (average <1% accuracy drop). Moreover, we show that
the poisoned models can effectively disguise the amplified membership leakage
under common membership privacy auditing, which can only be revealed by a set
of secret samples known by the adversary.
  Overall, our study not only points to the worst-case membership privacy
leakage, but also unveils a common pitfall underlying existing privacy auditing
methods, which calls for future efforts to rethink the current practice of
auditing membership privacy in machine learning models.

摘要：現代機器學習 (ML) 生態系統提供了大量的 ML 框架和程式碼儲存庫，可以極大地促進 ML 模型的開發。如今，即使不是 ML 專家的普通資料持有者也可以套用現成的程式碼庫，根據其資料建立高性能 ML 模型，其中許多資料本質上很敏感（例如：臨床紀錄）。
  在這項工作中，我們考慮了一個惡意的 ML 提供者，他向資料持有者提供模型訓練程式碼，無法存取訓練程序，而且只能透過黑盒子查詢存取產生的模型。在此設定中，我們展示了一種新的成員推論攻擊形式，它比先前的技術更強大。我們的攻擊讓對手能夠可靠地取消識別所有訓練範例（平均 >99% 攻擊 TPR@0.1% FPR），而且受損的模型仍然保持與未受損的模型一樣的競爭力（平均 <1% 準確度下降）。此外，我們展示了中毒的模型可以有效地隱藏在常見成員隱私稽核下的擴增成員洩漏，這只能由對手知道的秘密範例集揭露。
  總的來說，我們的研究不僅指出最壞情況的成員隱私洩漏，還揭示了現有隱私稽核方法中的一個常見陷阱，這需要未來的努力來重新思考目前在機器學習模型中稽核成員隱私的做法。

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

摘要：床邊超音波 (POCUS) 是臨床醫師在患者床邊進行和解讀超音波掃描的實務。然而，解讀這些影像所需的專業知識相當可觀，而且在緊急情況下可能並非隨時具備。這種現實情況使得機器學習分類器等演算法對於加強人類決策變得極為有價值。POCUS 裝置正以合理成本推出，尺寸為手機大小。將 POCUS 裝置轉變為救生工具的挑戰在於，解讀超音波影像需要專門訓練和經驗。不幸的是，取得正向訓練影像的困難度代表著建置有效率且準確的分類器的一大障礙。因此，我們嘗試探討的問題是如何探索策略，以提高使用稀疏資料訓練的分類器的準確度。我們假設使用少數資料實例進行訓練可能不足以讓分類器概括，導致它們過度擬合。我們的做法使用可解釋 AI 增強方法，以協助演算法從較少的資料中學習更多，並潛在協助分類器更好地概括。

##### **Optimized Learning for X-Ray Image Classification for Multi-Class Disease Diagnoses with Accelerated Computing Strategies**
2407.01705v1 by Sebastian A. Cruz Romero, Ivanelyz Rivera de Jesus, Dariana J. Troche Quinones, Wilson Rivera Gallego

X-ray image-based disease diagnosis lies in ensuring the precision of
identifying afflictions within the sample, a task fraught with challenges
stemming from the occurrence of false positives and false negatives. False
positives introduce the risk of erroneously identifying non-existent
conditions, leading to misdiagnosis and a decline in patient care quality.
Conversely, false negatives pose the threat of overlooking genuine
abnormalities, potentially causing delays in treatment and interventions,
thereby resulting in adverse patient outcomes. The urgency to overcome these
challenges compels ongoing efforts to elevate the precision and reliability of
X-ray image analysis algorithms within the computational framework. This study
introduces modified pre-trained ResNet models tailored for multi-class disease
diagnosis of X-ray images, incorporating advanced optimization strategies to
reduce the execution runtime of training and inference tasks. The primary
objective is to achieve tangible performance improvements through accelerated
implementations of PyTorch, CUDA, Mixed- Precision Training, and Learning Rate
Scheduler. While outcomes demonstrate substantial improvements in execution
runtimes between normal training and CUDA-accelerated training, negligible
differences emerge between various training optimization modalities. This
research marks a significant advancement in optimizing computational approaches
to reduce training execution time for larger models. Additionally, we explore
the potential of effective parallel data processing using MPI4Py for the
distribution of gradient descent optimization across multiple nodes and
leverage multiprocessing to expedite data preprocessing for larger datasets.

摘要：X 光影像疾病診斷在於確保識別樣本中疾病的精確性，這項任務充滿了挑戰，源自於假陽性和假陰性的發生。假陽性會帶來錯誤識別不存在的疾病的風險，導致誤診和患者照護品質下降。相反地，假陰性會帶來忽略真正異常的威脅，可能會導致治療和介入延誤，從而導致患者預後不良。克服這些挑戰的迫切性促使持續努力提升計算架構中 X 光影像分析演算法的精確度和可靠性。本研究引入了針對 X 光影像的多類疾病診斷量身打造的修改後預先訓練的 ResNet 模型，並結合先進的最佳化策略以減少訓練和推論任務的執行執行時間。主要目標是透過加速實作 PyTorch、CUDA、混合精度訓練和學習率排程器，來達成具體的效能提升。雖然結果顯示正常訓練和 CUDA 加速訓練之間的執行執行時間有大幅改善，但各種訓練最佳化模式之間的差異可以忽略不計。這項研究標誌著最佳化計算方法以減少較大型模型訓練執行時間的重大進展。此外，我們探索使用 MPI4Py 進行有效平行資料處理的可能性，以在多個節點上進行梯度下降最佳化，並利用多處理來加速較大型資料集的資料前處理。

##### **Deep Dive into MRI: Exploring Deep Learning Applications in 0.55T and 7T MRI**
2407.01318v1 by Ana Carolina Alves, André Ferreira, Behrus Puladi, Jan Egger, Victor Alves

The development of magnetic resonance imaging (MRI) for medical imaging has
provided a leap forward in diagnosis, providing a safe, non-invasive
alternative to techniques involving ionising radiation exposure for diagnostic
purposes. It was described by Block and Purcel in 1946, and it was not until
1980 that the first clinical application of MRI became available. Since that
time the MRI has gone through many advances and has altered the way diagnosing
procedures are performed. Due to its ability to improve constantly, MRI has
become a commonly used practice among several specialisations in medicine.
Particularly starting 0.55T and 7T MRI technologies have pointed out enhanced
preservation of image detail and advanced tissue characterisation. This review
examines the integration of deep learning (DL) techniques into these MRI
modalities, disseminating and exploring the study applications. It highlights
how DL contributes to 0.55T and 7T MRI data, showcasing the potential of DL in
improving and refining these technologies. The review ends with a brief
overview of how MRI technology will evolve in the coming years.

摘要：磁共振成像 (MRI) 在医学影像上的發展，為診斷技術帶來重大進展，提供一種安全、非侵入性的替代方案，以取代使用電離輻射進行診斷的技術。此技術由布洛克與珀塞爾於 1946 年提出，直到 1980 年，MRI 才首次應用於臨床。自那時起，MRI 經歷了許多進步，並改變了診斷程序的執行方式。由於 MRI 能持續改進，因此已成為醫學中多種專科的常用技術。特別是從 0.55T 和 7T MRI 技術開始，已指出增強影像細節的保存和進階組織表徵。本篇評論探討深度學習 (DL) 技術整合到這些 MRI 模式中，傳播並探討研究應用。它強調 DL 如何貢獻於 0.55T 和 7T MRI 資料，展示 DL 在改善和精進這些技術的潛力。本評論最後簡要概述 MRI 技術在未來幾年的發展方式。

##### **MIRAI: Evaluating LLM Agents for Event Forecasting**
2407.01231v1 by Chenchen Ye, Ziniu Hu, Yihe Deng, Zijie Huang, Mingyu Derek Ma, Yanqiao Zhu, Wei Wang

Recent advancements in Large Language Models (LLMs) have empowered LLM agents
to autonomously collect world information, over which to conduct reasoning to
solve complex problems. Given this capability, increasing interests have been
put into employing LLM agents for predicting international events, which can
influence decision-making and shape policy development on an international
scale. Despite such a growing interest, there is a lack of a rigorous benchmark
of LLM agents' forecasting capability and reliability. To address this gap, we
introduce MIRAI, a novel benchmark designed to systematically evaluate LLM
agents as temporal forecasters in the context of international events. Our
benchmark features an agentic environment with tools for accessing an extensive
database of historical, structured events and textual news articles. We refine
the GDELT event database with careful cleaning and parsing to curate a series
of relational prediction tasks with varying forecasting horizons, assessing LLM
agents' abilities from short-term to long-term forecasting. We further
implement APIs to enable LLM agents to utilize different tools via a code-based
interface. In summary, MIRAI comprehensively evaluates the agents' capabilities
in three dimensions: 1) autonomously source and integrate critical information
from large global databases; 2) write codes using domain-specific APIs and
libraries for tool-use; and 3) jointly reason over historical knowledge from
diverse formats and time to accurately predict future events. Through
comprehensive benchmarking, we aim to establish a reliable framework for
assessing the capabilities of LLM agents in forecasting international events,
thereby contributing to the development of more accurate and trustworthy models
for international relation analysis.

摘要：<paragraph>大型語言模型 (LLM) 的最新進展賦予了 LLM 代理自主收集世界資訊的能力，並基於這些資訊進行推理以解決複雜問題。鑑於此功能，將 LLM 代理用於預測國際事件的興趣日益濃厚，這可能會影響決策制定並在國際層面上塑造政策發展。儘管有如此濃厚的興趣，但缺乏對 LLM 代理預測能力和可靠性的嚴格基準。為了解決這一差距，我們引入了 MIRAI，這是一個新基準，旨在系統地評估 LLM 代理作為國際事件時間預測者的能力。我們的基準特點是提供一個代理環境，其中包含訪問大量歷史結構化事件和文字新聞文章的工具。我們通過仔細清理和解析 GDELT 事件資料庫，策劃了一系列具有不同預測範圍的關係預測任務，評估 LLM 代理從短期到長期預測的能力。我們進一步實作 API，使 LLM 代理能夠透過基於程式碼的介面使用不同的工具。總之，MIRAI 全面評估了代理在三個維度上的能力：1) 自主地從大型全球資料庫中獲取和整合關鍵資訊；2) 使用特定領域的 API 和程式庫編寫程式碼以使用工具；3) 共同推理來自不同格式和時間的歷史知識，以準確預測未來事件。透過全面的基準測試，我們旨在建立一個可靠的框架，用於評估 LLM 代理在預測國際事件方面的能力，從而為國際關係分析的更準確和值得信賴的模型的開發做出貢獻。</paragraph>

##### **Integrated feature analysis for deep learning interpretation and class activation maps**
2407.01142v1 by Yanli Li, Tahereh Hassanzadeh, Denis P. Shamonin, Monique Reijnierse, Annette H. M. van der Helm-van Mil, Berend C. Stoel

Understanding the decisions of deep learning (DL) models is essential for the
acceptance of DL to risk-sensitive applications. Although methods, like class
activation maps (CAMs), give a glimpse into the black box, they do miss some
crucial information, thereby limiting its interpretability and merely providing
the considered locations of objects. To provide more insight into the models
and the influence of datasets, we propose an integrated feature analysis
method, which consists of feature distribution analysis and feature
decomposition, to look closer into the intermediate features extracted by DL
models. This integrated feature analysis could provide information on
overfitting, confounders, outliers in datasets, model redundancies and
principal features extracted by the models, and provide distribution
information to form a common intensity scale, which are missing in current CAM
algorithms. The integrated feature analysis was applied to eight different
datasets for general validation: photographs of handwritten digits, two
datasets of natural images and five medical datasets, including skin
photography, ultrasound, CT, X-rays and MRIs. The method was evaluated by
calculating the consistency between the CAMs average class activation levels
and the logits of the model. Based on the eight datasets, the correlation
coefficients through our method were all very close to 100%, and based on the
feature decomposition, 5%-25% of features could generate equally informative
saliency maps and obtain the same model performances as using all features.
This proves the reliability of the integrated feature analysis. As the proposed
methods rely on very few assumptions, this is a step towards better model
interpretation and a useful extension to existing CAM algorithms. Codes:
https://github.com/YanliLi27/IFA

摘要：<paragraph>了解深度學習（DL）模型的決策對於風險敏感應用程式接受 DL 至關重要。儘管方法（如類別激勵映射 (CAM)）讓黑盒子得以一窺究竟，但它們仍遺漏了一些關鍵資訊，因而限制了解釋能力，僅提供物件被考慮的位置。為了更深入瞭解模型和資料集的影響，我們提出了一種整合特徵分析方法，包括特徵分佈分析和特徵分解，以更仔細地檢視 DL 模型提取的中間特徵。這種整合特徵分析可以提供有關過度擬合、混淆變數、資料集中的異常值、模型冗餘和模型提取的主要特徵的資訊，並提供分佈資訊以形成共同的強度量表，這是目前 CAM 演算法所缺少的。整合特徵分析已應用於八個不同的資料集以進行一般驗證：手寫數字照片、兩個自然影像資料集和五個醫學資料集，包括皮膚攝影、超音波、電腦斷層掃描、X 光和 MRI。該方法透過計算 CAM 平均類別激勵層級與模型的 logit 值之間的一致性來評估。根據這八個資料集，我們的方法得出的相關係數都非常接近 100%，根據特徵分解，5%-25% 的特徵可以產生同樣具有資訊性的顯著性圖，並獲得與使用所有特徵相同的模型效能。這證明了整合特徵分析的可靠性。由於所提出的方法依賴的假設很少，因此這是朝向更好的模型解釋邁出的一步，也是對現有 CAM 演算法有用的延伸。程式碼：https://github.com/YanliLi27/IFA</paragraph>

##### **An Outline of Prognostics and Health Management Large Model: Concepts, Paradigms, and Challenges**
2407.03374v1 by Laifa Tao, Shangyu Li, Haifei Liu, Qixuan Huang, Liang Ma, Guoao Ning, Yiling Chen, Yunlong Wu, Bin Li, Weiwei Zhang, Zhengduo Zhao, Wenchao Zhan, Wenyan Cao, Chao Wang, Hongmei Liu, Jian Ma, Mingliang Suo, Yujie Cheng, Yu Ding, Dengwei Song, Chen Lu

Prognosis and Health Management (PHM), critical for ensuring task completion
by complex systems and preventing unexpected failures, is widely adopted in
aerospace, manufacturing, maritime, rail, energy, etc. However, PHM's
development is constrained by bottlenecks like generalization, interpretation
and verification abilities. Presently, generative artificial intelligence (AI),
represented by Large Model, heralds a technological revolution with the
potential to fundamentally reshape traditional technological fields and human
production methods. Its capabilities, including strong generalization,
reasoning, and generative attributes, present opportunities to address PHM's
bottlenecks. To this end, based on a systematic analysis of the current
challenges and bottlenecks in PHM, as well as the research status and
advantages of Large Model, we propose a novel concept and three progressive
paradigms of Prognosis and Health Management Large Model (PHM-LM) through the
integration of the Large Model with PHM. Subsequently, we provide feasible
technical approaches for PHM-LM to bolster PHM's core capabilities within the
framework of the three paradigms. Moreover, to address core issues confronting
PHM, we discuss a series of technical challenges of PHM-LM throughout the
entire process of construction and application. This comprehensive effort
offers a holistic PHM-LM technical framework, and provides avenues for new PHM
technologies, methodologies, tools, platforms and applications, which also
potentially innovates design, research & development, verification and
application mode of PHM. And furthermore, a new generation of PHM with AI will
also capably be realized, i.e., from custom to generalized, from discriminative
to generative, and from theoretical conditions to practical applications.

摘要：預測與健康管理 (PHM) 對於確保複雜系統任務完成和防止意外故障至關重要，廣泛應用於航空、製造、海事、鐵路、能源等領域。然而，PHM 的發展受到泛化、解釋和驗證能力等瓶頸的制約。目前，以大模型為代表的生成式人工智慧 (AI) 預示著一場技術革命，有潛力從根本上重塑傳統技術領域和人類生產方式。其包括強泛化、推理和生成屬性在內的能力，為解決 PHM 的瓶頸提供了機會。為此，我們基於對 PHM 現有挑戰和瓶頸的系統分析，以及大模型的研究現狀和優勢，通過將大模型與 PHM 相結合，提出了預測與健康管理大模型 (PHM-LM) 的新概念和三個進步範例。隨後，我們在三個範例的框架內為 PHM-LM 提供了可行的技術方法，以加強 PHM 的核心能力。此外，為了解決 PHM 面臨的核心問題，我們在整個構建和應用過程中討論了 PHM-LM 的一系列技術挑戰。這項綜合工作提供了一個整體的 PHM-LM 技術框架，並為新的 PHM 技術、方法、工具、平台和應用程式提供了途徑，也可能創新 PHM 的設計、研發、驗證和應用模式。此外，還將能夠實現新一代具備 AI 的 PHM，即從客製化到泛化、從判別式到生成式，以及從理論條件到實際應用。

##### **Embedded Prompt Tuning: Towards Enhanced Calibration of Pretrained Models for Medical Images**
2407.01003v2 by Wenqiang Zu, Shenghao Xie, Qing Zhao, Guoqi Li, Lei Ma

Foundation models pre-trained on large-scale data have been widely witnessed
to achieve success in various natural imaging downstream tasks.
Parameter-efficient fine-tuning (PEFT) methods aim to adapt foundation models
to new domains by updating only a small portion of parameters in order to
reduce computational overhead. However, the effectiveness of these PEFT
methods, especially in cross-domain few-shot scenarios, e.g., medical image
analysis, has not been fully explored. In this work, we facilitate the study of
the performance of PEFT when adapting foundation models to medical image
classification tasks. Furthermore, to alleviate the limitations of prompt
introducing ways and approximation capabilities on Transformer architectures of
mainstream prompt tuning methods, we propose the Embedded Prompt Tuning (EPT)
method by embedding prompt tokens into the expanded channels. We also find that
there are anomalies in the feature space distribution of foundation models
during pre-training process, and prompt tuning can help mitigate this negative
impact. To explain this phenomenon, we also introduce a novel perspective to
understand prompt tuning: Prompt tuning is a distribution calibrator. And we
support it by analyzing patch-wise scaling and feature separation operations
contained in EPT. Our experiments show that EPT outperforms several
state-of-the-art fine-tuning methods by a significant margin on few-shot
medical image classification tasks, and completes the fine-tuning process
within highly competitive time, indicating EPT is an effective PEFT method. The
source code is available at github.com/zuwenqiang/EPT.

摘要：<paragraph>在大規模資料上預先訓練的基礎模型已被廣泛證明
在各種自然影像下游任務中取得成功。
參數有效微調 (PEFT) 方法旨在通過僅更新一小部分參數來適應基礎模型
到新網域，以減少運算開銷。然而，這些 PEFT 的有效性
方法，特別是在跨網域少次拍攝場景中，例如醫學影像
分析尚未得到充分探討。在這項工作中，我們促進了
研究 PEFT 在適應基礎模型到醫學影像時的效果
分類任務。此外，為了緩解提示的限制
在主流提示調整方法的 Transformer 架構上引入方式和近似能力，我們提出了嵌入式提示調整 (EPT)
方法是將提示代幣嵌入到擴展的通道中。我們還發現
在預訓練過程中，基礎模型的特徵空間分佈存在異常，並且提示調整可以幫助減輕這種負面
影響。為了解釋這種現象，我們還引入了一個新穎的觀點來
了解提示調整：提示調整是一個分佈校準器。我們
通過分析 EPT 中包含的補丁式縮放和特徵分離操作來支持它。我們的實驗表明，EPT 在少次拍攝中優於幾種最先進的微調方法
醫學影像分類任務的邊際，並在極具競爭力的時間內完成微調過程，表明 EPT 是一種有效的 PEFT 方法。
源代碼可在 github.com/zuwenqiang/EPT 中獲得。</paragraph>

##### **Individual brain parcellation: Review of methods, validations and applications**
2407.00984v1 by Chengyi Li, Shan Yu, Yue Cui

Individual brains vary greatly in morphology, connectivity and organization.
The applicability of group-level parcellations is limited by the rapid
development of precision medicine today because they do not take into account
the variation of parcels at the individual level. Accurate mapping of brain
functional regions at the individual level is pivotal for a comprehensive
understanding of the variations in brain function and behaviors, early and
precise identification of brain abnormalities, as well as personalized
treatments for neuropsychiatric disorders. With the development of neuroimaging
and machine learning techniques, studies on individual brain parcellation are
booming. In this paper, we offer an overview of recent advances in the
methodologies of individual brain parcellation, including optimization- and
learning-based methods. Comprehensive evaluation metrics to validate individual
brain mapping have been introduced. We also review the studies of how
individual brain mapping promotes neuroscience research and clinical medicine.
Finally, we summarize the major challenges and important future directions of
individualized brain parcellation. Collectively, we intend to offer a thorough
overview of individual brain parcellation methods, validations, and
applications, along with highlighting the current challenges that call for an
urgent demand for integrated platforms that integrate datasets, methods, and
validations.

摘要：各個大腦在形態、連接性和組織上差異極大。
群體層級的區塊化適用性受到當今精準醫療的快速發展所限制，因為它們沒有考慮到個體層級的區塊變異。在個體層級準確繪製大腦功能區域對於全面了解大腦功能和行為的變異、早期且精確地識別大腦異常，以及神經精神疾病的個人化治療至關重要。隨著神經影像和機器學習技術的發展，關於個別大腦區塊化的研究正在蓬勃發展。在本文中，我們概述了個別大腦區塊化方法學的最新進展，包括基於最佳化和學習的方法。已經引入了全面的評估指標來驗證個別大腦對應。我們還回顧了個別大腦對應如何促進神經科學研究和臨床醫學的研究。最後，我們總結了個別化大腦區塊化的主要挑戰和重要的未來方向。總的來說，我們打算對個別大腦區塊化方法、驗證和應用提供全面的概述，同時強調當前挑戰，這些挑戰迫切需要整合數據集、方法和驗證的整合平台。

##### **Hybrid RAG-empowered Multi-modal LLM for Secure Healthcare Data Management: A Diffusion-based Contract Theory Approach**
2407.00978v1 by Cheng Su, Jinbo Wen, Jiawen Kang, Yonghua Wang, Hudan Pan, M. Shamim Hossain

Secure data management and effective data sharing have become paramount in
the rapidly evolving healthcare landscape. The advancement of generative
artificial intelligence has positioned Multi-modal Large Language Models
(MLLMs) as crucial tools for managing healthcare data. MLLMs can support
multi-modal inputs and generate diverse types of content by leveraging
large-scale training on vast amounts of multi-modal data. However, critical
challenges persist in developing medical MLLMs, including healthcare data
security and freshness issues, affecting the output quality of MLLMs. In this
paper, we propose a hybrid Retrieval-Augmented Generation (RAG)-empowered
medical MLLMs framework for healthcare data management. This framework
leverages a hierarchical cross-chain architecture to facilitate secure data
training. Moreover, it enhances the output quality of MLLMs through hybrid RAG,
which employs multi-modal metrics to filter various unimodal RAG results and
incorporates these retrieval results as additional inputs to MLLMs.
Additionally, we employ age of information to indirectly evaluate the data
freshness impact of MLLMs and utilize contract theory to incentivize healthcare
data holders to share fresh data, mitigating information asymmetry in data
sharing. Finally, we utilize a generative diffusion model-based reinforcement
learning algorithm to identify the optimal contract for efficient data sharing.
Numerical results demonstrate the effectiveness of the proposed schemes, which
achieve secure and efficient healthcare data management.

摘要：在快速變化的醫療保健領域中，安全數據管理和有效數據共享已變得至關重要。生成式人工智慧的進步已將多模態大型語言模型 (MLLM) 定位為管理醫療保健數據的關鍵工具。MLLM 可支援多模態輸入，並透過利用大量多模態數據進行大規模訓練來產生各種類型的內容。然而，在開發醫療 MLLM 時仍存在關鍵挑戰，包括醫療保健數據安全性與新穎性問題，影響 MLLM 的輸出品質。在本文中，我們提出一個由檢索增強生成 (RAG) 賦能的混合醫療 MLLM 框架，用於醫療保健數據管理。此框架利用階層式跨鏈架構，以利於安全數據訓練。此外，它透過混合 RAG 來提升 MLLM 的輸出品質，此方法採用多模態指標來過濾各種單模態 RAG 結果，並將這些檢索結果作為額外輸入納入 MLLM。此外，我們採用資訊年齡來間接評估 MLLM 的數據新穎性影響，並利用契約理論來激勵醫療保健數據持有者共享新穎數據，從而減輕數據共享中的資訊不對稱。最後，我們利用生成擴散模型為基礎的強化學習演算法，以找出最佳契約，以進行有效率的數據共享。數值結果證明所提出的架構有效，可達成安全且有效率的醫療保健數據管理。

##### **Optimizing PM2.5 Forecasting Accuracy with Hybrid Meta-Heuristic and Machine Learning Models**
2407.01647v1 by Parviz Ghafariasl, Masoomeh Zeinalnezhad, Amir Ahmadishokooh

Timely alerts about hazardous air pollutants are crucial for public health.
However, existing forecasting models often overlook key factors like baseline
parameters and missing data, limiting their accuracy. This study introduces a
hybrid approach to address these issues, focusing on forecasting hourly PM2.5
concentrations using Support Vector Regression (SVR). Meta-heuristic
algorithms, Grey Wolf Optimization (GWO) and Particle Swarm Optimization (PSO),
optimize SVR Hyper-parameters "C" and "Gamma" to enhance prediction accuracy.
Evaluation metrics include R-squared (R2), Root Mean Square Error (RMSE), and
Mean Absolute Error (MAE). Results show significant improvements with PSO-SVR
(R2: 0.9401, RMSE: 0.2390, MAE: 0.1368) and GWO-SVR (R2: 0.9408, RMSE: 0.2376,
MAE: 0.1373), indicating robust and accurate models suitable for similar
research applications.

摘要：及時發布有關有害空氣污染物的警報對公共衛生至關重要。
然而，現有的預測模型通常會忽略基線參數和缺失資料等關鍵因素，從而限制了其準確性。本研究引入了一種混合方法來解決這些問題，重點關注使用支持向量回歸 (SVR) 預測每小時 PM2.5 濃度。元啟發式演算法、灰狼優化 (GWO) 和粒子群優化 (PSO) 優化 SVR 超參數「C」和「Gamma」以提高預測準確度。評估指標包括 R 平方 (R2)、均方根誤差 (RMSE) 和平均絕對誤差 (MAE)。結果顯示 PSO-SVR (R2：0.9401、RMSE：0.2390、MAE：0.1368) 和 GWO-SVR (R2：0.9408、RMSE：0.2376、MAE：0.1373) 有顯著改善，表明適用於類似研究應用程式的穩健且準確的模型。

##### **Deep learning for automated detection of breast cancer in deep ultraviolet fluorescence images with diffusion probabilistic model**
2407.00967v1 by Sepehr Salem Ghahfarokhi, Tyrell To, Julie Jorns, Tina Yen, Bing Yu, Dong Hye Ye

Data limitation is a significant challenge in applying deep learning to
medical images. Recently, the diffusion probabilistic model (DPM) has shown the
potential to generate high-quality images by converting Gaussian random noise
into realistic images. In this paper, we apply the DPM to augment the deep
ultraviolet fluorescence (DUV) image dataset with an aim to improve breast
cancer classification for intraoperative margin assessment. For classification,
we divide the whole surface DUV image into small patches and extract
convolutional features for each patch by utilizing the pre-trained ResNet.
Then, we feed them into an XGBoost classifier for patch-level decisions and
then fuse them with a regional importance map computed by Grad-CAM++ for whole
surface-level prediction. Our experimental results show that augmenting the
training dataset with the DPM significantly improves breast cancer detection
performance in DUV images, increasing accuracy from 93% to 97%, compared to
using Affine transformations and ProGAN.

摘要：資料限制是應用深度學習於醫學影像的一大挑戰。最近，擴散機率模型 (DPM) 已展現將高斯隨機雜訊轉換為逼真影像的潛力，用以產生高品質影像。在本文中，我們將 DPM 應用於擴充深度紫外螢光 (DUV) 影像資料集，目標是改善乳癌分類，用於術中邊緣評估。對於分類，我們將整個表面 DUV 影像分割成小區塊，並利用預訓練的 ResNet 為每個區塊萃取卷積特徵。接著，我們將它們輸入 XGBoost 分類器，用於區塊層級的決策，然後將它們與 Grad-CAM++ 計算出的區域重要性圖融合，用於整個表面層級的預測。我們的實驗結果顯示，使用 DPM 擴充訓練資料集可顯著提升 DUV 影像的乳癌偵測效能，與使用仿射轉換和 ProGAN 相比，準確率從 93% 提升至 97%。

##### **Characterizing Stereotypical Bias from Privacy-preserving Pre-Training**
2407.00764v1 by Stefan Arnold, Rene Gröbner, Annika Schreiner

Differential Privacy (DP) can be applied to raw text by exploiting the
spatial arrangement of words in an embedding space. We investigate the
implications of such text privatization on Language Models (LMs) and their
tendency towards stereotypical associations. Since previous studies documented
that linguistic proficiency correlates with stereotypical bias, one could
assume that techniques for text privatization, which are known to degrade
language modeling capabilities, would cancel out undesirable biases. By testing
BERT models trained on texts containing biased statements primed with varying
degrees of privacy, our study reveals that while stereotypical bias generally
diminishes when privacy is tightened, text privatization does not uniformly
equate to diminishing bias across all social domains. This highlights the need
for careful diagnosis of bias in LMs that undergo text privatization.

摘要：差分隱私 (DP) 可透過利用嵌入空間中字詞的空間排列來應用於原始文字。我們探討這種文字私有化對語言模型 (LM) 及其對刻板印象關聯的傾向所造成的影響。由於先前的研究記錄語言能力與刻板印象偏誤相關，因此可以假設已知會降低語言建模能力的文字私有化技術會消除不良偏誤。透過測試在包含以不同程度隱私為前提的偏見陳述的文字上訓練的 BERT 模型，我們的研究顯示，雖然在加強隱私時刻板印象偏誤通常會減少，但文字私有化並非在所有社會領域都等於減少偏誤。這突顯了在經過文字私有化的 LM 中仔細診斷偏誤的必要性。

##### **Chest-Diffusion: A Light-Weight Text-to-Image Model for Report-to-CXR Generation**
2407.00752v1 by Peng Huang, Xue Gao, Lihong Huang, Jing Jiao, Xiaokang Li, Yuanyuan Wang, Yi Guo

Text-to-image generation has important implications for generation of diverse
and controllable images. Several attempts have been made to adapt Stable
Diffusion (SD) to the medical domain. However, the large distribution
difference between medical reports and natural texts, as well as high
computational complexity in common stable diffusion limit the authenticity and
feasibility of the generated medical images. To solve above problems, we
propose a novel light-weight transformer-based diffusion model learning
framework, Chest-Diffusion, for report-to-CXR generation. Chest-Diffusion
employs a domain-specific text encoder to obtain accurate and expressive text
features to guide image generation, improving the authenticity of the generated
images. Meanwhile, we introduce a light-weight transformer architecture as the
denoising model, reducing the computational complexity of the diffusion model.
Experiments demonstrate that our Chest-Diffusion achieves the lowest FID score
24.456, under the computation budget of 118.918 GFLOPs, which is nearly
one-third of the computational complexity of SD.

摘要：文本到图像生成对于生成多样且可控的图像具有重要意义。已经做出了一些尝试来将 Stable Diffusion (SD) 调整到医学领域。然而，医学报告和自然文本之间存在较大的分布差异，以及常见的稳定扩散中的高计算复杂度限制了生成医学图像的真实性和可行性。为了解决上述问题，我们提出了一种新颖的轻量级基于 transformer 的扩散模型学习框架 Chest-Diffusion，用于报告到 CXR 生成。Chest-Diffusion 使用特定于领域的文本编码器来获取准确且富有表现力的文本特征以指导图像生成，从而提高生成图像的真实性。同时，我们引入了一个轻量级的 transformer 架构作为去噪模型，降低了扩散模型的计算复杂度。实验表明，我们的 Chest-Diffusion 在 118.918 GFLOP 的计算预算下实现了最低的 FID 分数 24.456，这几乎是 SD 计算复杂度的三分之一。

##### **Large Language Models Struggle in Token-Level Clinical Named Entity Recognition**
2407.00731v1 by Qiuhao Lu, Rui Li, Andrew Wen, Jinlian Wang, Liwei Wang, Hongfang Liu

Large Language Models (LLMs) have revolutionized various sectors, including
healthcare where they are employed in diverse applications. Their utility is
particularly significant in the context of rare diseases, where data scarcity,
complexity, and specificity pose considerable challenges. In the clinical
domain, Named Entity Recognition (NER) stands out as an essential task and it
plays a crucial role in extracting relevant information from clinical texts.
Despite the promise of LLMs, current research mostly concentrates on
document-level NER, identifying entities in a more general context across
entire documents, without extracting their precise location. Additionally,
efforts have been directed towards adapting ChatGPT for token-level NER.
However, there is a significant research gap when it comes to employing
token-level NER for clinical texts, especially with the use of local
open-source LLMs. This study aims to bridge this gap by investigating the
effectiveness of both proprietary and local LLMs in token-level clinical NER.
Essentially, we delve into the capabilities of these models through a series of
experiments involving zero-shot prompting, few-shot prompting,
retrieval-augmented generation (RAG), and instruction-fine-tuning. Our
exploration reveals the inherent challenges LLMs face in token-level NER,
particularly in the context of rare diseases, and suggests possible
improvements for their application in healthcare. This research contributes to
narrowing a significant gap in healthcare informatics and offers insights that
could lead to a more refined application of LLMs in the healthcare sector.

摘要：大型語言模型 (LLM) 已徹底改變了各個領域，包括醫療保健，它們在其中被用於各種應用程式。它們的實用性在罕見疾病的背景下尤其重要，因為資料稀少、複雜且具特異性，對此構成相當大的挑戰。在臨床領域中，命名實體識別 (NER) 是一個重要的任務，在從臨床文本中擷取相關資訊方面扮演至關重要的角色。儘管 LLM 前景看好，但目前的研究大多集中在文件層級的 NER，在整個文件中識別更通用的背景中的實體，而不會擷取它們精確的位置。此外，已將精力投入於調整 ChatGPT 以進行代幣層級的 NER。然而，在使用代幣層級的 NER 來處理臨床文本時，特別是在使用本地的開源 LLM 時，存在重大的研究差距。本研究旨在透過探討專有和本地 LLM 在代幣層級臨床 NER 中的有效性來彌補此差距。基本上，我們透過一系列涉及零次提示、少次提示、檢索增強生成 (RAG) 和指令微調的實驗，深入探討這些模型的能力。我們的探索揭示了 LLM 在代幣層級 NER 中面臨的固有挑戰，特別是在罕見疾病的背景下，並建議了它們在醫療保健應用中可能的改進。本研究有助於縮小醫療保健資訊學中的一個重大差距，並提供可望導致在醫療保健領域更精緻地應用 LLM 的見解。

##### **SCMIL: Sparse Context-aware Multiple Instance Learning for Predicting Cancer Survival Probability Distribution in Whole Slide Images**
2407.00664v1 by Zekang Yang, Hong Liu, Xiangdong Wang

Cancer survival prediction is a challenging task that involves analyzing of
the tumor microenvironment within Whole Slide Image (WSI). Previous methods
cannot effectively capture the intricate interaction features among instances
within the local area of WSI. Moreover, existing methods for cancer survival
prediction based on WSI often fail to provide better clinically meaningful
predictions. To overcome these challenges, we propose a Sparse Context-aware
Multiple Instance Learning (SCMIL) framework for predicting cancer survival
probability distributions. SCMIL innovatively segments patches into various
clusters based on their morphological features and spatial location
information, subsequently leveraging sparse self-attention to discern the
relationships between these patches with a context-aware perspective.
Considering many patches are irrelevant to the task, we introduce a learnable
patch filtering module called SoftFilter, which ensures that only interactions
between task-relevant patches are considered. To enhance the clinical relevance
of our prediction, we propose a register-based mixture density network to
forecast the survival probability distribution for individual patients. We
evaluate SCMIL on two public WSI datasets from the The Cancer Genome Atlas
(TCGA) specifically focusing on lung adenocarcinom (LUAD) and kidney renal
clear cell carcinoma (KIRC). Our experimental results indicate that SCMIL
outperforms current state-of-the-art methods for survival prediction, offering
more clinically meaningful and interpretable outcomes. Our code is accessible
at https://github.com/yang-ze-kang/SCMIL.

摘要：癌症存活預測是一項艱鉅的任務，涉及分析全幻燈片影像 (WSI) 中的腫瘤微環境。先前的研究方法無法有效擷取 WSI 局部區域內實例之間的複雜互動特徵。此外，現有的基於 WSI 的癌症存活預測方法通常無法提供更有意義的臨床預測。為了克服這些挑戰，我們提出了一個稀疏上下文感知多實例學習 (SCMIL) 框架，用於預測癌症存活機率分佈。SCMIL 創新地根據形態特徵和空間位置資訊將區塊分割成各種叢集，隨後利用稀疏自注意力來辨別這些區塊之間的關係，並具備上下文感知觀點。考量到許多區塊與任務無關，我們引入了一個可學習的區塊過濾模組 SoftFilter，以確保僅考慮與任務相關區塊之間的互動。為了增強我們預測的臨床相關性，我們提出了一個基於註冊的混合密度網路，以預測個別患者的存活機率分佈。我們在兩個來自癌症基因圖譜 (TCGA) 的公共 WSI 資料集上評估 SCMIL，特別關注肺腺癌 (LUAD) 和腎透明細胞癌 (KIRC)。我們的實驗結果表明，SCMIL 在存活預測方面優於當前最先進的方法，提供了更有意義且可解釋的臨床結果。我們的程式碼可在 https://github.com/yang-ze-kang/SCMIL 取得。

##### **TrialBench: Multi-Modal Artificial Intelligence-Ready Clinical Trial Datasets**
2407.00631v1 by Jintai Chen, Yaojun Hu, Yue Wang, Yingzhou Lu, Xu Cao, Miao Lin, Hongxia Xu, Jian Wu, Cao Xiao, Jimeng Sun, Lucas Glass, Kexin Huang, Marinka Zitnik, Tianfan Fu

Clinical trials are pivotal for developing new medical treatments, yet they
typically pose some risks such as patient mortality, adverse events, and
enrollment failure that waste immense efforts spanning over a decade. Applying
artificial intelligence (AI) to forecast or simulate key events in clinical
trials holds great potential for providing insights to guide trial designs.
However, complex data collection and question definition requiring medical
expertise and a deep understanding of trial designs have hindered the
involvement of AI thus far. This paper tackles these challenges by presenting a
comprehensive suite of meticulously curated AIready datasets covering
multi-modal data (e.g., drug molecule, disease code, text,
categorical/numerical features) and 8 crucial prediction challenges in clinical
trial design, encompassing prediction of trial duration, patient dropout rate,
serious adverse event, mortality rate, trial approval outcome, trial failure
reason, drug dose finding, design of eligibility criteria. Furthermore, we
provide basic validation methods for each task to ensure the datasets'
usability and reliability. We anticipate that the availability of such
open-access datasets will catalyze the development of advanced AI approaches
for clinical trial design, ultimately advancing clinical trial research and
accelerating medical solution development. The curated dataset, metrics, and
basic models are publicly available at
https://github.com/ML2Health/ML2ClinicalTrials/tree/main/AI4Trial.

摘要：臨床試驗對於開發新的醫療療法至關重要，但它們通常會帶來一些風險，例如患者死亡率、不良事件和註冊失敗，這些風險會浪費長達十年的巨大努力。將人工智慧 (AI) 應用於預測或模擬臨床試驗中的關鍵事件，對於提供見解以指導試驗設計具有巨大的潛力。然而，需要醫學專業知識和對試驗設計的深入了解的複雜數據收集和問題定義，迄今為止阻礙了 AI 的參與。本文通過提供一套全面的精心策劃的 AIready 數據集來應對這些挑戰，涵蓋多模式數據（例如，藥物分子、疾病代碼、文本、分類/數值特徵）和臨床試驗設計中的 8 項關鍵預測挑戰，包括預測試驗持續時間、患者輟學率、嚴重不良事件、死亡率、試驗批准結果、試驗失敗原因、藥物劑量發現、資格標準的設計。此外，我們為每個任務提供基本的驗證方法，以確保數據集的可用性和可靠性。我們預計這些開放訪問數據集的可用性將催化先進 AI 方法在臨床試驗設計中的開發，最終推進臨床試驗研究並加速醫療解決方案的開發。策展的數據集、指標和基本模型在 https://github.com/ML2Health/ML2ClinicalTrials/tree/main/AI4Trial 上公開提供。

##### **Answering real-world clinical questions using large language model based systems**
2407.00541v1 by Yen Sia Low, Michael L. Jackson, Rebecca J. Hyde, Robert E. Brown, Neil M. Sanghavi, Julian D. Baldwin, C. William Pike, Jananee Muralidharan, Gavin Hui, Natasha Alexander, Hadeel Hassan, Rahul V. Nene, Morgan Pike, Courtney J. Pokrzywa, Shivam Vedak, Adam Paul Yan, Dong-han Yao, Amy R. Zipursky, Christina Dinh, Philip Ballentine, Dan C. Derieg, Vladimir Polony, Rehan N. Chawdry, Jordan Davies, Brigham B. Hyde, Nigam H. Shah, Saurabh Gombar

Evidence to guide healthcare decisions is often limited by a lack of relevant
and trustworthy literature as well as difficulty in contextualizing existing
research for a specific patient. Large language models (LLMs) could potentially
address both challenges by either summarizing published literature or
generating new studies based on real-world data (RWD). We evaluated the ability
of five LLM-based systems in answering 50 clinical questions and had nine
independent physicians review the responses for relevance, reliability, and
actionability. As it stands, general-purpose LLMs (ChatGPT-4, Claude 3 Opus,
Gemini Pro 1.5) rarely produced answers that were deemed relevant and
evidence-based (2% - 10%). In contrast, retrieval augmented generation
(RAG)-based and agentic LLM systems produced relevant and evidence-based
answers for 24% (OpenEvidence) to 58% (ChatRWD) of questions. Only the agentic
ChatRWD was able to answer novel questions compared to other LLMs (65% vs.
0-9%). These results suggest that while general-purpose LLMs should not be used
as-is, a purpose-built system for evidence summarization based on RAG and one
for generating novel evidence working synergistically would improve
availability of pertinent evidence for patient care.

摘要：醫療保健決策的指導證據通常受到缺乏相關且可信賴文獻的限制，以及難以將現有研究背景化以適用於特定患者。大型語言模型 (LLM) 潛在可透過摘要已發表的文獻或根據真實世界資料 (RWD) 產生新的研究來解決這兩個挑戰。我們評估了五個基於 LLM 的系統回答 50 個臨床問題的能力，並讓九位獨立的醫師檢視回應的相關性、可靠性，以及可行性。目前，通用 LLM（ChatGPT-4、Claude 3 Opus、Gemini Pro 1.5）很少產生被認為相關且基於證據的答案（2% - 10%）。相反地，基於檢索增強生成（RAG）和代理 LLM 系統產生的答案，有 24%（OpenEvidence）至 58%（ChatRWD）的問題是相關且基於證據的。與其他 LLM 相比，只有代理 ChatRWD 能夠回答新問題（65% 對 0-9%）。這些結果表明，雖然不應按原樣使用通用 LLM，但一個基於 RAG 的專門建置系統，用於證據摘要，以及一個用於產生新證據的系統，協同運作，將可改善與患者照護相關證據的可用性。

##### **Privacy-Preserving and Trustworthy Deep Learning for Medical Imaging**
2407.00538v1 by Kiarash Sedghighadikolaei, Attila A Yavuz

The shift towards efficient and automated data analysis through Machine
Learning (ML) has notably impacted healthcare systems, particularly Radiomics.
Radiomics leverages ML to analyze medical images accurately and efficiently for
precision medicine. Current methods rely on Deep Learning (DL) to improve
performance and accuracy (Deep Radiomics). Given the sensitivity of medical
images, ensuring privacy throughout the Deep Radiomics pipeline-from data
generation and collection to model training and inference-is essential,
especially when outsourced. Thus, Privacy-Enhancing Technologies (PETs) are
crucial tools for Deep Radiomics. Previous studies and systematization efforts
have either broadly overviewed PETs and their applications or mainly focused on
subsets of PETs for ML algorithms. In Deep Radiomics, where efficiency,
accuracy, and privacy are crucial, many PETs, while theoretically applicable,
may not be practical without specialized optimizations or hybrid designs.
Additionally, not all DL models are suitable for Radiomics. Consequently, there
is a need for specialized studies that investigate and systematize the
effective and practical integration of PETs into the Deep Radiomics pipeline.
This work addresses this research gap by (1) classifying existing PETs,
presenting practical hybrid PETS constructions, and a taxonomy illustrating
their potential integration with the Deep Radiomics pipeline, with comparative
analyses detailing assumptions, architectural suitability, and security, (2)
Offering technical insights, describing potential challenges and means of
combining PETs into the Deep Radiomics pipeline, including integration
strategies, subtilities, and potential challenges, (3) Proposing potential
research directions, identifying challenges, and suggesting solutions to
enhance the PETs in Deep Radiomics.

摘要：機器學習（ML）朝向高效且自動化的資料分析轉變，顯著影響了醫療保健系統，尤其是放射組學。放射組學利用機器學習精準且有效地分析醫學影像，以進行精準醫療。目前的技術仰賴深度學習（DL）來提升效能和準確度（深度放射組學）。考量到醫學影像的敏感性，確保在深度放射組學流程中（從資料產生和收集到模型訓練和推論）的隱私至關重要，特別是在外包時。因此，隱私強化技術（PET）是深度放射組學的關鍵工具。先前的研究和系統化工作，不是廣泛概述 PET 和其應用，就是主要關注 PET 在機器學習演算法中的子集。在深度放射組學中，效率、準確度和隱私至關重要，許多 PET 雖然理論上適用，但若沒有專門的最佳化或混合設計，可能不切實際。此外，並非所有深度學習模型都適合放射組學。因此，需要專門的研究，調查和系統化 PET 在深度放射組學流程中的有效且實際整合。這項工作透過（1）分類現有的 PET，提出實際的混合 PET 建構，以及一個說明其與深度放射組學流程潛在整合的分類法，並提供詳細說明假設、架構適用性和安全性，（2）提供技術見解，說明將 PET 整合到深度放射組學流程中的潛在挑戰和方法，包括整合策略、細微差別和潛在挑戰，（3）提出潛在的研究方向，找出挑戰，並建議解決方案，以強化深度放射組學中的 PET。

##### **Interpreting Pretrained Speech Models for Automatic Speech Assessment of Voice Disorders**
2407.00531v1 by Hok-Shing Lau, Mark Huntly, Nathon Morgan, Adesua Iyenoma, Biao Zeng, Tim Bashford

Speech contains information that is clinically relevant to some diseases,
which has the potential to be used for health assessment. Recent work shows an
interest in applying deep learning algorithms, especially pretrained large
speech models to the applications of Automatic Speech Assessment. One question
that has not been explored is how these models output the results based on
their inputs. In this work, we train and compare two configurations of Audio
Spectrogram Transformer in the context of Voice Disorder Detection and apply
the attention rollout method to produce model relevance maps, the computed
relevance of the spectrogram regions when the model makes predictions. We use
these maps to analyse how models make predictions in different conditions and
to show that the spread of attention is reduced as a model is finetuned, and
the model attention is concentrated on specific phoneme regions.

摘要：语音包含一些疾病的临床相关信息，
这有潜力用于健康评估。最近的研究表明有兴趣应用深度学习算法，尤其是预训练的大型
语音模型用于自动语音评估的应用。一个尚未探索的问题是这些模型如何根据
其输入输出结果。在这项工作中，我们在语音障碍检测的背景下训练和比较了两个音频
频谱图转换器的配置，并应用注意力展开方法来生成模型相关性图，即模型做出预测时频谱图区域的计算相关性。我们使用
这些图来分析模型如何在不同条件下做出预测，并表明随着模型的微调，注意力的分布会减少，并且
模型注意力集中在特定的音素区域。

##### **ConU: Conformal Uncertainty in Large Language Models with Correctness Coverage Guarantees**
2407.00499v1 by Zhiyuan Wang, Jinhao Duan, Lu Cheng, Yue Zhang, Qingni Wang, Hengtao Shen, Xiaofeng Zhu, Xiaoshuang Shi, Kaidi Xu

Uncertainty quantification (UQ) in natural language generation (NLG) tasks
remains an open challenge, exacerbated by the intricate nature of the recent
large language models (LLMs). This study investigates adapting conformal
prediction (CP), which can convert any heuristic measure of uncertainty into
rigorous theoretical guarantees by constructing prediction sets, for black-box
LLMs in open-ended NLG tasks. We propose a sampling-based uncertainty measure
leveraging self-consistency and develop a conformal uncertainty criterion by
integrating the uncertainty condition aligned with correctness into the design
of the CP algorithm. Experimental results indicate that our uncertainty measure
generally surpasses prior state-of-the-art methods. Furthermore, we calibrate
the prediction sets within the model's unfixed answer distribution and achieve
strict control over the correctness coverage rate across 6 LLMs on 4 free-form
NLG datasets, spanning general-purpose and medical domains, while the small
average set size further highlights the efficiency of our method in providing
trustworthy guarantees for practical open-ended NLG applications.

摘要：自然語言生成 (NLG) 任務中的不確定性量化 (UQ) 仍然是一個開放性的挑戰，最近大型語言模型 (LLM) 的複雜性質加劇了這一挑戰。本研究探討了適應共形預測 (CP)，它可以通過構造預測集將任何不確定性的啟發式測量轉換為嚴格的理論保證，用於開放式 NLG 任務中的黑盒 LLM。我們提出了一種基於抽樣的測量不確定性的方法，利用了自洽性，並通過將與正確性一致的不確定性條件整合到 CP 演算法的設計中，開發了一個共形不確定性準則。實驗結果表明，我們的測量不確定性的方法通常優於先前的最先進方法。此外，我們在模型的未固定答案分佈內校正了預測集，並在 4 個自由形式 NLG 資料集上對 6 個 LLM 的正確性覆蓋率進行了嚴格控制，涵蓋了通用和醫療領域，而較小的平均集合大小進一步突出了我們的方法在為實用的開放式 NLG 應用提供可信保證方面的效率。

##### **MH-pFLGB: Model Heterogeneous personalized Federated Learning via Global Bypass for Medical Image Analysis**
2407.00474v1 by Luyuan Xie, Manqing Lin, ChenMing Xu, Tianyu Luan, Zhipeng Zeng, Wenjun Qian, Cong Li, Yuejian Fang, Qingni Shen, Zhonghai Wu

In the evolving application of medical artificial intelligence, federated
learning is notable for its ability to protect training data privacy. Federated
learning facilitates collaborative model development without the need to share
local data from healthcare institutions. Yet, the statistical and system
heterogeneity among these institutions poses substantial challenges, which
affects the effectiveness of federated learning and hampers the exchange of
information between clients. To address these issues, we introduce a novel
approach, MH-pFLGB, which employs a global bypass strategy to mitigate the
reliance on public datasets and navigate the complexities of non-IID data
distributions. Our method enhances traditional federated learning by
integrating a global bypass model, which would share the information among the
clients, but also serves as part of the network to enhance the performance on
each client. Additionally, MH-pFLGB provides a feature fusion module to better
combine the local and global features. We validate \model{}'s effectiveness and
adaptability through extensive testing on different medical tasks,
demonstrating superior performance compared to existing state-of-the-art
methods.

摘要：在醫療人工智慧的應用演進中，聯邦學習因其保護訓練資料隱私的能力而備受矚目。聯邦學習促進協作模型開發，無需分享醫療保健機構的本地資料。然而，這些機構之間的統計和系統異質性帶來了重大的挑戰，影響了聯邦學習的有效性，並阻礙了客戶端之間的資訊交換。為了解決這些問題，我們提出了一種新的方法 MH-pFLGB，它採用全球旁路策略來減輕對公共資料集的依賴，並應對非 IID 資料分佈的複雜性。我們的模型透過整合一個全球旁路模型來增強傳統的聯邦學習，該模型將在客戶端之間共享資訊，但也作為網路的一部分來增強每個客戶端的效能。此外，MH-pFLGB 提供了一個特徵融合模組，以更好地結合本地和全球特徵。我們透過在不同的醫療任務上進行廣泛的測試來驗證模型的有效性和適應性，證明其效能優於現有的最先進方法。

##### **pFLFE: Cross-silo Personalized Federated Learning via Feature Enhancement on Medical Image Segmentation**
2407.00462v1 by Luyuan Xie, Manqing Lin, Siyuan Liu, ChenMing Xu, Tianyu Luan, Cong Li, Yuejian Fang, Qingni Shen, Zhonghai Wu

In medical image segmentation, personalized cross-silo federated learning
(FL) is becoming popular for utilizing varied data across healthcare settings
to overcome data scarcity and privacy concerns. However, existing methods often
suffer from client drift, leading to inconsistent performance and delayed
training. We propose a new framework, Personalized Federated Learning via
Feature Enhancement (pFLFE), designed to mitigate these challenges. pFLFE
consists of two main stages: feature enhancement and supervised learning. The
first stage improves differentiation between foreground and background
features, and the second uses these enhanced features for learning from
segmentation masks. We also design an alternative training approach that
requires fewer communication rounds without compromising segmentation quality,
even with limited communication resources. Through experiments on three medical
segmentation tasks, we demonstrate that pFLFE outperforms the state-of-the-art
methods.

摘要：在醫學影像分割中，個人化跨資料孤島的聯邦學習 (FL) 逐漸盛行，用於利用醫療保健環境中的各種資料來克服資料稀少和隱私問題。然而，現有方法經常會出現客戶端偏移，導致效能不一致且訓練延遲。我們提出一個新的架構，透過功能增強 (pFLFE) 進行個人化聯邦學習，旨在減輕這些挑戰。pFLFE 包含兩個主要階段：功能增強和監督式學習。第一個階段改善前景和背景功能之間的差異，而第二個階段使用這些增強的功能從分割遮罩中學習。我們還設計了一個備用訓練方法，即使在通訊資源有限的情況下，也不影響分割品質，只需要較少的通訊回合。透過在三個醫學分割任務中進行實驗，我們證明 pFLFE 優於最先進的方法。

##### **Is It Really Long Context if All You Need Is Retrieval? Towards Genuinely Difficult Long Context NLP**
2407.00402v1 by Omer Goldman, Alon Jacovi, Aviv Slobodkin, Aviya Maimon, Ido Dagan, Reut Tsarfaty

Improvements in language models' capabilities have pushed their applications
towards longer contexts, making long-context evaluation and development an
active research area. However, many disparate use-cases are grouped together
under the umbrella term of "long-context", defined simply by the total length
of the model's input, including - for example - Needle-in-a-Haystack tasks,
book summarization, and information aggregation. Given their varied difficulty,
in this position paper we argue that conflating different tasks by their
context length is unproductive. As a community, we require a more precise
vocabulary to understand what makes long-context tasks similar or different. We
propose to unpack the taxonomy of long-context based on the properties that
make them more difficult with longer contexts. We propose two orthogonal axes
of difficulty: (I) Diffusion: How hard is it to find the necessary information
in the context? (II) Scope: How much necessary information is there to find? We
survey the literature on long-context, provide justification for this taxonomy
as an informative descriptor, and situate the literature with respect to it. We
conclude that the most difficult and interesting settings, whose necessary
information is very long and highly diffused within the input, is severely
under-explored. By using a descriptive vocabulary and discussing the relevant
properties of difficulty in long-context, we can implement more informed
research in this area. We call for a careful design of tasks and benchmarks
with distinctly long context, taking into account the characteristics that make
it qualitatively different from shorter context.

摘要：語言模型能力的提升已將其應用推向更長的脈絡，使得長脈絡評估和開發成為一個活躍的研究領域。然而，許多不同的用例被歸類在「長脈絡」這個總稱之下，僅由模型輸入的總長度定義，包括例如大海撈針任務、書籍摘要和資訊彙整。鑑於其難易度不同，我們在這篇立場文件中主張，將不同的任務混為一談是不具生產力的。作為一個社群，我們需要更精確的詞彙來理解是什麼讓長脈絡任務類似或不同。我們提議根據使它們在較長脈絡中更困難的屬性來解構長脈絡的分類。我們提出兩個正交的難度軸：(I) 擴散：在脈絡中找到必要資訊有多困難？(II) 範圍：有多少必要的資訊需要找到？我們調查了關於長脈絡的文獻，為此分類提供作為有意義描述符的依據，並根據它來定位文獻。我們得出結論，最困難且最有趣的設定，其必要資訊非常長且高度分散在輸入中，嚴重地未被探索。透過使用描述性詞彙和討論長脈絡中困難的相關屬性，我們可以在這個領域實施更明智的研究。我們呼籲仔細設計具有明顯長脈絡的任務和基準，考量使其在質上不同於較短脈絡的特性。

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

摘要：近年來，美國見證了電子煙或電子香菸使用率大幅激增，導致電子煙和電子煙使用相關肺損傷 (EVALI) 病例顯著增加，在 2019 年 EVALI 爆發期間造成住院和死亡，凸顯了理解電子煙行為和制定有效戒菸策略的迫切性。由於社群媒體平台的普及，全球超過 47 億使用者使用它們進行連結、溝通、新聞和娛樂，其中很大一部分與健康相關，因此將社群媒體資料建立為公共衛生研究中無價的有機資料資源。在本研究中，我們從 Reddit 上一個電子煙子社群中提取一個範例資料集，以分析使用者的戒電子煙意圖。利用 OpenAI 最新的大型語言模型 GPT-4 進行句子層級的戒電子煙意圖偵測，本研究比較了此模型的結果與外行人和臨床專家註解。使用不同的提示策略，例如零次學習、一次學習、少次學習和思考鏈提示，我們開發了 8 個提示，詳細程度不同，向 GPT-4 解釋任務，並評估這些策略彼此之間的效能。這些初步發現強調了 GPT-4 在社群媒體資料分析中的潛力，特別是在識別人類偵測可能無法察覺的使用者微妙意圖方面。

##### **Predicting Elevated Risk of Hospitalization Following Emergency Department Discharges**
2407.00147v1 by Dat Hong, Philip M. Polgreen, Alberto Maria Segre

Hospitalizations that follow closely on the heels of one or more emergency
department visits are often symptoms of missed opportunities to form a proper
diagnosis. These diagnostic errors imply a failure to recognize the need for
hospitalization and deliver appropriate care, and thus also bear important
connotations for patient safety. In this paper, we show how data mining
techniques can be applied to a large existing hospitalization data set to learn
useful models that predict these upcoming hospitalizations with high accuracy.
Specifically, we use an ensemble of logistics regression, na\"ive Bayes and
association rule classifiers to successfully predict hospitalization within 3,
7 and 14 days of an emergency department discharge. Aside from high accuracy,
one of the advantages of the techniques proposed here is that the resulting
classifier is easily inspected and interpreted by humans so that the learned
rules can be readily operationalized. These rules can then be easily
distributed and applied directly by physicians in emergency department settings
to predict the risk of early admission prior to discharging their emergency
department patients.

摘要：緊接在一次或多次急診科就診後住院，通常是錯失適當診斷機會的徵兆。這些診斷錯誤意味著未能察覺住院需求並提供適當照護，因此也對病患安全造成重大影響。在本文中，我們將展示資料探勘技術如何應用於現有的大型住院資料集，以學習預測這些即將到來的住院事件且準確度極高的有用模型。具體來說，我們使用邏輯迴歸、樸素貝氏和關聯規則分類器的組合，成功預測急診科出院後 3、7 和 14 天內的住院。除了高準確度之外，本文提出的技術優勢之一是，產生的分類器容易被人類檢查和解讀，因此可以輕鬆地將學習到的規則付諸實行。然後，這些規則可以輕易地被分發，並由急診科的醫師直接應用，以在出院前預測急診科病患早期入院的風險。

##### **BMW Agents -- A Framework For Task Automation Through Multi-Agent Collaboration**
2406.20041v3 by Noel Crawford, Edward B. Duffy, Iman Evazzade, Torsten Foehr, Gregory Robbins, Debbrata Kumar Saha, Jiya Varma, Marcin Ziolkowski

Autonomous agents driven by Large Language Models (LLMs) offer enormous
potential for automation. Early proof of this technology can be found in
various demonstrations of agents solving complex tasks, interacting with
external systems to augment their knowledge, and triggering actions. In
particular, workflows involving multiple agents solving complex tasks in a
collaborative fashion exemplify their capacity to operate in less strict and
less well-defined environments. Thus, a multi-agent approach has great
potential for serving as a backbone in many industrial applications, ranging
from complex knowledge retrieval systems to next generation robotic process
automation. Given the reasoning abilities within the current generation of
LLMs, complex processes require a multi-step approach that includes a plan of
well-defined and modular tasks. Depending on the level of complexity, these
tasks can be executed either by a single agent or a group of agents. In this
work, we focus on designing a flexible agent engineering framework with careful
attention to planning and execution, capable of handling complex use case
applications across various domains. The proposed framework provides
reliability in industrial applications and presents techniques to ensure a
scalable, flexible, and collaborative workflow for multiple autonomous agents
working together towards solving tasks.

摘要：由大型語言模型 (LLM) 驅動的自主代理人提供了巨大的自動化潛力。此技術的早期證明可以在代理人解決複雜任務、與外部系統互動以擴充其知識，以及觸發動作的各種演示中找到。特別是，涉及多個代理人以協作方式解決複雜任務的工作流程，說明了它們在較不嚴格和定義較不完善的環境中運作的能力。因此，多代理人方法極有可能成為許多產業應用中的骨幹，範圍從複雜的知識檢索系統到下一代機器人流程自動化。鑑於當前一代 LLM 中的推理能力，複雜的流程需要多步驟的方法，其中包括明確且模組化的任務計畫。根據複雜程度，這些任務可以由單一代理人或一群代理人執行。在這項工作中，我們專注於設計一個靈活的代理人工程架構，仔細注意計畫和執行，能夠處理跨越各種領域的複雜用例應用。所提出的架構在產業應用中提供了可靠性，並提出了技術，以確保多個自主代理人共同努力解決任務的可擴充性、靈活性，以及協作工作流程。

##### **Graph Neural Networks for Gut Microbiome Metaomic data: A preliminary work**
2407.00142v1 by Christopher Irwin, Flavio Mignone, Stefania Montani, Luigi Portinale

The gut microbiome, crucial for human health, presents challenges in
analyzing its complex metaomic data due to high dimensionality and sparsity.
Traditional methods struggle to capture its intricate relationships. We
investigate graph neural networks (GNNs) for this task, aiming to derive
meaningful representations of individual gut microbiomes. Unlike methods
relying solely on taxa abundance, we directly leverage phylogenetic
relationships, in order to obtain a generalized encoder for taxa networks. The
representation learnt from the encoder are then used to train a model for
phenotype prediction such as Inflammatory Bowel Disease (IBD).

摘要：腸道微生物組對於人類健康至關重要，由於其複雜的宏組數據具有高維度和稀疏性的特點，因此在分析時會面臨挑戰。傳統的方法難以捕捉其複雜的關係。我們研究了圖神經網路 (GNN)，旨在推導出個別腸道微生物組的意義表示。與僅依賴分類群豐度的其他方法不同，我們直接利用系統發生關係，以獲得分類群網路的廣義編碼器。然後，從編碼器學習到的表示用於訓練表型預測模型，例如炎症性腸病 (IBD)。

##### **Structure-aware World Model for Probe Guidance via Large-scale Self-supervised Pre-train**
2406.19756v1 by Haojun Jiang, Meng Li, Zhenguo Sun, Ning Jia, Yu Sun, Shaqi Luo, Shiji Song, Gao Huang

The complex structure of the heart leads to significant challenges in
echocardiography, especially in acquisition cardiac ultrasound images.
Successful echocardiography requires a thorough understanding of the structures
on the two-dimensional plane and the spatial relationships between planes in
three-dimensional space. In this paper, we innovatively propose a large-scale
self-supervised pre-training method to acquire a cardiac structure-aware world
model. The core innovation lies in constructing a self-supervised task that
requires structural inference by predicting masked structures on a 2D plane and
imagining another plane based on pose transformation in 3D space. To support
large-scale pre-training, we collected over 1.36 million echocardiograms from
ten standard views, along with their 3D spatial poses. In the downstream probe
guidance task, we demonstrate that our pre-trained model consistently reduces
guidance errors across the ten most common standard views on the test set with
0.29 million samples from 74 routine clinical scans, indicating that
structure-aware pre-training benefits the scanning.

摘要：心脏复杂的结构导致超音波心动图检查面临重大挑战，特别是在获取心脏超音波影像时。成功的超音波心动图检查需要透彻了解二维平面上的结构以及三维空间中各平面之间的空间关系。在本文中，我们创新性地提出了一种大规模自我监督预训练方法，以获取心脏结构感知的世界模型。核心创新在于构建一项自我监督任务，该任务需要通过预测 2D 平面上的遮罩结构并在 3D 空间中基于姿态转换想象另一个平面来进行结构推理。为了支持大规模预训练，我们从十个标准视图中收集了超过 136 万个超音波心动图，以及它们的 3D 空间姿态。在下游探头引导任务中，我们证明了我们的预训练模型在测试集上持续减少了十个最常见标准视图的引导误差，其中包含来自 74 个常规临床扫描的 0.29 百万个样本，表明感知结构的预训练有利于扫描。

##### **Multimodal Learning and Cognitive Processes in Radiology: MedGaze for Chest X-ray Scanpath Prediction**
2407.00129v1 by Akash Awasthi, Ngan Le, Zhigang Deng, Rishi Agrawal, Carol C. Wu, Hien Van Nguyen

Predicting human gaze behavior within computer vision is integral for
developing interactive systems that can anticipate user attention, address
fundamental questions in cognitive science, and hold implications for fields
like human-computer interaction (HCI) and augmented/virtual reality (AR/VR)
systems. Despite methodologies introduced for modeling human eye gaze behavior,
applying these models to medical imaging for scanpath prediction remains
unexplored. Our proposed system aims to predict eye gaze sequences from
radiology reports and CXR images, potentially streamlining data collection and
enhancing AI systems using larger datasets. However, predicting human scanpaths
on medical images presents unique challenges due to the diverse nature of
abnormal regions. Our model predicts fixation coordinates and durations
critical for medical scanpath prediction, outperforming existing models in the
computer vision community. Utilizing a two-stage training process and large
publicly available datasets, our approach generates static heatmaps and eye
gaze videos aligned with radiology reports, facilitating comprehensive
analysis. We validate our approach by comparing its performance with
state-of-the-art methods and assessing its generalizability among different
radiologists, introducing novel strategies to model radiologists' search
patterns during CXR image diagnosis. Based on the radiologist's evaluation,
MedGaze can generate human-like gaze sequences with a high focus on relevant
regions over the CXR images. It sometimes also outperforms humans in terms of
redundancy and randomness in the scanpaths.

摘要：預測電腦視覺中的人類視線行為對於開發互動式系統至關重要，這些系統可以預測使用者注意力、解決認知科學中的基本問題，並對人機互動 (HCI) 和擴增/虛擬實境 (AR/VR) 系統等領域產生影響。儘管引入了用於建模人類視線行為的方法，但將這些模型應用於醫學影像以進行掃描路徑預測仍未得到探索。我們提出的系統旨在根據放射科報告和 CXR 影像預測視線序列，這有可能簡化資料收集並使用更大的資料集來增強 AI 系統。然而，由於異常區域的多樣性，預測醫學影像上的人類掃描路徑提出了獨特的挑戰。我們的模型預測了對醫學掃描路徑預測至關重要的注視坐標和持續時間，表現優於電腦視覺社群中現有的模型。利用兩階段訓練流程和大量的公開可用資料集，我們的做法產生了與放射科報告相符的靜態熱圖和視線影片，從而促成了全面的分析。我們透過將其效能與最先進的方法進行比較並評估其在不同放射科醫師之間的概括性來驗證我們的做法，引入了新的策略來建模放射科醫師在 CXR 影像診斷期間的搜尋模式。根據放射科醫師的評估，MedGaze 可以產生類似人類的視線序列，高度關注 CXR 影像上的相關區域。在掃描路徑的冗餘性和隨機性方面，它有時也優於人類。

##### **ACES: Automatic Cohort Extraction System for Event-Stream Datasets**
2406.19653v1 by Justin Xu, Jack Gallifant, Alistair E. W. Johnson, Matthew B. A. McDermott

Reproducibility remains a significant challenge in machine learning (ML) for
healthcare. In this field, datasets, model pipelines, and even task/cohort
definitions are often private, leading to a significant barrier in sharing,
iterating, and understanding ML results on electronic health record (EHR)
datasets. In this paper, we address a significant part of this problem by
introducing the Automatic Cohort Extraction System for Event-Stream Datasets
(ACES). This tool is designed to simultaneously simplify the development of
task/cohorts for ML in healthcare and enable the reproduction of these cohorts,
both at an exact level for single datasets and at a conceptual level across
datasets. To accomplish this, ACES provides (1) a highly intuitive and
expressive configuration language for defining both dataset-specific concepts
and dataset-agnostic inclusion/exclusion criteria, and (2) a pipeline to
automatically extract patient records that meet these defined criteria from
real-world data. ACES can be automatically applied to any dataset in either the
Medical Event Data Standard (MEDS) or EventStreamGPT (ESGPT) formats, or to
*any* dataset for which the necessary task-specific predicates can be extracted
in an event-stream form. ACES has the potential to significantly lower the
barrier to entry for defining ML tasks, redefine the way researchers interact
with EHR datasets, and significantly improve the state of reproducibility for
ML studies in this modality. ACES is available at
https://github.com/justin13601/aces.

摘要：機器學習 (ML) 在醫療保健領域中，可複製性仍然是一項重大挑戰。在這個領域中，資料集、模型管線，甚至任務/群組定義通常都是私有的，這導致在電子健康紀錄 (EHR) 資料集上分享、重複和理解 ML 結果時產生重大的障礙。在本文中，我們透過導入事件串流資料集的自動群組萃取系統 (ACES) 來解決這個問題的其中一個重要部分。此工具旨在同時簡化醫療保健中 ML 的任務/群組開發，並讓這些群組得以複製，無論是在單一資料集的精確層級，還是在跨資料集的概念層級上。為達成此目的，ACES 提供了 (1) 一種高度直覺且具表現力的組態語言，用於定義資料集特定的概念和與資料集無關的包含/排除標準，以及 (2) 一個管線，用於自動從真實世界資料中萃取符合這些定義標準的病患記錄。ACES 可以自動套用至醫療事件資料標準 (MEDS) 或 EventStreamGPT (ESGPT) 格式中的任何資料集，或套用至 *任何* 可以以事件串流形式萃取必要的特定任務謂詞的資料集。ACES 有可能大幅降低定義 ML 任務的進入門檻，重新定義研究人員與 EHR 資料集互動的方式，並顯著改善此方式中 ML 研究的可複製性。ACES 可在 https://github.com/justin13601/aces 取得。

##### **Multimodal Data Integration for Precision Oncology: Challenges and Future Directions**
2406.19611v1 by Huajun Zhou, Fengtao Zhou, Chenyu Zhao, Yingxue Xu, Luyang Luo, Hao Chen

The essence of precision oncology lies in its commitment to tailor targeted
treatments and care measures to each patient based on the individual
characteristics of the tumor. The inherent heterogeneity of tumors necessitates
gathering information from diverse data sources to provide valuable insights
from various perspectives, fostering a holistic comprehension of the tumor.
Over the past decade, multimodal data integration technology for precision
oncology has made significant strides, showcasing remarkable progress in
understanding the intricate details within heterogeneous data modalities. These
strides have exhibited tremendous potential for improving clinical
decision-making and model interpretation, contributing to the advancement of
cancer care and treatment. Given the rapid progress that has been achieved, we
provide a comprehensive overview of about 300 papers detailing cutting-edge
multimodal data integration techniques in precision oncology. In addition, we
conclude the primary clinical applications that have reaped significant
benefits, including early assessment, diagnosis, prognosis, and biomarker
discovery. Finally, derived from the findings of this survey, we present an
in-depth analysis that explores the pivotal challenges and reveals essential
pathways for future research in the field of multimodal data integration for
precision oncology.

摘要：精準腫瘤學的精髓在於針對每位患者量身打造標靶治療和照護措施，而根據腫瘤的個別特徵。腫瘤的內在異質性需要從不同的資料來源蒐集資訊，以提供來自不同觀點的寶貴見解，促進對腫瘤的整體理解。在過去十年中，精準腫瘤學的多模式資料整合技術已取得顯著進展，在了解異質性資料模式中的複雜細節方面展現出顯著的進展。這些進展已展現出極大的潛力，可改善臨床決策制定和模型詮釋，有助於癌症照護和治療的進步。鑑於已取得的快速進展，我們提供了約 300 篇論文的全面概述，詳細說明精準腫瘤學中尖端的模態資料整合技術。此外，我們總結了已獲得顯著好處的主要臨床應用，包括早期評估、診斷、預後和生物標記發現。最後，根據這項調查結果，我們提出了一項深入分析，探討了關鍵挑戰，並揭示了精準腫瘤學中多模式資料整合領域未來研究的重要途徑。

##### **PathAlign: A vision-language model for whole slide images in histopathology**
2406.19578v1 by Faruk Ahmed, Andrew Sellergren, Lin Yang, Shawn Xu, Boris Babenko, Abbi Ward, Niels Olson, Arash Mohtashamian, Yossi Matias, Greg S. Corrado, Quang Duong, Dale R. Webster, Shravya Shetty, Daniel Golden, Yun Liu, David F. Steiner, Ellery Wulczyn

Microscopic interpretation of histopathology images underlies many important
diagnostic and treatment decisions. While advances in vision-language modeling
raise new opportunities for analysis of such images, the gigapixel-scale size
of whole slide images (WSIs) introduces unique challenges. Additionally,
pathology reports simultaneously highlight key findings from small regions
while also aggregating interpretation across multiple slides, often making it
difficult to create robust image-text pairs. As such, pathology reports remain
a largely untapped source of supervision in computational pathology, with most
efforts relying on region-of-interest annotations or self-supervision at the
patch-level. In this work, we develop a vision-language model based on the
BLIP-2 framework using WSIs paired with curated text from pathology reports.
This enables applications utilizing a shared image-text embedding space, such
as text or image retrieval for finding cases of interest, as well as
integration of the WSI encoder with a frozen large language model (LLM) for
WSI-based generative text capabilities such as report generation or
AI-in-the-loop interactions. We utilize a de-identified dataset of over 350,000
WSIs and diagnostic text pairs, spanning a wide range of diagnoses, procedure
types, and tissue types. We present pathologist evaluation of text generation
and text retrieval using WSI embeddings, as well as results for WSI
classification and workflow prioritization (slide-level triaging).
Model-generated text for WSIs was rated by pathologists as accurate, without
clinically significant error or omission, for 78% of WSIs on average. This work
demonstrates exciting potential capabilities for language-aligned WSI
embeddings.

摘要：顯微組織病理學影像的微觀詮釋是許多重要的診斷和治療決策的基礎。雖然視覺語言模型的進展為此類影像的分析帶來了新的契機，但全切片影像 (WSI) 的千兆像素等級大小帶來了獨特的挑戰。此外，病理報告同時強調了小區域的關鍵發現，同時也彙總了多個切片的詮釋，這通常使得建立穩健的影像文字對變得困難。因此，病理報告仍然是計算病理學中一個很大程度上未開發的監督來源，大多數工作依賴於感興趣區域註解或在貼片的層級上進行自我監督。在這項工作中，我們基於 BLIP-2 框架開發了一個視覺語言模型，使用與來自病理報告的策展文字配對的 WSI。這使得應用程式能夠使用共享的影像文字嵌入空間，例如文字或影像檢索來尋找感興趣的案例，以及將 WSI 編碼器與凍結的大語言模型 (LLM) 整合，用於 WSI 基於生成文字的能力，例如報告產生或 AI 循環互動。我們利用了一個包含超過 350,000 個 WSI 和診斷文字對的去識別化資料集，涵蓋了廣泛的診斷、程序類型和組織類型。我們展示了病理學家對使用 WSI 嵌入的文字產生和文字檢索的評估，以及 WSI 分類和工作流程優先順序（切片級別分類）的結果。病理學家評估了 WSI 的模型產生的文字，平均而言，78% 的 WSI 準確無臨床顯著錯誤或遺漏。這項工作展示了語言對齊 WSI 嵌入的令人興奮的潛在能力。

##### **Automated Web-Based Malaria Detection System with Machine Learning and Deep Learning Techniques**
2407.00120v1 by Abraham G Taye, Sador Yemane, Eshetu Negash, Yared Minwuyelet, Moges Abebe, Melkamu Hunegnaw Asmare

Malaria parasites pose a significant global health burden, causing widespread
suffering and mortality. Detecting malaria infection accurately is crucial for
effective treatment and control. However, existing automated detection
techniques have shown limitations in terms of accuracy and generalizability.
Many studies have focused on specific features without exploring more
comprehensive approaches. In our case, we formulate a deep learning technique
for malaria-infected cell classification using traditional CNNs and transfer
learning models notably VGG19, InceptionV3, and Xception. The models were
trained using NIH datasets and tested using different performance metrics such
as accuracy, precision, recall, and F1-score. The test results showed that deep
CNNs achieved the highest accuracy -- 97%, followed by Xception with an
accuracy of 95%. A machine learning model SVM achieved an accuracy of 83%,
while an Inception-V3 achieved an accuracy of 94%. Furthermore, the system can
be accessed through a web interface, where users can upload blood smear images
for malaria detection.

摘要：瘧疾寄生蟲對全球健康造成重大負擔，導致廣泛的痛苦和死亡。準確檢測瘧疾感染對於有效治療和控制至關重要。然而，現有的自動檢測技術在準確性和普遍性方面顯示出局限性。許多研究專注於特定特徵，而沒有探索更全面的方法。在我們的案例中，我們制定了一種深度學習技術，使用傳統的 CNN 和轉移學習模型，特別是 VGG19、InceptionV3 和 Xception，進行瘧疾感染細胞分類。這些模型使用 NIH 資料集進行訓練，並使用不同的效能指標進行測試，例如準確度、精確度、召回率和 F1 分數。測試結果表明，深度 CNN 達到了最高的準確度——97%，其次是 Xception，準確度為 95%。機器學習模型 SVM 達到了 83% 的準確度，而 Inception-V3 達到了 94% 的準確度。此外，該系統可透過網路介面存取，使用者可以在此介面中上傳血塗片影像以進行瘧疾檢測。

##### **HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale**
2406.19280v1 by Junying Chen, Ruyi Ouyang, Anningzhe Gao, Shunian Chen, Guiming Hardy Chen, Xidong Wang, Ruifei Zhang, Zhenyang Cai, Ke Ji, Guangjun Yu, Xiang Wan, Benyou Wang

The rapid development of multimodal large language models (MLLMs), such as
GPT-4V, has led to significant advancements. However, these models still face
challenges in medical multimodal capabilities due to limitations in the
quantity and quality of medical vision-text data, stemming from data privacy
concerns and high annotation costs. While pioneering approaches utilize
PubMed's large-scale, de-identified medical image-text pairs to address these
limitations, they still fall short due to inherent data noise. To tackle this,
we refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in
an 'unblinded' capacity to denoise and reformat the data, resulting in the
creation of the PubMedVision dataset with 1.3 million medical VQA samples. Our
validation demonstrates that: (1) PubMedVision can significantly enhance the
medical multimodal capabilities of current MLLMs, showing significant
improvement in benchmarks including the MMMU Health & Medicine track; (2)
manual checks by medical experts and empirical results validate the superior
data quality of our dataset compared to other data construction methods. Using
PubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows
superior performance in medical multimodal scenarios among open-source MLLMs.

摘要：多模态大语言模型（MLLM）的快速发展，例如 GPT-4V，带来了重大的进步。然而，由于医疗视觉文本数据的数量和质量的限制，这些模型在医疗多模态能力方面仍然面临挑战，这源于数据隐私问题和高昂的标注成本。虽然开创性的方法利用 PubMed 的大规模、去标识化的医学图像文本对来解决这些限制，但由于固有的数据噪声，它们仍然存在不足。为了解决这个问题，我们从 PubMed 中优化了医学图像文本对，并以“非盲”的方式采用了 MLLM（GPT-4V）来对数据进行去噪和重新格式化，从而创建了包含 130 万个医学 VQA 样本的 PubMedVision 数据集。我们的验证表明：(1) PubMedVision 可以显著增强当前 MLLM 的医疗多模态能力，在包括 MMMU 健康与医学轨道在内的基准测试中显示出显著的改进；(2) 医学专家的手动检查和实证结果验证了我们数据集与其他数据构建方法相比的卓越数据质量。使用 PubMedVision，我们训练了一个 34B 医学 MLLM HuatuoGPT-Vision，它在开源 MLLM 中的医学多模态场景中表现出卓越的性能。

##### **Generative AI for Synthetic Data Across Multiple Medical Modalities: A Systematic Review of Recent Developments and Challenges**
2407.00116v2 by Mahmoud Ibrahim, Yasmina Al Khalil, Sina Amirrajab, Chang Sun, Marcel Breeuwer, Josien Pluim, Bart Elen, Gokhan Ertaylan, Michel Dumontier

This paper presents a comprehensive systematic review of generative models
(GANs, VAEs, DMs, and LLMs) used to synthesize various medical data types,
including imaging (dermoscopic, mammographic, ultrasound, CT, MRI, and X-ray),
text, time-series, and tabular data (EHR). Unlike previous narrowly focused
reviews, our study encompasses a broad array of medical data modalities and
explores various generative models. Our search strategy queries databases such
as Scopus, PubMed, and ArXiv, focusing on recent works from January 2021 to
November 2023, excluding reviews and perspectives. This period emphasizes
recent advancements beyond GANs, which have been extensively covered
previously.
  The survey reveals insights from three key aspects: (1) Synthesis
applications and purpose of synthesis, (2) generation techniques, and (3)
evaluation methods. It highlights clinically valid synthesis applications,
demonstrating the potential of synthetic data to tackle diverse clinical
requirements. While conditional models incorporating class labels, segmentation
masks and image translations are prevalent, there is a gap in utilizing prior
clinical knowledge and patient-specific context, suggesting a need for more
personalized synthesis approaches and emphasizing the importance of tailoring
generative approaches to the unique characteristics of medical data.
Additionally, there is a significant gap in using synthetic data beyond
augmentation, such as for validation and evaluation of downstream medical AI
models. The survey uncovers that the lack of standardized evaluation
methodologies tailored to medical images is a barrier to clinical application,
underscoring the need for in-depth evaluation approaches, benchmarking, and
comparative studies to promote openness and collaboration.

摘要：<paragraph>本文提出了生成式模型（GAN、VAE、DM 和 LLM）的全面系统性回顾，这些模型用于合成各种医学数据类型，包括影像（皮肤镜、乳房 X 光检查、超声波、CT、MRI 和 X 射线）、文本、时间序列和表格数据（EHR）。与以往针对特定领域的狭窄综述不同，我们的研究涵盖了广泛的医学数据模式，并探讨了各种生成式模型。我们的搜索策略查询了 Scopus、PubMed 和 ArXiv 等数据库，重点关注 2021 年 1 月至 2023 年 11 月的近期作品，不包括评论和观点。该时段着重强调了 GAN 之外的最新进展，而 GAN 已在之前得到广泛介绍。
调查从三个关键方面揭示了见解：(1) 合成应用和合成的目的，(2) 生成技术，以及 (3) 评估方法。它突出了临床上有效的合成应用，展示了合成数据解决各种临床需求的潜力。虽然包含类别标签、分割掩模和图像转换的条件模型很普遍，但在利用先验临床知识和患者特定背景方面存在差距，这表明需要更多个性化的合成方法，并强调根据医学数据的独特特征定制生成方法的重要性。此外，在合成数据的应用中存在一个明显的差距，超出了增强之外，例如用于验证和评估下游医学 AI 模型。调查发现，缺乏针对医学图像定制的标准化评估方法是临床应用的障碍，这强调了对深入评估方法、基准测试和比较研究的需求，以促进开放性和协作。</paragraph>

##### **Segment Anything Model for automated image data annotation: empirical studies using text prompts from Grounding DINO**
2406.19057v2 by Fuseini Mumuni, Alhassan Mumuni

Grounding DINO and the Segment Anything Model (SAM) have achieved impressive
performance in zero-shot object detection and image segmentation, respectively.
Together, they have a great potential to revolutionize applications in
zero-shot semantic segmentation or data annotation. Yet, in specialized domains
like medical image segmentation, objects of interest (e.g., organs, tissues,
and tumors) may not fall in existing class names. To address this problem, the
referring expression comprehension (REC) ability of Grounding DINO is leveraged
to detect arbitrary targets by their language descriptions. However, recent
studies have highlighted severe limitation of the REC framework in this
application setting owing to its tendency to make false positive predictions
when the target is absent in the given image. And, while this bottleneck is
central to the prospect of open-set semantic segmentation, it is still largely
unknown how much improvement can be achieved by studying the prediction errors.
To this end, we perform empirical studies on six publicly available datasets
across different domains and reveal that these errors consistently follow a
predictable pattern and can, thus, be mitigated by a simple strategy.
Specifically, we show that false positive detections with appreciable
confidence scores generally occupy large image areas and can usually be
filtered by their relative sizes. More importantly, we expect these
observations to inspire future research in improving REC-based detection and
automated segmentation. Meanwhile, we evaluate the performance of SAM on
multiple datasets from various specialized domains and report significant
improvements in segmentation performance and annotation time savings over
manual approaches.

摘要：Grounding DINO 和 Segment Anything Model (SAM) 分別在零次學習目標偵測和影像分割方面取得令人印象深刻的表現。兩者結合起來，極有可能徹底改變零次學習語意分割或資料標註的應用。然而，在醫療影像分割等專業領域中，感興趣的物體（例如器官、組織和腫瘤）可能不在現有的類別名稱中。為了解決這個問題，Grounding DINO 的指稱表達理解 (REC) 能力被用於透過語言描述來偵測任意目標。然而，最近的研究強調了 REC 框架在這種應用設定中的嚴重限制，因為當目標不存在於給定的影像中時，它傾向於做出錯誤的正向預測。而且，儘管這個瓶頸對於開放式語意分割的前景至關重要，但透過研究預測誤差可以獲得多少改進仍然 weitgehend未知。為此，我們對六個不同領域的公開可用資料集進行實證研究，並揭示這些誤差始終遵循可預測的模式，因此可以透過一個簡單的策略來減輕。具體來說，我們表明具有可觀置信度分數的錯誤正向偵測通常佔據較大的影像區域，通常可以透過它們的相對大小來過濾。更重要的是，我們預期這些觀察結果將激勵未來在改進基於 REC 的偵測和自動分割方面的研究。同時，我們評估了 SAM 在來自各種專業領域的多個資料集上的效能，並報告了分割效能和標註時間相較於手動方法有顯著的改善。

##### **FedMap: Iterative Magnitude-Based Pruning for Communication-Efficient Federated Learning**
2406.19050v1 by Alexander Herzog, Robbie Southam, Ioannis Mavromatis, Aftab Khan

Federated Learning (FL) is a distributed machine learning approach that
enables training on decentralized data while preserving privacy. However, FL
systems often involve resource-constrained client devices with limited
computational power, memory, storage, and bandwidth. This paper introduces
FedMap, a novel method that aims to enhance the communication efficiency of FL
deployments by collaboratively learning an increasingly sparse global model
through iterative, unstructured pruning. Importantly, FedMap trains a global
model from scratch, unlike other methods reported in the literature, making it
ideal for privacy-critical use cases such as in the medical and finance
domains, where suitable pre-training data is often limited. FedMap adapts
iterative magnitude-based pruning to the FL setting, ensuring all clients prune
and refine the same subset of the global model parameters, therefore gradually
reducing the global model size and communication overhead. The iterative nature
of FedMap, forming subsequent models as subsets of predecessors, avoids
parameter reactivation issues seen in prior work, resulting in stable
performance. In this paper we provide an extensive evaluation of FedMap across
diverse settings, datasets, model architectures, and hyperparameters, assessing
performance in both IID and non-IID environments. Comparative analysis against
the baseline approach demonstrates FedMap's ability to achieve more stable
client model performance. For IID scenarios, FedMap achieves over $90$\%
pruning without significant performance degradation. In non-IID settings, it
achieves at least $~80$\% pruning while maintaining accuracy. FedMap offers a
promising solution to alleviate communication bottlenecks in FL systems while
retaining model accuracy.

摘要：联邦学习 (FL) 是一种分布式机器学习方法，可在保护隐私的同时对分散数据进行训练。然而，FL 系统通常涉及资源受限的客户端设备，其计算能力、内存、存储和带宽有限。本文介绍了 FedMap，这是一种新颖的方法，旨在通过协作学习一个不断稀疏的全局模型（通过迭代的非结构化剪枝）来提高 FL 部署的通信效率。重要的是，FedMap 从头开始训练一个全局模型，这与文献中报道的其他方法不同，使其非常适合隐私至关重要的用例，例如医疗和金融领域，其中合适的预训练数据通常有限。FedMap 将基于迭代幅度的剪枝调整到 FL 设置中，确保所有客户端都剪枝并优化全局模型参数的相同子集，从而逐渐减少全局模型大小和通信开销。FedMap 的迭代性质，将后续模型形成为前代模型的子集，避免了先前工作中看到的参数重新激活问题，从而产生了稳定的性能。在本文中，我们对 FedMap 在不同设置、数据集、模型架构和超参数中进行了广泛评估，评估了在 IID 和非 IID 环境中的性能。与基准方法的比较分析证明了 FedMap 能够实现更稳定的客户端模型性能。对于 IID 场景，FedMap 在不显着降低性能的情况下实现了超过 90% 的剪枝。在非 IID 设置中，它在保持准确性的同时实现了至少 80% 的剪枝。FedMap 为缓解 FL 系统中的通信瓶颈同时保持模型准确性提供了一个有希望的解决方案。

