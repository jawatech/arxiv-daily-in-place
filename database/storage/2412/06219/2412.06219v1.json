{"2412.06219": {"publish_time": "2024-12-09", "title": "Data Free Backdoor Attacks", "paper_summary": "Backdoor attacks aim to inject a backdoor into a classifier such that it\npredicts any input with an attacker-chosen backdoor trigger as an\nattacker-chosen target class. Existing backdoor attacks require either\nretraining the classifier with some clean data or modifying the model's\narchitecture. As a result, they are 1) not applicable when clean data is\nunavailable, 2) less efficient when the model is large, and 3) less stealthy\ndue to architecture changes. In this work, we propose DFBA, a novel\nretraining-free and data-free backdoor attack without changing the model\narchitecture. Technically, our proposed method modifies a few parameters of a\nclassifier to inject a backdoor. Through theoretical analysis, we verify that\nour injected backdoor is provably undetectable and unremovable by various\nstate-of-the-art defenses under mild assumptions. Our evaluation on multiple\ndatasets further demonstrates that our injected backdoor: 1) incurs negligible\nclassification loss, 2) achieves 100% attack success rates, and 3) bypasses six\nexisting state-of-the-art defenses. Moreover, our comparison with a\nstate-of-the-art non-data-free backdoor attack shows our attack is more\nstealthy and effective against various defenses while achieving less\nclassification accuracy loss.", "paper_summary_zh": "\u5f8c\u9580\u653b\u64ca\u65e8\u5728\u5c07\u4e00\u500b\u5f8c\u9580\u6ce8\u5165\u5206\u985e\u5668\u4e2d\uff0c\u4f7f\u5176\u5c07\u4efb\u4f55\u8f38\u5165\u8207\u653b\u64ca\u8005\u9078\u64c7\u7684\u5f8c\u9580\u89f8\u767c\u5668\u9810\u6e2c\u70ba\u653b\u64ca\u8005\u9078\u64c7\u7684\u76ee\u6a19\u985e\u5225\u3002\u73fe\u6709\u7684\u5f8c\u9580\u653b\u64ca\u9700\u8981\u91cd\u65b0\u8a13\u7df4\u5206\u985e\u5668\uff0c\u4f7f\u7528\u4e00\u4e9b\u4e7e\u6de8\u7684\u8cc7\u6599\u6216\u4fee\u6539\u6a21\u578b\u67b6\u69cb\u3002\u56e0\u6b64\uff0c\u5b83\u5011 1) \u5728\u6c92\u6709\u4e7e\u6de8\u8cc7\u6599\u6642\u4e0d\u9069\u7528\uff0c2) \u5728\u6a21\u578b\u8f03\u5927\u7684\u6642\u5019\u6548\u7387\u8f03\u4f4e\uff0c3) \u7531\u65bc\u67b6\u69cb\u7684\u8b8a\u66f4\u800c\u8f03\u4e0d\u96b1\u853d\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa DFBA\uff0c\u4e00\u7a2e\u65b0\u7a4e\u7684\u7121\u9700\u91cd\u65b0\u8a13\u7df4\u4e14\u7121\u9700\u8cc7\u6599\u7684\u5f8c\u9580\u653b\u64ca\uff0c\u800c\u4e0d\u6703\u6539\u8b8a\u6a21\u578b\u67b6\u69cb\u3002\u6280\u8853\u4e0a\uff0c\u6211\u5011\u63d0\u51fa\u7684\u65b9\u6cd5\u4fee\u6539\u5206\u985e\u5668\u7684\u5e7e\u500b\u53c3\u6578\uff0c\u4ee5\u6ce8\u5165\u5f8c\u9580\u3002\u900f\u904e\u7406\u8ad6\u5206\u6790\uff0c\u6211\u5011\u9a57\u8b49\u6211\u5011\u6ce8\u5165\u7684\u5f8c\u9580\u5728\u8f15\u5fae\u7684\u5047\u8a2d\u4e0b\uff0c\u88ab\u8b49\u660e\u7121\u6cd5\u88ab\u5404\u7a2e\u6700\u5148\u9032\u7684\u9632\u79a6\u63aa\u65bd\u5075\u6e2c\u548c\u79fb\u9664\u3002\u6211\u5011\u5728\u591a\u500b\u8cc7\u6599\u96c6\u4e0a\u7684\u8a55\u4f30\u9032\u4e00\u6b65\u8b49\u660e\u4e86\u6211\u5011\u6ce8\u5165\u7684\u5f8c\u9580\uff1a1) \u9020\u6210\u5fae\u4e0d\u8db3\u9053\u7684\u5206\u985e\u640d\u5931\uff0c2) \u9054\u5230 100% \u7684\u653b\u64ca\u6210\u529f\u7387\uff0c3) \u7e5e\u904e\u516d\u7a2e\u73fe\u6709\u7684\u6700\u5148\u9032\u9632\u79a6\u63aa\u65bd\u3002\u6b64\u5916\uff0c\u6211\u5011\u8207\u6700\u5148\u9032\u7684\u975e\u7121\u8cc7\u6599\u5f8c\u9580\u653b\u64ca\u7684\u6bd4\u8f03\u986f\u793a\uff0c\u6211\u5011\u7684\u653b\u64ca\u5728\u5c0d\u6297\u5404\u7a2e\u9632\u79a6\u63aa\u65bd\u6642\u66f4\u96b1\u853d\u4e14\u6709\u6548\uff0c\u540c\u6642\u9054\u5230\u8f03\u4f4e\u7684\u5206\u985e\u6e96\u78ba\u5ea6\u640d\u5931\u3002", "author": "Bochuan Cao et.al.", "authors": "Bochuan Cao, Jinyuan Jia, Chuxuan Hu, Wenbo Guo, Zhen Xiang, Jinghui Chen, Bo Li, Dawn Song", "id": "2412.06219v1", "paper_url": "http://arxiv.org/abs/2412.06219v1", "repo": "https://github.com/aaaaaasuka/datafree_backdoor_attacks"}}