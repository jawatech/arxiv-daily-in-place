{"2412.08237": {"publish_time": "2024-12-11", "title": "TouchTTS: An Embarrassingly Simple TTS Framework that Everyone Can Touch", "paper_summary": "It is well known that LLM-based systems are data-hungry. Recent LLM-based TTS\nworks typically employ complex data processing pipelines to obtain high-quality\ntraining data. These sophisticated pipelines require excellent models at each\nstage (e.g., speech denoising, speech enhancement, speaker diarization, and\npunctuation models), which themselves demand high-quality training data and are\nrarely open-sourced. Even with state-of-the-art models, issues persist, such as\nincomplete background noise removal and misalignment between punctuation and\nactual speech pauses. Moreover, the stringent filtering strategies often retain\nonly 10-30\\% of the original data, significantly impeding data scaling efforts.\nIn this work, we leverage a noise-robust audio tokenizer (S3Tokenizer) to\ndesign a simplified yet effective TTS data processing pipeline that maintains\ndata quality while substantially reducing data acquisition costs, achieving a\ndata retention rate of over 50\\%. Beyond data scaling challenges, LLM-based TTS\nsystems also incur higher deployment costs compared to conventional approaches.\nCurrent systems typically use LLMs solely for text-to-token generation, while\nrequiring separate models (e.g., flow matching models) for token-to-waveform\ngeneration, which cannot be directly executed by LLM inference engines, further\ncomplicating deployment. To address these challenges, we eliminate redundant\nmodules in both LLM and flow components, replacing the flow model backbone with\nan LLM architecture. Building upon this simplified flow backbone, we propose a\nunified architecture for both streaming and non-streaming inference,\nsignificantly reducing deployment costs. Finally, we explore the feasibility of\nunifying TTS and ASR tasks using the same data for training, thanks to the\nsimplified pipeline and the S3Tokenizer that reduces the quality requirements\nfor TTS training data.", "paper_summary_zh": "\u773e\u6240\u5468\u77e5\uff0c\u57fa\u65bc LLM \u7684\u7cfb\u7d71\u975e\u5e38\u8017\u8cc7\u6599\u3002\u6700\u8fd1\u57fa\u65bc LLM \u7684 TTS \u4f5c\u54c1\u901a\u5e38\u63a1\u7528\u8907\u96dc\u7684\u8cc7\u6599\u8655\u7406\u7ba1\u7dda\uff0c\u4ee5\u53d6\u5f97\u9ad8\u54c1\u8cea\u7684\u8a13\u7df4\u8cc7\u6599\u3002\u9019\u4e9b\u8907\u96dc\u7684\u7ba1\u7dda\u5728\u6bcf\u500b\u968e\u6bb5\u90fd\u9700\u8981\u512a\u79c0\u7684\u6a21\u578b\uff08\u4f8b\u5982\u8a9e\u97f3\u53bb\u96dc\u8a0a\u3001\u8a9e\u97f3\u589e\u5f37\u3001\u8aaa\u8a71\u8005\u65e5\u8a18\u5316\u548c\u6a19\u9ede\u7b26\u865f\u6a21\u578b\uff09\uff0c\u800c\u9019\u4e9b\u6a21\u578b\u672c\u8eab\u9700\u8981\u9ad8\u54c1\u8cea\u7684\u8a13\u7df4\u8cc7\u6599\uff0c\u800c\u4e14\u5f88\u5c11\u958b\u6e90\u3002\u5373\u4f7f\u4f7f\u7528\u6700\u5148\u9032\u7684\u6a21\u578b\uff0c\u554f\u984c\u4ecd\u7136\u5b58\u5728\uff0c\u4f8b\u5982\u80cc\u666f\u96dc\u8a0a\u79fb\u9664\u4e0d\u5b8c\u5168\uff0c\u4ee5\u53ca\u6a19\u9ede\u7b26\u865f\u548c\u5be6\u969b\u8a9e\u97f3\u505c\u9813\u4e4b\u9593\u7684\u5c0d\u9f4a\u932f\u8aa4\u3002\u6b64\u5916\uff0c\u56b4\u683c\u7684\u904e\u6ffe\u7b56\u7565\u901a\u5e38\u53ea\u4fdd\u7559\u539f\u59cb\u8cc7\u6599\u7684 10-30%\uff0c\u9019\u6703\u986f\u8457\u963b\u7919\u8cc7\u6599\u64f4\u5145\u5de5\u4f5c\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u5229\u7528\u6297\u96dc\u8a0a\u97f3\u8a0a\u5206\u8a5e\u5668 (S3Tokenizer) \u4f86\u8a2d\u8a08\u4e00\u500b\u7c21\u5316\u4f46\u6709\u6548\u7684 TTS \u8cc7\u6599\u8655\u7406\u7ba1\u7dda\uff0c\u5728\u5927\u5e45\u964d\u4f4e\u8cc7\u6599\u53d6\u5f97\u6210\u672c\u7684\u540c\u6642\uff0c\u7dad\u6301\u8cc7\u6599\u54c1\u8cea\uff0c\u9054\u6210\u8d85\u904e 50% \u7684\u8cc7\u6599\u4fdd\u7559\u7387\u3002\u9664\u4e86\u8cc7\u6599\u64f4\u5145\u7684\u6311\u6230\u4e4b\u5916\uff0c\u8207\u50b3\u7d71\u65b9\u6cd5\u76f8\u6bd4\uff0c\u57fa\u65bc LLM \u7684 TTS \u7cfb\u7d71\u4e5f\u7522\u751f\u66f4\u9ad8\u7684\u90e8\u7f72\u6210\u672c\u3002\u76ee\u524d\u7684\u7cfb\u7d71\u901a\u5e38\u53ea\u4f7f\u7528 LLM \u4f86\u9032\u884c\u6587\u5b57\u5230\u4ee3\u78bc\u7684\u7522\u751f\uff0c\u540c\u6642\u9700\u8981\u4e0d\u540c\u7684\u6a21\u578b\uff08\u4f8b\u5982\u6d41\u7a0b\u5339\u914d\u6a21\u578b\uff09\u4f86\u9032\u884c\u4ee3\u78bc\u5230\u6ce2\u5f62\u7684\u7522\u751f\uff0c\u800c LLM \u63a8\u8ad6\u5f15\u64ce\u7121\u6cd5\u76f4\u63a5\u57f7\u884c\u9019\u4e9b\u6a21\u578b\uff0c\u9019\u9032\u4e00\u6b65\u8907\u96dc\u5316\u4e86\u90e8\u7f72\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u6311\u6230\uff0c\u6211\u5011\u6d88\u9664\u4e86 LLM \u548c\u6d41\u7a0b\u5143\u4ef6\u4e2d\u7684\u91cd\u8907\u6a21\u7d44\uff0c\u4e26\u4ee5 LLM \u67b6\u69cb\u53d6\u4ee3\u6d41\u7a0b\u6a21\u578b\u4e3b\u5e79\u3002\u5efa\u69cb\u5728\u9019\u500b\u7c21\u5316\u7684\u6d41\u7a0b\u4e3b\u5e79\u4e4b\u4e0a\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u7d71\u4e00\u7684\u67b6\u69cb\uff0c\u7528\u65bc\u4e32\u6d41\u548c\u975e\u4e32\u6d41\u63a8\u8ad6\uff0c\u5927\u5e45\u964d\u4f4e\u90e8\u7f72\u6210\u672c\u3002\u6700\u5f8c\uff0c\u7531\u65bc\u7c21\u5316\u7684\u7ba1\u7dda\u548c S3Tokenizer \u964d\u4f4e\u4e86 TTS \u8a13\u7df4\u8cc7\u6599\u7684\u54c1\u8cea\u9700\u6c42\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u4f7f\u7528\u76f8\u540c\u7684\u8cc7\u6599\u4f86\u8a13\u7df4 TTS \u548c ASR \u4efb\u52d9\u7684\u53ef\u884c\u6027\u3002", "author": "Xingchen Song et.al.", "authors": "Xingchen Song, Mengtao Xing, Changwei Ma, Shengqiang Li, Di Wu, Binbin Zhang, Fuping Pan, Dinghao Zhou, Yuekai Zhang, Shun Lei, Zhendong Peng, Zhiyong Wu", "id": "2412.08237v1", "paper_url": "http://arxiv.org/abs/2412.08237v1", "repo": "null"}}