{"2407.18219": {"publish_time": "2024-07-25", "title": "Recursive Introspection: Teaching Language Model Agents How to Self-Improve", "paper_summary": "A central piece in enabling intelligent agentic behavior in foundation models\nis to make them capable of introspecting upon their behavior, reasoning, and\ncorrecting their mistakes as more computation or interaction is available. Even\nthe strongest proprietary large language models (LLMs) do not quite exhibit the\nability of continually improving their responses sequentially, even in\nscenarios where they are explicitly told that they are making a mistake. In\nthis paper, we develop RISE: Recursive IntroSpEction, an approach for\nfine-tuning LLMs to introduce this capability, despite prior work hypothesizing\nthat this capability may not be possible to attain. Our approach prescribes an\niterative fine-tuning procedure, which attempts to teach the model how to alter\nits response after having executed previously unsuccessful attempts to solve a\nhard test-time problem, with optionally additional environment feedback. RISE\nposes fine-tuning for a single-turn prompt as solving a multi-turn Markov\ndecision process (MDP), where the initial state is the prompt. Inspired by\nprinciples in online imitation learning and reinforcement learning, we propose\nstrategies for multi-turn data collection and training so as to imbue an LLM\nwith the capability to recursively detect and correct its previous mistakes in\nsubsequent iterations. Our experiments show that RISE enables Llama2, Llama3,\nand Mistral models to improve themselves with more turns on math reasoning\ntasks, outperforming several single-turn strategies given an equal amount of\ninference-time computation. We also find that RISE scales well, often attaining\nlarger benefits with more capable models. Our analysis shows that RISE makes\nmeaningful improvements to responses to arrive at the correct solution for\nchallenging prompts, without disrupting one-turn abilities as a result of\nexpressing more complex distributions.", "paper_summary_zh": "<paragraph>\u5728\u57fa\u790e\u6a21\u578b\u4e2d\u555f\u7528\u667a\u6167\u4ee3\u7406\u884c\u70ba\u7684\u6838\u5fc3\u90e8\u5206\u662f\u8b93\u5b83\u5011\u80fd\u5920\u5167\u7701\u81ea\u5df1\u7684\u884c\u70ba\u3001\u63a8\u7406\uff0c\u4e26\u5728\u6709\u66f4\u591a\u904b\u7b97\u6216\u4e92\u52d5\u6642\u66f4\u6b63\u81ea\u5df1\u7684\u932f\u8aa4\u3002\u5373\u4f7f\u662f\u6700\u5f37\u5927\u7684\u5c08\u6709\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4e5f\u7121\u6cd5\u5b8c\u5168\u5c55\u73fe\u9023\u7e8c\u5faa\u5e8f\u6f38\u9032\u5730\u6539\u5584\u5176\u56de\u61c9\u7684\u80fd\u529b\uff0c\u5373\u4f7f\u5728\u660e\u78ba\u544a\u77e5\u5b83\u5011\u72af\u932f\u7684\u60c5\u6cc1\u4e0b\u4e5f\u662f\u5982\u6b64\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u958b\u767c\u4e86 RISE\uff1a\u905e\u8ff4\u5167\u7701\uff0c\u4e00\u7a2e\u5fae\u8abf LLM \u7684\u65b9\u6cd5\u4f86\u5f15\u5165\u9019\u7a2e\u80fd\u529b\uff0c\u5118\u7ba1\u5148\u524d\u7684\u7814\u7a76\u5047\u8a2d\u7121\u6cd5\u7372\u5f97\u9019\u7a2e\u80fd\u529b\u3002\u6211\u5011\u7684\u505a\u6cd5\u898f\u5b9a\u4e86\u4e00\u7a2e\u53cd\u8986\u5fae\u8abf\u7a0b\u5e8f\uff0c\u8a72\u7a0b\u5e8f\u5617\u8a66\u6559\u5c0e\u6a21\u578b\u5982\u4f55\u5728\u57f7\u884c\u5148\u524d\u4e0d\u6210\u529f\u7684\u5617\u8a66\u4f86\u89e3\u6c7a\u56f0\u96e3\u7684\u6e2c\u8a66\u6642\u9593\u554f\u984c\u5f8c\u6539\u8b8a\u5176\u56de\u61c9\uff0c\u4e26\u53ef\u9078\u64c7\u984d\u5916\u63d0\u4f9b\u74b0\u5883\u56de\u994b\u3002RISE \u5c07\u55ae\u8f2a\u63d0\u793a\u7684\u5fae\u8abf\u8996\u70ba\u89e3\u6c7a\u591a\u8f2a\u99ac\u53ef\u592b\u6c7a\u7b56\u904e\u7a0b (MDP) \u7684\u554f\u984c\uff0c\u5176\u4e2d\u521d\u59cb\u72c0\u614b\u662f\u63d0\u793a\u3002\u53d7\u5230\u5728\u7dda\u6a21\u4eff\u5b78\u7fd2\u548c\u5f37\u5316\u5b78\u7fd2\u539f\u5247\u7684\u555f\u767c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u591a\u8f2a\u6578\u64da\u6536\u96c6\u548c\u8a13\u7df4\u7b56\u7565\uff0c\u4ee5\u8ce6\u4e88 LLM \u5728\u5f8c\u7e8c\u8fed\u4ee3\u4e2d\u905e\u8ff4\u6aa2\u6e2c\u548c\u7cfe\u6b63\u5176\u5148\u524d\u932f\u8aa4\u7684\u80fd\u529b\u3002\u6211\u5011\u7684\u5be6\u9a57\u8868\u660e\uff0cRISE \u80fd\u8b93 Llama2\u3001Llama3 \u548c Mistral \u6a21\u578b\u5728\u6578\u5b78\u63a8\u7406\u4efb\u52d9\u4e2d\u96a8\u8457\u66f4\u591a\u8f2a\u6b21\u800c\u81ea\u6211\u63d0\u5347\uff0c\u5728\u7d66\u5b9a\u76f8\u540c\u63a8\u7406\u6642\u9593\u904b\u7b97\u7684\u60c5\u6cc1\u4e0b\uff0c\u8868\u73fe\u512a\u65bc\u591a\u7a2e\u55ae\u8f2a\u7b56\u7565\u3002\u6211\u5011\u9084\u767c\u73fe RISE \u5177\u6709\u826f\u597d\u7684\u64f4\u5c55\u6027\uff0c\u901a\u5e38\u80fd\u96a8\u8457\u6a21\u578b\u529f\u80fd\u66f4\u5f37\u5927\u800c\u7372\u5f97\u66f4\u5927\u7684\u597d\u8655\u3002\u6211\u5011\u7684\u5206\u6790\u8868\u660e\uff0cRISE \u5c0d\u56de\u61c9\u9032\u884c\u4e86\u6709\u610f\u7fa9\u7684\u6539\u9032\uff0c\u4ee5\u91dd\u5c0d\u5177\u6709\u6311\u6230\u6027\u7684\u63d0\u793a\u5f97\u51fa\u6b63\u78ba\u7684\u89e3\u6c7a\u65b9\u6848\uff0c\u800c\u4e0d\u6703\u56e0\u70ba\u8868\u9054\u66f4\u8907\u96dc\u7684\u5206\u5e03\u800c\u7834\u58de\u55ae\u8f2a\u80fd\u529b\u3002</paragraph>", "author": "Yuxiao Qu et.al.", "authors": "Yuxiao Qu, Tianjun Zhang, Naman Garg, Aviral Kumar", "id": "2407.18219v1", "paper_url": "http://arxiv.org/abs/2407.18219v1", "repo": "null"}}