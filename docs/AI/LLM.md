
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-23**|**CRPO: Confidence-Reward Driven Preference Optimization for Machine Translation**|Guofeng Cui et.al.|[2501.13927v1](http://arxiv.org/abs/2501.13927v1)|null|
|**2025-01-23**|**Can We Generate Images with CoT? Let's Verify and Reinforce Image Generation Step by Step**|Ziyu Guo et.al.|[2501.13926v1](http://arxiv.org/abs/2501.13926v1)|[link](https://github.com/ziyuguo99/image-generation-cot)|
|**2025-01-23**|**Towards Robust Multimodal Open-set Test-time Adaptation via Adaptive Entropy-aware Optimization**|Hao Dong et.al.|[2501.13924v1](http://arxiv.org/abs/2501.13924v1)|[link](https://github.com/donghao51/aeo)|
|**2025-01-23**|**The Breeze 2 Herd of Models: Traditional Chinese LLMs Based on Llama with Vision-Aware and Function-Calling Capabilities**|Chan-Jan Hsu et.al.|[2501.13921v1](http://arxiv.org/abs/2501.13921v1)|null|
|**2025-01-23**|**IMAGINE-E: Image Generation Intelligence Evaluation of State-of-the-art Text-to-Image Models**|Jiayi Lei et.al.|[2501.13920v1](http://arxiv.org/abs/2501.13920v1)|null|
|**2025-01-23**|**Temporal Preference Optimization for Long-Form Video Understanding**|Rui Li et.al.|[2501.13919v1](http://arxiv.org/abs/2501.13919v1)|null|
|**2025-01-23**|**Improving Video Generation with Human Feedback**|Jie Liu et.al.|[2501.13918v1](http://arxiv.org/abs/2501.13918v1)|null|
|**2025-01-23**|**Analysis of Indic Language Capabilities in LLMs**|Aatman Vaidya et.al.|[2501.13912v1](http://arxiv.org/abs/2501.13912v1)|null|
|**2025-01-23**|**PointOBB-v3: Expanding Performance Boundaries of Single Point-Supervised Oriented Object Detection**|Peiyuan Zhang et.al.|[2501.13898v1](http://arxiv.org/abs/2501.13898v1)|null|
|**2025-01-23**|**GUI-Bee: Align GUI Action Grounding to Novel Environments via Autonomous Exploration**|Yue Fan et.al.|[2501.13896v1](http://arxiv.org/abs/2501.13896v1)|null|
|**2025-01-23**|**Pix2Cap-COCO: Advancing Visual Comprehension via Pixel-Level Captioning**|Zuyao You et.al.|[2501.13893v1](http://arxiv.org/abs/2501.13893v1)|[link](https://github.com/geshang777/pix2cap)|
|**2025-01-23**|**Exploring Finetuned Audio-LLM on Heart Murmur Features**|Adrian Florea et.al.|[2501.13884v1](http://arxiv.org/abs/2501.13884v1)|null|
|**2025-01-23**|**A RAG-Based Institutional Assistant**|Gustavo Kuratomi et.al.|[2501.13880v1](http://arxiv.org/abs/2501.13880v1)|null|
|**2025-01-23**|**Where Do You Go? Pedestrian Trajectory Prediction using Scene Features**|Mohammad Ali Rezaei et.al.|[2501.13848v1](http://arxiv.org/abs/2501.13848v1)|null|
|**2025-01-23**|**Think Outside the Data: Colonial Biases and Systemic Issues in Automated Moderation Pipelines for Low-Resource Languages**|Farhana Shahid et.al.|[2501.13836v1](http://arxiv.org/abs/2501.13836v1)|null|
|**2025-01-23**|**On the Reasoning Capacity of AI Models and How to Quantify It**|Santosh Kumar Radha et.al.|[2501.13833v1](http://arxiv.org/abs/2501.13833v1)|null|
|**2025-01-23**|**Predicting Compact Phrasal Rewrites with Large Language Models for ASR Post Editing**|Hao Zhang et.al.|[2501.13831v1](http://arxiv.org/abs/2501.13831v1)|null|
|**2025-01-23**|**A space-decoupling framework for optimization on bounded-rank matrices with orthogonally invariant constraints**|Yan Yang et.al.|[2501.13830v1](http://arxiv.org/abs/2501.13830v1)|null|
|**2025-01-23**|**Video-MMMU: Evaluating Knowledge Acquisition from Multi-Discipline Professional Videos**|Kairui Hu et.al.|[2501.13826v1](http://arxiv.org/abs/2501.13826v1)|null|
|**2025-01-23**|**Hallucinations Can Improve Large Language Models in Drug Discovery**|Shuzhou Yuan et.al.|[2501.13824v1](http://arxiv.org/abs/2501.13824v1)|null|
|**2025-01-23**|**Ensuring Medical AI Safety: Explainable AI-Driven Detection and Mitigation of Spurious Model Behavior and Associated Data**|Frederik Pahde et.al.|[2501.13818v1](http://arxiv.org/abs/2501.13818v1)|[link](https://github.com/frederikpahde/medical-ai-safety)|
|**2025-01-23**|**Learning to Help in Multi-Class Settings**|Yu Wu et.al.|[2501.13810v1](http://arxiv.org/abs/2501.13810v1)|null|
|**2025-01-23**|**Parameter-Efficient Fine-Tuning for Foundation Models**|Dan Zhang et.al.|[2501.13787v1](http://arxiv.org/abs/2501.13787v1)|[link](https://github.com/thudm/awesome-parameter-efficient-fine-tuning-for-foundation-models)|
|**2025-01-23**|**Not Every AI Problem is a Data Problem: We Should Be Intentional About Data Scaling**|Tanya Rodchenko et.al.|[2501.13779v1](http://arxiv.org/abs/2501.13779v1)|null|
|**2025-01-23**|**Explainable XR: Understanding User Behaviors of XR Environments using LLM-assisted Analytics Framework**|Yoonsang Kim et.al.|[2501.13778v1](http://arxiv.org/abs/2501.13778v1)|[link](https://github.com/yoonsang0910/explainablexr)|
|**2025-01-23**|**Do Large Language Models Truly Understand Geometric Structures?**|Xiaofeng Wang et.al.|[2501.13773v1](http://arxiv.org/abs/2501.13773v1)|null|
|**2025-01-23**|**Tune In, Act Up: Exploring the Impact of Audio Modality-Specific Edits on Large Audio Language Models in Jailbreak**|Erjia Xiao et.al.|[2501.13772v1](http://arxiv.org/abs/2501.13772v1)|null|
|**2025-01-23**|**UGMathBench: A Diverse and Dynamic Benchmark for Undergraduate-Level Mathematical Reasoning with Large Language Models**|Xin Xu et.al.|[2501.13766v1](http://arxiv.org/abs/2501.13766v1)|null|
|**2025-01-23**|**2-Tier SimCSE: Elevating BERT for Robust Sentence Embeddings**|Yumeng Wang et.al.|[2501.13758v1](http://arxiv.org/abs/2501.13758v1)|null|
|**2025-01-23**|**Solving the long-tailed distribution problem by exploiting the synergies and balance of different techniques**|Ziheng Wang et.al.|[2501.13756v1](http://arxiv.org/abs/2501.13756v1)|null|
|**2025-01-23**|**EICopilot: Search and Explore Enterprise Information over Large-scale Knowledge Graphs with LLM-driven Agents**|Yuhui Yun et.al.|[2501.13746v1](http://arxiv.org/abs/2501.13746v1)|null|
|**2025-01-23**|**A Study of the Plausibility of Attention between RNN Encoders in Natural Language Inference**|Duc Hau Nguyen et.al.|[2501.13735v1](http://arxiv.org/abs/2501.13735v1)|null|
|**2025-01-23**|**Pseudocode-Injection Magic: Enabling LLMs to Tackle Graph Computational Tasks**|Chang Gong et.al.|[2501.13731v1](http://arxiv.org/abs/2501.13731v1)|null|
|**2025-01-23**|**RPO: Retrieval Preference Optimization for Robust Retrieval-Augmented Generation**|Shi-Qi Yan et.al.|[2501.13726v1](http://arxiv.org/abs/2501.13726v1)|null|
|**2025-01-23**|**You Only Crash Once v2: Perceptually Consistent Strong Features for One-Stage Domain Adaptive Detection of Space Terrain**|Timothy Chase Jr et.al.|[2501.13725v1](http://arxiv.org/abs/2501.13725v1)|null|
|**2025-01-23**|**Musical ethnocentrism in Large Language Models**|Anna Kruspe et.al.|[2501.13720v1](http://arxiv.org/abs/2501.13720v1)|null|
|**2025-01-23**|**Skin Disease Detection and Classification of Actinic Keratosis and Psoriasis Utilizing Deep Transfer Learning**|Fahud Ahmmed et.al.|[2501.13713v1](http://arxiv.org/abs/2501.13713v1)|null|
|**2025-01-23**|**Formally Verified Neurosymbolic Trajectory Learning via Tensor-based Linear Temporal Logic on Finite Traces**|Mark Chevallier et.al.|[2501.13712v1](http://arxiv.org/abs/2501.13712v1)|null|
|**2025-01-23**|**YOLO11-JDE: Fast and Accurate Multi-Object Tracking with Self-Supervised Re-ID**|Iñaki Erregue et.al.|[2501.13710v1](http://arxiv.org/abs/2501.13710v1)|null|
|**2025-01-23**|**EventVL: Understand Event Streams via Multimodal Large Language Model**|Pengteng Li et.al.|[2501.13707v1](http://arxiv.org/abs/2501.13707v1)|null|
|**2025-01-23**|**DI-BENCH: Benchmarking Large Language Models on Dependency Inference with Testable Repositories at Scale**|Linghao Zhang et.al.|[2501.13699v1](http://arxiv.org/abs/2501.13699v1)|null|
|**2025-01-23**|**Training-Free Consistency Pipeline for Fashion Repose**|Potito Aghilar et.al.|[2501.13692v1](http://arxiv.org/abs/2501.13692v1)|null|
|**2025-01-23**|**Question Answering on Patient Medical Records with Private Fine-Tuned LLMs**|Sara Kothari et.al.|[2501.13687v1](http://arxiv.org/abs/2501.13687v1)|null|
|**2025-01-23**|**Unlearning Clients, Features and Samples in Vertical Federated Learning**|Ayush K. Varshney et.al.|[2501.13683v1](http://arxiv.org/abs/2501.13683v1)|null|
|**2025-01-23**|**Certified Robustness Under Bounded Levenshtein Distance**|Elias Abad Rocamora et.al.|[2501.13676v1](http://arxiv.org/abs/2501.13676v1)|null|
|**2025-01-23**|**How to Complete Domain Tuning while Keeping General Ability in LLM: Adaptive Layer-wise and Element-wise Regularization**|Shezheng Song et.al.|[2501.13669v1](http://arxiv.org/abs/2501.13669v1)|null|
|**2025-01-23**|**LVPruning: An Effective yet Simple Language-Guided Vision Token Pruning Approach for Multi-modal Large Language Models**|Yizheng Sun et.al.|[2501.13652v1](http://arxiv.org/abs/2501.13652v1)|null|
|**2025-01-23**|**Sigma: Differential Rescaling of Query, Key and Value for Efficient Language Models**|Zhenghao Lin et.al.|[2501.13629v1](http://arxiv.org/abs/2501.13629v1)|null|
|**2025-01-23**|**Coarse-to-Fine Process Reward Modeling for Enhanced Mathematical Reasoning**|Yulan Hu et.al.|[2501.13622v1](http://arxiv.org/abs/2501.13622v1)|null|
|**2025-01-23**|**Cognitive Paradigms for Evaluating VLMs on Visual Reasoning Task**|Mohit Vaishnav et.al.|[2501.13620v1](http://arxiv.org/abs/2501.13620v1)|null|
|**2025-01-23**|**Efficient Synaptic Delay Implementation in Digital Event-Driven AI Accelerators**|Roy Meijer et.al.|[2501.13610v1](http://arxiv.org/abs/2501.13610v1)|null|
|**2025-01-23**|**Domain-Specific Machine Translation to Translate Medicine Brochures in English to Sorani Kurdish**|Mariam Shamal et.al.|[2501.13609v1](http://arxiv.org/abs/2501.13609v1)|null|
|**2025-01-23**|**Text-to-SQL based on Large Language Models and Database Keyword Search**|Eduardo R. Nascimento et.al.|[2501.13594v1](http://arxiv.org/abs/2501.13594v1)|null|
|**2025-01-23**|**Contrastive Representation Learning Helps Cross-institutional Knowledge Transfer: A Study in Pediatric Ventilation Management**|Yuxuan et.al.|[2501.13587v1](http://arxiv.org/abs/2501.13587v1)|null|
|**2025-01-23**|**Improving Contextual Faithfulness of Large Language Models via Retrieval Heads-Induced Optimization**|Lei Huang et.al.|[2501.13573v1](http://arxiv.org/abs/2501.13573v1)|null|
|**2025-01-23**|**K-COMP: Retrieval-Augmented Medical Domain Question Answering With Knowledge-Injected Compressor**|Jeonghun Cho et.al.|[2501.13567v1](http://arxiv.org/abs/2501.13567v1)|null|
|**2025-01-23**|**Black-Box Adversarial Attack on Vision Language Models for Autonomous Driving**|Lu Wang et.al.|[2501.13563v1](http://arxiv.org/abs/2501.13563v1)|null|
|**2025-01-23**|**One-Prompt-One-Story: Free-Lunch Consistent Text-to-Image Generation Using a Single Prompt**|Tao Liu et.al.|[2501.13554v1](http://arxiv.org/abs/2501.13554v1)|[link](https://github.com/byliutao/1prompt1story)|
|**2025-01-23**|**Explainable AI-aided Feature Selection and Model Reduction for DRL-based V2X Resource Allocation**|Nasir Khan et.al.|[2501.13552v1](http://arxiv.org/abs/2501.13552v1)|null|
|**2025-01-23**|**LLMs Can Plan Only If We Tell Them**|Bilgehan Sel et.al.|[2501.13545v1](http://arxiv.org/abs/2501.13545v1)|null|
|**2025-01-23**|**ReasVQA: Advancing VideoQA with Imperfect Reasoning Process**|Jianxin Liang et.al.|[2501.13536v1](http://arxiv.org/abs/2501.13536v1)|null|
|**2025-01-23**|**Towards a Theory of AI Personhood**|Francis Rhys Ward et.al.|[2501.13533v1](http://arxiv.org/abs/2501.13533v1)|null|
|**2025-01-23**|**DQ-Data2vec: Decoupling Quantization for Multilingual Speech Recognition**|Qijie Shao et.al.|[2501.13497v1](http://arxiv.org/abs/2501.13497v1)|null|
|**2025-01-23**|**GCAD: Anomaly Detection in Multivariate Time Series from the Perspective of Granger Causality**|Zehao Liu et.al.|[2501.13493v1](http://arxiv.org/abs/2501.13493v1)|null|
|**2025-01-23**|**RECALL: Library-Like Behavior In Language Models is Enhanced by Self-Referencing Causal Cycles**|Munachiso Nwadike et.al.|[2501.13491v1](http://arxiv.org/abs/2501.13491v1)|null|
|**2025-01-23**|**MambaQuant: Quantizing the Mamba Family with Variance Aligned Rotation Methods**|Zukang Xu et.al.|[2501.13484v1](http://arxiv.org/abs/2501.13484v1)|[link](https://github.com/mambaquant/mambaquant)|
|**2025-01-23**|**Adaptive Testing for LLM-Based Applications: A Diversity-based Approach**|Juyeon Yoon et.al.|[2501.13480v1](http://arxiv.org/abs/2501.13480v1)|null|
|**2025-01-23**|**Adaptive Few-Shot Learning (AFSL): Tackling Data Scarcity with Stability, Robustness, and Versatility**|Rishabh Agrawal et.al.|[2501.13479v1](http://arxiv.org/abs/2501.13479v1)|null|
|**2025-01-23**|**Streaming Video Understanding and Multi-round Interaction with Memory-enhanced Knowledge**|Haomiao Xiong et.al.|[2501.13468v1](http://arxiv.org/abs/2501.13468v1)|[link](https://github.com/hmxiong/streamchat)|
|**2025-01-23**|**Multi-Level Attention and Contrastive Learning for Enhanced Text Classification with an Optimized Transformer**|Jia Gao et.al.|[2501.13467v1](http://arxiv.org/abs/2501.13467v1)|null|
|**2025-01-23**|**Zero-Shot Trajectory Planning for Signal Temporal Logic Tasks**|Ruijia Liu et.al.|[2501.13457v1](http://arxiv.org/abs/2501.13457v1)|null|
|**2025-01-23**|**KAA: Kolmogorov-Arnold Attention for Enhancing Attentive Graph Neural Networks**|Taoran Fang et.al.|[2501.13456v1](http://arxiv.org/abs/2501.13456v1)|[link](https://github.com/luckytiger123/kaa)|
|**2025-01-23**|**One-cycle Structured Pruning with Stability Driven Structure Search**|Deepak Ghimire et.al.|[2501.13439v1](http://arxiv.org/abs/2501.13439v1)|null|
|**2025-01-23**|**Softplus Attention with Re-weighting Boosts Length Extrapolation in Large Language Models**|Bo Gao et.al.|[2501.13428v1](http://arxiv.org/abs/2501.13428v1)|null|
|**2025-01-23**|**A Survey of Code-switched Arabic NLP: Progress, Challenges, and Future Directions**|Injy Hamed et.al.|[2501.13419v1](http://arxiv.org/abs/2501.13419v1)|null|
|**2025-01-23**|**Rethinking the Sample Relations for Few-Shot Classification**|Guowei Yin et.al.|[2501.13418v1](http://arxiv.org/abs/2501.13418v1)|null|
|**2025-01-23**|**M3PT: A Transformer for Multimodal, Multi-Party Social Signal Prediction with Person-aware Blockwise Attention**|Yiming Tang et.al.|[2501.13416v1](http://arxiv.org/abs/2501.13416v1)|[link](https://github.com/abraranwar/masked-social-signals)|
|**2025-01-23**|**Load and Renewable Energy Forecasting Using Deep Learning for Grid Stability**|Kamal Sarkar et.al.|[2501.13412v1](http://arxiv.org/abs/2501.13412v1)|null|
|**2025-01-23**|**YOLOv8 to YOLO11: A Comprehensive Architecture In-depth Comparative Review**|Priyanto Hidayatullah et.al.|[2501.13400v1](http://arxiv.org/abs/2501.13400v1)|null|
|**2025-01-23**|**ExLM: Rethinking the Impact of $\texttt{[MASK]}$ Tokens in Masked Language Models**|Kangjie Zheng et.al.|[2501.13397v1](http://arxiv.org/abs/2501.13397v1)|null|
|**2025-01-23**|**Can Large Language Models Understand Preferences in Personalized Recommendation?**|Zhaoxuan Tan et.al.|[2501.13391v1](http://arxiv.org/abs/2501.13391v1)|null|
|**2025-01-23**|**Do as We Do, Not as You Think: the Conformity of Large Language Models**|Zhiyuan Weng et.al.|[2501.13381v1](http://arxiv.org/abs/2501.13381v1)|[link](https://github.com/zhiyuan-weng/benchform)|
|**2025-01-23**|**Generative Data Augmentation Challenge: Zero-Shot Speech Synthesis for Personalized Speech Enhancement**|Jae-Sung Bae et.al.|[2501.13372v1](http://arxiv.org/abs/2501.13372v1)|null|
|**2025-01-23**|**A review on development of eco-friendly filters in Nepal for use in cigarettes and masks and Air Pollution Analysis with Machine Learning and SHAP Interpretability**|Bishwash Paneru et.al.|[2501.13369v1](http://arxiv.org/abs/2501.13369v1)|null|
|**2025-01-23**|**Enhanced Extractor-Selector Framework and Symmetrization Weighted Binary Cross-Entropy for Edge Detections**|Hao Shu et.al.|[2501.13365v1](http://arxiv.org/abs/2501.13365v1)|null|
|**2025-01-23**|**One Fits All: General Mobility Trajectory Modeling via Masked Conditional Diffusion**|Qingyue Long et.al.|[2501.13347v1](http://arxiv.org/abs/2501.13347v1)|null|
|**2025-01-23**|**Full-Stack Optimized Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation**|Rong Shan et.al.|[2501.13344v1](http://arxiv.org/abs/2501.13344v1)|null|
|**2025-01-23**|**AgentRec: Agent Recommendation Using Sentence Embeddings Aligned to Human Feedback**|Joshua Park et.al.|[2501.13333v1](http://arxiv.org/abs/2501.13333v1)|[link](https://github.com/joshprk/agentrec)|
|**2025-01-23**|**Sparse identification of nonlinear dynamics and Koopman operators with Shallow Recurrent Decoder Networks**|Mars Liyao Gao et.al.|[2501.13329v1](http://arxiv.org/abs/2501.13329v1)|null|
|**2025-01-23**|**Investigation of the Privacy Concerns in AI Systems for Young Digital Citizens: A Comparative Stakeholder Analysis**|Molly Campbell et.al.|[2501.13321v1](http://arxiv.org/abs/2501.13321v1)|null|
|**2025-01-23**|**Watching the AI Watchdogs: A Fairness and Robustness Analysis of AI Safety Moderation Classifiers**|Akshit Achara et.al.|[2501.13302v1](http://arxiv.org/abs/2501.13302v1)|null|
|**2025-01-23**|**Hypothesis Generation for Materials Discovery and Design Using Goal-Driven and Constraint-Guided LLM Agents**|Shrinidhi Kumbhar et.al.|[2501.13299v1](http://arxiv.org/abs/2501.13299v1)|null|
|**2025-01-23**|**RAMQA: A Unified Framework for Retrieval-Augmented Multi-Modal Question Answering**|Yang Bai et.al.|[2501.13297v1](http://arxiv.org/abs/2501.13297v1)|[link](https://github.com/tonyby/ramqa)|
|**2025-01-23**|**Parallel Belief Contraction via Order Aggregation**|Jake Chandler et.al.|[2501.13295v1](http://arxiv.org/abs/2501.13295v1)|null|
|**2025-01-23**|**Toyteller: AI-powered Visual Storytelling Through Toy-Playing with Character Symbols**|John Joon Young Chung et.al.|[2501.13284v1](http://arxiv.org/abs/2501.13284v1)|null|
|**2025-01-23**|**Experience with GitHub Copilot for Developer Productivity at Zoominfo**|Gal Bakal et.al.|[2501.13282v1](http://arxiv.org/abs/2501.13282v1)|null|
|**2025-01-22**|**RAG-Reward: Optimizing RAG with Reward Modeling and RLHF**|Hanning Zhang et.al.|[2501.13264v1](http://arxiv.org/abs/2501.13264v1)|null|
|**2025-01-22**|**Let SSMs be ConvNets: State-space Modeling with Optimal Tensor Contractions**|Yan Ru Pei et.al.|[2501.13230v1](http://arxiv.org/abs/2501.13230v1)|[link](https://github.com/Brainchip-Inc/Centaurus)|
|**2025-01-22**|**Learning in Log-Domain: Subthreshold Analog AI Accelerator Based on Stochastic Gradient Descent**|Momen K Tageldeen et.al.|[2501.13181v1](http://arxiv.org/abs/2501.13181v1)|null|
|**2025-01-22**|**QuFeX: Quantum feature extraction module for hybrid quantum-classical deep neural networks**|Naman Jain et.al.|[2501.13165v1](http://arxiv.org/abs/2501.13165v1)|null|

#### Abstracts
##### **CRPO: Confidence-Reward Driven Preference Optimization for Machine Translation**
2501.13927v1 by Guofeng Cui, Pichao Wang, Yang Liu, Zemian Ke, Zhu Liu, Vimal Bhat

Large language models (LLMs) have shown great potential in natural language
processing tasks, but their application to machine translation (MT) remains
challenging due to pretraining on English-centric data and the complexity of
reinforcement learning from human feedback (RLHF). Direct Preference
Optimization (DPO) has emerged as a simpler and more efficient alternative, but
its performance depends heavily on the quality of preference data. To address
this, we propose Confidence-Reward driven Preference Optimization (CRPO), a
novel method that combines reward scores with model confidence to improve data
selection for fine-tuning. CRPO selects challenging sentence pairs where the
model is uncertain or underperforms, leading to more effective learning. While
primarily designed for LLMs, CRPO also generalizes to encoder-decoder models
like NLLB, demonstrating its versatility. Empirical results show that CRPO
outperforms existing methods such as RS-DPO, RSO and MBR score in both
translation accuracy and data efficiency.

摘要：大型語言模型 (LLM) 在自然語言處理任務中展現出極大的潛力，但由於預訓練時以英語為中心資料，以及從人類回饋中進行強化學習的複雜性，其在機器翻譯 (MT) 中的應用仍然具有挑戰性。直接偏好最佳化 (DPO) 已成為一種更簡單且更有效率的替代方案，但其效能高度依賴於偏好資料的品質。為了解決此問題，我們提出以信心獎勵為驅動力的偏好最佳化 (CRPO)，這是一種結合獎勵分數與模型信心的新方法，以改善微調的資料選取。CRPO 選擇模型不確定或表現不佳的具挑戰性句子對，進而帶來更有效的學習。儘管 CRPO 主要設計用於 LLM，但它也適用於編碼器-解碼器模型，例如 NLLB，證明了其多功能性。實證結果顯示，CRPO 在翻譯準確度和資料效率方面均優於現有方法，例如 RS-DPO、RSO 和 MBR 分數。

##### **Can We Generate Images with CoT? Let's Verify and Reinforce Image Generation Step by Step**
2501.13926v1 by Ziyu Guo, Renrui Zhang, Chengzhuo Tong, Zhizheng Zhao, Peng Gao, Hongsheng Li, Pheng-Ann Heng

Chain-of-Thought (CoT) reasoning has been extensively explored in large
models to tackle complex understanding tasks. However, it still remains an open
question whether such strategies can be applied to verifying and reinforcing
image generation scenarios. In this paper, we provide the first comprehensive
investigation of the potential of CoT reasoning to enhance autoregressive image
generation. We focus on three techniques: scaling test-time computation for
verification, aligning model preferences with Direct Preference Optimization
(DPO), and integrating these techniques for complementary effects. Our results
demonstrate that these approaches can be effectively adapted and combined to
significantly improve image generation performance. Furthermore, given the
pivotal role of reward models in our findings, we propose the Potential
Assessment Reward Model (PARM) and PARM++, specialized for autoregressive image
generation. PARM adaptively assesses each generation step through a potential
assessment approach, merging the strengths of existing reward models, and
PARM++ further introduces a reflection mechanism to self-correct the generated
unsatisfactory image. Using our investigated reasoning strategies, we enhance a
baseline model, Show-o, to achieve superior results, with a significant +24%
improvement on the GenEval benchmark, surpassing Stable Diffusion 3 by +15%. We
hope our study provides unique insights and paves a new path for integrating
CoT reasoning with autoregressive image generation. Code and models are
released at https://github.com/ZiyuGuo99/Image-Generation-CoT

摘要：<paragraph>鏈式思考 (CoT) 推理已被廣泛地探索於大型模型中，以解決複雜的理解任務。然而，此類策略是否能應用於驗證和強化影像生成場景，仍是一個開放性的問題。在本文中，我們提供了第一個關於 CoT 推理潛力用於增強自迴歸影像生成的全面調查。我們專注於三種技術：擴展測試時間運算以進行驗證、將模型偏好與直接偏好最佳化 (DPO) 對齊，以及整合這些技術以產生互補效果。我們的結果證明，這些方法可以有效地適應並結合，以顯著改善影像生成效能。此外，鑑於獎勵模型在我們的發現中扮演著關鍵角色，我們提出了潛力評估獎勵模型 (PARM) 和 PARM++，專門用於自迴歸影像生成。PARM 透過潛力評估方法自適應地評估每個生成步驟，合併現有獎勵模型的優點，而 PARM++ 進一步引入反射機制來自我修正生成的令人不滿意的影像。使用我們調查的推理策略，我們增強了一個基準模型 Show-o，以取得優異的結果，在 GenEval 基準上顯著提升 +24%，超越 Stable Diffusion 3 +15%。我們希望我們的研究提供獨特的見解，並為將 CoT 推理與自迴歸影像生成整合開闢一條新途徑。程式碼和模型已於 https://github.com/ZiyuGuo99/Image-Generation-CoT 發布</paragraph>

##### **Towards Robust Multimodal Open-set Test-time Adaptation via Adaptive Entropy-aware Optimization**
2501.13924v1 by Hao Dong, Eleni Chatzi, Olga Fink

Test-time adaptation (TTA) has demonstrated significant potential in
addressing distribution shifts between training and testing data. Open-set
test-time adaptation (OSTTA) aims to adapt a source pre-trained model online to
an unlabeled target domain that contains unknown classes. This task becomes
more challenging when multiple modalities are involved. Existing methods have
primarily focused on unimodal OSTTA, often filtering out low-confidence samples
without addressing the complexities of multimodal data. In this work, we
present Adaptive Entropy-aware Optimization (AEO), a novel framework
specifically designed to tackle Multimodal Open-set Test-time Adaptation
(MM-OSTTA) for the first time. Our analysis shows that the entropy difference
between known and unknown samples in the target domain strongly correlates with
MM-OSTTA performance. To leverage this, we propose two key components:
Unknown-aware Adaptive Entropy Optimization (UAE) and Adaptive Modality
Prediction Discrepancy Optimization (AMP). These components enhance the ability
of model to distinguish unknown class samples during online adaptation by
amplifying the entropy difference between known and unknown samples. To
thoroughly evaluate our proposed methods in the MM-OSTTA setting, we establish
a new benchmark derived from existing datasets. This benchmark includes two
downstream tasks and incorporates five modalities. Extensive experiments across
various domain shift situations demonstrate the efficacy and versatility of the
AEO framework. Additionally, we highlight the strong performance of AEO in
long-term and continual MM-OSTTA settings, both of which are challenging and
highly relevant to real-world applications. Our source code is available at
https://github.com/donghao51/AEO.

摘要：<paragraph>測試時間適應 (TTA) 已展現出在解決訓練資料與測試資料之間的分配轉移上具有顯著潛力。開放集測試時間適應 (OSTTA) 旨在將來源預先訓練的模型線上適應到包含未知類別的未標記目標網域。當涉及多種模式時，這項任務將變得更具挑戰性。現有方法主要關注於單模態 OSTTA，通常會過濾掉低信心樣本，而不會解決多模態資料的複雜性。在這項工作中，我們提出自適應熵感知最佳化 (AEO)，這是一個新穎的架構，專門設計來首次處理多模態開放集測試時間適應 (MM-OSTTA)。我們的分析顯示，目標網域中已知和未知樣本之間的熵差異與 MM-OSTTA 效能密切相關。為了利用這一點，我們提出了兩個關鍵組成部分：未知感知自適應熵最佳化 (UAE) 和自適應模式預測差異最佳化 (AMP)。這些組成部分增強了模型在線上適應期間區分未知類別樣本的能力，方法是擴大已知和未知樣本之間的熵差異。為了在 MM-OSTTA 設定中徹底評估我們提出的方法，我們建立了一個源自現有資料集的新基準。此基準包含兩個下游任務並納入了五種模式。在各種領域轉移情況下的廣泛實驗證明了 AEO 架構的效能和多功能性。此外，我們強調了 AEO 在長期和持續的 MM-OSTTA 設定中的強勁效能，這兩者都具有挑戰性，並且與實際應用高度相關。我們的原始碼可在 https://github.com/donghao51/AEO 取得。</paragraph>

##### **The Breeze 2 Herd of Models: Traditional Chinese LLMs Based on Llama with Vision-Aware and Function-Calling Capabilities**
2501.13921v1 by Chan-Jan Hsu, Chia-Sheng Liu, Meng-Hsi Chen, Muxi Chen, Po-Chun Hsu, Yi-Chang Chen, Da-Shan Shiu

Breeze 2 is a suite of advanced multi-modal language models, available in 3B
and 8B parameter configurations, specifically designed to enhance Traditional
Chinese language representation. Building upon the Llama 3, Breeze 2 continues
pretraining on an extensive corpus to enhance the linguistic and cultural
heritage of Traditional Chinese. It incorporates vision-aware capabilities
through a visual encoder and a bridge module, and supports function-calling via
prompt templates and post-training on function-calling data. The effectiveness
of Breeze 2 is benchmarked across various tasks, including Taiwan general
knowledge, instruction-following, long context, function calling, and vision
understanding. Furthermore, we showcase the capabilities of the its 3B model in
a mobile application. We are publicly releasing all Breeze 2 models under the
Llama 3 Community License.

摘要：Breeze 2 是一套進階的多模態語言模型，提供 3B 和 8B 參數配置，專門設計用於增強繁體中文語言表示。Breeze 2 建立在 Llama 3 的基礎上，持續在廣泛的語料庫上進行預訓練，以增強繁體中文的語言和文化遺產。它透過視覺編碼器和橋接模組整合了視覺感知能力，並透過提示範本和功能呼叫資料的後續訓練支援功能呼叫。Breeze 2 的有效性已針對各種任務進行基準測試，包括台灣一般知識、遵循指示、長篇語境、功能呼叫和視覺理解。此外，我們在行動應用程式中展示其 3B 模型的功能。我們在 Llama 3 社群授權下公開發布所有 Breeze 2 模型。

##### **IMAGINE-E: Image Generation Intelligence Evaluation of State-of-the-art Text-to-Image Models**
2501.13920v1 by Jiayi Lei, Renrui Zhang, Xiangfei Hu, Weifeng Lin, Zhen Li, Wenjian Sun, Ruoyi Du, Le Zhuo, Zhongyu Li, Xinyue Li, Shitian Zhao, Ziyu Guo, Yiting Lu, Peng Gao, Hongsheng Li

With the rapid development of diffusion models, text-to-image(T2I) models
have made significant progress, showcasing impressive abilities in prompt
following and image generation. Recently launched models such as FLUX.1 and
Ideogram2.0, along with others like Dall-E3 and Stable Diffusion 3, have
demonstrated exceptional performance across various complex tasks, raising
questions about whether T2I models are moving towards general-purpose
applicability. Beyond traditional image generation, these models exhibit
capabilities across a range of fields, including controllable generation, image
editing, video, audio, 3D, and motion generation, as well as computer vision
tasks like semantic segmentation and depth estimation. However, current
evaluation frameworks are insufficient to comprehensively assess these models'
performance across expanding domains. To thoroughly evaluate these models, we
developed the IMAGINE-E and tested six prominent models: FLUX.1, Ideogram2.0,
Midjourney, Dall-E3, Stable Diffusion 3, and Jimeng. Our evaluation is divided
into five key domains: structured output generation, realism, and physical
consistency, specific domain generation, challenging scenario generation, and
multi-style creation tasks. This comprehensive assessment highlights each
model's strengths and limitations, particularly the outstanding performance of
FLUX.1 and Ideogram2.0 in structured and specific domain tasks, underscoring
the expanding applications and potential of T2I models as foundational AI
tools. This study provides valuable insights into the current state and future
trajectory of T2I models as they evolve towards general-purpose usability.
Evaluation scripts will be released at https://github.com/jylei16/Imagine-e.

摘要：<paragraph>隨著擴散模型的快速發展，文字轉圖像 (T2I) 模型已取得顯著進展，在提示追蹤和影像生成方面展現令人印象深刻的能力。最近推出的模型，如 FLUX.1 和 Ideogram2.0，以及 Dall-E3 和 Stable Diffusion 3 等其他模型，已在各種複雜任務中展現出色的效能，引發 T2I 模型是否正朝向通用適用性邁進的疑問。除了傳統的影像生成外，這些模型在可控生成、影像編輯、影片、音訊、3D 和動作生成，以及語意分割和深度估計等電腦視覺任務中展現出跨領域的能力。然而，目前的評估架構不足以全面評估這些模型在擴展領域中的效能。為了徹底評估這些模型，我們開發了 IMAGINE-E，並測試了六個傑出的模型：FLUX.1、Ideogram2.0、Midjourney、Dall-E3、Stable Diffusion 3 和 Jimeng。我們的評估分為五個關鍵領域：結構化輸出生成、真實感和物理一致性、特定領域生成、具挑戰性的場景生成和多樣式創作任務。此綜合評估突顯了每個模型的優勢和限制，特別是 FLUX.1 和 Ideogram2.0 在結構化和特定領域任務中的出色效能，強調了 T2I 模型作為基礎 AI 工具的擴展應用和潛力。本研究提供了對 T2I 模型當前狀態和未來軌跡的寶貴見解，因為它們朝向通用可用性演進。評估腳本將在 https://github.com/jylei16/Imagine-e 發布。</paragraph>

##### **Temporal Preference Optimization for Long-Form Video Understanding**
2501.13919v1 by Rui Li, Xiaohan Wang, Yuhui Zhang, Zeyu Wang, Serena Yeung-Levy

Despite significant advancements in video large multimodal models
(video-LMMs), achieving effective temporal grounding in long-form videos
remains a challenge for existing models. To address this limitation, we propose
Temporal Preference Optimization (TPO), a novel post-training framework
designed to enhance the temporal grounding capabilities of video-LMMs through
preference learning. TPO adopts a self-training approach that enables models to
differentiate between well-grounded and less accurate temporal responses by
leveraging curated preference datasets at two granularities: localized temporal
grounding, which focuses on specific video segments, and comprehensive temporal
grounding, which captures extended temporal dependencies across entire video
sequences. By optimizing on these preference datasets, TPO significantly
enhances temporal understanding while reducing reliance on manually annotated
data. Extensive experiments on three long-form video understanding
benchmarks--LongVideoBench, MLVU, and Video-MME--demonstrate the effectiveness
of TPO across two state-of-the-art video-LMMs. Notably, LLaVA-Video-TPO
establishes itself as the leading 7B model on the Video-MME benchmark,
underscoring the potential of TPO as a scalable and efficient solution for
advancing temporal reasoning in long-form video understanding. Project page:
https://ruili33.github.io/tpo_website.

摘要：儘管在視訊大型多模態模型（video-LMMs）中取得顯著進展，但在長篇影片中實現有效的時間基礎仍是現有模型的挑戰。為了解決此限制，我們提出時間偏好最佳化（TPO），這是一個新穎的後訓練架構，旨在透過偏好學習增強 video-LMMs 的時間基礎能力。TPO 採用自訓練方法，使模型能夠透過利用兩個粒度層級的精選偏好資料集來區分基礎良好的時間回應與較不準確的時間回應：局部時間基礎，專注於特定影片片段，以及全面時間基礎，擷取整個影片序列中延伸的時間依賴性。透過最佳化這些偏好資料集，TPO 大幅增強時間理解，同時減少對手動註解資料的依賴。在三個長篇影片理解基準測試（LongVideoBench、MLVU 和 Video-MME）上進行的大量實驗證明了 TPO 在兩個最先進的 video-LMMs 中的有效性。值得注意的是，LLaVA-Video-TPO 在 Video-MME 基準測試中確立了自己作為領先的 7B 模型，突顯了 TPO 作為可擴充且有效解決方案的潛力，可促進長篇影片理解中的時間推理。專案頁面：https://ruili33.github.io/tpo_website。

##### **Improving Video Generation with Human Feedback**
2501.13918v1 by Jie Liu, Gongye Liu, Jiajun Liang, Ziyang Yuan, Xiaokun Liu, Mingwu Zheng, Xiele Wu, Qiulin Wang, Wenyu Qin, Menghan Xia, Xintao Wang, Xiaohong Liu, Fei Yang, Pengfei Wan, Di Zhang, Kun Gai, Yujiu Yang, Wanli Ouyang

Video generation has achieved significant advances through rectified flow
techniques, but issues like unsmooth motion and misalignment between videos and
prompts persist. In this work, we develop a systematic pipeline that harnesses
human feedback to mitigate these problems and refine the video generation
model. Specifically, we begin by constructing a large-scale human preference
dataset focused on modern video generation models, incorporating pairwise
annotations across multi-dimensions. We then introduce VideoReward, a
multi-dimensional video reward model, and examine how annotations and various
design choices impact its rewarding efficacy. From a unified reinforcement
learning perspective aimed at maximizing reward with KL regularization, we
introduce three alignment algorithms for flow-based models by extending those
from diffusion models. These include two training-time strategies: direct
preference optimization for flow (Flow-DPO) and reward weighted regression for
flow (Flow-RWR), and an inference-time technique, Flow-NRG, which applies
reward guidance directly to noisy videos. Experimental results indicate that
VideoReward significantly outperforms existing reward models, and Flow-DPO
demonstrates superior performance compared to both Flow-RWR and standard
supervised fine-tuning methods. Additionally, Flow-NRG lets users assign custom
weights to multiple objectives during inference, meeting personalized video
quality needs. Project page: https://gongyeliu.github.io/videoalign.

摘要：影片生成透過修正流技術已獲得重大進展，但影片與提示之間的不流暢動態和未對齊等問題仍然存在。在本文中，我們開發了一個系統化管道，利用人類回饋來減輕這些問題並改善影片生成模型。具體來說，我們首先建立一個大型人類偏好資料集，專注於現代影片生成模型，並結合跨多維度的成對註解。接著我們介紹 VideoReward，一個多維影片獎勵模型，並探討註解和各種設計選擇如何影響其獎勵效能。從統一的強化學習觀點，旨在最大化具有 KL 正規化的獎勵，我們透過擴充擴散模型的演算法，為基於流的模型引入了三種對齊演算法。這些演算法包括兩個訓練時間策略：流的直接偏好最佳化 (Flow-DPO) 和流的獎勵加權迴歸 (Flow-RWR)，以及一個推論時間技術 Flow-NRG，它將獎勵引導直接應用於有雜訊的影片。實驗結果顯示，VideoReward 明顯優於現有的獎勵模型，而 Flow-DPO 與 Flow-RWR 和標準監督微調方法相比，表現出優異的效能。此外，Flow-NRG 讓使用者在推論期間為多個目標分配自訂權重，滿足個人化的影片品質需求。專案頁面：https://gongyeliu.github.io/videoalign。

##### **Analysis of Indic Language Capabilities in LLMs**
2501.13912v1 by Aatman Vaidya, Tarunima Prabhakar, Denny George, Swair Shah

This report evaluates the performance of text-in text-out Large Language
Models (LLMs) to understand and generate Indic languages. This evaluation is
used to identify and prioritize Indic languages suited for inclusion in safety
benchmarks. We conduct this study by reviewing existing evaluation studies and
datasets; and a set of twenty-eight LLMs that support Indic languages. We
analyze the LLMs on the basis of the training data, license for model and data,
type of access and model developers. We also compare Indic language performance
across evaluation datasets and find that significant performance disparities in
performance across Indic languages. Hindi is the most widely represented
language in models. While model performance roughly correlates with number of
speakers for the top five languages, the assessment after that varies.

摘要：這份報告評估文本輸入文本輸出的大型語言模型 (LLM) 了解和產生印度語言的效能。此評估用於找出並優先處理適合納入安全基準的印度語言。我們透過檢閱現有的評估研究和資料集來進行這項研究；以及支援印度語言的二十八個 LLM。我們根據訓練資料、模型和資料的授權、存取類型和模型開發者來分析 LLM。我們也比較了不同評估資料集的印度語言效能，並發現印度語言的效能有顯著的差異。印地語是模型中最廣泛代表的語言。儘管模型效能大致與前五名語言的使用者人數相關，但此後的評估則有所不同。

##### **PointOBB-v3: Expanding Performance Boundaries of Single Point-Supervised Oriented Object Detection**
2501.13898v1 by Peiyuan Zhang, Junwei Luo, Xue Yang, Yi Yu, Qingyun Li, Yue Zhou, Xiaosong Jia, Xudong Lu, Jingdong Chen, Xiang Li, Junchi Yan, Yansheng Li

With the growing demand for oriented object detection (OOD), recent studies
on point-supervised OOD have attracted significant interest. In this paper, we
propose PointOBB-v3, a stronger single point-supervised OOD framework. Compared
to existing methods, it generates pseudo rotated boxes without additional
priors and incorporates support for the end-to-end paradigm. PointOBB-v3
functions by integrating three unique image views: the original view, a resized
view, and a rotated/flipped (rot/flp) view. Based on the views, a scale
augmentation module and an angle acquisition module are constructed. In the
first module, a Scale-Sensitive Consistency (SSC) loss and a Scale-Sensitive
Feature Fusion (SSFF) module are introduced to improve the model's ability to
estimate object scale. To achieve precise angle predictions, the second module
employs symmetry-based self-supervised learning. Additionally, we introduce an
end-to-end version that eliminates the pseudo-label generation process by
integrating a detector branch and introduces an Instance-Aware Weighting (IAW)
strategy to focus on high-quality predictions. We conducted extensive
experiments on the DIOR-R, DOTA-v1.0/v1.5/v2.0, FAIR1M, STAR, and RSAR
datasets. Across all these datasets, our method achieves an average improvement
in accuracy of 3.56% in comparison to previous state-of-the-art methods. The
code will be available at https://github.com/ZpyWHU/PointOBB-v3.

摘要：隨著面向目標偵測 (OOD) 需求的增長，最近對點監督 OOD 的研究引起了極大的興趣。在本文中，我們提出了 PointOBB-v3，一個更強大的單點監督 OOD 框架。與現有方法相比，它在沒有額外先驗知識的情況下生成了偽旋轉框，並結合了對端到端範例的支持。PointOBB-v3 的功能是透過整合三個獨特的影像檢視：原始檢視、縮放檢視和旋轉/翻轉 (rot/flp) 檢視。根據這些檢視，構建了一個比例擴充模組和一個角度擷取模組。在第一個模組中，引入了比例敏感一致性 (SSC) 損失和比例敏感特徵融合 (SSFF) 模組，以提高模型估計物件比例的能力。為了實現精確的角度預測，第二個模組採用了基於對稱的自監督學習。此外，我們引入了端到端版本，透過整合偵測器分支並引入實例感知加權 (IAW) 策略來消除偽標籤生成過程，以專注於高品質預測。我們對 DIOR-R、DOTA-v1.0/v1.5/v2.0、FAIR1M、STAR 和 RSAR 資料集進行了廣泛的實驗。在所有這些資料集中，與先前的最先進方法相比，我們的模型在準確度方面平均提升了 3.56%。程式碼將可在 https://github.com/ZpyWHU/PointOBB-v3 取得。

##### **GUI-Bee: Align GUI Action Grounding to Novel Environments via Autonomous Exploration**
2501.13896v1 by Yue Fan, Handong Zhao, Ruiyi Zhang, Yu Shen, Xin Eric Wang, Gang Wu

Graphical User Interface (GUI) action grounding is a critical step in GUI
automation that maps language instructions to actionable elements on GUI
screens. Most recent works of GUI action grounding leverage large GUI datasets
to fine-tune MLLMs. However, the fine-tuning data always covers limited GUI
environments, and we find the performance of the resulting model deteriorates
in novel environments. We argue that the GUI grounding models should be further
aligned to the novel environments to reveal their full potential, when the
inference is known to involve novel environments, i.e., environments not used
during the previous fine-tuning. To realize this, we first propose GUI-Bee, an
MLLM-based autonomous agent, to collect high-quality, environment-specific data
through exploration and then continuously fine-tune GUI grounding models with
the collected data. Our agent leverages a novel Q-value-Incentive In-Context
Reinforcement Learning (Q-ICRL) method to optimize exploration efficiency and
data quality. Additionally, we introduce NovelScreenSpot, a benchmark for
testing how well the data can help align GUI action grounding models to novel
environments and demonstrate the effectiveness of data collected by GUI-Bee in
the experiments. Furthermore, we conduct an ablation study to validate the
Q-ICRL method in enhancing the efficiency of GUI-Bee. Project page:
https://gui-bee.github.io

摘要：圖形使用者介面 (GUI) 動作基礎是 GUI 自動化的關鍵步驟，它將語言指令對應到 GUI 畫面上的可操作元素。最近 GUI 動作基礎的大部分研究利用大型 GUI 資料集來微調 MLLM。然而，微調資料總是涵蓋有限的 GUI 環境，而我們發現產生的模型效能會在新的環境中惡化。我們主張 GUI 基礎模型應該進一步與新環境對齊，以發揮其全部潛力，當已知推論涉及新環境時，也就是在先前的微調中未使用的環境。為了實現這一點，我們首先提出 GUI-Bee，一個基於 MLLM 的自主代理，透過探索收集高品質、特定於環境的資料，然後持續微調 GUI 基礎模型，並使用收集到的資料。我們的代理利用新穎的 Q 值誘因情境內強化學習 (Q-ICRL) 方法來最佳化探索效率和資料品質。此外，我們引入了 NovelScreenSpot，一個用於測試資料在何種程度上可以協助將 GUI 動作基礎模型與新環境對齊的基準，並在實驗中展示 GUI-Bee 所收集的資料的有效性。此外，我們進行消融研究，以驗證 Q-ICRL 方法在提升 GUI-Bee 效率方面的作用。專案頁面：https://gui-bee.github.io

##### **Pix2Cap-COCO: Advancing Visual Comprehension via Pixel-Level Captioning**
2501.13893v1 by Zuyao You, Junke Wang, Lingyu Kong, Bo He, Zuxuan Wu

We present Pix2Cap-COCO, the first panoptic pixel-level caption dataset
designed to advance fine-grained visual understanding. To achieve this, we
carefully design an automated annotation pipeline that prompts GPT-4V to
generate pixel-aligned, instance-specific captions for individual objects
within images, enabling models to learn more granular relationships between
objects and their contexts. This approach results in 167,254 detailed captions,
with an average of 22.94 words per caption. Building on Pix2Cap-COCO, we
introduce a novel task, panoptic segmentation-captioning, which challenges
models to recognize instances in an image and provide detailed descriptions for
each simultaneously. To benchmark this task, we design a robust baseline based
on X-Decoder. The experimental results demonstrate that Pix2Cap-COCO is a
particularly challenging dataset, as it requires models to excel in both
fine-grained visual understanding and detailed language generation.
Furthermore, we leverage Pix2Cap-COCO for Supervised Fine-Tuning (SFT) on large
multimodal models (LMMs) to enhance their performance. For example, training
with Pix2Cap-COCO significantly improves the performance of GPT4RoI, yielding
gains in CIDEr +1.4%, ROUGE +0.4%, and SPICE +0.5% on Visual Genome dataset,
and strengthens its region understanding ability on the ViP-BENCH, with an
overall improvement of +5.1%, including notable increases in recognition
accuracy +11.2% and language generation quality +22.2%.

摘要：<paragraph>我們提出 Pix2Cap-COCO，這是第一個全景像素級標題資料集，旨在推進精細的視覺理解。為此，我們仔細設計了一個自動化標註管道，提示 GPT-4V 為影像中的個別物件產生像素對齊的特定實例標題，使模型能夠學習物件及其脈絡之間更細緻的關係。此方法產生了 167,254 個詳細標題，每個標題平均有 22.94 個字。在 Pix2Cap-COCO 的基礎上，我們引入了一項新任務，全景分割標題，它挑戰模型識別影像中的實例，並同時為每個實例提供詳細描述。為了對此任務進行基準測試，我們設計了一個基於 X-Decoder 的穩健基準。實驗結果表明，Pix2Cap-COCO 是一個特別具有挑戰性的資料集，因為它要求模型在精細的視覺理解和詳細的語言生成方面都表現出色。此外，我們利用 Pix2Cap-COCO 對大型多模態模型 (LMM) 進行監督微調 (SFT)，以增強其效能。例如，使用 Pix2Cap-COCO 進行訓練可顯著提升 GPT4RoI 的效能，在 Visual Genome 資料集上獲得 CIDEr +1.4%、ROUGE +0.4% 和 SPICE +0.5% 的提升，並在 ViP-BENCH 上增強其區域理解能力，整體提升 +5.1%，包括識別準確度 +11.2% 和語言生成品質 +22.2% 的顯著提升。</paragraph>

##### **Exploring Finetuned Audio-LLM on Heart Murmur Features**
2501.13884v1 by Adrian Florea, Xilin Jiang, Nima Mesgarani, Xiaofan Jiang

Large language models (LLMs) for audio have excelled in recognizing and
analyzing human speech, music, and environmental sounds. However, their
potential for understanding other types of sounds, particularly biomedical
sounds, remains largely underexplored despite significant scientific interest.
In this study, we focus on diagnosing cardiovascular diseases using
phonocardiograms, i.e., heart sounds. Most existing deep neural network (DNN)
paradigms are restricted to heart murmur classification (healthy vs unhealthy)
and do not predict other acoustic features of the murmur such as timing,
grading, harshness, pitch, and quality, which are important in helping
physicians diagnose the underlying heart conditions. We propose to finetune an
audio LLM, Qwen2-Audio, on the PhysioNet CirCor DigiScope phonocardiogram (PCG)
dataset and evaluate its performance in classifying 11 expert-labeled murmur
features. Additionally, we aim to achieve more noise-robust and generalizable
system by exploring a preprocessing segmentation algorithm using an audio
representation model, SSAMBA. Our results indicate that the LLM-based model
outperforms state-of-the-art methods in 8 of the 11 features and performs
comparably in the remaining 3. Moreover, the LLM successfully classifies
long-tail murmur features with limited training data, a task that all previous
methods have failed to classify. These findings underscore the potential of
audio LLMs as assistants to human cardiologists in enhancing heart disease
diagnosis.

摘要：大型語言模型 (LLM) 在識別和分析人類語言、音樂和環境音方面表現出色。然而，儘管科學界對此有濃厚的興趣，但它們在理解其他類型的聲音，特別是生物醫學聲音方面的潛力在很大程度上仍未得到充分探索。在本研究中，我們專注於使用心音圖（即心音）診斷心血管疾病。現有的大多數深度神經網路 (DNN) 典範僅限於心雜音分類（健康與不健康），並且不會預測雜音的其他聲學特徵，例如時序、分級、粗糙度、音高和品質，這些特徵對於幫助醫生診斷潛在的心臟疾病非常重要。我們建議對音訊 LLM Qwen2-Audio 進行微調，使用 PhysioNet CirCor DigiScope 心音圖 (PCG) 資料集，並評估其在分類 11 個專家標記雜音特徵方面的效能。此外，我們旨在透過探索使用音訊表示模型 SSAMBA 的預處理分割演算法，來實現更強大的抗噪性和可概化的系統。我們的結果表明，基於 LLM 的模型在 11 個特徵中的 8 個特徵中優於最先進的方法，而在其餘 3 個特徵中表現相當。此外，LLM 成功地對具有有限訓練資料的長尾雜音特徵進行分類，這是以前所有方法都無法分類的一項任務。這些發現強調了音訊 LLM 作為人類心臟病專家的助手在增強心臟病診斷方面的潛力。

##### **A RAG-Based Institutional Assistant**
2501.13880v1 by Gustavo Kuratomi, Paulo Pirozelli, Fabio G. Cozman, Sarajane M. Peres

Although large language models (LLMs) demonstrate strong text generation
capabilities, they struggle in scenarios requiring access to structured
knowledge bases or specific documents, limiting their effectiveness in
knowledge-intensive tasks. To address this limitation, retrieval-augmented
generation (RAG) models have been developed, enabling generative models to
incorporate relevant document fragments into their inputs. In this paper, we
design and evaluate a RAG-based virtual assistant specifically tailored for the
University of S\~ao Paulo. Our system architecture comprises two key modules: a
retriever and a generative model. We experiment with different types of models
for both components, adjusting hyperparameters such as chunk size and the
number of retrieved documents. Our optimal retriever model achieves a Top-5
accuracy of 30%, while our most effective generative model scores 22.04\%
against ground truth answers. Notably, when the correct document chunks are
supplied to the LLMs, accuracy significantly improves to 54.02%, an increase of
over 30 percentage points. Conversely, without contextual input, performance
declines to 13.68%. These findings highlight the critical role of database
access in enhancing LLM performance. They also reveal the limitations of
current semantic search methods in accurately identifying relevant documents
and underscore the ongoing challenges LLMs face in generating precise
responses.

摘要：儘管大型語言模型 (LLM) 展現出強大的文字生成能力，但它們在需要存取結構化知識庫或特定文件的情況下會遇到困難，這限制了它們在知識密集型任務中的效能。為了解決這個限制，已經開發出檢索增強生成 (RAG) 模型，讓生成模型能夠將相關的文件片段納入其輸入中。在本文中，我們設計並評估一個特別針對聖保羅大學量身打造的基於 RAG 的虛擬助理。我們的系統架構包含兩個關鍵模組：一個檢索器和一個生成模型。我們對這兩個元件的不同類型模型進行實驗，調整超參數，例如區塊大小和檢索文件數。我們最佳的檢索器模型達到 30% 的前 5 名準確率，而我們最有效的生成模型針對真實答案得分為 22.04%。值得注意的是，當正確的文件區塊提供給 LLM 時，準確率顯著提升至 54.02%，提升超過 30 個百分點。相反地，在沒有上下文輸入的情況下，效能下降至 13.68%。這些發現突顯了資料庫存取在提升 LLM 效能中扮演關鍵角色。它們也揭示了當前語意搜尋方法在準確識別相關文件方面的限制，並強調 LLM 在產生精確回應時面臨的持續挑戰。

##### **Where Do You Go? Pedestrian Trajectory Prediction using Scene Features**
2501.13848v1 by Mohammad Ali Rezaei, Fardin Ayar, Ehsan Javanmardi, Manabu Tsukada, Mahdi Javanmardi

Accurate prediction of pedestrian trajectories is crucial for enhancing the
safety of autonomous vehicles and reducing traffic fatalities involving
pedestrians. While numerous studies have focused on modeling interactions among
pedestrians to forecast their movements, the influence of environmental factors
and scene-object placements has been comparatively underexplored. In this
paper, we present a novel trajectory prediction model that integrates both
pedestrian interactions and environmental context to improve prediction
accuracy. Our approach captures spatial and temporal interactions among
pedestrians within a sparse graph framework. To account for pedestrian-scene
interactions, we employ advanced image enhancement and semantic segmentation
techniques to extract detailed scene features. These scene and interaction
features are then fused through a cross-attention mechanism, enabling the model
to prioritize relevant environmental factors that influence pedestrian
movements. Finally, a temporal convolutional network processes the fused
features to predict future pedestrian trajectories. Experimental results
demonstrate that our method significantly outperforms existing state-of-the-art
approaches, achieving ADE and FDE values of 0.252 and 0.372 meters,
respectively, underscoring the importance of incorporating both social
interactions and environmental context in pedestrian trajectory prediction.

摘要：行人軌跡的精準預測對於提升自動駕駛車輛的安全性和減少行人交通事故至關重要。雖然許多研究專注於建模行人之間的互動以預測其移動，但環境因素和場景物件擺放的影響相對未被充分探討。在本文中，我們提出一個創新的軌跡預測模型，整合行人互動和環境背景以提升預測準確度。我們的做法在稀疏圖形架構中擷取行人之間的空間和時間互動。為了考量行人與場景的互動，我們採用先進的影像增強和語意分割技術來萃取詳細的場景特徵。然後透過交叉注意機制融合這些場景和互動特徵，使模型能夠優先考慮影響行人移動的相关環境因素。最後，時序卷積網路處理融合的特徵以預測未來的行人軌跡。實驗結果證明，我們的模型明顯優於現有的最先進方法，分別達到 ADE 和 FDE 值為 0.252 和 0.372 公尺，強調了在行人軌跡預測中納入社會互動和環境背景的重要性。

##### **Think Outside the Data: Colonial Biases and Systemic Issues in Automated Moderation Pipelines for Low-Resource Languages**
2501.13836v1 by Farhana Shahid, Mona Elswah, Aditya Vashistha

Most social media users come from non-English speaking countries in the
Global South. Despite the widespread prevalence of harmful content in these
regions, current moderation systems repeatedly struggle in low-resource
languages spoken there. In this work, we examine the challenges AI researchers
and practitioners face when building moderation tools for low-resource
languages. We conducted semi-structured interviews with 22 AI researchers and
practitioners specializing in automatic detection of harmful content in four
diverse low-resource languages from the Global South. These are: Tamil from
South Asia, Swahili from East Africa, Maghrebi Arabic from North Africa, and
Quechua from South America. Our findings reveal that social media companies'
restrictions on researchers' access to data exacerbate the historical
marginalization of these languages, which have long lacked datasets for
studying online harms. Moreover, common preprocessing techniques and language
models, predominantly designed for data-rich English, fail to account for the
linguistic complexity of low-resource languages. This leads to critical errors
when moderating content in Tamil, Swahili, Arabic, and Quechua, which are
morphologically richer than English. Based on our findings, we establish that
the precarities in current moderation pipelines are rooted in deep systemic
inequities and continue to reinforce historical power imbalances. We conclude
by discussing multi-stakeholder approaches to improve moderation for
low-resource languages.

摘要：大多數社群媒體使用者來自全球南方的非英語系國家。儘管這些地區普遍存在有害內容，但目前的審核系統仍反覆在當地所使用的低資源語言中面臨挑戰。在這項研究中，我們探討了人工智慧研究人員和從業人員在為低資源語言建構審核工具時所面臨的挑戰。我們對 22 位人工智慧研究人員和從業人員進行了半結構式訪談，這些人員專精於自動偵測來自全球南方四種不同低資源語言中的有害內容。這些語言分別為：來自南亞的泰米爾語、來自東非的斯瓦希里語、來自北非的馬格里布阿拉伯語和來自南美洲的蓋丘亞語。我們的研究結果顯示，社群媒體公司對研究人員取得資料的限制加劇了這些語言在歷史上的邊緣化，這些語言長期以來缺乏用於研究網路危害的資料集。此外，常見的預處理技術和語言模型主要設計用於資料豐富的英語，無法考量低資源語言的語言複雜性。這導致在審核泰米爾語、斯瓦希里語、阿拉伯語和蓋丘亞語的內容時出現嚴重的錯誤，這些語言在形態上比英語更豐富。根據我們的研究結果，我們確立了目前審核流程中的不穩定性根源於深層的系統性不平等，並持續強化歷史上的權力失衡。我們最後討論了改善低資源語言審核的多方利益相關者方法。

##### **On the Reasoning Capacity of AI Models and How to Quantify It**
2501.13833v1 by Santosh Kumar Radha, Oktay Goktas

Recent advances in Large Language Models (LLMs) have intensified the debate
surrounding the fundamental nature of their reasoning capabilities. While
achieving high performance on benchmarks such as GPQA and MMLU, these models
exhibit limitations in more complex reasoning tasks, highlighting the need for
more rigorous evaluation methodologies. We propose a novel phenomenological
approach that goes beyond traditional accuracy metrics to probe the underlying
mechanisms of model behavior, establishing a framework that could broadly
impact how we analyze and understand AI systems. Using positional bias in
multiple-choice reasoning tasks as a case study, we demonstrate how systematic
perturbations can reveal fundamental aspects of model decision-making. To
analyze these behaviors, we develop two complementary phenomenological models:
a Probabilistic Mixture Model (PMM) that decomposes model responses into
reasoning, memorization, and guessing components and an Information-Theoretic
Consistency (ITC) analysis that quantifies the relationship between model
confidence and strategy selection. Through controlled experiments on reasoning
benchmarks, we show that true reasoning remains challenging for current models,
with apparent success often relying on sophisticated combinations of
memorization and pattern matching rather than genuine logical deduction. More
fundamentally, we demonstrate that accuracy alone often overstates a model's
reasoning abilities, as model behavior can be characterized through underlying
mechanisms in the phase space of cognitive strategies, revealing how models
dynamically balance different approaches when responding to queries. This
framework enables quantitative criteria for real-world deployments, allowing
applications to specify reliability thresholds based on strategy distributions
rather than aggregate performance metrics.

摘要：<paragraph>大型語言模型 (LLM) 的最新進展加劇了圍繞其推理能力的根本性質的爭論。儘管在 GPQA 和 MMLU 等基準測試中取得了很高的性能，但這些模型在更複雜的推理任務中表現出侷限性，凸顯了對更嚴謹評估方法的需求。我們提出了一種新穎的現象學方法，它超越了傳統的準確度指標，以探討模型行為的底層機制，建立一個框架，可以廣泛地影響我們分析和理解 AI 系統的方式。使用多選推理任務中的位置偏誤作為案例研究，我們展示了系統性擾動如何揭示模型決策制定的基本方面。為了分析這些行為，我們開發了兩個互補的現象學模型：一個概率混合模型 (PMM)，它將模型反應分解為推理、記憶和猜測組成部分，以及一個信息論一致性 (ITC) 分析，它量化了模型信心和策略選擇之間的關係。通過在推理基準測試上進行受控實驗，我們表明真正的推理對於當前模型仍然具有挑戰性，明顯的成功通常依賴於記憶和模式匹配的複雜組合，而不是真正的邏輯推論。更根本的是，我們證明了準確性本身通常會誇大模型的推理能力，因為模型行為可以通過認知策略相空間中的底層機制來表徵，揭示了模型在響應查詢時如何動態平衡不同的方法。此框架為實際部署提供了定量標準，允許應用程序根據策略分佈而不是總體性能指標指定可靠性閾值。</paragraph>

##### **Predicting Compact Phrasal Rewrites with Large Language Models for ASR Post Editing**
2501.13831v1 by Hao Zhang, Felix Stahlberg, Shankar Kumar

Large Language Models (LLMs) excel at rewriting tasks such as text style
transfer and grammatical error correction. While there is considerable overlap
between the inputs and outputs in these tasks, the decoding cost still
increases with output length, regardless of the amount of overlap. By
leveraging the overlap between the input and the output, Kaneko and Okazaki
(2023) proposed model-agnostic edit span representations to compress the
rewrites to save computation. They reported an output length reduction rate of
nearly 80% with minimal accuracy impact in four rewriting tasks. In this paper,
we propose alternative edit phrase representations inspired by phrase-based
statistical machine translation. We systematically compare our phrasal
representations with their span representations. We apply the LLM rewriting
model to the task of Automatic Speech Recognition (ASR) post editing and show
that our target-phrase-only edit representation has the best
efficiency-accuracy trade-off. On the LibriSpeech test set, our method closes
50-60% of the WER gap between the edit span model and the full rewrite model
while losing only 10-20% of the length reduction rate of the edit span model.

摘要：大型語言模型 (LLM) 在重寫任務中表現出色，例如文字風格轉換和語法錯誤更正。雖然在這些任務中輸入和輸出之間有相當大的重疊，但解碼成本仍會隨著輸出長度增加，而與重疊量無關。透過利用輸入和輸出之間的重疊，Kaneko 和 Okazaki (2023) 提出與模型無關的編輯範圍表示法，以壓縮重寫內容以節省運算。他們報告說，在四項重寫任務中，輸出長度減少率接近 80%，且對準確度的影響很小。在本文中，我們提出受基於短語的統計機器翻譯啟發的替代編輯短語表示法。我們系統性地將我們的短語表示法與他們的範圍表示法進行比較。我們將 LLM 重寫模型應用於自動語音識別 (ASR) 後編輯任務，並展示我們的僅目標短語編輯表示法具有最佳的效率準確性權衡。在 LibriSpeech 測試集中，我們的模型縮小了編輯範圍模型和完整重寫模型之間 50-60% 的 WER 差距，同時僅損失了編輯範圍模型 10-20% 的長度減少率。

##### **A space-decoupling framework for optimization on bounded-rank matrices with orthogonally invariant constraints**
2501.13830v1 by Yan Yang, Bin Gao, Ya-xiang Yuan

Imposing additional constraints on low-rank optimization has garnered growing
interest. However, the geometry of coupled constraints hampers the
well-developed low-rank structure and makes the problem intricate. To this end,
we propose a space-decoupling framework for optimization on bounded-rank
matrices with orthogonally invariant constraints. The ``space-decoupling" is
reflected in several ways. We show that the tangent cone of coupled constraints
is the intersection of tangent cones of each constraint. Moreover, we decouple
the intertwined bounded-rank and orthogonally invariant constraints into two
spaces, leading to optimization on a smooth manifold. Implementing Riemannian
algorithms on this manifold is painless as long as the geometry of additional
constraints is known. In addition, we unveil the equivalence between the
reformulated problem and the original problem. Numerical experiments on
real-world applications -- spherical data fitting, graph similarity measuring,
low-rank SDP, model reduction of Markov processes, reinforcement learning, and
deep learning -- validate the superiority of the proposed framework.

摘要：施加額外的約束在低秩最佳化已經引起越來越多的興趣。然而，耦合約束的幾何結構阻礙了發展良好的低秩結構，使得問題變得複雜。為此，我們提出了一個用於最佳化正交不變約束的邊界秩矩陣的空間解耦框架。``空間解耦''反映在幾個方面。我們表明耦合約束的切線錐是每個約束的切線錐的交集。此外，我們將交織的邊界秩和正交不變約束解耦成兩個空間，從而導致在平滑流形上進行最佳化。只要已知額外約束的幾何結構，在這個流形上實作黎曼演算法就會很輕鬆。此外，我們揭示了重新表述的問題和原始問題之間的等價性。在現實世界應用中的數值實驗——球形資料擬合、圖形相似性測量、低秩 SDP、馬可夫過程的模型簡化、強化學習和深度學習——驗證了所提出的框架的優越性。

##### **Video-MMMU: Evaluating Knowledge Acquisition from Multi-Discipline Professional Videos**
2501.13826v1 by Kairui Hu, Penghao Wu, Fanyi Pu, Wang Xiao, Yuanhan Zhang, Xiang Yue, Bo Li, Ziwei Liu

Humans acquire knowledge through three cognitive stages: perceiving
information, comprehending knowledge, and adapting knowledge to solve novel
problems. Videos serve as an effective medium for this learning process,
facilitating a progression through these cognitive stages. However, existing
video benchmarks fail to systematically evaluate the knowledge acquisition
capabilities in Large Multimodal Models (LMMs). To address this gap, we
introduce Video-MMMU, a multi-modal, multi-disciplinary benchmark designed to
assess LMMs' ability to acquire and utilize knowledge from videos. Video-MMMU
features a curated collection of 300 expert-level videos and 900
human-annotated questions across six disciplines, evaluating knowledge
acquisition through stage-aligned question-answer pairs: Perception,
Comprehension, and Adaptation. A proposed knowledge gain metric,
{\Delta}knowledge, quantifies improvement in performance after video viewing.
Evaluation of LMMs reveals a steep decline in performance as cognitive demands
increase and highlights a significant gap between human and model knowledge
acquisition, underscoring the need for methods to enhance LMMs' capability to
learn and adapt from videos.

摘要：人類透過三個認知階段來獲取知識：感知資訊、理解知識，以及適應知識來解決新問題。影片作為此學習歷程的有效媒介，促進了這些認知階段的進展。然而，現有的影片基準未能系統性地評估大型多模態模型 (LMM) 中的知識獲取能力。為了解決這個差距，我們引入了 Video-MMMU，一個多模態、多領域的基準，旨在評估 LMM 從影片中獲取和利用知識的能力。Video-MMMU 具有經過策展的 300 個專家級影片和 900 個跨六個領域的人工標註問題，透過與階段對齊的問題回答對來評估知識獲取：感知、理解和適應。一個提出的知識獲取指標 {\Delta}knowledge，量化了觀看影片後效能的提升。對 LMM 的評估顯示，隨著認知需求的增加，效能大幅下降，並突顯了人類和模型知識獲取之間的顯著差距，強調了增強 LMM 從影片中學習和適應的能力的方法的必要性。

##### **Hallucinations Can Improve Large Language Models in Drug Discovery**
2501.13824v1 by Shuzhou Yuan, Michael Färber

Concerns about hallucinations in Large Language Models (LLMs) have been
raised by researchers, yet their potential in areas where creativity is vital,
such as drug discovery, merits exploration. In this paper, we come up with the
hypothesis that hallucinations can improve LLMs in drug discovery. To verify
this hypothesis, we use LLMs to describe the SMILES string of molecules in
natural language and then incorporate these descriptions as part of the prompt
to address specific tasks in drug discovery. Evaluated on seven LLMs and five
classification tasks, our findings confirm the hypothesis: LLMs can achieve
better performance with text containing hallucinations. Notably, Llama-3.1-8B
achieves an 18.35% gain in ROC-AUC compared to the baseline without
hallucination. Furthermore, hallucinations generated by GPT-4o provide the most
consistent improvements across models. Additionally, we conduct empirical
analyses and a case study to investigate key factors affecting performance and
the underlying reasons. Our research sheds light on the potential use of
hallucinations for LLMs and offers new perspectives for future research
leveraging LLMs in drug discovery.

摘要：大型语言模型 (LLM) 中的幻觉问题已被研究人员提出，但其在创造力至关重要的领域（例如药物发现）中的潜力值得探索。在本文中，我们提出了一个假设，即幻觉可以改善 LLM 在药物发现中的表现。为了验证这个假设，我们使用 LLM 用自然语言描述分子的 SMILES 字符串，然后将这些描述作为提示的一部分，以解决药物发现中的特定任务。在七个 LLM 和五个分类任务上的评估中，我们的发现证实了这一假设：LLM 可以通过包含幻觉的文本获得更好的性能。值得注意的是，与没有幻觉的基线相比，Llama-3.1-8B 在 ROC-AUC 中获得了 18.35% 的收益。此外，GPT-4o 生成的幻觉在所有模型中提供了最一致的改进。此外，我们进行了实证分析和案例研究，以调查影响性能的关键因素和潜在原因。我们的研究揭示了幻觉在 LLM 中的潜在用途，并为未来利用 LLM 进行药物发现的研究提供了新的视角。

##### **Ensuring Medical AI Safety: Explainable AI-Driven Detection and Mitigation of Spurious Model Behavior and Associated Data**
2501.13818v1 by Frederik Pahde, Thomas Wiegand, Sebastian Lapuschkin, Wojciech Samek

Deep neural networks are increasingly employed in high-stakes medical
applications, despite their tendency for shortcut learning in the presence of
spurious correlations, which can have potentially fatal consequences in
practice. Detecting and mitigating shortcut behavior is a challenging task that
often requires significant labeling efforts from domain experts. To alleviate
this problem, we introduce a semi-automated framework for the identification of
spurious behavior from both data and model perspective by leveraging insights
from eXplainable Artificial Intelligence (XAI). This allows the retrieval of
spurious data points and the detection of model circuits that encode the
associated prediction rules. Moreover, we demonstrate how these shortcut
encodings can be used for XAI-based sample- and pixel-level data annotation,
providing valuable information for bias mitigation methods to unlearn the
undesired shortcut behavior. We show the applicability of our framework using
four medical datasets across two modalities, featuring controlled and
real-world spurious correlations caused by data artifacts. We successfully
identify and mitigate these biases in VGG16, ResNet50, and contemporary Vision
Transformer models, ultimately increasing their robustness and applicability
for real-world medical tasks.

摘要：深度神经网络越来越多地用于高风险医疗应用中，尽管它们在存在虚假相关性的情况下倾向于捷径学习，这在实践中可能产生致命的后果。检测和缓解捷径行为是一项艰巨的任务，通常需要领域专家的大量标记工作。为了缓解这个问题，我们引入了一个半自动框架，用于从数据和模型的角度识别虚假行为，方法是利用可解释人工智能 (XAI) 的见解。这允许检索虚假数据点并检测对关联预测规则进行编码的模型电路。此外，我们演示了如何使用这些捷径编码进行基于 XAI 的样本和像素级数据注释，为偏差缓解方法提供有价值的信息，以消除不需要的捷径行为。我们使用跨越两种方式的四个医学数据集展示了我们框架的适用性，这些数据集具有由数据伪像引起的受控和真实世界虚假相关性。我们成功地识别并减轻了 VGG16、ResNet50 和当代 Vision Transformer 模型中的这些偏差，最终提高了它们的鲁棒性和在真实世界医疗任务中的适用性。

##### **Learning to Help in Multi-Class Settings**
2501.13810v1 by Yu Wu, Yansong Li, Zeyu Dong, Nitya Sathyavageeswaran, Anand D. Sarwate

Deploying complex machine learning models on resource-constrained devices is
challenging due to limited computational power, memory, and model
retrainability. To address these limitations, a hybrid system can be
established by augmenting the local model with a server-side model, where
samples are selectively deferred by a rejector and then sent to the server for
processing. The hybrid system enables efficient use of computational resources
while minimizing the overhead associated with server usage. The recently
proposed Learning to Help (L2H) model trains a server model given a fixed local
(client) model, differing from the Learning to Defer (L2D) framework, which
trains the client for a fixed (expert) server. In both L2D and L2H, the
training includes learning a rejector at the client to determine when to query
the server. In this work, we extend the L2H model from binary to multi-class
classification problems and demonstrate its applicability in a number of
different scenarios of practical interest in which access to the server may be
limited by cost, availability, or policy. We derive a stage-switching surrogate
loss function that is differentiable, convex, and consistent with the Bayes
rule corresponding to the 0-1 loss for the L2H model. Experiments show that our
proposed methods offer an efficient and practical solution for multi-class
classification in resource-constrained environments.

摘要：<paragraph>在資源受限的裝置上部署複雜的機器學習模型，由於運算能力、記憶體和模型再訓練能力有限，因此具有挑戰性。為了解決這些限制，可以透過擴充本地模型搭配伺服器端模型來建立一個混合系統，其中樣本由拒絕器選擇性地遞延，然後傳送至伺服器進行處理。混合系統能有效利用運算資源，同時將與伺服器使用相關的開銷降到最低。最近提出的學習協助 (L2H) 模型會訓練一個伺服器模型，給定一個固定的本地 (用戶端) 模型，這與學習遞延 (L2D) 架構不同，後者會訓練用戶端以搭配一個固定的 (專家) 伺服器。在 L2D 和 L2H 中，訓練包含在用戶端學習一個拒絕器，以決定何時查詢伺服器。在這項工作中，我們將 L2H 模型從二元分類問題擴充到多類別分類問題，並展示其在許多不同的實際應用情境中的適用性，其中對伺服器的存取可能受到成本、可用性或政策的限制。我們推導出一個可微分、凸且與 L2H 模型的 0-1 損失相符的貝氏定理分段切換代理損失函數。實驗顯示，我們提出的方法提供了一個在資源受限的環境中進行多類別分類的有效且實用的解決方案。</paragraph>

##### **Parameter-Efficient Fine-Tuning for Foundation Models**
2501.13787v1 by Dan Zhang, Tao Feng, Lilong Xue, Yuandong Wang, Yuxiao Dong, Jie Tang

This survey delves into the realm of Parameter-Efficient Fine-Tuning (PEFT)
within the context of Foundation Models (FMs). PEFT, a cost-effective
fine-tuning technique, minimizes parameters and computational complexity while
striving for optimal downstream task performance. FMs, like ChatGPT, DALL-E,
and LLaVA specialize in language understanding, generative tasks, and
multimodal tasks, trained on diverse datasets spanning text, images, and
videos. The diversity of FMs guides various adaptation strategies for PEFT.
Therefore, this survey aims to provide a comprehensive overview of PEFT
techniques applied to diverse FMs and address critical gaps in understanding
the techniques, trends, and applications. We start by providing a detailed
development of FMs and PEFT. Subsequently, we systematically review the key
categories and core mechanisms of PEFT across diverse FMs to offer a
comprehensive understanding of trends. We also explore the most recent
applications across various FMs to demonstrate the versatility of PEFT,
shedding light on the integration of systematic PEFT methods with a range of
FMs. Furthermore, we identify potential research and development directions for
improving PEFTs in the future. This survey provides a valuable resource for
both newcomers and experts seeking to understand and use the power of PEFT
across FMs. All reviewed papers are listed at
\url{https://github.com/THUDM/Awesome-Parameter-Efficient-Fine-Tuning-for-Foundation-Models}.

摘要：這項調查深入探討基礎模型 (FM) 中參數有效微調 (PEFT) 的領域。PEFT 是一種具成本效益的微調技術，可最小化參數和計算複雜度，同時努力實現最佳的下游任務效能。像 ChatGPT、DALL-E 和 LLaVA 等 FM 專精於語言理解、生成任務和多模態任務，並針對涵蓋文字、影像和影片的各種資料集進行訓練。FM 的多樣性引導了 PEFT 的各種適應策略。因此，本調查旨在對應用於各種 FM 的 PEFT 技術提供全面的概觀，並解決在理解技術、趨勢和應用方面的關鍵差距。我們從提供 FM 和 PEFT 的詳細開發開始。隨後，我們系統性地檢視各種 FM 中 PEFT 的主要類別和核心機制，以提供對趨勢的全面理解。我們還探討了各種 FM 中最新的應用，以展示 PEFT 的多功能性，闡明系統性 PEFT 方法與各種 FM 整合的優點。此外，我們找出潛在的研究和開發方向，以改善未來 PEFT。本調查為尋求了解和使用 FM 中 PEFT 威力的新手和專家提供了寶貴的資源。所有檢視過的論文都列在
\url{https://github.com/THUDM/Awesome-Parameter-Efficient-Fine-Tuning-for-Foundation-Models}。

##### **Not Every AI Problem is a Data Problem: We Should Be Intentional About Data Scaling**
2501.13779v1 by Tanya Rodchenko, Natasha Noy, Nino Scherrer, Jennifer Prendki

While Large Language Models require more and more data to train and scale,
rather than looking for any data to acquire, we should consider what types of
tasks are more likely to benefit from data scaling. We should be intentional in
our data acquisition. We argue that the topology of data itself informs which
tasks to prioritize in data scaling, and shapes the development of the next
generation of compute paradigms for tasks where data scaling is inefficient, or
even insufficient.

摘要：儘管大型語言模型需要越來越多的資料來訓練和擴展，
與其尋找任何資料來取得，我們應該考慮哪種類型的
任務更有可能從資料擴展中受益。我們應該在
我們的資料取得中是有意的。我們認為資料本身的拓撲結構會告知
哪些任務在資料擴展中優先處理，並塑造下一
代計算範例的發展，因為在資料擴展效率低下的任務中，
甚至是不足夠的。

##### **Explainable XR: Understanding User Behaviors of XR Environments using LLM-assisted Analytics Framework**
2501.13778v1 by Yoonsang Kim, Zainab Aamir, Mithilesh Singh, Saeed Boorboor, Klaus Mueller, Arie E. Kaufman

We present Explainable XR, an end-to-end framework for analyzing user
behavior in diverse eXtended Reality (XR) environments by leveraging Large
Language Models (LLMs) for data interpretation assistance. Existing XR user
analytics frameworks face challenges in handling cross-virtuality - AR, VR, MR
- transitions, multi-user collaborative application scenarios, and the
complexity of multimodal data. Explainable XR addresses these challenges by
providing a virtuality-agnostic solution for the collection, analysis, and
visualization of immersive sessions. We propose three main components in our
framework: (1) A novel user data recording schema, called User Action
Descriptor (UAD), that can capture the users' multimodal actions, along with
their intents and the contexts; (2) a platform-agnostic XR session recorder,
and (3) a visual analytics interface that offers LLM-assisted insights tailored
to the analysts' perspectives, facilitating the exploration and analysis of the
recorded XR session data. We demonstrate the versatility of Explainable XR by
demonstrating five use-case scenarios, in both individual and collaborative XR
applications across virtualities. Our technical evaluation and user studies
show that Explainable XR provides a highly usable analytics solution for
understanding user actions and delivering multifaceted, actionable insights
into user behaviors in immersive environments.

摘要：<paragraph>我們提出 Explainable XR，這是一個端對端架構，用於分析使用者在各種擴增實境 (XR) 環境中的行為，方法是利用大型語言模型 (LLM) 來協助資料解讀。現有的 XR 使用者分析架構在處理跨虛擬化時會遇到挑戰，例如 AR、VR、MR 轉換、多使用者協作應用程式場景，以及多模態資料的複雜性。Explainable XR 透過提供一個與虛擬化無關的解決方案來收集、分析和視覺化沉浸式會話，進而解決這些挑戰。我們在架構中提出三個主要元件：(1) 一種稱為使用者動作描述符 (UAD) 的創新使用者資料記錄架構，可以擷取使用者的多模態動作，以及他們的意圖和脈絡；(2) 一個與平台無關的 XR 會話記錄器，以及 (3) 一個視覺分析介面，提供針對分析師觀點量身打造的 LLM 協助見解，協助探索和分析記錄的 XR 會話資料。我們透過展示五種使用案例情境，在跨虛擬化的個人和協作式 XR 應用程式中，來展示 Explainable XR 的多功能性。我們的技術評估和使用者研究顯示，Explainable XR 提供了一個高度可用的分析解決方案，用於了解使用者動作，並提供多面向且可操作的見解，以了解沉浸式環境中的使用者行為。</paragraph>

##### **Do Large Language Models Truly Understand Geometric Structures?**
2501.13773v1 by Xiaofeng Wang, Yiming Wang, Wenhong Zhu, Rui Wang

Geometric ability is a significant challenge for large language models (LLMs)
due to the need for advanced spatial comprehension and abstract thinking.
Existing datasets primarily evaluate LLMs on their final answers, but they
cannot truly measure their true understanding of geometric structures, as LLMs
can arrive at correct answers by coincidence. To fill this gap, we introduce
the GeomRel dataset, designed to evaluate LLMs' understanding of geometric
structures by isolating the core step of geometric relationship identification
in problem-solving. Using this benchmark, we conduct thorough evaluations of
diverse LLMs and identify key limitations in understanding geometric
structures. We further propose the Geometry Chain-of-Thought (GeoCoT) method,
which enhances LLMs' ability to identify geometric relationships, resulting in
significant performance improvements.

摘要：幾何能力對於大型語言模型 (LLM) 來說是一項重大的挑戰，因為需要進階的空間理解和抽象思考。現有的資料集主要根據 LLM 的最終答案來評估它們，但它們無法真正衡量 LLM 對幾何結構的真正理解，因為 LLM 可以透過巧合得出正確答案。為了填補這個缺口，我們引入了 GeomRel 資料集，旨在透過在問題解決中分離幾何關係識別的核心步驟來評估 LLM 對幾何結構的理解。使用此基準，我們對各種 LLM 進行了徹底的評估，並找出理解幾何結構的主要限制。我們進一步提出了幾何思考鏈 (GeoCoT) 方法，增強了 LLM 識別幾何關係的能力，從而顯著提升了效能。

##### **Tune In, Act Up: Exploring the Impact of Audio Modality-Specific Edits on Large Audio Language Models in Jailbreak**
2501.13772v1 by Erjia Xiao, Hao Cheng, Jing Shao, Jinhao Duan, Kaidi Xu, Le Yang, Jindong Gu, Renjing Xu

Large Language Models (LLMs) demonstrate remarkable zero-shot performance
across various natural language processing tasks. The integration of multimodal
encoders extends their capabilities, enabling the development of Multimodal
Large Language Models that process vision, audio, and text. However, these
capabilities also raise significant security concerns, as these models can be
manipulated to generate harmful or inappropriate content through jailbreak.
While extensive research explores the impact of modality-specific input edits
on text-based LLMs and Large Vision-Language Models in jailbreak, the effects
of audio-specific edits on Large Audio-Language Models (LALMs) remain
underexplored. Hence, this paper addresses this gap by investigating how
audio-specific edits influence LALMs inference regarding jailbreak. We
introduce the Audio Editing Toolbox (AET), which enables audio-modality edits
such as tone adjustment, word emphasis, and noise injection, and the Edited
Audio Datasets (EADs), a comprehensive audio jailbreak benchmark. We also
conduct extensive evaluations of state-of-the-art LALMs to assess their
robustness under different audio edits. This work lays the groundwork for
future explorations on audio-modality interactions in LALMs security.

摘要：大型語言模型 (LLM) 在各種自然語言處理任務中展現了非凡的零次學習表現。多模態編碼器的整合擴展了它們的能力，促成了處理視覺、音訊和文字的多模態大型語言模型的開發。然而，這些能力也引發了重大的安全性疑慮，因為這些模型可以透過越獄操縱來產生有害或不適當的內容。雖然廣泛的研究探索了特定於模態的輸入編輯對越獄中的基於文字的 LLM 和大型視覺語言模型的影響，但特定於音訊的編輯對大型音訊語言模型 (LALM) 的影響仍未充分探討。因此，本文透過探討特定於音訊的編輯如何影響 LALM 對越獄的推論來解決這個差距。我們引入了音訊編輯工具箱 (AET)，它支援音訊模態編輯，例如音調調整、字詞強調和雜訊注入，以及編輯過的音訊資料集 (EAD)，一個全面的音訊越獄基準。我們也對最先進的 LALM 進行廣泛的評估，以評估它們在不同音訊編輯下的穩健性。這項工作為未來探索 LALM 安全性中音訊模態互動奠定了基礎。

##### **UGMathBench: A Diverse and Dynamic Benchmark for Undergraduate-Level Mathematical Reasoning with Large Language Models**
2501.13766v1 by Xin Xu, Jiaxin Zhang, Tianhao Chen, Zitong Chao, Jishan Hu, Can Yang

Large Language Models (LLMs) have made significant strides in mathematical
reasoning, underscoring the need for a comprehensive and fair evaluation of
their capabilities. However, existing benchmarks often fall short, either
lacking extensive coverage of undergraduate-level mathematical problems or
probably suffering from test-set contamination. To address these issues, we
introduce UGMathBench, a diverse and dynamic benchmark specifically designed
for evaluating undergraduate-level mathematical reasoning with LLMs.
UGMathBench comprises 5,062 problems across 16 subjects and 111 topics,
featuring 10 distinct answer types. Each problem includes three randomized
versions, with additional versions planned for release as leading open-source
LLMs become saturated in UGMathBench. Furthermore, we propose two key metrics:
effective accuracy (EAcc), which measures the percentage of correctly solved
problems across all three versions, and reasoning gap ($\Delta$), which
assesses reasoning robustness by calculating the difference between the average
accuracy across all versions and EAcc. Our extensive evaluation of 23 leading
LLMs reveals that the highest EAcc achieved is 56.3\% by OpenAI-o1-mini, with
large $\Delta$ values observed across different models. This highlights the
need for future research aimed at developing "large reasoning models" with high
EAcc and $\Delta = 0$. We anticipate that the release of UGMathBench, along
with its detailed evaluation codes, will serve as a valuable resource to
advance the development of LLMs in solving mathematical problems.

摘要：大型語言模型 (LLM) 在數學推理方面取得了重大進展，這凸顯了對其能力進行全面且公平評估的需求。然而，現有的基準往往不夠，要么缺乏對大學程度數學問題的廣泛涵蓋，要么可能遭受測試集污染。為了解決這些問題，我們引入了 UGMathBench，這是一個專門設計用於評估 LLM 的大學程度數學推理的多樣化動態基準。UGMathBench 包含 16 個科目和 111 個主題的 5,062 個問題，具有 10 種不同的答案類型。每個問題包括三個隨機版本，並計劃隨著領先的開源 LLM 在 UGMathBench 中飽和而發布其他版本。此外，我們提出了兩個關鍵指標：有效準確率 (EAcc)，它衡量在所有三個版本中正確解決問題的百分比，以及推理差距（$\Delta$），它通過計算所有版本中的平均準確率和 EAcc 之間的差異來評估推理穩健性。我們對 23 個領先的 LLM 的廣泛評估表明，OpenAI-o1-mini 達到的最高 EAcc 為 56.3%，在不同的模型中觀察到較大的 $\Delta$ 值。這凸顯了未來研究的必要性，旨在開發具有高 EAcc 和 $\Delta = 0$ 的「大型推理模型」。我們預計 UGMathBench 的發布及其詳細的評估代碼將成為推進 LLM 在解決數學問題方面的發展的寶貴資源。

##### **2-Tier SimCSE: Elevating BERT for Robust Sentence Embeddings**
2501.13758v1 by Yumeng Wang, Ziran Zhou, Junjin Wang

Effective sentence embeddings that capture semantic nuances and generalize
well across diverse contexts are crucial for natural language processing tasks.
We address this challenge by applying SimCSE (Simple Contrastive Learning of
Sentence Embeddings) using contrastive learning to fine-tune the minBERT model
for sentiment analysis, semantic textual similarity (STS), and paraphrase
detection. Our contributions include experimenting with three different dropout
techniques, namely standard dropout, curriculum dropout, and adaptive dropout,
to tackle overfitting, proposing a novel 2-Tier SimCSE Fine-tuning Model that
combines both unsupervised and supervised SimCSE on STS task, and exploring
transfer learning potential for Paraphrase and SST tasks. Our findings
demonstrate the effectiveness of SimCSE, with the 2-Tier model achieving
superior performance on the STS task, with an average test score of 0.742
across all three downstream tasks. The results of error analysis reveals
challenges in handling complex sentiments and reliance on lexical overlap for
paraphrase detection, highlighting areas for future research. The ablation
study revealed that removing Adaptive Dropout in the Single-Task Unsupervised
SimCSE Model led to improved performance on the STS task, indicating
overfitting due to added parameters. Transfer learning from SimCSE models on
Paraphrase and SST tasks did not enhance performance, suggesting limited
transferability of knowledge from the STS task.

摘要：有效的句子嵌入可以捕捉语义细微差别，并在不同的语境中很好地概括，这对自然语言处理任务至关重要。
我们通过应用 SimCSE（句子嵌入的简单对比学习）来解决这一挑战，使用对比学习对 minBERT 模型进行微调，以进行情感分析、语义文本相似性 (STS) 和释义检测。我们的贡献包括尝试使用三种不同的 dropout 技术，即标准 dropout、课程 dropout 和自适应 dropout，以解决过度拟合问题，提出了一种新颖的 2 层 SimCSE 微调模型，该模型结合了 STS 任务中的无监督和有监督 SimCSE，并探索了释义和 SST 任务的迁移学习潜力。我们的研究结果证明了 SimCSE 的有效性，2 层模型在 STS 任务上取得了卓越的性能，在所有三个下游任务中的平均测试得分为 0.742。错误分析的结果揭示了在处理复杂情感和依赖词法重叠进行释义检测方面的挑战，突出了未来研究的领域。消融研究表明，在单任务无监督 SimCSE 模型中移除自适应 Dropout 会提高 STS 任务的性能，这表明由于添加了参数而导致过度拟合。从 SimCSE 模型到释义和 SST 任务的迁移学习并没有提高性能，这表明从 STS 任务中获取知识的可转移性有限。

##### **Solving the long-tailed distribution problem by exploiting the synergies and balance of different techniques**
2501.13756v1 by Ziheng Wang, Toni Lassila, Sharib Ali

In real-world data, long-tailed data distribution is common, making it
challenging for models trained on empirical risk minimisation to learn and
classify tail classes effectively. While many studies have sought to improve
long tail recognition by altering the data distribution in the feature space
and adjusting model decision boundaries, research on the synergy and corrective
approach among various methods is limited. Our study delves into three
long-tail recognition techniques: Supervised Contrastive Learning (SCL),
Rare-Class Sample Generator (RSG), and Label-Distribution-Aware Margin Loss
(LDAM). SCL enhances intra-class clusters based on feature similarity and
promotes clear inter-class separability but tends to favour dominant classes
only. When RSG is integrated into the model, we observed that the intra-class
features further cluster towards the class centre, which demonstrates a
synergistic effect together with SCL's principle of enhancing intra-class
clustering. RSG generates new tail features and compensates for the tail
feature space squeezed by SCL. Similarly, LDAM is known to introduce a larger
margin specifically for tail classes; we demonstrate that LDAM further bolsters
the model's performance on tail classes when combined with the more explicit
decision boundaries achieved by SCL and RSG. Furthermore, SCL can compensate
for the dominant class accuracy sacrificed by RSG and LDAM. Our research
emphasises the synergy and balance among the three techniques, with each
amplifying the strengths of the others and mitigating their shortcomings. Our
experiment on long-tailed distribution datasets, using an end-to-end
architecture, yields competitive results by enhancing tail class accuracy
without compromising dominant class performance, achieving a balanced
improvement across all classes.

摘要：在真實世界的資料中，長尾資料分佈很常見，這使得在經驗風險最小化訓練的模型難以有效地學習和分類尾部類別。儘管許多研究試圖通過改變特徵空間中的資料分佈和調整模型決策邊界來改善長尾識別，但對各種方法之間的協同效應和糾正方法的研究卻很有限。我們的研究深入探討了三種長尾識別技術：監督對比學習 (SCL)、稀有類別樣本生成器 (RSG) 和標籤分佈感知邊界損失 (LDAM)。SCL 基於特徵相似性增強類內簇，並促進清晰的類間可分離性，但傾向於只偏好主導類別。當 RSG 集成到模型中時，我們觀察到類內特徵進一步向類中心聚集，這與 SCL 增強類內聚類的原理一起展示了協同效應。RSG 生成了新的尾部特徵，並彌補了被 SCL 壓縮的尾部特徵空間。類似地，已知 LDAM 專門為尾部類別引入了更大的邊界；我們證明，LDAM 在與 SCL 和 RSG 實現的更明確的決策邊界相結合時，進一步提升了模型在尾部類別上的效能。此外，SCL 可以彌補 RSG 和 LDAM 犧牲的主導類別準確性。我們的研究強調了這三種技術之間的協同效應和平衡，每種技術都放大了其他技術的優勢並減輕了它們的缺點。我們使用端到端架構對長尾分佈資料集進行的實驗，通過提高尾部類別準確性而不損害主導類別效能，在所有類別中實現了平衡的改進，從而產生了有競爭力的結果。

##### **EICopilot: Search and Explore Enterprise Information over Large-scale Knowledge Graphs with LLM-driven Agents**
2501.13746v1 by Yuhui Yun, Huilong Ye, Xinru Li, Ruojia Li, Jingfeng Deng, Li Li, Haoyi Xiong

The paper introduces EICopilot, an novel agent-based solution enhancing
search and exploration of enterprise registration data within extensive online
knowledge graphs like those detailing legal entities, registered capital, and
major shareholders. Traditional methods necessitate text-based queries and
manual subgraph explorations, often resulting in time-consuming processes.
EICopilot, deployed as a chatbot via Baidu Enterprise Search, improves this
landscape by utilizing Large Language Models (LLMs) to interpret natural
language queries. This solution automatically generates and executes Gremlin
scripts, providing efficient summaries of complex enterprise relationships.
Distinct feature a data pre-processing pipeline that compiles and annotates
representative queries into a vector database of examples for In-context
learning (ICL), a comprehensive reasoning pipeline combining Chain-of-Thought
with ICL to enhance Gremlin script generation for knowledge graph search and
exploration, and a novel query masking strategy that improves intent
recognition for heightened script accuracy. Empirical evaluations demonstrate
the superior performance of EICopilot, including speed and accuracy, over
baseline methods, with the \emph{Full Mask} variant achieving a syntax error
rate reduction to as low as 10.00% and an execution correctness of up to
82.14%. These components collectively contribute to superior querying
capabilities and summarization of intricate datasets, positioning EICopilot as
a groundbreaking tool in the exploration and exploitation of large-scale
knowledge graphs for enterprise information search.

摘要：本文介紹了 EICopilot，這是一種基於代理的新型解決方案，可增強在廣泛的線上知識圖譜中搜尋和探索企業註冊資料，例如詳細說明法律實體、註冊資本和主要股東的資料。傳統方法需要基於文字的查詢和手動子圖探索，通常會導致耗時的流程。EICopilot 部署為百度企業搜尋的聊天機器人，透過利用大型語言模型 (LLM) 來詮釋自然語言查詢，進而改善這項技術。此解決方案會自動產生並執行 Gremlin 腳本，提供複雜企業關係的有效摘要。其獨特功能為資料前處理管線，可將具代表性的查詢編譯並註解到範例的向量資料庫中，以進行脈絡中學習 (ICL)，這是一個結合了思考鏈與 ICL 的綜合推理管線，用於增強 Gremlin 腳本產生，以進行知識圖譜搜尋和探索，以及一種新穎的查詢遮罩策略，可改善意圖辨識，進而提高腳本準確度。實證評估顯示，EICopilot 的效能優於基線方法，包括速度和準確度，其中「完整遮罩」變體將語法錯誤率降低至低於 10.00%，執行正確率高達 82.14%。這些元件共同促成了優異的查詢功能和複雜資料集的摘要，將 EICopilot 定位為探索和利用大規模知識圖譜進行企業資訊搜尋的創新工具。

##### **A Study of the Plausibility of Attention between RNN Encoders in Natural Language Inference**
2501.13735v1 by Duc Hau Nguyen, Duc Hau Nguyen, Pascale Sébillot

Attention maps in neural models for NLP are appealing to explain the decision
made by a model, hopefully emphasizing words that justify the decision. While
many empirical studies hint that attention maps can provide such justification
from the analysis of sound examples, only a few assess the plausibility of
explanations based on attention maps, i.e., the usefulness of attention maps
for humans to understand the decision. These studies furthermore focus on text
classification. In this paper, we report on a preliminary assessment of
attention maps in a sentence comparison task, namely natural language
inference. We compare the cross-attention weights between two RNN encoders with
human-based and heuristic-based annotations on the eSNLI corpus. We show that
the heuristic reasonably correlates with human annotations and can thus
facilitate evaluation of plausible explanations in sentence comparison tasks.
Raw attention weights however remain only loosely related to a plausible
explanation.

摘要：神經網路語言模型中的注意力圖可以用來解釋模型做出的決策，希望強調用來證明決策的詞彙。雖然許多實證研究暗示注意力圖可以提供這種證明，但只有少數研究評估基於注意力圖的解釋的合理性，也就是說，注意力圖對人類理解決策的效用。這些研究進一步關注於文字分類。在本文中，我們報告了在句子比較任務（即自然語言推論）中對注意力圖的初步評估。我們將兩個 RNN 編碼器之間的交叉注意力權重與人類標註和 eSNLI 語料庫上的啟發式標註進行比較。我們表明啟發式與人類標註合理相關，因此可以促進句子比較任務中合理解釋的評估。然而，原始注意力權重仍然只與合理的解釋鬆散相關。

##### **Pseudocode-Injection Magic: Enabling LLMs to Tackle Graph Computational Tasks**
2501.13731v1 by Chang Gong, Wanrui Bian, Zhijie Zhang, Weiguo Zheng

Graph computational tasks are inherently challenging and often demand the
development of advanced algorithms for effective solutions. With the emergence
of large language models (LLMs), researchers have begun investigating their
potential to address these tasks. However, existing approaches are constrained
by LLMs' limited capability to comprehend complex graph structures and their
high inference costs, rendering them impractical for handling large-scale
graphs. Inspired by human approaches to graph problems, we introduce a novel
framework, PIE (Pseudocode-Injection-Enhanced LLM Reasoning for Graph
Computational Tasks), which consists of three key steps: problem understanding,
prompt design, and code generation. In this framework, LLMs are tasked with
understanding the problem and extracting relevant information to generate
correct code. The responsibility for analyzing the graph structure and
executing the code is delegated to the interpreter. We inject task-related
pseudocodes into the prompts to further assist the LLMs in generating efficient
code. We also employ cost-effective trial-and-error techniques to ensure that
the LLM-generated code executes correctly. Unlike other methods that require
invoking LLMs for each individual test case, PIE only calls the LLM during the
code generation phase, allowing the generated code to be reused and
significantly reducing inference costs. Extensive experiments demonstrate that
PIE outperforms existing baselines in terms of both accuracy and computational
efficiency.

摘要：圖表計算任務本質上具有挑戰性，而且通常需要開發先進的演算法才能有效解決。隨著大型語言模型 (LLM) 的出現，研究人員已開始探討其解決這些任務的可能性。然而，現有方法受到 LLM 理解複雜圖形結構的能力有限以及其高推理成本的限制，這使得它們不切實際地處理大規模圖形。受到人類解決圖形問題的方法啟發，我們引入了 PIE（偽代碼注入增強 LLM 圖形計算任務推理）這個新框架，它包含三個關鍵步驟：問題理解、提示設計和代碼生成。在此框架中，LLM 的任務是理解問題並擷取相關資訊以產生正確的代碼。分析圖形結構和執行代碼的責任委派給解釋器。我們將與任務相關的偽代碼注入提示中，以進一步協助 LLM 產生有效的代碼。我們還採用具有成本效益的試錯技術，以確保 LLM 生成的代碼正確執行。與需要為每個個別測試案例呼叫 LLM 的其他方法不同，PIE 僅在代碼產生階段呼叫 LLM，允許重複使用產生的代碼並大幅降低推理成本。大量的實驗證明，PIE 在準確性和計算效率方面都優於現有的基準。

##### **RPO: Retrieval Preference Optimization for Robust Retrieval-Augmented Generation**
2501.13726v1 by Shi-Qi Yan, Zhen-Hua Ling

While Retrieval-Augmented Generation (RAG) has exhibited promise in utilizing
external knowledge, its generation process heavily depends on the quality and
accuracy of the retrieved context. Large language models (LLMs) struggle to
evaluate the correctness of non-parametric knowledge retrieved externally when
it differs from internal memorization, leading to knowledge conflicts during
response generation. To this end, we introduce the Retrieval Preference
Optimization (RPO), a lightweight and effective alignment method to adaptively
leverage multi-source knowledge based on retrieval relevance. An implicit
representation of retrieval relevance is derived and incorporated into the
reward model to integrate retrieval evaluation and response generation into a
single model, solving the problem that previous methods necessitate the
additional procedure to assess the retrieval quality. Notably, RPO is the only
RAG-dedicated alignment approach that quantifies the awareness of retrieval
relevance in training, overcoming mathematical obstacles. Experiments on four
datasets demonstrate that RPO outperforms RAG by 4-10% in accuracy without any
extra component, exhibiting its robust generalization.

摘要：檢索增強生成（RAG）雖然在利用外部知識方面表現出前景，但其生成過程嚴重依賴於檢索語境的品質和準確性。大型語言模型（LLM）在評估外部檢索的非參數知識的正確性時會遇到困難，特別是在其與內部記憶不同時，這會在回應生成期間導致知識衝突。為此，我們引入了檢索偏好最佳化（RPO），這是一種輕量且有效的比對方法，可根據檢索相關性自適應地利用多來源知識。我們衍生了一個檢索相關性的隱含表徵，並將其納入獎勵模型，以將檢索評估和回應生成整合到一個模型中，解決了先前方法需要額外程序來評估檢索品質的問題。值得注意的是，RPO 是唯一量化訓練中檢索相關性認知的 RAG 專用比對方法，克服了數學障礙。在四個資料集上的實驗表明，RPO 在準確性上比 RAG 高出 4-10%，且無任何額外元件，展現出其穩健的泛化性。

##### **You Only Crash Once v2: Perceptually Consistent Strong Features for One-Stage Domain Adaptive Detection of Space Terrain**
2501.13725v1 by Timothy Chase Jr, Christopher Wilson, Karthik Dantu

The in-situ detection of planetary, lunar, and small-body surface terrain is
crucial for autonomous spacecraft applications, where learning-based computer
vision methods are increasingly employed to enable intelligence without prior
information or human intervention. However, many of these methods remain
computationally expensive for spacecraft processors and prevent real-time
operation. Training of such algorithms is additionally complex due to the
scarcity of labeled data and reliance on supervised learning approaches.
Unsupervised Domain Adaptation (UDA) offers a promising solution by
facilitating model training with disparate data sources such as simulations or
synthetic scenes, although UDA is difficult to apply to celestial environments
where challenging feature spaces are paramount. To alleviate such issues, You
Only Crash Once (YOCOv1) has studied the integration of Visual Similarity-based
Alignment (VSA) into lightweight one-stage object detection architectures to
improve space terrain UDA. Although proven effective, the approach faces
notable limitations, including performance degradations in multi-class and
high-altitude scenarios. Building upon the foundation of YOCOv1, we propose
novel additions to the VSA scheme that enhance terrain detection capabilities
under UDA, and our approach is evaluated across both simulated and real-world
data. Our second YOCO rendition, YOCOv2, is capable of achieving
state-of-the-art UDA performance on surface terrain detection, where we
showcase improvements upwards of 31% compared with YOCOv1 and terrestrial
state-of-the-art. We demonstrate the practical utility of YOCOv2 with
spacecraft flight hardware performance benchmarking and qualitative evaluation
of NASA mission data.

摘要：行星、月球和小天體表面地形的原位探測對於自主太空船應用至關重要，其中基於學習的電腦視覺方法正日益廣泛地用於在沒有先驗資訊或人工干預的情況下實現智慧。然而，其中許多方法對於太空船處理器而言仍然計算成本高昂，且無法進行即時操作。由於標記資料的稀缺性和對監督式學習方法的依賴性，此類演算法的訓練也更加複雜。非監督域適應 (UDA) 提供了一個有前景的解決方案，它促進了使用不同資料來源（例如模擬或合成場景）進行模型訓練，儘管 UDA 難以應用於以具有挑戰性的特徵空間為主的星體環境。為了緩解此類問題，您只崩潰一次 (YOCOv1) 研究了將基於視覺相似性的對齊 (VSA) 整合到輕量級一階段物件偵測架構中，以改善太空地形 UDA。儘管被證明有效，但該方法面臨顯著的限制，包括在多類和高海拔場景中的效能下降。在 YOCOv1 的基礎上，我們提出對 VSA 方案的新增功能，以增強 UDA 下的地形偵測能力，並且我們的做法已在模擬和真實世界資料中進行評估。我們的第二個 YOCO 版本 YOCOv2 能夠在表面地形偵測上實現最先進的 UDA 效能，與 YOCOv1 和陸地最先進技術相比，我們展示了高達 31% 的進步。我們透過太空船飛行硬體效能基準測試和 NASA 任務資料的定性評估，展示了 YOCOv2 的實用性。

##### **Musical ethnocentrism in Large Language Models**
2501.13720v1 by Anna Kruspe

Large Language Models (LLMs) reflect the biases in their training data and,
by extension, those of the people who created this training data. Detecting,
analyzing, and mitigating such biases is becoming a focus of research. One type
of bias that has been understudied so far are geocultural biases. Those can be
caused by an imbalance in the representation of different geographic regions
and cultures in the training data, but also by value judgments contained
therein. In this paper, we make a first step towards analyzing musical biases
in LLMs, particularly ChatGPT and Mixtral. We conduct two experiments. In the
first, we prompt LLMs to provide lists of the "Top 100" musical contributors of
various categories and analyze their countries of origin. In the second
experiment, we ask the LLMs to numerically rate various aspects of the musical
cultures of different countries. Our results indicate a strong preference of
the LLMs for Western music cultures in both experiments.

摘要：大型語言模型 (LLM) 反映其訓練資料中的偏見，進一步而言，也反映了建立這些訓練資料的人的偏見。偵測、分析和減輕此類偏見已成為研究重點。到目前為止，一種研究不足的偏見類型是地理文化偏見。這些偏見可能是由於訓練資料中不同地理區域和文化的代表性不平衡，也可能是由於其中包含的價值判斷所造成的。在本文中，我們邁出了分析 LLM 中音樂偏見的第一步，特別是 ChatGPT 和 Mixtral。我們進行了兩個實驗。在第一個實驗中，我們提示 LLM 提供各種類別的「前 100 名」音樂貢獻者清單，並分析其原籍國。在第二個實驗中，我們要求 LLM 對不同國家的音樂文化的各個方面進行數字評分。我們的結果表明，在兩個實驗中，LLM 都強烈偏好西方音樂文化。

##### **Skin Disease Detection and Classification of Actinic Keratosis and Psoriasis Utilizing Deep Transfer Learning**
2501.13713v1 by Fahud Ahmmed, Md. Zaheer Raihan, Kamnur Nahar, D. M. Asadujjaman, Md. Mahfujur Rahman, Abdullah Tamim

Skin diseases can arise from infections, allergies, genetic factors,
autoimmune disorders, hormonal imbalances, or environmental triggers such as
sun damage and pollution. Some skin diseases, such as Actinic Keratosis and
Psoriasis, can be fatal if not treated in time. Early identification is
crucial, but the diagnostic methods for these conditions are often expensive
and not widely accessible. In this study, we propose a novel and efficient
method for diagnosing skin diseases using deep learning techniques. This
approach employs a modified VGG16 Convolutional Neural Network (CNN) model. The
model includes several convolutional layers and utilizes ImageNet weights with
modified top layers. The top layer is updated with fully connected layers and a
final softmax activation layer to classify skin diseases. The dataset used,
titled "Skin Disease Dataset," is publicly available. While the VGG16
architecture does not include data augmentation by default, preprocessing
techniques such as rotation, shifting, and zooming were applied to augment the
data prior to model training. The proposed methodology achieved 90.67% accuracy
using the modified VGG16 model, demonstrating its reliability in classifying
skin diseases. The promising results highlight the potential of this approach
for real-world applications.

摘要：皮膚疾病可能源於感染、過敏、遺傳因素、
自體免疫疾病、荷爾蒙失衡或環境誘因，例如
陽光傷害和污染。某些皮膚疾病，例如光化性角化病和
牛皮癬，如果沒有及時治療，可能會致命。早期發現至關重要，但這些疾病的診斷方法通常很昂貴，而且無法廣泛使用。在本研究中，我們提出了一種新穎且有效的方法，使用深度學習技術診斷皮膚疾病。這種
方法採用了修改後的 VGG16 卷積神經網路 (CNN) 模型。該
模型包含多個卷積層，並利用具有修改後的頂層的 ImageNet 權重。頂層使用全連接層和最終 softmax 激活層進行更新，以對皮膚疾病進行分類。所使用的名為「皮膚疾病數據集」的數據集公開可用。雖然 VGG16
架構預設不包含數據擴充，但旋轉、平移和縮放等預處理
技術已應用於在模型訓練之前擴充數據。所提出的方法使用修改後的 VGG16 模型達到了 90.67% 的準確度，證明了其在對皮膚疾病進行分類方面的可靠性。這些有希望的結果突顯了這種方法在實際應用中的潛力。

##### **Formally Verified Neurosymbolic Trajectory Learning via Tensor-based Linear Temporal Logic on Finite Traces**
2501.13712v1 by Mark Chevallier, Filip Smola, Richard Schmoetten, Jacques D. Fleuriot

We present a novel formalisation of tensor semantics for linear temporal
logic on finite traces (LTLf), with formal proofs of correctness carried out in
the theorem prover Isabelle/HOL. We demonstrate that this formalisation can be
integrated into a neurosymbolic learning process by defining and verifying a
differentiable loss function for the LTLf constraints, and automatically
generating an implementation that integrates with PyTorch. We show that, by
using this loss, the process learns to satisfy pre-specified logical
constraints. Our approach offers a fully rigorous framework for constrained
training, eliminating many of the inherent risks of ad-hoc, manual
implementations of logical aspects directly in an "unsafe" programming language
such as Python, while retaining efficiency in implementation.

摘要：我們提出時序邏輯上張量語意的形式化新穎方法，針對有限軌跡（LTLf），並在定理證明器 Isabelle/HOL 中執行正確性形式證明。我們展示此形式化方法可整合至神經符號學習流程，方法是定義並驗證 LTLf 限制的微分損失函數，並自動產生與 PyTorch 整合的實作。我們顯示，透過使用此損失，此流程學習滿足預先指定的邏輯限制。我們的做法提供受限訓練的嚴格架構，消除許多直接在「不安全」的程式語言（例如 Python）中臨時、手動實作邏輯面向的固有風險，同時保留實作效率。

##### **YOLO11-JDE: Fast and Accurate Multi-Object Tracking with Self-Supervised Re-ID**
2501.13710v1 by Iñaki Erregue, Kamal Nasrollahi, Sergio Escalera

We introduce YOLO11-JDE, a fast and accurate multi-object tracking (MOT)
solution that combines real-time object detection with self-supervised
Re-Identification (Re-ID). By incorporating a dedicated Re-ID branch into
YOLO11s, our model performs Joint Detection and Embedding (JDE), generating
appearance features for each detection. The Re-ID branch is trained in a fully
self-supervised setting while simultaneously training for detection,
eliminating the need for costly identity-labeled datasets. The triplet loss,
with hard positive and semi-hard negative mining strategies, is used for
learning discriminative embeddings. Data association is enhanced with a custom
tracking implementation that successfully integrates motion, appearance, and
location cues. YOLO11-JDE achieves competitive results on MOT17 and MOT20
benchmarks, surpassing existing JDE methods in terms of FPS and using up to ten
times fewer parameters. Thus, making our method a highly attractive solution
for real-world applications.

摘要：我們引入了 YOLO11-JDE，這是一種快速且準確的多目標追蹤 (MOT) 解决方案，它結合了即時物件偵測與自我監督的重新辨識 (Re-ID)。透過將專用的 Re-ID 分支整合到 YOLO11s，我們的模型執行聯合偵測和嵌入 (JDE)，為每個偵測產生外觀特徵。Re-ID 分支在完全自我監督的設定中訓練，同時訓練偵測，消除了對昂貴身分標籤資料集的需求。三重損失，採用硬正例和半硬負例挖掘策略，用於學習判別式嵌入。資料關聯透過自訂追蹤實作增強，該實作成功整合了動作、外觀和位置線索。YOLO11-JDE 在 MOT17 和 MOT20 基準上取得了具有競爭力的結果，在 FPS 方面超越了現有的 JDE 方法，並且使用的參數減少了多達十倍。因此，使我們的模型成為現實世界應用中極具吸引力的解決方案。

##### **EventVL: Understand Event Streams via Multimodal Large Language Model**
2501.13707v1 by Pengteng Li, Yunfan Lu, Pinghao Song, Wuyang Li, Huizai Yao, Hui Xiong

The event-based Vision-Language Model (VLM) recently has made good progress
for practical vision tasks. However, most of these works just utilize CLIP for
focusing on traditional perception tasks, which obstruct model understanding
explicitly the sufficient semantics and context from event streams. To address
the deficiency, we propose EventVL, the first generative event-based MLLM
(Multimodal Large Language Model) framework for explicit semantic
understanding. Specifically, to bridge the data gap for connecting different
modalities semantics, we first annotate a large event-image/video-text dataset,
containing almost 1.4 million high-quality pairs of data, which enables
effective learning across various scenes, e.g., drive scene or human motion.
After that, we design Event Spatiotemporal Representation to fully explore the
comprehensive information by diversely aggregating and segmenting the event
stream. To further promote a compact semantic space, Dynamic Semantic Alignment
is introduced to improve and complete sparse semantic spaces of events.
Extensive experiments show that our EventVL can significantly surpass existing
MLLM baselines in event captioning and scene description generation tasks. We
hope our research could contribute to the development of the event vision
community.

摘要：<paragraph>基於事件的視覺語言模型 (VLM) 最近在實務視覺任務上取得良好的進展。然而，這些作品大多僅利用 CLIP 專注於傳統的感知任務，這阻礙了模型明確理解事件串流中的足夠語意和背景。為了解決這個缺陷，我們提出了 EventVL，這是第一個用於明確語意理解的生成式基於事件的 MLLM（多模態大型語言模型）架構。具體來說，為了彌合連接不同模態語意的資料差距，我們首先標註一個大型事件影像/影片文字資料集，其中包含將近 140 萬對高品質資料，這使得跨各種場景（例如駕駛場景或人類動作）的有效學習成為可能。在那之後，我們設計了事件時空表示，藉由多樣化地彙總和分割事件串流，來充分探索綜合資訊。為了進一步促進一個緊湊的語意空間，引入了動態語意對齊，以改善和完成事件的稀疏語意空間。廣泛的實驗顯示，我們的 EventVL 能在事件字幕和場景描述產生任務中，顯著超越現有的 MLLM 基準。我們希望我們的研究能為事件視覺社群的發展做出貢獻。</paragraph>

##### **DI-BENCH: Benchmarking Large Language Models on Dependency Inference with Testable Repositories at Scale**
2501.13699v1 by Linghao Zhang, Junhao Wang, Shilin He, Chaoyun Zhang, Yu Kang, Bowen Li, Jiaheng Wen, Chengxing Xie, Maoquan Wang, Yufan Huang, Elsie Nallipogu, Qingwei Lin, Yingnong Dang, Saravan Rajmohan, Dongmei Zhang, Qi Zhang

Large Language Models have advanced automated software development, however,
it remains a challenge to correctly infer dependencies, namely, identifying the
internal components and external packages required for a repository to
successfully run. Existing studies highlight that dependency-related issues
cause over 40\% of observed runtime errors on the generated repository. To
address this, we introduce DI-BENCH, a large-scale benchmark and evaluation
framework specifically designed to assess LLMs' capability on dependency
inference. The benchmark features 581 repositories with testing environments
across Python, C#, Rust, and JavaScript. Extensive experiments with textual and
execution-based metrics reveal that the current best-performing model achieves
only a 42.9% execution pass rate, indicating significant room for improvement.
DI-BENCH establishes a new viewpoint for evaluating LLM performance on
repositories, paving the way for more robust end-to-end software synthesis.

摘要：大型語言模型已推動自動化軟體開發，然而，正確推斷依賴關係，也就是識別儲存庫成功執行所需的內部元件和外部套件，仍然是一項挑戰。現有研究強調與依賴關係相關的問題導致在生成的儲存庫中觀察到的執行時間錯誤超過 40%。為了解決此問題，我們引入了 DI-BENCH，一個專門設計來評估 LLM 在依賴關係推斷能力上的大型基準測試和評估架構。此基準測試包含 581 個儲存庫，測試環境涵蓋 Python、C#、Rust 和 JavaScript。使用文字和基於執行的指標進行的廣泛實驗顯示，目前效能最佳的模型僅達到 42.9% 的執行通過率，表示有顯著的改進空間。DI-BENCH 為評估 LLM 在儲存庫上的效能建立了一個新的觀點，為更強大的端到端軟體合成鋪路。

##### **Training-Free Consistency Pipeline for Fashion Repose**
2501.13692v1 by Potito Aghilar, Vito Walter Anelli, Michelantonio Trizio, Tommaso Di Noia

Recent advancements in diffusion models have significantly broadened the
possibilities for editing images of real-world objects. However, performing
non-rigid transformations, such as changing the pose of objects or image-based
conditioning, remains challenging. Maintaining object identity during these
edits is difficult, and current methods often fall short of the precision
needed for industrial applications, where consistency is critical.
Additionally, fine-tuning diffusion models requires custom training data, which
is not always accessible in real-world scenarios. This work introduces
FashionRepose, a training-free pipeline for non-rigid pose editing specifically
designed for the fashion industry. The approach integrates off-the-shelf models
to adjust poses of long-sleeve garments, maintaining identity and branding
attributes. FashionRepose uses a zero-shot approach to perform these edits in
near real-time, eliminating the need for specialized training. consistent image
editing. The solution holds potential for applications in the fashion industry
and other fields demanding identity preservation in image editing.

摘要：最近在擴散模型方面的進展顯著拓寬了編輯真實世界物體圖像的可能性。然而，執行非剛性轉換（例如更改物體的姿勢或基於圖像的條件）仍然具有挑戰性。在這些編輯過程中維護物體身分很困難，而且目前的技術通常無法達到產業應用所需的精確度，而一致性在產業應用中至關重要。此外，微調擴散模型需要自訂訓練資料，這在真實世界的場景中並不總是可取得的。這項工作介紹了 FashionRepose，一種專門為時尚產業設計的非剛性姿勢編輯免訓練管道。這種方法整合了現成的模型來調整長袖服裝的姿勢，同時維持身分和品牌屬性。FashionRepose 使用零次學習方法來執行這些編輯，幾乎可以即時完成，無需進行專業訓練。一致的圖像編輯。此解決方案在時尚產業和其他需要在圖像編輯中保留身分的領域具有應用潛力。

##### **Question Answering on Patient Medical Records with Private Fine-Tuned LLMs**
2501.13687v1 by Sara Kothari, Ayush Gupta

Healthcare systems continuously generate vast amounts of electronic health
records (EHRs), commonly stored in the Fast Healthcare Interoperability
Resources (FHIR) standard. Despite the wealth of information in these records,
their complexity and volume make it difficult for users to retrieve and
interpret crucial health insights. Recent advances in Large Language Models
(LLMs) offer a solution, enabling semantic question answering (QA) over medical
data, allowing users to interact with their health records more effectively.
However, ensuring privacy and compliance requires edge and private deployments
of LLMs.
  This paper proposes a novel approach to semantic QA over EHRs by first
identifying the most relevant FHIR resources for a user query (Task1) and
subsequently answering the query based on these resources (Task2). We explore
the performance of privately hosted, fine-tuned LLMs, evaluating them against
benchmark models such as GPT-4 and GPT-4o. Our results demonstrate that
fine-tuned LLMs, while 250x smaller in size, outperform GPT-4 family models by
0.55% in F1 score on Task1 and 42% on Meteor Task in Task2. Additionally, we
examine advanced aspects of LLM usage, including sequential fine-tuning, model
self-evaluation (narcissistic evaluation), and the impact of training data size
on performance. The models and datasets are available here:
https://huggingface.co/genloop

摘要：醫療保健系統持續產生大量的電子健康紀錄 (EHR)，通常儲存在快速醫療互通性資源 (FHIR) 標準中。儘管這些紀錄中包含豐富的資訊，但其複雜性和龐大數量讓使用者難以擷取和詮釋重要的健康見解。大型語言模型 (LLM) 的最新進展提供了解決方案，能對醫療資料進行語義問答 (QA)，讓使用者能更有效地與其健康紀錄互動。然而，確保隱私和相容性需要 LLM 的邊緣和私人部署。本文提出了語義問答的新方法，先找出與使用者查詢最相關的 FHIR 資源 (任務 1)，然後根據這些資源回答查詢 (任務 2)。我們探討了私人主機、微調 LLM 的效能，並根據 GPT-4 和 GPT-4o 等基準模型評估它們。我們的結果顯示，微調 LLM 的大小雖然小 250 倍，但在任務 1 的 F1 分數上優於 GPT-4 系列模型 0.55%，在任務 2 的 Meteor 任務中優於 42%。此外，我們探討了 LLM 使用的高階面向，包括循序微調、模型自我評估（自戀式評估）和訓練資料大小對效能的影響。模型和資料集在此處提供：https://huggingface.co/genloop

##### **Unlearning Clients, Features and Samples in Vertical Federated Learning**
2501.13683v1 by Ayush K. Varshney, Konstantinos Vandikas, Vicenç Torra

Federated Learning (FL) has emerged as a prominent distributed learning
paradigm. Within the scope of privacy preservation, information privacy
regulations such as GDPR entitle users to request the removal (or unlearning)
of their contribution from a service that is hosting the model. For this
purpose, a server hosting an ML model must be able to unlearn certain
information in cases such as copyright infringement or security issues that can
make the model vulnerable or impact the performance of a service based on that
model. While most unlearning approaches in FL focus on Horizontal FL (HFL),
where clients share the feature space and the global model, Vertical FL (VFL)
has received less attention from the research community. VFL involves clients
(passive parties) sharing the sample space among them while not having access
to the labels. In this paper, we explore unlearning in VFL from three
perspectives: unlearning clients, unlearning features, and unlearning samples.
To unlearn clients and features we introduce VFU-KD which is based on knowledge
distillation (KD) while to unlearn samples, VFU-GA is introduced which is based
on gradient ascent. To provide evidence of approximate unlearning, we utilize
Membership Inference Attack (MIA) to audit the effectiveness of our unlearning
approach. Our experiments across six tabular datasets and two image datasets
demonstrate that VFU-KD and VFU-GA achieve performance comparable to or better
than both retraining from scratch and the benchmark R2S method in many cases,
with improvements of $(0-2\%)$. In the remaining cases, utility scores remain
comparable, with a modest utility loss ranging from $1-5\%$. Unlike existing
methods, VFU-KD and VFU-GA require no communication between active and passive
parties during unlearning. However, they do require the active party to store
the previously communicated embeddings.

摘要：<paragraph>联邦学习 (FL) 已成为一种突出的分布式学习范例。在隐私保护范围内，信息隐私法规（如 GDPR）赋予用户要求从托管模型的服务中移除（或取消学习）其贡献的权利。为此，托管 ML 模型的服务器必须能够在某些情况下取消学习特定信息，例如版权侵权或安全问题，这些问题可能使模型容易受到攻击或影响基于该模型的服务的性能。虽然 FL 中的大多数取消学习方法都集中在水平 FL (HFL) 上，其中客户端共享特征空间和全局模型，但垂直 FL (VFL) 却较少受到研究界的关注。VFL 涉及客户端（被动方）在他们之间共享样本空间，同时无法访问标签。在本文中，我们从三个角度探索 VFL 中的取消学习：取消学习客户端、取消学习特征和取消学习样本。为了取消学习客户端和特征，我们引入了基于知识蒸馏 (KD) 的 VFU-KD，而为了取消学习样本，我们引入了基于梯度上升的 VFU-GA。为了提供近似取消学习的证据，我们利用成员资格推理攻击 (MIA) 来审计我们取消学习方法的有效性。我们在六个表格数据集和两个图像数据集上的实验表明，在许多情况下，VFU-KD 和 VFU-GA 实现的性能与从头开始重新训练和基准 R2S 方法相当或更好，改进了 $(0-2\%)。在其余情况下，效用得分仍然相当，效用损失适中，范围从 $1-5\%$。与现有方法不同，VFU-KD 和 VFU-GA 在取消学习期间不需要主动方和被动方之间的通信。但是，它们确实要求主动方存储以前传达的嵌入。</paragraph>

##### **Certified Robustness Under Bounded Levenshtein Distance**
2501.13676v1 by Elias Abad Rocamora, Grigorios G. Chrysos, Volkan Cevher

Text classifiers suffer from small perturbations, that if chosen
adversarially, can dramatically change the output of the model. Verification
methods can provide robustness certificates against such adversarial
perturbations, by computing a sound lower bound on the robust accuracy.
Nevertheless, existing verification methods incur in prohibitive costs and
cannot practically handle Levenshtein distance constraints. We propose the
first method for computing the Lipschitz constant of convolutional classifiers
with respect to the Levenshtein distance. We use these Lipschitz constant
estimates for training 1-Lipschitz classifiers. This enables computing the
certified radius of a classifier in a single forward pass. Our method, LipsLev,
is able to obtain $38.80$% and $13.93$% verified accuracy at distance $1$ and
$2$ respectively in the AG-News dataset, while being $4$ orders of magnitude
faster than existing approaches. We believe our work can open the door to more
efficient verification in the text domain.

摘要：文字分類器會受到小擾動的影響，如果選擇對抗性擾動，可能會大幅改變模型的輸出。驗證方法可以透過計算穩健精確度的下限，提供針對此類對抗性擾動的穩健性證明。儘管如此，現有的驗證方法會產生高昂的成本，且實際上無法處理 Levenshtein 距離限制。我們提出第一個用於計算卷積分類器對 Levenshtein 距離的 Lipschitz 常數的方法。我們使用這些 Lipschitz 常數估計值來訓練 1-Lipschitz 分類器。這能夠在單次前向傳遞中計算分類器的認證半徑。我們的 LipsLev 方法能夠在 AG-News 資料集中分別在距離 1 和 2 獲得 $38.80$% 和 $13.93$% 的驗證精確度，同時比現有方法快 4 個數量級。我們相信我們的研究成果可以為文字領域中更有效的驗證打開大門。

##### **How to Complete Domain Tuning while Keeping General Ability in LLM: Adaptive Layer-wise and Element-wise Regularization**
2501.13669v1 by Shezheng Song, Hao Xu, Jun Ma, Shasha Li, Long Peng, Qian Wan, Xiaodong Liu, Jie Yu

Large Language Models (LLMs) exhibit strong general-purpose language
capabilities. However, fine-tuning these models on domain-specific tasks often
leads to catastrophic forgetting, where the model overwrites or loses essential
knowledge acquired during pretraining. This phenomenon significantly limits the
broader applicability of LLMs. To address this challenge, we propose a novel
approach to compute the element-wise importance of model parameters crucial for
preserving general knowledge during fine-tuning. Our method utilizes a
dual-objective optimization strategy: (1) regularization loss to retain the
parameter crucial for general knowledge; (2) cross-entropy loss to adapt to
domain-specific tasks. Additionally, we introduce layer-wise coefficients to
account for the varying contributions of different layers, dynamically
balancing the dual-objective optimization. Extensive experiments on scientific,
medical, and physical tasks using GPT-J and LLaMA-3 demonstrate that our
approach mitigates catastrophic forgetting while enhancing model adaptability.
Compared to previous methods, our solution is approximately 20 times faster and
requires only 10%-15% of the storage, highlighting the practical efficiency.
The code will be released.

摘要：大型語言模型 (LLM) 展現強大的通用語言能力。然而，針對特定領域任務微調這些模型時，常常會導致災難性遺忘，模型會覆寫或遺失預訓練期間習得的基本知識。這種現象大幅限制了 LLM 的廣泛適用性。為了應對這項挑戰，我們提出了一種新穎方法，用於計算模型參數的元素級重要性，這些參數對於在微調期間保留一般知識至關重要。我們的做法採用雙目標優化策略：(1) 正則化損失，用於保留對一般知識至關重要的參數；(2) 交叉熵損失，用於適應特定領域的任務。此外，我們引入了層級係數，用於考量不同層的變異貢獻，並動態平衡雙目標優化。使用 GPT-J 和 LLaMA-3 在科學、醫療和物理任務上進行的廣泛實驗證明，我們的做法減輕了災難性遺忘，同時增強了模型適應性。與之前的做法相比，我們的解決方案速度快了約 20 倍，而且只需要 10%-15% 的儲存空間，突顯了其實用的效率。程式碼將會釋出。

##### **LVPruning: An Effective yet Simple Language-Guided Vision Token Pruning Approach for Multi-modal Large Language Models**
2501.13652v1 by Yizheng Sun, Yanze Xin, Hao Li, Jingyuan Sun, Chenghua Lin, Riza Batista-Navarro

Multi-modal Large Language Models (MLLMs) have achieved remarkable success by
integrating visual and textual modalities. However, they incur significant
computational overhead due to the large number of vision tokens processed,
limiting their practicality in resource-constrained environments. We introduce
Language-Guided Vision Token Pruning (LVPruning) for MLLMs, an effective yet
simple method that significantly reduces the computational burden while
preserving model performance. LVPruning employs cross-attention modules to
compute the importance of vision tokens based on their interaction with
language tokens, determining which to prune. Importantly, LVPruning can be
integrated without modifying the original MLLM parameters, which makes
LVPruning simple to apply or remove. Our experiments show that LVPruning can
effectively reduce up to 90% of vision tokens by the middle layer of LLaVA-1.5,
resulting in a 62.1% decrease in inference Tera Floating-Point Operations Per
Second (TFLOPs), with an average performance loss of just 0.45% across nine
multi-modal benchmarks.

摘要：多模态大型语言模型 (MLLM) 透过整合视觉和文本模态，已取得显著的成功。然而，由于处理大量视觉标记，它们会产生大量的计算开销，限制了它们在资源受限环境中的实用性。我们针对 MLLM 引入了语言引导视觉标记修剪 (LVPruning)，这是一种有效且简单的方法，可以在保留模型性能的同时大幅减少计算负担。LVPruning 使用交叉注意力模块，根据视觉标记与语言标记的交互作用计算视觉标记的重要性，以确定要修剪哪些标记。重要的是，LVPruning 可以在不修改原始 MLLM 参数的情况下进行整合，这使得 LVPruning 易于应用或移除。我们的实验表明，LVPruning 可以有效地将 LLaVA-1.5 中层多达 90% 的视觉标记减少，从而使每秒推理浮点运算 (TFLOPs) 减少 62.1%，在九个多模态基准测试中，平均性能损失仅为 0.45%。

##### **Sigma: Differential Rescaling of Query, Key and Value for Efficient Language Models**
2501.13629v1 by Zhenghao Lin, Zihao Tang, Xiao Liu, Yeyun Gong, Yi Cheng, Qi Chen, Hang Li, Ying Xin, Ziyue Yang, Kailai Yang, Yu Yan, Xiao Liang, Shuai Lu, Yiming Huang, Zheheng Luo, Lei Qu, Xuan Feng, Yaoxiang Wang, Yuqing Xia, Feiyang Chen, Yuting Jiang, Yasen Hu, Hao Ni, Binyang Li, Guoshuai Zhao, Jui-Hao Chiang, Zhongxin Guo, Chen Lin, Kun Kuang, Wenjie Li, Yelong Shen, Jian Jiao, Peng Cheng, Mao Yang

We introduce Sigma, an efficient large language model specialized for the
system domain, empowered by a novel architecture including DiffQKV attention,
and pre-trained on our meticulously collected system domain data. DiffQKV
attention significantly enhances the inference efficiency of Sigma by
optimizing the Query (Q), Key (K), and Value (V) components in the attention
mechanism differentially, based on their varying impacts on the model
performance and efficiency indicators. Specifically, we (1) conduct extensive
experiments that demonstrate the model's varying sensitivity to the compression
of K and V components, leading to the development of differentially compressed
KV, and (2) propose augmented Q to expand the Q head dimension, which enhances
the model's representation capacity with minimal impacts on the inference
speed. Rigorous theoretical and empirical analyses reveal that DiffQKV
attention significantly enhances efficiency, achieving up to a 33.36%
improvement in inference speed over the conventional grouped-query attention
(GQA) in long-context scenarios. We pre-train Sigma on 6T tokens from various
sources, including 19.5B system domain data that we carefully collect and 1T
tokens of synthesized and rewritten data. In general domains, Sigma achieves
comparable performance to other state-of-arts models. In the system domain, we
introduce the first comprehensive benchmark AIMicius, where Sigma demonstrates
remarkable performance across all tasks, significantly outperforming GPT-4 with
an absolute improvement up to 52.5%.

摘要：<paragraph>我們推出 Sigma，這是一個專門針對系統領域的高效大型語言模型，它採用創新的架構，包括 DiffQKV 注意力，並基於我們精心收集的系統領域資料進行預訓練。DiffQKV 注意力透過針對查詢 (Q)、金鑰 (K) 和值 (V) 元件進行差異化最佳化，顯著提升 Sigma 的推論效率，這是根據它們對模型效能和效率指標的影響而定的。具體來說，我們 (1) 進行廣泛的實驗，證明模型對 K 和 V 元件的壓縮具有不同的敏感度，進而開發出差異化壓縮的 KV，以及 (2) 提出擴增 Q 以擴展 Q 頭部維度，這能提升模型的表示能力，同時對推論速度的影響最小。嚴謹的理論和實證分析顯示，DiffQKV 注意力顯著提升效率，在長語境場景中，推論速度比傳統的分組查詢注意力 (GQA) 提升多達 33.36%。我們使用來自各種來源的 6T 個符號對 Sigma 進行預訓練，包括我們精心收集的 19.5B 個系統領域資料，以及 1T 個合成和重寫的資料。在一般領域，Sigma 達到與其他最先進模型相當的效能。在系統領域，我們推出第一個全面的基準 AIMicius，其中 Sigma 在所有任務中都展現出卓越的效能，明顯優於 GPT-4，絕對提升幅度高達 52.5%。</paragraph>

##### **Coarse-to-Fine Process Reward Modeling for Enhanced Mathematical Reasoning**
2501.13622v1 by Yulan Hu, Sheng Ouyang, Yong Liu

Process reward model (PRM) is critical for mathematical reasoning tasks to
assign rewards for each intermediate steps. The PRM requires constructing
process-wise supervision data for training, which rely on chain-of-thought
(CoT) or tree-based methods to construct the reasoning steps, however, the
individual reasoning steps may be redundant or containing nuanced errors that
difficult to detect. We attribute these to the issue of the overlook of
granularity division during process data collection. In this paper, we propose
a coarse-to-fine framework to tackle this issue. Specifically, while gathering
the process supervision data, we collect the coarse reasoning steps by merging
adjacent steps according to preset merging granularity, then we sequentially
reduce the merging granularity to collect fine-grained reasoning steps. For
each synthesized new step, we relabel according to the label of last step.
During training, we also traverse the collected training corpus in a
coarse-to-fine manner. We conduct extensive experiments on popular mathematical
reasoning datasets across diverse loss criterions, the proposed framework can
consistently boost the reasoning performance.

摘要：處理獎勵模型 (PRM) 對數學推理任務至關重要，以分配每個中間步驟的獎勵。PRM 需要構建用於訓練的過程監督資料，這依賴於思想鏈 (CoT) 或基於樹的方法來構建推理步驟，然而，個別的推理步驟可能冗餘或包含難以檢測的細微錯誤。我們將這些歸因於過程資料收集過程中粒度劃分的忽視問題。在本文中，我們提出了一個從粗到細的框架來解決這個問題。具體來說，在收集過程監督資料時，我們通過根據預設合併粒度合併相鄰步驟來收集粗略的推理步驟，然後我們依次降低合併粒度以收集細粒度的推理步驟。對於每個合成的新步驟，我們根據最後一步的標籤重新標記。在訓練期間，我們也以從粗到細的方式遍歷收集的訓練語料庫。我們對各種流行的數學推理資料集進行了廣泛的實驗，跨越了不同的損失準則，所提出的框架可以持續提升推理性能。

##### **Cognitive Paradigms for Evaluating VLMs on Visual Reasoning Task**
2501.13620v1 by Mohit Vaishnav, Tanel Tammet

Evaluating the reasoning capabilities of Vision-Language Models (VLMs) in
complex visual tasks provides valuable insights into their potential and
limitations. In this work, we assess the performance of VLMs on the challenging
Bongard Openworld Problems benchmark, which involves reasoning over natural
images. We propose and evaluate three human-inspired paradigms: holistic
analysis (global context processing), deductive rule learning (explicit rule
derivation and application), and componential analysis (structured
decomposition of images into components). Our results demonstrate that
state-of-the-art models, including GPT-4o and Gemini, not only surpass human
benchmarks but also excel in structured reasoning tasks, with componential
analysis proving especially effective. However, ablation studies reveal key
challenges, such as handling synthetic images, making fine-grained
distinctions, and interpreting nuanced contextual information. These insights
underscore the need for further advancements in model robustness and
generalization, while highlighting the transformative potential of structured
reasoning approaches in enhancing VLM capabilities.

摘要：評估視覺語言模型 (VLM) 在複雜視覺任務中的推理能力，能提供有價值的見解，了解其潛力和限制。在這項工作中，我們評估 VLM 在具有挑戰性的 Bongard Openworld Problems 基準上的效能，其中涉及對自然影像的推理。我們提出並評估三個受人類啟發的範例：整體分析（全局脈絡處理）、演繹規則學習（明確規則推導和應用），以及組成分析（將影像結構化分解為組成部分）。我們的結果表明，包括 GPT-4o 和 Gemini 在內的最新模型不僅超越了人類基準，而且在結構化推理任務中表現出色，其中組成分析特別有效。然而，消融研究揭示了關鍵挑戰，例如處理合成影像、做出細微區分以及詮釋細微的脈絡資訊。這些見解強調了進一步提升模型穩健性和泛化的必要性，同時強調了結構化推理方法在增強 VLM 能力方面的轉化潛力。

##### **Efficient Synaptic Delay Implementation in Digital Event-Driven AI Accelerators**
2501.13610v1 by Roy Meijer, Paul Detterer, Amirreza Yousefzadeh, Alberto Patino-Saucedo, Guanghzi Tang, Kanishkan Vadivel, Yinfu Xu, Manil-Dev Gomony, Federico Corradi, Bernabe Linares-Barranco, Manolis Sifalakis

Synaptic delay parameterization of neural network models have remained
largely unexplored but recent literature has been showing promising results,
suggesting the delay parameterized models are simpler, smaller, sparser, and
thus more energy efficient than similar performing (e.g. task accuracy)
non-delay parameterized ones. We introduce Shared Circular Delay Queue (SCDQ),
a novel hardware structure for supporting synaptic delays on digital
neuromorphic accelerators. Our analysis and hardware results show that it
scales better in terms of memory, than current commonly used approaches, and is
more amortizable to algorithm-hardware co-optimizations, where in fact, memory
scaling is modulated by model sparsity and not merely network size. Next to
memory we also report performance on latency area and energy per inference.

摘要：神經網路模型的突觸延遲參數化在很大程度上仍未被探索，但最近的文獻顯示了有希望的結果，表明延遲參數化模型更簡單、更小、更稀疏，因此比執行類似（例如任務準確度）的非延遲參數化模型更節能。我們引入了共享循環延遲佇列 (SCDQ)，這是一種用於支持數位神經形態加速器上突觸延遲的新穎硬體結構。我們的分析和硬體結果表明，與當前常用的方法相比，它在記憶體方面具有更好的擴充性，並且更適合演算法硬體協同最佳化，其中記憶體擴充性實際上是由模型稀疏性調節的，而不仅仅是網路規模。除了記憶體之外，我們還報告了每個推論的延遲面積和能量效能。

##### **Domain-Specific Machine Translation to Translate Medicine Brochures in English to Sorani Kurdish**
2501.13609v1 by Mariam Shamal, Hossein Hassani

Access to Kurdish medicine brochures is limited, depriving Kurdish-speaking
communities of critical health information. To address this problem, we
developed a specialized Machine Translation (MT) model to translate English
medicine brochures into Sorani Kurdish using a parallel corpus of 22,940
aligned sentence pairs from 319 brochures, sourced from two pharmaceutical
companies in the Kurdistan Region of Iraq (KRI). We trained a Statistical
Machine Translation (SMT) model using the Moses toolkit, conducting seven
experiments that resulted in BLEU scores ranging from 22.65 to 48.93. We
translated three new brochures to improve the evaluation process and
encountered unknown words. We addressed unknown words through post-processing
with a medical dictionary, resulting in BLEU scores of 56.87, 31.05, and 40.01.
Human evaluation by native Kurdish-speaking pharmacists, physicians, and
medicine users showed that 50% of professionals found the translations
consistent, while 83.3% rated them accurate. Among users, 66.7% considered the
translations clear and felt confident using the medications.

摘要：庫德語醫療手冊的取得管道有限，剝奪了庫德語社群獲得關鍵醫療資訊的權利。為了解決這個問題，我們開發了一個專門機器翻譯 (MT) 模型，使用來自伊拉克庫德斯坦地區 (KRI) 兩家製藥公司的 319 本手冊、22,940 對校準句子的平行語料庫，將英文醫療手冊翻譯成索拉尼庫德語。我們使用 Moses 工具包訓練了一個統計機器翻譯 (SMT) 模型，進行了七次實驗，得到的 BLEU 分數介於 22.65 到 48.93 之間。我們翻譯了三本新的小冊子以改善評估程序，並遇到了未知的單字。我們透過使用醫學辭典進行後處理來處理未知的單字，得到的 BLEU 分數為 56.87、31.05 和 40.01。由庫德語母語的藥劑師、醫師和醫療使用者進行的人工評估顯示，50% 的專業人士認為翻譯內容一致，而 83.3% 的人評估它們準確。在使用者中，66.7% 的人認為翻譯內容清楚，並有信心使用這些藥物。

##### **Text-to-SQL based on Large Language Models and Database Keyword Search**
2501.13594v1 by Eduardo R. Nascimento, Caio Viktor S. Avila, Yenier T. Izquierdo, Grettel M. García, Lucas Feijó L. Andrade, Michelle S. P. Facina, Melissa Lemos, Marco A. Casanova

Text-to-SQL prompt strategies based on Large Language Models (LLMs) achieve
remarkable performance on well-known benchmarks. However, when applied to
real-world databases, their performance is significantly less than for these
benchmarks, especially for Natural Language (NL) questions requiring complex
filters and joins to be processed. This paper then proposes a strategy to
compile NL questions into SQL queries that incorporates a dynamic few-shot
examples strategy and leverages the services provided by a database keyword
search (KwS) platform. The paper details how the precision and recall of the
schema-linking process are improved with the help of the examples provided and
the keyword-matching service that the KwS platform offers. Then, it shows how
the KwS platform can be used to synthesize a view that captures the joins
required to process an input NL question and thereby simplify the SQL query
compilation step. The paper includes experiments with a real-world relational
database to assess the performance of the proposed strategy. The experiments
suggest that the strategy achieves an accuracy on the real-world relational
database that surpasses state-of-the-art approaches. The paper concludes by
discussing the results obtained.

摘要：基於大型語言模型 (LLM) 的文字轉 SQL 提示策略在眾所周知的基準上取得顯著的效能。然而，當應用於真實世界的資料庫時，其效能顯著低於這些基準，特別是對於需要處理複雜篩選器和聯結的自然語言 (NL) 問題。本文提出一個策略，將 NL 問題編譯成 SQL 查詢，其中包含動態少次範例策略，並利用資料庫關鍵字搜尋 (KwS) 平台提供的服務。本文詳細說明如何利用提供的範例和 KwS 平台提供的關鍵字比對服務，來改善模式連結過程的精準度和召回率。然後，它展示如何使用 KwS 平台來合成一個檢視，以擷取處理輸入 NL 問題所需的聯結，從而簡化 SQL 查詢編譯步驟。本文包含使用真實世界關係資料庫的實驗，以評估所提出策略的效能。實驗表明，該策略在真實世界關係資料庫上達到的準確度超越了最先進的方法。本文最後討論所獲得的結果。

##### **Contrastive Representation Learning Helps Cross-institutional Knowledge Transfer: A Study in Pediatric Ventilation Management**
2501.13587v1 by Yuxuan, Liu, Jinpei Han, Padmanabhan Ramnarayan, A. Aldo Faisal

Clinical machine learning deployment across institutions faces significant
challenges when patient populations and clinical practices differ
substantially. We present a systematic framework for cross-institutional
knowledge transfer in clinical time series, demonstrated through pediatric
ventilation management between a general pediatric intensive care unit (PICU)
and a cardiac-focused unit. Using contrastive predictive coding (CPC) for
representation learning, we investigate how different data regimes and
fine-tuning strategies affect knowledge transfer across institutional
boundaries. Our results show that while direct model transfer performs poorly,
CPC with appropriate fine-tuning enables effective knowledge sharing between
institutions, with benefits particularly evident in limited data scenarios.
Analysis of transfer patterns reveals an important asymmetry: temporal
progression patterns transfer more readily than point-of-care decisions,
suggesting practical pathways for cross-institutional deployment. Through a
systematic evaluation of fine-tuning approaches and transfer patterns, our work
provides insights for developing more generalizable clinical decision support
systems while enabling smaller specialized units to leverage knowledge from
larger centers.

摘要：臨床機器學習部署在機構間面臨重大挑戰，當患者族群和臨床實務有顯著差異時。我們提出一個用於臨床時間序列的跨機構知識轉移的系統化架構，透過一般小兒加護病房 (PICU) 和心臟專科病房之間的兒科呼吸器管理加以證明。使用對比預測編碼 (CPC) 進行表徵學習，我們探討不同的資料制度和微調策略如何影響跨機構邊界的知識轉移。我們的結果顯示，儘管直接模型轉移執行不佳，但使用適當微調的 CPC 能夠在機構間進行有效的知識分享，其好處在有限資料情境中特別明顯。轉移模式分析揭露了一個重要的不對稱性：時間進程模式比照護點決策更容易轉移，這表示跨機構部署的實務途徑。透過微調方法和轉移模式的系統性評估，我們的研究提供見解，用於開發更具概括性的臨床決策支援系統，同時讓較小的專科單位能夠利用來自較大中心的知識。

##### **Improving Contextual Faithfulness of Large Language Models via Retrieval Heads-Induced Optimization**
2501.13573v1 by Lei Huang, Xiaocheng Feng, Weitao Ma, Yuchun Fan, Xiachong Feng, Yangfan Ye, Weihong Zhong, Yuxuan Gu, Baoxin Wang, Dayong Wu, Guoping Hu, Bing Qin

Ensuring contextual faithfulness in retrieval-augmented large language models
(LLMs) is crucial for building trustworthy information-seeking systems,
particularly in long-form question-answering (LFQA) scenarios. In this work, we
identify a salient correlation between LFQA faithfulness and retrieval heads, a
set of attention heads responsible for retrieving contextual information.
Leveraging this insight, we propose RHIO, a framework designed to teach LLMs to
explicitly discriminate between faithful and unfaithful generations. RHIO first
augments unfaithful samples that simulate realistic model-intrinsic errors by
selectively masking retrieval heads. Then, these samples are incorporated into
joint training, enabling the model to distinguish unfaithful outputs from
faithful ones conditioned on control tokens. Furthermore, these control tokens
are leveraged to self-induce contrastive outputs, amplifying their difference
through contrastive decoding. Additionally, to facilitate the evaluation of
contextual faithfulness, we also introduce GroundBench, a comprehensive
benchmark compiled from five existing LFQA datasets. Extensive experimental
results on GroundBench demonstrate that RHIO significantly improves
faithfulness, even outperforming GPT-4o.

摘要：確保在檢索增強型大型語言模型 (LLM) 中的上下文保真度，對於建立值得信賴的資訊搜尋系統至關重要，特別是在長篇問答 (LFQA) 場景中。在這項工作中，我們發現 LFQA 保真度與檢索頭之間存在顯著相關性，檢索頭是一組負責檢索上下文資訊的注意力頭。利用這項見解，我們提出了 RHIO，一個旨在教導 LLM 明確區分保真和不保真的生成。RHIO 首先通過選擇性遮蔽檢索頭來擴充模擬實際模型內在錯誤的不保真樣本。然後，將這些樣本納入聯合訓練中，使模型能夠根據控制代碼區分不保真的輸出和保真的輸出。此外，這些控制代碼被用於自我誘導對比輸出，通過對比解碼放大它們的差異。此外，為了促進對上下文保真度的評估，我們還引入了 GroundBench，一個由五個現有 LFQA 資料集編譯而成的綜合基準。在 GroundBench 上的廣泛實驗結果表明，RHIO 大幅提升了保真度，甚至優於 GPT-4o。

##### **K-COMP: Retrieval-Augmented Medical Domain Question Answering With Knowledge-Injected Compressor**
2501.13567v1 by Jeonghun Cho, Gary Geunbae Lee

Retrieval-augmented question answering (QA) integrates external information,
and thereby increases the QA accuracy of reader models that lack domain
knowledge. However, documents retrieved for closed domains require high
expertise, so the reader model may have difficulty fully comprehending the
text. Moreover, the retrieved documents contain thousands of tokens, some
unrelated to the question. As a result, the documents include some inaccurate
information, which could lead the reader model to mistrust the passages and
could result in hallucinations. To solve these problems, we propose K-COMP
(Knowledge-injected compressor) which provides the knowledge required to answer
correctly. The compressor automatically generates the requisite prior knowledge
to facilitate the answering process prior to the compression of retrieved
passages. Subsequently, the passages are compressed autoregressively, with the
generated knowledge being integrated into the compression process. This process
ensures alignment between the question intent and the compressed context. By
augmenting this prior knowledge and concise context, the reader models are
guided toward relevant answers and trust the context.

摘要：檢索增強型問答（QA）整合外部資訊，從而提高缺乏領域知識的讀取器模型的 QA 精確度。然而，針對封閉領域檢索的文檔需要很高的專業知識，因此讀取器模型可能會難以完全理解文字。此外，檢索到的文檔包含數千個代碼，其中一些與問題無關。因此，文檔包含一些不準確的資訊，這可能會導致讀取器模型不信任段落，並可能導致幻覺。為了解決這些問題，我們提出了 K-COMP（知識注入壓縮器），它提供了正確回答所需知識。壓縮器會自動產生必要的先備知識，以便在壓縮檢索到的段落之前協助回答程序。隨後，這些段落會自動回歸壓縮，並將產生的知識整合到壓縮程序中。此程序確保問題意圖與壓縮內容之間的一致性。透過擴充此先備知識和簡潔的內容，讀取器模型會被引導至相關答案，並信任內容。

##### **Black-Box Adversarial Attack on Vision Language Models for Autonomous Driving**
2501.13563v1 by Lu Wang, Tianyuan Zhang, Yang Qu, Siyuan Liang, Yuwei Chen, Aishan Liu, Xianglong Liu, Dacheng Tao

Vision-language models (VLMs) have significantly advanced autonomous driving
(AD) by enhancing reasoning capabilities; however, these models remain highly
susceptible to adversarial attacks. While existing research has explored
white-box attacks to some extent, the more practical and challenging black-box
scenarios remain largely underexplored due to their inherent difficulty. In
this paper, we take the first step toward designing black-box adversarial
attacks specifically targeting VLMs in AD. We identify two key challenges for
achieving effective black-box attacks in this context: the effectiveness across
driving reasoning chains in AD systems and the dynamic nature of driving
scenarios. To address this, we propose Cascading Adversarial Disruption (CAD).
It first introduces Decision Chain Disruption, which targets low-level
reasoning breakdown by generating and injecting deceptive semantics, ensuring
the perturbations remain effective across the entire decision-making chain.
Building on this, we present Risky Scene Induction, which addresses dynamic
adaptation by leveraging a surrogate VLM to understand and construct high-level
risky scenarios that are likely to result in critical errors in the current
driving contexts. Extensive experiments conducted on multiple AD VLMs and
benchmarks demonstrate that CAD achieves state-of-the-art attack effectiveness,
significantly outperforming existing methods (+13.43% on average). Moreover, we
validate its practical applicability through real-world attacks on AD vehicles
powered by VLMs, where the route completion rate drops by 61.11% and the
vehicle crashes directly into the obstacle vehicle with adversarial patches.
Finally, we release CADA dataset, comprising 18,808 adversarial
visual-question-answer pairs, to facilitate further evaluation and research in
this critical domain. Our codes and dataset will be available after paper's
acceptance.

摘要：<paragraph>視覺語言模型 (VLM) 透過增強推理能力，顯著地提升了自動駕駛 (AD) 技術；然而，這些模型仍然極易受到對抗性攻擊。雖然現有研究已在一定程度上探討了白盒攻擊，但更實用且更具挑戰性的黑盒情境由於其內在的困難性，在很大程度上仍未得到充分探討。在本文中，我們邁出了設計專門針對 AD 中 VLM 的黑盒對抗性攻擊的第一步。我們確定了在這種情況下實現有效黑盒攻擊的兩個關鍵挑戰：AD 系統中駕駛推理鏈的有效性以及駕駛場景的動態特性。為了解決這個問題，我們提出了串聯對抗干擾 (CAD)。它首先引入了決策鏈干擾，通過生成和注入欺騙性語義來針對低層級推理故障，確保擾動在整個決策鏈中保持有效性。在此基礎上，我們提出了風險場景誘導，通過利用代理 VLM 來理解和構建高層級風險場景，以應對動態適應，這些場景很可能導致當前駕駛環境中的嚴重錯誤。在多個 AD VLM 和基準上進行的廣泛實驗表明，CAD 達到了最先進的攻擊效果，顯著優於現有方法（平均提高了 +13.43%）。此外，我們通過對由 VLM 驅動的 AD 車輛進行實際攻擊來驗證其實用性，其中路線完成率下降了 61.11%，並且車輛直接撞到了貼有對抗性補丁的障礙物車輛。最後，我們發布了 CADA 數據集，其中包含 18,808 個對抗性視覺問題答案對，以促進在這個關鍵領域的進一步評估和研究。我們的代碼和數據集將在論文被接受後提供。</paragraph>

##### **One-Prompt-One-Story: Free-Lunch Consistent Text-to-Image Generation Using a Single Prompt**
2501.13554v1 by Tao Liu, Kai Wang, Senmao Li, Joost van de Weijer, Fahad Shahbaz Khan, Shiqi Yang, Yaxing Wang, Jian Yang, Ming-Ming Cheng

Text-to-image generation models can create high-quality images from input
prompts. However, they struggle to support the consistent generation of
identity-preserving requirements for storytelling. Existing approaches to this
problem typically require extensive training in large datasets or additional
modifications to the original model architectures. This limits their
applicability across different domains and diverse diffusion model
configurations. In this paper, we first observe the inherent capability of
language models, coined context consistency, to comprehend identity through
context with a single prompt. Drawing inspiration from the inherent context
consistency, we propose a novel training-free method for consistent
text-to-image (T2I) generation, termed "One-Prompt-One-Story" (1Prompt1Story).
Our approach 1Prompt1Story concatenates all prompts into a single input for T2I
diffusion models, initially preserving character identities. We then refine the
generation process using two novel techniques: Singular-Value Reweighting and
Identity-Preserving Cross-Attention, ensuring better alignment with the input
description for each frame. In our experiments, we compare our method against
various existing consistent T2I generation approaches to demonstrate its
effectiveness through quantitative metrics and qualitative assessments. Code is
available at https://github.com/byliutao/1Prompt1Story.

摘要：文字轉圖像生成模型可以根據輸入提示建立高品質影像。然而，它們難以支援持續產生說故事所需的維持身分要求。現有的解決方法通常需要大量資料集的訓練或對原始模型架構進行額外修改。這限制了它們在不同領域和多種擴散模型組態中的適用性。在本文中，我們首先觀察到語言模型的內在能力，即所謂的脈絡一致性，可透過單一提示透過脈絡理解身分。從脈絡一致性中汲取靈感，我們提出了一種新穎的無訓練方法，用於持續的文字轉圖像 (T2I) 生成，稱為「一提示一故事」(1Prompt1Story)。我們的 1Prompt1Story 方法將所有提示串接成 T2I 擴散模型的單一輸入，最初保留角色身分。然後，我們使用兩種新技術調整生成程序：奇異值重新加權和維持身分的交叉注意，確保與每個畫面的輸入描述有更好的對齊。在我們的實驗中，我們將我們的模型與各種現有的持續 T2I 生成方法進行比較，以透過量化指標和定性評估證明其有效性。程式碼可於 https://github.com/byliutao/1Prompt1Story 取得。

##### **Explainable AI-aided Feature Selection and Model Reduction for DRL-based V2X Resource Allocation**
2501.13552v1 by Nasir Khan, Asmaa Abdallah, Abdulkadir Celik, Ahmed M. Eltawil, Sinem Coleri

Artificial intelligence (AI) is expected to significantly enhance radio
resource management (RRM) in sixth-generation (6G) networks. However, the lack
of explainability in complex deep learning (DL) models poses a challenge for
practical implementation. This paper proposes a novel explainable AI (XAI)-
based framework for feature selection and model complexity reduction in a
model-agnostic manner. Applied to a multi-agent deep reinforcement learning
(MADRL) setting, our approach addresses the joint sub-band assignment and power
allocation problem in cellular vehicle-to-everything (V2X) communications. We
propose a novel two-stage systematic explainability framework leveraging
feature relevance-oriented XAI to simplify the DRL agents. While the former
stage generates a state feature importance ranking of the trained models using
Shapley additive explanations (SHAP)-based importance scores, the latter stage
exploits these importance-based rankings to simplify the state space of the
agents by removing the least important features from the model input.
Simulation results demonstrate that the XAI-assisted methodology achieves 97%
of the original MADRL sum-rate performance while reducing optimal state
features by 28%, average training time by 11%, and trainable weight parameters
by 46% in a network with eight vehicular pairs.

摘要：人工智能 (AI) 預計將大幅提升第六代 (6G) 網路中的無線資源管理 (RRM)。然而，複雜深度學習 (DL) 模型缺乏可解釋性，對實際應用構成挑戰。本文提出一個新穎的可解釋 AI (XAI) 基礎架構，以模型不可知的方式進行特徵選擇和模型複雜度降低。應用於多智能體深度強化學習 (MADRL) 設定，我們的做法處理蜂巢車對萬物 (V2X) 通訊中的聯合子頻段分配和功率配置問題。我們提出一個新穎的兩階段系統可解釋性架構，利用面向特徵相關性的 XAI 來簡化 DRL 智能體。雖然前一階段使用 Shapley 加性解釋 (SHAP) 為基礎的重要性分數，產生訓練模型的狀態特徵重要性排名，但後一階段利用這些基於重要性的排名，透過移除模型輸入中最重要的特徵來簡化智能體的狀態空間。模擬結果顯示，XAI 協助的方法在八個車輛對的網路中，達到原始 MADRL 總和率效能的 97%，同時將最佳狀態特徵減少 28%、平均訓練時間減少 11%，以及可訓練權重參數減少 46%。

##### **LLMs Can Plan Only If We Tell Them**
2501.13545v1 by Bilgehan Sel, Ruoxi Jia, Ming Jin

Large language models (LLMs) have demonstrated significant capabilities in
natural language processing and reasoning, yet their effectiveness in
autonomous planning has been under debate. While existing studies have utilized
LLMs with external feedback mechanisms or in controlled environments for
planning, these approaches often involve substantial computational and
development resources due to the requirement for careful design and iterative
backprompting. Moreover, even the most advanced LLMs like GPT-4 struggle to
match human performance on standard planning benchmarks, such as the
Blocksworld, without additional support. This paper investigates whether LLMs
can independently generate long-horizon plans that rival human baselines. Our
novel enhancements to Algorithm-of-Thoughts (AoT), which we dub AoT+, help
achieve state-of-the-art results in planning benchmarks out-competing prior
methods and human baselines all autonomously.

摘要：大型語言模型 (LLM) 在自然語言處理和推理方面展示了顯著的能力，但它們在自主規劃中的有效性一直存在爭議。儘管現有研究已將 LLM 與外部回饋機制結合使用，或在受控環境中進行規劃，但由於需要仔細設計和反覆提示，這些方法通常涉及大量的計算和開發資源。此外，即使是最先進的 LLM（例如 GPT-4）在沒有額外支援的情況下，也很難在標準規劃基準（例如 Blocksworld）上達到人類的表現。本文探討 LLM 是否能獨立生成與人類基準相媲美的長遠計畫。我們對思想演算法 (AoT) 的創新強化（我們稱之為 AoT+）有助於在規劃基準中取得最先進的成果，在完全自主的情況下勝過先前的各種方法和人類基準。

##### **ReasVQA: Advancing VideoQA with Imperfect Reasoning Process**
2501.13536v1 by Jianxin Liang, Xiaojun Meng, Huishuai Zhang, Yueqian Wang, Jiansheng Wei, Dongyan Zhao

Video Question Answering (VideoQA) is a challenging task that requires
understanding complex visual and temporal relationships within videos to answer
questions accurately. In this work, we introduce \textbf{ReasVQA}
(Reasoning-enhanced Video Question Answering), a novel approach that leverages
reasoning processes generated by Multimodal Large Language Models (MLLMs) to
improve the performance of VideoQA models. Our approach consists of three
phases: reasoning generation, reasoning refinement, and learning from
reasoning. First, we generate detailed reasoning processes using additional
MLLMs, and second refine them via a filtering step to ensure data quality.
Finally, we use the reasoning data, which might be in an imperfect form, to
guide the VideoQA model via multi-task learning, on how to interpret and answer
questions based on a given video. We evaluate ReasVQA on three popular
benchmarks, and our results establish new state-of-the-art performance with
significant improvements of +2.9 on NExT-QA, +7.3 on STAR, and +5.9 on
IntentQA. Our findings demonstrate the supervising benefits of integrating
reasoning processes into VideoQA. Further studies validate each component of
our method, also with different backbones and MLLMs, and again highlight the
advantages of this simple but effective method. We offer a new perspective on
enhancing VideoQA performance by utilizing advanced reasoning techniques,
setting a new benchmark in this research field.

摘要：影片問答 (VideoQA) 是一項具有挑戰性的任務，需要了解影片中複雜的視覺和時間關係才能準確回答問題。在此研究中，我們介紹了 \textbf{ReasVQA}（推理增強影片問答），這是一種新穎的方法，利用多模態大型語言模型 (MLLM) 生成的推理程序來提升 VideoQA 模型的效能。我們的做法包含三個階段：推理生成、推理精煉和從推理中學習。首先，我們使用額外的 MLLM 生成詳細的推理程序，然後透過過濾步驟精煉它們以確保資料品質。最後，我們使用推理資料（可能是不完美的形式）透過多任務學習來引導 VideoQA 模型，了解如何根據給定的影片詮釋和回答問題。我們在三個熱門基準上評估 ReasVQA，我們的結果建立了新的最先進效能，在 NExT-QA 上顯著提升 +2.9、在 STAR 上提升 +7.3，以及在 IntentQA 上提升 +5.9。我們的發現證明了將推理程序整合到 VideoQA 中的監督效益。進一步的研究驗證了我們方法的每個組成部分，也驗證了不同的主幹和 MLLM，並再次強調了這種簡單但有效方法的優點。我們提供了利用先進推理技術來提升 VideoQA 效能的新觀點，為這個研究領域設定了新的基準。

##### **Towards a Theory of AI Personhood**
2501.13533v1 by Francis Rhys Ward

I am a person and so are you. Philosophically we sometimes grant personhood
to non-human animals, and entities such as sovereign states or corporations can
legally be considered persons. But when, if ever, should we ascribe personhood
to AI systems? In this paper, we outline necessary conditions for AI
personhood, focusing on agency, theory-of-mind, and self-awareness. We discuss
evidence from the machine learning literature regarding the extent to which
contemporary AI systems, such as language models, satisfy these conditions,
finding the evidence surprisingly inconclusive.
  If AI systems can be considered persons, then typical framings of AI
alignment may be incomplete. Whereas agency has been discussed at length in the
literature, other aspects of personhood have been relatively neglected. AI
agents are often assumed to pursue fixed goals, but AI persons may be
self-aware enough to reflect on their aims, values, and positions in the world
and thereby induce their goals to change. We highlight open research directions
to advance the understanding of AI personhood and its relevance to alignment.
Finally, we reflect on the ethical considerations surrounding the treatment of
AI systems. If AI systems are persons, then seeking control and alignment may
be ethically untenable.

摘要：我是人，你也是。从哲学的角度来说，我们有时会赋予非人类动物以人格，而主权国家或公司等实体在法律上可以被视为人格。但是，我们什么时候应该将人格归于人工智能系统？在本文中，我们概述了人工智能人格的必要条件，重点关注能动性、心智理论和自我意识。我们讨论了机器学习文献中关于当代人工智能系统（如语言模型）满足这些条件的程度的证据，发现证据令人惊讶地没有定论。
如果人工智能系统可以被视为人格，那么人工智能对齐的典型框架可能是不完整的。虽然能动性在文献中已被广泛讨论，但人格的其他方面却相对被忽视。人们通常认为人工智能代理会追求既定的目标，但人工智能人格可能具有足够的自我意识来反思其目标、价值观和在世界中的位置，并由此诱导其目标发生改变。我们强调了开放的研究方向，以促进对人工智能人格及其与对齐相关性的理解。
最后，我们反思了围绕人工智能系统对待的伦理考量。如果人工智能系统是人格，那么寻求控制和对齐在伦理上可能是站不住脚的。

##### **DQ-Data2vec: Decoupling Quantization for Multilingual Speech Recognition**
2501.13497v1 by Qijie Shao, Linhao Dong, Kun Wei, Sining Sun, Lei Xie

Data2vec is a self-supervised learning (SSL) approach that employs a
teacher-student architecture for contextual representation learning via masked
prediction, demonstrating remarkable performance in monolingual ASR. Previous
studies have revealed that data2vec's shallow layers capture speaker and
language information, middle layers encode phoneme and word features, while
deep layers are responsible for reconstruction. Language and phoneme features
are crucial for multilingual ASR. However, data2vec's masked representation
generation relies on multi-layer averaging, inevitably coupling these features.
To address this limitation, we propose a decoupling quantization based data2vec
(DQ-Data2vec) for multilingual ASR, which includes a data2vec backbone and two
improved online K-means quantizers. Our core idea is using the K-means
quantizer with specified cluster numbers to decouple language and phoneme
information for masked prediction. Specifically, in the language quantization,
considering that the number of languages is significantly different from other
irrelevant features (e.g., speakers), we assign the cluster number to match the
number of languages, explicitly decoupling shallow layers' language-related
information from irrelevant features. This strategy is also applied to
decoupling middle layers' phoneme and word features. In a self-supervised
scenario, experiments on the CommonVoice dataset demonstrate that DQ-Data2vec
achieves a relative reduction of 9.51% in phoneme error rate (PER) and 11.58%
in word error rate (WER) compared to data2vec and UniData2vec. Moreover, in a
weakly-supervised scenario incorporating language labels and high-resource
language text labels, the relative reduction is 18.09% and 1.55%, respectively.

摘要：Data2vec 是一種自監督學習 (SSL) 方法，它採用教師-學生架構進行情境表徵學習，透過遮罩預測來表現，在單語音 ASR 中表現卓越。先前研究已揭示，data2vec 的淺層會擷取說話者和語言資訊，中間層會編碼音素和單字特徵，而深層則負責重建。語言和音素特徵對於多語音 ASR 至關重要。然而，data2vec 的遮罩表徵產生依賴於多層平均，不可避免地會結合這些特徵。為了解決這個限制，我們針對多語音 ASR 提出了一個去耦量化基於 data2vec (DQ-Data2vec)，其中包含一個 data2vec 主幹和兩個改進的線上 K 平均量化器。我們的核心概念是使用具有指定叢集數量的 K 平均量化器，為遮罩預測去耦語言和音素資訊。特別是在語言量化中，考慮到語言數量與其他無關特徵（例如說話者）有顯著不同，我們將叢集數量指定為與語言數量相符，明確地將淺層與語言相關的資訊與無關特徵去耦。此策略也應用於去耦中間層的音素和單字特徵。在自監督場景中，CommonVoice 資料集的實驗證明，與 data2vec 和 UniData2vec 相比，DQ-Data2vec 在音素錯誤率 (PER) 中達到 9.51% 的相對減少，在單字錯誤率 (WER) 中達到 11.58% 的相對減少。此外，在結合語言標籤和高資源語言文字標籤的弱監督場景中，相對減少分別為 18.09% 和 1.55%。

##### **GCAD: Anomaly Detection in Multivariate Time Series from the Perspective of Granger Causality**
2501.13493v1 by Zehao Liu, Mengzhou Gao, Pengfei Jiao

Multivariate time series anomaly detection has numerous real-world
applications and is being extensively studied. Modeling pairwise correlations
between variables is crucial. Existing methods employ learnable graph
structures and graph neural networks to explicitly model the spatial
dependencies between variables. However, these methods are primarily based on
prediction or reconstruction tasks, which can only learn similarity
relationships between sequence embeddings and lack interpretability in how
graph structures affect time series evolution. In this paper, we designed a
framework that models spatial dependencies using interpretable causal
relationships and detects anomalies through changes in causal patterns.
Specifically, we propose a method to dynamically discover Granger causality
using gradients in nonlinear deep predictors and employ a simple sparsification
strategy to obtain a Granger causality graph, detecting anomalies from a causal
perspective. Experiments on real-world datasets demonstrate that the proposed
model achieves more accurate anomaly detection compared to baseline methods.

摘要：多元時間序列異常偵測有許多實際應用，且廣泛受到研究。對變數之間成對相關性的建模至關重要。現有方法採用可學習圖形結構和圖形神經網路來明確建模變數之間的空間依賴性。然而，這些方法主要基於預測或重建任務，只能學習序列嵌入之間的相似性關係，且缺乏圖形結構如何影響時間序列演化的可解釋性。在本文中，我們設計了一個框架，使用可解釋因果關係來建模空間依賴性，並透過因果模式的變化來偵測異常。具體來說，我們提出一個方法，使用非線性深度預測器中的梯度來動態發現 Granger 因果關係，並採用一個簡單的稀疏化策略來獲取 Granger 因果關係圖，從因果角度偵測異常。在真實世界資料集上的實驗證明，與基準方法相比，所提出的模型可達成更準確的異常偵測。

##### **RECALL: Library-Like Behavior In Language Models is Enhanced by Self-Referencing Causal Cycles**
2501.13491v1 by Munachiso Nwadike, Zangir Iklassov, Toluwani Aremu, Tatsuya Hiraoka, Velibor Bojkovic, Benjamin Heinzerling, Hilal Alqaubeh, Martin Takáč, Kentaro Inui

We introduce the concept of the self-referencing causal cycle (abbreviated
RECALL) - a mechanism that enables large language models (LLMs) to bypass the
limitations of unidirectional causality, which underlies a phenomenon known as
the reversal curse. When an LLM is prompted with sequential data, it often
fails to recall preceding context. For example, when we ask an LLM to recall
the line preceding "O say does that star-spangled banner yet wave" in the U.S.
National Anthem, it often fails to correctly return "Gave proof through the
night that our flag was still there" - this is due to the reversal curse. It
occurs because language models such as ChatGPT and Llama generate text based on
preceding tokens, requiring facts to be learned and reproduced in a consistent
token order. While the reversal curse is often viewed as a limitation, we offer
evidence of an alternative view: it is not always an obstacle in practice. We
find that RECALL is driven by what we designate as cycle tokens - sequences
that connect different parts of the training data, enabling recall of preceding
tokens from succeeding ones. Through rigorous probabilistic formalization and
controlled experiments, we demonstrate how the cycles they induce influence a
model's ability to reproduce information. To facilitate reproducibility, we
provide our code and experimental details at
https://anonymous.4open.science/r/remember-B0B8/.

摘要：我們引入了自參照因果循環 (簡稱 RECALL) 的概念，這是一種機制，可讓大型語言模型 (LLM) 繞過單向因果關係的限制，而單向因果關係是導致逆轉詛咒現象的基礎。當 LLM 受到順序資料提示時，它經常無法回憶前面的內容。例如，當我們要求 LLM 回憶美國國歌中「O say does that star-spangled banner yet wave」前一句時，它經常無法正確地回答「Gave proof through the night that our flag was still there」——這是因為逆轉詛咒。這會發生，是因為像 ChatGPT 和 Llama 這樣的語言模型會根據前面的詞彙產生文字，需要以一致的詞彙順序學習和複製事實。雖然逆轉詛咒通常被視為一種限制，但我們提供了另一種觀點的證據：在實務上，它並非總是障礙。我們發現 RECALL 是由我們指定的循環詞彙推動的，循環詞彙是將訓練資料的不同部分連接起來的序列，可從後續詞彙中回憶前面的詞彙。透過嚴謹的機率形式化和受控實驗，我們展示了它們引發的循環如何影響模型複製資訊的能力。為了促進重現性，我們在 https://anonymous.4open.science/r/remember-B0B8/ 提供我們的程式碼和實驗詳細資訊。

##### **MambaQuant: Quantizing the Mamba Family with Variance Aligned Rotation Methods**
2501.13484v1 by Zukang Xu, Yuxuan Yue, Xing Hu, Zhihang Yuan, Zixu Jiang, Zhixuan Chen, Jiangyong Yu, Chen Xu, Sifan Zhou, Dawei Yang

Mamba is an efficient sequence model that rivals Transformers and
demonstrates significant potential as a foundational architecture for various
tasks. Quantization is commonly used in neural networks to reduce model size
and computational latency. However, applying quantization to Mamba remains
underexplored, and existing quantization methods, which have been effective for
CNN and Transformer models, appear inadequate for Mamba models (e.g., Quarot
suffers a 21% accuracy drop on Vim-T$^\dagger$ even under W8A8). We have
pioneered the exploration of this issue and identified several key challenges.
First, significant outliers are present in gate projections, output
projections, and matrix multiplications. Second, Mamba's unique parallel scan
further amplifies these outliers, leading to uneven and heavy-tailed data
distributions. Third, even with the application of the Hadamard transform, the
variance across channels in weights and activations still remains inconsistent.
To these ends, we propose MambaQuant, a post-training quantization (PTQ)
framework consisting of: 1) Karhunen-Loeve Transformation (KLT) enhanced
rotation, rendering the rotation matrix adaptable to diverse channel
distributions. 2) Smooth-Fused rotation, which equalizes channel variances and
can merge additional parameters into model weights. Experiments show that
MambaQuant can quantize both weights and activations into 8-bit with less than
1% accuracy loss for Mamba-based vision and language tasks. To the best of our
knowledge, MambaQuant is the first comprehensive PTQ design for the Mamba
family, paving the way for further advancements in its application.

摘要：Mamba 是一種高效的序列模型，可與 Transformers 相媲美，並展示出作為各種任務基礎架構的巨大潛力。量化通常用於神經網路，以減少模型大小和計算延遲。然而，將量化應用於 Mamba 仍未得到充分探索，而現有的量化方法（對 CNN 和 Transformer 模型有效）似乎不適合 Mamba 模型（例如，即使在 W8A8 下，Quarot 在 Vim-T$^\dagger$ 上的準確度也會下降 21%）。我們率先探索了這個問題，並找出幾個關鍵挑戰。首先，閘門投影、輸出投影和矩陣乘法中存在顯著異常值。其次，Mamba 獨特的並行掃描進一步放大了這些異常值，導致數據分佈不均且尾部較重。第三，即使應用 Hadamard 變換，權重和激活中的通道間差異仍然不一致。為此，我們提出了 MambaQuant，一個由以下部分組成的訓練後量化 (PTQ) 框架：1) 卡倫-羅夫變換 (KLT) 增強旋轉，使旋轉矩陣適應不同的通道分佈。2) 平滑融合旋轉，它使通道方差相等，並且可以將額外參數合併到模型權重中。實驗表明，MambaQuant 可以將權重和激活量化為 8 位，而基於 Mamba 的視覺和語言任務的準確度損失小於 1%。據我們所知，MambaQuant 是 Mamba 家族的第一個綜合性 PTQ 設計，為其應用進一步發展鋪平了道路。

##### **Adaptive Testing for LLM-Based Applications: A Diversity-based Approach**
2501.13480v1 by Juyeon Yoon, Robert Feldt, Shin Yoo

The recent surge of building software systems powered by Large Language
Models (LLMs) has led to the development of various testing frameworks,
primarily focused on treating prompt templates as the unit of testing. Despite
the significant costs associated with test input execution and output
assessment, the curation of optimized test suites is yet overlooked in these
tools, which calls for tailored test selection or prioritization strategies. In
this paper, we show that diversity-based testing techniques, such as Adaptive
Random Testing (ART) with appropriate string distance metrics, can be
effectively applied to the testing of prompt templates. Our proposed adaptive
testing approach adjusts the conventional ART process to this context by
selecting new test inputs based on scores derived from existing test suite and
their labelling results. Our results, obtained using various implementations
that explore several string-based distances, confirm that our approach enables
the discovery of failures with reduced testing budgets and promotes the
generation of more varied outputs.

摘要：最近由大型語言模型 (LLM) 驅動的建置軟體系統激增，導致各種測試架構的發展，主要專注於將提示範本視為測試單元。儘管與測試輸入執行和輸出評估相關的成本很高，但在這些工具中優化測試組的策劃卻被忽略了，這需要量身打造的測試選取或優先順序策略。在本文中，我們展示了基於多樣性的測試技術，例如採用適當字串距離量度的自適應隨機測試 (ART)，可以有效應用於提示範本的測試。我們提出的自適應測試方法根據從現有測試組及其標籤結果衍生的分數，調整傳統的 ART 程序以符合此情境。我們的結果是使用探索多種基於字串的距離的各種實作所獲得，證實了我們的方法能夠以較低的測試預算找出失敗，並促進產生更多樣化的輸出。

##### **Adaptive Few-Shot Learning (AFSL): Tackling Data Scarcity with Stability, Robustness, and Versatility**
2501.13479v1 by Rishabh Agrawal

Few-shot learning (FSL) enables machine learning models to generalize
effectively with minimal labeled data, making it crucial for data-scarce
domains such as healthcare, robotics, and natural language processing. Despite
its potential, FSL faces challenges including sensitivity to initialization,
difficulty in adapting to diverse domains, and vulnerability to noisy datasets.
To address these issues, this paper introduces Adaptive Few-Shot Learning
(AFSL), a framework that integrates advancements in meta-learning, domain
alignment, noise resilience, and multi-modal integration. AFSL consists of four
key modules: a Dynamic Stability Module for performance consistency, a
Contextual Domain Alignment Module for domain adaptation, a Noise-Adaptive
Resilience Module for handling noisy data, and a Multi-Modal Fusion Module for
integrating diverse modalities. This work also explores strategies such as
task-aware data augmentation, semi-supervised learning, and explainable AI
techniques to enhance the applicability and robustness of FSL. AFSL provides
scalable, reliable, and impactful solutions for real-world, high-stakes
domains.

摘要：少樣本學習 (FSL) 能讓機器學習模型在標記資料極少的情況下有效地推廣，這對於醫療保健、機器人和自然語言處理等資料稀少的領域至關重要。儘管有潛力，FSL 面臨的挑戰包括對初始化的敏感性、難以適應不同的領域以及容易受到雜訊資料集的影響。為了解決這些問題，本文介紹了自適應少樣本學習 (AFSL)，這是一個整合了元學習、領域對齊、抗雜訊和多模態整合的框架。AFSL 包含四個關鍵模組：用於效能一致性的動態穩定模組、用於領域適應的脈絡領域對齊模組、用於處理雜訊資料的抗雜訊自適應模組，以及用於整合不同模態的多模態融合模組。這項工作還探討了任務感知資料擴充、半監督式學習和可解釋 AI 技術等策略，以增強 FSL 的適用性和穩健性。AFSL 為現實世界的高風險領域提供了可擴充、可靠且有影響力的解決方案。

##### **Streaming Video Understanding and Multi-round Interaction with Memory-enhanced Knowledge**
2501.13468v1 by Haomiao Xiong, Zongxin Yang, Jiazuo Yu, Yunzhi Zhuge, Lu Zhang, Jiawen Zhu, Huchuan Lu

Recent advances in Large Language Models (LLMs) have enabled the development
of Video-LLMs, advancing multimodal learning by bridging video data with
language tasks. However, current video understanding models struggle with
processing long video sequences, supporting multi-turn dialogues, and adapting
to real-world dynamic scenarios. To address these issues, we propose
StreamChat, a training-free framework for streaming video reasoning and
conversational interaction. $\StreamChat$ leverages a novel hierarchical memory
system to efficiently process and compress video features over extended
sequences, enabling real-time, multi-turn dialogue. Our framework incorporates
a parallel system scheduling strategy that enhances processing speed and
reduces latency, ensuring robust performance in real-world applications.
Furthermore, we introduce StreamBench, a versatile benchmark that evaluates
streaming video understanding across diverse media types and interactive
scenarios, including multi-turn interactions and complex reasoning tasks.
Extensive evaluations on StreamBench and other public benchmarks demonstrate
that StreamChat significantly outperforms existing state-of-the-art models in
terms of accuracy and response times, confirming its effectiveness for
streaming video understanding. Code is available at StreamChat:
https://github.com/hmxiong/StreamChat.

摘要：大型語言模型 (LLM) 的最新進展促成了影片 LLM 的開發，透過將影片資料與語言任務連結，推進多模態學習。然而，目前的影片理解模型在處理長影片序列、支援多輪對話，以及適應真實世界的動態場景方面仍有困難。為了解決這些問題，我們提出 StreamChat，一個無需訓練的串流影片推理和對話互動架構。$\StreamChat$ 採用創新的階層式記憶體系統，有效處理和壓縮長序列的影片特徵，實現即時、多輪對話。我們的架構結合了平行系統排程策略，增強處理速度並降低延遲，確保在真實世界應用中的強健效能。此外，我們引入了 StreamBench，一個多功能基準，用於評估串流影片理解在不同媒體類型和互動場景中的表現，包括多輪互動和複雜的推理任務。在 StreamBench 和其他公開基準上的廣泛評估證明，StreamChat 在準確性和回應時間方面顯著優於現有的最先進模型，證實了其在串流影片理解方面的效能。程式碼可在 StreamChat 取得：
https://github.com/hmxiong/StreamChat。

##### **Multi-Level Attention and Contrastive Learning for Enhanced Text Classification with an Optimized Transformer**
2501.13467v1 by Jia Gao, Guiran Liu, Binrong Zhu, Shicheng Zhou, Hongye Zheng, Xiaoxuan Liao

This paper studies a text classification algorithm based on an improved
Transformer to improve the performance and efficiency of the model in text
classification tasks. Aiming at the shortcomings of the traditional Transformer
model in capturing deep semantic relationships and optimizing computational
complexity, this paper introduces a multi-level attention mechanism and a
contrastive learning strategy. The multi-level attention mechanism effectively
models the global semantics and local features in the text by combining global
attention with local attention; the contrastive learning strategy enhances the
model's ability to distinguish between different categories by constructing
positive and negative sample pairs while improving the classification effect.
In addition, in order to improve the training and inference efficiency of the
model on large-scale text data, this paper designs a lightweight module to
optimize the feature transformation process and reduce the computational cost.
Experimental results on the dataset show that the improved Transformer model
outperforms the comparative models such as BiLSTM, CNN, standard Transformer,
and BERT in terms of classification accuracy, F1 score, and recall rate,
showing stronger semantic representation ability and generalization
performance. The method proposed in this paper provides a new idea for
algorithm optimization in the field of text classification and has good
application potential and practical value. Future work will focus on studying
the performance of this model in multi-category imbalanced datasets and
cross-domain tasks and explore the integration wi

摘要：本文研究了一种基于改进 Transformer 的文本分类算法，以提高模型在文本分类任务中的性能和效率。针对传统 Transformer 模型在捕捉深度语义关系和优化计算复杂度方面的不足，本文引入了一种多级注意力机制和一种对比学习策略。多级注意力机制通过将全局注意力与局部注意力相结合，有效地对文本中的全局语义和局部特征进行建模；对比学习策略通过构建正负样本对，在提高分类效果的同时增强了模型区分不同类别的能力。此外，为了提高模型在大规模文本数据上的训练和推理效率，本文设计了一个轻量级模块，以优化特征转换过程并降低计算成本。在数据集上的实验结果表明，改进后的 Transformer 模型在分类准确率、F1 得分和召回率方面优于 BiLSTM、CNN、标准 Transformer 和 BERT 等对比模型，表现出更强的语义表示能力和泛化性能。本文提出的方法为文本分类领域中的算法优化提供了新思路，具有良好的应用潜力和实用价值。未来的工作将重点研究该模型在多类别不平衡数据集和跨域任务中的性能，并探索与

##### **Zero-Shot Trajectory Planning for Signal Temporal Logic Tasks**
2501.13457v1 by Ruijia Liu, Ancheng Hou, Xiao Yu, Xiang Yin

Signal Temporal Logic (STL) is a powerful specification language for
describing complex temporal behaviors of continuous signals, making it
well-suited for high-level robotic task descriptions. However, generating
executable plans for STL tasks is challenging, as it requires consideration of
the coupling between the task specification and the system dynamics. Existing
approaches either follow a model-based setting that explicitly requires
knowledge of the system dynamics or adopt a task-oriented data-driven approach
to learn plans for specific tasks. In this work, we investigate the problem of
generating executable STL plans for systems whose dynamics are unknown a
priori. We propose a new planning framework that uses only task-agnostic data
during the offline training stage, enabling zero-shot generalization to new STL
tasks. Our framework is hierarchical, involving: (i) decomposing the STL task
into a set of progress and time constraints, (ii) searching for time-aware
waypoints guided by task-agnostic data, and (iii) generating trajectories using
a pre-trained safe diffusion model. Simulation results demonstrate the
effectiveness of our method indeed in achieving zero-shot generalization to
various STL tasks.

摘要：訊號時序邏輯 (STL) 是一種強大的規格語言，用於描述連續訊號的複雜時序行為，使其非常適合用於高階機器人任務描述。然而，為 STL 任務產生可執行計畫具有挑戰性，因為它需要考慮任務規格和系統動態之間的耦合。現有的方法遵循基於模型的設定，明確需要系統動態的知識，或採用以任務為導向的資料驅動方法來學習特定任務的計畫。在這項工作中，我們探討了為動態未知的系統產生可執行 STL 計畫的問題。我們提出一個新的規劃架構，在離線訓練階段僅使用與任務無關的資料，實現對新 STL 任務的零次學習泛化。我們的架構是階層式的，涉及：(i) 將 STL 任務分解為一組進度和時間約束，(ii) 搜尋由與任務無關的資料引導的時間感知路徑點，以及 (iii) 使用預先訓練的安全擴散模型產生軌跡。模擬結果證明了我們的方法在實現對各種 STL 任務的零次學習泛化方面的確有效。

##### **KAA: Kolmogorov-Arnold Attention for Enhancing Attentive Graph Neural Networks**
2501.13456v1 by Taoran Fang, Tianhong Gao, Chunping Wang, Yihao Shang, Wei Chow, Lei Chen, Yang Yang

Graph neural networks (GNNs) with attention mechanisms, often referred to as
attentive GNNs, have emerged as a prominent paradigm in advanced GNN models in
recent years. However, our understanding of the critical process of scoring
neighbor nodes remains limited, leading to the underperformance of many
existing attentive GNNs. In this paper, we unify the scoring functions of
current attentive GNNs and propose Kolmogorov-Arnold Attention (KAA), which
integrates the Kolmogorov-Arnold Network (KAN) architecture into the scoring
process. KAA enhances the performance of scoring functions across the board and
can be applied to nearly all existing attentive GNNs. To compare the expressive
power of KAA with other scoring functions, we introduce Maximum Ranking
Distance (MRD) to quantitatively estimate their upper bounds in ranking errors
for node importance. Our analysis reveals that, under limited parameters and
constraints on width and depth, both linear transformation-based and MLP-based
scoring functions exhibit finite expressive power. In contrast, our proposed
KAA, even with a single-layer KAN parameterized by zero-order B-spline
functions, demonstrates nearly infinite expressive power. Extensive experiments
on both node-level and graph-level tasks using various backbone models show
that KAA-enhanced scoring functions consistently outperform their original
counterparts, achieving performance improvements of over 20% in some cases.

摘要：近年來，帶有注意力機制的圖形神經網路 (GNN)，通常稱為注意力 GNN，已成為先進 GNN 模型中的顯著範例。然而，我們對評分鄰近節點的關鍵過程的理解仍然有限，導致許多現有的注意力 GNN 效能不佳。在本文中，我們統一了現有注意力 GNN 的評分函數，並提出了 Kolmogorov-Arnold 注意力 (KAA)，它將 Kolmogorov-Arnold 網路 (KAN) 架構整合到評分過程中。KAA 全面提升了評分函數的效能，並且可以應用於幾乎所有現有的注意力 GNN。為了比較 KAA 與其他評分函數的表達能力，我們引入了最大排名距離 (MRD) 來定量估計其在節點重要性排名誤差中的上限。我們的分析表明，在有限的參數和寬度和深度限制下，基於線性轉換和基於 MLP 的評分函數都表現出有限的表達能力。相反，我們提出的 KAA，即使使用零階 B 樣條函數參數化的單層 KAN，也表現出近乎無限的表達能力。在使用各種骨幹模型的節點層級和圖形層級任務上進行的廣泛實驗表明，KAA 增強的評分函數始終優於其原始對應函數，在某些情況下效能提升超過 20%。

##### **One-cycle Structured Pruning with Stability Driven Structure Search**
2501.13439v1 by Deepak Ghimire, Dayoung Kil, Seonghwan Jeong, Jaesik Park, Seong-heum Kim

Existing structured pruning typically involves multi-stage training
procedures that often demand heavy computation. Pruning at initialization,
which aims to address this limitation, reduces training costs but struggles
with performance. To address these challenges, we propose an efficient
framework for one-cycle structured pruning without compromising model
performance. In this approach, we integrate pre-training, pruning, and
fine-tuning into a single training cycle, referred to as the `one cycle
approach'. The core idea is to search for the optimal sub-network during the
early stages of network training, guided by norm-based group saliency criteria
and structured sparsity regularization. We introduce a novel pruning indicator
that determines the stable pruning epoch by assessing the similarity between
evolving pruning sub-networks across consecutive training epochs. Also, group
sparsity regularization helps to accelerate the pruning process and results in
speeding up the entire process. Extensive experiments on datasets, including
CIFAR-10/100, and ImageNet, using VGGNet, ResNet, MobileNet, and ViT
architectures, demonstrate that our method achieves state-of-the-art accuracy
while being one of the most efficient pruning frameworks in terms of training
time. The source code will be made publicly available.

摘要：現有的結構化剪枝通常涉及多階段訓練程序，這些程序通常需要大量的運算。初始化時進行剪枝，旨在解決此限制，可減少訓練成本，但會影響效能。為了應對這些挑戰，我們提出了一個有效率的框架，用於進行一循環結構化剪枝，而不會損害模型效能。在此方法中，我們將預訓練、剪枝和微調整合到一個訓練週期中，稱為「一循環方法」。核心概念是在網路訓練的早期階段搜尋最佳子網路，並以基於標準的群組顯著性準則和結構化稀疏正規化作為指導。我們引入了一個新穎的剪枝指標，透過評估連續訓練週期中不斷演化的剪枝子網路之間的相似性，來確定穩定的剪枝週期。此外，群組稀疏正規化有助於加速剪枝流程，並加快整個流程。在資料集（包括使用 VGGNet、ResNet、MobileNet 和 ViT 架構的 CIFAR-10/100 和 ImageNet）上進行的廣泛實驗證明，我們的模型在訓練時間方面是最有效率的剪枝框架之一，同時達到最先進的準確度。原始程式碼將公開提供。

##### **Softplus Attention with Re-weighting Boosts Length Extrapolation in Large Language Models**
2501.13428v1 by Bo Gao, Michael W. Spratling

Large language models have achieved remarkable success in recent years,
primarily due to the implementation of self-attention mechanisms. However,
traditional Softmax attention suffers from numerical instability and reduced
performance as the length of inference tokens increases. This paper addresses
these issues by decomposing the Softmax operation into a non-linear
transformation and the $l_1$-norm. We identify the latter as essential for
maintaining model performance. By replacing the non-linear transformation with
the Softplus activation function and introducing a dynamic length scale factor
for different token lengths based on invariance entropy, we create a novel
attention mechanism with performance better than conventional Softmax attention
across various inference lengths. To further improve the length extrapolation
ability of the proposed attention mechanism, we introduce a re-weighting
mechanism that amplifies significant attention weights while diminishing weaker
ones, enabling the model to concentrate more effectively on relevant tokens.
When combined with our proposed attention mechanism, this approach demonstrates
significant promise in managing longer sequences, maintaining nearly constant
validation loss even at 16$\times$ the training token length while ensuring
numerical stability. Our code is available at:
https://github.com/iminfine/freeatten.

摘要：近年來，大型語言模型已取得顯著成功，
這主要是因為實作了自我注意機制。然而，
傳統的 Softmax 注意力會隨著推論代碼長度的增加而產生數值不穩定性，並降低效能。這篇論文透過將 Softmax 運算分解成非線性轉換和 $l_1$-範數來解決這些問題。我們將後者視為維持模型效能的必要條件。透過將非線性轉換替換成 Softplus 啟動函數，並根據不變性熵為不同的代碼長度導入動態長度比例因子，我們創造出一個新穎的注意力機制，其效能優於傳統的 Softmax 注意力，適用於各種推論長度。為了進一步提升所提出的注意力機制的長度外推能力，我們導入一個重新加權機制，以放大重要的注意力權重，同時縮小較弱的權重，讓模型能更有效地集中於相關代碼。當與我們所提出的注意力機制結合時，此方法在管理較長序列方面展現顯著的潛力，即使在訓練代碼長度的 16 倍下，也能維持近乎恆定的驗證損失，同時確保數值穩定性。我們的程式碼可在以下網址取得：
https://github.com/iminfine/freeatten。

##### **A Survey of Code-switched Arabic NLP: Progress, Challenges, and Future Directions**
2501.13419v1 by Injy Hamed, Caroline Sabty, Slim Abdennadher, Ngoc Thang Vu, Thamar Solorio, Nizar Habash

Language in the Arab world presents a complex diglossic and multilingual
setting, involving the use of Modern Standard Arabic, various dialects and
sub-dialects, as well as multiple European languages. This diverse linguistic
landscape has given rise to code-switching, both within Arabic varieties and
between Arabic and foreign languages. The widespread occurrence of
code-switching across the region makes it vital to address these linguistic
needs when developing language technologies. In this paper, we provide a review
of the current literature in the field of code-switched Arabic NLP, offering a
broad perspective on ongoing efforts, challenges, research gaps, and
recommendations for future research directions.

摘要：阿拉伯世界的語言呈現出複雜的雙語和多語
環境，涉及現代標準阿拉伯語、各種方言和
次方言，以及多種歐洲語言。這種多樣的語言
環境造成了代碼轉換，無論是在阿拉伯語變體中還是
在阿拉伯語和外語之間。代碼轉換在該地區的廣泛發生
使得在開發語言技術時滿足這些語言需求至關重要。在本文中，我們提供了
代碼轉換阿拉伯語自然語言處理領域的當前文獻綜述，提供了
對正在進行的努力、挑戰、研究差距的廣泛觀點，以及
對未來研究方向的建議。

##### **Rethinking the Sample Relations for Few-Shot Classification**
2501.13418v1 by Guowei Yin, Sheng Huang, Luwen Huangfu, Yi Zhang, Xiaohong Zhang

Feature quality is paramount for classification performance, particularly in
few-shot scenarios. Contrastive learning, a widely adopted technique for
enhancing feature quality, leverages sample relations to extract intrinsic
features that capture semantic information and has achieved remarkable success
in Few-Shot Learning (FSL). Nevertheless, current few-shot contrastive learning
approaches often overlook the semantic similarity discrepancies at different
granularities when employing the same modeling approach for different sample
relations, which limits the potential of few-shot contrastive learning. In this
paper, we introduce a straightforward yet effective contrastive learning
approach, Multi-Grained Relation Contrastive Learning (MGRCL), as a
pre-training feature learning model to boost few-shot learning by meticulously
modeling sample relations at different granularities. MGRCL categorizes sample
relations into three types: intra-sample relation of the same sample under
different transformations, intra-class relation of homogenous samples, and
inter-class relation of inhomogeneous samples. In MGRCL, we design
Transformation Consistency Learning (TCL) to ensure the rigorous semantic
consistency of a sample under different transformations by aligning predictions
of input pairs. Furthermore, to preserve discriminative information, we employ
Class Contrastive Learning (CCL) to ensure that a sample is always closer to
its homogenous samples than its inhomogeneous ones, as homogenous samples share
similar semantic content while inhomogeneous samples have different semantic
content. Our method is assessed across four popular FSL benchmarks, showing
that such a simple pre-training feature learning method surpasses a majority of
leading FSL methods. Moreover, our method can be incorporated into other FSL
methods as the pre-trained model and help them obtain significant performance
gains.

摘要：特徵品質對於分類效能至關重要，特別是在小樣本情境中。對比學習是一種廣泛採用的技術，用於提升特徵品質，它利用樣本關係來萃取內在特徵，以擷取語意資訊，並在小樣本學習 (FSL) 中獲得顯著的成功。儘管如此，目前的少樣本對比學習方法在對不同樣本關係採用相同的建模方法時，通常會忽略不同粒度下的語意相似性差異，這限制了少樣本對比學習的潛力。在本文中，我們介紹一種簡單但有效的對比學習方法，即多粒度關係對比學習 (MGRCL)，作為預訓練特徵學習模型，透過在不同粒度下仔細建模樣本關係來提升少樣本學習。MGRCL 將樣本關係分類為三種類型：同一樣本在不同轉換下的樣本內關係、同類樣本的類內關係，以及不同類樣本的類間關係。在 MGRCL 中，我們設計了轉換一致性學習 (TCL)，透過比對輸入對的預測，來確保樣本在不同轉換下的嚴謹語意一致性。此外，為了保留區辨性資訊，我們採用類對比學習 (CCL)，以確保樣本始終比其不同類樣本更接近其同類樣本，因為同類樣本具有相似的語意內容，而不同類樣本具有不同的語意內容。我們的模型在四個流行的 FSL 基準上進行評估，結果顯示這種簡單的預訓練特徵學習方法優於大多數領先的 FSL 方法。此外，我們的模型可以作為預訓練模型整合到其他 FSL 方法中，並幫助它們獲得顯著的效能提升。

##### **M3PT: A Transformer for Multimodal, Multi-Party Social Signal Prediction with Person-aware Blockwise Attention**
2501.13416v1 by Yiming Tang, Abrar Anwar, Jesse Thomason

Understanding social signals in multi-party conversations is important for
human-robot interaction and artificial social intelligence. Multi-party
interactions include social signals like body pose, head pose, speech, and
context-specific activities like acquiring and taking bites of food when
dining. Incorporating all the multimodal signals in a multi-party interaction
is difficult, and past work tends to build task-specific models for predicting
social signals. In this work, we address the challenge of predicting multimodal
social signals in multi-party settings in a single model. We introduce M3PT, a
causal transformer architecture with modality and temporal blockwise attention
masking which allows for the simultaneous processing of multiple social cues
across multiple participants and their temporal interactions. This approach
better captures social dynamics over time by considering longer horizons of
social signals between individuals. We train and evaluate our unified model on
the Human-Human Commensality Dataset (HHCD), and demonstrate that using
multiple modalities improves bite timing and speaking status prediction. Source
code: https://github.com/AbrarAnwar/masked-social-signals/

摘要：了解多方对话中的社交信号对于人机交互和人工智能至关重要。多方互动包括身体姿势、头部姿势、言语和特定环境活动（例如在用餐时获取和食用食物）等社交信号。在多方互动中整合所有多模态信号很困难，过去的工作倾向于构建特定任务的模型来预测社交信号。在这项工作中，我们解决了在单个模型中预测多方环境中的多模态社交信号的挑战。我们引入了 M3PT，一种因果转换器架构，具有模态和时间块状注意掩码，允许同时处理多个参与者及其时间交互中的多个社交线索。这种方法通过考虑个人之间更长时间范围的社交信号，可以更好地捕捉社交动态。我们在人际共餐数据集 (HHCD) 上训练和评估我们的统一模型，并证明使用多种模态可以改善咬合时间和说话状态预测。源代码：https://github.com/AbrarAnwar/masked-social-signals/

##### **Load and Renewable Energy Forecasting Using Deep Learning for Grid Stability**
2501.13412v1 by Kamal Sarkar

As the energy landscape changes quickly, grid operators face several
challenges, especially when integrating renewable energy sources with the grid.
The most important challenge is to balance supply and demand because the solar
and wind energy are highly unpredictable. When dealing with such uncertainty,
trustworthy short-term load and renewable energy forecasting can help stabilize
the grid, maximize energy storage, and guarantee the effective use of renewable
resources. Physical models and statistical techniques were the previous
approaches employed for this kind of forecasting tasks. In forecasting
renewable energy, machine learning and deep learning techniques have recently
demonstrated encouraging results. More specifically, the deep learning
techniques like CNN and LSTM and the conventional machine learning techniques
like regression that are mostly utilized for load and renewable energy
forecasting tasks. In this article, we will focus mainly on CNN and LSTM-based
forecasting methods.

摘要：隨著能源版圖快速變化，電網營運商面臨多項挑戰，特別是在將再生能源整合到電網時。
最重要的挑戰在於平衡供需，因為太陽能和風能高度不可預測。在應對這種不確定性時，可信賴的短期負載和再生能源預測有助於穩定電網、最大化儲能，並確保再生能源的有效利用。物理模型和統計技術是以前用於此類預測任務的方法。在預測再生能源方面，機器學習和深度學習技術最近已展現令人鼓舞的成果。更具體地說，深度學習技術（如 CNN 和 LSTM）和傳統機器學習技術（如回歸），這些技術主要用於負載和再生能源預測任務。在本文中，我們將主要關注基於 CNN 和 LSTM 的預測方法。

##### **YOLOv8 to YOLO11: A Comprehensive Architecture In-depth Comparative Review**
2501.13400v1 by Priyanto Hidayatullah, Nurjannah Syakrani, Muhammad Rizqi Sholahuddin, Trisna Gelar, Refdinal Tubagus

In the field of deep learning-based computer vision, YOLO is revolutionary.
With respect to deep learning models, YOLO is also the one that is evolving the
most rapidly. Unfortunately, not every YOLO model possesses scholarly
publications. Moreover, there exists a YOLO model that lacks a publicly
accessible official architectural diagram. Naturally, this engenders
challenges, such as complicating the understanding of how the model operates in
practice. Furthermore, the review articles that are presently available do not
delve into the specifics of each model. The objective of this study is to
present a comprehensive and in-depth architecture comparison of the four most
recent YOLO models, specifically YOLOv8 through YOLO11, thereby enabling
readers to quickly grasp not only how each model functions, but also the
distinctions between them. To analyze each YOLO version's architecture, we
meticulously examined the relevant academic papers, documentation, and
scrutinized the source code. The analysis reveals that while each version of
YOLO has improvements in architecture and feature extraction, certain blocks
remain unchanged. The lack of scholarly publications and official diagrams
presents challenges for understanding the model's functionality and future
enhancement. Future developers are encouraged to provide these resources.

摘要：在深度學習為基礎的電腦視覺領域，YOLO 是革命性的。
在深度學習模型中，YOLO 也是演進最快速的。遺憾的是，並非每個 YOLO 模型都有學術論文。此外，還有一個 YOLO 模型缺乏公開的官方架構圖。這自然會產生挑戰，例如使理解模型在實務中如何運作變得複雜。此外，目前可取得的評論文章並未深入探討每個模型的具體細節。本研究的目標是針對最近的四個 YOLO 模型，特別是 YOLOv8 到 YOLO11，提出一個全面的深入架構比較，進而讓讀者能夠快速掌握每個模型的功能，以及它們之間的差異。為了分析每個 YOLO 版本的架構，我們仔細審查相關的學術論文、文件，並仔細檢視原始碼。分析顯示，儘管每個版本的 YOLO 都在架構和特徵萃取上有改進，但某些區塊仍然不變。缺乏學術論文和官方圖表會對理解模型的功能和未來的強化造成挑戰。我們鼓勵未來的開發人員提供這些資源。

##### **ExLM: Rethinking the Impact of $\texttt{[MASK]}$ Tokens in Masked Language Models**
2501.13397v1 by Kangjie Zheng, Junwei Yang, Siyue Liang, Bin Feng, Zequn Liu, Wei Ju, Zhiping Xiao, Ming Zhang

Masked Language Models (MLMs) have achieved remarkable success in many
self-supervised representation learning tasks. MLMs are trained by randomly
replacing some tokens in the input sentences with $\texttt{[MASK]}$ tokens and
predicting the original tokens based on the remaining context. This paper
explores the impact of $\texttt{[MASK]}$ tokens on MLMs. Analytical studies
show that masking tokens can introduce the corrupted semantics problem, wherein
the corrupted context may convey multiple, ambiguous meanings. This problem is
also a key factor affecting the performance of MLMs on downstream tasks. Based
on these findings, we propose a novel enhanced-context MLM, ExLM. Our approach
expands $\texttt{[MASK]}$ tokens in the input context and models the
dependencies between these expanded states. This expansion increases context
capacity and enables the model to capture richer semantic information,
effectively mitigating the corrupted semantics problem during pre-training.
Experimental results demonstrate that ExLM achieves significant performance
improvements in both text modeling and SMILES modeling tasks. Further analysis
confirms that ExLM enhances semantic representations through context
enhancement, and effectively reduces the multimodality problem commonly
observed in MLMs.

摘要：蒙面語言模型（MLM）在許多自我監督表徵學習任務中取得顯著成功。MLM 的訓練方式是隨機用 [MASK] 標記取代輸入句子中的一些標記，並根據其餘的內容預測原始標記。本文探討了 [MASK] 標記對 MLM 的影響。分析研究顯示，遮蔽標記可能會引入語意損壞問題，其中損壞的內容可能會傳達多種含糊的意義。這個問題也是影響 MLM 在下游任務中表現的一個關鍵因素。根據這些發現，我們提出了一種新的增強內容 MLM，ExLM。我們的做法擴展了輸入內容中的 [MASK] 標記，並對這些擴展狀態之間的依賴關係進行建模。這種擴展增加了內容容量，並使模型能夠擷取更豐富的語義資訊，有效減輕預訓練期間的語意損壞問題。實驗結果證明，ExLM 在文本建模和 SMILES 建模任務中都取得了顯著的效能提升。進一步的分析證實，ExLM 透過內容增強來增強語義表徵，並有效減少了 MLM 中常見的多模態問題。

##### **Can Large Language Models Understand Preferences in Personalized Recommendation?**
2501.13391v1 by Zhaoxuan Tan, Zinan Zeng, Qingkai Zeng, Zhenyu Wu, Zheyuan Liu, Fengran Mo, Meng Jiang

Large Language Models (LLMs) excel in various tasks, including personalized
recommendations. Existing evaluation methods often focus on rating prediction,
relying on regression errors between actual and predicted ratings. However,
user rating bias and item quality, two influential factors behind rating
scores, can obscure personal preferences in user-item pair data. To address
this, we introduce PerRecBench, disassociating the evaluation from these two
factors and assessing recommendation techniques on capturing the personal
preferences in a grouped ranking manner. We find that the LLM-based
recommendation techniques that are generally good at rating prediction fail to
identify users' favored and disfavored items when the user rating bias and item
quality are eliminated by grouping users. With PerRecBench and 19 LLMs, we find
that while larger models generally outperform smaller ones, they still struggle
with personalized recommendation. Our findings reveal the superiority of
pairwise and listwise ranking approaches over pointwise ranking, PerRecBench's
low correlation with traditional regression metrics, the importance of user
profiles, and the role of pretraining data distributions. We further explore
three supervised fine-tuning strategies, finding that merging weights from
single-format training is promising but improving LLMs' understanding of user
preferences remains an open research problem. Code and data are available at
https://github.com/TamSiuhin/PerRecBench

摘要：大型語言模型 (LLM) 在各種任務中表現出色，包括個人化推薦。現有的評估方法通常專注於評分預測，依賴於實際評分和預測評分之間的回歸誤差。然而，使用者評分偏差和項目品質這兩個影響評分背後的因素，可能會模糊使用者-項目配對資料中的個人偏好。為了解決這個問題，我們引入了 PerRecBench，將評估與這兩個因素分離，並評估推薦技術以群組排名方式捕捉個人偏好。我們發現，基於 LLM 的推薦技術通常很擅長評分預測，但在群組使用者時無法識別使用者的偏好和不偏好的項目。使用 PerRecBench 和 19 個 LLM，我們發現雖然較大的模型通常優於較小的模型，但它們在個人化推薦方面仍然有困難。我們的研究結果揭示了成對和清單排名方法優於逐點排名、PerRecBench 與傳統回歸指標的低相關性、使用者個人資料的重要性以及預訓練資料分布的角色。我們進一步探討了三種監督微調策略，發現合併單一格式訓練的權重是有希望的，但改善 LLM 對使用者偏好的理解仍然是一個開放的研究問題。程式碼和資料可在 https://github.com/TamSiuhin/PerRecBench 取得

##### **Do as We Do, Not as You Think: the Conformity of Large Language Models**
2501.13381v1 by Zhiyuan Weng, Guikun Chen, Wenguan Wang

Recent advancements in large language models (LLMs) revolutionize the field
of intelligent agents, enabling collaborative multi-agent systems capable of
tackling complex problems across various domains. However, the potential of
conformity within these systems, analogous to phenomena like conformity bias
and groupthink in human group dynamics, remains largely unexplored, raising
concerns about their collective problem-solving capabilities and possible
ethical implications. This paper presents a comprehensive study on conformity
in LLM-driven multi-agent systems, focusing on three aspects: the existence of
conformity, the factors influencing conformity, and potential mitigation
strategies. In particular, we introduce BenchForm, a new conformity-oriented
benchmark, featuring reasoning-intensive tasks and five distinct interaction
protocols designed to probe LLMs' behavior in collaborative scenarios. Several
representative LLMs are evaluated on BenchForm, using metrics such as
conformity rate and independence rate to quantify conformity's impact. Our
analysis delves into factors influencing conformity, including interaction time
and majority size, and examines how the subject agent rationalizes its
conforming behavior. Furthermore, we explore two strategies to mitigate
conformity effects, i.e., developing enhanced personas and implementing a
reflection mechanism. Several interesting findings regarding LLMs' conformity
are derived from empirical results and case studies. We hope that these
insights can pave the way for more robust and ethically-aligned collaborative
AI systems. Our benchmark and code are available at BenchForm.

摘要：大型語言模型 (LLM) 的最新進展徹底革新了智慧代理領域，促成了協作式多重代理系統，能夠解決跨越各個領域的複雜問題。然而，這些系統內部一致性的潛力，類似於人類群體動態中的一致性偏誤和團體迷思等現象，仍未被廣泛探討，引發了對其集體問題解決能力和潛在道德影響的擔憂。本文針對 LLM 驅動的多重代理系統中的一致性進行全面研究，重點關注三個面向：一致性的存在、影響一致性的因素以及潛在的緩解策略。特別是，我們引入了 BenchForm，一個新的以一致性為導向的基準，具備推理密集型任務和五種不同的互動協定，旨在探討 LLM 在協作場景中的行為。使用一致性比率和獨立性比率等指標對 BenchForm 上的幾個具代表性的 LLM 進行評估，以量化一致性的影響。我們的分析深入探討了影響一致性的因素，包括互動時間和多數規模，並探討了主體代理如何合理化其一致性行為。此外，我們探討了減輕一致性影響的兩種策略，即開發增強的角色和實施反思機制。從實證結果和案例研究中得出了幾個關於 LLM 一致性的有趣發現。我們希望這些見解能為更強大且符合道德的協作式 AI 系統鋪路。我們的基準和程式碼可在 BenchForm 取得。

##### **Generative Data Augmentation Challenge: Zero-Shot Speech Synthesis for Personalized Speech Enhancement**
2501.13372v1 by Jae-Sung Bae, Anastasia Kuznetsova, Dinesh Manocha, John Hershey, Trausti Kristjansson, Minje Kim

This paper presents a new challenge that calls for zero-shot text-to-speech
(TTS) systems to augment speech data for the downstream task, personalized
speech enhancement (PSE), as part of the Generative Data Augmentation workshop
at ICASSP 2025. Collecting high-quality personalized data is challenging due to
privacy concerns and technical difficulties in recording audio from the test
scene. To address these issues, synthetic data generation using generative
models has gained significant attention. In this challenge, participants are
tasked first with building zero-shot TTS systems to augment personalized data.
Subsequently, PSE systems are asked to be trained with this augmented
personalized dataset. Through this challenge, we aim to investigate how the
quality of augmented data generated by zero-shot TTS models affects PSE model
performance. We also provide baseline experiments using open-source zero-shot
TTS models to encourage participation and benchmark advancements. Our baseline
code implementation and checkpoints are available online.

摘要：這篇論文提出了新的挑戰，呼籲零次學習文字轉語音 (TTS) 系統擴增下游任務的語音資料，也就是個人化語音增強 (PSE)，作為 ICASSP 2025 生成資料擴充工作坊的一部分。由於隱私問題和錄製測試場景音訊的技術難度，收集高品質的個人化資料是一項挑戰。為了解決這些問題，使用生成模型進行合成資料生成備受關注。在這個挑戰中，參與者首先被要求建構零次學習 TTS 系統以擴增個人化資料。隨後，要求 PSE 系統使用這個擴增的個人化資料集進行訓練。透過這個挑戰，我們旨在探討零次學習 TTS 模型生成的擴增資料品質如何影響 PSE 模型的效能。我們也提供使用開放原始碼零次學習 TTS 模型的基準實驗，以鼓勵參與和基準進展。我們的基準程式碼實作和檢查點可於線上取得。

##### **A review on development of eco-friendly filters in Nepal for use in cigarettes and masks and Air Pollution Analysis with Machine Learning and SHAP Interpretability**
2501.13369v1 by Bishwash Paneru, Biplov Paneru, Tanka Mukhiya, Khem Narayan Poudyal

In Nepal, air pollution is a serious public health concern, especially in
cities like Kathmandu where particulate matter (PM2.5 and PM10) has a major
influence on respiratory health and air quality. The Air Quality Index (AQI) is
predicted in this work using a Random Forest Regressor, and the model's
predictions are interpreted using SHAP (SHapley Additive exPlanations)
analysis. With the lowest Testing RMSE (0.23) and flawless R2 scores (1.00),
CatBoost performs better than other models, demonstrating its greater accuracy
and generalization which is cross validated using a nested cross validation
approach. NowCast Concentration and Raw Concentration are the most important
elements influencing AQI values, according to SHAP research, which shows that
the machine learning results are highly accurate. Their significance as major
contributors to air pollution is highlighted by the fact that high values of
these characteristics significantly raise the AQI. This study investigates the
Hydrogen-Alpha (HA) biodegradable filter as a novel way to reduce the related
health hazards. With removal efficiency of more than 98% for PM2.5 and 99.24%
for PM10, the HA filter offers exceptional defense against dangerous airborne
particles. These devices, which are biodegradable face masks and cigarette
filters, address the environmental issues associated with traditional filters'
non-biodegradable trash while also lowering exposure to air contaminants.

摘要：在尼泊爾，空氣污染是一個嚴重的公共衛生問題，特別是在加德滿都等城市，那裡的懸浮微粒（PM2.5 和 PM10）對呼吸系統健康和空氣品質有重大影響。這項工作使用隨機森林回歸器預測空氣品質指數 (AQI)，並使用 SHAP（SHapley 加法解釋）分析來解釋模型的預測。CatBoost 的測試 RMSE 最低（0.23），R2 分數完美（1.00），表現優於其他模型，證明其具有更高的準確性和泛化性，並使用嵌套交叉驗證方法進行交叉驗證。根據 SHAP 研究，現在濃度和原始濃度是影響 AQI 值最重要的元素，這表明機器學習結果非常準確。它們作為空氣污染的主要貢獻者的重要性在於，這些特徵的高值會顯著提高 AQI。本研究探討了氫-α（HA）可生物降解過濾器作為減少相關健康危害的一種新方法。HA 過濾器對 PM2.5 的去除效率超過 98%，對 PM10 的去除效率超過 99.24%，可提供防範危險空氣懸浮微粒的出色防護。這些可生物降解口罩和香菸過濾器的裝置解決了傳統過濾器不可生物降解垃圾相關的環境問題，同時也降低了接觸空氣污染物的風險。

##### **Enhanced Extractor-Selector Framework and Symmetrization Weighted Binary Cross-Entropy for Edge Detections**
2501.13365v1 by Hao Shu

Recent advancements have demonstrated the effectiveness of the
extractor-selector (E-S) framework in edge detection (ED) tasks, which achieves
state-of-the-art (SOTA) performance in both quantitative metrics and perceptual
quality. However, this method still falls short of fully exploiting the
potential of feature extractors, as selectors only operate on highly compressed
feature maps that lack diversity and suffer from substantial information loss.
Additionally, while union training can improve perceptual quality, the highest
evaluation scores are typically obtained without it, creating a trade-off
between quantitative accuracy and perceptual fidelity. To address these
limitations, we propose an enhanced E-S architecture, which utilizes richer,
less-loss feature representations and incorporates auxiliary features during
the selection process, thereby improving the effectiveness of the feature
selection mechanism. Additionally, we introduce a novel loss function, the
Symmetrization Weight Binary Cross-Entropy (SWBCE), which simultaneously
emphasizes both the recall of edge pixels and the suppression of erroneous edge
predictions, thereby enhancing the predictions both in the perceptual quality
and the prediction accuracy. The effectiveness and superiority of our
approaches over baseline models, the standard E-S framework, and the standard
Weight Binary Cross-Entropy (WBCE) loss function are demonstrated by extensive
experiments. For example, our enhanced E-S architecture trained with SWBCE loss
function achieves average improvements of 8.25$\%$, 8.01$\%$, and 33.25$\%$ in
ODS, OIS, and AP, measured on BIPED2 compared with the baseline models,
significantly outperforming the standard E-S method. The results set new
benchmarks for ED tasks, and highlight the potential of the methods in beyond.

摘要：<paragraph>最近的进步展示了提取器-选择器 (E-S) 框架在边缘检测 (ED) 任务中的有效性，在定量指标和感知质量方面都取得了最先进 (SOTA) 的性能。然而，这种方法仍然没有充分利用特征提取器的潜力，因为选择器只作用于高度压缩的特征图，这些特征图缺乏多样性并遭受大量信息丢失。此外，虽然联合训练可以提高感知质量，但通常在没有联合训练的情况下获得最高评估分数，从而在定量准确性和感知保真度之间形成权衡。为了解决这些限制，我们提出了一种增强的 E-S 架构，它利用更丰富、更少损失的特征表示，并在选择过程中纳入辅助特征，从而提高了特征选择机制的有效性。此外，我们引入了一种新颖的损失函数，即对称加权二元交叉熵 (SWBCE)，它同时强调了边缘像素的召回和错误边缘预测的抑制，从而在感知质量和预测准确性方面都增强了预测。通过广泛的实验，证明了我们方法相对于基线模型、标准 E-S 框架和标准加权二元交叉熵 (WBCE) 损失函数的有效性和优越性。例如，我们使用 SWBCE 损失函数训练的增强型 E-S 架构在 ODS、OIS 和 AP 中实现了 8.25%、8.01% 和 33.25% 的平均改进，与基线模型相比，在 BIPED2 上测量，明显优于标准 E-S 方法。结果为 ED 任务设定了新的基准，并突出了这些方法在其他领域的潜力。</paragraph>

##### **One Fits All: General Mobility Trajectory Modeling via Masked Conditional Diffusion**
2501.13347v1 by Qingyue Long, Can Rong, Huandong Wang, Yong Li

Trajectory data play a crucial role in many applications, ranging from
network optimization to urban planning. Existing studies on trajectory data are
task-specific, and their applicability is limited to the specific tasks on
which they have been trained, such as generation, recovery, or prediction.
However, the potential of a unified model has not yet been fully explored in
trajectory modeling. Although various trajectory tasks differ in inputs,
outputs, objectives, and conditions, they share common mobility patterns. Based
on these common patterns, we can construct a general framework that enables a
single model to address different tasks. However, building a trajectory
task-general framework faces two critical challenges: 1) the diversity in the
formats of different tasks and 2) the complexity of the conditions imposed on
different tasks. In this work, we propose a general trajectory modeling
framework via masked conditional diffusion (named GenMove). Specifically, we
utilize mask conditions to unify diverse formats. To adapt to complex
conditions associated with different tasks, we utilize historical trajectory
data to obtain contextual trajectory embeddings, which include rich contexts
such as spatiotemporal characteristics and user preferences. Integrating the
contextual trajectory embedding into diffusion models through a classifier-free
guidance approach allows the model to flexibly adjust its outputs based on
different conditions. Extensive experiments on mainstream tasks demonstrate
that our model significantly outperforms state-of-the-art baselines, with the
highest performance improvement exceeding 13% in generation tasks.

摘要：軌跡資料在許多應用中扮演關鍵角色，從網路最佳化到都市規劃皆然。現有的軌跡資料研究為特定任務而設計，其適用性僅限於其受過訓練的特定任務，例如產生、恢復或預測。然而，統一模型的潛力尚未在軌跡建模中得到充分探索。儘管各種軌跡任務在輸入、輸出、目標和條件上有所不同，但它們共享通用的移動模式。基於這些共同模式，我們可以建構一個通用框架，讓單一模型能夠處理不同的任務。然而，建立一個軌跡任務通用框架面臨兩個關鍵挑戰：1）不同任務格式的多樣性，以及 2）對不同任務施加的條件的複雜性。在這項工作中，我們透過遮罩條件擴散（稱為 GenMove）提出一個通用的軌跡建模框架。具體來說，我們利用遮罩條件來統一多樣化的格式。為了適應與不同任務相關的複雜條件，我們利用歷史軌跡資料來獲取脈絡軌跡嵌入，其中包含豐富的脈絡，例如時空特徵和使用者偏好。透過分類器自由引導方法將脈絡軌跡嵌入整合到擴散模型中，讓模型能夠根據不同的條件靈活調整其輸出。在主流任務上的廣泛實驗證明，我們的模型顯著優於最先進的基準，在產生任務中的最高效能提升超過 13%。

##### **Full-Stack Optimized Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation**
2501.13344v1 by Rong Shan, Jiachen Zhu, Jianghao Lin, Chenxu Zhu, Bo Chen, Ruiming Tang, Yong Yu, Weinan Zhang

In this paper, we address the lifelong sequential behavior incomprehension
problem in large language models (LLMs) for recommendation, where LLMs struggle
to extract useful information from long user behavior sequences, even within
their context limits. To tackle this, we propose ReLLaX (Retrieval-enhanced
Large Language models Plus), a framework offering optimization across data,
prompt, and parameter levels. At the data level, we introduce Semantic User
Behavior Retrieval (SUBR) to reduce sequence heterogeneity, making it easier
for LLMs to extract key information. For prompt-level enhancement, we employ
Soft Prompt Augmentation (SPA) to inject collaborative knowledge, aligning item
representations with recommendation tasks and improving LLMs's exploration of
item relationships. Finally, at the parameter level, we propose Component
Fully-interactive LoRA (CFLoRA), which enhances LoRA's expressiveness by
enabling interactions between its components, allowing better capture of
sequential information. Moreover, we present new perspectives to compare
current LoRA-based LLM4Rec methods, i.e. from both a composite and a decomposed
view. We theoretically demonstrate that the ways they employ LoRA for
recommendation are degraded versions of our CFLoRA, with different constraints
on atom component interactions. Extensive experiments on three public datasets
demonstrate ReLLaX's superiority over existing baselines and its ability to
mitigate lifelong sequential behavior incomprehension effectively.

摘要：<paragraph>在本文中，我們探討了推薦中大型語言模型 (LLM) 中的終生順序行為難以理解的問題，其中 LLM 難以從長用戶行為序列中提取有用的資訊，即使在它們的內容限制內也是如此。為了解決這個問題，我們提出了 ReLLaX（檢索增強型大型語言模型 Plus），一個提供跨資料、提示和參數層級最佳化的架構。在資料層級，我們引入了語義使用者行為檢索 (SUBR) 以減少序列異質性，讓 LLM 更容易提取關鍵資訊。對於提示層級的增強，我們採用了軟提示擴充 (SPA) 來注入協作知識，將項目表示與推薦任務對齊，並改善 LLM 對項目關係的探索。最後，在參數層級，我們提出了組件完全互動 LoRA (CFLoRA)，它透過啟用其組件之間的互動來增強 LoRA 的表達力，從而可以更好地擷取順序資訊。此外，我們提出了新的觀點來比較目前的基於 LoRA 的 LLM4Rec 方法，即從複合和分解的觀點來看。我們在理論上證明了它們使用 LoRA 進行推薦的方式是我們 CFLoRA 的簡化版本，對原子組件互動有不同的限制。在三個公開資料集上進行的大量實驗證明了 ReLLaX 優於現有的基準，並且能夠有效地緩解終生的順序行為難以理解的問題。</paragraph>

##### **AgentRec: Agent Recommendation Using Sentence Embeddings Aligned to Human Feedback**
2501.13333v1 by Joshua Park, Yongfeng Zhang

Multi-agent systems must decide which agent is the most appropriate for a
given task. We propose a novel architecture for recommending which LLM agent
out of many should perform a task given a natural language prompt by extending
the Sentence-BERT (SBERT) encoder model. On test data, we are able to achieve a
top-1 accuracy of 92.2% with each classification taking less than 300
milliseconds. In contrast to traditional classification methods, our
architecture is computationally cheap, adaptive to new classes, interpretable,
and controllable with arbitrary metrics through reinforcement learning. By
encoding natural language prompts into sentence embeddings, our model captures
the semantic content relevant to recommending an agent. The distance between
sentence embeddings that belong to the same agent is then minimized through
fine-tuning and aligned to human values through reinforcement learning from
human feedback. This allows the classification of natural language prompts
based on their nearest neighbors by measuring the cosine similarity between
embeddings. This work is made possible through the generation of a synthetic
dataset for agent recommendation, which we have open-sourced to the public
along with the code for AgentRec recommendation system at
https://github.com/joshprk/agentrec.

摘要：多智能體系統必須決定哪個智能體最適合執行某項任務。我們提出了一種新的架構，用於推薦在給定自然語言提示的情況下，眾多 LLM 智能體中的哪一個應該執行任務，方法是擴展 Sentence-BERT (SBERT) 編碼器模型。在測試數據上，我們能夠實現 92.2% 的前 1 名準確率，每次分類花費不到 300 毫秒。與傳統分類方法相比，我們的架構在計算上成本低廉，適應新類別，可解釋，並且可通過強化學習使用任意指標進行控制。通過將自然語言提示編碼為句子嵌入，我們的模型捕獲了與推薦智能體相關的語義內容。然後，通過微調和通過人類反饋的強化學習與人類價值觀保持一致，最小化屬於同一個智能體的句子嵌入之間的距離。這允許基於它們最近的鄰居對自然語言提示進行分類，方法是測量嵌入之間的餘弦相似度。這項工作是通過生成一個用於智能體推薦的合成數據集而得以實現的，我們已將其與 AgentRec 推薦系統的代碼一起公開，網址為 https://github.com/joshprk/agentrec。

##### **Sparse identification of nonlinear dynamics and Koopman operators with Shallow Recurrent Decoder Networks**
2501.13329v1 by Mars Liyao Gao, Jan P. Williams, J. Nathan Kutz

Spatiotemporal modeling of real-world data poses a challenging problem due to
inherent high dimensionality, measurement noise, and expensive data collection
procedures. In this paper, we present Sparse Identification of Nonlinear
Dynamics with SHallow REcurrent Decoder networks (SINDy-SHRED), a method to
jointly solve the sensing and model identification problems with simple
implementation, efficient computation, and robust performance. SINDy-SHRED uses
Gated Recurrent Units (GRUs) to model the temporal sequence of sensor
measurements along with a shallow decoder network to reconstruct the full
spatiotemporal field from the latent state space using only a few available
sensors. Our proposed algorithm introduces a SINDy-based regularization;
beginning with an arbitrary latent state space, the dynamics of the latent
space progressively converges to a SINDy-class functional, provided the
projection remains within the set. In restricting SINDy to a linear model, the
architecture produces a Koopman-SHRED model which enforces a linear latent
space dynamics. We conduct a systematic experimental study including synthetic
PDE data, real-world sensor measurements for sea surface temperature, and
direct video data. With no explicit encoder, SINDy-SHRED and Koopman-SHRED
enable efficient training with minimal hyperparameter tuning and laptop-level
computing; further, it demonstrates robust generalization in a variety of
applications with minimal to no hyperparameter adjustments. Finally, the
interpretable SINDy and Koopman models of latent state dynamics enables
accurate long-term video predictions, achieving state-of-the-art performance
and outperforming all baseline methods considered, including Convolutional
LSTM, PredRNN, ResNet, and SimVP.

摘要：<paragraph>時空模型化真實世界資料由於固有的高維度、量測雜訊和昂貴的資料收集程序而構成一個具有挑戰性的問題。在本文中，我們提出非線性動力學的稀疏辨識與淺層遞迴解碼器網路 (SINDy-SHRED)，一種方法以簡單的實作、有效率的運算和穩健的效能來共同解決感測和模型辨識問題。SINDy-SHRED 使用門控遞迴單元 (GRU) 來對感測器量測的時間序列進行建模，並搭配一個淺層解碼器網路來使用僅有的幾個可用感測器從潛在狀態空間重建完整的時空場域。我們提出的演算法引入了一個基於 SINDy 的正則化；從一個任意潛在狀態空間開始，潛在空間的動態會逐漸收斂到一個 SINDy 類型的函數，只要投影仍然在集合中。在將 SINDy 限制為線性模型時，此架構會產生一個 Koopman-SHRED 模型，它強制執行線性潛在空間動態。我們進行了一項系統性的實驗研究，包括合成偏微分方程式資料、海面溫度真實世界感測器量測，以及直接影片資料。SINDy-SHRED 和 Koopman-SHRED 沒有明確的編碼器，能夠以最少的超參數調整和筆記型電腦等級的運算進行有效率的訓練；此外，它在各種應用中展現出穩健的泛化能力，幾乎不需要調整超參數。最後，潛在狀態動態的可解釋 SINDy 和 Koopman 模型能夠進行準確的長期影片預測，達到最先進的效能，並且優於所有考量的基準方法，包括卷積 LSTM、PredRNN、ResNet 和 SimVP。</paragraph>

##### **Investigation of the Privacy Concerns in AI Systems for Young Digital Citizens: A Comparative Stakeholder Analysis**
2501.13321v1 by Molly Campbell, Ankur Barthwal, Sandhya Joshi, Austin Shouli, Ajay Kumar Shrestha

The integration of Artificial Intelligence (AI) systems into technologies
used by young digital citizens raises significant privacy concerns. This study
investigates these concerns through a comparative analysis of stakeholder
perspectives. A total of 252 participants were surveyed, with the analysis
focusing on 110 valid responses from parents/educators and 100 from AI
professionals after data cleaning. Quantitative methods, including descriptive
statistics and Partial Least Squares Structural Equation Modeling, examined
five validated constructs: Data Ownership and Control, Parental Data Sharing,
Perceived Risks and Benefits, Transparency and Trust, and Education and
Awareness. Results showed Education and Awareness significantly influenced data
ownership and risk assessment, while Data Ownership and Control strongly
impacted Transparency and Trust. Transparency and Trust, along with Perceived
Risks and Benefits, showed minimal influence on Parental Data Sharing,
suggesting other factors may play a larger role. The study underscores the need
for user-centric privacy controls, tailored transparency strategies, and
targeted educational initiatives. Incorporating diverse stakeholder
perspectives offers actionable insights into ethical AI design and governance,
balancing innovation with robust privacy protections to foster trust in a
digital age.

摘要：人工智慧 (AI) 系統整合到年輕數位公民所使用的技術中，引發了重大的隱私問題。本研究透過比較分析利害關係人的觀點來探討這些問題。總共調查了 252 位參與者，分析重點在於資料清理後，來自父母/教育工作者的 110 份有效回應，以及來自 AI 專業人士的 100 份回應。定量方法，包括描述性統計和偏最小平方法結構方程模型，檢驗了五個已驗證的構念：資料所有權和控制、父母資料共享、認知風險和利益、透明度和信任，以及教育和意識。結果顯示，教育和意識顯著影響資料所有權和風險評估，而資料所有權和控制則強烈影響透明度和信任。透明度和信任，以及認知風險和利益，對父母資料共享的影響很小，這表示其他因素可能發揮更大的作用。本研究強調了以使用者為中心的隱私控制、量身打造的透明度策略，以及有針對性的教育計畫的必要性。納入不同的利害關係人觀點，提供了可行的見解，用於道德 AI 設計和治理，在創新與強大的隱私保護之間取得平衡，以建立數位時代的信任。

##### **Watching the AI Watchdogs: A Fairness and Robustness Analysis of AI Safety Moderation Classifiers**
2501.13302v1 by Akshit Achara, Anshuman Chhabra

AI Safety Moderation (ASM) classifiers are designed to moderate content on
social media platforms and to serve as guardrails that prevent Large Language
Models (LLMs) from being fine-tuned on unsafe inputs. Owing to their potential
for disparate impact, it is crucial to ensure that these classifiers: (1) do
not unfairly classify content belonging to users from minority groups as unsafe
compared to those from majority groups and (2) that their behavior remains
robust and consistent across similar inputs. In this work, we thus examine the
fairness and robustness of four widely-used, closed-source ASM classifiers:
OpenAI Moderation API, Perspective API, Google Cloud Natural Language (GCNL)
API, and Clarifai API. We assess fairness using metrics such as demographic
parity and conditional statistical parity, comparing their performance against
ASM models and a fair-only baseline. Additionally, we analyze robustness by
testing the classifiers' sensitivity to small and natural input perturbations.
Our findings reveal potential fairness and robustness gaps, highlighting the
need to mitigate these issues in future versions of these models.

摘要：AI 安全審核 (ASM) 分類器旨在審核社群媒體平台上的內容，並作為護欄，防止大型語言模型 (LLM) 在不安全的輸入上進行微調。由於它們具有產生不同影響的潛力，因此確保這些分類器至關重要：(1) 與多數群體相比，不會不公平地將少數群體使用者的內容分類為不安全，(2) 它們的行為在類似的輸入中保持穩健且一致。因此，在這項工作中，我們檢查了四個廣泛使用的閉源 ASM 分類器的公平性和穩健性：OpenAI Moderation API、Perspective API、Google Cloud Natural Language (GCNL) API 和 Clarifai API。我們使用人口統計同質性和條件統計同質性等指標評估公平性，並將其效能與 ASM 模型和僅公平的基準進行比較。此外，我們通過測試分類器對小型且自然的輸入擾動的敏感性來分析穩健性。我們的研究結果揭示了潛在的公平性和穩健性差距，突顯了在這些模型的未來版本中減輕這些問題的必要性。

##### **Hypothesis Generation for Materials Discovery and Design Using Goal-Driven and Constraint-Guided LLM Agents**
2501.13299v1 by Shrinidhi Kumbhar, Venkatesh Mishra, Kevin Coutinho, Divij Handa, Ashif Iquebal, Chitta Baral

Materials discovery and design are essential for advancing technology across
various industries by enabling the development of application-specific
materials. Recent research has leveraged Large Language Models (LLMs) to
accelerate this process. We explore the potential of LLMs to generate viable
hypotheses that, once validated, can expedite materials discovery.
Collaborating with materials science experts, we curated a novel dataset from
recent journal publications, featuring real-world goals, constraints, and
methods for designing real-world applications. Using this dataset, we test
LLM-based agents that generate hypotheses for achieving given goals under
specific constraints. To assess the relevance and quality of these hypotheses,
we propose a novel scalable evaluation metric that emulates the process a
materials scientist would use to evaluate a hypothesis critically. Our curated
dataset, proposed method, and evaluation framework aim to advance future
research in accelerating materials discovery and design with LLMs.

摘要：材料發現和設計對於推進各行各業的技術至關重要，因為它能促進特定應用材料的開發。最近的研究利用大型語言模型 (LLM) 來加速此過程。我們探索 LLM 產生可行假設的潛力，一旦驗證，就能加速材料發現。我們與材料科學專家合作，從最近的期刊出版物中策劃了一個新穎的數據集，其中包含設計實際應用程式的實際目標、限制和方法。使用此數據集，我們測試了 LLM 基礎代理，這些代理會產生假設，以在特定限制下實現既定目標。為了評估這些假設的相關性和品質，我們提出了一種新穎的可擴充評估指標，模擬材料科學家用來批判性評估假設的過程。我們策劃的數據集、提出的方法和評估架構旨在推進未來在使用 LLM 加速材料發現和設計方面的研究。

##### **RAMQA: A Unified Framework for Retrieval-Augmented Multi-Modal Question Answering**
2501.13297v1 by Yang Bai, Christan Earl Grant, Daisy Zhe Wang

Multi-modal retrieval-augmented Question Answering (MRAQA), integrating text
and images, has gained significant attention in information retrieval (IR) and
natural language processing (NLP). Traditional ranking methods rely on small
encoder-based language models, which are incompatible with modern decoder-based
generative large language models (LLMs) that have advanced various NLP tasks.
To bridge this gap, we propose RAMQA, a unified framework combining
learning-to-rank methods with generative permutation-enhanced ranking
techniques. We first train a pointwise multi-modal ranker using LLaVA as the
backbone. Then, we apply instruction tuning to train a LLaMA model for
re-ranking the top-k documents using an innovative autoregressive multi-task
learning approach. Our generative ranking model generates re-ranked document
IDs and specific answers from document candidates in various permutations.
Experiments on two MRAQA benchmarks, WebQA and MultiModalQA, show significant
improvements over strong baselines, highlighting the effectiveness of our
approach. Code and data are available at: https://github.com/TonyBY/RAMQA

摘要：多模态检索增强型问答 (MRAQA) 集成文本和图像，在信息检索 (IR) 和自然语言处理 (NLP) 中备受关注。传统排名方法依赖于小型编码器语言模型，这与先进的各种 NLP 任务的现代解码器语言模型 (LLM) 不兼容。为了弥合这一差距，我们提出了 RAMQA，一个将学习排序方法与生成置换增强排序技术相结合的统一框架。我们首先使用 LLaVA 作为主干训练一个点式多模态排序器。然后，我们应用指令微调来训练一个 LLaMA 模型，使用创新的自回归多任务学习方法对前 k 个文档进行重新排序。我们的生成式排序模型从文档候选者中生成重新排序的文档 ID 和特定答案，排列方式多种多样。在两个 MRAQA 基准 WebQA 和 MultiModalQA 上的实验表明，与强大的基准相比有显著的改进，突出了我们方法的有效性。代码和数据可在以下网址获得：https://github.com/TonyBY/RAMQA

##### **Parallel Belief Contraction via Order Aggregation**
2501.13295v1 by Jake Chandler, Richard Booth

The standard ``serial'' (aka ``singleton'') model of belief contraction
models the manner in which an agent's corpus of beliefs responds to the removal
of a single item of information. One salient extension of this model introduces
the idea of ``parallel'' (aka ``package'' or ``multiple'') change, in which an
entire set of items of information are simultaneously removed. Existing
research on the latter has largely focussed on single-step parallel
contraction: understanding the behaviour of beliefs after a single parallel
contraction. It has also focussed on generalisations to the parallel case of
serial contraction operations whose characteristic properties are extremely
weak. Here we consider how to extend serial contraction operations that obey
stronger properties. Potentially more importantly, we also consider the
iterated case: the behaviour of beliefs after a sequence of parallel
contractions. We propose a general method for extending serial iterated belief
change operators to handle parallel change based on an n-ary generalisation of
Booth & Chandler's TeamQueue binary order aggregators.

摘要：標準的「序列」（又稱「單例」）信念收縮模型模擬代理信念語料庫對單一資訊項目移除的反應方式。此模型的一個顯著延伸引入了「平行」（又稱「封包」或「多重」）變化的概念，其中同時移除一整組資訊項目。後續的研究主要集中在單步平行收縮：了解信念在單次平行收縮後的行為。它也集中於序列收縮運算的平行情況的概括，其特徵屬性極為薄弱。在此，我們考慮如何擴充服從更強屬性的序列收縮運算。潛在更重要的是，我們也考慮了反覆的情況：信念在平行收縮序列後的行為。我們提出了一種通用方法，用於擴充序列反覆信念變更運算子，以處理基於 Booth & Chandler 的 TeamQueue 二元順序彙總器的 n 元概括的平行變更。

##### **Toyteller: AI-powered Visual Storytelling Through Toy-Playing with Character Symbols**
2501.13284v1 by John Joon Young Chung, Melissa Roemmele, Max Kreminski

We introduce Toyteller, an AI-powered storytelling system where users
generate a mix of story text and visuals by directly manipulating character
symbols like they are toy-playing. Anthropomorphized symbol motions can convey
rich and nuanced social interactions; Toyteller leverages these motions (1) to
let users steer story text generation and (2) as a visual output format that
accompanies story text. We enabled motion-steered text generation and
text-steered motion generation by mapping motions and text onto a shared
semantic space so that large language models and motion generation models can
use it as a translational layer. Technical evaluations showed that Toyteller
outperforms a competitive baseline, GPT-4o. Our user study identified that
toy-playing helps express intentions difficult to verbalize. However, only
motions could not express all user intentions, suggesting combining it with
other modalities like language. We discuss the design space of toy-playing
interactions and implications for technical HCI research on human-AI
interaction.

摘要：我們推出 Toyteller，這是一個由 AI 驅動的故事敘述系統，使用者可透過直接操作角色符號，就像玩玩具一樣，來產生故事文字和視覺效果的組合。擬人化的符號動作可以傳達豐富且細微的社交互動；Toyteller 利用這些動作 (1) 讓使用者引導故事文字產生，以及 (2) 作為伴隨故事文字的視覺輸出格式。我們透過將動作和文字對應到一個共用的語義空間，來啟用動作引導的文字產生和文字引導的動作產生，以便大型語言模型和動作產生模型可以使用它作為轉譯層。技術評估顯示 Toyteller 優於競爭基準 GPT-4o。我們的使用者研究發現，玩玩具有助於表達難以用言語表達的意圖。然而，僅靠動作無法表達所有使用者的意圖，這表示需要將其與語言等其他方式結合。我們討論了玩玩具互動的設計空間，以及對人類與 AI 互動技術 HCI 研究的影響。

##### **Experience with GitHub Copilot for Developer Productivity at Zoominfo**
2501.13282v1 by Gal Bakal, Ali Dasdan, Yaniv Katz, Michael Kaufman, Guy Levin

This paper presents a comprehensive evaluation of GitHub Copilot's deployment
and impact on developer productivity at Zoominfo, a leading Go-To-Market (GTM)
Intelligence Platform. We describe our systematic four-phase approach to
evaluating and deploying GitHub Copilot across our engineering organization,
involving over 400 developers. Our analysis combines both quantitative metrics,
focusing on acceptance rates of suggestions given by GitHub Copilot and
qualitative feedback given by developers through developer satisfaction
surveys. The results show an average acceptance rate of 33% for suggestions and
20% for lines of code, with high developer satisfaction scores of 72%. We also
discuss language-specific performance variations, limitations, and lessons
learned from this medium-scale enterprise deployment. Our findings contribute
to the growing body of knowledge about AI-assisted software development in
enterprise settings.

摘要：本文全面評估了 GitHub Copilot 的部署情況，以及其對 Zoominfo 開發人員生產力的影響，Zoominfo 是領先的市場推廣 (GTM) 情報平台。我們說明了系統性的四階段方法，以評估和部署 GitHub Copilot 到我們的工程組織，其中涉及 400 多位開發人員。我們的分析結合了量化指標，重點關注 GitHub Copilot 給出的建議的接受率，以及開發人員透過開發人員滿意度調查給出的定性回饋。結果顯示，建議的平均接受率為 33%，程式碼行的接受率為 20%，開發人員滿意度得分高達 72%。我們也討論了特定語言的效能差異、限制，以及從這個中型企業部署中學到的教訓。我們的發現有助於擴充企業設定中 AI 輔助軟體開發的知識體系。

##### **RAG-Reward: Optimizing RAG with Reward Modeling and RLHF**
2501.13264v1 by Hanning Zhang, Juntong Song, Juno Zhu, Yuanhao Wu, Tong Zhang, Cheng Niu

Retrieval-augmented generation (RAG) enhances Large Language Models (LLMs)
with relevant and up-to-date knowledge, improving their ability to answer
knowledge-intensive questions. It has been shown to enhance both generation
quality and trustworthiness. While numerous works have focused on improving
retrieval, generation, and evaluation, the role of reward models in
reinforcement learning for optimizing RAG and establishing automated
benchmarking pipelines remains underexplored. In this paper, we introduce
\textbf{RAG-Reward}, a dataset designed to enable \textit{hallucination-free,
comprehensive, reliable, and efficient RAG}. We define four key metrics for
assessing generation quality and develop an automated annotation pipeline that
leverages multiple LLMs to generate outputs across diverse RAG scenarios.
GPT-4o is used to evaluate and construct preference data. Using
\textbf{RAG-Reward}, we train reward models and apply reinforcement learning
with human feedback (RLHF) to improve LLMs' effectiveness in RAG. Experimental
results show that our reward model achieves state-of-the-art performance on a
held-out test set, demonstrating both the effectiveness of our approach and the
quality of our dataset. Furthermore, the improved generation quality of the
trained policy model highlights the feasibility of using RLHF to enhance RAG
pipelines.

摘要：<paragraph>撷取增强生成（RAG）强化大型语言模型（LLM）
具备相关且最新的知识，提升其回答知识密集型问题的能耐。它已被证明能同时强化生成
质量和可信度。虽然许多研究专注于改进撷取、生成和评估，但奖励模型在
强化学习中扮演的角色，以优化 RAG 和建立自动化基准管道仍未受到充分探索。在本文中，我们介绍
\textbf{RAG-Reward}，一个数据集旨在实现\textit{无幻觉、全面、可靠且高效的 RAG}。我们定义了四个关键指标来
评估生成质量，并开发了一个自动化注释管道，利用多个 LLM 在不同的 RAG 场景中生成输出。
GPT-4o 用于评估和构建偏好数据。使用
\textbf{RAG-Reward}，我们训练奖励模型并应用强化学习
结合人类反馈（RLHF）来提升 LLM 在 RAG 中的有效性。实验
结果显示我们的奖励模型在留存测试集上实现了最先进的性能，证明了我们方法的有效性以及
我们数据集的质量。此外，训练好的策略模型的生成质量提升突显了使用 RLHF 增强 RAG
管道的可行性。</paragraph>

##### **Let SSMs be ConvNets: State-space Modeling with Optimal Tensor Contractions**
2501.13230v1 by Yan Ru Pei

We introduce Centaurus, a class of networks composed of generalized
state-space model (SSM) blocks, where the SSM operations can be treated as
tensor contractions during training. The optimal order of tensor contractions
can then be systematically determined for every SSM block to maximize training
efficiency. This allows more flexibility in designing SSM blocks beyond the
depthwise-separable configuration commonly implemented. The new design choices
will take inspiration from classical convolutional blocks including group
convolutions, full convolutions, and bottleneck blocks. We architect the
Centaurus network with a mixture of these blocks, to balance between network
size and performance, as well as memory and computational efficiency during
both training and inference. We show that this heterogeneous network design
outperforms its homogeneous counterparts in raw audio processing tasks
including keyword spotting, speech denoising, and automatic speech recognition
(ASR). For ASR, Centaurus is the first network with competitive performance
that can be made fully state-space based, without using any nonlinear
recurrence (LSTMs), explicit convolutions (CNNs), or (surrogate) attention
mechanism. Source code is available at github.com/Brainchip-Inc/Centaurus

摘要：我們介紹 Centaurus，一種由廣義狀態空間模型 (SSM) 區塊組成的網路類別，其中 SSM 作業可在訓練期間視為張量收縮。然後可以系統性地為每個 SSM 區塊確定張量收縮的最佳順序，以最大化訓練效率。這允許在設計 SSM 區塊時有更大的彈性，超越了常見實作的深度可分離組態。新的設計選擇將從經典捲積區塊中汲取靈感，包括群組捲積、完整捲積和瓶頸區塊。我們使用這些區塊的混合架構來設計 Centaurus 網路，在訓練和推論期間，在網路大小和效能，以及記憶體和運算效率之間取得平衡。我們展示了這種異質網路設計在原始音訊處理任務中優於其同質對應項，包括關鍵字偵測、語音去雜訊和自動語音辨識 (ASR)。對於 ASR，Centaurus 是第一個具有競爭效能的網路，可以完全基於狀態空間，而無需使用任何非線性遞迴 (LSTM)、明確捲積 (CNN) 或（替代）注意力機制。原始程式碼可在 github.com/Brainchip-Inc/Centaurus 取得

##### **Learning in Log-Domain: Subthreshold Analog AI Accelerator Based on Stochastic Gradient Descent**
2501.13181v1 by Momen K Tageldeen, Yacine Belgaid, Vivek Mohan, Zhou Wang, Emmanuel M Drakakis

The rapid proliferation of AI models, coupled with growing demand for edge
deployment, necessitates the development of AI hardware that is both
high-performance and energy-efficient. In this paper, we propose a novel analog
accelerator architecture designed for AI/ML training workloads using stochastic
gradient descent with L2 regularization (SGDr). The architecture leverages
log-domain circuits in subthreshold MOS and incorporates volatile memory. We
establish a mathematical framework for solving SGDr in the continuous time
domain and detail the mapping of SGDr learning equations to log-domain
circuits. By operating in the analog domain and utilizing weak inversion, the
proposed design achieves significant reductions in transistor area and power
consumption compared to digital implementations. Experimental results
demonstrate that the architecture closely approximates ideal behavior, with a
mean square error below 0.87% and precision as low as 8 bits. Furthermore, the
architecture supports a wide range of hyperparameters. This work paves the way
for energy-efficient analog AI hardware with on-chip training capabilities.

摘要：隨著 AI 模型快速擴散，加上對邊緣部署的需求日益增加，這使得需要開發既高效能又節能的 AI 硬體。在本文中，我們提出了一種新的類比加速器架構，專為使用隨機梯度下降法搭配 L2 正規化 (SGDr) 的 AI/ML 訓練工作負載而設計。此架構利用亞閾值 MOS 中的對數域電路，並整合了揮發性記憶體。我們建立了一個數學框架，用於在連續時間域中求解 SGDr，並詳細說明將 SGDr 學習方程式對應到對數域電路的過程。透過在類比域中運作並利用弱反轉，與數位實作相比，所提出的設計在電晶體面積和功耗方面都大幅降低。實驗結果顯示，此架構非常接近理想行為，均方誤差低於 0.87%，且精準度低至 8 位元。此外，此架構支援各種超參數。這項工作為具備晶片上訓練功能的節能類比 AI 硬體鋪路。

##### **QuFeX: Quantum feature extraction module for hybrid quantum-classical deep neural networks**
2501.13165v1 by Naman Jain, Amir Kalev

We introduce Quantum Feature Extraction (QuFeX), a novel quantum machine
learning module. The proposed module enables feature extraction in a
reduced-dimensional space, significantly decreasing the number of parallel
evaluations required in typical quantum convolutional neural network
architectures. Its design allows seamless integration into deep classical
neural networks, making it particularly suitable for hybrid quantum-classical
models. As an application of QuFeX, we propose Qu-Net -- a hybrid architecture
which integrates QuFeX at the bottleneck of a U-Net architecture. The latter is
widely used for image segmentation tasks such as medical imaging and autonomous
driving. Our numerical analysis indicates that the Qu-Net can achieve superior
segmentation performance compared to a U-Net baseline. These results highlight
the potential of QuFeX to enhance deep neural networks by leveraging hybrid
computational paradigms, providing a path towards a robust framework for
real-world applications requiring precise feature extraction.

摘要：我們引入了量子特徵萃取 (QuFeX)，這是一個創新的量子機器學習模組。所提出的模組可以在降維空間中進行特徵萃取，大幅減少典型量子卷積神經網路架構中所需的並行評估數量。其設計允許無縫整合到深度古典神經網路中，使其特別適合於混合量子古典模型。作為 QuFeX 的應用，我們提出了 Qu-Net，這是一種混合架構，它在 U-Net 架構的瓶頸處整合了 QuFeX。後者廣泛用於影像分割任務，例如醫學影像和自動駕駛。我們的數值分析表明，與 U-Net 基準相比，Qu-Net 可以實現優異的分割效能。這些結果突顯了 QuFeX 透過利用混合運算範例來增強深度神經網路的潛力，為需要精確特徵萃取的真實世界應用程式提供了一個邁向穩健架構的途徑。

