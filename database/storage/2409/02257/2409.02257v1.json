{"2409.02257": {"publish_time": "2024-09-03", "title": "MMLU-Pro+: Evaluating Higher-Order Reasoning and Shortcut Learning in LLMs", "paper_summary": "Existing benchmarks for large language models (LLMs) increasingly struggle to\ndifferentiate between top-performing models, underscoring the need for more\nchallenging evaluation frameworks. We introduce MMLU-Pro+, an enhanced\nbenchmark building upon MMLU-Pro to assess shortcut learning and higher-order\nreasoning in LLMs. By incorporating questions with multiple correct answers\nacross diverse domains, MMLU-Pro+ tests LLMs' ability to engage in complex\nreasoning and resist simplistic problem-solving strategies. Our results show\nthat MMLU-Pro+ maintains MMLU-Pro's difficulty while providing a more rigorous\ntest of model discrimination, particularly in multi-correct answer scenarios.\nWe introduce novel metrics like shortcut selection ratio and correct pair\nidentification ratio, offering deeper insights into model behavior and\nanchoring bias. Evaluations of five state-of-the-art LLMs reveal significant\nperformance gaps, highlighting variations in reasoning abilities and bias\nsusceptibility. We release the dataset and evaluation codes at\n\\url{https://github.com/asgsaeid/mmlu-pro-plus}.", "paper_summary_zh": "\u73fe\u6709\u7684\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u57fa\u6e96\u8d8a\u4f86\u8d8a\u96e3\u4ee5\u5340\u5206\u6548\u80fd\u6700\u4f73\u7684\u6a21\u578b\uff0c\u9019\u7a81\u986f\u4e86\u5c0d\u66f4\u5177\u6311\u6230\u6027\u7684\u8a55\u4f30\u67b6\u69cb\u7684\u9700\u6c42\u3002\u6211\u5011\u5f15\u5165\u4e86 MMLU-Pro+\uff0c\u4e00\u500b\u5efa\u69cb\u65bc MMLU-Pro \u4e4b\u4e0a\u7684\u589e\u5f37\u5f0f\u57fa\u6e96\uff0c\u7528\u65bc\u8a55\u4f30 LLM \u4e2d\u7684\u6377\u5f91\u5b78\u7fd2\u548c\u9ad8\u968e\u63a8\u7406\u3002\u900f\u904e\u7d0d\u5165\u8de8\u4e0d\u540c\u9818\u57df\u4e14\u5177\u6709\u591a\u500b\u6b63\u78ba\u7b54\u6848\u7684\u554f\u984c\uff0cMMLU-Pro+ \u6e2c\u8a66\u4e86 LLM \u9032\u884c\u8907\u96dc\u63a8\u7406\u548c\u62b5\u79a6\u7c21\u5316\u554f\u984c\u89e3\u6c7a\u7b56\u7565\u7684\u80fd\u529b\u3002\u6211\u5011\u7684\u7d50\u679c\u986f\u793a\uff0cMMLU-Pro+ \u4fdd\u7559\u4e86 MMLU-Pro \u7684\u96e3\u5ea6\uff0c\u540c\u6642\u63d0\u4f9b\u4e86\u66f4\u56b4\u8b39\u7684\u6a21\u578b\u5340\u5206\u6e2c\u8a66\uff0c\u7279\u5225\u662f\u5728\u591a\u500b\u6b63\u78ba\u7b54\u6848\u7684\u60c5\u6cc1\u4e0b\u3002\u6211\u5011\u5f15\u5165\u4e86\u6377\u5f91\u9078\u64c7\u6bd4\u7387\u548c\u6b63\u78ba\u914d\u5c0d\u8b58\u5225\u6bd4\u7387\u7b49\u65b0\u7a4e\u7684\u6307\u6a19\uff0c\u63d0\u4f9b\u4e86\u5c0d\u6a21\u578b\u884c\u70ba\u548c\u9328\u5b9a\u504f\u5dee\u66f4\u6df1\u5165\u7684\u898b\u89e3\u3002\u5c0d\u4e94\u500b\u6700\u5148\u9032\u7684 LLM \u7684\u8a55\u4f30\u63ed\u793a\u4e86\u986f\u8457\u7684\u6548\u80fd\u5dee\u8ddd\uff0c\u7a81\u986f\u4e86\u63a8\u7406\u80fd\u529b\u548c\u504f\u5dee\u654f\u611f\u6027\u7684\u5dee\u7570\u3002\u6211\u5011\u5728 \\url{https://github.com/asgsaeid/mmlu-pro-plus} \u91cb\u51fa\u4e86\u8cc7\u6599\u96c6\u548c\u8a55\u4f30\u7a0b\u5f0f\u78bc\u3002", "author": "Saeid Asgari Taghanaki et.al.", "authors": "Saeid Asgari Taghanaki, Aliasgahr Khani, Amir Khasahmadi", "id": "2409.02257v1", "paper_url": "http://arxiv.org/abs/2409.02257v1", "repo": "null"}}