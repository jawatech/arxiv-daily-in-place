{"2502.15470": {"publish_time": "2025-02-21", "title": "PAPI: Exploiting Dynamic Parallelism in Large Language Model Decoding with a Processing-In-Memory-Enabled Computing System", "paper_summary": "Large language models (LLMs) are widely used for natural language\nunderstanding and text generation. An LLM model relies on a time-consuming step\ncalled LLM decoding to generate output tokens. Several prior works focus on\nimproving the performance of LLM decoding using parallelism techniques, such as\nbatching and speculative decoding. State-of-the-art LLM decoding has both\ncompute-bound and memory-bound kernels. Some prior works statically identify\nand map these different kernels to a heterogeneous architecture consisting of\nboth processing-in-memory (PIM) units and computation-centric accelerators. We\nobserve that characteristics of LLM decoding kernels (e.g., whether or not a\nkernel is memory-bound) can change dynamically due to parameter changes to meet\nuser and/or system demands, making (1) static kernel mapping to PIM units and\ncomputation-centric accelerators suboptimal, and (2) one-size-fits-all approach\nof designing PIM units inefficient due to a large degree of heterogeneity even\nin memory-bound kernels.\n  In this paper, we aim to accelerate LLM decoding while considering the\ndynamically changing characteristics of the kernels involved. We propose PAPI\n(PArallel Decoding with PIM), a PIM-enabled heterogeneous architecture that\nexploits dynamic scheduling of compute-bound or memory-bound kernels to\nsuitable hardware units. PAPI has two key mechanisms: (1) online kernel\ncharacterization to dynamically schedule kernels to the most suitable hardware\nunits at runtime and (2) a PIM-enabled heterogeneous computing system that\nharmoniously orchestrates both computation-centric processing units and hybrid\nPIM units with different computing capabilities. Our experimental results on\nthree broadly-used LLMs show that PAPI achieves 1.8$\\times$ and 11.1$\\times$\nspeedups over a state-of-the-art heterogeneous LLM accelerator and a\nstate-of-the-art PIM-only LLM accelerator, respectively.", "paper_summary_zh": "<paragraph>\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u88ab\u5e7f\u6cdb\u7528\u4e8e\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u548c\u6587\u672c\u751f\u6210\u3002LLM \u6a21\u578b\u4f9d\u8d56\u4e00\u4e2a\u8017\u65f6\u7684\u6b65\u9aa4\uff0c\u79f0\u4e3a LLM \u89e3\u7801\uff0c\u4ee5\u751f\u6210\u8f93\u51fa\u6807\u8bb0\u3002\u4e00\u4e9b\u5148\u524d\u7684\u5de5\u4f5c\u4e13\u6ce8\u4e8e\u4f7f\u7528\u5e76\u884c\u6280\u672f\uff08\u4f8b\u5982\u6279\u5904\u7406\u548c\u63a8\u6d4b\u89e3\u7801\uff09\u6765\u63d0\u9ad8 LLM \u89e3\u7801\u7684\u6027\u80fd\u3002\u6700\u5148\u8fdb\u7684 LLM \u89e3\u7801\u540c\u65f6\u5177\u6709\u8ba1\u7b97\u7ed1\u5b9a\u548c\u5185\u5b58\u7ed1\u5b9a\u7684\u5185\u6838\u3002\u4e00\u4e9b\u5148\u524d\u7684\u5de5\u4f5c\u9759\u6001\u8bc6\u522b\u8fd9\u4e9b\u4e0d\u540c\u7684\u5185\u6838\uff0c\u5e76\u5c06\u5b83\u4eec\u6620\u5c04\u5230\u4e00\u4e2a\u5f02\u6784\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u7531\u5904\u7406\u5185\u5b58 (PIM) \u5355\u5143\u548c\u4ee5\u8ba1\u7b97\u4e3a\u4e2d\u5fc3\u7684\u52a0\u901f\u5668\u7ec4\u6210\u3002\u6211\u4eec\u89c2\u5bdf\u5230\uff0cLLM \u89e3\u7801\u5185\u6838\u7684\u7279\u5f81\uff08\u4f8b\u5982\u5185\u6838\u662f\u5426\u53d7\u5185\u5b58\u7ed1\u5b9a\uff09\u53ef\u80fd\u4f1a\u56e0\u53c2\u6570\u66f4\u6539\u800c\u52a8\u6001\u53d8\u5316\uff0c\u4ee5\u6ee1\u8db3\u7528\u6237\u548c/\u6216\u7cfb\u7edf\u9700\u6c42\uff0c\u4ece\u800c\u4f7f (1) \u9759\u6001\u5185\u6838\u6620\u5c04\u5230 PIM \u5355\u5143\u548c\u4ee5\u8ba1\u7b97\u4e3a\u4e2d\u5fc3\u7684\u52a0\u901f\u5668\u6b21\u4f18\uff0c\u4ee5\u53ca (2) \u7531\u4e8e\u5373\u4f7f\u5728\u5185\u5b58\u7ed1\u5b9a\u5185\u6838\u4e2d\u4e5f\u6709\u5f88\u5927\u7a0b\u5ea6\u7684\u5f02\u6784\u6027\uff0c\u56e0\u6b64\u91c7\u7528\u4e00\u5200\u5207\u7684\u65b9\u6cd5\u6765\u8bbe\u8ba1 PIM \u5355\u5143\u6548\u7387\u4f4e\u4e0b\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u65e8\u5728\u5728\u8003\u8651\u6240\u6d89\u53ca\u5185\u6838\u7684\u52a8\u6001\u53d8\u5316\u7279\u5f81\u7684\u540c\u65f6\u52a0\u901f LLM \u89e3\u7801\u3002\u6211\u4eec\u63d0\u51fa\u4e86 PAPI\uff08PIM \u5e76\u884c\u89e3\u7801\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u542f\u7528 PIM \u7684\u5f02\u6784\u67b6\u6784\uff0c\u5b83\u5229\u7528\u8ba1\u7b97\u7ed1\u5b9a\u6216\u5185\u5b58\u7ed1\u5b9a\u5185\u6838\u7684\u52a8\u6001\u8c03\u5ea6\u5230\u5408\u9002\u7684\u786c\u4ef6\u5355\u5143\u3002PAPI \u6709\u4e24\u4e2a\u5173\u952e\u673a\u5236\uff1a(1) \u5728\u7ebf\u5185\u6838\u8868\u5f81\uff0c\u53ef\u5728\u8fd0\u884c\u65f6\u5c06\u5185\u6838\u52a8\u6001\u8c03\u5ea6\u5230\u6700\u5408\u9002\u7684\u786c\u4ef6\u5355\u5143\uff0c\u4ee5\u53ca (2) \u4e00\u4e2a\u542f\u7528 PIM \u7684\u5f02\u6784\u8ba1\u7b97\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u548c\u8c10\u5730\u534f\u8c03\u4ee5\u8ba1\u7b97\u4e3a\u4e2d\u5fc3\u7684\u5904\u7406\u5355\u5143\u548c\u5177\u6709\u4e0d\u540c\u8ba1\u7b97\u80fd\u529b\u7684\u6df7\u5408 PIM \u5355\u5143\u3002\u6211\u4eec\u5728\u4e09\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684 LLM \u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u6700\u5148\u8fdb\u7684\u5f02\u6784 LLM \u52a0\u901f\u5668\u548c\u6700\u5148\u8fdb\u7684\u4ec5 PIM LLM \u52a0\u901f\u5668\u76f8\u6bd4\uff0cPAPI \u5206\u522b\u5b9e\u73b0\u4e86 1.8 \u500d\u548c 11.1 \u500d\u7684\u52a0\u901f\u3002</paragraph>", "author": "Yintao He et.al.", "authors": "Yintao He, Haiyu Mao, Christina Giannoula, Mohammad Sadrosadati, Juan G\u00f3mez-Luna, Huawei Li, Xiaowei Li, Ying Wang, Onur Mutlu", "id": "2502.15470v1", "paper_url": "http://arxiv.org/abs/2502.15470v1", "repo": "null"}}