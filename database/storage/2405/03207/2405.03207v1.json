{"2405.03207": {"publish_time": "2024-05-06", "title": "A Philosophical Introduction to Language Models - Part II: The Way Forward", "paper_summary": "In this paper, the second of two companion pieces, we explore novel\nphilosophical questions raised by recent progress in large language models\n(LLMs) that go beyond the classical debates covered in the first part. We focus\nparticularly on issues related to interpretability, examining evidence from\ncausal intervention methods about the nature of LLMs' internal representations\nand computations. We also discuss the implications of multimodal and modular\nextensions of LLMs, recent debates about whether such systems may meet minimal\ncriteria for consciousness, and concerns about secrecy and reproducibility in\nLLM research. Finally, we discuss whether LLM-like systems may be relevant to\nmodeling aspects of human cognition, if their architectural characteristics and\nlearning scenario are adequately constrained.", "paper_summary_zh": "", "author": "Rapha\u00ebl Milli\u00e8re et.al.", "authors": "Rapha\u00ebl Milli\u00e8re,Cameron Buckner", "id": "2405.03207v1", "paper_url": "http://arxiv.org/abs/2405.03207v1", "repo": "null"}}