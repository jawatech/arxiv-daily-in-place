{"2407.18437": {"publish_time": "2024-07-26", "title": "Mixed Non-linear Quantization for Vision Transformers", "paper_summary": "The majority of quantization methods have been proposed to reduce the model\nsize of Vision Transformers, yet most of them have overlooked the quantization\nof non-linear operations. Only a few works have addressed quantization for\nnon-linear operations, but they applied a single quantization method across all\nnon-linear operations. We believe that this can be further improved by\nemploying a different quantization method for each non-linear operation.\nTherefore, to assign the most error-minimizing quantization method from the\nknown methods to each non-linear layer, we propose a mixed non-linear\nquantization that considers layer-wise quantization sensitivity measured by\nSQNR difference metric. The results show that our method outperforms I-BERT,\nFQ-ViT, and I-ViT in both 8-bit and 6-bit settings for ViT, DeiT, and Swin\nmodels by an average of 0.6%p and 19.6%p, respectively. Our method outperforms\nI-BERT and I-ViT by 0.6%p and 20.8%p, respectively, when training time is\nlimited. We plan to release our code at\nhttps://gitlab.com/ones-ai/mixed-non-linear-quantization.", "paper_summary_zh": "\u76ee\u524d\u5df2\u63d0\u51fa\u7684\u91cf\u5316\u65b9\u6cd5\u5927\u591a\u6570\u90fd\u662f\u4e3a\u4e86\u51cf\u5c0f\u89c6\u89c9\u8f6c\u6362\u5668\u7684\u6a21\u578b\u5927\u5c0f\uff0c\u4f46\u5176\u4e2d\u5927\u591a\u6570\u90fd\u5ffd\u7565\u4e86\u975e\u7ebf\u6027\u8fd0\u7b97\u7684\u91cf\u5316\u3002\u53ea\u6709\u5c11\u6570\u5de5\u4f5c\u89e3\u51b3\u4e86\u975e\u7ebf\u6027\u8fd0\u7b97\u7684\u91cf\u5316\u95ee\u9898\uff0c\u4f46\u5b83\u4eec\u5bf9\u6240\u6709\u975e\u7ebf\u6027\u8fd0\u7b97\u90fd\u5e94\u7528\u4e86\u5355\u4e00\u7684\u91cf\u5316\u65b9\u6cd5\u3002\u6211\u4eec\u76f8\u4fe1\u901a\u8fc7\u4e3a\u6bcf\u4e2a\u975e\u7ebf\u6027\u8fd0\u7b97\u91c7\u7528\u4e0d\u540c\u7684\u91cf\u5316\u65b9\u6cd5\uff0c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u6539\u8fdb\u8fd9\u4e00\u70b9\u3002\u56e0\u6b64\uff0c\u4e3a\u4e86\u5c06\u5df2\u77e5\u65b9\u6cd5\u4e2d\u6700\u80fd\u51cf\u5c11\u8bef\u5dee\u7684\u91cf\u5316\u65b9\u6cd5\u5206\u914d\u7ed9\u6bcf\u4e2a\u975e\u7ebf\u6027\u5c42\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u6df7\u5408\u975e\u7ebf\u6027\u91cf\u5316\uff0c\u8be5\u91cf\u5316\u8003\u8651\u4e86\u7531 SQNR \u5dee\u5206\u5ea6\u91cf\u8861\u91cf\u7684\u9010\u5c42\u91cf\u5316\u7075\u654f\u5ea6\u3002\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5728 ViT\u3001DeiT \u548c Swin \u6a21\u578b\u7684 8 \u4f4d\u548c 6 \u4f4d\u8bbe\u7f6e\u4e2d\u5206\u522b\u6bd4 I-BERT\u3001FQ-ViT \u548c I-ViT \u7684\u6027\u80fd\u9ad8\u51fa 0.6%p \u548c 19.6%p\u3002\u5f53\u8bad\u7ec3\u65f6\u95f4\u6709\u9650\u65f6\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u6bd4 I-BERT \u548c I-ViT \u7684\u6027\u80fd\u5206\u522b\u9ad8\u51fa 0.6%p \u548c 20.8%p\u3002\u6211\u4eec\u8ba1\u5212\u5728 https://gitlab.com/ones-ai/mixed-non-linear-quantization \u4e0a\u53d1\u5e03\u6211\u4eec\u7684\u4ee3\u7801\u3002", "author": "Gihwan Kim et.al.", "authors": "Gihwan Kim, Jemin Lee, Sihyeong Park, Yongin Kwon, Hyungshin Kim", "id": "2407.18437v1", "paper_url": "http://arxiv.org/abs/2407.18437v1", "repo": "null"}}