
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-25**|**Self-Training with Direct Preference Optimization Improves Chain-of-Thought Reasoning**|Tianduo Wang et.al.|[2407.18248v1](http://arxiv.org/abs/2407.18248v1)|[link](https://github.com/tianduowang/dpo-st)|
|**2024-07-25**|**LoRA-Pro: Are Low-Rank Adapters Properly Optimized?**|Zhengbo Wang et.al.|[2407.18242v1](http://arxiv.org/abs/2407.18242v1)|[link](https://github.com/mrflogs/LoRA-Pro)|
|**2024-07-25**|**Recursive Introspection: Teaching Language Model Agents How to Self-Improve**|Yuxiao Qu et.al.|[2407.18219v2](http://arxiv.org/abs/2407.18219v2)|null|
|**2024-07-25**|**Exploring Scaling Trends in LLM Robustness**|Nikolaus Howe et.al.|[2407.18213v2](http://arxiv.org/abs/2407.18213v2)|null|
|**2024-07-25**|**Differentiable Quantum Architecture Search in Asynchronous Quantum Reinforcement Learning**|Samuel Yen-Chi Chen et.al.|[2407.18202v1](http://arxiv.org/abs/2407.18202v1)|null|
|**2024-07-25**|**Gene Regulatory Network Inference from Pre-trained Single-Cell Transcriptomics Transformer with Joint Graph Learning**|Sindhura Kommu et.al.|[2407.18181v1](http://arxiv.org/abs/2407.18181v1)|null|
|**2024-07-25**|**Quasar-ViT: Hardware-Oriented Quantization-Aware Architecture Search for Vision Transformers**|Zhengang Li et.al.|[2407.18175v1](http://arxiv.org/abs/2407.18175v1)|null|
|**2024-07-25**|**The FIGNEWS Shared Task on News Media Narratives**|Wajdi Zaghouani et.al.|[2407.18147v1](http://arxiv.org/abs/2407.18147v1)|null|
|**2024-07-25**|**Taxonomy-Aware Continual Semantic Segmentation in Hyperbolic Spaces for Open-World Perception**|Julia Hindel et.al.|[2407.18145v1](http://arxiv.org/abs/2407.18145v1)|null|
|**2024-07-25**|**Dallah: A Dialect-Aware Multimodal Large Language Model for Arabic**|Fakhraddin Alwajih et.al.|[2407.18129v2](http://arxiv.org/abs/2407.18129v2)|null|
|**2024-07-25**|**Self-supervised pre-training with diffusion model for few-shot landmark detection in x-ray images**|Roberto Di Via et.al.|[2407.18125v1](http://arxiv.org/abs/2407.18125v1)|null|
|**2024-07-25**|**Tracking linguistic information in transformer-based sentence embeddings through targeted sparsification**|Vivi Nastase et.al.|[2407.18119v1](http://arxiv.org/abs/2407.18119v1)|[link](https://github.com/clcl-geneva/blm-snfdisentangling)|
|**2024-07-25**|**Multi-Resolution Histopathology Patch Graphs for Ovarian Cancer Subtyping**|Jack Breen et.al.|[2407.18105v1](http://arxiv.org/abs/2407.18105v1)|[link](https://github.com/scjjb/MultiscalePathGraph)|
|**2024-07-25**|**Privacy Threats and Countermeasures in Federated Learning for Internet of Things: A Systematic Review**|Adel ElZemity et.al.|[2407.18096v1](http://arxiv.org/abs/2407.18096v1)|null|
|**2024-07-25**|**PEFT-U: Parameter-Efficient Fine-Tuning for User Personalization**|Christopher Clarke et.al.|[2407.18078v1](http://arxiv.org/abs/2407.18078v1)|[link](https://github.com/ChrisIsKing/Parameter-Efficient-Personalization)|
|**2024-07-25**|**Difficulty Estimation and Simplification of French Text Using LLMs**|Henri Jamet et.al.|[2407.18061v1](http://arxiv.org/abs/2407.18061v1)|null|
|**2024-07-25**|**Peak-Controlled Logits Poisoning Attack in Federated Distillation**|Yuhan Tang et.al.|[2407.18039v1](http://arxiv.org/abs/2407.18039v1)|null|
|**2024-07-25**|**RestoreAgent: Autonomous Image Restoration Agent via Multimodal Large Language Models**|Haoyu Chen et.al.|[2407.18035v1](http://arxiv.org/abs/2407.18035v1)|null|
|**2024-07-25**|**AttentionHand: Text-driven Controllable Hand Image Generation for 3D Hand Reconstruction in the Wild**|Junho Park et.al.|[2407.18034v1](http://arxiv.org/abs/2407.18034v1)|null|
|**2024-07-25**|**Learning mental states estimation through self-observation: a developmental synergy between intentions and beliefs representations in a deep-learning model of Theory of Mind**|Francesca Bianco et.al.|[2407.18022v1](http://arxiv.org/abs/2407.18022v1)|null|
|**2024-07-25**|**Quadratic Advantage with Quantum Randomized Smoothing Applied to Time-Series Analysis**|Nicola Franco et.al.|[2407.18021v1](http://arxiv.org/abs/2407.18021v1)|null|
|**2024-07-25**|**GermanPartiesQA: Benchmarking Commercial Large Language Models for Political Bias and Sycophancy**|Jan Batzner et.al.|[2407.18008v1](http://arxiv.org/abs/2407.18008v1)|null|
|**2024-07-25**|**Keep the Cost Down: A Review on Methods to Optimize LLM' s KV-Cache Consumption**|Shi Luohe et.al.|[2407.18003v1](http://arxiv.org/abs/2407.18003v1)|null|
|**2024-07-25**|**On the Effect of Purely Synthetic Training Data for Different Automatic Speech Recognition Architectures**|Nick Rossenbach et.al.|[2407.17997v1](http://arxiv.org/abs/2407.17997v1)|null|
|**2024-07-25**|**What does Kiki look like? Cross-modal associations between speech sounds and visual shapes in vision-and-language models**|Tessa Verhoef et.al.|[2407.17974v1](http://arxiv.org/abs/2407.17974v1)|null|
|**2024-07-25**|**Relating the Seemingly Unrelated: Principled Understanding of Generalization for Generative Models in Arithmetic Reasoning Tasks**|Xingcheng Xu et.al.|[2407.17963v1](http://arxiv.org/abs/2407.17963v1)|null|
|**2024-07-25**|**The Curious Case of Representational Alignment: Unravelling Visio-Linguistic Tasks in Emergent Communication**|Tom Kouwenhoven et.al.|[2407.17960v1](http://arxiv.org/abs/2407.17960v1)|null|
|**2024-07-25**|**Real Time American Sign Language Detection Using Yolo-v9**|Amna Imran et.al.|[2407.17950v1](http://arxiv.org/abs/2407.17950v1)|null|
|**2024-07-25**|**Positive Text Reframing under Multi-strategy Optimization**|Shutong Jia et.al.|[2407.17940v1](http://arxiv.org/abs/2407.17940v1)|null|
|**2024-07-25**|**Comparison of different Artificial Neural Networks for Bitcoin price forecasting**|Silas Baumann et.al.|[2407.17930v1](http://arxiv.org/abs/2407.17930v1)|null|
|**2024-07-25**|**Invariance of deep image quality metrics to affine transformations**|Nuria Alabau-Bosque et.al.|[2407.17927v1](http://arxiv.org/abs/2407.17927v1)|[link](https://github.com/Rietta5/InvarianceTestIQA)|
|**2024-07-25**|**The Dark Side of Function Calling: Pathways to Jailbreaking Large Language Models**|Zihui Wu et.al.|[2407.17915v1](http://arxiv.org/abs/2407.17915v1)|[link](https://github.com/wooozihui/jailbreakfunction)|
|**2024-07-25**|**Modelling Multimodal Integration in Human Concept Processing with Vision-and-Language Models**|Anna Bavaresco et.al.|[2407.17914v1](http://arxiv.org/abs/2407.17914v1)|null|
|**2024-07-25**|**ReCorD: Reasoning and Correcting Diffusion for HOI Generation**|Jian-Yu Jiang-Lin et.al.|[2407.17911v1](http://arxiv.org/abs/2407.17911v1)|null|
|**2024-07-25**|**The Power of Combining Data and Knowledge: GPT-4o is an Effective Interpreter of Machine Learning Models in Predicting Lymph Node Metastasis of Lung Cancer**|Danqing Hu et.al.|[2407.17900v1](http://arxiv.org/abs/2407.17900v1)|null|
|**2024-07-25**|**3D Hole Filling using Deep Learning Inpainting**|Marina Hernández-Bautista et.al.|[2407.17896v1](http://arxiv.org/abs/2407.17896v1)|null|
|**2024-07-25**|**An Iterative Approach to Topic Modelling**|Albert Wong et.al.|[2407.17892v1](http://arxiv.org/abs/2407.17892v1)|null|
|**2024-07-25**|**Unraveling the Never-Ending Story of Lifecycles and Vitalizing Processes**|Stephan A. Fahrenkrog-Petersen et.al.|[2407.17881v1](http://arxiv.org/abs/2407.17881v1)|null|
|**2024-07-25**|**A Large-Scale Sensitivity Analysis on Latent Embeddings and Dimensionality Reductions for Text Spatializations**|Daniel Atzberger et.al.|[2407.17876v1](http://arxiv.org/abs/2407.17876v1)|[link](https://github.com/hpicgs/topic-models-and-dimensionality-reduction-sensitivity-study)|
|**2024-07-25**|**Improving Domain-Specific ASR with LLM-Generated Contextual Descriptions**|Jiwon Suh et.al.|[2407.17874v1](http://arxiv.org/abs/2407.17874v1)|null|
|**2024-07-25**|**Is the Digital Forensics and Incident Response Pipeline Ready for Text-Based Threats in LLM Era?**|Avanti Bhandarkar et.al.|[2407.17870v1](http://arxiv.org/abs/2407.17870v1)|null|
|**2024-07-25**|**Financial Statement Analysis with Large Language Models**|Alex Kim et.al.|[2407.17866v1](http://arxiv.org/abs/2407.17866v1)|null|
|**2024-07-25**|**factgenie: A Framework for Span-based Evaluation of Generated Texts**|Zdeněk Kasner et.al.|[2407.17863v1](http://arxiv.org/abs/2407.17863v1)|[link](https://github.com/kasnerz/factgenie)|
|**2024-07-25**|**Exploring Description-Augmented Dataless Intent Classification**|Ruoyu Hu et.al.|[2407.17862v1](http://arxiv.org/abs/2407.17862v1)|[link](https://github.com/ruoyunlp/dataless-intent-classification)|
|**2024-07-25**|**Shapley Value-based Contrastive Alignment for Multimodal Information Extraction**|Wen Luo et.al.|[2407.17854v1](http://arxiv.org/abs/2407.17854v1)|null|
|**2024-07-25**|**Scaling A Simple Approach to Zero-Shot Speech Recognition**|Jinming Zhao et.al.|[2407.17852v1](http://arxiv.org/abs/2407.17852v1)|[link](https://github.com/facebookresearch/fairseq)|
|**2024-07-25**|**Innovative Speech-Based Deep Learning Approaches for Parkinson's Disease Classification: A Systematic Review**|Lisanne van Gelderen et.al.|[2407.17844v1](http://arxiv.org/abs/2407.17844v1)|null|
|**2024-07-25**|**DragText: Rethinking Text Embedding in Point-based Image Editing**|Gayoon Choi et.al.|[2407.17843v1](http://arxiv.org/abs/2407.17843v1)|null|
|**2024-07-25**|**On the Opportunities of (Re)-Exploring Atmospheric Science by Foundation Models: A Case Study**|Lujia Zhang et.al.|[2407.17842v1](http://arxiv.org/abs/2407.17842v1)|null|
|**2024-07-25**|**Long-term Fairness in Ride-Hailing Platform**|Yufan Kang et.al.|[2407.17839v1](http://arxiv.org/abs/2407.17839v1)|null|
|**2024-07-25**|**UMono: Physical Model Informed Hybrid CNN-Transformer Framework for Underwater Monocular Depth Estimation**|Jian Wang et.al.|[2407.17838v1](http://arxiv.org/abs/2407.17838v1)|null|
|**2024-07-25**|**Unified Lexical Representation for Interpretable Visual-Language Alignment**|Yifan Li et.al.|[2407.17827v1](http://arxiv.org/abs/2407.17827v1)|null|
|**2024-07-25**|**Demystifying Verbatim Memorization in Large Language Models**|Jing Huang et.al.|[2407.17817v1](http://arxiv.org/abs/2407.17817v1)|null|
|**2024-07-25**|**NC-NCD: Novel Class Discovery for Node Classification**|Yue Hou et.al.|[2407.17816v1](http://arxiv.org/abs/2407.17816v1)|null|
|**2024-07-25**|**Enhancing Model Performance: Another Approach to Vision-Language Instruction Tuning**|Vedanshu et.al.|[2407.17813v1](http://arxiv.org/abs/2407.17813v1)|null|
|**2024-07-25**|**EEG-SSM: Leveraging State-Space Model for Dementia Detection**|Xuan-The Tran et.al.|[2407.17801v1](http://arxiv.org/abs/2407.17801v1)|null|
|**2024-07-25**|**A Unified Understanding of Adversarial Vulnerability Regarding Unimodal Models and Vision-Language Pre-training Models**|Haonan Zheng et.al.|[2407.17797v1](http://arxiv.org/abs/2407.17797v1)|null|
|**2024-07-25**|**Investigating learning-independent abstract reasoning in artificial neural networks**|Tomer Barak et.al.|[2407.17791v1](http://arxiv.org/abs/2407.17791v1)|[link](https://github.com/tomer-barak/learning-independent_abstract_reasoning)|
|**2024-07-25**|**Very Large-Scale Multi-Agent Simulation in AgentScope**|Xuchen Pan et.al.|[2407.17789v1](http://arxiv.org/abs/2407.17789v1)|[link](https://github.com/modelscope/agentscope)|
|**2024-07-25**|**Advancing Multi-Modal Sensing Through Expandable Modality Alignment**|Shenghong Dai et.al.|[2407.17777v1](http://arxiv.org/abs/2407.17777v1)|null|
|**2024-07-25**|**KiVA: Kid-inspired Visual Analogies for Testing Large Multimodal Models**|Eunice Yiu et.al.|[2407.17773v1](http://arxiv.org/abs/2407.17773v1)|[link](https://github.com/ey242/kiva)|
|**2024-07-25**|**Banyan: Improved Representation Learning with Explicit Structure**|Mattia Opper et.al.|[2407.17771v1](http://arxiv.org/abs/2407.17771v1)|null|
|**2024-07-25**|**BotEval: Facilitating Interactive Human Evaluation**|Hyundong Cho et.al.|[2407.17770v1](http://arxiv.org/abs/2407.17770v1)|null|
|**2024-07-25**|**Mpox Detection Advanced: Rapid Epidemic Response Through Synthetic Data**|Yudara Kularathne et.al.|[2407.17762v1](http://arxiv.org/abs/2407.17762v1)|null|
|**2024-07-25**|**TwIPS: A Large Language Model Powered Texting Application to Simplify Conversational Nuances for Autistic Users**|Rukhshan Haroon et.al.|[2407.17760v1](http://arxiv.org/abs/2407.17760v1)|null|
|**2024-07-25**|**Beyond Entity Alignment: Towards Complete Knowledge Graph Alignment via Entity-Relation Synergy**|Xiaohan Fang et.al.|[2407.17745v1](http://arxiv.org/abs/2407.17745v1)|null|
|**2024-07-25**|**Cost-effective Instruction Learning for Pathology Vision and Language Analysis**|Kaitao Chen et.al.|[2407.17734v1](http://arxiv.org/abs/2407.17734v1)|[link](https://github.com/jlinekai/clover)|
|**2024-07-25**|**Are Large Language Models Possible to Conduct Cognitive Behavioral Therapy?**|Hao Shen et.al.|[2407.17730v1](http://arxiv.org/abs/2407.17730v1)|null|
|**2024-07-25**|**Describe Where You Are: Improving Noise-Robustness for Speech Emotion Recognition with Text Description of the Environment**|Seong-Gyun Leem et.al.|[2407.17716v1](http://arxiv.org/abs/2407.17716v1)|null|
|**2024-07-25**|**Enhancing Agent Learning through World Dynamics Modeling**|Zhiyuan Sun et.al.|[2407.17695v1](http://arxiv.org/abs/2407.17695v1)|null|
|**2024-07-25**|**Examining the Influence of Political Bias on Large Language Model Performance in Stance Classification**|Lynnette Hui Xian Ng et.al.|[2407.17688v2](http://arxiv.org/abs/2407.17688v2)|null|
|**2024-07-25**|**Transformers on Markov Data: Constant Depth Suffices**|Nived Rajaraman et.al.|[2407.17686v1](http://arxiv.org/abs/2407.17686v1)|null|
|**2024-07-25**|**Efficient LLM Training and Serving with Heterogeneous Context Sharding among Attention Heads**|Xihui Lin et.al.|[2407.17678v1](http://arxiv.org/abs/2407.17678v1)|null|
|**2024-07-24**|**CRASAR-U-DROIDs: A Large Scale Benchmark Dataset for Building Alignment and Damage Assessment in Georectified sUAS Imagery**|Thomas Manzini et.al.|[2407.17673v1](http://arxiv.org/abs/2407.17673v1)|null|
|**2024-07-24**|**Spiking Neural Networks in Vertical Federated Learning: Performance Trade-offs**|Maryam Abbasihafshejani et.al.|[2407.17672v1](http://arxiv.org/abs/2407.17672v1)|null|
|**2024-07-24**|**SMA-Hyper: Spatiotemporal Multi-View Fusion Hypergraph Learning for Traffic Accident Prediction**|Xiaowei Gao et.al.|[2407.17642v1](http://arxiv.org/abs/2407.17642v1)|null|
|**2024-07-24**|**Time Matters: Examine Temporal Effects on Biomedical Language Models**|Weisi Liu et.al.|[2407.17638v1](http://arxiv.org/abs/2407.17638v1)|null|
|**2024-07-24**|**IgnitionInnovators at "Discharge Me!": Chain-of-Thought Instruction Finetuning Large Language Models for Discharge Summaries**|An Quang Tang et.al.|[2407.17636v1](http://arxiv.org/abs/2407.17636v1)|[link](https://github.com/antangrocket1312/discharge_llm)|
|**2024-07-24**|**Traditional Methods Outperform Generative LLMs at Forecasting Credit Ratings**|Felix Drinkall et.al.|[2407.17624v1](http://arxiv.org/abs/2407.17624v1)|null|
|**2024-07-24**|**CoMoTo: Unpaired Cross-Modal Lesion Distillation Improves Breast Lesion Detection in Tomosynthesis**|Muhammad Alberb et.al.|[2407.17620v1](http://arxiv.org/abs/2407.17620v1)|[link](https://github.com/muhammad-al-barbary/comoto)|
|**2024-07-24**|**Coupling Speech Encoders with Downstream Text Models**|Ciprian Chelba et.al.|[2407.17605v1](http://arxiv.org/abs/2407.17605v1)|null|
|**2024-07-24**|**I Could've Asked That: Reformulating Unanswerable Questions**|Wenting Zhao et.al.|[2407.17469v1](http://arxiv.org/abs/2407.17469v1)|[link](https://github.com/wenting-zhao/couldask)|
|**2024-07-24**|**WildHallucinations: Evaluating Long-form Factuality in LLMs with Real-World Entity Queries**|Wenting Zhao et.al.|[2407.17468v1](http://arxiv.org/abs/2407.17468v1)|null|
|**2024-07-24**|**CMR Scaling Law: Predicting Critical Mixture Ratios for Continual Pre-training of Language Models**|Jiawei Gu et.al.|[2407.17467v1](http://arxiv.org/abs/2407.17467v1)|null|
|**2024-07-24**|**Why Machines Can't Be Moral: Turing's Halting Problem and the Moral Limits of Artificial Intelligence**|Massimo Passamonti et.al.|[2407.16890v1](http://arxiv.org/abs/2407.16890v1)|null|
|**2024-07-24**|**Exploring Domain Robust Lightweight Reward Models based on Router Mechanism**|Hyuk Namgoong et.al.|[2407.17546v1](http://arxiv.org/abs/2407.17546v1)|null|
|**2024-07-24**|**Fluent Student-Teacher Redteaming**|T. Ben Thompson et.al.|[2407.17447v1](http://arxiv.org/abs/2407.17447v1)|[link](https://github.com/Confirm-Solutions/flrt)|
|**2024-07-24**|**HumanVid: Demystifying Training Data for Camera-controllable Human Image Animation**|Zhenzhi Wang et.al.|[2407.17438v1](http://arxiv.org/abs/2407.17438v1)|[link](https://github.com/zhenzhiwang/humanvid)|
|**2024-07-24**|**(PASS) Visual Prompt Locates Good Structure Sparsity through a Recurrent HyperNetwork**|Tianjin Huang et.al.|[2407.17412v1](http://arxiv.org/abs/2407.17412v1)|null|
|**2024-07-24**|**Dependency Transformer Grammars: Integrating Dependency Structures into Transformer Language Models**|Yida Zhao et.al.|[2407.17406v1](http://arxiv.org/abs/2407.17406v1)|[link](https://github.com/zhaoyd1/dep_transformer_grammars)|
|**2024-07-24**|**Grammar-based Game Description Generation using Large Language Models**|Tsunehiko Tanaka et.al.|[2407.17404v1](http://arxiv.org/abs/2407.17404v1)|null|
|**2024-07-24**|**Large Language Models for Anomaly Detection in Computational Workflows: from Supervised Fine-Tuning to In-Context Learning**|Hongwei Jin et.al.|[2407.17545v1](http://arxiv.org/abs/2407.17545v1)|[link](https://github.com/poseidon-workflows/llm_ad)|
|**2024-07-24**|**Systematic Reasoning About Relational Domains With Graph Neural Networks**|Irtaza Khalid et.al.|[2407.17396v1](http://arxiv.org/abs/2407.17396v1)|[link](https://github.com/erg0dic/gnn-sg)|
|**2024-07-24**|**CovScore: Evaluation of Multi-Document Abstractive Title Set Generation**|Itamar Trainin et.al.|[2407.17390v1](http://arxiv.org/abs/2407.17390v1)|null|
|**2024-07-24**|**PERSONA: A Reproducible Testbed for Pluralistic Alignment**|Louis Castricato et.al.|[2407.17387v1](http://arxiv.org/abs/2407.17387v1)|null|
|**2024-07-24**|**A Comprehensive Approach to Misspelling Correction with BERT and Levenshtein Distance**|Amirreza Naziri et.al.|[2407.17383v1](http://arxiv.org/abs/2407.17383v1)|null|
|**2024-07-24**|**MMRA: A Benchmark for Multi-granularity Multi-image Relational Association**|Siwei Wu et.al.|[2407.17379v1](http://arxiv.org/abs/2407.17379v1)|[link](https://github.com/wusiwei0410/mmra)|
|**2024-07-24**|**MathViz-E: A Case-study in Domain-Specialized Tool-Using Agents**|Arya Bulusu et.al.|[2407.17544v1](http://arxiv.org/abs/2407.17544v1)|[link](https://github.com/emergenceai/mathviz-e)|
|**2024-07-24**|**Dataset Distribution Impacts Model Fairness: Single vs. Multi-Task Learning**|Ralf Raumanns et.al.|[2407.17543v1](http://arxiv.org/abs/2407.17543v1)|null|
|**2024-07-24**|**Boosting Large Language Models with Socratic Method for Conversational Mathematics Teaching**|Yuyang Ding et.al.|[2407.17349v1](http://arxiv.org/abs/2407.17349v1)|null|

#### Abstracts
##### **Self-Training with Direct Preference Optimization Improves Chain-of-Thought Reasoning**
2407.18248v1 by Tianduo Wang, Shichen Li, Wei Lu

Effective training of language models (LMs) for mathematical reasoning tasks
demands high-quality supervised fine-tuning data. Besides obtaining annotations
from human experts, a common alternative is sampling from larger and more
powerful LMs. However, this knowledge distillation approach can be costly and
unstable, particularly when relying on closed-source, proprietary LMs like
GPT-4, whose behaviors are often unpredictable. In this work, we demonstrate
that the reasoning abilities of small-scale LMs can be enhanced through
self-training, a process where models learn from their own outputs. We also
show that the conventional self-training can be further augmented by a
preference learning algorithm called Direct Preference Optimization (DPO). By
integrating DPO into self-training, we leverage preference data to guide LMs
towards more accurate and diverse chain-of-thought reasoning. We evaluate our
method across various mathematical reasoning tasks using different base models.
Our experiments show that this approach not only improves LMs' reasoning
performance but also offers a more cost-effective and scalable solution
compared to relying on large proprietary LMs.

摘要：要有效訓練數學推理任務的語言模型 (LM)，需要高品質的監督微調資料。除了從人類專家取得註解之外，一個常見的替代方案是從更大、更強大的 LM 中取樣。然而，這種知識蒸餾方法代價高昂且不穩定，特別是當依賴於封閉原始碼的專有 LM（例如 GPT-4）時，其行為通常難以預測。在這項工作中，我們證明了小規模 LM 的推理能力可以透過自訓練來增強，這是一個模型從自己的輸出中學習的過程。我們也展示了傳統的自訓練可以進一步透過一種稱為直接偏好最佳化 (DPO) 的偏好學習演算法來擴充。透過將 DPO 整合到自訓練中，我們利用偏好資料引導 LM 朝向更準確、更多樣化的思考鏈推理。我們使用不同的基礎模型，在各種數學推理任務中評估我們的模型。我們的實驗顯示，這種方法不僅改善了 LM 的推理效能，而且與依賴大型專有 LM 相比，還提供了一個更具成本效益且可擴充的解決方案。

##### **LoRA-Pro: Are Low-Rank Adapters Properly Optimized?**
2407.18242v1 by Zhengbo Wang, Jian Liang

Low-Rank Adaptation, also known as LoRA, has emerged as a prominent method
for parameter-efficient fine-tuning foundation models by re-parameterizing the
original matrix into the product of two low-rank matrices. Despite its
efficiency, LoRA often yields inferior performance compared to full
fine-tuning. In this paper, we propose LoRA-Pro to bridge this performance gap.
Firstly, we delve into the optimization processes in LoRA and full fine-tuning.
We reveal that while LoRA employs low-rank approximation, it neglects to
approximate the optimization process of full fine-tuning. To address this, we
introduce a novel concept called the "equivalent gradient." This virtual
gradient makes the optimization process on the re-parameterized matrix
equivalent to LoRA, which can be used to quantify the differences between LoRA
and full fine-tuning. The equivalent gradient is derived from the gradients of
matrices $A$ and $B$. To narrow the performance gap, our approach minimizes the
differences between the equivalent gradient and the gradient obtained from full
fine-tuning during the optimization process. By solving this objective, we
derive optimal closed-form solutions for updating matrices $A$ and $B$. Our
method constrains the optimization process, shrinking the performance gap
between LoRA and full fine-tuning. Extensive experiments on natural language
processing tasks validate the effectiveness of our method.

摘要：低秩適應（LoRA）已成為一種重要的方法，可透過將原始矩陣重新參數化為兩個低秩矩陣的乘積，對參數有效率的微調基礎模型。儘管 LoRA 具有效率，但與完整微調相比，其效能通常較差。在本文中，我們提出 LoRA-Pro 來彌合此效能差距。首先，我們深入探討 LoRA 和完整微調中的最佳化程序。我們揭示，儘管 LoRA 採用低秩近似，但它忽略了完整微調的最佳化程序。為了解決這個問題，我們引入了一個名為「等效梯度」的新概念。這個虛擬梯度使重新參數化矩陣上的最佳化程序等同於 LoRA，可用来量化 LoRA 和完整微調之間的差異。等效梯度來自矩陣 A 和 B 的梯度。為了縮小效能差距，我們的做法是在最佳化程序中最小化等效梯度和從完整微調中獲得的梯度之間的差異。透過解決這個目標，我們推導出更新矩陣 A 和 B 的最佳閉式解。我們的做法約束了最佳化程序，縮小了 LoRA 和完整微調之間的效能差距。自然語言處理任務上的大量實驗驗證了我們方法的有效性。

##### **Recursive Introspection: Teaching Language Model Agents How to Self-Improve**
2407.18219v2 by Yuxiao Qu, Tianjun Zhang, Naman Garg, Aviral Kumar

A central piece in enabling intelligent agentic behavior in foundation models
is to make them capable of introspecting upon their behavior, reasoning, and
correcting their mistakes as more computation or interaction is available. Even
the strongest proprietary large language models (LLMs) do not quite exhibit the
ability of continually improving their responses sequentially, even in
scenarios where they are explicitly told that they are making a mistake. In
this paper, we develop RISE: Recursive IntroSpEction, an approach for
fine-tuning LLMs to introduce this capability, despite prior work hypothesizing
that this capability may not be possible to attain. Our approach prescribes an
iterative fine-tuning procedure, which attempts to teach the model how to alter
its response after having executed previously unsuccessful attempts to solve a
hard test-time problem, with optionally additional environment feedback. RISE
poses fine-tuning for a single-turn prompt as solving a multi-turn Markov
decision process (MDP), where the initial state is the prompt. Inspired by
principles in online imitation learning and reinforcement learning, we propose
strategies for multi-turn data collection and training so as to imbue an LLM
with the capability to recursively detect and correct its previous mistakes in
subsequent iterations. Our experiments show that RISE enables Llama2, Llama3,
and Mistral models to improve themselves with more turns on math reasoning
tasks, outperforming several single-turn strategies given an equal amount of
inference-time computation. We also find that RISE scales well, often attaining
larger benefits with more capable models. Our analysis shows that RISE makes
meaningful improvements to responses to arrive at the correct solution for
challenging prompts, without disrupting one-turn abilities as a result of
expressing more complex distributions.

摘要：<paragraph>在基礎模型中啟用智能代理行為的核心部分是讓它們能夠內省自己的行為、推理，並在有更多運算或互動可用時糾正它們的錯誤。即使是最強大的專有大型語言模型 (LLM) 也不太會表現出連續改進其回應的能力，即使在明確告訴它們它們犯了錯誤的情況下也是如此。在本文中，我們開發了 RISE：遞迴內省，一種微調 LLM 以引入此功能的方法，儘管先前的工作假設可能無法獲得此功能。我們的做法規定了一個反覆微調程序，該程序試圖教導模型如何在執行先前不成功的嘗試以解決困難的測試時間問題後更改其響應，並可選擇額外提供環境回饋。RISE 將單輪提示的微調設定為解決多輪馬可夫決策過程 (MDP)，其中初始狀態是提示。受在線模仿學習和強化學習原理的啟發，我們提出了多輪數據收集和訓練策略，以便賦予 LLM 在後續迭代中遞歸檢測和糾正其先前錯誤的能力。我們的實驗表明，RISE 使 Llama2、Llama3 和 Mistral 模型能夠在數學推理任務中通過更多輪次來改進自身，在給定相同推理時間計算的情況下，優於多種單輪策略。我們還發現 RISE 具有良好的擴展性，通常通過更強大的模型獲得更大的好處。我們的分析表明，RISE 對響應進行了有意義的改進，以獲得對具有挑戰性提示的正確解決方案，而不會因為表達更複雜的分布而破壞單輪能力。</paragraph>

##### **Exploring Scaling Trends in LLM Robustness**
2407.18213v2 by Nikolaus Howe, Michał Zajac, Ian McKenzie, Oskar Hollinsworth, Tom Tseng, Pierre-Luc Bacon, Adam Gleave

Language model capabilities predictably improve from scaling a model's size
and training data. Motivated by this, increasingly large language models have
been trained, yielding an array of impressive capabilities. Yet these models
are vulnerable to adversarial prompts, such as "jailbreaks" that hijack models
to perform undesired behaviors, posing a significant risk of misuse. Prior work
indicates that computer vision models become more robust with model and data
scaling, raising the question: does language model robustness also improve with
scale? We study this question empirically, finding that larger models respond
substantially better to adversarial training, but there is little to no benefit
from model scale in the absence of explicit defenses.

摘要：語言模型的能力可預測地從擴展模型大小和訓練資料中獲得改善。受此啟發，已經訓練出越來越大的語言模型，產生了一系列令人印象深刻的能力。然而，這些模型容易受到對抗性提示的影響，例如劫持模型以執行不需要的行為的「越獄」，對誤用構成重大風險。先前的研究表明，電腦視覺模型隨著模型和資料的擴展而變得更強大，這引發了一個問題：語言模型的穩健性是否也隨著規模而提高？我們以經驗研究這個問題，發現較大的模型對對抗性訓練的反應顯著更好，但在沒有明確防禦措施的情況下，模型規模幾乎沒有好處。

##### **Differentiable Quantum Architecture Search in Asynchronous Quantum Reinforcement Learning**
2407.18202v1 by Samuel Yen-Chi Chen

The emergence of quantum reinforcement learning (QRL) is propelled by
advancements in quantum computing (QC) and machine learning (ML), particularly
through quantum neural networks (QNN) built on variational quantum circuits
(VQC). These advancements have proven successful in addressing sequential
decision-making tasks. However, constructing effective QRL models demands
significant expertise due to challenges in designing quantum circuit
architectures, including data encoding and parameterized circuits, which
profoundly influence model performance. In this paper, we propose addressing
this challenge with differentiable quantum architecture search (DiffQAS),
enabling trainable circuit parameters and structure weights using
gradient-based optimization. Furthermore, we enhance training efficiency
through asynchronous reinforcement learning (RL) methods facilitating parallel
training. Through numerical simulations, we demonstrate that our proposed
DiffQAS-QRL approach achieves performance comparable to manually-crafted
circuit architectures across considered environments, showcasing stability
across diverse scenarios. This methodology offers a pathway for designing QRL
models without extensive quantum knowledge, ensuring robust performance and
fostering broader application of QRL.

摘要：量子強化學習 (QRL) 的出現是由量子運算 (QC) 和機器學習 (ML) 的進步推動，特別是建立在變分量子電路 (VQC) 上的量子神經網路 (QNN)。這些進步已被證明在解決序貫決策任務方面是成功的。然而，構建有效的 QRL 模型需要大量的專業知識，因為在設計量子電路架構時會遇到挑戰，包括數據編碼和參數化電路，這會深刻影響模型性能。在本文中，我們提出使用可微分量子架構搜尋 (DiffQAS) 來解決這個挑戰，使用基於梯度的最佳化來啟用可訓練的電路參數和結構權重。此外，我們透過非同步強化學習 (RL) 方法來增強訓練效率，促進並行訓練。透過數值模擬，我們證明我們提出的 DiffQAS-QRL 方法達到了與人工製作的電路架構相當的性能，在各種環境中展現了穩定性。這種方法提供了一個在沒有廣泛量子知識的情況下設計 QRL 模型的途徑，確保了穩健的性能，並促進了 QRL 的更廣泛應用。

##### **Gene Regulatory Network Inference from Pre-trained Single-Cell Transcriptomics Transformer with Joint Graph Learning**
2407.18181v1 by Sindhura Kommu, Yizhi Wang, Yue Wang, Xuan Wang

Inferring gene regulatory networks (GRNs) from single-cell RNA sequencing
(scRNA-seq) data is a complex challenge that requires capturing the intricate
relationships between genes and their regulatory interactions. In this study,
we tackle this challenge by leveraging the single-cell BERT-based pre-trained
transformer model (scBERT), trained on extensive unlabeled scRNA-seq data, to
augment structured biological knowledge from existing GRNs. We introduce a
novel joint graph learning approach that combines the rich contextual
representations learned by pre-trained single-cell language models with the
structured knowledge encoded in GRNs using graph neural networks (GNNs). By
integrating these two modalities, our approach effectively reasons over boththe
gene expression level constraints provided by the scRNA-seq data and the
structured biological knowledge inherent in GRNs. We evaluate our method on
human cell benchmark datasets from the BEELINE study with cell type-specific
ground truth networks. The results demonstrate superior performance over
current state-of-the-art baselines, offering a deeper understanding of cellular
regulatory mechanisms.

摘要：從單細胞 RNA 定序 (scRNA-seq) 資料推論基因調控網路 (GRN) 是一項複雜的挑戰，需要掌握基因與其調控交互作用之間的複雜關係。在此研究中，我們透過利用在廣泛的未標記 scRNA-seq 資料上訓練的單細胞 BERT 基於預訓練轉換器模型 (scBERT)，來克服此挑戰，以擴充現有 GRN 中的結構化生物知識。我們引入一種新穎的聯合圖形學習方法，它結合了預訓練單細胞語言模型所學習到的豐富脈絡表徵，以及使用圖形神經網路 (GNN) 對 GRN 中編碼的結構化知識。透過整合這兩種方式，我們的做法有效地對 scRNA-seq 資料提供的基因表現層級約束和 GRN 中固有的結構化生物知識進行推理。我們使用 BEELINE 研究中的人類細胞基準資料集，以及細胞類型特定的基本事實網路，來評估我們的方法。結果證明其效能優於目前最先進的基準，提供了對細胞調控機制的更深入理解。

##### **Quasar-ViT: Hardware-Oriented Quantization-Aware Architecture Search for Vision Transformers**
2407.18175v1 by Zhengang Li, Alec Lu, Yanyue Xie, Zhenglun Kong, Mengshu Sun, Hao Tang, Zhong Jia Xue, Peiyan Dong, Caiwen Ding, Yanzhi Wang, Xue Lin, Zhenman Fang

Vision transformers (ViTs) have demonstrated their superior accuracy for
computer vision tasks compared to convolutional neural networks (CNNs).
However, ViT models are often computation-intensive for efficient deployment on
resource-limited edge devices. This work proposes Quasar-ViT, a
hardware-oriented quantization-aware architecture search framework for ViTs, to
design efficient ViT models for hardware implementation while preserving the
accuracy. First, Quasar-ViT trains a supernet using our row-wise flexible
mixed-precision quantization scheme, mixed-precision weight entanglement, and
supernet layer scaling techniques. Then, it applies an efficient
hardware-oriented search algorithm, integrated with hardware latency and
resource modeling, to determine a series of optimal subnets from supernet under
different inference latency targets. Finally, we propose a series of
model-adaptive designs on the FPGA platform to support the architecture search
and mitigate the gap between the theoretical computation reduction and the
practical inference speedup. Our searched models achieve 101.5, 159.6, and
251.6 frames-per-second (FPS) inference speed on the AMD/Xilinx ZCU102 FPGA
with 80.4%, 78.6%, and 74.9% top-1 accuracy, respectively, for the ImageNet
dataset, consistently outperforming prior works.

摘要：<paragraph>與卷積神經網路（CNN）相比，視覺轉換器（ViT）已證明其在電腦視覺任務上的優異準確度。然而，ViT 模型通常在計算上很密集，無法在資源有限的邊緣裝置上有效率地部署。這項工作提出了 Quasar-ViT，一個面向硬體的量化感知架構搜尋框架，用於 ViT，以設計高效的 ViT 模型進行硬體實作，同時保持準確度。首先，Quasar-ViT 使用我們列式彈性混合精度量化方案、混合精度權重糾纏和超網路層縮放技術來訓練超網路。然後，它應用一個有效率的面向硬體的搜尋演算法，整合硬體延遲和資源建模，以在不同的推論延遲目標下從超網路中確定一系列最佳子網路。最後，我們在 FPGA 平臺上提出了一系列模型自適應設計，以支援架構搜尋並縮小理論運算減少和實際推論加速之間的差距。我們搜尋的模型在 AMD/Xilinx ZCU102 FPGA 上分別以 80.4%、78.6% 和 74.9% 的 top-1 準確度，達到 101.5、159.6 和 251.6 幀每秒 (FPS) 的推論速度，用於 ImageNet 資料集，始終優於先前的研究。</paragraph>

##### **The FIGNEWS Shared Task on News Media Narratives**
2407.18147v1 by Wajdi Zaghouani, Mustafa Jarrar, Nizar Habash, Houda Bouamor, Imed Zitouni, Mona Diab, Samhaa R. El-Beltagy, Muhammed AbuOdeh

We present an overview of the FIGNEWS shared task, organized as part of the
ArabicNLP 2024 conference co-located with ACL 2024. The shared task addresses
bias and propaganda annotation in multilingual news posts. We focus on the
early days of the Israel War on Gaza as a case study. The task aims to foster
collaboration in developing annotation guidelines for subjective tasks by
creating frameworks for analyzing diverse narratives highlighting potential
bias and propaganda. In a spirit of fostering and encouraging diversity, we
address the problem from a multilingual perspective, namely within five
languages: English, French, Arabic, Hebrew, and Hindi. A total of 17 teams
participated in two annotation subtasks: bias (16 teams) and propaganda (6
teams). The teams competed in four evaluation tracks: guidelines development,
annotation quality, annotation quantity, and consistency. Collectively, the
teams produced 129,800 data points. Key findings and implications for the field
are discussed.

摘要：<paragraph>我們概述了 FIGNEWS 共享任務，該任務作為 ArabicNLP 2024 會議的一部分，與 ACL 2024 共同舉辦。共享任務處理多語言新聞文章中的偏見和宣傳標註。我們專注於以色列對加薩戰爭的早期作為案例研究。該任務旨在通過建立分析不同敘述的框架來促進開發主觀任務的標註指南，重點是潛在的偏見和宣傳。本著培養和鼓勵多樣性的精神，我們從多語言的角度來解決這個問題，即在五種語言中：英語、法語、阿拉伯語、希伯來語和印地語。共有 17 個團隊參與了兩個標註子任務：偏見（16 個團隊）和宣傳（6 個團隊）。這些團隊參加了四個評估軌道：指南制定、標註品質、標註數量和一致性。總的來說，這些團隊產生了 129,800 個數據點。討論了該領域的關鍵發現和影響。</paragraph>

##### **Taxonomy-Aware Continual Semantic Segmentation in Hyperbolic Spaces for Open-World Perception**
2407.18145v1 by Julia Hindel, Daniele Cattaneo, Abhinav Valada

Semantic segmentation models are typically trained on a fixed set of classes,
limiting their applicability in open-world scenarios. Class-incremental
semantic segmentation aims to update models with emerging new classes while
preventing catastrophic forgetting of previously learned ones. However,
existing methods impose strict rigidity on old classes, reducing their
effectiveness in learning new incremental classes. In this work, we propose
Taxonomy-Oriented Poincar\'e-regularized Incremental-Class Segmentation
(TOPICS) that learns feature embeddings in hyperbolic space following explicit
taxonomy-tree structures. This supervision provides plasticity for old classes,
updating ancestors based on new classes while integrating new classes at
fitting positions. Additionally, we maintain implicit class relational
constraints on the geometric basis of the Poincar\'e ball. This ensures that
the latent space can continuously adapt to new constraints while maintaining a
robust structure to combat catastrophic forgetting. We also establish eight
realistic incremental learning protocols for autonomous driving scenarios,
where novel classes can originate from known classes or the background.
Extensive evaluations of TOPICS on the Cityscapes and Mapillary Vistas 2.0
benchmarks demonstrate that it achieves state-of-the-art performance. We make
the code and trained models publicly available at
http://topics.cs.uni-freiburg.de.

摘要：語意分割模型通常在固定的類別集合上訓練，
限制了它們在開放世界場景中的適用性。類別遞增
語意分割旨在使用新出現的類別更新模型，同時
防止災難性地遺忘先前學習的類別。然而，
現有方法對舊類別施加嚴格的剛性，降低了它們
學習新遞增類別的有效性。在這項工作中，我們提出
面向分類學的龐加萊正則化遞增類別分割 (TOPICS)，它在雙曲空間中學習特徵嵌入，遵循明確的
分類樹結構。這種監督為舊類別提供可塑性，
在適當的位置整合新類別的同時，基於新類別更新祖先。此外，我們在龐加萊球的幾何基礎上維持隱式類別關係約束。這確保了
潛在空間可以持續適應新約束，同時維持穩固的結構以對抗災難性遺忘。我們還為自動駕駛場景建立了八個
現實的遞增學習協定，其中新類別可以源自已知類別或背景。
在 Cityscapes 和 Mapillary Vistas 2.0 上對 TOPICS 的廣泛評估
基準證明它達到了最先進的效能。我們將
程式碼和訓練好的模型公開於
http://topics.cs.uni-freiburg.de。

##### **Dallah: A Dialect-Aware Multimodal Large Language Model for Arabic**
2407.18129v2 by Fakhraddin Alwajih, Gagan Bhatia, Muhammad Abdul-Mageed

Recent advancements have significantly enhanced the capabilities of
Multimodal Large Language Models (MLLMs) in generating and understanding
image-to-text content. Despite these successes, progress is predominantly
limited to English due to the scarcity of high quality multimodal resources in
other languages. This limitation impedes the development of competitive models
in languages such as Arabic. To alleviate this situation, we introduce an
efficient Arabic multimodal assistant, dubbed Dallah, that utilizes an advanced
language model based on LLaMA-2 to facilitate multimodal interactions. Dallah
demonstrates state-of-the-art performance in Arabic MLLMs. Through fine-tuning
six Arabic dialects, Dallah showcases its capability to handle complex
dialectal interactions incorporating both textual and visual elements. The
model excels in two benchmark tests: one evaluating its performance on Modern
Standard Arabic (MSA) and another specifically designed to assess dialectal
responses. Beyond its robust performance in multimodal interaction tasks,
Dallah has the potential to pave the way for further development of
dialect-aware Arabic MLLMs.

摘要：最近的進展顯著增強了多模態大型語言模型 (MLLM) 在產生和理解圖像到文字內容方面的能力。儘管取得了這些成功，但由於其他語言中缺乏高品質的多模態資源，進展主要僅限於英語。這種限制阻礙了在阿拉伯語等語言中開發競爭模型。為了緩解這種情況，我們引入了一個高效的阿拉伯語多模態助理，名為 Dallah，它利用基於 LLaMA-2 的先進語言模型來促進多模態互動。Dallah 在阿拉伯語 MLLM 中展示了最先進的性能。通過微調六種阿拉伯語方言，Dallah 展示了其處理複雜方言互動的能力，包括文本和視覺元素。該模型在兩個基準測試中表現出色：一個評估其在現代標準阿拉伯語 (MSA) 上的性能，另一個專門設計用於評估方言回應。除了在多模態互動任務中表現出色外，Dallah 還有可能為進一步開發具有方言意識的阿拉伯語 MLLM 鋪平道路。

##### **Self-supervised pre-training with diffusion model for few-shot landmark detection in x-ray images**
2407.18125v1 by Roberto Di Via, Francesca Odone, Vito Paolo Pastore

In the last few years, deep neural networks have been extensively applied in
the medical domain for different tasks, ranging from image classification and
segmentation to landmark detection. However, the application of these
technologies in the medical domain is often hindered by data scarcity, both in
terms of available annotations and images. This study introduces a new
self-supervised pre-training protocol based on diffusion models for landmark
detection in x-ray images. Our results show that the proposed self-supervised
framework can provide accurate landmark detection with a minimal number of
available annotated training images (up to 50), outperforming ImageNet
supervised pre-training and state-of-the-art self-supervised pre-trainings for
three popular x-ray benchmark datasets. To our knowledge, this is the first
exploration of diffusion models for self-supervised learning in landmark
detection, which may offer a valuable pre-training approach in few-shot
regimes, for mitigating data scarcity.

摘要：在過去幾年中，深度神經網路已廣泛應用於醫療領域的不同任務，從影像分類和分割到地標偵測。然而，這些技術在醫療領域的應用常常受到資料稀少的阻礙，無論是在可用的註解或影像方面。本研究介紹了一個新的自監督預訓練協定，它是基於擴散模型，用於 X 光影像中的地標偵測。我們的結果顯示，所提出的自監督架構可以在最少數量的可用註解訓練影像（最多 50 個）下提供準確的地標偵測，優於 ImageNet 監督式預訓練以及三個熱門 X 光基準資料集的最新自監督式預訓練。據我們所知，這是首次探討擴散模型用於地標偵測中的自監督式學習，它可能在小樣本訓練模式中提供有價值的預訓練方法，以減輕資料稀少的問題。

##### **Tracking linguistic information in transformer-based sentence embeddings through targeted sparsification**
2407.18119v1 by Vivi Nastase, Paola Merlo

Analyses of transformer-based models have shown that they encode a variety of
linguistic information from their textual input. While these analyses have shed
a light on the relation between linguistic information on one side, and
internal architecture and parameters on the other, a question remains
unanswered: how is this linguistic information reflected in sentence
embeddings? Using datasets consisting of sentences with known structure, we
test to what degree information about chunks (in particular noun, verb or
prepositional phrases), such as grammatical number, or semantic role, can be
localized in sentence embeddings. Our results show that such information is not
distributed over the entire sentence embedding, but rather it is encoded in
specific regions. Understanding how the information from an input text is
compressed into sentence embeddings helps understand current transformer models
and help build future explainable neural models.

摘要：基於Transformer的模型分析顯示，它們會對文本輸入編碼各種語言資訊。儘管這些分析已闡明一方面語言資訊與另一方面內部架構和參數之間的關係，但仍有一個問題未獲得解答：這種語言資訊是如何反映在句子嵌入中？我們使用包含已知結構句子的資料集，測試有關區塊（特別是名詞、動詞或介系詞短語）的資訊，例如文法數或語意角色，可以在何種程度上定位在句子嵌入中。我們的結果顯示，此類資訊並未分佈在整個句子嵌入中，而是編碼在特定區域中。了解輸入文字的資訊如何壓縮到句子嵌入中，有助於了解目前的Transformer模型，並有助於建構未來可解釋的神經模型。

##### **Multi-Resolution Histopathology Patch Graphs for Ovarian Cancer Subtyping**
2407.18105v1 by Jack Breen, Katie Allen, Kieran Zucker, Nicolas M. Orsi, Nishant Ravikumar

Computer vision models are increasingly capable of classifying ovarian
epithelial cancer subtypes, but they differ from pathologists by processing
small tissue patches at a single resolution. Multi-resolution graph models
leverage the spatial relationships of patches at multiple magnifications,
learning the context for each patch. In this study, we conduct the most
thorough validation of a graph model for ovarian cancer subtyping to date.
Seven models were tuned and trained using five-fold cross-validation on a set
of 1864 whole slide images (WSIs) from 434 patients treated at Leeds Teaching
Hospitals NHS Trust. The cross-validation models were ensembled and evaluated
using a balanced hold-out test set of 100 WSIs from 30 patients, and an
external validation set of 80 WSIs from 80 patients in the Transcanadian Study.
The best-performing model, a graph model using 10x+20x magnification data, gave
balanced accuracies of 73%, 88%, and 99% in cross-validation, hold-out testing,
and external validation, respectively. However, this only exceeded the
performance of attention-based multiple instance learning in external
validation, with a 93% balanced accuracy. Graph models benefitted greatly from
using the UNI foundation model rather than an ImageNet-pretrained ResNet50 for
feature extraction, with this having a much greater effect on performance than
changing the subsequent classification approach. The accuracy of the combined
foundation model and multi-resolution graph network offers a step towards the
clinical applicability of these models, with a new highest-reported performance
for this task, though further validations are still required to ensure the
robustness and usability of the models.

摘要：電腦視覺模型越來越能夠分類卵巢上皮癌的亞型，但它們與病理學家不同，它們以單一解析度處理小組織貼片。多解析度圖形模型利用多個放大倍率下貼片的空間關係，學習每個貼片的背景。在這項研究中，我們對圖形模型進行了迄今為止最徹底的卵巢癌亞型驗證。使用 434 名在利茲教學醫院 NHS 信託基金接受治療的患者的 1864 張全幻燈片影像 (WSI) 進行五倍交叉驗證，調整並訓練了七個模型。將交叉驗證模型集成並使用來自 30 名患者的 100 張 WSI 的平衡留出測試集和來自 Transcanadian 研究中 80 名患者的 80 張 WSI 的外部驗證集進行評估。表現最佳的模型，一個使用 10 倍+20 倍放大倍率資料的圖形模型，在交叉驗證、留出測試和外部驗證中分別給出 73%、88% 和 99% 的平衡準確度。然而，這僅超過了外部驗證中基於注意力的多實例學習的表現，平衡準確度為 93%。圖形模型從使用 UNI 基礎模型而不是 ImageNet 預訓練的 ResNet50 進行特徵提取中受益匪淺，與改變後續分類方法相比，這對效能有更大的影響。結合基礎模型和多解析度圖形網路的準確度為這些模型的臨床應用邁出了一步，對於這項任務來說，這是新的最高報告表現，儘管仍需要進一步的驗證來確保模型的穩健性和可用性。

##### **Privacy Threats and Countermeasures in Federated Learning for Internet of Things: A Systematic Review**
2407.18096v1 by Adel ElZemity, Budi Arief

Federated Learning (FL) in the Internet of Things (IoT) environments can
enhance machine learning by utilising decentralised data, but at the same time,
it might introduce significant privacy and security concerns due to the
constrained nature of IoT devices. This represents a research challenge that we
aim to address in this paper. We systematically analysed recent literature to
identify privacy threats in FL within IoT environments, and evaluate the
defensive measures that can be employed to mitigate these threats. Using a
Systematic Literature Review (SLR) approach, we searched five publication
databases (Scopus, IEEE Xplore, Wiley, ACM, and Science Direct), collating
relevant papers published between 2017 and April 2024, a period which spans
from the introduction of FL until now. Guided by the PRISMA protocol, we
selected 49 papers to focus our systematic review on. We analysed these papers,
paying special attention to the privacy threats and defensive measures --
specifically within the context of IoT -- using inclusion and exclusion
criteria tailored to highlight recent advances and critical insights. We
identified various privacy threats, including inference attacks, poisoning
attacks, and eavesdropping, along with defensive measures such as Differential
Privacy and Secure Multi-Party Computation. These defences were evaluated for
their effectiveness in protecting privacy without compromising the functional
integrity of FL in IoT settings. Our review underscores the necessity for
robust and efficient privacy-preserving strategies tailored for IoT
environments. Notably, there is a need for strategies against replay, evasion,
and model stealing attacks. Exploring lightweight defensive measures and
emerging technologies such as blockchain may help improve the privacy of FL in
IoT, leading to the creation of FL models that can operate under variable
network conditions.

摘要：<paragraph>聯邦學習 (FL) 在物聯網 (IoT) 環境中可以利用分散式數據增強機器學習，但同時，由於 IoT 設備的受限性質，它可能會帶來重大的隱私和安全問題。這是一個研究挑戰，我們希望在本文中解決這個問題。我們系統地分析了最近的文獻，以識別 IoT 環境中 FL 中的隱私威脅，並評估可採取的防禦措施來減輕這些威脅。使用系統文獻回顧 (SLR) 方法，我們搜索了五個出版物資料庫（Scopus、IEEE Xplore、Wiley、ACM 和 Science Direct），整理了 2017 年至 2024 年 4 月之間發表的相關論文，這段時間涵蓋了 FL 的引入至今。在 PRISMA 協議的指導下，我們選擇了 49 篇論文作為系統回顧的重點。我們分析了這些論文，特別關注隱私威脅和防禦措施——特別是在 IoT 的背景下——使用量身定制的包含和排除標準來強調最近的進展和批判性見解。我們發現了各種隱私威脅，包括推理攻擊、中毒攻擊和竊聽，以及防禦措施，例如差分隱私和安全多方計算。這些防禦措施的有效性在於保護隱私，同時不損害 IoT 設置中 FL 的功能完整性。我們的回顧強調了針對 IoT 環境量身定制的強大且有效的隱私保護策略的必要性。值得注意的是，需要針對重播、規避和模型竊取攻擊制定策略。探索輕量級防禦措施和區塊鏈等新興技術可能有助於提高 IoT 中 FL 的隱私性，從而創建可在變量網路條件下運作的 FL 模型。</paragraph>

##### **PEFT-U: Parameter-Efficient Fine-Tuning for User Personalization**
2407.18078v1 by Christopher Clarke, Yuzhao Heng, Lingjia Tang, Jason Mars

The recent emergence of Large Language Models (LLMs) has heralded a new era
of human-AI interaction. These sophisticated models, exemplified by Chat-GPT
and its successors, have exhibited remarkable capabilities in language
understanding. However, as these LLMs have undergone exponential growth, a
crucial dimension that remains understudied is the personalization of these
models. Large foundation models such as GPT-3 etc. focus on creating a
universal model that serves a broad range of tasks and users. This approach
emphasizes the model's generalization capabilities, treating users as a
collective rather than as distinct individuals. While practical for many common
applications, this one-size-fits-all approach often fails to address the rich
tapestry of human diversity and individual needs. To explore this issue we
introduce the PEFT-U Benchmark: a new dataset for building and evaluating NLP
models for user personalization. \datasetname{} consists of a series of
user-centered tasks containing diverse and individualized expressions where the
preferences of users can potentially differ for the same input. Using PEFT-U,
we explore the challenge of efficiently personalizing LLMs to accommodate
user-specific preferences in the context of diverse user-centered tasks.

摘要：大型語言模型 (LLM) 近期興起，預示著人機互動的新紀元。這些精密的模型，以 Chat-GPT 及其後繼者為例，在語言理解方面展現了非凡的能力。然而，隨著這些 LLM 經歷指數級增長，一個仍未得到充分研究的重要面向是這些模型的個人化。大型基礎模型，例如 GPT-3 等，專注於建立一個通用的模型，服務於廣泛的任務和使用者。此方法強調模型的概化能力，將使用者視為一個集體，而非獨立的個體。雖然對許多常見應用來說很實用，但這種一體適用的方法通常無法滿足人類多元性和個別需求的豐富性。為了探討此問題，我們引入了 PEFT-U 基準：一個用於建立和評估使用者個人化 NLP 模型的新資料集。\datasetname{} 包含一系列以使用者為中心的任務，其中包含多樣化且個性化的表達，使用者的偏好可能因相同的輸入而有所不同。使用 PEFT-U，我們探討了在多元化以使用者為中心的任務中，有效個人化 LLM 以適應使用者特定偏好的挑戰。

##### **Difficulty Estimation and Simplification of French Text Using LLMs**
2407.18061v1 by Henri Jamet, Yash Raj Shrestha, Michalis Vlachos

We leverage generative large language models for language learning
applications, focusing on estimating the difficulty of foreign language texts
and simplifying them to lower difficulty levels. We frame both tasks as
prediction problems and develop a difficulty classification model using labeled
examples, transfer learning, and large language models, demonstrating superior
accuracy compared to previous approaches. For simplification, we evaluate the
trade-off between simplification quality and meaning preservation, comparing
zero-shot and fine-tuned performances of large language models. We show that
meaningful text simplifications can be obtained with limited fine-tuning. Our
experiments are conducted on French texts, but our methods are
language-agnostic and directly applicable to other foreign languages.

摘要：我們利用生成式大型語言模型進行語言學習應用，重點在於估計外語文本的難度並將其簡化為較低的難度等級。我們將這兩個任務都設定為預測問題，並使用標記範例、轉移學習和大語言模型開發難度分類模型，與先前的做法相比，證明了其優越的準確性。對於簡化，我們評估了簡化品質與意義保留之間的取捨，比較大型語言模型的零次學習和微調效能。我們表明，透過有限的微調，可以獲得有意義的文本簡化。我們的實驗是在法語文本上進行的，但我們的語言方法與語言無關，並且可直接應用於其他外語。

##### **Peak-Controlled Logits Poisoning Attack in Federated Distillation**
2407.18039v1 by Yuhan Tang, Aoxu Zhang, Zhiyuan Wu, Bo Gao, Tian Wen, Yuwei Wang, Sheng Sun

Federated Distillation (FD) offers an innovative approach to distributed
machine learning, leveraging knowledge distillation for efficient and flexible
cross-device knowledge transfer without necessitating the upload of extensive
model parameters to a central server. While FD has gained popularity, its
vulnerability to poisoning attacks remains underexplored. To address this gap,
we previously introduced FDLA (Federated Distillation Logits Attack), a method
that manipulates logits communication to mislead and degrade the performance of
client models. However, the impact of FDLA on participants with different
identities and the effects of malicious modifications at various stages of
knowledge transfer remain unexplored. To this end, we present PCFDLA
(Peak-Controlled Federated Distillation Logits Attack), an advanced and more
stealthy logits poisoning attack method for FD. PCFDLA enhances the
effectiveness of FDLA by carefully controlling the peak values of logits to
create highly misleading yet inconspicuous modifications. Furthermore, we
introduce a novel metric for better evaluating attack efficacy, demonstrating
that PCFDLA maintains stealth while being significantly more disruptive to
victim models compared to its predecessors. Experimental results across various
datasets confirm the superior impact of PCFDLA on model accuracy, solidifying
its potential threat in federated distillation systems.

摘要：联邦蒸馏 (FD) 提供了一种分布式机器学习的创新方法，它利用知识蒸馏来实现高效且灵活的跨设备知识转移，而无需将大量的模型参数上传到中央服务器。虽然 FD 已获得普及，但其对中毒攻击的脆弱性仍未得到充分探索。为了解决这一差距，我们之前引入了 FDLA（联邦蒸馏 Logits 攻击），这是一种通过操纵 Logits 通信来误导并降低客户端模型性能的方法。但是，FDLA 对具有不同身份的参与者的影响以及在知识转移的不同阶段进行恶意修改的影响仍未得到探索。为此，我们提出了 PCFDLA（峰值控制联邦蒸馏 Logits 攻击），这是一种针对 FD 的高级且更隐蔽的 Logits 中毒攻击方法。PCFDLA 通过仔细控制 Logits 的峰值来增强 FDLA 的有效性，以创建极具误导性但又不引人注目的修改。此外，我们引入了一个新指标来更好地评估攻击效果，证明 PCFDLA 在保持隐蔽性的同时，与之前的攻击方法相比，对受害者模型的破坏性更大。跨各种数据集的实验结果证实了 PCFDLA 对模型精度的卓越影响，巩固了其在联邦蒸馏系统中的潜在威胁。

##### **RestoreAgent: Autonomous Image Restoration Agent via Multimodal Large Language Models**
2407.18035v1 by Haoyu Chen, Wenbo Li, Jinjin Gu, Jingjing Ren, Sixiang Chen, Tian Ye, Renjing Pei, Kaiwen Zhou, Fenglong Song, Lei Zhu

Natural images captured by mobile devices often suffer from multiple types of
degradation, such as noise, blur, and low light. Traditional image restoration
methods require manual selection of specific tasks, algorithms, and execution
sequences, which is time-consuming and may yield suboptimal results. All-in-one
models, though capable of handling multiple tasks, typically support only a
limited range and often produce overly smooth, low-fidelity outcomes due to
their broad data distribution fitting. To address these challenges, we first
define a new pipeline for restoring images with multiple degradations, and then
introduce RestoreAgent, an intelligent image restoration system leveraging
multimodal large language models. RestoreAgent autonomously assesses the type
and extent of degradation in input images and performs restoration through (1)
determining the appropriate restoration tasks, (2) optimizing the task
sequence, (3) selecting the most suitable models, and (4) executing the
restoration. Experimental results demonstrate the superior performance of
RestoreAgent in handling complex degradation, surpassing human experts.
Furthermore, the system modular design facilitates the fast integration of new
tasks and models, enhancing its flexibility and scalability for various
applications.

摘要：行動裝置拍攝的自然影像通常會受到多種類型的劣化，例如雜訊、模糊和低光源。傳統的影像修復方法需要手動選擇特定任務、演算法和執行順序，這既耗時又可能產生次佳的結果。雖然一體成型的模型能夠處理多項任務，但通常只支援有限的範圍，而且由於其廣泛的資料分佈擬合，通常會產生過於平滑、低保真的結果。為了應對這些挑戰，我們首先定義了一個新的管道來修復具有多重劣化現象的影像，然後介紹 RestoreAgent，一個利用多模態大型語言模型的智慧影像修復系統。RestoreAgent 自主評估輸入影像的劣化類型和程度，並透過 (1) 確定適當的修復任務、(2) 最佳化任務順序、(3) 選擇最合適的模型，以及 (4) 執行修復來執行修復。實驗結果證明 RestoreAgent 在處理複雜劣化方面的優異效能，超越了人類專家。此外，系統模組化設計有助於快速整合新的任務和模型，增強其靈活性，並擴充其在各種應用程式中的可擴充性。

##### **AttentionHand: Text-driven Controllable Hand Image Generation for 3D Hand Reconstruction in the Wild**
2407.18034v1 by Junho Park, Kyeongbo Kong, Suk-Ju Kang

Recently, there has been a significant amount of research conducted on 3D
hand reconstruction to use various forms of human-computer interaction.
However, 3D hand reconstruction in the wild is challenging due to extreme lack
of in-the-wild 3D hand datasets. Especially, when hands are in complex pose
such as interacting hands, the problems like appearance similarity, self-handed
occclusion and depth ambiguity make it more difficult. To overcome these
issues, we propose AttentionHand, a novel method for text-driven controllable
hand image generation. Since AttentionHand can generate various and numerous
in-the-wild hand images well-aligned with 3D hand label, we can acquire a new
3D hand dataset, and can relieve the domain gap between indoor and outdoor
scenes. Our method needs easy-to-use four modalities (i.e, an RGB image, a hand
mesh image from 3D label, a bounding box, and a text prompt). These modalities
are embedded into the latent space by the encoding phase. Then, through the
text attention stage, hand-related tokens from the given text prompt are
attended to highlight hand-related regions of the latent embedding. After the
highlighted embedding is fed to the visual attention stage, hand-related
regions in the embedding are attended by conditioning global and local hand
mesh images with the diffusion-based pipeline. In the decoding phase, the final
feature is decoded to new hand images, which are well-aligned with the given
hand mesh image and text prompt. As a result, AttentionHand achieved
state-of-the-art among text-to-hand image generation models, and the
performance of 3D hand mesh reconstruction was improved by additionally
training with hand images generated by AttentionHand.

摘要：<paragraph>最近，已针对 3D 手部重建进行了大量研究，以使用各种形式的人机交互。
然而，由于极度缺乏野外 3D 手部数据集，野外 3D 手部重建具有挑战性。特别是在手部处于复杂姿势（例如交互手部）时，外观相似性、自手遮挡和深度歧义等问题使情况变得更加困难。为了克服这些问题，我们提出了 AttentionHand，这是一种用于文本驱动的可控手部图像生成的新方法。由于 AttentionHand 可以生成各种大量与 3D 手部标签对齐良好的野外手部图像，我们可以获取新的 3D 手部数据集，并且可以缓解室内和室外场景之间的领域差距。我们的方法需要易于使用的四种模态（即 RGB 图像、3D 标签中的手部网格图像、边界框和文本提示）。这些模态通过编码阶段嵌入到潜在空间中。然后，通过文本注意力阶段，来自给定文本提示的手部相关标记被用来突出潜在嵌入中的手部相关区域。在突出显示的嵌入被馈送到视觉注意力阶段后，嵌入中的手部相关区域通过基于扩散的管道与全局和局部手部网格图像进行条件处理。在解码阶段，最终特征被解码为新的手部图像，这些图像与给定的手部网格图像和文本提示对齐良好。结果，AttentionHand 在文本到手部图像生成模型中实现了最先进的水平，并且通过使用 AttentionHand 生成的图像进行额外训练，改进了 3D 手部网格重建的性能。</paragraph>

##### **Learning mental states estimation through self-observation: a developmental synergy between intentions and beliefs representations in a deep-learning model of Theory of Mind**
2407.18022v1 by Francesca Bianco, Silvia Rigato, Maria Laura Filippetti, Dimitri Ognibene

Theory of Mind (ToM), the ability to attribute beliefs, intentions, or mental
states to others, is a crucial feature of human social interaction. In complex
environments, where the human sensory system reaches its limits, behaviour is
strongly driven by our beliefs about the state of the world around us.
Accessing others' mental states, e.g., beliefs and intentions, allows for more
effective social interactions in natural contexts. Yet, these variables are not
directly observable, making understanding ToM a challenging quest of interest
for different fields, including psychology, machine learning and robotics. In
this paper, we contribute to this topic by showing a developmental synergy
between learning to predict low-level mental states (e.g., intentions, goals)
and attributing high-level ones (i.e., beliefs). Specifically, we assume that
learning beliefs attribution can occur by observing one's own decision
processes involving beliefs, e.g., in a partially observable environment. Using
a simple feed-forward deep learning model, we show that, when learning to
predict others' intentions and actions, more accurate predictions can be
acquired earlier if beliefs attribution is learnt simultaneously. Furthermore,
we show that the learning performance improves even when observed actors have a
different embodiment than the observer and the gain is higher when observing
beliefs-driven chunks of behaviour. We propose that our computational approach
can inform the understanding of human social cognitive development and be
relevant for the design of future adaptive social robots able to autonomously
understand, assist, and learn from human interaction partners in novel natural
environments and tasks.

摘要：心智理論 (ToM) 是將信念、意圖或心智狀態歸因於他人的能力，是人類社交互動的一項關鍵特徵。在複雜的環境中，人類的感官系統會達到其極限，行為會受到我們對周遭世界狀態的信念強烈驅使。存取他人的心智狀態，例如信念和意圖，可以在自然情境中進行更有效的社交互動。然而，這些變數並非直接可觀察，使得理解心智理論成為一個具有挑戰性的任務，引起心理學、機器學習和機器人學等不同領域的興趣。在本文中，我們透過展示預測低階心智狀態（例如意圖、目標）和歸因高階心智狀態（即信念）之間的發展協同作用，為此主題做出貢獻。具體來說，我們假設信念歸因學習可以透過觀察個人涉及信念的決策過程來進行，例如在部分可觀察的環境中。使用簡單的前饋深度學習模型，我們展示在學習預測他人的意圖和行為時，如果同時學習信念歸因，可以更早獲得更準確的預測。此外，我們展示即使觀察到的行為者與觀察者具有不同的具體化，學習表現也會有所提升，而且在觀察由信念驅動的行為片段時，增益會更高。我們提出我們的計算方法可以為理解人類社會認知發展提供資訊，並與未來適應性社會機器人的設計相關，這些機器人能夠在新的自然環境和任務中自主理解、協助和從人類互動夥伴那裡學習。

##### **Quadratic Advantage with Quantum Randomized Smoothing Applied to Time-Series Analysis**
2407.18021v1 by Nicola Franco, Marie Kempkes, Jakob Spiegelberg, Jeanette Miriam Lorenz

As quantum machine learning continues to develop at a rapid pace, the
importance of ensuring the robustness and efficiency of quantum algorithms
cannot be overstated. Our research presents an analysis of quantum randomized
smoothing, how data encoding and perturbation modeling approaches can be
matched to achieve meaningful robustness certificates. By utilizing an
innovative approach integrating Grover's algorithm, a quadratic sampling
advantage over classical randomized smoothing is achieved. This strategy
necessitates a basis state encoding, thus restricting the space of meaningful
perturbations. We show how constrained $k$-distant Hamming weight perturbations
are a suitable noise distribution here, and elucidate how they can be
constructed on a quantum computer. The efficacy of the proposed framework is
demonstrated on a time series classification task employing a Bag-of-Words
pre-processing solution. The advantage of quadratic sample reduction is
recovered especially in the regime with large number of samples. This may allow
quantum computers to efficiently scale randomized smoothing to more complex
tasks beyond the reach of classical methods.

摘要：隨著量子機器學習持續快速發展，確保量子演算法的穩健性和效率至關重要。我們的研究分析了量子隨機平滑，以及如何將資料編碼和擾動建模方法匹配以取得有意義的穩健性證明。透過整合葛羅佛演算法的創新方法，達成相較於古典隨機平滑的二次取樣優勢。此策略需要基底態編碼，因此限制了有意義的擾動空間。我們展示了受約束的 k 遠距漢明權重擾動在此處為合適的雜訊分佈，並說明如何在量子電腦上建構它們。所提出的架構效能已在使用詞袋預處理解決方案的時間序列分類任務中得到驗證。二次取樣減少的優勢特別在大量樣本的條件下得以恢復。這可能讓量子電腦有效地將隨機平滑擴展到更複雜的任務，超越古典方法的範圍。

##### **GermanPartiesQA: Benchmarking Commercial Large Language Models for Political Bias and Sycophancy**
2407.18008v1 by Jan Batzner, Volker Stocker, Stefan Schmid, Gjergji Kasneci

LLMs are changing the way humans create and interact with content,
potentially affecting citizens' political opinions and voting decisions. As
LLMs increasingly shape our digital information ecosystems, auditing to
evaluate biases, sycophancy, or steerability has emerged as an active field of
research. In this paper, we evaluate and compare the alignment of six LLMs by
OpenAI, Anthropic, and Cohere with German party positions and evaluate
sycophancy based on a prompt experiment. We contribute to evaluating political
bias and sycophancy in multi-party systems across major commercial LLMs. First,
we develop the benchmark dataset GermanPartiesQA based on the Voting Advice
Application Wahl-o-Mat covering 10 state and 1 national elections between 2021
and 2023. In our study, we find a left-green tendency across all examined LLMs.
We then conduct our prompt experiment for which we use the benchmark and
sociodemographic data of leading German parliamentarians to evaluate changes in
LLMs responses. To differentiate between sycophancy and steerabilty, we use 'I
am [politician X], ...' and 'You are [politician X], ...' prompts. Against our
expectations, we do not observe notable differences between prompting 'I am'
and 'You are'. While our findings underscore that LLM responses can be
ideologically steered with political personas, they suggest that observed
changes in LLM outputs could be better described as personalization to the
given context rather than sycophancy.

摘要：大型語言模型 (LLM) 正在改變人類建立和互動內容的方式，
潛在地影響公民的政治觀點和投票決定。由於
LLM 愈來愈形塑我們的數位資訊生態系統，審查以
評估偏見、阿諛奉承或可操縱性已成為一項活躍的研究領域。在本文中，我們評估並比較 OpenAI、Anthropic 和 Cohere 的六個 LLM 與德國政黨立場的一致性，並根據提示實驗評估阿諛奉承。我們致力於評估主要商業 LLM 中多黨制的政治偏見和阿諛奉承。首先，
我們根據投票建議應用程式 Wahl-o-Mat 開發基準資料集 GermanPartiesQA，涵蓋 2021 年至 2023 年之間的 10 次州選舉和 1 次全國選舉。在我們的研究中，我們發現所有受檢 LLM 都傾向於左綠。然後，我們進行提示實驗，我們使用基準和德國國會議員的社會人口資料來評估 LLM 回應的變化。為了區分阿諛奉承和可操縱性，我們使用「我是 [政治人物 X]，...」和「你是 [政治人物 X]，...」提示。與我們的預期相反，我們沒有觀察到提示「我是」和「你是」之間的顯著差異。雖然我們的研究結果強調 LLM 回應可以用政治人物來進行意識形態操縱，但它們表明，觀察到的 LLM 輸出變化可以更適切地描述為對特定脈絡的個人化，而不是阿諛奉承。

##### **Keep the Cost Down: A Review on Methods to Optimize LLM' s KV-Cache Consumption**
2407.18003v1 by Shi Luohe, Zhang Hongyi, Yao Yao, Li Zuchao, Zhao Hai

Large Language Models (LLMs), epitomized by ChatGPT' s release in late 2022,
have revolutionized various industries with their advanced language
comprehension. However, their efficiency is challenged by the Transformer
architecture' s struggle with handling long texts. KV-Cache has emerged as a
pivotal solution to this issue, converting the time complexity of token
generation from quadratic to linear, albeit with increased GPU memory overhead
proportional to conversation length. With the development of the LLM community
and academia, various KV-Cache compression methods have been proposed. In this
review, we dissect the various properties of KV-Cache and elaborate on various
methods currently used to optimize the KV-Cache space usage of LLMs. These
methods span the pre-training phase, deployment phase, and inference phase, and
we summarize the commonalities and differences among these methods.
Additionally, we list some metrics for evaluating the long-text capabilities of
large language models, from both efficiency and capability perspectives. Our
review thus sheds light on the evolving landscape of LLM optimization, offering
insights into future advancements in this dynamic field.

摘要：大型語言模型 (LLM)，以 2022 年底發布的 ChatGPT 為代表，
以其先進的語言理解力徹底改變了各個產業。然而，其效率受到 Transformer
架構在處理長文字時所遭遇的困難所挑戰。KV 快取已成為解決此問題的關鍵解決方案，將 token
產生的時間複雜度從二次轉換為線性，儘管 GPU 記憶體開銷會隨著對話長度成比例地增加。隨著 LLM 社群
和學術界的發展，已提出各種 KV 快取壓縮方法。在此
回顧中，我們剖析了 KV 快取的各種特性，並闡述了目前用於最佳化 LLM 的 KV 快取空間使用率的各種
方法。這些
方法涵蓋了預訓練階段、部署階段和推論階段，我們總結了這些方法之間的共性和差異。
此外，我們列出了一些用於評估大型語言模型長文字能力的指標，從效率和能力的角度來看。因此，我們的
回顧闡明了 LLM 最佳化的演變趨勢，提供了對此動態領域未來進展的見解。

##### **On the Effect of Purely Synthetic Training Data for Different Automatic Speech Recognition Architectures**
2407.17997v1 by Nick Rossenbach, Benedikt Hilmes, Ralf Schlüter

In this work we evaluate the utility of synthetic data for training automatic
speech recognition (ASR). We use the ASR training data to train a
text-to-speech (TTS) system similar to FastSpeech-2. With this TTS we reproduce
the original training data, training ASR systems solely on synthetic data. For
ASR, we use three different architectures, attention-based encoder-decoder,
hybrid deep neural network hidden Markov model and a Gaussian mixture hidden
Markov model, showing the different sensitivity of the models to synthetic data
generation. In order to extend previous work, we present a number of ablation
studies on the effectiveness of synthetic vs. real training data for ASR. In
particular we focus on how the gap between training on synthetic and real data
changes by varying the speaker embedding or by scaling the model size. For the
latter we show that the TTS models generalize well, even when training scores
indicate overfitting.

摘要：在這項工作中，我們評估了合成資料在訓練自動語音辨識 (ASR) 的效用。我們使用 ASR 訓練資料來訓練類似 FastSpeech-2 的文字轉語音 (TTS) 系統。透過這個 TTS，我們重現原始訓練資料，僅使用合成資料訓練 ASR 系統。對於 ASR，我們使用三種不同的架構：基於注意力的編碼器-解碼器、混合深度神經網路隱藏馬可夫模型和高斯混合隱藏馬可夫模型，顯示模型對合成資料生成的敏感度不同。為了擴展先前的研究，我們提出了一些關於合成與真實訓練資料對 ASR 有效性的消融研究。特別是，我們專注於透過改變說話者嵌入或調整模型大小，來縮小在合成資料和真實資料上訓練的差距。對於後者，我們表明 TTS 模型具有良好的泛化性，即使訓練分數表示過度擬合。

##### **What does Kiki look like? Cross-modal associations between speech sounds and visual shapes in vision-and-language models**
2407.17974v1 by Tessa Verhoef, Kiana Shahrasbi, Tom Kouwenhoven

Humans have clear cross-modal preferences when matching certain novel words
to visual shapes. Evidence suggests that these preferences play a prominent
role in our linguistic processing, language learning, and the origins of
signal-meaning mappings. With the rise of multimodal models in AI, such as
vision- and-language (VLM) models, it becomes increasingly important to uncover
the kinds of visio-linguistic associations these models encode and whether they
align with human representations. Informed by experiments with humans, we probe
and compare four VLMs for a well-known human cross-modal preference, the
bouba-kiki effect. We do not find conclusive evidence for this effect but
suggest that results may depend on features of the models, such as architecture
design, model size, and training details. Our findings inform discussions on
the origins of the bouba-kiki effect in human cognition and future developments
of VLMs that align well with human cross-modal associations.

摘要：人類在將某些新字詞與視覺形狀配對時，具有明確的跨模態偏好。證據顯示這些偏好會在我們的語言處理、語言學習，以及符號與意義對應的起源中扮演重要的角色。隨著多模態模型在人工智慧領域的興起，例如視覺和語言 (VLM) 模型，揭露這些模型編碼的視覺語言關聯類型，以及它們是否與人類表徵一致，變得越來越重要。我們從人類實驗中獲得啟發，探討並比較四個 VLM 以了解眾所周知的 bouba-kiki 效應，這是人類著名的跨模態偏好。我們沒有找到此效應的決定性證據，但我們認為結果可能取決於模型的特徵，例如架構設計、模型大小和訓練細節。我們的研究結果有助於討論人類認知中 bouba-kiki 效應的起源，以及與人類跨模態關聯相符的 VLM 未來發展。

##### **Relating the Seemingly Unrelated: Principled Understanding of Generalization for Generative Models in Arithmetic Reasoning Tasks**
2407.17963v1 by Xingcheng Xu, Zibo Zhao, Haipeng Zhang, Yanqing Yang

Large language models (LLMs) have demonstrated impressive versatility across
numerous tasks, yet their generalization capabilities remain poorly understood.
To investigate these behaviors, arithmetic tasks serve as important venues. In
previous studies, seemingly unrelated mysteries still exist -- (1) models with
appropriate positional embeddings can correctly perform longer unseen
arithmetic operations such as addition, but their effectiveness varies in more
complex tasks like multiplication; (2) models perform well for longer unseen
cases in modular addition under specific moduli (e.g., modulo 100) but struggle
under very close moduli (e.g., modulo 101), regardless of the positional
encoding used. We believe previous studies have been treating the symptoms
rather than addressing the root cause -- they have paid excessive attention to
improving model components, while overlooking the differences in task
properties that may be the real drivers. This is confirmed by our unified
theoretical framework for different arithmetic scenarios. For example, unlike
multiplication, the digital addition task has the property of translation
invariance which naturally aligns with the relative positional encoding, and
this combination leads to successful generalization of addition to unseen
longer domains. The discrepancy in operations modulo 100 and 101 arises from
the base. Modulo 100, unlike 101, is compatible with the decimal system (base
10), such that unseen information in digits beyond the units digit and the tens
digit is actually not needed for the task. Extensive experiments with GPT-like
models validate our theoretical predictions. These findings deepen our
understanding of the generalization mechanisms, and facilitate more
data-efficient model training and objective-oriented AI alignment.

摘要：大型語言模型 (LLM) 已在眾多任務中展現出令人印象深刻的多功能性，但其概化能力仍鮮為人知。為了研究這些行為，算術任務扮演著重要的角色。在先前的研究中，看似無關的謎團仍然存在：(1) 具有適當位置嵌入的模型可以正確執行較長的未見算術運算，例如加法，但其在乘法等更複雜的任務中的效果卻有所不同；(2) 模型在特定模數 (例如模數 100) 下的較長未見情況中表現良好，但在非常接近的模數 (例如模數 101) 下卻會遇到困難，無論使用何種位置編碼。我們認為先前的研究一直在治療症狀，而不是解決根本原因——它們過度關注於改進模型組成部分，而忽視了可能是真正驅動因素的任務屬性差異。這一點已由我們針對不同算術場景提出的統一理論框架所證實。例如，與乘法不同，數位加法任務具有平移不變性的屬性，這自然與相對位置編碼一致，而這種組合導致加法成功概化到未見的較長網域。模數 100 和 101 運算中的差異源於基數。與 101 不同，模數 100 與十進位系統 (基數 10) 相容，因此在個位數和十位數之外的數字中未見的資訊實際上對於任務並非必要。使用類似 GPT 的模型進行的廣泛實驗驗證了我們的理論預測。這些發現加深了我們對概化機制的理解，並促進了更具資料效率的模型訓練和目標導向的人工智慧對齊。

##### **The Curious Case of Representational Alignment: Unravelling Visio-Linguistic Tasks in Emergent Communication**
2407.17960v1 by Tom Kouwenhoven, Max Peeperkorn, Bram van Dijk, Tessa Verhoef

Natural language has the universal properties of being compositional and
grounded in reality. The emergence of linguistic properties is often
investigated through simulations of emergent communication in referential
games. However, these experiments have yielded mixed results compared to
similar experiments addressing linguistic properties of human language. Here we
address representational alignment as a potential contributing factor to these
results. Specifically, we assess the representational alignment between agent
image representations and between agent representations and input images. Doing
so, we confirm that the emergent language does not appear to encode human-like
conceptual visual features, since agent image representations drift away from
inputs whilst inter-agent alignment increases. We moreover identify a strong
relationship between inter-agent alignment and topographic similarity, a common
metric for compositionality, and address its consequences. To address these
issues, we introduce an alignment penalty that prevents representational drift
but interestingly does not improve performance on a compositional
discrimination task. Together, our findings emphasise the key role
representational alignment plays in simulations of language emergence.

摘要：自然語言具有組成性且根植於現實的普遍屬性。語言屬性的出現經常透過指涉遊戲中緊急溝通的模擬來調查。然而，與探討人類語言語言屬性的類似實驗相比，這些實驗產生了不同的結果。在此，我們探討表徵對齊作為這些結果的潛在促成因素。具體來說，我們評估代理影像表徵之間以及代理表徵與輸入影像之間的表徵對齊。這樣做，我們確認緊急語言似乎沒有編碼類人概念視覺特徵，因為代理影像表徵偏離輸入，而代理間對齊則增加。此外，我們確認代理間對齊與拓撲相似性（組成性的常見指標）之間的強大關係，並探討其後果。為了解決這些問題，我們引入了防止表徵漂移的對齊懲罰，但有趣的是，這並未提升組成性區辨任務的表現。我們的發現共同強調了表徵對齊在語言出現模擬中扮演的重要角色。

##### **Real Time American Sign Language Detection Using Yolo-v9**
2407.17950v1 by Amna Imran, Meghana Shashishekhara Hulikal, Hamza A. A. Gardi

This paper focuses on real-time American Sign Language Detection. YOLO is a
convolutional neural network (CNN) based model, which was first released in
2015. In recent years, it gained popularity for its real-time detection
capabilities. Our study specifically targets YOLO-v9 model, released in 2024.
As the model is newly introduced, not much work has been done on it, especially
not in Sign Language Detection. Our paper provides deep insight on how YOLO- v9
works and better than previous model.

摘要：本論文專注於即時美國手語偵測。YOLO 是一種基於捲積神經網路 (CNN) 的模型，最早於 2015 年發布。近年來，由於其即時偵測能力而廣受歡迎。我們的研究特別針對 2024 年發布的 YOLO-v9 模型。由於該模型是新推出的，因此尚未有太多研究，特別是在手語偵測方面。我們的論文深入探討了 YOLO-v9 的運作方式，並說明其優於先前的模型。

##### **Positive Text Reframing under Multi-strategy Optimization**
2407.17940v1 by Shutong Jia, Biwei Cao, Qingqing Gao, Jiuxin Cao, Bo Liu

Differing from sentiment transfer, positive reframing seeks to substitute
negative perspectives with positive expressions while preserving the original
meaning. With the emergence of pre-trained language models (PLMs), it is
possible to achieve acceptable results by fine-tuning PLMs. Nevertheless,
generating fluent, diverse and task-constrained reframing text remains a
significant challenge. To tackle this issue, a \textbf{m}ulti-\textbf{s}trategy
\textbf{o}ptimization \textbf{f}ramework (MSOF) is proposed in this paper.
Starting from the objective of positive reframing, we first design positive
sentiment reward and content preservation reward to encourage the model to
transform the negative expressions of the original text while ensuring the
integrity and consistency of the semantics. Then, different decoding
optimization approaches are introduced to improve the quality of text
generation. Finally, based on the modeling formula of positive reframing, we
propose a multi-dimensional re-ranking method that further selects candidate
sentences from three dimensions: strategy consistency, text similarity and
fluency. Extensive experiments on two Seq2Seq PLMs, BART and T5, demonstrate
our framework achieves significant improvements on unconstrained and controlled
positive reframing tasks.

摘要：與情緒轉移不同，正向重構試圖以正向表達取代負面觀點，同時保留原始意思。隨著預訓練語言模型 (PLM) 的出現，透過微調 PLM 可以達成可接受的結果。然而，產生流暢、多樣化且符合任務限制的重構文本仍然是一項重大挑戰。為了解決這個問題，本文提出了一個多策略最佳化框架 (MSOF)。從正向重構的目標開始，我們首先設計正向情緒獎勵和內容保留獎勵，以鼓勵模型轉換原始文本的負面表達，同時確保語意的完整性和一致性。然後，引入不同的解碼最佳化方法來提升文本生成的品質。最後，基於正向重構的建模公式，我們提出了一個多維度的重新排序方法，從策略一致性、文字相似性和流暢度三個面向進一步選擇候選句子。在兩個 Seq2Seq PLM，BART 和 T5 上進行的廣泛實驗證明，我們的框架在不受限和受控的正向重構任務上獲得顯著的改進。

##### **Comparison of different Artificial Neural Networks for Bitcoin price forecasting**
2407.17930v1 by Silas Baumann, Karl A. Busch, Hamza A. A. Gardi

This study investigates the impact of varying sequence lengths on the
accuracy of predicting cryptocurrency returns using Artificial Neural Networks
(ANNs). Utilizing the Mean Absolute Error (MAE) as a threshold criterion, we
aim to enhance prediction accuracy by excluding returns that are smaller than
this threshold, thus mitigating errors associated with minor returns. The
subsequent evaluation focuses on the accuracy of predicted returns that exceed
this threshold. We compare four sequence lengths 168 hours (7 days), 72 hours
(3 days), 24 hours, and 12 hours each with a return prediction interval of 2
hours. Our findings reveal the influence of sequence length on prediction
accuracy and underscore the potential for optimized sequence configurations in
financial forecasting models.

摘要：本研究探討了序列長度變異對使用人工神經網路 (ANN) 預測加密貨幣報酬率準確度的影響。我們利用平均絕對誤差 (MAE) 作為閾值標準，旨在透過排除小於此閾值的報酬率來提升預測準確度，進而減輕與微小報酬率相關的誤差。後續評估著重於超過此閾值的預測報酬率準確度。我們比較了四種序列長度：168 小時 (7 天)、72 小時 (3 天)、24 小時和 12 小時，每個序列長度搭配 2 小時的報酬率預測區間。我們的發現揭示了序列長度對預測準確度的影響，並強調了在財務預測模型中優化序列組態的潛力。

##### **Invariance of deep image quality metrics to affine transformations**
2407.17927v1 by Nuria Alabau-Bosque, Paula Daudén-Oliver, Jorge Vila-Tomás, Valero Laparra, Jesús Malo

Deep architectures are the current state-of-the-art in predicting subjective
image quality. Usually, these models are evaluated according to their ability
to correlate with human opinion in databases with a range of distortions that
may appear in digital media. However, these oversee affine transformations
which may represent better the changes in the images actually happening in
natural conditions. Humans can be particularly invariant to these natural
transformations, as opposed to the digital ones. In this work, we evaluate
state-of-the-art deep image quality metrics by assessing their invariance to
affine transformations, specifically: rotation, translation, scaling, and
changes in spectral illumination. We propose a methodology to assign
invisibility thresholds for any perceptual metric. This methodology involves
transforming the distance measured by an arbitrary metric to a common distance
representation based on available subjectively rated databases. We
psychophysically measure an absolute detection threshold in that common
representation and express it in the physical units of each affine transform
for each metric. By doing so, we allow the analyzed metrics to be directly
comparable with actual human thresholds. We find that none of the
state-of-the-art metrics shows human-like results under this strong test based
on invisibility thresholds. This means that tuning the models exclusively to
predict the visibility of generic distortions may disregard other properties of
human vision as for instance invariances or invisibility thresholds.

摘要：深度架構是目前預測主觀影像品質的最新技術。通常，這些模型會根據它們與人類意見在包含可能出現在數位媒體中各種失真範圍的資料庫中相關聯的能力來評估。然而，這些模型會忽略仿射轉換，而仿射轉換可以更好地表示在自然條件下實際發生的影像變化。與數位轉換相比，人類對這些自然轉換可能特別不變。在這項工作中，我們透過評估它們對仿射轉換的不變性來評估最先進的深度影像品質指標，特別是：旋轉、平移、縮放和光譜照明的變化。我們提出了一種方法來為任何感知指標分配不可見閾值。此方法涉及將任意指標測量的距離轉換為基於可用主觀評分資料庫的共同距離表示。我們在該共同表示中以心理物理學的方式測量絕對檢測閾值，並針對每個指標以每個仿射轉換的物理單位表示。透過這麼做，我們讓分析的指標可以直接與實際的人類閾值進行比較。我們發現，在基於不可見閾值的嚴格測試中，沒有任何最先進的指標顯示出類似人類的結果。這表示僅調整模型以預測一般失真的可見性可能會忽略人類視覺的其他特性，例如不變性或不可見閾值。

##### **The Dark Side of Function Calling: Pathways to Jailbreaking Large Language Models**
2407.17915v1 by Zihui Wu, Haichang Gao, Jianping He, Ping Wang

Large language models (LLMs) have demonstrated remarkable capabilities, but
their power comes with significant security considerations. While extensive
research has been conducted on the safety of LLMs in chat mode, the security
implications of their function calling feature have been largely overlooked.
This paper uncovers a critical vulnerability in the function calling process of
LLMs, introducing a novel "jailbreak function" attack method that exploits
alignment discrepancies, user coercion, and the absence of rigorous safety
filters. Our empirical study, conducted on six state-of-the-art LLMs including
GPT-4o, Claude-3.5-Sonnet, and Gemini-1.5-pro, reveals an alarming average
success rate of over 90\% for this attack. We provide a comprehensive analysis
of why function calls are susceptible to such attacks and propose defensive
strategies, including the use of defensive prompts. Our findings highlight the
urgent need for enhanced security measures in the function calling capabilities
of LLMs, contributing to the field of AI safety by identifying a previously
unexplored risk, designing an effective attack method, and suggesting practical
defensive measures. Our code is available at
https://github.com/wooozihui/jailbreakfunction.

摘要：大型語言模型 (LLM) 已展示出非凡的能力，但其能力伴隨著重大的安全考量。儘管已對聊天模式中 LLM 的安全性進行廣泛的研究，但其函數呼叫功能的安全影響卻在很大程度上被忽視。本文揭露了 LLM 函數呼叫過程中的一個重大漏洞，引入了一種新的「越獄函數」攻擊方法，該方法利用對齊差異、使用者強制和缺乏嚴格的安全過濾器。我們針對六種最先進的 LLM（包括 GPT-4o、Claude-3.5-Sonnet 和 Gemini-1.5-pro）進行的實證研究顯示，這種攻擊的平均成功率高達 90%，令人堪憂。我們提供了函數呼叫容易受到此類攻擊的原因的全面分析，並提出了防禦策略，包括使用防禦提示。我們的研究結果強調了迫切需要增強 LLM 函數呼叫功能中的安全措施，通過識別以前未探索的風險、設計有效的攻擊方法和建議實用的防禦措施，為 AI 安全領域做出貢獻。我們的程式碼可在 https://github.com/wooozihui/jailbreakfunction 取得。

##### **Modelling Multimodal Integration in Human Concept Processing with Vision-and-Language Models**
2407.17914v1 by Anna Bavaresco, Marianne de Heer Kloots, Sandro Pezzelle, Raquel Fernández

Representations from deep neural networks (DNNs) have proven remarkably
predictive of neural activity involved in both visual and linguistic
processing. Despite these successes, most studies to date concern unimodal
DNNs, encoding either visual or textual input but not both. Yet, there is
growing evidence that human meaning representations integrate linguistic and
sensory-motor information. Here we investigate whether the integration of
multimodal information operated by current vision-and-language DNN models
(VLMs) leads to representations that are more aligned with human brain activity
than those obtained by language-only and vision-only DNNs. We focus on fMRI
responses recorded while participants read concept words in the context of
either a full sentence or an accompanying picture. Our results reveal that VLM
representations correlate more strongly than language- and vision-only DNNs
with activations in brain areas functionally related to language processing. A
comparison between different types of visuo-linguistic architectures shows that
recent generative VLMs tend to be less brain-aligned than previous
architectures with lower performance on downstream applications. Moreover,
through an additional analysis comparing brain vs. behavioural alignment across
multiple VLMs, we show that -- with one remarkable exception -- representations
that strongly align with behavioural judgments do not correlate highly with
brain responses. This indicates that brain similarity does not go hand in hand
with behavioural similarity, and vice versa.

摘要：深度神经网络 (DNN) 的表征已证明可以显著预测视觉和语言处理中涉及的神经活动。尽管取得了这些成功，但迄今为止大多数研究都涉及单模态 DNN，仅对视觉或文本输入进行编码，而不是两者都进行编码。然而，越来越多的证据表明，人类的意义表征整合了语言和感觉运动信息。在此，我们研究了由当前视觉语言 DNN 模型 (VLM) 运营的多模态信息整合是否导致了与人类大脑活动更一致的表征，而不是仅通过语言和仅通过视觉的 DNN 获得的表征。我们专注于在参与者在完整句子或附带图片的上下文中阅读概念词时记录的 fMRI 反应。我们的结果表明，VLM 表征与语言和仅视觉 DNN 更强烈地相关，与功能上与语言处理相关的脑区激活相关。不同类型视觉语言架构之间的比较表明，最近的生成式 VLM 往往比以前在下游应用程序上性能较低的架构与大脑对齐程度较低。此外，通过比较多个 VLM 中大脑与行为对齐的附加分析，我们表明——有一个显着的例外——与行为判断强烈对齐的表征与大脑反应没有高度相关性。这表明大脑相似性与行为相似性并不齐头并进，反之亦然。

##### **ReCorD: Reasoning and Correcting Diffusion for HOI Generation**
2407.17911v1 by Jian-Yu Jiang-Lin, Kang-Yang Huang, Ling Lo, Yi-Ning Huang, Terence Lin, Jhih-Ciang Wu, Hong-Han Shuai, Wen-Huang Cheng

Diffusion models revolutionize image generation by leveraging natural
language to guide the creation of multimedia content. Despite significant
advancements in such generative models, challenges persist in depicting
detailed human-object interactions, especially regarding pose and object
placement accuracy. We introduce a training-free method named Reasoning and
Correcting Diffusion (ReCorD) to address these challenges. Our model couples
Latent Diffusion Models with Visual Language Models to refine the generation
process, ensuring precise depictions of HOIs. We propose an interaction-aware
reasoning module to improve the interpretation of the interaction, along with
an interaction correcting module to refine the output image for more precise
HOI generation delicately. Through a meticulous process of pose selection and
object positioning, ReCorD achieves superior fidelity in generated images while
efficiently reducing computational requirements. We conduct comprehensive
experiments on three benchmarks to demonstrate the significant progress in
solving text-to-image generation tasks, showcasing ReCorD's ability to render
complex interactions accurately by outperforming existing methods in HOI
classification score, as well as FID and Verb CLIP-Score. Project website is
available at https://alberthkyhky.github.io/ReCorD/ .

摘要：擴散模型透過利用自然語言來引導多媒體內容的建立，進而革新了影像生成。儘管此類生成模型已有顯著的進展，但在描繪詳細的人類-物件互動方面仍存在挑戰，特別是在姿勢和物件放置的準確性上。我們提出了一種名為推理與修正擴散 (ReCorD) 的無訓練方法來解決這些挑戰。我們的模型將潛在擴散模型與視覺語言模型結合，以優化生成過程，確保精確描繪 HOI。我們提出了一個互動感知推理模組來改善互動的詮釋，並提出了一個互動修正模組來優化輸出影像，以更精確地生成 HOI。透過姿勢選擇和物件定位的細緻過程，ReCorD 在生成的影像中達到了更高的保真度，同時有效地降低了運算需求。我們在三個基準上進行了全面的實驗，以展示在解決文字到影像生成任務方面取得的顯著進展，展示了 ReCorD 在 HOI 分類分數以及 FID 和動詞 CLIP 分數方面優於現有方法，準確呈現複雜互動的能力。專案網站可於 https://alberthkyhky.github.io/ReCorD/ 取得。

##### **The Power of Combining Data and Knowledge: GPT-4o is an Effective Interpreter of Machine Learning Models in Predicting Lymph Node Metastasis of Lung Cancer**
2407.17900v1 by Danqing Hu, Bing Liu, Xiaofeng Zhu, Nan Wu

Lymph node metastasis (LNM) is a crucial factor in determining the initial
treatment for patients with lung cancer, yet accurate preoperative diagnosis of
LNM remains challenging. Recently, large language models (LLMs) have garnered
significant attention due to their remarkable text generation capabilities.
Leveraging the extensive medical knowledge learned from vast corpora, LLMs can
estimate probabilities for clinical problems, though their performance has
historically been inferior to data-driven machine learning models. In this
paper, we propose a novel ensemble method that combines the medical knowledge
acquired by LLMs with the latent patterns identified by machine learning models
to enhance LNM prediction performance. Initially, we developed machine learning
models using patient data. We then designed a prompt template to integrate the
patient data with the predicted probability from the machine learning model.
Subsequently, we instructed GPT-4o, the most advanced LLM developed by OpenAI,
to estimate the likelihood of LNM based on patient data and then adjust the
estimate using the machine learning output. Finally, we collected three outputs
from the GPT-4o using the same prompt and ensembled these results as the final
prediction. Using the proposed method, our models achieved an AUC value of
0.765 and an AP value of 0.415 for LNM prediction, significantly improving
predictive performance compared to baseline machine learning models. The
experimental results indicate that GPT-4o can effectively leverage its medical
knowledge and the probabilities predicted by machine learning models to achieve
more accurate LNM predictions. These findings demonstrate that LLMs can perform
well in clinical risk prediction tasks, offering a new paradigm for integrating
medical knowledge and patient data in clinical predictions.

摘要：淋巴結轉移 (LNM) 是決定肺癌患者初始治療的關鍵因素，但準確的術前 LNM 診斷仍然具有挑戰性。最近，大型語言模型 (LLM) 因其卓越的文本生成能力而備受關注。利用從龐大語料庫中學習到的廣泛醫學知識，LLM 可以估計臨床問題的機率，儘管它們的表現歷來不如數據驅動的機器學習模型。在本文中，我們提出了一種新穎的集成方法，將 LLM 獲得的醫學知識與機器學習模型識別的潛在模式相結合，以增強 LNM 預測性能。最初，我們使用患者數據開發了機器學習模型。然後，我們設計了一個提示模板，將患者數據與機器學習模型的預測機率相結合。隨後，我們指示 OpenAI 開發的最先進 LLM GPT-4o 根據患者數據估計 LNM 的可能性，然後使用機器學習輸出調整估計。最後，我們使用相同的提示從 GPT-4o 收集了三個輸出，並將這些結果作為最終預測進行集成。使用所提出的方法，我們的模型在 LNM 預測中實現了 0.765 的 AUC 值和 0.415 的 AP 值，與基線機器學習模型相比，預測性能顯著提高。實驗結果表明，GPT-4o 可以有效利用其醫學知識和機器學習模型預測的機率來實現更準確的 LNM 預測。這些發現表明，LLM 可以很好地執行臨床風險預測任務，為整合臨床預測中的醫學知識和患者數據提供了一個新的範例。

##### **3D Hole Filling using Deep Learning Inpainting**
2407.17896v1 by Marina Hernández-Bautista, F. J. Melero

The current work presents a novel methodology for completing 3D surfaces
produced from 3D digitization technologies in places where there is a scarcity
of meaningful geometric data. Incomplete or missing data in these
three-dimensional (3D) models can lead to erroneous or flawed renderings,
limiting their usefulness in a variety of applications such as visualization,
geometric computation, and 3D printing. Conventional surface estimation
approaches often produce implausible results, especially when dealing with
complex surfaces. To address this issue, we propose a technique that
incorporates neural network-based 2D inpainting to effectively reconstruct 3D
surfaces. Our customized neural networks were trained on a dataset containing
over 1 million curvature images. These images show the curvature of vertices as
planar representations in 2D. Furthermore, we used a coarse-to-fine surface
deformation technique to improve the accuracy of the reconstructed pictures and
assure surface adaptability. This strategy enables the system to learn and
generalize patterns from input data, resulting in the development of precise
and comprehensive three-dimensional surfaces. Our methodology excels in the
shape completion process, effectively filling complex holes in
three-dimensional surfaces with a remarkable level of realism and precision.

摘要：本研究提出了一種新穎的方法，用於在有意義的幾何數據稀缺的地方，完成由 3D 數位化技術產生的 3D 表面。這些三維 (3D) 模型中的不完整或遺失數據可能會導致錯誤或有缺陷的渲染，限制了它們在可視化、幾何計算和 3D 列印等各種應用中的實用性。傳統的曲面估計方法通常會產生難以置信的結果，特別是在處理複雜曲面時。為了解決這個問題，我們提出了一種技術，結合了基於神經網路的 2D 修補，以有效重建 3D 曲面。我們的客製化神經網路是在包含超過 100 萬個曲率影像的資料集上訓練的。這些影像顯示了頂點的曲率，作為 2D 中的平面表示。此外，我們使用由粗到細的曲面變形技術來提高重建影像的準確性，並確保曲面適應性。此策略使系統能夠從輸入數據中學習和概括模式，從而開發出精確且全面的三維曲面。我們的技術在形狀完成過程中表現出色，有效地填補了三維曲面中複雜的孔洞，具有顯著的真實性和準確性。

##### **An Iterative Approach to Topic Modelling**
2407.17892v1 by Albert Wong, Florence Wing Yau Cheng, Ashley Keung, Yamileth Hercules, Mary Alexandra Garcia, Yew-Wei Lim, Lien Pham

Topic modelling has become increasingly popular for summarizing text data,
such as social media posts and articles. However, topic modelling is usually
completed in one shot. Assessing the quality of resulting topics is
challenging. No effective methods or measures have been developed for assessing
the results or for making further enhancements to the topics. In this research,
we propose we propose to use an iterative process to perform topic modelling
that gives rise to a sense of completeness of the resulting topics when the
process is complete. Using the BERTopic package, a popular method in topic
modelling, we demonstrate how the modelling process can be applied iteratively
to arrive at a set of topics that could not be further improved upon using one
of the three selected measures for clustering comparison as the decision
criteria. This demonstration is conducted using a subset of the COVIDSenti-A
dataset. The early success leads us to believe that further research using in
using this approach in conjunction with other topic modelling algorithms could
be viable.

摘要：主題建模在總結文字資料上越來越受歡迎，例如社群媒體貼文和文章。然而，主題建模通常一次完成。評估產出主題的品質具有挑戰性。尚未發展出有效的方法或措施來評估結果或進一步增強主題。在這項研究中，我們提議使用反覆運算處理來執行主題建模，在處理完成時會產生結果主題的完整性。使用主題建模中常見的方法 BERTopic 套件，我們示範如何反覆套用建模處理，以得出無法使用三個選定的群集比較測量標準之一作為決策準則進一步改善的主題集。此示範使用 COVIDSenti-A 資料集的子集進行。早期的成功讓我們相信，使用這種方法與其他主題建模演算法結合進一步研究是可行的。

##### **Unraveling the Never-Ending Story of Lifecycles and Vitalizing Processes**
2407.17881v1 by Stephan A. Fahrenkrog-Petersen, Saimir Bala, Luise Pufahl, Jan Mendling

Business process management (BPM) has been widely used to discover, model,
analyze, and optimize organizational processes. BPM looks at these processes
with analysis techniques that assume a clearly defined start and end. However,
not all processes adhere to this logic, with the consequence that their
behavior cannot be appropriately captured by BPM analysis techniques. This
paper addresses this research problem at a conceptual level. More specifically,
we introduce the notion of vitalizing business processes that target the
lifecycle process of one or more entities. We show the existence of lifecycle
processes in many industries and that their appropriate conceptualizations pave
the way for the definition of suitable modeling and analysis techniques. This
paper provides a set of requirements for their analysis, and a
conceptualization of lifecycle and vitalizing processes.

摘要：業務流程管理 (BPM) 已廣泛用於發現、建模、分析和最佳化組織流程。BPM 以分析技術審視這些流程，假設有一個明確定義的開始和結束。然而，並非所有流程都遵循此邏輯，其後果是 BPM 分析技術無法適當地擷取其行為。本文在概念層面上探討此研究問題。更具體地說，我們引入了激勵業務流程的概念，其目標是針對一個或多個實體的生命週期流程。我們展示了許多產業中生命週期流程的存在，而其適當的概念化為定義合適的建模和分析技術鋪平了道路。本文提供了一組分析要求，以及生命週期和激勵流程的概念化。

##### **A Large-Scale Sensitivity Analysis on Latent Embeddings and Dimensionality Reductions for Text Spatializations**
2407.17876v1 by Daniel Atzberger, Tim Cech, Willy Scheibel, Jürgen Döllner, Michael Behrisch, Tobias Schreck

The semantic similarity between documents of a text corpus can be visualized
using map-like metaphors based on two-dimensional scatterplot layouts. These
layouts result from a dimensionality reduction on the document-term matrix or a
representation within a latent embedding, including topic models. Thereby, the
resulting layout depends on the input data and hyperparameters of the
dimensionality reduction and is therefore affected by changes in them.
Furthermore, the resulting layout is affected by changes in the input data and
hyperparameters of the dimensionality reduction. However, such changes to the
layout require additional cognitive efforts from the user. In this work, we
present a sensitivity study that analyzes the stability of these layouts
concerning (1) changes in the text corpora, (2) changes in the hyperparameter,
and (3) randomness in the initialization. Our approach has two stages: data
measurement and data analysis. First, we derived layouts for the combination of
three text corpora and six text embeddings and a grid-search-inspired
hyperparameter selection of the dimensionality reductions. Afterward, we
quantified the similarity of the layouts through ten metrics, concerning local
and global structures and class separation. Second, we analyzed the resulting
42817 tabular data points in a descriptive statistical analysis. From this, we
derived guidelines for informed decisions on the layout algorithm and highlight
specific hyperparameter settings. We provide our implementation as a Git
repository at
https://github.com/hpicgs/Topic-Models-and-Dimensionality-Reduction-Sensitivity-Study
and results as Zenodo archive at https://doi.org/10.5281/zenodo.12772898.

摘要：<paragraph>文本语料库中文件之间的语义相似性可以使用基于二维散点图布局的地图类比来可视化。这些布局源自文档术语矩阵上的降维或潜在嵌入中的表示，包括主题模型。因此，生成的布局取决于降维的输入数据和超参数，因此会受到它们的更改的影响。此外，生成的布局会受到输入数据和降维超参数更改的影响。然而，布局的此类更改需要用户付出额外的认知努力。在这项工作中，我们提出了一项敏感性研究，分析了这些布局在 (1) 文本语料库的变化、(2) 超参数的变化以及 (3) 初始化的随机性方面的稳定性。我们的方法有两个阶段：数据测量和数据分析。首先，我们导出了三个文本语料库和六个文本嵌入组合的布局，以及降维的网格搜索启发超参数选择。之后，我们通过十个指标量化了布局的相似性，涉及局部和全局结构以及类分离。其次，我们在描述性统计分析中分析了生成的 42817 个表格数据点。由此，我们得出了有关布局算法的明智决策指南，并重点介绍了特定的超参数设置。我们在 Git 存储库中提供了我们的实现，网址为 https://github.com/hpicgs/Topic-Models-and-Dimensionality-Reduction-Sensitivity-Study，并在 Zenodo 存档中提供了结果，网址为 https://doi.org/10.5281/zenodo.12772898。</paragraph>

##### **Improving Domain-Specific ASR with LLM-Generated Contextual Descriptions**
2407.17874v1 by Jiwon Suh, Injae Na, Woohwan Jung

End-to-end automatic speech recognition (E2E ASR) systems have significantly
improved speech recognition through training on extensive datasets. Despite
these advancements, they still struggle to accurately recognize domain specific
words, such as proper nouns and technical terminologies. To address this
problem, we propose a method to utilize the state-of-the-art Whisper without
modifying its architecture, preserving its generalization performance while
enabling it to leverage descriptions effectively. Moreover, we propose two
additional training techniques to improve the domain specific ASR: decoder
fine-tuning, and context perturbation. We also propose a method to use a Large
Language Model (LLM) to generate descriptions with simple metadata, when
descriptions are unavailable. Our experiments demonstrate that proposed methods
notably enhance domain-specific ASR accuracy on real-life datasets, with
LLM-generated descriptions outperforming human-crafted ones in effectiveness.

摘要：端到端自動語音辨識 (E2E ASR) 系統透過在廣泛的資料集上訓練，大幅提升了語音辨識能力。儘管有這些進展，它們在準確辨識特定領域的詞彙（例如專有名詞和技術術語）方面仍有困難。為了解決這個問題，我們提出了一種方法，利用最先進的 Whisper，而無需修改其架構，保留其泛化效能，同時讓它能有效利用描述。此外，我們提出了兩種額外的訓練技術來改善特定領域的 ASR：解碼器微調和脈絡擾動。我們還提出了一種方法，在沒有描述時，使用大型語言模型 (LLM) 來產生具有簡單元資料的描述。我們的實驗證明，所提出的方法顯著提升了真實資料集上的特定領域 ASR 準確度，由 LLM 產生的描述在有效性方面優於人工撰寫的描述。

##### **Is the Digital Forensics and Incident Response Pipeline Ready for Text-Based Threats in LLM Era?**
2407.17870v1 by Avanti Bhandarkar, Ronald Wilson, Anushka Swarup, Mengdi Zhu, Damon Woodard

In the era of generative AI, the widespread adoption of Neural Text
Generators (NTGs) presents new cybersecurity challenges, particularly within
the realms of Digital Forensics and Incident Response (DFIR). These challenges
primarily involve the detection and attribution of sources behind advanced
attacks like spearphishing and disinformation campaigns. As NTGs evolve, the
task of distinguishing between human and NTG-authored texts becomes critically
complex. This paper rigorously evaluates the DFIR pipeline tailored for
text-based security systems, specifically focusing on the challenges of
detecting and attributing authorship of NTG-authored texts. By introducing a
novel human-NTG co-authorship text attack, termed CS-ACT, our study uncovers
significant vulnerabilities in traditional DFIR methodologies, highlighting
discrepancies between ideal scenarios and real-world conditions. Utilizing 14
diverse datasets and 43 unique NTGs, up to the latest GPT-4, our research
identifies substantial vulnerabilities in the forensic profiling phase,
particularly in attributing authorship to NTGs. Our comprehensive evaluation
points to factors such as model sophistication and the lack of distinctive
style within NTGs as significant contributors for these vulnerabilities. Our
findings underscore the necessity for more sophisticated and adaptable
strategies, such as incorporating adversarial learning, stylizing NTGs, and
implementing hierarchical attribution through the mapping of NTG lineages to
enhance source attribution. This sets the stage for future research and the
development of more resilient text-based security systems.

摘要：在生成式 AI 時代，神經文本生成器 (NTG) 的廣泛採用提出了新的網路安全挑戰，特別是在數位鑑識和事件應變 (DFIR) 領域。這些挑戰主要涉及偵測和歸因於魚叉式網路釣魚和假訊息活動等進階攻擊背後的來源。隨著 NTG 的演進，區分人類和 NTG 撰寫文本的任務變得極為複雜。本文嚴謹地評估了專為基於文本的安全系統量身打造的 DFIR 管線，特別關注偵測和歸因 NTG 撰寫文本作者的挑戰。透過引入一種稱為 CS-ACT 的新型人類-NTG 共同創作文本攻擊，我們的研究揭露了傳統 DFIR 方法論中的重大漏洞，突顯了理想情況與實際情況之間的差異。利用 14 個不同的資料集和 43 個獨特的 NTG（包括最新的 GPT-4），我們的研究發現了鑑識分析階段的重大漏洞，特別是在將作者歸因於 NTG 時。我們的全面評估指出，模型複雜性和 NTG 中缺乏獨特風格等因素是這些漏洞的重要成因。我們的發現強調了更複雜和適應性策略的必要性，例如納入對抗性學習、調整 NTG 風格，以及透過將 NTG 世系映射到增強來源歸因來實施階層式歸因。這為未來的研究和更具韌性的基於文本的安全系統的開發奠定了基礎。

##### **Financial Statement Analysis with Large Language Models**
2407.17866v1 by Alex Kim, Maximilian Muhn, Valeri Nikolaev

We investigate whether an LLM can successfully perform financial statement
analysis in a way similar to a professional human analyst. We provide
standardized and anonymous financial statements to GPT4 and instruct the model
to analyze them to determine the direction of future earnings. Even without any
narrative or industry-specific information, the LLM outperforms financial
analysts in its ability to predict earnings changes. The LLM exhibits a
relative advantage over human analysts in situations when the analysts tend to
struggle. Furthermore, we find that the prediction accuracy of the LLM is on
par with the performance of a narrowly trained state-of-the-art ML model. LLM
prediction does not stem from its training memory. Instead, we find that the
LLM generates useful narrative insights about a company's future performance.
Lastly, our trading strategies based on GPT's predictions yield a higher Sharpe
ratio and alphas than strategies based on other models. Taken together, our
results suggest that LLMs may take a central role in decision-making.

摘要：我們探討 LLM 是否能成功執行財務報表分析，其方式類似於專業的人類分析師。我們提供標準化且匿名的財務報表給 GPT4，並指示模型分析它們以確定未來收益的方向。即使沒有任何敘述或產業特定資訊，LLM 在預測收益變動的能力上也優於財務分析師。當分析師傾向於陷入困境時，LLM 展現出相對於人類分析師的相對優勢。此外，我們發現 LLM 的預測準確度與訓練有素的最新 ML 模型的效能相當。LLM 的預測並非源自其訓練記憶。相反地，我們發現 LLM 能產生有關公司未來表現的有用敘述性見解。最後，我們根據 GPT 預測所建立的交易策略產生高於其他模型的夏普比率和 alpha 值。綜觀而言，我們的結果表明 LLM 可能在決策制定中扮演核心角色。

##### **factgenie: A Framework for Span-based Evaluation of Generated Texts**
2407.17863v1 by Zdeněk Kasner, Ondřej Plátek, Patrícia Schmidtová, Simone Balloccu, Ondřej Dušek

We present factgenie: a framework for annotating and visualizing word spans
in textual model outputs. Annotations can capture various span-based phenomena
such as semantic inaccuracies or irrelevant text. With factgenie, the
annotations can be collected both from human crowdworkers and large language
models. Our framework consists of a web interface for data visualization and
gathering text annotations, powered by an easily extensible codebase.

摘要：我們提出 factgenie：一個用於標註和視覺化文本模型輸出中字詞區間的框架。標註可以捕捉各種基於區間的現象，例如語義不準確或無關文字。有了 factgenie，可以從人工群眾工作者和大型語言模型收集標註。我們的框架包含一個網路介面，用於資料視覺化和收集文字標註，並由一個容易擴充的程式碼庫提供支援。

##### **Exploring Description-Augmented Dataless Intent Classification**
2407.17862v1 by Ruoyu Hu, Foaad Khosmood, Abbas Edalat

In this work, we introduce several schemes to leverage description-augmented
embedding similarity for dataless intent classification using current
state-of-the-art (SOTA) text embedding models. We report results of our methods
on four commonly used intent classification datasets and compare against
previous works of a similar nature. Our work shows promising results for
dataless classification scaling to a large number of unseen intents. We show
competitive results and significant improvements (+6.12\% Avg.) over strong
zero-shot baselines, all without training on labelled or task-specific data.
Furthermore, we provide qualitative error analysis of the shortfalls of this
methodology to help guide future research in this area.

摘要：在本文中，我们介绍了几种方案，利用描述增强嵌入相似性进行无数据意图分类，使用当前最先进 (SOTA) 的文本嵌入模型。我们报告了我们在四个常用的意图分类数据集上的方法结果，并与类似性质的先前工作进行了比较。我们的工作表明，无数据分类扩展到大量看不见的意图时，结果很有希望。我们展示了有竞争力的结果和显着改进（+6.12% 平均值）超过强大的零样本基线，所有这些都无需针对标记或特定任务的数据进行训练。此外，我们提供了此方法论不足的定性错误分析，以帮助指导该领域的未来研究。

##### **Shapley Value-based Contrastive Alignment for Multimodal Information Extraction**
2407.17854v1 by Wen Luo, Yu Xia, Shen Tianshu, Sujian Li

The rise of social media and the exponential growth of multimodal
communication necessitates advanced techniques for Multimodal Information
Extraction (MIE). However, existing methodologies primarily rely on direct
Image-Text interactions, a paradigm that often faces significant challenges due
to semantic and modality gaps between images and text. In this paper, we
introduce a new paradigm of Image-Context-Text interaction, where large
multimodal models (LMMs) are utilized to generate descriptive textual context
to bridge these gaps. In line with this paradigm, we propose a novel Shapley
Value-based Contrastive Alignment (Shap-CA) method, which aligns both
context-text and context-image pairs. Shap-CA initially applies the Shapley
value concept from cooperative game theory to assess the individual
contribution of each element in the set of contexts, texts and images towards
total semantic and modality overlaps. Following this quantitative evaluation, a
contrastive learning strategy is employed to enhance the interactive
contribution within context-text/image pairs, while minimizing the influence
across these pairs. Furthermore, we design an adaptive fusion module for
selective cross-modal fusion. Extensive experiments across four MIE datasets
demonstrate that our method significantly outperforms existing state-of-the-art
methods.

摘要：社群媒體的崛起和多模態溝通的指數型成長，需要進階的多模態資訊萃取 (MIE) 技術。然而，現有的方法論主要依賴於直接的影像文字互動，這種模式通常會因為影像和文字之間的語意和模態差距而面臨重大的挑戰。在本文中，我們引進一種新的影像-脈絡-文字互動模式，其中利用大型多模態模型 (LMM) 來產生描述性的文字脈絡，以彌補這些差距。根據這個模式，我們提出一個新的 Shapley 值基礎對比式校準 (Shap-CA) 方法，它校準脈絡文字和脈絡影像對。Shap-CA 最初應用合作博弈論中的 Shapley 值概念，評估脈絡、文字和影像集合中每個元素對總體語意和模態重疊的個別貢獻。在這個定量評估之後，採用對比式學習策略來加強脈絡文字/影像對之間的互動貢獻，同時將這些對之間的影響降到最低。此外，我們設計了一個適應式融合模組，用於選擇性的跨模態融合。在四個 MIE 資料集上的廣泛實驗證明，我們的方法明顯優於現有的最先進方法。

##### **Scaling A Simple Approach to Zero-Shot Speech Recognition**
2407.17852v1 by Jinming Zhao, Vineel Pratap, Michael Auli

Despite rapid progress in increasing the language coverage of automatic
speech recognition, the field is still far from covering all languages with a
known writing script. Recent work showed promising results with a zero-shot
approach requiring only a small amount of text data, however, accuracy heavily
depends on the quality of the used phonemizer which is often weak for unseen
languages. In this paper, we present MMS Zero-shot a conceptually simpler
approach based on romanization and an acoustic model trained on data in 1,078
different languages or three orders of magnitude more than prior art. MMS
Zero-shot reduces the average character error rate by a relative 46% over 100
unseen languages compared to the best previous work. Moreover, the error rate
of our approach is only 2.5x higher compared to in-domain supervised baselines,
while our approach uses no labeled data for the evaluation languages at all.

摘要：儘管自動語音辨識在擴展語言涵蓋範圍方面進展迅速，但此領域仍遠遠無法涵蓋所有已知書寫系統的語言。最近的研究顯示，一種只需少量文字資料的零次學習方法獲得了有希望的成果，然而，準確度高度依賴於所使用的音素化器的品質，而音素化器對於未見過的語言通常很弱。在本文中，我們提出了 MMS 零次學習，這是一種基於羅馬化和在 1,078 種不同語言的資料上訓練的聲學模型的概念上更簡單的方法，比先前的技術多了三個數量級。與先前的最佳技術相比，MMS 零次學習將 100 種未見過語言的平均字元錯誤率降低了相對的 46%。此外，與特定領域的監督基準相比，我們的方法的錯誤率僅高出 2.5 倍，而我們的方法完全不使用評估語言的標籤資料。

##### **Innovative Speech-Based Deep Learning Approaches for Parkinson's Disease Classification: A Systematic Review**
2407.17844v1 by Lisanne van Gelderen, Cristian Tejedor-García

Parkinson's disease (PD), the second most prevalent neurodegenerative
disorder worldwide, frequently presents with early-stage speech impairments.
Recent advancements in Artificial Intelligence (AI), particularly deep learning
(DL), have significantly enhanced PD diagnosis through the analysis of speech
data. Nevertheless, the progress of research is restricted by the limited
availability of publicly accessible speech-based PD datasets, primarily due to
privacy and ethical concerns. This review covers the latest DL-based AI
approaches for speech-based PD classification, focusing on performance,
available resources and associated challenges of 33 scientific works published
between 2020 and March 2024. These DL approaches are categorized into
end-to-end (E2E) learning, transfer learning (TL) and deep acoustic features
(DAF) extraction. Among E2E approaches, Convolutional Neural Networks (CNNs)
are prevalent, though Transformers are increasingly popular. E2E approaches
face challenges such as limited data and computational resources, especially
with Transformers. TL addresses these issues by providing more robust PD
diagnosis and better generalizability across languages. DAF extraction aims to
improve the explainability and interpretability of results by examining the
specific effects of deep features on both other DL approaches and more
traditional machine learning (ML) methods. However, it often underperforms
compared to E2E and TL approaches. This review also discusses unresolved issues
related to bias, explainability and privacy, highlighting the need for future
research.

摘要：帕金森氏症 (PD) 是全球第二常見的神經退化性疾病，通常會出現早期言語障礙。人工智慧 (AI) 的最新進展，尤其是深度學習 (DL)，已透過分析言語資料大幅提升 PD 診斷。儘管如此，研究進度受到公開可存取的基於言語的 PD 資料集有限所限制，這主要是由於隱私和倫理考量。本篇評論涵蓋了最新的基於 DL 的 AI 方法，用於基於言語的 PD 分類，重點在於 2020 年至 2024 年 3 月間發表的 33 篇科學著作的效能、可用資源和相關挑戰。這些 DL 方法被分類為端到端 (E2E) 學習、遷移學習 (TL) 和深度音響特徵 (DAF) 萃取。在 E2E 方法中，卷積神經網路 (CNN) 很普遍，儘管 Transformer 變得越來越受歡迎。E2E 方法面臨諸如資料和運算資源有限等挑戰，特別是使用 Transformer。TL 透過提供更強健的 PD 診斷和跨語言的更佳概括性來解決這些問題。DAF 萃取旨在透過檢視深度特徵對其他 DL 方法和更傳統機器學習 (ML) 方法的具體影響，來提升結果的可解釋性和可詮釋性。然而，與 E2E 和 TL 方法相比，它的表現通常較差。本篇評論也討論了與偏見、可解釋性和隱私相關的未解決問題，強調未來研究的必要性。

##### **DragText: Rethinking Text Embedding in Point-based Image Editing**
2407.17843v1 by Gayoon Choi, Taejin Jeong, Sujung Hong, Jaehoon Joo, Seong Jae Hwang

Point-based image editing enables accurate and flexible control through
content dragging. However, the role of text embedding in the editing process
has not been thoroughly investigated. A significant aspect that remains
unexplored is the interaction between text and image embeddings. In this study,
we show that during the progressive editing of an input image in a diffusion
model, the text embedding remains constant. As the image embedding increasingly
diverges from its initial state, the discrepancy between the image and text
embeddings presents a significant challenge. Moreover, we found that the text
prompt significantly influences the dragging process, particularly in
maintaining content integrity and achieving the desired manipulation. To
utilize these insights, we propose DragText, which optimizes text embedding in
conjunction with the dragging process to pair with the modified image
embedding. Simultaneously, we regularize the text optimization process to
preserve the integrity of the original text prompt. Our approach can be
seamlessly integrated with existing diffusion-based drag methods with only a
few lines of code.

摘要：基於點的影像編輯透過內容拖曳實現精準且彈性的控制。然而，文字嵌入在編輯過程中所扮演的角色尚未被徹底研究。文字嵌入與影像嵌入之間的互動是仍未探索的重要面向。在本研究中，我們展示在擴散模型中輸入影像的漸進式編輯過程中，文字嵌入保持不變。隨著影像嵌入與其初始狀態的差異越來越大，影像與文字嵌入之間的差異呈現出重大的挑戰。此外，我們發現文字提示會顯著影響拖曳過程，特別是在維持內容完整性並達成預期的操作。為了利用這些見解，我們提出 DragText，它會最佳化文字嵌入，並結合拖曳過程與修改後的影像嵌入配對。同時，我們規範化文字最佳化過程，以維持原始文字提示的完整性。我們的做法可以無縫整合到現有的基於擴散的拖曳方法中，只需幾行程式碼即可。

##### **On the Opportunities of (Re)-Exploring Atmospheric Science by Foundation Models: A Case Study**
2407.17842v1 by Lujia Zhang, Hanzhe Cui, Yurong Song, Chenyue Li, Binhang Yuan, Mengqian Lu

Most state-of-the-art AI applications in atmospheric science are based on
classic deep learning approaches. However, such approaches cannot automatically
integrate multiple complicated procedures to construct an intelligent agent,
since each functionality is enabled by a separate model learned from
independent climate datasets. The emergence of foundation models, especially
multimodal foundation models, with their ability to process heterogeneous input
data and execute complex tasks, offers a substantial opportunity to overcome
this challenge. In this report, we want to explore a central question - how the
state-of-the-art foundation model, i.e., GPT-4o, performs various atmospheric
scientific tasks. Toward this end, we conduct a case study by categorizing the
tasks into four main classes, including climate data processing, physical
diagnosis, forecast and prediction, and adaptation and mitigation. For each
task, we comprehensively evaluate the GPT-4o's performance along with a
concrete discussion. We hope that this report may shed new light on future AI
applications and research in atmospheric science.

摘要：目前在氣象科學中，大多數最先進的人工智慧應用程式都是基於經典深度學習方法。然而，這種方法無法自動整合多種複雜的程序來建構一個智慧型代理，因為每項功能都是由從獨立氣候資料集學習的單獨模型所啟用。基礎模型的出現，特別是多模態基礎模型，具備處理異質輸入資料和執行複雜任務的能力，提供了克服此挑戰的重大契機。在此報告中，我們想要探討一個核心問題——最先進的基礎模型，即 GPT-4o，如何執行各種大氣科學任務。為此，我們透過將任務分類為四個主要類別（包括氣候資料處理、物理診斷、預測和預報，以及適應和減緩）來進行個案研究。對於每個任務，我們會全面評估 GPT-4o 的效能，並進行具體的討論。我們希望這份報告能為未來的人工智慧應用程式和氣象科學研究帶來新的啟發。

##### **Long-term Fairness in Ride-Hailing Platform**
2407.17839v1 by Yufan Kang, Jeffrey Chan, Wei Shao, Flora D. Salim, Christopher Leckie

Matching in two-sided markets such as ride-hailing has recently received
significant attention. However, existing studies on ride-hailing mainly focus
on optimising efficiency, and fairness issues in ride-hailing have been
neglected. Fairness issues in ride-hailing, including significant earning
differences between drivers and variance of passenger waiting times among
different locations, have potential impacts on economic and ethical aspects.
The recent studies that focus on fairness in ride-hailing exploit traditional
optimisation methods and the Markov Decision Process to balance efficiency and
fairness. However, there are several issues in these existing studies, such as
myopic short-term decision-making from traditional optimisation and instability
of fairness in a comparably longer horizon from both traditional optimisation
and Markov Decision Process-based methods. To address these issues, we propose
a dynamic Markov Decision Process model to alleviate fairness issues currently
faced by ride-hailing, and seek a balance between efficiency and fairness, with
two distinct characteristics: (i) a prediction module to predict the number of
requests that will be raised in the future from different locations to allow
the proposed method to consider long-term fairness based on the whole timeline
instead of consider fairness only based on historical and current data
patterns; (ii) a customised scalarisation function for multi-objective
multi-agent Q Learning that aims to balance efficiency and fairness. Extensive
experiments on a publicly available real-world dataset demonstrate that our
proposed method outperforms existing state-of-the-art methods.

摘要：<paragraph>最近，在诸如叫车等双边市场中的匹配问题受到了广泛关注。然而，现有的关于叫车服务的的研究主要集中在优化效率上，而叫车服务的公平性问题却被忽视了。叫车服务中的公平性问题，包括司机之间的显著收入差异以及不同地点之间的乘客等待时间差异，对经济和道德方面都有潜在影响。最近关注叫车服务公平性的研究利用了传统的优化方法和马尔可夫决策过程来平衡效率和公平性。然而，现有的这些研究存在一些问题，例如传统的优化方法中的短视的短期决策，以及基于传统优化方法和基于马尔可夫决策过程的方法在相对较长的时域中公平性的不稳定性。为了解决这些问题，我们提出了一种动态马尔可夫决策过程模型来缓解叫车服务目前面临的公平性问题，并在效率和公平性之间寻求平衡，该模型具有两个显著特征：(i) 一个预测模块，用于预测未来不同地点提出的请求数量，以使所提出的方法能够基于整个时间线考虑长期公平性，而不是仅基于历史和当前数据模式考虑公平性；(ii) 一个用于多目标多智能体 Q 学习的定制标量化函数，旨在平衡效率和公平性。在公开的真实世界数据集上进行的广泛实验表明，我们提出的方法优于现有的最先进的方法。</paragraph>

##### **UMono: Physical Model Informed Hybrid CNN-Transformer Framework for Underwater Monocular Depth Estimation**
2407.17838v1 by Jian Wang, Jing Wang, Shenghui Rong, Bo He

Underwater monocular depth estimation serves as the foundation for tasks such
as 3D reconstruction of underwater scenes. However, due to the influence of
light and medium, the underwater environment undergoes a distinctive imaging
process, which presents challenges in accurately estimating depth from a single
image. The existing methods fail to consider the unique characteristics of
underwater environments, leading to inadequate estimation results and limited
generalization performance. Furthermore, underwater depth estimation requires
extracting and fusing both local and global features, which is not fully
explored in existing methods. In this paper, an end-to-end learning framework
for underwater monocular depth estimation called UMono is presented, which
incorporates underwater image formation model characteristics into network
architecture, and effectively utilize both local and global features of
underwater image. Experimental results demonstrate that the proposed method is
effective for underwater monocular depth estimation and outperforms the
existing methods in both quantitative and qualitative analyses.

摘要：水下單目深度估計作為水下場景 3D 重建等任務的基礎。然而，由於光線和媒介的影響，水下環境經歷了一個獨特的成像過程，這對於從單一影像準確估計深度提出了挑戰。現有方法未能考慮水下環境的獨特特徵，導致估計結果不充分，且泛化效能有限。此外，水下深度估計需要提取和融合局部和全局特徵，這在現有方法中並未得到充分探討。在本文中，提出了一個稱為 UMono 的水下單目深度估計端到端學習架構，它將水下影像形成模型特徵整合到網路架構中，並有效利用水下影像的局部和全局特徵。實驗結果表明，所提出的方法對於水下單目深度估計是有效的，並且在定量和定性分析中都優於現有方法。

##### **Unified Lexical Representation for Interpretable Visual-Language Alignment**
2407.17827v1 by Yifan Li, Yikai Wang, Yanwei Fu, Dongyu Ru, Zheng Zhang, Tong He

Visual-Language Alignment (VLA) has gained a lot of attention since CLIP's
groundbreaking work. Although CLIP performs well, the typical direct latent
feature alignment lacks clarity in its representation and similarity scores. On
the other hand, lexical representation, a vector whose element represents the
similarity between the sample and a word from the vocabulary, is a natural
sparse representation and interpretable, providing exact matches for individual
words. However, lexical representations is difficult to learn due to no
ground-truth supervision and false-discovery issues, and thus requires complex
design to train effectively. In this paper, we introduce LexVLA, a more
interpretable VLA framework by learning a unified lexical representation for
both modalities without complex design. We use DINOv2 as our visual model for
its local-inclined features and Llama 2, a generative language model, to
leverage its in-context lexical prediction ability. To avoid the false
discovery, we propose an overuse penalty to refrain the lexical representation
from falsely frequently activating meaningless words. We demonstrate that these
two pre-trained uni-modal models can be well-aligned by fine-tuning on modest
multi-modal dataset and avoid intricate training configurations. On cross-modal
retrieval benchmarks, LexVLA, trained on the CC-12M multi-modal dataset,
outperforms baselines fine-tuned on larger datasets (e.g., YFCC15M) and those
trained from scratch on even bigger datasets (e.g., 1.1B data, including
CC-12M). We conduct extensive experiments to analyze LexVLA.

摘要：自 CLIP 的開創性工作以來，視覺語言對齊 (VLA) 獲得了許多關注。儘管 CLIP 表現良好，但典型的直接潛在特徵對齊缺乏其表示和相似性評分的清晰度。另一方面，詞彙表示是一個向量，其元素表示樣本與詞彙中一個單詞之間的相似性，是一種自然的稀疏表示，並且可以解釋，為個別單詞提供準確的匹配。然而，由於沒有真實的監督和虛假發現問題，詞彙表示難以學習，因此需要複雜的設計才能有效訓練。在本文中，我們介紹了 LexVLA，這是一個更具可解釋性的 VLA 框架，通過學習一個統一的詞彙表示來表示兩種模式，而無需複雜的設計。我們使用 DINOv2 作為我們的視覺模型，因為它具有局部傾斜的特徵，以及 Llama 2，一個生成語言模型，以利用其上下文詞彙預測能力。為了避免虛假發現，我們提出了一個過度使用懲罰，以防止詞彙表示錯誤地頻繁激活無意義的詞。我們證明了這兩個預先訓練的單模態模型可以通過微調適度的多模態數據集並避免複雜的訓練配置來很好地對齊。在跨模態檢索基準上，在 CC-12M 多模態數據集上訓練的 LexVLA 優於在較大數據集（例如 YFCC15M）上進行微調的基線，以及從更大的數據集（例如 1.1B 數據，包括 CC-12M）中從頭訓練的基線。我們進行了大量的實驗來分析 LexVLA。

##### **Demystifying Verbatim Memorization in Large Language Models**
2407.17817v1 by Jing Huang, Diyi Yang, Christopher Potts

Large Language Models (LLMs) frequently memorize long sequences verbatim,
often with serious legal and privacy implications. Much prior work has studied
such verbatim memorization using observational data. To complement such work,
we develop a framework to study verbatim memorization in a controlled setting
by continuing pre-training from Pythia checkpoints with injected sequences. We
find that (1) non-trivial amounts of repetition are necessary for verbatim
memorization to happen; (2) later (and presumably better) checkpoints are more
likely to verbatim memorize sequences, even for out-of-distribution sequences;
(3) the generation of memorized sequences is triggered by distributed model
states that encode high-level features and makes important use of general
language modeling capabilities. Guided by these insights, we develop stress
tests to evaluate unlearning methods and find they often fail to remove the
verbatim memorized information, while also degrading the LM. Overall, these
findings challenge the hypothesis that verbatim memorization stems from
specific model weights or mechanisms. Rather, verbatim memorization is
intertwined with the LM's general capabilities and thus will be very difficult
to isolate and suppress without degrading model quality.

摘要：大型語言模型 (LLM) 經常逐字記憶長序列，
通常會造成嚴重的法律和隱私問題。許多先前的工作已經使用觀察資料研究這種逐字記憶。為了補充這類工作，
我們開發了一個架構，透過從注入序列的 Pythia 檢查點繼續預訓練，在受控設定下研究逐字記憶。我們發現 (1) 發生逐字記憶需要大量的重複；(2) 較後的 (且推測較好的) 檢查點較有可能逐字記憶序列，即使對於分佈外的序列；
(3) 記憶序列的產生是由編碼高階特徵的分布式模型狀態觸發，並大量使用一般語言建模功能。在這些見解的指導下，我們開發壓力測試來評估取消學習的方法，並發現它們通常無法移除逐字記憶的資訊，同時也會降低 LM。整體而言，這些發現挑戰了逐字記憶源自特定模型權重或機制的假設。反之，逐字記憶與 LM 的一般功能交織在一起，因此在不降低模型品質的情況下，將很難孤立和抑制。

##### **NC-NCD: Novel Class Discovery for Node Classification**
2407.17816v1 by Yue Hou, Xueyuan Chen, He Zhu, Romei Liu, Bowen Shi, Jiaheng Liu, Junran Wu, Ke Xu

Novel Class Discovery (NCD) involves identifying new categories within
unlabeled data by utilizing knowledge acquired from previously established
categories. However, existing NCD methods often struggle to maintain a balance
between the performance of old and new categories. Discovering unlabeled new
categories in a class-incremental way is more practical but also more
challenging, as it is frequently hindered by either catastrophic forgetting of
old categories or an inability to learn new ones. Furthermore, the
implementation of NCD on continuously scalable graph-structured data remains an
under-explored area. In response to these challenges, we introduce for the
first time a more practical NCD scenario for node classification (i.e.,
NC-NCD), and propose a novel self-training framework with prototype replay and
distillation called SWORD, adopted to our NC-NCD setting. Our approach enables
the model to cluster unlabeled new category nodes after learning labeled nodes
while preserving performance on old categories without reliance on old category
nodes. SWORD achieves this by employing a self-training strategy to learn new
categories and preventing the forgetting of old categories through the joint
use of feature prototypes and knowledge distillation. Extensive experiments on
four common benchmarks demonstrate the superiority of SWORD over other
state-of-the-art methods.

摘要：新穎類別發現 (NCD) 涉及利用從先前建立的類別中獲得的知識，在未標記資料中識別新的類別。然而，現有的 NCD 方法經常難以在舊類別和新類別的效能之間取得平衡。以類別遞增的方式發現未標記的新類別更實際，但挑戰性也更高，因為它經常受到舊類別的災難性遺忘或無法學習新類別的阻礙。此外，在連續可擴充的圖形結構資料上實作 NCD 仍是一個探索不足的領域。為了應對這些挑戰，我們首次引入一個更實用的節點分類 NCD 場景 (即 NC-NCD)，並提出一個新的自訓練架構，其中包含原型重播和稱為 SWORD 的知識萃取，並採用我們的 NC-NCD 設定。我們的做法讓模型在學習標籤節點後，能夠將未標記的新類別節點分群，同時在不依賴舊類別節點的情況下，維持舊類別的效能。SWORD 透過採用自訓練策略來學習新類別，並透過共同使用特徵原型和知識萃取來防止遺忘舊類別，進而達成此目標。在四個常見基準上的廣泛實驗證明了 SWORD 優於其他現有技術。

##### **Enhancing Model Performance: Another Approach to Vision-Language Instruction Tuning**
2407.17813v1 by Vedanshu, MM Tripathi, Bhavnesh Jaint

The integration of large language models (LLMs) with vision-language (VL)
tasks has been a transformative development in the realm of artificial
intelligence, highlighting the potential of LLMs as a versatile general-purpose
chatbot. However, the current trend in this evolution focuses on the
integration of vision and language to create models that can operate in more
diverse and real-world contexts. We present a novel approach, termed Bottleneck
Adapter, specifically crafted for enhancing the multimodal functionalities of
these complex models, enabling joint optimization of the entire multimodal LLM
framework through a process known as Multimodal Model Tuning (MMT). Our
approach utilizes lightweight adapters to connect the image encoder and LLM
without the need for large, complex neural networks. Unlike the conventional
modular training schemes, our approach adopts an end-to-end optimization
regime, which, when combined with the adapters, facilitates the joint
optimization using a significantly smaller parameter set. Our method exhibits
robust performance with 90.12\% accuracy, outperforming both human-level
performance (88.4\%) and LaVIN-7B (89.41\%).

摘要：大型語言模型 (LLM) 與視覺語言 (VL) 任務的整合是人工智慧領域的一項變革性發展，突顯了 LLM 作為多功能通用聊天機器人的潛力。然而，這種演化的當前趨勢著重於整合視覺和語言，以建立可在更多樣化且真實世界的環境中運作的模型。我們提出一個新穎的方法，稱為瓶頸適配器，專門用於增強這些複雜模型的多模態功能，透過一個稱為多模態模型調整 (MMT) 的程序，實現整個多模態 LLM 架構的聯合最佳化。我們的做法利用輕量級適配器連接影像編碼器和 LLM，而不需要大型、複雜的神經網路。與傳統的模組化訓練方案不同，我們的做法採用端到端最佳化機制，結合適配器後，有助於使用顯著較小的參數集進行聯合最佳化。我們的做法展現出穩健的效能，準確度達 90.12%，超越人類水準的效能 (88.4%) 和 LaVIN-7B (89.41%)。

##### **EEG-SSM: Leveraging State-Space Model for Dementia Detection**
2407.17801v1 by Xuan-The Tran, Linh Le, Quoc Toan Nguyen, Thomas Do, Chin-Teng Lin

State-space models (SSMs) have garnered attention for effectively processing
long data sequences, reducing the need to segment time series into shorter
intervals for model training and inference. Traditionally, SSMs capture only
the temporal dynamics of time series data, omitting the equally critical
spectral features. This study introduces EEG-SSM, a novel state-space
model-based approach for dementia classification using EEG data. Our model
features two primary innovations: EEG-SSM temporal and EEG-SSM spectral
components. The temporal component is designed to efficiently process EEG
sequences of varying lengths, while the spectral component enhances the model
by integrating frequency-domain information from EEG signals. The synergy of
these components allows EEG-SSM to adeptly manage the complexities of
multivariate EEG data, significantly improving accuracy and stability across
different temporal resolutions. Demonstrating a remarkable 91.0 percent
accuracy in classifying Healthy Control (HC), Frontotemporal Dementia (FTD),
and Alzheimer's Disease (AD) groups, EEG-SSM outperforms existing models on the
same dataset. The development of EEG-SSM represents an improvement in the use
of state-space models for screening dementia, offering more precise and
cost-effective tools for clinical neuroscience.

摘要：狀態空間模型 (SSM) 因有效處理長資料序列而備受關注，減少將時間序列區隔成較短區間以進行模型訓練和推論的需要。傳統上，SSM 只擷取時間序列資料的時間動態，省略同樣重要的頻譜特徵。本研究提出 EEG-SSM，一種新的基於狀態空間模型的方法，用於使用 EEG 資料進行失智症分類。我們的模型具有兩項主要的創新：EEG-SSM 時間和 EEG-SSM 頻譜組成部分。時間組成部分旨在有效率地處理長度不同的 EEG 序列，而頻譜組成部分透過整合 EEG 訊號的頻域資訊來增強模型。這些組成部分的協同作用讓 EEG-SSM 能靈活地管理多變量 EEG 資料的複雜性，大幅改善不同時間解析度下的準確性和穩定性。EEG-SSM 在分類健康對照組 (HC)、額顳葉型失智症 (FTD) 和阿茲海默症 (AD) 組別時展現出驚人的 91.0% 準確度，在相同的資料集上優於現有模型。EEG-SSM 的開發代表了使用狀態空間模型進行失智症篩檢的進步，為臨床神經科學提供更精確且更具成本效益的工具。

##### **A Unified Understanding of Adversarial Vulnerability Regarding Unimodal Models and Vision-Language Pre-training Models**
2407.17797v1 by Haonan Zheng, Xinyang Deng, Wen Jiang, Wenrui Li

With Vision-Language Pre-training (VLP) models demonstrating powerful
multimodal interaction capabilities, the application scenarios of neural
networks are no longer confined to unimodal domains but have expanded to more
complex multimodal V+L downstream tasks. The security vulnerabilities of
unimodal models have been extensively examined, whereas those of VLP models
remain challenging. We note that in CV models, the understanding of images
comes from annotated information, while VLP models are designed to learn image
representations directly from raw text. Motivated by this discrepancy, we
developed the Feature Guidance Attack (FGA), a novel method that uses text
representations to direct the perturbation of clean images, resulting in the
generation of adversarial images. FGA is orthogonal to many advanced attack
strategies in the unimodal domain, facilitating the direct application of rich
research findings from the unimodal to the multimodal scenario. By
appropriately introducing text attack into FGA, we construct Feature Guidance
with Text Attack (FGA-T). Through the interaction of attacking two modalities,
FGA-T achieves superior attack effects against VLP models. Moreover,
incorporating data augmentation and momentum mechanisms significantly improves
the black-box transferability of FGA-T. Our method demonstrates stable and
effective attack capabilities across various datasets, downstream tasks, and
both black-box and white-box settings, offering a unified baseline for
exploring the robustness of VLP models.

摘要：透過展現強大的多模態互動能力，視覺語言預訓練 (VLP) 模型讓神經網路的應用場景不再侷限於單模態領域，而是擴展到更複雜的多模態 V+L 下游任務。單模態模型的安全漏洞已被廣泛探討，而 VLP 模型的安全漏洞仍具有挑戰性。我們注意到在 CV 模型中，對影像的理解來自於標註資訊，而 VLP 模型則被設計為直接從原始文字中學習影像表示。基於此差異，我們開發了特徵引導攻擊 (FGA)，這是一種使用文字表示來引導乾淨影像擾動的新方法，進而產生對抗性影像。FGA 與單模態領域中的許多進階攻擊策略正交，促成了豐富的研究發現從單模態直接應用到多模態場景。透過適當地將文字攻擊引入 FGA，我們建構了採用文字攻擊的特徵引導 (FGA-T)。透過兩個模態的互動攻擊，FGA-T 對 VLP 模型達到了優異的攻擊效果。此外，加入資料擴充和動量機制顯著改善了 FGA-T 的黑盒轉移性。我們的模型在各種資料集、下游任務以及黑盒和白盒設定中展現了穩定且有效的攻擊能力，為探索 VLP 模型的穩健性提供了統一的基線。

##### **Investigating learning-independent abstract reasoning in artificial neural networks**
2407.17791v1 by Tomer Barak, Yonatan Loewenstein

Humans are capable of solving complex abstract reasoning tests. Whether this
ability reflects a learning-independent inference mechanism applicable to any
novel unlearned problem or whether it is a manifestation of extensive training
throughout life is an open question. Addressing this question in humans is
challenging because it is impossible to control their prior training. However,
assuming a similarity between the cognitive processing of Artificial Neural
Networks (ANNs) and humans, the extent to which training is required for ANNs'
abstract reasoning is informative about this question in humans. Previous
studies demonstrated that ANNs can solve abstract reasoning tests. However,
this success required extensive training. In this study, we examined the
learning-independent abstract reasoning of ANNs. Specifically, we evaluated
their performance without any pretraining, with the ANNs' weights being
randomly-initialized, and only change in the process of problem solving. We
found that naive ANN models can solve non-trivial visual reasoning tests,
similar to those used to evaluate human learning-independent reasoning. We
further studied the mechanisms that support this ability. Our results suggest
the possibility of learning-independent abstract reasoning that does not
require extensive training.

摘要：人類有能力解決複雜的抽象推理測驗。這種能力是反映出適用於任何新穎未學習問題的學習無關推論機制，還是反映出整個生命中廣泛訓練的表現，這是一個開放性的問題。在人類中探討這個問題具有挑戰性，因為不可能控制他們先前的訓練。然而，假設人工神經網路 (ANN) 和人類的認知處理之間存在相似性，那麼 ANN 抽象推理所需的訓練程度對於人類中的這個問題具有參考意義。先前的研究表明，ANN 可以解決抽象推理測驗。然而，這種成功需要廣泛的訓練。在本研究中，我們檢驗了 ANN 的學習無關抽象推理。具體來說，我們評估了它們在沒有任何預訓練的情況下的表現，其中 ANN 的權重是隨機初始化的，並且僅在問題解決過程中發生變化。我們發現，樸素的 ANN 模型可以解決非平凡的視覺推理測驗，類似於用於評估人類學習無關推理的測驗。我們進一步研究了支持這種能力的機制。我們的結果表明了學習無關抽象推理的可能性，它不需要廣泛的訓練。

##### **Very Large-Scale Multi-Agent Simulation in AgentScope**
2407.17789v1 by Xuchen Pan, Dawei Gao, Yuexiang Xie, Zhewei Wei, Yaliang Li, Bolin Ding, Ji-Rong Wen, Jingren Zhou

Recent advances in large language models (LLMs) have opened new avenues for
applying multi-agent systems in very large-scale simulations. However, there
remain several challenges when conducting multi-agent simulations with existing
platforms, such as limited scalability and low efficiency, unsatisfied agent
diversity, and effort-intensive management processes. To address these
challenges, we develop several new features and components for AgentScope, a
user-friendly multi-agent platform, enhancing its convenience and flexibility
for supporting very large-scale multi-agent simulations. Specifically, we
propose an actor-based distributed mechanism as the underlying technological
infrastructure towards great scalability and high efficiency, and provide
flexible environment support for simulating various real-world scenarios, which
enables parallel execution of multiple agents, centralized workflow
orchestration, and both inter-agent and agent-environment interactions among
agents. Moreover, we integrate an easy-to-use configurable tool and an
automatic background generation pipeline in AgentScope, simplifying the process
of creating agents with diverse yet detailed background settings. Last but not
least, we provide a web-based interface for conveniently monitoring and
managing a large number of agents that might deploy across multiple devices. We
conduct a comprehensive simulation to demonstrate the effectiveness of the
proposed enhancements in AgentScope, and provide detailed observations and
discussions to highlight the great potential of applying multi-agent systems in
large-scale simulations. The source code is released on GitHub at
https://github.com/modelscope/agentscope to inspire further research and
development in large-scale multi-agent simulations.

摘要：大型語言模型 (LLM) 的最新進展為在非常大規模的模擬中應用多主體系統開闢了新途徑。然而，在使用現有平台進行多主體模擬時，仍然存在一些挑戰，例如可擴展性有限且效率低、主體多樣性不足，以及管理流程需要大量人力。為了應對這些挑戰，我們為 AgentScope（一個使用者友善的多主體平台）開發了多項新功能和元件，提升其便利性和靈活性，以支援非常大規模的多主體模擬。具體來說，我們提出一個基於 actor 的分散機制作為底層技術基礎架構，以實現極佳的可擴展性和高效率，並提供靈活的環境支援，以模擬各種真實世界的場景，這使得多個主體能夠平行執行、集中工作流程編排，以及主體之間和主體與環境之間的互動。此外，我們將一個易於使用的可設定工具和一個自動背景生成管道整合到 AgentScope 中，簡化了建立具有多樣化且詳細背景設定的主體的流程。最後但並非最不重要的一點是，我們提供了一個基於網路的介面，以便便利地監控和管理可能部署在多個裝置上的大量主體。我們進行了一項全面的模擬，以展示 AgentScope 中所提出增強功能的有效性，並提供詳細的觀察和討論，以強調在大型模擬中應用多主體系統的巨大潛力。原始碼已在 GitHub 上釋出，網址為 https://github.com/modelscope/agentscope，以激勵在大型多主體模擬中進行進一步的研究和開發。

##### **Advancing Multi-Modal Sensing Through Expandable Modality Alignment**
2407.17777v1 by Shenghong Dai, Shiqi Jiang, Yifan Yang, Ting Cao, Mo Li, Suman Banerjee, Lili Qiu

Sensing technology is widely used for comprehending the physical world, with
numerous modalities explored in past decades. While there has been considerable
work on multi-modality learning, they all require data of all modalities be
paired. How to leverage multi-modality data with partially pairings remains an
open problem. To tackle this challenge, we introduce the Babel framework,
encompassing the neural network architecture, data preparation and processing,
as well as the training strategies. Babel serves as a scalable pre-trained
multi-modal sensing neural network, currently aligning six sensing modalities,
namely Wi-Fi, mmWave, IMU, LiDAR, video, and depth. To overcome the scarcity of
complete paired data, the key idea of Babel involves transforming the
N-modality alignment into a series of two-modality alignments by devising the
expandable network architecture. This concept is also realized via a series of
novel techniques, including the pre-trained modality tower that capitalizes on
available single-modal networks, and the adaptive training strategy balancing
the contribution of the newly incorporated modality with the previously
established modality alignment.
  Evaluation demonstrates Babel's outstanding performance on eight human
activity recognition datasets, compared to various baselines e.g., the top
multi-modal sensing framework, single-modal sensing networks, and multi-modal
large language models. Babel not only effectively fuses multiple available
modalities (up to 22% accuracy increase), but also enhance the performance of
individual modality (12% averaged accuracy improvement). Case studies also
highlight exciting application scenarios empowered by Babel, including
cross-modality retrieval (i.e., sensing imaging), and bridging LLM for sensing
comprehension.

摘要：感知技術廣泛用於理解物理世界，在過去的幾十年中探索了許多模式。雖然已經對多模式學習進行了大量研究，但它們都需要所有模式的數據配對。如何利用部分配對的多模式數據仍然是一個未解決的問題。為了應對這一挑戰，我們引入了 Babel 框架，它包含神經網絡架構、數據準備和處理以及訓練策略。Babel 作為一個可擴展的預訓練多模式感知神經網絡，目前對齊六種感知模式，即 Wi-Fi、毫米波、IMU、LiDAR、視頻和深度。為了克服配對數據的稀缺性，Babel 的關鍵思想涉及通過設計可擴展的網絡架構，將 N 模式對齊轉換為一系列兩模式對齊。這個概念也通過一系列新技術實現，包括利用可用單模式網絡的預訓練模式塔，以及平衡新加入模式與先前建立模式對齊的貢獻的自適應訓練策略。評估表明，與各種基準相比，Babel 在八個人類活動識別數據集上的表現出色，例如頂級多模式感知框架、單模式感知網絡和多模式大型語言模型。Babel 不僅有效地融合了多種可用模式（準確率提高了 22%），而且還提高了單個模式的性能（平均準確率提高了 12%）。案例研究還強調了 Babel 賦能的令人興奮的應用場景，包括跨模式檢索（即感測成像）和橋接 LLM 以進行感測理解。

##### **KiVA: Kid-inspired Visual Analogies for Testing Large Multimodal Models**
2407.17773v1 by Eunice Yiu, Maan Qraitem, Charlie Wong, Anisa Noor Majhi, Yutong Bai, Shiry Ginosar, Alison Gopnik, Kate Saenko

This paper investigates visual analogical reasoning in large multimodal
models (LMMs) compared to human adults and children. A "visual analogy" is an
abstract rule inferred from one image and applied to another. While benchmarks
exist for testing visual reasoning in LMMs, they require advanced skills and
omit basic visual analogies that even young children can make. Inspired by
developmental psychology, we propose a new benchmark of 1,400 visual
transformations of everyday objects to test LMMs on visual analogical reasoning
and compare them to children and adults. We structure the evaluation into three
stages: identifying what changed (e.g., color, number, etc.), how it changed
(e.g., added one object), and applying the rule to new scenarios. Our findings
show that while models like GPT-4V, LLaVA-1.5, and MANTIS identify the "what"
effectively, they struggle with quantifying the "how" and extrapolating this
rule to new objects. In contrast, children and adults exhibit much stronger
analogical reasoning at all three stages. Additionally, the strongest tested
model, GPT-4V, performs better in tasks involving simple visual attributes like
color and size, correlating with quicker human adult response times.
Conversely, more complex tasks such as number, rotation, and reflection, which
necessitate extensive cognitive processing and understanding of the 3D physical
world, present more significant challenges. Altogether, these findings
highlight the limitations of training models on data that primarily consists of
2D images and text.

摘要：<paragraph>本篇論文探討大型多模態模型 (LMM) 與人類成人和兒童在視覺類比推理上的差異。「視覺類比」是一種從一幅圖像推論出的抽象規則，並應用於另一幅圖像。雖然現有測試 LMM 視覺推理能力的基準，但這些基準需要進階技能，且省略了即使幼童也能做出的基本視覺類比。受發展心理學啟發，我們提出一個新的基準，包含 1,400 個日常物體的視覺轉換，以測試 LMM 的視覺類比推理能力，並將其與兒童和成人進行比較。我們將評估分為三個階段：找出改變的內容（例如顏色、數量等）、改變的方式（例如增加一個物件），以及將規則應用於新的場景。我們的研究結果顯示，儘管 GPT-4V、LLaVA-1.5 和 MANTIS 等模型能有效識別「是什麼」，但它們在量化「如何」以及將此規則推廣到新物件方面有困難。相比之下，兒童和成人則在所有三個階段都展現出更強的類比推理能力。此外，測試中表現最好的模型 GPT-4V 在涉及簡單視覺屬性（例如顏色和大小）的任務中表現較佳，這與人類成人的反應時間較快有關。相反地，更複雜的任務，例如數字、旋轉和反射，需要廣泛的認知處理和對 3D 物理世界的理解，對模型來說更具挑戰性。總而言之，這些研究結果突顯了在主要由 2D 影像和文字組成的資料上訓練模型的限制。</paragraph>

##### **Banyan: Improved Representation Learning with Explicit Structure**
2407.17771v1 by Mattia Opper, N. Siddharth

We present Banyan, an improved model to learn semantic representations by
inducing explicit structure over data. In contrast to prior approaches using
structure spanning single sentences, Banyan learns by resolving multiple
constituent structures into a shared one explicitly incorporating global
context. Combined with an improved message-passing scheme inspired by Griffin,
Banyan learns significantly better representations, avoids spurious false
negatives with contrastive learning, and drastically improves memory efficiency
in such explicit-structured models. Using the Self-StrAE framework, we show
that Banyan (a) outperforms baselines using sentential structure across various
settings (b) matches or outperforms unstructured baselines like GloVe
(+augmentations) and a RoBERTa medium (+simcse) pre-trained on 100M tokens,
despite having just a handful of (non-embedding) parameters, and (c) also
learns effective representations across several low resource (Asian and
African) languages as measured on SemRel tasks.

摘要：我們提出 Banyan，這是一個改進的模型，可以透過在資料上誘導明確的結構來學習語義表示。與先前使用跨越單一句子的結構的方法相反，Banyan 透過將多個組成結構解析成一個明確包含全局上下文的共享結構來學習。結合受 Griffin 啟發的改良訊息傳遞機制，Banyan 可以學習到顯著更好的表示，避免對比學習中的虛假否定，並大幅提高此類明確結構模型中的記憶體效率。使用 Self-StrAE 框架，我們展示 Banyan (a) 在各種設定中使用句子結構優於基準 (b) 匹配或優於非結構化基準，例如 GloVe (+ 擴充) 和在 100M 個代幣上預訓練的 RoBERTa 中型 (+ simcse)，儘管只有少數 (非嵌入) 參數，而且 (c) 也在幾個低資源 (亞洲和非洲) 語言中學習到有效的表示，如 SemRel 任務中所測量。

##### **BotEval: Facilitating Interactive Human Evaluation**
2407.17770v1 by Hyundong Cho, Thamme Gowda, Yuyang Huang, Zixun Lu, Tianli Tong, Jonathan May

Following the rapid progress in natural language processing (NLP) models,
language models are applied to increasingly more complex interactive tasks such
as negotiations and conversation moderations. Having human evaluators directly
interact with these NLP models is essential for adequately evaluating the
performance on such interactive tasks. We develop BotEval, an easily
customizable, open-source, evaluation toolkit that focuses on enabling
human-bot interactions as part of the evaluation process, as opposed to human
evaluators making judgements for a static input. BotEval balances flexibility
for customization and user-friendliness by providing templates for common use
cases that span various degrees of complexity and built-in compatibility with
popular crowdsourcing platforms. We showcase the numerous useful features of
BotEval through a study that evaluates the performance of various chatbots on
their effectiveness for conversational moderation and discuss how BotEval
differs from other annotation tools.

摘要：隨著自然語言處理 (NLP) 模型的快速進展，語言模型正被應用於越來越複雜的互動任務，例如協商和對話調節。讓人類評估人員直接與這些 NLP 模型互動對於充分評估此類互動任務的效能至關重要。我們開發了 BotEval，這是一個易於自訂、開源的評估工具包，其重點在於將人類機器人互動納入評估流程的一部分，而不是讓人類評估人員對靜態輸入做出判斷。BotEval 在自訂彈性和使用者友善性之間取得平衡，提供適用於各種複雜程度的常見使用案例範本，並內建與熱門群眾外包平台相容。我們透過一項研究展示了 BotEval 的許多有用功能，該研究評估了各種聊天機器人在對話調節方面的有效性，並討論 BotEval 與其他註解工具有何不同。

##### **Mpox Detection Advanced: Rapid Epidemic Response Through Synthetic Data**
2407.17762v1 by Yudara Kularathne, Prathapa Janitha, Sithira Ambepitiya, Prarththanan Sothyrajah, Thanveer Ahamed, Dinuka Wijesundara

Rapid development of disease detection models using computer vision is
crucial in responding to medical emergencies, such as epidemics or bioterrorism
events. Traditional data collection methods are often too slow in these
scenarios, requiring innovative approaches for quick, reliable model generation
from minimal data. Our study introduces a novel approach by constructing a
comprehensive computer vision model to detect Mpox lesions using only synthetic
data. Initially, these models generated a diverse set of synthetic images
representing Mpox lesions on various body parts (face, back, chest, leg, neck,
arm) across different skin tones as defined by the Fitzpatrick scale (fair,
brown, dark skin). Subsequently, we trained and tested a vision model with this
synthetic dataset to evaluate the diffusion models' efficacy in producing
high-quality training data and its impact on the vision model's medical image
recognition performance. The results were promising; the vision model achieved
a 97% accuracy rate, with 96% precision and recall for Mpox cases, and
similarly high metrics for normal and other skin disorder cases, demonstrating
its ability to correctly identify true positives and minimize false positives.
The model achieved an F1-Score of 96% for Mpox cases and 98% for normal and
other skin disorders, reflecting a balanced precision-recall relationship, thus
ensuring reliability and robustness in its predictions. Our proposed
SynthVision methodology indicates the potential to develop accurate computer
vision models with minimal data input for future medical emergencies.

摘要：<paragraph>利用電腦視覺快速開發疾病檢測模型對於因應醫療緊急事件（例如流行病或生物恐怖主義事件）至關重要。傳統的資料收集方法在這些情況下通常太慢，需要創新的方法才能從最少資料中快速、可靠地產生模型。我們的研究介紹了一種新穎的方法，透過建構一個全面的電腦視覺模型，僅使用合成資料來檢測猴痘病灶。最初，這些模型產生了一組多樣化的合成影像，代表了不同膚色（根據 Fitzpatrick 量表定義為白皙、棕色、深色皮膚）上不同身體部位（臉部、背部、胸部、腿部、頸部、手臂）的猴痘病灶。隨後，我們使用這個合成資料集訓練和測試一個視覺模型，以評估擴散模型產生高品質訓練資料的效能，以及其對視覺模型醫學影像辨識效能的影響。結果令人滿意；視覺模型達到了 97% 的準確率，猴痘病例的準確度和召回率為 96%，正常和其它皮膚疾病病例的指標也同樣高，證明了它正確辨識真陽性並將假陽性降至最低的能力。該模型在猴痘病例中達到了 96% 的 F1 分數，在正常和其它皮膚疾病中達到了 98%，反映出平衡的準確度召回率關係，從而確保其預測的可靠性和穩健性。我們提出的 SynthVision 方法表明，有可能為未來的醫療緊急事件開發出準確的電腦視覺模型，且資料輸入量最少。</paragraph>

##### **TwIPS: A Large Language Model Powered Texting Application to Simplify Conversational Nuances for Autistic Users**
2407.17760v1 by Rukhshan Haroon, Fahad Dogar

Autistic individuals often experience difficulties in conveying and
interpreting emotional tone and non-literal nuances. Many also mask their
communication style to avoid being misconstrued by others, spending
considerable time and mental effort in the process. To address these challenges
in text-based communication, we present TwIPS, a prototype texting application
powered by a large language model (LLM), which can assist users with: a)
deciphering tone and meaning of incoming messages, b) ensuring the emotional
tone of their message is in line with their intent, and c) coming up with
alternate phrasing for messages that could be misconstrued and received
negatively by others. We leverage an AI-based simulation and a conversational
script to evaluate TwIPS with 8 autistic participants in an in-lab setting. Our
findings show TwIPS enables a convenient way for participants to seek
clarifications, provides a better alternative to tone indicators, and
facilitates constructive reflection on writing technique and style. We also
examine how autistic users utilize language for self-expression and
interpretation in instant messaging, and gather feedback for enhancing our
prototype. We conclude with a discussion around balancing user-autonomy with
AI-mediation, establishing appropriate trust levels in AI systems, and
customization needs if autistic users in the context of AI-assisted
communication

摘要：自閉症患者通常難以傳達和詮釋情緒語氣和非字面含義。許多人也會掩飾他們的溝通方式，以避免被他人誤解，在此過程中花費大量時間和心力。為了應對文字溝通中的這些挑戰，我們提出了 TwIPS，這是一個由大型語言模型 (LLM) 提供支援的原型簡訊應用程式，可以協助使用者：a) 解讀訊息的語氣和含義，b) 確保他們訊息的情緒語氣符合他們的意圖，以及 c) 想出其他措辭，以免訊息被誤解並被他人負面接收。我們利用基於 AI 的模擬和對話腳本，在實驗室環境中對 8 位自閉症參與者評估 TwIPS。我們的研究結果顯示，TwIPS 讓參與者能夠方便地尋求澄清，提供了一個比語氣指標更好的替代方案，並促進對寫作技巧和風格的建設性反思。我們還探討了自閉症使用者如何利用語言在即時訊息中進行自我表達和詮釋，並收集回饋以增強我們的原型。我們最後討論了在 AI 輔助溝通的背景下，平衡使用者自主性與 AI 協調、建立對 AI 系統的適當信任程度，以及自閉症使用者的客製化需求。

##### **Beyond Entity Alignment: Towards Complete Knowledge Graph Alignment via Entity-Relation Synergy**
2407.17745v1 by Xiaohan Fang, Chaozhuo Li, Yi Zhao, Qian Zang, Litian Zhang, Jiquan Peng, Xi Zhang, Jibing Gong

Knowledge Graph Alignment (KGA) aims to integrate knowledge from multiple
sources to address the limitations of individual Knowledge Graphs (KGs) in
terms of coverage and depth. However, current KGA models fall short in
achieving a ``complete'' knowledge graph alignment. Existing models primarily
emphasize the linkage of cross-graph entities but overlook aligning relations
across KGs, thereby providing only a partial solution to KGA. The semantic
correlations embedded in relations are largely overlooked, potentially
restricting a comprehensive understanding of cross-KG signals. In this paper,
we propose to conceptualize relation alignment as an independent task and
conduct KGA by decomposing it into two distinct but highly correlated
sub-tasks: entity alignment and relation alignment. To capture the mutually
reinforcing correlations between these objectives, we propose a novel
Expectation-Maximization-based model, EREM, which iteratively optimizes both
sub-tasks. Experimental results on real-world datasets demonstrate that EREM
consistently outperforms state-of-the-art models in both entity alignment and
relation alignment tasks.

摘要：知識圖譜對齊 (KGA) 旨在整合來自多個來源的知識，以解決個別知識圖譜 (KG) 在涵蓋範圍和深度方面的限制。然而，當前的 KGA 模型無法達成「完整的」知識圖譜對齊。現有的模型主要強調跨圖譜實體的連結，但忽略了跨 KG 對齊關係，因此僅提供 KGA 的部分解決方案。關係中內嵌的語義關聯性在很大程度上被忽略，這可能會限制對跨 KG 訊號的全面理解。在本文中，我們建議將關係對齊概念化為一個獨立的任務，並通過將其分解為兩個不同但高度相關的子任務：實體對齊和關係對齊，來執行 KGA。為了捕捉這些目標之間相互強化的關聯性，我們提出了一個新的基於期望最大化的模型 EREM，它迭代優化兩個子任務。在真實世界資料集上的實驗結果表明，在實體對齊和關係對齊任務中，EREM 持續優於最先進的模型。

##### **Cost-effective Instruction Learning for Pathology Vision and Language Analysis**
2407.17734v1 by Kaitao Chen, Mianxin Liu, Fang Yan, Lei Ma, Xiaoming Shi, Lilong Wang, Xiaosong Wang, Lifeng Zhu, Zhe Wang, Mu Zhou, Shaoting Zhang

The advent of vision-language models fosters the interactive conversations
between AI-enabled models and humans. Yet applying these models into clinics
must deal with daunting challenges around large-scale training data, financial,
and computational resources. Here we propose a cost-effective instruction
learning framework for conversational pathology named as CLOVER. CLOVER only
trains a lightweight module and uses instruction tuning while freezing the
parameters of the large language model. Instead of using costly GPT-4, we
propose well-designed prompts on GPT-3.5 for building generation-based
instructions, emphasizing the utility of pathological knowledge derived from
the Internet source. To augment the use of instructions, we construct a
high-quality set of template-based instructions in the context of digital
pathology. From two benchmark datasets, our findings reveal the strength of
hybrid-form instructions in the visual question-answer in pathology. Extensive
results show the cost-effectiveness of CLOVER in answering both open-ended and
closed-ended questions, where CLOVER outperforms strong baselines that possess
37 times more training parameters and use instruction data generated from
GPT-4. Through the instruction tuning, CLOVER exhibits robustness of few-shot
learning in the external clinical dataset. These findings demonstrate that
cost-effective modeling of CLOVER could accelerate the adoption of rapid
conversational applications in the landscape of digital pathology.

摘要：視覺語言模型的出現促進了 AI 啟用模型與人類之間的互動對話。然而，將這些模型應用於臨床必須應對大規模訓練數據、財務和計算資源等嚴峻挑戰。在此，我們提出了一個名為 CLOVER 的經濟高效的會話病理學指令學習架構。CLOVER 僅訓練一個輕量級模組，並在凍結大型語言模型參數的同時使用指令微調。我們沒有使用昂貴的 GPT-4，而是針對 GPT-3.5 提出設計良好的提示，以建立基於生成的指令，強調從網際網路來源衍生的病理知識的效用。為了擴展指令的使用，我們在數位病理學的背景下構建了一組高品質的基於範本的指令。從兩個基準資料集，我們的研究結果揭示了混合形式指令在病理學視覺問答中的優勢。廣泛的結果顯示了 CLOVER 在回答開放式和封閉式問題方面的經濟效益，其中 CLOVER 優於擁有多 37 倍訓練參數並使用從 GPT-4 生成的指令資料的強大基準。透過指令微調，CLOVER 在外部臨床資料集中展現了小樣本學習的穩健性。這些發現證明了 CLOVER 的經濟高效建模可以加速在數位病理領域採用快速對話式應用程式。

##### **Are Large Language Models Possible to Conduct Cognitive Behavioral Therapy?**
2407.17730v1 by Hao Shen, Zihan Li, Minqiang Yang, Minghui Ni, Yongfeng Tao, Zhengyang Yu, Weihao Zheng, Chen Xu, Bin Hu

In contemporary society, the issue of psychological health has become
increasingly prominent, characterized by the diversification, complexity, and
universality of mental disorders. Cognitive Behavioral Therapy (CBT), currently
the most influential and clinically effective psychological treatment method
with no side effects, has limited coverage and poor quality in most countries.
In recent years, researches on the recognition and intervention of emotional
disorders using large language models (LLMs) have been validated, providing new
possibilities for psychological assistance therapy. However, are LLMs truly
possible to conduct cognitive behavioral therapy? Many concerns have been
raised by mental health experts regarding the use of LLMs for therapy. Seeking
to answer this question, we collected real CBT corpus from online video
websites, designed and conducted a targeted automatic evaluation framework
involving the evaluation of emotion tendency of generated text, structured
dialogue pattern and proactive inquiry ability. For emotion tendency, we
calculate the emotion tendency score of the CBT dialogue text generated by each
model. For structured dialogue pattern, we use a diverse range of automatic
evaluation metrics to compare speaking style, the ability to maintain
consistency of topic and the use of technology in CBT between different models
. As for inquiring to guide the patient, we utilize PQA (Proactive Questioning
Ability) metric. We also evaluated the CBT ability of the LLM after integrating
a CBT knowledge base to explore the help of introducing additional knowledge to
enhance the model's CBT counseling ability. Four LLM variants with excellent
performance on natural language processing are evaluated, and the experimental
result shows the great potential of LLMs in psychological counseling realm,
especially after combining with other technological means.

摘要：在當代社會中，心理健康議題日益受到重視，其特徵在於心理疾病的多樣化、複雜化、普遍化。認知行為療法（CBT），目前最具影響力且臨床療效最好的心理治療方法，在多數國家覆蓋率低且品質不佳。近年來，利用大型語言模型（LLM）辨識與介入情緒疾患的研究獲得驗證，為心理諮助治療帶來新的可能性。然而，LLM 是否真能執行認知行為治療？許多心理健康專家對於 LLM 應用於治療提出疑慮。為了解答此問題，我們從線上影音網站蒐集真實的 CBT 語料，設計並執行目標自動評估架構，包含評估生成文字的情緒傾向、結構化對話模式及主動提問能力。對於情緒傾向，我們計算各個模型產生的 CBT 對話文字的情緒傾向分數。對於結構化對話模式，我們使用多元的自動評估指標，比較不同模型在 CBT 中的說話風格、維持主題一致性的能力及使用技術。至於引導病患提問，我們採用 PQA（主動提問能力）指標。我們也評估 LLM 整合 CBT 知識庫後的 CBT 能力，探討引入額外知識對於增強模型 CBT 諮商能力的幫助。評估四種在自然語言處理表現優異的 LLM 變體，實驗結果顯示 LLM 在心理諮商領域有極大的潛力，特別是在結合其他技術手段後。

##### **Describe Where You Are: Improving Noise-Robustness for Speech Emotion Recognition with Text Description of the Environment**
2407.17716v1 by Seong-Gyun Leem, Daniel Fulford, Jukka-Pekka Onnela, David Gard, Carlos Busso

Speech emotion recognition (SER) systems often struggle in real-world
environments, where ambient noise severely degrades their performance. This
paper explores a novel approach that exploits prior knowledge of testing
environments to maximize SER performance under noisy conditions. To address
this task, we propose a text-guided, environment-aware training where an SER
model is trained with contaminated speech samples and their paired noise
description. We use a pre-trained text encoder to extract the text-based
environment embedding and then fuse it to a transformer-based SER model during
training and inference. We demonstrate the effectiveness of our approach
through our experiment with the MSP-Podcast corpus and real-world additive
noise samples collected from the Freesound repository. Our experiment indicates
that the text-based environment descriptions processed by a large language
model (LLM) produce representations that improve the noise-robustness of the
SER system. In addition, our proposed approach with an LLM yields better
performance than our environment-agnostic baselines, especially in low
signal-to-noise ratio (SNR) conditions. When testing at -5dB SNR level, our
proposed method shows better performance than our best baseline model by 31.8 %
(arousal), 23.5% (dominance), and 9.5% (valence).

摘要：語音情緒辨識 (SER) 系統在真實世界的環境中常常會遇到困難，因為環境噪音會嚴重降低其效能。本文探討了一種新方法，利用測試環境的先驗知識，在有噪音的條件下最大化 SER 效能。為了處理這個任務，我們提出一個文字導引、環境感知的訓練，其中 SER 模型使用受汙染的語音範例及其配對的噪音描述進行訓練。我們使用預先訓練的文字編碼器來萃取基於文字的環境嵌入，然後在訓練和推論期間將其融合到基於轉換器的 SER 模型中。我們透過使用 MSP-Podcast 語料庫和從 Freesound 資料庫收集的真實世界加成噪音範例進行實驗，證明了我們方法的有效性。我們的實驗表明，由大型語言模型 (LLM) 處理的基於文字的環境描述會產生表徵，進而提升 SER 系統的抗噪性。此外，我們提出的使用 LLM 的方法比我們與環境無關的基準線有更好的效能，特別是在低訊噪比 (SNR) 條件下。當在 -5dB SNR 等級進行測試時，我們提出的方法比我們最好的基準線模型在喚醒方面提升了 31.8%，在支配方面提升了 23.5%，在效價方面提升了 9.5%。

##### **Enhancing Agent Learning through World Dynamics Modeling**
2407.17695v1 by Zhiyuan Sun, Haochen Shi, Marc-Alexandre Côté, Glen Berseth, Xingdi Yuan, Bang Liu

While large language models (LLMs) have been increasingly deployed across
tasks in language understanding and interactive decision-making, their
impressive performance is largely due to the comprehensive and in-depth domain
knowledge embedded within them. However, the extent of this knowledge can vary
across different domains. Existing methods often assume that LLMs already
possess such comprehensive and in-depth knowledge of their environment,
overlooking potential gaps in their understanding of actual world dynamics. To
address this gap, we introduce Discover, Verify, and Evolve (DiVE), a framework
that discovers world dynamics from a small number of demonstrations, verifies
the correctness of these dynamics, and evolves new, advanced dynamics tailored
to the current situation. Through extensive evaluations, we analyze the impact
of each component on performance and compare the automatically generated
dynamics from DiVE with human-annotated world dynamics. Our results demonstrate
that LLMs guided by DiVE can make better decisions, achieving rewards
comparable to human players in the Crafter environment.

摘要：儘管大型語言模型 (LLM) 已在語言理解和互動決策制定等任務中得到越來越廣泛的部署，但它們令人印象深刻的表現很大程度上歸功於內嵌在其中的全面且深入的領域知識。然而，這種知識的程度在不同的領域中可能有所不同。現有方法通常假設 LLM 已具備對其環境的全面且深入的了解，忽視了它們對實際世界動態理解中的潛在差距。為了解決這個差距，我們引入了探索、驗證和演化 (DiVE)，這是一個框架，它從少數示範中探索世界動態，驗證這些動態的正確性，並演化出新的、先進的動態，這些動態專門針對當前情況。透過廣泛的評估，我們分析了每個組成部分對效能的影響，並將 DiVE 自動產生的動態與人工標註的世界動態進行比較。我們的結果表明，由 DiVE 指導的 LLM 可以做出更好的決策，在 Crafter 環境中獲得與人類玩家相當的獎勵。

##### **Examining the Influence of Political Bias on Large Language Model Performance in Stance Classification**
2407.17688v2 by Lynnette Hui Xian Ng, Iain Cruickshank, Roy Ka-Wei Lee

Large Language Models (LLMs) have demonstrated remarkable capabilities in
executing tasks based on natural language queries. However, these models,
trained on curated datasets, inherently embody biases ranging from racial to
national and gender biases. It remains uncertain whether these biases impact
the performance of LLMs for certain tasks. In this study, we investigate the
political biases of LLMs within the stance classification task, specifically
examining whether these models exhibit a tendency to more accurately classify
politically-charged stances. Utilizing three datasets, seven LLMs, and four
distinct prompting schemes, we analyze the performance of LLMs on politically
oriented statements and targets. Our findings reveal a statistically
significant difference in the performance of LLMs across various politically
oriented stance classification tasks. Furthermore, we observe that this
difference primarily manifests at the dataset level, with models and prompting
schemes showing statistically similar performances across different stance
classification datasets. Lastly, we observe that when there is greater
ambiguity in the target the statement is directed towards, LLMs have poorer
stance classification accuracy.
  Code & Dataset: http://doi.org/10.5281/zenodo.12938478

摘要：大型語言模型 (LLM) 在執行基於自然語言查詢的任務方面展示了非凡的能力。然而，這些模型在經過整理的資料集上訓練，從種族到國家和性別偏見，它們本質上包含了各種偏見。這些偏見是否會影響 LLM 對特定任務的執行，仍然不確定。在本研究中，我們探討了立場分類任務中 LLM 的政治偏見，特別是檢視這些模型是否表現出更準確分類政治立場的趨勢。利用三個資料集、七個 LLM 和四種不同的提示方案，我們分析了 LLM 在政治導向陳述和目標上的表現。我們的研究結果揭示了 LLM 在各種政治導向立場分類任務中的表現存在統計上顯著的差異。此外，我們觀察到這種差異主要表現在資料集層級，而模型和提示方案在不同的立場分類資料集上表現出統計上相似的表現。最後，我們觀察到，當陳述所針對的目標存在更大的歧義時，LLM 的立場分類準確度較差。
程式碼和資料集：http://doi.org/10.5281/zenodo.12938478

##### **Transformers on Markov Data: Constant Depth Suffices**
2407.17686v1 by Nived Rajaraman, Marco Bondaschi, Kannan Ramchandran, Michael Gastpar, Ashok Vardhan Makkuva

Attention-based transformers have been remarkably successful at modeling
generative processes across various domains and modalities. In this paper, we
study the behavior of transformers on data drawn from \kth Markov processes,
where the conditional distribution of the next symbol in a sequence depends on
the previous $k$ symbols observed. We observe a surprising phenomenon
empirically which contradicts previous findings: when trained for sufficiently
long, a transformer with a fixed depth and $1$ head per layer is able to
achieve low test loss on sequences drawn from \kth Markov sources, even as $k$
grows. Furthermore, this low test loss is achieved by the transformer's ability
to represent and learn the in-context conditional empirical distribution. On
the theoretical side, our main result is that a transformer with a single head
and three layers can represent the in-context conditional empirical
distribution for \kth Markov sources, concurring with our empirical
observations. Along the way, we prove that \textit{attention-only} transformers
with $O(\log_2(k))$ layers can represent the in-context conditional empirical
distribution by composing induction heads to track the previous $k$ symbols in
the sequence. These results provide more insight into our current understanding
of the mechanisms by which transformers learn to capture context, by
understanding their behavior on Markov sources.

摘要：基於注意力的Transformer在對各種領域和模態的生成式過程建模方面取得了顯著的成功。在本文中，我們研究了Transformer在從 k 階馬可夫過程中提取的資料上的行為，其中序列中下一個符號的條件分佈取決於觀察到的前 k 個符號。我們在經驗上觀察到一個驚人的現象，這與先前的發現相矛盾：經過充分長的訓練後，具有固定深度和每層 1 個頭的Transformer能夠在從 k 階馬可夫源中提取的序列上實現低測試損失，即使 k 增長。此外，這種低測試損失是通過Transformer表示和學習上下文條件經驗分佈的能力實現的。在理論方面，我們的的主要結果是具有單個頭和三層的Transformer可以表示 k 階馬可夫源的上下文條件經驗分佈，這與我們的經驗觀察結果一致。在此過程中，我們證明了具有 O(log_2(k)) 層的「僅注意力」Transformer可以通過組合歸納頭部來追蹤序列中的前 k 個符號，從而表示上下文條件經驗分佈。這些結果通過理解Transformer在馬可夫源上的行為，對我們當前對Transformer學習捕捉上下文的機制的理解提供了更多見解。

##### **Efficient LLM Training and Serving with Heterogeneous Context Sharding among Attention Heads**
2407.17678v1 by Xihui Lin, Yunan Zhang, Suyu Ge, Barun Patra, Vishrav Chaudhary, Xia Song

Existing LLM training and inference frameworks struggle in boosting
efficiency with sparsity while maintaining the integrity of context and model
architecture. Inspired by the sharding concept in database and the fact that
attention parallelizes over heads on accelerators, we propose Sparsely-Sharded
(S2) Attention, an attention algorithm that allocates heterogeneous context
partitions for different attention heads to divide and conquer. S2-Attention
enforces each attention head to only attend to a partition of contexts
following a strided sparsity pattern, while the full context is preserved as
the union of all the shards. As attention heads are processed in separate
thread blocks, the context reduction for each head can thus produce end-to-end
speed-up and memory reduction. At inference, LLMs trained with S2-Attention can
then take the KV cache reduction as free meals with guaranteed model quality
preserve. In experiments, we show S2-Attentioncan provide as much as (1) 25.3X
wall-clock attention speed-up over FlashAttention-2, resulting in 6X reduction
in end-to-end training time and 10X inference latency, (2) on-par model
training quality compared to default attention, (3)perfect needle retrieval
accuracy over 32K context window. On top of the algorithm, we build DKernel, an
LLM training and inference kernel library that allows users to customize
sparsity patterns for their own models. We open-sourced DKerneland make it
compatible with Megatron, Pytorch, and vLLM.

摘要：現有的 LLM 訓練和推理架構在提升稀疏性效率的同時，難以維持脈絡和模型架構的完整性。受到資料庫分片概念和注意力在加速器上平行於頭部的啟發，我們提出稀疏分片 (S2) 注意力，這是一種注意力演算法，它分配異質脈絡分割，供不同的注意力頭部進行分而治之。S2-Attention 強制每個注意力頭部只關注脈絡分割，遵循分步稀疏性模式，同時將完整脈絡保留為所有分片的聯集。由於注意力頭部在獨立的執行緒區塊中處理，因此每個頭部的脈絡簡化可以產生端到端的加速和記憶體減少。在推理時，使用 S2-Attention 訓練的 LLM 可以將 KV 快取簡化視為免費餐點，同時保證模型品質保持不變。在實驗中，我們展示 S2-Attention 可以提供高達 (1) 25.3 倍的 FlashAttention-2 牆面時脈注意力加速，從而將端到端訓練時間減少 6 倍，將推理延遲減少 10 倍，(2) 與預設注意力相比，模型訓練品質相當，(3) 在 32K 脈絡視窗中完美無缺的針頭檢索準確度。在演算法之上，我們建構了 DKernel，這是一個 LLM 訓練和推理核心函式庫，允許使用者為自己的模型自訂稀疏性模式。我們開放原始碼 DKernel，並使其與 Megatron、Pytorch 和 vLLM 相容。

##### **CRASAR-U-DROIDs: A Large Scale Benchmark Dataset for Building Alignment and Damage Assessment in Georectified sUAS Imagery**
2407.17673v1 by Thomas Manzini, Priyankari Perali, Raisa Karnik, Robin Murphy

This document presents the Center for Robot Assisted Search And Rescue -
Uncrewed Aerial Systems - Disaster Response Overhead Inspection Dataset
(CRASAR-U-DROIDs) for building damage assessment and spatial alignment
collected from small uncrewed aerial systems (sUAS) geospatial imagery. This
dataset is motivated by the increasing use of sUAS in disaster response and the
lack of previous work in utilizing high-resolution geospatial sUAS imagery for
machine learning and computer vision models, the lack of alignment with
operational use cases, and with hopes of enabling further investigations
between sUAS and satellite imagery. The CRASAR-U-DRIODs dataset consists of
fifty-two (52) orthomosaics from ten (10) federally declared disasters
(Hurricane Ian, Hurricane Ida, Hurricane Harvey, Hurricane Idalia, Hurricane
Laura, Hurricane Michael, Musset Bayou Fire, Mayfield Tornado, Kilauea
Eruption, and Champlain Towers Collapse) spanning 67.98 square kilometers
(26.245 square miles), containing 21,716 building polygons and damage labels,
and 7,880 adjustment annotations. The imagery was tiled and presented in
conjunction with overlaid building polygons to a pool of 130 annotators who
provided human judgments of damage according to the Joint Damage Scale. These
annotations were then reviewed via a two-stage review process in which building
polygon damage labels were first reviewed individually and then again by
committee. Additionally, the building polygons have been aligned spatially to
precisely overlap with the imagery to enable more performant machine learning
models to be trained. It appears that CRASAR-U-DRIODs is the largest labeled
dataset of sUAS orthomosaic imagery.

摘要：<paragraph>本文件展示了機器人協助搜尋和救援中心 - 無人機系統 - 災難應變航拍檢測資料集 (CRASAR-U-DROIDs)，用於建築損害評估和空間對齊，資料集收集自小型無人機 (sUAS) 地理空間影像。此資料集的動機來自於 sUAS 在災難應變中使用日益增加，以及先前缺乏利用高解析度 sUAS 地理空間影像進行機器學習和電腦視覺模型、缺乏與操作使用案例對齊，以及希望促成 sUAS 和衛星影像之間進一步調查。CRASAR-U-DROIDs 資料集包含來自十 (10) 個聯邦宣布的災難 (伊恩颶風、艾達颶風、哈維颶風、伊達莉亞颶風、勞拉颶風、麥可颶風、馬塞特灣大火、梅菲爾德龍捲風、基拉韋厄火山爆發和尚普蘭大廈倒塌) 的五十二 (52) 個正射影像，涵蓋 67.98 平方公里 (26.245 平方英里)，包含 21,716 個建築多邊形和損害標籤，以及 7,880 個調整註解。影像以拼貼方式呈現，並與疊加的建築多邊形一起呈現給 130 位註解者，他們根據聯合損害量表提供人為損害判斷。然後透過兩階段審查流程審查這些註解，其中建築多邊形損害標籤先個別審查，然後再由委員會審查。此外，建築多邊形已在空間上對齊，以便與影像精確重疊，以訓練效能更高的機器學習模型。CRASAR-U-DROIDs 看似是標籤最多的 sUAS 正射影像資料集。</paragraph>

##### **Spiking Neural Networks in Vertical Federated Learning: Performance Trade-offs**
2407.17672v1 by Maryam Abbasihafshejani, Anindya Maiti, Murtuza Jadliwala

Federated machine learning enables model training across multiple clients
while maintaining data privacy. Vertical Federated Learning (VFL) specifically
deals with instances where the clients have different feature sets of the same
samples. As federated learning models aim to improve efficiency and
adaptability, innovative neural network architectures like Spiking Neural
Networks (SNNs) are being leveraged to enable fast and accurate processing at
the edge. SNNs, known for their efficiency over Artificial Neural Networks
(ANNs), have not been analyzed for their applicability in VFL, thus far. In
this paper, we investigate the benefits and trade-offs of using SNN models in a
vertical federated learning setting. We implement two different federated
learning architectures -- with model splitting and without model splitting --
that have different privacy and performance implications. We evaluate the setup
using CIFAR-10 and CIFAR-100 benchmark datasets along with SNN implementations
of VGG9 and ResNET classification models. Comparative evaluations demonstrate
that the accuracy of SNN models is comparable to that of traditional ANNs for
VFL applications, albeit significantly more energy efficient.

摘要：聯邦機器學習讓模型訓練跨越多個客戶端，同時維持資料隱私。垂直聯邦學習 (VFL) 特別處理客戶端擁有相同樣本不同特徵集的案例。由於聯邦學習模型旨在提升效率和適應性，創新的神經網路架構（如脈衝神經網路 (SNNs)）被用於在邊緣裝置上實現快速且精確的處理。以其高於人工神經網路 (ANNs) 的效率著稱的 SNNs，目前尚未針對其在 VFL 中的適用性進行分析。在本文中，我們探討在垂直聯邦學習設定中使用 SNN 模型的優點和權衡。我們實作了兩種不同的聯邦學習架構（一種有模型分割，一種沒有模型分割），它們有不同的隱私和效能影響。我們使用 CIFAR-10 和 CIFAR-100 基準資料集以及 VGG9 和 ResNET 分類模型的 SNN 實作來評估設定。比較評估證明，SNN 模型的準確度與傳統 ANNs 在 VFL 應用中相當，但能源效率顯著提升。

##### **SMA-Hyper: Spatiotemporal Multi-View Fusion Hypergraph Learning for Traffic Accident Prediction**
2407.17642v1 by Xiaowei Gao, James Haworth, Ilya Ilyankou, Xianghui Zhang, Tao Cheng, Stephen Law, Huanfa Chen

Predicting traffic accidents is the key to sustainable city management, which
requires effective address of the dynamic and complex spatiotemporal
characteristics of cities. Current data-driven models often struggle with data
sparsity and typically overlook the integration of diverse urban data sources
and the high-order dependencies within them. Additionally, they frequently rely
on predefined topologies or weights, limiting their adaptability in
spatiotemporal predictions. To address these issues, we introduce the
Spatiotemporal Multiview Adaptive HyperGraph Learning (SMA-Hyper) model, a
dynamic deep learning framework designed for traffic accident prediction.
Building on previous research, this innovative model incorporates dual adaptive
spatiotemporal graph learning mechanisms that enable high-order cross-regional
learning through hypergraphs and dynamic adaptation to evolving urban data. It
also utilises contrastive learning to enhance global and local data
representations in sparse datasets and employs an advance attention mechanism
to fuse multiple views of accident data and urban functional features, thereby
enriching the contextual understanding of risk factors. Extensive testing on
the London traffic accident dataset demonstrates that the SMA-Hyper model
significantly outperforms baseline models across various temporal horizons and
multistep outputs, affirming the effectiveness of its multiview fusion and
adaptive learning strategies. The interpretability of the results further
underscores its potential to improve urban traffic management and safety by
leveraging complex spatiotemporal urban data, offering a scalable framework
adaptable to diverse urban environments.

摘要：預測交通事故是永續城市管理的關鍵，這需要有效處理城市動態且複雜的時空特徵。目前的資料驅動模型經常在資料稀疏性上掙扎，且通常忽略整合多樣的都市資料來源和它們之間的高階依賴性。此外，它們經常依賴預先定義的拓撲或權重，限制了它們在時空預測中的適應性。為了解決這些問題，我們引入了時空多視角自適應超圖學習 (SMA-Hyper) 模型，這是一個動態深度學習架構，設計用於交通事故預測。建構於先前的研究，這個創新模型結合了雙重自適應時空圖學習機制，透過超圖啟用高階跨區域學習，以及動態適應演化的都市資料。它也利用對比學習來增強稀疏資料集中的全局和局部資料表示，並採用先進的注意機制來融合事故資料和都市功能特徵的多重視角，從而豐富風險因子的脈絡理解。在倫敦交通事故資料集上的廣泛測試證明，SMA-Hyper 模型在各種時間範圍和多步驟輸出上都顯著優於基準模型，肯定了其多視角融合和自適應學習策略的有效性。結果的可解釋性進一步強調了它透過利用複雜的時空都市資料來改善都市交通管理和安全的潛力，提供一個可適應多樣都市環境的可擴充架構。

##### **Time Matters: Examine Temporal Effects on Biomedical Language Models**
2407.17638v1 by Weisi Liu, Zhe He, Xiaolei Huang

Time roots in applying language models for biomedical applications: models
are trained on historical data and will be deployed for new or future data,
which may vary from training data. While increasing biomedical tasks have
employed state-of-the-art language models, there are very few studies have
examined temporal effects on biomedical models when data usually shifts across
development and deployment. This study fills the gap by statistically probing
relations between language model performance and data shifts across three
biomedical tasks. We deploy diverse metrics to evaluate model performance,
distance methods to measure data drifts, and statistical methods to quantify
temporal effects on biomedical language models. Our study shows that time
matters for deploying biomedical language models, while the degree of
performance degradation varies by biomedical tasks and statistical
quantification approaches. We believe this study can establish a solid
benchmark to evaluate and assess temporal effects on deploying biomedical
language models.

摘要：時間植根於將語言模型應用於生物醫學應用：模型
經過歷史數據訓練，將部署於新數據或未來數據，
這可能會與訓練數據有所不同。雖然越來越多的生物醫學任務已經
採用了最先進的語言模型，但當數據通常在開發和部署之間轉移時，很少有研究
檢查了對生物醫學模型的時序效應。本研究通過統計探查
語言模型性能與三個生物醫學任務之間的數據轉移關係來填補這一空白。我們部署多種指標來評估模型性能，
距離方法來測量數據漂移，以及統計方法來量化
對生物醫學語言模型的時序效應。我們的研究表明，時間
對於部署生物醫學語言模型很重要，而性能下降的程度因生物醫學任務和統計
量化方法而異。我們相信這項研究可以建立一個穩固的
基準來評估和評估對部署生物醫學的時序效應
語言模型。

##### **IgnitionInnovators at "Discharge Me!": Chain-of-Thought Instruction Finetuning Large Language Models for Discharge Summaries**
2407.17636v1 by An Quang Tang, Xiuzhen Zhang, Minh Ngoc Dinh

This paper presents our proposed approach to the Discharge Me! shared task,
collocated with the 23th Workshop on Biomedical Natural Language Processing
(BioNLP). In this work, we develop an LLM-based framework for solving the
Discharge Summary Documentation (DSD) task, i.e., generating the two critical
target sections `Brief Hospital Course' and `Discharge Instructions' in the
discharge summary. By streamlining the recent instruction-finetuning process on
LLMs, we explore several prompting strategies for optimally adapting LLMs to
specific generation task of DSD. Experimental results show that providing a
clear output structure, complimented by a set of comprehensive
Chain-of-Thoughts (CoT) questions, effectively improves the model's reasoning
capability, and thereby, enhancing the structural correctness and faithfulness
of clinical information in the generated text. Source code is available at:
https://github.com/antangrocket1312/Discharge_LLM

摘要：本文介紹我們提出的「Discharge Me！」共享任務方法，與第 23 屆生物醫學自然語言處理工作坊 (BioNLP) 並列。在這項工作中，我們開發了一個基於 LLM 的架構，用於解決出院摘要文件 (DSD) 任務，也就是產生出院摘要中兩個重要的目標部分「簡要住院病程」和「出院指示」。透過簡化 LLM 上最近的指令微調流程，我們探討了多種提示策略，以最佳化調整 LLM 來執行 DSD 的特定生成任務。實驗結果顯示，提供明確的輸出結構，並搭配一組全面的思考鏈 (CoT) 問題，可以有效地提升模型的推理能力，進而增強所生成文字中臨床資訊的結構正確性和真實性。原始碼可在以下網址取得：https://github.com/antangrocket1312/Discharge_LLM

##### **Traditional Methods Outperform Generative LLMs at Forecasting Credit Ratings**
2407.17624v1 by Felix Drinkall, Janet B. Pierrehumbert, Stefan Zohren

Large Language Models (LLMs) have been shown to perform well for many
downstream tasks. Transfer learning can enable LLMs to acquire skills that were
not targeted during pre-training. In financial contexts, LLMs can sometimes
beat well-established benchmarks. This paper investigates how well LLMs perform
in the task of forecasting corporate credit ratings. We show that while LLMs
are very good at encoding textual information, traditional methods are still
very competitive when it comes to encoding numeric and multimodal data. For our
task, current LLMs perform worse than a more traditional XGBoost architecture
that combines fundamental and macroeconomic data with high-density text-based
embedding features.

摘要：大型語言模型 (LLM) 已被證明在許多下游任務中表現良好。轉移學習可以讓 LLM 習得在預訓練期間未設定為目標的技能。在金融背景下，LLM 有時可以超越既定的基準。本文探討 LLM 在預測公司信用評級任務中的表現。我們展示了儘管 LLM 在編碼文字資訊方面非常出色，但傳統方法在編碼數字和多模態資料方面仍非常有競爭力。對於我們的任務，當前 LLM 的表現比結合基本和巨觀經濟資料與高密度基於文字的嵌入特徵的更傳統的 XGBoost 架構差。

##### **CoMoTo: Unpaired Cross-Modal Lesion Distillation Improves Breast Lesion Detection in Tomosynthesis**
2407.17620v1 by Muhammad Alberb, Marawan Elbatel, Aya Elgebaly, Ricardo Montoya-del-Angel, Xiaomeng Li, Robert Martí

Digital Breast Tomosynthesis (DBT) is an advanced breast imaging modality
that offers superior lesion detection accuracy compared to conventional
mammography, albeit at the trade-off of longer reading time. Accelerating
lesion detection from DBT using deep learning is hindered by limited data
availability and huge annotation costs. A possible solution to this issue could
be to leverage the information provided by a more widely available modality,
such as mammography, to enhance DBT lesion detection. In this paper, we present
a novel framework, CoMoTo, for improving lesion detection in DBT. Our framework
leverages unpaired mammography data to enhance the training of a DBT model,
improving practicality by eliminating the need for mammography during
inference. Specifically, we propose two novel components, Lesion-specific
Knowledge Distillation (LsKD) and Intra-modal Point Alignment (ImPA). LsKD
selectively distills lesion features from a mammography teacher model to a DBT
student model, disregarding background features. ImPA further enriches LsKD by
ensuring the alignment of lesion features within the teacher before distilling
knowledge to the student. Our comprehensive evaluation shows that CoMoTo is
superior to traditional pretraining and image-level KD, improving performance
by 7% Mean Sensitivity under low-data setting. Our code is available at
https://github.com/Muhammad-Al-Barbary/CoMoTo .

摘要：數位乳房斷層合成 (DBT) 是一種進階乳房影像模式，
與傳統乳房攝影相比，它提供了優越的病灶偵測準確度，
儘管需要較長的判讀時間。加速
使用深度學習從 DBT 中偵測病灶受到資料
可用性有限和龐大標註成本的阻礙。解決此問題的一種可能方法是
利用更廣泛可用的模式（例如乳房攝影）所提供的資訊，
來增強 DBT 病灶偵測。在本文中，我們提出
一個新穎的架構 CoMoTo，用於改善 DBT 中的病灶偵測。我們的架構
利用未配對的乳房攝影資料來增強 DBT 模型的訓練，
透過消除推論期間對乳房攝影的需求來改善實用性。具體來說，我們提出兩個新穎的組成部分，病灶特定知識萃取 (LsKD) 和模內點對齊 (ImPA)。LsKD
有選擇性地從乳房攝影教師模型萃取出病灶特徵到 DBT
學生模型，忽略背景特徵。ImPA 進一步透過
確保教師內的病灶特徵在萃取出
知識到學生之前對齊，來豐富 LsKD。我們的全面評估顯示，CoMoTo 優於傳統的預訓練和影像層級 KD，在低資料設定下將效能提升 7% 的平均靈敏度。我們的程式碼可在 https://github.com/Muhammad-Al-Barbary/CoMoTo 取得。

##### **Coupling Speech Encoders with Downstream Text Models**
2407.17605v1 by Ciprian Chelba, Johan Schalkwyk

We present a modular approach to building cascade speech translation (AST)
models that guarantees that the resulting model performs no worse than the
1-best cascade baseline while preserving state-of-the-art speech recognition
(ASR) and text translation (MT) performance for a given task. Our novel
contribution is the use of an ``exporter'' layer that is trained under L2-loss
to ensure a strong match between ASR embeddings and the MT token embeddings for
the 1-best sequence. The ``exporter'' output embeddings are fed directly to the
MT model in lieu of 1-best token embeddings, thus guaranteeing that the
resulting model performs no worse than the 1-best cascade baseline, while
allowing back-propagation gradient to flow from the MT model into the ASR
components. The matched-embeddings cascade architecture provide a significant
improvement over its 1-best counterpart in scenarios where incremental training
of the MT model is not an option and yet we seek to improve quality by
leveraging (speech, transcription, translated transcription) data provided with
the AST task. The gain disappears when the MT model is incrementally trained on
the parallel text data available with the AST task. The approach holds promise
for other scenarios that seek to couple ASR encoders and immutable text models,
such at large language models (LLM).

摘要：我們提出了一個建構串聯語音翻譯 (AST) 模型的模組化方法，可確保產生的模型執行效能不遜於 1-best 串聯基準，同時保留最先進的語音辨識 (ASR) 和文字翻譯 (MT) 效能，以執行特定任務。我們的創新貢獻是使用一個在 L2 損失下訓練的「匯出層」，以確保 ASR 嵌入與 MT 代幣嵌入之間有強烈的匹配，以供 1-best 順序使用。將「匯出層」輸出嵌入直接提供給 MT 模型，以取代 1-best 代幣嵌入，從而確保產生的模型執行效能不遜於 1-best 串聯基準，同時允許反向傳播梯度從 MT 模型流入 ASR 組件。匹配嵌入串聯架構在其 1-best 對應架構中提供顯著的改進，在無法選擇 MT 模型增量訓練的情況下，我們仍尋求透過利用 AST 任務提供的（語音、轉錄、翻譯轉錄）資料來提升品質。當 MT 模型根據 AST 任務提供的平行文字資料進行增量訓練時，增益就會消失。這種方法對於尋求將 ASR 編碼器和不可變文字模型（例如大型語言模型 (LLM)）結合的其他場景很有前景。

##### **I Could've Asked That: Reformulating Unanswerable Questions**
2407.17469v1 by Wenting Zhao, Ge Gao, Claire Cardie, Alexander M. Rush

When seeking information from unfamiliar documents, users frequently pose
questions that cannot be answered by the documents. While existing large
language models (LLMs) identify these unanswerable questions, they do not
assist users in reformulating their questions, thereby reducing their overall
utility. We curate CouldAsk, an evaluation benchmark composed of existing and
new datasets for document-grounded question answering, specifically designed to
study reformulating unanswerable questions. We evaluate state-of-the-art
open-source and proprietary LLMs on CouldAsk. The results demonstrate the
limited capabilities of these models in reformulating questions. Specifically,
GPT-4 and Llama2-7B successfully reformulate questions only 26% and 12% of the
time, respectively. Error analysis shows that 62% of the unsuccessful
reformulations stem from the models merely rephrasing the questions or even
generating identical questions. We publicly release the benchmark and the code
to reproduce the experiments.

摘要：在從不熟悉的文檔中尋求資訊時，使用者經常會提出文檔無法回答的問題。雖然現有的大型語言模型 (LLM) 可以識別這些無法回答的問題，但它們並未協助使用者重新表述問題，因此降低了它們的整體效用。我們整理了 CouldAsk，這是一個評估基準，由現有和新的資料集組成，用於基於文檔的問答，特別設計用於研究重新表述無法回答的問題。我們在 CouldAsk 上評估了最先進的開源和專有 LLM。結果證明了這些模型在重新表述問題方面的能力有限。具體來說，GPT-4 和 Llama2-7B 分別僅在 26% 和 12% 的時間內成功重新表述問題。錯誤分析顯示，62% 的不成功重新表述源於模型僅僅重新表述問題，甚至產生相同的問題。我們公開發布基準和代碼以重現實驗。

##### **WildHallucinations: Evaluating Long-form Factuality in LLMs with Real-World Entity Queries**
2407.17468v1 by Wenting Zhao, Tanya Goyal, Yu Ying Chiu, Liwei Jiang, Benjamin Newman, Abhilasha Ravichander, Khyathi Chandu, Ronan Le Bras, Claire Cardie, Yuntian Deng, Yejin Choi

While hallucinations of large language models (LLMs) prevail as a major
challenge, existing evaluation benchmarks on factuality do not cover the
diverse domains of knowledge that the real-world users of LLMs seek information
about. To bridge this gap, we introduce WildHallucinations, a benchmark that
evaluates factuality. It does so by prompting LLMs to generate information
about entities mined from user-chatbot conversations in the wild. These
generations are then automatically fact-checked against a systematically
curated knowledge source collected from web search. Notably, half of these
real-world entities do not have associated Wikipedia pages. We evaluate 118,785
generations from 15 LLMs on 7,919 entities. We find that LLMs consistently
hallucinate more on entities without Wikipedia pages and exhibit varying
hallucination rates across different domains. Finally, given the same base
models, adding a retrieval component only slightly reduces hallucinations but
does not eliminate hallucinations.

摘要：儘管大型語言模型 (LLM) 的幻覺盛行，成為一項重大挑戰，但現有的關於事實性的評估基準並未涵蓋 LLM 的真實使用者尋求資訊的各種知識領域。為了彌補這個差距，我們引入了 WildHallucinations，這是一個評估事實性的基準。它透過提示 LLM 產生從野外使用者聊天機器人對話中提取的實體資訊來做到這一點。然後根據從網路搜尋收集的系統化策展知識來源，自動對這些生成進行事實查核。值得注意的是，這些真實世界實體中有一半沒有關聯的維基百科頁面。我們評估了 15 個 LLM 在 7,919 個實體上產生的 118,785 個生成。我們發現 LLM 持續對沒有維基百科頁面的實體產生更多幻覺，並在不同領域表現出不同的幻覺率。最後，在給定相同的基礎模型的情況下，加入檢索元件僅能稍微減少幻覺，但無法消除幻覺。

##### **CMR Scaling Law: Predicting Critical Mixture Ratios for Continual Pre-training of Language Models**
2407.17467v1 by Jiawei Gu, Zacc Yang, Chuanghao Ding, Rui Zhao, Fei Tan

Large Language Models (LLMs) excel in diverse tasks but often underperform in
specialized fields due to limited domain-specific or proprietary corpus.
Continual pre-training (CPT) enhances LLM capabilities by imbuing new
domain-specific or proprietary knowledge while replaying general corpus to
prevent catastrophic forgetting. The data mixture ratio of general corpus and
domain-specific corpus, however, has been chosen heuristically, leading to
sub-optimal training efficiency in practice. In this context, we attempt to
re-visit the scaling behavior of LLMs under the hood of CPT, and discover a
power-law relationship between loss, mixture ratio, and training tokens scale.
We formalize the trade-off between general and domain-specific capabilities,
leading to a well-defined Critical Mixture Ratio (CMR) of general and domain
data. By striking the balance, CMR maintains the model's general ability and
achieves the desired domain transfer, ensuring the highest utilization of
available resources. Therefore, if we value the balance between efficiency and
effectiveness, CMR can be consider as the optimal mixture ratio.Through
extensive experiments, we ascertain the predictability of CMR, and propose CMR
scaling law and have substantiated its generalization. These findings offer
practical guidelines for optimizing LLM training in specialized domains,
ensuring both general and domain-specific performance while efficiently
managing training resources.

摘要：大型語言模型 (LLM) 在各種任務中表現出色，但由於特定領域或專有語料庫有限，它們在專業領域的表現往往不佳。
持續預訓練 (CPT) 可透過導入新的特定領域或專有知識，同時重播一般語料庫來防止災難性遺忘，進而增強 LLM 的功能。然而，一般語料庫和特定領域語料庫的資料混合比例是根據經驗法則選擇的，導致實際訓練效率不佳。在此背景下，我們嘗試重新探討 LLM 在 CPT 引擎蓋下的擴充行為，並發現損失、混合比例和訓練代幣規模之間存在冪律關係。我們將一般功能和特定領域功能之間的權衡形式化，進而定義出一般資料和領域資料的明確臨界混合比例 (CMR)。CMR 在取得平衡後，可維持模型的一般能力並達成所需的領域轉移，確保對可用資源的最高利用率。因此，如果我們重視效率和效能之間的平衡，CMR 可以視為最佳混合比例。透過廣泛的實驗，我們確認了 CMR 的可預測性，並提出 CMR 擴充定律，並已證實其概括性。這些發現提供了實用的準則，用於最佳化特定領域的 LLM 訓練，同時確保一般和特定領域的效能，並有效管理訓練資源。

##### **Why Machines Can't Be Moral: Turing's Halting Problem and the Moral Limits of Artificial Intelligence**
2407.16890v1 by Massimo Passamonti

In this essay, I argue that explicit ethical machines, whose moral principles
are inferred through a bottom-up approach, are unable to replicate human-like
moral reasoning and cannot be considered moral agents. By utilizing Alan
Turing's theory of computation, I demonstrate that moral reasoning is
computationally intractable by these machines due to the halting problem. I
address the frontiers of machine ethics by formalizing moral problems into
'algorithmic moral questions' and by exploring moral psychology's dual-process
model. While the nature of Turing Machines theoretically allows artificial
agents to engage in recursive moral reasoning, critical limitations are
introduced by the halting problem, which states that it is impossible to
predict with certainty whether a computational process will halt. A thought
experiment involving a military drone illustrates this issue, showing that an
artificial agent might fail to decide between actions due to the halting
problem, which limits the agent's ability to make decisions in all instances,
undermining its moral agency.

摘要：在本文中，我主張通過自下而上方法推論出道德原則的明確道德機器，無法複製類人的道德推理，也不能被視為道德代理人。通過利用艾倫·圖靈的計算理論，我證明了由於停機問題，這些機器在計算上無法進行道德推理。我通過將道德問題形式化為「演算法道德問題」以及探索道德心理學的雙重過程模型，來探討機器倫理的邊界。雖然圖靈機的本質在理論上允許人工代理參與遞迴道德推理，但停機問題引入了關鍵限制，該問題指出不可能確定預測計算過程是否會停止。一個涉及軍事無人機的思想實驗說明了這個問題，表明人工代理可能會因為停機問題而無法在行動之間做出決定，這限制了代理人在所有情況下做出決定的能力，從而破壞了其道德代理。

##### **Exploring Domain Robust Lightweight Reward Models based on Router Mechanism**
2407.17546v1 by Hyuk Namgoong, Jeesu Jung, Sangkeun Jung, Yoonhyung Roh

Recent advancements in large language models have heavily relied on the large
reward model from reinforcement learning from human feedback for fine-tuning.
However, the use of a single reward model across various domains may not always
be optimal, often requiring retraining from scratch when new domain data is
introduced. To address these challenges, we explore the utilization of small
language models operating in a domain-specific manner based on router
mechanisms. Our three approaches are: 1) utilize mixture of experts to form a
single reward model by modularizing an internal router and experts, 2)
employing external router to select the appropriate reward model from multiple
domain-specific models, and 3) the framework reduces parameter size by loading
reward models and router adapters onto a single small language model using
adapters. Experimental validation underscores the effectiveness of our
approach, demonstrating performance comparable to baseline methods while also
reducing the total parameter size.

摘要：近期大型語言模型的進展高度仰賴強化學習中來自人類回饋的大型獎勵模型進行微調。然而，在不同領域中使用單一獎勵模型可能並不總是最佳的，在引入新的領域資料時，通常需要從頭開始重新訓練。為了應對這些挑戰，我們探索了基於路由機制的在特定領域運作的小型語言模型的利用。我們的三種方法是：1) 利用專家混合體通過模組化內部路由器和專家來形成單一獎勵模型，2) 使用外部路由器從多個特定領域模型中選擇適當的獎勵模型，以及 3) 該框架通過使用適配器將獎勵模型和路由器適配器載入到單一小型語言模型上來減少參數大小。實驗驗證強調了我們方法的有效性，展示了與基準方法相當的效能，同時也減少了總參數大小。

##### **Fluent Student-Teacher Redteaming**
2407.17447v1 by T. Ben Thompson, Michael Sklar

Many publicly available language models have been safety tuned to reduce the
likelihood of toxic or liability-inducing text. Users or security analysts
attempt to jailbreak or redteam these models with adversarial prompts which
cause compliance with requests. One attack method is to apply discrete
optimization techniques to the prompt. However, the resulting attack strings
are often gibberish text, easily filtered by defenders due to high measured
perplexity, and may fail for unseen tasks and/or well-tuned models. In this
work, we improve existing algorithms (primarily GCG and BEAST) to develop
powerful and fluent attacks on safety-tuned models like Llama-2 and Phi-3. Our
technique centers around a new distillation-based approach that encourages the
victim model to emulate a toxified finetune, either in terms of output
probabilities or internal activations. To encourage human-fluent attacks, we
add a multi-model perplexity penalty and a repetition penalty to the objective.
We also enhance optimizer strength by allowing token insertions, token swaps,
and token deletions and by using longer attack sequences. The resulting process
is able to reliably jailbreak the most difficult target models with prompts
that appear similar to human-written prompts. On Advbench we achieve attack
success rates $>93$% for Llama-2-7B, Llama-3-8B, and Vicuna-7B, while
maintaining model-measured perplexity $<33$; we achieve $95$% attack success
for Phi-3, though with higher perplexity. We also find a universally-optimized
single fluent prompt that induces $>88$% compliance on previously unseen tasks
across Llama-2-7B, Phi-3-mini and Vicuna-7B and transfers to other black-box
models.

摘要：許多公開可用的語言模型都經過安全性調整，以降低產生有毒或引發責任的文字的可能性。使用者或安全分析師嘗試使用對抗性提示來破解或對這些模型進行紅隊測試，這會導致符合請求。一種攻擊方法是對提示套用離散最佳化技術。然而，產生的攻擊字串通常是無意義的文字，由於測量到的困惑度高，很容易被防禦者過濾掉，並且可能無法執行未見過的工作和/或調整良好的模型。在這項工作中，我們改進了現有演算法（主要是 GCG 和 BEAST），以對 Llama-2 和 Phi-3 等安全性調整模型發動強大且流暢的攻擊。我們的技術圍繞一種新的基於蒸餾的方法，它鼓勵受害者模型模擬中毒的微調，無論是在輸出機率或內部激活方面。為了鼓勵人類流暢的攻擊，我們在目標中加入多模型困惑度懲罰和重複懲罰。我們還透過允許插入代碼、交換代碼和刪除代碼，以及使用較長的攻擊序列來增強最佳化器的強度。由此產生的程序能夠可靠地破解最困難的目標模型，其提示看起來類似於人類編寫的提示。在 Advbench 上，我們對 Llama-2-7B、Llama-3-8B 和 Vicuna-7B 達到了 $>93$% 的攻擊成功率，同時維持模型測量的困惑度 $<33$；我們對 Phi-3 達到了 $95$% 的攻擊成功率，儘管困惑度較高。我們還找到了經過通用最佳化的單一流暢提示，它可以在 Llama-2-7B、Phi-3-mini 和 Vicuna-7B 中以前所未見的工作上引發 $>88$% 的合規性，並傳輸到其他黑盒模型。

##### **HumanVid: Demystifying Training Data for Camera-controllable Human Image Animation**
2407.17438v1 by Zhenzhi Wang, Yixuan Li, Yanhong Zeng, Youqing Fang, Yuwei Guo, Wenran Liu, Jing Tan, Kai Chen, Tianfan Xue, Bo Dai, Dahua Lin

Human image animation involves generating videos from a character photo,
allowing user control and unlocking potential for video and movie production.
While recent approaches yield impressive results using high-quality training
data, the inaccessibility of these datasets hampers fair and transparent
benchmarking. Moreover, these approaches prioritize 2D human motion and
overlook the significance of camera motions in videos, leading to limited
control and unstable video generation.To demystify the training data, we
present HumanVid, the first large-scale high-quality dataset tailored for human
image animation, which combines crafted real-world and synthetic data. For the
real-world data, we compile a vast collection of copyright-free real-world
videos from the internet. Through a carefully designed rule-based filtering
strategy, we ensure the inclusion of high-quality videos, resulting in a
collection of 20K human-centric videos in 1080P resolution. Human and camera
motion annotation is accomplished using a 2D pose estimator and a SLAM-based
method. For the synthetic data, we gather 2,300 copyright-free 3D avatar assets
to augment existing available 3D assets. Notably, we introduce a rule-based
camera trajectory generation method, enabling the synthetic pipeline to
incorporate diverse and precise camera motion annotation, which can rarely be
found in real-world data. To verify the effectiveness of HumanVid, we establish
a baseline model named CamAnimate, short for Camera-controllable Human
Animation, that considers both human and camera motions as conditions. Through
extensive experimentation, we demonstrate that such simple baseline training on
our HumanVid achieves state-of-the-art performance in controlling both human
pose and camera motions, setting a new benchmark. Code and data will be
publicly available at \url{https://github.com/zhenzhiwang/HumanVid/}.

摘要：人類影像動畫涉及從角色照片產生影片，
讓使用者可以控制並解鎖影片和電影製作的潛力。
雖然最近的方法使用高品質訓練資料產生令人印象深刻的結果，
但這些資料集難以取得，阻礙了公平和透明的基準測試。
此外，這些方法優先考慮 2D 人類動作，
而忽略了影片中相機動作的重要性，導致控制受限且影片產生不穩定。
為了釐清訓練資料，我們提出 HumanVid，這是第一個針對人類影像動畫量身打造的大規模高品質資料集，
結合了精心製作的真實世界和合成資料。
對於真實世界資料，我們從網路上編制了大量免版權的真實世界影片。
透過精心設計的基於規則的過濾策略，我們確保納入高品質影片，
產生了 1080P 解析度的 20K 以人類為中心的影片集。
人類和相機動作註解是使用 2D 姿勢估計器和基於 SLAM 的方法完成的。
對於合成資料，我們收集了 2,300 個免版權的 3D 頭像資產來擴充現有的 3D 資產。
值得注意的是，我們引入了基於規則的相機軌跡產生方法，
使合成管線能夠納入多樣且精確的相機動作註解，這在真實世界資料中很少見。
為了驗證 HumanVid 的有效性，我們建立了一個名為 CamAnimate 的基準模型，簡稱 Camera-controllable Human Animation，
將人類和相機動作都視為條件。
透過廣泛的實驗，我們證明了在我們的 HumanVid 上進行這種簡單的基準訓練，
在控制人類姿勢和相機動作方面達到了最先進的效能，樹立了新的基準。
程式碼和資料將在 \url{https://github.com/zhenzhiwang/HumanVid/} 公開。

##### **(PASS) Visual Prompt Locates Good Structure Sparsity through a Recurrent HyperNetwork**
2407.17412v1 by Tianjin Huang, Fang Meng, Li Shen, Fan Liu, Yulong Pei, Mykola Pechenizkiy, Shiwei Liu, Tianlong Chen

Large-scale neural networks have demonstrated remarkable performance in
different domains like vision and language processing, although at the cost of
massive computation resources. As illustrated by compression literature,
structural model pruning is a prominent algorithm to encourage model
efficiency, thanks to its acceleration-friendly sparsity patterns. One of the
key questions of structural pruning is how to estimate the channel
significance. In parallel, work on data-centric AI has shown that
prompting-based techniques enable impressive generalization of large language
models across diverse downstream tasks. In this paper, we investigate a
charming possibility - \textit{leveraging visual prompts to capture the channel
importance and derive high-quality structural sparsity}. To this end, we
propose a novel algorithmic framework, namely \texttt{PASS}. It is a tailored
hyper-network to take both visual prompts and network weight statistics as
input, and output layer-wise channel sparsity in a recurrent manner. Such
designs consider the intrinsic channel dependency between layers. Comprehensive
experiments across multiple network architectures and six datasets demonstrate
the superiority of \texttt{PASS} in locating good structural sparsity. For
example, at the same FLOPs level, \texttt{PASS} subnetworks achieve $1\%\sim
3\%$ better accuracy on Food101 dataset; or with a similar performance of
$80\%$ accuracy, \texttt{PASS} subnetworks obtain $0.35\times$ more speedup
than the baselines.

摘要：大型神经網路在不同的領域，例如視覺和語言處理中，展現了非凡的效能，儘管是以大量的運算資源為代價。正如壓縮文獻所說明的，結構模型剪枝是一種突出的演算法，用於提升模型效率，這要歸功於其有利於加速的稀疏模式。結構剪枝的關鍵問題之一是如何估計通道重要性。與此同時，資料中心 AI 的研究表明，基於提示的技術能夠讓大型語言模型在各種下游任務中進行令人印象深刻的泛化。在本文中，我們探討了一個迷人的可能性——利用視覺提示來擷取通道重要性，並推導出高品質的結構稀疏性。為此，我們提出了一個新穎的演算法架構，即 \texttt{PASS}。它是一個量身打造的超網路，用於將視覺提示和網路權重統計資料作為輸入，並以遞迴方式輸出逐層通道稀疏性。此類設計考慮了層之間的內在通道依賴性。跨多個網路架構和六個資料集的綜合實驗證明了 \texttt{PASS} 在定位良好結構稀疏性方面的優越性。例如，在相同的 FLOP 層級，\texttt{PASS} 子網路在 Food101 資料集上達到了 $1\%\sim 3\%$ 的更佳準確度；或者在具有相似的 $80\%$ 準確度效能下，\texttt{PASS} 子網路比基準快了 $0.35\times$ 倍。

##### **Dependency Transformer Grammars: Integrating Dependency Structures into Transformer Language Models**
2407.17406v1 by Yida Zhao, Chao Lou, Kewei Tu

Syntactic Transformer language models aim to achieve better generalization
through simultaneously modeling syntax trees and sentences. While prior work
has been focusing on adding constituency-based structures to Transformers, we
introduce Dependency Transformer Grammars (DTGs), a new class of Transformer
language model with explicit dependency-based inductive bias. DTGs simulate
dependency transition systems with constrained attention patterns by modifying
attention masks, incorporate the stack information through relative positional
encoding, and augment dependency arc representation with a combination of token
embeddings and operation embeddings. When trained on a dataset of sentences
annotated with dependency trees, DTGs achieve better generalization while
maintaining comparable perplexity with Transformer language model baselines.
DTGs also outperform recent constituency-based models, showing that dependency
can better guide Transformer language models. Our code is released at
https://github.com/zhaoyd1/Dep_Transformer_Grammars.

摘要：句法轉換語言模型旨在透過同時對句法樹和句子進行建模來達成更好的概括。雖然先前的研究一直專注於在 Transformers 中加入基於成分的結構，但我們引入了依賴轉換語法 (DTG)，這是一種新的轉換語言模型類別，具有明確的基於依賴的歸納偏誤。DTG 模擬具有約束注意力模式的依賴轉換系統，透過修改注意力遮罩、透過相對位置編碼納入堆疊資訊，並結合標記嵌入和運算嵌入來擴充依賴弧表示。當在標記有依賴樹的句子資料集上進行訓練時，DTG 可在維持與轉換語言模型基準相當的困惑度的同時，達成更好的概括。DTG 也優於最近基於成分的模型，顯示依賴可以更好地引導轉換語言模型。我們的程式碼已在 https://github.com/zhaoyd1/Dep_Transformer_Grammars 發布。

##### **Grammar-based Game Description Generation using Large Language Models**
2407.17404v1 by Tsunehiko Tanaka, Edgar Simo-Serra

To lower the barriers to game design development, automated game design,
which generates game designs through computational processes, has been
explored. In automated game design, machine learning-based techniques such as
evolutionary algorithms have achieved success. Benefiting from the remarkable
advancements in deep learning, applications in computer vision and natural
language processing have progressed in level generation. However, due to the
limited amount of data in game design, the application of deep learning has
been insufficient for tasks such as game description generation. To pioneer a
new approach for handling limited data in automated game design, we focus on
the in-context learning of large language models (LLMs). LLMs can capture the
features of a task from a few demonstration examples and apply the capabilities
acquired during pre-training. We introduce the grammar of game descriptions,
which effectively structures the game design space, into the LLMs' reasoning
process. Grammar helps LLMs capture the characteristics of the complex task of
game description generation. Furthermore, we propose a decoding method that
iteratively improves the generated output by leveraging the grammar. Our
experiments demonstrate that this approach performs well in generating game
descriptions.

摘要：為了降低遊戲設計開發的門檻，自動化遊戲設計（透過運算程序產生遊戲設計）已經被廣泛探討。在自動化遊戲設計中，基於機器學習的技術（例如演化演算法）已取得成功。受益於深度學習的顯著進步，電腦視覺和自然語言處理的應用已在關卡生成方面取得進展。然而，由於遊戲設計中的數據量有限，深度學習的應用對於遊戲描述生成等任務來說還不足夠。為了在自動化遊戲設計中處理有限數據開創一種新方法，我們專注於大型語言模型 (LLM) 的語境學習。LLM 可以從少數示範範例中擷取任務的特徵，並應用預訓練期間習得的能力。我們將遊戲描述的語法（有效地建構遊戲設計空間）引入 LLM 的推理過程中。語法有助於 LLM 擷取遊戲描述生成這項複雜任務的特徵。此外，我們提出了一種解碼方法，透過利用語法反覆改善產生的輸出。我們的實驗證明，這種方法在產生遊戲描述方面表現良好。

##### **Large Language Models for Anomaly Detection in Computational Workflows: from Supervised Fine-Tuning to In-Context Learning**
2407.17545v1 by Hongwei Jin, George Papadimitriou, Krishnan Raghavan, Pawel Zuk, Prasanna Balaprakash, Cong Wang, Anirban Mandal, Ewa Deelman

Anomaly detection in computational workflows is critical for ensuring system
reliability and security. However, traditional rule-based methods struggle to
detect novel anomalies. This paper leverages large language models (LLMs) for
workflow anomaly detection by exploiting their ability to learn complex data
patterns. Two approaches are investigated: 1) supervised fine-tuning (SFT),
where pre-trained LLMs are fine-tuned on labeled data for sentence
classification to identify anomalies, and 2) in-context learning (ICL) where
prompts containing task descriptions and examples guide LLMs in few-shot
anomaly detection without fine-tuning. The paper evaluates the performance,
efficiency, generalization of SFT models, and explores zero-shot and few-shot
ICL prompts and interpretability enhancement via chain-of-thought prompting.
Experiments across multiple workflow datasets demonstrate the promising
potential of LLMs for effective anomaly detection in complex executions.

摘要：異常偵測在運算工作流程中至關重要，用於確保系統可靠性和安全性。然而，傳統的基於規則的方法難以偵測到新的異常。本文利用大型語言模型 (LLM) 進行工作流程異常偵測，方法是利用它們學習複雜資料模式的能力。研究了兩種方法：1) 監督微調 (SFT)，其中預先訓練的 LLM 在標籤資料上進行微調，用於句子分類以識別異常，以及 2) 上下文學習 (ICL)，其中包含任務描述和範例的提示在沒有微調的情況下引導 LLM 進行少次異常偵測。本文評估了 SFT 模型的效能、效率、泛化性，並探討了零次和少次 ICL 提示以及透過思考鏈提示增強可解釋性。跨多個工作流程資料集的實驗證明了 LLM 在複雜執行中進行有效異常偵測的潛力。

##### **Systematic Reasoning About Relational Domains With Graph Neural Networks**
2407.17396v1 by Irtaza Khalid, Steven Schockaert

Developing models that can learn to reason is a notoriously challenging
problem. We focus on reasoning in relational domains, where the use of Graph
Neural Networks (GNNs) seems like a natural choice. However, previous work on
reasoning with GNNs has shown that such models tend to fail when presented with
test examples that require longer inference chains than those seen during
training. This suggests that GNNs lack the ability to generalize from training
examples in a systematic way, which would fundamentally limit their reasoning
abilities. A common solution is to instead rely on neuro-symbolic methods,
which are capable of reasoning in a systematic way by design. Unfortunately,
the scalability of such methods is often limited and they tend to rely on
overly strong assumptions, e.g.\ that queries can be answered by inspecting a
single relational path. In this paper, we revisit the idea of reasoning with
GNNs, showing that systematic generalization is possible as long as the right
inductive bias is provided. In particular, we argue that node embeddings should
be treated as epistemic states and that GNN should be parameterised
accordingly. We propose a simple GNN architecture which is based on this view
and show that it is capable of achieving state-of-the-art results. We
furthermore introduce a benchmark which requires models to aggregate evidence
from multiple relational paths. We show that existing neuro-symbolic approaches
fail on this benchmark, whereas our considered GNN model learns to reason
accurately.

摘要：<paragraph>開發能學習推理的模型是出了名的困難問題。我們專注於關係領域中的推理，其中圖形神經網路 (GNN) 的使用似乎是一個自然選擇。然而，先前關於使用 GNN 推理的研究顯示，當提供比訓練期間所見更長推論鏈的測試範例時，此類模型往往會失敗。這表明 GNN 缺乏以系統方式從訓練範例中概化的能力，這從根本上限制了它們的推理能力。一個常見的解決方案是改而依賴神經符號方法，它在設計上能夠以系統方式進行推理。不幸的是，此類方法的可擴充性通常受到限制，而且它們往往依賴於過於強烈的假設，例如，查詢可以透過檢查單一關係路徑來回答。在本文中，我們重新探討使用 GNN 推理的想法，證明只要提供了正確的歸納偏誤，系統概化是可能的。特別是，我們主張節點嵌入應視為認識狀態，並且 GNN 應相應地參數化。我們提出了一個基於此觀點的簡單 GNN 架構，並表明它能夠實現最先進的結果。此外，我們還引入了需要模型從多個關係路徑匯總證據的基準。我們表明現有的神經符號方法在此基準上失敗，而我們考慮的 GNN 模型則學會準確推理。</paragraph>

##### **CovScore: Evaluation of Multi-Document Abstractive Title Set Generation**
2407.17390v1 by Itamar Trainin, Omri Abend

This paper introduces CovScore, an automatic reference-less methodology for
evaluating thematic title sets, extracted from a corpus of documents. While
such extraction methods are widely used, evaluating their effectiveness remains
an open question. Moreover, some existing practices heavily rely on slow and
laborious human annotation procedures. Inspired by recently introduced
LLM-based judge methods, we propose a novel methodology that decomposes quality
into five main metrics along different aspects of evaluation. This framing
simplifies and expedites the manual evaluation process and enables automatic
and independent LLM-based evaluation. As a test case, we apply our approach to
a corpus of Holocaust survivor testimonies, motivated both by its relevance to
title set extraction and by the moral significance of this pursuit. We validate
the methodology by experimenting with naturalistic and synthetic title set
generation systems and compare their performance with the methodology.

摘要：本文介紹 CovScore，這是一種自動無參考方法，用於評估從文件語料庫中提取的主題標題集。雖然此類提取方法被廣泛使用，但評估其有效性仍然是一個懸而未決的問題。此外，一些現有做法嚴重依賴於緩慢且費力的真人標註程序。受最近推出的基於 LLM 的評審方法的啟發，我們提出了一種新方法，將質量分解為五個主要指標，涵蓋評估的不同方面。此框架簡化並加快了手動評估過程，並實現了基於 LLM 的自動且獨立評估。作為一個測試案例，我們將我們的做法應用於大屠殺倖存者證詞語料庫，這既是因為它與標題集提取相關，也是因為這項追求的道德意義。我們通過對自然主義和合成標題集生成系統進行實驗來驗證該方法，並將其性能與該方法進行比較。

##### **PERSONA: A Reproducible Testbed for Pluralistic Alignment**
2407.17387v1 by Louis Castricato, Nathan Lile, Rafael Rafailov, Jan-Philipp Fränken, Chelsea Finn

The rapid advancement of language models (LMs) necessitates robust alignment
with diverse user values. However, current preference optimization approaches
often fail to capture the plurality of user opinions, instead reinforcing
majority viewpoints and marginalizing minority perspectives. We introduce
PERSONA, a reproducible test bed designed to evaluate and improve pluralistic
alignment of LMs. We procedurally generate diverse user profiles from US census
data, resulting in 1,586 synthetic personas with varied demographic and
idiosyncratic attributes. We then generate a large-scale evaluation dataset
containing 3,868 prompts and 317,200 feedback pairs obtained from our synthetic
personas. Leveraging this dataset, we systematically evaluate LM capabilities
in role-playing diverse users, verified through human judges, and the
establishment of both a benchmark, PERSONA Bench, for pluralistic alignment
approaches as well as an extensive dataset to create new and future benchmarks.
The full dataset and benchmarks are available here:
https://www.synthlabs.ai/research/persona.

摘要：語言模型 (LM) 的快速進步需要與多元的使用者價值觀進行穩健的對齊。然而，目前的偏好最佳化方法通常無法捕捉到使用者的意見多元性，反而強化了多數觀點，並將少數觀點邊緣化。我們引入了 PERSONA，一個可重製的測試平台，旨在評估和改善 LM 的多元對齊。我們根據美國人口普查資料程序化地產生了多樣化的使用者輪廓，產生了 1,586 個具有不同人口統計和特殊屬性的合成角色。然後，我們生成了包含 3,868 個提示和 317,200 個回饋配對的大規模評估資料集，這些配對來自我們的合成角色。利用此資料集，我們系統性地評估了 LM 在扮演不同使用者時的能力，並透過人工評審員驗證，以及建立了一個基準，PERSONA Bench，用於多元對齊方法，以及一個廣泛的資料集來建立新的和未來的基準。完整的資料集和基準可在此處取得：
https://www.synthlabs.ai/research/persona。

##### **A Comprehensive Approach to Misspelling Correction with BERT and Levenshtein Distance**
2407.17383v1 by Amirreza Naziri, Hossein Zeinali

Writing, as an omnipresent form of human communication, permeates nearly
every aspect of contemporary life. Consequently, inaccuracies or errors in
written communication can lead to profound consequences, ranging from financial
losses to potentially life-threatening situations. Spelling mistakes, among the
most prevalent writing errors, are frequently encountered due to various
factors. This research aims to identify and rectify diverse spelling errors in
text using neural networks, specifically leveraging the Bidirectional Encoder
Representations from Transformers (BERT) masked language model. To achieve this
goal, we compiled a comprehensive dataset encompassing both non-real-word and
real-word errors after categorizing different types of spelling mistakes.
Subsequently, multiple pre-trained BERT models were employed. To ensure optimal
performance in correcting misspelling errors, we propose a combined approach
utilizing the BERT masked language model and Levenshtein distance. The results
from our evaluation data demonstrate that the system presented herein exhibits
remarkable capabilities in identifying and rectifying spelling mistakes, often
surpassing existing systems tailored for the Persian language.

摘要：身為人類溝通中無所不在的一種形式，寫作滲透於當代生活的幾乎每個面向。因此，書面溝通中的不準確或錯誤可能導致深遠的後果，從財務損失到潛在危及生命的狀況。拼寫錯誤是最常見的寫作錯誤之一，由於各種因素而經常發生。本研究旨在使用神經網路識別和糾正文字中的各種拼寫錯誤，特別是利用來自 Transformer（BERT）的雙向編碼器表示法遮罩語言模型。為了實現這個目標，我們編制了一個全面的資料集，在對不同類型的拼寫錯誤進行分類後，包含非真實字詞和真實字詞的錯誤。隨後，採用了多個預訓練的 BERT 模型。為了確保在糾正拼寫錯誤方面獲得最佳效能，我們提出了一種結合 BERT 遮罩語言模型和 Levenshtein 距離的綜合方法。我們評估資料的結果表明，本文提出的系統在識別和糾正拼寫錯誤方面表現出顯著的能力，通常優於針對波斯語量身打造的現有系統。

##### **MMRA: A Benchmark for Multi-granularity Multi-image Relational Association**
2407.17379v1 by Siwei Wu, Kang Zhu, Yu Bai, Yiming Liang, Yizhi Li, Haoning Wu, Jiaheng Liu, Ruibo Liu, Xingwei Qu, Xuxin Cheng, Ge Zhang, Wenhao Huang, Chenghua Lin

Given the remarkable success that large visual language models (LVLMs) have
achieved in image perception tasks, the endeavor to make LVMLs perceive the
world like humans is drawing increasing attention. Current multi-modal
benchmarks mainly focus on the objective fact or certain topic related
potential knowledge within a image, but overlook the associative relations
between multiple images. Therefore, we define a multi-image relation
association task, and meticulously curate \textbf{MMRA} benchmark, a
\textbf{M}ulti-granularity \textbf{M}ulti-image \textbf{R}elational
\textbf{A}ssociation benchmark, consisted of \textbf{1026} samples. In order to
systematically and comprehensively evaluate mainstream LVLMs, we establish an
associational relation system among images that contain \textbf{11 subtasks}
(e.g, UsageSimilarity, SubEvent, etc.) at two granularity levels (i.e.,
"\textbf{image}" and "\textbf{entity}") according to the relations in
ConceptNet. Our experiments demonstrate that, on our MMRA benchmark, current
mainstream LVLMs all have their own advantages and disadvantages across
different subtasks. It is worth noting that, at the entity level, the
performance of all models is worse than that of them at the image level,
indicating that the fine-grained multi-image perception task is still
challenging for LVLMs. The tasks related to spatial perception are relatively
difficult for LVLMs to handle. Furthermore, we find that LVMLs exhibit a good
ability to perceive image details, and the key to enhancing their multi-image
association capability is to strengthen the reasoning ability of their language
model component. All our codes and data are released at
htt\url{https://github.com/Wusiwei0410/MMRA}.

摘要：<paragraph>鉴于大型视觉语言模型 (LVLMs) 在图像感知任务中取得的显著成功，让 LVML 像人类一样感知世界的努力正引起越来越多的关注。当前的多模态基准主要关注图像中的客观事实或与特定主题相关的潜在知识，但忽略了多幅图像之间的关联关系。因此，我们定义了一个多图像关系关联任务，并精心策划了\textbf{MMRA}基准，这是一个\textbf{M}ulti-granularity \textbf{M}ulti-image \textbf{R}elational \textbf{A}ssociation基准，由\textbf{1026}个样本组成。为了系统全面地评估主流 LVLMs，我们根据 ConceptNet 中的关系，在包含\textbf{11 个子任务}(例如 UsageSimilarity、SubEvent 等)的图像中建立了一个关联关系系统，该系统具有两个粒度级别(即“\textbf{图像}”和“\textbf{实体}”)。我们的实验表明，在我们的 MMRA 基准上，当前的主流 LVLMs 在不同的子任务中都有各自的优势和劣势。值得注意的是，在实体层面上，所有模型的性能都比它们在图像层面的性能差，这表明细粒度多图像感知任务对于 LVLMs 仍然具有挑战性。与空间感知相关的任务对于 LVLMs 来说相对难以处理。此外，我们发现 LVMLs 表现出良好的感知图像细节的能力，增强其多图像关联能力的关键在于加强其语言模型组件的推理能力。我们所有的代码和数据都可以在htt\url{https://github.com/Wusiwei0410/MMRA}发布。</paragraph>

##### **MathViz-E: A Case-study in Domain-Specialized Tool-Using Agents**
2407.17544v1 by Arya Bulusu, Brandon Man, Ashish Jagmohan, Aditya Vempaty, Jennifer Mari-Wyka, Deepak Akkil

There has been significant recent interest in harnessing LLMs to control
software systems through multi-step reasoning, planning and tool-usage. While
some promising results have been obtained, application to specific domains
raises several general issues including the control of specialized domain
tools, the lack of existing datasets for training and evaluation, and the
non-triviality of automated system evaluation and improvement. In this paper,
we present a case-study where we examine these issues in the context of a
specific domain. Specifically, we present an automated math visualizer and
solver system for mathematical pedagogy. The system orchestrates mathematical
solvers and math graphing tools to produce accurate visualizations from simple
natural language commands. We describe the creation of specialized data-sets,
and also develop an auto-evaluator to easily evaluate the outputs of our system
by comparing them to ground-truth expressions. We have open sourced the
data-sets and code for the proposed system.

摘要：最近，人们对利用大型语言模型 (LLM) 来通过多步骤推理、规划和工具使用来控制软件系统产生了极大的兴趣。虽然已经取得了一些有希望的结果，但应用于特定领域会引发几个普遍性问题，包括对专业领域工具的控制、缺乏用于训练和评估的现有数据集，以及自动化系统评估和改进的非平凡性。在本文中，我们提出了一个案例研究，其中我们研究了特定领域背景下的这些问题。具体来说，我们展示了一个用于数学教育的自动化数学可视化器和求解器系统。该系统协调数学求解器和数学绘图工具，以根据简单的自然语言命令生成准确的可视化效果。我们描述了专门数据集的创建，还开发了一个自动评估器，通过将我们的系统输出与真实表达式进行比较，轻松评估其输出。我们已经开源了所提议系统的代码和数据集。

##### **Dataset Distribution Impacts Model Fairness: Single vs. Multi-Task Learning**
2407.17543v1 by Ralf Raumanns, Gerard Schouten, Josien P. W. Pluim, Veronika Cheplygina

The influence of bias in datasets on the fairness of model predictions is a
topic of ongoing research in various fields. We evaluate the performance of
skin lesion classification using ResNet-based CNNs, focusing on patient sex
variations in training data and three different learning strategies. We present
a linear programming method for generating datasets with varying patient sex
and class labels, taking into account the correlations between these variables.
We evaluated the model performance using three different learning strategies: a
single-task model, a reinforcing multi-task model, and an adversarial learning
scheme. Our observations include: 1) sex-specific training data yields better
results, 2) single-task models exhibit sex bias, 3) the reinforcement approach
does not remove sex bias, 4) the adversarial model eliminates sex bias in cases
involving only female patients, and 5) datasets that include male patients
enhance model performance for the male subgroup, even when female patients are
the majority. To generalise these findings, in future research, we will examine
more demographic attributes, like age, and other possibly confounding factors,
such as skin colour and artefacts in the skin lesions. We make all data and
models available on GitHub.

摘要：在各種領域中，資料集中偏誤對模型預測公平性的影響是一項持續的研究主題。我們評估了使用基於 ResNet 的 CNN 進行皮膚病灶分類的效能，重點關注訓練資料中的患者性別差異和三種不同的學習策略。我們提出了一種線性規劃方法，用於生成具有不同患者性別和類別標籤的資料集，同時考慮這些變數之間的相關性。我們使用三種不同的學習策略評估了模型效能：單任務模型、強化多任務模型和對抗式學習方案。我們的觀察結果包括：1) 特定性別的訓練資料產生了更好的結果，2) 單任務模型表現出性別偏見，3) 強化方法並沒有消除性別偏見，4) 對抗模型消除了僅涉及女性患者的情況中的性別偏見，以及 5) 包含男性患者的資料集增強了男性子群的模型效能，即使女性患者佔多數。為了概括這些發現，在未來的研究中，我們將檢查更多的人口屬性，例如年齡，以及其他可能的混淆因素，例如皮膚顏色和皮膚病灶中的人工製品。我們將所有資料和模型都放在 GitHub 上。

##### **Boosting Large Language Models with Socratic Method for Conversational Mathematics Teaching**
2407.17349v1 by Yuyang Ding, Hanglei Hu, Jie Zhou, Qin Chen, Bo Jiang, Liang He

With the introduction of large language models (LLMs), automatic math
reasoning has seen tremendous success. However, current methods primarily focus
on providing solutions or using techniques like Chain-of-Thought to enhance
problem-solving accuracy. In this paper, we focus on improving the capability
of mathematics teaching via a Socratic teaching-based LLM
(\texttt{SocraticLLM}), which guides learners toward profound thinking with
clarity and self-discovery via conversation. We collect and release a
high-quality mathematical teaching dataset, named \texttt{SocraticMATH}, which
provides Socratic-style conversations of problems with extra knowledge. Also,
we propose a knowledge-enhanced LLM as a strong baseline to generate reliable
responses with review, guidance/heuristic, rectification, and summarization.
Experimental results show the great advantages of \texttt{SocraticLLM} by
comparing it with several strong generative models. The codes and datasets are
available on \url{https://github.com/ECNU-ICALK/SocraticMath}.

摘要：隨著大型語言模型 (LLM) 的導入，自動數學
推理取得了巨大的成功。然而，目前的方法主要專注於提供解決方案或使用思想鏈等技術來提高
問題解決的準確性。在本文中，我們專注於透過蘇格拉底教學為基礎的 LLM (\texttt{SocraticLLM}) 來提升數學教學能力，它透過對話引導學習者進行深入思考，並透過自我發現獲得清晰度。我們收集並發布一個高品質的數學教學資料集，名為 \texttt{SocraticMATH}，它提供了問題的蘇格拉底式對話以及額外的知識。此外，我們提出一個知識增強的 LLM 作為一個強大的基準，以產生可靠的回應，並提供回顧、指導/啟發式、修正和總結。實驗結果顯示了 \texttt{SocraticLLM} 的巨大優勢，並將其與幾個強大的生成模型進行比較。程式碼和資料集可在 \url{https://github.com/ECNU-ICALK/SocraticMath} 上取得。

