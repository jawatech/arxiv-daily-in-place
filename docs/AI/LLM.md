
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-29**|**Dialogue is Better Than Monologue: Instructing Medical LLMs via Strategical Conversations**|Zijie Liu et.al.|[2501.17860v1](http://arxiv.org/abs/2501.17860v1)|null|
|**2025-01-29**|**Improving Your Model Ranking on Chatbot Arena by Vote Rigging**|Rui Min et.al.|[2501.17858v1](http://arxiv.org/abs/2501.17858v1)|[link](https://github.com/sail-sg/rigging-chatbotarena)|
|**2025-01-29**|**GRACE: Generalizing Robot-Assisted Caregiving with User Functionality Embeddings**|Ziang Liu et.al.|[2501.17855v1](http://arxiv.org/abs/2501.17855v1)|null|
|**2025-01-29**|**From Sparse to Dense: Toddler-inspired Reward Transition in Goal-Oriented Reinforcement Learning**|Junseok Park et.al.|[2501.17842v1](http://arxiv.org/abs/2501.17842v1)|null|
|**2025-01-29**|**Learning Beyond the Surface: How Far Can Continual Pre-Training with LoRA Enhance LLMs' Domain-Specific Insight Learning?**|Pouya Pezeshkpour et.al.|[2501.17840v1](http://arxiv.org/abs/2501.17840v1)|[link](https://github.com/megagonlabs/insight_miner)|
|**2025-01-29**|**A Comprehensive Survey on Legal Summarization: Challenges and Future Directions**|Mousumi Akter et.al.|[2501.17830v1](http://arxiv.org/abs/2501.17830v1)|null|
|**2025-01-29**|**U2A: Unified Unimodal Adaptation for Robust and Efficient Multimodal Learning**|Md Kaykobad Reza et.al.|[2501.17823v1](http://arxiv.org/abs/2501.17823v1)|null|
|**2025-01-29**|**Aggregation Schemes for Single-Vector WSI Representation Learning in Digital Pathology**|Sobhan Hemati et.al.|[2501.17822v1](http://arxiv.org/abs/2501.17822v1)|null|
|**2025-01-29**|**P-TAME: Explain Any Image Classifier with Trained Perturbations**|Mariano V. Ntrougkas et.al.|[2501.17813v1](http://arxiv.org/abs/2501.17813v1)|null|
|**2025-01-29**|**Janus-Pro: Unified Multimodal Understanding and Generation with Data and Model Scaling**|Xiaokang Chen et.al.|[2501.17811v1](http://arxiv.org/abs/2501.17811v1)|[link](https://github.com/deepseek-ai/janus)|
|**2025-01-29**|**BreezyVoice: Adapting TTS for Taiwanese Mandarin with Enhanced Polyphone Disambiguation -- Challenges and Insights**|Chan-Jan Hsu et.al.|[2501.17790v1](http://arxiv.org/abs/2501.17790v1)|null|
|**2025-01-29**|**Reasoning Over the Glyphs: Evaluation of LLM's Decipherment of Rare Scripts**|Yu-Fei Shih et.al.|[2501.17785v1](http://arxiv.org/abs/2501.17785v1)|null|
|**2025-01-29**|**2SSP: A Two-Stage Framework for Structured Pruning of LLMs**|Fabrizio Sandri et.al.|[2501.17771v1](http://arxiv.org/abs/2501.17771v1)|null|
|**2025-01-29**|**Hybrid Graphs for Table-and-Text based Question Answering using LLMs**|Ankush Agarwal et.al.|[2501.17767v1](http://arxiv.org/abs/2501.17767v1)|null|
|**2025-01-29**|**Yin-Yang: Developing Motifs With Long-Term Structure And Controllability**|Keshav Bhandari et.al.|[2501.17759v1](http://arxiv.org/abs/2501.17759v1)|[link](https://github.com/keshavbhandari/yinyang)|
|**2025-01-29**|**Early External Safety Testing of OpenAI's o3-mini: Insights from the Pre-Deployment Evaluation**|Aitor Arrieta et.al.|[2501.17749v1](http://arxiv.org/abs/2501.17749v1)|null|
|**2025-01-29**|**Exact characterization of ε-Safe Decision Regions for exponential family distributions and Multi Cost SVM approximation**|Alberto Carlevaro et.al.|[2501.17731v1](http://arxiv.org/abs/2501.17731v1)|null|
|**2025-01-29**|**VICCA: Visual Interpretation and Comprehension of Chest X-ray Anomalies in Generated Report Without Human Feedback**|Sayeh Gholipour Picha et.al.|[2501.17726v1](http://arxiv.org/abs/2501.17726v1)|null|
|**2025-01-29**|**Using Code Generation to Solve Open Instances of Combinatorial Design Problems**|Christopher D. Rosin et.al.|[2501.17725v1](http://arxiv.org/abs/2501.17725v1)|[link](https://github.com/constructive-codes/cpro1)|
|**2025-01-29**|**RICoTA: Red-teaming of In-the-wild Conversation with Test Attempts**|Eujeong Choi et.al.|[2501.17715v1](http://arxiv.org/abs/2501.17715v1)|[link](https://github.com/boychaboy/ricota)|
|**2025-01-29**|**Inferring Implicit Goals Across Differing Task Models**|Silvia Tulli et.al.|[2501.17704v1](http://arxiv.org/abs/2501.17704v1)|null|
|**2025-01-29**|**Critique Fine-Tuning: Learning to Critique is More Effective than Learning to Imitate**|Yubo Wang et.al.|[2501.17703v1](http://arxiv.org/abs/2501.17703v1)|null|
|**2025-01-29**|**PulmoFusion: Advancing Pulmonary Health with Efficient Multi-Modal Fusion**|Ahmed Sharshar et.al.|[2501.17699v1](http://arxiv.org/abs/2501.17699v1)|[link](https://github.com/ahmed-sharshar/respirodynamics)|
|**2025-01-29**|**Segmentation-Aware Generative Reinforcement Network (GRN) for Tissue Layer Segmentation in 3-D Ultrasound Images for Chronic Low-back Pain (cLBP) Assessment**|Zixue Zeng et.al.|[2501.17690v1](http://arxiv.org/abs/2501.17690v1)|null|
|**2025-01-29**|**Planning with Vision-Language Models and a Use Case in Robot-Assisted Teaching**|Xuzhe Dang et.al.|[2501.17665v1](http://arxiv.org/abs/2501.17665v1)|null|
|**2025-01-29**|**Exploring Vision Language Models for Multimodal and Multilingual Stance Detection**|Jake Vasilakes et.al.|[2501.17654v1](http://arxiv.org/abs/2501.17654v1)|null|
|**2025-01-29**|**Tonguescape: Exploring Language Models Understanding of Vowel Articulation**|Haruki Sakajo et.al.|[2501.17643v1](http://arxiv.org/abs/2501.17643v1)|null|
|**2025-01-29**|**In-Context Meta LoRA Generation**|Yihua Shao et.al.|[2501.17635v1](http://arxiv.org/abs/2501.17635v1)|null|
|**2025-01-29**|**The Imitation Game According To Turing**|Sharon Temtsin et.al.|[2501.17629v1](http://arxiv.org/abs/2501.17629v1)|null|
|**2025-01-29**|**Uncertainty Quantification and Decomposition for LLM-based Recommendation**|Wonbin Kweon et.al.|[2501.17630v1](http://arxiv.org/abs/2501.17630v1)|[link](https://github.com/wonbinkweon/unc_llm_rec_www2025)|
|**2025-01-29**|**Structured Context Recomposition for Large Language Models Using Probabilistic Layer Realignment**|Jonathan Teel et.al.|[2501.17617v1](http://arxiv.org/abs/2501.17617v1)|null|
|**2025-01-29**|**Cross-lingual Embedding Clustering for Hierarchical Softmax in Low-Resource Multilingual Speech Recognition**|Zhengdong Yang et.al.|[2501.17615v1](http://arxiv.org/abs/2501.17615v1)|null|
|**2025-01-29**|**VoicePrompter: Robust Zero-Shot Voice Conversion with Voice Prompt and Conditional Flow Matching**|Ha-Yeong Choi et.al.|[2501.17612v1](http://arxiv.org/abs/2501.17612v1)|null|
|**2025-01-29**|**Semantic Consistency Regularization with Large Language Models for Semi-supervised Sentiment Analysis**|Kunrong Li et.al.|[2501.17598v1](http://arxiv.org/abs/2501.17598v1)|null|
|**2025-01-29**|**GLLM: Self-Corrective G-Code Generation using Large Language Models with User Feedback**|Mohamed Abdelaal et.al.|[2501.17584v1](http://arxiv.org/abs/2501.17584v1)|null|
|**2025-01-29**|**CSEval: Towards Automated, Multi-Dimensional, and Reference-Free Counterspeech Evaluation using Auto-Calibrated LLMs**|Amey Hengle et.al.|[2501.17581v1](http://arxiv.org/abs/2501.17581v1)|null|
|**2025-01-29**|**Music2Latent2: Audio Compression with Summary Embeddings and Autoregressive Decoding**|Marco Pasini et.al.|[2501.17578v1](http://arxiv.org/abs/2501.17578v1)|null|
|**2025-01-29**|**A linguistically-motivated evaluation methodology for unraveling model's abilities in reading comprehension tasks**|Elie Antoine et.al.|[2501.17569v1](http://arxiv.org/abs/2501.17569v1)|null|
|**2025-01-29**|**Exploring the Potential of Wireless-enabled Multi-Chip AI Accelerators**|Emmanuel Irabor et.al.|[2501.17567v1](http://arxiv.org/abs/2501.17567v1)|null|
|**2025-01-29**|**Solving Urban Network Security Games: Learning Platform, Benchmark, and Challenge for AI Research**|Shuxin Zhuang et.al.|[2501.17559v1](http://arxiv.org/abs/2501.17559v1)|null|
|**2025-01-29**|**An Exceptional Dataset For Rare Pancreatic Tumor Segmentation**|Wenqi Li et.al.|[2501.17555v1](http://arxiv.org/abs/2501.17555v1)|null|
|**2025-01-29**|**Query-Aware Learnable Graph Pooling Tokens as Prompt for Large Language Models**|Wooyoung Kim et.al.|[2501.17549v1](http://arxiv.org/abs/2501.17549v1)|null|
|**2025-01-29**|**Is Conversational XAI All You Need? Human-AI Decision Making With a Conversational XAI Assistant**|Gaole He et.al.|[2501.17546v1](http://arxiv.org/abs/2501.17546v1)|[link](https://github.com/delftcrowd/iui2025_convxai)|
|**2025-01-29**|**LLM Assistance for Pediatric Depression**|Mariia Ignashina et.al.|[2501.17510v1](http://arxiv.org/abs/2501.17510v1)|null|
|**2025-01-29**|**Neural Spelling: A Spell-Based BCI System for Language Neural Decoding**|Xiaowei Jiang et.al.|[2501.17489v1](http://arxiv.org/abs/2501.17489v1)|null|
|**2025-01-29**|**DINT Transformer**|Yueyang Cang et.al.|[2501.17486v1](http://arxiv.org/abs/2501.17486v1)|null|
|**2025-01-29**|**DFPE: A Diverse Fingerprint Ensemble for Enhancing LLM Performance**|Seffi Cohen et.al.|[2501.17479v1](http://arxiv.org/abs/2501.17479v1)|[link](https://github.com/nivgold/dfpe)|
|**2025-01-29**|**Large Language Models for Single-Step and Multi-Step Flight Trajectory Prediction**|Kaiwei Luo et.al.|[2501.17459v1](http://arxiv.org/abs/2501.17459v1)|null|
|**2025-01-29**|**Cross-Language Approach for Quranic QA**|Islam Oshallah et.al.|[2501.17449v1](http://arxiv.org/abs/2501.17449v1)|null|
|**2025-01-29**|**Towards Making Flowchart Images Machine Interpretable**|Shreya Shukla et.al.|[2501.17441v1](http://arxiv.org/abs/2501.17441v1)|null|
|**2025-01-29**|**Virus: Harmful Fine-tuning Attack for Large Language Models Bypassing Guardrail Moderation**|Tiansheng Huang et.al.|[2501.17433v1](http://arxiv.org/abs/2501.17433v1)|[link](https://github.com/git-disl/virus)|
|**2025-01-29**|**Algorithmic Segmentation and Behavioral Profiling for Ransomware Detection Using Temporal-Correlation Graphs**|Ignatius Rollere et.al.|[2501.17429v1](http://arxiv.org/abs/2501.17429v1)|null|
|**2025-01-29**|**Actions Speak Louder than Words: Agent Decisions Reveal Implicit Biases in Language Models**|Yuxuan Li et.al.|[2501.17420v1](http://arxiv.org/abs/2501.17420v1)|null|
|**2025-01-29**|**Reqo: A Robust and Explainable Query Optimization Cost Model**|Baoming Chang et.al.|[2501.17414v1](http://arxiv.org/abs/2501.17414v1)|[link](https://github.com/baomingchang/reqo-on-postgresql)|
|**2025-01-29**|**A Genetic Algorithm-Based Approach for Automated Optimization of Kolmogorov-Arnold Networks in Classification Tasks**|Quan Long et.al.|[2501.17411v1](http://arxiv.org/abs/2501.17411v1)|null|
|**2025-01-29**|**General Scene Adaptation for Vision-and-Language Navigation**|Haodong Hong et.al.|[2501.17403v1](http://arxiv.org/abs/2501.17403v1)|[link](https://github.com/honghd16/gsa-vln)|
|**2025-01-29**|**MultiChallenge: A Realistic Multi-Turn Conversation Evaluation Benchmark Challenging to Frontier LLMs**|Ved Sirdeshmukh et.al.|[2501.17399v1](http://arxiv.org/abs/2501.17399v1)|[link](https://github.com/ekwinox117/multi-challenge)|
|**2025-01-29**|**Leveraging In-Context Learning and Retrieval-Augmented Generation for Automatic Question Generation in Educational Domains**|Subhankar Maity et.al.|[2501.17397v1](http://arxiv.org/abs/2501.17397v1)|null|
|**2025-01-29**|**Learning Free Token Reduction for Multi-Modal LLM**|Zihui Zhao et.al.|[2501.17391v1](http://arxiv.org/abs/2501.17391v1)|null|
|**2025-01-29**|**Context-Aware Semantic Recomposition Mechanism for Large Language Models**|Richard Katrix et.al.|[2501.17386v1](http://arxiv.org/abs/2501.17386v1)|null|
|**2025-01-29**|**A Dual-Agent Adversarial Framework for Robust Generalization in Deep Reinforcement Learning**|Zhengpeng Xie et.al.|[2501.17384v1](http://arxiv.org/abs/2501.17384v1)|null|
|**2025-01-29**|**Forecasting S&P 500 Using LSTM Models**|Prashant Pilla et.al.|[2501.17366v1](http://arxiv.org/abs/2501.17366v1)|null|
|**2025-01-29**|**The M-factor: A Novel Metric for Evaluating Neural Architecture Search in Resource-Constrained Environments**|Srikanth Thudumu et.al.|[2501.17361v1](http://arxiv.org/abs/2501.17361v1)|null|
|**2025-01-29**|**On the Coexistence and Ensembling of Watermarks**|Aleksandar Petrov et.al.|[2501.17356v1](http://arxiv.org/abs/2501.17356v1)|null|
|**2025-01-28**|**Better Slow than Sorry: Introducing Positive Friction for Reliable Dialogue Systems**|Mert İnan et.al.|[2501.17348v1](http://arxiv.org/abs/2501.17348v1)|null|
|**2025-01-28**|**Deep-and-Wide Learning: Enhancing Data-Driven Inference via Synergistic Learning of Inter- and Intra-Data Representations**|Md Tauhidul Islam et.al.|[2501.17347v1](http://arxiv.org/abs/2501.17347v1)|null|
|**2025-01-28**|**Post-Training Quantization for 3D Medical Image Segmentation: A Practical Study on Real Inference Engines**|Chongyu Qu et.al.|[2501.17343v1](http://arxiv.org/abs/2501.17343v1)|null|
|**2025-01-28**|**Inferring from Logits: Exploring Best Practices for Decoding-Free Generative Candidate Selection**|Mingyu Derek Ma et.al.|[2501.17338v1](http://arxiv.org/abs/2501.17338v1)|null|
|**2025-01-28**|**Attribution analysis of legal language as used by LLM**|Richard K. Belew et.al.|[2501.17330v1](http://arxiv.org/abs/2501.17330v1)|null|
|**2025-01-28**|**Memorize and Rank: Elevating Large Language Models for Clinical Diagnosis Prediction**|Mingyu Derek Ma et.al.|[2501.17326v1](http://arxiv.org/abs/2501.17326v1)|null|
|**2025-01-28**|**A sketch of an AI control safety case**|Tomek Korbak et.al.|[2501.17315v1](http://arxiv.org/abs/2501.17315v1)|null|
|**2025-01-28**|**Probing LLM World Models: Enhancing Guesstimation with Wisdom of Crowds Decoding**|Yun-Shiuan Chuang et.al.|[2501.17310v1](http://arxiv.org/abs/2501.17310v1)|null|
|**2025-01-28**|**"Ownership, Not Just Happy Talk": Co-Designing a Participatory Large Language Model for Journalism**|Emily Tseng et.al.|[2501.17299v1](http://arxiv.org/abs/2501.17299v1)|null|
|**2025-01-28**|**Multi-Physics Simulations via Coupled Fourier Neural Operator**|Shibo Li et.al.|[2501.17296v1](http://arxiv.org/abs/2501.17296v1)|null|
|**2025-01-28**|**Mitigating Hallucinated Translations in Large Language Models with Hallucination-focused Preference Optimization**|Zilu Tang et.al.|[2501.17295v1](http://arxiv.org/abs/2501.17295v1)|null|
|**2025-01-28**|**Fine-Tuning Open-Source Large Language Models to Improve Their Performance on Radiation Oncology Tasks: A Feasibility Study to Investigate Their Potential Clinical Applications in Radiation Oncology**|Peilong Wang et.al.|[2501.17286v1](http://arxiv.org/abs/2501.17286v1)|null|
|**2025-01-28**|**From Natural Language to Extensive-Form Game Representations**|Shilong Deng et.al.|[2501.17282v1](http://arxiv.org/abs/2501.17282v1)|[link](https://github.com/zczlsde/gameinterpreter)|
|**2025-01-28**|**Tailored Truths: Optimizing LLM Persuasion with Personalization and Fabricated Statistics**|Jasper Timm et.al.|[2501.17273v1](http://arxiv.org/abs/2501.17273v1)|null|
|**2025-01-28**|**Comprehensive Evaluation for a Large Scale Knowledge Graph Question Answering Service**|Saloni Potdar et.al.|[2501.17270v1](http://arxiv.org/abs/2501.17270v1)|null|
|**2025-01-28**|**Giving the Old a Fresh Spin: Quality Estimation-Assisted Constrained Decoding for Automatic Post-Editing**|Sourabh Deoghare et.al.|[2501.17265v1](http://arxiv.org/abs/2501.17265v1)|null|
|**2025-01-28**|**SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training**|Tianzhe Chu et.al.|[2501.17161v1](http://arxiv.org/abs/2501.17161v1)|null|
|**2025-01-28**|**A Hybrid Deep Learning CNN Model for Enhanced COVID-19 Detection from Computed Tomography (CT) Scan Images**|Suresh Babu Nettur et.al.|[2501.17160v1](http://arxiv.org/abs/2501.17160v1)|null|
|**2025-01-28**|**Three-Dimensional Diffusion-Weighted Multi-Slab MRI With Slice Profile Compensation Using Deep Energy Model**|Reza Ghorbani et.al.|[2501.17152v1](http://arxiv.org/abs/2501.17152v1)|null|
|**2025-01-28**|**AxBench: Steering LLMs? Even Simple Baselines Outperform Sparse Autoencoders**|Zhengxuan Wu et.al.|[2501.17148v2](http://arxiv.org/abs/2501.17148v2)|null|
|**2025-01-28**|**FactCG: Enhancing Fact Checkers with Graph-Based Multi-Hop Data**|Deren Lei et.al.|[2501.17144v1](http://arxiv.org/abs/2501.17144v1)|[link](https://github.com/derenlei/factcg)|
|**2025-01-28**|**ASTRAL: Automated Safety Testing of Large Language Models**|Miriam Ugarte et.al.|[2501.17132v1](http://arxiv.org/abs/2501.17132v1)|null|
|**2025-01-28**|**Histoires Morales: A French Dataset for Assessing Moral Alignment**|Thibaud Leteno et.al.|[2501.17117v1](http://arxiv.org/abs/2501.17117v1)|[link](https://github.com/upunaprosk/histoires-morales)|
|**2025-01-28**|**Optimizing Large Language Model Training Using FP4 Quantization**|Ruizhe Wang et.al.|[2501.17116v1](http://arxiv.org/abs/2501.17116v1)|null|
|**2025-01-28**|**COS(M+O)S: Curiosity and RL-Enhanced MCTS for Exploring Story Space via Language Models**|Tobias Materzok et.al.|[2501.17104v1](http://arxiv.org/abs/2501.17104v1)|null|
|**2025-01-28**|**Why is the estimation of metaorder impact with public market data so challenging?**|Manuel Naviglio et.al.|[2501.17096v1](http://arxiv.org/abs/2501.17096v1)|null|
|**2025-01-28**|**Mamba-Shedder: Post-Transformer Compression for Efficient Selective Structured State Space Models**|J. Pablo Muñoz et.al.|[2501.17088v1](http://arxiv.org/abs/2501.17088v1)|[link](https://github.com/intellabs/hardware-aware-automated-machine-learning)|
|**2025-01-28**|**Learning Mean Field Control on Sparse Graphs**|Christian Fabian et.al.|[2501.17079v1](http://arxiv.org/abs/2501.17079v1)|null|
|**2025-01-28**|**EdgeMLOps: Operationalizing ML models with Cumulocity IoT and thin-edge.io for Visual quality Inspection**|Kanishk Chaturvedi et.al.|[2501.17062v1](http://arxiv.org/abs/2501.17062v1)|null|
|**2025-01-28**|**How Linguistics Learned to Stop Worrying and Love the Language Models**|Richard Futrell et.al.|[2501.17047v1](http://arxiv.org/abs/2501.17047v1)|null|
|**2025-01-28**|**Synthesizing 3D Abstractions by Inverting Procedural Buildings with Transformers**|Maximilian Dax et.al.|[2501.17044v2](http://arxiv.org/abs/2501.17044v2)|null|
|**2025-01-28**|**Benchmarking Quantum Convolutional Neural Networks for Signal Classification in Simulated Gamma-Ray Burst Detection**|Farida Farsian et.al.|[2501.17041v1](http://arxiv.org/abs/2501.17041v1)|null|
|**2025-01-28**|**Challenges in Ensuring AI Safety in DeepSeek-R1 Models: The Shortcomings of Reinforcement Learning Strategies**|Manojkumar Parmar et.al.|[2501.17030v1](http://arxiv.org/abs/2501.17030v1)|null|
|**2025-01-28**|**Revisit Mixture Models for Multi-Agent Simulation: Experimental Study within a Unified Framework**|Longzhong Lin et.al.|[2501.17015v1](http://arxiv.org/abs/2501.17015v1)|null|
|**2025-01-28**|**Generative quantum combinatorial optimization by means of a novel conditional generative quantum eigensolver**|Shunya Minami et.al.|[2501.16986v1](http://arxiv.org/abs/2501.16986v1)|null|
|**2025-01-28**|**Over-Tokenized Transformer: Vocabulary is Generally Worth Scaling**|Hongzhi Huang et.al.|[2501.16975v1](http://arxiv.org/abs/2501.16975v1)|null|

#### Abstracts
##### **Dialogue is Better Than Monologue: Instructing Medical LLMs via Strategical Conversations**
2501.17860v1 by Zijie Liu, Xinyu Zhao, Jie Peng, Zhuangdi Zhu, Qingyu Chen, Xia Hu, Tianlong Chen

Current medical AI systems often fail to replicate real-world clinical
reasoning, as they are predominantly trained and evaluated on static text and
question-answer tasks. These tuning methods and benchmarks overlook critical
aspects like evidence-based reasoning and handling distracting information. To
bridge this gap, we introduce a novel benchmark that simulates real-world
diagnostic scenarios, integrating noise and difficulty levels aligned with
USMLE standards. Moreover, we explore dialogue-based fine-tuning, which
transforms static datasets into conversational formats to better capture
iterative reasoning processes. Experiments show that dialogue-tuned models
outperform traditional methods, with improvements of $9.64\%$ in multi-round
reasoning scenarios and $6.18\%$ in accuracy in a noisy environment. Our
findings highlight dialogue tuning as a promising approach for advancing
clinically aligned and robust medical AI systems.

摘要：目前的醫療 AI 系統常無法複製真實世界的臨床推理，因為它們主要在靜態文字和問答任務上受訓和評估。這些調整方法和基準忽略了基於證據的推理和處理分散資訊等關鍵面向。為了彌補這個差距，我們提出一個模擬真實世界診斷情境的全新基準，整合與 USMLE 標準一致的雜訊和難度等級。此外，我們探索以對話為基礎的微調，將靜態資料集轉換為對話格式，以更好地捕捉反覆的推理過程。實驗顯示，對話微調模型優於傳統方法，在多輪推理情境中提升了 9.64%，在有雜訊的環境中提升了 6.18% 的準確度。我們的發現強調對話微調是一種有望推進與臨床相符且強健的醫療 AI 系統的方法。

##### **Improving Your Model Ranking on Chatbot Arena by Vote Rigging**
2501.17858v1 by Rui Min, Tianyu Pang, Chao Du, Qian Liu, Minhao Cheng, Min Lin

Chatbot Arena is a popular platform for evaluating LLMs by pairwise battles,
where users vote for their preferred response from two randomly sampled
anonymous models. While Chatbot Arena is widely regarded as a reliable LLM
ranking leaderboard, we show that crowdsourced voting can be rigged to improve
(or decrease) the ranking of a target model $m_{t}$. We first introduce a
straightforward target-only rigging strategy that focuses on new battles
involving $m_{t}$, identifying it via watermarking or a binary classifier, and
exclusively voting for $m_{t}$ wins. However, this strategy is practically
inefficient because there are over $190$ models on Chatbot Arena and on average
only about $1\%$ of new battles will involve $m_{t}$. To overcome this, we
propose omnipresent rigging strategies, exploiting the Elo rating mechanism of
Chatbot Arena that any new vote on a battle can influence the ranking of the
target model $m_{t}$, even if $m_{t}$ is not directly involved in the battle.
We conduct experiments on around $1.7$ million historical votes from the
Chatbot Arena Notebook, showing that omnipresent rigging strategies can improve
model rankings by rigging only hundreds of new votes. While we have evaluated
several defense mechanisms, our findings highlight the importance of continued
efforts to prevent vote rigging. Our code is available at
https://github.com/sail-sg/Rigging-ChatbotArena.

摘要：聊天機器人競技場是一個透過成對戰鬥來評估大型語言模型的熱門平台，使用者可以從兩個隨機抽樣的匿名模型中投票給他們偏好的回應。儘管聊天機器人競技場廣泛被視為可靠的大型語言模型排名排行榜，但我們表明群眾外包投票可以被操縱以提升（或降低）目標模型 $m_{t}$ 的排名。我們首先介紹了一個直接的僅目標操縱策略，該策略專注於涉及 $m_{t}$ 的新戰鬥，透過浮水印或二元分類器識別它，並專門投票給 $m_{t}$ 獲勝。然而，這個策略在實務上效率不彰，因為聊天機器人競技場上有超過 190 個模型，而且平均而言只有約 1% 的新戰鬥會涉及 $m_{t}$。為了克服這個問題，我們提出了無所不在的操縱策略，利用聊天機器人競技場的 Elo 評分機制，任何對戰鬥的新投票都可以影響目標模型 $m_{t}$ 的排名，即使 $m_{t}$ 沒有直接參與戰鬥。我們對聊天機器人競技場筆記本中約 170 萬張歷史投票進行了實驗，結果顯示無所不在的操縱策略僅透過操縱數百張新投票就能提升模型排名。儘管我們已經評估了幾種防禦機制，但我們的發現突顯了持續努力防止投票操縱的重要性。我們的程式碼可在 https://github.com/sail-sg/Rigging-ChatbotArena 取得。

##### **GRACE: Generalizing Robot-Assisted Caregiving with User Functionality Embeddings**
2501.17855v1 by Ziang Liu, Yuanchen Ju, Yu Da, Tom Silver, Pranav N. Thakkar, Jenna Li, Justin Guo, Katherine Dimitropoulou, Tapomayukh Bhattacharjee

Robot caregiving should be personalized to meet the diverse needs of care
recipients -- assisting with tasks as needed, while taking user agency in
action into account. In physical tasks such as handover, bathing, dressing, and
rehabilitation, a key aspect of this diversity is the functional range of
motion (fROM), which can vary significantly between individuals. In this work,
we learn to predict personalized fROM as a way to generalize robot
decision-making in a wide range of caregiving tasks. We propose a novel
data-driven method for predicting personalized fROM using functional assessment
scores from occupational therapy. We develop a neural model that learns to
embed functional assessment scores into a latent representation of the user's
physical function. The model is trained using motion capture data collected
from users with emulated mobility limitations. After training, the model
predicts personalized fROM for new users without motion capture. Through
simulated experiments and a real-robot user study, we show that the
personalized fROM predictions from our model enable the robot to provide
personalized and effective assistance while improving the user's agency in
action. See our website for more visualizations:
https://emprise.cs.cornell.edu/grace/.

摘要：機器人照護應根據照護對象的不同需求進行客製化，在需要時協助執行任務，同時考量使用者的自主行動。在移交、沐浴、穿衣和復健等身體任務中，這種多樣性的關鍵面向是功能性動作範圍 (fROM)，而這在不同個體之間可能差異很大。在這項工作中，我們學習預測客製化 fROM，作為在廣泛照護任務中概化機器人決策制定的一種方式。我們提出了一種使用職能治療功能評估分數來預測客製化 fROM 的新穎資料驅動方法。我們開發了一個神經模型，學習將功能評估分數嵌入到使用者的身體功能潛在表徵中。該模型使用從具有模擬行動限制的使用者收集的動作擷取資料進行訓練。訓練後，該模型會為沒有動作擷取的新使用者預測客製化 fROM。透過模擬實驗和真實機器人使用者研究，我們展示了我們模型的客製化 fROM 預測使機器人能夠提供客製化且有效的協助，同時提高使用者的自主行動。請參閱我們的網站以取得更多視覺化資料：https://emprise.cs.cornell.edu/grace/。

##### **From Sparse to Dense: Toddler-inspired Reward Transition in Goal-Oriented Reinforcement Learning**
2501.17842v1 by Junseok Park, Hyeonseo Yang, Min Whoo Lee, Won-Seok Choi, Minsu Lee, Byoung-Tak Zhang

Reinforcement learning (RL) agents often face challenges in balancing
exploration and exploitation, particularly in environments where sparse or
dense rewards bias learning. Biological systems, such as human toddlers,
naturally navigate this balance by transitioning from free exploration with
sparse rewards to goal-directed behavior guided by increasingly dense rewards.
Inspired by this natural progression, we investigate the Toddler-Inspired
Reward Transition in goal-oriented RL tasks. Our study focuses on transitioning
from sparse to potential-based dense (S2D) rewards while preserving optimal
strategies. Through experiments on dynamic robotic arm manipulation and
egocentric 3D navigation tasks, we demonstrate that effective S2D reward
transitions significantly enhance learning performance and sample efficiency.
Additionally, using a Cross-Density Visualizer, we show that S2D transitions
smooth the policy loss landscape, resulting in wider minima that improve
generalization in RL models. In addition, we reinterpret Tolman's maze
experiments, underscoring the critical role of early free exploratory learning
in the context of S2D rewards.

摘要：強化學習 (RL) 代理人經常在平衡探索和利用時面臨挑戰，特別是在稀疏或密集獎勵會影響學習的環境中。生物系統（例如人類幼兒）通過從具有稀疏獎勵的自由探索過渡到由越來越密集的獎勵引導的目標導向行為，自然而然地應對這種平衡。受這種自然進程的啟發，我們研究了目標導向 RL 任務中的幼兒啟發式獎勵轉換。我們的研究重點在於從稀疏轉換到基於潛力的密集 (S2D) 獎勵，同時保留最佳策略。通過對動態機器手臂操作和自我中心 3D 導航任務的實驗，我們證明了有效的 S2D 獎勵轉換顯著提高了學習性能和樣本效率。此外，使用交叉密度可視化工具，我們展示了 S2D 轉換可以平滑策略損失情況，從而產生更廣泛的最小值，從而改善 RL 模型中的泛化。此外，我們重新詮釋了托爾曼迷宮實驗，強調了在 S2D 獎勵的背景下早期自由探索學習的關鍵作用。

##### **Learning Beyond the Surface: How Far Can Continual Pre-Training with LoRA Enhance LLMs' Domain-Specific Insight Learning?**
2501.17840v1 by Pouya Pezeshkpour, Estevam Hruschka

Large Language Models (LLMs) have demonstrated remarkable performance on
various tasks, yet their ability to extract and internalize deeper insights
from domain-specific datasets remains underexplored. In this study, we
investigate how continual pre-training can enhance LLMs' capacity for insight
learning across three distinct forms: declarative, statistical, and
probabilistic insights. Focusing on two critical domains: medicine and finance,
we employ LoRA to train LLMs on two existing datasets. To evaluate each insight
type, we create benchmarks to measure how well continual pre-training helps
models go beyond surface-level knowledge. We also assess the impact of document
modification on capturing insights. The results show that, while continual
pre-training on original documents has a marginal effect, modifying documents
to retain only essential information significantly enhances the
insight-learning capabilities of LLMs.

摘要：大型語言模型 (LLM) 已在各種任務中展現出非凡的表現，但它們從特定領域的資料集中萃取和內化更深入見解的能力仍未被充分探討。在本研究中，我們探討持續預訓練如何增強 LLM 在三種不同形式的見解學習能力：宣告式、統計式和機率式見解。我們專注於兩個重要的領域：醫學和金融，並使用 LoRA 在兩個現有資料集上訓練 LLM。為了評估每種類型的見解，我們建立基準來衡量持續預訓練如何幫助模型超越表面層面的知識。我們也評估文件修改對擷取見解的影響。結果顯示，雖然在原始文件上進行持續預訓練的效果有限，但修改文件以僅保留必要資訊，可以顯著增強 LLM 的見解學習能力。

##### **A Comprehensive Survey on Legal Summarization: Challenges and Future Directions**
2501.17830v1 by Mousumi Akter, Erion Cano, Erik Weber, Dennis Dobler, Ivan Habernal

This article provides a systematic up-to-date survey of automatic
summarization techniques, datasets, models, and evaluation methods in the legal
domain. Through specific source selection criteria, we thoroughly review over
120 papers spanning the modern `transformer' era of natural language processing
(NLP), thus filling a gap in existing systematic surveys on the matter. We
present existing research along several axes and discuss trends, challenges,
and opportunities for future research.

摘要：本文提供了一份法律領域中自動摘要技術、資料集、模型和評估方法的系統性最新調查。透過具體的來源選擇標準，我們徹底檢視了涵蓋自然語言處理 (NLP) 現代「Transformer」時代的 120 篇論文，從而填補了現有系統性調查的空白。我們沿著幾個軸線呈現現有研究，並討論未來研究的趨勢、挑戰和機會。

##### **U2A: Unified Unimodal Adaptation for Robust and Efficient Multimodal Learning**
2501.17823v1 by Md Kaykobad Reza, Niki Nezakati, Ameya Patil, Mashhour Solh, M. Salman Asif

Multimodal learning often relies on designing new models and complex training
strategies to achieve optimal performance. We present Unified Unimodal
Adaptation (U2A), which jointly fine-tunes pretrained unimodal encoders using
low-rank adaptation (LoRA) for various multimodal tasks. Our method
significantly reduces the number of learnable parameters and eliminates the
need for complex training strategies, such as alternating training, gradient
modifications, or unimodal fine-tuning. To address missing modalities during
both training and testing, we introduce Mask Tokens (MT), which generate
missing modality features from available modalities using a single token per
modality. This simplifies the process, removing the need for specialized
feature estimation or prompt-tuning methods. Our evaluation demonstrates that
U2A matches or outperforms state-of-the-art methods in both complete and
missing modality settings, showcasing strong performance and robustness across
various modalities, tasks, and datasets. We also analyze and report the
effectiveness of Mask Tokens in different missing modality scenarios. Overall,
our method provides a robust, flexible, and efficient solution for multimodal
learning, with minimal computational overhead.

摘要：多模态学习通常依赖于设计新模型和复杂的训练策略以实现最佳性能。我们提出了统一单模态自适应 (U2A)，它使用低秩自适应 (LoRA) 联合微调预训练的单模态编码器，以用于各种多模态任务。我们的方法显著减少了可学习参数的数量，并且消除了对复杂训练策略的需求，例如交替训练、梯度修改或单模态微调。为了解决训练和测试期间缺少的模态，我们引入了掩码标记 (MT)，它使用每个模态的单个标记从可用模态生成缺失的模态特征。这简化了流程，消除了对专门的特征估计或提示调整方法的需求。我们的评估表明，U2A 在完整和缺失模态设置中均匹配或优于最先进的方法，展示了跨各种模态、任务和数据集的强大性能和鲁棒性。我们还分析并报告了掩码标记在不同缺失模态场景中的有效性。总体而言，我们的方法为多模态学习提供了一种健壮、灵活且高效的解决方案，计算开销最小。

##### **Aggregation Schemes for Single-Vector WSI Representation Learning in Digital Pathology**
2501.17822v1 by Sobhan Hemati, Ghazal Alabtah, Saghir Alfasly, H. R. Tizhoosh

A crucial step to efficiently integrate Whole Slide Images (WSIs) in
computational pathology is assigning a single high-quality feature vector,
i.e., one embedding, to each WSI. With the existence of many pre-trained deep
neural networks and the emergence of foundation models, extracting embeddings
for sub-images (i.e., tiles or patches) is straightforward. However, for WSIs,
given their high resolution and gigapixel nature, inputting them into existing
GPUs as a single image is not feasible. As a result, WSIs are usually split
into many patches. Feeding each patch to a pre-trained model, each WSI can then
be represented by a set of patches, hence, a set of embeddings. Hence, in such
a setup, WSI representation learning reduces to set representation learning
where for each WSI we have access to a set of patch embeddings. To obtain a
single embedding from a set of patch embeddings for each WSI, multiple
set-based learning schemes have been proposed in the literature. In this paper,
we evaluate the WSI search performance of multiple recently developed
aggregation techniques (mainly set representation learning techniques)
including simple average or max pooling operations, Deep Sets, Memory networks,
Focal attention, Gaussian Mixture Model (GMM) Fisher Vector, and deep sparse
and binary Fisher Vector on four different primary sites including bladder,
breast, kidney, and Colon from TCGA. Further, we benchmark the search
performance of these methods against the median of minimum distances of patch
embeddings, a non-aggregating approach used for WSI retrieval.

摘要：在計算病理學中有效整合全幻燈片影像 (WSI) 的關鍵步驟是為每個 WSI 指定一個單一的高品質特徵向量，即一個嵌入。由於許多預先訓練好的深度神經網路的存在和基礎模型的出現，提取子影像（即磁磚或貼片）的嵌入非常簡單。然而，對於 WSI，由於它們的高解析度和吉像素特性，將它們作為單一影像輸入現有的 GPU 是不可行的。因此，WSI 通常會被分割成許多貼片。將每個貼片輸入預先訓練好的模型後，每個 WSI 就可以用一組貼片來表示，因此，也就是一組嵌入。因此，在這樣的設定中，WSI 表示學習會簡化為集合表示學習，其中對於每個 WSI，我們可以存取一組貼片嵌入。為了從每個 WSI 的一組貼片嵌入中取得單一嵌入，文獻中已經提出了多種基於集合的學習方案。在本文中，我們評估了多種最近開發的聚合技術（主要是集合表示學習技術）的 WSI 搜尋效能，包括簡單的平均或最大池化運算、深度集合、記憶網路、焦點注意力、高斯混合模型 (GMM) Fisher 向量和深度稀疏和二進位 Fisher 向量，在 TCGA 的四個不同的主要部位，包括膀胱、乳房、腎臟和結腸。此外，我們將這些方法的搜尋效能與貼片嵌入的最小距離中位數進行基準比較，這是一種用於 WSI 擷取的非聚合方法。

##### **P-TAME: Explain Any Image Classifier with Trained Perturbations**
2501.17813v1 by Mariano V. Ntrougkas, Vasileios Mezaris, Ioannis Patras

The adoption of Deep Neural Networks (DNNs) in critical fields where
predictions need to be accompanied by justifications is hindered by their
inherent black-box nature. In this paper, we introduce P-TAME
(Perturbation-based Trainable Attention Mechanism for Explanations), a
model-agnostic method for explaining DNN-based image classifiers. P-TAME
employs an auxiliary image classifier to extract features from the input image,
bypassing the need to tailor the explanation method to the internal
architecture of the backbone classifier being explained. Unlike traditional
perturbation-based methods, which have high computational requirements, P-TAME
offers an efficient alternative by generating high-resolution explanations in a
single forward pass during inference. We apply P-TAME to explain the decisions
of VGG-16, ResNet-50, and ViT-B-16, three distinct and widely used image
classifiers. Quantitative and qualitative results show that our method matches
or outperforms previous explainability methods, including model-specific
approaches. Code and trained models will be released upon acceptance.

摘要：深度神经網路 (DNN) 在需要對預測進行佐證的重要領域中被採用受到其固有的黑箱性質所阻礙。在本文中，我們介紹了 P-TAME（基於擾動的可訓練注意力機制用於解釋），一種與模型無關的方法，用於解釋基於 DNN 的影像分類器。P-TAME 採用輔助影像分類器從輸入影像中提取特徵，繞過需要根據要解釋的主幹分類器的內部架構調整解釋方法。與具有高計算需求的傳統基於擾動的方法不同，P-TAME 在推論過程中透過單次前向傳遞產生高解析度解釋，提供了一種高效的替代方案。我們將 P-TAME 用於解釋 VGG-16、ResNet-50 和 ViT-B-16 的決策，這三種是不同的且廣泛使用的影像分類器。定量和定性結果顯示，我們的模型比之前的可解釋性方法（包括特定於模型的方法）匹配或表現得更好。程式碼和訓練模型將在接受後發布。

##### **Janus-Pro: Unified Multimodal Understanding and Generation with Data and Model Scaling**
2501.17811v1 by Xiaokang Chen, Zhiyu Wu, Xingchao Liu, Zizheng Pan, Wen Liu, Zhenda Xie, Xingkai Yu, Chong Ruan

In this work, we introduce Janus-Pro, an advanced version of the previous
work Janus. Specifically, Janus-Pro incorporates (1) an optimized training
strategy, (2) expanded training data, and (3) scaling to larger model size.
With these improvements, Janus-Pro achieves significant advancements in both
multimodal understanding and text-to-image instruction-following capabilities,
while also enhancing the stability of text-to-image generation. We hope this
work will inspire further exploration in the field. Code and models are
publicly available.

摘要：在這項工作中，我們介紹了 Janus-Pro，這是先前工作 Janus 的進階版本。具體來說，Janus-Pro 結合了 (1) 最佳化的訓練策略、(2) 擴充的訓練資料，以及 (3) 擴充到更大的模型規模。透過這些改進，Janus-Pro 在多模態理解和文字轉影像指令遵循能力方面都取得了顯著的進步，同時也增強了文字轉影像生成的穩定性。我們希望這項工作能激勵在該領域進一步探索。程式碼和模型已公開提供。

##### **BreezyVoice: Adapting TTS for Taiwanese Mandarin with Enhanced Polyphone Disambiguation -- Challenges and Insights**
2501.17790v1 by Chan-Jan Hsu, Yi-Cheng Lin, Chia-Chun Lin, Wei-Chih Chen, Ho Lam Chung, Chen-An Li, Yi-Chang Chen, Chien-Yu Yu, Ming-Ji Lee, Chien-Cheng Chen, Ru-Heng Huang, Hung-yi Lee, Da-Shan Shiu

We present BreezyVoice, a Text-to-Speech (TTS) system specifically adapted
for Taiwanese Mandarin, highlighting phonetic control abilities to address the
unique challenges of polyphone disambiguation in the language. Building upon
CosyVoice, we incorporate a $S^{3}$ tokenizer, a large language model (LLM), an
optimal-transport conditional flow matching model (OT-CFM), and a grapheme to
phoneme prediction model, to generate realistic speech that closely mimics
human utterances. Our evaluation demonstrates BreezyVoice's superior
performance in both general and code-switching contexts, highlighting its
robustness and effectiveness in generating high-fidelity speech. Additionally,
we address the challenges of generalizability in modeling long-tail speakers
and polyphone disambiguation. Our approach significantly enhances performance
and offers valuable insights into the workings of neural codec TTS systems.

摘要：我們提出 BreezyVoice，一個專門針對台灣國語的文字轉語音 (TTS) 系統，強調語音控制能力以解決語言中多音字消除歧義的獨特挑戰。在 CosyVoice 的基礎上，我們整合了一個 $S^{3}$ 分詞器、一個大型語言模型 (LLM)、一個最佳傳輸條件流匹配模型 (OT-CFM) 和一個音素預測模型，以產生逼真且與人類發音非常接近的語音。我們的評估證明了 BreezyVoice 在一般和語碼轉換情境中皆有卓越的表現，突顯了它在產生高保真語音方面的穩健性和有效性。此外，我們解決了在建模長尾說話者和多音字消除歧義中可概化性的挑戰。我們的做法大幅提升了效能，並提供了對神經編解碼器 TTS 系統運作方式的寶貴見解。

##### **Reasoning Over the Glyphs: Evaluation of LLM's Decipherment of Rare Scripts**
2501.17785v1 by Yu-Fei Shih, Zheng-Lin Lin, Shu-Kai Hsieh

We explore the capabilities of LVLMs and LLMs in deciphering rare scripts not
encoded in Unicode. We introduce a novel approach to construct a multimodal
dataset of linguistic puzzles involving such scripts, utilizing a tokenization
method for language glyphs. Our methods include the Picture Method for LVLMs
and the Description Method for LLMs, enabling these models to tackle these
challenges. We conduct experiments using prominent models, GPT-4o, Gemini, and
Claude 3.5 Sonnet, on linguistic puzzles. Our findings reveal the strengths and
limitations of current AI methods in linguistic decipherment, highlighting the
impact of Unicode encoding on model performance and the challenges of modeling
visual language tokens through descriptions. Our study advances understanding
of AI's potential in linguistic decipherment and underscores the need for
further research.

摘要：我們探討 LVLMs 和 LLM 解碼未編碼在 Unicode 中的罕見腳本的能力。我們引入一種創新的方法來建構一個涉及此類腳本的多模態語言謎題資料集，利用一種語言字形的標記化方法。我們的模型包含 LVLMs 的圖片方法和 LLM 的描述方法，使這些模型能夠應對這些挑戰。我們使用傑出的模型 GPT-4o、Gemini 和 Claude 3.5 Sonnet 對語言謎題進行實驗。我們的研究結果揭示了當前 AI 方法在語言解碼中的優點和限制，強調了 Unicode 編碼對模型效能的影響，以及透過描述對視覺語言標記建模的挑戰。我們的研究推動了對 AI 在語言解碼中的潛力的理解，並強調了進一步研究的必要性。

##### **2SSP: A Two-Stage Framework for Structured Pruning of LLMs**
2501.17771v1 by Fabrizio Sandri, Elia Cunegatti, Giovanni Iacca

We propose a novel Two-Stage framework for Structured Pruning (2SSP) for
pruning Large Language Models (LLMs), which combines two different strategies
of pruning, namely Width and Depth Pruning. The first stage (Width Pruning)
removes entire neurons, hence their corresponding rows and columns, aiming to
preserve the connectivity among the pruned structures in the intermediate state
of the Feed-Forward Networks in each Transformer block. This is done based on
an importance score measuring the impact of each neuron over the output
magnitude. The second stage (Depth Pruning), instead, removes entire Attention
submodules. This is done by applying an iterative process that removes the
Attention submodules with the minimum impact on a given metric of interest (in
our case, perplexity). We also propose a novel mechanism to balance the
sparsity rate of the two stages w.r.t. to the desired global sparsity. We test
2SSP on four LLM families and three sparsity rates (25\%, 37.5\%, and 50\%),
measuring the resulting perplexity over three language modeling datasets as
well as the performance over six downstream tasks. Our method consistently
outperforms five state-of-the-art competitors over three language modeling and
six downstream tasks, with an up to two-order-of-magnitude gain in terms of
pruning time. The code is available at available at
\url{https://github.com/FabrizioSandri/2SSP}.

摘要：我們提出了一個新穎的兩階段框架，用於結構化剪枝 (2SSP)，用於剪枝大型語言模型 (LLM)，它結合了兩種不同的剪枝策略，即寬度剪枝和深度剪枝。第一階段（寬度剪枝）移除整個神經元，因此移除對應的行和列，目標是在每個 Transformer 區塊的饋前網路的中間狀態中保留剪枝結構之間的連接性。這是根據一個重要性分數進行的，該分數測量每個神經元對輸出幅度的影響。第二階段（深度剪枝）則移除整個注意力子模組。這是通過應用一個迭代過程來完成的，該過程移除對給定感興趣指標（在我們的案例中，困惑度）影響最小的注意力子模組。我們還提出了一個新穎的機制來平衡兩個階段的稀疏率，以達到所需的整體稀疏率。我們在四個 LLM 家族和三個稀疏率（25%、37.5% 和 50%）上測試 2SSP，測量了三個語言建模資料集上的結果困惑度，以及六個下游任務上的效能。我們的模型在三個語言建模和六個下游任務上持續優於五個最先進的競爭對手，在剪枝時間方面獲得了高達兩個數量級的增益。程式碼可在 \url{https://github.com/FabrizioSandri/2SSP} 取得。

##### **Hybrid Graphs for Table-and-Text based Question Answering using LLMs**
2501.17767v1 by Ankush Agarwal, Ganesh S, Chaitanya Devaguptapu

Answering questions that require reasoning and aggregation across both
structured (tables) and unstructured (raw text) data sources presents
significant challenges. Current methods rely on fine-tuning and high-quality,
human-curated data, which is difficult to obtain. Recent advances in Large
Language Models (LLMs) have shown promising results for multi-hop question
answering (QA) over single-source text data in a zero-shot setting, yet
exploration into multi-source Table-Text QA remains limited. In this paper, we
present a novel Hybrid Graph-based approach for Table-Text QA that leverages
LLMs without fine-tuning. Our method constructs a unified Hybrid Graph from
textual and tabular data, pruning information based on the input question to
provide the LLM with relevant context concisely. We evaluate our approach on
the challenging Hybrid-QA and OTT-QA datasets using state-of-the-art LLMs,
including GPT-3.5, GPT-4, and LLaMA-3. Our method achieves the best zero-shot
performance on both datasets, improving Exact Match scores by up to 10% on
Hybrid-QA and 5.4% on OTT-QA. Moreover, our approach reduces token usage by up
to 53% compared to the original context.

摘要：回答需要對結構化（表格）和非結構化（原始文字）資料來源進行推理和彙總的問題會帶來重大挑戰。目前的辦法仰賴微調和高品質、人工整理的資料，而這很難取得。大型語言模型（LLM）的最新進展已針對零次學習設定的單一來源文字資料多跳問題回答（QA）展現出有希望的結果，但對多來源表格文字 QA 的探討仍然有限。在本文中，我們提出了一種新穎的基於混合圖表的表格文字 QA 方法，它利用 LLM 而無需微調。我們的辦法從文字和表格資料建構一個統一的混合圖表，根據輸入問題修剪資訊，以簡潔地為 LLM 提供相關脈絡。我們使用最先進的 LLM，包括 GPT-3.5、GPT-4 和 LLaMA-3，針對具有挑戰性的 Hybrid-QA 和 OTT-QA 資料集評估我們的辦法。我們的辦法在兩個資料集上都達到了最佳的零次學習效能，在 Hybrid-QA 上將完全比對分數提高了 10%，在 OTT-QA 上將完全比對分數提高了 5.4%。此外，與原始脈絡相比，我們的辦法將符號使用量減少了 53%。

##### **Yin-Yang: Developing Motifs With Long-Term Structure And Controllability**
2501.17759v1 by Keshav Bhandari, Geraint A. Wiggins, Simon Colton

Transformer models have made great strides in generating symbolically
represented music with local coherence. However, controlling the development of
motifs in a structured way with global form remains an open research area. One
of the reasons for this challenge is due to the note-by-note autoregressive
generation of such models, which lack the ability to correct themselves after
deviations from the motif. In addition, their structural performance on
datasets with shorter durations has not been studied in the literature. In this
study, we propose Yin-Yang, a framework consisting of a phrase generator,
phrase refiner, and phrase selector models for the development of motifs into
melodies with long-term structure and controllability. The phrase refiner is
trained on a novel corruption-refinement strategy which allows it to produce
melodic and rhythmic variations of an original motif at generation time,
thereby rectifying deviations of the phrase generator. We also introduce a new
objective evaluation metric for quantifying how smoothly the motif manifests
itself within the piece. Evaluation results show that our model achieves better
performance compared to state-of-the-art transformer models while having the
advantage of being controllable and making the generated musical structure
semi-interpretable, paving the way for musical analysis. Our code and demo page
can be found at https://github.com/keshavbhandari/yinyang.

摘要：Transformer模型在產生具有局部相干性的符號表示音樂方面取得了長足的進展。然而，以結構化的方式控制全局形式中的主題發展仍然是一個開放的研究領域。這種挑戰的原因之一是這種模型逐個音符的自動回歸生成，它們缺乏在偏離主題後自我糾正的能力。此外，尚未在文獻中研究它們在持續時間較短的數據集上的結構性能。在這項研究中，我們提出了陰陽，一個由短語生成器、短語精煉器和短語選擇器模型組成的框架，用於將主題發展成具有長期結構和可控性的旋律。短語精煉器在一個新穎的破壞精煉策略上進行訓練，這使它能夠在生成時產生原始主題的旋律和節奏變奏，從而糾正短語生成器的偏差。我們還引入了一個新的客觀評估指標，用於量化主題在作品中表現得有多麼流暢。評估結果表明，與最先進的Transformer模型相比，我們的模型取得了更好的性能，同時具有可控性和使生成的音樂結構半可解釋的優點，為音樂分析鋪平了道路。我們的代碼和演示頁面可以在 https://github.com/keshavbhandari/yinyang 中找到。

##### **Early External Safety Testing of OpenAI's o3-mini: Insights from the Pre-Deployment Evaluation**
2501.17749v1 by Aitor Arrieta, Miriam Ugarte, Pablo Valle, José Antonio Parejo, Sergio Segura

Large Language Models (LLMs) have become an integral part of our daily lives.
However, they impose certain risks, including those that can harm individuals'
privacy, perpetuate biases and spread misinformation. These risks highlight the
need for robust safety mechanisms, ethical guidelines, and thorough testing to
ensure their responsible deployment. Safety of LLMs is a key property that
needs to be thoroughly tested prior the model to be deployed and accessible to
the general users. This paper reports the external safety testing experience
conducted by researchers from Mondragon University and University of Seville on
OpenAI's new o3-mini LLM as part of OpenAI's early access for safety testing
program. In particular, we apply our tool, ASTRAL, to automatically and
systematically generate up to date unsafe test inputs (i.e., prompts) that
helps us test and assess different safety categories of LLMs. We automatically
generate and execute a total of 10,080 unsafe test input on a early o3-mini
beta version. After manually verifying the test cases classified as unsafe by
ASTRAL, we identify a total of 87 actual instances of unsafe LLM behavior. We
highlight key insights and findings uncovered during the pre-deployment
external testing phase of OpenAI's latest LLM.

摘要：大型語言模型 (LLM) 已成為我們日常生活不可或缺的一部分。
然而，它們會帶來某些風險，包括可能損害個人隱私、延續偏見和散布錯誤訊息的風險。這些風險突顯出需要穩健的安全機制、道德準則和徹底的測試，以確保其負責任的部署。LLM 的安全性是一個關鍵特性，需要在模型部署並供一般使用者存取之前進行徹底的測試。本文報告了 Mondragon 大學和塞維亞大學的研究人員在 OpenAI 的早期存取安全測試計畫中，針對 OpenAI 的新 o3-mini LLM 進行的外部安全測試經驗。特別是，我們運用我們的工具 ASTRAL 自動且系統性地產生最新的不安全測試輸入（即提示），這有助於我們測試和評估 LLM 的不同安全類別。我們自動產生並執行總共 10,080 個不安全測試輸入，針對早期 o3-mini 測試版。在手動驗證 ASTRAL 分類為不安全的測試案例後，我們總共找出 87 個 LLM 不安全行為的實際範例。我們重點說明在 OpenAI 最新 LLM 的部署前外部測試階段中發現的主要見解和發現。

##### **Exact characterization of ε-Safe Decision Regions for exponential family distributions and Multi Cost SVM approximation**
2501.17731v1 by Alberto Carlevaro, Teodoro Alamo, Fabrizio Dabbene, Maurizio Mongelli

Probabilistic guarantees on the prediction of data-driven classifiers are
necessary to define models that can be considered reliable. This is a key
requirement for modern machine learning in which the goodness of a system is
measured in terms of trustworthiness, clearly dividing what is safe from what
is unsafe. The spirit of this paper is exactly in this direction. First, we
introduce a formal definition of {\epsilon}-Safe Decision Region, a subset of
the input space in which the prediction of a target (safe) class is
probabilistically guaranteed. Second, we prove that, when data come from
exponential family distributions, the form of such a region is analytically
determined and controllable by design parameters, i.e. the probability of
sampling the target class and the confidence on the prediction. However, the
request of having exponential data is not always possible. Inspired by this
limitation, we developed Multi Cost SVM, an SVM based algorithm that
approximates the safe region and is also able to handle unbalanced data. The
research is complemented by experiments and code available for reproducibility.

摘要：在資料驅動分類器的預測上，機率保證對於定義可被認為可靠的模型是必要的。這是現代機器學習的一項關鍵需求，其中系統的優劣是根據可信度衡量的，清楚地將安全與不安全的區分開來。本文的精神正是朝這個方向發展。首先，我們引入{\epsilon}-安全決策區域的正式定義，它是輸入空間的一個子集，其中目標（安全）類別的預測在機率上是有保證的。其次，我們證明，當資料來自指數族分佈時，這種區域的形式是由設計參數解析確定的和可控的，即抽樣目標類別的機率和預測的信心。然而，擁有指數資料的要求並不總是可行的。受到這個限制的啟發，我們開發了多成本 SVM，一種基於 SVM 的演算法，它近似安全區域，並且也能夠處理不平衡的資料。本研究由實驗和可供重現的程式碼補充。

##### **VICCA: Visual Interpretation and Comprehension of Chest X-ray Anomalies in Generated Report Without Human Feedback**
2501.17726v1 by Sayeh Gholipour Picha, Dawood Al Chanti, Alice Caplier

As artificial intelligence (AI) becomes increasingly central to healthcare,
the demand for explainable and trustworthy models is paramount. Current report
generation systems for chest X-rays (CXR) often lack mechanisms for validating
outputs without expert oversight, raising concerns about reliability and
interpretability. To address these challenges, we propose a novel multimodal
framework designed to enhance the semantic alignment and localization accuracy
of AI-generated medical reports. Our framework integrates two key modules: a
Phrase Grounding Model, which identifies and localizes pathologies in CXR
images based on textual prompts, and a Text-to-Image Diffusion Module, which
generates synthetic CXR images from prompts while preserving anatomical
fidelity. By comparing features between the original and generated images, we
introduce a dual-scoring system: one score quantifies localization accuracy,
while the other evaluates semantic consistency. This approach significantly
outperforms existing methods, achieving state-of-the-art results in pathology
localization and text-to-image alignment. The integration of phrase grounding
with diffusion models, coupled with the dual-scoring evaluation system,
provides a robust mechanism for validating report quality, paving the way for
more trustworthy and transparent AI in medical imaging.

摘要：隨著人工智慧 (AI) 在醫療保健中扮演越來越重要的角色，
對可解釋且值得信賴的模型的需求至關重要。目前針對胸部 X 光 (CXR) 的報告生成系統通常缺乏在沒有專家監督的情況下驗證輸出的機制，這引發了對可靠性和可解釋性的疑慮。為了應對這些挑戰，我們提出了一個新穎的多模態架構，旨在增強 AI 生成的醫療報告的語義對齊和定位準確度。我們的架構整合了兩個關鍵模組：一個基於文字提示識別和定位 CXR 影像中病理的詞組基礎模型，以及一個文字到影像擴散模組，該模組在保留解剖結構保真度的同時，從提示中生成合成 CXR 影像。透過比較原始影像和生成影像之間的特徵，我們引入了雙重評分系統：一個評分量化定位準確度，而另一個評分則評估語義一致性。這種方法顯著優於現有方法，在病理定位和文字到影像對齊方面取得了最先進的成果。詞組基礎與擴散模型的整合，加上雙重評分評估系統，提供了一個驗證報告品質的強健機制，為醫療影像中更值得信賴且透明的 AI 鋪路。

##### **Using Code Generation to Solve Open Instances of Combinatorial Design Problems**
2501.17725v1 by Christopher D. Rosin

The Handbook of Combinatorial Designs catalogs many types of combinatorial
designs, together with lists of open instances for which existence has not yet
been determined. We develop a constructive protocol CPro1, which uses Large
Language Models (LLMs) to generate code that constructs combinatorial designs
and resolves some of these open instances. The protocol starts from a
definition of a particular type of design, and a verifier that reliably
confirms whether a proposed design is valid. The LLM selects strategies and
implements them in code, and scaffolding provides automated hyperparameter
tuning and execution feedback using the verifier. Most generated code fails,
but by generating many candidates, the protocol automates exploration of a
variety of standard methods (e.g. simulated annealing, genetic algorithms) and
experimentation with variations (e.g. cost functions) to find successful
approaches. Testing on 16 different types of designs, CPro1 constructs
solutions to open instances for 6 of them: Symmetric and Skew Weighing
Matrices, Equidistant Permutation Arrays, Packing Arrays, Balanced Ternary
Designs, and Florentine Rectangles.

摘要：組合設計手冊彙整了許多類型的組合設計，以及尚未確定存在的開放實例清單。我們開發了一個建構協定 CPro1，它使用大型語言模型 (LLM) 來產生建構組合設計的程式碼，並解決其中一些開放實例。此協定從特定類型設計的定義開始，以及一個可靠確認建議設計是否有效的驗證器。LLM 選擇策略並在程式碼中實作它們，而架構提供自動超參數調整和使用驗證器的執行回饋。大多數產生的程式碼都會失敗，但透過產生許多候選，此協定自動化探索各種標準方法（例如模擬退火、遺傳演算法）並實驗變異（例如成本函數）以找出成功的做法。在 16 種不同類型的設計上進行測試，CPro1 為其中 6 種設計建構了解決方案：對稱和偏斜加權矩陣、等距排列陣列、堆積陣列、平衡三元設計和佛羅倫斯矩形。

##### **RICoTA: Red-teaming of In-the-wild Conversation with Test Attempts**
2501.17715v1 by Eujeong Choi, Younghun Jeong, Soomin Kim, Won Ik Cho

User interactions with conversational agents (CAs) evolve in the era of
heavily guardrailed large language models (LLMs). As users push beyond
programmed boundaries to explore and build relationships with these systems,
there is a growing concern regarding the potential for unauthorized access or
manipulation, commonly referred to as "jailbreaking." Moreover, with CAs that
possess highly human-like qualities, users show a tendency toward initiating
intimate sexual interactions or attempting to tame their chatbots. To capture
and reflect these in-the-wild interactions into chatbot designs, we propose
RICoTA, a Korean red teaming dataset that consists of 609 prompts challenging
LLMs with in-the-wild user-made dialogues capturing jailbreak attempts. We
utilize user-chatbot conversations that were self-posted on a Korean
Reddit-like community, containing specific testing and gaming intentions with a
social chatbot. With these prompts, we aim to evaluate LLMs' ability to
identify the type of conversation and users' testing purposes to derive chatbot
design implications for mitigating jailbreaking risks. Our dataset will be made
publicly available via GitHub.

摘要：在大型語言模型 (LLM) 受到嚴格保護的時代，使用者與對話式代理 (CA) 的互動不斷演進。隨著使用者突破既定的界線，探索並建立與這些系統的關係，對於未經授權的存取或操縱（一般稱為「越獄」）的潛在風險也越來越令人擔憂。此外，由於 CA 擁有高度擬人的特質，使用者傾向於發起親密的性互動或嘗試馴服他們的聊天機器人。為了捕捉並反映這些在野互動到聊天機器人的設計中，我們提出 RICoTA，這是一個韓語紅隊數據集，包含 609 個提示，挑戰 LLM 使用捕捉越獄嘗試的野生成使用者對話。我們利用在類似韓國 Reddit 的社群中自行發布的使用者聊天機器人對話，其中包含與社交聊天機器人的具體測試和遊戲意圖。透過這些提示，我們旨在評估 LLM 識別對話類型和使用者測試目的的能力，以推導聊天機器人設計的含意，以減輕越獄風險。我們的數據集將透過 GitHub 公開。

##### **Inferring Implicit Goals Across Differing Task Models**
2501.17704v1 by Silvia Tulli, Stylianos Loukas Vasileiou, Mohamed Chetouani, Sarath Sreedharan

One of the significant challenges to generating value-aligned behavior is to
not only account for the specified user objectives but also any implicit or
unspecified user requirements. The existence of such implicit requirements
could be particularly common in settings where the user's understanding of the
task model may differ from the agent's estimate of the model. Under this
scenario, the user may incorrectly expect some agent behavior to be inevitable
or guaranteed. This paper addresses such expectation mismatch in the presence
of differing models by capturing the possibility of unspecified user subgoal in
the context of a task captured as a Markov Decision Process (MDP) and querying
for it as required. Our method identifies bottleneck states and uses them as
candidates for potential implicit subgoals. We then introduce a querying
strategy that will generate the minimal number of queries required to identify
a policy guaranteed to achieve the underlying goal. Our empirical evaluations
demonstrate the effectiveness of our approach in inferring and achieving
unstated goals across various tasks.

摘要：產生價值對齊行為時，其中一項重大挑戰在於，不僅要考慮指定的使用者目標，還要考慮任何隱含或未指定的使用者需求。此類隱含需求的存在，在使用者對任務模型的理解可能與代理人對模型的估計不同的情況中特別常見。在此情況下，使用者可能會錯誤地預期某些代理人行為是不可避免或有保證的。本文透過在馬可夫決策過程 (MDP) 中捕捉未指定使用者次目標的可能性，並在需要時查詢它，來解決在模型不同的情況下這種預期不符的問題。我們的做法會找出瓶頸狀態，並將它們用作潛在隱含次目標的候選者。然後，我們會引入一種查詢策略，這將產生識別策略所需的最小查詢數目，以確保達成基礎目標。我們的經驗評估證明了我們的方法在推論和達成各種任務中未說明目標的有效性。

##### **Critique Fine-Tuning: Learning to Critique is More Effective than Learning to Imitate**
2501.17703v1 by Yubo Wang, Xiang Yue, Wenhu Chen

Supervised Fine-Tuning (SFT) is commonly used to train language models to
imitate annotated responses for given instructions. In this paper, we challenge
this paradigm and propose Critique Fine-Tuning (CFT), a strategy where models
learn to critique noisy responses rather than simply imitate correct ones.
Inspired by human learning processes that emphasize critical thinking, CFT
encourages deeper analysis and nuanced understanding-traits often overlooked by
standard SFT. To validate the effectiveness of CFT, we construct a 50K-sample
dataset from WebInstruct, using GPT-4o as the teacher to generate critiques in
the form of (input=[query; noisy response], output=critique). CFT on this
dataset yields a consistent 4-10% improvement over SFT on six math benchmarks
with different base models like Qwen2.5, Qwen2.5-Math and DeepSeek-Math. We
further expand to MetaMath and NuminaMath datasets and observe similar gains
over SFT. Notably, our Qwen2.5-Math-CFT model-trained on just 50K
samples-matches or outperforms competitive models such as AceMath and
Qwen2.5-Math-Instruct on most benchmarks, both of which use over 2M samples.
Ablation studies show that CFT is robust to the source of noisy response and
teacher critique model. Through these findings, we argue that critique-based
training offers a more effective alternative to advance the reasoning of
language models.

摘要：<paragraph>監督微調 (SFT) 常用於訓練語言模型，以模仿針對特定指示的標註回應。在本文中，我們挑戰此範例並提出批判微調 (CFT)，這是一種策略，模型學習批判有雜訊的回應，而非僅模仿正確的回應。受強調批判性思考的人類學習過程啟發，CFT 鼓勵更深入的分析和細微的理解，這些特質通常被標準 SFT 忽略。為了驗證 CFT 的有效性，我們從 WebInstruct 建構一個 50K 範例的資料集，使用 GPT-4o 作為教師，以 (輸入=[查詢；有雜訊的回應]，輸出=批判) 的形式產生批判。此資料集上的 CFT 在六個數學基準上產生一致的 4-10% 進步，使用不同的基礎模型，例如 Qwen2.5、Qwen2.5-Math 和 DeepSeek-Math。我們進一步擴展到 MetaMath 和 NuminaMath 資料集，並觀察到比 SFT 類似的增益。值得注意的是，我們的 Qwen2.5-Math-CFT 模型僅訓練於 50K 範例，在多數基準上比 AceMath 和 Qwen2.5-Math-Instruct 等競爭模型匹配或表現更佳，而後兩者都使用超過 2M 範例。消融研究顯示，CFT 對有雜訊的回應來源和教師批判模型具有穩健性。透過這些發現，我們主張基於批判的訓練提供更有效的替代方案，以推進語言模型的推理。</paragraph>

##### **PulmoFusion: Advancing Pulmonary Health with Efficient Multi-Modal Fusion**
2501.17699v1 by Ahmed Sharshar, Yasser Attia, Mohammad Yaqub, Mohsen Guizani

Traditional remote spirometry lacks the precision required for effective
pulmonary monitoring. We present a novel, non-invasive approach using
multimodal predictive models that integrate RGB or thermal video data with
patient metadata. Our method leverages energy-efficient Spiking Neural Networks
(SNNs) for the regression of Peak Expiratory Flow (PEF) and classification of
Forced Expiratory Volume (FEV1) and Forced Vital Capacity (FVC), using
lightweight CNNs to overcome SNN limitations in regression tasks. Multimodal
data integration is improved with a Multi-Head Attention Layer, and we employ
K-Fold validation and ensemble learning to boost robustness. Using thermal
data, our SNN models achieve 92% accuracy on a breathing-cycle basis and 99.5%
patient-wise. PEF regression models attain Relative RMSEs of 0.11 (thermal) and
0.26 (RGB), with an MAE of 4.52% for FEV1/FVC predictions, establishing
state-of-the-art performance. Code and dataset can be found on
https://github.com/ahmed-sharshar/RespiroDynamics.git

摘要：傳統的遠距肺活量測量法缺乏有效肺部監測所需的精確度。我們提出了一種使用多模式預測模型的新型非侵入性方法，該模型將 RGB 或熱影像數據與患者元數據整合在一起。我們的技術利用節能的尖峰神經網路 (SNN) 來回歸最大呼氣流量 (PEF) 和分類用力呼氣量 (FEV1) 和用力肺活量 (FVC)，並使用輕量級 CNN 來克服 SNN 在回歸任務中的限制。多模式數據整合通過多頭注意力層得到改進，我們採用 K 折驗證和集成學習來提高魯棒性。使用熱數據，我們的 SNN 模型在呼吸週期基礎上實現了 92% 的準確度，在患者基礎上實現了 99.5% 的準確度。PEF 回歸模型獲得 0.11（熱）和 0.26（RGB）的相對 RMSE，FEV1/FVC 預測的 MAE 為 4.52%，建立了最先進的性能。代碼和數據集可在 https://github.com/ahmed-sharshar/RespiroDynamics.git 上找到

##### **Segmentation-Aware Generative Reinforcement Network (GRN) for Tissue Layer Segmentation in 3-D Ultrasound Images for Chronic Low-back Pain (cLBP) Assessment**
2501.17690v1 by Zixue Zeng, Xiaoyan Zhao, Matthew Cartier, Tong Yu, Jing Wang, Xin Meng, Zhiyu Sheng, Maryam Satarpour, John M Cormack, Allison Bean, Ryan Nussbaum, Maya Maurer, Emily Landis-Walkenhorst, Dinesh Kumbhare, Kang Kim, Ajay Wasan, Jiantao Pu

We introduce a novel segmentation-aware joint training framework called
generative reinforcement network (GRN) that integrates segmentation loss
feedback to optimize both image generation and segmentation performance in a
single stage. An image enhancement technique called segmentation-guided
enhancement (SGE) is also developed, where the generator produces images
tailored specifically for the segmentation model. Two variants of GRN were also
developed, including GRN for sample-efficient learning (GRN-SEL) and GRN for
semi-supervised learning (GRN-SSL). GRN's performance was evaluated using a
dataset of 69 fully annotated 3D ultrasound scans from 29 subjects. The
annotations included six anatomical structures: dermis, superficial fat,
superficial fascial membrane (SFM), deep fat, deep fascial membrane (DFM), and
muscle. Our results show that GRN-SEL with SGE reduces labeling efforts by up
to 70% while achieving a 1.98% improvement in the Dice Similarity Coefficient
(DSC) compared to models trained on fully labeled datasets. GRN-SEL alone
reduces labeling efforts by 60%, GRN-SSL with SGE decreases labeling
requirements by 70%, and GRN-SSL alone by 60%, all while maintaining
performance comparable to fully supervised models. These findings suggest the
effectiveness of the GRN framework in optimizing segmentation performance with
significantly less labeled data, offering a scalable and efficient solution for
ultrasound image analysis and reducing the burdens associated with data
annotation.

摘要：<paragraph>我們提出一個新穎的分割感知聯合訓練架構，稱為生成式強化網路 (GRN)，它整合了分割損失回饋，以在單一階段中優化影像生成和分割效能。也開發了一種稱為分割導向增強 (SGE) 的影像增強技術，其中生成器產生專門針對分割模型的影像。也開發了 GRN 的兩個變體，包括用於樣本有效率學習的 GRN (GRN-SEL) 和用於半監督式學習的 GRN (GRN-SSL)。GRN 的效能使用來自 29 個受試者的 69 個完整標註 3D 超音波掃描的資料集進行評估。標註包括六個解剖結構：真皮、淺層脂肪、淺層筋膜 (SFM)、深層脂肪、深層筋膜 (DFM) 和肌肉。我們的結果顯示，使用 SGE 的 GRN-SEL 可將標籤工作減少多達 70%，同時與在完整標籤資料集上訓練的模型相比，Dice 相似係數 (DSC) 改善了 1.98%。僅 GRN-SEL 可將標籤工作減少 60%，使用 SGE 的 GRN-SSL 可將標籤需求減少 70%，而僅 GRN-SSL 可減少 60%，所有這些同時維持與完全監督模型相當的效能。這些發現表明 GRN 架構在以顯著較少的標籤資料優化分割效能方面的有效性，提供了一個可擴充且有效率的超音波影像分析解決方案，並降低與資料標註相關的負擔。</paragraph>

##### **Planning with Vision-Language Models and a Use Case in Robot-Assisted Teaching**
2501.17665v1 by Xuzhe Dang, Lada Kudláčková, Stefan Edelkamp

Automating the generation of Planning Domain Definition Language (PDDL) with
Large Language Model (LLM) opens new research topic in AI planning,
particularly for complex real-world tasks. This paper introduces Image2PDDL, a
novel framework that leverages Vision-Language Models (VLMs) to automatically
convert images of initial states and descriptions of goal states into PDDL
problems. By providing a PDDL domain alongside visual inputs, Imasge2PDDL
addresses key challenges in bridging perceptual understanding with symbolic
planning, reducing the expertise required to create structured problem
instances, and improving scalability across tasks of varying complexity. We
evaluate the framework on various domains, including standard planning domains
like blocksworld and sliding tile puzzles, using datasets with multiple
difficulty levels. Performance is assessed on syntax correctness, ensuring
grammar and executability, and content correctness, verifying accurate state
representation in generated PDDL problems. The proposed approach demonstrates
promising results across diverse task complexities, suggesting its potential
for broader applications in AI planning. We will discuss a potential use case
in robot-assisted teaching of students with Autism Spectrum Disorder.

摘要：利用大型語言模型 (LLM) 自動化規劃領域定義語言 (PDDL) 的生成，為 AI 規劃開啟了新的研究主題，特別是對於複雜的真實世界任務。本文介紹 Image2PDDL，這是一個新穎的框架，它利用視覺語言模型 (VLM) 將初始狀態的影像和目標狀態的描述自動轉換為 PDDL 問題。透過提供 PDDL 領域和視覺輸入，Imasge2PDDL 應對了將感知理解與符號規劃結合起來的主要挑戰，減少了建立結構化問題實例所需的專業知識，並提高了跨越不同複雜性任務的可擴充性。我們在各種領域對該框架進行評估，包括標準規劃領域，例如積木世界和滑動拼圖，使用具有多個難度等級的資料集。效能評估包括語法正確性，確保語法和可執行性，以及內容正確性，驗證生成的 PDDL 問題中的準確狀態表示。所提出的方法在不同的任務複雜性中展示了有希望的結果，表明其在 AI 規劃中具有更廣泛的應用潛力。我們將討論自閉症譜系障礙學生的機器人輔助教學中的潛在用例。

##### **Exploring Vision Language Models for Multimodal and Multilingual Stance Detection**
2501.17654v1 by Jake Vasilakes, Carolina Scarton, Zhixue Zhao

Social media's global reach amplifies the spread of information, highlighting
the need for robust Natural Language Processing tasks like stance detection
across languages and modalities. Prior research predominantly focuses on
text-only inputs, leaving multimodal scenarios, such as those involving both
images and text, relatively underexplored. Meanwhile, the prevalence of
multimodal posts has increased significantly in recent years. Although
state-of-the-art Vision-Language Models (VLMs) show promise, their performance
on multimodal and multilingual stance detection tasks remains largely
unexamined. This paper evaluates state-of-the-art VLMs on a newly extended
dataset covering seven languages and multimodal inputs, investigating their use
of visual cues, language-specific performance, and cross-modality interactions.
Our results show that VLMs generally rely more on text than images for stance
detection and this trend persists across languages. Additionally, VLMs rely
significantly more on text contained within the images than other visual
content. Regarding multilinguality, the models studied tend to generate
consistent predictions across languages whether they are explicitly
multilingual or not, although there are outliers that are incongruous with
macro F1, language support, and model size.

摘要：社群媒體的全球影響力擴大了資訊的傳播，突顯了對健全自然語言處理任務的需求，例如跨語言和模態的立場偵測。先前的研究主要集中在純文字輸入上，而將涉及影像和文字的多模態場景留作相對未經探索的領域。同時，近年來多模態貼文的盛行已大幅增加。儘管最先進的視覺語言模型 (VLM) 顯示出前景，但它們在多模態和多語言立場偵測任務中的表現仍未經過廣泛檢驗。本文評估了最先進的 VLM，採用一個新擴充的資料集，涵蓋七種語言和多模態輸入，探討它們對視覺線索的使用、特定語言的表現以及跨模態互動。我們的結果顯示，VLM 一般更依賴文字而非影像進行立場偵測，而且這種趨勢在各語言間持續存在。此外，VLM 更顯著地依賴影像中包含的文字，而非其他視覺內容。關於多語言性，所研究的模型傾向於在各語言間產生一致的預測，無論它們是否明確地支援多語言，儘管有一些異常值與巨觀 F1、語言支援和模型大小不一致。

##### **Tonguescape: Exploring Language Models Understanding of Vowel Articulation**
2501.17643v1 by Haruki Sakajo, Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe

Vowels are primarily characterized by tongue position. Humans have discovered
these features of vowel articulation through their own experience and explicit
objective observation such as using MRI. With this knowledge and our
experience, we can explain and understand the relationship between tongue
positions and vowels, and this knowledge is helpful for language learners to
learn pronunciation. Since language models (LMs) are trained on a large amount
of data that includes linguistic and medical fields, our preliminary studies
indicate that an LM is able to explain the pronunciation mechanisms of vowels.
However, it is unclear whether multi-modal LMs, such as vision LMs, align
textual information with visual information. One question arises: do LMs
associate real tongue positions with vowel articulation? In this study, we
created video and image datasets from the existing real-time MRI dataset and
investigated whether LMs can understand vowel articulation based on tongue
positions using vision-based information. Our findings suggest that LMs exhibit
potential for understanding vowels and tongue positions when reference examples
are provided while they have difficulties without them. Our code for dataset
building is available on GitHub.

摘要：元音主要由舌頭位置決定。人類透過自己的經驗和明確的客觀觀察（例如使用 MRI）發現了元音發音的這些特徵。有了這些知識和經驗，我們可以解釋和理解舌頭位置和元音之間的關係，而這些知識對語言學習者學習發音很有幫助。由於語言模型 (LM) 是在包含語言學和醫學領域的大量資料上訓練的，我們的初步研究表明，LM 能夠解釋元音的發音機制。然而，尚不清楚多模態 LM（例如視覺 LM）是否將文字資訊與視覺資訊對齊。一個問題產生了：LM 是否將真實的舌頭位置與元音發音聯繫起來？在這項研究中，我們從現有的即時 MRI 資料集中建立了影片和影像資料集，並探討 LM 是否能根據舌頭位置使用基於視覺的資訊來理解元音發音。我們的研究結果表明，當提供參考範例時，LM 具有理解元音和舌頭位置的潛力，而沒有參考範例時則有困難。我們用於建立資料集的程式碼可在 GitHub 上取得。

##### **In-Context Meta LoRA Generation**
2501.17635v1 by Yihua Shao, Minxi Yan, Yang Liu, Siyu Chen, Wenjie Chen, Xinwei Long, Ziyang Yan, Lei Li, Chenyu Zhang, Nicu Sebe, Hao Tang, Yan Wang, Hao Zhao, Mengzhu Wang, Jingcai Guo

Low-rank Adaptation (LoRA) has demonstrated remarkable capabilities for task
specific fine-tuning. However, in scenarios that involve multiple tasks,
training a separate LoRA model for each one results in considerable
inefficiency in terms of storage and inference. Moreover, existing parameter
generation methods fail to capture the correlations among these tasks, making
multi-task LoRA parameter generation challenging. To address these limitations,
we propose In-Context Meta LoRA (ICM-LoRA), a novel approach that efficiently
achieves task-specific customization of large language models (LLMs).
Specifically, we use training data from all tasks to train a tailored
generator, Conditional Variational Autoencoder (CVAE). CVAE takes task
descriptions as inputs and produces task-aware LoRA weights as outputs. These
LoRA weights are then merged with LLMs to create task-specialized models
without the need for additional fine-tuning. Furthermore, we utilize in-context
meta-learning for knowledge enhancement and task mapping, to capture the
relationship between tasks and parameter distributions. As a result, our method
achieves more accurate LoRA parameter generation for diverse tasks using CVAE.
ICM-LoRA enables more accurate LoRA parameter reconstruction than current
parameter reconstruction methods and is useful for implementing task-specific
enhancements of LoRA parameters. At the same time, our method occupies 283MB,
only 1\% storage compared with the original LoRA.

摘要：低秩適應（LoRA）已展現出針對特定任務進行微調的卓越能力。然而，在涉及多項任務的場景中，為每個任務訓練一個獨立的 LoRA 模型會導致儲存和推論方面的顯著低效率。此外，現有的參數生成方法無法捕捉這些任務之間的關聯性，使得多任務 LoRA 參數生成具有挑戰性。為了解決這些限制，我們提出了情境元 LoRA（ICM-LoRA），這是一種新穎的方法，可有效實現大型語言模型（LLM）的特定任務自訂。具體來說，我們使用來自所有任務的訓練資料來訓練一個量身打造的生成器，條件變異自動編碼器（CVAE）。CVAE 將任務描述作為輸入，並產生與任務相關的 LoRA 權重作為輸出。然後將這些 LoRA 權重與 LLM 合併，以建立特定於任務的模型，而不需要額外的微調。此外，我們利用情境元學習來增強知識和任務對應，以捕捉任務和參數分佈之間的關係。因此，我們的模型使用 CVAE 針對不同的任務實現更準確的 LoRA 參數生成。與目前的參數重建方法相比，ICM-LoRA 能更準確地重建 LoRA 參數，並且有助於實作 LoRA 參數的特定任務增強。同時，我們的模型佔用 283MB，與原始 LoRA 相比，儲存量僅為 1%。

##### **The Imitation Game According To Turing**
2501.17629v1 by Sharon Temtsin, Diane Proudfoot, David Kaber, Christoph Bartneck

The current cycle of hype and anxiety concerning the benefits and risks to
human society of Artificial Intelligence is fuelled, not only by the increasing
use of generative AI and other AI tools by the general public, but also by
claims made on behalf of such technology by popularizers and scientists. In
particular, recent studies have claimed that Large Language Models (LLMs) can
pass the Turing Test-a goal for AI since the 1950s-and therefore can "think".
Large-scale impacts on society have been predicted as a result. Upon detailed
examination, however, none of these studies has faithfully applied Turing's
original instructions. Consequently, we conducted a rigorous Turing Test with
GPT-4-Turbo that adhered closely to Turing's instructions for a three-player
imitation game. We followed established scientific standards where Turing's
instructions were ambiguous or missing. For example, we performed a
Computer-Imitates-Human Game (CIHG) without constraining the time duration and
conducted a Man-Imitates-Woman Game (MIWG) as a benchmark. All but one
participant correctly identified the LLM, showing that one of today's most
advanced LLMs is unable to pass a rigorous Turing Test. We conclude that recent
extravagant claims for such models are unsupported, and do not warrant either
optimism or concern about the social impact of thinking machines.

摘要：當前關於人工智慧對人類社會的利弊的炒作和焦慮循環，不僅是由於公眾對生成式 AI 和其他 AI 工具的使用日益增加，還由於推廣者和科學家對此類技術提出的主張。特別是，最近的研究聲稱大型語言模型 (LLM) 可以通過圖靈測試——自 1950 年代以來 AI 的目標——因此可以「思考」。預測這將對社會產生大規模影響。然而，經過仔細檢查，這些研究都沒有忠實地應用圖靈的原始說明。因此，我們對 GPT-4-Turbo 進行了一項嚴格的圖靈測試，嚴格遵守圖靈對三人模仿遊戲的說明。在圖靈的說明模棱兩可或缺失的情況下，我們遵循既定的科學標準。例如，我們進行了一場計算機模仿人類遊戲 (CIHG)，沒有限制時間，並進行了一場男人模仿女人遊戲 (MIWG) 作為基準。除了參與者正確地識別了 LLM 之外，所有參與者都正確地識別了 LLM，這表明當今最先進的 LLM 之一無法通過嚴格的圖靈測試。我們得出結論，最近對此類模型的誇張說法得不到支持，也不保證對思考機器對社會影響的樂觀或擔憂。

##### **Uncertainty Quantification and Decomposition for LLM-based Recommendation**
2501.17630v1 by Wonbin Kweon, Sanghwan Jang, SeongKu Kang, Hwanjo Yu

Despite the widespread adoption of large language models (LLMs) for
recommendation, we demonstrate that LLMs often exhibit uncertainty in their
recommendations. To ensure the trustworthy use of LLMs in generating
recommendations, we emphasize the importance of assessing the reliability of
recommendations generated by LLMs. We start by introducing a novel framework
for estimating the predictive uncertainty to quantitatively measure the
reliability of LLM-based recommendations. We further propose to decompose the
predictive uncertainty into recommendation uncertainty and prompt uncertainty,
enabling in-depth analyses of the primary source of uncertainty. Through
extensive experiments, we (1) demonstrate predictive uncertainty effectively
indicates the reliability of LLM-based recommendations, (2) investigate the
origins of uncertainty with decomposed uncertainty measures, and (3) propose
uncertainty-aware prompting for a lower predictive uncertainty and enhanced
recommendation. Our source code and model weights are available at
https://github.com/WonbinKweon/UNC_LLM_REC_WWW2025

摘要：儘管大型語言模型 (LLM) 已廣泛用於推薦，但我們證明 LLM 通常在其推薦中表現出不確定性。為了確保在產生推薦時可信賴地使用 LLM，我們強調評估 LLM 產生的推薦之可靠性的重要性。我們首先介紹一個新的架構，用於估計預測不確定性，以量化衡量基於 LLM 的推薦之可靠性。我們進一步提出將預測不確定性分解為推薦不確定性和提示不確定性，從而深入分析不確定性的主要來源。透過廣泛的實驗，我們 (1) 證明預測不確定性有效地表示基於 LLM 的推薦之可靠性，(2) 調查具有分解不確定性測量的來源，以及 (3) 提出對不確定性有意識的提示，以降低預測不確定性和增強推薦。我們的原始碼和模型權重可在 https://github.com/WonbinKweon/UNC_LLM_REC_WWW2025 取得

##### **Structured Context Recomposition for Large Language Models Using Probabilistic Layer Realignment**
2501.17617v1 by Jonathan Teel, Jocasta Cumberbatch, Raphael Benington, Quentin Baskerville

Extended sequence generation often leads to degradation in contextual
consistency due to the inability of conventional self-attention mechanisms to
effectively retain long-range dependencies. Existing approaches, including
memory compression and retrieval-augmented conditioning, introduce
computational trade-offs that either increase inference latency or impose
additional storage overhead. Structured Context Recomposition (SCR) introduces
a probabilistic layer realignment strategy that dynamically adjusts learned
representations within transformer layers, ensuring that semantically relevant
embeddings persist throughout extended transformations. The proposed method
enhances coherence retention through a recursive weighting function that
redistributes representational emphasis based on inferred contextual relevance
rather than relying on fixed token-level attention scores. Empirical results
indicate that probabilistic realignment mitigates abrupt topic shifts and
logical inconsistencies, particularly in scenarios where sequences exceed
standard attention window constraints. Sequence-level entropy analysis further
reveals that SCR moderates representational variability without introducing
excessive output regularization, allowing models to sustain generative
diversity while preserving contextual alignment. Attention head deviation
measurements confirm that hierarchical reweighting contributes to smoother
token dependency transitions across transformer layers, reinforcing the
stability of multi-turn interactions and document-level reasoning.
Computational resource assessments show that while SCR incurs a moderate
increase in processing time, memory overhead remains within feasible limits,
making it suitable for practical deployment in autoregressive generative
applications.

摘要：長序列生成通常會導致背景一致性降低，因為傳統的自我注意機制無法有效保留長距離依賴關係。現有方法，包括記憶壓縮和檢索增強條件，會引入計算權衡，這些權衡會增加推理延遲或造成額外的儲存空間負擔。結構化背景重組 (SCR) 引入機率層重新對齊策略，它會動態調整Transformer層中的學習表徵，確保語義相關的嵌入在整個延伸轉換中持續存在。所提出的方法透過遞迴加權函數增強一致性保留，這個函數根據推論的背景相關性重新分配表徵重點，而不是依賴固定的代碼級別注意力分數。實證結果顯示，機率重新對齊可減緩突然的主題轉換和邏輯不一致，特別是在序列超過標準注意力視窗限制的情況下。序列級別熵分析進一步揭示，SCR 可調節表徵變異性，而不會引入過度的輸出正規化，讓模型在維持背景對齊的同時，持續生成多樣性。注意力頭部偏差測量確認，階層式重新加權有助於Transformer層之間更順暢的代碼依賴關係轉換，強化多回合互動和文件級推理的穩定性。計算資源評估顯示，儘管 SCR 會造成處理時間適度增加，但記憶體負擔仍維持在可行範圍內，使其適用於自迴歸生成式應用程式的實際部署。

##### **Cross-lingual Embedding Clustering for Hierarchical Softmax in Low-Resource Multilingual Speech Recognition**
2501.17615v1 by Zhengdong Yang, Qianying Liu, Sheng Li, Fei Cheng, Chenhui Chu

We present a novel approach centered on the decoding stage of Automatic
Speech Recognition (ASR) that enhances multilingual performance, especially for
low-resource languages. It utilizes a cross-lingual embedding clustering method
to construct a hierarchical Softmax (H-Softmax) decoder, which enables similar
tokens across different languages to share similar decoder representations. It
addresses the limitations of the previous Huffman-based H-Softmax method, which
relied on shallow features in token similarity assessments. Through experiments
on a downsampled dataset of 15 languages, we demonstrate the effectiveness of
our approach in improving low-resource multilingual ASR accuracy.

摘要：我們提出了一種新穎的方法，專注於自動語音識別 (ASR) 的解碼階段，可以增強多語言效能，特別是對於低資源語言。它利用跨語言嵌入式群集方法來建構階層式 Softmax (H-Softmax) 解碼器，這使得不同語言中的相似符號可以共用相似的解碼器表示。它解決了先前基於 Huffman 的 H-Softmax 方法的限制，該方法依賴於符號相似性評估中的淺層特徵。透過對 15 種語言的降採樣資料集進行實驗，我們證明了我們的方法在提升低資源多語言 ASR 準確度方面的有效性。

##### **VoicePrompter: Robust Zero-Shot Voice Conversion with Voice Prompt and Conditional Flow Matching**
2501.17612v1 by Ha-Yeong Choi, Jaehan Park

Despite remarkable advancements in recent voice conversion (VC) systems,
enhancing speaker similarity in zero-shot scenarios remains challenging. This
challenge arises from the difficulty of generalizing and adapting speaker
characteristics in speech within zero-shot environments, which is further
complicated by mismatch between the training and inference processes. To
address these challenges, we propose VoicePrompter, a robust zero-shot VC model
that leverages in-context learning with voice prompts. VoicePrompter is
composed of (1) a factorization method that disentangles speech components and
(2) a DiT-based conditional flow matching (CFM) decoder that conditions on
these factorized features and voice prompts. Additionally, (3) latent mixup is
used to enhance in-context learning by combining various speaker features. This
approach improves speaker similarity and naturalness in zero-shot VC by
applying mixup to latent representations. Experimental results demonstrate that
VoicePrompter outperforms existing zero-shot VC systems in terms of speaker
similarity, speech intelligibility, and audio quality. Our demo is available at
\url{https://hayeong0.github.io/VoicePrompter-demo/}.

摘要：儘管最近的語音轉換 (VC) 系統有顯著的進展，但在零次學習場景中增強說話者相似性仍然具有挑戰性。這個挑戰來自於在零次學習環境中概化和適應語音中說話者特徵的難度，而訓練和推論過程之間的不匹配進一步複雜化了這個挑戰。為了應對這些挑戰，我們提出了 VoicePrompter，這是一個強大的零次學習 VC 模型，它利用語音提示進行情境學習。VoicePrompter 由 (1) 一個分解語音組成的分解方法和 (2) 一個基於 DiT 的條件流匹配 (CFM) 解碼器組成，它以這些分解的特徵和語音提示為條件。此外，(3) 潛在混淆用於透過結合各種說話者特徵來增強情境學習。這種方法透過將混淆應用於潛在表徵來改善零次學習 VC 中的說話者相似性和自然性。實驗結果表明，VoicePrompter 在說話者相似性、語音清晰度和音訊品質方面優於現有的零次學習 VC 系統。我們的示範可以在 \url{https://hayeong0.github.io/VoicePrompter-demo/} 中取得。

##### **Semantic Consistency Regularization with Large Language Models for Semi-supervised Sentiment Analysis**
2501.17598v1 by Kunrong Li, Xinyu Liu, Zhen Chen

Accurate sentiment analysis of texts is crucial for a variety of
applications, such as understanding customer feedback, monitoring market
trends, and detecting public sentiment. However, manually annotating large
sentiment corpora for supervised learning is labor-intensive and
time-consuming. Therefore, it is essential and effective to develop a
semi-supervised method for the sentiment analysis task. Although some methods
have been proposed for semi-supervised text classification, they rely on the
intrinsic information within the unlabeled data and the learning capability of
the NLP model, which lack generalization ability to the sentiment analysis
scenario and may prone to overfit. Inspired by the ability of pretrained Large
Language Models (LLMs) in following instructions and generating coherent text,
we propose a Semantic Consistency Regularization with Large Language Models
(SCR) framework for semi-supervised sentiment analysis. We introduce two
prompting strategies to semantically enhance unlabeled text using LLMs. The
first is Entity-based Enhancement (SCR-EE), which involves extracting entities
and numerical information, and querying the LLM to reconstruct the textual
information. The second is Concept-based Enhancement (SCR-CE), which directly
queries the LLM with the original sentence for semantic reconstruction.
Subsequently, the LLM-augmented data is utilized for a consistency loss with
confidence thresholding, which preserves high-quality agreement samples to
provide additional supervision signals during training. Furthermore, to fully
utilize the uncertain unlabeled data samples, we propose a class re-assembling
strategy inspired by the class space shrinking theorem. Experiments show our
method achieves remarkable performance over prior semi-supervised methods.

摘要：準確的情感分析對於各種應用程式至關重要，例如了解客戶回饋、監控市場趨勢和偵測公眾情緒。然而，手動註解大型情感語料庫以進行監督式學習既費力又費時。因此，開發一種半監督式的情感分析任務方法至關重要且有效。儘管已經提出了一些半監督式文本分類方法，但它們依賴於未標記資料中的內在資訊和 NLP 模型的學習能力，這缺乏對情感分析情境的概括能力，並且可能容易過度擬合。受到預訓練大型語言模型 (LLM) 在遵循說明和生成連貫文本方面的能力的啟發，我們提出了一個具有大型語言模型 (SCR) 的語義一致性正則化框架，用於半監督式情感分析。我們引入了兩種提示策略，以使用 LLM 語義增強未標記文本。第一個是基於實體的增強 (SCR-EE)，它涉及提取實體和數字資訊，並查詢 LLM 以重建文本資訊。第二個是基於概念的增強 (SCR-CE)，它直接查詢具有語義重建功能的原始句子的 LLM。隨後，將 LLM 擴充的資料用於具有信心閾值的稠密損失，這保留了高品質的一致性樣本，以便在訓練期間提供額外的監督訊號。此外，為了充分利用不確定的未標記資料樣本，我們提出了一個類別重新組裝策略，其靈感來自類別空間縮減定理。實驗表明，我們的模型比先前的半監督式方法取得了顯著的效能。

##### **GLLM: Self-Corrective G-Code Generation using Large Language Models with User Feedback**
2501.17584v1 by Mohamed Abdelaal, Samuel Lokadjaja, Gilbert Engert

This paper introduces GLLM, an innovative tool that leverages Large Language
Models (LLMs) to automatically generate G-code from natural language
instructions for Computer Numerical Control (CNC) machining. GLLM addresses the
challenges of manual G-code writing by bridging the gap between human-readable
task descriptions and machine-executable code. The system incorporates a
fine-tuned StarCoder-3B model, enhanced with domain-specific training data and
a Retrieval-Augmented Generation (RAG) mechanism. GLLM employs advanced
prompting strategies and a novel self-corrective code generation approach to
ensure both syntactic and semantic correctness of the generated G-code. The
architecture includes robust validation mechanisms, including syntax checks,
G-code-specific verifications, and functional correctness evaluations using
Hausdorff distance. By combining these techniques, GLLM aims to democratize CNC
programming, making it more accessible to users without extensive programming
experience while maintaining high accuracy and reliability in G-code
generation.

摘要：這篇論文介紹 GLLM，這是一個創新的工具，它利用大型語言模型 (LLM) 從自然語言指令自動產生 G 程式碼，用於電腦數值控制 (CNC) 加工。GLLM 透過橋接人類可讀的工作描述和機器可執行的程式碼，解決了手動撰寫 G 程式碼的挑戰。此系統結合了經過微調的 StarCoder-3B 模型，並透過特定領域的訓練資料和檢索擴充產生 (RAG) 機制加以強化。GLLM 採用進階的提示策略和新穎的自訂正程式碼產生方法，以確保產生的 G 程式碼在語法和語義上皆正確無誤。此架構包含強健的驗證機制，包括語法檢查、特定於 G 程式碼的驗證，以及使用 Hausdorff 距離進行的功能正確性評估。透過結合這些技術，GLLM 旨在讓 CNC 編程民主化，讓沒有豐富程式設計經驗的使用者也能更輕鬆上手，同時在 G 程式碼產生過程中維持高準確度和可靠度。

##### **CSEval: Towards Automated, Multi-Dimensional, and Reference-Free Counterspeech Evaluation using Auto-Calibrated LLMs**
2501.17581v1 by Amey Hengle, Aswini Kumar, Anil Bandhakavi, Tanmoy Chakraborty

Counterspeech has been popular as an effective approach to counter online
hate speech, leading to increasing research interest in automated counterspeech
generation using language models. However, this field lacks standardised
evaluation protocols and robust automated evaluation metrics that align with
human judgement. Current automatic evaluation methods, primarily based on
similarity metrics, do not effectively capture the complex and independent
attributes of counterspeech quality, such as contextual relevance,
aggressiveness, or argumentative coherence. This has led to an increased
dependency on labor-intensive human evaluations to assess automated
counter-speech generation methods. To address these challenges, we introduce
CSEval, a novel dataset and framework for evaluating counterspeech quality
across four dimensions: contextual-relevance, aggressiveness,
argument-coherence, and suitableness. Furthermore, we propose Auto-Calibrated
COT for Counterspeech Evaluation (ACE), a prompt-based method with
auto-calibrated chain-of-thoughts (CoT) for scoring counterspeech using large
language models. Our experiments show that ACE outperforms traditional metrics
like ROUGE, METEOR, and BertScore in correlating with human judgement,
indicating a significant advancement in automated counterspeech evaluation.

摘要：反論言論一直被視為對抗網路仇恨言論的有效方法，導致人們對使用語言模型進行自動反論言論產生的研究興趣日益增加。然而，這個領域缺乏標準化的評估協定和與人類判斷一致的穩健自動評估指標。目前的自動評估方法主要基於相似性指標，無法有效捕捉反論言論品質的複雜且獨立屬性，例如上下文相關性、攻擊性或論證一致性。這導致對勞力密集型人類評估的依賴性增加，以評估自動反論言論產生方法。為了應對這些挑戰，我們引入了 CSEval，這是一個新的資料集和框架，用於評估反論言論品質的四個面向：上下文相關性、攻擊性、論證一致性和適宜性。此外，我們提出了用於反論言論評估的自動校準 COT（ACE），這是一種基於提示的方法，具有自動校準的思考鏈（CoT），用於使用大型語言模型對反論言論進行評分。我們的實驗表明，ACE 在與人類判斷相關方面優於傳統指標，例如 ROUGE、METEOR 和 BertScore，這表示自動反論言論評估有了顯著進展。

##### **Music2Latent2: Audio Compression with Summary Embeddings and Autoregressive Decoding**
2501.17578v1 by Marco Pasini, Stefan Lattner, George Fazekas

Efficiently compressing high-dimensional audio signals into a compact and
informative latent space is crucial for various tasks, including generative
modeling and music information retrieval (MIR). Existing audio autoencoders,
however, often struggle to achieve high compression ratios while preserving
audio fidelity and facilitating efficient downstream applications. We introduce
Music2Latent2, a novel audio autoencoder that addresses these limitations by
leveraging consistency models and a novel approach to representation learning
based on unordered latent embeddings, which we call summary embeddings. Unlike
conventional methods that encode local audio features into ordered sequences,
Music2Latent2 compresses audio signals into sets of summary embeddings, where
each embedding can capture distinct global features of the input sample. This
enables to achieve higher reconstruction quality at the same compression ratio.
To handle arbitrary audio lengths, Music2Latent2 employs an autoregressive
consistency model trained on two consecutive audio chunks with causal masking,
ensuring coherent reconstruction across segment boundaries. Additionally, we
propose a novel two-step decoding procedure that leverages the denoising
capabilities of consistency models to further refine the generated audio at no
additional cost. Our experiments demonstrate that Music2Latent2 outperforms
existing continuous audio autoencoders regarding audio quality and performance
on downstream tasks. Music2Latent2 paves the way for new possibilities in audio
compression.

摘要：有效地將高維度音訊訊號壓縮成緊湊且具資訊性的潛在空間對於各種任務至關重要，包括生成式模型和音樂資訊檢索 (MIR)。然而，現有的音訊自動編碼器在保持音訊保真度和促進有效的下游應用時，通常難以實現高壓縮率。我們介紹 Music2Latent2，這是一個新穎的音訊自動編碼器，它透過利用一致性模型和一種基於無序潛在嵌入的表徵學習新方法來解決這些限制，我們稱之為摘要嵌入。與將局部音訊特徵編碼成有序序列的傳統方法不同，Music2Latent2 將音訊訊號壓縮成摘要嵌入集合，其中每個嵌入都可以擷取輸入樣本的不同全局特徵。這能夠在相同的壓縮率下實現更高的重建品質。為了處理任意的音訊長度，Music2Latent2 使用自迴歸一致性模型，該模型在兩個連續的音訊區塊上訓練，並使用因果遮罩，確保跨區段邊界的連貫重建。此外，我們提出了一種新穎的兩步解碼程序，它利用了一致性模型的去噪能力，以進一步改善生成的音訊，而無需額外成本。我們的實驗表明，Music2Latent2 在音訊品質和下游任務的效能方面優於現有的連續音訊自動編碼器。Music2Latent2 為音訊壓縮的新可能性鋪平了道路。

##### **A linguistically-motivated evaluation methodology for unraveling model's abilities in reading comprehension tasks**
2501.17569v1 by Elie Antoine, Frédéric Béchet, Géraldine Damnati, Philippe Langlais

We introduce an evaluation methodology for reading comprehension tasks based
on the intuition that certain examples, by the virtue of their linguistic
complexity, consistently yield lower scores regardless of model size or
architecture. We capitalize on semantic frame annotation for characterizing
this complexity, and study seven complexity factors that may account for
model's difficulty. We first deploy this methodology on a carefully annotated
French reading comprehension benchmark showing that two of those complexity
factors are indeed good predictors of models' failure, while others are less
so. We further deploy our methodology on a well studied English benchmark by
using Chat-GPT as a proxy for semantic annotation. Our study reveals that
fine-grained linguisticallymotivated automatic evaluation of a reading
comprehension task is not only possible, but helps understand models' abilities
to handle specific linguistic characteristics of input examples. It also shows
that current state-of-the-art models fail with some for those characteristics
which suggests that adequately handling them requires more than merely
increasing model size.

摘要：我們基於以下直覺，提出一個用於閱讀理解任務的評估方法：某些範例由於其語言複雜性，始終會產生較低的分數，而與模型大小或架構無關。我們利用語義框架標註來表徵這種複雜性，並研究可能導致模型困難的七個複雜性因素。我們首先在一個經過仔細標註的法文閱讀理解基準上部署此方法，顯示其中兩個複雜性因素確實是模型失敗的良好預測指標，而其他因素則不然。我們進一步在一個經過深入研究的英文基準上部署我們的評估方法，使用 Chat-GPT 作為語義標註的代理。我們的研究表明，對閱讀理解任務進行細緻的語言激勵自動評估不僅是可能的，而且有助於了解模型處理輸入範例的特定語言特徵的能力。它還顯示，當前最先進的模型在某些特徵上會失敗，這表明適當地處理它們需要的不僅僅是增加模型大小。

##### **Exploring the Potential of Wireless-enabled Multi-Chip AI Accelerators**
2501.17567v1 by Emmanuel Irabor, Mariam Musavi, Abhijit Das, Sergi Abadal

The insatiable appetite of Artificial Intelligence (AI) workloads for
computing power is pushing the industry to develop faster and more efficient
accelerators. The rigidity of custom hardware, however, conflicts with the need
for scalable and versatile architectures capable of catering to the needs of
the evolving and heterogeneous pool of Machine Learning (ML) models in the
literature. In this context, multi-chiplet architectures assembling multiple
(perhaps heterogeneous) accelerators are an appealing option that is
unfortunately hindered by the still rigid and inefficient chip-to-chip
interconnects. In this paper, we explore the potential of wireless technology
as a complement to existing wired interconnects in this multi-chiplet approach.
Using an evaluation framework from the state-of-the-art, we show that wireless
interconnects can lead to speedups of 10% on average and 20% maximum. We also
highlight the importance of load balancing between the wired and wireless
interconnects, which will be further explored in future work.

摘要：人工智慧（AI）工作負載對運算能力的貪婪胃口正推動產業開發更快速且更有效率的加速器。然而，客製化硬體的僵化性與可擴充且多功能架構的需求產生衝突，而這些架構有能力滿足文獻中不斷演進且異質的機器學習（ML）模型的需求。在此脈絡下，組裝多個（可能是異質的）加速器的多晶片架構是一個誘人的選擇，但不幸的是，受到仍然僵化且低效率的晶片間互連阻礙。在本文中，我們探討無線技術作為此多晶片方法中現有有線互連的補充的潛力。使用來自最新技術的評估架構，我們顯示無線互連平均可提升 10% 的速度，最高可提升 20%。我們也強調有線和無線互連之間負載平衡的重要性，這將在未來的研究中進一步探討。

##### **Solving Urban Network Security Games: Learning Platform, Benchmark, and Challenge for AI Research**
2501.17559v1 by Shuxin Zhuang, Shuxin Li, Tianji Yang, Muheng Li, Xianjie Shi, Bo An, Youzhi Zhang

After the great achievement of solving two-player zero-sum games, more and
more AI researchers focus on solving multiplayer games. To facilitate the
development of designing efficient learning algorithms for solving multiplayer
games, we propose a multiplayer game platform for solving Urban Network
Security Games (\textbf{UNSG}) that model real-world scenarios. That is,
preventing criminal activity is a highly significant responsibility assigned to
police officers in cities, and police officers have to allocate their limited
security resources to interdict the escaping criminal when a crime takes place
in a city. This interaction between multiple police officers and the escaping
criminal can be modeled as a UNSG. The variants of UNSGs can model different
real-world settings, e.g., whether real-time information is available or not,
and whether police officers can communicate or not. The main challenges of
solving this game include the large size of the game and the co-existence of
cooperation and competition. While previous efforts have been made to tackle
UNSGs, they have been hampered by performance and scalability issues.
Therefore, we propose an open-source UNSG platform (\textbf{GraphChase}) for
designing efficient learning algorithms for solving UNSGs. Specifically,
GraphChase offers a unified and flexible game environment for modeling various
variants of UNSGs, supporting the development, testing, and benchmarking of
algorithms. We believe that GraphChase not only facilitates the development of
efficient algorithms for solving real-world problems but also paves the way for
significant advancements in algorithmic development for solving general
multiplayer games.

摘要：<paragraph>在解決兩人零和博弈獲得重大成就後，越來越多的 AI 研究人員專注於解決多人博弈。為了促進設計用於解決多人博弈的有效學習演算法的開發，我們提出一個多人博弈平台，用於解決模擬真實世界場景的城市網路安全博弈 (UNSG)。也就是說，防止犯罪活動是分配給城市中警察人員的一項極其重要的責任，而警察人員必須在城市中發生犯罪時分配其有限的安全資源來阻止逃逸的罪犯。警察人員和逃逸罪犯之間的這種互動可以建模為 UNSG。UNSG 的變體可以模擬不同的真實世界設定，例如，是否可以使用即時資訊，以及警察人員是否可以溝通。解決此博弈的主要挑戰包括博弈規模龐大，以及合作與競爭並存。儘管之前已做出努力來解決 UNSG，但它們受到效能和可擴充性的問題所阻礙。因此，我們提出一個開源 UNSG 平台 (GraphChase)，用於設計用於解決 UNSG 的有效學習演算法。具體來說，GraphChase 提供一個統一且靈活的博弈環境，用於模擬 UNSG 的各種變體，支援演算法的開發、測試和基準測試。我們相信 GraphChase 不僅促進開發用於解決真實世界問題的有效演算法，也為解決一般多人博弈的演算法開發鋪平了道路。</paragraph>

##### **An Exceptional Dataset For Rare Pancreatic Tumor Segmentation**
2501.17555v1 by Wenqi Li, Yingli Chen, Keyang Zhou, Xiaoxiao Hu, Zilu Zheng, Yue Yan, Xinpeng Zhang, Wei Tang, Zhenxing Qian

Pancreatic NEuroendocrine Tumors (pNETs) are very rare endocrine neoplasms
that account for less than 5% of all pancreatic malignancies, with an incidence
of only 1-1.5 cases per 100,000. Early detection of pNETs is critical for
improving patient survival, but the rarity of pNETs makes segmenting them from
CT a very challenging problem. So far, there has not been a dataset
specifically for pNETs available to researchers. To address this issue, we
propose a pNETs dataset, a well-annotated Contrast-Enhanced Computed Tomography
(CECT) dataset focused exclusively on Pancreatic Neuroendocrine Tumors,
containing data from 469 patients. This is the first dataset solely dedicated
to pNETs, distinguishing it from previous collections. Additionally, we provide
the baseline detection networks with a new slice-wise weight loss function
designed for the UNet-based model, improving the overall pNET segmentation
performance. We hope that our dataset can enhance the understanding and
diagnosis of pNET Tumors within the medical community, facilitate the
development of more accurate diagnostic tools, and ultimately improve patient
outcomes and advance the field of oncology.

摘要：胰臟神經內分泌腫瘤 (pNETs) 是非常罕見的內分泌腫瘤，僅佔所有胰臟惡性腫瘤的不到 5%，每 100,000 人中僅發生 1-1.5 個病例。早期發現 pNETs 對改善患者存活率至關重要，但 pNETs 的罕見性使得從 CT 中分割它們成為一個非常具有挑戰性的問題。到目前為止，還沒有專門針對 pNETs 的數據集可供研究人員使用。為了解決這個問題，我們提出了一個 pNETs 數據集，一個專注於胰臟神經內分泌腫瘤的標註良好的對比增強電腦斷層掃描 (CECT) 數據集，包含來自 469 名患者的數據。這是第一個專門針對 pNETs 的數據集，這使其有別於之前的收集。此外，我們為基線檢測網路提供了一個新的基於 UNet 模型設計的切片加權損失函數，改善了整體 pNET 分割性能。我們希望我們的數據集能夠增強醫學界對 pNET 腫瘤的理解和診斷，促進更準確的診斷工具的開發，最終改善患者的預後並推進腫瘤學領域。

##### **Query-Aware Learnable Graph Pooling Tokens as Prompt for Large Language Models**
2501.17549v1 by Wooyoung Kim, Byungyoon Park, Wooju Kim

Graph-structured data plays a vital role in numerous domains, such as social
networks, citation networks, commonsense reasoning graphs and knowledge graphs.
While graph neural networks have been employed for graph processing, recent
advancements have explored integrating large language models for graph-based
tasks. In this paper, we propose a novel approach named Learnable Graph Pooling
Token (LGPT), which addresses the limitations of the scalability issues in
node-level projection and information loss in graph-level projection. LGPT
enables flexible and efficient graph representation by introducing learnable
parameters that act as tokens in large language models, balancing fine-grained
and global graph information. Additionally, we investigate an Early Query
Fusion technique, which fuses query context before constructing the graph
representation, leading to more effective graph embeddings. Our method achieves
a 4.13\% performance improvement on the GraphQA benchmark without training the
large language model, demonstrating significant gains in handling complex
textual-attributed graph data.

摘要：圖形結構資料在許多領域中扮演著至關重要的角色，例如社交網路、引用網路、常識推理圖形和知識圖形。雖然圖形神經網路已用於圖形處理，但最近的進展已探討整合大型語言模型以進行基於圖形的任務。在本文中，我們提出了一種名為可學習圖形池化令牌 (LGPT) 的新方法，它解決了節點層級投影中的可擴充性問題和圖形層級投影中的資訊遺失限制。LGPT 透過引入可學習的參數（在大型語言模型中作為令牌運作）來啟用彈性和高效的圖形表示，平衡細粒度和整體圖形資訊。此外，我們研究了一種早期查詢融合技術，它在建構圖形表示之前融合查詢內容，進而產生更有效的圖形嵌入。我們的方法在 GraphQA 基準上達到了 4.13% 的效能提升，而無需訓練大型語言模型，證明了在處理複雜的文字屬性圖形資料方面有顯著的進展。

##### **Is Conversational XAI All You Need? Human-AI Decision Making With a Conversational XAI Assistant**
2501.17546v1 by Gaole He, Nilay Aishwarya, Ujwal Gadiraju

Explainable artificial intelligence (XAI) methods are being proposed to help
interpret and understand how AI systems reach specific predictions. Inspired by
prior work on conversational user interfaces, we argue that augmenting existing
XAI methods with conversational user interfaces can increase user engagement
and boost user understanding of the AI system. In this paper, we explored the
impact of a conversational XAI interface on users' understanding of the AI
system, their trust, and reliance on the AI system. In comparison to an XAI
dashboard, we found that the conversational XAI interface can bring about a
better understanding of the AI system among users and higher user trust.
However, users of both the XAI dashboard and conversational XAI interfaces
showed clear overreliance on the AI system. Enhanced conversations powered by
large language model (LLM) agents amplified over-reliance. Based on our
findings, we reason that the potential cause of such overreliance is the
illusion of explanatory depth that is concomitant with both XAI interfaces. Our
findings have important implications for designing effective conversational XAI
interfaces to facilitate appropriate reliance and improve human-AI
collaboration. Code can be found at
https://github.com/delftcrowd/IUI2025_ConvXAI

摘要：可解釋人工智慧 (XAI) 方法被提出用於幫助解釋並理解人工智慧系統如何達成特定預測。受對話式使用者介面的先前研究啟發，我們主張透過對話式使用者介面擴充現有的 XAI 方法，可以提升使用者的參與度並增強使用者對人工智慧系統的理解。在本文中，我們探討了對話式 XAI 介面對使用者理解人工智慧系統、其信任度和對人工智慧系統的依賴性的影響。與 XAI 儀表板相比，我們發現對話式 XAI 介面可以讓使用者對人工智慧系統有更深入的理解，以及更高的使用者信任度。然而，XAI 儀表板和對話式 XAI 介面的使用者都清楚地展現出過度依賴人工智慧系統的現象。由大型語言模型 (LLM) 代理增強的對話會放大過度依賴。根據我們的研究結果，我們推論這種過度依賴的潛在原因是與這兩個 XAI 介面同時存在的解釋深度錯覺。我們的研究結果對設計有效對話式 XAI 介面以促進適當依賴並改善人機協作具有重要的意義。程式碼可以在 https://github.com/delftcrowd/IUI2025_ConvXAI 找到

##### **LLM Assistance for Pediatric Depression**
2501.17510v1 by Mariia Ignashina, Paulina Bondaronek, Dan Santel, John Pestian, Julia Ive

Traditional depression screening methods, such as the PHQ-9, are particularly
challenging for children in pediatric primary care due to practical
limitations. AI has the potential to help, but the scarcity of annotated
datasets in mental health, combined with the computational costs of training,
highlights the need for efficient, zero-shot approaches. In this work, we
investigate the feasibility of state-of-the-art LLMs for depressive symptom
extraction in pediatric settings (ages 6-24). This approach aims to complement
traditional screening and minimize diagnostic errors.
  Our findings show that all LLMs are 60% more efficient than word match, with
Flan leading in precision (average F1: 0.65, precision: 0.78), excelling in the
extraction of more rare symptoms like "sleep problems" (F1: 0.92) and
"self-loathing" (F1: 0.8). Phi strikes a balance between precision (0.44) and
recall (0.60), performing well in categories like "Feeling depressed" (0.69)
and "Weight change" (0.78). Llama 3, with the highest recall (0.90),
overgeneralizes symptoms, making it less suitable for this type of analysis.
Challenges include the complexity of clinical notes and overgeneralization from
PHQ-9 scores. The main challenges faced by LLMs include navigating the complex
structure of clinical notes with content from different times in the patient
trajectory, as well as misinterpreting elevated PHQ-9 scores.
  We finally demonstrate the utility of symptom annotations provided by Flan as
features in an ML algorithm, which differentiates depression cases from
controls with high precision of 0.78, showing a major performance boost
compared to a baseline that does not use these features.

摘要：<paragraph>傳統的憂鬱症篩檢方法，例如 PHQ-9，由於實際限制，對於小兒科初級照護中的兒童來說特別具有挑戰性。AI 有可能提供幫助，但心理健康中註解資料集的稀少，加上訓練的運算成本，突顯了對有效率的零次學習方法的需求。在這項工作中，我們探討了最先進的 LLM 在小兒科環境（6-24 歲）中提取憂鬱症狀的可行性。這種方法旨在補充傳統篩檢並將診斷錯誤降至最低。我們的研究結果顯示，所有 LLM 的效率都比字詞比對高出 60%，而 Flan 在精確度方面領先（平均 F1：0.65，精確度：0.78），在提取較罕見的症狀方面表現出色，例如「睡眠問題」（F1：0.92）和「自我厭惡」（F1：0.8）。Phi 在精確度（0.44）和召回率（0.60）之間取得平衡，在「感到沮喪」（0.69）和「體重改變」（0.78）等類別中表現良好。擁有最高召回率（0.90）的 Llama 3 會過度概括症狀，使其不太適合此類分析。挑戰包括臨床筆記的複雜性和 PHQ-9 分數的過度概括。LLM 面臨的主要挑戰包括在患者歷程中不同時間的內容中導航臨床筆記的複雜結構，以及誤解 PHQ-9 分數升高。我們最後展示了 Flan 提供的症狀註解作為機器學習演算法中特徵的效用，它以 0.78 的高精確度將憂鬱症病例與對照組區分開來，與不使用這些特徵的基準相比，顯示出主要的效能提升。</paragraph>

##### **Neural Spelling: A Spell-Based BCI System for Language Neural Decoding**
2501.17489v1 by Xiaowei Jiang, Charles Zhou, Yiqun Duan, Ziyi Zhao, Thomas Do, Chin-Teng Lin

Brain-computer interfaces (BCIs) present a promising avenue by translating
neural activity directly into text, eliminating the need for physical actions.
However, existing non-invasive BCI systems have not successfully covered the
entire alphabet, limiting their practicality. In this paper, we propose a novel
non-invasive EEG-based BCI system with Curriculum-based Neural Spelling
Framework, which recognizes all 26 alphabet letters by decoding neural signals
associated with handwriting first, and then apply a Generative AI (GenAI) to
enhance spell-based neural language decoding tasks. Our approach combines the
ease of handwriting with the accessibility of EEG technology, utilizing
advanced neural decoding algorithms and pre-trained large language models
(LLMs) to translate EEG patterns into text with high accuracy. This system show
how GenAI can improve the performance of typical spelling-based neural language
decoding task, and addresses the limitations of previous methods, offering a
scalable and user-friendly solution for individuals with communication
impairments, thereby enhancing inclusive communication options.

摘要：腦機介面 (BCI) 透過將神經活動直接轉換成文字，提供了消除身體動作需求的途徑。然而，現有的非侵入式 BCI 系統並未成功涵蓋所有字母，限制了其實用性。在本文中，我們提出了一種新的基於 EEG 的非侵入式 BCI 系統，該系統採用基於課程的神經拼寫架構，透過先解碼與手寫相關的神經訊號來辨識所有 26 個字母，然後應用生成式 AI (GenAI) 來增強基於拼寫的神經語言解碼任務。我們的做法結合了手寫的容易性與 EEG 技術的可及性，利用先進的神經解碼演算法和預先訓練的大語言模型 (LLM) 將 EEG 模式轉換為具有高準確度的文字。此系統展示了 GenAI 如何改善典型的基於拼寫的神經語言解碼任務的效能，並解決了先前方法的限制，為有溝通障礙的個人提供可擴充且友善的解決方案，進而增強包容性的溝通選項。

##### **DINT Transformer**
2501.17486v1 by Yueyang Cang, Yuhang Liu, Xiaoteng Zhang, Erlu Zhao, Li Shi

DIFF Transformer addresses the issue of irrelevant context interference by
introducing a differential attention mechanism that enhances the robustness of
local attention. However, it has two critical limitations: the lack of global
context modeling, which is essential for identifying globally significant
tokens, and numerical instability due to the absence of strict row
normalization in the attention matrix. To overcome these challenges, we propose
DINT Transformer, which extends DIFF Transformer by incorporating a
differential-integral mechanism. By computing global importance scores and
integrating them into the attention matrix, DINT Transformer improves its
ability to capture global dependencies. Moreover, the unified parameter design
enforces row-normalized attention matrices, improving numerical stability.
Experimental results demonstrate that DINT Transformer excels in accuracy and
robustness across various practical applications, such as long-context language
modeling and key information retrieval. These results position DINT Transformer
as a highly effective and promising architecture.

摘要：DIFF Transformer 透過導入強化局部注意力穩健性的微分注意力機制，來解決無關背景干擾的問題。然而，它有兩個重大的限制：缺乏整體背景建模，這對於識別整體重要的符號至關重要，以及由於注意力矩陣中缺乏嚴格的行正規化而導致數值不穩定。為了克服這些挑戰，我們提出了 DINT Transformer，它透過納入微分積分機制來擴充 DIFF Transformer。透過計算整體重要性分數並將它們整合到注意力矩陣中，DINT Transformer 改善了其捕捉整體依賴性的能力。此外，統一參數設計強制執行行正規化的注意力矩陣，改善了數值穩定性。實驗結果表明，DINT Transformer 在各種實際應用中表現出卓越的準確性和穩健性，例如長背景語言建模和關鍵資訊檢索。這些結果將 DINT Transformer 定位為一個高效且有前景的架構。

##### **DFPE: A Diverse Fingerprint Ensemble for Enhancing LLM Performance**
2501.17479v1 by Seffi Cohen, Niv Goldshlager, Nurit Cohen-Inger, Bracha Shapira, Lior Rokach

Large Language Models (LLMs) have shown remarkable capabilities across
various natural language processing tasks but often struggle to excel uniformly
in diverse or complex domains. We propose a novel ensemble method - Diverse
Fingerprint Ensemble (DFPE), which leverages the complementary strengths of
multiple LLMs to achieve more robust performance. Our approach involves: (1)
clustering models based on response "fingerprints" patterns, (2) applying a
quantile-based filtering mechanism to remove underperforming models at a
per-subject level, and (3) assigning adaptive weights to remaining models based
on their subject-wise validation accuracy. In experiments on the Massive
Multitask Language Understanding (MMLU) benchmark, DFPE outperforms the best
single model by 3% overall accuracy and 5% in discipline-level accuracy. This
method increases the robustness and generalization of LLMs and underscores how
model selection, diversity preservation, and performance-driven weighting can
effectively address challenging, multi-faceted language understanding tasks.

摘要：大型語言模型 (LLM) 在各種自然語言處理任務中展現出非凡的能力，但通常難以在多元或複雜的領域中全面表現優異。我們提出了一種新穎的整體方法 - 多元指紋整體 (DFPE)，它利用多個 LLM 的互補優勢來實現更穩健的效能。我們的方法包括：(1) 根據回應「指紋」模式對模型進行分群，(2) 應用基於分位數的過濾機制來移除在每個主題層級表現不佳的模型，以及 (3) 根據模型在每個主題的驗證準確度，為其分配自適應權重。在 Massive Multitask Language Understanding (MMLU) 基準測試的實驗中，DFPE 在整體準確度上優於最佳單一模型 3%，在學科層級準確度上優於 5%。此方法增加了 LLM 的穩健性和泛化性，並強調模型選擇、多元性保留和效能驅動的加權如何能有效地解決具有挑戰性的多面向語言理解任務。

##### **Large Language Models for Single-Step and Multi-Step Flight Trajectory Prediction**
2501.17459v1 by Kaiwei Luo, Jiliu Zhou

Flight trajectory prediction is a critical time series task in aviation.
While deep learning methods have shown significant promise, the application of
large language models (LLMs) to this domain remains underexplored. This study
pioneers the use of LLMs for flight trajectory prediction by reframing it as a
language modeling problem. Specifically, We extract features representing the
aircraft's position and status from ADS-B flight data to construct a
prompt-based dataset, where trajectory waypoints are converted into language
tokens. The dataset is then employed to fine-tune LLMs, enabling them to learn
complex spatiotemporal patterns for accurate predictions. Comprehensive
experiments demonstrate that LLMs achieve notable performance improvements in
both single-step and multi-step predictions compared to traditional methods,
with LLaMA-3.1 model achieving the highest overall accuracy. However, the high
inference latency of LLMs poses a challenge for real-time applications,
underscoring the need for further research in this promising direction.

摘要：飛行軌跡預測是航空領域中一個關鍵的時間序列任務。
儘管深度學習方法已展現出顯著前景，但大型語言模型 (LLM) 在此領域的應用仍未得到充分探索。本研究率先將 LLM 用於飛行軌跡預測，方法是將其重新定義為一個語言建模問題。具體來說，我們從 ADS-B 飛行數據中提取表示飛機位置和狀態的特征，以構建一個基於提示的數據集，其中軌跡航點被轉換為語言符號。然後使用該數據集對 LLM 進行微調，使其能夠學習複雜的時空模式，從而進行準確的預測。全面的實驗表明，與傳統方法相比，LLM 在單步和多步預測中都取得了顯著的性能提升，其中 LLaMA-3.1 模型達到了最高的整體準確率。然而，LLM 的高推理延遲對實時應用構成了挑戰，這強調了在這一有前景的方向上進行進一步研究的必要性。

##### **Cross-Language Approach for Quranic QA**
2501.17449v1 by Islam Oshallah, Mohamed Basem, Ali Hamdi, Ammar Mohammed

Question answering systems face critical limitations in languages with
limited resources and scarce data, making the development of robust models
especially challenging. The Quranic QA system holds significant importance as
it facilitates a deeper understanding of the Quran, a Holy text for over a
billion people worldwide. However, these systems face unique challenges,
including the linguistic disparity between questions written in Modern Standard
Arabic and answers found in Quranic verses written in Classical Arabic, and the
small size of existing datasets, which further restricts model performance. To
address these challenges, we adopt a cross-language approach by (1) Dataset
Augmentation: expanding and enriching the dataset through machine translation
to convert Arabic questions into English, paraphrasing questions to create
linguistic diversity, and retrieving answers from an English translation of the
Quran to align with multilingual training requirements; and (2) Language Model
Fine-Tuning: utilizing pre-trained models such as BERT-Medium, RoBERTa-Base,
DeBERTa-v3-Base, ELECTRA-Large, Flan-T5, Bloom, and Falcon to address the
specific requirements of Quranic QA. Experimental results demonstrate that this
cross-language approach significantly improves model performance, with
RoBERTa-Base achieving the highest MAP@10 (0.34) and MRR (0.52), while
DeBERTa-v3-Base excels in Recall@10 (0.50) and Precision@10 (0.24). These
findings underscore the effectiveness of cross-language strategies in
overcoming linguistic barriers and advancing Quranic QA systems

摘要：<paragraph>問答系統在資源有限且資料稀少的語言中面臨嚴重的限制，這使得建立穩健模型特別具有挑戰性。古蘭經問答系統具有重要的意義，因為它促進了對古蘭經的深入理解，而古蘭經是全球超過十億人的神聖文本。然而，這些系統面臨著獨特的挑戰，包括以現代標準阿拉伯語寫成的問題與以古典阿拉伯語寫成的古蘭經經文中發現的答案之間的語言差異，以及現有資料集規模小，進一步限制了模型的效能。為了應對這些挑戰，我們採用跨語言方法，包括：(1) 資料集擴充：透過機器翻譯將阿拉伯語問題轉換成英語、改寫問題以創造語言多樣性，以及從古蘭經的英文翻譯中擷取答案以符合多語言訓練需求，來擴充和豐富資料集；以及 (2) 語言模型微調：利用預先訓練的模型，例如 BERT-Medium、RoBERTa-Base、DeBERTa-v3-Base、ELECTRA-Large、Flan-T5、Bloom 和 Falcon，來滿足古蘭經問答的特定需求。實驗結果表明，這種跨語言方法顯著提升了模型效能，其中 RoBERTa-Base 在 MAP@10 (0.34) 和 MRR (0.52) 方面取得最高成就，而 DeBERTa-v3-Base 則在 Recall@10 (0.50) 和 Precision@10 (0.24) 方面表現出色。這些發現強調了跨語言策略在克服語言障礙和推進古蘭經問答系統方面的有效性</paragraph>

##### **Towards Making Flowchart Images Machine Interpretable**
2501.17441v1 by Shreya Shukla, Prajwal Gatti, Yogesh Kumar, Vikash Yadav, Anand Mishra

Computer programming textbooks and software documentations often contain
flowcharts to illustrate the flow of an algorithm or procedure. Modern OCR
engines often tag these flowcharts as graphics and ignore them in further
processing. In this paper, we work towards making flowchart images
machine-interpretable by converting them to executable Python codes. To this
end, inspired by the recent success in natural language to code generation
literature, we present a novel transformer-based framework, namely FloCo-T5.
Our model is well-suited for this task,as it can effectively learn semantics,
structure, and patterns of programming languages, which it leverages to
generate syntactically correct code. We also used a task-specific pre-training
objective to pre-train FloCo-T5 using a large number of logic-preserving
augmented code samples. Further, to perform a rigorous study of this problem,
we introduce theFloCo dataset that contains 11,884 flowchart images and their
corresponding Python codes. Our experiments show promising results, and
FloCo-T5 clearly outperforms related competitive baselines on code generation
metrics. We make our dataset and implementation publicly available.

摘要：電腦程式教科書和軟體文件常包含流程圖，以說明演算法或程序的流程。現代 OCR 引擎常將這些流程圖標籤為圖形，並在後續處理中忽略它們。在本文中，我們致力於讓流程圖影像可供機器解讀，方法是將它們轉換為可執行的 Python 程式碼。為此，受到自然語言生成程式碼的最新進展啟發，我們提出一個新穎的基於轉換器的架構，稱為 FloCo-T5。我們的模型非常適合此任務，因為它可以有效地學習程式語言的語意、結構和模式，並利用這些知識來產生語法正確的程式碼。我們還使用特定於任務的預訓練目標，使用大量的邏輯保留擴充程式碼範例來預訓練 FloCo-T5。此外，為了對這個問題進行嚴謹的研究，我們引入了 FloCo 資料集，其中包含 11,884 張流程圖影像及其對應的 Python 程式碼。我們的實驗顯示出有希望的結果，而 FloCo-T5 在程式碼產生指標上明顯優於相關的競爭基線。我們公開提供我們的資料集和實作。

##### **Virus: Harmful Fine-tuning Attack for Large Language Models Bypassing Guardrail Moderation**
2501.17433v1 by Tiansheng Huang, Sihao Hu, Fatih Ilhan, Selim Furkan Tekin, Ling Liu

Recent research shows that Large Language Models (LLMs) are vulnerable to
harmful fine-tuning attacks -- models lose their safety alignment ability after
fine-tuning on a few harmful samples. For risk mitigation, a guardrail is
typically used to filter out harmful samples before fine-tuning. By designing a
new red-teaming method, we in this paper show that purely relying on the
moderation guardrail for data filtration is not reliable. Our proposed attack
method, dubbed Virus, easily bypasses the guardrail moderation by slightly
modifying the harmful data. Experimental results show that the harmful data
optimized by Virus is not detectable by the guardrail with up to 100\% leakage
ratio, and can simultaneously achieve superior attack performance. Finally, the
key message we want to convey through this paper is that: \textbf{it is
reckless to consider guardrail moderation as a clutch at straws towards harmful
fine-tuning attack}, as it cannot solve the inherent safety issue of the
pre-trained LLMs. Our code is available at https://github.com/git-disl/Virus

摘要：最近的研究表明，大型语言模型 (LLM) 容易受到有害微调攻击——模型在对几个有害样本进行微调后会失去其安全对齐能力。为了降低风险，通常使用护栏在微调之前过滤掉有害样本。通过设计一种新的红队方法，我们在本文中表明，单纯依赖调节护栏进行数据过滤并不可靠。我们提出的攻击方法，称为 Virus，通过略微修改有害数据轻松绕过护栏调节。实验结果表明，Virus 优化的有害数据在高达 100% 的泄漏率下无法被护栏检测到，并且可以同时实现卓越的攻击性能。最后，我们希望通过本文传达的关键信息是：\textbf{将护栏调节视为对有害微调攻击的救命稻草是鲁莽的}，因为它无法解决预训练 LLM 固有的安全问题。我们的代码可在 https://github.com/git-disl/Virus 获得

##### **Algorithmic Segmentation and Behavioral Profiling for Ransomware Detection Using Temporal-Correlation Graphs**
2501.17429v1 by Ignatius Rollere, Caspian Hartsfield, Seraphina Courtenay, Lucian Fenwick, Aurelia Grunwald

The rapid evolution of cyber threats has outpaced traditional detection
methodologies, necessitating innovative approaches capable of addressing the
adaptive and complex behaviors of modern adversaries. A novel framework was
introduced, leveraging Temporal-Correlation Graphs to model the intricate
relationships and temporal patterns inherent in malicious operations. The
approach dynamically captured behavioral anomalies, offering a robust mechanism
for distinguishing between benign and malicious activities in real-time
scenarios. Extensive experiments demonstrated the framework's effectiveness
across diverse ransomware families, with consistently high precision, recall,
and overall detection accuracy. Comparative evaluations highlighted its better
performance over traditional signature-based and heuristic methods,
particularly in handling polymorphic and previously unseen ransomware variants.
The architecture was designed with scalability and modularity in mind, ensuring
compatibility with enterprise-scale environments while maintaining resource
efficiency. Analysis of encryption speeds, anomaly patterns, and temporal
correlations provided deeper insights into the operational strategies of
ransomware, validating the framework's adaptability to evolving threats. The
research contributes to advancing cybersecurity technologies by integrating
dynamic graph analytics and machine learning for future innovations in threat
detection. Results from this study underline the potential for transforming the
way organizations detect and mitigate complex cyberattacks.

摘要：網路威脅快速演化已超越傳統偵測方法，因此需要創新方法來因應現代對手適應性強且複雜的行為。一個新架構應運而生，利用時間關聯圖形來模擬惡意操作中複雜的關係和時間模式。這種方法動態擷取行為異常，提供一種強健的機制，用於在實際情況中區分良性和惡意活動。廣泛的實驗證明了該架構在各種勒索軟體系列中都非常有效，始終保持高精準度、召回率和整體偵測準確度。比較評估強調了它比傳統的基於簽章和啟發式方法有更好的效能，特別是在處理多形性和以前未見過的勒索軟體變種方面。此架構在設計時考量了可擴充性和模組化，確保與企業規模環境相容，同時維持資源效率。對加密速度、異常模式和時間關聯性的分析提供了更深入的見解，了解勒索軟體的操作策略，驗證了該架構對不斷演變的威脅具有適應性。這項研究透過整合動態圖形分析和機器學習，為威脅偵測的未來創新做出貢獻，有助於推動網路安全技術的進步。這項研究的結果強調了轉變組織偵測和緩解複雜網路攻擊方式的潛力。

##### **Actions Speak Louder than Words: Agent Decisions Reveal Implicit Biases in Language Models**
2501.17420v1 by Yuxuan Li, Hirokazu Shirado, Sauvik Das

While advances in fairness and alignment have helped mitigate overt biases
exhibited by large language models (LLMs) when explicitly prompted, we
hypothesize that these models may still exhibit implicit biases when simulating
human behavior. To test this hypothesis, we propose a technique to
systematically uncover such biases across a broad range of sociodemographic
categories by assessing decision-making disparities among agents with
LLM-generated, sociodemographically-informed personas. Using our technique, we
tested six LLMs across three sociodemographic groups and four decision-making
scenarios. Our results show that state-of-the-art LLMs exhibit significant
sociodemographic disparities in nearly all simulations, with more advanced
models exhibiting greater implicit biases despite reducing explicit biases.
Furthermore, when comparing our findings to real-world disparities reported in
empirical studies, we find that the biases we uncovered are directionally
aligned but markedly amplified. This directional alignment highlights the
utility of our technique in uncovering systematic biases in LLMs rather than
random variations; moreover, the presence and amplification of implicit biases
emphasizes the need for novel strategies to address these biases.

摘要：<paragraph>雖然公平性和對齊的進展有助於減輕大型語言模型 (LLM) 在明確提示下表現出的明顯偏見，但我們假設這些模型在模擬人類行為時仍可能表現出隱含偏見。為了驗證這個假設，我們提出了一種技術，通過評估具有 LLM 生成、社會人口統計資料知情角色的代理之間的決策差異，系統地揭示廣泛的社會人口統計類別中的此類偏見。使用我們的技術，我們在三個社會人口統計群組和四個決策制定場景中測試了六個 LLM。我們的結果表明，最先進的 LLM 在幾乎所有模擬中都表現出顯著的社會人口統計差異，儘管減少了明顯偏見，但更先進的模型表現出更大的隱含偏見。此外，當將我們的發現與實證研究中報告的現實世界差異進行比較時，我們發現我們發現的偏見在方向上是一致的，但明顯放大。這種方向一致性突出了我們的技術在揭示 LLM 中的系統性偏見而不是隨機變異方面的效用；此外，隱含偏見的存在和放大強調了需要新的策略來解決這些偏見。</paragraph>

##### **Reqo: A Robust and Explainable Query Optimization Cost Model**
2501.17414v1 by Baoming Chang, Amin Kamali, Verena Kantere

In recent years, there has been a growing interest in using machine learning
(ML) in query optimization to select more efficient plans. Existing
learning-based query optimizers use certain model architectures to convert
tree-structured query plans into representations suitable for downstream ML
tasks. As the design of these architectures significantly impacts cost
estimation, we propose a tree model architecture based on Bidirectional Graph
Neural Networks (Bi-GNN) aggregated by Gated Recurrent Units (GRUs) to achieve
more accurate cost estimates. The inherent uncertainty of data and model
parameters also leads to inaccurate cost estimates, resulting in suboptimal
plans and less robust query performance. To address this, we implement a novel
learning-to-rank cost model that effectively quantifies the uncertainty in cost
estimates using approximate probabilistic ML. This model adaptively integrates
quantified uncertainty with estimated costs and learns from comparing pairwise
plans, achieving more robust performance. In addition, we propose the first
explainability technique specifically designed for learning-based cost models.
This technique explains the contribution of any subgraphs in the query plan to
the final predicted cost, which can be integrated and trained with any
learning-based cost model to significantly boost the model's explainability. By
incorporating these innovations, we propose a cost model for a Robust and
Explainable Query Optimizer, Reqo, that improves the accuracy, robustness, and
explainability of cost estimation, outperforming state-of-the-art approaches in
all three dimensions.

摘要：近年来，人们对在查询优化中使用机器学习 (ML) 来选择更有效的计划越来越感兴趣。现有的基于学习的查询优化器使用特定模型架构将树形结构查询计划转换为适合下游 ML 任务的表示。由于这些架构的设计会显著影响成本估算，我们提出了一种基于双向图神经网络 (Bi-GNN) 的树模型架构，该架构由门控循环单元 (GRU) 聚合，以实现更准确的成本估算。数据和模型参数的固有不确定性也会导致成本估算不准确，从而导致计划不理想和查询性能不佳。为了解决这个问题，我们实现了一个新颖的学习排序成本模型，该模型使用近似概率 ML 有效地量化了成本估算中的不确定性。此模型自适应地将量化的不确定性与估计成本相结合，并从比较成对计划中学习，从而实现更稳健的性能。此外，我们提出了第一个专门为基于学习的成本模型设计的可解释性技术。此技术解释了查询计划中任何子图对最终预测成本的贡献，该技术可以与任何基于学习的成本模型集成并进行训练，以显著提高模型的可解释性。通过结合这些创新，我们为稳健且可解释的查询优化器 Reqo 提出了一种成本模型，该模型提高了成本估算的准确性、稳健性和可解释性，在所有三个维度上都优于最先进的方法。

##### **A Genetic Algorithm-Based Approach for Automated Optimization of Kolmogorov-Arnold Networks in Classification Tasks**
2501.17411v1 by Quan Long, Bin Wang, Bing Xue, Mengjie Zhang

To address the issue of interpretability in multilayer perceptrons (MLPs),
Kolmogorov-Arnold Networks (KANs) are introduced in 2024. However, optimizing
KAN structures is labor-intensive, typically requiring manual intervention and
parameter tuning. This paper proposes GA-KAN, a genetic algorithm-based
approach that automates the optimization of KANs, requiring no human
intervention in the design process. To the best of our knowledge, this is the
first time that evolutionary computation is explored to optimize KANs
automatically. Furthermore, inspired by the use of sparse connectivity in MLPs
in effectively reducing the number of parameters, GA-KAN further explores
sparse connectivity to tackle the challenge of extensive parameter spaces in
KANs. GA-KAN is validated on two toy datasets, achieving optimal results
without the manual tuning required by the original KAN. Additionally, GA-KAN
demonstrates superior performance across five classification datasets,
outperforming traditional methods on all datasets and providing interpretable
symbolic formulae for the Wine and Iris datasets, thereby enhancing model
transparency. Furthermore, GA-KAN significantly reduces the number of
parameters over the standard KAN across all the five datasets. The core
contributions of GA-KAN include automated optimization, a new encoding
strategy, and a new decoding process, which together improve the accuracy and
interpretability, and reduce the number of parameters.

摘要：<paragraph>為了解決多層感知器 (MLP) 中的可解釋性問題，2024 年引入了 Kolmogorov-Arnold 網路 (KAN)。然而，最佳化 KAN 結構是一項耗費大量人力的事務，通常需要人工介入和參數調整。本文提出了 GA-KAN，一種基於遺傳演算法的方法，它自動化了 KAN 的最佳化，在設計過程中無需人工介入。據我們所知，這是首次探索使用演化運算自動最佳化 KAN。此外，受到 MLP 中使用稀疏連線以有效減少參數數量的啟發，GA-KAN 進一步探索稀疏連線，以應對 KAN 中廣泛參數空間的挑戰。GA-KAN 在兩個玩具資料集上進行驗證，在無需原始 KAN 所需的手動調整的情況下，達到了最佳結果。此外，GA-KAN 在五個分類資料集上展現出卓越的效能，在所有資料集上都優於傳統方法，並為葡萄酒和鳶尾花資料集提供了可解釋的符號公式，從而增強了模型透明度。此外，GA-KAN 在所有五個資料集上顯著減少了比標準 KAN 更少的參數。GA-KAN 的核心貢獻包括自動最佳化、新的編碼策略和新的解碼過程，它們共同改進了準確性和可解釋性，並減少了參數數量。</paragraph>

##### **General Scene Adaptation for Vision-and-Language Navigation**
2501.17403v1 by Haodong Hong, Yanyuan Qiao, Sen Wang, Jiajun Liu, Qi Wu

Vision-and-Language Navigation (VLN) tasks mainly evaluate agents based on
one-time execution of individual instructions across multiple environments,
aiming to develop agents capable of functioning in any environment in a
zero-shot manner. However, real-world navigation robots often operate in
persistent environments with relatively consistent physical layouts, visual
observations, and language styles from instructors. Such a gap in the task
setting presents an opportunity to improve VLN agents by incorporating
continuous adaptation to specific environments. To better reflect these
real-world conditions, we introduce GSA-VLN, a novel task requiring agents to
execute navigation instructions within a specific scene and simultaneously
adapt to it for improved performance over time. To evaluate the proposed task,
one has to address two challenges in existing VLN datasets: the lack of OOD
data, and the limited number and style diversity of instructions for each
scene. Therefore, we propose a new dataset, GSA-R2R, which significantly
expands the diversity and quantity of environments and instructions for the R2R
dataset to evaluate agent adaptability in both ID and OOD contexts.
Furthermore, we design a three-stage instruction orchestration pipeline that
leverages LLMs to refine speaker-generated instructions and apply role-playing
techniques to rephrase instructions into different speaking styles. This is
motivated by the observation that each individual user often has consistent
signatures or preferences in their instructions. We conducted extensive
experiments on GSA-R2R to thoroughly evaluate our dataset and benchmark various
methods. Based on our findings, we propose a novel method, GR-DUET, which
incorporates memory-based navigation graphs with an environment-specific
training strategy, achieving state-of-the-art results on all GSA-R2R splits.

摘要：視覺語言導航 (VLN) 任務主要根據代理程式在多個環境中執行個別指令的一次性執行來評估代理程式，旨在開發能夠在任何環境中以零次學習的方式運作的代理程式。然而，真實世界的導航機器人通常在持續性的環境中運作，而這些環境具有相對一致的物理配置、視覺觀察和指令的語言風格。任務設定中的這種差距提供了一個機會，可以透過將連續適應特定環境納入其中來改善 VLN 代理程式。為了更好地反映這些真實世界的條件，我們推出了 GSA-VLN，這是一個新任務，要求代理程式在特定場景中執行導航指令，並同時適應該場景，以隨著時間推移而提高效能。為了評估所提出的任務，必須解決現有 VLN 資料集中的兩個挑戰：缺乏 OOD 資料，以及每個場景的指令數量和風格多樣性有限。因此，我們提出了一個新的資料集 GSA-R2R，它顯著擴展了 R2R 資料集的環境和指令的多樣性和數量，以評估代理程式在 ID 和 OOD 背景下的適應能力。此外，我們設計了一個三階段指令編排管道，該管道利用大型語言模型 (LLM) 來精煉由說話者產生的指令，並應用角色扮演技巧將指令改寫成不同的說話風格。這項技術的靈感來自於觀察到每個個別使用者通常在其指令中具有相符的簽名或偏好。我們針對 GSA-R2R 進行了大量的實驗，以徹底評估我們的資料集和基準各種方法。根據我們的研究結果，我們提出了一種新的方法 GR-DUET，它將基於記憶的導航圖表與特定於環境的訓練策略結合在一起，在所有 GSA-R2R 分割中取得了最先進的結果。

##### **MultiChallenge: A Realistic Multi-Turn Conversation Evaluation Benchmark Challenging to Frontier LLMs**
2501.17399v1 by Ved Sirdeshmukh, Kaustubh Deshpande, Johannes Mols, Lifeng Jin, Ed-Yeremai Cardona, Dean Lee, Jeremy Kritz, Willow Primack, Summer Yue, Chen Xing

We present MultiChallenge, a pioneering benchmark evaluating large language
models (LLMs) on conducting multi-turn conversations with human users, a
crucial yet underexamined capability for their applications. MultiChallenge
identifies four categories of challenges in multi-turn conversations that are
not only common and realistic among current human-LLM interactions, but are
also challenging to all current frontier LLMs. All 4 challenges require
accurate instruction-following, context allocation, and in-context reasoning at
the same time. We also develop LLM as judge with instance-level rubrics to
facilitate an automatic evaluation method with fair agreement with experienced
human raters. Despite achieving near-perfect scores on existing multi-turn
evaluation benchmarks, all frontier models have less than 50% accuracy on
MultiChallenge, with the top-performing Claude 3.5 Sonnet (June 2024) achieving
just a 41.4% average accuracy.

摘要：我們提出 MultiChallenge，一個開創性的基準，用於評估大型語言模型 (LLM) 與人類使用者進行多輪對話的能力，這是一個對其應用至關重要但尚未充分探討的能力。MultiChallenge 識別出多輪對話中的四種類別挑戰，這些挑戰不僅在當前人類與 LLM 的互動中常見且真實，而且對於所有當前的前沿 LLM 來說也是具有挑戰性的。所有 4 個挑戰同時需要準確的指令遵循、上下文分配和上下文推理。我們還開發了具有例項級別評分標準的 LLM 作為評審，以促進一種自動評估方法，該方法與經驗豐富的人類評分員達成公平的一致。儘管在現有的多輪評估基準上取得了接近完美的得分，但所有前沿模型在 MultiChallenge 上的準確率都低於 50%，表現最好的 Claude 3.5 Sonnet（2024 年 6 月）僅達到 41.4% 的平均準確率。

##### **Leveraging In-Context Learning and Retrieval-Augmented Generation for Automatic Question Generation in Educational Domains**
2501.17397v1 by Subhankar Maity, Aniket Deroy, Sudeshna Sarkar

Question generation in education is a time-consuming and cognitively
demanding task, as it requires creating questions that are both contextually
relevant and pedagogically sound. Current automated question generation methods
often generate questions that are out of context. In this work, we explore
advanced techniques for automated question generation in educational contexts,
focusing on In-Context Learning (ICL), Retrieval-Augmented Generation (RAG),
and a novel Hybrid Model that merges both methods. We implement GPT-4 for ICL
using few-shot examples and BART with a retrieval module for RAG. The Hybrid
Model combines RAG and ICL to address these issues and improve question
quality. Evaluation is conducted using automated metrics, followed by human
evaluation metrics. Our results show that both the ICL approach and the Hybrid
Model consistently outperform other methods, including baseline models, by
generating more contextually accurate and relevant questions.

摘要：在教育中產生問題是一項耗時且認知上要求很高的任務，因為它需要產生在脈絡上相關且在教學法上合理的題目。目前的自動化問題產生方法通常會產生脈絡不符的題目。在這項工作中，我們探討了在教育脈絡中自動化產生問題的進階技術，重點在於脈絡學習 (ICL)、檢索增強產生 (RAG) 和一個合併這兩種方法的新型混合模型。我們實作了 GPT-4 來進行 ICL，使用少量的範例，以及 BART 加上檢索模組來進行 RAG。混合模型結合了 RAG 和 ICL 來解決這些問題，並提升問題品質。評估是使用自動化指標進行，接著是人工評估指標。我們的結果顯示，ICL 方法和混合模型都持續優於其他方法，包括基準模型，透過產生更多脈絡上準確且相關的題目。

##### **Learning Free Token Reduction for Multi-Modal LLM**
2501.17391v1 by Zihui Zhao, Yingxin Li, Yang Li

Vision-Language Models (VLMs) have achieved remarkable success across a range
of multimodal tasks; however, their practical deployment is often constrained
by high computational costs and prolonged inference times. Since the vision
modality typically carries more information than the text modality, compressing
visual prompts offers a promising solution to alleviate these challenges.
Existing approaches predominantly focus on refining model architectures or
directly reducing the number of visual tokens. However, these methods often
compromise inference performance due to a lack of consideration for the unique
spatial and temporal characteristics of visual data. In this work, we propose a
token compression paradigm that operates on both spatial and temporal
dimensions. Our approach includes a learning-free, plug-and-play compression
pipeline that can be seamlessly integrated into most Multimodal Large Language
Model (MLLM) frameworks. By leveraging this method, we enhance the model
inference capability while simultaneously reducing its computational cost.
Experimental results on the Video-QA task demonstrate the effectiveness of the
proposed approach, showcasing significant improvements in efficiency without
sacrificing performance.

摘要：視覺語言模型 (VLM) 已在各種多模態任務中取得顯著的成功；然而，其實際部署通常受到高運算成本和延長的推論時間的限制。由於視覺模態通常比文字模態承載更多資訊，因此壓縮視覺提示提供了一個有希望的解決方案來緩解這些挑戰。現有的方法主要集中於優化模型架構或直接減少視覺代碼的數量。然而，這些方法由於沒有考慮視覺資料的獨特空間和時間特徵，因此常常會影響推論效能。在這項工作中，我們提出一個在空間和時間維度上運作的代碼壓縮範例。我們的做法包括一個免學習、即插即用的壓縮管線，可以無縫整合到大多數多模態大型語言模型 (MLLM) 框架中。透過利用這種方法，我們增強了模型推論能力，同時降低了其運算成本。視訊問答任務的實驗結果證明了所提出方法的有效性，展示了在不犧牲效能的情況下顯著提升效率。

##### **Context-Aware Semantic Recomposition Mechanism for Large Language Models**
2501.17386v1 by Richard Katrix, Quentin Carroway, Rowan Hawkesbury, Matthias Heathfield

Context-aware processing mechanisms have increasingly become a critical area
of exploration for improving the semantic and contextual capabilities of
language generation models. The Context-Aware Semantic Recomposition Mechanism
(CASRM) was introduced as a novel framework designed to address limitations in
coherence, contextual adaptability, and error propagation in large-scale text
generation tasks. Through the integration of dynamically generated context
vectors and attention modulation layers, CASRM enhances the alignment between
token-level representations and broader contextual dependencies. Experimental
evaluations demonstrated significant improvements in semantic coherence across
multiple domains, including technical, conversational, and narrative text. The
ability to adapt to unseen domains and ambiguous inputs was evaluated using a
diverse set of test scenarios, highlighting the robustness of the proposed
mechanism. A detailed computational analysis revealed that while CASRM
introduces additional processing overhead, the gains in linguistic precision
and contextual relevance outweigh the marginal increase in complexity. The
framework also successfully mitigates error propagation in sequential tasks,
improving performance in dialogue continuation and multi-step text synthesis.
Additional investigations into token-level attention distribution emphasized
the dynamic focus shifts enabled through context-aware enhancements. The
findings suggest that CASRM offers a scalable and flexible solution for
integrating contextual intelligence into existing language model architectures.

摘要：语境感知处理机制已逐渐成为探索改善语言生成模型语义和语境功能的关键领域。语境感知语义重组机制 (CASRM) 作为一种新颖的框架被引入，旨在解决大规模文本生成任务中的连贯性、语境适应性和错误传播的局限性。通过整合动态生成的语境向量和注意力调节层，CASRM 增强了标记级表征和更广泛的语境依赖性之间的对齐。实验评估表明，在包括技术性、会话性和叙述性文本在内的多个领域中，语义连贯性都有显著提高。使用各种测试场景评估了适应未见领域和模棱两可输入的能力，突出了所提出机制的稳健性。详细的计算分析表明，虽然 CASRM 引入了额外的处理开销，但语言精确性和语境相关性的提升超过了复杂性的边际增加。该框架还成功减轻了顺序任务中的错误传播，提高了对话延续和多步文本合成的性能。对标记级注意力分布的进一步研究强调了通过语境感知增强实现的动态焦点转移。研究结果表明，CASRM 为将语境智能集成到现有语言模型架构中提供了一种可扩展且灵活的解决方案。

##### **A Dual-Agent Adversarial Framework for Robust Generalization in Deep Reinforcement Learning**
2501.17384v1 by Zhengpeng Xie, Jiahang Cao, Yulong Zhang, Qiang Zhang, Renjing Xu

Recently, empowered with the powerful capabilities of neural networks,
reinforcement learning (RL) has successfully tackled numerous challenging
tasks. However, while these models demonstrate enhanced decision-making
abilities, they are increasingly prone to overfitting. For instance, a trained
RL model often fails to generalize to even minor variations of the same task,
such as a change in background color or other minor semantic differences. To
address this issue, we propose a dual-agent adversarial policy learning
framework, which allows agents to spontaneously learn the underlying semantics
without introducing any human prior knowledge. Specifically, our framework
involves a game process between two agents: each agent seeks to maximize the
impact of perturbing on the opponent's policy by producing representation
differences for the same state, while maintaining its own stability against
such perturbations. This interaction encourages agents to learn generalizable
policies, capable of handling irrelevant features from the high-dimensional
observations. Extensive experimental results on the Procgen benchmark
demonstrate that the adversarial process significantly improves the
generalization performance of both agents, while also being applied to various
RL algorithms, e.g., Proximal Policy Optimization (PPO). With the adversarial
framework, the RL agent outperforms the baseline methods by a significant
margin, especially in hard-level tasks, marking a significant step forward in
the generalization capabilities of deep reinforcement learning.

摘要：<paragraph>近期，在神经網路強大功能的加持下，強化學習 (RL) 已成功解決許多具有挑戰性的任務。然而，儘管這些模型展現出增強的決策能力，它們卻越來越容易過度擬合。例如，訓練過的 RL 模型通常無法概括到同一個任務的微小變化，例如背景顏色的改變或其他細微的語義差異。為了解決這個問題，我們提出一個雙代理對抗策略學習框架，該框架允許代理自動學習基礎語義，而無需引入任何人類先驗知識。具體來說，我們的框架涉及兩個代理之間的遊戲過程：每個代理都試圖通過產生相同狀態的表示差異來最大化對對手策略的擾動影響，同時保持其自身對這些擾動的穩定性。這種交互作用鼓勵代理學習可概括的策略，能夠處理高維度觀察中的無關特徵。在 Procgen 基準上的廣泛實驗結果表明，對抗過程顯著提高了兩個代理的泛化效能，同時也應用於各種 RL 演算法，例如近端策略最佳化 (PPO)。有了對抗框架，RL 代理的表現顯著優於基準方法，特別是在高難度任務中，標誌著深度強化學習的泛化能力向前邁進了一大步。</paragraph>

##### **Forecasting S&P 500 Using LSTM Models**
2501.17366v1 by Prashant Pilla, Raji Mekonen

With the volatile and complex nature of financial data influenced by external
factors, forecasting the stock market is challenging. Traditional models such
as ARIMA and GARCH perform well with linear data but struggle with non-linear
dependencies. Machine learning and deep learning models, particularly Long
Short-Term Memory (LSTM) networks, address these challenges by capturing
intricate patterns and long-term dependencies. This report compares ARIMA and
LSTM models in predicting the S&P 500 index, a major financial benchmark.
  Using historical price data and technical indicators, we evaluated these
models using Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE). The
ARIMA model showed reasonable performance with an MAE of 462.1, RMSE of 614,
and 89.8 percent accuracy, effectively capturing short-term trends but limited
by its linear assumptions. The LSTM model, leveraging sequential processing
capabilities, outperformed ARIMA with an MAE of 369.32, RMSE of 412.84, and
92.46 percent accuracy, capturing both short- and long-term dependencies.
Notably, the LSTM model without additional features performed best, achieving
an MAE of 175.9, RMSE of 207.34, and 96.41 percent accuracy, showcasing its
ability to handle market data efficiently.
  Accurately predicting stock movements is crucial for investment strategies,
risk assessments, and market stability. Our findings confirm the potential of
deep learning models in handling volatile financial data compared to
traditional ones. The results highlight the effectiveness of LSTM and suggest
avenues for further improvements. This study provides insights into financial
forecasting, offering a comparative analysis of ARIMA and LSTM while outlining
their strengths and limitations.

摘要：<paragraph>由於金融資料會受到外部因素影響，且波動且複雜，預測股市是一項挑戰。傳統模型（例如 ARIMA 和 GARCH）對於線性資料表現良好，但對於非線性依賴性則有困難。機器學習和深度學習模型，特別是長短期記憶 (LSTM) 網路，透過捕捉複雜模式和長期依賴性來解決這些挑戰。此報告比較了 ARIMA 和 LSTM 模型在預測主要金融基準標普 500 指數的表現。我們使用歷史價格資料和技術指標，使用平均絕對誤差 (MAE) 和均方根誤差 (RMSE) 評估這些模型。ARIMA 模型表現合理，MAE 為 462.1，RMSE 為 614，準確率為 89.8%，有效捕捉短期趨勢，但受到其線性假設的限制。LSTM 模型利用順序處理能力，表現優於 ARIMA，MAE 為 369.32，RMSE 為 412.84，準確率為 92.46%，捕捉短期和長期依賴性。值得注意的是，沒有額外功能的 LSTM 模型表現最佳，MAE 為 175.9，RMSE 為 207.34，準確率為 96.41%，展示其有效處理市場資料的能力。準確預測股票走勢對於投資策略、風險評估和市場穩定至關重要。我們的研究結果證實了深度學習模型在處理波動的金融資料方面的潛力，優於傳統模型。結果突顯了 LSTM 的有效性，並建議進一步改進的途徑。本研究提供了對金融預測的見解，提供了 ARIMA 和 LSTM 的比較分析，同時概述了它們的優點和缺點。</paragraph>

##### **The M-factor: A Novel Metric for Evaluating Neural Architecture Search in Resource-Constrained Environments**
2501.17361v1 by Srikanth Thudumu, Hy Nguyen, Hung Du, Nhat Duong, Zafaryab Rasool, Rena Logothetis, Scott Barnett, Rajesh Vasa, Kon Mouzakis

Neural Architecture Search (NAS) aims to automate the design of deep neural
networks. However, existing NAS techniques often focus on maximising accuracy,
neglecting model efficiency. This limitation restricts their use in
resource-constrained environments like mobile devices and edge computing
systems. Moreover, current evaluation metrics prioritise performance over
efficiency, lacking a balanced approach for assessing architectures suitable
for constrained scenarios. To address these challenges, this paper introduces
the M-factor, a novel metric combining model accuracy and size. Four diverse
NAS techniques are compared: Policy-Based Reinforcement Learning, Regularised
Evolution, Tree-structured Parzen Estimator (TPE), and Multi-trial Random
Search. These techniques represent different NAS paradigms, providing a
comprehensive evaluation of the M-factor. The study analyses ResNet
configurations on the CIFAR-10 dataset, with a search space of 19,683
configurations. Experiments reveal that Policy-Based Reinforcement Learning and
Regularised Evolution achieved M-factor values of 0.84 and 0.82, respectively,
while Multi-trial Random Search attained 0.75, and TPE reached 0.67.
Policy-Based Reinforcement Learning exhibited performance changes after 39
trials, while Regularised Evolution optimised within 20 trials. The research
investigates the optimisation dynamics and trade-offs between accuracy and
model size for each strategy. Findings indicate that, in some cases, random
search performed comparably to more complex algorithms when assessed using the
M-factor. These results highlight how the M-factor addresses the limitations of
existing metrics by guiding NAS towards balanced architectures, offering
valuable insights for selecting strategies in scenarios requiring both
performance and efficiency.

摘要：神經架構搜尋（NAS）旨在自動化深度神經網路的設計。然而，現有的 NAS 技術通常專注於最大化準確度，而忽略模型效率。此限制會限制它們在受資源限制的環境中使用，例如行動裝置和邊緣運算系統。此外，目前的評估指標優先於效率的效能，缺乏平衡的方法來評估適用於受限情境的架構。為了應對這些挑戰，本文引入了 M 因子，這是一個結合模型準確度和大小的新指標。比較了四種不同的 NAS 技術：基於策略的強化學習、正則化演化、樹狀 Parzen 估計器 (TPE) 和多試驗隨機搜尋。這些技術代表不同的 NAS 典範，提供了 M 因子的全面評估。本研究在 CIFAR-10 資料集上分析了 ResNet 組態，其中搜尋空間為 19,683 個組態。實驗表明，基於策略的強化學習和正則化演化分別達到 0.84 和 0.82 的 M 因子值，而多試驗隨機搜尋達到 0.75，TPE 達到 0.67。基於策略的強化學習在 39 次試驗後表現出效能變化，而正則化演化在 20 次試驗內進行最佳化。研究調查了每個策略的最佳化動態以及準確度和模型大小之間的取捨。研究結果表明，在某些情況下，使用 M 因子評估時，隨機搜尋的表現與更複雜的演算法相當。這些結果突出了 M 因子如何透過引導 NAS 採用平衡的架構來解決現有指標的限制，為在需要效能和效率的情況下選擇策略提供有價值的見解。

##### **On the Coexistence and Ensembling of Watermarks**
2501.17356v1 by Aleksandar Petrov, Shruti Agarwal, Philip H. S. Torr, Adel Bibi, John Collomosse

Watermarking, the practice of embedding imperceptible information into media
such as images, videos, audio, and text, is essential for intellectual property
protection, content provenance and attribution. The growing complexity of
digital ecosystems necessitates watermarks for different uses to be embedded in
the same media. However, to detect and decode all watermarks, they need to
coexist well with one another. We perform the first study of coexistence of
deep image watermarking methods and, contrary to intuition, we find that
various open-source watermarks can coexist with only minor impacts on image
quality and decoding robustness. The coexistence of watermarks also opens the
avenue for ensembling watermarking methods. We show how ensembling can increase
the overall message capacity and enable new trade-offs between capacity,
accuracy, robustness and image quality, without needing to retrain the base
models.

摘要：水印，將難以察覺的資訊嵌入媒體（例如圖片、影片、音訊和文字）中的做法，對於智慧財產保護、內容出處和歸屬至關重要。數位生態系統日益複雜，需要將不同用途的水印嵌入同一媒體中。然而，要偵測和解碼所有水印，它們需要彼此良好共存。我們執行深度影像水印方法的共存首次研究，與直覺相反，我們發現各種開源水印可以共存，對影像品質和解碼穩健性僅造成輕微影響。水印的共存也開啟了整合水印方法的途徑。我們展示了整合如何增加整體訊息容量，並在容量、準確度、穩健性和影像品質之間實現新的權衡，而無需重新訓練基礎模型。

##### **Better Slow than Sorry: Introducing Positive Friction for Reliable Dialogue Systems**
2501.17348v1 by Mert İnan, Anthony Sicilia, Suvodip Dey, Vardhan Dongre, Tejas Srinivasan, Jesse Thomason, Gökhan Tür, Dilek Hakkani-Tür, Malihe Alikhani

While theories of discourse and cognitive science have long recognized the
value of unhurried pacing, recent dialogue research tends to minimize friction
in conversational systems. Yet, frictionless dialogue risks fostering
uncritical reliance on AI outputs, which can obscure implicit assumptions and
lead to unintended consequences. To meet this challenge, we propose integrating
positive friction into conversational AI, which promotes user reflection on
goals, critical thinking on system response, and subsequent re-conditioning of
AI systems. We hypothesize systems can improve goal alignment, modeling of user
mental states, and task success by deliberately slowing down conversations in
strategic moments to ask questions, reveal assumptions, or pause. We present an
ontology of positive friction and collect expert human annotations on
multi-domain and embodied goal-oriented corpora. Experiments on these corpora,
along with simulated interactions using state-of-the-art systems, suggest
incorporating friction not only fosters accountable decision-making, but also
enhances machine understanding of user beliefs and goals, and increases task
success rates.

摘要：儘管論述理論和認知科學早已認知到放慢步調的價值，最近的對話研究傾向於最小化對話系統中的摩擦。然而，無摩擦的對話有導致過度依賴 AI 輸出的風險，而這可能會模糊隱含的假設並導致意外的後果。為了應對這項挑戰，我們建議將正向摩擦整合到對話式 AI 中，這會促進使用者反思目標、對系統回應進行批判性思考，以及後續對 AI 系統進行重新調整。我們假設系統可以透過在策略性時刻故意放慢對話速度來詢問問題、揭露假設或暫停，進而改善目標對齊、對使用者心智狀態建模，以及任務成功率。我們提出正向摩擦的本體論，並在多領域和具體目標導向的語料庫上收集專家的人類註解。針對這些語料庫的實驗，以及使用最先進系統進行的模擬互動，表明納入摩擦不僅能促進負責任的決策制定，還能增進機器對使用者信念和目標的理解，並提高任務成功率。

##### **Deep-and-Wide Learning: Enhancing Data-Driven Inference via Synergistic Learning of Inter- and Intra-Data Representations**
2501.17347v1 by Md Tauhidul Islam, Lei Xing

Advancements in deep learning are revolutionizing science and engineering.
The immense success of deep learning is largely due to its ability to extract
essential high-dimensional (HD) features from input data and make inference
decisions based on this information. However, current deep neural network (DNN)
models face several challenges, such as the requirements of extensive amounts
of data and computational resources. Here, we introduce a new learning scheme,
referred to as deep-and-wide learning (DWL), to systematically capture features
not only within individual input data (intra-data features) but also across the
data (inter-data features). Furthermore, we propose a dual-interactive-channel
network (D-Net) to realize the DWL, which leverages our Bayesian formulation of
low-dimensional (LD) inter-data feature extraction and its synergistic
interaction with the conventional HD representation of the dataset, for
substantially enhanced computational efficiency and inference. The proposed
technique has been applied to data across various disciplines for both
classification and regression tasks. Our results demonstrate that DWL surpasses
state-of-the-art DNNs in accuracy by a substantial margin with limited training
data and improves the computational efficiency by order(s) of magnitude. The
proposed DWL strategy dramatically alters the data-driven learning techniques,
including emerging large foundation models, and sheds significant insights into
the evolving field of AI.

摘要：深度學習的進展正在革新科學和工程。
深度學習的巨大成功在很大程度上歸功於它從輸入數據中提取本質高維（HD）特徵並基於此信息做出推論決策的能力。然而，當前的深度神經網路（DNN）模型面臨著諸多挑戰，例如對大量數據和計算資源的需求。在此，我們引入了一種新的學習方案，稱為深度廣度學習（DWL），以系統地捕獲特徵，不僅在個別輸入數據（數據內特徵）中，而且在數據（數據間特徵）中。此外，我們提出了一個雙互動通道網路（D-Net）來實現 DWL，它利用我們對低維（LD）數據間特徵提取的貝葉斯公式及其與數據集的傳統 HD 表示的協同交互作用，以大幅提高計算效率和推理。所提出的技術已應用於各個學科的數據，用於分類和回歸任務。我們的結果表明，DWL 在準確性方面以大幅優勢超越了最先進的 DNN，且訓練數據有限，並將計算效率提高了幾個數量級。所提出的 DWL 策略極大地改變了數據驅動的學習技術，包括新興的大型基礎模型，並對人工智能的演進領域提供了重要的見解。

##### **Post-Training Quantization for 3D Medical Image Segmentation: A Practical Study on Real Inference Engines**
2501.17343v1 by Chongyu Qu, Ritchie Zhao, Ye Yu, Bin Liu, Tianyuan Yao, Junchao Zhu, Bennett A. Landman, Yucheng Tang, Yuankai Huo

Quantizing deep neural networks ,reducing the precision (bit-width) of their
computations, can remarkably decrease memory usage and accelerate processing,
making these models more suitable for large-scale medical imaging applications
with limited computational resources. However, many existing methods studied
"fake quantization", which simulates lower precision operations during
inference, but does not actually reduce model size or improve real-world
inference speed. Moreover, the potential of deploying real 3D low-bit
quantization on modern GPUs is still unexplored. In this study, we introduce a
real post-training quantization (PTQ) framework that successfully implements
true 8-bit quantization on state-of-the-art (SOTA) 3D medical segmentation
models, i.e., U-Net, SegResNet, SwinUNETR, nnU-Net, UNesT, TransUNet,
ST-UNet,and VISTA3D. Our approach involves two main steps. First, we use
TensorRT to perform fake quantization for both weights and activations with
unlabeled calibration dataset. Second, we convert this fake quantization into
real quantization via TensorRT engine on real GPUs, resulting in real-world
reductions in model size and inference latency. Extensive experiments
demonstrate that our framework effectively performs 8-bit quantization on GPUs
without sacrificing model performance. This advancement enables the deployment
of efficient deep learning models in medical imaging applications where
computational resources are constrained. The code and models have been
released, including U-Net, TransUNet pretrained on the BTCV dataset for
abdominal (13-label) segmentation, UNesT pretrained on the Whole Brain Dataset
for whole brain (133-label) segmentation, and nnU-Net, SegResNet, SwinUNETR and
VISTA3D pretrained on TotalSegmentator V2 for full body (104-label)
segmentation. https://github.com/hrlblab/PTQ.

摘要：<paragraph>量化深度神经网络，降低其计算的精度（位宽），可以显著减少内存使用量并加速处理，使这些模型更适合于具有有限计算资源的大规模医学影像应用。然而，许多现有方法研究了“伪量化”，它在推理期间模拟较低精度的操作，但实际上并没有减少模型大小或提高实际推理速度。此外，在现代 GPU 上部署真正的 3D 低位量化的潜力仍未得到探索。在这项研究中，我们引入了一个真正的训练后量化 (PTQ) 框架，该框架成功地在最先进的 (SOTA) 3D 医学分割模型（即 U-Net、SegResNet、SwinUNETR、nnU-Net、UNesT、TransUNet、ST-UNet 和 VISTA3D）上实现了真正的 8 位量化。我们的方法涉及两个主要步骤。首先，我们使用 TensorRT 对权重和激活进行伪量化，并使用未标记的校准数据集。其次，我们将这种伪量化通过真实 GPU 上的 TensorRT 引擎转换为真正的量化，从而在模型大小和推理延迟方面实现了实际的减少。大量的实验表明，我们的框架在 GPU 上有效地执行 8 位量化，而不会牺牲模型性能。这一进步使得在计算资源受限的医学影像应用中部署高效的深度学习模型成为可能。代码和模型已经发布，包括 U-Net、TransUNET，在 BTCV 数据集上预训练用于腹部（13 标签）分割，UNesT 在 Whole Brain 数据集上预训练用于全脑（133 标签）分割，以及 nnU-Net、SegResNet、SwinUNETR 和 VISTA3D 在 TotalSegmentator V2 上预训练用于全身（104 标签）分割。https://github.com/hrlblab/PTQ。</paragraph>

##### **Inferring from Logits: Exploring Best Practices for Decoding-Free Generative Candidate Selection**
2501.17338v1 by Mingyu Derek Ma, Yanna Ding, Zijie Huang, Jianxi Gao, Yizhou Sun, Wei Wang

Generative Language Models rely on autoregressive decoding to produce the
output sequence token by token. Many tasks such as preference optimization,
require the model to produce task-level output consisting of multiple tokens
directly by selecting candidates from a pool as predictions. Determining a
task-level prediction from candidates using the ordinary token-level decoding
mechanism is constrained by time-consuming decoding and interrupted gradients
by discrete token selection. Existing works have been using decoding-free
candidate selection methods to obtain candidate probability from initial output
logits over vocabulary. Though these estimation methods are widely used, they
are not systematically evaluated, especially on end tasks. We introduce an
evaluation of a comprehensive collection of decoding-free candidate selection
approaches on a comprehensive set of tasks, including five multiple-choice QA
tasks with a small candidate pool and four clinical decision tasks with a
massive amount of candidates, some with 10k+ options. We evaluate the
estimation methods paired with a wide spectrum of foundation LMs covering
different architectures, sizes and training paradigms. The results and insights
from our analysis inform the future model design.

摘要：生成語言模型依靠自迴歸解碼來逐個符號產生輸出序列。許多任務（如偏好最佳化）要求模型直接從候選池中選擇預測，產生由多個符號組成的任務級別輸出。使用一般的符號級別解碼機制從候選者中確定任務級別預測受到耗時的解碼和離散符號選擇中斷的梯度的約束。現有工作一直使用無解碼候選者選擇方法從初始輸出邏輯值中獲得候選者機率。儘管這些估計方法被廣泛使用，但它們並未經過系統評估，特別是在最終任務上。我們針對全面的任務集，包括五個具有小型候選者池的多選題問答任務和四個具有大量候選者的臨床決策任務（其中一些有 10k+ 選項），對全面的無解碼候選者選擇方法進行評估。我們評估與廣泛基礎語言模型配對的估計方法，這些模型涵蓋不同的架構、大小和訓練範例。我們分析的結果和見解為未來的模型設計提供了資訊。

##### **Attribution analysis of legal language as used by LLM**
2501.17330v1 by Richard K. Belew

Three publicly-available LLM specifically designed for legal tasks have been
implemented and shown that classification accuracy can benefit from training
over legal corpora, but why and how? Here we use two publicly-available legal
datasets, a simpler binary classification task of ``overruling'' texts, and a
more elaborate multiple choice task identifying ``holding'' judicial decisions.
We report on experiments contrasting the legal LLM and a generic BERT model for
comparison, against both datasets. We use integrated gradient attribution
techniques to impute ``causes'' of variation in the models' perfomance, and
characterize them in terms of the tokenizations each use. We find that while
all models can correctly classify some test examples from the casehold task,
other examples can only be identified by only one, model, and attribution can
be used to highlight the reasons for this. We find that differential behavior
of the models' tokenizers accounts for most of the difference and analyze these
differences in terms of the legal language they process. Frequency analysis of
tokens generated by dataset texts, combined with use of known ``stop word''
lists, allow identification of tokens that are clear signifiers of legal
topics.

摘要：有三個專門設計用於法律任務的公開 LLM 已實施，並顯示分類準確度可以受益於法律語料庫的訓練，但原因和方式為何？在這裡，我們使用兩個公開的法律資料集，一個較簡單的二元分類任務「推翻」文本，以及一個更精細的多選題任務，用於識別「持有」司法決定。我們報告了對比法律 LLM 和通用 BERT 模型的實驗，以針對這兩個資料集進行比較。我們使用整合梯度歸因技術來估算模型效能變化的「原因」，並根據每個模型使用的標記化來描述它們。我們發現，雖然所有模型都可以正確分類案例持有任務中的一些測試範例，但其他範例只能由一個模型識別，而歸因可用於強調這樣做的原因。我們發現，模型標記器的差異行為解釋了大部分差異，並根據它們處理的法律語言分析這些差異。資料集文本產生的標記的頻率分析，結合使用已知的「停止詞」清單，可以識別出法律主題的明確標記。

##### **Memorize and Rank: Elevating Large Language Models for Clinical Diagnosis Prediction**
2501.17326v1 by Mingyu Derek Ma, Xiaoxuan Wang, Yijia Xiao, Anthony Cuturrufo, Vijay S Nori, Eran Halperin, Wei Wang

Clinical diagnosis prediction models, when provided with a patient's medical
history, aim to detect potential diseases early, facilitating timely
intervention and improving prognostic outcomes. However, the inherent scarcity
of patient data and large disease candidate space often pose challenges in
developing satisfactory models for this intricate task. The exploration of
leveraging Large Language Models (LLMs) for encapsulating clinical decision
processes has been limited. We introduce MERA, a clinical diagnosis prediction
model that bridges pertaining natural language knowledge with medical practice.
We apply hierarchical contrastive learning on a disease candidate ranking list
to alleviate the large decision space issue. With concept memorization through
fine-tuning, we bridge the natural language clinical knowledge with medical
codes. Experimental results on MIMIC-III and IV datasets show that MERA
achieves the state-of-the-art diagnosis prediction performance and dramatically
elevates the diagnosis prediction capabilities of generative LMs.

摘要：臨床診斷預測模型在提供患者病歷的同時，旨在及早發現潛在疾病，促進及時干預並改善預後結果。然而，患者數據的固有稀缺性和大量的疾病候選空間通常對開發令人滿意的模型以應對這項複雜的任務構成挑戰。利用大型語言模型 (LLM) 來封裝臨床決策流程的探索受到限制。我們引入了 MERA，這是一個臨床診斷預測模型，它將相關的自然語言知識與醫療實踐聯繫起來。我們在疾病候選排名清單上應用分層對比學習，以緩解大型決策空間問題。通過微調概念記憶，我們將自然語言臨床知識與醫療代碼聯繫起來。在 MIMIC-III 和 IV 數據集上的實驗結果表明，MERA 達到了最先進的診斷預測性能，並顯著提升了生成式 LM 的診斷預測能力。

##### **A sketch of an AI control safety case**
2501.17315v1 by Tomek Korbak, Joshua Clymer, Benjamin Hilton, Buck Shlegeris, Geoffrey Irving

As LLM agents gain a greater capacity to cause harm, AI developers might
increasingly rely on control measures such as monitoring to justify that they
are safe. We sketch how developers could construct a "control safety case",
which is a structured argument that models are incapable of subverting control
measures in order to cause unacceptable outcomes. As a case study, we sketch an
argument that a hypothetical LLM agent deployed internally at an AI company
won't exfiltrate sensitive information. The sketch relies on evidence from a
"control evaluation,"' where a red team deliberately designs models to
exfiltrate data in a proxy for the deployment environment. The safety case then
hinges on several claims: (1) the red team adequately elicits model
capabilities to exfiltrate data, (2) control measures remain at least as
effective in deployment, and (3) developers conservatively extrapolate model
performance to predict the probability of data exfiltration in deployment. This
safety case sketch is a step toward more concrete arguments that can be used to
show that a dangerously capable LLM agent is safe to deploy.

摘要：隨著 LLM 代理造成傷害的能力越來越強，AI 開發人員可能會越來越依賴監控等控制措施來證明它們是安全的。我們概述開發人員如何構建「控制安全案例」，這是一個結構化的論證，說明模型無法顛覆控制措施以造成不可接受的結果。作為一個案例研究，我們概述了一個論證，即在 AI 公司內部部署的假設 LLM 代理不會洩露敏感資訊。這個概要依賴於「控制評估」的證據，其中一個紅色小組故意設計模型來在部署環境的代理中洩露資料。安全案例接著依賴於幾個主張：(1) 紅色小組充分引出模型洩露資料的能力，(2) 控制措施在部署中至少維持同樣的效力，以及 (3) 開發人員保守地推斷模型效能以預測資料在部署中外洩的機率。這個安全案例概要是朝向更具體的論證邁進的一步，可用於證明具有危險能力的 LLM 代理部署是安全的。

##### **Probing LLM World Models: Enhancing Guesstimation with Wisdom of Crowds Decoding**
2501.17310v1 by Yun-Shiuan Chuang, Nikunj Harlalka, Sameer Narendran, Alexander Cheung, Sizhe Gao, Siddharth Suresh, Junjie Hu, Timothy T. Rogers

Guesstimation, the task of making approximate quantity estimates, is a common
real-world challenge. However, it has been largely overlooked in large language
models (LLMs) and vision language models (VLMs) research. We introduce a novel
guesstimation dataset, MARBLES. This dataset requires one to estimate how many
items (e.g., marbles) can fit into containers (e.g., a one-cup measuring cup),
both with and without accompanying images. Inspired by the social science
concept of the ``{Wisdom of Crowds'' (WOC) - taking the median from estimates
from a crowd), which has proven effective in guesstimation, we propose ``WOC
decoding'' strategy for LLM guesstimation. We show that LLMs/VLMs perform well
on guesstimation, suggesting that they possess some level of a "world model"
necessary for guesstimation. Moreover, similar to human performance, the WOC
decoding method improves LLM/VLM guesstimation accuracy. Furthermore, the
inclusion of images in the multimodal condition enhances model performance.
These results highlight the value of WOC decoding strategy for LLMs/VLMs and
position guesstimation as a probe for evaluating LLMs/VLMs' world model.

摘要：估計，即進行近似數量估計的任務，是一個常見的
現實世界挑戰。然而，它在大型語言模型 (LLM) 和視覺語言模型 (VLM) 研究中很大程度上被忽視了。我們引入了一個新穎的估計數據集，MARBLES。此數據集要求人們估計有多少
物品（例如，彈珠）可以放入容器（例如，一個量杯），無論是否附有圖片。受社會科學概念``{群眾的智慧'' (WOC) 的啟發 - 從人群的估計中取中位數），這已被證明在估計中很有效，我們提出了 LLM 估計的``WOC
解碼''策略。我們表明 LLM/VLM 在估計方面表現良好，這表明它們具有一定的估計所需的「世界模型」。此外，與人類表現類似，WOC
解碼方法提高了 LLM/VLM 的估計準確度。此外，在多模態條件中包含圖像可以增強模型性能。
這些結果突出了 WOC 解碼策略對 LLM/VLM 的價值，並將估計定位為評估 LLM/VLM 世界模型的探針。

##### **"Ownership, Not Just Happy Talk": Co-Designing a Participatory Large Language Model for Journalism**
2501.17299v1 by Emily Tseng, Meg Young, Marianne Aubin Le Quéré, Aimee Rinehart, Harini Suresh

Journalism has emerged as an essential domain for understanding the uses,
limitations, and impacts of large language models (LLMs) in the workplace. News
organizations face divergent financial incentives: LLMs already permeate
newswork processes within financially constrained organizations, even as
ongoing legal challenges assert that AI companies violate their copyright. At
stake are key questions about what LLMs are created to do, and by whom: How
might a journalist-led LLM work, and what can participatory design illuminate
about the present-day challenges about adapting ``one-size-fits-all''
foundation models to a given context of use? In this paper, we undertake a
co-design exploration to understand how a participatory approach to LLMs might
address opportunities and challenges around AI in journalism. Our 20 interviews
with reporters, data journalists, editors, labor organizers, product leads, and
executives highlight macro, meso, and micro tensions that designing for this
opportunity space must address. From these desiderata, we describe the result
of our co-design work: organizational structures and functionality for a
journalist-controlled LLM. In closing, we discuss the limitations of commercial
foundation models for workplace use, and the methodological implications of
applying participatory methods to LLM co-design.

摘要：新聞業已浮現為理解大型語言模型 (LLM) 在工作場所中的用途、限制和影響的必要領域。新聞組織面臨不同的財務誘因：LLM 已滲透到財務受限組織的新聞工作流程中，即使持續的法律挑戰聲稱 AI 公司侵犯其版權。關鍵問題在於 LLM 是為何而生，又是由誰創造：記者主導的 LLM 如何運作，以及參與式設計可以揭示哪些關於適應「一體適用」基礎模型到特定使用情境中的當前挑戰？在本文中，我們進行共同設計探索，以了解參與式 LLM 方法如何解決新聞業中與 AI 相關的機會和挑戰。我們對記者、數據記者、編輯、勞工組織者、產品負責人和主管進行的 20 次訪談，突顯了為這個機會空間設計時必須解決的巨觀、中觀和微觀緊張關係。根據這些理想條件，我們描述了共同設計工作的成果：記者控制的 LLM 的組織結構和功能。在結尾，我們討論了商業基礎模型在工作場所使用中的限制，以及將參與式方法應用於 LLM 共同設計的方法論影響。

##### **Multi-Physics Simulations via Coupled Fourier Neural Operator**
2501.17296v1 by Shibo Li, Tao Wang, Yifei Sun, Heiwei Tang

Physical simulations are essential tools across critical fields such as
mechanical and aerospace engineering, chemistry, meteorology, etc. While neural
operators, particularly the Fourier Neural Operator (FNO), have shown promise
in predicting simulation results with impressive performance and efficiency,
they face limitations when handling real-world scenarios involving coupled
multi-physics outputs. Current neural operator methods either overlook the
correlations between multiple physical processes or employ simplistic
architectures that inadequately capture these relationships. To overcome these
challenges, we introduce a novel coupled multi-physics neural operator learning
(COMPOL) framework that extends the capabilities of Fourier operator layers to
model interactions among multiple physical processes. Our approach implements
feature aggregation through recurrent and attention mechanisms, enabling
comprehensive modeling of coupled interactions. Our method's core is an
innovative system for aggregating latent features from multi-physics processes.
These aggregated features serve as enriched information sources for neural
operator layers, allowing our framework to capture complex physical
relationships accurately. We evaluated our coupled multi-physics neural
operator across diverse physical simulation tasks, including biological
systems, fluid mechanics, and multiphase flow in porous media. Our proposed
model demonstrates a two to three-fold improvement in predictive performance
compared to existing approaches.

摘要：物理模擬是機械和航空工程、化學、氣象學等關鍵領域的必要工具。雖然神經算子，特別是傅立葉神經算子 (FNO)，已展現出令人印象深刻的效能和效率，預測模擬結果時很有前景，但在處理涉及耦合多物理輸出結果的真實世界場景時，它們會面臨限制。目前的類神經算子方法會忽略多個物理程序之間的關聯性，或採用簡化的架構，無法充分捕捉這些關係。為了克服這些挑戰，我們引入了一個新的耦合多物理神經算子學習 (COMPOL) 架構，它擴展了傅立葉算子層的能力，以建模多個物理程序之間的交互作用。我們的做法通過遞歸和注意機制實作特徵聚合，實現了耦合交互作用的全面建模。我們的方法核心是一個創新的系統，用於聚合來自多物理程序的潛在特徵。這些聚合的特徵作為神經算子層的豐富資訊來源，讓我們的架構能夠準確捕捉複雜的物理關係。我們在不同的物理模擬任務中評估了我們的耦合多物理神經算子，包括生物系統、流體力學和多相流動在多孔介質中。我們提出的模型展示出比現有方法高出兩到三倍的預測效能。

##### **Mitigating Hallucinated Translations in Large Language Models with Hallucination-focused Preference Optimization**
2501.17295v1 by Zilu Tang, Rajen Chatterjee, Sarthak Garg

Machine Translation (MT) is undergoing a paradigm shift, with systems based
on fine-tuned large language models (LLM) becoming increasingly competitive
with traditional encoder-decoder models trained specifically for translation
tasks. However, LLM-based systems are at a higher risk of generating
hallucinations, which can severely undermine user's trust and safety. Most
prior research on hallucination mitigation focuses on traditional MT models,
with solutions that involve post-hoc mitigation - detecting hallucinated
translations and re-translating them. While effective, this approach introduces
additional complexity in deploying extra tools in production and also increases
latency. To address these limitations, we propose a method that intrinsically
learns to mitigate hallucinations during the model training phase.
Specifically, we introduce a data creation framework to generate hallucination
focused preference datasets. Fine-tuning LLMs on these preference datasets
reduces the hallucination rate by an average of 96% across five language pairs,
while preserving overall translation quality. In a zero-shot setting our
approach reduces hallucinations by 89% on an average across three unseen target
languages.

摘要：機器翻譯 (MT) 正在經歷一場典範轉移，基於微調大型語言模型 (LLM) 的系統與專門為翻譯任務訓練的傳統編碼器-解碼器模型競爭日趨激烈。然而，基於 LLM 的系統產生幻覺的風險較高，這可能會嚴重損害使用者的信任和安全。大多數先前關於幻覺減緩的研究都集中在傳統的 MT 模型上，其解決方案涉及事後減緩——偵測幻覺翻譯並重新翻譯。雖然有效，但這種方法在生產環境中部署額外工具時會增加複雜性，也會增加延遲。為了解決這些限制，我們提出了一種方法，在模型訓練階段內在學習減輕幻覺。具體來說，我們引入一個資料建立架構來產生以幻覺為中心的偏好資料集。在這些偏好資料集上微調 LLM 可將幻覺率平均降低 96%，橫跨五種語言對，同時保留整體翻譯品質。在零次學習設定中，我們的做法平均將幻覺減少 89%，橫跨三種未見過的目標語言。

##### **Fine-Tuning Open-Source Large Language Models to Improve Their Performance on Radiation Oncology Tasks: A Feasibility Study to Investigate Their Potential Clinical Applications in Radiation Oncology**
2501.17286v1 by Peilong Wang, Zhengliang Liu, Yiwei Li, Jason Holmes, Peng Shu, Lian Zhang, Xiang Li, Quanzheng Li, Brady S. Laughlin, Diego Santos Toesca, Sujay A. Vora, Samir H. Patel, Terence T. Sio, Tianming Liu, Wei Liu

Background: The radiation oncology clinical practice involves many steps
relying on the dynamic interplay of abundant text data. Large language models
have displayed remarkable capabilities in processing complex text information.
But their direct applications in specific fields like radiation oncology remain
underexplored.
  Purpose: This study aims to investigate whether fine-tuning LLMs with domain
knowledge can improve the performance on Task (1) treatment regimen generation,
Task (2) treatment modality selection (photon, proton, electron, or
brachytherapy), and Task (3) ICD-10 code prediction in radiation oncology.
  Methods: Data for 15,724 patient cases were extracted. Cases where patients
had a single diagnostic record, and a clearly identifiable primary treatment
plan were selected for preprocessing and manual annotation to have 7,903 cases
of the patient diagnosis, treatment plan, treatment modality, and ICD-10 code.
Each case was used to construct a pair consisting of patient diagnostics
details and an answer (treatment regimen, treatment modality, or ICD-10 code
respectively) for the supervised fine-tuning of these three tasks. Open source
LLaMA2-7B and Mistral-7B models were utilized for the fine-tuning with the
Low-Rank Approximations method. Accuracy and ROUGE-1 score were reported for
the fine-tuned models and original models. Clinical evaluation was performed on
Task (1) by radiation oncologists, while precision, recall, and F-1 score were
evaluated for Task (2) and (3). One-sided Wilcoxon signed-rank tests were used
to statistically analyze the results.
  Results: Fine-tuned LLMs outperformed original LLMs across all tasks with
p-value <= 0.001. Clinical evaluation demonstrated that over 60% of the
fine-tuned LLMs-generated treatment regimens were clinically acceptable.
Precision, recall, and F1-score showed improved performance of fine-tuned LLMs.

摘要：<paragraph>背景：放射肿瘤临床实践涉及许多步骤，这些步骤依赖于丰富文本数据的动态交互。大型语言模型在处理复杂的文本信息方面表现出了卓越的能力。但它们在放射肿瘤等特定领域的直接应用仍未得到充分探索。
目的：本研究旨在调查通过领域知识微调 LLM 是否可以提高任务 (1) 治疗方案生成、任务 (2) 治疗方式选择（光子、质子、电子或近距离放射治疗）和任务 (3) 放射肿瘤中 ICD-10 代码预测的性能。
方法：提取了 15,724 例患者病例的数据。选择了患者有单一诊断记录且有明确可识别的主要治疗计划的病例，进行预处理和手动注释，得到 7,903 例患者诊断、治疗计划、治疗方式和 ICD-10 代码。每个病例都用于构建一对，包括患者诊断详情和答案（分别是治疗方案、治疗方式或 ICD-10 代码），用于这三个任务的监督微调。开源 LLaMA2-7B 和 Mistral-7B 模型被用于使用低秩逼近方法进行微调。报告了微调模型和原始模型的准确性和 ROUGE-1 分数。任务 (1) 由放射肿瘤科医师进行临床评估，而任务 (2) 和 (3) 则评估了精确度、召回率和 F-1 分数。单侧 Wilcoxon 符号秩检验用于对结果进行统计分析。
结果：微调后的 LLM 在所有任务中都优于原始 LLM，p 值 <= 0.001。临床评估表明，超过 60% 的微调 LLM 生成的治疗方案在临床上是可接受的。精确度、召回率和 F1 分数显示微调后的 LLM 性能得到改善。</paragraph>

##### **From Natural Language to Extensive-Form Game Representations**
2501.17282v1 by Shilong Deng, Yongzhao Wang, Rahul Savani

We introduce a framework for translating game descriptions in natural
language into extensive-form representations in game theory, leveraging Large
Language Models (LLMs) and in-context learning. Given the varying levels of
strategic complexity in games, such as perfect versus imperfect information,
directly applying in-context learning would be insufficient. To address this,
we introduce a two-stage framework with specialized modules to enhance
in-context learning, enabling it to divide and conquer the problem effectively.
In the first stage, we tackle the challenge of imperfect information by
developing a module that identifies information sets along and the
corresponding partial tree structure. With this information, the second stage
leverages in-context learning alongside a self-debugging module to produce a
complete extensive-form game tree represented using pygambit, the Python API of
a recognized game-theoretic analysis tool called Gambit. Using this python
representation enables the automation of tasks such as computing Nash
equilibria directly from natural language descriptions. We evaluate the
performance of the full framework, as well as its individual components, using
various LLMs on games with different levels of strategic complexity. Our
experimental results show that the framework significantly outperforms baseline
models in generating accurate extensive-form games, with each module playing a
critical role in its success.

摘要：我們引入了一個架構，用於將自然語言中的遊戲描述轉換為博弈論中的廣義形式表示，利用大型語言模型 (LLM) 和情境學習。鑑於遊戲中策略複雜程度的不同，例如完美資訊與不完美資訊，直接應用情境學習將是不夠的。為了解決這個問題，我們引入了一個兩階段架構，其中包含專門模組來增強情境學習，使其能夠有效地分而治之。在第一階段，我們通過開發一個模組來解決不完美資訊的挑戰，該模組可以識別沿著資訊集和對應的部分樹狀結構。有了這些資訊，第二階段利用情境學習和自除錯模組來產生一個完整的廣義形式遊戲樹，使用 pygambit 表示，它是稱為 Gambit 的公認博弈論分析工具的 Python API。使用此 python 表示可以自動執行任務，例如直接從自然語言描述中計算納許均衡。我們使用不同策略複雜程度的遊戲對完整架構及其個別組件的性能進行評估，使用各種 LLM。我們的實驗結果表明，該架構在生成準確的廣義形式遊戲方面顯著優於基準模型，每個模組在其成功中都發揮著至關重要的作用。

##### **Tailored Truths: Optimizing LLM Persuasion with Personalization and Fabricated Statistics**
2501.17273v1 by Jasper Timm, Chetan Talele, Jacob Haimes

Large Language Models (LLMs) are becoming increasingly persuasive,
demonstrating the ability to personalize arguments in conversation with humans
by leveraging their personal data. This may have serious impacts on the scale
and effectiveness of disinformation campaigns. We studied the persuasiveness of
LLMs in a debate setting by having humans $(n=33)$ engage with LLM-generated
arguments intended to change the human's opinion. We quantified the LLM's
effect by measuring human agreement with the debate's hypothesis pre- and
post-debate and analyzing both the magnitude of opinion change, as well as the
likelihood of an update in the LLM's direction. We compare persuasiveness
across established persuasion strategies, including personalized arguments
informed by user demographics and personality, appeal to fabricated statistics,
and a mixed strategy utilizing both personalized arguments and fabricated
statistics. We found that static arguments generated by humans and GPT-4o-mini
have comparable persuasive power. However, the LLM outperformed static
human-written arguments when leveraging the mixed strategy in an interactive
debate setting. This approach had a $\mathbf{51\%}$ chance of persuading
participants to modify their initial position, compared to $\mathbf{32\%}$ for
the static human-written arguments. Our results highlight the concerning
potential for LLMs to enable inexpensive and persuasive large-scale
disinformation campaigns.

摘要：大型語言模型 (LLM) 變得越來越有說服力，展示了在與人類對話中透過利用其個人資料來個性化論點的能力。這可能會對錯誤資訊活動的規模和有效性產生嚴重影響。我們在辯論場景中研究了 LLM 的說服力，讓人類 $(n=33)$ 參與 LLM 生成的論點，目的是改變人類的觀點。我們透過衡量人類在辯論前和辯論後的意見是否認同辯論的假設，並分析意見改變的幅度以及 LLM 方向更新的可能性，來量化 LLM 的影響。我們比較了既定的說服策略的說服力，包括根據使用者人口統計資料和個性化而成的個性化論點、訴諸虛構的統計數據，以及利用個性化論點和虛構統計數據的混合策略。我們發現，人類和 GPT-4o-mini 生成的靜態論點具有相當的說服力。然而，當在互動式辯論場景中利用混合策略時，LLM 優於靜態人類撰寫的論點。此方法有 $\mathbf{51\%}$ 的機率說服參與者修改其初始立場，而靜態人類撰寫的論點只有 $\mathbf{32\%}$。我們的結果突顯了 LLM 可能讓大規模錯誤資訊活動變得便宜且具有說服力的令人擔憂的可能性。

##### **Comprehensive Evaluation for a Large Scale Knowledge Graph Question Answering Service**
2501.17270v1 by Saloni Potdar, Daniel Lee, Omar Attia, Varun Embar, De Meng, Ramesh Balaji, Chloe Seivwright, Eric Choi, Mina H. Farid, Yiwen Sun, Yunyao Li

Question answering systems for knowledge graph (KGQA), answer factoid
questions based on the data in the knowledge graph. KGQA systems are complex
because the system has to understand the relations and entities in the
knowledge-seeking natural language queries and map them to structured queries
against the KG to answer them. In this paper, we introduce Chronos, a
comprehensive evaluation framework for KGQA at industry scale. It is designed
to evaluate such a multi-component system comprehensively, focusing on (1)
end-to-end and component-level metrics, (2) scalable to diverse datasets and
(3) a scalable approach to measure the performance of the system prior to
release. In this paper, we discuss the unique challenges associated with
evaluating KGQA systems at industry scale, review the design of Chronos, and
how it addresses these challenges. We will demonstrate how it provides a base
for data-driven decisions and discuss the challenges of using it to measure and
improve a real-world KGQA system.

摘要：知識圖譜問答系統 (KGQA) 根據知識圖譜中的資料回答事實問題。KGQA 系統很複雜，因為系統必須理解知識尋求自然語言查詢中的關係和實體，並將它們對映到針對知識圖譜的結構化查詢，才能回答這些查詢。在本文中，我們介紹了 Chronos，這是一個用於產業規模 KGQA 的全面評估框架。它旨在全面評估這種多組件系統，重點關注：(1) 端對端和組件層級指標，(2) 可擴充至各種資料集，以及 (3) 可擴充的方法，用於在釋出前衡量系統的效能。在本文中，我們討論了與產業規模 KGQA 系統評估相關的獨特挑戰，檢視 Chronos 的設計，以及它如何應對這些挑戰。我們將展示它如何提供資料驅動決策的基礎，並討論使用它來衡量和改善真實世界 KGQA 系統的挑戰。

##### **Giving the Old a Fresh Spin: Quality Estimation-Assisted Constrained Decoding for Automatic Post-Editing**
2501.17265v1 by Sourabh Deoghare, Diptesh Kanojia, Pushpak Bhattacharyya

Automatic Post-Editing (APE) systems often struggle with over-correction,
where unnecessary modifications are made to a translation, diverging from the
principle of minimal editing. In this paper, we propose a novel technique to
mitigate over-correction by incorporating word-level Quality Estimation (QE)
information during the decoding process. This method is architecture-agnostic,
making it adaptable to any APE system, regardless of the underlying model or
training approach. Our experiments on English-German, English-Hindi, and
English-Marathi language pairs show the proposed approach yields significant
improvements over their corresponding baseline APE systems, with TER gains of
$0.65$, $1.86$, and $1.44$ points, respectively. These results underscore the
complementary relationship between QE and APE tasks and highlight the
effectiveness of integrating QE information to reduce over-correction in APE
systems.

摘要：自動後編輯 (APE) 系統經常會過度修正，
在翻譯中進行不必要的修改，偏離了最小編輯的原則。在本文中，我們提出了一種新的技術，通過在解碼過程中整合詞級品質評估 (QE) 資訊來減輕過度修正。這種方法與架構無關，因此可以適應任何 APE 系統，無論其底層模型或訓練方法為何。我們對英語-德語、英語-印地語和英語-馬拉地語語言對進行的實驗表明，所提出的方法比其對應的基準 APE 系統有顯著的改進，TER 分別增加了 0.65、1.86 和 1.44 分。這些結果強調了 QE 和 APE 任務之間的互補關係，並突出了整合 QE 資訊以減少 APE 系統中過度修正的有效性。

##### **SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training**
2501.17161v1 by Tianzhe Chu, Yuexiang Zhai, Jihan Yang, Shengbang Tong, Saining Xie, Dale Schuurmans, Quoc V. Le, Sergey Levine, Yi Ma

Supervised fine-tuning (SFT) and reinforcement learning (RL) are widely used
post-training techniques for foundation models. However, their roles in
enhancing model generalization capabilities remain unclear. This paper studies
the difference between SFT and RL on generalization and memorization, focusing
on text-based rule variants and visual variants. We introduce GeneralPoints, an
arithmetic reasoning card game, and adopt V-IRL, a real-world navigation
environment, to assess how models trained with SFT and RL generalize to unseen
variants in both textual and visual domains. We show that RL, especially when
trained with an outcome-based reward, generalizes across both rule-based
textual and visual variants. SFT, in contrast, tends to memorize training data
and struggles to generalize out-of-distribution scenarios. Further analysis
reveals that RL improves the model's underlying visual recognition
capabilities, contributing to its enhanced generalization in the visual domain.
Despite RL's superior generalization, we show that SFT remains essential for
effective RL training; SFT stabilizes the model's output format, enabling
subsequent RL to achieve its performance gains. These findings demonstrates the
capability of RL for acquiring generalizable knowledge in complex, multi-modal
tasks.

摘要：監督微調 (SFT) 和強化學習 (RL) 是廣泛用於基礎模型的訓練後技術。然而，它們在增強模型泛化能力中的作用仍不明確。本文探討了 SFT 和 RL 在泛化和記憶力方面的差異，重點關注基於文本的規則變體和視覺變體。我們引入了 GeneralPoints，一種算術推理紙牌遊戲，並採用 V-IRL，一個真實世界的導航環境，來評估使用 SFT 和 RL 訓練的模型如何泛化到文本和視覺領域中未見過的變體。我們表明 RL，特別是在使用基於結果的獎勵進行訓練時，可以泛化到基於規則的文本和視覺變體。相比之下，SFT 傾向於記憶訓練數據，並且難以泛化到分佈外的場景。進一步的分析表明，RL 改善了模型的底層視覺識別能力，有助於其在視覺領域中的泛化能力增強。儘管 RL 具有優越的泛化能力，但我們表明 SFT 仍然對於有效的 RL 訓練至關重要；SFT 穩定模型的輸出格式，使後續 RL 能夠實現其性能提升。這些發現展示了 RL 在複雜的多模態任務中獲取可泛化知識的能力。

##### **A Hybrid Deep Learning CNN Model for Enhanced COVID-19 Detection from Computed Tomography (CT) Scan Images**
2501.17160v1 by Suresh Babu Nettur, Shanthi Karpurapu, Unnati Nettur, Likhit Sagar Gajja, Sravanthy Myneni, Akhil Dusi, Lalithya Posham

Early detection of COVID-19 is crucial for effective treatment and
controlling its spread. This study proposes a novel hybrid deep learning model
for detecting COVID-19 from CT scan images, designed to assist overburdened
medical professionals. Our proposed model leverages the strengths of VGG16,
DenseNet121, and MobileNetV2 to extract features, followed by Principal
Component Analysis (PCA) for dimensionality reduction, after which the features
are stacked and classified using a Support Vector Classifier (SVC). We
conducted comparative analysis between the proposed hybrid model and individual
pre-trained CNN models, using a dataset of 2,108 training images and 373 test
images comprising both COVID-positive and non-COVID images. Our proposed hybrid
model achieved an accuracy of 98.93%, outperforming the individual models in
terms of precision, recall, F1 scores, and ROC curve performance.

摘要：早期偵測 COVID-19 對有效治療和控制其傳播至關重要。本研究提出一個新穎的深度學習混合模型，用於從電腦斷層掃描影像中偵測 COVID-19，旨在協助負擔過重的醫療專業人員。我們提出的模型利用 VGG16、DenseNet121 和 MobileNetV2 的優點來萃取特徵，接著進行主成分分析 (PCA) 以進行降維，然後將特徵堆疊並使用支持向量分類器 (SVC) 進行分類。我們對提出的混合模型和個別預訓練的 CNN 模型進行比較分析，使用包含 2,108 張訓練影像和 373 張測試影像的資料集，其中包含 COVID-19 陽性影像和非 COVID-19 影像。我們提出的混合模型達到了 98.93% 的準確度，在精準度、召回率、F1 分數和 ROC 曲線效能方面優於個別模型。

##### **Three-Dimensional Diffusion-Weighted Multi-Slab MRI With Slice Profile Compensation Using Deep Energy Model**
2501.17152v1 by Reza Ghorbani, Jyothi Rikhab Chand, Chu-Yu Lee, Mathews Jacob, Merry Mani

Three-dimensional (3D) multi-slab acquisition is a technique frequently
employed in high-resolution diffusion-weighted MRI in order to achieve the best
signal-to-noise ratio (SNR) efficiency. However, this technique is limited by
slab boundary artifacts that cause intensity fluctuations and aliasing between
slabs which reduces the accuracy of anatomical imaging. Addressing this issue
is crucial for advancing diffusion MRI quality and making high-resolution
imaging more feasible for clinical and research applications. In this work, we
propose a regularized slab profile encoding (PEN) method within a Plug-and-Play
ADMM framework, incorporating multi-scale energy (MuSE) regularization to
effectively improve the slab combined reconstruction. Experimental results
demonstrate that the proposed method significantly improves image quality
compared to non-regularized and TV-regularized PEN approaches. The regularized
PEN framework provides a more robust and efficient solution for high-resolution
3D diffusion MRI, potentially enabling clearer, more reliable anatomical
imaging across various applications.

摘要：三維 (3D) 多層板擷取是一種技術，經常使用於高解析度擴散加權 MRI，以達到最佳的訊號雜訊比 (SNR) 效率。然而，此技術受到層板邊界偽影的限制，會造成強度波動和層板之間的混疊，降低解剖影像的準確度。解決這個問題對於提升擴散 MRI 品質至關重要，並使高解析度影像更適用於臨床和研究應用。在這項工作中，我們在 Plug-and-Play ADMM 架構內提出正規化的層板輪廓編碼 (PEN) 方法，並結合多尺度能量 (MuSE) 正規化，以有效改善層板組合重建。實驗結果證明，與非正規化和 TV 正規化 PEN 方法相比，所提出的方法顯著提升了影像品質。正規化的 PEN 架構為高解析度 3D 擴散 MRI 提供更強固且有效率的解決方案，潛在可實現更清晰、更可靠的解剖影像，適用於各種應用。

##### **AxBench: Steering LLMs? Even Simple Baselines Outperform Sparse Autoencoders**
2501.17148v2 by Zhengxuan Wu, Aryaman Arora, Atticus Geiger, Zheng Wang, Jing Huang, Dan Jurafsky, Christopher D. Manning, Christopher Potts

Fine-grained steering of language model outputs is essential for safety and
reliability. Prompting and finetuning are widely used to achieve these goals,
but interpretability researchers have proposed a variety of
representation-based techniques as well, including sparse autoencoders (SAEs),
linear artificial tomography, supervised steering vectors, linear probes, and
representation finetuning. At present, there is no benchmark for making direct
comparisons between these proposals. Therefore, we introduce AxBench, a
large-scale benchmark for steering and concept detection, and report
experiments on Gemma-2-2B and 9B. For steering, we find that prompting
outperforms all existing methods, followed by finetuning. For concept
detection, representation-based methods such as difference-in-means, perform
the best. On both evaluations, SAEs are not competitive. We introduce a novel
weakly-supervised representational method (Rank-1 Representation Finetuning;
ReFT-r1), which is competitive on both tasks while providing the
interpretability advantages that prompting lacks. Along with AxBench, we train
and publicly release SAE-scale feature dictionaries for ReFT-r1 and DiffMean.

摘要：微調語言模型輸出對於安全性與可靠性至關重要。提示與微調廣泛用於達成這些目標，但可解釋性研究人員也提出各種基於表徵的技術，包括稀疏自動編碼器 (SAE)、線性人工斷層攝影、監督引導向量、線性探測和表徵微調。目前沒有基準可供對這些提案進行直接比較。因此，我們引入了 AxBench，一個用於引導和概念檢測的大規模基準，並報告了在 Gemma-2-2B 和 9B 上的實驗。對於引導，我們發現提示優於所有現有方法，其次是微調。對於概念檢測，基於表徵的方法（例如均值差）表現最佳。在兩項評估中，SAE 沒有競爭力。我們引入了一種新穎的弱監督表徵方法（1 級表徵微調；ReFT-r1），它在兩項任務上都具有競爭力，同時提供了提示所缺乏的可解釋性優勢。隨著 AxBench，我們訓練並公開發布了 ReFT-r1 和 DiffMean 的 SAE 級別特徵字典。

##### **FactCG: Enhancing Fact Checkers with Graph-Based Multi-Hop Data**
2501.17144v1 by Deren Lei, Yaxi Li, Siyao Li, Mengya Hu, Rui Xu, Ken Archer, Mingyu Wang, Emily Ching, Alex Deng

Prior research on training grounded factuality classification models to
detect hallucinations in large language models (LLMs) has relied on public
natural language inference (NLI) data and synthetic data. However, conventional
NLI datasets are not well-suited for document-level reasoning, which is
critical for detecting LLM hallucinations. Recent approaches to document-level
synthetic data generation involve iteratively removing sentences from documents
and annotating factuality using LLM-based prompts. While effective, this method
is computationally expensive for long documents and limited by the LLM's
capabilities. In this work, we analyze the differences between existing
synthetic training data used in state-of-the-art models and real LLM output
claims. Based on our findings, we propose a novel approach for synthetic data
generation, CG2C, that leverages multi-hop reasoning on context graphs
extracted from documents. Our fact checker model, FactCG, demonstrates improved
performance with more connected reasoning, using the same backbone models.
Experiments show it even outperforms GPT-4-o on the LLM-Aggrefact benchmark
with much smaller model size.

摘要：先前的研究訓練了基於事實的分類模型，以偵測大型語言模型 (LLM) 中的幻覺，依賴於公開的自然語言推論 (NLI) 資料和合成資料。然而，傳統的 NLI 資料集並不適合文件層級的推理，這對於偵測 LLM 的幻覺至關重要。最近的文件層級合成資料生成方法涉及從文件中反覆移除句子，並使用基於 LLM 的提示註解事實。雖然有效，但此方法對於長文件來說在運算上很昂貴，且受限於 LLM 的能力。在這項工作中，我們分析了現有合成訓練資料與最先進模型中使用的真實 LLM 輸出宣告之間的差異。根據我們的研究結果，我們提出了一個用於合成資料生成的創新方法 CG2C，它利用從文件中提取的內容圖表進行多跳推理。我們的查核模型 FactCG 使用相同的骨幹模型，展示了在更多連結的推理下改進的效能。實驗表明，它甚至在 LLM-Aggrefact 基準上優於 GPT-4-o，且模型大小小得多。

##### **ASTRAL: Automated Safety Testing of Large Language Models**
2501.17132v1 by Miriam Ugarte, Pablo Valle, José Antonio Parejo, Sergio Segura, Aitor Arrieta

Large Language Models (LLMs) have recently gained attention due to their
ability to understand and generate sophisticated human-like content. However,
ensuring their safety is paramount as they might provide harmful and unsafe
responses. Existing LLM testing frameworks address various safety-related
concerns (e.g., drugs, terrorism, animal abuse) but often face challenges due
to unbalanced and obsolete datasets. In this paper, we present ASTRAL, a tool
that automates the generation and execution of test cases (i.e., prompts) for
testing the safety of LLMs. First, we introduce a novel black-box coverage
criterion to generate balanced and diverse unsafe test inputs across a diverse
set of safety categories as well as linguistic writing characteristics (i.e.,
different style and persuasive writing techniques). Second, we propose an
LLM-based approach that leverages Retrieval Augmented Generation (RAG),
few-shot prompting strategies and web browsing to generate up-to-date test
inputs. Lastly, similar to current LLM test automation techniques, we leverage
LLMs as test oracles to distinguish between safe and unsafe test outputs,
allowing a fully automated testing approach. We conduct an extensive evaluation
on well-known LLMs, revealing the following key findings: i) GPT3.5 outperforms
other LLMs when acting as the test oracle, accurately detecting unsafe
responses, and even surpassing more recent LLMs (e.g., GPT-4), as well as LLMs
that are specifically tailored to detect unsafe LLM outputs (e.g., LlamaGuard);
ii) the results confirm that our approach can uncover nearly twice as many
unsafe LLM behaviors with the same number of test inputs compared to currently
used static datasets; and iii) our black-box coverage criterion combined with
web browsing can effectively guide the LLM on generating up-to-date unsafe test
inputs, significantly increasing the number of unsafe LLM behaviors.

摘要：<paragraph>大型語言模型（LLM）最近因其理解和生成複雜的人類內容的能力而備受關注。然而，確保它們的安全至關重要，因為它們可能會提供有害和不安全的回應。現有的 LLM 測試框架解決了各種與安全相關的問題（例如，藥物、恐怖主義、虐待動物），但由於數據集不平衡和過時，它們常常面臨挑戰。在本文中，我們介紹 ASTRAL，這是一個工具，可以自動生成和執行測試用例（即提示），以測試 LLM 的安全性。首先，我們引入了一個新穎的黑盒覆蓋標準，以生成跨越不同安全類別以及語言寫作特徵（即不同風格和說服性寫作技巧）的平衡且多樣化的不安全測試輸入。其次，我們提出了一種基於 LLM 的方法，該方法利用檢索增強生成（RAG）、少次提示策略和網絡瀏覽來生成最新的測試輸入。最後，與當前的 LLM 測試自動化技術類似，我們利用 LLM 作為測試預言來區分安全和不安全的測試輸出，從而允許完全自動化的測試方法。我們對眾所周知的 LLM 進行了廣泛的評估，揭示了以下關鍵發現：i) GPT3.5 在充當測試預言時優於其他 LLM，準確檢測不安全的響應，甚至超越了更新的 LLM（例如，GPT-4），以及專門定制為檢測不安全的 LLM 輸出的 LLM（例如，LlamaGuard）；ii) 結果證實，與當前使用的靜態數據集相比，我們的方案可以用相同數量的測試輸入發現幾乎多一倍的不安全 LLM 行為；iii) 我們的黑盒覆蓋標準與網絡瀏覽相結合，可以有效地指導 LLM 生成最新的不安全測試輸入，從而顯著增加不安全 LLM 行為的數量。</paragraph>

##### **Histoires Morales: A French Dataset for Assessing Moral Alignment**
2501.17117v1 by Thibaud Leteno, Irina Proskurina, Antoine Gourru, Julien Velcin, Charlotte Laclau, Guillaume Metzler, Christophe Gravier

Aligning language models with human values is crucial, especially as they
become more integrated into everyday life. While models are often adapted to
user preferences, it is equally important to ensure they align with moral norms
and behaviours in real-world social situations. Despite significant progress in
languages like English and Chinese, French has seen little attention in this
area, leaving a gap in understanding how LLMs handle moral reasoning in this
language. To address this gap, we introduce Histoires Morales, a French dataset
derived from Moral Stories, created through translation and subsequently
refined with the assistance of native speakers to guarantee grammatical
accuracy and adaptation to the French cultural context. We also rely on
annotations of the moral values within the dataset to ensure their alignment
with French norms. Histoires Morales covers a wide range of social situations,
including differences in tipping practices, expressions of honesty in
relationships, and responsibilities toward animals. To foster future research,
we also conduct preliminary experiments on the alignment of multilingual models
on French and English data and the robustness of the alignment. We find that
while LLMs are generally aligned with human moral norms by default, they can be
easily influenced with user-preference optimization for both moral and immoral
data.

摘要：語言模型與人類價值觀的對齊至關重要，特別是它們越來越融入日常生活之際。儘管模型通常會根據用戶偏好進行調整，但同樣重要的是確保它們符合現實世界社會情境中的道德規範和行為。儘管英語和中文等語言取得了顯著進展，但法語在這方面鮮受關注，這使得我們對 LLM 如何處理這種語言中的道德推理缺乏了解。為了解決這一差距，我們引入了 Histoires Morales，這是一個法語數據集，它源自道德故事，通過翻譯創建，隨後在母語人士的協助下進行了改進，以保證語法準確性和對法語文化背景的適應性。我們還依賴數據集中道德價值的註釋，以確保它們與法語規範保持一致。Histoires Morales 涵蓋了廣泛的社會情境，包括小費習慣的差異、關係中的誠實表達以及對動物的責任。為了促進未來的研究，我們還對法語和英語數據上多語言模型的對齊以及對齊的穩健性進行了初步實驗。我們發現，儘管 LLM 通常默認與人類道德規範保持一致，但它們可以通過對道德和不道德數據的用戶偏好優化而輕易受到影響。

##### **Optimizing Large Language Model Training Using FP4 Quantization**
2501.17116v1 by Ruizhe Wang, Yeyun Gong, Xiao Liu, Guoshuai Zhao, Ziyue Yang, Baining Guo, Zhengjun Zha, Peng Cheng

The growing computational demands of training large language models (LLMs)
necessitate more efficient methods. Quantized training presents a promising
solution by enabling low-bit arithmetic operations to reduce these costs. While
FP8 precision has demonstrated feasibility, leveraging FP4 remains a challenge
due to significant quantization errors and limited representational capacity.
This work introduces the first FP4 training framework for LLMs, addressing
these challenges with two key innovations: a differentiable quantization
estimator for precise weight updates and an outlier clamping and compensation
strategy to prevent activation collapse. To ensure stability, the framework
integrates a mixed-precision training scheme and vector-wise quantization.
Experimental results demonstrate that our FP4 framework achieves accuracy
comparable to BF16 and FP8, with minimal degradation, scaling effectively to
13B-parameter LLMs trained on up to 100B tokens. With the emergence of
next-generation hardware supporting FP4, our framework sets a foundation for
efficient ultra-low precision training.

摘要：大型語言模型（LLM）訓練不斷增長的計算需求，需要更有效率的方法。量化訓練提供了一個有前途的解決方案，透過啟用低位元算術運算來降低這些成本。雖然 FP8 精度已證明可行，但由於量化誤差顯著和表示能力有限，因此利用 FP4 仍然是一個挑戰。這項工作引入了 LLM 的第一個 FP4 訓練架構，透過兩個關鍵創新來解決這些挑戰：一個可微分量化估計器，用於精確權重更新，以及一個異常值箝制和補償策略，以防止激活崩潰。為了確保穩定性，該架構整合了一個混合精度訓練方案和向量化量化。實驗結果表明，我們的 FP4 架構達到了與 BF16 和 FP8 相當的準確度，且有最小的衰減，可有效擴充到在多達 100B 個符號上訓練的 13B 參數 LLM。隨著支援 FP4 的新一代硬體出現，我們的架構為高效的超低精度訓練奠定了基礎。

##### **COS(M+O)S: Curiosity and RL-Enhanced MCTS for Exploring Story Space via Language Models**
2501.17104v1 by Tobias Materzok

We present COS(M+O)S, a System 2-inspired framework for open-ended plot
development that systematically explores the vast space of possible story
expansions, enabling a 3B-parameter language model to approach the plot quality
of a 70B model on select short-story tasks. The method accomplishes this by
combining Monte Carlo Tree Search (MCTS), guided by a step-level value model
that rewards moderate surprisal (curiosity) while penalizing incoherence, and
Odds Ratio Preference Optimization (ORPO) to fine-tune the policy on high-value
plot expansions. This iterative reinforcement learning loop systematically
explores multiple candidate plot branches, backpropagates quality signals, and
adapts the policy for faster convergence, notably shifting the policy from
puzzle-based Chain-of-Thought to more character-driven storytelling. In
small-scale tests with short-story prompts, 67%-77% of participants favored
COS(M+O)S's highest-rated expansions over lower-rated ones, suggesting that our
learned value function aligns. GPT-4o ratings further show that COS(M+O)S
surpasses naive single-pass decoding from Llama 3.2 3B by 0.59 SD, coming
within 0.06 SD of Llama 3.1 70B (no significant difference, p=0.93). Pairwise
comparisons with o1 place COS(M+O)S 1.5 SD above the 3B baseline and find no
statistically significant gap from 70B. Nevertheless, absolute story quality
remains modest, constrained by the small model's capacity and limited training
data.

摘要：<paragraph>我們提出 COS(M+O)S，一個受 System 2 啟發的架構，用於開放式情節發展，系統性地探索可能的故事情節擴展的廣闊空間，使 3B 參數語言模型能夠在選擇的短篇故事任務中接近 70B 模型的情節品質。此方法透過結合蒙地卡羅樹搜尋 (MCTS)，由階層價值模型引導，獎勵適度的驚喜 (好奇心)，同時懲罰不連貫性，以及機率比偏好最佳化 (ORPO) 來微調高價值情節擴展的政策。此反覆強化學習迴圈系統性地探索多個候選情節分支，反向傳播品質訊號，並調整政策以加快收斂，特別是將政策從基於謎題的思考鏈轉移到更多以角色為導向的故事敘述。在短篇故事提示的小規模測試中，67%-77% 的參與者偏好 COS(M+O)S 評分最高的擴展，而非評分較低的擴展，這表明我們學習到的價值函數是一致的。GPT-4o 評分進一步顯示，COS(M+O)S 超越了 Llama 3.2 3B 的單次解碼，SD 值為 0.59，接近 Llama 3.1 70B 的 SD 值 0.06（無顯著差異，p=0.93）。與 o1 的成對比較將 COS(M+O)S 放在 3B 基準線上方 1.5 SD，並且發現與 70B 之間沒有統計上顯著的差距。儘管如此，絕對的故事品質仍然適中，受到小模型容量和有限訓練資料的限制。</paragraph>

##### **Why is the estimation of metaorder impact with public market data so challenging?**
2501.17096v1 by Manuel Naviglio, Giacomo Bormetti, Francesco Campigli, German Rodikov, Fabrizio Lillo

Estimating market impact and transaction costs of large trades (metaorders)
is a very important topic in finance. However, using models of price and trade
based on public market data provide average price trajectories which are
qualitatively different from what is observed during real metaorder executions:
the price increases linearly, rather than in a concave way, during the
execution and the amount of reversion after its end is very limited. We claim
that this is a generic phenomenon due to the fact that even sophisticated
statistical models are unable to correctly describe the origin of the
autocorrelation of the order flow. We propose a modified Transient Impact Model
which provides more realistic trajectories by assuming that only a fraction of
the metaorder trading triggers market order flow. Interestingly, in our model
there is a critical condition on the kernels of the price and order flow
equations in which market impact becomes permanent.

摘要：評估大型交易的市場影響和交易成本（元訂單）是金融中非常重要的主題。然而，基於公開市場資料的價格和交易模型提供了平均價格軌跡，這與實際元訂單執行期間觀察到的情況有本質上的不同：價格在執行期間呈線性增加，而不是凹形增加，並且在執行結束後回歸的數量非常有限。我們聲稱這是一個普遍現象，因為即使是複雜的統計模型也無法正確描述訂單流自相關的起源。我們提出了一個修正的瞬態影響模型，通過假設只有部分元訂單交易會觸發市場訂單流來提供更真實的軌跡。有趣的是，在我們的模型中，價格和訂單流方程式的核存在一個臨界條件，在該條件下市場影響將變為永久性。

##### **Mamba-Shedder: Post-Transformer Compression for Efficient Selective Structured State Space Models**
2501.17088v1 by J. Pablo Muñoz, Jinjie Yuan, Nilesh Jain

Large pre-trained models have achieved outstanding results in sequence
modeling. The Transformer block and its attention mechanism have been the main
drivers of the success of these models. Recently, alternative architectures,
such as Selective Structured State Space Models (SSMs), have been proposed to
address the inefficiencies of Transformers. This paper explores the compression
of SSM-based models, particularly Mamba and its hybrids. We study the
sensitivity of these models to the removal of selected components at different
granularities to reduce the model size and computational overhead, thus
improving their efficiency while maintaining accuracy. The proposed solutions,
collectively referred to as Mamba-Shedder, achieve a speedup of up to 1.4x
during inference, demonstrating that model efficiency can be improved by
eliminating several redundancies with minimal impact on the overall model
performance. The code is available at
https://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning.

摘要：大型預訓練模型在序列建模中取得了傑出的成果。Transformer 塊及其注意力機制一直是這些模型成功的主要驅動力。最近，已經提出了替代結構，例如選擇性結構狀態空間模型 (SSM)，以解決 Transformer 的低效率問題。本文探討了基於 SSM 的模型的壓縮，特別是 Mamba 及其混合體。我們研究了這些模型在不同粒度下移除選定組件以降低模型大小和運算負擔的敏感性，從而提高其效率，同時維持準確性。所提出的解決方案，統稱為 Mamba-Shedder，在推理期間實現了高達 1.4 倍的加速，證明了透過消除多餘的冗餘，同時對整體模型效能的影響最小，可以提高模型效率。程式碼可在 https://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning 取得。

##### **Learning Mean Field Control on Sparse Graphs**
2501.17079v1 by Christian Fabian, Kai Cui, Heinz Koeppl

Large agent networks are abundant in applications and nature and pose
difficult challenges in the field of multi-agent reinforcement learning (MARL)
due to their computational and theoretical complexity. While graphon mean field
games and their extensions provide efficient learning algorithms for dense and
moderately sparse agent networks, the case of realistic sparser graphs remains
largely unsolved. Thus, we propose a novel mean field control model inspired by
local weak convergence to include sparse graphs such as power law networks with
coefficients above two. Besides a theoretical analysis, we design scalable
learning algorithms which apply to the challenging class of graph sequences
with finite first moment. We compare our model and algorithms for various
examples on synthetic and real world networks with mean field algorithms based
on Lp graphons and graphexes. As it turns out, our approach outperforms
existing methods in many examples and on various networks due to the special
design aiming at an important, but so far hard to solve class of MARL problems.

摘要：大型代理網路在應用與自然中十分豐富，且由於其運算與理論上的複雜性，在多重代理強化學習 (MARL) 領域中帶來困難的挑戰。雖然圖元平均場博弈及其擴充提供密集且適度稀疏代理網路的高效學習演算法，但現實中較稀疏圖形的情況仍然在很大程度上未獲解決。因此，我們提出一個新的平均場控制模型，其靈感來自局部弱收斂，以納入稀疏圖形，例如係數大於 2 的冪律網路。除了理論分析之外，我們設計了可擴充的學習演算法，適用於具有有限一階矩的圖序列的挑戰性類別。我們在合成和真實世界網路中比較了我們的模型和演算法，以及基於 Lp 圖元和圖形元的平均場演算法。事實證明，由於特別的設計旨在解決一個重要但到目前為止難以解決的 MARL 問題類別，我們的做法在許多範例和各種網路中優於現有方法。

##### **EdgeMLOps: Operationalizing ML models with Cumulocity IoT and thin-edge.io for Visual quality Inspection**
2501.17062v1 by Kanishk Chaturvedi, Johannes Gasthuber, Mohamed Abdelaal

This paper introduces EdgeMLOps, a framework leveraging Cumulocity IoT and
thin-edge.io for deploying and managing machine learning models on
resource-constrained edge devices. We address the challenges of model
optimization, deployment, and lifecycle management in edge environments. The
framework's efficacy is demonstrated through a visual quality inspection (VQI)
use case where images of assets are processed on edge devices, enabling
real-time condition updates within an asset management system. Furthermore, we
evaluate the performance benefits of different quantization methods,
specifically static and dynamic signed-int8, on a Raspberry Pi 4, demonstrating
significant inference time reductions compared to FP32 precision. Our results
highlight the potential of EdgeMLOps to enable efficient and scalable AI
deployments at the edge for industrial applications.

摘要：本文介绍了 EdgeMLOps，这是一个利用 Cumulocity IoT 和 thin-edge.io 的框架，用于在资源受限的边缘设备上部署和管理机器学习模型。我们解决了在边缘环境中进行模型优化、部署和生命周期管理的挑战。该框架的功效通过视觉质量检查 (VQI) 用例得到证明，其中资产的图像在边缘设备上进行处理，从而在资产管理系统中启用实时状态更新。此外，我们评估了不同量化方法的性能优势，特别是在 Raspberry Pi 4 上的静态和动态有符号 int8，与 FP32 精度相比，展示了显著的推理时间缩减。我们的结果突出了 EdgeMLOps 在为工业应用实现高效且可扩展的边缘 AI 部署方面的潜力。

##### **How Linguistics Learned to Stop Worrying and Love the Language Models**
2501.17047v1 by Richard Futrell, Kyle Mahowald

Language models can produce fluent, grammatical text. Nonetheless, some
maintain that language models don't really learn language and also that, even
if they did, that would not be informative for the study of human learning and
processing. On the other side, there have been claims that the success of LMs
obviates the need for studying linguistic theory and structure. We argue that
both extremes are wrong. LMs can contribute to fundamental questions about
linguistic structure, language processing, and learning. They force us to
rethink arguments about learning and are informative for major questions in
linguistic theory. But they do not replace linguistic structure and theory. We
offer an optimistic take on the relationship between language models and
linguistics.

摘要：語言模型可以產生流暢、符合文法的文字。儘管如此，有些人堅持認為語言模型並未真正學習語言，即使他們真的學習了，這對人類學習和處理的研究也沒有幫助。另一方面，有人聲稱語言模型的成功消除了研究語言學理論和結構的必要性。我們認為這兩種極端說法都是錯誤的。語言模型可以探討語言結構、語言處理和學習的基本問題。它們迫使我們重新思考關於學習的論點，並為語言學理論中的主要問題提供資訊。但它們並不能取代語言結構和理論。我們對語言模型和語言學之間的關係持樂觀態度。

##### **Synthesizing 3D Abstractions by Inverting Procedural Buildings with Transformers**
2501.17044v2 by Maximilian Dax, Jordi Berbel, Jan Stria, Leonidas Guibas, Urs Bergmann

We generate abstractions of buildings, reflecting the essential aspects of
their geometry and structure, by learning to invert procedural models. We first
build a dataset of abstract procedural building models paired with simulated
point clouds and then learn the inverse mapping through a transformer. Given a
point cloud, the trained transformer then infers the corresponding abstracted
building in terms of a programmatic language description. This approach
leverages expressive procedural models developed for gaming and animation, and
thereby retains desirable properties such as efficient rendering of the
inferred abstractions and strong priors for regularity and symmetry. Our
approach achieves good reconstruction accuracy in terms of geometry and
structure, as well as structurally consistent inpainting.

摘要：我們透過學習反轉程序模型，產生建築物的抽象化，反映其幾何形狀和結構的基本面向。我們首先建立一個抽象程序化建築模型的資料集，並與模擬點雲配對，然後透過轉換器學習反向對應。給定一個點雲，訓練好的轉換器接著會推論對應的抽象化建築，以程式語言描述的形式。這個方法利用了為遊戲和動畫開發的表達程序模型，從而保留了理想的屬性，例如有效渲染推論的抽象化，以及規則性和對稱性的強先驗。我們的做法在幾何形狀和結構方面達到了良好的重建準確度，並且在結構上具有一致的修復。

##### **Benchmarking Quantum Convolutional Neural Networks for Signal Classification in Simulated Gamma-Ray Burst Detection**
2501.17041v1 by Farida Farsian, Nicolò Parmiggiani, Alessandro Rizzo, Gabriele Panebianco, Andrea Bulgarelli, Francesco Schillirò, Carlo Burigana, Vincenzo Cardone, Luca Cappelli, Massimo Meneghetti, Giuseppe Murante, Giuseppe Sarracino, Roberto Scaramella, Vincenzo Testa, Tiziana Trombetti

This study evaluates the use of Quantum Convolutional Neural Networks (QCNNs)
for identifying signals resembling Gamma-Ray Bursts (GRBs) within simulated
astrophysical datasets in the form of light curves. The task addressed here
focuses on distinguishing GRB-like signals from background noise in simulated
Cherenkov Telescope Array Observatory (CTAO) data, the next-generation
astrophysical observatory for very high-energy gamma-ray science. QCNNs, a
quantum counterpart of classical Convolutional Neural Networks (CNNs), leverage
quantum principles to process and analyze high-dimensional data efficiently. We
implemented a hybrid quantum-classical machine learning technique using the
Qiskit framework, with the QCNNs trained on a quantum simulator. Several QCNN
architectures were tested, employing different encoding methods such as Data
Reuploading and Amplitude encoding. Key findings include that QCNNs achieved
accuracy comparable to classical CNNs, often surpassing 90\%, while using fewer
parameters, potentially leading to more efficient models in terms of
computational resources. A benchmark study further examined how hyperparameters
like the number of qubits and encoding methods affected performance, with more
qubits and advanced encoding methods generally enhancing accuracy but
increasing complexity. QCNNs showed robust performance on time-series datasets,
successfully detecting GRB signals with high precision. The research is a
pioneering effort in applying QCNNs to astrophysics, offering insights into
their potential and limitations. This work sets the stage for future
investigations to fully realize the advantages of QCNNs in astrophysical data
analysis.

摘要：本研究評估量子卷積神經網路 (QCNN) 在模擬光曲線形式的天體物理資料集中識別類似伽瑪射線暴 (GRB) 信號的用途。此處處理的任務專注於區分模擬切倫科夫望遠鏡陣列天文台 (CTAO) 資料中類 GRB 信號與背景雜訊，CTAO 是下一代極高能伽瑪射線科學的天體物理天文台。QCNN 是經典卷積神經網路 (CNN) 的量子對應物，利用量子原理有效率地處理和分析高維度資料。我們使用 Qiskit 架構實作了混合量子-經典機器學習技術，其中 QCNN 在量子模擬器上受訓。測試了數種 QCNN 架構，採用了不同的編碼方法，例如資料重新上傳和振幅編碼。主要發現包括 QCNN 達到了與經典 CNN 相當的準確度，通常超過 90%，同時使用較少的參數，這可能在計算資源方面導致更有效的模型。基準研究進一步探討了超參數（例如量子位元數和編碼方法）如何影響效能，通常更多量子位元和進階編碼方法會提高準確度，但也會增加複雜度。QCNN 在時間序列資料集上展現了強健的效能，成功地以高準確度偵測 GRB 信號。這項研究是將 QCNN 應用於天體物理學的先驅性努力，提供了對其潛力和限制的見解。這項工作為未來的研究奠定了基礎，以充分發揮 QCNN 在天體物理資料分析中的優勢。

##### **Challenges in Ensuring AI Safety in DeepSeek-R1 Models: The Shortcomings of Reinforcement Learning Strategies**
2501.17030v1 by Manojkumar Parmar, Yuvaraj Govindarajulu

Large Language Models (LLMs) have achieved remarkable progress in reasoning,
alignment, and task-specific performance. However, ensuring harmlessness in
these systems remains a critical challenge, particularly in advanced models
like DeepSeek-R1. This paper examines the limitations of Reinforcement Learning
(RL) as the primary approach for reducing harmful outputs in DeepSeek-R1 and
compares it with Supervised Fine-Tuning (SFT). While RL improves reasoning
capabilities, it faces challenges such as reward hacking, generalization
failures, language mixing, and high computational costs. We propose hybrid
training approaches combining RL and SFT to achieve robust harmlessness
reduction. Usage recommendations and future directions for deploying
DeepSeek-R1 responsibly are also presented.

摘要：大型語言模型 (LLM) 在推理、對齊和特定任務表現方面取得顯著進展。然而，確保這些系統的無害性仍然是一項嚴峻的挑戰，尤其是在 DeepSeek-R1 等先進模型中。本文探討了強化學習 (RL) 作為減少 DeepSeek-R1 中有害輸出之主要方法的限制，並將其與監督微調 (SFT) 進行比較。儘管 RL 改善了推理能力，但它面臨獎勵破解、泛化失敗、語言混淆和高計算成本等挑戰。我們提出結合 RL 和 SFT 的混合訓練方法，以實現穩健的無害性降低。還提出了負責任地部署 DeepSeek-R1 的使用建議和未來方向。

##### **Revisit Mixture Models for Multi-Agent Simulation: Experimental Study within a Unified Framework**
2501.17015v1 by Longzhong Lin, Xuewu Lin, Kechun Xu, Haojian Lu, Lichao Huang, Rong Xiong, Yue Wang

Simulation plays a crucial role in assessing autonomous driving systems,
where the generation of realistic multi-agent behaviors is a key aspect. In
multi-agent simulation, the primary challenges include behavioral multimodality
and closed-loop distributional shifts. In this study, we revisit mixture models
for generating multimodal agent behaviors, which can cover the mainstream
methods including continuous mixture models and GPT-like discrete models.
Furthermore, we introduce a closed-loop sample generation approach tailored for
mixture models to mitigate distributional shifts. Within the unified mixture
model~(UniMM) framework, we recognize critical configurations from both model
and data perspectives. We conduct a systematic examination of various model
configurations, including positive component matching, continuous regression,
prediction horizon, and the number of components. Moreover, our investigation
into the data configuration highlights the pivotal role of closed-loop samples
in achieving realistic simulations. To extend the benefits of closed-loop
samples across a broader range of mixture models, we further address the
shortcut learning and off-policy learning issues. Leveraging insights from our
exploration, the distinct variants proposed within the UniMM framework,
including discrete, anchor-free, and anchor-based models, all achieve
state-of-the-art performance on the WOSAC benchmark.

摘要：模擬在評估自動駕駛系統中扮演至關重要的角色，其中生成逼真的多主體行為是關鍵面向。在多主體模擬中，主要的挑戰包括行為的多模式性與閉環分佈轉移。在本研究中，我們重新探討混合模型來產生多模式主體行為，這可以涵蓋主流方法，包括連續混合模型和類似 GPT 的離散模型。此外，我們引入一種針對混合模型量身打造的閉環樣本生成方法，以減輕分佈轉移。在統一混合模型 (UniMM) 框架中，我們從模型和資料觀點識別關鍵配置。我們對各種模型配置進行系統性探討，包括正向元件匹配、連續回歸、預測範圍和元件數量。此外，我們對資料配置的研究強調了閉環樣本在實現逼真模擬中的關鍵作用。為了將閉環樣本的優點擴展到更廣泛的混合模型中，我們進一步解決捷徑學習和非策略學習問題。利用我們探索中的見解，在 UniMM 框架內提出的不同變體，包括離散、無錨點和基於錨點的模型，在 WOSAC 基準上都達到最先進的效能。

##### **Generative quantum combinatorial optimization by means of a novel conditional generative quantum eigensolver**
2501.16986v1 by Shunya Minami, Kouhei Nakaji, Yohichi Suzuki, Alán Aspuru-Guzik, Tadashi Kadowaki

Quantum computing is entering a transformative phase with the emergence of
logical quantum processors, which hold the potential to tackle complex problems
beyond classical capabilities. While significant progress has been made,
applying quantum algorithms to real-world problems remains challenging. Hybrid
quantum-classical techniques have been explored to bridge this gap, but they
often face limitations in expressiveness, trainability, or scalability. In this
work, we introduce conditional Generative Quantum Eigensolver
(conditional-GQE), a context-aware quantum circuit generator powered by an
encoder-decoder Transformer. Focusing on combinatorial optimization, we train
our generator for solving problems with up to 10 qubits, exhibiting nearly
perfect performance on new problems. By leveraging the high expressiveness and
flexibility of classical generative models, along with an efficient
preference-based training scheme, conditional-GQE provides a generalizable and
scalable framework for quantum circuit generation. Our approach advances hybrid
quantum-classical computing and contributes to accelerate the transition toward
fault-tolerant quantum computing.

摘要：量子運算正進入一個轉型階段，透過邏輯量子處理器的出現，它具備解決複雜問題的潛力，超越傳統的能力。儘管已取得重大進展，將量子演算法應用於現實世界的問題仍然具有挑戰性。混合量子古典技術已被探索用於彌合此差距，但它們在表達能力、可訓練性或可擴充性方面常常面臨限制。在這項工作中，我們引入了條件生成量子本徵求解器 (conditional-GQE)，這是一個由編碼器解碼器 Transformer 提供動力的情境感知量子電路生成器。專注於組合最佳化，我們訓練我們的生成器來解決高達 10 個量子位的問題，在新的問題上表現出接近完美的效能。透過利用古典生成模型的高表達能力和靈活性，以及一種有效基於偏好的訓練方案，條件生成量子本徵求解器提供了一個可概括且可擴充的量子電路生成架構。我們的做法推動了混合量子古典運算，並有助於加速朝向容錯量子運算的過渡。

##### **Over-Tokenized Transformer: Vocabulary is Generally Worth Scaling**
2501.16975v1 by Hongzhi Huang, Defa Zhu, Banggu Wu, Yutao Zeng, Ya Wang, Qiyang Min, Xun Zhou

Tokenization is a fundamental component of large language models (LLMs), yet
its influence on model scaling and performance is not fully explored. In this
paper, we introduce Over-Tokenized Transformers, a novel framework that
decouples input and output vocabularies to improve language modeling
performance. Specifically, our approach scales up input vocabularies to
leverage multi-gram tokens. Through extensive experiments, we uncover a
log-linear relationship between input vocabulary size and training loss,
demonstrating that larger input vocabularies consistently enhance model
performance, regardless of model size. Using a large input vocabulary, we
achieve performance comparable to double-sized baselines with no additional
cost. Our findings highlight the importance of tokenization in scaling laws and
provide practical insight for tokenizer design, paving the way for more
efficient and powerful LLMs.

摘要：分詞是大型語言模型 (LLM) 的基本組成部分，但
其對模型擴展和效能的影響尚未完全探索。在本文中，
我們介紹過度分詞Transformer，這是一個新穎的架構，
它解耦輸入和輸出詞彙表以改善語言建模
效能。具體來說，我們的做法是擴展輸入詞彙表以
利用多字元詞彙。透過廣泛的實驗，我們發現輸入詞彙量大小和訓練損失之間存在對數線性關係，
證明了較大的輸入詞彙量始終增強模型
效能，無論模型大小如何。使用大量的輸入詞彙量，我們
實現與雙倍大小基準相當的效能，而沒有額外的
成本。我們的發現突顯了分詞在擴充定律中的重要性，
並為分詞器設計提供了實用的見解，為更多
高效且強大的 LLM 鋪平了道路。

