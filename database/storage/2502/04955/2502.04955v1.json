{"2502.04955": {"publish_time": "2025-02-07", "title": "Claim Extraction for Fact-Checking: Data, Models, and Automated Metrics", "paper_summary": "In this paper, we explore the problem of Claim Extraction using one-to-many\ntext generation methods, comparing LLMs, small summarization models finetuned\nfor the task, and a previous NER-centric baseline QACG. As the current\npublications on Claim Extraction, Fact Extraction, Claim Generation and\nCheck-worthy Claim Detection are quite scattered in their means and\nterminology, we compile their common objectives, releasing the FEVERFact\ndataset, with 17K atomic factual claims extracted from 4K contextualised\nWikipedia sentences, adapted from the original FEVER. We compile the known\nobjectives into an Evaluation framework of: Atomicity, Fluency,\nDecontextualization, Faithfulness checked for each generated claim separately,\nand Focus and Coverage measured against the full set of predicted claims for a\nsingle input. For each metric, we implement a scale using a reduction to an\nalready-explored NLP task. We validate our metrics against human grading of\ngeneric claims, to see that the model ranking on $F_{fact}$, our hardest\nmetric, did not change and the evaluation framework approximates human grading\nvery closely in terms of $F_1$ and RMSE.", "paper_summary_zh": "\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u4e00\u5bf9\u591a\u7684\u6587\u672c\u751f\u6210\u65b9\u6cd5\u63a2\u8a0e\u8072\u660e\u62bd\u53d6\u7684\u554f\u984c\uff0c\u6bd4\u8f03 LLM\u3001\u91dd\u5c0d\u6b64\u4efb\u52d9\u5fae\u8abf\u7684\u5c0f\u578b\u6458\u8981\u6a21\u578b\u4ee5\u53ca\u5148\u524d\u7684 NER \u70ba\u4e2d\u5fc3\u7684\u57fa\u6e96 QACG\u3002\u7531\u65bc\u76ee\u524d\u95dc\u65bc\u8072\u660e\u62bd\u53d6\u3001\u4e8b\u5be6\u62bd\u53d6\u3001\u8072\u660e\u751f\u6210\u548c\u503c\u5f97\u6aa2\u67e5\u7684\u8072\u660e\u5075\u6e2c\u7684\u51fa\u7248\u7269\u5728\u65b9\u6cd5\u548c\u8853\u8a9e\u4e0a\u76f8\u7576\u5206\u6563\uff0c\u6211\u5011\u7de8\u5236\u4e86\u5b83\u5011\u7684\u5171\u540c\u76ee\u6a19\uff0c\u767c\u5e03\u4e86 FEVERFact \u8cc7\u6599\u96c6\uff0c\u5176\u4e2d\u5305\u542b\u5f9e 4K \u500b\u8a9e\u5883\u5316\u7dad\u57fa\u767e\u79d1\u53e5\u5b50\u4e2d\u62bd\u53d6\u7684 17K \u539f\u5b50\u4e8b\u5be6\u8072\u660e\uff0c\u6539\u7de8\u81ea\u539f\u59cb\u7684 FEVER\u3002\u6211\u5011\u5c07\u5df2\u77e5\u7684\u76ee\u6a19\u7de8\u8b6f\u6210\u4e00\u500b\u8a55\u4f30\u6846\u67b6\uff1a\u539f\u5b50\u6027\u3001\u6d41\u66a2\u6027\u3001\u53bb\u8108\u7d61\u5316\u3001\u5fe0\u5be6\u5ea6\u5206\u5225\u6aa2\u67e5\u6bcf\u500b\u751f\u6210\u7684\u8072\u660e\uff0c\u4ee5\u53ca\u91dd\u5c0d\u55ae\u4e00\u8f38\u5165\u9810\u6e2c\u7684\u8072\u660e\u5168\u96c6\u6e2c\u91cf\u7126\u9ede\u548c\u8986\u84cb\u7387\u3002\u5c0d\u65bc\u6bcf\u500b\u6307\u6a19\uff0c\u6211\u5011\u4f7f\u7528\u7c21\u5316\u70ba\u5df2\u63a2\u8a0e\u7684 NLP \u4efb\u52d9\u4f86\u5be6\u4f5c\u4e00\u500b\u91cf\u8868\u3002\u6211\u5011\u6839\u64da\u4eba\u985e\u5c0d\u4e00\u822c\u6027\u8072\u660e\u8a55\u7d1a\u9a57\u8b49\u6211\u5011\u7684\u6307\u6a19\uff0c\u4ee5\u67e5\u770b\u6a21\u578b\u5728 $F_{fact}$\uff08\u6211\u5011\u6700\u56f0\u96e3\u7684\u6307\u6a19\uff09\u4e0a\u7684\u6392\u540d\u6c92\u6709\u6539\u8b8a\uff0c\u4e26\u4e14\u8a55\u4f30\u6846\u67b6\u5728 $F_1$ \u548c RMSE \u65b9\u9762\u975e\u5e38\u63a5\u8fd1\u4eba\u985e\u8a55\u7d1a\u3002", "author": "Herbert Ullrich et.al.", "authors": "Herbert Ullrich, Tom\u00e1\u0161 Mlyn\u00e1\u0159, Jan Drchal", "id": "2502.04955v1", "paper_url": "http://arxiv.org/abs/2502.04955v1", "repo": "null"}}