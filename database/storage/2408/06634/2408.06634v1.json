{"2408.06634": {"publish_time": "2024-08-13", "title": "Harnessing Earnings Reports for Stock Predictions: A QLoRA-Enhanced LLM Approach", "paper_summary": "Accurate stock market predictions following earnings reports are crucial for\ninvestors. Traditional methods, particularly classical machine learning models,\nstruggle with these predictions because they cannot effectively process and\ninterpret extensive textual data contained in earnings reports and often\noverlook nuances that influence market movements. This paper introduces an\nadvanced approach by employing Large Language Models (LLMs) instruction\nfine-tuned with a novel combination of instruction-based techniques and\nquantized low-rank adaptation (QLoRA) compression. Our methodology integrates\n'base factors', such as financial metric growth and earnings transcripts, with\n'external factors', including recent market indices performances and analyst\ngrades, to create a rich, supervised dataset. This comprehensive dataset\nenables our models to achieve superior predictive performance in terms of\naccuracy, weighted F1, and Matthews correlation coefficient (MCC), especially\nevident in the comparison with benchmarks such as GPT-4. We specifically\nhighlight the efficacy of the llama-3-8b-Instruct-4bit model, which showcases\nsignificant improvements over baseline models. The paper also discusses the\npotential of expanding the output capabilities to include a 'Hold' option and\nextending the prediction horizon, aiming to accommodate various investment\nstyles and time frames. This study not only demonstrates the power of\nintegrating cutting-edge AI with fine-tuned financial data but also paves the\nway for future research in enhancing AI-driven financial analysis tools.", "paper_summary_zh": "\u5c0d\u65bc\u6295\u8cc7\u4eba\u800c\u8a00\uff0c\u5728\u6536\u76ca\u5831\u544a\u5f8c\u9032\u884c\u6e96\u78ba\u7684\u80a1\u5e02\u9810\u6e2c\u81f3\u95dc\u91cd\u8981\u3002\u50b3\u7d71\u65b9\u6cd5\uff0c\u7279\u5225\u662f\u7d93\u5178\u6a5f\u5668\u5b78\u7fd2\u6a21\u578b\uff0c\u5728\u9019\u4e9b\u9810\u6e2c\u4e2d\u9762\u81e8\u6311\u6230\uff0c\u56e0\u70ba\u5b83\u5011\u7121\u6cd5\u6709\u6548\u8655\u7406\u548c\u8a6e\u91cb\u6536\u76ca\u5831\u544a\u4e2d\u5305\u542b\u7684\u5ee3\u6cdb\u6587\u5b57\u8cc7\u6599\uff0c\u4e26\u4e14\u5e38\u5e38\u5ffd\u7565\u5f71\u97ff\u5e02\u5834\u6ce2\u52d5\u7684\u7d30\u5fae\u5dee\u5225\u3002\u672c\u6587\u4ecb\u7d39\u4e00\u7a2e\u5148\u9032\u7684\u65b9\u6cd5\uff0c\u63a1\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6307\u4ee4\uff0c\u4e26\u7d50\u5408\u57fa\u65bc\u6307\u4ee4\u7684\u6280\u8853\u548c\u91cf\u5316\u4f4e\u79e9\u9069\u61c9 (QLoRA) \u58d3\u7e2e\u9032\u884c\u5fae\u8abf\u3002\u6211\u5011\u7684\u6280\u8853\u6574\u5408\u4e86\u300c\u57fa\u672c\u56e0\u7d20\u300d\uff0c\u4f8b\u5982\u8ca1\u52d9\u6307\u6a19\u6210\u9577\u548c\u6536\u76ca\u7d00\u9304\uff0c\u4ee5\u53ca\u300c\u5916\u90e8\u56e0\u7d20\u300d\uff0c\u5305\u62ec\u8fd1\u671f\u5e02\u5834\u6307\u6578\u8868\u73fe\u548c\u5206\u6790\u5e2b\u8a55\u7d1a\uff0c\u4ee5\u5efa\u7acb\u4e00\u500b\u8c50\u5bcc\u7684\u76e3\u7763\u5f0f\u8cc7\u6599\u96c6\u3002\u9019\u500b\u5168\u9762\u7684\u8cc7\u6599\u96c6\u8b93\u6211\u5011\u7684\u6a21\u578b\u5728\u6e96\u78ba\u5ea6\u3001\u52a0\u6b0a F1 \u548c\u99ac\u4fee\u65af\u76f8\u95dc\u4fc2\u6578 (MCC) \u65b9\u9762\uff0c\u9054\u5230\u512a\u7570\u7684\u9810\u6e2c\u6548\u80fd\uff0c\u7279\u5225\u662f\u5728\u8207 GPT-4 \u7b49\u57fa\u6e96\u9032\u884c\u6bd4\u8f03\u6642\uff0c\u66f4\u70ba\u660e\u986f\u3002\u6211\u5011\u7279\u5225\u5f37\u8abf llama-3-8b-Instruct-4bit \u6a21\u578b\u7684\u6548\u80fd\uff0c\u5b83\u5c55\u793a\u51fa\u6bd4\u57fa\u6e96\u6a21\u578b\u6709\u986f\u8457\u7684\u9032\u6b65\u3002\u672c\u6587\u4e5f\u63a2\u8a0e\u4e86\u5c07\u8f38\u51fa\u80fd\u529b\u64f4\u5c55\u5230\u5305\u542b\u300c\u6301\u6709\u300d\u9078\u9805\uff0c\u4e26\u5ef6\u4f38\u9810\u6e2c\u7bc4\u570d\u7684\u53ef\u80fd\u6027\uff0c\u65e8\u5728\u5bb9\u7d0d\u5404\u7a2e\u6295\u8cc7\u98a8\u683c\u548c\u6642\u9593\u6846\u67b6\u3002\u672c\u7814\u7a76\u4e0d\u50c5\u5c55\u793a\u4e86\u6574\u5408\u5c16\u7aef AI \u8207\u5fae\u8abf\u8ca1\u52d9\u8cc7\u6599\u7684\u529b\u91cf\uff0c\u4e5f\u70ba\u672a\u4f86\u589e\u5f37 AI \u9a45\u52d5\u7684\u8ca1\u52d9\u5206\u6790\u5de5\u5177\u7684\u7814\u7a76\u92ea\u8def\u3002", "author": "Haowei Ni et.al.", "authors": "Haowei Ni, Shuchen Meng, Xupeng Chen, Ziqing Zhao, Andi Chen, Panfeng Li, Shiyao Zhang, Qifu Yin, Yuanqing Wang, Yuxi Chan", "id": "2408.06634v1", "paper_url": "http://arxiv.org/abs/2408.06634v1", "repo": "null"}}