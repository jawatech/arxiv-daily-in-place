{"2412.02935": {"publish_time": "2024-12-04", "title": "Dynamic Graph Neural Ordinary Differential Equation Network for Multi-modal Emotion Recognition in Conversation", "paper_summary": "Multimodal emotion recognition in conversation (MERC) refers to identifying\nand classifying human emotional states by combining data from multiple\ndifferent modalities (e.g., audio, images, text, video, etc.). Most existing\nmultimodal emotion recognition methods use GCN to improve performance, but\nexisting GCN methods are prone to overfitting and cannot capture the temporal\ndependency of the speaker's emotions. To address the above problems, we propose\na Dynamic Graph Neural Ordinary Differential Equation Network (DGODE) for MERC,\nwhich combines the dynamic changes of emotions to capture the temporal\ndependency of speakers' emotions, and effectively alleviates the overfitting\nproblem of GCNs. Technically, the key idea of DGODE is to utilize an adaptive\nmixhop mechanism to improve the generalization ability of GCNs and use the\ngraph ODE evolution network to characterize the continuous dynamics of node\nrepresentations over time and capture temporal dependencies. Extensive\nexperiments on two publicly available multimodal emotion recognition datasets\ndemonstrate that the proposed DGODE model has superior performance compared to\nvarious baselines. Furthermore, the proposed DGODE can also alleviate the\nover-smoothing problem, thereby enabling the construction of a deep GCN\nnetwork.", "paper_summary_zh": "\u591a\u6a21\u6001\u5bf9\u8bdd\u60c5\u611f\u8bc6\u522b\uff08MERC\uff09\u662f\u6307\u901a\u8fc7\u7ed3\u5408\u6765\u81ea\u591a\u79cd\u4e0d\u540c\u6a21\u6001\uff08\u4f8b\u5982\u97f3\u9891\u3001\u56fe\u50cf\u3001\u6587\u672c\u3001\u89c6\u9891\u7b49\uff09\u7684\u6570\u636e\u6765\u8bc6\u522b\u548c\u5206\u7c7b\u4eba\u7c7b\u60c5\u611f\u72b6\u6001\u3002\u5927\u591a\u6570\u73b0\u6709\u7684\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u65b9\u6cd5\u4f7f\u7528 GCN \u6765\u63d0\u9ad8\u6027\u80fd\uff0c\u4f46\u73b0\u6709\u7684 GCN \u65b9\u6cd5\u5bb9\u6613\u8fc7\u62df\u5408\uff0c\u5e76\u4e14\u65e0\u6cd5\u6355\u6349\u8bf4\u8bdd\u4eba\u60c5\u611f\u7684\u65f6\u95f4\u4f9d\u8d56\u6027\u3002\u4e3a\u4e86\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e MERC \u7684\u52a8\u6001\u56fe\u795e\u7ecf\u5e38\u5fae\u5206\u65b9\u7a0b\u7f51\u7edc (DGODE)\uff0c\u5b83\u7ed3\u5408\u4e86\u60c5\u611f\u7684\u52a8\u6001\u53d8\u5316\u6765\u6355\u6349\u8bf4\u8bdd\u4eba\u60c5\u611f\u7684\u65f6\u95f4\u4f9d\u8d56\u6027\uff0c\u5e76\u6709\u6548\u5730\u7f13\u89e3\u4e86 GCN \u7684\u8fc7\u62df\u5408\u95ee\u9898\u3002\u4ece\u6280\u672f\u4e0a\u8bb2\uff0cDGODE \u7684\u5173\u952e\u601d\u60f3\u662f\u5229\u7528\u81ea\u9002\u5e94\u6df7\u5408\u673a\u5236\u6765\u63d0\u9ad8 GCN \u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u4f7f\u7528\u56fe ODE \u6f14\u5316\u7f51\u7edc\u6765\u8868\u5f81\u8282\u70b9\u8868\u793a\u968f\u65f6\u95f4\u53d8\u5316\u7684\u8fde\u7eed\u52a8\u6001\u5e76\u6355\u6349\u65f6\u95f4\u4f9d\u8d56\u6027\u3002\u5728\u4e24\u4e2a\u516c\u5f00\u7684\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684 DGODE \u6a21\u578b\u4e0e\u5404\u79cd\u57fa\u7ebf\u76f8\u6bd4\u5177\u6709\u4f18\u8d8a\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0c\u6240\u63d0\u51fa\u7684 DGODE \u8fd8\u53ef\u4ee5\u7f13\u89e3\u8fc7\u5ea6\u5e73\u6ed1\u95ee\u9898\uff0c\u4ece\u800c\u80fd\u591f\u6784\u5efa\u6df1\u5ea6 GCN \u7f51\u7edc\u3002", "author": "Yuntao Shou et.al.", "authors": "Yuntao Shou, Tao Meng, Wei Ai, Keqin Li", "id": "2412.02935v1", "paper_url": "http://arxiv.org/abs/2412.02935v1", "repo": "null"}}