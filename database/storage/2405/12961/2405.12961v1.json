{"2405.12961": {"publish_time": "2024-05-21", "title": "Energy Rank Alignment: Using Preference Optimization to Search Chemical Space at Scale", "paper_summary": "Searching through chemical space is an exceptionally challenging problem\nbecause the number of possible molecules grows combinatorially with the number\nof atoms. Large, autoregressive models trained on databases of chemical\ncompounds have yielded powerful generators, but we still lack robust strategies\nfor generating molecules with desired properties. This molecular search problem\nclosely resembles the \"alignment\" problem for large language models, though for\nmany chemical tasks we have a specific and easily evaluable reward function.\nHere, we introduce an algorithm called energy rank alignment (ERA) that\nleverages an explicit reward function to produce a gradient-based objective\nthat we use to optimize autoregressive policies. We show theoretically that\nthis algorithm is closely related to proximal policy optimization (PPO) and\ndirect preference optimization (DPO), but has a minimizer that converges to an\nideal Gibbs-Boltzmann distribution with the reward playing the role of an\nenergy function. Furthermore, this algorithm is highly scalable, does not\nrequire reinforcement learning, and performs well relative to DPO when the\nnumber of preference observations per pairing is small. We deploy this approach\nto align molecular transformers to generate molecules with externally specified\nproperties and find that it does so robustly, searching through diverse parts\nof chemical space. While our focus here is on chemical search, we also obtain\nexcellent results on an AI supervised task for LLM alignment, showing that the\nmethod is scalable and general.", "paper_summary_zh": "<paragraph>\u5728\u5316\u5b78\u7a7a\u9593\u4e2d\u9032\u884c\u641c\u5c0b\u662f\u4e00\u500b\u6975\u5177\u6311\u6230\u6027\u7684\u554f\u984c\uff0c\u56e0\u70ba\u53ef\u80fd\u7684\u5206\u5b50\u6578\u91cf\u6703\u96a8\u8457\u539f\u5b50\u6578\u91cf\u7684\u589e\u52a0\u800c\u7d44\u5408\u5f0f\u589e\u9577\u3002\u5728\u5316\u5b78\u5316\u5408\u7269\u8cc7\u6599\u5eab\u4e0a\u8a13\u7df4\u7684\u5927\u578b\u81ea\u8ff4\u6b78\u6a21\u578b\u5df2\u7d93\u7522\u751f\u4e86\u5f37\u5927\u7684\u751f\u6210\u5668\uff0c\u4f46\u6211\u5011\u4ecd\u7136\u7f3a\u4e4f\u7528\u65bc\u751f\u6210\u5177\u6709\u6240\u9700\u5c6c\u6027\u7684\u5206\u5b50\u7684\u7a69\u5065\u7b56\u7565\u3002\u9019\u500b\u5206\u5b50\u641c\u5c0b\u554f\u984c\u8207\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u7684\u300c\u6bd4\u5c0d\u300d\u554f\u984c\u975e\u5e38\u76f8\u4f3c\uff0c\u5118\u7ba1\u5c0d\u65bc\u8a31\u591a\u5316\u5b78\u4efb\u52d9\uff0c\u6211\u5011\u6709\u4e00\u500b\u5177\u9ad4\u4e14\u6613\u65bc\u8a55\u4f30\u7684\u56de\u994b\u51fd\u6578\u3002\u5728\u6b64\uff0c\u6211\u5011\u5f15\u5165\u4e00\u7a2e\u7a31\u70ba\u80fd\u91cf\u7b49\u7d1a\u6bd4\u5c0d (ERA) \u7684\u6f14\u7b97\u6cd5\uff0c\u5b83\u5229\u7528\u660e\u78ba\u7684\u56de\u994b\u51fd\u6578\u4f86\u7522\u751f\u57fa\u65bc\u68af\u5ea6\u7684\u76ee\u6a19\uff0c\u6211\u5011\u4f7f\u7528\u8a72\u76ee\u6a19\u4f86\u6700\u4f73\u5316\u81ea\u8ff4\u6b78\u7b56\u7565\u3002\u6211\u5011\u5728\u7406\u8ad6\u4e0a\u8b49\u660e\u4e86\u9019\u500b\u6f14\u7b97\u6cd5\u8207\u8fd1\u7aef\u7b56\u7565\u6700\u4f73\u5316 (PPO) \u548c\u76f4\u63a5\u504f\u597d\u6700\u4f73\u5316 (DPO) \u5bc6\u5207\u76f8\u95dc\uff0c\u4f46\u5177\u6709\u6536\u6582\u5230\u7406\u60f3 Gibbs-Boltzmann \u5206\u5e03\u7684\u6700\u5c0f\u5316\u5668\uff0c\u5176\u4e2d\u56de\u994b\u626e\u6f14\u80fd\u91cf\u51fd\u6578\u7684\u89d2\u8272\u3002\u6b64\u5916\uff0c\u9019\u500b\u6f14\u7b97\u6cd5\u5177\u6709\u9ad8\u5ea6\u7684\u53ef\u64f4\u5145\u6027\uff0c\u4e0d\u9700\u8981\u5f37\u5316\u5b78\u7fd2\uff0c\u4e26\u4e14\u5728\u6bcf\u6b21\u914d\u5c0d\u7684\u504f\u597d\u89c0\u5bdf\u6578\u91cf\u8f03\u5c11\u6642\uff0c\u76f8\u5c0d\u65bc DPO \u7684\u8868\u73fe\u826f\u597d\u3002\u6211\u5011\u63a1\u7528\u9019\u7a2e\u65b9\u6cd5\u4f86\u6bd4\u5c0d\u5206\u5b50\u8f49\u63db\u5668\uff0c\u4ee5\u751f\u6210\u5177\u6709\u5916\u90e8\u6307\u5b9a\u5c6c\u6027\u7684\u5206\u5b50\uff0c\u4e26\u767c\u73fe\u5b83\u80fd\u7a69\u5065\u5730\u9032\u884c\u641c\u5c0b\uff0c\u5728\u5316\u5b78\u7a7a\u9593\u7684\u4e0d\u540c\u90e8\u5206\u4e2d\u9032\u884c\u641c\u5c0b\u3002\u96d6\u7136\u6211\u5011\u9019\u88e1\u7684\u91cd\u9ede\u662f\u5316\u5b78\u641c\u5c0b\uff0c\u4f46\u6211\u5011\u4e5f\u5728 LLM \u6bd4\u5c0d\u7684\u4eba\u5de5\u667a\u6167\u76e3\u7763\u4efb\u52d9\u4e2d\u7372\u5f97\u4e86\u6975\u4f73\u7684\u7d50\u679c\uff0c\u9019\u8868\u660e\u9019\u500b\u65b9\u6cd5\u5177\u6709\u53ef\u64f4\u5145\u6027\u548c\u901a\u7528\u6027\u3002</paragraph>", "author": "Shriram Chennakesavalu et.al.", "authors": "Shriram Chennakesavalu, Frank Hu, Sebastian Ibarraran, Grant M. Rotskoff", "id": "2405.12961v1", "paper_url": "http://arxiv.org/abs/2405.12961v1", "repo": "null"}}