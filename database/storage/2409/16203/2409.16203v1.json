{"2409.16203": {"publish_time": "2024-09-24", "title": "Facial Expression-Enhanced TTS: Combining Face Representation and Emotion Intensity for Adaptive Speech", "paper_summary": "We propose FEIM-TTS, an innovative zero-shot text-to-speech (TTS) model that\nsynthesizes emotionally expressive speech, aligned with facial images and\nmodulated by emotion intensity. Leveraging deep learning, FEIM-TTS transcends\ntraditional TTS systems by interpreting facial cues and adjusting to emotional\nnuances without dependence on labeled datasets. To address sparse\naudio-visual-emotional data, the model is trained using LRS3, CREMA-D, and MELD\ndatasets, demonstrating its adaptability. FEIM-TTS's unique capability to\nproduce high-quality, speaker-agnostic speech makes it suitable for creating\nadaptable voices for virtual characters. Moreover, FEIM-TTS significantly\nenhances accessibility for individuals with visual impairments or those who\nhave trouble seeing. By integrating emotional nuances into TTS, our model\nenables dynamic and engaging auditory experiences for webcomics, allowing\nvisually impaired users to enjoy these narratives more fully. Comprehensive\nevaluation evidences its proficiency in modulating emotion and intensity,\nadvancing emotional speech synthesis and accessibility. Samples are available\nat: https://feim-tts.github.io/.", "paper_summary_zh": "\u6211\u5011\u63d0\u51fa FEIM-TTS\uff0c\u9019\u662f\u4e00\u500b\u5275\u65b0\u7684\u96f6\u6b21\u5b78\u7fd2\u6587\u5b57\u8f49\u8a9e\u97f3 (TTS) \u6a21\u578b\uff0c\u5b83\u53ef\u4ee5\u5408\u6210\u5bcc\u6709\u60c5\u611f\u8868\u9054\u529b\u7684\u8a9e\u97f3\uff0c\u8207\u9762\u90e8\u5f71\u50cf\u5c0d\u9f4a\uff0c\u4e26\u6839\u64da\u60c5\u7dd2\u5f37\u5ea6\u9032\u884c\u8abf\u6574\u3002FEIM-TTS \u900f\u904e\u6df1\u5ea6\u5b78\u7fd2\u8d85\u8d8a\u50b3\u7d71\u7684 TTS \u7cfb\u7d71\uff0c\u5b83\u53ef\u4ee5\u89e3\u8b80\u9762\u90e8\u7dda\u7d22\u4e26\u8abf\u6574\u60c5\u7dd2\u7d30\u5fae\u5dee\u5225\uff0c\u800c\u7121\u9700\u4f9d\u8cf4\u6a19\u8a18\u8cc7\u6599\u96c6\u3002\u70ba\u4e86\u8655\u7406\u7a00\u758f\u7684\u8996\u807d\u60c5\u7dd2\u8cc7\u6599\uff0c\u6b64\u6a21\u578b\u4f7f\u7528 LRS3\u3001CREMA-D \u548c MELD \u8cc7\u6599\u96c6\u9032\u884c\u8a13\u7df4\uff0c\u5c55\u73fe\u5176\u9069\u61c9\u6027\u3002FEIM-TTS \u5177\u6709\u7368\u7279\u7684\u80fd\u529b\uff0c\u53ef\u4ee5\u7522\u751f\u9ad8\u54c1\u8cea\u3001\u8207\u8aaa\u8a71\u8005\u7121\u95dc\u7684\u8a9e\u97f3\uff0c\u9019\u4f7f\u5176\u9069\u7528\u65bc\u70ba\u865b\u64ec\u89d2\u8272\u5275\u9020\u53ef\u9069\u61c9\u7684\u8072\u97f3\u3002\u6b64\u5916\uff0cFEIM-TTS \u5927\u5e45\u63d0\u5347\u4e86\u8996\u969c\u4eba\u58eb\u6216\u6709\u8996\u529b\u554f\u984c\u8005\u7684\u7121\u969c\u7919\u6027\u3002\u900f\u904e\u5c07\u60c5\u7dd2\u7d30\u5fae\u5dee\u5225\u6574\u5408\u5230 TTS \u4e2d\uff0c\u6211\u5011\u7684\u6a21\u578b\u80fd\u70ba\u7db2\u8def\u6f2b\u756b\u5e36\u4f86\u52d5\u614b\u4e14\u5f15\u4eba\u5165\u52dd\u7684\u807d\u89ba\u9ad4\u9a57\uff0c\u8b93\u8996\u969c\u4f7f\u7528\u8005\u80fd\u66f4\u5145\u5206\u4eab\u53d7\u9019\u4e9b\u6558\u4e8b\u3002\u5168\u9762\u7684\u8a55\u4f30\u8b49\u660e\u4e86\u5176\u5728\u8abf\u6574\u60c5\u7dd2\u548c\u5f37\u5ea6\u65b9\u9762\u7684\u80fd\u529b\uff0c\u9032\u800c\u63a8\u52d5\u4e86\u60c5\u7dd2\u8a9e\u97f3\u5408\u6210\u548c\u7121\u969c\u7919\u6027\u3002\u7bc4\u4f8b\u53ef\u5728\u4ee5\u4e0b\u7db2\u5740\u53d6\u5f97\uff1ahttps://feim-tts.github.io/\u3002", "author": "Yunji Chu et.al.", "authors": "Yunji Chu, Yunseob Shim, Unsang Park", "id": "2409.16203v1", "paper_url": "http://arxiv.org/abs/2409.16203v1", "repo": "null"}}