{"2501.03468": {"publish_time": "2025-01-07", "title": "MTRAG: A Multi-Turn Conversational Benchmark for Evaluating Retrieval-Augmented Generation Systems", "paper_summary": "Retrieval-augmented generation (RAG) has recently become a very popular task\nfor Large Language Models (LLMs). Evaluating them on multi-turn RAG\nconversations, where the system is asked to generate a response to a question\nin the context of a preceding conversation is an important and often overlooked\ntask with several additional challenges. We present MTRAG: an end-to-end\nhuman-generated multi-turn RAG benchmark that reflects several real-world\nproperties across diverse dimensions for evaluating the full RAG pipeline.\nMTRAG contains 110 conversations averaging 7.7 turns each across four domains\nfor a total of 842 tasks. We also explore automation paths via synthetic data\nand LLM-as-a-Judge evaluation. Our human and automatic evaluations show that\neven state-of-the-art LLM RAG systems struggle on MTRAG. We demonstrate the\nneed for strong retrieval and generation systems that can handle later turns,\nunanswerable questions, non-standalone questions, and multiple domains. MTRAG\nis available at https://github.com/ibm/mt-rag-benchmark.", "paper_summary_zh": "\u6aa2\u7d22\u589e\u5f37\u751f\u6210 (RAG) \u8fd1\u671f\u5df2\u6210\u70ba\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4e2d\u975e\u5e38\u71b1\u9580\u7684\u4efb\u52d9\u3002\u5728\u591a\u8f2a RAG \u5c0d\u8a71\u4e2d\u8a55\u4f30\u5b83\u5011\uff0c\u7cfb\u7d71\u6703\u5728\u5148\u524d\u63d0\u51fa\u7684\u5c0d\u8a71\u5167\u5bb9\u4e2d\u7522\u751f\u5c0d\u554f\u984c\u7684\u56de\u61c9\uff0c\u9019\u662f\u4e00\u9805\u91cd\u8981\u4e14\u7d93\u5e38\u88ab\u5ffd\u7565\u7684\u4efb\u52d9\uff0c\u540c\u6642\u4e5f\u5e36\u4f86\u8a31\u591a\u984d\u5916\u7684\u6311\u6230\u3002\u6211\u5011\u63d0\u51fa MTRAG\uff1a\u4e00\u500b\u7aef\u5c0d\u7aef\u7684\u3001\u7531\u4eba\u985e\u7522\u751f\u7684\u591a\u8f2a RAG \u57fa\u6e96\uff0c\u5b83\u53cd\u6620\u4e86\u5404\u7a2e\u7dad\u5ea6\u4e2d\u591a\u9805\u771f\u5be6\u4e16\u754c\u7684\u5c6c\u6027\uff0c\u7528\u65bc\u8a55\u4f30\u5b8c\u6574\u7684 RAG \u7ba1\u7dda\u3002MTRAG \u5305\u542b 110 \u5834\u5c0d\u8a71\uff0c\u5e73\u5747\u6bcf\u5834\u5c0d\u8a71\u6709 7.7 \u8f2a\uff0c\u6db5\u84cb\u56db\u500b\u9818\u57df\uff0c\u7e3d\u5171\u6709 842 \u500b\u4efb\u52d9\u3002\u6211\u5011\u4e5f\u900f\u904e\u5408\u6210\u8cc7\u6599\u548c LLM \u4f5c\u70ba\u8a55\u5be9\u7684\u8a55\u4f30\uff0c\u63a2\u7d22\u81ea\u52d5\u5316\u8def\u5f91\u3002\u6211\u5011\u7684\u4eba\u985e\u548c\u81ea\u52d5\u8a55\u4f30\u986f\u793a\uff0c\u5373\u4f7f\u662f\u76ee\u524d\u6700\u5148\u9032\u7684 LLM RAG \u7cfb\u7d71\u5728 MTRAG \u4e0a\u4e5f\u96e3\u4ee5\u61c9\u4ed8\u3002\u6211\u5011\u8b49\u660e\u4e86\u5c0d\u5f37\u5927\u7684\u6aa2\u7d22\u548c\u751f\u6210\u7cfb\u7d71\u7684\u9700\u6c42\uff0c\u9019\u4e9b\u7cfb\u7d71\u53ef\u4ee5\u8655\u7406\u5f8c\u7e8c\u8f2a\u6b21\u3001\u7121\u6cd5\u56de\u7b54\u7684\u554f\u984c\u3001\u975e\u7368\u7acb\u554f\u984c\u548c\u591a\u500b\u9818\u57df\u3002MTRAG \u53ef\u5728 https://github.com/ibm/mt-rag-benchmark \u53d6\u5f97\u3002", "author": "Yannis Katsis et.al.", "authors": "Yannis Katsis, Sara Rosenthal, Kshitij Fadnis, Chulaka Gunasekara, Young-Suk Lee, Lucian Popa, Vraj Shah, Huaiyu Zhu, Danish Contractor, Marina Danilevsky", "id": "2501.03468v1", "paper_url": "http://arxiv.org/abs/2501.03468v1", "repo": "https://github.com/ibm/mt-rag-benchmark"}}