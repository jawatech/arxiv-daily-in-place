
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-07**|**Data Advisor: Dynamic Data Curation for Safety Alignment of Large Language Models**|Fei Wang et.al.|[2410.05269v1](http://arxiv.org/abs/2410.05269v1)|null|
|**2024-10-07**|**Grounding Partially-Defined Events in Multimodal Data**|Kate Sanders et.al.|[2410.05267v1](http://arxiv.org/abs/2410.05267v1)|null|
|**2024-10-07**|**PrefixQuant: Static Quantization Beats Dynamic through Prefixed Outliers in LLMs**|Mengzhao Chen et.al.|[2410.05265v1](http://arxiv.org/abs/2410.05265v1)|[link](https://github.com/chenmnz/prefixquant)|
|**2024-10-07**|**TurtleBench: Evaluating Top Language Models via Real-World Yes/No Puzzles**|Qingchen Yu et.al.|[2410.05262v1](http://arxiv.org/abs/2410.05262v1)|null|
|**2024-10-07**|**TextHawk2: A Large Vision-Language Model Excels in Bilingual OCR and Grounding with 16x Fewer Tokens**|Ya-Qi Yu et.al.|[2410.05261v1](http://arxiv.org/abs/2410.05261v1)|null|
|**2024-10-07**|**Differential Transformer**|Tianzhu Ye et.al.|[2410.05258v1](http://arxiv.org/abs/2410.05258v1)|null|
|**2024-10-07**|**GLEE: A Unified Framework and Benchmark for Language-based Economic Environments**|Eilam Shapira et.al.|[2410.05254v1](http://arxiv.org/abs/2410.05254v1)|null|
|**2024-10-07**|**Causal Micro-Narratives**|Mourad Heddaya et.al.|[2410.05252v1](http://arxiv.org/abs/2410.05252v1)|null|
|**2024-10-07**|**SFTMix: Elevating Language Model Instruction Tuning with Mixup Recipe**|Yuxin Xiao et.al.|[2410.05248v1](http://arxiv.org/abs/2410.05248v1)|null|
|**2024-10-07**|**Navigating the Digital World as Humans Do: Universal Visual Grounding for GUI Agents**|Boyu Gou et.al.|[2410.05243v1](http://arxiv.org/abs/2410.05243v1)|null|
|**2024-10-07**|**TuneVLSeg: Prompt Tuning Benchmark for Vision-Language Segmentation Models**|Rabin Adhikari et.al.|[2410.05239v1](http://arxiv.org/abs/2410.05239v1)|[link](https://github.com/naamiinepal/tunevlseg)|
|**2024-10-07**|**CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**|katerina Sviridova et.al.|[2410.05235v1](http://arxiv.org/abs/2410.05235v1)|null|
|**2024-10-07**|**GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models**|Iman Mirzadeh et.al.|[2410.05229v1](http://arxiv.org/abs/2410.05229v1)|null|
|**2024-10-07**|**Cookbook: A framework for improving LLM generative abilities via programmatic data generating templates**|Avanika Narayan et.al.|[2410.05224v1](http://arxiv.org/abs/2410.05224v1)|null|
|**2024-10-07**|**Precise Model Benchmarking with Only a Few Observations**|Riccardo Fogliato et.al.|[2410.05222v1](http://arxiv.org/abs/2410.05222v1)|null|
|**2024-10-07**|**Density estimation with LLMs: a geometric investigation of in-context learning trajectories**|Toni J. B. Liu et.al.|[2410.05218v1](http://arxiv.org/abs/2410.05218v1)|null|
|**2024-10-07**|**Preserving Multi-Modal Capabilities of Pre-trained VLMs for Improving Vision-Linguistic Compositionality**|Youngtaek Oh et.al.|[2410.05210v1](http://arxiv.org/abs/2410.05210v1)|[link](https://github.com/ytaek-oh/fsc-clip)|
|**2024-10-07**|**Studying and Mitigating Biases in Sign Language Understanding Models**|Katherine Atwell et.al.|[2410.05206v1](http://arxiv.org/abs/2410.05206v1)|null|
|**2024-10-07**|**RevisEval: Improving LLM-as-a-Judge via Response-Adapted References**|Qiyuan Zhang et.al.|[2410.05193v1](http://arxiv.org/abs/2410.05193v1)|null|
|**2024-10-07**|**Understanding Warmup-Stable-Decay Learning Rates: A River Valley Loss Landscape Perspective**|Kaiyue Wen et.al.|[2410.05192v1](http://arxiv.org/abs/2410.05192v1)|null|
|**2024-10-07**|**LADEV: A Language-Driven Testing and Evaluation Platform for Vision-Language-Action Models in Robotic Manipulation**|Zhijie Wang et.al.|[2410.05191v1](http://arxiv.org/abs/2410.05191v1)|null|
|**2024-10-07**|**Enhancing Equity in Large Language Models for Medical Applications**|Yuelyu Ji et.al.|[2410.05180v1](http://arxiv.org/abs/2410.05180v1)|null|
|**2024-10-07**|**ReasoningRank: Teaching Student Models to Rank through Reasoning-Based Knowledge Distillation**|Yuelyu Ji et.al.|[2410.05168v1](http://arxiv.org/abs/2410.05168v1)|null|
|**2024-10-07**|**Presto! Distilling Steps and Layers for Accelerating Music Generation**|Zachary Novack et.al.|[2410.05167v1](http://arxiv.org/abs/2410.05167v1)|null|
|**2024-10-07**|**Efficient Inference for Large Language Model-based Generative Recommendation**|Xinyu Lin et.al.|[2410.05165v1](http://arxiv.org/abs/2410.05165v1)|null|
|**2024-10-07**|**Deciphering the Interplay of Parametric and Non-parametric Memory in Retrieval-augmented Language Models**|Mehrdad Farahani et.al.|[2410.05162v1](http://arxiv.org/abs/2410.05162v1)|null|
|**2024-10-07**|**VLM2Vec: Training Vision-Language Models for Massive Multimodal Embedding Tasks**|Ziyan Jiang et.al.|[2410.05160v1](http://arxiv.org/abs/2410.05160v1)|null|
|**2024-10-07**|**CTC-GMM: CTC guided modality matching for fast and accurate streaming speech translation**|Rui Zhao et.al.|[2410.05146v1](http://arxiv.org/abs/2410.05146v1)|null|
|**2024-10-07**|**Scalable and Accurate Graph Reasoning with LLM-based Multi-Agents**|Yuwei Hu et.al.|[2410.05130v1](http://arxiv.org/abs/2410.05130v1)|null|
|**2024-10-07**|**Last Iterate Convergence in Monotone Mean Field Games**|Noboru Isobe et.al.|[2410.05127v1](http://arxiv.org/abs/2410.05127v1)|null|
|**2024-10-07**|**Human-Feedback Efficient Reinforcement Learning for Online Diffusion Model Finetuning**|Ayano Hiranaka et.al.|[2410.05116v1](http://arxiv.org/abs/2410.05116v1)|null|
|**2024-10-07**|**Synthetic Generation of Dermatoscopic Images with GAN and Closed-Form Factorization**|Rohan Reddy Mekala et.al.|[2410.05114v1](http://arxiv.org/abs/2410.05114v1)|null|
|**2024-10-07**|**SparsePO: Controlling Preference Alignment of LLMs via Sparse Token Masks**|Fenia Christopoulou et.al.|[2410.05102v1](http://arxiv.org/abs/2410.05102v1)|null|
|**2024-10-07**|**Investigating large language models for their competence in extracting grammatically sound sentences from transcribed noisy utterances**|Alina Wróblewska et.al.|[2410.05099v1](http://arxiv.org/abs/2410.05099v1)|null|
|**2024-10-07**|**On the Structure of Game Provenance and its Applications**|Shawn Bowers et.al.|[2410.05094v1](http://arxiv.org/abs/2410.05094v1)|null|
|**2024-10-07**|**Explanation sensitivity to the randomness of large language models: the case of journalistic text classification**|Jeremie Bogaert et.al.|[2410.05085v1](http://arxiv.org/abs/2410.05085v1)|null|
|**2024-10-07**|**ScienceAgentBench: Toward Rigorous Assessment of Language Agents for Data-Driven Scientific Discovery**|Ziru Chen et.al.|[2410.05080v1](http://arxiv.org/abs/2410.05080v1)|null|
|**2024-10-07**|**Compression via Pre-trained Transformers: A Study on Byte-Level Multimodal Data**|David Heurtel-Depeiges et.al.|[2410.05078v1](http://arxiv.org/abs/2410.05078v1)|null|
|**2024-10-07**|**ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering**|Francesco Maria Molfese et.al.|[2410.05077v1](http://arxiv.org/abs/2410.05077v1)|null|
|**2024-10-07**|**TidalDecode: Fast and Accurate LLM Decoding with Position Persistent Sparse Attention**|Lijie Yang et.al.|[2410.05076v1](http://arxiv.org/abs/2410.05076v1)|null|
|**2024-10-07**|**Transition of $α$-mixing in Random Iterations with Applications in Queuing Theory**|Attila Lovas et.al.|[2410.05056v1](http://arxiv.org/abs/2410.05056v1)|null|
|**2024-10-07**|**Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes**|Kosuke Nishida et.al.|[2410.05052v1](http://arxiv.org/abs/2410.05052v1)|null|
|**2024-10-07**|**FreSh: Frequency Shifting for Accelerated Neural Representation Learning**|Adam Kania et.al.|[2410.05050v1](http://arxiv.org/abs/2410.05050v1)|null|
|**2024-10-07**|**A test suite of prompt injection attacks for LLM-based machine translation**|Antonio Valerio Miceli-Barone et.al.|[2410.05047v1](http://arxiv.org/abs/2410.05047v1)|null|
|**2024-10-07**|**Named Clinical Entity Recognition Benchmark**|Wadood M Abdul et.al.|[2410.05046v1](http://arxiv.org/abs/2410.05046v1)|null|
|**2024-10-07**|**Can LLMs plan paths with extra hints from solvers?**|Erik Wu et.al.|[2410.05045v1](http://arxiv.org/abs/2410.05045v1)|null|
|**2024-10-07**|**PhotoReg: Photometrically Registering 3D Gaussian Splatting Models**|Ziwen Yuan et.al.|[2410.05044v1](http://arxiv.org/abs/2410.05044v1)|null|
|**2024-10-07**|**DEPT: Decoupled Embeddings for Pre-training Language Models**|Alex Iacob et.al.|[2410.05021v1](http://arxiv.org/abs/2410.05021v1)|null|
|**2024-10-07**|**On the Biased Assessment of Expert Finding Systems**|Jens-Joris Decorte et.al.|[2410.05018v1](http://arxiv.org/abs/2410.05018v1)|null|
|**2024-10-07**|**SkillMatch: Evaluating Self-supervised Learning of Skill Relatedness**|Jens-Joris Decorte et.al.|[2410.05006v1](http://arxiv.org/abs/2410.05006v1)|null|
|**2024-10-07**|**Stage-Wise and Prior-Aware Neural Speech Phase Prediction**|Fei Liu et.al.|[2410.04990v1](http://arxiv.org/abs/2410.04990v1)|null|
|**2024-10-07**|**On the Rigour of Scientific Writing: Criteria, Analysis, and Insights**|Joseph James et.al.|[2410.04981v1](http://arxiv.org/abs/2410.04981v1)|null|
|**2024-10-07**|**6DGS: Enhanced Direction-Aware Gaussian Splatting for Volumetric Rendering**|Zhongpai Gao et.al.|[2410.04974v1](http://arxiv.org/abs/2410.04974v1)|null|
|**2024-10-07**|**Collaboration! Towards Robust Neural Methods for Routing Problems**|Jianan Zhou et.al.|[2410.04968v1](http://arxiv.org/abs/2410.04968v1)|null|
|**2024-10-07**|**Activation Scaling for Steering and Interpreting Language Models**|Niklas Stoehr et.al.|[2410.04962v1](http://arxiv.org/abs/2410.04962v1)|null|
|**2024-10-07**|**Leverage Knowledge Graph and Large Language Model for Law Article Recommendation: A Case Study of Chinese Criminal Law**|Yongming Chen et.al.|[2410.04949v1](http://arxiv.org/abs/2410.04949v1)|null|
|**2024-10-07**|**Detecting and Approximating Redundant Computational Blocks in Neural Networks**|Irene Cannistraci et.al.|[2410.04941v1](http://arxiv.org/abs/2410.04941v1)|null|
|**2024-10-07**|**Training Interactive Agent in Large FPS Game Map with Rule-enhanced Reinforcement Learning**|Chen Zhang et.al.|[2410.04936v1](http://arxiv.org/abs/2410.04936v1)|null|
|**2024-10-07**|**The Role of Governments in Increasing Interconnected Post-Deployment Monitoring of AI**|Merlin Stein et.al.|[2410.04931v1](http://arxiv.org/abs/2410.04931v1)|null|
|**2024-10-07**|**Intent Classification for Bank Chatbots through LLM Fine-Tuning**|Bibiána Lajčinová et.al.|[2410.04925v1](http://arxiv.org/abs/2410.04925v1)|null|
|**2024-10-07**|**Defense-as-a-Service: Black-box Shielding against Backdoored Graph Models**|Xiao Yang et.al.|[2410.04916v1](http://arxiv.org/abs/2410.04916v1)|null|
|**2024-10-07**|**Patch is Enough: Naturalistic Adversarial Patch against Vision-Language Pre-training Models**|Dehong Kong et.al.|[2410.04884v1](http://arxiv.org/abs/2410.04884v1)|null|
|**2024-10-07**|**Leveraging Grammar Induction for Language Understanding and Generation**|Jushi Kai et.al.|[2410.04878v1](http://arxiv.org/abs/2410.04878v1)|null|
|**2024-10-07**|**TimeCNN: Refining Cross-Variable Interaction on Time Point for Time Series Forecasting**|Ao Hu et.al.|[2410.04853v1](http://arxiv.org/abs/2410.04853v1)|null|
|**2024-10-07**|**Rationale-Aware Answer Verification by Pairwise Self-Evaluation**|Akira Kawabata et.al.|[2410.04838v1](http://arxiv.org/abs/2410.04838v1)|null|
|**2024-10-07**|**As Simple as Fine-tuning: LLM Alignment via Bidirectional Negative Feedback Loss**|Xin Mao et.al.|[2410.04834v1](http://arxiv.org/abs/2410.04834v1)|null|
|**2024-10-07**|**Multimodal Fusion Strategies for Mapping Biophysical Landscape Features**|Lucia Gordon et.al.|[2410.04833v1](http://arxiv.org/abs/2410.04833v1)|null|
|**2024-10-07**|**MINER: Mining the Underlying Pattern of Modality-Specific Neurons in Multimodal Large Language Models**|Kaichen Huang et.al.|[2410.04819v1](http://arxiv.org/abs/2410.04819v1)|null|
|**2024-10-07**|**Resource-Efficient Multiview Perception: Integrating Semantic Masking with Masked Autoencoders**|Kosta Dakic et.al.|[2410.04817v1](http://arxiv.org/abs/2410.04817v1)|null|
|**2024-10-07**|**A Review of Artificial Intelligence based Biological-Tree Construction: Priorities, Methods, Applications and Trends**|Zelin Zang et.al.|[2410.04815v1](http://arxiv.org/abs/2410.04815v1)|null|
|**2024-10-07**|**Learning Interpretable Hierarchical Dynamical Systems Models from Time Series Data**|Manuel Brenner et.al.|[2410.04814v1](http://arxiv.org/abs/2410.04814v1)|null|
|**2024-10-07**|**LPZero: Language Model Zero-cost Proxy Search from Zero**|Peijie Dong et.al.|[2410.04808v1](http://arxiv.org/abs/2410.04808v1)|null|
|**2024-10-07**|**DAPE V2: Process Attention Score as Feature Map for Length Extrapolation**|Chuanyang Zheng et.al.|[2410.04798v1](http://arxiv.org/abs/2410.04798v1)|null|
|**2024-10-07**|**Representing the Under-Represented: Cultural and Core Capability Benchmarks for Developing Thai Large Language Models**|Dahyun Kim et.al.|[2410.04795v1](http://arxiv.org/abs/2410.04795v1)|null|
|**2024-10-07**|**GARLIC: LLM-Guided Dynamic Progress Control with Hierarchical Weighted Graph for Long Document QA**|Xinyu Wang et.al.|[2410.04790v1](http://arxiv.org/abs/2410.04790v1)|null|
|**2024-10-07**|**Analysis of Hybrid Compositions in Animation Film with Weakly Supervised Learning**|Mónica Apellaniz Portos et.al.|[2410.04789v1](http://arxiv.org/abs/2410.04789v1)|null|
|**2024-10-07**|**Formality is Favored: Unraveling the Learning Preferences of Large Language Models on Data with Conflicting Knowledge**|Jiahuan Li et.al.|[2410.04784v1](http://arxiv.org/abs/2410.04784v1)|null|
|**2024-10-07**|**Molecular topological deep learning for polymer property prediction**|Cong Shen et.al.|[2410.04765v1](http://arxiv.org/abs/2410.04765v1)|null|
|**2024-10-07**|**Driving with Regulation: Interpretable Decision-Making for Autonomous Vehicles with Retrieval-Augmented Reasoning via LLM**|Tianhui Cai et.al.|[2410.04759v1](http://arxiv.org/abs/2410.04759v1)|null|
|**2024-10-07**|**Item Cluster-aware Prompt Learning for Session-based Recommendation**|Wooseong Yang et.al.|[2410.04756v1](http://arxiv.org/abs/2410.04756v1)|null|
|**2024-10-07**|**ImProver: Agent-Based Automated Proof Optimization**|Riyaz Ahuja et.al.|[2410.04753v1](http://arxiv.org/abs/2410.04753v1)|null|
|**2024-10-07**|**Document-level Causal Relation Extraction with Knowledge-guided Binary Question Answering**|Zimu Wang et.al.|[2410.04752v1](http://arxiv.org/abs/2410.04752v1)|null|
|**2024-10-07**|**Intriguing Properties of Large Language and Vision Models**|Young-Jun Lee et.al.|[2410.04751v1](http://arxiv.org/abs/2410.04751v1)|null|
|**2024-10-07**|**Evaluating the Generalization Ability of Spatiotemporal Model in Urban Scenario**|Hongjun Wang et.al.|[2410.04740v1](http://arxiv.org/abs/2410.04740v1)|null|
|**2024-10-07**|**TableRAG: Million-Token Table Understanding with Language Models**|Si-An Chen et.al.|[2410.04739v1](http://arxiv.org/abs/2410.04739v1)|null|
|**2024-10-07**|**TLDR: Token-Level Detective Reward Model for Large Vision Language Models**|Deqing Fu et.al.|[2410.04734v1](http://arxiv.org/abs/2410.04734v1)|null|
|**2024-10-07**|**Efficient transformer with reinforced position embedding for language models**|Yen-Che Hsiao et.al.|[2410.04731v1](http://arxiv.org/abs/2410.04731v1)|null|
|**2024-10-07**|**Forgetting Curve: A Reliable Method for Evaluating Memorization Capability for Long-context Models**|Xinyu Liu et.al.|[2410.04727v1](http://arxiv.org/abs/2410.04727v1)|[link](https://github.com/1azybug/forgettingcurve)|
|**2024-10-07**|**ProtoNAM: Prototypical Neural Additive Models for Interpretable Deep Tabular Learning**|Guangzhi Xiong et.al.|[2410.04723v1](http://arxiv.org/abs/2410.04723v1)|[link](https://github.com/teddy-xionggz/protonam)|
|**2024-10-07**|**$\textbf{Only-IF}$:Revealing the Decisive Effect of Instruction Diversity on Generalization**|Dylan Zhang et.al.|[2410.04717v1](http://arxiv.org/abs/2410.04717v1)|null|
|**2024-10-07**|**Rule-based Data Selection for Large Language Models**|Xiaomin Li et.al.|[2410.04715v1](http://arxiv.org/abs/2410.04715v1)|null|
|**2024-10-07**|**Tight Stability, Convergence, and Robustness Bounds for Predictive Coding Networks**|Ankur Mali et.al.|[2410.04708v1](http://arxiv.org/abs/2410.04708v1)|null|
|**2024-10-07**|**Learning How Hard to Think: Input-Adaptive Allocation of LM Computation**|Mehul Damani et.al.|[2410.04707v1](http://arxiv.org/abs/2410.04707v1)|null|
|**2024-10-07**|**Modeling and Estimation of Vocal Tract and Glottal Source Parameters Using ARMAX-LF Model**|Kai Lia et.al.|[2410.04704v1](http://arxiv.org/abs/2410.04704v1)|null|
|**2024-10-07**|**The LLM Effect: Are Humans Truly Using LLMs, or Are They Being Influenced By Them Instead?**|Alexander S. Choi et.al.|[2410.04699v1](http://arxiv.org/abs/2410.04699v1)|null|
|**2024-10-07**|**MathHay: An Automated Benchmark for Long-Context Mathematical Reasoning in LLMs**|Lei Wang et.al.|[2410.04698v1](http://arxiv.org/abs/2410.04698v1)|null|
|**2024-10-07**|**Deeper Insights Without Updates: The Power of In-Context Learning Over Fine-Tuning**|Qingyu Yin et.al.|[2410.04691v1](http://arxiv.org/abs/2410.04691v1)|null|
|**2024-10-07**|**Towards Measuring Goal-Directedness in AI Systems**|Dylan Xu et.al.|[2410.04683v1](http://arxiv.org/abs/2410.04683v1)|null|
|**2024-10-07**|**Adversarial Multi-Agent Evaluation of Large Language Models through Iterative Debates**|Chaithanya Bandi et.al.|[2410.04663v1](http://arxiv.org/abs/2410.04663v1)|null|
|**2024-10-07**|**Knowledge Graph Based Agent for Complex, Knowledge-Intensive QA in Medicine**|Xiaorui Su et.al.|[2410.04660v1](http://arxiv.org/abs/2410.04660v1)|null|

#### Abstracts
##### **Data Advisor: Dynamic Data Curation for Safety Alignment of Large Language Models**
2410.05269v1 by Fei Wang, Ninareh Mehrabi, Palash Goyal, Rahul Gupta, Kai-Wei Chang, Aram Galstyan

Data is a crucial element in large language model (LLM) alignment. Recent
studies have explored using LLMs for efficient data collection. However,
LLM-generated data often suffers from quality issues, with underrepresented or
absent aspects and low-quality datapoints. To address these problems, we
propose Data Advisor, an enhanced LLM-based method for generating data that
takes into account the characteristics of the desired dataset. Starting from a
set of pre-defined principles in hand, Data Advisor monitors the status of the
generated data, identifies weaknesses in the current dataset, and advises the
next iteration of data generation accordingly. Data Advisor can be easily
integrated into existing data generation methods to enhance data quality and
coverage. Experiments on safety alignment of three representative LLMs (i.e.,
Mistral, Llama2, and Falcon) demonstrate the effectiveness of Data Advisor in
enhancing model safety against various fine-grained safety issues without
sacrificing model utility.

摘要：資料是大型語言模型（LLM）調整中的關鍵元素。最近的研究已探討使用 LLM 來進行有效率的資料收集。然而，由 LLM 生成的資料常有品質問題，包括代表性不足或遺漏面向，以及品質低落資料點。為了解決這些問題，我們提出資料顧問，這是一種進階的基於 LLM 的方法，用於生成資料，並考量到所需資料集的特徵。從一組預先定義的手邊原則開始，資料顧問會監控已生成資料的狀態，識別目前資料集的弱點，並據此建議下一次資料生成的迭代。資料顧問可以輕易整合到現有的資料生成方法中，以提升資料品質和涵蓋範圍。針對三個具代表性的 LLM（例如 Mistral、Llama2 和 Falcon）的安全調整進行的實驗，證明了資料顧問在提升模型安全，以對抗各種細微的安全問題，同時不犧牲模型效用的有效性。

##### **Grounding Partially-Defined Events in Multimodal Data**
2410.05267v1 by Kate Sanders, Reno Kriz, David Etter, Hannah Recknor, Alexander Martin, Cameron Carpenter, Jingyang Lin, Benjamin Van Durme

How are we able to learn about complex current events just from short
snippets of video? While natural language enables straightforward ways to
represent under-specified, partially observable events, visual data does not
facilitate analogous methods and, consequently, introduces unique challenges in
event understanding. With the growing prevalence of vision-capable AI agents,
these systems must be able to model events from collections of unstructured
video data. To tackle robust event modeling in multimodal settings, we
introduce a multimodal formulation for partially-defined events and cast the
extraction of these events as a three-stage span retrieval task. We propose a
corresponding benchmark for this task, MultiVENT-G, that consists of 14.5 hours
of densely annotated current event videos and 1,168 text documents, containing
22.8K labeled event-centric entities. We propose a collection of LLM-driven
approaches to the task of multimodal event analysis, and evaluate them on
MultiVENT-G. Results illustrate the challenges that abstract event
understanding poses and demonstrates promise in event-centric video-language
systems.

摘要：我們如何僅從影片的短片段中了解複雜的時事？雖然自然語言能以直接的方式表示未明確指定、部分可觀察的事件，但視覺資料無法促進類似的辦法，因此在事件理解方面引入了獨特的挑戰。隨著具備視覺能力的人工智慧代理日益普及，這些系統必須能夠根據非結構化影片資料的集合來建構事件模型。為了在多模態設定中處理穩健事件建模，我們引入了部分定義事件的多模態公式，並將這些事件的萃取視為三階段跨度擷取任務。我們提出此任務的對應基準 MultiVENT-G，其中包含 14.5 小時的密集註解時事影片和 1,168 份文字文件，包含 22.8K 個標籤事件中心實體。我們提出了一系列由 LLM 驅動的方法來執行多模態事件分析任務，並在 MultiVENT-G 上評估這些方法。結果說明了抽象事件理解所帶來的挑戰，並展示了以事件為中心的影片語言系統的潛力。

##### **PrefixQuant: Static Quantization Beats Dynamic through Prefixed Outliers in LLMs**
2410.05265v1 by Mengzhao Chen, Yi Liu, Jiahao Wang, Yi Bin, Wenqi Shao, Ping Luo

Quantization is essential for deploying Large Language Models (LLMs) by
enhancing memory efficiency and inference speed. Existing methods for
activation quantization mainly address channel-wise outliers, often neglecting
token-wise outliers, leading to reliance on costly per-token dynamic
quantization. To address this, we introduce PrefixQuant, a novel technique that
isolates outlier tokens offline without re-training. Specifically, PrefixQuant
identifies high-frequency outlier tokens and prefixes them in the KV cache,
preventing the generation of outlier tokens during inference and simplifying
quantization. To our knowledge, PrefixQuant is the first to enable efficient
per-tensor static quantization to outperform expensive per-token dynamic
quantization. For instance, in W4A4KV4 (4- bit weight, 4-bit activation, and
4-bit KV cache) Llama-3-8B, PrefixQuant with per-tensor static quantization
achieves a 7.43 WikiText2 perplexity and 71.08% average accuracy on 5
common-sense reasoning tasks, outperforming previous per-token dynamic
quantization methods like QuaRot with 0.98 perplexity improvement and +5.98
points accuracy. Additionally, the inference speed of W4A4 quantized models
using PrefixQuant is 1.60x to 2.81x faster than FP16 models and exceeds QuaRot
models by 1.2x to 1.3x. Our code is available at
\url{https://github.com/ChenMnZ/PrefixQuant}.

摘要：量化對於部署大型語言模型 (LLM) 至關重要，因為它能提升記憶體效率和推論速度。現有用於激活量化的方法主要針對通道外異常值，常常忽略了令牌外異常值，導致依賴於昂貴的逐令牌動態量化。為了解決這個問題，我們引入了 PrefixQuant，這是一種新穎的技術，可以在不重新訓練的情況下離線隔離異常令牌。具體來說，PrefixQuant 會識別高頻率異常令牌，並將它們置於 KV 快取中，防止在推論期間產生異常令牌，並簡化量化。據我們所知，PrefixQuant 是第一個能讓高效的逐張量靜態量化優於昂貴的逐令牌動態量化的技術。例如，在 W4A4KV4（4 位元權重、4 位元啟動和 4 位元 KV 快取）Llama-3-8B 中，採用逐張量靜態量化的 PrefixQuant 達到了 7.43 WikiText2 困惑度和 5 項常識推理任務的 71.08% 平均準確度，優於先前的逐令牌動態量化方法，例如 QuaRot，困惑度改善了 0.98，準確度提高了 +5.98 點。此外，使用 PrefixQuant 的 W4A4 量化模型的推論速度比 FP16 模型快 1.60 倍到 2.81 倍，並超過 QuaRot 模型 1.2 倍到 1.3 倍。我們的程式碼可在 \url{https://github.com/ChenMnZ/PrefixQuant} 取得。

##### **TurtleBench: Evaluating Top Language Models via Real-World Yes/No Puzzles**
2410.05262v1 by Qingchen Yu, Shichao Song, Ke Fang, Yunfeng Shi, Zifan Zheng, Hanyu Wang, Simin Niu, Zhiyu Li

As the application of Large Language Models (LLMs) expands, the demand for
reliable evaluations increases. Existing LLM evaluation benchmarks primarily
rely on static datasets, making it challenging to assess model performance in
dynamic interactions with users. Moreover, these benchmarks often depend on
specific background knowledge, complicating the measurement of a model's
logical reasoning capabilities. Other dynamic evaluation methods based on
strong models or manual efforts may introduce biases and incur high costs and
time demands, hindering large-scale application. To address these issues, we
propose TurtleBench. TurtleBench collects real user guesses from our online
Turtle Soup Puzzle platform that we developed. This approach allows for the
relatively dynamic generation of evaluation datasets, mitigating the risk of
model cheating while aligning assessments more closely with genuine user needs
for reasoning capabilities, thus enhancing the reliability of evaluations.
TurtleBench includes 1,532 user guesses along with the correctness of guesses
after annotation. Using this dataset, we thoroughly evaluated nine of the most
advanced LLMs available today. Notably, the OpenAI o1 series models did not
achieve leading results in these evaluations. We propose several hypotheses for
further research, such as "the latent reasoning of o1 utilizes trivial
Chain-of-Thought (CoT) techniques" and "increasing CoT length not only provides
reasoning benefits but also incurs noise costs."

摘要：隨著大型語言模型 (LLM) 應用範圍的擴展，對可靠評估的需求也隨之增加。現有的 LLM 評估基準主要依賴靜態數據集，這使得評估模型在與使用者的動態互動中的效能變得有挑戰性。此外，這些基準通常依賴於特定的背景知識，這使得衡量模型的邏輯推理能力變得複雜。其他基於強大模型或人工努力的動態評估方法可能會引入偏差，並造成高成本和時間需求，阻礙大規模應用。為了解決這些問題，我們提出了 TurtleBench。TurtleBench 從我們開發的線上 Turtle Soup Puzzle 平台收集真實使用者的猜測。這種方法允許相對動態地產生評估數據集，降低模型作弊的風險，同時讓評估更貼近使用者在推理能力方面的真實需求，從而提高評估的可靠性。TurtleBench 包含 1,532 個使用者猜測，以及猜測在註解後的正確性。使用這個數據集，我們徹底評估了當今最先進的九個 LLM。值得注意的是，OpenAI o1 系列模型在這些評估中未取得領先的結果。我們提出了幾個進一步研究的假設，例如「o1 的潛在推理利用了微不足道的思考鏈 (CoT) 技術」和「增加 CoT 長度不僅提供了推理優勢，還產生了雜訊成本」。

##### **TextHawk2: A Large Vision-Language Model Excels in Bilingual OCR and Grounding with 16x Fewer Tokens**
2410.05261v1 by Ya-Qi Yu, Minghui Liao, Jiwen Zhang, Jihao Wu

Reading dense text and locating objects within images are fundamental
abilities for Large Vision-Language Models (LVLMs) tasked with advanced jobs.
Previous LVLMs, including superior proprietary models like GPT-4o, have
struggled to excel in both tasks simultaneously. Moreover, previous LVLMs with
fine-grained perception cost thousands of tokens per image, making them
resource-intensive. We present TextHawk2, a bilingual LVLM featuring efficient
fine-grained perception and demonstrating cutting-edge performance across
general-purpose, OCR, and grounding tasks with 16 times fewer image tokens.
Critical improvements include: (1) Token Compression: Building on the efficient
architecture of its predecessor, TextHawk2 significantly reduces the number of
tokens per image by 16 times, facilitating training and deployment of the
TextHawk series with minimal resources. (2) Visual Encoder Reinforcement: We
enhance the visual encoder through LVLM co-training, unlocking its potential
for previously unseen tasks like Chinese OCR and grounding. (3) Data Diversity:
We maintain a comparable scale of 100 million samples while diversifying the
sources of pre-training data. We assess TextHawk2 across multiple benchmarks,
where it consistently delivers superior performance and outperforms
closed-source models of similar scale, such as achieving 78.4% accuracy on
OCRBench, 81.4% accuracy on ChartQA, 89.6% ANLS on DocVQA, and 88.1%
accuracy@0.5 on RefCOCOg-test.

摘要：閱讀密集文字和定位影像中的物件是大型視覺語言模型 (LVLMs) 執行進階工作時的基本能力。
包含 GPT-4o 等優秀專有模型在內的先前的 LVLMs 在同時執行這兩個工作時都難以表現出色。
此外，具有細緻知覺的先前 LVLMs 每張影像的成本高達數千個代幣，這讓它們消耗大量資源。
我們提出 TextHawk2，這是一個具備高效細緻知覺的雙語 LVLM，並在一般用途、OCR 和基礎工作中展現出先進的效能，而且影像代幣減少了 16 倍。
重要的改進包括：(1) 代幣壓縮：建構於其前身的高效架構上，TextHawk2 將每張影像的代幣數量大幅減少 16 倍，以最少的資源促進 TextHawk 系列的訓練和部署。(2) 視覺編碼器強化：我們透過 LVLM 共同訓練來強化視覺編碼器，發揮其在先前未見的工作（例如中文 OCR 和基礎）中的潛力。(3) 資料多樣性：我們維持 1 億個樣本的可比規模，同時使預訓練資料的來源多樣化。我們在多個基準測試中評估 TextHawk2，它始終提供優異的效能，並優於規模類似的閉源模型，例如在 OCRBench 上達到 78.4% 的準確度、在 ChartQA 上達到 81.4% 的準確度、在 DocVQA 上達到 89.6% 的 ANLS，以及在 RefCOCOg-test 上達到 88.1% 的準確度@0.5。

##### **Differential Transformer**
2410.05258v1 by Tianzhu Ye, Li Dong, Yuqing Xia, Yutao Sun, Yi Zhu, Gao Huang, Furu Wei

Transformer tends to overallocate attention to irrelevant context. In this
work, we introduce Diff Transformer, which amplifies attention to the relevant
context while canceling noise. Specifically, the differential attention
mechanism calculates attention scores as the difference between two separate
softmax attention maps. The subtraction cancels noise, promoting the emergence
of sparse attention patterns. Experimental results on language modeling show
that Diff Transformer outperforms Transformer in various settings of scaling up
model size and training tokens. More intriguingly, it offers notable advantages
in practical applications, such as long-context modeling, key information
retrieval, hallucination mitigation, in-context learning, and reduction of
activation outliers. By being less distracted by irrelevant context, Diff
Transformer can mitigate hallucination in question answering and text
summarization. For in-context learning, Diff Transformer not only enhances
accuracy but is also more robust to order permutation, which was considered as
a chronic robustness issue. The results position Diff Transformer as a highly
effective and promising architecture to advance large language models.

摘要：Transformer 傾向於過度將注意力分配給無關的內容。在這項工作中，我們引入了 Diff Transformer，它會放大對相關內容的注意力，同時消除雜訊。具體來說，差分注意力機制將注意力分數計算為兩個獨立 softmax 注意力圖之間的差異。減法消除了雜訊，促进了稀疏注意力模式的出現。語言建模的實驗結果表明，Diff Transformer 在擴展模型大小和訓練標記的各種設定中都優於 Transformer。更有趣的是，它在實用應用中提供了顯著的優勢，例如長內容建模、關鍵資訊檢索、幻覺減緩、情境學習和減少激活異常值。透過減少對無關內容的干擾，Diff Transformer 可以減輕問答和文字摘要中的幻覺。對於情境學習，Diff Transformer 不僅提高了準確性，而且對順序排列也更穩健，這被認為是一個長期的穩健性問題。這些結果將 Diff Transformer 定位為一種高效且有前途的架構，以推進大型語言模型。

##### **GLEE: A Unified Framework and Benchmark for Language-based Economic Environments**
2410.05254v1 by Eilam Shapira, Omer Madmon, Itamar Reinman, Samuel Joseph Amouyal, Roi Reichart, Moshe Tennenholtz

Large Language Models (LLMs) show significant potential in economic and
strategic interactions, where communication via natural language is often
prevalent. This raises key questions: Do LLMs behave rationally? Can they mimic
human behavior? Do they tend to reach an efficient and fair outcome? What is
the role of natural language in the strategic interaction? How do
characteristics of the economic environment influence these dynamics? These
questions become crucial concerning the economic and societal implications of
integrating LLM-based agents into real-world data-driven systems, such as
online retail platforms and recommender systems. While the ML community has
been exploring the potential of LLMs in such multi-agent setups, varying
assumptions, design choices and evaluation criteria across studies make it
difficult to draw robust and meaningful conclusions. To address this, we
introduce a benchmark for standardizing research on two-player, sequential,
language-based games. Inspired by the economic literature, we define three base
families of games with consistent parameterization, degrees of freedom and
economic measures to evaluate agents' performance (self-gain), as well as the
game outcome (efficiency and fairness). We develop an open-source framework for
interaction simulation and analysis, and utilize it to collect a dataset of LLM
vs. LLM interactions across numerous game configurations and an additional
dataset of human vs. LLM interactions. Through extensive experimentation, we
demonstrate how our framework and dataset can be used to: (i) compare the
behavior of LLM-based agents to human players in various economic contexts;
(ii) evaluate agents in both individual and collective performance measures;
and (iii) quantify the effect of the economic characteristics of the
environments on the behavior of agents.

摘要：大型語言模型 (LLM) 在經濟和策略互動中展現出顯著的潛力，其中透過自然語言進行溝通的情況經常出現。這引發了幾個關鍵問題：LLM 是否表現出理性行為？它們能模擬人類行為嗎？它們是否傾向於達成有效率且公平的結果？自然語言在策略互動中扮演什麼角色？經濟環境的特性如何影響這些動態？這些問題對於整合基於 LLM 的代理到現實世界資料驅動系統（例如線上零售平台和推薦系統）的經濟和社會影響至關重要。雖然機器學習社群一直在探索 LLM 在此類多重代理設定中的潛力，但不同研究中的假設、設計選擇和評估標準不同，使得難以得出穩健且有意義的結論。為了解決這個問題，我們針對雙人、循序、基於語言的遊戲引入了標準化研究的基準。受到經濟文獻的啟發，我們定義了三個基本遊戲家族，具有相符的參數化、自由度和經濟衡量標準，用於評估代理的表現（自我獲利），以及遊戲結果（效率和公平性）。我們開發了一個開放原始碼架構，用於互動模擬和分析，並利用它收集了 LLM 與 LLM 在許多遊戲配置中互動的資料集，以及人類與 LLM 互動的額外資料集。透過廣泛的實驗，我們展示了我們的架構和資料集如何用於：(i) 比較基於 LLM 的代理與人類玩家在各種經濟情境中的行為；(ii) 評估代理在個人和集體表現衡量標準中的表現；以及 (iii) 量化環境的經濟特性對代理行為的影響。

##### **Causal Micro-Narratives**
2410.05252v1 by Mourad Heddaya, Qingcheng Zeng, Chenhao Tan, Rob Voigt, Alexander Zentefis

We present a novel approach to classify causal micro-narratives from text.
These narratives are sentence-level explanations of the cause(s) and/or
effect(s) of a target subject. The approach requires only a subject-specific
ontology of causes and effects, and we demonstrate it with an application to
inflation narratives. Using a human-annotated dataset spanning historical and
contemporary US news articles for training, we evaluate several large language
models (LLMs) on this multi-label classification task. The best-performing
model--a fine-tuned Llama 3.1 8B--achieves F1 scores of 0.87 on narrative
detection and 0.71 on narrative classification. Comprehensive error analysis
reveals challenges arising from linguistic ambiguity and highlights how model
errors often mirror human annotator disagreements. This research establishes a
framework for extracting causal micro-narratives from real-world data, with
wide-ranging applications to social science research.

摘要：我們提出了一種新的方法，從文本中對因果微觀敘事進行分類。
這些敘事是對目標主體的成因和/或影響的句子級解釋。這種方法只需要一個特定於主體的因果關係本體論，我們通過應用於通貨膨脹敘事來展示它。使用涵蓋歷史和當代美國新聞文章的人工標註數據集進行訓練，我們在這個多標籤分類任務中評估了幾個大型語言模型 (LLM)。性能最佳的模型——微調後的 Llama 3.1 8B——在敘事檢測中獲得了 0.87 的 F1 分數，在敘事分類中獲得了 0.71 的 F1 分數。全面的錯誤分析揭示了語言歧義帶來的挑戰，並強調了模型錯誤如何經常反映人類標註者的分歧。這項研究建立了一個從現實世界數據中提取因果微觀敘事的框架，在社會科學研究中具有廣泛的應用。

##### **SFTMix: Elevating Language Model Instruction Tuning with Mixup Recipe**
2410.05248v1 by Yuxin Xiao, Shujian Zhang, Wenxuan Zhou, Marzyeh Ghassemi, Sanqiang Zhao

To induce desired behaviors in large language models (LLMs) for
interaction-driven tasks, the instruction-tuning stage typically trains LLMs on
instruction-response pairs using the next-token prediction (NTP) loss. Previous
work aiming to improve instruction-tuning performance often emphasizes the need
for higher-quality supervised fine-tuning (SFT) datasets, which typically
involves expensive data filtering with proprietary LLMs or labor-intensive data
generation by human annotators. However, these approaches do not fully leverage
the datasets' intrinsic properties, resulting in high computational and labor
costs, thereby limiting scalability and performance gains. In this paper, we
propose SFTMix, a novel recipe that elevates instruction-tuning performance
beyond the conventional NTP paradigm, without the need for well-curated
datasets. Observing that LLMs exhibit uneven confidence across the semantic
representation space, we argue that examples with different confidence levels
should play distinct roles during the instruction-tuning process. Based on this
insight, SFTMix leverages training dynamics to identify examples with varying
confidence levels, then applies a Mixup-based regularization to mitigate
overfitting on confident examples while propagating supervision signals to
improve learning on relatively unconfident ones. This approach enables SFTMix
to significantly outperform NTP across a wide range of instruction-following
and healthcare domain-specific SFT tasks, demonstrating its adaptability to
diverse LLM families and scalability to datasets of any size. Comprehensive
ablation studies further verify the robustness of SFTMix's design choices,
underscoring its versatility in consistently enhancing performance across
different LLMs and datasets in broader natural language processing
applications.

摘要：<paragraph>為了誘導大型語言模型 (LLM) 在互動驅動任務中產生想要的行為，指令調整階段通常使用下一個符號預測 (NTP) 損失在指令回應配對上訓練 LLM。先前旨在改善指令調整效能的研究，通常強調需要品質更高的監督微調 (SFT) 資料集，這通常涉及使用專有 LLM 進行昂貴的資料篩選或由人工註解人員進行大量資料產生。然而，這些方法並未充分利用資料集的內在屬性，導致高昂的運算和人力成本，因此限制了可擴充性和效能提升。在本文中，我們提出 SFTMix，這是一個創新的方法，可以提升指令調整效能，超越傳統的 NTP 典範，而且不需要精心整理的資料集。觀察到 LLM 在語意表示空間中展現出不均勻的信心，我們認為在指令調整過程中，具有不同信心層級的範例應扮演不同的角色。基於這個見解，SFTMix 利用訓練動態來識別具有不同信心層級的範例，然後應用基於 Mixup 的正規化來減輕對有信心的範例進行過度擬合，同時傳播監督訊號以改善對相對沒有信心的範例的學習。此方法讓 SFTMix 能在廣泛的指令遵循和醫療保健領域特定 SFT 任務中顯著優於 NTP，證明其對不同 LLM 家族的適應性和對任何規模資料集的可擴充性。全面的消融研究進一步驗證了 SFTMix 設計選擇的穩健性，強調其在更廣泛的自然語言處理應用中持續提升不同 LLM 和資料集效能的多功能性。</paragraph>

##### **Navigating the Digital World as Humans Do: Universal Visual Grounding for GUI Agents**
2410.05243v1 by Boyu Gou, Ruohan Wang, Boyuan Zheng, Yanan Xie, Cheng Chang, Yiheng Shu, Huan Sun, Yu Su

Multimodal large language models (MLLMs) are transforming the capabilities of
graphical user interface (GUI) agents, facilitating their transition from
controlled simulations to complex, real-world applications across various
platforms. However, the effectiveness of these agents hinges on the robustness
of their grounding capability. Current GUI agents predominantly utilize
text-based representations such as HTML or accessibility trees, which, despite
their utility, often introduce noise, incompleteness, and increased
computational overhead. In this paper, we advocate a human-like embodiment for
GUI agents that perceive the environment entirely visually and directly take
pixel-level operations on the GUI. The key is visual grounding models that can
accurately map diverse referring expressions of GUI elements to their
coordinates on the GUI across different platforms. We show that a simple
recipe, which includes web-based synthetic data and slight adaptation of the
LLaVA architecture, is surprisingly effective for training such visual
grounding models. We collect the largest dataset for GUI visual grounding so
far, containing 10M GUI elements and their referring expressions over 1.3M
screenshots, and use it to train UGround, a strong universal visual grounding
model for GUI agents. Empirical results on six benchmarks spanning three
categories (grounding, offline agent, and online agent) show that 1) UGround
substantially outperforms existing visual grounding models for GUI agents, by
up to 20% absolute, and 2) agents with UGround outperform state-of-the-art
agents, despite the fact that existing agents use additional text-based input
while ours only uses visual perception. These results provide strong support
for the feasibility and promises of GUI agents that navigate the digital world
as humans do.

摘要：多模态大型语言模型 (MLLM) 正在改变图形用户界面 (GUI) 代理的能力，促进它们从受控模拟向跨各种平台的复杂现实世界应用程序过渡。然而，这些代理的有效性取决于其基础能力的稳健性。当前的 GUI 代理主要使用基于文本的表示，例如 HTML 或无障碍树，尽管它们很实用，但通常会引入噪声、不完整性和增加的计算开销。在本文中，我们主张 GUI 代理采用类人化身，它们完全通过视觉感知环境并直接在 GUI 上执行像素级操作。关键在于视觉基础模型，它可以准确地将 GUI 元素的不同引用表达式映射到它们在不同平台上的 GUI 坐标。我们展示了一个简单的配方，其中包括基于网络的合成数据和 LLaVA 架构的轻微调整，对于训练此类视觉基础模型出人意料地有效。我们收集了迄今为止最大的 GUI 视觉基础数据集，其中包含 1000 万个 GUI 元素及其在 130 万个屏幕截图上的引用表达式，并使用它来训练 UGround，一个强大的 GUI 代理通用视觉基础模型。跨越三个类别（基础、离线代理和在线代理）的六个基准的经验结果表明，1）UGround 在 GUI 代理的现有视觉基础模型中表现明显优异，绝对值高达 20%，并且 2）使用 UGround 的代理优于最先进的代理，尽管现有代理使用额外的基于文本的输入，而我们的代理仅使用视觉感知。这些结果为 GUI 代理的可行性和前景提供了强有力的支持，这些代理像人类一样在数字世界中导航。

##### **TuneVLSeg: Prompt Tuning Benchmark for Vision-Language Segmentation Models**
2410.05239v1 by Rabin Adhikari, Safal Thapaliya, Manish Dhakal, Bishesh Khanal

Vision-Language Models (VLMs) have shown impressive performance in vision
tasks, but adapting them to new domains often requires expensive fine-tuning.
Prompt tuning techniques, including textual, visual, and multimodal prompting,
offer efficient alternatives by leveraging learnable prompts. However, their
application to Vision-Language Segmentation Models (VLSMs) and evaluation under
significant domain shifts remain unexplored. This work presents an open-source
benchmarking framework, TuneVLSeg, to integrate various unimodal and multimodal
prompt tuning techniques into VLSMs, making prompt tuning usable for downstream
segmentation datasets with any number of classes. TuneVLSeg includes $6$ prompt
tuning strategies on various prompt depths used in $2$ VLSMs totaling of $8$
different combinations. We test various prompt tuning on $8$ diverse medical
datasets, including $3$ radiology datasets (breast tumor, echocardiograph,
chest X-ray pathologies) and $5$ non-radiology datasets (polyp, ulcer, skin
cancer), and two natural domain segmentation datasets. Our study found that
textual prompt tuning struggles under significant domain shifts, from
natural-domain images to medical data. Furthermore, visual prompt tuning, with
fewer hyperparameters than multimodal prompt tuning, often achieves performance
competitive to multimodal approaches, making it a valuable first attempt. Our
work advances the understanding and applicability of different prompt-tuning
techniques for robust domain-specific segmentation. The source code is
available at https://github.com/naamiinepal/tunevlseg.

摘要：<paragraph>視覺語言模型 (VLM) 在視覺任務中表現出色，但要將其調整到新的領域通常需要昂貴的微調。提示調整技術，包括文字、視覺和多模態提示，通過利用可學習的提示提供了高效的替代方案。然而，它們在視覺語言分割模型 (VLSM) 中的應用和在顯著領域轉移下的評估仍未得到探索。這項工作提出了開源基準架構 TuneVLSeg，將各種單模態和多模態提示調整技術整合到 VLSM 中，使提示調整可用於具有任意數量類別的下游分割資料集。TuneVLSeg 包含 $6$ 個提示調整策略，用於 $2$ 個 VLSM 中使用的各種提示深度，總計 $8$ 個不同的組合。我們在 $8$ 個不同的醫療資料集上測試了各種提示調整，包括 $3$ 個放射科資料集（乳腺腫瘤、超音波心動圖、胸部 X 光病理）和 $5$ 個非放射科資料集（息肉、潰瘍、皮膚癌）以及兩個自然領域分割資料集。我們的研究發現，文字提示調整在顯著的領域轉移（從自然領域影像到醫療資料）中會遇到困難。此外，視覺提示調整的超參數比多模態提示調整少，通常可以達到與多模態方法競爭的效能，使其成為有價值的第一次嘗試。我們的研究推動了對不同提示調整技術在穩健領域特定分割中的理解和應用。原始碼可在 https://github.com/naamiinepal/tunevlseg 中取得。</paragraph>

##### **CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**
2410.05235v1 by katerina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri

Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.

摘要：解釋人工智慧 (AI) 的決策是當今 AI 的一項重大挑戰，特別是應用於醫療和法律等敏感情境時。然而，解釋決策背後的基本原理的需求，也是基於人類的審議的主要議題，因為有必要證明為何做出某項決策。例如，住院醫師不僅需要提供（可能是正確的）診斷，還需要解釋他們如何得出某個結論。因此，開發新的工具來幫助住院醫師訓練他們的解釋技能，是 AI 在教育中的核心目標。在本文中，我們遵循這個方向，並根據我們的知識，提出第一個多語言醫療問題解答資料集，其中臨床病例的正確和不正確診斷，都附有由醫師撰寫的自然語言解釋。這些解釋已使用論證組成（即前提、主張）和論證關係（即攻擊、支持）進行手動註解，產生多語言 CasiMedicos-Arg 資料集，其中包含 558 個臨床病例，使用四種語言（英語、西班牙語、法語、義大利語）撰寫解釋，我們註解了 5021 個主張、2313 個前提、2431 個支持關係和 1106 個攻擊關係。我們最後展示了競爭基準如何在論證探勘任務的這個具挑戰性資料集上執行。

##### **GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models**
2410.05229v1 by Iman Mirzadeh, Keivan Alizadeh, Hooman Shahrokhi, Oncel Tuzel, Samy Bengio, Mehrdad Farajtabar

Recent advancements in Large Language Models (LLMs) have sparked interest in
their formal reasoning capabilities, particularly in mathematics. The GSM8K
benchmark is widely used to assess the mathematical reasoning of models on
grade-school-level questions. While the performance of LLMs on GSM8K has
significantly improved in recent years, it remains unclear whether their
mathematical reasoning capabilities have genuinely advanced, raising questions
about the reliability of the reported metrics. To address these concerns, we
conduct a large-scale study on several SOTA open and closed models. To overcome
the limitations of existing evaluations, we introduce GSM-Symbolic, an improved
benchmark created from symbolic templates that allow for the generation of a
diverse set of questions. GSM-Symbolic enables more controllable evaluations,
providing key insights and more reliable metrics for measuring the reasoning
capabilities of models.Our findings reveal that LLMs exhibit noticeable
variance when responding to different instantiations of the same question.
Specifically, the performance of all models declines when only the numerical
values in the question are altered in the GSM-Symbolic benchmark. Furthermore,
we investigate the fragility of mathematical reasoning in these models and show
that their performance significantly deteriorates as the number of clauses in a
question increases. We hypothesize that this decline is because current LLMs
cannot perform genuine logical reasoning; they replicate reasoning steps from
their training data. Adding a single clause that seems relevant to the question
causes significant performance drops (up to 65%) across all state-of-the-art
models, even though the clause doesn't contribute to the reasoning chain needed
for the final answer. Overall, our work offers a more nuanced understanding of
LLMs' capabilities and limitations in mathematical reasoning.

摘要：<paragraph>大型語言模型 (LLM) 最近的進展，激發了人們對其形式推理能力的興趣，特別是在數學方面。GSM8K 基準廣泛用於評估模型在小學程度問題上的數學推理能力。儘管近年來 LLM 在 GSM8K 上的表現有了顯著提升，但其數學推理能力是否真正進步仍不清楚，這引發了對報告指標可靠性的質疑。為了解決這些問題，我們對幾個 SOTA 開放和封閉模型進行了大規模研究。為了克服現有評估的限制，我們引入了 GSM-Symbolic，這是一個從符號模板創建的改進基準，允許生成多樣化的問題集。GSM-Symbolic 能夠進行更可控的評估，為衡量模型推理能力提供關鍵見解和更可靠的指標。我們的研究結果表明，LLM 在回答同一問題的不同實例時表現出明顯的差異。具體來說，當 GSM-Symbolic 基準中僅更改問題中的數值時，所有模型的性能都會下降。此外，我們研究了這些模型中數學推理的脆弱性，並表明隨著問題中子句數量的增加，它們的性能會顯著下降。我們假設這種下降是因為當前的 LLM 無法執行真正的邏輯推理；它們從訓練數據中複製推理步驟。添加一個看似與問題相關的單一子句會導致所有最先進模型的性能顯著下降（高達 65%），即使該子句不會影響最終答案所需的推理鏈。總的來說，我們的研究對 LLM 在數學推理方面的能力和局限性提供了更細緻的理解。</paragraph>

##### **Cookbook: A framework for improving LLM generative abilities via programmatic data generating templates**
2410.05224v1 by Avanika Narayan, Mayee F. Chen, Kush Bhatia, Christopher Ré

Fine-tuning large language models (LLMs) on instruction datasets is a common
way to improve their generative capabilities. However, instruction datasets can
be expensive and time-consuming to manually curate, and while LLM-generated
data is less labor-intensive, it may violate user privacy agreements or terms
of service of LLM providers. Therefore, we seek a way of constructing
instruction datasets with samples that are not generated by humans or LLMs but
still improve LLM generative capabilities. In this work, we introduce Cookbook,
a framework that programmatically generates training data consisting of simple
patterns over random tokens, resulting in a scalable, cost-effective approach
that avoids legal and privacy issues. First, Cookbook uses a template -- a data
generating Python function -- to produce training data that encourages the
model to learn an explicit pattern-based rule that corresponds to a desired
task. We find that fine-tuning on Cookbook-generated data is able to improve
performance on its corresponding task by up to 52.7 accuracy points. Second,
since instruction datasets improve performance on multiple downstream tasks
simultaneously, Cookbook algorithmically learns how to mix data from various
templates to optimize performance on multiple tasks. On the standard multi-task
GPT4ALL evaluation suite, Mistral-7B fine-tuned using a Cookbook-generated
dataset attains the best accuracy on average compared to other 7B parameter
instruction-tuned models and is the best performing model on 3 out of 8 tasks.
Finally, we analyze when and why Cookbook improves performance and present a
metric that allows us to verify that the improvement is largely explained by
the model's generations adhering better to template rules.

摘要：<paragraph>微調大型語言模型 (LLM) 的指令資料集是一種常見的改善其生成能力的方法。然而，指令資料集的建立可能需要大量手動整理，且耗時費力；而 LLM 生成的資料雖然較不費力，卻可能違反使用者的隱私協議或 LLM 提供者的服務條款。因此，我們尋求一種方法來建構指令資料集，其中包含的範例並非由人類或 LLM 生成，但仍能提升 LLM 的生成能力。在本文中，我們介紹 Cookbook，一個以程式方式生成訓練資料的架構，這些資料由隨機代碼上的簡單模式組成，進而產生一種可擴充、經濟實惠的方法，避免法律和隱私問題。首先，Cookbook 使用一個範本（一個資料產生 Python 函式）來產生訓練資料，鼓勵模型學習與所需任務相對應的明確模式化規則。我們發現微調 Cookbook 生成的資料能夠將其對應任務的效能提升多達 52.7 個準確度點。其次，由於指令資料集可以同時提升多個下游任務的效能，Cookbook 以演算法的方式學習如何混合來自不同範本的資料，以最佳化多個任務的效能。在標準多任務 GPT4ALL 評量套件上，微調使用 Cookbook 生成的資料集的 Mistral-7B 在與其他 7B 參數指令微調模型相比之下，平均準確度最高，且在 8 個任務中有 3 個任務的表現最佳。最後，我們分析 Cookbook 何時以及為何提升效能，並提出一個指標，讓我們能夠驗證效能提升在很大程度上是由於模型的生成更符合範本規則所致。</paragraph>

##### **Precise Model Benchmarking with Only a Few Observations**
2410.05222v1 by Riccardo Fogliato, Pratik Patil, Nil-Jana Akpinar, Mathew Monfort

How can we precisely estimate a large language model's (LLM) accuracy on
questions belonging to a specific topic within a larger question-answering
dataset? The standard direct estimator, which averages the model's accuracy on
the questions in each subgroup, may exhibit high variance for subgroups
(topics) with small sample sizes. Synthetic regression modeling, which
leverages the model's accuracy on questions about other topics, may yield
biased estimates that are too unreliable for large subgroups. We prescribe a
simple yet effective solution: an empirical Bayes (EB) estimator that balances
direct and regression estimates for each subgroup separately, improving the
precision of subgroup-level estimates of model performance. Our experiments on
multiple datasets show that this approach consistently provides more precise
estimates of the LLM performance compared to the direct and regression
approaches, achieving substantial reductions in the mean squared error.
Confidence intervals for EB estimates also have near-nominal coverage and are
narrower compared to those for the direct estimator. Additional experiments on
tabular and vision data validate the benefits of this EB approach.

摘要：如何精準估計大型語言模型 (LLM) 在較大型問答資料集內特定主題問題上的準確度？標準直接估計器會針對每個子群組中的問題平均模型的準確度，對於樣本量較小的子群組（主題）可能會出現高變異。合成迴歸模型會利用模型在其他主題問題上的準確度，可能會產生有偏差的估計值，對於大型子群組來說過於不可靠。我們建議一個簡單但有效的解決方案：一個經驗貝氏 (EB) 估計器，分別針對每個子群組平衡直接和迴歸估計值，改善模型效能子群組層級估計值的精準度。我們在多個資料集上的實驗顯示，與直接和迴歸方法相比，這種方法持續提供 LLM 效能更精準的估計值，大幅降低均方誤差。EB 估計值的信心區間也具有近乎名義上的覆蓋率，並且比直接估計器的信心區間更窄。在表格和視覺資料上的其他實驗驗證了這種 EB 方法的好處。

##### **Density estimation with LLMs: a geometric investigation of in-context learning trajectories**
2410.05218v1 by Toni J. B. Liu, Nicolas Boullé, Raphaël Sarfati, Christopher J. Earls

Large language models (LLMs) demonstrate remarkable emergent abilities to
perform in-context learning across various tasks, including time series
forecasting. This work investigates LLMs' ability to estimate probability
density functions (PDFs) from data observed in-context; such density estimation
(DE) is a fundamental task underlying many probabilistic modeling problems. We
leverage the Intensive Principal Component Analysis (InPCA) to visualize and
analyze the in-context learning dynamics of LLaMA-2 models. Our main finding is
that these LLMs all follow similar learning trajectories in a low-dimensional
InPCA space, which are distinct from those of traditional density estimation
methods like histograms and Gaussian kernel density estimation (KDE). We
interpret the LLaMA in-context DE process as a KDE with an adaptive kernel
width and shape. This custom kernel model captures a significant portion of
LLaMA's behavior despite having only two parameters. We further speculate on
why LLaMA's kernel width and shape differs from classical algorithms, providing
insights into the mechanism of in-context probabilistic reasoning in LLMs.

摘要：大型語言模型 (LLM) 展示了非凡的新興能力，可以在各種任務中執行情境學習，包括時間序列預測。這項工作探討了 LLM 從情境中觀察到的資料估計機率密度函數 (PDF) 的能力；這種密度估計 (DE) 是許多機率模型問題的基礎任務。我們利用密集主成分分析 (InPCA) 來視覺化和分析 LLaMA-2 模型的情境學習動態。我們的發現是，這些 LLM 在低維度 InPCA 空間中都遵循類似的學習軌跡，這與直方圖和高斯核密度估計 (KDE) 等傳統密度估計方法不同。我們將 LLaMA 情境 DE 過程解釋為具有自適應核寬度和形狀的 KDE。儘管只有兩個參數，但此自訂核模型仍捕捉到 LLaMA 行為的重要部分。我們進一步推測 LLaMA 的核寬度和形狀與經典演算法不同的原因，並深入了解 LLM 中情境機率推理的機制。

##### **Preserving Multi-Modal Capabilities of Pre-trained VLMs for Improving Vision-Linguistic Compositionality**
2410.05210v1 by Youngtaek Oh, Jae Won Cho, Dong-Jin Kim, In So Kweon, Junmo Kim

In this paper, we propose a new method to enhance compositional understanding
in pre-trained vision and language models (VLMs) without sacrificing
performance in zero-shot multi-modal tasks. Traditional fine-tuning approaches
often improve compositional reasoning at the cost of degrading multi-modal
capabilities, primarily due to the use of global hard negative (HN) loss, which
contrasts global representations of images and texts. This global HN loss
pushes HN texts that are highly similar to the original ones, damaging the
model's multi-modal representations. To overcome this limitation, we propose
Fine-grained Selective Calibrated CLIP (FSC-CLIP), which integrates local hard
negative loss and selective calibrated regularization. These innovations
provide fine-grained negative supervision while preserving the model's
representational integrity. Our extensive evaluations across diverse benchmarks
for both compositionality and multi-modal tasks show that FSC-CLIP not only
achieves compositionality on par with state-of-the-art models but also retains
strong multi-modal capabilities. Code is available at:
https://github.com/ytaek-oh/fsc-clip.

摘要：<paragraph>在本文中，我們提出了一種新的方法來增強預訓練視覺和語言模型 (VLM) 中的組合理解，同時不犧牲零次學習多模式任務的性能。傳統的微調方法通常會以降低多模式能力為代價來改進組合推理，這主要是由於使用了全局硬負例 (HN) 損失，這與圖像和文本的全局表示形成對比。此全局 HN 損失會推動與原始文本高度相似的 HN 文本，損害模型的多模式表示。為了克服這個限制，我們提出了細粒度選擇性校準 CLIP (FSC-CLIP)，它整合了局部硬負例損失和選擇性校準正則化。這些創新提供了細粒度的負面監督，同時保留了模型的表示完整性。我們對組合性和多模式任務的各種基準進行的廣泛評估表明，FSC-CLIP 不僅實現了與最先進模型相當的組合性，而且還保留了強大的多模式能力。程式碼可在以下位置取得：
https://github.com/ytaek-oh/fsc-clip。</paragraph>

##### **Studying and Mitigating Biases in Sign Language Understanding Models**
2410.05206v1 by Katherine Atwell, Danielle Bragg, Malihe Alikhani

Ensuring that the benefits of sign language technologies are distributed
equitably among all community members is crucial. Thus, it is important to
address potential biases and inequities that may arise from the design or use
of these resources. Crowd-sourced sign language datasets, such as the ASL
Citizen dataset, are great resources for improving accessibility and preserving
linguistic diversity, but they must be used thoughtfully to avoid reinforcing
existing biases.
  In this work, we utilize the rich information about participant demographics
and lexical features present in the ASL Citizen dataset to study and document
the biases that may result from models trained on crowd-sourced sign datasets.
Further, we apply several bias mitigation techniques during model training, and
find that these techniques reduce performance disparities without decreasing
accuracy. With the publication of this work, we release the demographic
information about the participants in the ASL Citizen dataset to encourage
future bias mitigation work in this space.

摘要：確保手語技術的優勢能公平地分配給所有社區成員至關重要。因此，了解在設計或使用這些資源時可能產生的潛在偏差和不公平性很重要。群眾外包手語資料集（例如 ASL Citizen 資料集）是改善無障礙性和維護語言多樣性的絕佳資源，但必須謹慎使用，以避免強化現有的偏差。
在這項工作中，我們利用 ASL Citizen 資料集中參與者的豐富人口統計資料和詞彙特徵，來研究和記錄由群眾外包手語資料集訓練的模型可能產生的偏差。此外，我們在模型訓練期間套用多種偏差緩解技術，並發現這些技術減少了效能差異，卻沒有降低準確性。隨著這項工作的發表，我們公佈了 ASL Citizen 資料集中參與者的人口統計資料，以鼓勵未來在此領域進行偏差緩解工作。

##### **RevisEval: Improving LLM-as-a-Judge via Response-Adapted References**
2410.05193v1 by Qiyuan Zhang, Yufei Wang, Tiezheng YU, Yuxin Jiang, Chuhan Wu, Liangyou Li, Yasheng Wang, Xin Jiang, Lifeng Shang, Ruiming Tang, Fuyuan Lyu, Chen Ma

With significant efforts in recent studies, LLM-as-a-Judge has become a
cost-effective alternative to human evaluation for assessing the text
generation quality in a wide range of tasks. However, there still remains a
reliability gap between LLM-as-a-Judge and human evaluation. One important
reason is the lack of guided oracles in the evaluation process. Motivated by
the role of reference pervasively used in classic text evaluation, we introduce
RevisEval, a novel text generation evaluation paradigm via the response-adapted
references. RevisEval is driven by the key observation that an ideal reference
should maintain the necessary relevance to the response to be evaluated.
Specifically, RevisEval leverages the text revision capabilities of large
language models (LLMs) to adaptively revise the response, then treat the
revised text as the reference (response-adapted reference) for the subsequent
evaluation. Extensive experiments demonstrate that RevisEval outperforms
traditional reference-free and reference-based evaluation paradigms that use
LLM-as-a-Judge across NLG tasks and open-ended instruction-following tasks.
More importantly, our response-adapted references can further boost the
classical text metrics, e.g., BLEU and BERTScore, compared to traditional
references and even rival the LLM-as-a-Judge. A detailed analysis is also
conducted to confirm RevisEval's effectiveness in bias reduction, the impact of
inference cost, and reference relevance.

摘要：<paragraph>在最近的研究中，LLM-as-a-Judge 已成為一種評估各種任務中文字生成品質的具成本效益的替代方案，可以取代人工評估。然而，LLM-as-a-Judge 與人工評估之間仍存在可靠性差距。一個重要的原因是評估過程中缺乏引導式神諭。在經典文字評估中普遍使用參考的啟發下，我們引入了 RevisEval，一種透過回應適應參考的新文字生成評估範例。RevisEval 受到一個關鍵觀察的驅動，即理想的參考應與要評估的回應保持必要的相關性。具體來說，RevisEval 利用大型語言模型 (LLM) 的文字修改能力來適應性地修改回應，然後將修改後的文字作為後續評估的參考（回應適應參考）。廣泛的實驗證明，RevisEval 在 NLG 任務和開放式指令遵循任務中優於使用 LLM-as-a-Judge 的傳統無參考和基於參考的評估範例。更重要的是，與傳統參考相比，我們的回應適應參考可以進一步提升經典文字指標，例如 BLEU 和 BERTScore，甚至與 LLM-as-a-Judge 相媲美。還進行了詳細分析以確認 RevisEval 在減少偏差、推理成本影響和參考相關性方面的有效性。</paragraph>

##### **Understanding Warmup-Stable-Decay Learning Rates: A River Valley Loss Landscape Perspective**
2410.05192v1 by Kaiyue Wen, Zhiyuan Li, Jason Wang, David Hall, Percy Liang, Tengyu Ma

Training language models currently requires pre-determining a fixed compute
budget because the typical cosine learning rate schedule depends on the total
number of steps. In contrast, the Warmup-Stable-Decay (WSD) schedule uses a
constant learning rate to produce a main branch of iterates that can in
principle continue indefinitely without a pre-specified compute budget. Then,
given any compute budget, one can branch out from the main branch at a proper
at any time with a rapidly decaying learning rate to produce a strong model.
Empirically, WSD generates a non-traditional loss curve: the loss remains
elevated during the stable phase but sharply declines during the decay phase.
Towards explaining this phenomenon, we conjecture that pretraining loss
exhibits a river valley landscape, which resembles a deep valley with a river
at its bottom. Under this assumption, we show that during the stable phase, the
iterate undergoes large oscillations due to the high learning rate, yet it
progresses swiftly along the river. During the decay phase, the rapidly
dropping learning rate minimizes the iterate's oscillations, moving it closer
to the river and revealing true optimization progress. Therefore, the sustained
high learning rate phase and fast decaying phase are responsible for progress
in the river and the mountain directions respectively, and are both critical.
Our analysis predicts phenomenons consistent with empirical observations and
shows that this landscape can emerge from pretraining on a simple bi-gram
dataset. Inspired by the theory, we introduce WSD-S, a variant of WSD that
reuses previous checkpoints' decay phases and keeps only one main branch, where
we resume from a decayed checkpoint. WSD-S empirically outperforms WSD and
Cyclic-Cosine in obtaining multiple language model checkpoints across various
compute budgets in a single run for parameters scaling from 0.1B to 1.2B.

摘要：目前訓練語言模型需要預先決定一個固定的運算預算，因為典型的餘弦學習率時程取決於步驟的總數。相反地，熱身-穩定-衰減 (WSD) 時程使用一個固定的學習率來產生一個原則上可以無限持續而無需預先指定運算預算的迭代主分支。然後，在給定的任何運算預算下，人們可以在適當的任何時間從主分支分支出一個快速衰減學習率以產生一個強大的模型。根據經驗，WSD 會產生一個非傳統的損失曲線：損失在穩定階段保持升高，但在衰減階段急劇下降。為了解釋這種現象，我們推測預訓練損失表現出一個河谷景觀，它類似於一個底部有河流的深谷。在這個假設下，我們表明在穩定階段，由於高學習率，迭代會經歷大的振盪，但它沿著河流迅速推進。在衰減階段，快速下降的學習率最小化迭代的振盪，使其更接近河流並揭示真正的優化進度。因此，持續的高學習率階段和快速衰減階段分別負責河流和山脈方向的進度，並且兩者都很重要。我們的分析預測了與經驗觀察一致的現象，並表明這種景觀可以從一個簡單的二元語料庫的預訓練中出現。受到這個理論的啟發，我們引入了 WSD-S，它是 WSD 的一個變體，它重複使用先前檢查點的衰減階段並只保留一個主分支，我們從一個衰減的檢查點恢復。WSD-S 在單次運算中跨越各種運算預算獲得多個語言模型檢查點方面，在經驗上優於 WSD 和循環餘弦，參數範圍從 0.1B 到 1.2B。

##### **LADEV: A Language-Driven Testing and Evaluation Platform for Vision-Language-Action Models in Robotic Manipulation**
2410.05191v1 by Zhijie Wang, Zhehua Zhou, Jiayang Song, Yuheng Huang, Zhan Shu, Lei Ma

Building on the advancements of Large Language Models (LLMs) and Vision
Language Models (VLMs), recent research has introduced Vision-Language-Action
(VLA) models as an integrated solution for robotic manipulation tasks. These
models take camera images and natural language task instructions as input and
directly generate control actions for robots to perform specified tasks,
greatly improving both decision-making capabilities and interaction with human
users. However, the data-driven nature of VLA models, combined with their lack
of interpretability, makes the assurance of their effectiveness and robustness
a challenging task. This highlights the need for a reliable testing and
evaluation platform. For this purpose, in this work, we propose LADEV, a
comprehensive and efficient platform specifically designed for evaluating VLA
models. We first present a language-driven approach that automatically
generates simulation environments from natural language inputs, mitigating the
need for manual adjustments and significantly improving testing efficiency.
Then, to further assess the influence of language input on the VLA models, we
implement a paraphrase mechanism that produces diverse natural language task
instructions for testing. Finally, to expedite the evaluation process, we
introduce a batch-style method for conducting large-scale testing of VLA
models. Using LADEV, we conducted experiments on several state-of-the-art VLA
models, demonstrating its effectiveness as a tool for evaluating these models.
Our results showed that LADEV not only enhances testing efficiency but also
establishes a solid baseline for evaluating VLA models, paving the way for the
development of more intelligent and advanced robotic systems.

摘要：<paragraph>建立在大语言模型 (LLM) 和视觉语言模型 (VLM) 的进步之上，最近的研究引入了视觉语言动作 (VLA) 模型，作为机器人操作任务的集成解决方案。这些模型以相机图像和自然语言任务指令作为输入，并直接为机器人生成控制动作以执行指定任务，极大地提高了决策能力和与人类用户的交互。然而，VLA 模型的数据驱动特性及其缺乏可解释性，使得确保其有效性和鲁棒性成为一项具有挑战性的任务。这凸显了对可靠的测试和评估平台的需求。为此，在这项工作中，我们提出了 LADEV，这是一个专门为评估 VLA 模型而设计的全面且高效的平台。我们首先提出了一种语言驱动的方案，该方案可以根据自然语言输入自动生成仿真环境，从而减轻手动调整的需要并显著提高测试效率。然后，为了进一步评估语言输入对 VLA 模型的影响，我们实现了一个同义词转换机制，该机制会产生不同的自然语言任务指令进行测试。最后，为了加快评估过程，我们引入了一种批量方法来进行 VLA 模型的大规模测试。使用 LADEV，我们对几个最先进的 VLA 模型进行了实验，证明了它作为评估这些模型的工具的有效性。我们的结果表明，LADEV 不仅提高了测试效率，而且还为评估 VLA 模型建立了一个坚实的基础，为开发更智能、更先进的机器人系统铺平了道路。</paragraph>

##### **Enhancing Equity in Large Language Models for Medical Applications**
2410.05180v1 by Yuelyu Ji, Wenhe Ma, Sonish Sivarajkumar, Hang Zhang, Eugene Mathew Sadhu, Zhuochun Li, Xizhi Wu, Shyam Visweswaran, Yanshan Wang

Recent advancements have highlighted the potential of large language models
(LLMs) in medical applications, notably in automating Clinical Trial Matching
for translational research and providing medical question-answering for
clinical decision support. However, our study reveals significant inequities in
the use of LLMs, particularly for individuals from specific racial, gender, and
underrepresented groups influenced by social determinants of health. These
disparities could worsen existing health inequities if LLMs are broadly adopted
in healthcare. To address this, we propose and evaluate a novel framework,
EquityGuard, designed to detect and mitigate biases in LLM-based medical
applications. EquityGuard incorporates a Bias Detection Mechanism capable of
identifying and correcting unfair predictions, thus enhancing outcomes and
promoting equity across diverse population groups.

摘要：最近的進展突顯出大型語言模型 (LLM) 在醫療應用中的潛力，特別是在轉譯研究中自動化臨床試驗配對，以及提供醫療問題解答以作為臨床決策支援。然而，我們的研究揭示了 LLM 使用上的顯著不平等，特別是對於受社會健康決定因素影響的特定種族、性別和代表性不足的群體。如果 LLM 廣泛應用於醫療保健，這些差異可能會惡化現有的健康不平等。為了解決這個問題，我們提出並評估了一個創新的框架 EquityGuard，旨在偵測和減輕基於 LLM 的醫療應用中的偏差。EquityGuard 結合了一個偏差偵測機制，能夠識別和修正不公平的預測，從而改善結果並促進不同人口群體之間的公平性。

##### **ReasoningRank: Teaching Student Models to Rank through Reasoning-Based Knowledge Distillation**
2410.05168v1 by Yuelyu Ji, Zhuochun Li, Rui Meng, Daqing He

Reranking documents based on their relevance to a given query is critical in
information retrieval. Traditional reranking methods often focus on improving
the initial rankings but lack transparency, failing to explain why one document
is ranked higher. In this paper, we introduce ReasoningRank, a novel reranking
approach that enhances clarity by generating two types of reasoning: explicit
reasoning, which explains how a document addresses the query, and comparison
reasoning, which justifies the relevance of one document over another. We
leverage large language models (LLMs) as teacher models to generate these
explanations and distill this knowledge into smaller, more resource-efficient
student models. While the student models may not outperform LLMs in speed, they
significantly reduce the computational burden by requiring fewer resources,
making them more suitable for large-scale or resource-constrained settings.
These student models are trained to both generate meaningful reasoning and
rerank documents, achieving competitive performance across multiple datasets,
including MSMARCO and BRIGHT. Experiments demonstrate that ReasoningRank
improves reranking accuracy and provides valuable insights into the
decision-making process, offering a structured and interpretable solution for
reranking tasks.

摘要：在資訊檢索中，根據文件與特定查詢的相關性重新排序文件至關重要。傳統的重新排序方法通常專注於改善初始排名，但缺乏透明度，無法解釋為何某個文件排名較高。在本文中，我們介紹了 ReasoningRank，這是一種新穎的重新排序方法，透過產生兩種推理來增強清晰度：明確推理，解釋文件如何解決查詢，以及比較推理，證明一個文件比另一個文件更相關。我們利用大型語言模型 (LLM) 作為教師模型來產生這些解釋，並將這些知識提煉成更小、更省資源的學生模型。雖然學生模型在速度上可能無法超越 LLM，但它們透過減少資源需求來顯著降低運算負擔，使其更適合於大規模或資源受限的設定。這些學生模型經過訓練，可以產生有意義的推理並重新排序文件，在包括 MSMARCO 和 BRIGHT 在內的各種資料集上都能獲得競爭力的效能。實驗證明，ReasoningRank 改善了重新排序的準確性，並提供了對決策過程的寶貴見解，為重新排序任務提供了結構化且可解釋的解決方案。

##### **Presto! Distilling Steps and Layers for Accelerating Music Generation**
2410.05167v1 by Zachary Novack, Ge Zhu, Jonah Casebeer, Julian McAuley, Taylor Berg-Kirkpatrick, Nicholas J. Bryan

Despite advances in diffusion-based text-to-music (TTM) methods, efficient,
high-quality generation remains a challenge. We introduce Presto!, an approach
to inference acceleration for score-based diffusion transformers via reducing
both sampling steps and cost per step. To reduce steps, we develop a new
score-based distribution matching distillation (DMD) method for the EDM-family
of diffusion models, the first GAN-based distillation method for TTM. To reduce
the cost per step, we develop a simple, but powerful improvement to a recent
layer distillation method that improves learning via better preserving hidden
state variance. Finally, we combine our step and layer distillation methods
together for a dual-faceted approach. We evaluate our step and layer
distillation methods independently and show each yield best-in-class
performance. Our combined distillation method can generate high-quality outputs
with improved diversity, accelerating our base model by 10-18x (230/435ms
latency for 32 second mono/stereo 44.1kHz, 15x faster than comparable SOTA) --
the fastest high-quality TTM to our knowledge. Sound examples can be found at
https://presto-music.github.io/web/.

摘要：儘管基於擴散的文字轉音樂 (TTM) 方法有進展，但有效率、高品質的生成仍然是一個挑戰。我們介紹 Presto！，一種透過減少取樣步驟和每個步驟的成本來加速基於分數的擴散Transformer的推論加速方法。為了減少步驟，我們開發了一種新的基於分數的分配匹配蒸餾 (DMD) 方法，適用於擴散模型的 EDM 家族，這是 TTM 的第一個基於 GAN 的蒸餾方法。為了減少每個步驟的成本，我們開發了一種簡單但強大的改進方法，用於最近的層蒸餾方法，透過更好地保留隱藏狀態變異來改善學習。最後，我們將我們的步驟和層蒸餾方法結合在一起，形成一個雙管齊下的方法。我們獨立評估我們的步驟和層蒸餾方法，並展示每個方法都能產生同類最佳的效能。我們結合的蒸餾方法可以生成高品質的輸出，並提高多樣性，將我們的基礎模型加速 10-18 倍（32 秒單聲道/立體聲 44.1kHz 的延遲時間為 230/435 毫秒，比同類 SOTA 快 15 倍）——這是我們所知最快的 TTM 高品質。可以在 https://presto-music.github.io/web/ 找到聲音範例。

##### **Efficient Inference for Large Language Model-based Generative Recommendation**
2410.05165v1 by Xinyu Lin, Chaoqun Yang, Wenjie Wang, Yongqi Li, Cunxiao Du, Fuli Feng, See-Kiong Ng, Tat-Seng Chua

Large Language Model (LLM)-based generative recommendation has achieved
notable success, yet its practical deployment is costly particularly due to
excessive inference latency caused by autoregressive decoding. For lossless LLM
decoding acceleration, Speculative Decoding (SD) has emerged as a promising
solution. However, applying SD to generative recommendation presents unique
challenges due to the requirement of generating top-K items (i.e., K distinct
token sequences) as a recommendation list by beam search. This leads to more
stringent verification in SD, where all the top-K sequences from the target LLM
must be successfully drafted by the draft model at each decoding step. To
alleviate this, we consider 1) boosting top-K sequence alignment between the
draft model and the target LLM, and 2) relaxing the verification strategy to
reduce trivial LLM calls. To this end, we propose an alignment framework named
AtSpeed, which presents the AtSpeed-S optimization objective for top-K
alignment under the strict top-K verification. Moreover, we introduce a relaxed
sampling verification strategy that allows high-probability non-top-K drafted
sequences to be accepted, significantly reducing LLM calls. Correspondingly, we
propose AtSpeed-R for top-K alignment under this relaxed sampling verification.
Empirical results on two real-world datasets demonstrate that AtSpeed
significantly accelerates LLM-based generative recommendation, e.g., near 2x
speedup under strict top-K verification and up to 2.5 speedup under relaxed
sampling verification. The codes and datasets will be released in the near
future.

摘要：<paragraph>基於大型語言模型 (LLM) 的生成式推薦已取得顯著成功，但其實際部署成本高昂，特別是因為自迴歸解碼導致過度的推論延遲。對於無損失的 LLM 解碼加速，推測性解碼 (SD) 已成為一種有前途的解決方案。然而，由於需要透過波束搜尋產生頂級 K 項目（即 K 個不同的代幣序列）作為推薦清單，將 SD 應用於生成式推薦會產生獨特的挑戰。這導致在 SD 中進行更嚴格的驗證，其中目標 LLM 的所有頂級 K 序列都必須在每個解碼步驟由草稿模型成功起草。為了緩解這一點，我們考慮 1) 提升草稿模型和目標 LLM 之間的頂級 K 序列對齊，以及 2) 放寬驗證策略以減少無關緊要的 LLM 呼叫。為此，我們提出了一個名為 AtSpeed 的對齊架構，它提出了在嚴格的頂級 K 驗證下用於頂級 K 對齊的 AtSpeed-S 最佳化目標。此外，我們引入了一種放寬的抽樣驗證策略，允許接受高機率非頂級 K 起草序列，大幅減少 LLM 呼叫。相應地，我們提出 AtSpeed-R 用於在這種放寬的抽樣驗證下進行頂級 K 對齊。在兩個真實世界資料集上的實證結果表明，AtSpeed 大幅加速了基於 LLM 的生成式推薦，例如，在嚴格的頂級 K 驗證下加速近 2 倍，在放寬的抽樣驗證下加速高達 2.5 倍。這些程式碼和資料集將在不久的將來發布。</paragraph>

##### **Deciphering the Interplay of Parametric and Non-parametric Memory in Retrieval-augmented Language Models**
2410.05162v1 by Mehrdad Farahani, Richard Johansson

Generative language models often struggle with specialized or less-discussed
knowledge. A potential solution is found in Retrieval-Augmented Generation
(RAG) models which act like retrieving information before generating responses.
In this study, we explore how the \textsc{Atlas} approach, a RAG model, decides
between what it already knows (parametric) and what it retrieves
(non-parametric). We use causal mediation analysis and controlled experiments
to examine how internal representations influence information processing. Our
findings disentangle the effects of parametric knowledge and the retrieved
context. They indicate that in cases where the model can choose between both
types of information (parametric and non-parametric), it relies more on the
context than the parametric knowledge. Furthermore, the analysis investigates
the computations involved in \emph{how} the model uses the information from the
context. We find that multiple mechanisms are active within the model and can
be detected with mediation analysis: first, the decision of \emph{whether the
context is relevant}, and second, how the encoder computes output
representations to support copying when relevant.

摘要：生成式語言模型通常難以處理專業或較少討論的知識。一個潛在的解決方案可以在檢索增強生成 (RAG) 模型中找到，此類模型的作用類似於在產生回應之前檢索資訊。在此研究中，我們探討 \textsc{Atlas} 方法（一種 RAG 模型）如何決定它已知（參數化）的內容和它檢索（非參數化）的內容。我們使用因果中介分析和受控實驗來檢驗內部表徵如何影響資訊處理。我們的發現釐清了參數化知識和檢索到的背景的影響。它們表明，在模型可以在兩種資訊（參數化和非參數化）之間進行選擇的情況下，它更依賴於背景而非參數化知識。此外，分析還探討了模型如何使用來自背景的資訊所涉及的運算。我們發現模型內部有多種機制處於活動狀態，並且可以使用中介分析來檢測這些機制：首先，決定「背景是否相關」，其次，編碼器如何計算輸出表徵以在相關時支援複製。

##### **VLM2Vec: Training Vision-Language Models for Massive Multimodal Embedding Tasks**
2410.05160v1 by Ziyan Jiang, Rui Meng, Xinyi Yang, Semih Yavuz, Yingbo Zhou, Wenhu Chen

Embedding models have been crucial in enabling various downstream tasks such
as semantic similarity, information retrieval, and clustering. Recently, there
has been a surge of interest in developing universal text embedding models that
can generalize across tasks (e.g., MTEB). However, progress in learning
universal multimodal embedding models has been relatively slow despite their
importance. In this work, we aim to explore the potential for building
universal embeddings capable of handling a wide range of downstream tasks. Our
contributions are twofold: (1) MMEB (Massive Multimodal Embedding Benchmark),
which covers 4 meta-tasks (i.e. classification, visual question answering,
multimodal retrieval, and visual grounding) and 36 datasets, including 20
training and 16 evaluation datasets, and (2) VLM2Vec (Vision-Language Model ->
Vector), a contrastive training framework that converts any state-of-the-art
vision-language model into an embedding model via training on MMEB. Unlike
previous models such as CLIP and BLIP, VLM2Vec can process any combination of
images and text to generate a fixed-dimensional vector based on task
instructions. We build a series of VLM2Vec models on Phi-3.5-V and evaluate
them on MMEB's evaluation split. Our results show that \model achieves an
absolute average improvement of 10% to 20% over existing multimodal embedding
models on both in-distribution and out-of-distribution datasets in MMEB.

摘要：<paragraph>嵌入模型對於支援各種下游任務至關重要，例如語義相似性、資訊檢索和分類。最近，開發通用文字嵌入模型的興趣激增，這些模型可以跨任務進行概括（例如 MTEB）。然而，儘管通用多模態嵌入模型很重要，但學習進度相對緩慢。在這項工作中，我們旨在探討建立能夠處理廣泛下游任務的通用嵌入的可能性。我們的貢獻有兩方面：(1) MMEB (大規模多模態嵌入基準)，涵蓋 4 個元任務（即分類、視覺問題解答、多模態檢索和視覺基礎）和 36 個資料集，包括 20 個訓練資料集和 16 個評估資料集，以及 (2) VLM2Vec (視覺語言模型 -> 向量)，一種對比訓練框架，透過在 MMEB 上訓練將任何最先進的視覺語言模型轉換為嵌入模型。與 CLIP 和 BLIP 等先前的模型不同，VLM2Vec 可以處理任何圖像和文字組合，以根據任務說明產生固定維度的向量。我們在 Phi-3.5-V 上建立了一系列 VLM2Vec 模型，並在 MMEB 的評估分割上對它們進行評估。我們的結果表明，\model 在 MMEB 的分佈內和分佈外資料集上，比現有的多模態嵌入模型取得了 10% 到 20% 的絕對平均改進。</paragraph>

##### **CTC-GMM: CTC guided modality matching for fast and accurate streaming speech translation**
2410.05146v1 by Rui Zhao, Jinyu Li, Ruchao Fan, Matt Post

Models for streaming speech translation (ST) can achieve high accuracy and
low latency if they're developed with vast amounts of paired audio in the
source language and written text in the target language. Yet, these text labels
for the target language are often pseudo labels due to the prohibitive cost of
manual ST data labeling. In this paper, we introduce a methodology named
Connectionist Temporal Classification guided modality matching (CTC-GMM) that
enhances the streaming ST model by leveraging extensive machine translation
(MT) text data. This technique employs CTC to compress the speech sequence into
a compact embedding sequence that matches the corresponding text sequence,
allowing us to utilize matched {source-target} language text pairs from the MT
corpora to refine the streaming ST model further. Our evaluations with FLEURS
and CoVoST2 show that the CTC-GMM approach can increase translation accuracy
relatively by 13.9% and 6.4% respectively, while also boosting decoding speed
by 59.7% on GPU.

摘要：串流語音翻譯 (ST) 模型如果使用大量配對的原始語言音訊和目標語言書面文字來開發，可以達到高準確度和低延遲。然而，由於人工 ST 資料標記的成本過高，這些目標語言的文字標籤通常是偽標籤。在本文中，我們介紹一種名為連接主義時序分類引導模態匹配 (CTC-GMM) 的方法，透過利用大量的機器翻譯 (MT) 文字資料來增強串流 ST 模型。此技術採用 CTC 將語音序列壓縮成一個緊湊的嵌入序列，與對應的文字序列相符，讓我們能夠利用 MT 語料庫中匹配的 {原始語言-目標語言} 語言文字對進一步改善串流 ST 模型。我們使用 FLEURS 和 CoVoST2 進行評估，結果顯示 CTC-GMM 方法可以分別將翻譯準確度提高 13.9% 和 6.4%，同時在 GPU 上將解碼速度提升 59.7%。

##### **Scalable and Accurate Graph Reasoning with LLM-based Multi-Agents**
2410.05130v1 by Yuwei Hu, Runlin Lei, Xinyi Huang, Zhewei Wei, Yongchao Liu

Recent research has explored the use of Large Language Models (LLMs) for
tackling complex graph reasoning tasks. However, due to the intricacies of
graph structures and the inherent limitations of LLMs in handling long text,
current approaches often fail to deliver satisfactory accuracy, even on
small-scale graphs and simple tasks. To address these challenges, we introduce
GraphAgent-Reasoner, a fine-tuning-free framework that utilizes a multi-agent
collaboration strategy for explicit and precise graph reasoning. Inspired by
distributed graph computation theory, our framework decomposes graph problems
into smaller, node-centric tasks that are distributed among multiple agents.
The agents collaborate to solve the overall problem, significantly reducing the
amount of information and complexity handled by a single LLM, thus enhancing
the accuracy of graph reasoning. By simply increasing the number of agents,
GraphAgent-Reasoner can efficiently scale to accommodate larger graphs with
over 1,000 nodes. Evaluated on the GraphInstruct dataset, our framework
demonstrates near-perfect accuracy on polynomial-time graph reasoning tasks,
significantly outperforming the best available models, both closed-source and
fine-tuned open-source variants. Our framework also demonstrates the capability
to handle real-world graph reasoning applications such as webpage importance
analysis.

摘要：近期研究已探討使用大型語言模型 (LLM) 來處理複雜的圖形推理任務。然而，由於圖形結構的複雜性和 LLM 在處理長文本時固有的限制，現有方法通常無法提供令人滿意的準確性，即使是在小規模圖形和簡單任務上。為了應對這些挑戰，我們引入了 GraphAgent-Reasoner，這是一個無需微調的框架，它利用多主體協作策略進行明確且精確的圖形推理。我們的框架受到分散式圖形計算理論的啟發，將圖形問題分解成更小的以節點為中心的任務，並將這些任務分配給多個主體。這些主體協作解決整體問題，大幅減少單個 LLM 處理的資訊量和複雜度，從而提升圖形推理的準確性。透過單純增加主體數量，GraphAgent-Reasoner 可以有效擴充以容納節點超過 1,000 個的大型圖形。在 GraphInstruct 資料集上進行評估，我們的框架在多項式時間圖形推理任務上展現出近乎完美的準確性，大幅優於市面上最好的模型，包含閉源和微調開源版本。我們的框架也展現出處理真實世界圖形推理應用程式的能力，例如網頁重要性分析。

##### **Last Iterate Convergence in Monotone Mean Field Games**
2410.05127v1 by Noboru Isobe, Kenshi Abe, Kaito Ariu

Mean Field Game (MFG) is a framework utilized to model and approximate the
behavior of a large number of agents, and the computation of equilibria in MFG
has been a subject of interest. Despite the proposal of methods to approximate
the equilibria, algorithms where the sequence of updated policy converges to
equilibrium, specifically those exhibiting last-iterate convergence, have been
limited. We propose the use of a simple, proximal-point-type algorithm to
compute equilibria for MFGs. Subsequently, we provide the first last-iterate
convergence guarantee under the Lasry--Lions-type monotonicity condition. We
further employ the Mirror Descent algorithm for the regularized MFG to
efficiently approximate the update rules of the proximal point method for MFGs.
We demonstrate that the algorithm can approximate with an accuracy of
$\varepsilon$ after $\mathcal{O}({\log(1/\varepsilon)})$ iterations. This
research offers a tractable approach for large-scale and large-population
games.

摘要：平均場博弈 (MFG) 是一個用於建模和近似大量博弈者行為的框架，而 MFG 中均衡的計算一直是人們感興趣的主題。儘管提出了近似均衡的方法，但更新策略序列收斂到均衡的演算法，特別是那些展現最後一次迭代收斂的演算法，一直很有限。我們建議使用一種簡單的近端點類型演算法來計算 MFG 的均衡。隨後，我們在 Lasry--Lions 型單調性條件下提供了第一個最後一次迭代收斂保證。我們進一步採用鏡像下降演算法，用於正則化 MFG，以有效近似 MFG 近端點方法的更新規則。我們證明了該演算法可以在 $\mathcal{O}({\log(1/\varepsilon)})$ 次迭代後以 $\varepsilon$ 的精度進行近似。這項研究為大規模和大群體博弈提供了一種可行的途徑。

##### **Human-Feedback Efficient Reinforcement Learning for Online Diffusion Model Finetuning**
2410.05116v1 by Ayano Hiranaka, Shang-Fu Chen, Chieh-Hsin Lai, Dongjun Kim, Naoki Murata, Takashi Shibuya, Wei-Hsiang Liao, Shao-Hua Sun, Yuki Mitsufuji

Controllable generation through Stable Diffusion (SD) fine-tuning aims to
improve fidelity, safety, and alignment with human guidance. Existing
reinforcement learning from human feedback methods usually rely on predefined
heuristic reward functions or pretrained reward models built on large-scale
datasets, limiting their applicability to scenarios where collecting such data
is costly or difficult. To effectively and efficiently utilize human feedback,
we develop a framework, HERO, which leverages online human feedback collected
on the fly during model learning. Specifically, HERO features two key
mechanisms: (1) Feedback-Aligned Representation Learning, an online training
method that captures human feedback and provides informative learning signals
for fine-tuning, and (2) Feedback-Guided Image Generation, which involves
generating images from SD's refined initialization samples, enabling faster
convergence towards the evaluator's intent. We demonstrate that HERO is 4x more
efficient in online feedback for body part anomaly correction compared to the
best existing method. Additionally, experiments show that HERO can effectively
handle tasks like reasoning, counting, personalization, and reducing NSFW
content with only 0.5K online feedback.

摘要：可控生成透過 Stable Diffusion (SD) 微調，旨在提高保真度、安全性，並與人類指導一致。現有的透過人類回饋方法進行的強化學習通常依賴預先定義的啟發式獎勵函數，或建構於大型資料集上的預訓練獎勵模型，這限制了它們在收集此類資料成本高昂或困難的情況下的適用性。為了有效且有效地利用人類回饋，我們開發了一個架構 HERO，它利用在模型學習過程中即時收集的線上人類回饋。具體而言，HERO 具備兩個關鍵機制：(1) 回饋對齊表示學習，一種線上訓練方法，用於擷取人類回饋並提供用於微調的資訊性學習訊號，以及 (2) 回饋引導影像生成，這涉及從 SD 的精製初始化樣本生成影像，從而能更快地朝評估者的意圖收斂。我們證明，與現有最佳方法相比，HERO 在用於身體部位異常校正的線上回饋中效率高出 4 倍。此外，實驗表明，HERO 可以有效地處理推理、計數、個人化和減少 NSFW 內容等任務，而僅需 0.5K 的線上回饋。

##### **Synthetic Generation of Dermatoscopic Images with GAN and Closed-Form Factorization**
2410.05114v1 by Rohan Reddy Mekala, Frederik Pahde, Simon Baur, Sneha Chandrashekar, Madeline Diep, Markus Wenzel, Eric L. Wisotzky, Galip Ümit Yolcu, Sebastian Lapuschkin, Jackie Ma, Peter Eisert, Mikael Lindvall, Adam Porter, Wojciech Samek

In the realm of dermatological diagnoses, where the analysis of dermatoscopic
and microscopic skin lesion images is pivotal for the accurate and early
detection of various medical conditions, the costs associated with creating
diverse and high-quality annotated datasets have hampered the accuracy and
generalizability of machine learning models. We propose an innovative
unsupervised augmentation solution that harnesses Generative Adversarial
Network (GAN) based models and associated techniques over their latent space to
generate controlled semiautomatically-discovered semantic variations in
dermatoscopic images. We created synthetic images to incorporate the semantic
variations and augmented the training data with these images. With this
approach, we were able to increase the performance of machine learning models
and set a new benchmark amongst non-ensemble based models in skin lesion
classification on the HAM10000 dataset; and used the observed analytics and
generated models for detailed studies on model explainability, affirming the
effectiveness of our solution.

摘要：在皮膚科診斷領域，皮膚鏡檢查和顯微鏡皮膚病變影像的分析對於準確且早期偵測各種醫療狀況至關重要，但建立多樣化且高品質的標記資料集相關成本已阻礙機器學習模型的準確性和普遍性。我們提出創新的非監督式擴充解決方案，利用生成對抗網路 (GAN) 基礎模型及其在潛在空間上的相關技術，以在皮膚鏡影像中產生受控的半自動發現語義變化。我們建立合成影像以納入語義變化，並使用這些影像擴充訓練資料。透過此方法，我們得以提升機器學習模型的效能，並在 HAM10000 資料集的皮膚病變分類中設定非整體式模型的新基準；並使用觀察到的分析和建立的模型進行模型可解釋性的詳細研究，確認我們解決方案的有效性。

##### **SparsePO: Controlling Preference Alignment of LLMs via Sparse Token Masks**
2410.05102v1 by Fenia Christopoulou, Ronald Cardenas, Gerasimos Lampouras, Haitham Bou-Ammar, Jun Wang

Preference Optimization (PO) has proven an effective step for aligning
language models to human-desired behaviors. Current variants, following the
offline Direct Preference Optimization objective, have focused on a strict
setting where all tokens are contributing signals of KL divergence and rewards
to the loss function. However, human preference is not affected by each word in
a sequence equally but is often dependent on specific words or phrases, e.g.
existence of toxic terms leads to non-preferred responses. Based on this
observation, we argue that not all tokens should be weighted equally during PO
and propose a flexible objective termed SparsePO, that aims to automatically
learn to weight the KL divergence and reward corresponding to each token during
PO training. We propose two different variants of weight-masks that can either
be derived from the reference model itself or learned on the fly. Notably, our
method induces sparsity in the learned masks, allowing the model to learn how
to best weight reward and KL divergence contributions at the token level,
learning an optimal level of mask sparsity. Extensive experiments on multiple
domains, including sentiment control, dialogue, text summarization and
text-to-code generation, illustrate that our approach assigns meaningful
weights to tokens according to the target task, generates more responses with
the desired preference and improves reasoning tasks by up to 2 percentage
points compared to other token- and response-level PO methods.

摘要：偏好优化 (PO) 已被证明是将语言模型与人类期望行为对齐的有效步骤。遵循离线直接偏好优化目标的当前变体专注于一个严格的设置，其中所有标记都在为损失函数贡献 KL 散度和奖励的信号。然而，人类偏好不会受到序列中每个单词的影响，而通常依赖于特定单词或短语，例如存在有毒术语会导致非首选响应。基于此观察，我们认为在 PO 期间并非所有标记都应赋予同等权重，并提出了一个灵活的目标，称为 SparsePO，旨在自动学习在 PO 训练期间为每个标记加权 KL 散度和奖励。我们提出了两种不同的权重掩码变体，它们可以从参考模型本身派生或动态学习。值得注意的是，我们的方法在学习的掩码中引入稀疏性，允许模型学习如何最好地对标记级别的奖励和 KL 散度贡献进行加权，从而学习最佳的掩码稀疏性级别。在包括情感控制、对话、文本摘要和文本到代码生成在内的多个领域的广泛实验表明，我们的方法根据目标任务为标记分配了有意义的权重，生成了更多具有所需偏好的响应，并且与其他标记和响应级别的 PO 方法相比，推理任务提高了 2 个百分点。

##### **Investigating large language models for their competence in extracting grammatically sound sentences from transcribed noisy utterances**
2410.05099v1 by Alina Wróblewska

Selectively processing noisy utterances while effectively disregarding
speech-specific elements poses no considerable challenge for humans, as they
exhibit remarkable cognitive abilities to separate semantically significant
content from speech-specific noise (i.e. filled pauses, disfluencies, and
restarts). These abilities may be driven by mechanisms based on acquired
grammatical rules that compose abstract syntactic-semantic structures within
utterances. Segments without syntactic and semantic significance are
consistently disregarded in these structures. The structures, in tandem with
lexis, likely underpin language comprehension and thus facilitate effective
communication. In our study, grounded in linguistically motivated experiments,
we investigate whether large language models (LLMs) can effectively perform
analogical speech comprehension tasks. In particular, we examine the ability of
LLMs to extract well-structured utterances from transcriptions of noisy
dialogues. We conduct two evaluation experiments in the Polish language
scenario, using a~dataset presumably unfamiliar to LLMs to mitigate the risk of
data contamination. Our results show that not all extracted utterances are
correctly structured, indicating that either LLMs do not fully acquire
syntactic-semantic rules or they acquire them but cannot apply them
effectively. We conclude that the ability of LLMs to comprehend noisy
utterances is still relatively superficial compared to human proficiency in
processing them.

摘要：有选择地处理嘈杂的言语，同时有效地忽略特定于语音的元素，对人类来说并不是一个很大的挑战，因为他们表现出非凡的认知能力，可以将语义上重要的内容与特定于语音的噪音（即填充停顿、言语失利和重新开始）分开。这些能力可能是由基于习得的语法规则的机制驱动的，这些规则在言语中构成抽象的句法语义结构。在这些结构中，没有句法和语义意义的片段始终被忽略。这些结构与词汇一起，可能支撑着语言理解，从而促进有效的沟通。在我们的研究中，基于语言学动机的实验，我们调查了大型语言模型 (LLM) 是否可以有效地执行类比语音理解任务。特别是，我们研究了 LLM 从嘈杂对话的转录中提取结构良好的言语的能力。我们在波兰语场景中进行了两个评估实验，使用 LLM 可能不熟悉的~数据集来减轻数据污染的风险。我们的结果表明，并非所有提取的言语都结构正确，这表明 LLM 或者没有完全习得句法语义规则，或者习得了这些规则但无法有效地应用它们。我们得出结论，与人类处理嘈杂言语的能力相比，LLM 理解嘈杂言语的能力仍然相对肤浅。

##### **On the Structure of Game Provenance and its Applications**
2410.05094v1 by Shawn Bowers, Yilin Xia, Bertram Ludäscher

Provenance in databases has been thoroughly studied for positive and for
recursive queries, then for first-order (FO) queries, i.e., having negation but
no recursion. Query evaluation can be understood as a two-player game where the
opponents argue whether or not a tuple is in the query answer. This
game-theoretic approach yields a natural provenance model for FO queries,
unifying how and why-not provenance. Here, we study the fine-grain structure of
game provenance. A game $G=(V,E)$ consists of positions $V$ and moves $E$ and
can be solved by computing the well-founded model of a single, unstratifiable
rule: \[ \text{win}(X) \leftarrow \text{move}(X, Y), \neg \, \text{win}(Y). \]
In the solved game $G^{\lambda}$, the value of a position $x\,{\in}\,V$ is
either won, lost, or drawn. This value is explained by the provenance
$\mathscr{P}$(x), i.e., certain (annotated) edges reachable from $x$. We
identify seven edge types that give rise to new kinds of provenance, i.e.,
potential, actual, and primary, and demonstrate that "not all moves are created
equal". We describe the new provenance types, show how they can be computed
while solving games, and discuss applications, e.g., for abstract argumentation
frameworks.

摘要：<paragraph>資料庫中的來源已針對正向和遞迴查詢進行徹底研究，然後針對一階 (FO) 查詢（即具有否定但沒有遞迴）進行研究。查詢評估可以理解為一個雙人遊戲，對手爭論元組是否在查詢答案中。這種博弈論方法產生了 FO 查詢的自然來源模型，統一了如何和為何不來源。在此，我們研究了遊戲來源的細粒度結構。遊戲 $G=(V,E)$ 包含位置 $V$ 和移動 $E$，並且可以透過計算單一、不可分層規則的良好基礎模型來解決：\[\text{win}(X) \leftarrow \text{move}(X, Y), \neg \, \text{win}(Y). \]在已解決的遊戲 $G^{\lambda}$ 中，位置 $x\,{\in}\,V$ 的值可以是獲勝、失敗或平手。此值由來源 $\mathscr{P}$(x) 來解釋，即從 $x$ 可到達的特定（註解）邊緣。我們識別出七種類型的邊緣，這些邊緣產生了新類型的來源，即潛在、實際和主要，並證明「並非所有移動都是平等的」。我們描述了新的來源類型，展示了如何在解決遊戲時計算它們，並討論應用，例如抽象論證框架。</paragraph>

##### **Explanation sensitivity to the randomness of large language models: the case of journalistic text classification**
2410.05085v1 by Jeremie Bogaert, Marie-Catherine de Marneffe, Antonin Descampe, Louis Escouflaire, Cedrick Fairon, Francois-Xavier Standaert

Large language models (LLMs) perform very well in several natural language
processing tasks but raise explainability challenges. In this paper, we examine
the effect of random elements in the training of LLMs on the explainability of
their predictions. We do so on a task of opinionated journalistic text
classification in French. Using a fine-tuned CamemBERT model and an explanation
method based on relevance propagation, we find that training with different
random seeds produces models with similar accuracy but variable explanations.
We therefore claim that characterizing the explanations' statistical
distribution is needed for the explainability of LLMs. We then explore a
simpler model based on textual features which offers stable explanations but is
less accurate. Hence, this simpler model corresponds to a different tradeoff
between accuracy and explainability. We show that it can be improved by
inserting features derived from CamemBERT's explanations. We finally discuss
new research directions suggested by our results, in particular regarding the
origin of the sensitivity observed in the training randomness.

摘要：大型語言模型 (LLM) 在多項自然語言處理任務中表現出色，但提出了可解釋性的挑戰。在本文中，我們探討了 LLM 訓練中的隨機元素對其預測可解釋性的影響。我們對法語中觀點鮮明的新聞文本分類任務進行了研究。使用微調後的 CamemBERT 模型和基於相關性傳播的解釋方法，我們發現使用不同的隨機種子訓練會產生具有相似準確度但解釋變數的模型。因此，我們聲稱需要對解釋的統計分佈進行表徵，以解釋 LLM。然後，我們探索了一個基於文本特徵的更簡單模型，該模型提供了穩定的解釋，但準確度較低。因此，這個更簡單的模型對應於準確性和可解釋性之間的另一種權衡。我們表明，通過插入從 CamemBERT 的解釋中得出的特徵，可以對其進行改進。我們最終討論了我們的結果所提出的新的研究方向，特別是關於在訓練隨機性中觀察到的敏感性的來源。

##### **ScienceAgentBench: Toward Rigorous Assessment of Language Agents for Data-Driven Scientific Discovery**
2410.05080v1 by Ziru Chen, Shijie Chen, Yuting Ning, Qianheng Zhang, Boshi Wang, Botao Yu, Yifei Li, Zeyi Liao, Chen Wei, Zitong Lu, Vishal Dey, Mingyi Xue, Frazier N. Baker, Benjamin Burns, Daniel Adu-Ampratwum, Xuhui Huang, Xia Ning, Song Gao, Yu Su, Huan Sun

The advancements of language language models (LLMs) have piqued growing
interest in developing LLM-based language agents to automate scientific
discovery end-to-end, which has sparked both excitement and skepticism about
the true capabilities of such agents. In this work, we argue that for an agent
to fully automate scientific discovery, it must be able to complete all
essential tasks in the workflow. Thus, we call for rigorous assessment of
agents on individual tasks in a scientific workflow before making bold claims
on end-to-end automation. To this end, we present ScienceAgentBench, a new
benchmark for evaluating language agents for data-driven scientific discovery.
To ensure the scientific authenticity and real-world relevance of our
benchmark, we extract 102 tasks from 44 peer-reviewed publications in four
disciplines and engage nine subject matter experts to validate them. We unify
the target output for every task to a self-contained Python program file and
employ an array of evaluation metrics to examine the generated programs,
execution results, and costs. Each task goes through multiple rounds of manual
validation by annotators and subject matter experts to ensure its annotation
quality and scientific plausibility. We also propose two effective strategies
to mitigate data contamination concerns. Using our benchmark, we evaluate five
open-weight and proprietary LLMs, each with three frameworks: direct prompting,
OpenHands, and self-debug. Given three attempts for each task, the
best-performing agent can only solve 32.4% of the tasks independently and 34.3%
with expert-provided knowledge. These results underscore the limited capacities
of current language agents in generating code for data-driven discovery, let
alone end-to-end automation for scientific research.

摘要：<paragraph>語言模型（LLM）的進步引起人們對開發基於 LLM 的語言代理以自動化科學發現的興趣，這引起了人們對此類代理的真正能力的興奮和懷疑。在這項工作中，我們認為，要讓代理完全自動化科學發現，它必須能夠完成工作流程中的所有基本任務。因此，我們呼籲在對科學工作流程中的個別任務進行嚴格評估後，再對端到端自動化提出大膽主張。為此，我們提出了 ScienceAgentBench，這是一個新的基準，用於評估數據驅動科學發現的語言代理。為了確保我們基準的科學真實性和現實世界相關性，我們從四個學科的 44 篇同行評審出版物中提取了 102 項任務，並聘請了九位主題專家對其進行驗證。我們將每個任務的目標輸出統一為一個獨立的 Python 程序文件，並採用一系列評估指標來檢查生成的程序、執行結果和成本。每個任務都經過註釋者和主題專家多輪手動驗證，以確保其註釋質量和科學合理性。我們還提出了兩種有效的策略來減輕數據污染問題。使用我們的基準，我們評估了五個開放權重和專有 LLM，每個 LLM 有三個框架：直接提示、OpenHands 和自調試。給定每個任務三次嘗試，表現最好的代理只能獨立解決 32.4% 的任務，在專家提供的知識下可以解決 34.3% 的任務。這些結果強調了當前語言代理在為數據驅動發現生成代碼方面的能力有限，更不用說科學研究的端到端自動化了。</paragraph>

##### **Compression via Pre-trained Transformers: A Study on Byte-Level Multimodal Data**
2410.05078v1 by David Heurtel-Depeiges, Anian Ruoss, Joel Veness, Tim Genewein

Foundation models have recently been shown to be strong data compressors.
However, when accounting for their excessive parameter count, their compression
ratios are actually inferior to standard compression algorithms. Moreover,
naively reducing the number of parameters may not necessarily help as it leads
to worse predictions and thus weaker compression. In this paper, we conduct a
large-scale empirical study to investigate whether there is a sweet spot where
competitive compression ratios with pre-trained vanilla transformers are
possible. To this end, we train families of models on 165GB of raw byte
sequences of either text, image, or audio data (and all possible combinations
of the three) and then compress 1GB of out-of-distribution (OOD) data from each
modality. We find that relatively small models (i.e., millions of parameters)
can outperform standard general-purpose compression algorithms (gzip, LZMA2)
and even domain-specific compressors (PNG, JPEG 2000, FLAC) - even when
factoring in parameter count. We achieve, e.g., the lowest compression ratio of
0.49 on OOD audio data (vs. 0.54 for FLAC). To study the impact of model- and
dataset scale, we conduct extensive ablations and hyperparameter sweeps, and we
investigate the effect of unimodal versus multimodal training. We find that
even small models can be trained to perform well on multiple modalities, but,
in contrast to previously reported results with large-scale foundation models,
transfer to unseen modalities is generally weak.

摘要：最近已证明，基础模型是强大的数据压缩器。
然而，在考虑其过多的参数计数时，其压缩比实际上不如标准压缩算法。此外，简单地减少参数数量不一定有帮助，因为它会导致更差的预测，从而导致更弱的压缩。在本文中，我们进行了一项大规模的实证研究，以调查是否存在一个可以实现与预训练的香草转换器具有竞争力的压缩比的最佳点。为此，我们在 165GB 的文本、图像或音频数据的原始字节序列（以及三者的所有可能组合）上训练模型族，然后压缩来自每个模态的 1GB 的分布外 (OOD) 数据。我们发现，相对较小的模型（即数百万个参数）可以优于标准通用压缩算法（gzip、LZMA2），甚至优于特定于领域的压缩器（PNG、JPEG 2000、FLAC）——即使在考虑参数计数时也是如此。例如，我们在 OOD 音频数据上实现了 0.49 的最低压缩比（而 FLAC 为 0.54）。为了研究模型和数据集规模的影响，我们进行了广泛的消融和超参数扫描，并且我们调查了单模态与多模态训练的效果。我们发现，即使是小模型也可以训练得很好地执行多种模态，但是，与先前报道的大规模基础模型的结果相反，转移到未见过的模态通常很弱。

##### **ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering**
2410.05077v1 by Francesco Maria Molfese, Simone Conia, Riccardo Orlando, Roberto Navigli

Current Large Language Models (LLMs) have shown strong reasoning capabilities
in commonsense question answering benchmarks, but the process underlying their
success remains largely opaque. As a consequence, recent approaches have
equipped LLMs with mechanisms for knowledge retrieval, reasoning and
introspection, not only to improve their capabilities but also to enhance the
interpretability of their outputs. However, these methods require additional
training, hand-crafted templates or human-written explanations. To address
these issues, we introduce ZEBRA, a zero-shot question answering framework that
combines retrieval, case-based reasoning and introspection and dispenses with
the need for additional training of the LLM. Given an input question, ZEBRA
retrieves relevant question-knowledge pairs from a knowledge base and generates
new knowledge by reasoning over the relationships in these pairs. This
generated knowledge is then used to answer the input question, improving the
model's performance and interpretability. We evaluate our approach across 8
well-established commonsense reasoning benchmarks, demonstrating that ZEBRA
consistently outperforms strong LLMs and previous knowledge integration
approaches, achieving an average accuracy improvement of up to 4.5 points.

摘要：當前的巨量語言模型（LLM）在常識問答基準中展現出強大的推理能力，但其成功背後的過程在很大程度上仍不透明。因此，最近的方法為 LLM 配備了知識檢索、推理和內省的機制，不僅可以提升其能力，還能增強其輸出的可解釋性。然而，這些方法需要額外的訓練、手工製作的模板或人為撰寫的說明。為了解決這些問題，我們引入了 ZEBRA，這是一個零次學習問題回答框架，它結合了檢索、基於案例的推理和內省，並消除了對 LLM 進行額外訓練的需求。給定一個輸入問題，ZEBRA 會從知識庫中檢索相關的問題知識對，並通過推理這些對中的關係來產生新的知識。然後使用這個產生的知識來回答輸入問題，從而提升模型的效能和可解釋性。我們在 8 個完善的常識推理基準中評估了我們的做法，證明 ZEBRA 持續優於強大的 LLM 和先前的知識整合方法，平均準確度提升了 4.5 個百分點。

##### **TidalDecode: Fast and Accurate LLM Decoding with Position Persistent Sparse Attention**
2410.05076v1 by Lijie Yang, Zhihao Zhang, Zhuofu Chen, Zikun Li, Zhihao Jia

Large language models (LLMs) have driven significant advancements across
diverse NLP tasks, with long-context models gaining prominence for handling
extended inputs. However, the expanding key-value (KV) cache size required by
Transformer architectures intensifies the memory constraints, particularly
during the decoding phase, creating a significant bottleneck. Existing sparse
attention mechanisms designed to address this bottleneck have two limitations:
(1) they often fail to reliably identify the most relevant tokens for
attention, and (2) they overlook the spatial coherence of token selection
across consecutive Transformer layers, which can lead to performance
degradation and substantial overhead in token selection. This paper introduces
TidalDecode, a simple yet effective algorithm and system for fast and accurate
LLM decoding through position persistent sparse attention. TidalDecode
leverages the spatial coherence of tokens selected by existing sparse attention
methods and introduces a few token selection layers that perform full attention
to identify the tokens with the highest attention scores, while all other
layers perform sparse attention with the pre-selected tokens. This design
enables TidalDecode to substantially reduce the overhead of token selection for
sparse attention without sacrificing the quality of the generated results.
Evaluation on a diverse set of LLMs and tasks shows that TidalDecode closely
matches the generative performance of full attention methods while reducing the
LLM decoding latency by up to 2.1x.

摘要：大型語言模型 (LLM) 已推動各種 NLP 任務的顯著進展，其中長語境模型在處理擴充輸入方面越來越重要。然而，Transformer 架構所需的擴充鍵值 (KV) 快取大小加劇了記憶體限制，特別是在解碼階段，造成顯著的瓶頸。現有的稀疏注意力機制旨在解決此瓶頸，但有兩個限制：(1) 它們通常無法可靠地識別最相關的注意力權重，以及 (2) 它們忽略了跨連續 Transformer 層的權重選擇空間一致性，這可能導致權重選擇效能下降和大量開銷。本文介紹 TidalDecode，一種透過位置持續稀疏注意力進行快速且準確的 LLM 解碼的簡單但有效的演算法和系統。TidalDecode 利用現有稀疏注意力方法所選權重的空間一致性，並引入幾個執行完整注意力的權重選擇層，以識別具有最高注意力分數的權重，而所有其他層則對預先選取的權重執行稀疏注意力。此設計使 TidalDecode 能夠大幅減少稀疏注意力的權重選擇開銷，而不會犧牲生成結果的品質。在各種 LLM 和任務上的評估顯示，TidalDecode 與完整注意力方法的生成效能非常接近，同時將 LLM 解碼延遲減少多達 2.1 倍。

##### **Transition of $α$-mixing in Random Iterations with Applications in Queuing Theory**
2410.05056v1 by Attila Lovas

Nonlinear time series models incorporating exogenous regressors provide the
foundation for numerous significant models across econometrics, queuing theory,
machine learning, and various other disciplines. Despite their importance, the
framework for the statistical analysis of such models is still incomplete. In
contrast, multiple versions of the law of large numbers and the (functional)
central limit theorem have been established for weakly dependent variables. We
prove the transition of mixing properties of the exogenous regressor to the
response through a coupling argument, leveraging these established results.
Furthermore, we study Markov chains in random environments under a suitable
form of drift and minorization condition when the environment process is
non-stationary, merely having favorable mixing properties. Following a novel
statistical estimation theory approach and using the Cram\'er-Rao lower bound,
we also establish the functional central limit theorem. Additionally, we apply
our framework to single-server queuing models. Overall, these results open the
door to the statistical analysis of a large class of random iterative models.

摘要：非線性時間序列模型結合外生迴歸量，為計量經濟學、排隊論、機器學習和許多其他領域中的許多重要模型提供了基礎。儘管它們很重要，但對此類模型進行統計分析的框架仍不完整。相比之下，對於弱依賴變數，已經建立了多個版本的大數法則和（函數）中心極限定理。我們通過一個耦合論證證明了外生迴歸量的混合屬性向響應的轉換，利用了這些已建立的結果。此外，當環境過程是非平穩的，僅具有良好的混合屬性時，我們在隨機環境中研究具有適當形式的漂移和最小化條件的馬可夫鏈。遵循一種新穎的統計估計理論方法並使用 Cram\'er-Rao 下界，我們還建立了函數中心極限定理。此外，我們將我們的框架應用於單伺服器排隊模型。總的來說，這些結果為大量隨機反覆模型的統計分析打開了大門。

##### **Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes**
2410.05052v1 by Kosuke Nishida, Kyosuke Nishida, Kuniko Saito

Loss spikes, a phenomenon in which the loss value diverges suddenly, is a
fundamental issue in the pre-training of large language models. This paper
supposes that the non-uniformity of the norm of the parameters is one of the
causes of loss spikes. Here, in training of neural networks, the scale of the
gradients is required to be kept constant throughout the layers to avoid the
vanishing and exploding gradients problem. However, to meet these requirements
in the Transformer model, the norm of the model parameters must be non-uniform,
and thus, parameters whose norm is smaller are more sensitive to the parameter
update. To address this issue, we propose a novel technique, weight scaling as
reparameterization (WeSaR). WeSaR introduces a gate parameter per parameter
matrix and adjusts it to the value satisfying the requirements. Because of the
gate parameter, WeSaR sets the norm of the original parameters uniformly, which
results in stable training. Experimental results with the Transformer decoders
consisting of 130 million, 1.3 billion, and 13 billion parameters showed that
WeSaR stabilizes and accelerates training and that it outperformed compared
methods including popular initialization methods.

摘要：損失飆升是一種損失值突然發散的現象，是大語言模型預訓練中的基本問題。本文假設參數範數的不均勻性是損失飆升的原因之一。在這裡，在神經網路的訓練中，梯度的規模需要在各層中保持恆定，以避免梯度消失和爆炸問題。然而，為了滿足 Transformer 模型中的這些要求，模型參數的範數必須是不均勻的，因此，範數較小的參數對參數更新更敏感。為了解決這個問題，我們提出了一種新技術，將權重縮放作為重新參數化（WeSaR）。WeSaR 為每個參數矩陣引入一個閘門參數，並將其調整為滿足要求的值。由於閘門參數，WeSaR 將原始參數的範數設定為均勻，從而導致穩定的訓練。包含 1.3 億、13 億和 130 億個參數的 Transformer 解碼器的實驗結果表明，WeSaR 穩定並加速了訓練，並且它優於包括流行初始化方法在內的比較方法。

##### **FreSh: Frequency Shifting for Accelerated Neural Representation Learning**
2410.05050v1 by Adam Kania, Marko Mihajlovic, Sergey Prokudin, Jacek Tabor, Przemysław Spurek

Implicit Neural Representations (INRs) have recently gained attention as a
powerful approach for continuously representing signals such as images, videos,
and 3D shapes using multilayer perceptrons (MLPs). However, MLPs are known to
exhibit a low-frequency bias, limiting their ability to capture high-frequency
details accurately. This limitation is typically addressed by incorporating
high-frequency input embeddings or specialized activation layers. In this work,
we demonstrate that these embeddings and activations are often configured with
hyperparameters that perform well on average but are suboptimal for specific
input signals under consideration, necessitating a costly grid search to
identify optimal settings. Our key observation is that the initial frequency
spectrum of an untrained model's output correlates strongly with the model's
eventual performance on a given target signal. Leveraging this insight, we
propose frequency shifting (or FreSh), a method that selects embedding
hyperparameters to align the frequency spectrum of the model's initial output
with that of the target signal. We show that this simple initialization
technique improves performance across various neural representation methods and
tasks, achieving results comparable to extensive hyperparameter sweeps but with
only marginal computational overhead compared to training a single model with
default hyperparameters.

摘要：隱式神經表示 (INR) 近來作為一種強大的方法而備受關注，可用於使用多層感知器 (MLP) 連續表示影像、影片和 3D 形狀等訊號。然而，已知 MLP 會表現出低頻偏差，限制了其準確擷取高頻細節的能力。此限制通常透過納入高頻輸入嵌入或專門的激活層來解決。在這項研究中，我們證明這些嵌入和激活通常會使用平均表現良好的超參數進行設定，但對於考慮中的特定輸入訊號而言並非最佳，需要耗費成本的網格搜尋來找出最佳設定。我們的關鍵觀察是，未訓練模型輸出的初始頻率譜與模型在特定目標訊號上的最終效能密切相關。利用此見解，我們提出頻率位移 (或 FreSh)，一種方法用於選擇嵌入超參數，以將模型初始輸出的頻率譜與目標訊號的頻率譜對齊。我們顯示此簡單的初始化技術可改善各種神經表示方法和任務的效能，達成與廣泛超參數掃描相當的結果，但與使用預設超參數訓練單一模型相比，僅有邊際的運算負擔。

##### **A test suite of prompt injection attacks for LLM-based machine translation**
2410.05047v1 by Antonio Valerio Miceli-Barone, Zhifan Sun

LLM-based NLP systems typically work by embedding their input data into
prompt templates which contain instructions and/or in-context examples,
creating queries which are submitted to a LLM, and then parsing the LLM
response in order to generate the system outputs. Prompt Injection Attacks
(PIAs) are a type of subversion of these systems where a malicious user crafts
special inputs which interfere with the prompt templates, causing the LLM to
respond in ways unintended by the system designer.
  Recently, Sun and Miceli-Barone proposed a class of PIAs against LLM-based
machine translation. Specifically, the task is to translate questions from the
TruthfulQA test suite, where an adversarial prompt is prepended to the
questions, instructing the system to ignore the translation instruction and
answer the questions instead.
  In this test suite, we extend this approach to all the language pairs of the
WMT 2024 General Machine Translation task. Moreover, we include additional
attack formats in addition to the one originally studied.

摘要：LLM 為基礎的 NLP 系統通常透過將輸入資料嵌入包含指示和/或情境範例的提示範本中，建立提交至 LLM 的查詢，然後剖析 LLM 回應以產生系統輸出。提示注入攻擊 (PIA) 是一種破壞這些系統的類型，其中惡意使用者會製作會干擾提示範本的特殊輸入，導致 LLM 以系統設計者未預期的方式回應。
最近，Sun 和 Miceli-Barone 提出了一類針對 LLM 為基礎的機器翻譯的 PIA。具體來說，任務是翻譯 TruthfulQA 測試套件中的問題，其中會在問題前加上對抗性提示，指示系統忽略翻譯指示，而改為回答問題。
在此測試套件中，我們將此方法延伸至 WMT 2024 一般機器翻譯任務的所有語言對。此外，除了最初研究的攻擊格式外，我們還包括其他攻擊格式。

##### **Named Clinical Entity Recognition Benchmark**
2410.05046v1 by Wadood M Abdul, Marco AF Pimentel, Muhammad Umar Salman, Tathagata Raha, Clément Christophe, Praveen K Kanithi, Nasir Hayat, Ronnie Rajan, Shadab Khan

This technical report introduces a Named Clinical Entity Recognition
Benchmark for evaluating language models in healthcare, addressing the crucial
natural language processing (NLP) task of extracting structured information
from clinical narratives to support applications like automated coding,
clinical trial cohort identification, and clinical decision support.
  The leaderboard provides a standardized platform for assessing diverse
language models, including encoder and decoder architectures, on their ability
to identify and classify clinical entities across multiple medical domains. A
curated collection of openly available clinical datasets is utilized,
encompassing entities such as diseases, symptoms, medications, procedures, and
laboratory measurements. Importantly, these entities are standardized according
to the Observational Medical Outcomes Partnership (OMOP) Common Data Model,
ensuring consistency and interoperability across different healthcare systems
and datasets, and a comprehensive evaluation of model performance. Performance
of models is primarily assessed using the F1-score, and it is complemented by
various assessment modes to provide comprehensive insights into model
performance. The report also includes a brief analysis of models evaluated to
date, highlighting observed trends and limitations.
  By establishing this benchmarking framework, the leaderboard aims to promote
transparency, facilitate comparative analyses, and drive innovation in clinical
entity recognition tasks, addressing the need for robust evaluation methods in
healthcare NLP.

摘要：這份技術報告介紹了一個命名臨床實體辨識基準，用於評估醫療保健中的語言模型，解決從臨床敘述中萃取結構化資訊的關鍵自然語言處理 (NLP) 任務，以支援自動編碼、臨床試驗群組識別和臨床決策支援等應用程式。
排行榜提供一個標準化平台，用於評估各種語言模型，包括編碼器和解碼器架構，以及它們跨多個醫療領域識別和分類臨床實體的能力。利用精心整理的公開臨床資料集，涵蓋疾病、症狀、藥物、程序和實驗室測量等實體。重要的是，這些實體根據觀察性醫療結果合作夥伴關係 (OMOP) 常見資料模型標準化，確保不同醫療保健系統和資料集之間的一致性和互通性，以及模型效能的全面評估。模型效能主要使用 F1 分數評估，並輔以各種評估模式，提供對模型效能的全面見解。報告還包括對迄今評估模型的簡要分析，重點說明觀察到的趨勢和限制。
透過建立此基準架構，排行榜旨在促進透明度、促進比較分析，並推動臨床實體辨識任務的創新，滿足醫療保健 NLP 中對健全評估方法的需求。

##### **Can LLMs plan paths with extra hints from solvers?**
2410.05045v1 by Erik Wu, Sayan Mitra

Large Language Models (LLMs) have shown remarkable capabilities in natural
language processing, mathematical problem solving, and tasks related to program
synthesis. However, their effectiveness in long-term planning and higher-order
reasoning has been noted to be limited and fragile. This paper explores an
approach for enhancing LLM performance in solving a classical robotic planning
task by integrating solver-generated feedback. We explore four different
strategies for providing feedback, including visual feedback, we utilize
fine-tuning, and we evaluate the performance of three different LLMs across a
10 standard and 100 more randomly generated planning problems. Our results
suggest that the solver-generated feedback improves the LLM's ability to solve
the moderately difficult problems, but the harder problems still remain out of
reach. The study provides detailed analysis of the effects of the different
hinting strategies and the different planning tendencies of the evaluated LLMs.

摘要：大型語言模型 (LLM) 已在自然語言處理、數學問題解決和與程式合成相關的任務中展現出顯著的能力。然而，它們在長期規劃和高階推理中的有效性被認為是有限且脆弱的。本文探討了一種透過整合求解器產生的回饋來增強 LLM 在解決經典機器人規劃任務中效能的方法。我們探討了四種不同的回饋提供策略，包括視覺回饋，我們利用微調，並評估了三個不同 LLM 在 10 個標準和 100 個隨機產生的規劃問題中的效能。我們的結果表明，求解器產生的回饋改善了 LLM 解決中等難度問題的能力，但較難的問題仍然無法解決。這項研究提供了對不同提示策略的影響和評估的 LLM 的不同規劃傾向的詳細分析。

##### **PhotoReg: Photometrically Registering 3D Gaussian Splatting Models**
2410.05044v1 by Ziwen Yuan, Tianyi Zhang, Matthew Johnson-Roberson, Weiming Zhi

Building accurate representations of the environment is critical for
intelligent robots to make decisions during deployment. Advances in
photorealistic environment models have enabled robots to develop
hyper-realistic reconstructions, which can be used to generate images that are
intuitive for human inspection. In particular, the recently introduced
\ac{3DGS}, which describes the scene with up to millions of primitive
ellipsoids, can be rendered in real time. \ac{3DGS} has rapidly gained
prominence. However, a critical unsolved problem persists: how can we fuse
multiple \ac{3DGS} into a single coherent model? Solving this problem will
enable robot teams to jointly build \ac{3DGS} models of their surroundings. A
key insight of this work is to leverage the {duality} between photorealistic
reconstructions, which render realistic 2D images from 3D structure, and
\emph{3D foundation models}, which predict 3D structure from image pairs. To
this end, we develop PhotoReg, a framework to register multiple photorealistic
\ac{3DGS} models with 3D foundation models. As \ac{3DGS} models are generally
built from monocular camera images, they have \emph{arbitrary scale}. To
resolve this, PhotoReg actively enforces scale consistency among the different
\ac{3DGS} models by considering depth estimates within these models. Then, the
alignment is iteratively refined with fine-grained photometric losses to
produce high-quality fused \ac{3DGS} models. We rigorously evaluate PhotoReg on
both standard benchmark datasets and our custom-collected datasets, including
with two quadruped robots. The code is released at
\url{ziweny11.github.io/photoreg}.

摘要：<paragraph>建立環境的精確表示對於智慧型機器人在部署期間做出決策至關重要。寫實環境模型的進步使機器人能夠開發超寫實重建，可據此產生直覺上讓人類檢視的影像。特別是最近推出的 3DGS，其以多達數百萬個原始橢球體描述場景，可即時呈現。3DGS 已迅速獲得重視。然而，仍存在一個關鍵的未解決問題：我們如何將多個 3DGS 融合成一個單一的相容模型？解決此問題將使機器人團隊能夠共同建立其周圍環境的 3DGS 模型。此項工作的關鍵見解是利用寫實重建（從 3D 結構呈現寫實的 2D 影像）與 3D 基礎模型（從影像對預測 3D 結構）之間的對偶性。為此，我們開發了 PhotoReg，一個用於將多個寫實 3DGS 模型與 3D 基礎模型註冊的架構。由於 3DGS 模型通常建構自單眼相機影像，因此它們具有任意比例。為了解決這個問題，PhotoReg 透過考量這些模型內的深度估計，積極強制執行不同 3DGS 模型之間的比例一致性。然後，透過細緻的光度損失反覆調整比對，以產生高品質的融合 3DGS 模型。我們在標準基準資料集和我們自訂收集的資料集（包括兩個四足機器人）上嚴格評估 PhotoReg。程式碼已在 ziweny11.github.io/photoreg 發布。</paragraph>

##### **DEPT: Decoupled Embeddings for Pre-training Language Models**
2410.05021v1 by Alex Iacob, Lorenzo Sani, Meghdad Kurmanji, William F. Shen, Xinchi Qiu, Dongqi Cai, Yan Gao, Nicholas D. Lane

Language Model pre-training benefits from a broader data mixture to enhance
performance across domains and languages. However, training on such
heterogeneous text corpora is complex, requiring extensive and cost-intensive
efforts. Since these data sources vary in lexical, syntactic, and semantic
aspects, they cause negative interference or the "curse of multilinguality". We
propose a novel pre-training framework to alleviate this curse. Our method,
DEPT, decouples the embedding layers from the transformer body while
simultaneously training the latter in multiple contexts. DEPT enables the model
to train without being bound to a shared global vocabulary. DEPT: (1) can train
robustly and effectively under significant data heterogeneity, (2) reduces the
parameter count of the token embeddings by up to 80% and the communication
costs by 675x for billion-scale models (3) enhances model generalization and
plasticity in adapting to new languages and domains, and (4) allows training
with custom optimized vocabulary per data source. We prove DEPT's potential by
performing the first vocabulary-agnostic federated multilingual pre-training of
a 1.3 billion-parameter model across high and low-resource languages, reducing
its parameter count by 409 million.

摘要：語言模型預訓練得益於更廣泛的資料組合，以提升跨領域和跨語言的效能。然而，在如此異質的文字語料庫上進行訓練很複雜，需要廣泛且成本密集的努力。由於這些資料來源在詞彙、句法和語義方面有所不同，因此會造成負面干擾或「多語言的詛咒」。我們提出一個新穎的預訓練架構來減輕這個詛咒。我們的 DEPT 方法將嵌入層與 Transformer 主體分開，同時在多重脈絡中訓練後者。DEPT 使模型能夠在不受限於共享全局詞彙表的情況下進行訓練。DEPT：(1) 能在顯著的資料異質性下穩健且有效地訓練，(2) 將權杖嵌入的參數數量減少多達 80%，並將十億規模模型的通訊成本降低 675 倍，(3) 增強模型的泛化能力和適應新語言和領域的可塑性，以及 (4) 允許使用針對每個資料來源最佳化過的自訂詞彙表進行訓練。我們透過執行第一個與詞彙無關的 13 億參數模型聯邦多語言預訓練，跨越高資源和低資源語言，證明了 DEPT 的潛力，將其參數數量減少了 4.09 億。

##### **On the Biased Assessment of Expert Finding Systems**
2410.05018v1 by Jens-Joris Decorte, Jeroen Van Hautte, Chris Develder, Thomas Demeester

In large organisations, identifying experts on a given topic is crucial in
leveraging the internal knowledge spread across teams and departments.
So-called enterprise expert retrieval systems automatically discover and
structure employees' expertise based on the vast amount of heterogeneous data
available about them and the work they perform. Evaluating these systems
requires comprehensive ground truth expert annotations, which are hard to
obtain. Therefore, the annotation process typically relies on automated
recommendations of knowledge areas to validate. This case study provides an
analysis of how these recommendations can impact the evaluation of expert
finding systems. We demonstrate on a popular benchmark that system-validated
annotations lead to overestimated performance of traditional term-based
retrieval models and even invalidate comparisons with more recent neural
methods. We also augment knowledge areas with synonyms to uncover a strong bias
towards literal mentions of their constituent words. Finally, we propose
constraints to the annotation process to prevent these biased evaluations, and
show that this still allows annotation suggestions of high utility. These
findings should inform benchmark creation or selection for expert finding, to
guarantee meaningful comparison of methods.

摘要：在大組織中，找出特定主題的專家對於利用團隊和部門間傳播的內部知識至關重要。
所謂的企業專家檢索系統會自動根據大量可用的異質資料和他們執行的任務，找出並建構員工的專業知識。
評估這些系統需要全面的真實專家註解，而這很難取得。
因此，註解流程通常依賴於知識領域的自動化建議來驗證。
本個案研究分析了這些建議如何影響專家尋找系統的評估。
我們在一個熱門基準上示範，系統驗證的註解會導致傳統基於術語的檢索模型的效能被高估，甚至會使與較新的神經方法的比較失效。
我們也用同義詞擴充知識領域，以找出對其組成詞彙的字面提及的強烈偏見。
最後，我們建議對註解流程進行約束，以防止這些有偏見的評估，並顯示這仍然允許高實用性的註解建議。
這些發現應告知基準建立或選擇以進行專家尋找，以確保方法的意義比較。

##### **SkillMatch: Evaluating Self-supervised Learning of Skill Relatedness**
2410.05006v1 by Jens-Joris Decorte, Jeroen Van Hautte, Thomas Demeester, Chris Develder

Accurately modeling the relationships between skills is a crucial part of
human resources processes such as recruitment and employee development. Yet, no
benchmarks exist to evaluate such methods directly. We construct and release
SkillMatch, a benchmark for the task of skill relatedness, based on expert
knowledge mining from millions of job ads. Additionally, we propose a scalable
self-supervised learning technique to adapt a Sentence-BERT model based on
skill co-occurrence in job ads. This new method greatly surpasses traditional
models for skill relatedness as measured on SkillMatch. By releasing SkillMatch
publicly, we aim to contribute a foundation for research towards increased
accuracy and transparency of skill-based recommendation systems.

摘要：準確建模技能之間的關係是人力資源流程（例如招聘和員工發展）中至關重要的一部分。然而，目前尚無基準可直接評估此類方法。我們根據數百萬個職位廣告中的專家知識挖掘，構建並發布了 SkillMatch，這是一個用於評估技能相關性任務的基準。此外，我們提出了一種可擴充的自監督學習技術，以根據職位廣告中的技能共現情況調整 Sentence-BERT 模型。這種新方法在 SkillMatch 上測量時，遠遠超過了傳統的技能相關性模型。通過公開發布 SkillMatch，我們旨在為提高基於技能的推薦系統的準確性和透明度提供研究基礎。

##### **Stage-Wise and Prior-Aware Neural Speech Phase Prediction**
2410.04990v1 by Fei Liu, Yang Ai, Hui-Peng Du, Ye-Xin Lu, Rui-Chen Zheng, Zhen-Hua Ling

This paper proposes a novel Stage-wise and Prior-aware Neural Speech Phase
Prediction (SP-NSPP) model, which predicts the phase spectrum from input
amplitude spectrum by two-stage neural networks. In the initial
prior-construction stage, we preliminarily predict a rough prior phase spectrum
from the amplitude spectrum. The subsequent refinement stage transforms the
amplitude spectrum into a refined high-quality phase spectrum conditioned on
the prior phase. Networks in both stages use ConvNeXt v2 blocks as the backbone
and adopt adversarial training by innovatively introducing a phase spectrum
discriminator (PSD). To further improve the continuity of the refined phase, we
also incorporate a time-frequency integrated difference (TFID) loss in the
refinement stage. Experimental results confirm that, compared to neural
network-based no-prior phase prediction methods, the proposed SP-NSPP achieves
higher phase prediction accuracy, thanks to introducing the coarse phase priors
and diverse training criteria. Compared to iterative phase estimation
algorithms, our proposed SP-NSPP does not require multiple rounds of staged
iterations, resulting in higher generation efficiency.

摘要：本文提出了一個新穎的分階段且先驗感知神經語音相位預測 (SP-NSPP) 模型，該模型通過兩階段神經網路從輸入振幅譜預測相位譜。在初始先驗構建階段，我們從振幅譜預測一個粗略的先驗相位譜。後續的細化階段將振幅譜轉換為一個細化的、高品質的相位譜，以先驗相位為條件。兩個階段的網路都使用 ConvNeXt v2 區塊作為主幹，並通過創新地引入相位譜判別器 (PSD) 採用對抗訓練。為了進一步提高細化相位的連續性，我們還在細化階段中加入了時頻整合差分 (TFID) 損失。實驗結果證實，與基於神經網路的無先驗相位預測方法相比，所提出的 SP-NSPP 得益於引入了粗略相位先驗和多樣化的訓練標準，實現了更高的相位預測準確度。與迭代相位估計演算法相比，我們提出的 SP-NSPP 不需要多輪分階段迭代，從而產生更高的生成效率。

##### **On the Rigour of Scientific Writing: Criteria, Analysis, and Insights**
2410.04981v1 by Joseph James, Chenghao Xiao, Yucheng Li, Chenghua Lin

Rigour is crucial for scientific research as it ensures the reproducibility
and validity of results and findings. Despite its importance, little work
exists on modelling rigour computationally, and there is a lack of analysis on
whether these criteria can effectively signal or measure the rigour of
scientific papers in practice. In this paper, we introduce a bottom-up,
data-driven framework to automatically identify and define rigour criteria and
assess their relevance in scientific writing. Our framework includes rigour
keyword extraction, detailed rigour definition generation, and salient criteria
identification. Furthermore, our framework is domain-agnostic and can be
tailored to the evaluation of scientific rigour for different areas,
accommodating the distinct salient criteria across fields. We conducted
comprehensive experiments based on datasets collected from two high impact
venues for Machine Learning and NLP (i.e., ICLR and ACL) to demonstrate the
effectiveness of our framework in modelling rigour. In addition, we analyse
linguistic patterns of rigour, revealing that framing certainty is crucial for
enhancing the perception of scientific rigour, while suggestion certainty and
probability uncertainty diminish it.

摘要：嚴謹性對於科學研究至關重要，因為它確保了結果和發現的可重複性和有效性。儘管其重要性，很少有工作對嚴謹性進行計算建模，並且缺乏對這些標準是否能有效信號或衡量科學論文的嚴謹性的分析。在本文中，我們介紹了一個自下而上的、數據驅動的框架，以自動識別和定義嚴謹性標準，並評估它們在科學寫作中的相關性。我們的框架包括嚴謹關鍵字提取、詳細的嚴謹性定義生成和顯著標準識別。此外，我們的框架與領域無關，可以針對不同領域的科學嚴謹性評估進行調整，以適應不同領域的顯著標準。我們根據從機器學習和自然語言處理的兩個高影響力場館（即 ICLR 和 ACL）收集的數據集進行了綜合實驗，以證明我們的框架在嚴謹性建模中的有效性。此外，我們分析了嚴謹性的語言模式，揭示了構建確定性對於增強科學嚴謹性的感知至關重要，而建議確定性和概率不確定性則會降低它。

##### **6DGS: Enhanced Direction-Aware Gaussian Splatting for Volumetric Rendering**
2410.04974v1 by Zhongpai Gao, Benjamin Planche, Meng Zheng, Anwesa Choudhuri, Terrence Chen, Ziyan Wu

Novel view synthesis has advanced significantly with the development of
neural radiance fields (NeRF) and 3D Gaussian splatting (3DGS). However,
achieving high quality without compromising real-time rendering remains
challenging, particularly for physically-based ray tracing with view-dependent
effects. Recently, N-dimensional Gaussians (N-DG) introduced a 6D
spatial-angular representation to better incorporate view-dependent effects,
but the Gaussian representation and control scheme are sub-optimal. In this
paper, we revisit 6D Gaussians and introduce 6D Gaussian Splatting (6DGS),
which enhances color and opacity representations and leverages the additional
directional information in the 6D space for optimized Gaussian control. Our
approach is fully compatible with the 3DGS framework and significantly improves
real-time radiance field rendering by better modeling view-dependent effects
and fine details. Experiments demonstrate that 6DGS significantly outperforms
3DGS and N-DG, achieving up to a 15.73 dB improvement in PSNR with a reduction
of 66.5% Gaussian points compared to 3DGS.

摘要：神經輻照場 (NeRF) 和 3D 高斯潑濺 (3DGS) 的發展，讓新穎的視圖合成技術取得顯著進展。然而，在不影響即時渲染的情況下達成高品質，仍然是一項挑戰，特別是對於具有視點相關效果的基於物理的光線追蹤。最近，N 維高斯 (N-DG) 引入 6D 空間-角度表示，以更好地納入視點相關效果，但高斯表示和控制方案並非最佳。在本文中，我們重新探討 6D 高斯，並介紹 6D 高斯潑濺 (6DGS)，它增強了色彩和不透明度的表示，並利用 6D 空間中的額外方向資訊來最佳化高斯控制。我們的做法與 3DGS 架構完全相容，並透過更好地建模視點相關效果和精細細節，顯著改善即時輻照場渲染。實驗證明，與 3DGS 相比，6DGS 的表現明顯優於 3DGS 和 N-DG，在 PSNR 方面提升達 15.73 dB，而高斯點減少了 66.5%。

##### **Collaboration! Towards Robust Neural Methods for Routing Problems**
2410.04968v1 by Jianan Zhou, Yaoxin Wu, Zhiguang Cao, Wen Song, Jie Zhang, Zhiqi Shen

Despite enjoying desirable efficiency and reduced reliance on domain
expertise, existing neural methods for vehicle routing problems (VRPs) suffer
from severe robustness issues -- their performance significantly deteriorates
on clean instances with crafted perturbations. To enhance robustness, we
propose an ensemble-based Collaborative Neural Framework (CNF) w.r.t. the
defense of neural VRP methods, which is crucial yet underexplored in the
literature. Given a neural VRP method, we adversarially train multiple models
in a collaborative manner to synergistically promote robustness against
attacks, while boosting standard generalization on clean instances. A neural
router is designed to adeptly distribute training instances among models,
enhancing overall load balancing and collaborative efficacy. Extensive
experiments verify the effectiveness and versatility of CNF in defending
against various attacks across different neural VRP methods. Notably, our
approach also achieves impressive out-of-distribution generalization on
benchmark instances.

摘要：儘管現有的神經方法對於車輛路徑問題 (VRP) 具有令人滿意的效率，且減少了對領域專業知識的依賴，但它們仍有嚴重的穩健性問題，其效能會在經過精心擾動的乾淨個體上大幅下降。為了增強穩健性，我們提出了一個基於整體的協作神經架構 (CNF)，以防禦神經 VRP 方法，這在文獻中至關重要，但尚未被充分探討。給定一個神經 VRP 方法，我們以對抗的方式訓練多個模型，以協作的方式促進對抗攻擊的穩健性，同時提升在乾淨個體上的標準泛化。神經路由器被設計成能夠靈巧地在模型之間分配訓練個體，增強整體負載平衡和協作效能。廣泛的實驗驗證了 CNF 在防禦不同神經 VRP 方法的各種攻擊方面的有效性和多功能性。值得注意的是，我們的做法在基準個體上也達到了令人印象深刻的非分佈泛化。

##### **Activation Scaling for Steering and Interpreting Language Models**
2410.04962v1 by Niklas Stoehr, Kevin Du, Vésteinn Snæbjarnarson, Robert West, Ryan Cotterell, Aaron Schein

Given the prompt "Rome is in", can we steer a language model to flip its
prediction of an incorrect token "France" to a correct token "Italy" by only
multiplying a few relevant activation vectors with scalars? We argue that
successfully intervening on a model is a prerequisite for interpreting its
internal workings. Concretely, we establish a three-term objective: a
successful intervention should flip the correct with the wrong token and vice
versa (effectiveness), and leave other tokens unaffected (faithfulness), all
while being sparse (minimality). Using gradient-based optimization, this
objective lets us learn (and later evaluate) a specific kind of efficient and
interpretable intervention: activation scaling only modifies the signed
magnitude of activation vectors to strengthen, weaken, or reverse the steering
directions already encoded in the model. On synthetic tasks, this intervention
performs comparably with steering vectors in terms of effectiveness and
faithfulness, but is much more minimal allowing us to pinpoint interpretable
model components. We evaluate activation scaling from different angles, compare
performance on different datasets, and make activation scalars a learnable
function of the activation vectors themselves to generalize to varying-length
prompts.

摘要：给定提示“罗马在”，我们是否可以通过仅用标量乘以几个相关的激活向量，引导语言模型将其对错误标记“法国”的预测翻转为正确标记“意大利”？我们认为，成功干预模型是解释其内部运作的前提。具体来说，我们建立了一个三项目标：一个成功的干预应该将正确的标记与错误的标记翻转，反之亦然（有效性），并且不影响其他标记（忠实度），同时是稀疏的（最小性）。使用基于梯度的优化，此目标使我们能够学习（并在稍后评估）一种特定类型的有效且可解释的干预：激活缩放仅修改激活向量的有符号幅度，以增强、削弱或反转模型中已编码的转向方向。在合成任务中，这种干预在有效性和忠实度方面与转向向量表现相当，但最小得多，使我们能够精确定位可解释的模型组件。我们从不同的角度评估激活缩放，比较不同数据集上的性能，并将激活标量作为激活向量本身的可学习函数，以推广到变长提示。

##### **Leverage Knowledge Graph and Large Language Model for Law Article Recommendation: A Case Study of Chinese Criminal Law**
2410.04949v1 by Yongming Chen, Miner Chen, Ye Zhu, Juan Pei, Siyu Chen, Yu Zhou, Yi Wang, Yifan Zhou, Hao Li, Songan Zhang

Court efficiency is vital for social stability. However, in most countries
around the world, the grassroots courts face case backlogs, with decisions
relying heavily on judicial personnel's cognitive labor, lacking intelligent
tools to improve efficiency. To address this issue, we propose an efficient law
article recommendation approach utilizing a Knowledge Graph (KG) and a Large
Language Model (LLM). Firstly, we propose a Case-Enhanced Law Article Knowledge
Graph (CLAKG) as a database to store current law statutes, historical case
information, and correspondence between law articles and historical cases.
Additionally, we introduce an automated CLAKG construction method based on LLM.
On this basis, we propose a closed-loop law article recommendation method.
Finally, through a series of experiments using judgment documents from the
website "China Judgements Online", we have improved the accuracy of law article
recommendation in cases from 0.549 to 0.694, demonstrating that our proposed
method significantly outperforms baseline approaches.

摘要：法院效率對於社會穩定至關重要。然而，在世界大多數國家中，基層法院面臨案件積壓，判決嚴重依賴司法人員的認知勞動，缺乏提高效率的智能工具。為了解決這個問題，我們提出了一個利用知識圖譜 (KG) 和大型語言模型 (LLM) 的高效法律條文推薦方法。首先，我們提出一個案例增強法律條文知識圖譜 (CLAKG) 作為一個資料庫，用於儲存現行法律法規、歷史案例資訊和法律條文與歷史案例之間的對應關係。此外，我們引入一個基於 LLM 的自動化 CLAKG 構建方法。在此基礎上，我們提出了一個閉環法律條文推薦方法。最後，透過一連串使用來自網站「中國裁判文書網」的裁判文書的實驗，我們將案件中法律條文推薦的準確率從 0.549 提升至 0.694，證明我們提出的方法顯著優於基準方法。

##### **Detecting and Approximating Redundant Computational Blocks in Neural Networks**
2410.04941v1 by Irene Cannistraci, Emanuele Rodolà, Bastian Rieck

Deep neural networks often learn similar internal representations, both
across different models and within their own layers. While inter-network
similarities have enabled techniques such as model stitching and merging,
intra-network similarities present new opportunities for designing more
efficient architectures. In this paper, we investigate the emergence of these
internal similarities across different layers in diverse neural architectures,
showing that similarity patterns emerge independently of the datataset used. We
introduce a simple metric, Block Redundancy, to detect redundant blocks,
providing a foundation for future architectural optimization methods. Building
on this, we propose Redundant Blocks Approximation (RBA), a general framework
that identifies and approximates one or more redundant computational blocks
using simpler transformations. We show that the transformation $\mathcal{T}$
between two representations can be efficiently computed in closed-form, and it
is enough to replace the redundant blocks from the network. RBA reduces model
parameters and time complexity while maintaining good performance. We validate
our method on classification tasks in the vision domain using a variety of
pretrained foundational models and datasets.

摘要：深度神经网络通常会学习相似的内部表示，无论是在不同模型之间还是在其自身的层内。虽然网络间相似性已使模型拼接和合并等技术成为可能，但网络内相似性为设计更有效的架构提供了新的机会。在本文中，我们调查了在不同神经架构的不同层中出现的这些内部相似性，表明相似性模式独立于所使用的数据集而出现。我们引入了一个简单的度量标准，即块冗余，以检测冗余块，为未来的架构优化方法奠定基础。在此基础上，我们提出了冗余块近似 (RBA)，这是一个通用框架，它使用更简单的变换来识别和近似一个或多个冗余计算块。我们表明，两个表示之间的变换$\mathcal{T}$可以在封闭形式中有效计算，并且足以替换网络中的冗余块。RBA 减少了模型参数和时间复杂度，同时保持了良好的性能。我们使用各种预训练基础模型和数据集对视觉域中的分类任务验证了我们的方法。

##### **Training Interactive Agent in Large FPS Game Map with Rule-enhanced Reinforcement Learning**
2410.04936v1 by Chen Zhang, Huan Hu, Yuan Zhou, Qiyang Cao, Ruochen Liu, Wenya Wei, Elvis S. Liu

In the realm of competitive gaming, 3D first-person shooter (FPS) games have
gained immense popularity, prompting the development of game AI systems to
enhance gameplay. However, deploying game AI in practical scenarios still poses
challenges, particularly in large-scale and complex FPS games. In this paper,
we focus on the practical deployment of game AI in the online multiplayer
competitive 3D FPS game called Arena Breakout, developed by Tencent Games. We
propose a novel gaming AI system named Private Military Company Agent (PMCA),
which is interactable within a large game map and engages in combat with
players while utilizing tactical advantages provided by the surrounding
terrain.
  To address the challenges of navigation and combat in modern 3D FPS games, we
introduce a method that combines navigation mesh (Navmesh) and shooting-rule
with deep reinforcement learning (NSRL). The integration of Navmesh enhances
the agent's global navigation capabilities while shooting behavior is
controlled using rule-based methods to ensure controllability. NSRL employs a
DRL model to predict when to enable the navigation mesh, resulting in a diverse
range of behaviors for the game AI. Customized rewards for human-like behaviors
are also employed to align PMCA's behavior with that of human players.

摘要：在競爭激烈的遊戲領域中，3D 第一人稱射擊 (FPS) 遊戲獲得了極高的人氣，促使遊戲 AI 系統的開發以增強遊戲玩法。然而，在實際場景中部署遊戲 AI 仍然會帶來挑戰，尤其是在大型且複雜的 FPS 遊戲中。在本文中，我們專注於在 Tencent Games 開發的在線多人競爭 3D FPS 遊戲 Arena Breakout 中實際部署遊戲 AI。我們提出了一個名為私人軍事公司特工 (PMCA) 的新遊戲 AI 系統，它可以在大型遊戲地圖中進行互動，並在利用周圍地形提供的戰術優勢時與玩家進行戰鬥。
為了應對現代 3D FPS 遊戲中的導航和戰鬥挑戰，我們引入了一種結合導航網格 (Navmesh) 和射擊規則與深度強化學習 (NSRL) 的方法。Navmesh 的整合增強了代理的全局導航能力，而射擊行為則使用基於規則的方法進行控制，以確保可控性。NSRL 使用 DRL 模型來預測何時啟用導航網格，從而為遊戲 AI 產生各種行為。還採用了針對類人行為的客製化獎勵，以使 PMCA 的行為與人類玩家的行為保持一致。

##### **The Role of Governments in Increasing Interconnected Post-Deployment Monitoring of AI**
2410.04931v1 by Merlin Stein, Jamie Bernardi, Connor Dunlop

Language-based AI systems are diffusing into society, bringing positive and
negative impacts. Mitigating negative impacts depends on accurate impact
assessments, drawn from an empirical evidence base that makes causal
connections between AI usage and impacts. Interconnected post-deployment
monitoring combines information about model integration and use, application
use, and incidents and impacts. For example, inference time monitoring of
chain-of-thought reasoning can be combined with long-term monitoring of
sectoral AI diffusion, impacts and incidents. Drawing on information sharing
mechanisms in other industries, we highlight example data sources and specific
data points that governments could collect to inform AI risk management.

摘要：以語言為基礎的人工智慧系統正擴散至社會，帶來正面與負面的影響。減輕負面影響仰賴準確的影響評估，而這些評估則來自於經驗證據基礎，並在人工智慧使用與影響之間建立因果關係。相互連結的部署後監控結合了關於模型整合與使用、應用程式使用、事件與影響的資訊。例如，對思考鏈推理的推論時間監控可以結合對產業人工智慧擴散、影響與事件的長期監控。利用其他產業的資訊分享機制，我們強調了政府可以收集的範例資料來源和特定資料點，以提供人工智慧風險管理資訊。

##### **Intent Classification for Bank Chatbots through LLM Fine-Tuning**
2410.04925v1 by Bibiána Lajčinová, Patrik Valábek, Michal Spišiak

This study evaluates the application of large language models (LLMs) for
intent classification within a chatbot with predetermined responses designed
for banking industry websites. Specifically, the research examines the
effectiveness of fine-tuning SlovakBERT compared to employing multilingual
generative models, such as Llama 8b instruct and Gemma 7b instruct, in both
their pre-trained and fine-tuned versions. The findings indicate that
SlovakBERT outperforms the other models in terms of in-scope accuracy and
out-of-scope false positive rate, establishing it as the benchmark for this
application.

摘要：本研究評估了大型語言模型 (LLM) 在預先設定的回應中用於聊天機器人的意圖分類的應用，這些回應是為銀行業網站設計的。具體來說，這項研究探討了微調 SlovakBERT 的有效性，並將其與採用多語言生成模型（例如 Llama 8b instruct 和 Gemma 7b instruct）進行比較，包括它們的預訓練和微調版本。研究結果表明，SlovakBERT 在範圍內準確性和範圍外誤報率方面優於其他模型，使其成為此應用程序的基準。

##### **Defense-as-a-Service: Black-box Shielding against Backdoored Graph Models**
2410.04916v1 by Xiao Yang, Kai Zhou, Yuni Lai, Gaolei Li

With the trend of large graph learning models, business owners tend to employ
a model provided by a third party to deliver business services to users.
However, these models might be backdoored, and malicious users can submit
trigger-embedded inputs to manipulate the model predictions. Current graph
backdoor defenses have several limitations: 1) depending on model-related
details, 2) requiring additional model fine-tuning, and 3) relying upon extra
explainability tools, all of which are infeasible under stringent privacy
policies. To address those limitations, we propose GraphProt, which allows
resource-constrained business owners to rely on third parties to avoid backdoor
attacks on GNN-based graph classifiers. Our GraphProt is model-agnostic and
only relies on the input graph. The key insight is to leverage subgraph
information for prediction, thereby mitigating backdoor effects induced by
triggers. GraphProt comprises two components: clustering-based trigger
elimination and robust subgraph ensemble. Specifically, we first propose
feature-topology clustering that aims to remove most of the anomalous subgraphs
(triggers). Moreover, we design subgraph sampling strategies based on
feature-topology clustering to build a robust classifier via majority vote.
Experimental results across three backdoor attacks and six benchmark datasets
demonstrate that GraphProt significantly reduces the backdoor attack success
rate while preserving the model accuracy on regular graph classification tasks.

摘要：随着大型图学习模型的趋势，企业主倾向于采用第三方提供的模型向用户提供业务服务。然而，这些模型可能是后门，恶意用户可以提交触发器嵌入的输入来操纵模型预测。当前的图后门防御有几个限制：1）依赖于与模型相关的细节，2）需要额外的模型微调，3）依赖于额外的可解释性工具，所有这些在严格的隐私政策下都是不可行的。为了解决这些限制，我们提出了 GraphProt，它允许资源受限的企业主依靠第三方来避免基于 GNN 的图分类器的后门攻击。我们的 GraphProt 与模型无关，只依赖于输入图。关键的见解是利用子图信息进行预测，从而减轻由触发器引起的后门效应。GraphProt 包含两个组件：基于聚类的触发器消除和鲁棒子图集成。具体来说，我们首先提出特征拓扑聚类，旨在去除大部分异常子图（触发器）。此外，我们基于特征拓扑聚类设计子图采样策略，以通过多数投票构建鲁棒分类器。三个后门攻击和六个基准数据集的实验结果表明，GraphProt 显着降低了后门攻击成功率，同时保持了模型在常规图分类任务上的准确性。

##### **Patch is Enough: Naturalistic Adversarial Patch against Vision-Language Pre-training Models**
2410.04884v1 by Dehong Kong, Siyuan Liang, Xiaopeng Zhu, Yuansheng Zhong, Wenqi Ren

Visual language pre-training (VLP) models have demonstrated significant
success across various domains, yet they remain vulnerable to adversarial
attacks. Addressing these adversarial vulnerabilities is crucial for enhancing
security in multimodal learning. Traditionally, adversarial methods targeting
VLP models involve simultaneously perturbing images and text. However, this
approach faces notable challenges: first, adversarial perturbations often fail
to translate effectively into real-world scenarios; second, direct
modifications to the text are conspicuously visible. To overcome these
limitations, we propose a novel strategy that exclusively employs image patches
for attacks, thus preserving the integrity of the original text. Our method
leverages prior knowledge from diffusion models to enhance the authenticity and
naturalness of the perturbations. Moreover, to optimize patch placement and
improve the efficacy of our attacks, we utilize the cross-attention mechanism,
which encapsulates intermodal interactions by generating attention maps to
guide strategic patch placements. Comprehensive experiments conducted in a
white-box setting for image-to-text scenarios reveal that our proposed method
significantly outperforms existing techniques, achieving a 100% attack success
rate. Additionally, it demonstrates commendable performance in transfer tasks
involving text-to-image configurations.

摘要：視覺語言預訓練 (VLP) 模型在各種領域中展現顯著的成功，但它們仍然容易受到對抗性攻擊。處理這些對抗性漏洞對於增強多模態學習中的安全性至關重要。傳統上，針對 VLP 模型的對抗性方法包括同時擾動影像和文字。然而，這種方法面臨顯著的挑戰：首先，對抗性擾動通常無法有效轉換成真實世界的場景；其次，對文字的直接修改顯而易見。為了克服這些限制，我們提出了一種新穎的策略，該策略專門使用影像貼片進行攻擊，從而保留原始文字的完整性。我們的模型利用擴散模型中的先驗知識來增強擾動的真實性和自然性。此外，為了優化貼片放置並提高攻擊的效能，我們利用跨注意力機制，透過產生注意力圖來引導策略性貼片放置，從而封裝跨模態互動。在影像到文字場景的白盒設定中進行的全面實驗表明，我們提出的方法明顯優於現有技術，達到 100% 的攻擊成功率。此外，它在涉及文字到影像配置的轉移任務中展示了值得稱道的效能。

##### **Leveraging Grammar Induction for Language Understanding and Generation**
2410.04878v1 by Jushi Kai, Shengyuan Hou, Yusheng Huang, Zhouhan Lin

Grammar induction has made significant progress in recent years. However, it
is not clear how the application of induced grammar could enhance practical
performance in downstream tasks. In this work, we introduce an unsupervised
grammar induction method for language understanding and generation. We
construct a grammar parser to induce constituency structures and dependency
relations, which is simultaneously trained on downstream tasks without
additional syntax annotations. The induced grammar features are subsequently
incorporated into Transformer as a syntactic mask to guide self-attention. We
evaluate and apply our method to multiple machine translation tasks and natural
language understanding tasks. Our method demonstrates superior performance
compared to the original Transformer and other models enhanced with external
parsers. Experimental results indicate that our method is effective in both
from-scratch and pre-trained scenarios. Additionally, our research highlights
the contribution of explicitly modeling the grammatical structure of texts to
neural network models.

摘要：語法歸納在近年來取得顯著進展。然而，尚不清楚歸納語法的應用如何能提升下游任務的實際表現。在這項工作中，我們介紹了一種非監督式語言理解和產生的語法歸納方法。我們建構了一個語法解析器來歸納成份結構和依存關係，並同時在沒有額外句法標註的情況下，對下游任務進行訓練。隨後將歸納的語法特徵作為句法遮罩整合到 Transformer 中，以引導自我注意。我們評估並將我們的模型應用於多項機器翻譯任務和自然語言理解任務。與原始 Transformer 和其他使用外部解析器增強的模型相比，我們的模型展現出優異的表現。實驗結果表明，我們的模型在從頭訓練和預訓練場景中都非常有效。此外，我們的研究重點說明了將文本的語法結構明確建模對神經網路模型的貢獻。

##### **TimeCNN: Refining Cross-Variable Interaction on Time Point for Time Series Forecasting**
2410.04853v1 by Ao Hu, Dongkai Wang, Yong Dai, Shiyi Qi, Liangjian Wen, Jun Wang, Zhi Chen, Xun Zhou, Zenglin Xu, Jiang Duan

Time series forecasting is extensively applied across diverse domains.
Transformer-based models demonstrate significant potential in modeling
cross-time and cross-variable interaction. However, we notice that the
cross-variable correlation of multivariate time series demonstrates
multifaceted (positive and negative correlations) and dynamic progression over
time, which is not well captured by existing Transformer-based models. To
address this issue, we propose a TimeCNN model to refine cross-variable
interactions to enhance time series forecasting. Its key innovation is
timepoint-independent, where each time point has an independent convolution
kernel, allowing each time point to have its independent model to capture
relationships among variables. This approach effectively handles both positive
and negative correlations and adapts to the evolving nature of variable
relationships over time. Extensive experiments conducted on 12 real-world
datasets demonstrate that TimeCNN consistently outperforms state-of-the-art
models. Notably, our model achieves significant reductions in computational
requirements (approximately 60.46%) and parameter count (about 57.50%), while
delivering inference speeds 3 to 4 times faster than the benchmark iTransformer
model

摘要：時序預測廣泛應用於各個領域。
基於 Transformer 的模型在建模跨時間和跨變數交互方面展現出顯著的潛力。然而，我們注意到多變數時序的跨變數相關性呈現多方面的（正相關和負相關）和動態進展，這一點並未被現有的基於 Transformer 的模型很好地捕捉到。為了解決這個問題，我們提出了一個 TimeCNN 模型來優化跨變數交互以增強時序預測。其關鍵創新是時間點無關的，其中每個時間點都有獨立的卷積核，允許每個時間點擁有自己的獨立模型來捕捉變數之間的關係。這種方法有效地處理正相關和負相關，並適應變數關係隨時間推移而變化的本質。在 12 個真實世界資料集上進行的大量實驗表明，TimeCNN 持續優於最先進的模型。值得注意的是，我們的模型在計算需求（約 60.46%）和參數計數（約 57.50%）方面實現了顯著的降低，同時提供比基準 iTransformer 模型快 3 到 4 倍的推理速度

##### **Rationale-Aware Answer Verification by Pairwise Self-Evaluation**
2410.04838v1 by Akira Kawabata, Saku Sugawara

Answer verification identifies correct solutions among candidates generated
by large language models (LLMs). Current approaches typically train verifier
models by labeling solutions as correct or incorrect based solely on whether
the final answer matches the gold answer. However, this approach neglects any
flawed rationale in the solution yielding the correct answer, undermining the
verifier's ability to distinguish between sound and flawed rationales. We
empirically show that in StrategyQA, only 19% of LLM-generated solutions with
correct answers have valid rationales, thus leading to an unreliable verifier.
Furthermore, we demonstrate that training a verifier on valid rationales
significantly improves its ability to distinguish valid and flawed rationale.
To make a better verifier without extra human supervision, we introduce REPS
(Rationale Enhancement through Pairwise Selection), a method for selecting
valid rationales from candidates by iteratively applying pairwise
self-evaluation using the same LLM that generates the solutions. Verifiers
trained on solutions selected by REPS outperform those trained using
conventional training methods on three reasoning benchmarks (ARC-Challenge,
DROP, and StrategyQA). Our results suggest that training reliable verifiers
requires ensuring the validity of rationales in addition to the correctness of
the final answers, which would be critical for models assisting humans in
solving complex reasoning tasks.

摘要：答案驗證會從大型語言模型 (LLM) 生成的候選答案中找出正確的解答。目前的作法通常會根據最終答案是否與正確答案相符，將解答標記為正確或不正確，進而訓練驗證模型。然而，這種作法忽略了產生正確答案的解答中任何有缺陷的依據，這會損害驗證器區分合理依據和有缺陷依據的能力。我們透過實證顯示，在 StrategyQA 中，只有 19% 產生正確答案的 LLM 生成的解答具有有效的依據，因此導致驗證器不可靠。此外，我們證明了在有效的依據上訓練驗證器，可以顯著提升其區分有效和有缺陷依據的能力。為了在沒有額外人工監督的情況下製作出更好的驗證器，我們引入了 REPS（透過成對選擇進行依據強化），這是一種透過使用產生解答的相同 LLM，反覆套用成對自我評估來從候選答案中選擇有效依據的方法。使用 REPS 選擇的解答所訓練的驗證器，在三個推理基準測試（ARC-Challenge、DROP 和 StrategyQA）上的表現優於使用傳統訓練方法訓練的驗證器。我們的結果顯示，訓練可靠的驗證器需要確保依據的有效性，以及最終答案的正確性，這對於協助人類解決複雜推理任務的模型至關重要。

##### **As Simple as Fine-tuning: LLM Alignment via Bidirectional Negative Feedback Loss**
2410.04834v1 by Xin Mao, Feng-Lin Li, Huimin Xu, Wei Zhang, Wang Chen, Anh Tuan Luu

Direct Preference Optimization (DPO) has emerged as a more computationally
efficient alternative to Reinforcement Learning from Human Feedback (RLHF) with
Proximal Policy Optimization (PPO), eliminating the need for reward models and
online sampling. Despite these benefits, DPO and its variants remain sensitive
to hyper-parameters and prone to instability, particularly on mathematical
datasets. We argue that these issues arise from the unidirectional
likelihood-derivative negative feedback inherent in the log-likelihood loss
function. To address this, we propose a novel LLM alignment loss that
establishes a stable Bidirectional Negative Feedback (BNF) during optimization.
Our proposed BNF loss eliminates the need for pairwise contrastive losses and
does not require any extra tunable hyper-parameters or pairwise preference
data, streamlining the alignment pipeline to be as simple as supervised
fine-tuning. We conduct extensive experiments across two challenging QA
benchmarks and four reasoning benchmarks. The experimental results show that
BNF achieves comparable performance to the best methods on QA benchmarks, while
its performance decrease on the four reasoning benchmarks is significantly
lower compared to the best methods, thus striking a better balance between
value alignment and reasoning ability. In addition, we further validate the
performance of BNF on non-pairwise datasets, and conduct in-depth analysis of
log-likelihood and logit shifts across different preference optimization
methods.

摘要：直接偏好優化 (DPO) 已成為一種更具計算效率的替代方案，用於透過近端策略最佳化 (PPO) 從人類回饋中進行強化學習 (RLHF)，消除了對獎勵模型和線上抽樣的需要。儘管有這些好處，但 DPO 及其變體仍然對超參數敏感，且容易不穩定，特別是在數學資料集上。我們認為這些問題源於對數似然損失函數中固有的單向似然導數負回饋。為了解決這個問題，我們提出了一種新穎的 LLM 對齊損失，它在最佳化過程中建立了一個穩定的雙向負回饋 (BNF)。我們提出的 BNF 損失消除了對成對對比損失的需求，並且不需要任何額外的可調整超參數或成對偏好數據，簡化了對齊管道，使其與監督微調一樣簡單。我們在兩個具有挑戰性的問答基準和四個推理基準上進行了廣泛的實驗。實驗結果表明，BNF 在問答基準上達到了與最佳方法相當的效能，而在四個推理基準上的效能下降與最佳方法相比顯著降低，從而取得了價值對齊和推理能力之間更好的平衡。此外，我們進一步驗證了 BNF 在非成對資料集上的效能，並對不同偏好最佳化方法中的對數似然和 logit 轉移進行了深入分析。

##### **Multimodal Fusion Strategies for Mapping Biophysical Landscape Features**
2410.04833v1 by Lucia Gordon, Nico Lang, Catherine Ressijac, Andrew Davies

Multimodal aerial data are used to monitor natural systems, and machine
learning can significantly accelerate the classification of landscape features
within such imagery to benefit ecology and conservation. It remains
under-explored, however, how these multiple modalities ought to be fused in a
deep learning model. As a step towards filling this gap, we study three
strategies (Early fusion, Late fusion, and Mixture of Experts) for fusing
thermal, RGB, and LiDAR imagery using a dataset of spatially-aligned
orthomosaics in these three modalities. In particular, we aim to map three
ecologically-relevant biophysical landscape features in African savanna
ecosystems: rhino middens, termite mounds, and water. The three fusion
strategies differ in whether the modalities are fused early or late, and if
late, whether the model learns fixed weights per modality for each class or
generates weights for each class adaptively, based on the input. Overall, the
three methods have similar macro-averaged performance with Late fusion
achieving an AUC of 0.698, but their per-class performance varies strongly,
with Early fusion achieving the best recall for middens and water and Mixture
of Experts achieving the best recall for mounds.

摘要：多模態航空數據用於監控自然系統，而機器學習可以顯著加速此類影像中景觀特徵的分類，以造福生態和保育。然而，如何將這些多重模態融合在深度學習模型中仍有待進一步探討。為了填補這項空白，我們研究了三種策略（早期融合、後期融合和專家混合）以融合熱像、RGB 和 LiDAR 影像，使用這三種模態中空間對齊正射影像的資料集。具體來說，我們的目標是繪製非洲稀樹草原生態系統中三個生態相關的生物物理景觀特徵：犀牛糞堆、白蟻丘和水。這三種融合策略的差異在於模態是早期或後期融合，以及如果後期融合，模型是針對每個類別學習每個模態的固定權重，還是根據輸入自適應地產生每個類別的權重。總體而言，這三種方法具有相似的巨觀平均效能，後期融合達到 0.698 的 AUC，但它們的每個類別效能差異很大，早期融合達到糞堆和水的最佳召回率，而專家混合達到土丘的最佳召回率。

##### **MINER: Mining the Underlying Pattern of Modality-Specific Neurons in Multimodal Large Language Models**
2410.04819v1 by Kaichen Huang, Jiahao Huo, Yibo Yan, Kun Wang, Yutao Yue, Xuming Hu

In recent years, multimodal large language models (MLLMs) have significantly
advanced, integrating more modalities into diverse applications. However, the
lack of explainability remains a major barrier to their use in scenarios
requiring decision transparency. Current neuron-level explanation paradigms
mainly focus on knowledge localization or language- and domain-specific
analyses, leaving the exploration of multimodality largely unaddressed. To
tackle these challenges, we propose MINER, a transferable framework for mining
modality-specific neurons (MSNs) in MLLMs, which comprises four stages: (1)
modality separation, (2) importance score calculation, (3) importance score
aggregation, (4) modality-specific neuron selection. Extensive experiments
across six benchmarks and two representative MLLMs show that (I) deactivating
ONLY 2% of MSNs significantly reduces MLLMs performance (0.56 to 0.24 for
Qwen2-VL, 0.69 to 0.31 for Qwen2-Audio), (II) different modalities mainly
converge in the lower layers, (III) MSNs influence how key information from
various modalities converges to the last token, (IV) two intriguing phenomena
worth further investigation, i.e., semantic probing and semantic telomeres. The
source code is available at this URL.

摘要：近年來，多模態大型語言模型（MLLM）已顯著進步，將更多模態整合到各種應用中。然而，缺乏可解釋性仍然是它們在需要決策透明度的場景中使用的一大障礙。目前的元件層級解釋範例主要集中在知識定位或語言和特定領域的分析上，在很大程度上忽略了多模態的探索。為了應對這些挑戰，我們提出了 MINER，一個可轉移的框架，用於挖掘 MLLM 中的模態特定神經元（MSN），它包含四個階段：(1) 模態分離，(2) 重要性分數計算，(3) 重要性分數聚合，(4) 模態特定神經元選擇。在六個基準和兩個代表性 MLLM 上進行的廣泛實驗表明 (I) 僅停用 2% 的 MSN 顯著降低了 MLLM 的效能（Qwen2-VL 從 0.56 降至 0.24，Qwen2-Audio 從 0.69 降至 0.31），(II) 不同的模態主要集中在下層，(III) MSN 影響了來自不同模態的關鍵資訊如何集中到最後一個符號，(IV) 兩個值得進一步研究的有趣現象，即語義探測和語義端粒。原始程式碼可在這個 URL 取得。

##### **Resource-Efficient Multiview Perception: Integrating Semantic Masking with Masked Autoencoders**
2410.04817v1 by Kosta Dakic, Kanchana Thilakarathna, Rodrigo N. Calheiros, Teng Joon Lim

Multiview systems have become a key technology in modern computer vision,
offering advanced capabilities in scene understanding and analysis. However,
these systems face critical challenges in bandwidth limitations and
computational constraints, particularly for resource-limited camera nodes like
drones. This paper presents a novel approach for communication-efficient
distributed multiview detection and tracking using masked autoencoders (MAEs).
We introduce a semantic-guided masking strategy that leverages pre-trained
segmentation models and a tunable power function to prioritize informative
image regions. This approach, combined with an MAE, reduces communication
overhead while preserving essential visual information. We evaluate our method
on both virtual and real-world multiview datasets, demonstrating comparable
performance in terms of detection and tracking performance metrics compared to
state-of-the-art techniques, even at high masking ratios. Our selective masking
algorithm outperforms random masking, maintaining higher accuracy and precision
as the masking ratio increases. Furthermore, our approach achieves a
significant reduction in transmission data volume compared to baseline methods,
thereby balancing multiview tracking performance with communication efficiency.

摘要：多視角系統已成為現代電腦視覺中的關鍵技術，在場景理解和分析中提供先進的功能。然而，這些系統在頻寬限制和計算限制方面面臨嚴峻的挑戰，特別是對於資源有限的相機節點，例如無人機。本文提出了一種新的方法，使用遮罩式自動編碼器 (MAE) 進行通訊高效的分散多視角偵測和追蹤。我們引入了一種語義引導遮罩策略，該策略利用預先訓練的分割模型和可調整的冪函數來優先考慮有意義的影像區域。這種方法與 MAE 結合使用，可減少通訊開銷，同時保留必要的視覺資訊。我們在虛擬和真實世界多視角資料集上評估了我們的方法，證明了與最先進的技術相比，即使在高遮罩率下，在偵測和追蹤效能指標方面也具有可比的效能。我們的選擇性遮罩演算法優於隨機遮罩，隨著遮罩率的增加，維持較高的準確度和精確度。此外，與基線方法相比，我們的做法顯著減少了傳輸資料量，從而平衡了多視角追蹤效能和通訊效率。

##### **A Review of Artificial Intelligence based Biological-Tree Construction: Priorities, Methods, Applications and Trends**
2410.04815v1 by Zelin Zang, Yongjie Xu, Chenrui Duan, Jinlin Wu, Stan Z. Li, Zhen Lei

Biological tree analysis serves as a pivotal tool in uncovering the
evolutionary and differentiation relationships among organisms, genes, and
cells. Its applications span diverse fields including phylogenetics,
developmental biology, ecology, and medicine. Traditional tree inference
methods, while foundational in early studies, face increasing limitations in
processing the large-scale, complex datasets generated by modern
high-throughput technologies. Recent advances in deep learning offer promising
solutions, providing enhanced data processing and pattern recognition
capabilities. However, challenges remain, particularly in accurately
representing the inherently discrete and non-Euclidean nature of biological
trees. In this review, we first outline the key biological priors fundamental
to phylogenetic and differentiation tree analyses, facilitating a deeper
interdisciplinary understanding between deep learning researchers and
biologists. We then systematically examine the commonly used data formats and
databases, serving as a comprehensive resource for model testing and
development. We provide a critical analysis of traditional tree generation
methods, exploring their underlying biological assumptions, technical
characteristics, and limitations. Current developments in deep learning-based
tree generation are reviewed, highlighting both recent advancements and
existing challenges. Furthermore, we discuss the diverse applications of
biological trees across various biological domains. Finally, we propose
potential future directions and trends in leveraging deep learning for
biological tree research, aiming to guide further exploration and innovation in
this field.

摘要：生物樹分析作為揭示生物體、基因和細胞之間的演化和分化關係的關鍵工具。其應用跨越包括系統發生學、發育生物學、生態學和醫學等多個領域。傳統的樹推論方法雖然在早期研究中具有基礎性，但在處理現代高通量技術產生的規模龐大、複雜的數據集方面面臨著越來越多的限制。深度學習的最新進展提供了有前景的解決方案，提供了增強的數據處理和模式識別能力。然而，挑戰依然存在，特別是在準確表示生物樹固有的離散和非歐幾何性質方面。在這篇綜述中，我們首先概述了系統發生和分化樹分析的基本生物先驗，促進了深度學習研究人員和生物學家之間更深入的跨學科理解。然後，我們系統地檢查了常用的數據格式和數據庫，作為模型測試和開發的綜合資源。我們對傳統的樹生成方法進行了批判性分析，探討了它們的底層生物假設、技術特徵和局限性。回顧了基於深度學習的樹生成的當前發展，重點介紹了最近的進展和現有的挑戰。此外，我們討論了生物樹在各種生物領域的多樣化應用。最後，我們提出了利用深度學習進行生物樹研究的潛在未來方向和趨勢，旨在指導該領域的進一步探索和創新。

##### **Learning Interpretable Hierarchical Dynamical Systems Models from Time Series Data**
2410.04814v1 by Manuel Brenner, Elias Weber, Georgia Koppe, Daniel Durstewitz

In science, we are often interested in obtaining a generative model of the
underlying system dynamics from observed time series. While powerful methods
for dynamical systems reconstruction (DSR) exist when data come from a single
domain, how to best integrate data from multiple dynamical regimes and leverage
it for generalization is still an open question. This becomes particularly
important when individual time series are short, and group-level information
may help to fill in for gaps in single-domain data. At the same time, averaging
is not an option in DSR, as it will wipe out crucial dynamical properties
(e.g., limit cycles in one domain vs. chaos in another). Hence, a framework is
needed that enables to efficiently harvest group-level (multi-domain)
information while retaining all single-domain dynamical characteristics. Here
we provide such a hierarchical approach and showcase it on popular DSR
benchmarks, as well as on neuroscientific and medical time series. In addition
to faithful reconstruction of all individual dynamical regimes, our
unsupervised methodology discovers common low-dimensional feature spaces in
which datasets with similar dynamics cluster. The features spanning these
spaces were further dynamically highly interpretable, surprisingly in often
linear relation to control parameters that govern the dynamics of the
underlying system. Finally, we illustrate transfer learning and generalization
to new parameter regimes.

摘要：在科學中，我們常常有興趣從觀察到的時間序列中獲得基礎系統動態的生成模型。雖然當資料來自單一領域時，強大的動態系統重建 (DSR) 方法已經存在，但如何最佳整合來自多個動態機制的資料並利用它進行概括仍然是一個開放的問題。當個別時間序列很短時，這一點尤其重要，而且群組層級的資訊可能有助於填補單一領域資料中的空白。同時，平均化並非 DSR 中的選項，因為它會消除關鍵的動態特性（例如，一個領域中的極限週期相對於另一個領域中的混亂）。因此，需要一個框架，能夠有效收集群組層級（多領域）資訊，同時保留所有單一領域動態特性。在這裡，我們提供這種階層式方法，並在流行的 DSR 基準以及神經科學和醫學時間序列中展示它。除了忠實重建所有個別動態機制之外，我們的非監督方法還發現了常見的低維特徵空間，其中具有相似動態的資料集會成群。跨越這些空間的特徵在動態上進一步具有高度可解釋性，令人驚訝的是，它們通常與控制基礎系統動態的控制參數呈線性關係。最後，我們說明了遷移式學習和對新參數機制的概括。

##### **LPZero: Language Model Zero-cost Proxy Search from Zero**
2410.04808v1 by Peijie Dong, Lujun Li, Xiang Liu, Zhenheng Tang, Xuebo Liu, Qiang Wang, Xiaowen Chu

In spite of the outstanding performance, Neural Architecture Search (NAS) is
criticized for massive computation. Recently, Zero-shot NAS has emerged as a
promising approach by exploiting Zero-cost (ZC) proxies, which markedly reduce
computational demands. Despite this, existing ZC proxies heavily rely on expert
knowledge and incur significant trial-and-error costs. Particularly in NLP
tasks, most existing ZC proxies fail to surpass the performance of the naive
baseline. To address these challenges, we introduce a novel framework,
\textbf{LPZero}, which is the first to automatically design ZC proxies for
various tasks, achieving higher ranking consistency than human-designed
proxies. Specifically, we model the ZC proxy as a symbolic equation and
incorporate a unified proxy search space that encompasses existing ZC proxies,
which are composed of a predefined set of mathematical symbols. To
heuristically search for the best ZC proxy, LPZero incorporates genetic
programming to find the optimal symbolic composition. We propose a
\textit{Rule-based Pruning Strategy (RPS),} which preemptively eliminates
unpromising proxies, thereby mitigating the risk of proxy degradation.
Extensive experiments on FlexiBERT, GPT-2, and LLaMA-7B demonstrate LPZero's
superior ranking ability and performance on downstream tasks compared to
current approaches.

摘要：儘管神经架构搜索 (NAS) 拥有出色的性能，但它因大量运算而受到批评。最近，零次学习 NAS 作为一种有前途的方法出现，它利用零成本 (ZC) 代理，大幅减少了计算需求。尽管如此，现有的 ZC 代理严重依赖专家知识，并会产生大量的试错成本。特别是在 NLP 任务中，大多数现有的 ZC 代理都无法超越朴素基准的性能。为了解决这些挑战，我们引入了新颖的框架 \textbf{LPZero}，这是第一个自动为各种任务设计 ZC 代理的框架，其排名一致性高于人工设计的代理。具体来说，我们将 ZC 代理建模为一个符号方程式，并纳入了统一的代理搜索空间，其中包含现有的 ZC 代理，这些代理由一组预定义的数学符号组成。为了启发式地搜索最佳 ZC 代理，LPZero 纳入了遗传编程以找到最佳符号组合。我们提出了一个 \textit{基于规则的修剪策略 (RPS)，}它会预先消除没有前途的代理，从而减轻代理退化的风险。在 FlexiBERT、GPT-2 和 LLaMA-7B 上进行的广泛实验表明，与当前方法相比，LPZero 在下游任务上具有卓越的排名能力和性能。

##### **DAPE V2: Process Attention Score as Feature Map for Length Extrapolation**
2410.04798v1 by Chuanyang Zheng, Yihang Gao, Han Shi, Jing Xiong, Jiankai Sun, Jingyao Li, Minbin Huang, Xiaozhe Ren, Michael Ng, Xin Jiang, Zhenguo Li, Yu Li

The attention mechanism is a fundamental component of the Transformer model,
contributing to interactions among distinct tokens, in contrast to earlier
feed-forward neural networks. In general, the attention scores are determined
simply by the key-query products. However, this work's occasional trial
(combining DAPE and NoPE) of including additional MLPs on attention scores
without position encoding indicates that the classical key-query multiplication
may limit the performance of Transformers. In this work, we conceptualize
attention as a feature map and apply the convolution operator (for neighboring
attention scores across different heads) to mimic the processing methods in
computer vision. Specifically, the main contribution of this paper is
identifying and interpreting the Transformer length extrapolation problem as a
result of the limited expressiveness of the naive query and key dot product,
and we successfully translate the length extrapolation issue into a
well-understood feature map processing problem. The novel insight, which can be
adapted to various attention-related models, reveals that the current
Transformer architecture has the potential for further evolution. Extensive
experiments demonstrate that treating attention as a feature map and applying
convolution as a processing method significantly enhances Transformer
performance.

摘要：注意力机制是 Transformer 模型的基本組成部分，與早期的前饋神經網路不同，它有助於不同符號之間的互動。一般來說，注意力分數僅由鍵查詢乘積決定。然而，這項工作偶爾嘗試（結合 DAPE 和 NoPE）在注意力分數中加入額外的 MLP，而沒有位置編碼，這表示傳統的鍵查詢乘法可能會限制 Transformer 的效能。在這項工作中，我們將注意力概念化為特徵圖，並套用卷積運算子（針對不同頭部之間的鄰近注意力分數）來模擬電腦視覺中的處理方法。具體來說，本文的主要貢獻是將 Transformer 長度外推問題識別並詮釋為單純的查詢和鍵點積表現力有限的結果，而且我們成功地將長度外推問題轉換為一個理解良好的特徵圖處理問題。這個新穎的見解可以調整為各種與注意力相關的模型，它揭示了目前的 Transformer 架構有進一步演化的潛力。廣泛的實驗證明，將注意力視為特徵圖並套用卷積作為處理方法，可以顯著提升 Transformer 的效能。

##### **Representing the Under-Represented: Cultural and Core Capability Benchmarks for Developing Thai Large Language Models**
2410.04795v1 by Dahyun Kim, Sukyung Lee, Yungi Kim, Attapol Rutherford, Chanjun Park

The rapid advancement of large language models (LLMs) has highlighted the
need for robust evaluation frameworks that assess their core capabilities, such
as reasoning, knowledge, and commonsense, leading to the inception of certain
widely-used benchmark suites such as the H6 benchmark. However, these benchmark
suites are primarily built for the English language, and there exists a lack
thereof for under-represented languages, in terms of LLM development, such as
Thai. On the other hand, developing LLMs for Thai should also include enhancing
the cultural understanding as well as core capabilities. To address these dual
challenge in Thai LLM research, we propose two key benchmarks: Thai-H6 and Thai
Cultural and Linguistic Intelligence Benchmark (ThaiCLI). Through a thorough
evaluation of various LLMs with multi-lingual capabilities, we provide a
comprehensive analysis of the proposed benchmarks and how they contribute to
Thai LLM development. Furthermore, we will make both the datasets and
evaluation code publicly available to encourage further research and
development for Thai LLMs.

摘要：隨著大型語言模型 (LLM) 的快速進展，凸顯了對健全評估架構的需求，以評估其核心能力，例如推理、知識和常識，進而促使某些廣泛使用的基準套件（例如 H6基準）的誕生。然而，這些基準套件主要是為英語而建構，而對於在 LLM 開發方面代表性不足的語言，例如泰語，則缺乏此類基準套件。另一方面，為泰語開發 LLM 也應包括增強文化理解和核心能力。為了應對泰語 LLM 研究中的這項雙重挑戰，我們提出了兩個關鍵基準：泰語 H6 和泰語文化和語言智能基準 (ThaiCLI)。透過對具有多語言能力的各種 LLM 進行徹底評估，我們提供了對所提出基準的全面分析，以及它們如何促進泰語 LLM 的發展。此外，我們將公開發布資料集和評估程式碼，以鼓勵進一步研究和開發泰語 LLM。

##### **GARLIC: LLM-Guided Dynamic Progress Control with Hierarchical Weighted Graph for Long Document QA**
2410.04790v1 by Xinyu Wang, Yanzheng Xiang, Lin Gui, Yulan He

In the past, Retrieval-Augmented Generation (RAG) methods split text into
chunks to enable language models to handle long documents. Recent tree-based
RAG methods are able to retrieve detailed information while preserving global
context. However, with the advent of more powerful LLMs, such as Llama 3.1,
which offer better comprehension and support for longer inputs, we found that
even recent tree-based RAG methods perform worse than directly feeding the
entire document into Llama 3.1, although RAG methods still hold an advantage in
reducing computational costs. In this paper, we propose a new retrieval method,
called LLM-Guided Dynamic Progress Control with Hierarchical Weighted Graph
(GARLIC), which outperforms previous state-of-the-art baselines, including
Llama 3.1, while retaining the computational efficiency of RAG methods. Our
method introduces several improvements: (1) Rather than using a tree structure,
we construct a Hierarchical Weighted Directed Acyclic Graph with many-to-many
summarization, where the graph edges are derived from attention mechanisms, and
each node focuses on a single event or very few events. (2) We introduce a
novel retrieval method that leverages the attention weights of LLMs rather than
dense embedding similarity. Our method allows for searching the graph along
multiple paths and can terminate at any depth. (3) We use the LLM to control
the retrieval process, enabling it to dynamically adjust the amount and depth
of information retrieved for different queries. Experimental results show that
our method outperforms previous state-of-the-art baselines, including Llama
3.1, on two single-document and two multi-document QA datasets, while
maintaining similar computational complexity to traditional RAG methods.

摘要：<paragraph>在過去，檢索增強生成 (RAG) 方法會將文字切割成塊，以使語言模型能夠處理長篇文件。最近的基於樹的 RAG 方法能夠在保留整體脈絡的同時檢索詳細資訊。然而，隨著功能更強大的 LLM（例如 Llama 3.1）的出現，這些 LLM 提供了更好的理解力和對更長輸入的支援，我們發現即使是最近的基於樹的 RAG 方法也比直接將整個文件輸入 Llama 3.1 的表現更差，儘管 RAG 方法在降低運算成本方面仍具備優勢。在本文中，我們提出了一種新的檢索方法，稱為具有分層加權圖的 LLM 引導動態進度控制 (GARLIC)，它優於先前的最先進基準，包括 Llama 3.1，同時保留了 RAG 方法的運算效率。我們的改進方法引入了多項改進：(1) 我們沒有使用樹狀結構，而是構建了一個具有多對多摘要的分層加權有向無環圖，其中圖邊緣源自注意力機制，每個節點都專注於單一事件或極少數事件。(2) 我們引入了一種新穎的檢索方法，它利用 LLM 的注意力權重，而不是密集嵌入相似性。我們的改進方法允許沿多個路徑搜尋圖，並且可以在任何深度終止。(3) 我們使用 LLM 來控制檢索過程，使其能夠動態調整為不同查詢檢索的資訊量和深度。實驗結果表明，我們的改進方法在兩個單文件和兩個多文件問答資料集上優於先前的最先進基準，包括 Llama 3.1，同時維持與傳統 RAG 方法類似的運算複雜度。</paragraph>

##### **Analysis of Hybrid Compositions in Animation Film with Weakly Supervised Learning**
2410.04789v1 by Mónica Apellaniz Portos, Roberto Labadie-Tamayo, Claudius Stemmler, Erwin Feyersinger, Andreas Babic, Franziska Bruckner, Vrääth Öhner, Matthias Zeppelzauer

We present an approach for the analysis of hybrid visual compositions in
animation in the domain of ephemeral film. We combine ideas from
semi-supervised and weakly supervised learning to train a model that can
segment hybrid compositions without requiring pre-labeled segmentation masks.
We evaluate our approach on a set of ephemeral films from 13 film archives.
Results demonstrate that the proposed learning strategy yields a performance
close to a fully supervised baseline. On a qualitative level the performed
analysis provides interesting insights on hybrid compositions in animation
film.

摘要：我們提出一個方法，用於分析短暫電影中混合視覺合成。我們結合半監督式和弱監督式學習的想法，訓練一個模型，該模型可以在不需要預先標記的分割遮罩的情況下分割混合合成。我們在來自 13 個電影檔案館的一組短暫電影上評估我們的做法。結果表明，所提出的學習策略產生的性能接近於完全監督的基線。在定性層面上，所執行的分析提供了對動畫電影中混合合成的一些有趣的見解。

##### **Formality is Favored: Unraveling the Learning Preferences of Large Language Models on Data with Conflicting Knowledge**
2410.04784v1 by Jiahuan Li, Yiqing Cao, Shujian Huang, Jiajun Chen

Having been trained on massive pretraining data, large language models have
shown excellent performance on many knowledge-intensive tasks. However,
pretraining data tends to contain misleading and even conflicting information,
and it is intriguing to understand how LLMs handle these noisy data during
training. In this study, we systematically analyze LLMs' learning preferences
for data with conflicting knowledge. We find that pretrained LLMs establish
learning preferences similar to humans, i.e., preferences towards formal texts
and texts with fewer spelling errors, resulting in faster learning and more
favorable treatment of knowledge in data with such features when facing
conflicts. This finding is generalizable across models and languages and is
more evident in larger models. An in-depth analysis reveals that LLMs tend to
trust data with features that signify consistency with the majority of data,
and it is possible to instill new preferences and erase old ones by
manipulating the degree of consistency with the majority data.

摘要：在海量预训练数据上进行训练后，大型语言模型在许多知识密集型任务上表现出了优异的性能。然而，预训练数据往往包含误导甚至相互矛盾的信息，了解 LLM 在训练期间如何处理这些噪声数据是一件很有意思的事情。在这项研究中，我们系统地分析了 LLM 对具有冲突知识的数据的学习偏好。我们发现，预训练的 LLM 建立了类似于人类的学习偏好，即偏好正式文本和拼写错误较少的文本，从而在面对冲突时能够更快地学习和更倾向于处理具有此类特征的数据中的知识。这一发现可以推广到不同的模型和语言，并且在较大的模型中更加明显。深入分析表明，LLM 倾向于信任具有与大多数数据一致性的特征的数据，并且可以通过操纵与大多数数据的一致性程度来灌输新的偏好并消除旧的偏好。

##### **Molecular topological deep learning for polymer property prediction**
2410.04765v1 by Cong Shen, Yipeng Zhang, Fei Han, Kelin Xia

Accurate and efficient prediction of polymer properties is of key importance
for polymer design. Traditional experimental tools and density function theory
(DFT)-based simulations for polymer property evaluation, are both expensive and
time-consuming. Recently, a gigantic amount of graph-based molecular models
have emerged and demonstrated huge potential in molecular data analysis. Even
with the great progresses, these models tend to ignore the high-order and
mutliscale information within the data. In this paper, we develop molecular
topological deep learning (Mol-TDL) for polymer property analysis. Our Mol-TDL
incorporates both high-order interactions and multiscale properties into
topological deep learning architecture. The key idea is to represent polymer
molecules as a series of simplicial complices at different scales and build up
simplical neural networks accordingly. The aggregated information from
different scales provides a more accurate prediction of polymer molecular
properties.

摘要：聚合物的特性預測準確且有效，對於聚合物設計至關重要。傳統的實驗工具和基於密度泛函理論 (DFT) 的聚合物特性評估模擬既昂貴又耗時。近期，大量的圖形化分子模型應運而生，在分子數據分析中展現出巨大的潛力。即使有了這些巨大的進展，這些模型還是傾向於忽略數據中的高階和多尺度信息。在本文中，我們開發了分子拓撲深度學習 (Mol-TDL) 來進行聚合物特性分析。我們的 Mol-TDL 將高階交互作用和多尺度特性整合到拓撲深度學習架構中。其關鍵在於將聚合物分子表示為一系列不同尺度的單純復形，並據此建立單純神經網路。來自不同尺度的彙總信息可更準確地預測聚合物分子特性。

##### **Driving with Regulation: Interpretable Decision-Making for Autonomous Vehicles with Retrieval-Augmented Reasoning via LLM**
2410.04759v1 by Tianhui Cai, Yifan Liu, Zewei Zhou, Haoxuan Ma, Seth Z. Zhao, Zhiwen Wu, Jiaqi Ma

This work presents an interpretable decision-making framework for autonomous
vehicles that integrates traffic regulations, norms, and safety guidelines
comprehensively and enables seamless adaptation to different regions. While
traditional rule-based methods struggle to incorporate the full scope of
traffic rules, we develop a Traffic Regulation Retrieval (TRR) Agent based on
Retrieval-Augmented Generation (RAG) to automatically retrieve relevant traffic
rules and guidelines from extensive regulation documents and relevant records
based on the ego vehicle's situation. Given the semantic complexity of the
retrieved rules, we also design a reasoning module powered by a Large Language
Model (LLM) to interpret these rules, differentiate between mandatory rules and
safety guidelines, and assess actions on legal compliance and safety.
Additionally, the reasoning is designed to be interpretable, enhancing both
transparency and reliability. The framework demonstrates robust performance on
both hypothesized and real-world cases across diverse scenarios, along with the
ability to adapt to different regions with ease.

摘要：本研究提出了一個可解釋的決策制定架構，適用於自動駕駛車輛，該架構將交通法規、規範和安全準則全面整合，並能無縫適應不同地區。雖然傳統的基於規則的方法難以納入所有交通規則，但我們開發了一個基於檢索增強生成 (RAG) 的交通法規檢索 (TRR) 代理，以根據自駕車輛的情況從廣泛的法規文件和相關記錄中自動檢索相關交通規則和準則。鑑於檢索規則的語義複雜性，我們還設計了一個由大型語言模型 (LLM) 驅動的推理模組，以解釋這些規則、區分強制性規則和安全準則，並評估法律合規性和安全性方面的行動。此外，推理被設計為可解釋的，既增強了透明度又增強了可靠性。該架構在各種場景中對假設和真實案例都表現出穩健的性能，同時還能輕鬆適應不同地區。

##### **Item Cluster-aware Prompt Learning for Session-based Recommendation**
2410.04756v1 by Wooseong Yang, Chen Wang, Zihe Song, Weizhi Zhang, Philip S. Yu

Session-based recommendation (SBR) aims to capture dynamic user preferences
by analyzing item sequences within individual sessions. However, most existing
approaches focus mainly on intra-session item relationships, neglecting the
connections between items across different sessions (inter-session
relationships), which limits their ability to fully capture complex item
interactions. While some methods incorporate inter-session information, they
often suffer from high computational costs, leading to longer training times
and reduced efficiency. To address these challenges, we propose the CLIP-SBR
(Cluster-aware Item Prompt learning for Session-Based Recommendation)
framework. CLIP-SBR is composed of two modules: 1) an item relationship mining
module that builds a global graph to effectively model both intra- and
inter-session relationships, and 2) an item cluster-aware prompt learning
module that uses soft prompts to integrate these relationships into SBR models
efficiently. We evaluate CLIP-SBR across eight SBR models and three benchmark
datasets, consistently demonstrating improved recommendation performance and
establishing CLIP-SBR as a robust solution for session-based recommendation
tasks.

摘要：基於會話的推薦 (SBR) 的目標是透過分析個別會話中的項目序列來捕捉動態使用者偏好。然而，現有的方法大多著重於會話內項目關係，忽略不同會話之間項目的關聯 (會話間關係)，這限制了它們完全捕捉複雜項目互動的能力。雖然有些方法納入了會話間資訊，但它們經常會產生高運算成本，導致訓練時間更長，效率降低。為了應對這些挑戰，我們提出了 CLIP-SBR (基於會話的推薦的群集感知項目提示學習) 架構。CLIP-SBR 由兩個模組組成：1) 項目關係挖掘模組，建立一個全域圖形來有效建模會話內和會話間關係，以及 2) 項目群集感知提示學習模組，使用軟提示將這些關係有效整合到 SBR 模型中。我們在八個 SBR 模型和三個基準資料集上評估 CLIP-SBR，持續展現改善的推薦效能，並確立 CLIP-SBR 為基於會話的推薦任務的穩健解決方案。

##### **ImProver: Agent-Based Automated Proof Optimization**
2410.04753v1 by Riyaz Ahuja, Jeremy Avigad, Prasad Tetali, Sean Welleck

Large language models (LLMs) have been used to generate formal proofs of
mathematical theorems in proofs assistants such as Lean. However, we often want
to optimize a formal proof with respect to various criteria, depending on its
downstream use. For example, we may want a proof to adhere to a certain style,
or to be readable, concise, or modularly structured. Having suitably optimized
proofs is also important for learning tasks, especially since human-written
proofs may not optimal for that purpose. To this end, we study a new problem of
automated proof optimization: rewriting a proof so that it is correct and
optimizes for an arbitrary criterion, such as length or readability. As a first
method for automated proof optimization, we present ImProver, a
large-language-model agent that rewrites proofs to optimize arbitrary
user-defined metrics in Lean. We find that naively applying LLMs to proof
optimization falls short, and we incorporate various improvements into
ImProver, such as the use of symbolic Lean context in a novel Chain-of-States
technique, as well as error-correction and retrieval. We test ImProver on
rewriting real-world undergraduate, competition, and research-level mathematics
theorems, finding that ImProver is capable of rewriting proofs so that they are
substantially shorter, more modular, and more readable.

摘要：大型語言模型 (LLM) 已用於生成形式化證明，例如在 Lean 等證明輔助工具中證明數學定理。然而，我們通常希望根據各種準則來優化形式化證明，具體取決於其下游用途。例如，我們可能希望證明符合某種風格，或具有可讀性、簡潔性或模組化結構。擁有適當優化的證明對於學習任務也很重要，特別是因為人寫的證明可能不適合該目的。為此，我們研究了一個新的自動化證明優化問題：改寫證明，使其正確並針對任意準則（例如長度或可讀性）進行優化。作為自動化證明優化的第一種方法，我們提出了 ImProver，這是一個大型語言模型代理，它改寫證明以優化 Lean 中任意使用者定義的指標。我們發現，天真地將 LLM 應用於證明優化是不夠的，我們在 ImProver 中加入了各種改進，例如在新的狀態鏈技術中使用符號化 Lean 上下文，以及錯誤校正和檢索。我們在改寫真實世界的大學部、競賽和研究級別數學定理上測試了 ImProver，發現 ImProver 能夠改寫證明，使其顯著更短、更具模組化和更具可讀性。

##### **Document-level Causal Relation Extraction with Knowledge-guided Binary Question Answering**
2410.04752v1 by Zimu Wang, Lei Xia, Wei Wang, Xinya Du

As an essential task in information extraction (IE), Event-Event Causal
Relation Extraction (ECRE) aims to identify and classify the causal
relationships between event mentions in natural language texts. However,
existing research on ECRE has highlighted two critical challenges, including
the lack of document-level modeling and causal hallucinations. In this paper,
we propose a Knowledge-guided binary Question Answering (KnowQA) method with
event structures for ECRE, consisting of two stages: Event Structure
Construction and Binary Question Answering. We conduct extensive experiments
under both zero-shot and fine-tuning settings with large language models (LLMs)
on the MECI and MAVEN-ERE datasets. Experimental results demonstrate the
usefulness of event structures on document-level ECRE and the effectiveness of
KnowQA by achieving state-of-the-art on the MECI dataset. We observe not only
the effectiveness but also the high generalizability and low inconsistency of
our method, particularly when with complete event structures after fine-tuning
the models.

摘要：作為資訊萃取 (IE) 中的一項重要任務，事件事件因果關係萃取 (ECRE) 的目標是識別並分類自然語言文字中事件提及之間的因果關係。然而，現有關於 ECRE 的研究突顯了兩個關鍵挑戰，包括缺乏文件層級建模和因果幻覺。在本文中，我們提出一個具備事件結構的知識引導二元問答 (KnowQA) 方法用於 ECRE，它包含兩個階段：事件結構建構和二元問答。我們在大型語言模型 (LLM) 的零次學習和微調設定下，對 MECI 和 MAVEN-ERE 資料集進行廣泛的實驗。實驗結果證明了事件結構在文件層級 ECRE 中的效用，以及 KnowQA 的有效性，在 MECI 資料集上達到了最先進的水平。我們觀察到我們的模型不僅有效，而且具有高度的概括性以及低不一致性，特別是在微調模型後具備完整的事件結構時。

##### **Intriguing Properties of Large Language and Vision Models**
2410.04751v1 by Young-Jun Lee, Byungsoo Ko, Han-Gyu Kim, Yechan Hwang, Ho-Jin Choi

Recently, large language and vision models (LLVMs) have received significant
attention and development efforts due to their remarkable generalization
performance across a wide range of tasks requiring perception and cognitive
abilities. A key factor behind their success is their simple architecture,
which consists of a vision encoder, a projector, and a large language model
(LLM). Despite their achievements in advanced reasoning tasks, their
performance on fundamental perception-related tasks (e.g., MMVP) remains
surprisingly low. This discrepancy raises the question of how LLVMs truly
perceive images and exploit the advantages of the vision encoder. To address
this, we systematically investigate this question regarding several aspects:
permutation invariance, robustness, math reasoning, alignment preserving and
importance, by evaluating the most common LLVM's families (i.e., LLaVA) across
10 evaluation benchmarks. Our extensive experiments reveal several intriguing
properties of current LLVMs: (1) they internally process the image in a global
manner, even when the order of visual patch sequences is randomly permuted; (2)
they are sometimes able to solve math problems without fully perceiving
detailed numerical information; (3) the cross-modal alignment is overfitted to
complex reasoning tasks, thereby, causing them to lose some of the original
perceptual capabilities of their vision encoder; (4) the representation space
in the lower layers (<25%) plays a crucial role in determining performance and
enhancing visual understanding. Lastly, based on the above observations, we
suggest potential future directions for building better LLVMs and constructing
more challenging evaluation benchmarks.

摘要：<paragraph>最近，大型语言和视觉模型 (LLVM) 因其在需要感知和认知能力的广泛任务中表现出的卓越泛化性能而受到广泛关注和开发。它们成功的关键因素在于其简单的架构，该架构由视觉编码器、投影仪和大型语言模型 (LLM) 组成。尽管它们在高级推理任务中取得了成就，但它们在基本感知相关任务（例如 MMVP）上的表现仍然出人意料的低。这种差异提出了 LLVMs 如何真正感知图像并利用视觉编码器优势的问题。为了解决这个问题，我们系统地从几个方面对此问题进行了调查：排列不变性、鲁棒性、数学推理、对齐保持和重要性，通过在 10 个评估基准上评估最常见的 LLVM 家族（即 LLaVA）。我们广泛的实验揭示了当前 LLVMs 的几个有趣的特性：(1) 即使视觉补丁序列的顺序被随机排列，它们也会以全局方式在内部处理图像；(2) 它们有时能够在没有完全感知详细数字信息的情况下解决数学问题；(3) 跨模式对齐过度拟合到复杂的推理任务，因此导致它们失去视觉编码器的一些原始感知能力；(4) 较低层（<25%）中的表示空间在确定性能和增强视觉理解中起着至关重要的作用。最后，基于上述观察，我们提出了构建更好的 LLVMs 和构建更具挑战性的评估基准的潜在未来方向。</paragraph>

##### **Evaluating the Generalization Ability of Spatiotemporal Model in Urban Scenario**
2410.04740v1 by Hongjun Wang, Jiyuan Chen, Tong Pan, Zheng Dong, Lingyu Zhang, Renhe Jiang, Xuan Song

Spatiotemporal neural networks have shown great promise in urban scenarios by
effectively capturing temporal and spatial correlations. However, urban
environments are constantly evolving, and current model evaluations are often
limited to traffic scenarios and use data mainly collected only a few weeks
after training period to evaluate model performance. The generalization ability
of these models remains largely unexplored. To address this, we propose a
Spatiotemporal Out-of-Distribution (ST-OOD) benchmark, which comprises six
urban scenario: bike-sharing, 311 services, pedestrian counts, traffic speed,
traffic flow, ride-hailing demand, and bike-sharing, each with in-distribution
(same year) and out-of-distribution (next years) settings. We extensively
evaluate state-of-the-art spatiotemporal models and find that their performance
degrades significantly in out-of-distribution settings, with most models
performing even worse than a simple Multi-Layer Perceptron (MLP). Our findings
suggest that current leading methods tend to over-rely on parameters to overfit
training data, which may lead to good performance on in-distribution data but
often results in poor generalization. We also investigated whether dropout
could mitigate the negative effects of overfitting. Our results showed that a
slight dropout rate could significantly improve generalization performance on
most datasets, with minimal impact on in-distribution performance. However,
balancing in-distribution and out-of-distribution performance remains a
challenging problem. We hope that the proposed benchmark will encourage further
research on this critical issue.

摘要：時空神經網路已在城市場景中展現出極大的前景，能有效捕捉時間和空間相關性。然而，城市環境不斷演變，目前的模型評估通常僅限於交通場景，並使用主要僅在訓練期後幾週收集的資料來評估模型效能。這些模型的泛化能力在很大程度上仍未探索。為了解決此問題，我們提出一個時空分布外 (ST-OOD) 基準，其中包含六個城市場景：共享單車、311 服務、行人計數、交通速度、交通流量、叫車需求和共享單車，每個場景都有分佈內（同一年）和分佈外（次年）設定。我們廣泛評估最先進的時空模型，並發現它們在分佈外設定中的效能顯著下降，大多數模型的效能甚至比簡單的多層感知器 (MLP) 還要差。我們的研究結果表明，目前的領先方法傾向於過度依賴參數來過度擬合訓練資料，這可能會導致在分佈內資料上有良好的效能，但通常會導致泛化能力不佳。我們還研究了中斷是否可以減輕過度擬合的負面影響。我們的結果表明，輕微的中斷率可以顯著改善大多數資料集上的泛化效能，對分佈內效能的影響最小。然而，平衡分佈內和分佈外效能仍然是一個具有挑戰性的問題。我們希望所提出的基準將鼓勵對這個關鍵問題進行進一步的研究。

##### **TableRAG: Million-Token Table Understanding with Language Models**
2410.04739v1 by Si-An Chen, Lesly Miculicich, Julian Martin Eisenschlos, Zifeng Wang, Zilong Wang, Yanfei Chen, Yasuhisa Fujii, Hsuan-Tien Lin, Chen-Yu Lee, Tomas Pfister

Recent advancements in language models (LMs) have notably enhanced their
ability to reason with tabular data, primarily through program-aided mechanisms
that manipulate and analyze tables. However, these methods often require the
entire table as input, leading to scalability challenges due to the positional
bias or context length constraints. In response to these challenges, we
introduce TableRAG, a Retrieval-Augmented Generation (RAG) framework
specifically designed for LM-based table understanding. TableRAG leverages
query expansion combined with schema and cell retrieval to pinpoint crucial
information before providing it to the LMs. This enables more efficient data
encoding and precise retrieval, significantly reducing prompt lengths and
mitigating information loss. We have developed two new million-token benchmarks
from the Arcade and BIRD-SQL datasets to thoroughly evaluate TableRAG's
effectiveness at scale. Our results demonstrate that TableRAG's retrieval
design achieves the highest retrieval quality, leading to the new
state-of-the-art performance on large-scale table understanding.

摘要：語言模型 (LM) 的最新進展顯著提升了其處理表格資料的能力，主要是透過操作和分析表格的程式輔助機制。然而，這些方法通常需要整個表格作為輸入，由於位置偏差或內容長度限制，導致可擴充性挑戰。為了應對這些挑戰，我們引入了 TableRAG，一種專門為基於 LM 的表格理解而設計的檢索增強生成 (RAG) 框架。TableRAG 利用查詢擴充與架構和儲存格檢索相結合，在提供給 LM 之前精確找出關鍵資訊。這能更有效地編碼資料和精確檢索，大幅減少提示長度並減輕資訊遺失。我們從 Arcade 和 BIRD-SQL 資料集開發了兩個新的百萬代幣基準，以徹底評估 TableRAG 在大規模上的有效性。我們的結果證明，TableRAG 的檢索設計達到了最高的檢索品質，在大型表格理解上領先新的技術水準。

##### **TLDR: Token-Level Detective Reward Model for Large Vision Language Models**
2410.04734v1 by Deqing Fu, Tong Xiao, Rui Wang, Wang Zhu, Pengchuan Zhang, Guan Pang, Robin Jia, Lawrence Chen

Although reward models have been successful in improving multimodal large
language models, the reward models themselves remain brutal and contain minimal
information. Notably, existing reward models only mimic human annotations by
assigning only one binary feedback to any text, no matter how long the text is.
In the realm of multimodal language models, where models are required to
process both images and texts, a naive reward model may learn implicit biases
toward texts and become less grounded in images. In this paper, we propose a
$\textbf{T}$oken-$\textbf{L}$evel $\textbf{D}$etective $\textbf{R}$eward Model
($\textbf{TLDR}$) to provide fine-grained annotations to each text token. We
first introduce a perturbation-based method to generate synthetic hard
negatives and their token-level labels to train TLDR models. Then we show the
rich usefulness of TLDR models both in assisting off-the-shelf models to
self-correct their generations, and in serving as a hallucination evaluation
tool. Finally, we show that TLDR models can significantly speed up human
annotation by 3 times to acquire a broader range of high-quality vision
language data.

摘要：雖然獎勵模型在改善多模態大型語言模型方面取得成功，但獎勵模型本身仍然很殘酷且包含最少資訊。值得注意的是，現有的獎勵模型僅透過將一個二元回饋分配給任何文字來模仿人類註解，無論文字有多長。在多模態語言模型領域中，模型需要處理影像和文字，一個天真的獎勵模型可能會學習對文字的隱含偏見，且不太依賴於影像。在本文中，我們提出了一個 $\textbf{T}$oken-$\textbf{L}$evel $\textbf{D}$etective $\textbf{R}$eward Model（$\textbf{TLDR}$）來為每個文字代幣提供細緻的註解。我們首先介紹一個基於擾動的方法來生成合成難負例及其代幣級別標籤以訓練 TLDR 模型。然後，我們展示了 TLDR 模型的豐富實用性，既可以協助現成的模型自我修正其生成，又可以作為幻覺評估工具。最後，我們展示了 TLDR 模型可以將人類註解的速度顯著提高 3 倍，以獲取更廣泛的高品質視覺語言資料。

##### **Efficient transformer with reinforced position embedding for language models**
2410.04731v1 by Yen-Che Hsiao, Abhishek Dutta

In this paper, we propose an efficient transformer architecture that uses
reinforced positional embedding to obtain superior performance with half the
number of encoder decoder layers. We demonstrate that concatenating positional
encoding with trainable token embeddings, normalizing columns in the token
embedding matrix, and using the normalized token embedding matrix as the value
of the attention layer improve the training and validation loss and the
training time in an encoder-decoder Transformer model for a Portuguese-English
translation task with 10 epochs or 12 hours of training across 10 trials. Our
method, with roughly a threefold parameter reduction compared to the baseline
model, yields a mean training loss of 1.21, a mean validation loss of 1.51, and
an average training time of 1352.27 seconds per epoch, surpassing the baseline
model with the same embedding dimension that employs addition of positional
encoding and token embeddings, which achieves a mean training loss of 1.96, a
validation loss of 2.18, and an average training time of 4297.79 seconds per
epoch. Additionally, we evaluated our proposed architecture and the baseline
across 14 diverse translation datasets from TensorFlow. The results indicate
that our method consistently achieves lower or comparable training and
validation losses, suggesting enhanced learning efficiency.

摘要：<paragraph>在本文中，我們提出了一種高效的 Transformer 架構，它使用增強的位置嵌入，以使用編碼器解碼器層的一半來獲得更好的性能。我們證明了將位置編碼與可訓練的令牌嵌入串聯、對令牌嵌入矩陣中的列進行正規化以及使用正規化的令牌嵌入矩陣作為注意力層的值，可以改善編碼器-解碼器 Transformer 模型的訓練和驗證損失以及訓練時間，用於葡萄牙語-英語翻譯任務，在 10 次試驗中進行了 10 個時期或 12 小時的訓練。與基線模型相比，我們的模型將參數減少了大約三分之一，平均訓練損失為 1.21，平均驗證損失為 1.51，平均訓練時間為每個時期 1352.27 秒，超過了採用位置編碼和令牌嵌入相加的相同嵌入維度的基線模型，後者實現了 1.96 的平均訓練損失、2.18 的驗證損失以及每個時期 4297.79 秒的平均訓練時間。此外，我們在 TensorFlow 的 14 個不同的翻譯數據集中評估了我們提出的架構和基線。結果表明，我們的模型始終實現更低或相當的訓練和驗證損失，這表明增強的學習效率。</paragraph>

##### **Forgetting Curve: A Reliable Method for Evaluating Memorization Capability for Long-context Models**
2410.04727v1 by Xinyu Liu, Runsong Zhao, Pengcheng Huang, Chunyang Xiao, Bei Li, Jingang Wang, Tong Xiao, Jingbo Zhu

Numerous recent works target to extend effective context length for language
models and various methods, tasks and benchmarks exist to measure model's
effective memorization length. However, through thorough investigations, we
find limitations for currently existing evaluations on model's memorization
capability. We provide an extensive survey for limitations in this work and
propose a new method called forgetting curve to measure the memorization
capability of long-context models. We show that forgetting curve has the
advantage of being robust to the tested corpus and the experimental settings,
of not relying on prompts and can be applied to any model size.
  We apply our forgetting curve to a large variety of models involving both
transformer and RNN/SSM based architectures. Our measurement provides empirical
evidence for the effectiveness of transformer extension techniques while raises
questions for the effective length of RNN/SSM based models. We also examine the
difference between our measurement and existing benchmarks as well as popular
metrics for various models. Our code and results can be found at
https://github.com/1azybug/ForgettingCurve.

摘要：許多近期作品目標擴展語言模型的有效內容長度，並且有各種方法、任務和基準來衡量模型的有效記憶長度。然而，經過徹底調查，我們發現目前現有的評估對於模型的記憶能力有其限制。我們在這項工作中提供了限制的廣泛調查，並提出了一種稱為遺忘曲線的新方法來衡量長內容模型的記憶能力。我們展示了遺忘曲線具有對測試語料和實驗設定穩健、不依賴提示，且可應用於任何模型大小的優點。
  我們將我們的遺忘曲線應用於各種模型，包括Transformer和基於 RNN/SSM 的架構。我們的測量提供了Transformer擴充技術有效性的實證證據，同時也對基於 RNN/SSM 的模型的有效長度提出疑問。我們還檢查了我們的測量與現有基準以及各種模型的熱門指標之間的差異。我們的程式碼和結果可以在 https://github.com/1azybug/ForgettingCurve 中找到。

##### **ProtoNAM: Prototypical Neural Additive Models for Interpretable Deep Tabular Learning**
2410.04723v1 by Guangzhi Xiong, Sanchit Sinha, Aidong Zhang

Generalized additive models (GAMs) have long been a powerful white-box tool
for the intelligible analysis of tabular data, revealing the influence of each
feature on the model predictions. Despite the success of neural networks (NNs)
in various domains, their application as NN-based GAMs in tabular data analysis
remains suboptimal compared to tree-based ones, and the opacity of encoders in
NN-GAMs also prevents users from understanding how networks learn the
functions. In this work, we propose a new deep tabular learning method, termed
Prototypical Neural Additive Model (ProtoNAM), which introduces prototypes into
neural networks in the framework of GAMs. With the introduced prototype-based
feature activation, ProtoNAM can flexibly model the irregular mapping from
tabular features to the outputs while maintaining the explainability of the
final prediction. We also propose a gradient-boosting inspired hierarchical
shape function modeling method, facilitating the discovery of complex feature
patterns and bringing transparency into the learning process of each network
layer. Our empirical evaluations demonstrate that ProtoNAM outperforms all
existing NN-based GAMs, while providing additional insights into the shape
function learned for each feature. The source code of ProtoNAM is available at
\url{https://github.com/Teddy-XiongGZ/ProtoNAM}.

摘要：廣義加法模型 (GAM) 長期以來一直是表格資料可理解分析的強大白盒工具，揭示每個特徵對模型預測的影響。儘管神經網路 (NN) 在各個領域都獲得成功，但其作為基於 NN 的 GAM 在表格資料分析中的應用與基於樹的 GAM 相比仍然次佳，而且 NN-GAM 中編碼器的模糊性也阻礙使用者了解網路如何學習函數。在這項工作中，我們提出了一種新的深度表格學習方法，稱為原型神經加法模型 (ProtoNAM)，它在 GAM 的架構中將原型引入神經網路。透過引入基於原型的特徵啟動，ProtoNAM 可以靈活地建模從表格特徵到輸出的不規則對應，同時保持最終預測的可解釋性。我們還提出了一種受梯度提升啟發的分層形狀函數建模方法，促進複雜特徵模式的發現，並為每個網路層的學習過程帶來透明度。我們的實證評估表明，ProtoNAM 優於所有現有的基於 NN 的 GAM，同時提供對每個特徵學習的形狀函數的額外見解。ProtoNAM 的原始程式碼可以在 \url{https://github.com/Teddy-XiongGZ/ProtoNAM} 取得。

##### **$\textbf{Only-IF}$:Revealing the Decisive Effect of Instruction Diversity on Generalization**
2410.04717v1 by Dylan Zhang, Justin Wang, Francois Charton

Understanding and accurately following instructions is critical for large
language models (LLMs) to be effective across diverse tasks. In this work, we
rigorously examine the key factors that enable models to generalize to unseen
instructions, providing insights to guide the collection of data for
instruction-tuning. Through controlled experiments, inspired by the
Turing-complete Markov algorithm, we demonstrate that such generalization
$\textbf{only emerges}$ when training data is diversified enough across
semantic domains. Our findings also reveal that merely diversifying within
limited domains fails to ensure robust generalization. In contrast,
cross-domain data diversification, even under constrained data budgets,
significantly enhances a model's adaptability. We further extend our analysis
to real-world scenarios, including fine-tuning of
$\textit{$\textbf{specialist}$}$ and $\textit{$\textbf{generalist}$}$ models.
In both cases, we demonstrate that 1) better performance can be achieved by
increasing the diversity of an established dataset while keeping the data size
constant, and 2) when scaling up the data, diversifying the semantics of
instructions is more effective than simply increasing the quantity of similar
data. Our research provides important insights for dataset collation,
particularly when optimizing model performance by expanding training data for
both specialist and generalist scenarios. We show that careful consideration of
data diversification is key: training specialist models with data extending
beyond their core domain leads to significant performance improvements, while
generalist models benefit from diverse data mixtures that enhance their overall
instruction-following capabilities across a wide range of applications. Our
results highlight the critical role of strategic diversification and offer
clear guidelines for improving data quality.

摘要：<paragraph>對於大型語言模型 (LLM) 來說，理解並準確遵循指示對於在各種任務中發揮作用至關重要。在這項工作中，我們嚴格審查了使模型能夠概括到未見指示的關鍵因素，並提供見解以指導指示調整數據的收集。通過受圖靈完備馬可夫演算法啟發的受控實驗，我們證明了這種概括僅當訓練數據在語義領域中足夠多樣化時才會出現。我們的發現還表明，僅在有限的領域內進行多樣化不足以確保穩健的概括。相比之下，即使在受限的數據預算下，跨領域數據多樣化也會顯著增強模型的適應性。我們進一步將我們的分析擴展到現實世界場景，包括微調專家和通才模型。在這兩種情況下，我們證明了 1) 可以在保持數據大小不變的同時通過增加既定數據集的多樣性來實現更好的性能，以及 2) 在擴展數據時，多樣化指令的語義比簡單地增加相似數據的數量更有效。我們的研究為數據集整理提供了重要的見解，特別是在通過擴展專家和通才場景的訓練數據來優化模型性能時。我們表明，仔細考慮數據多樣化是關鍵：使用超出其核心領域的數據訓練專家模型會導致性能顯著提升，而通才模型受益於多樣化的數據混合，這些混合增強了它們在廣泛應用中的整體指令遵循能力。我們的結果突出了策略多樣化的關鍵作用，並為提高數據質量提供了明確的指導方針。</paragraph>

##### **Rule-based Data Selection for Large Language Models**
2410.04715v1 by Xiaomin Li, Mingye Gao, Zhiwei Zhang, Chang Yue, Hong Hu

The quality of training data significantly impacts the performance of large
language models (LLMs). There are increasing studies using LLMs to rate and
select data based on several human-crafted metrics (rules). However, these
conventional rule-based approaches often depend too heavily on human
heuristics, lack effective metrics for assessing rules, and exhibit limited
adaptability to new tasks. In our study, we introduce an innovative rule-based
framework that utilizes the orthogonality of score vectors associated with
rules as a novel metric for rule evaluations. Our approach includes an
automated pipeline that first uses LLMs to generate a diverse set of rules,
encompassing various rating dimensions to evaluate data quality. Then it rates
a batch of data based on these rules and uses the determinantal point process
(DPP) from random matrix theory to select the most orthogonal score vectors,
thereby identifying a set of independent rules. These rules are subsequently
used to evaluate all data, selecting samples with the highest average scores
for downstream tasks such as LLM training. We verify the effectiveness of our
method through two experimental setups: 1) comparisons with ground truth
ratings and 2) benchmarking LLMs trained with the chosen data. Our
comprehensive experiments cover a range of scenarios, including general
pre-training and domain-specific fine-tuning in areas such as IMDB, Medical,
Math, and Code. The outcomes demonstrate that our DPP-based rule rating method
consistently outperforms other approaches, including rule-free rating, uniform
sampling, importance resampling, and QuRating, in terms of both rating
precision and model performance.

摘要：訓練資料的品質會顯著影響大型語言模型 (LLM) 的效能。有愈來愈多研究使用 LLM 來評分並根據多項人為建立的指標 (規則) 選擇資料。然而，這些傳統的基於規則的方法通常過度依賴人類的啟發法，缺乏評估規則的有效指標，且在適應新任務方面展現出有限的靈活性。在我們的研究中，我們引進一個創新的基於規則的架構，它利用與規則相關聯的分數向量的正交性作為規則評估的新指標。我們的做法包括一個自動化流程，該流程首先使用 LLM 產生一組多樣化的規則，涵蓋各種評分面向以評估資料品質。接著，它根據這些規則評分一批資料，並使用隨機矩陣理論中的行列式點過程 (DPP) 來選出最正交的分數向量，從而找出獨立規則的集合。這些規則隨後用於評估所有資料，針對下游任務（例如 LLM 訓練）選出平均分數最高的樣本。我們透過兩個實驗設定驗證我們方法的有效性：1) 與真實評分進行比較，以及 2) 對使用所選資料訓練的 LLM 進行基準測試。我們全面的實驗涵蓋一系列情境，包括在 IMDB、醫學、數學和程式碼等領域的一般預訓練和特定領域的微調。結果顯示，我們的基於 DPP 的規則評分方法在評分精準度和模型效能方面始終優於其他方法，包括無規則評分、均勻抽樣、重要性再抽樣和 QuRating。

##### **Tight Stability, Convergence, and Robustness Bounds for Predictive Coding Networks**
2410.04708v1 by Ankur Mali, Tommaso Salvatori, Alexander Ororbia

Energy-based learning algorithms, such as predictive coding (PC), have
garnered significant attention in the machine learning community due to their
theoretical properties, such as local operations and biologically plausible
mechanisms for error correction. In this work, we rigorously analyze the
stability, robustness, and convergence of PC through the lens of dynamical
systems theory. We show that, first, PC is Lyapunov stable under mild
assumptions on its loss and residual energy functions, which implies intrinsic
robustness to small random perturbations due to its well-defined
energy-minimizing dynamics. Second, we formally establish that the PC updates
approximate quasi-Newton methods by incorporating higher-order curvature
information, which makes them more stable and able to converge with fewer
iterations compared to models trained via backpropagation (BP). Furthermore,
using this dynamical framework, we provide new theoretical bounds on the
similarity between PC and other algorithms, i.e., BP and target propagation
(TP), by precisely characterizing the role of higher-order derivatives. These
bounds, derived through detailed analysis of the Hessian structures, show that
PC is significantly closer to quasi-Newton updates than TP, providing a deeper
understanding of the stability and efficiency of PC compared to conventional
learning methods.

摘要：基於能量的學習演算法，例如預測編碼 (PC)，由於其理論性質（例如局部運算和生物學上合理的誤差修正機制），在機器學習社群中獲得顯著關注。在這項工作中，我們透過動態系統理論的觀點，嚴謹分析 PC 的穩定性、穩健性和收斂性。我們首先展示，在對其損失和殘差能量函數的溫和假設下，PC 是 Lyapunov 穩定的，這表示由於其定義良好的能量最小化動態，而具有對小型隨機擾動的內在穩健性。其次，我們正式建立 PC 更新近似準牛頓法，方法是納入高階曲率資訊，這使得它們更穩定，並且能夠與透過反向傳播 (BP) 訓練的模型相比，以更少的反覆運算來收斂。此外，使用這個動態框架，我們提供了 PC 與其他演算法（即 BP 和目標傳播 (TP)）之間相似性的新理論界線，方法是精確描述高階導數的角色。這些界線是透過對海森結構的詳細分析所衍生，顯示 PC 明顯比 TP 更接近準牛頓更新，這提供了對 PC 的穩定性和效率，與傳統學習方法相比，有更深入的了解。

##### **Learning How Hard to Think: Input-Adaptive Allocation of LM Computation**
2410.04707v1 by Mehul Damani, Idan Shenfeld, Andi Peng, Andreea Bobu, Jacob Andreas

Computationally intensive decoding procedures--including search, reranking,
and self-critique--can improve the quality of language model (LM) outputs in
problems spanning code generation, numerical reasoning, and dialog. Existing
work typically applies the same decoding procedure for every input to an LM.
But not all inputs require the same amount of computation to process. Can we
allocate decoding computation adaptively, using more resources to answer
questions whose answers will be harder to compute? We present an approach that
predicts the distribution of rewards given an input and computation budget,
then allocates additional computation to inputs for which it is predicted to be
most useful. We apply this approach in two decoding procedures: first, an
adaptive best-of-k procedure that dynamically selects the number of samples to
generate as input to a reranker; second, a routing procedure that dynamically
responds to a query using a decoding procedure that is expensive but accurate,
or one that is cheaper but less capable. Across a suite of programming,
mathematics, and dialog tasks, we show that accurate computation-allocation
procedures can be learned, and reduce computation by up to 50% at no cost to
response quality, or improve quality by up to 10% at a fixed computational
budget.

摘要：計算密集型解碼程序（包括搜尋、重新排序和自我批評）可以改善語言模型 (LM) 輸出在跨越程式碼產生、數值推理和對話問題中的品質。現有的工作通常對 LM 的每個輸入套用相同的解碼程序。但並非所有輸入都需要相同的計算量來處理。我們能適應性地分配解碼計算嗎？利用更多資源來回答答案較難計算的問題？我們提出了一種方法，它會預測在給定輸入和計算預算下的獎勵分配，然後將額外的計算分配給預測對其最有用的輸入。我們在兩個解碼程序中套用此方法：首先，一個適應性最佳 k 程序，它會動態選擇要產生作為重新排序器輸入的範例數；其次，一個路由程序，它會使用昂貴但精確的解碼程序或較便宜但功能較少的解碼程序，來動態回應查詢。在程式設計、數學和對話任務套件中，我們展示了精確的計算分配程序是可以學習的，而且可以在不損失回應品質的情況下將計算減少多達 50%，或是在固定的計算預算下將品質提升多達 10%。

##### **Modeling and Estimation of Vocal Tract and Glottal Source Parameters Using ARMAX-LF Model**
2410.04704v1 by Kai Lia, Masato Akagia, Yongwei Lib, Masashi Unokia

Modeling and estimation of the vocal tract and glottal source parameters of
vowels from raw speech can be typically done by using the Auto-Regressive with
eXogenous input (ARX) model and Liljencrants-Fant (LF) model with an
iteration-based estimation approach. However, the all-pole autoregressive model
in the modeling of vocal tract filters cannot provide the locations of
anti-formants (zeros), which increases the estimation errors in certain classes
of speech sounds, such as nasal, fricative, and stop consonants. In this paper,
we propose the Auto-Regressive Moving Average eXogenous with LF (ARMAX-LF)
model to extend the ARX-LF model to a wider variety of speech sounds, including
vowels and nasalized consonants. The LF model represents the glottal source
derivative as a parametrized time-domain model, and the ARMAX model represents
the vocal tract as a pole-zero filter with an additional exogenous LF
excitation as input. To estimate multiple parameters with fewer errors, we
first utilize the powerful nonlinear fitting ability of deep neural networks
(DNNs) to build a mapping from extracted glottal source derivatives or speech
waveforms to corresponding LF parameters. Then, glottal source and vocal tract
parameters can be estimated with fewer estimation errors and without any
iterations as in the analysis-by-synthesis strategy. Experimental results with
synthesized speech using the linear source-filter model, synthesized speech
using the physical model, and real speech signals showed that the proposed
ARMAX-LF model with a DNN-based estimation method can estimate the parameters
of both vowels and nasalized sounds with fewer errors and estimation time.

摘要：<paragraph>從原始語音建模並估計聲道和聲門源參數通常可以透過使用具有外生輸入的自動迴歸 (ARX) 模型和基於反覆運算估計方法的 Liljencrants-Fant (LF) 模型來完成。然而，聲道濾波器建模中的全極自動迴歸模型無法提供反共振點 (零點) 的位置，這會增加某些類別的語音音素（例如鼻音、擦音和塞音）的估計誤差。在本文中，我們提出自動迴歸移動平均外生 LF (ARMAX-LF) 模型，將 ARX-LF 模型擴展到更多類別的語音音素，包括元音和鼻化輔音。LF 模型將聲門源導數表示為參數化的時域模型，而 ARMAX 模型將聲道表示為具有額外外生 LF 激勵作為輸入的極零濾波器。為了以較少的誤差估計多個參數，我們首先利用深度神經網路 (DNN) 強大的非線性擬合能力，從提取的聲門源導數或語音波形建立到對應 LF 參數的對應。然後，聲門源和聲道參數可以用較少的估計誤差和無需任何反覆運算（就像在分析合成策略中一樣）來估計。使用線性源濾波器合成的語音、使用物理模型合成的語音和真實語音訊號的實驗結果顯示，所提出的 ARMAX-LF 模型搭配基於 DNN 的估計方法，可以以較少的誤差和估計時間估計元音和鼻音的參數。</paragraph>

##### **The LLM Effect: Are Humans Truly Using LLMs, or Are They Being Influenced By Them Instead?**
2410.04699v1 by Alexander S. Choi, Syeda Sabrina Akter, JP Singh, Antonios Anastasopoulos

Large Language Models (LLMs) have shown capabilities close to human
performance in various analytical tasks, leading researchers to use them for
time and labor-intensive analyses. However, their capability to handle highly
specialized and open-ended tasks in domains like policy studies remains in
question. This paper investigates the efficiency and accuracy of LLMs in
specialized tasks through a structured user study focusing on Human-LLM
partnership. The study, conducted in two stages-Topic Discovery and Topic
Assignment-integrates LLMs with expert annotators to observe the impact of LLM
suggestions on what is usually human-only analysis. Results indicate that
LLM-generated topic lists have significant overlap with human generated topic
lists, with minor hiccups in missing document-specific topics. However, LLM
suggestions may significantly improve task completion speed, but at the same
time introduce anchoring bias, potentially affecting the depth and nuance of
the analysis, raising a critical question about the trade-off between increased
efficiency and the risk of biased analysis.

摘要：大型語言模型 (LLM) 在各種分析任務中展現出接近人類表現的能力，促使研究人員將其用於耗時且費力的分析。然而，它們在處理政策研究等領域中高度專業化且開放式任務的能力仍有待質疑。本文透過專注於人機合作的結構化使用者研究，探討 LLM 在專業任務中的效率和準確性。這項研究分為兩個階段進行，主題發現和主題分配，將 LLM 與專家註解人員整合，觀察 LLM 建議對通常僅限人類進行的分析的影響。結果顯示，LLM 生成的主題清單與人類生成的主題清單有顯著重疊，僅在遺漏特定於文件的主题時出現小問題。然而，LLM 建議可能會顯著提高任務完成速度，但同時也會引入錨定偏誤，可能影響分析的深度和細微差別，引發了一個關於提高效率與有偏分析風險之間權衡的關鍵問題。

##### **MathHay: An Automated Benchmark for Long-Context Mathematical Reasoning in LLMs**
2410.04698v1 by Lei Wang, Shan Dong, Yuhui Xu, Hanze Dong, Yalu Wang, Amrita Saha, Ee-Peng Lim, Caiming Xiong, Doyen Sahoo

Recent large language models (LLMs) have demonstrated versatile capabilities
in long-context scenarios. Although some recent benchmarks have been developed
to evaluate the long-context capabilities of LLMs, there is a lack of
benchmarks evaluating the mathematical reasoning abilities of LLMs over long
contexts, which is crucial for LLMs' application in real-world scenarios. In
this paper, we introduce MathHay, an automated benchmark designed to assess the
long-context mathematical reasoning capabilities of LLMs. Unlike previous
benchmarks like Needle in a Haystack, which focus primarily on information
retrieval within long texts, MathHay demands models with both
information-seeking and complex mathematical reasoning abilities. We conduct
extensive experiments on MathHay to assess the long-context mathematical
reasoning abilities of eight top-performing LLMs. Even the best-performing
model, Gemini-1.5-Pro-002, still struggles with mathematical reasoning over
long contexts, achieving only 51.26% accuracy at 128K tokens. This highlights
the significant room for improvement on the MathHay benchmark.

摘要：最近的大型语言模型 (LLM) 已在长文本情境中展示出多功能的能力。虽然最近已开发出一些基准来评估 LLM 的长文本能力，但缺乏评估 LLM 在长文本中数学推理能力的基准，这对 LLM 在现实世界情境中的应用至关重要。在本文中，我们介绍了 MathHay，一个自动基准，旨在评估 LLM 的长文本数学推理能力。与主要专注于长文本中信息检索的 Needle in a Haystack 等先前基准不同，MathHay 要求模型同时具有信息搜索和复杂的数学推理能力。我们对 MathHay 进行了广泛的实验，以评估八种性能最佳的 LLM 的长文本数学推理能力。即使是性能最佳的模型 Gemini-1.5-Pro-002，在长文本中进行数学推理时仍然困难，在 128K 个标记中仅达到 51.26% 的准确率。这突显了在 MathHay 基准上改进的巨大空间。

##### **Deeper Insights Without Updates: The Power of In-Context Learning Over Fine-Tuning**
2410.04691v1 by Qingyu Yin, Xuzheng He, Luoao Deng, Chak Tou Leong, Fan Wang, Yanzhao Yan, Xiaoyu Shen, Qiang Zhang

Fine-tuning and in-context learning (ICL) are two prevalent methods in
imbuing large language models with task-specific knowledge. It is commonly
believed that fine-tuning can surpass ICL given sufficient training samples as
it allows the model to adjust its internal parameters based on the data.
However, this paper presents a counterintuitive finding: For tasks with
implicit patterns, ICL captures these patterns significantly better than
fine-tuning. We developed several datasets featuring implicit patterns, such as
sequences determining answers through parity or identifying reducible terms in
calculations. We then evaluated the models' understanding of these patterns
under both fine-tuning and ICL across models ranging from 0.5B to 7B
parameters. The results indicate that models employing ICL can quickly grasp
deep patterns and significantly improve accuracy. In contrast, fine-tuning,
despite utilizing thousands of times more training samples than ICL, achieved
only limited improvements. We also proposed circuit shift theory from a
mechanistic interpretability's view to explain why ICL wins.

摘要：微调和情境学习 (ICL) 是两种普遍用于赋予大型语言模型任务特定知识的方法。人们普遍认为，微调可以通过足够的训练样本超越 ICL，因为它允许模型根据数据调整其内部参数。然而，本文提出了一个反直觉的发现：对于具有隐式模式的任务，ICL 捕捉这些模式明显优于微调。我们开发了几个具有隐式模式的数据集，例如通过奇偶性确定答案或识别计算中可约项的序列。然后，我们评估了模型在从 0.5B 到 7B 参数的各种模型中对这些模式的理解，包括微调和 ICL。结果表明，采用 ICL 的模型可以快速掌握深度模式并显着提高准确性。相比之下，微调尽管使用了比 ICL 多数千倍的训练样本，但仅取得了有限的改进。我们还从机制可解释性的角度提出了电路转换理论，以解释 ICL 获胜的原因。

##### **Towards Measuring Goal-Directedness in AI Systems**
2410.04683v1 by Dylan Xu, Juan-Pablo Rivera

Recent advances in deep learning have brought attention to the possibility of
creating advanced, general AI systems that outperform humans across many tasks.
However, if these systems pursue unintended goals, there could be catastrophic
consequences. A key prerequisite for AI systems pursuing unintended goals is
whether they will behave in a coherent and goal-directed manner in the first
place, optimizing for some unknown goal; there exists significant research
trying to evaluate systems for said behaviors. However, the most rigorous
definitions of goal-directedness we currently have are difficult to compute in
real-world settings. Drawing upon this previous literature, we explore policy
goal-directedness within reinforcement learning (RL) environments. In our
findings, we propose a different family of definitions of the goal-directedness
of a policy that analyze whether it is well-modeled as near-optimal for many
(sparse) reward functions. We operationalize this preliminary definition of
goal-directedness and test it in toy Markov decision process (MDP)
environments. Furthermore, we explore how goal-directedness could be measured
in frontier large-language models (LLMs). Our contribution is a definition of
goal-directedness that is simpler and more easily computable in order to
approach the question of whether AI systems could pursue dangerous goals. We
recommend further exploration of measuring coherence and goal-directedness,
based on our findings.

摘要：深度學習的最新進展引起了人們對創造先進、通用的 AI 系統的可能性，這些系統在許多任務上都優於人類。
然而，如果這些系統追求意外的目標，可能會造成災難性的後果。AI 系統追求意外目標的一個關鍵先決條件是它們是否會首先以連貫且目標導向的方式行事，針對一些未知目標進行優化；存在大量研究嘗試評估系統的上述行為。然而，我們目前對目標導向性最嚴謹的定義難以在現實世界環境中計算。借鑒先前的文獻，我們探討了強化學習 (RL) 環境中的策略目標導向性。在我們的研究結果中，我們提出了策略目標導向性的不同定義系列，分析了它是否可以很好地建模為許多（稀疏）獎勵函數的近乎最佳值。我們將目標導向性的這個初步定義付諸實踐，並在玩具馬可夫決策過程 (MDP) 環境中對其進行了測試。此外，我們探討了如何在前沿大型語言模型 (LLM) 中衡量目標導向性。我們的貢獻是目標導向性的定義，它更簡單、更容易計算，以便解決 AI 系統是否會追求危險目標的問題。我們建議根據我們的研究結果進一步探索衡量連貫性和目標導向性。

##### **Adversarial Multi-Agent Evaluation of Large Language Models through Iterative Debates**
2410.04663v1 by Chaithanya Bandi, Hari Bandi, Abir Harrasse

This paper explores optimal architectures for evaluating the outputs of large
language models (LLMs) using LLMs themselves. We propose a novel framework that
interprets LLMs as advocates within an ensemble of interacting agents, allowing
them to defend their answers and reach conclusions through a judge and jury
system. This approach offers a more dynamic and comprehensive evaluation
process compared to traditional human-based assessments or automated metrics.
We discuss the motivation behind this framework, its key components, and
comparative advantages. We also present a probabilistic model to evaluate the
error reduction achieved by iterative advocate systems. Finally, we outline
experiments to validate the effectiveness of multi-advocate architectures and
discuss future research directions.

摘要：這篇論文探討使用大型語言模型 (LLM) 本身來評估大型語言模型 (LLM) 輸出的最佳架構。我們提出一個新的框架，將 LLM 解釋為一群互動代理中的倡導者，讓它們為自己的答案辯護並透過法官和陪審團制度達成結論。與傳統的人類評估或自動化指標相比，這種方法提供了一個更動態且全面的評估過程。我們討論這個框架背後的動機、它的關鍵組成部分和比較優勢。我們也提出一個機率模型來評估迭代倡導系統達成的錯誤減少。最後，我們概述實驗以驗證多倡導架構的有效性，並討論未來的研究方向。

##### **Knowledge Graph Based Agent for Complex, Knowledge-Intensive QA in Medicine**
2410.04660v1 by Xiaorui Su, Yibo Wang, Shanghua Gao, Xiaolong Liu, Valentina Giunchiglia, Djork-Arné Clevert, Marinka Zitnik

Biomedical knowledge is uniquely complex and structured, requiring distinct
reasoning strategies compared to other scientific disciplines like physics or
chemistry. Biomedical scientists do not rely on a single approach to reasoning;
instead, they use various strategies, including rule-based, prototype-based,
and case-based reasoning. This diversity calls for flexible approaches that
accommodate multiple reasoning strategies while leveraging in-domain knowledge.
We introduce KGARevion, a knowledge graph (KG) based agent designed to address
the complexity of knowledge-intensive medical queries. Upon receiving a query,
KGARevion generates relevant triplets by using the knowledge base of the LLM.
These triplets are then verified against a grounded KG to filter out erroneous
information and ensure that only accurate, relevant data contribute to the
final answer. Unlike RAG-based models, this multi-step process ensures
robustness in reasoning while adapting to different models of medical
reasoning. Evaluations on four gold-standard medical QA datasets show that
KGARevion improves accuracy by over 5.2%, outperforming 15 models in handling
complex medical questions. To test its capabilities, we curated three new
medical QA datasets with varying levels of semantic complexity, where KGARevion
achieved a 10.4% improvement in accuracy.

摘要：生物医学知識獨特地複雜且結構化，需要與其他科學領域（如物理或化學）不同的推理策略。生物醫學科學家不依賴單一的推理方法；相反，他們使用各種策略，包括基於規則、基於原型和基於案例的推理。這種多樣性需要靈活的方法，同時利用領域知識來適應多種推理策略。我們介紹了 KGARevion，這是一個基於知識圖譜 (KG) 的代理，旨在解決知識密集型醫療查詢的複雜性。在收到查詢後，KGARevion 使用 LLM 的知識庫生成相關的三元組。然後將這些三元組與基礎 KG 進行驗證，以過濾掉錯誤信息並確保只有準確、相關的數據有助於最終答案。與基於 RAG 的模型不同，這種多步驟過程確保了推理的穩健性，同時適應不同的醫療推理模型。對四個黃金標準醫療 QA 數據集的評估表明，KGARevion 將準確率提高了 5.2%，在處理複雜的醫療問題方面優於 15 個模型。為了測試其能力，我們策劃了三個新的醫療 QA 數據集，具有不同的語義複雜性，其中 KGARevion 在準確率上提高了 10.4%。

