{"2502.15218": {"publish_time": "2025-02-21", "title": "ESPnet-SpeechLM: An Open Speech Language Model Toolkit", "paper_summary": "We present ESPnet-SpeechLM, an open toolkit designed to democratize the\ndevelopment of speech language models (SpeechLMs) and voice-driven agentic\napplications. The toolkit standardizes speech processing tasks by framing them\nas universal sequential modeling problems, encompassing a cohesive workflow of\ndata preprocessing, pre-training, inference, and task evaluation. With\nESPnet-SpeechLM, users can easily define task templates and configure key\nsettings, enabling seamless and streamlined SpeechLM development. The toolkit\nensures flexibility, efficiency, and scalability by offering highly\nconfigurable modules for every stage of the workflow. To illustrate its\ncapabilities, we provide multiple use cases demonstrating how competitive\nSpeechLMs can be constructed with ESPnet-SpeechLM, including a 1.7B-parameter\nmodel pre-trained on both text and speech tasks, across diverse benchmarks. The\ntoolkit and its recipes are fully transparent and reproducible at:\nhttps://github.com/espnet/espnet/tree/speechlm.", "paper_summary_zh": "\u6211\u5011\u63a8\u51fa ESPnet-SpeechLM\uff0c\u9019\u662f\u4e00\u500b\u958b\u653e\u7684\u5de5\u5177\u5305\uff0c\u65e8\u5728\u6c11\u4e3b\u5316\u8a9e\u97f3\u8a9e\u8a00\u6a21\u578b (SpeechLM) \u548c\u8a9e\u97f3\u9a45\u52d5\u7684\u4ee3\u7406\u61c9\u7528\u7a0b\u5f0f\u7684\u958b\u767c\u3002\u6b64\u5de5\u5177\u5305\u900f\u904e\u5c07\u8a9e\u97f3\u8655\u7406\u4efb\u52d9\u6a19\u6e96\u5316\uff0c\u4e26\u5c07\u5b83\u5011\u8a2d\u5b9a\u70ba\u901a\u7528\u7684\u5e8f\u5217\u5efa\u6a21\u554f\u984c\uff0c\u5305\u542b\u8cc7\u6599\u524d\u8655\u7406\u3001\u9810\u8a13\u7df4\u3001\u63a8\u8ad6\u548c\u4efb\u52d9\u8a55\u4f30\u7684\u5167\u805a\u5de5\u4f5c\u6d41\u7a0b\u3002\u6709\u4e86 ESPnet-SpeechLM\uff0c\u4f7f\u7528\u8005\u53ef\u4ee5\u8f15\u9b06\u5b9a\u7fa9\u4efb\u52d9\u7bc4\u672c\u548c\u8a2d\u5b9a\u4e3b\u8981\u8a2d\u5b9a\uff0c\u8b93 SpeechLM \u958b\u767c\u8b8a\u5f97\u7121\u7e2b\u4e14\u7c21\u5316\u3002\u6b64\u5de5\u5177\u5305\u900f\u904e\u70ba\u5de5\u4f5c\u6d41\u7a0b\u7684\u6bcf\u500b\u968e\u6bb5\u63d0\u4f9b\u9ad8\u5ea6\u53ef\u8a2d\u5b9a\u7684\u6a21\u7d44\uff0c\u78ba\u4fdd\u9748\u6d3b\u6027\u3001\u6548\u7387\u548c\u53ef\u64f4\u5145\u6027\u3002\u70ba\u4e86\u8aaa\u660e\u5176\u529f\u80fd\uff0c\u6211\u5011\u63d0\u4f9b\u4e86\u591a\u500b\u4f7f\u7528\u6848\u4f8b\uff0c\u5c55\u793a\u5982\u4f55\u4f7f\u7528 ESPnet-SpeechLM \u5efa\u69cb\u5177\u7af6\u722d\u529b\u7684 SpeechLM\uff0c\u5305\u62ec\u5728\u5404\u7a2e\u57fa\u6e96\u4e0a\u9810\u5148\u8a13\u7df4\u7684 1.7B \u53c3\u6578\u6a21\u578b\uff0c\u6db5\u84cb\u6587\u5b57\u548c\u8a9e\u97f3\u4efb\u52d9\u3002\u6b64\u5de5\u5177\u5305\u53ca\u5176\u7bc4\u4f8b\u5728 https://github.com/espnet/espnet/tree/speechlm \u5b8c\u5168\u900f\u660e\u4e14\u53ef\u91cd\u88fd\u3002", "author": "Jinchuan Tian et.al.", "authors": "Jinchuan Tian, Jiatong Shi, William Chen, Siddhant Arora, Yoshiki Masuyama, Takashi Maekaku, Yihan Wu, Junyi Peng, Shikhar Bharadwaj, Yiwen Zhao, Samuele Cornell, Yifan Peng, Xiang Yue, Chao-Han Huck Yang, Graham Neubig, Shinji Watanabe", "id": "2502.15218v1", "paper_url": "http://arxiv.org/abs/2502.15218v1", "repo": "null"}}