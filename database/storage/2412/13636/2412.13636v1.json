{"2412.13636": {"publish_time": "2024-12-18", "title": "Consistency of Compositional Generalization across Multiple Levels", "paper_summary": "Compositional generalization is the capability of a model to understand novel\ncompositions composed of seen concepts. There are multiple levels of novel\ncompositions including phrase-phrase level, phrase-word level, and word-word\nlevel. Existing methods achieve promising compositional generalization, but the\nconsistency of compositional generalization across multiple levels of novel\ncompositions remains unexplored. The consistency refers to that a model should\ngeneralize to a phrase-phrase level novel composition, and\nphrase-word/word-word level novel compositions that can be derived from it\nsimultaneously. In this paper, we propose a meta-learning based framework, for\nachieving consistent compositional generalization across multiple levels. The\nbasic idea is to progressively learn compositions from simple to complex for\nconsistency. Specifically, we divide the original training set into multiple\nvalidation sets based on compositional complexity, and introduce multiple\nmeta-weight-nets to generate sample weights for samples in different validation\nsets. To fit the validation sets in order of increasing compositional\ncomplexity, we optimize the parameters of each meta-weight-net independently\nand sequentially in a multilevel optimization manner. We build a GQA-CCG\ndataset to quantitatively evaluate the consistency. Experimental results on\nvisual question answering and temporal video grounding, demonstrate the\neffectiveness of the proposed framework. We release GQA-CCG at\nhttps://github.com/NeverMoreLCH/CCG.", "paper_summary_zh": "\u7d44\u5408\u6cdb\u5316\u662f\u6307\u6a21\u578b\u7406\u89e3\u7531\u5df2\u898b\u6982\u5ff5\u7d44\u6210\u7684\u5275\u65b0\u7d44\u5408\u7684\u80fd\u529b\u3002\u5275\u65b0\u7d44\u5408\u6709\u591a\u500b\u5c64\u6b21\uff0c\u5305\u62ec\u7247\u8a9e-\u7247\u8a9e\u5c64\u6b21\u3001\u7247\u8a9e-\u8a5e\u5f59\u5c64\u6b21\u548c\u8a5e\u5f59-\u8a5e\u5f59\u5c64\u6b21\u3002\u73fe\u6709\u65b9\u6cd5\u5be6\u73fe\u4e86\u6709\u524d\u666f\u7684\u7d44\u5408\u6cdb\u5316\uff0c\u4f46\u7d44\u5408\u6cdb\u5316\u5728\u591a\u500b\u5275\u65b0\u7d44\u5408\u5c64\u6b21\u4e2d\u7684\u4e00\u81f4\u6027\u4ecd\u672a\u63a2\u7d22\u3002\u4e00\u81f4\u6027\u662f\u6307\u6a21\u578b\u61c9\u6982\u5316\u70ba\u7247\u8a9e-\u7247\u8a9e\u5c64\u6b21\u7684\u5275\u65b0\u7d44\u5408\uff0c\u4ee5\u53ca\u53ef\u4ee5\u540c\u6642\u5f9e\u4e2d\u884d\u751f\u7684\u7247\u8a9e-\u8a5e\u5f59/\u8a5e\u5f59-\u8a5e\u5f59\u5c64\u6b21\u7684\u5275\u65b0\u7d44\u5408\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u57fa\u65bc\u5143\u5b78\u7fd2\u7684\u6846\u67b6\uff0c\u7528\u65bc\u5728\u591a\u500b\u5c64\u6b21\u5be6\u73fe\u4e00\u81f4\u7684\u7d44\u5408\u6cdb\u5316\u3002\u57fa\u672c\u601d\u60f3\u662f\u9010\u6b65\u5b78\u7fd2\u5f9e\u7c21\u55ae\u5230\u8907\u96dc\u7684\u7d44\u5408\u4ee5\u4fdd\u6301\u4e00\u81f4\u6027\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u6839\u64da\u7d44\u5408\u8907\u96dc\u6027\u5c07\u539f\u59cb\u8a13\u7df4\u96c6\u5283\u5206\u70ba\u591a\u500b\u9a57\u8b49\u96c6\uff0c\u4e26\u5f15\u5165\u591a\u500b\u5143\u6b0a\u91cd\u7db2\u8def\u4f86\u70ba\u4e0d\u540c\u9a57\u8b49\u96c6\u4e2d\u7684\u6a23\u672c\u751f\u6210\u6a23\u672c\u6b0a\u91cd\u3002\u70ba\u4e86\u6309\u7167\u7d44\u5408\u8907\u96dc\u6027\u905e\u589e\u7684\u9806\u5e8f\u64ec\u5408\u9a57\u8b49\u96c6\uff0c\u6211\u5011\u4ee5\u591a\u5c64\u6b21\u512a\u5316\u7684\u65b9\u5f0f\u7368\u7acb\u4e14\u4f9d\u5e8f\u512a\u5316\u6bcf\u500b\u5143\u6b0a\u91cd\u7db2\u8def\u7684\u53c3\u6578\u3002\u6211\u5011\u5efa\u7acb\u4e86\u4e00\u500b GQA-CCG \u8cc7\u6599\u96c6\u4f86\u5b9a\u91cf\u8a55\u4f30\u4e00\u81f4\u6027\u3002\u8996\u89ba\u554f\u984c\u89e3\u7b54\u548c\u6642\u5e8f\u5f71\u7247\u63a5\u5730\u7684\u5be6\u9a57\u7d50\u679c\u8b49\u660e\u4e86\u6240\u63d0\u51fa\u6846\u67b6\u7684\u6709\u6548\u6027\u3002\u6211\u5011\u5728 https://github.com/NeverMoreLCH/CCG \u91cb\u51fa GQA-CCG\u3002", "author": "Chuanhao Li et.al.", "authors": "Chuanhao Li, Zhen Li, Chenchen Jing, Xiaomeng Fan, Wenbo Ye, Yuwei Wu, Yunde Jia", "id": "2412.13636v1", "paper_url": "http://arxiv.org/abs/2412.13636v1", "repo": "https://github.com/nevermorelch/ccg"}}