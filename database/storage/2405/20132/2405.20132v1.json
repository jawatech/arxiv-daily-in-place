{"2405.20132": {"publish_time": "2024-05-30", "title": "LLaMEA: A Large Language Model Evolutionary Algorithm for Automatically Generating Metaheuristics", "paper_summary": "Large Language Models (LLMs) such as GPT-4 have demonstrated their ability to\nunderstand natural language and generate complex code snippets. This paper\nintroduces a novel Large Language Model Evolutionary Algorithm (LLaMEA)\nframework, leveraging GPT models for the automated generation and refinement of\nalgorithms. Given a set of criteria and a task definition (the search space),\nLLaMEA iteratively generates, mutates and selects algorithms based on\nperformance metrics and feedback from runtime evaluations. This framework\noffers a unique approach to generating optimized algorithms without requiring\nextensive prior expertise. We show how this framework can be used to generate\nnovel black-box metaheuristic optimization algorithms automatically. LLaMEA\ngenerates multiple algorithms that outperform state-of-the-art optimization\nalgorithms (Covariance Matrix Adaptation Evolution Strategy and Differential\nEvolution) on the five dimensional black box optimization benchmark (BBOB). The\nresults demonstrate the feasibility of the framework and identify future\ndirections for automated generation and optimization of algorithms via LLMs.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)\uff0c\u4f8b\u5982 GPT-4\uff0c\u5df2\u5c55\u793a\u5176\u7406\u89e3\u81ea\u7136\u8a9e\u8a00\u548c\u751f\u6210\u8907\u96dc\u7a0b\u5f0f\u78bc\u7247\u6bb5\u7684\u80fd\u529b\u3002\u672c\u6587\u4ecb\u7d39\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u6f14\u7b97\u6cd5 (LLaMEA) \u67b6\u69cb\uff0c\u5229\u7528 GPT \u6a21\u578b\u81ea\u52d5\u751f\u6210\u548c\u6539\u9032\u6f14\u7b97\u6cd5\u3002\u7d66\u5b9a\u4e00\u7d44\u6a19\u6e96\u548c\u4efb\u52d9\u5b9a\u7fa9\uff08\u641c\u5c0b\u7a7a\u9593\uff09\uff0cLLaMEA \u6703\u6839\u64da\u57f7\u884c\u6642\u9593\u8a55\u4f30\u7684\u6548\u80fd\u6307\u6a19\u548c\u56de\u994b\uff0c\u53cd\u8986\u751f\u6210\u3001\u8b8a\u7570\u548c\u9078\u64c7\u6f14\u7b97\u6cd5\u3002\u6b64\u67b6\u69cb\u63d0\u4f9b\u4e86\u4e00\u7a2e\u7368\u7279\u7684\u65b9\u6cd5\u4f86\u751f\u6210\u6700\u4f73\u5316\u6f14\u7b97\u6cd5\uff0c\u800c\u7121\u9700\u5ee3\u6cdb\u7684\u5148\u9a57\u5c08\u696d\u77e5\u8b58\u3002\u6211\u5011\u5c55\u793a\u4e86\u5982\u4f55\u4f7f\u7528\u6b64\u67b6\u69cb\u81ea\u52d5\u751f\u6210\u65b0\u7a4e\u7684\u9ed1\u76d2\u5143\u555f\u767c\u5f0f\u6700\u4f73\u5316\u6f14\u7b97\u6cd5\u3002LLaMEA \u751f\u6210\u4e86\u591a\u7a2e\u6f14\u7b97\u6cd5\uff0c\u5176\u6548\u80fd\u512a\u65bc\u4e94\u7dad\u9ed1\u76d2\u6700\u4f73\u5316\u57fa\u6e96 (BBOB) \u4e0a\u7684\u6700\u65b0\u6700\u4f73\u5316\u6f14\u7b97\u6cd5\uff08\u5354\u65b9\u5dee\u77e9\u9663\u9069\u61c9\u6f14\u5316\u7b56\u7565\u548c\u5dee\u5206\u6f14\u5316\uff09\u3002\u7d50\u679c\u8b49\u660e\u4e86\u6b64\u67b6\u69cb\u7684\u53ef\u884c\u6027\uff0c\u4e26\u6307\u51fa\u4e86\u900f\u904e LLM \u81ea\u52d5\u751f\u6210\u548c\u6700\u4f73\u5316\u6f14\u7b97\u6cd5\u7684\u672a\u4f86\u65b9\u5411\u3002", "author": "Niki van Stein et.al.", "authors": "Niki van Stein, Thomas B\u00e4ck", "id": "2405.20132v1", "paper_url": "http://arxiv.org/abs/2405.20132v1", "repo": "null"}}