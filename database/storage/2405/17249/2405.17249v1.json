{"2405.17249": {"publish_time": "2024-05-27", "title": "Assessing LLMs Suitability for Knowledge Graph Completion", "paper_summary": "Recent work shown the capability of Large Language Models (LLMs) to solve\ntasks related to Knowledge Graphs, such as Knowledge Graph Completion, even in\nZero- or Few-Shot paradigms. However, they are known to hallucinate answers, or\noutput results in a non-deterministic manner, thus leading to wrongly reasoned\nresponses, even if they satisfy the user's demands. To highlight opportunities\nand challenges in knowledge graphs-related tasks, we experiment with two\ndistinguished LLMs, namely Mixtral-8x7B-Instruct-v0.1, and gpt-3.5-turbo-0125,\non Knowledge Graph Completion for static knowledge graphs, using prompts\nconstructed following the TELeR taxonomy, in Zero- and One-Shot contexts, on a\nTask-Oriented Dialogue system use case. When evaluated using both strict and\nflexible metrics measurement manners, our results show that LLMs could be fit\nfor such a task if prompts encapsulate sufficient information and relevant\nexamples.", "paper_summary_zh": "\u6700\u8fd1\u7684\u7814\u7a76\u663e\u793a\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u5177\u5907\u89e3\u51b3\u77e5\u8bc6\u56fe\u8c31\u76f8\u5173\u4efb\u52a1\u7684\u80fd\u529b\uff0c\u4f8b\u5982\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\uff0c\u5373\u4f7f\u5728\u96f6\u6b21\u6216\u5c0f\u6837\u672c\u7684\u60c5\u51b5\u4e0b\u4e5f\u662f\u5982\u6b64\u3002\u7136\u800c\uff0c\u4f17\u6240\u5468\u77e5\uff0c\u5b83\u4eec\u4f1a\u4ea7\u751f\u5e7b\u89c9\u7b54\u6848\uff0c\u6216\u4ee5\u975e\u786e\u5b9a\u6027\u7684\u65b9\u5f0f\u8f93\u51fa\u7ed3\u679c\uff0c\u4ece\u800c\u5bfc\u81f4\u63a8\u7406\u9519\u8bef\u7684\u54cd\u5e94\uff0c\u5373\u4f7f\u5b83\u4eec\u6ee1\u8db3\u4e86\u7528\u6237\u7684\u9700\u6c42\u3002\u4e3a\u4e86\u7a81\u51fa\u77e5\u8bc6\u56fe\u8c31\u76f8\u5173\u4efb\u52a1\u4e2d\u7684\u673a\u9047\u548c\u6311\u6218\uff0c\u6211\u4eec\u5bf9\u4e24\u79cd\u6770\u51fa\u7684 LLM \u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u5206\u522b\u662f Mixtral-8x7B-Instruct-v0.1 \u548c gpt-3.5-turbo-0125\uff0c\u5728\u9759\u6001\u77e5\u8bc6\u56fe\u8c31\u7684\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u4e0a\uff0c\u4f7f\u7528\u6839\u636e TELeR \u5206\u7c7b\u6cd5\u6784\u5efa\u7684\u63d0\u793a\uff0c\u5728\u96f6\u6b21\u548c\u4e00\u6b21\u4e0a\u4e0b\u6587\u4e2d\uff0c\u5728\u9762\u5411\u4efb\u52a1\u7684\u5bf9\u8bdd\u7cfb\u7edf\u7528\u4f8b\u4e2d\u3002\u5f53\u4f7f\u7528\u4e25\u683c\u548c\u7075\u6d3b\u7684\u5ea6\u91cf\u65b9\u5f0f\u8fdb\u884c\u8bc4\u4f30\u65f6\uff0c\u6211\u4eec\u7684\u7ed3\u679c\u8868\u660e\uff0c\u5982\u679c\u63d0\u793a\u5305\u542b\u8db3\u591f\u7684\u4fe1\u606f\u548c\u76f8\u5173\u793a\u4f8b\uff0c\u5219 LLM \u9002\u7528\u4e8e\u6b64\u7c7b\u4efb\u52a1\u3002", "author": "Vasile Ionut Remus Iga et.al.", "authors": "Vasile Ionut Remus Iga, Gheorghe Cosmin Silaghi", "id": "2405.17249v1", "paper_url": "http://arxiv.org/abs/2405.17249v1", "repo": "https://github.com/ionutiga/llms-for-kgc"}}