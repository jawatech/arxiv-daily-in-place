{"2401.02985": {"publish_time": "2024-01-02", "title": "Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education", "paper_summary": "The rapid evolution of artificial intelligence (AI), especially in the domain\nof Large Language Models (LLMs) and generative AI, has opened new avenues for\napplication across various fields, yet its role in business education remains\nunderexplored. This study introduces the first benchmark to assess the\nperformance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and\nGPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models\n(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission\nprocess for graduate business programs. Our analysis shows that most LLMs\noutperform human candidates, with GPT-4 Turbo not only outperforming the other\nmodels but also surpassing the average scores of graduate students at top\nbusiness schools. Through a case study, this research examines GPT-4 Turbo's\nability to explain answers, evaluate responses, identify errors, tailor\ninstructions, and generate alternative scenarios. The latest LLM versions,\nGPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in\nreasoning tasks compared to their predecessors, underscoring their potential\nfor complex problem-solving. While AI's promise in education, assessment, and\ntutoring is clear, challenges remain. Our study not only sheds light on LLMs'\nacademic potential but also emphasizes the need for careful development and\napplication of AI in education. As AI technology advances, it is imperative to\nestablish frameworks and protocols for AI interaction, verify the accuracy of\nAI-generated content, ensure worldwide access for diverse learners, and create\nan educational environment where AI supports human expertise. This research\nsets the stage for further exploration into the responsible use of AI to enrich\neducational experiences and improve exam preparation and assessment methods.", "paper_summary_zh": "", "author": "Vahid Ashrafimoghari et.al.", "authors": "Vahid Ashrafimoghari,Necdet G\u00fcrkan,Jordan W. Suchow", "id": "2401.02985v1", "paper_url": "http://arxiv.org/abs/2401.02985v1", "repo": "null"}}