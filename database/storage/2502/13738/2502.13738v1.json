{"2502.13738": {"publish_time": "2025-02-19", "title": "Enhancing Input-Label Mapping in In-Context Learning with Contrastive Decoding", "paper_summary": "Large language models (LLMs) excel at a range of tasks through in-context\nlearning (ICL), where only a few task examples guide their predictions.\nHowever, prior research highlights that LLMs often overlook input-label mapping\ninformation in ICL, relying more on their pre-trained knowledge. To address\nthis issue, we introduce In-Context Contrastive Decoding (ICCD), a novel method\nthat emphasizes input-label mapping by contrasting the output distributions\nbetween positive and negative in-context examples. Experiments on 7 natural\nlanguage understanding (NLU) tasks show that our ICCD method brings consistent\nand significant improvement (up to +2.1 improvement on average) upon 6\ndifferent scales of LLMs without requiring additional training. Our approach is\nversatile, enhancing performance with various demonstration selection methods,\ndemonstrating its broad applicability and effectiveness. The code and scripts\nwill be publicly released.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u900f\u904e\u60c5\u5883\u5b78\u7fd2 (ICL) \u64c5\u9577\u65bc\u5404\u7a2e\u4efb\u52d9\uff0c\u5176\u4e2d\u50c5\u6709\u5c11\u6578\u4efb\u52d9\u7bc4\u4f8b\u5f15\u5c0e\u5176\u9810\u6e2c\u3002\n\u7136\u800c\uff0c\u5148\u524d\u7684\u7814\u7a76\u5f37\u8abf\uff0cLLM \u5728 ICL \u4e2d\u7d93\u5e38\u5ffd\u7565\u8f38\u5165\u6a19\u7c64\u5c0d\u61c9\u8cc7\u8a0a\uff0c\u800c\u66f4\u591a\u4f9d\u8cf4\u5176\u9810\u5148\u8a13\u7df4\u7684\u77e5\u8b58\u3002\n\u70ba\u4e86\u89e3\u6c7a\u6b64\u554f\u984c\uff0c\u6211\u5011\u5f15\u9032\u60c5\u5883\u5c0d\u6bd4\u89e3\u78bc (ICCD) \u9019\u4e00\u7a2e\u5275\u65b0\u65b9\u6cd5\uff0c\u900f\u904e\u5c0d\u6bd4\u6b63\u8ca0\u60c5\u5883\u7bc4\u4f8b\u4e4b\u9593\u7684\u8f38\u51fa\u5206\u5e03\uff0c\u5f37\u8abf\u8f38\u5165\u6a19\u7c64\u5c0d\u61c9\u3002\n\u5728 7 \u9805\u81ea\u7136\u8a9e\u8a00\u7406\u89e3 (NLU) \u4efb\u52d9\u4e0a\u7684\u5be6\u9a57\u986f\u793a\uff0c\u6211\u5011\u7684 ICCD \u65b9\u6cd5\u5728 6 \u7a2e\u4e0d\u540c\u898f\u6a21\u7684 LLM \u4e0a\u5e36\u4f86\u4e00\u81f4\u4e14\u986f\u8457\u7684\u6539\u5584\uff08\u5e73\u5747\u6539\u5584\u5e45\u5ea6\u9ad8\u9054 +2.1\uff09\uff0c\u800c\u7121\u9700\u984d\u5916\u8a13\u7df4\u3002\n\u6211\u5011\u7684\u505a\u6cd5\u5f88\u9748\u6d3b\uff0c\u900f\u904e\u5404\u7a2e\u793a\u7bc4\u9078\u64c7\u65b9\u6cd5\u63d0\u5347\u6548\u80fd\uff0c\u5c55\u73fe\u5176\u5ee3\u6cdb\u7684\u9069\u7528\u6027\u548c\u6709\u6548\u6027\u3002\n\u7a0b\u5f0f\u78bc\u548c\u8173\u672c\u5c07\u516c\u958b\u91cb\u51fa\u3002", "author": "Keqin Peng et.al.", "authors": "Keqin Peng, Liang Ding, Yuanxin Ouyang, Meng Fang, Yancheng Yuan, Dacheng Tao", "id": "2502.13738v1", "paper_url": "http://arxiv.org/abs/2502.13738v1", "repo": "null"}}