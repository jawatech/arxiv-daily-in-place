{"2405.20643": {"publish_time": "2024-05-31", "title": "Learning Gaze-aware Compositional GAN", "paper_summary": "Gaze-annotated facial data is crucial for training deep neural networks\n(DNNs) for gaze estimation. However, obtaining these data is labor-intensive\nand requires specialized equipment due to the challenge of accurately\nannotating the gaze direction of a subject. In this work, we present a\ngenerative framework to create annotated gaze data by leveraging the benefits\nof labeled and unlabeled data sources. We propose a Gaze-aware Compositional\nGAN that learns to generate annotated facial images from a limited labeled\ndataset. Then we transfer this model to an unlabeled data domain to take\nadvantage of the diversity it provides. Experiments demonstrate our approach's\neffectiveness in generating within-domain image augmentations in the ETH-XGaze\ndataset and cross-domain augmentations in the CelebAMask-HQ dataset domain for\ngaze estimation DNN training. We also show additional applications of our work,\nwhich include facial image editing and gaze redirection.", "paper_summary_zh": "\u7528\u51dd\u8996\u6a19\u8a3b\u7684\u4eba\u81c9\u8cc7\u6599\u5c0d\u65bc\u8a13\u7df4\u6df1\u5ea6\u795e\u7d93\u7db2\u8def (DNN) \u4ee5\u9032\u884c\u51dd\u8996\u4f30\u8a08\u81f3\u95dc\u91cd\u8981\u3002\u7136\u800c\uff0c\u53d6\u5f97\u9019\u4e9b\u8cc7\u6599\u9700\u8981\u5927\u91cf\u4eba\u529b\uff0c\u4e14\u7531\u65bc\u6e96\u78ba\u6a19\u8a3b\u53d7\u8a66\u8005\u7684\u51dd\u8996\u65b9\u5411\u5177\u6709\u6311\u6230\u6027\uff0c\u56e0\u6b64\u9700\u8981\u5c08\u696d\u7684\u8a2d\u5099\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u751f\u6210\u5f0f\u67b6\u69cb\uff0c\u900f\u904e\u5229\u7528\u6a19\u7c64\u8cc7\u6599\u548c\u672a\u6a19\u7c64\u8cc7\u6599\u4f86\u6e90\u7684\u512a\u9ede\uff0c\u4f86\u5efa\u7acb\u6a19\u8a3b\u7684\u51dd\u8996\u8cc7\u6599\u3002\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u51dd\u8996\u611f\u77e5\u5408\u6210 GAN\uff0c\u8a72 GAN \u6703\u5b78\u7fd2\u5f9e\u6709\u9650\u7684\u6a19\u7c64\u8cc7\u6599\u96c6\u4e2d\u7522\u751f\u6a19\u8a3b\u7684\u4eba\u81c9\u5f71\u50cf\u3002\u7136\u5f8c\uff0c\u6211\u5011\u5c07\u6b64\u6a21\u578b\u8f49\u79fb\u5230\u672a\u6a19\u7c64\u7684\u8cc7\u6599\u7db2\u57df\uff0c\u4ee5\u5229\u7528\u5176\u6240\u63d0\u4f9b\u7684\u591a\u6a23\u6027\u3002\u5be6\u9a57\u8b49\u660e\u4e86\u6211\u5011\u7684\u65b9\u6cd5\u5728 ETH-XGaze \u8cc7\u6599\u96c6\u4e2d\u7522\u751f\u540c\u7db2\u57df\u5f71\u50cf\u64f4\u5145\uff0c\u4ee5\u53ca\u5728 CelebAMask-HQ \u8cc7\u6599\u96c6\u7db2\u57df\u4e2d\u7522\u751f\u8de8\u7db2\u57df\u64f4\u5145\u7684\u6709\u6548\u6027\uff0c\u4ee5\u9032\u884c\u51dd\u8996\u4f30\u8a08 DNN \u8a13\u7df4\u3002\u6211\u5011\u4e5f\u5c55\u793a\u4e86\u6211\u5011\u5de5\u4f5c\u7684\u5176\u4ed6\u61c9\u7528\uff0c\u5305\u62ec\u4eba\u81c9\u5f71\u50cf\u7de8\u8f2f\u548c\u51dd\u8996\u91cd\u65b0\u5c0e\u5411\u3002", "author": "Nerea Aranjuelo et.al.", "authors": "Nerea Aranjuelo, Siyu Huang, Ignacio Arganda-Carreras, Luis Unzueta, Oihana Otaegui, Hanspeter Pfister, Donglai Wei", "id": "2405.20643v1", "paper_url": "http://arxiv.org/abs/2405.20643v1", "repo": "https://github.com/naranjuelo/gc-gan"}}