{"2501.02795": {"publish_time": "2025-01-06", "title": "InfiFusion: A Unified Framework for Enhanced Cross-Model Reasoning via LLM Fusion", "paper_summary": "Large Language Models (LLMs) have demonstrated strong performance across\nvarious reasoning tasks, yet building a single model that consistently excels\nacross all domains remains challenging. This paper addresses this problem by\nexploring strategies to integrate multiple domain-specialized models into an\nefficient pivot model.We propose two fusion strategies to combine the strengths\nof multiple LLMs: (1) a pairwise, multi-step fusion approach that sequentially\ndistills each source model into the pivot model, followed by a weight merging\nstep to integrate the distilled models into the final model. This method\nachieves strong performance but requires substantial training effort; and (2) a\nunified fusion approach that aggregates all source models' outputs\nsimultaneously.To improve the fusion process, we introduce a novel\nRate-Skewness Adaptive Fusion (RSAF) technique, which dynamically adjusts top-K\nratios during parameter merging for enhanced flexibility and\nstability.Furthermore, we propose an uncertainty-based weighting method for the\nunified approach, which dynamically balances the contributions of source models\nand outperforms other logits/distribution ensemble methods.We achieved accuracy\nimprovements of 9.27%, 8.80%, and 8.89% on the GSM8K, MATH, and HumanEval\ntasks, respectively.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u5404\u7a2e\u63a8\u7406\u4efb\u52d9\u4e2d\u5c55\u73fe\u5f37\u52c1\u7684\u6548\u80fd\uff0c\u4f46\u5efa\u7acb\u4e00\u500b\u5728\u6240\u6709\u9818\u57df\u90fd\u80fd\u6301\u7e8c\u5353\u8d8a\u7684\u55ae\u4e00\u6a21\u578b\u4ecd\u7136\u5177\u6709\u6311\u6230\u6027\u3002\u672c\u6587\u900f\u904e\u63a2\u7d22\u5c07\u591a\u500b\u9818\u57df\u5c08\u7528\u6a21\u578b\u6574\u5408\u5230\u4e00\u500b\u9ad8\u6548\u7684\u6a1e\u7d10\u6a21\u578b\u4e2d\uff0c\u4f86\u89e3\u6c7a\u9019\u500b\u554f\u984c\u3002\u6211\u5011\u63d0\u51fa\u5169\u7a2e\u878d\u5408\u7b56\u7565\u4f86\u7d50\u5408\u591a\u500b LLM \u7684\u512a\u9ede\uff1a(1) \u6210\u5c0d\u3001\u591a\u6b65\u9a5f\u878d\u5408\u65b9\u6cd5\uff0c\u4f9d\u5e8f\u5c07\u6bcf\u500b\u4f86\u6e90\u6a21\u578b\u8403\u53d6\u51fa\u6a1e\u7d10\u6a21\u578b\uff0c\u63a5\u8457\u9032\u884c\u6b0a\u91cd\u5408\u4f75\u6b65\u9a5f\uff0c\u5c07\u8403\u53d6\u51fa\u7684\u6a21\u578b\u6574\u5408\u5230\u6700\u7d42\u6a21\u578b\u4e2d\u3002\u6b64\u65b9\u6cd5\u53ef\u9054\u6210\u5f37\u52c1\u7684\u6548\u80fd\uff0c\u4f46\u9700\u8981\u5927\u91cf\u7684\u8a13\u7df4\u5de5\u4f5c\uff1b(2) \u7d71\u4e00\u878d\u5408\u65b9\u6cd5\uff0c\u540c\u6642\u5f59\u6574\u6240\u6709\u4f86\u6e90\u6a21\u578b\u7684\u8f38\u51fa\u3002\u70ba\u4e86\u6539\u5584\u878d\u5408\u6d41\u7a0b\uff0c\u6211\u5011\u5f15\u5165\u4e00\u7a2e\u65b0\u7a4e\u7684\u6bd4\u7387\u504f\u5ea6\u81ea\u9069\u61c9\u878d\u5408 (RSAF) \u6280\u8853\uff0c\u5728\u53c3\u6578\u5408\u4f75\u671f\u9593\u52d5\u614b\u8abf\u6574\u524d K \u500b\u6bd4\u7387\uff0c\u4ee5\u589e\u5f37\u5f48\u6027\u548c\u7a69\u5b9a\u6027\u3002\u6b64\u5916\uff0c\u6211\u5011\u91dd\u5c0d\u7d71\u4e00\u65b9\u6cd5\u63d0\u51fa\u4e00\u500b\u57fa\u65bc\u4e0d\u78ba\u5b9a\u6027\u7684\u52a0\u6b0a\u65b9\u6cd5\uff0c\u53ef\u4ee5\u52d5\u614b\u5e73\u8861\u4f86\u6e90\u6a21\u578b\u7684\u8ca2\u737b\uff0c\u4e26\u4e14\u512a\u65bc\u5176\u4ed6\u908f\u8f2f/\u5206\u914d\u6574\u9ad4\u65b9\u6cd5\u3002\u6211\u5011\u5206\u5225\u5728 GSM8K\u3001MATH \u548c HumanEval \u4efb\u52d9\u4e2d\uff0c\u9054\u5230\u4e86 9.27%\u30018.80% \u548c 8.89% \u7684\u6e96\u78ba\u5ea6\u63d0\u5347\u3002", "author": "Zhaoyi Yan et.al.", "authors": "Zhaoyi Yan, Zhijie Sang, Yiming Zhang, Yuhao Fu, Baoyi He, Qi Zhou, Yining Di, Chunlin Ji, Shengyu Zhang, Fei Wu, Hongxia Yang", "id": "2501.02795v1", "paper_url": "http://arxiv.org/abs/2501.02795v1", "repo": "null"}}