{"2410.01532": {"publish_time": "2024-10-02", "title": "Seeing Eye to AI: Human Alignment via Gaze-Based Response Rewards for Large Language Models", "paper_summary": "Advancements in Natural Language Processing (NLP), have led to the emergence\nof Large Language Models (LLMs) such as GPT, Llama, Claude, and Gemini, which\nexcel across a range of tasks but require extensive fine-tuning to align their\noutputs with human expectations. A widely used method for achieving this\nalignment is Reinforcement Learning from Human Feedback (RLHF), which, despite\nits success, faces challenges in accurately modelling human preferences. In\nthis paper, we introduce GazeReward, a novel framework that integrates implicit\nfeedback -- and specifically eye-tracking (ET) data -- into the Reward Model\n(RM). In addition, we explore how ET-based features can provide insights into\nuser preferences. Through ablation studies we test our framework with different\nintegration methods, LLMs, and ET generator models, demonstrating that our\napproach significantly improves the accuracy of the RM on established human\npreference datasets. This work advances the ongoing discussion on optimizing AI\nalignment with human values, exploring the potential of cognitive data for\nshaping future NLP research.", "paper_summary_zh": "\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u7684\u9032\u6b65\uff0c\u5c0e\u81f4\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u51fa\u73fe\uff0c\u4f8b\u5982 GPT\u3001Llama\u3001Claude \u548c Gemini\uff0c\u5b83\u5011\u5728\u5404\u7a2e\u4efb\u52d9\u4e2d\u8868\u73fe\u51fa\u8272\uff0c\u4f46\u9700\u8981\u5ee3\u6cdb\u7684\u5fae\u8abf\u624d\u80fd\u4f7f\u5176\u8f38\u51fa\u8207\u4eba\u985e\u7684\u671f\u671b\u4fdd\u6301\u4e00\u81f4\u3002\u5be6\u73fe\u9019\u7a2e\u4e00\u81f4\u6027\u7684\u5ee3\u6cdb\u4f7f\u7528\u7684\u65b9\u6cd5\u662f\u4eba\u985e\u56de\u994b\u5f37\u5316\u5b78\u7fd2 (RLHF)\uff0c\u5118\u7ba1\u5b83\u5f88\u6210\u529f\uff0c\u4f46\u5728\u6e96\u78ba\u5efa\u6a21\u4eba\u985e\u504f\u597d\u65b9\u9762\u9762\u81e8\u6311\u6230\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86 GazeReward\uff0c\u9019\u662f\u4e00\u500b\u65b0\u7684\u6846\u67b6\uff0c\u5b83\u5c07\u96b1\u5f0f\u56de\u994b\u2014\u2014\u7279\u5225\u662f\u773c\u7403\u8ffd\u8e64 (ET) \u8cc7\u6599\u2014\u2014\u6574\u5408\u5230\u56de\u5831\u6a21\u578b (RM) \u4e2d\u3002\u6b64\u5916\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u57fa\u65bc ET \u7684\u7279\u5fb5\u5982\u4f55\u63d0\u4f9b\u5c0d\u4f7f\u7528\u8005\u504f\u597d\u7684\u898b\u89e3\u3002\u900f\u904e\u6d88\u878d\u7814\u7a76\uff0c\u6211\u5011\u4f7f\u7528\u4e0d\u540c\u7684\u6574\u5408\u65b9\u6cd5\u3001LLM \u548c ET \u751f\u6210\u5668\u6a21\u578b\u6e2c\u8a66\u6211\u5011\u7684\u6846\u67b6\uff0c\u8b49\u660e\u6211\u5011\u7684\u65b9\u6cd5\u986f\u8457\u63d0\u9ad8\u4e86 RM \u5728\u5df2\u5efa\u7acb\u7684\u4eba\u985e\u504f\u597d\u8cc7\u6599\u96c6\u4e0a\u7684\u6e96\u78ba\u6027\u3002\u9019\u9805\u5de5\u4f5c\u63a8\u52d5\u4e86\u512a\u5316 AI \u8207\u4eba\u985e\u50f9\u503c\u89c0\u4e00\u81f4\u6027\u7684\u6301\u7e8c\u8a0e\u8ad6\uff0c\u63a2\u7d22\u8a8d\u77e5\u8cc7\u6599\u5728\u5851\u9020\u672a\u4f86 NLP \u7814\u7a76\u4e2d\u7684\u6f5b\u529b\u3002", "author": "Angela Lopez-Cardona et.al.", "authors": "Angela Lopez-Cardona, Carlos Segura, Alexandros Karatzoglou, Sergi Abadal, Ioannis Arapakis", "id": "2410.01532v1", "paper_url": "http://arxiv.org/abs/2410.01532v1", "repo": "null"}}