{"2411.06916": {"publish_time": "2024-11-11", "title": "Slowing Down Forgetting in Continual Learning", "paper_summary": "A common challenge in continual learning (CL) is catastrophic forgetting,\nwhere the performance on old tasks drops after new, additional tasks are\nlearned. In this paper, we propose a novel framework called ReCL to slow down\nforgetting in CL. Our framework exploits an implicit bias of gradient-based\nneural networks due to which these converge to margin maximization points. Such\nconvergence points allow us to reconstruct old data from previous tasks, which\nwe then combine with the current training data. Our framework is flexible and\ncan be applied on top of existing, state-of-the-art CL methods to slow down\nforgetting. We further demonstrate the performance gain from our framework\nacross a large series of experiments, including different CL scenarios (class\nincremental, domain incremental, task incremental learning) different datasets\n(MNIST, CIFAR10), and different network architectures. Across all experiments,\nwe find large performance gains through ReCL. To the best of our knowledge, our\nframework is the first to address catastrophic forgetting by leveraging models\nin CL as their own memory buffers.", "paper_summary_zh": "\u6301\u7e8c\u5b78\u7fd2 (CL) \u4e2d\u5e38\u898b\u7684\u6311\u6230\u662f\u707d\u96e3\u6027\u907a\u5fd8\uff0c\u4e5f\u5c31\u662f\u5728\u5b78\u7fd2\u65b0\u7684\u984d\u5916\u4efb\u52d9\u5f8c\uff0c\u820a\u4efb\u52d9\u7684\u8868\u73fe\u4e0b\u964d\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u540d\u70ba ReCL \u7684\u65b0\u6846\u67b6\uff0c\u7528\u4f86\u6e1b\u7de9 CL \u4e2d\u7684\u907a\u5fd8\u3002\u6211\u5011\u7684\u6846\u67b6\u5229\u7528\u4e86\u57fa\u65bc\u68af\u5ea6\u7684\u985e\u795e\u7d93\u7db2\u8def\u7684\u5167\u96b1\u504f\u5dee\uff0c\u56e0\u70ba\u9019\u4e9b\u7db2\u8def\u6703\u6536\u6582\u5230\u908a\u754c\u6700\u5927\u5316\u9ede\u3002\u9019\u6a23\u7684\u6536\u6582\u9ede\u8b93\u6211\u5011\u53ef\u4ee5\u5f9e\u5148\u524d\u7684\u4efb\u52d9\u4e2d\u91cd\u5efa\u820a\u8cc7\u6599\uff0c\u7136\u5f8c\u6211\u5011\u5c07\u5176\u8207\u76ee\u524d\u7684\u8a13\u7df4\u8cc7\u6599\u7d50\u5408\u3002\u6211\u5011\u7684\u6846\u67b6\u5f88\u9748\u6d3b\uff0c\u53ef\u4ee5\u61c9\u7528\u65bc\u73fe\u6709\u7684\u3001\u6700\u5148\u9032\u7684 CL \u65b9\u6cd5\u4e4b\u4e0a\uff0c\u4ee5\u6e1b\u7de9\u907a\u5fd8\u3002\u6211\u5011\u9032\u4e00\u6b65\u5c55\u793a\u4e86\u6211\u5011\u7684\u6846\u67b6\u5728\u5927\u91cf\u5be6\u9a57\u4e2d\u7372\u5f97\u7684\u6548\u80fd\u63d0\u5347\uff0c\u5305\u62ec\u4e0d\u540c\u7684 CL \u5834\u666f\uff08\u985e\u5225\u589e\u91cf\u3001\u9818\u57df\u589e\u91cf\u3001\u4efb\u52d9\u589e\u91cf\u5b78\u7fd2\uff09\u4e0d\u540c\u7684\u8cc7\u6599\u96c6\uff08MNIST\u3001CIFAR10\uff09\u548c\u4e0d\u540c\u7684\u7db2\u8def\u67b6\u69cb\u3002\u5728\u6240\u6709\u5be6\u9a57\u4e2d\uff0c\u6211\u5011\u90fd\u767c\u73fe ReCL \u5e36\u4f86\u4e86\u986f\u8457\u7684\u6548\u80fd\u63d0\u5347\u3002\u64da\u6211\u5011\u6240\u77e5\uff0c\u6211\u5011\u7684\u6846\u67b6\u662f\u7b2c\u4e00\u500b\u900f\u904e\u5229\u7528 CL \u4e2d\u7684\u6a21\u578b\u4f5c\u70ba\u5176\u81ea\u5df1\u7684\u8a18\u61b6\u9ad4\u7de9\u885d\u5340\u4f86\u89e3\u6c7a\u707d\u96e3\u6027\u907a\u5fd8\u7684\u6846\u67b6\u3002", "author": "Pascal Janetzky et.al.", "authors": "Pascal Janetzky, Tobias Schlagenhauf, Stefan Feuerriegel", "id": "2411.06916v1", "paper_url": "http://arxiv.org/abs/2411.06916v1", "repo": "null"}}