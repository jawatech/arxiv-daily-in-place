{"2411.19943": {"publish_time": "2024-11-29", "title": "Critical Tokens Matter: Token-Level Contrastive Estimation Enhence LLM's Reasoning Capability", "paper_summary": "Large Language Models (LLMs) have exhibited remarkable performance on\nreasoning tasks. They utilize autoregressive token generation to construct\nreasoning trajectories, enabling the development of a coherent chain of\nthought. In this work, we explore the impact of individual tokens on the final\noutcomes of reasoning tasks. We identify the existence of ``critical tokens''\nthat lead to incorrect reasoning trajectories in LLMs. Specifically, we find\nthat LLMs tend to produce positive outcomes when forced to decode other tokens\ninstead of critical tokens. Motivated by this observation, we propose a novel\napproach - cDPO - designed to automatically recognize and conduct token-level\nrewards for the critical tokens during the alignment process. Specifically, we\ndevelop a contrastive estimation approach to automatically identify critical\ntokens. It is achieved by comparing the generation likelihood of positive and\nnegative models. To achieve this, we separately fine-tune the positive and\nnegative models on various reasoning trajectories, consequently, they are\ncapable of identifying identify critical tokens within incorrect trajectories\nthat contribute to erroneous outcomes. Moreover, to further align the model\nwith the critical token information during the alignment process, we extend the\nconventional DPO algorithms to token-level DPO and utilize the differential\nlikelihood from the aforementioned positive and negative model as important\nweight for token-level DPO learning.Experimental results on GSM8K and MATH500\nbenchmarks with two-widely used models Llama-3 (8B and 70B) and deepseek-math\n(7B) demonstrate the effectiveness of the propsoed approach cDPO.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5728\u63a8\u7406\u4efb\u52d9\u4e0a\u5c55\u73fe\u51fa\u986f\u8457\u7684\u8868\u73fe\u3002\u5b83\u5011\u5229\u7528\u81ea\u8ff4\u6b78\u7b26\u865f\u7522\u751f\u4f86\u69cb\u5efa\u63a8\u7406\u8ecc\u8de1\uff0c\u5f9e\u800c\u80fd\u5920\u767c\u5c55\u51fa\u4e00\u689d\u9023\u8cab\u7684\u601d\u7dad\u93c8\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63a2\u8a0e\u4e86\u500b\u5225\u7b26\u865f\u5c0d\u63a8\u7406\u4efb\u52d9\u6700\u7d42\u7d50\u679c\u7684\u5f71\u97ff\u3002\u6211\u5011\u767c\u73fe LLM \u4e2d\u5b58\u5728\u5c0e\u81f4\u63a8\u7406\u8ecc\u8de1\u4e0d\u6b63\u78ba\u7684\u300c\u95dc\u9375\u7b26\u865f\u300d\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u767c\u73fe LLM \u50be\u5411\u65bc\u5728\u88ab\u8feb\u89e3\u78bc\u5176\u4ed6\u7b26\u865f\u800c\u4e0d\u662f\u95dc\u9375\u7b26\u865f\u6642\u7522\u751f\u6b63\u5411\u7d50\u679c\u3002\u53d7\u6b64\u89c0\u5bdf\u7d50\u679c\u555f\u767c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u65b9\u6cd5 - cDPO - \u65e8\u5728\u81ea\u52d5\u8b58\u5225\u4e26\u5728\u5c0d\u9f4a\u904e\u7a0b\u4e2d\u5c0d\u95dc\u9375\u7b26\u865f\u9032\u884c\u7b26\u865f\u5c64\u7d1a\u7684\u734e\u52f5\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u7a2e\u5c0d\u6bd4\u4f30\u8a08\u65b9\u6cd5\u4f86\u81ea\u52d5\u8b58\u5225\u95dc\u9375\u7b26\u865f\u3002\u9019\u662f\u901a\u904e\u6bd4\u8f03\u6b63\u5411\u548c\u8ca0\u5411\u6a21\u578b\u7684\u7522\u751f\u53ef\u80fd\u6027\u4f86\u5be6\u73fe\u7684\u3002\u70ba\u6b64\uff0c\u6211\u5011\u5206\u5225\u5c0d\u6b63\u5411\u548c\u8ca0\u5411\u6a21\u578b\u9032\u884c\u5fae\u8abf\uff0c\u91dd\u5c0d\u5404\u7a2e\u63a8\u7406\u8ecc\u8de1\uff0c\u56e0\u6b64\uff0c\u5b83\u5011\u80fd\u5920\u8b58\u5225\u51fa\u5c0e\u81f4\u932f\u8aa4\u7d50\u679c\u7684\u4e0d\u6b63\u78ba\u8ecc\u8de1\u4e2d\u7684\u95dc\u9375\u7b26\u865f\u3002\u6b64\u5916\uff0c\u70ba\u4e86\u9032\u4e00\u6b65\u5728\u5c0d\u9f4a\u904e\u7a0b\u4e2d\u5c07\u6a21\u578b\u8207\u95dc\u9375\u7b26\u865f\u8cc7\u8a0a\u5c0d\u9f4a\uff0c\u6211\u5011\u5c07\u50b3\u7d71\u7684 DPO \u6f14\u7b97\u6cd5\u64f4\u5c55\u5230\u7b26\u865f\u5c64\u7d1a\u7684 DPO\uff0c\u4e26\u5229\u7528\u4e0a\u8ff0\u6b63\u5411\u548c\u8ca0\u5411\u6a21\u578b\u7684\u5dee\u7570\u53ef\u80fd\u6027\u4f5c\u70ba\u7b26\u865f\u5c64\u7d1a DPO \u5b78\u7fd2\u7684\u91cd\u8981\u6b0a\u91cd\u3002\u5728 GSM8K \u548c MATH500 \u57fa\u6e96\u4e0a\u4f7f\u7528\u5169\u500b\u5ee3\u6cdb\u4f7f\u7528\u7684\u6a21\u578b Llama-3\uff088B \u548c 70B\uff09\u548c deepseek-math\uff087B\uff09\u9032\u884c\u7684\u5be6\u9a57\u7d50\u679c\u8b49\u660e\u4e86\u6240\u63d0\u51fa\u7684\u65b9\u6cd5 cDPO \u7684\u6709\u6548\u6027\u3002", "author": "Zicheng Lin et.al.", "authors": "Zicheng Lin, Tian Liang, Jiahao Xu, Xing Wang, Ruilin Luo, Chufan Shi, Siheng Li, Yujiu Yang, Zhaopeng Tu", "id": "2411.19943v1", "paper_url": "http://arxiv.org/abs/2411.19943v1", "repo": "null"}}