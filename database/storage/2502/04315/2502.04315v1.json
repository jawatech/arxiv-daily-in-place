{"2502.04315": {"publish_time": "2025-02-06", "title": "ChamaleonLLM: Batch-Aware Dynamic Low-Rank Adaptation via Inference-Time Clusters", "paper_summary": "Recent advances in large language models (LLMs) have shown remarkable\nperformance across diverse tasks. However, these models are typically deployed\nwith fixed weights, which limits their ability to adapt dynamically to the\nvariability inherent in real-world data during inference. This paper introduces\nChamaleonLLM, a novel framework that enables inference-time adaptation of LLMs\nby leveraging batch-aware clustering and on-the-fly generation of low-rank\nupdates. Unlike traditional fine-tuning approaches such as Low-Rank Adaptation\n(LoRA) or methods that rely on a fixed set of pre-learned uniforms (changeable\nmasks), our method dynamically generates adaptive modifications to the decoder\nweights based on the aggregated statistics of clustered batches. By\nintelligently grouping similar inputs and computing context-aware low-rank\nupdates via a hyper-network, ChamaleonLLM achieves significant performance\ngains, outperforming conventional LoRA methods while eliminating the overhead\nof maintaining multiple expert models. Our experiments highlight the potential\nof our approach to serve as a versatile and highly adaptive solution for\nlanguage model inference. ChamaleonLLM is open-sourced to ensure the\nreproducibility of our experiments:\nhttps://anonymous.4open.science/r/ChamaleonLLM/", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u6700\u65b0\u9032\u5c55\u5df2\u5728\u5404\u7a2e\u4efb\u52d9\u4e2d\u5c55\u73fe\u51fa\u5353\u8d8a\u7684\u6548\u80fd\u3002\u7136\u800c\uff0c\u9019\u4e9b\u6a21\u578b\u901a\u5e38\u6703\u4ee5\u56fa\u5b9a\u7684\u6b0a\u91cd\u9032\u884c\u90e8\u7f72\uff0c\u9019\u9650\u5236\u4e86\u5b83\u5011\u5728\u63a8\u7406\u904e\u7a0b\u4e2d\u52d5\u614b\u9069\u61c9\u73fe\u5be6\u4e16\u754c\u8cc7\u6599\u4e2d\u56fa\u6709\u8b8a\u7570\u6027\u7684\u80fd\u529b\u3002\u672c\u6587\u4ecb\u7d39\u4e86 ChamaleonLLM\uff0c\u4e00\u500b\u5275\u65b0\u7684\u67b6\u69cb\uff0c\u5b83\u900f\u904e\u5229\u7528\u6279\u6b21\u611f\u77e5\u5206\u7fa4\u548c\u5373\u6642\u751f\u6210\u4f4e\u79e9\u66f4\u65b0\uff0c\u5be6\u73fe LLM \u7684\u63a8\u7406\u6642\u9593\u9069\u61c9\u3002\u8207\u50b3\u7d71\u7684\u5fae\u8abf\u65b9\u6cd5\uff08\u4f8b\u5982\u4f4e\u79e9\u9069\u61c9 (LoRA) \u6216\u4f9d\u8cf4\u65bc\u56fa\u5b9a\u9810\u5148\u5b78\u7fd2\u7684\u5747\u52fb\u96c6 (\u53ef\u8b8a\u906e\u7f69) \u7684\u65b9\u6cd5\uff09\u4e0d\u540c\uff0c\u6211\u5011\u7684\u6a21\u578b\u6703\u6839\u64da\u5206\u7fa4\u6279\u6b21\u7684\u532f\u7e3d\u7d71\u8a08\u8cc7\u6599\uff0c\u52d5\u614b\u751f\u6210\u5c0d\u89e3\u78bc\u5668\u6b0a\u91cd\u7684\u9069\u61c9\u6027\u4fee\u6539\u3002\u900f\u904e\u667a\u6167\u5730\u5c07\u985e\u4f3c\u7684\u8f38\u5165\u5206\u7d44\uff0c\u4e26\u900f\u904e\u8d85\u7db2\u8def\u8a08\u7b97\u8207\u8108\u7d61\u76f8\u95dc\u7684\u4f4e\u79e9\u66f4\u65b0\uff0cChamaleonLLM \u9054\u5230\u4e86\u986f\u8457\u7684\u6548\u80fd\u63d0\u5347\uff0c\u512a\u65bc\u50b3\u7d71\u7684 LoRA \u65b9\u6cd5\uff0c\u540c\u6642\u6d88\u9664\u4e86\u7dad\u8b77\u591a\u500b\u5c08\u5bb6\u6a21\u578b\u7684\u958b\u92b7\u3002\u6211\u5011\u7684\u5be6\u9a57\u7a81\u986f\u4e86\u6211\u5011\u7684\u65b9\u6cd5\u4f5c\u70ba\u8a9e\u8a00\u6a21\u578b\u63a8\u7406\u7684\u901a\u7528\u4e14\u9ad8\u5ea6\u9069\u61c9\u6027\u89e3\u6c7a\u65b9\u6848\u7684\u6f5b\u529b\u3002ChamaleonLLM \u662f\u958b\u6e90\u7684\uff0c\u4ee5\u78ba\u4fdd\u6211\u5011\u5be6\u9a57\u7684\u53ef\u8907\u88fd\u6027\uff1a\nhttps://anonymous.4open.science/r/ChamaleonLLM/", "author": "Kamer Ali Yuksel et.al.", "authors": "Kamer Ali Yuksel, Hassan Sawaf", "id": "2502.04315v1", "paper_url": "http://arxiv.org/abs/2502.04315v1", "repo": "null"}}