{"2504.02670": {"publish_time": "2025-04-03", "title": "Affordable AI Assistants with Knowledge Graph of Thoughts", "paper_summary": "Large Language Models (LLMs) are revolutionizing the development of AI\nassistants capable of performing diverse tasks across domains. However, current\nstate-of-the-art LLM-driven agents face significant challenges, including high\noperational costs and limited success rates on complex benchmarks like GAIA. To\naddress these issues, we propose the Knowledge Graph of Thoughts (KGoT), an\ninnovative AI assistant architecture that integrates LLM reasoning with\ndynamically constructed knowledge graphs (KGs). KGoT extracts and structures\ntask-relevant knowledge into a dynamic KG representation, iteratively enhanced\nthrough external tools such as math solvers, web crawlers, and Python scripts.\nSuch structured representation of task-relevant knowledge enables low-cost\nmodels to solve complex tasks effectively. For example, KGoT achieves a 29%\nimprovement in task success rates on the GAIA benchmark compared to Hugging\nFace Agents with GPT-4o mini, while reducing costs by over 36x compared to\nGPT-4o. Improvements for recent reasoning models are similar, e.g., 36% and\n37.5% for Qwen2.5-32B and Deepseek-R1-70B, respectively. KGoT offers a\nscalable, affordable, and high-performing solution for AI assistants.", "paper_summary_zh": "<paragraph>\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6b63\u5728\u5fb9\u5e95\u6539\u8b8a\u80fd\u5920\u8de8\u9818\u57df\u57f7\u884c\u591a\u6a23\u5316\u4efb\u52d9\u7684 AI \u52a9\u7406\u7684\u958b\u767c\u3002\u7136\u800c\uff0c\u76ee\u524d\u6700\u5148\u9032\u7684 LLM \u9a45\u52d5\u4ee3\u7406\u9762\u81e8\u8457\u91cd\u5927\u6311\u6230\uff0c\u5305\u62ec\u9ad8\u6602\u7684\u71df\u904b\u6210\u672c\u4ee5\u53ca\u5728 GAIA \u7b49\u8907\u96dc\u57fa\u6e96\u6e2c\u8a66\u4e2d\u7684\u6210\u529f\u7387\u6709\u9650\u3002\u70ba\u4e86\u61c9\u5c0d\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u601d\u7dad\u77e5\u8b58\u5716\u8b5c (KGoT)\uff0c\u9019\u662f\u4e00\u7a2e\u5275\u65b0\u7684 AI \u52a9\u7406\u67b6\u69cb\uff0c\u5b83\u5c07 LLM \u63a8\u7406\u8207\u52d5\u614b\u69cb\u5efa\u7684\u77e5\u8b58\u5716\u8b5c (KG) \u76f8\u7d50\u5408\u3002KGoT \u5c07\u8207\u4efb\u52d9\u76f8\u95dc\u7684\u77e5\u8b58\u63d0\u53d6\u4e26\u69cb\u5efa\u6210\u52d5\u614b KG \u8868\u793a\u5f62\u5f0f\uff0c\u4e26\u900f\u904e\u6578\u5b78\u6c42\u89e3\u5668\u3001\u7db2\u8def\u722c\u87f2\u548c Python \u8173\u672c\u7b49\u5916\u90e8\u5de5\u5177\u9032\u884c\u8fed\u4ee3\u589e\u5f37\u3002\u9019\u7a2e\u8207\u4efb\u52d9\u76f8\u95dc\u7684\u77e5\u8b58\u7684\u7d50\u69cb\u5316\u8868\u793a\u4f7f\u4f4e\u6210\u672c\u6a21\u578b\u80fd\u5920\u6709\u6548\u5730\u89e3\u6c7a\u8907\u96dc\u4efb\u52d9\u3002\u4f8b\u5982\uff0c\u8207\u4f7f\u7528 GPT-4o mini \u7684 Hugging Face Agents \u76f8\u6bd4\uff0cKGoT \u5728 GAIA \u57fa\u6e96\u6e2c\u8a66\u4e2d\u7684\u4efb\u52d9\u6210\u529f\u7387\u63d0\u9ad8\u4e86 29%\uff0c\u540c\u6642\u8207 GPT-4o \u76f8\u6bd4\uff0c\u6210\u672c\u964d\u4f4e\u4e86 36 \u500d\u4ee5\u4e0a\u3002\u8fd1\u671f\u63a8\u7406\u6a21\u578b\u7684\u6539\u9032\u4e5f\u985e\u4f3c\uff0c\u4f8b\u5982 Qwen2.5-32B \u548c Deepseek-R1-70B \u5206\u5225\u63d0\u9ad8\u4e86 36% \u548c 37.5%\u3002KGoT \u70ba AI \u52a9\u7406\u63d0\u4f9b\u4e86\u4e00\u500b\u53ef\u64f4\u5c55\u3001\u50f9\u683c\u5408\u7406\u4e14\u9ad8\u6548\u80fd\u7684\u89e3\u6c7a\u65b9\u6848\u3002</paragraph>\n", "author": "Maciej Besta et.al.", "authors": "Maciej Besta, Lorenzo Paleari, Jia Hao Andrea Jiang, Robert Gerstenberger, You Wu, Patrick Iff, Ales Kubicek, Piotr Nyczyk, Diana Khimey, J\u00f3n Gunnar Hannesson, Grzegorz Kwa\u015bniewski, Marcin Copik, Hubert Niewiadomski, Torsten Hoefler", "id": "2504.02670v1", "paper_url": "http://arxiv.org/abs/2504.02670v1", "repo": "null"}}