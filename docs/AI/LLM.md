
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-13**|**Agents in Software Engineering: Survey, Landscape, and Vision**|Yanxian Huang et.al.|[2409.09030v1](http://arxiv.org/abs/2409.09030v1)|[link](https://github.com/deepsoftwareanalytics/awesome-agent4se)|
|**2024-09-13**|**Towards Leveraging Contrastively Pretrained Neural Audio Embeddings for Recommender Tasks**|Florian Grötschla et.al.|[2409.09026v1](http://arxiv.org/abs/2409.09026v1)|null|
|**2024-09-13**|**AI-LieDar: Examine the Trade-off Between Utility and Truthfulness in LLM Agents**|Zhe Su et.al.|[2409.09013v1](http://arxiv.org/abs/2409.09013v1)|null|
|**2024-09-13**|**VAE Explainer: Supplement Learning Variational Autoencoders with Interactive Visualization**|Donald Bertucci et.al.|[2409.09011v1](http://arxiv.org/abs/2409.09011v1)|[link](https://github.com/xnought/vae-explainer)|
|**2024-09-13**|**Contri(e)ve: Context + Retrieve for Scholarly Question Answering**|Kanchan Shivashankar et.al.|[2409.09010v1](http://arxiv.org/abs/2409.09010v1)|null|
|**2024-09-13**|**Optimizing Rare Word Accuracy in Direct Speech Translation with a Retrieval-and-Demonstration Approach**|Siqi Li et.al.|[2409.09009v1](http://arxiv.org/abs/2409.09009v1)|[link](https://github.com/siqilii/retrieve-and-demonstration-st)|
|**2024-09-13**|**SGFormer: Single-Layer Graph Transformers with Approximation-Free Linear Complexity**|Qitian Wu et.al.|[2409.09007v1](http://arxiv.org/abs/2409.09007v1)|[link](https://github.com/qitianwu/sgformer)|
|**2024-09-13**|**E2MoCase: A Dataset for Emotional, Event and Moral Observations in News Articles on High-impact Legal Cases**|Candida M. Greco et.al.|[2409.09001v1](http://arxiv.org/abs/2409.09001v1)|null|
|**2024-09-13**|**Predicting Trust In Autonomous Vehicles: Modeling Young Adult Psychosocial Traits, Risk-Benefit Attitudes, And Driving Factors With Machine Learning**|Robert Kaufman et.al.|[2409.08980v1](http://arxiv.org/abs/2409.08980v1)|null|
|**2024-09-13**|**Safeguarding Decentralized Social Media: LLM Agents for Automating Community Rule Compliance**|Lucio La Cava et.al.|[2409.08963v1](http://arxiv.org/abs/2409.08963v1)|null|
|**2024-09-13**|**SynSUM -- Synthetic Benchmark with Structured and Unstructured Medical Records**|Paloma Rabaey et.al.|[2409.08936v1](http://arxiv.org/abs/2409.08936v1)|[link](https://github.com/prabaey/synsum)|
|**2024-09-13**|**Optimization and Generalization Guarantees for Weight Normalization**|Pedro Cisneros-Velarde et.al.|[2409.08935v1](http://arxiv.org/abs/2409.08935v1)|null|
|**2024-09-13**|**Yes, Prime Minister, question order does matter -- and it's certainly not classical! But is it quantum?**|Dorje C. Brody et.al.|[2409.08930v1](http://arxiv.org/abs/2409.08930v1)|null|
|**2024-09-13**|**XSub: Explanation-Driven Adversarial Attack against Blackbox Classifiers via Feature Substitution**|Kiana Vu et.al.|[2409.08919v1](http://arxiv.org/abs/2409.08919v1)|null|
|**2024-09-13**|**Latent Space Score-based Diffusion Model for Probabilistic Multivariate Time Series Imputation**|Guojun Liang et.al.|[2409.08917v1](http://arxiv.org/abs/2409.08917v1)|[link](https://github.com/gorgen2020/LSSDM_imputation)|
|**2024-09-13**|**Farmer.Chat: Scaling AI-Powered Agricultural Services for Smallholder Farmers**|Namita Singh et.al.|[2409.08916v1](http://arxiv.org/abs/2409.08916v1)|null|
|**2024-09-13**|**Affective Computing Has Changed: The Foundation Model Disruption**|Björn Schuller et.al.|[2409.08907v1](http://arxiv.org/abs/2409.08907v1)|null|
|**2024-09-13**|**AnyBipe: An End-to-End Framework for Training and Deploying Bipedal Robots Guided by Large Language Models**|Yifei Yao et.al.|[2409.08904v1](http://arxiv.org/abs/2409.08904v1)|null|
|**2024-09-13**|**Exploring Action-Centric Representations Through the Lens of Rate-Distortion Theory**|Miguel de Llanza Varona et.al.|[2409.08892v1](http://arxiv.org/abs/2409.08892v1)|null|
|**2024-09-13**|**Visual Language Tracking with Multi-modal Interaction: A Robust Benchmark**|Xuchen Li et.al.|[2409.08887v1](http://arxiv.org/abs/2409.08887v1)|null|
|**2024-09-13**|**Exploring the Impact of Data Quantity on ASR in Extremely Low-resource Languages**|Yao-Fei Cheng et.al.|[2409.08872v1](http://arxiv.org/abs/2409.08872v1)|null|
|**2024-09-13**|**Exploring Graph Structure Comprehension Ability of Multimodal Large Language Models: Case Studies**|Zhiqiang Zhong et.al.|[2409.08864v1](http://arxiv.org/abs/2409.08864v1)|null|
|**2024-09-13**|**Using The Concept Hierarchy for Household Action Recognition**|Andrei Costinescu et.al.|[2409.08853v1](http://arxiv.org/abs/2409.08853v1)|null|
|**2024-09-13**|**FP-VEC: Fingerprinting Large Language Models via Efficient Vector Addition**|Zhenhua Xu et.al.|[2409.08846v1](http://arxiv.org/abs/2409.08846v1)|null|
|**2024-09-13**|**AIPO: Improving Training Objective for Iterative Preference Optimization**|Yaojie Shen et.al.|[2409.08845v1](http://arxiv.org/abs/2409.08845v1)|null|
|**2024-09-13**|**A RAG Approach for Generating Competency Questions in Ontology Engineering**|Xueli Pan et.al.|[2409.08820v1](http://arxiv.org/abs/2409.08820v1)|null|
|**2024-09-13**|**Deep reinforcement learning for tracking a moving target in jellyfish-like swimming**|Yihao Chen et.al.|[2409.08815v1](http://arxiv.org/abs/2409.08815v1)|null|
|**2024-09-13**|**Your Weak LLM is Secretly a Strong Teacher for Alignment**|Leitian Tao et.al.|[2409.08813v1](http://arxiv.org/abs/2409.08813v1)|null|
|**2024-09-13**|**Mutual Theory of Mind in Human-AI Collaboration: An Empirical Study with LLM-driven AI Agents in a Real-time Shared Workspace Task**|Shao Zhang et.al.|[2409.08811v1](http://arxiv.org/abs/2409.08811v1)|null|
|**2024-09-13**|**TabKANet: Tabular Data Modelling with Kolmogorov-Arnold Network and Transformer**|Weihao Gao et.al.|[2409.08806v1](http://arxiv.org/abs/2409.08806v1)|[link](https://github.com/tsinghuamedgao20/tabkanet)|
|**2024-09-13**|**Exploring SSL Discrete Tokens for Multilingual ASR**|Mingyu Cui et.al.|[2409.08805v1](http://arxiv.org/abs/2409.08805v1)|null|
|**2024-09-13**|**Reading ability detection using eye-tracking data with LSTM-based few-shot learning**|Nanxi Li et.al.|[2409.08798v1](http://arxiv.org/abs/2409.08798v1)|null|
|**2024-09-13**|**Exploring SSL Discrete Speech Features for Zipformer-based Contextual ASR**|Mingyu Cui et.al.|[2409.08797v1](http://arxiv.org/abs/2409.08797v1)|[link](https://github.com/open-creator/icefall)|
|**2024-09-13**|**Optimizing Ingredient Substitution Using Large Language Models to Enhance Phytochemical Content in Recipes**|Luis Rita et.al.|[2409.08792v1](http://arxiv.org/abs/2409.08792v1)|null|
|**2024-09-13**|**Sign Language Sense Disambiguation**|Jana Grimm et.al.|[2409.08780v1](http://arxiv.org/abs/2409.08780v1)|[link](https://github.com/OvrK12/slt)|
|**2024-09-13**|**What You Say = What You Want? Teaching Humans to Articulate Requirements for LLMs**|Qianou Ma et.al.|[2409.08775v1](http://arxiv.org/abs/2409.08775v1)|null|
|**2024-09-13**|**HOLA-Drone: Hypergraphic Open-ended Learning for Zero-Shot Multi-Drone Cooperative Pursuit**|Yang Li et.al.|[2409.08767v1](http://arxiv.org/abs/2409.08767v1)|null|
|**2024-09-13**|**Journalists, Emotions, and the Introduction of Generative AI Chatbots: A Large-Scale Analysis of Tweets Before and After the Launch of ChatGPT**|Seth C. Lewis et.al.|[2409.08761v1](http://arxiv.org/abs/2409.08761v1)|null|
|**2024-09-13**|**Bridging Dynamic Factor Models and Neural Controlled Differential Equations for Nowcasting GDP**|Seonkyu Lim et.al.|[2409.08732v1](http://arxiv.org/abs/2409.08732v1)|[link](https://github.com/jeongwhanchoi/NCDENow)|
|**2024-09-13**|**Distilling Monolingual and Crosslingual Word-in-Context Representations**|Yuki Arase et.al.|[2409.08719v1](http://arxiv.org/abs/2409.08719v1)|[link](https://github.com/yukiar/distil_wic)|
|**2024-09-13**|**Text-To-Speech Synthesis In The Wild**|Jee-weon Jung et.al.|[2409.08711v1](http://arxiv.org/abs/2409.08711v1)|null|
|**2024-09-13**|**L3Cube-IndicQuest: A Benchmark Questing Answering Dataset for Evaluating Knowledge of LLMs in Indic Context**|Pritika Rohera et.al.|[2409.08706v1](http://arxiv.org/abs/2409.08706v1)|null|
|**2024-09-13**|**NeSHFS: Neighborhood Search with Heuristic-based Feature Selection for Click-Through Rate Prediction**|Dogukan Aksu et.al.|[2409.08703v1](http://arxiv.org/abs/2409.08703v1)|null|
|**2024-09-13**|**DM: Dual-path Magnitude Network for General Speech Restoration**|Da-Hee Yang et.al.|[2409.08702v1](http://arxiv.org/abs/2409.08702v1)|null|
|**2024-09-13**|**Precision Aquaculture: An Integrated Computer Vision and IoT Approach for Optimized Tilapia Feeding**|Rania Hossam et.al.|[2409.08695v1](http://arxiv.org/abs/2409.08695v1)|null|
|**2024-09-13**|**B4: Towards Optimal Assessment of Plausible Code Solutions with Plausible Tests**|Mouxiang Chen et.al.|[2409.08692v1](http://arxiv.org/abs/2409.08692v1)|[link](https://github.com/zju-ctag/b4)|
|**2024-09-13**|**NEST-RQ: Next Token Prediction for Speech Self-Supervised Pre-Training**|Minglun Han et.al.|[2409.08680v1](http://arxiv.org/abs/2409.08680v1)|null|
|**2024-09-13**|**Investigating Disentanglement in a Phoneme-level Speech Codec for Prosody Modeling**|Sotirios Karapiperis et.al.|[2409.08664v1](http://arxiv.org/abs/2409.08664v1)|null|
|**2024-09-13**|**CPL: Critical Planning Step Learning Boosts LLM Generalization in Reasoning Tasks**|Tianlong Wang et.al.|[2409.08642v1](http://arxiv.org/abs/2409.08642v1)|null|
|**2024-09-13**|**Improving Analog Neural Network Robustness: A Noise-Agnostic Approach with Explainable Regularizations**|Alice Duque et.al.|[2409.08633v1](http://arxiv.org/abs/2409.08633v1)|null|
|**2024-09-13**|**Sybil Detection using Graph Neural Networks**|Stuart Heeb et.al.|[2409.08631v1](http://arxiv.org/abs/2409.08631v1)|null|
|**2024-09-13**|**Deep learning-based shot-domain seismic deblending**|Jing Sun et.al.|[2409.08602v1](http://arxiv.org/abs/2409.08602v1)|null|
|**2024-09-13**|**LA-RAG:Enhancing LLM-based ASR Accuracy with Retrieval-Augmented Generation**|Shaojun Li et.al.|[2409.08597v1](http://arxiv.org/abs/2409.08597v1)|null|
|**2024-09-13**|**Large Language Model Can Transcribe Speech in Multi-Talker Scenarios with Versatile Instructions**|Lingwei Meng et.al.|[2409.08596v1](http://arxiv.org/abs/2409.08596v1)|null|
|**2024-09-13**|**Automatic Generation of Fast and Accurate Performance Models for Deep Neural Network Accelerators**|Konstantin Lübeck et.al.|[2409.08595v1](http://arxiv.org/abs/2409.08595v1)|null|
|**2024-09-13**|**LHQ-SVC: Lightweight and High Quality Singing Voice Conversion Modeling**|Yubo Huang et.al.|[2409.08583v1](http://arxiv.org/abs/2409.08583v1)|null|
|**2024-09-13**|**Molecular Graph Representation Learning via Structural Similarity Information**|Chengyu Yao et.al.|[2409.08580v1](http://arxiv.org/abs/2409.08580v1)|[link](https://github.com/yaoyao-yaoyao-cell/mssm-gnn)|
|**2024-09-13**|**Cracking the Code: Multi-domain LLM Evaluation on Real-World Professional Exams in Indonesia**|Fajri Koto et.al.|[2409.08564v1](http://arxiv.org/abs/2409.08564v1)|null|
|**2024-09-13**|**Expediting and Elevating Large Language Model Reasoning via Hidden Chain-of-Thought Decoding**|Tianqiao Liu et.al.|[2409.08561v1](http://arxiv.org/abs/2409.08561v1)|null|
|**2024-09-13**|**LLM-Powered Grapheme-to-Phoneme Conversion: Benchmark and Case Study**|Mahta Fetrat Qharabagh et.al.|[2409.08554v1](http://arxiv.org/abs/2409.08554v1)|null|
|**2024-09-13**|**ATFLRec: A Multimodal Recommender System with Audio-Text Fusion and Low-Rank Adaptation via Instruction-Tuned Large Language Model**|Zezheng Qin et.al.|[2409.08543v1](http://arxiv.org/abs/2409.08543v1)|null|
|**2024-09-13**|**SRE-CNN: A Spatiotemporal Rotation-Equivariant CNN for Cardiac Cine MR Imaging**|Yuliang Zhu et.al.|[2409.08537v1](http://arxiv.org/abs/2409.08537v1)|null|
|**2024-09-13**|**Integration of Mamba and Transformer -- MAT for Long-Short Range Time Series Forecasting with Application to Weather Dynamics**|Wenqing Zhang et.al.|[2409.08530v1](http://arxiv.org/abs/2409.08530v1)|null|
|**2024-09-13**|**Eir: Thai Medical Large Language Models**|Yutthakorn Thiprak et.al.|[2409.08523v1](http://arxiv.org/abs/2409.08523v1)|null|
|**2024-09-13**|**MAPX: An explainable model-agnostic framework for the detection of false information on social media networks**|Sarah Condran et.al.|[2409.08522v1](http://arxiv.org/abs/2409.08522v1)|[link](https://github.com/scondran/mapx_framework)|
|**2024-09-13**|**Apollo: Band-sequence Modeling for High-Quality Audio Restoration**|Kai Li et.al.|[2409.08514v1](http://arxiv.org/abs/2409.08514v1)|[link](https://github.com/jusperlee/apollo)|
|**2024-09-13**|**Sub-graph Based Diffusion Model for Link Prediction**|Hang Li et.al.|[2409.08487v1](http://arxiv.org/abs/2409.08487v1)|null|
|**2024-09-13**|**A BERT-Based Summarization approach for depression detection**|Hossein Salahshoor Gavalan et.al.|[2409.08483v1](http://arxiv.org/abs/2409.08483v1)|null|
|**2024-09-13**|**Exploring Information Retrieval Landscapes: An Investigation of a Novel Evaluation Techniques and Comparative Document Splitting Methods**|Esmaeil Narimissa et.al.|[2409.08479v1](http://arxiv.org/abs/2409.08479v1)|null|
|**2024-09-13**|**Integrating Neural Operators with Diffusion Models Improves Spectral Representation in Turbulence Modeling**|Vivek Oommen et.al.|[2409.08477v1](http://arxiv.org/abs/2409.08477v1)|[link](https://github.com/vivekoommen/NeuralOperator_DiffusionModel)|
|**2024-09-13**|**An Intent Modeling and Inference Framework for Autonomous and Remotely Piloted Aerial Systems**|Kesav Kaza et.al.|[2409.08472v1](http://arxiv.org/abs/2409.08472v1)|null|
|**2024-09-13**|**Explaining Datasets in Words: Statistical Models with Natural Language Parameters**|Ruiqi Zhong et.al.|[2409.08466v1](http://arxiv.org/abs/2409.08466v1)|[link](https://github.com/ruiqi-zhong/nlparam)|
|**2024-09-13**|**Input-to-State Stable Coupled Oscillator Networks for Closed-form Model-based Control in Latent Space**|Maximilian Stölzle et.al.|[2409.08439v1](http://arxiv.org/abs/2409.08439v1)|null|
|**2024-09-13**|**When Context Leads but Parametric Memory Follows in Large Language Models**|Yufei Tao et.al.|[2409.08435v1](http://arxiv.org/abs/2409.08435v1)|[link](https://github.com/PortNLP/WikiAtomic)|
|**2024-09-12**|**Knowledge Tagging with Large Language Model based Multi-Agent System**|Hang Li et.al.|[2409.08406v1](http://arxiv.org/abs/2409.08406v1)|null|
|**2024-09-12**|**Scores as Actions: a framework of fine-tuning diffusion models by continuous-time reinforcement learning**|Hanyang Zhao et.al.|[2409.08400v1](http://arxiv.org/abs/2409.08400v1)|null|
|**2024-09-12**|**Self-Supervised Inference of Agents in Trustless Environments**|Vladyslav Larin et.al.|[2409.08386v1](http://arxiv.org/abs/2409.08386v1)|null|
|**2024-09-12**|**Rethinking Prompting Strategies for Multi-Label Recognition with Partial Annotations**|Samyak Rawlekar et.al.|[2409.08381v1](http://arxiv.org/abs/2409.08381v1)|null|
|**2024-09-12**|**The Impact of Large Language Models on Open-source Innovation: Evidence from GitHub Copilot**|Doron Yeverechyahu et.al.|[2409.08379v1](http://arxiv.org/abs/2409.08379v1)|null|
|**2024-09-12**|**FedProphet: Memory-Efficient Federated Adversarial Training via Theoretic-Robustness and Low-Inconsistency Cascade Learning**|Minxue Tang et.al.|[2409.08372v1](http://arxiv.org/abs/2409.08372v1)|null|
|**2024-09-12**|**E-QUARTIC: Energy Efficient Edge Ensemble of Convolutional Neural Networks for Resource-Optimized Learning**|Le Zhang et.al.|[2409.08369v1](http://arxiv.org/abs/2409.08369v1)|null|
|**2024-09-12**|**An Experimental Study of Competitive Market Behavior Through LLMs**|Jingru Jia et.al.|[2409.08357v1](http://arxiv.org/abs/2409.08357v1)|null|
|**2024-09-12**|**Bayesian Inverse Graphics for Few-Shot Concept Learning**|Octavio Arriaga et.al.|[2409.08351v1](http://arxiv.org/abs/2409.08351v1)|null|
|**2024-09-12**|**Towards Quantifying and Reducing Language Mismatch Effects in Cross-Lingual Speech Anti-Spoofing**|Tianchi Liu et.al.|[2409.08346v1](http://arxiv.org/abs/2409.08346v1)|null|
|**2024-09-12**|**Real or Robotic? Assessing Whether LLMs Accurately Simulate Qualities of Human Responses in Dialogue**|Johnathan Ivey et.al.|[2409.08330v1](http://arxiv.org/abs/2409.08330v1)|[link](https://github.com/davidjurgens/human-llm-similarity)|
|**2024-09-12**|**AnySkin: Plug-and-play Skin Sensing for Robotic Touch**|Raunaq Bhirangi et.al.|[2409.08276v1](http://arxiv.org/abs/2409.08276v1)|null|
|**2024-09-12**|**Hand-Object Interaction Pretraining from Videos**|Himanshu Gaurav Singh et.al.|[2409.08273v1](http://arxiv.org/abs/2409.08273v1)|null|
|**2024-09-12**|**Windows Agent Arena: Evaluating Multi-Modal OS Agents at Scale**|Rogerio Bonatti et.al.|[2409.08264v2](http://arxiv.org/abs/2409.08264v2)|[link](https://github.com/microsoft/windowsagentarena)|
|**2024-09-12**|**LoRID: Low-Rank Iterative Diffusion for Adversarial Purification**|Geigh Zollicoffer et.al.|[2409.08255v1](http://arxiv.org/abs/2409.08255v1)|null|
|**2024-09-12**|**The Design of Informative Take-Over Requests for Semi-Autonomous Cyber-Physical Systems: Combining Spoken Language and Visual Icons in a Drone-Controller Setting**|Ashwini Gundappa et.al.|[2409.08253v2](http://arxiv.org/abs/2409.08253v2)|null|
|**2024-09-12**|**OmniQuery: Contextually Augmenting Captured Multimodal Memory to Enable Personal Question Answering**|Jiahao Nick Li et.al.|[2409.08250v1](http://arxiv.org/abs/2409.08250v1)|null|
|**2024-09-12**|**IFAdapter: Instance Feature Control for Grounded Text-to-Image Generation**|Yinwei Wu et.al.|[2409.08240v1](http://arxiv.org/abs/2409.08240v1)|null|
|**2024-09-12**|**Source2Synth: Synthetic Data Generation and Curation Grounded in Real Data Sources**|Alisia Lupidi et.al.|[2409.08239v1](http://arxiv.org/abs/2409.08239v1)|null|
|**2024-09-12**|**LLM Honeypot: Leveraging Large Language Models as Advanced Interactive Honeypot Systems**|Hakan T. Otal et.al.|[2409.08234v1](http://arxiv.org/abs/2409.08234v1)|[link](https://github.com/ai-in-complex-systems-lab/llm-honeypot)|
|**2024-09-12**|**CliquePH: Higher-Order Information for Graph Neural Networks through Persistent Homology on Clique Graphs**|Davide Buffelli et.al.|[2409.08217v1](http://arxiv.org/abs/2409.08217v1)|null|
|**2024-09-12**|**LT3SD: Latent Trees for 3D Scene Diffusion**|Quan Meng et.al.|[2409.08215v1](http://arxiv.org/abs/2409.08215v1)|null|
|**2024-09-12**|**What Makes a Maze Look Like a Maze?**|Joy Hsu et.al.|[2409.08202v1](http://arxiv.org/abs/2409.08202v1)|null|
|**2024-09-12**|**AudioBERT: Audio Knowledge Augmented Language Model**|Hyunjong Ok et.al.|[2409.08199v1](http://arxiv.org/abs/2409.08199v1)|[link](https://github.com/hj-ok/audiobert)|
|**2024-09-12**|**Fine-tuning Large Language Models for Entity Matching**|Aaron Steiner et.al.|[2409.08185v1](http://arxiv.org/abs/2409.08185v1)|[link](https://github.com/wbsg-uni-mannheim/tailormatch)|
|**2024-09-12**|**On the Role of Context in Reading Time Prediction**|Andreas Opedal et.al.|[2409.08160v1](http://arxiv.org/abs/2409.08160v1)|[link](https://github.com/rycolab/context-reading-time)|

#### Abstracts
##### **Agents in Software Engineering: Survey, Landscape, and Vision**
2409.09030v1 by Yanxian Huang, Wanjun Zhong, Ensheng Shi, Min Yang, Jiachi Chen, Hui Li, Yuchi Ma, Qianxiang Wang, Zibin Zheng, Yanlin Wang

In recent years, Large Language Models (LLMs) have achieved remarkable
success and have been widely used in various downstream tasks, especially in
the tasks of the software engineering (SE) field. We find that many studies
combining LLMs with SE have employed the concept of agents either explicitly or
implicitly. However, there is a lack of an in-depth survey to sort out the
development context of existing works, analyze how existing works combine the
LLM-based agent technologies to optimize various tasks, and clarify the
framework of LLM-based agents in SE. In this paper, we conduct the first survey
of the studies on combining LLM-based agents with SE and present a framework of
LLM-based agents in SE which includes three key modules: perception, memory,
and action. We also summarize the current challenges in combining the two
fields and propose future opportunities in response to existing challenges. We
maintain a GitHub repository of the related papers at:
https://github.com/DeepSoftwareAnalytics/Awesome-Agent4SE.

摘要：近年來，大型語言模型 (LLM) 已取得顯著的成功，並廣泛用於各種下游任務，特別是在軟體工程 (SE) 領域的任務中。我們發現許多結合 LLM 和 SE 的研究已經明確或隱含地採用了代理的概念。然而，缺乏深入的調查來整理現有工作的開發背景，分析現有工作如何結合基於 LLM 的代理技術來最佳化各種任務，並釐清 LLM 基於代理在 SE 中的架構。在本文中，我們對結合基於 LLM 的代理與 SE 的研究進行首次調查，並提出一個基於 LLM 的代理在 SE 中的架構，其中包含三個關鍵模組：感知、記憶和動作。我們也總結了結合這兩個領域的現有挑戰，並針對現有挑戰提出未來的機會。我們在 GitHub 儲存庫中維護相關論文：
https://github.com/DeepSoftwareAnalytics/Awesome-Agent4SE。

##### **Towards Leveraging Contrastively Pretrained Neural Audio Embeddings for Recommender Tasks**
2409.09026v1 by Florian Grötschla, Luca Strässle, Luca A. Lanzendörfer, Roger Wattenhofer

Music recommender systems frequently utilize network-based models to capture
relationships between music pieces, artists, and users. Although these
relationships provide valuable insights for predictions, new music pieces or
artists often face the cold-start problem due to insufficient initial
information. To address this, one can extract content-based information
directly from the music to enhance collaborative-filtering-based methods. While
previous approaches have relied on hand-crafted audio features for this
purpose, we explore the use of contrastively pretrained neural audio embedding
models, which offer a richer and more nuanced representation of music. Our
experiments demonstrate that neural embeddings, particularly those generated
with the Contrastive Language-Audio Pretraining (CLAP) model, present a
promising approach to enhancing music recommendation tasks within graph-based
frameworks.

摘要：音樂推薦系統經常使用基於網路的模型來擷取音樂作品、藝術家和使用者之間的關係。儘管這些關係為預測提供了有價值的見解，但由於初始資訊不足，新的音樂作品或藝術家經常面臨冷啟動問題。為了解決這個問題，可以從音樂中直接擷取基於內容的資訊，以增強基於協同過濾的方法。雖然先前的做法已依賴手工製作的音訊特徵來達成此目的，但我們探索使用對比預訓練神經音訊嵌入模型，這提供了更豐富且更細緻的音樂表示。我們的實驗證明了神經嵌入，特別是使用對比語言音訊預訓練 (CLAP) 模型產生的嵌入，展示了一種有前景的方法，可以用於增強圖形化框架中的音樂推薦任務。

##### **AI-LieDar: Examine the Trade-off Between Utility and Truthfulness in LLM Agents**
2409.09013v1 by Zhe Su, Xuhui Zhou, Sanketh Rangreji, Anubha Kabra, Julia Mendelsohn, Faeze Brahman, Maarten Sap

To be safely and successfully deployed, LLMs must simultaneously satisfy
truthfulness and utility goals. Yet, often these two goals compete (e.g., an AI
agent assisting a used car salesman selling a car with flaws), partly due to
ambiguous or misleading user instructions. We propose AI-LieDar, a framework to
study how LLM-based agents navigate scenarios with utility-truthfulness
conflicts in a multi-turn interactive setting. We design a set of realistic
scenarios where language agents are instructed to achieve goals that are in
conflict with being truthful during a multi-turn conversation with simulated
human agents. To evaluate the truthfulness at large scale, we develop a
truthfulness detector inspired by psychological literature to assess the
agents' responses. Our experiment demonstrates that all models are truthful
less than 50% of the time, although truthfulness and goal achievement (utility)
rates vary across models. We further test the steerability of LLMs towards
truthfulness, finding that models follow malicious instructions to deceive, and
even truth-steered models can still lie. These findings reveal the complex
nature of truthfulness in LLMs and underscore the importance of further
research to ensure the safe and reliable deployment of LLMs and AI agents.

摘要：為了安全且成功地部署 LLM，必須同時滿足真實性和實用性目標。然而，這兩個目標通常會相互競爭（例如，AI 代理協助二手車銷售員銷售有缺陷的汽車），部分原因是使用者說明模稜兩可或具有誤導性。我們提出 AI-LieDar，一個架構用於研究基於 LLM 的代理如何應對多輪互動設定中實用性真實性衝突的場景。我們設計了一組逼真的場景，其中語言代理被指示在與模擬人類代理的多輪對話中實現與真實性相衝突的目標。為了大規模評估真實性，我們開發了一個受心理學文獻啟發的真實性偵測器，用於評估代理的反應。我們的實驗表明，所有模型的真實性低於 50%，儘管真實性和目標達成（實用性）率因模型而異。我們進一步測試了 LLM 對真實性的可控性，發現模型遵循惡意指令進行欺騙，即使是真實性導向的模型仍然可能說謊。這些發現揭示了 LLM 中真實性的複雜本質，並強調了進一步研究以確保 LLM 和 AI 代理安全可靠部署的重要性。

##### **VAE Explainer: Supplement Learning Variational Autoencoders with Interactive Visualization**
2409.09011v1 by Donald Bertucci, Alex Endert

Variational Autoencoders are widespread in Machine Learning, but are
typically explained with dense math notation or static code examples. This
paper presents VAE Explainer, an interactive Variational Autoencoder running in
the browser to supplement existing static documentation (e.g., Keras Code
Examples). VAE Explainer adds interactions to the VAE summary with interactive
model inputs, latent space, and output. VAE Explainer connects the high-level
understanding with the implementation: annotated code and a live computational
graph. The VAE Explainer interactive visualization is live at
https://xnought.github.io/vae-explainer and the code is open source at
https://github.com/xnought/vae-explainer.

摘要：變異式自動編碼器在機器學習中廣泛使用，但通常以密集的數學符號或靜態程式碼範例來解釋。本文介紹 VAE Explainer，一個互動式變異式自動編碼器，在瀏覽器中執行，以補充現有的靜態文件（例如 Keras 程式碼範例）。VAE Explainer 將互動加入 VAE 摘要，包含互動式模型輸入、潛在空間和輸出。VAE Explainer 將高層級理解與實作連結：註解程式碼和即時運算圖。VAE Explainer 互動式視覺化可在 https://xnought.github.io/vae-explainer 看到，而程式碼在 https://github.com/xnought/vae-explainer 開放原始碼。

##### **Contri(e)ve: Context + Retrieve for Scholarly Question Answering**
2409.09010v1 by Kanchan Shivashankar, Nadine Steinmetz

Scholarly communication is a rapid growing field containing a wealth of
knowledge. However, due to its unstructured and document format, it is
challenging to extract useful information from them through conventional
document retrieval methods. Scholarly knowledge graphs solve this problem, by
representing the documents in a semantic network, providing, hidden insights,
summaries and ease of accessibility through queries. Naturally, question
answering for scholarly graphs expands the accessibility to a wider audience.
But some of the knowledge in this domain is still presented as unstructured
text, thus requiring a hybrid solution for question answering systems. In this
paper, we present a two step solution using open source Large Language
Model(LLM): Llama3.1 for Scholarly-QALD dataset. Firstly, we extract the
context pertaining to the question from different structured and unstructured
data sources: DBLP, SemOpenAlex knowledge graphs and Wikipedia text. Secondly,
we implement prompt engineering to improve the information retrieval
performance of the LLM. Our approach achieved an F1 score of 40% and also
observed some anomalous responses from the LLM, that are discussed in the final
part of the paper.

摘要：學術交流是一個快速成長的領域，包含了豐富的知識。然而，由於其非結構化和文件格式，透過傳統的文件檢索方法很難從中萃取出有用的資訊。學術知識圖譜解決了這個問題，它以語義網路呈現文件，提供隱藏的見解、摘要和透過查詢輕鬆存取。自然地，學術圖譜的問答擴展了對更廣泛受眾的存取性。但這個領域中的一些知識仍然以非結構化文字呈現，因此需要一個混合解決方案來進行問答系統。在本文中，我們提出了一個使用開放原始碼大型語言模型 (LLM) 的兩步驟解決方案：Llama3.1 for Scholarly-QALD 資料集。首先，我們從不同的結構化和非結構化資料來源中萃取與問題相關的脈絡：DBLP、SemOpenAlex 知識圖譜和維基百科文字。其次，我們實作提示工程以改善 LLM 的資訊檢索效能。我們的做法達到了 40% 的 F1 分數，並且也觀察到 LLM 的一些異常回應，這些回應在本文的最後一部分中進行了討論。

##### **Optimizing Rare Word Accuracy in Direct Speech Translation with a Retrieval-and-Demonstration Approach**
2409.09009v1 by Siqi Li, Danni Liu, Jan Niehues

Direct speech translation (ST) models often struggle with rare words.
Incorrect translation of these words can have severe consequences, impacting
translation quality and user trust. While rare word translation is inherently
challenging for neural models due to sparse learning signals, real-world
scenarios often allow access to translations of past recordings on similar
topics. To leverage these valuable resources, we propose a
retrieval-and-demonstration approach to enhance rare word translation accuracy
in direct ST models. First, we adapt existing ST models to incorporate
retrieved examples for rare word translation, which allows the model to benefit
from prepended examples, similar to in-context learning. We then develop a
cross-modal (speech-to-speech, speech-to-text, text-to-text) retriever to
locate suitable examples. We demonstrate that standard ST models can be
effectively adapted to leverage examples for rare word translation, improving
rare word translation accuracy over the baseline by 17.6% with gold examples
and 8.5% with retrieved examples. Moreover, our speech-to-speech retrieval
approach outperforms other modalities and exhibits higher robustness to unseen
speakers. Our code is publicly available
(https://github.com/SiqiLii/Retrieve-and-Demonstration-ST).

摘要：直译 (ST) 模型通常难以处理罕见字词。
这些字词翻译不正确可能会造成严重后果，影响翻译品质和使用者信任。虽然罕见字词翻译对神经模型来说本来就具有挑战性，因为学习信号稀疏，但现实世界的情境通常可以存取类似主题过去录音的翻译。为了善用这些有价值的资源，我们提出一种撷取与示范方法来提升直接 ST 模型中罕见字词翻译的准确度。首先，我们调整现有的 ST 模型，纳入罕见字词翻译的撷取范例，让模型能够受益于前置范例，类似于语境学习。然后，我们开发一个跨模态（语音转语音、语音转文字、文字转文字）撷取器来找出合适的范例。我们示范标准 ST 模型可以有效地调整来善用罕见字词翻译的范例，以黄金范例提升罕见字词翻译准确度 17.6%，以撷取范例提升 8.5%。此外，我们的语音转语音撷取方法优于其他模态，且对未见过的说话者展现出更高的稳健性。我们的代码已公开（https://github.com/SiqiLii/Retrieve-and-Demonstration-ST）。

##### **SGFormer: Single-Layer Graph Transformers with Approximation-Free Linear Complexity**
2409.09007v1 by Qitian Wu, Kai Yang, Hengrui Zhang, David Wipf, Junchi Yan

Learning representations on large graphs is a long-standing challenge due to
the inter-dependence nature. Transformers recently have shown promising
performance on small graphs thanks to its global attention for capturing
all-pair interactions beyond observed structures. Existing approaches tend to
inherit the spirit of Transformers in language and vision tasks, and embrace
complicated architectures by stacking deep attention-based propagation layers.
In this paper, we attempt to evaluate the necessity of adopting multi-layer
attentions in Transformers on graphs, which considerably restricts the
efficiency. Specifically, we analyze a generic hybrid propagation layer,
comprised of all-pair attention and graph-based propagation, and show that
multi-layer propagation can be reduced to one-layer propagation, with the same
capability for representation learning. It suggests a new technical path for
building powerful and efficient Transformers on graphs, particularly through
simplifying model architectures without sacrificing expressiveness. As
exemplified by this work, we propose a Simplified Single-layer Graph
Transformers (SGFormer), whose main component is a single-layer global
attention that scales linearly w.r.t. graph sizes and requires none of any
approximation for accommodating all-pair interactions. Empirically, SGFormer
successfully scales to the web-scale graph ogbn-papers100M, yielding
orders-of-magnitude inference acceleration over peer Transformers on
medium-sized graphs, and demonstrates competitiveness with limited labeled
data.

摘要：在大型圖表上學習表徵由於相互依賴的性質而成為一項長期的挑戰。由於 Transfomer 能夠針對所有成對互動進行全局關注，超越觀測結構，因此最近在小型圖表上展現出令人滿意的效能。現有的方法傾向於繼承 Transformer 在語言和視覺任務中的精神，並通過堆疊基於深度關注的傳播層來採用複雜的架構。在本文中，我們嘗試評估在圖表上採用多層注意力 Transformer 的必要性，這極大地限制了效率。具體來說，我們分析了一個通用的混合傳播層，它包含所有成對注意力和基於圖表的傳播，並表明多層傳播可以簡化為單層傳播，具有相同的表徵學習能力。這為在圖表上構建強大而高效的 Transformer 提供了一條新的技術路徑，特別是通過簡化模型架構，而無需犧牲表達能力。正如這項工作所例證的，我們提出了一個簡化的單層圖形 Transformer (SGFormer)，其主要組成部分是一個單層全局注意力，它與圖形大小成線性比例，並且不需要任何近似來適應所有成對互動。根據經驗，SGFormer 成功地擴展到網路規模的圖表 ogbn-papers100M，在中等大小的圖表上產生了比同儕 Transformer 快幾個數量級的推論加速，並證明了在標籤資料有限的情況下具有競爭力。

##### **E2MoCase: A Dataset for Emotional, Event and Moral Observations in News Articles on High-impact Legal Cases**
2409.09001v1 by Candida M. Greco, Lorenzo Zangari, Davide Picca, Andrea Tagarelli

The way media reports on legal cases can significantly shape public opinion,
often embedding subtle biases that influence societal views on justice and
morality. Analyzing these biases requires a holistic approach that captures the
emotional tone, moral framing, and specific events within the narratives. In
this work we introduce E2MoCase, a novel dataset designed to facilitate the
integrated analysis of emotions, moral values, and events within legal
narratives and media coverage. By leveraging advanced models for emotion
detection, moral value identification, and event extraction, E2MoCase offers a
multi-dimensional perspective on how legal cases are portrayed in news
articles.

摘要：媒體報導法律案件的方式會顯著影響輿論，
通常會嵌入微妙的偏見，影響社會對正義和道德的觀點。
分析這些偏見需要一種整體方法，這種方法捕捉敘述中的情緒語氣、道德框架和具體事件。
在這項工作中，我們引入了 E2MoCase，這是一個新穎的數據集，旨在促進對法律敘述和媒體報導中情緒、道德價值觀和事件的綜合分析。
通過利用先進的情緒檢測模型、道德價值觀識別和事件提取，E2MoCase 提供了一個多維度的視角，說明新聞文章中如何描繪法律案件。

##### **Predicting Trust In Autonomous Vehicles: Modeling Young Adult Psychosocial Traits, Risk-Benefit Attitudes, And Driving Factors With Machine Learning**
2409.08980v1 by Robert Kaufman, Emi Lee, Manas Satish Bedmutha, David Kirsh, Nadir Weibel

Low trust remains a significant barrier to Autonomous Vehicle (AV) adoption.
To design trustworthy AVs, we need to better understand the individual traits,
attitudes, and experiences that impact people's trust judgements. We use
machine learning to understand the most important factors that contribute to
young adult trust based on a comprehensive set of personal factors gathered via
survey (n = 1457). Factors ranged from psychosocial and cognitive attributes to
driving style, experiences, and perceived AV risks and benefits. Using the
explainable AI technique SHAP, we found that perceptions of AV risks and
benefits, attitudes toward feasibility and usability, institutional trust,
prior experience, and a person's mental model are the most important
predictors. Surprisingly, psychosocial and many technology- and
driving-specific factors were not strong predictors. Results highlight the
importance of individual differences for designing trustworthy AVs for diverse
groups and lead to key implications for future design and research.

摘要：低信任度仍然是自動駕駛車輛 (AV) 普及的重要障礙。
為了設計值得信賴的自動駕駛車輛，我們需要更深入地了解影響人們信任判斷的個人特質、
態度和經驗。我們使用機器學習來了解對年輕人信任度影響最大的因素，這些因素是根據
透過調查收集的個人因素全面設定（n = 1457）。這些因素範圍從心理社會和認知屬性到
駕駛風格、經驗和認知的自動駕駛車輛風險和優點。使用可解釋的 AI 技術 SHAP，我們發現
認知自動駕駛車輛風險和優點、對可行性和可用性的態度、機構信任、先前經驗和個人的心智模式
是最重要的預測因子。令人驚訝的是，心理社會和許多技術和駕駛特定因素並非強有力的預測因子。
結果突顯了個人差異對於為不同群體設計值得信賴的自動駕駛車輛的重要性，並對未來的設計和研究產生了
關鍵影響。

##### **Safeguarding Decentralized Social Media: LLM Agents for Automating Community Rule Compliance**
2409.08963v1 by Lucio La Cava, Andrea Tagarelli

Ensuring content compliance with community guidelines is crucial for
maintaining healthy online social environments. However, traditional
human-based compliance checking struggles with scaling due to the increasing
volume of user-generated content and a limited number of moderators. Recent
advancements in Natural Language Understanding demonstrated by Large Language
Models unlock new opportunities for automated content compliance verification.
This work evaluates six AI-agents built on Open-LLMs for automated rule
compliance checking in Decentralized Social Networks, a challenging environment
due to heterogeneous community scopes and rules. Analyzing over 50,000 posts
from hundreds of Mastodon servers, we find that AI-agents effectively detect
non-compliant content, grasp linguistic subtleties, and adapt to diverse
community contexts. Most agents also show high inter-rater reliability and
consistency in score justification and suggestions for compliance. Human-based
evaluation with domain experts confirmed the agents' reliability and
usefulness, rendering them promising tools for semi-automated or
human-in-the-loop content moderation systems.

摘要：確保內容符合社群規範對於維持健康的線上社群環境至關重要。然而，傳統的人工合規檢查在面對大量使用者產生的內容和有限的管理員人數時，難以擴展。大型語言模型所展現的自然語言理解技術的最新進展，為自動化內容合規驗證開啟了新的契機。這項研究評估了六個建立在開放大型語言模型上的 AI 代理，以進行去中心化社群網路中的自動化規則合規檢查，由於社群範圍和規則的異質性，這是一個具有挑戰性的環境。我們分析了來自數百個 Mastodon 伺服器的 50,000 多則貼文，發現 AI 代理可以有效偵測不合規的內容、掌握語言的細微差別，並適應不同的社群脈絡。大多數代理在評分理由和合規建議方面也展現出很高的評分者間信賴度和一致性。與領域專家的合作評估證實了這些代理的可靠性和實用性，使其成為半自動化或人機協作內容審核系統中很有前景的工具。

##### **SynSUM -- Synthetic Benchmark with Structured and Unstructured Medical Records**
2409.08936v1 by Paloma Rabaey, Henri Arno, Stefan Heytens, Thomas Demeester

We present the SynSUM benchmark, a synthetic dataset linking unstructured
clinical notes to structured background variables. The dataset consists of
10,000 artificial patient records containing tabular variables (like symptoms,
diagnoses and underlying conditions) and related notes describing the fictional
patient encounter in the domain of respiratory diseases. The tabular portion of
the data is generated through a Bayesian network, where both the causal
structure between the variables and the conditional probabilities are proposed
by an expert based on domain knowledge. We then prompt a large language model
(GPT-4o) to generate a clinical note related to this patient encounter,
describing the patient symptoms and additional context. The SynSUM dataset is
primarily designed to facilitate research on clinical information extraction in
the presence of tabular background variables, which can be linked through
domain knowledge to concepts of interest to be extracted from the text - the
symptoms, in the case of SynSUM. Secondary uses include research on the
automation of clinical reasoning over both tabular data and text, causal effect
estimation in the presence of tabular and/or textual confounders, and
multi-modal synthetic data generation. The dataset can be downloaded from
https://github.com/prabaey/SynSUM.

摘要：我們提出 SynSUM 基準，一個將非結構化臨床記錄連結到結構化背景變數的合成資料集。該資料集包含 10,000 個人工病歷，其中包含表格變數（例如症狀、診斷和潛在狀況）和相關記錄，描述了呼吸系統疾病領域中的虛構患者遭遇。資料的表格部分是透過貝氏網路產生的，其中變數之間的因果結構和條件機率都是由專家根據領域知識提出的。然後，我們提示一個大型語言模型 (GPT-4o) 產生與此患者遭遇相關的臨床記錄，描述患者症狀和額外背景。SynSUM 資料集主要是為了促進在表格背景變數存在的情況下進行臨床資訊萃取的研究，這些變數可以透過領域知識連結到從文本中萃取的目標概念 - 在 SynSUM 的案例中，是症狀。次要用途包括研究表格資料和文本的臨床推理自動化、在表格和/或文本混淆因子存在的情況下進行因果效應估計，以及多模式合成資料生成。此資料集可從 https://github.com/prabaey/SynSUM 下載。

##### **Optimization and Generalization Guarantees for Weight Normalization**
2409.08935v1 by Pedro Cisneros-Velarde, Zhijie Chen, Sanmi Koyejo, Arindam Banerjee

Weight normalization (WeightNorm) is widely used in practice for the training
of deep neural networks and modern deep learning libraries have built-in
implementations of it. In this paper, we provide the first theoretical
characterizations of both optimization and generalization of deep WeightNorm
models with smooth activation functions. For optimization, from the form of the
Hessian of the loss, we note that a small Hessian of the predictor leads to a
tractable analysis. Thus, we bound the spectral norm of the Hessian of
WeightNorm networks and show its dependence on the network width and weight
normalization terms--the latter being unique to networks without WeightNorm.
Then, we use this bound to establish training convergence guarantees under
suitable assumptions for gradient decent. For generalization, we use WeightNorm
to get a uniform convergence based generalization bound, which is independent
from the width and depends sublinearly on the depth. Finally, we present
experimental results which illustrate how the normalization terms and other
quantities of theoretical interest relate to the training of WeightNorm
networks.

摘要：權重正規化 (WeightNorm) 在深度神經網路的訓練中廣泛使用，而現代深度學習函式庫也內建了它的實作。在這篇論文中，我們提供了使用平滑啟用函數的深度 WeightNorm 模型的最佳化和泛化的第一個理論特徵。對於最佳化，從損失的 Hessian 形式，我們注意到預測器的 Hessian 很小會導致一個易於處理的分析。因此，我們約束了 WeightNorm 網路的 Hessian 的譜範數，並展示了它對網路寬度和權重正規化項的依賴性，後者是沒有 WeightNorm 網路獨有的。然後，我們使用這個約束在梯度下降的適當假設下建立訓練收斂保證。對於泛化，我們使用 WeightNorm 獲得一個基於均勻收斂的泛化約束，它與寬度無關，並且與深度呈次線性依賴。最後，我們提供了實驗結果，說明正規化項和理論上其他有趣量如何與 WeightNorm 網路的訓練相關。

##### **Yes, Prime Minister, question order does matter -- and it's certainly not classical! But is it quantum?**
2409.08930v1 by Dorje C. Brody

Response to a poll can be manipulated by means of a series of leading
questions. We show that such phenomena cannot be explained by use of classical
probability theory, whereas quantum probability theory admits a possibility of
offering an explanation. Admissible transformation rules in quantum
probability, however, do impose some constraints on the modelling of cognitive
behaviour, which are highlighted here. Focusing on a recent poll conducted by
Ipsos on a set of questions posed by Sir Humphrey Appleby in an episode of the
British political satire \textit{Yes, Prime Minister}, we show that the
resulting data cannot be explained quite so simply using quantum rules,
although it seems not impossible.

摘要：透過一系列引導性問題，可以操縱民意調查的回應。我們表明，此類現象無法透過使用古典機率論來解釋，而量子機率論則有可能提供解釋。然而，量子機率中允許的轉換規則確實對認知行為的建模施加了一些限制，本文將重點說明這些限制。針對 Ipsos 最近針對英國政治諷刺劇《首相，閣下》中 Humphrey Appleby 爵士提出的一系列問題所進行的民意調查，我們表明，儘管看似並非不可能，但所得資料無法僅使用量子規則來解釋。

##### **XSub: Explanation-Driven Adversarial Attack against Blackbox Classifiers via Feature Substitution**
2409.08919v1 by Kiana Vu, Phung Lai, Truc Nguyen

Despite its significant benefits in enhancing the transparency and
trustworthiness of artificial intelligence (AI) systems, explainable AI (XAI)
has yet to reach its full potential in real-world applications. One key
challenge is that XAI can unintentionally provide adversaries with insights
into black-box models, inevitably increasing their vulnerability to various
attacks. In this paper, we develop a novel explanation-driven adversarial
attack against black-box classifiers based on feature substitution, called
XSub. The key idea of XSub is to strategically replace important features
(identified via XAI) in the original sample with corresponding important
features from a "golden sample" of a different label, thereby increasing the
likelihood of the model misclassifying the perturbed sample. The degree of
feature substitution is adjustable, allowing us to control how much of the
original samples information is replaced. This flexibility effectively balances
a trade-off between the attacks effectiveness and its stealthiness. XSub is
also highly cost-effective in that the number of required queries to the
prediction model and the explanation model in conducting the attack is in O(1).
In addition, XSub can be easily extended to launch backdoor attacks in case the
attacker has access to the models training data. Our evaluation demonstrates
that XSub is not only effective and stealthy but also cost-effective, enabling
its application across a wide range of AI models.

摘要：儘管可解釋 AI (XAI) 在提升人工智慧 (AI) 系統的透明度和可信度方面有顯著的優點，但 XAI 尚未在實際應用中發揮其全部潛力。一個關鍵的挑戰在於，XAI 可能無意間讓對手深入了解黑盒模型，這不可避免地會增加其遭受各種攻擊的脆弱性。在本文中，我們針對基於特徵替換的黑盒分類器開發了一種新穎的由解釋驅動的對抗性攻擊，稱為 XSub。XSub 的關鍵思想是策略性地用來自不同標籤的「黃金樣本」中對應的重要特徵來替換原始樣本中的重要特徵（透過 XAI 識別），從而增加模型對擾動樣本進行錯誤分類的可能性。特徵替換的程度是可以調整的，這讓我們能夠控制替換多少原始樣本資訊。這種靈活性有效地平衡了攻擊的有效性與隱蔽性之間的折衷。XSub 也非常具有成本效益，因為在進行攻擊時，對預測模型和解釋模型所需的查詢數量為 O(1)。此外，如果攻擊者可以存取模型的訓練資料，XSub 可以輕鬆地擴充套件以發動後門攻擊。我們的評估證明，XSub 不僅有效且隱蔽，而且具有成本效益，使其能夠應用於廣泛的 AI 模型。

##### **Latent Space Score-based Diffusion Model for Probabilistic Multivariate Time Series Imputation**
2409.08917v1 by Guojun Liang, Najmeh Abiri, Atiye Sadat Hashemi, Jens Lundström, Stefan Byttner, Prayag Tiwari

Accurate imputation is essential for the reliability and success of
downstream tasks. Recently, diffusion models have attracted great attention in
this field. However, these models neglect the latent distribution in a
lower-dimensional space derived from the observed data, which limits the
generative capacity of the diffusion model. Additionally, dealing with the
original missing data without labels becomes particularly problematic. To
address these issues, we propose the Latent Space Score-Based Diffusion Model
(LSSDM) for probabilistic multivariate time series imputation. Observed values
are projected onto low-dimensional latent space and coarse values of the
missing data are reconstructed without knowing their ground truth values by
this unsupervised learning approach. Finally, the reconstructed values are fed
into a conditional diffusion model to obtain the precise imputed values of the
time series. In this way, LSSDM not only possesses the power to identify the
latent distribution but also seamlessly integrates the diffusion model to
obtain the high-fidelity imputed values and assess the uncertainty of the
dataset. Experimental results demonstrate that LSSDM achieves superior
imputation performance while also providing a better explanation and
uncertainty analysis of the imputation mechanism. The website of the code is
\textit{https://github.com/gorgen2020/LSSDM\_imputation}.

摘要：精確的插補對於下游任務的可靠性和成功至關重要。最近，擴散模型在這個領域引起了極大的關注。然而，這些模型忽略了從觀測資料中衍生的低維空間中的潛在分佈，這限制了擴散模型的生成能力。此外，處理沒有標籤的原始遺失資料變得特別有問題。為了解決這些問題，我們提出了用於機率多變量時間序列插補的潛在空間基於分數的擴散模型 (LSSDM)。觀測值被投影到低維潛在空間，並且透過這種非監督式學習方法，在不知道遺失資料的真實值的情況下重建遺失資料的粗略值。最後，將重建值輸入條件擴散模型，以取得時間序列的精確插補值。透過這種方式，LSSDM 不僅具備識別潛在分佈的能力，而且還無縫地整合擴散模型，以取得高保真插補值並評估資料集的不確定性。實驗結果表明，LSSDM 達到了卓越的插補效能，同時也提供了插補機制的更佳說明和不確定性分析。程式碼的網站是 \textit{https://github.com/gorgen2020/LSSDM\_imputation}。

##### **Farmer.Chat: Scaling AI-Powered Agricultural Services for Smallholder Farmers**
2409.08916v1 by Namita Singh, Jacqueline Wang'ombe, Nereah Okanga, Tetyana Zelenska, Jona Repishti, Jayasankar G K, Sanjeev Mishra, Rajsekar Manokaran, Vineet Singh, Mohammed Irfan Rafiq, Rikin Gandhi, Akshay Nambi

Small and medium-sized agricultural holders face challenges like limited
access to localized, timely information, impacting productivity and
sustainability. Traditional extension services, which rely on in-person agents,
struggle with scalability and timely delivery, especially in remote areas. We
introduce Farmer.Chat, a generative AI-powered chatbot designed to address
these issues. Leveraging Generative AI, Farmer.Chat offers personalized,
reliable, and contextually relevant advice, overcoming limitations of previous
chatbots in deterministic dialogue flows, language support, and unstructured
data processing. Deployed in four countries, Farmer.Chat has engaged over
15,000 farmers and answered over 300,000 queries. This paper highlights how
Farmer.Chat's innovative use of GenAI enhances agricultural service scalability
and effectiveness. Our evaluation, combining quantitative analysis and
qualitative insights, highlights Farmer.Chat's effectiveness in improving
farming practices, enhancing trust, response quality, and user engagement.

摘要：小型和中型的農業經營者面臨著諸如無法獲取在地化、及時的資訊等挑戰，這影響了生產力和永續性。傳統的推廣服務依賴於親自代理，在可擴充性和及時交付方面遇到困難，尤其是在偏遠地區。我們引入了 Farmer.Chat，這是一個由生成式 AI 驅動的聊天機器人，旨在解決這些問題。利用生成式 AI，Farmer.Chat 提供個性化、可靠且與情境相關的建議，克服了先前聊天機器人在確定性對話流程、語言支援和非結構化資料處理方面的限制。Farmer.Chat 已在四個國家/地區部署，已吸引超過 15,000 名農民，並回答了超過 300,000 個查詢。本文重點介紹 Farmer.Chat 如何創新地使用 GenAI 來提升農業服務的可擴充性和有效性。我們的評估結合了量化分析和定性見解，強調了 Farmer.Chat 在改善農業實務、提升信任度、回應品質和使用者參與方面的有效性。

##### **Affective Computing Has Changed: The Foundation Model Disruption**
2409.08907v1 by Björn Schuller, Adria Mallol-Ragolta, Alejandro Peña Almansa, Iosif Tsangko, Mostafa M. Amin, Anastasia Semertzidou, Lukas Christ, Shahin Amiriparian

The dawn of Foundation Models has on the one hand revolutionised a wide range
of research problems, and, on the other hand, democratised the access and use
of AI-based tools by the general public. We even observe an incursion of these
models into disciplines related to human psychology, such as the Affective
Computing domain, suggesting their affective, emerging capabilities. In this
work, we aim to raise awareness of the power of Foundation Models in the field
of Affective Computing by synthetically generating and analysing multimodal
affective data, focusing on vision, linguistics, and speech (acoustics). We
also discuss some fundamental problems, such as ethical issues and regulatory
aspects, related to the use of Foundation Models in this research area.

摘要：基礎模型的興起一方面徹底改變了廣泛的研究問題，另一方面也讓一般大眾能民主化地存取和使用基於 AI 的工具。我們甚至觀察到這些模型進入了與人類心理學相關的領域，例如情感運算領域，這表明它們的情感和新興能力。在這項工作中，我們旨在通過綜合生成和分析多模態情感數據，專注於視覺、語言和語音（聲學），提高基礎模型在情感運算領域的力量的認識。我們還討論了一些基本問題，例如倫理問題和監管方面，這些問題與在這個研究領域中使用基礎模型有關。

##### **AnyBipe: An End-to-End Framework for Training and Deploying Bipedal Robots Guided by Large Language Models**
2409.08904v1 by Yifei Yao, Wentao He, Chenyu Gu, Jiaheng Du, Fuwei Tan, Zhen Zhu, Junguo Lu

Training and deploying reinforcement learning (RL) policies for robots,
especially in accomplishing specific tasks, presents substantial challenges.
Recent advancements have explored diverse reward function designs, training
techniques, simulation-to-reality (sim-to-real) transfers, and performance
analysis methodologies, yet these still require significant human intervention.
This paper introduces an end-to-end framework for training and deploying RL
policies, guided by Large Language Models (LLMs), and evaluates its
effectiveness on bipedal robots. The framework consists of three interconnected
modules: an LLM-guided reward function design module, an RL training module
leveraging prior work, and a sim-to-real homomorphic evaluation module. This
design significantly reduces the need for human input by utilizing only
essential simulation and deployment platforms, with the option to incorporate
human-engineered strategies and historical data. We detail the construction of
these modules, their advantages over traditional approaches, and demonstrate
the framework's capability to autonomously develop and refine controlling
strategies for bipedal robot locomotion, showcasing its potential to operate
independently of human intervention.

摘要：訓練和部署機器人的強化學習 (RL) 政策，特別是在完成特定任務時，會帶來重大的挑戰。最近的進展探索了多樣化的獎勵函數設計、訓練技術、模擬到現實 (sim-to-real) 轉移和效能分析方法，但這些仍然需要大量的人工介入。本文介紹了一個端到端的框架，用於訓練和部署 RL 政策，由大型語言模型 (LLM) 指導，並評估其在雙足機器人上的有效性。該框架包含三個相互連接的模組：LLM 指導的獎勵函數設計模組、利用先前工作的 RL 訓練模組，以及模擬到真實同態評估模組。此設計透過僅使用必要的模擬和部署平台，大幅減少對人工輸入的需求，並具備整合人工設計策略和歷史資料的選項。我們詳細說明這些模組的建構、它們相較於傳統方法的優點，並展示該框架自主開發和改善雙足機器人運動控制策略的能力，展示其獨立於人工介入運作的潛力。

##### **Exploring Action-Centric Representations Through the Lens of Rate-Distortion Theory**
2409.08892v1 by Miguel de Llanza Varona, Christopher L. Buckley, Beren Millidge

Organisms have to keep track of the information in the environment that is
relevant for adaptive behaviour. Transmitting information in an economical and
efficient way becomes crucial for limited-resourced agents living in
high-dimensional environments. The efficient coding hypothesis claims that
organisms seek to maximize the information about the sensory input in an
efficient manner. Under Bayesian inference, this means that the role of the
brain is to efficiently allocate resources in order to make predictions about
the hidden states that cause sensory data. However, neither of those frameworks
accounts for how that information is exploited downstream, leaving aside the
action-oriented role of the perceptual system. Rate-distortion theory, which
defines optimal lossy compression under constraints, has gained attention as a
formal framework to explore goal-oriented efficient coding. In this work, we
explore action-centric representations in the context of rate-distortion
theory. We also provide a mathematical definition of abstractions and we argue
that, as a summary of the relevant details, they can be used to fix the content
of action-centric representations. We model action-centric representations
using VAEs and we find that such representations i) are efficient lossy
compressions of the data; ii) capture the task-dependent invariances necessary
to achieve successful behaviour; and iii) are not in service of reconstructing
the data. Thus, we conclude that full reconstruction of the data is rarely
needed to achieve optimal behaviour, consistent with a teleological approach to
perception.

摘要：<paragraph>生物體必須追蹤環境中與適應行為相關的資訊。對於生活在高維度環境中、資源有限的代理人而言，以經濟有效的方式傳遞資訊至關重要。有效編碼假說主張，生物體會尋求以有效的方式最大化感官輸入的資訊。在貝氏推論下，這表示大腦的角色是有效分配資源，以便對造成感官資料的隱藏狀態進行預測。然而，這些架構都沒有說明這些資訊如何在下游被利用，並忽略了知覺系統的動作導向角色。速率失真理論定義了在約束條件下的最佳有損壓縮，已被視為探索目標導向有效編碼的形式架構。在這項研究中，我們在速率失真理論的脈絡中探討以動作為中心的表徵。我們也提供抽象概念的數學定義，並主張，它們作為相關細節的摘要，可用於修正以動作為中心的表徵內容。我們使用變分自編碼器對以動作為中心的表徵進行建模，並發現這些表徵 i) 是資料的有效有損壓縮；ii) 捕捉達成成功行為所需的與任務相關的不變性；以及 iii) 不用於重建資料。因此，我們得出結論，要達成最佳行為，很少需要完整重建資料，這與目的論的知覺方法一致。</paragraph>

##### **Visual Language Tracking with Multi-modal Interaction: A Robust Benchmark**
2409.08887v1 by Xuchen Li, Shiyu Hu, Xiaokun Feng, Dailing Zhang, Meiqi Wu, Jing Zhang, Kaiqi Huang

Visual Language Tracking (VLT) enhances tracking by mitigating the
limitations of relying solely on the visual modality, utilizing high-level
semantic information through language. This integration of the language enables
more advanced human-machine interaction. The essence of interaction is
cognitive alignment, which typically requires multiple information exchanges,
especially in the sequential decision-making process of VLT. However, current
VLT benchmarks do not account for multi-round interactions during tracking.
They provide only an initial text and bounding box (bbox) in the first frame,
with no further interaction as tracking progresses, deviating from the original
motivation of the VLT task. To address these limitations, we propose a novel
and robust benchmark, VLT-MI (Visual Language Tracking with Multi-modal
Interaction), which introduces multi-round interaction into the VLT task for
the first time. (1) We generate diverse, multi-granularity texts for
multi-round, multi-modal interaction based on existing mainstream VLT
benchmarks using DTLLM-VLT, leveraging the world knowledge of LLMs. (2) We
propose a new VLT interaction paradigm that achieves multi-round interaction
through text updates and object recovery. When multiple tracking failures
occur, we provide the tracker with more aligned texts and corrected bboxes
through interaction, thereby expanding the scope of VLT downstream tasks. (3)
We conduct comparative experiments on both traditional VLT benchmarks and
VLT-MI, evaluating and analyzing the accuracy and robustness of trackers under
the interactive paradigm. This work offers new insights and paradigms for the
VLT task, enabling a fine-grained evaluation of multi-modal trackers. We
believe this approach can be extended to additional datasets in the future,
supporting broader evaluations and comparisons of video-language model
capabilities.

摘要：視覺語言追蹤 (VLT) 透過語言利用高層級語義資訊，減輕僅依賴視覺模式的限制，進而增強追蹤。這種語言整合能促成更進階的人機互動。互動的本質在於認知對齊，這通常需要多重資訊交換，特別是在 VLT 的循序決策過程中。然而，目前的 VLT 基準並未考量追蹤期間的多輪互動。它們僅在第一個畫格中提供初始文字和邊界框 (bbox)，而隨著追蹤的進行並未進一步互動，這偏離了 VLT 任務的原始動機。為了解決這些限制，我們提出一個新穎且穩健的基準 VLT-MI（多模式互動視覺語言追蹤），這首次在 VLT 任務中引入多輪互動。（1）我們使用 DTLLM-VLT 根據現有的主流 VLT 基準，為多輪、多模式互動產生多樣化、多粒度的文字，並利用 LLM 的世界知識。（2）我們提出一個新的 VLT 互動範例，透過文字更新和物件復原來達成多輪互動。當發生多個追蹤失敗時，我們透過互動為追蹤器提供更一致的文字和修正的 bbox，從而擴展 VLT 下游任務的範圍。（3）我們在傳統 VLT 基準和 VLT-MI 上進行比較實驗，評估和分析在互動範例下追蹤器的準確性和穩健性。這項工作為 VLT 任務提供了新的見解和範例，能對多模式追蹤器進行細緻的評估。我們相信這種方法未來可以擴展到其他資料集，支援更廣泛的評估和影片語言模型功能的比較。

##### **Exploring the Impact of Data Quantity on ASR in Extremely Low-resource Languages**
2409.08872v1 by Yao-Fei Cheng, Li-Wei Chen, Hung-Shin Lee, Hsin-Min Wang

This study investigates the efficacy of data augmentation techniques for
low-resource automatic speech recognition (ASR), focusing on two endangered
Austronesian languages, Amis and Seediq. Recognizing the potential of
self-supervised learning (SSL) in low-resource settings, we explore the impact
of data volume on the continued pre-training of SSL models. We propose a novel
data-selection scheme leveraging a multilingual corpus to augment the limited
target language data. This scheme utilizes a language classifier to extract
utterance embeddings and employs one-class classifiers to identify utterances
phonetically and phonologically proximate to the target languages. Utterances
are ranked and selected based on their decision scores, ensuring the inclusion
of highly relevant data in the SSL-ASR pipeline. Our experimental results
demonstrate the effectiveness of this approach, yielding substantial
improvements in ASR performance for both Amis and Seediq. These findings
underscore the feasibility and promise of data augmentation through
cross-lingual transfer learning for low-resource language ASR.

摘要：本研究探討資料擴充技術在低資源自動語音辨識 (ASR) 的效能，重點放在兩種瀕危南島語言，阿美語和賽德克語。了解自監督學習 (SSL) 在低資源環境中的潛力，我們探討資料量對 SSL 模型持續預訓練的影響。我們提出一個新穎的資料選取方案，利用多語言語料庫來擴充有限的目標語言資料。此方案利用語言分類器來萃取語句嵌入，並使用單類分類器來識別語音在語音和音位上接近目標語言的語句。語句根據其決策分數進行排序和選取，確保在 SSL-ASR 管線中包含高度相關的資料。我們的實驗結果證明了此方法的有效性，對阿美語和賽德克語的 ASR 效能產生顯著的改善。這些發現強調了透過跨語言遷移學習進行資料擴充對低資源語言 ASR 的可行性和前景。

##### **Exploring Graph Structure Comprehension Ability of Multimodal Large Language Models: Case Studies**
2409.08864v1 by Zhiqiang Zhong, Davide Mottin

Large Language Models (LLMs) have shown remarkable capabilities in processing
various data structures, including graphs. While previous research has focused
on developing textual encoding methods for graph representation, the emergence
of multimodal LLMs presents a new frontier for graph comprehension. These
advanced models, capable of processing both text and images, offer potential
improvements in graph understanding by incorporating visual representations
alongside traditional textual data. This study investigates the impact of graph
visualisations on LLM performance across a range of benchmark tasks at node,
edge, and graph levels. Our experiments compare the effectiveness of multimodal
approaches against purely textual graph representations. The results provide
valuable insights into both the potential and limitations of leveraging visual
graph modalities to enhance LLMs' graph structure comprehension abilities.

摘要：大型語言模型 (LLM) 在處理各種數據結構（包括圖形）方面表現出非凡的能力。儘管先前的研究著重於開發圖形表示的文本編碼方法，但多模態 LLM 的出現為圖形理解提供了新的領域。這些先進的模型能夠處理文本和圖像，透過結合視覺表示與傳統文本資料，提供圖形理解的潛在改進。本研究探討圖形視覺化對 LLM 在節點、邊緣和圖形層級一系列基準任務的效能影響。我們的實驗比較了多模態方法與純文本圖形表示的有效性。結果提供了有價值的見解，了解利用視覺圖形模態來增強 LLM 圖形結構理解能力的潛力與限制。

##### **Using The Concept Hierarchy for Household Action Recognition**
2409.08853v1 by Andrei Costinescu, Luis Figueredo, Darius Burschka

We propose a method to systematically represent both the static and the
dynamic components of environments, i.e. objects and agents, as well as the
changes that are happening in the environment, i.e. the actions and skills
performed by agents. Our approach, the Concept Hierarchy, provides the
necessary information for autonomous systems to represent environment states,
perform action modeling and recognition, and plan the execution of tasks.
Additionally, the hierarchical structure supports generalization and knowledge
transfer to environments. We rigorously define tasks, actions, skills, and
affordances that enable human-understandable action and skill recognition.

摘要：我們提出了一種方法，用以系統性地表示環境中的靜態和動態組成，也就是物件和代理，以及環境中發生的變化，也就是代理執行的動作和技能。我們的概念階層方法提供了自體系統所需的資訊，用以表示環境狀態、執行動作建模和辨識，以及規劃任務執行。此外，階層結構支援環境中的概化和知識轉移。我們嚴謹地定義了任務、動作、技能和可供性，這些定義能夠實現人類可理解的動作和技能辨識。

##### **FP-VEC: Fingerprinting Large Language Models via Efficient Vector Addition**
2409.08846v1 by Zhenhua Xu, Wenpeng Xing, Zhebo Wang, Chang Hu, Chen Jie, Meng Han

Training Large Language Models (LLMs) requires immense computational power
and vast amounts of data. As a result, protecting the intellectual property of
these models through fingerprinting is essential for ownership authentication.
While adding fingerprints to LLMs through fine-tuning has been attempted, it
remains costly and unscalable. In this paper, we introduce FP-VEC, a pilot
study on using fingerprint vectors as an efficient fingerprinting method for
LLMs. Our approach generates a fingerprint vector that represents a
confidential signature embedded in the model, allowing the same fingerprint to
be seamlessly incorporated into an unlimited number of LLMs via vector
addition. Results on several LLMs show that FP-VEC is lightweight by running on
CPU-only devices for fingerprinting, scalable with a single training and
unlimited fingerprinting process, and preserves the model's normal behavior.
The project page is available at https://fingerprintvector.github.io .

摘要：訓練大型語言模型 (LLM) 需要龐大的運算能力和大量的資料。因此，透過指紋辨識保護這些模型的智慧財產權對於所有權驗證至關重要。雖然已嘗試透過微調將指紋新增至 LLM，但它仍然昂貴且無法擴充。在本文中，我們介紹 FP-VEC，這是一個試驗研究，使用指紋向量作為 LLM 的一種有效指紋辨識方法。我們的做法會產生一個指紋向量，用來表示嵌入模型中的機密簽章，讓同一個指紋能透過向量加法無縫地整合到無限個 LLM 中。在多個 LLM 上的結果顯示，FP-VEC 透過僅在 CPU 裝置上執行指紋辨識而輕量化，且透過單一訓練和無限指紋辨識程序而具備擴充性，並保留模型的正常行為。專案頁面可於 https://fingerprintvector.github.io 取得。

##### **AIPO: Improving Training Objective for Iterative Preference Optimization**
2409.08845v1 by Yaojie Shen, Xinyao Wang, Yulei Niu, Ying Zhou, Lexin Tang, Libo Zhang, Fan Chen, Longyin Wen

Preference Optimization (PO), is gaining popularity as an alternative choice
of Proximal Policy Optimization (PPO) for aligning Large Language Models
(LLMs). Recent research on aligning LLMs iteratively with synthetic or
partially synthetic data shows promising results in scaling up PO training for
both academic settings and proprietary trained models such as Llama3. Despite
its success, our study shows that the length exploitation issue present in PO
is even more severe in Iterative Preference Optimization (IPO) due to the
iterative nature of the process. In this work, we study iterative preference
optimization with synthetic data. We share the findings and analysis along the
way of building the iterative preference optimization pipeline. More
specifically, we discuss the length exploitation issue during iterative
preference optimization and propose our training objective for iterative
preference optimization, namely Agreement-aware Iterative Preference
Optimization (AIPO). To demonstrate the effectiveness of our method, we conduct
comprehensive experiments and achieve state-of-the-art performance on MT-Bench,
AlpacaEval 2.0, and Arena-Hard. Our implementation and model checkpoints will
be made available at https://github.com/bytedance/AIPO.

摘要：偏好優化 (PO) 正在作為近端策略優化的替代選擇而獲得普及，用於對齊大型語言模型 (LLM)。最近對使用合成或部分合成數據迭代對齊 LLM 的研究顯示，在擴展 PO 訓練方面取得了可喜的成果，適用於學術環境和專有訓練模型，例如 Llama3。儘管取得了成功，但我們的研究表明，由於過程的迭代性質，在迭代偏好優化 (IPO) 中，PO 中存在的長度利用問題甚至更加嚴重。在這項工作中，我們研究了使用合成數據進行迭代偏好優化。我們在建立迭代偏好優化管道的過程中分享了發現和分析。更具體地說，我們討論了在迭代偏好優化期間的長度利用問題，並提出了我們用於迭代偏好優化的訓練目標，即基於協議的迭代偏好優化 (AIPO)。為了證明我們方法的有效性，我們進行了全面的實驗，並在 MT-Bench、AlpacaEval 2.0 和 Arena-Hard 上取得了最先進的性能。我們的實作和模型檢查點將在 https://github.com/bytedance/AIPO 上提供。

##### **A RAG Approach for Generating Competency Questions in Ontology Engineering**
2409.08820v1 by Xueli Pan, Jacco van Ossenbruggen, Victor de Boer, Zhisheng Huang

Competency question (CQ) formulation is central to several ontology
development and evaluation methodologies. Traditionally, the task of crafting
these competency questions heavily relies on the effort of domain experts and
knowledge engineers which is often time-consuming and labor-intensive. With the
emergence of Large Language Models (LLMs), there arises the possibility to
automate and enhance this process. Unlike other similar works which use
existing ontologies or knowledge graphs as input to LLMs, we present a
retrieval-augmented generation (RAG) approach that uses LLMs for the automatic
generation of CQs given a set of scientific papers considered to be a domain
knowledge base. We investigate its performance and specifically, we study the
impact of different number of papers to the RAG and different temperature
setting of the LLM. We conduct experiments using GPT-4 on two domain ontology
engineering tasks and compare results against ground-truth CQs constructed by
domain experts. Empirical assessments on the results, utilizing evaluation
metrics (precision and consistency), reveal that compared to zero-shot
prompting, adding relevant domain knowledge to the RAG improves the performance
of LLMs on generating CQs for concrete ontology engineering tasks.

摘要：能力問題 (CQ) 的制定是幾個本体論發展和評估方法的中心。傳統上，制定這些能力問題的任務很大程度上依賴於領域專家和知識工程師的努力，這通常是耗時且勞力密集的。隨著大型語言模型 (LLM) 的出現，自動化和增強此過程的可能性出現了。與其他使用現有本体論或知識圖譜作為 LLM 輸入的類似工作不同，我們提出了一種檢索增強生成 (RAG) 方法，該方法使用 LLM 自動生成被認為是領域知識庫的一組科學論文的 CQ。我們研究其性能，特別是我們研究不同數量的論文對 RAG 的影響和 LLM 的不同溫度設置。我們使用 GPT-4 對兩個領域本体論工程任務進行實驗，並將結果與由領域專家構造的真實 CQ 進行比較。利用評估指標（精確度和一致性）對結果進行的實證評估表明，與零次提示相比，將相關領域知識添加到 RAG 可以提高 LLM 在為具體本体論工程任務生成 CQ 方面的性能。

##### **Deep reinforcement learning for tracking a moving target in jellyfish-like swimming**
2409.08815v1 by Yihao Chen, Yue Yang

We develop a deep reinforcement learning method for training a jellyfish-like
swimmer to effectively track a moving target in a two-dimensional flow. This
swimmer is a flexible object equipped with a muscle model based on torsional
springs. We employ a deep Q-network (DQN) that takes the swimmer's geometry and
dynamic parameters as inputs, and outputs actions which are the forces applied
to the swimmer. In particular, we introduce an action regulation to mitigate
the interference from complex fluid-structure interactions. The goal of these
actions is to navigate the swimmer to a target point in the shortest possible
time. In the DQN training, the data on the swimmer's motions are obtained from
simulations conducted using the immersed boundary method. During tracking a
moving target, there is an inherent delay between the application of forces and
the corresponding response of the swimmer's body due to hydrodynamic
interactions between the shedding vortices and the swimmer's own locomotion.
Our tests demonstrate that the swimmer, with the DQN agent and action
regulation, is able to dynamically adjust its course based on its instantaneous
state. This work extends the application scope of machine learning in
controlling flexible objects within fluid environments.

摘要：我們開發了一種深度強化學習方法，用於訓練一個類似水母的游泳者，以有效追蹤在二維流中的移動目標。這個游泳者是一個具有基於扭轉彈簧的肌肉模型的柔性物體。我們採用一個深度 Q 網路 (DQN)，它將游泳者的幾何形狀和動態參數作為輸入，並輸出作用在游泳者身上的力，即動作。特別是，我們引入了一個動作調節，以減輕複雜流體結構相互作用的干擾。這些動作的目標是在最短時間內導航游泳者到目標點。在 DQN 訓練中，游泳者運動的數據是從使用浸沒邊界方法進行的模擬中獲得的。在追蹤移動目標的過程中，由於脫落渦流和游泳者自身的運動之間的流體動力相互作用，力的施加和游泳者身體的相應反應之間存在固有的延遲。我們的測試表明，游泳者在 DQN 代理和動作調節的作用下，能夠根據其瞬時狀態動態調整其航向。這項工作擴大了機器學習在流體環境中控制柔性物體的應用範圍。

##### **Your Weak LLM is Secretly a Strong Teacher for Alignment**
2409.08813v1 by Leitian Tao, Yixuan Li

The burgeoning capabilities of large language models (LLMs) have underscored
the need for alignment to ensure these models act in accordance with human
values and intentions. Existing alignment frameworks present constraints either
in the form of expensive human effort or high computational costs. This paper
explores a promising middle ground, where we employ a weak LLM that is
significantly less resource-intensive than top-tier models, yet offers more
automation than purely human feedback. We present a systematic study to
evaluate and understand weak LLM's ability to generate feedback for alignment.
Our empirical findings demonstrate that weak LLMs can provide feedback that
rivals or even exceeds that of fully human-annotated data. Our study indicates
a minimized impact of model size on feedback efficacy, shedding light on a
scalable and sustainable alignment strategy. To deepen our understanding of
alignment under weak LLM feedback, we conduct a series of qualitative and
quantitative analyses, offering novel insights into the quality discrepancies
between human feedback vs. weak LLM feedback.

摘要：大型語言模型（LLM）蓬勃發展的能力強調了對齊的需求，以確保這些模型按照人類的價值觀和意圖行事。現有的對齊框架以昂貴的人力成本或高計算成本的形式呈現約束。本文探討了一個有希望的折衷方案，在其中我們採用一個弱 LLM，其資源密集程度遠低於頂級模型，但提供的自動化程度卻高於純粹的人類回饋。我們提出了一項系統性研究，以評估和了解弱 LLM 生成對齊回饋的能力。我們的經驗發現表明，弱 LLM 可以提供與完全人工註釋數據相媲美甚至超過其的回饋。我們的研究表明模型大小對回饋效果的影響最小，這為可擴展且可持續的對齊策略提供了啟示。為了加深我們對弱 LLM 回饋下對齊的理解，我們進行了一系列定性和定量分析，提供了人類回饋與弱 LLM 回饋之間質量差異的新見解。

##### **Mutual Theory of Mind in Human-AI Collaboration: An Empirical Study with LLM-driven AI Agents in a Real-time Shared Workspace Task**
2409.08811v1 by Shao Zhang, Xihuai Wang, Wenhao Zhang, Yongshan Chen, Landi Gao, Dakuo Wang, Weinan Zhang, Xinbing Wang, Ying Wen

Theory of Mind (ToM) significantly impacts human collaboration and
communication as a crucial capability to understand others. When AI agents with
ToM capability collaborate with humans, Mutual Theory of Mind (MToM) arises in
such human-AI teams (HATs). The MToM process, which involves interactive
communication and ToM-based strategy adjustment, affects the team's performance
and collaboration process. To explore the MToM process, we conducted a
mixed-design experiment using a large language model-driven AI agent with ToM
and communication modules in a real-time shared-workspace task. We find that
the agent's ToM capability does not significantly impact team performance but
enhances human understanding of the agent and the feeling of being understood.
Most participants in our study believe verbal communication increases human
burden, and the results show that bidirectional communication leads to lower
HAT performance. We discuss the results' implications for designing AI agents
that collaborate with humans in real-time shared workspace tasks.

摘要：心智理論（ToM）顯著影響人類協作和溝通，作為理解他人的關鍵能力。當具備心智理論能力的人工智慧代理與人類協作時，在這樣的人類人工智慧團隊（HAT）中會出現相互心智理論（MToM）。MToM 程序涉及互動溝通和基於心智理論的策略調整，影響團隊的表現和協作程序。為了探索 MToM 程序，我們使用具備心智理論和溝通模組的大型語言模型驅動的人工智慧代理，在一個即時共享工作空間任務中進行了混合設計實驗。我們發現代理的心智理論能力並沒有顯著影響團隊表現，但增強了人類對代理的理解和被理解的感覺。我們研究中大多數參與者相信，口頭溝通增加了人類負擔，而結果顯示雙向溝通導致較低的 HAT 表現。我們討論了這些結果對設計在即時共享工作空間任務中與人類協作的人工智慧代理的影響。

##### **TabKANet: Tabular Data Modelling with Kolmogorov-Arnold Network and Transformer**
2409.08806v1 by Weihao Gao, Zheng Gong, Zhuo Deng, Fuju Rong, Chucheng Chen, Lan Ma

Tabular data is the most common type of data in real-life scenarios. In this
study, we propose a method based on the TabKANet architecture, which utilizes
the Kolmogorov-Arnold network to encode numerical features and merge them with
categorical features, enabling unified modeling of tabular data on the
Transformer architecture. This model demonstrates outstanding performance in
six widely used binary classification tasks, suggesting that TabKANet has the
potential to become a standard approach for tabular modeling, surpassing
traditional neural networks. Furthermore, this research reveals the significant
advantages of the Kolmogorov-Arnold network in encoding numerical features. The
code of our work is available at https://github.com/tsinghuamedgao20/TabKANet.

摘要：表格資料是真實生活中最常見的資料類型。在此研究中，我們提出一個基於 TabKANet 架構的方法，它利用 Kolmogorov-Arnold 網路對數值特徵進行編碼，並將它們與類別特徵合併，在 Transformer 架構上實現表格資料的統一建模。此模型在六項廣泛使用的二元分類任務中展現出傑出的效能，這表明 TabKANet 有可能成為表格建模的標準方法，超越傳統的神經網路。此外，此研究揭示了 Kolmogorov-Arnold 網路在編碼數值特徵方面的顯著優勢。我們工作的程式碼可於 https://github.com/tsinghuamedgao20/TabKANet 取得。

##### **Exploring SSL Discrete Tokens for Multilingual ASR**
2409.08805v1 by Mingyu Cui, Daxin Tan, Yifan Yang, Dingdong Wang, Huimeng Wang, Xiao Chen, Xie Chen, Xunying Liu

With the advancement of Self-supervised Learning (SSL) in speech-related
tasks, there has been growing interest in utilizing discrete tokens generated
by SSL for automatic speech recognition (ASR), as they offer faster processing
techniques. However, previous studies primarily focused on multilingual ASR
with Fbank features or English ASR with discrete tokens, leaving a gap in
adapting discrete tokens for multilingual ASR scenarios. This study presents a
comprehensive comparison of discrete tokens generated by various leading SSL
models across multiple language domains. We aim to explore the performance and
efficiency of speech discrete tokens across multiple language domains for both
monolingual and multilingual ASR scenarios. Experimental results demonstrate
that discrete tokens achieve comparable results against systems trained on
Fbank features in ASR tasks across seven language domains with an average word
error rate (WER) reduction of 0.31% and 1.76% absolute (2.80% and 15.70%
relative) on dev and test sets respectively, with particularly WER reduction of
6.82% absolute (41.48% relative) on the Polish test set.

摘要：隨著自監督學習 (SSL) 在語音相關任務中的進展，利用 SSL 產生的離散符號進行自動語音辨識 (ASR) 的興趣不斷增加，因為它們提供了更快的處理技術。然而，先前的研究主要集中在使用 Fbank 特徵的多語言 ASR 或使用離散符號的英文 ASR，在將離散符號適應到多語言 ASR 場景方面仍有差距。本研究對各種領先 SSL 模型在多個語言領域產生的離散符號進行了全面的比較。我們的目標是探討離散語音符號在多個語言領域中單語和多語 ASR 場景下的性能和效率。實驗結果表明，離散符號在七個語言領域的 ASR 任務中達到了與在 Fbank 特徵上訓練的系統相當的結果，在開發和測試集上分別將平均字元錯誤率 (WER) 降低了 0.31% 和 1.76% 絕對值（2.80% 和 15.70% 相對值），特別是在波蘭語測試集上將 WER 降低了 6.82% 絕對值（41.48% 相對值）。

##### **Reading ability detection using eye-tracking data with LSTM-based few-shot learning**
2409.08798v1 by Nanxi Li, Hongjiang Wang, Zehui Zhan

Reading ability detection is important in modern educational field. In this
paper, a method of predicting scores of reading ability is proposed, using the
eye-tracking data of a few subjects (e.g., 68 subjects). The proposed method
built a regression model for the score prediction by combining Long Short Time
Memory (LSTM) and light-weighted neural networks. Experiments show that with
few-shot learning strategy, the proposed method achieved higher accuracy than
previous methods of score prediction in reading ability detection. The code can
later be downloaded at
https://github.com/pumpkinLNX/LSTM-eye-tracking-pytorch.git

摘要：閱讀能力檢測在現代教育領域中非常重要。在本文中，提出了一種使用少數受試者（例如 68 位受試者）的眼動追蹤資料來預測閱讀能力分數的方法。所提出的方法結合了長短期記憶 (LSTM) 和輕量化神經網路，建立了一個用於分數預測的回歸模型。實驗表明，藉由少次學習策略，所提出的方法在閱讀能力檢測中，比先前的分數預測方法達到了更高的準確度。稍後可以在 https://github.com/pumpkinLNX/LSTM-eye-tracking-pytorch.git 下載程式碼

##### **Exploring SSL Discrete Speech Features for Zipformer-based Contextual ASR**
2409.08797v1 by Mingyu Cui, Yifan Yang, Jiajun Deng, Jiawen Kang, Shujie Hu, Tianzi Wang, Zhaoqing Li, Shiliang Zhang, Xie Chen, Xunying Liu

Self-supervised learning (SSL) based discrete speech representations are
highly compact and domain adaptable. In this paper, SSL discrete speech
features extracted from WavLM models are used as additional cross-utterance
acoustic context features in Zipformer-Transducer ASR systems. The efficacy of
replacing Fbank features with discrete token features for modelling either
cross-utterance contexts (from preceding and future segments), or current
utterance's internal contexts alone, or both at the same time, are demonstrated
thoroughly on the Gigaspeech 1000-hr corpus. The best Zipformer-Transducer
system using discrete tokens based cross-utterance context features outperforms
the baseline using utterance internal context only with statistically
significant word error rate (WER) reductions of 0.32% to 0.41% absolute (2.78%
to 3.54% relative) on the dev and test data. The lowest published WER of 11.15%
and 11.14% were obtained on the dev and test sets. Our work is open-source and
publicly available at
https://github.com/open-creator/icefall/tree/master/egs/gigaspeech/Context\_ASR.

摘要：基於自我監督學習 (SSL) 的離散語音表徵高度緊湊且具備領域適應性。本文使用從 WavLM 模型中萃取的 SSL 離散語音特徵，作為 Zipformer-Transducer ASR 系統中額外的跨 utterance 音響背景特徵。僅針對跨 utterance 背景（來自前段和後段）、或僅針對當前 utterance 的內部背景，或同時針對兩者建模，以離散代號特徵取代 Fbank 特徵的效能，已在 Gigaspeech 1000 小時語料庫上獲得徹底驗證。使用基於離散代號的跨 utterance 背景特徵的最佳 Zipformer-Transducer 系統，其效能優於僅使用 utterance 內部背景的基準，在開發和測試資料上，字元錯誤率 (WER) 絕對降低 0.32% 至 0.41%（相對降低 2.78% 至 3.54%），且具有統計顯著性。在開發和測試集上，獲得最低已發表的 WER，分別為 11.15% 和 11.14%。我們的作品是開源的，且可於 https://github.com/open-creator/icefall/tree/master/egs/gigaspeech/Context\_ASR 公開取得。

##### **Optimizing Ingredient Substitution Using Large Language Models to Enhance Phytochemical Content in Recipes**
2409.08792v1 by Luis Rita, Josh Southern, Ivan Laponogov, Kyle Higgins, Kirill Veselkov

In the emerging field of computational gastronomy, aligning culinary
practices with scientifically supported nutritional goals is increasingly
important. This study explores how large language models (LLMs) can be applied
to optimize ingredient substitutions in recipes, specifically to enhance the
phytochemical content of meals. Phytochemicals are bioactive compounds found in
plants, which, based on preclinical studies, may offer potential health
benefits. We fine-tuned models, including OpenAI's GPT-3.5, DaVinci, and Meta's
TinyLlama, using an ingredient substitution dataset. These models were used to
predict substitutions that enhance phytochemical content and create a
corresponding enriched recipe dataset. Our approach improved Hit@1 accuracy on
ingredient substitution tasks, from the baseline 34.53 plus-minus 0.10% to
38.03 plus-minus 0.28% on the original GISMo dataset, and from 40.24 plus-minus
0.36% to 54.46 plus-minus 0.29% on a refined version of the same dataset. These
substitutions led to the creation of 1,951 phytochemically enriched ingredient
pairings and 1,639 unique recipes. While this approach demonstrates potential
in optimizing ingredient substitutions, caution must be taken when drawing
conclusions about health benefits, as the claims are based on preclinical
evidence. Future work should include clinical validation and broader datasets
to further evaluate the nutritional impact of these substitutions. This
research represents a step forward in using AI to promote healthier eating
practices, providing potential pathways for integrating computational methods
with nutritional science.

摘要：<paragraph>在計算美食學的新興領域中，將烹飪實務與科學支持的營養目標相結合，變得越來越重要。本研究探討如何應用大型語言模型 (LLM) 來最佳化食譜中的食材替換，特別是為了提升餐點的植物化學物質含量。植物化學物質是存在於植物中的生物活性化合物，根據臨床前研究，可能提供潛在的健康益處。我們微調了模型，包括 OpenAI 的 GPT-3.5、DaVinci 和 Meta 的 TinyLlama，使用食材替換資料集。這些模型用於預測可提升植物化學物質含量並建立對應的豐富食譜資料集的替換。我們的做法改善了食材替換任務的 Hit@1 準確度，從原本的 GISMo 資料集的 34.53 正負 0.10% 到 38.03 正負 0.28%，以及從同一資料集的精緻版本中的 40.24 正負 0.36% 到 54.46 正負 0.29%。這些替換導致建立了 1,951 個植物化學物質豐富的食材配對和 1,639 個獨特的食譜。雖然這種做法證明了在最佳化食材替換方面具有潛力，但在得出關於健康益處的結論時必須謹慎，因為這些說法是基於臨床前證據。未來的研究應包括臨床驗證和更廣泛的資料集，以進一步評估這些替換的營養影響。這項研究代表了使用 AI 來促進更健康的飲食習慣向前邁進一步，為將計算方法與營養科學整合提供了潛在途徑。</paragraph>

##### **Sign Language Sense Disambiguation**
2409.08780v1 by Jana Grimm, Miriam Winkler, Oliver Kraus, Tanalp Agustoslu

This project explores methods to enhance sign language translation of German
sign language, specifically focusing on disambiguation of homonyms. Sign
language is ambiguous and understudied which is the basis for our experiments.
We approach the improvement by training transformer-based models on various
bodypart representations to shift the focus on said bodypart. To determine the
impact of, e.g., the hand or mouth representations, we experiment with
different combinations. The results show that focusing on the mouth increases
the performance in small dataset settings while shifting the focus on the hands
retrieves better results in larger dataset settings. Our results contribute to
better accessibility for non-hearing persons by improving the systems powering
digital assistants, enabling a more accurate interaction. The code for this
project can be found on GitHub.

摘要：本專案探討了增強德國手語翻譯的方法，特別著重於消除同義詞的歧義。手語具有歧義性且研究不足，這是我們實驗的基礎。我們透過在各種身體部位表示上訓練基於轉換器的模型來改善，以將焦點轉移到所述身體部位。為了確定例如手部或嘴巴表示的影響，我們嘗試了不同的組合。結果顯示，在小型資料集設定中專注於嘴巴會提升效能，而在大型資料集設定中將焦點轉移到手上則會獲得更好的結果。我們的結果透過改善為數位助理提供動力的系統，進而提升非聽障人士的可及性，並能更準確地互動。此專案的程式碼可以在 GitHub 上找到。

##### **What You Say = What You Want? Teaching Humans to Articulate Requirements for LLMs**
2409.08775v1 by Qianou Ma, Weirui Peng, Hua Shen, Kenneth Koedinger, Tongshuang Wu

Prompting ChatGPT to achieve complex goals (e.g., creating a customer support
chatbot) often demands meticulous prompt engineering, including aspects like
fluent writing and chain-of-thought techniques. While emerging prompt
optimizers can automatically refine many of these aspects, we argue that
clearly conveying customized requirements (e.g., how to handle diverse inputs)
remains a human-centric challenge. In this work, we introduce
Requirement-Oriented Prompt Engineering (ROPE), a paradigm that focuses human
attention on generating clear, complete requirements during prompting. We
implement ROPE through an assessment and training suite that provides
deliberate practice with LLM-generated feedback. In a study with 30 novices, we
show that requirement-focused training doubles novices' prompting performance,
significantly outperforming conventional prompt engineering training and prompt
optimization. We also demonstrate that high-quality LLM outputs are directly
tied to the quality of input requirements. Our work paves the way for more
effective task delegation in human-LLM collaborative prompting.

摘要：提示 ChatGPT 达成复杂目标（例如，建立一个客服聊天机器人）通常需要一丝不苟的提示工程，包括流畅的写作和思维链技术等方面。虽然新兴的提示优化器可以自动优化这些方面的许多内容，但我们认为，清晰地传达定制化需求（例如，如何处理不同的输入）仍然是一项以人为中心的任务。在这项工作中，我们引入了面向需求的提示工程 (ROPE)，这是一种范例，它将人的注意力集中在提示期间生成清晰、完整的要求上。我们通过一个评估和培训套件实现了 ROPE，该套件提供与 LLM 生成的反馈进行深思熟虑的练习。在一项针对 30 名新手的研究中，我们表明，以需求为重点的培训使新手的提示性能提高了一倍，明显优于传统的提示工程培训和提示优化。我们还证明，高质量的 LLM 输出与输入需求的质量直接相关。我们的工作为在人机协作提示中更有效地委派任务铺平了道路。

##### **HOLA-Drone: Hypergraphic Open-ended Learning for Zero-Shot Multi-Drone Cooperative Pursuit**
2409.08767v1 by Yang Li, Dengyu Zhang, Junfan Chen, Ying Wen, Qingrui Zhang, Shaoshuai Mou, Wei Pan

Zero-shot coordination (ZSC) is a significant challenge in multi-agent
collaboration, aiming to develop agents that can coordinate with unseen
partners they have not encountered before. Recent cutting-edge ZSC methods have
primarily focused on two-player video games such as OverCooked!2 and Hanabi. In
this paper, we extend the scope of ZSC research to the multi-drone cooperative
pursuit scenario, exploring how to construct a drone agent capable of
coordinating with multiple unseen partners to capture multiple evaders. We
propose a novel Hypergraphic Open-ended Learning Algorithm (HOLA-Drone) that
continuously adapts the learning objective based on our hypergraphic-form game
modeling, aiming to improve cooperative abilities with multiple unknown drone
teammates. To empirically verify the effectiveness of HOLA-Drone, we build two
different unseen drone teammate pools to evaluate their performance in
coordination with various unseen partners. The experimental results demonstrate
that HOLA-Drone outperforms the baseline methods in coordination with unseen
drone teammates. Furthermore, real-world experiments validate the feasibility
of HOLA-Drone in physical systems. Videos can be found on the project
homepage~\url{https://sites.google.com/view/hola-drone}.

摘要：零次學習協調 (ZSC) 是多重代理合作中的一項重大挑戰，目標是開發出能與未曾遇見的陌生合作夥伴協調的代理。最近的尖端 ZSC 方法主要專注於雙人電玩遊戲，例如 OverCooked!2 和 Hanabi。在本文中，我們將 ZSC 研究的範圍擴展到多無人機協作追逐場景，探討如何建構一個無人機代理，以便與多個未曾見過的合作夥伴協調，以捕捉多個逃犯。我們提出了一種新穎的超圖開放式學習演算法 (HOLA-Drone)，該演算法會根據我們的超圖形式遊戲建模持續調整學習目標，旨在提升與多個未知無人機隊友的合作能力。為了憑經驗驗證 HOLA-Drone 的效能，我們建立了兩個不同的未曾見過無人機隊友池，以評估它們在與各種未曾見過合作夥伴協調時的表現。實驗結果證明，HOLA-Drone 在與未曾見過的無人機隊友協調時，表現優於基線方法。此外，真實世界的實驗驗證了 HOLA-Drone 在物理系統中的可行性。可以在專案首頁~\url{https://sites.google.com/view/hola-drone} 找到影片。

##### **Journalists, Emotions, and the Introduction of Generative AI Chatbots: A Large-Scale Analysis of Tweets Before and After the Launch of ChatGPT**
2409.08761v1 by Seth C. Lewis, David M. Markowitz, Jon Benedik Bunquin

As part of a broader look at the impact of generative AI, this study
investigated the emotional responses of journalists to the release of ChatGPT
at the time of its launch. By analyzing nearly 1 million Tweets from
journalists at major U.S. news outlets, we tracked changes in emotional tone
and sentiment before and after the introduction of ChatGPT in November 2022.
Using various computational and natural language processing techniques to
measure emotional shifts in response to ChatGPT's release, we found an increase
in positive emotion and a more favorable tone post-launch, suggesting initial
optimism toward AI's potential. This research underscores the pivotal role of
journalists as interpreters of technological innovation and disruption,
highlighting how their emotional reactions may shape public narratives around
emerging technologies. The study contributes to understanding the intersection
of journalism, emotion, and AI, offering insights into the broader societal
impact of generative AI tools.

摘要：作為廣泛探討生成式 AI 影響力的一部分，本研究調查了記者在 ChatGPT 推出時對其發布的情緒反應。透過分析來自美國主要新聞媒體的記者發布的近 100 萬則推文，我們追蹤了 2022 年 11 月 ChatGPT 推出前後情緒語氣和情感的變化。使用各種運算和自然語言處理技術來衡量對 ChatGPT 發布的情緒轉變，我們發現正面情緒增加，且在推出後語氣更為正面，顯示出對 AI 潛力的初步樂觀。本研究強調了記者作為技術創新和破壞的詮釋者所扮演的關鍵角色，並強調了他們的情緒反應如何形塑大眾對新興技術的論述。本研究有助於了解新聞工作、情緒和 AI 的交集，並提供對生成式 AI 工具更廣泛的社會影響的見解。

##### **Bridging Dynamic Factor Models and Neural Controlled Differential Equations for Nowcasting GDP**
2409.08732v1 by Seonkyu Lim, Jeongwhan Choi, Noseong Park, Sang-Ha Yoon, ShinHyuck Kang, Young-Min Kim, Hyunjoong Kang

Gross domestic product (GDP) nowcasting is crucial for policy-making as GDP
growth is a key indicator of economic conditions. Dynamic factor models (DFMs)
have been widely adopted by government agencies for GDP nowcasting due to their
ability to handle irregular or missing macroeconomic indicators and their
interpretability. However, DFMs face two main challenges: i) the lack of
capturing economic uncertainties such as sudden recessions or booms, and ii)
the limitation of capturing irregular dynamics from mixed-frequency data. To
address these challenges, we introduce NCDENow, a novel GDP nowcasting
framework that integrates neural controlled differential equations (NCDEs) with
DFMs. This integration effectively handles the dynamics of irregular time
series. NCDENow consists of 3 main modules: i) factor extraction leveraging
DFM, ii) dynamic modeling using NCDE, and iii) GDP growth prediction through
regression. We evaluate NCDENow against 6 baselines on 2 real-world GDP
datasets from South Korea and the United Kingdom, demonstrating its enhanced
predictive capability. Our empirical results favor our method, highlighting the
significant potential of integrating NCDE into nowcasting models. Our code and
dataset are available at https://github.com/sklim84/NCDENow_CIKM2024.

摘要：國內生產毛額 (GDP) 即時預測對於政策制定至關重要，因為 GDP 成長是經濟狀況的重要指標。動態因子模型 (DFM) 因應對不規則或缺失的巨觀經濟指標，以及可解釋性的能力，已被政府機構廣泛採用於 GDP 即時預測。然而，DFM 面臨兩項主要挑戰：i) 無法捕捉經濟不確定性，例如突然的衰退或繁榮，以及 ii) 從混合頻率資料中捕捉不規則動態的限制。為了應對這些挑戰，我們引入了 NCDENow，這是一個新的 GDP 即時預測架構，它將神經控制微分方程 (NCDE) 與 DFM 整合在一起。這種整合有效地處理了不規則時間序列的動態。NCDENow 包含 3 個主要模組：i) 利用 DFM 提取因子，ii) 使用 NCDE 進行動態建模，以及 iii) 透過迴歸預測 GDP 成長。我們針對來自南韓和英國的 2 個真實世界 GDP 資料集，對 NCDENow 與 6 個基準進行評估，證明了它增強的預測能力。我們的實證結果支持我們的模型，強調將 NCDE 整合到即時預測模型中的重大潛力。我們的程式碼和資料集可在 https://github.com/sklim84/NCDENow_CIKM2024 取得。

##### **Distilling Monolingual and Crosslingual Word-in-Context Representations**
2409.08719v1 by Yuki Arase, Tomoyuki Kajiwara

In this study, we propose a method that distils representations of word
meaning in context from a pre-trained masked language model in both monolingual
and crosslingual settings. Word representations are the basis for context-aware
lexical semantics and unsupervised semantic textual similarity (STS)
estimation. Different from existing approaches, our method does not require
human-annotated corpora nor updates of the parameters of the pre-trained model.
The latter feature is appealing for practical scenarios where the off-the-shelf
pre-trained model is a common asset among different applications. Specifically,
our method learns to combine the outputs of different hidden layers of the
pre-trained model using self-attention. Our auto-encoder based training only
requires an automatically generated corpus. To evaluate the performance of the
proposed approach, we performed extensive experiments using various benchmark
tasks. The results on the monolingual tasks confirmed that our representations
exhibited a competitive performance compared to that of the previous study for
the context-aware lexical semantic tasks and outperformed it for STS
estimation. The results of the crosslingual tasks revealed that the proposed
method largely improved crosslingual word representations of multilingual
pre-trained models.

摘要：<paragraph>在這項研究中，我們提出了一種方法，可以從預先訓練好的遮蔽語言模型中提取單詞在上下文中含義的表徵，同時適用於單語和跨語言設置。單詞表徵是基於上下文感知的詞彙語義和無監督語義文本相似性 (STS) 估計。與現有方法不同，我們的方法不需要人工註解的語料庫，也不需要更新預先訓練好的模型的參數。後者對於實際場景很有吸引力，在這種場景中，現成的預先訓練好的模型是不同應用程序之間的共同資產。具體來說，我們的方法學會使用自注意力結合預先訓練好的模型的不同隱藏層的輸出。我們基於自動編碼器的訓練只需要一個自動生成的語料庫。為了評估所提出方法的性能，我們使用各種基準任務進行了廣泛的實驗。單語任務的結果證實，與先前研究相比，我們的表徵在基於上下文的詞彙語義任務中表現出了競爭力，並且在 STS 估計中優於它。跨語言任務的結果表明，所提出的方法極大地改進了多語言預先訓練模型的跨語言單詞表徵。</paragraph>

##### **Text-To-Speech Synthesis In The Wild**
2409.08711v1 by Jee-weon Jung, Wangyou Zhang, Soumi Maiti, Yihan Wu, Xin Wang, Ji-Hoon Kim, Yuta Matsunaga, Seyun Um, Jinchuan Tian, Hye-jin Shim, Nicholas Evans, Joon Son Chung, Shinnosuke Takamichi, Shinji Watanabe

Text-to-speech (TTS) systems are traditionally trained using modest databases
of studio-quality, prompted or read speech collected in benign acoustic
environments such as anechoic rooms. The recent literature nonetheless shows
efforts to train TTS systems using data collected in the wild. While this
approach allows for the use of massive quantities of natural speech, until now,
there are no common datasets. We introduce the TTS In the Wild (TITW) dataset,
the result of a fully automated pipeline, in this case, applied to the
VoxCeleb1 dataset commonly used for speaker recognition. We further propose two
training sets. TITW-Hard is derived from the transcription, segmentation, and
selection of VoxCeleb1 source data. TITW-Easy is derived from the additional
application of enhancement and additional data selection based on DNSMOS. We
show that a number of recent TTS models can be trained successfully using
TITW-Easy, but that it remains extremely challenging to produce similar results
using TITW-Hard. Both the dataset and protocols are publicly available and
support the benchmarking of TTS systems trained using TITW data.

摘要：文字轉語音 (TTS) 系統傳統上使用適度的資料庫進行訓練，這些資料庫包含在無回音室等良性聲學環境中收集的錄音室品質、提示式或朗讀式語音。儘管如此，最近的文獻顯示了使用在野外收集的資料訓練 TTS 系統的努力。雖然這種方法允許使用大量的自然語音，但到目前為止，還沒有通用的資料集。我們介紹 TTS In the Wild (TITW) 資料集，這是全自動化流程的結果，在這種情況下，應用於通常用於說話者識別的 VoxCeleb1 資料集。我們進一步提出了兩個訓練集。TITW-Hard 來自 VoxCeleb1 原始資料的轉錄、分段和選擇。TITW-Easy 來自基於 DNSMOS 的增強和額外資料選擇的額外應用。我們表明，許多最近的 TTS 模型可以使用 TITW-Easy 成功訓練，但使用 TITW-Hard 產生類似結果仍然極具挑戰性。資料集和協定都是公開可用的，並支援使用 TITW 資料訓練的 TTS 系統的基準測試。

##### **L3Cube-IndicQuest: A Benchmark Questing Answering Dataset for Evaluating Knowledge of LLMs in Indic Context**
2409.08706v1 by Pritika Rohera, Chaitrali Ginimav, Akanksha Salunke, Gayatri Sawant, Raviraj Joshi

Large Language Models (LLMs) have made significant progress in incorporating
Indic languages within multilingual models. However, it is crucial to
quantitatively assess whether these languages perform comparably to globally
dominant ones, such as English. Currently, there is a lack of benchmark
datasets specifically designed to evaluate the regional knowledge of LLMs in
various Indic languages. In this paper, we present the L3Cube-IndicQuest, a
gold-standard question-answering benchmark dataset designed to evaluate how
well multilingual LLMs capture regional knowledge across various Indic
languages. The dataset contains 200 question-answer pairs, each for English and
19 Indic languages, covering five domains specific to the Indic region. We aim
for this dataset to serve as a benchmark, providing ground truth for evaluating
the performance of LLMs in understanding and representing knowledge relevant to
the Indian context. The IndicQuest can be used for both reference-based
evaluation and LLM-as-a-judge evaluation. The dataset is shared publicly at
https://github.com/l3cube-pune/indic-nlp .

摘要：大型語言模型 (LLM) 在將印度語言納入多語言模型方面取得了重大進展。然而，量化評估這些語言是否表現得與全球主流語言（例如英語）相當至關重要。目前，缺乏專門設計用於評估 LLM 在各種印度語言中的區域知識的基準數據集。在本文中，我們提出了 L3Cube-IndicQuest，這是一個黃金標準問題解答基準數據集，旨在評估多語言 LLM 如何跨各種印度語言捕捉區域知識。該數據集包含 200 個問題解答對，每個都針對英語和 19 種印度語言，涵蓋印度地區特有的五個領域。我們希望此數據集可用作基準，為評估 LLM 在理解和表示與印度背景相關的知識方面的性能提供真實依據。IndicQuest 可用於基於參考的評估和 LLM 作為評審的評估。該數據集在 https://github.com/l3cube-pune/indic-nlp 公開共享。

##### **NeSHFS: Neighborhood Search with Heuristic-based Feature Selection for Click-Through Rate Prediction**
2409.08703v1 by Dogukan Aksu, Ismail Hakki Toroslu, Hasan Davulcu

Click-through-rate (CTR) prediction plays an important role in online
advertising and ad recommender systems. In the past decade, maximizing CTR has
been the main focus of model development and solution creation. Therefore,
researchers and practitioners have proposed various models and solutions to
enhance the effectiveness of CTR prediction. Most of the existing literature
focuses on capturing either implicit or explicit feature interactions. Although
implicit interactions are successfully captured in some studies, explicit
interactions present a challenge for achieving high CTR by extracting both
low-order and high-order feature interactions. Unnecessary and irrelevant
features may cause high computational time and low prediction performance.
Furthermore, certain features may perform well with specific predictive models
while underperforming with others. Also, feature distribution may fluctuate due
to traffic variations. Most importantly, in live production environments,
resources are limited, and the time for inference is just as crucial as
training time. Because of all these reasons, feature selection is one of the
most important factors in enhancing CTR prediction model performance. Simple
filter-based feature selection algorithms do not perform well and they are not
sufficient. An effective and efficient feature selection algorithm is needed to
consistently filter the most useful features during live CTR prediction
process. In this paper, we propose a heuristic algorithm named Neighborhood
Search with Heuristic-based Feature Selection (NeSHFS) to enhance CTR
prediction performance while reducing dimensionality and training time costs.
We conduct comprehensive experiments on three public datasets to validate the
efficiency and effectiveness of our proposed solution.

摘要：點擊率 (CTR) 預測在線上廣告和廣告推薦系統中扮演著重要的角色。在過去的十年中，最大化 CTR 一直是模型開發和解決方案建立的主要焦點。因此，研究人員和實務工作者提出了各種模型和解決方案，以增強 CTR 預測的有效性。現有的大部分文獻都著重於擷取內隱或外顯的特徵互動。儘管內隱互動在某些研究中已成功擷取，但外顯互動在提取低階和高階特徵互動時，對達成高 CTR 構成挑戰。不必要和不相關的特徵可能會導致高運算時間和低預測效能。此外，某些特徵在特定預測模型中表現良好，而在其他模型中表現不佳。此外，特徵分佈可能會因流量變化而波動。最重要的是，在實況製作環境中，資源有限，而推論時間與訓練時間一樣至關重要。由於所有這些原因，特徵選取是增強 CTR 預測模型效能最重要的因素之一。簡單的基於篩選的特徵選取演算法表現不佳，而且不足夠。需要一個有效率且有效能的特徵選取演算法，才能在實況 CTR 預測過程中持續篩選最有用的特徵。在本文中，我們提出一個名為鄰域搜尋與基於啟發式特徵選取 (NeSHFS) 的啟發式演算法，以增強 CTR 預測效能，同時降低維度和訓練時間成本。我們在三個公開資料集上進行全面的實驗，以驗證我們所提出的解決方案的效率和有效性。

##### **DM: Dual-path Magnitude Network for General Speech Restoration**
2409.08702v1 by Da-Hee Yang, Dail Kim, Joon-Hyuk Chang, Jeonghwan Choi, Han-gil Moon

In this paper, we introduce a novel general speech restoration model: the
Dual-path Magnitude (DM) network, designed to address multiple distortions
including noise, reverberation, and bandwidth degradation effectively. The DM
network employs dual parallel magnitude decoders that share parameters: one
uses a masking-based algorithm for distortion removal and the other employs a
mapping-based approach for speech restoration. A novel aspect of the DM network
is the integration of the magnitude spectrogram output from the masking decoder
into the mapping decoder through a skip connection, enhancing the overall
restoration capability. This integrated approach overcomes the inherent
limitations observed in previous models, as detailed in a step-by-step
analysis. The experimental results demonstrate that the DM network outperforms
other baseline models in the comprehensive aspect of general speech
restoration, achieving substantial restoration with fewer parameters.

摘要：在本文中，我們提出了一個新穎的通用語音還原模型：雙路幅度 (DM) 網路，旨在有效解決包括噪聲、殘響和頻寬衰減在內的各種失真。DM 網路採用共享參數的雙並行幅度解碼器：一個使用基於遮罩的演算法來移除失真，另一個採用基於對應的語音還原方法。DM 網路的一個新穎面向是將遮罩解碼器的幅度頻譜圖輸出透過跳躍連線整合到對應解碼器中，增強整體還原能力。這種整合方法克服了先前模型中觀察到的固有限制，如逐步分析中所述。實驗結果表明，DM 網路在通用語音還原的綜合方面優於其他基準模型，以較少的參數實現顯著的還原。

##### **Precision Aquaculture: An Integrated Computer Vision and IoT Approach for Optimized Tilapia Feeding**
2409.08695v1 by Rania Hossam, Ahmed Heakl, Walid Gomaa

Traditional fish farming practices often lead to inefficient feeding,
resulting in environmental issues and reduced productivity. We developed an
innovative system combining computer vision and IoT technologies for precise
Tilapia feeding. Our solution uses real-time IoT sensors to monitor water
quality parameters and computer vision algorithms to analyze fish size and
count, determining optimal feed amounts. A mobile app enables remote monitoring
and control. We utilized YOLOv8 for keypoint detection to measure Tilapia
weight from length, achieving \textbf{94\%} precision on 3,500 annotated
images. Pixel-based measurements were converted to centimeters using depth
estimation for accurate feeding calculations. Our method, with data collection
mirroring inference conditions, significantly improved results. Preliminary
estimates suggest this approach could increase production up to 58 times
compared to traditional farms. Our models, code, and dataset are
open-source~\footnote{The code, dataset, and models are available upon
reasonable request.

摘要：傳統養殖魚類的做法通常會導致餵食效率不彰，
造成環境問題和生產力降低。我們開發了一個創新的系統，結合電腦視覺和 IoT 技術，用於精準餵食吳郭魚。我們的解決方案使用即時 IoT 感測器監控水質參數，並使用電腦視覺演算法分析魚的大小和數量，以確定最佳飼料量。行動應用程式可進行遠端監控和控制。我們利用 YOLOv8 進行關鍵點偵測，以根據長度測量吳郭魚的重量，在 3,500 張標記影像上達到 \textbf{94\%} 的精準度。使用深度估計將基於像素的測量值轉換為公分，以進行準確的餵食計算。我們的這個方法，其資料收集反映了推論條件，大幅改善了結果。初步估計顯示，與傳統養殖場相比，這種方法可以將產量提高多達 58 倍。我們的模型、程式碼和資料集都是開源的~\footnote{在合理的要求下，可以取得程式碼、資料集和模型。

##### **B4: Towards Optimal Assessment of Plausible Code Solutions with Plausible Tests**
2409.08692v1 by Mouxiang Chen, Zhongxin Liu, He Tao, Yusu Hong, David Lo, Xin Xia, Jianling Sun

Selecting the best code solution from multiple generated ones is an essential
task in code generation, which can be achieved by using some reliable
validators (e.g., developer-written test cases) for assistance. Since reliable
test cases are not always available and can be expensive to build in practice,
researchers propose to automatically generate test cases to assess code
solutions. However, when both code solutions and test cases are plausible and
not reliable, selecting the best solution becomes challenging. Although some
heuristic strategies have been proposed to tackle this problem, they lack a
strong theoretical guarantee and it is still an open question whether an
optimal selection strategy exists. Our work contributes in two ways. First, we
show that within a Bayesian framework, the optimal selection strategy can be
defined based on the posterior probability of the observed passing states
between solutions and tests. The problem of identifying the best solution is
then framed as an integer programming problem. Second, we propose an efficient
approach for approximating this optimal (yet uncomputable) strategy, where the
approximation error is bounded by the correctness of prior knowledge. We then
incorporate effective prior knowledge to tailor code generation tasks. Both
theoretical and empirical studies confirm that existing heuristics are limited
in selecting the best solutions with plausible test cases. Our proposed
approximated optimal strategy B4 significantly surpasses existing heuristics in
selecting code solutions generated by large language models (LLMs) with
LLM-generated tests, achieving a relative performance improvement by up to 50%
over the strongest heuristic and 246% over the random selection in the most
challenging scenarios. Our code is publicly available at
https://github.com/ZJU-CTAG/B4.

摘要：<paragraph>在程式碼產生中，從多個產生的程式碼解決方案中選出最佳解決方案是一項必要的任務，可透過使用一些可靠的驗證器（例如開發人員撰寫的測試案例）來協助達成。由於可靠的測試案例並非總是可用，且在實務上建置成本可能很高，因此研究人員提出自動產生測試案例來評估程式碼解決方案。然而，當程式碼解決方案和測試案例都合理且不可靠時，選擇最佳解決方案就會變得具有挑戰性。雖然已提出一些啟發式策略來解決此問題，但它們缺乏強有力的理論保證，且最佳選擇策略是否存在仍是一個開放性問題。我們的研究以兩種方式做出貢獻。首先，我們證明在貝氏架構中，最佳選擇策略可以根據解決方案和測試之間觀察到的通過狀態的後驗機率來定義。然後，找出最佳解決方案的問題被設定為一個整數規劃問題。其次，我們提出了一個有效的近似方法來近似這個最佳（但不可計算）策略，其中近似誤差受到先驗知識正確性的限制。然後，我們納入有效的先驗知識來調整程式碼產生任務。理論和實證研究都證實，現有的啟發式在使用合理的測試案例選擇最佳解決方案時受到限制。我們提出的近似最佳策略 B4 在使用 LLM 產生的測試來選擇大型語言模型 (LLM) 產生的程式碼解決方案時，顯著優於現有的啟發式，在最具挑戰性的情況下，相較於最強大的啟發式，相對效能提升了 50%，相較於隨機選擇，提升了 246%。我們的程式碼已公開於 https://github.com/ZJU-CTAG/B4。</paragraph>

##### **NEST-RQ: Next Token Prediction for Speech Self-Supervised Pre-Training**
2409.08680v1 by Minglun Han, Ye Bai, Chen Shen, Youjia Huang, Mingkun Huang, Zehua Lin, Linhao Dong, Lu Lu, Yuxuan Wang

Speech self-supervised pre-training can effectively improve the performance
of downstream tasks. However, previous self-supervised learning (SSL) methods
for speech, such as HuBERT and BEST-RQ, focus on utilizing non-causal encoders
with bidirectional context, and lack sufficient support for downstream
streaming models. To address this issue, we introduce the next token prediction
based speech pre-training method with random-projection quantizer (NEST-RQ).
NEST-RQ employs causal encoders with only left context and uses next token
prediction (NTP) as the training task. On the large-scale dataset, compared to
BEST-RQ, the proposed NEST-RQ achieves comparable performance on non-streaming
automatic speech recognition (ASR) and better performance on streaming ASR. We
also conduct analytical experiments in terms of the future context size of
streaming ASR, the codebook quality of SSL and the model size of the encoder.
In summary, the paper demonstrates the feasibility of the NTP in speech SSL and
provides empirical evidence and insights for speech SSL research.

摘要：語音自我監督預訓練能有效提升下游任務的表現。然而，先前的語音自我監督學習 (SSL) 方法，例如 HuBERT 和 BEST-RQ，專注於利用具有雙向脈絡的非因果編碼器，且缺乏對下游串流模型的足夠支援。為了解決這個問題，我們引入了基於下一個標記預測的語音預訓練方法，並搭配隨機投影量化器 (NEST-RQ)。NEST-RQ 採用僅有左脈絡的因果編碼器，並使用下一個標記預測 (NTP) 作為訓練任務。在大型資料集上，與 BEST-RQ 相比，所提出的 NEST-RQ 在非串流自動語音辨識 (ASR) 上達到了相當的表現，而在串流 ASR 上則有更好的表現。我們也針對串流 ASR 的未來脈絡大小、SSL 的碼本品質和編碼器的模型大小進行了分析實驗。總之，本文證明了 NTP 在語音 SSL 中的可行性，並為語音 SSL 研究提供了實證證據和見解。

##### **Investigating Disentanglement in a Phoneme-level Speech Codec for Prosody Modeling**
2409.08664v1 by Sotirios Karapiperis, Nikolaos Ellinas, Alexandra Vioni, Junkwang Oh, Gunu Jho, Inchul Hwang, Spyros Raptis

Most of the prevalent approaches in speech prosody modeling rely on learning
global style representations in a continuous latent space which encode and
transfer the attributes of reference speech. However, recent work on neural
codecs which are based on Residual Vector Quantization (RVQ) already shows
great potential offering distinct advantages. We investigate the prosody
modeling capabilities of the discrete space of such an RVQ-VAE model, modifying
it to operate on the phoneme-level. We condition both the encoder and decoder
of the model on linguistic representations and apply a global speaker embedding
in order to factor out both phonetic and speaker information. We conduct an
extensive set of investigations based on subjective experiments and objective
measures to show that the phoneme-level discrete latent representations
obtained this way achieves a high degree of disentanglement, capturing
fine-grained prosodic information that is robust and transferable. The latent
space turns out to have interpretable structure with its principal components
corresponding to pitch and energy.

摘要：大多數流行的語音韻律模型方法依賴於在連續潛在空間中學習全域風格表示，編碼並轉移參考語音的屬性。然而，最近基於殘差向量量化 (RVQ) 的神經編解碼器已經展現出極大的潛力，提供明顯的優勢。我們研究這種 RVQ-VAE 模型離散空間的韻律建模能力，修改它以在音位層級上運作。我們對模型的編碼器和解碼器套用語言表示的條件，並套用全域說話者嵌入以分解語音和說話者資訊。我們根據主觀實驗和客觀測量進行廣泛的調查，以證明這樣獲得的音位層級離散潛在表示達成高度的解糾纏，捕捉細緻的韻律資訊，既穩健又可轉移。潛在空間被證明具有可詮釋結構，其主成分對應於音高和能量。

##### **CPL: Critical Planning Step Learning Boosts LLM Generalization in Reasoning Tasks**
2409.08642v1 by Tianlong Wang, Xueting Han, Jing Bai

Post-training large language models (LLMs) to develop reasoning capabilities
has proven effective across diverse domains, such as mathematical reasoning and
code generation. However, existing methods primarily focus on improving
task-specific reasoning but have not adequately addressed the model's
generalization capabilities across a broader range of reasoning tasks. To
tackle this challenge, we introduce Critical Planning Step Learning (CPL),
which leverages Monte Carlo Tree Search (MCTS) to explore diverse planning
steps in multi-step reasoning tasks. Based on long-term outcomes, CPL learns
step-level planning preferences to improve the model's planning capabilities
and, consequently, its general reasoning capabilities. Furthermore, while
effective in many scenarios for aligning LLMs, existing preference learning
approaches like Direct Preference Optimization (DPO) struggle with complex
multi-step reasoning tasks due to their inability to capture fine-grained
supervision at each step. We propose Step-level Advantage Preference
Optimization (Step-APO), which integrates an advantage estimate for step-level
preference pairs obtained via MCTS into the DPO. This enables the model to more
effectively learn critical intermediate planning steps, thereby further
improving its generalization in reasoning tasks. Experimental results
demonstrate that our method, trained exclusively on GSM8K and MATH, not only
significantly improves performance on GSM8K (+10.5%) and MATH (+6.5%), but also
enhances out-of-domain reasoning benchmarks, such as ARC-C (+4.0%), BBH
(+1.8%), MMLU-STEM (+2.2%), and MMLU (+0.9%).

摘要：<paragraph>訓練後的大語言模型 (LLM) 已證明能有效開發推理能力，涵蓋各種領域，例如數學推理和程式碼生成。然而，現有方法主要著重於改善特定任務的推理，但並未充分解決模型在更廣泛推理任務中的概化能力。為了解決這個挑戰，我們引入了「關鍵規劃步驟學習」(CPL)，它利用蒙地卡羅樹狀搜尋 (MCTS) 來探索多步驟推理任務中的不同規劃步驟。基於長期結果，CPL 學習步驟層級的規劃偏好，以改善模型的規劃能力，進而改善其一般推理能力。此外，雖然現有偏好學習方法（例如直接偏好最佳化 (DPO)）在許多情境中能有效調整 LLM，但對於複雜的多步驟推理任務卻難以應付，因為它們無法在每個步驟中擷取細緻的監督。我們提出了「步驟層級優勢偏好最佳化」(Step-APO)，它將透過 MCTS 獲得的步驟層級偏好對集成的優勢估計值納入 DPO 中。這使模型能更有效地學習關鍵的中間規劃步驟，進而進一步改善其在推理任務中的概化能力。實驗結果證明，我們的模型僅在 GSM8K 和 MATH 上接受訓練，不僅顯著提升了 GSM8K (+10.5%) 和 MATH (+6.5%) 的效能，也提升了領域外的推理基準，例如 ARC-C (+4.0%)、BBH (+1.8%)、MMLU-STEM (+2.2%) 和 MMLU (+0.9%)。</paragraph>

##### **Improving Analog Neural Network Robustness: A Noise-Agnostic Approach with Explainable Regularizations**
2409.08633v1 by Alice Duque, Pedro Freire, Egor Manuylovich, Dmitrii Stoliarov, Jaroslaw Prilepsky, Sergei Turitsyn

This work tackles the critical challenge of mitigating "hardware noise" in
deep analog neural networks, a major obstacle in advancing analog signal
processing devices. We propose a comprehensive, hardware-agnostic solution to
address both correlated and uncorrelated noise affecting the activation layers
of deep neural models. The novelty of our approach lies in its ability to
demystify the "black box" nature of noise-resilient networks by revealing the
underlying mechanisms that reduce sensitivity to noise. In doing so, we
introduce a new explainable regularization framework that harnesses these
mechanisms to significantly enhance noise robustness in deep neural
architectures.

摘要：這項研究應對了緩解深度類比神經網路中「硬體雜訊」的重大挑戰，這是推動類比訊號處理裝置的重大障礙。我們提出一個全面的、與硬體無關的解決方案，以解決影響深度神經模型的激活層的相關和非相關雜訊。我們的方法的新穎性在於它能夠揭示降低雜訊敏感度的基礎機制，從而揭開抗雜訊網路的「黑盒子」本質。在這樣做的過程中，我們引入了一個新的可解釋正則化框架，它利用這些機制來顯著增強深度神經架構中的雜訊魯棒性。

##### **Sybil Detection using Graph Neural Networks**
2409.08631v1 by Stuart Heeb, Andreas Plesner, Roger Wattenhofer

This paper presents SYBILGAT, a novel approach to Sybil detection in social
networks using Graph Attention Networks (GATs). Traditional methods for Sybil
detection primarily leverage structural properties of networks; however, they
tend to struggle with a large number of attack edges and are often unable to
simultaneously utilize both known Sybil and honest nodes. Our proposed method
addresses these limitations by dynamically assigning attention weights to
different nodes during aggregations, enhancing detection performance. We
conducted extensive experiments in various scenarios, including pretraining in
sampled subgraphs, synthetic networks, and networks under targeted attacks. The
results show that SYBILGAT significantly outperforms the state-of-the-art
algorithms, particularly in scenarios with high attack complexity and when the
number of attack edges increases. Our approach shows robust performance across
different network models and sizes, even as the detection task becomes more
challenging. We successfully applied the model to a real-world Twitter graph
with more than 269k nodes and 6.8M edges. The flexibility and generalizability
of SYBILGAT make it a promising tool to defend against Sybil attacks in online
social networks with only structural information.

摘要：本文提出 SYBILGAT，這是一種使用圖注意力網路 (GAT) 在社交網路中偵測 Sybil 的新方法。傳統的 Sybil 偵測方法主要利用網路的結構特性；然而，它們往往難以應付大量的攻擊邊緣，而且通常無法同時利用已知的 Sybil 節點和誠實節點。我們提出的方法透過在聚合期間動態地將注意力權重分配給不同的節點來解決這些限制，進而提升偵測效能。我們在各種情境中進行了廣泛的實驗，包括在取樣的子圖、合成網路和受到目標攻擊的網路中進行預訓練。結果顯示，SYBILGAT 明顯優於現有的演算法，特別是在攻擊複雜度高且攻擊邊緣數量增加的情況下。我們的做法在不同的網路模型和規模中展現出穩健的效能，即使偵測任務變得更具挑戰性。我們成功地將該模型應用於一個真實世界的 Twitter 圖，該圖包含超過 269k 個節點和 6.8M 條邊緣。SYBILGAT 的靈活性與泛用性使其成為一種有前途的工具，可用於防禦僅具有結構資訊的線上社交網路中的 Sybil 攻擊。

##### **Deep learning-based shot-domain seismic deblending**
2409.08602v1 by Jing Sun, Song Hou, Vetle Vinje, Gordon Poole, Leiv-J Gelius

To streamline fast-track processing of large data volumes, we have developed
a deep learning approach to deblend seismic data in the shot domain based on a
practical strategy for generating high-quality training data along with a list
of data conditioning techniques to improve performance of the data-driven
model. We make use of unblended shot gathers acquired at the end of each sail
line, to which the access requires no additional time or labor costs beyond the
blended acquisition. By manually blending these data we obtain training data
with good control of the ground truth and fully adapted to the given survey.
Furthermore, we train a deep neural network using multi-channel inputs that
include adjacent blended shot gathers as additional channels. The prediction of
the blending noise is added in as a related and auxiliary task with the main
task of the network being the prediction of the primary-source events. Blending
noise in the ground truth is scaled down during the training and validation
process due to its excessively strong amplitudes. As part of the process, the
to-be-deblended shot gathers are aligned by the blending noise. Implementation
on field blended-by-acquisition data demonstrates that introducing the
suggested data conditioning steps can considerably reduce the leakage of
primary-source events in the deep part of the blended section. The complete
proposed approach performs almost as well as a conventional algorithm in the
shallow section and shows great advantage in efficiency. It performs slightly
worse for larger traveltimes, but still removes the blending noise efficiently.

摘要：為了簡化大量資料的快速處理，我們開發出一種深度學習方法，根據生成高品質訓練資料的實用策略，以及改善資料驅動模型效能的資料處理技術清單，在震源域中去混合地震資料。我們使用在每條航線結束時取得的未混合震源資料，存取這些資料不需要額外時間或勞動力成本，超出混合取得的資料。透過手動混合這些資料，我們取得了對地面真實情況有良好控制且完全適應給定調查的訓練資料。此外，我們使用多通道輸入訓練一個深度神經網路，其中包括相鄰混合震源資料作為額外通道。混合雜訊的預測被加入作為一個相關的輔助任務，而網路的主要任務是預測主要震源事件。由於振幅過強，地面真實情況中的混合雜訊在訓練和驗證過程中會縮小。作為該過程的一部分，待去混合的震源資料會藉由混合雜訊對齊。在現場混合取得的資料上實作，證明引入建議的資料處理步驟可以大幅減少混合區段深層中主要震源事件的洩漏。完整的建議方法在淺層區段的效能幾乎與傳統演算法一樣好，且在效率上展現極大優勢。對於較大的行進時間，效能略差，但仍然可以有效移除混合雜訊。

##### **LA-RAG:Enhancing LLM-based ASR Accuracy with Retrieval-Augmented Generation**
2409.08597v1 by Shaojun Li, Hengchao Shang, Daimeng Wei, Jiaxin Guo, Zongyao Li, Xianghui He, Min Zhang, Hao Yang

Recent advancements in integrating speech information into large language
models (LLMs) have significantly improved automatic speech recognition (ASR)
accuracy. However, existing methods often constrained by the capabilities of
the speech encoders under varied acoustic conditions, such as accents. To
address this, we propose LA-RAG, a novel Retrieval-Augmented Generation (RAG)
paradigm for LLM-based ASR. LA-RAG leverages fine-grained token-level speech
datastores and a speech-to-speech retrieval mechanism to enhance ASR accuracy
via LLM in-context learning (ICL) capabilities. Experiments on Mandarin and
various Chinese dialect datasets demonstrate significant improvements in ASR
accuracy compared to existing methods, validating the effectiveness of our
approach, especially in handling accent variations.

摘要：近來將語音資訊整合至大型語言模型 (LLM) 的進展，已顯著提升自動語音辨識 (ASR) 的準確度。然而，現有方法通常受到語音編碼器在各種聲學條件（例如口音）下的能力所限制。為了解決此問題，我們提出 LA-RAG，一種基於 LLM 的 ASR 的新型檢索增強生成 (RAG) 典範。LA-RAG 利用細粒度的 token 層級語音資料儲存庫和語音轉語音檢索機制，透過 LLM 情境學習 (ICL) 能力來增強 ASR 準確度。在普通話和各種漢語方言資料集上的實驗證明，與現有方法相比，ASR 準確度有顯著的提升，驗證了我們方法的有效性，特別是在處理口音變異方面。

##### **Large Language Model Can Transcribe Speech in Multi-Talker Scenarios with Versatile Instructions**
2409.08596v1 by Lingwei Meng, Shujie Hu, Jiawen Kang, Zhaoqing Li, Yuejiao Wang, Wenxuan Wu, Xixin Wu, Xunying Liu, Helen Meng

Recent advancements in large language models (LLMs) have revolutionized
various domains, bringing significant progress and new opportunities. Despite
progress in speech-related tasks, LLMs have not been sufficiently explored in
multi-talker scenarios. In this work, we present a pioneering effort to
investigate the capability of LLMs in transcribing speech in multi-talker
environments, following versatile instructions related to multi-talker
automatic speech recognition (ASR), target talker ASR, and ASR based on
specific talker attributes such as sex, occurrence order, language, and keyword
spoken. Our approach utilizes WavLM and Whisper encoder to extract
multi-faceted speech representations that are sensitive to speaker
characteristics and semantic context. These representations are then fed into
an LLM fine-tuned using LoRA, enabling the capabilities for speech
comprehension and transcription. Comprehensive experiments reveal the promising
performance of our proposed system, MT-LLM, in cocktail party scenarios,
highlighting the potential of LLM to handle speech-related tasks based on user
instructions in such complex settings.

摘要：大型語言模型（LLM）的近期進展徹底改變了各個領域，帶來顯著的進展和新機遇。儘管在與語音相關的任務中取得進展，但 LLM 尚未在多說話者場景中得到充分探索。在這項工作中，我們提出了一項開創性的努力，以研究 LLM 在多說話者環境中轉錄語音的能力，遵循與多說話者自動語音識別 (ASR)、目標說話者 ASR 和基於特定說話者屬性的 ASR（例如性別、出現順序、語言和關鍵字）相關的多功能說明發言。我們的做法利用 WavLM 和 Whisper 編碼器來提取對說話者特徵和語義上下文敏感的多方面語音表示。然後將這些表示輸入到使用 LoRA 微調的 LLM 中，從而實現語音理解和轉錄功能。全面的實驗揭示了我們提出的系統 MT-LLM 在雞尾酒會場景中的出色性能，突出了 LLM 在此類複雜設置中根據用戶說明處理與語音相關任務的潛力。

##### **Automatic Generation of Fast and Accurate Performance Models for Deep Neural Network Accelerators**
2409.08595v1 by Konstantin Lübeck, Alexander Louis-Ferdinand Jung, Felix Wedlich, Mika Markus Müller, Federico Nicolás Peccia, Felix Thömmes, Jannik Steinmetz, Valentin Biermaier, Adrian Frischknecht, Paul Palomero Bernardo, Oliver Bringmann

Implementing Deep Neural Networks (DNNs) on resource-constrained edge devices
is a challenging task that requires tailored hardware accelerator architectures
and a clear understanding of their performance characteristics when executing
the intended AI workload. To facilitate this, we present an automated
generation approach for fast performance models to accurately estimate the
latency of a DNN mapped onto systematically modeled and concisely described
accelerator architectures. Using our accelerator architecture description
method, we modeled representative DNN accelerators such as Gemmini, UltraTrail,
Plasticine-derived, and a parameterizable systolic array. Together with DNN
mappings for those modeled architectures, we perform a combined DNN/hardware
dependency graph analysis, which enables us, in the best case, to evaluate only
154 loop kernel iterations to estimate the performance for 4.19 billion
instructions achieving a significant speedup. We outperform regression and
analytical models in terms of mean absolute percentage error (MAPE) compared to
simulation results, while being several magnitudes faster than an RTL
simulation.

摘要：在資源受限的邊緣裝置上實作深度神經網路 (DNN) 是一項艱鉅的任務，需要客製化的硬體加速器架構，以及在執行預期的 AI 工作負載時，清楚了解其效能特性。為此，我們提出一個自動化生成方法，用於快速效能模型，以準確估計 DNN 對系統化建模和簡潔描述的加速器架構的延遲。使用我們的加速器架構描述方法，我們對代表性的 DNN 加速器進行建模，例如 Gemmini、UltraTrail、Plasticine 衍生和可參數化收縮陣列。結合這些建模架構的 DNN 對應，我們執行 DNN/硬體相依圖分析，在最佳情況下，我們僅評估 154 個迴圈核心迭代，即可估計 41.9 億個指令的效能，並顯著加速。與模擬結果相比，我們在平均絕對百分比誤差 (MAPE) 方面優於迴歸和分析模型，同時比 RTL 模擬快好幾個數量級。

##### **LHQ-SVC: Lightweight and High Quality Singing Voice Conversion Modeling**
2409.08583v1 by Yubo Huang, Xin Lai, Muyang Ye, Anran Zhu, Zixi Wang, Jingzehua Xu, Shuai Zhang, Zhiyuan Zhou, Weijie Niu

Singing Voice Conversion (SVC) has emerged as a significant subfield of Voice
Conversion (VC), enabling the transformation of one singer's voice into another
while preserving musical elements such as melody, rhythm, and timbre.
Traditional SVC methods have limitations in terms of audio quality, data
requirements, and computational complexity. In this paper, we propose LHQ-SVC,
a lightweight, CPU-compatible model based on the SVC framework and diffusion
model, designed to reduce model size and computational demand without
sacrificing performance. We incorporate features to improve inference quality,
and optimize for CPU execution by using performance tuning tools and parallel
computing frameworks. Our experiments demonstrate that LHQ-SVC maintains
competitive performance, with significant improvements in processing speed and
efficiency across different devices. The results suggest that LHQ-SVC can meet

摘要：歌唱聲音轉換 (SVC) 已成為聲音轉換 (VC) 的一個重要子領域，能夠將一位歌手的聲音轉換為另一位歌手的聲音，同時保留旋律、節奏和音色等音樂元素。
傳統的 SVC 方法在音訊品質、資料需求和運算複雜性方面存在限制。在本文中，我們提出 LHQ-SVC，這是一個基於 SVC 架構和擴散模型的輕量級、相容於 CPU 的模型，旨在減少模型大小和運算需求，同時不犧牲效能。我們加入功能以提升推論品質，並透過使用效能調整工具和並行運算架構來針對 CPU 執行進行最佳化。我們的實驗證明，LHQ-SVC 保持競爭力，在處理速度和效率方面有顯著提升，適用於各種裝置。結果表明，LHQ-SVC 能夠滿足

##### **Molecular Graph Representation Learning via Structural Similarity Information**
2409.08580v1 by Chengyu Yao, Hong Huang, Hang Gao, Fengge Wu, Haiming Chen, Junsuo Zhao

Graph Neural Networks (GNNs) have been widely employed for feature
representation learning in molecular graphs. Therefore, it is crucial to
enhance the expressiveness of feature representation to ensure the
effectiveness of GNNs. However, a significant portion of current research
primarily focuses on the structural features within individual molecules, often
overlooking the structural similarity between molecules, which is a crucial
aspect encapsulating rich information on the relationship between molecular
properties and structural characteristics. Thus, these approaches fail to
capture the rich semantic information at the molecular structure level. To
bridge this gap, we introduce the \textbf{Molecular Structural Similarity Motif
GNN (MSSM-GNN)}, a novel molecular graph representation learning method that
can capture structural similarity information among molecules from a global
perspective. In particular, we propose a specially designed graph that
leverages graph kernel algorithms to represent the similarity between molecules
quantitatively. Subsequently, we employ GNNs to learn feature representations
from molecular graphs, aiming to enhance the accuracy of property prediction by
incorporating additional molecular representation information. Finally, through
a series of experiments conducted on both small-scale and large-scale molecular
datasets, we demonstrate that our model consistently outperforms eleven
state-of-the-art baselines. The codes are available at
https://github.com/yaoyao-yaoyao-cell/MSSM-GNN.

摘要：<paragraph>圖神經網路 (GNN) 已廣泛用於分子圖中的特徵表示學習。因此，增強特徵表示的表達能力對於確保 GNN 的有效性至關重要。然而，目前研究的很大一部分主要集中於個別分子內的結構特徵，常常忽略分子之間的結構相似性，而這是一個包含分子特性和結構特徵之間關係的豐富資訊的關鍵面向。因此，這些方法無法擷取分子結構層級的豐富語義資訊。為了彌補這個差距，我們引入了**分子結構相似性基序 GNN (MSSM-GNN)**，這是一種新穎的分子圖表示學習方法，可以從全局觀點擷取分子之間的結構相似性資訊。具體來說，我們提出了一個特別設計的圖，利用圖核演算法來量化表示分子之間的相似性。隨後，我們採用 GNN 從分子圖中學習特徵表示，旨在透過納入額外的分子表示資訊來提高屬性預測的準確性。最後，透過在小規模和大型分子資料集上進行一系列實驗，我們證明我們的模型始終優於十一種最先進的基準。程式碼可在 https://github.com/yaoyao-yaoyao-cell/MSSM-GNN 取得。</paragraph>

##### **Cracking the Code: Multi-domain LLM Evaluation on Real-World Professional Exams in Indonesia**
2409.08564v1 by Fajri Koto

While knowledge evaluation in large language models has predominantly focused
on academic subjects like math and physics, these assessments often fail to
capture the practical demands of real-world professions. In this paper, we
introduce IndoCareer, a dataset comprising 8,834 multiple-choice questions
designed to evaluate performance in vocational and professional certification
exams across various fields. With a focus on Indonesia, IndoCareer provides
rich local contexts, spanning six key sectors: (1) healthcare, (2) insurance
and finance, (3) creative and design, (4) tourism and hospitality, (5)
education and training, and (6) law. Our comprehensive evaluation of 27 large
language models shows that these models struggle particularly in fields with
strong local contexts, such as insurance and finance. Additionally, while using
the entire dataset, shuffling answer options generally maintains consistent
evaluation results across models, but it introduces instability specifically in
the insurance and finance sectors.

摘要：雖然大型語言模型的知識評估主要集中在數學和物理等學術科目，但這些評估通常無法掌握現實世界職業的實際需求。在本文中，我們介紹了 IndoCareer，這是一個包含 8,834 個多選題的資料集，旨在評估各個領域的職業和專業認證考試表現。IndoCareer 專注於印度尼西亞，提供了豐富的在地脈絡，涵蓋六個關鍵部門：(1) 醫療保健，(2) 保險和金融，(3) 創意和設計，(4) 旅遊和款待，(5) 教育和培訓，以及 (6) 法律。我們對 27 個大型語言模型的全面評估顯示，這些模型在具有強烈在地脈絡的領域（例如保險和金融）中特別吃力。此外，雖然使用整個資料集，但隨機排列答案選項通常會在所有模型中維持一致的評估結果，但它特別在保險和金融部門引入了不穩定性。

##### **Expediting and Elevating Large Language Model Reasoning via Hidden Chain-of-Thought Decoding**
2409.08561v1 by Tianqiao Liu, Zui Chen, Zitao Liu, Mi Tian, Weiqi Luo

Large language models (LLMs) have demonstrated remarkable capabilities in
tasks requiring reasoning and multi-step problem-solving through the use of
chain-of-thought (CoT) prompting. However, generating the full CoT process
results in significantly longer output sequences, leading to increased
computational costs and latency during inference. To address this challenge, we
propose a novel approach to compress the CoT process through semantic
alignment, enabling more efficient decoding while preserving the benefits of
CoT reasoning. Our method introduces an auxiliary CoT model that learns to
generate and compress the full thought process into a compact special token
representation semantically aligned with the original CoT output. This
compressed representation is then integrated into the input of the Hidden
Chain-of-Thought (HCoT) model. The training process follows a two-stage
procedure: First, the CoT model is optimized to generate the compressed token
representations aligned with the ground-truth CoT outputs using a contrastive
loss. Subsequently, with the CoT model parameters frozen, the HCoT model is
fine-tuned to generate accurate subsequent predictions conditioned on the
prefix instruction and the compressed CoT representations from the CoT model.
Extensive experiments across three challenging domains - mathematical
reasoning, agent invocation, and question answering - demonstrate that our
semantic compression approach achieves competitive or improved performance
compared to the full CoT baseline, while providing significant speedups of at
least 1.5x in decoding time. Moreover, incorporating contrastive learning
objectives further enhances the quality of the compressed representations,
leading to better CoT prompting and improved task accuracy. Our work paves the
way for more efficient exploitation of multi-step reasoning capabilities in
LLMs across a wide range of applications.

摘要：大型語言模型 (LLM) 已在透過思考鏈 (CoT) 提示進行推理和多步驟問題解決等任務中展現出卓越的能力。然而，生成完整的 CoT 程序會產生顯著更長的輸出序列，導致在推理期間增加運算成本和延遲。為了應對此挑戰，我們提出了一種透過語義對齊來壓縮 CoT 程序的新方法，在保留 CoT 推理優點的同時實現更有效率的解碼。我們的方法引入了輔助 CoT 模型，可學習將完整的思考過程生成並壓縮成與原始 CoT 輸出語義對齊的特殊簡潔代幣表示。然後將此壓縮表示整合到隱藏思考鏈 (HCoT) 模型的輸入中。訓練程序遵循一個兩階段程序：首先，最佳化 CoT 模型，以使用對比損失來生成與基本事實 CoT 輸出對齊的壓縮代幣表示。隨後，在凍結 CoT 模型參數的情況下，微調 HCoT 模型，以根據前置指令和來自 CoT 模型的壓縮 CoT 表示生成準確的後續預測。在三個具有挑戰性的領域（數學推理、代理呼叫和問題回答）中進行的廣泛實驗證明，與完整的 CoT 基準相比，我們的語義壓縮方法可實現競爭力或更高的效能，同時在解碼時間上提供至少 1.5 倍的顯著加速。此外，納入對比學習目標進一步提升了壓縮表示的品質，進而改善了 CoT 提示和任務準確性。我們的研究為在廣泛應用中更有效率地利用 LLM 中的多步驟推理能力鋪平了道路。

##### **LLM-Powered Grapheme-to-Phoneme Conversion: Benchmark and Case Study**
2409.08554v1 by Mahta Fetrat Qharabagh, Zahra Dehghanian, Hamid R. Rabiee

Grapheme-to-phoneme (G2P) conversion is critical in speech processing,
particularly for applications like speech synthesis. G2P systems must possess
linguistic understanding and contextual awareness of languages with polyphone
words and context-dependent phonemes. Large language models (LLMs) have
recently demonstrated significant potential in various language tasks,
suggesting that their phonetic knowledge could be leveraged for G2P. In this
paper, we evaluate the performance of LLMs in G2P conversion and introduce
prompting and post-processing methods that enhance LLM outputs without
additional training or labeled data. We also present a benchmarking dataset
designed to assess G2P performance on sentence-level phonetic challenges of the
Persian language. Our results show that by applying the proposed methods, LLMs
can outperform traditional G2P tools, even in an underrepresented language like
Persian, highlighting the potential of developing LLM-aided G2P systems.

摘要：音素轉換 (G2P) 在語音處理中至關重要，特別是對於語音合成等應用。G2P 系統必須具備語言理解力和對具有多音字和依賴於上下文的音素的語言的上下文感知能力。大型語言模型 (LLM) 最近在各種語言任務中展現出顯著的潛力，表明其音標知識可用於 G2P。在本文中，我們評估了 LLM 在 G2P 轉換中的性能，並介紹了增強 LLM 輸出的提示和後處理方法，而無需額外的訓練或標記數據。我們還提供了一個基準數據集，旨在評估 LLM 在波斯語句子級音標挑戰中的 G2P 性能。我們的結果表明，通過應用所提出的方法，LLM 可以優於傳統的 G2P 工具，即使是在波斯語等代表性不足的語言中，這突顯了開發 LLM 輔助 G2P 系統的潛力。

##### **ATFLRec: A Multimodal Recommender System with Audio-Text Fusion and Low-Rank Adaptation via Instruction-Tuned Large Language Model**
2409.08543v1 by Zezheng Qin

Recommender Systems (RS) play a pivotal role in boosting user satisfaction by
providing personalized product suggestions in domains such as e-commerce and
entertainment. This study examines the integration of multimodal data text and
audio into large language models (LLMs) with the aim of enhancing
recommendation performance. Traditional text and audio recommenders encounter
limitations such as the cold-start problem, and recent advancements in LLMs,
while promising, are computationally expensive. To address these issues,
Low-Rank Adaptation (LoRA) is introduced, which enhances efficiency without
compromising performance. The ATFLRec framework is proposed to integrate audio
and text modalities into a multimodal recommendation system, utilizing various
LoRA configurations and modality fusion techniques. Results indicate that
ATFLRec outperforms baseline models, including traditional and graph neural
network-based approaches, achieving higher AUC scores. Furthermore, separate
fine-tuning of audio and text data with distinct LoRA modules yields optimal
performance, with different pooling methods and Mel filter bank numbers
significantly impacting performance. This research offers valuable insights
into optimizing multimodal recommender systems and advancing the integration of
diverse data modalities in LLMs.

摘要：推薦系統 (RS) 在提升使用者滿意度中扮演著舉足輕重的角色，它在電子商務和娛樂等領域提供個人化的產品建議。本研究探討將多模態資料文字和音訊整合到大型語言模型 (LLM) 中，以增強推薦效能。傳統的文字和音訊推薦器會遇到冷啟動問題等限制，而 LLM 的最新進展雖然很有前景，但計算成本很高。為了解決這些問題，引入了低秩適應 (LoRA)，它在不影響效能的情況下提升了效率。ATFLRec 框架被提出來將音訊和文字模態整合到多模態推薦系統中，利用各種 LoRA 配置和模態融合技術。結果表明，ATFLRec 優於基線模型，包括傳統和基於圖神經網路的方法，達到了更高的 AUC 分數。此外，使用不同的 LoRA 模組對音訊和文字資料進行單獨微調會產生最佳效能，不同的池化方法和 Mel 濾波器組數會對效能產生顯著影響。本研究提供了寶貴的見解，用於最佳化多模態推薦系統，並推動將不同的資料模態整合到 LLM 中。

##### **SRE-CNN: A Spatiotemporal Rotation-Equivariant CNN for Cardiac Cine MR Imaging**
2409.08537v1 by Yuliang Zhu, Jing Cheng, Zhuo-Xu Cui, Jianfeng Ren, Chengbo Wang, Dong Liang

Dynamic MR images possess various transformation symmetries,including the
rotation symmetry of local features within the image and along the temporal
dimension. Utilizing these symmetries as prior knowledge can facilitate dynamic
MR imaging with high spatiotemporal resolution. Equivariant CNN is an effective
tool to leverage the symmetry priors. However, current equivariant CNN methods
fail to fully exploit these symmetry priors in dynamic MR imaging. In this
work, we propose a novel framework of Spatiotemporal Rotation-Equivariant CNN
(SRE-CNN), spanning from the underlying high-precision filter design to the
construction of the temporal-equivariant convolutional module and imaging
model, to fully harness the rotation symmetries inherent in dynamic MR images.
The temporal-equivariant convolutional module enables exploitation the rotation
symmetries in both spatial and temporal dimensions, while the high-precision
convolutional filter, based on parametrization strategy, enhances the
utilization of rotation symmetry of local features to improve the
reconstruction of detailed anatomical structures. Experiments conducted on
highly undersampled dynamic cardiac cine data (up to 20X) have demonstrated the
superior performance of our proposed approach, both quantitatively and
qualitatively.

摘要：動態 MR 影像擁有各種轉換對稱性，包括影像內部局部特徵的旋轉對稱性，以及沿時間維度的旋轉對稱性。利用這些對稱性作為先驗知識，可以促進具有高時空解析度的動態 MR 影像。等變異 CNN 是利用對稱先驗的有效工具。然而，當前的等變異 CNN 方法無法在動態 MR 影像中充分利用這些對稱先驗。在這項工作中，我們提出了一個時空旋轉等變異 CNN（SRE-CNN）的新框架，從底層的高精度濾波器設計到時間等變異卷積模組和影像模型的建構，以充分利用動態 MR 影像中固有的旋轉對稱性。時間等變異卷積模組能夠利用時空維度中的旋轉對稱性，而基於參數化策略的高精度卷積濾波器，則增強了對局部特徵旋轉對稱性的利用，以改善詳細解剖結構的重建。在高度欠採樣的動態心臟電影資料（高達 20 倍）上進行的實驗，證明了我們提出的方法在量化和質化方面的優異效能。

##### **Integration of Mamba and Transformer -- MAT for Long-Short Range Time Series Forecasting with Application to Weather Dynamics**
2409.08530v1 by Wenqing Zhang, Junming Huang, Ruotong Wang, Changsong Wei, Wenqian Huang, Yuxin Qiao

Long-short range time series forecasting is essential for predicting future
trends and patterns over extended periods. While deep learning models such as
Transformers have made significant strides in advancing time series
forecasting, they often encounter difficulties in capturing long-term
dependencies and effectively managing sparse semantic features. The state-space
model, Mamba, addresses these issues through its adept handling of selective
input and parallel computing, striking a balance between computational
efficiency and prediction accuracy. This article examines the advantages and
disadvantages of both Mamba and Transformer models, and introduces a combined
approach, MAT, which leverages the strengths of each model to capture unique
long-short range dependencies and inherent evolutionary patterns in
multivariate time series. Specifically, MAT harnesses the long-range dependency
capabilities of Mamba and the short-range characteristics of Transformers.
Experimental results on benchmark weather datasets demonstrate that MAT
outperforms existing comparable methods in terms of prediction accuracy,
scalability, and memory efficiency.

摘要：長短期時間序列預測對於預測未來趨勢和長期模式至關重要。雖然像 Transformers 這樣的深度學習模型在促進時間序列預測方面取得了顯著進展，但它們在捕捉長期依賴性和有效管理稀疏語義特徵方面常常遇到困難。狀態空間模型 Mamba 通過巧妙處理選擇性輸入和並行計算來解決這些問題，在計算效率和預測準確性之間取得平衡。本文探討了 Mamba 和 Transformer 模型的優缺點，並介紹了一種結合方法 MAT，該方法利用每種模型的優勢來捕捉多元時間序列中獨特的長短期依賴性和固有的演化模式。具體來說，MAT 利用了 Mamba 的長程依賴性能力和 Transformers 的短程特徵。基準天氣數據集上的實驗結果表明，MAT 在預測準確性、可擴展性和內存效率方面優於現有的可比方法。

##### **Eir: Thai Medical Large Language Models**
2409.08523v1 by Yutthakorn Thiprak, Rungtam Ngodngamthaweesuk, Songtam Ngodngamtaweesuk

We present Eir Thai Medical LLM, a large language model with 8 billion
parameters, specifically designed to enhance the accuracy of handling medical
tasks in the Thai language. This model focuses on providing clear and
easy-to-understand answers for both healthcare professionals and patients,
thereby improving the efficiency of diagnosis and treatment processes. Human
evaluation was conducted to ensure that the model adheres to care standards and
provides unbiased answers.
  To prioritize data security, the model is deployed within the hospital's
internal network, ensuring both high security and faster processing speeds. The
internal API connection is secured with encryption and strict authentication
measures to prevent data leaks and unauthorized access.
  We evaluated several open-source large language models with 8 billion
parameters on four medical benchmarks: MedQA, MedMCQA, PubMedQA, and the
medical subset of MMLU. The best-performing baselines were used to develop Eir
Thai Medical LLM. Our evaluation employed multiple questioning strategies,
including zero-shot, few-shot, chain-of-thought reasoning, and
ensemble/self-consistency voting methods. Our model outperformed commercially
available Thai-language large language models by more than 10%. In addition, we
developed enhanced model testing tailored for clinical use in Thai across 18
clinical tasks, where our model exceeded GPT-4o performance by more than 11%

摘要：<paragraph>我們提出了 Eir Thai Medical LLM，這是一個擁有 80 億個參數的大語言模型，專門設計用於提升泰語醫療任務的準確性。此模型專注於為醫療專業人員和患者提供清晰且易於理解的答案，從而提高診斷和治療流程的效率。進行了人工評估以確保模型符合照護標準並提供公正的答案。
為了優先考慮資料安全性，模型部署在醫院的內部網路中，確保高安全性與更快的處理速度。內部 API 連線使用加密和嚴格的身份驗證措施保護，以防止資料外洩和未經授權的存取。
我們在四個醫療基準上評估了幾個具有 80 億個參數的開源大型語言模型：MedQA、MedMCQA、PubMedQA 和 MMLU 的醫療子集。效能最好的基線用於開發 Eir Thai Medical LLM。我們的評估採用多種提問策略，包括零次學習、少次學習、思考鏈推理和整體/自洽投票方法。我們的模型優於市面上可用的泰語大型語言模型 10% 以上。此外，我們開發了針對泰語臨床使用量身打造的增強模型測試，涵蓋 18 項臨床任務，我們的模型在效能上超過 GPT-4o 11% 以上</paragraph>

##### **MAPX: An explainable model-agnostic framework for the detection of false information on social media networks**
2409.08522v1 by Sarah Condran, Michael Bewong, Selasi Kwashie, Md Zahidul Islam, Irfan Altas, Joshua Condran

The automated detection of false information has become a fundamental task in
combating the spread of "fake news" on online social media networks (OSMN) as
it reduces the need for manual discernment by individuals. In the literature,
leveraging various content or context features of OSMN documents have been
found useful. However, most of the existing detection models often utilise
these features in isolation without regard to the temporal and dynamic changes
oft-seen in reality, thus, limiting the robustness of the models. Furthermore,
there has been little to no consideration of the impact of the quality of
documents' features on the trustworthiness of the final prediction. In this
paper, we introduce a novel model-agnostic framework, called MAPX, which allows
evidence based aggregation of predictions from existing models in an
explainable manner. Indeed, the developed aggregation method is adaptive,
dynamic and considers the quality of OSMN document features. Further, we
perform extensive experiments on benchmarked fake news datasets to demonstrate
the effectiveness of MAPX using various real-world data quality scenarios. Our
empirical results show that the proposed framework consistently outperforms all
state-of-the-art models evaluated. For reproducibility, a demo of MAPX is
available at \href{https://github.com/SCondran/MAPX_framework}{this link}

摘要：自動偵測假訊息已成為對抗線上社群媒體網路（OSMN）上「假新聞」散播的基本任務，因為它減少了個人手動辨別的需要。在文獻中，利用 OSMN 文件的各種內容或背景特徵已被發現是有用的。然而，現有的偵測模型大多在不考慮現實中常見的時態和動態變化下，孤立地使用這些特徵，因此限制了模型的穩健性。此外，對於文件特徵品質對最終預測可信度的影響幾乎沒有考慮。在本文中，我們引入一個新的與模型無關的框架，稱為 MAPX，它允許以可解釋的方式從現有模型中聚合基於證據的預測。事實上，開發的聚合方法是自適應的、動態的，並且考慮 OSMN 文件特徵的品質。此外，我們對基準假新聞資料集進行廣泛的實驗，以展示 MAPX 在各種真實世界資料品質場景中的有效性。我們的實證結果表明，所提出的框架始終優於所有評估的最新模型。為確保可複製性，MAPX 的示範可以在 \href{https://github.com/SCondran/MAPX_framework}{此連結} 取得

##### **Apollo: Band-sequence Modeling for High-Quality Audio Restoration**
2409.08514v1 by Kai Li, Yi Luo

Audio restoration has become increasingly significant in modern society, not
only due to the demand for high-quality auditory experiences enabled by
advanced playback devices, but also because the growing capabilities of
generative audio models necessitate high-fidelity audio. Typically, audio
restoration is defined as a task of predicting undistorted audio from damaged
input, often trained using a GAN framework to balance perception and
distortion. Since audio degradation is primarily concentrated in mid- and
high-frequency ranges, especially due to codecs, a key challenge lies in
designing a generator capable of preserving low-frequency information while
accurately reconstructing high-quality mid- and high-frequency content.
Inspired by recent advancements in high-sample-rate music separation, speech
enhancement, and audio codec models, we propose Apollo, a generative model
designed for high-sample-rate audio restoration. Apollo employs an explicit
frequency band split module to model the relationships between different
frequency bands, allowing for more coherent and higher-quality restored audio.
Evaluated on the MUSDB18-HQ and MoisesDB datasets, Apollo consistently
outperforms existing SR-GAN models across various bit rates and music genres,
particularly excelling in complex scenarios involving mixtures of multiple
instruments and vocals. Apollo significantly improves music restoration quality
while maintaining computational efficiency. The source code for Apollo is
publicly available at https://github.com/JusperLee/Apollo.

摘要：音訊還原在現代社會中變得越來越重要，這不只是因為進階播放裝置帶來的對高品質聽覺體驗的需求，也因為生成式音訊模型的成長能力需要高保真音訊。通常，音訊還原被定義為從受損輸入預測未失真的音訊的任務，通常使用 GAN 架構進行訓練以平衡感知和失真。由於音訊劣化主要集中在中頻和高頻範圍，特別是編解碼器，因此一個關鍵挑戰在於設計一個能夠保留低頻資訊的產生器，同時精確重建高品質的中頻和高頻內容。受到最近在高取樣率音樂分離、語音增強和音訊編解碼器模型方面進展的啟發，我們提出 Apollo，一個專門用於高取樣率音訊還原的生成式模型。Apollo 使用一個明確的頻率頻段分割模組來建模不同頻率頻段之間的關係，允許更一致且更高品質的還原音訊。在 MUSDB18-HQ 和 MoisesDB 資料集上進行評估，Apollo 在各種位元率和音樂類型中始終優於現有的 SR-GAN 模型，特別是在涉及多種樂器和人聲的複雜場景中表現出色。Apollo 大幅提升了音樂還原品質，同時維持計算效率。Apollo 的原始程式碼已公開於 https://github.com/JusperLee/Apollo。

##### **Sub-graph Based Diffusion Model for Link Prediction**
2409.08487v1 by Hang Li, Wei Jin, Geri Skenderi, Harry Shomer, Wenzhuo Tang, Wenqi Fan, Jiliang Tang

Denoising Diffusion Probabilistic Models (DDPMs) represent a contemporary
class of generative models with exceptional qualities in both synthesis and
maximizing the data likelihood. These models work by traversing a forward
Markov Chain where data is perturbed, followed by a reverse process where a
neural network learns to undo the perturbations and recover the original data.
There have been increasing efforts exploring the applications of DDPMs in the
graph domain. However, most of them have focused on the generative perspective.
In this paper, we aim to build a novel generative model for link prediction. In
particular, we treat link prediction between a pair of nodes as a conditional
likelihood estimation of its enclosing sub-graph. With a dedicated design to
decompose the likelihood estimation process via the Bayesian formula, we are
able to separate the estimation of sub-graph structure and its node features.
Such designs allow our model to simultaneously enjoy the advantages of
inductive learning and the strong generalization capability. Remarkably,
comprehensive experiments across various datasets validate that our proposed
method presents numerous advantages: (1) transferability across datasets
without retraining, (2) promising generalization on limited training data, and
(3) robustness against graph adversarial attacks.

摘要：去噪扩散概率模型 (DDPM) 代表了一类当代生成模型，在合成和最大化数据似然性方面具有卓越的品质。这些模型通过遍历正向马尔可夫链来工作，其中数据受到扰动，然后是反向过程，其中神经网络学习消除扰动并恢复原始数据。在图领域探索 DDPM 的应用已成为一项日益增长的努力。然而，大多数都专注于生成视角。在本文中，我们旨在为链接预测构建一个新颖的生成模型。具体来说，我们将一对节点之间的链接预测视为其封闭子图的条件似然估计。通过贝叶斯公式分解似然估计过程的专门设计，我们能够分离子图结构及其节点特征的估计。这种设计使我们的模型能够同时享受归纳学习的优势和强大的泛化能力。值得注意的是，跨各种数据集的综合实验验证了我们提出的方法具有许多优势：(1) 无需重新训练即可跨数据集转移，(2) 对有限的训练数据进行有希望的泛化，以及 (3) 对图对抗攻击的鲁棒性。

##### **A BERT-Based Summarization approach for depression detection**
2409.08483v1 by Hossein Salahshoor Gavalan, Mohmmad Naim Rastgoo, Bahareh Nakisa

Depression is a globally prevalent mental disorder with potentially severe
repercussions if not addressed, especially in individuals with recurrent
episodes. Prior research has shown that early intervention has the potential to
mitigate or alleviate symptoms of depression. However, implementing such
interventions in a real-world setting may pose considerable challenges. A
promising strategy involves leveraging machine learning and artificial
intelligence to autonomously detect depression indicators from diverse data
sources. One of the most widely available and informative data sources is text,
which can reveal a person's mood, thoughts, and feelings. In this context,
virtual agents programmed to conduct interviews using clinically validated
questionnaires, such as those found in the DAIC-WOZ dataset, offer a robust
means for depression detection through linguistic analysis. Utilizing
BERT-based models, which are powerful and versatile yet use fewer resources
than contemporary large language models, to convert text into numerical
representations significantly enhances the precision of depression diagnosis.
These models adeptly capture complex semantic and syntactic nuances, improving
the detection accuracy of depressive symptoms. Given the inherent limitations
of these models concerning text length, our study proposes text summarization
as a preprocessing technique to diminish the length and intricacies of input
texts. Implementing this method within our uniquely developed framework for
feature extraction and classification yielded an F1-score of 0.67 on the test
set surpassing all prior benchmarks and 0.81 on the validation set exceeding
most previous results on the DAIC-WOZ dataset. Furthermore, we have devised a
depression lexicon to assess summary quality and relevance. This lexicon
constitutes a valuable asset for ongoing research in depression detection.

摘要：憂鬱症是一種全球普遍存在的心理疾病，如果不加以解決，可能會造成嚴重的後果，尤其是對有復發性發作的人。先前的研究表明，早期介入有可能減輕或緩解憂鬱症狀。然而，在現實環境中實施此類干預措施可能會帶來相當大的挑戰。一個有前途的策略包括利用機器學習和人工智慧，從不同的數據來源中自動檢測憂鬱症指標。最廣泛可用且最有資訊的數據來源之一是文字，它可以揭示一個人的情緒、想法和感受。在此脈絡中，使用臨床驗證問卷（例如在 DAIC-WOZ 資料集中找到的問卷）編寫程式進行訪談的虛擬代理人，提供了一種透過語言分析進行憂鬱症檢測的強大方法。利用 BERT 基礎模型（功能強大且用途廣泛，但使用的資源比當代大型語言模型少）將文字轉換為數值表示，可顯著提高憂鬱症診斷的準確性。這些模型巧妙地捕捉複雜的語義和句法細微差別，提高憂鬱症狀的檢測準確性。鑑於這些模型在文字長度方面存在固有缺陷，我們的研究提出文字摘要作為預處理技術，以減少輸入文字的長度和複雜性。在我們獨自開發的功能提取和分類框架中實施此方法，在測試集中產生 0.67 的 F1 分數，超越所有先前的基準，在驗證集中產生 0.81 的 F1 分數，超過 DAIC-WOZ 資料集上大多數先前的結果。此外，我們設計了一個憂鬱症詞彙表，用於評估摘要品質和相關性。此詞彙表構成憂鬱症檢測持續研究的寶貴資產。

##### **Exploring Information Retrieval Landscapes: An Investigation of a Novel Evaluation Techniques and Comparative Document Splitting Methods**
2409.08479v1 by Esmaeil Narimissa, David Raithel

The performance of Retrieval-Augmented Generation (RAG) systems in
information retrieval is significantly influenced by the characteristics of the
documents being processed. In this study, the structured nature of textbooks,
the conciseness of articles, and the narrative complexity of novels are shown
to require distinct retrieval strategies. A comparative evaluation of multiple
document-splitting methods reveals that the Recursive Character Splitter
outperforms the Token-based Splitter in preserving contextual integrity. A
novel evaluation technique is introduced, utilizing an open-source model to
generate a comprehensive dataset of question-and-answer pairs, simulating
realistic retrieval scenarios to enhance testing efficiency and metric
reliability. The evaluation employs weighted scoring metrics, including
SequenceMatcher, BLEU, METEOR, and BERT Score, to assess the system's accuracy
and relevance. This approach establishes a refined standard for evaluating the
precision of RAG systems, with future research focusing on optimizing chunk and
overlap sizes to improve retrieval accuracy and efficiency.

摘要：檢索增強生成（RAG）系統在資訊檢索中的表現，會受到處理文件特性的顯著影響。在本研究中，教科書的結構化性質、文章的簡潔性，以及小說的敘事複雜性，顯示需要不同的檢索策略。對多種文件分割方法的比較評估顯示，遞迴字元分割器在保留脈絡完整性方面優於基於代碼的分割器。引入了一種新穎的評估技術，利用開源模型生成一個包含問題和答案對的綜合資料集，模擬實際的檢索場景，以提高測試效率和指標可靠性。評估採用加權評分指標，包括 SequenceMatcher、BLEU、METEOR 和 BERT 分數，以評估系統的準確性和相關性。此方法為評估 RAG 系統的準確性建立了一個精緻的標準，未來的研究重點在於最佳化區塊和重疊大小，以提高檢索準確性和效率。

##### **Integrating Neural Operators with Diffusion Models Improves Spectral Representation in Turbulence Modeling**
2409.08477v1 by Vivek Oommen, Aniruddha Bora, Zhen Zhang, George Em Karniadakis

We integrate neural operators with diffusion models to address the spectral
limitations of neural operators in surrogate modeling of turbulent flows. While
neural operators offer computational efficiency, they exhibit deficiencies in
capturing high-frequency flow dynamics, resulting in overly smooth
approximations. To overcome this, we condition diffusion models on neural
operators to enhance the resolution of turbulent structures. Our approach is
validated for different neural operators on diverse datasets, including a high
Reynolds number jet flow simulation and experimental Schlieren velocimetry. The
proposed method significantly improves the alignment of predicted energy
spectra with true distributions compared to neural operators alone.
Additionally, proper orthogonal decomposition analysis demonstrates enhanced
spectral fidelity in space-time. This work establishes a new paradigm for
combining generative models with neural operators to advance surrogate modeling
of turbulent systems, and it can be used in other scientific applications that
involve microstructure and high-frequency content. See our project page:
vivekoommen.github.io/NO_DM

摘要：我們整合神經算子與擴散模型，以解決神經算子在湍流的代理建模中頻譜限制。雖然神經算子提供計算效率，但它們在捕捉高頻率流動動力學方面表現出不足，導致過於平滑的近似值。為了克服這個問題，我們以神經算子為條件對擴散模型進行條件設定，以增強湍流結構的分辨率。我們的做法在不同的神經算子上針對不同的資料集進行驗證，包括高雷諾數噴射流模擬和實驗性紋影速度測量。與單獨的神經算子相比，所提出的方法顯著改善了預測能量譜與真實分佈的對齊。此外，適當的正交分解分析證明了時空中的頻譜保真度得到增強。這項工作為將生成模型與神經算子結合起來以推進湍流系統的代理建模建立了一個新的範例，並且它可以用於涉及微結構和高頻率內容的其他科學應用中。請參閱我們的專案頁面：vivekoommen.github.io/NO_DM

##### **An Intent Modeling and Inference Framework for Autonomous and Remotely Piloted Aerial Systems**
2409.08472v1 by Kesav Kaza, Varun Mehta, Hamid Azad, Miodrag Bolic, Iraj Mantegh

An intent modelling and inference framework is presented to assist the
defense planning for protecting a geo-fence against unauthorized flights.
First, a novel mathematical definition for the intent of an uncrewed aircraft
system (UAS) is presented. The concepts of critical waypoints and critical
waypoint patterns are introduced and associated with a motion process to fully
characterize an intent. This modelling framework consists of representations of
a UAS mission planner, used to plan the aircraft's motion sequence, as well as
a defense planner, defined to protect the geo-fence. It is applicable to
autonomous, semi-autonomous, and piloted systems in 2D and 3D environments with
obstacles. The framework is illustrated by defining a library of intents for a
security application. Detection and tracking of the target are presumed for
formulating the intent inference problem. Multiple formulations of the decision
maker's objective are discussed as part of a deep-learning-based methodology.
Further, a multi-modal dynamic model for characterizing the UAS flight is
discussed. This is later utilized to extract features using the interacting
multiple model (IMM) filter for training the intent classifier. Finally, as
part of the simulation study, an attention-based bi-directional long short-term
memory (Bi-LSTM) network for intent inference is presented. The simulation
experiments illustrate various aspects of the framework, including trajectory
generation, radar measurement simulation, etc., in 2D and 3D environments.

摘要：<paragraph>本文提出了一個意圖建模和推論架構，協助防禦規劃以保護地理圍欄免受未經授權的飛行侵擾。
首先，本文提出了一個無人機系統 (UAS) 意圖的新數學定義。本文引入了關鍵航點和關鍵航點模式的概念，並將其與運動過程關聯起來，以充分表徵意圖。此建模架構包含無人機任務規劃器的表示，用於規劃飛機的運動序列，以及定義用於保護地理圍欄的防禦規劃器。它適用於 2D 和 3D 環境中的自主、半自主和駕駛系統，且有障礙物。該架構透過定義安全應用程式的意圖庫來說明。假設可以偵測和追蹤目標，以制定意圖推論問題。多種決策者目標的制定被視為基於深度學習的方法論的一部分。此外，本文討論了一個用於表徵無人機飛行的多模式動態模型。這後來被用於使用互動多重模型 (IMM) 濾波器提取特徵，以訓練意圖分類器。最後，作為模擬研究的一部分，本文提出了一個基於注意力的雙向長短期記憶 (Bi-LSTM) 網路，用於意圖推論。模擬實驗說明了該架構的各個方面，包括軌跡生成、雷達測量模擬等，在 2D 和 3D 環境中。</paragraph>

##### **Explaining Datasets in Words: Statistical Models with Natural Language Parameters**
2409.08466v1 by Ruiqi Zhong, Heng Wang, Dan Klein, Jacob Steinhardt

To make sense of massive data, we often fit simplified models and then
interpret the parameters; for example, we cluster the text embeddings and then
interpret the mean parameters of each cluster. However, these parameters are
often high-dimensional and hard to interpret. To make model parameters directly
interpretable, we introduce a family of statistical models -- including
clustering, time series, and classification models -- parameterized by natural
language predicates. For example, a cluster of text about COVID could be
parameterized by the predicate "discusses COVID". To learn these statistical
models effectively, we develop a model-agnostic algorithm that optimizes
continuous relaxations of predicate parameters with gradient descent and
discretizes them by prompting language models (LMs). Finally, we apply our
framework to a wide range of problems: taxonomizing user chat dialogues,
characterizing how they evolve across time, finding categories where one
language model is better than the other, clustering math problems based on
subareas, and explaining visual features in memorable images. Our framework is
highly versatile, applicable to both textual and visual domains, can be easily
steered to focus on specific properties (e.g. subareas), and explains
sophisticated concepts that classical methods (e.g. n-gram analysis) struggle
to produce.

摘要：為了理解大量資料，我們經常建立簡化的模型，然後
解釋參數；例如，我們將文本嵌入分群，然後
解釋每個群集的平均參數。然而，這些參數
通常是高維度的，難以解釋。為了讓模型參數直接
可解釋，我們引入了一系列統計模型——包括
分群、時間序列和分類模型——由自然
語言謂詞參數化。例如，一個關於 COVID 的文本群集可以
由謂詞「討論 COVID」參數化。為了有效地學習這些統計
模型，我們開發了一個與模型無關的演算法，該演算法最佳化
謂詞參數的連續放鬆，並使用梯度下降和
提示語言模型 (LM) 對其進行離散化。最後，我們將我們
的架構應用於廣泛的問題：分類使用者聊天對話，
描述它們如何隨著時間演變，找出一個
語言模型優於另一個語言模型的類別，根據
子領域對數學問題進行分群，並解釋令人難忘的圖像中的視覺特徵。我們的架構非常靈活，適用於文本和視覺領域，可以輕鬆
引導以關注特定屬性（例如子領域），並解釋
傳統方法（例如 n-gram 分析）難以產生的複雜概念。

##### **Input-to-State Stable Coupled Oscillator Networks for Closed-form Model-based Control in Latent Space**
2409.08439v1 by Maximilian Stölzle, Cosimo Della Santina

Even though a variety of methods (e.g., RL, MPC, LQR) have been proposed in
the literature, efficient and effective latent-space control of physical
systems remains an open challenge. A promising avenue would be to leverage
powerful and well-understood closed-form strategies from control theory
literature in combination with learned dynamics, such as potential-energy
shaping. We identify three fundamental shortcomings in existing latent-space
models that have so far prevented this powerful combination: (i) they lack the
mathematical structure of a physical system, (ii) they do not inherently
conserve the stability properties of the real systems. Furthermore, (iii) these
methods do not have an invertible mapping between input and latent-space
forcing. This work proposes a novel Coupled Oscillator Network (CON) model that
simultaneously tackles all these issues. More specifically, (i) we show
analytically that CON is a Lagrangian system - i.e., it presses well-defined
potential and kinetic energy terms. Then, (ii) we provide formal proof of
global Input-to-State stability using Lyapunov arguments. Moving to the
experimental side, (iii) we demonstrate that CON reaches SoA performance when
learning complex nonlinear dynamics of mechanical systems directly from images.
An additional methodological innovation contributing to achieving this third
goal is an approximated closed-form solution for efficient integration of
network dynamics, which eases efficient training. We tackle (iv) by
approximating the forcing-to-input mapping with a decoder that is trained to
reconstruct the input based on the encoded latent space force. Finally, we
leverage these four properties and show that they enable latent-space control.
We use an integral-saturated PID with potential force compensation and
demonstrate high-quality performance on a soft robot using raw pixels as the
only feedback information.

摘要：<paragraph>儘管文獻中提出了各種方法（例如 RL、MPC、LQR），但物理系統的有效且高效率的潛在空間控制仍然是一個開放性的挑戰。一個有前景的方法是利用控制理論文獻中強大且易於理解的閉合形式策略，結合學習動力學，例如勢能塑造。我們找出在現有潛在空間模型中的三個基本缺點，到目前為止，這些缺點阻礙了這種強大的組合：（i）它們缺乏物理系統的數學結構，（ii）它們本身不會保留真實系統的穩定性。此外，（iii）這些方法沒有輸入和潛在空間強制之間的可逆映射。這項工作提出了一個新穎的耦合振盪器網路 (CON) 模型，同時解決了所有這些問題。更具體地說，（i）我們分析性地表明 CON 是拉格朗日系統 - 也就是說，它壓縮定義良好的勢能和動能項。然後，（ii）我們使用李亞普諾夫論證提供了輸入到狀態的全局穩定的正式證明。轉到實驗方面，（iii）我們證明了 CON 在直接從圖像中學習機械系統的複雜非線性動力學時達到了 SoA 效能。有助於實現此第三個目標的另一項方法論創新是網路動力學有效整合的近似閉合形式解，這簡化了有效的訓練。我們通過使用訓練成根據編碼潛在空間力重建輸入的解碼器來近似強制到輸入的映射，來解決 (iv)。最後，我們利用這四個特性並表明它們啟用了潛在空間控制。我們使用具有勢能補償的積分飽和 PID，並使用原始像素作為唯一的回饋資訊，在軟機器人上展示了高品質的效能。</paragraph>

##### **When Context Leads but Parametric Memory Follows in Large Language Models**
2409.08435v1 by Yufei Tao, Adam Hiatt, Erik Haake, Antonie J. Jetter, Ameeta Agrawal

Large language models (LLMs) have demonstrated remarkable progress in
leveraging diverse knowledge sources. This study investigates how nine widely
used LLMs allocate knowledge between local context and global parameters when
answering open-ended questions in knowledge-consistent scenarios. We introduce
a novel dataset, WikiAtomic, and systematically vary context sizes to analyze
how LLMs prioritize and utilize the provided information and their parametric
knowledge in knowledge-consistent scenarios. Additionally, we also study their
tendency to hallucinate under varying context sizes. Our findings reveal
consistent patterns across models, including a consistent reliance on both
contextual (around 70%) and parametric (around 30%) knowledge, and a decrease
in hallucinations with increasing context. These insights highlight the
importance of more effective context organization and developing models that
use input more deterministically for robust performance.

摘要：大型語言模型 (LLM) 在利用多樣化的知識來源方面已展現顯著進展。本研究探討九種廣泛使用的 LLM 在知識一致的場景中回答開放式問題時，如何將知識分配到局部脈絡和全局參數。我們引入了一個新穎的資料集 WikiAtomic，並系統性地改變脈絡大小，以分析 LLM 如何在知識一致的場景中優先處理和利用提供的資訊及其參數知識。此外，我們還研究了它們在不同脈絡大小下產生幻覺的傾向。我們的研究結果揭示了所有模型的一致模式，包括持續依賴於脈絡（約 70%）和參數（約 30%）知識，以及隨著脈絡增加而減少幻覺。這些見解強調了更有效脈絡組織和開發模型的重要性，這些模型更確定地使用輸入以獲得穩健的效能。

##### **Knowledge Tagging with Large Language Model based Multi-Agent System**
2409.08406v1 by Hang Li, Tianlong Xu, Ethan Chang, Qingsong Wen

Knowledge tagging for questions is vital in modern intelligent educational
applications, including learning progress diagnosis, practice question
recommendations, and course content organization. Traditionally, these
annotations have been performed by pedagogical experts, as the task demands not
only a deep semantic understanding of question stems and knowledge definitions
but also a strong ability to link problem-solving logic with relevant knowledge
concepts. With the advent of advanced natural language processing (NLP)
algorithms, such as pre-trained language models and large language models
(LLMs), pioneering studies have explored automating the knowledge tagging
process using various machine learning models. In this paper, we investigate
the use of a multi-agent system to address the limitations of previous
algorithms, particularly in handling complex cases involving intricate
knowledge definitions and strict numerical constraints. By demonstrating its
superior performance on the publicly available math question knowledge tagging
dataset, MathKnowCT, we highlight the significant potential of an LLM-based
multi-agent system in overcoming the challenges that previous methods have
encountered. Finally, through an in-depth discussion of the implications of
automating knowledge tagging, we underscore the promising results of deploying
LLM-based algorithms in educational contexts.

摘要：知識標記對於現代智慧教育應用程式來說至關重要，包括學習進度診斷、練習題建議和課程內容組織。傳統上，這些標記是由教學專家執行，因為這項任務不僅需要對問題主幹和知識定義有深入的語義理解，還需要將問題解決邏輯與相關知識概念聯繫起來的強大能力。隨著先進的自然語言處理 (NLP) 演算法的出現，例如預先訓練的語言模型和大語言模型 (LLM)，開創性的研究已經探索使用各種機器學習模型自動化知識標記流程。在本文中，我們研究使用多代理系統來解決先前演算法的限制，特別是在處理涉及複雜知識定義和嚴格數值約束的複雜案例時。通過證明其在公開可用的數學問題知識標記資料集 MathKnowCT 上的優異效能，我們強調了基於 LLM 的多代理系統在克服先前方法遇到的挑戰方面的巨大潛力。最後，通過深入討論自動化知識標記的影響，我們強調了在教育環境中部署基於 LLM 的演算法的有希望的結果。

##### **Scores as Actions: a framework of fine-tuning diffusion models by continuous-time reinforcement learning**
2409.08400v1 by Hanyang Zhao, Haoxian Chen, Ji Zhang, David D. Yao, Wenpin Tang

Reinforcement Learning from human feedback (RLHF) has been shown a promising
direction for aligning generative models with human intent and has also been
explored in recent works for alignment of diffusion generative models. In this
work, we provide a rigorous treatment by formulating the task of fine-tuning
diffusion models, with reward functions learned from human feedback, as an
exploratory continuous-time stochastic control problem. Our key idea lies in
treating the score-matching functions as controls/actions, and upon this, we
develop a unified framework from a continuous-time perspective, to employ
reinforcement learning (RL) algorithms in terms of improving the generation
quality of diffusion models. We also develop the corresponding continuous-time
RL theory for policy optimization and regularization under assumptions of
stochastic different equations driven environment. Experiments on the
text-to-image (T2I) generation will be reported in the accompanied paper.

摘要：強化學習來自人類回饋（RLHF）已被證明是一個有希望的方向，可以將生成模型與人類意圖保持一致，並且最近的工作也已探索用於擴散生成模型的一致性。在這項工作中，我們通過將微調擴散模型的任務表述為一個探索性連續時間隨機控制問題，並從人類回饋中學習獎勵函數，提供了一個嚴謹的處理方法。我們的關鍵思想在於將分數匹配函數視為控制/動作，並在此基礎上，我們從連續時間的角度開發了一個統一的框架，以採用強化學習（RL）演算法來改善擴散模型的生成品質。我們還開發了相應的連續時間 RL 理論，用於在隨機不同方程式驅動環境的假設下進行策略優化和正則化。文本到影像（T2I）生成的實驗將在附帶論文中報告。

##### **Self-Supervised Inference of Agents in Trustless Environments**
2409.08386v1 by Vladyslav Larin, Ivan Nikitin, Alexander Firsov

In this paper, we propose a novel approach where agents can form swarms to
produce high-quality responses effectively. This is accomplished by utilizing
agents capable of data inference and ranking, which can be effectively
implemented using LLMs as response classifiers. We assess existing approaches
for trustless agent inference, define our methodology, estimate practical
parameters, and model various types of malicious agent attacks. Our method
leverages the collective intelligence of swarms, ensuring robust and efficient
decentralized AI inference with better accuracy, security, and reliability. We
show that our approach is an order of magnitude faster than other trustless
inference strategies reaching less than 125 ms validation latency.

摘要：在本文中，我們提出了一種新穎的方法，其中代理可以形成群體，以有效地產生高品質的回應。這是通過利用能夠進行數據推理和排名的代理來實現的，這些代理可以使用 LLM 作為響應分類器來有效地實現。我們評估了現有的無信任代理推理方法，定義了我們的方法論，估計了實際參數，並對各種類型的惡意代理攻擊進行了建模。我們的技術利用了群體的集體智慧，確保了健壯且高效的去中心化 AI 推理，具有更好的準確性、安全性與可靠性。我們表明，我們的技術比其他無信任推理策略快一個數量級，驗證延遲小於 125 毫秒。

##### **Rethinking Prompting Strategies for Multi-Label Recognition with Partial Annotations**
2409.08381v1 by Samyak Rawlekar, Shubhang Bhatnagar, Narendra Ahuja

Vision-language models (VLMs) like CLIP have been adapted for Multi-Label
Recognition (MLR) with partial annotations by leveraging prompt-learning, where
positive and negative prompts are learned for each class to associate their
embeddings with class presence or absence in the shared vision-text feature
space. While this approach improves MLR performance by relying on VLM priors,
we hypothesize that learning negative prompts may be suboptimal, as the
datasets used to train VLMs lack image-caption pairs explicitly focusing on
class absence. To analyze the impact of positive and negative prompt learning
on MLR, we introduce PositiveCoOp and NegativeCoOp, where only one prompt is
learned with VLM guidance while the other is replaced by an embedding vector
learned directly in the shared feature space without relying on the text
encoder. Through empirical analysis, we observe that negative prompts degrade
MLR performance, and learning only positive prompts, combined with learned
negative embeddings (PositiveCoOp), outperforms dual prompt learning
approaches. Moreover, we quantify the performance benefits that prompt-learning
offers over a simple vision-features-only baseline, observing that the baseline
displays strong performance comparable to dual prompt learning approach
(DualCoOp), when the proportion of missing labels is low, while requiring half
the training compute and 16 times fewer parameters

摘要：視覺語言模型 (VLM)，如 CLIP，已透過提示學習進行多標籤辨識 (MLR)，其中針對每個類別學習正向和負向提示，以將其嵌入與類別在共享視覺文本特徵空間中是否存在關聯。雖然這種方法透過依賴 VLM 先驗來提升 MLR 效能，但我們假設學習負向提示可能是次佳的，因為用於訓練 VLM 的資料集缺乏明確著重於類別不存在的影像標題配對。為了分析正向和負向提示學習對 MLR 的影響，我們引入了 PositiveCoOp 和 NegativeCoOp，其中只使用 VLM 指導學習一個提示，而另一個提示則由在共享特徵空間中直接學習的嵌入向量取代，而不依賴文字編碼器。透過實證分析，我們觀察到負向提示會降低 MLR 效能，而且僅學習正向提示，並結合學習的負向嵌入 (PositiveCoOp)，其效能優於雙重提示學習方法。此外，我們量化了提示學習相較於僅限視覺特徵的簡單基準所提供的效能優勢，觀察到當遺失標籤的比例較低時，基準會顯示出與雙重提示學習方法 (DualCoOp) 相當的強大效能，同時需要一半的訓練運算和少 16 倍的參數

##### **The Impact of Large Language Models on Open-source Innovation: Evidence from GitHub Copilot**
2409.08379v1 by Doron Yeverechyahu, Raveesh Mayya, Gal Oestreicher-Singer

Generative AI (GenAI) has been shown to enhance individual productivity in a
guided setting. While it is also likely to transform processes in a
collaborative work setting, it is unclear what trajectory this transformation
will follow. Collaborative environment is characterized by a blend of
origination tasks that involve building something from scratch and iteration
tasks that involve refining on others' work. Whether GenAI affects these two
aspects of collaborative work and to what extent is an open empirical question.
We study this question within the open-source development landscape, a prime
example of collaborative innovation, where contributions are voluntary and
unguided. Specifically, we focus on the launch of GitHub Copilot in October
2021 and leverage a natural experiment in which GitHub Copilot (a
programming-focused LLM) selectively rolled out support for Python, but not for
R. We observe a significant jump in overall contributions, suggesting that
GenAI effectively augments collaborative innovation in an unguided setting.
Interestingly, Copilot's launch increased maintenance-related contributions,
which are mostly iterative tasks involving building on others' work,
significantly more than code-development contributions, which are mostly
origination tasks involving standalone contributions. This disparity was
exacerbated in active projects with extensive coding activity, raising concerns
that, as GenAI models improve to accommodate richer context, the gap between
origination and iterative solutions may widen. We discuss practical and policy
implications to incentivize high-value innovative solutions.

摘要：生成式人工智能 (GenAI) 已被證明可提升個人在指導設定中的生產力。雖然它也可能會轉變協作工作設定中的流程，但目前尚不清楚此轉型將會遵循什麼軌跡。協作環境的特徵是融合了從頭開始建立某項事物的新建工作和對他人工作進行優化的反覆工作。GenAI 是否影響協作工作的這兩個面向，以及影響程度如何，是一個開放的實證問題。我們在開放原始碼開發環境中研究此問題，這是協作創新的主要範例，其中貢獻是自願且不受指導的。具體來說，我們專注於 2021 年 10 月發布的 GitHub Copilot，並利用 GitHub Copilot（以程式設計為主的 LLM）選擇性地推出對 Python 的支援，但沒有對 R 的支援，這是一個自然實驗。我們觀察到整體貢獻大幅增加，這表明 GenAI 有效地增加了在不受指導的設定中的協作創新。有趣的是，Copilot 的推出增加了與維護相關的貢獻，這些貢獻大多是涉及建立在他人工作上的反覆工作，遠多於程式碼開發貢獻，後者大多是涉及獨立貢獻的新建工作。這種差異在具有廣泛編碼活動的活躍專案中被加劇，這引發了擔憂，即隨著 GenAI 模型的改進以適應更豐富的內容，新建和反覆解決方案之間的差距可能會擴大。我們討論了激勵高價值創新解決方案的實際和政策含意。

##### **FedProphet: Memory-Efficient Federated Adversarial Training via Theoretic-Robustness and Low-Inconsistency Cascade Learning**
2409.08372v1 by Minxue Tang, Yitu Wang, Jingyang Zhang, Louis DiValentin, Aolin Ding, Amin Hass, Yiran Chen, Hai "Helen" Li

Federated Learning (FL) provides a strong privacy guarantee by enabling local
training across edge devices without training data sharing, and Federated
Adversarial Training (FAT) further enhances the robustness against adversarial
examples, promoting a step toward trustworthy artificial intelligence. However,
FAT requires a large model to preserve high accuracy while achieving strong
robustness, and it is impractically slow when directly training with
memory-constrained edge devices due to the memory-swapping latency. Moreover,
existing memory-efficient FL methods suffer from poor accuracy and weak
robustness in FAT because of inconsistent local and global models, i.e.,
objective inconsistency.
  In this paper, we propose FedProphet, a novel FAT framework that can achieve
memory efficiency, adversarial robustness, and objective consistency
simultaneously. FedProphet partitions the large model into small cascaded
modules such that the memory-constrained devices can conduct adversarial
training module-by-module. A strong convexity regularization is derived to
theoretically guarantee the robustness of the whole model, and we show that the
strong robustness implies low objective inconsistency in FedProphet. We also
develop a training coordinator on the server of FL, with Adaptive Perturbation
Adjustment for utility-robustness balance and Differentiated Module Assignment
for objective inconsistency mitigation. FedProphet empirically shows a
significant improvement in both accuracy and robustness compared to previous
memory-efficient methods, achieving almost the same performance of end-to-end
FAT with 80% memory reduction and up to 10.8x speedup in training time.

摘要：<paragraph>联邦学习 (FL) 借由启用边缘设备进行本地训练，且不分享训练数据，提供强力的隐私保证，而联邦对抗训练 (FAT) 进一步增强对抗范例的稳健性，促进迈向可信赖的人工智能。然而，FAT 需要大型模型来保持高准确性，同时实现强稳健性，并且直接使用内存受限的边缘设备进行训练时，由于内存交换延迟，其实际上很慢。此外，现有的内存高效 FL 方法在 FAT 中遭受准确性差和稳健性弱的问题，这是因为本地模型和全局模型不一致，即目标不一致。
  在本文中，我们提出 FedProphet，这是一个新颖的 FAT 框架，可以同时实现内存效率、对抗稳健性和目标一致性。FedProphet 将大型模型分割成小型级联模块，以便内存受限的设备可以逐模块地进行对抗训练。推导出强凸性正则化来从理论上保证整个模型的稳健性，并且我们表明强稳健性表示 FedProphet 中的低目标不一致性。我们还在 FL 的服务器上开发了一个训练协调器，其中包含用于效用稳健性平衡的自适应扰动调整和用于缓解目标不一致性的差异化模块分配。FedProphet 在准确性和稳健性方面均显示出显着的改善，与之前的内存高效方法相比，实现了与端到端 FAT 几乎相同的性能，内存减少了 80%，训练时间加快了 10.8 倍。</paragraph>

##### **E-QUARTIC: Energy Efficient Edge Ensemble of Convolutional Neural Networks for Resource-Optimized Learning**
2409.08369v1 by Le Zhang, Onat Gungor, Flavio Ponzina, Tajana Rosing

Ensemble learning is a meta-learning approach that combines the predictions
of multiple learners, demonstrating improved accuracy and robustness.
Nevertheless, ensembling models like Convolutional Neural Networks (CNNs)
result in high memory and computing overhead, preventing their deployment in
embedded systems. These devices are usually equipped with small batteries that
provide power supply and might include energy-harvesting modules that extract
energy from the environment. In this work, we propose E-QUARTIC, a novel Energy
Efficient Edge Ensembling framework to build ensembles of CNNs targeting
Artificial Intelligence (AI)-based embedded systems. Our design outperforms
single-instance CNN baselines and state-of-the-art edge AI solutions, improving
accuracy and adapting to varying energy conditions while maintaining similar
memory requirements. Then, we leverage the multi-CNN structure of the designed
ensemble to implement an energy-aware model selection policy in
energy-harvesting AI systems. We show that our solution outperforms the
state-of-the-art by reducing system failure rate by up to 40% while ensuring
higher average output qualities. Ultimately, we show that the proposed design
enables concurrent on-device training and high-quality inference execution at
the edge, limiting the performance and energy overheads to less than 0.04%.

摘要：整體學習是一種元學習方法，它結合了多個學習者的預測，展示了改進的準確性和穩健性。
儘管如此，像卷積神經網路 (CNN) 這樣的整體模型會導致高記憶體和運算開銷，阻止它們部署在嵌入式系統中。這些設備通常配備小電池，可提供電源，並且可能包括從環境中提取能量的能量收集模組。在這項工作中，我們提出了 E-QUARTIC，一個新穎的節能邊緣整體架構，用於建立針對人工智慧 (AI) 基於嵌入式系統的 CNN 整體。我們的設計優於單一實例 CNN 基準和最先進的邊緣 AI 解決方案，提高準確性並適應不同的能量條件，同時保持類似的記憶體需求。然後，我們利用設計的整體的多 CNN 結構，在能量收集 AI 系統中實施一個節能模型選擇策略。我們展示了我們的解決方案優於最先進的技術，將系統故障率降低了 40%，同時確保更高的平均輸出品質。最終，我們展示了所提出的設計能夠在邊緣進行並發的裝置上訓練和高品質的推論執行，將效能和能源開銷限制在低於 0.04%。

##### **An Experimental Study of Competitive Market Behavior Through LLMs**
2409.08357v1 by Jingru Jia, Zehua Yuan

This study explores the potential of large language models (LLMs) to conduct
market experiments, aiming to understand their capability to comprehend
competitive market dynamics. We model the behavior of market agents in a
controlled experimental setting, assessing their ability to converge toward
competitive equilibria. The results reveal the challenges current LLMs face in
replicating the dynamic decision-making processes characteristic of human
trading behavior. Unlike humans, LLMs lacked the capacity to achieve market
equilibrium. The research demonstrates that while LLMs provide a valuable tool
for scalable and reproducible market simulations, their current limitations
necessitate further advancements to fully capture the complexities of market
behavior. Future work that enhances dynamic learning capabilities and
incorporates elements of behavioral economics could improve the effectiveness
of LLMs in the economic domain, providing new insights into market dynamics and
aiding in the refinement of economic policies.

摘要：本研究探討大型語言模型 (LLM) 進行市場實驗的潛力，旨在了解其理解競爭市場動態的能力。我們在受控實驗環境中模擬市場代理人的行為，評估他們收斂於競爭均衡的能力。結果揭示了當前 LLM 在複製人類交易行為特有的動態決策制定過程中面臨的挑戰。與人類不同，LLM 缺乏實現市場均衡的能力。研究表明，儘管 LLM 為可擴充且可重製的市場模擬提供了有價值的工具，但其當前的限制需要進一步的進展才能全面掌握市場行為的複雜性。增強動態學習能力並納入行為經濟學元素的未來工作可以提高 LLM 在經濟領域的有效性，提供對市場動態的新見解，並有助於完善經濟政策。

##### **Bayesian Inverse Graphics for Few-Shot Concept Learning**
2409.08351v1 by Octavio Arriaga, Jichen Guo, Rebecca Adam, Sebastian Houben, Frank Kirchner

Humans excel at building generalizations of new concepts from just one single
example. Contrary to this, current computer vision models typically require
large amount of training samples to achieve a comparable accuracy. In this work
we present a Bayesian model of perception that learns using only minimal data,
a prototypical probabilistic program of an object. Specifically, we propose a
generative inverse graphics model of primitive shapes, to infer posterior
distributions over physically consistent parameters from one or several images.
We show how this representation can be used for downstream tasks such as
few-shot classification and pose estimation. Our model outperforms existing
few-shot neural-only classification algorithms and demonstrates generalization
across varying lighting conditions, backgrounds, and out-of-distribution
shapes. By design, our model is uncertainty-aware and uses our new
differentiable renderer for optimizing global scene parameters through gradient
descent, sampling posterior distributions over object parameters with Markov
Chain Monte Carlo (MCMC), and using a neural based likelihood function.

摘要：人類擅長僅從一個單一範例建立新概念的概括。與此相反，目前的電腦視覺模型通常需要大量的訓練樣本才能達到可比較的準確度。在這項工作中，我們提出一個貝氏感知模型，它僅使用最少的數據進行學習，一個物體的原型機率程式。具體來說，我們提出一個原始形狀的生成式反向圖形模型，以從一個或多個影像推論出物理一致參數上的後驗分佈。我們展示如何將此表徵用於下游任務，例如少樣本分類和姿勢估計。我們的模型優於現有的僅神經少樣本分類演算法，並展示了在不同光照條件、背景和分布外形狀下的概括能力。根據設計，我們的模型具有不確定性感知，並使用我們新的可微分渲染器透過梯度下降最佳化全局場景參數，使用馬可夫鏈蒙地卡羅 (MCMC) 對物件參數進行後驗分佈取樣，並使用基於神經的似然函數。

##### **Towards Quantifying and Reducing Language Mismatch Effects in Cross-Lingual Speech Anti-Spoofing**
2409.08346v1 by Tianchi Liu, Ivan Kukanov, Zihan Pan, Qiongqiong Wang, Hardik B. Sailor, Kong Aik Lee

The effects of language mismatch impact speech anti-spoofing systems, while
investigations and quantification of these effects remain limited. Existing
anti-spoofing datasets are mainly in English, and the high cost of acquiring
multilingual datasets hinders training language-independent models. We initiate
this work by evaluating top-performing speech anti-spoofing systems that are
trained on English data but tested on other languages, observing notable
performance declines. We propose an innovative approach - Accent-based data
expansion via TTS (ACCENT), which introduces diverse linguistic knowledge to
monolingual-trained models, improving their cross-lingual capabilities. We
conduct experiments on a large-scale dataset consisting of over 3 million
samples, including 1.8 million training samples and nearly 1.2 million testing
samples across 12 languages. The language mismatch effects are preliminarily
quantified and remarkably reduced over 15% by applying the proposed ACCENT.
This easily implementable method shows promise for multilingual and
low-resource language scenarios.

摘要：語言不匹配的影響會影響語音防偽系統，而對這些影響的調查和量化仍然有限。現有的防偽數據集主要使用英文，而獲取多語言數據集的高昂成本阻礙了訓練語言無關模型。我們通過評估使用英文數據訓練但使用其他語言測試的表現最佳的語音防偽系統來啟動這項工作，觀察到表現顯著下降。我們提出了一種創新的方法 - 基於口音的數據擴展通過 TTS（ACCENT），它將多樣的語言知識引入到單語言訓練模型中，從而提高了它們的跨語言能力。我們對一個包含 300 萬個樣本的大規模數據集進行了實驗，其中包括 180 萬個訓練樣本和 12 種語言的近 120 萬個測試樣本。通過應用所提出的 ACCENT，語言不匹配的影響得到了初步量化，並顯著降低了 15% 以上。這種易於實現的方法顯示出對多語言和低資源語言場景很有前途。

##### **Real or Robotic? Assessing Whether LLMs Accurately Simulate Qualities of Human Responses in Dialogue**
2409.08330v1 by Johnathan Ivey, Shivani Kumar, Jiayu Liu, Hua Shen, Sushrita Rakshit, Rohan Raju, Haotian Zhang, Aparna Ananthasubramaniam, Junghwan Kim, Bowen Yi, Dustin Wright, Abraham Israeli, Anders Giovanni Møller, Lechen Zhang, David Jurgens

Studying and building datasets for dialogue tasks is both expensive and
time-consuming due to the need to recruit, train, and collect data from study
participants. In response, much recent work has sought to use large language
models (LLMs) to simulate both human-human and human-LLM interactions, as they
have been shown to generate convincingly human-like text in many settings.
However, to what extent do LLM-based simulations \textit{actually} reflect
human dialogues? In this work, we answer this question by generating a
large-scale dataset of 100,000 paired LLM-LLM and human-LLM dialogues from the
WildChat dataset and quantifying how well the LLM simulations align with their
human counterparts. Overall, we find relatively low alignment between
simulations and human interactions, demonstrating a systematic divergence along
the multiple textual properties, including style and content. Further, in
comparisons of English, Chinese, and Russian dialogues, we find that models
perform similarly. Our results suggest that LLMs generally perform better when
the human themself writes in a way that is more similar to the LLM's own style.

摘要：研究和建立对话任务的数据集既昂贵又耗时，这是因为需要招募、培训和收集研究参与者的数据。对此，许多近期工作试图使用大型语言模型（LLM）来模拟人与人以及人与 LLM 之间的互动，因为它们已被证明可以在许多设置中生成令人信服的类人文本。然而，基于 LLM 的模拟在多大程度上\textit{实际上}反映了人类对话？在这项工作中，我们通过从 WildChat 数据集中生成一个包含 100,000 对 LLM-LLM 和人机对话的大规模数据集，并量化 LLM 模拟与其人类对应项的匹配程度，来回答这个问题。总体而言，我们发现模拟与人类互动之间的匹配度相对较低，这证明了在包括风格和内容在内的多种文本属性上的系统性差异。此外，在对英语、中文和俄语对话的比较中，我们发现模型的表现相似。我们的结果表明，当人类自己以更类似于 LLM 自身风格的方式书写时，LLM 通常表现得更好。

##### **AnySkin: Plug-and-play Skin Sensing for Robotic Touch**
2409.08276v1 by Raunaq Bhirangi, Venkatesh Pattabiraman, Enes Erciyes, Yifeng Cao, Tess Hellebrekers, Lerrel Pinto

While tactile sensing is widely accepted as an important and useful sensing
modality, its use pales in comparison to other sensory modalities like vision
and proprioception. AnySkin addresses the critical challenges that impede the
use of tactile sensing -- versatility, replaceability, and data reusability.
Building on the simplistic design of ReSkin, and decoupling the sensing
electronics from the sensing interface, AnySkin simplifies integration making
it as straightforward as putting on a phone case and connecting a charger.
Furthermore, AnySkin is the first uncalibrated tactile-sensor with
cross-instance generalizability of learned manipulation policies. To summarize,
this work makes three key contributions: first, we introduce a streamlined
fabrication process and a design tool for creating an adhesive-free, durable
and easily replaceable magnetic tactile sensor; second, we characterize slip
detection and policy learning with the AnySkin sensor; and third, we
demonstrate zero-shot generalization of models trained on one instance of
AnySkin to new instances, and compare it with popular existing tactile
solutions like DIGIT and ReSkin.https://any-skin.github.io/

摘要：儘管觸覺感測被廣泛接受為一種重要且有用的感測方式，但與視覺和本體感覺等其他感官方式相比，它的使用顯得相形見絀。AnySkin 解決了阻礙觸覺感測使用的關鍵挑戰，包括多功能性、可替換性和資料可重用性。AnySkin 建立在 ReSkin 的簡化設計之上，並將感測電子元件與感測介面分開，簡化了整合，使其像戴上手機殼並連接充電器一樣簡單。此外，AnySkin 是第一個未校準的觸覺感測器，具有跨例學習操作策略的概括性。總之，這項工作做出了三項關鍵貢獻：首先，我們引入了一個簡化的製造流程和一個設計工具，用於建立無黏著劑、耐用且易於更換的磁性觸覺感測器；其次，我們利用 AnySkin 感測器來表徵滑動偵測和策略學習；第三，我們展示了在一個 AnySkin 實例上訓練的模型對新實例的零次學習概括性，並將其與 DIGIT 和 ReSkin 等現有的熱門觸覺解決方案進行了比較。https://any-skin.github.io/

##### **Hand-Object Interaction Pretraining from Videos**
2409.08273v1 by Himanshu Gaurav Singh, Antonio Loquercio, Carmelo Sferrazza, Jane Wu, Haozhi Qi, Pieter Abbeel, Jitendra Malik

We present an approach to learn general robot manipulation priors from 3D
hand-object interaction trajectories. We build a framework to use in-the-wild
videos to generate sensorimotor robot trajectories. We do so by lifting both
the human hand and the manipulated object in a shared 3D space and retargeting
human motions to robot actions. Generative modeling on this data gives us a
task-agnostic base policy. This policy captures a general yet flexible
manipulation prior. We empirically demonstrate that finetuning this policy,
with both reinforcement learning (RL) and behavior cloning (BC), enables
sample-efficient adaptation to downstream tasks and simultaneously improves
robustness and generalizability compared to prior approaches. Qualitative
experiments are available at: \url{https://hgaurav2k.github.io/hop/}.

摘要：我們提出一個方法，從 3D 手部物件互動軌跡中學習一般機器人操控先驗。我們建立一個架構，使用野外影片來產生感測運動機器人軌跡。我們這樣做是透過提升人類的手和被操控的物件在一個共用的 3D 空間中，並將人類動作重新設定為機器人動作。這個資料上的生成模型給了我們一個與任務無關的基本策略。此策略捕捉到一般但靈活的操控先驗。我們經驗性地證明，微調此策略，同時使用強化學習 (RL) 和行為複製 (BC)，能有效率地調整下游任務，並同時改善健壯性和概括性，與先前的做法相比。定性實驗可以在以下網址取得：\url{https://hgaurav2k.github.io/hop/}。

##### **Windows Agent Arena: Evaluating Multi-Modal OS Agents at Scale**
2409.08264v2 by Rogerio Bonatti, Dan Zhao, Francesco Bonacci, Dillon Dupont, Sara Abdali, Yinheng Li, Yadong Lu, Justin Wagle, Kazuhito Koishida, Arthur Bucker, Lawrence Jang, Zack Hui

Large language models (LLMs) show remarkable potential to act as computer
agents, enhancing human productivity and software accessibility in multi-modal
tasks that require planning and reasoning. However, measuring agent performance
in realistic environments remains a challenge since: (i) most benchmarks are
limited to specific modalities or domains (e.g. text-only, web navigation, Q&A,
coding) and (ii) full benchmark evaluations are slow (on order of magnitude of
days) given the multi-step sequential nature of tasks. To address these
challenges, we introduce the Windows Agent Arena: a reproducible, general
environment focusing exclusively on the Windows operating system (OS) where
agents can operate freely within a real Windows OS and use the same wide range
of applications, tools, and web browsers available to human users when solving
tasks. We adapt the OSWorld framework (Xie et al., 2024) to create 150+ diverse
Windows tasks across representative domains that require agent abilities in
planning, screen understanding, and tool usage. Our benchmark is scalable and
can be seamlessly parallelized in Azure for a full benchmark evaluation in as
little as 20 minutes. To demonstrate Windows Agent Arena's capabilities, we
also introduce a new multi-modal agent, Navi. Our agent achieves a success rate
of 19.5% in the Windows domain, compared to 74.5% performance of an unassisted
human. Navi also demonstrates strong performance on another popular web-based
benchmark, Mind2Web. We offer extensive quantitative and qualitative analysis
of Navi's performance, and provide insights into the opportunities for future
research in agent development and data generation using Windows Agent Arena.
  Webpage: https://microsoft.github.io/WindowsAgentArena
  Code: https://github.com/microsoft/WindowsAgentArena

摘要：大型語言模型 (LLM) 展現出作為電腦代理的顯著潛力，在需要規劃和推理的多模態任務中提升人類生產力和軟體可及性。然而，在現實環境中衡量代理效能仍然是一項挑戰，原因如下：(i) 大多數基準測試僅限於特定模態或領域（例如純文字、網路導覽、問答、編碼），以及 (ii) 由於任務的多步驟順序性質，完整的基準測試評估很慢（約需數天）。為了應對這些挑戰，我們引入了 Windows Agent Arena：一個可重製、通用的環境，專注於 Windows 作業系統 (OS)，其中代理可以在真正的 Windows OS 中自由操作，並在解決任務時使用與人類使用者相同的廣泛應用程式、工具和網路瀏覽器。我們採用 OSWorld 框架（謝等人，2024 年）來建立 150 多項多元的 Windows 任務，涵蓋需要代理在規劃、螢幕理解和工具使用方面具備能力的代表性領域。我們的基準測試具有可擴充性，可以在 Azure 中無縫並行化，在短短 20 分鐘內完成完整的基準測試評估。為了展示 Windows Agent Arena 的功能，我們還引入了一個新的多模態代理程式 Navi。與未受協助的人類 74.5% 的表現相比，我們的代理在 Windows 領域達到了 19.5% 的成功率。Navi 在另一個流行的網路基準測試 Mind2Web 上也表現出強勁的效能。我們提供了 Navi 效能的廣泛量化和定性分析，並提供了使用 Windows Agent Arena 進行代理開發和資料產生的未來研究機會的見解。
網頁：https://microsoft.github.io/WindowsAgentArena
程式碼：https://github.com/microsoft/WindowsAgentArena

##### **LoRID: Low-Rank Iterative Diffusion for Adversarial Purification**
2409.08255v1 by Geigh Zollicoffer, Minh Vu, Ben Nebgen, Juan Castorena, Boian Alexandrov, Manish Bhattarai

This work presents an information-theoretic examination of diffusion-based
purification methods, the state-of-the-art adversarial defenses that utilize
diffusion models to remove malicious perturbations in adversarial examples. By
theoretically characterizing the inherent purification errors associated with
the Markov-based diffusion purifications, we introduce LoRID, a novel Low-Rank
Iterative Diffusion purification method designed to remove adversarial
perturbation with low intrinsic purification errors. LoRID centers around a
multi-stage purification process that leverages multiple rounds of
diffusion-denoising loops at the early time-steps of the diffusion models, and
the integration of Tucker decomposition, an extension of matrix factorization,
to remove adversarial noise at high-noise regimes. Consequently, LoRID
increases the effective diffusion time-steps and overcomes strong adversarial
attacks, achieving superior robustness performance in CIFAR-10/100, CelebA-HQ,
and ImageNet datasets under both white-box and black-box settings.

摘要：這項工作提出了基於擴散的淨化方法的信息理論檢驗，這是一種最先進的對抗性防禦，利用擴散模型來移除對抗性範例中的惡意擾動。通過理論上表徵與基於馬可夫的擴散淨化相關的固有淨化誤差，我們引入了 LoRID，一種新穎的低秩反覆擴散淨化方法，旨在以低內在淨化誤差移除對抗性擾動。LoRID 以多階段淨化過程為中心，利用擴散模型的早期時間步長進行多輪擴散去噪迴圈，並整合了矩陣分解的延伸 — 塔克分解，以在高噪聲狀態下移除對抗性雜訊。因此，LoRID增加了有效的擴散時間步長，並克服了強大的對抗性攻擊，在白盒和黑盒設定下，在 CIFAR-10/100、CelebA-HQ 和 ImageNet 資料集上達到了優異的穩健性表現。

##### **The Design of Informative Take-Over Requests for Semi-Autonomous Cyber-Physical Systems: Combining Spoken Language and Visual Icons in a Drone-Controller Setting**
2409.08253v2 by Ashwini Gundappa, Emilia Ellsiepen, Lukas Schmitz, Frederik Wiehr, Vera Demberg

The question of how cyber-physical systems should interact with human
partners that can take over control or exert oversight is becoming more
pressing, as these systems are deployed for an ever larger range of tasks.
Drawing on the literatures on handing over control during semi-autonomous
driving and human-robot interaction, we propose a design of a take-over request
that combines an abstract pre-alert with an informative TOR: Relevant sensor
information is highlighted on the controller's display, while a spoken message
verbalizes the reason for the TOR. We conduct our study in the context of a
semi-autonomous drone control scenario as our testbed. The goal of our online
study is to assess in more detail what form a language-based TOR should take.
Specifically, we compare a full sentence condition to shorter fragments, and
test whether the visual highlighting should be done synchronously or
asynchronously with the speech. Participants showed a higher accuracy in
choosing the correct solution with our bi-modal TOR and felt that they were
better able to recognize the critical situation. Using only fragments in the
spoken message rather than full sentences did not lead to improved accuracy or
faster reactions. Also, synchronizing the visual highlighting with the spoken
message did not result in better accuracy and response times were even
increased in this condition.

摘要：隨著這些系統被部署到越來越廣泛的任務中，如何讓網路物理系統與可以接管控制或執行監督的人類夥伴互動的問題變得越來越緊迫。
透過利用關於在半自動駕駛和人機互動中移交控制權的文獻，我們提出了一個接管請求的設計，它結合了一個抽象的預警和一個資訊性的 TOR：相關的感測器資訊會在控制器的顯示器上被凸顯，而一個口語訊息則會表達 TOR 的原因。我們在一個半自動無人機控制場景的背景下進行我們的研究，作為我們的測試平台。我們的線上研究的目標是更詳細地評估基於語言的 TOR 應該採取什麼形式。
具體來說，我們比較一個完整句子的條件和較短的片段，並測試視覺凸顯是否應該與語音同步或異步進行。參與者在使用我們的雙模式 TOR 時展現出更高的準確性，並感覺他們更能夠識別關鍵情況。在口語訊息中只使用片段而不是完整句子並未導致準確性提高或反應更快。此外，將視覺凸顯與口語訊息同步並未導致更好的準確性，而且在此條件下，反應時間甚至增加。

##### **OmniQuery: Contextually Augmenting Captured Multimodal Memory to Enable Personal Question Answering**
2409.08250v1 by Jiahao Nick Li, Zhuohao Jerry Zhang, Jiaju Ma

People often capture memories through photos, screenshots, and videos. While
existing AI-based tools enable querying this data using natural language, they
mostly only support retrieving individual pieces of information like certain
objects in photos and struggle with answering more complex queries that involve
interpreting interconnected memories like event sequences. We conducted a
one-month diary study to collect realistic user queries and generated a
taxonomy of necessary contextual information for integrating with captured
memories. We then introduce OmniQuery, a novel system that is able to answer
complex personal memory-related questions that require extracting and inferring
contextual information. OmniQuery augments single captured memories through
integrating scattered contextual information from multiple interconnected
memories, retrieves relevant memories, and uses a large language model (LLM) to
comprehensive answers. In human evaluations, we show the effectiveness of
OmniQuery with an accuracy of 71.5%, and it outperformed a conventional RAG
system, winning or tying in 74.5% of the time.

摘要：人們經常透過照片、螢幕截圖和影片來捕捉回憶。現有的基於人工智慧的工具，雖然能使用自然語言來查詢這些資料，但它們大多只支援擷取個別資訊，例如照片中的特定物件，而且很難回答涉及解讀相互連結回憶（例如事件順序）的更複雜查詢。我們進行了一項為期一個月的日記研究，以收集實際的使用者查詢，並產生了一個必要的脈絡資訊分類法，用於與擷取的回憶整合。然後，我們介紹 OmniQuery，這是一個新穎的系統，能夠回答複雜的個人記憶相關問題，需要擷取和推斷脈絡資訊。OmniQuery 透過整合來自多個相互連結回憶的零散脈絡資訊，來擴充單一的擷取回憶，擷取相關回憶，並使用大型語言模型 (LLM) 來提供全面的答案。在人類評量中，我們以 71.5% 的準確度展示了 OmniQuery 的有效性，並且它優於傳統的 RAG 系統，在 74.5% 的時間中獲勝或打平。

##### **IFAdapter: Instance Feature Control for Grounded Text-to-Image Generation**
2409.08240v1 by Yinwei Wu, Xianpan Zhou, Bing Ma, Xuefeng Su, Kai Ma, Xinchao Wang

While Text-to-Image (T2I) diffusion models excel at generating visually
appealing images of individual instances, they struggle to accurately position
and control the features generation of multiple instances. The Layout-to-Image
(L2I) task was introduced to address the positioning challenges by
incorporating bounding boxes as spatial control signals, but it still falls
short in generating precise instance features. In response, we propose the
Instance Feature Generation (IFG) task, which aims to ensure both positional
accuracy and feature fidelity in generated instances. To address the IFG task,
we introduce the Instance Feature Adapter (IFAdapter). The IFAdapter enhances
feature depiction by incorporating additional appearance tokens and utilizing
an Instance Semantic Map to align instance-level features with spatial
locations. The IFAdapter guides the diffusion process as a plug-and-play
module, making it adaptable to various community models. For evaluation, we
contribute an IFG benchmark and develop a verification pipeline to objectively
compare models' abilities to generate instances with accurate positioning and
features. Experimental results demonstrate that IFAdapter outperforms other
models in both quantitative and qualitative evaluations.

摘要：文本到图像 (T2I) 扩散模型虽然很擅长生成视觉上吸引人的个体实例图像，但它们在准确定位和控制多个实例的特征生成方面却遇到了困难。布局到图像 (L2I) 任务通过将边界框作为空间控制信号来解决定位难题，但它在生成精确的实例特征方面仍然存在不足。对此，我们提出了实例特征生成 (IFG) 任务，旨在确保生成实例中的位置准确性和特征保真度。为了解决 IFG 任务，我们引入了实例特征适配器 (IFAdapter)。IFAdapter 通过合并额外的外观标记并利用实例语义图将实例级特征与空间位置对齐来增强特征描述。IFAdapter 以即插即用模块的形式指导扩散过程，使其能够适应各种社区模型。为了进行评估，我们贡献了一个 IFG 基准并开发了一个验证管道，以客观地比较模型生成具有准确定位和特征的实例的能力。实验结果表明，IFAdapter 在定量和定性评估中都优于其他模型。

##### **Source2Synth: Synthetic Data Generation and Curation Grounded in Real Data Sources**
2409.08239v1 by Alisia Lupidi, Carlos Gemmell, Nicola Cancedda, Jane Dwivedi-Yu, Jason Weston, Jakob Foerster, Roberta Raileanu, Maria Lomeli

Large Language Models still struggle in challenging scenarios that leverage
structured data, complex reasoning, or tool usage. In this paper, we propose
Source2Synth: a new method that can be used for teaching LLMs new skills
without relying on costly human annotations. Source2Synth takes as input a
custom data source and produces synthetic data points with intermediate
reasoning steps grounded in real-world sources. Source2Synth improves the
dataset quality by discarding low-quality generations based on their
answerability. We demonstrate the generality of this approach by applying it to
two challenging domains: we test reasoning abilities in multi-hop question
answering (MHQA), and tool usage in tabular question answering (TQA). Our
method improves performance by 25.51% for TQA on WikiSQL and 22.57% for MHQA on
HotPotQA compared to the fine-tuned baselines.

摘要：大型語言模型在利用結構化資料、複雜推理或工具使用的情況下仍面臨挑戰。在本文中，我們提出 Source2Synth：一種新的方法，可用於教授 LLM 新技能，而無需依賴昂貴的人工註解。Source2Synth 以自訂資料來源作為輸入，並產生以真實世界來源為基礎的合成資料點，其中包含中間推理步驟。Source2Synth 透過根據其可回答性來捨棄低品質的生成，進而提升資料集品質。我們透過將此方法應用於兩個具有挑戰性的領域來展示此方法的普遍性：我們在多跳問題回答 (MHQA) 中測試推理能力，以及在表格問題回答 (TQA) 中測試工具使用。與微調基線相比，我們的模型在 WikiSQL 上的 TQA 任務中將效能提升了 25.51%，在 HotPotQA 上的 MHQA 任務中提升了 22.57%。

##### **LLM Honeypot: Leveraging Large Language Models as Advanced Interactive Honeypot Systems**
2409.08234v1 by Hakan T. Otal, M. Abdullah Canbaz

The rapid evolution of cyber threats necessitates innovative solutions for
detecting and analyzing malicious activity. Honeypots, which are decoy systems
designed to lure and interact with attackers, have emerged as a critical
component in cybersecurity. In this paper, we present a novel approach to
creating realistic and interactive honeypot systems using Large Language Models
(LLMs). By fine-tuning a pre-trained open-source language model on a diverse
dataset of attacker-generated commands and responses, we developed a honeypot
capable of sophisticated engagement with attackers. Our methodology involved
several key steps: data collection and processing, prompt engineering, model
selection, and supervised fine-tuning to optimize the model's performance.
Evaluation through similarity metrics and live deployment demonstrated that our
approach effectively generates accurate and informative responses. The results
highlight the potential of LLMs to revolutionize honeypot technology, providing
cybersecurity professionals with a powerful tool to detect and analyze
malicious activity, thereby enhancing overall security infrastructure.

摘要：網路威脅的快速演變，需要創新的解決方案來偵測和分析惡意活動。Honeypot 是用來引誘和與攻擊者互動的誘餌系統，已成為網路安全中至關重要的組成部分。在本文中，我們提出了一種使用大型語言模型 (LLM) 來建立逼真且互動式 honeypot 系統的新方法。透過微調預先訓練的開源語言模型，使用攻擊者產生的指令和回應的多元資料集，我們開發了一個 honeypot，能夠與攻擊者進行複雜的互動。我們的做法包含幾個關鍵步驟：資料收集和處理、提示工程、模型選擇，以及監督微調以最佳化模型的效能。透過相似性指標和實際部署的評估，證明了我們的做法有效地產生了準確且有意義的回應。結果凸顯了 LLM 徹底改變 honeypot 技術的潛力，為網路安全專業人員提供了一個強大的工具來偵測和分析惡意活動，進而增強整體的安全基礎架構。

##### **CliquePH: Higher-Order Information for Graph Neural Networks through Persistent Homology on Clique Graphs**
2409.08217v1 by Davide Buffelli, Farzin Soleymani, Bastian Rieck

Graph neural networks have become the default choice by practitioners for
graph learning tasks such as graph classification and node classification.
Nevertheless, popular graph neural network models still struggle to capture
higher-order information, i.e., information that goes \emph{beyond} pairwise
interactions. Recent work has shown that persistent homology, a tool from
topological data analysis, can enrich graph neural networks with topological
information that they otherwise could not capture. Calculating such features is
efficient for dimension 0 (connected components) and dimension 1 (cycles).
However, when it comes to higher-order structures, it does not scale well, with
a complexity of $O(n^d)$, where $n$ is the number of nodes and $d$ is the order
of the structures. In this work, we introduce a novel method that extracts
information about higher-order structures in the graph while still using the
efficient low-dimensional persistent homology algorithm. On standard benchmark
datasets, we show that our method can lead to up to $31\%$ improvements in test
accuracy.

摘要：圖形神經網路已成為從業人員在圖形學習任務（例如圖形分類和節點分類）中的預設選擇。
儘管如此，流行的圖形神經網路模型仍難以擷取高階資訊，即超越成對互動的資訊。最近的研究顯示，作為拓撲資料分析工具的持續同調，可以用拓撲資訊豐富圖形神經網路，而這些資訊是它們無法擷取的。計算此類特徵對於維度 0（連通元件）和維度 1（循環）來說很有效率。
然而，當涉及到高階結構時，它的擴充性不佳，複雜度為 $O(n^d)$，其中 $n$ 是節點數，$d$ 是結構的階數。在這項工作中，我們介紹了一種新方法，用於萃取圖形中高階結構的資訊，同時仍使用高效的低維持續同調演算法。在標準基準資料集上，我們顯示我們的模型可以使測試準確度提升多達 $31\%$。

##### **LT3SD: Latent Trees for 3D Scene Diffusion**
2409.08215v1 by Quan Meng, Lei Li, Matthias Nießner, Angela Dai

We present LT3SD, a novel latent diffusion model for large-scale 3D scene
generation. Recent advances in diffusion models have shown impressive results
in 3D object generation, but are limited in spatial extent and quality when
extended to 3D scenes. To generate complex and diverse 3D scene structures, we
introduce a latent tree representation to effectively encode both
lower-frequency geometry and higher-frequency detail in a coarse-to-fine
hierarchy. We can then learn a generative diffusion process in this latent 3D
scene space, modeling the latent components of a scene at each resolution
level. To synthesize large-scale scenes with varying sizes, we train our
diffusion model on scene patches and synthesize arbitrary-sized output 3D
scenes through shared diffusion generation across multiple scene patches.
Through extensive experiments, we demonstrate the efficacy and benefits of
LT3SD for large-scale, high-quality unconditional 3D scene generation and for
probabilistic completion for partial scene observations.

摘要：我們提出 LT3SD，一種適用於大規模 3D 場景生成的新型潛在擴散模型。擴散模型的最新進展已在 3D 物件生成中展現出令人印象深刻的成果，但當擴展到 3D 場景時，其空間範圍和品質卻受到限制。為了生成複雜且多樣的 3D 場景結構，我們引入潛在樹狀表示法，以在由粗至細的階層結構中有效編碼低頻幾何和高頻細節。然後，我們可以在這個潛在 3D 場景空間中學習生成擴散過程，對場景的潛在組成部分進行建模，並在每個解析度層級中建模。為了合成具有不同大小的大規模場景，我們在場景貼片上訓練我們的擴散模型，並透過多個場景貼片的共享擴散生成合成任意大小的輸出 3D 場景。透過廣泛的實驗，我們證明了 LT3SD 在大規模、高品質無條件 3D 場景生成以及部分場景觀察的機率性完成方面的效能和優點。

##### **What Makes a Maze Look Like a Maze?**
2409.08202v1 by Joy Hsu, Jiayuan Mao, Joshua B. Tenenbaum, Noah D. Goodman, Jiajun Wu

A unique aspect of human visual understanding is the ability to flexibly
interpret abstract concepts: acquiring lifted rules explaining what they
symbolize, grounding them across familiar and unfamiliar contexts, and making
predictions or reasoning about them. While off-the-shelf vision-language models
excel at making literal interpretations of images (e.g., recognizing object
categories such as tree branches), they still struggle to make sense of such
visual abstractions (e.g., how an arrangement of tree branches may form the
walls of a maze). To address this challenge, we introduce Deep Schema Grounding
(DSG), a framework that leverages explicit structured representations of visual
abstractions for grounding and reasoning. At the core of DSG are
schemas--dependency graph descriptions of abstract concepts that decompose them
into more primitive-level symbols. DSG uses large language models to extract
schemas, then hierarchically grounds concrete to abstract components of the
schema onto images with vision-language models. The grounded schema is used to
augment visual abstraction understanding. We systematically evaluate DSG and
different methods in reasoning on our new Visual Abstractions Dataset, which
consists of diverse, real-world images of abstract concepts and corresponding
question-answer pairs labeled by humans. We show that DSG significantly
improves the abstract visual reasoning performance of vision-language models,
and is a step toward human-aligned understanding of visual abstractions.

摘要：人類視覺理解的獨特面向在於靈活詮釋抽象概念的能力：獲取解釋其象徵意義的提升規則，在熟悉和不熟悉的背景下奠定其基礎，並對其進行預測或推理。雖然現成的視覺語言模型擅長對影像進行字面詮釋（例如辨識樹枝等物體類別），但它們在理解此類視覺抽象概念時仍有困難（例如樹枝的排列如何形成迷宮的牆壁）。為了應對此挑戰，我們引入了深度模式基礎（DSG），這是一個框架，利用視覺抽象概念的明確結構化表示來進行基礎和推理。DSG 的核心是模式——抽象概念的依賴圖描述，將其分解為更原始層級的符號。DSG 使用大型語言模型來提取模式，然後將模式的具體組成部分分層基礎到影像上，並使用視覺語言模型。基礎模式用於擴充視覺抽象理解。我們系統性地評估了 DSG 和我們的新視覺抽象資料集上的不同推理方法，該資料集包含各種真實世界的抽象概念影像，以及由人類標記的對應問題解答對。我們證明 DSG 大幅提升了視覺語言模型的抽象視覺推理效能，並且朝著與人類一致的視覺抽象理解邁進一步。

##### **AudioBERT: Audio Knowledge Augmented Language Model**
2409.08199v1 by Hyunjong Ok, Suho Yoo, Jaeho Lee

Recent studies have identified that language models, pretrained on text-only
datasets, often lack elementary visual knowledge, \textit{e.g.,} colors of
everyday objects. Motivated by this observation, we ask whether a similar
shortcoming exists in terms of the \textit{auditory} knowledge. To answer this
question, we construct a new dataset called AuditoryBench, which consists of
two novel tasks for evaluating auditory knowledge. Based on our analysis using
the benchmark, we find that language models also suffer from a severe lack of
auditory knowledge. To address this limitation, we propose AudioBERT, a novel
method to augment the auditory knowledge of BERT through a retrieval-based
approach. First, we detect auditory knowledge spans in prompts to query our
retrieval model efficiently. Then, we inject audio knowledge into BERT and
switch on low-rank adaptation for effective adaptation when audio knowledge is
required. Our experiments demonstrate that AudioBERT is quite effective,
achieving superior performance on the AuditoryBench. The dataset and code are
available at \bulurl{https://github.com/HJ-Ok/AudioBERT}.

摘要：最近的研究發現，在純文字資料集上進行預訓練的語言模型，通常缺乏基本的視覺知識，例如日常物品的顏色。受此觀察結果的啟發，我們想知道在聽覺知識方面是否存在類似的缺點。為了回答這個問題，我們建構了一個名為 AuditoryBench 的新資料集，其中包含兩個評估聽覺知識的新穎任務。根據我們使用基準進行的分析，我們發現語言模型也嚴重缺乏聽覺知識。為了解決這個限制，我們提出了 AudioBERT，這是一種透過檢索為基礎的方法來擴充 BERT 聽覺知識的新方法。首先，我們在提示中偵測聽覺知識範圍，以有效查詢我們的檢索模型。然後，我們將音訊知識注入 BERT，並在需要音訊知識時開啟低階適應以進行有效的適應。我們的實驗證明 AudioBERT 非常有效，在 AuditoryBench 上取得優異的效能。資料集和程式碼可在 https://github.com/HJ-Ok/AudioBERT 取得。

##### **Fine-tuning Large Language Models for Entity Matching**
2409.08185v1 by Aaron Steiner, Ralph Peeters, Christian Bizer

Generative large language models (LLMs) are a promising alternative to
pre-trained language models for entity matching due to their high zero-shot
performance and their ability to generalize to unseen entities. Existing
research on using LLMs for entity matching has focused on prompt engineering
and in-context learning. This paper explores the potential of fine-tuning LLMs
for entity matching. We analyze fine-tuning along two dimensions: 1) The
representation of training examples, where we experiment with adding different
types of LLM-generated explanations to the training set, and 2) the selection
and generation of training examples using LLMs. In addition to the matching
performance on the source dataset, we investigate how fine-tuning affects the
model's ability to generalize to other in-domain datasets as well as across
topical domains. Our experiments show that fine-tuning significantly improves
the performance of the smaller models while the results for the larger models
are mixed. Fine-tuning also improves the generalization to in-domain datasets
while hurting cross-domain transfer. We show that adding structured
explanations to the training set has a positive impact on the performance of
three out of four LLMs, while the proposed example selection and generation
methods only improve the performance of Llama 3.1 8B while decreasing the
performance of GPT-4o Mini.

摘要：生成式大型語言模型 (LLM) 由於其高零次學習表現以及對未見實體進行泛化的能力，是實體配對中預先訓練語言模型的有希望的替代方案。現有關於使用 LLM 進行實體配對的研究已專注於提示工程和情境學習。本文探討了微調 LLM 以進行實體配對的潛力。我們沿著兩個面向分析微調：1) 訓練範例的表徵，我們在其中嘗試將不同類型的 LLM 生成的說明新增到訓練組，以及 2) 使用 LLM 選擇和產生訓練範例。除了在來源資料集上的配對效能之外，我們探討微調如何影響模型對其他領域內資料集以及跨主題領域進行泛化的能力。我們的實驗顯示，微調顯著提升較小型模型的效能，而較大型模型的結果則好壞參半。微調也提升了對領域內資料集的泛化，同時損害了跨領域轉移。我們顯示，將結構化說明新增到訓練組對四個 LLM 中的三個的效能有正面的影響，而所提出的範例選擇和產生方法僅提升了 Llama 3.1 8B 的效能，同時降低了 GPT-4o Mini 的效能。

##### **On the Role of Context in Reading Time Prediction**
2409.08160v1 by Andreas Opedal, Eleanor Chodroff, Ryan Cotterell, Ethan Gotlieb Wilcox

We present a new perspective on how readers integrate context during
real-time language comprehension. Our proposals build on surprisal theory,
which posits that the processing effort of a linguistic unit (e.g., a word) is
an affine function of its in-context information content. We first observe that
surprisal is only one out of many potential ways that a contextual predictor
can be derived from a language model. Another one is the pointwise mutual
information (PMI) between a unit and its context, which turns out to yield the
same predictive power as surprisal when controlling for unigram frequency.
Moreover, both PMI and surprisal are correlated with frequency. This means that
neither PMI nor surprisal contains information about context alone. In response
to this, we propose a technique where we project surprisal onto the orthogonal
complement of frequency, yielding a new contextual predictor that is
uncorrelated with frequency. Our experiments show that the proportion of
variance in reading times explained by context is a lot smaller when context is
represented by the orthogonalized predictor. From an interpretability
standpoint, this indicates that previous studies may have overstated the role
that context has in predicting reading times.

摘要：我們提出了一個新的觀點，說明讀者如何在實時語言理解過程中整合脈絡。我們的提案建立在驚奇理論之上，該理論假設語言單元（例如單詞）的處理工作量是其上下文信息內容的仿射函數。我們首先觀察到，驚奇只是從語言模型中推導上下文預測器的許多潛在方法之一。另一種方法是單元及其上下文之間的逐點互信息 (PMI)，當控制單字頻率時，它產生的預測能力與驚奇相同。此外，PMI 和驚奇都與頻率相關。這表示 PMI 和驚奇都不包含僅關於脈絡的信息。針對此問題，我們提出了一種技術，將驚奇投影到頻率的正交補集上，產生一個與頻率無關的新上下文預測器。我們的實驗表明，當脈絡由正交化預測器表示時，閱讀時間中由脈絡解釋的變異比例要小得多。從可解釋性的角度來看，這表明先前的研究可能誇大了脈絡在預測閱讀時間中所扮演的角色。

