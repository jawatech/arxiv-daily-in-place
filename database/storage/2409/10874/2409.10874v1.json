{"2409.10874": {"publish_time": "2024-09-17", "title": "American Sign Language to Text Translation using Transformer and Seq2Seq with LSTM", "paper_summary": "Sign language translation is one of the important issues in communication\nbetween deaf and hearing people, as it expresses words through hand, body, and\nmouth movements. American Sign Language is one of the sign languages used, one\nof which is the alphabetic sign. The development of neural machine translation\ntechnology is moving towards sign language translation. Transformer became the\nstate-of-the-art in natural language processing. This study compares the\nTransformer with the Sequence-to-Sequence (Seq2Seq) model in translating sign\nlanguage to text. In addition, an experiment was conducted by adding Residual\nLong Short-Term Memory (ResidualLSTM) in the Transformer. The addition of\nResidualLSTM to the Transformer reduces the performance of the Transformer\nmodel by 23.37% based on the BLEU Score value. In comparison, the Transformer\nitself increases the BLEU Score value by 28.14 compared to the Seq2Seq model.", "paper_summary_zh": "\u624b\u8a9e\u7ffb\u8b6f\u662f\u807e\u4eba\u548c\u807d\u4eba\u6e9d\u901a\u4e2d\u7684\u91cd\u8981\u8b70\u984c\u4e4b\u4e00\uff0c\u56e0\u70ba\u5b83\u900f\u904e\u624b\u3001\u8eab\u9ad4\u548c\u5634\u5df4\u7684\u52d5\u4f5c\u4f86\u8868\u9054\u55ae\u5b57\u3002\u7f8e\u570b\u624b\u8a9e\u662f\u5176\u4e2d\u4e00\u7a2e\u624b\u8a9e\uff0c\u5176\u4e2d\u4e00\u7a2e\u662f\u5b57\u6bcd\u624b\u8a9e\u3002\u795e\u7d93\u6a5f\u5668\u7ffb\u8b6f\u6280\u8853\u7684\u767c\u5c55\u6b63\u671d\u5411\u624b\u8a9e\u7ffb\u8b6f\u9081\u9032\u3002Transformer \u6210\u70ba\u4e86\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u7684\u6700\u65b0\u6280\u8853\u3002\u672c\u7814\u7a76\u6bd4\u8f03\u4e86 Transformer \u8207\u5e8f\u5217\u5230\u5e8f\u5217 (Seq2Seq) \u6a21\u578b\u5728\u5c07\u624b\u8a9e\u7ffb\u8b6f\u6210\u6587\u5b57\u7684\u8868\u73fe\u3002\u6b64\u5916\uff0c\u9084\u900f\u904e\u5728 Transformer \u4e2d\u52a0\u5165\u6b98\u5dee\u9577\u77ed\u671f\u8a18\u61b6 (ResidualLSTM) \u9032\u884c\u5be6\u9a57\u3002\u5728 Transformer \u4e2d\u52a0\u5165 ResidualLSTM \u6703\u8b93 Transformer \u6a21\u578b\u7684\u8868\u73fe\u964d\u4f4e 23.37%\uff0c\u6839\u64da BLEU \u8a55\u5206\u503c\u3002\u76f8\u8f03\u4e4b\u4e0b\uff0c\u8207 Seq2Seq \u6a21\u578b\u76f8\u6bd4\uff0cTransformer \u672c\u8eab\u8b93 BLEU \u8a55\u5206\u503c\u589e\u52a0\u4e86 28.14\u3002", "author": "Gregorius Guntur Sunardi Putra et.al.", "authors": "Gregorius Guntur Sunardi Putra, Adifa Widyadhani Chanda D'Layla, Dimas Wahono, Riyanarto Sarno, Agus Tri Haryono", "id": "2409.10874v1", "paper_url": "http://arxiv.org/abs/2409.10874v1", "repo": "null"}}