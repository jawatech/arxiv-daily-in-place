{"2408.13854": {"publish_time": "2024-08-25", "title": "Tangram: A Challenging Benchmark for Geometric Element Recognizing", "paper_summary": "Significant advancements in Large Multimodal Models (LMMs) have enabled them\nto tackle complex problems involving visual-mathematical reasoning. However,\ntheir ability to identify geometric elements remains understudied. To bridge\nthis gap, we introduce Tangram, a novel benchmark designed to evaluate the\nperformance of LMMs on geometric element recognition. Tangram includes 1,080\ndiverse geometric diagrams sourced from primary and secondary school exams,\ncompetitions, and textbooks, covering from simple basic geometric shapes to\ncomplex combinations. Each diagram is associated with four questions, resulting\nin a total of 4,320 visual-question-answer pairs. Unlike existing benchmarks\nthat seek higher-level cognition and reasoning, Tangram focuses on the\nunderstanding of geometric elements, requiring models to perform a \"simple but\ninteresting\" counting task. Systematic evaluation of 10 prominent LMMs, such as\nGPT-4o and Claude 3.5 Sonnet, shows that even in the seemingly simple task,\nthese models still face significant challenges. Notably, the overall accuracy\nof the top performer across all tested models is only 56.8%, marking a\nsignificant gap when compared to human performance. These findings highlight\nthe limitations of current multimodal artificial intelligence systems in\nhandling basic perception tasks, and will inspire the development of the next\ngeneration of expert-level multimodal foundational models. The Tangram and\nevaluation code will be available soon.", "paper_summary_zh": "\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b (LMM) \u7684\u91cd\u5927\u8fdb\u5c55\u4f7f\u5b83\u4eec\u80fd\u591f\u89e3\u51b3\u6d89\u53ca\u89c6\u89c9\u6570\u5b66\u63a8\u7406\u7684\u590d\u6742\u95ee\u9898\u3002\u7136\u800c\uff0c\u5b83\u4eec\u8bc6\u522b\u51e0\u4f55\u5143\u7d20\u7684\u80fd\u529b\u4ecd\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002\u4e3a\u4e86\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\uff0c\u6211\u4eec\u5f15\u5165\u4e86 Tangram\uff0c\u8fd9\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u57fa\u51c6\uff0c\u65e8\u5728\u8bc4\u4f30 LMM \u5728\u51e0\u4f55\u5143\u7d20\u8bc6\u522b\u4e0a\u7684\u6027\u80fd\u3002Tangram \u5305\u542b 1,080 \u4e2a\u6765\u81ea\u5c0f\u5b66\u548c\u4e2d\u5b66\u8003\u8bd5\u3001\u7ade\u8d5b\u548c\u6559\u79d1\u4e66\u7684\u591a\u6837\u5316\u51e0\u4f55\u56fe\u5f62\uff0c\u6db5\u76d6\u4ece\u7b80\u5355\u7684\u57fa\u672c\u51e0\u4f55\u5f62\u72b6\u5230\u590d\u6742\u7684\u7ec4\u5408\u3002\u6bcf\u4e2a\u56fe\u8868\u90fd\u4e0e\u56db\u4e2a\u95ee\u9898\u76f8\u5173\uff0c\u603b\u5171\u5f62\u6210 4,320 \u4e2a\u89c6\u89c9\u95ee\u9898\u7b54\u6848\u5bf9\u3002\u4e0e\u5bfb\u6c42\u66f4\u9ad8\u7ea7\u8ba4\u77e5\u548c\u63a8\u7406\u7684\u73b0\u6709\u57fa\u51c6\u4e0d\u540c\uff0cTangram \u4e13\u6ce8\u4e8e\u5bf9\u51e0\u4f55\u5143\u7d20\u7684\u7406\u89e3\uff0c\u8981\u6c42\u6a21\u578b\u6267\u884c\u201c\u7b80\u5355\u4f46\u6709\u8da3\u201d\u7684\u8ba1\u6570\u4efb\u52a1\u3002\u5bf9 10 \u4e2a\u8457\u540d\u7684 LMM\uff08\u4f8b\u5982 GPT-4o \u548c Claude 3.5 Sonnet\uff09\u8fdb\u884c\u7684\u7cfb\u7edf\u8bc4\u4f30\u8868\u660e\uff0c\u5373\u4f7f\u5728\u770b\u4f3c\u7b80\u5355\u7684\u4efb\u52a1\u4e2d\uff0c\u8fd9\u4e9b\u6a21\u578b\u4ecd\u7136\u9762\u4e34\u7740\u91cd\u5927\u6311\u6218\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5728\u6240\u6709\u6d4b\u8bd5\u6a21\u578b\u4e2d\uff0c\u8868\u73b0\u6700\u4f73\u7684\u6a21\u578b\u7684\u6574\u4f53\u51c6\u786e\u7387\u4ec5\u4e3a 56.8%\uff0c\u4e0e\u4eba\u7c7b\u8868\u73b0\u76f8\u6bd4\u5b58\u5728\u663e\u7740\u5dee\u8ddd\u3002\u8fd9\u4e9b\u53d1\u73b0\u7a81\u51fa\u4e86\u5f53\u524d\u591a\u6a21\u6001\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u5728\u5904\u7406\u57fa\u672c\u611f\u77e5\u4efb\u52a1\u65f6\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5c06\u6fc0\u53d1\u4e0b\u4e00\u4ee3\u4e13\u5bb6\u7ea7\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u7684\u53d1\u5c55\u3002Tangram \u548c\u8bc4\u4f30\u4ee3\u7801\u5c06\u5f88\u5feb\u63d0\u4f9b\u3002", "author": "Jiamin Tang et.al.", "authors": "Jiamin Tang, Chao Zhang, Xudong Zhu, Mengchi Liu", "id": "2408.13854v1", "paper_url": "http://arxiv.org/abs/2408.13854v1", "repo": "null"}}