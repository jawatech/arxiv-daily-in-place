{"2411.09400": {"publish_time": "2024-11-14", "title": "Imagined Speech and Visual Imagery as Intuitive Paradigms for Brain-Computer Interfaces", "paper_summary": "Recent advancements in brain-computer interface (BCI) technology have\nemphasized the promise of imagined speech and visual imagery as effective\nparadigms for intuitive communication. This study investigates the\nclassification performance and brain connectivity patterns associated with\nthese paradigms, focusing on decoding accuracy across selected word classes.\nSixteen participants engaged in tasks involving thirteen imagined speech and\nvisual imagery classes, revealing above-chance classification accuracy for both\nparadigms. Variability in classification accuracy across individual classes\nhighlights the influence of sensory and motor associations in imagined speech\nand vivid visual associations in visual imagery. Connectivity analysis further\ndemonstrated increased functional connectivity in language-related and sensory\nregions for imagined speech, whereas visual imagery activated spatial and\nvisual processing networks. These findings suggest the potential of imagined\nspeech and visual imagery as an intuitive and scalable paradigm for BCI\ncommunication when selecting optimal word classes. Further exploration of the\ndecoding outcomes for these two paradigms could provide insights for practical\nBCI communication.", "paper_summary_zh": "\u8166\u6a5f\u4ecb\u9762 (BCI) \u6280\u8853\u7684\u6700\u65b0\u9032\u5c55\n\u5f37\u8abf\u4e86\u60f3\u50cf\u8a9e\u8a00\u548c\u8996\u89ba\u610f\u8c61\u4f5c\u70ba\u76f4\u89ba\u6e9d\u901a\u7684\u6709\u6548\u5178\u7bc4\u3002\u672c\u7814\u7a76\u63a2\u8a0e\u4e86\u8207\u9019\u4e9b\u5178\u7bc4\u76f8\u95dc\u7684\u5206\u985e\u6548\u80fd\u548c\u8166\u90e8\u9023\u7d50\u6a21\u5f0f\uff0c\u5c08\u6ce8\u65bc\u89e3\u78bc\u7279\u5b9a\u5b57\u8a5e\u985e\u5225\u7684\u6e96\u78ba\u5ea6\u3002\u5341\u516d\u4f4d\u53c3\u8207\u8005\u53c3\u8207\u4e86\u5305\u542b\u5341\u4e09\u7a2e\u60f3\u50cf\u8a9e\u8a00\u548c\u8996\u89ba\u610f\u8c61\u985e\u5225\u7684\u4efb\u52d9\uff0c\u63ed\u9732\u4e86\u5169\u7a2e\u5178\u7bc4\u7686\u9ad8\u65bc\u96a8\u6a5f\u7684\u5206\u985e\u6e96\u78ba\u5ea6\u3002\u4e0d\u540c\u985e\u5225\u7684\u5206\u985e\u6e96\u78ba\u5ea6\u8b8a\u7570\u6027\u7a81\u986f\u4e86\u611f\u89ba\u548c\u904b\u52d5\u95dc\u806f\u5c0d\u60f3\u50cf\u8a9e\u8a00\u7684\u5f71\u97ff\uff0c\u4ee5\u53ca\u8996\u89ba\u610f\u8c61\u4e2d\u751f\u52d5\u7684\u8996\u89ba\u95dc\u806f\u3002\u9023\u63a5\u6027\u5206\u6790\u9032\u4e00\u6b65\u8b49\u660e\u4e86\u60f3\u50cf\u8a9e\u8a00\u7684\u8a9e\u8a00\u76f8\u95dc\u548c\u611f\u89ba\u5340\u57df\u529f\u80fd\u9023\u63a5\u6027\u589e\u52a0\uff0c\u800c\u8996\u89ba\u610f\u8c61\u5247\u6d3b\u5316\u4e86\u7a7a\u9593\u548c\u8996\u89ba\u8655\u7406\u7db2\u8def\u3002\u9019\u4e9b\u767c\u73fe\u8868\u660e\u60f3\u50cf\u8a9e\u8a00\u548c\u8996\u89ba\u610f\u8c61\u5177\u6709\u6f5b\u529b\uff0c\u53ef\u7528\u65bc\u9078\u64c7\u6700\u4f73\u5b57\u8a5e\u985e\u5225\u6642\uff0c\u4f5c\u70ba BCI \u6e9d\u901a\u7684\u76f4\u89ba\u4e14\u53ef\u64f4\u5145\u7684\u5178\u7bc4\u3002\u9032\u4e00\u6b65\u63a2\u8a0e\u9019\u5169\u7a2e\u5178\u7bc4\u7684\u89e3\u78bc\u7d50\u679c\uff0c\u53ef\u4ee5\u70ba\u5be6\u52d9\u4e0a\u7684 BCI \u6e9d\u901a\u63d0\u4f9b\u898b\u89e3\u3002", "author": "Seo-Hyun Lee et.al.", "authors": "Seo-Hyun Lee, Ji-Ha Park, Deok-Seon Kim", "id": "2411.09400v1", "paper_url": "http://arxiv.org/abs/2411.09400v1", "repo": "null"}}