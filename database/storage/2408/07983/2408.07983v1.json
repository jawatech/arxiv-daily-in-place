{"2408.07983": {"publish_time": "2024-08-15", "title": "ArabLegalEval: A Multitask Benchmark for Assessing Arabic Legal Knowledge in Large Language Models", "paper_summary": "The rapid advancements in Large Language Models (LLMs) have led to\nsignificant improvements in various natural language processing tasks. However,\nthe evaluation of LLMs' legal knowledge, particularly in non-English languages\nsuch as Arabic, remains under-explored. To address this gap, we introduce\nArabLegalEval, a multitask benchmark dataset for assessing the Arabic legal\nknowledge of LLMs. Inspired by the MMLU and LegalBench datasets, ArabLegalEval\nconsists of multiple tasks sourced from Saudi legal documents and synthesized\nquestions. In this work, we aim to analyze the capabilities required to solve\nlegal problems in Arabic and benchmark the performance of state-of-the-art\nLLMs. We explore the impact of in-context learning and investigate various\nevaluation methods. Additionally, we explore workflows for generating questions\nwith automatic validation to enhance the dataset's quality. We benchmark\nmultilingual and Arabic-centric LLMs, such as GPT-4 and Jais, respectively. We\nalso share our methodology for creating the dataset and validation, which can\nbe generalized to other domains. We hope to accelerate AI research in the\nArabic Legal domain by releasing the ArabLegalEval dataset and code:\nhttps://github.com/Thiqah/ArabLegalEval", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5feb\u901f\u9032\u6b65\u5df2\u7d93\u5728\u5404\u7a2e\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4efb\u52d9\u4e2d\u5e36\u4f86\u986f\u8457\u7684\u6539\u9032\u3002\u7136\u800c\uff0cLLM \u7684\u6cd5\u5f8b\u77e5\u8b58\u8a55\u4f30\uff0c\u7279\u5225\u662f\u5728\u963f\u62c9\u4f2f\u8a9e\u7b49\u975e\u82f1\u8a9e\u8a9e\u8a00\u4e2d\uff0c\u4ecd\u7136\u8655\u65bc\u63a2\u7d22\u4e0d\u8db3\u7684\u72c0\u614b\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u5dee\u8ddd\uff0c\u6211\u5011\u5f15\u5165\u4e86 ArabLegalEval\uff0c\u4e00\u500b\u7528\u65bc\u8a55\u4f30 LLM \u7684\u963f\u62c9\u4f2f\u8a9e\u6cd5\u5f8b\u77e5\u8b58\u7684\u591a\u4efb\u52d9\u57fa\u6e96\u6578\u64da\u96c6\u3002\u53d7 MMLU \u548c LegalBench \u6578\u64da\u96c6\u7684\u555f\u767c\uff0cArabLegalEval \u5305\u542b\u4e86\u591a\u500b\u4efb\u52d9\uff0c\u9019\u4e9b\u4efb\u52d9\u4f86\u81ea\u6c99\u70cf\u5730\u963f\u62c9\u4f2f\u6cd5\u5f8b\u6587\u4ef6\u548c\u7d9c\u5408\u554f\u984c\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u7684\u76ee\u6a19\u662f\u5206\u6790\u89e3\u6c7a\u963f\u62c9\u4f2f\u8a9e\u6cd5\u5f8b\u554f\u984c\u6240\u9700\u7684\u80fd\u529b\uff0c\u4e26\u5c0d\u6700\u5148\u9032\u7684 LLM \u7684\u6027\u80fd\u9032\u884c\u57fa\u6e96\u6e2c\u8a66\u3002\u6211\u5011\u63a2\u8a0e\u4e86\u60c5\u5883\u5b78\u7fd2\u7684\u5f71\u97ff\uff0c\u4e26\u7814\u7a76\u4e86\u5404\u7a2e\u8a55\u4f30\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u6211\u5011\u9084\u63a2\u8a0e\u4e86\u4f7f\u7528\u81ea\u52d5\u9a57\u8b49\u751f\u6210\u554f\u984c\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u4ee5\u63d0\u9ad8\u6578\u64da\u96c6\u7684\u8cea\u91cf\u3002\u6211\u5011\u5c0d\u591a\u8a9e\u8a00\u548c\u4ee5\u963f\u62c9\u4f2f\u8a9e\u70ba\u4e2d\u5fc3\u7684 LLM\uff08\u4f8b\u5982 GPT-4 \u548c Jais\uff09\u9032\u884c\u4e86\u57fa\u6e96\u6e2c\u8a66\u3002\u6211\u5011\u9084\u5206\u4eab\u4e86\u6211\u5011\u7528\u65bc\u5275\u5efa\u6578\u64da\u96c6\u548c\u9a57\u8b49\u7684\u65b9\u6cd5\uff0c\u8a72\u65b9\u6cd5\u53ef\u4ee5\u63a8\u5ee3\u5230\u5176\u4ed6\u9818\u57df\u3002\u6211\u5011\u5e0c\u671b\u901a\u904e\u767c\u5e03 ArabLegalEval \u6578\u64da\u96c6\u548c\u4ee3\u78bc\u4f86\u52a0\u901f\u963f\u62c9\u4f2f\u8a9e\u6cd5\u5f8b\u9818\u57df\u7684\u4eba\u5de5\u667a\u6167\u7814\u7a76\uff1ahttps://github.com/Thiqah/ArabLegalEval", "author": "Faris Hijazi et.al.", "authors": "Faris Hijazi, Somayah AlHarbi, Abdulaziz AlHussein, Harethah Abu Shairah, Reem AlZahrani, Hebah AlShamlan, Omar Knio, George Turkiyyah", "id": "2408.07983v1", "paper_url": "http://arxiv.org/abs/2408.07983v1", "repo": "https://github.com/thiqah/arablegaleval"}}