
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-02-20**|**LServe: Efficient Long-sequence LLM Serving with Unified Sparse Attention**|Shang Yang et.al.|[2502.14866v1](http://arxiv.org/abs/2502.14866v1)|null|
|**2025-02-20**|**Interpretable Text Embeddings and Text Similarity Explanation: A Primer**|Juri Opitz et.al.|[2502.14862v1](http://arxiv.org/abs/2502.14862v1)|null|
|**2025-02-20**|**Aligning LLMs to Ask Good Questions A Case Study in Clinical Reasoning**|Shuyue Stella Li et.al.|[2502.14860v1](http://arxiv.org/abs/2502.14860v1)|null|
|**2025-02-20**|**FR-Spec: Accelerating Large-Vocabulary Language Models via Frequency-Ranked Speculative Sampling**|Weilin Zhao et.al.|[2502.14856v1](http://arxiv.org/abs/2502.14856v1)|null|
|**2025-02-20**|**Prompt-to-Leaderboard**|Evan Frick et.al.|[2502.14855v1](http://arxiv.org/abs/2502.14855v1)|null|
|**2025-02-20**|**CLIPPER: Compression enables long-context synthetic data generation**|Chau Minh Pham et.al.|[2502.14854v1](http://arxiv.org/abs/2502.14854v1)|null|
|**2025-02-20**|**GATE: Graph-based Adaptive Tool Evolution Across Diverse Tasks**|Jianwen Luo et.al.|[2502.14848v1](http://arxiv.org/abs/2502.14848v1)|null|
|**2025-02-20**|**Scaling Text-Rich Image Understanding via Code-Guided Synthetic Multimodal Data Generation**|Yue Yang et.al.|[2502.14846v1](http://arxiv.org/abs/2502.14846v1)|null|
|**2025-02-20**|**Revealing and Mitigating Over-Attention in Knowledge Editing**|Pinzheng Wang et.al.|[2502.14838v1](http://arxiv.org/abs/2502.14838v1)|null|
|**2025-02-20**|**Towards Economical Inference: Enabling DeepSeek's Multi-Head Latent Attention in Any Transformer-based LLMs**|Tao Ji et.al.|[2502.14837v1](http://arxiv.org/abs/2502.14837v1)|null|
|**2025-02-20**|**LongWriter-V: Enabling Ultra-Long and High-Fidelity Generation in Vision-Language Models**|Shangqing Tu et.al.|[2502.14834v1](http://arxiv.org/abs/2502.14834v1)|null|
|**2025-02-20**|**Improving the Diffusability of Autoencoders**|Ivan Skorokhodov et.al.|[2502.14831v1](http://arxiv.org/abs/2502.14831v1)|null|
|**2025-02-20**|**Middle-Layer Representation Alignment for Cross-Lingual Transfer in Fine-Tuned LLMs**|Danni Liu et.al.|[2502.14830v1](http://arxiv.org/abs/2502.14830v1)|null|
|**2025-02-20**|**Measuring Faithfulness of Chains of Thought by Unlearning Reasoning Steps**|Martin Tutek et.al.|[2502.14829v1](http://arxiv.org/abs/2502.14829v1)|null|
|**2025-02-20**|**Exploring Advanced Techniques for Visual Question Answering: A Comprehensive Comparison**|Aiswarya Baby et.al.|[2502.14827v1](http://arxiv.org/abs/2502.14827v1)|null|
|**2025-02-20**|**eC-Tab2Text: Aspect-Based Text Generation from e-Commerce Product Tables**|Luis Antonio Gutiérrez Guanilo et.al.|[2502.14820v1](http://arxiv.org/abs/2502.14820v1)|null|
|**2025-02-20**|**Optimizing Model Selection for Compound AI Systems**|Lingjiao Chen et.al.|[2502.14815v1](http://arxiv.org/abs/2502.14815v1)|null|
|**2025-02-20**|**FetalCLIP: A Visual-Language Foundation Model for Fetal Ultrasound Image Analysis**|Fadillah Maani et.al.|[2502.14807v1](http://arxiv.org/abs/2502.14807v1)|null|
|**2025-02-20**|**From RAG to Memory: Non-Parametric Continual Learning for Large Language Models**|Bernal Jiménez Gutiérrez et.al.|[2502.14802v1](http://arxiv.org/abs/2502.14802v1)|null|
|**2025-02-20**|**A Survey on Text-Driven 360-Degree Panorama Generation**|Hai Wang et.al.|[2502.14799v1](http://arxiv.org/abs/2502.14799v1)|null|
|**2025-02-20**|**Rapid Word Learning Through Meta In-Context Learning**|Wentao Wang et.al.|[2502.14791v1](http://arxiv.org/abs/2502.14791v1)|null|
|**2025-02-20**|**SigLIP 2: Multilingual Vision-Language Encoders with Improved Semantic Understanding, Localization, and Dense Features**|Michael Tschannen et.al.|[2502.14786v1](http://arxiv.org/abs/2502.14786v1)|null|
|**2025-02-20**|**ReVision: A Dataset and Baseline VLM for Privacy-Preserving Task-Oriented Visual Instruction Rewriting**|Abhijit Mishra et.al.|[2502.14780v1](http://arxiv.org/abs/2502.14780v1)|null|
|**2025-02-20**|**Harnessing PDF Data for Improving Japanese Large Multimodal Models**|Jeonghun Baek et.al.|[2502.14778v1](http://arxiv.org/abs/2502.14778v1)|null|
|**2025-02-20**|**Making Universal Policies Universal**|Niklas Höpner et.al.|[2502.14777v1](http://arxiv.org/abs/2502.14777v1)|null|
|**2025-02-20**|**SurveyX: Academic Survey Automation via Large Language Models**|Xun Liang et.al.|[2502.14776v1](http://arxiv.org/abs/2502.14776v1)|null|
|**2025-02-20**|**Logic-RL: Unleashing LLM Reasoning with Rule-Based Reinforcement Learning**|Tian Xie et.al.|[2502.14768v1](http://arxiv.org/abs/2502.14768v1)|null|
|**2025-02-20**|**Tree-of-Debate: Multi-Persona Debate Trees Elicit Critical Thinking for Scientific Comparative Analysis**|Priyanka Kargupta et.al.|[2502.14767v1](http://arxiv.org/abs/2502.14767v1)|null|
|**2025-02-20**|**Step-by-Step Fact Verification System for Medical Claims with Explainable Reasoning**|Juraj Vladika et.al.|[2502.14765v1](http://arxiv.org/abs/2502.14765v1)|null|
|**2025-02-20**|**EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations**|Haotian Zhai et.al.|[2502.14760v1](http://arxiv.org/abs/2502.14760v1)|null|
|**2025-02-20**|**On the Influence of Context Size and Model Choice in Retrieval-Augmented Generation Systems**|Juraj Vladika et.al.|[2502.14759v1](http://arxiv.org/abs/2502.14759v1)|null|
|**2025-02-20**|**MedVAE: Efficient Automated Interpretation of Medical Images with Large-Scale Generalizable Autoencoders**|Maya Varma et.al.|[2502.14753v1](http://arxiv.org/abs/2502.14753v1)|null|
|**2025-02-20**|**TritonBench: Benchmarking Large Language Model Capabilities for Generating Triton Operators**|Jianling Li et.al.|[2502.14752v1](http://arxiv.org/abs/2502.14752v1)|null|
|**2025-02-20**|**Large Language Models Struggle to Describe the Haystack without Human Help: Human-in-the-loop Evaluation of LLMs**|Zongxia Li et.al.|[2502.14748v1](http://arxiv.org/abs/2502.14748v1)|null|
|**2025-02-20**|**HiddenDetect: Detecting Jailbreak Attacks against Large Vision-Language Models via Monitoring Hidden States**|Yilei Jiang et.al.|[2502.14744v1](http://arxiv.org/abs/2502.14744v1)|null|
|**2025-02-20**|**Multi-Agent Coordination across Diverse Applications: A Survey**|Lijun Sun et.al.|[2502.14743v1](http://arxiv.org/abs/2502.14743v1)|null|
|**2025-02-20**|**YOLOv12: A Breakdown of the Key Architectural Features**|Mujadded Al Rabbani Alif et.al.|[2502.14740v1](http://arxiv.org/abs/2502.14740v1)|null|
|**2025-02-20**|**SuperGPQA: Scaling LLM Evaluation across 285 Graduate Disciplines**|M-A-P Team et.al.|[2502.14739v1](http://arxiv.org/abs/2502.14739v1)|null|
|**2025-02-20**|**EAGER-LLM: Enhancing Large Language Models as Recommenders through Exogenous Behavior-Semantic Integration**|Minjie Hong et.al.|[2502.14735v1](http://arxiv.org/abs/2502.14735v1)|null|
|**2025-02-20**|**Sentence Smith: Formally Controllable Text Transformation and its Application to Evaluation of Text Embedding Models**|Hongji Li et.al.|[2502.14734v1](http://arxiv.org/abs/2502.14734v1)|null|
|**2025-02-20**|**WavRAG: Audio-Integrated Retrieval Augmented Generation for Spoken Dialogue Models**|Yifu Chen et.al.|[2502.14727v1](http://arxiv.org/abs/2502.14727v1)|null|
|**2025-02-20**|**Entity Framing and Role Portrayal in the News**|Tarek Mahmoud et.al.|[2502.14718v1](http://arxiv.org/abs/2502.14718v1)|null|
|**2025-02-20**|**From Knowledge Generation to Knowledge Verification: Examining the BioMedical Generative Capabilities of ChatGPT**|Ahmed Abdeen Hamed et.al.|[2502.14714v1](http://arxiv.org/abs/2502.14714v1)|null|
|**2025-02-20**|**Data-Efficient Pretraining with Group-Level Data Influence Modeling**|Zichun Yu et.al.|[2502.14709v1](http://arxiv.org/abs/2502.14709v1)|null|
|**2025-02-20**|**Human Misperception of Generative-AI Alignment: A Laboratory Experiment**|Kevin He et.al.|[2502.14708v1](http://arxiv.org/abs/2502.14708v1)|null|
|**2025-02-20**|**Not All Data are Good Labels: On the Self-supervised Labeling for Time Series Forecasting**|Yuxuan Yang et.al.|[2502.14704v1](http://arxiv.org/abs/2502.14704v1)|null|
|**2025-02-20**|**I-MCTS: Enhancing Agentic AutoML via Introspective Monte Carlo Tree Search**|Zujie Liang et.al.|[2502.14693v1](http://arxiv.org/abs/2502.14693v1)|null|
|**2025-02-20**|**Bridging the Gap: Transforming Natural Language Questions into SQL Queries via Abstract Query Pattern and Contextual Schema Markup**|Yonghui Kong et.al.|[2502.14682v1](http://arxiv.org/abs/2502.14682v1)|null|
|**2025-02-20**|**How to Get Your LLM to Generate Challenging Problems for Evaluation**|Arkil Patel et.al.|[2502.14678v1](http://arxiv.org/abs/2502.14678v1)|null|
|**2025-02-20**|**Data-Constrained Synthesis of Training Data for De-Identification**|Thomas Vakili et.al.|[2502.14677v1](http://arxiv.org/abs/2502.14677v1)|null|
|**2025-02-20**|**BP-SGCN: Behavioral Pseudo-Label Informed Sparse Graph Convolution Network for Pedestrian and Heterogeneous Trajectory Prediction**|Ruochen Li et.al.|[2502.14676v1](http://arxiv.org/abs/2502.14676v1)|null|
|**2025-02-20**|**Explanations of Deep Language Models Explain Language Representations in the Brain**|Maryam Rahimi et.al.|[2502.14671v1](http://arxiv.org/abs/2502.14671v1)|null|
|**2025-02-20**|**AlphaMaze: Enhancing Large Language Models' Spatial Intelligence via GRPO**|Alan Dao et.al.|[2502.14669v1](http://arxiv.org/abs/2502.14669v1)|null|
|**2025-02-20**|**InstructAgent: Building User Controllable Recommender via LLM Agent**|Wujiang Xu et.al.|[2502.14662v1](http://arxiv.org/abs/2502.14662v1)|null|
|**2025-02-20**|**Edit Once, Update Everywhere: A Simple Framework for Cross-Lingual Knowledge Synchronization in LLMs**|Yuchen Wu et.al.|[2502.14645v1](http://arxiv.org/abs/2502.14645v1)|null|
|**2025-02-20**|**LIFT: Improving Long Context Understanding of Large Language Models through Long Input Fine-Tuning**|Yansheng Mao et.al.|[2502.14644v1](http://arxiv.org/abs/2502.14644v1)|null|
|**2025-02-20**|**Length-Controlled Margin-Based Preference Optimization without Reference Model**|Gengxu Li et.al.|[2502.14643v1](http://arxiv.org/abs/2502.14643v1)|null|
|**2025-02-20**|**How Far are LLMs from Being Our Digital Twins? A Benchmark for Persona-Based Behavior Chain Simulation**|Rui Li et.al.|[2502.14642v1](http://arxiv.org/abs/2502.14642v1)|null|
|**2025-02-20**|**NAVIG: Natural Language-guided Analysis with Vision Language Models for Image Geo-localization**|Zheyuan Zhang et.al.|[2502.14638v1](http://arxiv.org/abs/2502.14638v1)|null|
|**2025-02-20**|**ReQFlow: Rectified Quaternion Flow for Efficient and High-Quality Protein Backbone Generation**|Angxiao Yue et.al.|[2502.14637v1](http://arxiv.org/abs/2502.14637v1)|[link](https://github.com/AngxiaoYue/ReQFlow)|
|**2025-02-20**|**PEARL: Towards Permutation-Resilient LLMs**|Liang Chen et.al.|[2502.14628v1](http://arxiv.org/abs/2502.14628v1)|null|
|**2025-02-20**|**ATRI: Mitigating Multilingual Audio Text Retrieval Inconsistencies by Reducing Data Distribution Errors**|Yuguo Yin et.al.|[2502.14627v1](http://arxiv.org/abs/2502.14627v1)|null|
|**2025-02-20**|**Multi-Record Web Page Information Extraction From News Websites**|Alexander Kustenkov et.al.|[2502.14625v1](http://arxiv.org/abs/2502.14625v1)|null|
|**2025-02-20**|**Exploring RWKV for Sentence Embeddings: Layer-wise Analysis and Baseline Comparison for Semantic Similarity**|Xinghan Pan et.al.|[2502.14620v1](http://arxiv.org/abs/2502.14620v1)|[link](https://github.com/PStarH/RWKV-embedding)|
|**2025-02-20**|**Reward Models Identify Consistency, Not Causality**|Yuhui Xu et.al.|[2502.14619v1](http://arxiv.org/abs/2502.14619v1)|null|
|**2025-02-20**|**FIND: Fine-grained Information Density Guided Adaptive Retrieval-Augmented Generation for Disease Diagnosis**|Mingyi Jia et.al.|[2502.14614v1](http://arxiv.org/abs/2502.14614v1)|null|
|**2025-02-20**|**Behavioral Analysis of Information Salience in Large Language Models**|Jan Trienes et.al.|[2502.14613v1](http://arxiv.org/abs/2502.14613v1)|null|
|**2025-02-20**|**A Theory for Conditional Generative Modeling on Multiple Data Sources**|Rongzhen Wang et.al.|[2502.14583v1](http://arxiv.org/abs/2502.14583v1)|null|
|**2025-02-20**|**A Statistical Case Against Empirical Human-AI Alignment**|Julian Rodemann et.al.|[2502.14581v1](http://arxiv.org/abs/2502.14581v1)|null|
|**2025-02-20**|**ReVISE: Learning to Refine at Test-Time via Intrinsic Self-Verification**|Hyunseok Lee et.al.|[2502.14565v1](http://arxiv.org/abs/2502.14565v1)|null|
|**2025-02-20**|**Plan-over-Graph: Towards Parallelable LLM Agent Schedule**|Shiqi Zhang et.al.|[2502.14563v1](http://arxiv.org/abs/2502.14563v1)|null|
|**2025-02-20**|**Can LLMs Predict Citation Intent? An Experimental Analysis of In-context Learning and Fine-tuning on Open LLMs**|Paris Koloveas et.al.|[2502.14561v1](http://arxiv.org/abs/2502.14561v1)|null|
|**2025-02-20**|**Less is More: Improving LLM Alignment via Preference Data Selection**|Xun Deng et.al.|[2502.14560v1](http://arxiv.org/abs/2502.14560v1)|null|
|**2025-02-20**|**FUIA: Model Inversion Attack against Federated Unlearning**|Lei Zhou et.al.|[2502.14558v1](http://arxiv.org/abs/2502.14558v1)|null|
|**2025-02-20**|**Multiscale Byte Language Models -- A Hierarchical Architecture for Causal Million-Length Sequence Modeling**|Eric Egli et.al.|[2502.14553v1](http://arxiv.org/abs/2502.14553v1)|null|
|**2025-02-20**|**Position: Graph Learning Will Lose Relevance Due To Poor Benchmarks**|Maya Bechler-Speicher et.al.|[2502.14546v1](http://arxiv.org/abs/2502.14546v1)|null|
|**2025-02-20**|**LLM-based User Profile Management for Recommender System**|Seunghwan Bang et.al.|[2502.14541v1](http://arxiv.org/abs/2502.14541v1)|null|
|**2025-02-20**|**LoRA-GGPO: Mitigating Double Descent in LoRA Fine-Tuning via Gradient-Guided Perturbation Optimization**|Yupeng Chang et.al.|[2502.14538v1](http://arxiv.org/abs/2502.14538v1)|null|
|**2025-02-20**|**CORBA: Contagious Recursive Blocking Attacks on Multi-Agent Systems Based on Large Language Models**|Zhenhong Zhou et.al.|[2502.14529v1](http://arxiv.org/abs/2502.14529v1)|null|
|**2025-02-20**|**Small Graph Is All You Need: DeepStateGNN for Scalable Traffic Forecasting**|Yannick Wölker et.al.|[2502.14525v1](http://arxiv.org/abs/2502.14525v1)|null|
|**2025-02-20**|**Generative adversarial networks vs large language models: a comparative study on synthetic tabular data generation**|Austin A. Barr et.al.|[2502.14523v1](http://arxiv.org/abs/2502.14523v1)|null|
|**2025-02-20**|**MultiSlav: Using Cross-Lingual Knowledge Transfer to Combat the Curse of Multilinguality**|Artur Kot et.al.|[2502.14509v1](http://arxiv.org/abs/2502.14509v1)|null|
|**2025-02-20**|**Can LLMs Simulate L2-English Dialogue? An Information-Theoretic Analysis of L1-Dependent Biases**|Rena Gao et.al.|[2502.14507v1](http://arxiv.org/abs/2502.14507v1)|null|
|**2025-02-20**|**PLPHP: Per-Layer Per-Head Vision Token Pruning for Efficient Large Vision-Language Models**|Yu Meng et.al.|[2502.14504v1](http://arxiv.org/abs/2502.14504v1)|null|
|**2025-02-20**|**How Much Knowledge Can You Pack into a LoRA Adapter without Harming LLM?**|Sergey Pletenev et.al.|[2502.14502v1](http://arxiv.org/abs/2502.14502v1)|null|
|**2025-02-20**|**Towards a Perspectivist Turn in Argument Quality Assessment**|Julia Romberg et.al.|[2502.14501v1](http://arxiv.org/abs/2502.14501v1)|null|
|**2025-02-20**|**MLGym: A New Framework and Benchmark for Advancing AI Research Agents**|Deepak Nathani et.al.|[2502.14499v1](http://arxiv.org/abs/2502.14499v1)|null|
|**2025-02-20**|**Stories that (are) Move(d by) Markets: A Causal Exploration of Market Shocks and Semantic Shifts across Different Partisan Groups**|Felix Drinkall et.al.|[2502.14497v1](http://arxiv.org/abs/2502.14497v1)|null|
|**2025-02-20**|**Enhancing Language Multi-Agent Learning with Multi-Agent Credit Re-Assignment for Interactive Environment Generalization**|Zhitao He et.al.|[2502.14496v1](http://arxiv.org/abs/2502.14496v1)|null|
|**2025-02-20**|**StructFlowBench: A Structured Flow Benchmark for Multi-turn Instruction Following**|Jinnan Li et.al.|[2502.14494v1](http://arxiv.org/abs/2502.14494v1)|null|
|**2025-02-20**|**Statistical Scenario Modelling and Lookalike Distributions for Multi-Variate AI Risk**|Elija Perrier et.al.|[2502.14491v1](http://arxiv.org/abs/2502.14491v1)|null|
|**2025-02-20**|**Temporal Misalignment and Probabilistic Neurons**|Velibor Bojković et.al.|[2502.14487v1](http://arxiv.org/abs/2502.14487v1)|null|
|**2025-02-20**|**How Jailbreak Defenses Work and Ensemble? A Mechanistic Investigation**|Zhuohang Long et.al.|[2502.14486v1](http://arxiv.org/abs/2502.14486v1)|null|
|**2025-02-20**|**NLoRA: Nyström-Initiated Low-Rank Adaptation for Large Language Models**|Chenlu Guo et.al.|[2502.14482v1](http://arxiv.org/abs/2502.14482v1)|null|
|**2025-02-20**|**Unshackling Context Length: An Efficient Selective Attention Approach through Query-Key Compression**|Haoyu Wang et.al.|[2502.14477v1](http://arxiv.org/abs/2502.14477v1)|null|
|**2025-02-20**|**Argument-Based Comparative Question Answering Evaluation Benchmark**|Irina Nikishina et.al.|[2502.14476v1](http://arxiv.org/abs/2502.14476v1)|null|
|**2025-02-20**|**Enhancing Smart Environments with Context-Aware Chatbots using Large Language Models**|Aurora Polo-Rodríguez et.al.|[2502.14469v1](http://arxiv.org/abs/2502.14469v1)|null|
|**2025-02-20**|**Llamba: Scaling Distilled Recurrent Models for Efficient Language Processing**|Aviv Bick et.al.|[2502.14458v1](http://arxiv.org/abs/2502.14458v1)|null|
|**2025-02-20**|**Narrative-Driven Travel Planning: Geoculturally-Grounded Script Generation with Evolutionary Itinerary Optimization**|Ran Ding et.al.|[2502.14456v1](http://arxiv.org/abs/2502.14456v1)|null|
|**2025-02-20**|**Optimal word order for non-causal text generation with Large Language Models: the Spanish case**|Andrea Busto-Castiñeira et.al.|[2502.14451v1](http://arxiv.org/abs/2502.14451v1)|null|

#### Abstracts
##### **LServe: Efficient Long-sequence LLM Serving with Unified Sparse Attention**
2502.14866v1 by Shang Yang, Junxian Guo, Haotian Tang, Qinghao Hu, Guangxuan Xiao, Jiaming Tang, Yujun Lin, Zhijian Liu, Yao Lu, Song Han

Large language models (LLMs) have shown remarkable potential in processing
long sequences, yet efficiently serving these long-context models remains
challenging due to the quadratic computational complexity of attention in the
prefilling stage and the large memory footprint of the KV cache in the decoding
stage. To address these issues, we introduce LServe, an efficient system that
accelerates long-sequence LLM serving via hybrid sparse attention. This method
unifies different hardware-friendly, structured sparsity patterns for both
prefilling and decoding attention into a single framework, where computations
on less important tokens are skipped block-wise. LServe demonstrates the
compatibility of static and dynamic sparsity in long-context LLM attention.
This design enables multiplicative speedups by combining these optimizations.
Specifically, we convert half of the attention heads to nearly free streaming
heads in both the prefilling and decoding stages. Additionally, we find that
only a constant number of KV pages is required to preserve long-context
capabilities, irrespective of context length. We then design a hierarchical KV
page selection policy that dynamically prunes KV pages based on query-centric
similarity. On average, LServe accelerates LLM prefilling by up to 2.9x and
decoding by 1.3-2.1x over vLLM, maintaining long-context accuracy. Code is
released at https://github.com/mit-han-lab/omniserve.

摘要：大型語言模型 (LLM) 在處理長序列方面展現出驚人的潛力，但由於預填充階段注意力的二次計算複雜度和解碼階段 KV 快取的大量記憶體使用量，有效提供這些長語境模型服務仍然具有挑戰性。為了解決這些問題，我們引入了 LServe，一個透過混合稀疏注意力加速長序列 LLM 服務的高效系統。此方法將不同的硬體友善的結構化稀疏模式統一到一個單一的架構中，用於預填充和解碼注意力，其中對較不重要的符號的運算會以區塊方式略過。LServe 證明了靜態和動態稀疏性在長語境 LLM 注意力中的相容性。此設計透過結合這些最佳化來實現倍增加速。具體來說，我們將一半的注意力頭轉換為預填充和解碼階段中幾乎免費的串流頭。此外，我們發現僅需要恆定的 KV 頁數來保留長語境功能，而與語境長度無關。然後，我們設計了一個分層式 KV 頁面選擇策略，根據以查詢為中心的相似性動態刪除 KV 頁面。平均而言，LServe 將 LLM 預填充加速了 2.9 倍，將解碼加速了 1.3-2.1 倍，同時維持長語境的準確性。程式碼已發布在 https://github.com/mit-han-lab/omniserve。

##### **Interpretable Text Embeddings and Text Similarity Explanation: A Primer**
2502.14862v1 by Juri Opitz, Lucas Möller, Andrianos Michail, Simon Clematide

Text embeddings and text embedding models are a backbone of many AI and NLP
systems, particularly those involving search. However, interpretability
challenges persist, especially in explaining obtained similarity scores, which
is crucial for applications requiring transparency. In this paper, we give a
structured overview of interpretability methods specializing in explaining
those similarity scores, an emerging research area. We study the methods'
individual ideas and techniques, evaluating their potential for improving
interpretability of text embeddings and explaining predicted similarities.

摘要：文字嵌入和文字嵌入模型是許多 AI 和 NLP 系統的骨幹，特別是那些涉及搜尋的系統。然而，可解釋性的挑戰依然存在，特別是在解釋獲得的相似度分數時，這對於需要透明度的應用程式至關重要。在本文中，我們對專門用於解釋這些相似度分數的可解釋性方法給予結構化的概述，這是一個新興的研究領域。我們研究了這些方法的個別想法和技術，評估它們改善文字嵌入的可解釋性和解釋預測相似度的潛力。

##### **Aligning LLMs to Ask Good Questions A Case Study in Clinical Reasoning**
2502.14860v1 by Shuyue Stella Li, Jimin Mun, Faeze Brahman, Jonathan S. Ilgen, Yulia Tsvetkov, Maarten Sap

Large language models (LLMs) often fail to ask effective questions under
uncertainty, making them unreliable in domains where proactive
information-gathering is essential for decisionmaking. We present ALFA, a
framework that improves LLM question-asking by (i) decomposing the notion of a
"good" question into a set of theory-grounded attributes (e.g., clarity,
relevance), (ii) controllably synthesizing attribute-specific question
variations, and (iii) aligning models via preference-based optimization to
explicitly learn to ask better questions along these fine-grained attributes.
Focusing on clinical reasoning as a case study, we introduce the MediQ-AskDocs
dataset, composed of 17k real-world clinical interactions augmented with 80k
attribute-specific preference pairs of follow-up questions, as well as a novel
expert-annotated interactive healthcare QA task to evaluate question-asking
abilities. Models aligned with ALFA reduce diagnostic errors by 56.6% on
MediQ-AskDocs compared to SOTA instruction-tuned LLMs, with a question-level
win-rate of 64.4% and strong generalizability. Our findings suggest that
explicitly guiding question-asking with structured, fine-grained attributes
offers a scalable path to improve LLMs, especially in expert application
domains.

摘要：大型語言模型 (LLM) 經常在不確定性下無法提出有效問題，這使得它們在主動收集資訊對於決策制定至關重要的領域中不可靠。我們提出 ALFA，一個透過 (i) 將「良好」問題的概念分解成一組以理論為基礎的屬性（例如，清晰度、相關性），(ii) 可控地合成屬性特定的問題變體，以及 (iii) 透過基於偏好的最佳化調整模型，明確學習沿著這些細緻屬性提出更好的問題，來改善 LLM 提問的架構。專注於臨床推理作為案例研究，我們引入了 MediQ-AskDocs 資料集，由 17k 個真實世界的臨床互動組成，並增加了 80k 個屬性特定的後續問題偏好配對，以及一個由專家註解的互動式醫療保健問答任務來評估提問能力。與 SOTA 指令調整的 LLM 相比，與 ALFA 對齊的模型將 MediQ-AskDocs 上的診斷錯誤減少了 56.6%，問題層級的勝率為 64.4%，並且具有很強的普遍性。我們的研究結果表明，明確地以結構化、細緻的屬性來引導提問，提供了一條可擴充的途徑來改善 LLM，特別是在專家應用領域。

##### **FR-Spec: Accelerating Large-Vocabulary Language Models via Frequency-Ranked Speculative Sampling**
2502.14856v1 by Weilin Zhao, Tengyu Pan, Xu Han, Yudi Zhang, Ao Sun, Yuxiang Huang, Kaihuo Zhang, Weilun Zhao, Yuxuan Li, Jianyong Wang, Zhiyuan Liu, Maosong Sun

Speculative sampling has emerged as an important technique for accelerating
the auto-regressive generation process of large language models (LLMs) by
utilizing a draft-then-verify mechanism to produce multiple tokens per forward
pass. While state-of-the-art speculative sampling methods use only a single
layer and a language modeling (LM) head as the draft model to achieve
impressive layer compression, their efficiency gains are substantially reduced
for large-vocabulary LLMs, such as Llama-3-8B with a vocabulary of 128k tokens.
To address this, we present FR-Spec, a frequency-ranked speculative sampling
framework that optimizes draft candidate selection through vocabulary space
compression. By constraining the draft search to a frequency-prioritized token
subset, our method reduces LM Head computation overhead by 75% while ensuring
the equivalence of the final output distribution. Experiments across multiple
datasets demonstrate an average of 1.12$\times$ speedup over the
state-of-the-art speculative sampling method EAGLE-2.

摘要：推測取樣已成為一種重要的技術，可用於透過利用先起草後驗證的機制來加速大型語言模型 (LLM) 的自迴歸生成過程，並在每次前向傳遞中產生多個代幣。儘管最先進的推測取樣方法只使用單一層和語言建模 (LM) 頭作為起草模型，以達成令人印象深刻的層壓縮，但對於大型詞彙表 LLM（例如詞彙表包含 128k 個代幣的 Llama-3-8B），其效率提升會大幅降低。為了解決這個問題，我們提出了 FR-Spec，這是一種頻率排序推測取樣架構，它透過詞彙空間壓縮來最佳化起草候選選取。我們的這個方法透過將起草搜尋限制在優先於頻率的代幣子集中，將 LM 頭部運算開銷減少了 75%，同時確保最終輸出分佈的等效性。透過多個資料集的實驗證明，與最先進的推測取樣方法 EAGLE-2 相比，平均提速了 1.12 倍。

##### **Prompt-to-Leaderboard**
2502.14855v1 by Evan Frick, Connor Chen, Joseph Tennyson, Tianle Li, Wei-Lin Chiang, Anastasios N. Angelopoulos, Ion Stoica

Large language model (LLM) evaluations typically rely on aggregated metrics
like accuracy or human preference, averaging across users and prompts. This
averaging obscures user- and prompt-specific variations in model performance.
To address this, we propose Prompt-to-Leaderboard (P2L), a method that produces
leaderboards specific to a prompt. The core idea is to train an LLM taking
natural language prompts as input to output a vector of Bradley-Terry
coefficients which are then used to predict the human preference vote. The
resulting prompt-dependent leaderboards allow for unsupervised task-specific
evaluation, optimal routing of queries to models, personalization, and
automated evaluation of model strengths and weaknesses. Data from Chatbot Arena
suggest that P2L better captures the nuanced landscape of language model
performance than the averaged leaderboard. Furthermore, our findings suggest
that P2L's ability to produce prompt-specific evaluations follows a power law
scaling similar to that observed in LLMs themselves. In January 2025, the
router we trained based on this methodology achieved the \#1 spot in the
Chatbot Arena leaderboard. Our code is available at this GitHub link:
https://github.com/lmarena/p2l.

摘要：大型語言模型 (LLM) 評估通常依賴於彙總的指標，例如準確性或人類偏好，平均值跨使用者和提示。此平均值模糊了使用者和提示特定的模型效能變異。為了解決此問題，我們提出提示到排行榜 (P2L)，一種產生特定於提示的排行榜的方法。核心概念是訓練 LLM，將自然語言提示作為輸入，以輸出 Bradley-Terry 係數向量，然後用於預測人類偏好投票。產生的提示相關排行榜允許無監督任務特定評估、最佳查詢路由至模型、個人化以及模型優缺點的自動化評估。來自 Chatbot Arena 的資料表明，P2L 比平均排行榜更能捕捉語言模型效能的細微變化。此外，我們的研究結果表明，P2L 產生提示特定評估的能力遵循類似於 LLM 本身觀察到的冪律縮放。2025 年 1 月，我們根據此方法訓練的路由器在 Chatbot Arena 排行榜中獲得了第一名。我們的程式碼可在 GitHub 連結取得：https://github.com/lmarena/p2l。

##### **CLIPPER: Compression enables long-context synthetic data generation**
2502.14854v1 by Chau Minh Pham, Yapei Chang, Mohit Iyyer

LLM developers are increasingly reliant on synthetic data, but generating
high-quality data for complex long-context reasoning tasks remains challenging.
We introduce CLIPPER, a compression-based approach for generating synthetic
data tailored to narrative claim verification - a task that requires reasoning
over a book to verify a given claim. Instead of generating claims directly from
the raw text of the book, which results in artifact-riddled claims, CLIPPER
first compresses the book into chapter outlines and book summaries and then
uses these intermediate representations to generate complex claims and
corresponding chain-of-thoughts. Compared to naive approaches, CLIPPER produces
claims that are more valid, grounded, and complex. Using CLIPPER, we construct
a dataset of 19K synthetic book claims paired with their source texts and
chain-of-thought reasoning, and use it to fine-tune three open-weight models.
Our best model achieves breakthrough results on narrative claim verification
(from 28% to 76% accuracy on our test set) and sets a new state-of-the-art for
sub-10B models on the NoCha leaderboard. Further analysis shows that our models
generate more detailed and grounded chain-of-thought reasoning while also
improving performance on other narrative understanding tasks (e.g.,
NarrativeQA).

摘要：LLM 開發人員越來越依賴合成資料，但為複雜的長語境推理任務生成高品質資料仍然具有挑戰性。我們引入了 CLIPPER，一種基於壓縮的方法，用於生成針對敘事性聲明驗證量身打造的合成資料，這項任務需要對一本書進行推理才能驗證給定的聲明。CLIPPER 沒有直接從書籍的原始文字生成聲明，這會產生充滿人工製品的聲明，而是先將書籍壓縮成章節大綱和書籍摘要，然後使用這些中間表示來生成複雜的聲明和對應的思維鏈。與天真的方法相比，CLIPPER 產生的聲明更有效、更有根據且更複雜。使用 CLIPPER，我們構建了一個包含 19K 個合成書籍聲明及其原始文字和思維鏈推理的資料集，並用於微調三個開放權重模型。我們最好的模型在敘事性聲明驗證方面取得了突破性的結果（在我們的測試集中準確率從 28% 提升到 76%），並在 NoCha 排行榜上為低於 10B 的模型設定了新的技術水準。進一步的分析表明，我們的模型生成了更詳細且有根據的思維鏈推理，同時也提高了其他敘事理解任務（例如 NarrativeQA）的效能。

##### **GATE: Graph-based Adaptive Tool Evolution Across Diverse Tasks**
2502.14848v1 by Jianwen Luo, Yiming Huang, Jinxiang Meng, Fangyu Lei, Shizhu He, Xiao Liu, Shanshan Jiang, Bin Dong, Jun Zhao, Kang Liu

Large Language Models (LLMs) have shown great promise in tool-making, yet
existing frameworks often struggle to efficiently construct reliable toolsets
and are limited to single-task settings. To address these challenges, we
propose GATE (Graph-based Adaptive Tool Evolution), an adaptive framework that
dynamically constructs and evolves a hierarchical graph of reusable tools
across multiple scenarios. We evaluate GATE on open-ended tasks (Minecraft),
agent-based tasks (TextCraft, DABench), and code generation tasks (MATH, Date,
TabMWP). Our results show that GATE achieves up to 4.3x faster milestone
completion in Minecraft compared to the previous SOTA, and provides an average
improvement of 9.23% over existing tool-making methods in code generation tasks
and 10.03% in agent tasks. GATE demonstrates the power of adaptive evolution,
balancing tool quantity, complexity, and functionality while maintaining high
efficiency. Code and data are available at
\url{https://github.com/ayanami2003/GATE}.

摘要：大型語言模型 (LLM) 在工具製作方面展現出極大的潛力，然而現有的框架經常難以有效地建構可靠的工具組，並且僅限於單一任務設定。為了應對這些挑戰，我們提出了 GATE（基於圖形的自適應工具演化），這是一個自適應框架，可跨多個場景動態建構和演化可重複使用的工具階層圖。我們在開放式任務（Minecraft）、基於代理的任務（TextCraft、DABench）和程式碼生成任務（MATH、Date、TabMWP）上評估了 GATE。我們的結果顯示，與先前的 SOTA 相比，GATE 在 Minecraft 中實現了高達 4.3 倍的里程碑完成速度，並且在程式碼生成任務中提供了比現有工具製作方法平均提升 9.23%，在代理任務中提升了 10.03%。GATE 展示了自適應演化的力量，在保持高效率的同時，平衡了工具數量、複雜性和功能性。程式碼和資料可在 \url{https://github.com/ayanami2003/GATE} 取得。

##### **Scaling Text-Rich Image Understanding via Code-Guided Synthetic Multimodal Data Generation**
2502.14846v1 by Yue Yang, Ajay Patel, Matt Deitke, Tanmay Gupta, Luca Weihs, Andrew Head, Mark Yatskar, Chris Callison-Burch, Ranjay Krishna, Aniruddha Kembhavi, Christopher Clark

Reasoning about images with rich text, such as charts and documents, is a
critical application of vision-language models (VLMs). However, VLMs often
struggle in these domains due to the scarcity of diverse text-rich
vision-language data. To address this challenge, we present CoSyn, a framework
that leverages the coding capabilities of text-only large language models
(LLMs) to automatically create synthetic text-rich multimodal data. Given input
text describing a target domain (e.g., "nutrition fact labels"), CoSyn prompts
an LLM to generate code (Python, HTML, LaTeX, etc.) for rendering synthetic
images. With the underlying code as textual representations of the synthetic
images, CoSyn can generate high-quality instruction-tuning data, again relying
on a text-only LLM. Using CoSyn, we constructed a dataset comprising 400K
images and 2.7M rows of vision-language instruction-tuning data. Comprehensive
experiments on seven benchmarks demonstrate that models trained on our
synthetic data achieve state-of-the-art performance among competitive
open-source models, including Llama 3.2, and surpass proprietary models such as
GPT-4V and Gemini 1.5 Flash. Furthermore, CoSyn can produce synthetic pointing
data, enabling VLMs to ground information within input images, showcasing its
potential for developing multimodal agents capable of acting in real-world
environments.

摘要：透過豐富文字（例如圖表和文件）對影像進行推理，是視覺語言模型 (VLM) 的重要應用。然而，由於多元化文字豐富的視覺語言資料稀少，VLM 在這些領域中經常會遇到困難。為了應對這個挑戰，我們提出了 CoSyn，一個利用純文字大型語言模型 (LLM) 的編碼能力來自動建立合成文字豐富多模態資料的架構。給定描述目標網域的輸入文字（例如「營養成分標籤」），CoSyn 會提示 LLM 產生用於合成影像渲染的程式碼（Python、HTML、LaTeX 等）。透過將底層程式碼作為合成影像的文字表示，CoSyn 可以產生高品質的指令調整資料，再次依賴純文字 LLM。使用 CoSyn，我們建構了一個包含 40 萬張影像和 270 萬列視覺語言指令調整資料的資料集。在七個基準上的全面實驗證明，在我們的合成資料上訓練的模型在競爭對手的開源模型（包括 Llama 3.2）中達到了最先進的效能，並超越了 GPT-4V 和 Gemini 1.5 Flash 等專有模型。此外，CoSyn 可以產生合成指向資料，讓 VLM 能在輸入影像中建立資訊基礎，展示其在開發能夠在真實世界環境中運作的多模態代理方面的潛力。

##### **Revealing and Mitigating Over-Attention in Knowledge Editing**
2502.14838v1 by Pinzheng Wang, Zecheng Tang, Keyan Zhou, Juntao Li, Qiaoming Zhu, Min Zhang

Large Language Models have demonstrated superior performance across a wide
range of tasks, but they still exhibit undesirable errors due to incorrect
knowledge learned from the training data. To avoid this, knowledge editing
methods emerged to precisely edit the specific model knowledge via efficiently
modifying a very small percentage of parameters. % However, those methods can
lead to the problem of Specificity Failure: when the content related to the
edited knowledge occurs in the context, it can inadvertently corrupt other
pre-existing knowledge. However, those methods can lead to the problem of
Specificity Failure, where the existing knowledge and capabilities are severely
degraded due to editing. Our preliminary indicates that Specificity Failure
primarily stems from the model's attention heads assigning excessive attention
scores to entities related to the edited knowledge, thereby unduly focusing on
specific snippets within the context, which we denote as the Attention Drift
phenomenon. To mitigate such Attention Drift issue, we introduce a simple yet
effective method Selective Attention Drift Restriction}(SADR), which introduces
an additional regularization term during the knowledge editing process to
restrict changes in the attention weight distribution, thereby preventing undue
focus on the edited entity. Experiments on five frequently used strong LLMs
demonstrate the effectiveness of our method, where SADR can significantly
mitigate Specificity Failure in the predominant knowledge editing tasks.

摘要：大型語言模型已在廣泛任務中展現出卓越的效能，但由於從訓練資料中學習到不正確的知識，它們仍會出現令人不滿意的錯誤。為避免此情況，知識編輯方法應運而生，透過有效修改極少數參數來精準編輯特定模型知識。% 然而，這些方法可能會導致特異性失敗問題：當與已編輯知識相關的內容出現在文中時，可能會無意間損害其他既有知識。然而，這些方法可能會導致特異性失敗問題，因為現有知識和能力會因編輯而嚴重降低。我們的初步研究表明，特異性失敗主要源於模型的注意力權重將過度注意力分數分配給與已編輯知識相關的實體，從而過度關注文中特定的片段，我們將此現象稱為注意力偏移。為減輕這種注意力偏移問題，我們引入了一個簡單但有效的方法選擇性注意力偏移限制}(SADR)，在知識編輯過程中引入一個額外的正則化項來限制注意力權重分配的變動，從而防止過度關注已編輯實體。在五個經常使用的強大 LLM 上進行的實驗證明了我們方法的有效性，其中 SADR 可以顯著減輕主要知識編輯任務中的特異性失敗。

##### **Towards Economical Inference: Enabling DeepSeek's Multi-Head Latent Attention in Any Transformer-based LLMs**
2502.14837v1 by Tao Ji, Bin Guo, Yuanbin Wu, Qipeng Guo, Lixing Shen, Zhan Chen, Xipeng Qiu, Qi Zhang, Tao Gui

Multi-head Latent Attention (MLA) is an innovative architecture proposed by
DeepSeek, designed to ensure efficient and economical inference by
significantly compressing the Key-Value (KV) cache into a latent vector.
Compared to MLA, standard LLMs employing Multi-Head Attention (MHA) and its
variants such as Grouped-Query Attention (GQA) exhibit significant cost
disadvantages. Enabling well-trained LLMs (e.g., Llama) to rapidly adapt to MLA
without pre-training from scratch is both meaningful and challenging. This
paper proposes the first data-efficient fine-tuning method for transitioning
from MHA to MLA (MHA2MLA), which includes two key components: for partial-RoPE,
we remove RoPE from dimensions of queries and keys that contribute less to the
attention scores, for low-rank approximation, we introduce joint SVD
approximations based on the pre-trained parameters of keys and values. These
carefully designed strategies enable MHA2MLA to recover performance using only
a small fraction (0.3% to 0.6%) of the data, significantly reducing inference
costs while seamlessly integrating with compression techniques such as KV cache
quantization. For example, the KV cache size of Llama2-7B is reduced by 92.19%,
with only a 0.5% drop in LongBench performance.

摘要：多頭潛在注意力 (MLA) 是 DeepSeek 提出的一種創新架構，旨在通過將鍵值 (KV) 快取大幅壓縮成潛在向量，確保有效率且經濟的推論。與 MLA 相比，採用多頭注意力 (MHA) 及其變體（例如分組查詢注意力 (GQA)）的標準 LLM 會出現顯著的成本劣勢。讓訓練完善的 LLM（例如 Llama）能夠快速適應 MLA，而無需從頭開始預訓練，這既有意義又具有挑戰性。本文提出了第一個資料有效微調方法，用於從 MHA 轉換到 MLA (MHA2MLA)，其中包含兩個關鍵組成部分：對於部分 RoPE，我們從查詢和鍵的維度中移除對注意力分數貢獻較小的 RoPE，對於低秩近似，我們基於鍵和值的預訓練參數引入聯合 SVD 近似。這些經過仔細設計的策略讓 MHA2MLA 能夠僅使用一小部分資料 (0.3% 至 0.6%) 來恢復效能，大幅降低推論成本，同時與壓縮技術（例如 KV 快取量化）無縫整合。例如，Llama2-7B 的 KV 快取大小減少了 92.19%，而 LongBench 效能僅下降了 0.5%。

##### **LongWriter-V: Enabling Ultra-Long and High-Fidelity Generation in Vision-Language Models**
2502.14834v1 by Shangqing Tu, Yucheng Wang, Daniel Zhang-Li, Yushi Bai, Jifan Yu, Yuhao Wu, Lei Hou, Huiqin Liu, Zhiyuan Liu, Bin Xu, Juanzi Li

Existing Large Vision-Language Models (LVLMs) can process inputs with context
lengths up to 128k visual and text tokens, yet they struggle to generate
coherent outputs beyond 1,000 words. We find that the primary limitation is the
absence of long output examples during supervised fine-tuning (SFT). To tackle
this issue, we introduce LongWriter-V-22k, a SFT dataset comprising 22,158
examples, each with multiple input images, an instruction, and corresponding
outputs ranging from 0 to 10,000 words. Moreover, to achieve long outputs that
maintain high-fidelity to the input images, we employ Direct Preference
Optimization (DPO) to the SFT model. Given the high cost of collecting human
feedback for lengthy outputs (e.g., 3,000 words), we propose IterDPO, which
breaks long outputs into segments and uses iterative corrections to form
preference pairs with the original outputs. Additionally, we develop
MMLongBench-Write, a benchmark featuring six tasks to evaluate the
long-generation capabilities of VLMs. Our 7B parameter model, trained with
LongWriter-V-22k and IterDPO, achieves impressive performance on this
benchmark, outperforming larger proprietary models like GPT-4o. Code and data:
https://github.com/THU-KEG/LongWriter-V

摘要：現有的大型視覺語言模型 (LVLMs) 能處理長度達 128k 視覺和文字符號的輸入內容，但卻難以產生超過 1,000 字的連貫輸出。我們發現，主要限制在於監督微調 (SFT) 期間缺少長輸出範例。為了解決此問題，我們引入了 LongWriter-V-22k，這是一個 SFT 資料集，包含 22,158 個範例，每個範例都有多個輸入影像、一個說明和對應的輸出，範圍從 0 到 10,000 字。此外，為了產生與輸入影像高度保真的長輸出，我們對 SFT 模型採用直接偏好最佳化 (DPO)。考量到收集人類回饋的成本很高（例如 3,000 字），我們提出 IterDPO，它會將長輸出區分成幾個區塊，並使用反覆修正來形成與原始輸出的偏好配對。此外，我們開發了 MMLongBench-Write，這是一個基準，包含六項任務，用於評估 VLM 的長生成能力。我們的 7B 參數模型使用 LongWriter-V-22k 和 IterDPO 進行訓練，在這個基準上取得令人印象深刻的效能，超越了 GPT-4o 等大型專有模型。程式碼和資料：https://github.com/THU-KEG/LongWriter-V

##### **Improving the Diffusability of Autoencoders**
2502.14831v1 by Ivan Skorokhodov, Sharath Girish, Benran Hu, Willi Menapace, Yanyu Li, Rameen Abdal, Sergey Tulyakov, Aliaksandr Siarohin

Latent diffusion models have emerged as the leading approach for generating
high-quality images and videos, utilizing compressed latent representations to
reduce the computational burden of the diffusion process. While recent
advancements have primarily focused on scaling diffusion backbones and
improving autoencoder reconstruction quality, the interaction between these
components has received comparatively less attention. In this work, we perform
a spectral analysis of modern autoencoders and identify inordinate
high-frequency components in their latent spaces, which are especially
pronounced in the autoencoders with a large bottleneck channel size. We
hypothesize that this high-frequency component interferes with the
coarse-to-fine nature of the diffusion synthesis process and hinders the
generation quality. To mitigate the issue, we propose scale equivariance: a
simple regularization strategy that aligns latent and RGB spaces across
frequencies by enforcing scale equivariance in the decoder. It requires minimal
code changes and only up to 20K autoencoder fine-tuning steps, yet
significantly improves generation quality, reducing FID by 19% for image
generation on ImageNet-1K 256x256 and FVD by at least 44% for video generation
on Kinetics-700 17x256x256.

摘要：潛在擴散模型已成為生成高品質影像和影片的主流方法，利用壓縮潛在表示來降低擴散過程的計算負擔。雖然近期的進展主要集中在擴充擴散主幹並提升自編碼器重建品質，但這些組成之間的交互作用卻鮮少受到關注。在這項研究中，我們對現代自編碼器進行頻譜分析，並在它們的潛在空間中找出不適當的高頻率組成，這在瓶頸通道尺寸較大的自編碼器中特別明顯。我們假設這種高頻率組成會干擾擴散合成過程由粗到細的性質，並阻礙生成品質。為了緩解這個問題，我們提出規模等變性：一種簡單的正則化策略，透過在解碼器中強制執行規模等變性，使潛在空間和 RGB 空間在各個頻率中保持一致。它只需要最小的程式碼變更，且僅需最多 20K 個自編碼器微調步驟，就能顯著提升生成品質，將 ImageNet-1K 256x256 上的影像生成的 FID 降低 19%，並將 Kinetics-700 17x256x256 上的影片生成的 FVD 降低至少 44%。

##### **Middle-Layer Representation Alignment for Cross-Lingual Transfer in Fine-Tuned LLMs**
2502.14830v1 by Danni Liu, Jan Niehues

While large language models demonstrate remarkable capabilities at
task-specific applications through fine-tuning, extending these benefits across
diverse languages is essential for broad accessibility. However, effective
cross-lingual transfer is hindered by LLM performance gaps across languages and
the scarcity of fine-tuning data in many languages. Through analysis of LLM
internal representations from over 1,000+ language pairs, we discover that
middle layers exhibit the strongest potential for cross-lingual alignment.
Building on this finding, we propose a middle-layer alignment objective
integrated into task-specific training. Our experiments on slot filling,
machine translation, and structured text generation show consistent
improvements in cross-lingual transfer, especially to lower-resource languages.
The method is robust to the choice of alignment languages and generalizes to
languages unseen during alignment. Furthermore, we show that separately trained
alignment modules can be merged with existing task-specific modules, improving
cross-lingual capabilities without full re-training. Our code is publicly
available (https://github.com/dannigt/mid-align).

摘要：儘管大型語言模型在特定任務應用中透過微調展現出卓越的能力，但要讓這些好處擴及各種語言，對於廣泛的可及性來說至關重要。然而，有效的跨語言轉移受到跨語言 LLM 效能差距以及許多語言中微調資料的稀少性所阻礙。透過分析來自 1,000 多種語言對的 LLM 內部表示，我們發現中間層展現出最強的跨語言對齊潛力。根據這個發現，我們提出一個整合到特定任務訓練中的中間層對齊目標。我們在插槽填補、機器翻譯和結構化文字生成方面的實驗顯示，跨語言轉移持續改善，特別是對於低資源語言。此方法對於對齊語言的選擇具有穩健性，並推廣到對齊期間未曾見過的語言。此外，我們展示了單獨訓練的對齊模組可以與現有的特定任務模組合併，在不重新訓練的情況下改善跨語言能力。我們的程式碼已公開（https://github.com/dannigt/mid-align）。

##### **Measuring Faithfulness of Chains of Thought by Unlearning Reasoning Steps**
2502.14829v1 by Martin Tutek, Fateme Hashemi Chaleshtori, Ana Marasović, Yonatan Belinkov

When prompted to think step-by-step, language models (LMs) produce a chain of
thought (CoT), a sequence of reasoning steps that the model supposedly used to
produce its prediction. However, despite much work on CoT prompting, it is
unclear if CoT reasoning is faithful to the models' parameteric beliefs. We
introduce a framework for measuring parametric faithfulness of generated
reasoning, and propose Faithfulness by Unlearning Reasoning steps (FUR), an
instance of this framework. FUR erases information contained in reasoning steps
from model parameters. We perform experiments unlearning CoTs of four LMs
prompted on four multi-choice question answering (MCQA) datasets. Our
experiments show that FUR is frequently able to change the underlying models'
prediction by unlearning key steps, indicating when a CoT is parametrically
faithful. Further analysis shows that CoTs generated by models post-unlearning
support different answers, hinting at a deeper effect of unlearning.
Importantly, CoT steps identified as important by FUR do not align well with
human notions of plausbility, emphasizing the need for specialized alignment

摘要：当提示逐步思考时，语言模型 (LM) 会产生一系列思考 (CoT)，这是模型用来产生预测的一系列推理步骤。然而，尽管在 CoT 提示上做了很多工作，但尚不清楚 CoT 推理是否符合模型的参数化信念。我们引入了一个框架来衡量生成推理的参数化保真度，并提出了通过取消学习推理步骤 (FUR) 的保真度，这是该框架的一个实例。FUR 从模型参数中擦除推理步骤中包含的信息。我们执行实验，取消学习提示在四个多项选择问答 (MCQA) 数据集上的四个 LM 的 CoT。我们的实验表明，FUR 经常能够通过取消学习关键步骤来改变底层模型的预测，表明 CoT 在参数上是保真的。进一步的分析表明，模型在取消学习后生成的 CoT 支持不同的答案，暗示取消学习具有更深层次的影响。重要的是，FUR 确定的 CoT 步骤与人类对合理性的概念不太一致，强调了专门对齐的必要性

##### **Exploring Advanced Techniques for Visual Question Answering: A Comprehensive Comparison**
2502.14827v1 by Aiswarya Baby, Tintu Thankom Koshy

Visual Question Answering (VQA) has emerged as a pivotal task in the
intersection of computer vision and natural language processing, requiring
models to understand and reason about visual content in response to natural
language questions. Analyzing VQA datasets is essential for developing robust
models that can handle the complexities of multimodal reasoning. Several
approaches have been developed to examine these datasets, each offering
distinct perspectives on question diversity, answer distribution, and
visual-textual correlations. Despite significant progress, existing VQA models
face challenges related to dataset bias, limited model complexity, commonsense
reasoning gaps, rigid evaluation methods, and generalization to real world
scenarios. This paper presents a comprehensive comparative study of five
advanced VQA models: ABC-CNN, KICNLE, Masked Vision and Language Modeling,
BLIP-2, and OFA, each employing distinct methodologies to address these
challenges.

摘要：視覺問答 (VQA) 已成為電腦視覺與自然語言處理交會中的關鍵任務，要求模型理解和推理視覺內容以回應自然語言問題。分析 VQA 資料集對於開發健全的模型至關重要，這些模型能夠處理多模態推理的複雜性。已經開發出多種方法來檢驗這些資料集，每種方法都提供有關問題多樣性、答案分佈和視覺文本關聯性的不同觀點。儘管有顯著進展，現有的 VQA 模型仍面臨與資料集偏差、模型複雜性有限、常識推理差距、僵化的評估方法和推廣到現實世界場景相關的挑戰。本文對五個先進的 VQA 模型進行了全面的比較研究：ABC-CNN、KICNLE、Masked Vision and Language Modeling、BLIP-2 和 OFA，每個模型都採用不同的方法來應對這些挑戰。

##### **eC-Tab2Text: Aspect-Based Text Generation from e-Commerce Product Tables**
2502.14820v1 by Luis Antonio Gutiérrez Guanilo, Mir Tafseer Nayeem, Cristian López, Davood Rafiei

Large Language Models (LLMs) have demonstrated exceptional versatility across
diverse domains, yet their application in e-commerce remains underexplored due
to a lack of domain-specific datasets. To address this gap, we introduce
eC-Tab2Text, a novel dataset designed to capture the intricacies of e-commerce,
including detailed product attributes and user-specific queries. Leveraging
eC-Tab2Text, we focus on text generation from product tables, enabling LLMs to
produce high-quality, attribute-specific product reviews from structured
tabular data. Fine-tuned models were rigorously evaluated using standard
Table2Text metrics, alongside correctness, faithfulness, and fluency
assessments. Our results demonstrate substantial improvements in generating
contextually accurate reviews, highlighting the transformative potential of
tailored datasets and fine-tuning methodologies in optimizing e-commerce
workflows. This work highlights the potential of LLMs in e-commerce workflows
and the essential role of domain-specific datasets in tailoring them to
industry-specific challenges.

摘要：大型語言模型 (LLM) 在各種領域展現出非凡的多功能性，但由於缺乏特定領域的資料集，因此它們在電子商務中的應用仍未得到充分探索。為了解決這個差距，我們引入了 eC-Tab2Text，這是一個新穎的資料集，旨在捕捉電子商務的複雜性，包括詳細的產品屬性和使用者特定的查詢。利用 eC-Tab2Text，我們專注於從產品表格中產生文字，使 LLM 能夠從結構化的表格資料中產生高品質、特定屬性的產品評論。微調模型使用標準的 Table2Text 指標，以及正確性、忠實度和流利度評估進行嚴格評估。我們的結果證明在產生符合語境的準確評論方面有顯著的進步，突顯了客製化資料集和微調方法在最佳化電子商務工作流程中的轉型潛力。這項工作突顯了 LLM 在電子商務工作流程中的潛力，以及特定領域資料集在因應產業特定挑戰中至關重要的角色。

##### **Optimizing Model Selection for Compound AI Systems**
2502.14815v1 by Lingjiao Chen, Jared Quincy Davis, Boris Hanin, Peter Bailis, Matei Zaharia, James Zou, Ion Stoica

Compound AI systems that combine multiple LLM calls, such as self-refine and
multi-agent-debate, achieve strong performance on many AI tasks. We address a
core question in optimizing compound systems: for each LLM call or module in
the system, how should one decide which LLM to use? We show that these LLM
choices have a large effect on quality, but the search space is exponential. We
propose LLMSelector, an efficient framework for model selection in compound
systems, which leverages two key empirical insights: (i) end-to-end performance
is often monotonic in how well each module performs, with all other modules
held fixed, and (ii) per-module performance can be estimated accurately by an
LLM. Building upon these insights, LLMSelector iteratively selects one module
and allocates to it the model with the highest module-wise performance, as
estimated by an LLM, until no further gain is possible. LLMSelector is
applicable to any compound system with a bounded number of modules, and its
number of API calls scales linearly with the number of modules, achieving
high-quality model allocation both empirically and theoretically. Experiments
with popular compound systems such as multi-agent debate and self-refine using
LLMs such as GPT-4o, Claude 3.5 Sonnet and Gemini 1.5 show that LLMSelector
confers 5%-70% accuracy gains compared to using the same LLM for all modules.

摘要：複合式 AI 系統結合多個 LLM 呼叫，例如自我精煉和多代理辯論，在許多 AI 任務中都能獲得強大的效能。我們解決了最佳化複合式系統中的核心問題：對於系統中的每個 LLM 呼叫或模組，應該如何決定要使用哪個 LLM？我們表明這些 LLM 選擇對品質有很大的影響，但搜尋空間是呈指數增長的。我們提出 LLMSelector，一種用於複合式系統中模型選擇的有效架構，它利用了兩個主要的經驗見解：(i) 端對端效能通常會隨著每個模組執行得有多好而單調變化，而其他所有模組保持固定，以及 (ii) 每個模組的效能都可以由 LLM 精準估計。LLMSelector 建立在這些見解之上，反覆選擇一個模組，並根據 LLM 估計的模組最佳效能，將模型分配給它，直到無法再進一步提升為止。LLMSelector 適用於任何具有有限數量的模組的複合式系統，其 API 呼叫數量與模組數量成線性比例，在經驗和理論上都實現了高品質的模型配置。使用 GPT-4o、Claude 3.5 Sonnet 和 Gemini 1.5 等 LLM，對多代理辯論和自我精煉等熱門複合式系統進行的實驗表明，與對所有模組使用相同的 LLM 相比，LLMSelector 可帶來 5%-70% 的準確度提升。

##### **FetalCLIP: A Visual-Language Foundation Model for Fetal Ultrasound Image Analysis**
2502.14807v1 by Fadillah Maani, Numan Saeed, Tausifa Saleem, Zaid Farooq, Hussain Alasmawi, Werner Diehl, Ameera Mohammad, Gareth Waring, Saudabi Valappi, Leanne Bricker, Mohammad Yaqub

Foundation models are becoming increasingly effective in the medical domain,
offering pre-trained models on large datasets that can be readily adapted for
downstream tasks. Despite progress, fetal ultrasound images remain a
challenging domain for foundation models due to their inherent complexity,
often requiring substantial additional training and facing limitations due to
the scarcity of paired multimodal data. To overcome these challenges, here we
introduce FetalCLIP, a vision-language foundation model capable of generating
universal representation of fetal ultrasound images. FetalCLIP was pre-trained
using a multimodal learning approach on a diverse dataset of 210,035 fetal
ultrasound images paired with text. This represents the largest paired dataset
of its kind used for foundation model development to date. This unique training
approach allows FetalCLIP to effectively learn the intricate anatomical
features present in fetal ultrasound images, resulting in robust
representations that can be used for a variety of downstream applications. In
extensive benchmarking across a range of key fetal ultrasound applications,
including classification, gestational age estimation, congenital heart defect
(CHD) detection, and fetal structure segmentation, FetalCLIP outperformed all
baselines while demonstrating remarkable generalizability and strong
performance even with limited labeled data. We plan to release the FetalCLIP
model publicly for the benefit of the broader scientific community.

摘要：基礎模型在醫療領域正變得越來越有效，
提供在大型資料集上預先訓練的模型，可輕鬆適應
下游任務。儘管有進展，但胎兒超音波影像仍然是
基礎模型的挑戰領域，因為它們固有的複雜性，
通常需要大量的額外訓練，並且由於配對多模態數據的稀缺而面臨限制。為了克服這些挑戰，我們在此
介紹 FetalCLIP，一種能夠產生
胎兒超音波影像通用表示的視覺語言基礎模型。FetalCLIP 使用多模態學習方法在包含 210,035 張胎兒
超音波影像與文字配對的多樣化資料集上進行預訓練。這代表迄今為止用於基礎模型開發的最大配對資料集。這種獨特的訓練
方法使 FetalCLIP 能夠有效地學習胎兒超音波影像中存在的複雜解剖特徵，從而產生強大的
表示，可應用於各種下游應用。在涵蓋一系列關鍵胎兒超音波應用（包括分類、胎齡估算、先天性心臟缺陷
(CHD) 偵測和胎兒結構分割）的廣泛基準測試中，FetalCLIP 在展現出卓越的泛化能力和強勁的
效能，即使標記資料有限，也優於所有基準。我們計畫公開發布 FetalCLIP 模型，造福廣大的科學界。

##### **From RAG to Memory: Non-Parametric Continual Learning for Large Language Models**
2502.14802v1 by Bernal Jiménez Gutiérrez, Yiheng Shu, Weijian Qi, Sizhe Zhou, Yu Su

Our ability to continuously acquire, organize, and leverage knowledge is a
key feature of human intelligence that AI systems must approximate to unlock
their full potential. Given the challenges in continual learning with large
language models (LLMs), retrieval-augmented generation (RAG) has become the
dominant way to introduce new information. However, its reliance on vector
retrieval hinders its ability to mimic the dynamic and interconnected nature of
human long-term memory. Recent RAG approaches augment vector embeddings with
various structures like knowledge graphs to address some of these gaps, namely
sense-making and associativity. However, their performance on more basic
factual memory tasks drops considerably below standard RAG. We address this
unintended deterioration and propose HippoRAG 2, a framework that outperforms
standard RAG comprehensively on factual, sense-making, and associative memory
tasks. HippoRAG 2 builds upon the Personalized PageRank algorithm used in
HippoRAG and enhances it with deeper passage integration and more effective
online use of an LLM. This combination pushes this RAG system closer to the
effectiveness of human long-term memory, achieving a 7% improvement in
associative memory tasks over the state-of-the-art embedding model while also
exhibiting superior factual knowledge and sense-making memory capabilities.
This work paves the way for non-parametric continual learning for LLMs. Our
code and data will be released at https://github.com/OSU-NLP-Group/HippoRAG.

摘要：我們持續獲取、組織和利用知識的能力是人類智慧的一項關鍵特徵，而人工智慧系統必須近似於此才能發揮其全部潛力。由於大型語言模型 (LLM) 持續學習的挑戰，檢索增強生成 (RAG) 已成為引入新資訊的主流方式。然而，它依賴向量檢索阻礙了它模擬人類長期記憶的動態和相互連結的本質。最近的 RAG 方法用各種結構（如知識圖譜）增強向量嵌入，以解決其中一些差距，即意義建構和聯想性。然而，它們在更基本的實際記憶任務上的表現遠低於標準 RAG。我們解決了這種意外的惡化，並提出了 HippoRAG 2，這是一個在實際、意義建構和聯想記憶任務上全面優於標準 RAG 的框架。HippoRAG 2 建立在 HippoRAG 中使用的 Personalized PageRank 演算法之上，並透過更深入的段落整合和更有效的 LLM 線上使用來增強它。這種組合將此 RAG 系統推向更接近人類長期記憶的效能，在聯想記憶任務上比最先進的嵌入模型提升了 7%，同時也展現出優異的實際知識和意義建構記憶能力。這項工作為 LLM 的非參數持續學習鋪平了道路。我們的程式碼和資料將在 https://github.com/OSU-NLP-Group/HippoRAG 上發布。

##### **A Survey on Text-Driven 360-Degree Panorama Generation**
2502.14799v1 by Hai Wang, Xiaoyu Xiang, Weihao Xia, Jing-Hao Xue

The advent of text-driven 360-degree panorama generation, enabling the
synthesis of 360-degree panoramic images directly from textual descriptions,
marks a transformative advancement in immersive visual content creation. This
innovation significantly simplifies the traditionally complex process of
producing such content. Recent progress in text-to-image diffusion models has
accelerated the rapid development in this emerging field. This survey presents
a comprehensive review of text-driven 360-degree panorama generation, offering
an in-depth analysis of state-of-the-art algorithms and their expanding
applications in 360-degree 3D scene generation. Furthermore, we critically
examine current limitations and propose promising directions for future
research. A curated project page with relevant resources and research papers is
available at https://littlewhitesea.github.io/Text-Driven-Pano-Gen/.

摘要：文字驅動 360 度全景圖生成技術的出現，使能從文字描述中直接合成 360 度全景圖像，標誌著沉浸式視覺內容創作的變革性進展。這項創新顯著簡化了傳統上複雜的製作此類內容的過程。最近在文字轉圖像擴散模型方面的進展加速了這個新興領域的快速發展。本調查提供了對文字驅動 360 度全景圖生成的全面回顧，深入分析了最先進的演算法及其在 360 度 3D 場景生成中的擴展應用。此外，我們批判性地審視了當前的限制，並提出了未來研究的有希望的方向。一個精選的專案頁面，其中包含相關資源和研究論文，可在 https://littlewhitesea.github.io/Text-Driven-Pano-Gen/ 獲得。

##### **Rapid Word Learning Through Meta In-Context Learning**
2502.14791v1 by Wentao Wang, Guangyuan Jiang, Tal Linzen, Brenden M. Lake

Humans can quickly learn a new word from a few illustrative examples, and
then systematically and flexibly use it in novel contexts. Yet the abilities of
current language models for few-shot word learning, and methods for improving
these abilities, are underexplored. In this study, we introduce a novel method,
Meta-training for IN-context learNing Of Words (Minnow). This method trains
language models to generate new examples of a word's usage given a few
in-context examples, using a special placeholder token to represent the new
word. This training is repeated on many new words to develop a general
word-learning ability. We find that training models from scratch with Minnow on
human-scale child-directed language enables strong few-shot word learning,
comparable to a large language model (LLM) pre-trained on orders of magnitude
more data. Furthermore, through discriminative and generative evaluations, we
demonstrate that finetuning pre-trained LLMs with Minnow improves their ability
to discriminate between new words, identify syntactic categories of new words,
and generate reasonable new usages and definitions for new words, based on one
or a few in-context examples. These findings highlight the data efficiency of
Minnow and its potential to improve language model performance in word learning
tasks.

摘要：人類可以從幾個說明性的範例中快速學習一個新字詞，然後系統性且靈活地將其用於新的脈絡中。然而，目前語言模型在少量字詞學習中的能力，以及改善這些能力的方法，尚未得到充分探討。在這項研究中，我們引入了一種新方法，即「用於字詞情境學習的元訓練」(Minnow)。此方法訓練語言模型在給定幾個情境範例的情況下，產生字詞用法的範例，並使用特殊佔位符標記來表示新的字詞。此訓練會在許多新字詞上重複進行，以培養一般的字詞學習能力。我們發現，從頭開始使用 Minnow 在人類規模的兒童導向語言上訓練模型，可以實現強大的少量字詞學習能力，這與預先在大量資料上訓練的大型語言模型 (LLM) 相當。此外，透過區辨性和生成性評估，我們證明使用 Minnow 微調預先訓練的 LLM 可以提升其區辨新字詞、識別新字詞的句法類別，以及根據一個或幾個情境範例產生合理的新用法和定義的能力。這些發現突顯了 Minnow 的資料效率，以及它在字詞學習任務中提升語言模型效能的潛力。

##### **SigLIP 2: Multilingual Vision-Language Encoders with Improved Semantic Understanding, Localization, and Dense Features**
2502.14786v1 by Michael Tschannen, Alexey Gritsenko, Xiao Wang, Muhammad Ferjad Naeem, Ibrahim Alabdulmohsin, Nikhil Parthasarathy, Talfan Evans, Lucas Beyer, Ye Xia, Basil Mustafa, Olivier Hénaff, Jeremiah Harmsen, Andreas Steiner, Xiaohua Zhai

We introduce SigLIP 2, a family of new multilingual vision-language encoders
that build on the success of the original SigLIP. In this second iteration, we
extend the original image-text training objective with several prior,
independently developed techniques into a unified recipe -- this includes
captioning-based pretraining, self-supervised losses (self-distillation, masked
prediction) and online data curation. With these changes, SigLIP 2 models
outperform their SigLIP counterparts at all model scales in core capabilities,
including zero-shot classification, image-text retrieval, and transfer
performance when extracting visual representations for Vision-Language Models
(VLMs). Furthermore, the new training recipe leads to significant improvements
on localization and dense prediction tasks. We also train variants which
support multiple resolutions and preserve the input's native aspect ratio.
Finally, we train on a more diverse data-mixture that includes de-biasing
techniques, leading to much better multilingual understanding and improved
fairness. To allow users to trade off inference cost with performance, we
release model checkpoints at four sizes: ViT-B (86M), L (303M), So400m (400M),
and g (1B).

摘要：我們推出了 SigLIP 2，這是一個新的多語言視覺語言編碼器系列，它建立在 SigLIP 的成功基礎上。在這個第二個版本中，我們將原來的圖像文字訓練目標與幾個先前獨立開發的技術擴展到一個統一的配方中，其中包括基於標題的預訓練、自我監督損失（自我蒸餾、遮罩預測）和線上數據策展。有了這些改變，SigLIP 2 模型在所有模型規模上都超越了 SigLIP 的對應模型，包括零次分類、圖像文字檢索和在為視覺語言模型 (VLM) 提取視覺表示時傳輸效能。此外，新的訓練配方也大幅改善了定位和密集預測任務。我們還訓練了支援多種解析度和保留輸入原生長寬比的變體。最後，我們在一個更為多樣化的數據組合上進行訓練，其中包括去偏見技術，從而大幅提升多語言理解力並改善公平性。為了讓使用者權衡推理成本與效能，我們發布了四種大小的模型檢查點：ViT-B (86M)、L (303M)、So400m (400M) 和 g (1B)。

##### **ReVision: A Dataset and Baseline VLM for Privacy-Preserving Task-Oriented Visual Instruction Rewriting**
2502.14780v1 by Abhijit Mishra, Richard Noh, Hsiang Fu, Mingda Li, Minji Kim

Efficient and privacy-preserving multimodal interaction is essential as AR,
VR, and modern smartphones with powerful cameras become primary interfaces for
human-computer communication. Existing powerful large vision-language models
(VLMs) enabling multimodal interaction often rely on cloud-based processing,
raising significant concerns about (1) visual privacy by transmitting sensitive
vision data to servers, and (2) their limited real-time, on-device usability.
This paper explores Visual Instruction Rewriting, a novel approach that
transforms multimodal instructions into text-only commands, allowing seamless
integration of lightweight on-device instruction rewriter VLMs (250M
parameters) with existing conversational AI systems, enhancing vision data
privacy. To achieve this, we present a dataset of over 39,000 examples across
14 domains and develop a compact VLM, pretrained on image captioning datasets
and fine-tuned for instruction rewriting. Experimental results, evaluated
through NLG metrics such as BLEU, METEOR, and ROUGE, along with semantic
parsing analysis, demonstrate that even a quantized version of the model
(<500MB storage footprint) can achieve effective instruction rewriting, thus
enabling privacy-focused, multimodal AI applications.

摘要：高效且重視隱私的多模態互動至關重要，因為 AR、VR 和配備強大相機的現代智慧型手機已成為人機溝通的主要介面。現有的強大大型視覺語言模型 (VLM) 能支援多模態互動，通常仰賴雲端處理，這引發了重大的疑慮，包括：(1) 將敏感的視覺資料傳輸至伺服器，會造成視覺隱私問題，以及 (2) 其有限的即時、裝置上可用性。本文探討視覺指令改寫，這是一種新穎的方法，可將多模態指令轉換為純文字指令，讓輕量級的裝置上指令改寫 VLM (250M 參數) 與現有的對話式 AI 系統無縫整合，進而強化視覺資料的隱私。為達成此目標，我們提供一個跨越 14 個領域、超過 39,000 個範例的資料集，並開發一個精簡的 VLM，在圖片標題資料集上進行預訓練，並針對指令改寫進行微調。實驗結果透過 NLG 指標（例如 BLEU、METEOR 和 ROUGE）以及語意解析分析進行評估，證明即使是模型的量化版本（<500MB 儲存空間佔用量）也能有效執行指令改寫，進而支援注重隱私的多模態 AI 應用程式。

##### **Harnessing PDF Data for Improving Japanese Large Multimodal Models**
2502.14778v1 by Jeonghun Baek, Akiko Aizawa, Kiyoharu Aizawa

Large Multimodal Models (LMMs) have demonstrated strong performance in
English, but their effectiveness in Japanese remains limited due to the lack of
high-quality training data. Current Japanese LMMs often rely on translated
English datasets, restricting their ability to capture Japan-specific cultural
knowledge. To address this, we explore the potential of Japanese PDF data as a
training resource, an area that remains largely underutilized. We introduce a
fully automated pipeline that leverages pretrained models to extract image-text
pairs from PDFs through layout analysis, OCR, and vision-language pairing,
removing the need for manual annotation. Additionally, we construct instruction
data from extracted image-text pairs to enrich the training data. To evaluate
the effectiveness of PDF-derived data, we train Japanese LMMs and assess their
performance on the Japanese LMM Benchmark. Our results demonstrate substantial
improvements, with performance gains ranging from 3.9% to 13.8% on Heron-Bench.
Further analysis highlights the impact of PDF-derived data on various factors,
such as model size and language models, reinforcing its value as a multimodal
resource for Japanese LMMs. We plan to make the source code and data publicly
available upon acceptance.

摘要：大型多模態模型 (LMM) 已在英語中表現出強勁的效能，但由於缺乏高品質的訓練資料，它們在日語中的效能仍然有限。目前的日語 LMM 通常依賴於翻譯後的英語資料集，限制了它們擷取特定於日本的文化知識的能力。為了解決這個問題，我們探索了日語 PDF 資料作為訓練資源的潛力，這個領域在很大程度上仍然未被充分利用。我們引入了一個全自動的管道，利用預先訓練好的模型透過版面分析、光學字元辨識和視覺語言配對從 PDF 中擷取影像文字對，消除了手動註解的需要。此外，我們從擷取的影像文字對中建構說明資料，以豐富訓練資料。為了評估 PDF 衍生資料的效能，我們訓練了日語 LMM，並在日語 LMM 基準上評估它們的效能。我們的結果證明了顯著的進步，在 Heron-Bench 上的效能提升幅度從 3.9% 到 13.8%。進一步的分析重點說明了 PDF 衍生資料對各種因素的影響，例如模型大小和語言模型，加強了其作為日語 LMM 的多模態資源的價值。我們計畫在接受後公開原始程式碼和資料。

##### **Making Universal Policies Universal**
2502.14777v1 by Niklas Höpner, David Kuric, Herke van Hoof

The development of a generalist agent capable of solving a wide range of
sequential decision-making tasks remains a significant challenge. We address
this problem in a cross-agent setup where agents share the same observation
space but differ in their action spaces. Our approach builds on the universal
policy framework, which decouples policy learning into two stages: a
diffusion-based planner that generates observation sequences and an inverse
dynamics model that assigns actions to these plans. We propose a method for
training the planner on a joint dataset composed of trajectories from all
agents. This method offers the benefit of positive transfer by pooling data
from different agents, while the primary challenge lies in adapting shared
plans to each agent's unique constraints. We evaluate our approach on the
BabyAI environment, covering tasks of varying complexity, and demonstrate
positive transfer across agents. Additionally, we examine the planner's
generalisation ability to unseen agents and compare our method to traditional
imitation learning approaches. By training on a pooled dataset from multiple
agents, our universal policy achieves an improvement of up to $42.20\%$ in task
completion accuracy compared to a policy trained on a dataset from a single
agent.

摘要：開發一種能夠解決廣泛順序決策任務的通才代理仍然是一項重大挑戰。我們在跨代理設置中解決這個問題，其中代理共享相同的觀察空間，但在其動作空間中有所不同。我們的做法建立在通用策略框架之上，該框架將策略學習解耦為兩個階段：生成觀察序列的基於擴散的規劃器和將動作分配給這些計劃的逆動態模型。我們提出了一種在由所有代理的軌跡組成的聯合數據集上訓練規劃器的方法。這種方法提供了通過彙總來自不同代理的數據來進行正向傳輸的好處，而主要的挑戰在於將共享計劃適應於每個代理的唯一約束。我們在 BabyAI 環境中評估了我們的做法，涵蓋了不同複雜程度的任務，並展示了跨代理的正向傳輸。此外，我們檢查了規劃器對未見代理的概括能力，並將我們的做法與傳統的模仿學習方法進行了比較。通過在來自多個代理的彙總數據集上進行訓練，我們的通用策略在任務完成準確度方面實現了高達 42.20% 的改進，而從單個代理的數據集上訓練的策略。

##### **SurveyX: Academic Survey Automation via Large Language Models**
2502.14776v1 by Xun Liang, Jiawei Yang, Yezhaohui Wang, Chen Tang, Zifan Zheng, Simin Niu, Shichao Song, Hanyu Wang, Bo Tang, Feiyu Xiong, Keming Mao, Zhiyu li

Large Language Models (LLMs) have demonstrated exceptional comprehension
capabilities and a vast knowledge base, suggesting that LLMs can serve as
efficient tools for automated survey generation. However, recent research
related to automated survey generation remains constrained by some critical
limitations like finite context window, lack of in-depth content discussion,
and absence of systematic evaluation frameworks. Inspired by human writing
processes, we propose SurveyX, an efficient and organized system for automated
survey generation that decomposes the survey composing process into two phases:
the Preparation and Generation phases. By innovatively introducing online
reference retrieval, a pre-processing method called AttributeTree, and a
re-polishing process, SurveyX significantly enhances the efficacy of survey
composition. Experimental evaluation results show that SurveyX outperforms
existing automated survey generation systems in content quality (0.259
improvement) and citation quality (1.76 enhancement), approaching human expert
performance across multiple evaluation dimensions. Examples of surveys
generated by SurveyX are available on www.surveyx.cn

摘要：大型語言模型 (LLM) 已展現出卓越的理解能力和廣泛的知識庫，表示 LLM 可作為自動調查生成的有用工具。然而，與自動調查生成相關的最新研究仍受到一些關鍵限制的約束，例如有限的上下文視窗、缺乏深入的內容討論以及系統評估架構的缺失。受到人類寫作過程的啟發，我們提出 SurveyX，這是一個用於自動調查生成的有效且有組織的系統，它將調查組成過程分解為兩個階段：準備和生成階段。透過創新地引入線上參考檢索、一種稱為 AttributeTree 的預處理方法和重新潤飾過程，SurveyX 大幅提升了調查組成的效能。實驗評估結果顯示，SurveyX 在內容品質（提升 0.259）和引用品質（提升 1.76）方面優於現有的自動調查生成系統，在多個評估面向中接近人類專家的表現。由 SurveyX 生成的調查範例可在 www.surveyx.cn 取得

##### **Logic-RL: Unleashing LLM Reasoning with Rule-Based Reinforcement Learning**
2502.14768v1 by Tian Xie, Zitian Gao, Qingnan Ren, Haoming Luo, Yuqian Hong, Bryan Dai, Joey Zhou, Kai Qiu, Zhirong Wu, Chong Luo

Inspired by the success of DeepSeek-R1, we explore the potential of
rule-based reinforcement learning (RL) in large reasoning models. To analyze
reasoning dynamics, we use synthetic logic puzzles as training data due to
their controllable complexity and straightforward answer verification. We make
some key technical contributions that lead to effective and stable RL training:
a system prompt that emphasizes the thinking and answering process, a stringent
format reward function that penalizes outputs for taking shortcuts, and a
straightforward training recipe that achieves stable convergence. Our 7B model
develops advanced reasoning skills-such as reflection, verification, and
summarization-that are absent from the logic corpus. Remarkably, after training
on just 5K logic problems, it demonstrates generalization abilities to the
challenging math benchmarks AIME and AMC.

摘要：在 DeepSeek-R1 成功案例的启发下，我们探索了基于规则的强化学习 (RL) 在大型推理模型中的潜力。为了分析推理动态，我们使用合成逻辑难题作为训练数据，因为它们的可控复杂性和直接的答案验证。我们做出了一些关键的技术贡献，这些贡献导致了有效且稳定的 RL 训练：一个强调思考和回答过程的系统提示、一个严格的格式奖励函数，用于惩罚采取捷径的输出，以及一个实现稳定收敛的直接训练配方。我们的 7B 模型发展了高级推理技能，例如反射、验证和总结，这些技能在逻辑语料库中是不存在的。值得注意的是，在仅对 5K 个逻辑问题进行训练后，它展示了对具有挑战性的数学基准 AIME 和 AMC 的泛化能力。

##### **Tree-of-Debate: Multi-Persona Debate Trees Elicit Critical Thinking for Scientific Comparative Analysis**
2502.14767v1 by Priyanka Kargupta, Ishika Agarwal, Tal August, Jiawei Han

With the exponential growth of research facilitated by modern technology and
improved accessibility, scientific discoveries have become increasingly
fragmented within and across fields. This makes it challenging to assess the
significance, novelty, incremental findings, and equivalent ideas between
related works, particularly those from different research communities. Large
language models (LLMs) have recently demonstrated strong quantitative and
qualitative reasoning abilities, and multi-agent LLM debates have shown promise
in handling complex reasoning tasks by exploring diverse perspectives and
reasoning paths. Inspired by this, we introduce Tree-of-Debate (ToD), a
framework which converts scientific papers into LLM personas that debate their
respective novelties. To emphasize structured, critical reasoning rather than
focusing solely on outcomes, ToD dynamically constructs a debate tree, enabling
fine-grained analysis of independent novelty arguments within scholarly
articles. Through experiments on scientific literature across various domains,
evaluated by expert researchers, we demonstrate that ToD generates informative
arguments, effectively contrasts papers, and supports researchers in their
literature review.

摘要：隨著現代科技促進的研究呈指數成長，加上可近性的提升，科學發現已在各領域內外變得越來越分散。這使得評估相關作品之間的重要性、新穎性、漸進式發現和等價概念變得具有挑戰性，特別是來自不同研究社群的作品。大型語言模型 (LLM) 近期已展現出強大的量化和質化推理能力，而多重代理 LLM 辯論已在處理複雜推理任務方面展現出潛力，方法是探索不同的觀點和推理路徑。受到此啟發，我們引入了辯論樹 (ToD)，這是一個將科學論文轉換為 LLM 人格的架構，這些人格會辯論各自的新穎性。為了強調結構化、批判性推理，而非僅專注於結果，ToD 會動態建構一個辯論樹，讓使用者能夠深入分析學術文章中獨立的新穎性論點。透過在不同領域的科學文獻上進行實驗，並由專家研究員進行評估，我們證明了 ToD 能產生有見地的論點、有效對比論文，並在研究人員的文獻回顧中提供協助。

##### **Step-by-Step Fact Verification System for Medical Claims with Explainable Reasoning**
2502.14765v1 by Juraj Vladika, Ivana Hacajová, Florian Matthes

Fact verification (FV) aims to assess the veracity of a claim based on
relevant evidence. The traditional approach for automated FV includes a
three-part pipeline relying on short evidence snippets and encoder-only
inference models. More recent approaches leverage the multi-turn nature of LLMs
to address FV as a step-by-step problem where questions inquiring additional
context are generated and answered until there is enough information to make a
decision. This iterative method makes the verification process rational and
explainable. While these methods have been tested for encyclopedic claims,
exploration on domain-specific and realistic claims is missing. In this work,
we apply an iterative FV system on three medical fact-checking datasets and
evaluate it with multiple settings, including different LLMs, external web
search, and structured reasoning using logic predicates. We demonstrate
improvements in the final performance over traditional approaches and the high
potential of step-by-step FV systems for domain-specific claims.

摘要：事實驗證 (FV) 旨在根據相關證據評估主張的真實性。自動化 FV 的傳統方法包括依賴於短證據片段和僅編碼器推論模型的三部分管道。最近的方法利用 LLM 的多輪特性，將 FV 視為一個逐步問題，其中會產生問題來詢問額外背景並回答，直到有足夠的資訊可以做出決定。這種迭代方法使驗證過程合理且可解釋。雖然這些方法已針對百科全書式主張進行測試，但缺乏對特定領域和現實主張的探討。在這項工作中，我們在三個醫學事實查核資料集上應用了一個迭代 FV 系統，並使用多種設定對其進行評估，包括不同的 LLM、外部網路搜尋和使用邏輯謂詞的結構化推理。我們展示了傳統方法的最終效能改進，以及逐步 FV 系統對特定領域主張的高潛力。

##### **EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations**
2502.14760v1 by Haotian Zhai, Connor Lawless, Ellen Vitercik, Liu Leqi

A fundamental problem in combinatorial optimization is identifying equivalent
formulations, which can lead to more efficient solution strategies and deeper
insights into a problem's computational complexity. The need to automatically
identify equivalence between problem formulations has grown as optimization
copilots--systems that generate problem formulations from natural language
descriptions--have proliferated. However, existing approaches to checking
formulation equivalence lack grounding, relying on simple heuristics which are
insufficient for rigorous validation. Inspired by Karp reductions, in this work
we introduce quasi-Karp equivalence, a formal criterion for determining when
two optimization formulations are equivalent based on the existence of a
mapping between their decision variables. We propose EquivaMap, a framework
that leverages large language models to automatically discover such mappings,
enabling scalable and reliable equivalence verification. To evaluate our
approach, we construct the first open-source dataset of equivalent optimization
formulations, generated by applying transformations such as adding slack
variables or valid inequalities to existing formulations. Empirically,
EquivaMap significantly outperforms existing methods, achieving substantial
improvements in correctly identifying formulation equivalence.

摘要：<paragraph>組合優化中的基本問題在於識別等效公式，這可能導致更有效的解決策略，並更深入地了解問題的計算複雜性。隨著優化輔助系統（從自然語言描述中產生問題公式的系統）的普及，自動識別問題公式之間等價性的需求也隨之增加。然而，現有的公式等價性檢查方法缺乏依據，依賴於簡單的啟發法，而這對於嚴格驗證來說是不夠的。受 Karp 遞減啟發，我們在這項工作中引入了準 Karp 等價性，這是一個正式標準，用於根據決策變數之間的映射存在性來確定兩個優化公式何時等效。我們提出了 EquivaMap，一個利用大型語言模型自動發現此類映射的框架，實現可擴充且可靠的等價性驗證。為了評估我們的做法，我們構建了第一個等效優化公式的開源資料集，該資料集是通過對現有公式套用轉換（例如添加鬆弛變數或有效不等式）產生的。根據經驗，EquivaMap 明顯優於現有方法，在正確識別公式等價性方面取得了顯著進展。</paragraph>

##### **On the Influence of Context Size and Model Choice in Retrieval-Augmented Generation Systems**
2502.14759v1 by Juraj Vladika, Florian Matthes

Retrieval-augmented generation (RAG) has emerged as an approach to augment
large language models (LLMs) by reducing their reliance on static knowledge and
improving answer factuality. RAG retrieves relevant context snippets and
generates an answer based on them. Despite its increasing industrial adoption,
systematic exploration of RAG components is lacking, particularly regarding the
ideal size of provided context, and the choice of base LLM and retrieval
method. To help guide development of robust RAG systems, we evaluate various
context sizes, BM25 and semantic search as retrievers, and eight base LLMs.
Moving away from the usual RAG evaluation with short answers, we explore the
more challenging long-form question answering in two domains, where a good
answer has to utilize the entire context. Our findings indicate that final QA
performance improves steadily with up to 15 snippets but stagnates or declines
beyond that. Finally, we show that different general-purpose LLMs excel in the
biomedical domain than the encyclopedic one, and that open-domain evidence
retrieval in large corpora is challenging.

摘要：檢索增強生成 (RAG) 已成為一種方法，可透過減少大型語言模型 (LLM) 對靜態知識的依賴，並改善答案的真實性，來增強大型語言模型 (LLM)。RAG 會擷取相關的內容片段，並根據這些片段產生答案。儘管其產業採用率不斷提高，但缺乏對 RAG 組成的系統性探討，特別是在提供的內容的理想大小，以及基礎 LLM 和檢索方法的選擇方面。為了協助引導穩健 RAG 系統的開發，我們評估了各種內容大小、BM25 和語意搜尋作為檢索器，以及八個基礎 LLM。我們不再使用簡短答案進行常見的 RAG 評估，而是探討在兩個領域中更具挑戰性的長篇問答，其中一個好的答案必須利用整個內容。我們的研究結果指出，最終的問答效能會隨著多達 15 個片段而穩定提升，但在超過這個數量後就會停滯或下降。最後，我們表明不同的通用 LLM 在生物醫學領域比百科全書領域更為出色，而且在大型語料庫中進行開放領域證據檢索具有挑戰性。

##### **MedVAE: Efficient Automated Interpretation of Medical Images with Large-Scale Generalizable Autoencoders**
2502.14753v1 by Maya Varma, Ashwin Kumar, Rogier van der Sluijs, Sophie Ostmeier, Louis Blankemeier, Pierre Chambon, Christian Bluethgen, Jip Prince, Curtis Langlotz, Akshay Chaudhari

Medical images are acquired at high resolutions with large fields of view in
order to capture fine-grained features necessary for clinical decision-making.
Consequently, training deep learning models on medical images can incur large
computational costs. In this work, we address the challenge of downsizing
medical images in order to improve downstream computational efficiency while
preserving clinically-relevant features. We introduce MedVAE, a family of six
large-scale 2D and 3D autoencoders capable of encoding medical images as
downsized latent representations and decoding latent representations back to
high-resolution images. We train MedVAE autoencoders using a novel two-stage
training approach with 1,052,730 medical images. Across diverse tasks obtained
from 20 medical image datasets, we demonstrate that (1) utilizing MedVAE latent
representations in place of high-resolution images when training downstream
models can lead to efficiency benefits (up to 70x improvement in throughput)
while simultaneously preserving clinically-relevant features and (2) MedVAE can
decode latent representations back to high-resolution images with high
fidelity. Our work demonstrates that large-scale, generalizable autoencoders
can help address critical efficiency challenges in the medical domain. Our code
is available at https://github.com/StanfordMIMI/MedVAE.

摘要：医学影像以高解析度和广阔的视野获取，以便捕捉临床决策所需的细微特征。因此，在医学影像上训练深度学习模型可能会产生巨大的计算成本。在这项工作中，我们解决了缩小医学影像以提高下游计算效率同时保留临床相关特征的挑战。我们介绍了 MedVAE，这是一个由六个大型 2D 和 3D 自动编码器组成的系列，能够将医学影像编码为缩小的潜在表示，并将潜在表示解码回高分辨率影像。我们使用一种新颖的两阶段训练方法，利用 1,052,730 张医学影像来训练 MedVAE 自动编码器。在从 20 个医学影像数据集获得的不同任务中，我们证明了 (1) 在训练下游模型时，利用 MedVAE 潜在表示代替高分辨率影像可以带来效率优势（吞吐量提高高达 70 倍），同时保留临床相关特征；(2) MedVAE 可以将潜在表示解码回高分辨率影像，且保真度高。我们的工作表明，大规模、可推广的自动编码器可以帮助解决医学领域的重大效率挑战。我们的代码可在 https://github.com/StanfordMIMI/MedVAE 获得。

##### **TritonBench: Benchmarking Large Language Model Capabilities for Generating Triton Operators**
2502.14752v1 by Jianling Li, Shangzhan Li, Zhenye Gao, Qi Shi, Yuxuan Li, Zefan Wang, Jiacheng Huang, Haojie Wang, Jianrong Wang, Xu Han, Zhiyuan Liu, Maosong Sun

Triton, a high-level Python-like language designed for building efficient GPU
kernels, is widely adopted in deep learning frameworks due to its portability,
flexibility, and accessibility. However, programming and parallel optimization
still require considerable trial and error from Triton developers. Despite
advances in large language models (LLMs) for conventional code generation,
these models struggle to generate accurate, performance-optimized Triton code,
as they lack awareness of its specifications and the complexities of GPU
programming. More critically, there is an urgent need for systematic
evaluations tailored to Triton. In this work, we introduce TritonBench, the
first comprehensive benchmark for Triton operator generation. TritonBench
features two evaluation channels: a curated set of 184 real-world operators
from GitHub and a collection of operators aligned with PyTorch interfaces.
Unlike conventional code benchmarks prioritizing functional correctness,
TritonBench also profiles efficiency performance on widely deployed GPUs
aligned with industry applications. Our study reveals that current
state-of-the-art code LLMs struggle to generate efficient Triton operators,
highlighting a significant gap in high-performance code generation. TritonBench
will be available at https://github.com/thunlp/TritonBench.

摘要：Triton 是一種高階的類 Python 語言，專門用於建構高效的 GPU 核心，由於其可移植性、靈活性及可存取性，已廣泛採用於深度學習框架中。然而，編程和並行最佳化仍需要 Triton 開發人員進行大量的試驗和錯誤。儘管大型語言模型 (LLM) 在傳統程式碼產生方面取得了進展，但這些模型在產生準確且效能最佳化的 Triton 程式碼時仍面臨困難，因為它們缺乏對其規格和 GPU 編程複雜性的認識。更重要的是，迫切需要針對 Triton 量身打造的系統性評估。在這項工作中，我們介紹 TritonBench，這是第一個針對 Triton 算子產生進行全面評比的基準。TritonBench 具有兩個評估管道：一組來自 GitHub 的 184 個真實世界算子，以及一組與 PyTorch 介面對齊的算子。與優先考慮功能正確性的傳統程式碼基準不同，TritonBench 還剖析了與產業應用對齊的廣泛部署 GPU 上的效能表現。我們的研究表明，目前最先進的程式碼 LLM 難以產生高效的 Triton 算子，突顯了高性能程式碼產生中的重大差距。TritonBench 將在 https://github.com/thunlp/TritonBench 提供。

##### **Large Language Models Struggle to Describe the Haystack without Human Help: Human-in-the-loop Evaluation of LLMs**
2502.14748v1 by Zongxia Li, Lorena Calvo-Bartolomé, Alexander Hoyle, Paiheng Xu, Alden Dima, Juan Francisco Fung, Jordan Boyd-Graber

A common use of NLP is to facilitate the understanding of large document
collections, with a shift from using traditional topic models to Large Language
Models. Yet the effectiveness of using LLM for large corpus understanding in
real-world applications remains under-explored. This study measures the
knowledge users acquire with unsupervised, supervised LLM-based exploratory
approaches or traditional topic models on two datasets. While LLM-based methods
generate more human-readable topics and show higher average win probabilities
than traditional models for data exploration, they produce overly generic
topics for domain-specific datasets that do not easily allow users to learn
much about the documents. Adding human supervision to the LLM generation
process improves data exploration by mitigating hallucination and
over-genericity but requires greater human effort. In contrast, traditional.
models like Latent Dirichlet Allocation (LDA) remain effective for exploration
but are less user-friendly. We show that LLMs struggle to describe the haystack
of large corpora without human help, particularly domain-specific data, and
face scaling and hallucination limitations due to context length constraints.
Dataset available at https://huggingface. co/datasets/zli12321/Bills.

摘要：NLP 的常見用途是促進對大型文件集合的理解，從使用傳統主題模型轉向大型語言模型。然而，在現實世界的應用中使用 LLM 了解大型語料庫的有效性仍未得到充分探索。本研究衡量了使用者在兩個資料集上使用無監督、監督的基於 LLM 的探索性方法或傳統主題模型獲得的知識。雖然基於 LLM 的方法會產生更多人類可讀的主題，並且顯示出比傳統模型更高的平均獲勝機率，但它們會為特定領域的資料集產生過於通用的主題，而這些主題不容易讓使用者對文件有深入了解。在 LLM 生成過程中加入人類監督可透過減輕幻覺和過度泛化來改善資料探索，但需要更多的人力。相反地，傳統模型（如潛在狄利克雷配置 (LDA)）仍然有效於探索，但使用者友善度較低。我們表明，LLM 難以在沒有人類幫助的情況下描述大型語料庫的乾草堆，特別是特定領域的資料，並且會因上下文長度限制而面臨擴充性和幻覺限制。資料集可於 https://huggingface.co/datasets/zli12321/Bills 取得。

##### **HiddenDetect: Detecting Jailbreak Attacks against Large Vision-Language Models via Monitoring Hidden States**
2502.14744v1 by Yilei Jiang, Xinyan Gao, Tianshuo Peng, Yingshui Tan, Xiaoyong Zhu, Bo Zheng, Xiangyu Yue

The integration of additional modalities increases the susceptibility of
large vision-language models (LVLMs) to safety risks, such as jailbreak
attacks, compared to their language-only counterparts. While existing research
primarily focuses on post-hoc alignment techniques, the underlying safety
mechanisms within LVLMs remain largely unexplored. In this work , we
investigate whether LVLMs inherently encode safety-relevant signals within
their internal activations during inference. Our findings reveal that LVLMs
exhibit distinct activation patterns when processing unsafe prompts, which can
be leveraged to detect and mitigate adversarial inputs without requiring
extensive fine-tuning. Building on this insight, we introduce HiddenDetect, a
novel tuning-free framework that harnesses internal model activations to
enhance safety. Experimental results show that {HiddenDetect} surpasses
state-of-the-art methods in detecting jailbreak attacks against LVLMs. By
utilizing intrinsic safety-aware patterns, our method provides an efficient and
scalable solution for strengthening LVLM robustness against multimodal threats.
Our code will be released publicly at
https://github.com/leigest519/HiddenDetect.

摘要：整合其他模态会增加大型视觉语言模型 (LVLMs) 对安全风险的敏感性，例如越狱攻击，与仅语言的对应模型相比。虽然现有的研究主要集中于事后对齐技术，但 LVLMs 内部的基本安全机制在很大程度上仍未得到探索。在这项工作中，我们调查了 LVLMs 在推理过程中是否在其内部激活中固有地编码了与安全相关的信号。我们的研究结果表明，LVLMs 在处理不安全提示时表现出不同的激活模式，这可以用来检测和缓解对抗性输入，而无需进行广泛的微调。基于这一见解，我们引入了 HiddenDetect，这是一个新颖的无调优框架，利用内部模型激活来增强安全性。实验结果表明，{HiddenDetect} 在检测针对 LVLMs 的越狱攻击方面超越了最先进的方法。通过利用内在的安全感知模式，我们的方法为加强 LVLM 对多模态威胁的鲁棒性提供了一种高效且可扩展的解决方案。我们的代码将在 https://github.com/leigest519/HiddenDetect 公开发布。

##### **Multi-Agent Coordination across Diverse Applications: A Survey**
2502.14743v1 by Lijun Sun, Yijun Yang, Qiqi Duan, Yuhui Shi, Chao Lyu, Yu-Cheng Chang, Chin-Teng Lin, Yang Shen

Multi-agent coordination studies the underlying mechanism enabling the
trending spread of diverse multi-agent systems (MAS) and has received
increasing attention, driven by the expansion of emerging applications and
rapid AI advances. This survey outlines the current state of coordination
research across applications through a unified understanding that answers four
fundamental coordination questions: (1) what is coordination; (2) why
coordination; (3) who to coordinate with; and (4) how to coordinate. Our
purpose is to explore existing ideas and expertise in coordination and their
connections across diverse applications, while identifying and highlighting
emerging and promising research directions. First, general coordination
problems that are essential to varied applications are identified and analyzed.
Second, a number of MAS applications are surveyed, ranging from widely studied
domains, e.g., search and rescue, warehouse automation and logistics, and
transportation systems, to emerging fields including humanoid and
anthropomorphic robots, satellite systems, and large language models (LLMs).
Finally, open challenges about the scalability, heterogeneity, and learning
mechanisms of MAS are analyzed and discussed. In particular, we identify the
hybridization of hierarchical and decentralized coordination, human-MAS
coordination, and LLM-based MAS as promising future directions.

摘要：多智能體協調研究探討了促成各種多智能體系統 (MAS) 流行擴散的底層機制，並隨著新興應用擴展和 AI 快速進展而受到越來越多的關注。這項調查透過統一的理解來概述協調研究的現狀，回答了四個基本的協調問題：(1) 什麼是協調；(2) 為什麼協調；(3) 與誰協調；以及 (4) 如何協調。我們的目的是探索協調中現有的想法和專業知識，以及它們在不同應用中的關聯，同時找出並強調新興且有前景的研究方向。首先，找出並分析了對各種應用至關重要的協調問題。其次，調查了許多 MAS 應用，範圍從廣泛研究的領域（例如搜尋和救援、倉庫自動化和物流，以及運輸系統），到新興領域，包括人形機器人和擬人機器人、衛星系統和大語言模型 (LLM)。最後，分析並討論了有關 MAS 的可擴充性、異質性和學習機制的開放挑戰。特別是，我們將分層協調和分散式協調、人類-MAS 協調和基於 LLM 的 MAS 的混合視為有前景的未來方向。

##### **YOLOv12: A Breakdown of the Key Architectural Features**
2502.14740v1 by Mujadded Al Rabbani Alif, Muhammad Hussain

This paper presents an architectural analysis of YOLOv12, a significant
advancement in single-stage, real-time object detection building upon the
strengths of its predecessors while introducing key improvements. The model
incorporates an optimised backbone (R-ELAN), 7x7 separable convolutions, and
FlashAttention-driven area-based attention, improving feature extraction,
enhanced efficiency, and robust detections. With multiple model variants,
similar to its predecessors, YOLOv12 offers scalable solutions for both
latency-sensitive and high-accuracy applications. Experimental results manifest
consistent gains in mean average precision (mAP) and inference speed, making
YOLOv12 a compelling choice for applications in autonomous systems, security,
and real-time analytics. By achieving an optimal balance between computational
efficiency and performance, YOLOv12 sets a new benchmark for real-time computer
vision, facilitating deployment across diverse hardware platforms, from edge
devices to high-performance clusters.

摘要：本文提出 YOLOv12 的架構分析，這是在單階段即時物件偵測領域的重大進展，它建立在前任的優勢之上，同時引入了關鍵改進。該模型結合了最佳化的主幹 (R-ELAN)、7x7 可分離卷積和 FlashAttention 驅動的基於區域的注意力，改進了特徵提取、增強了效率和穩健的偵測。與其前身類似，YOLOv12 具有多種模型變體，為低延遲敏感型和高準確度應用程式提供了可擴充的解決方案。實驗結果顯示在平均準確度 (mAP) 和推論速度方面都有顯著的提升，這使得 YOLOv12 成為自動化系統、安全性和即時分析應用程式的理想選擇。透過在運算效率和效能之間取得最佳平衡，YOLOv12 為即時電腦視覺樹立了新的基準，促進了在各種硬體平台（從邊緣裝置到高性能叢集）上的部署。

##### **SuperGPQA: Scaling LLM Evaluation across 285 Graduate Disciplines**
2502.14739v1 by M-A-P Team, Xinrun Du, Yifan Yao, Kaijing Ma, Bingli Wang, Tianyu Zheng, Kang Zhu, Minghao Liu, Yiming Liang, Xiaolong Jin, Zhenlin Wei, Chujie Zheng, Kaixing Deng, Shuyue Guo, Shian Jia, Sichao Jiang, Yiyan Liao, Rui Li, Qinrui Li, Sirun Li, Yizhi Li, Yunwen Li, Dehua Ma, Yuansheng Ni, Haoran Que, Qiyao Wang, Zhoufutu Wen, Siwei Wu, Tianshun Xing, Ming Xu, Zhenzhu Yang, Zekun Moore Wang, Junting Zhou, Yuelin Bai, Xingyuan Bu, Chenglin Cai, Liang Chen, Yifan Chen, Chengtuo Cheng, Tianhao Cheng, Keyi Ding, Siming Huang, Yun Huang, Yaoru Li, Yizhe Li, Zhaoqun Li, Tianhao Liang, Chengdong Lin, Hongquan Lin, Yinghao Ma, Zhongyuan Peng, Zifan Peng, Qige Qi, Shi Qiu, Xingwei Qu, Yizhou Tan, Zili Wang, Chenqing Wang, Hao Wang, Yiya Wang, Yubo Wang, Jiajun Xu, Kexin Yang, Ruibin Yuan, Yuanhao Yue, Tianyang Zhan, Chun Zhang, Jingyang Zhang, Xiyue Zhang, Xingjian Zhang, Yue Zhang, Yongchi Zhao, Xiangyu Zheng, Chenghua Zhong, Yang Gao, Zhoujun Li, Dayiheng Liu, Qian Liu, Tianyu Liu, Shiwen Ni, Junran Peng, Yujia Qin, Wenbo Su, Guoyin Wang, Shi Wang, Jian Yang, Min Yang, Meng Cao, Xiang Yue, Zhaoxiang Zhang, Wangchunshu Zhou, Jiaheng Liu, Qunshu Lin, Wenhao Huang, Ge Zhang

Large language models (LLMs) have demonstrated remarkable proficiency in
mainstream academic disciplines such as mathematics, physics, and computer
science. However, human knowledge encompasses over 200 specialized disciplines,
far exceeding the scope of existing benchmarks. The capabilities of LLMs in
many of these specialized fields-particularly in light industry, agriculture,
and service-oriented disciplines-remain inadequately evaluated. To address this
gap, we present SuperGPQA, a comprehensive benchmark that evaluates
graduate-level knowledge and reasoning capabilities across 285 disciplines. Our
benchmark employs a novel Human-LLM collaborative filtering mechanism to
eliminate trivial or ambiguous questions through iterative refinement based on
both LLM responses and expert feedback. Our experimental results reveal
significant room for improvement in the performance of current state-of-the-art
LLMs across diverse knowledge domains (e.g., the reasoning-focused model
DeepSeek-R1 achieved the highest accuracy of 61.82% on SuperGPQA), highlighting
the considerable gap between current model capabilities and artificial general
intelligence. Additionally, we present comprehensive insights from our
management of a large-scale annotation process, involving over 80 expert
annotators and an interactive Human-LLM collaborative system, offering valuable
methodological guidance for future research initiatives of comparable scope.

摘要：大型語言模型 (LLM) 已展現出在主流學術領域（如數學、物理和電腦科學）的卓越能力。然而，人類知識包含超過 200 個專業領域，遠遠超過現有基準的範圍。LLM 在許多這些專業領域（特別是在輕工業、農業和服務導向領域）的能力仍未得到充分評估。為了解決這個差距，我們提出了 SuperGPQA，這是一個綜合基準，用於評估 285 個領域的研究生級知識和推理能力。我們的基準採用新穎的人類-LLM 協同過濾機制，透過基於 LLM 回應和專家回饋的迭代改進，來消除瑣碎或模稜兩可的問題。我們的實驗結果顯示，當前最先進的 LLM 在不同知識領域的表現仍有很大的改進空間（例如，以推理為重點的模型 DeepSeek-R1 在 SuperGPQA 上達到了 61.82% 的最高準確度），突顯了當前模型能力與人工通用智慧之間的巨大差距。此外，我們從管理大型註釋過程（涉及 80 多位專家註釋者和一個互動式人類-LLM 協作系統）中提出了全面的見解，為未來具有可比規模的研究計畫提供了寶貴的方法論指導。

##### **EAGER-LLM: Enhancing Large Language Models as Recommenders through Exogenous Behavior-Semantic Integration**
2502.14735v1 by Minjie Hong, Yan Xia, Zehan Wang, Jieming Zhu, Ye Wang, Sihang Cai, Xiaoda Yang, Quanyu Dai, Zhenhua Dong, Zhimeng Zhang, Zhou Zhao

Large language models (LLMs) are increasingly leveraged as foundational
backbones in the development of advanced recommender systems, offering enhanced
capabilities through their extensive knowledge and reasoning. Existing
llm-based recommender systems (RSs) often face challenges due to the
significant differences between the linguistic semantics of pre-trained LLMs
and the collaborative semantics essential for RSs. These systems use
pre-trained linguistic semantics but learn collaborative semantics from scratch
via the llm-Backbone. However, LLMs are not designed for recommendations,
leading to inefficient collaborative learning, weak result correlations, and
poor integration of traditional RS features. To address these challenges, we
propose EAGER-LLM, a decoder-only llm-based generative recommendation framework
that integrates endogenous and exogenous behavioral and semantic information in
a non-intrusive manner. Specifically, we propose 1)dual-source knowledge-rich
item indices that integrates indexing sequences for exogenous signals, enabling
efficient link-wide processing; 2)non-invasive multiscale alignment
reconstruction tasks guide the model toward a deeper understanding of both
collaborative and semantic signals; 3)an annealing adapter designed to finely
balance the model's recommendation performance with its comprehension
capabilities. We demonstrate EAGER-LLM's effectiveness through rigorous testing
on three public benchmarks.

摘要：大型語言模型（LLM）正日益被用作先進推薦系統開發中的基礎主幹，透過其廣泛的知識和推理能力提供增強功能。現有的基於 LLM 的推薦系統（RS）通常會因為預先訓練的 LLM 語言語義與 RS 必備的協作語義之間的顯著差異而面臨挑戰。這些系統使用預先訓練的語言語義，但透過 LLM 主幹從頭學習協作語義。然而，LLM 並非專為推薦而設計，導致協作學習效率低落、結果關聯性薄弱，以及與傳統 RS 功能整合不佳。為了應對這些挑戰，我們提出 EAGER-LLM，這是一種僅解碼器、基於 LLM 的生成推薦架構，能以非侵入性方式整合內生和外生行為和語義資訊。具體來說，我們提出 1) 雙來源、知識豐富的項目索引，它整合了外生訊號的索引序列，實現了高效的鏈路廣泛處理；2) 非侵入式多尺度對齊重建任務引導模型更深入地理解協作和語義訊號；3) 退火適配器旨在精細地平衡模型的推薦效能與其理解能力。我們透過在三個公共基準上的嚴格測試證明了 EAGER-LLM 的有效性。

##### **Sentence Smith: Formally Controllable Text Transformation and its Application to Evaluation of Text Embedding Models**
2502.14734v1 by Hongji Li, Andrianos Michail, Reto Gubelmann, Simon Clematide, Juri Opitz

We propose the Sentence Smith framework that enables controlled and specified
manipulation of text meaning. It consists of three main steps: 1. Parsing a
sentence into a semantic graph, 2. Applying human-designed semantic
manipulation rules, and 3. Generating text from the manipulated graph. A final
filtering step (4.) ensures the validity of the applied transformation. To
demonstrate the utility of Sentence Smith in an application study, we use it to
generate hard negative pairs that challenge text embedding models. Since the
controllable generation makes it possible to clearly isolate different types of
semantic shifts, we can gain deeper insights into the specific strengths and
weaknesses of widely used text embedding models, also addressing an issue in
current benchmarking where linguistic phenomena remain opaque. Human validation
confirms that the generations produced by Sentence Smith are highly accurate.

摘要：我們提出 Sentence Smith 框架，它能控制並指定文本含義的處理。它包含三個主要步驟：1. 將句子解析成語義圖形，2. 套用人為設計的語義處理規則，3. 從處理過的圖形生成文本。最後的過濾步驟 (4.) 確保套用轉換的有效性。為了在應用研究中展示 Sentence Smith 的效用，我們使用它來產生挑戰文本嵌入模型的困難負面對。由於可控生成能清楚地隔離不同類型的語義轉移，我們能更深入地了解廣泛使用的文本嵌入模型的具體優點和缺點，同時也解決了語言現象在當前基準測試中仍然不透明的問題。人為驗證確認 Sentence Smith 產生的生成高度準確。

##### **WavRAG: Audio-Integrated Retrieval Augmented Generation for Spoken Dialogue Models**
2502.14727v1 by Yifu Chen, Shengpeng Ji, Haoxiao Wang, Ziqing Wang, Siyu Chen, Jinzheng He, Jin Xu, Zhou Zhao

Retrieval Augmented Generation (RAG) has gained widespread adoption owing to
its capacity to empower large language models (LLMs) to integrate external
knowledge. However, existing RAG frameworks are primarily designed for
text-based LLMs and rely on Automatic Speech Recognition to process speech
input, which discards crucial audio information, risks transcription errors,
and increases computational overhead. Therefore, we introduce WavRAG, the first
retrieval augmented generation framework with native, end-to-end audio support.
WavRAG offers two key features: 1) Bypassing ASR, WavRAG directly processes raw
audio for both embedding and retrieval. 2) WavRAG integrates audio and text
into a unified knowledge representation. Specifically, we propose the
WavRetriever to facilitate the retrieval from a text-audio hybrid knowledge
base, and further enhance the in-context capabilities of spoken dialogue models
through the integration of chain-of-thought reasoning. In comparison to
state-of-the-art ASR-Text RAG pipelines, WavRAG achieves comparable retrieval
performance while delivering a 10x acceleration. Furthermore, WavRAG's unique
text-audio hybrid retrieval capability extends the boundaries of RAG to the
audio modality.

摘要：檢索增強生成 (RAG) 因其賦能大型語言模型 (LLM) 整合外部知識的能力而獲得廣泛採用。然而，現有的 RAG 框架主要設計用於基於文字的 LLM，並依賴自動語音辨識處理語音輸入，這會捨棄重要的音訊資訊、有轉錄錯誤的風險，並增加運算負擔。因此，我們引入了 WavRAG，這是第一個具備原生端對端音訊支援的檢索增強生成框架。WavRAG 提供兩個主要功能：1) 繞過 ASR，WavRAG 直接處理原始音訊以進行嵌入和檢索。2) WavRAG 將音訊和文字整合到統一的知識表示中。具體來說，我們提出了 WavRetriever 以利於從文字音訊混合知識庫中進行檢索，並透過整合思考鏈推理進一步增強對話模型的語境能力。與最先進的 ASR 文字 RAG 管線相比，WavRAG 達到了相當的檢索效能，同時提供了 10 倍的加速。此外，WavRAG 獨特的文字音訊混合檢索能力將 RAG 的界線延伸到音訊模式。

##### **Entity Framing and Role Portrayal in the News**
2502.14718v1 by Tarek Mahmoud, Zhuohan Xie, Dimitar Dimitrov, Nikolaos Nikolaidis, Purificação Silvano, Roman Yangarber, Shivam Sharma, Elisa Sartori, Nicolas Stefanovitch, Giovanni Da San Martino, Jakub Piskorski, Preslav Nakov

We introduce a novel multilingual hierarchical corpus annotated for entity
framing and role portrayal in news articles. The dataset uses a unique taxonomy
inspired by storytelling elements, comprising 22 fine-grained roles, or
archetypes, nested within three main categories: protagonist, antagonist, and
innocent. Each archetype is carefully defined, capturing nuanced portrayals of
entities such as guardian, martyr, and underdog for protagonists; tyrant,
deceiver, and bigot for antagonists; and victim, scapegoat, and exploited for
innocents. The dataset includes 1,378 recent news articles in five languages
(Bulgarian, English, Hindi, European Portuguese, and Russian) focusing on two
critical domains of global significance: the Ukraine-Russia War and Climate
Change. Over 5,800 entity mentions have been annotated with role labels. This
dataset serves as a valuable resource for research into role portrayal and has
broader implications for news analysis. We describe the characteristics of the
dataset and the annotation process, and we report evaluation results on
fine-tuned state-of-the-art multilingual transformers and hierarchical
zero-shot learning using LLMs at the level of a document, a paragraph, and a
sentence.

摘要：<paragraph>我們引進一個新穎的多語言層級語料庫，其中註解了新聞文章中的實體框架和角色描繪。此資料集使用了一個獨特的分類法，其靈感來自講故事元素，包含 22 個細緻的角色或原型，嵌套在三個主要類別中：主角、對手和無辜者。每個原型都經過仔細定義，捕捉了實體的細微描繪，例如主角的監護人、烈士和弱者；對手的暴君、欺騙者和偏執狂；以及無辜者的受害者、替罪羊和被剝削者。該資料集包括五種語言（保加利亞語、英語、印地語、歐洲葡萄牙語和俄語）中的 1,378 篇近期新聞文章，重點關注兩個具有全球意義的關鍵領域：烏克蘭-俄羅斯戰爭和氣候變遷。超過 5,800 個實體提及已註解為角色標籤。此資料集作為角色描繪研究的寶貴資源，並對新聞分析有更廣泛的影響。我們描述了資料集的特徵和註解過程，並報告了對使用 LLM 在文件、段落和句子層級進行微調的最新多語言轉換器和層級零次學習的評估結果。</paragraph>

##### **From Knowledge Generation to Knowledge Verification: Examining the BioMedical Generative Capabilities of ChatGPT**
2502.14714v1 by Ahmed Abdeen Hamed, Byung Suk Lee

The generative capabilities of LLM models present opportunities in
accelerating tasks and concerns with the authenticity of the knowledge it
produces. To address the concerns, we present a computational approach that
systematically evaluates the factual accuracy of biomedical knowledge that an
LLM model has been prompted to generate. Our approach encompasses two
processes: the generation of disease-centric associations and the verification
of them using the semantic knowledge of the biomedical ontologies. Using
ChatGPT as the select LLM model, we designed a set of prompt-engineering
processes to generate linkages between diseases, drugs, symptoms, and genes to
establish grounds for assessments. Experimental results demonstrate high
accuracy in identifying disease terms (88%-97%), drug names (90%-91%), and
genetic information (88%-98%). The symptom term identification accuracy was
notably lower (49%-61%), as verified against the DOID, ChEBI, SYMPTOM, and GO
ontologies accordingly. The verification of associations reveals literature
coverage rates of (89%-91%) among disease-drug and disease-gene associations.
The low identification accuracy for symptom terms also contributed to the
verification of symptom-related associations (49%-62%).

摘要：LLM 模型的生成能力為加速任務和對其產生的知識真實性的疑慮提供了機會。為了解決這些疑慮，我們提出了計算方法，系統性評估 LLM 模型受提示而產生的生物醫學知識的事實準確性。我們的做法包括兩個過程：生成以疾病為中心的關聯，並使用生物醫學本体的語義知識驗證它們。使用 ChatGPT 作為選定的 LLM 模型，我們設計了一組提示工程流程，以生成疾病、藥物、症狀和基因之間的關聯，作為評估的依據。實驗結果證明在識別疾病術語 (88%-97%)、藥物名稱 (90%-91%) 和遺傳資訊 (88%-98%) 方面具有很高的準確性。症狀術語識別準確性顯著較低 (49%-61%)，並根據 DOID、ChEBI、SYMPTOM 和 GO 本体進行驗證。關聯驗證顯示疾病-藥物和疾病-基因關聯的文獻覆蓋率為 (89%-91%)。症狀術語的低識別準確性也影響了症狀相關關聯的驗證 (49%-62%)。

##### **Data-Efficient Pretraining with Group-Level Data Influence Modeling**
2502.14709v1 by Zichun Yu, Fei Peng, Jie Lei, Arnold Overwijk, Wen-tau Yih, Chenyan Xiong

Data-efficient pretraining has shown tremendous potential to elevate scaling
laws. This paper argues that effective pretraining data should be curated at
the group level, treating a set of data points as a whole rather than as
independent contributors. To achieve that, we propose Group-Level Data
Influence Modeling (Group-MATES), a novel data-efficient pretraining method
that captures and optimizes group-level data utility. Specifically, Group-MATES
collects oracle group-level influences by locally probing the pretraining model
with data sets. It then fine-tunes a relational data influence model to
approximate oracles as relationship-weighted aggregations of individual
influences. The fine-tuned model selects the data subset by maximizing its
group-level influence prediction, with influence-aware clustering to enable
efficient inference. Experiments on the DCLM benchmark demonstrate that
Group-MATES achieves a 10% relative core score improvement on 22 downstream
tasks over DCLM-Baseline and 5% over individual-influence-based methods,
establishing a new state-of-the-art. Further analyses highlight the
effectiveness of relational data influence models in capturing intricate
interactions between data points.

摘要：資料有效的預訓練已展現出提升規模化定律的巨大潛力。本文認為，有效的預訓練資料應在群組層級中進行策展，將資料點集合視為一個整體，而非獨立的貢獻者。為達成此目的，我們提出群組層級資料影響建模（Group-MATES），這是一種新穎的資料有效預訓練方法，可擷取和最佳化群組層級資料效用。具體而言，Group-MATES 透過使用資料集在區域探測預訓練模型，收集神諭群組層級影響。接著，微調關係資料影響模型，以關係加權聚合個別影響來近似神諭。微調模型透過最大化其群組層級影響預測，選取資料子集，並透過考量影響的群集，啟用有效率的推論。在 DCLM 基準上的實驗證明，與 DCLM-Baseline 相比，Group-MATES 在 22 個下游任務上達成 10% 的相對核心分數提升，並比基於個別影響的方法高出 5%，建立了新的技術水準。進一步的分析強調了關係資料影響模型在擷取資料點之間的複雜互動上的有效性。

##### **Human Misperception of Generative-AI Alignment: A Laboratory Experiment**
2502.14708v1 by Kevin He, Ran Shorrer, Mengjia Xia

We conduct an incentivized laboratory experiment to study people's perception
of generative artificial intelligence (GenAI) alignment in the context of
economic decision-making. Using a panel of economic problems spanning the
domains of risk, time preference, social preference, and strategic
interactions, we ask human subjects to make choices for themselves and to
predict the choices made by GenAI on behalf of a human user. We find that
people overestimate the degree of alignment between GenAI's choices and human
choices. In every problem, human subjects' average prediction about GenAI's
choice is substantially closer to the average human-subject choice than it is
to the GenAI choice. At the individual level, different subjects' predictions
about GenAI's choice in a given problem are highly correlated with their own
choices in the same problem. We explore the implications of people
overestimating GenAI alignment in a simple theoretical model.

摘要：我們進行一項誘因實驗室實驗，以研究人們對生成式人工智慧 (GenAI) 在經濟決策制定中的對齊認知。使用涵蓋風險、時間偏好、社會偏好和策略性互動領域的經濟問題小組，我們要求受試者為自己做出選擇，並預測 GenAI 代表人類使用者做出的選擇。我們發現人們高估了 GenAI 選擇和人類選擇之間的對齊程度。在每個問題中，受試者對 GenAI 選擇的平均預測都比對 GenAI 選擇的預測更接近於平均人類受試者選擇。在個人層面上，不同受試者對特定問題中 GenAI 選擇的預測與他們在同一個問題中的選擇高度相關。我們在一個簡單的理論模型中探討了人們高估 GenAI 對齊的影響。

##### **Not All Data are Good Labels: On the Self-supervised Labeling for Time Series Forecasting**
2502.14704v1 by Yuxuan Yang, Dalin Zhang, Yuxuan Liang, Hua Lu, Huan Li, Gang Chen

Time Series Forecasting (TSF) is a crucial task in various domains, yet
existing TSF models rely heavily on high-quality data and insufficiently
exploit all available data. This paper explores a novel self-supervised
approach to re-label time series datasets by inherently constructing candidate
datasets. During the optimization of a simple reconstruction network,
intermediates are used as pseudo labels in a self-supervised paradigm,
improving generalization for any predictor. We introduce the Self-Correction
with Adaptive Mask (SCAM), which discards overfitted components and selectively
replaces them with pseudo labels generated from reconstructions. Additionally,
we incorporate Spectral Norm Regularization (SNR) to further suppress
overfitting from a loss landscape perspective. Our experiments on eleven
real-world datasets demonstrate that SCAM consistently improves the performance
of various backbone models. This work offers a new perspective on constructing
datasets and enhancing the generalization of TSF models through self-supervised
learning.

摘要：時間序列預測 (TSF) 在各個領域中都是一項重要的任務，但現有的 TSF 模型極度依賴高品質的資料，且無法充分利用所有可用的資料。本文探討了一種新穎的自監督方法，藉由內建地建構候選資料集來重新標記時間序列資料集。在最佳化一個簡單的重建網路過程中，中間產物會在自監督範例中作為偽標籤，進而改善任何預測器的概化能力。我們引入了帶有自適應遮罩 (SCAM) 的自我修正，它會捨棄過度擬合的組成，並選擇性地以從重建產生的偽標籤取代它們。此外，我們納入了頻譜範數正規化 (SNR) 來進一步抑制從損失景觀觀點來看產生的過度擬合。我們在 11 個真實世界的資料集上進行的實驗，證明 SCAM 持續改善各種主幹模型的效能。這項工作提供了建構資料集和透過自監督學習來提升 TSF 模型概化能力的新觀點。

##### **I-MCTS: Enhancing Agentic AutoML via Introspective Monte Carlo Tree Search**
2502.14693v1 by Zujie Liang, Feng Wei, Wujiang Xu, Lin Chen, Yuxi Qian, Xinhui Wu

Recent advancements in large language models (LLMs) have shown remarkable
potential in automating machine learning tasks. However, existing LLM-based
agents often struggle with low-diversity and suboptimal code generation. While
recent work has introduced Monte Carlo Tree Search (MCTS) to address these
issues, limitations persist in the quality and diversity of thoughts generated,
as well as in the scalar value feedback mechanisms used for node selection. In
this study, we introduce Introspective Monte Carlo Tree Search (I-MCTS), a
novel approach that iteratively expands tree nodes through an introspective
process that meticulously analyzes solutions and results from parent and
sibling nodes. This facilitates a continuous refinement of the node in the
search tree, thereby enhancing the overall decision-making process.Furthermore,
we integrate a Large Language Model (LLM)-based value model to facilitate
direct evaluation of each node's solution prior to conducting comprehensive
computational rollouts. A hybrid rewarding mechanism is implemented to
seamlessly transition the Q-value from LLM-estimated scores to actual
performance scores. This allows higher-quality nodes to be traversed
earlier.Applied to the various ML tasks, our approach demonstrates a6\%
absolute improvement in performance compared to the strong open-source AutoML
agents, showcasing its effectiveness in enhancing agentic AutoML systems.

摘要：大型語言模型 (LLM) 的最新進展已展現出自動化機器學習任務的顯著潛力。然而，現有的基於 LLM 的代理通常會遇到低多樣性和次優代碼生成的問題。雖然最近的工作已引入蒙地卡羅樹搜尋 (MCTS) 來解決這些問題，但仍存在於所產生想法的品質和多樣性，以及用於節點選擇的標量值回饋機制中。在本研究中，我們介紹了內省蒙地卡羅樹搜尋 (I-MCTS)，這是一種透過內省過程反覆擴展樹節點的新方法，該過程會細緻地分析來自父節點和同層節點的解決方案和結果。這有助於持續改善搜尋樹中的節點，進而增強整體決策制定過程。此外，我們整合了一個基於大型語言模型 (LLM) 的值模型，以便在進行全面運算展開之前直接評估每個節點的解決方案。實作了一種混合獎勵機制，以無縫地將 Q 值從 LLM 估計分數轉換為實際效能分數。這允許較高品質的節點更早被遍歷。應用於各種 ML 任務，我們的做法展示出比強大的開源 AutoML 代理高出 6% 的絕對效能提升，證明了其在增強代理式 AutoML 系統方面的有效性。

##### **Bridging the Gap: Transforming Natural Language Questions into SQL Queries via Abstract Query Pattern and Contextual Schema Markup**
2502.14682v1 by Yonghui Kong, Hongbing Hu, Dan Zhang, Siyuan Chai, Fan Zhang, Wei Wang

Large language models have demonstrated excellent performance in many tasks,
including Text-to-SQL, due to their powerful in-context learning capabilities.
They are becoming the mainstream approach for Text-to-SQL. However, these
methods still have a significant gap compared to human performance, especially
on complex questions. As the complexity of questions increases, the gap between
questions and SQLs increases. We identify two important gaps: the structural
mapping gap and the lexical mapping gap. To tackle these two gaps, we propose
PAS-SQL, an efficient SQL generation pipeline based on LLMs, which alleviates
gaps through Abstract Query Pattern (AQP) and Contextual Schema Markup (CSM).
AQP aims to obtain the structural pattern of the question by removing
database-related information, which enables us to find structurally similar
demonstrations. CSM aims to associate database-related text span in the
question with specific tables or columns in the database, which alleviates the
lexical mapping gap. Experimental results on the Spider and BIRD datasets
demonstrate the effectiveness of our proposed method. Specifically, PAS-SQL +
GPT-4o sets a new state-of-the-art on the Spider benchmark with an execution
accuracy of 87.9\%, and achieves leading results on the BIRD dataset with an
execution accuracy of 64.67\%.

摘要：大型語言模型在許多任務中表現出色，包括文字轉 SQL，這歸功於它們強大的情境學習能力。它們正成為文字轉 SQL 的主流方法。然而，這些方法與人類的表現仍有顯著差距，特別是在複雜的問題上。隨著問題的複雜性增加，問題和 SQL 之間的差距也隨之增加。我們找出兩個重要的差距：結構對應差距和詞彙對應差距。為了解決這兩個差距，我們提出 PAS-SQL，一種基於 LLM 的高效 SQL 產生管道，它透過抽象查詢模式 (AQP) 和情境架構標記 (CSM) 來縮小差距。AQP 旨在透過移除與資料庫相關的資訊來取得問題的結構模式，這使我們能夠找到結構上相似的範例。CSM 旨在將問題中與資料庫相關的文字範圍與資料庫中的特定表格或欄位關聯起來，這可以縮小詞彙對應差距。在 Spider 和 BIRD 資料集上的實驗結果證明了我們所提出的方法的有效性。具體來說，PAS-SQL + GPT-4o 在 Spider 基準測試中設定了一個新的技術水準，執行準確度為 87.9%，並在 BIRD 資料集上取得領先的結果，執行準確度為 64.67%。

##### **How to Get Your LLM to Generate Challenging Problems for Evaluation**
2502.14678v1 by Arkil Patel, Siva Reddy, Dzmitry Bahdanau

The pace of evolution of Large Language Models (LLMs) necessitates new
approaches for rigorous and comprehensive evaluation. Traditional human
annotation is increasingly impracticable due to the complexities and costs
involved in generating high-quality, challenging problems. In this work, we
introduce CHASE, a unified framework to synthetically generate challenging
problems using LLMs without human involvement. For a given task, our approach
builds a hard problem in a bottom-up manner from simpler components. Moreover,
our framework decomposes the generation process into independently verifiable
sub-tasks, thereby ensuring a high level of quality and correctness. We
implement CHASE to create evaluation benchmarks across three diverse domains:
(1) document-based question answering, (2) repository-level code completion,
and (3) math reasoning. The performance of state-of-the-art LLMs on these
synthetic benchmarks lies in the range of 40-60% accuracy, thereby
demonstrating the effectiveness of our framework at generating challenging
problems. We publicly release our benchmarks and code.

摘要：大型語言模型 (LLM) 的演化速度需要新的方法來進行嚴謹且全面的評估。由於產生高品質、具挑戰性的問題所涉及的複雜性和成本，傳統的人工標註正變得越來越不可行。在這項工作中，我們介紹了 CHASE，一個統一的框架，用於使用 LLM 合成產生具有挑戰性的問題，而無需人工參與。對於給定的任務，我們的做法是以自下而上的方式從更簡單的組成部分來建立一個困難的問題。此外，我們的框架將生成過程分解為獨立可驗證的子任務，從而確保高品質和正確性。我們實作 CHASE 來建立三個不同領域的評估基準：(1) 基於文件的問答、(2) 儲存庫層級的程式碼完成，以及 (3) 數學推理。最先進的 LLM 在這些合成基準上的效能落在 40-60% 的準確度範圍內，從而證明了我們的框架在產生具有挑戰性的問題上的有效性。我們公開發布我們的基準和程式碼。

##### **Data-Constrained Synthesis of Training Data for De-Identification**
2502.14677v1 by Thomas Vakili, Aron Henriksson, Hercules Dalianis

Many sensitive domains -- such as the clinical domain -- lack widely
available datasets due to privacy risks. The increasing generative capabilities
of large language models (LLMs) have made synthetic datasets a viable path
forward. In this study, we domain-adapt LLMs to the clinical domain and
generate synthetic clinical texts that are machine-annotated with tags for
personally identifiable information using capable encoder-based NER models. The
synthetic corpora are then used to train synthetic NER models. The results show
that training NER models using synthetic corpora incurs only a small drop in
predictive performance. The limits of this process are investigated in a
systematic ablation study -- using both Swedish and Spanish data. Our analysis
shows that smaller datasets can be sufficient for domain-adapting LLMs for data
synthesis. Instead, the effectiveness of this process is almost entirely
contingent on the performance of the machine-annotating NER models trained
using the original data.

摘要：許多敏感領域（例如臨床領域）由於隱私風險而缺乏廣泛可用的資料集。大型語言模型 (LLM) 不斷增強的生成能力已使合成資料集成為可行的途徑。在這項研究中，我們將領域適應 LLM 應用於臨床領域，並生成使用具備編碼器功能的 NER 模型以個人可識別資訊標籤進行機器標註的合成臨床文本。然後使用合成語料庫來訓練合成 NER 模型。結果顯示，使用合成語料庫訓練 NER 模型僅會導致預測效能略微下降。在系統消融研究中調查此程序的限制，同時使用瑞典語和西班牙語資料。我們的分析顯示，較小的資料集足以用於領域適應 LLM 以進行資料合成。相反地，此程序的有效性幾乎完全取決於使用原始資料訓練的機器標註 NER 模型的效能。

##### **BP-SGCN: Behavioral Pseudo-Label Informed Sparse Graph Convolution Network for Pedestrian and Heterogeneous Trajectory Prediction**
2502.14676v1 by Ruochen Li, Stamos Katsigiannis, Tae-Kyun Kim, Hubert P. H. Shum

Trajectory prediction allows better decision-making in applications of
autonomous vehicles or surveillance by predicting the short-term future
movement of traffic agents. It is classified into pedestrian or heterogeneous
trajectory prediction. The former exploits the relatively consistent behavior
of pedestrians, but is limited in real-world scenarios with heterogeneous
traffic agents such as cyclists and vehicles. The latter typically relies on
extra class label information to distinguish the heterogeneous agents, but such
labels are costly to annotate and cannot be generalized to represent different
behaviors within the same class of agents. In this work, we introduce the
behavioral pseudo-labels that effectively capture the behavior distributions of
pedestrians and heterogeneous agents solely based on their motion features,
significantly improving the accuracy of trajectory prediction. To implement the
framework, we propose the Behavioral Pseudo-Label Informed Sparse Graph
Convolution Network (BP-SGCN) that learns pseudo-labels and informs to a
trajectory predictor. For optimization, we propose a cascaded training scheme,
in which we first learn the pseudo-labels in an unsupervised manner, and then
perform end-to-end fine-tuning on the labels in the direction of increasing the
trajectory prediction accuracy. Experiments show that our pseudo-labels
effectively model different behavior clusters and improve trajectory
prediction. Our proposed BP-SGCN outperforms existing methods using both
pedestrian (ETH/UCY, pedestrian-only SDD) and heterogeneous agent datasets
(SDD, Argoverse 1).

摘要：軌跡預測允許在自動駕駛車輛或監視應用中做出更好的決策，藉由預測交通代理的短期未來移動。它被分類為行人或異質軌跡預測。前者利用行人相對一致的行為，但受限於與自行車騎士和車輛等異質交通代理的真實世界場景。後者通常依賴額外的類別標籤資訊來區分異質代理，但此類標籤的註解成本很高，且無法概括為表示同一類別代理中的不同行為。在這項工作中，我們引入了行為偽標籤，它僅根據行人和異質代理的運動特徵有效捕捉行為分佈，顯著提升軌跡預測的準確度。為實作架構，我們提出了行為偽標籤告知稀疏圖形卷積網路 (BP-SGCN)，它學習偽標籤並告知軌跡預測器。針對最佳化，我們提出了一種串聯訓練方案，其中我們首先以非監督的方式學習偽標籤，然後在標籤上執行端到端微調，朝著提升軌跡預測準確度的方向進行。實驗顯示我們的偽標籤有效建模不同的行為叢集，並提升軌跡預測。我們提出的 BP-SGCN 使用行人 (ETH/UCY，僅限行人的 SDD) 和異質代理資料集 (SDD，Argoverse 1) 都優於現有方法。

##### **Explanations of Deep Language Models Explain Language Representations in the Brain**
2502.14671v1 by Maryam Rahimi, Yadollah Yaghoobzadeh, Mohammad Reza Daliri

Recent advances in artificial intelligence have given rise to large language
models (LLMs) that not only achieve human-like performance but also share
computational principles with the brain's language processing mechanisms. While
previous research has primarily focused on aligning LLMs' internal
representations with neural activity, we introduce a novel approach that
leverages explainable AI (XAI) methods to forge deeper connections between the
two domains. Using attribution methods, we quantified how preceding words
contribute to an LLM's next-word predictions and employed these explanations to
predict fMRI recordings from participants listening to the same narratives. Our
findings demonstrate that attribution methods robustly predict brain activity
across the language network, surpassing traditional internal representations in
early language areas. This alignment is hierarchical: early-layer explanations
correspond to the initial stages of language processing in the brain, while
later layers align with more advanced stages. Moreover, the layers more
influential on LLM next-word prediction$\unicode{x2014}$those with higher
attribution scores$\unicode{x2014}$exhibited stronger alignment with neural
activity. This work establishes a bidirectional bridge between AI and
neuroscience. First, we demonstrate that attribution methods offer a powerful
lens for investigating the neural mechanisms of language comprehension,
revealing how meaning emerges from preceding context. Second, we propose using
brain alignment as a metric to evaluate the validity of attribution methods,
providing a framework for assessing their biological plausibility.

摘要：最近的人工智能的進展產生了大型語言模型 (LLM)，它不僅達到類似人類的表現，還與大腦的語言處理機制共享計算原理。雖然先前的研究主要集中於將 LLM 的內部表徵與神經活動對齊，但我們引入了一種新穎的方法，該方法利用可解釋 AI (XAI) 方法在兩個域之間建立更深層的聯繫。使用歸因方法，我們量化了前一個單詞如何促成 LLM 的下一個單詞預測，並利用這些解釋來預測參與者在聆聽相同敘述時的大腦功能性磁共振造影 (fMRI) 記錄。我們的發現表明，歸因方法可以穩健地預測整個語言網路中的大腦活動，超越了早期語言區域中的傳統內部表徵。這種對齊是分層的：早期層次解釋對應於大腦中語言處理的初始階段，而後續層次則與更進階的階段對齊。此外，對 LLM 下一個單詞預測影響力較大的層次（即歸因分數較高的層次）表現出與神經活動更強的對齊。這項工作在 AI 與神經科學之間建立了一個雙向橋樑。首先，我們證明歸因方法提供了一個強大的視角，用於研究語言理解的神經機制，揭示意義如何從先前的脈絡中產生。其次，我們建議使用大腦對齊作為評估歸因方法有效性的指標，提供了一個評估其生物學合理性的框架。

##### **AlphaMaze: Enhancing Large Language Models' Spatial Intelligence via GRPO**
2502.14669v1 by Alan Dao, Dinh Bach Vu

Large Language Models (LLMs) have demonstrated impressive capabilities in
language processing, yet they often struggle with tasks requiring genuine
visual spatial reasoning. In this paper, we introduce a novel two-stage
training framework designed to equip standard LLMs with visual reasoning
abilities for maze navigation. First, we leverage Supervised Fine Tuning (SFT)
on a curated dataset of tokenized maze representations to teach the model to
predict step-by-step movement commands. Next, we apply Group Relative Policy
Optimization (GRPO)-a technique used in DeepSeekR1-with a carefully crafted
reward function to refine the model's sequential decision-making and encourage
emergent chain-of-thought behaviors. Experimental results on synthetically
generated mazes show that while a baseline model fails to navigate the maze,
the SFT-trained model achieves 86% accuracy, and further GRPO fine-tuning
boosts accuracy to 93%. Qualitative analyses reveal that GRPO fosters more
robust and self-corrective reasoning, highlighting the potential of our
approach to bridge the gap between language models and visual spatial tasks.
These findings offer promising implications for applications in robotics,
autonomous navigation, and other domains that require integrated visual and
sequential reasoning.

摘要：大型語言模型（LLM）在語言處理方面展現出令人印象深刻的能力，但它們經常難以應付需要真正視覺空間推理的任務。在本文中，我們介紹了一種新穎的兩階段訓練架構，旨在為標準 LLM 提供迷宮導航的視覺推理能力。首先，我們在標記化迷宮表示的策展資料集上利用監督微調（SFT）來教導模型預測逐步移動指令。接下來，我們使用 DeepSeekR1 中使用的技術，即群體相對策略最佳化（GRPO），並搭配精心設計的獎勵函數來優化模型的順序決策制定，並鼓勵出現連貫的思考行為。在合成產生的迷宮上進行的實驗結果顯示，雖然基準模型無法導航迷宮，但經過 SFT 訓練的模型達到 86% 的準確度，而進一步的 GRPO 微調將準確度提升至 93%。定性分析顯示，GRPO 促進更強健且自我修正的推理，凸顯了我們的方法在彌合語言模型與視覺空間任務之間差距的潛力。這些發現為機器人、自主導航和其他需要整合視覺和順序推理的領域的應用提供了有希望的啟示。

##### **InstructAgent: Building User Controllable Recommender via LLM Agent**
2502.14662v1 by Wujiang Xu, Yunxiao Shi, Zujie Liang, Xuying Ning, Kai Mei, Kun Wang, Xi Zhu, Min Xu, Yongfeng Zhang

Traditional recommender systems usually take the user-platform paradigm,
where users are directly exposed under the control of the platform's
recommendation algorithms. However, the defect of recommendation algorithms may
put users in very vulnerable positions under this paradigm. First, many
sophisticated models are often designed with commercial objectives in mind,
focusing on the platform's benefits, which may hinder their ability to protect
and capture users' true interests. Second, these models are typically optimized
using data from all users, which may overlook individual user's preferences.
Due to these shortcomings, users may experience several disadvantages under the
traditional user-platform direct exposure paradigm, such as lack of control
over the recommender system, potential manipulation by the platform, echo
chamber effects, or lack of personalization for less active users due to the
dominance of active users during collaborative learning. Therefore, there is an
urgent need to develop a new paradigm to protect user interests and alleviate
these issues. Recently, some researchers have introduced LLM agents to simulate
user behaviors, these approaches primarily aim to optimize platform-side
performance, leaving core issues in recommender systems unresolved. To address
these limitations, we propose a new user-agent-platform paradigm, where agent
serves as the protective shield between user and recommender system that
enables indirect exposure. To this end, we first construct four recommendation
datasets, denoted as $\dataset$, along with user instructions for each record.

摘要：傳統推薦系統通常採用使用者-平台範例，
其中使用者直接暴露在平台推薦演算法的控制之下。然而，推薦演算法的缺陷可能會讓使用者在這個範例中處於非常脆弱的位置。首先，許多精密的模型通常在設計時就考慮到商業目標，專注於平台的利益，這可能會阻礙它們保護和掌握使用者真正興趣的能力。其次，這些模型通常使用所有使用者的資料進行最佳化，這可能會忽略個別使用者的偏好。由於這些缺點，使用者可能會在傳統使用者-平台直接暴露範例中遇到一些缺點，例如缺乏對推薦系統的控制、平台的潛在操縱、同溫層效應，或由於活躍使用者在協作學習中的主導地位而缺乏針對較不活躍使用者的個人化。因此，迫切需要開發一種新的範例來保護使用者利益並緩解這些問題。最近，一些研究人員引入了 LLM 代理程式來模擬使用者行為，這些方法主要旨在最佳化平台端的效能，而未解決推薦系統中的核心問題。為了解決這些限制，我們提出了一種新的使用者-代理程式-平台範例，其中代理程式作為使用者和推薦系統之間的保護盾，實現間接暴露。為此，我們首先構建了四個推薦資料集，表示為 $\dataset$，以及每條記錄的使用者說明。

##### **Edit Once, Update Everywhere: A Simple Framework for Cross-Lingual Knowledge Synchronization in LLMs**
2502.14645v1 by Yuchen Wu, Liang Ding, Li Shen, Dacheng Tao

Knowledge editing allows for efficient adaptation of large language models
(LLMs) to new information or corrections without requiring full retraining.
However, prior methods typically focus on either single-language editing or
basic multilingual editing, failing to achieve true cross-linguistic knowledge
synchronization. To address this, we present a simple and practical
state-of-the-art (SOTA) recipe Cross-Lingual Knowledge Democracy Edit (X-KDE),
designed to propagate knowledge from a dominant language to other languages
effectively. Our X-KDE comprises two stages: (i) Cross-lingual Edition
Instruction Tuning (XE-IT), which fine-tunes the model on a curated parallel
dataset to modify in-scope knowledge while preserving unrelated information,
and (ii) Target-language Preference Optimization (TL-PO), which applies
advanced optimization techniques to ensure consistency across languages,
fostering the transfer of updates. Additionally, we contribute a high-quality,
cross-lingual dataset, specifically designed to enhance knowledge transfer
across languages. Extensive experiments on the Bi-ZsRE and MzsRE benchmarks
show that X-KDE significantly enhances cross-lingual performance, achieving an
average improvement of +8.19%, while maintaining high accuracy in monolingual
settings.

摘要：知識編輯允許大語言模型 (LLM) 有效地適應新資訊或修正，而無需進行完整的再訓練。
然而，先前的做法通常專注於單一語言編輯或基本的語音編輯，未能實現真正的跨語言知識同步。為了解決這個問題，我們提出了一個簡單且實用的最先進 (SOTA) 配方，即跨語言知識民主編輯 (X-KDE)，旨在有效地從主導語言傳播知識到其他語言。我們的 X-KDE 包含兩個階段：(i) 跨語言版本指令調整 (XE-IT)，它微調模型，在經過整理的平行資料集上修改範圍內的知識，同時保留不相關的資訊，以及 (ii) 目標語言偏好最佳化 (TL-PO)，它應用先進的最佳化技術，以確保跨語言的一致性，促進更新的傳輸。此外，我們貢獻了一個高品質的跨語言資料集，特別設計用於增強跨語言的知識傳輸。在 Bi-ZsRE 和 MzsRE 基準上的廣泛實驗表明，X-KDE 大幅提升了跨語言效能，在單語言設定中維持高準確度的同時，平均提升了 +8.19%。

##### **LIFT: Improving Long Context Understanding of Large Language Models through Long Input Fine-Tuning**
2502.14644v1 by Yansheng Mao, Yufei Xu, Jiaqi Li, Fanxu Meng, Haotong Yang, Zilong Zheng, Xiyuan Wang, Muhan Zhang

Long context understanding remains challenging for large language models due
to their limited context windows. This paper presents Long Input Fine-Tuning
(LIFT), a novel framework for long-context modeling that can improve the
long-context performance of arbitrary (short-context) LLMs by dynamically
adapting model parameters based on the long input. Importantly, LIFT, rather
than endlessly extending the context window size to accommodate increasingly
longer inputs in context, chooses to store and absorb the long input in
parameter. By fine-tuning the long input into model parameters, LIFT allows
short-context LLMs to answer questions even when the required information is
not provided in the context during inference. Furthermore, to enhance LIFT
performance while maintaining the original in-context learning (ICL)
capabilities, we introduce Gated Memory, a specialized attention adapter that
automatically balances long input memorization and ICL. We provide a
comprehensive analysis of the strengths and limitations of LIFT on long context
understanding, offering valuable directions for future research.

摘要：由於大型語言模型的上下文視窗有限，因此對於它們而言，長語境理解仍然具有挑戰性。本文提出了長輸入微調 (LIFT)，這是一個用於長語境建模的新穎架構，它可以通過根據長輸入動態調整模型參數來改善任意（短語境）LLM 的長語境效能。重要的是，LIFT 沒有無限擴充上下文視窗大小以容納語境中越來越長的輸入，而是選擇將長輸入儲存在參數中並吸收它。通過將長輸入微調到模型參數中，LIFT 允許短語境 LLM 回答問題，即使在推理期間語境中沒有提供所需資訊也是如此。此外，為了在保持原始語境中學習 (ICL) 能力的同時增強 LIFT 效能，我們引入了閘控記憶體，這是一個自動平衡長輸入記憶和 ICL 的特殊注意力適配器。我們對 LIFT 在長語境理解方面的優缺點進行了全面的分析，為未來的研究提供了有價值的方向。

##### **Length-Controlled Margin-Based Preference Optimization without Reference Model**
2502.14643v1 by Gengxu Li, Tingyu Xia, Yi Chang, Yuan Wu

Direct Preference Optimization (DPO) is a widely adopted offline algorithm
for preference-based reinforcement learning from human feedback (RLHF),
designed to improve training simplicity and stability by redefining reward
functions. However, DPO is hindered by several limitations, including length
bias, memory inefficiency, and probability degradation. To address these
challenges, we propose Length-Controlled Margin-Based Preference Optimization
(LMPO), a more efficient and robust alternative. LMPO introduces a uniform
reference model as an upper bound for the DPO loss, enabling a more accurate
approximation of the original optimization objective. Additionally, an average
log-probability optimization strategy is employed to minimize discrepancies
between training and inference phases. A key innovation of LMPO lies in its
Length-Controlled Margin-Based loss function, integrated within the
Bradley-Terry framework. This loss function regulates response length while
simultaneously widening the margin between preferred and rejected outputs. By
doing so, it mitigates probability degradation for both accepted and discarded
responses, addressing a significant limitation of existing methods. We evaluate
LMPO against state-of-the-art preference optimization techniques on two
open-ended large language models, Mistral and LLaMA3, across six conditional
benchmarks. Our experimental results demonstrate that LMPO effectively controls
response length, reduces probability degradation, and outperforms existing
approaches. The code is available at \url{https://github.com/gengxuli/LMPO}.

摘要：直接偏好優化 (DPO) 是一種廣泛採用的離線演算法，用於從人類回饋 (RLHF) 中進行基於偏好的強化學習，旨在透過重新定義獎勵函數來提升訓練的簡潔性和穩定性。然而，DPO 受到若干限制的阻礙，包括長度偏差、記憶體效率低下和機率下降。為了解決這些挑戰，我們提出長度控制邊際偏好優化 (LMPO)，一種更有效率且穩健的替代方案。LMPO 引入統一參考模型作為 DPO 損失的上限，能夠更準確地近似原始最佳化目標。此外，採用平均對數機率最佳化策略來最小化訓練和推論階段之間的差異。LMPO 的一項關鍵創新在於其長度控制邊際損失函數，整合在 Bradley-Terry 架構中。此損失函數調節回應長度，同時擴大偏好和拒絕輸出之間的邊際。藉由這麼做，它減輕了已接受和已捨棄回應的機率下降，解決了現有方法的重大限制。我們在兩個開放式大型語言模型 Mistral 和 LLaMA3 上，針對六個條件基準，評估 LMPO 與最先進的偏好優化技術。我們的實驗結果證明，LMPO 有效控制回應長度，減少機率下降，並優於現有方法。程式碼可在 \url{https://github.com/gengxuli/LMPO} 取得。

##### **How Far are LLMs from Being Our Digital Twins? A Benchmark for Persona-Based Behavior Chain Simulation**
2502.14642v1 by Rui Li, Heming Xia, Xinfeng Yuan, Qingxiu Dong, Lei Sha, Wenjie Li, Zhifang Sui

Recently, LLMs have garnered increasing attention across academic disciplines
for their potential as human digital twins, virtual proxies designed to
replicate individuals and autonomously perform tasks such as decision-making,
problem-solving, and reasoning on their behalf. However, current evaluations of
LLMs primarily emphasize dialogue simulation while overlooking human behavior
simulation, which is crucial for digital twins. To address this gap, we
introduce BehaviorChain, the first benchmark for evaluating LLMs' ability to
simulate continuous human behavior. BehaviorChain comprises diverse,
high-quality, persona-based behavior chains, totaling 15,846 distinct behaviors
across 1,001 unique personas, each with detailed history and profile metadata.
For evaluation, we integrate persona metadata into LLMs and employ them to
iteratively infer contextually appropriate behaviors within dynamic scenarios
provided by BehaviorChain. Comprehensive evaluation results demonstrated that
even state-of-the-art models struggle with accurately simulating continuous
human behavior.

摘要：最近，LLM 在各個學科中備受關注，因為它們具有作為人類數位雙胞胎的潛力，也就是虛擬代理人，旨在複製個人並自主執行任務，例如代表他們進行決策、解決問題和推理。然而，LLM 目前的評估主要強調對話模擬，同時忽視了人類行為模擬，這對數位雙胞胎至關重要。為了解決這個差距，我們引入了 BehaviorChain，這是第一個用於評估 LLM 模擬連續人類行為能力的基準。BehaviorChain 包含多樣化、高品質、基於角色的行為鏈，總共涵蓋 1,001 個獨特角色的 15,846 種不同行為，每個角色都有詳細的歷史和個人資料元數據。在評估中，我們將角色元數據整合到 LLM 中，並使用它們在 BehaviorChain 提供的動態場景中反覆推斷出在情境中適當的行為。全面的評估結果表明，即使是最先進的模型在準確模擬連續人類行為方面也存在困難。

##### **NAVIG: Natural Language-guided Analysis with Vision Language Models for Image Geo-localization**
2502.14638v1 by Zheyuan Zhang, Runze Li, Tasnim Kabir, Jordan Boyd-Graber

Image geo-localization is the task of predicting the specific location of an
image and requires complex reasoning across visual, geographical, and cultural
contexts. While prior Vision Language Models (VLMs) have the best accuracy at
this task, there is a dearth of high-quality datasets and models for analytical
reasoning. We first create NaviClues, a high-quality dataset derived from
GeoGuessr, a popular geography game, to supply examples of expert reasoning
from language. Using this dataset, we present Navig, a comprehensive image
geo-localization framework integrating global and fine-grained image
information. By reasoning with language, Navig reduces the average distance
error by 14% compared to previous state-of-the-art models while requiring fewer
than 1000 training samples. Our dataset and code are available at
https://github.com/SparrowZheyuan18/Navig/.

摘要：影像地理定位是預測影像特定位置的任務，需要跨視覺、地理和文化脈絡進行複雜的推理。雖然先前的視覺語言模型 (VLM) 在此任務中擁有最佳準確度，但缺乏高品質的資料集和分析推理模型。我們首先建立 NaviClues，這是一個源自 GeoGuessr 的高品質資料集，GeoGuessr 是一款流行的地理遊戲，可提供來自語言的專家推理範例。使用此資料集，我們提出 Navig，這是一個綜合性的影像地理定位架構，整合了全球和細緻的影像資訊。透過語言推理，Navig 將平均距離誤差減少了 14%，與先前的最先進模型相比，同時只需要不到 1000 個訓練樣本。我們的資料集和程式碼可在 https://github.com/SparrowZheyuan18/Navig/ 取得。

##### **ReQFlow: Rectified Quaternion Flow for Efficient and High-Quality Protein Backbone Generation**
2502.14637v1 by Angxiao Yue, Zichong Wang, Hongteng Xu

Protein backbone generation plays a central role in de novo protein design
and is significant for many biological and medical applications. Although
diffusion and flow-based generative models provide potential solutions to this
challenging task, they often generate proteins with undesired designability and
suffer computational inefficiency. In this study, we propose a novel rectified
quaternion flow (ReQFlow) matching method for fast and high-quality protein
backbone generation. In particular, our method generates a local translation
and a 3D rotation from random noise for each residue in a protein chain, which
represents each 3D rotation as a unit quaternion and constructs its flow by
spherical linear interpolation (SLERP) in an exponential format. We train the
model by quaternion flow (QFlow) matching with guaranteed numerical stability
and rectify the QFlow model to accelerate its inference and improve the
designability of generated protein backbones, leading to the proposed ReQFlow
model. Experiments show that ReQFlow achieves state-of-the-art performance in
protein backbone generation while requiring much fewer sampling steps and
significantly less inference time (e.g., being 37x faster than RFDiffusion and
62x faster than Genie2 when generating a backbone of length 300), demonstrating
its effectiveness and efficiency. The code is available at
https://github.com/AngxiaoYue/ReQFlow.

摘要：蛋白骨架生成在從頭蛋白質設計中扮演核心角色，且對於許多生物和醫學應用來說意義重大。儘管擴散和基於流的生成模型提供了解決此項挑戰性任務的潛在方案，但它們經常生成具有不受歡迎的可設計性的蛋白質，且遭受運算效率不彰之苦。在本研究中，我們提出了一種新穎的修正四元數流 (ReQFlow) 匹配方法，用於快速且高品質的蛋白質骨架生成。特別是，我們的模型會為蛋白質鏈中的每個殘基從隨機雜訊中生成一個局部平移和一個 3D 旋轉，將每個 3D 旋轉表示為單位四元數，並以指數格式透過球面線性插值 (SLERP) 建構其流。我們透過四元數流 (QFlow) 匹配訓練模型，並保證數值穩定性，並修正 QFlow 模型以加速其推論並改善生成蛋白質骨架的可設計性，進而提出建議的 ReQFlow 模型。實驗顯示，ReQFlow 在蛋白質骨架生成中達成最先進的效能，同時所需採樣步驟少得多，且推論時間大幅減少（例如，在生成長度為 300 的骨架時比 RFDiffusion 快 37 倍，比 Genie2 快 62 倍），證明其有效性和效率。程式碼可在 https://github.com/AngxiaoYue/ReQFlow 取得。

##### **PEARL: Towards Permutation-Resilient LLMs**
2502.14628v1 by Liang Chen, Li Shen, Yang Deng, Xiaoyan Zhao, Bin Liang, Kam-Fai Wong

The in-context learning (ICL) capability of large language models (LLMs)
enables them to perform challenging tasks using provided demonstrations.
However, ICL is highly sensitive to the ordering of demonstrations, leading to
instability in predictions. This paper shows that this vulnerability can be
exploited to design a natural attack - difficult for model providers to detect
- that achieves nearly 80% success rate on LLaMA-3 by simply permuting the
demonstrations. Existing mitigation methods primarily rely on post-processing
and fail to enhance the model's inherent robustness to input permutations,
raising concerns about safety and reliability of LLMs. To address this issue,
we propose Permutation-resilient learning (PEARL), a novel framework based on
distributionally robust optimization (DRO), which optimizes model performance
against the worst-case input permutation. Specifically, PEARL consists of a
permutation-proposal network (P-Net) and the LLM. The P-Net generates the most
challenging permutations by treating it as an optimal transport problem, which
is solved using an entropy-constrained Sinkhorn algorithm. Through minimax
optimization, the P-Net and the LLM iteratively optimize against each other,
progressively improving the LLM's robustness. Experiments on synthetic
pre-training and real-world instruction tuning tasks demonstrate that PEARL
effectively mitigates permutation attacks and enhances performance. Notably,
despite being trained on fewer shots and shorter contexts, PEARL achieves
performance gains of up to 40% when scaled to many-shot and long-context
scenarios, highlighting its efficiency and generalization capabilities.

摘要：大型語言模型 (LLM) 的語境學習 (ICL) 能力使其能夠透過提供的示範來執行具有挑戰性的任務。然而，ICL 對示範的排序非常敏感，導致預測不穩定。本文顯示，可以利用此漏洞來設計一種自然攻擊，讓模型提供者難以偵測，透過簡單地排列示範，在 LLaMA-3 上達到近 80% 的成功率。現有的緩解方法主要依賴後處理，且無法增強模型對輸入排列的固有穩健性，引發了對 LLM 的安全性與可靠性的疑慮。為了解決此問題，我們提出了一種基於分配穩健最佳化 (DRO) 的新型架構，稱為排列彈性學習 (PEARL)，它針對最差情況的輸入排列來最佳化模型效能。具體來說，PEARL 包含排列建議網路 (P-Net) 和 LLM。P-Net 將其視為最優傳輸問題來產生最具挑戰性的排列，並使用熵約束 Sinkhorn 演算法來解決。透過極小極大最佳化，P-Net 和 LLM 迭代地相互最佳化，逐步改善 LLM 的穩健性。在合成預訓練和真實世界指令調整任務上的實驗證明，PEARL 有效地減輕了排列攻擊並增強了效能。值得注意的是，儘管在較少的次數和較短的語境中進行訓練，但 PEARL 在擴展到多重次數和長語境場景時仍可獲得高達 40% 的效能提升，突顯了其效率和泛化能力。

##### **ATRI: Mitigating Multilingual Audio Text Retrieval Inconsistencies by Reducing Data Distribution Errors**
2502.14627v1 by Yuguo Yin, Yuxin Xie, Wenyuan Yang, Dongchao Yang, Jinghan Ru, Xianwei Zhuang, Liming Liang, Yuexian Zou

Multilingual audio-text retrieval (ML-ATR) is a challenging task that aims to
retrieve audio clips or multilingual texts from databases. However, existing
ML-ATR schemes suffer from inconsistencies for instance similarity matching
across languages. We theoretically analyze the inconsistency in terms of both
multilingual modal alignment direction error and weight error, and propose the
theoretical weight error upper bound for quantifying the inconsistency. Based
on the analysis of the weight error upper bound, we find that the inconsistency
problem stems from the data distribution error caused by random sampling of
languages. We propose a consistent ML-ATR scheme using 1-to-k contrastive
learning and audio-English co-anchor contrastive learning, aiming to mitigate
the negative impact of data distribution error on recall and consistency in
ML-ATR. Experimental results on the translated AudioCaps and Clotho datasets
show that our scheme achieves state-of-the-art performance on recall and
consistency metrics for eight mainstream languages, including English. Our code
will be available at https://github.com/ATRI-ACL/ATRI-ACL.

摘要：多模態多語言音訊文字檢索 (ML-ATR) 是一項具有挑戰性的任務，旨在從資料庫中檢索音訊片段或多語言文字。然而，現有的 ML-ATR 架構存在不一致的情況，例如跨語言的相似性比對。我們在理論上分析了不一致性，包括多模態多語言對齊方向誤差和權重誤差，並提出理論權重誤差上限以量化不一致性。根據權重誤差上限的分析，我們發現不一致性問題源於由語言隨機取樣造成的資料分佈誤差。我們提出一個一致的 ML-ATR 架構，採用 1 對 k 對比學習和音訊-英語共同錨點對比學習，旨在減輕資料分佈誤差對 ML-ATR 中召回率和一致性的負面影響。在已翻譯的 AudioCaps 和 Clotho 資料集上的實驗結果顯示，我們的架構在包括英語在內的八種主流語言的召回率和一致性指標上達到了最先進的效能。我們的程式碼將在 https://github.com/ATRI-ACL/ATRI-ACL 中提供。

##### **Multi-Record Web Page Information Extraction From News Websites**
2502.14625v1 by Alexander Kustenkov, Maksim Varlamov, Alexander Yatskov

In this paper, we focused on the problem of extracting information from web
pages containing many records, a task of growing importance in the era of
massive web data. Recently, the development of neural network methods has
improved the quality of information extraction from web pages. Nevertheless,
most of the research and datasets are aimed at studying detailed pages. This
has left multi-record "list pages" relatively understudied, despite their
widespread presence and practical significance.
  To address this gap, we created a large-scale, open-access dataset
specifically designed for list pages. This is the first dataset for this task
in the Russian language. Our dataset contains 13,120 web pages with news lists,
significantly exceeding existing datasets in both scale and complexity. Our
dataset contains attributes of various types, including optional and
multi-valued, providing a realistic representation of real-world list pages.
These features make our dataset a valuable resource for studying information
extraction from pages containing many records.
  Furthermore, we proposed our own multi-stage information extraction methods.
In this work, we explore and demonstrate several strategies for applying
MarkupLM to the specific challenges of multi-record web pages. Our experiments
validate the advantages of our methods.
  By releasing our dataset to the public, we aim to advance the field of
information extraction from multi-record pages.

摘要：<paragraph>在本文中，我們專注於從包含大量記錄的網頁中提取資訊的問題，這項任務在海量網路資料的時代中越來越重要。最近，神經網路方法的發展已改善從網頁中提取資訊的品質。儘管如此，大多數的研究和資料集都旨在研究詳細的網頁。儘管多記錄「清單網頁」廣泛存在且具有實用意義，但它們相對來說研究較少。
為了解決這個差距，我們建立了一個專門針對清單網頁設計的大規模、開放存取的資料集。這是俄語中第一個針對此任務的資料集。我們的資料集包含 13,120 個包含新聞清單的網頁，在規模和複雜度上都遠遠超過現有的資料集。我們的資料集包含各種類型的屬性，包括可選和多值，提供真實世界清單網頁的實際表示。這些特點使我們的資料集成為研究從包含大量記錄的網頁中提取資訊的寶貴資源。
此外，我們提出了我們自己的多階段資訊提取方法。在這項工作中，我們探討並展示了將 MarkupLM 應用於多記錄網頁特定挑戰的幾種策略。我們的實驗驗證了我們方法的優點。
透過向公眾發布我們的資料集，我們旨在推進從多記錄網頁中提取資訊的領域。</paragraph>

##### **Exploring RWKV for Sentence Embeddings: Layer-wise Analysis and Baseline Comparison for Semantic Similarity**
2502.14620v1 by Xinghan Pan

This paper investigates the efficacy of RWKV, a novel language model
architecture known for its linear attention mechanism, for generating sentence
embeddings in a zero-shot setting. I conduct a layer-wise analysis to evaluate
the semantic similarity captured by embeddings from different hidden layers of
a pre-trained RWKV model. The performance is assessed on the Microsoft Research
Paraphrase Corpus (MRPC) dataset using Spearman correlation and compared
against a GloVe-based baseline. My results indicate that while RWKV embeddings
capture some semantic relatedness, they underperform compared to the GloVe
baseline in terms of Spearman correlation. I also analyze the inference time
and GPU memory usage, highlighting the computational trade-offs associated with
RWKV embeddings. The findings suggest that while RWKV offers potential
advantages in terms of linear scaling, its zero-shot sentence embedding quality
for semantic similarity tasks requires further investigation and potential
task-specific fine-tuning to match or exceed simpler baselines.

摘要：本文探討 RWKV 的效能，這是一種以線性注意力機制聞名的語言模型架構，可用於在零次學習設定中產生句子嵌入。我進行逐層分析，以評估預先訓練的 RWKV 模型中不同隱藏層的嵌入所擷取的語義相似性。效能評估使用 Microsoft Research Paraphrase Corpus (MRPC) 資料集，採用 Spearman 相關係數，並與基於 GloVe 的基準進行比較。我的結果顯示，雖然 RWKV 嵌入可以擷取一些語義相關性，但與 GloVe 基準相比，在 Spearman 相關係數方面表現不佳。我也分析了推論時間和 GPU 記憶體使用量，強調與 RWKV 嵌入相關的運算折衷。這些發現表明，雖然 RWKV 在線性縮放方面具有潛在優勢，但其在語義相似性任務中的零次學習句子嵌入品質需要進一步探討，並需要潛在的特定任務微調，才能達到或超越較簡單的基準。

##### **Reward Models Identify Consistency, Not Causality**
2502.14619v1 by Yuhui Xu, Hanze Dong, Lei Wang, Caiming Xiong, Junnan Li

Reward models (RMs) play a crucial role in aligning large language models
(LLMs) with human preferences and enhancing reasoning quality. Traditionally,
RMs are trained to rank candidate outputs based on their correctness and
coherence. However, in this work, we present several surprising findings that
challenge common assumptions about RM behavior. Our analysis reveals that
state-of-the-art reward models prioritize structural consistency over causal
correctness. Specifically, removing the problem statement has minimal impact on
reward scores, whereas altering numerical values or disrupting the reasoning
flow significantly affects RM outputs. Furthermore, RMs exhibit a strong
dependence on complete reasoning trajectories truncated or incomplete steps
lead to significant variations in reward assignments, indicating that RMs
primarily rely on learned reasoning patterns rather than explicit problem
comprehension. These findings hold across multiple architectures, datasets, and
tasks, leading to three key insights: (1) RMs primarily assess coherence rather
than true reasoning quality; (2) The role of explicit problem comprehension in
reward assignment is overstated; (3) Current RMs may be more effective at
ranking responses than verifying logical validity. Our results suggest a
fundamental limitation in existing reward modeling approaches, emphasizing the
need for a shift toward causality-aware reward models that go beyond
consistency-driven evaluation.

摘要：獎勵模型 (RM) 在將大型語言模型 (LLM) 與人類偏好對齊並提升推理品質方面扮演至關重要的角色。傳統上，RM 會訓練來根據候選輸出的正確性和一致性進行排名。然而，在這項工作中，我們提出幾個令人驚訝的發現，挑戰了關於 RM 行為的常見假設。我們的分析顯示，最先進的獎勵模型優先考慮結構一致性，而不是因果正確性。具體來說，移除問題陳述對獎勵分數的影響很小，而改變數值或中斷推理流程則會顯著影響 RM 輸出。此外，RM 表現出對完整推理軌跡的強烈依賴性，截斷或不完整的步驟會導致獎勵分配產生重大變化，這表示 RM 主要依賴於學習到的推理模式，而不是明確的問題理解。這些發現適用於多種架構、資料集和任務，得出三個關鍵見解：(1) RM 主要評估一致性，而不是真正的推理品質；(2) 在獎勵分配中，明確問題理解的角色被誇大了；(3) 目前的 RM 在排名回應方面可能比驗證邏輯有效性更有效。我們的結果表明現有獎勵建模方法存在根本限制，強調需要轉向因果感知獎勵模型，超越以一致性為導向的評估。

##### **FIND: Fine-grained Information Density Guided Adaptive Retrieval-Augmented Generation for Disease Diagnosis**
2502.14614v1 by Mingyi Jia, Junwen Duan, Yan Song, Jianxin Wang

Retrieval-Augmented Large Language Models (LLMs), which integrate external
knowledge into LLMs, have shown remarkable performance in various medical
domains, including clinical diagnosis. However, existing RAG methods struggle
to effectively assess task difficulty to make retrieval decisions, thereby
failing to meet the clinical requirements for balancing efficiency and
accuracy. So in this paper, we propose FIND (\textbf{F}ine-grained
\textbf{In}formation \textbf{D}ensity Guided Adaptive RAG), a novel framework
that improves the reliability of RAG in disease diagnosis scenarios. FIND
incorporates a fine-grained adaptive control module to determine whether
retrieval is necessary based on the information density of the input. By
optimizing the retrieval process and implementing a knowledge filtering module,
FIND ensures that the retrieval is better suited to clinical scenarios.
Experiments on three Chinese electronic medical record datasets demonstrate
that FIND significantly outperforms various baseline methods, highlighting its
effectiveness in clinical diagnosis tasks.

摘要：檢索增強大型語言模型 (LLM)，將外部知識整合至 LLM，已於各種醫療領域展現出卓越效能，包括臨床診斷。然而，現有的 RAG 方法難以有效評估任務難度以做出檢索決策，因此無法滿足平衡效率和精確度的臨床需求。因此，我們在本文中提出 FIND（**F**ine-grained **In**formation **D**ensity Guided Adaptive RAG），一種新穎架構，可提升 RAG 在疾病診斷場景中的可靠性。FIND 整合一個細緻化的自適應控制模組，根據輸入的資訊密度判斷是否需要檢索。透過最佳化檢索程序並實作一個知識過濾模組，FIND 確保檢索更適合臨床場景。在三個中文電子病歷資料集上的實驗顯示，FIND 明顯優於各種基線方法，突顯其在臨床診斷任務中的有效性。

##### **Behavioral Analysis of Information Salience in Large Language Models**
2502.14613v1 by Jan Trienes, Jörg Schlötterer, Junyi Jessy Li, Christin Seifert

Large Language Models (LLMs) excel at text summarization, a task that
requires models to select content based on its importance. However, the exact
notion of salience that LLMs have internalized remains unclear. To bridge this
gap, we introduce an explainable framework to systematically derive and
investigate information salience in LLMs through their summarization behavior.
Using length-controlled summarization as a behavioral probe into the content
selection process, and tracing the answerability of Questions Under Discussion
throughout, we derive a proxy for how models prioritize information. Our
experiments on 13 models across four datasets reveal that LLMs have a nuanced,
hierarchical notion of salience, generally consistent across model families and
sizes. While models show highly consistent behavior and hence salience
patterns, this notion of salience cannot be accessed through introspection, and
only weakly correlates with human perceptions of information salience.

摘要：大型語言模型 (LLM) 在文字摘要方面表現出色，這項任務需要模型根據重要性來選擇內容。然而，LLM 內化的顯著性準確概念仍不清楚。為了彌補這個差距，我們引入了一個可解釋的架構，透過摘要行為系統性地推導和調查 LLM 中的資訊顯著性。使用長度控制摘要作為行為探測來探討內容選擇過程，並追蹤討論中問題的可回答性，我們推導出一個模型優先處理資訊的方式代理。我們針對四個資料集中的 13 個模型進行的實驗揭示，LLM 具有細緻入微、階層式的顯著性概念，通常在模型系列和大小之間保持一致。雖然模型表現出高度一致的行為，因此具有顯著性模式，但這個顯著性概念無法透過內省來存取，而且與人類對資訊顯著性的認知僅有微弱相關性。

##### **A Theory for Conditional Generative Modeling on Multiple Data Sources**
2502.14583v1 by Rongzhen Wang, Yan Zhang, Chenyu Zheng, Chongxuan Li, Guoqiang Wu

The success of large generative models has driven a paradigm shift,
leveraging massive multi-source data to enhance model capabilities. However,
the interaction among these sources remains theoretically underexplored. This
paper takes the first step toward a rigorous analysis of multi-source training
in conditional generative modeling, where each condition represents a distinct
data source. Specifically, we establish a general distribution estimation error
bound in average total variation distance for conditional maximum likelihood
estimation based on the bracketing number. Our result shows that when source
distributions share certain similarities and the model is expressive enough,
multi-source training guarantees a sharper bound than single-source training.
We further instantiate the general theory on conditional Gaussian estimation
and deep generative models including autoregressive and flexible energy-based
models, by characterizing their bracketing numbers. The results highlight that
the number of sources and similarity among source distributions improve the
advantage of multi-source training. Simulations and real-world experiments
validate our theory. Code is available at:
\url{https://github.com/ML-GSAI/Multi-Source-GM}.

摘要：大型生成模型的成功推動了範例轉移，利用大量多來源資料來增強模型功能。然而，這些來源之間的互動在理論上仍未得到充分探討。本文踏出了嚴謹分析條件生成模型中多來源訓練的第一步，其中每個條件代表一個不同的資料來源。具體來說，我們建立了一個基於括號數的條件最大似然估計的平均總變異距離中的通用分佈估計誤差界限。我們的結果表明，當來源分佈具有一定的相似性且模型具有足夠的表達力時，多來源訓練保證了比單來源訓練更嚴格的界限。我們進一步在條件高斯估計和深度生成模型（包括自迴歸和靈活的基於能量的模型）上例證了通用理論，通過表徵它們的括號數。結果強調了來源數和來源分佈之間的相似性提高了多來源訓練的優勢。模擬和真實世界的實驗驗證了我們的理論。程式碼可在以下網址取得：\url{https://github.com/ML-GSAI/Multi-Source-GM}。

##### **A Statistical Case Against Empirical Human-AI Alignment**
2502.14581v1 by Julian Rodemann, Esteban Garces Arias, Christoph Luther, Christoph Jansen, Thomas Augustin

Empirical human-AI alignment aims to make AI systems act in line with
observed human behavior. While noble in its goals, we argue that empirical
alignment can inadvertently introduce statistical biases that warrant caution.
This position paper thus advocates against naive empirical alignment, offering
prescriptive alignment and a posteriori empirical alignment as alternatives. We
substantiate our principled argument by tangible examples like human-centric
decoding of language models.

摘要：經驗主義的人工智慧校準旨在使人工智慧系統根據觀察到的人類行為採取行動。儘管目標崇高，我們認為經驗主義校準可能會無意中引入需要謹慎對待的統計偏差。因此，本立場文件主張反對天真的經驗主義校準，提供規範性校準和後驗經驗主義校準作為替代方案。我們以具體的例子（例如以人為中心的語言模型解碼）來證明我們的原則性論點。

##### **ReVISE: Learning to Refine at Test-Time via Intrinsic Self-Verification**
2502.14565v1 by Hyunseok Lee, Seunghyuk Oh, Jaehyung Kim, Jinwoo Shin, Jihoon Tack

Self-awareness, i.e., the ability to assess and correct one's own generation,
is a fundamental aspect of human intelligence, making its replication in large
language models (LLMs) an important yet challenging task. Previous works tackle
this by employing extensive reinforcement learning or rather relying on large
external verifiers. In this work, we propose Refine via Intrinsic
Self-Verification (ReVISE), an efficient and effective framework that enables
LLMs to self-correct their outputs through self-verification. The core idea of
ReVISE is to enable LLMs to verify their reasoning processes and continually
rethink reasoning trajectories based on its verification. We introduce a
structured curriculum based upon online preference learning to implement this
efficiently. Specifically, as ReVISE involves two challenging tasks (i.e.,
self-verification and reasoning correction), we tackle each task sequentially
using curriculum learning, collecting both failed and successful reasoning
paths to construct preference pairs for efficient training. During inference,
our approach enjoys natural test-time scaling by integrating self-verification
and correction capabilities, further enhanced by our proposed confidence-aware
decoding mechanism. Our experiments on various reasoning tasks demonstrate that
ReVISE achieves efficient self-correction and significantly improves reasoning
performance.

摘要：自我覺察，亦即評估和修正自身產出的能力，是人類智慧的基本面向，使其能在大型語言模型 (LLM) 中複製，是一項重要且具挑戰性的任務。先前的研究透過採用廣泛的強化學習或依賴大型外部驗證器來解決這個問題。在這項研究中，我們提出透過內在自我驗證 (ReVISE) 進行精煉，一個有效率且有效的架構，使 LLM 能透過自我驗證來自我修正其產出。ReVISE 的核心概念是讓 LLM 能驗證其推理過程，並根據驗證結果持續重新思考推理軌跡。我們導入一個建構於線上偏好學習的結構化課程，以有效率地實作這項功能。具體來說，由於 ReVISE 涉及兩項具有挑戰性的任務（即自我驗證和推理修正），我們使用課程學習循序漸進地處理每一項任務，收集失敗和成功的推理路徑，以建構偏好對，進行有效率的訓練。在推論期間，我們的作法透過整合自我驗證和修正功能，享有自然的測試時間擴充，並進一步透過我們提出的具備信心感知的解碼機制進行強化。我們在各種推理任務上的實驗顯示，ReVISE 達到有效率的自我修正，並顯著提升推理效能。

##### **Plan-over-Graph: Towards Parallelable LLM Agent Schedule**
2502.14563v1 by Shiqi Zhang, Xinbei Ma, Zouying Cao, Zhuosheng Zhang, Hai Zhao

Large Language Models (LLMs) have demonstrated exceptional abilities in
reasoning for task planning. However, challenges remain under-explored for
parallel schedules. This paper introduces a novel paradigm, plan-over-graph, in
which the model first decomposes a real-life textual task into executable
subtasks and constructs an abstract task graph. The model then understands this
task graph as input and generates a plan for parallel execution. To enhance the
planning capability of complex, scalable graphs, we design an automated and
controllable pipeline to generate synthetic graphs and propose a two-stage
training scheme. Experimental results show that our plan-over-graph method
significantly improves task performance on both API-based LLMs and trainable
open-sourced LLMs. By normalizing complex tasks as graphs, our method naturally
supports parallel execution, demonstrating global efficiency. The code and data
are available at https://github.com/zsq259/Plan-over-Graph.

摘要：大型語言模型 (LLM) 已展現出在任務規劃推理方面的非凡能力。然而，對於並行時程表的挑戰仍未充分探討。本文介紹了一個新穎的範例，即圖形規劃，其中模型首先將現實生活中的文字任務分解為可執行的子任務，並建構一個抽象任務圖。然後，模型將此任務圖理解為輸入，並產生一個並行執行的計畫。為了增強複雜、可擴充圖形的規劃能力，我們設計了一個自動化且可控的管道來產生合成圖形，並提出了一個兩階段訓練方案。實驗結果表明，我們的圖形規劃方法顯著提升了基於 API 的 LLM 和可訓練的開源 LLM 的任務效能。透過將複雜任務標準化為圖形，我們的模型自然支援並行執行，展現出整體效率。程式碼和資料可在 https://github.com/zsq259/Plan-over-Graph 取得。

##### **Can LLMs Predict Citation Intent? An Experimental Analysis of In-context Learning and Fine-tuning on Open LLMs**
2502.14561v1 by Paris Koloveas, Serafeim Chatzopoulos, Thanasis Vergoulis, Christos Tryfonopoulos

This work investigates the ability of open Large Language Models (LLMs) to
predict citation intent through in-context learning and fine-tuning. Unlike
traditional approaches that rely on pre-trained models like SciBERT, which
require extensive domain-specific pretraining and specialized architectures, we
demonstrate that general-purpose LLMs can be adapted to this task with minimal
task-specific data. We evaluate twelve model variations across five prominent
open LLM families using zero, one, few, and many-shot prompting to assess
performance across scenarios. Our experimental study identifies the
top-performing model through extensive experimentation of in-context
learning-related parameters, which we fine-tune to further enhance task
performance. The results highlight the strengths and limitations of LLMs in
recognizing citation intents, providing valuable insights for model selection
and prompt engineering. Additionally, we make our end-to-end evaluation
framework and models openly available for future use.

摘要：本研究探討開放式大型語言模型 (LLM) 透過情境學習和微調來預測引文意圖的能力。與依賴於預訓練模型（例如 SciBERT）的傳統方法不同，後者需要廣泛的特定領域預訓練和專業架構，我們證明了通用 LLM 可以使用最少的特定任務數據來適應此任務。我們使用零次、一次、少次和多次提示評估五個著名的開放式 LLM 家族中的十二個模型變體，以評估不同場景的效能。我們的實驗研究透過廣泛的實驗來識別情境學習相關參數中效能最佳的模型，我們微調這些參數以進一步增強任務效能。結果突顯了 LLM 在識別引文意圖方面的優點和限制，為模型選擇和提示工程提供了有價值的見解。此外，我們將端到端評估架構和模型公開供未來使用。

##### **Less is More: Improving LLM Alignment via Preference Data Selection**
2502.14560v1 by Xun Deng, Han Zhong, Rui Ai, Fuli Feng, Zheng Wang, Xiangnan He

Direct Preference Optimization (DPO) has emerged as a promising approach for
aligning large language models with human preferences. While prior work mainly
extends DPO from the aspect of the objective function, we instead improve DPO
from the largely overlooked but critical aspect of data selection.
Specifically, we address the issue of parameter shrinkage caused by noisy data
by proposing a novel margin-maximization principle for dataset curation in DPO
training. To accurately estimate margins for data selection, we propose a
dual-margin guided approach that considers both external reward margins and
implicit DPO reward margins. Extensive experiments demonstrate that our method
reduces computational cost dramatically while improving performance.
Remarkably, by using just 10\% of the Ultrafeedback dataset, our approach
achieves 3\% to 8\% improvements across various Llama and Mistral series models
on the AlpacaEval 2.0 benchmark. Furthermore, our approach seamlessly extends
to iterative DPO, yielding a roughly 3\% improvement with 25\% online data,
while further reducing training time. These results highlight the potential of
data selection strategies for advancing preference optimization.

摘要：直接偏好最佳化 (DPO) 已成為一種有希望的方法，可將大型語言模型與人類偏好保持一致。雖然先前的研究主要從目標函數的角度延伸 DPO，但我們反而從資料選擇這個極易被忽略但至關重要的角度改進 DPO。
具體來說，我們透過提出一個用於 DPO 訓練中資料集整理的新邊際最大化原則，來解決由雜訊資料造成的參數收縮問題。為了準確估計資料選擇的邊際，我們提出一個雙邊際引導方法，它同時考慮外部獎勵邊際和隱含 DPO 獎勵邊際。大規模的實驗證明，我們的這種方法大幅降低了運算成本，同時改善了效能。
值得注意的是，我們的這種方法僅使用 Ultrafeedback 資料集的 10%，便在 AlpacaEval 2.0 基準上，在各種 Llama 和 Mistral 系列模型中取得了 3% 到 8% 的改進。此外，我們的這種方法可以無縫地延伸到迭代 DPO，在使用 25% 線上資料的情況下產生了大約 3% 的改進，同時進一步減少了訓練時間。這些結果突顯了資料選擇策略在推進偏好最佳化方面的潛力。

##### **FUIA: Model Inversion Attack against Federated Unlearning**
2502.14558v1 by Lei Zhou, Youwen Zhu

With the introduction of regulations related to the ``right to be forgotten",
federated learning (FL) is facing new privacy compliance challenges. To address
these challenges, researchers have proposed federated unlearning (FU). However,
existing FU research has primarily focused on improving the efficiency of
unlearning, with less attention paid to the potential privacy vulnerabilities
inherent in these methods. To address this gap, we draw inspiration from
gradient inversion attacks in FL and propose the federated unlearning inversion
attack (FUIA). The FUIA is specifically designed for the three types of FU
(sample unlearning, client unlearning, and class unlearning), aiming to provide
a comprehensive analysis of the privacy leakage risks associated with FU. In
FUIA, the server acts as an honest-but-curious attacker, recording and
exploiting the model differences before and after unlearning to expose the
features and labels of forgotten data. FUIA significantly leaks the privacy of
forgotten data and can target all types of FU. This attack contradicts the goal
of FU to eliminate specific data influence, instead exploiting its
vulnerabilities to recover forgotten data and expose its privacy flaws.
Extensive experimental results show that FUIA can effectively reveal the
private information of forgotten data. To mitigate this privacy leakage, we
also explore two potential defense methods, although these come at the cost of
reduced unlearning effectiveness and the usability of the unlearned model.

摘要：隨著「被遺忘權」相關法規的推出，
聯盟學習 (FL) 面臨新的隱私合規挑戰。為了應對
這些挑戰，研究人員提出了聯盟取消學習 (FU)。然而，
現有的 FU 研究主要集中在提高取消學習的效率，較少關注這些方法中固有的潛在隱私漏洞。為了解決這個差距，我們從
FL 中的梯度反演攻擊中汲取靈感，並提出聯盟取消學習反演
攻擊 (FUIA)。FUIA 專門設計用於三種類型的 FU
（樣本取消學習、客戶端取消學習和類別取消學習），旨在提供
對與 FU 相關的隱私洩露風險的全面分析。在
FUIA 中，伺服器充當誠實但好奇的攻擊者，記錄並
利用取消學習前後的模型差異來揭露遺忘資料的功能和標籤。FUIA 大幅洩露遺忘資料的隱私，並且可以針對所有類型的 FU。此攻擊與 FU 消除特定資料影響的目標相矛盾，而是利用其
漏洞來恢復遺忘資料並揭露其隱私缺陷。廣泛的實驗結果表明 FUIA 可以有效揭露遺忘資料的私人資訊。為了減輕這種隱私洩露，我們
還探索了兩種潛在的防禦方法，儘管這些方法以降低取消學習的有效性和已取消學習模型的可用性為代價。

##### **Multiscale Byte Language Models -- A Hierarchical Architecture for Causal Million-Length Sequence Modeling**
2502.14553v1 by Eric Egli, Matteo Manica, Jannis Born

Bytes form the basis of the digital world and thus are a promising building
block for multimodal foundation models. Recently, Byte Language Models (BLMs)
have emerged to overcome tokenization, yet the excessive length of bytestreams
requires new architectural paradigms. Therefore, we present the Multiscale Byte
Language Model (MBLM), a model-agnostic hierarchical decoder stack that allows
training with context windows of $5$M bytes on single GPU in full model
precision. We thoroughly examine MBLM's performance with Transformer and Mamba
blocks on both unimodal and multimodal tasks. Our experiments demonstrate that
hybrid architectures are efficient in handling extremely long byte sequences
during training while achieving near-linear generational efficiency. To the
best of our knowledge, we present the first evaluation of BLMs on visual Q\&A
tasks and find that, despite serializing images and the absence of an encoder,
a MBLM with pure next token prediction can match custom CNN-LSTM architectures
with designated classification heads. We show that MBLMs exhibit strong
adaptability in integrating diverse data representations, including pixel and
image filestream bytes, underlining their potential toward omnimodal foundation
models. Source code is publicly available at:
https://github.com/ai4sd/multiscale-byte-lm

摘要：位元組構成數位世界的基礎，因此是多模態基礎模型的一個有前途的建構模組。最近，位元組語言模型 (BLM) 已應運而生，以克服標記化，但位元組串流的過長需要新的架構範例。因此，我們提出多尺度位元組語言模型 (MBLM)，這是一個與模型無關的分層解碼器堆疊，允許在單一 GPU 上以完整的模型精度訓練 500 萬位元組的內容視窗。我們徹底檢驗了 MBLM 在單模態和多模態任務上使用 Transformer 和 Mamba 區塊的效能。我們的實驗證明，混合架構在處理訓練期間極長的位元組序列時很有效率，同時達到近乎線性的生成效率。據我們所知，我們提出在視覺問答任務上對 BLM 的首次評估，並發現，儘管序列化影像且沒有編碼器，但具有純粹下一個標記預測的 MBLM 可以匹配具有指定分類標頭的客製化 CNN-LSTM 架構。我們表明，MBLM 在整合各種資料表示形式方面表現出強大的適應性，包括像素和影像檔案串流位元組，強調它們朝向全模態基礎模型的潛力。原始碼已公開於：
https://github.com/ai4sd/multiscale-byte-lm

##### **Position: Graph Learning Will Lose Relevance Due To Poor Benchmarks**
2502.14546v1 by Maya Bechler-Speicher, Ben Finkelshtein, Fabrizio Frasca, Luis Müller, Jan Tönshoff, Antoine Siraudin, Viktor Zaverkin, Michael M. Bronstein, Mathias Niepert, Bryan Perozzi, Mikhail Galkin, Christopher Morris

While machine learning on graphs has demonstrated promise in drug design and
molecular property prediction, significant benchmarking challenges hinder its
further progress and relevance. Current benchmarking practices often lack focus
on transformative, real-world applications, favoring narrow domains like
two-dimensional molecular graphs over broader, impactful areas such as
combinatorial optimization, relational databases, or chip design. Additionally,
many benchmark datasets poorly represent the underlying data, leading to
inadequate abstractions and misaligned use cases. Fragmented evaluations and an
excessive focus on accuracy further exacerbate these issues, incentivizing
overfitting rather than fostering generalizable insights. These limitations
have prevented the development of truly useful graph foundation models. This
position paper calls for a paradigm shift toward more meaningful benchmarks,
rigorous evaluation protocols, and stronger collaboration with domain experts
to drive impactful and reliable advances in graph learning research, unlocking
the potential of graph learning.

摘要：<paragraph>儘管圖形上的機器學習在藥物設計和分子屬性預測方面已展現潛力，但顯著的基準挑戰阻礙了其進一步進展和相關性。目前的基準實務往往缺乏對轉型性、真實世界應用的關注，偏好於狹窄的領域，例如二維分子圖形，而不是組合最佳化、關係資料庫或晶片設計等更廣泛、更有影響力的領域。此外，許多基準資料集無法充分表示基礎資料，導致抽象化不充分和使用案例錯位。支離破碎的評估和過度關注準確性進一步加劇了這些問題，激勵過度擬合，而不是培養可概括的見解。這些限制阻礙了真正有用的圖形基礎模型的開發。這篇立場文件呼籲將範例轉變為更有意義的基準、嚴格的評估協定，以及與領域專家的更強大合作，以推動圖形學習研究中具有影響力和可靠性的進展，釋放圖形學習的潛力。</paragraph>

##### **LLM-based User Profile Management for Recommender System**
2502.14541v1 by Seunghwan Bang, Hwanjun Song

The rapid advancement of Large Language Models (LLMs) has opened new
opportunities in recommender systems by enabling zero-shot recommendation
without conventional training. Despite their potential, most existing works
rely solely on users' purchase histories, leaving significant room for
improvement by incorporating user-generated textual data, such as reviews and
product descriptions. Addressing this gap, we propose PURE, a novel LLM-based
recommendation framework that builds and maintains evolving user profiles by
systematically extracting and summarizing key information from user reviews.
PURE consists of three core components: a Review Extractor for identifying user
preferences and key product features, a Profile Updater for refining and
updating user profiles, and a Recommender for generating personalized
recommendations using the most current profile. To evaluate PURE, we introduce
a continuous sequential recommendation task that reflects real-world scenarios
by adding reviews over time and updating predictions incrementally. Our
experimental results on Amazon datasets demonstrate that PURE outperforms
existing LLM-based methods, effectively leveraging long-term user information
while managing token limitations.

摘要：大型語言模型 (LLM) 的快速進步為推薦系統開啟了新的機會，它能實現零次學習推薦，而無需傳統訓練。儘管有潛力，但現有的大部分工作僅依賴於使用者的購買記錄，透過納入使用者產生的文字資料，例如評論和產品說明，仍有很大的改進空間。針對此差距，我們提出 PURE，一個新穎的基於 LLM 的推薦架構，透過系統性地從使用者評論中提取和總結關鍵資訊，建立並維護不斷演進的使用者檔案。PURE 由三個核心組成部分組成：一個評論萃取器，用於識別使用者的喜好和產品主要功能；一個檔案更新器，用於精煉和更新使用者檔案；一個推薦器，用於使用最新的檔案產生個人化推薦。為了評估 PURE，我們引入一個連續順序推薦任務，透過隨著時間新增評論和遞增更新預測，反映真實世界的場景。我們在 Amazon 資料集上的實驗結果證明，PURE 優於現有的基於 LLM 的方法，在管理符號限制的同時，有效地利用長期使用者資訊。

##### **LoRA-GGPO: Mitigating Double Descent in LoRA Fine-Tuning via Gradient-Guided Perturbation Optimization**
2502.14538v1 by Yupeng Chang, Chenlu Guo, Yi Chang, Yuan Wu

Large Language Models (LLMs) have achieved remarkable success in natural
language processing, but their full fine-tuning remains resource-intensive.
Parameter-Efficient Fine-Tuning (PEFT) methods, such as Low-Rank Adaptation
(LoRA), have emerged as a practical solution by approximating parameter updates
with low-rank matrices. However, LoRA often exhibits a "double descent"
phenomenon during fine-tuning, where model performance degrades due to
overfitting and limited expressiveness caused by low-rank constraints. To
address this issue, we propose LoRA-GGPO (Gradient-Guided Perturbation
Optimization), a novel method that leverages gradient and weight norms to
generate targeted perturbations. By optimizing the sharpness of the loss
landscape, LoRA-GGPO guides the model toward flatter minima, mitigating the
double descent problem and improving generalization. Extensive experiments on
natural language understanding (NLU) and generation (NLG) tasks demonstrate
that LoRA-GGPO outperforms LoRA and its state-of-the-art variants. Furthermore,
extended experiments specifically designed to analyze the double descent
phenomenon confirm that LoRA-GGPO effectively alleviates this issue, producing
more robust and generalizable models. Our work provides a robust and efficient
solution for fine-tuning LLMs, with broad applicability in real-world
scenarios. The code is available at https://github.com/llm172/LoRA-GGPO.

摘要：大型語言模型 (LLM) 在自然語言處理方面取得了顯著的成功，但它們的完全微調仍然需要大量資源。參數高效微調 (PEFT) 方法（例如低秩適應 (LoRA)）已成為一種實用的解決方案，它通過低秩矩陣近似參數更新。然而，LoRA 在微調過程中經常表現出「雙重下降」現象，其中模型性能會因過度擬合和低秩約束導致的表達能力有限而下降。為了解決這個問題，我們提出了 LoRA-GGPO（梯度引導擾動優化），這是一種利用梯度和權重範數來產生目標擾動的新方法。通過優化損失函數曲面的陡度，LoRA-GGPO 引導模型朝向更平坦的最小值，從而減輕雙重下降問題並改善泛化能力。在自然語言理解 (NLU) 和生成 (NLG) 任務中進行的廣泛實驗表明，LoRA-GGPO 優於 LoRA 及其最先進的變體。此外，專門設計用於分析雙重下降現象的延伸實驗證實，LoRA-GGPO 有效地緩解了這個問題，產生了更強大且更具泛化能力的模型。我們的研究為微調 LLM 提供了一個強大且高效的解決方案，在現實世界場景中具有廣泛的適用性。代碼可在 https://github.com/llm172/LoRA-GGPO 獲得。

##### **CORBA: Contagious Recursive Blocking Attacks on Multi-Agent Systems Based on Large Language Models**
2502.14529v1 by Zhenhong Zhou, Zherui Li, Jie Zhang, Yuanhe Zhang, Kun Wang, Yang Liu, Qing Guo

Large Language Model-based Multi-Agent Systems (LLM-MASs) have demonstrated
remarkable real-world capabilities, effectively collaborating to complete
complex tasks. While these systems are designed with safety mechanisms, such as
rejecting harmful instructions through alignment, their security remains
largely unexplored. This gap leaves LLM-MASs vulnerable to targeted
disruptions. In this paper, we introduce Contagious Recursive Blocking Attacks
(Corba), a novel and simple yet highly effective attack that disrupts
interactions between agents within an LLM-MAS. Corba leverages two key
properties: its contagious nature allows it to propagate across arbitrary
network topologies, while its recursive property enables sustained depletion of
computational resources. Notably, these blocking attacks often involve
seemingly benign instructions, making them particularly challenging to mitigate
using conventional alignment methods. We evaluate Corba on two widely-used
LLM-MASs, namely, AutoGen and Camel across various topologies and commercial
models. Additionally, we conduct more extensive experiments in open-ended
interactive LLM-MASs, demonstrating the effectiveness of Corba in complex
topology structures and open-source models. Our code is available at:
https://github.com/zhrli324/Corba.

摘要：基於大型語言模型的多主體系統（LLM-MAS）已展現出卓越的真實世界能力，有效地協作以完成複雜任務。儘管這些系統設計有安全機制，例如透過對齊拒絕有害指令，但其安全性仍未得到充分探討。此一缺口讓 LLM-MAS 易受針對性的破壞。在本文中，我們介紹了傳染性遞迴封鎖攻擊（Corba），這是一種新穎且簡單但極為有效的攻擊，會破壞 LLM-MAS 中主體之間的互動。Corba 利用了兩個關鍵特性：其傳染性使其能夠在任意網路拓撲中傳播，而其遞迴特性則能持續耗盡運算資源。值得注意的是，這些封鎖攻擊通常涉及看似良性的指令，這使得使用傳統對齊方法來減輕攻擊特別具有挑戰性。我們在兩個廣泛使用的 LLM-MAS，即 AutoGen 和 Camel 上評估了 Corba，涵蓋了各種拓撲和商業模型。此外，我們在開放式互動 LLM-MAS 中進行了更廣泛的實驗，證明了 Corba 在複雜拓撲結構和開源模型中的有效性。我們的程式碼可在以下網址取得：https://github.com/zhrli324/Corba。

##### **Small Graph Is All You Need: DeepStateGNN for Scalable Traffic Forecasting**
2502.14525v1 by Yannick Wölker, Arash Hajisafi, Cyrus Shahabi, Matthias Renz

We propose a novel Graph Neural Network (GNN) model, named DeepStateGNN, for
analyzing traffic data, demonstrating its efficacy in two critical tasks:
forecasting and reconstruction. Unlike typical GNN methods that treat each
traffic sensor as an individual graph node, DeepStateGNN clusters sensors into
higher-level graph nodes, dubbed Deep State Nodes, based on various similarity
criteria, resulting in a fixed number of nodes in a Deep State graph. The term
"Deep State" nodes is a play on words, referencing hidden networks of power
that, like these nodes, secretly govern traffic independently of visible
sensors. These Deep State Nodes are defined by several similarity factors,
including spatial proximity (e.g., sensors located nearby in the road network),
functional similarity (e.g., sensors on similar types of freeways), and
behavioral similarity under specific conditions (e.g., traffic behavior during
rain). This clustering approach allows for dynamic and adaptive node grouping,
as sensors can belong to multiple clusters and clusters may evolve over time.
Our experimental results show that DeepStateGNN offers superior scalability and
faster training, while also delivering more accurate results than competitors.
It effectively handles large-scale sensor networks, outperforming other methods
in both traffic forecasting and reconstruction accuracy.

摘要：<paragraph>我們提出一個名為 DeepStateGNN 的新穎圖形神經網路 (GNN) 模型，用於分析交通數據，並展示其在兩個關鍵任務中的效能：預測和重建。與將每個交通感測器視為個別圖形節點的典型 GNN 方法不同，DeepStateGNN 會根據各種相似性準則將感測器群集到較高層級的圖形節點中，稱為 Deep State 節點，這會在 Deep State 圖形中產生固定數量的節點。「Deep State」節點這個術語是文字遊戲，指的是隱藏的權力網路，就像這些節點一樣，秘密地獨立於可見感測器管理交通。這些 Deep State 節點由幾個相似性因素定義，包括空間接近性（例如，位於道路網路中附近的感測器）、功能相似性（例如，位於類似類型高速公路上的感測器）以及特定條件下的行為相似性（例如，雨中的交通行為）。這種群集方法允許動態和自適應節點分組，因為感測器可以屬於多個群集，而且群集可能會隨著時間演變。我們的實驗結果顯示，DeepStateGNN 提供了卓越的可擴充性和更快的訓練速度，同時也比競爭對手提供了更準確的結果。它有效地處理了大規模感測器網路，在交通預測和重建準確度方面都優於其他方法。</paragraph>

##### **Generative adversarial networks vs large language models: a comparative study on synthetic tabular data generation**
2502.14523v1 by Austin A. Barr, Robert Rozman, Eddie Guo

We propose a new framework for zero-shot generation of synthetic tabular
data. Using the large language model (LLM) GPT-4o and plain-language prompting,
we demonstrate the ability to generate high-fidelity tabular data without
task-specific fine-tuning or access to real-world data (RWD) for pre-training.
To benchmark GPT-4o, we compared the fidelity and privacy of LLM-generated
synthetic data against data generated with the conditional tabular generative
adversarial network (CTGAN), across three open-access datasets: Iris, Fish
Measurements, and Real Estate Valuation. Despite the zero-shot approach, GPT-4o
outperformed CTGAN in preserving means, 95% confidence intervals, bivariate
correlations, and data privacy of RWD, even at amplified sample sizes. Notably,
correlations between parameters were consistently preserved with appropriate
direction and strength. However, refinement is necessary to better retain
distributional characteristics. These findings highlight the potential of LLMs
in tabular data synthesis, offering an accessible alternative to generative
adversarial networks and variational autoencoders.

摘要：我們提出一個新的架構，用於合成表格資料的零次學習產生。利用大型語言模型 (LLM) GPT-4o 和自然語言提示，我們證明了在沒有特定任務微調或取得真實世界資料 (RWD) 進行預訓練的情況下，產生高保真表格資料的能力。為了對 GPT-4o 進行基準測試，我們比較了 LLM 生成的合成資料與使用條件表格生成對抗網路 (CTGAN) 生成的資料在保真度和隱私性方面的表現，比較對象是三個開放取用的資料集：鳶尾花、魚類測量和房地產估價。儘管採用零次學習方法，GPT-4o 在保留平均值、95% 信賴區間、二元關聯和 RWD 的資料隱私方面都優於 CTGAN，即使在擴增的樣本大小下也是如此。值得注意的是，參數之間的關聯始終保持適當的方向和強度。然而，需要進行改進以更好地保留分佈特徵。這些發現突顯了 LLM 在表格資料合成中的潛力，為生成對抗網路和變異自動編碼器提供了可行的替代方案。

##### **MultiSlav: Using Cross-Lingual Knowledge Transfer to Combat the Curse of Multilinguality**
2502.14509v1 by Artur Kot, Mikołaj Koszowski, Wojciech Chojnowski, Mieszko Rutkowski, Artur Nowakowski, Kamil Guttmann, Mikołaj Pokrywka

Does multilingual Neural Machine Translation (NMT) lead to The Curse of the
Multlinguality or provides the Cross-lingual Knowledge Transfer within a
language family? In this study, we explore multiple approaches for extending
the available data-regime in NMT and we prove cross-lingual benefits even in
0-shot translation regime for low-resource languages. With this paper, we
provide state-of-the-art open-source NMT models for translating between
selected Slavic languages. We released our models on the HuggingFace Hub
(https://hf.co/collections/allegro/multislav-6793d6b6419e5963e759a683) under
the CC BY 4.0 license. Slavic language family comprises morphologically rich
Central and Eastern European languages. Although counting hundreds of millions
of native speakers, Slavic Neural Machine Translation is under-studied in our
opinion. Recently, most NMT research focuses either on: high-resource languages
like English, Spanish, and German - in WMT23 General Translation Task 7 out of
8 task directions are from or to English; massively multilingual models
covering multiple language groups; or evaluation techniques.

摘要：多語言神經機器翻譯 (NMT) 是否會導致多語言的詛咒，或在語言家族中提供跨語言知識轉移？在這項研究中，我們探討了多種擴展 NMT 中可用資料範圍的方法，並證明了即使在低資源語言的零次學習翻譯中也有跨語言的優點。透過這篇論文，我們提供了最先進的開源 NMT 模型，用於翻譯選定的斯拉夫語。我們在 HuggingFace Hub (https://hf.co/collections/allegro/multislav-6793d6b6419e5963e759a683) 下根據 CC BY 4.0 授權發布我們的模型。斯拉夫語系包含形態豐富的中歐和東歐語言。儘管擁有數億母語人士，但我們認為斯拉夫神經機器翻譯的研究不足。最近，大多數 NMT 研究都專注於：高資源語言，例如英語、西班牙語和德語 - 在 WMT23 一般翻譯任務中，8 個任務方向中有 7 個來自英語或翻譯成英語；涵蓋多個語言群組的大規模多語言模型；或評估技術。

##### **Can LLMs Simulate L2-English Dialogue? An Information-Theoretic Analysis of L1-Dependent Biases**
2502.14507v1 by Rena Gao, Xuetong Wu, Tatsuki Kuribayashi, Mingrui Ye, Siya Qi, Carsten Roever, Yuanxing Liu, Zheng Yuan, Jey Han Lau

This study evaluates Large Language Models' (LLMs) ability to simulate
non-native-like English use observed in human second language (L2) learners
interfered with by their native first language (L1). In dialogue-based
interviews, we prompt LLMs to mimic L2 English learners with specific L1s
(e.g., Japanese, Thai, Urdu) across seven languages, comparing their outputs to
real L2 learner data. Our analysis examines L1-driven linguistic biases, such
as reference word usage and avoidance behaviors, using information-theoretic
and distributional density measures. Results show that modern LLMs (e.g.,
Qwen2.5, LLAMA3.3, DeepseekV3, GPT-4o) replicate L1-dependent patterns observed
in human L2 data, with distinct influences from various languages (e.g.,
Japanese, Korean, and Mandarin significantly affect tense agreement, and Urdu
influences noun-verb collocations). Our results reveal the potential of LLMs
for L2 dialogue generation and evaluation for future educational applications.

摘要：本研究評估大型語言模型 (LLM) 模擬非母語英語使用者的能力，這些使用者會受到母語 (L1) 干擾，而母語是第二語言 (L2) 學習者。在基於對話的訪談中，我們提示 LLM 模仿具有特定 L1（例如日語、泰語、烏爾都語）的 L2 英語學習者，並比較七種語言的輸出與真實的 L2 學習者資料。我們的分析使用資訊理論和分佈密度測量來檢視 L1 驅動的語言偏差，例如參考詞使用和避免行為。結果顯示，現代 LLM（例如 Qwen2.5、LLAMA3.3、DeepseekV3、GPT-4o）複製了在人類 L2 資料中觀察到的 L1 相依模式，並受到各種語言的明顯影響（例如，日語、韓語和普通話顯著影響時態一致性，而烏爾都語影響名詞動詞搭配）。我們的結果揭示了 LLM 在 L2 對話產生和評估方面的潛力，可供未來教育應用使用。

##### **PLPHP: Per-Layer Per-Head Vision Token Pruning for Efficient Large Vision-Language Models**
2502.14504v1 by Yu Meng, Kaiyuan Li, Chenran Huang, Chen Gao, Xinlei Chen, Yong Li, Xiaoping Zhang

Large Vision-Language Models (LVLMs) have demonstrated remarkable
capabilities across a range of multimodal tasks. However, their inference
efficiency is constrained by the large number of visual tokens processed during
decoding. To address this challenge, we propose Per-Layer Per-Head Vision Token
Pruning (PLPHP), a two-level fine-grained pruning method including Layer-Level
Retention Rate Allocation and Head-Level Vision Token Pruning. Motivated by the
Vision Token Re-attention phenomenon across decoder layers, we dynamically
adjust token retention rates layer by layer. Layers that exhibit stronger
attention to visual information preserve more vision tokens, while layers with
lower vision attention are aggressively pruned. Furthermore, PLPHP applies
pruning at the attention head level, enabling different heads within the same
layer to independently retain critical context. Experiments on multiple
benchmarks demonstrate that PLPHP delivers an 18% faster decoding speed and
reduces the Key-Value Cache (KV Cache) size by over 50%, all at the cost of
0.46% average performance drop, while also achieving notable performance
improvements in multi-image tasks. These results highlight the effectiveness of
fine-grained token pruning and contribute to advancing the efficiency and
scalability of LVLMs. Our source code will be made publicly available.

摘要：大型視覺語言模型 (LVLMs) 已在各種多模態任務中展現出非凡的能力。然而，其推理效率受到解碼過程中處理的大量視覺符號的限制。為了應對這一挑戰，我們提出逐層逐頭視覺符號剪枝 (PLPHP)，這是一種包括層級保留率分配和頭級視覺符號剪枝的兩級細粒度剪枝方法。受解碼器層中視覺符號重新關注現象的啟發，我們動態地逐層調整符號保留率。對視覺資訊表現出更強關注力的層保留更多視覺符號，而視覺關注力較低的層則被積極剪枝。此外，PLPHP 在關注頭級別應用剪枝，使同一層中的不同頭部可以獨立保留關鍵上下文。在多個基準測試上的實驗表明，PLPHP 的解碼速度提高了 18%，且將鍵值快取 (KV 快取) 大小減少了 50% 以上，而代價僅為平均效能下降 0.46%，同時還在多影像任務中實現了顯著的效能提升。這些結果突顯了細粒度符號剪枝的有效性，並有助於提升 LVLMs 的效率和可擴充性。我們的原始碼將公開提供。

##### **How Much Knowledge Can You Pack into a LoRA Adapter without Harming LLM?**
2502.14502v1 by Sergey Pletenev, Maria Marina, Daniil Moskovskiy, Vasily Konovalov, Pavel Braslavski, Alexander Panchenko, Mikhail Salnikov

The performance of Large Language Models (LLMs) on many tasks is greatly
limited by the knowledge learned during pre-training and stored in the model's
parameters. Low-rank adaptation (LoRA) is a popular and efficient training
technique for updating or domain-specific adaptation of LLMs. In this study, we
investigate how new facts can be incorporated into the LLM using LoRA without
compromising the previously learned knowledge. We fine-tuned
Llama-3.1-8B-instruct using LoRA with varying amounts of new knowledge. Our
experiments have shown that the best results are obtained when the training
data contains a mixture of known and new facts. However, this approach is still
potentially harmful because the model's performance on external
question-answering benchmarks declines after such fine-tuning. When the
training data is biased towards certain entities, the model tends to regress to
few overrepresented answers. In addition, we found that the model becomes more
confident and refuses to provide an answer in only few cases. These findings
highlight the potential pitfalls of LoRA-based LLM updates and underscore the
importance of training data composition and tuning parameters to balance new
knowledge integration and general model capabilities.

摘要：大型語言模型 (LLM) 在許多任務上的表現受到預訓練期間學到的知識和儲存在模型參數中的知識的極大限制。低階適應 (LoRA) 是一種流行且有效的訓練技術，用於更新或 LLM 的特定領域適應。在這項研究中，我們探討如何使用 LoRA 將新事實納入 LLM，同時不損害先前學到的知識。我們使用不同數量的知識微調 Llama-3.1-8B-instruct。我們的實驗表明，當訓練資料包含已知和新事實的混合時，會獲得最佳結果。然而，這種方法仍然具有潛在的危害性，因為模型在外部問答基準上的表現會在這種微調後下降。當訓練資料偏向於某些實體時，模型傾向於回歸到少數過度表示的答案。此外，我們發現模型變得更有信心，並且在極少數情況下拒絕提供答案。這些發現突顯了基於 LoRA 的 LLM 更新的潛在缺點，並強調了訓練資料組成和調整參數以平衡新知識整合和一般模型能力的重要性。

##### **Towards a Perspectivist Turn in Argument Quality Assessment**
2502.14501v1 by Julia Romberg, Maximilian Maurer, Henning Wachsmuth, Gabriella Lapesa

The assessment of argument quality depends on well-established logical,
rhetorical, and dialectical properties that are unavoidably subjective:
multiple valid assessments may exist, there is no unequivocal ground truth.
This aligns with recent paths in machine learning, which embrace the
co-existence of different perspectives. However, this potential remains largely
unexplored in NLP research on argument quality. One crucial reason seems to be
the yet unexplored availability of suitable datasets. We fill this gap by
conducting a systematic review of argument quality datasets. We assign them to
a multi-layered categorization targeting two aspects: (a) What has been
annotated: we collect the quality dimensions covered in datasets and
consolidate them in an overarching taxonomy, increasing dataset comparability
and interoperability. (b) Who annotated: we survey what information is given
about annotators, enabling perspectivist research and grounding our
recommendations for future actions. To this end, we discuss datasets suitable
for developing perspectivist models (i.e., those containing individual,
non-aggregated annotations), and we showcase the importance of a controlled
selection of annotators in a pilot study.

摘要：論證品質的評估取決於根深蒂固的邏輯、修辭和辯證屬性，這些屬性難免具有主觀性：可能存在多種有效的評估，沒有明確的真實依據。這與機器學習中最近的途徑一致，這些途徑接受了不同觀點的共存。然而，這種潛力在論證品質的 NLP 研究中仍然很大程度上未被探索。一個關鍵原因似乎是尚未探索合適的資料集的可用性。我們通過對論證品質資料集進行系統性回顧來填補這一空白。我們將它們分配到一個多層次分類，針對兩個方面：(a) 已註釋的內容：我們收集資料集中涵蓋的品質維度，並將它們整合到一個總體分類法中，提高資料集的可比性和互操作性。(b) 誰做了註釋：我們調查了關於註釋者的哪些資訊，使觀點主義研究成為可能，並為我們對未來行動的建議奠定基礎。為此，我們討論了適合開發觀點主義模型的資料集（即那些包含個別、非聚合註釋的資料集），並在試驗研究中展示了受控選擇註釋者的重要性。

##### **MLGym: A New Framework and Benchmark for Advancing AI Research Agents**
2502.14499v1 by Deepak Nathani, Lovish Madaan, Nicholas Roberts, Nikolay Bashlykov, Ajay Menon, Vincent Moens, Amar Budhiraja, Despoina Magka, Vladislav Vorotilov, Gaurav Chaurasia, Dieuwke Hupkes, Ricardo Silveira Cabral, Tatiana Shavrina, Jakob Foerster, Yoram Bachrach, William Yang Wang, Roberta Raileanu

We introduce Meta MLGym and MLGym-Bench, a new framework and benchmark for
evaluating and developing LLM agents on AI research tasks. This is the first
Gym environment for machine learning (ML) tasks, enabling research on
reinforcement learning (RL) algorithms for training such agents. MLGym-bench
consists of 13 diverse and open-ended AI research tasks from diverse domains
such as computer vision, natural language processing, reinforcement learning,
and game theory. Solving these tasks requires real-world AI research skills
such as generating new ideas and hypotheses, creating and processing data,
implementing ML methods, training models, running experiments, analyzing the
results, and iterating through this process to improve on a given task. We
evaluate a number of frontier large language models (LLMs) on our benchmarks
such as Claude-3.5-Sonnet, Llama-3.1 405B, GPT-4o, o1-preview, and Gemini-1.5
Pro. Our MLGym framework makes it easy to add new tasks, integrate and evaluate
models or agents, generate synthetic data at scale, as well as develop new
learning algorithms for training agents on AI research tasks. We find that
current frontier models can improve on the given baselines, usually by finding
better hyperparameters, but do not generate novel hypotheses, algorithms,
architectures, or substantial improvements. We open-source our framework and
benchmark to facilitate future research in advancing the AI research
capabilities of LLM agents.

摘要：<paragraph>我們推出 Meta MLGym 和 MLGym-Bench，一個用於評估和開發 AI 研究任務中 LLM 代理的新架構和基準。這是第一個用於機器學習 (ML) 任務的 Gym 環境，可針對訓練此類代理的強化學習 (RL) 演算法進行研究。MLGym-bench 包含 13 項來自不同領域的開放式 AI 研究任務，例如電腦視覺、自然語言處理、強化學習和博弈論。解決這些任務需要實際的 AI 研究技能，例如產生新想法和假設、建立和處理資料、實作 ML 方法、訓練模型、執行實驗、分析結果，並透過此流程反覆運算來改善特定任務。我們在基準上評估許多前沿大型語言模型 (LLM)，例如 Claude-3.5-Sonnet、Llama-3.1 405B、GPT-4o、o1-preview 和 Gemini-1.5 Pro。我們的 MLGym 架構讓新增任務、整合和評估模型或代理、大規模產生合成資料，以及開發新的學習演算法以訓練 AI 研究任務中的代理變得容易。我們發現目前的邊界模型可以改善既定的基準，通常是透過尋找更好的超參數，但不會產生新穎的假設、演算法、架構或實質性的改進。我們開放原始碼架構和基準，以促進未來在提升 LLM 代理的 AI 研究能力方面的研究。</paragraph>

##### **Stories that (are) Move(d by) Markets: A Causal Exploration of Market Shocks and Semantic Shifts across Different Partisan Groups**
2502.14497v1 by Felix Drinkall, Stefan Zohren, Michael McMahon, Janet B. Pierrehumbert

Macroeconomic fluctuations and the narratives that shape them form a mutually
reinforcing cycle: public discourse can spur behavioural changes leading to
economic shifts, which then result in changes in the stories that propagate. We
show that shifts in semantic embedding space can be causally linked to
financial market shocks -- deviations from the expected market behaviour.
Furthermore, we show how partisanship can influence the predictive power of
text for market fluctuations and shape reactions to those same shocks. We also
provide some evidence that text-based signals are particularly salient during
unexpected events such as COVID-19, highlighting the value of language data as
an exogenous variable in economic forecasting. Our findings underscore the
bidirectional relationship between news outlets and market shocks, offering a
novel empirical approach to studying their effect on each other.

摘要：宏觀經濟波動與形塑它們的敘事形成一個相互強化的循環：公共論述可能激發導致經濟變化的行為改變，進而導致宣傳故事的改變。我們表明，語義嵌入空間的轉變可能與金融市場震盪（與預期的市場行為的偏差）有因果關係。此外，我們展示了黨派立場如何影響文字對市場波動的預測能力，以及如何形塑對這些震盪的反應。我們還提供了一些證據，證明在 COVID-19 等意外事件期間，基於文字的信號特別顯著，突顯了語言資料在經濟預測中作為外生變數的價值。我們的研究結果強調了新聞媒體與市場震盪之間的雙向關係，提供了一種研究它們對彼此影響的新穎實證方法。

##### **Enhancing Language Multi-Agent Learning with Multi-Agent Credit Re-Assignment for Interactive Environment Generalization**
2502.14496v1 by Zhitao He, Zijun Liu, Peng Li, May Fung, Ming Yan, Ji Zhang, Fei Huang, Yang Liu

LLM-based agents have made significant advancements in interactive
environments, such as mobile operations and web browsing, and other domains
beyond computer using. Current multi-agent systems universally excel in
performance, compared to single agents, but struggle with generalization across
environments due to predefined roles and inadequate strategies for generalizing
language agents. The challenge of achieving both strong performance and good
generalization has hindered the progress of multi-agent systems for interactive
environments. To address these issues, we propose CollabUIAgents, a multi-agent
reinforcement learning framework with a novel multi-agent credit re-assignment
(CR) strategy, assigning process rewards with LLMs rather than
environment-specific rewards and learning with synthesized preference data, in
order to foster generalizable, collaborative behaviors among the role-free
agents' policies. Empirical results show that our framework improves both
performance and cross-environment generalizability of multi-agent systems.
Moreover, our 7B-parameter system achieves results on par with or exceed strong
closed-source models, and the LLM that guides the CR. We also provide insights
in using granular CR rewards effectively for environment generalization, and
accommodating trained LLMs in multi-agent systems.

摘要：基於 LLM 的代理在互動式環境中取得重大進展，例如行動運算和網頁瀏覽，以及電腦使用以外的其他領域。與單一代理相比，目前的 Multi-Agent 系統在效能上普遍表現出色，但由於預先定義的角色和不適當的語言代理概化策略，導致難以跨環境概化。在互動式環境中，同時達成強大效能和良好概化的挑戰，阻礙了 Multi-Agent 系統的進展。為了解決這些問題，我們提出 CollabUIAgents，這是一個 Multi-Agent 強化學習架構，具備創新的 Multi-Agent 信用重新分配 (CR) 策略，使用 LLM 而不是特定於環境的獎勵來分配程序獎勵，並透過綜合偏好資料進行學習，以促進無角色代理政策之間可概化的協作行為。經驗結果顯示，我們的架構同時改善了 Multi-Agent 系統的效能和跨環境概化能力。此外，我們的 7B 參數系統在效能上與強大的閉源模型和引導 CR 的 LLM 相當或超越它們。我們也提供見解，說明如何有效地使用細粒化的 CR 獎勵來進行環境概化，以及如何在 Multi-Agent 系統中容納受過訓練的 LLM。

##### **StructFlowBench: A Structured Flow Benchmark for Multi-turn Instruction Following**
2502.14494v1 by Jinnan Li, Jinzhe Li, Yue Wang, Yi Chang, Yuan Wu

Multi-turn instruction following capability constitutes a core competency of
large language models (LLMs) in real-world applications. Existing evaluation
benchmarks predominantly focus on fine-grained constraint satisfaction and
domain-specific capability assessment, yet overlook the crucial structural
dependency between dialogue turns that distinguishes multi-turn from
single-turn interactions. This structural dependency not only reflects user
intent but also establishes a second dimension for instruction following
evaluation beyond constraint satisfaction. To address this gap, we propose
StructFlowBench, a multi-turn instruction following benchmark with structural
flow modeling. The benchmark innovatively defines a structural flow framework
comprising six fundamental inter-turn relationships, which not only introduces
novel structural constraints for model evaluation but also serves as generation
parameters for creating customized dialogue flows tailored to specific
scenarios. Adopting established LLM-based automatic evaluation methodologies,
we conduct systematic evaluations of 13 leading open-source and closed-source
LLMs. Experimental results reveal significant deficiencies in current models'
comprehension of multi-turn dialogue structures. The code is available at
\url{https://github.com/MLGroupJLU/StructFlowBench}.

摘要：多輪指令遵循能力構成大型語言模型 (LLM) 在現實世界應用中的核心能力。現有的評估基準主要專注於細粒度的約束滿足和特定領域的能力評估，卻忽略了多輪與單輪互動之間區別的關鍵結構依賴性。這種結構依賴性不僅反映了使用者的意圖，也為指令遵循評估建立了超越約束滿足的第二個維度。為了解決這個差距，我們提出了 StructFlowBench，一個具有結構流建模的多輪指令遵循基準。該基準創新地定義了一個結構流框架，包含六個基本的回合間關係，這不僅引入了模型評估的新結構約束，還可用作生成參數，用於創建針對特定場景定制的對話流。採用已建立的基於 LLM 的自動評估方法，我們對 13 個領先的開源和閉源 LLM 進行了系統評估。實驗結果揭示了當前模型在理解多輪對話結構方面存在顯著缺陷。程式碼可在 \url{https://github.com/MLGroupJLU/StructFlowBench} 取得。

##### **Statistical Scenario Modelling and Lookalike Distributions for Multi-Variate AI Risk**
2502.14491v1 by Elija Perrier

Evaluating AI safety requires statistically rigorous methods and risk metrics
for understanding how the use of AI affects aggregated risk. However, much AI
safety literature focuses upon risks arising from AI models in isolation,
lacking consideration of how modular use of AI affects risk distribution of
workflow components or overall risk metrics. There is also a lack of
statistical grounding enabling sensitisation of risk models in the presence of
absence of AI to estimate causal contributions of AI. This is in part due to
the dearth of AI impact data upon which to fit distributions. In this work, we
address these gaps in two ways. First, we demonstrate how scenario modelling
(grounded in established statistical techniques such as Markov chains, copulas
and Monte Carlo simulation) can be used to model AI risk holistically. Second,
we show how lookalike distributions from phenomena analogous to AI can be used
to estimate AI impacts in the absence of directly observable data. We
demonstrate the utility of our methods for benchmarking cumulative AI risk via
risk analysis of a logistic scenario simulations.

摘要：評估 AI 安全性需要嚴格的統計方法和風險指標，以了解 AI 的使用如何影響累積風險。然而，許多 AI 安全性文獻著重於 AI 模型孤立產生的風險，缺乏考量 AI 的模組化使用如何影響工作流程組件的風險分佈或整體風險指標。在有或沒有 AI 的情況下，統計基礎也缺乏讓風險模型敏感化的能力，以估計 AI 的因果關係貢獻。這部分是因為缺乏 AI 影響資料來擬合分佈。在這項研究中，我們以兩種方式解決這些差距。首先，我們展示情境建模（建立在已建立的統計技術上，例如馬可夫鏈、copula 和蒙地卡羅模擬）如何用於整體建模 AI 風險。其次，我們展示如何使用類似於 AI 現象的相似分佈來估計在沒有直接可觀察資料的情況下 AI 的影響。我們透過後勤情境模擬的風險分析，展示了我們的方法對於評量累積 AI 風險的效用。

##### **Temporal Misalignment and Probabilistic Neurons**
2502.14487v1 by Velibor Bojković, Xiaofeng Wu, Bin Gu

Spiking Neural Networks (SNNs) offer a more energy-efficient alternative to
Artificial Neural Networks (ANNs) by mimicking biological neural principles,
establishing them as a promising approach to mitigate the increasing energy
demands of large-scale neural models. However, fully harnessing the
capabilities of SNNs remains challenging due to their discrete signal
processing and temporal dynamics. ANN-SNN conversion has emerged as a practical
approach, enabling SNNs to achieve competitive performance on complex machine
learning tasks. In this work, we identify a phenomenon in the ANN-SNN
conversion framework, termed temporal misalignment, in which random spike
rearrangement across SNN layers leads to performance improvements. Based on
this observation, we introduce biologically plausible two-phase probabilistic
(TPP) spiking neurons, further enhancing the conversion process. We demonstrate
the advantages of our proposed method both theoretically and empirically
through comprehensive experiments on CIFAR-10/100, CIFAR10-DVS, and ImageNet
across a variety of architectures, achieving state-of-the-art results.

摘要：脈衝神經網路 (SNN) 模仿生物神經原理，提供了一種比人工神經網路 (ANN) 更省能的替代方案，確立了它們作為緩解大型神經模型日益增長能耗需求的一種有前途的方法。然而，由於 SNN 的離散訊號處理和時間動態，要充分利用 SNN 的功能仍然具有挑戰性。ANN-SNN 轉換已經成為一種實用的方法，使 SNN 能夠在複雜機器學習任務中實現競爭性能。在這項工作中，我們在 ANN-SNN 轉換框架中發現了一種現象，稱為時間錯位，其中隨機脈衝在 SNN 層之間重新排列會導致性能提升。基於這一觀察，我們引入了生物學上合理的兩階段機率 (TPP) 脈衝神經元，進一步增強了轉換過程。我們通過在 CIFAR-10/100、CIFAR10-DVS 和 ImageNet 上對各種架構進行綜合實驗，從理論和經驗上證明了我們提出的方法的優點，取得了最先進的結果。

##### **How Jailbreak Defenses Work and Ensemble? A Mechanistic Investigation**
2502.14486v1 by Zhuohang Long, Siyuan Wang, Shujun Liu, Yuhang Lai, Xuanjing Huang, Zhongyu Wei

Jailbreak attacks, where harmful prompts bypass generative models' built-in
safety, raise serious concerns about model vulnerability. While many defense
methods have been proposed, the trade-offs between safety and helpfulness, and
their application to Large Vision-Language Models (LVLMs), are not well
understood. This paper systematically examines jailbreak defenses by reframing
the standard generation task as a binary classification problem to assess model
refusal tendencies for both harmful and benign queries. We identify two key
defense mechanisms: safety shift, which increases refusal rates across all
queries, and harmfulness discrimination, which improves the model's ability to
distinguish between harmful and benign inputs. Using these mechanisms, we
develop two ensemble defense strategies-inter-mechanism ensembles and
intra-mechanism ensembles-to balance safety and helpfulness. Experiments on the
MM-SafetyBench and MOSSBench datasets with LLaVA-1.5 models show that these
strategies effectively improve model safety or optimize the trade-off between
safety and helpfulness.

摘要：越獄攻擊，其中有害提示繞過生成模型內建的安全機制，引發了對模型漏洞的嚴重疑慮。雖然已提出許多防禦方法，但安全性與有益性之間的取捨，以及它們在大型視覺語言模型 (LVLMs) 中的應用，尚未得到充分理解。本文透過將標準生成任務重新定義為二元分類問題，系統性地檢視越獄防禦，以評估模型對有害和良性查詢的拒絕傾向。我們找出兩種關鍵的防禦機制：安全轉移，這會提高所有查詢的拒絕率，以及危害區分，這會提升模型區分有害和良性輸入的能力。使用這些機制，我們開發出兩種整體防禦策略，機制間整體和機制內整體，以平衡安全性與有益性。在使用 LLaVA-1.5 模型的 MM-SafetyBench 和 MOSSBench 資料集上進行的實驗顯示，這些策略有效地提升了模型安全性，或最佳化了安全性與有益性之間的取捨。

##### **NLoRA: Nyström-Initiated Low-Rank Adaptation for Large Language Models**
2502.14482v1 by Chenlu Guo, Yuan Wu, Yi Chang

Parameter-efficient fine-tuning (PEFT) is essential for adapting large
language models (LLMs), with low-rank adaptation (LoRA) being the most popular
approach. However, LoRA suffers from slow convergence, and some recent LoRA
variants, such as PiSSA, primarily rely on Singular Value Decomposition (SVD)
for initialization, leading to expensive computation. To mitigate these
problems, we use the Nystr\"om method, which follows a three-matrix
manipulation. We first introduce StructuredLoRA (SLoRA), which investigates
adding a small intermediate matrix between the low-rank matrices A and B.
Secondly, we propose Nystr\"omLoRA (NLoRA), which leverages Nystr\"om-based
initialization for SLoRA to improve its effectiveness and efficiency. Finally,
we propose IntermediateTune (IntTune), which explores fine-tuning exclusively
on the intermediate matrix of NLoRA to further boost LLM efficiency. We
evaluate our methods on five natural language generation (NLG) tasks and eight
natural language understanding (NLU) tasks. On GSM8K, SLoRA and NLoRA achieve
accuracies of 56.48% and 57.70%, surpassing LoRA by 33.52% and 36.41%, with
only 3.67 million additional trainable parameters. IntTune improves average NLG
performance over LoRA by 7.45% while using only 1.25% of its parameters. These
results demonstrate the efficiency and effectiveness of our approach in
enhancing model performance with minimal parameter overhead.

摘要：參數高效微調 (PEFT) 對於調整大型語言模型 (LLM) 至關重要，其中低秩調整 (LoRA) 是最受歡迎的方法。然而，LoRA 存在收斂速度慢的問題，而一些最近的 LoRA 變體，例如 PiSSA，主要依賴奇異值分解 (SVD) 進行初始化，導致運算成本高昂。為了減輕這些問題，我們使用了 Nystr\"om 方法，它遵循三矩陣操作。我們首先介紹 StructuredLoRA (SLoRA)，它研究在低秩矩陣 A 和 B 之間添加一個小的中間矩陣。其次，我們提出了 Nystr\"omLoRA (NLoRA)，它利用基於 Nystr\"om 的初始化方法為 SLoRA 提升其有效性和效率。最後，我們提出了 IntermediateTune (IntTune)，它探討了僅對 NLoRA 的中間矩陣進行微調，以進一步提升 LLM 效率。我們在五項自然語言生成 (NLG) 任務和八項自然語言理解 (NLU) 任務上評估了我們的這些方法。在 GSM8K 上，SLoRA 和 NLoRA 分別達到了 56.48% 和 57.70% 的準確率，比 LoRA 高出 33.52% 和 36.41%，而僅增加了 367 萬個可訓練參數。IntTune 在僅使用 LoRA 1.25% 的參數的情況下，將平均 NLG 效能提升了 7.45%。這些結果證明了我們的方法在以最少的參數開銷提升模型效能方面的效率和有效性。

##### **Unshackling Context Length: An Efficient Selective Attention Approach through Query-Key Compression**
2502.14477v1 by Haoyu Wang, Tong Teng, Tianyu Guo, An Xiao, Duyu Tang, Hanting Chen, Yunhe Wang

Handling long-context sequences efficiently remains a significant challenge
in large language models (LLMs). Existing methods for token selection in
sequence extrapolation either employ a permanent eviction strategy or select
tokens by chunk, which may lead to the loss of critical information. We propose
Efficient Selective Attention (ESA), a novel approach that extends context
length by efficiently selecting the most critical tokens at the token level to
compute attention. ESA reduces the computational complexity of token selection
by compressing query and key vectors into lower-dimensional representations. We
evaluate ESA on long sequence benchmarks with maximum lengths up to 256k using
open-source LLMs with context lengths of 8k and 32k. ESA outperforms other
selective attention methods, especially in tasks requiring the retrieval of
multiple pieces of information, achieving comparable performance to
full-attention extrapolation methods across various tasks, with superior
results in certain tasks.

摘要：在大型語言模型 (LLM) 中，有效處理長語境序列仍然是一項重大挑戰。現有的序列外推標記選擇方法採用永久驅逐策略或按塊選擇標記，這可能會導致關鍵資訊遺失。我們提出高效選擇性注意 (ESA)，這是一種新穎的方法，它透過在標記層級有效選擇最關鍵的標記來計算注意，從而延伸語境長度。ESA 透過將查詢和關鍵向量壓縮成較低維度的表示，來降低標記選擇的運算複雜度。我們使用開放原始碼 LLM，在語境長度為 8k 和 32k 的情況下，對長序列基準進行評估，最大長度達 256k。ESA 的表現優於其他選擇性注意方法，特別是在需要擷取多條資訊的任務中，在各種任務中達到與全注意外推方法相當的效能，並且在某些任務中獲得更佳的結果。

##### **Argument-Based Comparative Question Answering Evaluation Benchmark**
2502.14476v1 by Irina Nikishina, Saba Anwar, Nikolay Dolgov, Maria Manina, Daria Ignatenko, Viktor Moskvoretskii, Artem Shelmanov, Tim Baldwin, Chris Biemann

In this paper, we aim to solve the problems standing in the way of automatic
comparative question answering. To this end, we propose an evaluation framework
to assess the quality of comparative question answering summaries. We formulate
15 criteria for assessing comparative answers created using manual annotation
and annotation from 6 large language models and two comparative question
asnwering datasets. We perform our tests using several LLMs and manual
annotation under different settings and demonstrate the constituency of both
evaluations. Our results demonstrate that the Llama-3 70B Instruct model
demonstrates the best results for summary evaluation, while GPT-4 is the best
for answering comparative questions. All used data, code, and evaluation
results are publicly
available\footnote{\url{https://anonymous.4open.science/r/cqa-evaluation-benchmark-4561/README.md}}.

摘要：在本文中，我們旨在解決阻礙自動比較性問題解答的難題。為此，我們提出一個評估框架，用於評估比較性問題解答摘要的品質。我們制定了 15 項準則，用於評估使用手動標註和來自 6 個大型語言模型和兩個比較性問題解答資料集的標註所建立的比較性答案。我們在不同的設定下使用幾個 LLM 和手動標註執行測試，並展示兩種評估的組成。我們的結果表明，Llama-3 70B Instruct 模型在摘要評估中表現最佳，而 GPT-4 在回答比較性問題方面表現最佳。所有使用過的資料、程式碼和評估結果均公開可用\footnote{\url{https://anonymous.4open.science/r/cqa-evaluation-benchmark-4561/README.md}}。

##### **Enhancing Smart Environments with Context-Aware Chatbots using Large Language Models**
2502.14469v1 by Aurora Polo-Rodríguez, Laura Fiorini, Erika Rovini, Filippo Cavallo, Javier Medina-Quero

This work presents a novel architecture for context-aware interactions within
smart environments, leveraging Large Language Models (LLMs) to enhance user
experiences. Our system integrates user location data obtained through UWB tags
and sensor-equipped smart homes with real-time human activity recognition (HAR)
to provide a comprehensive understanding of user context. This contextual
information is then fed to an LLM-powered chatbot, enabling it to generate
personalised interactions and recommendations based on the user's current
activity and environment. This approach moves beyond traditional static chatbot
interactions by dynamically adapting to the user's real-time situation. A case
study conducted from a real-world dataset demonstrates the feasibility and
effectiveness of our proposed architecture, showcasing its potential to create
more intuitive and helpful interactions within smart homes. The results
highlight the significant benefits of integrating LLM with real-time activity
and location data to deliver personalised and contextually relevant user
experiences.

摘要：本研究提出了一種創新的架構，用於在智慧環境中進行情境感知互動，利用大型語言模型 (LLM) 來提升使用者體驗。我們的系統整合了透過超寬頻標籤取得的使用者位置資料，以及配備感測器的智慧家庭，並具備即時人類活動辨識 (HAR)，以全面了解使用者的情境。接著，將這些情境資訊輸入 LLM 驅動的聊天機器人，讓它能根據使用者的當前活動和環境產生個人化的互動和建議。這種方法超越了傳統的靜態聊天機器人互動，能動態地適應使用者的即時狀況。從真實世界資料集進行的案例研究，展示了我們提出的架構的可行性和有效性，突顯出它在智慧家庭中創造更直覺且有用的互動的潛力。結果突顯了將 LLM 與即時活動和位置資料整合，以提供個人化且與情境相關的使用者體驗的顯著優點。

##### **Llamba: Scaling Distilled Recurrent Models for Efficient Language Processing**
2502.14458v1 by Aviv Bick, Tobias Katsch, Nimit Sohoni, Arjun Desai, Albert Gu

We introduce Llamba, a family of efficient recurrent language models
distilled from Llama-3.x into the Mamba architecture. The series includes
Llamba-1B, Llamba-3B, and Llamba-8B, which achieve higher inference throughput
and handle significantly larger batch sizes than Transformer-based models while
maintaining comparable benchmark performance. Furthermore, Llamba demonstrates
the effectiveness of cross-architecture distillation using MOHAWK (Bick et al.,
2024), achieving these results with less than 0.1% of the training data
typically used for models of similar size. To take full advantage of their
efficiency, we provide an optimized implementation of Llamba for
resource-constrained devices such as smartphones and edge platforms, offering a
practical and memory-efficient alternative to Transformers. Overall, Llamba
improves the tradeoff between speed, memory efficiency, and performance, making
high-quality language models more accessible.

摘要：我們推出 Llamba，一種高效的遞迴語言模型家族，從 Llama-3.x 萃取到 Mamba 架構中。該系列包含 Llamba-1B、Llamba-3B 和 Llamba-8B，它們比基於 Transformer 的模型實現更高的推理吞吐量，並處理顯著更大的批次大小，同時保持可比較的基準效能。此外，Llamba 證明了使用 MOHAWK（Bick 等人，2024 年）進行跨架構萃取的有效性，在訓練資料不到類似大小模型通常使用的 0.1% 的情況下實現了這些結果。為了充分利用其效率，我們為 Llamba 提供了針對資源受限裝置（例如智慧型手機和邊緣平台）的最佳化實作，提供實用且記憶體效率高的 Transformer 替代方案。總體而言，Llamba 改善了速度、記憶體效率和效能之間的權衡，讓高品質語言模型更易於取得。

##### **Narrative-Driven Travel Planning: Geoculturally-Grounded Script Generation with Evolutionary Itinerary Optimization**
2502.14456v1 by Ran Ding, Ziyu Zhang, Ying Zhu, Ziqian Kong, Peilan Xu

To enhance tourists' experiences and immersion, this paper proposes a
narrative-driven travel planning framework called NarrativeGuide, which
generates a geoculturally-grounded narrative script for travelers, offering a
novel, role-playing experience for their journey. In the initial stage,
NarrativeGuide constructs a knowledge graph for attractions within a city, then
configures the worldview, character setting, and exposition based on the
knowledge graph. Using this foundation, the knowledge graph is combined to
generate an independent scene unit for each attraction. During the itinerary
planning stage, NarrativeGuide models narrative-driven travel planning as an
optimization problem, utilizing a genetic algorithm (GA) to refine the
itinerary. Before evaluating the candidate itinerary, transition scripts are
generated for each pair of adjacent attractions, which, along with the scene
units, form a complete script. The weighted sum of script coherence, travel
time, and attraction scores is then used as the fitness value to update the
candidate solution set. Experimental results across four cities, i.e., Nanjing
and Yangzhou in China, Paris in France, and Berlin in Germany, demonstrate
significant improvements in narrative coherence and cultural fit, alongside a
notable reduction in travel time and an increase in the quality of visited
attractions. Our study highlights that incorporating external evolutionary
optimization effectively addresses the limitations of large language models in
travel planning.Our codes are available at
https://github.com/Evan01225/Narrative-Driven-Travel-Planning.

摘要：為了增強遊客的體驗和沉浸感，本文提出了一個名為 NarrativeGuide 的敘事驅動旅遊規劃框架，它會為旅客產生一個以地理文化為基礎的敘事腳本，為他們的旅程提供一個新穎的角色扮演體驗。在初始階段，NarrativeGuide 會為城市內的景點建立一個知識圖譜，然後根據知識圖譜配置世界觀、角色設定和說明。利用這個基礎，知識圖譜會與每個景點結合，為其產生一個獨立的場景單元。在行程規劃階段，NarrativeGuide 將敘事驅動的旅遊規劃建模為一個最佳化問題，利用遺傳演算法 (GA) 來優化行程。在評估候選行程之前，會為每對相鄰景點產生過場腳本，這些腳本會與場景單元一起形成一個完整的腳本。接著，將腳本連貫性、旅遊時間和景點分數的加權和用作適應值，以更新候選解集。在四個城市（即中國的南京和揚州、法國的巴黎和德國的柏林）進行的實驗結果顯示，敘事連貫性和文化契合度都有顯著的提升，同時旅遊時間大幅減少，且所參觀景點的品質也提升了。我們的研究強調，納入外部演化最佳化能有效解決大型語言模型在旅遊規劃中的限制。我們的程式碼可在 https://github.com/Evan01225/Narrative-Driven-Travel-Planning 取得。

##### **Optimal word order for non-causal text generation with Large Language Models: the Spanish case**
2502.14451v1 by Andrea Busto-Castiñeira, Silvia García-Méndez, Francisco de Arriba-Pérez, Francisco J. González-Castaño

Natural Language Generation (NLG) popularity has increased owing to the
progress in Large Language Models (LLMs), with zero-shot inference
capabilities. However, most neural systems utilize decoder-only causal
(unidirectional) transformer models, which are effective for English but may
reduce the richness of languages with less strict word order, subject omission,
or different relative clause attachment preferences. This is the first work
that analytically addresses optimal text generation order for non-causal
language models. We present a novel Viterbi algorithm-based methodology for
maximum likelihood word order estimation. We analyze the non-causal
most-likelihood order probability for NLG in Spanish and, then, the probability
of generating the same phrases with Spanish causal NLG. This comparative
analysis reveals that causal NLG prefers English-like SVO structures. We also
analyze the relationship between optimal generation order and causal
left-to-right generation order using Spearman's rank correlation. Our results
demonstrate that the ideal order predicted by the maximum likelihood estimator
is not closely related to the causal order and may be influenced by the
syntactic structure of the target sentence.

摘要：自然語言生成 (NLG) 的普及歸功於大型語言模型 (LLM) 的進步，以及零次學習推論能力。然而，大多數神經系統使用僅解碼器因果 (單向) Transformer模型，這對英語很有效，但可能會減少語序較不嚴謹、省略主詞或相對從句附加偏好不同的語言的豐富性。這是第一個針對非因果語言模型分析性地解決最佳文字生成順序的研究。我們提出了一種基於維特比演算法的新方法，用於最大似然詞序估計。我們分析了西班牙語 NLG 的非因果最大似然順序機率，然後分析了使用西班牙語因果 NLG 生成相同短語的機率。這種比較分析顯示，因果 NLG 偏好英語式的 SVO 結構。我們還使用 Spearman 等級相關性分析最佳生成順序和因果從左到右生成順序之間的關係。我們的結果表明，最大似然估計器預測的理想順序與因果順序沒有密切關係，並且可能會受到目標句子的語法結構影響。

