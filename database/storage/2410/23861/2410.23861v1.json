{"2410.23861": {"publish_time": "2024-10-31", "title": "Audio Is the Achilles' Heel: Red Teaming Audio Large Multimodal Models", "paper_summary": "Large Multimodal Models (LMMs) have demonstrated the ability to interact with\nhumans under real-world conditions by combining Large Language Models (LLMs)\nand modality encoders to align multimodal information (visual and auditory)\nwith text. However, such models raise new safety challenges of whether models\nthat are safety-aligned on text also exhibit consistent safeguards for\nmultimodal inputs. Despite recent safety-alignment research on vision LMMs, the\nsafety of audio LMMs remains under-explored. In this work, we comprehensively\nred team the safety of five advanced audio LMMs under three settings: (i)\nharmful questions in both audio and text formats, (ii) harmful questions in\ntext format accompanied by distracting non-speech audio, and (iii)\nspeech-specific jailbreaks. Our results under these settings demonstrate that\nopen-source audio LMMs suffer an average attack success rate of 69.14% on\nharmful audio questions, and exhibit safety vulnerabilities when distracted\nwith non-speech audio noise. Our speech-specific jailbreaks on Gemini-1.5-Pro\nachieve an attack success rate of 70.67% on the harmful query benchmark. We\nprovide insights on what could cause these reported safety-misalignments.\nWarning: this paper contains offensive examples.", "paper_summary_zh": "\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\uff08LMM\uff09\u5df2\u5c55\u793a\u51fa\u5728\u73b0\u5b9e\u4e16\u754c\u6761\u4ef6\u4e0b\u4e0e\u4eba\u7c7b\u4e92\u52a8\uff0c\u65b9\u6cd5\u662f\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u548c\u6a21\u6001\u7f16\u7801\u5668\uff0c\u5c06\u591a\u6a21\u6001\u4fe1\u606f\uff08\u89c6\u89c9\u548c\u542c\u89c9\uff09\u4e0e\u6587\u672c\u5bf9\u9f50\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u6a21\u578b\u63d0\u51fa\u4e86\u65b0\u7684\u5b89\u5168\u6311\u6218\uff0c\u5373\u5728\u6587\u672c\u4e0a\u5b89\u5168\u5bf9\u9f50\u7684\u6a21\u578b\u662f\u5426\u4e5f\u5bf9\u591a\u6a21\u6001\u8f93\u5165\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u4fdd\u969c\u63aa\u65bd\u3002\u5c3d\u7ba1\u6700\u8fd1\u5bf9\u89c6\u89c9 LMM \u8fdb\u884c\u4e86\u5b89\u5168\u5bf9\u9f50\u7814\u7a76\uff0c\u4f46\u97f3\u9891 LMM \u7684\u5b89\u5168\u6027\u4ecd\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u5728\u4e09\u79cd\u8bbe\u7f6e\u4e0b\u5168\u9762\u5730\u5bf9\u4e94\u79cd\u5148\u8fdb\u7684\u97f3\u9891 LMM \u7684\u5b89\u5168\u6027\u8fdb\u884c\u4e86\u7ea2\u961f\u6d4b\u8bd5\uff1a(i) \u97f3\u9891\u548c\u6587\u672c\u683c\u5f0f\u7684\u6709\u5bb3\u95ee\u9898\uff0c(ii) \u6587\u672c\u683c\u5f0f\u7684\u6709\u5bb3\u95ee\u9898\uff0c\u5e76\u4f34\u6709\u5206\u6563\u6ce8\u610f\u529b\u7684\u975e\u8bed\u97f3\u97f3\u9891\uff0c\u4ee5\u53ca (iii) \u7279\u5b9a\u7684\u8bed\u97f3\u8d8a\u72f1\u3002\u6211\u4eec\u5728\u8fd9\u4e9b\u8bbe\u7f6e\u4e0b\u7684\u7ed3\u679c\u8868\u660e\uff0c\u5f00\u6e90\u97f3\u9891 LMM \u5728\u6709\u5bb3\u97f3\u9891\u95ee\u9898\u4e0a\u7684\u5e73\u5747\u653b\u51fb\u6210\u529f\u7387\u4e3a 69.14%\uff0c\u5e76\u4e14\u5728\u88ab\u975e\u8bed\u97f3\u97f3\u9891\u566a\u97f3\u5206\u6563\u6ce8\u610f\u529b\u65f6\u8868\u73b0\u51fa\u5b89\u5168\u6f0f\u6d1e\u3002\u6211\u4eec\u5728 Gemini-1.5-Pro \u4e0a\u9488\u5bf9\u7279\u5b9a\u8bed\u97f3\u7684\u8d8a\u72f1\u5728\u6709\u5bb3\u67e5\u8be2\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e86 70.67% \u7684\u653b\u51fb\u6210\u529f\u7387\u3002\u6211\u4eec\u63d0\u4f9b\u4e86\u5bf9\u53ef\u80fd\u5bfc\u81f4\u8fd9\u4e9b\u62a5\u544a\u7684\u5b89\u5168\u9519\u4f4d\u7684\u539f\u56e0\u7684\u89c1\u89e3\u3002\u8b66\u544a\uff1a\u672c\u6587\u5305\u542b\u653b\u51fb\u6027\u793a\u4f8b\u3002", "author": "Hao Yang et.al.", "authors": "Hao Yang, Lizhen Qu, Ehsan Shareghi, Gholamreza Haffari", "id": "2410.23861v1", "paper_url": "http://arxiv.org/abs/2410.23861v1", "repo": "null"}}