{"2411.05778": {"publish_time": "2024-11-08", "title": "LLMs as Method Actors: A Model for Prompt Engineering and Architecture", "paper_summary": "We introduce \"Method Actors\" as a mental model for guiding LLM prompt\nengineering and prompt architecture. Under this mental model, LLMs should be\nthought of as actors; prompts as scripts and cues; and LLM responses as\nperformances. We apply this mental model to the task of improving LLM\nperformance at playing Connections, a New York Times word puzzle game that\nprior research identified as a challenging benchmark for evaluating LLM\nreasoning. Our experiments with GPT-4o show that a \"Method Actors\" approach can\nsignificantly improve LLM performance over both a vanilla and \"Chain of\nThoughts\" approach. A vanilla approach solves 27% of Connections puzzles in our\ndataset and a \"Chain of Thoughts\" approach solves 41% of puzzles, whereas our\nstrongest \"Method Actor\" approach solves 86% of puzzles. We also test OpenAI's\nnewest model designed specifically for complex reasoning tasks, o1-preview.\nWhen asked to solve a puzzle all at once, o1-preview solves 79% of Connections\npuzzles in our dataset, and when allowed to build puzzle solutions one guess at\na time over multiple API calls, o1-preview solves 100% of the puzzles.\nIncorporating a \"Method Actor\" prompt architecture increases the percentage of\npuzzles that o1-preview solves perfectly from 76% to 87%.", "paper_summary_zh": "<paragraph>\u6211\u5011\u5f15\u5165\u300c\u65b9\u6cd5\u6f14\u54e1\u300d\u4f5c\u70ba\u6307\u5c0e LLM \u63d0\u793a\u5de5\u7a0b\u548c\u63d0\u793a\u67b6\u69cb\u7684\u5fc3\u667a\u6a21\u578b\u3002\u5728\u9019\u500b\u5fc3\u667a\u6a21\u578b\u4e0b\uff0cLLM \u61c9\u88ab\u8996\u70ba\u6f14\u54e1\uff1b\u63d0\u793a\u70ba\u8173\u672c\u548c\u63d0\u793a\uff1bLLM \u56de\u61c9\u70ba\u8868\u6f14\u3002\u6211\u5011\u5c07\u9019\u500b\u5fc3\u667a\u6a21\u578b\u61c9\u7528\u65bc\u6539\u9032 LLM \u5728\u73a9\u300c\u9023\u7dda\u300d\u904a\u6232\u6642\u7684\u8868\u73fe\uff0c\u9019\u662f\u4e00\u6b3e\u7d10\u7d04\u6642\u5831\u7684\u6587\u5b57\u76ca\u667a\u904a\u6232\uff0c\u5148\u524d\u7684\u7814\u7a76\u6307\u51fa\u9019\u662f\u4e00\u500b\u7528\u65bc\u8a55\u4f30 LLM \u63a8\u7406\u7684\u5177\u6709\u6311\u6230\u6027\u7684\u57fa\u6e96\u3002\u6211\u5011\u5c0d GPT-4o \u9032\u884c\u7684\u5be6\u9a57\u986f\u793a\uff0c\u300c\u65b9\u6cd5\u6f14\u54e1\u300d\u65b9\u6cd5\u53ef\u4ee5\u986f\u8457\u63d0\u5347 LLM \u7684\u8868\u73fe\uff0c\u512a\u65bc\u50b3\u7d71\u65b9\u6cd5\u548c\u300c\u601d\u8003\u93c8\u300d\u65b9\u6cd5\u3002\u50b3\u7d71\u65b9\u6cd5\u5728\u6211\u5011\u7684\u8cc7\u6599\u96c6\u4e2d\u89e3\u958b\u4e86 27% \u7684\u300c\u9023\u7dda\u300d\u76ca\u667a\u904a\u6232\uff0c\u800c\u300c\u601d\u8003\u93c8\u300d\u65b9\u6cd5\u89e3\u958b\u4e86 41% \u7684\u76ca\u667a\u904a\u6232\uff0c\u800c\u6211\u5011\u6700\u5f37\u5927\u7684\u300c\u65b9\u6cd5\u6f14\u54e1\u300d\u65b9\u6cd5\u89e3\u958b\u4e86 86% \u7684\u76ca\u667a\u904a\u6232\u3002\u6211\u5011\u4e5f\u6e2c\u8a66\u4e86 OpenAI \u6700\u65b0\u5c08\u9580\u8a2d\u8a08\u7528\u65bc\u8907\u96dc\u63a8\u7406\u4efb\u52d9\u7684\u6a21\u578b o1-preview\u3002\u7576\u8981\u6c42\u4e00\u6b21\u89e3\u958b\u4e00\u500b\u76ca\u667a\u904a\u6232\u6642\uff0co1-preview \u5728\u6211\u5011\u7684\u8cc7\u6599\u96c6\u4e2d\u89e3\u958b\u4e86 79% \u7684\u300c\u9023\u7dda\u300d\u76ca\u667a\u904a\u6232\uff0c\u800c\u7576\u5141\u8a31\u4e00\u6b21\u731c\u6e2c\u4e00\u500b\u63d0\u793a\uff0c\u900f\u904e\u591a\u6b21 API \u547c\u53eb\u4f86\u5efa\u69cb\u76ca\u667a\u904a\u6232\u89e3\u7b54\u6642\uff0co1-preview \u89e3\u958b\u4e86 100% \u7684\u76ca\u667a\u904a\u6232\u3002\u6574\u5408\u300c\u65b9\u6cd5\u6f14\u54e1\u300d\u63d0\u793a\u67b6\u69cb\u6703\u5c07 o1-preview \u5b8c\u7f8e\u89e3\u958b\u7684\u76ca\u667a\u904a\u6232\u767e\u5206\u6bd4\u5f9e 76% \u63d0\u5347\u81f3 87%\u3002</paragraph>", "author": "Colin Doyle et.al.", "authors": "Colin Doyle", "id": "2411.05778v1", "paper_url": "http://arxiv.org/abs/2411.05778v1", "repo": "null"}}