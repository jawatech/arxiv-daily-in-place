{"2408.13836": {"publish_time": "2024-08-25", "title": "PropSAM: A Propagation-Based Model for Segmenting Any 3D Objects in Multi-Modal Medical Images", "paper_summary": "Volumetric segmentation is crucial for medical imaging but is often\nconstrained by labor-intensive manual annotations and the need for\nscenario-specific model training. Furthermore, existing general segmentation\nmodels are inefficient due to their design and inferential approaches.\nAddressing this clinical demand, we introduce PropSAM, a propagation-based\nsegmentation model that optimizes the use of 3D medical structure information.\nPropSAM integrates a CNN-based UNet for intra-slice processing with a\nTransformer-based module for inter-slice propagation, focusing on structural\nand semantic continuities to enhance segmentation across various modalities.\nDistinctively, PropSAM operates on a one-view prompt, such as a 2D bounding box\nor sketch mask, unlike conventional models that require two-view prompts. It\nhas demonstrated superior performance, significantly improving the Dice\nSimilarity Coefficient (DSC) across 44 medical datasets and various imaging\nmodalities, outperforming models like MedSAM and SegVol with an average DSC\nimprovement of 18.1%. PropSAM also maintains stable predictions despite prompt\ndeviations and varying propagation configurations, confirmed by one-way ANOVA\ntests with P>0.5985 and P>0.6131, respectively. Moreover, PropSAM's efficient\narchitecture enables faster inference speeds (Wilcoxon rank-sum test, P<0.001)\nand reduces user interaction time by 37.8% compared to two-view prompt models.\nIts ability to handle irregular and complex objects with robust performance\nfurther demonstrates its potential in clinical settings, facilitating more\nautomated and reliable medical imaging analyses with minimal retraining.", "paper_summary_zh": "\u9ad4\u7a4d\u5206\u5272\u5c0d\u65bc\u91ab\u5b78\u5f71\u50cf\u81f3\u95dc\u91cd\u8981\uff0c\u4f46\u901a\u5e38\u53d7\u5230\u8017\u8cbb\u5927\u91cf\u4eba\u529b\u7684\u6a19\u8a3b\u548c\u7279\u5b9a\u5834\u666f\u6a21\u578b\u8a13\u7df4\u9700\u6c42\u7684\u9650\u5236\u3002\u6b64\u5916\uff0c\u73fe\u6709\u7684\u901a\u7528\u5206\u5272\u6a21\u578b\u7531\u65bc\u5176\u8a2d\u8a08\u548c\u63a8\u8ad6\u65b9\u6cd5\u800c\u6548\u7387\u4f4e\u4e0b\u3002\u70ba\u4e86\u6eff\u8db3\u9019\u9805\u81e8\u5e8a\u9700\u6c42\uff0c\u6211\u5011\u5f15\u5165\u4e86 PropSAM\uff0c\u9019\u662f\u4e00\u7a2e\u57fa\u65bc\u50b3\u64ad\u7684\u5206\u5272\u6a21\u578b\uff0c\u512a\u5316\u4e86 3D \u91ab\u5b78\u7d50\u69cb\u8cc7\u8a0a\u7684\u4f7f\u7528\u3002PropSAM \u6574\u5408\u4e86\u4e00\u500b\u57fa\u65bc CNN \u7684 UNet\uff0c\u7528\u65bc\u5207\u7247\u5167\u8655\u7406\uff0c\u4ee5\u53ca\u4e00\u500b\u57fa\u65bc Transformer \u7684\u6a21\u7d44\uff0c\u7528\u65bc\u5207\u7247\u9593\u50b3\u64ad\uff0c\u91cd\u9ede\u95dc\u6ce8\u7d50\u69cb\u548c\u8a9e\u7fa9\u9023\u7e8c\u6027\uff0c\u4ee5\u589e\u5f37\u5404\u7a2e\u6a21\u5f0f\u4e0b\u7684\u5206\u5272\u3002\u8207\u9700\u8981\u5169\u8996\u63d0\u793a\u7684\u50b3\u7d71\u6a21\u578b\u4e0d\u540c\uff0cPropSAM \u7368\u7279\u5730\u904b\u4f5c\u65bc\u55ae\u8996\u63d0\u793a\u4e0a\uff0c\u4f8b\u5982 2D \u908a\u754c\u6846\u6216\u8349\u5716\u906e\u7f69\u3002\u5b83\u5df2\u8b49\u660e\u5177\u6709\u512a\u7570\u7684\u6548\u80fd\uff0c\u986f\u8457\u6539\u5584\u4e86 44 \u500b\u91ab\u5b78\u8cc7\u6599\u96c6\u548c\u5404\u7a2e\u5f71\u50cf\u6a21\u5f0f\u4e0b\u7684\u9ab0\u5b50\u76f8\u4f3c\u4fc2\u6578 (DSC)\uff0c\u512a\u65bc MedSAM \u548c SegVol \u7b49\u6a21\u578b\uff0c\u5e73\u5747 DSC \u63d0\u5347\u4e86 18.1%\u3002\u5118\u7ba1\u63d0\u793a\u504f\u5dee\u548c\u50b3\u64ad\u914d\u7f6e\u4e0d\u540c\uff0cPropSAM \u4ecd\u80fd\u7dad\u6301\u7a69\u5b9a\u7684\u9810\u6e2c\uff0c\u9019\u5df2\u901a\u904e\u55ae\u5411 ANOVA \u6e2c\u8a66\u5f97\u5230\u8b49\u5be6\uff0c\u5206\u5225\u70ba P>0.5985 \u548c P>0.6131\u3002\u6b64\u5916\uff0cPropSAM \u7684\u9ad8\u6548\u67b6\u69cb\u80fd\u5be6\u73fe\u66f4\u5feb\u7684\u63a8\u8ad6\u901f\u5ea6\uff08Wilcoxon \u7b49\u7d1a\u548c\u7e3d\u548c\u6aa2\u5b9a\uff0cP<0.001\uff09\uff0c\u4e26\u5c07\u4f7f\u7528\u8005\u4e92\u52d5\u6642\u9593\u6e1b\u5c11\u4e86 37.8%\uff0c\u512a\u65bc\u5169\u8996\u63d0\u793a\u6a21\u578b\u3002\u5b83\u5728\u8655\u7406\u4e0d\u898f\u5247\u548c\u8907\u96dc\u7269\u4ef6\u6642\u80fd\u5c55\u73fe\u51fa\u7a69\u5065\u7684\u6548\u80fd\uff0c\u9032\u4e00\u6b65\u8b49\u660e\u4e86\u5176\u5728\u81e8\u5e8a\u74b0\u5883\u4e2d\u7684\u6f5b\u529b\uff0c\u6709\u52a9\u65bc\u4ee5\u6700\u5c11\u7684\u91cd\u65b0\u8a13\u7df4\u9032\u884c\u66f4\u81ea\u52d5\u5316\u548c\u53ef\u9760\u7684\u91ab\u5b78\u5f71\u50cf\u5206\u6790\u3002", "author": "Zifan Chen et.al.", "authors": "Zifan Chen, Xinyu Nan, Jiazheng Li, Jie Zhao, Haifeng Li, Zilin Lin, Haoshen Li, Heyun Chen, Yiting Liu, Bin Dong, Li Zhang, Lei Tang", "id": "2408.13836v1", "paper_url": "http://arxiv.org/abs/2408.13836v1", "repo": "null"}}