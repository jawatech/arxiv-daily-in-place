{"2409.11363": {"publish_time": "2024-09-17", "title": "CORE-Bench: Fostering the Credibility of Published Research Through a Computational Reproducibility Agent Benchmark", "paper_summary": "AI agents have the potential to aid users on a variety of consequential\ntasks, including conducting scientific research. To spur the development of\nuseful agents, we need benchmarks that are challenging, but more crucially,\ndirectly correspond to real-world tasks of interest. This paper introduces such\na benchmark, designed to measure the accuracy of AI agents in tackling a\ncrucial yet surprisingly challenging aspect of scientific research:\ncomputational reproducibility. This task, fundamental to the scientific\nprocess, involves reproducing the results of a study using the provided code\nand data. We introduce CORE-Bench (Computational Reproducibility Agent\nBenchmark), a benchmark consisting of 270 tasks based on 90 scientific papers\nacross three disciplines (computer science, social science, and medicine).\nTasks in CORE-Bench consist of three difficulty levels and include both\nlanguage-only and vision-language tasks. We provide an evaluation system to\nmeasure the accuracy of agents in a fast and parallelizable way, saving days of\nevaluation time for each run compared to a sequential implementation. We\nevaluated two baseline agents: the general-purpose AutoGPT and a task-specific\nagent called CORE-Agent. We tested both variants using two underlying language\nmodels: GPT-4o and GPT-4o-mini. The best agent achieved an accuracy of 21% on\nthe hardest task, showing the vast scope for improvement in automating routine\nscientific tasks. Having agents that can reproduce existing work is a necessary\nstep towards building agents that can conduct novel research and could verify\nand improve the performance of other research agents. We hope that CORE-Bench\ncan improve the state of reproducibility and spur the development of future\nresearch agents.", "paper_summary_zh": "\u4eba\u5de5\u667a\u6167\u4ee3\u7406\u7a0b\u5f0f\u6709\u6f5b\u529b\u5354\u52a9\u4f7f\u7528\u8005\u57f7\u884c\u5404\u7a2e\u5f8c\u7e8c\u4efb\u52d9\uff0c\u5305\u62ec\u9032\u884c\u79d1\u5b78\u7814\u7a76\u3002\u70ba\u4e86\u523a\u6fc0\u6709\u7528\u7684\u4ee3\u7406\u7a0b\u5f0f\u958b\u767c\uff0c\u6211\u5011\u9700\u8981\u5177\u6709\u6311\u6230\u6027\uff0c\u4f46\u66f4\u91cd\u8981\u7684\u662f\uff0c\u76f4\u63a5\u5c0d\u61c9\u65bc\u611f\u8208\u8da3\u7684\u771f\u5be6\u4e16\u754c\u4efb\u52d9\u7684\u57fa\u6e96\u3002\u672c\u6587\u4ecb\u7d39\u4e86\u4e00\u500b\u9019\u6a23\u7684\u57fa\u6e96\uff0c\u65e8\u5728\u8861\u91cf\u4eba\u5de5\u667a\u6167\u4ee3\u7406\u7a0b\u5f0f\u5728\u61c9\u5c0d\u79d1\u5b78\u7814\u7a76\u4e2d\u4e00\u500b\u81f3\u95dc\u91cd\u8981\u4f46\u4ee4\u4eba\u9a5a\u8a1d\u5730\u5177\u6709\u6311\u6230\u6027\u7684\u65b9\u9762\uff1a\u8a08\u7b97\u91cd\u73fe\u6027\u3002\u6b64\u4efb\u52d9\u5c0d\u65bc\u79d1\u5b78\u904e\u7a0b\u81f3\u95dc\u91cd\u8981\uff0c\u5305\u62ec\u4f7f\u7528\u63d0\u4f9b\u7684\u7a0b\u5f0f\u78bc\u548c\u8cc7\u6599\u91cd\u73fe\u7814\u7a76\u7d50\u679c\u3002\u6211\u5011\u4ecb\u7d39\u4e86 CORE-Bench\uff08\u8a08\u7b97\u91cd\u73fe\u6027\u4ee3\u7406\u7a0b\u5f0f\u57fa\u6e96\uff09\uff0c\u4e00\u500b\u57fa\u6e96\uff0c\u5305\u542b 270 \u500b\u4efb\u52d9\uff0c\u57fa\u65bc\u4e09\u500b\u5b78\u79d1\uff08\u96fb\u8166\u79d1\u5b78\u3001\u793e\u6703\u79d1\u5b78\u548c\u91ab\u5b78\uff09\u7684 90 \u7bc7\u79d1\u5b78\u8ad6\u6587\u3002CORE-Bench \u4e2d\u7684\u4efb\u52d9\u5305\u542b\u4e09\u500b\u96e3\u5ea6\u7b49\u7d1a\uff0c\u5305\u62ec\u50c5\u8a9e\u8a00\u548c\u8996\u89ba\u8a9e\u8a00\u4efb\u52d9\u3002\u6211\u5011\u63d0\u4f9b\u4e00\u500b\u8a55\u4f30\u7cfb\u7d71\uff0c\u4ee5\u5feb\u901f\u4e14\u53ef\u4e26\u884c\u7684\u65b9\u5f0f\u8861\u91cf\u4ee3\u7406\u7a0b\u5f0f\u7684\u6e96\u78ba\u6027\uff0c\u8207\u5faa\u5e8f\u5be6\u4f5c\u76f8\u6bd4\uff0c\u6bcf\u6b21\u57f7\u884c\u53ef\u7bc0\u7701\u6578\u5929\u7684\u8a55\u4f30\u6642\u9593\u3002\u6211\u5011\u8a55\u4f30\u4e86\u5169\u500b\u57fa\u6e96\u4ee3\u7406\u7a0b\u5f0f\uff1a\u901a\u7528 AutoGPT \u548c\u7a31\u70ba CORE-Agent \u7684\u7279\u5b9a\u4efb\u52d9\u4ee3\u7406\u7a0b\u5f0f\u3002\u6211\u5011\u4f7f\u7528\u5169\u500b\u57fa\u790e\u8a9e\u8a00\u6a21\u578b\u6e2c\u8a66\u4e86\u9019\u5169\u7a2e\u8b8a\u9ad4\uff1aGPT-4o \u548c GPT-4o-mini\u3002\u5728\u6700\u56f0\u96e3\u7684\u4efb\u52d9\u4e2d\uff0c\u6700\u597d\u7684\u4ee3\u7406\u7a0b\u5f0f\u9054\u5230\u4e86 21% \u7684\u6e96\u78ba\u5ea6\uff0c\u986f\u793a\u4e86\u5728\u81ea\u52d5\u5316\u4f8b\u884c\u79d1\u5b78\u4efb\u52d9\u4e2d\u6539\u9032\u7684\u5ee3\u95ca\u7bc4\u570d\u3002\u64c1\u6709\u80fd\u5920\u91cd\u73fe\u73fe\u6709\u5de5\u4f5c\u7684\u4ee3\u7406\u7a0b\u5f0f\u662f\u5efa\u69cb\u80fd\u5920\u9032\u884c\u65b0\u7814\u7a76\u4e26\u9a57\u8b49\u548c\u6539\u9032\u5176\u4ed6\u7814\u7a76\u4ee3\u7406\u7a0b\u5f0f\u6548\u80fd\u7684\u4ee3\u7406\u7a0b\u5f0f\u7684\u5fc5\u8981\u6b65\u9a5f\u3002\u6211\u5011\u5e0c\u671b CORE-Bench \u80fd\u5920\u6539\u5584\u91cd\u73fe\u6027\u72c0\u614b\uff0c\u4e26\u523a\u6fc0\u672a\u4f86\u7814\u7a76\u4ee3\u7406\u7a0b\u5f0f\u7684\u958b\u767c\u3002", "author": "Zachary S. Siegel et.al.", "authors": "Zachary S. Siegel, Sayash Kapoor, Nitya Nagdir, Benedikt Stroebl, Arvind Narayanan", "id": "2409.11363v1", "paper_url": "http://arxiv.org/abs/2409.11363v1", "repo": "https://github.com/siegelz/core-bench"}}