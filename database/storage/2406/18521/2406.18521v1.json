{"2406.18521": {"publish_time": "2024-06-26", "title": "CharXiv: Charting Gaps in Realistic Chart Understanding in Multimodal LLMs", "paper_summary": "Chart understanding plays a pivotal role when applying Multimodal Large\nLanguage Models (MLLMs) to real-world tasks such as analyzing scientific papers\nor financial reports. However, existing datasets often focus on oversimplified\nand homogeneous charts with template-based questions, leading to an\nover-optimistic measure of progress. We demonstrate that although open-source\nmodels can appear to outperform strong proprietary models on these benchmarks,\na simple stress test with slightly different charts or questions can\ndeteriorate performance by up to 34.5%. In this work, we propose CharXiv, a\ncomprehensive evaluation suite involving 2,323 natural, challenging, and\ndiverse charts from arXiv papers. CharXiv includes two types of questions: 1)\ndescriptive questions about examining basic chart elements and 2) reasoning\nquestions that require synthesizing information across complex visual elements\nin the chart. To ensure quality, all charts and questions are handpicked,\ncurated, and verified by human experts. Our results reveal a substantial,\npreviously underestimated gap between the reasoning skills of the strongest\nproprietary model (i.e., GPT-4o), which achieves 47.1% accuracy, and the\nstrongest open-source model (i.e., InternVL Chat V1.5), which achieves 29.2%.\nAll models lag far behind human performance of 80.5%, underscoring weaknesses\nin the chart understanding capabilities of existing MLLMs. We hope CharXiv\nfacilitates future research on MLLM chart understanding by providing a more\nrealistic and faithful measure of progress. Project page and leaderboard:\nhttps://charxiv.github.io/", "paper_summary_zh": "<paragraph>\u5728\u5c07\u591a\u6a21\u614b\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM) \u61c9\u7528\u65bc\u5206\u6790\u79d1\u5b78\u8ad6\u6587\u6216\u8ca1\u52d9\u5831\u544a\u7b49\u5be6\u969b\u4efb\u52d9\u6642\uff0c\u5716\u8868\u7406\u89e3\u626e\u6f14\u8457\u81f3\u95dc\u91cd\u8981\u7684\u89d2\u8272\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684\u8cc7\u6599\u96c6\u901a\u5e38\u8457\u91cd\u65bc\u904e\u65bc\u7c21\u5316\u4e14\u540c\u8cea\u7684\u5716\u8868\uff0c\u4e26\u642d\u914d\u57fa\u65bc\u7bc4\u672c\u7684\u554f\u984c\uff0c\u5c0e\u81f4\u9032\u5ea6\u7684\u8861\u91cf\u904e\u65bc\u6a02\u89c0\u3002\u6211\u5011\u8b49\u660e\uff0c\u5118\u7ba1\u958b\u6e90\u6a21\u578b\u5728\u9019\u4e9b\u57fa\u6e96\u6e2c\u8a66\u4e2d\u4f3c\u4e4e\u512a\u65bc\u5f37\u5927\u7684\u5c08\u6709\u6a21\u578b\uff0c\u4f46\u4f7f\u7528\u7565\u6709\u4e0d\u540c\u7684\u5716\u8868\u6216\u554f\u984c\u9032\u884c\u7c21\u55ae\u7684\u58d3\u529b\u6e2c\u8a66\uff0c\u6703\u4f7f\u6548\u80fd\u4e0b\u964d\u591a\u9054 34.5%\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u63d0\u51fa CharXiv\uff0c\u9019\u662f\u4e00\u500b\u5168\u9762\u7684\u8a55\u4f30\u5957\u4ef6\uff0c\u5305\u542b\u4f86\u81ea arXiv \u8ad6\u6587\u7684 2,323 \u500b\u81ea\u7136\u3001\u5177\u6311\u6230\u6027\u548c\u591a\u6a23\u5316\u7684\u5716\u8868\u3002CharXiv \u5305\u542b\u5169\u7a2e\u985e\u578b\u7684\u554f\u984c\uff1a1) \u95dc\u65bc\u6aa2\u67e5\u57fa\u672c\u5716\u8868\u5143\u7d20\u7684\u63cf\u8ff0\u6027\u554f\u984c\uff0c\u4ee5\u53ca 2) \u63a8\u7406\u554f\u984c\uff0c\u9700\u8981\u7d9c\u5408\u5716\u8868\u4e2d\u8907\u96dc\u8996\u89ba\u5143\u7d20\u4e2d\u7684\u8cc7\u8a0a\u3002\u70ba\u4e86\u78ba\u4fdd\u54c1\u8cea\uff0c\u6240\u6709\u5716\u8868\u548c\u554f\u984c\u90fd\u7531\u4eba\u985e\u5c08\u5bb6\u89aa\u81ea\u6311\u9078\u3001\u7b56\u5283\u548c\u9a57\u8b49\u3002\u6211\u5011\u7684\u7d50\u679c\u63ed\u793a\u4e86\u4e00\u500b\u5be6\u8cea\u6027\u7684\u3001\u5148\u524d\u4f4e\u4f30\u7684\u5dee\u8ddd\uff0c\u5b58\u5728\u65bc\u6700\u5f37\u5927\u7684\u5c08\u6709\u6a21\u578b\uff08\u5373 GPT-4o\uff09\u7684\u63a8\u7406\u6280\u80fd\uff08\u9054\u5230 47.1% \u7684\u6e96\u78ba\u5ea6\uff09\u548c\u6700\u5f37\u5927\u7684\u958b\u6e90\u6a21\u578b\uff08\u5373 InternVL Chat V1.5\uff09\u7684\u63a8\u7406\u6280\u80fd\uff08\u9054\u5230 29.2%\uff09\u4e4b\u9593\u3002\u6240\u6709\u6a21\u578b\u90fd\u9060\u9060\u843d\u5f8c\u65bc\u4eba\u985e\u7684 80.5% \u6548\u80fd\uff0c\u7a81\u986f\u4e86\u73fe\u6709 MLLM \u5728\u5716\u8868\u7406\u89e3\u80fd\u529b\u65b9\u9762\u7684\u5f31\u9ede\u3002\u6211\u5011\u5e0c\u671b CharXiv \u80fd\u5920\u900f\u904e\u63d0\u4f9b\u66f4\u5be6\u969b\u4e14\u5fe0\u5be6\u7684\u9032\u5ea6\u8861\u91cf\uff0c\u4fc3\u9032\u672a\u4f86\u95dc\u65bc MLLM \u5716\u8868\u7406\u89e3\u7684\u7814\u7a76\u3002\u5c08\u6848\u9801\u9762\u548c\u6392\u884c\u699c\uff1ahttps://charxiv.github.io/</paragraph>", "author": "Zirui Wang et.al.", "authors": "Zirui Wang, Mengzhou Xia, Luxi He, Howard Chen, Yitao Liu, Richard Zhu, Kaiqu Liang, Xindi Wu, Haotian Liu, Sadhika Malladi, Alexis Chevalier, Sanjeev Arora, Danqi Chen", "id": "2406.18521v1", "paper_url": "http://arxiv.org/abs/2406.18521v1", "repo": "null"}}