{"2408.04174": {"publish_time": "2024-08-08", "title": "wav2graph: A Framework for Supervised Learning Knowledge Graph from Speech", "paper_summary": "Knowledge graphs (KGs) enhance the performance of large language models\n(LLMs) and search engines by providing structured, interconnected data that\nimproves reasoning and context-awareness. However, KGs only focus on text data,\nthereby neglecting other modalities such as speech. In this work, we introduce\nwav2graph, the first framework for supervised learning knowledge graph from\nspeech data. Our pipeline are straightforward: (1) constructing a KG based on\ntranscribed spoken utterances and a named entity database, (2) converting KG\ninto embedding vectors, and (3) training graph neural networks (GNNs) for node\nclassification and link prediction tasks. Through extensive experiments\nconducted in inductive and transductive learning contexts using\nstate-of-the-art GNN models, we provide baseline results and error analysis for\nnode classification and link prediction tasks on human transcripts and\nautomatic speech recognition (ASR) transcripts, including evaluations using\nboth encoder-based and decoder-based node embeddings, as well as monolingual\nand multilingual acoustic pre-trained models. All related code, data, and\nmodels are published online.", "paper_summary_zh": "\u77e5\u8b58\u5716\u8b5c (KG) \u900f\u904e\u63d0\u4f9b\u7d50\u69cb\u5316\u3001\u76f8\u4e92\u9023\u7d50\u7684\u8cc7\u6599\uff0c\u9032\u800c\u6539\u5584\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u548c\u641c\u5c0b\u5f15\u64ce\u7684\u6548\u80fd\uff0c\u63d0\u5347\u63a8\u7406\u548c\u8108\u7d61\u611f\u77e5\u3002\u7136\u800c\uff0cKG \u53ea\u95dc\u6ce8\u6587\u5b57\u8cc7\u6599\uff0c\u56e0\u6b64\u5ffd\u7565\u4e86\u5176\u4ed6\u5f62\u5f0f\uff0c\u4f8b\u5982\u8a9e\u97f3\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39 wav2graph\uff0c\u9019\u662f\u7b2c\u4e00\u500b\u5f9e\u8a9e\u97f3\u8cc7\u6599\u4e2d\u76e3\u7763\u5b78\u7fd2\u77e5\u8b58\u5716\u8b5c\u7684\u67b6\u69cb\u3002\u6211\u5011\u7684\u6d41\u7a0b\u5f88\u76f4\u63a5\uff1a(1) \u6839\u64da\u8f49\u9304\u7684\u53e3\u8a9e\u8868\u9054\u548c\u547d\u540d\u5be6\u9ad4\u8cc7\u6599\u5eab\u5efa\u69cb KG\uff0c(2) \u5c07 KG \u8f49\u63db\u70ba\u5d4c\u5165\u5411\u91cf\uff0c\u4ee5\u53ca (3) \u8a13\u7df4\u5716\u5f62\u795e\u7d93\u7db2\u8def (GNN) \u4ee5\u9032\u884c\u7bc0\u9ede\u5206\u985e\u548c\u9023\u7d50\u9810\u6e2c\u4efb\u52d9\u3002\u900f\u904e\u4f7f\u7528\u6700\u5148\u9032\u7684 GNN \u6a21\u578b\u5728\u6b78\u7d0d\u548c\u8f49\u5c0e\u5b78\u7fd2\u7684\u74b0\u5883\u4e2d\u9032\u884c\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0c\u6211\u5011\u63d0\u4f9b\u7bc0\u9ede\u5206\u985e\u548c\u9023\u7d50\u9810\u6e2c\u4efb\u52d9\u7684\u57fa\u6e96\u7d50\u679c\u548c\u932f\u8aa4\u5206\u6790\uff0c\u5176\u4e2d\u5305\u62ec\u4f7f\u7528\u7de8\u78bc\u5668\u70ba\u57fa\u790e\u548c\u89e3\u78bc\u5668\u70ba\u57fa\u790e\u7684\u7bc0\u9ede\u5d4c\u5165\uff0c\u4ee5\u53ca\u55ae\u8a9e\u548c\u591a\u8a9e\u97f3\u5b78\u9810\u8a13\u7df4\u6a21\u578b\u7684\u8a55\u4f30\u3002\u6240\u6709\u76f8\u95dc\u7a0b\u5f0f\u78bc\u3001\u8cc7\u6599\u548c\u6a21\u578b\u7686\u5df2\u5728\u7dda\u4e0a\u767c\u5e03\u3002", "author": "Khai Le-Duc et.al.", "authors": "Khai Le-Duc, Quy-Anh Dang, Tan-Hanh Pham, Truong-Son Hy", "id": "2408.04174v1", "paper_url": "http://arxiv.org/abs/2408.04174v1", "repo": "null"}}