{"2405.10266": {"publish_time": "2024-05-16", "title": "A Tale of Two Languages: Large-Vocabulary Continuous Sign Language Recognition from Spoken Language Supervision", "paper_summary": "In this work, our goals are two fold: large-vocabulary continuous sign\nlanguage recognition (CSLR), and sign language retrieval. To this end, we\nintroduce a multi-task Transformer model, CSLR2, that is able to ingest a\nsigning sequence and output in a joint embedding space between signed language\nand spoken language text. To enable CSLR evaluation in the large-vocabulary\nsetting, we introduce new dataset annotations that have been manually\ncollected. These provide continuous sign-level annotations for six hours of\ntest videos, and will be made publicly available. We demonstrate that by a\ncareful choice of loss functions, training the model for both the CSLR and\nretrieval tasks is mutually beneficial in terms of performance -- retrieval\nimproves CSLR performance by providing context, while CSLR improves retrieval\nwith more fine-grained supervision. We further show the benefits of leveraging\nweak and noisy supervision from large-vocabulary datasets such as BOBSL, namely\nsign-level pseudo-labels, and English subtitles. Our model significantly\noutperforms the previous state of the art on both tasks.", "paper_summary_zh": "\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u7684\u76ee\u6a19\u6709\u5169\u500b\uff1a\u5927\u8a5e\u5f59\u91cf\u9023\u7e8c\u624b\u8a9e\u8fa8\u8b58 (CSLR) \u548c\u624b\u8a9e\u6aa2\u7d22\u3002\u70ba\u6b64\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u591a\u4efb\u52d9 Transformer \u6a21\u578b CSLR2\uff0c\u5b83\u80fd\u5920\u651d\u53d6\u624b\u8a9e\u5e8f\u5217\u4e26\u5728\u624b\u8a9e\u548c\u53e3\u8a9e\u6587\u672c\u4e4b\u9593\u7684\u806f\u5408\u5d4c\u5165\u7a7a\u9593\u4e2d\u8f38\u51fa\u3002\u70ba\u4e86\u5728\u5927\u91cf\u8a5e\u5f59\u7684\u8a2d\u5b9a\u4e2d\u555f\u7528 CSLR \u8a55\u4f30\uff0c\u6211\u5011\u5f15\u5165\u4e86\u5df2\u624b\u52d5\u6536\u96c6\u7684\u65b0\u8cc7\u6599\u96c6\u8a3b\u89e3\u3002\u9019\u4e9b\u8a3b\u89e3\u70ba\u516d\u5c0f\u6642\u7684\u6e2c\u8a66\u5f71\u7247\u63d0\u4f9b\u4e86\u9023\u7e8c\u7684\u624b\u8a9e\u7d1a\u5225\u8a3b\u89e3\uff0c\u4e26\u5c07\u516c\u958b\u63d0\u4f9b\u3002\u6211\u5011\u8b49\u660e\uff0c\u900f\u904e\u4ed4\u7d30\u9078\u64c7\u640d\u5931\u51fd\u6578\uff0c\u91dd\u5c0d CSLR \u548c\u6aa2\u7d22\u4efb\u52d9\u8a13\u7df4\u6a21\u578b\u5728\u6548\u80fd\u65b9\u9762\u662f\u4e92\u5229\u7684\u2014\u2014\u6aa2\u7d22\u900f\u904e\u63d0\u4f9b\u4e0a\u4e0b\u6587\u4f86\u6539\u5584 CSLR \u6548\u80fd\uff0c\u800c CSLR \u5247\u900f\u904e\u66f4\u7d30\u7dfb\u7684\u76e3\u7763\u4f86\u6539\u5584\u6aa2\u7d22\u3002\u6211\u5011\u9032\u4e00\u6b65\u5c55\u793a\u4e86\u5229\u7528\u4f86\u81ea\u5927\u8a5e\u5f59\u91cf\u8cc7\u6599\u96c6\uff08\u4f8b\u5982 BOBSL\uff09\u7684\u5f31\u76e3\u7763\u548c\u96dc\u8a0a\u76e3\u7763\u7684\u597d\u8655\uff0c\u5373\u624b\u8a9e\u7d1a\u5225\u7684\u507d\u6a19\u7c64\u548c\u82f1\u6587\u5b57\u5e55\u3002\u6211\u5011\u7684\u6a21\u578b\u5728\u5169\u500b\u4efb\u52d9\u4e0a\u90fd\u986f\u8457\u512a\u65bc\u5148\u524d\u7684\u6280\u8853\u6c34\u6e96\u3002", "author": "Charles Raude et.al.", "authors": "Charles Raude, K R Prajwal, Liliane Momeni, Hannah Bull, Samuel Albanie, Andrew Zisserman, G\u00fcl Varol", "id": "2405.10266v1", "paper_url": "http://arxiv.org/abs/2405.10266v1", "repo": "null"}}