
### LLM
|Publish Date|Title|Authors|PDF|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-04-26**|**Probabilistic Inference in Language Models via Twisted Sequential Monte Carlo**|Stephen Zhao et.al.|[2404.17546v1](http://arxiv.org/abs/2404.17546v1)|null|
|**2024-04-26**|**Large Language Model Agent as a Mechanical Designer**|Yayati Jadhav et.al.|[2404.17525v1](http://arxiv.org/abs/2404.17525v1)|null|
|**2024-04-26**|**On the Use of Large Language Models to Generate Capability Ontologies**|Luis Miguel Vieira da Silva et.al.|[2404.17524v2](http://arxiv.org/abs/2404.17524v2)|null|
|**2024-04-26**|**Enhancing Legal Compliance and Regulation Analysis with Large Language Models**|Shabnam Hassani et.al.|[2404.17522v1](http://arxiv.org/abs/2404.17522v1)|null|
|**2024-04-26**|**A Comprehensive Evaluation on Event Reasoning of Large Language Models**|Zhengwei Tao et.al.|[2404.17513v1](http://arxiv.org/abs/2404.17513v1)|[link](https://github.com/tzwwww/ev2)|
|**2024-04-26**|**Causally Abstracted Multi-armed Bandits**|Fabio Massimo Zennaro et.al.|[2404.17493v1](http://arxiv.org/abs/2404.17493v1)|null|
|**2024-04-26**|**Tabular Data Contrastive Learning via Class-Conditioned and Feature-Correlation Based Augmentation**|Wei Cui et.al.|[2404.17489v1](http://arxiv.org/abs/2404.17489v1)|[link](https://github.com/willtop/tabular-class-conditioned-ssl)|
|**2024-04-26**|**Conformal Prediction with Learned Features**|Shayan Kiyani et.al.|[2404.17487v1](http://arxiv.org/abs/2404.17487v1)|null|
|**2024-04-26**|**ReproHum #0087-01: Human Evaluation Reproduction Report for Generating Fact Checking Explanations**|Tyler Loakman et.al.|[2404.17481v1](http://arxiv.org/abs/2404.17481v1)|null|
|**2024-04-26**|**CEval: A Benchmark for Evaluating Counterfactual Text Generation**|Van Bach Nguyen et.al.|[2404.17475v1](http://arxiv.org/abs/2404.17475v1)|null|
|**2024-04-26**|**Ruffle&Riley: Insights from Designing and Evaluating a Large Language Model-Based Conversational Tutoring System**|Robin Schmucker et.al.|[2404.17460v1](http://arxiv.org/abs/2404.17460v1)|null|
|**2024-04-26**|**Domain Adaptive and Fine-grained Anomaly Detection for Single-cell Sequencing Data and Beyond**|Kaichen Xu et.al.|[2404.17454v1](http://arxiv.org/abs/2404.17454v1)|[link](https://github.com/catchxu/acsleuth)|
|**2024-04-26**|**"ChatGPT Is Here to Help, Not to Replace Anybody" -- An Evaluation of Students' Opinions On Integrating ChatGPT In CS Courses**|Bruno Pereira Cipriano et.al.|[2404.17443v1](http://arxiv.org/abs/2404.17443v1)|null|
|**2024-04-26**|**Real-World Deployment of a Hierarchical Uncertainty-Aware Collaborative Multiagent Planning System**|Martina Stadler Kurtz et.al.|[2404.17438v1](http://arxiv.org/abs/2404.17438v1)|null|
|**2024-04-26**|**Evaluation of Geographical Distortions in Language Models: A Crucial Step Towards Equitable Representations**|Rémy Decoupes et.al.|[2404.17401v1](http://arxiv.org/abs/2404.17401v1)|null|
|**2024-04-26**|**Spatial-frequency Dual-Domain Feature Fusion Network for Low-Light Remote Sensing Image Enhancement**|Zishu Yao et.al.|[2404.17400v1](http://arxiv.org/abs/2404.17400v1)|null|
|**2024-04-26**|**Child Speech Recognition in Human-Robot Interaction: Problem Solved?**|Ruben Janssens et.al.|[2404.17394v1](http://arxiv.org/abs/2404.17394v1)|null|
|**2024-04-26**|**M3BAT: Unsupervised Domain Adaptation for Multimodal Mobile Sensing with Multi-Branch Adversarial Training**|Lakmal Meegahapola et.al.|[2404.17391v1](http://arxiv.org/abs/2404.17391v1)|null|
|**2024-04-26**|**Assessing the Potential of AI for Spatially Sensitive Nature-Related Financial Risks**|Steven Reece et.al.|[2404.17369v1](http://arxiv.org/abs/2404.17369v1)|null|
|**2024-04-26**|**Similarity Equivariant Graph Neural Networks for Homogenization of Metamaterials**|Fleur Hendriks et.al.|[2404.17365v1](http://arxiv.org/abs/2404.17365v1)|null|
|**2024-04-26**|**A Bionic Natural Language Parser Equivalent to a Pushdown Automaton**|Zhenghao Wei et.al.|[2404.17343v1](http://arxiv.org/abs/2404.17343v1)|null|
|**2024-04-26**|**Can a Multichoice Dataset be Repurposed for Extractive Question Answering?**|Teresa Lynn et.al.|[2404.17342v1](http://arxiv.org/abs/2404.17342v1)|null|
|**2024-04-26**|**Metronome: tracing variation in poetic meters via local sequence alignment**|Ben Nagy et.al.|[2404.17337v1](http://arxiv.org/abs/2404.17337v1)|[link](https://github.com/bnagy/metronome-paper)|
|**2024-04-26**|**Introducing cosmosGPT: Monolingual Training for Turkish Language Models**|H. Toprak Kesgin et.al.|[2404.17336v1](http://arxiv.org/abs/2404.17336v1)|null|
|**2024-04-26**|**A Novel Spike Transformer Network for Depth Estimation from Event Cameras via Cross-modality Knowledge Distillation**|Xin Zhang et.al.|[2404.17335v1](http://arxiv.org/abs/2404.17335v1)|null|
|**2024-04-26**|**Part-Guided 3D RL for Sim2Real Articulated Object Manipulation**|Pengwei Xie et.al.|[2404.17302v1](http://arxiv.org/abs/2404.17302v1)|[link](https://github.com/thu-vclab/part-guided-3d-rl-for-sim2real-articulated-object-manipulation)|
|**2024-04-26**|**When to Trust LLMs: Aligning Confidence with Response Quality**|Shuchang Tao et.al.|[2404.17287v1](http://arxiv.org/abs/2404.17287v1)|null|
|**2024-04-26**|**Reinforcement Retrieval Leveraging Fine-grained Feedback for Fact Checking News Claims with Black-Box LLM**|Xuan Zhang et.al.|[2404.17283v1](http://arxiv.org/abs/2404.17283v1)|[link](https://github.com/jadecurl/ffrr)|
|**2024-04-26**|**Enhancing Privacy and Security of Autonomous UAV Navigation**|Vatsal Aggarwal et.al.|[2404.17225v1](http://arxiv.org/abs/2404.17225v1)|null|
|**2024-04-26**|**Prompting Techniques for Reducing Social Bias in LLMs through System 1 and System 2 Cognitive Processes**|Mahammed Kamruzzaman et.al.|[2404.17218v1](http://arxiv.org/abs/2404.17218v1)|null|
|**2024-04-26**|**Prompting Towards Alleviating Code-Switched Data Scarcity in Under-Resourced Languages with GPT as a Pivot**|Michelle Terblanche et.al.|[2404.17216v1](http://arxiv.org/abs/2404.17216v1)|null|
|**2024-04-26**|**Human-Imperceptible Retrieval Poisoning Attacks in LLM-Powered Applications**|Quan Zhang et.al.|[2404.17196v1](http://arxiv.org/abs/2404.17196v1)|null|
|**2024-04-26**|**TIGQA:An Expert Annotated Question Answering Dataset in Tigrinya**|Hailay Teklehaymanot et.al.|[2404.17194v1](http://arxiv.org/abs/2404.17194v1)|null|
|**2024-04-26**|**MCSDNet: Mesoscale Convective System Detection Network via Multi-scale Spatiotemporal Information**|Jiajun Liang et.al.|[2404.17186v1](http://arxiv.org/abs/2404.17186v1)|null|
|**2024-04-26**|**A Unified Label-Aware Contrastive Learning Framework for Few-Shot Named Entity Recognition**|Haojie Zhang et.al.|[2404.17178v1](http://arxiv.org/abs/2404.17178v1)|null|
|**2024-04-26**|**Exploring Beyond Logits: Hierarchical Dynamic Labeling Based on Embeddings for Semi-Supervised Classification**|Yanbiao Ma et.al.|[2404.17173v1](http://arxiv.org/abs/2404.17173v1)|null|
|**2024-04-26**|**Quantifying Memorization of Domain-Specific Pre-trained Language Models using Japanese Newspaper and Paywalls**|Shotaro Ishihara et.al.|[2404.17143v1](http://arxiv.org/abs/2404.17143v1)|null|
|**2024-04-26**|**Small Language Models Need Strong Verifiers to Self-Correct Reasoning**|Yunxiang Zhang et.al.|[2404.17140v1](http://arxiv.org/abs/2404.17140v1)|null|
|**2024-04-26**|**Automated Data Visualization from Natural Language via Large Language Models: An Exploratory Study**|Yang Wu et.al.|[2404.17136v1](http://arxiv.org/abs/2404.17136v1)|null|
|**2024-04-26**|**Process Mining Embeddings: Learning Vector Representations for Petri Nets**|Juan G. Colonna et.al.|[2404.17129v1](http://arxiv.org/abs/2404.17129v1)|[link](https://github.com/juancolonna/petrinet2vec)|
|**2024-04-26**|**Deep Evidential Learning for Dose Prediction**|Hai Siong Tan et.al.|[2404.17126v1](http://arxiv.org/abs/2404.17126v1)|null|
|**2024-04-26**|**Text Sentiment Analysis and Classification Based on Bidirectional Gated Recurrent Units (GRUs) Model**|Wei Xu et.al.|[2404.17123v1](http://arxiv.org/abs/2404.17123v1)|null|
|**2024-04-26**|**2M-NER: Contrastive Learning for Multilingual and Multimodal NER with Language and Modal Fusion**|Dongsheng Wang et.al.|[2404.17122v1](http://arxiv.org/abs/2404.17122v1)|null|
|**2024-04-26**|**Talking Nonsense: Probing Large Language Models' Understanding of Adversarial Gibberish Inputs**|Valeriia Cherepanova et.al.|[2404.17120v2](http://arxiv.org/abs/2404.17120v2)|null|
|**2024-04-26**|**CLARE: Cognitive Load Assessment in REaltime with Multimodal Data**|Anubhav Bhatti et.al.|[2404.17098v1](http://arxiv.org/abs/2404.17098v1)|null|
|**2024-04-25**|**CyNetDiff -- A Python Library for Accelerated Implementation of Network Diffusion Models**|Eliot W. Robson et.al.|[2404.17059v1](http://arxiv.org/abs/2404.17059v1)|null|
|**2024-04-25**|**Agentive Permissions in Multiagent Systems**|Qi Shi et.al.|[2404.17053v1](http://arxiv.org/abs/2404.17053v1)|null|
|**2024-04-25**|**Generative AI in Color-Changing Systems: Re-Programmable 3D Object Textures with Material and Design Constraints**|Yunyi Zhu et.al.|[2404.17028v1](http://arxiv.org/abs/2404.17028v1)|null|
|**2024-04-25**|**Player-Driven Emergence in LLM-Driven Game Narrative**|Xiangyu Peng et.al.|[2404.17027v1](http://arxiv.org/abs/2404.17027v1)|null|
|**2024-04-25**|**Generating Minimalist Adversarial Perturbations to Test Object-Detection Models: An Adaptive Multi-Metric Evolutionary Search Approach**|Cristopher McIntyre-Garcia et.al.|[2404.17020v1](http://arxiv.org/abs/2404.17020v1)|[link](https://github.com/cmcin019/tm-evo)|
|**2024-04-25**|**Türkçe Dil Modellerinin Performans Karşılaştırması Performance Comparison of Turkish Language Models**|Eren Dogan et.al.|[2404.17010v1](http://arxiv.org/abs/2404.17010v1)|null|
|**2024-04-25**|**Evaluating Class Membership Relations in Knowledge Graphs using Large Language Models**|Bradley P. Allen et.al.|[2404.17000v1](http://arxiv.org/abs/2404.17000v1)|[link](https://github.com/bradleypallen/evaluating-kg-class-memberships-using-llms)|
|**2024-04-25**|**IDIL: Imitation Learning of Intent-Driven Expert Behavior**|Sangwon Seo et.al.|[2404.16989v1](http://arxiv.org/abs/2404.16989v1)|null|
|**2024-04-25**|**Examining the robustness of LLM evaluation to the distributional assumptions of benchmarks**|Melissa Ailem et.al.|[2404.16966v1](http://arxiv.org/abs/2404.16966v1)|null|
|**2024-04-25**|**A Closer Look at Classification Evaluation Metrics and a Critical Reflection of Common Evaluation Practice**|Juri Opitz et.al.|[2404.16958v1](http://arxiv.org/abs/2404.16958v1)|null|
|**2024-04-25**|**Taming False Positives in Out-of-Distribution Detection with Human Feedback**|Harit Vishwakarma et.al.|[2404.16954v1](http://arxiv.org/abs/2404.16954v1)|[link](https://github.com/2454511550lin/tamefalsepositives-ood)|
|**2024-04-25**|**Make-it-Real: Unleashing Large Multimodal Model's Ability for Painting 3D Objects with Realistic Materials**|Ye Fang et.al.|[2404.16829v2](http://arxiv.org/abs/2404.16829v2)|null|
|**2024-04-25**|**A Survey of Generative Search and Recommendation in the Era of Large Language Models**|Yongqi Li et.al.|[2404.16924v1](http://arxiv.org/abs/2404.16924v1)|null|
|**2024-04-25**|**IndicGenBench: A Multilingual Benchmark to Evaluate Generation Capabilities of LLMs on Indic Languages**|Harman Singh et.al.|[2404.16816v1](http://arxiv.org/abs/2404.16816v1)|null|
|**2024-04-25**|**Make Your LLM Fully Utilize the Context**|Shengnan An et.al.|[2404.16811v2](http://arxiv.org/abs/2404.16811v2)|[link](https://github.com/microsoft/FILM)|
|**2024-04-25**|**Improving Diversity of Commonsense Generation by Large Language Models via In-Context Learning**|Tianhui Zhang et.al.|[2404.16807v1](http://arxiv.org/abs/2404.16807v1)|null|
|**2024-04-25**|**A Short Survey of Human Mobility Prediction in Epidemic Modeling from Transformers to LLMs**|Christian N. Mayemba et.al.|[2404.16921v1](http://arxiv.org/abs/2404.16921v1)|null|
|**2024-04-25**|**AAPL: Adding Attributes to Prompt Learning for Vision-Language Models**|Gahyeon Kim et.al.|[2404.16804v1](http://arxiv.org/abs/2404.16804v1)|[link](https://github.com/Gahyeonkim09/AAPL)|
|**2024-04-25**|**Weak-to-Strong Extrapolation Expedites Alignment**|Chujie Zheng et.al.|[2404.16792v1](http://arxiv.org/abs/2404.16792v1)|[link](https://github.com/chujiezheng/llm-extrapolation)|
|**2024-04-25**|**Continual Learning of Large Language Models: A Comprehensive Survey**|Haizhou Shi et.al.|[2404.16789v1](http://arxiv.org/abs/2404.16789v1)|[link](https://github.com/wang-ml-lab/llm-continual-learning-survey)|
|**2024-04-25**|**Modeling Selective Feature Attention for Representation-based Siamese Text Matching**|Jianxiang Zang et.al.|[2404.16776v1](http://arxiv.org/abs/2404.16776v1)|[link](https://github.com/hggzjx/sfa)|
|**2024-04-25**|**REBEL: Reinforcement Learning via Regressing Relative Rewards**|Zhaolin Gao et.al.|[2404.16767v1](http://arxiv.org/abs/2404.16767v1)|null|
|**2024-04-25**|**Prefix Text as a Yarn: Eliciting Non-English Alignment in Foundation Language Model**|Runzhe Zhan et.al.|[2404.16766v1](http://arxiv.org/abs/2404.16766v1)|null|
|**2024-04-25**|**Automatic Speech Recognition System-Independent Word Error Rate Estimation**|Chanho Park et.al.|[2404.16743v2](http://arxiv.org/abs/2404.16743v2)|null|
|**2024-04-25**|**Distilling Privileged Information for Dubins Traveling Salesman Problems with Neighborhoods**|Min Kyu Shin et.al.|[2404.16721v1](http://arxiv.org/abs/2404.16721v1)|null|
|**2024-04-25**|**Features Fusion for Dual-View Mammography Mass Detection**|Arina Varlamova et.al.|[2404.16718v1](http://arxiv.org/abs/2404.16718v1)|null|
|**2024-04-25**|**Embracing Diversity: Interpretable Zero-shot classification beyond one vector per class**|Mazda Moayeri et.al.|[2404.16717v1](http://arxiv.org/abs/2404.16717v1)|null|
|**2024-04-25**|**LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding**|Mostafa Elhoushi et.al.|[2404.16710v2](http://arxiv.org/abs/2404.16710v2)|null|
|**2024-04-25**|**Cooperate or Collapse: Emergence of Sustainability Behaviors in a Society of LLM Agents**|Giorgio Piatti et.al.|[2404.16698v1](http://arxiv.org/abs/2404.16698v1)|null|
|**2024-04-25**|**Influence of Solution Efficiency and Valence of Instruction on Additive and Subtractive Solution Strategies in Humans and GPT-4**|Lydia Uhler et.al.|[2404.16692v1](http://arxiv.org/abs/2404.16692v1)|null|
|**2024-04-25**|**Prediction Is All MoE Needs: Expert Load Distribution Goes from Fluctuating to Stabilizing**|Peizhuang Cong et.al.|[2404.16914v1](http://arxiv.org/abs/2404.16914v1)|null|
|**2024-04-25**|**DE-CGAN: Boosting rTMS Treatment Prediction with Diversity Enhancing Conditional Generative Adversarial Networks**|Matthew Squires et.al.|[2404.16913v1](http://arxiv.org/abs/2404.16913v1)|null|
|**2024-04-25**|**EmoVIT: Revolutionizing Emotion Insights with Visual Instruction Tuning**|Hongxia Xie et.al.|[2404.16670v1](http://arxiv.org/abs/2404.16670v1)|[link](https://github.com/aimmemotion/emovit)|
|**2024-04-25**|**Formal Specification, Assessment, and Enforcement of Fairness for Generative AIs**|Chih-Hong Cheng et.al.|[2404.16663v2](http://arxiv.org/abs/2404.16663v2)|[link](https://github.com/semta-group/fairgenai)|
|**2024-04-25**|**Benchmarking Mobile Device Control Agents across Diverse Configurations**|Juyong Lee et.al.|[2404.16660v1](http://arxiv.org/abs/2404.16660v1)|null|
|**2024-04-25**|**ProbGate at EHRSQL 2024: Enhancing SQL Query Generation Accuracy through Probabilistic Threshold Filtering and Error Handling**|Sangryul Kim et.al.|[2404.16659v1](http://arxiv.org/abs/2404.16659v1)|[link](https://github.com/venzino-han/probgate_ehrsql)|
|**2024-04-25**|**A Self-Organizing Clustering System for Unsupervised Distribution Shift Detection**|Sebastián Basterrech et.al.|[2404.16656v1](http://arxiv.org/abs/2404.16656v1)|null|
|**2024-04-25**|**Análise de ambiguidade linguística em modelos de linguagem de grande escala (LLMs)**|Lavínia de Carvalho Moraes et.al.|[2404.16653v1](http://arxiv.org/abs/2404.16653v1)|null|
|**2024-04-25**|**Tele-FLM Technical Report**|Xiang Li et.al.|[2404.16645v1](http://arxiv.org/abs/2404.16645v1)|null|
|**2024-04-25**|**Legal Aspects for Software Developers Interested in Generative AI Applications**|Steffen Herbold et.al.|[2404.16630v1](http://arxiv.org/abs/2404.16630v1)|null|
|**2024-04-25**|**Incorporating Lexical and Syntactic Knowledge for Unsupervised Cross-Lingual Transfer**|Jianyu Zheng et.al.|[2404.16627v1](http://arxiv.org/abs/2404.16627v1)|[link](https://github.com/tian14267/ls_mbert)|
|**2024-04-25**|**Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare**|Emre Can Acikgoz et.al.|[2404.16621v1](http://arxiv.org/abs/2404.16621v1)|null|
|**2024-04-25**|**SFMViT: SlowFast Meet ViT in Chaotic World**|Jiaying Lin et.al.|[2404.16609v1](http://arxiv.org/abs/2404.16609v1)|[link](https://github.com/jfightyr/slowfast-meet-vit)|
|**2024-04-25**|**Understanding Privacy Risks of Embeddings Induced by Large Language Models**|Zhihao Zhu et.al.|[2404.16587v1](http://arxiv.org/abs/2404.16587v1)|null|
|**2024-04-25**|**Neural Interaction Energy for Multi-Agent Trajectory Prediction**|Kaixin Shen et.al.|[2404.16579v1](http://arxiv.org/abs/2404.16579v1)|null|
|**2024-04-25**|**Exploring Internal Numeracy in Language Models: A Case Study on ALBERT**|Ulme Wennberg et.al.|[2404.16574v1](http://arxiv.org/abs/2404.16574v1)|null|
|**2024-04-25**|**Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark**|Elizabeth Fons et.al.|[2404.16563v1](http://arxiv.org/abs/2404.16563v1)|null|
|**2024-04-25**|**Evolve Cost-aware Acquisition Functions Using Large Language Models**|Yiming Yao et.al.|[2404.16906v1](http://arxiv.org/abs/2404.16906v1)|null|
|**2024-04-25**|**DeepKalPose: An Enhanced Deep-Learning Kalman Filter for Temporally Consistent Monocular Vehicle Pose Estimation**|Leandro Di Bella et.al.|[2404.16558v1](http://arxiv.org/abs/2404.16558v1)|null|
|**2024-04-25**|**Energy-Latency Manipulation of Multi-modal Large Language Models via Verbose Samples**|Kuofeng Gao et.al.|[2404.16557v1](http://arxiv.org/abs/2404.16557v1)|null|
|**2024-04-25**|**Developing Acoustic Models for Automatic Speech Recognition in Swedish**|Giampiero Salvi et.al.|[2404.16547v1](http://arxiv.org/abs/2404.16547v1)|null|
|**2024-04-25**|**Samsung Research China-Beijing at SemEval-2024 Task 3: A multi-stage framework for Emotion-Cause Pair Extraction in Conversations**|Shen Zhang et.al.|[2404.16905v1](http://arxiv.org/abs/2404.16905v1)|null|
|**2024-04-25**|**SIDEs: Separating Idealization from Deceptive Explanations in xAI**|Emily Sullivan et.al.|[2404.16534v1](http://arxiv.org/abs/2404.16534v1)|null|
|**2024-04-25**|**Global Concept Explanations for Graphs by Contrastive Learning**|Jonas Teufel et.al.|[2404.16532v1](http://arxiv.org/abs/2404.16532v1)|[link](https://github.com/aimat-lab/megan_global_explanations)|
|**2024-04-25**|**Building a Japanese Document-Level Relation Extraction Dataset Assisted by Cross-Lingual Transfer**|Youmi Ma et.al.|[2404.16506v1](http://arxiv.org/abs/2404.16506v1)|null|

#### Abstracts
##### **Probabilistic Inference in Language Models via Twisted Sequential Monte Carlo**
2404.17546v1 by Stephen Zhao,Rob Brekelmans,Alireza Makhzani,Roger Grosse

Numerous capability and safety techniques of Large Language Models (LLMs),
including RLHF, automated red-teaming, prompt engineering, and infilling, can
be cast as sampling from an unnormalized target distribution defined by a given
reward or potential function over the full sequence. In this work, we leverage
the rich toolkit of Sequential Monte Carlo (SMC) for these probabilistic
inference problems. In particular, we use learned twist functions to estimate
the expected future value of the potential at each timestep, which enables us
to focus inference-time computation on promising partial sequences. We propose
a novel contrastive method for learning the twist functions, and establish
connections with the rich literature of soft reinforcement learning. As a
complementary application of our twisted SMC framework, we present methods for
evaluating the accuracy of language model inference techniques using novel
bidirectional SMC bounds on the log partition function. These bounds can be
used to estimate the KL divergence between the inference and target
distributions in both directions. We apply our inference evaluation techniques
to show that twisted SMC is effective for sampling undesirable outputs from a
pretrained model (a useful component of harmlessness training and automated
red-teaming), generating reviews with varied sentiment, and performing
infilling tasks.

摘要：大型語言模型 (LLM) 的許多功能和安全技術，包括 RLHF、自動紅隊、提示工程和填充，可以視為從由給定獎勵或潛在函數定義的非正規化目標分佈中進行抽樣，函數遍及整個序列。在這項工作中，我們利用序貫蒙地卡羅 (SMC) 的豐富工具包來解決這些機率推論問題。特別是，我們使用學習的扭曲函數來估計每個時間步長中潛力的預期未來值，這使我們能夠將推論時間運算集中在有希望的部分序列上。我們提出了一種新穎的反差方法來學習扭曲函數，並建立與軟強化學習豐富文獻的聯繫。作為我們扭曲的 SMC 框架的補充應用，我們提出了使用對數分割函數上的新雙向 SMC 界限評估語言模型推論技術準確性的方法。這些界限可用於估計推論分佈和目標分佈之間的 KL 散度，朝兩個方向進行。我們應用我們的推論評估技術來表明，扭曲的 SMC 可有效地從預訓練模型中抽樣不需要的輸出（無害性訓練和自動紅隊的有用組成部分），生成具有不同情緒的評論，並執行填充任務。

##### **Large Language Model Agent as a Mechanical Designer**
2404.17525v1 by Yayati Jadhav,Amir Barati Farimani

Conventional mechanical design paradigms rely on experts systematically
refining concepts through experience-guided modification and FEA to meet
specific requirements. However, this approach can be time-consuming and heavily
dependent on prior knowledge and experience. While numerous machine learning
models have been developed to streamline this intensive and expert-driven
iterative process, these methods typically demand extensive training data and
considerable computational resources. Furthermore, methods based on deep
learning are usually restricted to the specific domains and tasks for which
they were trained, limiting their applicability across different tasks. This
creates a trade-off between the efficiency of automation and the demand for
resources. In this study, we present a novel approach that integrates
pre-trained LLMs with a FEM module. The FEM module evaluates each design and
provides essential feedback, guiding the LLMs to continuously learn, plan,
generate, and optimize designs without the need for domain-specific training.
We demonstrate the effectiveness of our proposed framework in managing the
iterative optimization of truss structures, showcasing its capability to reason
about and refine designs according to structured feedback and criteria. Our
results reveal that these LLM-based agents can successfully generate truss
designs that comply with natural language specifications with a success rate of
up to 90%, which varies according to the applied constraints. By employing
prompt-based optimization techniques we show that LLM based agents exhibit
optimization behavior when provided with solution-score pairs to iteratively
refine designs to meet specifications. This ability of LLM agents to produce
viable designs and optimize them based on their inherent reasoning capabilities
highlights their potential to develop and implement effective design strategies
autonomously.

摘要：<paragraph>傳統機械設計範例仰賴專家系統性地透過經驗引導的修改和有限元素分析 (FEA) 來優化概念，以符合特定需求。然而，這種方法可能很耗時，而且高度依賴於先前的知識和經驗。儘管已開發出許多機器學習模型來簡化這個密集且由專家驅動的迭代流程，但這些方法通常需要大量的訓練資料和可觀的運算資源。此外，基於深度學習的方法通常僅限於它們受訓的特定領域和任務，限制了它們在不同任務之間的適用性。這造成了自動化效率和資源需求之間的權衡。在本研究中，我們提出了一種創新的方法，將預先訓練的 LLM 與有限元素分析模組整合在一起。有限元素分析模組會評估每個設計，並提供必要的回饋，引導 LLM 持續學習、規劃、產生和最佳化設計，而無需進行特定領域的訓練。我們展示了所提出的架構在管理桁架結構的迭代最佳化方面的效能，展示了其根據結構化回饋和準則推理和優化設計的能力。我們的結果顯示，這些基於 LLM 的代理程式可以成功產生符合自然語言規格的桁架設計，成功率高達 90%，具體取決於所套用的約束。透過採用基於提示的最佳化技術，我們展示了 LLM 基於代理程式在提供解決方案分數對以迭代方式優化設計以符合規格時，會展現最佳化行為。LLM 代理程式能夠產生可行的設計並根據其內在推理能力最佳化這些設計，突顯了它們自主開發和實施有效設計策略的潛力。</paragraph>

##### **On the Use of Large Language Models to Generate Capability Ontologies**
2404.17524v2 by Luis Miguel Vieira da Silva,Aljosha Köcher,Felix Gehlhoff,Alexander Fay

Capability ontologies are increasingly used to model functionalities of
systems or machines. The creation of such ontological models with all
properties and constraints of capabilities is very complex and can only be done
by ontology experts. However, Large Language Models (LLMs) have shown that they
can generate machine-interpretable models from natural language text input and
thus support engineers / ontology experts. Therefore, this paper investigates
how LLMs can be used to create capability ontologies. We present a study with a
series of experiments in which capabilities with varying complexities are
generated using different prompting techniques and with different LLMs. Errors
in the generated ontologies are recorded and compared. To analyze the quality
of the generated ontologies, a semi-automated approach based on RDF syntax
checking, OWL reasoning, and SHACL constraints is used. The results of this
study are very promising because even for complex capabilities, the generated
ontologies are almost free of errors.

摘要：能力本体论越来越多地用于建模系统或机器的功能。创建具有所有功能属性和约束的此类本体模型非常复杂，只能由本体专家完成。然而，大语言模型 (LLM) 已表明，它们可以从自然语言文本输入生成机器可解释的模型，从而为工程师/本体专家提供支持。因此，本文研究了如何使用 LLM 来创建能力本体。我们提出了一项研究，其中进行了一系列实验，在这些实验中，使用不同的提示技术和不同的 LLM 生成了具有不同复杂性的能力。记录并比较了生成本体中的错误。为了分析生成本体的质量，使用了基于 RDF 语法检查、OWL 推理和 SHACL 约束的半自动化方法。这项研究的结果非常有希望，因为即使对于复杂的能力，生成的本体几乎没有错误。

##### **Enhancing Legal Compliance and Regulation Analysis with Large Language Models**
2404.17522v1 by Shabnam Hassani

This research explores the application of Large Language Models (LLMs) for
automating the extraction of requirement-related legal content in the food
safety domain and checking legal compliance of regulatory artifacts. With
Industry 4.0 revolutionizing the food industry and with the General Data
Protection Regulation (GDPR) reshaping privacy policies and data processing
agreements, there is a growing gap between regulatory analysis and recent
technological advancements. This study aims to bridge this gap by leveraging
LLMs, namely BERT and GPT models, to accurately classify legal provisions and
automate compliance checks. Our findings demonstrate promising results,
indicating LLMs' significant potential to enhance legal compliance and
regulatory analysis efficiency, notably by reducing manual workload and
improving accuracy within reasonable time and financial constraints.

摘要：本研究探討大型語言模型 (LLM) 在食品安全領域自動化提取與需求相關的法律內容以及檢查法規文物的法律合規性的應用。隨著工業 4.0 徹底改變食品產業，以及《一般資料保護規範》(GDPR) 重塑隱私政策和資料處理協議，法規分析與近期技術進步之間的差距越來越大。本研究旨在透過利用 LLM，即 BERT 和 GPT 模型，準確分類法律條款並自動化合規性檢查，來彌合此差距。我們的研究結果顯示出有前途的成果，表明 LLM 在增強法律合規性和法規分析效率方面具有顯著的潛力，特別是透過減少手動工作量並在合理的時間和財務限制內提高準確性。

##### **A Comprehensive Evaluation on Event Reasoning of Large Language Models**
2404.17513v1 by Zhengwei Tao,Zhi Jin,Yifan Zhang,Xiancai Chen,Xiaoying Bai,Yue Fang,Haiyan Zhao,Jia Li,Chongyang Tao

Event reasoning is a fundamental ability that underlies many applications. It
requires event schema knowledge to perform global reasoning and needs to deal
with the diversity of the inter-event relations and the reasoning paradigms.
How well LLMs accomplish event reasoning on various relations and reasoning
paradigms remains unknown. To mitigate this disparity, we comprehensively
evaluate the abilities of event reasoning of LLMs. We introduce a novel
benchmark EV2 for EValuation of EVent reasoning. EV2 consists of two levels of
evaluation of schema and instance and is comprehensive in relations and
reasoning paradigms. We conduct extensive experiments on EV2. We find that LLMs
have abilities to accomplish event reasoning but their performances are far
from satisfactory. We also notice the imbalance of event reasoning abilities in
LLMs. Besides, LLMs have event schema knowledge, however, they're not aligned
with humans on how to utilize the knowledge. Based on these findings, we
introduce two methods to guide the LLMs to utilize the event schema knowledge.
Both methods achieve improvements.

摘要：事件推理是許多應用程式背後的基本能力。它需要事件模式知識來執行全域推理，並且需要處理事件間關係和推理範例的多樣性。大型語言模型在各種關係和推理範例上有多好的事件推理能力，仍不得而知。為了減輕這種差異，我們全面評估大型語言模型的事件推理能力。我們引入了一個新的基準 EV2，用於評估事件推理。EV2 包含模式和實例的兩個評估層級，並且在關係和推理範例上很全面。我們在 EV2 上進行了廣泛的實驗。我們發現大型語言模型有能力完成事件推理，但它們的表現遠未令人滿意。我們還注意到大型語言模型中事件推理能力的不平衡。此外，大型語言模型具有事件模式知識，但它們在如何利用知識方面與人類並不一致。根據這些發現，我們介紹了兩種方法來指導大型語言模型利用事件模式知識。這兩種方法都取得了改進。

##### **Causally Abstracted Multi-armed Bandits**
2404.17493v1 by Fabio Massimo Zennaro,Nicholas Bishop,Joel Dyer,Yorgos Felekis,Anisoara Calinescu,Michael Wooldridge,Theodoros Damoulas

Multi-armed bandits (MAB) and causal MABs (CMAB) are established frameworks
for decision-making problems. The majority of prior work typically studies and
solves individual MAB and CMAB in isolation for a given problem and associated
data. However, decision-makers are often faced with multiple related problems
and multi-scale observations where joint formulations are needed in order to
efficiently exploit the problem structures and data dependencies. Transfer
learning for CMABs addresses the situation where models are defined on
identical variables, although causal connections may differ. In this work, we
extend transfer learning to setups involving CMABs defined on potentially
different variables, with varying degrees of granularity, and related via an
abstraction map. Formally, we introduce the problem of causally abstracted MABs
(CAMABs) by relying on the theory of causal abstraction in order to express a
rigorous abstraction map. We propose algorithms to learn in a CAMAB, and study
their regret. We illustrate the limitations and the strengths of our algorithms
on a real-world scenario related to online advertising.

摘要：多臂老虎机 (MAB) 和因果 MAB (CMAB) 是决策问题的既定框架。大多数先前的工作通常孤立地研究和解决给定问题和关联数据的单个 MAB 和 CMAB。然而，决策者经常面临多个相关问题和多尺度观察，需要联合公式才能有效利用问题结构和数据依赖性。CMAB 的迁移学习解决了模型在相同变量上定义的情况，尽管因果关系可能不同。在这项工作中，我们将迁移学习扩展到涉及在潜在不同变量上定义的 CMAB 的设置，具有不同程度的粒度，并通过抽象映射相关联。正式地，我们通过依赖因果抽象理论来引入因果抽象 MAB (CAMAB) 的问题，以表达严格的抽象映射。我们提出算法在 CAMAB 中学习，并研究它们的后悔。我们在与在线广告相关的真实场景中说明了我们算法的局限性和优势。

##### **Tabular Data Contrastive Learning via Class-Conditioned and Feature-Correlation Based Augmentation**
2404.17489v1 by Wei Cui,Rasa Hosseinzadeh,Junwei Ma,Tongzi Wu,Yi Sui,Keyvan Golestan

Contrastive learning is a model pre-training technique by first creating
similar views of the original data, and then encouraging the data and its
corresponding views to be close in the embedding space. Contrastive learning
has witnessed success in image and natural language data, thanks to the
domain-specific augmentation techniques that are both intuitive and effective.
Nonetheless, in tabular domain, the predominant augmentation technique for
creating views is through corrupting tabular entries via swapping values, which
is not as sound or effective. We propose a simple yet powerful improvement to
this augmentation technique: corrupting tabular data conditioned on class
identity. Specifically, when corrupting a specific tabular entry from an anchor
row, instead of randomly sampling a value in the same feature column from the
entire table uniformly, we only sample from rows that are identified to be
within the same class as the anchor row. We assume the semi-supervised learning
setting, and adopt the pseudo labeling technique for obtaining class identities
over all table rows. We also explore the novel idea of selecting features to be
corrupted based on feature correlation structures. Extensive experiments show
that the proposed approach consistently outperforms the conventional corruption
method for tabular data classification tasks. Our code is available at
https://github.com/willtop/Tabular-Class-Conditioned-SSL.

摘要：對比學習是一種模型預訓練技術，首先建立原始資料的相似檢視，然後鼓勵資料及其對應檢視在嵌入空間中接近。對比學習見證了影像和自然語言資料的成功，這要歸功於既直觀又有效的特定領域擴充技術。儘管如此，在表格領域，用於建立檢視的主要擴充技術是透過交換值來損壞表格條目，這並非那麼健全或有效。我們提出了一項對此擴充技術的簡單但強大的改進：基於類別身分損壞表格資料。具體來說，在從錨定列損壞特定表格條目時，我們不會在整個表格中從同一特徵欄位中隨機抽樣一個值，而只會從被識別為與錨定列同類的列中抽樣。我們假設半監督學習設定，並採用偽標籤技術來取得所有表格列的類別身分。我們還探討了基於特徵關聯結構選擇要損壞的特徵的新穎構想。廣泛的實驗顯示，所提出的方法在表格資料分類任務中始終優於傳統的損壞方法。我們的程式碼可於 https://github.com/willtop/Tabular-Class-Conditioned-SSL 取得。

##### **Conformal Prediction with Learned Features**
2404.17487v1 by Shayan Kiyani,George Pappas,Hamed Hassani

In this paper, we focus on the problem of conformal prediction with
conditional guarantees. Prior work has shown that it is impossible to construct
nontrivial prediction sets with full conditional coverage guarantees. A wealth
of research has considered relaxations of full conditional guarantees, relying
on some predefined uncertainty structures. Departing from this line of
thinking, we propose Partition Learning Conformal Prediction (PLCP), a
framework to improve conditional validity of prediction sets through learning
uncertainty-guided features from the calibration data. We implement PLCP
efficiently with alternating gradient descent, utilizing off-the-shelf machine
learning models. We further analyze PLCP theoretically and provide conditional
guarantees for infinite and finite sample sizes. Finally, our experimental
results over four real-world and synthetic datasets show the superior
performance of PLCP compared to state-of-the-art methods in terms of coverage
and length in both classification and regression scenarios.

摘要：在本文中，我们专注于具有条件保证的共形预测问题。先前的研究表明，不可能构建具有完全条件覆盖保证的非平凡预测集。大量研究考虑了完全条件保证的放松，依赖于一些预定义的不确定性结构。脱离这一思路，我们提出了分区学习共形预测 (PLCP)，一个通过从校准数据中学习不确定性引导特征来提高预测集条件有效性的框架。我们使用交替梯度下降有效地实现了 PLCP，利用现成的机器学习模型。我们进一步从理论上分析了 PLCP，并为无限和有限样本量提供了条件保证。最后，我们在四个真实世界和合成数据集上的实验结果表明，在分类和回归场景中，PLCP 在覆盖率和长度方面都优于最先进的方法。

##### **ReproHum #0087-01: Human Evaluation Reproduction Report for Generating Fact Checking Explanations**
2404.17481v1 by Tyler Loakman,Chenghua Lin

This paper presents a partial reproduction of Generating Fact Checking
Explanations by Anatanasova et al (2020) as part of the ReproHum element of the
ReproNLP shared task to reproduce the findings of NLP research regarding human
evaluation. This shared task aims to investigate the extent to which NLP as a
field is becoming more or less reproducible over time. Following the
instructions provided by the task organisers and the original authors, we
collect relative rankings of 3 fact-checking explanations (comprising a gold
standard and the outputs of 2 models) for 40 inputs on the criteria of
Coverage. The results of our reproduction and reanalysis of the original work's
raw results lend support to the original findings, with similar patterns seen
between the original work and our reproduction. Whilst we observe slight
variation from the original results, our findings support the main conclusions
drawn by the original authors pertaining to the efficacy of their proposed
models.

摘要：本文部分重現 Anatanasova 等人 (2020) 的事實查核說明生成，作為 ReproNLP 共享任務的 ReproHum 元素的一部分，以重現 NLP 研究關於人類評估的發現。這個共享任務旨在調查 NLP 作為一個領域隨著時間推移變得越來越可重現的程度。遵循任務組織者和原始作者提供的說明，我們收集了 40 個輸入的 3 個事實查核說明（包括黃金標準和 2 個模型的輸出）的相對排名，根據覆蓋範圍的標準。我們對原始工作的原始結果進行重現和重新分析的結果支持原始發現，原始工作和我們的重現之間出現了類似的模式。雖然我們觀察到與原始結果有輕微的差異，但我們的發現支持原始作者關於其提出的模型的功效得出的主要結論。

##### **CEval: A Benchmark for Evaluating Counterfactual Text Generation**
2404.17475v1 by Van Bach Nguyen,Jörg Schlötterer,Christin Seifert

Counterfactual text generation aims to minimally change a text, such that it
is classified differently. Judging advancements in method development for
counterfactual text generation is hindered by a non-uniform usage of data sets
and metrics in related work. We propose CEval, a benchmark for comparing
counterfactual text generation methods. CEval unifies counterfactual and text
quality metrics, includes common counterfactual datasets with human
annotations, standard baselines (MICE, GDBA, CREST) and the open-source
language model LLAMA-2. Our experiments found no perfect method for generating
counterfactual text. Methods that excel at counterfactual metrics often produce
lower-quality text while LLMs with simple prompts generate high-quality text
but struggle with counterfactual criteria. By making CEval available as an
open-source Python library, we encourage the community to contribute more
methods and maintain consistent evaluation in future work.

摘要：反事實文本生成旨在對文本進行最小的更改，以使其被分類為不同的類別。由於相關工作中數據集和指標的使用不統一，因此阻礙了對反事實文本生成方法開發進展的判斷。我們提出了 CEval，這是一個用於比較反事實文本生成方法的基準。CEval 統一了反事實和文本質量指標，包括帶有人工註釋的常見反事實數據集、標準基準（MICE、GDBA、CREST）和開源語言模型 LLAMA-2。我們的實驗沒有找到生成反事實文本的完美方法。在反事實指標上表現出色的方法通常會產生質量較低的文本，而帶有簡單提示的 LLM 會生成高質量的文本，但在反事實標準上遇到困難。通過將 CEval 作為開源 Python 庫提供，我們鼓勵社區貢獻更多方法並在未來的研究中保持一致的評估。

##### **Ruffle&Riley: Insights from Designing and Evaluating a Large Language Model-Based Conversational Tutoring System**
2404.17460v1 by Robin Schmucker,Meng Xia,Amos Azaria,Tom Mitchell

Conversational tutoring systems (CTSs) offer learning experiences through
interactions based on natural language. They are recognized for promoting
cognitive engagement and improving learning outcomes, especially in reasoning
tasks. Nonetheless, the cost associated with authoring CTS content is a major
obstacle to widespread adoption and to research on effective instructional
design. In this paper, we discuss and evaluate a novel type of CTS that
leverages recent advances in large language models (LLMs) in two ways: First,
the system enables AI-assisted content authoring by inducing an easily editable
tutoring script automatically from a lesson text. Second, the system automates
the script orchestration in a learning-by-teaching format via two LLM-based
agents (Ruffle&Riley) acting as a student and a professor. The system allows
for free-form conversations that follow the ITS-typical inner and outer loop
structure. We evaluate Ruffle&Riley's ability to support biology lessons in two
between-subject online user studies (N = 200) comparing the system to simpler
QA chatbots and reading activity. Analyzing system usage patterns,
pre/post-test scores and user experience surveys, we find that Ruffle&Riley
users report high levels of engagement, understanding and perceive the offered
support as helpful. Even though Ruffle&Riley users require more time to
complete the activity, we did not find significant differences in short-term
learning gains over the reading activity. Our system architecture and user
study provide various insights for designers of future CTSs. We further
open-source our system to support ongoing research on effective instructional
design of LLM-based learning technologies.

摘要：對話式教學系統 (CTS) 透過基於自然語言的互動提供學習體驗。它們因促進認知參與和改善學習成果而受到肯定，尤其是在推理任務中。儘管如此，撰寫 CTS 內容相關的成本是廣泛採用和研究有效教學設計的主要障礙。在本文中，我們討論並評估一種新穎的 CTS 類型，它以兩種方式利用大型語言模型 (LLM) 的最新進展：首先，該系統透過自動從課程文字中引導出易於編輯的教學腳本，實現 AI 協助內容撰寫。其次，該系統透過兩個基於 LLM 的代理（Ruffle 和 Riley）以學習教學的形式自動執行腳本編排，它們分別扮演學生和教授的角色。該系統允許進行自由形式的對話，遵循 ITS 典型的內外迴圈結構。我們評估了 Ruffle 和 Riley 在兩項受試者間線上使用者研究（N = 200）中支援生物課程的能力，將該系統與更簡單的問答聊天機器人和閱讀活動進行比較。透過分析系統使用模式、測驗前後評分和使用者體驗調查，我們發現 Ruffle 和 Riley 的使用者回報了高參與度、理解度，並認為所提供的支援有幫助。儘管 Ruffle 和 Riley 的使用者需要更多時間才能完成活動，但我們沒有發現其短期學習成果與閱讀活動有顯著差異。我們的系統架構和使用者研究為未來的 CTS 設計師提供了各種見解。我們進一步開放我們的系統，以支援持續研究 LLM 為基礎的學習技術的有效教學設計。

##### **Domain Adaptive and Fine-grained Anomaly Detection for Single-cell Sequencing Data and Beyond**
2404.17454v1 by Kaichen Xu,Yueyang Ding,Suyang Hou,Weiqiang Zhan,Nisang Chen,Jun Wang,Xiaobo Sun

Fined-grained anomalous cell detection from affected tissues is critical for
clinical diagnosis and pathological research. Single-cell sequencing data
provide unprecedented opportunities for this task. However, current anomaly
detection methods struggle to handle domain shifts prevalent in multi-sample
and multi-domain single-cell sequencing data, leading to suboptimal
performance. Moreover, these methods fall short of distinguishing anomalous
cells into pathologically distinct subtypes. In response, we propose ACSleuth,
a novel, reconstruction deviation-guided generative framework that integrates
the detection, domain adaptation, and fine-grained annotating of anomalous
cells into a methodologically cohesive workflow. Notably, we present the first
theoretical analysis of using reconstruction deviations output by generative
models for anomaly detection in lieu of domain shifts. This analysis informs us
to develop a novel and superior maximum mean discrepancy-based anomaly scorer
in ACSleuth. Extensive benchmarks over various single-cell data and other types
of tabular data demonstrate ACSleuth's superiority over the state-of-the-art
methods in identifying and subtyping anomalies in multi-sample and multi-domain
contexts. Our code is available at https://github.com/Catchxu/ACsleuth.

摘要：细粒度异常细胞检测对于临床诊断和病理研究至关重要。单细胞测序数据为这项任务提供了前所未有的机会。然而，当前的异常检测方法难以处理多样本和多域单细胞测序数据中普遍存在的域偏移，从而导致性能不佳。此外，这些方法无法将异常细胞区分成病理学上不同的亚型。为了解决这个问题，我们提出了 ACSleuth，这是一个新颖的、重建偏差指导的生成框架，它将异常细胞的检测、域适应和细粒度注释整合到一个方法论上连贯的工作流中。值得注意的是，我们提出了第一个理论分析，即利用生成模型输出的重建偏差来代替域偏移进行异常检测。这一分析让我们能够在 ACSleuth 中开发一种新颖且优越的最大均值差异异常评分器。对各种单细胞数据和其他类型表格数据的广泛基准测试表明，ACSleuth 在识别和对多样本和多域环境中的异常进行亚型分类方面优于最先进的方法。我们的代码可在 https://github.com/Catchxu/ACsleuth 获取。

##### **"ChatGPT Is Here to Help, Not to Replace Anybody" -- An Evaluation of Students' Opinions On Integrating ChatGPT In CS Courses**
2404.17443v1 by Bruno Pereira Cipriano,Pedro Alves

Large Language Models (LLMs) like GPT and Bard are capable of producing code
based on textual descriptions, with remarkable efficacy. Such technology will
have profound implications for computing education, raising concerns about
cheating, excessive dependence, and a decline in computational thinking skills,
among others. There has been extensive research on how teachers should handle
this challenge but it is also important to understand how students feel about
this paradigm shift. In this research, 52 first-year CS students were surveyed
in order to assess their views on technologies with code-generation
capabilities, both from academic and professional perspectives. Our findings
indicate that while students generally favor the academic use of GPT, they
don't over rely on it, only mildly asking for its help. Although most students
benefit from GPT, some struggle to use it effectively, urging the need for
specific GPT training. Opinions on GPT's impact on their professional lives
vary, but there is a consensus on its importance in academic practice.

摘要：大型語言模型（LLM），例如 GPT 和 Bard，能夠根據文本描述產生程式碼，且具有顯著的功效。此類技術將對計算教育產生深遠的影響，引發人們對作弊、過度依賴和計算思維技能下降等問題的擔憂。關於教師應如何應對這一挑戰，已經有大量的研究，但了解學生對這一範式轉變的感受也很重要。在這項研究中，調查了 52 名一年級 CS 學生，以評估他們對具有程式碼生成功能的技術的看法，無論是從學術還是專業的角度。我們的研究結果表明，儘管學生普遍贊成在學術上使用 GPT，但他們並不過度依賴它，只是輕微地尋求它的幫助。儘管大多數學生受益於 GPT，但有些學生在有效使用它時遇到了困難，這迫切需要進行具體的 GPT 培訓。對於 GPT 對其職業生涯的影響，意見不一，但對於其在學術實踐中的重要性，則達成共識。

##### **Real-World Deployment of a Hierarchical Uncertainty-Aware Collaborative Multiagent Planning System**
2404.17438v1 by Martina Stadler Kurtz,Samuel Prentice,Yasmin Veys,Long Quang,Carlos Nieto-Granda,Michael Novitzky,Ethan Stump,Nicholas Roy

We would like to enable a collaborative multiagent team to navigate at long
length scales and under uncertainty in real-world environments. In practice,
planning complexity scales with the number of agents in the team, with the
length scale of the environment, and with environmental uncertainty. Enabling
tractable planning requires developing abstract models that can represent
complex, high-quality plans. However, such models often abstract away
information needed to generate directly-executable plans for real-world agents
in real-world environments, as planning in such detail, especially in the
presence of real-world uncertainty, would be computationally intractable. In
this paper, we describe the deployment of a planning system that used a
hierarchy of planners to execute collaborative multiagent navigation tasks in
real-world, unknown environments. By developing a planning system that was
robust to failures at every level of the planning hierarchy, we enabled the
team to complete collaborative navigation tasks, even in the presence of
imperfect planning abstractions and real-world uncertainty. We deployed our
approach on a Clearpath Husky-Jackal team navigating in a structured outdoor
environment, and demonstrated that the system enabled the agents to
successfully execute collaborative plans.

摘要：我們希望在現實世界的環境中，讓一個協作的多重代理團隊在長距離的尺度下，在不確定性的情況下導航。在實務上，規劃的複雜性會隨著團隊中代理人的數量、環境的長度尺度，以及環境的不確定性而增加。要讓規劃容易處理，需要發展出抽象的模型，可以呈現複雜、高品質的計畫。然而，這種模型常常會抽象掉資訊，這些資訊是為了在現實世界的環境中，為現實世界的代理人產生直接可執行的計畫，因為在這種細節下規劃，特別是在有現實世界不確定性的情況下，在運算上會難以處理。在本文中，我們描述了一個規劃系統的部署，這個系統使用了一個規劃者的階層，在現實世界中未知的環境中執行協作的多重代理導航任務。透過發展一個在規劃階層的每個層級中，對於失敗都具有穩健性的規劃系統，我們讓團隊能夠完成協作的導航任務，即使在不完美的規劃抽象和現實世界的不確定性中也能完成。我們在一個結構化的戶外環境中部署了我們的做法，讓 Clearpath Husky-Jackal 團隊導航，並展示了這個系統讓代理人能夠成功執行協作計畫。

##### **Evaluation of Geographical Distortions in Language Models: A Crucial Step Towards Equitable Representations**
2404.17401v1 by Rémy Decoupes,Roberto Interdonato,Mathieu Roche,Maguelonne Teisseire,Sarah Valentin

Language models now constitute essential tools for improving efficiency for
many professional tasks such as writing, coding, or learning. For this reason,
it is imperative to identify inherent biases. In the field of Natural Language
Processing, five sources of bias are well-identified: data, annotation,
representation, models, and research design. This study focuses on biases
related to geographical knowledge. We explore the connection between geography
and language models by highlighting their tendency to misrepresent spatial
information, thus leading to distortions in the representation of geographical
distances. This study introduces four indicators to assess these distortions,
by comparing geographical and semantic distances. Experiments are conducted
from these four indicators with ten widely used language models. Results
underscore the critical necessity of inspecting and rectifying spatial biases
in language models to ensure accurate and equitable representations.

摘要：語言模型現已成為提升許多專業工作效率的必要工具，例如寫作、編碼或學習。因此，找出內在偏見至關重要。在自然語言處理領域，有五種偏見來源已廣為人知：資料、標註、表示、模型和研究設計。本研究專注於與地理知識相關的偏見。我們透過強調語言模型容易錯誤呈現空間資訊的傾向，探討地理與語言模型之間的關聯，進而導致地理距離的表示失真。本研究引入了四個指標來評估這些失真，方法是比較地理距離和語義距離。針對這四個指標，使用十種廣泛使用的語言模型進行實驗。結果強調檢查和修正語言模型中的空間偏見，以確保準確且公平的表示，至關重要。

##### **Spatial-frequency Dual-Domain Feature Fusion Network for Low-Light Remote Sensing Image Enhancement**
2404.17400v1 by Zishu Yao,Guodong Fan,Jinfu Fan,Min Gan,C. L. Philip Chen

Low-light remote sensing images generally feature high resolution and high
spatial complexity, with continuously distributed surface features in space.
This continuity in scenes leads to extensive long-range correlations in spatial
domains within remote sensing images. Convolutional Neural Networks, which rely
on local correlations for long-distance modeling, struggle to establish
long-range correlations in such images. On the other hand, transformer-based
methods that focus on global information face high computational complexities
when processing high-resolution remote sensing images. From another
perspective, Fourier transform can compute global information without
introducing a large number of parameters, enabling the network to more
efficiently capture the overall image structure and establish long-range
correlations. Therefore, we propose a Dual-Domain Feature Fusion Network (DFFN)
for low-light remote sensing image enhancement. Specifically, this challenging
task of low-light enhancement is divided into two more manageable sub-tasks:
the first phase learns amplitude information to restore image brightness, and
the second phase learns phase information to refine details. To facilitate
information exchange between the two phases, we designed an information fusion
affine block that combines data from different phases and scales. Additionally,
we have constructed two dark light remote sensing datasets to address the
current lack of datasets in dark light remote sensing image enhancement.
Extensive evaluations show that our method outperforms existing
state-of-the-art methods. The code is available at
https://github.com/iijjlk/DFFN.

摘要：低光遙感影像通常具有高解析度和高空間複雜度，其中表面特徵在空間中連續分佈。場景中的這種連續性導致遙感影像中空間域內的廣泛長程相關性。卷積神經網路依賴於局部相關性進行長距離建模，難以在這種影像中建立長程相關性。另一方面，基於變壓器的關注全球資訊的方法在處理高解析度遙感影像時會面臨高計算複雜度。從另一個角度來看，傅立葉變換可以在不引入大量參數的情況下計算全局資訊，使網路能夠更有效率地擷取整體影像結構並建立長程相關性。因此，我們提出了一個雙域特徵融合網路（DFFN）用於低光遙感影像增強。具體來說，這個具有挑戰性的低光增強任務被分為兩個更易於管理的子任務：第一階段學習振幅資訊以恢復影像亮度，第二階段學習相位資訊以精煉細節。為了促進兩個階段之間的資訊交換，我們設計了一個資訊融合仿射區塊，結合了來自不同階段和尺度的資料。此外，我們構建了兩個暗光遙感資料集，以解決當前暗光遙感影像增強中缺乏資料集的問題。廣泛的評估表明，我們的模型優於現有的最先進模型。程式碼可在 https://github.com/iijjlk/DFFN 獲得。

##### **Child Speech Recognition in Human-Robot Interaction: Problem Solved?**
2404.17394v1 by Ruben Janssens,Eva Verhelst,Giulio Antonio Abbo,Qiaoqiao Ren,Maria Jose Pinto Bernal,Tony Belpaeme

Automated Speech Recognition shows superhuman performance for adult English
speech on a range of benchmarks, but disappoints when fed children's speech.
This has long sat in the way of child-robot interaction. Recent evolutions in
data-driven speech recognition, including the availability of Transformer
architectures and unprecedented volumes of training data, might mean a
breakthrough for child speech recognition and social robot applications aimed
at children. We revisit a study on child speech recognition from 2017 and show
that indeed performance has increased, with newcomer OpenAI Whisper doing
markedly better than leading commercial cloud services. While transcription is
not perfect yet, the best model recognises 60.3% of sentences correctly barring
small grammatical differences, with sub-second transcription time running on a
local GPU, showing potential for usable autonomous child-robot speech
interactions.

摘要：自動語音辨識在各種基準上對成人英語語音表現出超人的表現，但在輸入兒童語音時卻令人失望。這長期以來一直阻礙了兒童機器人互動。數據驅動語音辨識的最新演進，包括 Transformer 架構的可用性和前所未有的訓練資料量，可能意味著兒童語音辨識和針對兒童的社交機器人應用程式取得突破。我們重新審視了 2017 年的一項兒童語音辨識研究，並表明表現確實有所提升，新來者 OpenAI Whisper 的表現明顯優於領先的商業雲端服務。雖然轉錄還不完美，但最好的模型可以正確辨識 60.3% 的句子，並排除小的語法差異，在本地 GPU 上執行亞秒轉錄時間，顯示出可用於自主兒童機器人語音互動的潛力。

##### **M3BAT: Unsupervised Domain Adaptation for Multimodal Mobile Sensing with Multi-Branch Adversarial Training**
2404.17391v1 by Lakmal Meegahapola,Hamza Hassoune,Daniel Gatica-Perez

Over the years, multimodal mobile sensing has been used extensively for
inferences regarding health and well being, behavior, and context. However, a
significant challenge hindering the widespread deployment of such models in
real world scenarios is the issue of distribution shift. This is the phenomenon
where the distribution of data in the training set differs from the
distribution of data in the real world, the deployment environment. While
extensively explored in computer vision and natural language processing, and
while prior research in mobile sensing briefly addresses this concern, current
work primarily focuses on models dealing with a single modality of data, such
as audio or accelerometer readings, and consequently, there is little research
on unsupervised domain adaptation when dealing with multimodal sensor data. To
address this gap, we did extensive experiments with domain adversarial neural
networks (DANN) showing that they can effectively handle distribution shifts in
multimodal sensor data. Moreover, we proposed a novel improvement over DANN,
called M3BAT, unsupervised domain adaptation for multimodal mobile sensing with
multi-branch adversarial training, to account for the multimodality of sensor
data during domain adaptation with multiple branches. Through extensive
experiments conducted on two multimodal mobile sensing datasets, three
inference tasks, and 14 source-target domain pairs, including both regression
and classification, we demonstrate that our approach performs effectively on
unseen domains. Compared to directly deploying a model trained in the source
domain to the target domain, the model shows performance increases up to 12%
AUC (area under the receiver operating characteristics curves) on
classification tasks, and up to 0.13 MAE (mean absolute error) on regression
tasks.

摘要：多年来，多模态移动传感已被广泛用于推断健康和福祉、行为和背景。然而，阻碍此类模型在现实世界场景中广泛部署的一个重大挑战是分布偏移问题。这是训练集中数据的分布与现实世界中的数据分布不同的现象，即部署环境。虽然在计算机视觉和自然语言处理中进行了广泛的探索，并且虽然移动传感方面的先前研究简要地解决了这一问题，但当前的工作主要集中在处理单一数据模式的模型上，例如音频或加速计读数，因此，在处理多模态传感器数据时，几乎没有无监督域自适应的研究。为了解决这一差距，我们对域对抗神经网络 (DANN) 进行了广泛的实验，表明它们可以有效地处理多模态传感器数据中的分布偏移。此外，我们提出了对 DANN 的一项新改进，称为 M3BAT，用于多模态移动传感的多分支对抗训练的无监督域自适应，以在域自适应期间考虑传感器数据的多种模式。通过对两个多模态移动传感数据集、三个推理任务和 14 个源目标域对（包括回归和分类）进行广泛的实验，我们证明了我们的方法在看不见的域上有效执行。与将源域中训练的模型直接部署到目标域相比，该模型在分类任务上的性能提高了 12% AUC（接收器操作特征曲线下的面积），在回归任务上的性能提高了 0.13 MAE（平均绝对误差）。

##### **Assessing the Potential of AI for Spatially Sensitive Nature-Related Financial Risks**
2404.17369v1 by Steven Reece,Emma O donnell,Felicia Liu,Joanna Wolstenholme,Frida Arriaga,Giacomo Ascenzi,Richard Pywell

There is growing recognition among financial institutions, financial
regulators and policy makers of the importance of addressing nature-related
risks and opportunities. Evaluating and assessing nature-related risks for
financial institutions is challenging due to the large volume of heterogeneous
data available on nature and the complexity of investment value chains and the
various components' relationship to nature. The dual problem of scaling data
analytics and analysing complex systems can be addressed using Artificial
Intelligence (AI). We address issues such as plugging existing data gaps with
discovered data, data estimation under uncertainty, time series analysis and
(near) real-time updates. This report presents potential AI solutions for
models of two distinct use cases, the Brazil Beef Supply Use Case and the Water
Utility Use Case. Our two use cases cover a broad perspective within
sustainable finance. The Brazilian cattle farming use case is an example of
greening finance - integrating nature-related considerations into mainstream
financial decision-making to transition investments away from sectors with poor
historical track records and unsustainable operations. The deployment of
nature-based solutions in the UK water utility use case is an example of
financing green - driving investment to nature-positive outcomes. The two use
cases also cover different sectors, geographies, financial assets and AI
modelling techniques, providing an overview on how AI could be applied to
different challenges relating to nature's integration into finance. This report
is primarily aimed at financial institutions but is also of interest to ESG
data providers, TNFD, systems modellers, and, of course, AI practitioners.

摘要：金融機構、金融監管機構和政策制定者日益認識到解決與自然相關的風險和機遇的重要性。由於關於自然的大量異質數據以及投資價值鏈的複雜性以及各種組成部分與自然的關係，金融機構評估和評估與自然相關的風險具有挑戰性。使用人工智慧 (AI) 可以解決數據分析擴展和分析複雜系統的雙重問題。我們解決諸如用發現的數據填補現有數據差距、不確定性下的數據估計、時間序列分析和（接近）實時更新等問題。本報告針對兩個不同用例模型（巴西牛肉供應用例和水務用例）提出了潛在的 AI 解决方案。我們的兩個用例涵蓋了可持續金融中的廣泛觀點。巴西養牛用例是綠色金融的範例 - 將與自然相關的考量納入主流金融決策制定，以將投資從歷史記錄不佳和運營不可持續的部門轉移出去。在英國水務用例中部署基於自然的解決方案是綠色融資的一個範例 - 推動投資以獲得對自然有利的成果。這兩個用例還涵蓋了不同的部門、地理區域、金融資產和 AI 建模技術，概述了如何將 AI 應用於與自然融入金融相關的不同挑戰。本報告主要針對金融機構，但對 ESG 數據提供者、TNFD、系統建模者以及當然還有 AI 從業者也很有意義。

##### **Similarity Equivariant Graph Neural Networks for Homogenization of Metamaterials**
2404.17365v1 by Fleur Hendriks,Vlado Menkovski,Martin Doškář,Marc G. D. Geers,Ondřej Rokoš

Soft, porous mechanical metamaterials exhibit pattern transformations that
may have important applications in soft robotics, sound reduction and
biomedicine. To design these innovative materials, it is important to be able
to simulate them accurately and quickly, in order to tune their mechanical
properties. Since conventional simulations using the finite element method
entail a high computational cost, in this article we aim to develop a machine
learning-based approach that scales favorably to serve as a surrogate model. To
ensure that the model is also able to handle various microstructures, including
those not encountered during training, we include the microstructure as part of
the network input. Therefore, we introduce a graph neural network that predicts
global quantities (energy, stress stiffness) as well as the pattern
transformations that occur (the kinematics). To make our model as accurate and
data-efficient as possible, various symmetries are incorporated into the model.
The starting point is an E(n)-equivariant graph neural network (which respects
translation, rotation and reflection) that has periodic boundary conditions
(i.e., it is in-/equivariant with respect to the choice of RVE), is scale
in-/equivariant, can simulate large deformations, and can predict scalars,
vectors as well as second and fourth order tensors (specifically energy, stress
and stiffness). The incorporation of scale equivariance makes the model
equivariant with respect to the similarities group, of which the Euclidean
group E(n) is a subgroup. We show that this network is more accurate and
data-efficient than graph neural networks with fewer symmetries. To create an
efficient graph representation of the finite element discretization, we use
only the internal geometrical hole boundaries from the finite element mesh to
achieve a better speed-up and scaling with the mesh size.

摘要：柔軟多孔的機械超材料展現出形變轉換，這在軟機器人、降噪和生物醫學中可能具有重要的應用。為了設計這些創新材料，能夠準確且快速地模擬它們非常重要，以便調整其機械屬性。由於使用有限元素方法的傳統模擬需要很高的計算成本，因此在本文中，我們旨在開發一種基於機器學習的方法，該方法可以很好地擴展以作為代理模型。為了確保模型還能處理各種微結構，包括訓練過程中未遇到的微結構，我們將微結構作為網路輸入的一部分。因此，我們引入了一個圖神經網路，它可以預測全局量（能量、應力剛度）以及發生的形變轉換（運動學）。為了使我們的模型盡可能準確且資料有效，將各種對稱性納入模型中。起點是一個 E(n) 等變圖神經網路（它尊重平移、旋轉和反射），它具有週期性邊界條件（即，它相對於 RVE 的選擇是不變/等變的），是尺度不變/等變的，可以模擬大變形，並且可以預測標量、向量以及二階和四階張量（特別是能量、應力和剛度）。尺度等變性的納入使模型相對於相似性群組保持等變性，其中歐幾里得群組 E(n) 是子群。我們表明，與具有較少對稱性的圖神經網路相比，這個網路更準確且資料有效。為了創建有限元離散化的有效圖表示，我們僅使用有限元網格中的內部幾何孔洞邊界，以實現更好的加速和網格尺寸縮放。

##### **A Bionic Natural Language Parser Equivalent to a Pushdown Automaton**
2404.17343v1 by Zhenghao Wei,Kehua Lin,Jianlin Feng

Assembly Calculus (AC), proposed by Papadimitriou et al., aims to reproduce
advanced cognitive functions through simulating neural activities, with several
applications based on AC having been developed, including a natural language
parser proposed by Mitropolsky et al. However, this parser lacks the ability to
handle Kleene closures, preventing it from parsing all regular languages and
rendering it weaker than Finite Automata (FA). In this paper, we propose a new
bionic natural language parser (BNLP) based on AC and integrates two new
biologically rational structures, Recurrent Circuit and Stack Circuit which are
inspired by RNN and short-term memory mechanism. In contrast to the original
parser, the BNLP can fully handle all regular languages and Dyck languages.
Therefore, leveraging the Chomsky-Sch \H{u}tzenberger theorem, the BNLP which
can parse all Context-Free Languages can be constructed. We also formally prove
that for any PDA, a Parser Automaton corresponding to BNLP can always be
formed, ensuring that BNLP has a description ability equal to that of PDA and
addressing the deficiencies of the original parser.

摘要：帕帕季米特里欧等人提出的組合演算 (AC) 旨在透過模擬神經活動來複製先進的認知功能，而基於 AC 的多項應用已獲開發，包括米特羅波斯基等人提出的自然語言解析器。然而，此解析器缺乏處理 Kleene 閉包的能力，導致無法解析所有正則語言，且功能弱於有限狀態自動機 (FA)。在本文中，我們提出一個新的基於 AC 的仿生自然語言解析器 (BNLP)，並整合兩個新的生物合理結構：迴路電路和堆疊電路，它們的靈感來自 RNN 和短期記憶機制。與原始解析器不同，BNLP 能夠完全處理所有正則語言和 Dyck 語言。因此，利用喬姆斯基-舒岑伯格定理，可以建構出能夠解析所有上下文無關語言的 BNLP。我們也正式證明，對於任何 PDA，都可以形成與 BNLP 相應的解析器自動機，確保 BNLP 具有與 PDA 相等的描述能力，並解決了原始解析器的缺陷。

##### **Can a Multichoice Dataset be Repurposed for Extractive Question Answering?**
2404.17342v1 by Teresa Lynn,Malik H. Altakrori,Samar Mohamed Magdy,Rocktim Jyoti Das,Chenyang Lyu,Mohamed Nasr,Younes Samih,Alham Fikri Aji,Preslav Nakov,Shantanu Godbole,Salim Roukos,Radu Florian,Nizar Habash

The rapid evolution of Natural Language Processing (NLP) has favored major
languages such as English, leaving a significant gap for many others due to
limited resources. This is especially evident in the context of data
annotation, a task whose importance cannot be underestimated, but which is
time-consuming and costly. Thus, any dataset for resource-poor languages is
precious, in particular when it is task-specific. Here, we explore the
feasibility of repurposing existing datasets for a new NLP task: we repurposed
the Belebele dataset (Bandarkar et al., 2023), which was designed for
multiple-choice question answering (MCQA), to enable extractive QA (EQA) in the
style of machine reading comprehension. We present annotation guidelines and a
parallel EQA dataset for English and Modern Standard Arabic (MSA). We also
present QA evaluation results for several monolingual and cross-lingual QA
pairs including English, MSA, and five Arabic dialects. Our aim is to enable
others to adapt our approach for the 120+ other language variants in Belebele,
many of which are deemed under-resourced. We also conduct a thorough analysis
and share our insights from the process, which we hope will contribute to a
deeper understanding of the challenges and the opportunities associated with
task reformulation in NLP research.

摘要：自然語言處理 (NLP) 的快速發展偏袒了英語等主要語言，由於資源有限，許多其他語言被遠遠拋在後面。這在資料標註的背景下尤其明顯，這項任務的重要性不容小覷，但它既耗時又昂貴。因此，任何針對資源匱乏語言的資料集都是寶貴的，特別是當它是特定於任務時。在此，我們探討了將現有資料集重新用於新 NLP 任務的可行性：我們重新利用了 Belebele 資料集 (Bandarkar 等人，2023 年)，該資料集是為多選題回答 (MCQA) 設計的，以啟用機器閱讀理解風格的抽取式問答 (EQA)。我們提供了標註指南和一個針對英語和現代標準阿拉伯語 (MSA) 的平行 EQA 資料集。我們還提供了幾個單語和跨語言問答對的問答評估結果，包括英語、MSA 和五種阿拉伯語方言。我們的目標是讓其他人能夠將我們的做法改編為 Belebele 中的 120 多種其他語言變體，其中許多被認為是資源匱乏的。我們還進行了徹底的分析，並分享了我們從這個過程中獲得的見解，我們希望這將有助於更深入地了解 NLP 研究中與任務重新制定相關的挑戰和機遇。

##### **Metronome: tracing variation in poetic meters via local sequence alignment**
2404.17337v1 by Ben Nagy,Artjoms Šeļa,Mirella De Sisto,Petr Plecháč

All poetic forms come from somewhere. Prosodic templates can be copied for
generations, altered by individuals, imported from foreign traditions, or
fundamentally changed under the pressures of language evolution. Yet these
relationships are notoriously difficult to trace across languages and times.
This paper introduces an unsupervised method for detecting structural
similarities in poems using local sequence alignment. The method relies on
encoding poetic texts as strings of prosodic features using a four-letter
alphabet; these sequences are then aligned to derive a distance measure based
on weighted symbol (mis)matches. Local alignment allows poems to be clustered
according to emergent properties of their underlying prosodic patterns. We
evaluate method performance on a meter recognition tasks against strong
baselines and show its potential for cross-lingual and historical research
using three short case studies: 1) mutations in quantitative meter in classical
Latin, 2) European diffusion of the Renaissance hendecasyllable, and 3)
comparative alignment of modern meters in 18--19th century Czech, German and
Russian. We release an implementation of the algorithm as a Python package with
an open license.

摘要：所有詩歌形式都來自某處。韻律範本可以被代代相傳、由個人修改、從外國傳統中引入，或在語言演變的壓力下發生根本性的變化。然而，這些關係難以跨語言和時間追溯。本文介紹了一種無監督方法，使用局部序列比對來檢測詩歌中的結構相似性。該方法依賴於使用四個字母的字母表將詩歌文本編碼為韻律特徵字串；然後將這些序列對齊以根據加權符號（錯誤）匹配導出距離度量。局部比對允許根據其底層韻律模式的新興特性對詩歌進行分群。我們針對強大的基準對一個韻律識別任務評估方法的性能，並展示了它在三個簡短的案例研究中跨語言和歷史研究的潛力：1) 古典拉丁語中數量韻律的變異，2) 文藝復興時期十一音節詩在歐洲的傳播，以及 3) 18-19 世紀捷克語、德語和俄語中現代韻律的比較對齊。我們以開放許可證的形式發布了該演算法的實作，作為一個 Python 套件。

##### **Introducing cosmosGPT: Monolingual Training for Turkish Language Models**
2404.17336v1 by H. Toprak Kesgin,M. Kaan Yuce,Eren Dogan,M. Egemen Uzun,Atahan Uz,H. Emre Seyrek,Ahmed Zeer,M. Fatih Amasyali

The number of open source language models that can produce Turkish is
increasing day by day, as in other languages. In order to create the basic
versions of such models, the training of multilingual models is usually
continued with Turkish corpora. The alternative is to train the model with only
Turkish corpora. In this study, we first introduce the cosmosGPT models that we
created with this alternative method. Then, we introduce new finetune datasets
for basic language models to fulfill user requests and new evaluation datasets
for measuring the capabilities of Turkish language models. Finally, a
comprehensive comparison of the adapted Turkish language models on different
capabilities is presented. The results show that the language models we built
with the monolingual corpus have promising performance despite being about 10
times smaller than the others.

摘要：隨著其他語言，能夠產生土耳其語的開源語言模型數量與日俱增。為了建立此類模型的基本版本，通常會使用土耳其語語料庫持續訓練多語言模型。另一種方法是只使用土耳其語語料庫訓練模型。在本研究中，我們首先介紹使用此替代方法建立的 cosmosGPT 模型。接著，我們介紹用於滿足使用者要求的基本語言模型的新微調資料集，以及用於衡量土耳其語語言模型能力的新評估資料集。最後，針對不同能力的已調整土耳其語語言模型進行全面比較。結果顯示，儘管我們使用單一語言語料庫建立的語言模型比其他模型小約 10 倍，但仍有令人滿意的表現。

##### **A Novel Spike Transformer Network for Depth Estimation from Event Cameras via Cross-modality Knowledge Distillation**
2404.17335v1 by Xin Zhang,Liangxiu Han,Tam Sobeih,Lianghao Han,Darren Dancey

Depth estimation is crucial for interpreting complex environments, especially
in areas such as autonomous vehicle navigation and robotics. Nonetheless,
obtaining accurate depth readings from event camera data remains a formidable
challenge. Event cameras operate differently from traditional digital cameras,
continuously capturing data and generating asynchronous binary spikes that
encode time, location, and light intensity. Yet, the unique sampling mechanisms
of event cameras render standard image based algorithms inadequate for
processing spike data. This necessitates the development of innovative,
spike-aware algorithms tailored for event cameras, a task compounded by the
irregularity, continuity, noise, and spatial and temporal characteristics
inherent in spiking data.Harnessing the strong generalization capabilities of
transformer neural networks for spatiotemporal data, we propose a purely
spike-driven spike transformer network for depth estimation from spiking camera
data. To address performance limitations with Spiking Neural Networks (SNN), we
introduce a novel single-stage cross-modality knowledge transfer framework
leveraging knowledge from a large vision foundational model of artificial
neural networks (ANN) (DINOv2) to enhance the performance of SNNs with limited
data. Our experimental results on both synthetic and real datasets show
substantial improvements over existing models, with notable gains in Absolute
Relative and Square Relative errors (49% and 39.77% improvements over the
benchmark model Spike-T, respectively). Besides accuracy, the proposed model
also demonstrates reduced power consumptions, a critical factor for practical
applications.

摘要：深度估算对于解释复杂的环境至关重要，尤其是在自动驾驶导航和机器人等领域。尽管如此，从事件相机数据中获取准确的深度读数仍然是一项艰巨的挑战。事件相机与传统的数码相机运作方式不同，它会持续捕捉数据并生成异步二进制尖峰，对时间、位置和光强进行编码。然而，事件相机的独特采样机制使得基于标准图像的算法无法充分处理尖峰数据。这就需要开发创新的、针对事件相机定制的、能感知尖峰的算法，而尖峰数据固有的不规则性、连续性、噪声以及时空特征使得这项任务变得更加复杂。利用 Transformer 神经网络对时空数据的强大泛化能力，我们提出了一种纯尖峰驱动的尖峰 Transformer 网络，用于从尖峰相机数据中进行深度估算。为了解决尖峰神经网络 (SNN) 的性能限制，我们引入了一种新颖的单阶段跨模态知识转移框架，利用来自人工神经网络 (ANN) 的大型视觉基础模型 (DINOv2) 的知识来增强 SNN 在数据有限情况下的性能。我们在合成数据集和真实数据集上的实验结果表明，与现有模型相比有了实质性的改进，在绝对相对误差和平方相对误差方面取得了显著提升（分别比基准模型 Spike-T 提升了 49% 和 39.77%）。除了准确性之外，所提出的模型还展示了降低的功耗，这是实际应用的关键因素。

##### **Part-Guided 3D RL for Sim2Real Articulated Object Manipulation**
2404.17302v1 by Pengwei Xie,Rui Chen,Siang Chen,Yuzhe Qin,Fanbo Xiang,Tianyu Sun,Jing Xu,Guijin Wang,Hao Su

Manipulating unseen articulated objects through visual feedback is a critical
but challenging task for real robots. Existing learning-based solutions mainly
focus on visual affordance learning or other pre-trained visual models to guide
manipulation policies, which face challenges for novel instances in real-world
scenarios. In this paper, we propose a novel part-guided 3D RL framework, which
can learn to manipulate articulated objects without demonstrations. We combine
the strengths of 2D segmentation and 3D RL to improve the efficiency of RL
policy training. To improve the stability of the policy on real robots, we
design a Frame-consistent Uncertainty-aware Sampling (FUS) strategy to get a
condensed and hierarchical 3D representation. In addition, a single versatile
RL policy can be trained on multiple articulated object manipulation tasks
simultaneously in simulation and shows great generalizability to novel
categories and instances. Experimental results demonstrate the effectiveness of
our framework in both simulation and real-world settings. Our code is available
at
https://github.com/THU-VCLab/Part-Guided-3D-RL-for-Sim2Real-Articulated-Object-Manipulation.

摘要：操縱未見的關節物體通過視覺回饋是一個至關重要的任務，但對於真正的機器人來說卻是一個具有挑戰性的任務。現有的基於學習的解決方案主要集中於視覺能力學習或其他預先訓練的視覺模型，以指導操作策略，這對於現實世界場景中的新實例來說面臨挑戰。在本文中，我們提出了一個新穎的部件引導 3D RL 框架，它可以學習在沒有演示的情況下操縱關節物體。我們結合了 2D 分割和 3D RL 的優勢來提高 RL 策略訓練的效率。為了提高策略在真實機器人上的穩定性，我們設計了一個幀一致的不確定性感知採樣 (FUS) 策略，以獲得一個簡潔的分層 3D 表示。此外，一個單一的通用 RL 策略可以在模擬中同時訓練多個關節物體操縱任務，並對新的類別和實例表現出很強的泛化能力。實驗結果證明了我們框架在模擬和現實世界設置中的有效性。我們的代碼可以在以下位置獲得：
https://github.com/THU-VCLab/Part-Guided-3D-RL-for-Sim2Real-Articulated-Object-Manipulation。

##### **When to Trust LLMs: Aligning Confidence with Response Quality**
2404.17287v1 by Shuchang Tao,Liuyi Yao,Hanxing Ding,Yuexiang Xie,Qi Cao,Fei Sun,Jinyang Gao,Huawei Shen,Bolin Ding

Despite the success of large language models (LLMs) in natural language
generation, much evidence shows that LLMs may produce incorrect or nonsensical
text. This limitation highlights the importance of discerning when to trust
LLMs, especially in safety-critical domains. Existing methods, which rely on
verbalizing confidence to tell the reliability by inducing top-k responses and
sampling-aggregating multiple responses, often fail, due to the lack of
objective guidance of confidence. To address this, we propose
CONfidence-Quality-ORDerpreserving alignment approach (CONQORD), leveraging
reinforcement learning with a tailored dual-component reward function. This
function encompasses quality reward and orderpreserving alignment reward
functions. Specifically, the order-preserving reward incentivizes the model to
verbalize greater confidence for responses of higher quality to align the order
of confidence and quality. Experiments demonstrate that our CONQORD
significantly improves the alignment performance between confidence levels and
response accuracy, without causing the model to become over-cautious.
Furthermore, the aligned confidence provided by CONQORD informs when to trust
LLMs, and acts as a determinant for initiating the retrieval process of
external knowledge. Aligning confidence with response quality ensures more
transparent and reliable responses, providing better trustworthiness.

摘要：儘管大型語言模型 (LLM) 在自然語言生成方面取得成功，許多證據顯示，LLM 可能會產生不正確或無意義的文字。此限制突顯出辨別何時信任 LLM 的重要性，尤其是在安全關鍵領域。現有方法依賴於表達信心來透過誘導前 k 個回應和取樣彙總多個回應來判斷可靠性，由於缺乏客觀的信心指導，因此常常會失敗。為了解決此問題，我們提出 CONfidence-Quality-ORDerpreserving alignment approach (CONQORD)，利用強化學習搭配量身打造的雙元件獎勵函數。此函數包含品質獎勵和 orderpreserving alignment 獎勵函數。具體來說，order-preserving 獎勵會激勵模型對品質較高的回應表達更高的信心，以比對信心和品質的順序。實驗證明，我們的 CONQORD 大幅改善了信心層級和回應準確度之間的比對效能，而不會讓模型變得過於謹慎。此外，CONQORD 提供的比對信心會說明何時信任 LLM，並作為啟動外部知識擷取程序的決定因素。將信心與回應品質比對可確保回應更透明且更可靠，提供更好的可信度。

##### **Reinforcement Retrieval Leveraging Fine-grained Feedback for Fact Checking News Claims with Black-Box LLM**
2404.17283v1 by Xuan Zhang,Wei Gao

Retrieval-augmented language models have exhibited promising performance
across various areas of natural language processing (NLP), including
fact-critical tasks. However, due to the black-box nature of advanced large
language models (LLMs) and the non-retrieval-oriented supervision signal of
specific tasks, the training of retrieval model faces significant challenges
under the setting of black-box LLM. We propose an approach leveraging
Fine-grained Feedback with Reinforcement Retrieval (FFRR) to enhance
fact-checking on news claims by using black-box LLM. FFRR adopts a two-level
strategy to gather fine-grained feedback from the LLM, which serves as a reward
for optimizing the retrieval policy, by rating the retrieved documents based on
the non-retrieval ground truth of the task. We evaluate our model on two public
datasets for real-world news claim verification, and the results demonstrate
that FFRR achieves significant improvements over strong LLM-enabled and non-LLM
baselines.

摘要：檢索增強語言模型已在自然語言處理 (NLP) 的各個領域展現出良好的效能，包含事實驗證任務。然而，由於進階大型語言模型 (LLM) 的黑箱性質，以及特定任務的非檢索導向監督訊號，在黑箱 LLM 的設定下，檢索模型的訓練面臨重大挑戰。我們提出一個利用強化檢索微調回饋 (FFRR) 的方法，以使用黑箱 LLM 增強新聞聲明的查核。FFRR 採用一個兩層策略，從 LLM 收集微調回饋，透過根據任務的非檢索真實情況評分檢索到的文件，作為最佳化檢索政策的獎勵。我們使用兩個公共資料集評估我們的模型，以進行真實世界的新聞聲明驗證，結果顯示 FFRR 在強大的 LLM 啟用和非 LLM 基準上獲得顯著改進。

##### **Enhancing Privacy and Security of Autonomous UAV Navigation**
2404.17225v1 by Vatsal Aggarwal,Arjun Ramesh Kaushik,Charanjit Jutla,Nalini Ratha

Autonomous Unmanned Aerial Vehicles (UAVs) have become essential tools in
defense, law enforcement, disaster response, and product delivery. These
autonomous navigation systems require a wireless communication network, and of
late are deep learning based. In critical scenarios such as border protection
or disaster response, ensuring the secure navigation of autonomous UAVs is
paramount. But, these autonomous UAVs are susceptible to adversarial attacks
through the communication network or the deep learning models - eavesdropping /
man-in-the-middle / membership inference / reconstruction. To address this
susceptibility, we propose an innovative approach that combines Reinforcement
Learning (RL) and Fully Homomorphic Encryption (FHE) for secure autonomous UAV
navigation. This end-to-end secure framework is designed for real-time video
feeds captured by UAV cameras and utilizes FHE to perform inference on
encrypted input images. While FHE allows computations on encrypted data,
certain computational operators are yet to be implemented. Convolutional neural
networks, fully connected neural networks, activation functions and OpenAI Gym
Library are meticulously adapted to the FHE domain to enable encrypted data
processing. We demonstrate the efficacy of our proposed approach through
extensive experimentation. Our proposed approach ensures security and privacy
in autonomous UAV navigation with negligible loss in performance.

摘要：自主無人機 (UAV) 已成為國防、執法、災害應變和產品遞送中的重要工具。這些自主導航系統需要無線通訊網路，並且最近是基於深度學習。在邊境保護或災害應變等關鍵情境中，確保自主無人機的安全導航至關重要。但是，這些自主無人機容易受到透過通訊網路或深度學習模型的對抗性攻擊 - 竊聽 / 中間人 / 會員推論 / 重建。為了解決這種敏感性，我們提出了一種創新的方法，結合強化學習 (RL) 和全同態加密 (FHE) 以確保自主無人機安全導航。這個端到端安全架構是針對無人機相機捕捉的即時視訊串流所設計，並利用 FHE 對加密輸入影像執行推論。雖然 FHE 允許對加密資料進行運算，但某些運算運算子尚未實作。卷積神經網路、全連接神經網路、啟用功能和 OpenAI Gym 函式庫經過細心調整以適應 FHE 領域，以啟用加密資料處理。我們透過廣泛的實驗證明了我們所提出的方法的功效。我們所提出的方法確保在自主無人機導航中的安全性與隱私，且效能損失可以忽略不計。

##### **Prompting Techniques for Reducing Social Bias in LLMs through System 1 and System 2 Cognitive Processes**
2404.17218v1 by Mahammed Kamruzzaman,Gene Louis Kim

Dual process theory posits that human cognition arises via two systems.
System 1, which is a quick, emotional, and intuitive process, which is subject
to cognitive biases, and System 2, a slow, onerous, and deliberate process. NLP
researchers often compare zero-shot prompting in LLMs to System 1 reasoning and
chain-of-thought (CoT) prompting to System 2. In line with this interpretation,
prior research has found that using CoT prompting in LLMs leads to reduced
gender bias. We investigate the relationship between bias, CoT prompting, and
dual process theory in LLMs directly. We compare zero-shot, CoT, and a variety
of dual process theory-based prompting strategies on two bias datasets spanning
nine different social bias categories. We also use human and machine personas
to determine whether the effects of dual process theory in LLMs are based on
modeling human cognition or inherent to the system. We find that a human
persona, System 2, and CoT prompting all tend to reduce social biases in LLMs,
though the best combination of features depends on the exact model and bias
category -- resulting in up to a 13 percent drop in stereotypical judgments by
an LLM.

摘要：双重过程理论认为人类认知通过两个系统产生。
系统 1 是一个快速、情绪化且直观的过程，容易受到认知偏差的影响，而系统 2 则是一个缓慢、繁琐且深思熟虑的过程。NLP 研究人员经常将 LLM 中的零样本提示与系统 1 推理和思想链 (CoT) 提示与系统 2 进行比较。根据这种解释，先前的研究发现，在 LLM 中使用 CoT 提示会导致性别偏见减少。我们直接研究了 LLM 中偏见、CoT 提示和双重过程理论之间的关系。我们在跨越九个不同社会偏见类别的两个偏见数据集上比较了零样本、CoT 和各种基于双重过程理论的提示策略。我们还使用人类和机器角色来确定 LLM 中双重过程理论的影响是基于对人类认知的建模还是系统固有的。我们发现，人类角色、系统 2 和 CoT 提示都倾向于减少 LLM 中的社会偏见，尽管最佳功能组合取决于确切的模型和偏见类别——导致 LLM 的刻板判断下降多达 13 个百分点。

##### **Prompting Towards Alleviating Code-Switched Data Scarcity in Under-Resourced Languages with GPT as a Pivot**
2404.17216v1 by Michelle Terblanche,Kayode Olaleye,Vukosi Marivate

Many multilingual communities, including numerous in Africa, frequently
engage in code-switching during conversations. This behaviour stresses the need
for natural language processing technologies adept at processing code-switched
text. However, data scarcity, particularly in African languages, poses a
significant challenge, as many are low-resourced and under-represented. In this
study, we prompted GPT 3.5 to generate Afrikaans--English and Yoruba--English
code-switched sentences, enhancing diversity using topic-keyword pairs,
linguistic guidelines, and few-shot examples. Our findings indicate that the
quality of generated sentences for languages using non-Latin scripts, like
Yoruba, is considerably lower when compared with the high Afrikaans-English
success rate. There is therefore a notable opportunity to refine prompting
guidelines to yield sentences suitable for the fine-tuning of language models.
We propose a framework for augmenting the diversity of synthetically generated
code-switched data using GPT and propose leveraging this technology to mitigate
data scarcity in low-resourced languages, underscoring the essential role of
native speakers in this process.

摘要：許多多元語言社群，包括非洲的許多社群，在對話中經常進行語言轉換。這種行為強調了自然語言處理技術在處理語言轉換文本方面的必要性。然而，資料的稀少，特別是非洲語言，構成了一個重大的挑戰，因為許多語言資源匱乏且代表性不足。在本研究中，我們提示 GPT 3.5 產生南非語-英語和約魯巴語-英語的語言轉換句子，使用主題關鍵字對、語言指南和少數範例來增強多樣性。我們的研究結果表明，與南非語-英語的高成功率相比，使用非拉丁文字的語言（如約魯巴語）所產生的句子的品質明顯較低。因此，有一個顯著的機會可以優化提示指南，以產生適合微調語言模型的句子。我們提出了一個框架，用於使用 GPT 增加合成語言轉換資料的多樣性，並建議利用這項技術來減輕資源匱乏語言的資料稀少問題，強調了母語人士在此過程中扮演的重要角色。

##### **Human-Imperceptible Retrieval Poisoning Attacks in LLM-Powered Applications**
2404.17196v1 by Quan Zhang,Binqi Zeng,Chijin Zhou,Gwihwan Go,Heyuan Shi,Yu Jiang

Presently, with the assistance of advanced LLM application development
frameworks, more and more LLM-powered applications can effortlessly augment the
LLMs' knowledge with external content using the retrieval augmented generation
(RAG) technique. However, these frameworks' designs do not have sufficient
consideration of the risk of external content, thereby allowing attackers to
undermine the applications developed with these frameworks. In this paper, we
reveal a new threat to LLM-powered applications, termed retrieval poisoning,
where attackers can guide the application to yield malicious responses during
the RAG process. Specifically, through the analysis of LLM application
frameworks, attackers can craft documents visually indistinguishable from
benign ones. Despite the documents providing correct information, once they are
used as reference sources for RAG, the application is misled into generating
incorrect responses. Our preliminary experiments indicate that attackers can
mislead LLMs with an 88.33\% success rate, and achieve a 66.67\% success rate
in the real-world application, demonstrating the potential impact of retrieval
poisoning.

摘要：目前，在進階 LLM 應用程式開發框架的協助下，愈來愈多由 LLM 驅動的應用程式可以輕鬆地利用擷取擴充生成 (RAG) 技術，以外部內容擴充 LLM 的知識。然而，這些框架的設計並未充分考量外部內容的風險，因此允許攻擊者破壞使用這些框架開發的應用程式。在本文中，我們揭露了一個針對 LLM 驅動應用程式的全新威脅，稱為擷取中毒，攻擊者可以在 RAG 程序期間引導應用程式產生惡意回應。具體來說，攻擊者可以透過分析 LLM 應用程式框架，製作出在視覺上與良性文件難以區分的檔案。儘管這些文件提供了正確的資訊，但一旦它們被用作 RAG 的參考來源，應用程式就會被誤導而產生不正確的回應。我們的初步實驗表明，攻擊者可以以 88.33% 的成功率誤導 LLM，並在實際應用中達到 66.67% 的成功率，這證明了擷取中毒的潛在影響。

##### **TIGQA:An Expert Annotated Question Answering Dataset in Tigrinya**
2404.17194v1 by Hailay Teklehaymanot,Dren Fazlija,Niloy Ganguly,Gourab K. Patro,Wolfgang Nejdl

The absence of explicitly tailored, accessible annotated datasets for
educational purposes presents a notable obstacle for NLP tasks in languages
with limited resources.This study initially explores the feasibility of using
machine translation (MT) to convert an existing dataset into a Tigrinya dataset
in SQuAD format. As a result, we present TIGQA, an expert annotated educational
dataset consisting of 2.68K question-answer pairs covering 122 diverse topics
such as climate, water, and traffic. These pairs are from 537 context
paragraphs in publicly accessible Tigrinya and Biology books. Through
comprehensive analyses, we demonstrate that the TIGQA dataset requires skills
beyond simple word matching, requiring both single-sentence and
multiple-sentence inference abilities. We conduct experiments using
state-of-the art MRC methods, marking the first exploration of such models on
TIGQA. Additionally, we estimate human performance on the dataset and juxtapose
it with the results obtained from pretrained models.The notable disparities
between human performance and best model performance underscore the potential
for further enhancements to TIGQA through continued research. Our dataset is
freely accessible via the provided link to encourage the research community to
address the challenges in the Tigrinya MRC.

摘要：由於缺乏為教育目的量身打造、可存取的註解資料集，對資源有限語言中的自然語言處理任務構成顯著障礙。本研究最初探討使用機器翻譯 (MT) 將現有資料集轉換成 SQuAD 格式的提格雷尼亞語資料集的可行性。因此，我們提出 TIGQA，這是一個專家註解的教育資料集，包含 2.68K 個問答對，涵蓋 122 個不同的主題，例如氣候、水和交通。這些對來自 537 個公開可存取的提格雷尼亞語和生物學書籍中的背景段落。透過全面的分析，我們證明 TIGQA 資料集需要超越單純字詞配對的技能，同時需要單句和多句推論能力。我們使用最先進的 MRC 方法進行實驗，標誌著首次在 TIGQA 上探索此類模型。此外，我們估計人類在資料集上的表現，並將其與從預訓練模型獲得的結果並列。人類表現和最佳模型表現之間的顯著差異強調了透過持續研究進一步增強 TIGQA 的潛力。我們的資料集可透過提供的連結免費取得，以鼓勵研究社群解決提格雷尼亞語 MRC 中的挑戰。

##### **MCSDNet: Mesoscale Convective System Detection Network via Multi-scale Spatiotemporal Information**
2404.17186v1 by Jiajun Liang,Baoquan Zhang,Yunming Ye,Xutao Li,Chuyao Luo,Xukai Fu

The accurate detection of Mesoscale Convective Systems (MCS) is crucial for
meteorological monitoring due to their potential to cause significant
destruction through severe weather phenomena such as hail, thunderstorms, and
heavy rainfall. However, the existing methods for MCS detection mostly targets
on single-frame detection, which just considers the static characteristics and
ignores the temporal evolution in the life cycle of MCS. In this paper, we
propose a novel encoder-decoder neural network for MCS detection(MCSDNet).
MCSDNet has a simple architecture and is easy to expand. Different from the
previous models, MCSDNet targets on multi-frames detection and leverages
multi-scale spatiotemporal information for the detection of MCS regions in
remote sensing imagery(RSI). As far as we know, it is the first work to utilize
multi-scale spatiotemporal information to detect MCS regions. Firstly, we
design a multi-scale spatiotemporal information module to extract multi-level
semantic from different encoder levels, which makes our models can extract more
detail spatiotemporal features. Secondly, a Spatiotemporal Mix Unit(STMU) is
introduced to MCSDNet to capture both intra-frame features and inter-frame
correlations, which is a scalable module and can be replaced by other
spatiotemporal module, e.g., CNN, RNN, Transformer and our proposed Dual
Spatiotemporal Attention(DSTA). This means that the future works about
spatiotemporal modules can be easily integrated to our model. Finally, we
present MCSRSI, the first publicly available dataset for multi-frames MCS
detection based on visible channel images from the FY-4A satellite. We also
conduct several experiments on MCSRSI and find that our proposed MCSDNet
achieve the best performance on MCS detection task when comparing to other
baseline methods.

摘要：中尺度对流系统（MCS）的准确检测对于气象监测至关重要，因为它们有可能通过冰雹、雷暴和暴雨等恶劣天气现象造成重大破坏。然而，现有的 MCS 检测方法主要针对单帧检测，仅考虑静态特征，而忽略了 MCS 生命周期中的时间演变。在本文中，我们提出了一种用于 MCS 检测的新型编码器-解码器神经网络（MCSDNet）。MCSDNet 架构简单，易于扩展。与之前的模型不同，MCSDNet 针对多帧检测，并利用多尺度时空信息来检测遥感图像（RSI）中的 MCS 区域。据我们所知，这是第一个利用多尺度时空信息来检测 MCS 区域的工作。首先，我们设计了一个多尺度时空信息模块，从不同的编码器层中提取多级语义，这使得我们的模型可以提取更多细节的时空特征。其次，在 MCSDNet 中引入了一个时空混合单元（STMU）来捕获帧内特征和帧间相关性，这是一个可扩展的模块，可以被其他时空模块（例如 CNN、RNN、Transformer 和我们提出的双时空注意力（DSTA））替换。这意味着关于时空模块的未来工作可以很容易地集成到我们的模型中。最后，我们提出了 MCSRSI，这是第一个基于 FY-4A 卫星可见光通道图像的多帧 MCS 检测公开数据集。我们还对 MCSRSI 进行了多项实验，发现与其他基线方法相比，我们提出的 MCSDNet 在 MCS 检测任务上取得了最佳性能。

##### **A Unified Label-Aware Contrastive Learning Framework for Few-Shot Named Entity Recognition**
2404.17178v1 by Haojie Zhang,Yimeng Zhuang

Few-shot Named Entity Recognition (NER) aims to extract named entities using
only a limited number of labeled examples. Existing contrastive learning
methods often suffer from insufficient distinguishability in context vector
representation because they either solely rely on label semantics or completely
disregard them. To tackle this issue, we propose a unified label-aware
token-level contrastive learning framework. Our approach enriches the context
by utilizing label semantics as suffix prompts. Additionally, it simultaneously
optimizes context-context and context-label contrastive learning objectives to
enhance generalized discriminative contextual representations.Extensive
experiments on various traditional test domains (OntoNotes, CoNLL'03, WNUT'17,
GUM, I2B2) and the large-scale few-shot NER dataset (FEWNERD) demonstrate the
effectiveness of our approach. It outperforms prior state-of-the-art models by
a significant margin, achieving an average absolute gain of 7% in micro F1
scores across most scenarios. Further analysis reveals that our model benefits
from its powerful transfer capability and improved contextual representations.

摘要：小样本命名实体识别 (NER) 旨在仅使用数量有限的标记示例来提取命名实体。现有的对比学习方法通常在上下文向量表示中缺乏足够的区分度，因为它们要么仅依赖于标签语义，要么完全不考虑它们。为了解决这个问题，我们提出了一个统一的标签感知令牌级对比学习框架。我们的方法通过利用标签语义作为后缀提示来丰富上下文。此外，它同时优化上下文-上下文和上下文-标签对比学习目标，以增强广义判别上下文表示。在各种传统测试域（OntoNotes、CoNLL'03、WNUT'17、GUM、I2B2）和大规模小样本 NER 数据集（FEWNERD）上的大量实验证明了我们方法的有效性。它以显著的优势优于先前的最先进模型，在大多数场景中，微型 F1 分数平均绝对增益为 7%。进一步的分析表明，我们的模型受益于其强大的转移能力和改进的上下文表示。

##### **Exploring Beyond Logits: Hierarchical Dynamic Labeling Based on Embeddings for Semi-Supervised Classification**
2404.17173v1 by Yanbiao Ma,Licheng Jiao,Fang Liu,Lingling Li,Shuyuan Yang,Xu Liu

In semi-supervised learning, methods that rely on confidence learning to
generate pseudo-labels have been widely proposed. However, increasing research
finds that when faced with noisy and biased data, the model's representation
network is more reliable than the classification network. Additionally, label
generation methods based on model predictions often show poor adaptability
across different datasets, necessitating customization of the classification
network. Therefore, we propose a Hierarchical Dynamic Labeling (HDL) algorithm
that does not depend on model predictions and utilizes image embeddings to
generate sample labels. We also introduce an adaptive method for selecting
hyperparameters in HDL, enhancing its versatility. Moreover, HDL can be
combined with general image encoders (e.g., CLIP) to serve as a fundamental
data processing module. We extract embeddings from datasets with class-balanced
and long-tailed distributions using pre-trained semi-supervised models.
Subsequently, samples are re-labeled using HDL, and the re-labeled samples are
used to further train the semi-supervised models. Experiments demonstrate
improved model performance, validating the motivation that representation
networks are more reliable than classifiers or predictors. Our approach has the
potential to change the paradigm of pseudo-label generation in semi-supervised
learning.

摘要：在半监督学习中，依赖置信学习来生成伪标签的方法已被广泛提出。然而，越来越多的研究发现，当面临嘈杂且有偏差的数据时，模型的表示网络比分类网络更可靠。此外，基于模型预测的标签生成方法通常在不同数据集上表现出较差的适应性，需要对分类网络进行定制。因此，我们提出了一种不依赖于模型预测并利用图像嵌入来生成样本标签的分层动态标签 (HDL) 算法。我们还引入了一种自适应方法来选择 HDL 中的超参数，增强其通用性。此外，HDL 可以与通用图像编码器（例如 CLIP）相结合，作为基本数据处理模块。我们使用预训练的半监督模型从具有类平衡和长尾分布的数据集中提取嵌入。随后，使用 HDL 重新标记样本，并使用重新标记的样本进一步训练半监督模型。实验表明模型性能得到提升，验证了表示网络比分类器或预测器更可靠的动机。我们的方法有可能改变半监督学习中伪标签生成范式。

##### **Quantifying Memorization of Domain-Specific Pre-trained Language Models using Japanese Newspaper and Paywalls**
2404.17143v1 by Shotaro Ishihara

Dominant pre-trained language models (PLMs) have been successful in
high-quality natural language generation. However, the analysis of their
generation is not mature: do they acquire generalizable linguistic
abstractions, or do they simply memorize and recover substrings of the training
data? Especially, few studies focus on domain-specific PLM. In this study, we
pre-trained domain-specific GPT-2 models using a limited corpus of Japanese
newspaper articles and quantified memorization of training data by comparing
them with general Japanese GPT-2 models. Our experiments revealed that
domain-specific PLMs sometimes "copy and paste" on a large scale. Furthermore,
we replicated the empirical finding that memorization is related to
duplication, model size, and prompt length, in Japanese the same as in previous
English studies. Our evaluations are relieved from data contamination concerns
by focusing on newspaper paywalls, which prevent their use as training data. We
hope that our paper encourages a sound discussion such as the security and
copyright of PLMs.

摘要：目前主導的預先訓練語言模型 (PLM) 已成功應用於高品質自然語言生成。然而，對於其生成的分析尚未成熟：它們是否獲得可概括的語言抽象，或者它們只是記憶並恢復訓練資料的子字串？特別是，很少有研究專注於特定領域的 PLM。在本研究中，我們使用有限的日文報紙文章語料庫預先訓練特定領域的 GPT-2 模型，並透過與一般日文 GPT-2 模型進行比較，量化訓練資料的記憶。我們的實驗顯示，特定領域的 PLM 有時會大規模「複製貼上」。此外，我們複製了經驗發現，即記憶與重複、模型大小和提示長度有關，這在日文與先前的英文研究中相同。我們的評估透過關注報紙付費牆（防止其用作訓練資料）來消除資料污染問題。我們希望我們的論文能鼓勵健全的討論，例如 PLM 的安全性與著作權。

##### **Small Language Models Need Strong Verifiers to Self-Correct Reasoning**
2404.17140v1 by Yunxiang Zhang,Muhammad Khalifa,Lajanugen Logeswaran,Jaekyeom Kim,Moontae Lee,Honglak Lee,Lu Wang

Self-correction has emerged as a promising solution to boost the reasoning
performance of large language models (LLMs), where LLMs refine their solutions
using self-generated critiques that pinpoint the errors. This work explores
whether smaller-size (<= 13B) language models (LMs) have the ability of
self-correction on reasoning tasks with minimal inputs from stronger LMs. We
propose a novel pipeline that prompts smaller LMs to collect self-correction
data that supports the training of self-refinement abilities. First, we
leverage correct solutions to guide the model in critiquing their incorrect
responses. Second, the generated critiques, after filtering, are used for
supervised fine-tuning of the self-correcting reasoner through solution
refinement. Our experimental results show improved self-correction abilities of
two models on five datasets spanning math and commonsense reasoning, with
notable performance gains when paired with a strong GPT-4-based verifier,
though limitations are identified when using a weak self-verifier for
determining when to correct.

摘要：自校正已成为提升大型语言模型 (LLM) 推理性能的一种有前途的解决方案，其中 LLM 使用自生成的批评来查明错误，从而优化其解决方案。这项工作探讨了较小规模 (<= 13B) 的语言模型 (LM) 在推理任务中是否具有自校正能力，且仅从更强大的 LM 中获得最少的输入。我们提出了一种新颖的管道，它提示较小的 LM 收集自校正数据，以支持自优化能力的训练。首先，我们利用正确的解决方案来指导模型批评其不正确的响应。其次，在经过筛选后，生成的批评用于通过解决方案优化对自校正推理器的监督微调。我们的实验结果表明，在五个跨越数学和常识推理的数据集上，两个模型的自校正能力得到了提升，当与基于 GPT-4 的强大验证器配对时，性能提升显著，尽管在使用较弱的自验证器来确定何时校正时，会发现一些局限性。

##### **Automated Data Visualization from Natural Language via Large Language Models: An Exploratory Study**
2404.17136v1 by Yang Wu,Yao Wan,Hongyu Zhang,Yulei Sui,Wucai Wei,Wei Zhao,Guandong Xu,Hai Jin

The Natural Language to Visualization (NL2Vis) task aims to transform
natural-language descriptions into visual representations for a grounded table,
enabling users to gain insights from vast amounts of data. Recently, many deep
learning-based approaches have been developed for NL2Vis. Despite the
considerable efforts made by these approaches, challenges persist in
visualizing data sourced from unseen databases or spanning multiple tables.
Taking inspiration from the remarkable generation capabilities of Large
Language Models (LLMs), this paper conducts an empirical study to evaluate
their potential in generating visualizations, and explore the effectiveness of
in-context learning prompts for enhancing this task. In particular, we first
explore the ways of transforming structured tabular data into sequential text
prompts, as to feed them into LLMs and analyze which table content contributes
most to the NL2Vis. Our findings suggest that transforming structured tabular
data into programs is effective, and it is essential to consider the table
schema when formulating prompts. Furthermore, we evaluate two types of LLMs:
finetuned models (e.g., T5-Small) and inference-only models (e.g., GPT-3.5),
against state-of-the-art methods, using the NL2Vis benchmarks (i.e., nvBench).
The experimental results reveal that LLMs outperform baselines, with
inference-only models consistently exhibiting performance improvements, at
times even surpassing fine-tuned models when provided with certain few-shot
demonstrations through in-context learning. Finally, we analyze when the LLMs
fail in NL2Vis, and propose to iteratively update the results using strategies
such as chain-of-thought, role-playing, and code-interpreter. The experimental
results confirm the efficacy of iterative updates and hold great potential for
future study.

摘要：自然語言到視覺化 (NL2Vis) 任務旨在將自然語言描述轉換為接地表的視覺表示，使用戶能夠從大量數據中獲取見解。最近，已經為 NL2Vis 開發了許多基於深度學習的方法。儘管這些方法付出了相當大的努力，但在對來自未見數據庫或跨越多個表的數據進行視覺化時，挑戰仍然存在。受大型語言模型 (LLM) 的卓越生成能力的啟發，本文進行了一項實證研究，以評估其在生成視覺化方面的潛力，並探索情境學習提示在增強此任務中的有效性。特別是，我們首先探索將結構化表格數據轉換為順序文本提示的方法，以便將它們輸入到 LLM 中並分析哪個表格內容對 NL2Vis 的貢獻最大。我們的研究結果表明，將結構化表格數據轉換為程序是有效的，在制定提示時考慮表格架構至關重要。此外，我們評估了兩種 LLM：微調模型（例如，T5-Small）和僅推理模型（例如，GPT-3.5），針對最先進的方法，使用 NL2Vis 基準（即 nvBench）。實驗結果表明，LLM 優於基準，其中僅推理模型持續表現出性能改進，有時甚至在通過情境學習提供某些少次演示時超過了微調模型。最後，我們分析了 LLM 在 NL2Vis 中何時失敗，並提出使用思想鏈、角色扮演和代碼解釋器等策略迭代更新結果。實驗結果證實了迭代更新的有效性，並對未來的研究具有巨大的潛力。

##### **Process Mining Embeddings: Learning Vector Representations for Petri Nets**
2404.17129v1 by Juan G. Colonna,Ahmed A. Fares,Márcio Duarte,Ricardo Sousa

Process mining offers powerful techniques for discovering, analyzing, and
enhancing real-world business processes. In this context, Petri nets provide an
expressive means of modeling process behavior. However, directly analyzing and
comparing intricate Petri net presents challenges. This study introduces
PetriNet2Vec, a novel unsupervised methodology based on Natural Language
Processing concepts inspired by Doc2Vec and designed to facilitate the
effective comparison, clustering, and classification of process models
represented as embedding vectors. These embedding vectors allow us to quantify
similarities and relationships between different process models. Our
methodology was experimentally validated using the PDC Dataset, featuring 96
diverse Petri net models. We performed cluster analysis, created UMAP
visualizations, and trained a decision tree to provide compelling evidence for
the capability of PetriNet2Vec to discern meaningful patterns and relationships
among process models and their constituent tasks. Through a series of
experiments, we demonstrated that PetriNet2Vec was capable of learning the
structure of Petri nets, as well as the main properties used to simulate the
process models of our dataset. Furthermore, our results showcase the utility of
the learned embeddings in two crucial downstream tasks within process mining
enhancement: process classification and process retrieval.

摘要：流程挖掘提供了用于发现、分析和提升实际业务流程的强大技术。在此背景下，Petri 网提供了建模流程行为的表达方式。然而，直接分析和比较复杂的 Petri 网提出了挑战。本研究介绍了 PetriNet2Vec，这是一种基于自然语言处理概念的新型无监督方法，灵感来自 Doc2Vec，旨在促进将表示为嵌入向量的流程模型的有效比较、聚类和分类。这些嵌入向量使我们能够量化不同流程模型之间的相似性和关系。我们的方法使用 PDC 数据集进行了实验验证，该数据集包含 96 个不同的 Petri 网模型。我们执行了聚类分析，创建了 UMAP 可视化，并训练了一棵决策树，为 PetriNet2Vec 识别流程模型及其组成任务之间的有意义模式和关系的能力提供了令人信服的证据。通过一系列实验，我们证明了 PetriNet2Vec 能够学习 Petri 网的结构，以及用于模拟我们数据集的流程模型的主要属性。此外，我们的结果展示了学习到的嵌入在流程挖掘增强中的两个关键下游任务中的效用：流程分类和流程检索。

##### **Deep Evidential Learning for Dose Prediction**
2404.17126v1 by Hai Siong Tan,Kuancheng Wang,Rafe Mcbeth

In this work, we present a novel application of an uncertainty-quantification
framework called Deep Evidential Learning in the domain of radiotherapy dose
prediction. Using medical images of the Open Knowledge-Based Planning Challenge
dataset, we found that this model can be effectively harnessed to yield
uncertainty estimates that inherited correlations with prediction errors upon
completion of network training. This was achieved only after reformulating the
original loss function for a stable implementation. We found that (i)epistemic
uncertainty was highly correlated with prediction errors, with various
association indices comparable or stronger than those for Monte-Carlo Dropout
and Deep Ensemble methods, (ii)the median error varied with uncertainty
threshold much more linearly for epistemic uncertainty in Deep Evidential
Learning relative to these other two conventional frameworks, indicative of a
more uniformly calibrated sensitivity to model errors, (iii)relative to
epistemic uncertainty, aleatoric uncertainty demonstrated a more significant
shift in its distribution in response to Gaussian noise added to CT intensity,
compatible with its interpretation as reflecting data noise. Collectively, our
results suggest that Deep Evidential Learning is a promising approach that can
endow deep-learning models in radiotherapy dose prediction with statistical
robustness. Towards enhancing its clinical relevance, we demonstrate how we can
use such a model to construct the predicted Dose-Volume-Histograms' confidence
intervals.

摘要：在本研究中，我们提出不确定性量化框架（称为深度证据学习）在放射治疗剂量预测领域中的新应用。使用开放知识计划挑战数据集的医学图像，我们发现该模型可以有效利用，在网络训练完成后产生与预测误差相关的继承相关性的不确定性估计。这仅在为稳定实现重新表述原始损失函数后才实现。我们发现 (i) 认知不确定性与预测误差高度相关，各种关联指数与蒙特卡洛丢弃法和深度集成方法相当或更强，(ii) 相对于其他两个传统框架，深度证据学习中认知不确定性的中值误差随不确定性阈值变化更为线性，表明对模型误差的灵敏度更均匀地校准，(iii) 相对于认知不确定性，偶然不确定性在响应于添加到 CT 强度的 Gaussian 噪声时表现出其分布的更显着变化，符合其解释为反映数据噪声。总的来说，我们的结果表明，深度证据学习是一种很有前途的方法，可以为放射治疗剂量预测中的深度学习模型赋予统计稳健性。为了提高其临床相关性，我们演示了如何使用这种模型来构建预测剂量体积直方图的置信区间。

##### **Text Sentiment Analysis and Classification Based on Bidirectional Gated Recurrent Units (GRUs) Model**
2404.17123v1 by Wei Xu,Jianlong Chen,Zhicheng Ding,Jinyin Wang

This paper explores the importance of text sentiment analysis and
classification in the field of natural language processing, and proposes a new
approach to sentiment analysis and classification based on the bidirectional
gated recurrent units (GRUs) model. The study firstly analyses the word cloud
model of the text with six sentiment labels, and then carries out data
preprocessing, including the steps of removing special symbols, punctuation
marks, numbers, stop words and non-alphabetic parts. Subsequently, the data set
is divided into training set and test set, and through model training and
testing, it is found that the accuracy of the validation set is increased from
85% to 93% with training, which is an increase of 8%; at the same time, the
loss value of the validation set decreases from 0.7 to 0.1 and tends to be
stable, and the model is gradually close to the actual value, which can
effectively classify the text emotions. The confusion matrix shows that the
accuracy of the model on the test set reaches 94.8%, the precision is 95.9%,
the recall is 99.1%, and the F1 score is 97.4%, which proves that the model has
good generalisation ability and classification effect. Overall, the study
demonstrated an effective method for text sentiment analysis and classification
with satisfactory results.

摘要：本文探讨了文本情感分析和分类在自然语言处理领域的重要性，并提出了一种基于双向门控循环单元 (GRU) 模型的情感分析和分类新方法。该研究首先分析了文本的词云模型，该模型具有六个情感标签，然后进行数据预处理，包括去除特殊符号、标点符号、数字、停用词和非字母部分的步骤。随后，将数据集划分为训练集和测试集，并通过模型训练和测试发现，训练后验证集的准确率从 85% 提高到 93%，提高了 8%；同时，验证集的损失值从 0.7 下降到 0.1 并趋于稳定，模型逐渐接近实际值，可以有效地对文本情感进行分类。混淆矩阵表明，该模型在测试集上的准确率达到 94.8%，精确率为 95.9%，召回率为 99.1%，F1 得分为 97.4%，证明该模型具有良好的泛化能力和分类效果。总体而言，该研究展示了一种有效的方法，用于文本情感分析和分类，并取得了令人满意的结果。

##### **2M-NER: Contrastive Learning for Multilingual and Multimodal NER with Language and Modal Fusion**
2404.17122v1 by Dongsheng Wang,Xiaoqin Feng,Zeming Liu,Chuan Wang

Named entity recognition (NER) is a fundamental task in natural language
processing that involves identifying and classifying entities in sentences into
pre-defined types. It plays a crucial role in various research fields,
including entity linking, question answering, and online product
recommendation. Recent studies have shown that incorporating multilingual and
multimodal datasets can enhance the effectiveness of NER. This is due to
language transfer learning and the presence of shared implicit features across
different modalities. However, the lack of a dataset that combines
multilingualism and multimodality has hindered research exploring the
combination of these two aspects, as multimodality can help NER in multiple
languages simultaneously. In this paper, we aim to address a more challenging
task: multilingual and multimodal named entity recognition (MMNER), considering
its potential value and influence. Specifically, we construct a large-scale
MMNER dataset with four languages (English, French, German and Spanish) and two
modalities (text and image). To tackle this challenging MMNER task on the
dataset, we introduce a new model called 2M-NER, which aligns the text and
image representations using contrastive learning and integrates a multimodal
collaboration module to effectively depict the interactions between the two
modalities. Extensive experimental results demonstrate that our model achieves
the highest F1 score in multilingual and multimodal NER tasks compared to some
comparative and representative baselines. Additionally, in a challenging
analysis, we discovered that sentence-level alignment interferes a lot with NER
models, indicating the higher level of difficulty in our dataset.

摘要：命名實體辨識 (NER) 是自然語言處理中的一項基本任務，涉及將句子中的實體識別並分類為預先定義的類型。它在各種研究領域中扮演著至關重要的角色，包括實體連結、問題解答和線上產品推薦。最近的研究表明，納入多語言和多模態資料集可以增強 NER 的效能。這是由於語言遷移學習和不同模態之間存在共享的隱含特徵。然而，缺乏結合多語言和多模態的資料集阻礙了探索這兩個面向結合的研究，因為多模態可以同時幫助多種語言的 NER。在本文中，我們旨在解決一項更具挑戰性的任務：多語言和多模態命名實體辨識 (MMNER)，考量其潛在價值和影響力。具體來說，我們構建了一個包含四種語言（英語、法語、德語和西班牙語）和兩種模態（文字和影像）的大規模 MMNER 資料集。為了在資料集上應對這個具有挑戰性的 MMNER 任務，我們引入了一個名為 2M-NER 的新模型，它使用對比學習比對文字和影像表示，並整合了一個多模態協作模組來有效描繪這兩種模態之間的互動。廣泛的實驗結果證明，與一些比較性和代表性的基線相比，我們的模型在多語言和多模態 NER 任務中取得了最高的 F1 分數。此外，在一個具有挑戰性的分析中，我們發現句子層級的比對會對 NER 模型造成很大的干擾，這表示我們的資料集難度較高。

##### **Talking Nonsense: Probing Large Language Models' Understanding of Adversarial Gibberish Inputs**
2404.17120v2 by Valeriia Cherepanova,James Zou

Large language models (LLMs) exhibit excellent ability to understand human
languages, but do they also understand their own language that appears
gibberish to us? In this work we delve into this question, aiming to uncover
the mechanisms underlying such behavior in LLMs. We employ the Greedy
Coordinate Gradient optimizer to craft prompts that compel LLMs to generate
coherent responses from seemingly nonsensical inputs. We call these inputs LM
Babel and this work systematically studies the behavior of LLMs manipulated by
these prompts. We find that the manipulation efficiency depends on the target
text's length and perplexity, with the Babel prompts often located in lower
loss minima compared to natural prompts. We further examine the structure of
the Babel prompts and evaluate their robustness. Notably, we find that guiding
the model to generate harmful texts is not more difficult than into generating
benign texts, suggesting lack of alignment for out-of-distribution prompts.

摘要：大型語言模型 (LLM) 展現了理解人類語言的絕佳能力，但它們是否也理解對我們來說是胡言亂語的它們自己的語言？在這項工作中，我們深入探討這個問題，旨在揭示 LLM 中這種行為背後的基本機制。我們採用 Greedy Coordinate Gradient 最佳化器來製作提示，促使 LLM 從看似無意義的輸入中產生連貫的回應。我們將這些輸入稱為 LM Babel，這項工作系統性地研究了受這些提示操縱的 LLM 的行為。我們發現操縱效率取決於目標文本的長度和困惑度，與自然提示相比，Babel 提示通常位於較低的損失極小值中。我們進一步檢查了 Babel 提示的結構並評估它們的魯棒性。值得注意的是，我們發現引導模型生成有害文本並不比生成良性文本更困難，這表明對分佈外提示缺乏對齊。

##### **CLARE: Cognitive Load Assessment in REaltime with Multimodal Data**
2404.17098v1 by Anubhav Bhatti,Prithila Angkan,Behnam Behinaein,Zunayed Mahmud,Dirk Rodenburg,Heather Braund,P. James Mclellan,Aaron Ruberto,Geoffery Harrison,Daryl Wilson,Adam Szulewski,Dan Howes,Ali Etemad,Paul Hungler

We present a novel multimodal dataset for Cognitive Load Assessment in
REaltime (CLARE). The dataset contains physiological and gaze data from 24
participants with self-reported cognitive load scores as ground-truth labels.
The dataset consists of four modalities, namely, Electrocardiography (ECG),
Electrodermal Activity (EDA), Electroencephalogram (EEG), and Gaze tracking. To
map diverse levels of mental load on participants during experiments, each
participant completed four nine-minutes sessions on a computer-based operator
performance and mental workload task (the MATB-II software) with varying levels
of complexity in one minute segments. During the experiment, participants
reported their cognitive load every 10 seconds. For the dataset, we also
provide benchmark binary classification results with machine learning and deep
learning models on two different evaluation schemes, namely, 10-fold and
leave-one-subject-out (LOSO) cross-validation. Benchmark results show that for
10-fold evaluation, the convolutional neural network (CNN) based deep learning
model achieves the best classification performance with ECG, EDA, and Gaze. In
contrast, for LOSO, the best performance is achieved by the deep learning model
with ECG, EDA, and EEG.

摘要：我們提出了一個創新的多模態數據集，用於認知負載評估
REaltime (CLARE)。該數據集包含來自 24 位參與者的生理和注視數據，並以自我報告的認知負載分數作為真實標籤。
該數據集包含四種模式，即心電圖 (ECG)、皮膚電活動 (EDA)、腦電圖 (EEG) 和注視追蹤。為了在實驗期間對參與者進行不同程度的心理負載映射，每位參與者在電腦操作員性能和心理工作負載任務（MATB-II 軟體）上完成了四次九分鐘的會議，其中一分鐘的複雜度不同。在實驗期間，參與者每 10 秒報告一次他們的認知負載。對於該數據集，我們還使用機器學習和深度學習模型在兩種不同的評估方案上提供了基準二元分類結果，即 10 倍和留一法 (LOSO) 交叉驗證。基準結果表明，對於 10 倍評估，基於卷積神經網路 (CNN) 的深度學習模型使用 ECG、EDA 和注視實現了最佳分類性能。相比之下，對於 LOSO，使用 ECG、EDA 和 EEG 的深度學習模型實現了最佳性能。

##### **CyNetDiff -- A Python Library for Accelerated Implementation of Network Diffusion Models**
2404.17059v1 by Eliot W. Robson,Dhemath Reddy,Abhishek K. Umrawal

In recent years, there has been increasing interest in network diffusion
models and related problems. The most popular of these are the independent
cascade and linear threshold models. Much of the recent experimental work done
on these models requires a large number of simulations conducted on large
graphs, a computationally expensive task suited for low-level languages.
However, many researchers prefer the use of higher-level languages (such as
Python) for their flexibility and shorter development times. Moreover, in many
research tasks, these simulations are the most computationally intensive task,
so it would be desirable to have a library for these with an interface to a
high-level language with the performance of a low-level language. To fill this
niche, we introduce CyNetDiff, a Python library with components written in
Cython to provide improved performance for these computationally intensive
diffusion tasks.

摘要：近年来，网络扩散模型及相关问题越来越受到关注。其中最受欢迎的是独立级联和线性阈值模型。在这些模型上进行的许多近期实验工作需要对大型图进行大量的模拟，这是一项适合低级语言的计算成本高昂的任务。然而，许多研究人员更喜欢使用高级语言（如 Python），因为它们具有灵活性且开发时间较短。此外，在许多研究任务中，这些模拟是计算量最大的任务，因此最好有一个针对它们的库，该库具有高级语言的接口和低级语言的性能。为了填补这一空白，我们引入了 CyNetDiff，这是一个 Python 库，其中包含以 Cython 编写的组件，以提高这些计算密集型扩散任务的性能。

##### **Agentive Permissions in Multiagent Systems**
2404.17053v1 by Qi Shi

This paper proposes to distinguish four forms of agentive permissions in
multiagent settings. The main technical results are the complexity analysis of
model checking, the semantic undefinability of modalities that capture these
forms of permissions through each other, and a complete logical system
capturing the interplay between these modalities.

摘要：本文提出區分多重代理設定中四種形式的代理許可。主要的技術結果是模型檢查的複雜性分析、捕捉這些許可形式通過彼此的模態語義不可定義性，以及捕捉這些模態之間交互作用的完整邏輯系統。

##### **Generative AI in Color-Changing Systems: Re-Programmable 3D Object Textures with Material and Design Constraints**
2404.17028v1 by Yunyi Zhu,Faraz Faruqi,Stefanie Mueller

Advances in Generative AI tools have allowed designers to manipulate existing
3D models using text or image-based prompts, enabling creators to explore
different design goals. Photochromic color-changing systems, on the other hand,
allow for the reprogramming of surface texture of 3D models, enabling easy
customization of physical objects and opening up the possibility of using
object surfaces for data display. However, existing photochromic systems
require the user to manually design the desired texture, inspect the simulation
of the pattern on the object, and verify the efficacy of the generated pattern.
These manual design, inspection, and verification steps prevent the user from
efficiently exploring the design space of possible patterns. Thus, by designing
an automated workflow desired for an end-to-end texture application process, we
can allow rapid iteration on different practicable patterns.
  In this workshop paper, we discuss the possibilities of extending generative
AI systems, with material and design constraints for reprogrammable surfaces
with photochromic materials. By constraining generative AI systems to colors
and materials possible to be physically realized with photochromic dyes, we can
create tools that would allow users to explore different viable patterns, with
text and image-based prompts. We identify two focus areas in this topic:
photochromic material constraints and design constraints for data-encoded
textures. We highlight the current limitations of using generative AI tools to
create viable textures using photochromic material. Finally, we present
possible approaches to augment generative AI methods to take into account the
photochromic material constraints, allowing for the creation of viable
photochromic textures rapidly and easily.

摘要：生成式 AI 工具的进步让设计师能够使用基于文本或图像的提示来操作现有的 3D 模型，从而让创作者能够探索不同的设计目标。另一方面，光致变色系统允许重新编程 3D 模型的表面纹理，从而轻松定制物理对象并开启使用对象表面进行数据显示的可能性。但是，现有的光致变色系统要求用户手动设计所需的纹理，检查对象上的图案模拟，并验证生成图案的有效性。这些手动设计、检查和验证步骤阻止了用户有效地探索可能的图案设计空间。因此，通过设计一个自动化的工作流程，满足端到端纹理应用流程的需求，我们可以对不同的可行图案进行快速迭代。在这篇研讨会论文中，我们讨论了扩展生成式 AI 系统的可能性，并为使用光致变色材料的可重新编程表面提供材料和设计约束。通过将生成式 AI 系统约束为光致变色染料在物理上可以实现的颜色和材料，我们可以创建允许用户使用基于文本和图像的提示来探索不同可行图案的工具。我们在这一主题中确定了两个重点领域：光致变色材料约束和用于数据编码纹理的设计约束。我们强调了使用生成式 AI 工具创建使用光致变色材料的可行纹理的当前限制。最后，我们提出了增强生成式 AI 方法以考虑光致变色材料约束的可能方法，从而允许快速轻松地创建可行光致变色纹理。

##### **Player-Driven Emergence in LLM-Driven Game Narrative**
2404.17027v1 by Xiangyu Peng,Jessica Quaye,Weijia Xu,Chris Brockett,Bill Dolan,Nebojsa Jojic,Gabriel DesGarennes,Ken Lobb,Michael Xu,Jorge Leandro,Claire Jin,Sudha Rao

We explore how interaction with large language models (LLMs) can give rise to
emergent behaviors, empowering players to participate in the evolution of game
narratives. Our testbed is a text-adventure game in which players attempt to
solve a mystery under a fixed narrative premise, but can freely interact with
non-player characters generated by GPT-4, a large language model. We recruit 28
gamers to play the game and use GPT-4 to automatically convert the game logs
into a node-graph representing the narrative in the player's gameplay. We find
that through their interactions with the non-deterministic behavior of the LLM,
players are able to discover interesting new emergent nodes that were not a
part of the original narrative but have potential for being fun and engaging.
Players that created the most emergent nodes tended to be those that often
enjoy games that facilitate discovery, exploration and experimentation.

摘要：我們探討如何與大型語言模型（LLM）互動可以產生新興行為，讓玩家能夠參與遊戲敘事的演化。我們的測試平台是一個文字冒險遊戲，玩家在固定的敘事前提下嘗試解開謎團，但可以自由地與由大型語言模型 GPT-4 生成的非玩家角色互動。我們招募了 28 位玩家來玩遊戲，並使用 GPT-4 將遊戲記錄自動轉換成節點圖，代表玩家遊戲中的敘事。我們發現，透過與 LLM 的非確定性行為互動，玩家能夠發現有趣的、新的、新興節點，這些節點並非原始敘事的一部分，但有潛力變得有趣且引人入勝。創造最多新興節點的玩家往往是那些經常享受促進發現、探索和實驗的遊戲的玩家。

##### **Generating Minimalist Adversarial Perturbations to Test Object-Detection Models: An Adaptive Multi-Metric Evolutionary Search Approach**
2404.17020v1 by Cristopher McIntyre-Garcia,Adrien Heymans,Beril Borali,Won-Sook Lee,Shiva Nejati

Deep Learning (DL) models excel in computer vision tasks but can be
susceptible to adversarial examples. This paper introduces Triple-Metric
EvoAttack (TM-EVO), an efficient algorithm for evaluating the robustness of
object-detection DL models against adversarial attacks. TM-EVO utilizes a
multi-metric fitness function to guide an evolutionary search efficiently in
creating effective adversarial test inputs with minimal perturbations. We
evaluate TM-EVO on widely-used object-detection DL models, DETR and Faster
R-CNN, and open-source datasets, COCO and KITTI. Our findings reveal that
TM-EVO outperforms the state-of-the-art EvoAttack baseline, leading to
adversarial tests with less noise while maintaining efficiency.

摘要：深度學習 (DL) 模型在電腦視覺任務中表現出色，但容易受到對抗範例的影響。本文介紹了 Triple-Metric EvoAttack (TM-EVO)，這是一種用於評估物件偵測 DL 模型對抗攻擊魯棒性的高效演算法。TM-EVO 利用多指標適應度函數有效引導演化搜尋，以最小的擾動建立有效的對抗測試輸入。我們在廣泛使用的物件偵測 DL 模型 DETR 和 Faster R-CNN，以及開源資料集 COCO 和 KITTI 上評估 TM-EVO。我們的研究結果顯示 TM-EVO 優於最先進的 EvoAttack 基準，可在維持效率的同時進行雜訊較少的對抗測試。

##### **Türkçe Dil Modellerinin Performans Karşılaştırması Performance Comparison of Turkish Language Models**
2404.17010v1 by Eren Dogan,M. Egemen Uzun,Atahan Uz,H. Emre Seyrek,Ahmed Zeer,Ezgi Sevi,H. Toprak Kesgin,M. Kaan Yuce,M. Fatih Amasyali

The developments that language models have provided in fulfilling almost all
kinds of tasks have attracted the attention of not only researchers but also
the society and have enabled them to become products. There are commercially
successful language models available. However, users may prefer open-source
language models due to cost, data privacy, or regulations. Yet, despite the
increasing number of these models, there is no comprehensive comparison of
their performance for Turkish. This study aims to fill this gap in the
literature. A comparison is made among seven selected language models based on
their contextual learning and question-answering abilities. Turkish datasets
for contextual learning and question-answering were prepared, and both
automatic and human evaluations were conducted. The results show that for
question-answering, continuing pretraining before fine-tuning with
instructional datasets is more successful in adapting multilingual models to
Turkish and that in-context learning performances do not much related to
question-answering performances.

摘要：語言模型在完成幾乎所有類型的任務上所提供的發展，不僅吸引了研究人員的注意，也吸引了社會的注意，並使它們能夠成為產品。有商業上成功的語言模型可用。然而，使用者可能由於成本、資料隱私或法規而偏好開源語言模型。儘管這些模型的數量不斷增加，但沒有全面比較它們在土耳其語的表現。本研究旨在填補文獻中的這項空白。根據七個選定的語言模型的脈絡學習和問答能力，進行比較。準備了用於脈絡學習和問答的土耳其語資料集，並進行了自動和人工評估。結果表明，對於問答，在使用教學資料集進行微調之前繼續預訓練在將多語言模型適應到土耳其語方面更成功，而且脈絡學習表現與問答表現沒有太大關係。

##### **Evaluating Class Membership Relations in Knowledge Graphs using Large Language Models**
2404.17000v1 by Bradley P. Allen,Paul T. Groth

A backbone of knowledge graphs are their class membership relations, which
assign entities to a given class. As part of the knowledge engineering process,
we propose a new method for evaluating the quality of these relations by
processing descriptions of a given entity and class using a zero-shot
chain-of-thought classifier that uses a natural language intensional definition
of a class. We evaluate the method using two publicly available knowledge
graphs, Wikidata and CaLiGraph, and 7 large language models. Using the
gpt-4-0125-preview large language model, the method's classification
performance achieves a macro-averaged F1-score of 0.830 on data from Wikidata
and 0.893 on data from CaLiGraph. Moreover, a manual analysis of the
classification errors shows that 40.9% of errors were due to the knowledge
graphs, with 16.0% due to missing relations and 24.9% due to incorrectly
asserted relations. These results show how large language models can assist
knowledge engineers in the process of knowledge graph refinement. The code and
data are available on Github.

摘要：知識圖譜的骨幹是類別成員關係，它將實體指定給特定類別。作為知識工程程序的一部分，我們提出了一種新的方法來評估這些關係的品質，方法是使用零次學習思考鏈分類器處理給定實體和類別的描述，該分類器使用類別的自然語言內涵定義。我們使用兩個公開可用的知識圖譜 Wikidata 和 CaLiGraph 以及 7 個大型語言模型來評估該方法。使用 gpt-4-0125-preview 大型語言模型，該方法的分類效能對來自 Wikidata 的資料達到 0.830 的巨觀平均 F1 分數，對來自 CaLiGraph 的資料達到 0.893。此外，對分類錯誤的手動分析顯示，40.9% 的錯誤是因知識圖譜而產生，其中 16.0% 是因關係遺漏而產生，24.9% 是因錯誤斷言關係而產生。這些結果顯示大型語言模型如何協助知識工程師進行知識圖譜精煉的程序。程式碼和資料可在 Github 上取得。

##### **IDIL: Imitation Learning of Intent-Driven Expert Behavior**
2404.16989v1 by Sangwon Seo,Vaibhav Unhelkar

When faced with accomplishing a task, human experts exhibit intentional
behavior. Their unique intents shape their plans and decisions, resulting in
experts demonstrating diverse behaviors to accomplish the same task. Due to the
uncertainties encountered in the real world and their bounded rationality,
experts sometimes adjust their intents, which in turn influences their
behaviors during task execution. This paper introduces IDIL, a novel imitation
learning algorithm to mimic these diverse intent-driven behaviors of experts.
Iteratively, our approach estimates expert intent from heterogeneous
demonstrations and then uses it to learn an intent-aware model of their
behavior. Unlike contemporary approaches, IDIL is capable of addressing
sequential tasks with high-dimensional state representations, while
sidestepping the complexities and drawbacks associated with adversarial
training (a mainstay of related techniques). Our empirical results suggest that
the models generated by IDIL either match or surpass those produced by recent
imitation learning benchmarks in metrics of task performance. Moreover, as it
creates a generative model, IDIL demonstrates superior performance in intent
inference metrics, crucial for human-agent interactions, and aptly captures a
broad spectrum of expert behaviors.

摘要：当面对一项任务时，人类专家会表现出有意的行为。他们独特的意图塑造了他们的计划和决定，导致专家表现出不同的行为来完成同一项任务。由于在现实世界中遇到的不确定性和他们有限的理性，专家有时会调整他们的意图，这反过来又会影响他们在执行任务期间的行为。本文介绍了 IDIL，一种新颖的模仿学习算法，用于模仿专家这些不同的意图驱动行为。我们的方法迭代地从异构演示中估计专家意图，然后使用它来学习他们行为的意图感知模型。与当代方法不同，IDIL 能够解决具有高维状态表示的顺序任务，同时避开与对抗性训练（相关技术的支柱）相关的复杂性和缺点。我们的实证结果表明，IDIL 生成的模型在任务性能指标上与最近的模仿学习基准产生的模型相匹配或超越它们。此外，由于它创建了一个生成模型，因此 IDIL 在意图推理指标中表现出优越的性能，这对于人机交互至关重要，并恰当地捕捉了广泛的专家行为。

##### **Examining the robustness of LLM evaluation to the distributional assumptions of benchmarks**
2404.16966v1 by Melissa Ailem,Katerina Marazopoulou,Charlotte Siska,James Bono

Benchmarks have emerged as the central approach for evaluating Large Language
Models (LLMs). The research community often relies on a model's average
performance across the test prompts of a benchmark to evaluate the model's
performance. This is consistent with the assumption that the test prompts
within a benchmark represent a random sample from a real-world distribution of
interest. We note that this is generally not the case; instead, we hold that
the distribution of interest varies according to the specific use case. We find
that (1) the correlation in model performance across test prompts is
non-random, (2) accounting for correlations across test prompts can change
model rankings on major benchmarks, (3) explanatory factors for these
correlations include semantic similarity and common LLM failure points.

摘要：基准測試已成為評估大型語言模型 (LLM) 的核心方法。研究社群通常依賴模型在基准測試的測試提示上的平均表現來評估模型的表現。這與以下假設一致：基准測試中的測試提示代表了感興趣的真實世界分佈的隨機樣本。我們注意到這通常並非如此；相反，我們認為感興趣的分佈會根據具體的使用案例而有所不同。我們發現 (1) 模型在測試提示上的表現相關性並非隨機的，(2) 考慮測試提示的相關性會改變模型在主要基准測試上的排名，(3) 這些相關性的解釋因素包括語義相似性和常見的 LLM 失敗點。

##### **A Closer Look at Classification Evaluation Metrics and a Critical Reflection of Common Evaluation Practice**
2404.16958v1 by Juri Opitz

Classification systems are evaluated in a countless number of papers.
However, we find that evaluation practice is often nebulous. Frequently,
metrics are selected without arguments, and blurry terminology invites
misconceptions. For instance, many works use so-called 'macro' metrics to rank
systems (e.g., 'macro F1') but do not clearly specify what they would expect
from such a 'macro' metric. This is problematic, since picking a metric can
affect paper findings as well as shared task rankings, and thus any clarity in
the process should be maximized.
  Starting from the intuitive concepts of bias and prevalence, we perform an
analysis of common evaluation metrics, considering expectations as found
expressed in papers. Equipped with a thorough understanding of the metrics, we
survey metric selection in recent shared tasks of Natural Language Processing.
The results show that metric choices are often not supported with convincing
arguments, an issue that can make any ranking seem arbitrary. This work aims at
providing overview and guidance for more informed and transparent metric
selection, fostering meaningful evaluation.

摘要：分類系統在無數論文中得到評估。
然而，我們發現評估實務經常是模糊不清的。
通常，指標的選擇缺乏依據，模糊的術語容易引起誤解。
例如，許多作品使用所謂的「巨觀」指標對系統進行排名（例如「巨觀 F1」），但沒有明確說明他們對這種「巨觀」指標的期望。
這是個問題，因為選擇指標會影響論文發現以及共享任務排名，因此應最大程度地提高流程的清晰度。
從偏誤和流行率的直觀概念出發，我們對常見的評估指標進行了分析，考慮了論文中表達的期望。
在透徹了解這些指標後，我們調查了自然語言處理最近共享任務中的指標選擇。
結果表明，指標選擇往往缺乏令人信服的依據，這可能會讓任何排名看起來都是武斷的。
這項工作旨在為更明智、更透明的指標選擇提供概述和指導，促進有意義的評估。

##### **Taming False Positives in Out-of-Distribution Detection with Human Feedback**
2404.16954v1 by Harit Vishwakarma,Heguang Lin,Ramya Korlakai Vinayak

Robustness to out-of-distribution (OOD) samples is crucial for safely
deploying machine learning models in the open world. Recent works have focused
on designing scoring functions to quantify OOD uncertainty. Setting appropriate
thresholds for these scoring functions for OOD detection is challenging as OOD
samples are often unavailable up front. Typically, thresholds are set to
achieve a desired true positive rate (TPR), e.g., $95\%$ TPR. However, this can
lead to very high false positive rates (FPR), ranging from 60 to 96\%, as
observed in the Open-OOD benchmark. In safety-critical real-life applications,
e.g., medical diagnosis, controlling the FPR is essential when dealing with
various OOD samples dynamically. To address these challenges, we propose a
mathematically grounded OOD detection framework that leverages expert feedback
to \emph{safely} update the threshold on the fly. We provide theoretical
results showing that it is guaranteed to meet the FPR constraint at all times
while minimizing the use of human feedback. Another key feature of our
framework is that it can work with any scoring function for OOD uncertainty
quantification. Empirical evaluation of our system on synthetic and benchmark
OOD datasets shows that our method can maintain FPR at most $5\%$ while
maximizing TPR.

摘要：對於在開放世界中安全部署機器學習模型來說，對分布外 (OOD) 樣本的穩健性至關重要。最近的研究集中在設計評分函數以量化 OOD 不確定性。由於 OOD 樣本通常在前期不可用，因此為這些評分函數設定適當的 OOD 檢測閾值具有挑戰性。通常，閾值被設定為達到所需的真陽性率 (TPR)，例如 95% TPR。然而，這可能會導致非常高的假陽性率 (FPR)，範圍從 60% 到 96%，正如在 Open-OOD 基準中觀察到的那樣。在安全關鍵的現實應用中，例如醫療診斷，在動態處理各種 OOD 樣本時控制 FPR 至關重要。為了應對這些挑戰，我們提出了一個以數學為基礎的 OOD 檢測框架，它利用專家回饋來動態地「安全地」更新閾值。我們提供了理論結果，表明它保證始終滿足 FPR 約束，同時最大限度地減少人工回饋的使用。我們框架的另一個關鍵特徵是它可以與任何用於 OOD 不確定性量化的評分函數配合使用。我們系統在合成和基準 OOD 資料集上的經驗評估表明，我們的模型可以在最大化 TPR 的同時將 FPR 維持在最多 5%。

##### **Make-it-Real: Unleashing Large Multimodal Model's Ability for Painting 3D Objects with Realistic Materials**
2404.16829v2 by Ye Fang,Zeyi Sun,Tong Wu,Jiaqi Wang,Ziwei Liu,Gordon Wetzstein,Dahua Lin

Physically realistic materials are pivotal in augmenting the realism of 3D
assets across various applications and lighting conditions. However, existing
3D assets and generative models often lack authentic material properties.
Manual assignment of materials using graphic software is a tedious and
time-consuming task. In this paper, we exploit advancements in Multimodal Large
Language Models (MLLMs), particularly GPT-4V, to present a novel approach,
Make-it-Real: 1) We demonstrate that GPT-4V can effectively recognize and
describe materials, allowing the construction of a detailed material library.
2) Utilizing a combination of visual cues and hierarchical text prompts, GPT-4V
precisely identifies and aligns materials with the corresponding components of
3D objects. 3) The correctly matched materials are then meticulously applied as
reference for the new SVBRDF material generation according to the original
diffuse map, significantly enhancing their visual authenticity. Make-it-Real
offers a streamlined integration into the 3D content creation workflow,
showcasing its utility as an essential tool for developers of 3D assets.

摘要：物理真實的材質對於提升各種應用和光照條件下的 3D 素材真實性至關重要。然而，現有的 3D 素材和生成模型通常缺乏真實的材質屬性。使用圖形軟體手動指定材質是一項繁瑣且耗時的任務。在本文中，我們利用多模態大型語言模型 (MLLM)，特別是 GPT-4V，來提出一個創新的方法：Make-it-Real：1) 我們證明 GPT-4V 能有效地辨識和描述材質，允許建立一個詳細的材質庫。2) 利用視覺線索和階層式文字提示的組合，GPT-4V 精確地辨識並將材質與 3D 物件的對應組件對齊。3) 然後將正確匹配的材質細緻地應用為參考，根據原始漫射貼圖生成新的 SVBRDF 材質，顯著地提升其視覺真實性。Make-it-Real 提供簡化的整合方式，融入 3D 內容創作工作流程，展示其作為 3D 素材開發人員的必要工具的實用性。

##### **A Survey of Generative Search and Recommendation in the Era of Large Language Models**
2404.16924v1 by Yongqi Li,Xinyu Lin,Wenjie Wang,Fuli Feng,Liang Pang,Wenjie Li,Liqiang Nie,Xiangnan He,Tat-Seng Chua

With the information explosion on the Web, search and recommendation are
foundational infrastructures to satisfying users' information needs. As the two
sides of the same coin, both revolve around the same core research problem,
matching queries with documents or users with items. In the recent few decades,
search and recommendation have experienced synchronous technological paradigm
shifts, including machine learning-based and deep learning-based paradigms.
Recently, the superintelligent generative large language models have sparked a
new paradigm in search and recommendation, i.e., generative search (retrieval)
and recommendation, which aims to address the matching problem in a generative
manner. In this paper, we provide a comprehensive survey of the emerging
paradigm in information systems and summarize the developments in generative
search and recommendation from a unified perspective. Rather than simply
categorizing existing works, we abstract a unified framework for the generative
paradigm and break down the existing works into different stages within this
framework to highlight the strengths and weaknesses. And then, we distinguish
generative search and recommendation with their unique challenges, identify
open problems and future directions, and envision the next information-seeking
paradigm.

摘要：随着网络上信息爆炸，搜索和推荐已成为满足用户的信息需求的基础设施。作为同一枚硬币的两面，两者都围绕着同一个核心研究问题，即查询与文档或用户与项目的匹配。在最近的几十年里，搜索和推荐经历了同步的技术范式转变，包括基于机器学习和基于深度学习的范式。最近，超智能生成式大语言模型在搜索和推荐中引发了一种新的范式，即生成式搜索（检索）和推荐，其目的是以生成式的方式解决匹配问题。在本文中，我们对信息系统中新兴的范式进行了全面的调查，并从统一的角度总结了生成式搜索和推荐的发展。我们没有仅仅对现有工作进行分类，而是抽象了一个统一的生成式范式框架，并将现有工作分解为该框架内的不同阶段，以突出其优点和缺点。然后，我们区分了生成式搜索和推荐及其独特的挑战，确定了开放的问题和未来的方向，并设想下一个信息搜索范式。

##### **IndicGenBench: A Multilingual Benchmark to Evaluate Generation Capabilities of LLMs on Indic Languages**
2404.16816v1 by Harman Singh,Nitish Gupta,Shikhar Bharadwaj,Dinesh Tewari,Partha Talukdar

As large language models (LLMs) see increasing adoption across the globe, it
is imperative for LLMs to be representative of the linguistic diversity of the
world. India is a linguistically diverse country of 1.4 Billion people. To
facilitate research on multilingual LLM evaluation, we release IndicGenBench -
the largest benchmark for evaluating LLMs on user-facing generation tasks
across a diverse set 29 of Indic languages covering 13 scripts and 4 language
families. IndicGenBench is composed of diverse generation tasks like
cross-lingual summarization, machine translation, and cross-lingual question
answering. IndicGenBench extends existing benchmarks to many Indic languages
through human curation providing multi-way parallel evaluation data for many
under-represented Indic languages for the first time. We evaluate a wide range
of proprietary and open-source LLMs including GPT-3.5, GPT-4, PaLM-2, mT5,
Gemma, BLOOM and LLaMA on IndicGenBench in a variety of settings. The largest
PaLM-2 models performs the best on most tasks, however, there is a significant
performance gap in all languages compared to English showing that further
research is needed for the development of more inclusive multilingual language
models. IndicGenBench is released at
www.github.com/google-research-datasets/indic-gen-bench

摘要：随着大型语言模型（LLM）在全球范围内被越来越广泛地采用，LLM 必须代表世界语言多样性势在必行。印度是一个拥有 14 亿人口的语言多样性国家。为了促进对多语言 LLM 评估的研究，我们发布了 IndicGenBench - 用于评估 LLM 在面向用户生成任务上的最大基准，涵盖 13 种文字和 4 种语言系列的 29 种印地语。IndicGenBench 由跨语言摘要、机器翻译和跨语言问答等多种生成任务组成。IndicGenBench 通过人工整理将现有基准扩展到多种印地语，首次为许多代表性不足的印地语提供了多向并行评估数据。我们在各种设置中对 IndicGenBench 评估了广泛的专有和开源 LLM，包括 GPT-3.5、GPT-4、PaLM-2、mT5、Gemma、BLOOM 和 LLaMA。最大的 PaLM-2 模型在大多数任务上表现最佳，但是，与英语相比，所有语言的性能差距都很大，表明需要进一步研究以开发更具包容性的多语言语言模型。IndicGenBench 已在 www.github.com/google-research-datasets/indic-gen-bench 发布

##### **Make Your LLM Fully Utilize the Context**
2404.16811v2 by Shengnan An,Zexiong Ma,Zeqi Lin,Nanning Zheng,Jian-Guang Lou

While many contemporary large language models (LLMs) can process lengthy
input, they still struggle to fully utilize information within the long
context, known as the lost-in-the-middle challenge. We hypothesize that it
stems from insufficient explicit supervision during the long-context training,
which fails to emphasize that any position in a long context can hold crucial
information. Based on this intuition, our study presents information-intensive
(IN2) training, a purely data-driven solution to overcome lost-in-the-middle.
Specifically, IN2 training leverages a synthesized long-context question-answer
dataset, where the answer requires (1) fine-grained information awareness on a
short segment (~128 tokens) within a synthesized long context (4K-32K tokens),
and (2) the integration and reasoning of information from two or more short
segments. Through applying this information-intensive training on Mistral-7B,
we present FILM-7B (FILl-in-the-Middle). To thoroughly assess the ability of
FILM-7B for utilizing long contexts, we design three probing tasks that
encompass various context styles (document, code, and structured-data context)
and information retrieval patterns (forward, backward, and bi-directional
retrieval). The probing results demonstrate that FILM-7B can robustly retrieve
information from different positions in its 32K context window. Beyond these
probing tasks, FILM-7B significantly improves the performance on real-world
long-context tasks (e.g., 23.5->26.9 F1 score on NarrativeQA), while
maintaining a comparable performance on short-context tasks (e.g., 59.3->59.2
accuracy on MMLU). Github Link: https://github.com/microsoft/FILM.

摘要：儘管許多當代大型語言模型 (LLM) 能處理長篇輸入，但它們仍難以充分利用長篇脈絡中的資訊，也就是所謂的「遺失於中間」挑戰。我們假設這是由於長篇脈絡訓練期間監督不足所致，因為訓練未能強調長篇脈絡中的任何位置都可能包含關鍵資訊。基於此直覺，我們的研究提出「資訊密集型」(IN2) 訓練，這是一種純粹由資料驅動的解決方案，用於克服「遺失於中間」的挑戰。具體來說，IN2 訓練利用合成的長篇脈絡問答資料集，其中答案需要 (1) 在合成的長篇脈絡 (4K-32K 個詞元) 中針對短區段 (~128 個詞元) 進行細微的資訊感知，以及 (2) 整合和推理來自兩個或多個短區段的資訊。透過將此資訊密集型訓練應用於 Mistral-7B，我們提出 FILM-7B (FILl-in-the-Middle)。為了徹底評估 FILM-7B 利用長篇脈絡的能力，我們設計了三項探測任務，涵蓋各種脈絡樣式 (文件、程式碼和結構化資料脈絡) 和資訊檢索模式 (前向、後向和雙向檢索)。探測結果顯示，FILM-7B 能從其 32K 脈絡視窗中的不同位置穩健地檢索資訊。除了這些探測任務之外，FILM-7B 也顯著提升了實際長篇脈絡任務的效能 (例如，NarrativeQA 上的 F1 分數從 23.5->26.9)，同時在短篇脈絡任務上維持相當的效能 (例如，MMLU 上的準確度從 59.3->59.2)。Github 連結：https://github.com/microsoft/FILM。

##### **Improving Diversity of Commonsense Generation by Large Language Models via In-Context Learning**
2404.16807v1 by Tianhui Zhang,Bei Peng,Danushka Bollegala

Generative Commonsense Reasoning (GCR) requires a model to reason about a
situation using commonsense knowledge, while generating coherent sentences.
Although the quality of the generated sentences is crucial, the diversity of
the generation is equally important because it reflects the model's ability to
use a range of commonsense knowledge facts. Large Language Models (LLMs) have
shown proficiency in enhancing the generation quality across various tasks
through in-context learning (ICL) using given examples without the need for any
fine-tuning. However, the diversity aspect in LLM outputs has not been
systematically studied before. To address this, we propose a simple method that
diversifies the LLM generations, while preserving their quality. Experimental
results on three benchmark GCR datasets show that our method achieves an ideal
balance between the quality and diversity. Moreover, the sentences generated by
our proposed method can be used as training data to improve diversity in
existing commonsense generators.

摘要：生成常識推理 (GCR) 要求模型使用常識知識對情況進行推理，同時生成連貫的句子。
儘管生成句子的品質至關重要，但生成的多樣性也同樣重要，因為它反映了模型使用一系列常識知識事實的能力。大型語言模型 (LLM) 已顯示出透過使用提供的範例進行情境中學習 (ICL) 來增強各種任務的生成品質，而無需任何微調。然而，LLM 輸出中的多樣性方面以前尚未得到系統性研究。為了解決這個問題，我們提出了一種簡單的方法，這種方法可以使 LLM 生成多樣化，同時保持其品質。在三個基準 GCR 資料集上的實驗結果顯示，我們的模型在品質和多樣性之間取得了理想的平衡。此外，我們提出的方法生成的句子可用作訓練資料，以提高現有常識生成器的多樣性。

##### **A Short Survey of Human Mobility Prediction in Epidemic Modeling from Transformers to LLMs**
2404.16921v1 by Christian N. Mayemba,D'Jeff K. Nkashama,Jean Marie Tshimula,Maximilien V. Dialufuma,Jean Tshibangu Muabila,Mbuyi Mukendi Didier,Hugues Kanda,René Manassé Galekwa,Heber Dibwe Fita,Serge Mundele,Kalonji Kalala,Aristarque Ilunga,Lambert Mukendi Ntobo,Dominique Muteba,Aaron Aruna Abedi

This paper provides a comprehensive survey of recent advancements in
leveraging machine learning techniques, particularly Transformer models, for
predicting human mobility patterns during epidemics. Understanding how people
move during epidemics is essential for modeling the spread of diseases and
devising effective response strategies. Forecasting population movement is
crucial for informing epidemiological models and facilitating effective
response planning in public health emergencies. Predicting mobility patterns
can enable authorities to better anticipate the geographical and temporal
spread of diseases, allocate resources more efficiently, and implement targeted
interventions. We review a range of approaches utilizing both pretrained
language models like BERT and Large Language Models (LLMs) tailored
specifically for mobility prediction tasks. These models have demonstrated
significant potential in capturing complex spatio-temporal dependencies and
contextual patterns in textual data.

摘要：本文全面綜述了最近在利用機器學習技術，特別是 Transformer 模型，來預測流行病期間人類流動模式的進展。了解人們在流行病期間的移動方式對於模擬疾病的傳播和制定有效的應對策略至關重要。預測人口流動對於為流行病學模型提供信息和促進公共衛生緊急情況下的有效應對規劃至關重要。預測流動模式可以使當局更好地預測疾病的地理和時間傳播，更有效地分配資源，並實施有針對性的干預措施。我們回顧了一系列利用預訓練語言模型（如 BERT）和專門針對流動性預測任務定制的大語言模型 (LLM) 的方法。這些模型已證明在捕捉文本數據中複雜的時空依賴性和上下文模式方面具有顯著的潛力。

##### **AAPL: Adding Attributes to Prompt Learning for Vision-Language Models**
2404.16804v1 by Gahyeon Kim,Sohee Kim,Seokju Lee

Recent advances in large pre-trained vision-language models have demonstrated
remarkable performance on zero-shot downstream tasks. Building upon this,
recent studies, such as CoOp and CoCoOp, have proposed the use of prompt
learning, where context within a prompt is replaced with learnable vectors,
leading to significant improvements over manually crafted prompts. However, the
performance improvement for unseen classes is still marginal, and to tackle
this problem, data augmentation has been frequently used in traditional
zero-shot learning techniques. Through our experiments, we have identified
important issues in CoOp and CoCoOp: the context learned through traditional
image augmentation is biased toward seen classes, negatively impacting
generalization to unseen classes. To address this problem, we propose
adversarial token embedding to disentangle low-level visual augmentation
features from high-level class information when inducing bias in learnable
prompts. Through our novel mechanism called "Adding Attributes to Prompt
Learning", AAPL, we guide the learnable context to effectively extract text
features by focusing on high-level features for unseen classes. We have
conducted experiments across 11 datasets, and overall, AAPL shows favorable
performances compared to the existing methods in few-shot learning, zero-shot
learning, cross-dataset, and domain generalization tasks.

摘要：最近大型预训练视觉语言模型的进步已在零次学习下游任务中表现出卓越的性能。在此基础上，最近的研究（例如 CoOp 和 CoCoOp）提出了使用提示学习，其中提示中的上下文被可学习向量取代，从而比手动制作的提示有了显著的改进。然而，对于未见过的类别，性能改进仍然很小，为了解决这个问题，数据增强经常用于传统的零次学习技术中。通过我们的实验，我们发现了 CoOp 和 CoCoOp 中的重要问题：通过传统图像增强学习的上下文偏向于已见的类别，对未见的类别产生负面影响。为了解决这个问题，我们提出了对抗性令牌嵌入，以在可学习提示中引入偏差时，将低级视觉增强特征与高级类别信息解开。通过我们称为“向提示学习中添加属性”的创新机制 AAPL，我们引导可学习上下文有效地提取文本特征，重点关注未见类别的高级特征。我们对 11 个数据集进行了实验，总体而言，与现有方法相比，AAPL 在少量学习、零次学习、跨数据集和域泛化任务中表现出良好的性能。

##### **Weak-to-Strong Extrapolation Expedites Alignment**
2404.16792v1 by Chujie Zheng,Ziqi Wang,Heng Ji,Minlie Huang,Nanyun Peng

Although the capabilities of large language models (LLMs) ideally scale up
with increasing data and compute, they are inevitably constrained by limited
resources in reality. Suppose we have a moderately trained LLM (e.g., trained
to align with human preference) in hand, can we further exploit its potential
and cheaply acquire a stronger model? In this paper, we propose a simple method
called ExPO to boost LLMs' alignment with human preference. ExPO assumes that a
medium-aligned model can be interpolated between a less-aligned (weaker) model,
e.g., the initial SFT model, and a better-aligned (stronger) one, thereby
directly obtaining this stronger model by extrapolating from the weights of the
former two relatively weaker models. On the AlpacaEval 2.0 benchmark, we show
that ExPO pushes models trained with less preference data (e.g., 10% or 20%) to
reach and even surpass the fully-trained one, without any additional training.
Furthermore, ExPO also significantly improves off-the-shelf DPO/RLHF models and
exhibits decent scalability across model sizes from 7B to 70B. Our work
demonstrates the efficacy of model extrapolation in exploiting LLMs'
capabilities, suggesting a promising direction that deserves future
exploration.

摘要：儘管大型語言模型 (LLM) 的能力理想上會隨著資料和運算的增加而提升，但它們在現實中不可避免地受到有限資源的限制。假設我們手邊有一個訓練適中的 LLM（例如，訓練為與人類偏好一致），我們是否能進一步發揮其潛力並以低成本獲得更強大的模型？在本文中，我們提出一個名為 ExPO 的簡單方法，以提升 LLM 與人類偏好的對齊。ExPO 假設一個中等對齊的模型可以內插於一個較不對齊（較弱）的模型（例如，初始 SFT 模型）和一個對齊更好的（較強）模型之間，從而直接透過從前兩個相對較弱的模型的權重外推來獲得這個較強的模型。在 AlpacaEval 2.0 基準上，我們展示 ExPO 將使用較少偏好資料（例如，10% 或 20%）訓練的模型推升至達到甚至超越完全訓練的模型，而無需任何額外的訓練。此外，ExPO 也顯著地改善了現成的 DPO/RLHF 模型，並展現出從 7B 到 70B 的模型規模的良好可擴充性。我們的研究展示了模型外推在利用 LLM 能力方面的效能，這表明了一個值得未來探索的有前途的方向。

##### **Continual Learning of Large Language Models: A Comprehensive Survey**
2404.16789v1 by Haizhou Shi,Zihao Xu,Hengyi Wang,Weiyi Qin,Wenyuan Wang,Yibin Wang,Hao Wang

The recent success of large language models (LLMs) trained on static,
pre-collected, general datasets has sparked numerous research directions and
applications. One such direction addresses the non-trivial challenge of
integrating pre-trained LLMs into dynamic data distributions, task structures,
and user preferences. Pre-trained LLMs, when tailored for specific needs, often
experience significant performance degradation in previous knowledge domains --
a phenomenon known as "catastrophic forgetting". While extensively studied in
the continual learning (CL) community, it presents new manifestations in the
realm of LLMs. In this survey, we provide a comprehensive overview of the
current research progress on LLMs within the context of CL. This survey is
structured into four main sections: we first describe an overview of
continually learning LLMs, consisting of two directions of continuity: vertical
continuity (or vertical continual learning), i.e., continual adaptation from
general to specific capabilities, and horizontal continuity (or horizontal
continual learning), i.e., continual adaptation across time and domains
(Section 3). We then summarize three stages of learning LLMs in the context of
modern CL: Continual Pre-Training (CPT), Domain-Adaptive Pre-training (DAP),
and Continual Fine-Tuning (CFT) (Section 4). Then we provide an overview of
evaluation protocols for continual learning with LLMs, along with the current
available data sources (Section 5). Finally, we discuss intriguing questions
pertaining to continual learning for LLMs (Section 6). The full list of papers
examined in this survey is available at
https://github.com/Wang-ML-Lab/llm-continual-learning-survey.

摘要：最近针对静态、预先收集的一般数据集训练的大型语言模型 (LLM) 获得成功，引发了大量研究方向和应用。其中一个方向解决了将预先训练的 LLM 集成到动态数据分布、任务结构和用户偏好中的非平凡挑战。针对特定需求定制的预先训练的 LLM 在先前的知识领域中往往会遇到性能大幅下降的问题，这一现象被称为“灾难性遗忘”。虽然在持续学习 (CL) 社区中进行了广泛的研究，但在 LLM 领域中出现了新的表现形式。在本次调查中，我们对 CL 背景下 LLM 的当前研究进展进行了全面概述。本次调查分为四个主要部分：我们首先描述了持续学习 LLM 的概述，包括两个连续性方向：垂直连续性（或垂直持续学习），即从一般能力到特定能力的持续适应，以及水平连续性（或水平持续学习），即跨时间和领域的持续适应（第 3 节）。然后，我们总结了在现代 CL 背景下学习 LLM 的三个阶段：持续预训练 (CPT)、域自适应预训练 (DAP) 和持续微调 (CFT)（第 4 节）。然后，我们概述了 LLM 持续学习的评估协议，以及当前可用的数据源（第 5 节）。最后，我们讨论了与 LLM 的持续学习相关的有趣问题（第 6 节）。本次调查中检查的论文完整列表可在 https://github.com/Wang-ML-Lab/llm-continual-learning-survey 中找到。

##### **Modeling Selective Feature Attention for Representation-based Siamese Text Matching**
2404.16776v1 by Jianxiang Zang,Hui Liu

Representation-based Siamese networks have risen to popularity in lightweight
text matching due to their low deployment and inference costs. While word-level
attention mechanisms have been implemented within Siamese networks to improve
performance, we propose Feature Attention (FA), a novel downstream block
designed to enrich the modeling of dependencies among embedding features.
Employing "squeeze-and-excitation" techniques, the FA block dynamically adjusts
the emphasis on individual features, enabling the network to concentrate more
on features that significantly contribute to the final classification. Building
upon FA, we introduce a dynamic "selection" mechanism called Selective Feature
Attention (SFA), which leverages a stacked BiGRU Inception structure. The SFA
block facilitates multi-scale semantic extraction by traversing different
stacked BiGRU layers, encouraging the network to selectively concentrate on
semantic information and embedding features across varying levels of
abstraction. Both the FA and SFA blocks offer a seamless integration capability
with various Siamese networks, showcasing a plug-and-play characteristic.
Experimental evaluations conducted across diverse text matching baselines and
benchmarks underscore the indispensability of modeling feature attention and
the superiority of the "selection" mechanism.

摘要：基于表征的孪生网络由于其低部署和推理成本，在轻量级文本匹配中已广受欢迎。虽然词级注意力机制已在孪生网络中实现以提高性能，但我们提出了一种新颖的下游块特征注意力（FA），旨在丰富嵌入特征之间依赖关系的建模。采用“挤压和激励”技术，FA 块动态调整对各个特征的强调，使网络能够更多地集中于对最终分类有重大贡献的特征。在 FA 的基础上，我们引入了一种称为选择性特征注意力（SFA）的动态“选择”机制，它利用了堆叠的 BiGRU Inception 结构。SFA 块通过遍历不同的堆叠 BiGRU 层来促进多尺度语义提取，鼓励网络选择性地专注于不同抽象级别的语义信息和嵌入特征。FA 和 SFA 块都提供与各种孪生网络的无缝集成能力，展示了即插即用的特性。在各种文本匹配基线和基准上进行的实验评估强调了建模特征注意力的必要性和“选择”机制的优越性。

##### **REBEL: Reinforcement Learning via Regressing Relative Rewards**
2404.16767v1 by Zhaolin Gao,Jonathan D. Chang,Wenhao Zhan,Owen Oertell,Gokul Swamy,Kianté Brantley,Thorsten Joachims,J. Andrew Bagnell,Jason D. Lee,Wen Sun

While originally developed for continuous control problems, Proximal Policy
Optimization (PPO) has emerged as the work-horse of a variety of reinforcement
learning (RL) applications including the fine-tuning of generative models.
Unfortunately, PPO requires multiple heuristics to enable stable convergence
(e.g. value networks, clipping) and is notorious for its sensitivity to the
precise implementation of these components. In response, we take a step back
and ask what a minimalist RL algorithm for the era of generative models would
look like. We propose REBEL, an algorithm that cleanly reduces the problem of
policy optimization to regressing the relative rewards via a direct policy
parameterization between two completions to a prompt, enabling strikingly
lightweight implementation. In theory, we prove that fundamental RL algorithms
like Natural Policy Gradient can be seen as variants of REBEL, which allows us
to match the strongest known theoretical guarantees in terms of convergence and
sample complexity in the RL literature. REBEL can also cleanly incorporate
offline data and handle the intransitive preferences we frequently see in
practice. Empirically, we find that REBEL provides a unified approach to
language modeling and image generation with stronger or similar performance as
PPO and DPO, all while being simpler to implement and more computationally
tractable than PPO.

摘要：最初为连续控制问题而开发的近端策略优化 (PPO) 已成为各种强化学习 (RL) 应用（包括生成模型的微调）的动力。不幸的是，PPO 需要多个启发式方法才能实现稳定的收敛（例如值网络、裁剪），并且以其对这些组件的精确实现方式的敏感性而臭名昭著。作为回应，我们退后一步，并询问生成模型时代的极简主义 RL 算法是什么样的。我们提出了 REBEL，这是一种算法，它通过直接策略参数化在两个完成之间对提示进行回归，将策略优化的难题干净地简化为回归相对奖励，从而实现惊人的轻量级实现。在理论上，我们证明了诸如自然策略梯度之类的基本 RL 算法可以看作是 REBEL 的变体，这使我们能够在收敛和样本复杂性方面匹配 RL 文献中已知的理论保证。REBEL 还可以干净地合并离线数据并处理我们在实践中经常看到的非传递性偏好。根据经验，我们发现 REBEL 提供了一种统一的方法来进行语言建模和图像生成，其性能比 PPO 和 DPO 更强或相似，同时比 PPO 更易于实现且在计算上更易于处理。

##### **Prefix Text as a Yarn: Eliciting Non-English Alignment in Foundation Language Model**
2404.16766v1 by Runzhe Zhan,Xinyi Yang,Derek F. Wong,Lidia S. Chao,Yue Zhang

While supervised fine-tuning (SFT) has been a straightforward approach for
tailoring the output of foundation large language model (LLM) to specific
preferences, concerns have been raised about the depth of this alignment, with
some critiques suggesting it is merely "superficial". We critically examine
this hypothesis within the scope of cross-lingual generation tasks, proposing
that the effectiveness of SFT may be constrained by its reliance on prior
tokens to guide cross-lingual generation. Based on this crucial insight, and in
response to the challenges posed by the costly and limited availability of
non-English data for SFT, we introduce a novel training-free alignment method
named PreTTY, which employs minimal task-related prior tokens to bridge the
foundation LLM and the SFT LLM, achieving comparable performance without
training. Experiments on machine translation and part-of-speech tagging across
eight languages demonstrate the efficacy of PreTTY in cross-lingual settings.
Remarkably, by initiating the decoding process with only one or two prior
tokens, foundation LLMs can achieve performance comparable to their SFT
counterparts. This method presents a cost-effective alternative to SFT and
advances the democratization of multilingual LLMs.

摘要：<paragraph>雖然監督微調 (SFT) 對於調整基礎大型語言模型 (LLM) 的輸出以符合特定偏好是一種直接的方法，但對於此對齊的深度已引起疑慮，一些批評者認為它僅僅是「表面上的」。我們在跨語言生成任務的範圍內批判性地檢視此假設，提出 SFT 的有效性可能受到其依賴先前符號來引導跨語言生成的限制。基於此關鍵見解，並針對非英語資料對 SFT 昂貴且有限的可用性所造成的挑戰，我們引入一種名為 PreTTY 的新訓練免費對齊方法，它使用最少的與任務相關的先前符號來橋接基礎 LLM 和 SFT LLM，在不進行訓練的情況下達成相近的效能。跨越八種語言的機器翻譯和詞性標記的實驗證明了 PreTTY 在跨語言設定中的效能。值得注意的是，僅使用一個或兩個先前符號啟動解碼程序，基礎 LLM 便能達成與其 SFT 對應模型相近的效能。此方法提供一個對 SFT 來說具有成本效益的替代方案，並推動多語言 LLM 的民主化。</paragraph>

##### **Automatic Speech Recognition System-Independent Word Error Rate Estimation**
2404.16743v2 by Chanho Park,Mingjie Chen,Thomas Hain

Word error rate (WER) is a metric used to evaluate the quality of
transcriptions produced by Automatic Speech Recognition (ASR) systems. In many
applications, it is of interest to estimate WER given a pair of a speech
utterance and a transcript. Previous work on WER estimation focused on building
models that are trained with a specific ASR system in mind (referred to as ASR
system-dependent). These are also domain-dependent and inflexible in real-world
applications. In this paper, a hypothesis generation method for ASR
System-Independent WER estimation (SIWE) is proposed. In contrast to prior
work, the WER estimators are trained using data that simulates ASR system
output. Hypotheses are generated using phonetically similar or linguistically
more likely alternative words. In WER estimation experiments, the proposed
method reaches a similar performance to ASR system-dependent WER estimators on
in-domain data and achieves state-of-the-art performance on out-of-domain data.
On the out-of-domain data, the SIWE model outperformed the baseline estimators
in root mean square error and Pearson correlation coefficient by relative
17.58% and 18.21%, respectively, on Switchboard and CALLHOME. The performance
was further improved when the WER of the training set was close to the WER of
the evaluation dataset.

摘要：字詞錯誤率 (WER) 是一個用於評估自動語音辨識 (ASR) 系統所產生轉錄品質的指標。在許多應用中，估計給定一對語音發話和轉錄的 WER 是很有意義的。先前關於 WER 估計的研究著重於建立針對特定 ASR 系統訓練的模型（稱為 ASR 系統依賴）。這些模型在現實世界應用中也依賴於領域，而且不靈活。在本文中，提出了一種用於 ASR 系統非依賴 WER 估計 (SIWE) 的假設產生方法。與先前的研究相反，WER 估計器使用模擬 ASR 系統輸出的資料進行訓練。假設是使用在語音上相似的或在語言上更可能的替代字詞產生的。在 WER 估計實驗中，所提出的方法在領域內資料上達到了與 ASR 系統依賴 WER 估計器相似的效能，並在領域外資料上達到了最先進的效能。在領域外資料上，SIWE 模型在均方根誤差和 Pearson 相關係數上分別優於基線估計器 17.58% 和 18.21%，在 Switchboard 和 CALLHOME 上。當訓練組的 WER 接近評估資料集的 WER 時，效能進一步提升。

##### **Distilling Privileged Information for Dubins Traveling Salesman Problems with Neighborhoods**
2404.16721v1 by Min Kyu Shin,Su-Jeong Park,Seung-Keol Ryu,Heeyeon Kim,Han-Lim Choi

This paper presents a novel learning approach for Dubins Traveling Salesman
Problems(DTSP) with Neighborhood (DTSPN) to quickly produce a tour of a
non-holonomic vehicle passing through neighborhoods of given task points. The
method involves two learning phases: initially, a model-free reinforcement
learning approach leverages privileged information to distill knowledge from
expert trajectories generated by the LinKernighan heuristic (LKH) algorithm.
Subsequently, a supervised learning phase trains an adaptation network to solve
problems independently of privileged information. Before the first learning
phase, a parameter initialization technique using the demonstration data was
also devised to enhance training efficiency. The proposed learning method
produces a solution about 50 times faster than LKH and substantially
outperforms other imitation learning and RL with demonstration schemes, most of
which fail to sense all the task points.

摘要：本文提出了一種針對具有鄰域的杜賓斯旅行商問題 (DTSPN) 的新穎學習方法，以快速產生非完整約束車輛通過給定任務點鄰域的巡迴路線。該方法包含兩個學習階段：最初，無模型強化學習方法利用特權資訊從 LinKernighan 啟發式 (LKH) 演算法產生的專家軌跡中萃取知識。隨後，監督式學習階段訓練適應網路，以獨立於特權資訊來解決問題。在第一個學習階段之前，還設計了一種使用示範資料的參數初始化技術，以提高訓練效率。所提出的學習方法產生的解比 LKH 快約 50 倍，並且大幅優於其他模仿學習和帶示範的 RL 方案，其中大多數都無法感測所有任務點。

##### **Features Fusion for Dual-View Mammography Mass Detection**
2404.16718v1 by Arina Varlamova,Valery Belotsky,Grigory Novikov,Anton Konushin,Evgeny Sidorov

Detection of malignant lesions on mammography images is extremely important
for early breast cancer diagnosis. In clinical practice, images are acquired
from two different angles, and radiologists can fully utilize information from
both views, simultaneously locating the same lesion. However, for automatic
detection approaches such information fusion remains a challenge. In this
paper, we propose a new model called MAMM-Net, which allows the processing of
both mammography views simultaneously by sharing information not only on an
object level, as seen in existing works, but also on a feature level.
MAMM-Net's key component is the Fusion Layer, based on deformable attention and
designed to increase detection precision while keeping high recall. Our
experiments show superior performance on the public DDSM dataset compared to
the previous state-of-the-art model, while introducing new helpful features
such as lesion annotation on pixel-level and classification of lesions
malignancy.

摘要：乳房攝影檢查影像上惡性病灶的偵測對於乳癌早期診斷至關重要。在臨床實務上，影像會從兩個不同的角度取得，而放射科醫師可以充分運用兩者視角的資訊，同時定位同一個病灶。然而，對於自動偵測方法而言，這種資訊融合仍是一項挑戰。在本文中，我們提出一個名為 MAMM-Net 的新模型，它允許同時處理兩個乳房攝影視角，不僅在物件層級共享資訊（如同現有研究所示），也在特徵層級共享資訊。MAMM-Net 的關鍵組成是融合層，它基於可變形注意力，並設計用於在維持高召回率的同時提高偵測精度。我們的實驗在公共 DDSM 資料集上展現出優異的效能，優於先前的最先進模型，同時引入了新的有益特徵，例如像素層級的病灶註解和病灶惡性度分類。

##### **Embracing Diversity: Interpretable Zero-shot classification beyond one vector per class**
2404.16717v1 by Mazda Moayeri,Michael Rabbat,Mark Ibrahim,Diane Bouchacourt

Vision-language models enable open-world classification of objects without
the need for any retraining. While this zero-shot paradigm marks a significant
advance, even today's best models exhibit skewed performance when objects are
dissimilar from their typical depiction. Real world objects such as pears
appear in a variety of forms -- from diced to whole, on a table or in a bowl --
yet standard VLM classifiers map all instances of a class to a \it{single
vector based on the class label}. We argue that to represent this rich
diversity within a class, zero-shot classification should move beyond a single
vector. We propose a method to encode and account for diversity within a class
using inferred attributes, still in the zero-shot setting without retraining.
We find our method consistently outperforms standard zero-shot classification
over a large suite of datasets encompassing hierarchies, diverse object states,
and real-world geographic diversity, as well finer-grained datasets where
intra-class diversity may be less prevalent. Importantly, our method is
inherently interpretable, offering faithful explanations for each inference to
facilitate model debugging and enhance transparency. We also find our method
scales efficiently to a large number of attributes to account for diversity --
leading to more accurate predictions for atypical instances. Finally, we
characterize a principled trade-off between overall and worst class accuracy,
which can be tuned via a hyperparameter of our method. We hope this work spurs
further research into the promise of zero-shot classification beyond a single
class vector for capturing diversity in the world, and building transparent AI
systems without compromising performance.

摘要：视觉语言模型能够对物体进行开放世界的分类，而无需任何重新训练。虽然这种零样本范式标志着重大进步，但即使是当今最好的模型在对象与其典型描述不同时也会表现出偏差。现实世界中的物体，如梨，会以各种形式出现——从切成小块到整个，放在桌子上或碗里——但标准的 VLM 分类器将一个类别的所有实例映射到一个基于类别标签的单一向量。我们认为，为了表示一个类别中的这种丰富多样性，零样本分类应该超越单个向量。我们提出了一种方法，使用推断的属性对一个类别中的多样性进行编码和解释，仍然在零样本设置中，无需重新训练。我们发现我们的方法在包含层次结构、不同对象状态和现实世界地理多样性的大型数据集套件以及类内多样性可能不太普遍的更细粒度数据集上，始终优于标准的零样本分类。重要的是，我们的方法本质上是可解释的，为每个推理提供了忠实的解释，以促进模型调试并增强透明度。我们还发现我们的方法可以有效地扩展到大量属性以解释多样性——从而对非典型实例进行更准确的预测。最后，我们描述了整体和最差类别准确性之间的原则权衡，可以通过我们方法的一个超参数进行调整。我们希望这项工作激发进一步研究零样本分类的承诺，超越单个类别向量来捕捉世界中的多样性，并在不影响性能的情况下构建透明的人工智能系统。

##### **LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding**
2404.16710v2 by Mostafa Elhoushi,Akshat Shrivastava,Diana Liskovich,Basil Hosmer,Bram Wasti,Liangzhen Lai,Anas Mahmoud,Bilge Acun,Saurabh Agarwal,Ahmed Roman,Ahmed A Aly,Beidi Chen,Carole-Jean Wu

We present LayerSkip, an end-to-end solution to speed-up inference of large
language models (LLMs). First, during training we apply layer dropout, with low
dropout rates for earlier layers and higher dropout rates for later layers, and
an early exit loss where all transformer layers share the same exit. Second,
during inference, we show that this training recipe increases the accuracy of
early exit at earlier layers, without adding any auxiliary layers or modules to
the model. Third, we present a novel self-speculative decoding solution where
we exit at early layers and verify and correct with remaining layers of the
model. Our proposed self-speculative decoding approach has less memory
footprint than other speculative decoding approaches and benefits from shared
compute and activations of the draft and verification stages. We run
experiments on different Llama model sizes on different types of training:
pretraining from scratch, continual pretraining, finetuning on specific data
domain, and finetuning on specific task. We implement our inference solution
and show speedups of up to 2.16x on summarization for CNN/DM documents, 1.82x
on coding, and 2.0x on TOPv2 semantic parsing task.

摘要：<paragraph>我們提出 LayerSkip，一種端到端的解決方案，用於加速大型語言模型 (LLM) 的推論。首先，在訓練期間，我們應用層級輟學，較早層級的輟學率較低，較晚層級的輟學率較高，以及一個所有變壓器層級共享相同出口的早期退出損失。其次，在推論期間，我們展示了此訓練配方增加了較早層級早期退出的準確性，而無需向模型添加任何輔助層級或模組。第三，我們提出了一個新穎的自推測解碼解決方案，在其中我們在較早層級退出，並使用模型的剩餘層級進行驗證和更正。我們提出的自推測解碼方法比其他推測解碼方法的記憶體佔用量更少，並且受益於草稿和驗證階段的共享計算和激活。我們針對不同類型的訓練對不同 Llama 模型大小執行實驗：從頭開始預訓練、持續預訓練、針對特定資料網域進行微調，以及針對特定任務進行微調。我們實作我們的推論解決方案，並展示了 CNN/DM 文件摘要的加速效果高達 2.16 倍、編碼加速 1.82 倍，以及 TOPv2 語意解析任務加速 2.0 倍。</paragraph>

##### **Cooperate or Collapse: Emergence of Sustainability Behaviors in a Society of LLM Agents**
2404.16698v1 by Giorgio Piatti,Zhijing Jin,Max Kleiman-Weiner,Bernhard Schölkopf,Mrinmaya Sachan,Rada Mihalcea

In the rapidly evolving field of artificial intelligence, ensuring safe
decision-making of Large Language Models (LLMs) is a significant challenge.
This paper introduces Governance of the Commons Simulation (GovSim), a
simulation platform designed to study strategic interactions and cooperative
decision-making in LLMs. Through this simulation environment, we explore the
dynamics of resource sharing among AI agents, highlighting the importance of
ethical considerations, strategic planning, and negotiation skills. GovSim is
versatile and supports any text-based agent, including LLMs agents. Using the
Generative Agent framework, we create a standard agent that facilitates the
integration of different LLMs. Our findings reveal that within GovSim, only two
out of 15 tested LLMs managed to achieve a sustainable outcome, indicating a
significant gap in the ability of models to manage shared resources.
Furthermore, we find that by removing the ability of agents to communicate,
they overuse the shared resource, highlighting the importance of communication
for cooperation. Interestingly, most LLMs lack the ability to make
universalized hypotheses, which highlights a significant weakness in their
reasoning skills. We open source the full suite of our research results,
including the simulation environment, agent prompts, and a comprehensive web
interface.

摘要：<paragraph>在快速發展的人工智慧領域中，確保大型語言模型 (LLM) 安全決策是一項重大挑戰。本文介紹了治理公地模擬 (GovSim)，這是一個模擬平台，旨在研究 LLM 中的策略互動和合作決策。透過此模擬環境，我們探討了 AI 代理之間資源共享的動態，強調了倫理考量、策略規劃和談判技巧的重要性。GovSim 具有多功能性，支援任何基於文字的代理，包括 LLM 代理。使用生成代理架構，我們建立了一個標準代理，以促進不同 LLM 的整合。我們的研究結果顯示，在 GovSim 中，15 個受測 LLM 中只有兩個設法達成永續成果，這表示模型管理共享資源的能力存在顯著差距。此外，我們發現，透過移除代理溝通的能力，他們會過度使用共享資源，這突顯了溝通對於合作的重要性。有趣的是，大多數 LLM 都缺乏提出普遍化假設的能力，這突顯了其推理能力的顯著弱點。我們開放原始碼了我們所有研究結果的完整套件，包括模擬環境、代理提示和一個全面的網路介面。</paragraph>

##### **Influence of Solution Efficiency and Valence of Instruction on Additive and Subtractive Solution Strategies in Humans and GPT-4**
2404.16692v1 by Lydia Uhler,Verena Jordan,Jürgen Buder,Markus Huff,Frank Papenmeier

We explored the addition bias, a cognitive tendency to prefer adding elements
over removing them to alter an initial state or structure, by conducting four
preregistered experiments examining the problem-solving behavior of both humans
and OpenAl's GPT-4 large language model. The experiments involved 588
participants from the U.S. and 680 iterations of the GPT-4 model. The
problem-solving task was either to create symmetry within a grid (Experiments 1
and 3) or to edit a summary (Experiments 2 and 4). As hypothesized, we found
that overall, the addition bias was present. Solution efficiency (Experiments 1
and 2) and valence of the instruction (Experiments 3 and 4) played important
roles. Human participants were less likely to use additive strategies when
subtraction was relatively more efficient than when addition and subtraction
were equally efficient. GPT-4 exhibited the opposite behavior, with a strong
addition bias when subtraction was more efficient. In terms of instruction
valence, GPT-4 was more likely to add words when asked to "improve" compared to
"edit", whereas humans did not show this effect. When we looked at the addition
bias under different conditions, we found more biased responses for GPT-4
compared to humans. Our findings highlight the importance of considering
comparable and sometimes superior subtractive alternatives, as well as
reevaluating one's own and particularly the language models' problem-solving
behavior.

摘要：我們探討了加法偏誤，這是一種認知傾向，偏好添加元素，而非移除元素來改變初始狀態或結構，我們透過執行四項預先註冊的實驗來探討人類和 OpenAl 的 GPT-4 大型語言模型的解決問題行為。這些實驗包含來自美國的 588 位參與者和 GPT-4 模型的 680 次迭代。解決問題的任務是要在網格中建立對稱性（實驗 1 和 3）或編輯摘要（實驗 2 和 4）。正如我們所假設的，我們發現整體而言，加法偏誤是存在的。解決方案效率（實驗 1 和 2）和指令的效價（實驗 3 和 4）扮演了重要的角色。當減法比加法和減法同樣有效率時，人類參與者較不可能使用加法策略。GPT-4 表現出相反的行為，當減法較有效率時，加法偏誤強烈。在指令效價方面，與「編輯」相比，GPT-4 在被要求「改進」時更有可能添加字詞，而人類則沒有表現出這種效應。當我們在不同條件下檢視加法偏誤時，我們發現 GPT-4 的反應比人類更偏頗。我們的研究結果強調了考慮可比較且有時更優越的減法替代方案的重要性，以及重新評估自身和特別是語言模型的解決問題行為。

##### **Prediction Is All MoE Needs: Expert Load Distribution Goes from Fluctuating to Stabilizing**
2404.16914v1 by Peizhuang Cong,Aomufei Yuan,Shimao Chen,Yuxuan Tian,Bowen Ye,Tong Yang

MoE facilitates the development of large models by making the computational
complexity of the model no longer scale linearly with increasing parameters.
The learning sparse gating network selects a set of experts for each token to
be processed; however, this may lead to differences in the number of tokens
processed by each expert over several successive iterations, i.e., the expert
load fluctuations, which reduces computational parallelization and resource
utilization. To this end, we traced and analyzed loads of each expert in the
training iterations for several large language models in this work, and defined
the transient state with "obvious load fluctuation" and the stable state with
"temporal locality". Moreover, given the characteristics of these two states
and the computational overhead, we deployed three classical prediction
algorithms that achieve accurate expert load prediction results. For the GPT3
350M model, the average error rates for predicting the expert load proportion
over the next 1,000 and 2,000 steps are approximately 1.3% and 1.8%,
respectively. This work can provide valuable guidance for expert placement or
resource allocation for MoE model training. Based on this work, we will propose
an expert placement scheme for transient and stable states in our coming work.

摘要：MoE 透過讓模型的計算複雜度不再隨著參數增加而線性擴展，進而促進大型模型的開發。學習稀疏閘控網路會為每個要處理的符號選擇一組專家；然而，這可能會導致每個專家在多次連續反覆運算中處理的符號數量不同，也就是專家負載波動，這會降低計算並行化和資源利用率。為了解決這個問題，我們追蹤並分析了這項工作中幾個大型語言模型在訓練反覆運算中每個專家的負載，並定義了「負載波動明顯」的暫態狀態和「時間局部性」的穩定狀態。此外，考量這兩個狀態的特徵和計算成本，我們部署了三個經典預測演算法，可達成精準的專家負載預測結果。對於 GPT3 350M 模型，預測接下來 1,000 和 2,000 個步驟的專家負載比例的平均誤差率分別約為 1.3% 和 1.8%。這項工作可以為 MoE 模型訓練的專家配置或資源配置提供有價值的指導。根據這項工作，我們將在後續工作中提出一個針對暫態和穩定狀態的專家配置方案。

##### **DE-CGAN: Boosting rTMS Treatment Prediction with Diversity Enhancing Conditional Generative Adversarial Networks**
2404.16913v1 by Matthew Squires,Xiaohui Tao,Soman Elangovan,Raj Gururajan,Haoran Xie,Xujuan Zhou,Yuefeng Li,U Rajendra Acharya

Repetitive Transcranial Magnetic Stimulation (rTMS) is a well-supported,
evidence-based treatment for depression. However, patterns of response to this
treatment are inconsistent. Emerging evidence suggests that artificial
intelligence can predict rTMS treatment outcomes for most patients using fMRI
connectivity features. While these models can reliably predict treatment
outcomes for many patients for some underrepresented fMRI connectivity measures
DNN models are unable to reliably predict treatment outcomes. As such we
propose a novel method, Diversity Enhancing Conditional General Adversarial
Network (DE-CGAN) for oversampling these underrepresented examples. DE-CGAN
creates synthetic examples in difficult-to-classify regions by first
identifying these data points and then creating conditioned synthetic examples
to enhance data diversity. Through empirical experiments we show that a
classification model trained using a diversity enhanced training set
outperforms traditional data augmentation techniques and existing benchmark
results. This work shows that increasing the diversity of a training dataset
can improve classification model performance. Furthermore, this work provides
evidence for the utility of synthetic patients providing larger more robust
datasets for both AI researchers and psychiatrists to explore variable
relationships.

摘要：重複經顱磁刺激 (rTMS) 是一種得到充分支持的、基於證據的抑鬱症治療方法。然而，對這種治療的反應模式並不一致。新興證據表明，人工智慧可以使用 fMRI 連接特徵預測大多數患者的 rTMS 治療結果。雖然這些模型可以可靠地預測許多患者的治療結果，但對於一些未被充分表示的 fMRI 連接測量，DNN 模型無法可靠地預測治療結果。因此，我們提出了一種新方法，即多樣性增強條件生成對抗網路 (DE-CGAN) 來對這些未被充分表示的範例進行過採樣。DE-CGAN 通過首先識別這些數據點，然後創建條件合成範例來增強數據多樣性，從而創建難以分類區域中的合成範例。通過實證實驗，我們表明使用多樣性增強訓練集訓練的分類模型優於傳統數據擴充技術和現有基準結果。這項工作表明，增加訓練數據集的多樣性可以提高分類模型的性能。此外，這項工作為合成患者的效用提供了證據，為人工智能研究人員和精神科醫生探索變量關係提供了更大、更強大的數據集。

##### **EmoVIT: Revolutionizing Emotion Insights with Visual Instruction Tuning**
2404.16670v1 by Hongxia Xie,Chu-Jun Peng,Yu-Wen Tseng,Hung-Jen Chen,Chan-Feng Hsu,Hong-Han Shuai,Wen-Huang Cheng

Visual Instruction Tuning represents a novel learning paradigm involving the
fine-tuning of pre-trained language models using task-specific instructions.
This paradigm shows promising zero-shot results in various natural language
processing tasks but is still unexplored in vision emotion understanding. In
this work, we focus on enhancing the model's proficiency in understanding and
adhering to instructions related to emotional contexts. Initially, we identify
key visual clues critical to visual emotion recognition. Subsequently, we
introduce a novel GPT-assisted pipeline for generating emotion visual
instruction data, effectively addressing the scarcity of annotated instruction
data in this domain. Expanding on the groundwork established by InstructBLIP,
our proposed EmoVIT architecture incorporates emotion-specific instruction
data, leveraging the powerful capabilities of Large Language Models to enhance
performance. Through extensive experiments, our model showcases its proficiency
in emotion classification, adeptness in affective reasoning, and competence in
comprehending humor. The comparative analysis provides a robust benchmark for
Emotion Visual Instruction Tuning in the era of LLMs, providing valuable
insights and opening avenues for future exploration in this domain. Our code is
available at \url{https://github.com/aimmemotion/EmoVIT}.

摘要：視覺指令調整是一種新穎的學習範例，涉及使用特定於任務的指令微調預先訓練的語言模型。此範例在各種自然語言處理任務中顯示出有希望的零次學習結果，但在視覺情緒理解中仍未探索。在這項工作中，我們專注於增強模型在理解和遵守與情緒背景相關的指令方面的能力。最初，我們識別出對視覺情緒辨識至關重要的關鍵視覺線索。隨後，我們引入了一個新穎的 GPT 輔助管道來產生情緒視覺指令數據，有效地解決了此領域中標記指令數據的稀缺性。在 InstructBLIP 建立的基礎上，我們提出的 EmoVIT 架構結合了特定於情緒的指令數據，利用大型語言模型的強大功能來增強效能。透過廣泛的實驗，我們的模型展示了其在情緒分類、情感推理的熟練度，以及理解幽默的能力。比較分析為 LLM 時代的情緒視覺指令調整提供了穩健的基準，提供了寶貴的見解，並為此領域未來的探索開啟了途徑。我們的程式碼可在 \url{https://github.com/aimmemotion/EmoVIT} 取得。

##### **Formal Specification, Assessment, and Enforcement of Fairness for Generative AIs**
2404.16663v2 by Chih-Hong Cheng,Changshun Wu,Harald Ruess,Xingyu Zhao,Saddek Bensalem

Reinforcing or even exacerbating societal biases and inequalities will
increase significantly as generative AI increasingly produces useful artifacts,
from text to images and beyond, for the real world. We address these issues by
formally characterizing the notion of fairness for generative AI as a basis for
monitoring and enforcing fairness. We define two levels of fairness using the
notion of infinite sequences of abstractions of AI-generated artifacts such as
text or images. The first is the fairness demonstrated on the generated
sequences, which is evaluated only on the outputs while agnostic to the prompts
and models used. The second is the inherent fairness of the generative AI
model, which requires that fairness be manifested when input prompts are
neutral, that is, they do not explicitly instruct the generative AI to produce
a particular type of output. We also study relative intersectional fairness to
counteract the combinatorial explosion of fairness when considering multiple
categories together with lazy fairness enforcement. Finally, fairness
monitoring and enforcement are tested against some current generative AI
models.

摘要：生成式人工智能日益为现实世界产生有用的制品，从文本到图像甚至更多，而强化甚至加剧社会偏见和不平等的情况将显著增加。我们通过正式描述生成式人工智能的公平概念，作为监控和执行公平性的基础，来解决这些问题。我们使用人工智能生成制品（如文本或图像）的抽象无限序列概念，定义了两个级别的公平性。第一个是生成序列中体现的公平性，仅在输出上进行评估，而与提示和使用的模型无关。第二个是生成式人工智能模型的内在公平性，它要求在输入提示为中立时表现出公平性，即它们不会明确指示生成式人工智能生成特定类型的输出。我们还研究相对交叉公平性，以在考虑多个类别和懒惰公平性执行时抵消公平性的组合爆炸。最后，公平性监控和执行针对一些当前的生成式人工智能模型进行了测试。

##### **Benchmarking Mobile Device Control Agents across Diverse Configurations**
2404.16660v1 by Juyong Lee,Taywon Min,Minyong An,Changyeon Kim,Kimin Lee

Developing autonomous agents for mobile devices can significantly enhance
user interactions by offering increased efficiency and accessibility. However,
despite the growing interest in mobile device control agents, the absence of a
commonly adopted benchmark makes it challenging to quantify scientific progress
in this area. In this work, we introduce B-MoCA: a novel benchmark designed
specifically for evaluating mobile device control agents. To create a realistic
benchmark, we develop B-MoCA based on the Android operating system and define
60 common daily tasks. Importantly, we incorporate a randomization feature that
changes various aspects of mobile devices, including user interface layouts and
language settings, to assess generalization performance. We benchmark diverse
agents, including agents employing large language models (LLMs) or multi-modal
LLMs as well as agents trained from scratch using human expert demonstrations.
While these agents demonstrate proficiency in executing straightforward tasks,
their poor performance on complex tasks highlights significant opportunities
for future research to enhance their effectiveness. Our source code is publicly
available at https://b-moca.github.io.

摘要：開發行動裝置的自主代理程式能大幅提升使用者的互動，因為它能提供更高的效率和可及性。然而，儘管行動裝置控制代理程式越來越受到重視，但由於缺乏普遍採用的基準，因此難以量化這個領域的科學進展。在這項工作中，我們引入了 B-MoCA：一個專門用於評估行動裝置控制代理程式的全新基準。為了建立一個寫實的基準，我們根據 Android 作業系統開發 B-MoCA，並定義了 60 項常見的日常任務。重要的是，我們加入了一個隨機化功能，它會變更行動裝置的各種面向，包括使用者介面配置和語言設定，以評估概化效能。我們對各種代理程式進行基準測試，包括使用大型語言模型 (LLM) 或多模態 LLM 的代理程式，以及使用人類專家示範從頭訓練的代理程式。儘管這些代理程式在執行直接任務方面表現出熟練度，但它們在複雜任務上的表現不佳，這突顯出未來研究在提升其效能方面有顯著的機會。我們的原始碼已公開於 https://b-moca.github.io。

##### **ProbGate at EHRSQL 2024: Enhancing SQL Query Generation Accuracy through Probabilistic Threshold Filtering and Error Handling**
2404.16659v1 by Sangryul Kim,Donghee Han,Sehyun Kim

Recently, deep learning-based language models have significantly enhanced
text-to-SQL tasks, with promising applications in retrieving patient records
within the medical domain. One notable challenge in such applications is
discerning unanswerable queries. Through fine-tuning model, we demonstrate the
feasibility of converting medical record inquiries into SQL queries.
Additionally, we introduce an entropy-based method to identify and filter out
unanswerable results. We further enhance result quality by filtering
low-confidence SQL through log probability-based distribution, while
grammatical and schema errors are mitigated by executing queries on the actual
database. We experimentally verified that our method can filter unanswerable
questions, which can be widely utilized even when the parameters of the model
are not accessible, and that it can be effectively utilized in practice.

摘要：近期，基于深度学习的语言模型极大地增强了文本到 SQL 的任务，在医疗领域检索患者记录方面具有广阔的应用前景。此类应用中一个显著的挑战在于识别不可回答的查询。通过微调模型，我们展示了将病历查询转换为 SQL 查询的可行性。此外，我们引入了一种基于熵的方法来识别并过滤掉不可回答的结果。我们通过基于对数概率分布过滤低置信度的 SQL 进一步提高结果质量，同时通过在实际数据库上执行查询来缓解语法和模式错误。我们通过实验验证了我们的方法可以过滤掉不可回答的问题，即使在无法访问模型参数的情况下也可以广泛使用，并且在实践中可以有效地利用。

##### **A Self-Organizing Clustering System for Unsupervised Distribution Shift Detection**
2404.16656v1 by Sebastián Basterrech,Line Clemmensen,Gerardo Rubino

Modeling non-stationary data is a challenging problem in the field of
continual learning, and data distribution shifts may result in negative
consequences on the performance of a machine learning model. Classic learning
tools are often vulnerable to perturbations of the input covariates, and are
sensitive to outliers and noise, and some tools are based on rigid algebraic
assumptions. Distribution shifts are frequently occurring due to changes in raw
materials for production, seasonality, a different user base, or even
adversarial attacks. Therefore, there is a need for more effective distribution
shift detection techniques.
  In this work, we propose a continual learning framework for monitoring and
detecting distribution changes. We explore the problem in a latent space
generated by a bio-inspired self-organizing clustering and statistical aspects
of the latent space. In particular, we investigate the projections made by two
topology-preserving maps: the Self-Organizing Map and the Scale Invariant Map.
Our method can be applied in both a supervised and an unsupervised context. We
construct the assessment of changes in the data distribution as a comparison of
Gaussian signals, making the proposed method fast and robust. We compare it to
other unsupervised techniques, specifically Principal Component Analysis (PCA)
and Kernel-PCA. Our comparison involves conducting experiments using sequences
of images (based on MNIST and injected shifts with adversarial samples),
chemical sensor measurements, and the environmental variable related to ozone
levels. The empirical study reveals the potential of the proposed approach.

摘要：非平穩資料建模是持續學習領域中的一項挑戰性問題，而資料分佈轉移可能會對機器學習模型的效能造成負面影響。傳統的學習工具通常容易受到輸入協變數的擾動影響，且對離群值和雜訊敏感，有些工具則基於僵化的代數假設。由於生產中的原料變動、季節性、不同的使用者基礎，甚至對抗性攻擊，分佈轉移經常發生。因此，需要更有效的分布轉移偵測技術。
在這項工作中，我們提出了一個持續學習架構，用於監控和偵測分佈變化。我們在由生物啟發的自組織聚類和潛在空間的統計面向所產生的潛在空間中探討問題。特別是，我們調查了兩個拓撲保留映射所做的投影：自組織映射和尺度不變映射。我們的技術可以應用於監督式和非監督式的環境中。我們將資料分佈變化的評估建構為高斯訊號的比較，使所提出的技術快速且穩健。我們將其與其他非監督式技術進行比較，特別是主成分分析 (PCA) 和核 PCA。我們的比較涉及使用影像序列（基於 MNIST 和注入對抗樣本的轉移）、化學感測器量測，以及與臭氧濃度相關的環境變數來進行實驗。實證研究揭示了所提出方法的潛力。

##### **Análise de ambiguidade linguística em modelos de linguagem de grande escala (LLMs)**
2404.16653v1 by Lavínia de Carvalho Moraes,Irene Cristina Silvério,Rafael Alexandre Sousa Marques,Bianca de Castro Anaia,Dandara Freitas de Paula,Maria Carolina Schincariol de Faria,Iury Cleveston,Alana de Santana Correia,Raquel Meister Ko Freitag

Linguistic ambiguity continues to represent a significant challenge for
natural language processing (NLP) systems, notwithstanding the advancements in
architectures such as Transformers and BERT. Inspired by the recent success of
instructional models like ChatGPT and Gemini (In 2023, the artificial
intelligence was called Bard.), this study aims to analyze and discuss
linguistic ambiguity within these models, focusing on three types prevalent in
Brazilian Portuguese: semantic, syntactic, and lexical ambiguity. We create a
corpus comprising 120 sentences, both ambiguous and unambiguous, for
classification, explanation, and disambiguation. The models capability to
generate ambiguous sentences was also explored by soliciting sets of sentences
for each type of ambiguity. The results underwent qualitative analysis, drawing
on recognized linguistic references, and quantitative assessment based on the
accuracy of the responses obtained. It was evidenced that even the most
sophisticated models, such as ChatGPT and Gemini, exhibit errors and
deficiencies in their responses, with explanations often providing
inconsistent. Furthermore, the accuracy peaked at 49.58 percent, indicating the
need for descriptive studies for supervised learning.

摘要：語言的模糊性持續對自然語言處理 (NLP) 系統構成重大挑戰，儘管變形金剛和 BERT 等架構已有所進步。受 ChatGPT 和 Gemini 等指導模型近期成功的啟發（2023 年，人工智慧被稱為 Bard），本研究旨在分析和討論這些模型中的語言模糊性，重點關注巴西葡萄牙語中普遍存在的語意、句法和詞彙模糊性三種類型。我們建立一個語料庫，包含 120 個模棱兩可和明確的句子，用於分類、解釋和消除歧義。還通過為每種類型的模糊性徵求句子集來探討模型產生模棱兩可句子的能力。結果經過定性分析，利用公認的語言參考，並根據獲得的回應的準確性進行定量評估。結果表明，即使是最複雜的模型，例如 ChatGPT 和 Gemini，其回應中也存在錯誤和缺陷，解釋通常前後矛盾。此外，準確率最高為 49.58%，這表明需要進行監督式學習的描述性研究。

##### **Tele-FLM Technical Report**
2404.16645v1 by Xiang Li,Yiqun Yao,Xin Jiang,Xuezhi Fang,Chao Wang,Xinzhang Liu,Zihan Wang,Yu Zhao,Xin Wang,Yuyao Huang,Shuangyong Song,Yongxiang Li,Zheng Zhang,Bo Zhao,Aixin Sun,Yequan Wang,Zhongjiang He,Zhongyuan Wang,Xuelong Li,Tiejun Huang

Large language models (LLMs) have showcased profound capabilities in language
understanding and generation, facilitating a wide array of applications.
However, there is a notable paucity of detailed, open-sourced methodologies on
efficiently scaling LLMs beyond 50 billion parameters with minimum
trial-and-error cost and computational resources. In this report, we introduce
Tele-FLM (aka FLM-2), a 52B open-sourced multilingual large language model that
features a stable, efficient pre-training paradigm and enhanced factual
judgment capabilities. Tele-FLM demonstrates superior multilingual language
modeling abilities, measured by BPB on textual corpus. Besides, in both English
and Chinese foundation model evaluation, it is comparable to strong
open-sourced models that involve larger pre-training FLOPs, such as Llama2-70B
and DeepSeek-67B. In addition to the model weights, we share the core designs,
engineering practices, and training details, which we expect to benefit both
the academic and industrial communities.

摘要：大型語言模型 (LLM) 在語言理解和生成方面展示了深厚的功力，促成各種應用。
然而，在有效擴充 LLM 超過 500 億個參數，同時將試錯成本和計算資源降至最低方面，目前尚缺乏詳細、開放原始碼的方法論。在本報告中，我們介紹 Tele-FLM（又稱 FLM-2），這是一個 520 億個開放原始碼的多語言大型語言模型，具有穩定的、高效的預訓練範例和增強的事實判斷能力。Tele-FLM 展示了優異的多語言語言建模能力，由 BPB 在文本語料庫中測量。此外，在英語和中文基礎模型評估中，它與涉及更大預訓練 FLOP 的強大開放原始碼模型相當，例如 Llama2-70B 和 DeepSeek-67B。除了模型權重外，我們還分享核心設計、工程實務和訓練細節，我們期望這能使學術界和產業界受益。

##### **Legal Aspects for Software Developers Interested in Generative AI Applications**
2404.16630v1 by Steffen Herbold,Brian Valerius,Anamaria Mojica-Hanke,Isabella Lex,Joel Mittel

Recent successes in Generative Artificial Intelligence (GenAI) have led to
new technologies capable of generating high-quality code, natural language, and
images. The next step is to integrate GenAI technology into products, a task
typically conducted by software developers. Such product development always
comes with a certain risk of liability. Within this article, we want to shed
light on the current state of two such risks: data protection and copyright.
Both aspects are crucial for GenAI. This technology deals with data for both
model training and generated output. We summarize key aspects regarding our
current knowledge that every software developer involved in product development
using GenAI should be aware of to avoid critical mistakes that may expose them
to liability claims.

摘要：生成式人工智能 (GenAI) 近期的成功，已带来能够生成高质量程式码、自然语言和图像的新技术。下一步是将 GenAI 技术整合到产品中，这项任务通常由软件开发人员执行。此类产品开发总是伴随著一定的责任风险。在本文中，我们希望阐明两种此类风险的当前状态：资料保护和版权。这两方面对于 GenAI 至关重要。这项技术处理用于模型训练和生成输出的资料。我们总结了有关我们当前知识的关键面向，每个参与使用 GenAI 进行产品开发的软件开发人员都应该了解这些面向，以避免可能使他们面临责任索赔的关键错误。

##### **Incorporating Lexical and Syntactic Knowledge for Unsupervised Cross-Lingual Transfer**
2404.16627v1 by Jianyu Zheng,Fengfei Fan,Jianquan Li

Unsupervised cross-lingual transfer involves transferring knowledge between
languages without explicit supervision. Although numerous studies have been
conducted to improve performance in such tasks by focusing on cross-lingual
knowledge, particularly lexical and syntactic knowledge, current approaches are
limited as they only incorporate syntactic or lexical information. Since each
type of information offers unique advantages and no previous attempts have
combined both, we attempt to explore the potential of this approach. In this
paper, we present a novel framework called "Lexicon-Syntax Enhanced
Multilingual BERT" that combines both lexical and syntactic knowledge.
Specifically, we use Multilingual BERT (mBERT) as the base model and employ two
techniques to enhance its learning capabilities. The code-switching technique
is used to implicitly teach the model lexical alignment information, while a
syntactic-based graph attention network is designed to help the model encode
syntactic structure. To integrate both types of knowledge, we input
code-switched sequences into both the syntactic module and the mBERT base model
simultaneously. Our extensive experimental results demonstrate this framework
can consistently outperform all baselines of zero-shot cross-lingual transfer,
with the gains of 1.0~3.7 points on text classification, named entity
recognition (ner), and semantic parsing tasks. Keywords:cross-lingual transfer,
lexicon, syntax, code-switching, graph attention network

摘要：無監督跨語言轉移涉及在語言之間轉移知識，而無需明確的監督。儘管已經進行了大量的研究，通過專注於跨語言知識（特別是詞彙和語法知識）來提高此類任務的性能，但當前的方法受到限制，因為它們僅包含語法或詞彙信息。由於每種類型的信息都提供獨特的優勢，並且以前沒有嘗試將兩者結合起來，因此我們嘗試探索這種方法的潛力。在本文中，我們提出了一個名為「詞彙語法增強多語言 BERT」的新框架，它結合了詞彙和語法知識。具體來說，我們使用多語言 BERT（mBERT）作為基礎模型，並採用兩種技術來增強其學習能力。代碼切換技術用於隱式教授模型詞彙對齊信息，而基於語法的圖注意力網絡旨在幫助模型編碼語法結構。為了整合這兩種知識類型，我們同時將代碼切換序列輸入語法模塊和 mBERT 基礎模型。我們廣泛的實驗結果表明，這個框架可以持續優於零次跨語言轉移的所有基準，在文本分類、命名實體識別（ner）和語義解析任務上獲得 1.0~3.7 分的收益。關鍵字：跨語言轉移、詞彙、語法、代碼切換、圖注意力網絡

##### **Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare**
2404.16621v1 by Emre Can Acikgoz,Osman Batur İnce,Rayene Bench,Arda Anıl Boz,İlker Kesen,Aykut Erdem,Erkut Erdem

The integration of Large Language Models (LLMs) into healthcare promises to
transform medical diagnostics, research, and patient care. Yet, the progression
of medical LLMs faces obstacles such as complex training requirements, rigorous
evaluation demands, and the dominance of proprietary models that restrict
academic exploration. Transparent, comprehensive access to LLM resources is
essential for advancing the field, fostering reproducibility, and encouraging
innovation in healthcare AI. We present Hippocrates, an open-source LLM
framework specifically developed for the medical domain. In stark contrast to
previous efforts, it offers unrestricted access to its training datasets,
codebase, checkpoints, and evaluation protocols. This open approach is designed
to stimulate collaborative research, allowing the community to build upon,
refine, and rigorously evaluate medical LLMs within a transparent ecosystem.
Also, we introduce Hippo, a family of 7B models tailored for the medical
domain, fine-tuned from Mistral and LLaMA2 through continual pre-training,
instruction tuning, and reinforcement learning from human and AI feedback. Our
models outperform existing open medical LLMs models by a large-margin, even
surpassing models with 70B parameters. Through Hippocrates, we aspire to unlock
the full potential of LLMs not just to advance medical knowledge and patient
care but also to democratize the benefits of AI research in healthcare, making
them available across the globe.

摘要：大型語言模型 (LLM) 與醫療保健的整合承諾將轉化醫療診斷、研究和患者照護。然而，醫療 LLM 的進程面臨複雜的訓練需求、嚴格的評估需求以及限制學術探索的專有模式等障礙。透明、全面的 LLM 資源取得對於推進該領域、促進可複製性以及鼓勵醫療保健 AI 的創新至關重要。我們提出 Hippocrates，一個專門為醫療領域開發的開源 LLM 框架。與之前的努力截然不同，它提供對其訓練資料集、程式碼庫、檢查點和評估協定的不受限制的存取。這種開放的方法旨在激勵協作研究，讓社群能夠在一個透明的生態系統中建構、優化和嚴格評估醫療 LLM。此外，我們介紹 Hippo，一個針對醫療領域量身打造的 7B 模型家族，透過持續預訓練、指令調整以及來自人類和 AI 回饋的強化學習，從 Mistral 和 LLaMA2 中微調。我們的模型比現有的開放醫療 LLM 模型優異許多，甚至超越具有 70B 參數的模型。透過 Hippocrates，我們渴望釋放 LLM 的全部潛力，不僅推動醫療知識和患者照護，也民主化醫療保健中 AI 研究的優點，讓它們在全球各地都能取得。

##### **SFMViT: SlowFast Meet ViT in Chaotic World**
2404.16609v1 by Jiaying Lin,Jiajun Wen,Mengyuan Liu,Jinfu Liu,Baiqiao Yin,Yue Li

The task of spatiotemporal action localization in chaotic scenes is a
challenging task toward advanced video understanding. Paving the way with
high-quality video feature extraction and enhancing the precision of
detector-predicted anchors can effectively improve model performance. To this
end, we propose a high-performance dual-stream spatiotemporal feature
extraction network SFMViT with an anchor pruning strategy. The backbone of our
SFMViT is composed of ViT and SlowFast with prior knowledge of spatiotemporal
action localization, which fully utilizes ViT's excellent global feature
extraction capabilities and SlowFast's spatiotemporal sequence modeling
capabilities. Secondly, we introduce the confidence maximum heap to prune the
anchors detected in each frame of the picture to filter out the effective
anchors. These designs enable our SFMViT to achieve a mAP of 26.62% in the
Chaotic World dataset, far exceeding existing models. Code is available at
https://github.com/jfightyr/SlowFast-Meet-ViT.

摘要：在混乱场景中进行时空动作定位的任务是朝着高级视频理解迈进的具有挑战性的任务。通过高质量视频特征提取和增强检测器预测锚点的精度，可以有效地提高模型性能。为此，我们提出了一种具有锚点剪枝策略的高性能双流时空特征提取网络 SFMViT。我们的 SFMViT 的主干由 ViT 和 SlowFast 组成，具有时空动作定位的先验知识，充分利用了 ViT 出色的全局特征提取能力和 SlowFast 的时空序列建模能力。其次，我们引入置信度最大堆来剪除图片中每帧中检测到的锚点，以滤除有效的锚点。这些设计使我们的 SFMViT 在 Chaotic World 数据集中实现了 26.62% 的 mAP，远远超过现有模型。代码可在 https://github.com/jfightyr/SlowFast-Meet-ViT 获得。

##### **Understanding Privacy Risks of Embeddings Induced by Large Language Models**
2404.16587v1 by Zhihao Zhu,Ninglu Shao,Defu Lian,Chenwang Wu,Zheng Liu,Yi Yang,Enhong Chen

Large language models (LLMs) show early signs of artificial general
intelligence but struggle with hallucinations. One promising solution to
mitigate these hallucinations is to store external knowledge as embeddings,
aiding LLMs in retrieval-augmented generation. However, such a solution risks
compromising privacy, as recent studies experimentally showed that the original
text can be partially reconstructed from text embeddings by pre-trained
language models. The significant advantage of LLMs over traditional pre-trained
models may exacerbate these concerns. To this end, we investigate the
effectiveness of reconstructing original knowledge and predicting entity
attributes from these embeddings when LLMs are employed. Empirical findings
indicate that LLMs significantly improve the accuracy of two evaluated tasks
over those from pre-trained models, regardless of whether the texts are
in-distribution or out-of-distribution. This underscores a heightened potential
for LLMs to jeopardize user privacy, highlighting the negative consequences of
their widespread use. We further discuss preliminary strategies to mitigate
this risk.

摘要：大型語言模型（LLM）展現出人工通用智慧的早期跡象，但仍受幻覺困擾。一個有望解決這些幻覺的方法是將外部知識儲存為嵌入，協助 LLM 進行檢索增強生成。然而，這種解決方案有損害隱私的風險，因為最近的研究透過實驗顯示，預先訓練的語言模型可以從文字嵌入中部分重建原始文字。LLM 相較於傳統預先訓練模型的顯著優勢可能會加劇這些疑慮。為此，我們探討在使用 LLM 時，從這些嵌入中重建原始知識和預測實體屬性的有效性。實證結果顯示，無論文字是否在分佈內或分佈外，LLM 都能顯著提升兩個評估任務的準確度，優於預先訓練模型。這強調了 LLM 危害使用者隱私的潛力，凸顯其廣泛使用所帶來的負面後果。我們進一步討論減輕此風險的初步策略。

##### **Neural Interaction Energy for Multi-Agent Trajectory Prediction**
2404.16579v1 by Kaixin Shen,Ruijie Quan,Linchao Zhu,Jun Xiao,Yi Yang

Maintaining temporal stability is crucial in multi-agent trajectory
prediction. Insufficient regularization to uphold this stability often results
in fluctuations in kinematic states, leading to inconsistent predictions and
the amplification of errors. In this study, we introduce a framework called
Multi-Agent Trajectory prediction via neural interaction Energy (MATE). This
framework assesses the interactive motion of agents by employing neural
interaction energy, which captures the dynamics of interactions and illustrates
their influence on the future trajectories of agents. To bolster temporal
stability, we introduce two constraints: inter-agent interaction constraint and
intra-agent motion constraint. These constraints work together to ensure
temporal stability at both the system and agent levels, effectively mitigating
prediction fluctuations inherent in multi-agent systems. Comparative
evaluations against previous methods on four diverse datasets highlight the
superior prediction accuracy and generalization capabilities of our model.

摘要：在多智能體軌跡預測中，維持時間穩定性至關重要。不足夠的正則化來維持此穩定性通常會導致運動狀態波動，進而導致預測不一致和錯誤放大。在此研究中，我們引入了一個名為神經互動能量多智能體軌跡預測 (MATE) 的框架。此框架透過採用神經互動能量來評估智能體的互動運動，這種能量捕捉了互動的動態，並說明了它們對智能體未來軌跡的影響。為了加強時間穩定性，我們引入了兩個約束：智能體間互動約束和智能體內運動約束。這些約束共同作用，以確保系統和智能體層面的時間穩定性，有效減輕了多智能體系統中固有的預測波動。針對四個不同資料集與先前方法進行的比較評估突顯了我們模型的優異預測準確性和泛化能力。

##### **Exploring Internal Numeracy in Language Models: A Case Study on ALBERT**
2404.16574v1 by Ulme Wennberg,Gustav Eje Henter

It has been found that Transformer-based language models have the ability to
perform basic quantitative reasoning. In this paper, we propose a method for
studying how these models internally represent numerical data, and use our
proposal to analyze the ALBERT family of language models. Specifically, we
extract the learned embeddings these models use to represent tokens that
correspond to numbers and ordinals, and subject these embeddings to Principal
Component Analysis (PCA). PCA results reveal that ALBERT models of different
sizes, trained and initialized separately, consistently learn to use the axes
of greatest variation to represent the approximate ordering of various
numerical concepts. Numerals and their textual counterparts are represented in
separate clusters, but increase along the same direction in 2D space. Our
findings illustrate that language models, trained purely to model text, can
intuit basic mathematical concepts, opening avenues for NLP applications that
intersect with quantitative reasoning.

摘要：研究發現，基於 Transformer 的語言模型具有執行基本數量推理的能力。在本文中，我們提出了一種方法來研究這些模型在內部如何表示數字資料，並使用我們的提案來分析 ALBERT 語言模型家族。具體來說，我們提取這些模型用來表示對應於數字和序數的記號的已學習嵌入，並對這些嵌入進行主成分分析 (PCA)。PCA 結果顯示，不同大小的 ALBERT 模型，分別訓練和初始化，始終學會使用最大變異的軸來表示各種數學概念的近似排序。數字及其文字對應物以分開的群集表示，但在 2D 空間中沿著相同的方向增加。我們的發現說明了純粹訓練來建模文字的語言模型可以直覺理解基本的數學概念，為與數量推理相交的 NLP 應用開啟了途徑。

##### **Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark**
2404.16563v1 by Elizabeth Fons,Rachneet Kaur,Soham Palande,Zhen Zeng,Svitlana Vyetrenko,Tucker Balch

Large Language Models (LLMs) offer the potential for automatic time series
analysis and reporting, which is a critical task across many domains, spanning
healthcare, finance, climate, energy, and many more. In this paper, we propose
a framework for rigorously evaluating the capabilities of LLMs on time series
understanding, encompassing both univariate and multivariate forms. We
introduce a comprehensive taxonomy of time series features, a critical
framework that delineates various characteristics inherent in time series data.
Leveraging this taxonomy, we have systematically designed and synthesized a
diverse dataset of time series, embodying the different outlined features. This
dataset acts as a solid foundation for assessing the proficiency of LLMs in
comprehending time series. Our experiments shed light on the strengths and
limitations of state-of-the-art LLMs in time series understanding, revealing
which features these models readily comprehend effectively and where they
falter. In addition, we uncover the sensitivity of LLMs to factors including
the formatting of the data, the position of points queried within a series and
the overall time series length.

摘要：大型語言模型 (LLM) 提供了自動時間序列分析和報告的潛力，這是一項跨越醫療保健、金融、氣候、能源等許多領域的關鍵任務。在本文中，我們提出了一個框架，用於嚴格評估 LLM 在時間序列理解上的能力，包括單變量和多變量形式。我們引入了時間序列特徵的全面分類法，這是一個關鍵框架，它描述了時間序列數據中固有的各種特徵。利用這個分類法，我們系統地設計並綜合了一個時間序列的多樣化數據集，體現了不同的概述特徵。這個數據集作為評估 LLM 在理解時間序列方面的熟練程度的堅實基礎。我們的實驗闡明了最先進的 LLM 在時間序列理解方面的優勢和局限性，揭示了這些模型哪些特徵可以輕鬆有效地理解，以及它們在哪裡失敗。此外，我們發現 LLM 對以下因素的敏感性：數據的格式、序列中查詢點的位置和整體時間序列長度。

##### **Evolve Cost-aware Acquisition Functions Using Large Language Models**
2404.16906v1 by Yiming Yao,Fei Liu,Ji Cheng,Qingfu Zhang

Many real-world optimization scenarios involve expensive evaluation with
unknown and heterogeneous costs. Cost-aware Bayesian optimization stands out as
a prominent solution in addressing these challenges. To approach the global
optimum within a limited budget in a cost-efficient manner, the design of
cost-aware acquisition functions (AFs) becomes a crucial step. However,
traditional manual design paradigm typically requires extensive domain
knowledge and involves a labor-intensive trial-and-error process. This paper
introduces EvolCAF, a novel framework that integrates large language models
(LLMs) with evolutionary computation (EC) to automatically design cost-aware
AFs. Leveraging the crossover and mutation in the algorithm space, EvolCAF
offers a novel design paradigm, significantly reduces the reliance on domain
expertise and model training. The designed cost-aware AF maximizes the
utilization of available information from historical data, surrogate models and
budget details. It introduces novel ideas not previously explored in the
existing literature on acquisition function design, allowing for clear
interpretations to provide insights into its behavior and decision-making
process. In comparison to the well-known EIpu and EI-cool methods designed by
human experts, our approach showcases remarkable efficiency and generalization
across various tasks, including 12 synthetic problems and 3 real-world
hyperparameter tuning test sets.

摘要：許多真實世界的最佳化情境都涉及昂貴的評估以及未知且異質的成本。成本感知貝氏最佳化在解決這些挑戰中脫穎而出，成為一個重要的解決方案。為了在有限的預算內以經濟有效的方式接近全域最佳化，成本感知取得函數 (AF) 的設計成為一個關鍵步驟。然而，傳統的人工設計範例通常需要廣泛的領域知識，並涉及勞力密集的試錯過程。這篇論文介紹了 EvolCAF，一個整合大型語言模型 (LLM) 與演化計算 (EC) 的新穎架構，用於自動設計成本感知 AF。透過利用演算法空間中的交叉和突變，EvolCAF 提供了一個新穎的設計範例，大幅降低了對領域專業知識和模型訓練的依賴。所設計的成本感知 AF 將來自歷史資料、代理模型和預算明細的可用資訊使用最大化。它引入了先前在取得函數設計現有文獻中未曾探討過的新穎概念，允許明確的詮釋，以提供對其行為和決策制定過程的見解。與由人類專家設計的知名 EIpu 和 EI-cool 方法相比，我們的做法在各種任務中展現了顯著的效率和概化能力，包括 12 個合成問題和 3 個真實世界的超參數調整測試集。

##### **DeepKalPose: An Enhanced Deep-Learning Kalman Filter for Temporally Consistent Monocular Vehicle Pose Estimation**
2404.16558v1 by Leandro Di Bella,Yangxintong Lyu,Adrian Munteanu

This paper presents DeepKalPose, a novel approach for enhancing temporal
consistency in monocular vehicle pose estimation applied on video through a
deep-learning-based Kalman Filter. By integrating a Bi-directional Kalman
filter strategy utilizing forward and backward time-series processing, combined
with a learnable motion model to represent complex motion patterns, our method
significantly improves pose accuracy and robustness across various conditions,
particularly for occluded or distant vehicles. Experimental validation on the
KITTI dataset confirms that DeepKalPose outperforms existing methods in both
pose accuracy and temporal consistency.

摘要：本文提出了 DeepKalPose，這是一種新穎的方法，可透過基於深度學習的卡爾曼濾波器，在影片中應用於單眼車輛位姿估計，以增強時間一致性。透過整合利用正向和反向時間序列處理的雙向卡爾曼濾波器策略，並結合可學習的運動模型來表示複雜的運動模式，我們的技術大幅提升了各種條件下的位姿準確度和穩健性，特別是對於被遮擋或距離較遠的車輛。在 KITTI 資料集上的實驗驗證證實，DeepKalPose 在位姿準確度和時間一致性方面都優於現有方法。

##### **Energy-Latency Manipulation of Multi-modal Large Language Models via Verbose Samples**
2404.16557v1 by Kuofeng Gao,Jindong Gu,Yang Bai,Shu-Tao Xia,Philip Torr,Wei Liu,Zhifeng Li

Despite the exceptional performance of multi-modal large language models
(MLLMs), their deployment requires substantial computational resources. Once
malicious users induce high energy consumption and latency time (energy-latency
cost), it will exhaust computational resources and harm availability of
service. In this paper, we investigate this vulnerability for MLLMs,
particularly image-based and video-based ones, and aim to induce high
energy-latency cost during inference by crafting an imperceptible perturbation.
We find that high energy-latency cost can be manipulated by maximizing the
length of generated sequences, which motivates us to propose verbose samples,
including verbose images and videos. Concretely, two modality non-specific
losses are proposed, including a loss to delay end-of-sequence (EOS) token and
an uncertainty loss to increase the uncertainty over each generated token. In
addition, improving diversity is important to encourage longer responses by
increasing the complexity, which inspires the following modality specific loss.
For verbose images, a token diversity loss is proposed to promote diverse
hidden states. For verbose videos, a frame feature diversity loss is proposed
to increase the feature diversity among frames. To balance these losses, we
propose a temporal weight adjustment algorithm. Experiments demonstrate that
our verbose samples can largely extend the length of generated sequences.

摘要：儘管多模態大型語言模型 (MLLM) 具有卓越的效能，但其部署需要大量的運算資源。一旦惡意使用者造成高耗能和延遲時間（耗能延遲成本），將會耗盡運算資源並損害服務的可用性。在本文中，我們探討 MLLM 的此一漏洞，特別是基於影像和基於影片的 MLLM，並旨在透過製作難以察覺的擾動來造成高耗能延遲成本。我們發現，高耗能延遲成本可以透過最大化生成序列的長度來操縱，這促使我們提出冗長的範例，包括冗長的影像和影片。具體來說，提出了兩種非特定於模態的損失，包括延遲序列結束 (EOS) 標記的損失，以及增加每個生成標記的不確定性的不確定性損失。此外，改善多樣性對於透過增加複雜度來鼓勵更長的回應非常重要，這啟發了以下特定於模態的損失。對於冗長的影像，提出了標記多樣性損失以促進多樣化的隱藏狀態。對於冗長的影片，提出了幀特徵多樣性損失以增加幀之間的特徵多樣性。為了平衡這些損失，我們提出了一個時間權重調整演算法。實驗證明，我們的冗長範例可以在很大程度上延伸生成序列的長度。

##### **Developing Acoustic Models for Automatic Speech Recognition in Swedish**
2404.16547v1 by Giampiero Salvi

This paper is concerned with automatic continuous speech recognition using
trainable systems. The aim of this work is to build acoustic models for spoken
Swedish. This is done employing hidden Markov models and using the SpeechDat
database to train their parameters. Acoustic modeling has been worked out at a
phonetic level, allowing general speech recognition applications, even though a
simplified task (digits and natural number recognition) has been considered for
model evaluation. Different kinds of phone models have been tested, including
context independent models and two variations of context dependent models.
Furthermore many experiments have been done with bigram language models to tune
some of the system parameters. System performance over various speaker subsets
with different sex, age and dialect has also been examined. Results are
compared to previous similar studies showing a remarkable improvement.

摘要：本文關注使用可訓練系統進行自動連續語音辨識。這項工作的目標是為瑞典語口語建立聲學模型。這項工作採用隱馬可夫模型，並使用 SpeechDat 資料庫來訓練模型參數。聲學建模已在音標層級進行，允許一般語音辨識應用程式，即使已經考慮到簡化任務（數字和自然數字辨識）來進行模型評估。已經測試了不同類型的音素模型，包括與語境無關的模型和兩種與語境相關的模型變異。此外，已經使用二元語言模型進行許多實驗來調整部分系統參數。也已經檢查了具有不同性別、年齡和方言的各種說話者子集的系統效能。將結果與先前的類似研究進行比較，顯示出顯著的進步。

##### **Samsung Research China-Beijing at SemEval-2024 Task 3: A multi-stage framework for Emotion-Cause Pair Extraction in Conversations**
2404.16905v1 by Shen Zhang,Haojie Zhang,Jing Zhang,Xudong Zhang,Yimeng Zhuang,Jinting Wu

In human-computer interaction, it is crucial for agents to respond to human
by understanding their emotions. Unraveling the causes of emotions is more
challenging. A new task named Multimodal Emotion-Cause Pair Extraction in
Conversations is responsible for recognizing emotion and identifying causal
expressions. In this study, we propose a multi-stage framework to generate
emotion and extract the emotion causal pairs given the target emotion. In the
first stage, Llama-2-based InstructERC is utilized to extract the emotion
category of each utterance in a conversation. After emotion recognition, a
two-stream attention model is employed to extract the emotion causal pairs
given the target emotion for subtask 2 while MuTEC is employed to extract
causal span for subtask 1. Our approach achieved first place for both of the
two subtasks in the competition.

摘要：在人機互動中，代理必須透過理解人類的情緒來回應人類。釐清情緒的原因更具挑戰性。一項名為對話中多模態情緒原因對提取的新任務負責辨識情緒並找出因果表達。在本研究中，我們提出一個多階段架構來產生情緒並提取給定目標情緒的情緒因果對。在第一階段，使用基於 Llama-2 的 InstructERC 來提取對話中每個發言的情緒類別。在情緒辨識後，採用雙流注意力模型來提取給定子任務 2 的目標情緒的情緒因果對，而 MuTEC 則用於提取子任務 1 的因果區間。我們的做法在競賽中兩個子任務中都獲得第一名。

##### **SIDEs: Separating Idealization from Deceptive Explanations in xAI**
2404.16534v1 by Emily Sullivan

Explainable AI (xAI) methods are important for establishing trust in using
black-box models. However, recent criticism has mounted against current xAI
methods that they disagree, are necessarily false, and can be manipulated,
which has started to undermine the deployment of black-box models. Rudin (2019)
goes so far as to say that we should stop using black-box models altogether in
high-stakes cases because xAI explanations "must be wrong". However, strict
fidelity to the truth is historically not a desideratum in science.
Idealizations -- the intentional distortions introduced to scientific theories
and models -- are commonplace in the natural sciences and are seen as a
successful scientific tool. Thus, it is not falsehood qua falsehood that is the
issue. In this paper, I outline the need for xAI research to engage in
idealization evaluation. Drawing on the use of idealizations in the natural
sciences and philosophy of science, I introduce a novel framework for
evaluating whether xAI methods engage in successful idealizations or deceptive
explanations (SIDEs). SIDEs evaluates whether the limitations of xAI methods,
and the distortions that they introduce, can be part of a successful
idealization or are indeed deceptive distortions as critics suggest. I discuss
the role that existing research can play in idealization evaluation and where
innovation is necessary. Through a qualitative analysis we find that leading
feature importance methods and counterfactual explanations are subject to
idealization failure and suggest remedies for ameliorating idealization
failure.

摘要：<paragraph>可解釋 AI (xAI) 方法對於建立對黑箱模型使用的信任非常重要。然而，最近針對當前 xAI 方法提出了批評，認為它們並不一致、必然是錯誤的，並且可以被操縱，這已開始破壞黑箱模型的部署。Rudin (2019) 甚至表示，我們應該在高風險情況下完全停止使用黑箱模型，因為 xAI 解釋「必定是錯誤的」。然而，嚴格忠於事實並非科學中歷來的理想狀態。理想化——科學理論和模型中引入的故意扭曲——在自然科學中很常見，被視為一種成功的科學工具。因此，問題不在於虛假本身。在本文中，我概述了 xAI 研究參與理想化評估的必要性。借鑒自然科學和科學哲學中對理想化的使用，我引入了一個新的框架，用於評估 xAI 方法是從事成功的理想化還是具有欺騙性的解釋 (SIDE)。SIDE 評估了 xAI 方法的局限性及其引入的扭曲是否可以成為成功理想化的一部分，或者正如批評者所建議的那樣，它們確實是具有欺騙性的扭曲。我討論了現有研究在理想化評估中可以扮演的角色，以及創新在哪裡是必要的。通過定性分析，我們發現領先的特徵重要性方法和反事實解釋容易發生理想化失敗，並提出補救措施來改善理想化失敗。</paragraph>

##### **Global Concept Explanations for Graphs by Contrastive Learning**
2404.16532v1 by Jonas Teufel,Pascal Friederich

Beyond improving trust and validating model fairness, xAI practices also have
the potential to recover valuable scientific insights in application domains
where little to no prior human intuition exists. To that end, we propose a
method to extract global concept explanations from the predictions of graph
neural networks to develop a deeper understanding of the tasks underlying
structure-property relationships. We identify concept explanations as dense
clusters in the self-explaining Megan models subgraph latent space. For each
concept, we optimize a representative prototype graph and optionally use GPT-4
to provide hypotheses about why each structure has a certain effect on the
prediction. We conduct computational experiments on synthetic and real-world
graph property prediction tasks. For the synthetic tasks we find that our
method correctly reproduces the structural rules by which they were created.
For real-world molecular property regression and classification tasks, we find
that our method rediscovers established rules of thumb. More specifically, our
results for molecular mutagenicity prediction indicate more fine-grained
resolution of structural details than existing explainability methods,
consistent with previous results from chemistry literature. Overall, our
results show promising capability to extract the underlying structure-property
relationships for complex graph property prediction tasks.

摘要：除了提升信任度和验证模型公平性之外，xAI 实践也有可能在应用领域中恢复有价值的科学见解，在这些领域中几乎没有或完全没有先验的人类直觉。为此，我们提出了一种从图神经网络的预测中提取全局概念解释的方法，以更深入地了解结构属性关系背后的任务。我们将概念解释识别为自解释 Megan 模型子图潜在空间中的密集簇。对于每个概念，我们优化一个具有代表性的原型图，并选择性地使用 GPT-4 来提供关于为什么每个结构对预测产生一定影响的假设。我们在合成和实际图属性预测任务上进行计算实验。对于合成任务，我们发现我们的方法正确地再现了创建它们的结构规则。对于实际分子属性回归和分类任务，我们发现我们的方法重新发现了已建立的经验法则。更具体地说，我们的分子致突变性预测结果表明，与化学文献中的先前结果一致，结构细节的分辨率比现有可解释性方法更精细。总体而言，我们的结果显示出从复杂的图属性预测任务中提取底层结构属性关系的有希望的能力。

##### **Building a Japanese Document-Level Relation Extraction Dataset Assisted by Cross-Lingual Transfer**
2404.16506v1 by Youmi Ma,An Wang,Naoaki Okazaki

Document-level Relation Extraction (DocRE) is the task of extracting all
semantic relationships from a document. While studies have been conducted on
English DocRE, limited attention has been given to DocRE in non-English
languages. This work delves into effectively utilizing existing English
resources to promote DocRE studies in non-English languages, with Japanese as
the representative case. As an initial attempt, we construct a dataset by
transferring an English dataset to Japanese. However, models trained on such a
dataset suffer from low recalls. We investigate the error cases and attribute
the failure to different surface structures and semantics of documents
translated from English and those written by native speakers. We thus switch to
explore if the transferred dataset can assist human annotation on Japanese
documents. In our proposal, annotators edit relation predictions from a model
trained on the transferred dataset. Quantitative analysis shows that relation
recommendations suggested by the model help reduce approximately 50% of the
human edit steps compared with the previous approach. Experiments quantify the
performance of existing DocRE models on our collected dataset, portraying the
challenges of Japanese and cross-lingual DocRE.

摘要：文件級關係萃取 (DocRE) 是從文件中萃取所有語義關係的任務。雖然有研究探討英文的 DocRE，但對於非英文語言的 DocRE 關注較少。這項工作深入探討如何有效利用現有的英文資源，以推廣非英文語言的 DocRE 研究，並以日文為代表性案例。作為初步嘗試，我們透過將英文資料集轉移到日文來建構資料集。然而，在這樣的資料集上訓練的模型召回率很低。我們調查錯誤案例，並將失敗歸因於從英文翻譯的文件與由母語人士撰寫的文件在表面結構和語義上的差異。因此，我們轉而探索轉移的資料集是否可以協助對日文文件進行人工標註。在我們的提案中，標註人員編輯從在轉移資料集上訓練的模型中預測的關係。量化分析顯示，該模型建議的關係建議有助於減少約 50% 的人工編輯步驟，與先前的做法相比有顯著改善。實驗量化了現有 DocRE 模型在我們收集的資料集上的效能，描繪了日文和跨語言 DocRE 的挑戰。

