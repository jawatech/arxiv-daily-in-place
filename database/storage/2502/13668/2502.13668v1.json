{"2502.13668": {"publish_time": "2025-02-19", "title": "PeerQA: A Scientific Question Answering Dataset from Peer Reviews", "paper_summary": "We present PeerQA, a real-world, scientific, document-level Question\nAnswering (QA) dataset. PeerQA questions have been sourced from peer reviews,\nwhich contain questions that reviewers raised while thoroughly examining the\nscientific article. Answers have been annotated by the original authors of each\npaper. The dataset contains 579 QA pairs from 208 academic articles, with a\nmajority from ML and NLP, as well as a subset of other scientific communities\nlike Geoscience and Public Health. PeerQA supports three critical tasks for\ndeveloping practical QA systems: Evidence retrieval, unanswerable question\nclassification, and answer generation. We provide a detailed analysis of the\ncollected dataset and conduct experiments establishing baseline systems for all\nthree tasks. Our experiments and analyses reveal the need for\ndecontextualization in document-level retrieval, where we find that even simple\ndecontextualization approaches consistently improve retrieval performance\nacross architectures. On answer generation, PeerQA serves as a challenging\nbenchmark for long-context modeling, as the papers have an average size of 12k\ntokens. Our code and data is available at https://github.com/UKPLab/peerqa.", "paper_summary_zh": "<paragraph>\u6211\u5011\u63d0\u51fa PeerQA\uff0c\u4e00\u500b\u771f\u5be6\u4e16\u754c\u3001\u79d1\u5b78\u7684\u3001\u6587\u4ef6\u5c64\u7d1a\u7684\u554f\u7b54 (QA) \u8cc7\u6599\u96c6\u3002PeerQA \u554f\u984c\u4f86\u81ea\u65bc\u540c\u884c\u8a55\u5be9\uff0c\u5176\u4e2d\u5305\u542b\u5be9\u67e5\u8005\u5728\u5fb9\u5e95\u5be9\u67e5\u79d1\u5b78\u6587\u7ae0\u6642\u63d0\u51fa\u7684\u554f\u984c\u3002\u7b54\u6848\u662f\u7531\u6bcf\u7bc7\u8ad6\u6587\u7684\u539f\u59cb\u4f5c\u8005\u8a3b\u89e3\u7684\u3002\u6b64\u8cc7\u6599\u96c6\u5305\u542b\u4f86\u81ea 208 \u7bc7\u5b78\u8853\u6587\u7ae0\u7684 579 \u500b QA \u5c0d\uff0c\u5176\u4e2d\u5927\u90e8\u5206\u4f86\u81ea ML \u548c NLP\uff0c\u4ee5\u53ca\u5176\u4ed6\u79d1\u5b78\u793e\u7fa4\uff08\u4f8b\u5982\u5730\u7403\u79d1\u5b78\u548c\u516c\u5171\u885b\u751f\uff09\u7684\u5b50\u96c6\u3002PeerQA \u652f\u63f4\u958b\u767c\u5be6\u7528 QA \u7cfb\u7d71\u7684\u4e09\u9805\u91cd\u8981\u4efb\u52d9\uff1a\u8b49\u64da\u6aa2\u7d22\u3001\u7121\u89e3\u7b54\u554f\u984c\u5206\u985e\u548c\u7b54\u6848\u7522\u751f\u3002\u6211\u5011\u63d0\u4f9b\u6536\u96c6\u5230\u7684\u8cc7\u6599\u96c6\u7684\u8a73\u7d30\u5206\u6790\uff0c\u4e26\u9032\u884c\u5be6\u9a57\uff0c\u70ba\u6240\u6709\u4e09\u9805\u4efb\u52d9\u5efa\u7acb\u57fa\u6e96\u7cfb\u7d71\u3002\u6211\u5011\u7684\u5be6\u9a57\u548c\u5206\u6790\u63ed\u793a\u4e86\u5728\u6587\u4ef6\u5c64\u7d1a\u6aa2\u7d22\u4e2d\u53bb\u8108\u7d61\u5316\u7684\u5fc5\u8981\u6027\uff0c\u6211\u5011\u767c\u73fe\u5373\u4f7f\u662f\u7c21\u55ae\u7684\u53bb\u8108\u7d61\u5316\u65b9\u6cd5\u4e5f\u80fd\u6301\u7e8c\u6539\u5584\u8de8\u67b6\u69cb\u7684\u6aa2\u7d22\u6548\u80fd\u3002\u5728\u7b54\u6848\u7522\u751f\u65b9\u9762\uff0cPeerQA \u662f\u4e00\u500b\u7528\u65bc\u9577\u8108\u7d61\u5efa\u6a21\u7684\u5177\u6311\u6230\u6027\u57fa\u6e96\uff0c\u56e0\u70ba\u8ad6\u6587\u7684\u5e73\u5747\u5927\u5c0f\u70ba 12k \u500b\u7b26\u865f\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u548c\u8cc7\u6599\u53ef\u65bc https://github.com/UKPLab/peerqa \u53d6\u5f97\u3002</paragraph>", "author": "Tim Baumg\u00e4rtner et.al.", "authors": "Tim Baumg\u00e4rtner, Ted Briscoe, Iryna Gurevych", "id": "2502.13668v1", "paper_url": "http://arxiv.org/abs/2502.13668v1", "repo": "null"}}