
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-18**|**Latent Causal Probing: A Formal Perspective on Probing with Causal Models of Data**|Charles Jin et.al.|[2407.13765v1](http://arxiv.org/abs/2407.13765v1)|null|
|**2024-07-18**|**Neural Network Tire Force Modeling for Automated Drifting**|Nicholas Drake Broadbent et.al.|[2407.13760v1](http://arxiv.org/abs/2407.13760v1)|null|
|**2024-07-18**|**Black-Box Opinion Manipulation Attacks to Retrieval-Augmented Generation of Large Language Models**|Zhuo Chen et.al.|[2407.13757v1](http://arxiv.org/abs/2407.13757v1)|null|
|**2024-07-18**|**LLMs as Function Approximators: Terminology, Taxonomy, and Questions for Evaluation**|David Schlangen et.al.|[2407.13744v1](http://arxiv.org/abs/2407.13744v1)|null|
|**2024-07-18**|**CellularLint: A Systematic Approach to Identify Inconsistent Behavior in Cellular Network Specifications**|Mirza Masfiqur Rahman et.al.|[2407.13742v1](http://arxiv.org/abs/2407.13742v1)|null|
|**2024-07-18**|**Scaling Granite Code Models to 128K Context**|Matt Stallone et.al.|[2407.13739v1](http://arxiv.org/abs/2407.13739v1)|null|
|**2024-07-18**|**Understanding Reinforcement Learning-Based Fine-Tuning of Diffusion Models: A Tutorial and Review**|Masatoshi Uehara et.al.|[2407.13734v1](http://arxiv.org/abs/2407.13734v1)|null|
|**2024-07-18**|**Baba Is AI: Break the Rules to Beat the Benchmark**|Nathan Cloos et.al.|[2407.13729v1](http://arxiv.org/abs/2407.13729v1)|null|
|**2024-07-18**|**CoDefeater: Using LLMs To Find Defeaters in Assurance Cases**|Usman Gohar et.al.|[2407.13717v1](http://arxiv.org/abs/2407.13717v1)|null|
|**2024-07-18**|**FSP-Laplace: Function-Space Priors for the Laplace Approximation in Bayesian Deep Learning**|Tristan Cinquin et.al.|[2407.13711v1](http://arxiv.org/abs/2407.13711v1)|null|
|**2024-07-18**|**Understanding Reference Policies in Direct Preference Optimization**|Yixin Liu et.al.|[2407.13709v1](http://arxiv.org/abs/2407.13709v1)|null|
|**2024-07-18**|**ANHALTEN: Cross-Lingual Transfer for German Token-Level Reference-Free Hallucination Detection**|Janek Herrlein et.al.|[2407.13702v1](http://arxiv.org/abs/2407.13702v1)|[link](https://github.com/janekh24/anhalten)|
|**2024-07-18**|**Cross-Task Attack: A Self-Supervision Generative Framework Based on Attention Shift**|Qingyuan Zeng et.al.|[2407.13700v1](http://arxiv.org/abs/2407.13700v1)|null|
|**2024-07-18**|**A Comprehensive Review of Recommender Systems: Transitioning from Theory to Practice**|Shaina Raza et.al.|[2407.13699v1](http://arxiv.org/abs/2407.13699v1)|null|
|**2024-07-18**|**Benchmark Agreement Testing Done Right: A Guide for LLM Benchmark Evaluation**|Yotam Perlitz et.al.|[2407.13696v1](http://arxiv.org/abs/2407.13696v1)|[link](https://github.com/ibm/benchbench)|
|**2024-07-18**|**Prover-Verifier Games improve legibility of LLM outputs**|Jan Hendrik Kirchner et.al.|[2407.13692v1](http://arxiv.org/abs/2407.13692v1)|null|
|**2024-07-18**|**Shaded Route Planning Using Active Segmentation and Identification of Satellite Images**|Longchao Da et.al.|[2407.13689v1](http://arxiv.org/abs/2407.13689v1)|null|
|**2024-07-18**|**HPix: Generating Vector Maps from Satellite Images**|Aditya Taparia et.al.|[2407.13680v1](http://arxiv.org/abs/2407.13680v1)|[link](https://github.com/aditya-taparia/Satellite-Image-to-Vector-Map)|
|**2024-07-18**|**PASTA: Controllable Part-Aware Shape Generation with Autoregressive Transformers**|Songlin Li et.al.|[2407.13677v1](http://arxiv.org/abs/2407.13677v1)|null|
|**2024-07-18**|**FuLG: 150B Romanian Corpus for Language Model Pretraining**|Vlad-Andrei Bădoiu et.al.|[2407.13657v1](http://arxiv.org/abs/2407.13657v1)|null|
|**2024-07-18**|**Weak-to-Strong Reasoning**|Yuqing Yang et.al.|[2407.13647v1](http://arxiv.org/abs/2407.13647v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|null|
|**2024-07-18**|**Scaling Laws with Vocabulary: Larger Models Deserve Larger Vocabularies**|Chaofan Tao et.al.|[2407.13623v1](http://arxiv.org/abs/2407.13623v1)|null|
|**2024-07-18**|**Differential Privacy Mechanisms in Neural Tangent Kernel Regression**|Jiuxiang Gu et.al.|[2407.13621v1](http://arxiv.org/abs/2407.13621v1)|null|
|**2024-07-18**|**Training-free Composite Scene Generation for Layout-to-Image Synthesis**|Jiaqi Liu et.al.|[2407.13609v1](http://arxiv.org/abs/2407.13609v1)|null|
|**2024-07-18**|**dzNLP at NADI 2024 Shared Task: Multi-Classifier Ensemble with Weighted Voting and TF-IDF Features**|Mohamed Lichouri et.al.|[2407.13608v1](http://arxiv.org/abs/2407.13608v1)|null|
|**2024-07-18**|**dzStance at StanceEval2024: Arabic Stance Detection based on Sentence Transformers**|Mohamed Lichouri et.al.|[2407.13603v1](http://arxiv.org/abs/2407.13603v1)|null|
|**2024-07-18**|**PLANTS: A Novel Problem and Dataset for Summarization of Planning-Like (PL) Tasks**|Vishal Pallagani et.al.|[2407.13597v1](http://arxiv.org/abs/2407.13597v1)|null|
|**2024-07-18**|**Towards Zero-Shot Multimodal Machine Translation**|Matthieu Futeral et.al.|[2407.13579v1](http://arxiv.org/abs/2407.13579v1)|null|
|**2024-07-18**|**Large Language Models as Reliable Knowledge Bases?**|Danna Zheng et.al.|[2407.13578v1](http://arxiv.org/abs/2407.13578v1)|null|
|**2024-07-18**|**dzFinNlp at AraFinNLP: Improving Intent Detection in Financial Conversational Agents**|Mohamed Lichouri et.al.|[2407.13565v1](http://arxiv.org/abs/2407.13565v1)|null|
|**2024-07-18**|**Research on Tibetan Tourism Viewpoints information generation system based on LLM**|Jinhu Qi et.al.|[2407.13561v1](http://arxiv.org/abs/2407.13561v1)|null|
|**2024-07-18**|**Qalam : A Multimodal LLM for Arabic Optical Character and Handwriting Recognition**|Gagan Bhatia et.al.|[2407.13559v1](http://arxiv.org/abs/2407.13559v1)|null|
|**2024-07-18**|**Enhancing Source-Free Domain Adaptive Object Detection with Low-confidence Pseudo Label Distillation**|Ilhoon Yoon et.al.|[2407.13524v1](http://arxiv.org/abs/2407.13524v1)|null|
|**2024-07-18**|**Can Open-Source LLMs Compete with Commercial Models? Exploring the Few-Shot Performance of Current GPT Models in Biomedical Tasks**|Samy Ateia et.al.|[2407.13511v1](http://arxiv.org/abs/2407.13511v1)|null|
|**2024-07-18**|**Spontaneous Style Text-to-Speech Synthesis with Controllable Spontaneous Behaviors Based on Language Models**|Weiqin Li et.al.|[2407.13509v1](http://arxiv.org/abs/2407.13509v1)|null|
|**2024-07-18**|**Robots Can Multitask Too: Integrating a Memory Architecture and LLMs for Enhanced Cross-Task Robot Action Generation**|Hassan Ali et.al.|[2407.13505v1](http://arxiv.org/abs/2407.13505v1)|null|
|**2024-07-18**|**Training Foundation Models as Data Compression: On Information, Model Weights and Copyright Law**|Giorgio Franceschelli et.al.|[2407.13493v1](http://arxiv.org/abs/2407.13493v1)|null|
|**2024-07-18**|**Enhancing Biomedical Knowledge Discovery for Diseases: An End-To-End Open-Source Framework**|Christos Theodoropoulos et.al.|[2407.13492v1](http://arxiv.org/abs/2407.13492v1)|null|
|**2024-07-18**|**Combining Constraint Programming Reasoning with Large Language Model Predictions**|Florian Régin et.al.|[2407.13490v1](http://arxiv.org/abs/2407.13490v1)|null|
|**2024-07-18**|**Attention Overflow: Language Model Input Blur during Long-Context Missing Items Recommendation**|Damien Sileo et.al.|[2407.13481v1](http://arxiv.org/abs/2407.13481v1)|null|
|**2024-07-18**|**Risk-Aware Vehicle Trajectory Prediction Under Safety-Critical Scenarios**|Qingfan Wang et.al.|[2407.13480v1](http://arxiv.org/abs/2407.13480v1)|null|
|**2024-07-18**|**Fixed and Adaptive Simultaneous Machine Translation Strategies Using Adapters**|Abderrahmane Issam et.al.|[2407.13469v1](http://arxiv.org/abs/2407.13469v1)|[link](https://github.com/issam9/adapters-simt)|
|**2024-07-18**|**End-To-End Clinical Trial Matching with Large Language Models**|Dyke Ferber et.al.|[2407.13463v1](http://arxiv.org/abs/2407.13463v1)|null|
|**2024-07-18**|**BEAF: Observing BEfore-AFter Changes to Evaluate Hallucination in Vision-language Models**|Moon Ye-Bin et.al.|[2407.13442v1](http://arxiv.org/abs/2407.13442v1)|null|
|**2024-07-18**|**Reducing Barriers to the Use of Marginalised Music Genres in AI**|Nick Bryan-Kinns et.al.|[2407.13439v1](http://arxiv.org/abs/2407.13439v1)|null|
|**2024-07-18**|**Enhancing Out-of-Vocabulary Performance of Indian TTS Systems for Practical Applications through Low-Effort Data Strategies**|Srija Anand et.al.|[2407.13435v1](http://arxiv.org/abs/2407.13435v1)|null|
|**2024-07-18**|**Improving Out-of-Distribution Generalization of Trajectory Prediction for Autonomous Driving via Polynomial Representations**|Yue Yao et.al.|[2407.13431v1](http://arxiv.org/abs/2407.13431v1)|null|
|**2024-07-18**|**Towards Dynamic Feature Acquisition on Medical Time Series by Maximizing Conditional Mutual Information**|Fedor Sergeev et.al.|[2407.13429v1](http://arxiv.org/abs/2407.13429v1)|null|
|**2024-07-18**|**DeepClair: Utilizing Market Forecasts for Effective Portfolio Selection**|Donghee Choi et.al.|[2407.13427v1](http://arxiv.org/abs/2407.13427v1)|null|
|**2024-07-18**|**From Words to Worlds: Compositionality for Cognitive Architectures**|Ruchira Dhar et.al.|[2407.13419v1](http://arxiv.org/abs/2407.13419v1)|null|
|**2024-07-18**|**DISCOVER: A Data-driven Interactive System for Comprehensive Observation, Visualization, and ExploRation of Human Behaviour**|Dominik Schiller et.al.|[2407.13408v1](http://arxiv.org/abs/2407.13408v1)|null|
|**2024-07-18**|**Correcting the Mythos of KL-Regularization: Direct Alignment without Overparameterization via Chi-squared Preference Optimization**|Audrey Huang et.al.|[2407.13399v1](http://arxiv.org/abs/2407.13399v1)|null|
|**2024-07-18**|**Linear-Complexity Self-Supervised Learning for Speech Processing**|Shucong Zhang et.al.|[2407.13377v1](http://arxiv.org/abs/2407.13377v1)|null|
|**2024-07-18**|**Capturing Style in Author and Document Representation**|Enzo Terreau et.al.|[2407.13358v1](http://arxiv.org/abs/2407.13358v1)|null|
|**2024-07-18**|**Learning-From-Mistakes Prompting for Indigenous Language Translation**|You-Cheng Liao et.al.|[2407.13343v1](http://arxiv.org/abs/2407.13343v1)|null|
|**2024-07-18**|**Why do you cite? An investigation on citation intents and decision-making classification processes**|Lorenzo Paolini et.al.|[2407.13329v1](http://arxiv.org/abs/2407.13329v1)|null|
|**2024-07-18**|**Deep Reinforcement Learning for Multi-Objective Optimization: Enhancing Wind Turbine Energy Generation while Mitigating Noise Emissions**|Martín de Frutos et.al.|[2407.13320v1](http://arxiv.org/abs/2407.13320v1)|null|
|**2024-07-18**|**Sortability of Time Series Data**|Christopher Lohse et.al.|[2407.13313v1](http://arxiv.org/abs/2407.13313v1)|null|
|**2024-07-18**|**CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis**|Junying Chen et.al.|[2407.13301v1](http://arxiv.org/abs/2407.13301v1)|null|
|**2024-07-18**|**Robust ASR Error Correction with Conservative Data Filtering**|Takuma Udagawa et.al.|[2407.13300v1](http://arxiv.org/abs/2407.13300v1)|null|
|**2024-07-18**|**SpeciaLex: A Benchmark for In-Context Specialized Lexicon Learning**|Joseph Marvin Imperial et.al.|[2407.13297v1](http://arxiv.org/abs/2407.13297v1)|null|
|**2024-07-18**|**Low-Resourced Speech Recognition for Iu Mien Language via Weakly-Supervised Phoneme-based Multilingual Pre-training**|Lukuan Dong et.al.|[2407.13292v1](http://arxiv.org/abs/2407.13292v1)|null|
|**2024-07-18**|**Mixture of Experts based Multi-task Supervise Learning from Crowds**|Tao Han et.al.|[2407.13268v1](http://arxiv.org/abs/2407.13268v1)|null|
|**2024-07-18**|**Are Large Language Models Capable of Generating Human-Level Narratives?**|Yufei Tian et.al.|[2407.13248v1](http://arxiv.org/abs/2407.13248v1)|null|
|**2024-07-18**|**PM-LLM-Benchmark: Evaluating Large Language Models on Process Mining Tasks**|Alessandro Berti et.al.|[2407.13244v1](http://arxiv.org/abs/2407.13244v1)|null|
|**2024-07-18**|**NODER: Image Sequence Regression Based on Neural Ordinary Differential Equations**|Hao Bai et.al.|[2407.13241v1](http://arxiv.org/abs/2407.13241v1)|null|
|**2024-07-18**|**LLM-Empowered State Representation for Reinforcement Learning**|Boyuan Wang et.al.|[2407.13237v1](http://arxiv.org/abs/2407.13237v1)|null|
|**2024-07-18**|**Evaluating Large Language Models for Anxiety and Depression Classification using Counseling and Psychotherapy Transcripts**|Junwei Sun et.al.|[2407.13228v1](http://arxiv.org/abs/2407.13228v1)|null|
|**2024-07-18**|**LiNR: Model Based Neural Retrieval on GPUs at LinkedIn**|Fedor Borisyuk et.al.|[2407.13218v1](http://arxiv.org/abs/2407.13218v1)|null|
|**2024-07-18**|**Transformer-based Single-Cell Language Model: A Survey**|Wei Lan et.al.|[2407.13205v1](http://arxiv.org/abs/2407.13205v1)|null|
|**2024-07-18**|**Adaptive Foundation Models for Online Decisions: HyperAgent with Fast Incremental Uncertainty Estimation**|Yingru Li et.al.|[2407.13195v1](http://arxiv.org/abs/2407.13195v1)|null|
|**2024-07-18**|**Robust Multivariate Time Series Forecasting against Intra- and Inter-Series Transitional Shift**|Hui He et.al.|[2407.13194v1](http://arxiv.org/abs/2407.13194v1)|null|
|**2024-07-18**|**Retrieval-Augmented Generation for Natural Language Processing: A Survey**|Shangyu Wu et.al.|[2407.13193v2](http://arxiv.org/abs/2407.13193v2)|null|
|**2024-07-18**|**SpaDiT: Diffusion Transformer for Spatial Gene Expression Prediction using scRNA-seq**|Xiaoyu Li et.al.|[2407.13182v1](http://arxiv.org/abs/2407.13182v1)|null|
|**2024-07-18**|**Unified-EGformer: Exposure Guided Lightweight Transformer for Mixed-Exposure Image Enhancement**|Eashan Adhikarla et.al.|[2407.13170v1](http://arxiv.org/abs/2407.13170v1)|null|
|**2024-07-18**|**SciCode: A Research Coding Benchmark Curated by Scientists**|Minyang Tian et.al.|[2407.13168v1](http://arxiv.org/abs/2407.13168v1)|null|
|**2024-07-18**|**Translate-and-Revise: Boosting Large Language Models for Constrained Translation**|Pengcheng Huang et.al.|[2407.13164v1](http://arxiv.org/abs/2407.13164v1)|null|
|**2024-07-18**|**ROLeR: Effective Reward Shaping in Offline Reinforcement Learning for Recommender Systems**|Yi Zhang et.al.|[2407.13163v1](http://arxiv.org/abs/2407.13163v1)|null|
|**2024-07-18**|**Learning Camouflaged Object Detection from Noisy Pseudo Label**|Jin Zhang et.al.|[2407.13157v1](http://arxiv.org/abs/2407.13157v1)|null|
|**2024-07-18**|**Preset-Voice Matching for Privacy Regulated Speech-to-Speech Translation Systems**|Daniel Platnick et.al.|[2407.13153v1](http://arxiv.org/abs/2407.13153v1)|null|
|**2024-07-18**|**A light-weight and efficient punctuation and word casing prediction model for on-device streaming ASR**|Jian You et.al.|[2407.13142v1](http://arxiv.org/abs/2407.13142v1)|null|
|**2024-07-18**|**MO-EMT-NAS: Multi-Objective Continuous Transfer of Architectural Knowledge Between Tasks from Different Datasets**|Peng Liao et.al.|[2407.13122v1](http://arxiv.org/abs/2407.13122v1)|null|
|**2024-07-18**|**TrialEnroll: Predicting Clinical Trial Enrollment Success with Deep & Cross Network and Large Language Models**|Ling Yue et.al.|[2407.13115v1](http://arxiv.org/abs/2407.13115v1)|null|
|**2024-07-18**|**Multiobjective Vehicle Routing Optimization with Time Windows: A Hybrid Approach Using Deep Reinforcement Learning and NSGA-II**|Rixin Wu et.al.|[2407.13113v1](http://arxiv.org/abs/2407.13113v1)|null|
|**2024-07-18**|**Retrieve, Summarize, Plan: Advancing Multi-hop Question Answering with an Iterative Approach**|Zhouyu Jiang et.al.|[2407.13101v1](http://arxiv.org/abs/2407.13101v1)|null|
|**2024-07-18**|**AlcLaM: Arabic Dialectal Language Model**|Murtadha Ahmed et.al.|[2407.13097v1](http://arxiv.org/abs/2407.13097v1)|[link](https://github.com/amurtadha/alclam)|
|**2024-07-18**|**MetaSumPerceiver: Multimodal Multi-Document Evidence Summarization for Fact-Checking**|Ting-Chih Chen et.al.|[2407.13089v1](http://arxiv.org/abs/2407.13089v1)|null|
|**2024-07-18**|**Enhancing Temporal Action Localization: Advanced S6 Modeling with Recurrent Mechanism**|Sangyoun Lee et.al.|[2407.13078v1](http://arxiv.org/abs/2407.13078v1)|[link](https://github.com/lsy0882/RDFA-S6)|
|**2024-07-18**|**Dynamic Sentiment Analysis with Local Large Language Models using Majority Voting: A Study on Factors Affecting Restaurant Evaluation**|Junichiro Niimi et.al.|[2407.13069v1](http://arxiv.org/abs/2407.13069v1)|null|
|**2024-07-17**|**Establishing Knowledge Preference in Language Models**|Sizhe Zhou et.al.|[2407.13048v1](http://arxiv.org/abs/2407.13048v1)|null|
|**2024-07-17**|**Turkish Delights: a Dataset on Turkish Euphemisms**|Hasan Can Biyik et.al.|[2407.13040v1](http://arxiv.org/abs/2407.13040v1)|[link](https://github.com/hasancanbiyik/turkish_pets)|
|**2024-07-17**|**ColorMAE: Exploring data-independent masking strategies in Masked AutoEncoders**|Carlos Hinojosa et.al.|[2407.13036v1](http://arxiv.org/abs/2407.13036v1)|null|
|**2024-07-17**|**Pre-Trained Foundation Model representations to uncover Breathing patterns in Speech**|Vikramjit Mitra et.al.|[2407.13035v1](http://arxiv.org/abs/2407.13035v1)|null|
|**2024-07-17**|**A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks**|Shubham Vatsal et.al.|[2407.12994v1](http://arxiv.org/abs/2407.12994v1)|null|
|**2024-07-17**|**Retrieval-Enhanced Machine Learning: Synthesis and Opportunities**|To Eun Kim et.al.|[2407.12982v1](http://arxiv.org/abs/2407.12982v1)|null|
|**2024-07-17**|**A Framework for testing Federated Learning algorithms using an edge-like environment**|Felipe Machado Schwanck et.al.|[2407.12980v1](http://arxiv.org/abs/2407.12980v1)|null|
|**2024-07-17**|**Learning Long-Horizon Predictions for Quadrotor Dynamics**|Pratyaksh Prabhav Rao et.al.|[2407.12964v1](http://arxiv.org/abs/2407.12964v1)|null|
|**2024-07-17**|**Beyond the Veil of Similarity: Quantifying Semantic Continuity in Explainable AI**|Qi Huang et.al.|[2407.12950v1](http://arxiv.org/abs/2407.12950v1)|null|
|**2024-07-17**|**Halu-J: Critique-Based Hallucination Judge**|Binjie Wang et.al.|[2407.12943v1](http://arxiv.org/abs/2407.12943v1)|null|

#### Abstracts
##### **Latent Causal Probing: A Formal Perspective on Probing with Causal Models of Data**
2407.13765v1 by Charles Jin

As language models (LMs) deliver increasing performance on a range of NLP
tasks, probing classifiers have become an indispensable technique in the effort
to better understand their inner workings. A typical setup involves (1)
defining an auxiliary task consisting of a dataset of text annotated with
labels, then (2) supervising small classifiers to predict the labels from the
representations of a pretrained LM as it processed the dataset. A high probing
accuracy is interpreted as evidence that the LM has learned to perform the
auxiliary task as an unsupervised byproduct of its original pretraining
objective. Despite the widespread usage of probes, however, the robust design
and analysis of probing experiments remains a challenge. We develop a formal
perspective on probing using structural causal models (SCM). Specifically,
given an SCM which explains the distribution of tokens observed during
training, we frame the central hypothesis as whether the LM has learned to
represent the latent variables of the SCM. Empirically, we extend a recent
study of LMs in the context of a synthetic grid-world navigation task, where
having an exact model of the underlying causal structure allows us to draw
strong inferences from the result of probing experiments. Our techniques
provide robust empirical evidence for the ability of LMs to learn the latent
causal concepts underlying text.

摘要：隨著語言模型 (LM) 在一系列自然語言處理 (NLP) 任務中提供越來越高的效能，探索分類器已成為更深入了解其內部運作的必要技術。典型的設定包括 (1) 定義一項輔助任務，該任務包含標有標籤的文字資料集，然後 (2) 監督小型分類器，以預測預訓練 LM 在處理資料集時表徵的標籤。高的探索準確度被解釋為 LM 已學會執行輔助任務的證據，作為其原始預訓練目標的非監督副產品。然而，儘管廣泛使用探測，但探測實驗的穩健設計和分析仍然是一個挑戰。我們使用結構因果模型 (SCM) 開發了探測的正式觀點。具體來說，給定一個解釋在訓練期間觀察到的代幣分佈的 SCM，我們將中心假設設定為 LM 是否已學會表徵 SCM 的潛在變數。根據經驗，我們擴展了最近在合成網格世界導航任務背景下的 LM 研究，其中擁有基礎因果結構的精確模型使我們能夠從探測實驗的結果中得出強有力的推論。我們的技術為 LM 學習文字背後潛在因果概念的能力提供了穩健的實證證據。

##### **Neural Network Tire Force Modeling for Automated Drifting**
2407.13760v1 by Nicholas Drake Broadbent, Trey Weber, Daiki Mori, J. Christian Gerdes

Automated drifting presents a challenge problem for vehicle control,
requiring models and control algorithms that can precisely handle nonlinear,
coupled tire forces at the friction limits. We present a neural network
architecture for predicting front tire lateral force as a drop-in replacement
for physics-based approaches. With a full-scale automated vehicle purpose-built
for the drifting application, we deploy these models in a nonlinear model
predictive controller tuned for tracking a reference drifting trajectory, for
direct comparisons of model performance. The neural network tire model exhibits
significantly improved path tracking performance over the brush tire model in
cases where front-axle braking force is applied, suggesting the neural
network's ability to express previously unmodeled, latent dynamics in the
drifting condition.

摘要：自動漂移對於車輛控制是一個具有挑戰性的問題，
需要模型和控制演算法，能夠精確處理非線性、
耦合的輪胎力在摩擦極限下。我們提出一個神經網路
架構，用於預測前輪橫向力，作為基於物理方法的替代方案。
使用專為漂移應用而建的全尺寸自動駕駛車輛，我們在非線性模型
預測控制器中部署這些模型，針對追蹤參考漂移軌跡進行調整，以
直接比較模型效能。神經網路輪胎模型在施加前軸煞車力的情況下，
表現出顯著改善的路徑追蹤效能，這表示神經網路能夠表達以前未建模的、
在漂移條件下的潛在動態。

##### **Black-Box Opinion Manipulation Attacks to Retrieval-Augmented Generation of Large Language Models**
2407.13757v1 by Zhuo Chen, Jiawei Liu, Haotan Liu, Qikai Cheng, Fan Zhang, Wei Lu, Xiaozhong Liu

Retrieval-Augmented Generation (RAG) is applied to solve hallucination
problems and real-time constraints of large language models, but it also
induces vulnerabilities against retrieval corruption attacks. Existing research
mainly explores the unreliability of RAG in white-box and closed-domain QA
tasks. In this paper, we aim to reveal the vulnerabilities of
Retrieval-Enhanced Generative (RAG) models when faced with black-box attacks
for opinion manipulation. We explore the impact of such attacks on user
cognition and decision-making, providing new insight to enhance the reliability
and security of RAG models. We manipulate the ranking results of the retrieval
model in RAG with instruction and use these results as data to train a
surrogate model. By employing adversarial retrieval attack methods to the
surrogate model, black-box transfer attacks on RAG are further realized.
Experiments conducted on opinion datasets across multiple topics show that the
proposed attack strategy can significantly alter the opinion polarity of the
content generated by RAG. This demonstrates the model's vulnerability and, more
importantly, reveals the potential negative impact on user cognition and
decision-making, making it easier to mislead users into accepting incorrect or
biased information.

摘要：檢索增強生成 (RAG) 用於解決大型語言模型的幻覺問題和即時約束，但它也會引發對檢索破壞攻擊的漏洞。現有研究主要探討 RAG 在白盒和封閉域 QA 任務中的不可靠性。在本文中，我們旨在揭示檢索增強生成 (RAG) 模型在面對意見操縱的黑盒攻擊時的漏洞。我們探討了此類攻擊對使用者認知和決策制定的影響，並提供新的見解來增強 RAG 模型的可靠性和安全性。我們使用說明操縱 RAG 中檢索模型的排名結果，並使用這些結果作為資料來訓練代理模型。通過對代理模型採用對抗性檢索攻擊方法，進一步實現了對 RAG 的黑盒傳輸攻擊。在多個主題的意見資料集上進行的實驗表明，所提出的攻擊策略可以顯著改變 RAG 生成的內容的意見極性。這證明了模型的脆弱性，更重要的是，揭示了對使用者認知和決策制定的潛在負面影響，使得誤導使用者接受不正確或有偏見的資訊變得更加容易。

##### **LLMs as Function Approximators: Terminology, Taxonomy, and Questions for Evaluation**
2407.13744v1 by David Schlangen

Natural Language Processing has moved rather quickly from modelling specific
tasks to taking more general pre-trained models and fine-tuning them for
specific tasks, to a point where we now have what appear to be inherently
generalist models. This paper argues that the resultant loss of clarity on what
these models model leads to metaphors like "artificial general intelligences"
that are not helpful for evaluating their strengths and weaknesses. The
proposal is to see their generality, and their potential value, in their
ability to approximate specialist function, based on a natural language
specification. This framing brings to the fore questions of the quality of the
approximation, but beyond that, also questions of discoverability, stability,
and protectability of these functions. As the paper will show, this framing
hence brings together in one conceptual framework various aspects of
evaluation, both from a practical and a theoretical perspective, as well as
questions often relegated to a secondary status (such as "prompt injection" and
"jailbreaking").

摘要：自然語言處理已經從建模特定任務相當快速地轉移到採用更通用的預訓練模型，並針對特定任務微調它們，進展到我們現在擁有看似本質上是通才模型的地步。這篇論文認為，對於這些模型建模的內容缺乏明確性，導致出現「人工通用智慧」等比喻，而這對於評估它們的優缺點沒有幫助。建議在它們近似專家功能的能力中，根據自然語言規格，了解它們的通用性和潛在價值。此架構凸顯了近似品質的問題，但除此之外，也凸顯了這些功能的可發現性、穩定性和可保護性的問題。正如本文將展示的，此架構因此在一個概念架構中彙整了評估的各個方面，無論是從實務或理論的角度，以及經常降級為次要狀態的問題（例如「提示注入」和「越獄」）。

##### **CellularLint: A Systematic Approach to Identify Inconsistent Behavior in Cellular Network Specifications**
2407.13742v1 by Mirza Masfiqur Rahman, Imtiaz Karim, Elisa Bertino

In recent years, there has been a growing focus on scrutinizing the security
of cellular networks, often attributing security vulnerabilities to issues in
the underlying protocol design descriptions. These protocol design
specifications, typically extensive documents that are thousands of pages long,
can harbor inaccuracies, underspecifications, implicit assumptions, and
internal inconsistencies. In light of the evolving landscape, we introduce
CellularLint--a semi-automatic framework for inconsistency detection within the
standards of 4G and 5G, capitalizing on a suite of natural language processing
techniques. Our proposed method uses a revamped few-shot learning mechanism on
domain-adapted large language models. Pre-trained on a vast corpus of cellular
network protocols, this method enables CellularLint to simultaneously detect
inconsistencies at various levels of semantics and practical use cases. In
doing so, CellularLint significantly advances the automated analysis of
protocol specifications in a scalable fashion. In our investigation, we focused
on the Non-Access Stratum (NAS) and the security specifications of 4G and 5G
networks, ultimately uncovering 157 inconsistencies with 82.67% accuracy. After
verification of these inconsistencies on open-source implementations and 17
commercial devices, we confirm that they indeed have a substantial impact on
design decisions, potentially leading to concerns related to privacy,
integrity, availability, and interoperability.

摘要：近年来，人们越来越关注对蜂窝网络的安全性进行审查，通常将安全漏洞归因于底层协议设计描述中的问题。这些协议设计规范通常是长达数千页的大型文档，可能存在不准确、欠规范、隐含假设和内部不一致的情况。鉴于不断变化的格局，我们引入了 CellularLint——一个用于检测 4G 和 5G 标准中不一致性的半自动框架，它利用了一套自然语言处理技术。我们提出的方法在经过领域适应的大语言模型上使用改进的少样本学习机制。这种方法经过大量蜂窝网络协议语料库的预训练，使 CellularLint 能够同时检测语义和实际用例中不同层面的不一致性。通过这样做，CellularLint 以可扩展的方式极大地推进了协议规范的自动化分析。在我们的调查中，我们重点关注了 4G 和 5G 网络的非接入层 (NAS) 和安全规范，最终发现了 157 个不一致性，准确率为 82.67%。在对开源实现和 17 个商用设备验证了这些不一致性之后，我们确认它们确实对设计决策产生了重大影响，可能导致与隐私、完整性、可用性和互操作性相关的问题。

##### **Scaling Granite Code Models to 128K Context**
2407.13739v1 by Matt Stallone, Vaibhav Saxena, Leonid Karlinsky, Bridget McGinn, Tim Bula, Mayank Mishra, Adriana Meza Soria, Gaoyuan Zhang, Aditya Prasad, Yikang Shen, Saptha Surendran, Shanmukha Guttula, Hima Patel, Parameswaran Selvam, Xuan-Hong Dang, Yan Koyfman, Atin Sood, Rogerio Feris, Nirmit Desai, David D. Cox, Ruchir Puri, Rameswar Panda

This paper introduces long-context Granite code models that support effective
context windows of up to 128K tokens. Our solution for scaling context length
of Granite 3B/8B code models from 2K/4K to 128K consists of a light-weight
continual pretraining by gradually increasing its RoPE base frequency with
repository-level file packing and length-upsampled long-context data.
Additionally, we also release instruction-tuned models with long-context
support which are derived by further finetuning the long context base models on
a mix of permissively licensed short and long-context instruction-response
pairs. While comparing to the original short-context Granite code models, our
long-context models achieve significant improvements on long-context tasks
without any noticeable performance degradation on regular code completion
benchmarks (e.g., HumanEval). We release all our long-context Granite code
models under an Apache 2.0 license for both research and commercial use.

摘要：本文介绍了支持高达 128K 令牌的有效上下文窗口的长上下文 Granite 代码模型。我们针对将 Granite 3B/8B 代码模型的上下文长度从 2K/4K 扩展到 128K 的解决方案包括通过逐渐增加其 RoPE 基本频率，并结合存储库级别的文件打包和长度上采样的长上下文数据，进行轻量级的持续预训练。此外，我们还发布了具有长上下文支持的指令调整模型，这些模型是通过对长上下文基础模型进行进一步微调而得出的，微调基于许可宽松的短上下文和长上下文指令-响应对的混合。在与原始短上下文 Granite 代码模型进行比较时，我们的长上下文模型在长上下文任务中取得了显著的改进，而在常规代码完成基准（例如 HumanEval）上没有任何明显的性能下降。我们根据 Apache 2.0 许可证发布我们所有长上下文 Granite 代码模型，供研究和商业用途。

##### **Understanding Reinforcement Learning-Based Fine-Tuning of Diffusion Models: A Tutorial and Review**
2407.13734v1 by Masatoshi Uehara, Yulai Zhao, Tommaso Biancalani, Sergey Levine

This tutorial provides a comprehensive survey of methods for fine-tuning
diffusion models to optimize downstream reward functions. While diffusion
models are widely known to provide excellent generative modeling capability,
practical applications in domains such as biology require generating samples
that maximize some desired metric (e.g., translation efficiency in RNA, docking
score in molecules, stability in protein). In these cases, the diffusion model
can be optimized not only to generate realistic samples but also to explicitly
maximize the measure of interest. Such methods are based on concepts from
reinforcement learning (RL). We explain the application of various RL
algorithms, including PPO, differentiable optimization, reward-weighted MLE,
value-weighted sampling, and path consistency learning, tailored specifically
for fine-tuning diffusion models. We aim to explore fundamental aspects such as
the strengths and limitations of different RL-based fine-tuning algorithms
across various scenarios, the benefits of RL-based fine-tuning compared to
non-RL-based approaches, and the formal objectives of RL-based fine-tuning
(target distributions). Additionally, we aim to examine their connections with
related topics such as classifier guidance, Gflownets, flow-based diffusion
models, path integral control theory, and sampling from unnormalized
distributions such as MCMC. The code of this tutorial is available at
https://github.com/masa-ue/RLfinetuning_Diffusion_Bioseq

摘要：本教程提供了全面調查微調擴散模型以優化下游回報函數的方法。雖然廣為人知的是，擴散模型提供了優異的生成建模能力，但生物學等領域的實際應用需要生成最大化某些所需指標的樣本（例如，RNA 中的轉譯效率、分子中的對接分數、蛋白質中的穩定性）。在這些情況下，擴散模型不僅可以最佳化以生成逼真的樣本，還可以明確最大化感興趣的測量。此類方法基於強化學習 (RL) 的概念。我們說明了各種 RL 演算法的應用，包括 PPO、可微分最佳化、回報加權 MLE、值加權取樣和路徑一致性學習，這些演算法專門針對微調擴散模型而量身打造。我們的目標是探討基本面向，例如在各種場景中基於 RL 的不同微調演算法的優缺點、與非基於 RL 的方法相比，基於 RL 的微調的優點，以及基於 RL 的微調（目標分佈）的形式化目標。此外，我們的目標是探討它們與相關主題的關聯性，例如分類器指導、Gflownet、基於流的擴散模型、路徑積分控制理論，以及從未正規化的分佈（例如 MCMC）中取樣。本教程的程式碼可在 https://github.com/masa-ue/RLfinetuning_Diffusion_Bioseq 取得

##### **Baba Is AI: Break the Rules to Beat the Benchmark**
2407.13729v1 by Nathan Cloos, Meagan Jens, Michelangelo Naim, Yen-Ling Kuo, Ignacio Cases, Andrei Barbu, Christopher J. Cueva

Humans solve problems by following existing rules and procedures, and also by
leaps of creativity to redefine those rules and objectives. To probe these
abilities, we developed a new benchmark based on the game Baba Is You where an
agent manipulates both objects in the environment and rules, represented by
movable tiles with words written on them, to reach a specified goal and win the
game. We test three state-of-the-art multi-modal large language models (OpenAI
GPT-4o, Google Gemini-1.5-Pro and Gemini-1.5-Flash) and find that they fail
dramatically when generalization requires that the rules of the game must be
manipulated and combined.

摘要：人類解決問題的方式是遵循現有的規則和程序，並透過創意的飛躍重新定義這些規則和目標。為了探究這些能力，我們開發了一個新的基準，基於遊戲「Baba Is You」，其中代理人同時操縱環境中的物件和規則，這些規則由寫有文字的可移動磁磚表示，以達成特定目標並贏得遊戲。我們測試了三個最先進的多模態大型語言模型（OpenAI GPT-4o、Google Gemini-1.5-Pro 和 Gemini-1.5-Flash），並發現當概化需要操縱和組合遊戲規則時，它們會大幅失敗。

##### **CoDefeater: Using LLMs To Find Defeaters in Assurance Cases**
2407.13717v1 by Usman Gohar, Michael C. Hunter, Robyn R. Lutz, Myra B. Cohen

Constructing assurance cases is a widely used, and sometimes required,
process toward demonstrating that safety-critical systems will operate safely
in their planned environment. To mitigate the risk of errors and missing edge
cases, the concept of defeaters - arguments or evidence that challenge claims
in an assurance case - has been introduced. Defeaters can provide timely
detection of weaknesses in the arguments, prompting further investigation and
timely mitigations. However, capturing defeaters relies on expert judgment,
experience, and creativity and must be done iteratively due to evolving
requirements and regulations. This paper proposes CoDefeater, an automated
process to leverage large language models (LLMs) for finding defeaters. Initial
results on two systems show that LLMs can efficiently find known and unforeseen
feasible defeaters to support safety analysts in enhancing the completeness and
confidence of assurance cases.

摘要：建構保證案例是一種廣泛使用，有時甚至必要的流程，用於證明安全關鍵系統會在其計畫環境中安全運作。為了減輕錯誤和遺漏邊緣案例的風險，已導入了反駁者的概念，也就是挑戰保證案例中主張的論點或證據。反駁者可以即時偵測論點中的弱點，促使進一步調查和及時緩解。然而，擷取反駁者依賴於專家判斷、經驗和創造力，並且必須隨著不斷變化的需求和法規反覆進行。本文提出 CoDefeater，這是一個自動化流程，利用大型語言模型 (LLM) 來尋找反駁者。針對兩個系統的初步結果顯示，LLM 可以有效找出已知和未預見到的可行反駁者，以協助安全分析師提升保證案例的完整性和信心。

##### **FSP-Laplace: Function-Space Priors for the Laplace Approximation in Bayesian Deep Learning**
2407.13711v1 by Tristan Cinquin, Marvin Pförtner, Vincent Fortuin, Philipp Hennig, Robert Bamler

Laplace approximations are popular techniques for endowing deep networks with
epistemic uncertainty estimates as they can be applied without altering the
predictions of the neural network, and they scale to large models and datasets.
While the choice of prior strongly affects the resulting posterior
distribution, computational tractability and lack of interpretability of weight
space typically limit the Laplace approximation to isotropic Gaussian priors,
which are known to cause pathological behavior as depth increases. As a remedy,
we directly place a prior on function space. More precisely, since Lebesgue
densities do not exist on infinite-dimensional function spaces, we have to
recast training as finding the so-called weak mode of the posterior measure
under a Gaussian process (GP) prior restricted to the space of functions
representable by the neural network. Through the GP prior, one can express
structured and interpretable inductive biases, such as regularity or
periodicity, directly in function space, while still exploiting the implicit
inductive biases that allow deep networks to generalize. After model
linearization, the training objective induces a negative log-posterior density
to which we apply a Laplace approximation, leveraging highly scalable methods
from matrix-free linear algebra. Our method provides improved results where
prior knowledge is abundant, e.g., in many scientific inference tasks. At the
same time, it stays competitive for black-box regression and classification
tasks where neural networks typically excel.

摘要：拉普拉斯近似是赋予深度网络认知不确定性估计的流行技术，因为它们可以在不改变神经网络预测的情况下应用，并且可以扩展到大型模型和数据集。虽然先验的选择强烈影响最终的后验分布，但计算可处理性和权重空间的可解释性缺乏通常将拉普拉斯近似限制为各向同性高斯先验，已知随着深度增加，各向同性高斯先验会导致病态行为。作为补救措施，我们直接在函数空间上放置先验。更准确地说，由于勒贝格密度不存在于无限维函数空间上，我们必须将训练重新表述为在限制为神经网络可表示的函数空间的高斯过程 (GP) 先验下找到后验测度的所谓弱模式。通过 GP 先验，人们可以在函数空间中直接表达结构化且可解释的归纳偏差，例如规律性或周期性，同时仍然利用允许深度网络泛化的隐式归纳偏差。在模型线性化之后，训练目标会引起负对数后验密度，我们对其应用拉普拉斯近似，利用无矩阵线性代数中高度可扩展的方法。我们的方法在先验知识丰富的情况下（例如在许多科学推理任务中）提供了改进的结果。同时，它在黑盒回归和分类任务中保持竞争力，而神经网络通常在这些任务中表现出色。

##### **Understanding Reference Policies in Direct Preference Optimization**
2407.13709v1 by Yixin Liu, Pengfei Liu, Arman Cohan

Direct Preference Optimization (DPO) has become a widely used training method
for the instruction fine-tuning of large language models (LLMs). In this work,
we explore an under-investigated aspect of DPO - its dependency on the
reference model or policy. Such reference policies, typically instantiated as
the model to be further fine-tuned, are important since they can impose an
upper limit on DPO's effectiveness. Therefore, we address three related
research questions in this work. First, we explore the optimal strength of the
KL-divergence constraint in DPO, which penalizes deviations from the reference
policy, and find that DPO is sensitive to this strength. Next, we examine the
necessity of reference policies for instruction fine-tuning by providing both
theoretical and empirical comparisons between DPO and related learning
objectives, demonstrating DPO's superiority. Additionally, we investigate
whether DPO benefits from stronger reference policies, finding that a stronger
reference policy can lead to improved performance, but only when it is similar
to the model being fine-tuned. Our findings highlight the confounding role of
reference policies in DPO and offer insights for best practices, while also
identifying open research questions for future studies.

摘要：直接偏好優化（DPO）已成為廣泛使用的訓練方法，用於大型語言模型（LLM）的指令微調。在這項工作中，我們探討了 DPO 一個未經調查的面向 - 它對參考模型或政策的依賴性。此類參考政策通常被例示為要進一步微調的模型，它們很重要，因為它們可以對 DPO 的有效性施加上限。因此，我們在這項工作中解決了三個相關的研究問題。首先，我們探討了 DPO 中 KL-divergence 約束的最佳強度，它會懲罰與參考政策的偏差，並發現 DPO 對此強度很敏感。接下來，我們透過提供 DPO 與相關學習目標之間的理論和實證比較來檢驗指令微調對參考政策的必要性，證明了 DPO 的優越性。此外，我們探討了 DPO 是否受益於更強的參考政策，發現更強的參考政策可以帶來更好的效能，但僅當它類似於要微調的模型時。我們的研究結果突出了參考政策在 DPO 中的混淆作用，並為最佳實務提供了見解，同時也找出未來研究的開放式研究問題。

##### **ANHALTEN: Cross-Lingual Transfer for German Token-Level Reference-Free Hallucination Detection**
2407.13702v1 by Janek Herrlein, Chia-Chien Hung, Goran Glavaš

Research on token-level reference-free hallucination detection has
predominantly focused on English, primarily due to the scarcity of robust
datasets in other languages. This has hindered systematic investigations into
the effectiveness of cross-lingual transfer for this important NLP application.
To address this gap, we introduce ANHALTEN, a new evaluation dataset that
extends the English hallucination detection dataset to German. To the best of
our knowledge, this is the first work that explores cross-lingual transfer for
token-level reference-free hallucination detection. ANHALTEN contains gold
annotations in German that are parallel (i.e., directly comparable to the
original English instances). We benchmark several prominent cross-lingual
transfer approaches, demonstrating that larger context length leads to better
hallucination detection in German, even without succeeding context.
Importantly, we show that the sample-efficient few-shot transfer is the most
effective approach in most setups. This highlights the practical benefits of
minimal annotation effort in the target language for reference-free
hallucination detection. Aiming to catalyze future research on cross-lingual
token-level reference-free hallucination detection, we make ANHALTEN publicly
available: https://github.com/janekh24/anhalten

摘要：有關代幣層級無參考幻覺檢測的研究主要集中於英文，這主要是由於其他語言缺乏穩健的資料集。這阻礙了對這種重要的 NLP 應用程式進行跨語言轉移有效性的系統性調查。為了解決這個差距，我們引入了 ANHALTEN，這是一個新的評量資料集，將英文幻覺檢測資料集擴展到德文。據我們所知，這是第一個探討代幣層級無參考幻覺檢測的跨語言轉移的工作。ANHALTEN 包含德文的黃金註解，這些註解是平行的（即可以直接與原始英文實例進行比較）。我們對幾種著名的跨語言轉移方法進行基準測試，證明較大的脈絡長度會導致在德文中進行更好的幻覺檢測，即使沒有後續脈絡。重要的是，我們表明樣本效率高的少次數轉移在大多數設定中是最有效的方法。這突顯了在目標語言中進行無參考幻覺檢測時，最小註解工作量的實際好處。為了催化未來對跨語言代幣層級無參考幻覺檢測的研究，我們公開了 ANHALTEN：https://github.com/janekh24/anhalten

##### **Cross-Task Attack: A Self-Supervision Generative Framework Based on Attention Shift**
2407.13700v1 by Qingyuan Zeng, Yunpeng Gong, Min Jiang

Studying adversarial attacks on artificial intelligence (AI) systems helps
discover model shortcomings, enabling the construction of a more robust system.
Most existing adversarial attack methods only concentrate on single-task
single-model or single-task cross-model scenarios, overlooking the multi-task
characteristic of artificial intelligence systems. As a result, most of the
existing attacks do not pose a practical threat to a comprehensive and
collaborative AI system. However, implementing cross-task attacks is highly
demanding and challenging due to the difficulty in obtaining the real labels of
different tasks for the same picture and harmonizing the loss functions across
different tasks. To address this issue, we propose a self-supervised Cross-Task
Attack framework (CTA), which utilizes co-attention and anti-attention maps to
generate cross-task adversarial perturbation. Specifically, the co-attention
map reflects the area to which different visual task models pay attention,
while the anti-attention map reflects the area that different visual task
models neglect. CTA generates cross-task perturbations by shifting the
attention area of samples away from the co-attention map and closer to the
anti-attention map. We conduct extensive experiments on multiple vision tasks
and the experimental results confirm the effectiveness of the proposed design
for adversarial attacks.

摘要：研究人工智慧 (AI) 系統的對抗攻擊有助於
發現模型的缺點，從而能夠建構更強大的系統。
現有的對抗攻擊方法大多只專注於單一任務
單一模型或單一任務跨模型場景，忽略了人工智慧系統的多任務
特性。因此，現有的攻擊大多對全面且
協作式 AI 系統不構成實際威脅。然而，由於難以取得
同一張圖片不同任務的真實標籤，以及調和不同任務的損失函數，因此實作跨任務攻擊非常
要求且具有挑戰性。為了解決這個問題，我們提出一個自我監督的跨任務
攻擊架構 (CTA)，它利用共同注意和反注意地圖來
產生跨任務對抗擾動。特別是，共同注意地圖反映不同視覺任務模型注意到的區域，
而反注意地圖反映不同視覺任務模型忽略的區域。CTA 透過將
樣本的注意區域從共同注意地圖移開並靠近
反注意地圖來產生跨任務擾動。我們對多個視覺任務進行廣泛的實驗
並且實驗結果證實了所提出的設計對於對抗攻擊的有效性。

##### **A Comprehensive Review of Recommender Systems: Transitioning from Theory to Practice**
2407.13699v1 by Shaina Raza, Mizanur Rahman, Safiullah Kamawal, Armin Toroghi, Ananya Raval, Farshad Navah, Amirmohammad Kazemeini

Recommender Systems (RS) play an integral role in enhancing user experiences
by providing personalized item suggestions. This survey reviews the progress in
RS inclusively from 2017 to 2024, effectively connecting theoretical advances
with practical applications. We explore the development from traditional RS
techniques like content-based and collaborative filtering to advanced methods
involving deep learning, graph-based models, reinforcement learning, and large
language models. We also discuss specialized systems such as context-aware,
review-based, and fairness-aware RS. The primary goal of this survey is to
bridge theory with practice. It addresses challenges across various sectors,
including e-commerce, healthcare, and finance, emphasizing the need for
scalable, real-time, and trustworthy solutions. Through this survey, we promote
stronger partnerships between academic research and industry practices. The
insights offered by this survey aim to guide industry professionals in
optimizing RS deployment and to inspire future research directions, especially
in addressing emerging technological and societal trends

摘要：推薦系統 (RS) 在提升使用者體驗中扮演著不可或缺的角色，透過提供個人化的商品建議。這項調查回顧了 RS 在 2017 年到 2024 年間的進展，有效地將理論進展與實際應用連結起來。我們探討了從傳統的 RS 技術，例如基於內容和協同過濾，到涉及深度學習、基於圖形的模型、強化學習和大語言模型等先進方法的發展。我們也討論了專門的系統，例如情境感知、基於評論和公平感知的 RS。這項調查的主要目標是將理論與實務結合起來。它解決了各個領域的挑戰，包括電子商務、醫療保健和金融，強調了對可擴充、即時和可信賴的解決方案的需求。透過這項調查，我們促進了學術研究和產業實務之間更強大的夥伴關係。這項調查提供的見解旨在引導產業專業人士優化 RS 部署，並激勵未來的研究方向，特別是在解決新興的技術和社會趨勢方面。

##### **Benchmark Agreement Testing Done Right: A Guide for LLM Benchmark Evaluation**
2407.13696v1 by Yotam Perlitz, Ariel Gera, Ofir Arviv, Asaf Yehudai, Elron Bandel, Eyal Shnarch, Michal Shmueli-Scheuer, Leshem Choshen

Recent advancements in Language Models (LMs) have catalyzed the creation of
multiple benchmarks, designed to assess these models' general capabilities. A
crucial task, however, is assessing the validity of the benchmarks themselves.
This is most commonly done via Benchmark Agreement Testing (BAT), where new
benchmarks are validated against established ones using some agreement metric
(e.g., rank correlation). Despite the crucial role of BAT for benchmark
builders and consumers, there are no standardized procedures for such agreement
testing. This deficiency can lead to invalid conclusions, fostering mistrust in
benchmarks and upending the ability to properly choose the appropriate
benchmark to use. By analyzing over 40 prominent benchmarks, we demonstrate how
some overlooked methodological choices can significantly influence BAT results,
potentially undermining the validity of conclusions. To address these
inconsistencies, we propose a set of best practices for BAT and demonstrate how
utilizing these methodologies greatly improves BAT robustness and validity. To
foster adoption and facilitate future research,, we introduce BenchBench, a
python package for BAT, and release the BenchBench-leaderboard, a
meta-benchmark designed to evaluate benchmarks using their peers. Our findings
underscore the necessity for standardized BAT, ensuring the robustness and
validity of benchmark evaluations in the evolving landscape of language model
research.
  BenchBench Package: https://github.com/IBM/BenchBench
  Leaderboard: https://huggingface.co/spaces/per/BenchBench

摘要：<paragraph>語言模型 (LM) 的最新進展催化了多個基準的建立，這些基準旨在評估這些模型的一般能力。然而，一項至關重要的任務是評估基準本身的有效性。這通常通過基準協議測試 (BAT) 來完成，其中使用一些協議指標（例如，等級相關性）根據已建立的基準驗證新的基準。儘管 BAT 對基準構建者和消費者扮演著至關重要的角色，但對於此類協議測試並沒有標準化的程序。這種缺陷可能會導致無效的結論，造成對基準的不信任，並破壞適當地選擇適當基準使用的能力。通過分析超過 40 個重要的基準，我們展示了一些被忽視的方法論選擇如何顯著影響 BAT 結果，並可能破壞結論的有效性。為了解決這些不一致之處，我們提出了一套 BAT 的最佳實務範例，並展示了利用這些方法論如何大幅改善 BAT 的穩健性和有效性。為了促進採用和促進未來的研究，我們引入了 BenchBench，一個用於 BAT 的 python 套件，並發布了 BenchBench-leaderboard，一個元基準，旨在使用同儕評估基準。我們的發現強調了標準化 BAT 的必要性，確保了基準評估在語言模型研究不斷變化的環境中的穩健性和有效性。
BenchBench 套件：https://github.com/IBM/BenchBench
排行榜：https://huggingface.co/spaces/per/BenchBench</paragraph>

##### **Prover-Verifier Games improve legibility of LLM outputs**
2407.13692v1 by Jan Hendrik Kirchner, Yining Chen, Harri Edwards, Jan Leike, Nat McAleese, Yuri Burda

One way to increase confidence in the outputs of Large Language Models (LLMs)
is to support them with reasoning that is clear and easy to check -- a property
we call legibility. We study legibility in the context of solving grade-school
math problems and show that optimizing chain-of-thought solutions only for
answer correctness can make them less legible. To mitigate the loss in
legibility, we propose a training algorithm inspired by Prover-Verifier Game
from Anil et al. (2021). Our algorithm iteratively trains small verifiers to
predict solution correctness, "helpful" provers to produce correct solutions
that the verifier accepts, and "sneaky" provers to produce incorrect solutions
that fool the verifier. We find that the helpful prover's accuracy and the
verifier's robustness to adversarial attacks increase over the course of
training. Furthermore, we show that legibility training transfers to
time-constrained humans tasked with verifying solution correctness. Over course
of LLM training human accuracy increases when checking the helpful prover's
solutions, and decreases when checking the sneaky prover's solutions. Hence,
training for checkability by small verifiers is a plausible technique for
increasing output legibility. Our results suggest legibility training against
small verifiers as a practical avenue for increasing legibility of large LLMs
to humans, and thus could help with alignment of superhuman models.

摘要：一種增加大型語言模型 (LLM) 輸出可信度的方法是提供清晰且易於檢查的推理，我們稱此特性為可讀性。我們在解決小學數學問題的背景下研究可讀性，並顯示僅針對答案正確性最佳化思考鏈解決方案可能會降低其可讀性。為了減輕可讀性損失，我們提出了一種受 Anil 等人 (2021) 的證明者驗證者遊戲啟發的訓練演算法。我們的演算法反覆訓練小型驗證者以預測解的正確性，訓練「有用的」證明者以產生驗證者接受的正確解，以及訓練「狡猾的」證明者以產生欺騙驗證者的錯誤解。我們發現有用的證明者的準確度和驗證者對對抗性攻擊的穩健性在訓練過程中會增加。此外，我們顯示可讀性訓練會轉移到受限時間的人類，這些人類負責驗證解的正確性。在 LLM 訓練過程中，在檢查有用的證明者的解時，人類的準確度會增加，而在檢查狡猾的證明者的解時，人類的準確度會降低。因此，透過小型驗證者進行可驗證性訓練是一種增加輸出可讀性的可行技術。我們的結果表明，針對小型驗證者的可讀性訓練是一種增加大型 LLM 對人類可讀性的實際途徑，因此有助於調整超人類模型。

##### **Shaded Route Planning Using Active Segmentation and Identification of Satellite Images**
2407.13689v1 by Longchao Da, Rohan Chhibba, Rushabh Jaiswal, Ariane Middel, Hua Wei

Heatwaves pose significant health risks, particularly due to prolonged
exposure to high summer temperatures. Vulnerable groups, especially pedestrians
and cyclists on sun-exposed sidewalks, motivate the development of a route
planning method that incorporates somatosensory temperature effects through
shade ratio consideration. This paper is the first to introduce a pipeline that
utilizes segmentation foundation models to extract shaded areas from
high-resolution satellite images. These areas are then integrated into a
multi-layered road map, enabling users to customize routes based on a balance
between distance and shade exposure, thereby enhancing comfort and health
during outdoor activities. Specifically, we construct a graph-based
representation of the road map, where links indicate connectivity and are
updated with shade ratio data for dynamic route planning. This system is
already implemented online, with a video demonstration, and will be
specifically adapted to assist travelers during the 2024 Olympic Games in
Paris.

摘要：熱浪造成顯著的健康風險，特別是長時間暴露在夏季的高溫下。容易受傷害的族群，尤其是行走在陽光直射人行道上的行人和自行車騎士，促成了規劃路線方法的發展，其中納入了透過遮陽率考量來產生的體感溫度影響。本文首次介紹一個利用分割基礎模型從高解析度衛星影像中擷取陰影區域的管線。這些區域接著整合到多層道路地圖中，使用戶能夠根據距離和遮陽曝曬之間的平衡來自訂路線，進而提升戶外活動時的舒適度和健康。具體來說，我們建構了一個以圖形為基礎的道路地圖表徵，其中連結表示連通性，並透過遮陽率資料更新以進行動態路線規劃。此系統已線上實作，並附有影片示範，且將特別調整以協助旅客參加 2024 年巴黎奧運。

##### **HPix: Generating Vector Maps from Satellite Images**
2407.13680v1 by Aditya Taparia, Keshab Nath

Vector maps find widespread utility across diverse domains due to their
capacity to not only store but also represent discrete data boundaries such as
building footprints, disaster impact analysis, digitization, urban planning,
location points, transport links, and more. Although extensive research exists
on identifying building footprints and road types from satellite imagery, the
generation of vector maps from such imagery remains an area with limited
exploration. Furthermore, conventional map generation techniques rely on
labor-intensive manual feature extraction or rule-based approaches, which
impose inherent limitations. To surmount these limitations, we propose a novel
method called HPix, which utilizes modified Generative Adversarial Networks
(GANs) to generate vector tile map from satellite images. HPix incorporates two
hierarchical frameworks: one operating at the global level and the other at the
local level, resulting in a comprehensive model. Through empirical evaluations,
our proposed approach showcases its effectiveness in producing highly accurate
and visually captivating vector tile maps derived from satellite images. We
further extend our study's application to include mapping of road intersections
and building footprints cluster based on their area.

摘要：向量地圖由於其不僅能儲存，還能表示離散資料邊界（例如建築物足跡、災害影響分析、數位化、都市規劃、地點點、運輸連結等）的能力，因此在各種領域中廣泛使用。儘管現有大量研究用於從衛星影像中辨識建築物足跡和道路類型，但從此類影像產生向量地圖仍是一個探索有限的領域。此外，傳統的地圖產生技術依賴於勞力密集的手動特徵萃取或基於規則的方法，這會造成固有的限制。為了克服這些限制，我們提出了一種名為 HPix 的新方法，它利用修改過的生成對抗網路 (GAN) 從衛星影像產生向量磚塊地圖。HPix 結合了兩個階層架構：一個在全球層級運作，另一個在局部層級運作，產生一個全面的模型。透過實證評估，我們提出的方法展示了其在產生源自衛星影像的高精度且視覺上引人入勝的向量磚塊地圖方面的效能。我們進一步擴展研究的應用，包括根據區域對道路交叉口和建築物足跡群集進行製圖。

##### **PASTA: Controllable Part-Aware Shape Generation with Autoregressive Transformers**
2407.13677v1 by Songlin Li, Despoina Paschalidou, Leonidas Guibas

The increased demand for tools that automate the 3D content creation process
led to tremendous progress in deep generative models that can generate diverse
3D objects of high fidelity. In this paper, we present PASTA, an autoregressive
transformer architecture for generating high quality 3D shapes. PASTA comprises
two main components: An autoregressive transformer that generates objects as a
sequence of cuboidal primitives and a blending network, implemented with a
transformer decoder that composes the sequences of cuboids and synthesizes high
quality meshes for each object. Our model is trained in two stages: First we
train our autoregressive generative model using only annotated cuboidal parts
as supervision and next, we train our blending network using explicit 3D
supervision, in the form of watertight meshes. Evaluations on various ShapeNet
objects showcase the ability of our model to perform shape generation from
diverse inputs \eg from scratch, from a partial object, from text and images,
as well size-guided generation, by explicitly conditioning on a bounding box
that defines the object's boundaries. Moreover, as our model considers the
underlying part-based structure of a 3D object, we are able to select a
specific part and produce shapes with meaningful variations of this part. As
evidenced by our experiments, our model generates 3D shapes that are both more
realistic and diverse than existing part-based and non part-based methods,
while at the same time is simpler to implement and train.

摘要：<paragraph>由於對自動化 3D 內容建立流程的工具需求增加，導致深度生成模型在生成多樣化且高保真度的 3D 物件方面取得了長足的進展。在本文中，我們提出 PASTA，這是一種用於生成高品質 3D 形狀的自迴歸轉換器架構。PASTA 包含兩個主要組成部分：一個自迴歸轉換器，將物件生成為一系列的立方體基本形狀，以及一個混合網路，實作於一個轉換器解碼器，用於組合立方體序列並為每個物件合成高品質網格。我們的模型分兩個階段訓練：首先，我們使用僅註解的立方體部分作為監督訓練我們的自迴歸生成模型，接著，我們使用明確的 3D 監督訓練我們的混合網路，以水密網格的形式。在各種 ShapeNet 物件上的評估展示了我們的模型能夠根據不同的輸入執行形狀生成，例如從頭開始、從部分物件、從文字和影像，以及大小引導生成，透過明確地以定義物件邊界的邊界框作為條件。此外，由於我們的模型考慮了 3D 物件的基本部分結構，我們能夠選擇特定的部分並產生具有此部分有意義變化的形狀。正如我們的實驗所證明的，我們的模型產生的 3D 形狀比現有的基於部分和非基於部分的方法更逼真且多樣化，同時實作和訓練也更簡單。</paragraph>

##### **FuLG: 150B Romanian Corpus for Language Model Pretraining**
2407.13657v1 by Vlad-Andrei Bădoiu, Mihai-Valentin Dumitru, Alexandru M. Gherghescu, Alexandru Agache, Costin Raiciu

Research in the field of language models is rapidly evolving, with many open
models being released to the public. Openly available pretraining corpora
usually focus on only a handful of languages, with many others either missing
completely or extremely underrepresented. In this report, we introduce FuLG, a
hundred-fifty-billion-token Romanian corpus extracted from CommonCrawl. We
present our methodology for filtering FuLG and compare it via ablation studies
against existing Romanian corpora.

摘要：語言模型的研究領域正在快速演變，許多開放模型已發布給公眾。公開可用的預訓練語料庫通常只專注於少數語言，其他許多語言要么完全遺漏，要么極度代表不足。在此報告中，我們介紹了 FuLG，一個從 CommonCrawl 中提取的 1500 億個羅馬尼亞語料庫。我們展示了我們過濾 FuLG 的方法，並通過消融研究將其與現有的羅馬尼亞語料庫進行比較。

##### **Weak-to-Strong Reasoning**
2407.13647v1 by Yuqing Yang, Yan Ma, Pengfei Liu

When large language models (LLMs) exceed human-level capabilities, it becomes
increasingly challenging to provide full-scale and accurate supervisions for
these models. Weak-to-strong learning, which leverages a less capable model to
unlock the latent abilities of a stronger model, proves valuable in this
context. Yet, the efficacy of this approach for complex reasoning tasks is
still untested. Furthermore, tackling reasoning tasks under the weak-to-strong
setting currently lacks efficient methods to avoid blindly imitating the weak
supervisor including its errors. In this paper, we introduce a progressive
learning framework that enables the strong model to autonomously refine its
training data, without requiring input from either a more advanced model or
human-annotated data. This framework begins with supervised fine-tuning on a
selective small but high-quality dataset, followed by preference optimization
on contrastive samples identified by the strong model itself. Extensive
experiments on the GSM8K and MATH datasets demonstrate that our method
significantly enhances the reasoning capabilities of Llama2-70b using three
separate weak models. This method is further validated in a forward-looking
experimental setup, where Llama3-8b-instruct effectively supervises Llama3-70b
on the highly challenging OlympicArena dataset. This work paves the way for a
more scalable and sophisticated strategy to enhance AI reasoning powers. All
relevant code and resources are available in
\url{https://github.com/GAIR-NLP/weak-to-strong-reasoning}.

摘要：<paragraph>當大型語言模型 (LLM) 超越人類層級的能力時，為這些模型提供全面且精準的監督變得越來越具有挑戰性。弱到強學習利用能力較差的模型來解鎖較強模型的潛在能力，在此背景下證明了其價值。然而，這種方法對複雜推理任務的效能仍未經過測試。此外，在弱到強的設定下處理推理任務，目前缺乏有效的方法來避免盲目模仿較弱的監督者，包括其錯誤。在本文中，我們介紹一個漸進式學習架構，使強模型能夠自主精進其訓練資料，而無需來自更先進模型或人工標註資料的輸入。此架構從對精選的小型但高品質資料集進行監督微調開始，然後對強模型本身識別出的對比樣本進行偏好最佳化。在 GSM8K 和 MATH 資料集上的廣泛實驗證明，我們的方法使用三個獨立的弱模型，顯著提升了 Llama2-70b 的推理能力。此方法在一個前瞻性的實驗設置中進一步得到驗證，其中 Llama3-8b-instruct 有效地監督 Llama3-70b 處理極具挑戰性的 OlympicArena 資料集。這項工作為提升 AI 推理能力提供了更具可擴充性和精緻性的策略。所有相關程式碼和資源都可以在 \url{https://github.com/GAIR-NLP/weak-to-strong-reasoning} 中取得。</paragraph>

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

摘要：本研究旨在探討將自然語言處理 (NLP) 和機器學習 (ML) 技術實作於醫療信函編碼自動化，並具備視覺化說明能力和輕量化的本地電腦設定。目前在臨床環境中，編碼是一種手動流程，涉及為病患文件中的每項病症、程序和藥物指派代碼 (例如，使用 SNOMED CT 代碼 56265001 表示心臟病)。此領域有使用最新 ML 模型進行自動編碼的初步研究；然而，由於模型的複雜性和大小，並未實現實際部署。為了進一步促進自動編碼實務的可能性，我們在本地電腦設定中探討了一些解決方案；此外，我們探討了說明功能在 AI 模型透明度中的功能。我們使用公開的 MIMIC-III 資料庫和 HAN/HLAN 網路模型進行 ICD 代碼預測。我們還試驗了 ICD 和 SNOMED CT 知識庫之間的對應。在我們的實驗中，這些模型提供了 97.98% 代碼的有用資訊。這項調查結果可以為實務中的自動臨床編碼實作提供一些見解，例如在醫院環境中，由臨床醫生使用的本地電腦，專案頁面 \url{https://github.com/Glenj01/Medical-Coding}。

##### **Scaling Laws with Vocabulary: Larger Models Deserve Larger Vocabularies**
2407.13623v1 by Chaofan Tao, Qian Liu, Longxu Dou, Niklas Muennighoff, Zhongwei Wan, Ping Luo, Min Lin, Ngai Wong

Research on scaling large language models (LLMs) has primarily focused on
model parameters and training data size, overlooking the role of vocabulary
size. % Intuitively, larger vocabularies enable more efficient tokenization by
representing sentences with fewer tokens, but they also increase the risk of
under-fitting representations for rare tokens. We investigate how vocabulary
size impacts LLM scaling laws by training models ranging from 33M to 3B
parameters on up to 500B characters with various vocabulary configurations. We
propose three complementary approaches for predicting the compute-optimal
vocabulary size: IsoFLOPs analysis, derivative estimation, and parametric fit
of the loss function. Our approaches converge on the same result that the
optimal vocabulary size depends on the available compute budget and that larger
models deserve larger vocabularies. However, most LLMs use too small vocabulary
sizes. For example, we predict that the optimal vocabulary size of Llama2-70B
should have been at least 216K, 7 times larger than its vocabulary of 32K. We
validate our predictions empirically by training models with 3B parameters
across different FLOPs budgets. Adopting our predicted optimal vocabulary size
consistently improves downstream performance over commonly used vocabulary
sizes. By increasing the vocabulary size from the conventional 32K to 43K, we
improve performance on ARC-Challenge from 29.1 to 32.0 with the same 2.3e21
FLOPs. Our work emphasizes the necessity of jointly considering model
parameters and vocabulary size for efficient scaling.

摘要：大型語言模型 (LLM) 的擴充研究主要集中在
模型參數和訓練資料大小，忽略了詞彙量的角色
大小。% 直覺上，較大的詞彙量能透過
使用較少符號表示句子來更有效率地進行符號化，但它們也增加了
低擬合罕見符號表示的風險。我們研究詞彙量
大小如何影響 LLM 擴充定律，訓練模型範圍從 33M 到 3B
參數，在最多 500B 個字元上，搭配各種詞彙量組態。我們
提出三種互補的方法來預測計算最佳的
詞彙量大小：IsoFLOPs 分析、導數估計和參數擬合
損失函數。我們的做法收斂於相同的結果，即
最佳詞彙量大小取決於可用的計算預算，並且較大的
模型需要較大的詞彙量。然而，大多數 LLM 使用太小的詞彙量
大小。例如，我們預測 Llama2-70B 的最佳詞彙量大小
應該至少為 216K，比其 32K 的詞彙量大 7 倍。我們
透過使用 3B 參數在不同的 FLOPs 預算中訓練模型來驗證我們的預測
。採用我們預測的最佳詞彙量大小可以持續改善下游效能
超過常用的詞彙量大小。透過將詞彙量大小從傳統的 32K 增加到 43K，我們
使用相同的 2.3e21 FLOPs 將 ARC-Challenge 上的效能從 29.1 提升到 32.0。我們的研究強調了在有效擴充中共同考量模型
參數和詞彙量大小的必要性。

##### **Differential Privacy Mechanisms in Neural Tangent Kernel Regression**
2407.13621v1 by Jiuxiang Gu, Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song

Training data privacy is a fundamental problem in modern Artificial
Intelligence (AI) applications, such as face recognition, recommendation
systems, language generation, and many others, as it may contain sensitive user
information related to legal issues. To fundamentally understand how privacy
mechanisms work in AI applications, we study differential privacy (DP) in the
Neural Tangent Kernel (NTK) regression setting, where DP is one of the most
powerful tools for measuring privacy under statistical learning, and NTK is one
of the most popular analysis frameworks for studying the learning mechanisms of
deep neural networks. In our work, we can show provable guarantees for both
differential privacy and test accuracy of our NTK regression. Furthermore, we
conduct experiments on the basic image classification dataset CIFAR10 to
demonstrate that NTK regression can preserve good accuracy under a modest
privacy budget, supporting the validity of our analysis. To our knowledge, this
is the first work to provide a DP guarantee for NTK regression.

摘要：訓練資料隱私是現代人工智慧 (AI) 應用中的一個基本問題，例如人臉辨識、推薦系統、語言生成等等，因為它可能包含與法律問題相關的敏感使用者資訊。為了從根本上了解隱私機制如何在 AI 應用中運作，我們在神經切線核 (NTK) 回歸設定中研究差分隱私 (DP)，其中 DP 是衡量統計學習下隱私的最強大工具之一，而 NTK 是研究深度神經網路學習機制的熱門分析架構之一。在我們的研究中，我們可以為我們的 NTK 回歸展示可證明保證，同時兼顧差分隱私和測試準確性。此外，我們在基本影像分類資料集 CIFAR10 上進行實驗，以證明 NTK 回歸在適度的隱私預算下可以保持良好的準確性，支持我們分析的有效性。據我們所知，這是第一個為 NTK 回歸提供 DP 保證的研究。

##### **Training-free Composite Scene Generation for Layout-to-Image Synthesis**
2407.13609v1 by Jiaqi Liu, Tao Huang, Chang Xu

Recent breakthroughs in text-to-image diffusion models have significantly
advanced the generation of high-fidelity, photo-realistic images from textual
descriptions. Yet, these models often struggle with interpreting spatial
arrangements from text, hindering their ability to produce images with precise
spatial configurations. To bridge this gap, layout-to-image generation has
emerged as a promising direction. However, training-based approaches are
limited by the need for extensively annotated datasets, leading to high data
acquisition costs and a constrained conceptual scope. Conversely, training-free
methods face challenges in accurately locating and generating semantically
similar objects within complex compositions. This paper introduces a novel
training-free approach designed to overcome adversarial semantic intersections
during the diffusion conditioning phase. By refining intra-token loss with
selective sampling and enhancing the diffusion process with attention
redistribution, we propose two innovative constraints: 1) an inter-token
constraint that resolves token conflicts to ensure accurate concept synthesis;
and 2) a self-attention constraint that improves pixel-to-pixel relationships.
Our evaluations confirm the effectiveness of leveraging layout information for
guiding the diffusion process, generating content-rich images with enhanced
fidelity and complexity. Code is available at
https://github.com/Papple-F/csg.git.

摘要：最近在文本到图像扩散模型方面的突破显着提升了从文本描述生成高保真、逼真的图像的能力。然而，这些模型通常难以从文本中解释空间排列，这阻碍了它们生成具有精确空间配置的图像的能力。为了弥合这一差距，布局到图像生成已成为一个有前途的方向。然而，基于训练的方法受到广泛注释数据集需求的限制，导致数据获取成本高昂且概念范围受限。相反，无训练方法在准确定位和生成复杂构图中的语义相似对象方面面临挑战。本文介绍了一种新颖的无训练方法，旨在克服扩散调节阶段的对立语义交叉。通过使用选择性采样细化令牌内损失，并通过注意重新分配增强扩散过程，我们提出了两个创新约束：1）解决令牌冲突以确保准确概念合成的令牌间约束；2）改善像素到像素关系的自注意约束。我们的评估证实了利用布局信息指导扩散过程的有效性，生成了内容丰富、保真度和复杂性更高的图像。代码可在 https://github.com/Papple-F/csg.git 获得。

##### **dzNLP at NADI 2024 Shared Task: Multi-Classifier Ensemble with Weighted Voting and TF-IDF Features**
2407.13608v1 by Mohamed Lichouri, Khaled Lounnas, Boualem Nadjib Zahaf, Mehdi Ayoub Rabiai

This paper presents the contribution of our dzNLP team to the NADI 2024
shared task, specifically in Subtask 1 - Multi-label Country-level Dialect
Identification (MLDID) (Closed Track). We explored various configurations to
address the challenge: in Experiment 1, we utilized a union of n-gram analyzers
(word, character, character with word boundaries) with different n-gram values;
in Experiment 2, we combined a weighted union of Term Frequency-Inverse
Document Frequency (TF-IDF) features with various weights; and in Experiment 3,
we implemented a weighted major voting scheme using three classifiers: Linear
Support Vector Classifier (LSVC), Random Forest (RF), and K-Nearest Neighbors
(KNN).
  Our approach, despite its simplicity and reliance on traditional machine
learning techniques, demonstrated competitive performance in terms of F1-score
and precision. Notably, we achieved the highest precision score of 63.22% among
the participating teams. However, our overall F1 score was approximately 21%,
significantly impacted by a low recall rate of 12.87%. This indicates that
while our models were highly precise, they struggled to recall a broad range of
dialect labels, highlighting a critical area for improvement in handling
diverse dialectal variations.

摘要：本論文介紹了我們 dzNLP 團隊對 NADI 2024 共享任務的貢獻，特別是在子任務 1 - 多標籤國家級方言識別 (MLDID)（封閉軌道）。我們探索了各種配置來應對挑戰：在實驗 1 中，我們利用 n-gram 分析器（字詞、字元、帶有字詞邊界的字元）的聯集，並使用不同的 n-gram 值；在實驗 2 中，我們結合了術語頻率-逆文件頻率 (TF-IDF) 特徵的加權聯集，並使用不同的權重；在實驗 3 中，我們使用三個分類器實作加權多數投票方案：線性支持向量分類器 (LSVC)、隨機森林 (RF) 和 K 最近鄰 (KNN)。
我們的做法儘管簡單，且依賴傳統機器學習技術，但在 F1 分數和精確度方面展現了競爭力的表現。值得注意的是，我們在參賽隊伍中達到了 63.22% 的最高精確度分數。然而，我們的整體 F1 分數大約為 21%，受到 12.87% 的低召回率顯著影響。這表示雖然我們的模型非常精確，但它們難以召回廣泛的方言標籤，突顯出在處理多樣化的方言變體時，改善的重要領域。

##### **dzStance at StanceEval2024: Arabic Stance Detection based on Sentence Transformers**
2407.13603v1 by Mohamed Lichouri, Khaled Lounnas, Khelil Rafik Ouaras, Mohamed Abi, Anis Guechtouli

This study compares Term Frequency-Inverse Document Frequency (TF-IDF)
features with Sentence Transformers for detecting writers' stances--favorable,
opposing, or neutral--towards three significant topics: COVID-19 vaccine,
digital transformation, and women empowerment. Through empirical evaluation, we
demonstrate that Sentence Transformers outperform TF-IDF features across
various experimental setups. Our team, dzStance, participated in a stance
detection competition, achieving the 13th position (74.91%) among 15 teams in
Women Empowerment, 10th (73.43%) in COVID Vaccine, and 12th (66.97%) in Digital
Transformation. Overall, our team's performance ranked 13th (71.77%) among all
participants. Notably, our approach achieved promising F1-scores, highlighting
its effectiveness in identifying writers' stances on diverse topics. These
results underscore the potential of Sentence Transformers to enhance stance
detection models for addressing critical societal issues.

摘要：本研究比較了詞頻-逆向文件頻率 (TF-IDF) 特徵和句子轉換器，用於偵測作者對三個重要主題的立場，包括支持、反對或中立：COVID-19 疫苗、數位轉型和女性賦權。透過實證評估，我們證明句子轉換器在各種實驗設定中優於 TF-IDF 特徵。我們的團隊 dzStance 參加了立場偵測競賽，在 15 個團隊中獲得了第 13 名 (74.91%) 的成績，其中在女性賦權中排名第 10 (73.43%)，在 COVID 疫苗中排名第 10 (73.43%)，在數位轉型中排名第 12 (66.97%)。總體而言，我們團隊的表現排名第 13 (71.77%)。值得注意的是，我們的策略達到了有希望的 F1 分數，突顯了其在辨識作者對不同主題立場的有效性。這些結果強調了句子轉換器在加強立場偵測模型以解決關鍵社會問題方面的潛力。

##### **PLANTS: A Novel Problem and Dataset for Summarization of Planning-Like (PL) Tasks**
2407.13597v1 by Vishal Pallagani, Biplav Srivastava, Nitin Gupta

Text summarization is a well-studied problem that deals with deriving
insights from unstructured text consumed by humans, and it has found extensive
business applications. However, many real-life tasks involve generating a
series of actions to achieve specific goals, such as workflows, recipes,
dialogs, and travel plans. We refer to them as planning-like (PL) tasks noting
that the main commonality they share is control flow information. which may be
partially specified. Their structure presents an opportunity to create more
practical summaries to help users make quick decisions. We investigate this
observation by introducing a novel plan summarization problem, presenting a
dataset, and providing a baseline method for generating PL summaries. Using
quantitative metrics and qualitative user studies to establish baselines, we
evaluate the plan summaries from our method and large language models. We
believe the novel problem and dataset can reinvigorate research in
summarization, which some consider as a solved problem.

摘要：文本摘要是一個經過深入研究的問題，它處理的是從人類所閱讀的非結構化文本中推導見解，並且已經找到廣泛的商業應用。然而，許多真實生活的任務涉及生成一系列動作以達成具體的目標，例如工作流程、食譜、對話和旅遊計畫。我們將它們稱為計畫型 (PL) 任務，並注意到它們共有的主要特徵是控制流程資訊，而控制流程資訊可能是部分指定的。它們的結構提供了一個機會，可以建立更多實用的摘要，以協助使用者快速做出決策。我們透過引進一個新穎的計畫摘要問題、提供一個資料集，以及提供一個生成 PL 摘要的基準方法來探討這個觀察。我們使用量化指標和定性使用者研究來建立基準，並評估我們的方法和大型語言模型所產生的計畫摘要。我們相信這個新穎的問題和資料集可以重新激勵摘要的研究，而摘要研究被一些人認為是一個已經解決的問題。

##### **Towards Zero-Shot Multimodal Machine Translation**
2407.13579v1 by Matthieu Futeral, Cordelia Schmid, Benoît Sagot, Rachel Bawden

Current multimodal machine translation (MMT) systems rely on fully supervised
data (i.e models are trained on sentences with their translations and
accompanying images). However, this type of data is costly to collect, limiting
the extension of MMT to other language pairs for which such data does not
exist. In this work, we propose a method to bypass the need for fully
supervised data to train MMT systems, using multimodal English data only. Our
method, called ZeroMMT, consists in adapting a strong text-only machine
translation (MT) model by training it on a mixture of two objectives: visually
conditioned masked language modelling and the Kullback-Leibler divergence
between the original and new MMT outputs. We evaluate on standard MMT
benchmarks and the recently released CoMMuTE, a contrastive benchmark aiming to
evaluate how well models use images to disambiguate English sentences. We
obtain disambiguation performance close to state-of-the-art MMT models trained
additionally on fully supervised examples. To prove that our method generalizes
to languages with no fully supervised training data available, we extend the
CoMMuTE evaluation dataset to three new languages: Arabic, Russian and Chinese.
We further show that we can control the trade-off between disambiguation
capabilities and translation fidelity at inference time using classifier-free
guidance and without any additional data. Our code, data and trained models are
publicly accessible.

摘要：<paragraph>目前的 multimodal machine translation (MMT) 系統依賴於完全監督的資料（例如，模型針對具有翻譯和附帶圖片的句子進行訓練）。然而，此類資料的收集成本高昂，限制了 MMT 擴展到尚不存在此類資料的其他語言對。在這項工作中，我們提出了一種方法來繞過訓練 MMT 系統對完全監督資料的需求，僅使用 multimodal 英語資料。我們的稱為 ZeroMMT 的方法在於透過針對兩個目標的混合進行訓練來調整強大的純文字機器翻譯 (MT) 模型：視覺條件遮罩語言建模和原始 MMT 輸出與新 MMT 輸出之間的 Kullback-Leibler 距離。我們在標準 MMT 基準和最近發布的 CoMMuTE 上進行評估，後者是一個對比基準，旨在評估模型使用圖片來消除英語句子歧義的程度。我們獲得的消除歧義效能接近於額外針對完全監督範例進行訓練的最新 MMT 模型。為了證明我們的模型可以推廣到沒有可用的完全監督訓練資料的語言，我們將 CoMMuTE 評估資料集擴展到三種新語言：阿拉伯語、俄語和中文。我們進一步證明，我們可以在推理時間使用無分類器指導且不使用任何額外資料來控制消除歧義能力和翻譯保真度之間的權衡。我們的程式碼、資料和訓練模型可公開取得。</paragraph>

##### **Large Language Models as Reliable Knowledge Bases?**
2407.13578v1 by Danna Zheng, Mirella Lapata, Jeff Z. Pan

The NLP community has recently shown a growing interest in leveraging Large
Language Models (LLMs) for knowledge-intensive tasks, viewing LLMs as potential
knowledge bases (KBs). However, the reliability and extent to which LLMs can
function as KBs remain underexplored. While previous studies suggest LLMs can
encode knowledge within their parameters, the amount of parametric knowledge
alone is not sufficient to evaluate their effectiveness as KBs. This study
defines criteria that a reliable LLM-as-KB should meet, focusing on factuality
and consistency, and covering both seen and unseen knowledge. We develop
several metrics based on these criteria and use them to evaluate 26 popular
LLMs, while providing a comprehensive analysis of the effects of model size,
instruction tuning, and in-context learning (ICL). Our results paint a worrying
picture. Even a high-performant model like GPT-3.5-turbo is not factual or
consistent, and strategies like ICL and fine-tuning are unsuccessful at making
LLMs better KBs.

摘要：NLP 社群最近顯示出對利用大型語言模型 (LLM) 來執行知識密集型任務的興趣日益增長，將 LLM 視為潛在的知識庫 (KB)。然而，LLM 作為 KB 的可靠性和程度仍未被充分探討。雖然先前的研究表明 LLM 可以對其參數內的知識進行編碼，但僅參數知識的數量並不足以評估其作為 KB 的有效性。本研究定義了一個可靠的 LLM 作為 KB 應該符合的標準，重點關注事實性和一致性，並涵蓋已見和未見的知識。我們根據這些標準制定了幾個指標，並使用它們來評估 26 個流行的 LLM，同時對模型大小、指令調整和情境學習 (ICL) 的影響進行全面分析。我們的結果描繪了一幅令人擔憂的畫面。即使是像 GPT-3.5-turbo 這樣的高性能模型，事實上也不一致，而 ICL 和微調等策略也無法讓 LLM 成為更好的 KB。

##### **dzFinNlp at AraFinNLP: Improving Intent Detection in Financial Conversational Agents**
2407.13565v1 by Mohamed Lichouri, Khaled Lounnas, Mohamed Zakaria Amziane

In this paper, we present our dzFinNlp team's contribution for intent
detection in financial conversational agents, as part of the AraFinNLP shared
task. We experimented with various models and feature configurations, including
traditional machine learning methods like LinearSVC with TF-IDF, as well as
deep learning models like Long Short-Term Memory (LSTM). Additionally, we
explored the use of transformer-based models for this task. Our experiments
show promising results, with our best model achieving a micro F1-score of
93.02% and 67.21% on the ArBanking77 dataset, in the development and test sets,
respectively.

摘要：在本文中，我們介紹了我們的 dzFinNlp 團隊在金融對話代理中意圖偵測的貢獻，作為 AraFinNLP 共享任務的一部分。我們嘗試了各種模型和特徵配置，包括使用 TF-IDF 的傳統機器學習方法，例如 LinearSVC，以及深度學習模型，例如長短期記憶 (LSTM)。此外，我們還探索了將基於轉換器的模型用於此任務。我們的實驗顯示出有希望的結果，我們的最佳模型在 ArBanking77 數據集上分別在開發和測試集中達到了 93.02% 和 67.21% 的微觀 F1 分數。

##### **Research on Tibetan Tourism Viewpoints information generation system based on LLM**
2407.13561v1 by Jinhu Qi, Shuai Yan, Wentao Zhang, Yibo Zhang, Zirui Liu, Ke Wang

Tibet, ensconced within China's territorial expanse, is distinguished by its
labyrinthine and heterogeneous topography, a testament to its profound
historical heritage, and the cradle of a unique religious ethos. The very
essence of these attributes, however, has impeded the advancement of Tibet's
tourism service infrastructure, rendering existing smart tourism services
inadequate for the region's visitors. This study delves into the ramifications
of informational disparities at tourist sites on Tibetan tourism and addresses
the challenge of establishing the Large Language Model (LLM) evaluation
criteria. It introduces an innovative approach, the DualGen Bridge AI system,
employing supervised fine-tuning techniques to bolster model functionality and
enhance optimization processes. Furthermore, it pioneers a multi-structured
generative results assessment framework. Empirical validation confirms the
efficacy of this framework. The study also explores the application of the
supervised fine-tuning method within the proprietary DualGen Bridge AI, aimed
at refining the generation of tourist site information. The study's findings
offer valuable insights for optimizing system performance and provide support
and inspiration for the application of LLM technology in Tibet's tourism
services and beyond, potentially revolutionizing the smart tourism industry
with advanced, tailored information generation capabilities.

摘要：西藏，坐落在中國的領土範圍內，以其迷宮般且異質的地形而著稱，見證了其深厚的歷史遺產，是獨特宗教精神的搖籃。然而，這些屬性的精髓阻礙了西藏旅遊服務基礎設施的進步，導致現有的智慧旅遊服務無法滿足該地區遊客的需求。本研究深入探討了西藏旅遊景點資訊落差的後果，並解決了建立大型語言模型 (LLM) 評估標準的挑戰。它引入了一種創新方法，即 DualGen Bridge AI 系統，採用監督微調技術來加強模型功能並增強最佳化流程。此外，它開創了一個多結構生成結果評估框架。實證驗證證實了此框架的效力。本研究還探討了監督微調方法在專有的 DualGen Bridge AI 中的應用，旨在優化旅遊景點資訊的生成。本研究的發現為最佳化系統效能提供了寶貴的見解，並為 LLM 技術在西藏旅遊服務及其他領域的應用提供了支持和靈感，有可能透過先進、客製化的資訊生成能力，徹底革新智慧旅遊產業。

##### **Qalam : A Multimodal LLM for Arabic Optical Character and Handwriting Recognition**
2407.13559v1 by Gagan Bhatia, El Moatez Billah Nagoudi, Fakhraddin Alwajih, Muhammad Abdul-Mageed

Arabic Optical Character Recognition (OCR) and Handwriting Recognition (HWR)
pose unique challenges due to the cursive and context-sensitive nature of the
Arabic script. This study introduces Qalam, a novel foundation model designed
for Arabic OCR and HWR, built on a SwinV2 encoder and RoBERTa decoder
architecture. Our model significantly outperforms existing methods, achieving a
Word Error Rate (WER) of just 0.80% in HWR tasks and 1.18% in OCR tasks. We
train Qalam on a diverse dataset, including over 4.5 million images from Arabic
manuscripts and a synthetic dataset comprising 60k image-text pairs. Notably,
Qalam demonstrates exceptional handling of Arabic diacritics, a critical
feature in Arabic scripts. Furthermore, it shows a remarkable ability to
process high-resolution inputs, addressing a common limitation in current OCR
systems. These advancements underscore Qalam's potential as a leading solution
for Arabic script recognition, offering a significant leap in accuracy and
efficiency.

摘要：阿拉伯光學字元辨識 (OCR) 和手寫辨識 (HWR)
由於阿拉伯文字的草書和語境相關性，因此帶來了獨特的挑戰。本研究引入了 Qalam，一種專為阿拉伯 OCR 和 HWR 設計的新型基礎模型，建立在 SwinV2 編碼器和 RoBERTa 解碼器架構上。我們的模型顯著優於現有方法，在 HWR 任務中實現了僅為 0.80% 的字元錯誤率 (WER)，在 OCR 任務中實現了 1.18% 的字元錯誤率。我們在一個多樣化的資料集上訓練 Qalam，其中包括來自阿拉伯手稿的超過 450 萬張圖片和一個包含 6 萬張圖片文字對的合成資料集。值得注意的是，Qalam 展示了對阿拉伯變音符號的出色處理，這是阿拉伯文字中的一項關鍵特徵。此外，它還展示了處理高解析度輸入的非凡能力，解決了當前 OCR 系統中的常見限制。這些進步強調了 Qalam 作為阿拉伯文字辨識領先解決方案的潛力，在準確性和效率方面提供了顯著的飛躍。

##### **Enhancing Source-Free Domain Adaptive Object Detection with Low-confidence Pseudo Label Distillation**
2407.13524v1 by Ilhoon Yoon, Hyeongjun Kwon, Jin Kim, Junyoung Park, Hyunsung Jang, Kwanghoon Sohn

Source-Free domain adaptive Object Detection (SFOD) is a promising strategy
for deploying trained detectors to new, unlabeled domains without accessing
source data, addressing significant concerns around data privacy and
efficiency. Most SFOD methods leverage a Mean-Teacher (MT) self-training
paradigm relying heavily on High-confidence Pseudo Labels (HPL). However, these
HPL often overlook small instances that undergo significant appearance changes
with domain shifts. Additionally, HPL ignore instances with low confidence due
to the scarcity of training samples, resulting in biased adaptation toward
familiar instances from the source domain. To address this limitation, we
introduce the Low-confidence Pseudo Label Distillation (LPLD) loss within the
Mean-Teacher based SFOD framework. This novel approach is designed to leverage
the proposals from Region Proposal Network (RPN), which potentially encompasses
hard-to-detect objects in unfamiliar domains. Initially, we extract HPL using a
standard pseudo-labeling technique and mine a set of Low-confidence Pseudo
Labels (LPL) from proposals generated by RPN, leaving those that do not overlap
significantly with HPL. These LPL are further refined by leveraging
class-relation information and reducing the effect of inherent noise for the
LPLD loss calculation. Furthermore, we use feature distance to adaptively
weight the LPLD loss to focus on LPL containing a larger foreground area. Our
method outperforms previous SFOD methods on four cross-domain object detection
benchmarks. Extensive experiments demonstrate that our LPLD loss leads to
effective adaptation by reducing false negatives and facilitating the use of
domain-invariant knowledge from the source model. Code is available at
https://github.com/junia3/LPLD.

摘要：<paragraph>無來源域自適應物件偵測 (SFOD) 是一種將已訓練偵測器部署到新的未標記域而不存取來源資料的策略，可解決資料隱私和效率方面的重大問題。大多數 SFOD 方法利用平均教師 (MT) 自我訓練範例，高度依賴高信心偽標籤 (HPL)。然而，這些 HPL 常常忽略在域轉移中經歷顯著外觀變化的微小實例。此外，由於訓練樣本稀少，HPL 會忽略信心較低的實例，導致對來源域中熟悉的實例產生偏差適應。為了解決這個限制，我們在基於平均教師的 SFOD 架構中引入了低信心偽標籤蒸餾 (LPLD) 損失。這種新方法旨在利用區域建議網路 (RPN) 的建議，這可能涵蓋不熟悉的域中難以偵測的物件。最初，我們使用標準偽標籤技術提取 HPL，並從 RPN 生成的建議中找出低信心偽標籤 (LPL)，留下那些與 HPL 沒有顯著重疊的建議。這些 LPL 會進一步透過利用類別關係資訊和減少 LPLD 損失計算的固有雜訊效果來精煉。此外，我們使用特徵距離自適應地加權 LPLD 損失，以專注於包含較大前景區域的 LPL。我們的模型在四個跨域物件偵測基準上優於先前的 SFOD 模型。廣泛的實驗證明，我們的 LPLD 損失可透過減少假陰性和促進使用來源模型中的域不變知識來有效適應。程式碼可在 https://github.com/junia3/LPLD 取得。</paragraph>

##### **Can Open-Source LLMs Compete with Commercial Models? Exploring the Few-Shot Performance of Current GPT Models in Biomedical Tasks**
2407.13511v1 by Samy Ateia, Udo Kruschwitz

Commercial large language models (LLMs), like OpenAI's GPT-4 powering ChatGPT
and Anthropic's Claude 3 Opus, have dominated natural language processing (NLP)
benchmarks across different domains. New competing Open-Source alternatives
like Mixtral 8x7B or Llama 3 have emerged and seem to be closing the gap while
often offering higher throughput and being less costly to use. Open-Source LLMs
can also be self-hosted, which makes them interesting for enterprise and
clinical use cases where sensitive data should not be processed by third
parties. We participated in the 12th BioASQ challenge, which is a retrieval
augmented generation (RAG) setting, and explored the performance of current GPT
models Claude 3 Opus, GPT-3.5-turbo and Mixtral 8x7b with in-context learning
(zero-shot, few-shot) and QLoRa fine-tuning. We also explored how additional
relevant knowledge from Wikipedia added to the context-window of the LLM might
improve their performance. Mixtral 8x7b was competitive in the 10-shot setting,
both with and without fine-tuning, but failed to produce usable results in the
zero-shot setting. QLoRa fine-tuning and Wikipedia context did not lead to
measurable performance gains. Our results indicate that the performance gap
between commercial and open-source models in RAG setups exists mainly in the
zero-shot setting and can be closed by simply collecting few-shot examples for
domain-specific use cases. The code needed to rerun these experiments is
available through GitHub.

摘要：商業大型語言模型（LLM），例如 OpenAI 的 GPT-4 支援 ChatGPT，以及 Anthropic 的 Claude 3 Opus，已在不同領域主宰自然語言處理（NLP）基準。新的競爭性開源替代方案，例如 Mixtral 8x7B 或 Llama 3 已出現，並似乎正在縮小差距，同時通常提供更高的處理量，而且使用成本更低。開源 LLM 也可以自行託管，這使得它們對敏感資料不應由第三方處理的企業和臨床用例很有吸引力。我們參加了第 12 屆 BioASQ 挑戰，這是一個檢索增強生成（RAG）設定，並探討了當前 GPT 模型 Claude 3 Opus、GPT-3.5-turbo 和 Mixtral 8x7b 在情境學習（零次學習、少次學習）和 QLoRa 微調中的效能。我們還探討了從維基百科新增到 LLM 的情境視窗中的額外相關知識如何提升其效能。Mixtral 8x7b 在 10 次學習設定中具有競爭力，無論是否進行微調，但無法在零次學習設定中產生可用的結果。QLoRa 微調和維基百科情境並未帶來可衡量的效能提升。我們的結果表明，在 RAG 設定中，商業和開源模型之間的效能差距主要存在於零次學習設定中，而且可以透過僅收集特定領域用例的少次學習範例來縮小差距。執行這些實驗所需的程式碼可透過 GitHub 取得。

##### **Spontaneous Style Text-to-Speech Synthesis with Controllable Spontaneous Behaviors Based on Language Models**
2407.13509v1 by Weiqin Li, Peiji Yang, Yicheng Zhong, Yixuan Zhou, Zhisheng Wang, Zhiyong Wu, Xixin Wu, Helen Meng

Spontaneous style speech synthesis, which aims to generate human-like speech,
often encounters challenges due to the scarcity of high-quality data and
limitations in model capabilities. Recent language model-based TTS systems can
be trained on large, diverse, and low-quality speech datasets, resulting in
highly natural synthesized speech. However, they are limited by the difficulty
of simulating various spontaneous behaviors and capturing prosody variations in
spontaneous speech. In this paper, we propose a novel spontaneous speech
synthesis system based on language models. We systematically categorize and
uniformly model diverse spontaneous behaviors. Moreover, fine-grained prosody
modeling is introduced to enhance the model's ability to capture subtle prosody
variations in spontaneous speech.Experimental results show that our proposed
method significantly outperforms the baseline methods in terms of prosody
naturalness and spontaneous behavior naturalness.

摘要：自發式語音合成旨在產生類人語音，但由於缺乏高品質資料和模型功能的限制，經常會遇到挑戰。最近基於語言模型的 TTS 系統可以在大型、多樣且低品質的語音資料集上進行訓練，產生高度自然的合成語音。然而，它們受到模擬各種自發行為和捕捉自發語音中語調變化的難度所限制。在本文中，我們提出了一個基於語言模型的新穎自發語音合成系統。我們系統地分類並統一建模各種自發行為。此外，我們引入了細粒度的語調建模，以增強模型捕捉自發語音中細微語調變化的能力。實驗結果表明，我們提出的方法在語調自然度和自發行為自然度方面顯著優於基準方法。

##### **Robots Can Multitask Too: Integrating a Memory Architecture and LLMs for Enhanced Cross-Task Robot Action Generation**
2407.13505v1 by Hassan Ali, Philipp Allgeuer, Carlo Mazzola, Giulia Belgiovine, Burak Can Kaplan, Stefan Wermter

Large Language Models (LLMs) have been recently used in robot applications
for grounding LLM common-sense reasoning with the robot's perception and
physical abilities. In humanoid robots, memory also plays a critical role in
fostering real-world embodiment and facilitating long-term interactive
capabilities, especially in multi-task setups where the robot must remember
previous task states, environment states, and executed actions. In this paper,
we address incorporating memory processes with LLMs for generating cross-task
robot actions, while the robot effectively switches between tasks. Our proposed
dual-layered architecture features two LLMs, utilizing their complementary
skills of reasoning and following instructions, combined with a memory model
inspired by human cognition. Our results show a significant improvement in
performance over a baseline of five robotic tasks, demonstrating the potential
of integrating memory with LLMs for combining the robot's action and perception
for adaptive task execution.

摘要：大型語言模型 (LLM) 近來已用於機器人應用中，以機器人的感知和物理能力為基礎，建立 LLM 常識推理。在類人機器人中，記憶也扮演著關鍵角色，促進真實世界的具體化，並促進長期互動能力，特別是在多任務設定中，機器人必須記住先前的任務狀態、環境狀態和執行動作。在本文中，我們探討將記憶流程與 LLM 整合，以產生跨任務機器人動作，同時機器人在任務之間有效切換。我們提出的雙層架構採用兩個 LLM，利用它們在推理和遵循指令方面的互補技能，並結合受人類認知啟發的記憶模型。我們的結果顯示，在五項機器人任務的基準上，效能有顯著提升，證明了將記憶與 LLM 整合以結合機器人的動作和感知，以進行適應性任務執行的潛力。

##### **Training Foundation Models as Data Compression: On Information, Model Weights and Copyright Law**
2407.13493v1 by Giorgio Franceschelli, Claudia Cevenini, Mirco Musolesi

The training process of foundation models as for other classes of deep
learning systems is based on minimizing the reconstruction error over a
training set. For this reason, they are susceptible to the memorization and
subsequent reproduction of training samples. In this paper, we introduce a
training-as-compressing perspective, wherein the model's weights embody a
compressed representation of the training data. From a copyright standpoint,
this point of view implies that the weights could be considered a reproduction
or a derivative work of a potentially protected set of works. We investigate
the technical and legal challenges that emerge from this framing of the
copyright of outputs generated by foundation models, including their
implications for practitioners and researchers. We demonstrate that adopting an
information-centric approach to the problem presents a promising pathway for
tackling these emerging complex legal issues.

摘要：基礎模型的訓練過程，與其他類別的深度學習系統一樣，是基於最小化訓練集上的重建誤差。因此，它們容易記憶並隨後複製訓練樣本。在本文中，我們引入了訓練即壓縮的觀點，其中模型的權重體現了訓練資料的壓縮表示。從版權的角度來看，這個觀點意味著權重可以被視為一組潛在受保護作品的複製或衍生作品。我們探討了從這種構架中產生的基礎模型輸出版權所產生的技術和法律挑戰，包括對從業者和研究人員的影響。我們證明採用以資訊為中心的解決問題方法，為解決這些新興的複雜法律問題提供了一條有希望的途徑。

##### **Enhancing Biomedical Knowledge Discovery for Diseases: An End-To-End Open-Source Framework**
2407.13492v1 by Christos Theodoropoulos, Andrei Catalin Coman, James Henderson, Marie-Francine Moens

The ever-growing volume of biomedical publications creates a critical need
for efficient knowledge discovery. In this context, we introduce an open-source
end-to-end framework designed to construct knowledge around specific diseases
directly from raw text. To facilitate research in disease-related knowledge
discovery, we create two annotated datasets focused on Rett syndrome and
Alzheimer's disease, enabling the identification of semantic relations between
biomedical entities. Extensive benchmarking explores various ways to represent
relations and entity representations, offering insights into optimal modeling
strategies for semantic relation detection and highlighting language models'
competence in knowledge discovery. We also conduct probing experiments using
different layer representations and attention scores to explore transformers'
ability to capture semantic relations.

摘要：隨著生物醫學出版物數量不斷增加，對於有效率的知識發現產生了迫切需求。在此背景下，我們推出一個開源的端對端架構，旨在直接從原始文本中建構特定疾病相關的知識。為了促進疾病相關知識發現的研究，我們建立了兩個標註資料集，分別專注於瑞特氏症候群和阿茲海默症，並能識別生物醫學實體之間的語義關係。廣泛的基準測試探討了各種表示關係和實體表示的方法，提供深入了解語義關係偵測的最佳建模策略，並強調語言模型在知識發現中的能力。我們也進行了探索實驗，使用不同的層級表示和注意力分數，以探討Transformer擷取語義關係的能力。

##### **Combining Constraint Programming Reasoning with Large Language Model Predictions**
2407.13490v1 by Florian Régin, Elisabetta De Maria, Alexandre Bonlarron

Constraint Programming (CP) and Machine Learning (ML) face challenges in text
generation due to CP's struggle with implementing "meaning'' and ML's
difficulty with structural constraints. This paper proposes a solution by
combining both approaches and embedding a Large Language Model (LLM) in CP. The
LLM handles word generation and meaning, while CP manages structural
constraints. This approach builds on GenCP, an improved version of On-the-fly
Constraint Programming Search (OTFS) using LLM-generated domains. Compared to
Beam Search (BS), a standard NLP method, this combined approach (GenCP with
LLM) is faster and produces better results, ensuring all constraints are
satisfied. This fusion of CP and ML presents new possibilities for enhancing
text generation under constraints.

摘要：約束式程式設計（CP）和機器學習（ML）在文字生成方面面臨挑戰，因為 CP 在實作「意義」上遇到困難，而 ML 則在結構限制上遇到困難。這篇論文提出一個解決方案，結合兩種方法，並將大型語言模型（LLM）嵌入到 CP 中。LLM 處理字詞生成和意義，而 CP 則管理結構限制。此方法建立在 GenCP 上，GenCP 是使用 LLM 生成的網域的即時約束式程式設計搜尋（OTFS）的改良版本。與標準 NLP 方法 Beam Search（BS）相比，這種結合方法（GenCP 與 LLM）更快且產生更好的結果，確保滿足所有約束。CP 和 ML 的這種融合為在約束下增強文字生成提供了新的可能性。

##### **Attention Overflow: Language Model Input Blur during Long-Context Missing Items Recommendation**
2407.13481v1 by Damien Sileo

Large language models (LLMs) can suggest missing elements from items listed
in a prompt, which can be used for list completion or recommendations based on
users' history. However, their performance degrades when presented with too
many items, as they start to suggest items already included in the input list.
This occurs at around 100 items for mid-2024 flagship LLMs. We evaluate this
phenomenon on both synthetic problems (e.g., finding missing numbers in a given
range of shuffled integers) and realistic movie recommendation scenarios. We
refer to this issue as \textit{attention overflow}, as preventing repetition
requires attending to all items simultaneously. Although iterative loops can
mitigate this problem, their costs increase with the repetition rate, affecting
the language models' ability to derive novelty from lengthy inputs.

摘要：大型語言模型 (LLM) 可以建議在提示中列出的項目中遺失的元素，這些元素可用於根據使用者的歷史記錄進行清單完成或建議。然而，當提供過多項目時，它們的效能會下降，因為它們會開始建議輸入清單中已包含的項目。對於 2024 年中期的旗艦 LLM，這大約發生在 100 個項目左右。我們在合成問題（例如，在給定的洗牌整數範圍中找出遺失的數字）和實際的電影推薦場景中評估了這個現象。我們將這個問題稱為「注意力溢位」，因為防止重複需要同時關注所有項目。儘管反覆運算可以減輕這個問題，但它們的成本會隨著重複率而增加，影響語言模型從冗長的輸入中得出新穎性的能力。

##### **Risk-Aware Vehicle Trajectory Prediction Under Safety-Critical Scenarios**
2407.13480v1 by Qingfan Wang, Dongyang Xu, Gaoyuan Kuang, Chen Lv, Shengbo Eben Li, Bingbing Nie

Trajectory prediction is significant for intelligent vehicles to achieve
high-level autonomous driving, and a lot of relevant research achievements have
been made recently. Despite the rapid development, most existing studies solely
focused on normal safe scenarios while largely neglecting safety-critical
scenarios, particularly those involving imminent collisions. This oversight may
result in autonomous vehicles lacking the essential predictive ability in such
situations, posing a significant threat to safety. To tackle these, this paper
proposes a risk-aware trajectory prediction framework tailored to
safety-critical scenarios. Leveraging distinctive hazardous features, we
develop three core risk-aware components. First, we introduce a
risk-incorporated scene encoder, which augments conventional encoders with
quantitative risk information to achieve risk-aware encoding of hazardous scene
contexts. Next, we incorporate endpoint-risk-combined intention queries as
prediction priors in the decoder to ensure that the predicted multimodal
trajectories cover both various spatial intentions and risk levels. Lastly, an
auxiliary risk prediction task is implemented for the ultimate risk-aware
prediction. Furthermore, to support model training and performance evaluation,
we introduce a safety-critical trajectory prediction dataset and tailored
evaluation metrics. We conduct comprehensive evaluations and compare our model
with several SOTA models. Results demonstrate the superior performance of our
model, with a significant improvement in most metrics. This prediction
advancement enables autonomous vehicles to execute correct collision avoidance
maneuvers under safety-critical scenarios, eventually enhancing road traffic
safety.

摘要：軌跡預測對於智慧型車輛實現高階自動駕駛非常重要，且最近也取得許多相關的研究成果。儘管發展迅速，但現有研究大多僅專注於正常的安全場景，而忽略了安全關鍵場景，特別是那些涉及即將發生碰撞的場景。這種疏忽可能會導致自動駕駛車輛在這種情況下缺乏必要的預測能力，對安全構成重大威脅。為了解決這些問題，本文提出了一個針對安全關鍵場景量身打造的風險感知軌跡預測框架。利用獨特的危險特徵，我們開發了三個核心風險感知組件。首先，我們引入了一個風險整合場景編碼器，它使用定量風險資訊擴充傳統編碼器，以實現危險場景環境的風險感知編碼。接下來，我們將端點風險組合意圖查詢作為解碼器中的預測先驗，以確保預測的多模式軌跡涵蓋各種空間意圖和風險等級。最後，實作了一個輔助風險預測任務，以進行最終的風險感知預測。此外，為了支援模型訓練和效能評估，我們引入了一個安全關鍵軌跡預測資料集和量身打造的評估指標。我們進行了全面的評估，並將我們的模型與幾個 SOTA 模型進行比較。結果證明了我們模型的優異效能，在多數指標上都有顯著的進步。這種預測進展使自動駕駛車輛能夠在安全關鍵場景下執行正確的避撞操作，最終提升道路交通安全。

##### **Fixed and Adaptive Simultaneous Machine Translation Strategies Using Adapters**
2407.13469v1 by Abderrahmane Issam, Yusuf Can Semerci, Jan Scholtes, Gerasimos Spanakis

Simultaneous machine translation aims at solving the task of real-time
translation by starting to translate before consuming the full input, which
poses challenges in terms of balancing quality and latency of the translation.
The wait-$k$ policy offers a solution by starting to translate after consuming
$k$ words, where the choice of the number $k$ directly affects the latency and
quality. In applications where we seek to keep the choice over latency and
quality at inference, the wait-$k$ policy obliges us to train more than one
model. In this paper, we address the challenge of building one model that can
fulfil multiple latency levels and we achieve this by introducing lightweight
adapter modules into the decoder. The adapters are trained to be specialized
for different wait-$k$ values and compared to other techniques they offer more
flexibility to allow for reaping the benefits of parameter sharing and
minimizing interference. Additionally, we show that by combining with an
adaptive strategy, we can further improve the results. Experiments on two
language directions show that our method outperforms or competes with other
strong baselines on most latency values.

摘要：同步機器翻譯旨在透過在消耗完所有輸入前開始翻譯來解決即時翻譯任務，這在翻譯品質和延遲之間的平衡方面帶來挑戰。等候-$k$ 政策透過在消耗完 $k$ 個詞彙後開始翻譯來提供解決方案，其中數字 $k$ 的選擇直接影響延遲和品質。在我們尋求在推論中保留延遲和品質選擇的應用程式中，等候-$k$ 政策要求我們訓練多於一個模型。在本文中，我們探討建立一個可以滿足多個延遲層級的模型的挑戰，我們透過在解碼器中引入輕量級適配器模組來達成此目標。這些適配器經過訓練，可以針對不同的等候-$k$ 值進行專門化，並且與其他技術相比，它們提供更大的彈性，以利於獲取參數共用和最小化干擾的好處。此外，我們展示透過與適應性策略結合，我們可以進一步改善結果。在兩種語言方向的實驗顯示，我們的模型在大部分延遲值方面優於或與其他強大的基線競爭。

##### **End-To-End Clinical Trial Matching with Large Language Models**
2407.13463v1 by Dyke Ferber, Lars Hilgers, Isabella C. Wiest, Marie-Elisabeth Leßmann, Jan Clusmann, Peter Neidlinger, Jiefu Zhu, Georg Wölflein, Jacqueline Lammert, Maximilian Tschochohei, Heiko Böhme, Dirk Jäger, Mihaela Aldea, Daniel Truhn, Christiane Höper, Jakob Nikolas Kather

Matching cancer patients to clinical trials is essential for advancing
treatment and patient care. However, the inconsistent format of medical free
text documents and complex trial eligibility criteria make this process
extremely challenging and time-consuming for physicians. We investigated
whether the entire trial matching process - from identifying relevant trials
among 105,600 oncology-related clinical trials on clinicaltrials.gov to
generating criterion-level eligibility matches - could be automated using Large
Language Models (LLMs). Using GPT-4o and a set of 51 synthetic Electronic
Health Records (EHRs), we demonstrate that our approach identifies relevant
candidate trials in 93.3% of cases and achieves a preliminary accuracy of 88.0%
when matching patient-level information at the criterion level against a
baseline defined by human experts. Utilizing LLM feedback reveals that 39.3%
criteria that were initially considered incorrect are either ambiguous or
inaccurately annotated, leading to a total model accuracy of 92.7% after
refining our human baseline. In summary, we present an end-to-end pipeline for
clinical trial matching using LLMs, demonstrating high precision in screening
and matching trials to individual patients, even outperforming the performance
of qualified medical doctors. Our fully end-to-end pipeline can operate
autonomously or with human supervision and is not restricted to oncology,
offering a scalable solution for enhancing patient-trial matching in real-world
settings.

摘要：配對癌症患者與臨床試驗對於推進治療和患者照護至關重要。然而，醫療自由文本文件格式不一致以及複雜的試驗資格標準，使得這個過程對醫師來說極具挑戰性且耗時。我們調查了整個試驗配對過程——從在 clinicaltrials.gov 上 105,600 個與腫瘤學相關的臨床試驗中找出相關試驗，到產生標準層級資格配對——是否可以使用大型語言模型 (LLM) 自動化。我們使用 GPT-4o 和一套 51 個合成的電子健康紀錄 (EHR)，證明我們的做法在 93.3% 的案例中找出相關候選試驗，並且在針對人類專家定義的基準，比對標準層級的患者層級資訊時，達到 88.0% 的初步準確度。利用 LLM 回饋顯示，最初被認為不正確的 39.3% 標準，不是模稜兩可就是註解不準確，在我們改善人類基準後，導致模型總準確度為 92.7%。總之，我們提出一個使用 LLM 的臨床試驗配對端到端管線，證明在篩選和比對試驗到個別患者時具有高精準度，甚至優於合格醫生的表現。我們完全的端到端管線可以自主運作或在人類監督下運作，且不限於腫瘤學，提供一個可擴充的解決方案，用於提升現實世界中的患者試驗配對。

##### **BEAF: Observing BEfore-AFter Changes to Evaluate Hallucination in Vision-language Models**
2407.13442v1 by Moon Ye-Bin, Nam Hyeon-Woo, Wonseok Choi, Tae-Hyun Oh

Vision language models (VLMs) perceive the world through a combination of a
visual encoder and a large language model (LLM). The visual encoder,
pre-trained on large-scale vision-text datasets, provides zero-shot
generalization to visual data, and the LLM endows its high reasoning ability to
VLMs. It leads VLMs to achieve high performance on wide benchmarks without
fine-tuning, exhibiting zero or few-shot capability. However, recent studies
show that VLMs are vulnerable to hallucination. This undesirable behavior
degrades reliability and credibility, thereby making users unable to fully
trust the output from VLMs. To enhance trustworthiness and better tackle the
hallucination of VLMs, we curate a new evaluation dataset, called the
BEfore-AFter hallucination dataset (BEAF), and introduce new metrics: True
Understanding (TU), IGnorance (IG), StuBbornness (SB), and InDecision (ID).
Unlike prior works that focus only on constructing questions and answers, the
key idea of our benchmark is to manipulate visual scene information by image
editing models and to design the metrics based on scene changes. This allows us
to clearly assess whether VLMs correctly understand a given scene by observing
the ability to perceive changes. We also visualize image-wise object
relationship by virtue of our two-axis view: vision and text. Upon evaluating
VLMs with our dataset, we observed that our metrics reveal different aspects of
VLM hallucination that have not been reported before. Project page:
\url{https://beafbench.github.io/}

摘要：<paragraph>視覺語言模型 (VLM) 透過視覺編碼器與大型語言模型 (LLM) 的組合來感知世界。視覺編碼器在大型視覺文字資料集上進行預訓練，提供零次學習泛化到視覺資料，而 LLM 則賦予 VLM 高推理能力。這使得 VLM 在廣泛基準上實現高性能，無需微調，展現零次或少量學習能力。然而，最近的研究顯示 VLM 容易出現幻覺。這種不良行為會降低可靠性和可信度，因此讓使用者無法完全信任 VLM 的輸出。為了提升可信度並更好地解決 VLM 的幻覺問題，我們策劃了一個新的評估資料集，稱為 BEfore-AFter 幻覺資料集 (BEAF)，並引入了新的指標：真實理解 (TU)、無知 (IG)、頑固 (SB) 和猶豫不決 (ID)。與先前僅專注於建構問題和答案的研究不同，我們的基準測試關鍵在於透過影像編輯模型來操縱視覺場景資訊，並根據場景變化來設計指標。這讓我們可以透過觀察感知變化的能力，清楚評估 VLM 是否正確理解給定的場景。我們也透過我們的雙軸視圖：視覺和文字，將影像中的物件關係視覺化。在使用我們的資料集評估 VLM 時，我們觀察到我們的指標揭露了 VLM 幻覺的不同面向，這些面向在過去未曾被報導過。專案頁面：\url{https://beafbench.github.io/}</paragraph>

##### **Reducing Barriers to the Use of Marginalised Music Genres in AI**
2407.13439v1 by Nick Bryan-Kinns, Zijin Li

AI systems for high quality music generation typically rely on extremely
large musical datasets to train the AI models. This creates barriers to
generating music beyond the genres represented in dominant datasets such as
Western Classical music or pop music. We undertook a 4 month international
research project summarised in this paper to explore the eXplainable AI (XAI)
challenges and opportunities associated with reducing barriers to using
marginalised genres of music with AI models. XAI opportunities identified
included topics of improving transparency and control of AI models, explaining
the ethics and bias of AI models, fine tuning large models with small datasets
to reduce bias, and explaining style-transfer opportunities with AI models.
Participants in the research emphasised that whilst it is hard to work with
small datasets such as marginalised music and AI, such approaches strengthen
cultural representation of underrepresented cultures and contribute to
addressing issues of bias of deep learning models. We are now building on this
project to bring together a global International Responsible AI Music community
and invite people to join our network.

摘要：高品質音樂生成的人工智慧系統通常仰賴極大量的音樂資料集來訓練人工智慧模型。這會為生成音樂帶來阻礙，因為這些資料集只代表了主流的音樂類型，例如西方古典音樂或流行音樂。我們進行了一個為期 4 個月的國際研究計畫，並將其摘要於本文中，以探討與減少使用邊緣音樂類型與人工智慧模型的阻礙相關的「可解釋人工智慧」(XAI) 挑戰和機會。我們找出的人工智慧機會包括改善人工智慧模型的透明度和控制、解釋人工智慧模型的道德和偏見、使用小型資料集微調大型模型以減少偏見，以及解釋人工智慧模型的風格轉移機會。研究參與者強調，儘管使用邊緣音樂和人工智慧等小型資料集很困難，但這種方法可以加強對代表性不足的文化的文化呈現，並有助於解決深度學習模型的偏見問題。我們現在正以此計畫為基礎，召集一個全球性的國際負責任人工智慧音樂社群，並邀請大家加入我們的網路。

##### **Enhancing Out-of-Vocabulary Performance of Indian TTS Systems for Practical Applications through Low-Effort Data Strategies**
2407.13435v1 by Srija Anand, Praveen Srinivasa Varadhan, Ashwin Sankar, Giri Raju, Mitesh M. Khapra

Publicly available TTS datasets for low-resource languages like Hindi and
Tamil typically contain 10-20 hours of data, leading to poor vocabulary
coverage. This limitation becomes evident in downstream applications where
domain-specific vocabulary coupled with frequent code-mixing with English,
results in many OOV words. To highlight this problem, we create a benchmark
containing OOV words from several real-world applications. Indeed,
state-of-the-art Hindi and Tamil TTS systems perform poorly on this OOV
benchmark, as indicated by intelligibility tests. To improve the model's OOV
performance, we propose a low-effort and economically viable strategy to obtain
more training data. Specifically, we propose using volunteers as opposed to
high quality voice artists to record words containing character bigrams unseen
in the training data. We show that using such inexpensive data, the model's
performance improves on OOV words, while not affecting voice quality and
in-domain performance.

摘要：<paragraph>對於印地語和泰米爾語等低資源語言，公開可用的 TTS 資料集通常包含 10-20 小時的資料，導致詞彙涵蓋範圍很差。這種限制在下游應用中很明顯，在這些應用中，特定領域的詞彙與頻繁的英語代碼混合，導致出現許多 OOV 字詞。為了凸顯這個問題，我們建立了一個基準，其中包含來自多個真實世界應用程式的 OOV 字詞。事實上，最先進的印地語和泰米爾語 TTS 系統在這個 OOV 基準上表現不佳，這從可懂度測試中可以看出。為了提高模型的 OOV 效能，我們提出了一種低成本且經濟可行的策略，以取得更多訓練資料。具體來說，我們建議使用志工，而不是高品質的配音員，來錄製訓練資料中未出現的字元二元組所組成的字詞。我們表明，使用這種低成本資料，模型在 OOV 字詞上的效能有所提升，同時不影響語音品質和特定領域效能。</paragraph>

##### **Improving Out-of-Distribution Generalization of Trajectory Prediction for Autonomous Driving via Polynomial Representations**
2407.13431v1 by Yue Yao, Shengchao Yan, Daniel Goehring, Wolfram Burgard, Joerg Reichardt

Robustness against Out-of-Distribution (OoD) samples is a key performance
indicator of a trajectory prediction model. However, the development and
ranking of state-of-the-art (SotA) models are driven by their In-Distribution
(ID) performance on individual competition datasets. We present an OoD testing
protocol that homogenizes datasets and prediction tasks across two large-scale
motion datasets. We introduce a novel prediction algorithm based on polynomial
representations for agent trajectory and road geometry on both the input and
output sides of the model. With a much smaller model size, training effort, and
inference time, we reach near SotA performance for ID testing and significantly
improve robustness in OoD testing. Within our OoD testing protocol, we further
study two augmentation strategies of SotA models and their effects on model
generalization. Highlighting the contrast between ID and OoD performance, we
suggest adding OoD testing to the evaluation criteria of trajectory prediction
models.

摘要：對抗分布外 (OoD) 範例的穩健性是軌跡預測模型的關鍵效能指標。然而，最先進 (SotA) 模型的開發和排名是由其在個別競賽資料集上的分布內 (ID) 效能所驅動的。我們提出一個 OoD 測試協定，用於將資料集和預測任務同質化，並涵蓋兩個大型運動資料集。我們引入一種新穎的預測演算法，其基礎是模型輸入和輸出兩側的代理軌跡和道路幾何的二次方程式表示法。透過大幅縮小模型大小、訓練工作量和推論時間，我們在 ID 測試中達到接近 SotA 的效能，並在 OoD 測試中大幅提升穩健性。在我們的 OoD 測試協定中，我們進一步研究 SotA 模型的兩種擴充策略及其對模型泛化的影響。我們強調 ID 和 OoD 效能之間的對比，建議將 OoD 測試新增到軌跡預測模型的評量準則中。

##### **Towards Dynamic Feature Acquisition on Medical Time Series by Maximizing Conditional Mutual Information**
2407.13429v1 by Fedor Sergeev, Paola Malsot, Gunnar Rätsch, Vincent Fortuin

Knowing which features of a multivariate time series to measure and when is a
key task in medicine, wearables, and robotics. Better acquisition policies can
reduce costs while maintaining or even improving the performance of downstream
predictors. Inspired by the maximization of conditional mutual information, we
propose an approach to train acquirers end-to-end using only the downstream
loss. We show that our method outperforms random acquisition policy, matches a
model with an unrestrained budget, but does not yet overtake a static
acquisition strategy. We highlight the assumptions and outline avenues for
future work.

摘要：了解多變量時間序列的哪些特徵以及何時測量是醫學、穿戴裝置和機器人技術中的關鍵任務。更好的獲取政策可以降低成本，同時維持或甚至改善下游預測器的效能。受到條件互資訊最大化的啟發，我們提出一個方法，使用僅下游損失，從頭到尾訓練獲取器。我們展示我們的方法優於隨機獲取政策，符合預算不受限制的模型，但尚未超越靜態獲取策略。我們強調假設並概述未來工作的途徑。

##### **DeepClair: Utilizing Market Forecasts for Effective Portfolio Selection**
2407.13427v1 by Donghee Choi, Jinkyu Kim, Mogan Gim, Jinho Lee, Jaewoo Kang

Utilizing market forecasts is pivotal in optimizing portfolio selection
strategies. We introduce DeepClair, a novel framework for portfolio selection.
DeepClair leverages a transformer-based time-series forecasting model to
predict market trends, facilitating more informed and adaptable portfolio
decisions. To integrate the forecasting model into a deep reinforcement
learning-driven portfolio selection framework, we introduced a two-step
strategy: first, pre-training the time-series model on market data, followed by
fine-tuning the portfolio selection architecture using this model.
Additionally, we investigated the optimization technique, Low-Rank Adaptation
(LoRA), to enhance the pre-trained forecasting model for fine-tuning in
investment scenarios. This work bridges market forecasting and portfolio
selection, facilitating the advancement of investment strategies.

摘要：利用市場預測對於最佳化投資組合選擇策略至關重要。我們介紹 DeepClair，一個用於投資組合選擇的新穎架構。DeepClair 採用基於Transformer的時間序列預測模型來預測市場趨勢，促進更明智且適應性更強的投資組合決策。為了將預測模型整合到深度強化學習驅動的投資組合選擇架構中，我們引入了一個兩步驟策略：首先，使用市場數據對時間序列模型進行預訓練，然後使用此模型微調投資組合選擇架構。此外，我們研究了優化技術，低秩適應（LoRA），以增強預訓練的預測模型，以便在投資情境中進行微調。這項工作橋接了市場預測和投資組合選擇，促进了投資策略的進步。

##### **From Words to Worlds: Compositionality for Cognitive Architectures**
2407.13419v1 by Ruchira Dhar, Anders Søgaard

Large language models (LLMs) are very performant connectionist systems, but
do they exhibit more compositionality? More importantly, is that part of why
they perform so well? We present empirical analyses across four LLM families
(12 models) and three task categories, including a novel task introduced below.
Our findings reveal a nuanced relationship in learning of compositional
strategies by LLMs -- while scaling enhances compositional abilities,
instruction tuning often has a reverse effect. Such disparity brings forth some
open issues regarding the development and improvement of large language models
in alignment with human cognitive capacities.

摘要：大型語言模型 (LLM) 是效能極佳的連接主義系統，但它們是否展現更多組合性？更重要的是，這是否是它們表現如此出色的部分原因？我們針對四個 LLM 家族（12 個模型）和三項任務類別進行實證分析，包括以下介紹的新任務。我們的研究結果揭示了 LLM 在學習組合策略時微妙的關係——儘管擴充能增強組合能力，但指令調整通常會產生相反的效果。這種差異帶來了一些開放性的問題，關於大型語言模型的開發和改進是否與人類認知能力一致。

##### **DISCOVER: A Data-driven Interactive System for Comprehensive Observation, Visualization, and ExploRation of Human Behaviour**
2407.13408v1 by Dominik Schiller, Tobias Hallmen, Daksitha Withanage Don, Elisabeth André, Tobias Baur

Understanding human behavior is a fundamental goal of social sciences, yet
its analysis presents significant challenges. Conventional methodologies
employed for the study of behavior, characterized by labor-intensive data
collection processes and intricate analyses, frequently hinder comprehensive
exploration due to their time and resource demands. In response to these
challenges, computational models have proven to be promising tools that help
researchers analyze large amounts of data by automatically identifying
important behavioral indicators, such as social signals. However, the
widespread adoption of such state-of-the-art computational models is impeded by
their inherent complexity and the substantial computational resources necessary
to run them, thereby constraining accessibility for researchers without
technical expertise and adequate equipment. To address these barriers, we
introduce DISCOVER -- a modular and flexible, yet user-friendly software
framework specifically developed to streamline computational-driven data
exploration for human behavior analysis. Our primary objective is to
democratize access to advanced computational methodologies, thereby enabling
researchers across disciplines to engage in detailed behavioral analysis
without the need for extensive technical proficiency. In this paper, we
demonstrate the capabilities of DISCOVER using four exemplary data exploration
workflows that build on each other: Interactive Semantic Content Exploration,
Visual Inspection, Aided Annotation, and Multimodal Scene Search. By
illustrating these workflows, we aim to emphasize the versatility and
accessibility of DISCOVER as a comprehensive framework and propose a set of
blueprints that can serve as a general starting point for exploratory data
analysis.

摘要：<paragraph>了解人類行為是社會科學的基本目標，但其分析卻面臨著重大的挑戰。傳統上用於行為研究的方法，其特徵是勞動密集型的資料收集過程和複雜的分析，由於時間和資源需求，常常阻礙全面的探索。為了應對這些挑戰，計算模型已被證明是一種很有前途的工具，它可以通過自動識別重要的行為指標（例如社交信號）來幫助研究人員分析大量的資料。然而，這些最先進的計算模型的廣泛採用受到其固有的複雜性和運行它們所需的巨大計算資源的阻礙，從而限制了沒有技術專長和適當設備的研究人員的可及性。為了消除這些障礙，我們引入了 DISCOVER——一個模組化且靈活但又友好的軟體框架，專門開發用於簡化計算驅動的資料探索以進行人類行為分析。我們的首要目標是使先進的計算方法民主化，從而使各個學科的研究人員能夠從事詳細的行為分析，而無需廣泛的技術能力。在本文中，我們使用四個範例資料探索工作流程展示了 DISCOVER 的功能，這些工作流程相互建立：互動式語義內容探索、視覺檢查、輔助註解和多模態場景搜索。通過說明這些工作流程，我們旨在強調 DISCOVER 作為一個綜合框架的多功能性和可及性，並提出了一組藍圖，可以用作探索性資料分析的通用起點。</paragraph>

##### **Correcting the Mythos of KL-Regularization: Direct Alignment without Overparameterization via Chi-squared Preference Optimization**
2407.13399v1 by Audrey Huang, Wenhao Zhan, Tengyang Xie, Jason D. Lee, Wen Sun, Akshay Krishnamurthy, Dylan J. Foster

Language model alignment methods, such as reinforcement learning from human
feedback (RLHF), have led to impressive advances in language model
capabilities, but existing techniques are limited by a widely observed
phenomenon known as overoptimization, where the quality of the language model
plateaus or degrades over the course of the alignment process. Overoptimization
is often attributed to overfitting to an inaccurate reward model, and while it
can be mitigated through online data collection, this is infeasible in many
settings. This raises a fundamental question: Do existing offline alignment
algorithms make the most of the data they have, or can their sample-efficiency
be improved further?
  We address this question with a new algorithm for offline alignment,
$\chi^2$-Preference Optimization ($\chi$PO). $\chi$PO is a one-line change to
Direct Preference Optimization (DPO; Rafailov et al., 2023), which only
involves modifying the logarithmic link function in the DPO objective. Despite
this minimal change, $\chi$PO implicitly implements the principle of pessimism
in the face of uncertainty via regularization with the $\chi^2$-divergence --
which quantifies uncertainty more effectively than KL-regularization -- and
provably alleviates overoptimization, achieving sample-complexity guarantees
based on single-policy concentrability -- the gold standard in offline
reinforcement learning. $\chi$PO's simplicity and strong guarantees make it the
first practical and general-purpose offline alignment algorithm that is
provably robust to overoptimization.

摘要：語言模型對齊方法，例如人類回饋強化學習 (RLHF)，已導致語言模型能力的顯著進步，但現有技術受到廣泛觀察到的現象限制，稱為過度最佳化，其中語言模型的品質在對齊過程中達到平穩期或下降。過度最佳化通常歸因於過度擬合不準確的獎勵模型，雖然它可以透過線上資料收集來減輕，但在許多設定中這是不可行的。這引發了一個基本問題：現有的離線對齊演算法是否充分利用了他們擁有的資料，或者他們的樣本效率可以進一步提高？
我們使用一種新的離線對齊演算法來解決這個問題，即 $\chi^2$ 偏好最佳化（$\chi$PO）。$\chi$PO 是對直接偏好最佳化（DPO；Rafailov 等人，2023 年）的一行變更，它只涉及修改 DPO 目標中的對數連結函數。儘管有這個最小的變更，$\chi$PO 透過使用 $\chi^2$ 距離進行正則化，在面對不確定性時隱含地實作了悲觀原則，而 $\chi^2$ 距離比 KL 正則化更有效地量化了不確定性，並且可以證明地減輕過度最佳化，根據單一政策集中度實現樣本複雜度保證，這是離線強化學習中的黃金標準。$\chi$PO 的簡潔性和強有力的保證使其成為第一個實用的通用離線對齊演算法，它可以證明對過度最佳化具有魯棒性。

##### **Linear-Complexity Self-Supervised Learning for Speech Processing**
2407.13377v1 by Shucong Zhang, Titouan Parcollet, Rogier van Dalen, Sourav Bhattacharya

Self-supervised learning (SSL) models usually require weeks of pre-training
with dozens of high-end GPUs. These models typically have a multi-headed
self-attention (MHSA) context encoder. However, MHSA takes quadratic time and
space in the input length, contributing to the high pre-training cost.
Linear-complexity alternatives to MHSA have been proposed. For instance, in
supervised training, the SummaryMixing model is the first to outperform MHSA
across multiple speech processing tasks. However, these cheaper alternatives
have not been explored for SSL yet. This paper studies a linear-complexity
context encoder for SSL for the first time. With better or equivalent
performance for the downstream tasks of the MP3S benchmark, SummaryMixing
reduces the pre-training time and peak VRAM of wav2vec 2.0 model by 18% and by
23%, respectively, leading to the pre-training of a 155M wav2vec 2.0 model
finished within one week with 4 Tesla A100 GPUs. Code is available at
https://github.com/SamsungLabs/SummaryMixing.

摘要：自监督学习（SSL）模型通常需要数周的预训练，并使用数十个高端 GPU。这些模型通常具有多头自注意力（MHSA）上下文编码器。然而，MHSA 在输入长度上呈二次时间和空间，这导致了较高的预训练成本。已经提出了 MHSA 的线性复杂度替代方案。例如，在监督训练中，SummaryMixing 模型是第一个在多个语音处理任务中优于 MHSA 的模型。然而，这些更便宜的替代方案尚未用于 SSL。本文首次研究了 SSL 的线性复杂度上下文编码器。对于 MP3S 基准的下游任务，SummaryMixing 具有更好或相当的性能，它将 wav2vec 2.0 模型的预训练时间和峰值 VRAM 分别减少了 18% 和 23%，从而在不到一周的时间内使用 4 个 Tesla A100 GPU 完成了 155M wav2vec 2.0 模型的预训练。代码可在 https://github.com/SamsungLabs/SummaryMixing 获得。

##### **Capturing Style in Author and Document Representation**
2407.13358v1 by Enzo Terreau, Antoine Gourru, Julien Velcin

A wide range of Deep Natural Language Processing (NLP) models integrates
continuous and low dimensional representations of words and documents.
Surprisingly, very few models study representation learning for authors. These
representations can be used for many NLP tasks, such as author identification
and classification, or in recommendation systems. A strong limitation of
existing works is that they do not explicitly capture writing style, making
them hardly applicable to literary data. We therefore propose a new
architecture based on Variational Information Bottleneck (VIB) that learns
embeddings for both authors and documents with a stylistic constraint. Our
model fine-tunes a pre-trained document encoder. We stimulate the detection of
writing style by adding predefined stylistic features making the representation
axis interpretable with respect to writing style indicators. We evaluate our
method on three datasets: a literary corpus extracted from the Gutenberg
Project, the Blog Authorship Corpus and IMDb62, for which we show that it
matches or outperforms strong/recent baselines in authorship attribution while
capturing much more accurately the authors stylistic aspects.

摘要：廣泛的深度自然語言處理 (NLP) 模型整合了單詞和文件的連續且低維表示。令人驚訝的是，很少有模型研究作者的表示學習。這些表示可用於許多 NLP 任務，例如作者識別和分類，或推薦系統。現有工作的重大限制在於它們沒有明確捕捉寫作風格，這使得它們難以應用於文學數據。因此，我們提出了一種基於變分信息瓶頸 (VIB) 的新架構，該架構學習具有風格約束的作者和文件的嵌入。我們的模型微調了預先訓練的文檔編碼器。我們通過添加預定義的風格特徵來激勵寫作風格的檢測，從而使表示軸相對於寫作風格指標具有可解釋性。我們在三個數據集上評估了我們的模型：從古騰堡項目中提取的文學語料庫、博客作者語料庫和 IMDb62，我們展示了它在作者歸屬中匹配或優於強/最近的基準，同時更準確地捕捉作者的風格方面。

##### **Learning-From-Mistakes Prompting for Indigenous Language Translation**
2407.13343v1 by You-Cheng Liao, Chen-Jui Yu, Chi-Yi Lin, He-Feng Yun, Yen-Hsiang Wang, Hsiao-Min Li, Yao-Chung Fan

Using large language models, this paper presents techniques to improve
extremely low-resourced indigenous language translations. Our approaches are
grounded in the use of (1) the presence of a datastore consisting of a limited
number of parallel translation examples, (2) the inherent capabilities of LLMs
like GPT-3.5, and (3) a word-level translation dictionary. We harness the
potential of LLMs and in-context learning techniques in such a setting for
using LLMs as universal translators for extremely low-resourced languages. Our
methodology hinges on utilizing LLMs as language compilers for selected
language pairs, hypothesizing that they could internalize syntactic structures
to facilitate accurate translation. We introduce three techniques: KNNPrompting
with Retrieved Prompting Context, Chain-of-Thought Prompting and
Learningfrom-Mistakes Prompting, with the last method addressing past errors.
The evaluation results suggest that, even with limited corpora, LLMs can
effectively translate extremely low-resource languages when paired with proper
prompting.

摘要：利用大型語言模型，本文提出了改進極度低資源原住民語言翻譯的技術。我們的做法建立在以下基礎上：(1) 存在一個包含有限數量平行翻譯範例的資料庫，(2) GPT-3.5 等 LLM 的固有能力，以及 (3) 一個字級翻譯詞典。我們利用 LLM 的潛力以及情境學習技術，在這樣的環境中將 LLM 用作極度低資源語言的通用翻譯器。我們的技術取決於利用 LLM 作為特定語言對的語言編譯器，假設它們可以內化句法結構以促進準確翻譯。我們介紹了三種技術：帶有檢索提示語境的 KNNPrompting、思考鏈條提示語境和錯誤學習提示語境，最後一種方法解決了過去的錯誤。評估結果表明，即使在語料庫有限的情況下，LLM 在與適當提示配對時也能有效翻譯極度低資源語言。

##### **Why do you cite? An investigation on citation intents and decision-making classification processes**
2407.13329v1 by Lorenzo Paolini, Sahar Vahdati, Angelo Di Iorio, Robert Wardenga, Ivan Heibi, Silvio Peroni

Identifying the reason for which an author cites another work is essential to
understand the nature of scientific contributions and to assess their impact.
Citations are one of the pillars of scholarly communication and most metrics
employed to analyze these conceptual links are based on quantitative
observations. Behind the act of referencing another scholarly work there is a
whole world of meanings that needs to be proficiently and effectively revealed.
This study emphasizes the importance of trustfully classifying citation intents
to provide more comprehensive and insightful analyses in research assessment.
We address this task by presenting a study utilizing advanced Ensemble
Strategies for Citation Intent Classification (CIC) incorporating Language
Models (LMs) and employing Explainable AI (XAI) techniques to enhance the
interpretability and trustworthiness of models' predictions. Our approach
involves two ensemble classifiers that utilize fine-tuned SciBERT and XLNet LMs
as baselines. We further demonstrate the critical role of section titles as a
feature in improving models' performances. The study also introduces a web
application developed with Flask and currently available at
http://137.204.64.4:81/cic/classifier, aimed at classifying citation intents.
One of our models sets as a new state-of-the-art (SOTA) with an 89.46% Macro-F1
score on the SciCite benchmark. The integration of XAI techniques provides
insights into the decision-making processes, highlighting the contributions of
individual words for level-0 classifications, and of individual models for the
metaclassification. The findings suggest that the inclusion of section titles
significantly enhances classification performances in the CIC task. Our
contributions provide useful insights for developing more robust datasets and
methodologies, thus fostering a deeper understanding of scholarly
communication.

摘要：<paragraph>找出作者引用其他作品的原因對於了解科學貢獻的本質和評估其影響至關重要。
引用是學術交流的支柱之一，大多數用於分析這些概念連結的指標都基於定量觀察。在引用另一部學術作品的行為背後，存在著一個需要熟練且有效揭示的意義世界。
本研究強調了信賴地對引用意圖進行分類以在研究評估中提供更全面且有見地的分析的重要性。我們通過提出一項研究來解決此任務，該研究利用了先進的引用意圖分類 (CIC) 混合策略，結合了語言模型 (LM) 並採用可解釋 AI (XAI) 技術來增強模型預測的可解釋性和可信度。我們的做法涉及兩個混合分類器，它們利用微調後的 SciBERT 和 XLNet LM 作為基準。我們進一步證明了章節標題作為特徵在改善模型性能中的關鍵作用。該研究還介紹了一個使用 Flask 開發的 Web 應用程式，目前可在 http://137.204.64.4:81/cic/classifier 上使用，用於對引用意圖進行分類。我們的其中一個模型以 89.46% 的 SciCite 基準宏觀 F1 分數設定為新的最先進 (SOTA) 狀態。XAI 技術的整合提供了對決策過程的見解，突出了個別詞彙對 0 級分類的貢獻，以及個別模型對元分類的貢獻。研究結果表明，在 CIC 任務中加入章節標題可以顯著提高分類性能。我們的貢獻為開發更強大的資料集和方法論提供了有用的見解，從而促進了對學術交流的更深入理解。</paragraph>

##### **Deep Reinforcement Learning for Multi-Objective Optimization: Enhancing Wind Turbine Energy Generation while Mitigating Noise Emissions**
2407.13320v1 by Martín de Frutos, Oscar A. Marino, David Huergo, Esteban Ferrer

We develop a torque-pitch control framework using deep reinforcement learning
for wind turbines to optimize the generation of wind turbine energy while
minimizing operational noise. We employ a double deep Q-learning, coupled to a
blade element momentum solver, to enable precise control over wind turbine
parameters. In addition to the blade element momentum, we use the wind turbine
acoustic model of Brooks Pope and Marcolini. Through training with simple
winds, the agent learns optimal control policies that allow efficient control
for complex turbulent winds. Our experiments demonstrate that the reinforcement
learning is able to find optima at the Pareto front, when maximizing energy
while minimizing noise. In addition, the adaptability of the reinforcement
learning agent to changing turbulent wind conditions, underscores its efficacy
for real-world applications. We validate the methodology using a SWT2.3-93 wind
turbine with a rated power of 2.3 MW. We compare the reinforcement learning
control to classic controls to show that they are comparable when not taking
into account noise emissions. When including a maximum limit of 45 dB to the
noise produced (100 meters downwind of the turbine), the extracted yearly
energy decreases by 22%. The methodology is flexible and allows for easy tuning
of the objectives and constraints through the reward definitions, resulting in
a flexible multi-objective optimization framework for wind turbine control.
Overall, our findings highlight the potential of RL-based control strategies to
improve wind turbine efficiency while mitigating noise pollution, thus
advancing sustainable energy generation technologies

摘要：<paragraph>我們使用深度強化學習開發一種扭矩俯仰控制架構，用於風力渦輪機，以最佳化風力渦輪機能量的產生，同時最小化運作噪音。我們採用雙重深度 Q 學習，結合葉片元素動量求解器，以精確控制風力渦輪機參數。除了葉片元素動量外，我們還使用 Brooks Pope 和 Marcolini 的風力渦輪機聲學模型。透過使用簡單風力進行訓練，代理程式會學習最佳控制政策，以允許對複雜湍流風進行有效控制。我們的實驗證明，強化學習能夠在帕累托前緣找到最佳值，同時最大化能量並最小化噪音。此外，強化學習代理程式對不斷變化的湍流風狀況的適應性，強調了其在實際應用中的功效。我們使用額定功率為 2.3 MW 的 SWT2.3-93 風力渦輪機驗證方法。我們將強化學習控制與傳統控制進行比較，以表明在不考慮噪音排放時它們是可比較的。當將 45 dB 的最大限制納入渦輪機下風處 100 公尺處產生的噪音時，提取的年能量會減少 22%。該方法靈活，允許透過獎勵定義輕鬆調整目標和約束，從而形成一個靈活的多目標最佳化架構，用於風力渦輪機控制。總體而言，我們的研究結果突出了基於 RL 的控制策略在提高風力渦輪機效率的同時減輕噪音污染的潛力，從而推進永續能源產生技術。</paragraph>

##### **Sortability of Time Series Data**
2407.13313v1 by Christopher Lohse, Jonas Wahl

Evaluating the performance of causal discovery algorithms that aim to find
causal relationships between time-dependent processes remains a challenging
topic. In this paper, we show that certain characteristics of datasets, such as
varsortability (Reisach et al. 2021) and $R^2$-sortability (Reisach et al.
2023), also occur in datasets for autocorrelated stationary time series. We
illustrate this empirically using four types of data: simulated data based on
SVAR models and Erd\H{o}s-R\'enyi graphs, the data used in the 2019
causality-for-climate challenge (Runge et al. 2019), real-world river stream
datasets, and real-world data generated by the Causal Chamber of (Gamella et
al. 2024). To do this, we adapt var- and $R^2$-sortability to time series data.
We also investigate the extent to which the performance of score-based causal
discovery methods goes hand in hand with high sortability. Arguably, our most
surprising finding is that the investigated real-world datasets exhibit high
varsortability and low $R^2$-sortability indicating that scales may carry a
significant amount of causal information.

摘要：評估旨在找出時間相關程序之間因果關係的因果發現演算法的效能，仍然是一個具有挑戰性的主題。在本文中，我們展示了資料集的某些特徵，例如變異排序（Reisach 等人 2021 年）和 R2 排序（Reisach 等人 2023 年），也出現在自相關平穩時間序列的資料集中。我們使用四種類型的資料以實證方式說明這一點：基於 SVAR 模型和 Erd\H{o}s-R\'enyi 圖形模擬的資料、2019 年因果關係氣候挑戰（Runge 等人 2019 年）中使用的資料、真實世界的河流串流資料集，以及由因果室（Gamella 等人 2024 年）產生的真實世界資料。為此，我們將變異和 R2 排序調整為時間序列資料。我們還探討了基於分數的因果發現方法的效能與高排序性之間的關係。可以說，我們最令人驚訝的發現是，所研究的真實世界資料集展現出高變異排序和低 R2 排序，這表示尺度可能承載大量的因果資訊。

##### **CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis**
2407.13301v1 by Junying Chen, Chi Gui, Anningzhe Gao, Ke Ji, Xidong Wang, Xiang Wan, Benyou Wang

The field of medical diagnosis has undergone a significant transformation
with the advent of large language models (LLMs), yet the challenges of
interpretability within these models remain largely unaddressed. This study
introduces Chain-of-Diagnosis (CoD) to enhance the interpretability of
LLM-based medical diagnostics. CoD transforms the diagnostic process into a
diagnostic chain that mirrors a physician's thought process, providing a
transparent reasoning pathway. Additionally, CoD outputs the disease confidence
distribution to ensure transparency in decision-making. This interpretability
makes model diagnostics controllable and aids in identifying critical symptoms
for inquiry through the entropy reduction of confidences. With CoD, we
developed DiagnosisGPT, capable of diagnosing 9604 diseases. Experimental
results demonstrate that DiagnosisGPT outperforms other LLMs on diagnostic
benchmarks. Moreover, DiagnosisGPT provides interpretability while ensuring
controllability in diagnostic rigor.

摘要：隨著大型語言模型 (LLM) 的出現，醫療診斷領域經歷了一場重大轉型，但這些模型的可解釋性挑戰在很大程度上仍未得到解決。本研究引入了診斷鏈 (CoD) 來增強基於 LLM 的醫療診斷的可解釋性。CoD 將診斷過程轉換為一個診斷鏈，反映了醫生的思考過程，提供了一條透明的推理路徑。此外，CoD 輸出了疾病置信度分佈，以確保決策透明度。這種可解釋性使模型診斷可控，並有助於通過置信度的熵減來識別需要詢問的關鍵症狀。使用 CoD，我們開發了 DiagnosisGPT，它能夠診斷 9604 種疾病。實驗結果表明，DiagnosisGPT 在診斷基準上優於其他 LLM。此外，DiagnosisGPT 在確保診斷嚴謹性可控性的同時提供了可解釋性。

##### **Robust ASR Error Correction with Conservative Data Filtering**
2407.13300v1 by Takuma Udagawa, Masayuki Suzuki, Masayasu Muraoka, Gakuto Kurata

Error correction (EC) based on large language models is an emerging
technology to enhance the performance of automatic speech recognition (ASR)
systems. Generally, training data for EC are collected by automatically pairing
a large set of ASR hypotheses (as sources) and their gold references (as
targets). However, the quality of such pairs is not guaranteed, and we observed
various types of noise which can make the EC models brittle, e.g. inducing
overcorrection in out-of-domain (OOD) settings. In this work, we propose two
fundamental criteria that EC training data should satisfy: namely, EC targets
should (1) improve linguistic acceptability over sources and (2) be inferable
from the available context (e.g. source phonemes). Through these criteria, we
identify low-quality EC pairs and train the models not to make any correction
in such cases, the process we refer to as conservative data filtering. In our
experiments, we focus on Japanese ASR using a strong Conformer-CTC as the
baseline and finetune Japanese LLMs for EC. Through our evaluation on a suite
of 21 internal benchmarks, we demonstrate that our approach can significantly
reduce overcorrection and improve both the accuracy and quality of ASR results
in the challenging OOD settings.

摘要：基於大型語言模型的錯誤修正 (EC) 是一種新興技術，用於提升自動語音辨識 (ASR) 系統的效能。一般來說，EC 的訓練資料會透過自動配對大量的 ASR 假設（作為來源）和其黃金參考（作為目標）來收集。然而，這些配對的品質並非有保證，而且我們觀察到各種類型的雜訊，這些雜訊可能會讓 EC 模型變得脆弱，例如在領域外 (OOD) 設定中導致過度修正。在這項工作中，我們提出了 EC 訓練資料應該滿足的兩個基本準則：也就是說，EC 目標應該 (1) 改善來源的語言可接受度，以及 (2) 可以從可用脈絡（例如來源音素）推論出來。透過這些準則，我們找出低品質的 EC 配對，並訓練模型在這種情況下不進行任何修正，這個過程我們稱為保守資料過濾。在我們的實驗中，我們專注於使用強大的 Conformer-CTC 作為基準的日語 ASR，並微調日語 LLM 以進行 EC。透過我們對 21 個內部基準的評估，我們證明了我們的方法可以大幅減少過度修正，並改善 ASR 結果在具有挑戰性的 OOD 設定中的準確度和品質。

##### **SpeciaLex: A Benchmark for In-Context Specialized Lexicon Learning**
2407.13297v1 by Joseph Marvin Imperial, Harish Tayyar Madabushi

Specialized lexicons are collections of words with associated constraints
such as special definitions, specific roles, and intended target audiences.
These constraints are necessary for content generation and documentation tasks
(e.g., writing technical manuals or children's books), where the goal is to
reduce the ambiguity of text content and increase its overall readability for a
specific group of audience. Understanding how large language models can capture
these constraints can help researchers build better, more impactful tools for
wider use beyond the NLP community. Towards this end, we introduce SpeciaLex, a
benchmark for evaluating a language model's ability to follow specialized
lexicon-based constraints across 18 diverse subtasks with 1,285 test instances
covering core tasks of Checking, Identification, Rewriting, and Open
Generation. We present an empirical evaluation of 15 open and closed-source
LLMs and discuss insights on how factors such as model scale, openness, setup,
and recency affect performance upon evaluating with the benchmark.

摘要：專業詞彙表是具備相關約束的詞彙集合，例如特殊定義、特定角色和預期的目標受眾。這些約束對於內容產生和文件編寫任務（例如撰寫技術手冊或兒童讀物）是必要的，因為目標是減少文字內容的歧義性，並提高其針對特定受眾群體的整體可讀性。了解大型語言模型如何捕捉這些約束，有助於研究人員為 NLP 社群以外更廣泛的用途建構更好、更具影響力的工具。為此，我們引入了 SpeciaLex，這是一個基準，用於評估語言模型遵循專業詞彙表約束的能力，涵蓋 18 個不同的子任務，其中有 1,285 個測試實例，涵蓋檢查、識別、重寫和開放式產生的核心任務。我們對 15 個開放和閉源 LLM 進行了實證評估，並討論了模型規模、開放性、設定和新近性等因素如何影響基準評估效能的見解。

##### **Low-Resourced Speech Recognition for Iu Mien Language via Weakly-Supervised Phoneme-based Multilingual Pre-training**
2407.13292v1 by Lukuan Dong, Donghong Qin, Fengbo Bai, Fanhua Song, Yan Liu, Chen Xu, Zhijian Ou

The mainstream automatic speech recognition (ASR) technology usually requires
hundreds to thousands of hours of annotated speech data. Three approaches to
low-resourced ASR are phoneme or subword based supervised pre-training, and
self-supervised pre-training over multilingual data. The Iu Mien language is
the main ethnic language of the Yao ethnic group in China and is low-resourced
in the sense that the annotated speech is very limited. With less than 10 hours
of transcribed Iu Mien language, this paper investigates and compares the three
approaches for Iu Mien speech recognition. Our experiments are based on the
recently released, three backbone models pretrained over the 10 languages from
the CommonVoice dataset (CV-Lang10), which correspond to the three approaches
for low-resourced ASR. It is found that phoneme supervision can achieve better
results compared to subword supervision and self-supervision, thereby providing
higher data-efficiency. Particularly, the Whistle models, i.e., obtained by the
weakly-supervised phoneme-based multilingual pre-training, obtain the most
competitive results.

摘要：主流的自動語音辨識（ASR）技術通常需要數百到數千小時的標註語音資料。低資源 ASR 的三種方法是基於音素或子字的監督式預訓練，以及多語言資料的自我監督式預訓練。勉語是中國瑤族的主要民族語言，在標註語音非常有限的意義上屬於低資源語言。本文使用不到 10 小時的轉錄勉語，探討並比較了勉語語音辨識的這三種方法。我們的實驗基於最近發布的三個主幹模型，它們在 CommonVoice 資料集（CV-Lang10）的 10 種語言上進行了預訓練，這三種方法分別對應於低資源 ASR 的三種方法。研究發現，與子字監督和自我監督相比，音素監督可以獲得更好的結果，從而提供更高的資料效率。特別是 Whistle 模型，即透過弱監督音素為基礎的多語言預訓練獲得的模型，獲得了最具競爭力的結果。

##### **Mixture of Experts based Multi-task Supervise Learning from Crowds**
2407.13268v1 by Tao Han, Huaixuan Shi, Xinyi Ding, Xiao Ma, Huamao Gu, Yili Fang

Existing truth inference methods in crowdsourcing aim to map redundant labels
and items to the ground truth. They treat the ground truth as hidden variables
and use statistical or deep learning-based worker behavior models to infer the
ground truth. However, worker behavior models that rely on ground truth hidden
variables overlook workers' behavior at the item feature level, leading to
imprecise characterizations and negatively impacting the quality of truth
inference. This paper proposes a new paradigm of multi-task supervised learning
from crowds, which eliminates the need for modeling of items's ground truth in
worker behavior models. Within this paradigm, we propose a worker behavior
model at the item feature level called Mixture of Experts based Multi-task
Supervised Learning from Crowds (MMLC). Two truth inference strategies are
proposed within MMLC. The first strategy, named MMLC-owf, utilizes clustering
methods in the worker spectral space to identify the projection vector of the
oracle worker. Subsequently, the labels generated based on this vector are
considered as the inferred truth. The second strategy, called MMLC-df, employs
the MMLC model to fill the crowdsourced data, which can enhance the
effectiveness of existing truth inference methods. Experimental results
demonstrate that MMLC-owf outperforms state-of-the-art methods and MMLC-df
enhances the quality of existing truth inference methods.

摘要：現有的群眾外包真實性推論方法旨在將重複標籤和項目對應到基本事實。他們將基本事實視為隱藏變數，並使用基於統計或深度學習的工作者行為模型來推論基本事實。然而，依賴於基本事實隱藏變數的工作者行為模型忽略了工作者在項目特徵層級的行為，導致不精確的表徵並對真實性推論的品質產生負面影響。本文提出了一種新的多任務監督式學習典範，從群眾中消除了對工作者行為模型中項目基本事實建模的需求。在這個典範中，我們提出了在項目特徵層級的工作者行為模型，稱為基於專家混合的多任務監督式學習（MMLC）。在 MMLC 中提出了兩種真實性推論策略。第一個策略稱為 MMLC-owf，利用工作者光譜空間中的分群方法來識別神諭工作者的投影向量。隨後，基於此向量產生的標籤被視為推論出的真實性。第二個策略稱為 MMLC-df，採用 MMLC 模型來填補群眾外包資料，這可以提升現有真實性推論方法的效能。實驗結果證明，MMLC-owf 優於最先進的方法，而 MMLC-df 則提升了現有真實性推論方法的品質。

##### **Are Large Language Models Capable of Generating Human-Level Narratives?**
2407.13248v1 by Yufei Tian, Tenghao Huang, Miri Liu, Derek Jiang, Alexander Spangher, Muhao Chen, Jonathan May, Nanyun Peng

This paper investigates the capability of LLMs in storytelling, focusing on
narrative development and plot progression. We introduce a novel computational
framework to analyze narratives through three discourse-level aspects: i) story
arcs, ii) turning points, and iii) affective dimensions, including arousal and
valence. By leveraging expert and automatic annotations, we uncover significant
discrepancies between the LLM- and human- written stories. While human-written
stories are suspenseful, arousing, and diverse in narrative structures, LLM
stories are homogeneously positive and lack tension. Next, we measure narrative
reasoning skills as a precursor to generative capacities, concluding that most
LLMs fall short of human abilities in discourse understanding. Finally, we show
that explicit integration of aforementioned discourse features can enhance
storytelling, as is demonstrated by over 40% improvement in neural storytelling
in terms of diversity, suspense, and arousal.

摘要：本文探討了大型語言模型 (LLM) 在講故事方面的能力，重點在於敘事發展和情節進展。我們引入了一個新穎的計算框架，通過三個話語層面來分析敘事：i) 故事弧、ii) 轉折點，以及 iii) 情感維度，包括喚醒和效價。透過利用專家和自動註解，我們發現 LLM 和人類撰寫的故事之間存在顯著差異。雖然人類撰寫的故事懸疑、激動人心，且在敘事結構上多樣化，但 LLM 的故事同質性地正面且缺乏張力。接下來，我們衡量敘事推理技能作為生成能力的前身，得出結論，大多數 LLM 在話語理解方面遠不及人類的能力。最後，我們表明前述話語特徵的明確整合可以增強講故事的能力，正如在神經故事講述中，多樣性、懸念和喚醒方面有超過 40% 的改進所證明的那樣。

##### **PM-LLM-Benchmark: Evaluating Large Language Models on Process Mining Tasks**
2407.13244v1 by Alessandro Berti, Humam Kourani, Wil M. P. van der Aalst

Large Language Models (LLMs) have the potential to semi-automate some process
mining (PM) analyses. While commercial models are already adequate for many
analytics tasks, the competitive level of open-source LLMs in PM tasks is
unknown. In this paper, we propose PM-LLM-Benchmark, the first comprehensive
benchmark for PM focusing on domain knowledge (process-mining-specific and
process-specific) and on different implementation strategies. We focus also on
the challenges in creating such a benchmark, related to the public availability
of the data and on evaluation biases by the LLMs. Overall, we observe that most
of the considered LLMs can perform some process mining tasks at a satisfactory
level, but tiny models that would run on edge devices are still inadequate. We
also conclude that while the proposed benchmark is useful for identifying LLMs
that are adequate for process mining tasks, further research is needed to
overcome the evaluation biases and perform a more thorough ranking of the
competitive LLMs.

摘要：大型語言模型 (LLM) 有潛力半自動化一些流程
探勘 (PM) 分析。儘管商業模型已足夠應付許多
分析任務，但開放原始碼 LLM 在 PM 任務中的競爭力仍
未知。在本文中，我們提出 PM-LLM-Benchmark，這是第一個針對 PM 的全面性基準測試，著重於領域知識（流程探勘專用和流程專用）和不同的實作策略。我們也專注於建立此類基準測試的挑戰，這與資料的公開可用性及 LLM 的評量偏差有關。整體而言，我們觀察到大多數考慮的 LLM 都能以令人滿意的水準執行一些流程探勘任務，但會在邊緣裝置上執行的微小模型仍不足夠。我們也總結，儘管建議的基準測試有助於找出適合流程探勘任務的 LLM，但需要進一步的研究來克服評量偏差並對具競爭力的 LLM 執行更徹底的排名。

##### **NODER: Image Sequence Regression Based on Neural Ordinary Differential Equations**
2407.13241v1 by Hao Bai, Yi Hong

Regression on medical image sequences can capture temporal image pattern
changes and predict images at missing or future time points. However, existing
geodesic regression methods limit their regression performance by a strong
underlying assumption of linear dynamics, while diffusion-based methods have
high computational costs and lack constraints to preserve image topology. In
this paper, we propose an optimization-based new framework called NODER, which
leverages neural ordinary differential equations to capture complex underlying
dynamics and reduces its high computational cost of handling high-dimensional
image volumes by introducing the latent space. We compare our NODER with two
recent regression methods, and the experimental results on ADNI and ACDC
datasets demonstrate that our method achieves the state-of-the-art performance
in 3D image regression. Our model needs only a couple of images in a sequence
for prediction, which is practical, especially for clinical situations where
extremely limited image time series are available for analysis. Our source code
is available at https://github.com/ZedKing12138/NODER-pytorch.

摘要：回歸醫療影像序列可以捕捉時間影像模式變化，並預測遺失或未來時間點的影像。然而，現有的測地線迴歸方法限制其迴歸效能，因為其強烈依賴線性動態的基本假設，而基於擴散的方法則具有很高的運算成本，而且缺乏保留影像拓撲的約束。在本文中，我們提出一個稱為 NODER 的基於最佳化的全新架構，它利用神經常微分方程式來捕捉複雜的底層動態，並透過引入潛在空間來降低處理高維度影像體積的高運算成本。我們將 NODER 與兩種最近的迴歸方法進行比較，在 ADNI 和 ACDC 資料集上的實驗結果證明，我們的模型在 3D 影像迴歸中取得了最先進的效能。我們的模型只需要序列中幾個影像即可進行預測，這很實用，特別是在臨床情況下，極其有限的影像時間序列可供分析。我們的原始程式碼可在 https://github.com/ZedKing12138/NODER-pytorch 取得。

##### **LLM-Empowered State Representation for Reinforcement Learning**
2407.13237v1 by Boyuan Wang, Yun Qu, Yuhang Jiang, Jianzhun Shao, Chang Liu, Wenming Yang, Xiangyang Ji

Conventional state representations in reinforcement learning often omit
critical task-related details, presenting a significant challenge for value
networks in establishing accurate mappings from states to task rewards.
Traditional methods typically depend on extensive sample learning to enrich
state representations with task-specific information, which leads to low sample
efficiency and high time costs. Recently, surging knowledgeable large language
models (LLM) have provided promising substitutes for prior injection with
minimal human intervention. Motivated by this, we propose LLM-Empowered State
Representation (LESR), a novel approach that utilizes LLM to autonomously
generate task-related state representation codes which help to enhance the
continuity of network mappings and facilitate efficient training. Experimental
results demonstrate LESR exhibits high sample efficiency and outperforms
state-of-the-art baselines by an average of 29% in accumulated reward in Mujoco
tasks and 30% in success rates in Gym-Robotics tasks.

摘要：傳統的強化學習中的狀態表示通常會遺漏
與任務相關的關鍵細節，這對價值
網路在建立從狀態到任務獎勵的精確對應時會造成重大的挑戰。
傳統方法通常依賴於廣泛的樣本學習，以豐富
任務特定資訊的狀態表示，這會導致低樣本
效率和高時間成本。最近，激增的知識型大型語言
模型 (LLM) 已經提供了有希望的替代方案，可以透過
最少的人工介入來進行先前的注入。受此啟發，我們提出 LLM 強化狀態
表示 (LESR)，這是一種利用 LLM 自主
產生與任務相關的狀態表示碼的新方法，有助於增強
網路對應的連續性並促進有效訓練。實驗
結果證明 LESR 展現出高樣本效率，並且在 Mujoco
任務中累積獎勵的表現比最先進的基準高出平均 29%，而在 Gym-Robotics 任務中的成功率則高出 30%。

##### **Evaluating Large Language Models for Anxiety and Depression Classification using Counseling and Psychotherapy Transcripts**
2407.13228v1 by Junwei Sun, Siqi Ma, Yiran Fan, Peter Washington

We aim to evaluate the efficacy of traditional machine learning and large
language models (LLMs) in classifying anxiety and depression from long
conversational transcripts. We fine-tune both established transformer models
(BERT, RoBERTa, Longformer) and more recent large models (Mistral-7B), trained
a Support Vector Machine with feature engineering, and assessed GPT models
through prompting. We observe that state-of-the-art models fail to enhance
classification outcomes compared to traditional machine learning methods.

摘要：我們旨在評估傳統機器學習和大型語言模型 (LLM) 在根據冗長的對話記錄對焦慮和憂鬱進行分類的效能。我們微調既有的Transformer模型 (BERT、RoBERTa、Longformer) 和更新的大型模型 (Mistral-7B)，訓練具備特徵工程的支援向量機，並透過提示評估 GPT 模型。我們觀察到，與傳統機器學習方法相比，最先進的模型無法提升分類結果。

##### **LiNR: Model Based Neural Retrieval on GPUs at LinkedIn**
2407.13218v1 by Fedor Borisyuk, Qingquan Song, Mingzhou Zhou, Ganesh Parameswaran, Madhu Arun, Siva Popuri, Tugrul Bingol, Zhuotao Pei, Kuang-Hsuan Lee, Lu Zheng, Qizhan Shao, Ali Naqvi, Sen Zhou, Aman Gupta

This paper introduces LiNR, LinkedIn's large-scale, GPU-based retrieval
system. LiNR supports a billion-sized index on GPU models. We discuss our
experiences and challenges in creating scalable, differentiable search indexes
using TensorFlow and PyTorch at production scale. In LiNR, both items and model
weights are integrated into the model binary. Viewing index construction as a
form of model training, we describe scaling our system for large indexes,
incorporating full scans and efficient filtering. A key focus is on enabling
attribute-based pre-filtering for exhaustive GPU searches, addressing the
common challenge of post-filtering in KNN searches that often reduces system
quality. We further provide multi-embedding retrieval algorithms and strategies
for tackling cold start issues in retrieval. Our advancements in supporting
larger indexes through quantization are also discussed. We believe LiNR
represents one of the industry's first Live-updated model-based retrieval
indexes. Applied to out-of-network post recommendations on LinkedIn Feed, LiNR
has contributed to a 3% relative increase in professional daily active users.
We envisage LiNR as a step towards integrating retrieval and ranking into a
single GPU model, simplifying complex infrastructures and enabling end-to-end
optimization of the entire differentiable infrastructure through gradient
descent.

摘要：本文介绍了 LinkedIn 的大规模基于 GPU 的检索系统 LiNR。LiNR 在 GPU 模型上支持十亿级索引。我们讨论了使用 TensorFlow 和 PyTorch 在生产规模上创建可扩展、可微分搜索索引的经验和挑战。在 LiNR 中，项目和模型权重都集成到了模型二进制文件中。将索引构建视为一种模型训练形式，我们描述了针对大型索引扩展我们的系统，结合了全扫描和高效过滤。一个重点是针对穷举 GPU 搜索启用基于属性的预过滤，解决了 KNN 搜索中常见的后过滤挑战，而后过滤通常会降低系统质量。我们进一步提供了多嵌入检索算法和策略，以解决检索中的冷启动问题。我们还讨论了通过量化支持更大索引的进展。我们相信 LiNR 代表了业界首批基于实时更新模型的检索索引之一。应用于 LinkedIn Feed 上的网络外帖子推荐，LiNR 已为专业日活跃用户增加了 3% 的相对增长。我们设想 LiNR 是将检索和排名集成到单一 GPU 模型中的一步，简化复杂的架构并通过梯度下降实现整个可微分架构的端到端优化。

##### **Transformer-based Single-Cell Language Model: A Survey**
2407.13205v1 by Wei Lan, Guohang He, Mingyang Liu, Qingfeng Chen, Junyue Cao, Wei Peng

The transformers have achieved significant accomplishments in the natural
language processing as its outstanding parallel processing capabilities and
highly flexible attention mechanism. In addition, increasing studies based on
transformers have been proposed to model single-cell data. In this review, we
attempt to systematically summarize the single-cell language models and
applications based on transformers. First, we provide a detailed introduction
about the structure and principles of transformers. Then, we review the
single-cell language models and large language models for single-cell data
analysis. Moreover, we explore the datasets and applications of single-cell
language models in downstream tasks such as batch correction, cell clustering,
cell type annotation, gene regulatory network inference and perturbation
response. Further, we discuss the challenges of single-cell language models and
provide promising research directions. We hope this review will serve as an
up-to-date reference for researchers interested in the direction of single-cell
language models.

摘要：Transformer在自然語言處理方面取得了顯著的成就，因為它出色的並行處理能力和高度靈活的注意機制。此外，已經提出越來越多的基於Transformer的研究來對單細胞數據建模。在這篇評論中，我們嘗試系統地總結基於Transformer的單細胞語言模型和應用。首先，我們詳細介紹Transformer的結構和原理。然後，我們回顧單細胞語言模型和大語言模型，以進行單細胞數據分析。此外，我們探索單細胞語言模型在批次校正、細胞聚類、細胞類型註解、基因調控網路推論和擾動反應等下游任務中的數據集和應用。此外，我們討論了單細胞語言模型的挑戰，並提供了有前景的研究方向。我們希望這篇評論能作為對單細胞語言模型方向感興趣的研究人員的最新參考。

##### **Adaptive Foundation Models for Online Decisions: HyperAgent with Fast Incremental Uncertainty Estimation**
2407.13195v1 by Yingru Li, Jiawei Xu, Zhi-Quan Luo

Foundation models often struggle with uncertainty when faced with new
situations in online decision-making, necessitating scalable and efficient
exploration to resolve this uncertainty. We introduce GPT-HyperAgent, an
augmentation of GPT with HyperAgent for uncertainty-aware, scalable exploration
in contextual bandits, a fundamental online decision problem involving natural
language input. We prove that HyperAgent achieves fast incremental uncertainty
estimation with $\tilde{O}(\log T)$ per-step computational complexity over $T$
periods under the linear realizable assumption. Our analysis demonstrates that
HyperAgent's regret order matches that of exact Thompson sampling in linear
contextual bandits, closing a significant theoretical gap in scalable
exploration. Empirical results in real-world contextual bandit tasks, such as
automated content moderation with human feedback, validate the practical
effectiveness of GPT-HyperAgent for safety-critical decisions. Our code is
open-sourced at \url{https://github.com/szrlee/GPT-HyperAgent/}.

摘要：基礎模型在面對線上決策的新情況時，通常會對不確定性感到困難，這需要可擴充且有效的探索來解決此不確定性。我們引入了 GPT-HyperAgent，這是 GPT 的擴充，具有不確定性感知、可擴充的探索，可用於情境強盜，這是一個涉及自然語言輸入的基本線上決策問題。我們證明了 HyperAgent 在線性可實現假設下，在 T 個週期內以每個步驟 $\tilde{O}(\log T)$ 的計算複雜度，實現快速遞增的不確定性估計。我們的分析表明，HyperAgent 的後悔順序與線性情境強盜中精確的 Thompson 抽樣相匹配，縮小了可擴充探索中的顯著理論差距。在現實世界的上下文強盜任務中的經驗結果，例如帶有人類回饋的自動內容審核，驗證了 GPT-HyperAgent 在安全關鍵決策中的實際有效性。我們的程式碼在 \url{https://github.com/szrlee/GPT-HyperAgent/} 開源。

##### **Robust Multivariate Time Series Forecasting against Intra- and Inter-Series Transitional Shift**
2407.13194v1 by Hui He, Qi Zhang, Kun Yi, Xiaojun Xue, Shoujin Wang, Liang Hu, Longbing Cao

The non-stationary nature of real-world Multivariate Time Series (MTS) data
presents forecasting models with a formidable challenge of the time-variant
distribution of time series, referred to as distribution shift. Existing
studies on the distribution shift mostly adhere to adaptive normalization
techniques for alleviating temporal mean and covariance shifts or time-variant
modeling for capturing temporal shifts. Despite improving model generalization,
these normalization-based methods often assume a time-invariant transition
between outputs and inputs but disregard specific intra-/inter-series
correlations, while time-variant models overlook the intrinsic causes of the
distribution shift. This limits model expressiveness and interpretability of
tackling the distribution shift for MTS forecasting. To mitigate such a
dilemma, we present a unified Probabilistic Graphical Model to Jointly
capturing intra-/inter-series correlations and modeling the time-variant
transitional distribution, and instantiate a neural framework called JointPGM
for non-stationary MTS forecasting. Specifically, JointPGM first employs
multiple Fourier basis functions to learn dynamic time factors and designs two
distinct learners: intra-series and inter-series learners. The intra-series
learner effectively captures temporal dynamics by utilizing temporal gates,
while the inter-series learner explicitly models spatial dynamics through
multi-hop propagation, incorporating Gumbel-softmax sampling. These two types
of series dynamics are subsequently fused into a latent variable, which is
inversely employed to infer time factors, generate final prediction, and
perform reconstruction. We validate the effectiveness and efficiency of
JointPGM through extensive experiments on six highly non-stationary MTS
datasets, achieving state-of-the-art forecasting performance of MTS
forecasting.

摘要：真實世界多變量時間序列 (MTS) 資料的非平穩特性為預測模型帶來了時間變異時間序列分佈的重大挑戰，稱為分佈轉移。現有關於分佈轉移的研究大多採用自適應正規化技術來減輕時間平均值和協方差轉移，或採用時間變異模型來捕捉時間轉移。儘管改善了模型泛化，但這些基於正規化的方法通常假設輸出和輸入之間的時間不變轉換，但忽略了特定的序列內/序列間相關性，而時間變異模型則忽略了分佈轉移的內在原因。這限制了模型表達能力和對 MTS 預測分佈轉移的解釋能力。為了緩解這種困境，我們提出了一個統一的機率圖形模型來聯合捕捉序列內/序列間相關性並對時間變異過渡分佈進行建模，並實例化一個名為 JointPGM 的神經框架，用於非平穩 MTS 預測。具體來說，JointPGM 首先採用多個傅立葉基函數來學習動態時間因子，並設計了兩個不同的學習器：序列內學習器和序列間學習器。序列內學習器通過利用時間門有效地捕捉時間動態，而序列間學習器通過多跳傳播明確地對空間動態進行建模，並結合了 Gumbel-softmax 採樣。這兩種序列動態隨後融合成一個潛在變數，該變數被反向用於推論時間因子、產生最終預測並執行重建。我們通過在六個高度非平穩 MTS 資料集上進行廣泛的實驗驗證了 JointPGM 的有效性和效率，達到了 MTS 預測的最新預測性能。

##### **Retrieval-Augmented Generation for Natural Language Processing: A Survey**
2407.13193v2 by Shangyu Wu, Ying Xiong, Yufei Cui, Haolun Wu, Can Chen, Ye Yuan, Lianming Huang, Xue Liu, Tei-Wei Kuo, Nan Guan, Chun Jason Xue

Large language models (LLMs) have demonstrated great success in various
fields, benefiting from their huge amount of parameters that store knowledge.
However, LLMs still suffer from several key issues, such as hallucination
problems, knowledge update issues, and lacking domain-specific expertise. The
appearance of retrieval-augmented generation (RAG), which leverages an external
knowledge database to augment LLMs, makes up those drawbacks of LLMs. This
paper reviews all significant techniques of RAG, especially in the retriever
and the retrieval fusions. Besides, tutorial codes are provided for
implementing the representative techniques in RAG. This paper further discusses
the RAG training, including RAG with/without datastore update. Then, we
introduce the application of RAG in representative natural language processing
tasks and industrial scenarios. Finally, this paper discusses the future
directions and challenges of RAG for promoting its development.

摘要：大型語言模型 (LLM) 在各個領域都展現出極佳的成果，受益於其儲存知識的龐大參數量。
然而，LLM 仍有幾個關鍵問題，例如幻覺問題、知識更新問題，以及缺乏特定領域的專業知識。
檢索增強生成 (RAG) 的出現，它利用外部知識庫來擴充 LLM，彌補了 LLM 的這些缺點。
本文回顧了 RAG 的所有重要技術，特別是在檢索器和檢索融合中。
此外，還提供了教學程式碼，用於在 RAG 中實作代表性技術。
本文進一步討論了 RAG 訓練，包括有/無資料庫更新的 RAG。
然後，我們介紹了 RAG 在代表性自然語言處理任務和產業場景中的應用。
最後，本文討論了 RAG 未來發展的方向和挑戰，以促進其發展。

##### **SpaDiT: Diffusion Transformer for Spatial Gene Expression Prediction using scRNA-seq**
2407.13182v1 by Xiaoyu Li, Fangfang Zhu, Wenwen Min

The rapid development of spatial transcriptomics (ST) technologies is
revolutionizing our understanding of the spatial organization of biological
tissues. Current ST methods, categorized into next-generation sequencing-based
(seq-based) and fluorescence in situ hybridization-based (image-based) methods,
offer innovative insights into the functional dynamics of biological tissues.
However, these methods are limited by their cellular resolution and the
quantity of genes they can detect. To address these limitations, we propose
SpaDiT, a deep learning method that utilizes a diffusion generative model to
integrate scRNA-seq and ST data for the prediction of undetected genes. By
employing a Transformer-based diffusion model, SpaDiT not only accurately
predicts unknown genes but also effectively generates the spatial structure of
ST genes. We have demonstrated the effectiveness of SpaDiT through extensive
experiments on both seq-based and image-based ST data. SpaDiT significantly
contributes to ST gene prediction methods with its innovative approach.
Compared to eight leading baseline methods, SpaDiT achieved state-of-the-art
performance across multiple metrics, highlighting its substantial
bioinformatics contribution.

摘要：空間轉錄組學 (ST) 技術的快速發展正在徹底改變我們對生物組織空間組織的理解。當前 ST 方法分為基於次世代定序 (seq-based) 和基於原位螢光雜交 (image-based) 的方法，為生物組織的功能動力學提供了創新的見解。然而，這些方法受到其細胞解析度和可檢測基因數量的限制。為了解決這些限制，我們提出了 SpaDiT，這是一種深度學習方法，利用擴散生成模型整合 scRNA-seq 和 ST 數據來預測未檢測到的基因。通過採用基於 Transformer 的擴散模型，SpaDiT 不僅可以準確預測未知基因，還可以有效生成 ST 基因的空間結構。我們通過對基於 seq 和基於影像的 ST 數據進行廣泛的實驗，證明了 SpaDiT 的有效性。SpaDiT 以其創新的方法顯著貢獻了 ST 基因預測方法。與八種領先的基線方法相比，SpaDiT 在多項指標上實現了最先進的性能，突顯了其在生物資訊學上的重大貢獻。

##### **Unified-EGformer: Exposure Guided Lightweight Transformer for Mixed-Exposure Image Enhancement**
2407.13170v1 by Eashan Adhikarla, Kai Zhang, Rosaura G. VidalMata, Manjushree Aithal, Nikhil Ambha Madhusudhana, John Nicholson, Lichao Sun, Brian D. Davison

Despite recent strides made by AI in image processing, the issue of mixed
exposure, pivotal in many real-world scenarios like surveillance and
photography, remains inadequately addressed. Traditional image enhancement
techniques and current transformer models are limited with primary focus on
either overexposure or underexposure. To bridge this gap, we introduce the
Unified-Exposure Guided Transformer (Unified-EGformer). Our proposed solution
is built upon advanced transformer architectures, equipped with local
pixel-level refinement and global refinement blocks for color correction and
image-wide adjustments. We employ a guided attention mechanism to precisely
identify exposure-compromised regions, ensuring its adaptability across various
real-world conditions. U-EGformer, with a lightweight design featuring a memory
footprint (peak memory) of only $\sim$1134 MB (0.1 Million parameters) and an
inference time of 95 ms (9.61x faster than the average), is a viable choice for
real-time applications such as surveillance and autonomous navigation.
Additionally, our model is highly generalizable, requiring minimal fine-tuning
to handle multiple tasks and datasets with a single architecture.

摘要：儘管 AI 在影像處理方面有近期的進展，但混合曝光的問題在許多真實世界的場景中至關重要，例如監控和攝影，但仍未得到充分的解決。傳統的影像增強技術和目前的Transformer模型受到限制，主要關注過度曝光或曝光不足。為了彌合這個差距，我們引入了統一曝光引導Transformer（Unified-EGformer）。我們提出的解決方案建立在先進的Transformer架構上，配備了用於色彩校正和全影像調整的局部像素級精煉和全局精煉區塊。我們採用引導式注意力機制來精確識別曝光不良區域，確保其適應各種真實世界的條件。U-EGformer 採用輕量級設計，具有僅約 1134 MB（0.1 百萬個參數）的記憶體占用空間（峰值記憶體）和 95 毫秒的推論時間（比平均速度快 9.61 倍），是監控和自主導航等即時應用程式的可行選擇。此外，我們的模型具有高度的概括性，只需最少的微調即可使用單一架構來處理多項任務和資料集。

##### **SciCode: A Research Coding Benchmark Curated by Scientists**
2407.13168v1 by Minyang Tian, Luyu Gao, Shizhuo Dylan Zhang, Xinan Chen, Cunwei Fan, Xuefei Guo, Roland Haas, Pan Ji, Kittithat Krongchon, Yao Li, Shengyan Liu, Di Luo, Yutao Ma, Hao Tong, Kha Trinh, Chenyu Tian, Zihan Wang, Bohao Wu, Yanyu Xiong, Shengzhu Yin, Minhui Zhu, Kilian Lieret, Yanxin Lu, Genglin Liu, Yufeng Du, Tianhua Tao, Ofir Press, Jamie Callan, Eliu Huerta, Hao Peng

Since language models (LMs) now outperform average humans on many challenging
tasks, it has become increasingly difficult to develop challenging,
high-quality, and realistic evaluations. We address this issue by examining
LMs' capabilities to generate code for solving real scientific research
problems. Incorporating input from scientists and AI researchers in 16 diverse
natural science sub-fields, including mathematics, physics, chemistry, biology,
and materials science, we created a scientist-curated coding benchmark,
SciCode. The problems in SciCode naturally factorize into multiple subproblems,
each involving knowledge recall, reasoning, and code synthesis. In total,
SciCode contains 338 subproblems decomposed from 80 challenging main problems.
It offers optional descriptions specifying useful scientific background
information and scientist-annotated gold-standard solutions and test cases for
evaluation. Claude3.5-Sonnet, the best-performing model among those tested, can
solve only 4.6% of the problems in the most realistic setting. We believe that
SciCode demonstrates both contemporary LMs' progress towards becoming helpful
scientific assistants and sheds light on the development and evaluation of
scientific AI in the future.

摘要：由於語言模型 (LM) 現在在許多具有挑戰性的任務上都優於一般人類，因此要開發具有挑戰性、高品質且實際的評量變得越來越困難。我們透過檢視 LM 產生程式碼以解決實際科學研究問題的能力來解決這個問題。我們納入 16 個不同的自然科學子領域（包括數學、物理、化學、生物和材料科學）的科學家和 AI 研究人員的意見，創建了一個由科學家策劃的程式碼基準 SciCode。SciCode 中的問題自然會分解成多個子問題，每個子問題都涉及知識回溯、推理和程式碼合成。總而言之，SciCode 包含從 80 個具有挑戰性的主要問題分解而來的 338 個子問題。它提供可選擇的說明，說明有用的科學背景資訊和科學家註解的黃金標準解決方案和測試案例以供評量。在測試的模型中表現最佳的 Claude3.5-Sonnet，只能在最實際的設定中解決 4.6% 的問題。我們相信 SciCode 證明了當代 LM 朝著成為有用的科學助理邁進的進展，並為未來科學 AI 的開發和評量帶來曙光。

##### **Translate-and-Revise: Boosting Large Language Models for Constrained Translation**
2407.13164v1 by Pengcheng Huang, Yongyu Mu, Yuzhang Wu, Bei Li, Chunyang Xiao, Tong Xiao, Jingbo Zhu

Imposing constraints on machine translation systems presents a challenging
issue because these systems are not trained to make use of constraints in
generating adequate, fluent translations. In this paper, we leverage the
capabilities of large language models (LLMs) for constrained translation, given
that LLMs can easily adapt to this task by taking translation instructions and
constraints as prompts. However, LLMs cannot always guarantee the adequacy of
translation, and, in some cases, ignore the given constraints. This is in part
because LLMs might be overly confident in their predictions, overriding the
influence of the constraints. To overcome this overiding behaviour, we propose
to add a revision process that encourages LLMs to correct the outputs by
prompting them about the constraints that have not yet been met. We evaluate
our approach on four constrained translation tasks, encompassing both lexical
and structural constraints in multiple constraint domains. Experiments show
15\% improvement in constraint-based translation accuracy over standard LLMs
and the approach also significantly outperforms neural machine translation
(NMT) state-of-the-art methods.

摘要：對機器翻譯系統施加限制是一個具有挑戰性的問題，因為這些系統並未經過訓練，無法利用限制來產生適當且流暢的翻譯。在本文中，我們利用大型語言模型 (LLM) 的能力來進行受限翻譯，因為 LLM 可以透過將翻譯說明和限制作為提示，輕鬆適應這項任務。然而，LLM 無法總是保證翻譯的充分性，並且在某些情況下會忽略給定的限制。這部分是因為 LLM 可能過度自信於自己的預測，而忽視了限制的影響。為了克服這種過度行為，我們建議增加一個修訂程序，鼓勵 LLM 透過提示尚未滿足的限制來修正輸出。我們在四項受限翻譯任務中評估我們的做法，涵蓋多個限制領域中的詞彙和結構限制。實驗顯示，與標準 LLM 相比，基於約束的翻譯準確度提高了 15%，並且該方法也顯著優於神經機器翻譯 (NMT) 的最新方法。

##### **ROLeR: Effective Reward Shaping in Offline Reinforcement Learning for Recommender Systems**
2407.13163v1 by Yi Zhang, Ruihong Qiu, Jiajun Liu, Sen Wang

Offline reinforcement learning (RL) is an effective tool for real-world
recommender systems with its capacity to model the dynamic interest of users
and its interactive nature. Most existing offline RL recommender systems focus
on model-based RL through learning a world model from offline data and building
the recommendation policy by interacting with this model. Although these
methods have made progress in the recommendation performance, the effectiveness
of model-based offline RL methods is often constrained by the accuracy of the
estimation of the reward model and the model uncertainties, primarily due to
the extreme discrepancy between offline logged data and real-world data in user
interactions with online platforms. To fill this gap, a more accurate reward
model and uncertainty estimation are needed for the model-based RL methods. In
this paper, a novel model-based Reward Shaping in Offline Reinforcement
Learning for Recommender Systems, ROLeR, is proposed for reward and uncertainty
estimation in recommendation systems. Specifically, a non-parametric reward
shaping method is designed to refine the reward model. In addition, a flexible
and more representative uncertainty penalty is designed to fit the needs of
recommendation systems. Extensive experiments conducted on four benchmark
datasets showcase that ROLeR achieves state-of-the-art performance compared
with existing baselines. The source code can be downloaded at
https://github.com/ArronDZhang/ROLeR.

摘要：離線強化學習 (RL) 是一種有效的工具，可用於現實世界的推薦系統，因為它能夠模擬使用者的動態興趣，且具有互動特性。現有的離線 RL 推薦系統大多著重於透過學習離線資料的世界模型，並透過與此模型互動來建構推薦政策的基於模型的 RL。儘管這些方法在推薦效能上有進展，但基於模型的離線 RL 方法的有效性通常會受到獎勵模型估計的準確度和模型不確定性的限制，這主要是由於離線記錄資料與使用者與線上平台互動時的實際資料之間存在極大的差異。為了填補此差距，基於模型的 RL 方法需要更準確的獎勵模型和不確定性估計。在本文中，提出了一種名為 ROLeR 的推薦系統離線強化學習中的新穎基於模型的獎勵成形，用於推薦系統中的獎勵和不確定性估計。具體來說，設計了一種非參數獎勵成形方法來改善獎勵模型。此外，設計了一個靈活且更具代表性的不確定性懲罰，以符合推薦系統的需求。在四個基準資料集上進行的廣泛實驗顯示，與現有的基準相比，ROLeR 達到了最先進的效能。原始碼可於 https://github.com/ArronDZhang/ROLeR 下載。

##### **Learning Camouflaged Object Detection from Noisy Pseudo Label**
2407.13157v1 by Jin Zhang, Ruiheng Zhang, Yanjiao Shi, Zhe Cao, Nian Liu, Fahad Shahbaz Khan

Existing Camouflaged Object Detection (COD) methods rely heavily on
large-scale pixel-annotated training sets, which are both time-consuming and
labor-intensive. Although weakly supervised methods offer higher annotation
efficiency, their performance is far behind due to the unclear visual
demarcations between foreground and background in camouflaged images. In this
paper, we explore the potential of using boxes as prompts in camouflaged scenes
and introduce the first weakly semi-supervised COD method, aiming for
budget-efficient and high-precision camouflaged object segmentation with an
extremely limited number of fully labeled images. Critically, learning from
such limited set inevitably generates pseudo labels with serious noisy pixels.
To address this, we propose a noise correction loss that facilitates the
model's learning of correct pixels in the early learning stage, and corrects
the error risk gradients dominated by noisy pixels in the memorization stage,
ultimately achieving accurate segmentation of camouflaged objects from noisy
labels. When using only 20% of fully labeled data, our method shows superior
performance over the state-of-the-art methods.

摘要：現有的偽裝物體偵測 (COD) 方法高度依賴於大規模像素註解訓練集，這既耗時又費力。儘管弱監督方法提供了更高的註解效率，但由於偽裝影像中前景和背景之間的視覺界線不明確，因此它們的效能遠遠落後。在本文中，我們探討了在偽裝場景中使用方塊作為提示的可能性，並介紹了第一個弱半監督 COD 方法，目標是使用極少數的完全標籤影像，進行經濟高效且高精準度的偽裝物體分割。至關重要的是，從如此有限的集合中學習，不可避免地會產生帶有嚴重雜訊像素的偽標籤。為了解決這個問題，我們提出了一個雜訊修正損失，有助於模型在早期學習階段學習正確的像素，並在記憶階段修正由雜訊像素主導的錯誤風險梯度，最終實現從雜訊標籤中準確分割偽裝物體。當僅使用 20% 的完全標籤資料時，我們的模型顯示出優於最先進模型的效能。

##### **Preset-Voice Matching for Privacy Regulated Speech-to-Speech Translation Systems**
2407.13153v1 by Daniel Platnick, Bishoy Abdelnour, Eamon Earl, Rahul Kumar, Zahra Rezaei, Thomas Tsangaris, Faraj Lagum

In recent years, there has been increased demand for speech-to-speech
translation (S2ST) systems in industry settings. Although successfully
commercialized, cloning-based S2ST systems expose their distributors to
liabilities when misused by individuals and can infringe on personality rights
when exploited by media organizations. This work proposes a regulated S2ST
framework called Preset-Voice Matching (PVM). PVM removes cross-lingual voice
cloning in S2ST by first matching the input voice to a similar prior consenting
speaker voice in the target-language. With this separation, PVM avoids cloning
the input speaker, ensuring PVM systems comply with regulations and reduce risk
of misuse. Our results demonstrate PVM can significantly improve S2ST system
run-time in multi-speaker settings and the naturalness of S2ST synthesized
speech. To our knowledge, PVM is the first explicitly regulated S2ST framework
leveraging similarly-matched preset-voices for dynamic S2ST tasks.

摘要：近年來，產業環境對於語音轉語音（S2ST）系統的需求日益增加。儘管已成功商業化，但基於複製的 S2ST 系統在遭個人不當使用時，會使發行商承擔法律責任，且在遭媒體組織利用時，可能會侵犯人格權。本研究提出一個稱為預設語音比對（PVM）的受規範 S2ST 架構。PVM 透過先將輸入語音與目標語言中類似的先前同意講者語音進行比對，來移除 S2ST 中的跨語言語音複製。透過這種分離，PVM 可避免複製輸入講者，確保 PVM 系統符合法規並降低遭不當使用的風險。我們的結果顯示，PVM 可以大幅改善多講者設定中的 S2ST 系統執行時間，以及 S2ST 合成語音的自然度。據我們所知，PVM 是第一個明確受規範的 S2ST 架構，它會利用類似的預設語音進行比對，以執行動態 S2ST 任務。

##### **A light-weight and efficient punctuation and word casing prediction model for on-device streaming ASR**
2407.13142v1 by Jian You, Xiangfeng Li

Punctuation and word casing prediction are necessary for automatic speech
recognition (ASR). With the popularity of on-device end-to-end streaming ASR
systems, the on-device punctuation and word casing prediction become a
necessity while we found little discussion on this. With the emergence of
Transformer, Transformer based models have been explored for this scenario.
However, Transformer based models are too large for on-device ASR systems. In
this paper, we propose a light-weight and efficient model that jointly predicts
punctuation and word casing in real time. The model is based on Convolutional
Neural Network (CNN) and Bidirectional Long Short-Term Memory (BiLSTM).
Experimental results on the IWSLT2011 test set show that the proposed model
obtains 9% relative improvement compared to the best of non-Transformer models
on overall F1-score. Compared to the representative of Transformer based
models, the proposed model achieves comparable results to the representative
model while being only one-fortieth its size and 2.5 times faster in terms of
inference time. It is suitable for on-device streaming ASR systems. Our code is
publicly available.

摘要：標點符號和字詞大小寫預測對於自動語音辨識 (ASR) 來說是必要的。隨著裝置上端對端串流 ASR 系統的普及，裝置上標點符號和字詞大小寫預測變得必要，但我們發現很少有關於這方面的討論。隨著 Transformer 的出現，基於 Transformer 的模型已探索用於此情境。然而，基於 Transformer 的模型對於裝置上 ASR 系統來說過於龐大。在本文中，我們提出一個輕量且高效的模型，用於在即時預測標點符號和字詞大小寫。該模型基於卷積神經網路 (CNN) 和雙向長短期記憶 (BiLSTM)。在 IWSLT2011 測試集上的實驗結果顯示，與非 Transformer 模型中最好的模型相比，所提出的模型在整體 F1 分數上獲得了 9% 的相對改進。與基於 Transformer 的模型的代表相比，所提出的模型在僅為其大小的四十分之一且推論時間快 2.5 倍的情況下，達到了與代表模型相當的結果。它適用於裝置上串流 ASR 系統。我們的程式碼已公開。

##### **MO-EMT-NAS: Multi-Objective Continuous Transfer of Architectural Knowledge Between Tasks from Different Datasets**
2407.13122v1 by Peng Liao, XiLu Wang, Yaochu Jin, WenLi Du

Deploying models across diverse devices demands tradeoffs among multiple
objectives due to different resource constraints. Arguably, due to the small
model trap problem in multi-objective neural architecture search (MO-NAS) based
on a supernet, existing approaches may fail to maintain large models. Moreover,
multi-tasking neural architecture search (MT-NAS) excels in handling multiple
tasks simultaneously, but most existing efforts focus on tasks from the same
dataset, limiting their practicality in real-world scenarios where multiple
tasks may come from distinct datasets. To tackle the above challenges, we
propose a Multi-Objective Evolutionary Multi-Tasking framework for NAS
(MO-EMT-NAS) to achieve architectural knowledge transfer across tasks from
different datasets while finding Pareto optimal architectures for
multi-objectives, model accuracy and computational efficiency. To alleviate the
small model trap issue, we introduce an auxiliary objective that helps maintain
multiple larger models of similar accuracy. Moreover, the computational
efficiency is further enhanced by parallelizing the training and validation of
the weight-sharing-based supernet. Experimental results on seven datasets with
two, three, and four task combinations show that MO-EMT-NAS achieves a better
minimum classification error while being able to offer flexible trade-offs
between model performance and complexity, compared to the state-of-the-art
single-objective MT-NAS algorithms. The runtime of MO-EMT-NAS is reduced by
59.7% to 77.7%, compared to the corresponding multi-objective single-task
approaches.

摘要：<paragraph>由於不同的資源限制，在各種裝置上部署模型需要在多重目標之間進行權衡。可以說，由於基於超網路的多目標神經架構搜尋 (MO-NAS) 中存在小型模型陷阱問題，現有方法可能無法維護大型模型。此外，多任務神經架構搜尋 (MT-NAS) 擅長同時處理多項任務，但大多數現有工作都專注於來自相同資料集的任務，這限制了它們在現實世界中的實用性，在現實世界中，多項任務可能來自不同的資料集。為了應對上述挑戰，我們提出了多目標演化多任務 NAS 框架 (MO-EMT-NAS)，以在來自不同資料集的任務之間實現架構知識轉移，同時為多目標、模型準確性和計算效率找到帕累托最優架構。為了緩解小型模型陷阱問題，我們引入了一個輔助目標，有助於維護多個具有類似準確度的大型模型。此外，通過並行化基於權重共享的超網路的訓練和驗證，進一步提高了計算效率。在具有兩個、三個和四個任務組合的七個資料集上的實驗結果表明，與最先進的單目標 MT-NAS 演算法相比，MO-EMT-NAS 在能夠提供模型效能和複雜度之間的靈活權衡的同時，達到了較佳的最小分類誤差。與對應的多目標單任務方法相比，MO-EMT-NAS 的執行時間減少了 59.7% 至 77.7%。</paragraph>

##### **TrialEnroll: Predicting Clinical Trial Enrollment Success with Deep & Cross Network and Large Language Models**
2407.13115v1 by Ling Yue, Sixue Xing, Jintai Chen, Tianfan Fu

Clinical trials need to recruit a sufficient number of volunteer patients to
demonstrate the statistical power of the treatment (e.g., a new drug) in curing
a certain disease. Clinical trial recruitment has a significant impact on trial
success. Forecasting whether the recruitment process would be successful before
we run the trial would save many resources and time. This paper develops a
novel deep & cross network with large language model (LLM)-augmented text
feature that learns semantic information from trial eligibility criteria and
predicts enrollment success. The proposed method enables interpretability by
understanding which sentence/word in eligibility criteria contributes heavily
to prediction. We also demonstrate the empirical superiority of the proposed
method (0.7002 PR-AUC) over a bunch of well-established machine learning
methods. The code and curated dataset are publicly available at
https://anonymous.4open.science/r/TrialEnroll-7E12.

摘要：臨床試驗需要招募足夠數量的志願患者，才能證明治療方法（例如新藥）在治療某種疾病方面的統計學功效。臨床試驗招募對試驗成功有顯著影響。在我們執行試驗之前預測招募過程是否會成功，將可以節省許多資源和時間。本文開發了一個新的深度和交叉網路，具有大型語言模型（LLM）增強的文字特徵，可以從試驗資格標準中學習語義資訊，並預測註冊成功。所提出的方法透過了解資格標準中哪個句子/詞對預測有很大貢獻，從而實現了解釋性。我們還展示了所提出的方法（0.7002 PR-AUC）在經驗上優於許多既定的機器學習方法。程式碼和策展資料集可在 https://anonymous.4open.science/r/TrialEnroll-7E12 公開取得。

##### **Multiobjective Vehicle Routing Optimization with Time Windows: A Hybrid Approach Using Deep Reinforcement Learning and NSGA-II**
2407.13113v1 by Rixin Wu, Ran Wang, Jie Hao, Qiang Wu, Ping Wang, Dusit Niyato

This paper proposes a weight-aware deep reinforcement learning (WADRL)
approach designed to address the multiobjective vehicle routing problem with
time windows (MOVRPTW), aiming to use a single deep reinforcement learning
(DRL) model to solve the entire multiobjective optimization problem. The
Non-dominated sorting genetic algorithm-II (NSGA-II) method is then employed to
optimize the outcomes produced by the WADRL, thereby mitigating the limitations
of both approaches. Firstly, we design an MOVRPTW model to balance the
minimization of travel cost and the maximization of customer satisfaction.
Subsequently, we present a novel DRL framework that incorporates a
transformer-based policy network. This network is composed of an encoder
module, a weight embedding module where the weights of the objective functions
are incorporated, and a decoder module. NSGA-II is then utilized to optimize
the solutions generated by WADRL. Finally, extensive experimental results
demonstrate that our method outperforms the existing and traditional methods.
Due to the numerous constraints in VRPTW, generating initial solutions of the
NSGA-II algorithm can be time-consuming. However, using solutions generated by
the WADRL as initial solutions for NSGA-II significantly reduces the time
required for generating initial solutions. Meanwhile, the NSGA-II algorithm can
enhance the quality of solutions generated by WADRL, resulting in solutions
with better scalability. Notably, the weight-aware strategy significantly
reduces the training time of DRL while achieving better results, enabling a
single DRL model to solve the entire multiobjective optimization problem.

摘要：<paragraph>這篇論文提出一個重量感知深度強化學習 (WADRL) 方法，旨在解決具時間窗的多目標車輛路線問題 (MOVRPTW)，目標是使用單一深度強化學習 (DRL) 模型來解決整個多目標最佳化問題。接著採用非支配排序遺傳演算法 II (NSGA-II) 方法來最佳化 WADRL 產生的結果，從而減輕兩種方法的限制。首先，我們設計一個 MOVRPTW 模型來平衡旅行成本的最小化和顧客滿意度的最大化。接著，我們提出一個新的 DRL 架構，其中包含一個基於 Transformer 的策略網路。這個網路由一個編碼器模組、一個將目標函數的權重納入其中的權重嵌入模組，以及一個解碼器模組組成。接著利用 NSGA-II 來最佳化 WADRL 生成的解。最後，廣泛的實驗結果證明，我們的方法優於現有和傳統的方法。由於 VRPTW 中的約束眾多，產生 NSGA-II 演算法的初始解會很耗時。然而，使用 WADRL 生成的解作為 NSGA-II 的初始解，可以大幅減少產生初始解所需的時間。同時，NSGA-II 演算法可以提升 WADRL 生成的解的品質，產生具有更好可擴充性的解。值得注意的是，重量感知策略大幅減少了 DRL 的訓練時間，同時獲得更好的結果，讓單一 DRL 模型就能解決整個多目標最佳化問題。</paragraph>

##### **Retrieve, Summarize, Plan: Advancing Multi-hop Question Answering with an Iterative Approach**
2407.13101v1 by Zhouyu Jiang, Mengshu Sun, Lei Liang, Zhiqiang Zhang

Multi-hop question answering is a challenging task with distinct industrial
relevance, and Retrieval-Augmented Generation (RAG) methods based on large
language models (LLMs) have become a popular approach to tackle this task.
Owing to the potential inability to retrieve all necessary information in a
single iteration, a series of iterative RAG methods has been recently
developed, showing significant performance improvements. However, existing
methods still face two critical challenges: context overload resulting from
multiple rounds of retrieval, and over-planning and repetitive planning due to
the lack of a recorded retrieval trajectory. In this paper, we propose a novel
iterative RAG method called ReSP, equipped with a dual-function summarizer.
This summarizer compresses information from retrieved documents, targeting both
the overarching question and the current sub-question concurrently.
Experimental results on the multi-hop question-answering datasets HotpotQA and
2WikiMultihopQA demonstrate that our method significantly outperforms the
state-of-the-art, and exhibits excellent robustness concerning context length.

摘要：多跳問題回答是一個具有明顯產業相關性的挑戰性任務，而基於大型語言模型 (LLM) 的檢索增強生成 (RAG) 方法已成為應對此任務的流行方法。由於無法在單次迭代中檢索所有必要資訊的潛在問題，最近開發了一系列迭代式 RAG 方法，顯示出顯著的效能提升。然而，現有方法仍面臨兩項關鍵挑戰：多輪檢索導致的內容過載，以及由於缺乏記錄的檢索軌跡而導致的過度規劃和重複規劃。在本文中，我們提出了一種名為 ReSP 的創新迭代式 RAG 方法，它配備了一個雙功能摘要器。此摘要器壓縮來自檢索文件的資訊，同時針對總括性問題和當前的子問題。在多跳問題回答資料集 HotpotQA 和 2WikiMultihopQA 上的實驗結果表明，我們的模型顯著優於最先進的技術，並在內容長度方面展現出極佳的穩健性。

##### **AlcLaM: Arabic Dialectal Language Model**
2407.13097v1 by Murtadha Ahmed, Saghir Alfasly, Bo Wen, Jamaal Qasem, Mohammed Ahmed, Yunfeng Liu

Pre-trained Language Models (PLMs) are integral to many modern natural
language processing (NLP) systems. Although multilingual models cover a wide
range of languages, they often grapple with challenges like high inference
costs and a lack of diverse non-English training data. Arabic-specific PLMs are
trained predominantly on modern standard Arabic, which compromises their
performance on regional dialects. To tackle this, we construct an Arabic
dialectal corpus comprising 3.4M sentences gathered from social media
platforms. We utilize this corpus to expand the vocabulary and retrain a
BERT-based model from scratch. Named AlcLaM, our model was trained using only
13 GB of text, which represents a fraction of the data used by existing models
such as CAMeL, MARBERT, and ArBERT, compared to 7.8%, 10.2%, and 21.3%,
respectively. Remarkably, AlcLaM demonstrates superior performance on a variety
of Arabic NLP tasks despite the limited training data. AlcLaM is available at
GitHub https://github.com/amurtadha/Alclam and HuggingFace
https://huggingface.co/rahbi.

摘要：預訓練語言模型 (PLM) 是許多現代自然語言處理 (NLP) 系統中不可或缺的一部分。儘管多語言模型涵蓋廣泛的語言，但它們經常會遇到高推理成本和缺乏多樣化非英語訓練資料等挑戰。阿拉伯語特定 PLM 主要針對現代標準阿拉伯語進行訓練，這會損害它們在區域方言中的表現。為了解決這個問題，我們建立了一個阿拉伯方言語料庫，其中包含從社群媒體平台收集的 340 萬個句子。我們利用這個語料庫來擴充詞彙量，並從頭開始重新訓練 BERT 模型。我們的模型名為 AlcLaM，僅使用 13 GB 的文字進行訓練，僅佔現有模型（例如 CAMeL、MARBERT 和 ArBERT）所用資料的一小部分，分別為 7.8%、10.2% 和 21.3%。值得注意的是，儘管訓練資料有限，但 AlcLaM 在各種阿拉伯語 NLP 任務中表現出卓越的效能。AlcLaM 可在 GitHub https://github.com/amurtadha/Alclam 和 HuggingFace https://huggingface.co/rahbi 取得。

##### **MetaSumPerceiver: Multimodal Multi-Document Evidence Summarization for Fact-Checking**
2407.13089v1 by Ting-Chih Chen, Chia-Wei Tang, Chris Thomas

Fact-checking real-world claims often requires reviewing multiple multimodal
documents to assess a claim's truthfulness, which is a highly laborious and
time-consuming task. In this paper, we present a summarization model designed
to generate claim-specific summaries useful for fact-checking from multimodal,
multi-document datasets. The model takes inputs in the form of documents,
images, and a claim, with the objective of assisting in fact-checking tasks. We
introduce a dynamic perceiver-based model that can handle inputs from multiple
modalities of arbitrary lengths. To train our model, we leverage a novel
reinforcement learning-based entailment objective to generate summaries that
provide evidence distinguishing between different truthfulness labels. To
assess the efficacy of our approach, we conduct experiments on both an existing
benchmark and a new dataset of multi-document claims that we contribute. Our
approach outperforms the SOTA approach by 4.6% in the claim verification task
on the MOCHEG dataset and demonstrates strong performance on our new
Multi-News-Fact-Checking dataset.

摘要：事實查核現實世界的說法通常需要檢閱多種多模態文件以評估說法的真實性，這是一項高度費力和耗時的任務。在本文中，我們提出了一個摘要模型，旨在從多模態、多文件數據集中生成對事實查核有用的特定於說法的摘要。該模型以文件、圖像和說法形式接收輸入，目的是協助進行事實查核任務。我們引入了一個基於動態感知器的模型，它可以處理來自多種模態的任意長度的輸入。為了訓練我們的模型，我們利用一種新穎的基於強化學習的蘊涵目標來生成摘要，這些摘要提供了區分不同真實性標籤的證據。為了評估我們方法的有效性，我們在現有基準和我們貢獻的多文件說法的新數據集上進行了實驗。我們的做法在 MOCHEG 數據集上的說法驗證任務中比 SOTA 方法高出 4.6%，並在我們新的 Multi-News-Fact-Checking 數據集上展示了強勁的性能。

##### **Enhancing Temporal Action Localization: Advanced S6 Modeling with Recurrent Mechanism**
2407.13078v1 by Sangyoun Lee, Juho Jung, Changdae Oh, Sunghee Yun

Temporal Action Localization (TAL) is a critical task in video analysis,
identifying precise start and end times of actions. Existing methods like CNNs,
RNNs, GCNs, and Transformers have limitations in capturing long-range
dependencies and temporal causality. To address these challenges, we propose a
novel TAL architecture leveraging the Selective State Space Model (S6). Our
approach integrates the Feature Aggregated Bi-S6 block, Dual Bi-S6 structure,
and a recurrent mechanism to enhance temporal and channel-wise dependency
modeling without increasing parameter complexity. Extensive experiments on
benchmark datasets demonstrate state-of-the-art results with mAP scores of
74.2% on THUMOS-14, 42.9% on ActivityNet, 29.6% on FineAction, and 45.8% on
HACS. Ablation studies validate our method's effectiveness, showing that the
Dual structure in the Stem module and the recurrent mechanism outperform
traditional approaches. Our findings demonstrate the potential of S6-based
models in TAL tasks, paving the way for future research.

摘要：時序動作定位 (TAL) 是影片分析中的一項重要任務，用於識別動作的精確開始和結束時間。現有的方法，例如 CNN、RNN、GCN 和 Transformer，在捕捉長距離依賴性和時序因果關係方面有其限制。為了應對這些挑戰，我們提出了一種利用選擇性狀態空間模型 (S6) 的新型 TAL 架構。我們的做法整合了特徵聚合雙向 S6 區塊、雙向 S6 結構和遞迴機制，以增強時序和通道依賴性建模，而不會增加參數複雜性。在基準資料集上進行的廣泛實驗證明了最先進的結果，在 THUMOS-14 上的 mAP 分數為 74.2%，在 ActivityNet 上為 42.9%，在 FineAction 上為 29.6%，在 HACS 上為 45.8%。消融研究驗證了我們方法的有效性，表明 Stem 模組中的雙重結構和遞迴機制優於傳統方法。我們的發現證明了基於 S6 的模型在 TAL 任務中的潛力，為未來的研究鋪平了道路。

##### **Dynamic Sentiment Analysis with Local Large Language Models using Majority Voting: A Study on Factors Affecting Restaurant Evaluation**
2407.13069v1 by Junichiro Niimi

User-generated contents (UGCs) on online platforms allow marketing
researchers to understand consumer preferences for products and services. With
the advance of large language models (LLMs), some studies utilized the models
for annotation and sentiment analysis. However, the relationship between the
accuracy and the hyper-parameters of LLMs is yet to be thoroughly examined. In
addition, the issues of variability and reproducibility of results from each
trial of LLMs have rarely been considered in existing literature. Since actual
human annotation uses majority voting to resolve disagreements among
annotators, this study introduces a majority voting mechanism to a sentiment
analysis model using local LLMs. By a series of three analyses of online
reviews on restaurant evaluations, we demonstrate that majority voting with
multiple attempts using a medium-sized model produces more robust results than
using a large model with a single attempt. Furthermore, we conducted further
analysis to investigate the effect of each aspect on the overall evaluation.

摘要：線上平台上的使用者產生內容 (UGC) 能讓行銷研究人員了解消費者對產品和服務的喜好。隨著大型語言模型 (LLM) 的進步，有些研究利用這些模型進行標註和情緒分析。然而，LLM 的準確度和超參數之間的關係尚未得到徹底檢驗。此外，現有文獻很少考量 LLM 每一次試驗結果的可變性和可複製性問題。由於實際的人工標註使用多數決來解決標註者之間的分歧，本研究在使用局部 LLM 的情緒分析模型中引入了多數決機制。透過對餐廳評價的線上評論進行三項分析，我們證明使用中等規模的模型進行多次嘗試的多數決，會產生比使用大型模型進行一次嘗試更穩健的結果。此外，我們進一步進行分析，探討每個面向對整體評價的影響。

##### **Establishing Knowledge Preference in Language Models**
2407.13048v1 by Sizhe Zhou, Sha Li, Yu Meng, Yizhu Jiao, Heng Ji, Jiawei Han

Language models are known to encode a great amount of factual knowledge
through pretraining. However, such knowledge might be insufficient to cater to
user requests, requiring the model to integrate external knowledge sources and
adhere to user-provided specifications. When answering questions about ongoing
events, the model should use recent news articles to update its response; when
asked to provide recommendations, the model should prioritize user
specifications over retrieved product reviews; when some facts are edited in
the model, the updated facts should override all prior knowledge learned by the
model even if they are conflicting. In all of the cases above, the model faces
a decision between its own parametric knowledge, (retrieved) contextual
knowledge, and user instruction knowledge. In this paper, we (1) unify such
settings into the problem of knowledge preference and define a three-level
preference hierarchy over these knowledge sources; (2) compile a collection of
existing datasets IfQA, MQuAKE, and MRQA covering a combination of settings
(with/without user specifications, with/without context documents) to
systematically evaluate how well models obey the intended knowledge preference;
and (3) propose a dataset synthesis method that composes diverse
question-answer pairs with user assumptions and related context to directly
fine-tune LMs for instilling the hierarchy of knowledge. We demonstrate that a
7B model, fine-tuned on only a few thousand examples automatically generated by
our proposed method, effectively achieves superior performance (more than 18%
improvement across all evaluation benchmarks) in adhering to the desired
knowledge preference hierarchy.

摘要：語言模型已知可以透過預訓練編碼大量的事實知識。然而，此類知識可能不足以迎合使用者的要求，需要模型整合外部知識來源並遵守使用者提供的規格。在回答有關正在發生的事件的問題時，模型應使用最近的新聞文章來更新其回應；在被要求提供建議時，模型應優先考慮使用者規格，而不是擷取的產品評論；當模型中的一些事實被編輯時，更新的事實應優先於模型先前學習的所有知識，即使它們相互衝突。在上述所有情況中，模型面臨其自身參數化知識、（擷取的）脈絡知識和使用者指令知識之間的決策。在本文中，我們 (1) 將此類設定統一到知識偏好的問題中，並在這些知識來源上定義一個三層級的偏好層次；(2) 編制現有資料集 IfQA、MQuAKE 和 MRQA 的集合，涵蓋各種設定（有/沒有使用者規格，有/沒有脈絡文件），以系統性地評估模型遵守預期知識偏好的程度；(3) 提出一個資料集合成方法，該方法組成具有使用者假設和相關脈絡的不同問題-答案配對，以直接微調 LM 以灌輸知識層次。我們證明了一個 7B 模型，僅微調我們提出的方法自動產生的數千個範例，有效地達到了優異的效能（在所有評估基準中改善超過 18%），以遵守所需的知識偏好層次。

##### **Turkish Delights: a Dataset on Turkish Euphemisms**
2407.13040v1 by Hasan Can Biyik, Patrick Lee, Anna Feldman

Euphemisms are a form of figurative language relatively understudied in
natural language processing. This research extends the current computational
work on potentially euphemistic terms (PETs) to Turkish. We introduce the
Turkish PET dataset, the first available of its kind in the field. By creating
a list of euphemisms in Turkish, collecting example contexts, and annotating
them, we provide both euphemistic and non-euphemistic examples of PETs in
Turkish. We describe the dataset and methodologies, and also experiment with
transformer-based models on Turkish euphemism detection by using our dataset
for binary classification. We compare performances across models using F1,
accuracy, and precision as evaluation metrics.

摘要：委婉語是一種在自然語言處理中相對未被深入研究的比喻語言形式。本研究將目前關於潛在委婉語術語 (PET) 的計算工作擴展到土耳其語。我們介紹了土耳其 PET 資料集，這是該領域中第一個同類資料集。透過建立土耳其語委婉語清單、收集範例語境並註解它們，我們提供了土耳其語中 PET 的委婉語和非委婉語範例。我們描述了資料集和方法，並使用我們的資料集對土耳其語委婉語偵測進行了基於Transformer的模型實驗，以進行二元分類。我們使用 F1、準確度和精確度作為評估指標，比較了不同模型的效能。

##### **ColorMAE: Exploring data-independent masking strategies in Masked AutoEncoders**
2407.13036v1 by Carlos Hinojosa, Shuming Liu, Bernard Ghanem

Masked AutoEncoders (MAE) have emerged as a robust self-supervised framework,
offering remarkable performance across a wide range of downstream tasks. To
increase the difficulty of the pretext task and learn richer visual
representations, existing works have focused on replacing standard random
masking with more sophisticated strategies, such as adversarial-guided and
teacher-guided masking. However, these strategies depend on the input data thus
commonly increasing the model complexity and requiring additional calculations
to generate the mask patterns. This raises the question: Can we enhance MAE
performance beyond random masking without relying on input data or incurring
additional computational costs? In this work, we introduce a simple yet
effective data-independent method, termed ColorMAE, which generates different
binary mask patterns by filtering random noise. Drawing inspiration from color
noise in image processing, we explore four types of filters to yield mask
patterns with different spatial and semantic priors. ColorMAE requires no
additional learnable parameters or computational overhead in the network, yet
it significantly enhances the learned representations. We provide a
comprehensive empirical evaluation, demonstrating our strategy's superiority in
downstream tasks compared to random masking. Notably, we report an improvement
of 2.72 in mIoU in semantic segmentation tasks relative to baseline MAE
implementations.

摘要：遮蔽式自動編碼器 (MAE) 已成為一種強大的自監督式架構，在廣泛的下游任務中展現出卓越的效能。為了增加預設任務的難度並學習更豐富的視覺表示，現有的作品專注於用更精密的策略取代標準隨機遮蔽，例如對抗引導和教師引導遮蔽。然而，這些策略依賴於輸入資料，因此通常會增加模型複雜度，並需要額外的計算來產生遮蔽模式。這引發了一個問題：我們能否在不依賴輸入資料或產生額外的運算成本的情況下，提升 MAE 效能，並超越隨機遮蔽？在這項工作中，我們引入了一個簡單但有效的資料無關方法，稱為 ColorMAE，它透過濾除隨機雜訊來產生不同的二進制遮蔽模式。從影像處理中的彩色雜訊中汲取靈感，我們探索四種類型的濾波器，以產生具有不同空間和語義先驗的遮蔽模式。ColorMAE 在網路中不需要額外的可學習參數或運算開銷，但它卻能顯著提升學習到的表示。我們提供了一個全面的經驗評估，證明我們的策略在與隨機遮蔽相比之下，在下游任務中的優越性。值得注意的是，我們報告在語意分割任務中，相對於基準 MAE 實作，mIoU 改善了 2.72。

##### **Pre-Trained Foundation Model representations to uncover Breathing patterns in Speech**
2407.13035v1 by Vikramjit Mitra, Anirban Chatterjee, Ke Zhai, Helen Weng, Ayuko Hill, Nicole Hay, Christopher Webb, Jamie Cheng, Erdrin Azemi

The process of human speech production involves coordinated respiratory
action to elicit acoustic speech signals. Typically, speech is produced when
air is forced from the lungs and is modulated by the vocal tract, where such
actions are interspersed by moments of breathing in air (inhalation) to refill
the lungs again. Respiratory rate (RR) is a vital metric that is used to assess
the overall health, fitness, and general well-being of an individual. Existing
approaches to measure RR (number of breaths one takes in a minute) are
performed using specialized equipment or training. Studies have demonstrated
that machine learning algorithms can be used to estimate RR using bio-sensor
signals as input. Speech-based estimation of RR can offer an effective approach
to measure the vital metric without requiring any specialized equipment or
sensors. This work investigates a machine learning based approach to estimate
RR from speech segments obtained from subjects speaking to a close-talking
microphone device. Data were collected from N=26 individuals, where the
groundtruth RR was obtained through commercial grade chest-belts and then
manually corrected for any errors. A convolutional long-short term memory
network (Conv-LSTM) is proposed to estimate respiration time-series data from
the speech signal. We demonstrate that the use of pre-trained representations
obtained from a foundation model, such as Wav2Vec2, can be used to estimate
respiration-time-series with low root-mean-squared error and high correlation
coefficient, when compared with the baseline. The model-driven time series can
be used to estimate $RR$ with a low mean absolute error (MAE) ~ 1.6
breaths/min.

摘要：人類說話的過程涉及協調的呼吸作用以引發聲學語音訊號。通常，當空氣從肺部排出並由聲道調節時會產生語音，其中這些動作會穿插吸入空氣（吸氣）的時刻，以再次填滿肺部。呼吸率 (RR) 是一項重要的指標，用於評估個人的整體健康、體能和一般幸福感。現有的測量 RR（每分鐘呼吸次數）方法是使用專業設備或訓練來執行。研究表明，機器學習演算法可用於使用生物感測器訊號作為輸入來估計 RR。基於語音的 RR 估計可以提供一種有效的測量方法，無需任何專業設備或感測器。這項工作探討了一種基於機器學習的方法，用於從受試者對著近講麥克風裝置說話所獲得的語音片段中估計 RR。資料是從 N=26 個人收集的，其中透過商用等級胸帶取得基準 RR，然後手動更正任何錯誤。提出了一個卷積長短期記憶網路 (Conv-LSTM) 來從語音訊號估計呼吸時間序列資料。我們證明，與基準相比，使用從基礎模型（例如 Wav2Vec2）獲得的預訓練表示可以估計具有低均方根誤差和高相關係數的呼吸時間序列。模型驅動的時間序列可用於估計平均絕對誤差 (MAE) 約為 1.6 次/分鐘的低 $RR$。

##### **A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks**
2407.12994v1 by Shubham Vatsal, Harsh Dubey

Large language models (LLMs) have shown remarkable performance on many
different Natural Language Processing (NLP) tasks. Prompt engineering plays a
key role in adding more to the already existing abilities of LLMs to achieve
significant performance gains on various NLP tasks. Prompt engineering requires
composing natural language instructions called prompts to elicit knowledge from
LLMs in a structured way. Unlike previous state-of-the-art (SoTA) models,
prompt engineering does not require extensive parameter re-training or
fine-tuning based on the given NLP task and thus solely operates on the
embedded knowledge of LLMs. Additionally, LLM enthusiasts can intelligently
extract LLMs' knowledge through a basic natural language conversational
exchange or prompt engineering, allowing more and more people even without deep
mathematical machine learning background to experiment with LLMs. With prompt
engineering gaining popularity in the last two years, researchers have come up
with numerous engineering techniques around designing prompts to improve
accuracy of information extraction from the LLMs. In this paper, we summarize
different prompting techniques and club them together based on different NLP
tasks that they have been used for. We further granularly highlight the
performance of these prompting strategies on various datasets belonging to that
NLP task, talk about the corresponding LLMs used, present a taxonomy diagram
and discuss the possible SoTA for specific datasets. In total, we read and
present a survey of 44 research papers which talk about 39 different prompting
methods on 29 different NLP tasks of which most of them have been published in
the last two years.

摘要：大型語言模型 (LLM) 在許多不同的自然語言處理 (NLP) 任務中展現了卓越的效能。提示工程在提升 LLM 已有能力的基礎上，於各種 NLP 任務中達成顯著的效能提升，扮演了關鍵角色。提示工程需要撰寫稱為提示的自然語言指令，以結構化的方式從 LLM 中引出知識。與先前的最先進 (SoTA) 模型不同，提示工程不需要根據既定的 NLP 任務進行廣泛的參數重新訓練或微調，因此僅在 LLM 的內嵌知識上運作。此外，LLM 愛好者可以透過基本的自然語言對話交流或提示工程，來智能地萃取 LLM 的知識，讓越來越多即使沒有深入數學機器學習背景的人，也能夠使用 LLM 進行實驗。隨著提示工程在過去兩年獲得廣泛採用，研究人員提出了許多工程技術，圍繞著提示設計來提升從 LLM 中萃取資訊的準確度。在本文中，我們總結了不同的提示技術，並根據它們被用於的不同 NLP 任務，將它們歸類在一起。我們進一步詳細說明了這些提示策略在屬於該 NLP 任務的各種資料集上的效能，討論了對應使用的 LLM，展示了一個分類圖，並討論了特定資料集可能的 SoTA。總計，我們閱讀並展示了 44 篇研究論文的調查，這些論文探討了 29 個不同的 NLP 任務中的 39 種不同的提示方法，其中大多數已於過去兩年內發表。

##### **Retrieval-Enhanced Machine Learning: Synthesis and Opportunities**
2407.12982v1 by To Eun Kim, Alireza Salemi, Andrew Drozdov, Fernando Diaz, Hamed Zamani

In the field of language modeling, models augmented with retrieval components
have emerged as a promising solution to address several challenges faced in the
natural language processing (NLP) field, including knowledge grounding,
interpretability, and scalability. Despite the primary focus on NLP, we posit
that the paradigm of retrieval-enhancement can be extended to a broader
spectrum of machine learning (ML) such as computer vision, time series
prediction, and computational biology. Therefore, this work introduces a formal
framework of this paradigm, Retrieval-Enhanced Machine Learning (REML), by
synthesizing the literature in various domains in ML with consistent notations
which is missing from the current literature. Also, we found that while a
number of studies employ retrieval components to augment their models, there is
a lack of integration with foundational Information Retrieval (IR) research. We
bridge this gap between the seminal IR research and contemporary REML studies
by investigating each component that comprises the REML framework. Ultimately,
the goal of this work is to equip researchers across various disciplines with a
comprehensive, formally structured framework of retrieval-enhanced models,
thereby fostering interdisciplinary future research.

摘要：在語言模型領域中，配備檢索元件的模型已成為解決自然語言處理 (NLP) 領域中面臨的多項挑戰的有希望的解決方案，包括知識基礎、可解釋性和可擴充性。儘管主要關注 NLP，我們假設檢索增強的範例可以擴展到更廣泛的機器學習 (ML)，例如電腦視覺、時間序列預測和計算生物學。因此，這項工作透過綜合使用 ML 中各種領域的文獻，以一致的符號表示法，介紹了這個範例的正式架構，檢索增強機器學習 (REML)，而這在目前的文獻中是缺失的。此外，我們發現雖然許多研究採用檢索元件來擴充他們的模型，但缺乏與基礎資訊檢索 (IR) 研究的整合。我們透過調查組成 REML 架構的每個元件，來彌合開創性的 IR 研究與當代 REML 研究之間的差距。最終，這項工作的目標是為各個領域的研究人員提供檢索增強模型的全面、正式結構化架構，從而促進跨學科的未來研究。

##### **A Framework for testing Federated Learning algorithms using an edge-like environment**
2407.12980v1 by Felipe Machado Schwanck, Marcos Tomazzoli Leipnitz, Joel Luís Carbonera, Juliano Araujo Wickboldt

Federated Learning (FL) is a machine learning paradigm in which many clients
cooperatively train a single centralized model while keeping their data private
and decentralized. FL is commonly used in edge computing, which involves
placing computer workloads (both hardware and software) as close as possible to
the edge, where the data is being created and where actions are occurring,
enabling faster response times, greater data privacy, and reduced data transfer
costs. However, due to the heterogeneous data distributions/contents of
clients, it is non-trivial to accurately evaluate the contributions of local
models in global centralized model aggregation. This is an example of a major
challenge in FL, commonly known as data imbalance or class imbalance. In
general, testing and assessing FL algorithms can be a very difficult and
complex task due to the distributed nature of the systems. In this work, a
framework is proposed and implemented to assess FL algorithms in a more easy
and scalable way. This framework is evaluated over a distributed edge-like
environment managed by a container orchestration platform (i.e. Kubernetes).

摘要：聯盟式學習 (FL) 是一種機器學習範例，其中許多用戶端在保持資料私密且分散的情況下，共同訓練單一集中式模型。FL 常用於邊緣運算，這涉及將電腦工作負載（硬體和軟體）盡可能地放置在邊緣，也就是資料建立和動作發生的地方，以實現更快的反應時間、更高的資料隱私和降低資料傳輸成本。然而，由於用戶端的資料分佈/內容異質，因此要準確評估在全球集中式模型匯總中本地模型的貢獻並非易事。這是 FL 中一項重大挑戰的範例，通常稱為資料不平衡或類別不平衡。一般來說，由於系統的分布式特性，測試和評估 FL 演算法可能是一項非常困難且複雜的任務。在此工作中，提出並實作了一個架構，以更輕鬆且可擴充的方式評估 FL 演算法。此架構在由容器協調平台（例如 Kubernetes）管理的分布式邊緣環境中進行評估。

##### **Learning Long-Horizon Predictions for Quadrotor Dynamics**
2407.12964v1 by Pratyaksh Prabhav Rao, Alessandro Saviolo, Tommaso Castiglione Ferrari, Giuseppe Loianno

Accurate modeling of system dynamics is crucial for achieving
high-performance planning and control of robotic systems. Although existing
data-driven approaches represent a promising approach for modeling dynamics,
their accuracy is limited to a short prediction horizon, overlooking the impact
of compounding prediction errors over longer prediction horizons. Strategies to
mitigate these cumulative errors remain underexplored. To bridge this gap, in
this paper, we study the key design choices for efficiently learning
long-horizon prediction dynamics for quadrotors. Specifically, we analyze the
impact of multiple architectures, historical data, and multi-step loss
formulation. We show that sequential modeling techniques showcase their
advantage in minimizing compounding errors compared to other types of
solutions. Furthermore, we propose a novel decoupled dynamics learning
approach, which further simplifies the learning process while also enhancing
the approach modularity. Extensive experiments and ablation studies on
real-world quadrotor data demonstrate the versatility and precision of the
proposed approach. Our outcomes offer several insights and methodologies for
enhancing long-term predictive accuracy of learned quadrotor dynamics for
planning and control.

摘要：系統動態的準確建模對於實現機器人系統的高效能規劃和控制至關重要。儘管現有的資料驅動方法代表了建模動態的一種有前途的方法，但其準確性僅限於短預測範圍，忽視了在較長預測範圍內累積預測誤差的影響。減輕這些累積誤差的策略仍未得到充分探索。為了彌合這一差距，在本文中，我們研究了有效學習四旋翼飛行器長期預測動態的關鍵設計選擇。具體而言，我們分析了多種架構、歷史資料和多步損失公式的影響。我們表明，與其他類型的解決方案相比，序列建模技術展示了其在最小化累積誤差方面的優勢。此外，我們提出了一種新穎的解耦動態學習方法，它進一步簡化了學習過程，同時也增強了方法的模組化。對真實世界四旋翼飛行器資料進行的廣泛實驗和消融研究證明了所提出方法的多功能性和精確性。我們的成果為增強學習的四旋翼飛行器動態的長期預測準確性以進行規劃和控制提供了多種見解和方法。

##### **Beyond the Veil of Similarity: Quantifying Semantic Continuity in Explainable AI**
2407.12950v1 by Qi Huang, Emanuele Mezzi, Osman Mutlu, Miltiadis Kofinas, Vidya Prasad, Shadnan Azwad Khan, Elena Ranguelova, Niki van Stein

We introduce a novel metric for measuring semantic continuity in Explainable
AI methods and machine learning models. We posit that for models to be truly
interpretable and trustworthy, similar inputs should yield similar
explanations, reflecting a consistent semantic understanding. By leveraging XAI
techniques, we assess semantic continuity in the task of image recognition. We
conduct experiments to observe how incremental changes in input affect the
explanations provided by different XAI methods. Through this approach, we aim
to evaluate the models' capability to generalize and abstract semantic concepts
accurately and to evaluate different XAI methods in correctly capturing the
model behaviour. This paper contributes to the broader discourse on AI
interpretability by proposing a quantitative measure for semantic continuity
for XAI methods, offering insights into the models' and explainers' internal
reasoning processes, and promoting more reliable and transparent AI systems.

摘要：我們為衡量可解釋 AI 方法和機器學習模型中的語義連續性，引入一種新的指標。我們假設，對於真正可解釋和可信賴的模型，類似的輸入應產生類似的解釋，反映一致的語義理解。透過利用 XAI 技術，我們評估圖像辨識任務中的語義連續性。我們進行實驗，觀察輸入的增量變化如何影響不同 XAI 方法提供的解釋。透過這種方法，我們旨在評估模型概括和抽象語義概念的準確性，並評估不同 XAI 方法在正確捕捉模型行為方面的能力。本文透過提出 XAI 方法的語義連續性定量測量，為 AI 可解釋性的廣泛論述做出貢獻，提供對模型和解釋器內部推理過程的見解，並促進更可靠和透明的 AI 系統。

##### **Halu-J: Critique-Based Hallucination Judge**
2407.12943v1 by Binjie Wang, Steffi Chern, Ethan Chern, Pengfei Liu

Large language models (LLMs) frequently generate non-factual content, known
as hallucinations. Existing retrieval-augmented-based hallucination detection
approaches typically address this by framing it as a classification task,
evaluating hallucinations based on their consistency with retrieved evidence.
However, this approach usually lacks detailed explanations for these
evaluations and does not assess the reliability of these explanations.
Furthermore, deficiencies in retrieval systems can lead to irrelevant or
partially relevant evidence retrieval, impairing the detection process.
Moreover, while real-world hallucination detection requires analyzing multiple
pieces of evidence, current systems usually treat all evidence uniformly
without considering its relevance to the content. To address these challenges,
we introduce Halu-J, a critique-based hallucination judge with 7 billion
parameters. Halu-J enhances hallucination detection by selecting pertinent
evidence and providing detailed critiques. Our experiments indicate that Halu-J
outperforms GPT-4o in multiple-evidence hallucination detection and matches its
capability in critique generation and evidence selection. We also introduce
ME-FEVER, a new dataset designed for multiple-evidence hallucination detection.
Our code and dataset can be found in https://github.com/GAIR-NLP/factool .

摘要：大型語言模型 (LLM) 經常產生非事實性的內容，稱為幻覺。現有的檢索增強型幻覺偵測方法通常將其設定為分類任務，根據幻覺與檢索證據的一致性來評估幻覺。然而，這種方法通常缺乏對這些評估的詳細說明，並且不會評估這些說明的可靠性。此外，檢索系統的缺陷可能會導致檢索到不相關或部分相關的證據，從而損害偵測過程。此外，雖然現實世界的幻覺檢測需要分析多個證據，但目前的系統通常會統一處理所有證據，而不考慮其與內容相關性。為了應對這些挑戰，我們引入了 Halu-J，一個基於批評的幻覺評審，有 70 億個參數。Halu-J 透過選擇相關證據並提供詳細的批評來增強幻覺檢測。我們的實驗表明，Halu-J 在多證據幻覺檢測中優於 GPT-4o，並在批評產生和證據選擇中與其能力相匹配。我們還引入了 ME-FEVER，一個專為多證據幻覺檢測而設計的新資料集。我們的程式碼和資料集可以在 https://github.com/GAIR-NLP/factool 中找到。

