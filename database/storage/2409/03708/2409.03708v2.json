{"2409.03708": {"publish_time": "2024-09-05", "title": "RAG based Question-Answering for Contextual Response Prediction System", "paper_summary": "Large Language Models (LLMs) have shown versatility in various Natural\nLanguage Processing (NLP) tasks, including their potential as effective\nquestion-answering systems. However, to provide precise and relevant\ninformation in response to specific customer queries in industry settings, LLMs\nrequire access to a comprehensive knowledge base to avoid hallucinations.\nRetrieval Augmented Generation (RAG) emerges as a promising technique to\naddress this challenge. Yet, developing an accurate question-answering\nframework for real-world applications using RAG entails several challenges: 1)\ndata availability issues, 2) evaluating the quality of generated content, and\n3) the costly nature of human evaluation. In this paper, we introduce an\nend-to-end framework that employs LLMs with RAG capabilities for industry use\ncases. Given a customer query, the proposed system retrieves relevant knowledge\ndocuments and leverages them, along with previous chat history, to generate\nresponse suggestions for customer service agents in the contact centers of a\nmajor retail company. Through comprehensive automated and human evaluations, we\nshow that this solution outperforms the current BERT-based algorithms in\naccuracy and relevance. Our findings suggest that RAG-based LLMs can be an\nexcellent support to human customer service representatives by lightening their\nworkload.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5728\u5404\u7a2e\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u4efb\u52d9\u4e2d\u5c55\u73fe\u5176\u591a\u529f\u80fd\u6027\uff0c\u5305\u62ec\u5176\u4f5c\u70ba\u6709\u6548\u554f\u7b54\u7cfb\u7d71\u7684\u6f5b\u529b\u3002\u7136\u800c\uff0c\u8981\u5728\u7522\u696d\u74b0\u5883\u4e2d\u91dd\u5c0d\u7279\u5b9a\u5ba2\u6236\u67e5\u8a62\u63d0\u4f9b\u7cbe\u78ba\u4e14\u76f8\u95dc\u7684\u8cc7\u8a0a\uff0cLLM \u9700\u8981\u5b58\u53d6\u5168\u9762\u7684\u77e5\u8b58\u5eab\uff0c\u4ee5\u907f\u514d\u7522\u751f\u5e7b\u89ba\u3002\u6aa2\u7d22\u64f4\u5145\u751f\u6210 (RAG) \u6d6e\u73fe\u70ba\u89e3\u6c7a\u6b64\u6311\u6230\u7684\u4e00\u9805\u6709\u524d\u9014\u7684\u6280\u8853\u3002\u7136\u800c\uff0c\u4f7f\u7528 RAG \u70ba\u771f\u5be6\u4e16\u754c\u61c9\u7528\u958b\u767c\u6e96\u78ba\u7684\u554f\u7b54\u67b6\u69cb\u6703\u5e36\u4f86\u591a\u9805\u6311\u6230\uff1a1) \u8cc7\u6599\u53ef\u7528\u6027\u554f\u984c\u30012) \u8a55\u4f30\u751f\u6210\u5167\u5bb9\u7684\u54c1\u8cea\uff0c\u4ee5\u53ca 3) \u4eba\u5de5\u8a55\u4f30\u7684\u6602\u8cb4\u6027\u8cea\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u4ecb\u7d39\u4e86\u4e00\u500b\u7aef\u5230\u7aef\u67b6\u69cb\uff0c\u5b83\u63a1\u7528\u5177\u5099 RAG \u529f\u80fd\u7684 LLM\uff0c\u4ee5\u9069\u7528\u65bc\u7522\u696d\u7528\u4f8b\u3002\u91dd\u5c0d\u5ba2\u6236\u67e5\u8a62\uff0c\u6240\u63d0\u51fa\u7684\u7cfb\u7d71\u6703\u6aa2\u7d22\u76f8\u95dc\u7684\u77e5\u8b58\u6587\u4ef6\uff0c\u4e26\u5229\u7528\u9019\u4e9b\u6587\u4ef6\u4ee5\u53ca\u5148\u524d\u7684\u804a\u5929\u8a18\u9304\uff0c\u70ba\u5927\u578b\u96f6\u552e\u516c\u53f8\u7684\u806f\u7d61\u4e2d\u5fc3\u4e2d\u7684\u5ba2\u6236\u670d\u52d9\u4ee3\u7406\u7522\u751f\u56de\u61c9\u5efa\u8b70\u3002\u900f\u904e\u5168\u9762\u7684\u81ea\u52d5\u5316\u548c\u4eba\u5de5\u8a55\u4f30\uff0c\u6211\u5011\u8b49\u660e\u6b64\u89e3\u6c7a\u65b9\u6848\u5728\u6e96\u78ba\u6027\u548c\u76f8\u95dc\u6027\u65b9\u9762\u512a\u65bc\u76ee\u524d\u7684 BERT-based \u6f14\u7b97\u6cd5\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u986f\u793a\uff0c\u57fa\u65bc RAG \u7684 LLM \u53ef\u4ee5\u900f\u904e\u6e1b\u8f15\u4eba\u985e\u5ba2\u670d\u4eba\u54e1\u7684\u5de5\u4f5c\u8ca0\u64d4\uff0c\u6210\u70ba\u5176\u7d55\u4f73\u7684\u652f\u63f4\u3002", "author": "Sriram Veturi et.al.", "authors": "Sriram Veturi, Saurabh Vaichal, Reshma Lal Jagadheesh, Nafis Irtiza Tripto, Nian Yan", "id": "2409.03708v2", "paper_url": "http://arxiv.org/abs/2409.03708v2", "repo": "null"}}