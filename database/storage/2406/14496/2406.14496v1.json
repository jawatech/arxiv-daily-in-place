{"2406.14496": {"publish_time": "2024-06-20", "title": "African or European Swallow? Benchmarking Large Vision-Language Models for Fine-Grained Object Classification", "paper_summary": "Recent Large Vision-Language Models (LVLMs) demonstrate impressive abilities\non numerous image understanding and reasoning tasks. The task of fine-grained\nobject classification (e.g., distinction between \\textit{animal species}),\nhowever, has been probed insufficiently, despite its downstream importance. We\nfill this evaluation gap by creating \\texttt{FOCI} (\\textbf{F}ine-grained\n\\textbf{O}bject \\textbf{C}lass\\textbf{I}fication), a difficult multiple-choice\nbenchmark for fine-grained object classification, from existing object\nclassification datasets: (1) multiple-choice avoids ambiguous answers\nassociated with casting classification as open-ended QA task; (2) we retain\nclassification difficulty by mining negative labels with a CLIP model.\n\\texttt{FOCI}\\xspace complements five popular classification datasets with four\ndomain-specific subsets from ImageNet-21k. We benchmark 12 public LVLMs on\n\\texttt{FOCI} and show that it tests for a \\textit{complementary skill} to\nestablished image understanding and reasoning benchmarks. Crucially, CLIP\nmodels exhibit dramatically better performance than LVLMs. Since the image\nencoders of LVLMs come from these CLIP models, this points to inadequate\nalignment for fine-grained object distinction between the encoder and the LLM\nand warrants (pre)training data with more fine-grained annotation. We release\nour code at \\url{https://github.com/gregor-ge/FOCI-Benchmark}.", "paper_summary_zh": "<paragraph>\u6700\u8fd1\u7684\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b (LVLMs) \u5728\u8bb8\u591a\u56fe\u50cf\u7406\u89e3\u548c\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u60ca\u4eba\u7684\u80fd\u529b\u3002\u7136\u800c\uff0c\u7ec6\u7c92\u5ea6\u5bf9\u8c61\u5206\u7c7b\uff08\u4f8b\u5982\uff0c\u533a\u5206\u201c\u52a8\u7269\u79cd\u7c7b\u201d\uff09\u7684\u4efb\u52a1\uff0c\u5c3d\u7ba1\u5176\u4e0b\u6e38\u91cd\u8981\u6027\uff0c\u4f46\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7a76\u3002\u6211\u4eec\u901a\u8fc7\u521b\u5efa \\texttt{FOCI}\uff08\\textbf{F}ine-grained \\textbf{O}bject \\textbf{C}lass\\textbf{I}fication\uff09\uff0c\u4e00\u4e2a\u56f0\u96be\u7684\u591a\u9879\u9009\u62e9\u57fa\u51c6\uff0c\u7528\u4e8e\u4ece\u73b0\u6709\u5bf9\u8c61\u5206\u7c7b\u6570\u636e\u96c6\u8fdb\u884c\u7ec6\u7c92\u5ea6\u5bf9\u8c61\u5206\u7c7b\uff0c\u6765\u586b\u8865\u8fd9\u4e00\u8bc4\u4f30\u7a7a\u767d\uff1a\uff081\uff09\u591a\u9879\u9009\u62e9\u907f\u514d\u4e86\u5c06\u5206\u7c7b\u8868\u8ff0\u4e3a\u5f00\u653e\u5f0f\u95ee\u7b54\u4efb\u52a1\u6240\u5e26\u6765\u7684\u6a21\u68f1\u4e24\u53ef\u7684\u7b54\u6848\uff1b\uff082\uff09\u6211\u4eec\u901a\u8fc7\u4f7f\u7528 CLIP \u6a21\u578b\u6316\u6398\u8d1f\u6807\u7b7e\u6765\u4fdd\u7559\u5206\u7c7b\u96be\u5ea6\u3002\\texttt{FOCI}\\xspace \u7528 ImageNet-21k \u4e2d\u7684\u56db\u4e2a\u7279\u5b9a\u9886\u57df\u7684\u5b50\u96c6\u8865\u5145\u4e86\u4e94\u4e2a\u6d41\u884c\u7684\u5206\u7c7b\u6570\u636e\u96c6\u3002\u6211\u4eec\u5728 \\texttt{FOCI} \u4e0a\u5bf9 12 \u4e2a\u516c\u5171 LVLMs \u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u8868\u660e\u5b83\u6d4b\u8bd5\u4e86\u4e00\u9879\u201c\u8865\u5145\u6280\u80fd\u201d\uff0c\u4ee5\u5efa\u7acb\u56fe\u50cf\u7406\u89e3\u548c\u63a8\u7406\u57fa\u51c6\u3002\u81f3\u5173\u91cd\u8981\u7684\u662f\uff0cCLIP \u6a21\u578b\u8868\u73b0\u51fa\u6bd4 LVLMs \u663e\u8457\u66f4\u597d\u7684\u6027\u80fd\u3002\u7531\u4e8e LVLMs \u7684\u56fe\u50cf\u7f16\u7801\u5668\u6765\u81ea\u8fd9\u4e9b CLIP \u6a21\u578b\uff0c\u8fd9\u8868\u660e\u7f16\u7801\u5668\u548c LLM \u4e4b\u95f4\u5728\u7ec6\u7c92\u5ea6\u5bf9\u8c61\u533a\u5206\u65b9\u9762\u5b58\u5728\u4e0d\u5145\u5206\u7684\u5bf9\u9f50\uff0c\u5e76\u4fdd\u8bc1\u4f7f\u7528\u66f4\u7ec6\u7c92\u5ea6\u7684\u6ce8\u91ca\u8fdb\u884c\uff08\u9884\uff09\u8bad\u7ec3\u6570\u636e\u3002\u6211\u4eec\u5728 \\url{https://github.com/gregor-ge/FOCI-Benchmark} \u4e0a\u53d1\u5e03\u4e86\u6211\u4eec\u7684\u4ee3\u7801\u3002</paragraph>", "author": "Gregor Geigle et.al.", "authors": "Gregor Geigle, Radu Timofte, Goran Glava\u0161", "id": "2406.14496v1", "paper_url": "http://arxiv.org/abs/2406.14496v1", "repo": "null"}}