{"2409.06348": {"publish_time": "2024-09-10", "title": "VoiceWukong: Benchmarking Deepfake Voice Detection", "paper_summary": "With the rapid advancement of technologies like text-to-speech (TTS) and\nvoice conversion (VC), detecting deepfake voices has become increasingly\ncrucial. However, both academia and industry lack a comprehensive and intuitive\nbenchmark for evaluating detectors. Existing datasets are limited in language\ndiversity and lack many manipulations encountered in real-world production\nenvironments.\n  To fill this gap, we propose VoiceWukong, a benchmark designed to evaluate\nthe performance of deepfake voice detectors. To build the dataset, we first\ncollected deepfake voices generated by 19 advanced and widely recognized\ncommercial tools and 15 open-source tools. We then created 38 data variants\ncovering six types of manipulations, constructing the evaluation dataset for\ndeepfake voice detection. VoiceWukong thus includes 265,200 English and 148,200\nChinese deepfake voice samples. Using VoiceWukong, we evaluated 12\nstate-of-the-art detectors. AASIST2 achieved the best equal error rate (EER) of\n13.50%, while all others exceeded 20%. Our findings reveal that these detectors\nface significant challenges in real-world applications, with dramatically\ndeclining performance. In addition, we conducted a user study with more than\n300 participants. The results are compared with the performance of the 12\ndetectors and a multimodel large language model (MLLM), i.e., Qwen2-Audio,\nwhere different detectors and humans exhibit varying identification\ncapabilities for deepfake voices at different deception levels, while the LALM\ndemonstrates no detection ability at all. Furthermore, we provide a leaderboard\nfor deepfake voice detection, publicly available at\n{https://voicewukong.github.io}.", "paper_summary_zh": "<paragraph>\u96a8\u8457\u6587\u5b57\u8f49\u8a9e\u97f3 (TTS) \u548c\u8a9e\u97f3\u8f49\u63db (VC) \u7b49\u6280\u8853\u7684\u5feb\u901f\u9032\u6b65\uff0c\u5075\u6e2c\u6df1\u5ea6\u9020\u5047\u8a9e\u97f3\u8b8a\u5f97\u8d8a\u4f86\u8d8a\u91cd\u8981\u3002\u7136\u800c\uff0c\u5b78\u8853\u754c\u548c\u696d\u754c\u90fd\u7f3a\u4e4f\u4e00\u500b\u5168\u9762\u4e14\u76f4\u89c0\u7684\u57fa\u6e96\u4f86\u8a55\u4f30\u5075\u6e2c\u5668\u3002\u73fe\u6709\u7684\u8cc7\u6599\u96c6\u5728\u8a9e\u8a00\u591a\u6a23\u6027\u65b9\u9762\u53d7\u5230\u9650\u5236\uff0c\u4e26\u4e14\u7f3a\u4e4f\u5728\u73fe\u5be6\u4e16\u754c\u751f\u7522\u74b0\u5883\u4e2d\u9047\u5230\u7684\u8a31\u591a\u64cd\u4f5c\u3002\n  \u70ba\u4e86\u586b\u88dc\u9019\u500b\u7a7a\u767d\uff0c\u6211\u5011\u63d0\u51fa\u4e86 VoiceWukong\uff0c\u4e00\u500b\u65e8\u5728\u8a55\u4f30\u6df1\u5ea6\u9020\u5047\u8a9e\u97f3\u5075\u6e2c\u5668\u6548\u80fd\u7684\u57fa\u6e96\u3002\u70ba\u4e86\u5efa\u7acb\u8cc7\u6599\u96c6\uff0c\u6211\u5011\u9996\u5148\u6536\u96c6\u4e86\u7531 19 \u500b\u5148\u9032\u4e14\u5ee3\u6cdb\u8a8d\u53ef\u7684\u5546\u696d\u5de5\u5177\u548c 15 \u500b\u958b\u6e90\u5de5\u5177\u751f\u6210\u7684\u6df1\u5ea6\u9020\u5047\u8a9e\u97f3\u3002\u7136\u5f8c\uff0c\u6211\u5011\u5275\u5efa\u4e86 38 \u7a2e\u8cc7\u6599\u8b8a\u9ad4\uff0c\u6db5\u84cb\u516d\u7a2e\u985e\u578b\u7684\u64cd\u4f5c\uff0c\u69cb\u5efa\u4e86\u6df1\u5ea6\u9020\u5047\u8a9e\u97f3\u5075\u6e2c\u7684\u8a55\u4f30\u8cc7\u6599\u96c6\u3002\u56e0\u6b64\uff0cVoiceWukong \u5305\u542b 265,200 \u500b\u82f1\u6587\u548c 148,200 \u500b\u4e2d\u6587\u6df1\u5ea6\u9020\u5047\u8a9e\u97f3\u7bc4\u4f8b\u3002\u4f7f\u7528 VoiceWukong\uff0c\u6211\u5011\u8a55\u4f30\u4e86 12 \u500b\u6700\u5148\u9032\u7684\u5075\u6e2c\u5668\u3002AASIST2 \u9054\u5230\u4e86 13.50% \u7684\u6700\u4f73\u7b49\u932f\u7387 (EER)\uff0c\u800c\u5176\u4ed6\u6240\u6709\u5075\u6e2c\u5668\u90fd\u8d85\u904e\u4e86 20%\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u986f\u793a\uff0c\u9019\u4e9b\u5075\u6e2c\u5668\u5728\u73fe\u5be6\u4e16\u754c\u61c9\u7528\u4e2d\u9762\u81e8\u91cd\u5927\u6311\u6230\uff0c\u6548\u80fd\u5927\u5e45\u4e0b\u964d\u3002\u6b64\u5916\uff0c\u6211\u5011\u9032\u884c\u4e86\u4e00\u9805\u6709\u8d85\u904e 300 \u540d\u53c3\u8207\u8005\u7684\u4f7f\u7528\u8005\u7814\u7a76\u3002\u7d50\u679c\u8207 12 \u500b\u5075\u6e2c\u5668\u7684\u6548\u80fd\u4ee5\u53ca\u591a\u6a21\u5f0f\u5927\u578b\u8a9e\u8a00\u6a21\u578b (MLLM)\uff08\u5373 Qwen2-Audio\uff09\u9032\u884c\u6bd4\u8f03\uff0c\u5176\u4e2d\u4e0d\u540c\u7684\u5075\u6e2c\u5668\u548c\u4eba\u985e\u5728\u4e0d\u540c\u6b3a\u9a19\u5c64\u7d1a\u5c0d\u6df1\u5ea6\u9020\u5047\u8a9e\u97f3\u5c55\u73fe\u51fa\u4e0d\u540c\u7684\u8fa8\u8b58\u80fd\u529b\uff0c\u800c LALM \u5247\u5b8c\u5168\u6c92\u6709\u5075\u6e2c\u80fd\u529b\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u4f9b\u4e86\u4e00\u500b\u6df1\u5ea6\u9020\u5047\u8a9e\u97f3\u5075\u6e2c\u6392\u884c\u699c\uff0c\u53ef\u5728 {https://voicewukong.github.io} \u516c\u958b\u53d6\u5f97\u3002</paragraph>", "author": "Ziwei Yan et.al.", "authors": "Ziwei Yan, Yanjie Zhao, Haoyu Wang", "id": "2409.06348v1", "paper_url": "http://arxiv.org/abs/2409.06348v1", "repo": "null"}}