{"2501.05510": {"publish_time": "2025-01-09", "title": "OVO-Bench: How Far is Your Video-LLMs from Real-World Online Video Understanding?", "paper_summary": "Temporal Awareness, the ability to reason dynamically based on the timestamp\nwhen a question is raised, is the key distinction between offline and online\nvideo LLMs. Unlike offline models, which rely on complete videos for static,\npost hoc analysis, online models process video streams incrementally and\ndynamically adapt their responses based on the timestamp at which the question\nis posed. Despite its significance, temporal awareness has not been adequately\nevaluated in existing benchmarks. To fill this gap, we present OVO-Bench\n(Online-VideO-Benchmark), a novel video benchmark that emphasizes the\nimportance of timestamps for advanced online video understanding capability\nbenchmarking. OVO-Bench evaluates the ability of video LLMs to reason and\nrespond to events occurring at specific timestamps under three distinct\nscenarios: (1) Backward tracing: trace back to past events to answer the\nquestion. (2) Real-time understanding: understand and respond to events as they\nunfold at the current timestamp. (3) Forward active responding: delay the\nresponse until sufficient future information becomes available to answer the\nquestion accurately. OVO-Bench comprises 12 tasks, featuring 644 unique videos\nand approximately human-curated 2,800 fine-grained meta-annotations with\nprecise timestamps. We combine automated generation pipelines with human\ncuration. With these high-quality samples, we further developed an evaluation\npipeline to systematically query video LLMs along the video timeline.\nEvaluations of nine Video-LLMs reveal that, despite advancements on traditional\nbenchmarks, current models struggle with online video understanding, showing a\nsignificant gap compared to human agents. We hope OVO-Bench will drive progress\nin video LLMs and inspire future research in online video reasoning. Our\nbenchmark and code can be accessed at https://github.com/JoeLeelyf/OVO-Bench.", "paper_summary_zh": "\u6642\u9593\u611f\u77e5\uff0c\u5373\u6839\u64da\u554f\u984c\u63d0\u51fa\u7684\u6642\u9593\u6233\u9032\u884c\u52d5\u614b\u63a8\u7406\u7684\u80fd\u529b\uff0c\u662f\u5728\u7dda\u548c\u96e2\u7dda\u5f71\u7247 LLM \u4e4b\u9593\u7684\u4e3b\u8981\u5340\u5225\u3002\u8207\u4f9d\u8cf4\u5b8c\u6574\u5f71\u7247\u9032\u884c\u975c\u614b\u4e8b\u5f8c\u5206\u6790\u7684\u96e2\u7dda\u6a21\u578b\u4e0d\u540c\uff0c\u5728\u7dda\u6a21\u578b\u6703\u905e\u589e\u5730\u8655\u7406\u5f71\u7247\u4e32\u6d41\uff0c\u4e26\u6839\u64da\u554f\u984c\u63d0\u51fa\u7684\u6642\u9593\u6233\u52d5\u614b\u8abf\u6574\u5176\u56de\u61c9\u3002\u5118\u7ba1\u6642\u9593\u611f\u77e5\u5f88\u91cd\u8981\uff0c\u4f46\u5728\u73fe\u6709\u57fa\u6e96\u6e2c\u8a66\u4e2d\u5c1a\u672a\u5f97\u5230\u5145\u5206\u8a55\u4f30\u3002\u70ba\u4e86\u586b\u88dc\u9019\u4e00\u7a7a\u767d\uff0c\u6211\u5011\u63d0\u51fa\u4e86 OVO-Bench\uff08Online-VideO-Benchmark\uff09\uff0c\u9019\u662f\u4e00\u500b\u65b0\u7a4e\u7684\u5f71\u7247\u57fa\u6e96\u6e2c\u8a66\uff0c\u5f37\u8abf\u6642\u9593\u6233\u5c0d\u65bc\u5148\u9032\u7684\u5728\u7dda\u5f71\u7247\u7406\u89e3\u80fd\u529b\u57fa\u6e96\u6e2c\u8a66\u7684\u91cd\u8981\u6027\u3002OVO-Bench \u8a55\u4f30\u5f71\u7247 LLM \u5728\u4e09\u7a2e\u4e0d\u540c\u60c5\u6cc1\u4e0b\u5c0d\u7279\u5b9a\u6642\u9593\u6233\u767c\u751f\u7684\u4e8b\u4ef6\u9032\u884c\u63a8\u7406\u548c\u56de\u61c9\u7684\u80fd\u529b\uff1a(1) \u5411\u5f8c\u8ffd\u6eaf\uff1a\u8ffd\u6eaf\u904e\u53bb\u7684\u4e8b\u4ef6\u4ee5\u56de\u7b54\u554f\u984c\u3002(2) \u5be6\u6642\u7406\u89e3\uff1a\u7406\u89e3\u4e26\u56de\u61c9\u5728\u7576\u524d\u6642\u9593\u6233\u5c55\u958b\u7684\u4e8b\u4ef6\u3002(3) \u524d\u5411\u4e3b\u52d5\u56de\u61c9\uff1a\u5ef6\u9072\u56de\u61c9\uff0c\u76f4\u5230\u6709\u8db3\u5920\u7684\u672a\u4f86\u8cc7\u8a0a\u53ef\u7528\u65bc\u6e96\u78ba\u56de\u7b54\u554f\u984c\u3002OVO-Bench \u5305\u542b 12 \u9805\u4efb\u52d9\uff0c\u5177\u6709 644 \u500b\u7368\u7279\u7684\u5f71\u7247\u548c\u7d04 2,800 \u500b\u7d93\u904e\u4eba\u5de5\u7b56\u5283\u7684\u7cbe\u7d30\u5316\u5143\u8a3b\u89e3\uff0c\u4e26\u9644\u6709\u7cbe\u78ba\u7684\u6642\u9593\u6233\u3002\u6211\u5011\u5c07\u81ea\u52d5\u5316\u751f\u6210\u7ba1\u9053\u8207\u4eba\u5de5\u7b56\u5283\u76f8\u7d50\u5408\u3002\u6709\u4e86\u9019\u4e9b\u9ad8\u54c1\u8cea\u7684\u7bc4\u4f8b\uff0c\u6211\u5011\u9032\u4e00\u6b65\u958b\u767c\u4e86\u4e00\u500b\u8a55\u4f30\u7ba1\u9053\uff0c\u4ee5\u7cfb\u7d71\u5730\u67e5\u8a62\u5f71\u7247 LLM \u6cbf\u8457\u5f71\u7247\u6642\u9593\u8ef8\u3002\u5c0d\u4e5d\u500b Video-LLM \u7684\u8a55\u4f30\u8868\u660e\uff0c\u5118\u7ba1\u5728\u50b3\u7d71\u57fa\u6e96\u6e2c\u8a66\u65b9\u9762\u53d6\u5f97\u4e86\u9032\u5c55\uff0c\u4f46\u76ee\u524d\u7684\u6a21\u578b\u5728\u5728\u7dda\u5f71\u7247\u7406\u89e3\u65b9\u9762\u4ecd\u5b58\u5728\u56f0\u96e3\uff0c\u8207\u4eba\u985e\u4ee3\u7406\u76f8\u6bd4\u5b58\u5728\u986f\u8457\u5dee\u8ddd\u3002\u6211\u5011\u5e0c\u671b OVO-Bench \u80fd\u5920\u63a8\u52d5\u5f71\u7247 LLM \u7684\u9032\u5c55\uff0c\u4e26\u6fc0\u52f5\u672a\u4f86\u5728\u7dda\u5f71\u7247\u63a8\u7406\u7684\u7814\u7a76\u3002\u6211\u5011\u7684\u57fa\u6e96\u6e2c\u8a66\u548c\u7a0b\u5f0f\u78bc\u53ef\u4ee5\u5728 https://github.com/JoeLeelyf/OVO-Bench \u53d6\u5f97\u3002", "author": "Yifei Li et.al.", "authors": "Yifei Li, Junbo Niu, Ziyang Miao, Chunjiang Ge, Yuanhang Zhou, Qihao He, Xiaoyi Dong, Haodong Duan, Shuangrui Ding, Rui Qian, Pan Zhang, Yuhang Zang, Yuhang Cao, Conghui He, Jiaqi Wang", "id": "2501.05510v1", "paper_url": "http://arxiv.org/abs/2501.05510v1", "repo": "https://github.com/joeleelyf/ovo-bench"}}