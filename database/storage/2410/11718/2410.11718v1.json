{"2410.11718": {"publish_time": "2024-10-15", "title": "Converging to a Lingua Franca: Evolution of Linguistic Regions and Semantics Alignment in Multilingual Large Language Models", "paper_summary": "Large language models (LLMs) have demonstrated remarkable performance,\nparticularly in multilingual contexts. While recent studies suggest that LLMs\ncan transfer skills learned in one language to others, the internal mechanisms\nbehind this ability remain unclear. We observed that the neuron activation\npatterns of LLMs exhibit similarities when processing the same language,\nrevealing the existence and location of key linguistic regions. Additionally,\nwe found that neuron activation patterns are similar when processing sentences\nwith the same semantic meaning in different languages. This indicates that LLMs\nmap semantically identical inputs from different languages into a \"Lingua\nFranca\", a common semantic latent space that allows for consistent processing\nacross languages. This semantic alignment becomes more pronounced with training\nand increased model size, resulting in a more language-agnostic activation\npattern. Moreover, we found that key linguistic neurons are concentrated in the\nfirst and last layers of LLMs, becoming denser in the first layers as training\nprogresses. Experiments on BLOOM and LLaMA2 support these findings,\nhighlighting the structural evolution of multilingual LLMs during training and\nscaling up. This paper provides insights into the internal workings of LLMs,\noffering a foundation for future improvements in their cross-lingual\ncapabilities.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5c55\u73fe\u51fa\u5353\u8d8a\u7684\u6548\u80fd\uff0c\u7279\u5225\u662f\u5728\u591a\u8a9e\u8a00\u7684\u74b0\u5883\u4e2d\u3002\u96d6\u7136\u6700\u8fd1\u7684\u7814\u7a76\u8868\u660e LLM \u53ef\u4ee5\u5c07\u5728\u4e00\u7a2e\u8a9e\u8a00\u4e2d\u7fd2\u5f97\u7684\u6280\u80fd\u8f49\u79fb\u5230\u5176\u4ed6\u8a9e\u8a00\uff0c\u4f46\u9019\u7a2e\u80fd\u529b\u80cc\u5f8c\u7684\u5167\u90e8\u6a5f\u5236\u4ecd\u4e0d\u6e05\u695a\u3002\u6211\u5011\u89c0\u5bdf\u5230\uff0cLLM \u7684\u795e\u7d93\u5143\u6d3b\u5316\u6a21\u5f0f\u5728\u8655\u7406\u540c\u7a2e\u8a9e\u8a00\u6642\u8868\u73fe\u51fa\u76f8\u4f3c\u6027\uff0c\u63ed\u793a\u4e86\u95dc\u9375\u8a9e\u8a00\u5340\u57df\u7684\u5b58\u5728\u548c\u4f4d\u7f6e\u3002\u6b64\u5916\uff0c\u6211\u5011\u767c\u73fe\uff0c\u5728\u8655\u7406\u4e0d\u540c\u8a9e\u8a00\u4e2d\u5177\u6709\u76f8\u540c\u8a9e\u7fa9\u610f\u7fa9\u7684\u53e5\u5b50\u6642\uff0c\u795e\u7d93\u5143\u6d3b\u5316\u6a21\u5f0f\u662f\u76f8\u4f3c\u7684\u3002\u9019\u8868\u660e LLM \u5c07\u4f86\u81ea\u4e0d\u540c\u8a9e\u8a00\u7684\u8a9e\u7fa9\u4e0a\u76f8\u540c\u7684\u8f38\u5165\u6620\u5c04\u5230\u4e00\u500b\u300c\u901a\u7528\u8a9e\u300d\uff0c\u4e00\u500b\u901a\u7528\u7684\u8a9e\u7fa9\u6f5b\u5728\u7a7a\u9593\uff0c\u5141\u8a31\u8de8\u8a9e\u8a00\u9032\u884c\u4e00\u81f4\u7684\u8655\u7406\u3002\u9019\u7a2e\u8a9e\u7fa9\u5c0d\u9f4a\u96a8\u8457\u8a13\u7df4\u548c\u6a21\u578b\u898f\u6a21\u7684\u589e\u52a0\u800c\u8b8a\u5f97\u66f4\u52a0\u660e\u986f\uff0c\u5f9e\u800c\u7522\u751f\u66f4\u8207\u8a9e\u8a00\u7121\u95dc\u7684\u6d3b\u5316\u6a21\u5f0f\u3002\u6b64\u5916\uff0c\u6211\u5011\u767c\u73fe\u95dc\u9375\u8a9e\u8a00\u795e\u7d93\u5143\u96c6\u4e2d\u5728 LLM \u7684\u7b2c\u4e00\u5c64\u548c\u6700\u5f8c\u4e00\u5c64\uff0c\u96a8\u8457\u8a13\u7df4\u7684\u9032\u884c\uff0c\u5b83\u5011\u5728\u7b2c\u4e00\u5c64\u8b8a\u5f97\u66f4\u5bc6\u96c6\u3002\u5c0d BLOOM \u548c LLaMA2 \u7684\u5be6\u9a57\u652f\u6301\u4e86\u9019\u4e9b\u767c\u73fe\uff0c\u7a81\u51fa\u4e86\u591a\u8a9e\u8a00 LLM \u5728\u8a13\u7df4\u548c\u64f4\u5c55\u904e\u7a0b\u4e2d\u7684\u7d50\u69cb\u6f14\u5316\u3002\u672c\u6587\u63d0\u4f9b\u4e86\u5c0d LLM \u5167\u90e8\u904b\u4f5c\u7684\u898b\u89e3\uff0c\u70ba\u672a\u4f86\u63d0\u9ad8\u5176\u8de8\u8a9e\u8a00\u80fd\u529b\u5960\u5b9a\u4e86\u57fa\u790e\u3002", "author": "Hongchuan Zeng et.al.", "authors": "Hongchuan Zeng, Senyu Han, Lu Chen, Kai Yu", "id": "2410.11718v1", "paper_url": "http://arxiv.org/abs/2410.11718v1", "repo": "null"}}