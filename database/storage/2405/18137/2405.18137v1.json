{"2405.18137": {"publish_time": "2024-05-28", "title": "Exploiting LLM Quantization", "paper_summary": "Quantization leverages lower-precision weights to reduce the memory usage of\nlarge language models (LLMs) and is a key technique for enabling their\ndeployment on commodity hardware. While LLM quantization's impact on utility\nhas been extensively explored, this work for the first time studies its adverse\neffects from a security perspective. We reveal that widely used quantization\nmethods can be exploited to produce a harmful quantized LLM, even though the\nfull-precision counterpart appears benign, potentially tricking users into\ndeploying the malicious quantized model. We demonstrate this threat using a\nthree-staged attack framework: (i) first, we obtain a malicious LLM through\nfine-tuning on an adversarial task; (ii) next, we quantize the malicious model\nand calculate constraints that characterize all full-precision models that map\nto the same quantized model; (iii) finally, using projected gradient descent,\nwe tune out the poisoned behavior from the full-precision model while ensuring\nthat its weights satisfy the constraints computed in step (ii). This procedure\nresults in an LLM that exhibits benign behavior in full precision but when\nquantized, it follows the adversarial behavior injected in step (i). We\nexperimentally demonstrate the feasibility and severity of such an attack\nacross three diverse scenarios: vulnerable code generation, content injection,\nand over-refusal attack. In practice, the adversary could host the resulting\nfull-precision model on an LLM community hub such as Hugging Face, exposing\nmillions of users to the threat of deploying its malicious quantized version on\ntheir devices.", "paper_summary_zh": "\u91cf\u5316\u5229\u7528\u4f4e\u7cbe\u5ea6\u6b0a\u91cd\u4f86\u6e1b\u5c11\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u8a18\u61b6\u9ad4\u4f7f\u7528\u91cf\uff0c\u4e26\u4e14\u662f\u8b93\u5b83\u5011\u80fd\u5920\u5728\u5546\u54c1\u786c\u9ad4\u4e0a\u90e8\u7f72\u7684\u95dc\u9375\u6280\u8853\u3002\u5118\u7ba1 LLM \u91cf\u5316\u5c0d\u6548\u7528\u7684\u5f71\u97ff\u5df2\u5ee3\u6cdb\u63a2\u8a0e\uff0c\u4f46\u9019\u9805\u5de5\u4f5c\u9996\u6b21\u5f9e\u5b89\u5168\u89d2\u5ea6\u7814\u7a76\u5176\u8ca0\u9762\u5f71\u97ff\u3002\u6211\u5011\u63ed\u9732\u5ee3\u6cdb\u4f7f\u7528\u7684\u91cf\u5316\u65b9\u6cd5\u53ef\u4ee5\u88ab\u5229\u7528\u4f86\u7522\u751f\u6709\u5bb3\u7684\u91cf\u5316 LLM\uff0c\u5373\u4f7f\u5168\u7cbe\u5ea6\u5c0d\u61c9\u7269\u770b\u8d77\u4f86\u662f\u826f\u6027\u7684\uff0c\u6f5b\u5728\u5730\u8a98\u9a19\u4f7f\u7528\u8005\u90e8\u7f72\u60e1\u610f\u7684\u91cf\u5316\u6a21\u578b\u3002\u6211\u5011\u4f7f\u7528\u4e09\u968e\u6bb5\u653b\u64ca\u67b6\u69cb\u4f86\u5c55\u793a\u6b64\u5a01\u8105\uff1a(i) \u9996\u5148\uff0c\u6211\u5011\u900f\u904e\u5728\u5c0d\u6297\u4efb\u52d9\u4e0a\u9032\u884c\u5fae\u8abf\u4f86\u7372\u5f97\u60e1\u610f LLM\uff1b(ii) \u63a5\u8457\uff0c\u6211\u5011\u91cf\u5316\u60e1\u610f\u6a21\u578b\u4e26\u8a08\u7b97\u51fa\u63cf\u8ff0\u6240\u6709\u6620\u5c04\u5230\u76f8\u540c\u91cf\u5316\u6a21\u578b\u7684\u5168\u7cbe\u5ea6\u6a21\u578b\u7684\u7d04\u675f\uff1b(iii) \u6700\u5f8c\uff0c\u4f7f\u7528\u6295\u5f71\u68af\u5ea6\u4e0b\u964d\uff0c\u6211\u5011\u8abf\u6574\u51fa\u5168\u7cbe\u5ea6\u6a21\u578b\u4e2d\u7684\u4e2d\u6bd2\u884c\u70ba\uff0c\u540c\u6642\u78ba\u4fdd\u5176\u6b0a\u91cd\u6eff\u8db3\u5728\u6b65\u9a5f (ii) \u4e2d\u8a08\u7b97\u51fa\u7684\u7d04\u675f\u3002\u6b64\u7a0b\u5e8f\u6703\u7522\u751f\u4e00\u500b LLM\uff0c\u5b83\u5728\u5168\u7cbe\u5ea6\u6642\u8868\u73fe\u51fa\u826f\u6027\u884c\u70ba\uff0c\u4f46\u5728\u91cf\u5316\u6642\uff0c\u5b83\u6703\u9075\u5faa\u5728\u6b65\u9a5f (i) \u4e2d\u6ce8\u5165\u7684\u5c0d\u6297\u884c\u70ba\u3002\u6211\u5011\u5728\u4e09\u7a2e\u4e0d\u540c\u7684\u60c5\u5883\u4e2d\u4ee5\u5be6\u9a57\u65b9\u5f0f\u8b49\u660e\u6b64\u985e\u653b\u64ca\u7684\u53ef\u884c\u6027\u548c\u56b4\u91cd\u6027\uff1a\u6613\u53d7\u653b\u64ca\u7684\u7a0b\u5f0f\u78bc\u7522\u751f\u3001\u5167\u5bb9\u6ce8\u5165\u548c\u904e\u5ea6\u62d2\u7d55\u653b\u64ca\u3002\u5728\u5be6\u52d9\u4e0a\uff0c\u5c0d\u624b\u53ef\u4ee5\u5c07\u7522\u751f\u7684\u5168\u7cbe\u5ea6\u6a21\u578b\u8a17\u7ba1\u5728 LLM \u793e\u7fa4\u4e2d\u5fc3\uff0c\u4f8b\u5982 Hugging Face\uff0c\u8b93\u6578\u767e\u842c\u4f7f\u7528\u8005\u9762\u81e8\u5728\u5176\u88dd\u7f6e\u4e0a\u90e8\u7f72\u5176\u60e1\u610f\u91cf\u5316\u7248\u672c\u7684\u5a01\u8105\u3002", "author": "Kazuki Egashira et.al.", "authors": "Kazuki Egashira, Mark Vero, Robin Staab, Jingxuan He, Martin Vechev", "id": "2405.18137v1", "paper_url": "http://arxiv.org/abs/2405.18137v1", "repo": "null"}}