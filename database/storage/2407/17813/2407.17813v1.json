{"2407.17813": {"publish_time": "2024-07-25", "title": "Enhancing Model Performance: Another Approach to Vision-Language Instruction Tuning", "paper_summary": "The integration of large language models (LLMs) with vision-language (VL)\ntasks has been a transformative development in the realm of artificial\nintelligence, highlighting the potential of LLMs as a versatile general-purpose\nchatbot. However, the current trend in this evolution focuses on the\nintegration of vision and language to create models that can operate in more\ndiverse and real-world contexts. We present a novel approach, termed Bottleneck\nAdapter, specifically crafted for enhancing the multimodal functionalities of\nthese complex models, enabling joint optimization of the entire multimodal LLM\nframework through a process known as Multimodal Model Tuning (MMT). Our\napproach utilizes lightweight adapters to connect the image encoder and LLM\nwithout the need for large, complex neural networks. Unlike the conventional\nmodular training schemes, our approach adopts an end-to-end optimization\nregime, which, when combined with the adapters, facilitates the joint\noptimization using a significantly smaller parameter set. Our method exhibits\nrobust performance with 90.12\\% accuracy, outperforming both human-level\nperformance (88.4\\%) and LaVIN-7B (89.41\\%).", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8207\u8996\u89ba\u8a9e\u8a00 (VL) \u4efb\u52d9\u7684\u6574\u5408\u662f\u4eba\u5de5\u667a\u6167\u9818\u57df\u7684\u4e00\u9805\u8b8a\u9769\u6027\u767c\u5c55\uff0c\u7a81\u986f\u4e86 LLM \u4f5c\u70ba\u591a\u529f\u80fd\u901a\u7528\u804a\u5929\u6a5f\u5668\u4eba\u7684\u6f5b\u529b\u3002\u7136\u800c\uff0c\u9019\u7a2e\u6f14\u5316\u7684\u7576\u524d\u8da8\u52e2\u8457\u91cd\u65bc\u6574\u5408\u8996\u89ba\u548c\u8a9e\u8a00\uff0c\u4ee5\u5efa\u7acb\u53ef\u5728\u66f4\u591a\u6a23\u5316\u4e14\u771f\u5be6\u4e16\u754c\u7684\u74b0\u5883\u4e2d\u904b\u4f5c\u7684\u6a21\u578b\u3002\u6211\u5011\u63d0\u51fa\u4e00\u500b\u65b0\u7a4e\u7684\u65b9\u6cd5\uff0c\u7a31\u70ba\u74f6\u9838\u9069\u914d\u5668\uff0c\u5c08\u9580\u7528\u65bc\u589e\u5f37\u9019\u4e9b\u8907\u96dc\u6a21\u578b\u7684\u591a\u6a21\u614b\u529f\u80fd\uff0c\u900f\u904e\u4e00\u500b\u7a31\u70ba\u591a\u6a21\u614b\u6a21\u578b\u8abf\u6574 (MMT) \u7684\u7a0b\u5e8f\uff0c\u5be6\u73fe\u6574\u500b\u591a\u6a21\u614b LLM \u67b6\u69cb\u7684\u806f\u5408\u6700\u4f73\u5316\u3002\u6211\u5011\u7684\u505a\u6cd5\u5229\u7528\u8f15\u91cf\u7d1a\u9069\u914d\u5668\u9023\u63a5\u5f71\u50cf\u7de8\u78bc\u5668\u548c LLM\uff0c\u800c\u4e0d\u9700\u8981\u5927\u578b\u3001\u8907\u96dc\u7684\u795e\u7d93\u7db2\u8def\u3002\u8207\u50b3\u7d71\u7684\u6a21\u7d44\u5316\u8a13\u7df4\u65b9\u6848\u4e0d\u540c\uff0c\u6211\u5011\u7684\u505a\u6cd5\u63a1\u7528\u7aef\u5230\u7aef\u6700\u4f73\u5316\u6a5f\u5236\uff0c\u7d50\u5408\u9069\u914d\u5668\u5f8c\uff0c\u6709\u52a9\u65bc\u4f7f\u7528\u986f\u8457\u8f03\u5c0f\u7684\u53c3\u6578\u96c6\u9032\u884c\u806f\u5408\u6700\u4f73\u5316\u3002\u6211\u5011\u7684\u505a\u6cd5\u5c55\u73fe\u51fa\u7a69\u5065\u7684\u6548\u80fd\uff0c\u6e96\u78ba\u5ea6\u9054 90.12%\uff0c\u8d85\u8d8a\u4eba\u985e\u6c34\u6e96\u7684\u6548\u80fd (88.4%) \u548c LaVIN-7B (89.41%)\u3002", "author": "Vedanshu et.al.", "authors": "Vedanshu, MM Tripathi, Bhavnesh Jaint", "id": "2407.17813v1", "paper_url": "http://arxiv.org/abs/2407.17813v1", "repo": "null"}}