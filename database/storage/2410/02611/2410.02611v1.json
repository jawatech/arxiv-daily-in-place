{"2410.02611": {"publish_time": "2024-10-03", "title": "IndicSentEval: How Effectively do Multilingual Transformer Models encode Linguistic Properties for Indic Languages?", "paper_summary": "Transformer-based models have revolutionized the field of natural language\nprocessing. To understand why they perform so well and to assess their\nreliability, several studies have focused on questions such as: Which\nlinguistic properties are encoded by these models, and to what extent? How\nrobust are these models in encoding linguistic properties when faced with\nperturbations in the input text? However, these studies have mainly focused on\nBERT and the English language. In this paper, we investigate similar questions\nregarding encoding capability and robustness for 8 linguistic properties across\n13 different perturbations in 6 Indic languages, using 9 multilingual\nTransformer models (7 universal and 2 Indic-specific). To conduct this study,\nwe introduce a novel multilingual benchmark dataset, IndicSentEval, containing\napproximately $\\sim$47K sentences. Surprisingly, our probing analysis of\nsurface, syntactic, and semantic properties reveals that while almost all\nmultilingual models demonstrate consistent encoding performance for English,\nthey show mixed results for Indic languages. As expected, Indic-specific\nmultilingual models capture linguistic properties in Indic languages better\nthan universal models. Intriguingly, universal models broadly exhibit better\nrobustness compared to Indic-specific models, particularly under perturbations\nsuch as dropping both nouns and verbs, dropping only verbs, or keeping only\nnouns. Overall, this study provides valuable insights into probing and\nperturbation-specific strengths and weaknesses of popular multilingual\nTransformer-based models for different Indic languages. We make our code and\ndataset publicly available [https://tinyurl.com/IndicSentEval}].", "paper_summary_zh": "<paragraph>\u57fa\u65bc Transformer \u7684\u6a21\u578b\u5df2\u7d93\u5fb9\u5e95\u6539\u8b8a\u4e86\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u9818\u57df\u3002\u70ba\u4e86\u4e86\u89e3\u5b83\u5011\u70ba\u4f55\u8868\u73fe\u5982\u6b64\u51fa\u8272\uff0c\u4e26\u8a55\u4f30\u5b83\u5011\u7684\u53ef\u9760\u6027\uff0c\u591a\u9805\u7814\u7a76\u5c08\u6ce8\u65bc\u4ee5\u4e0b\u554f\u984c\uff1a\u9019\u4e9b\u6a21\u578b\u7de8\u78bc\u4e86\u54ea\u4e9b\u8a9e\u8a00\u7279\u6027\uff0c\u7de8\u78bc\u7a0b\u5ea6\u5982\u4f55\uff1f\u9019\u4e9b\u6a21\u578b\u5728\u9762\u5c0d\u8f38\u5165\u6587\u5b57\u4e2d\u7684\u64fe\u52d5\u6642\uff0c\u7de8\u78bc\u8a9e\u8a00\u7279\u6027\u7684\u7a69\u5065\u6027\u5982\u4f55\uff1f\u7136\u800c\uff0c\u9019\u4e9b\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u65bc BERT \u548c\u82f1\u6587\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u7814\u7a76\u4e86 6 \u7a2e\u5370\u5ea6\u8a9e\u8a00\u4e2d 13 \u7a2e\u4e0d\u540c\u64fe\u52d5\u7684 8 \u7a2e\u8a9e\u8a00\u7279\u6027\u7684\u7de8\u78bc\u80fd\u529b\u548c\u7a69\u5065\u6027\uff0c\u4e26\u4f7f\u7528\u4e86 9 \u7a2e\u591a\u8a9e\u8a00 Transformer \u6a21\u578b\uff087 \u7a2e\u901a\u7528\u6a21\u578b\u548c 2 \u7a2e\u5370\u5ea6\u7279\u5b9a\u6a21\u578b\uff09\u3002\u70ba\u4e86\u9032\u884c\u9019\u9805\u7814\u7a76\uff0c\u6211\u5011\u5f15\u5165\u4e86\u65b0\u7684\u591a\u8a9e\u8a00\u57fa\u6e96\u6578\u64da\u96c6 IndicSentEval\uff0c\u5176\u4e2d\u5305\u542b\u5927\u7d04 47K \u500b\u53e5\u5b50\u3002\u4ee4\u4eba\u9a5a\u8a1d\u7684\u662f\uff0c\u6211\u5011\u5c0d\u8868\u9762\u3001\u8a9e\u6cd5\u548c\u8a9e\u7fa9\u7279\u6027\u7684\u63a2\u6e2c\u5206\u6790\u986f\u793a\uff0c\u96d6\u7136\u5e7e\u4e4e\u6240\u6709\u591a\u8a9e\u8a00\u6a21\u578b\u90fd\u5c55\u73fe\u51fa\u4e00\u81f4\u7684\u82f1\u6587\u7de8\u78bc\u6548\u80fd\uff0c\u4f46\u5b83\u5011\u5728\u5370\u5ea6\u8a9e\u8a00\u65b9\u9762\u537b\u5448\u73fe\u51fa\u597d\u58de\u53c3\u534a\u7684\u7d50\u679c\u3002\u6b63\u5982\u9810\u671f\uff0c\u5370\u5ea6\u7279\u5b9a\u591a\u8a9e\u8a00\u6a21\u578b\u6bd4\u901a\u7528\u6a21\u578b\u66f4\u80fd\u6355\u6349\u5370\u5ea6\u8a9e\u8a00\u4e2d\u7684\u8a9e\u8a00\u7279\u6027\u3002\u6709\u8da3\u7684\u662f\uff0c\u8207\u5370\u5ea6\u7279\u5b9a\u6a21\u578b\u76f8\u6bd4\uff0c\u901a\u7528\u6a21\u578b\u666e\u904d\u8868\u73fe\u51fa\u66f4\u597d\u7684\u7a69\u5065\u6027\uff0c\u7279\u5225\u662f\u5728\u4e1f\u68c4\u540d\u8a5e\u548c\u52d5\u8a5e\u3001\u50c5\u4e1f\u68c4\u52d5\u8a5e\u6216\u50c5\u4fdd\u7559\u540d\u8a5e\u7b49\u64fe\u52d5\u4e0b\u3002\u7e3d\u9ad4\u800c\u8a00\uff0c\u9019\u9805\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u50f9\u503c\u7684\u898b\u89e3\uff0c\u7528\u65bc\u63a2\u6e2c\u548c\u64fe\u52d5\u7279\u5b9a\u512a\u52e2\u548c\u52a3\u52e2\uff0c\u4ee5\u4e86\u89e3\u4e0d\u540c\u5370\u5ea6\u8a9e\u8a00\u7684\u591a\u8a9e\u8a00\u57fa\u65bc Transformer \u7684\u71b1\u9580\u6a21\u578b\u3002\u6211\u5011\u516c\u958b\u4e86\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u548c\u6578\u64da\u96c6 [https://tinyurl.com/IndicSentEval}].</paragraph>", "author": "Akhilesh Aravapalli et.al.", "authors": "Akhilesh Aravapalli, Mounika Marreddy, Subba Reddy Oota, Radhika Mamidi, Manish Gupta", "id": "2410.02611v1", "paper_url": "http://arxiv.org/abs/2410.02611v1", "repo": "null"}}