{"2405.04065": {"publish_time": "2024-05-07", "title": "FlashBack:Efficient Retrieval-Augmented Language Modeling for Long Context Inference", "paper_summary": "Retrieval-Augmented Language Modeling (RALM) by integrating large language\nmodels (LLM) with relevant documents from an external corpus is a proven method\nfor enabling the LLM to generate information beyond the scope of its\npre-training corpus. Previous work using utilizing retrieved content by simply\nprepending retrieved contents to the input poses a high runtime issue, which\ndegrades the inference efficiency of the LLMs because they fail to use the\nKey-Value (KV) cache efficiently. In this paper, we propose \\textsc{FlashBack},\na modular RALM designed to improve the inference efficiency of RALM with\nappending context pattern while maintaining decent performance after specific\nfine-tuning without heavily destruct the knowledge integrity of the LLM.\n\\textsc{FlashBack} appends retrieved documents at the end of the context for\nefficiently utilizing the KV cache instead of prepending them. Our experiment\nshows that the inference speed of \\textsc{FlashBack} is up to $4\\times$ faster\nthan the prepending method on a 7B LLM (Llama 2). Via bypassing unnecessary\nre-computation, it demonstrates an advancement by achieving significantly\nfaster inference speed, and this heightened efficiency will substantially\nreduce inferential cost. Our code will be publicly available.", "paper_summary_zh": "\u6aa2\u7d22\u64f4\u5145\u8a9e\u8a00\u6a21\u578b (RALM) \u900f\u904e\u6574\u5408\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8207\u5916\u90e8\u8a9e\u6599\u5eab\u4e2d\u7684\u76f8\u95dc\u6587\u4ef6\uff0c\u662f\u4e00\u7a2e\u5df2\u8b49\u5be6\u7684\u65b9\u6cd5\uff0c\u53ef\u8b93 LLM \u7522\u751f\u8d85\u51fa\u5176\u9810\u8a13\u7df4\u8a9e\u6599\u5eab\u7bc4\u570d\u7684\u8cc7\u8a0a\u3002\u5148\u524d\u5229\u7528\u6aa2\u7d22\u5167\u5bb9\u7684\u5de5\u4f5c\uff0c\u50c5\u900f\u904e\u5c07\u6aa2\u7d22\u5167\u5bb9\u9810\u5148\u9644\u52a0\u81f3\u8f38\u5165\uff0c\u6703\u9020\u6210\u9ad8\u57f7\u884c\u6642\u9593\u554f\u984c\uff0c\u9032\u800c\u964d\u4f4e LLM \u63a8\u8ad6\u6548\u7387\uff0c\u56e0\u70ba\u4ed6\u5011\u7121\u6cd5\u6709\u6548\u4f7f\u7528\u9375\u503c (KV) \u5feb\u53d6\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa \\textsc{FlashBack}\uff0c\u4e00\u500b\u6a21\u7d44\u5316 RALM\uff0c\u65e8\u5728\u900f\u904e\u9644\u52a0\u8108\u7d61\u6a21\u5f0f\u4f86\u6539\u5584 RALM \u7684\u63a8\u8ad6\u6548\u7387\uff0c\u540c\u6642\u5728\u7279\u5b9a\u5fae\u8abf\u5f8c\u7dad\u6301\u826f\u597d\u7684\u6548\u80fd\uff0c\u800c\u4e0d\u6703\u56b4\u91cd\u7834\u58de LLM \u7684\u77e5\u8b58\u5b8c\u6574\u6027\u3002\\textsc{FlashBack} \u5c07\u6aa2\u7d22\u5230\u7684\u6587\u4ef6\u9644\u52a0\u5728\u8108\u7d61\u7684\u7d50\u5c3e\uff0c\u4ee5\u6709\u6548\u5229\u7528 KV \u5feb\u53d6\uff0c\u800c\u975e\u5c07\u5176\u9810\u5148\u9644\u52a0\u3002\u6211\u5011\u7684\u5be6\u9a57\u986f\u793a\uff0c\\textsc{FlashBack} \u7684\u63a8\u8ad6\u901f\u5ea6\u5728 7B LLM (Llama 2) \u4e0a\u6bd4\u9810\u5148\u9644\u52a0\u65b9\u6cd5\u5feb $4\\times$ \u4ee5\u4e0a\u3002\u900f\u904e\u7e5e\u904e\u4e0d\u5fc5\u8981\u7684\u91cd\u65b0\u904b\u7b97\uff0c\u5b83\u900f\u904e\u9054\u6210\u986f\u8457\u66f4\u5feb\u7684\u63a8\u8ad6\u901f\u5ea6\u4f86\u5c55\u73fe\u9032\u5c55\uff0c\u800c\u9019\u7a2e\u66f4\u9ad8\u7684\u6548\u7387\u5c07\u5927\u5e45\u964d\u4f4e\u63a8\u8ad6\u6210\u672c\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u5c07\u516c\u958b\u63d0\u4f9b\u3002", "author": "Runheng Liu et.al.", "authors": "Runheng Liu, Xingchen Xiao, Heyan Huang, Zewen Chi, Zhijing Wu", "id": "2405.04065v1", "paper_url": "http://arxiv.org/abs/2405.04065v1", "repo": "null"}}