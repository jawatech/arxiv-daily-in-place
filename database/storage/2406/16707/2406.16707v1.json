{"2406.16707": {"publish_time": "2024-06-24", "title": "Probabilistic Subgoal Representations for Hierarchical Reinforcement learning", "paper_summary": "In goal-conditioned hierarchical reinforcement learning (HRL), a high-level\npolicy specifies a subgoal for the low-level policy to reach. Effective HRL\nhinges on a suitable subgoal represen tation function, abstracting state space\ninto latent subgoal space and inducing varied low-level behaviors. Existing\nmethods adopt a subgoal representation that provides a deterministic mapping\nfrom state space to latent subgoal space. Instead, this paper utilizes Gaussian\nProcesses (GPs) for the first probabilistic subgoal representation. Our method\nemploys a GP prior on the latent subgoal space to learn a posterior\ndistribution over the subgoal representation functions while exploiting the\nlong-range correlation in the state space through learnable kernels. This\nenables an adaptive memory that integrates long-range subgoal information from\nprior planning steps allowing to cope with stochastic uncertainties.\nFurthermore, we propose a novel learning objective to facilitate the\nsimultaneous learning of probabilistic subgoal representations and policies\nwithin a unified framework. In experiments, our approach outperforms\nstate-of-the-art baselines in standard benchmarks but also in environments with\nstochastic elements and under diverse reward conditions. Additionally, our\nmodel shows promising capabilities in transferring low-level policies across\ndifferent tasks.", "paper_summary_zh": "\u5728\u76ee\u6a19\u689d\u4ef6\u5206\u5c64\u5f37\u5316\u5b78\u7fd2 (HRL) \u4e2d\uff0c\u9ad8\u968e\u653f\u7b56\u6703\u70ba\u4f4e\u968e\u653f\u7b56\u6307\u5b9a\u4e00\u500b\u5b50\u76ee\u6a19\u3002\u6709\u6548\u7684 HRL \u53d6\u6c7a\u65bc\u4e00\u500b\u5408\u9069\u7684\u5b50\u76ee\u6a19\u8868\u793a\u51fd\u6578\uff0c\u5c07\u72c0\u614b\u7a7a\u9593\u62bd\u8c61\u6210\u6f5b\u5728\u5b50\u76ee\u6a19\u7a7a\u9593\uff0c\u4e26\u8a98\u767c\u5404\u7a2e\u4f4e\u968e\u884c\u70ba\u3002\u73fe\u6709\u65b9\u6cd5\u63a1\u7528\u4e00\u500b\u5b50\u76ee\u6a19\u8868\u793a\uff0c\u63d0\u4f9b\u5f9e\u72c0\u614b\u7a7a\u9593\u5230\u6f5b\u5728\u5b50\u76ee\u6a19\u7a7a\u9593\u7684\u78ba\u5b9a\u6027\u5c0d\u61c9\u3002\u76f8\u53cd\uff0c\u672c\u6587\u5229\u7528\u9ad8\u65af\u7a0b\u5e8f (GP) \u4f5c\u70ba\u7b2c\u4e00\u500b\u6a5f\u7387\u5b50\u76ee\u6a19\u8868\u793a\u3002\u6211\u5011\u7684\u65b9\u6cd5\u63a1\u7528\u6f5b\u5728\u5b50\u76ee\u6a19\u7a7a\u9593\u4e0a\u7684 GP \u5148\u9a57\u4f86\u5b78\u7fd2\u5b50\u76ee\u6a19\u8868\u793a\u51fd\u6578\u4e0a\u7684\u5f8c\u9a57\u5206\u4f48\uff0c\u540c\u6642\u900f\u904e\u53ef\u5b78\u7fd2\u6838\u4f86\u5229\u7528\u72c0\u614b\u7a7a\u9593\u4e2d\u7684\u9577\u7a0b\u95dc\u806f\u3002\u9019\u80fd\u5efa\u7acb\u4e00\u500b\u9069\u61c9\u6027\u8a18\u61b6\u9ad4\uff0c\u6574\u5408\u4f86\u81ea\u5148\u524d\u898f\u5283\u6b65\u9a5f\u7684\u9577\u7a0b\u5b50\u76ee\u6a19\u8cc7\u8a0a\uff0c\u5141\u8a31\u61c9\u5c0d\u96a8\u6a5f\u4e0d\u78ba\u5b9a\u6027\u3002\u6b64\u5916\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u65b0\u7a4e\u7684\u5b78\u7fd2\u76ee\u6a19\uff0c\u4ee5\u4fc3\u9032\u5728\u7d71\u4e00\u67b6\u69cb\u4e2d\u540c\u6642\u5b78\u7fd2\u6a5f\u7387\u5b50\u76ee\u6a19\u8868\u793a\u548c\u653f\u7b56\u3002\u5728\u5be6\u9a57\u4e2d\uff0c\u6211\u5011\u7684\u505a\u6cd5\u5728\u6a19\u6e96\u57fa\u6e96\u4ee5\u53ca\u5728\u5177\u6709\u96a8\u6a5f\u5143\u7d20\u548c\u4e0d\u540c\u734e\u52f5\u689d\u4ef6\u7684\u74b0\u5883\u4e2d\u90fd\u512a\u65bc\u6700\u5148\u9032\u7684\u57fa\u6e96\u3002\u6b64\u5916\uff0c\u6211\u5011\u7684\u6a21\u578b\u5728\u4e0d\u540c\u4efb\u52d9\u9593\u8f49\u79fb\u4f4e\u968e\u653f\u7b56\u6642\uff0c\u5c55\u73fe\u51fa\u6709\u524d\u9014\u7684\u80fd\u529b\u3002", "author": "Vivienne Huiling Wang et.al.", "authors": "Vivienne Huiling Wang, Tinghuai Wang, Wenyan Yang, Joni-Kristian K\u00e4m\u00e4r\u00e4inen, Joni Pajarinen", "id": "2406.16707v1", "paper_url": "http://arxiv.org/abs/2406.16707v1", "repo": "null"}}