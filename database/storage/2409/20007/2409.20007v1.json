{"2409.20007": {"publish_time": "2024-09-30", "title": "Developing Instruction-Following Speech Language Model Without Speech Instruction-Tuning Data", "paper_summary": "Recent end-to-end speech language models (SLMs) have expanded upon the\ncapabilities of large language models (LLMs) by incorporating pre-trained\nspeech models. However, these SLMs often undergo extensive speech\ninstruction-tuning to bridge the gap between speech and text modalities. This\nrequires significant annotation efforts and risks catastrophic forgetting of\nthe original language capabilities. In this work, we present a simple yet\neffective automatic process for creating speech-text pair data that carefully\ninjects speech paralinguistic understanding abilities into SLMs while\npreserving the inherent language capabilities of the text-based LLM. Our model\ndemonstrates general capabilities for speech-related tasks without the need for\nspeech instruction-tuning data, achieving impressive performance on\nDynamic-SUPERB and AIR-Bench-Chat benchmarks. Furthermore, our model exhibits\nthe ability to follow complex instructions derived from LLMs, such as specific\noutput formatting and chain-of-thought reasoning. Our approach not only\nenhances the versatility and effectiveness of SLMs but also reduces reliance on\nextensive annotated datasets, paving the way for more efficient and capable\nspeech understanding systems.", "paper_summary_zh": "\u8fd1\u671f\u7684\u7aef\u5230\u7aef\u8bed\u97f3\u8bed\u8a00\u6a21\u578b (SLM) \u5df2\u901a\u8fc7\u6574\u5408\u9884\u5148\u8bad\u7ec3\u7684\u8bed\u97f3\u6a21\u578b\uff0c\u6269\u5927\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u7684\u80fd\u529b\u3002\u7136\u800c\uff0c\u8fd9\u4e9b SLM \u7ecf\u5e38\u8fdb\u884c\u5e7f\u6cdb\u7684\u8bed\u97f3\u6307\u4ee4\u5fae\u8c03\uff0c\u4ee5\u5f25\u5408\u8bed\u97f3\u548c\u6587\u672c\u6a21\u6001\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002\u8fd9\u9700\u8981\u5927\u91cf\u7684\u6807\u6ce8\u5de5\u4f5c\uff0c\u5e76\u4e14\u6709\u707e\u96be\u6027\u9057\u5fd8\u539f\u59cb\u8bed\u8a00\u80fd\u529b\u7684\u98ce\u9669\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e00\u4e2a\u7b80\u5355\u4f46\u6709\u6548\u7684\u81ea\u52a8\u6d41\u7a0b\u6765\u521b\u5efa\u8bed\u97f3\u6587\u672c\u5bf9\u6570\u636e\uff0c\u8be5\u6570\u636e\u5c06\u8bed\u97f3\u526f\u8bed\u8a00\u7406\u89e3\u80fd\u529b\u5c0f\u5fc3\u6ce8\u5165 SLM\uff0c\u540c\u65f6\u4fdd\u7559\u57fa\u4e8e\u6587\u672c\u7684 LLM \u7684\u56fa\u6709\u8bed\u8a00\u80fd\u529b\u3002\u6211\u4eec\u7684\u6a21\u578b\u5c55\u793a\u4e86\u5bf9\u4e0e\u8bed\u97f3\u76f8\u5173\u7684\u4efb\u52a1\u7684\u4e00\u822c\u80fd\u529b\uff0c\u800c\u4e0d\u9700\u8981\u8bed\u97f3\u6307\u4ee4\u5fae\u8c03\u6570\u636e\uff0c\u5728 Dynamic-SUPERB \u548c AIR-Bench-Chat \u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0c\u6211\u4eec\u7684\u6a21\u578b\u5c55\u793a\u4e86\u9075\u5faa\u4ece LLM \u884d\u751f\u7684\u590d\u6742\u6307\u4ee4\u7684\u80fd\u529b\uff0c\u4f8b\u5982\u7279\u5b9a\u7684\u8f93\u51fa\u683c\u5f0f\u548c\u601d\u60f3\u94fe\u63a8\u7406\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u4e0d\u4ec5\u589e\u5f3a\u4e86 SLM \u7684\u591a\u529f\u80fd\u6027\u548c\u6709\u6548\u6027\uff0c\u800c\u4e14\u51cf\u5c11\u4e86\u5bf9\u5927\u91cf\u6807\u6ce8\u6570\u636e\u96c6\u7684\u4f9d\u8d56\uff0c\u4e3a\u66f4\u9ad8\u6548\u3001\u66f4\u5f3a\u5927\u7684\u8bed\u97f3\u7406\u89e3\u7cfb\u7edf\u94fa\u5e73\u4e86\u9053\u8def\u3002", "author": "Ke-Han Lu et.al.", "authors": "Ke-Han Lu, Zhehuai Chen, Szu-Wei Fu, Chao-Han Huck Yang, Jagadeesh Balam, Boris Ginsburg, Yu-Chiang Frank Wang, Hung-yi Lee", "id": "2409.20007v1", "paper_url": "http://arxiv.org/abs/2409.20007v1", "repo": "null"}}