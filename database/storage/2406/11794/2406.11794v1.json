{"2406.11794": {"publish_time": "2024-06-17", "title": "DataComp-LM: In search of the next generation of training sets for language models", "paper_summary": "We introduce DataComp for Language Models (DCLM), a testbed for controlled\ndataset experiments with the goal of improving language models. As part of\nDCLM, we provide a standardized corpus of 240T tokens extracted from Common\nCrawl, effective pretraining recipes based on the OpenLM framework, and a broad\nsuite of 53 downstream evaluations. Participants in the DCLM benchmark can\nexperiment with data curation strategies such as deduplication, filtering, and\ndata mixing at model scales ranging from 412M to 7B parameters. As a baseline\nfor DCLM, we conduct extensive experiments and find that model-based filtering\nis key to assembling a high-quality training set. The resulting dataset,\nDCLM-Baseline enables training a 7B parameter language model from scratch to\n64% 5-shot accuracy on MMLU with 2.6T training tokens. Compared to MAP-Neo, the\nprevious state-of-the-art in open-data language models, DCLM-Baseline\nrepresents a 6.6 percentage point improvement on MMLU while being trained with\n40% less compute. Our baseline model is also comparable to Mistral-7B-v0.3 and\nLlama 3 8B on MMLU (63% & 66%), and performs similarly on an average of 53\nnatural language understanding tasks while being trained with 6.6x less compute\nthan Llama 3 8B. Our results highlight the importance of dataset design for\ntraining language models and offer a starting point for further research on\ndata curation.", "paper_summary_zh": "<paragraph>\u6211\u5011\u70ba\u8a9e\u8a00\u6a21\u578b (DCLM) \u5f15\u5165 DataComp\uff0c\u4e00\u500b\u7528\u65bc\u63a7\u5236\u8cc7\u6599\u96c6\u5be6\u9a57\u7684\u6e2c\u8a66\u5e73\u53f0\uff0c\u76ee\u6a19\u662f\u6539\u9032\u8a9e\u8a00\u6a21\u578b\u3002\u4f5c\u70ba DCLM \u7684\u4e00\u90e8\u5206\uff0c\u6211\u5011\u63d0\u4f9b\u4e00\u500b\u6a19\u6e96\u8a9e\u6599\u5eab\uff0c\u5305\u542b\u5f9e Common Crawl \u4e2d\u63d0\u53d6\u7684 240T \u500b\u7b26\u865f\uff0c\u57fa\u65bc OpenLM \u6846\u67b6\u7684\u6709\u6548\u9810\u8a13\u7df4\u914d\u65b9\uff0c\u4ee5\u53ca\u5ee3\u6cdb\u7684 53 \u500b\u4e0b\u6e38\u8a55\u4f30\u3002DCLM \u57fa\u6e96\u6e2c\u8a66\u7684\u53c3\u8207\u8005\u53ef\u4ee5\u5617\u8a66\u8cc7\u6599\u7b56\u5c55\u7b56\u7565\uff0c\u4f8b\u5982\u53bb\u91cd\u3001\u904e\u6ffe\u548c\u8cc7\u6599\u6df7\u5408\uff0c\u6a21\u578b\u898f\u6a21\u5f9e 412M \u5230 7B \u500b\u53c3\u6578\u3002\u4f5c\u70ba DCLM \u7684\u57fa\u6e96\uff0c\u6211\u5011\u9032\u884c\u4e86\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0c\u767c\u73fe\u57fa\u65bc\u6a21\u578b\u7684\u904e\u6ffe\u662f\u7d44\u88dd\u9ad8\u54c1\u8cea\u8a13\u7df4\u96c6\u7684\u95dc\u9375\u3002\u7531\u6b64\u7522\u751f\u7684\u8cc7\u6599\u96c6 DCLM-Baseline \u80fd\u5920\u5f9e\u982d\u958b\u59cb\u8a13\u7df4\u4e00\u500b 7B \u53c3\u6578\u8a9e\u8a00\u6a21\u578b\uff0c\u5728 MMLU \u4e0a\u4ee5 2.6T \u500b\u8a13\u7df4\u7b26\u865f\u9054\u5230 64% \u7684 5 \u6b21\u6e96\u78ba\u5ea6\u3002\u8207 MAP-Neo \u76f8\u6bd4\uff0cDCLM-Baseline \u662f\u958b\u653e\u8cc7\u6599\u8a9e\u8a00\u6a21\u578b\u4e2d\u5148\u524d\u7684\u6700\u65b0\u6280\u8853\uff0c\u5728 MMLU \u4e0a\u63d0\u9ad8\u4e86 6.6 \u500b\u767e\u5206\u9ede\uff0c\u540c\u6642\u8a13\u7df4\u6642\u904b\u7b97\u91cf\u6e1b\u5c11\u4e86 40%\u3002\u6211\u5011\u7684\u57fa\u6e96\u6a21\u578b\u4e5f\u8207 MMLU \u4e0a\u7684 Mistral-7B-v0.3 \u548c Llama 3 8B \u76f8\u7576\uff0863% \u548c 66%\uff09\uff0c\u4e26\u4e14\u5728\u5e73\u5747 53 \u500b\u81ea\u7136\u8a9e\u8a00\u7406\u89e3\u4efb\u52d9\u4e0a\u7684\u8868\u73fe\u985e\u4f3c\uff0c\u540c\u6642\u8a13\u7df4\u6642\u904b\u7b97\u91cf\u6bd4 Llama 3 8B \u5c11 6.6 \u500d\u3002\u6211\u5011\u7684\u7d50\u679c\u5f37\u8abf\u4e86\u8cc7\u6599\u96c6\u8a2d\u8a08\u5c0d\u8a13\u7df4\u8a9e\u8a00\u6a21\u578b\u7684\u91cd\u8981\u6027\uff0c\u4e26\u70ba\u8cc7\u6599\u7b56\u5c55\u7684\u9032\u4e00\u6b65\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u500b\u8d77\u9ede\u3002</paragraph>", "author": "Jeffrey Li et.al.", "authors": "Jeffrey Li, Alex Fang, Georgios Smyrnis, Maor Ivgi, Matt Jordan, Samir Gadre, Hritik Bansal, Etash Guha, Sedrick Keh, Kushal Arora, Saurabh Garg, Rui Xin, Niklas Muenninghoff, Reinhard Heckel, Jean Mercat, Mayee Chen, Suchin Gururangan, Mitchell Wortsman, Alon Albalak, Yonatan Bitton, Marianna Nezhurina, Amro Abbas, Cheng-Yu Hsieh, Dhruba Ghosh, Josh Gardner, Maciej Kilian, Hanlin Zhang, Rulin Shao, Sarah Pratt, Sunny Sanyal, Gabriel Ilharco, Giannis Daras, Kalyani Marathe, Aaron Gokaslan, Jieyu Zhang, Khyathi Chandu, Thao Nguyen, Igor Vasiljevic, Sham Kakade, Shuran Song, Sujay Sanghavi, Fartash Faghri, Sewoong Oh, Luke Zettlemoyer, Kyle Lo, Alaaeldin El-Nouby, Hadi Pouransari, Alexander Toshev, Stephanie Wang, Dirk Groeneveld, Luca Soldani, Pang Wei Koh, Jenia Jitsev, Thomas Kollar, Alexandros G. Dimakis, Yair Carmon, Achal Dave, Ludwig Schmidt, Vaishaal Shankar", "id": "2406.11794v1", "paper_url": "http://arxiv.org/abs/2406.11794v1", "repo": "null"}}