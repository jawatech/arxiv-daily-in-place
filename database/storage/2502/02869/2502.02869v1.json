{"2502.02869": {"publish_time": "2025-02-05", "title": "OmniRL: In-Context Reinforcement Learning by Large-Scale Meta-Training in Randomized Worlds", "paper_summary": "We introduce OmniRL, a highly generalizable in-context reinforcement learning\n(ICRL) model that is meta-trained on hundreds of thousands of diverse tasks.\nThese tasks are procedurally generated by randomizing state transitions and\nrewards within Markov Decision Processes. To facilitate this extensive\nmeta-training, we propose two key innovations: 1. An efficient data synthesis\npipeline for ICRL, which leverages the interaction histories of diverse\nbehavior policies; and 2. A novel modeling framework that integrates both\nimitation learning and reinforcement learning (RL) within the context, by\nincorporating prior knowledge. For the first time, we demonstrate that\nin-context learning (ICL) alone, without any gradient-based fine-tuning, can\nsuccessfully tackle unseen Gymnasium tasks through imitation learning, online\nRL, or offline RL. Additionally, we show that achieving generalized ICRL\ncapabilities-unlike task identification-oriented few-shot learning-critically\ndepends on long trajectories generated by variant tasks and diverse behavior\npolicies. By emphasizing the potential of ICL and departing from pre-training\nfocused on acquiring specific skills, we further underscore the significance of\nmeta-training aimed at cultivating the ability of ICL itself.", "paper_summary_zh": "\u6211\u5011\u4ecb\u7d39 OmniRL\uff0c\u9019\u662f\u4e00\u7a2e\u9ad8\u5ea6\u53ef\u6982\u5316\u7684\u60c5\u5883\u5167\u5f37 reinforcement learning\n(ICRL) \u6a21\u578b\uff0c\u4e26\u91dd\u5c0d\u6578\u5341\u842c\u500b\u4e0d\u540c\u7684\u4efb\u52d9\u9032\u884c\u5143\u8a13\u7df4\u3002\n\u9019\u4e9b\u4efb\u52d9\u662f\u900f\u904e\u96a8\u6a5f\u5316\u99ac\u53ef\u592b\u6c7a\u7b56\u7a0b\u5e8f\u4e2d\u7684\u72c0\u614b\u8f49\u63db\u548c\n\u734e\u52f5\u4f86\u7a0b\u5e8f\u5316\u751f\u6210\u7684\u3002\u70ba\u4e86\u4fc3\u9032\u9019\u7a2e\u5ee3\u6cdb\u7684\n\u5143\u8a13\u7df4\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u5169\u500b\u95dc\u9375\u5275\u65b0\uff1a1. \u4e00\u500b\u7528\u65bc ICRL \u7684\u9ad8\u6548\u6578\u64da\u5408\u6210\n\u7ba1\u9053\uff0c\u5b83\u5229\u7528\u4e86\u4e0d\u540c\n\u884c\u70ba\u653f\u7b56\u7684\u4e92\u52d5\u6b77\u53f2\u8a18\u9304\uff1b2. \u4e00\u500b\u65b0\u7a4e\u7684\u5efa\u6a21\u6846\u67b6\uff0c\u5b83\u900f\u904e\n\u7d0d\u5165\u5148\u9a57\u77e5\u8b58\uff0c\u5c07\u6a21\u4eff\u5b78\u7fd2\u548c\u5f37\u5316\u5b78\u7fd2 (RL) \u6574\u5408\u5230\u60c5\u5883\u4e2d\u3002\u6211\u5011\u9996\u6b21\u8b49\u660e\n\u60c5\u5883\u5167\u5b78\u7fd2 (ICL) \u672c\u8eab\uff0c\u5728\u6c92\u6709\u4efb\u4f55\u57fa\u65bc\u68af\u5ea6\u7684\u5fae\u8abf\u60c5\u6cc1\u4e0b\uff0c\u53ef\u4ee5\n\u900f\u904e\u6a21\u4eff\u5b78\u7fd2\u3001\u7dda\u4e0a\nRL \u6216\u96e2\u7dda RL \u6210\u529f\u61c9\u5c0d\u672a\u898b\u904e\u7684 Gymnasium \u4efb\u52d9\u3002\u6b64\u5916\uff0c\u6211\u5011\u8868\u660e\u5be6\u73fe\u5ee3\u7fa9\u7684 ICRL\n\u80fd\u529b\uff08\u8207\u4ee5\u4efb\u52d9\u8b58\u5225\u70ba\u5c0e\u5411\u7684\u5c11\u6b21\u5b78\u7fd2\u4e0d\u540c\uff09\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\n\u53d6\u6c7a\u65bc\u7531\u8b8a\u7570\u4efb\u52d9\u548c\u4e0d\u540c\u884c\u70ba\n\u653f\u7b56\u751f\u6210\u7684\u9577\u8ecc\u8de1\u3002\u900f\u904e\u5f37\u8abf ICL \u7684\u6f5b\u529b\u4e26\u64fa\u812b\u5c08\u6ce8\u65bc\u7372\u53d6\u7279\u5b9a\u6280\u80fd\u7684\u9810\u8a13\u7df4\uff0c\u6211\u5011\u9032\u4e00\u6b65\u5f37\u8abf\u4e86\n\u65e8\u5728\u57f9\u990a ICL \u672c\u8eab\u80fd\u529b\u7684\u5143\u8a13\u7df4\u7684\u91cd\u8981\u6027\u3002", "author": "Fan Wang et.al.", "authors": "Fan Wang, Pengtao Shao, Yiming Zhang, Bo Yu, Shaoshan Liu, Ning Ding, Yang Cao, Yu Kang, Haifeng Wang", "id": "2502.02869v1", "paper_url": "http://arxiv.org/abs/2502.02869v1", "repo": "null"}}