{"2406.17741": {"publish_time": "2024-06-25", "title": "Point-SAM: Promptable 3D Segmentation Model for Point Clouds", "paper_summary": "The development of 2D foundation models for image segmentation has been\nsignificantly advanced by the Segment Anything Model (SAM). However, achieving\nsimilar success in 3D models remains a challenge due to issues such as\nnon-unified data formats, lightweight models, and the scarcity of labeled data\nwith diverse masks. To this end, we propose a 3D promptable segmentation model\n(Point-SAM) focusing on point clouds. Our approach utilizes a transformer-based\nmethod, extending SAM to the 3D domain. We leverage part-level and object-level\nannotations and introduce a data engine to generate pseudo labels from SAM,\nthereby distilling 2D knowledge into our 3D model. Our model outperforms\nstate-of-the-art models on several indoor and outdoor benchmarks and\ndemonstrates a variety of applications, such as 3D annotation. Codes and demo\ncan be found at https://github.com/zyc00/Point-SAM.", "paper_summary_zh": "2D \u5f71\u50cf\u5206\u5272\u57fa\u790e\u6a21\u578b\u7684\u767c\u5c55\u5df2\u56e0 Segment Anything Model (SAM) \u800c\u5927\u5e45\u9032\u5c55\u3002\u7136\u800c\uff0c\u7531\u65bc\u975e\u7d71\u4e00\u8cc7\u6599\u683c\u5f0f\u3001\u8f15\u91cf\u7d1a\u6a21\u578b\uff0c\u4ee5\u53ca\u6a19\u7c64\u8cc7\u6599\u7f3a\u4e4f\u591a\u6a23\u5316\u906e\u7f69\u7b49\u554f\u984c\uff0c\u5728 3D \u6a21\u578b\u4e2d\u53d6\u5f97\u985e\u4f3c\u7684\u6210\u529f\u4ecd\u662f\u4e00\u9805\u6311\u6230\u3002\u70ba\u6b64\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u5c08\u6ce8\u65bc\u9ede\u96f2\u7684 3D \u53ef\u63d0\u793a\u5f0f\u5206\u5272\u6a21\u578b (Point-SAM)\u3002\u6211\u5011\u7684\u65b9\u6cd5\u5229\u7528\u57fa\u65bc Transformer \u7684\u65b9\u6cd5\uff0c\u5c07 SAM \u64f4\u5c55\u5230 3D \u9818\u57df\u3002\u6211\u5011\u5229\u7528\u90e8\u5206\u7d1a\u548c\u7269\u4ef6\u7d1a\u8a3b\u89e3\uff0c\u4e26\u5f15\u5165\u4e00\u500b\u8cc7\u6599\u5f15\u64ce\u5f9e SAM \u7522\u751f\u507d\u6a19\u7c64\uff0c\u5f9e\u800c\u5c07 2D \u77e5\u8b58\u63d0\u7149\u5230\u6211\u5011\u7684 3D \u6a21\u578b\u4e2d\u3002\u6211\u5011\u7684\u6a21\u578b\u5728\u591a\u500b\u5ba4\u5167\u548c\u5ba4\u5916\u57fa\u6e96\u4e0a\u512a\u65bc\u6700\u5148\u9032\u7684\u6a21\u578b\uff0c\u4e26\u5c55\u793a\u4e86\u5404\u7a2e\u61c9\u7528\uff0c\u4f8b\u5982 3D \u8a3b\u89e3\u3002\u7a0b\u5f0f\u78bc\u548c\u793a\u7bc4\u53ef\u4ee5\u5728 https://github.com/zyc00/Point-SAM \u4e2d\u627e\u5230\u3002", "author": "Yuchen Zhou et.al.", "authors": "Yuchen Zhou, Jiayuan Gu, Tung Yen Chiang, Fanbo Xiang, Hao Su", "id": "2406.17741v1", "paper_url": "http://arxiv.org/abs/2406.17741v1", "repo": "https://github.com/zyc00/point-sam"}}