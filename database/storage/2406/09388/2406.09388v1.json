{"2406.09388": {"publish_time": "2024-06-13", "title": "Exploring the Spectrum of Visio-Linguistic Compositionality and Recognition", "paper_summary": "Vision and language models (VLMs) such as CLIP have showcased remarkable\nzero-shot recognition abilities yet face challenges in visio-linguistic\ncompositionality, particularly in linguistic comprehension and fine-grained\nimage-text alignment. This paper explores the intricate relationship between\ncompositionality and recognition -- two pivotal aspects of VLM capability. We\nconduct a comprehensive evaluation of existing VLMs, covering both pre-training\napproaches aimed at recognition and the fine-tuning methods designed to improve\ncompositionality. Our evaluation employs 12 benchmarks for compositionality,\nalong with 21 zero-shot classification and two retrieval benchmarks for\nrecognition. In our analysis from 274 CLIP model checkpoints, we reveal\npatterns and trade-offs that emerge between compositional understanding and\nrecognition accuracy. Ultimately, this necessitates strategic efforts towards\ndeveloping models that improve both capabilities, as well as the meticulous\nformulation of benchmarks for compositionality. We open our evaluation\nframework at https://github.com/ytaek-oh/vl_compo.", "paper_summary_zh": "\u8996\u89ba\u548c\u8a9e\u8a00\u6a21\u578b (VLM)\uff0c\u4f8b\u5982 CLIP\uff0c\u5c55\u793a\u4e86\u975e\u51e1\u7684\u96f6\u6b21\u5b78\u7fd2\u8fa8\u8b58\u80fd\u529b\uff0c\u4f46\u537b\u5728\u8996\u89ba\u8a9e\u8a00\u7684\u7d44\u6210\u6027\u65b9\u9762\u9762\u81e8\u6311\u6230\uff0c\u7279\u5225\u662f\u5728\u8a9e\u8a00\u7406\u89e3\u548c\u7d30\u7dfb\u7684\u5f71\u50cf\u6587\u5b57\u5c0d\u9f4a\u4e0a\u3002\u672c\u6587\u63a2\u8a0e\u4e86\u7d44\u6210\u6027\u548c\u8fa8\u8b58\u4e4b\u9593\u7684\u8907\u96dc\u95dc\u4fc2\uff0c\u9019\u662f VLM \u80fd\u529b\u7684\u5169\u500b\u95dc\u9375\u9762\u5411\u3002\u6211\u5011\u5c0d\u73fe\u6709\u7684 VLM \u9032\u884c\u5168\u9762\u8a55\u4f30\uff0c\u6db5\u84cb\u4e86\u91dd\u5c0d\u8fa8\u8b58\u7684\u9810\u8a13\u7df4\u65b9\u6cd5\u548c\u65e8\u5728\u6539\u5584\u7d44\u6210\u6027\u7684\u5fae\u8abf\u65b9\u6cd5\u3002\u6211\u5011\u7684\u8a55\u4f30\u63a1\u7528\u4e86 12 \u500b\u7d44\u6210\u6027\u57fa\u6e96\uff0c\u4ee5\u53ca 21 \u500b\u96f6\u6b21\u5b78\u7fd2\u5206\u985e\u548c\u5169\u500b\u7528\u65bc\u8fa8\u8b58\u7684\u6aa2\u7d22\u57fa\u6e96\u3002\u5728\u6211\u5011\u5c0d 274 \u500b CLIP \u6a21\u578b\u6aa2\u67e5\u9ede\u7684\u5206\u6790\u4e2d\uff0c\u6211\u5011\u63ed\u793a\u4e86\u7d44\u6210\u7406\u89e3\u548c\u8fa8\u8b58\u6e96\u78ba\u5ea6\u4e4b\u9593\u51fa\u73fe\u7684\u6a21\u5f0f\u548c\u6b0a\u8861\u3002\u6700\u7d42\uff0c\u9019\u9700\u8981\u7b56\u7565\u6027\u5730\u52aa\u529b\u958b\u767c\u80fd\u6539\u5584\u9019\u5169\u7a2e\u80fd\u529b\u7684\u6a21\u578b\uff0c\u4ee5\u53ca\u4ed4\u7d30\u5236\u5b9a\u7d44\u6210\u6027\u7684\u57fa\u6e96\u3002\u6211\u5011\u5728 https://github.com/ytaek-oh/vl_compo \u958b\u653e\u6211\u5011\u7684\u8a55\u4f30\u67b6\u69cb\u3002", "author": "Youngtaek Oh et.al.", "authors": "Youngtaek Oh, Pyunghwan Ahn, Jinhyung Kim, Gwangmo Song, Soonyoung Lee, In So Kweon, Junmo Kim", "id": "2406.09388v1", "paper_url": "http://arxiv.org/abs/2406.09388v1", "repo": "https://github.com/ytaek-oh/vl_compo"}}