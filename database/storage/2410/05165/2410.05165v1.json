{"2410.05165": {"publish_time": "2024-10-07", "title": "Efficient Inference for Large Language Model-based Generative Recommendation", "paper_summary": "Large Language Model (LLM)-based generative recommendation has achieved\nnotable success, yet its practical deployment is costly particularly due to\nexcessive inference latency caused by autoregressive decoding. For lossless LLM\ndecoding acceleration, Speculative Decoding (SD) has emerged as a promising\nsolution. However, applying SD to generative recommendation presents unique\nchallenges due to the requirement of generating top-K items (i.e., K distinct\ntoken sequences) as a recommendation list by beam search. This leads to more\nstringent verification in SD, where all the top-K sequences from the target LLM\nmust be successfully drafted by the draft model at each decoding step. To\nalleviate this, we consider 1) boosting top-K sequence alignment between the\ndraft model and the target LLM, and 2) relaxing the verification strategy to\nreduce trivial LLM calls. To this end, we propose an alignment framework named\nAtSpeed, which presents the AtSpeed-S optimization objective for top-K\nalignment under the strict top-K verification. Moreover, we introduce a relaxed\nsampling verification strategy that allows high-probability non-top-K drafted\nsequences to be accepted, significantly reducing LLM calls. Correspondingly, we\npropose AtSpeed-R for top-K alignment under this relaxed sampling verification.\nEmpirical results on two real-world datasets demonstrate that AtSpeed\nsignificantly accelerates LLM-based generative recommendation, e.g., near 2x\nspeedup under strict top-K verification and up to 2.5 speedup under relaxed\nsampling verification. The codes and datasets will be released in the near\nfuture.", "paper_summary_zh": "<paragraph>\u57fa\u65bc\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u751f\u6210\u5f0f\u63a8\u85a6\u5df2\u53d6\u5f97\u986f\u8457\u6210\u529f\uff0c\u4f46\u5176\u5be6\u969b\u90e8\u7f72\u6210\u672c\u9ad8\u6602\uff0c\u7279\u5225\u662f\u56e0\u70ba\u81ea\u8ff4\u6b78\u89e3\u78bc\u5c0e\u81f4\u904e\u5ea6\u7684\u63a8\u8ad6\u5ef6\u9072\u3002\u5c0d\u65bc\u7121\u640d\u5931\u7684 LLM \u89e3\u78bc\u52a0\u901f\uff0c\u63a8\u6e2c\u6027\u89e3\u78bc (SD) \u5df2\u6210\u70ba\u4e00\u7a2e\u6709\u524d\u9014\u7684\u89e3\u6c7a\u65b9\u6848\u3002\u7136\u800c\uff0c\u7531\u65bc\u9700\u8981\u900f\u904e\u6ce2\u675f\u641c\u5c0b\u7522\u751f\u9802\u7d1a K \u9805\u76ee\uff08\u5373 K \u500b\u4e0d\u540c\u7684\u4ee3\u5e63\u5e8f\u5217\uff09\u4f5c\u70ba\u63a8\u85a6\u6e05\u55ae\uff0c\u5c07 SD \u61c9\u7528\u65bc\u751f\u6210\u5f0f\u63a8\u85a6\u6703\u7522\u751f\u7368\u7279\u7684\u6311\u6230\u3002\u9019\u5c0e\u81f4\u5728 SD \u4e2d\u9032\u884c\u66f4\u56b4\u683c\u7684\u9a57\u8b49\uff0c\u5176\u4e2d\u76ee\u6a19 LLM \u7684\u6240\u6709\u9802\u7d1a K \u5e8f\u5217\u90fd\u5fc5\u9808\u5728\u6bcf\u500b\u89e3\u78bc\u6b65\u9a5f\u7531\u8349\u7a3f\u6a21\u578b\u6210\u529f\u8d77\u8349\u3002\u70ba\u4e86\u7de9\u89e3\u9019\u4e00\u9ede\uff0c\u6211\u5011\u8003\u616e 1) \u63d0\u5347\u8349\u7a3f\u6a21\u578b\u548c\u76ee\u6a19 LLM \u4e4b\u9593\u7684\u9802\u7d1a K \u5e8f\u5217\u5c0d\u9f4a\uff0c\u4ee5\u53ca 2) \u653e\u5bec\u9a57\u8b49\u7b56\u7565\u4ee5\u6e1b\u5c11\u7121\u95dc\u7dca\u8981\u7684 LLM \u547c\u53eb\u3002\u70ba\u6b64\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u540d\u70ba AtSpeed \u7684\u5c0d\u9f4a\u67b6\u69cb\uff0c\u5b83\u63d0\u51fa\u4e86\u5728\u56b4\u683c\u7684\u9802\u7d1a K \u9a57\u8b49\u4e0b\u7528\u65bc\u9802\u7d1a K \u5c0d\u9f4a\u7684 AtSpeed-S \u6700\u4f73\u5316\u76ee\u6a19\u3002\u6b64\u5916\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e00\u7a2e\u653e\u5bec\u7684\u62bd\u6a23\u9a57\u8b49\u7b56\u7565\uff0c\u5141\u8a31\u63a5\u53d7\u9ad8\u6a5f\u7387\u975e\u9802\u7d1a K \u8d77\u8349\u5e8f\u5217\uff0c\u5927\u5e45\u6e1b\u5c11 LLM \u547c\u53eb\u3002\u76f8\u61c9\u5730\uff0c\u6211\u5011\u63d0\u51fa AtSpeed-R \u7528\u65bc\u5728\u9019\u7a2e\u653e\u5bec\u7684\u62bd\u6a23\u9a57\u8b49\u4e0b\u9032\u884c\u9802\u7d1a K \u5c0d\u9f4a\u3002\u5728\u5169\u500b\u771f\u5be6\u4e16\u754c\u8cc7\u6599\u96c6\u4e0a\u7684\u5be6\u8b49\u7d50\u679c\u8868\u660e\uff0cAtSpeed \u5927\u5e45\u52a0\u901f\u4e86\u57fa\u65bc LLM \u7684\u751f\u6210\u5f0f\u63a8\u85a6\uff0c\u4f8b\u5982\uff0c\u5728\u56b4\u683c\u7684\u9802\u7d1a K \u9a57\u8b49\u4e0b\u52a0\u901f\u8fd1 2 \u500d\uff0c\u5728\u653e\u5bec\u7684\u62bd\u6a23\u9a57\u8b49\u4e0b\u52a0\u901f\u9ad8\u9054 2.5 \u500d\u3002\u9019\u4e9b\u7a0b\u5f0f\u78bc\u548c\u8cc7\u6599\u96c6\u5c07\u5728\u4e0d\u4e45\u7684\u5c07\u4f86\u767c\u5e03\u3002</paragraph>", "author": "Xinyu Lin et.al.", "authors": "Xinyu Lin, Chaoqun Yang, Wenjie Wang, Yongqi Li, Cunxiao Du, Fuli Feng, See-Kiong Ng, Tat-Seng Chua", "id": "2410.05165v1", "paper_url": "http://arxiv.org/abs/2410.05165v1", "repo": "null"}}