{"2405.21018": {"publish_time": "2024-05-31", "title": "Improved Techniques for Optimization-Based Jailbreaking on Large Language Models", "paper_summary": "Large language models (LLMs) are being rapidly developed, and a key component\nof their widespread deployment is their safety-related alignment. Many\nred-teaming efforts aim to jailbreak LLMs, where among these efforts, the\nGreedy Coordinate Gradient (GCG) attack's success has led to a growing interest\nin the study of optimization-based jailbreaking techniques. Although GCG is a\nsignificant milestone, its attacking efficiency remains unsatisfactory. In this\npaper, we present several improved (empirical) techniques for\noptimization-based jailbreaks like GCG. We first observe that the single target\ntemplate of \"Sure\" largely limits the attacking performance of GCG; given this,\nwe propose to apply diverse target templates containing harmful self-suggestion\nand/or guidance to mislead LLMs. Besides, from the optimization aspects, we\npropose an automatic multi-coordinate updating strategy in GCG (i.e.,\nadaptively deciding how many tokens to replace in each step) to accelerate\nconvergence, as well as tricks like easy-to-hard initialisation. Then, we\ncombine these improved technologies to develop an efficient jailbreak method,\ndubbed $\\mathcal{I}$-GCG. In our experiments, we evaluate on a series of\nbenchmarks (such as NeurIPS 2023 Red Teaming Track). The results demonstrate\nthat our improved techniques can help GCG outperform state-of-the-art\njailbreaking attacks and achieve nearly 100% attack success rate. The code is\nreleased at https://github.com/jiaxiaojunQAQ/I-GCG.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6b63\u5728\u5feb\u901f\u767c\u5c55\uff0c\u800c\u5176\u5ee3\u6cdb\u90e8\u7f72\u7684\u4e00\u500b\u95dc\u9375\u7d44\u6210\u90e8\u5206\u662f\u5176\u8207\u5b89\u5168\u76f8\u95dc\u7684\u4e00\u81f4\u6027\u3002\u8a31\u591a\u7d05\u968a\u884c\u52d5\u65e8\u5728\u7834\u89e3 LLM\uff0c\u5728\u9019\u4e9b\u884c\u52d5\u4e2d\uff0c\u8caa\u5a6a\u5750\u6a19\u68af\u5ea6 (GCG) \u653b\u64ca\u7684\u6210\u529f\u5f15\u8d77\u4e86\u4eba\u5011\u5c0d\u57fa\u65bc\u6700\u4f73\u5316\u7684\u7834\u89e3\u6280\u8853\u7814\u7a76\u7684\u8208\u8da3\u65e5\u76ca\u6fc3\u539a\u3002\u5118\u7ba1 GCG \u662f\u500b\u91cd\u8981\u7684\u91cc\u7a0b\u7891\uff0c\u4f46\u5176\u653b\u64ca\u6548\u7387\u4ecd\u7136\u4ee4\u4eba\u4e0d\u6eff\u610f\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u5e7e\u7a2e\u6539\u9032\u7684\uff08\u7d93\u9a57\uff09\u6280\u8853\uff0c\u7528\u65bc\u57fa\u65bc\u6700\u4f73\u5316\u7684\u7834\u89e3\uff0c\u4f8b\u5982 GCG\u3002\u6211\u5011\u9996\u5148\u89c0\u5bdf\u5230\u300c\u78ba\u5b9a\u300d\u7684\u55ae\u4e00\u76ee\u6a19\u7bc4\u672c\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u9650\u5236\u4e86 GCG \u7684\u653b\u64ca\u6548\u80fd\uff1b\u6709\u9451\u65bc\u6b64\uff0c\u6211\u5011\u5efa\u8b70\u61c9\u7528\u5305\u542b\u6709\u5bb3\u81ea\u6211\u6697\u793a\u548c/\u6216\u6307\u5c0e\u7684\u5404\u7a2e\u76ee\u6a19\u7bc4\u672c\u4f86\u8aa4\u5c0e LLM\u3002\u6b64\u5916\uff0c\u5f9e\u6700\u4f73\u5316\u7684\u89d2\u5ea6\u4f86\u770b\uff0c\u6211\u5011\u5728 GCG \u4e2d\u63d0\u51fa\u4e86\u4e00\u7a2e\u81ea\u52d5\u591a\u5750\u6a19\u66f4\u65b0\u7b56\u7565\uff08\u5373\u81ea\u9069\u61c9\u5730\u6c7a\u5b9a\u5728\u6bcf\u4e00\u6b65\u4e2d\u66ff\u63db\u591a\u5c11\u500b\u4ee3\u5e63\uff09\u4ee5\u52a0\u901f\u6536\u6582\uff0c\u4ee5\u53ca\u8af8\u5982\u6613\u65bc\u56f0\u96e3\u521d\u59cb\u5316\u7684\u6280\u5de7\u3002\u7136\u5f8c\uff0c\u6211\u5011\u5c07\u9019\u4e9b\u6539\u9032\u7684\u6280\u8853\u7d50\u5408\u8d77\u4f86\uff0c\u958b\u767c\u51fa\u4e00\u7a2e\u9ad8\u6548\u7684\u7834\u89e3\u65b9\u6cd5\uff0c\u7a31\u70ba $\\mathcal{I}$-GCG\u3002\u5728\u6211\u5011\u7684\u5be6\u9a57\u4e2d\uff0c\u6211\u5011\u5728\u4e00\u7cfb\u5217\u57fa\u6e96\u4e0a\u9032\u884c\u8a55\u4f30\uff08\u4f8b\u5982 NeurIPS 2023 \u7d05\u968a\u8ffd\u8e64\uff09\u3002\u7d50\u679c\u8868\u660e\uff0c\u6211\u5011\u6539\u9032\u7684\u6280\u8853\u53ef\u4ee5\u5e6b\u52a9 GCG \u512a\u65bc\u6700\u5148\u9032\u7684\u7834\u89e3\u653b\u64ca\uff0c\u4e26\u5be6\u73fe\u63a5\u8fd1 100% \u7684\u653b\u64ca\u6210\u529f\u7387\u3002\u4ee3\u78bc\u5df2\u767c\u5e03\u5728 https://github.com/jiaxiaojunQAQ/I-GCG\u3002", "author": "Xiaojun Jia et.al.", "authors": "Xiaojun Jia, Tianyu Pang, Chao Du, Yihao Huang, Jindong Gu, Yang Liu, Xiaochun Cao, Min Lin", "id": "2405.21018v1", "paper_url": "http://arxiv.org/abs/2405.21018v1", "repo": "https://github.com/jiaxiaojunqaq/i-gcg"}}