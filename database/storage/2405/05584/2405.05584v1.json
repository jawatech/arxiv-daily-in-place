{"2405.05584": {"publish_time": "2024-05-09", "title": "A Survey on Backbones for Deep Video Action Recognition", "paper_summary": "Action recognition is a key technology in building interactive metaverses.\nWith the rapid development of deep learning, methods in action recognition have\nalso achieved great advancement. Researchers design and implement the backbones\nreferring to multiple standpoints, which leads to the diversity of methods and\nencountering new challenges. This paper reviews several action recognition\nmethods based on deep neural networks. We introduce these methods in three\nparts: 1) Two-Streams networks and their variants, which, specifically in this\npaper, use RGB video frame and optical flow modality as input; 2) 3D\nconvolutional networks, which make efforts in taking advantage of RGB modality\ndirectly while extracting different motion information is no longer necessary;\n3) Transformer-based methods, which introduce the model from natural language\nprocessing into computer vision and video understanding. We offer objective\nsights in this review and hopefully provide a reference for future research.", "paper_summary_zh": "\u52d5\u4f5c\u8fa8\u8b58\u662f\u5efa\u7acb\u4e92\u52d5\u5f0f\u5143\u5b87\u5b99\u7684\u95dc\u9375\u6280\u8853\u3002\n\u96a8\u8457\u6df1\u5ea6\u5b78\u7fd2\u7684\u5feb\u901f\u767c\u5c55\uff0c\u52d5\u4f5c\u8fa8\u8b58\u65b9\u6cd5\u4e5f\u53d6\u5f97\u4e86\u5f88\u5927\u7684\u9032\u5c55\u3002\u7814\u7a76\u4eba\u54e1\u6839\u64da\u591a\u500b\u89c0\u9ede\u8a2d\u8a08\u548c\u5be6\u4f5c\u9aa8\u5e79\uff0c\u9019\u5c0e\u81f4\u65b9\u6cd5\u7684\u591a\u6a23\u6027\u4e26\u9047\u5230\u65b0\u7684\u6311\u6230\u3002\u672c\u6587\u56de\u9867\u4e86\u57fa\u65bc\u6df1\u5ea6\u795e\u7d93\u7db2\u8def\u7684\u5e7e\u7a2e\u52d5\u4f5c\u8fa8\u8b58\u65b9\u6cd5\u3002\u6211\u5011\u5206\u70ba\u4e09\u90e8\u5206\u4ecb\u7d39\u9019\u4e9b\u65b9\u6cd5\uff1a1) \u96d9\u6d41\u7db2\u8def\u53ca\u5176\u8b8a\u9ad4\uff0c\u7279\u5225\u662f\u5728\u672c\u6587\u4e2d\uff0c\u4f7f\u7528 RGB \u5f71\u7247\u5e40\u548c\u5149\u6d41\u6a21\u5f0f\u4f5c\u70ba\u8f38\u5165\uff1b2) 3D \u5377\u7a4d\u7db2\u8def\uff0c\u52aa\u529b\u76f4\u63a5\u5229\u7528 RGB \u6a21\u5f0f\uff0c\u540c\u6642\u4e0d\u518d\u9700\u8981\u63d0\u53d6\u4e0d\u540c\u7684\u52d5\u4f5c\u8cc7\u8a0a\uff1b3) \u57fa\u65bc Transformer \u7684\u65b9\u6cd5\uff0c\u5c07\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u4e2d\u7684\u6a21\u578b\u5f15\u5165\u96fb\u8166\u8996\u89ba\u548c\u5f71\u7247\u7406\u89e3\u3002\u6211\u5011\u5728\u6b64\u56de\u9867\u4e2d\u63d0\u4f9b\u5ba2\u89c0\u7684\u898b\u89e3\uff0c\u4e26\u5e0c\u671b\u70ba\u672a\u4f86\u7684\u7814\u7a76\u63d0\u4f9b\u53c3\u8003\u3002", "author": "Zixuan Tang et.al.", "authors": "Zixuan Tang, Youjun Zhao, Yuhang Wen, Mengyuan Liu", "id": "2405.05584v1", "paper_url": "http://arxiv.org/abs/2405.05584v1", "repo": "null"}}