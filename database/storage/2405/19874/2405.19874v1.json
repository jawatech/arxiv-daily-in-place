{"2405.19874": {"publish_time": "2024-05-30", "title": "Is In-Context Learning Sufficient for Instruction Following in LLMs?", "paper_summary": "In-context learning (ICL) allows LLMs to learn from examples without changing\ntheir weights, which is a particularly promising capability for long-context\nLLMs that can potentially learn from many examples. Recently, Lin et al. (2024)\nproposed URIAL, a method using only three in-context examples to align base\nLLMs, achieving non-trivial instruction following performance. In this work, we\nshow that, while effective, ICL alignment with URIAL still underperforms\ncompared to instruction fine-tuning on established benchmarks such as MT-Bench\nand AlpacaEval 2.0 (LC), especially with more capable base LMs. Unlike for\ntasks such as classification, translation, or summarization, adding more ICL\ndemonstrations for long-context LLMs does not systematically improve\ninstruction following performance. To address this limitation, we derive a\ngreedy selection approach for ICL examples that noticeably improves\nperformance, yet without bridging the gap to instruction fine-tuning. Finally,\nwe provide a series of ablation studies to better understand the reasons behind\nthe remaining gap, and we show how some aspects of ICL depart from the existing\nknowledge and are specific to the instruction tuning setting. Overall, our work\nadvances the understanding of ICL as an alignment technique. We provide our\ncode at https://github.com/tml-epfl/icl-alignment.", "paper_summary_zh": "<paragraph>\u60c5\u5883\u5f0f\u5b78\u7fd2 (ICL) \u8b93\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u80fd\u5920\u5f9e\u7bc4\u4f8b\u4e2d\u5b78\u7fd2\uff0c\u800c\u7121\u9700\u6539\u8b8a\u5176\u6b0a\u91cd\uff0c\u9019\u5c0d\u65bc\u6f5b\u5728\u80fd\u5f9e\u8a31\u591a\u7bc4\u4f8b\u4e2d\u5b78\u7fd2\u7684\u9577\u60c5\u5883 LLM \u800c\u8a00\uff0c\u662f\u4e00\u7a2e\u7279\u5225\u6709\u524d\u9014\u7684\u80fd\u529b\u3002\u6700\u8fd1\uff0cLin \u7b49\u4eba (2024) \u63d0\u51fa URIAL\uff0c\u4e00\u7a2e\u50c5\u4f7f\u7528\u4e09\u500b\u60c5\u5883\u5f0f\u7bc4\u4f8b\u4f86\u6bd4\u5c0d\u57fa\u790e LLM \u7684\u65b9\u6cd5\uff0c\u5be6\u73fe\u4e86\u975e\u5e73\u51e1\u7684\u6307\u4ee4\u9075\u5faa\u6548\u80fd\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u8b49\u660e\uff0c\u5118\u7ba1\u6709\u6548\uff0c\u4f46\u8207\u5728\u65e2\u5b9a\u7684\u57fa\u6e96\uff08\u4f8b\u5982 MT-Bench \u548c AlpacaEval 2.0 (LC)\uff09\u4e0a\u9032\u884c\u6307\u4ee4\u5fae\u8abf\u76f8\u6bd4\uff0cICL \u6bd4\u5c0d\u8207 URIAL \u4ecd\u7136\u8868\u73fe\u4e0d\u4f73\uff0c\u7279\u5225\u662f\u5c0d\u65bc\u529f\u80fd\u66f4\u5f37\u5927\u7684\u57fa\u790e LLM\u3002\u8207\u5206\u985e\u3001\u7ffb\u8b6f\u6216\u6458\u8981\u7b49\u4efb\u52d9\u4e0d\u540c\uff0c\u70ba\u9577\u60c5\u5883 LLM \u52a0\u5165\u66f4\u591a ICL \u793a\u7bc4\u4e26\u4e0d\u6703\u7cfb\u7d71\u6027\u5730\u6539\u5584\u6307\u4ee4\u9075\u5faa\u6548\u80fd\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u9650\u5236\uff0c\u6211\u5011\u63a8\u5c0e\u51fa\u4e00\u500b\u91dd\u5c0d ICL \u7bc4\u4f8b\u7684\u8caa\u5a6a\u9078\u64c7\u65b9\u6cd5\uff0c\u986f\u8457\u6539\u5584\u4e86\u6548\u80fd\uff0c\u4f46\u4e26\u672a\u5f4c\u5408\u8207\u6307\u4ee4\u5fae\u8abf\u4e4b\u9593\u7684\u5dee\u8ddd\u3002\u6700\u5f8c\uff0c\u6211\u5011\u63d0\u4f9b\u4e86\u4e00\u7cfb\u5217\u6d88\u878d\u7814\u7a76\uff0c\u4ee5\u66f4\u597d\u5730\u4e86\u89e3\u9020\u6210\u5269\u9918\u5dee\u8ddd\u7684\u539f\u56e0\uff0c\u4e26\u5c55\u793a ICL \u7684\u67d0\u4e9b\u65b9\u9762\u5982\u4f55\u504f\u96e2\u73fe\u6709\u77e5\u8b58\uff0c\u4e26\u4e14\u7279\u5b9a\u65bc\u6307\u4ee4\u8abf\u6574\u8a2d\u5b9a\u3002\u7e3d\u9ad4\u800c\u8a00\uff0c\u6211\u5011\u7684\u7814\u7a76\u4fc3\u9032\u4e86\u5c0d ICL \u4f5c\u70ba\u6bd4\u5c0d\u6280\u8853\u7684\u7406\u89e3\u3002\u6211\u5011\u5728 https://github.com/tml-epfl/icl-alignment \u63d0\u4f9b\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u3002</paragraph>", "author": "Hao Zhao et.al.", "authors": "Hao Zhao, Maksym Andriushchenko, Francesco Croce, Nicolas Flammarion", "id": "2405.19874v1", "paper_url": "http://arxiv.org/abs/2405.19874v1", "repo": "null"}}