
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-11**|**"My Grade is Wrong!": A Contestable AI Framework for Interactive Feedback in Evaluating Student Essays**|Shengxin Hong et.al.|[2409.07453v1](http://arxiv.org/abs/2409.07453v1)|null|
|**2024-09-11**|**SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories**|Ben Bogin et.al.|[2409.07440v1](http://arxiv.org/abs/2409.07440v1)|[link](https://github.com/allenai/super-benchmark)|
|**2024-09-11**|**A Suite for Acoustic Language Model Evaluation**|Gallil Maimon et.al.|[2409.07437v1](http://arxiv.org/abs/2409.07437v1)|null|
|**2024-09-11**|**Synthetic continued pretraining**|Zitong Yang et.al.|[2409.07431v1](http://arxiv.org/abs/2409.07431v1)|[link](https://github.com/zitongyang/synthetic_continued_pretraining)|
|**2024-09-11**|**Agent Workflow Memory**|Zora Zhiruo Wang et.al.|[2409.07429v1](http://arxiv.org/abs/2409.07429v1)|[link](https://github.com/zorazrw/agent-workflow-memory)|
|**2024-09-11**|**Towards Fairer Health Recommendations: finding informative unbiased samples via Word Sense Disambiguation**|Gavin Butts et.al.|[2409.07424v1](http://arxiv.org/abs/2409.07424v1)|null|
|**2024-09-11**|**Enhancing adversarial robustness in Natural Language Inference using explanations**|Alexandros Koulakos et.al.|[2409.07423v1](http://arxiv.org/abs/2409.07423v1)|null|
|**2024-09-11**|**Hierarchical Reinforcement Learning for Temporal Abstraction of Listwise Recommendation**|Luo Ji et.al.|[2409.07416v1](http://arxiv.org/abs/2409.07416v1)|null|
|**2024-09-11**|**SoK: Security and Privacy Risks of Medical AI**|Yuanhaur Chang et.al.|[2409.07415v1](http://arxiv.org/abs/2409.07415v1)|null|
|**2024-09-11**|**CLNX: Bridging Code and Natural Language for C/C++ Vulnerability-Contributing Commits Identification**|Zeqing Qin et.al.|[2409.07407v1](http://arxiv.org/abs/2409.07407v1)|null|
|**2024-09-11**|**AdaCAD: Adaptively Decoding to Balance Conflicts between Contextual and Parametric Knowledge**|Han Wang et.al.|[2409.07394v1](http://arxiv.org/abs/2409.07394v1)|[link](https://github.com/hannight/adacad)|
|**2024-09-11**|**Awaking the Slides: A Tuning-free and Knowledge-regulated AI Tutoring System via Language Model Coordination**|Daniel Zhang-Li et.al.|[2409.07372v1](http://arxiv.org/abs/2409.07372v1)|null|
|**2024-09-11**|**Demo: SGCode: A Flexible Prompt-Optimizing System for Secure Generation of Code**|Khiem Ton et.al.|[2409.07368v1](http://arxiv.org/abs/2409.07368v1)|null|
|**2024-09-11**|**Think Together and Work Better: Combining Humans' and LLMs' Think-Aloud Outcomes for Effective Text Evaluation**|SeongYeub Chu et.al.|[2409.07355v1](http://arxiv.org/abs/2409.07355v1)|[link](https://github.com/BBeeChu/InteractEval)|
|**2024-09-11**|**Securing Vision-Language Models with a Robust Encoder Against Jailbreak and Adversarial Attacks**|Md Zarif Hossain et.al.|[2409.07353v1](http://arxiv.org/abs/2409.07353v1)|[link](https://github.com/speedlab-git/robust-encoder-against-jailbreak-attack)|
|**2024-09-11**|**Federated Impression for Learning with Distributed Heterogeneous Data**|Sana Ayromlou et.al.|[2409.07351v1](http://arxiv.org/abs/2409.07351v1)|null|
|**2024-09-11**|**Online Decision MetaMorphFormer: A Casual Transformer-Based Reinforcement Learning Framework of Universal Embodied Intelligence**|Luo Ji et.al.|[2409.07341v1](http://arxiv.org/abs/2409.07341v1)|null|
|**2024-09-11**|**Explanation, Debate, Align: A Weak-to-Strong Framework for Language Model Generalization**|Mehrdad Zakershahrak et.al.|[2409.07335v1](http://arxiv.org/abs/2409.07335v1)|null|
|**2024-09-11**|**Module-wise Adaptive Adversarial Training for End-to-end Autonomous Driving**|Tianyuan Zhang et.al.|[2409.07321v1](http://arxiv.org/abs/2409.07321v1)|null|
|**2024-09-11**|**MEDIC: Towards a Comprehensive Framework for Evaluating LLMs in Clinical Applications**|Praveen K Kanithi et.al.|[2409.07314v1](http://arxiv.org/abs/2409.07314v1)|null|
|**2024-09-11**|**Exploring User-level Gradient Inversion with a Diffusion Prior**|Zhuohang Li et.al.|[2409.07291v1](http://arxiv.org/abs/2409.07291v1)|null|
|**2024-09-11**|**Using Generative Agents to Create Tip Sheets for Investigative Data Reporting**|Joris Veerbeek et.al.|[2409.07286v1](http://arxiv.org/abs/2409.07286v1)|null|
|**2024-09-11**|**Cross-Dialect Text-To-Speech in Pitch-Accent Language Incorporating Multi-Dialect Phoneme-Level BERT**|Kazuki Yamauchi et.al.|[2409.07265v1](http://arxiv.org/abs/2409.07265v1)|null|
|**2024-09-11**|**Propaganda to Hate: A Multimodal Analysis of Arabic Memes with Multi-Agent LLMs**|Firoj Alam et.al.|[2409.07246v1](http://arxiv.org/abs/2409.07246v1)|null|
|**2024-09-11**|**Behavioral Cloning Models Reality Check for Autonomous Driving**|Mustafa Yildirim et.al.|[2409.07218v1](http://arxiv.org/abs/2409.07218v1)|null|
|**2024-09-11**|**Heterogeneity-Aware Coordination for Federated Learning via Stitching Pre-trained blocks**|Shichen Zhan et.al.|[2409.07202v1](http://arxiv.org/abs/2409.07202v1)|null|
|**2024-09-11**|**ThermalGaussian: Thermal 3D Gaussian Splatting**|Rongfeng Lu et.al.|[2409.07200v1](http://arxiv.org/abs/2409.07200v1)|null|
|**2024-09-11**|**A Perspective on AI-Guided Molecular Simulations in VR: Exploring Strategies for Imitation Learning in Hyperdimensional Molecular Systems**|Mohamed Dhouioui et.al.|[2409.07189v1](http://arxiv.org/abs/2409.07189v1)|null|
|**2024-09-11**|**Enhancing Angular Resolution via Directionality Encoding and Geometric Constraints in Brain Diffusion Tensor Imaging**|Sheng Chen et.al.|[2409.07186v1](http://arxiv.org/abs/2409.07186v1)|null|
|**2024-09-11**|**Linear Time Complexity Conformers with SummaryMixing for Streaming Speech Recognition**|Titouan Parcollet et.al.|[2409.07165v1](http://arxiv.org/abs/2409.07165v1)|null|
|**2024-09-11**|**A Fine-grained Sentiment Analysis of App Reviews using Large Language Models: An Evaluation Study**|Faiz Ali Shah et.al.|[2409.07162v1](http://arxiv.org/abs/2409.07162v1)|[link](https://github.com/faiz-ut/eval-feature-sentiment-extraction-llms)|
|**2024-09-11**|**Recurrent Aggregators in Neural Algorithmic Reasoning**|Kaijia Xu et.al.|[2409.07154v1](http://arxiv.org/abs/2409.07154v1)|null|
|**2024-09-11**|**Zero-Shot Text-to-Speech as Golden Speech Generator: A Systematic Framework and its Applicability in Automatic Pronunciation Assessment**|Tien-Hong Lo et.al.|[2409.07151v1](http://arxiv.org/abs/2409.07151v1)|null|
|**2024-09-11**|**Gated Slot Attention for Efficient Linear-Time Sequence Modeling**|Yu Zhang et.al.|[2409.07146v1](http://arxiv.org/abs/2409.07146v1)|null|
|**2024-09-11**|**Leveraging Unstructured Text Data for Federated Instruction Tuning of Large Language Models**|Rui Ye et.al.|[2409.07136v1](http://arxiv.org/abs/2409.07136v1)|null|
|**2024-09-11**|**LLM-based feature generation from text for interpretable machine learning**|Vojtěch Balek et.al.|[2409.07132v1](http://arxiv.org/abs/2409.07132v1)|null|
|**2024-09-11**|**Reranking Laws for Language Generation: A Communication-Theoretic Perspective**|António Farinhas et.al.|[2409.07131v1](http://arxiv.org/abs/2409.07131v1)|null|
|**2024-09-11**|**Deep Learning Techniques for Hand Vein Biometrics: A Comprehensive Review**|Mustapha Hemis et.al.|[2409.07128v1](http://arxiv.org/abs/2409.07128v1)|null|
|**2024-09-11**|**DCMAC: Demand-aware Customized Multi-Agent Communication via Upper Bound Training**|Dongkun Huo et.al.|[2409.07127v1](http://arxiv.org/abs/2409.07127v1)|null|
|**2024-09-11**|**Cross-Refine: Improving Natural Language Explanation Generation by Learning in Tandem**|Qianli Wang et.al.|[2409.07123v1](http://arxiv.org/abs/2409.07123v1)|null|
|**2024-09-11**|**Attention Down-Sampling Transformer, Relative Ranking and Self-Consistency for Blind Image Quality Assessment**|Mohammed Alsaafin et.al.|[2409.07115v1](http://arxiv.org/abs/2409.07115v1)|[link](https://github.com/mas94/adtrs)|
|**2024-09-11**|**A Continual and Incremental Learning Approach for TinyML On-device Training Using Dataset Distillation and Model Size Adaption**|Marcus Rüb et.al.|[2409.07114v1](http://arxiv.org/abs/2409.07114v1)|null|
|**2024-09-11**|**Redundancy-Aware Camera Selection for Indoor Scene Neural Rendering**|Zehao Wang et.al.|[2409.07098v1](http://arxiv.org/abs/2409.07098v1)|null|
|**2024-09-11**|**CWT-Net: Super-resolution of Histopathology Images Using a Cross-scale Wavelet-based Transformer**|Feiyang Jia et.al.|[2409.07092v1](http://arxiv.org/abs/2409.07092v1)|null|
|**2024-09-11**|**Ontology-Free General-Domain Knowledge Graph-to-Text Generation Dataset Synthesis using Large Language Model**|Daehee Kim et.al.|[2409.07088v1](http://arxiv.org/abs/2409.07088v1)|[link](https://github.com/daehuikim/WikiOFGraph)|
|**2024-09-11**|**Understanding Knowledge Drift in LLMs through Misinformation**|Alina Fastowski et.al.|[2409.07085v1](http://arxiv.org/abs/2409.07085v1)|[link](https://github.com/afastowski/knowledge_drift)|
|**2024-09-11**|**Multimodal Emotion Recognition with Vision-language Prompting and Modality Dropout**|Anbin QI et.al.|[2409.07078v1](http://arxiv.org/abs/2409.07078v1)|null|
|**2024-09-11**|**Latent Space Interpretation for Stylistic Analysis and Explainable Authorship Attribution**|Milad Alshomary et.al.|[2409.07072v1](http://arxiv.org/abs/2409.07072v1)|null|
|**2024-09-11**|**Automated Speaking Assessment of Conversation Tests with Novel Graph-based Modeling on Spoken Response Coherence**|Jiun-Ting Li et.al.|[2409.07064v1](http://arxiv.org/abs/2409.07064v1)|null|
|**2024-09-11**|**Native vs Non-Native Language Prompting: A Comparative Analysis**|Mohamed Bayan Kmainasi et.al.|[2409.07054v1](http://arxiv.org/abs/2409.07054v1)|null|
|**2024-09-11**|**Beyond IID: Optimizing Instruction Learning from the Perspective of Instruction Interaction and Dependency**|Hanyu Zhao et.al.|[2409.07045v1](http://arxiv.org/abs/2409.07045v1)|null|
|**2024-09-11**|**Improving Anomalous Sound Detection via Low-Rank Adaptation Fine-Tuning of Pre-Trained Audio Models**|Xinhu Zheng et.al.|[2409.07016v1](http://arxiv.org/abs/2409.07016v1)|null|
|**2024-09-11**|**Towards Predicting Temporal Changes in a Patient's Chest X-ray Images based on Electronic Health Records**|Daeun Kyung et.al.|[2409.07012v1](http://arxiv.org/abs/2409.07012v1)|null|
|**2024-09-11**|**What is the Right Notion of Distance between Predict-then-Optimize Tasks?**|Paula Rodriguez-Diaz et.al.|[2409.06997v1](http://arxiv.org/abs/2409.06997v1)|null|
|**2024-09-11**|**Large Language Models and the Extended Church-Turing Thesis**|Jiří Wiedermann et.al.|[2409.06978v1](http://arxiv.org/abs/2409.06978v1)|null|
|**2024-09-11**|**Policy Filtration in RLHF to Fine-Tune LLM for Code Generation**|Wei Shen et.al.|[2409.06957v1](http://arxiv.org/abs/2409.06957v1)|[link](https://github.com/swtheing/pf-ppo-rlhf)|
|**2024-09-11**|**Neural Algorithmic Reasoning with Multiple Correct Solutions**|Zeno Kujawa et.al.|[2409.06953v1](http://arxiv.org/abs/2409.06953v1)|null|
|**2024-09-11**|**You Have Thirteen Hours in Which to Solve the Labyrinth: Enhancing AI Game Masters with Function Calling**|Jaewoo Song et.al.|[2409.06949v1](http://arxiv.org/abs/2409.06949v1)|null|
|**2024-09-11**|**FSMDet: Vision-guided feature diffusion for fully sparse 3D detector**|Tianran Liu et.al.|[2409.06945v1](http://arxiv.org/abs/2409.06945v1)|null|
|**2024-09-11**|**FreeRide: Harvesting Bubbles in Pipeline Parallelism**|Jiashu Zhang et.al.|[2409.06941v1](http://arxiv.org/abs/2409.06941v1)|null|
|**2024-09-11**|**Intrapartum Ultrasound Image Segmentation of Pubic Symphysis and Fetal Head Using Dual Student-Teacher Framework with CNN-ViT Collaborative Learning**|Jianmei Jiang et.al.|[2409.06928v1](http://arxiv.org/abs/2409.06928v1)|[link](https://github.com/jjm1589/dstct)|
|**2024-09-11**|**Representation Tuning**|Christopher M. Ackerman et.al.|[2409.06927v1](http://arxiv.org/abs/2409.06927v1)|[link](https://github.com/cma1114/representation_tuning)|
|**2024-09-10**|**Applied Federated Model Personalisation in the Industrial Domain: A Comparative Study**|Ilias Siniosoglou et.al.|[2409.06904v1](http://arxiv.org/abs/2409.06904v1)|null|
|**2024-09-10**|**A Dataset for Evaluating LLM-based Evaluation Functions for Research Question Extraction Task**|Yuya Fujisaki et.al.|[2409.06883v1](http://arxiv.org/abs/2409.06883v1)|null|
|**2024-09-10**|**NSP: A Neuro-Symbolic Natural Language Navigational Planner**|William English et.al.|[2409.06859v1](http://arxiv.org/abs/2409.06859v1)|null|
|**2024-09-10**|**What is the Role of Small Models in the LLM Era: A Survey**|Lihu Chen et.al.|[2409.06857v2](http://arxiv.org/abs/2409.06857v2)|[link](https://github.com/tigerchen52/role_of_small_models)|
|**2024-09-10**|**LIME-M: Less Is More for Evaluation of MLLMs**|Kang Zhu et.al.|[2409.06851v1](http://arxiv.org/abs/2409.06851v1)|[link](https://github.com/kangreen0210/lime-m)|
|**2024-09-10**|**PingPong: A Benchmark for Role-Playing Language Models with User Emulation and Multi-Model Evaluation**|Ilya Gusev et.al.|[2409.06820v1](http://arxiv.org/abs/2409.06820v1)|null|
|**2024-09-10**|**Bifurcation Identification for Ultrasound-driven Robotic Cannulation**|Cecilia G. Morales et.al.|[2409.06817v1](http://arxiv.org/abs/2409.06817v1)|null|
|**2024-09-10**|**Personalized Federated Learning Techniques: Empirical Analysis**|Azal Ahmad Khan et.al.|[2409.06805v1](http://arxiv.org/abs/2409.06805v1)|null|
|**2024-09-10**|**Decomposition of surprisal: Unified computational model of ERP components in language processing**|Jiaxuan Li et.al.|[2409.06803v1](http://arxiv.org/abs/2409.06803v1)|null|
|**2024-09-10**|**Adaptive Meta-Domain Transfer Learning (AMDTL): A Novel Approach for Knowledge Transfer in AI**|Michele Laurelli et.al.|[2409.06800v1](http://arxiv.org/abs/2409.06800v1)|[link](https://github.com/mlaurelli/amdtl)|
|**2024-09-10**|**Translating Step-by-Step: Decomposing the Translation Process for Improved Translation Quality of Long-Form Texts**|Eleftheria Briakou et.al.|[2409.06790v1](http://arxiv.org/abs/2409.06790v1)|null|
|**2024-09-10**|**Hint-AD: Holistically Aligned Interpretability in End-to-End Autonomous Driving**|Kairui Ding et.al.|[2409.06702v1](http://arxiv.org/abs/2409.06702v1)|null|
|**2024-09-10**|**Modeling Image Tone Dichotomy with the Power Function**|Axel Martinez et.al.|[2409.06764v1](http://arxiv.org/abs/2409.06764v1)|null|
|**2024-09-10**|**Geometric-Averaged Preference Optimization for Soft Preference Labels**|Hiroki Furuta et.al.|[2409.06691v1](http://arxiv.org/abs/2409.06691v1)|null|
|**2024-09-10**|**Benchmarking Sub-Genre Classification For Mainstage Dance Music**|Hongzhi Shu et.al.|[2409.06690v1](http://arxiv.org/abs/2409.06690v1)|null|
|**2024-09-10**|**Generative Hierarchical Materials Search**|Sherry Yang et.al.|[2409.06762v1](http://arxiv.org/abs/2409.06762v1)|null|
|**2024-09-10**|**E2LLM: Encoder Elongated Large Language Models for Long-Context Understanding and Reasoning**|Zihan Liao et.al.|[2409.06679v1](http://arxiv.org/abs/2409.06679v1)|null|
|**2024-09-10**|**Liability and Insurance for Catastrophic Losses: the Nuclear Power Precedent and Lessons for AI**|Cristian Trout et.al.|[2409.06673v1](http://arxiv.org/abs/2409.06673v1)|null|
|**2024-09-10**|**LLaMA-Omni: Seamless Speech Interaction with Large Language Models**|Qingkai Fang et.al.|[2409.06666v1](http://arxiv.org/abs/2409.06666v1)|[link](https://github.com/ictnlp/llama-omni)|
|**2024-09-10**|**Sortformer: Seamless Integration of Speaker Diarization and ASR by Bridging Timestamps and Tokens**|Taejin Park et.al.|[2409.06656v1](http://arxiv.org/abs/2409.06656v1)|null|
|**2024-09-10**|**EyeCLIP: A visual-language foundation model for multi-modal ophthalmic image analysis**|Danli Shi et.al.|[2409.06644v2](http://arxiv.org/abs/2409.06644v2)|null|
|**2024-09-10**|**TeXBLEU: Automatic Metric for Evaluate LaTeX Format**|Kyudan Jung et.al.|[2409.06639v2](http://arxiv.org/abs/2409.06639v2)|[link](https://github.com/kyudan1/texbleu)|
|**2024-09-10**|**MoWE-Audio: Multitask AudioLLMs with Mixture of Weak Encoders**|Wenyu Zhang et.al.|[2409.06635v1](http://arxiv.org/abs/2409.06635v1)|null|
|**2024-09-10**|**Beyond designer's knowledge: Generating materials design hypotheses via large language models**|Quanliang Liu et.al.|[2409.06756v1](http://arxiv.org/abs/2409.06756v1)|null|
|**2024-09-10**|**A Practice of Post-Training on Llama-3 70B with Optimal Selection of Additional Language Mixture Ratio**|Ningyuan Xi et.al.|[2409.06624v1](http://arxiv.org/abs/2409.06624v1)|null|
|**2024-09-10**|**Exploring Italian sentence embeddings properties through multi-tasking**|Vivi Nastase et.al.|[2409.06622v1](http://arxiv.org/abs/2409.06622v1)|null|
|**2024-09-10**|**Scaling Law Hypothesis for Multimodal Model**|Qingyun Sun et.al.|[2409.06754v1](http://arxiv.org/abs/2409.06754v1)|null|
|**2024-09-10**|**Label-free Monitoring of Self-Supervised Learning Progress**|Isaac Xu et.al.|[2409.06612v1](http://arxiv.org/abs/2409.06612v1)|null|
|**2024-09-10**|**Alleviating Hallucinations in Large Language Models with Scepticism Modeling**|Yetao Wu et.al.|[2409.06601v1](http://arxiv.org/abs/2409.06601v1)|null|
|**2024-09-10**|**GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering**|Sacha Muller et.al.|[2409.06595v1](http://arxiv.org/abs/2409.06595v1)|null|
|**2024-09-10**|**Developing the Temporal Graph Convolutional Neural Network Model to Predict Hip Replacement using Electronic Health Records**|Zoe Hancox et.al.|[2409.06585v1](http://arxiv.org/abs/2409.06585v1)|[link](https://github.com/zoehancox/sparse_tgcnn)|
|**2024-09-10**|**Quantifying and Enabling the Interpretability of CLIP-like Models**|Avinash Madasu et.al.|[2409.06579v1](http://arxiv.org/abs/2409.06579v1)|null|
|**2024-09-10**|**Exploring syntactic information in sentence embeddings through multilingual subject-verb agreement**|Vivi Nastase et.al.|[2409.06567v1](http://arxiv.org/abs/2409.06567v1)|null|
|**2024-09-10**|**Indirect Dynamic Negotiation in the Nash Demand Game**|Tatiana V. Guy et.al.|[2409.06566v1](http://arxiv.org/abs/2409.06566v1)|null|
|**2024-09-10**|**From LIMA to DeepLIMA: following a new path of interoperability**|Victor Bocharov et.al.|[2409.06550v1](http://arxiv.org/abs/2409.06550v1)|null|
|**2024-09-10**|**Mapping News Narratives Using LLMs and Narrative-Structured Text Embeddings**|Jan Elfes et.al.|[2409.06540v1](http://arxiv.org/abs/2409.06540v1)|null|
|**2024-09-10**|**Questioning Internal Knowledge Structure of Large Language Models Through the Lens of the Olympic Games**|Juhwan Choi et.al.|[2409.06518v1](http://arxiv.org/abs/2409.06518v1)|null|
|**2024-09-10**|**Sine, Transient, Noise Neural Modeling of Piano Notes**|Riccardo Simionato et.al.|[2409.06513v1](http://arxiv.org/abs/2409.06513v1)|null|

#### Abstracts
##### **"My Grade is Wrong!": A Contestable AI Framework for Interactive Feedback in Evaluating Student Essays**
2409.07453v1 by Shengxin Hong, Chang Cai, Sixuan Du, Haiyue Feng, Siyuan Liu, Xiuyi Fan

Interactive feedback, where feedback flows in both directions between teacher
and student, is more effective than traditional one-way feedback. However, it
is often too time-consuming for widespread use in educational practice. While
Large Language Models (LLMs) have potential for automating feedback, they
struggle with reasoning and interaction in an interactive setting. This paper
introduces CAELF, a Contestable AI Empowered LLM Framework for automating
interactive feedback. CAELF allows students to query, challenge, and clarify
their feedback by integrating a multi-agent system with computational
argumentation. Essays are first assessed by multiple Teaching-Assistant Agents
(TA Agents), and then a Teacher Agent aggregates the evaluations through formal
reasoning to generate feedback and grades. Students can further engage with the
feedback to refine their understanding. A case study on 500 critical thinking
essays with user studies demonstrates that CAELF significantly improves
interactive feedback, enhancing the reasoning and interaction capabilities of
LLMs. This approach offers a promising solution to overcoming the time and
resource barriers that have limited the adoption of interactive feedback in
educational settings.

摘要：互動式回饋，也就是回饋在老師和學生之間雙向流動，比傳統單向回饋更有效。然而，在教育實務中廣泛使用互動式回饋往往會過於耗時。儘管大型語言模型 (LLM) 有自動化回饋的潛力，但它們在互動式環境中的推理和互動方面仍有困難。本文介紹 CAELF，一個可爭辯的人工智慧強化 LLM 架構，用於自動化互動式回饋。CAELF 透過整合一個具備計算論證的多重代理系統，讓學生可以查詢、質疑和釐清他們的回饋。論文首先由多位教學助理代理 (TA 代理) 評量，然後教師代理透過形式推理彙整這些評量，以產生回饋和評分。學生可以進一步參與回饋，以改善他們的理解。一個針對 500 篇批判性思考論文的案例研究，以及使用者研究，證明 CAELF 大幅改善了互動式回饋，增強了 LLM 的推理和互動能力。這種方法提供了一個有希望的解決方案，可以克服在教育環境中採用互動式回饋的時間和資源障礙。

##### **SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories**
2409.07440v1 by Ben Bogin, Kejuan Yang, Shashank Gupta, Kyle Richardson, Erin Bransom, Peter Clark, Ashish Sabharwal, Tushar Khot

Given that Large Language Models (LLMs) have made significant progress in
writing code, can they now be used to autonomously reproduce results from
research repositories? Such a capability would be a boon to the research
community, helping researchers validate, understand, and extend prior work. To
advance towards this goal, we introduce SUPER, the first benchmark designed to
evaluate the capability of LLMs in setting up and executing tasks from research
repositories. SUPERaims to capture the realistic challenges faced by
researchers working with Machine Learning (ML) and Natural Language Processing
(NLP) research repositories. Our benchmark comprises three distinct problem
sets: 45 end-to-end problems with annotated expert solutions, 152 sub problems
derived from the expert set that focus on specific challenges (e.g.,
configuring a trainer), and 602 automatically generated problems for
larger-scale development. We introduce various evaluation measures to assess
both task success and progress, utilizing gold solutions when available or
approximations otherwise. We show that state-of-the-art approaches struggle to
solve these problems with the best model (GPT-4o) solving only 16.3% of the
end-to-end set, and 46.1% of the scenarios. This illustrates the challenge of
this task, and suggests that SUPER can serve as a valuable resource for the
community to make and measure progress.

摘要：鉴于大型语言模型 (LLM) 在编写代码方面取得了显著进展，它们现在可否用于自主复制研究存储库中的结果？这种能力将对研究界大有裨益，有助于研究人员验证、理解和扩展先前的工作。为了实现这一目标，我们引入了 SUPER，这是第一个旨在评估 LLM 在设置和执行研究存储库中的任务的能力的基准。SUPER 旨在解决研究人员在使用机器学习 (ML) 和自然语言处理 (NLP) 研究存储库时面临的实际挑战。我们的基准包含三个不同的问题集：45 个带有专家解决方案注释的端到端问题、152 个从专家集中派生出来的子问题，这些子问题侧重于特定挑战（例如配置训练器），以及 602 个为更大规模开发自动生成的问题。我们引入了各种评估措施来评估任务成功和进度，在有黄金解决方案时使用黄金解决方案，否则使用近似值。我们表明，最先进的方法难以解决这些问题，最好的模型 (GPT-4o) 仅解决了 16.3% 的端到端集和 46.1% 的场景。这说明了这项任务的挑战性，并表明 SUPER 可以作为社区做出和衡量进步的宝贵资源。

##### **A Suite for Acoustic Language Model Evaluation**
2409.07437v1 by Gallil Maimon, Amit Roth, Yossi Adi

Speech language models have recently demonstrated great potential as
universal speech processing systems. Such models have the ability to model the
rich acoustic information existing in audio signals, beyond spoken content,
such as emotion, background noise, etc. Despite this, evaluation benchmarks
which evaluate awareness to a wide range of acoustic aspects, are lacking. To
help bridge this gap, we introduce SALMon, a novel evaluation suite
encompassing background noise, emotion, speaker identity and room impulse
response. The proposed benchmarks both evaluate the consistency of the
inspected element and how much it matches the spoken text. We follow a
modelling based approach, measuring whether a model gives correct samples
higher scores than incorrect ones. This approach makes the benchmark fast to
compute even for large models. We evaluated several speech language models on
SALMon, thus highlighting the strengths and weaknesses of each evaluated
method. Code and data are publicly available at
https://pages.cs.huji.ac.il/adiyoss-lab/salmon/ .

摘要：語音語言模型最近已展現出作為通用語音處理系統的巨大潛力。此類模型有能力對音訊訊號中存在的豐富聲學資訊進行建模，除了口說內容之外，例如情緒、背景噪音等。儘管如此，評估基準會評估對廣泛聲學層面的認識，卻有所欠缺。為了幫助彌補此差距，我們引進 SALMon，一個新穎的評估套件，包含背景噪音、情緒、說話者身分和房間脈衝響應。建議的基準同時評估所檢查元素的一致性，以及它與口說文字的匹配程度。我們採用基於建模的方法，測量模型是否給予正確樣本高於不正確樣本的分數。此方法讓基準即使對於大型模型也能快速運算。我們在 SALMon 上評估了數個語音語言模型，從而突顯每個評估方法的優缺點。程式碼和資料已公開於 https://pages.cs.huji.ac.il/adiyoss-lab/salmon/。

##### **Synthetic continued pretraining**
2409.07431v1 by Zitong Yang, Neil Band, Shuangping Li, Emmanuel Candès, Tatsunori Hashimoto

Pretraining on large-scale, unstructured internet text has enabled language
models to acquire a significant amount of world knowledge. However, this
knowledge acquisition is data-inefficient -- to learn a given fact, models must
be trained on hundreds to thousands of diverse representations of it. This
poses a challenge when adapting a pretrained model to a small corpus of
domain-specific documents, where each fact may appear rarely or only once. We
propose to bridge this gap with synthetic continued pretraining: using the
small domain-specific corpus to synthesize a large corpus more amenable to
learning, and then performing continued pretraining on the synthesized corpus.
We instantiate this proposal with EntiGraph, a synthetic data augmentation
algorithm that extracts salient entities from the source documents and then
generates diverse text by drawing connections between the sampled entities.
Synthetic continued pretraining using EntiGraph enables a language model to
answer questions and follow generic instructions related to the source
documents without access to them. If instead, the source documents are
available at inference time, we show that the knowledge acquired through our
approach compounds with retrieval-augmented generation. To better understand
these results, we build a simple mathematical model of EntiGraph, and show how
synthetic data augmentation can "rearrange" knowledge to enable more
data-efficient learning.

摘要：在规模庞大、结构松散的互联网文本上进行预训练，使语言模型能够获取大量的世界知识。然而，这种知识获取效率低下——为了学习一个给定的事实，模型必须接受数百到数千个不同表示形式的训练。当将预训练模型适应到一个包含特定领域文档的小语料库时，这会带来一个挑战，因为每个事实可能很少出现或只出现一次。我们建议用合成持续预训练来弥合理论差距：使用特定领域的小语料库来合成一个更容易学习的大语料库，然后对合成的语料库进行持续预训练。我们用 EntiGraph 实例化了此提议，这是一种合成数据扩充算法，它从源文档中提取显著实体，然后通过绘制抽样实体之间的联系来生成不同的文本。使用 EntiGraph 进行合成持续预训练使语言模型能够回答问题并遵循与源文档相关的通用说明，而无需访问它们。如果相反，源文档在推理时可用，我们表明通过我们的方法获得的知识与检索增强生成相结合。为了更好地理解这些结果，我们建立了一个 EntiGraph 的简单数学模型，并展示了合成数据扩充如何“重新排列”知识以实现更有效率的数据学习。

##### **Agent Workflow Memory**
2409.07429v1 by Zora Zhiruo Wang, Jiayuan Mao, Daniel Fried, Graham Neubig

Despite the potential of language model-based agents to solve real-world
tasks such as web navigation, current methods still struggle with long-horizon
tasks with complex action trajectories. In contrast, humans can flexibly solve
complex tasks by learning reusable task workflows from past experiences and
using them to guide future actions. To build agents that can similarly benefit
from this process, we introduce Agent Workflow Memory (AWM), a method for
inducing commonly reused routines, i.e., workflows, and selectively providing
workflows to the agent to guide subsequent generations. AWM flexibly applies to
both offline and online scenarios, where agents induce workflows from training
examples beforehand or from test queries on the fly. We experiment on two major
web navigation benchmarks -- Mind2Web and WebArena -- that collectively cover
1000+ tasks from 200+ domains across travel, shopping, and social media, among
others. AWM substantially improves the baseline results by 24.6% and 51.1%
relative success rate on Mind2Web and WebArena while reducing the number of
steps taken to solve WebArena tasks successfully. Furthermore, online AWM
robustly generalizes in cross-task, website, and domain evaluations, surpassing
baselines from 8.9 to 14.0 absolute points as train-test task distribution gaps
widen.

摘要：儘管基於語言模型的代理程式具有解決實際世界任務（例如網頁導覽）的潛力，但目前的方法仍難以應付具有複雜動作軌跡的長時程任務。相反地，人類可以透過從過去經驗中學習可重複使用的任務工作流程並使用它們來指導未來行動，靈活地解決複雜任務。為了建構可以從此過程中受益的代理程式，我們引入了代理程式工作流程記憶體 (AWM)，這是一種誘導常用重複常式（即工作流程）並有選擇性地提供工作流程給代理程式以指導後續世代的方法。AWM 可靈活應用於離線和線上場景，其中代理程式事先從訓練範例或從即時測試查詢中誘導工作流程。我們在兩個主要的網頁導覽基準 -- Mind2Web 和 WebArena -- 上進行實驗，這些基準共同涵蓋了來自旅遊、購物和社群媒體等 200 多個網域的 1000 多項任務。AWM 大幅改善了基準結果，在 Mind2Web 和 WebArena 上的相對成功率分別提高了 24.6% 和 51.1%，同時減少了成功解決 WebArena 任務所需的步驟數。此外，線上 AWM 在跨任務、網站和網域評估中強健地概括，超越了基準 8.9 至 14.0 個絕對點，因為訓練測試任務分佈差距擴大。

##### **Towards Fairer Health Recommendations: finding informative unbiased samples via Word Sense Disambiguation**
2409.07424v1 by Gavin Butts, Pegah Emdad, Jethro Lee, Shannon Song, Chiman Salavati, Willmar Sosa Diaz, Shiri Dori-Hacohen, Fabricio Murai

There have been growing concerns around high-stake applications that rely on
models trained with biased data, which consequently produce biased predictions,
often harming the most vulnerable. In particular, biased medical data could
cause health-related applications and recommender systems to create outputs
that jeopardize patient care and widen disparities in health outcomes. A recent
framework titled Fairness via AI posits that, instead of attempting to correct
model biases, researchers must focus on their root causes by using AI to debias
data. Inspired by this framework, we tackle bias detection in medical curricula
using NLP models, including LLMs, and evaluate them on a gold standard dataset
containing 4,105 excerpts annotated by medical experts for bias from a large
corpus. We build on previous work by coauthors which augments the set of
negative samples with non-annotated text containing social identifier terms.
However, some of these terms, especially those related to race and ethnicity,
can carry different meanings (e.g., "white matter of spinal cord"). To address
this issue, we propose the use of Word Sense Disambiguation models to refine
dataset quality by removing irrelevant sentences. We then evaluate fine-tuned
variations of BERT models as well as GPT models with zero- and few-shot
prompting. We found LLMs, considered SOTA on many NLP tasks, unsuitable for
bias detection, while fine-tuned BERT models generally perform well across all
evaluated metrics.

摘要：隨著仰賴由有偏差資料訓練的模型的高風險應用程式越來越多，人們也對此越來越感到憂心，因為這些模型會產生有偏差的預測，而這些預測通常會傷害到最弱勢的族群。特別是，有偏差的醫療資料可能會導致與健康相關的應用程式和推薦系統產生危害病患照護並擴大健康結果差異的輸出。最近一個名為「透過 AI 達成公平性」的架構主張，研究人員不應嘗試修正模型偏差，而必須透過使用 AI 來消除資料偏差，進而找出偏差的根源。受到這個架構的啟發，我們使用包括 LLM 在內的 NLP 模型來處理醫學課程中的偏差偵測，並在一個由醫學專家標註了 4,105 段摘錄的黃金標準資料集上對這些模型進行評估，該資料集來自一個包含大量語料庫的偏差。我們建立在共同作者之前的工作基礎上，該工作透過包含社會標識符詞彙的未標註文字來擴充負面範例的集合。然而，其中某些詞彙，特別是與種族和民族相關的詞彙，可能會帶有不同的意思（例如：「脊髓白質」）。為了解決這個問題，我們建議使用詞彙辨義模型來移除不相關的句子，進而改善資料集品質。接著，我們評估微調後的 BERT 模型變體，以及採用零次和少量提示的 GPT 模型。我們發現，儘管 LLM 在許多 NLP 任務上被認為是 SOTA，但並不適合用於偏差偵測，而微調後的 BERT 模型在所有評估指標上通常都有良好的表現。

##### **Enhancing adversarial robustness in Natural Language Inference using explanations**
2409.07423v1 by Alexandros Koulakos, Maria Lymperaiou, Giorgos Filandrianos, Giorgos Stamou

The surge of state-of-the-art Transformer-based models has undoubtedly pushed
the limits of NLP model performance, excelling in a variety of tasks. We cast
the spotlight on the underexplored task of Natural Language Inference (NLI),
since models trained on popular well-suited datasets are susceptible to
adversarial attacks, allowing subtle input interventions to mislead the model.
In this work, we validate the usage of natural language explanation as a
model-agnostic defence strategy through extensive experimentation: only by
fine-tuning a classifier on the explanation rather than premise-hypothesis
inputs, robustness under various adversarial attacks is achieved in comparison
to explanation-free baselines. Moreover, since there is no standard strategy of
testing the semantic validity of the generated explanations, we research the
correlation of widely used language generation metrics with human perception,
in order for them to serve as a proxy towards robust NLI models. Our approach
is resource-efficient and reproducible without significant computational
limitations.

摘要：隨著最先進的 Transformer 模型的興起，無疑地推動了 NLP 模型效能的極限，在各種任務中表現出色。我們將焦點放在自然語言推理 (NLI) 這個尚未充分探索的任務上，因為在廣受歡迎且適用的資料集上訓練的模型容易受到對抗性攻擊，允許微妙的輸入干預來誤導模型。在這項工作中，我們透過廣泛的實驗驗證了使用自然語言解釋作為與模型無關的防禦策略：僅透過微調分類器針對解釋，而不是前提假設輸入，與沒有解釋的基線相比，在各種對抗性攻擊下實現了穩健性。此外，由於沒有測試生成解釋的語義有效性的標準策略，我們研究了廣泛使用的語言生成指標與人類感知之間的關聯性，以便它們作為健全 NLI 模型的代理。我們的做法資源有效且可複製，沒有顯著的計算限制。

##### **Hierarchical Reinforcement Learning for Temporal Abstraction of Listwise Recommendation**
2409.07416v1 by Luo Ji, Gao Liu, Mingyang Yin, Hongxia Yang, Jingren Zhou

Modern listwise recommendation systems need to consider both long-term user
perceptions and short-term interest shifts. Reinforcement learning can be
applied on recommendation to study such a problem but is also subject to large
search space, sparse user feedback and long interactive latency. Motivated by
recent progress in hierarchical reinforcement learning, we propose a novel
framework called mccHRL to provide different levels of temporal abstraction on
listwise recommendation. Within the hierarchical framework, the high-level
agent studies the evolution of user perception, while the low-level agent
produces the item selection policy by modeling the process as a sequential
decision-making problem. We argue that such framework has a well-defined
decomposition of the outra-session context and the intra-session context, which
are encoded by the high-level and low-level agents, respectively. To verify
this argument, we implement both a simulator-based environment and an
industrial dataset-based experiment. Results observe significant performance
improvement by our method, compared with several well-known baselines. Data and
codes have been made public.

摘要：現代的清單推薦系統需要考慮長期的使用者感知和短期的興趣轉移。強化學習可以應用在推薦系統上來研究此類問題，但也會受到廣闊的搜尋空間、稀疏的使用者回饋和長的互動延遲影響。受到層級強化學習的最新進展啟發，我們提出了一個名為 mccHRL 的新框架，在清單推薦上提供不同層級的時間抽象。在層級框架中，高層級的代理研究使用者感知的演變，而低層級的代理則透過將流程建模為順序決策問題來產生項目選擇政策。我們認為此框架對超時段脈絡和時段內脈絡有明確的分解，分別由高層級和低層級代理編碼。為了驗證此論點，我們同時實作了基於模擬器的環境和基於產業資料集的實驗。與幾個著名的基準相比，結果觀察到我們的方法有顯著的效能提升。資料和程式碼已經公開。

##### **SoK: Security and Privacy Risks of Medical AI**
2409.07415v1 by Yuanhaur Chang, Han Liu, Evin Jaff, Chenyang Lu, Ning Zhang

The integration of technology and healthcare has ushered in a new era where
software systems, powered by artificial intelligence and machine learning, have
become essential components of medical products and services. While these
advancements hold great promise for enhancing patient care and healthcare
delivery efficiency, they also expose sensitive medical data and system
integrity to potential cyberattacks. This paper explores the security and
privacy threats posed by AI/ML applications in healthcare. Through a thorough
examination of existing research across a range of medical domains, we have
identified significant gaps in understanding the adversarial attacks targeting
medical AI systems. By outlining specific adversarial threat models for medical
settings and identifying vulnerable application domains, we lay the groundwork
for future research that investigates the security and resilience of AI-driven
medical systems. Through our analysis of different threat models and
feasibility studies on adversarial attacks in different medical domains, we
provide compelling insights into the pressing need for cybersecurity research
in the rapidly evolving field of AI healthcare technology.

摘要：科技與醫療的整合開啟了一個新紀元，由人工智慧和機器學習驅動的軟體系統已成為醫療產品和服務的必要組成部分。雖然這些進步對改善患者照護和醫療保健提供效率有很大的幫助，但它們也讓敏感的醫療資料和系統完整性面臨潛在的網路攻擊風險。本文探討了人工智慧/機器學習應用在醫療保健中帶來的安全性和隱私威脅。透過徹底檢視各項醫療領域現有的研究，我們發現了在了解針對醫療人工智慧系統的對抗性攻擊方面有顯著的差距。透過概述醫療環境的特定對抗性威脅模型並找出容易受攻擊的應用領域，我們為未來研究奠定基礎，探討人工智慧驅動醫療系統的安全性與復原力。透過分析不同的威脅模型和針對不同醫療領域的對抗性攻擊可行性研究，我們對人工智慧醫療保健技術快速發展領域中網路安全研究的迫切需求提供了令人信服的見解。

##### **CLNX: Bridging Code and Natural Language for C/C++ Vulnerability-Contributing Commits Identification**
2409.07407v1 by Zeqing Qin, Yiwei Wu, Lansheng Han

Large Language Models (LLMs) have shown great promise in vulnerability
identification. As C/C++ comprises half of the Open-Source Software (OSS)
vulnerabilities over the past decade and updates in OSS mainly occur through
commits, enhancing LLMs' ability to identify C/C++ Vulnerability-Contributing
Commits (VCCs) is essential. However, current studies primarily focus on
further pre-training LLMs on massive code datasets, which is resource-intensive
and poses efficiency challenges. In this paper, we enhance the ability of
BERT-based LLMs to identify C/C++ VCCs in a lightweight manner. We propose
CodeLinguaNexus (CLNX) as a bridge facilitating communication between C/C++
programs and LLMs. Based on commits, CLNX efficiently converts the source code
into a more natural representation while preserving key details. Specifically,
CLNX first applies structure-level naturalization to decompose complex
programs, followed by token-level naturalization to interpret complex symbols.
We evaluate CLNX on public datasets of 25,872 C/C++ functions with their
commits. The results show that CLNX significantly enhances the performance of
LLMs on identifying C/C++ VCCs. Moreover, CLNX-equipped CodeBERT achieves new
state-of-the-art and identifies 38 OSS vulnerabilities in the real world.

摘要：大型語言模型 (LLM) 在漏洞識別方面展現出極大的前景。由於 C/C++ 涵蓋了過去十年中一半的開源軟體 (OSS) 漏洞，而 OSS 更新主要透過提交進行，因此提升 LLM 識別 C/C++ 漏洞貢獻提交 (VCC) 的能力至關重要。然而，目前的研究主要集中於在大量的程式碼資料集上進一步預訓練 LLM，這需要大量的資源且會造成效率方面的挑戰。在本文中，我們以輕量化的方式提升 BERT-based LLM 識別 C/C++ VCC 的能力。我們提出 CodeLinguaNexus (CLNX) 作為促進 C/C++ 程式與 LLM 之間溝通的橋樑。CLNX 基於提交，將原始程式碼有效地轉換為更自然的表示形式，同時保留關鍵細節。具體來說，CLNX 首先應用結構層次自然化來分解複雜的程式，然後應用代碼層次自然化來解釋複雜的符號。我們在包含 25,872 個 C/C++ 函數及其提交的公開資料集上評估 CLNX。結果顯示，CLNX 大幅提升 LLM 識別 C/C++ VCC 的效能。此外，配備 CLNX 的 CodeBERT 達到新的技術水準，並在真實世界中識別出 38 個 OSS 漏洞。

##### **AdaCAD: Adaptively Decoding to Balance Conflicts between Contextual and Parametric Knowledge**
2409.07394v1 by Han Wang, Archiki Prasad, Elias Stengel-Eskin, Mohit Bansal

Knowledge conflict arises from discrepancies between information in the
context of a large language model (LLM) and the knowledge stored in its
parameters. This can hurt performance when using standard decoding techniques,
which tend to ignore the context. Existing test-time contrastive methods seek
to address this by comparing the LLM's output distribution with and without the
context and adjust the model according to the contrast between them. However,
we find that these methods frequently misjudge the degree of conflict and
struggle to handle instances that vary in their amount of conflict, with static
methods over-adjusting when conflict is absent. We propose a fine-grained,
instance-level approach called AdaCAD, which dynamically infers the weight of
adjustment based on the degree of conflict, as measured by the Jensen-Shannon
divergence between distributions representing contextual and parametric
knowledge. Our experiments across four models on six diverse question-answering
(QA) datasets and three summarization tasks demonstrate that our training-free
adaptive method consistently outperforms other decoding methods on QA, with
average accuracy gains of 14.21% (absolute) over a static contrastive baseline,
and improves the factuality of summaries by 5.59 (AlignScore). Furthermore, our
analysis shows that while decoding with contrastive baselines hurts performance
when conflict is absent, AdaCAD mitigates these losses, making it more
applicable to real-world datasets in which some examples have conflict and
others do not.

摘要：知識衝突源自於大型語言模型 (LLM) 中的資訊與儲存在其參數中的知識之間的差異。在使用標準解碼技術時，這可能會損害效能，因為這些技術往往會忽略上下文。現有的測試時間對比方法會透過比較 LLM 的輸出分佈（有上下文和無上下文）來解決這個問題，並根據它們之間的對比調整模型。然而，我們發現這些方法經常誤判衝突程度，且難以處理衝突量不同的實例，而靜態方法在沒有衝突時會過度調整。我們提出一個稱為 AdaCAD 的細緻化、實例層級方法，它會根據衝突程度動態推論調整權重，而衝突程度是由表示情境和參數知識的分佈之間的 Jensen-Shannon 散度所測量。我們在六個不同的問答 (QA) 資料集和三個摘要任務中，針對四個模型所做的實驗證明，我們的無訓練自適應方法在 QA 上始終優於其他解碼方法，平均準確度比靜態對比基準高出 14.21%（絕對值），並將摘要的事實性提高 5.59（AlignScore）。此外，我們的分析顯示，雖然使用對比基準進行解碼在沒有衝突時會損害效能，但 AdaCAD 減輕了這些損失，使其更適用於某些範例有衝突而另一些範例沒有衝突的真實世界資料集。

##### **Awaking the Slides: A Tuning-free and Knowledge-regulated AI Tutoring System via Language Model Coordination**
2409.07372v1 by Daniel Zhang-Li, Zheyuan Zhang, Jifan Yu, Joy Lim Jia Yin, Shangqing Tu, Linlu Gong, Haohua Wang, Zhiyuan Liu, Huiqin Liu, Lei Hou, Juanzi Li

The vast pre-existing slides serve as rich and important materials to carry
lecture knowledge. However, effectively leveraging lecture slides to serve
students is difficult due to the multi-modal nature of slide content and the
heterogeneous teaching actions. We study the problem of discovering effective
designs that convert a slide into an interactive lecture. We develop
Slide2Lecture, a tuning-free and knowledge-regulated intelligent tutoring
system that can (1) effectively convert an input lecture slide into a
structured teaching agenda consisting of a set of heterogeneous teaching
actions; (2) create and manage an interactive lecture that generates responsive
interactions catering to student learning demands while regulating the
interactions to follow teaching actions. Slide2Lecture contains a complete
pipeline for learners to obtain an interactive classroom experience to learn
the slide. For teachers and developers, Slide2Lecture enables customization to
cater to personalized demands. The evaluation rated by annotators and students
shows that Slide2Lecture is effective in outperforming the remaining
implementation. Slide2Lecture's online deployment has made more than 200K
interaction with students in the 3K lecture sessions. We open source
Slide2Lecture's implementation in
https://anonymous.4open.science/r/slide2lecture-4210/.

摘要：既有的豐富簡報投影片，是傳遞課程知識的重要素材。不過，由於簡報投影片的內容多元，教學行為又相當多元，要有效運用簡報投影片來服務學生，相當困難。本研究探討找出有效設計，將簡報投影片轉化為互動式課程。我們開發出 Slide2Lecture，這是一個無需調整參數、知識導向的智慧教學系統，可以：(1) 有效將輸入的課程簡報投影片，轉換成由一系列多元教學行為組成的結構化教學計畫；(2) 建立並管理互動式課程，產生回應式的互動，以滿足學生的學習需求，同時調整互動，以遵循教學行為。Slide2Lecture 包含一個完整的流程，讓學習者可以獲得互動式教室體驗，以學習簡報投影片。對於教師和開發人員，Slide2Lecture 能夠客製化，以滿足個人需求。經由註解者和學生評分，Slide2Lecture 的表現優於其他實作。Slide2Lecture 的線上部署，已在 3K 堂課程中與學生產生超過 20 萬次的互動。我們開放 Slide2Lecture 的實作原始碼，網址為 https://anonymous.4open.science/r/slide2lecture-4210/。

##### **Demo: SGCode: A Flexible Prompt-Optimizing System for Secure Generation of Code**
2409.07368v1 by Khiem Ton, Nhi Nguyen, Mahmoud Nazzal, Abdallah Khreishah, Cristian Borcea, NhatHai Phan, Ruoming Jin, Issa Khalil, Yelong Shen

This paper introduces SGCode, a flexible prompt-optimizing system to generate
secure code with large language models (LLMs). SGCode integrates recent
prompt-optimization approaches with LLMs in a unified system accessible through
front-end and back-end APIs, enabling users to 1) generate secure code, which
is free of vulnerabilities, 2) review and share security analysis, and 3)
easily switch from one prompt optimization approach to another, while providing
insights on model and system performance. We populated SGCode on an AWS server
with PromSec, an approach that optimizes prompts by combining an LLM and
security tools with a lightweight generative adversarial graph neural network
to detect and fix security vulnerabilities in the generated code. Extensive
experiments show that SGCode is practical as a public tool to gain insights
into the trade-offs between model utility, secure code generation, and system
cost. SGCode has only a marginal cost compared with prompting LLMs. SGCode is
available at: http://3.131.141.63:8501/.

摘要：本文介紹 SGCode，這是一個彈性的提示最佳化系統，用於使用大型語言模型 (LLM) 產生安全的程式碼。SGCode 將最近的提示最佳化方法與 LLM 整合在一個統一的系統中，可透過前端和後端 API 存取，使用戶能夠 1) 產生安全的程式碼，沒有漏洞，2) 檢閱並分享安全性分析，以及 3) 輕鬆從一種提示最佳化方法切換到另一種方法，同時提供模型和系統效能的見解。我們在 AWS 伺服器上使用 PromSec 填充 SGCode，這是一種透過結合 LLM 和安全性工具與輕量級生成對抗圖神經網路來最佳化提示的方法，用於偵測並修正產生程式碼中的安全性漏洞。廣泛的實驗顯示，SGCode 是一個實用的公開工具，可用於深入了解模型效用、安全程式碼產生和系統成本之間的權衡。與提示 LLM 相比，SGCode 僅有微小的成本。SGCode 可在以下網址取得：http://3.131.141.63:8501/。

##### **Think Together and Work Better: Combining Humans' and LLMs' Think-Aloud Outcomes for Effective Text Evaluation**
2409.07355v1 by SeongYeub Chu, JongWoo Kim, MunYong Yi

This study introduces \textbf{InteractEval}, a framework that integrates
human expertise and Large Language Models (LLMs) using the Think-Aloud (TA)
method to generate attributes for checklist-based text evaluation. By combining
human flexibility and reasoning with LLM consistency, InteractEval outperforms
traditional non-LLM-based and LLM-based baselines across four distinct
dimensions, consisting of Coherence, Fluency, Consistency, and Relevance. The
experiment also investigates the effectiveness of the TA method, showing that
it promotes divergent thinking in both humans and LLMs, leading to the
generation of a wider range of relevant attributes and enhance text evaluation
performance. Comparative analysis reveals that humans excel at identifying
attributes related to internal quality (Coherence and Fluency), but LLMs
perform better at those attributes related to external alignment (Consistency
and Relevance). Consequently, leveraging both humans and LLMs together produces
the best evaluation outcomes. In other words, this study emphasizes the
necessity of effectively combining humans and LLMs in an automated
checklist-based text evaluation framework. The code is available at
\textbf{\url{https://github.com/BBeeChu/InteractEval.git}}.

摘要：本研究引入了 **InteractEval**，一個整合人類專業知識和大型語言模型 (LLM) 的框架，使用思考出聲 (TA) 方法為基於核對清單的文字評估產生屬性。透過結合人類的靈活性與推理能力和 LLM 的一致性，InteractEval 在四個不同的面向（包括一致性、流暢度、連貫性和相關性）上優於傳統的非 LLM 基準和 LLM 基準。實驗也探討了 TA 方法的有效性，顯示它能促進人類和 LLM 的發散性思考，從而產生更廣泛相關屬性並提升文字評估的表現。比較分析顯示，人類擅於找出與內部品質（一致性和流暢度）相關的屬性，但 LLM 在與外部對齊（連貫性和相關性）相關的屬性上表現得更好。因此，同時利用人類和 LLM 能產生最佳的評估結果。換句話說，本研究強調在自動化的基於核對清單的文字評估框架中有效結合人類和 LLM 的必要性。程式碼可在 **\url{https://github.com/BBeeChu/InteractEval.git}** 取得。

##### **Securing Vision-Language Models with a Robust Encoder Against Jailbreak and Adversarial Attacks**
2409.07353v1 by Md Zarif Hossain, Ahmed Imteaj

Large Vision-Language Models (LVLMs), trained on multimodal big datasets,
have significantly advanced AI by excelling in vision-language tasks. However,
these models remain vulnerable to adversarial attacks, particularly jailbreak
attacks, which bypass safety protocols and cause the model to generate
misleading or harmful responses. This vulnerability stems from both the
inherent susceptibilities of LLMs and the expanded attack surface introduced by
the visual modality. We propose Sim-CLIP+, a novel defense mechanism that
adversarially fine-tunes the CLIP vision encoder by leveraging a Siamese
architecture. This approach maximizes cosine similarity between perturbed and
clean samples, facilitating resilience against adversarial manipulations.
Sim-CLIP+ offers a plug-and-play solution, allowing seamless integration into
existing LVLM architectures as a robust vision encoder. Unlike previous
defenses, our method requires no structural modifications to the LVLM and
incurs minimal computational overhead. Sim-CLIP+ demonstrates effectiveness
against both gradient-based adversarial attacks and various jailbreak
techniques. We evaluate Sim-CLIP+ against three distinct jailbreak attack
strategies and perform clean evaluations using standard downstream datasets,
including COCO for image captioning and OKVQA for visual question answering.
Extensive experiments demonstrate that Sim-CLIP+ maintains high clean accuracy
while substantially improving robustness against both gradient-based
adversarial attacks and jailbreak techniques. Our code and robust vision
encoders are available at
https://github.com/speedlab-git/Robust-Encoder-against-Jailbreak-attack.git.

摘要：<paragraph>大型視覺語言模型 (LVLMs) 接受過多模態大型資料集的訓練，在視覺語言任務中表現出色，大幅提升了人工智慧。然而，這些模型仍然容易受到對抗性攻擊，特別是越獄攻擊，這會繞過安全協定並導致模型產生誤導或有害的回應。此漏洞源於 LLM 本身的易受攻擊性，以及視覺模態所帶來的擴充攻擊面。我們提出 Sim-CLIP+，這是一種新穎的防禦機制，透過利用 Siamese 架構對抗性微調 CLIP 視覺編碼器。此方法最大化擾動和乾淨樣本之間的餘弦相似性，以利於對抗對抗性操作。Sim-CLIP+ 提供即插即用解決方案，可作為強健的視覺編碼器無縫整合至現有的 LVLM 架構。與先前的防禦措施不同，我們的做法不需要對 LVLM 進行結構修改，且運算負擔極小。Sim-CLIP+ 已證實對抗梯度式對抗性攻擊和各種越獄技術有效。我們針對三種不同的越獄攻擊策略評估 Sim-CLIP+，並使用標準下游資料集（包括用於影像標題的 COCO 和用於視覺問題解答的 OKVQA）執行乾淨評估。廣泛的實驗證明，Sim-CLIP+ 在大幅提升對抗梯度式對抗性攻擊和越獄技術的強健性的同時，維持高度的乾淨準確度。我們的程式碼和強健的視覺編碼器可在 https://github.com/speedlab-git/Robust-Encoder-against-Jailbreak-attack.git 取得。</paragraph>

##### **Federated Impression for Learning with Distributed Heterogeneous Data**
2409.07351v1 by Sana Ayromlou, Atrin Arya, Armin Saadat, Purang Abolmaesumi, Xiaoxiao Li

Standard deep learning-based classification approaches may not always be
practical in real-world clinical applications, as they require a centralized
collection of all samples. Federated learning (FL) provides a paradigm that can
learn from distributed datasets across clients without requiring them to share
data, which can help mitigate privacy and data ownership issues. In FL,
sub-optimal convergence caused by data heterogeneity is common among data from
different health centers due to the variety in data collection protocols and
patient demographics across centers. Through experimentation in this study, we
show that data heterogeneity leads to the phenomenon of catastrophic forgetting
during local training. We propose FedImpres which alleviates catastrophic
forgetting by restoring synthetic data that represents the global information
as federated impression. To achieve this, we distill the global model resulting
from each communication round. Subsequently, we use the synthetic data
alongside the local data to enhance the generalization of local training.
Extensive experiments show that the proposed method achieves state-of-the-art
performance on both the BloodMNIST and Retina datasets, which contain label
imbalance and domain shift, with an improvement in classification accuracy of
up to 20%.

摘要：標準的深度學習分類方法在實際的臨床應用中可能並不總是實用的，因為它們需要集中收集所有樣本。聯邦學習 (FL) 提供了一個範例，可以在不讓客戶端分享數據的情況下從分布式數據集學習，這有助於減輕隱私和數據所有權問題。在 FL 中，由於不同醫療中心的數據收集協定和患者人口統計資料的差異，來自不同醫療中心的數據之間常見的數據異質性會導致次最佳收斂。透過本研究中的實驗，我們表明數據異質性會導致局部訓練期間發生災難性遺忘現象。我們提出 FedImpres，它透過還原表示全球資訊的合成資料作為聯邦印象來減輕災難性遺忘。為此，我們提煉出每一輪通訊所產生的全球模型。隨後，我們使用合成資料和本地資料來增強本地訓練的概括性。廣泛的實驗表明，所提出的方法在 BloodMNIST 和 Retina 數據集上都達到了最先進的效能，這些數據集包含標籤不平衡和領域轉移，分類準確度提高了 20%。

##### **Online Decision MetaMorphFormer: A Casual Transformer-Based Reinforcement Learning Framework of Universal Embodied Intelligence**
2409.07341v1 by Luo Ji, Runji Lin

Interactive artificial intelligence in the motion control field is an
interesting topic, especially when universal knowledge is adaptive to multiple
tasks and universal environments. Despite there being increasing efforts in the
field of Reinforcement Learning (RL) with the aid of transformers, most of them
might be limited by the offline training pipeline, which prohibits exploration
and generalization abilities. To address this limitation, we propose the
framework of Online Decision MetaMorphFormer (ODM) which aims to achieve
self-awareness, environment recognition, and action planning through a unified
model architecture. Motivated by cognitive and behavioral psychology, an ODM
agent is able to learn from others, recognize the world, and practice itself
based on its own experience. ODM can also be applied to any arbitrary agent
with a multi-joint body, located in different environments, and trained with
different types of tasks using large-scale pre-trained datasets. Through the
use of pre-trained datasets, ODM can quickly warm up and learn the necessary
knowledge to perform the desired task, while the target environment continues
to reinforce the universal policy. Extensive online experiments as well as
few-shot and zero-shot environmental tests are used to verify ODM's performance
and generalization ability. The results of our study contribute to the study of
general artificial intelligence in embodied and cognitive fields. Code,
results, and video examples can be found on the website
\url{https://rlodm.github.io/odm/}.

摘要：運動控制領域的互動式人工智慧是一個有趣的議題，特別是在通用知識適用於多項任務和通用環境時。儘管在強化學習（RL）領域中，在Transformer的幫助下付出了越來越多的努力，但其中大部分可能受到離線訓練管線的限制，這會禁止探索和概括能力。為了解決這個限制，我們提出了線上決策 MetaMorphFormer（ODM）架構，其目標是透過統一的模型架構來實現自我意識、環境識別和動作規劃。在認知和行為心理學的激勵下，ODM 代理能夠從他人學習、認識世界並根據自己的經驗練習。ODM 也可以應用於任何具有多關節身體、位於不同環境中的任意代理，並使用大型預先訓練的資料集訓練不同類型的任務。透過使用預先訓練的資料集，ODM 可以快速熱身並學習執行所需任務的必要知識，而目標環境會持續強化通用政策。廣泛的線上實驗以及少次嘗試和零次嘗試的環境測試用於驗證 ODM 的效能和概括能力。我們研究的結果有助於具身和認知領域中通用人工智慧的研究。程式碼、結果和影片範例可以在網站上找到：\url{https://rlodm.github.io/odm/}。

##### **Explanation, Debate, Align: A Weak-to-Strong Framework for Language Model Generalization**
2409.07335v1 by Mehrdad Zakershahrak, Samira Ghodratnama

The rapid advancement of artificial intelligence systems has brought the
challenge of AI alignment to the forefront of research, particularly in complex
decision-making and task execution. As these systems surpass human-level
performance in sophisticated problems, ensuring their alignment with human
values, intentions, and ethical guidelines becomes crucial. Building on
previous work in explanation generation for human-agent alignment, we address
the more complex dynamics of multi-agent systems and human-AI teams. This paper
introduces a novel approach to model alignment through weak-to-strong
generalization in the context of language models. We present a framework where
a strong model facilitates the improvement of a weaker model, bridging the gap
between explanation generation and model alignment. Our method, formalized as a
facilitation function, allows for the transfer of capabilities from advanced
models to less capable ones without direct access to extensive training data.
Our results suggest that this facilitation-based approach not only enhances
model performance but also provides insights into the nature of model alignment
and the potential for scalable oversight of AI systems.

摘要：人工智慧系統的快速進步，讓 AI 對齊的挑戰成為研究的最前線，特別是在複雜的決策制定和任務執行中。由於這些系統在複雜問題中超越人類層級的表現，確保它們與人類價值觀、意圖和道德準則保持一致變得至關重要。建立在先前人類代理對齊的解釋產生工作基礎上，我們探討了多代理系統和人類 AI 團隊更複雜的動態。本文介紹了一種透過語言模型中從弱到強概括來建模對齊的新方法。我們提出了一個架構，其中強大的模型促進了較弱模型的改進，縮小了解釋產生和模型對齊之間的差距。我們的這個方法形式化為一個促進功能，允許從進階模型將能力轉移到較弱的模型，而無需直接存取廣泛的訓練資料。我們的結果表明，這種基於促進的方法不僅增強了模型效能，還提供了對模型對齊的本質和 AI 系統可擴充監督的潛力的見解。

##### **Module-wise Adaptive Adversarial Training for End-to-end Autonomous Driving**
2409.07321v1 by Tianyuan Zhang, Lu Wang, Jiaqi Kang, Xinwei Zhang, Siyuan Liang, Yuwei Chen, Aishan Liu, Xianglong Liu

Recent advances in deep learning have markedly improved autonomous driving
(AD) models, particularly end-to-end systems that integrate perception,
prediction, and planning stages, achieving state-of-the-art performance.
However, these models remain vulnerable to adversarial attacks, where
human-imperceptible perturbations can disrupt decision-making processes. While
adversarial training is an effective method for enhancing model robustness
against such attacks, no prior studies have focused on its application to
end-to-end AD models. In this paper, we take the first step in adversarial
training for end-to-end AD models and present a novel Module-wise Adaptive
Adversarial Training (MA2T). However, extending conventional adversarial
training to this context is highly non-trivial, as different stages within the
model have distinct objectives and are strongly interconnected. To address
these challenges, MA2T first introduces Module-wise Noise Injection, which
injects noise before the input of different modules, targeting training models
with the guidance of overall objectives rather than each independent module
loss. Additionally, we introduce Dynamic Weight Accumulation Adaptation, which
incorporates accumulated weight changes to adaptively learn and adjust the loss
weights of each module based on their contributions (accumulated reduction
rates) for better balance and robust training. To demonstrate the efficacy of
our defense, we conduct extensive experiments on the widely-used nuScenes
dataset across several end-to-end AD models under both white-box and black-box
attacks, where our method outperforms other baselines by large margins
(+5-10%). Moreover, we validate the robustness of our defense through
closed-loop evaluation in the CARLA simulation environment, showing improved
resilience even against natural corruption.

摘要：<paragraph>深度學習的最新進展顯著改善了自動駕駛 (AD) 模型，特別是整合感知、預測和規劃階段的端到端系統，達到了最先進的效能。
然而，這些模型仍然容易受到對抗性攻擊，其中人類無法察覺的擾動會破壞決策制定過程。雖然對抗性訓練是一種增強模型對抗此類攻擊的有效方法，但沒有先前的研究專注於將其應用於端到端 AD 模型。在本文中，我們採取了端到端 AD 模型對抗性訓練的第一步，並提出了一種新穎的模組化自適應對抗性訓練 (MA2T)。然而，將傳統的對抗性訓練擴展到這個背景下非常困難，因為模型中的不同階段有不同的目標，並且緊密相連。為了應對這些挑戰，MA2T 首先引入了模組化雜訊注入，它在不同模組的輸入之前注入雜訊，以整體目標的指導訓練模型，而不是每個獨立模組的損失。此外，我們引入了動態權重累積適應，它結合了累積的權重變化，根據其貢獻（累積的減少率）自適應地學習和調整每個模組的損失權重，以獲得更好的平衡和穩健的訓練。為了證明我們防禦的有效性，我們在廣泛使用的 nuScenes 資料集上對多個端到端 AD 模型進行了廣泛的實驗，在白盒和黑盒攻擊下，我們的模型以很大的幅度（+5-10%）優於其他基線。此外，我們通過在 CARLA 模擬環境中進行閉環評估驗證了我們防禦的穩健性，即使面對自然破壞，也顯示出改進的復原力。</paragraph>

##### **MEDIC: Towards a Comprehensive Framework for Evaluating LLMs in Clinical Applications**
2409.07314v1 by Praveen K Kanithi, Clément Christophe, Marco AF Pimentel, Tathagata Raha, Nada Saadi, Hamza Javed, Svetlana Maslenkova, Nasir Hayat, Ronnie Rajan, Shadab Khan

The rapid development of Large Language Models (LLMs) for healthcare
applications has spurred calls for holistic evaluation beyond frequently-cited
benchmarks like USMLE, to better reflect real-world performance. While
real-world assessments are valuable indicators of utility, they often lag
behind the pace of LLM evolution, likely rendering findings obsolete upon
deployment. This temporal disconnect necessitates a comprehensive upfront
evaluation that can guide model selection for specific clinical applications.
We introduce MEDIC, a framework assessing LLMs across five critical dimensions
of clinical competence: medical reasoning, ethics and bias, data and language
understanding, in-context learning, and clinical safety. MEDIC features a novel
cross-examination framework quantifying LLM performance across areas like
coverage and hallucination detection, without requiring reference outputs. We
apply MEDIC to evaluate LLMs on medical question-answering, safety,
summarization, note generation, and other tasks. Our results show performance
disparities across model sizes, baseline vs medically finetuned models, and
have implications on model selection for applications requiring specific model
strengths, such as low hallucination or lower cost of inference. MEDIC's
multifaceted evaluation reveals these performance trade-offs, bridging the gap
between theoretical capabilities and practical implementation in healthcare
settings, ensuring that the most promising models are identified and adapted
for diverse healthcare applications.

摘要：大型語言模型 (LLM) 在醫療保健應用方面的快速發展，促使人們呼籲進行整體評估，超越經常引用的基準（例如 USMLE），以更好地反映實際效能。儘管實際評估是實用性的寶貴指標，但它們通常落後於 LLM 演化的速度，在部署後可能會使研究結果過時。這種時間上的脫節需要進行全面的前期評估，以指導特定臨床應用程式的模型選擇。我們引進 MEDIC，一個評估 LLM 跨越臨床能力的五個關鍵面向的架構：醫療推理、倫理和偏差、資料和語言理解、情境學習和臨床安全性。MEDIC 採用一種新穎的交互式檢查架構，量化 LLM 在涵蓋範圍和幻覺偵測等領域的效能，而不需要參考輸出。我們使用 MEDIC 來評估 LLM 在醫療問題解答、安全性、摘要、筆記產生和其他任務上的表現。我們的結果顯示，不同模型大小、基準與經過醫療微調的模型之間的效能差異，並對需要特定模型優勢的應用程式（例如低幻覺或較低的推論成本）的模型選擇產生影響。MEDIC 的多面向評估揭示了這些效能權衡，縮小了理論能力與醫療保健環境中的實際實作之間的差距，確保找出最有希望的模型，並針對不同的醫療保健應用程式進行調整。

##### **Exploring User-level Gradient Inversion with a Diffusion Prior**
2409.07291v1 by Zhuohang Li, Andrew Lowy, Jing Liu, Toshiaki Koike-Akino, Bradley Malin, Kieran Parsons, Ye Wang

We explore user-level gradient inversion as a new attack surface in
distributed learning. We first investigate existing attacks on their ability to
make inferences about private information beyond training data reconstruction.
Motivated by the low reconstruction quality of existing methods, we propose a
novel gradient inversion attack that applies a denoising diffusion model as a
strong image prior in order to enhance recovery in the large batch setting.
Unlike traditional attacks, which aim to reconstruct individual samples and
suffer at large batch and image sizes, our approach instead aims to recover a
representative image that captures the sensitive shared semantic information
corresponding to the underlying user. Our experiments with face images
demonstrate the ability of our methods to recover realistic facial images along
with private user attributes.

摘要：我們探索使用者層級梯度反轉作為分散式學習中新的攻擊面。我們首先調查現有攻擊，了解它們推論訓練資料重建以外的私人資訊的能力。在現有方法重建品質低落的動機下，我們提出一個新穎的梯度反轉攻擊，它採用去噪擴散模型作為強大的影像先驗，以增強在大批次設定中的復原能力。與傳統攻擊不同的是，傳統攻擊旨在重建個別樣本，並在大量的批次和影像大小中受苦，我們的做法反而旨在復原一個代表性的影像，捕捉與底層使用者相應的敏感共享語義資訊。我們對人臉影像進行的實驗證明了我們的方法能夠復原逼真的臉部影像，以及私人使用者屬性。

##### **Using Generative Agents to Create Tip Sheets for Investigative Data Reporting**
2409.07286v1 by Joris Veerbeek, Nicholas Diakopoulos

This paper introduces a system using generative AI agents to create tip
sheets for investigative data reporting. Our system employs three specialized
agents--an analyst, a reporter, and an editor--to collaboratively generate and
refine tips from datasets. We validate this approach using real-world
investigative stories, demonstrating that our agent-based system generally
generates more newsworthy and accurate insights compared to a baseline model
without agents, although some variability was noted between different stories.
Our findings highlight the potential of generative AI to provide leads for
investigative data reporting.

摘要：本論文介紹一個系統，利用生成式 AI 代理來為調查資料報導建立提示清單。我們的系統採用三個專業代理——分析師、記者和編輯——來協作生成和優化來自資料集的提示。我們使用真實世界的調查報導來驗證此方法，證明我們的基於代理的系統通常會產生比沒有代理的基線模型更多有新聞價值且準確的見解，儘管在不同的報導之間會有一些差異。我們的發現突顯了生成式 AI 為調查資料報導提供線索的潛力。

##### **Cross-Dialect Text-To-Speech in Pitch-Accent Language Incorporating Multi-Dialect Phoneme-Level BERT**
2409.07265v1 by Kazuki Yamauchi, Yuki Saito, Hiroshi Saruwatari

We explore cross-dialect text-to-speech (CD-TTS), a task to synthesize
learned speakers' voices in non-native dialects, especially in pitch-accent
languages. CD-TTS is important for developing voice agents that naturally
communicate with people across regions. We present a novel TTS model comprising
three sub-modules to perform competitively at this task. We first train a
backbone TTS model to synthesize dialect speech from a text conditioned on
phoneme-level accent latent variables (ALVs) extracted from speech by a
reference encoder. Then, we train an ALV predictor to predict ALVs tailored to
a target dialect from input text leveraging our novel multi-dialect
phoneme-level BERT. We conduct multi-dialect TTS experiments and evaluate the
effectiveness of our model by comparing it with a baseline derived from
conventional dialect TTS methods. The results show that our model improves the
dialectal naturalness of synthetic speech in CD-TTS.

摘要：我們探討跨方言文字轉語音 (CD-TTS)，這項任務用於合成學習者在非母語方言中的聲音，特別是在音高重音語言中。CD-TTS 對於開發能與不同地區的人自然溝通的語音代理非常重要。我們提出一個新穎的 TTS 模型，包含三個子模組，以在這個任務中表現出色。我們首先訓練一個主幹 TTS 模型，從一個受語音中由參考編碼器提取的音素級重音潛在變數 (ALV) 條件化的文字中合成方言語音。然後，我們訓練一個 ALV 預測器，利用我們新穎的多方言音素級 BERT 從輸入文字中預測適合目標方言的 ALV。我們進行多方言 TTS 實驗，並透過將我們的模型與源自傳統方言 TTS 方法的基準進行比較，來評估其有效性。結果顯示我們的模型改善了 CD-TTS 中合成語音的方言自然性。

##### **Propaganda to Hate: A Multimodal Analysis of Arabic Memes with Multi-Agent LLMs**
2409.07246v1 by Firoj Alam, Md. Rafiul Biswas, Uzair Shah, Wajdi Zaghouani, Georgios Mikros

In the past decade, social media platforms have been used for information
dissemination and consumption. While a major portion of the content is posted
to promote citizen journalism and public awareness, some content is posted to
mislead users. Among different content types such as text, images, and videos,
memes (text overlaid on images) are particularly prevalent and can serve as
powerful vehicles for propaganda, hate, and humor. In the current literature,
there have been efforts to individually detect such content in memes. However,
the study of their intersection is very limited. In this study, we explore the
intersection between propaganda and hate in memes using a multi-agent LLM-based
approach. We extend the propagandistic meme dataset with coarse and
fine-grained hate labels. Our finding suggests that there is an association
between propaganda and hate in memes. We provide detailed experimental results
that can serve as a baseline for future studies. We will make the experimental
resources publicly available to the community.

摘要：在過去十年中，社群媒體平台已用於資訊傳播和消費。雖然大部分內容是為了推廣公民新聞和公眾意識而發布，但有些內容是為了誤導使用者而發布。在文字、圖片和影片等不同內容類型中，迷因（疊加在圖片上的文字）特別普遍，可用作宣傳、仇恨和幽默的有力媒介。在目前的文獻中，已嘗試個別偵測迷因中的此類內容。然而，對其交集的研究非常有限。在本研究中，我們使用基於多代理 LLM 的方法探討迷因中宣傳和仇恨之間的交集。我們使用粗略和細粒度的仇恨標籤擴充宣傳迷因資料集。我們的研究結果表明，迷因中的宣傳和仇恨之間存在關聯。我們提供了詳細的實驗結果，可作為未來研究的基準。我們將使實驗資源公開提供給社群。

##### **Behavioral Cloning Models Reality Check for Autonomous Driving**
2409.07218v1 by Mustafa Yildirim, Barkin Dagda, Vinal Asodia, Saber Fallah

How effective are recent advancements in autonomous vehicle perception
systems when applied to real-world autonomous vehicle control? While numerous
vision-based autonomous vehicle systems have been trained and evaluated in
simulated environments, there is a notable lack of real-world validation for
these systems. This paper addresses this gap by presenting the real-world
validation of state-of-the-art perception systems that utilize Behavior Cloning
(BC) for lateral control, processing raw image data to predict steering
commands. The dataset was collected using a scaled research vehicle and tested
on various track setups. Experimental results demonstrate that these methods
predict steering angles with low error margins in real-time, indicating
promising potential for real-world applications.

摘要：最新進步的自動駕駛感知系統應用於實際的自動駕駛控制時，有多大的效能？雖然許多基於視覺的自動駕駛系統已在模擬環境中受訓和評估，但這些系統顯著缺乏實際驗證。本文透過呈現利用行為複製 (BC) 進行側向控制、處理原始影像資料以預測轉向指令的最新感知系統的實際驗證，來探討這個差距。資料集使用縮放的研究車輛收集，並在各種軌道設置中進行測試。實驗結果證明，這些方法在實際時間中以低誤差範圍預測轉向角度，顯示出在實際應用中的潛在前景。

##### **Heterogeneity-Aware Coordination for Federated Learning via Stitching Pre-trained blocks**
2409.07202v1 by Shichen Zhan, Yebo Wu, Chunlin Tian, Yan Zhao, Li Li

Federated learning (FL) coordinates multiple devices to collaboratively train
a shared model while preserving data privacy. However, large memory footprint
and high energy consumption during the training process excludes the low-end
devices from contributing to the global model with their own data, which
severely deteriorates the model performance in real-world scenarios. In this
paper, we propose FedStitch, a hierarchical coordination framework for
heterogeneous federated learning with pre-trained blocks. Unlike the
traditional approaches that train the global model from scratch, for a new
task, FedStitch composes the global model via stitching pre-trained blocks.
Specifically, each participating client selects the most suitable block based
on their local data from the candidate pool composed of blocks from pre-trained
models. The server then aggregates the optimal block for stitching. This
process iterates until a new stitched network is generated. Except for the new
training paradigm, FedStitch consists of the following three core components:
1) an RL-weighted aggregator, 2) a search space optimizer deployed on the
server side, and 3) a local energy optimizer deployed on each participating
client. The RL-weighted aggregator helps to select the right block in the
non-IID scenario, while the search space optimizer continuously reduces the
size of the candidate block pool during stitching. Meanwhile, the local energy
optimizer is designed to minimize energy consumption of each client while
guaranteeing the overall training progress. The results demonstrate that
compared to existing approaches, FedStitch improves the model accuracy up to
20.93%. At the same time, it achieves up to 8.12% speedup, reduces the memory
footprint up to 79.5%, and achieves 89.41% energy saving at most during the
learning procedure.

摘要：<paragraph>联邦学习 (FL) 协调多个设备共同训练一个共享模型，同时保护数据隐私。然而，在训练过程中巨大的内存占用和高能耗使得低端设备无法用自己的数据为全局模型做出贡献，这严重降低了模型在实际场景中的性能。在本文中，我们提出了 FedStitch，一个用于异构联邦学习的分层协调框架，其中包含预训练块。与从头开始训练全局模型的传统方法不同，对于一项新任务，FedStitch 通过拼接预训练块来组合全局模型。具体来说，每个参与的客户端根据其本地数据从由预训练模型中的块组成的候选池中选择最合适的块。然后服务器聚合最优块以进行拼接。此过程会迭代，直到生成一个新的拼接网络。除了新的训练范例，FedStitch 包含以下三个核心组件：1) 一个 RL 加权聚合器，2) 部署在服务器端的搜索空间优化器，以及 3) 部署在每个参与客户端上的本地能量优化器。RL 加权聚合器有助于在非 IID 场景中选择正确的块，而搜索空间优化器在拼接期间不断减小候选块池的大小。同时，本地能量优化器旨在最大程度地减少每个客户端的能耗，同时保证整体训练进度。结果表明，与现有方法相比，FedStitch 将模型准确度提高了 20.93%。同时，它实现了高达 8.12% 的加速，将内存占用减少了 79.5%，并在学习过程中最多实现了 89.41% 的节能。</paragraph>

##### **ThermalGaussian: Thermal 3D Gaussian Splatting**
2409.07200v1 by Rongfeng Lu, Hangyu Chen, Zunjie Zhu, Yuhang Qin, Ming Lu, Le Zhang, Chenggang Yan, Anke Xue

Thermography is especially valuable for the military and other users of
surveillance cameras. Some recent methods based on Neural Radiance Fields
(NeRF) are proposed to reconstruct the thermal scenes in 3D from a set of
thermal and RGB images. However, unlike NeRF, 3D Gaussian splatting (3DGS)
prevails due to its rapid training and real-time rendering. In this work, we
propose ThermalGaussian, the first thermal 3DGS approach capable of rendering
high-quality images in RGB and thermal modalities. We first calibrate the RGB
camera and the thermal camera to ensure that both modalities are accurately
aligned. Subsequently, we use the registered images to learn the multimodal 3D
Gaussians. To prevent the overfitting of any single modality, we introduce
several multimodal regularization constraints. We also develop smoothing
constraints tailored to the physical characteristics of the thermal modality.
Besides, we contribute a real-world dataset named RGBT-Scenes, captured by a
hand-hold thermal-infrared camera, facilitating future research on thermal
scene reconstruction. We conduct comprehensive experiments to show that
ThermalGaussian achieves photorealistic rendering of thermal images and
improves the rendering quality of RGB images. With the proposed multimodal
regularization constraints, we also reduced the model's storage cost by 90\%.
The code and dataset will be released.

摘要：熱像儀對於軍方和其他監控相機使用者來說特別有價值。一些基於神經輻照場 (NeRF) 的最新方法被提議用於從一組熱和 RGB 影像中 3D 重建熱場景。然而，與 NeRF 不同，3D 高斯潑濺 (3DGS) 由於其快速的訓練和即時渲染而盛行。在這項工作中，我們提出 ThermalGaussian，這是第一個能夠以 RGB 和熱模式渲染高品質影像的熱 3DGS 方法。我們首先校正 RGB 相機和熱相機，以確保兩種模式都準確對齊。隨後，我們使用已配準的影像來學習多模態 3D 高斯。為了防止任何單一模式過度擬合，我們引入了多個多模態正則化約束。我們還開發了針對熱模式的物理特性的平滑約束。此外，我們貢獻了一個名為 RGBT-Scenes 的真實世界資料集，它是由手持熱紅外線相機所擷取，有助於促進未來對熱場景重建的研究。我們進行了全面的實驗，以證明 ThermalGaussian 可實現熱影像的寫實渲染，並提升 RGB 影像的渲染品質。有了所提出的多模態正則化約束，我們還將模型的儲存成本降低了 90%。程式碼和資料集將會釋出。

##### **A Perspective on AI-Guided Molecular Simulations in VR: Exploring Strategies for Imitation Learning in Hyperdimensional Molecular Systems**
2409.07189v1 by Mohamed Dhouioui, Jonathan Barnoud, Rhoslyn Roebuck Williams, Harry J. Stroud, Phil Bates, David R. Glowacki

Molecular dynamics simulations are a crucial computational tool for
researchers to understand and engineer molecular structure and function in
areas such as drug discovery, protein engineering, and material design. Despite
their utility, MD simulations are expensive, owing to the high dimensionality
of molecular systems. Interactive molecular dynamics in virtual reality
(iMD-VR) has recently been developed as a 'human-in-the-loop' strategy, which
leverages high-performance computing to accelerate the researcher's ability to
solve the hyperdimensional sampling problem. By providing an immersive 3D
environment that enables visualization and manipulation of real-time molecular
motion, iMD-VR enables researchers and students to efficiently and intuitively
explore and navigate these complex, high-dimensional systems. iMD-VR platforms
offer a unique opportunity to quickly generate rich datasets that capture human
experts' spatial insight regarding molecular structure and function. This paper
explores the possibility of employing user-generated iMD-VR datasets to train
AI agents via imitation learning (IL). IL is an important technique in robotics
that enables agents to mimic complex behaviors from expert demonstrations, thus
circumventing the need for explicit programming or intricate reward design. We
review the utilization of IL for manipulation tasks in robotics and discuss how
iMD-VR recordings could be used to train IL models for solving specific
molecular 'tasks'. We then investigate how such approaches could be applied to
the data captured from iMD-VR recordings. Finally, we outline the future
research directions and potential challenges of using AI agents to augment
human expertise to efficiently navigate conformational spaces, highlighting how
this approach could provide valuable insight across domains such as materials
science, protein engineering, and computer-aided drug design.

摘要：分子動力學模擬是研究人員了解和設計分子結構和功能的重要計算工具，應用於藥物發現、蛋白質工程和材料設計等領域。儘管實用，但由於分子系統的高維度，MD 模擬成本昂貴。虛擬現實中的互動式分子動力學 (iMD-VR) 最近被開發為「人機協作」策略，它利用高效能運算加速研究人員解決超維取樣問題的能力。通過提供一個身臨其境的 3D 環境，可以視覺化和操作實時分子運動，iMD-VR 使研究人員和學生能夠有效且直觀地探索和導航這些複雜的高維系統。iMD-VR 平台提供了一個獨特的機會，可以快速生成豐富的數據集，捕捉人類專家對分子結構和功能的空間見解。本文探討了利用使用者產生的 iMD-VR 數據集通過模仿學習 (IL) 訓練 AI 代理的可能性。IL 是機器人技術中的一項重要技術，它使代理能夠模仿專家示範中的複雜行為，從而避免了對明確程式設計或複雜獎勵設計的需求。我們回顧了 IL 在機器人操作任務中的應用，並討論了如何使用 iMD-VR 記錄來訓練 IL 模型以解決具體的分子「任務」。然後我們探討如何將這種方法應用於從 iMD-VR 記錄中獲取的數據。最後，我們概述了未來研究方向和使用 AI 代理來擴充人類專業知識以有效導航構象空間的潛在挑戰，強調這種方法如何能在材料科學、蛋白質工程和電腦輔助藥物設計等領域提供有價值的見解。

##### **Enhancing Angular Resolution via Directionality Encoding and Geometric Constraints in Brain Diffusion Tensor Imaging**
2409.07186v1 by Sheng Chen, Zihao Tang, Mariano Cabezas, Xinyi Wang, Arkiev D'Souza, Michael Barnett, Fernando Calamante, Weidong Cai, Chenyu Wang

Diffusion-weighted imaging (DWI) is a type of Magnetic Resonance Imaging
(MRI) technique sensitised to the diffusivity of water molecules, offering the
capability to inspect tissue microstructures and is the only in-vivo method to
reconstruct white matter fiber tracts non-invasively. The DWI signal can be
analysed with the diffusion tensor imaging (DTI) model to estimate the
directionality of water diffusion within voxels. Several scalar metrics,
including axial diffusivity (AD), mean diffusivity (MD), radial diffusivity
(RD), and fractional anisotropy (FA), can be further derived from DTI to
quantitatively summarise the microstructural integrity of brain tissue. These
scalar metrics have played an important role in understanding the organisation
and health of brain tissue at a microscopic level in clinical studies. However,
reliable DTI metrics rely on DWI acquisitions with high gradient directions,
which often go beyond the commonly used clinical protocols. To enhance the
utility of clinically acquired DWI and save scanning time for robust DTI
analysis, this work proposes DirGeo-DTI, a deep learning-based method to
estimate reliable DTI metrics even from a set of DWIs acquired with the minimum
theoretical number (6) of gradient directions. DirGeo-DTI leverages directional
encoding and geometric constraints to facilitate the training process. Two
public DWI datasets were used for evaluation, demonstrating the effectiveness
of the proposed method. Extensive experimental results show that the proposed
method achieves the best performance compared to existing DTI enhancement
methods and potentially reveals further clinical insights with routine clinical
DWI scans.

摘要：擴散加權影像（DWI）是一種磁振造影（MRI）技術，對水分子擴散敏感，能檢測組織微結構，是唯一非侵入性重建白質纖維束的體內方法。DWI 訊號可用擴散張量影像（DTI）模型分析，以估計體素內水擴散的方向性。從 DTI 可進一步衍生出數個標量量測，包括軸向擴散率（AD）、平均擴散率（MD）、徑向擴散率（RD）和分數各向異性（FA），以量化總結腦組織的微結構完整性。這些標量量測在臨床研究中對於了解腦組織在微觀層面的組織和健康扮演重要角色。然而，可靠的 DTI 量測仰賴具有高梯度方向的 DWI 擷取，這通常超出臨床上常用的協定。為了提升臨床擷取 DWI 的效用，並為穩健的 DTI 分析節省掃描時間，本研究提出 DirGeo-DTI，一種基於深度學習的方法，即使從具備最小理論數量（6）的梯度方向擷取的 DWI 組也能估計可靠的 DTI 量測。DirGeo-DTI 利用方向編碼和幾何約束來促進訓練過程。使用兩個公開的 DWI 資料集進行評估，證明了所提出方法的有效性。廣泛的實驗結果顯示，與現有的 DTI 增強方法相比，所提出的方法取得最佳效能，並潛在揭露例行臨床 DWI 掃描的進一步臨床見解。

##### **Linear Time Complexity Conformers with SummaryMixing for Streaming Speech Recognition**
2409.07165v1 by Titouan Parcollet, Rogier van Dalen, Shucong Zhang, Sourav Batthacharya

Automatic speech recognition (ASR) with an encoder equipped with
self-attention, whether streaming or non-streaming, takes quadratic time in the
length of the speech utterance. This slows down training and decoding, increase
their cost, and limit the deployment of the ASR in constrained devices.
SummaryMixing is a promising linear-time complexity alternative to
self-attention for non-streaming speech recognition that, for the first time,
preserves or outperforms the accuracy of self-attention models. Unfortunately,
the original definition of SummaryMixing is not suited to streaming speech
recognition. Hence, this work extends SummaryMixing to a Conformer Transducer
that works in both a streaming and an offline mode. It shows that this new
linear-time complexity speech encoder outperforms self-attention in both
scenarios while requiring less compute and memory during training and decoding.

摘要：配備自我注意力的編碼器自動語音辨識 (ASR)，無論是串流或非串流，在語音語句的長度上會花費二次方時間。這會減慢訓練和解碼速度，增加其成本，並限制在受限裝置中部署 ASR。
摘要混合是一種有前途的線性時間複雜度替代方案，可取代非串流語音辨識的自我注意力，它首次保留或超越了自我注意力模型的準確度。不幸的是，SummaryMixing 的原始定義並不適合串流語音辨識。因此，這項工作將 SummaryMixing 延伸到一個在串流和離線模式下都能運作的 Conformer Transducer。它顯示出這種新的線性時間複雜度語音編碼器在兩種情況下都優於自我注意力，同時在訓練和解碼期間需要更少的運算和記憶體。

##### **A Fine-grained Sentiment Analysis of App Reviews using Large Language Models: An Evaluation Study**
2409.07162v1 by Faiz Ali Shah, Ahmed Sabir, Rajesh Sharma

Analyzing user reviews for sentiment towards app features can provide
valuable insights into users' perceptions of app functionality and their
evolving needs. Given the volume of user reviews received daily, an automated
mechanism to generate feature-level sentiment summaries of user reviews is
needed. Recent advances in Large Language Models (LLMs) such as ChatGPT have
shown impressive performance on several new tasks without updating the model's
parameters i.e. using zero or a few labeled examples. Despite these
advancements, LLMs' capabilities to perform feature-specific sentiment analysis
of user reviews remain unexplored. This study compares the performance of
state-of-the-art LLMs, including GPT-4, ChatGPT, and LLama-2-chat variants, for
extracting app features and associated sentiments under 0-shot, 1-shot, and
5-shot scenarios. Results indicate the best-performing GPT-4 model outperforms
rule-based approaches by 23.6% in f1-score with zero-shot feature extraction;
5-shot further improving it by 6%. GPT-4 achieves a 74% f1-score for predicting
positive sentiment towards correctly predicted app features, with 5-shot
enhancing it by 7%. Our study suggests that LLM models are promising for
generating feature-specific sentiment summaries of user reviews.

摘要：分析使用者評論以了解應用程式功能的觀感，可提供有價值的見解，了解使用者對應用程式功能的看法和他們不斷變化的需求。鑑於每天收到的使用者評論數量龐大，需要一種自動化機制來產生使用者評論的功能層級觀感摘要。大型語言模型 (LLM) 的最新進展，例如 ChatGPT，已在多項新任務中展現令人印象深刻的效能，而無需更新模型的參數，即使用零個或幾個標記範例。儘管有這些進展，LLM 執行使用者評論的功能特定觀感分析的能力仍未被探索。本研究比較了最先進的 LLM 的效能，包括 GPT-4、ChatGPT 和 LLama-2-chat 變體，用於在 0 次嘗試、1 次嘗試和 5 次嘗試的情況下擷取應用程式功能和關聯觀感。結果表明，效能最佳的 GPT-4 模型在零次嘗試功能擷取中，f1 分數比基於規則的方法高出 23.6%；5 次嘗試進一步提高了 6%。GPT-4 在預測正確預測的應用程式功能的正面觀感方面達到 74% 的 f1 分數，5 次嘗試將其提高了 7%。我們的研究表明，LLM 模型有望產生使用者評論的功能特定觀感摘要。

##### **Recurrent Aggregators in Neural Algorithmic Reasoning**
2409.07154v1 by Kaijia Xu, Petar Veličković

Neural algorithmic reasoning (NAR) is an emerging field that seeks to design
neural networks that mimic classical algorithmic computations. Today, graph
neural networks (GNNs) are widely used in neural algorithmic reasoners due to
their message passing framework and permutation equivariance. In this extended
abstract, we challenge this design choice, and replace the equivariant
aggregation function with a recurrent neural network. While seemingly
counter-intuitive, this approach has appropriate grounding when nodes have a
natural ordering -- and this is the case frequently in established reasoning
benchmarks like CLRS-30. Indeed, our recurrent NAR (RNAR) model performs very
strongly on such tasks, while handling many others gracefully. A notable
achievement of RNAR is its decisive state-of-the-art result on the Heapsort and
Quickselect tasks, both deemed as a significant challenge for contemporary
neural algorithmic reasoners -- especially the latter, where RNAR achieves a
mean micro-F1 score of 87%.

摘要：神經演算法推理 (NAR) 是一個新興領域，旨在設計模擬經典演算法運算的神經網路。現今，圖形神經網路 (GNN) 由於其訊息傳遞架構和排列等變性，廣泛用於神經演算法推理器中。在此延伸摘要中，我們挑戰此設計選擇，並以遞迴神經網路取代等變聚合函式。雖然看似反直覺，但當節點具有自然排序時，此方法有適當的基礎，而這在已建立的推理基準（如 CLRS-30）中很常見。事實上，我們的遞迴 NAR (RNAR) 模型在這些任務上表現得非常好，同時也能優雅地處理許多其他任務。RNAR 的一個顯著成就是其在堆排序和快速選擇任務上取得的決定性最新結果，這兩個任務都被視為當代神經演算法推理器的一項重大挑戰，特別是後者，RNAR 在此任務上取得了 87% 的平均微 F1 分數。

##### **Zero-Shot Text-to-Speech as Golden Speech Generator: A Systematic Framework and its Applicability in Automatic Pronunciation Assessment**
2409.07151v1 by Tien-Hong Lo, Meng-Ting Tsai, Berlin Chen

Second language (L2) learners can improve their pronunciation by imitating
golden speech, especially when the speech that aligns with their respective
speech characteristics. This study explores the hypothesis that
learner-specific golden speech generated with zero-shot text-to-speech (ZS-TTS)
techniques can be harnessed as an effective metric for measuring the
pronunciation proficiency of L2 learners. Building on this exploration, the
contributions of this study are at least two-fold: 1) design and development of
a systematic framework for assessing the ability of a synthesis model to
generate golden speech, and 2) in-depth investigations of the effectiveness of
using golden speech in automatic pronunciation assessment (APA). Comprehensive
experiments conducted on the L2-ARCTIC and Speechocean762 benchmark datasets
suggest that our proposed modeling can yield significant performance
improvements with respect to various assessment metrics in relation to some
prior arts. To our knowledge, this study is the first to explore the role of
golden speech in both ZS-TTS and APA, offering a promising regime for
computer-assisted pronunciation training (CAPT).

摘要：第二語言 (L2) 學習者能藉由模仿黃金語音來改善自己的發音，特別是當語音與其各自的語音特徵相符時。本研究探討以下假設：使用零次學習文字轉語音 (ZS-TTS) 技術產生的學習者特定黃金語音可以用作衡量 L2 學習者發音能力的有效指標。在此探索的基礎上，本研究的貢獻至少有兩方面：1) 設計並開發一個系統化架構，用於評估合成模型產生黃金語音的能力，以及 2) 深入探討在自動發音評估 (APA) 中使用黃金語音的有效性。在 L2-ARCTIC 和 Speechocean762 基準資料集上進行的綜合實驗表明，我們提出的建模可以針對一些先前的技術，在各種評估指標方面產生顯著的效能提升。據我們所知，本研究是第一個探討黃金語音在 ZS-TTS 和 APA 中的角色，為電腦輔助發音訓練 (CAPT) 提供了一個有前景的方案。

##### **Gated Slot Attention for Efficient Linear-Time Sequence Modeling**
2409.07146v1 by Yu Zhang, Songlin Yang, Ruijie Zhu, Yue Zhang, Leyang Cui, Yiqiao Wang, Bolun Wang, Freda Shi, Bailin Wang, Wei Bi, Peng Zhou, Guohong Fu

Linear attention Transformers and their gated variants, celebrated for
enabling parallel training and efficient recurrent inference, still fall short
in recall-intensive tasks compared to traditional Transformers and demand
significant resources for training from scratch. This paper introduces Gated
Slot Attention (GSA), which enhances Attention with Bounded-memory-Control
(ABC) by incorporating a gating mechanism inspired by Gated Linear Attention
(GLA). Essentially, GSA comprises a two-layer GLA linked via softmax, utilizing
context-aware memory reading and adaptive forgetting to improve memory capacity
while maintaining compact recurrent state size. This design greatly enhances
both training and inference efficiency through GLA's hardware-efficient
training algorithm and reduced state size. Additionally, retaining the softmax
operation is particularly beneficial in "finetuning pretrained Transformers to
RNNs" (T2R) settings, reducing the need for extensive training from scratch.
Extensive experiments confirm GSA's superior performance in scenarios requiring
in-context recall and in T2R settings.

摘要：線性注意力Transformer及其門控變體因能進行平行訓練和高效遞迴推論而受到讚譽，但與傳統Transformer相比，在需要召回的密集任務中仍有不足，且需要大量資源才能從頭開始訓練。本文介紹了門控時隙注意力 (GSA)，它通過結合受門控線性注意力 (GLA) 啟發的門控機制來增強帶邊界記憶控制 (ABC) 的注意力。實質上，GSA 包含一個通過 softmax 連結的兩層 GLA，利用上下文感知記憶體讀取和自適應遺忘來改善記憶體容量，同時保持緊湊的遞迴狀態大小。這種設計通過 GLA 的硬體高效訓練演算法和縮小的狀態大小，極大地提高了訓練和推論效率。此外，在「微調預訓練Transformer到 RNN」(T2R) 設定中保留 softmax 操作特別有益，減少了從頭開始進行大量訓練的需要。廣泛的實驗證實了 GSA 在需要上下文召回和 T2R 設定中的場景中的卓越效能。

##### **Leveraging Unstructured Text Data for Federated Instruction Tuning of Large Language Models**
2409.07136v1 by Rui Ye, Rui Ge, Yuchi Fengting, Jingyi Chai, Yanfeng Wang, Siheng Chen

Federated instruction tuning enables multiple clients to collaboratively
fine-tune a shared large language model (LLM) that can follow humans'
instructions without directly sharing raw data. However, existing literature
impractically requires that all the clients readily hold instruction-tuning
data (i.e., structured instruction-response pairs), which necessitates massive
human annotations since clients' data is usually unstructured text instead.
Addressing this, we propose a novel and flexible framework FedIT-U2S, which can
automatically transform unstructured corpus into structured data for federated
instruction tuning. FedIT-U2S consists two key steps: (1) few-shot
instruction-tuning data generation, where each unstructured data piece together
with several examples is combined to prompt an LLM in generating an
instruction-response pair. To further enhance the flexibility, a
retrieval-based example selection technique is proposed, where the examples are
automatically selected based on the relatedness between the client's data piece
and example pool, bypassing the need of determining examples in advance. (2) A
typical federated instruction tuning process based on the generated data.
Overall, FedIT-U2S can be applied to diverse scenarios as long as the client
holds valuable text corpus, broadening the application scope of federated
instruction tuning. We conduct a series of experiments on three domains
(medicine, knowledge, and math), showing that our proposed FedIT-U2S can
consistently and significantly brings improvement over the base LLM.

摘要：<paragraph>聯邦式教學調整讓多位客戶能夠協作微調一個共享的大語言模型 (LLM)，而這個模型可以遵循人類的指示，而無需直接分享原始資料。然而，現有的文獻不切實際地要求所有客戶都能隨時掌握教學調整資料（也就是結構化的教學-回應配對），這需要大量的標註，因為客戶的資料通常是沒有結構的文字。為了解決這個問題，我們提出了一個新穎且靈活的架構 FedIT-U2S，它可以自動將非結構化的語料庫轉換成結構化的資料，以進行聯邦式教學調整。FedIT-U2S 包含兩個關鍵步驟：(1) 少次教學調整資料產生，其中每個非結構化資料片段與幾個範例結合，以提示 LLM 產生一個教學-回應配對。為了進一步增強靈活性，提出了一種基於檢索的範例選擇技術，其中範例是根據客戶資料片段與範例池之間的關聯性自動選擇的，無需事先確定範例。(2) 基於產生資料的典型聯邦式教學調整程序。總的來說，只要客戶擁有有價值的文字語料庫，FedIT-U2S 就能應用於各種情況，擴展了聯邦式教學調整的應用範圍。我們在三個領域（醫學、知識和數學）進行了一系列實驗，結果顯示我們提出的 FedIT-U2S 能夠持續且顯著地改善基礎 LLM。</paragraph>

##### **LLM-based feature generation from text for interpretable machine learning**
2409.07132v1 by Vojtěch Balek, Lukáš Sýkora, Vilém Sklenák, Tomáš Kliegr

Existing text representations such as embeddings and bag-of-words are not
suitable for rule learning due to their high dimensionality and absent or
questionable feature-level interpretability. This article explores whether
large language models (LLMs) could address this by extracting a small number of
interpretable features from text. We demonstrate this process on two datasets
(CORD-19 and M17+) containing several thousand scientific articles from
multiple disciplines and a target being a proxy for research impact. An
evaluation based on testing for the statistically significant correlation with
research impact has shown that LLama 2-generated features are semantically
meaningful. We consequently used these generated features in text
classification to predict the binary target variable representing the citation
rate for the CORD-19 dataset and the ordinal 5-class target representing an
expert-awarded grade in the M17+ dataset. Machine-learning models trained on
the LLM-generated features provided similar predictive performance to the
state-of-the-art embedding model SciBERT for scientific text. The LLM used only
62 features compared to 768 features in SciBERT embeddings, and these features
were directly interpretable, corresponding to notions such as article
methodological rigor, novelty, or grammatical correctness. As the final step,
we extract a small number of well-interpretable action rules. Consistently
competitive results obtained with the same LLM feature set across both
thematically diverse datasets show that this approach generalizes across
domains.

摘要：現有的文本表示，例如嵌入和詞袋，由於其高維度和缺乏或有疑問的功能級別可解釋性，因此不適合規則學習。本文探討了大型語言模型 (LLM) 是否可以通過從文本中提取少數可解釋特徵來解決此問題。我們在兩個數據集（CORD-19 和 M17+）上展示了這個過程，這些數據集包含來自多個學科的數千篇科學文章，目標是作為研究影響力的代理。基於對與研究影響力具有統計顯著相關性的測試的評估表明，LLama 2 生成的特徵在語義上是有意義的。因此，我們在文本分類中使用了這些生成的特性來預測代表 CORD-19 數據集引文率的二元目標變量和代表 M17+ 數據集中專家評分的序數 5 類目標。在 LLM 生成的特徵上訓練的機器學習模型提供了與科學文本的最新嵌入模型 SciBERT 類似的預測性能。與 SciBERT 嵌入中的 768 個特徵相比，LLM 僅使用了 62 個特徵，並且這些特徵是直接可解釋的，對應於文章方法論嚴謹性、新穎性或語法正確性等概念。作為最後一步，我們提取了少數可很好解釋的動作規則。在兩個主題多樣化的數據集中使用相同的 LLM 特徵集獲得的持續競爭結果表明，這種方法可以推廣到各個領域。

##### **Reranking Laws for Language Generation: A Communication-Theoretic Perspective**
2409.07131v1 by António Farinhas, Haau-Sing Li, André F. T. Martins

To ensure large language models (LLMs) are used safely, one must reduce their
propensity to hallucinate or to generate unacceptable answers. A simple and
often used strategy is to first let the LLM generate multiple hypotheses and
then employ a reranker to choose the best one. In this paper, we draw a
parallel between this strategy and the use of redundancy to decrease the error
rate in noisy communication channels. We conceptualize the generator as a
sender transmitting multiple descriptions of a message through parallel noisy
channels. The receiver decodes the message by ranking the (potentially
corrupted) descriptions and selecting the one found to be most reliable. We
provide conditions under which this protocol is asymptotically error-free
(i.e., yields an acceptable answer almost surely) even in scenarios where the
reranker is imperfect (governed by Mallows or Zipf-Mandelbrot models) and the
channel distributions are statistically dependent. We use our framework to
obtain reranking laws which we validate empirically on two real-world tasks
using LLMs: text-to-code generation with DeepSeek-Coder 7B and machine
translation of medical data with TowerInstruct 13B.

摘要：為了確保大型語言模型 (LLM) 能夠安全使用，必須降低它們產生幻覺或產生不可接受答案的傾向。一種簡單且常用的策略是先讓 LLM 產生多個假設，然後使用重新排序器選擇最佳的一個。在本文中，我們將此策略與使用冗餘來降低噪聲通信通道中的錯誤率之間畫上平行線。我們將生成器概念化為一個發送者，通過並行的噪聲通道傳輸消息的多次描述。接收器通過對（潛在已損壞的）描述進行排序並選擇被認為最可靠的描述來解碼消息。我們提供了在這種協議在漸近意義上無錯誤的情況（即幾乎肯定會產生可接受的答案），即使在重新排序器不完美（受 Mallows 或 Zipf-Mandelbrot 模型支配）和通道分佈在統計上依賴的情況下也是如此。我們使用我們的框架來獲取重新排序定律，並使用 LLM 在兩個真實世界的任務中對其進行經驗驗證：使用 DeepSeek-Coder 7B 進行文本到代碼的生成，以及使用 TowerInstruct 13B 進行醫學數據的機器翻譯。

##### **Deep Learning Techniques for Hand Vein Biometrics: A Comprehensive Review**
2409.07128v1 by Mustapha Hemis, Hamza Kheddar, Sami Bourouis, Nasir Saleem

Biometric authentication has garnered significant attention as a secure and
efficient method of identity verification. Among the various modalities, hand
vein biometrics, including finger vein, palm vein, and dorsal hand vein
recognition, offer unique advantages due to their high accuracy, low
susceptibility to forgery, and non-intrusiveness. The vein patterns within the
hand are highly complex and distinct for each individual, making them an ideal
biometric identifier. Additionally, hand vein recognition is contactless,
enhancing user convenience and hygiene compared to other modalities such as
fingerprint or iris recognition. Furthermore, the veins are internally located,
rendering them less susceptible to damage or alteration, thus enhancing the
security and reliability of the biometric system. The combination of these
factors makes hand vein biometrics a highly effective and secure method for
identity verification. This review paper delves into the latest advancements in
deep learning techniques applied to finger vein, palm vein, and dorsal hand
vein recognition. It encompasses all essential fundamentals of hand vein
biometrics, summarizes publicly available datasets, and discusses
state-of-the-art metrics used for evaluating the three modes. Moreover, it
provides a comprehensive overview of suggested approaches for finger, palm,
dorsal, and multimodal vein techniques, offering insights into the best
performance achieved, data augmentation techniques, and effective transfer
learning methods, along with associated pretrained deep learning models.
Additionally, the review addresses research challenges faced and outlines
future directions and perspectives, encouraging researchers to enhance existing
methods and propose innovative techniques.

摘要：生物特徵驗證作為一種安全且有效的身分驗證方法，已獲得廣泛的關注。在各種方式中，手部靜脈生物特徵，包括手指靜脈、手掌靜脈和手背靜脈辨識，由於其高準確度、低偽造性以及非侵入性，提供獨特的優勢。手部靜脈圖案非常複雜，且因人而異，使其成為理想的生物特徵識別碼。此外，手部靜脈辨識是無接觸的，與指紋或虹膜辨識等其他方式相比，能提升使用者的便利性及衛生。再者，靜脈位於人體內部，使其不易受到損壞或改變，進而提升生物特徵系統的安全性及可靠性。這些因素結合起來，使得手部靜脈生物特徵成為一種高度有效且安全的驗證身分方法。這篇評論文章深入探討應用於手指靜脈、手掌靜脈和手背靜脈辨識的深度學習技術的最新進展。它包含了手部靜脈生物特徵的所有基本原理，彙整了公開可用的資料集，並討論了用於評估這三種模式的最新指標。此外，它全面概述了手指、手掌、手背和多模式靜脈技術的建議方法，提供對最佳效能、資料擴充技術和有效遷移學習方法的見解，以及相關的預訓練深度學習模型。此外，這篇評論探討了研究面臨的挑戰，並概述了未來的方向和觀點，鼓勵研究人員加強現有方法並提出創新的技術。

##### **DCMAC: Demand-aware Customized Multi-Agent Communication via Upper Bound Training**
2409.07127v1 by Dongkun Huo, Huateng Zhang, Yixue Hao, Yuanlin Ye, Long Hu, Rui Wang, Min Chen

Efficient communication can enhance the overall performance of collaborative
multi-agent reinforcement learning. A common approach is to share observations
through full communication, leading to significant communication overhead.
Existing work attempts to perceive the global state by conducting teammate
model based on local information. However, they ignore that the uncertainty
generated by prediction may lead to difficult training. To address this
problem, we propose a Demand-aware Customized Multi-Agent Communication (DCMAC)
protocol, which use an upper bound training to obtain the ideal policy. By
utilizing the demand parsing module, agent can interpret the gain of sending
local message on teammate, and generate customized messages via compute the
correlation between demands and local observation using cross-attention
mechanism. Moreover, our method can adapt to the communication resources of
agents and accelerate the training progress by appropriating the ideal policy
which is trained with joint observation. Experimental results reveal that DCMAC
significantly outperforms the baseline algorithms in both unconstrained and
communication constrained scenarios.

摘要：高效的溝通可以提升協作多智能體強化學習的整體表現。一種常見的方法是透過完全溝通來分享觀察，導致顯著的溝通負擔。現有研究嘗試根據局部資訊進行隊友建模，以感知全局狀態。然而，它們忽略了預測產生的不確定性可能導致訓練困難。為了解決這個問題，我們提出一個需求感知自訂多智能體溝通 (DCMAC) 協定，它使用上限訓練來取得理想策略。透過使用需求解析模組，智能體可以解釋發送局部訊息給隊友的收益，並透過使用跨注意力機制計算需求和局部觀察之間的關聯性來產生自訂訊息。此外，我們的模型可以適應智能體的溝通資源，並透過挪用使用聯合觀察訓練的理想策略來加速訓練進度。實驗結果顯示，DCMAC 在不受限和受限的溝通場景中都顯著優於基準演算法。

##### **Cross-Refine: Improving Natural Language Explanation Generation by Learning in Tandem**
2409.07123v1 by Qianli Wang, Tatiana Anikina, Nils Feldhus, Simon Ostermann, Sebastian Möller, Vera Schmitt

Natural language explanations (NLEs) are vital for elucidating the reasoning
behind large language model (LLM) decisions. Many techniques have been
developed to generate NLEs using LLMs. However, like humans, LLMs might not
always produce optimal NLEs on first attempt. Inspired by human learning
processes, we introduce Cross-Refine, which employs role modeling by deploying
two LLMs as generator and critic, respectively. The generator outputs a first
NLE and then refines this initial explanation using feedback and suggestions
provided by the critic. Cross-Refine does not require any supervised training
data or additional training. We validate Cross-Refine across three NLP tasks
using three state-of-the-art open-source LLMs through automatic and human
evaluation. We select Self-Refine (Madaan et al., 2023) as the baseline, which
only utilizes self-feedback to refine the explanations. Our findings from
automatic evaluation and a user study indicate that Cross-Refine outperforms
Self-Refine. Meanwhile, Cross-Refine can perform effectively with less powerful
LLMs, whereas Self-Refine only yields strong results with ChatGPT.
Additionally, we conduct an ablation study to assess the importance of feedback
and suggestions. Both of them play an important role in refining explanations.
We further evaluate Cross-Refine on a bilingual dataset in English and German.

摘要：自然語言解釋 (NLE) 對於闡明大型語言模型 (LLM) 決策背後的推理至關重要。已經開發出許多技術來使用 LLM 生成 NLE。然而，與人類一樣，LLM 可能並非總是能在首次嘗試時產生最佳的 NLE。受人類學習過程的啟發，我們引入了 Cross-Refine，它通過部署兩個 LLM 分別作為生成器和批評者來採用角色建模。生成器輸出第一個 NLE，然後使用批評者提供的反饋和建議來完善這個初始解釋。Cross-Refine 不需要任何監督式訓練資料或額外訓練。我們通過自動和人工評估，使用三個最先進的開源 LLM，在三個 NLP 任務中驗證了 Cross-Refine。我們選擇 Self-Refine (Madaan 等人，2023 年) 作為基線，它僅利用自我反饋來完善解釋。我們從自動評估和用戶研究中得出的結果表明，Cross-Refine 優於 Self-Refine。同時，Cross-Refine 可以有效地使用功能較弱的 LLM，而 Self-Refine 僅在 ChatGPT 中產生強勁的結果。此外，我們進行了一項消融研究來評估反饋和建議的重要性。它們都對完善解釋起著重要作用。我們進一步在英語和德語的雙語數據集上評估了 Cross-Refine。

##### **Attention Down-Sampling Transformer, Relative Ranking and Self-Consistency for Blind Image Quality Assessment**
2409.07115v1 by Mohammed Alsaafin, Musab Alsheikh, Saeed Anwar, Muhammad Usman

The no-reference image quality assessment is a challenging domain that
addresses estimating image quality without the original reference. We introduce
an improved mechanism to extract local and non-local information from images
via different transformer encoders and CNNs. The utilization of Transformer
encoders aims to mitigate locality bias and generate a non-local representation
by sequentially processing CNN features, which inherently capture local visual
structures. Establishing a stronger connection between subjective and objective
assessments is achieved through sorting within batches of images based on
relative distance information. A self-consistency approach to self-supervision
is presented, explicitly addressing the degradation of no-reference image
quality assessment (NR-IQA) models under equivariant transformations. Our
approach ensures model robustness by maintaining consistency between an image
and its horizontally flipped equivalent. Through empirical evaluation of five
popular image quality assessment datasets, the proposed model outperforms
alternative algorithms in the context of no-reference image quality assessment
datasets, especially on smaller datasets. Codes are available at
\href{https://github.com/mas94/ADTRS}{https://github.com/mas94/ADTRS}

摘要：無參考圖像品質評估是一個具有挑戰性的領域，它處理在沒有原始參考的情況下評估圖像品質。我們引入一個改良的機制，透過不同的 Transformer 編碼器和 CNN 從圖像中提取局部和非局部資訊。Transformer 編碼器的使用旨在減輕局部偏差，並透過循序處理 CNN 特徵來產生一個非局部表示，而 CNN 特徵本質上會擷取局部視覺結構。透過根據相對距離資訊在影像批次中進行排序，建立主觀和客觀評估之間更強的連結。提出了一個自一致的方法來自我監督，明確地解決了無參考圖像品質評估 (NR-IQA) 模型在等變換轉換下的退化問題。我們的做法透過維持影像及其水平翻轉等效物之間的一致性，確保模型的穩健性。透過對五個流行的影像品質評估資料集進行實證評估，所提出的模型在無參考影像品質評估資料集的背景下優於其他演算法，特別是在較小的資料集上。程式碼可在 \href{https://github.com/mas94/ADTRS}{https://github.com/mas94/ADTRS} 取得

##### **A Continual and Incremental Learning Approach for TinyML On-device Training Using Dataset Distillation and Model Size Adaption**
2409.07114v1 by Marcus Rüb, Philipp Tuchel, Axel Sikora, Daniel Mueller-Gritschneder

A new algorithm for incremental learning in the context of Tiny Machine
learning (TinyML) is presented, which is optimized for low-performance and
energy efficient embedded devices. TinyML is an emerging field that deploys
machine learning models on resource-constrained devices such as
microcontrollers, enabling intelligent applications like voice recognition,
anomaly detection, predictive maintenance, and sensor data processing in
environments where traditional machine learning models are not feasible. The
algorithm solve the challenge of catastrophic forgetting through the use of
knowledge distillation to create a small, distilled dataset. The novelty of the
method is that the size of the model can be adjusted dynamically, so that the
complexity of the model can be adapted to the requirements of the task. This
offers a solution for incremental learning in resource-constrained
environments, where both model size and computational efficiency are critical
factors. Results show that the proposed algorithm offers a promising approach
for TinyML incremental learning on embedded devices. The algorithm was tested
on five datasets including: CIFAR10, MNIST, CORE50, HAR, Speech Commands. The
findings indicated that, despite using only 43% of Floating Point Operations
(FLOPs) compared to a larger fixed model, the algorithm experienced a
negligible accuracy loss of just 1%. In addition, the presented method is
memory efficient. While state-of-the-art incremental learning is usually very
memory intensive, the method requires only 1% of the original data set.

摘要：<paragraph>提出了一種針對小型機器學習 (TinyML) 背景中的增量學習的新演算法，該演算法經過最佳化，適用於低效能且節能的嵌入式裝置。TinyML 是新興領域，它在受限資源的裝置上部署機器學習模型，例如微控制器，讓智慧型應用程式得以在傳統機器學習模型無法執行的環境中執行，例如語音辨識、異常偵測、預測性維護和感測器資料處理。該演算法透過使用知識萃取來建立小型萃取資料集，解決了災難性遺忘的挑戰。此方法的創新之處在於可以動態調整模型大小，以便模型複雜度可以適應任務需求。這為受限資源環境中的增量學習提供了解決方案，其中模型大小和運算效率都是關鍵因素。結果顯示，所提出的演算法為嵌入式裝置上的 TinyML 增量學習提供了有前途的方法。該演算法在五個資料集上進行了測試，包括：CIFAR10、MNIST、CORE50、HAR、Speech Commands。研究結果顯示，儘管與較大的固定模型相比，僅使用了 43% 的浮點運算 (FLOP)，但該演算法的精確度損失微乎其微，僅 1%。此外，所提出的方法具有記憶體效率。雖然最先進的增量學習通常非常耗費記憶體，但該方法僅需要 1% 的原始資料集。</paragraph>

##### **Redundancy-Aware Camera Selection for Indoor Scene Neural Rendering**
2409.07098v1 by Zehao Wang, Han Zhou, Matthew B. Blaschko, Tinne Tuytelaars, Minye Wu

Novel view synthesis of indoor scenes can be achieved by capturing a
monocular video sequence of the environment. However, redundant information
caused by artificial movements in the input video data reduces the efficiency
of scene modeling. In this work, we tackle this challenge from the perspective
of camera selection. We begin by constructing a similarity matrix that
incorporates both the spatial diversity of the cameras and the semantic
variation of the images. Based on this matrix, we use the Intra-List Diversity
(ILD) metric to assess camera redundancy, formulating the camera selection task
as an optimization problem. Then we apply a diversity-based sampling algorithm
to optimize the camera selection. We also develop a new dataset, IndoorTraj,
which includes long and complex camera movements captured by humans in virtual
indoor environments, closely mimicking real-world scenarios. Experimental
results demonstrate that our strategy outperforms other approaches under time
and memory constraints. Remarkably, our method achieves performance comparable
to models trained on the full dataset, while using only an average of 15% of
the frames and 75% of the allotted time.

摘要：室內場景的新穎視圖合成，可透過擷取環境的單眼影片序列來達成。然而，輸入影片資料中的人工動作所造成的冗餘資訊降低了場景建模的效率。在這項研究中，我們從相機選擇的角度來應對這項挑戰。我們首先建構一個相似矩陣，其中包含相機的空間多樣性和影像的語義變化。根據這個矩陣，我們使用 Intra-List Diversity (ILD) 指標來評估相機冗餘，將相機選擇任務制定為一個最佳化問題。接著，我們套用一個基於多樣性的取樣演算法來最佳化相機選擇。我們也開發了一個新的資料集 IndoorTraj，其中包含人類在虛擬室內環境中擷取的長而複雜的相機動作，非常接近真實世界的場景。實驗結果顯示，我們的策略在時間和記憶體限制下優於其他方法。值得注意的是，我們的模型在僅使用平均 15% 的影格和 75% 的分配時間的情況下，就能達到與在完整資料集上訓練的模型相當的效能。

##### **CWT-Net: Super-resolution of Histopathology Images Using a Cross-scale Wavelet-based Transformer**
2409.07092v1 by Feiyang Jia, Zhineng Chen, Ziying Song, Lin Liu, Caiyan Jia

Super-resolution (SR) aims to enhance the quality of low-resolution images
and has been widely applied in medical imaging. We found that the design
principles of most existing methods are influenced by SR tasks based on
real-world images and do not take into account the significance of the
multi-level structure in pathological images, even if they can achieve
respectable objective metric evaluations. In this work, we delve into two
super-resolution working paradigms and propose a novel network called CWT-Net,
which leverages cross-scale image wavelet transform and Transformer
architecture. Our network consists of two branches: one dedicated to learning
super-resolution and the other to high-frequency wavelet features. To generate
high-resolution histopathology images, the Transformer module shares and fuses
features from both branches at various stages. Notably, we have designed a
specialized wavelet reconstruction module to effectively enhance the wavelet
domain features and enable the network to operate in different modes, allowing
for the introduction of additional relevant information from cross-scale
images. Our experimental results demonstrate that our model significantly
outperforms state-of-the-art methods in both performance and visualization
evaluations and can substantially boost the accuracy of image diagnostic
networks.

摘要：超解析度 (SR) 旨在提升低解析度影像的品質，並已廣泛應用於醫學影像。我們發現現有方法的大部分設計原則都受到基於真實影像的 SR 任務影響，而且即使它們能達到可觀的客觀指標評估，也不會考慮病理影像中多層級結構的重要性。在這項工作中，我們深入探討兩種超解析度工作範例，並提出一個名為 CWT-Net 的新型網路，它利用跨尺度影像小波轉換和 Transformer 架構。我們的網路包含兩個分支：一個專門用於學習超解析度，另一個則用於高頻小波特徵。為了產生高解析度組織病理學影像，Transformer 模組會在不同階段分享和融合來自兩個分支的特徵。值得注意的是，我們設計了一個專門的小波重建模組，以有效增強小波域特徵，並讓網路能夠在不同模式下運作，允許從跨尺度影像中引入其他相關資訊。我們的實驗結果證明，我們的模型在效能和視覺化評估方面都大幅優於現有技術，而且能大幅提升影像診斷網路的準確度。

##### **Ontology-Free General-Domain Knowledge Graph-to-Text Generation Dataset Synthesis using Large Language Model**
2409.07088v1 by Daehee Kim, Deokhyung Kang, Sangwon Ryu, Gary Geunbae Lee

Knowledge Graph-to-Text (G2T) generation involves verbalizing structured
knowledge graphs into natural language text. Recent advancements in Pretrained
Language Models (PLMs) have improved G2T performance, but their effectiveness
depends on datasets with precise graph-text alignment. However, the scarcity of
high-quality, general-domain G2T generation datasets restricts progress in the
general-domain G2T generation research. To address this issue, we introduce
Wikipedia Ontology-Free Graph-text dataset (WikiOFGraph), a new large-scale G2T
dataset generated using a novel method that leverages Large Language Model
(LLM) and Data-QuestEval. Our new dataset, which contains 5.85M general-domain
graph-text pairs, offers high graph-text consistency without relying on
external ontologies. Experimental results demonstrate that PLM fine-tuned on
WikiOFGraph outperforms those trained on other datasets across various
evaluation metrics. Our method proves to be a scalable and effective solution
for generating high-quality G2T data, significantly advancing the field of G2T
generation.

摘要：知識圖譜到文字 (G2T) 生成涉及將結構化知識圖譜表達為自然語言文字。預訓練語言模型 (PLM) 的最新進展改善了 G2T 的效能，但其有效性取決於具有精確圖形文字對齊的資料集。然而，高品質、一般領域 G2T 生成資料集的稀少性限制了一般領域 G2T 生成研究的進展。為了解決這個問題，我們引入了維基百科本体免費圖形文字資料集 (WikiOFGraph)，這是一個使用利用大型語言模型 (LLM) 和 Data-QuestEval 的新方法生成的新大型 G2T 資料集。我們的這個新資料集包含 585 萬個一般領域的圖形文字對，提供高圖形文字一致性，而不依賴於外部本体。實驗結果表明，在 WikiOFGraph 上微調的 PLM 在各種評估指標上優於在其他資料集上訓練的 PLM。我們的這個方法被證明是一個可擴充且有效的解決方案，用於生成高品質的 G2T 資料，顯著推動了 G2T 生成領域的發展。

##### **Understanding Knowledge Drift in LLMs through Misinformation**
2409.07085v1 by Alina Fastowski, Gjergji Kasneci

Large Language Models (LLMs) have revolutionized numerous applications,
making them an integral part of our digital ecosystem. However, their
reliability becomes critical, especially when these models are exposed to
misinformation. We primarily analyze the susceptibility of state-of-the-art
LLMs to factual inaccuracies when they encounter false information in a QnA
scenario, an issue that can lead to a phenomenon we refer to as *knowledge
drift*, which significantly undermines the trustworthiness of these models. We
evaluate the factuality and the uncertainty of the models' responses relying on
Entropy, Perplexity, and Token Probability metrics. Our experiments reveal that
an LLM's uncertainty can increase up to 56.6% when the question is answered
incorrectly due to the exposure to false information. At the same time,
repeated exposure to the same false information can decrease the models
uncertainty again (-52.8% w.r.t. the answers on the untainted prompts),
potentially manipulating the underlying model's beliefs and introducing a drift
from its original knowledge. These findings provide insights into LLMs'
robustness and vulnerability to adversarial inputs, paving the way for
developing more reliable LLM applications across various domains. The code is
available at https://github.com/afastowski/knowledge_drift.

摘要：大型語言模型 (LLM) 已徹底改變了許多應用程式，讓它們成為我們數位生態系中不可或缺的一部分。然而，它們的可靠性變得至關重要，尤其當這些模型接觸到錯誤資訊時。我們主要分析最先進的 LLM 在問答情境中接觸到錯誤資訊時對事實不正確的敏感性，這個問題可能會導致我們稱為「知識漂移」的現象，這會嚴重損害這些模型的可靠性。我們根據熵、困惑度和權杖機率指標評估模型回應的事實性和不確定性。我們的實驗顯示，當 LLM 因接觸到錯誤資訊而回答錯誤時，其不確定性可能會增加高達 56.6%。同時，重複接觸相同的錯誤資訊可能會再次降低模型的不確定性（相對於未受污染提示的答案 -52.8%），潛在地操縱底層模型的信念並導致其原始知識漂移。這些發現提供了對 LLM 對抗性輸入的穩健性和脆弱性的見解，為在各種領域開發更可靠的 LLM 應用程式鋪平了道路。程式碼可在 https://github.com/afastowski/knowledge_drift 取得。

##### **Multimodal Emotion Recognition with Vision-language Prompting and Modality Dropout**
2409.07078v1 by Anbin QI, Zhongliang Liu, Xinyong Zhou, Jinba Xiao, Fengrun Zhang, Qi Gan, Ming Tao, Gaozheng Zhang, Lu Zhang

In this paper, we present our solution for the Second Multimodal Emotion
Recognition Challenge Track 1(MER2024-SEMI). To enhance the accuracy and
generalization performance of emotion recognition, we propose several methods
for Multimodal Emotion Recognition. Firstly, we introduce EmoVCLIP, a model
fine-tuned based on CLIP using vision-language prompt learning, designed for
video-based emotion recognition tasks. By leveraging prompt learning on CLIP,
EmoVCLIP improves the performance of pre-trained CLIP on emotional videos.
Additionally, to address the issue of modality dependence in multimodal fusion,
we employ modality dropout for robust information fusion. Furthermore, to aid
Baichuan in better extracting emotional information, we suggest using GPT-4 as
the prompt for Baichuan. Lastly, we utilize a self-training strategy to
leverage unlabeled videos. In this process, we use unlabeled videos with
high-confidence pseudo-labels generated by our model and incorporate them into
the training set. Experimental results demonstrate that our model ranks 1st in
the MER2024-SEMI track, achieving an accuracy of 90.15% on the test set.

摘要：在本文中，我們提出我們對第二屆多模態情緒識別挑戰賽軌道 1 (MER2024-SEMI) 的解決方案。為了增強情緒識別的準確性和泛化效能，我們針對多模態情緒識別提出幾種方法。首先，我們介紹 EmoVCLIP，一種基於 CLIP 微調的模型，使用視覺語言提示學習，專為基於影片的情緒識別任務而設計。透過在 CLIP 上利用提示學習，EmoVCLIP 改善了預訓練 CLIP 在情緒影片上的效能。此外，為了解決多模態融合中的模態依賴性問題，我們採用模態中斷，以實現穩健的資訊融合。此外，為了協助百川更好地擷取情緒資訊，我們建議使用 GPT-4 作為百川的提示。最後，我們利用自訓練策略來利用未標記的影片。在此過程中，我們使用未標記的影片，其中包含由我們的模型產生的高可信度偽標籤，並將它們納入訓練組。實驗結果表明，我們的模型在 MER2024-SEMI 軌道中排名第一，在測試組上達到 90.15% 的準確度。

##### **Latent Space Interpretation for Stylistic Analysis and Explainable Authorship Attribution**
2409.07072v1 by Milad Alshomary, Narutatsu Ri, Marianna Apidianaki, Ajay Patel, Smaranda Muresan, Kathleen McKeown

Recent state-of-the-art authorship attribution methods learn authorship
representations of texts in a latent, non-interpretable space, hindering their
usability in real-world applications. Our work proposes a novel approach to
interpreting these learned embeddings by identifying representative points in
the latent space and utilizing LLMs to generate informative natural language
descriptions of the writing style of each point. We evaluate the alignment of
our interpretable space with the latent one and find that it achieves the best
prediction agreement compared to other baselines. Additionally, we conduct a
human evaluation to assess the quality of these style descriptions, validating
their utility as explanations for the latent space. Finally, we investigate
whether human performance on the challenging AA task improves when aided by our
system's explanations, finding an average improvement of around +20% in
accuracy.

摘要：最近最先進的作者身份歸因方法會學習文本的作者身份表示，這些表示法位於潛在的非可解釋空間中，這會阻礙它們在現實世界應用中的可用性。我們的研究提出了一種新穎的方法來詮釋這些學習到的嵌入，方法是識別潛在空間中的代表點，並利用 LLM 來產生每一點寫作風格的資訊性自然語言描述。我們評估了我們可解釋空間與潛在空間的一致性，發現與其他基準相比，它達到了最佳的預測一致性。此外，我們進行了人工評估以評估這些風格描述的品質，驗證它們作為潛在空間解釋的效用。最後，我們調查了在我們的系統解釋的輔助下，人類在具有挑戰性的 AA 任務上的表現是否有所改善，發現準確度平均提高了約 +20%。

##### **Automated Speaking Assessment of Conversation Tests with Novel Graph-based Modeling on Spoken Response Coherence**
2409.07064v1 by Jiun-Ting Li, Bi-Cheng Yan, Tien-Hong Lo, Yi-Cheng Wang, Yung-Chang Hsu, Berlin Chen

Automated speaking assessment in conversation tests (ASAC) aims to evaluate
the overall speaking proficiency of an L2 (second-language) speaker in a
setting where an interlocutor interacts with one or more candidates. Although
prior ASAC approaches have shown promising performance on their respective
datasets, there is still a dearth of research specifically focused on
incorporating the coherence of the logical flow within a conversation into the
grading model. To address this critical challenge, we propose a hierarchical
graph model that aptly incorporates both broad inter-response interactions
(e.g., discourse relations) and nuanced semantic information (e.g., semantic
words and speaker intents), which is subsequently fused with contextual
information for the final prediction. Extensive experimental results on the
NICT-JLE benchmark dataset suggest that our proposed modeling approach can
yield considerable improvements in prediction accuracy with respect to various
assessment metrics, as compared to some strong baselines. This also sheds light
on the importance of investigating coherence-related facets of spoken responses
in ASAC.

摘要：自動對話評量中的自動化口說評量（ASAC）旨在評估 L2（第二語言）話者在與一位或多位應試者互動的環境中，整體的口說能力。儘管先前的 ASAC 方法在其各自的資料集上展現出有前途的表現，但仍缺乏專注於將對話中邏輯流程的連貫性納入評分模型的研究。為了應對這項關鍵挑戰，我們提出了一個階層式圖形模型，它適當地結合了廣泛的回應間互動（例如：語篇關係）和細微的語義資訊（例如：語義字詞和說話者意圖），隨後與脈絡資訊融合，以進行最終預測。在 NICT-JLE 基準資料集上進行的廣泛實驗結果表明，與一些強大的基準線相比，我們提出的建模方法可以顯著提升預測準確度，特別是在各種評量指標方面。這也闡明了在 ASAC 中探討口語回應的連貫性相關面向的重要性。

##### **Native vs Non-Native Language Prompting: A Comparative Analysis**
2409.07054v1 by Mohamed Bayan Kmainasi, Rakif Khan, Ali Ezzat Shahroor, Boushra Bendou, Maram Hasanain, Firoj Alam

Large language models (LLMs) have shown remarkable abilities in different
fields, including standard Natural Language Processing (NLP) tasks. To elicit
knowledge from LLMs, prompts play a key role, consisting of natural language
instructions. Most open and closed source LLMs are trained on available labeled
and unlabeled resources--digital content such as text, images, audio, and
videos. Hence, these models have better knowledge for high-resourced languages
but struggle with low-resourced languages. Since prompts play a crucial role in
understanding their capabilities, the language used for prompts remains an
important research question. Although there has been significant research in
this area, it is still limited, and less has been explored for medium to
low-resourced languages. In this study, we investigate different prompting
strategies (native vs. non-native) on 11 different NLP tasks associated with 12
different Arabic datasets (9.7K data points). In total, we conducted 197
experiments involving 3 LLMs, 12 datasets, and 3 prompting strategies. Our
findings suggest that, on average, the non-native prompt performs the best,
followed by mixed and native prompts.

摘要：大型語言模型 (LLM) 在不同領域展現出非凡的能力，包括標準自然語言處理 (NLP) 任務。為了從 LLM 獲取知識，提示扮演了關鍵角色，包含自然語言指令。大多數開放和封閉原始碼 LLM 都在可用的標記和未標記資源（數位內容，例如文字、影像、音訊和影片）上進行訓練。因此，這些模型對於高資源語言有更好的知識，但在低資源語言上卻很吃力。由於提示在理解其功能中扮演了至關重要的角色，因此用於提示的語言仍然是一個重要的研究問題。儘管這個領域有許多重要的研究，但仍有限，而且對於中低資源語言的研究較少。在這項研究中，我們針對 12 個不同的阿拉伯語資料集（9.7K 資料點）的 11 個不同 NLP 任務研究不同的提示策略（母語 vs. 非母語）。總共進行了 197 次實驗，涉及 3 個 LLM、12 個資料集和 3 個提示策略。我們的研究結果表明，平均而言，非母語提示表現最佳，其次是混合和母語提示。

##### **Beyond IID: Optimizing Instruction Learning from the Perspective of Instruction Interaction and Dependency**
2409.07045v1 by Hanyu Zhao, Li Du, Yiming Ju, Chengwei Wu, Tengfei Pan

With the availability of various instruction datasets, a pivotal challenge is
how to effectively select and integrate these instructions to fine-tune large
language models (LLMs). Previous research mainly focuses on selecting
individual high-quality instructions. However, these works overlooked the joint
interactions and dependencies between different categories of instructions,
leading to suboptimal selection strategies. Moreover, the nature of these
interaction patterns remains largely unexplored, let alone optimize the
instruction set with regard to them. To fill these gaps, in this paper, we: (1)
systemically investigate interaction and dependency patterns between different
categories of instructions, (2) manage to optimize the instruction set
concerning the interaction patterns using a linear programming-based method,
and optimize the learning schema of SFT using an instruction dependency
taxonomy guided curriculum learning. Experimental results across different LLMs
demonstrate improved performance over strong baselines on widely adopted
benchmarks.

摘要：隨著各種指令資料集的出現，一個關鍵的挑戰在於如何有效地選擇和整合這些指令，以微調大型語言模型 (LLM)。先前的研究主要集中在選擇個別的高品質指令。然而，這些研究忽略了不同類別指令之間的聯合互動和依賴性，導致次佳的選擇策略。此外，這些互動模式的本質在很大程度上仍未被探索，更不用說根據它們來優化指令集。為了填補這些空白，在本文中，我們：(1) 系統性地研究不同類別指令之間的互動和依賴性模式，(2) 使用基於線性規劃的方法管理優化指令集，並使用指令依賴性分類指導課程學習來優化 SFT 的學習架構。跨不同 LLM 的實驗結果證明，在廣泛採用的基準上，相較於強大的基準線，我們的表現有所提升。

##### **Improving Anomalous Sound Detection via Low-Rank Adaptation Fine-Tuning of Pre-Trained Audio Models**
2409.07016v1 by Xinhu Zheng, Anbai Jiang, Bing Han, Yanmin Qian, Pingyi Fan, Jia Liu, Wei-Qiang Zhang

Anomalous Sound Detection (ASD) has gained significant interest through the
application of various Artificial Intelligence (AI) technologies in industrial
settings. Though possessing great potential, ASD systems can hardly be readily
deployed in real production sites due to the generalization problem, which is
primarily caused by the difficulty of data collection and the complexity of
environmental factors. This paper introduces a robust ASD model that leverages
audio pre-trained models. Specifically, we fine-tune these models using machine
operation data, employing SpecAug as a data augmentation strategy.
Additionally, we investigate the impact of utilizing Low-Rank Adaptation (LoRA)
tuning instead of full fine-tuning to address the problem of limited data for
fine-tuning. Our experiments on the DCASE2023 Task 2 dataset establish a new
benchmark of 77.75% on the evaluation set, with a significant improvement of
6.48% compared with previous state-of-the-art (SOTA) models, including top-tier
traditional convolutional networks and speech pre-trained models, which
demonstrates the effectiveness of audio pre-trained models with LoRA tuning.
Ablation studies are also conducted to showcase the efficacy of the proposed
scheme.

摘要：異常聲音偵測 (ASD) 在工業環境中透過應用各種人工智慧 (AI) 技術獲得了極大的關注。儘管擁有巨大的潛力，但 ASD 系統由於泛化問題而難以在實際生產現場中輕易部署，這主要是由於資料收集的困難性和環境因素的複雜性所造成。本文介紹了一個強健的 ASD 模型，它利用了音訊預訓練模型。具體來說，我們使用機器操作資料微調這些模型，採用 SpecAug 作為資料擴充策略。此外，我們研究了使用低秩適應 (LoRA) 微調來解決微調資料有限的問題，而不是進行完全微調。我們在 DCASE2023 任務 2 資料集上的實驗建立了一個新的基準，在評估集中獲得了 77.75%，與之前的最先進 (SOTA) 模型相比，有 6.48% 的顯著提升，其中包括頂級傳統卷積網路和語音預訓練模型，這證明了使用 LoRA 微調的音訊預訓練模型的有效性。消融研究也進行了，以展示所提出方案的功效。

##### **Towards Predicting Temporal Changes in a Patient's Chest X-ray Images based on Electronic Health Records**
2409.07012v1 by Daeun Kyung, Junu Kim, Tackeun Kim, Edward Choi

Chest X-ray imaging (CXR) is an important diagnostic tool used in hospitals
to assess patient conditions and monitor changes over time. Generative models,
specifically diffusion-based models, have shown promise in generating realistic
synthetic X-rays. However, these models mainly focus on conditional generation
using single-time-point data, i.e., typically CXRs taken at a specific time
with their corresponding reports, limiting their clinical utility, particularly
for capturing temporal changes. To address this limitation, we propose a novel
framework, EHRXDiff, which predicts future CXR images by integrating previous
CXRs with subsequent medical events, e.g., prescriptions, lab measures, etc.
Our framework dynamically tracks and predicts disease progression based on a
latent diffusion model, conditioned on the previous CXR image and a history of
medical events. We comprehensively evaluate the performance of our framework
across three key aspects, including clinical consistency, demographic
consistency, and visual realism. We demonstrate that our framework generates
high-quality, realistic future images that capture potential temporal changes,
suggesting its potential for further development as a clinical simulation tool.
This could offer valuable insights for patient monitoring and treatment
planning in the medical field.

摘要：胸部 X 光影像（CXR）是一種重要的診斷工具，用於醫院評估病患狀況並監控其隨著時間的變化。生成模型，特別是基於擴散的模型，已在生成逼真的合成 X 光影像方面展現出潛力。然而，這些模型主要專注於使用單一時間點資料進行條件生成，即通常在特定時間點拍攝的 CXR 及其對應報告，這限制了其臨床效用，特別是對於捕捉時間變化。為了解決此限制，我們提出了一個新的框架 EHRXDiff，它透過整合先前的 CXR 與後續的醫療事件（例如處方、實驗室檢測等）來預測未來的 CXR 影像。我們的框架基於潛在擴散模型動態追蹤並預測疾病進展，條件取決於先前的 CXR 影像和醫療事件的歷史記錄。我們全面評估了我們框架在三個關鍵方面的效能，包括臨床一致性、人口統計一致性和視覺逼真度。我們證明我們的框架生成了高品質、逼真的未來影像，捕捉了潛在的時間變化，這表明其進一步發展為臨床模擬工具的潛力。這可以為醫療領域的病患監控和治療規劃提供有價值的見解。

##### **What is the Right Notion of Distance between Predict-then-Optimize Tasks?**
2409.06997v1 by Paula Rodriguez-Diaz, Lingkai Kong, Kai Wang, David Alvarez-Melis, Milind Tambe

Comparing datasets is a fundamental task in machine learning, essential for
various learning paradigms; from evaluating train and test datasets for model
generalization to using dataset similarity for detecting data drift. While
traditional notions of dataset distances offer principled measures of
similarity, their utility has largely been assessed through prediction error
minimization. However, in Predict-then-Optimize (PtO) frameworks, where
predictions serve as inputs for downstream optimization tasks, model
performance is measured through decision regret minimization rather than
prediction error minimization. In this work, we (i) show that traditional
dataset distances, which rely solely on feature and label dimensions, lack
informativeness in the PtO context, and (ii) propose a new dataset distance
that incorporates the impacts of downstream decisions. Our results show that
this decision-aware dataset distance effectively captures adaptation success in
PtO contexts, providing a PtO adaptation bound in terms of dataset distance.
Empirically, we show that our proposed distance measure accurately predicts
transferability across three different PtO tasks from the literature.

摘要：比較資料集是機器學習中一項基礎任務，對於各種學習範例至關重要；從評估訓練和測試資料集以進行模型概化，到使用資料集相似性來偵測資料偏移。雖然傳統的資料集距離概念提供了原則性的相似性測量，但其效用已透過預測誤差最小化進行評估。然而，在預測後最佳化 (PtO) 架構中，預測作為下游最佳化任務的輸入，模型效能是透過決策後悔最小化而非預測誤差最小化來衡量的。在這項工作中，我們 (i) 顯示僅依賴特徵和標籤維度的傳統資料集距離，在 PtO 背景中缺乏資訊性，並 (ii) 提出一個新的資料集距離，納入下游決策的影響。我們的結果顯示，這個具決策意識的資料集距離有效捕捉 PtO 背景中的適應成功，在資料集距離方面提供 PtO 適應界限。根據經驗，我們顯示我們提出的距離測量準確預測了文獻中三個不同 PtO 任務的可轉移性。

##### **Large Language Models and the Extended Church-Turing Thesis**
2409.06978v1 by Jiří Wiedermann, Jan van Leeuwen

The Extended Church-Turing Thesis (ECTT) posits that all effective
information processing, including unbounded and non-uniform interactive
computations, can be described in terms of interactive Turing machines with
advice. Does this assertion also apply to the abilities of contemporary large
language models (LLMs)? From a broader perspective, this question calls for an
investigation of the computational power of LLMs by the classical means of
computability and computational complexity theory, especially the theory of
automata. Along these lines, we establish a number of fundamental results.
Firstly, we argue that any fixed (non-adaptive) LLM is computationally
equivalent to a, possibly very large, deterministic finite-state transducer.
This characterizes the base level of LLMs. We extend this to a key result
concerning the simulation of space-bounded Turing machines by LLMs. Secondly,
we show that lineages of evolving LLMs are computationally equivalent to
interactive Turing machines with advice. The latter finding confirms the
validity of the ECTT for lineages of LLMs. From a computability viewpoint, it
also suggests that lineages of LLMs possess super-Turing computational power.
Consequently, in our computational model knowledge generation is in general a
non-algorithmic process realized by lineages of LLMs. Finally, we discuss the
merits of our findings in the broader context of several related disciplines
and philosophies.

摘要：廣義的邱奇-圖靈論題 (ECTT) 假設所有有效的資訊處理，包括無界且非均勻的互動式運算，都可以用帶有建議的互動式圖靈機來描述。這個論斷也適用於當代大型語言模型 (LLM) 的能力嗎？從廣泛的角度來看，這個問題要求透過可計算性和計算複雜度理論的經典方法，特別是自動機理論，來探討 LLM 的計算能力。在這些方面，我們建立了許多基本結果。首先，我們主張任何固定的（非適應性）LLM 在計算上等同於一個可能非常大的確定有限狀態轉換器。這描述了 LLM 的基礎層級。我們將其延伸到一個關鍵結果，涉及 LLM 對空間受限圖靈機的模擬。其次，我們表明，演化 LLM 的譜系在計算上等同於帶有建議的互動式圖靈機。後者的發現證實了 ECTT 對 LLM 譜系的有效性。從可計算性的觀點來看，它也表明 LLM 的譜系具有超圖靈的計算能力。因此，在我們的計算模型中，知識生成通常是由 LLM 的譜系實現的非演算法過程。最後，我們在幾個相關學科和哲學的廣泛背景下討論了我們發現的優點。

##### **Policy Filtration in RLHF to Fine-Tune LLM for Code Generation**
2409.06957v1 by Wei Shen, Chuheng Zhang

Reinforcement learning from human feedback (RLHF) is one of the key
techniques that helps large language models (LLMs) to follow instructions and
provide helpful and harmless responses. While direct policy optimization
methods exist, state-of-the-art LLMs adopt RL-based methods (usually PPO) in
RLHF to train the policy to generate good responses guided by a reward model
learned from preference data. The main challenge of these methods is the
inaccuracy of the intermediate reward model, especially in code generation
tasks that require long and complex reasoning to score a response. We find that
the reliability of the reward model varies across responses assigned with
different rewards. This motivates us to filter the samples whose rewards may be
unreliable to improve signal-to-noise ratio during policy learning, resulting
in Policy Filtration for Proximal Policy Optimization (PF-PPO). To choose a
proper policy filtration strategy for a given reward model, the coefficient of
determination ($R^2$) between rewards and actual scores on filtered samples
serves as a good metrics and helps us find several promising strategies. We
provide extensive experiments to validate the effectiveness of PF-PPO in code
generation tasks, and find that some variants of PF-PPO are highly effective
and achieve new state-of-the-art performance across 7-billion-parameter models
on HumanEval, MBPP, and a new and more challenging LeetCode Contest benchmark.

摘要：人類回饋中的強化學習 (RLHF) 是幫助大型語言模型 (LLM) 遵循指示並提供有益且無害回應的主要技術之一。雖然存在直接策略最佳化方法，但最先進的 LLM 在 RLHF 中採用基於 RL 的方法（通常為 PPO），以訓練策略根據從偏好數據中學習到的獎勵模型來產生良好的回應。這些方法的主要挑戰是中間獎勵模型的不準確性，特別是在需要長時間且複雜的推理才能為回應評分的程式碼生成任務中。我們發現獎勵模型的可靠性因分配不同獎勵的回應而異。這促使我們過濾掉獎勵可能不可靠的樣本，以提高策略學習期間的信噪比，從而產生用於近端策略最佳化的策略過濾 (PF-PPO)。為了針對給定的獎勵模型選擇適當的策略過濾策略，過濾樣本上獎勵與實際分數之間的決定係數 ($R^2$) 可作為良好的指標，並幫助我們找到幾種有前途的策略。我們提供了大量的實驗來驗證 PF-PPO 在程式碼生成任務中的有效性，並發現 PF-PPO 的一些變體非常有效，並且在 HumanEval、MBPP 和一個新的、更具挑戰性的 LeetCode 競賽基準測試中，在 70 億個參數模型上實現了新的最先進效能。

##### **Neural Algorithmic Reasoning with Multiple Correct Solutions**
2409.06953v1 by Zeno Kujawa, John Poole, Dobrik Georgiev, Danilo Numeroso, Pietro Liò

Neural Algorithmic Reasoning (NAR) aims to optimize classical algorithms.
However, canonical implementations of NAR train neural networks to return only
a single solution, even when there are multiple correct solutions to a problem,
such as single-source shortest paths. For some applications, it is desirable to
recover more than one correct solution. To that end, we give the first method
for NAR with multiple solutions. We demonstrate our method on two classical
algorithms: Bellman-Ford (BF) and Depth-First Search (DFS), favouring deeper
insight into two algorithms over a broader survey of algorithms. This method
involves generating appropriate training data as well as sampling and
validating solutions from model output. Each step of our method, which can
serve as a framework for neural algorithmic reasoning beyond the tasks
presented in this paper, might be of independent interest to the field and our
results represent the first attempt at this task in the NAR literature.

摘要：神經演算法推理 (NAR) 的目標是最佳化傳統演算法。
然而，NAR 的典型實作訓練神經網路只回傳
單一解，即使問題有多個正確解，
例如單一來源最短路徑。對於某些應用，
取得多個正確解是可取的。為此，我們提供了
第一個具有多個解的 NAR 方法。我們在兩個經典
演算法上展示我們的演算法：貝爾曼-福特 (BF) 和深度優先搜尋 (DFS)，偏好深入
洞察兩種演算法，而不是廣泛的演算法調查。此方法
涉及產生適當的訓練資料以及從模型輸出中抽樣和
驗證解。我們的每個方法步驟，可以用作
神經演算法推理的框架，超越本文中提出的任務，
可能對該領域具有獨立的興趣，我們的
結果代表了 NAR 文獻中首次嘗試此任務。

##### **You Have Thirteen Hours in Which to Solve the Labyrinth: Enhancing AI Game Masters with Function Calling**
2409.06949v1 by Jaewoo Song, Andrew Zhu, Chris Callison-Burch

Developing a consistent and reliable AI game master for text-based games is a
challenging task due to the limitations of large language models (LLMs) and the
complexity of the game master's role. This paper presents a novel approach to
enhance AI game masters by leveraging function calling in the context of the
table-top role-playing game "Jim Henson's Labyrinth: The Adventure Game." Our
methodology involves integrating game-specific controls through functions,
which we show improves the narrative quality and state update consistency of
the AI game master. The experimental results, based on human evaluations and
unit tests, demonstrate the effectiveness of our approach in enhancing gameplay
experience and maintaining coherence with the game state. This work contributes
to the advancement of game AI and interactive storytelling, offering insights
into the design of more engaging and consistent AI-driven game masters.

摘要：開發一致且可靠的文字遊戲 AI 遊戲大師是一項艱鉅的任務，原因在於大型語言模型 (LLM) 的限制以及遊戲大師角色的複雜性。本文提出了一種新穎的方法來增強 AI 遊戲大師，方法是在桌上角色扮演遊戲「吉姆漢森的迷宮：冒險遊戲」的背景下利用函式呼叫。我們的做法包括透過函式整合特定於遊戲的控制，我們展示出這項做法改進了 AI 遊戲大師的敘事品質和狀態更新一致性。實驗結果基於人工評估和單元測試，證明了我們的方法在增強遊戲體驗和維持與遊戲狀態的一致性方面是有效的。這項工作對遊戲 AI 和互動式說故事的進步有貢獻，提供洞察力以設計更引人入勝且一致的 AI 驅動遊戲大師。

##### **FSMDet: Vision-guided feature diffusion for fully sparse 3D detector**
2409.06945v1 by Tianran Liu, Morteza Mousa Pasandi, Robert Laganiere

Fully sparse 3D detection has attracted an increasing interest in the recent
years. However, the sparsity of the features in these frameworks challenges the
generation of proposals because of the limited diffusion process. In addition,
the quest for efficiency has led to only few work on vision-assisted fully
sparse models. In this paper, we propose FSMDet (Fully Sparse Multi-modal
Detection), which use visual information to guide the LiDAR feature diffusion
process while still maintaining the efficiency of the pipeline. Specifically,
most of fully sparse works focus on complex customized center fusion
diffusion/regression operators. However, we observed that if the adequate
object completion is performed, even the simplest interpolation operator leads
to satisfactory results. Inspired by this observation, we split the
vision-guided diffusion process into two modules: a Shape Recover Layer
(SRLayer) and a Self Diffusion Layer (SDLayer). The former uses RGB information
to recover the shape of the visible part of an object, and the latter uses a
visual prior to further spread the features to the center region. Experiments
demonstrate that our approach successfully improves the performance of previous
fully sparse models that use LiDAR only and reaches SOTA performance in
multimodal models. At the same time, thanks to the sparse architecture, our
method can be up to 5 times more efficient than previous SOTA methods in the
inference process.

摘要：近年來，全稀疏 3D 檢測已引起越來越大的興趣。然而，這些架構中特徵的稀疏性由於擴散過程有限，對提案的生成提出了挑戰。此外，對效率的追求導致僅有少數關於視覺輔助全稀疏模型的研究。在本文中，我們提出了 FSMDet（全稀疏多模態檢測），它使用視覺資訊來引導 LiDAR 特徵擴散過程，同時仍保持管線的效率。具體來說，大多數全稀疏工作都專注於複雜的客製化中心融合擴散/迴歸運算子。然而，我們觀察到，如果執行適當的物件完成，即使是最簡單的插值運算子也會產生令人滿意的結果。受到此觀察結果的啟發，我們將視覺引導擴散過程分為兩個模組：形狀恢復層 (SRLayer) 和自擴散層 (SDLayer)。前者使用 RGB 資訊來恢復物件可見部分的形狀，而後者使用視覺先驗將特徵進一步擴散到中心區域。實驗證明，我們的做法成功地改進了先前僅使用 LiDAR 的全稀疏模型的效能，並在多模態模型中達到 SOTA 效能。同時，由於稀疏架構，我們的方法在推論過程中可以比先前的 SOTA 方法快達 5 倍。

##### **FreeRide: Harvesting Bubbles in Pipeline Parallelism**
2409.06941v1 by Jiashu Zhang, Zihan Pan, Molly, Xu, Khuzaima Daudjee, Sihang Liu

The occurrence of bubbles in pipeline parallelism is an inherent limitation
that can account for more than 40% of the large language model (LLM) training
time and is one of the main reasons for the underutilization of GPU resources
in LLM training. Harvesting these bubbles for GPU side tasks can increase
resource utilization and reduce training costs but comes with challenges.
First, because bubbles are discontinuous with various shapes, programming side
tasks becomes difficult while requiring excessive engineering effort. Second, a
side task can compete with pipeline training for GPU resources and incur
significant overhead. To address these challenges, we propose FreeRide, a
system designed to harvest bubbles in pipeline parallelism for side tasks.
FreeRide provides programmers with interfaces to implement side tasks easily,
manages bubbles and side tasks during pipeline training, and controls access to
GPU resources by side tasks to reduce overhead. We demonstrate that FreeRide
achieves 7.8% average cost savings with a negligible overhead of about 1% in
training LLMs while serving model training, graph analytics, and image
processing side tasks.

摘要：管線平行處理中發生氣泡是一個固有限制，可能佔大型語言模型 (LLM) 訓練時間的 40% 以上，並且是 LLM 訓練中 GPU 資源利用不足的主要原因之一。收集這些氣泡以進行 GPU 側面任務可以提高資源利用率並降低訓練成本，但會帶來挑戰。首先，由於氣泡是不連續的且形狀各異，因此編寫程式側面任務變得困難，同時需要過多的工程工作。其次，側面任務可能會與管線訓練競爭 GPU 資源，並造成顯著的開銷。為了應對這些挑戰，我們提出了 FreeRide，這是一個旨在收集管線平行處理中的氣泡以進行側面任務的系統。FreeRide 為程式設計師提供了輕鬆實作側面任務的介面，在管線訓練期間管理氣泡和側面任務，並控制側面任務對 GPU 資源的存取以減少開銷。我們證明 FreeRide 在訓練 LLM 時可節省 7.8% 的平均成本，同時在執行模型訓練、圖形分析和影像處理側面任務時，開銷可忽略不計，約為 1%。

##### **Intrapartum Ultrasound Image Segmentation of Pubic Symphysis and Fetal Head Using Dual Student-Teacher Framework with CNN-ViT Collaborative Learning**
2409.06928v1 by Jianmei Jiang, Huijin Wang, Jieyun Bai, Shun Long, Shuangping Chen, Victor M. Campello, Karim Lekadir

The segmentation of the pubic symphysis and fetal head (PSFH) constitutes a
pivotal step in monitoring labor progression and identifying potential delivery
complications. Despite the advances in deep learning, the lack of annotated
medical images hinders the training of segmentation. Traditional
semi-supervised learning approaches primarily utilize a unified network model
based on Convolutional Neural Networks (CNNs) and apply consistency
regularization to mitigate the reliance on extensive annotated data. However,
these methods often fall short in capturing the discriminative features of
unlabeled data and in delineating the long-range dependencies inherent in the
ambiguous boundaries of PSFH within ultrasound images. To address these
limitations, we introduce a novel framework, the Dual-Student and Teacher
Combining CNN and Transformer (DSTCT), which synergistically integrates the
capabilities of CNNs and Transformers. Our framework comprises a Vision
Transformer (ViT) as the teacher and two student mod ls one ViT and one CNN.
This dual-student setup enables mutual supervision through the generation of
both hard and soft pseudo-labels, with the consistency in their predictions
being refined by minimizing the classifier determinacy discrepancy. The teacher
model further reinforces learning within this architecture through the
imposition of consistency regularization constraints. To augment the
generalization abilities of our approach, we employ a blend of data and model
perturbation techniques. Comprehensive evaluations on the benchmark dataset of
the PSFH Segmentation Grand Challenge at MICCAI 2023 demonstrate our DSTCT
framework outperformed ten contemporary semi-supervised segmentation methods.
Code available at https://github.com/jjm1589/DSTCT.

摘要：恥骨聯合和胎頭（PSFH）的分割是監測產程進度和識別潛在分娩併發症的關鍵步驟。儘管深度學習取得進展，但標註醫學影像的缺乏阻礙了分割的訓練。傳統的半監督式學習方法主要利用基於卷積神經網路（CNN）的統一網路模型，並應用一致性正則化來減輕對大量標註數據的依賴。然而，這些方法通常無法捕捉未標註數據的區別性特徵，也無法描繪超音波影像中 PSFH 模糊邊界中固有的長程依賴性。為了解決這些限制，我們引入了一個新的框架，即雙學生和教師結合 CNN 和 Transformer（DSTCT），它協同整合了 CNN 和 Transformer 的功能。我們的框架包含一個視覺 Transformer（ViT）作為教師和兩個學生模型，一個 ViT 和一個 CNN。這種雙學生設置通過生成硬偽標籤和軟偽標籤實現相互監督，並通過最小化分類器確定性差異來優化其預測的一致性。教師模型通過施加一致性正則化約束進一步加強了此架構中的學習。為了增強我們方法的泛化能力，我們採用了數據和模型擾動技術的混合。在 MICCAI 2023 的 PSFH 分割大挑戰基準數據集上的綜合評估表明，我們的 DSTCT 框架優於十種當代半監督式分割方法。程式碼可在 https://github.com/jjm1589/DSTCT 取得。

##### **Representation Tuning**
2409.06927v1 by Christopher M. Ackerman

Activation engineering is becoming increasingly popular as a means of online
control of large language models (LLMs). In this work, I extend the idea of
active steering with vectors that represent a behavioral direction of interest
to tuning those vectors directly into the model, obviating the need for online
control. First, I identify activation vectors related to honesty in an
open-source LLM (Llama- 2-13b-chat). Next, I demonstrate that model output can
be made more or less honest by adding positive or negative multiples of these
vectors to residual stream activations during generation. Then, I show that a
similar effect can be achieved by fine-tuning the vectors directly into the
model, by use of a dual loss function based on the cosine similarity of
residual stream activations to the vectors combined with a standard token-based
loss ("representation tuning"). Finally, I compare the generations in response
to honesty-probing prompts from the resulting models to those from models
fine-tuned with a token-based loss alone, and to those from the untuned model
subjected to online steering. Overall, fine-tuning the vectors into the models
using the cosine similarity plus token loss showed a stronger effect than
online steering, and generalized better than using the standard loss,
suggesting the potential utility of this approach as a safety measure. Code and
data are available at https://github.com/cma1114/representation_tuning; tuned
models are available at https://huggingface.co/collections/cackerman/
representation-tuning-66da1e5ab41cd1b824687d9f.

摘要：激活工程正日益成为在线控制大型语言模型 (LLM) 的一种流行手段。在这项工作中，我将主动转向的想法扩展到使用表示感兴趣行为方向的向量，以直接将这些向量调整到模型中，从而避免了在线控制的需要。首先，我在开源 LLM（Llama-2-13b-chat）中识别了与诚实相关的激活向量。接下来，我演示了可以通过在生成过程中将这些向量的正倍数或负倍数添加到残差流激活中，使模型输出变得更加诚实或不那么诚实。然后，我展示了可以通过使用基于残差流激活与向量的余弦相似性的双重损失函数以及基于令牌的标准损失（“表示调整”）将向量直接微调到模型中来实现类似的效果。最后，我将响应诚实探测提示所生成的模型与仅使用基于令牌的损失进行微调的模型以及未调整的模型（经过在线转向）所生成的模型进行比较。总体而言，使用余弦相似度加上令牌损失将向量微调到模型中的效果比在线转向更强，并且比使用标准损失泛化得更好，这表明这种方法作为安全措施的潜在效用。代码和数据可在 https://github.com/cma1114/representation_tuning 获得；经过调整的模型可在 https://huggingface.co/collections/cackerman/representation-tuning-66da1e5ab41cd1b824687d9f 获得。

##### **Applied Federated Model Personalisation in the Industrial Domain: A Comparative Study**
2409.06904v1 by Ilias Siniosoglou, Vasileios Argyriou, George Fragulis, Panagiotis Fouliras, Georgios Th. Papadopoulos, Anastasios Lytos, Panagiotis Sarigiannidis

The time-consuming nature of training and deploying complicated Machine and
Deep Learning (DL) models for a variety of applications continues to pose
significant challenges in the field of Machine Learning (ML). These challenges
are particularly pronounced in the federated domain, where optimizing models
for individual nodes poses significant difficulty. Many methods have been
developed to tackle this problem, aiming to reduce training expenses and time
while maintaining efficient optimisation. Three suggested strategies to tackle
this challenge include Active Learning, Knowledge Distillation, and Local
Memorization. These methods enable the adoption of smaller models that require
fewer computational resources and allow for model personalization with local
insights, thereby improving the effectiveness of current models. The present
study delves into the fundamental principles of these three approaches and
proposes an advanced Federated Learning System that utilises different
Personalisation methods towards improving the accuracy of AI models and
enhancing user experience in real-time NG-IoT applications, investigating the
efficacy of these techniques in the local and federated domain. The results of
the original and optimised models are then compared in both local and federated
contexts using a comparison analysis. The post-analysis shows encouraging
outcomes when it comes to optimising and personalising the models with the
suggested techniques.

摘要：在机器学习（ML）领域中，训练和部署各种应用程序的复杂机器和深度学习（DL）模型耗时，这持续对该领域构成重大挑战。这些挑战在联邦领域中尤为明显，在该领域中，针对各个节点优化模型会造成重大困难。已经开发了许多方法来解决此问题，旨在减少训练开支和时间，同时保持有效的优化。解决此挑战的三种建议策略包括主动学习、知识蒸馏和本地记忆。这些方法能够采用需要较少计算资源的较小模型，并允许使用本地见解对模型进行个性化设置，从而提高当前模型的有效性。本研究深入探讨了这三种方法的基本原理，并提出了一个先进的联邦学习系统，该系统利用不同的个性化方法来提高人工智能模型的准确性，并增强实时 NG-IoT 应用程序中的用户体验，调查了这些技术在本地和联邦领域的功效。然后，使用比较分析在本地和联邦上下文中比较原始模型和优化模型的结果。事后分析显示，使用建议的技术对模型进行优化和个性化时，结果令人鼓舞。

##### **A Dataset for Evaluating LLM-based Evaluation Functions for Research Question Extraction Task**
2409.06883v1 by Yuya Fujisaki, Shiro Takagi, Hideki Asoh, Wataru Kumagai

The progress in text summarization techniques has been remarkable. However
the task of accurately extracting and summarizing necessary information from
highly specialized documents such as research papers has not been sufficiently
investigated. We are focusing on the task of extracting research questions (RQ)
from research papers and construct a new dataset consisting of machine learning
papers, RQ extracted from these papers by GPT-4, and human evaluations of the
extracted RQ from multiple perspectives. Using this dataset, we systematically
compared recently proposed LLM-based evaluation functions for summarizations,
and found that none of the functions showed sufficiently high correlations with
human evaluations. We expect our dataset provides a foundation for further
research on developing better evaluation functions tailored to the RQ
extraction task, and contribute to enhance the performance of the task. The
dataset is available at https://github.com/auto-res/PaperRQ-HumanAnno-Dataset.

摘要：文本摘要技術的進展十分顯著。然而，從高度專業化的文件（例如研究論文）中準確提取和摘要必要資訊的任務尚未得到充分研究。我們專注於從研究論文中提取研究問題 (RQ) 的任務，並構建一個新的資料集，其中包含機器學習論文、GPT-4 從這些論文中提取的 RQ，以及從多個角度對提取的 RQ 進行的人工評估。使用此資料集，我們系統地比較了最近提出的用於摘要的基於 LLM 的評估函數，並發現沒有任何函數顯示出與人工評估有足夠高的相關性。我們預計我們的資料集將為進一步研究開發針對 RQ 提取任務量身打造的更好評估函數奠定基礎，並有助於提高任務的性能。該資料集可在 https://github.com/auto-res/PaperRQ-HumanAnno-Dataset 取得。

##### **NSP: A Neuro-Symbolic Natural Language Navigational Planner**
2409.06859v1 by William English, Dominic Simon, Rickard Ewetz, Sumit Jha

Path planners that can interpret free-form natural language instructions hold
promise to automate a wide range of robotics applications. These planners
simplify user interactions and enable intuitive control over complex
semi-autonomous systems. While existing symbolic approaches offer guarantees on
the correctness and efficiency, they struggle to parse free-form natural
language inputs. Conversely, neural approaches based on pre-trained Large
Language Models (LLMs) can manage natural language inputs but lack performance
guarantees. In this paper, we propose a neuro-symbolic framework for path
planning from natural language inputs called NSP. The framework leverages the
neural reasoning abilities of LLMs to i) craft symbolic representations of the
environment and ii) a symbolic path planning algorithm. Next, a solution to the
path planning problem is obtained by executing the algorithm on the environment
representation. The framework uses a feedback loop from the symbolic execution
environment to the neural generation process to self-correct syntax errors and
satisfy execution time constraints. We evaluate our neuro-symbolic approach
using a benchmark suite with 1500 path-planning problems. The experimental
evaluation shows that our neuro-symbolic approach produces 90.1% valid paths
that are on average 19-77% shorter than state-of-the-art neural approaches.

摘要：能夠解讀自由形式自然語言指令的路徑規劃器，有望自動化各種機器人應用程式。這些規劃器簡化了使用者互動，並能直覺地控制複雜的半自主系統。現有的符號方法雖然保證了正確性和效率，但在解析自由形式的自然語言輸入時卻有困難。相反地，基於預先訓練的大語言模型 (LLM) 的神經方法可以處理自然語言輸入，但缺乏效能保證。在本文中，我們提出了一個名為 NSP 的神經符號框架，用於從自然語言輸入進行路徑規劃。該框架利用 LLM 的神經推理能力來 i) 建構環境的符號表示，以及 ii) 一個符號路徑規劃演算法。接著，透過在環境表示上執行演算法，得到路徑規劃問題的解法。該框架使用從符號執行環境到神經生成過程的回饋迴路，以自行修正語法錯誤並滿足執行時間限制。我們使用包含 1500 個路徑規劃問題的基準測試套件，來評估我們的神經符號方法。實驗評估顯示，我們的神經符號方法產生了 90.1% 有效路徑，平均比最先進的神經方法短 19-77%。

##### **What is the Role of Small Models in the LLM Era: A Survey**
2409.06857v2 by Lihu Chen, Gaël Varoquaux

Large Language Models (LLMs) have made significant progress in advancing
artificial general intelligence (AGI), leading to the development of
increasingly large models such as GPT-4 and LLaMA-405B. However, scaling up
model sizes results in exponentially higher computational costs and energy
consumption, making these models impractical for academic researchers and
businesses with limited resources. At the same time, Small Models (SMs) are
frequently used in practical settings, although their significance is currently
underestimated. This raises important questions about the role of small models
in the era of LLMs, a topic that has received limited attention in prior
research. In this work, we systematically examine the relationship between LLMs
and SMs from two key perspectives: Collaboration and Competition. We hope this
survey provides valuable insights for practitioners, fostering a deeper
understanding of the contribution of small models and promoting more efficient
use of computational resources. The code is available at
https://github.com/tigerchen52/role_of_small_models

摘要：大型語言模型 (LLM) 在促進人工通用智能 (AGI) 方面取得了重大進展，導致開發出越來越大的模型，例如 GPT-4 和 LLaMA-405B。然而，擴大模型規模會導致計算成本和能源消耗呈指數級增長，這使得這些模型對於資源有限的學術研究人員和企業來說不切實際。與此同時，小型模型 (SM) 經常在實際環境中使用，儘管它們的重要性目前被低估了。這引發了關於 LLM 時代小型模型作用的重要問題，這個話題在先前的研究中受到的關注有限。在這項工作中，我們從協作和競爭這兩個關鍵角度系統地探討了 LLM 和 SM 之間的關係。我們希望這項調查能為實務工作者提供有價值的見解，促進對小型模型貢獻的更深入理解，並促進更有效率地使用計算資源。程式碼可在 https://github.com/tigerchen52/role_of_small_models 獲得

##### **LIME-M: Less Is More for Evaluation of MLLMs**
2409.06851v1 by Kang Zhu, Qianbo Zang, Shian Jia, Siwei Wu, Feiteng Fang, Yizhi Li, Shuyue Guo, Tianyu Zheng, Bo Li, Haoning Wu, Xingwei Qu, Jian Yang, Zachary Liu, Xiang Yue, J. H. Liu, Chenghua Lin, Min Yang, Shiwen Ni, Wenhao Huang, Ge Zhang

With the remarkable success achieved by Multimodal Large Language Models
(MLLMs), numerous benchmarks have been designed to assess MLLMs' ability to
guide their development in image perception tasks (e.g., image captioning and
visual question answering). However, the existence of numerous benchmarks
results in a substantial computational burden when evaluating model performance
across all of them. Moreover, these benchmarks contain many overly simple
problems or challenging samples, which do not effectively differentiate the
capabilities among various MLLMs. To address these challenges, we propose a
pipeline to process the existing benchmarks, which consists of two modules: (1)
Semi-Automated Screening Process and (2) Eliminating Answer Leakage. The
Semi-Automated Screening Process filters out samples that cannot distinguish
the model's capabilities by synthesizing various MLLMs and manually evaluating
them. The Eliminate Answer Leakage module filters samples whose answers can be
inferred without images. Finally, we curate the LIME-M: Less Is More for
Evaluation of Multimodal LLMs, a lightweight Multimodal benchmark that can more
effectively evaluate the performance of different models. Our experiments
demonstrate that: LIME-M can better distinguish the performance of different
MLLMs with fewer samples (24% of the original) and reduced time (23% of the
original); LIME-M eliminates answer leakage, focusing mainly on the information
within images; The current automatic metric (i.e., CIDEr) is insufficient for
evaluating MLLMs' capabilities in captioning. Moreover, removing the caption
task score when calculating the overall score provides a more accurate
reflection of model performance differences. All our codes and data are
released at https://github.com/kangreen0210/LIME-M.

摘要：<paragraph>隨著多模態大型語言模型 (MLLM) 取得顯著成功，已經設計了許多基準來評估 MLLM 在影像感知任務（例如影像標題和視覺問答）中引導其發展的能力。然而，眾多基準的存在會在評估所有模型效能時造成大量的運算負擔。此外，這些基準包含許多過於簡單的問題或具挑戰性的範例，無法有效區分各種 MLLM 的功能。為了應對這些挑戰，我們提出一個處理現有基準的管道，其中包含兩個模組：(1) 半自動篩選程序和 (2) 消除答案外洩。半自動篩選程序會篩選無法區分模型功能的範例，方法是合成各種 MLLM 並手動評估它們。消除答案外洩模組會篩選出答案可以在沒有影像的情況下推論出來的範例。最後，我們策劃了 LIME-M：更少即更多，用於評估多模態 LLM，這是一個輕量級的多模態基準，可以更有效地評估不同模型的效能。我們的實驗證明：LIME-M 可以用更少的範例（原始的 24%）和更短的時間（原始的 23%）來區分不同 MLLM 的效能；LIME-M 消除了答案外洩，主要關注影像中的資訊；目前的自動評量指標（即 CIDEr）不足以評估 MLLM 在標題中的功能。此外，在計算整體分數時移除標題任務分數，可以更準確地反映模型效能的差異。我們所有的程式碼和資料都發佈在 https://github.com/kangreen0210/LIME-M。</paragraph>

##### **PingPong: A Benchmark for Role-Playing Language Models with User Emulation and Multi-Model Evaluation**
2409.06820v1 by Ilya Gusev

We introduce a novel benchmark for evaluating the role-playing capabilities
of language models. Our approach leverages language models themselves to
emulate users in dynamic, multi-turn conversations and to assess the resulting
dialogues. The framework consists of three main components: a player model
assuming a specific character role, an interrogator model simulating user
behavior, and a judge model evaluating conversation quality. We conducted
experiments comparing automated evaluations with human annotations to validate
our approach, demonstrating strong correlations across multiple criteria. This
work provides a foundation for a robust and dynamic evaluation of model
capabilities in interactive scenarios.

摘要：我們引入了一個新基準，用於評估語言模型的角色扮演能力。我們的做法利用語言模型本身來模擬動態、多輪對話中的用戶，並評估產生的對話。此框架包含三個主要組成部分：假設特定角色角色的玩家模型、模擬用戶行為的詢問者模型，以及評估對話品質的評審模型。我們進行了實驗，比較自動評估與人類註解，以驗證我們的做法，證明了多項標準之間的強相關性。這項工作為在互動情境中對模型能力進行穩健且動態的評估奠定了基礎。

##### **Bifurcation Identification for Ultrasound-driven Robotic Cannulation**
2409.06817v1 by Cecilia G. Morales, Dhruv Srikanth, Jack H. Good, Keith A. Dufendach, Artur Dubrawski

In trauma and critical care settings, rapid and precise intravascular access
is key to patients' survival. Our research aims at ensuring this access, even
when skilled medical personnel are not readily available. Vessel bifurcations
are anatomical landmarks that can guide the safe placement of catheters or
needles during medical procedures. Although ultrasound is advantageous in
navigating anatomical landmarks in emergency scenarios due to its portability
and safety, to our knowledge no existing algorithm can autonomously extract
vessel bifurcations using ultrasound images. This is primarily due to the
limited availability of ground truth data, in particular, data from live
subjects, needed for training and validating reliable models. Researchers often
resort to using data from anatomical phantoms or simulations. We introduce
BIFURC, Bifurcation Identification for Ultrasound-driven Robot Cannulation, a
novel algorithm that identifies vessel bifurcations and provides optimal needle
insertion sites for an autonomous robotic cannulation system. BIFURC integrates
expert knowledge with deep learning techniques to efficiently detect vessel
bifurcations within the femoral region and can be trained on a limited amount
of in-vivo data. We evaluated our algorithm using a medical phantom as well as
real-world experiments involving live pigs. In all cases, BIFURC consistently
identified bifurcation points and needle insertion locations in alignment with
those identified by expert clinicians.

摘要：在創傷和重症照護環境中，快速且精確的血管內通路是患者存活的關鍵。我們的研究旨在確保這種通路，即使在熟練的醫療人員無法立即獲得的情況下。血管分叉是解剖標誌，可以指導在醫療過程中安全放置導管或針頭。儘管超音波由於其可攜性和安全性而在緊急情況下導航解剖標誌具有優勢，但據我們所知，沒有現有演算法可以使用超音波影像自動提取血管分叉。這主要是由於地面實況資料的可用性有限，特別是來自活體受試者的資料，而這對於訓練和驗證可靠模型是必需的。研究人員經常求助於使用解剖模型或模擬的資料。我們引入了 BIFURC，即超音波驅動機器人插管的分叉識別，這是一種新穎的演算法，可以識別血管分叉，並為自動機器人插管系統提供最佳針頭插入位置。BIFURC 將專家知識與深度學習技術相結合，以有效檢測股骨區域內的血管分叉，並且可以在有限的體內資料上進行訓練。我們使用醫用模型以及涉及活體豬的真實世界實驗評估了我們的演算法。在所有情況下，BIFURC 都一致地識別出分叉點和針頭插入位置，與專家臨床醫生識別的位置一致。

##### **Personalized Federated Learning Techniques: Empirical Analysis**
2409.06805v1 by Azal Ahmad Khan, Ahmad Faraz Khan, Haider Ali, Ali Anwar

Personalized Federated Learning (pFL) holds immense promise for tailoring
machine learning models to individual users while preserving data privacy.
However, achieving optimal performance in pFL often requires a careful
balancing act between memory overhead costs and model accuracy. This paper
delves into the trade-offs inherent in pFL, offering valuable insights for
selecting the right algorithms for diverse real-world scenarios. We empirically
evaluate ten prominent pFL techniques across various datasets and data splits,
uncovering significant differences in their performance. Our study reveals
interesting insights into how pFL methods that utilize personalized (local)
aggregation exhibit the fastest convergence due to their efficiency in
communication and computation. Conversely, fine-tuning methods face limitations
in handling data heterogeneity and potential adversarial attacks while
multi-objective learning methods achieve higher accuracy at the cost of
additional training and resource consumption. Our study emphasizes the critical
role of communication efficiency in scaling pFL, demonstrating how it can
significantly affect resource usage in real-world deployments.

摘要：個人化聯合學習 (pFL) 在維護資料隱私的同時，為客製化機器學習模型給個別使用者帶來極大的希望。然而，要達成 pFL 的最佳效能，通常需要在記憶體開銷成本和模型準確度之間取得仔細的平衡。本文深入探討 pFL 中固有的權衡取捨，為在各種實際場景中選擇正確的演算法提供寶貴的見解。我們根據各種資料集和資料分割，對十種傑出的 pFL 技術進行實證評估，揭露其效能的顯著差異。我們的研究揭露了有趣的見解，說明利用個人化 (局部) 聚合的 pFL 方法，由於其在通訊和運算方面的效率，展現出最快的收斂速度。相反地，微調方法在處理資料異質性和潛在對抗攻擊方面面臨限制，而多目標學習方法則以額外的訓練和資源消耗為代價，達到更高的準確度。我們的研究強調了通訊效率在擴充 pFL 中的關鍵角色，展示它如何在實際部署中顯著影響資源使用。

##### **Decomposition of surprisal: Unified computational model of ERP components in language processing**
2409.06803v1 by Jiaxuan Li, Richard Futrell

The functional interpretation of language-related ERP components has been a
central debate in psycholinguistics for decades. We advance an
information-theoretic model of human language processing in the brain in which
incoming linguistic input is processed at first shallowly and later with more
depth, with these two kinds of information processing corresponding to distinct
electroencephalographic signatures. Formally, we show that the information
content (surprisal) of a word in context can be decomposed into two quantities:
(A) heuristic surprise, which signals shallow processing difficulty for a word,
and corresponds with the N400 signal; and (B) discrepancy signal, which
reflects the discrepancy between shallow and deep interpretations, and
corresponds to the P600 signal. Both of these quantities can be estimated
straightforwardly using modern NLP models. We validate our theory by
successfully simulating ERP patterns elicited by a variety of linguistic
manipulations in previously-reported experimental data from six experiments,
with successful novel qualitative and quantitative predictions. Our theory is
compatible with traditional cognitive theories assuming a `good-enough'
heuristic interpretation stage, but with a precise information-theoretic
formulation. The model provides an information-theoretic model of ERP
components grounded on cognitive processes, and brings us closer to a
fully-specified neuro-computational model of language processing.

摘要：語言相關 ERP 成分的函數詮釋數十年來一直是心理語言學中的核心爭論。我們提出一個大腦中人類語言處理的資訊理論模型，其中輸入的語言輸入一開始會被淺層處理，之後會更深入地處理，這兩種資訊處理方式對應於不同的腦電圖特徵。正式地，我們證明了一個詞彙在脈絡中的資訊內容（驚訝度）可以分解成兩個量：（A）啟發式驚訝，它表示一個詞彙的淺層處理難度，並且與 N400 信號相符；以及（B）差異信號，它反映淺層和深層詮釋之間的差異，並且與 P600 信號相符。這兩個量都可以使用現代 NLP 模型直接估計。我們透過成功模擬先前報告的六個實驗中各種語言操作引發的 ERP 模式來驗證我們的理論，並成功進行新的定性和定量預測。我們的理論與傳統的認知理論相容，假設一個「足夠好」的啟發式詮釋階段，但有一個精確的資訊理論公式。這個模型提供了一個基於認知過程的 ERP 成分的資訊理論模型，並讓我們更接近一個完全指定的語言處理神經計算模型。

##### **Adaptive Meta-Domain Transfer Learning (AMDTL): A Novel Approach for Knowledge Transfer in AI**
2409.06800v1 by Michele Laurelli

This paper presents Adaptive Meta-Domain Transfer Learning (AMDTL), a novel
methodology that combines principles of meta-learning with domain-specific
adaptations to enhance the transferability of artificial intelligence models
across diverse and unknown domains. AMDTL aims to address the main challenges
of transfer learning, such as domain misalignment, negative transfer, and
catastrophic forgetting, through a hybrid framework that emphasizes both
generalization and contextual specialization. The framework integrates a
meta-learner trained on a diverse distribution of tasks, adversarial training
techniques for aligning domain feature distributions, and dynamic feature
regulation mechanisms based on contextual domain embeddings. Experimental
results on benchmark datasets demonstrate that AMDTL outperforms existing
transfer learning methodologies in terms of accuracy, adaptation efficiency,
and robustness. This research provides a solid theoretical and practical
foundation for the application of AMDTL in various fields, opening new
perspectives for the development of more adaptable and inclusive AI systems.

摘要：本文提出自適應元域轉移學習 (AMDTL)，這是一種結合元學習原理與特定領域適應的新方法，用於增強人工智慧模型在不同且未知領域間的可轉移性。AMDTL 旨在透過強調泛化和脈絡專業化的混合架構，來解決轉移學習的主要挑戰，例如領域錯位、負面轉移和災難性遺忘。此架構整合在不同任務分佈上訓練的元學習器、用於調整領域特徵分佈的對抗訓練技術，以及基於脈絡領域嵌入的動態特徵調節機制。基準資料集上的實驗結果證明，AMDTL 在準確度、適應效率和穩健性方面優於現有的轉移學習方法。此研究為 AMDTL 在各種領域的應用提供了穩固的理論和實務基礎，為開發更具適應性和包容性的 AI 系統開啟了新視野。

##### **Translating Step-by-Step: Decomposing the Translation Process for Improved Translation Quality of Long-Form Texts**
2409.06790v1 by Eleftheria Briakou, Jiaming Luo, Colin Cherry, Markus Freitag

In this paper we present a step-by-step approach to long-form text
translation, drawing on established processes in translation studies. Instead
of viewing machine translation as a single, monolithic task, we propose a
framework that engages language models in a multi-turn interaction,
encompassing pre-translation research, drafting, refining, and proofreading,
resulting in progressively improved translations. Extensive automatic
evaluations using Gemini 1.5 Pro across ten language pairs show that
translating step-by-step yields large translation quality improvements over
conventional zero-shot prompting approaches and earlier human-like baseline
strategies, resulting in state-of-the-art results on WMT2024.

摘要：在本文中，我們提出了一種分步式方法來進行長篇文本翻譯，並借鑑了翻譯研究中既定的流程。我們並非將機器翻譯視為一項單一、龐大的任務，而是提出了一個框架，讓語言模型參與多輪互動，包括譯前研究、起草、潤飾和校對，從而逐步改進翻譯。使用 Gemini 1.5 Pro 對十種語言對進行的廣泛自動評估表明，分步翻譯比傳統的零次提示方法和早期類人基線策略產生了巨大的翻譯質量改進，從而在 WMT2024 上取得了最先進的結果。

##### **Hint-AD: Holistically Aligned Interpretability in End-to-End Autonomous Driving**
2409.06702v1 by Kairui Ding, Boyuan Chen, Yuchen Su, Huan-ang Gao, Bu Jin, Chonghao Sima, Wuqiang Zhang, Xiaohui Li, Paul Barsch, Hongyang Li, Hao Zhao

End-to-end architectures in autonomous driving (AD) face a significant
challenge in interpretability, impeding human-AI trust. Human-friendly natural
language has been explored for tasks such as driving explanation and 3D
captioning. However, previous works primarily focused on the paradigm of
declarative interpretability, where the natural language interpretations are
not grounded in the intermediate outputs of AD systems, making the
interpretations only declarative. In contrast, aligned interpretability
establishes a connection between language and the intermediate outputs of AD
systems. Here we introduce Hint-AD, an integrated AD-language system that
generates language aligned with the holistic perception-prediction-planning
outputs of the AD model. By incorporating the intermediate outputs and a
holistic token mixer sub-network for effective feature adaptation, Hint-AD
achieves desirable accuracy, achieving state-of-the-art results in driving
language tasks including driving explanation, 3D dense captioning, and command
prediction. To facilitate further study on driving explanation task on
nuScenes, we also introduce a human-labeled dataset, Nu-X. Codes, dataset, and
models will be publicly available.

摘要：端對端自動駕駛 (AD) 架構在可解釋性上會面臨重大挑戰，阻礙人類對 AI 的信任。人類友善的自然語言已被探索用於駕駛解釋和 3D 字幕等任務。然而，先前的作品主要集中在宣告式可解釋性的範例上，其中自然語言解釋並未奠基於 AD 系統的中間輸出，使得解釋僅為宣告式。相反地，校準的可解釋性在語言和 AD 系統的中間輸出之間建立了連結。在此我們介紹 Hint-AD，一個整合的 AD 語言系統，用於產生與 AD 模型的整體感知預測規劃輸出校準的語言。透過結合中間輸出和一個用於有效特徵適應的整體標記混合器子網路，Hint-AD 達到了理想的準確度，在駕駛語言任務中取得了最先進的成果，包括駕駛解釋、3D 密集字幕和指令預測。為了促進在 nuScenes 上進一步研究駕駛解釋任務，我們還介紹了一個人類標記的資料集 Nu-X。程式碼、資料集和模型將公開提供。

##### **Modeling Image Tone Dichotomy with the Power Function**
2409.06764v1 by Axel Martinez, Gustavo Olague, Emilio Hernandez

The primary purpose of this paper is to present the concept of dichotomy in
image illumination modeling based on the power function. In particular, we
review several mathematical properties of the power function to identify the
limitations and propose a new mathematical model capable of abstracting
illumination dichotomy. The simplicity of the equation opens new avenues for
classical and modern image analysis and processing. The article provides
practical and illustrative image examples to explain how the new model manages
dichotomy in image perception. The article shows dichotomy image space as a
viable way to extract rich information from images despite poor contrast linked
to tone, lightness, and color perception. Moreover, a comparison with
state-of-the-art methods in image enhancement provides evidence of the method's
value.

摘要：本文的主要目的是基於冪函數，提出影像光照模型中的二分法概念。特別是，我們檢視冪函數的數學特性，以識別限制並提出一個新的數學模型，能夠抽象化光照二分法。此方程式的簡潔性為傳統和現代影像分析與處理開啟了新途徑。本文提供實用且說明性的影像範例，說明新模型如何管理影像感知中的二分法。本文展示二分法影像空間，作為從影像中擷取豐富資訊的可行方法，儘管對比度不佳，與色調、明度和色彩感知相關。此外，與影像增強中的最新方法比較，提供了此方法價值的證據。

##### **Geometric-Averaged Preference Optimization for Soft Preference Labels**
2409.06691v1 by Hiroki Furuta, Kuang-Huei Lee, Shixiang Shane Gu, Yutaka Matsuo, Aleksandra Faust, Heiga Zen, Izzeddin Gur

Many algorithms for aligning LLMs with human preferences assume that human
preferences are binary and deterministic. However, it is reasonable to think
that they can vary with different individuals, and thus should be
distributional to reflect the fine-grained relationship between the responses.
In this work, we introduce the distributional soft preference labels and
improve Direct Preference Optimization (DPO) with a weighted geometric average
of the LLM output likelihood in the loss function. In doing so, the scale of
learning loss is adjusted based on the soft labels, and the loss with equally
preferred responses would be close to zero. This simple modification can be
easily applied to any DPO family and helps the models escape from the
over-optimization and objective mismatch prior works suffer from. In our
experiments, we simulate the soft preference labels with AI feedback from LLMs
and demonstrate that geometric averaging consistently improves performance on
standard benchmarks for alignment research. In particular, we observe more
preferable responses than binary labels and significant improvements with data
where modestly-confident labels are in the majority.

摘要：許多用於將 LLM 與人類偏好對齊的演算法假設人類偏好是二元的且確定的。然而，可以合理地認為它們會因人而異，因此應以分佈式方式反映回應之間的細微關係。在這項工作中，我們引入了分佈式軟偏好標籤，並使用損失函數中 LLM 輸出似然加權幾何平均值改進了直接偏好最佳化 (DPO)。在這樣做的過程中，學習損失的規模會根據軟標籤進行調整，並且具有相同偏好回應的損失將接近於零。這個簡單的修改可以輕鬆應用於任何 DPO 家族，並幫助模型擺脫過度最佳化和目標不匹配的問題。在我們的實驗中，我們使用來自 LLM 的 AI 回饋模擬軟偏好標籤，並證明幾何平均始終改善對齊研究的標準基準的效能。特別是，我們觀察到比二元標籤更理想的回應，並且在中度自信標籤佔多數的資料中獲得顯著的改進。

##### **Benchmarking Sub-Genre Classification For Mainstage Dance Music**
2409.06690v1 by Hongzhi Shu, Xinglin Li, Hongyu Jiang, Minghao Fu, Xinyu Li

Music classification, with a wide range of applications, is one of the most
prominent tasks in music information retrieval. To address the absence of
comprehensive datasets and high-performing methods in the classification of
mainstage dance music, this work introduces a novel benchmark comprising a new
dataset and a baseline. Our dataset extends the number of sub-genres to cover
most recent mainstage live sets by top DJs worldwide in music festivals. A
continuous soft labeling approach is employed to account for tracks that span
multiple sub-genres, preserving the inherent sophistication. For the baseline,
we developed deep learning models that outperform current state-of-the-art
multimodel language models, which struggle to identify house music sub-genres,
emphasizing the need for specialized models trained on fine-grained datasets.
Our benchmark is applicable to serve for application scenarios such as music
recommendation, DJ set curation, and interactive multimedia, where we also
provide video demos. Our code is on
\url{https://anonymous.4open.science/r/Mainstage-EDM-Benchmark/}.

摘要：音樂分類擁有廣泛的應用，是音樂資訊檢索中最突出的任務之一。為了解決主流舞曲分類中缺乏全面資料集和高性能方法的問題，這項工作引入了一個包含新資料集和基準的新基準。我們的資料集擴展了子類型的數量，涵蓋了全球頂尖 DJ 在音樂節中的最新主流現場表演。採用連續軟標籤方法來考量橫跨多個子類型的曲目，保留其固有的複雜性。對於基準，我們開發了深度學習模型，其效能優於目前的最新多模式語言模型，而後者難以識別浩室音樂子類型，強調了針對細粒度資料集訓練的專門模型的必要性。我們的基準適用於音樂推薦、DJ 組合策展和互動多媒體等應用場景，我們也提供影片示範。我們的程式碼位於
\url{https://anonymous.4open.science/r/Mainstage-EDM-Benchmark/}。

##### **Generative Hierarchical Materials Search**
2409.06762v1 by Sherry Yang, Simon Batzner, Ruiqi Gao, Muratahan Aykol, Alexander L. Gaunt, Brendan McMorrow, Danilo J. Rezende, Dale Schuurmans, Igor Mordatch, Ekin D. Cubuk

Generative models trained at scale can now produce text, video, and more
recently, scientific data such as crystal structures. In applications of
generative approaches to materials science, and in particular to crystal
structures, the guidance from the domain expert in the form of high-level
instructions can be essential for an automated system to output candidate
crystals that are viable for downstream research. In this work, we formulate
end-to-end language-to-structure generation as a multi-objective optimization
problem, and propose Generative Hierarchical Materials Search (GenMS) for
controllable generation of crystal structures. GenMS consists of (1) a language
model that takes high-level natural language as input and generates
intermediate textual information about a crystal (e.g., chemical formulae), and
(2) a diffusion model that takes intermediate information as input and
generates low-level continuous value crystal structures. GenMS additionally
uses a graph neural network to predict properties (e.g., formation energy) from
the generated crystal structures. During inference, GenMS leverages all three
components to conduct a forward tree search over the space of possible
structures. Experiments show that GenMS outperforms other alternatives of
directly using language models to generate structures both in satisfying user
request and in generating low-energy structures. We confirm that GenMS is able
to generate common crystal structures such as double perovskites, or spinels,
solely from natural language input, and hence can form the foundation for more
complex structure generation in near future.

摘要：<paragraph>大規模訓練的生成模型現在可以產生文字、影片，以及最近的科學資料，例如晶體結構。在生成方法應用於材料科學，尤其是晶體結構時，領域專家的指導，以高階指令的形式，對於自動化系統輸出可行於下游研究的候選晶體至關重要。在這項工作中，我們將端對端語言到結構生成制定為多目標最佳化問題，並提出生成分層材料搜尋 (GenMS) 以控制晶體結構的生成。GenMS 包含 (1) 一個語言模型，它將高階自然語言作為輸入，並生成有關晶體的中間文字資訊（例如化學公式），以及 (2) 一個擴散模型，它將中間資訊作為輸入，並生成低階連續值晶體結構。GenMS 此外使用圖形神經網路從生成的晶體結構預測屬性（例如形成能）。在推理期間，GenMS 利用所有三個組件對可能的結構空間進行前向樹狀搜尋。實驗顯示，GenMS 優於直接使用語言模型來生成結構的其他替代方案，無論是在滿足使用者要求或生成低能結構方面。我們確認 GenMS 能夠僅從自然語言輸入生成常見的晶體結構，例如雙鈣鈦礦或尖晶石，因此可以在不久的將來形成更複雜結構生成的基礎。</paragraph>

##### **E2LLM: Encoder Elongated Large Language Models for Long-Context Understanding and Reasoning**
2409.06679v1 by Zihan Liao, Jun Wang, Hang Yu, Lingxiao Wei, Jianguo Li, Jun Wang, Wei Zhang

In the realm of Large Language Models (LLMs), the ability to process long
contexts is increasingly crucial for tasks such as multi-round dialogues, code
generation, and document summarization. This paper addresses the challenges of
enhancing the long-context performance, reducing computational complexity, and
leveraging pretrained models collectively termed the "impossible triangle." We
introduce E2LLM (Encoder Elongated Large Language Models), a novel approach
that effectively navigates this paradox. The method involves splitting long
contexts into chunks, compressing each into embedding vectors via a pretrained
text encoder, and utilizing an adapter to align these representations with a
decoder-only LLM. Two training objectives, focusing on reconstruction of the
encoder output and long-context instruction fine-tuning, are employed to
facilitate the understanding of soft prompts by the LLM. Experimental results
demonstrate that E2LLM achieves superior performance in long-context scenarios
while balancing efficiency, performance, and compatibility with pretrained
models. Our framework thus represents a significant advancement in the field,
contributing to effective long-text modeling.

摘要：在大語言模型 (LLM) 領域中，處理長語境的能耐對於多輪對話、程式碼產生和文件摘要等任務越來越重要。本文探討了增強長語境效能、降低計算複雜度和運用預訓練模型的挑戰，這些挑戰統稱為「不可能三角」。我們引入了 E2LLM（編碼器延伸大語言模型），這是一種新穎的方法，可以有效地解決這個悖論。此方法包括將長語境分割成區塊，透過預訓練文本編碼器將每個區塊壓縮成嵌入向量，並使用適配器將這些表示與僅解碼器 LLM 對齊。兩個訓練目標，專注於重建編碼器輸出和長語境指令微調，用於促進 LLM 對軟提示的理解。實驗結果表明，E2LLM 在長語境場景中實現了卓越的效能，同時平衡了效率、效能和與預訓練模型的相容性。因此，我們的架構代表了該領域的重大進展，有助於有效的長文本建模。

##### **Liability and Insurance for Catastrophic Losses: the Nuclear Power Precedent and Lessons for AI**
2409.06673v1 by Cristian Trout

As AI systems become more autonomous and capable, experts warn of them
potentially causing catastrophic losses. Drawing on the successful precedent
set by the nuclear power industry, this paper argues that developers of
frontier AI models should be assigned limited, strict, and exclusive third
party liability for harms resulting from Critical AI Occurrences (CAIOs) -
events that cause or easily could have caused catastrophic losses. Mandatory
insurance for CAIO liability is recommended to overcome developers'
judgment-proofness, mitigate winner's curse dynamics, and leverage insurers'
quasi-regulatory abilities. Based on theoretical arguments and observations
from the analogous nuclear power context, insurers are expected to engage in a
mix of causal risk-modeling, monitoring, lobbying for stricter regulation, and
providing loss prevention guidance in the context of insuring against
heavy-tail risks from AI. While not a substitute for regulation, clear
liability assignment and mandatory insurance can help efficiently allocate
resources to risk-modeling and safe design, facilitating future regulatory
efforts.

摘要：隨著 AI 系統變得更加自主且強大，專家警告它們可能會造成災難性的損失。本文借鑑核能產業設定的成功先例，主張前沿 AI 模型的開發者應承擔有限、嚴格且專屬的第三方責任，以彌補關鍵 AI 事件 (CAIO) 所造成的損害，而 CAIO 是造成或可能造成災難性損失的事件。建議強制為 CAIO 責任投保，以克服開發者的抗辯不能性，減輕贏家的詛咒動態，並利用保險人的準監管能力。根據理論論點和類比核能脈絡的觀察，保險人預計將從事因果風險建模、監控、遊說更嚴格的法規，以及在承保 AI 重尾風險的背景下提供損失預防指導。儘管無法取代法規，但明確的責任分配和強制保險有助於有效分配資源以進行風險建模和安全設計，促進未來的法規制定工作。

##### **LLaMA-Omni: Seamless Speech Interaction with Large Language Models**
2409.06666v1 by Qingkai Fang, Shoutao Guo, Yan Zhou, Zhengrui Ma, Shaolei Zhang, Yang Feng

Models like GPT-4o enable real-time interaction with large language models
(LLMs) through speech, significantly enhancing user experience compared to
traditional text-based interaction. However, there is still a lack of
exploration on how to build speech interaction models based on open-source
LLMs. To address this, we propose LLaMA-Omni, a novel model architecture
designed for low-latency and high-quality speech interaction with LLMs.
LLaMA-Omni integrates a pretrained speech encoder, a speech adaptor, an LLM,
and a streaming speech decoder. It eliminates the need for speech
transcription, and can simultaneously generate text and speech responses
directly from speech instructions with extremely low latency. We build our
model based on the latest Llama-3.1-8B-Instruct model. To align the model with
speech interaction scenarios, we construct a dataset named InstructS2S-200K,
which includes 200K speech instructions and corresponding speech responses.
Experimental results show that compared to previous speech-language models,
LLaMA-Omni provides better responses in both content and style, with a response
latency as low as 226ms. Additionally, training LLaMA-Omni takes less than 3
days on just 4 GPUs, paving the way for the efficient development of
speech-language models in the future.

摘要：LLaMA-Omni 等模型能透過語音與大型語言模型 (LLM) 進行即時互動，與傳統的文字互動相比，大幅提升使用者體驗。然而，關於如何根據開放原始碼 LLM 建構語音互動模型，目前仍缺乏探討。為了解決這個問題，我們提出 LLaMA-Omni，一種新穎的模型架構，專為與 LLM 進行低延遲、高品質的語音互動而設計。LLaMA-Omni 整合了預訓練的語音編碼器、語音適配器、LLM 和串流語音解碼器。它消除了語音轉錄的需要，並能直接從語音指令產生文字和語音回應，且延遲極低。我們根據最新的 Llama-3.1-8B-Instruct 模型建立我們的模型。為了讓模型與語音互動情境相符，我們建構了一個名為 InstructS2S-200K 的資料集，其中包含 200K 個語音指令和對應的語音回應。實驗結果顯示，與先前的語音語言模型相比，LLaMA-Omni 在內容和風格上提供了更好的回應，回應延遲低至 226 毫秒。此外，訓練 LLaMA-Omni 只需要不到 3 天的時間，而且僅使用 4 個 GPU，為未來語音語言模型的有效開發鋪路。

##### **Sortformer: Seamless Integration of Speaker Diarization and ASR by Bridging Timestamps and Tokens**
2409.06656v1 by Taejin Park, Ivan Medennikov, Kunal Dhawan, Weiqing Wang, He Huang, Nithin Rao Koluguri, Krishna C. Puvvada, Jagadeesh Balam, Boris Ginsburg

We propose Sortformer, a novel neural model for speaker diarization, trained
with unconventional objectives compared to existing end-to-end diarization
models. The permutation problem in speaker diarization has long been regarded
as a critical challenge. Most prior end-to-end diarization systems employ
permutation invariant loss (PIL), which optimizes for the permutation that
yields the lowest error. In contrast, we introduce Sort Loss, which enables a
diarization model to autonomously resolve permutation, with or without PIL. We
demonstrate that combining Sort Loss and PIL achieves performance competitive
with state-of-the-art end-to-end diarization models trained exclusively with
PIL. Crucially, we present a streamlined multispeaker ASR architecture that
leverages Sortformer as a speaker supervision model, embedding speaker label
estimation within the ASR encoder state using a sinusoidal kernel function.
This approach resolves the speaker permutation problem through sorted
objectives, effectively bridging speaker-label timestamps and speaker tokens.
In our experiments, we show that the proposed multispeaker ASR architecture,
enhanced with speaker supervision, improves performance via adapter techniques.
Code and trained models will be made publicly available via the NVIDIA NeMo
framework

摘要：我們提出 Sortformer，這是一個用於說話者分組的新型神經模型，它與現有的端到端分組模型相比，採用了非常規的目標進行訓練。說話者分組中的排列問題長期以來一直被認為是一個關鍵挑戰。大多數先前的端到端分組系統採用排列不變損失 (PIL)，它針對產生最低錯誤的排列進行優化。相比之下，我們引入了分類損失，它使分組模型能夠自主解決排列，無論是否使用 PIL。我們證明了將分類損失和 PIL 結合起來，可以實現與僅使用 PIL 訓練的最新端到端分組模型相媲美的效能。至關重要的是，我們提出了一個簡化的多說話者 ASR 架構，它利用 Sortformer 作為說話者監督模型，使用正弦核函數在 ASR 編碼器狀態中嵌入說話者標籤估計。這種方法通過分類目標解決了說話者排列問題，有效地橋接了說話者標籤時間戳和說話者標記。在我們的實驗中，我們展示了通過適配器技術增強的建議多說話者 ASR 架構通過適配器技術改善了效能。程式碼和訓練好的模型將通過 NVIDIA NeMo 框架公開。

##### **EyeCLIP: A visual-language foundation model for multi-modal ophthalmic image analysis**
2409.06644v2 by Danli Shi, Weiyi Zhang, Jiancheng Yang, Siyu Huang, Xiaolan Chen, Mayinuer Yusufu, Kai Jin, Shan Lin, Shunming Liu, Qing Zhang, Mingguang He

Early detection of eye diseases like glaucoma, macular degeneration, and
diabetic retinopathy is crucial for preventing vision loss. While artificial
intelligence (AI) foundation models hold significant promise for addressing
these challenges, existing ophthalmic foundation models primarily focus on a
single modality, whereas diagnosing eye diseases requires multiple modalities.
A critical yet often overlooked aspect is harnessing the multi-view information
across various modalities for the same patient. Additionally, due to the
long-tail nature of ophthalmic diseases, standard fully supervised or
unsupervised learning approaches often struggle. Therefore, it is essential to
integrate clinical text to capture a broader spectrum of diseases. We propose
EyeCLIP, a visual-language foundation model developed using over 2.77 million
multi-modal ophthalmology images with partial text data. To fully leverage the
large multi-modal unlabeled and labeled data, we introduced a pretraining
strategy that combines self-supervised reconstructions, multi-modal image
contrastive learning, and image-text contrastive learning to learn a shared
representation of multiple modalities. Through evaluation using 14 benchmark
datasets, EyeCLIP can be transferred to a wide range of downstream tasks
involving ocular and systemic diseases, achieving state-of-the-art performance
in disease classification, visual question answering, and cross-modal
retrieval. EyeCLIP represents a significant advancement over previous methods,
especially showcasing few-shot, even zero-shot capabilities in real-world
long-tail scenarios.

摘要：早期偵測青光眼、黃斑部病變和糖尿病視網膜病變等眼疾對於預防視力喪失至關重要。儘管人工智慧 (AI) 基礎模型在應對這些挑戰方面極具前景，但現有的眼科基礎模型主要關注於單一模式，而診斷眼疾需要多種模式。一個重要但經常被忽視的方面是利用同一患者不同模式的多視圖資訊。此外，由於眼科疾病的長尾性質，標準的全監督或無監督學習方法通常難以應付。因此，整合臨床文本以涵蓋更廣泛的疾病譜系至關重要。我們提出 EyeCLIP，這是一個視覺語言基礎模型，使用超過 277 萬張具有部分文字資料的多模式眼科影像開發而成。為了充分利用大量的多模式未標記和標記資料，我們引入了一種預訓練策略，結合了自我監督重建、多模式影像對比學習和影像文字對比學習，以學習多種模式的共享表徵。透過使用 14 個基準資料集進行評估，EyeCLIP 可以轉移到涉及眼部和全身疾病的廣泛下游任務，在疾病分類、視覺問題解答和跨模式檢索中實現最先進的效能。EyeCLIP 代表了對先前方法的重大進展，特別是在現實世界長尾場景中展示了小樣本，甚至零樣本的能力。

##### **TeXBLEU: Automatic Metric for Evaluate LaTeX Format**
2409.06639v2 by Kyudan Jung, Nam-Joon Kim, Hyongon Ryu, Sieun Hyeon, Seung-jun Lee, Hyeok-jae Lee

LaTeX is suitable for creating specially formatted documents in science,
technology, mathematics, and computer science. Although the use of mathematical
expressions in LaTeX format along with language models is increasing, there are
no proper evaluation matrices to evaluate them. In this study, we propose
TeXBLEU, a metric for evaluating mathematical expressions in the LaTeX format
built on the n-gram-based BLEU metric widely used in translation tasks. The
proposed TeXBLEU consists of a predefined tokenizer trained on the arXiv paper
dataset and a fine-tuned embedding model with positional encoding. The TeXBLEU
score was calculated by replacing BLUE's modified precision score with the
similarity of n-gram-based tokens. TeXBLEU showed improvements of 86\%, 121\%,
and 610\% over traditional evaluation metrics, such as BLEU, sacreBLEU, and
Rouge, respectively, on the MathBridge dataset with 1,000 data points. The code
is available at https://github.com/KyuDan1/TeXBLEU.

摘要：LaTeX 適用於製作科學、技術、數學和電腦科學中格式特殊的文章。儘管 LaTeX 格式中的數學表達式與語言模型的使用日益增加，但目前沒有適當的評估矩陣來評估它們。在這項研究中，我們提出了 TeXBLEU，這是一種用於評估 LaTeX 格式中數學表達式的指標，它建立在廣泛用於翻譯任務的基於 n-gram 的 BLEU 指標上。所提出的 TeXBLEU 包含一個在 arXiv 論文資料集上訓練好的預定義分詞器，以及一個帶有位置編碼的微調嵌入模型。TeXBLEU 分數是透過將 BLUE 的修改後準確度分數替換為基於 n-gram 的標記的相似性來計算的。在包含 1,000 個資料點的 MathBridge 資料集上，TeXBLEU 分別比傳統的評估指標，例如 BLEU、sacreBLEU 和 Rouge，提高了 86%、121% 和 610%。該程式碼可於 https://github.com/KyuDan1/TeXBLEU 取得。

##### **MoWE-Audio: Multitask AudioLLMs with Mixture of Weak Encoders**
2409.06635v1 by Wenyu Zhang, Shuo Sun, Bin Wang, Xunlong Zou, Zhuohan Liu, Yingxu He, Geyu Lin, Nancy F. Chen, Ai Ti Aw

The rapid advancements in large language models (LLMs) have significantly
enhanced natural language processing capabilities, facilitating the development
of AudioLLMs that process and understand speech and audio inputs alongside
text. Existing AudioLLMs typically combine a pre-trained audio encoder with a
pre-trained LLM, which are subsequently finetuned on specific audio tasks.
However, the pre-trained audio encoder has constrained capacity to capture
features for new tasks and datasets. To address this, we propose to incorporate
mixtures of `weak' encoders (MoWE) into the AudioLLM framework. MoWE
supplements a base encoder with a pool of relatively light weight encoders,
selectively activated based on the audio input to enhance feature extraction
without significantly increasing model size. Our empirical results demonstrate
that MoWE effectively improves multi-task performance, broadening the
applicability of AudioLLMs to more diverse audio tasks.

摘要：大型語言模型 (LLM) 的快速進展顯著提升了自然語言處理能力，促进了 AudioLLM 的發展，AudioLLM 能處理和理解語音和音訊輸入以及文字。現有的 AudioLLM 通常將預先訓練的音訊編碼器與預先訓練的 LLM 結合，然後針對特定音訊任務進行微調。然而，預先訓練的音訊編碼器在擷取新任務和資料集特徵的能力受到限制。為了解決這個問題，我們提議將「弱」編碼器混合 (MoWE) 納入 AudioLLM 架構。MoWE 使用一群相對輕量的編碼器補充基本編碼器，根據音訊輸入有選擇地啟用，以增強特徵擷取，而不會顯著增加模型大小。我們的實證結果證明，MoWE 有效地改進了多任務效能，擴大了 AudioLLM 在更多元音訊任務中的適用性。

##### **Beyond designer's knowledge: Generating materials design hypotheses via large language models**
2409.06756v1 by Quanliang Liu, Maciej P. Polak, So Yeon Kim, MD Al Amin Shuvo, Hrishikesh Shridhar Deodhar, Jeongsoo Han, Dane Morgan, Hyunseok Oh

Materials design often relies on human-generated hypotheses, a process
inherently limited by cognitive constraints such as knowledge gaps and limited
ability to integrate and extract knowledge implications, particularly when
multidisciplinary expertise is required. This work demonstrates that large
language models (LLMs), coupled with prompt engineering, can effectively
generate non-trivial materials hypotheses by integrating scientific principles
from diverse sources without explicit design guidance by human experts. These
include design ideas for high-entropy alloys with superior cryogenic properties
and halide solid electrolytes with enhanced ionic conductivity and formability.
These design ideas have been experimentally validated in high-impact
publications in 2023 not available in the LLM training data, demonstrating the
LLM's ability to generate highly valuable and realizable innovative ideas not
established in the literature. Our approach primarily leverages materials
system charts encoding processing-structure-property relationships, enabling
more effective data integration by condensing key information from numerous
papers, and evaluation and categorization of numerous hypotheses for human
cognition, both through the LLM. This LLM-driven approach opens the door to new
avenues of artificial intelligence-driven materials discovery by accelerating
design, democratizing innovation, and expanding capabilities beyond the
designer's direct knowledge.

摘要：材料設計經常依賴於人類產生的假設，這個過程本質上受到認知限制，例如知識差距和整合與提取知識含義的能力有限，特別是在需要跨學科專業知識時。這項工作證明了大型語言模型 (LLM) 搭配提示工程，可以透過整合來自不同來源的科學原理，有效產生非平凡的材料假設，而無需人類專家明確的設計指導。這些包括具有優異低溫特性的高熵合金設計理念，以及具有增強離子電導率和成形性的鹵化物固體電解質。這些設計理念已在 2023 年的高影響力出版物中得到實驗驗證，這些出版物在 LLM 訓練資料中不可用，證明了 LLM 能夠產生高度有價值且可實現的創新理念，這些理念尚未在文獻中確立。我們的做法主要利用編碼加工結構屬性關係的材料系統圖表，透過濃縮來自多篇論文的關鍵資訊，以及透過 LLM 對人類認知進行大量假設的評估和分類，實現更有效的資料整合。這種由 LLM 驅動的方法為人工智慧驅動的材料發現開啟了新途徑，透過加速設計、民主化創新，以及擴展設計師直接知識以外的能力。

##### **A Practice of Post-Training on Llama-3 70B with Optimal Selection of Additional Language Mixture Ratio**
2409.06624v1 by Ningyuan Xi, Yetao Wu, Kun Fan, Teng Chen, Qingqing Gu, Peng Yu, Jinxian Qu, Chenxi Liu, Zhonglin Jiang, Yong Chen, Luo Ji

Large Language Models (LLM) often needs to be Continual Pre-Trained (CPT) to
obtain the unfamiliar language skill or adapt into new domains. The huge
training cost of CPT often asks for cautious choice of key hyper-parameters
such as the mixture ratio of extra language or domain corpus. However, there is
no systematic study which bridge the gap between the optimal mixture ratio and
the actual model performance, and the gap between experimental scaling law and
the actual deployment in the full model size. In this paper, we perform CPT on
Llama-3 8B and 70B to enhance its Chinese ability. We study the optimal
correlation between the Additional Language Mixture Ratio (ALMR) and the
Learning Rate (LR) on the 8B size which directly indicate the optimal
experimental set up. By thorough choice of hyper-parameter, and subsequent
fine-tuning, the model capability is improved not only on the Chinese-related
benchmark, but also some specific domains including math, coding and emotional
intelligence. We deploy the final 70B version of LLM on an real-life chat
system which obtain satisfying performance.

摘要：大型语言模型 (LLM) 经常需要持续预训练 (CPT) 以获得不熟悉的语言技能或适应新领域。CPT 的巨额训练成本通常需要谨慎选择关键超参数，例如额外语言或领域语料库的混合比例。然而，没有系统性的研究来弥合理想混合比例与实际模型性能之间的差距，以及实验缩放定律与实际部署在完整模型规模之间的差距。在本文中，我们在 Llama-3 8B 和 70B 上执行 CPT 以增强其中文能力。我们研究了 8B 大小上的附加语言混合比例 (ALMR) 和学习率 (LR) 之间的最优相关性，该相关性直接指示最优实验设置。通过彻底选择超参数和随后的微调，模型能力不仅在与中文相关的基准上得到提升，而且在包括数学、编码和情商在内的一些特定领域也得到提升。我们在一个现实生活聊天系统上部署了 LLM 的最终 70B 版本，该系统获得了令人满意的性能。

##### **Exploring Italian sentence embeddings properties through multi-tasking**
2409.06622v1 by Vivi Nastase, Giuseppe Samo, Chunyang Jiang, Paola Merlo

We investigate to what degree existing LLMs encode abstract linguistic
information in Italian in a multi-task setting. We exploit curated synthetic
data on a large scale -- several Blackbird Language Matrices (BLMs) problems in
Italian -- and use them to study how sentence representations built using
pre-trained language models encode specific syntactic and semantic information.
We use a two-level architecture to model separately a compression of the
sentence embeddings into a representation that contains relevant information
for a task, and a BLM task. We then investigate whether we can obtain
compressed sentence representations that encode syntactic and semantic
information relevant to several BLM tasks. While we expected that the sentence
structure -- in terms of sequence of phrases/chunks -- and chunk properties
could be shared across tasks, performance and error analysis show that the
clues for the different tasks are encoded in different manners in the sentence
embeddings, suggesting that abstract linguistic notions such as constituents or
thematic roles does not seem to be present in the pretrained sentence
embeddings.

摘要：我們調查現有 LLM 在多任務設定中編碼義大利文抽象語言資訊的程度。我們利用大量策展的合成資料（義大利文的幾個 Blackbird Language Matrices (BLM) 問題），並用它們來研究使用預先訓練的語言模型建構的句子表徵如何編碼特定的句法和語義資訊。我們使用二層架構來分別模擬句子嵌入壓縮成包含任務相關資訊的表徵，以及 BLM 任務。我們接著調查我們是否能取得編碼句法和語義資訊的壓縮句子表徵，這些資訊與幾個 BLM 任務相關。雖然我們預期句子結構（以詞組/區塊序列表示）和區塊屬性可以在任務間共用，但效能和錯誤分析顯示，不同任務的線索以不同方式編碼在句子嵌入中，這表示抽象語言概念（例如成分或主題角色）似乎不存在於預先訓練的句子嵌入中。

##### **Scaling Law Hypothesis for Multimodal Model**
2409.06754v1 by Qingyun Sun, Zhen Guo

We propose a scaling law hypothesis for multimodal models processing text,
audio, images, and video within a shared token and embedding space. Our
framework predicts model performance based on modality-specific compression and
tokenization efficiency, extending established scaling laws from text-based
decoder models to mixed-modality systems. We explore whether leveraging more
training data in multiple modalities can reduce the size of the multimodal
model, enabling efficient deployment on resource-constrained devices.

摘要：我們提出一個針對多模態模型處理文字、音訊、影像和影片的縮放定律假設，它們在一個共用的符號和嵌入空間內處理。我們的架構預測基於特定模態的壓縮和符號化效率的模型效能，將既有的縮放定律從基於文字的解碼器模型延伸到混合模態系統。我們探討利用更多不同模態的訓練資料是否能縮小多模態模型的規模，讓資源受限的裝置也能有效部署。

##### **Label-free Monitoring of Self-Supervised Learning Progress**
2409.06612v1 by Isaac Xu, Scott Lowe, Thomas Trappenberg

Self-supervised learning (SSL) is an effective method for exploiting
unlabelled data to learn a high-level embedding space that can be used for
various downstream tasks. However, existing methods to monitor the quality of
the encoder -- either during training for one model or to compare several
trained models -- still rely on access to annotated data. When SSL
methodologies are applied to new data domains, a sufficiently large labelled
dataset may not always be available. In this study, we propose several
evaluation metrics which can be applied on the embeddings of unlabelled data
and investigate their viability by comparing them to linear probe accuracy (a
common metric which utilizes an annotated dataset). In particular, we apply
$k$-means clustering and measure the clustering quality with the silhouette
score and clustering agreement. We also measure the entropy of the embedding
distribution. We find that while the clusters did correspond better to the
ground truth annotations as training of the network progressed, label-free
clustering metrics correlated with the linear probe accuracy only when training
with SSL methods SimCLR and MoCo-v2, but not with SimSiam. Additionally,
although entropy did not always have strong correlations with LP accuracy, this
appears to be due to instability arising from early training, with the metric
stabilizing and becoming more reliable at later stages of learning.
Furthermore, while entropy generally decreases as learning progresses, this
trend reverses for SimSiam. More research is required to establish the cause
for this unexpected behaviour. Lastly, we find that while clustering based
approaches are likely only viable for same-architecture comparisons, entropy
may be architecture-independent.

摘要：<paragraph>自监督学习 (SSL) 是一种有效的方法，可利用未标记的数据学习可用于各种下游任务的高级嵌入空间。然而，用于监控编码器质量的现有方法——无论是针对一个模型的训练期间还是用于比较多个训练模型——仍然依赖于对注释数据的访问。当 SSL 方法应用于新的数据域时，可能并不总是可以使用足够大的标记数据集。在这项研究中，我们提出了几种评估指标，可应用于未标记数据的嵌入，并通过将它们与线性探测准确度（一种利用注释数据集的常见指标）进行比较来调查其可行性。特别是，我们应用 k 均值聚类，并使用轮廓得分和聚类一致性来衡量聚类质量。我们还测量嵌入分布的熵。我们发现，虽然随着网络训练的进行，聚类确实更好地对应于真实注释，但无标签聚类指标仅在使用 SSL 方法 SimCLR 和 MoCo-v2 训练时与线性探测准确度相关，而与 SimSiam 无关。此外，尽管熵并不总是与 LP 准确度有很强的相关性，但这似乎是由于早期训练引起的不稳定性，随着学习的后期，该指标会稳定并变得更加可靠。此外，虽然熵通常随着学习的进行而降低，但对于 SimSiam，这种趋势会逆转。需要更多的研究来确定这种意外行为的原因。最后，我们发现，虽然基于聚类的方法可能只适用于相同架构的比较，但熵可能是与架构无关的。</paragraph>

##### **Alleviating Hallucinations in Large Language Models with Scepticism Modeling**
2409.06601v1 by Yetao Wu, Yihong Wang, Teng Chen, Chenxi Liu, Ningyuan Xi, Qingqing Gu, Hongyang Lei, Zhonglin Jiang, Yong Chen, Luo Ji

Hallucinations is a major challenge for large language models (LLMs),
prevents adoption in diverse fields. Uncertainty estimation could be used for
alleviating the damages of hallucinations. The skeptical emotion of human could
be useful for enhancing the ability of self estimation. Inspirited by this
observation, we proposed a new approach called Skepticism Modeling (SM). This
approach is formalized by combining the information of token and logits for
self estimation. We construct the doubt emotion aware data, perform continual
pre-training, and then fine-tune the LLMs, improve their ability of self
estimation. Experimental results demonstrate this new approach effectively
enhances a model's ability to estimate their uncertainty, and validate its
generalization ability of other tasks by out-of-domain experiments.

摘要：幻覺是大型語言模型 (LLM) 的一項重大挑戰，
防止在不同領域中採用。不確定性估計可用於
減輕幻覺的損害。人類的懷疑情緒可能
有助於增強自我估計的能力。受到這個啟發
觀察，我們提出了一種稱為懷疑建模 (SM) 的新方法。這
種方法透過結合代幣和對數的信息進行自我估計而形式化。我們建構懷疑情緒感知數據，執行持續
預訓練，然後微調 LLM，提升它們自我估計的能力。實驗結果證明這種新方法有效
增強模型估計其不確定性的能力，並透過領域外實驗驗證其對其他任務的泛化能力。

##### **GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering**
2409.06595v1 by Sacha Muller, António Loison, Bilel Omrani, Gautier Viaud

Retrieval-Augmented Generation (RAG) has emerged as a common paradigm to use
Large Language Models (LLMs) alongside private and up-to-date knowledge bases.
In this work, we address the challenges of using LLM-as-a-Judge when evaluating
grounded answers generated by RAG systems. To assess the calibration and
discrimination capabilities of judge models, we identify 7 generator failure
modes and introduce GroUSE (Grounded QA Unitary Scoring of Evaluators), a
meta-evaluation benchmark of 144 unit tests. This benchmark reveals that
existing automated RAG evaluation frameworks often overlook important failure
modes, even when using GPT-4 as a judge.
  To improve on the current design of automated RAG evaluation frameworks, we
propose a novel pipeline and find that while closed models perform well on
GroUSE, state-of-the-art open-source judges do not generalize to our proposed
criteria, despite strong correlation with GPT-4's judgement. Our findings
suggest that correlation with GPT-4 is an incomplete proxy for the practical
performance of judge models and should be supplemented with evaluations on unit
tests for precise failure mode detection.
  We further show that finetuning Llama-3 on GPT-4's reasoning traces
significantly boosts its evaluation capabilities, improving upon both
correlation with GPT-4's evaluations and calibration on reference situations.

摘要：檢索增強生成 (RAG) 已成為一種常見範例，可將大型語言模型 (LLM) 與私人且最新的知識庫一起使用。在這項工作中，我們在評估 RAG 系統生成的基礎答案時，探討了使用 LLM 作為評審時所面臨的挑戰。為了評估評審模型的校準和區分能力，我們找出 7 種生成器故障模式，並引入了 GroUSE（評估人員的基礎問答單元評分），這是一個包含 144 個單元測試的元評估基準。此基準揭示了現有的自動化 RAG 評估架構通常會忽略重要的故障模式，即使使用 GPT-4 作為評審也是如此。為了改善自動化 RAG 評估架構的當前設計，我們提出了一個新的管道，並發現封閉模型在 GroUSE 上表現良好，但最先進的開源評審並未概括到我們提出的標準，儘管與 GPT-4 的判斷有很強的相關性。我們的研究結果表明，與 GPT-4 的相關性是評審模型實際效能的不完整代理，應補充單元測試的評估，以進行精確的故障模式偵測。我們進一步表明，在 GPT-4 的推理軌跡上微調 Llama-3 可顯著提升其評估能力，同時改善與 GPT-4 評估的相關性，並校準參考情況。

##### **Developing the Temporal Graph Convolutional Neural Network Model to Predict Hip Replacement using Electronic Health Records**
2409.06585v1 by Zoe Hancox, Sarah R. Kingsbury, Andrew Clegg, Philip G. Conaghan, Samuel D. Relton

Background: Hip replacement procedures improve patient lives by relieving
pain and restoring mobility. Predicting hip replacement in advance could reduce
pain by enabling timely interventions, prioritising individuals for surgery or
rehabilitation, and utilising physiotherapy to potentially delay the need for
joint replacement. This study predicts hip replacement a year in advance to
enhance quality of life and health service efficiency. Methods: Adapting
previous work using Temporal Graph Convolutional Neural Network (TG-CNN)
models, we construct temporal graphs from primary care medical event codes,
sourced from ResearchOne EHRs of 40-75-year-old patients, to predict hip
replacement risk. We match hip replacement cases to controls by age, sex, and
Index of Multiple Deprivation. The model, trained on 9,187 cases and 9,187
controls, predicts hip replacement one year in advance. We validate the model
on two unseen datasets, recalibrating for class imbalance. Additionally, we
conduct an ablation study and compare against four baseline models. Results:
Our best model predicts hip replacement risk one year in advance with an AUROC
of 0.724 (95% CI: 0.715-0.733) and an AUPRC of 0.185 (95% CI: 0.160-0.209),
achieving a calibration slope of 1.107 (95% CI: 1.074-1.139) after
recalibration. Conclusions: The TG-CNN model effectively predicts hip
replacement risk by identifying patterns in patient trajectories, potentially
improving understanding and management of hip-related conditions.

摘要：背景：髖關節置換手術可減輕疼痛並恢復行動能力，進而改善患者生活。預測髖關節置換手術有助於及時介入、優先安排個人進行手術或復健，並利用物理治療來延緩關節置換手術的必要性，進而減少疼痛。本研究預測一年後的髖關節置換手術，以提升生活品質和醫療服務效率。方法：採用時間圖形卷積神經網路 (TG-CNN) 模型改編先前的研究，我們從 ResearchOne EHR 40-75 歲患者的主要照護醫療事件代碼建構時間圖形，以預測髖關節置換手術風險。我們根據年齡、性別和多重剝奪指數，將髖關節置換手術病例與對照組進行配對。該模型針對 9,187 個病例和 9,187 個對照組進行訓練，預測一年後的髖關節置換手術。我們在兩個未見數據集驗證模型，並重新校準以解決類別不平衡問題。此外，我們進行消融研究，並與四個基準模型進行比較。結果：我們最佳的模型預測一年後的髖關節置換手術風險，AUROC 為 0.724 (95% CI：0.715-0.733)，AUPRC 為 0.185 (95% CI：0.160-0.209)，重新校準後校準斜率為 1.107 (95% CI：1.074-1.139)。結論：TG-CNN 模型可有效預測髖關節置換手術風險，方法是找出患者軌跡中的模式，進而潛在改善對髖關節相關疾病的了解和管理。

##### **Quantifying and Enabling the Interpretability of CLIP-like Models**
2409.06579v1 by Avinash Madasu, Yossi Gandelsman, Vasudev Lal, Phillip Howard

CLIP is one of the most popular foundational models and is heavily used for
many vision-language tasks. However, little is known about the inner workings
of CLIP. To bridge this gap we propose a study to quantify the interpretability
in CLIP like models. We conduct this study on six different CLIP models from
OpenAI and OpenCLIP which vary by size, type of pre-training data and patch
size. Our approach begins with using the TEXTSPAN algorithm and in-context
learning to break down individual attention heads into specific properties. We
then evaluate how easily these heads can be interpreted using new metrics which
measure property consistency within heads and property disentanglement across
heads. Our findings reveal that larger CLIP models are generally more
interpretable than their smaller counterparts. To further assist users in
understanding the inner workings of CLIP models, we introduce CLIP-InterpreT, a
tool designed for interpretability analysis. CLIP-InterpreT offers five types
of analyses: property-based nearest neighbor search, per-head topic
segmentation, contrastive segmentation, per-head nearest neighbors of an image,
and per-head nearest neighbors of text.

摘要：CLIP 是最流行的基础模型之一，被广泛用于许多视觉语言任务。然而，关于 CLIP 的内部工作原理知之甚少。为了弥合这一差距，我们提出了一项研究来量化 CLIP 等模型的可解释性。我们对 OpenAI 和 OpenCLIP 的六个不同的 CLIP 模型进行了这项研究，这些模型的大小、预训练数据类型和补丁大小各不相同。我们的方法首先使用 TEXTSPAN 算法和上下文学习将各个注意力头分解为特定属性。然后我们评估使用新指标解释这些头的容易程度，这些指标测量头内属性一致性和头间属性解耦。我们的研究结果表明，较大的 CLIP 模型通常比较小的模型更具可解释性。为了进一步帮助用户了解 CLIP 模型的内部工作原理，我们引入了 CLIP-InterpreT，这是一个专为可解释性分析而设计的工具。CLIP-InterpreT 提供五种类型的分析：基于属性的最近邻搜索、每个头的主题分割、对比分割、图像的每个头的最近邻和文本的每个头的最近邻。

##### **Exploring syntactic information in sentence embeddings through multilingual subject-verb agreement**
2409.06567v1 by Vivi Nastase, Chunyang Jiang, Giuseppe Samo, Paola Merlo

In this paper, our goal is to investigate to what degree multilingual
pretrained language models capture cross-linguistically valid abstract
linguistic representations. We take the approach of developing curated
synthetic data on a large scale, with specific properties, and using them to
study sentence representations built using pretrained language models. We use a
new multiple-choice task and datasets, Blackbird Language Matrices (BLMs), to
focus on a specific grammatical structural phenomenon -- subject-verb agreement
across a variety of sentence structures -- in several languages. Finding a
solution to this task requires a system detecting complex linguistic patterns
and paradigms in text representations. Using a two-level architecture that
solves the problem in two steps -- detect syntactic objects and their
properties in individual sentences, and find patterns across an input sequence
of sentences -- we show that despite having been trained on multilingual texts
in a consistent manner, multilingual pretrained language models have
language-specific differences, and syntactic structure is not shared, even
across closely related languages.

摘要：在本文中，我们的目标是研究多语言预训练语言模型在多大程度上捕捉到跨语言有效的抽象语言表征。我们采取的方法是在大规模上开发经过整理的合成数据，具有特定属性，并使用它们来研究使用预训练语言模型构建的句子表征。我们使用一项新的多项选择任务和数据集，即黑鸟语言矩阵 (BLM)，以专注于一种特定的语法结构现象——跨多种句子结构的主谓一致——在多种语言中。找到解决此任务的方法需要一个系统来检测文本表征中的复杂语言模式和范例。使用一个两级架构，分两步解决问题——检测单个句子中的句法对象及其属性，并在输入句子序列中查找模式——我们表明，尽管以一致的方式在多语言文本上进行训练，多语言预训练语言模型具有语言特异性差异，即使在密切相关的语言中，句法结构也没有共享。

##### **Indirect Dynamic Negotiation in the Nash Demand Game**
2409.06566v1 by Tatiana V. Guy, Jitka Homolová, Aleksej Gaj

The paper addresses a problem of sequential bilateral bargaining with
incomplete information. We proposed a decision model that helps agents to
successfully bargain by performing indirect negotiation and learning the
opponent's model. Methodologically the paper casts heuristically-motivated
bargaining of a self-interested independent player into a framework of Bayesian
learning and Markov decision processes. The special form of the reward
implicitly motivates the players to negotiate indirectly, via closed-loop
interaction. We illustrate the approach by applying our model to the Nash
demand game, which is an abstract model of bargaining. The results indicate
that the established negotiation: i) leads to coordinating players' actions;
ii) results in maximising success rate of the game and iii) brings more
individual profit to the players.

摘要：本文讨论了在信息不完全的情况下进行顺序双边谈判的问题。我们提出了一种决策模型，通过执行间接谈判和学习对手的模型来帮助代理人成功地进行谈判。从方法论上讲，该论文将自私的独立参与者的启发式激励讨价还价纳入贝叶斯学习和马尔可夫决策过程的框架中。奖励的特殊形式隐含地激励参与者通过闭环交互间接谈判。我们通过将我们的模型应用于纳什需求博弈（一种讨价还价的抽象模型）来说明这种方法。结果表明，既定的谈判：i）导致协调参与者的行动；ii）导致最大化博弈的成功率，并且 iii）为参与者带来更多个人利益。

##### **From LIMA to DeepLIMA: following a new path of interoperability**
2409.06550v1 by Victor Bocharov, Romaric Besançon, Gaël de Chalendar, Olivier Ferret, Nasredine Semmar

In this article, we describe the architecture of the LIMA (Libre Multilingual
Analyzer) framework and its recent evolution with the addition of new text
analysis modules based on deep neural networks. We extended the functionality
of LIMA in terms of the number of supported languages while preserving existing
configurable architecture and the availability of previously developed
rule-based and statistical analysis components. Models were trained for more
than 60 languages on the Universal Dependencies 2.5 corpora, WikiNer corpora,
and CoNLL-03 dataset. Universal Dependencies allowed us to increase the number
of supported languages and to generate models that could be integrated into
other platforms. This integration of ubiquitous Deep Learning Natural Language
Processing models and the use of standard annotated collections using Universal
Dependencies can be viewed as a new path of interoperability, through the
normalization of models and data, that are complementary to a more standard
technical interoperability, implemented in LIMA through services available in
Docker containers on Docker Hub.

摘要：在本文中，我們描述了 LIMA（Libre Multilingual Analyzer）架構及其最近加入基於深度神經網路的新文字分析模組的演進。我們在保留現有可組態架構和先前開發的基於規則和統計分析元件可用性的同時，擴充了 LIMA 在支援語言數量方面的功能。針對 Universal Dependencies 2.5 語料庫、WikiNer 語料庫和 CoNLL-03 資料集為超過 60 種語言訓練模型。Universal Dependencies 讓我們得以增加支援語言的數量，並產生可整合到其他平台的模型。普遍的深度學習自然語言處理模型的整合，以及使用 Universal Dependencies 的標準註解集合，可視為一種透過模型和資料的標準化而產生的新的互操作性途徑，這對於 LIMA 中透過 Docker Hub 上的 Docker 容器中可用的服務所實作的更標準化的技術互操作性而言，具有互補性。

##### **Mapping News Narratives Using LLMs and Narrative-Structured Text Embeddings**
2409.06540v1 by Jan Elfes

Given the profound impact of narratives across various societal levels, from
personal identities to international politics, it is crucial to understand
their distribution and development over time. This is particularly important in
online spaces. On the Web, narratives can spread rapidly and intensify societal
divides and conflicts. While many qualitative approaches exist, quantifying
narratives remains a significant challenge. Computational narrative analysis
lacks frameworks that are both comprehensive and generalizable. To address this
gap, we introduce a numerical narrative representation grounded in
structuralist linguistic theory. Chiefly, Greimas' Actantial Model represents a
narrative through a constellation of six functional character roles. These
so-called actants are genre-agnostic, making the model highly generalizable. We
extract the actants using an open-source LLM and integrate them into a
Narrative-Structured Text Embedding that captures both the semantics and
narrative structure of a text. We demonstrate the analytical insights of the
method on the example of 5000 full-text news articles from Al Jazeera and The
Washington Post on the Israel-Palestine conflict. Our method successfully
distinguishes articles that cover the same topics but differ in narrative
structure.

摘要：由於敘事在各個社會層面，從個人身分到國際政治，都有深遠的影響，因此了解敘事的分布和發展過程至關重要。這在網路空間中尤其重要。在網路上，敘事可以迅速傳播並加劇社會分歧和衝突。儘管有許多定性方法，但量化敘事仍然是一項重大的挑戰。計算敘事分析缺乏既全面又可概括的架構。為了解決這個差距，我們引入了一個基於結構主義語言理論的數值敘事表徵。最重要的是，格雷馬斯的行動者模型通過一組六個功能角色來表示敘事。這些所謂的行動者與類型無關，使得該模型具有高度的概括性。我們使用開源 LLM 提取行動者，並將它們整合到一個敘事結構化文字嵌入中，該嵌入同時捕捉文本的語義和敘事結構。我們在半島電視台和華盛頓郵報上關於巴以衝突的 5000 篇全文新聞文章的範例中展示了該方法的分析見解。我們的模型成功區分了涵蓋相同主題但敘事結構不同的文章。

##### **Questioning Internal Knowledge Structure of Large Language Models Through the Lens of the Olympic Games**
2409.06518v1 by Juhwan Choi, YoungBin Kim

Large language models (LLMs) have become a dominant approach in natural
language processing, yet their internal knowledge structures remain largely
unexplored. In this paper, we analyze the internal knowledge structures of LLMs
using historical medal tallies from the Olympic Games. We task the models with
providing the medal counts for each team and identifying which teams achieved
specific rankings. Our results reveal that while state-of-the-art LLMs perform
remarkably well in reporting medal counts for individual teams, they struggle
significantly with questions about specific rankings. This suggests that the
internal knowledge structures of LLMs are fundamentally different from those of
humans, who can easily infer rankings from known medal counts. To support
further research, we publicly release our code, dataset, and model outputs.

摘要：大型語言模型 (LLM) 已成為自然語言處理領域的主流方法，但它們的內部知識結構在很大程度上仍未被探索。在本文中，我們使用奧運會的歷史獎牌數分析了 LLM 的內部知識結構。我們要求模型提供每個團隊的獎牌數，並找出哪些團隊達到了特定排名。我們的結果表明，雖然最先進的 LLM 在報告個別團隊的獎牌數方面表現出色，但它們在關於特定排名的問題上卻遇到了很大的困難。這表明 LLM 的內部知識結構與人類的內部知識結構有根本的不同，人類可以輕鬆地從已知的獎牌數中推斷出排名。為了支持進一步的研究，我們公開發布了我們的代碼、數據集和模型輸出。

##### **Sine, Transient, Noise Neural Modeling of Piano Notes**
2409.06513v1 by Riccardo Simionato, Stefano Fasciani

This paper introduces a novel method for emulating piano sounds. We propose
to exploit the sine, transient, and noise decomposition to design a
differentiable spectral modeling synthesizer replicating piano notes. Three
sub-modules learn these components from piano recordings and generate the
corresponding harmonic, transient, and noise signals. Splitting the emulation
into three independently trainable models reduces the modeling tasks'
complexity. The quasi-harmonic content is produced using a differentiable
sinusoidal model guided by physics-derived formulas, whose parameters are
automatically estimated from audio recordings. The noise sub-module uses a
learnable time-varying filter, and the transients are generated using a deep
convolutional network. From singular notes, we emulate the coupling between
different keys in trichords with a convolutional-based network. Results show
the model matches the partial distribution of the target while predicting the
energy in the higher part of the spectrum presents more challenges. The energy
distribution in the spectra of the transient and noise components is accurate
overall. While the model is more computationally and memory efficient,
perceptual tests reveal limitations in accurately modeling the attack phase of
notes. Despite this, it generally achieves perceptual accuracy in emulating
single notes and trichords.

摘要：本文介紹一種模擬鋼琴音效的新方法。我們建議利用正弦波、暫態和雜訊分解來設計一個可微分頻譜建模合成器，以複製鋼琴音符。三個子模組從鋼琴錄音中學習這些組成部分，並產生相應的諧波、暫態和雜訊訊號。將模擬拆分為三個獨立可訓練的模型，降低了建模任務的複雜性。準諧波內容是使用由物理公式引導的可微分正弦模型產生的，其參數會從音訊錄音中自動估計。雜訊子模組使用可學習的時間變異濾波器，而暫態是使用深度卷積網路產生的。從單一音符中，我們模擬了三和弦中不同鍵之間的耦合，使用基於卷積的網路。結果顯示，該模型匹配目標的部分分佈，同時預測光譜高部分的能量提出了更多挑戰。暫態和雜訊組成部分光譜中的能量分佈整體上是準確的。雖然該模型在運算和記憶體方面更有效率，但感知測試顯示在準確建模音符的攻擊階段方面有其限制。儘管如此，它通常在模擬單音符和三和弦時達到感知準確度。

