{"2406.15085": {"publish_time": "2024-06-21", "title": "A Unified Framework for Input Feature Attribution Analysis", "paper_summary": "Explaining the decision-making process of machine learning models is crucial\nfor ensuring their reliability and fairness. One popular explanation form\nhighlights key input features, such as i) tokens (e.g., Shapley Values and\nIntegrated Gradients), ii) interactions between tokens (e.g., Bivariate Shapley\nand Attention-based methods), or iii) interactions between spans of the input\n(e.g., Louvain Span Interactions). However, these explanation types have only\nbeen studied in isolation, making it difficult to judge their respective\napplicability. To bridge this gap, we propose a unified framework that\nfacilitates a direct comparison between highlight and interactive explanations\ncomprised of four diagnostic properties. Through extensive analysis across\nthese three types of input feature explanations--each utilizing three different\nexplanation techniques--across two datasets and two models, we reveal that each\nexplanation type excels in terms of different diagnostic properties. In our\nexperiments, highlight explanations are the most faithful to a model's\nprediction, and interactive explanations provide better utility for learning to\nsimulate a model's predictions. These insights further highlight the need for\nfuture research to develop combined methods that enhance all diagnostic\nproperties.", "paper_summary_zh": "\u89e3\u91cb\u6a5f\u5668\u5b78\u7fd2\u6a21\u578b\u7684\u6c7a\u7b56\u904e\u7a0b\u5c0d\u65bc\u78ba\u4fdd\u5b83\u5011\u7684\u53ef\u9760\u6027\u548c\u516c\u5e73\u6027\u81f3\u95dc\u91cd\u8981\u3002\u4e00\u7a2e\u6d41\u884c\u7684\u89e3\u91cb\u5f62\u5f0f\u7a81\u51fa\u4e86\u95dc\u9375\u8f38\u5165\u7279\u5fb5\uff0c\u4f8b\u5982 i) \u4ee3\u5e63\uff08\u4f8b\u5982\uff0cShapley \u503c\u548c\u7a4d\u5206\u68af\u5ea6\uff09\u3001ii) \u4ee3\u5e63\u4e4b\u9593\u7684\u4ea4\u4e92\uff08\u4f8b\u5982\uff0c\u96d9\u8b8a\u91cf Shapley \u548c\u57fa\u65bc\u6ce8\u610f\u529b\u7684\u65b9\u6cd5\uff09\uff0c\u6216 iii) \u8f38\u5165\u8de8\u5ea6\u7684\u4ea4\u4e92\uff08\u4f8b\u5982\uff0c\u9b6f\u6c76\u8de8\u5ea6\u4ea4\u4e92\uff09\u3002\u7136\u800c\uff0c\u9019\u4e9b\u89e3\u91cb\u985e\u578b\u50c5\u5728\u5b64\u7acb\u7684\u74b0\u5883\u4e2d\u9032\u884c\u4e86\u7814\u7a76\uff0c\u9019\u4f7f\u5f97\u96e3\u4ee5\u5224\u65b7\u5b83\u5011\u5404\u81ea\u7684\u9069\u7528\u6027\u3002\u70ba\u4e86\u5f4c\u5408\u9019\u4e00\u5dee\u8ddd\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u500b\u7d71\u4e00\u7684\u6846\u67b6\uff0c\u8a72\u6846\u67b6\u4fc3\u9032\u4e86\u7531\u56db\u500b\u8a3a\u65b7\u5c6c\u6027\u7d44\u6210\u7684\u4eae\u9ede\u548c\u4e92\u52d5\u89e3\u91cb\u4e4b\u9593\u7684\u76f4\u63a5\u6bd4\u8f03\u3002\u901a\u904e\u5c0d\u9019\u4e09\u7a2e\u985e\u578b\u7684\u8f38\u5165\u7279\u5fb5\u89e3\u91cb\uff08\u6bcf\u7a2e\u985e\u578b\u90fd\u4f7f\u7528\u4e09\u7a2e\u4e0d\u540c\u7684\u89e3\u91cb\u6280\u8853\uff09\u5728\u5169\u500b\u6578\u64da\u96c6\u548c\u5169\u500b\u6a21\u578b\u4e2d\u9032\u884c\u5ee3\u6cdb\u5206\u6790\uff0c\u6211\u5011\u767c\u73fe\u6bcf\u7a2e\u985e\u578b\u7684\u89e3\u91cb\u5728\u4e0d\u540c\u7684\u8a3a\u65b7\u5c6c\u6027\u65b9\u9762\u90fd\u975e\u5e38\u51fa\u8272\u3002\u5728\u6211\u5011\u7684\u5be6\u9a57\u4e2d\uff0c\u4eae\u9ede\u89e3\u91cb\u6700\u5fe0\u5be6\u65bc\u6a21\u578b\u7684\u9810\u6e2c\uff0c\u800c\u4e92\u52d5\u89e3\u91cb\u5247\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u6548\u7528\uff0c\u7528\u65bc\u6a21\u64ec\u6a21\u578b\u7684\u9810\u6e2c\u3002\u9019\u4e9b\u898b\u89e3\u9032\u4e00\u6b65\u5f37\u8abf\u4e86\u672a\u4f86\u7814\u7a76\u9700\u8981\u958b\u767c\u7d50\u5408\u65b9\u6cd5\u4ee5\u589e\u5f37\u6240\u6709\u8a3a\u65b7\u5c6c\u6027\u7684\u5fc5\u8981\u6027\u3002", "author": "Jingyi Sun et.al.", "authors": "Jingyi Sun, Pepa Atanasova, Isabelle Augenstein", "id": "2406.15085v1", "paper_url": "http://arxiv.org/abs/2406.15085v1", "repo": "null"}}