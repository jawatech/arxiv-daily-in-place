{"2406.07115": {"publish_time": "2024-06-11", "title": "Advancing Tool-Augmented Large Language Models: Integrating Insights from Errors in Inference Trees", "paper_summary": "Tool-augmented large language models (LLMs) leverage tools, often in the form\nof APIs, to enhance their reasoning capabilities on complex tasks, thus taking\non the role of intelligent agents interacting with the real world. The recently\nintroduced ToolLLaMA model by Qin et al. [2024] utilizes the depth-first\nsearch-based decision tree (DFSDT) method for reasoning with $16000+$\nreal-world APIs, which effectively improves the planning and inferencing\nperformance of tool-augmented LLMs compared to traditional chain reasoning\napproaches. However, their approach only employs successful paths from decision\ntrees (also called inference trees) for supervised fine-tuning (SFT) during\ntraining, which does not fully exploit the advantages of the tree of thought.\nIn this study, we propose an inference trajectory optimization framework based\non the preference data extracted from decision trees to address this\nlimitation. We first introduce a novel method for constructing preference data\nfrom the tree of thought, capitalizing on the failed explorations previously\noverlooked in the trees. Specifically, we generate an effective step-wise\npreference dataset, named ToolPreference, for tool use based on the ToolBench\ndataset. In the subsequent training phase, we first fine-tune the LLM with\ntool-usage expert trajectories and then use these step-wise preference pairs\nfor direct preference optimization (DPO) to update the policy of the LLM,\nresulting in our ToolPrefer-LLaMA (TP-LLaMA) model. Our experiments demonstrate\nthat by obtaining insights from errors in inference trees, TP-LLaMA\nsignificantly outperforms the baselines across almost all test scenarios by a\nlarge margin and exhibits better generalization capabilities with unseen APIs.\nAt the same time, TP-LLaMA has also demonstrated superior reasoning efficiency\ncompared to the baselines, making it more suitable for complex tool-usage\nreasoning tasks.", "paper_summary_zh": "<paragraph>\u5177\u5de5\u5177\u589e\u5f37\u7684\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u900f\u904e\u5de5\u5177\uff08\u901a\u5e38\u4ee5 API \u5f62\u5f0f\u5448\u73fe\uff09\u4f86\u63d0\u5347\u5176\u5728\u8907\u96dc\u4efb\u52d9\u4e0a\u7684\u63a8\u7406\u80fd\u529b\uff0c\u9032\u800c\u626e\u6f14\u8207\u771f\u5be6\u4e16\u754c\u4e92\u52d5\u7684\u667a\u6167\u578b\u4ee3\u7406\u7684\u89d2\u8272\u3002Qin \u7b49\u4eba [2024] \u6700\u8fd1\u63d0\u51fa\u7684 ToolLLaMA \u6a21\u578b\u5229\u7528\u6df1\u5ea6\u512a\u5148\u641c\u5c0b\u70ba\u57fa\u790e\u7684\u6c7a\u7b56\u6a39 (DFSDT) \u65b9\u6cd5\uff0c\u4ee5\u8d85\u904e 16000 \u500b\u771f\u5be6\u4e16\u754c API \u9032\u884c\u63a8\u7406\uff0c\u8207\u50b3\u7d71\u7684\u93c8\u5f0f\u63a8\u7406\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6709\u6548\u63d0\u5347\u5177\u5de5\u5177\u589e\u5f37\u7684 LLM \u5728\u898f\u5283\u548c\u63a8\u8ad6\u4e0a\u7684\u8868\u73fe\u3002\u7136\u800c\uff0c\u4ed6\u5011\u7684\u505a\u6cd5\u50c5\u63a1\u7528\u6c7a\u7b56\u6a39\uff08\u4e5f\u7a31\u70ba\u63a8\u8ad6\u6a39\uff09\u4e2d\u7684\u6210\u529f\u8def\u5f91\uff0c\u5728\u8a13\u7df4\u671f\u9593\u9032\u884c\u76e3\u7763\u5fae\u8abf (SFT)\uff0c\u4e26\u672a\u5b8c\u5168\u767c\u63ee\u601d\u60f3\u6a39\u7684\u512a\u52e2\u3002\u5728\u672c\u7814\u7a76\u4e2d\uff0c\u6211\u5011\u63d0\u51fa\u4e00\u500b\u57fa\u65bc\u5f9e\u6c7a\u7b56\u6a39\u4e2d\u8403\u53d6\u7684\u504f\u597d\u8cc7\u6599\u7684\u63a8\u8ad6\u8ecc\u8de1\u6700\u4f73\u5316\u67b6\u69cb\uff0c\u4ee5\u89e3\u6c7a\u6b64\u9650\u5236\u3002\u6211\u5011\u9996\u5148\u63d0\u51fa\u4e00\u500b\u5f9e\u601d\u60f3\u6a39\u5efa\u69cb\u504f\u597d\u8cc7\u6599\u7684\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u5148\u524d\u5728\u6a39\u4e2d\u88ab\u5ffd\u7565\u7684\u5931\u6557\u63a2\u7d22\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u6839\u64da ToolBench \u8cc7\u6599\u96c6\u7522\u751f\u4e00\u500b\u6709\u6548\u7684\u9010\u6b65\u504f\u597d\u8cc7\u6599\u96c6\uff0c\u7a31\u70ba ToolPreference\uff0c\u4ee5\u4f9b\u5de5\u5177\u4f7f\u7528\u3002\u5728\u5f8c\u7e8c\u7684\u8a13\u7df4\u968e\u6bb5\uff0c\u6211\u5011\u9996\u5148\u4f7f\u7528\u5de5\u5177\u4f7f\u7528\u5c08\u5bb6\u8ecc\u8de1\u5fae\u8abf LLM\uff0c\u7136\u5f8c\u4f7f\u7528\u9019\u4e9b\u9010\u6b65\u504f\u597d\u5c0d\u9032\u884c\u76f4\u63a5\u504f\u597d\u6700\u4f73\u5316 (DPO) \u4f86\u66f4\u65b0 LLM \u7684\u653f\u7b56\uff0c\u7522\u751f\u6211\u5011\u7684 ToolPrefer-LLaMA (TP-LLaMA) \u6a21\u578b\u3002\u6211\u5011\u7684\u5be6\u9a57\u8b49\u660e\uff0c\u85c9\u7531\u5f9e\u63a8\u8ad6\u6a39\u4e2d\u7684\u932f\u8aa4\u4e2d\u7372\u5f97\u898b\u89e3\uff0cTP-LLaMA \u5728\u5e7e\u4e4e\u6240\u6709\u6e2c\u8a66\u60c5\u5883\u4e2d\u90fd\u5927\u5e45\u8d85\u8d8a\u57fa\u6e96\uff0c\u4e26\u5c55\u73fe\u51fa\u5c0d\u672a\u898b API \u66f4\u4f73\u7684\u6cdb\u5316\u80fd\u529b\u3002\u540c\u6642\uff0c\u8207\u57fa\u6e96\u76f8\u6bd4\uff0cTP-LLaMA \u4e5f\u5c55\u73fe\u51fa\u512a\u7570\u7684\u63a8\u7406\u6548\u7387\uff0c\u4f7f\u5176\u66f4\u9069\u5408\u65bc\u8907\u96dc\u7684\u5de5\u5177\u4f7f\u7528\u63a8\u7406\u4efb\u52d9\u3002</paragraph>", "author": "Sijia Chen et.al.", "authors": "Sijia Chen, Yibo Wang, Yi-Feng Wu, Qing-Guo Chen, Zhao Xu, Weihua Luo, Kaifu Zhang, Lijun Zhang", "id": "2406.07115v1", "paper_url": "http://arxiv.org/abs/2406.07115v1", "repo": "null"}}