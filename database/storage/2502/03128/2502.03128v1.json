{"2502.03128": {"publish_time": "2025-02-05", "title": "Metis: A Foundation Speech Generation Model with Masked Generative Pre-training", "paper_summary": "We introduce Metis, a foundation model for unified speech generation. Unlike\nprevious task-specific or multi-task models, Metis follows a pre-training and\nfine-tuning paradigm. It is pre-trained on large-scale unlabeled speech data\nusing masked generative modeling and then fine-tuned to adapt to diverse speech\ngeneration tasks. Specifically, 1) Metis utilizes two discrete speech\nrepresentations: SSL tokens derived from speech self-supervised learning (SSL)\nfeatures, and acoustic tokens directly quantized from waveforms. 2) Metis\nperforms masked generative pre-training on SSL tokens, utilizing 300K hours of\ndiverse speech data, without any additional condition. 3) Through fine-tuning\nwith task-specific conditions, Metis achieves efficient adaptation to various\nspeech generation tasks while supporting multimodal input, even when using\nlimited data and trainable parameters. Experiments demonstrate that Metis can\nserve as a foundation model for unified speech generation: Metis outperforms\nstate-of-the-art task-specific or multi-task systems across five speech\ngeneration tasks, including zero-shot text-to-speech, voice conversion, target\nspeaker extraction, speech enhancement, and lip-to-speech, even with fewer than\n20M trainable parameters or 300 times less training data. Audio samples are are\navailable at https://metis-demo.github.io/.", "paper_summary_zh": "<paragraph>\u6211\u5011\u4ecb\u7d39 Metis\uff0c\u4e00\u500b\u7528\u65bc\u7d71\u4e00\u8a9e\u97f3\u751f\u6210\u7684\u57fa\u790e\u6a21\u578b\u3002\u8207\u5148\u524d\u7684\u7279\u5b9a\u4efb\u52d9\u6216\u591a\u4efb\u52d9\u6a21\u578b\u4e0d\u540c\uff0cMetis \u9075\u5faa\u9810\u8a13\u7df4\u548c\u5fae\u8abf\u7bc4\u4f8b\u3002\u5b83\u4f7f\u7528\u906e\u853d\u751f\u6210\u5f0f\u6a21\u578b\u5728\u5927\u91cf\u672a\u6a19\u8a18\u8a9e\u97f3\u8cc7\u6599\u4e0a\u9032\u884c\u9810\u8a13\u7df4\uff0c\u7136\u5f8c\u9032\u884c\u5fae\u8abf\u4ee5\u9069\u61c9\u5404\u7a2e\u8a9e\u97f3\u751f\u6210\u4efb\u52d9\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c1\uff09Metis \u5229\u7528\u5169\u7a2e\u96e2\u6563\u8a9e\u97f3\u8868\u793a\uff1a\u4f86\u81ea\u8a9e\u97f3\u81ea\u6211\u76e3\u7763\u5f0f\u5b78\u7fd2 (SSL) \u7279\u5fb5\u7684 SSL \u4ee3\u5e63\uff0c\u4ee5\u53ca\u76f4\u63a5\u5f9e\u6ce2\u5f62\u91cf\u5316\u7684\u8072\u5b78\u4ee3\u5e63\u30022\uff09Metis \u5c0d SSL \u4ee3\u5e63\u57f7\u884c\u906e\u853d\u751f\u6210\u5f0f\u9810\u8a13\u7df4\uff0c\u5229\u7528 300K \u5c0f\u6642\u7684\u5404\u7a2e\u8a9e\u97f3\u8cc7\u6599\uff0c\u800c\u7121\u9700\u4efb\u4f55\u984d\u5916\u689d\u4ef6\u30023\uff09\u900f\u904e\u4f7f\u7528\u7279\u5b9a\u65bc\u4efb\u52d9\u7684\u689d\u4ef6\u9032\u884c\u5fae\u8abf\uff0cMetis \u80fd\u6709\u6548\u9069\u61c9\u5404\u7a2e\u8a9e\u97f3\u751f\u6210\u4efb\u52d9\uff0c\u540c\u6642\u652f\u63f4\u591a\u6a21\u614b\u8f38\u5165\uff0c\u5373\u4f7f\u5728\u4f7f\u7528\u6709\u9650\u7684\u8cc7\u6599\u548c\u53ef\u8a13\u7df4\u53c3\u6578\u6642\u4e5f\u662f\u5982\u6b64\u3002\u5be6\u9a57\u8b49\u660e Metis \u53ef\u4f5c\u70ba\u7d71\u4e00\u8a9e\u97f3\u751f\u6210\u7684\u57fa\u790e\u6a21\u578b\uff1aMetis \u5728\u4e94\u9805\u8a9e\u97f3\u751f\u6210\u4efb\u52d9\u4e2d\u512a\u65bc\u6700\u5148\u9032\u7684\u7279\u5b9a\u4efb\u52d9\u6216\u591a\u4efb\u52d9\u7cfb\u7d71\uff0c\u5305\u62ec\u96f6\u6b21\u5b78\u7fd2\u6587\u5b57\u8f49\u8a9e\u97f3\u3001\u8a9e\u97f3\u8f49\u63db\u3001\u76ee\u6a19\u8aaa\u8a71\u8005\u63d0\u53d6\u3001\u8a9e\u97f3\u589e\u5f37\u548c\u5507\u5f62\u8f49\u8a9e\u97f3\uff0c\u5373\u4f7f\u53ef\u8a13\u7df4\u53c3\u6578\u5c11\u65bc 20M \u6216\u8a13\u7df4\u8cc7\u6599\u5c11 300 \u500d\u3002\u97f3\u8a0a\u7bc4\u4f8b\u53ef\u5728 https://metis-demo.github.io/ \u53d6\u5f97\u3002</paragraph>", "author": "Yuancheng Wang et.al.", "authors": "Yuancheng Wang, Jiachen Zheng, Junan Zhang, Xueyao Zhang, Huan Liao, Zhizheng Wu", "id": "2502.03128v1", "paper_url": "http://arxiv.org/abs/2502.03128v1", "repo": "null"}}