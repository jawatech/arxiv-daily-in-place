{"2412.11988": {"publish_time": "2024-12-16", "title": "SciFaultyQA: Benchmarking LLMs on Faulty Science Question Detection with a GAN-Inspired Approach to Synthetic Dataset Generation", "paper_summary": "Consider the problem: ``If one man and one woman can produce one child in one\nyear, how many children will be produced by one woman and three men in 0.5\nyears?\" Current large language models (LLMs) such as GPT-4o, GPT-o1-preview,\nand Gemini Flash frequently answer \"0.5,\" which does not make sense. While\nthese models sometimes acknowledge the unrealistic nature of the question, in\nmany cases (8 out of 10 trials), they provide the nonsensical answer of \"0.5\nchild.\" Additionally, temporal variation has been observed: if an LLM answers\ncorrectly once (by recognizing the faulty nature of the question), subsequent\nresponses are more likely to also reflect this understanding. However, this is\ninconsistent.\n  These types of questions have motivated us to develop a dataset of science\nquestions, SciFaultyQA, where the questions themselves are intentionally\nfaulty. We observed that LLMs often proceed to answer these flawed questions\nwithout recognizing their inherent issues, producing results that are logically\nor scientifically invalid. By analyzing such patterns, we developed a novel\nmethod for generating synthetic datasets to evaluate and benchmark the\nperformance of various LLMs in identifying these flawed questions. We have also\ndeveloped novel approaches to reduce the errors.", "paper_summary_zh": "<paragraph>\u8003\u616e\u9019\u500b\u554f\u984c\uff1a``\u5982\u679c\u4e00\u500b\u7537\u4eba\u548c\u4e00\u500b\u5973\u4eba\u4e00\u5e74\u53ef\u4ee5\u751f\u4e00\u500b\u5b69\u5b50\uff0c\u90a3\u9ebc\u4e00\u500b\u5973\u4eba\u548c\u4e09\u500b\u7537\u4eba\u5728 0.5 \u5e74\u53ef\u4ee5\u751f\u591a\u5c11\u500b\u5b69\u5b50\uff1f\" \u7576\u524d\u7684\u5de8\u91cf\u8a9e\u8a00\u6a21\u578b (LLM)\uff0c\u4f8b\u5982 GPT-4o\u3001GPT-o1-preview \u548c Gemini Flash\uff0c\u7d93\u5e38\u56de\u7b54\u300c0.5\u300d\uff0c\u9019\u6c92\u6709\u9053\u7406\u3002\u96d6\u7136\u9019\u4e9b\u6a21\u578b\u6709\u6642\u6703\u627f\u8a8d\u9019\u500b\u554f\u984c\u4e0d\u5207\u5be6\u969b\uff0c\u4f46\u5728\u8a31\u591a\u60c5\u6cc1\u4e0b\uff0810 \u6b21\u6e2c\u8a66\u4e2d\u6709 8 \u6b21\uff09\uff0c\u5b83\u5011\u7d66\u51fa\u4e86\u300c0.5 \u500b\u5b69\u5b50\u300d\u7684\u7121\u7a3d\u4e4b\u8ac7\u3002\u6b64\u5916\uff0c\u5df2\u7d93\u89c0\u5bdf\u5230\u6642\u9593\u8b8a\u5316\uff1a\u5982\u679c\u4e00\u500b LLM \u6b63\u78ba\u56de\u7b54\u4e00\u6b21\uff08\u901a\u904e\u8a8d\u8b58\u5230\u554f\u984c\u7684\u932f\u8aa4\u6027\u8cea\uff09\uff0c\u5f8c\u7e8c\u56de\u7b54\u4e5f\u66f4\u6709\u53ef\u80fd\u53cd\u6620\u9019\u7a2e\u7406\u89e3\u3002\u7136\u800c\uff0c\u9019\u662f\u4e0d\u4e00\u81f4\u7684\u3002\n  \u9019\u4e9b\u985e\u578b\u7684\u554f\u984c\u4fc3\u4f7f\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b\u79d1\u5b78\u554f\u984c\u6578\u64da\u96c6 SciFaultyQA\uff0c\u5176\u4e2d\u554f\u984c\u672c\u8eab\u662f\u6709\u610f\u932f\u8aa4\u7684\u3002\u6211\u5011\u89c0\u5bdf\u5230\uff0cLLM \u7d93\u5e38\u7e7c\u7e8c\u56de\u7b54\u9019\u4e9b\u6709\u7f3a\u9677\u7684\u554f\u984c\uff0c\u800c\u6c92\u6709\u8a8d\u8b58\u5230\u5b83\u5011\u56fa\u6709\u7684\u554f\u984c\uff0c\u7522\u751f\u5728\u908f\u8f2f\u4e0a\u6216\u79d1\u5b78\u4e0a\u7121\u6548\u7684\u7d50\u679c\u3002\u901a\u904e\u5206\u6790\u9019\u7a2e\u6a21\u5f0f\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u7a2e\u751f\u6210\u5408\u6210\u6578\u64da\u96c6\u7684\u65b0\u65b9\u6cd5\uff0c\u4ee5\u8a55\u4f30\u548c\u6bd4\u8f03\u5404\u7a2e LLM \u5728\u8b58\u5225\u9019\u4e9b\u6709\u7f3a\u9677\u554f\u984c\u65b9\u9762\u7684\u6027\u80fd\u3002\u6211\u5011\u9084\u958b\u767c\u4e86\u65b0\u7684\u65b9\u6cd5\u4f86\u6e1b\u5c11\u932f\u8aa4\u3002</paragraph>", "author": "Debarshi Kundu et.al.", "authors": "Debarshi Kundu", "id": "2412.11988v1", "paper_url": "http://arxiv.org/abs/2412.11988v1", "repo": "https://github.com/debarshikundupsu/scifaultyqa"}}