
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-06-10**|**IllumiNeRF: 3D Relighting without Inverse Rendering**|Xiaoming Zhao et.al.|[2406.06527v1](http://arxiv.org/abs/2406.06527v1)|null|
|**2024-06-10**|**Decentralized Personalized Federated Learning**|Salma Kharrat et.al.|[2406.06520v1](http://arxiv.org/abs/2406.06520v1)|null|
|**2024-06-10**|**Merlin: A Vision Language Foundation Model for 3D Computed Tomography**|Louis Blankemeier et.al.|[2406.06512v1](http://arxiv.org/abs/2406.06512v1)|null|
|**2024-06-10**|**Monkey See, Monkey Do: Harnessing Self-attention in Motion Diffusion for Zero-shot Motion Transfer**|Sigal Raab et.al.|[2406.06508v1](http://arxiv.org/abs/2406.06508v1)|[link](https://github.com/monkeyseedocg/momo-code)|
|**2024-06-10**|**Adaptive Opponent Policy Detection in Multi-Agent MDPs: Real-Time Strategy Switch Identification Using Running Error Estimation**|Mohidul Haque Mridul et.al.|[2406.06500v1](http://arxiv.org/abs/2406.06500v1)|null|
|**2024-06-10**|**Direct Preference Optimization for Suppressing Hallucinated Prior Exams in Radiology Report Generation**|Oishi Banerjee et.al.|[2406.06496v1](http://arxiv.org/abs/2406.06496v1)|null|
|**2024-06-10**|**Scaling Continuous Latent Variable Models as Probabilistic Integral Circuits**|Gennaro Gala et.al.|[2406.06494v1](http://arxiv.org/abs/2406.06494v1)|null|
|**2024-06-10**|**Can Language Models Serve as Text-Based World Simulators?**|Ruoyao Wang et.al.|[2406.06485v1](http://arxiv.org/abs/2406.06485v1)|null|
|**2024-06-10**|**Parallelizing Linear Transformers with the Delta Rule over Sequence Length**|Songlin Yang et.al.|[2406.06484v1](http://arxiv.org/abs/2406.06484v1)|null|
|**2024-06-10**|**Towards a Personal Health Large Language Model**|Justin Cosentino et.al.|[2406.06474v1](http://arxiv.org/abs/2406.06474v1)|null|
|**2024-06-10**|**GKAN: Graph Kolmogorov-Arnold Networks**|Mehrdad Kiamari et.al.|[2406.06470v1](http://arxiv.org/abs/2406.06470v1)|null|
|**2024-06-10**|**Husky: A Unified, Open-Source Language Agent for Multi-Step Reasoning**|Joongwon Kim et.al.|[2406.06469v1](http://arxiv.org/abs/2406.06469v1)|[link](https://github.com/agent-husky/husky-v1)|
|**2024-06-10**|**How Far Can Transformers Reason? The Locality Barrier and Inductive Scratchpad**|Emmanuel Abbe et.al.|[2406.06467v1](http://arxiv.org/abs/2406.06467v1)|[link](https://github.com/aryol/inductive-scratchpad)|
|**2024-06-10**|**AID: Adapting Image2Video Diffusion Models for Instruction-guided Video Prediction**|Zhen Xing et.al.|[2406.06465v1](http://arxiv.org/abs/2406.06465v1)|null|
|**2024-06-10**|**Transforming Wearable Data into Health Insights using Large Language Model Agents**|Mike A. Merrill et.al.|[2406.06464v1](http://arxiv.org/abs/2406.06464v1)|null|
|**2024-06-10**|**Reasoning in Token Economies: Budget-Aware Evaluation of LLM Reasoning Strategies**|Junlin Wang et.al.|[2406.06461v1](http://arxiv.org/abs/2406.06461v1)|null|
|**2024-06-10**|**Evaluating the Retrieval Component in LLM-Based Question Answering Systems**|Ashkan Alinejad et.al.|[2406.06458v1](http://arxiv.org/abs/2406.06458v1)|null|
|**2024-06-10**|**A Large Language Model Pipeline for Breast Cancer Oncology**|Tristen Pool et.al.|[2406.06455v1](http://arxiv.org/abs/2406.06455v1)|null|
|**2024-06-10**|**Insights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course**|Aadarsh Padiyath et.al.|[2406.06451v1](http://arxiv.org/abs/2406.06451v1)|null|
|**2024-06-10**|**LLM Dataset Inference: Did you train on my dataset?**|Pratyush Maini et.al.|[2406.06443v1](http://arxiv.org/abs/2406.06443v1)|[link](https://github.com/pratyushmaini/llm_dataset_inference)|
|**2024-06-10**|**Interpretability of Language Models via Task Spaces**|Lucas Weber et.al.|[2406.06441v1](http://arxiv.org/abs/2406.06441v1)|null|
|**2024-06-10**|**Multimodal Contextualized Semantic Parsing from Speech**|Jordan Voas et.al.|[2406.06438v1](http://arxiv.org/abs/2406.06438v1)|null|
|**2024-06-10**|**Language Models are Alignable Decision-Makers: Dataset and Application to the Medical Triage Domain**|Brian Hu et.al.|[2406.06435v1](http://arxiv.org/abs/2406.06435v1)|[link](https://github.com/itm-kitware/llm-alignable-dm)|
|**2024-06-10**|**DISCO: An End-to-End Bandit Framework for Personalised Discount Allocation**|Jason Shuo Zhang et.al.|[2406.06433v1](http://arxiv.org/abs/2406.06433v1)|null|
|**2024-06-10**|**Explainable Graph Neural Networks Under Fire**|Zhong Li et.al.|[2406.06417v1](http://arxiv.org/abs/2406.06417v1)|null|
|**2024-06-10**|**Controlling Emotion in Text-to-Speech with Natural Language Prompts**|Thomas Bott et.al.|[2406.06406v1](http://arxiv.org/abs/2406.06406v1)|null|
|**2024-06-10**|**Meta Learning Text-to-Speech Synthesis in over 7000 Languages**|Florian Lux et.al.|[2406.06403v1](http://arxiv.org/abs/2406.06403v1)|null|
|**2024-06-10**|**INTERSPEECH 2009 Emotion Challenge Revisited: Benchmarking 15 Years of Progress in Speech Emotion Recognition**|Andreas Triantafyllopoulos et.al.|[2406.06401v1](http://arxiv.org/abs/2406.06401v1)|null|
|**2024-06-10**|**An Empirical Design Justice Approach to Identifying Ethical Considerations in the Intersection of Large Language Models and Social Robotics**|Alva Markelius et.al.|[2406.06400v1](http://arxiv.org/abs/2406.06400v1)|null|
|**2024-06-10**|**Should We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue**|Simone Alghisi et.al.|[2406.06399v1](http://arxiv.org/abs/2406.06399v1)|null|
|**2024-06-10**|**Contrastive learning of T cell receptor representations**|Yuta Nagano et.al.|[2406.06397v1](http://arxiv.org/abs/2406.06397v1)|null|
|**2024-06-10**|**Towards Lifelong Learning of Large Language Models: A Survey**|Junhao Zheng et.al.|[2406.06391v1](http://arxiv.org/abs/2406.06391v1)|null|
|**2024-06-10**|**Low-Rank Quantization-Aware Training for LLMs**|Yelysei Bondarenko et.al.|[2406.06385v1](http://arxiv.org/abs/2406.06385v1)|null|
|**2024-06-10**|**Diffusion-RPO: Aligning Diffusion Models through Relative Preference Optimization**|Yi Gu et.al.|[2406.06382v1](http://arxiv.org/abs/2406.06382v1)|[link](https://github.com/yigu1008/diffusion-rpo)|
|**2024-06-10**|**Improving Deep Learning-based Automatic Cranial Defect Reconstruction by Heavy Data Augmentation: From Image Registration to Latent Diffusion Models**|Marek Wodzinski et.al.|[2406.06372v1](http://arxiv.org/abs/2406.06372v1)|null|
|**2024-06-10**|**mHuBERT-147: A Compact Multilingual HuBERT Model**|Marcely Zanon Boito et.al.|[2406.06371v1](http://arxiv.org/abs/2406.06371v1)|null|
|**2024-06-10**|**Annotation alignment: Comparing LLM and human annotations of conversational safety**|Rajiv Movva et.al.|[2406.06369v1](http://arxiv.org/abs/2406.06369v1)|null|
|**2024-06-10**|**Symmetric Dot-Product Attention for Efficient Training of BERT Language Models**|Martin Courtois et.al.|[2406.06366v1](http://arxiv.org/abs/2406.06366v1)|null|
|**2024-06-10**|**MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows**|Xingjian Zhang et.al.|[2406.06357v1](http://arxiv.org/abs/2406.06357v1)|null|
|**2024-06-10**|**Predicting Heart Activity from Speech using Data-driven and Knowledge-based features**|Gasser Elbanna et.al.|[2406.06341v1](http://arxiv.org/abs/2406.06341v1)|null|
|**2024-06-10**|**Optimisation of federated learning settings under statistical heterogeneity variations**|Basem Suleiman et.al.|[2406.06340v1](http://arxiv.org/abs/2406.06340v1)|null|
|**2024-06-10**|**MedExQA: Medical Question Answering Benchmark with Multiple Explanations**|Yunsoo Kim et.al.|[2406.06331v1](http://arxiv.org/abs/2406.06331v1)|null|
|**2024-06-10**|**A Parameter-efficient Language Extension Framework for Multilingual ASR**|Wei Liu et.al.|[2406.06329v1](http://arxiv.org/abs/2406.06329v1)|null|
|**2024-06-10**|**Self-Tuning: Instructing LLMs to Effectively Acquire New Knowledge through Self-Teaching**|Xiaoying Zhang et.al.|[2406.06326v1](http://arxiv.org/abs/2406.06326v1)|null|
|**2024-06-10**|**Tx-LLM: A Large Language Model for Therapeutics**|Juan Manuel Zambrano Chaves et.al.|[2406.06316v1](http://arxiv.org/abs/2406.06316v1)|null|
|**2024-06-10**|**Multi-Prompting Decoder Helps Better Language Understanding**|Zifeng Cheng et.al.|[2406.06279v1](http://arxiv.org/abs/2406.06279v1)|null|
|**2024-06-10**|**MaskLID: Code-Switching Language Identification through Iterative Masking**|Amir Hossein Kargaran et.al.|[2406.06263v1](http://arxiv.org/abs/2406.06263v1)|[link](https://github.com/cisnlp/masklid)|
|**2024-06-10**|**Learning Fine-Grained Controllability on Speech Generation via Efficient Fine-Tuning**|Chung-Ming Chien et.al.|[2406.06251v1](http://arxiv.org/abs/2406.06251v1)|null|
|**2024-06-10**|**Data Augmentation in Earth Observation: A Diffusion Model Approach**|Tiago Sousa et.al.|[2406.06218v1](http://arxiv.org/abs/2406.06218v1)|null|
|**2024-06-10**|**A Statistical Theory of Regularization-Based Continual Learning**|Xuyang Zhao et.al.|[2406.06213v1](http://arxiv.org/abs/2406.06213v1)|null|
|**2024-06-10**|**2DP-2MRC: 2-Dimensional Pointer-based Machine Reading Comprehension Method for Multimodal Moment Retrieval**|Jiajun He et.al.|[2406.06201v1](http://arxiv.org/abs/2406.06201v1)|null|
|**2024-06-10**|**LINGOLY: A Benchmark of Olympiad-Level Linguistic Reasoning Puzzles in Low-Resource and Extinct Languages**|Andrew M. Bean et.al.|[2406.06196v1](http://arxiv.org/abs/2406.06196v1)|[link](https://github.com/am-bean/lingOly)|
|**2024-06-10**|**Generalized Nested Latent Variable Models for Lossy Coding applied to Wind Turbine Scenarios**|Raül Pérez-Gonzalo et.al.|[2406.06165v1](http://arxiv.org/abs/2406.06165v1)|null|
|**2024-06-10**|**Get rich quick: exact solutions reveal how unbalanced initializations promote rapid feature learning**|Daniel Kunin et.al.|[2406.06158v1](http://arxiv.org/abs/2406.06158v1)|null|
|**2024-06-10**|**Language Models Resist Alignment**|Jiaming Ji et.al.|[2406.06144v1](http://arxiv.org/abs/2406.06144v1)|null|
|**2024-06-10**|**Can I understand what I create? Self-Knowledge Evaluation of Large Language Models**|Zhiquan Tan et.al.|[2406.06140v1](http://arxiv.org/abs/2406.06140v1)|null|
|**2024-06-10**|**Thunder : Unified Regression-Diffusion Speech Enhancement with a Single Reverse Step using Brownian Bridge**|Thanapat Trachu et.al.|[2406.06139v1](http://arxiv.org/abs/2406.06139v1)|null|
|**2024-06-10**|**DiffInject: Revisiting Debias via Synthetic Data Generation using Diffusion-based Style Injection**|Donggeun Ko et.al.|[2406.06134v1](http://arxiv.org/abs/2406.06134v1)|null|
|**2024-06-10**|**Building Bridges: A Dataset for Evaluating Gender-Fair Machine Translation into German**|Manuel Lardelli et.al.|[2406.06131v1](http://arxiv.org/abs/2406.06131v1)|[link](https://github.com/g8a9/building-bridges-gender-fair-german-mt)|
|**2024-06-10**|**Verifiable Generation with Subsentence-Level Fine-Grained Citations**|Shuyang Cao et.al.|[2406.06125v1](http://arxiv.org/abs/2406.06125v1)|null|
|**2024-06-10**|**Enhancing Long-Term Memory using Hierarchical Aggregate Tree for Retrieval Augmented Generation**|Aadharsh Aadhithya A et.al.|[2406.06124v1](http://arxiv.org/abs/2406.06124v1)|null|
|**2024-06-10**|**JenGAN: Stacked Shifted Filters in GAN-Based Speech Synthesis**|Hyunjae Cho et.al.|[2406.06111v1](http://arxiv.org/abs/2406.06111v1)|null|
|**2024-06-10**|**Recurrent Context Compression: Efficiently Expanding the Context Window of LLM**|Chensen Huang et.al.|[2406.06110v1](http://arxiv.org/abs/2406.06110v1)|[link](https://github.com/WUHU-G/RCC_Transformer)|
|**2024-06-10**|**EXPIL: Explanatory Predicate Invention for Learning in Games**|Jingyuan Sha et.al.|[2406.06107v1](http://arxiv.org/abs/2406.06107v1)|null|
|**2024-06-10**|**StreamAtt: Direct Streaming Speech-to-Text Translation with Attention-based Audio History Selection**|Sara Papi et.al.|[2406.06097v1](http://arxiv.org/abs/2406.06097v1)|null|
|**2024-06-10**|**Efficient k-Nearest-Neighbor Machine Translation with Dynamic Retrieval**|Yan Gao et.al.|[2406.06073v1](http://arxiv.org/abs/2406.06073v1)|null|
|**2024-06-10**|**ProcessPainter: Learn Painting Process from Sequence Data**|Yiren Song et.al.|[2406.06062v1](http://arxiv.org/abs/2406.06062v1)|null|
|**2024-06-10**|**Greedy SLIM: A SLIM-Based Approach For Preference Elicitation**|Claudius Proissl et.al.|[2406.06061v1](http://arxiv.org/abs/2406.06061v1)|null|
|**2024-06-10**|**Synth-SBDH: A Synthetic Dataset of Social and Behavioral Determinants of Health for Clinical Text**|Avijit Mitra et.al.|[2406.06056v1](http://arxiv.org/abs/2406.06056v1)|[link](https://github.com/avipartho/synth-sbdh)|
|**2024-06-10**|**On the Utility of Accounting for Human Beliefs about AI Behavior in Human-AI Collaboration**|Guanghui Yu et.al.|[2406.06051v1](http://arxiv.org/abs/2406.06051v1)|null|
|**2024-06-10**|**Robust Latent Representation Tuning for Image-text Classification**|Hao Sun et.al.|[2406.06048v1](http://arxiv.org/abs/2406.06048v1)|null|
|**2024-06-10**|**MATES: Model-Aware Data Selection for Efficient Pretraining with Data Influence Models**|Zichun Yu et.al.|[2406.06046v1](http://arxiv.org/abs/2406.06046v1)|[link](https://github.com/cxcscmu/mates)|
|**2024-06-10**|**Synthesizing Efficient Data with Diffusion Models for Person Re-Identification Pre-Training**|Ke Niu et.al.|[2406.06045v1](http://arxiv.org/abs/2406.06045v1)|[link](https://github.com/keniu042/diffusion-reid)|
|**2024-06-10**|**Investigating Pre-Training Objectives for Generalization in Vision-Based Reinforcement Learning**|Donghu Kim et.al.|[2406.06037v1](http://arxiv.org/abs/2406.06037v1)|null|
|**2024-06-10**|**The Curse of Popularity: Popular Entities have Catastrophic Side Effects when Deleting Knowledge from Language Models**|Ryosuke Takahashi et.al.|[2406.06032v1](http://arxiv.org/abs/2406.06032v1)|null|
|**2024-06-10**|**HOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question Answering using LLMs**|Pranoy Panda et.al.|[2406.06027v1](http://arxiv.org/abs/2406.06027v1)|null|
|**2024-06-10**|**RepoQA: Evaluating Long Context Code Understanding**|Jiawei Liu et.al.|[2406.06025v1](http://arxiv.org/abs/2406.06025v1)|null|
|**2024-06-10**|**Shoulders of Giants: A Look at the Degree and Utility of Openness in NLP Research**|Surangika Ranathunga et.al.|[2406.06021v1](http://arxiv.org/abs/2406.06021v1)|null|
|**2024-06-10**|**Neuro-TransUNet: Segmentation of stroke lesion in MRI using transformers**|Muhammad Nouman et.al.|[2406.06017v1](http://arxiv.org/abs/2406.06017v1)|null|
|**2024-06-10**|**CARES: A Comprehensive Benchmark of Trustworthiness in Medical Vision Language Models**|Peng Xia et.al.|[2406.06007v1](http://arxiv.org/abs/2406.06007v1)|[link](https://github.com/richard-peng-xia/cares)|
|**2024-06-10**|**FLEUR: An Explainable Reference-Free Evaluation Metric for Image Captioning Using a Large Multimodal Model**|Yebin Lee et.al.|[2406.06004v1](http://arxiv.org/abs/2406.06004v1)|[link](https://github.com/yebin46/fleur)|
|**2024-06-10**|**ThaiCoref: Thai Coreference Resolution Dataset**|Pontakorn Trakuekul et.al.|[2406.06000v1](http://arxiv.org/abs/2406.06000v1)|[link](https://github.com/nlp-chula/thai-coref)|
|**2024-06-10**|**fSEAD: a Composable FPGA-based Streaming Ensemble Anomaly Detection Library**|Binglei Lou et.al.|[2406.05999v1](http://arxiv.org/abs/2406.05999v1)|[link](https://github.com/bingleilou/fsead)|
|**2024-06-10**|**A Dual-View Approach to Classifying Radiology Reports by Co-Training**|Yutong Han et.al.|[2406.05995v1](http://arxiv.org/abs/2406.05995v1)|[link](https://github.com/manga-uofa/radiology-cotrain)|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-10**|**ShiftAddLLM: Accelerating Pretrained LLMs via Post-Training Multiplication-Less Reparameterization**|Haoran You et.al.|[2406.05981v1](http://arxiv.org/abs/2406.05981v1)|null|
|**2024-06-10**|**Decision-Making Behavior Evaluation Framework for LLMs under Uncertain Context**|Jingru Jia et.al.|[2406.05972v1](http://arxiv.org/abs/2406.05972v1)|null|
|**2024-06-10**|**Prompting Large Language Models with Audio for General-Purpose Speech Summarization**|Wonjune Kang et.al.|[2406.05968v1](http://arxiv.org/abs/2406.05968v1)|null|
|**2024-06-10**|**CVQA: Culturally-diverse Multilingual Visual Question Answering Benchmark**|David Romero et.al.|[2406.05967v1](http://arxiv.org/abs/2406.05967v1)|null|
|**2024-06-10**|**MakeSinger: A Semi-Supervised Training Method for Data-Efficient Singing Voice Synthesis via Classifier-free Diffusion Guidance**|Semin Kim et.al.|[2406.05965v1](http://arxiv.org/abs/2406.05965v1)|null|
|**2024-06-10**|**Solution for SMART-101 Challenge of CVPR Multi-modal Algorithmic Reasoning Task 2024**|Jinwoo Ahn et.al.|[2406.05963v1](http://arxiv.org/abs/2406.05963v1)|null|
|**2024-06-10**|**Turbo Sparse: Achieving LLM SOTA Performance with Minimal Activated Parameters**|Yixin Song et.al.|[2406.05955v1](http://arxiv.org/abs/2406.05955v1)|null|
|**2024-06-10**|**Aligning Large Language Models with Representation Editing: A Control Perspective**|Lingkai Kong et.al.|[2406.05954v1](http://arxiv.org/abs/2406.05954v1)|null|
|**2024-06-10**|**Chain-of-Scrutiny: Detecting Backdoor Attacks for Large Language Models**|Xi Li et.al.|[2406.05948v1](http://arxiv.org/abs/2406.05948v1)|null|
|**2024-06-10**|**Safety Alignment Should Be Made More Than Just a Few Tokens Deep**|Xiangyu Qi et.al.|[2406.05946v1](http://arxiv.org/abs/2406.05946v1)|[link](https://github.com/unispac/shallow-vs-deep-alignment)|
|**2024-06-09**|**Semisupervised Neural Proto-Language Reconstruction**|Liang Lu et.al.|[2406.05930v1](http://arxiv.org/abs/2406.05930v1)|null|
|**2024-06-09**|**Hello Again! LLM-powered Personalized Agent for Long-term Dialogue**|Hao Li et.al.|[2406.05925v1](http://arxiv.org/abs/2406.05925v1)|null|
|**2024-06-09**|**Why Don't Prompt-Based Fairness Metrics Correlate?**|Abdelrahman Zayed et.al.|[2406.05918v1](http://arxiv.org/abs/2406.05918v1)|null|
|**2024-06-09**|**BD-SAT: High-resolution Land Use Land Cover Dataset & Benchmark Results for Developing Division: Dhaka, BD**|Ovi Paul et.al.|[2406.05912v1](http://arxiv.org/abs/2406.05912v1)|null|
|**2024-06-09**|**Feriji: A French-Zarma Parallel Corpus, Glossary & Translator**|Mamadou K. Keita et.al.|[2406.05888v1](http://arxiv.org/abs/2406.05888v1)|null|

#### Abstracts
##### **IllumiNeRF: 3D Relighting without Inverse Rendering**
2406.06527v1 by Xiaoming Zhao, Pratul P. Srinivasan, Dor Verbin, Keunhong Park, Ricardo Martin Brualla, Philipp Henzler

Existing methods for relightable view synthesis -- using a set of images of
an object under unknown lighting to recover a 3D representation that can be
rendered from novel viewpoints under a target illumination -- are based on
inverse rendering, and attempt to disentangle the object geometry, materials,
and lighting that explain the input images. Furthermore, this typically
involves optimization through differentiable Monte Carlo rendering, which is
brittle and computationally-expensive. In this work, we propose a simpler
approach: we first relight each input image using an image diffusion model
conditioned on lighting and then reconstruct a Neural Radiance Field (NeRF)
with these relit images, from which we render novel views under the target
lighting. We demonstrate that this strategy is surprisingly competitive and
achieves state-of-the-art results on multiple relighting benchmarks. Please see
our project page at https://illuminerf.github.io/.

摘要：現有的可重新點亮視圖合成方法 -- 使用一組在未知光源下拍攝的物件影像來還原 3D 呈現，以便在目標光源下從新視點渲染 -- 是基於反向渲染，並嘗試解開物件幾何形狀、材質和解釋輸入影像的光源。此外，這通常涉及透過可微分蒙地卡羅渲染進行最佳化，這既脆弱又需要大量運算。在這項工作中，我們提出一個更簡單的方法：我們首先使用基於光源條件的影像擴散模型重新點亮每個輸入影像，然後使用這些重新點亮的影像重建神經輻照場 (NeRF)，並從中在目標光源下渲染新視圖。我們證明此策略具有驚人的競爭力，並在多個重新點亮基準測試中達到最先進的成果。請參閱我們的專案頁面 https://illuminerf.github.io/。

##### **Decentralized Personalized Federated Learning**
2406.06520v1 by Salma Kharrat, Marco Canini, Samuel Horvath

This work tackles the challenges of data heterogeneity and communication
limitations in decentralized federated learning. We focus on creating a
collaboration graph that guides each client in selecting suitable collaborators
for training personalized models that leverage their local data effectively.
Our approach addresses these issues through a novel, communication-efficient
strategy that enhances resource efficiency. Unlike traditional methods, our
formulation identifies collaborators at a granular level by considering
combinatorial relations of clients, enhancing personalization while minimizing
communication overhead. We achieve this through a bi-level optimization
framework that employs a constrained greedy algorithm, resulting in a
resource-efficient collaboration graph for personalized learning. Extensive
evaluation against various baselines across diverse datasets demonstrates the
superiority of our method, named DPFL. DPFL consistently outperforms other
approaches, showcasing its effectiveness in handling real-world data
heterogeneity, minimizing communication overhead, enhancing resource
efficiency, and building personalized models in decentralized federated
learning scenarios.

摘要：这项工作解决了去中心化联邦学习中数据异质性和通信限制的挑战。我们专注于创建一个协作图，指导每个客户端选择合适的协作者来训练个性化模型，该模型有效利用其本地数据。我们的方法通过一种新颖的、通信效率高的策略来解决这些问题，该策略提高了资源效率。与传统方法不同，我们的公式通过考虑客户端的组合关系来细粒度地识别协作者，在最大程度减少通信开销的同时增强个性化。我们通过一个双层优化框架来实现这一点，该框架采用受约束的贪心算法，从而生成一个用于个性化学习的资源高效协作图。针对不同数据集的各种基准进行的广泛评估证明了我们名为 DPFL 的方法的优越性。DPFL 始终优于其他方法，展示了其在处理现实世界数据异质性、最小化通信开销、提高资源效率和在去中心化联邦学习场景中构建个性化模型方面的有效性。

##### **Merlin: A Vision Language Foundation Model for 3D Computed Tomography**
2406.06512v1 by Louis Blankemeier, Joseph Paul Cohen, Ashwin Kumar, Dave Van Veen, Syed Jamal Safdar Gardezi, Magdalini Paschali, Zhihong Chen, Jean-Benoit Delbrouck, Eduardo Reis, Cesar Truyts, Christian Bluethgen, Malte Engmann Kjeldskov Jensen, Sophie Ostmeier, Maya Varma, Jeya Maria Jose Valanarasu, Zhongnan Fang, Zepeng Huo, Zaid Nabulsi, Diego Ardila, Wei-Hung Weng, Edson Amaro Junior, Neera Ahuja, Jason Fries, Nigam H. Shah, Andrew Johnston, Robert D. Boutin, Andrew Wentland, Curtis P. Langlotz, Jason Hom, Sergios Gatidis, Akshay S. Chaudhari

Over 85 million computed tomography (CT) scans are performed annually in the
US, of which approximately one quarter focus on the abdomen. Given the current
radiologist shortage, there is a large impetus to use artificial intelligence
to alleviate the burden of interpreting these complex imaging studies. Prior
state-of-the-art approaches for automated medical image interpretation leverage
vision language models (VLMs). However, current medical VLMs are generally
limited to 2D images and short reports, and do not leverage electronic health
record (EHR) data for supervision. We introduce Merlin - a 3D VLM that we train
using paired CT scans (6+ million images from 15,331 CTs), EHR diagnosis codes
(1.8+ million codes), and radiology reports (6+ million tokens). We evaluate
Merlin on 6 task types and 752 individual tasks. The non-adapted
(off-the-shelf) tasks include zero-shot findings classification (31 findings),
phenotype classification (692 phenotypes), and zero-shot cross-modal retrieval
(image to findings and image to impressions), while model adapted tasks include
5-year disease prediction (6 diseases), radiology report generation, and 3D
semantic segmentation (20 organs). We perform internal validation on a test set
of 5,137 CTs, and external validation on 7,000 clinical CTs and on two public
CT datasets (VerSe, TotalSegmentator). Beyond these clinically-relevant
evaluations, we assess the efficacy of various network architectures and
training strategies to depict that Merlin has favorable performance to existing
task-specific baselines. We derive data scaling laws to empirically assess
training data needs for requisite downstream task performance. Furthermore,
unlike conventional VLMs that require hundreds of GPUs for training, we perform
all training on a single GPU.

摘要：<paragraph>美國每年執行超過 8500 萬次電腦斷層掃描 (CT)，其中約四分之一針對腹部。鑑於目前放射科醫師短缺，因此有很大的動力使用人工智慧來減輕詮釋這些複雜影像研究的負擔。先前自動化醫學影像詮釋的最新方法利用視覺語言模型 (VLM)。然而，目前的醫學 VLM 通常僅限於 2D 影像和簡短報告，而且不會利用電子健康紀錄 (EHR) 資料進行監督。我們介紹 Merlin，這是一個 3D VLM，我們使用配對的 CT 掃描（來自 15,331 個 CT 的 600 多萬張影像）、EHR 診斷碼（180 多萬個碼）和放射科報告（600 多萬個代碼）來訓練它。我們在 6 個任務類型和 752 個個別任務上評估 Merlin。非適應型（現成的）任務包括零次學習結果分類（31 個結果）、表型分類（692 個表型）和零次學習跨模態檢索（影像到結果和影像到印象），而模型適應任務包括 5 年疾病預測（6 種疾病）、放射科報告產生和 3D 語意分割（20 個器官）。我們在 5,137 個 CT 的測試集上執行內部驗證，並在 7,000 個臨床 CT 和兩個公開 CT 資料集（VerSe、TotalSegmentator）上執行外部驗證。除了這些與臨床相關的評估之外，我們還評估各種網路架構和訓練策略的效能，以說明 Merlin 在現有的特定任務基線上具有良好的效能。我們推導出資料擴充法則，以根據經驗評估下游任務效能所需的訓練資料需求。此外，與需要數百個 GPU 才能進行訓練的傳統 VLM 不同，我們在單一 GPU 上執行所有訓練。</paragraph>

##### **Monkey See, Monkey Do: Harnessing Self-attention in Motion Diffusion for Zero-shot Motion Transfer**
2406.06508v1 by Sigal Raab, Inbar Gat, Nathan Sala, Guy Tevet, Rotem Shalev-Arkushin, Ohad Fried, Amit H. Bermano, Daniel Cohen-Or

Given the remarkable results of motion synthesis with diffusion models, a
natural question arises: how can we effectively leverage these models for
motion editing? Existing diffusion-based motion editing methods overlook the
profound potential of the prior embedded within the weights of pre-trained
models, which enables manipulating the latent feature space; hence, they
primarily center on handling the motion space. In this work, we explore the
attention mechanism of pre-trained motion diffusion models. We uncover the
roles and interactions of attention elements in capturing and representing
intricate human motion patterns, and carefully integrate these elements to
transfer a leader motion to a follower one while maintaining the nuanced
characteristics of the follower, resulting in zero-shot motion transfer.
Editing features associated with selected motions allows us to confront a
challenge observed in prior motion diffusion approaches, which use general
directives (e.g., text, music) for editing, ultimately failing to convey subtle
nuances effectively. Our work is inspired by how a monkey closely imitates what
it sees while maintaining its unique motion patterns; hence we call it Monkey
See, Monkey Do, and dub it MoMo. Employing our technique enables accomplishing
tasks such as synthesizing out-of-distribution motions, style transfer, and
spatial editing. Furthermore, diffusion inversion is seldom employed for
motions; as a result, editing efforts focus on generated motions, limiting the
editability of real ones. MoMo harnesses motion inversion, extending its
application to both real and generated motions. Experimental results show the
advantage of our approach over the current art. In particular, unlike methods
tailored for specific applications through training, our approach is applied at
inference time, requiring no training. Our webpage is at
https://monkeyseedocg.github.io.

摘要：<paragraph>鉴于扩散模型在运动合成方面取得了显著成果，一个自然而然的问题出现了：我们如何有效地利用这些模型进行运动编辑？现有的基于扩散的运动编辑方法忽略了预训练模型权重中嵌入的先验的巨大潜力，而这使得操纵潜在特征空间成为可能；因此，它们主要集中于处理运动空间。在这项工作中，我们探索了预训练运动扩散模型的注意力机制。我们揭示了注意力元素在捕捉和表示复杂的人类运动模式中的作用和交互，并仔细整合这些元素，将一个引导者的运动转移给一个跟随者，同时保持跟随者的细微特征，从而实现零次运动转移。编辑与所选动作相关的特征使我们能够应对先前运动扩散方法中观察到的一个挑战，该方法使用一般指令（例如，文本、音乐）进行编辑，最终无法有效传达微妙的细微差别。我们的工作灵感来自于猴子在保持其独特运动模式的同时密切模仿它所看到的东西；因此，我们称之为 Monkey See，Monkey Do，并称之为 MoMo。采用我们的技术可以完成诸如合成分布外运动、风格迁移和空间编辑等任务。此外，扩散反演很少用于运动；因此，编辑工作集中在生成的运动上，限制了真实运动的可编辑性。MoMo 利用运动反演，将其应用扩展到真实运动和生成运动。实验结果表明了我们的方法优于当前技术。特别是，与通过训练针对特定应用程序的方法不同，我们的方法应用于推理时间，不需要训练。我们的网页位于 https://monkeyseedocg.github.io。</paragraph>

##### **Adaptive Opponent Policy Detection in Multi-Agent MDPs: Real-Time Strategy Switch Identification Using Running Error Estimation**
2406.06500v1 by Mohidul Haque Mridul, Mohammad Foysal Khan, Redwan Ahmed Rizvee, Md Mosaddek Khan

In Multi-agent Reinforcement Learning (MARL), accurately perceiving
opponents' strategies is essential for both cooperative and adversarial
contexts, particularly within dynamic environments. While Proximal Policy
Optimization (PPO) and related algorithms such as Actor-Critic with Experience
Replay (ACER), Trust Region Policy Optimization (TRPO), and Deep Deterministic
Policy Gradient (DDPG) perform well in single-agent, stationary environments,
they suffer from high variance in MARL due to non-stationary and hidden
policies of opponents, leading to diminished reward performance. Additionally,
existing methods in MARL face significant challenges, including the need for
inter-agent communication, reliance on explicit reward information, high
computational demands, and sampling inefficiencies. These issues render them
less effective in continuous environments where opponents may abruptly change
their policies without prior notice. Against this background, we present
OPS-DeMo (Online Policy Switch-Detection Model), an online algorithm that
employs dynamic error decay to detect changes in opponents' policies. OPS-DeMo
continuously updates its beliefs using an Assumed Opponent Policy (AOP) Bank
and selects corresponding responses from a pre-trained Response Policy Bank.
Each response policy is trained against consistently strategizing opponents,
reducing training uncertainty and enabling the effective use of algorithms like
PPO in multi-agent environments. Comparative assessments show that our approach
outperforms PPO-trained models in dynamic scenarios like the Predator-Prey
setting, providing greater robustness to sudden policy shifts and enabling more
informed decision-making through precise opponent policy insights.

摘要：在多智能體強化學習 (MARL) 中，準確感知對手的策略對於合作和對抗環境都至關重要，特別是在動態環境中。雖然近端策略優化 (PPO) 和相關演算法，例如帶有經驗回放的動作-評論家 (ACER)、信任區域策略優化 (TRPO) 和深度確定性策略梯度 (DDPG) 在單一智能體、靜態環境中表現良好，但它們在 MARL 中會因對手的非平穩性和隱藏策略而導致高差異，從而降低獎勵表現。此外，MARL 中現有的方法面臨重大挑戰，包括需要智能體間通訊、依賴明確的獎勵資訊、高計算需求和取樣效率低下。這些問題使得它們在連續環境中效果較差，在連續環境中，對手可能會在沒有事先通知的情況下突然改變他們的策略。在此背景下，我們提出了 OPS-DeMo（線上策略切換檢測模型），這是一種線上演算法，採用動態誤差衰減來檢測對手策略的變化。OPS-DeMo 使用假設對手策略 (AOP) 庫持續更新其信念，並從預先訓練的回應策略庫中選擇相應的回應。每個回應策略針對持續制定策略的對手進行訓練，減少訓練不確定性，並使 PPO 等演算法在多智能體環境中得到有效使用。比較評估表明，我們的做法在動態場景（如掠食者-獵物設定）中優於 PPO 訓練模型，對突然的策略轉變提供了更高的魯棒性，並通過準確的對手策略見解實現更明智的決策制定。

##### **Direct Preference Optimization for Suppressing Hallucinated Prior Exams in Radiology Report Generation**
2406.06496v1 by Oishi Banerjee, Hong-Yu Zhou, Subathra Adithan, Stephen Kwak, Kay Wu, Pranav Rajpurkar

Recent advances in generative vision-language models (VLMs) have exciting
potential implications for AI in radiology, yet VLMs are also known to produce
hallucinations, nonsensical text, and other unwanted behaviors that can waste
clinicians' time and cause patient harm. Drawing on recent work on direct
preference optimization (DPO), we propose a simple method for modifying the
behavior of pretrained VLMs performing radiology report generation by
suppressing unwanted types of generations. We apply our method to the
prevention of hallucinations of prior exams, addressing a long-established
problem behavior in models performing chest X-ray report generation. Across our
experiments, we find that DPO fine-tuning achieves a 3.2-4.8x reduction in
lines hallucinating prior exams while maintaining model performance on clinical
accuracy metrics. Our work is, to the best of our knowledge, the first work to
apply DPO to medical VLMs, providing a data- and compute- efficient way to
suppress problem behaviors while maintaining overall clinical accuracy.

摘要：生成式視覺語言模型 (VLM) 的最新進展對於放射學中的 AI 具有令人興奮的潛在影響，但 VLM 也會產生幻覺、無意義的文字和其他不需要的行為，這些行為可能會浪費臨床醫生的時間並造成病患傷害。利用最近關於直接偏好最佳化 (DPO) 的研究，我們提出了一個簡單的方法來修改執行放射學報告產生的預訓練 VLM 行為，方法是抑制不需要的產生類型。我們將方法應用於防止先前檢查的幻覺，解決執行胸部 X 光報告產生的模型中長期存在的問題行為。在我們的實驗中，我們發現 DPO 微調可將幻覺先前檢查的行數減少 3.2-4.8 倍，同時維持模型在臨床準確性指標上的表現。據我們所知，我們的研究是第一個將 DPO 應用於醫療 VLM 的研究，提供一種資料和運算有效率的方法，可以在維持整體臨床準確性的同時抑制問題行為。

##### **Scaling Continuous Latent Variable Models as Probabilistic Integral Circuits**
2406.06494v1 by Gennaro Gala, Cassio de Campos, Antonio Vergari, Erik Quaeghebeur

Probabilistic integral circuits (PICs) have been recently introduced as
probabilistic models enjoying the key ingredient behind expressive generative
models: continuous latent variables (LVs). PICs are symbolic computational
graphs defining continuous LV models as hierarchies of functions that are
summed and multiplied together, or integrated over some LVs. They are tractable
if LVs can be analytically integrated out, otherwise they can be approximated
by tractable probabilistic circuits (PC) encoding a hierarchical numerical
quadrature process, called QPCs.
  So far, only tree-shaped PICs have been explored, and training them via
numerical quadrature requires memory-intensive processing at scale. In this
paper, we address these issues, and present: (i) a pipeline for building
DAG-shaped PICs out of arbitrary variable decompositions, (ii) a procedure for
training PICs using tensorized circuit architectures, and (iii) neural
functional sharing techniques to allow scalable training. In extensive
experiments, we showcase the effectiveness of functional sharing and the
superiority of QPCs over traditional PCs.

摘要：機率積分電路 (PIC) 最近被引入為機率模型，享有表現性生成模型背後的關鍵成分：連續潛在變數 (LV)。PIC 是符號運算圖形，定義連續 LV 模型為函數層級架構，這些函數會相加、相乘或在某些 LV 上進行積分。如果 LV 可以分析性地積分出來，它們就是可處理的，否則它們可以用編碼層級數值正交過程的可處理機率電路 (PC) 來近似，稱為 QPC。
到目前為止，只有樹狀 PIC 被探索，而透過數值正交訓練它們需要大量記憶體的處理。在本文中，我們探討這些問題，並提出：(i) 一個用於建構出任意變數分解的 DAG 形狀 PIC 的管道，(ii) 一個用於使用張量化電路架構訓練 PIC 的程序，以及 (iii) 神經功能共享技術，以允許可擴充的訓練。在大量的實驗中，我們展示了功能共享的有效性，以及 QPC 優於傳統 PC 的優越性。

##### **Can Language Models Serve as Text-Based World Simulators?**
2406.06485v1 by Ruoyao Wang, Graham Todd, Ziang Xiao, Xingdi Yuan, Marc-Alexandre Côté, Peter Clark, Peter Jansen

Virtual environments play a key role in benchmarking advances in complex
planning and decision-making tasks but are expensive and complicated to build
by hand. Can current language models themselves serve as world simulators,
correctly predicting how actions change different world states, thus bypassing
the need for extensive manual coding? Our goal is to answer this question in
the context of text-based simulators. Our approach is to build and use a new
benchmark, called ByteSized32-State-Prediction, containing a dataset of text
game state transitions and accompanying game tasks. We use this to directly
quantify, for the first time, how well LLMs can serve as text-based world
simulators. We test GPT-4 on this dataset and find that, despite its impressive
performance, it is still an unreliable world simulator without further
innovations. This work thus contributes both new insights into current LLM's
capabilities and weaknesses, as well as a novel benchmark to track future
progress as new models appear.

摘要：虛擬環境在複雜規劃和決策任務中的基準進展中扮演關鍵角色，但手動建構既昂貴又複雜。目前的語言模型本身能作為世界模擬器嗎？正確預測動作如何改變不同的世界狀態，從而繞過廣泛手動編碼的需要？我們的目標是在基於文字的模擬器背景下回答這個問題。我們的做法是建構並使用一個名為 ByteSized32-State-Prediction 的新基準，其中包含一個文字遊戲狀態轉換和隨附遊戲任務的資料集。我們使用它來直接量化，這是第一次，LLM 如何作為基於文字的世界模擬器。我們在這個資料集上測試了 GPT-4，發現儘管它表現出色，但它仍然是一個不可靠的世界模擬器，沒有進一步的創新。因此，這項工作既為當前 LLM 的能力和弱點提供了新的見解，也為隨著新模型的出現而追蹤未來進展提供了一個新的基準。

##### **Parallelizing Linear Transformers with the Delta Rule over Sequence Length**
2406.06484v1 by Songlin Yang, Bailin Wang, Yu Zhang, Yikang Shen, Yoon Kim

Transformers with linear attention (i.e., linear transformers) and
state-space models have recently been suggested as a viable linear-time
alternative to transformers with softmax attention. However, these models still
underperform transformers especially on tasks that require in-context
retrieval. While more expressive variants of linear transformers which replace
the additive outer-product update in linear transformers with the delta rule
have been found to be more effective at associative recall, existing algorithms
for training such models do not parallelize over sequence length and are thus
inefficient to train on modern hardware. This work describes a
hardware-efficient algorithm for training linear transformers with the delta
rule, which exploits a memory-efficient representation for computing products
of Householder matrices. This algorithm allows us to scale up DeltaNet to
standard language modeling settings. We train a 1.3B model for 100B tokens and
find that it outperforms recent linear-time baselines such as Mamba and GLA in
terms of perplexity and zero-shot performance on downstream tasks (including on
tasks that focus on recall). We also experiment with two hybrid models which
combine DeltaNet layers with (1) sliding-window attention layers every other
layer or (2) two global attention layers, and find that these hybrid models
outperform strong transformer baselines.

摘要：帶有線性注意力（即線性Transformer）的Transformer和狀態空間模型最近已被建議作為具有 softmax 注意力的Transformer的可行的線性時間替代方案。然而，這些模型仍然表現不佳，特別是在需要上下文檢索的任務上。雖然已經發現用 delta 規則替換線性Transformer中的加法外積更新的線性Transformer的更具表現力的變體在聯想召回方面更有效，但現有的訓練此類模型的演算法並未在序列長度上並行化，因此在現代硬體上訓練效率低下。這項工作描述了一種用於訓練具有 delta 規則的線性Transformer的硬體高效演算法，該演算法利用記憶體高效的表示來計算 Householder 矩陣的乘積。此演算法允許我們將 DeltaNet 擴展到標準語言建模設定。我們訓練了一個 1.3B 模型，用於 100B 個代幣，並發現它在困惑度和下游任務的零次學習效能方面優於最近的線性時間基線，例如 Mamba 和 GLA（包括專注於召回的任務）。我們還對兩種混合模型進行了實驗，這些模型將 DeltaNet 層與（1）每隔一層的滑動視窗注意力層或（2）兩個全局注意力層結合在一起，並發現這些混合模型優於強大的Transformer基線。

##### **Towards a Personal Health Large Language Model**
2406.06474v1 by Justin Cosentino, Anastasiya Belyaeva, Xin Liu, Nicholas A. Furlotte, Zhun Yang, Chace Lee, Erik Schenck, Yojan Patel, Jian Cui, Logan Douglas Schneider, Robby Bryant, Ryan G. Gomes, Allen Jiang, Roy Lee, Yun Liu, Javier Perez, Jameson K. Rogers, Cathy Speed, Shyam Tailor, Megan Walker, Jeffrey Yu, Tim Althoff, Conor Heneghan, John Hernandez, Mark Malhotra, Leor Stern, Yossi Matias, Greg S. Corrado, Shwetak Patel, Shravya Shetty, Jiening Zhan, Shruthi Prabhakara, Daniel McDuff, Cory Y. McLean

In health, most large language model (LLM) research has focused on clinical
tasks. However, mobile and wearable devices, which are rarely integrated into
such tasks, provide rich, longitudinal data for personal health monitoring.
Here we present Personal Health Large Language Model (PH-LLM), fine-tuned from
Gemini for understanding and reasoning over numerical time-series personal
health data. We created and curated three datasets that test 1) production of
personalized insights and recommendations from sleep patterns, physical
activity, and physiological responses, 2) expert domain knowledge, and 3)
prediction of self-reported sleep outcomes. For the first task we designed 857
case studies in collaboration with domain experts to assess real-world
scenarios in sleep and fitness. Through comprehensive evaluation of
domain-specific rubrics, we observed that Gemini Ultra 1.0 and PH-LLM are not
statistically different from expert performance in fitness and, while experts
remain superior for sleep, fine-tuning PH-LLM provided significant improvements
in using relevant domain knowledge and personalizing information for sleep
insights. We evaluated PH-LLM domain knowledge using multiple choice sleep
medicine and fitness examinations. PH-LLM achieved 79% on sleep and 88% on
fitness, exceeding average scores from a sample of human experts. Finally, we
trained PH-LLM to predict self-reported sleep quality outcomes from textual and
multimodal encoding representations of wearable data, and demonstrate that
multimodal encoding is required to match performance of specialized
discriminative models. Although further development and evaluation are
necessary in the safety-critical personal health domain, these results
demonstrate both the broad knowledge and capabilities of Gemini models and the
benefit of contextualizing physiological data for personal health applications
as done with PH-LLM.

摘要：在健康領域，大多數大型語言模型 (LLM) 研究都專注於臨床任務。然而，行動裝置和穿戴式裝置很少整合到此類任務中，但它們會提供豐富的縱向資料，用於個人健康監控。在這裡，我們提出個人健康大型語言模型 (PH-LLM)，經過 Gemini 微調，用於理解和推理數值時間序列個人健康資料。我們建立並策劃了三個測試資料集，用於測試 1) 從睡眠模式、身體活動和生理反應中產生個人化見解和建議，2) 專家領域知識，以及 3) 預測自我報告的睡眠結果。對於第一個任務，我們與領域專家合作設計了 857 個案例研究，以評估睡眠和健身的真實情況。透過對特定領域評分標準的全面評估，我們觀察到 Gemini Ultra 1.0 和 PH-LLM 在健身方面的表現與專家表現沒有統計學差異，而專家在睡眠方面的表現仍然較佳，但微調 PH-LLM 在使用相關領域知識和個人化睡眠見解資訊方面提供了顯著改進。我們使用多選題睡眠醫學和健身檢查評估 PH-LLM 領域知識。PH-LLM 在睡眠方面達到 79%，在健身方面達到 88%，超過了部分人類專家的平均分數。最後，我們訓練 PH-LLM 從可穿戴資料的文字和多模態編碼表示中預測自我報告的睡眠品質結果，並證明多模態編碼對於匹配特殊辨別模型的效能是必要的。儘管在安全關鍵的個人健康領域中需要進一步的開發和評估，但這些結果證明了 Gemini 模型的廣泛知識和功能，以及使用 PH-LLM 對生理資料進行情境化以用於個人健康應用程式的優點。

##### **GKAN: Graph Kolmogorov-Arnold Networks**
2406.06470v1 by Mehrdad Kiamari, Mohammad Kiamari, Bhaskar Krishnamachari

We introduce Graph Kolmogorov-Arnold Networks (GKAN), an innovative neural
network architecture that extends the principles of the recently proposed
Kolmogorov-Arnold Networks (KAN) to graph-structured data. By adopting the
unique characteristics of KANs, notably the use of learnable univariate
functions instead of fixed linear weights, we develop a powerful model for
graph-based learning tasks. Unlike traditional Graph Convolutional Networks
(GCNs) that rely on a fixed convolutional architecture, GKANs implement
learnable spline-based functions between layers, transforming the way
information is processed across the graph structure. We present two different
ways to incorporate KAN layers into GKAN: architecture 1 -- where the learnable
functions are applied to input features after aggregation and architecture 2 --
where the learnable functions are applied to input features before aggregation.
We evaluate GKAN empirically using a semi-supervised graph learning task on a
real-world dataset (Cora). We find that architecture generally performs better.
We find that GKANs achieve higher accuracy in semi-supervised learning tasks on
graphs compared to the traditional GCN model. For example, when considering 100
features, GCN provides an accuracy of 53.5 while a GKAN with a comparable
number of parameters gives an accuracy of 61.76; with 200 features, GCN
provides an accuracy of 61.24 while a GKAN with a comparable number of
parameters gives an accuracy of 67.66. We also present results on the impact of
various parameters such as the number of hidden nodes, grid-size, and the
polynomial-degree of the spline on the performance of GKAN.

摘要：<paragraph>我們介紹圖形柯爾莫哥洛夫-阿諾德網路 (GKAN)，這是一種創新的神經網路架構，它將最近提出的柯爾莫哥洛夫-阿諾德網路 (KAN) 原理擴展到圖形結構資料。透過採用 KAN 的獨特特性，特別是使用可學習的單變量函數代替固定的線性權重，我們開發了一個用於基於圖形的學習任務的強大模型。與依賴於固定卷積架構的傳統圖形卷積網路 (GCN) 不同，GKAN 在層之間實作可學習的基於樣條的函數，轉換了在圖形結構中處理資訊的方式。我們提出兩種不同的方式將 KAN 層納入 GKAN：架構 1 -- 其中可學習的函數在聚合後應用於輸入特徵，以及架構 2 -- 其中可學習的函數在聚合前應用於輸入特徵。我們使用真實世界資料集 (Cora) 上的半監督圖形學習任務，對 GKAN 進行經驗評估。我們發現架構 1 通常表現得更好。我們發現，與傳統 GCN 模型相比，GKAN 在圖形上的半監督學習任務中獲得更高的準確度。例如，在考慮 100 個特徵時，GCN 提供 53.5 的準確度，而具有可比參數數量的 GKAN 提供 61.76 的準確度；對於 200 個特徵，GCN 提供 61.24 的準確度，而具有可比參數數量的 GKAN 提供 67.66 的準確度。我們還提供了各種參數對 GKAN 效能的影響的結果，例如隱藏節點數、網格大小和樣條的多項式次數。</paragraph>

##### **Husky: A Unified, Open-Source Language Agent for Multi-Step Reasoning**
2406.06469v1 by Joongwon Kim, Bhargavi Paranjape, Tushar Khot, Hannaneh Hajishirzi

Language agents perform complex tasks by using tools to execute each step
precisely. However, most existing agents are based on proprietary models or
designed to target specific tasks, such as mathematics or multi-hop question
answering. We introduce Husky, a holistic, open-source language agent that
learns to reason over a unified action space to address a diverse set of
complex tasks involving numerical, tabular, and knowledge-based reasoning.
Husky iterates between two stages: 1) generating the next action to take
towards solving a given task and 2) executing the action using expert models
and updating the current solution state. We identify a thorough ontology of
actions for addressing complex tasks and curate high-quality data to train
expert models for executing these actions. Our experiments show that Husky
outperforms prior language agents across 14 evaluation datasets. Moreover, we
introduce HuskyQA, a new evaluation set which stress tests language agents for
mixed-tool reasoning, with a focus on retrieving missing knowledge and
performing numerical reasoning. Despite using 7B models, Husky matches or even
exceeds frontier LMs such as GPT-4 on these tasks, showcasing the efficacy of
our holistic approach in addressing complex reasoning problems. Our code and
models are available at https://github.com/agent-husky/Husky-v1.

摘要：語言代理透過使用工具精確執行每個步驟來執行複雜的任務。然而，大多數現有的代理基於專有模型或設計用於針對特定任務，例如數學或多跳問題回答。我們介紹 Husky，一個整體、開源的語言代理，它學習在統一的動作空間中進行推理，以解決涉及數字、表格和基於知識的推理的多種複雜任務。Husky 在兩個階段之間進行反覆運算：1) 為了解決給定的任務而產生下一個要執行的動作，以及 2) 使用專家模型執行動作並更新當前的解決方案狀態。我們識別出一個用於解決複雜任務的徹底動作本體，並整理高品質的資料來訓練專家模型以執行這些動作。我們的實驗顯示，Husky 在 14 個評估資料集中的表現優於先前的語言代理。此外，我們引入了 HuskyQA，這是一個新的評估集，它針對混合工具推理對語言代理進行壓力測試，重點是擷取遺失的知識和執行數字推理。儘管使用了 7B 模型，但 Husky 在這些任務上匹配或甚至超過了 GPT-4 等前沿 LM，展示了我們整體方法在解決複雜推理問題中的功效。我們的程式碼和模型可在 https://github.com/agent-husky/Husky-v1 中取得。

##### **How Far Can Transformers Reason? The Locality Barrier and Inductive Scratchpad**
2406.06467v1 by Emmanuel Abbe, Samy Bengio, Aryo Lotfi, Colin Sandon, Omid Saremi

Can Transformers predict new syllogisms by composing established ones? More
generally, what type of targets can be learned by such models from scratch?
Recent works show that Transformers can be Turing-complete in terms of
expressivity, but this does not address the learnability objective. This paper
puts forward the notion of 'distribution locality' to capture when weak
learning is efficiently achievable by regular Transformers, where the locality
measures the least number of tokens required in addition to the tokens
histogram to correlate nontrivially with the target. As shown experimentally
and theoretically under additional assumptions, distributions with high
locality cannot be learned efficiently. In particular, syllogisms cannot be
composed on long chains. Furthermore, we show that (i) an agnostic scratchpad
cannot help to break the locality barrier, (ii) an educated scratchpad can help
if it breaks the locality at each step, (iii) a notion of 'inductive
scratchpad' can both break the locality and improve the out-of-distribution
generalization, e.g., generalizing to almost double input size for some
arithmetic tasks.

摘要：Transformer 能否透過組合已建立的三段論法來預測新的三段論法？更普遍地說，此類模型可以從頭學習哪種類型的目標？最近的研究顯示，Transformer 在表達能力方面可以是圖靈完備的，但這並未解決可學習性目標。本文提出了「分佈局部性」的概念，以捕捉在正規 Transformer 中何時可以有效達成弱學習，其中局部性衡量除了直方圖之外，與目標非平凡地相關聯所需的最小令牌數。如在額外的假設下透過實驗和理論所示，具有高局部性的分佈無法有效學習。特別是，三段論法無法在長鏈上組成。此外，我們證明 (i) 不可知備忘錄無法協助突破局部性障礙，(ii) 受過教育的備忘錄如果在每個步驟中打破局部性，就能提供協助，(iii) 「歸納備忘錄」的概念既能打破局部性，又能改善分佈外概化，例如，對於某些算術任務，概化到幾乎是輸入大小的兩倍。

##### **AID: Adapting Image2Video Diffusion Models for Instruction-guided Video Prediction**
2406.06465v1 by Zhen Xing, Qi Dai, Zejia Weng, Zuxuan Wu, Yu-Gang Jiang

Text-guided video prediction (TVP) involves predicting the motion of future
frames from the initial frame according to an instruction, which has wide
applications in virtual reality, robotics, and content creation. Previous TVP
methods make significant breakthroughs by adapting Stable Diffusion for this
task. However, they struggle with frame consistency and temporal stability
primarily due to the limited scale of video datasets. We observe that
pretrained Image2Video diffusion models possess good priors for video dynamics
but they lack textual control. Hence, transferring Image2Video models to
leverage their video dynamic priors while injecting instruction control to
generate controllable videos is both a meaningful and challenging task. To
achieve this, we introduce the Multi-Modal Large Language Model (MLLM) to
predict future video states based on initial frames and text instructions. More
specifically, we design a dual query transformer (DQFormer) architecture, which
integrates the instructions and frames into the conditional embeddings for
future frame prediction. Additionally, we develop Long-Short Term Temporal
Adapters and Spatial Adapters that can quickly transfer general video diffusion
models to specific scenarios with minimal training costs. Experimental results
show that our method significantly outperforms state-of-the-art techniques on
four datasets: Something Something V2, Epic Kitchen-100, Bridge Data, and
UCF-101. Notably, AID achieves 91.2% and 55.5% FVD improvements on Bridge and
SSv2 respectively, demonstrating its effectiveness in various domains. More
examples can be found at our website https://chenhsing.github.io/AID.

摘要：<paragraph>文字引導影片預測 (TVP) 涉及根據指令從初始影格預測未來影格的動作，這在虛擬實境、機器人和內容創作中具有廣泛的應用。先前的 TVP 方法通過調整 Stable Diffusion 來執行這項任務，取得重大的突破。然而，它們面臨影格一致性和時間穩定性的問題，主要是由於影片資料集的規模有限。我們觀察到預訓練的 Image2Video diffusion 模型擁有良好的影片動態先驗，但它們缺乏文字控制。因此，將 Image2Video 模型轉移以利用其影片動態先驗，同時注入指令控制以產生可控制影片，這是一項有意義且具有挑戰性的任務。為了達成此目的，我們引入了多模態大型語言模型 (MLLM) 來根據初始影格和文字指令預測未來的影片狀態。更具體地說，我們設計了雙查詢轉換器 (DQFormer) 架構，它將指令和影格整合到未來影格預測的條件嵌入中。此外，我們開發了長短期時間適配器和空間適配器，它們可以快速將一般影片 diffusion 模型轉移到特定場景，且訓練成本極低。實驗結果顯示，我們的模型在四個資料集上明顯優於最先進的技術：Something Something V2、Epic Kitchen-100、Bridge Data 和 UCF-101。值得注意的是，AID 分別在 Bridge 和 SSv2 上達到了 91.2% 和 55.5% 的 FVD 改進，證明了它在各種領域的有效性。更多範例可以在我們的網站 https://chenhsing.github.io/AID 中找到。</paragraph>

##### **Transforming Wearable Data into Health Insights using Large Language Model Agents**
2406.06464v1 by Mike A. Merrill, Akshay Paruchuri, Naghmeh Rezaei, Geza Kovacs, Javier Perez, Yun Liu, Erik Schenck, Nova Hammerquist, Jake Sunshine, Shyam Tailor, Kumar Ayush, Hao-Wei Su, Qian He, Cory McLean, Mark Malhotra, Shwetak Patel, Jiening Zhan, Tim Althoff, Daniel McDuff, Xin Liu

Despite the proliferation of wearable health trackers and the importance of
sleep and exercise to health, deriving actionable personalized insights from
wearable data remains a challenge because doing so requires non-trivial
open-ended analysis of these data. The recent rise of large language model
(LLM) agents, which can use tools to reason about and interact with the world,
presents a promising opportunity to enable such personalized analysis at scale.
Yet, the application of LLM agents in analyzing personal health is still
largely untapped. In this paper, we introduce the Personal Health Insights
Agent (PHIA), an agent system that leverages state-of-the-art code generation
and information retrieval tools to analyze and interpret behavioral health data
from wearables. We curate two benchmark question-answering datasets of over
4000 health insights questions. Based on 650 hours of human and expert
evaluation we find that PHIA can accurately address over 84% of factual
numerical questions and more than 83% of crowd-sourced open-ended questions.
This work has implications for advancing behavioral health across the
population, potentially enabling individuals to interpret their own wearable
data, and paving the way for a new era of accessible, personalized wellness
regimens that are informed by data-driven insights.

摘要：儘管可穿戴健康追蹤器激增，且睡眠和運動對健康至關重要，但從可穿戴裝置資料中得出可行的個人化見解仍然是一項挑戰，因為這麼做需要對這些資料進行重要的開放式分析。最近大型語言模型 (LLM) 代理程式興起，可以使用工具對世界進行推理和互動，這提供了在規模上進行此類個人化分析的絕佳機會。然而，LLM 代理程式在分析個人健康方面的應用仍未得到充分開發。在本文中，我們介紹了個人健康見解代理 (PHIA)，這是一個代理系統，它利用最先進的程式碼產生和資訊檢索工具來分析和詮釋來自可穿戴裝置的行為健康資料。我們策劃了兩個基準問題解答資料集，包含超過 4000 個健康見解問題。根據 650 小時的人員和專家評估，我們發現 PHIA 能夠準確回答超過 84% 的事實性數字問題和超過 83% 的群眾外包開放式問題。這項工作對促進全體人口的行為健康具有影響，潛在地使個人能夠詮釋他們自己的可穿戴裝置資料，並為一個由資料驅動的見解所揭示的新時代的平易近人、個人化的健康養生法鋪平道路。

##### **Reasoning in Token Economies: Budget-Aware Evaluation of LLM Reasoning Strategies**
2406.06461v1 by Junlin Wang, Siddhartha Jain, Dejiao Zhang, Baishakhi Ray, Varun Kumar, Ben Athiwaratkun

A diverse array of reasoning strategies has been proposed to elicit the
capabilities of large language models. However, in this paper, we point out
that traditional evaluations which focus solely on performance metrics miss a
key factor: the increased effectiveness due to additional compute. By
overlooking this aspect, a skewed view of strategy efficiency is often
presented. This paper introduces a framework that incorporates the compute
budget into the evaluation, providing a more informative comparison that takes
into account both performance metrics and computational cost. In this
budget-aware perspective, we find that complex reasoning strategies often don't
surpass simpler baselines purely due to algorithmic ingenuity, but rather due
to the larger computational resources allocated. When we provide a simple
baseline like chain-of-thought self-consistency with comparable compute
resources, it frequently outperforms reasoning strategies proposed in the
literature. In this scale-aware perspective, we find that unlike
self-consistency, certain strategies such as multi-agent debate or Reflexion
can become worse if more compute budget is utilized.

摘要：<paragraph>已提出各種不同的推理策略來引出大型語言模型的能力。然而，在本文中，我們指出僅專注於效能指標的傳統評估遺漏了一個關鍵因素：由於額外運算而增加的效能。透過忽略這個面向，通常會呈現出策略效率的偏差觀點。本文介紹了一個將運算預算納入評估的架構，提供了一個更具參考性的比較，同時考量效能指標和運算成本。在這個考量預算的觀點中，我們發現複雜的推理策略通常並非僅由於演算法的巧妙而超越更簡單的基準，而是由於配置了更大的運算資源。當我們提供一個簡單的基準，例如具有可比運算資源的思想鏈自洽性時，它經常優於文獻中提出的推理策略。在這個考量規模的觀點中，我們發現與自洽性不同，某些策略（例如多主體辯論或 Reflexion）在使用更多運算預算時可能會變得更糟。</paragraph>

##### **Evaluating the Retrieval Component in LLM-Based Question Answering Systems**
2406.06458v1 by Ashkan Alinejad, Krtin Kumar, Ali Vahdat

Question answering systems (QA) utilizing Large Language Models (LLMs)
heavily depend on the retrieval component to provide them with domain-specific
information and reduce the risk of generating inaccurate responses or
hallucinations. Although the evaluation of retrievers dates back to the early
research in Information Retrieval, assessing their performance within LLM-based
chatbots remains a challenge.
  This study proposes a straightforward baseline for evaluating retrievers in
Retrieval-Augmented Generation (RAG)-based chatbots. Our findings demonstrate
that this evaluation framework provides a better image of how the retriever
performs and is more aligned with the overall performance of the QA system.
Although conventional metrics such as precision, recall, and F1 score may not
fully capture LLMs' capabilities - as they can yield accurate responses despite
imperfect retrievers - our method considers LLMs' strengths to ignore
irrelevant contexts, as well as potential errors and hallucinations in their
responses.

摘要：問題回答系統（QA）利用大型語言模型（LLM），高度依賴檢索組件提供特定領域的資訊，並降低產生不準確的回應或幻覺的風險。雖然檢索器的評估可以追溯到資訊檢索的早期研究，但在基於 LLM 的聊天機器人中評估其效能仍然是一項挑戰。
本研究提出了一個直接的基線，用於評估基於檢索增強生成（RAG）的聊天機器人中的檢索器。我們的研究結果表明，這個評估架構提供了檢索器效能的更佳影像，並且更符合 QA 系統的整體效能。雖然傳統指標，例如準確度、召回率和 F1 分數，可能無法完全捕捉 LLM 的功能，因為它們可以產生準確的回應，儘管檢索器不完美，但我們的的方法考慮了 LLM 的優勢，以忽略不相關的內容，以及其回應中潛在的錯誤和幻覺。

##### **A Large Language Model Pipeline for Breast Cancer Oncology**
2406.06455v1 by Tristen Pool, Dennis Trujillo

Large language models (LLMs) have demonstrated potential in the innovation of
many disciplines. However, how they can best be developed for oncology remains
underdeveloped. State-of-the-art OpenAI models were fine-tuned on a clinical
dataset and clinical guidelines text corpus for two important cancer treatment
factors, adjuvant radiation therapy and chemotherapy, using a novel Langchain
prompt engineering pipeline. A high accuracy (0.85+) was achieved in the
classification of adjuvant radiation therapy and chemotherapy for breast cancer
patients. Furthermore, a confidence interval was formed from observational data
on the quality of treatment from human oncologists to estimate the proportion
of scenarios in which the model must outperform the original oncologist in its
treatment prediction to be a better solution overall as 8.2% to 13.3%. Due to
indeterminacy in the outcomes of cancer treatment decisions, future
investigation, potentially a clinical trial, would be required to determine if
this threshold was met by the models. Nevertheless, with 85% of U.S. cancer
patients receiving treatment at local community facilities, these kinds of
models could play an important part in expanding access to quality care with
outcomes that lie, at minimum, close to a human oncologist.

摘要：大型語言模型 (LLM) 已在許多領域的創新中展現其潛力。然而，如何才能最佳地開發它們以用於腫瘤學仍處於未開發狀態。最先進的 OpenAI 模型針對臨床資料集和臨床指南文字語料庫進行微調，以針對兩個重要的癌症治療因素，輔助放射治療和化療，使用創新的 Langchain 提示工程管道。在乳癌患者的輔助放射治療和化療分類中，達到了很高的準確度 (0.85+)。此外，根據人類腫瘤學家對治療品質的觀察資料，形成了一個信心區間，以估計在模型必須在其治療預測中優於原始腫瘤學家的情況下，作為整體更好的解決方案的比例，為 8.2% 至 13.3%。由於癌症治療決策結果的不確定性，未來的調查（可能是臨床試驗）將被要求確定模型是否達到此閾值。儘管如此，由於 85% 的美國癌症患者在當地社區設施接受治療，這些類型的模型可以在擴大獲得品質照護的機會中發揮重要作用，其結果至少接近人類腫瘤學家。

##### **Insights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course**
2406.06451v1 by Aadarsh Padiyath, Xinying Hou, Amy Pang, Diego Viramontes Vargas, Xingjian Gu, Tamara Nelson-Fromm, Zihan Wu, Mark Guzdial, Barbara Ericson

The capability of large language models (LLMs) to generate, debug, and
explain code has sparked the interest of researchers and educators in
undergraduate programming, with many anticipating their transformative
potential in programming education. However, decisions about why and how to use
LLMs in programming education may involve more than just the assessment of an
LLM's technical capabilities. Using the social shaping of technology theory as
a guiding framework, our study explores how students' social perceptions
influence their own LLM usage. We then examine the correlation of self-reported
LLM usage with students' self-efficacy and midterm performances in an
undergraduate programming course. Triangulating data from an anonymous
end-of-course student survey (n = 158), a mid-course self-efficacy survey
(n=158), student interviews (n = 10), self-reported LLM usage on homework, and
midterm performances, we discovered that students' use of LLMs was associated
with their expectations for their future careers and their perceptions of peer
usage. Additionally, early self-reported LLM usage in our context correlated
with lower self-efficacy and lower midterm scores, while students' perceived
over-reliance on LLMs, rather than their usage itself, correlated with
decreased self-efficacy later in the course.

摘要：大型語言模型 (LLM) 生成、除錯和說明程式碼的能力，激發了研究人員和教育工作者對大學部程式設計的興趣，許多人預期它們在程式設計教育中的轉型潛力。然而，關於在程式設計教育中為何以及如何使用 LLM 的決定，可能涉及的層面不只是評估 LLM 的技術能力而已。本研究以科技社會建構論為指導架構，探討學生的社會認知如何影響他們對 LLM 的使用。接著我們檢視自述 LLM 使用狀況與學生在大專程式設計課程中的自我效能和期中表現之間的關聯性。透過三角定位來自匿名課程結束時學生問卷調查 (n = 158)、課程中段自我效能問卷調查 (n = 158)、學生訪談 (n = 10)、作業中自述 LLM 使用狀況，以及期中表現等資料，我們發現學生使用 LLM 與他們對未來職涯的期望，以及他們對同儕使用狀況的認知有關。此外，在我們的脈絡中，早期自述 LLM 使用狀況與較低的自我效能和較低的期中成績有關，而學生感知過度依賴 LLM，而非使用本身，與課程後段自我效能降低有關。

##### **LLM Dataset Inference: Did you train on my dataset?**
2406.06443v1 by Pratyush Maini, Hengrui Jia, Nicolas Papernot, Adam Dziedzic

The proliferation of large language models (LLMs) in the real world has come
with a rise in copyright cases against companies for training their models on
unlicensed data from the internet. Recent works have presented methods to
identify if individual text sequences were members of the model's training
data, known as membership inference attacks (MIAs). We demonstrate that the
apparent success of these MIAs is confounded by selecting non-members (text
sequences not used for training) belonging to a different distribution from the
members (e.g., temporally shifted recent Wikipedia articles compared with ones
used to train the model). This distribution shift makes membership inference
appear successful. However, most MIA methods perform no better than random
guessing when discriminating between members and non-members from the same
distribution (e.g., in this case, the same period of time). Even when MIAs
work, we find that different MIAs succeed at inferring membership of samples
from different distributions. Instead, we propose a new dataset inference
method to accurately identify the datasets used to train large language models.
This paradigm sits realistically in the modern-day copyright landscape, where
authors claim that an LLM is trained over multiple documents (such as a book)
written by them, rather than one particular paragraph. While dataset inference
shares many of the challenges of membership inference, we solve it by
selectively combining the MIAs that provide positive signal for a given
distribution, and aggregating them to perform a statistical test on a given
dataset. Our approach successfully distinguishes the train and test sets of
different subsets of the Pile with statistically significant p-values < 0.1,
without any false positives.

摘要：<paragraph>大型語言模型 (LLM) 在現實世界中激增，導致對公司使用未經授權的網路資料訓練模型的著作權案件增加。最近的研究提出了方法來識別個別文字序列是否為模型訓練資料的成員，稱為成員身分推論攻擊 (MIA)。我們證明了這些 MIA 的明顯成功是因為選擇了不屬於成員的非成員（未用於訓練的文字序列），這些非成員來自與成員不同的分佈（例如，與用於訓練模型的維基百科文章相比，時間上有所推移的近期維基百科文章）。這種分佈轉移使得成員身分推論看起來很成功。然而，大多數 MIA 方法在區分來自相同分佈的成員和非成員時，表現不比隨機猜測好（例如，在這種情況下，相同時間段）。即使 MIA 有效，我們也發現不同的 MIA 成功推論來自不同分佈的樣本的身分。相反，我們提出了一種新的資料集推論方法來準確識別用於訓練大型語言模型的資料集。這種範例切合實際地存在於現代的著作權環境中，在這種環境中，作者聲稱 LLM 是根據他們撰寫的多個文件（例如一本書）進行訓練，而不是特定段落。雖然資料集推論與成員身分推論有許多相同的挑戰，但我們透過選擇性地結合對特定分佈提供正向訊號的 MIA，並將它們彙總起來對特定資料集執行統計檢定，來解決這個問題。我們的做法成功區分了 Pile 不同子集的訓練集和測試集，且具有統計顯著性 p 值 < 0.1，沒有任何誤報。</paragraph>

##### **Interpretability of Language Models via Task Spaces**
2406.06441v1 by Lucas Weber, Jaap Jumelet, Elia Bruni, Dieuwke Hupkes

The usual way to interpret language models (LMs) is to test their performance
on different benchmarks and subsequently infer their internal processes. In
this paper, we present an alternative approach, concentrating on the quality of
LM processing, with a focus on their language abilities. To this end, we
construct 'linguistic task spaces' -- representations of an LM's language
conceptualisation -- that shed light on the connections LMs draw between
language phenomena. Task spaces are based on the interactions of the learning
signals from different linguistic phenomena, which we assess via a method we
call 'similarity probing'. To disentangle the learning signals of linguistic
phenomena, we further introduce a method called 'fine-tuning via gradient
differentials' (FTGD). We apply our methods to language models of three
different scales and find that larger models generalise better to overarching
general concepts for linguistic tasks, making better use of their shared
structure. Further, the distributedness of linguistic processing increases with
pre-training through increased parameter sharing between related linguistic
tasks. The overall generalisation patterns are mostly stable throughout
training and not marked by incisive stages, potentially explaining the lack of
successful curriculum strategies for LMs.

摘要：語言模型 (LM) 的常見解讀方式是測試其在不同基準上的表現，然後推論其內部程序。在本文中，我們提出了一種替代方法，專注於 LM 處理的品質，重點放在其語言能力上。為此，我們建構了「語言任務空間」——LM 語言概念化的表徵——它闡明了 LM 在語言現象之間建立的連結。任務空間基於不同語言現象的學習訊號的交互作用，我們透過一種我們稱為「相似性探測」的方法來評估這些交互作用。為了解開語言現象的學習訊號，我們進一步引入一種稱為「透過梯度差進行微調」(FTGD) 的方法。我們將我們的這些方法應用於三個不同規模的語言模型，發現較大的模型對於語言任務的廣泛一般概念能概化得更好，並能更好地利用它們的共享結構。此外，語言處理的分布性會隨著預訓練而增加，這是因為相關語言任務之間的參數共享增加了。整體概化模式在整個訓練過程中大多是穩定的，並沒有明顯的階段，這可能解釋了 LM 缺乏成功的課程策略的原因。

##### **Multimodal Contextualized Semantic Parsing from Speech**
2406.06438v1 by Jordan Voas, Raymond Mooney, David Harwath

We introduce Semantic Parsing in Contextual Environments (SPICE), a task
designed to enhance artificial agents' contextual awareness by integrating
multimodal inputs with prior contexts. SPICE goes beyond traditional semantic
parsing by offering a structured, interpretable framework for dynamically
updating an agent's knowledge with new information, mirroring the complexity of
human communication. We develop the VG-SPICE dataset, crafted to challenge
agents with visual scene graph construction from spoken conversational
exchanges, highlighting speech and visual data integration. We also present the
Audio-Vision Dialogue Scene Parser (AViD-SP) developed for use on VG-SPICE.
These innovations aim to improve multimodal information processing and
integration. Both the VG-SPICE dataset and the AViD-SP model are publicly
available.

摘要：我們在語境環境中引入了語意解析 (SPICE)，這是一項任務，旨在透過將多模態輸入與先前的語境整合，來提升人工代理的語境感知。SPICE 超越了傳統的語意解析，提供了一個結構化且可解釋的架構，用於動態更新代理的知識，並反映人類溝通的複雜性。我們開發了 VG-SPICE 資料集，旨在透過口語對話交流來挑戰代理的視覺場景圖形建構，強調語音和視覺資料整合。我們還展示了用於 VG-SPICE 的音頻視覺對話場景解析器 (AViD-SP)。這些創新旨在改善多模態資訊處理和整合。VG-SPICE 資料集和 AViD-SP 模型都是公開可用的。

##### **Language Models are Alignable Decision-Makers: Dataset and Application to the Medical Triage Domain**
2406.06435v1 by Brian Hu, Bill Ray, Alice Leung, Amy Summerville, David Joy, Christopher Funk, Arslan Basharat

In difficult decision-making scenarios, it is common to have conflicting
opinions among expert human decision-makers as there may not be a single right
answer. Such decisions may be guided by different attributes that can be used
to characterize an individual's decision. We introduce a novel dataset for
medical triage decision-making, labeled with a set of decision-maker attributes
(DMAs). This dataset consists of 62 scenarios, covering six different DMAs,
including ethical principles such as fairness and moral desert. We present a
novel software framework for human-aligned decision-making by utilizing these
DMAs, paving the way for trustworthy AI with better guardrails. Specifically,
we demonstrate how large language models (LLMs) can serve as ethical
decision-makers, and how their decisions can be aligned to different DMAs using
zero-shot prompting. Our experiments focus on different open-source models with
varying sizes and training techniques, such as Falcon, Mistral, and Llama 2.
Finally, we also introduce a new form of weighted self-consistency that
improves the overall quantified performance. Our results provide new research
directions in the use of LLMs as alignable decision-makers. The dataset and
open-source software are publicly available at:
https://github.com/ITM-Kitware/llm-alignable-dm.

摘要：在困難的決策情境中，專家人類決策者之間產生相互衝突的意見是很常見的，因為可能沒有單一的正確答案。此類決策可能受到用於描述個人決策的不同屬性的指導。我們引入了一個新穎的醫療分流決策制定資料集，並標記了一組決策者屬性 (DMA)。此資料集包含 62 個情境，涵蓋六個不同的 DMA，包括公平性和道德沙漠等道德原則。我們提出了一個新穎的軟體架構，用於透過利用這些 DMA 進行與人類一致的決策制定，為具有更好護欄的值得信賴的 AI 鋪平道路。具體來說，我們展示了大型語言模型 (LLM) 如何作為道德決策者，以及如何使用零次提示將其決策與不同的 DMA 對齊。我們的實驗重點關注具有不同大小和訓練技術的不同開源模型，例如 Falcon、Mistral 和 Llama 2。最後，我們還引入了一種新的加權自一致性形式，它改進了整體量化效能。我們的結果為 LLM 作為可對齊決策者的使用提供了新的研究方向。資料集和開源軟體可在以下位置公開取得：
https://github.com/ITM-Kitware/llm-alignable-dm。

##### **DISCO: An End-to-End Bandit Framework for Personalised Discount Allocation**
2406.06433v1 by Jason Shuo Zhang, Benjamin Howson, Panayiota Savva, Eleanor Loh

Personalised discount codes provide a powerful mechanism for managing
customer relationships and operational spend in e-commerce. Bandits are well
suited for this product area, given the partial information nature of the
problem, as well as the need for adaptation to the changing business
environment. Here, we introduce DISCO, an end-to-end contextual bandit
framework for personalised discount code allocation at ASOS.com. DISCO adapts
the traditional Thompson Sampling algorithm by integrating it within an integer
program, thereby allowing for operational cost control. Because bandit learning
is often worse with high dimensional actions, we focused on building low
dimensional action and context representations that were nonetheless capable of
good accuracy. Additionally, we sought to build a model that preserved the
relationship between price and sales, in which customers increasing their
purchasing in response to lower prices ("negative price elasticity"). These
aims were achieved by using radial basis functions to represent the continuous
(i.e. infinite armed) action space, in combination with context embeddings
extracted from a neural network. These feature representations were used within
a Thompson Sampling framework to facilitate exploration, and further integrated
with an integer program to allocate discount codes across ASOS's customer base.
These modelling decisions result in a reward model that (a) enables pooled
learning across similar actions, (b) is highly accurate, including in
extrapolation, and (c) preserves the expected negative price elasticity.
Through offline analysis, we show that DISCO is able to effectively enact
exploration and improves its performance over time, despite the global
constraint. Finally, we subjected DISCO to a rigorous online A/B test, and find
that it achieves a significant improvement of >1% in average basket value,
relative to the legacy systems.

摘要：<paragraph>個人化折扣碼提供了一種強大的機制來管理電子商務中的客戶關係和營運支出。由於問題的部分資訊性質，以及適應不斷變化的商業環境的需求，強盜非常適合這個產品領域。在此，我們介紹 DISCO，一個針對 ASOS.com 上個人化折扣碼分配的端到端情境強盜框架。DISCO 透過將傳統的 Thompson Sampling 演算法整合到一個整數程式中來進行調整，從而允許營運成本控制。由於強盜學習通常在高維度動作中較差，因此我們專注於建立低維度動作和情境表示，這些表示仍然能夠有良好的準確度。此外，我們尋求建立一個保留價格和銷售之間關係的模型，其中客戶會因應較低的價格而增加購買（「負價格彈性」）。這些目標是透過使用徑向基函數來表示連續的（即無限武裝）動作空間，並結合從神經網路中提取的情境嵌入來實現。這些特徵表示在 Thompson Sampling 框架中用於促進探索，並進一步與整數程式整合，以在 ASOS 的客戶群中分配折扣碼。這些建模決策產生了一個獎勵模型，該模型 (a) 能夠跨類似動作進行匯集學習，(b) 具有很高的準確度，包括外推，以及 (c) 保留預期的負價格彈性。透過離線分析，我們表明 DISCO 能夠有效地制定探索並隨著時間推移提高其效能，儘管存在全球約束。最後，我們對 DISCO 進行了嚴格的線上 A/B 測試，發現它在平均購物籃價值方面取得了 >1% 的顯著改善，相對於傳統系統。</paragraph>

##### **Explainable Graph Neural Networks Under Fire**
2406.06417v1 by Zhong Li, Simon Geisler, Yuhang Wang, Stephan Günnemann, Matthijs van Leeuwen

Predictions made by graph neural networks (GNNs) usually lack
interpretability due to their complex computational behavior and the abstract
nature of graphs. In an attempt to tackle this, many GNN explanation methods
have emerged. Their goal is to explain a model's predictions and thereby obtain
trust when GNN models are deployed in decision critical applications. Most GNN
explanation methods work in a post-hoc manner and provide explanations in the
form of a small subset of important edges and/or nodes. In this paper we
demonstrate that these explanations can unfortunately not be trusted, as common
GNN explanation methods turn out to be highly susceptible to adversarial
perturbations. That is, even small perturbations of the original graph
structure that preserve the model's predictions may yield drastically different
explanations. This calls into question the trustworthiness and practical
utility of post-hoc explanation methods for GNNs. To be able to attack GNN
explanation models, we devise a novel attack method dubbed \textit{GXAttack},
the first \textit{optimization-based} adversarial attack method for post-hoc
GNN explanations under such settings. Due to the devastating effectiveness of
our attack, we call for an adversarial evaluation of future GNN explainers to
demonstrate their robustness.

摘要：圖形神經網路 (GNN) 所做的預測通常缺乏可解釋性，這是因為它們的運算行為很複雜，而且圖形的性質很抽象。為了解決這個問題，已經出現了許多 GNN 解釋方法。它們的目標是解釋模型的預測，從而當 GNN 模型部署在決策關鍵應用程式中時，可以獲得信任。大多數 GNN 解釋方法都是事後運作，並以一小部分重要邊緣和/或節點的形式提供解釋。在本文中，我們證明了這些解釋不幸地不可靠，因為常見的 GNN 解釋方法很容易受到對抗性擾動的影響。也就是說，即使是保留模型預測的原始圖形結構的小擾動，也可能會產生截然不同的解釋。這對 GNN 的事後解釋方法的可信度和實用性提出了質疑。為了能夠攻擊 GNN 解釋模型，我們設計了一種新穎的攻擊方法，稱為 \textit{GXAttack}，這是第一個在這種設定下針對事後 GNN 解釋的\textit{基於最佳化}對抗攻擊方法。由於我們的攻擊具有毀滅性的有效性，我們呼籲對未來的 GNN 解釋器進行對抗性評估，以證明它們的穩健性。

##### **Controlling Emotion in Text-to-Speech with Natural Language Prompts**
2406.06406v1 by Thomas Bott, Florian Lux, Ngoc Thang Vu

In recent years, prompting has quickly become one of the standard ways of
steering the outputs of generative machine learning models, due to its
intuitive use of natural language. In this work, we propose a system
conditioned on embeddings derived from an emotionally rich text that serves as
prompt. Thereby, a joint representation of speaker and prompt embeddings is
integrated at several points within a transformer-based architecture. Our
approach is trained on merged emotional speech and text datasets and varies
prompts in each training iteration to increase the generalization capabilities
of the model. Objective and subjective evaluation results demonstrate the
ability of the conditioned synthesis system to accurately transfer the emotions
present in a prompt to speech. At the same time, precise tractability of
speaker identities as well as overall high speech quality and intelligibility
are maintained.

摘要：近年来，提示已迅速成为引导生成式机器学习模型输出的标准方式之一，因为它直观地使用了自然语言。在这项工作中，我们提出了一个系统，该系统以来自情感丰富的文本的嵌入为条件，该文本用作提示。因此，说话人和提示嵌入的联合表示在基于 Transformer 的架构中的几个点上被集成。我们的方法在合并的情感语音和文本数据集上进行训练，并在每次训练迭代中改变提示，以提高模型的泛化能力。客观和主观评估结果证明了条件合成系统将提示中存在的情绪准确地转移到语音中的能力。同时，保持了说话人身份的精确可追溯性以及整体高语音质量和可懂度。

##### **Meta Learning Text-to-Speech Synthesis in over 7000 Languages**
2406.06403v1 by Florian Lux, Sarina Meyer, Lyonel Behringer, Frank Zalkow, Phat Do, Matt Coler, Emanuël A. P. Habets, Ngoc Thang Vu

In this work, we take on the challenging task of building a single
text-to-speech synthesis system that is capable of generating speech in over
7000 languages, many of which lack sufficient data for traditional TTS
development. By leveraging a novel integration of massively multilingual
pretraining and meta learning to approximate language representations, our
approach enables zero-shot speech synthesis in languages without any available
data. We validate our system's performance through objective measures and human
evaluation across a diverse linguistic landscape. By releasing our code and
models publicly, we aim to empower communities with limited linguistic
resources and foster further innovation in the field of speech technology.

摘要：在這項工作中，我們承擔了建立單一文字轉語音合成系統的挑戰性任務，該系統能夠以超過 7000 種語言產生語音，其中許多語言缺乏足夠的資料來進行傳統的 TTS 開發。透過利用大量多語言預訓練和元學習的新穎整合來近似語言表示，我們的做法可以在沒有任何可用資料的語言中進行零次學習語音合成。我們透過客觀措施和人類評估在不同的語言環境中驗證我們系統的效能。透過公開我們的程式碼和模型，我們旨在賦能語言資源有限的社群，並促進語音技術領域的進一步創新。

##### **INTERSPEECH 2009 Emotion Challenge Revisited: Benchmarking 15 Years of Progress in Speech Emotion Recognition**
2406.06401v1 by Andreas Triantafyllopoulos, Anton Batliner, Simon Rampp, Manuel Milling, Björn Schuller

We revisit the INTERSPEECH 2009 Emotion Challenge -- the first ever speech
emotion recognition (SER) challenge -- and evaluate a series of deep learning
models that are representative of the major advances in SER research in the
time since then. We start by training each model using a fixed set of
hyperparameters, and further fine-tune the best-performing models of that
initial setup with a grid search. Results are always reported on the official
test set with a separate validation set only used for early stopping. Most
models score below or close to the official baseline, while they marginally
outperform the original challenge winners after hyperparameter tuning. Our work
illustrates that, despite recent progress, FAU-AIBO remains a very challenging
benchmark. An interesting corollary is that newer methods do not consistently
outperform older ones, showing that progress towards `solving' SER is not
necessarily monotonic.

摘要：我們重新探討 INTERSPEECH 2009 情緒挑戰 -- 第一個語音情緒辨識 (SER) 挑戰 -- 並評估一系列深度學習模型，這些模型代表自那時以來 SER 研究的主要進展。我們首先使用一組固定的超參數訓練每個模型，並使用網格搜尋進一步微調該初始設定中表現最佳的模型。結果總是報告在官方測試集上，並只使用單獨的驗證集進行早期停止。大多數模型的分數低於或接近官方基準，而在超參數調整後，它們的表現略優於原始挑戰賽的獲勝者。我們的研究說明，儘管有近期的進展，FAU-AIBO 仍然是一個非常具有挑戰性的基準。一個有趣的推論是，較新的方法並非始終優於較舊的方法，這表明朝向「解決」SER 的進展不一定會單調。

##### **An Empirical Design Justice Approach to Identifying Ethical Considerations in the Intersection of Large Language Models and Social Robotics**
2406.06400v1 by Alva Markelius

The integration of Large Language Models (LLMs) in social robotics presents a
unique set of ethical challenges and social impacts. This research is set out
to identify ethical considerations that arise in the design and development of
these two technologies in combination. Using LLMs for social robotics may
provide benefits, such as enabling natural language open-domain dialogues.
However, the intersection of these two technologies also gives rise to ethical
concerns related to misinformation, non-verbal cues, emotional disruption, and
biases. The robot's physical social embodiment adds complexity, as ethical
hazards associated with LLM-based Social AI, such as hallucinations and
misinformation, can be exacerbated due to the effects of physical embodiment on
social perception and communication. To address these challenges, this study
employs an empirical design justice-based methodology, focusing on identifying
socio-technical ethical considerations through a qualitative co-design and
interaction study. The purpose of the study is to identify ethical
considerations relevant to the process of co-design of, and interaction with a
humanoid social robot as the interface of a LLM, and to evaluate how a design
justice methodology can be used in the context of designing LLMs-based social
robotics. The findings reveal a mapping of ethical considerations arising in
four conceptual dimensions: interaction, co-design, terms of service and
relationship and evaluates how a design justice approach can be used
empirically in the intersection of LLMs and social robotics.

摘要：大型語言模型 (LLM) 在社交機器人中的整合提出了一系列獨特的倫理挑戰和社會影響。本研究旨在找出結合這兩種技術時在設計和開發中出現的倫理考量。將 LLM 用於社交機器人可能會帶來好處，例如實現自然語言開放領域對話。然而，這兩種技術的交叉也引發了與錯誤訊息、非語言提示、情緒中斷和偏見相關的倫理問題。機器人的物理社交體現增加了複雜性，因為與 LLM 為基礎的社交 AI 相關的倫理風險，例如幻覺和錯誤訊息，可能會因物理體現對社交感知和溝通的影響而加劇。為了應對這些挑戰，本研究採用基於經驗設計正義的方法，重點透過定性共創和互動研究找出社會技術倫理考量。本研究的目的是找出與共創過程相關的倫理考量，以及與作為 LLM 介面的類人社交機器人互動，並評估如何能在設計基於 LLM 的社交機器人的脈絡中使用設計正義方法。研究結果揭示了出現在四個概念面向的倫理考量對應關係：互動、共創、服務條款和關係，並評估如何能在 LLM 和社交機器人的交叉領域中以經驗方式使用設計正義方法。

##### **Should We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue**
2406.06399v1 by Simone Alghisi, Massimo Rizzoli, Gabriel Roccabruna, Seyed Mahed Mousavi, Giuseppe Riccardi

We study the limitations of Large Language Models (LLMs) for the task of
response generation in human-machine dialogue. Several techniques have been
proposed in the literature for different dialogue types (e.g., Open-Domain).
However, the evaluations of these techniques have been limited in terms of base
LLMs, dialogue types and evaluation metrics. In this work, we extensively
analyze different LLM adaptation techniques when applied to different dialogue
types. We have selected two base LLMs, Llama-2 and Mistral, and four dialogue
types Open-Domain, Knowledge-Grounded, Task-Oriented, and Question Answering.
We evaluate the performance of in-context learning and fine-tuning techniques
across datasets selected for each dialogue type. We assess the impact of
incorporating external knowledge to ground the generation in both scenarios of
Retrieval-Augmented Generation (RAG) and gold knowledge. We adopt consistent
evaluation and explainability criteria for automatic metrics and human
evaluation protocols. Our analysis shows that there is no universal
best-technique for adapting large language models as the efficacy of each
technique depends on both the base LLM and the specific type of dialogue. Last
but not least, the assessment of the best adaptation technique should include
human evaluation to avoid false expectations and outcomes derived from
automatic metrics.

摘要：我們探討大型語言模型 (LLM) 在人機對話中回應生成任務的限制。針對不同的對話類型（例如，開放領域），文獻中已提出多種技術。然而，這些技術的評估在基本 LLM、對話類型和評估指標方面受到限制。在這項工作中，我們廣泛分析了應用於不同對話類型的不同 LLM 適應技術。我們選擇了兩個基本 LLM，Llama-2 和 Mistral，以及四種類型的對話：開放領域、知識基礎、任務導向和問答。我們評估了針對每個對話類型所選資料集的語境學習和微調技術的效能。我們評估了在檢索強化生成 (RAG) 和黃金知識這兩種情況下，加入外部知識以奠定生成的基礎的影響。我們採用一致的評估和可解釋性標準，用於自動指標和人類評估協定。我們的分析顯示，沒有通用的最佳技術來適應大型語言模型，因為每種技術的效能取決於基本 LLM 和特定類型的對話。最後但並非最不重要的一點是，最佳適應技術的評估應包括人類評估，以避免來自自動指標的錯誤期望和結果。

##### **Contrastive learning of T cell receptor representations**
2406.06397v1 by Yuta Nagano, Andrew Pyo, Martina Milighetti, James Henderson, John Shawe-Taylor, Benny Chain, Andreas Tiffeau-Mayer

Computational prediction of the interaction of T cell receptors (TCRs) and
their ligands is a grand challenge in immunology. Despite advances in
high-throughput assays, specificity-labelled TCR data remains sparse. In other
domains, the pre-training of language models on unlabelled data has been
successfully used to address data bottlenecks. However, it is unclear how to
best pre-train protein language models for TCR specificity prediction. Here we
introduce a TCR language model called SCEPTR (Simple Contrastive Embedding of
the Primary sequence of T cell Receptors), capable of data-efficient transfer
learning. Through our model, we introduce a novel pre-training strategy
combining autocontrastive learning and masked-language modelling, which enables
SCEPTR to achieve its state-of-the-art performance. In contrast, existing
protein language models and a variant of SCEPTR pre-trained without
autocontrastive learning are outperformed by sequence alignment-based methods.
We anticipate that contrastive learning will be a useful paradigm to decode the
rules of TCR specificity.

摘要：T 細胞受容體 (TCR) 和其配體的相互作用的計算預測是免疫學中的一項重大挑戰。儘管高通量檢測技術進步，但特異性標記的 TCR 資料仍然稀少。在其他領域，語言模型在未標記資料上的預訓練已成功用於解決資料瓶頸。然而，目前尚不清楚如何最佳預訓練蛋白質語言模型以進行 TCR 特異性預測。在此，我們引入了一個名為 SCEPTR（T 細胞受容體主要序列的簡單對比嵌入）的 TCR 語言模型，它能夠進行資料有效率的遷移學習。透過我們的模型，我們引入了一種結合自動對比學習和遮罩語言建模的新穎預訓練策略，這使 SCEPTR 能夠實現其最先進的效能。相比之下，現有的蛋白質語言模型和 SCEPTR 的一個變體在未進行自動對比學習的情況下進行預訓練，其效能不如基於序列比對的方法。我們預期對比學習將成為解碼 TCR 特異性規則的一個有用的範例。

##### **Towards Lifelong Learning of Large Language Models: A Survey**
2406.06391v1 by Junhao Zheng, Shengjie Qiu, Chengming Shi, Qianli Ma

As the applications of large language models (LLMs) expand across diverse
fields, the ability of these models to adapt to ongoing changes in data, tasks,
and user preferences becomes crucial. Traditional training methods, relying on
static datasets, are increasingly inadequate for coping with the dynamic nature
of real-world information. Lifelong learning, also known as continual or
incremental learning, addresses this challenge by enabling LLMs to learn
continuously and adaptively over their operational lifetime, integrating new
knowledge while retaining previously learned information and preventing
catastrophic forgetting. This survey delves into the sophisticated landscape of
lifelong learning, categorizing strategies into two primary groups: Internal
Knowledge and External Knowledge. Internal Knowledge includes continual
pretraining and continual finetuning, each enhancing the adaptability of LLMs
in various scenarios. External Knowledge encompasses retrieval-based and
tool-based lifelong learning, leveraging external data sources and
computational tools to extend the model's capabilities without modifying core
parameters. The key contributions of our survey are: (1) Introducing a novel
taxonomy categorizing the extensive literature of lifelong learning into 12
scenarios; (2) Identifying common techniques across all lifelong learning
scenarios and classifying existing literature into various technique groups
within each scenario; (3) Highlighting emerging techniques such as model
expansion and data selection, which were less explored in the pre-LLM era.
Through a detailed examination of these groups and their respective categories,
this survey aims to enhance the adaptability, reliability, and overall
performance of LLMs in real-world applications.

摘要：隨著大型語言模型 (LLM) 的應用擴展到不同領域，這些模型適應資料、任務和使用者偏好的持續變化的能力變得至關重要。傳統的訓練方法依賴於靜態資料集，越來越不足以應對真實世界資訊的動態特性。終身學習，也稱為持續或增量學習，透過讓 LLM 在其運作壽命期間持續且適應性地學習，整合新知識，同時保留先前學習的資訊，並防止災難性遺忘，來解決此挑戰。本調查深入探討終身學習的複雜領域，將策略分類為兩大主要群組：內部知識和外部知識。內部知識包括持續預訓練和持續微調，每個知識都增強了 LLM 在各種場景中的適應能力。外部知識包含基於檢索和基於工具的終身學習，利用外部資料來源和運算工具來擴展模型的能力，而無需修改核心參數。我們調查的主要貢獻包括：(1) 引入新分類法，將廣泛的終身學習文獻分類為 12 個場景；(2) 找出所有終身學習場景中的常見技術，並將現有文獻分類為每個場景中的各種技術群組；(3) 強調新興技術，例如模型擴充和資料選取，這些技術在 LLM 前時代較少被探討。透過詳細檢視這些群組及其各自的類別，本調查旨在增強 LLM 在真實世界應用中的適應性、可靠性和整體效能。

##### **Low-Rank Quantization-Aware Training for LLMs**
2406.06385v1 by Yelysei Bondarenko, Riccardo Del Chiaro, Markus Nagel

Large language models (LLMs) are omnipresent, however their practical
deployment is challenging due to their ever increasing computational and memory
demands. Quantization is one of the most effective ways to make them more
compute and memory efficient. Quantization-aware training (QAT) methods,
generally produce the best quantized performance, however it comes at the cost
of potentially long training time and excessive memory usage, making it
impractical when applying for LLMs. Inspired by parameter-efficient fine-tuning
(PEFT) and low-rank adaptation (LoRA) literature, we propose LR-QAT -- a
lightweight and memory-efficient QAT algorithm for LLMs. LR-QAT employs several
components to save memory without sacrificing predictive performance: (a)
low-rank auxiliary weights that are aware of the quantization grid; (b) a
downcasting operator using fixed-point or double-packed integers and (c)
checkpointing. Unlike most related work, our method (i) is inference-efficient,
leading to no additional overhead compared to traditional PTQ; (ii) can be seen
as a general extended pretraining framework, meaning that the resulting model
can still be utilized for any downstream task afterwards; (iii) can be applied
across a wide range of quantization settings, such as different choices
quantization granularity, activation quantization, and seamlessly combined with
many PTQ techniques. We apply LR-QAT to the LLaMA-2/3 and Mistral model
families and validate its effectiveness on several downstream tasks. Our method
outperforms common post-training quantization (PTQ) approaches and reaches the
same model performance as full-model QAT at the fraction of its memory usage.
Specifically, we can train a 7B LLM on a single consumer grade GPU with 24GB of
memory.

摘要：大型語言模型 (LLM) 無所不在，但由於其不斷增加的運算和記憶體需求，它們的實際部署具有挑戰性。量化是讓它們更具運算和記憶體效率的最有效方法之一。量化感知訓練 (QAT) 方法通常會產生最佳的量化效能，但代價是潛在的訓練時間長和過度使用記憶體，這使得其在應用於 LLM 時不切實際。受到參數有效微調 (PEFT) 和低秩適應 (LoRA) 文獻的啟發，我們提出 LR-QAT ——一種適用於 LLM 的輕量級且記憶體效率高的 QAT 演算法。LR-QAT 使用多個組件來節省記憶體，同時不犧牲預測效能：(a) 了解量化網格的低秩輔助權重；(b) 使用定點或雙封裝整數的下轉算元；以及 (c) 檢查點。與大多數相關工作不同，我們的方法 (i) 具有推理效率，與傳統 PTQ 相比沒有額外的開銷；(ii) 可以看作是一種通用的延伸預訓練架構，這意味著產生的模型仍然可以在之後用於任何下游任務；(iii) 可以應用於廣泛的量化設定，例如不同的量化粒度選擇、激活量化，並與許多 PTQ 技術無縫結合。我們將 LR-QAT 應用於 LLaMA-2/3 和 Mistral 模型系列，並在多項下游任務中驗證其有效性。我們的方法優於常見的訓練後量化 (PTQ) 方法，並在使用記憶體的一小部分時達到與全模型 QAT 相同的模型效能。具體來說，我們可以在單個消費者級 GPU 上訓練一個 7B LLM，記憶體為 24GB。

##### **Diffusion-RPO: Aligning Diffusion Models through Relative Preference Optimization**
2406.06382v1 by Yi Gu, Zhendong Wang, Yueqin Yin, Yujia Xie, Mingyuan Zhou

Aligning large language models with human preferences has emerged as a
critical focus in language modeling research. Yet, integrating preference
learning into Text-to-Image (T2I) generative models is still relatively
uncharted territory. The Diffusion-DPO technique made initial strides by
employing pairwise preference learning in diffusion models tailored for
specific text prompts. We introduce Diffusion-RPO, a new method designed to
align diffusion-based T2I models with human preferences more effectively. This
approach leverages both prompt-image pairs with identical prompts and those
with semantically related content across various modalities. Furthermore, we
have developed a new evaluation metric, style alignment, aimed at overcoming
the challenges of high costs, low reproducibility, and limited interpretability
prevalent in current evaluations of human preference alignment. Our findings
demonstrate that Diffusion-RPO outperforms established methods such as
Supervised Fine-Tuning and Diffusion-DPO in tuning Stable Diffusion versions
1.5 and XL-1.0, achieving superior results in both automated evaluations of
human preferences and style alignment. Our code is available at
https://github.com/yigu1008/Diffusion-RPO

摘要：将大型语言模型与人类偏好相结合已成为语言建模研究中的一个关键焦点。然而，将偏好学习整合到文本到图像（T2I）生成模型中仍然是一个相对未知的领域。Diffusion-DPO 技术通过在针对特定文本提示定制的扩散模型中采用成对偏好学习，取得了初步进展。我们引入了 Diffusion-RPO，这是一种旨在更有效地将基于扩散的 T2I 模型与人类偏好相结合的新方法。这种方法同时利用了具有相同提示的提示图像对和跨各种模态具有语义相关内容的提示图像对。此外，我们开发了一种新的评估指标——风格对齐，旨在克服当前人类偏好对齐评估中普遍存在的高成本、低可重复性和有限的可解释性等挑战。我们的研究结果表明，Diffusion-RPO 在调整 Stable Diffusion 版本 1.5 和 XL-1.0 时优于已建立的方法，例如监督微调和 Diffusion-DPO，在人类偏好的自动化评估和风格对齐方面都取得了更好的结果。我们的代码可在 https://github.com/yigu1008/Diffusion-RPO 获得

##### **Improving Deep Learning-based Automatic Cranial Defect Reconstruction by Heavy Data Augmentation: From Image Registration to Latent Diffusion Models**
2406.06372v1 by Marek Wodzinski, Kamil Kwarciak, Mateusz Daniol, Daria Hemmerling

Modeling and manufacturing of personalized cranial implants are important
research areas that may decrease the waiting time for patients suffering from
cranial damage. The modeling of personalized implants may be partially
automated by the use of deep learning-based methods. However, this task suffers
from difficulties with generalizability into data from previously unseen
distributions that make it difficult to use the research outcomes in real
clinical settings. Due to difficulties with acquiring ground-truth annotations,
different techniques to improve the heterogeneity of datasets used for training
the deep networks have to be considered and introduced. In this work, we
present a large-scale study of several augmentation techniques, varying from
classical geometric transformations, image registration, variational
autoencoders, and generative adversarial networks, to the most recent advances
in latent diffusion models. We show that the use of heavy data augmentation
significantly increases both the quantitative and qualitative outcomes,
resulting in an average Dice Score above 0.94 for the SkullBreak and above 0.96
for the SkullFix datasets. Moreover, we show that the synthetically augmented
network successfully reconstructs real clinical defects. The work is a
considerable contribution to the field of artificial intelligence in the
automatic modeling of personalized cranial implants.

摘要：客製化顱骨植入物的建模和製造是重要的研究領域，可能會縮短遭受顱骨損傷患者的等待時間。客製化植入物的建模可以透過使用基於深度學習的方法來部分自動化。然而，此任務會受到先前未見過分佈資料的概括性困難影響，這使得在實際臨床環境中使用研究結果變得困難。由於難以取得地面實況註解，必須考量並引入不同的技術來改善用於訓練深度網路的資料集異質性。在這項工作中，我們提出多種擴充技術的大規模研究，從古典幾何轉換、影像配準、變異自動編碼器和生成對抗網路，到潛在擴散模型的最新進展。我們顯示使用大量資料擴充會顯著增加量化和質化結果，導致 SkullBreak 的平均 Dice 分數高於 0.94，而 SkullFix 資料集則高於 0.96。此外，我們顯示合成擴充網路成功重建真實的臨床缺陷。這項工作為人工智慧在客製化顱骨植入物自動建模領域做出了重大貢獻。

##### **mHuBERT-147: A Compact Multilingual HuBERT Model**
2406.06371v1 by Marcely Zanon Boito, Vivek Iyer, Nikolaos Lagos, Laurent Besacier, Ioan Calapodescu

We present mHuBERT-147, the first general-purpose massively multilingual
HuBERT speech representation model trained on 90K hours of clean, open-license
data. To scale up the multi-iteration HuBERT approach, we use faiss-based
clustering, achieving 5.2x faster label assignment over the original method. We
also apply a new multilingual batching up-sampling strategy, leveraging both
language and dataset diversity. After 3 training iterations and with only 95M
parameters, mHuBERT-147 outperforms larger models trained on substantially more
data. We rank second and first on the ML-SUPERB 10min/1h leaderboards
respectively, with SOTA scores for all LID tasks. Across ASR/LID tasks, our
model consistently surpasses XLS-R (300M params; 436K hours) and demonstrates
strong competitiveness against the much larger MMS (1B params; 491K hours). Our
findings suggest that mHuBERT-147 is a promising model for multilingual speech
processing tasks, offering an unprecedented balance between high performance
and parameter efficiency.

摘要：我們展示 mHuBERT-147，這是一個經過 90K 小時乾淨、開放許可證資料訓練的第一個通用、大量多語言 HuBERT 語音表示模型。為了擴大多重反覆運算的 HuBERT 方法，我們使用基於 faiss 的分群，達成比原始方法快 5.2 倍的標籤指派。我們也運用一種新的多語言批次上採樣策略，同時利用語言和資料集的多樣性。經過 3 次訓練反覆運算，且僅有 95M 參數，mHuBERT-147 就優於經過更多資料訓練的較大型模型。我們分別在 ML-SUPERB 10 分鐘/1 小時排行榜上排名第二和第一，且所有 LID 任務都有 SOTA 分數。在 ASR/LID 任務中，我們的模型持續超越 XLS-R（300M 參數；436K 小時），並展現出與更大規模的 MMS（1B 參數；491K 小時）的強勁競爭力。我們的發現顯示，mHuBERT-147 是多語言語音處理任務的一個有前途的模型，在高性能和參數效率之間提供前所未有的平衡。

##### **Annotation alignment: Comparing LLM and human annotations of conversational safety**
2406.06369v1 by Rajiv Movva, Pang Wei Koh, Emma Pierson

To what extent to do LLMs align with human perceptions of safety? We study
this question via *annotation alignment*, the extent to which LLMs and humans
agree when annotating the safety of user-chatbot conversations. We leverage the
recent DICES dataset (Aroyo et al., 2023), in which 350 conversations are each
rated for safety by 112 annotators spanning 10 race-gender groups. GPT-4
achieves a Pearson correlation of $r = 0.59$ with the average annotator rating,
higher than the median annotator's correlation with the average ($r=0.51$). We
show that larger datasets are needed to resolve whether GPT-4 exhibits
disparities in how well it correlates with demographic groups. Also, there is
substantial idiosyncratic variation in correlation *within* groups, suggesting
that race & gender do not fully capture differences in alignment. Finally, we
find that GPT-4 cannot predict when one demographic group finds a conversation
more unsafe than another.

摘要：LLM 在多大程度上與人類的安全認知保持一致？我們透過「標註對齊」探討這個問題，也就是 LLM 和人類在對使用者聊天機器人對話的安全標註時，意見一致的程度。我們利用最近的 DICES 資料集（Aroyo 等人，2023 年），其中 350 個對話每一個都由 112 位標註員評分，涵蓋 10 個種族性別群組。GPT-4 的皮爾森相關係數為 $r = 0.59$，與平均標註員評分相關，高於中位數標註員與平均值的相關係數（$r=0.51$）。我們顯示需要更大的資料集來確定 GPT-4 是否在與人口統計群組相關的程度方面表現出差異。此外，群組「內部」的相關性存在大量的特異性差異，這表明種族和性別並未完全捕捉到對齊的差異。最後，我們發現 GPT-4 無法預測一個人口統計群組何時會發現對話比另一個群組更不安全。

##### **Symmetric Dot-Product Attention for Efficient Training of BERT Language Models**
2406.06366v1 by Martin Courtois, Malte Ostendorff, Leonhard Hennig, Georg Rehm

Initially introduced as a machine translation model, the Transformer
architecture has now become the foundation for modern deep learning
architecture, with applications in a wide range of fields, from computer vision
to natural language processing. Nowadays, to tackle increasingly more complex
tasks, Transformer-based models are stretched to enormous sizes, requiring
increasingly larger training datasets, and unsustainable amount of compute
resources. The ubiquitous nature of the Transformer and its core component, the
attention mechanism, are thus prime targets for efficiency research. In this
work, we propose an alternative compatibility function for the self-attention
mechanism introduced by the Transformer architecture. This compatibility
function exploits an overlap in the learned representation of the traditional
scaled dot-product attention, leading to a symmetric with pairwise coefficient
dot-product attention. When applied to the pre-training of BERT-like models,
this new symmetric attention mechanism reaches a score of 79.36 on the GLUE
benchmark against 78.74 for the traditional implementation, leads to a
reduction of 6% in the number of trainable parameters, and reduces the number
of training steps required before convergence by half.

摘要：最初以機器翻譯模型推出的 Transformer 架構，現已成為現代深度學習架構的基礎，在從電腦視覺到自然語言處理等廣泛領域中都有應用。如今，為了應對日益複雜的任務，Transformer 模型被擴展到極大的規模，需要越來越大的訓練資料集和難以持續的運算資源。Transformer 和其核心組成部分注意力機制的普遍性，因此成為效率研究的主要目標。在這項工作中，我們為 Transformer 架構引入的自注意力機制提出了另一種相容性函數。此相容性函數利用傳統縮放點積注意力的學習表徵中的重疊，導致與成對係數點積注意力對稱。當應用於 BERT 類模型的預訓練時，這種新的對稱注意力機制在 GLUE 基準上達到 79.36 分，而傳統實作則為 78.74 分，導致可訓練參數數量減少 6%，並將收斂前所需的訓練步驟數量減半。

##### **MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific Workflows**
2406.06357v1 by Xingjian Zhang, Yutong Xie, Jin Huang, Jinge Ma, Zhaoying Pan, Qijia Liu, Ziyang Xiong, Tolga Ergen, Dongsub Shim, Honglak Lee, Qiaozhu Mei

Scientific innovation relies on detailed workflows, which include critical
steps such as analyzing literature, generating ideas, validating these ideas,
interpreting results, and inspiring follow-up research. However, scientific
publications that document these workflows are extensive and unstructured. This
makes it difficult for both human researchers and AI systems to effectively
navigate and explore the space of scientific innovation. To address this issue,
we introduce MASSW, a comprehensive text dataset on Multi-Aspect Summarization
of Scientific Workflows. MASSW includes more than 152,000 peer-reviewed
publications from 17 leading computer science conferences spanning the past 50
years. Using Large Language Models (LLMs), we automatically extract five core
aspects from these publications -- context, key idea, method, outcome, and
projected impact -- which correspond to five key steps in the research
workflow. These structured summaries facilitate a variety of downstream tasks
and analyses. The quality of the LLM-extracted summaries is validated by
comparing them with human annotations. We demonstrate the utility of MASSW
through multiple novel machine-learning tasks that can be benchmarked using
this new dataset, which make various types of predictions and recommendations
along the scientific workflow. MASSW holds significant potential for
researchers to create and benchmark new AI methods for optimizing scientific
workflows and fostering scientific innovation in the field. Our dataset is
openly available at \url{https://github.com/xingjian-zhang/massw}.

摘要：科學創新仰賴詳細的工作流程，其中包含分析文獻、產生想法、驗證這些想法、詮釋結果和激勵後續研究等關鍵步驟。然而，記錄這些工作流程的科學出版物既廣泛又缺乏結構。這使得人類研究人員和人工智慧系統都難以有效地瀏覽和探索科學創新的空間。為了解決這個問題，我們引入了 MASSW，一個關於科學工作流程的多面向摘要的綜合文本資料集。MASSW 包含來自 17 個領先電腦科學會議的 152,000 多篇經過同行評審的出版物，涵蓋過去 50 年。使用大型語言模型 (LLM)，我們從這些出版物中自動提取五個核心面向——背景、關鍵想法、方法、結果和預期影響——這五個面向對應於研究工作流程中的五個關鍵步驟。這些結構化的摘要有助於各種下游任務和分析。LLM 提取的摘要品質已通過與人類註解進行比較來驗證。我們透過多項新穎的機器學習任務展示了 MASSW 的效用，這些任務可以使用這個新資料集進行基準測試，並在科學工作流程中做出各種類型的預測和建議。MASSW 對於研究人員來說具有重要的潛力，可以建立和基準化新的 AI 方法，以最佳化科學工作流程並促進該領域的科學創新。我們的資料集可在 \url{https://github.com/xingjian-zhang/massw} 公開取得。

##### **Predicting Heart Activity from Speech using Data-driven and Knowledge-based features**
2406.06341v1 by Gasser Elbanna, Zohreh Mostaani, Mathew Magimai. -Doss

Accurately predicting heart activity and other biological signals is crucial
for diagnosis and monitoring. Given that speech is an outcome of multiple
physiological systems, a significant body of work studied the acoustic
correlates of heart activity. Recently, self-supervised models have excelled in
speech-related tasks compared to traditional acoustic methods. However, the
robustness of data-driven representations in predicting heart activity remained
unexplored. In this study, we demonstrate that self-supervised speech models
outperform acoustic features in predicting heart activity parameters. We also
emphasize the impact of individual variability on model generalizability. These
findings underscore the value of data-driven representations in such tasks and
the need for more speech-based physiological data to mitigate speaker-related
challenges.

摘要：準確預測心臟活動和其他生物訊號對於診斷和監控至關重要。由於語言是多重生理系統的結果，大量工作研究了心臟活動的聲學相關性。最近，與傳統的聲學方法相比，自我監督模型在與語音相關的任務中表現出色。然而，資料驅動表示法在預測心臟活動中的穩健性仍未得到探討。在這項研究中，我們證明自我監督語音模型在預測心臟活動參數方面優於聲學特徵。我們還強調了個人變異性對模型泛化性的影響。這些發現強調了資料驅動表示法在這些任務中的價值，以及需要更多基於語音的生理資料來減輕與說話者相關的挑戰。

##### **Optimisation of federated learning settings under statistical heterogeneity variations**
2406.06340v1 by Basem Suleiman, Muhammad Johan Alibasa, Rizka Widyarini Purwanto, Lewis Jeffries, Ali Anaissi, Jacky Song

Federated Learning (FL) enables local devices to collaboratively learn a
shared predictive model by only periodically sharing model parameters with a
central aggregator. However, FL can be disadvantaged by statistical
heterogeneity produced by the diversity in each local devices data
distribution, which creates different levels of Independent and Identically
Distributed (IID) data. Furthermore, this can be more complex when optimising
different combinations of FL parameters and choosing optimal aggregation. In
this paper, we present an empirical analysis of different FL training
parameters and aggregators over various levels of statistical heterogeneity on
three datasets. We propose a systematic data partition strategy to simulate
different levels of statistical heterogeneity and a metric to measure the level
of IID. Additionally, we empirically identify the best FL model and key
parameters for datasets of different characteristics. On the basis of these, we
present recommended guidelines for FL parameters and aggregators to optimise
model performance under different levels of IID and with different datasets

摘要：聯邦學習 (FL) 讓在地裝置能夠透過定期與中央聚合器分享模型參數，來協作學習一個共享的預測模型。然而，FL 可能會因為在地裝置資料分佈的多樣性而產生統計異質性，進而導致不同程度的獨立同分布 (IID) 資料，而造成劣勢。此外，在最佳化 FL 參數的不同組合和選擇最佳聚合時，這可能會變得更複雜。在本文中，我們針對三個資料集在不同程度的統計異質性上，對不同的 FL 訓練參數和聚合器進行實證分析。我們提出了一個系統性的資料分割策略，來模擬不同程度的統計異質性，以及一個用於衡量 IID 程度的指標。此外，我們根據經驗找出最佳的 FL 模型和針對不同特性的資料集的主要參數。基於這些，我們針對 FL 參數和聚合器提出建議的準則，以最佳化在不同程度的 IID 和不同資料集下的模型效能

##### **MedExQA: Medical Question Answering Benchmark with Multiple Explanations**
2406.06331v1 by Yunsoo Kim, Jinge Wu, Yusuf Abdulle, Honghan Wu

This paper introduces MedExQA, a novel benchmark in medical
question-answering, to evaluate large language models' (LLMs) understanding of
medical knowledge through explanations. By constructing datasets across five
distinct medical specialties that are underrepresented in current datasets and
further incorporating multiple explanations for each question-answer pair, we
address a major gap in current medical QA benchmarks which is the absence of
comprehensive assessments of LLMs' ability to generate nuanced medical
explanations. Our work highlights the importance of explainability in medical
LLMs, proposes an effective methodology for evaluating models beyond
classification accuracy, and sheds light on one specific domain, speech
language pathology, where current LLMs including GPT4 lack good understanding.
Our results show generation evaluation with multiple explanations aligns better
with human assessment, highlighting an opportunity for a more robust automated
comprehension assessment for LLMs. To diversify open-source medical LLMs
(currently mostly based on Llama2), this work also proposes a new medical
model, MedPhi-2, based on Phi-2 (2.7B). The model outperformed medical LLMs
based on Llama2-70B in generating explanations, showing its effectiveness in
the resource-constrained medical domain. We will share our benchmark datasets
and the trained model.

摘要：本文介绍了 MedExQA，这是一个医学问答领域的新基准，用于通过解释评估大型语言模型 (LLM) 对医学知识的理解。通过在当前数据集中的五个代表性不足的不同医学专业领域构建数据集，并为每个问题-答案对进一步纳入多个解释，我们解决了当前医学问答基准中的一大缺陷，即缺乏对 LLM 生成细微医学解释的能力的全面评估。我们的工作强调了可解释性在医学 LLM 中的重要性，提出了一种超越分类准确度来评估模型的有效方法，并阐明了一个特定领域，即语言病理学，其中包括 GPT4 在内的当前 LLM 缺乏良好的理解。我们的结果表明，使用多个解释进行生成评估与人类评估更一致，突显了对 LLM 进行更稳健的自动理解评估的机会。为了使开源医学 LLM 多样化（目前主要基于 Llama2），这项工作还提出了一种新的医学模型 MedPhi-2，基于 Phi-2 (2.7B)。该模型在生成解释方面优于基于 Llama2-70B 的医学 LLM，显示了其在资源受限的医学领域的有效性。我们将分享我们的基准数据集和训练好的模型。

##### **A Parameter-efficient Language Extension Framework for Multilingual ASR**
2406.06329v1 by Wei Liu, Jingyong Hou, Dong Yang, Muyong Cao, Tan Lee

Covering all languages with a multilingual speech recognition model (MASR) is
very difficult. Performing language extension on top of an existing MASR is a
desirable choice. In this study, the MASR continual learning problem is
probabilistically decomposed into language identity prediction (LP) and
cross-lingual adaptation (XLA) sub-problems. Based on this, we propose an
architecture-based framework for language extension that can fundamentally
solve catastrophic forgetting, debudded as PELE. PELE is designed to be
parameter-efficient, incrementally incorporating an add-on module to adapt to a
new language. Specifically, different parameter-efficient fine-tuning (PEFT)
modules and their variants are explored as potential candidates to perform XLA.
Experiments are carried out on 5 new languages with a wide range of
low-resourced data sizes. The best-performing PEFT candidate can achieve
satisfactory performance across all languages and demonstrates superiority in
three of five languages over the continual joint learning setting. Notably,
PEFT methods focusing on weight parameters or input features are revealed to be
limited in performance, showing significantly inferior extension capabilities
compared to inserting a lightweight module in between layers such as an
Adapter.

摘要：使用多语言语音识别模型 (MASR) 涵盖所有语言非常困难。在现有 MASR 的基础上执行语言扩展是一个理想的选择。在本研究中，MASR 持续学习问题在概率上分解为语言标识预测 (LP) 和跨语言适应 (XLA) 子问题。在此基础上，我们提出了一个基于架构的语言扩展框架，该框架可以从根本上解决灾难性遗忘，并将其作为 PELE 进行调试。PELE 被设计为参数高效，逐步合并附加模块以适应新语言。具体来说，探索了不同的参数高效微调 (PEFT) 模块及其变体作为执行 XLA 的潜在候选。在 5 种具有广泛低资源数据大小的新语言上进行了实验。性能最好的 PEFT 候选可以在所有语言中实现令人满意的性能，并在五种语言中的三种语言中展示出优于持续联合学习设置的优势。值得注意的是，专注于权重参数或输入特征的 PEFT 方法显示出性能受限，与在层之间插入轻量级模块（例如适配器）相比，扩展能力明显较差。

##### **Self-Tuning: Instructing LLMs to Effectively Acquire New Knowledge through Self-Teaching**
2406.06326v1 by Xiaoying Zhang, Baolin Peng, Ye Tian, Jingyan Zhou, Yipeng Zhang, Haitao Mi, Helen Meng

Large language models (LLMs) often struggle to provide up-to-date information
due to their one-time training and the constantly evolving nature of the world.
To keep LLMs current, existing approaches typically involve continued
pre-training on new documents. However, they frequently face difficulties in
extracting stored knowledge. Motivated by the remarkable success of the Feynman
Technique in efficient human learning, we introduce Self-Tuning, a learning
framework aimed at improving an LLM's ability to effectively acquire new
knowledge from raw documents through self-teaching. Specifically, we develop a
Self-Teaching strategy that augments the documents with a set of
knowledge-intensive tasks created in a self-supervised manner, focusing on
three crucial aspects: memorization, comprehension, and self-reflection.
Additionally, we introduce three Wiki-Newpages-2023-QA datasets to facilitate
an in-depth analysis of an LLM's knowledge acquisition ability concerning
memorization, extraction, and reasoning. Extensive experimental results on
Llama2 family models reveal that Self-Tuning consistently exhibits superior
performance across all knowledge acquisition tasks and excels in preserving
previous knowledge.

摘要：大型語言模型（LLM）通常難以提供最新資訊，因為它們是一次性訓練，而世界不斷在演變。為了讓 LLM 保持最新，現有方法通常涉及持續對新文件進行預訓練。然而，它們經常在提取儲存的知識時遇到困難。受到費曼技巧在有效人類學習中顯著成功的啟發，我們引入了自適應，這是一個學習架構，旨在通過自學提高 LLM 從原始文件中有效獲取新知識的能力。具體來說，我們開發了一種自學策略，該策略使用以自監督方式建立的一組知識密集型任務來擴充文件，重點關注三個關鍵方面：記憶、理解和自我反省。此外，我們引入了三個 Wiki-Newpages-2023-QA 數據集，以利於深入分析 LLM 在記憶、提取和推理方面的知識獲取能力。在 Llama2 家族模型上的廣泛實驗結果表明，自適應在所有知識獲取任務中持續表現出優異的性能，並且擅長保留先前的知識。

##### **Tx-LLM: A Large Language Model for Therapeutics**
2406.06316v1 by Juan Manuel Zambrano Chaves, Eric Wang, Tao Tu, Eeshit Dhaval Vaishnav, Byron Lee, S. Sara Mahdavi, Christopher Semturs, David Fleet, Vivek Natarajan, Shekoofeh Azizi

Developing therapeutics is a lengthy and expensive process that requires the
satisfaction of many different criteria, and AI models capable of expediting
the process would be invaluable. However, the majority of current AI approaches
address only a narrowly defined set of tasks, often circumscribed within a
particular domain. To bridge this gap, we introduce Tx-LLM, a generalist large
language model (LLM) fine-tuned from PaLM-2 which encodes knowledge about
diverse therapeutic modalities. Tx-LLM is trained using a collection of 709
datasets that target 66 tasks spanning various stages of the drug discovery
pipeline. Using a single set of weights, Tx-LLM simultaneously processes a wide
variety of chemical or biological entities(small molecules, proteins, nucleic
acids, cell lines, diseases) interleaved with free-text, allowing it to predict
a broad range of associated properties, achieving competitive with
state-of-the-art (SOTA) performance on 43 out of 66 tasks and exceeding SOTA on
22. Among these, Tx-LLM is particularly powerful and exceeds best-in-class
performance on average for tasks combining molecular SMILES representations
with text such as cell line names or disease names, likely due to context
learned during pretraining. We observe evidence of positive transfer between
tasks with diverse drug types (e.g.,tasks involving small molecules and tasks
involving proteins), and we study the impact of model size, domain finetuning,
and prompting strategies on performance. We believe Tx-LLM represents an
important step towards LLMs encoding biochemical knowledge and could have a
future role as an end-to-end tool across the drug discovery development
pipeline.

摘要：開發治療藥物是一個漫長且昂貴的過程，需要滿足許多不同的標準，而能夠加速這個過程的 AI 模型將會非常有價值。然而，目前大多數的 AI 方法僅能處理定義狹隘的一組任務，通常侷限在特定領域內。為了彌合這個差距，我們引入了 Tx-LLM，一個從 PaLM-2 微調而來的通才大型語言模型 (LLM)，它編碼了關於各種治療方式的知識。Tx-LLM 是使用 709 個資料集訓練的，這些資料集針對 66 個任務，涵蓋藥物發現管線的各個階段。Tx-LLM 使用單一組權重，同時處理各種化學或生物實體（小分子、蛋白質、核酸、細胞系、疾病）穿插自由文字，讓它能夠預測廣泛的關聯屬性，在 66 個任務中有 43 個任務達到與最先進 (SOTA) 技術同等的效能，並在 22 個任務中超越 SOTA。其中，Tx-LLM 特別強大，在結合分子 SMILES 表示法與文字（例如細胞系名稱或疾病名稱）的任務中，平均效能超越同類最佳效能，這可能是由於在預訓練期間學習到的脈絡。我們觀察到不同藥物類型任務（例如，涉及小分子的任務和涉及蛋白質的任務）之間具有正向轉移的證據，並且我們研究了模型大小、領域微調和提示策略對效能的影響。我們相信 Tx-LLM 代表了 LLM 編碼生化知識的重要一步，並且可以在藥物發現開發管線中作為端到端工具發揮未來的作用。

##### **Multi-Prompting Decoder Helps Better Language Understanding**
2406.06279v1 by Zifeng Cheng, Zhaoling Chen, Zhiwei Jiang, Yafeng Yin, Shiping Ge, Yuliang Liu, Qing Gu

Recent Pre-trained Language Models (PLMs) usually only provide users with the
inference APIs, namely the emerging Model-as-a-Service (MaaS) setting. To adapt
MaaS PLMs to downstream tasks without accessing their parameters and gradients,
some existing methods focus on the output-side adaptation of PLMs, viewing the
PLM as an encoder and then optimizing a task-specific decoder for decoding the
output hidden states and class scores of the PLM. Despite the effectiveness of
these methods, they only use a single prompt to query PLMs for decoding,
leading to a heavy reliance on the quality of the adopted prompt. In this
paper, we propose a simple yet effective Multi-Prompting Decoder (MPD)
framework for MaaS adaptation. The core idea is to query PLMs with multiple
different prompts for each sample, thereby obtaining multiple output hidden
states and class scores for subsequent decoding. Such multi-prompting decoding
paradigm can simultaneously mitigate reliance on the quality of a single
prompt, alleviate the issue of data scarcity under the few-shot setting, and
provide richer knowledge extracted from PLMs. Specifically, we propose two
decoding strategies: multi-prompting decoding with optimal transport for hidden
states and calibrated decoding for class scores. Extensive experiments
demonstrate that our method achieves new state-of-the-art results on multiple
natural language understanding datasets under the few-shot setting.

摘要：近期的预训练语言模型 (PLM) 通常只为用户提供推理 API，即新兴的模型即服务 (MaaS) 设置。为了在不访问其参数和梯度的情况下将 MaaS PLM 适应下游任务，一些现有方法专注于 PLM 的输出端适应，将 PLM 视为编码器，然后优化特定于任务的解码器来解码 PLM 的输出隐藏状态和类分数。尽管这些方法有效，但它们只使用一个提示来查询 PLM 进行解码，导致严重依赖所采用提示的质量。在本文中，我们提出了一个简单而有效的用于 MaaS 适应的多提示解码器 (MPD) 框架。其核心思想是使用多个不同的提示为每个样本查询 PLM，从而获得多个输出隐藏状态和类分数以进行后续解码。这种多提示解码范例可以同时减轻对单个提示质量的依赖，缓解小样本设置下的数据稀缺问题，并提供从 PLM 中提取的更丰富的知识。具体来说，我们提出了两种解码策略：用于隐藏状态的最优传输的多提示解码和用于类分数的校准解码。大量的实验表明，我们的方法在小样本设置下在多个自然语言理解数据集上取得了新的最先进的结果。

##### **MaskLID: Code-Switching Language Identification through Iterative Masking**
2406.06263v1 by Amir Hossein Kargaran, François Yvon, Hinrich Schütze

We present MaskLID, a simple, yet effective, code-switching (CS) language
identification (LID) method. MaskLID does not require any training and is
designed to complement current high-performance sentence-level LIDs.
Sentence-level LIDs are classifiers trained on monolingual texts to provide
single labels, typically using a softmax layer to turn scores into
probabilities. However, in cases where a sentence is composed in both L1 and L2
languages, the LID classifier often only returns the dominant label L1. To
address this limitation, MaskLID employs a strategy to mask text features
associated with L1, allowing the LID to classify the text as L2 in the next
round. This method uses the LID itself to identify the features that require
masking and does not rely on any external resource. In this work, we explore
the use of MaskLID for two open-source LIDs (GlotLID and OpenLID), that are
both based on the FastText architecture. Code and demo are available at
https://github.com/cisnlp/MaskLID.

摘要：我們提出 MaskLID，一種簡單但有效的代碼切換 (CS) 語言識別 (LID) 方法。MaskLID 不需要任何訓練，並且旨在補充當前高效能的句子層級 LID。句子層級 LID 是在單語文本上訓練的分類器，用於提供單一標籤，通常使用 softmax 層將分數轉換為機率。然而，在句子由 L1 和 L2 語言組成的案例中，LID 分類器通常只會回傳主要標籤 L1。為了解決此限制，MaskLID 採用一種策略來遮蔽與 L1 相關的文字特徵，讓 LID 能在下一個回合將文字分類為 L2。此方法使用 LID 本身來識別需要遮蔽的特徵，且不依賴任何外部資源。在這項工作中，我們探討將 MaskLID 用於兩個開源 LID (GlotLID 和 OpenLID)，它們都基於 FastText 架構。程式碼和示範可於 https://github.com/cisnlp/MaskLID 取得。

##### **Learning Fine-Grained Controllability on Speech Generation via Efficient Fine-Tuning**
2406.06251v1 by Chung-Ming Chien, Andros Tjandra, Apoorv Vyas, Matt Le, Bowen Shi, Wei-Ning Hsu

As the scale of generative models continues to grow, efficient reuse and
adaptation of pre-trained models have become crucial considerations. In this
work, we propose Voicebox Adapter, a novel approach that integrates
fine-grained conditions into a pre-trained Voicebox speech generation model
using a cross-attention module. To ensure a smooth integration of newly added
modules with pre-trained ones, we explore various efficient fine-tuning
approaches. Our experiment shows that the LoRA with bias-tuning configuration
yields the best performance, enhancing controllability without compromising
speech quality. Across three fine-grained conditional generation tasks, we
demonstrate the effectiveness and resource efficiency of Voicebox Adapter.
Follow-up experiments further highlight the robustness of Voicebox Adapter
across diverse data setups.

摘要：隨著生成式模型的規模持續成長，預訓練模型的有效再利用和適應已成為關鍵考量。在這項工作中，我們提出 Voicebox Adapter，一種新穎的方法，它使用跨注意力模組將細粒度條件整合到預訓練的 Voicebox 語音生成模型中。為了確保新增加的模組與預訓練模組順利整合，我們探討了各種有效微調方法。我們的實驗顯示，帶有偏差調整組態的 LoRA 產生最佳效能，增強可控性而不會損害語音品質。在三個細粒度條件式生成任務中，我們展示了 Voicebox Adapter 的有效性和資源效率。後續實驗進一步突顯了 Voicebox Adapter 在不同資料設定中的穩健性。

##### **Data Augmentation in Earth Observation: A Diffusion Model Approach**
2406.06218v1 by Tiago Sousa, Benoît Ries, Nicolas Guelfi

The scarcity of high-quality Earth Observation (EO) imagery poses a
significant challenge, despite its critical role in enabling precise analysis
and informed decision-making across various sectors. This scarcity is primarily
due to atmospheric conditions, seasonal variations, and limited geographical
coverage, which complicates the application of Artificial Intelligence (AI) in
EO. Data augmentation, a widely used technique in AI that involves generating
additional data mainly through parameterized image transformations, has been
employed to increase the volume and diversity of data. However, this method
often falls short in generating sufficient diversity across key semantic axes,
adversely affecting the accuracy of EO applications. To address this issue, we
propose a novel four-stage approach aimed at improving the diversity of
augmented data by integrating diffusion models. Our approach employs
meta-prompts for instruction generation, harnesses general-purpose
vision-language models for generating rich captions, fine-tunes an Earth
Observation diffusion model, and iteratively augments data. We conducted
extensive experiments using four different data augmentation techniques, and
our approach consistently demonstrated improvements, outperforming the
established augmentation methods, revealing its effectiveness in generating
semantically rich and diverse EO images.

摘要：儘管高品質地球觀測 (EO) 影像在促成精準分析和跨產業的明智決策扮演著至關重要的角色，但其稀缺性仍構成了一項重大挑戰。這種稀缺性主要來自於大氣條件、季節變化和有限的地理範圍，這使人工智慧 (AI) 在 EO 中的應用變得複雜。資料擴充是一種在 AI 中廣泛使用的技術，包括透過參數化的影像轉換來產生額外的資料，已被用於增加資料的數量和多樣性。然而，這種方法通常無法在關鍵的語義軸中產生足夠的多樣性，進而對 EO 應用程式的精確度造成負面影響。為了解決這個問題，我們提出了一種創新的四階段方法，旨在透過整合擴散模型來改善擴充資料的多樣性。我們的方法採用元提示來產生指示，利用通用視覺語言模型來產生豐富的標題，微調地球觀測擴散模型，並反覆擴充資料。我們使用四種不同的資料擴充技術進行了廣泛的實驗，而我們的做法持續展現出改進，優於既定的擴充方法，顯示出其在產生語義豐富且多樣化的 EO 影像方面的效能。

##### **A Statistical Theory of Regularization-Based Continual Learning**
2406.06213v1 by Xuyang Zhao, Huiyuan Wang, Weiran Huang, Wei Lin

We provide a statistical analysis of regularization-based continual learning
on a sequence of linear regression tasks, with emphasis on how different
regularization terms affect the model performance. We first derive the
convergence rate for the oracle estimator obtained as if all data were
available simultaneously. Next, we consider a family of generalized
$\ell_2$-regularization algorithms indexed by matrix-valued hyperparameters,
which includes the minimum norm estimator and continual ridge regression as
special cases. As more tasks are introduced, we derive an iterative update
formula for the estimation error of generalized $\ell_2$-regularized
estimators, from which we determine the hyperparameters resulting in the
optimal algorithm. Interestingly, the choice of hyperparameters can effectively
balance the trade-off between forward and backward knowledge transfer and
adjust for data heterogeneity. Moreover, the estimation error of the optimal
algorithm is derived explicitly, which is of the same order as that of the
oracle estimator. In contrast, our lower bounds for the minimum norm estimator
and continual ridge regression show their suboptimality. A byproduct of our
theoretical analysis is the equivalence between early stopping and generalized
$\ell_2$-regularization in continual learning, which may be of independent
interest. Finally, we conduct experiments to complement our theory.

摘要：<paragraph>我們提供基於正則化的持續學習在線性回歸任務序列上的統計分析，重點在於不同的正則化項如何影響模型效能。我們首先推導出假設所有資料同時可用的情況下所獲得的 oracle 估計量的收斂率。接下來，我們考慮一個由矩陣值超參數索引的廣義 $\ell_2$-正則化演算法族，其中包括最小範數估計量和連續嶺回歸作為特例。隨著更多任務的引入，我們推導出廣義 $\ell_2$-正則化估計量的估計誤差的迭代更新公式，由此我們確定產生最佳演算法的超參數。有趣的是，超參數的選擇可以有效平衡正向和反向知識轉移之間的權衡，並調整資料異質性。此外，最佳演算法的估計誤差是明確推導出來的，與 oracle 估計量的估計誤差同數量級。相比之下，我們對最小範數估計量和連續嶺回歸的下界顯示了它們的次最佳性。我們理論分析的副產品是早期停止和廣義 $\ell_2$-正則化在持續學習中的等價性，這可能是獨立的興趣。最後，我們進行實驗以補充我們的理論。</paragraph>

##### **2DP-2MRC: 2-Dimensional Pointer-based Machine Reading Comprehension Method for Multimodal Moment Retrieval**
2406.06201v1 by Jiajun He, Tomoki Toda

Moment retrieval aims to locate the most relevant moment in an untrimmed
video based on a given natural language query. Existing solutions can be
roughly categorized into moment-based and clip-based methods. The former often
involves heavy computations, while the latter, due to overlooking
coarse-grained information, typically underperforms compared to moment-based
models. Hence, this paper proposes a novel 2-Dimensional Pointer-based Machine
Reading Comprehension for Moment Retrieval Choice (2DP-2MRC) model to address
the issue of imprecise localization in clip-based methods while maintaining
lower computational complexity than moment-based methods. Specifically, we
introduce an AV-Encoder to capture coarse-grained information at moment and
video levels. Additionally, a 2D pointer encoder module is introduced to
further enhance boundary detection for target moment. Extensive experiments on
the HiREST dataset demonstrate that 2DP-2MRC significantly outperforms existing
baseline models.

摘要：時刻檢索旨在根據給定的自然語言查詢，在未修剪的影片中找到最相關的時刻。現有的解決方案大致可分類為基於時刻和基於片段的方法。前者通常涉及繁重的運算，而後者由於忽略了粗粒度資訊，通常表現不如基於時刻的模型。因此，本文提出了一個新的基於二維指標的機器閱讀理解時刻檢索選擇 (2DP-2MRC) 模型，以解決基於片段的方法中定位不精確的問題，同時維持比基於時刻的方法更低的運算複雜度。具體來說，我們引入了 AV 編碼器來擷取時刻和影片層級的粗粒度資訊。此外，還引入了 2D 指標編碼器模組，以進一步增強目標時刻的邊界檢測。在 HiREST 資料集上的廣泛實驗證明，2DP-2MRC 明顯優於現有的基線模型。

##### **LINGOLY: A Benchmark of Olympiad-Level Linguistic Reasoning Puzzles in Low-Resource and Extinct Languages**
2406.06196v1 by Andrew M. Bean, Simi Hellsten, Harry Mayne, Jabez Magomere, Ethan A. Chi, Ryan Chi, Scott A. Hale, Hannah Rose Kirk

In this paper, we present the LingOly benchmark, a novel benchmark for
advanced reasoning abilities in large language models. Using challenging
Linguistic Olympiad puzzles, we evaluate (i) capabilities for in-context
identification and generalisation of linguistic patterns in very low-resource
or extinct languages, and (ii) abilities to follow complex task instructions.
The LingOly benchmark covers more than 90 mostly low-resource languages,
minimising issues of data contamination, and contains 1,133 problems across 6
formats and 5 levels of human difficulty. We assess performance with both
direct accuracy and comparison to a no-context baseline to penalise
memorisation. Scores from 11 state-of-the-art LLMs demonstrate the benchmark to
be challenging, and models perform poorly on the higher difficulty problems. On
harder problems, even the top model only achieved 35.3% accuracy, 21.7%
improvement over the no-context baseline. Large closed models typically
outperform open models, and in general, the higher resource the language, the
better the scores. These results indicate, in absence of memorisation, true
multi-step out-of-domain reasoning remains a challenge for current language
models.

摘要：在本文中，我们提出了 LingOly Benchmark，这是一个针对大型语言模型的高级推理能力的新基准。通过使用具有挑战性的语言奥林匹克难题，我们评估了（i）在极低资源或灭绝语言中对语言模式进行语境识别和概括的能力，以及（ii）遵循复杂任务说明的能力。LingOly Benchmark 涵盖了 90 多种低资源语言，最大程度地减少了数据污染问题，并包含了 6 种格式和 5 个难度等级的 1,133 个问题。我们通过直接准确性和与无上下文基准的比较来评估性能，以惩罚记忆。来自 11 个最先进 LLM 的分数表明该基准具有挑战性，并且模型在难度较高的难题上表现不佳。在较难的问题上，即使是顶级模型也只达到 35.3% 的准确度，比无上下文基准提高了 21.7%。大型封闭模型通常优于开放模型，并且一般来说，语言资源越多，分数就越好。这些结果表明，在没有记忆的情况下，真正的多步骤域外推理仍然是当前语言模型面临的挑战。

##### **Generalized Nested Latent Variable Models for Lossy Coding applied to Wind Turbine Scenarios**
2406.06165v1 by Raül Pérez-Gonzalo, Andreas Espersen, Antonio Agudo

Rate-distortion optimization through neural networks has accomplished
competitive results in compression efficiency and image quality. This
learning-based approach seeks to minimize the compromise between compression
rate and reconstructed image quality by automatically extracting and retaining
crucial information, while discarding less critical details. A successful
technique consists in introducing a deep hyperprior that operates within a
2-level nested latent variable model, enhancing compression by capturing
complex data dependencies. This paper extends this concept by designing a
generalized L-level nested generative model with a Markov chain structure. We
demonstrate as L increases that a trainable prior is detrimental and explore a
common dimensionality along the distinct latent variables to boost compression
performance. As this structured framework can represent autoregressive coders,
we outperform the hyperprior model and achieve state-of-the-art performance
while reducing substantially the computational cost. Our experimental
evaluation is performed on wind turbine scenarios to study its application on
visual inspections

摘要：透過神經網路進行速率失真最佳化，在壓縮效率和影像品質方面已取得具競爭力的成果。這種基於學習的方法，透過自動擷取和保留關鍵資訊，同時捨棄較不重要的細節，以最小化壓縮速率和重建影像品質之間的折衷。一種成功的技術是引入一個在 2 層嵌套潛在變數模型中運作的深度超先驗，透過擷取複雜的資料相依性來增強壓縮。本文透過設計一個具有馬可夫鏈結構的廣義 L 層嵌套生成模型，來延伸這個概念。我們證明隨著 L 的增加，一個可訓練的先驗是有害的，並探索一個沿著不同潛在變數的共同維度，以提升壓縮效能。由於這個結構化架構可以表示自迴歸編碼器，我們優於超先驗模型，並在大幅降低運算成本的同時，達到最先進的效能。我們的實驗評估是在風力渦輪機場景中進行，以研究其在視覺檢查中的應用。

##### **Get rich quick: exact solutions reveal how unbalanced initializations promote rapid feature learning**
2406.06158v1 by Daniel Kunin, Allan Raventós, Clémentine Dominé, Feng Chen, David Klindt, Andrew Saxe, Surya Ganguli

While the impressive performance of modern neural networks is often
attributed to their capacity to efficiently extract task-relevant features from
data, the mechanisms underlying this rich feature learning regime remain
elusive, with much of our theoretical understanding stemming from the opposing
lazy regime. In this work, we derive exact solutions to a minimal model that
transitions between lazy and rich learning, precisely elucidating how
unbalanced layer-specific initialization variances and learning rates determine
the degree of feature learning. Our analysis reveals that they conspire to
influence the learning regime through a set of conserved quantities that
constrain and modify the geometry of learning trajectories in parameter and
function space. We extend our analysis to more complex linear models with
multiple neurons, outputs, and layers and to shallow nonlinear networks with
piecewise linear activation functions. In linear networks, rapid feature
learning only occurs with balanced initializations, where all layers learn at
similar speeds. While in nonlinear networks, unbalanced initializations that
promote faster learning in earlier layers can accelerate rich learning. Through
a series of experiments, we provide evidence that this unbalanced rich regime
drives feature learning in deep finite-width networks, promotes
interpretability of early layers in CNNs, reduces the sample complexity of
learning hierarchical data, and decreases the time to grokking in modular
arithmetic. Our theory motivates further exploration of unbalanced
initializations to enhance efficient feature learning.

摘要：儘管現代神經網路令人印象深刻的效能通常歸因於其從資料中有效提取與任務相關特徵的能力，但這種豐富特徵學習機制背後的機制仍然難以捉摸，而我們大部分的理論理解都源自於相反的懶惰機制。在這項研究中，我們導出了一個在懶惰學習和豐富學習之間轉換的最小模型的精確解，精確闡明了不平衡的特定層初始化變異數和學習率如何決定特徵學習的程度。我們的分析揭示了它們串謀透過一組受保護的數量來影響學習機制，這些數量約束和修改了學習軌跡在參數和函數空間中的幾何形狀。我們將我們的分析延伸到具有多個神經元、輸出和層的更複雜線性模型，以及具有分段線性激活函數的淺層非線性網路。在線性網路中，快速特徵學習僅發生在平衡的初始化中，其中所有層級都以類似的速度學習。而在非線性網路中，在較早層級促進更快學習的不平衡初始化可以加速豐富學習。透過一系列實驗，我們提供了證據證明這種不平衡的豐富機制推動了深度有限寬度網路中的特徵學習，提升了 CNN 中早期層級的可解釋性，降低了學習階層資料的樣本複雜性，並減少了在模組化算術中理解的時間。我們的理論激勵進一步探索不平衡的初始化，以增強有效率的特徵學習。

##### **Language Models Resist Alignment**
2406.06144v1 by Jiaming Ji, Kaile Wang, Tianyi Qiu, Boyuan Chen, Jiayi Zhou, Changye Li, Hantao Lou, Yaodong Yang

Large language models (LLMs) may exhibit undesirable behaviors. Recent
efforts have focused on aligning these models to prevent harmful generation.
Despite these efforts, studies have shown that even a well-conducted alignment
process can be easily circumvented, whether intentionally or accidentally. Do
alignment fine-tuning have robust effects on models, or are merely superficial?
In this work, we answer this question through both theoretical and empirical
means. Empirically, we demonstrate the elasticity of post-alignment models,
i.e., the tendency to revert to the behavior distribution formed during the
pre-training phase upon further fine-tuning. Using compression theory, we
formally derive that such fine-tuning process \textit{disproportionately}
undermines alignment compared to pre-training, potentially by orders of
magnitude. We conduct experimental validations to confirm the presence of
elasticity across models of varying types and sizes. Specifically, we find that
model performance declines rapidly before reverting to the pre-training
distribution, after which the rate of decline drops significantly. We further
reveal that elasticity positively correlates with increased model size and the
expansion of pre-training data. Our discovery signifies the importance of
taming the inherent elasticity of LLMs, thereby overcoming the resistance of
LLMs to alignment finetuning.

摘要：大型語言模型 (LLM) 可能會表現出不良行為。最近的努力集中於調整這些模型以防止有害生成。儘管有這些努力，研究表明，即使是進行良好的調整過程，也可能在有意或無意間輕易地被迴避。調整微調對模型有強大的影響，還是僅僅是表面上的？在這項工作中，我們通過理論和經驗方法回答這個問題。經驗上，我們展示了後調整模型的彈性，即在進一步微調時恢復到預訓練階段形成的行為分佈的趨勢。使用壓縮理論，我們正式推導出這種微調過程與預訓練相比，對齊方式的影響「不成比例」，可能達到數量級。我們進行實驗驗證以確認各種類型和規模的模型中彈性的存在。具體來說，我們發現模型性能在恢復到預訓練分佈之前迅速下降，之後下降率顯著下降。我們進一步揭示彈性與模型尺寸的增加和預訓練數據的擴展呈正相關。我們的發現表明馴服 LLM 固有的彈性非常重要，從而克服了 LLM 對調整微調的抵抗力。

##### **Can I understand what I create? Self-Knowledge Evaluation of Large Language Models**
2406.06140v1 by Zhiquan Tan, Lai Wei, Jindong Wang, Xing Xie, Weiran Huang

Large language models (LLMs) have achieved remarkable progress in linguistic
tasks, necessitating robust evaluation frameworks to understand their
capabilities and limitations. Inspired by Feynman's principle of understanding
through creation, we introduce a self-knowledge evaluation framework that is
easy to implement, evaluating models on their ability to comprehend and respond
to self-generated questions. Our findings, based on testing multiple models
across diverse tasks, reveal significant gaps in the model's self-knowledge
ability. Further analysis indicates these gaps may be due to misalignment with
human attention mechanisms. Additionally, fine-tuning on self-generated math
task may enhance the model's math performance, highlighting the potential of
the framework for efficient and insightful model evaluation and may also
contribute to the improvement of LLMs.

摘要：大型語言模型 (LLM) 在語言任務上取得了顯著進展，需要強大的評估框架來了解其能力和限制。受費曼通過創造力理解原理的啟發，我們引入了一個易於實作的自知評估框架，根據模型理解和回應自生問題的能力來評估模型。我們的研究結果基於對多個模型在不同任務中的測試，揭示了模型自知能力的顯著差距。進一步的分析表明，這些差距可能是由於與人類注意力機制不一致所致。此外，針對自生數學任務進行微調可以增強模型的數學效能，突顯了該框架在高效且有見地的模型評估方面的潛力，並且可能也有助於改進 LLM。

##### **Thunder : Unified Regression-Diffusion Speech Enhancement with a Single Reverse Step using Brownian Bridge**
2406.06139v1 by Thanapat Trachu, Chawan Piansaddhayanon, Ekapol Chuangsuwanich

Diffusion-based speech enhancement has shown promising results, but can
suffer from a slower inference time. Initializing the diffusion process with
the enhanced audio generated by a regression-based model can be used to reduce
the computational steps required. However, these approaches often necessitate a
regression model, further increasing the system's complexity. We propose
Thunder, a unified regression-diffusion model that utilizes the Brownian bridge
process which can allow the model to act in both modes. The regression mode can
be accessed by setting the diffusion time step closed to 1. However, the
standard score-based diffusion modeling does not perform well in this setup due
to gradient instability. To mitigate this problem, we modify the diffusion
model to predict the clean speech instead of the score function, achieving
competitive performance with a more compact model size and fewer reverse steps.

摘要：基於擴散的語音增強已展現出有前途的結果，但可能會遭受較慢的推理時間。用基於回歸模型所產生的增強音訊初始化擴散過程，可減少所需的運算步驟。然而，這些方法通常需要一個回歸模型，進一步增加系統的複雜性。我們提出 Thunder，一個統一的回歸擴散模型，它利用布朗橋過程，讓模型可以在兩種模式下運作。回歸模式可透過將擴散時間步驟設定接近 1 來存取。然而，標準基於分數的擴散建模在這種設定下無法順利執行，原因是梯度不穩定。為了減輕這個問題，我們修改擴散模型，以預測乾淨的語音，而非分數函數，並以更精簡的模型大小和更少的反向步驟，達成具有競爭力的效能。

##### **DiffInject: Revisiting Debias via Synthetic Data Generation using Diffusion-based Style Injection**
2406.06134v1 by Donggeun Ko, Sangwoo Jo, Dongjun Lee, Namjun Park, Jaekwang Kim

Dataset bias is a significant challenge in machine learning, where specific
attributes, such as texture or color of the images are unintentionally learned
resulting in detrimental performance. To address this, previous efforts have
focused on debiasing models either by developing novel debiasing algorithms or
by generating synthetic data to mitigate the prevalent dataset biases. However,
generative approaches to date have largely relied on using bias-specific
samples from the dataset, which are typically too scarce. In this work, we
propose, DiffInject, a straightforward yet powerful method to augment synthetic
bias-conflict samples using a pretrained diffusion model. This approach
significantly advances the use of diffusion models for debiasing purposes by
manipulating the latent space. Our framework does not require any explicit
knowledge of the bias types or labelling, making it a fully unsupervised
setting for debiasing. Our methodology demonstrates substantial result in
effectively reducing dataset bias.

摘要：資料集偏差是機器學習中的一項重大挑戰，其中特定屬性（例如影像的紋理或顏色）會在無意間被學習，導致效能下降。為了解決此問題，先前的努力已專注於透過開發新的去偏差演算法或產生合成資料來消除模型偏差，以減輕普遍存在的資料集偏差。然而，迄今為止的生成方法在很大程度上依賴於使用資料集中特定偏差的樣本，而這些樣本通常過於稀少。在這項工作中，我們提出 DiffInject，這是一種直接而強大的方法，可使用預先訓練的擴散模型來增加合成偏差衝突樣本。此方法透過操作潛在空間，大幅提升擴散模型在去偏差目的中的使用。我們的架構不需要任何有關偏差類型或標籤的明確知識，使其成為一個完全無監督的去偏差設定。我們的研究方法在有效減少資料集偏差方面展現出顯著的結果。

##### **Building Bridges: A Dataset for Evaluating Gender-Fair Machine Translation into German**
2406.06131v1 by Manuel Lardelli, Giuseppe Attanasio, Anne Lauscher

The translation of gender-neutral person-referring terms (e.g., the students)
is often non-trivial. Translating from English into German poses an interesting
case -- in German, person-referring nouns are usually gender-specific, and if
the gender of the referent(s) is unknown or diverse, the generic masculine (die
Studenten (m.)) is commonly used. This solution, however, reduces the
visibility of other genders, such as women and non-binary people. To counteract
gender discrimination, a societal movement towards using gender-fair language
exists (e.g., by adopting neosystems). However, gender-fair German is currently
barely supported in machine translation (MT), requiring post-editing or manual
translations. We address this research gap by studying gender-fair language in
English-to-German MT. Concretely, we enrich a community-created gender-fair
language dictionary and sample multi-sentence test instances from encyclopedic
text and parliamentary speeches. Using these novel resources, we conduct the
first benchmark study involving two commercial systems and six neural MT models
for translating words in isolation and natural contexts across two domains. Our
findings show that most systems produce mainly masculine forms and rarely
gender-neutral variants, highlighting the need for future research. We release
code and data at
https://github.com/g8a9/building-bridges-gender-fair-german-mt.

摘要：性別中立的人稱術語（例如學生）的翻譯通常非同小可。從英語翻譯成德語是一個有趣的案例——在德語中，人稱名詞通常是性別特定的，如果所指者的性別未知或多樣，則通常使用一般陽性（die Studenten (m.)）。然而，這種解決方案降低了其他性別（例如女性和非二元性別者）的能見度。為了對抗性別歧視，存在著一種使用性別公平語言的社會運動（例如，通過採用新系統）。然而，性別公平的德語目前在機器翻譯（MT）中幾乎沒有支持，需要後編輯或人工翻譯。我們通過研究英譯德 MT 中的性別公平語言來解決這一研究差距。具體來說，我們豐富了一本社區創建的性別公平語言詞典，並從百科全書文本和議會演講中抽取了多句測試實例。使用這些新資源，我們進行了第一個基準研究，其中涉及兩個商業系統和六個神經 MT 模型，用於翻譯兩個領域中孤立的單詞和自然語境。我們的研究結果表明，大多數系統主要產生陽性形式，很少產生性別中立的變體，這突顯了未來研究的必要性。我們在 https://github.com/g8a9/building-bridges-gender-fair-german-mt. 發布代碼和數據。

##### **Verifiable Generation with Subsentence-Level Fine-Grained Citations**
2406.06125v1 by Shuyang Cao, Lu Wang

Verifiable generation requires large language models (LLMs) to cite source
documents supporting their outputs, thereby improve output transparency and
trustworthiness. Yet, previous work mainly targets the generation of
sentence-level citations, lacking specificity about which parts of a sentence
are backed by the cited sources. This work studies verifiable generation with
subsentence-level fine-grained citations for more precise location of generated
content supported by the cited sources. We first present a dataset, SCiFi,
comprising 10K Wikipedia paragraphs with subsentence-level citations. Each
paragraph is paired with a set of candidate source documents for citation and a
query that triggers the generation of the paragraph content. On SCiFi, we
evaluate the performance of state-of-the-art LLMs and strategies for processing
long documents designed for these models. Our experiment results reveals key
factors that could enhance the quality of citations, including the expansion of
the source documents' context accessible to the models and the implementation
of specialized model tuning.

摘要：可驗證生成需要大型語言模型 (LLM) 引用支援其輸出的原始文件，從而提升輸出透明度和可信度。然而，先前的研究主要針對句子層級引文的生成，缺乏關於句子哪些部分受到引文來源支持的具體資訊。本研究探討可驗證生成，並採用子句層級的細緻引文，以更精確地定位由引文來源支援的生成內容。我們首先提出一個名為 SCiFi 的資料集，其中包含 10K 個帶有子句層級引文的維基百科段落。每個段落都與一組候選原始文件配對，以供引文和觸發段落內容生成的查詢。在 SCiFi 上，我們評估了最先進的 LLM 的效能，以及針對這些模型設計的長文件處理策略。我們的實驗結果揭示了幾個可以提升引文品質的關鍵因素，包括擴充模型可存取的原始文件內容，以及實作專門的模型調整。

##### **Enhancing Long-Term Memory using Hierarchical Aggregate Tree for Retrieval Augmented Generation**
2406.06124v1 by Aadharsh Aadhithya A, Sachin Kumar S, Soman K. P

Large language models have limited context capacity, hindering reasoning over
long conversations. We propose the Hierarchical Aggregate Tree memory structure
to recursively aggregate relevant dialogue context through conditional tree
traversals. HAT encapsulates information from children nodes, enabling broad
coverage with depth control. We formulate finding best context as optimal tree
traversal. Experiments show HAT improves dialog coherence and summary quality
over baseline contexts, demonstrating the techniques effectiveness for multi
turn reasoning without exponential parameter growth. This memory augmentation
enables more consistent, grounded longform conversations from LLMs

摘要：大型語言模型的背景容量有限，阻礙了對長對話的推理。我們提出分層聚合樹記憶結構，通過條件樹遍歷遞迴聚合相關對話背景。HAT 封裝了子節點的信息，實現了廣泛覆蓋和深度控制。我們將找到最佳背景表述為最佳樹遍歷。實驗表明，HAT 在對話連貫性和摘要質量方面優於基線背景，證明了該技術在沒有指數參數增長的情況下進行多輪推理的有效性。這種記憶擴充使大型語言模型能夠進行更一致、更紮實的長篇對話。

##### **JenGAN: Stacked Shifted Filters in GAN-Based Speech Synthesis**
2406.06111v1 by Hyunjae Cho, Junhyeok Lee, Wonbin Jung

Non-autoregressive GAN-based neural vocoders are widely used due to their
fast inference speed and high perceptual quality. However, they often suffer
from audible artifacts such as tonal artifacts in their generated results.
Therefore, we propose JenGAN, a new training strategy that involves stacking
shifted low-pass filters to ensure the shift-equivariant property. This method
helps prevent aliasing and reduce artifacts while preserving the model
structure used during inference. In our experimental evaluation, JenGAN
consistently enhances the performance of vocoder models, yielding significantly
superior scores across the majority of evaluation metrics.

摘要：基於非自迴歸 GAN 的神經音訊編碼器因其快速推論速度和高感知品質而廣泛使用。然而，它們的生成結果中常出現可聽見的人工製品，例如音調的人工製品。因此，我們提出了 JenGAN，一種新的訓練策略，其中涉及堆疊移位的低通濾波器以確保移位等變性。此方法有助於防止混疊並減少人工製品，同時保留推論期間使用的模型結構。在我們的實驗評估中，JenGAN 持續增強音訊編碼器模型的效能，在大部分評估指標中產生顯著優異的分數。

##### **Recurrent Context Compression: Efficiently Expanding the Context Window of LLM**
2406.06110v1 by Chensen Huang, Guibo Zhu, Xuepeng Wang, Yifei Luo, Guojing Ge, Haoran Chen, Dong Yi, Jinqiao Wang

To extend the context length of Transformer-based large language models
(LLMs) and improve comprehension capabilities, we often face limitations due to
computational resources and bounded memory storage capacity. This work
introduces a method called Recurrent Context Compression (RCC), designed to
efficiently expand the context window length of LLMs within constrained storage
space. We also investigate the issue of poor model responses when both
instructions and context are compressed in downstream tasks, and propose an
instruction reconstruction method to mitigate this problem. We validated the
effectiveness of our approach on multiple tasks, achieving a compression rate
of up to 32x on text reconstruction tasks with a BLEU4 score close to 0.95, and
nearly 100\% accuracy on a passkey retrieval task with a sequence length of 1M.
Finally, our method demonstrated competitive performance in long-text
question-answering tasks compared to non-compressed methods, while
significantly saving storage resources in long-text inference tasks. Our code,
models, and demo are available at https://github.com/WUHU-G/RCC_Transformer

摘要：為了擴展基於 Transformer 的大型語言模型 (LLM) 的內容長度，並改善理解能力，我們常常會因為計算資源和受限的記憶體儲存容量而面臨限制。這項工作介紹一種稱為遞迴內容壓縮 (RCC) 的方法，旨在有效地擴展 LLM 在受限儲存空間內的內容視窗長度。我們也探討了當指示和內容在下游任務中都經過壓縮時，模型回應不佳的問題，並提出了一種指示重建方法來減輕這個問題。我們在多項任務中驗證了我們方法的有效性，在文本重建任務中實現了高達 32 倍的壓縮率，BLEU4 分數接近 0.95，並且在序列長度為 1M 的密鑰檢索任務中準確率接近 100%。最後，我們的模型在長文本問答任務中展現出與未壓縮方法相當的效能，同時在長文本推論任務中大幅節省了儲存資源。我們的程式碼、模型和示範可在 https://github.com/WUHU-G/RCC_Transformer 取得。

##### **EXPIL: Explanatory Predicate Invention for Learning in Games**
2406.06107v1 by Jingyuan Sha, Hikaru Shindo, Quentin Delfosse, Kristian Kersting, Devendra Singh Dhami

Reinforcement learning (RL) has proven to be a powerful tool for training
agents that excel in various games. However, the black-box nature of neural
network models often hinders our ability to understand the reasoning behind the
agent's actions. Recent research has attempted to address this issue by using
the guidance of pretrained neural agents to encode logic-based policies,
allowing for interpretable decisions. A drawback of such approaches is the
requirement of large amounts of predefined background knowledge in the form of
predicates, limiting its applicability and scalability. In this work, we
propose a novel approach, Explanatory Predicate Invention for Learning in Games
(EXPIL), that identifies and extracts predicates from a pretrained neural
agent, later used in the logic-based agents, reducing the dependency on
predefined background knowledge. Our experimental evaluation on various games
demonstrate the effectiveness of EXPIL in achieving explainable behavior in
logic agents while requiring less background knowledge.

摘要：強化學習 (RL) 已被證明是一種強大的工具，可用於訓練在各種遊戲中表現出色的代理。然而，神經網路模型的黑盒性質常常阻礙我們理解代理動作背後的推理。最近的研究嘗試通過使用預訓練神經代理的指導來編碼基於邏輯的策略來解決這個問題，從而允許做出可解釋的決策。這種方法的一個缺點是需要大量預定義的背景知識，例如謂詞，這限制了它的適用性和可擴展性。在這項工作中，我們提出了一種新穎的方法，即遊戲學習的解釋性謂詞發明 (EXPIL)，它從預訓練的神經代理中識別和提取謂詞，稍後用於基於邏輯的代理中，從而減少對預定義背景知識的依賴。我們在各種遊戲中進行的實驗評估證明了 EXPIL 在邏輯代理中實現可解釋行為的有效性，同時需要更少的背景知識。

##### **StreamAtt: Direct Streaming Speech-to-Text Translation with Attention-based Audio History Selection**
2406.06097v1 by Sara Papi, Marco Gaido, Matteo Negri, Luisa Bentivogli

Streaming speech-to-text translation (StreamST) is the task of automatically
translating speech while incrementally receiving an audio stream. Unlike
simultaneous ST (SimulST), which deals with pre-segmented speech, StreamST
faces the challenges of handling continuous and unbounded audio streams. This
requires additional decisions about what to retain of the previous history,
which is impractical to keep entirely due to latency and computational
constraints. Despite the real-world demand for real-time ST, research on
streaming translation remains limited, with existing works solely focusing on
SimulST. To fill this gap, we introduce StreamAtt, the first StreamST policy,
and propose StreamLAAL, the first StreamST latency metric designed to be
comparable with existing metrics for SimulST. Extensive experiments across all
8 languages of MuST-C v1.0 show the effectiveness of StreamAtt compared to a
naive streaming baseline and the related state-of-the-art SimulST policy,
providing a first step in StreamST research.

摘要：串流語音轉文字翻譯 (StreamST) 是一項任務，自動翻譯語音，同時遞增接收音訊串流。與處理預先分段語音的同步 ST (SimulST) 不同，StreamST 面臨處理連續且無界音訊串流的挑戰。這需要額外決定要保留多少先前的記錄，由於延遲和運算限制，完全保留是不切實際的。儘管實時 ST 有實際需求，串流翻譯的研究仍然有限，現有的作品僅專注於 SimulST。為了填補這個空白，我們介紹 StreamAtt，第一個 StreamST 政策，並提出 StreamLAAL，第一個 StreamST 延遲指標，設計成與現有的 SimulST 指標相容。在 MuST-C v1.0 的所有 8 種語言中進行的廣泛實驗顯示了 StreamAtt 的有效性，與天真的串流基準和相關的最新 SimulST 政策相比，為 StreamST 研究提供了第一步。

##### **Efficient k-Nearest-Neighbor Machine Translation with Dynamic Retrieval**
2406.06073v1 by Yan Gao, Zhiwei Cao, Zhongjian Miao, Baosong Yang, Shiyu Liu, Min Zhang, Jinsong Su

To achieve non-parametric NMT domain adaptation, $k$-Nearest-Neighbor Machine
Translation ($k$NN-MT) constructs an external datastore to store
domain-specific translation knowledge, which derives a $k$NN distribution to
interpolate the prediction distribution of the NMT model via a linear
interpolation coefficient $\lambda$. Despite its success, $k$NN retrieval at
each timestep leads to substantial time overhead. To address this issue,
dominant studies resort to $k$NN-MT with adaptive retrieval ($k$NN-MT-AR),
which dynamically estimates $\lambda$ and skips $k$NN retrieval if $\lambda$ is
less than a fixed threshold. Unfortunately, $k$NN-MT-AR does not yield
satisfactory results. In this paper, we first conduct a preliminary study to
reveal two key limitations of $k$NN-MT-AR: 1) the optimization gap leads to
inaccurate estimation of $\lambda$ for determining $k$NN retrieval skipping,
and 2) using a fixed threshold fails to accommodate the dynamic demands for
$k$NN retrieval at different timesteps. To mitigate these limitations, we then
propose $k$NN-MT with dynamic retrieval ($k$NN-MT-DR) that significantly
extends vanilla $k$NN-MT in two aspects. Firstly, we equip $k$NN-MT with a
MLP-based classifier for determining whether to skip $k$NN retrieval at each
timestep. Particularly, we explore several carefully-designed scalar features
to fully exert the potential of the classifier. Secondly, we propose a
timestep-aware threshold adjustment method to dynamically generate the
threshold, which further improves the efficiency of our model. Experimental
results on the widely-used datasets demonstrate the effectiveness and
generality of our model.\footnote{Our code is available at
\url{https://github.com/DeepLearnXMU/knn-mt-dr}.

摘要：<paragraph>為了達成非參數式 NMT 領域適應，$k$ 最近鄰機器翻譯 ($k$NN-MT) 建構一個外部資料儲存庫，用來儲存領域特定的翻譯知識，並由此衍生出一個 $k$NN 分布，透過線性插值係數 $\lambda$ 來內插 NMT 模型的預測分布。儘管它成功了，但每次時間步長的 $k$NN 擷取都會導致大量的時間開銷。為了解決這個問題，主要的研究所採用具有適應性擷取的 $k$NN-MT ($k$NN-MT-AR)，它動態估計 $\lambda$，並在 $\lambda$ 小於固定閾值時略過 $k$NN 擷取。不幸的是，$k$NN-MT-AR 沒有產生令人滿意的結果。在本文中，我們首先進行初步研究，以揭示 $k$NN-MT-AR 的兩個主要限制：1) 最佳化差距導致不準確估計 $\lambda$ 以決定略過 $k$NN 擷取，以及 2) 使用固定閾值無法滿足不同時間步長對 $k$NN 擷取的動態需求。為了減輕這些限制，我們接著提出具有動態擷取的 $k$NN-MT ($k$NN-MT-DR)，它在兩個方面顯著地延伸了香草 $k$NN-MT。首先，我們為 $k$NN-MT 配備一個基於 MLP 的分類器，用於確定是否在每個時間步長略過 $k$NN 擷取。特別是，我們探討了幾個精心設計的純量特徵，以充分發揮分類器的潛力。其次，我們提出了一個具時間步長感知的閾值調整方法，用於動態產生閾值，進一步提高了我們模型的效率。在廣泛使用的資料集上的實驗結果證明了我們模型的有效性和普遍性。\footnote{我們的程式碼可在 \url{https://github.com/DeepLearnXMU/knn-mt-dr} 取得。}</paragraph>

##### **ProcessPainter: Learn Painting Process from Sequence Data**
2406.06062v1 by Yiren Song, Shijie Huang, Chen Yao, Xiaojun Ye, Hai Ci, Jiaming Liu, Yuxuan Zhang, Mike Zheng Shou

The painting process of artists is inherently stepwise and varies
significantly among different painters and styles. Generating detailed,
step-by-step painting processes is essential for art education and research,
yet remains largely underexplored. Traditional stroke-based rendering methods
break down images into sequences of brushstrokes, yet they fall short of
replicating the authentic processes of artists, with limitations confined to
basic brushstroke modifications. Text-to-image models utilizing diffusion
processes generate images through iterative denoising, also diverge
substantially from artists' painting process. To address these challenges, we
introduce ProcessPainter, a text-to-video model that is initially pre-trained
on synthetic data and subsequently fine-tuned with a select set of artists'
painting sequences using the LoRA model. This approach successfully generates
painting processes from text prompts for the first time. Furthermore, we
introduce an Artwork Replication Network capable of accepting arbitrary-frame
input, which facilitates the controlled generation of painting processes,
decomposing images into painting sequences, and completing semi-finished
artworks. This paper offers new perspectives and tools for advancing art
education and image generation technology.

摘要：藝術家的繪畫過程本質上是逐步進行的，並且在不同的畫家和風格之間有顯著的差異。生成詳細的、逐步的繪畫過程對於藝術教育和研究至關重要，但仍未得到充分的探索。傳統的基於筆觸的渲染方法將圖像分解為一系列筆觸，但它們無法複製藝術家的真實過程，其局限性僅限於基本的筆觸修改。利用擴散過程的文字到圖像模型通過迭代去噪來生成圖像，也與藝術家的繪畫過程有很大不同。為了應對這些挑戰，我們引入了 ProcessPainter，這是一個文字到視頻模型，最初在合成數據上進行預訓練，然後使用 LoRA 模型對一組選定的藝術家繪畫序列進行微調。這種方法首次成功地從文本提示中生成了繪畫過程。此外，我們引入了一個 Artwork Replication Network，它能夠接受任意幀輸入，這有助於控制繪畫過程的生成，將圖像分解為繪畫序列，並完成半成品藝術品。本文為推進藝術教育和圖像生成技術提供了新的視角和工具。

##### **Greedy SLIM: A SLIM-Based Approach For Preference Elicitation**
2406.06061v1 by Claudius Proissl, Amel Vatic, Helmut Waldschmidt

Preference elicitation is an active learning approach to tackle the
cold-start problem of recommender systems. Roughly speaking, new users are
asked to rate some carefully selected items in order to compute appropriate
recommendations for them. To the best of our knowledge, we are the first to
propose a method for preference elicitation that is based on SLIM , a
state-of-the-art technique for top-N recommendation. Our approach mainly
consists of a new training technique for SLIM, which we call Greedy SLIM. This
technique iteratively selects items for the training in order to minimize the
SLIM loss greedily. We conduct offline experiments as well as a user study to
assess the performance of this new method. The results are remarkable,
especially with respect to the user study. We conclude that Greedy SLIM seems
to be more suitable for preference elicitation than widely used methods based
on latent factor models.

摘要：偏好引導是一種主動學習方法，用於解決推薦系統的冷啟動問題。粗略來說，會要求新使用者評分一些經過精心挑選的項目，以便為他們計算出合適的推薦。據我們所知，我們是第一個提出基於 SLIM（一種最先進的頂尖推薦技術）的偏好引導方法。我們的做法主要包含一種 SLIM 的新訓練技術，我們稱之為貪婪 SLIM。此技術會反覆選擇訓練項目，以貪婪的方式最小化 SLIM 損失。我們進行了離線實驗和使用者研究，以評估此新方法的效能。結果非常顯著，特別是在使用者研究方面。我們得出結論，與基於潛在因子模型的廣泛使用方法相比，貪婪 SLIM 似乎更適合偏好引導。

##### **Synth-SBDH: A Synthetic Dataset of Social and Behavioral Determinants of Health for Clinical Text**
2406.06056v1 by Avijit Mitra, Emily Druhl, Raelene Goodwin, Hong Yu

Social and behavioral determinants of health (SBDH) play a crucial role in
health outcomes and are frequently documented in clinical text. Automatically
extracting SBDH information from clinical text relies on publicly available
good-quality datasets. However, existing SBDH datasets exhibit substantial
limitations in their availability and coverage. In this study, we introduce
Synth-SBDH, a novel synthetic dataset with detailed SBDH annotations,
encompassing status, temporal information, and rationale across 15 SBDH
categories. We showcase the utility of Synth-SBDH on three tasks using
real-world clinical datasets from two distinct hospital settings, highlighting
its versatility, generalizability, and distillation capabilities. Models
trained on Synth-SBDH consistently outperform counterparts with no Synth-SBDH
training, achieving up to 62.5% macro-F improvements. Additionally, Synth-SBDH
proves effective for rare SBDH categories and under-resource constraints. Human
evaluation demonstrates a Human-LLM alignment of 71.06% and uncovers areas for
future refinements.

摘要：社會和行為健康決定因素 (SBDH) 在健康結果中扮演關鍵角色，並且經常在臨床文本中被記錄下來。自動從臨床文本中萃取 SBDH 資訊仰賴公開且品質良好的資料集。然而，現有的 SBDH 資料集在取得和涵蓋範圍上展現出大量的限制。在這項研究中，我們引進了 Synth-SBDH，一個具有詳細 SBDH 標註的新合成資料集，涵蓋了 15 個 SBDH 類別的狀態、時間資訊和依據。我們使用來自兩個不同醫院環境的真實臨床資料集，展示了 Synth-SBDH 在三項任務中的效用，突出了它的多功能性、概括性，和萃取能力。在 Synth-SBDH 上訓練的模型始終優於沒有接受過 Synth-SBDH 訓練的模型，在巨量 F 分數上提升了 62.5%。此外，Synth-SBDH 證明了它對於罕見的 SBDH 類別和資源不足的限制是有用的。人類評估顯示出 71.06% 的人類-LLM 一致性，並揭露了未來改進的方向。

##### **On the Utility of Accounting for Human Beliefs about AI Behavior in Human-AI Collaboration**
2406.06051v1 by Guanghui Yu, Robert Kasumba, Chien-Ju Ho, William Yeoh

To enable effective human-AI collaboration, merely optimizing AI performance
while ignoring humans is not sufficient. Recent research has demonstrated that
designing AI agents to account for human behavior leads to improved performance
in human-AI collaboration. However, a limitation of most existing approaches is
their assumption that human behavior is static, irrespective of AI behavior. In
reality, humans may adjust their action plans based on their observations of AI
behavior. In this paper, we address this limitation by enabling a collaborative
AI agent to consider the beliefs of its human partner, i.e., what the human
partner thinks the AI agent is doing, and design its action plan to facilitate
easier collaboration with its human partner. Specifically, we developed a model
of human beliefs that accounts for how humans reason about the behavior of
their AI partners. Based on this belief model, we then developed an AI agent
that considers both human behavior and human beliefs in devising its strategy
for working with humans. Through extensive real-world human-subject
experiments, we demonstrated that our belief model more accurately predicts
humans' beliefs about AI behavior. Moreover, we showed that our design of AI
agents that accounts for human beliefs enhances performance in human-AI
collaboration.

摘要：<paragraph>要實現有效的人工智慧協作，僅優化人工智慧效能，而忽略人類是不夠的。最近的研究表明，設計人工智慧代理來考量人類行為，會提升人機協作的效能。然而，大多數現有方法的限制在於，它們假設人類行為是靜態的，與人工智慧行為無關。實際上，人類可能會根據他們對人工智慧行為的觀察來調整他們的行動計畫。在本文中，我們透過讓協作式人工智慧代理考慮其人類夥伴的信念（即人類夥伴認為人工智慧代理在做什麼）來解決這個限制，並設計其行動計畫以促進與其人類夥伴更輕鬆的協作。具體來說，我們開發了一個人類信念模型，說明人類如何推理其人工智慧夥伴的行為。基於這個信念模型，我們接著開發了一個人工智慧代理，在為與人類合作制定策略時，會考慮人類行為和人類信念。透過廣泛的真實世界人類受試者實驗，我們證明了我們的信念模型更準確地預測了人類對人工智慧行為的信念。此外，我們展示了我們考慮人類信念的人工智慧代理設計，增強了人機協作的效能。</paragraph>

##### **Robust Latent Representation Tuning for Image-text Classification**
2406.06048v1 by Hao Sun, Yu Song

Large models have demonstrated exceptional generalization capabilities in
computer vision and natural language processing. Recent efforts have focused on
enhancing these models with multimodal processing abilities. However,
addressing the challenges posed by scenarios where one modality is absent
remains a significant hurdle. In response to this issue, we propose a robust
latent representation tuning method for large models. Specifically, our
approach introduces a modality latent translation module to maximize the
correlation between modalities. Following this, a newly designed fusion module
is employed to facilitate information interaction between the modalities. In
this framework, not only are common semantics refined during training, but the
method also yields robust representations in the absence of one modality.
Importantly, our method maintains the frozen state of the image and text
foundation models to preserve their abilities acquired through large-scale
pretraining. We conduct experiments on several public datasets, and the results
underscore the effectiveness of our proposed method.

摘要：大型模型在電腦視覺和自然語言處理中展現了卓越的泛化能力。最近的努力集中在增強這些模型的多模態處理能力上。然而，在一個模態缺失的情況下，解決所帶來的挑戰仍然是一個重大的難題。為了應對這個問題，我們提出了一種針對大型模型的穩健潛在表徵調整方法。具體來說，我們的做法引入了模態潛在翻譯模組，以最大化模態之間的關聯性。在此之後，採用一個新設計的融合模組，以促進模態之間的資訊互動。在這個架構中，不僅在訓練期間精煉了共用語義，而且該方法還在一個模態缺失的情況下產生了穩健的表徵。重要的是，我們的做法維持了影像和文字基礎模型的凍結狀態，以保留它們透過大規模預訓練所獲得的能力。我們在幾個公開資料集上進行了實驗，結果突顯了我們所提出的方法的有效性。

##### **MATES: Model-Aware Data Selection for Efficient Pretraining with Data Influence Models**
2406.06046v1 by Zichun Yu, Spandan Das, Chenyan Xiong

Pretraining data selection has the potential to improve language model
pretraining efficiency by utilizing higher-quality data from massive web data
corpora. Current data selection methods, which rely on either hand-crafted
rules or larger reference models, are conducted statically and do not capture
the evolving data preferences during pretraining. In this paper, we introduce
model-aware data selection with data influence models (MATES), where a data
influence model continuously adapts to the evolving data preferences of the
pretraining model and then selects the data most effective for the current
pretraining progress. Specifically, we fine-tune a small data influence model
to approximate oracle data preference signals collected by locally probing the
pretraining model and to select data accordingly for the next pretraining
stage. Experiments on Pythia and the C4 dataset demonstrate that MATES
significantly outperforms random data selection on extensive downstream tasks
in both zero- and few-shot settings. It doubles the gains achieved by recent
data selection approaches that leverage larger reference models and reduces the
total FLOPs required to reach certain performances by half. Further analysis
validates the ever-changing data preferences of pretraining models and the
effectiveness of our data influence models to capture them. Our code is
open-sourced at https://github.com/cxcscmu/MATES.

摘要：預訓練資料的選取有潛力透過利用來自大量網路資料語料庫較高品質的資料來提升語言模型預訓練效率。目前的資料選取方法仰賴人工規則或較大的參考模型，採取靜態執行，且不會捕捉預訓練期間不斷變化的資料偏好。在本文中，我們引進具備資料影響模型的模型感知資料選取（MATES），其中一個資料影響模型會持續適應預訓練模型不斷變化的資料偏好，然後選取對目前的預訓練進度最有效的資料。具體來說，我們微調一個小型資料影響模型，以近似透過局部探測預訓練模型而收集的神諭資料偏好訊號，並據此為下一個預訓練階段選取資料。在 Pythia 和 C4 資料集上的實驗證明，MATES 在廣泛的下游任務中，無論是零次學習或少次學習設定，都顯著優於隨機資料選取。它讓採用較大參考模型的最新資料選取方法所獲得的收益加倍，並將達到特定效能所需的總 FLOP 減半。進一步的分析驗證了預訓練模型不斷變化的資料偏好，以及我們的資料影響模型捕捉這些偏好的有效性。我們的程式碼在 https://github.com/cxcscmu/MATES 開源。

##### **Synthesizing Efficient Data with Diffusion Models for Person Re-Identification Pre-Training**
2406.06045v1 by Ke Niu, Haiyang Yu, Xuelin Qian, Teng Fu, Bin Li, Xiangyang Xue

Existing person re-identification (Re-ID) methods principally deploy the
ImageNet-1K dataset for model initialization, which inevitably results in
sub-optimal situations due to the large domain gap. One of the key challenges
is that building large-scale person Re-ID datasets is time-consuming. Some
previous efforts address this problem by collecting person images from the
internet e.g., LUPerson, but it struggles to learn from unlabeled,
uncontrollable, and noisy data. In this paper, we present a novel paradigm
Diffusion-ReID to efficiently augment and generate diverse images based on
known identities without requiring any cost of data collection and annotation.
Technically, this paradigm unfolds in two stages: generation and filtering.
During the generation stage, we propose Language Prompts Enhancement (LPE) to
ensure the ID consistency between the input image sequence and the generated
images. In the diffusion process, we propose a Diversity Injection (DI) module
to increase attribute diversity. In order to make the generated data have
higher quality, we apply a Re-ID confidence threshold filter to further remove
the low-quality images. Benefiting from our proposed paradigm, we first create
a new large-scale person Re-ID dataset Diff-Person, which consists of over 777K
images from 5,183 identities. Next, we build a stronger person Re-ID backbone
pre-trained on our Diff-Person. Extensive experiments are conducted on four
person Re-ID benchmarks in six widely used settings. Compared with other
pre-training and self-supervised competitors, our approach shows significant
superiority.

摘要：現有人員重新識別 (Re-ID) 方法主要部署 ImageNet-1K 資料集進行模型初始化，這不可避免地會因巨大的領域差距而導致次佳情況。其中一個關鍵挑戰是建立大規模人員 Re-ID 資料集非常耗時。一些先前的努力透過從網際網路收集人員影像來解決此問題，例如 LUPerson，但它難以從未標記、不受控和有雜訊的資料中學習。在本文中，我們提出了一種新穎的範例 Diffusion-ReID，可以在不需任何資料收集和註解成本的情況下，根據已知身分有效地擴充和產生多樣化的影像。技術上來說，此範例分為兩個階段進行：產生和過濾。在產生階段，我們提出語言提示增強 (LPE) 以確保輸入影像序列和產生的影像之間的身分一致性。在擴散過程中，我們提出多樣性注入 (DI) 模組以增加屬性多樣性。為了使產生的資料具有更高的品質，我們套用 Re-ID 信心閾值過濾器進一步移除低品質的影像。受益於我們提出的範例，我們首先建立一個新的、大規模的人員 Re-ID 資料集 Diff-Person，其中包含來自 5,183 個身分的 777K 以上影像。接下來，我們建立一個更強大的人員 Re-ID 主幹，預先訓練於我們的 Diff-Person。在六種廣泛使用的設定中，對四個人員 Re-ID 基準進行了廣泛的實驗。與其他預訓練和自我監督的競爭者相比，我們的做法顯示出顯著的優越性。

##### **Investigating Pre-Training Objectives for Generalization in Vision-Based Reinforcement Learning**
2406.06037v1 by Donghu Kim, Hojoon Lee, Kyungmin Lee, Dongyoon Hwang, Jaegul Choo

Recently, various pre-training methods have been introduced in vision-based
Reinforcement Learning (RL). However, their generalization ability remains
unclear due to evaluations being limited to in-distribution environments and
non-unified experimental setups. To address this, we introduce the Atari
Pre-training Benchmark (Atari-PB), which pre-trains a ResNet-50 model on 10
million transitions from 50 Atari games and evaluates it across diverse
environment distributions. Our experiments show that pre-training objectives
focused on learning task-agnostic features (e.g., identifying objects and
understanding temporal dynamics) enhance generalization across different
environments. In contrast, objectives focused on learning task-specific
knowledge (e.g., identifying agents and fitting reward functions) improve
performance in environments similar to the pre-training dataset but not in
varied ones. We publicize our codes, datasets, and model checkpoints at
https://github.com/dojeon-ai/Atari-PB.

摘要：最近，在基于视觉的强化学习 (RL) 中引入了各种预训练方法。然而，由于评估仅限于分布内环境和非统一的实验设置，因此它们的泛化能力仍然不清楚。为了解决这个问题，我们引入了雅达利预训练基准 (Atari-PB)，它对 ResNet-50 模型进行了预训练，该模型来自 50 个雅达利游戏的 1000 万个过渡，并在不同的环境分布中对其进行了评估。我们的实验表明，专注于学习与任务无关的特征（例如，识别对象和理解时间动态）的预训练目标增强了在不同环境中的泛化能力。相比之下，专注于学习特定任务知识（例如，识别代理并拟合奖励函数）的目标提高了与预训练数据集类似的环境中的性能，但在不同的环境中却没有提高。我们在 https://github.com/dojeon-ai/Atari-PB 公布了我们的代码、数据集和模型检查点。

##### **The Curse of Popularity: Popular Entities have Catastrophic Side Effects when Deleting Knowledge from Language Models**
2406.06032v1 by Ryosuke Takahashi, Go Kamoda, Benjamin Heinzerling, Keisuke Sakaguchi, Kentaro Inui

Language models (LMs) encode world knowledge in their internal parameters
through training. However, LMs may learn personal and confidential information
from the training data, leading to privacy concerns such as data leakage.
Therefore, research on knowledge deletion from LMs is essential. This study
focuses on the knowledge stored in LMs and analyzes the relationship between
the side effects of knowledge deletion and the entities related to the
knowledge. Our findings reveal that deleting knowledge related to popular
entities can have catastrophic side effects. Furthermore, this research is the
first to analyze knowledge deletion in models trained on synthetic knowledge
graphs, indicating a new direction for controlled experiments.

摘要：語言模型 (LM) 透過訓練將世界知識編碼在其內部參數中。然而，LM 可能會從訓練資料中學習到個人和機密資訊，導致資料外洩等隱私問題。因此，研究從 LM 中刪除知識至關重要。本研究著重於儲存在 LM 中的知識，並分析知識刪除的副作用與與知識相關的實體之間的關係。我們的研究結果揭示，刪除與熱門實體相關的知識可能會造成災難性的副作用。此外，本研究首次分析在合成知識圖譜上訓練的模型中的知識刪除，指出受控實驗的新方向。

##### **HOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question Answering using LLMs**
2406.06027v1 by Pranoy Panda, Ankush Agarwal, Chaitanya Devaguptapu, Manohar Kaul, Prathosh A P

Given unstructured text, Large Language Models (LLMs) are adept at answering
simple (single-hop) questions. However, as the complexity of the questions
increase, the performance of LLMs degrade. We believe this is due to the
overhead associated with understanding the complex question followed by
filtering and aggregating unstructured information in the raw text. Recent
methods try to reduce this burden by integrating structured knowledge triples
into the raw text, aiming to provide a structured overview that simplifies
information processing. However, this simplistic approach is query-agnostic and
the extracted facts are ambiguous as they lack context. To address these
drawbacks and to enable LLMs to answer complex (multi-hop) questions with ease,
we propose to use a knowledge graph (KG) that is context-aware and is distilled
to contain query-relevant information. The use of our compressed distilled KG
as input to the LLM results in our method utilizing up to $67\%$ fewer tokens
to represent the query relevant information present in the supporting
documents, compared to the state-of-the-art (SoTA) method. Our experiments show
consistent improvements over the SoTA across several metrics (EM, F1,
BERTScore, and Human Eval) on two popular benchmark datasets (HotpotQA and
MuSiQue).

摘要：給定非結構化文本，大型語言模型 (LLM) 擅長回答簡單（單跳）問題。然而，隨著問題的複雜性增加，LLM 的效能會下降。我們相信這是因為理解複雜問題所伴隨的開銷，接著在原始文本中過濾和彙總非結構化資訊。最近的方法嘗試透過將結構化知識三元組整合到原始文本中來減輕這個負擔，目的是提供一個簡化資訊處理的結構化概觀。然而，這種簡化的方式與查詢無關，而且提取的事實模稜兩可，因為它們缺乏背景。為了解決這些缺點，並使 LLM 能夠輕鬆回答複雜（多跳）問題，我們建議使用一個與背景相關且經過提煉以包含與查詢相關資訊的知識圖譜 (KG)。將我們壓縮提煉的 KG 用作 LLM 的輸入，使得我們的模型使用比最先進 (SoTA) 方法減少多達 $67\%$ 的標記來表示支援文件中的與查詢相關的資訊。我們的實驗顯示，在兩個流行的基準資料集（HotpotQA 和 MuSiQue）上，我們的模型在多項指標（EM、F1、BERTScore 和人工評估）中都比 SoTA 有顯著的改善。

##### **RepoQA: Evaluating Long Context Code Understanding**
2406.06025v1 by Jiawei Liu, Jia Le Tian, Vijay Daita, Yuxiang Wei, Yifeng Ding, Yuhan Katherine Wang, Jun Yang, Lingming Zhang

Recent advances have been improving the context windows of Large Language
Models (LLMs). To quantify the real long-context capabilities of LLMs,
evaluators such as the popular Needle in a Haystack have been developed to test
LLMs over a large chunk of raw texts. While effective, current evaluations
overlook the insight of how LLMs work with long-context code, i.e.,
repositories. To this end, we initiate the RepoQA benchmark to evaluate LLMs on
long-context code understanding. Traditional needle testers ask LLMs to
directly retrieve the answer from the context without necessary deep
understanding. In RepoQA, we built our initial task, namely Searching Needle
Function (SNF), which exercises LLMs to search functions given their
natural-language description, i.e., LLMs cannot find the desired function if
they cannot understand the description and code. RepoQA is multilingual and
comprehensive: it includes 500 code search tasks gathered from 50 popular
repositories across 5 modern programming languages. By evaluating 26 general
and code-specific LLMs on RepoQA, we show (i) there is still a small gap
between the best open and proprietary models; (ii) different models are good at
different languages; and (iii) models may understand code better without
comments.

摘要：最近的进步改善了大型语言模型 (LLM) 的上下文窗口。为了量化 LLM 的真正长上下文能力，已经开发出诸如流行的大海捞针之类的评估器，以在大量原始文本上测试 LLM。虽然有效，但当前的评估忽略了 LLM 如何使用长上下文代码（即存储库）的见解。为此，我们启动了 RepoQA 基准来评估 LLM 对长上下文代码理解。传统的针测试要求 LLM 直接从上下文中检索答案，而无需必要的深入理解。在 RepoQA 中，我们构建了我们的初始任务，即搜索针函数 (SNF)，它让 LLM 根据其自然语言描述搜索函数，即如果 LLM 无法理解描述和代码，则无法找到所需函数。RepoQA 是多语言且全面的：它包含从 5 种现代编程语言中的 50 个流行存储库中收集的 500 个代码搜索任务。通过评估 RepoQA 上的 26 个通用和特定于代码的 LLM，我们展示了 (i) 最好的开放和专有模型之间仍然存在很小的差距；(ii) 不同的模型擅长不同的语言；(iii) 模型可能在没有注释的情况下更好地理解代码。

##### **Shoulders of Giants: A Look at the Degree and Utility of Openness in NLP Research**
2406.06021v1 by Surangika Ranathunga, Nisansa de Silva, Dilith Jayakody, Aloka Fernando

We analysed a sample of NLP research papers archived in ACL Anthology as an
attempt to quantify the degree of openness and the benefit of such an open
culture in the NLP community. We observe that papers published in different NLP
venues show different patterns related to artefact reuse. We also note that
more than 30% of the papers we analysed do not release their artefacts
publicly, despite promising to do so. Further, we observe a wide language-wise
disparity in publicly available NLP-related artefacts.

摘要：我們分析了儲存在 ACL Anthology 中的 NLP 研究論文樣本，以嘗試量化 NLP 社群中開放程度和這種開放文化的好處。我們觀察到在不同 NLP 場所發表的論文顯示出與人工製品再利用相關的不同模式。我們還注意到，儘管承諾公開，但我們分析的論文中超過 30% 沒有公開其人工製品。此外，我們觀察到在公開可用的 NLP 相關人工製品中存在廣泛的語言差異。

##### **Neuro-TransUNet: Segmentation of stroke lesion in MRI using transformers**
2406.06017v1 by Muhammad Nouman, Mohamed Mabrok, Essam A. Rashed

Accurate segmentation of the stroke lesions using magnetic resonance imaging
(MRI) is associated with difficulties due to the complicated anatomy of the
brain and the different properties of the lesions. This study introduces the
Neuro-TransUNet framework, which synergizes the U-Net's spatial feature
extraction with SwinUNETR's global contextual processing ability, further
enhanced by advanced feature fusion and segmentation synthesis techniques. The
comprehensive data pre-processing pipeline improves the framework's efficiency,
which involves resampling, bias correction, and data standardization, enhancing
data quality and consistency. Ablation studies confirm the significant impact
of the advanced integration of U-Net with SwinUNETR and data pre-processing
pipelines on performance and demonstrate the model's effectiveness. The
proposed Neuro-TransUNet model, trained with the ATLAS v2.0 \emph{training}
dataset, outperforms existing deep learning algorithms and establishes a new
benchmark in stroke lesion segmentation.

摘要：使用磁共振成像（MRI）準確分割中風病灶會因大腦結構複雜和病灶性質差異而產生困難。本研究提出 Neuro-TransUNet 框架，它將 U-Net 的空間特徵提取與 SwinUNETR 的全局脈絡處理能力結合起來，並進一步透過先進的特徵融合和分割合成技術進行強化。全面的資料預處理管線改善了框架的效率，其中包括重新取樣、偏差校正和資料標準化，以提升資料品質和一致性。消融研究證實了 U-Net 與 SwinUNETR 的先進整合，以及資料預處理管線對效能的重大影響，並證明了模型的有效性。所提出的 Neuro-TransUNet 模型使用 ATLAS v2.0 訓練資料集進行訓練，其表現優於現有的深度學習演算法，並在中風病灶分割中建立新的基準。

##### **CARES: A Comprehensive Benchmark of Trustworthiness in Medical Vision Language Models**
2406.06007v1 by Peng Xia, Ze Chen, Juanxi Tian, Yangrui Gong, Ruibo Hou, Yue Xu, Zhenbang Wu, Zhiyuan Fan, Yiyang Zhou, Kangyu Zhu, Wenhao Zheng, Zhaoyang Wang, Xiao Wang, Xuchao Zhang, Chetan Bansal, Marc Niethammer, Junzhou Huang, Hongtu Zhu, Yun Li, Jimeng Sun, Zongyuan Ge, Gang Li, James Zou, Huaxiu Yao

Artificial intelligence has significantly impacted medical applications,
particularly with the advent of Medical Large Vision Language Models
(Med-LVLMs), sparking optimism for the future of automated and personalized
healthcare. However, the trustworthiness of Med-LVLMs remains unverified,
posing significant risks for future model deployment. In this paper, we
introduce CARES and aim to comprehensively evaluate the Trustworthiness of
Med-LVLMs across the medical domain. We assess the trustworthiness of Med-LVLMs
across five dimensions, including trustfulness, fairness, safety, privacy, and
robustness. CARES comprises about 41K question-answer pairs in both closed and
open-ended formats, covering 16 medical image modalities and 27 anatomical
regions. Our analysis reveals that the models consistently exhibit concerns
regarding trustworthiness, often displaying factual inaccuracies and failing to
maintain fairness across different demographic groups. Furthermore, they are
vulnerable to attacks and demonstrate a lack of privacy awareness. We publicly
release our benchmark and code in https://github.com/richard-peng-xia/CARES.

摘要：人工智能已顯著影響醫療應用，
尤其是在醫療大型視覺語言模型 (Med-LVLMs) 出現後，為自動化和個人化醫療保健的未來帶來樂觀。然而，Med-LVLMs 的可信度仍未得到驗證，對未來的模型部署構成重大風險。在本文中，我們介紹了 CARES，旨在全面評估 Med-LVLMs 在醫療領域的可信度。我們從可信度、公平性、安全性、隱私和穩健性等五個面向評估 Med-LVLMs 的可信度。CARES 包含約 41K 個封閉式和開放式格式的問題解答配對，涵蓋 16 種醫學影像模式和 27 個解剖區域。我們的分析顯示，這些模型始終表現出關於可信度的疑慮，經常顯示出事實上的不準確性，並且無法在不同的人口群體中保持公平性。此外，它們容易受到攻擊，並且缺乏隱私意識。我們公開發布我們的基準和代碼，網址為 https://github.com/richard-peng-xia/CARES。

##### **FLEUR: An Explainable Reference-Free Evaluation Metric for Image Captioning Using a Large Multimodal Model**
2406.06004v1 by Yebin Lee, Imseong Park, Myungjoo Kang

Most existing image captioning evaluation metrics focus on assigning a single
numerical score to a caption by comparing it with reference captions. However,
these methods do not provide an explanation for the assigned score. Moreover,
reference captions are expensive to acquire. In this paper, we propose FLEUR,
an explainable reference-free metric to introduce explainability into image
captioning evaluation metrics. By leveraging a large multimodal model, FLEUR
can evaluate the caption against the image without the need for reference
captions, and provide the explanation for the assigned score. We introduce
score smoothing to align as closely as possible with human judgment and to be
robust to user-defined grading criteria. FLEUR achieves high correlations with
human judgment across various image captioning evaluation benchmarks and
reaches state-of-the-art results on Flickr8k-CF, COMPOSITE, and Pascal-50S
within the domain of reference-free evaluation metrics. Our source code and
results are publicly available at: https://github.com/Yebin46/FLEUR.

摘要：大多數現有的圖像標題評估指標著重於透過將標題與參考標題進行比較，來為標題指定單一的數值分數。然而，這些方法並未對指定的分數提供說明。此外，參考標題的取得成本很高。在本文中，我們提出 FLEUR，一種可解釋的無參考指標，用於在圖像標題評估指標中引入可解釋性。藉由利用大型多模態模型，FLEUR 可以針對圖像評估標題，而無需參考標題，並提供指定分數的說明。我們引入分數平滑，以盡可能與人類判斷保持一致，並對使用者定義的評分標準具有穩健性。FLEUR 在各種圖像標題評估基準中與人類判斷達成高度相關，並在無參考評估指標的領域中，於 Flickr8k-CF、COMPOSITE 和 Pascal-50S 達到最先進的結果。我們的原始碼和結果已公開於：https://github.com/Yebin46/FLEUR。

##### **ThaiCoref: Thai Coreference Resolution Dataset**
2406.06000v1 by Pontakorn Trakuekul, Wei Qi Leong, Charin Polpanumas, Jitkapat Sawatphol, William Chandra Tjhi, Attapol T. Rutherford

While coreference resolution is a well-established research area in Natural
Language Processing (NLP), research focusing on Thai language remains limited
due to the lack of large annotated corpora. In this work, we introduce
ThaiCoref, a dataset for Thai coreference resolution. Our dataset comprises
777,271 tokens, 44,082 mentions and 10,429 entities across four text genres:
university essays, newspapers, speeches, and Wikipedia. Our annotation scheme
is built upon the OntoNotes benchmark with adjustments to address Thai-specific
phenomena. Utilizing ThaiCoref, we train models employing a multilingual
encoder and cross-lingual transfer techniques, achieving a best F1 score of
67.88\% on the test set. Error analysis reveals challenges posed by Thai's
unique linguistic features. To benefit the NLP community, we make the dataset
and the model publicly available at http://www.github.com/nlp-chula/thai-coref .

摘要：雖然共指消解是自然語言處理 (NLP) 中一個成熟的研究領域，但由於缺乏大量的標註語料庫，以泰語為重點的研究仍然有限。在這項工作中，我們引入了 ThaiCoref，一個用於泰語共指消解的資料集。我們的資料集包含 777,271 個字元、44,082 個提及和 10,429 個實體，涵蓋四種類型的文字：大學論文、報紙、演講和維基百科。我們的標註方案建立在 OntoNotes 基準上，並針對泰語特定現象進行了調整。利用 ThaiCoref，我們訓練了採用多語言編碼器和跨語言轉移技術的模型，在測試集上達到了 67.88% 的最佳 F1 分數。錯誤分析揭示了泰語獨特語言特徵帶來的挑戰。為了使 NLP 社群受益，我們在 http://www.github.com/nlp-chula/thai-coref 上公開了資料集和模型。

##### **fSEAD: a Composable FPGA-based Streaming Ensemble Anomaly Detection Library**
2406.05999v1 by Binglei Lou, David Boland, Philip H. W. Leong

Machine learning ensembles combine multiple base models to produce a more
accurate output. They can be applied to a range of machine learning problems,
including anomaly detection. In this paper, we investigate how to maximize the
composability and scalability of an FPGA-based streaming ensemble anomaly
detector (fSEAD). To achieve this, we propose a flexible computing architecture
consisting of multiple partially reconfigurable regions, pblocks, which each
implement anomaly detectors. Our proof-of-concept design supports three
state-of-the-art anomaly detection algorithms: Loda, RS-Hash and xStream. Each
algorithm is scalable, meaning multiple instances can be placed within a pblock
to improve performance. Moreover, fSEAD is implemented using High-level
synthesis (HLS), meaning further custom anomaly detectors can be supported.
Pblocks are interconnected via an AXI-switch, enabling them to be composed in
an arbitrary fashion before combining and merging results at run-time to create
an ensemble that maximizes the use of FPGA resources and accuracy. Through
utilizing reconfigurable Dynamic Function eXchange (DFX), the detector can be
modified at run-time to adapt to changing environmental conditions. We compare
fSEAD to an equivalent central processing unit (CPU) implementation using four
standard datasets, with speed-ups ranging from $3\times$ to $8\times$.

摘要：機器學習合奏結合多個基礎模型來產生更準確的輸出。它們可以應用於各種機器學習問題，包括異常偵測。在本文中，我們探討如何最大化基於 FPGA 的串流合奏異常偵測器 (fSEAD) 的可組合性和可擴充性。為此，我們提出了一個靈活的運算架構，由多個部分可重新配置的區域 (pblock) 組成，每個區域都實作異常偵測器。我們的概念驗證設計支援三種最先進的異常偵測演算法：Loda、RS-Hash 和 xStream。每個演算法都是可擴充的，表示可以將多個執行個體放置在 pblock 內以提升效能。此外，fSEAD 是使用高階綜合 (HLS) 實作的，表示可以支援更多自訂異常偵測器。Pblock 透過 AXI 交換器互連，讓它們可以在執行時間組合和合併結果之前以任意方式組成，以建立一個最大化 FPGA 資源和精確度使用的合奏。透過利用可重新配置的動態功能交換 (DFX)，偵測器可以在執行時間修改以適應變化的環境條件。我們使用四個標準資料集將 fSEAD 與等效的中央處理器 (CPU) 實作進行比較，加速範圍從 $3\times$ 到 $8\times$。

##### **A Dual-View Approach to Classifying Radiology Reports by Co-Training**
2406.05995v1 by Yutong Han, Yan Yuan, Lili Mou

Radiology report analysis provides valuable information that can aid with
public health initiatives, and has been attracting increasing attention from
the research community. In this work, we present a novel insight that the
structure of a radiology report (namely, the Findings and Impression sections)
offers different views of a radiology scan. Based on this intuition, we further
propose a co-training approach, where two machine learning models are built
upon the Findings and Impression sections, respectively, and use each other's
information to boost performance with massive unlabeled data in a
semi-supervised manner. We conducted experiments in a public health
surveillance study, and results show that our co-training approach is able to
improve performance using the dual views and surpass competing supervised and
semi-supervised methods.

摘要：放射學報告分析提供有價值的資訊，有助於公共衛生計畫，並已吸引研究社群越來越多的關注。在這項工作中，我們提出一個新的見解，即放射學報告的結構（即「發現」和「印象」部分）提供放射學掃描的不同觀點。基於這個直覺，我們進一步提出一個共同訓練方法，其中兩個機器學習模型分別建立在「發現」和「印象」部分之上，並使用彼此的資訊以大量未標記資料以半監督的方式提升效能。我們在公共衛生監測研究中進行實驗，結果顯示我們的共同訓練方法能夠使用雙重觀點來提升效能，並超越競爭的監督式和半監督式方法。

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

摘要：心理健康構成了一項複雜且普遍的全球挑戰，影響了數百萬人的生活，並經常導致嚴重的後果。在本文中，我們進行了一項徹底的調查，以探索數據科學、人工智慧和心理保健的交集，重點關注通過線上社交媒體 (OSM) 進行心理疾病檢測的最新發展。很大一部分人口積極參與 OSM 平台，創造了一個龐大的人員資料庫，對心理健康分析具有巨大的潛力。本文探討了傳統的診斷方法、最先進的資料和 AI 驅動的研究，以及心理保健中可解釋 AI (XAI) 模型的出現。我們回顧了最先進的機器學習方法，特別是那些基於現代深度學習的方法，同時強調了醫療保健 AI 模型中可解釋性的必要性。實驗設計部分提供了對普遍做法的見解，包括可用的資料集和評估方法。我們還找出該領域的主要問題和挑戰，並提出了有希望的未來研究方向。由於心理健康決策需要透明度、可解釋性和道德考量，本文有助於推進心理保健中透過社交媒體推進 XAI 的持續討論。這裡提出的全面概述旨在引導研究人員、從業人員和政策制定者發展心理疾病檢測領域。

##### **ShiftAddLLM: Accelerating Pretrained LLMs via Post-Training Multiplication-Less Reparameterization**
2406.05981v1 by Haoran You, Yipin Guo, Yichao Fu, Wei Zhou, Huihong Shi, Xiaofan Zhang, Souvik Kundu, Amir Yazdanbakhsh, Yingyan Lin

Large language models (LLMs) have shown impressive performance on language
tasks but face challenges when deployed on resource-constrained devices due to
their extensive parameters and reliance on dense multiplications, resulting in
high memory demands and latency bottlenecks. Shift-and-add reparameterization
offers a promising solution by replacing costly multiplications with
hardware-friendly primitives in both the attention and multi-layer perceptron
(MLP) layers of an LLM. However, current reparameterization techniques require
training from scratch or full parameter fine-tuning to restore accuracy, which
is resource-intensive for LLMs. To address this, we propose accelerating
pretrained LLMs through post-training shift-and-add reparameterization,
creating efficient multiplication-free models, dubbed ShiftAddLLM.
Specifically, we quantize each weight matrix into binary matrices paired with
group-wise scaling factors. The associated multiplications are reparameterized
into (1) shifts between activations and scaling factors and (2) queries and
adds according to the binary matrices. To reduce accuracy loss, we present a
multi-objective optimization method to minimize both weight and output
activation reparameterization errors. Additionally, based on varying
sensitivity across layers to reparameterization, we develop an automated bit
allocation strategy to further reduce memory usage and latency. Experiments on
five LLM families and eight tasks consistently validate the effectiveness of
ShiftAddLLM, achieving average perplexity improvements of 5.6 and 22.7 points
at comparable or lower latency compared to the most competitive quantized LLMs
at 3 and 2 bits, respectively, and more than 80% memory and energy reductions
over the original LLMs. Codes and models are available at
https://github.com/GATECH-EIC/ShiftAddLLM.

摘要：大型語言模型 (LLM) 在語言任務上表現出色，但由於其廣泛的參數和對密集乘法的依賴性，在部署到資源受限的設備上時會面臨挑戰，導致高記憶體需求和延遲瓶頸。移位和加法重新參數化提供了一個有希望的解決方案，它用硬體友善的原語取代了注意力和多層感知器 (MLP) 層中的昂貴乘法。然而，目前的重新參數化技術需要從頭開始訓練或進行完全參數微調才能恢復準確性，這對於 LLM 來說是資源密集型的。為了解決這個問題，我們建議通過訓練後移位和加法重新參數化來加速預訓練的 LLM，創造出稱為 ShiftAddLLM 的高效無乘法模型。具體來說，我們將每個權重矩陣量化為二進制矩陣，並配對組級縮放因子。相關的乘法重新參數化為：(1) 激活和縮放因子之間的移位，以及 (2) 查詢和根據二進制矩陣進行加法。為了減少準確性損失，我們提出了一種多目標優化方法，以最小化權重和輸出激活重新參數化誤差。此外，基於各層對重新參數化的不同敏感性，我們開發了一種自動化位元分配策略，以進一步減少記憶體使用量和延遲。在五個 LLM 系列和八個任務上的實驗持續驗證了 ShiftAddLLM 的有效性，在與最具競爭力的 3 位和 2 位量化 LLM 相當或更低的延遲下，分別實現了平均困惑度改善 5.6 點和 22.7 點，並且比原始 LLM 節省了超過 80% 的記憶體和能源。程式碼和模型可在 https://github.com/GATECH-EIC/ShiftAddLLM 取得。

##### **Decision-Making Behavior Evaluation Framework for LLMs under Uncertain Context**
2406.05972v1 by Jingru Jia, Zehua Yuan, Junhao Pan, Paul McNamara, Deming Chen

When making decisions under uncertainty, individuals often deviate from
rational behavior, which can be evaluated across three dimensions: risk
preference, probability weighting, and loss aversion. Given the widespread use
of large language models (LLMs) in decision-making processes, it is crucial to
assess whether their behavior aligns with human norms and ethical expectations
or exhibits potential biases. Several empirical studies have investigated the
rationality and social behavior performance of LLMs, yet their internal
decision-making tendencies and capabilities remain inadequately understood.
This paper proposes a framework, grounded in behavioral economics, to evaluate
the decision-making behaviors of LLMs. Through a multiple-choice-list
experiment, we estimate the degree of risk preference, probability weighting,
and loss aversion in a context-free setting for three commercial LLMs:
ChatGPT-4.0-Turbo, Claude-3-Opus, and Gemini-1.0-pro. Our results reveal that
LLMs generally exhibit patterns similar to humans, such as risk aversion and
loss aversion, with a tendency to overweight small probabilities. However,
there are significant variations in the degree to which these behaviors are
expressed across different LLMs. We also explore their behavior when embedded
with socio-demographic features, uncovering significant disparities. For
instance, when modeled with attributes of sexual minority groups or physical
disabilities, Claude-3-Opus displays increased risk aversion, leading to more
conservative choices. These findings underscore the need for careful
consideration of the ethical implications and potential biases in deploying
LLMs in decision-making scenarios. Therefore, this study advocates for
developing standards and guidelines to ensure that LLMs operate within ethical
boundaries while enhancing their utility in complex decision-making
environments.

摘要：<paragraph>在不確定情況下做出決策時，個人通常會偏離理性行為，這可以用三個面向來評估：風險偏好、機率加權和損失規避。鑒於大型語言模型 (LLM) 在決策過程中被廣泛使用，因此評估其行為是否符合人類規範和道德期望或表現出潛在偏見至關重要。多項實證研究調查了 LLM 的理性與社會行為表現，但其內部決策傾向和能力仍未被充分理解。本文提出了一個基於行為經濟學的架構，用於評估 LLM 的決策行為。透過多選題實驗，我們估計了三個商業 LLM：ChatGPT-4.0-Turbo、Claude-3-Opus 和 Gemini-1.0-pro 在無背景設定下的風險偏好、機率加權和損失規避程度。我們的結果顯示，LLM 通常表現出類似於人類的模式，例如風險規避和損失規避，並傾向於高估小機率。然而，這些行為在不同 LLM 中表現的程度存在顯著差異。我們也探討了它們在嵌入社會人口特徵時的行為，發現了顯著的差異。例如，當以性少數群體或身體殘疾的屬性建模時，Claude-3-Opus 會表現出更高的風險規避，導致更保守的選擇。這些發現強調了在決策場景中部署 LLM 時，需要仔細考量其道德意涵和潛在偏見。因此，本研究主張制定標準和準則，以確保 LLM 在道德界限內運作，同時提升其在複雜決策環境中的效用。</paragraph>

##### **Prompting Large Language Models with Audio for General-Purpose Speech Summarization**
2406.05968v1 by Wonjune Kang, Deb Roy

In this work, we introduce a framework for speech summarization that
leverages the processing and reasoning capabilities of large language models
(LLMs). We propose an end-to-end system that combines an instruction-tuned LLM
with an audio encoder that converts speech into token representations that the
LLM can interpret. Using a dataset with paired speech-text data, the overall
system is trained to generate consistent responses to prompts with the same
semantic information regardless of the input modality. The resulting framework
allows the LLM to process speech inputs in the same way as text, enabling
speech summarization by simply prompting the LLM. Unlike prior approaches, our
method is able to summarize spoken content from any arbitrary domain, and it
can produce summaries in different styles by varying the LLM prompting
strategy. Experiments demonstrate that our approach outperforms a cascade
baseline of speech recognition followed by LLM text processing.

摘要：在這項工作中，我們介紹了一個語言摘要的架構，利用大型語言模型 (LLM) 的處理和推理能力。我們提議一個端到端系統，結合一個經過指令調整的 LLM，以及一個音訊編碼器，將語音轉換成 LLM 可以詮釋的符號表示。使用配對語音文字資料的資料集，整體系統經過訓練，可以對提示產生一致的回應，而不管輸入模式如何，語意資訊都是相同的。產生的架構允許 LLM 以與文字相同的方式處理語音輸入，只要提示 LLM 即可進行語音摘要。與先前的做法不同，我們的做法可以摘要來自任何任意領域的口語內容，並且可以透過改變 LLM 提示策略來產生不同風格的摘要。實驗證明，我們的做法優於語音辨識後接 LLM 文字處理的串聯基準。

##### **CVQA: Culturally-diverse Multilingual Visual Question Answering Benchmark**
2406.05967v1 by David Romero, Chenyang Lyu, Haryo Akbarianto Wibowo, Teresa Lynn, Injy Hamed, Aditya Nanda Kishore, Aishik Mandal, Alina Dragonetti, Artem Abzaliev, Atnafu Lambebo Tonja, Bontu Fufa Balcha, Chenxi Whitehouse, Christian Salamea, Dan John Velasco, David Ifeoluwa Adelani, David Le Meur, Emilio Villa-Cueva, Fajri Koto, Fauzan Farooqui, Frederico Belcavello, Ganzorig Batnasan, Gisela Vallejo, Grainne Caulfield, Guido Ivetta, Haiyue Song, Henok Biadglign Ademtew, Hernán Maina, Holy Lovenia, Israel Abebe Azime, Jan Christian Blaise Cruz, Jay Gala, Jiahui Geng, Jesus-German Ortiz-Barajas, Jinheon Baek, Jocelyn Dunstan, Laura Alonso Alemany, Kumaranage Ravindu Yasas Nagasinghe, Luciana Benotti, Luis Fernando D'Haro, Marcelo Viridiano, Marcos Estecha-Garitagoitia, Maria Camila Buitrago Cabrera, Mario Rodríguez-Cantelar, Mélanie Jouitteau, Mihail Mihaylov, Mohamed Fazli Mohamed Imam, Muhammad Farid Adilazuarda, Munkhjargal Gochoo, Munkh-Erdene Otgonbold, Naome Etori, Olivier Niyomugisha, Paula Mónica Silva, Pranjal Chitale, Raj Dabre, Rendi Chevi, Ruochen Zhang, Ryandito Diandaru, Samuel Cahyawijaya, Santiago Góngora, Soyeong Jeong, Sukannya Purkayastha, Tatsuki Kuribayashi, Thanmay Jayakumar, Tiago Timponi Torrent, Toqeer Ehsan, Vladimir Araujo, Yova Kementchedjhieva, Zara Burzo, Zheng Wei Lim, Zheng Xin Yong, Oana Ignat, Joan Nwatu, Rada Mihalcea, Thamar Solorio, Alham Fikri Aji

Visual Question Answering (VQA) is an important task in multimodal AI, and it
is often used to test the ability of vision-language models to understand and
reason on knowledge present in both visual and textual data. However, most of
the current VQA models use datasets that are primarily focused on English and a
few major world languages, with images that are typically Western-centric.
While recent efforts have tried to increase the number of languages covered on
VQA datasets, they still lack diversity in low-resource languages. More
importantly, although these datasets often extend their linguistic range via
translation or some other approaches, they usually keep images the same,
resulting in narrow cultural representation. To address these limitations, we
construct CVQA, a new Culturally-diverse multilingual Visual Question Answering
benchmark, designed to cover a rich set of languages and cultures, where we
engage native speakers and cultural experts in the data collection process. As
a result, CVQA includes culturally-driven images and questions from across 28
countries on four continents, covering 26 languages with 11 scripts, providing
a total of 9k questions. We then benchmark several Multimodal Large Language
Models (MLLMs) on CVQA, and show that the dataset is challenging for the
current state-of-the-art models. This benchmark can serve as a probing
evaluation suite for assessing the cultural capability and bias of multimodal
models and hopefully encourage more research efforts toward increasing cultural
awareness and linguistic diversity in this field.

摘要：視覺問答 (VQA) 是多模態 AI 中的一項重要任務，且常被用於測試視覺語言模型在理解和推理視覺和文字資料中知識的能力。然而，目前大部分的 VQA 模型使用的資料集主要集中在英語和一些主要的世界語言，且使用的圖像通常以西方為中心。儘管最近的研究已嘗試增加 VQA 資料集中涵蓋的語言數量，但在低資源語言中仍然缺乏多樣性。更重要的是，儘管這些資料集經常透過翻譯或其他方法來擴展其語言範圍，但它們通常會保留相同的圖像，導致文化呈現狹隘。為了解決這些限制，我們建構了 CVQA，一個新的文化多元多語言視覺問答基準，旨在涵蓋豐富的語言和文化，在資料收集過程中，我們聘請了母語人士和文化專家。因此，CVQA 包含來自四大洲 28 個國家的文化驅動圖像和問題，涵蓋 26 種語言和 11 種文字，總共提供了 9k 個問題。然後，我們在 CVQA 上對幾個多模態大型語言模型 (MLLM) 進行基準測試，並顯示該資料集對目前的最新模型來說具有挑戰性。此基準測試可用作探測評估套件，用於評估多模態模型的文化能力和偏見，並有望鼓勵更多研究工作，以提高該領域的文化意識和語言多樣性。

##### **MakeSinger: A Semi-Supervised Training Method for Data-Efficient Singing Voice Synthesis via Classifier-free Diffusion Guidance**
2406.05965v1 by Semin Kim, Myeonghun Jeong, Hyeonseung Lee, Minchan Kim, Byoung Jin Choi, Nam Soo Kim

In this paper, we propose MakeSinger, a semi-supervised training method for
singing voice synthesis (SVS) via classifier-free diffusion guidance. The
challenge in SVS lies in the costly process of gathering aligned sets of text,
pitch, and audio data. MakeSinger enables the training of the diffusion-based
SVS model from any speech and singing voice data regardless of its labeling,
thereby enhancing the quality of generated voices with large amount of
unlabeled data. At inference, our novel dual guiding mechanism gives text and
pitch guidance on the reverse diffusion step by estimating the score of masked
input. Experimental results show that the model trained in a semi-supervised
manner outperforms other baselines trained only on the labeled data in terms of
pronunciation, pitch accuracy and overall quality. Furthermore, we demonstrate
that by adding Text-to-Speech (TTS) data in training, the model can synthesize
the singing voices of TTS speakers even without their singing voices.

摘要：在本文中，我們提出 MakeSinger，一種透過分類器自由擴散引導進行歌唱語音合成 (SVS) 的半監督訓練方法。SVS 的挑戰在於收集對齊的文本、音高和音訊資料的成本高昂。MakeSinger 能夠訓練基於擴散的 SVS 模型，而不論其標籤為何，從任何語音和歌唱語音資料中進行訓練，從而透過大量的未標籤資料提升產生的語音品質。在推論中，我們新穎的雙重引導機制會在反向擴散步驟中提供文本和音高的引導，方法是估計遮蔽輸入的分數。實驗結果顯示，以半監督方式訓練的模型在發音、音高準確度和整體品質方面優於僅在標籤資料上訓練的其他基準。此外，我們示範透過在訓練中加入文字轉語音 (TTS) 資料，該模型可以合成 TTS 說話者的歌唱語音，即使沒有他們的歌唱語音。

##### **Solution for SMART-101 Challenge of CVPR Multi-modal Algorithmic Reasoning Task 2024**
2406.05963v1 by Jinwoo Ahn, Junhyeok Park, Min-Jun Kim, Kang-Hyeon Kim, So-Yeong Sohn, Yun-Ji Lee, Du-Seong Chang, Yu-Jung Heo, Eun-Sol Kim

In this paper, the solution of HYU MLLAB KT Team to the Multimodal
Algorithmic Reasoning Task: SMART-101 CVPR 2024 Challenge is presented. Beyond
conventional visual question-answering problems, the SMART-101 challenge aims
to achieve human-level multimodal understanding by tackling complex
visio-linguistic puzzles designed for children in the 6-8 age group. To solve
this problem, we suggest two main ideas. First, to utilize the reasoning
ability of a large-scale language model (LLM), the given visual cues (images)
are grounded in the text modality. For this purpose, we generate highly
detailed text captions that describe the context of the image and use these
captions as input for the LLM. Second, due to the nature of puzzle images,
which often contain various geometric visual patterns, we utilize an object
detection algorithm to ensure these patterns are not overlooked in the
captioning process. We employed the SAM algorithm, which can detect
various-size objects, to capture the visual features of these geometric
patterns and used this information as input for the LLM. Under the puzzle split
configuration, we achieved an option selection accuracy Oacc of 29.5 on the
test set and a weighted option selection accuracy (WOSA) of 27.1 on the
challenge set.

摘要：在本文中，介紹了 HYU MLLAB KT 團隊針對多模態演算法推理任務：SMART-101 CVPR 2024 挑戰的解決方案。除了傳統的視覺問答問題之外，SMART-101 挑戰旨在透過解決專為 6-8 歲兒童設計的複雜視覺語言謎題，來達成人類等級的多模態理解。為了解決這個問題，我們提出了兩個主要想法。首先，為了利用大規模語言模型 (LLM) 的推理能力，給定的視覺線索（影像）被基礎化於文字模式中。為了這個目的，我們產生了高度詳細的文字標題，來描述影像的內容，並將這些標題用作 LLM 的輸入。其次，由於謎題影像的本質，通常包含各種幾何視覺模式，我們利用物件偵測演算法來確保這些模式不會在標題處理過程中被忽略。我們採用了 SAM 演算法，它可以偵測各種大小的物件，來擷取這些幾何模式的視覺特徵，並將此資訊用作 LLM 的輸入。在謎題分割配置下，我們在測試集上達到了選項選擇準確度 Oacc 為 29.5，在挑戰集上達到了加權選項選擇準確度 (WOSA) 為 27.1。

##### **Turbo Sparse: Achieving LLM SOTA Performance with Minimal Activated Parameters**
2406.05955v1 by Yixin Song, Haotong Xie, Zhengyan Zhang, Bo Wen, Li Ma, Zeyu Mi, Haibo Chen

Exploiting activation sparsity is a promising approach to significantly
accelerating the inference process of large language models (LLMs) without
compromising performance. However, activation sparsity is determined by
activation functions, and commonly used ones like SwiGLU and GeGLU exhibit
limited sparsity. Simply replacing these functions with ReLU fails to achieve
sufficient sparsity. Moreover, inadequate training data can further increase
the risk of performance degradation. To address these challenges, we propose a
novel dReLU function, which is designed to improve LLM activation sparsity,
along with a high-quality training data mixture ratio to facilitate effective
sparsification. Additionally, we leverage sparse activation patterns within the
Feed-Forward Network (FFN) experts of Mixture-of-Experts (MoE) models to
further boost efficiency. By applying our neuron sparsification method to the
Mistral and Mixtral models, only 2.5 billion and 4.3 billion parameters are
activated per inference iteration, respectively, while achieving even more
powerful model performance. Evaluation results demonstrate that this sparsity
achieves a 2-5x decoding speedup. Remarkably, on mobile phones, our
TurboSparse-Mixtral-47B achieves an inference speed of 11 tokens per second.
Our models are available at \url{https://huggingface.co/PowerInfer}

摘要：利用激活稀疏性是一种有前途的方法，可以在不影响性能的情况下显著加速大型语言模型 (LLM) 的推理过程。然而，激活稀疏性是由激活函数决定的，而常用的函数（如 SwiGLU 和 GeGLU）表现出的稀疏性有限。简单地用 ReLU 替换这些函数无法实现足够的稀疏性。此外，训练数据不足会进一步增加性能下降的风险。为了应对这些挑战，我们提出了一个新颖的 dReLU 函数，该函数旨在提高 LLM 激活稀疏性，并采用高质量的训练数据混合比来促进有效的稀疏化。此外，我们利用混合专家 (MoE) 模型的馈送前向网络 (FFN) 专家中的稀疏激活模式来进一步提高效率。通过将我们的神经元稀疏化方法应用于 Mistral 和 Mixtral 模型，每次推理迭代仅激活 25 亿和 43 亿个参数，同时实现更强大的模型性能。评估结果表明，这种稀疏性实现了 2-5 倍的解码速度提升。值得注意的是，在移动电话上，我们的 TurboSparse-Mixtral-47B 的推理速度达到了每秒 11 个标记。我们的模型可在 \url{https://huggingface.co/PowerInfer} 获得

##### **Aligning Large Language Models with Representation Editing: A Control Perspective**
2406.05954v1 by Lingkai Kong, Haorui Wang, Wenhao Mu, Yuanqi Du, Yuchen Zhuang, Yifei Zhou, Yue Song, Rongzhi Zhang, Kai Wang, Chao Zhang

Aligning large language models (LLMs) with human objectives is crucial for
real-world applications. However, fine-tuning LLMs for alignment often suffers
from unstable training and requires substantial computing resources. Test-time
alignment techniques, such as prompting and guided decoding, do not modify the
underlying model, and their performance remains dependent on the original
model's capabilities. To address these challenges, we propose aligning LLMs
through representation editing. The core of our method is to view a pre-trained
autoregressive LLM as a discrete-time stochastic dynamical system. To achieve
alignment for specific objectives, we introduce external control signals into
the state space of this language dynamical system. We train a value function
directly on the hidden states according to the Bellman equation, enabling
gradient-based optimization to obtain the optimal control signals at test time.
Our experiments demonstrate that our method outperforms existing test-time
alignment techniques while requiring significantly fewer resources compared to
fine-tuning methods.

摘要：對齊大型語言模型 (LLM) 與人類目標對於真實世界的應用至關重要。然而，微調 LLM 以進行對齊通常會導致訓練不穩定，並且需要大量的運算資源。測試時間對齊技術，例如提示和引導解碼，不會修改基礎模型，並且它們的性能仍然依賴於原始模型的功能。為了應對這些挑戰，我們建議通過表示編輯對齊 LLM。我們方法的核心是將預先訓練的自動回歸 LLM 視為離散時間隨機動力系統。為了實現特定目標的對齊，我們將外部控制信號引入此語言動力系統的狀態空間。我們根據貝爾曼方程式直接在隱藏狀態上訓練值函數，從而使基於梯度的最佳化能夠在測試時獲得最佳控制信號。我們的實驗表明，與微調方法相比，我們的模型優於現有的測試時間對齊技術，同時所需的資源也少得多。

##### **Chain-of-Scrutiny: Detecting Backdoor Attacks for Large Language Models**
2406.05948v1 by Xi Li, Yusen Zhang, Renze Lou, Chen Wu, Jiaqi Wang

Backdoor attacks present significant threats to Large Language Models (LLMs),
particularly with the rise of third-party services that offer API integration
and prompt engineering. Untrustworthy third parties can plant backdoors into
LLMs and pose risks to users by embedding malicious instructions into user
queries. The backdoor-compromised LLM will generate malicious output when and
input is embedded with a specific trigger predetermined by an attacker.
Traditional defense strategies, which primarily involve model parameter
fine-tuning and gradient calculation, are inadequate for LLMs due to their
extensive computational and clean data requirements. In this paper, we propose
a novel solution, Chain-of-Scrutiny (CoS), to address these challenges.
Backdoor attacks fundamentally create a shortcut from the trigger to the target
output, thus lack reasoning support. Accordingly, CoS guides the LLMs to
generate detailed reasoning steps for the input, then scrutinizes the reasoning
process to ensure consistency with the final answer. Any inconsistency may
indicate an attack. CoS only requires black-box access to LLM, offering a
practical defense, particularly for API-accessible LLMs. It is user-friendly,
enabling users to conduct the defense themselves. Driven by natural language,
the entire defense process is transparent to users. We validate the
effectiveness of CoS through extensive experiments across various tasks and
LLMs. Additionally, experiments results shows CoS proves more beneficial for
more powerful LLMs.

摘要：後門攻擊對大型語言模型 (LLM) 構成重大威脅，特別是在提供 API 整合和提示工程的第三方服務興起的情況下。不可信的第三方可以將後門植入 LLM，並透過將惡意指令嵌入使用者查詢中，對使用者構成風險。後門受損的 LLM 將在輸入嵌入攻擊者預先設定的特定觸發器時產生惡意輸出。傳統的防禦策略主要涉及模型參數微調和梯度計算，由於其廣泛的計算和乾淨資料需求，因此不足以應對 LLM。在本文中，我們提出了一種創新的解決方案，即審查鏈 (CoS)，以應對這些挑戰。後門攻擊基本上從觸發器建立到目標輸出的捷徑，因此缺乏推理支援。因此，CoS 指導 LLM 為輸入產生詳細的推理步驟，然後仔細審查推理過程，以確保與最終答案一致。任何不一致都可能表示攻擊。CoS 只需要對 LLM 進行黑盒存取，提供實用的防禦，特別是對於可透過 API 存取的 LLM。它使用方便，使用戶可以自行進行防禦。在自然語言的驅動下，整個防禦過程對使用者而言是透明的。我們透過各種任務和 LLM 的廣泛實驗驗證了 CoS 的有效性。此外，實驗結果顯示 CoS 對功能更強大的 LLM 更有益。

##### **Safety Alignment Should Be Made More Than Just a Few Tokens Deep**
2406.05946v1 by Xiangyu Qi, Ashwinee Panda, Kaifeng Lyu, Xiao Ma, Subhrajit Roy, Ahmad Beirami, Prateek Mittal, Peter Henderson

The safety alignment of current Large Language Models (LLMs) is vulnerable.
Relatively simple attacks, or even benign fine-tuning, can jailbreak aligned
models. We argue that many of these vulnerabilities are related to a shared
underlying issue: safety alignment can take shortcuts, wherein the alignment
adapts a model's generative distribution primarily over only its very first few
output tokens. We refer to this issue as shallow safety alignment. In this
paper, we present case studies to explain why shallow safety alignment can
exist and provide evidence that current aligned LLMs are subject to this issue.
We also show how these findings help explain multiple recently discovered
vulnerabilities in LLMs, including the susceptibility to adversarial suffix
attacks, prefilling attacks, decoding parameter attacks, and fine-tuning
attacks. Importantly, we discuss how this consolidated notion of shallow safety
alignment sheds light on promising research directions for mitigating these
vulnerabilities. For instance, we show that deepening the safety alignment
beyond just the first few tokens can often meaningfully improve robustness
against some common exploits. Finally, we design a regularized finetuning
objective that makes the safety alignment more persistent against fine-tuning
attacks by constraining updates on initial tokens. Overall, we advocate that
future safety alignment should be made more than just a few tokens deep.

摘要：大型語言模型 (LLM) 的安全調整容易受到攻擊。
相對簡單的攻擊，甚至是良性的微調，都可以破解調整過的模型。我們認為，其中許多漏洞都與一個共同的根本問題有關：安全調整可以走捷徑，其中調整主要只針對模型生成分布的前幾個輸出代碼。我們將此問題稱為淺層安全調整。在本文中，我們提出案例研究來解釋為什麼會出現淺層安全調整，並提供證據證明當前調整過的 LLM 會受到此問題影響。我們還展示了這些發現如何幫助解釋最近在 LLM 中發現的多個漏洞，包括對抗性後綴攻擊、預填充攻擊、解碼參數攻擊和微調攻擊的敏感性。重要的是，我們討論了淺層安全調整的這個統一概念如何為減輕這些漏洞提供有希望的研究方向。例如，我們表明，將安全調整擴展到前幾個代碼之外通常可以顯著提高對某些常見漏洞的魯棒性。最後，我們設計了一個正則化的微調目標，通過限制初始代碼的更新，使安全調整對微調攻擊更具持續性。總的來說，我們提倡未來的安全調整應該不止幾個代碼深度。

##### **Semisupervised Neural Proto-Language Reconstruction**
2406.05930v1 by Liang Lu, Peirong Xie, David R. Mortensen

Existing work implementing comparative reconstruction of ancestral languages
(proto-languages) has usually required full supervision. However, historical
reconstruction models are only of practical value if they can be trained with a
limited amount of labeled data. We propose a semisupervised historical
reconstruction task in which the model is trained on only a small amount of
labeled data (cognate sets with proto-forms) and a large amount of unlabeled
data (cognate sets without proto-forms). We propose a neural architecture for
comparative reconstruction (DPD-BiReconstructor) incorporating an essential
insight from linguists' comparative method: that reconstructed words should not
only be reconstructable from their daughter words, but also deterministically
transformable back into their daughter words. We show that this architecture is
able to leverage unlabeled cognate sets to outperform strong semisupervised
baselines on this novel task.

摘要：現有的工作實施祖語的比較重建（原始語言）通常需要完全監督。然而，歷史重建模型只有在使用有限標記資料訓練時才有實用價值。我們提出一個半監督的歷史重建任務，其中模型僅使用少量標記資料（具有原始形式的同源詞組）和大量的未標記資料（沒有原始形式的同源詞組）進行訓練。我們提出了一個比較重建的神經架構（DPD-BiReconstructor），其中融入了語言學家比較方法的一項基本見解：重建的詞彙不僅應該可以從它們的子詞重建，而且還應該可以確定性地轉換回它們的子詞。我們表明，這種架構能夠利用未標記的同源詞組，在這個新任務中優於強大的半監督基準。

##### **Hello Again! LLM-powered Personalized Agent for Long-term Dialogue**
2406.05925v1 by Hao Li, Chenghao Yang, An Zhang, Yang Deng, Xiang Wang, Tat-Seng Chua

Open-domain dialogue systems have seen remarkable advancements with the
development of large language models (LLMs). Nonetheless, most existing
dialogue systems predominantly focus on brief single-session interactions,
neglecting the real-world demands for long-term companionship and personalized
interactions with chatbots. Crucial to addressing this real-world need are
event summary and persona management, which enable reasoning for appropriate
long-term dialogue responses. Recent progress in the human-like cognitive and
reasoning capabilities of LLMs suggests that LLM-based agents could
significantly enhance automated perception, decision-making, and
problem-solving. In response to this potential, we introduce a model-agnostic
framework, the Long-term Dialogue Agent (LD-Agent), which incorporates three
independently tunable modules dedicated to event perception, persona
extraction, and response generation. For the event memory module, long and
short-term memory banks are employed to separately focus on historical and
ongoing sessions, while a topic-based retrieval mechanism is introduced to
enhance the accuracy of memory retrieval. Furthermore, the persona module
conducts dynamic persona modeling for both users and agents. The integration of
retrieved memories and extracted personas is subsequently fed into the
generator to induce appropriate responses. The effectiveness, generality, and
cross-domain capabilities of LD-Agent are empirically demonstrated across
various illustrative benchmarks, models, and tasks. The code is released at
https://github.com/leolee99/LD-Agent.

摘要：開放領域對話系統隨著大型語言模型 (LLM) 的發展而取得顯著進展。儘管如此，現有的對話系統大多專注於簡短的單一對話互動，忽略了對長期陪伴和與聊天機器人進行個性化互動的實際需求。滿足這種實際需求至關重要的是事件摘要和角色管理，它們能夠推理出適當的長期對話回應。LLM 類人認知和推理能力的最新進展表明，基於 LLM 的代理可以顯著增強自動感知、決策制定和問題解決。針對這種潛力，我們引入了一個與模型無關的框架，即長期對話代理 (LD-Agent)，它包含三個獨立可調的模組，專門用於事件感知、角色提取和回應產生。對於事件記憶模組，採用長期和短期記憶庫分別關注歷史和進行中的對話，同時引入基於主題的檢索機制來提高記憶檢索的準確性。此外，角色模組對使用者和代理進行動態角色建模。檢索的記憶和提取的角色隨後被輸入到生成器中以誘導適當的回應。LD-Agent 的有效性、普遍性和跨領域功能已在各種說明性基準、模型和任務中得到實證證明。程式碼發布於 https://github.com/leolee99/LD-Agent。

##### **Why Don't Prompt-Based Fairness Metrics Correlate?**
2406.05918v1 by Abdelrahman Zayed, Goncalo Mordido, Ioana Baldini, Sarath Chandar

The widespread use of large language models has brought up essential
questions about the potential biases these models might learn. This led to the
development of several metrics aimed at evaluating and mitigating these biases.
In this paper, we first demonstrate that prompt-based fairness metrics exhibit
poor agreement, as measured by correlation, raising important questions about
the reliability of fairness assessment using prompts. Then, we outline six
relevant reasons why such a low correlation is observed across existing
metrics. Based on these insights, we propose a method called Correlated
Fairness Output (CAIRO) to enhance the correlation between fairness metrics.
CAIRO augments the original prompts of a given fairness metric by using several
pre-trained language models and then selects the combination of the augmented
prompts that achieves the highest correlation across metrics. We show a
significant improvement in Pearson correlation from 0.3 and 0.18 to 0.90 and
0.98 across metrics for gender and religion biases, respectively. Our code is
available at https://github.com/chandar-lab/CAIRO.

摘要：大型語言模型的廣泛使用提出了關於這些模型可能學習到的潛在偏差的基本問題。這導致了開發了幾個用於評估和減輕這些偏差的指標。在本文中，我們首先證明基於提示的公平性指標表現出很差的一致性，如通過相關性測量的那樣，這引發了關於使用提示進行公平性評估的可靠性的重要問題。然後，我們概述了在現有指標中觀察到如此低相關性的六個相關原因。基於這些見解，我們提出了一種稱為相關公平性輸出 (CAIRO) 的方法來增強公平性指標之間的相關性。CAIRO 通過使用幾個預訓練的語言模型來擴充給定公平性指標的原始提示，然後選擇在指標之間實現最高相關性的擴充提示組合。我們展示了性別和宗教偏差的指標的皮爾森相關性從 0.3 和 0.18 分別顯著提高到 0.90 和 0.98。我們的代碼可在 https://github.com/chandar-lab/CAIRO 獲得。

##### **BD-SAT: High-resolution Land Use Land Cover Dataset & Benchmark Results for Developing Division: Dhaka, BD**
2406.05912v1 by Ovi Paul, Abu Bakar Siddik Nayem, Anis Sarker, Amin Ahsan Ali, M Ashraful Amin, AKM Mahbubur Rahman

Land Use Land Cover (LULC) analysis on satellite images using deep
learning-based methods is significantly helpful in understanding the geography,
socio-economic conditions, poverty levels, and urban sprawl in developing
countries. Recent works involve segmentation with LULC classes such as
farmland, built-up areas, forests, meadows, water bodies, etc. Training deep
learning methods on satellite images requires large sets of images annotated
with LULC classes. However, annotated data for developing countries are scarce
due to a lack of funding, absence of dedicated residential/industrial/economic
zones, a large population, and diverse building materials. BD-SAT provides a
high-resolution dataset that includes pixel-by-pixel LULC annotations for Dhaka
metropolitan city and surrounding rural/urban areas. Using a strict and
standardized procedure, the ground truth is created using Bing satellite
imagery with a ground spatial distance of 2.22 meters per pixel. A three-stage,
well-defined annotation process has been followed with support from GIS experts
to ensure the reliability of the annotations. We performed several experiments
to establish benchmark results. The results show that the annotated BD-SAT is
sufficient to train large deep learning models with adequate accuracy for five
major LULC classes: forest, farmland, built-up areas, water bodies, and
meadows.

摘要：使用基於深度學習的方法對衛星影像進行土地利用土地覆蓋 (LULC) 分析，對於了解開發中國家的地理、社會經濟條件、貧困程度和都市擴張極有幫助。最近的研究涉及使用農田、建成區、森林、草地、水體等 LULC 類別進行分割。在衛星影像上訓練深度學習方法需要大量標註有 LULC 類別的影像集。然而，由於缺乏資金、沒有專門的住宅/工業/經濟區、人口眾多和建築材料多樣，開發中國家的標註資料很稀少。BD-SAT 提供了一個高解析度資料集，其中包含達卡都會區和周圍農村/都市地區的逐像素 LULC 標註。使用嚴格且標準化的程序，使用 Bing 衛星影像建立真實情況，其地面空間距離為每像素 2.22 公尺。在 GIS 專家的支援下，遵循了一個定義明確的三階段標註程序，以確保標註的可靠性。我們進行了多項實驗以建立基準結果。結果顯示，標註的 BD-SAT 足以訓練大型深度學習模型，對於五個主要的 LULC 類別（森林、農田、建成區、水體和草地）具有足夠的準確度。

##### **Feriji: A French-Zarma Parallel Corpus, Glossary & Translator**
2406.05888v1 by Mamadou K. Keita, Elysabhete Amadou Ibrahim, Habibatou Abdoulaye Alfari, Christopher Homan

Machine translation (MT) is a rapidly expanding field that has experienced
significant advancements in recent years with the development of models capable
of translating multiple languages with remarkable accuracy. However, the
representation of African languages in this field still needs to improve due to
linguistic complexities and limited resources. This applies to the Zarma
language, a dialect of Songhay (of the Nilo-Saharan language family) spoken by
over 5 million people across Niger and neighboring countries
\cite{lewis2016ethnologue}. This paper introduces Feriji, the first robust
French-Zarma parallel corpus and glossary designed for MT. The corpus,
containing 61,085 sentences in Zarma and 42,789 in French, and a glossary of
4,062 words represent a significant step in addressing the need for more
resources for Zarma. We fine-tune three large language models on our dataset,
obtaining a BLEU score of 30.06 on the best-performing model. We further
evaluate the models on human judgments of fluency, comprehension, and
readability and the importance and impact of the corpus and models. Our
contributions help to bridge a significant language gap and promote an
essential and overlooked indigenous African language.

摘要：機器翻譯 (MT) 是快速擴展的領域，隨著能夠以驚人準確度翻譯多種語言的模型的開發，近年來已取得顯著進展。然而，由於語言複雜性和資源有限，此領域中非洲語言的代表性仍有待改進。這適用於 Zarma 語言，這是 Songhay（尼羅撒哈拉語系）的方言，超過 500 萬人使用，遍及尼日和鄰國 \cite{lewis2016ethnologue}。本文介紹了 Feriji，這是第一個專為 MT 設計的強健法語-扎爾馬平行語料庫和詞彙表。語料庫包含 61,085 句扎爾馬語和 42,789 句法語，而詞彙表包含 4,062 個單字，代表著滿足扎爾馬語更多資源需求的重大進展。我們針對自己的資料集微調了三個大型語言模型，在效能最佳的模型上取得 BLEU 分數 30.06。我們進一步針對人類對流暢度、理解度和可讀性的判斷，以及語料庫和模型的重要性與影響，評估這些模型。我們的貢獻有助於彌合重大的語言差距，並推廣一種重要且被忽視的非洲本土語言。

