{"2501.00070": {"publish_time": "2024-12-29", "title": "ICLR: In-Context Learning of Representations", "paper_summary": "Recent work has demonstrated that semantics specified by pretraining data\ninfluence how representations of different concepts are organized in a large\nlanguage model (LLM). However, given the open-ended nature of LLMs, e.g., their\nability to in-context learn, we can ask whether models alter these pretraining\nsemantics to adopt alternative, context-specified ones. Specifically, if we\nprovide in-context exemplars wherein a concept plays a different role than what\nthe pretraining data suggests, do models reorganize their representations in\naccordance with these novel semantics? To answer this question, we take\ninspiration from the theory of conceptual role semantics and define a toy\n\"graph tracing\" task wherein the nodes of the graph are referenced via concepts\nseen during training (e.g., apple, bird, etc.) and the connectivity of the\ngraph is defined via some predefined structure (e.g., a square grid). Given\nexemplars that indicate traces of random walks on the graph, we analyze\nintermediate representations of the model and find that as the amount of\ncontext is scaled, there is a sudden re-organization from pretrained semantic\nrepresentations to in-context representations aligned with the graph structure.\nFurther, we find that when reference concepts have correlations in their\nsemantics (e.g., Monday, Tuesday, etc.), the context-specified graph structure\nis still present in the representations, but is unable to dominate the\npretrained structure. To explain these results, we analogize our task to energy\nminimization for a predefined graph topology, providing evidence towards an\nimplicit optimization process to infer context-specified semantics. Overall,\nour findings indicate scaling context-size can flexibly re-organize model\nrepresentations, possibly unlocking novel capabilities.", "paper_summary_zh": "<paragraph>\u6700\u8fd1\u7684\u7814\u7a76\u8868\u660e\uff0c\u7531\u9884\u8bad\u7ec3\u6570\u636e\u6307\u5b9a\u7684\u8bed\u4e49\u4f1a\u5f71\u54cd\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u4e2d\u4e0d\u540c\u6982\u5ff5\u7684\u8868\u5f81\u7ec4\u7ec7\u65b9\u5f0f\u3002\u7136\u800c\uff0c\u9274\u4e8e LLM \u7684\u5f00\u653e\u5f0f\u672c\u8d28\uff0c\u4f8b\u5982\u5b83\u4eec\u5728\u8bed\u5883\u4e2d\u5b66\u4e60\u7684\u80fd\u529b\uff0c\u6211\u4eec\u53ef\u4ee5\u8be2\u95ee\u6a21\u578b\u662f\u5426\u4f1a\u6539\u53d8\u8fd9\u4e9b\u9884\u8bad\u7ec3\u8bed\u4e49\u4ee5\u91c7\u7528\u66ff\u4ee3\u7684\u3001\u8bed\u5883\u6307\u5b9a\u7684\u8bed\u4e49\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5982\u679c\u6211\u4eec\u5728\u8bed\u5883\u4e2d\u63d0\u4f9b\u793a\u4f8b\uff0c\u5176\u4e2d\u4e00\u4e2a\u6982\u5ff5\u626e\u6f14\u7684\u89d2\u8272\u4e0e\u9884\u8bad\u7ec3\u6570\u636e\u6240\u6697\u793a\u7684\u4e0d\u540c\uff0c\u6a21\u578b\u662f\u5426\u4f1a\u6839\u636e\u8fd9\u4e9b\u65b0\u8bed\u4e49\u91cd\u65b0\u7ec4\u7ec7\u5b83\u4eec\u7684\u8868\u5f81\uff1f\u4e3a\u4e86\u56de\u7b54\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u4eec\u4ece\u6982\u5ff5\u89d2\u8272\u8bed\u4e49\u7406\u8bba\u4e2d\u6c72\u53d6\u7075\u611f\uff0c\u5e76\u5b9a\u4e49\u4e86\u4e00\u4e2a\u73a9\u5177\u201c\u56fe\u793a\u8ffd\u8e2a\u201d\u4efb\u52a1\uff0c\u5176\u4e2d\u56fe\u7684\u8282\u70b9\u901a\u8fc7\u8bad\u7ec3\u671f\u95f4\u770b\u5230\u7684\u6982\u5ff5\uff08\u4f8b\u5982\uff0c\u82f9\u679c\u3001\u9e1f\u7b49\uff09\u8fdb\u884c\u5f15\u7528\uff0c\u5e76\u4e14\u56fe\u7684\u8fde\u901a\u6027\u662f\u901a\u8fc7\u4e00\u4e9b\u9884\u5b9a\u4e49\u7684\u7ed3\u6784\uff08\u4f8b\u5982\uff0c\u6b63\u65b9\u5f62\u7f51\u683c\uff09\u5b9a\u4e49\u7684\u3002\u7ed9\u5b9a\u6307\u793a\u5728\u56fe\u4e0a\u968f\u673a\u6e38\u8d70\u7684\u8f68\u8ff9\u7684\u793a\u4f8b\uff0c\u6211\u4eec\u5206\u6790\u4e86\u6a21\u578b\u7684\u4e2d\u95f4\u8868\u5f81\uff0c\u53d1\u73b0\u968f\u7740\u8bed\u5883\u91cf\u7684\u589e\u52a0\uff0c\u4ece\u9884\u8bad\u7ec3\u8bed\u4e49\u8868\u5f81\u5230\u4e0e\u56fe\u7ed3\u6784\u5bf9\u9f50\u7684\u8bed\u5883\u8868\u5f81\u7a81\u7136\u53d1\u751f\u4e86\u91cd\u65b0\u7ec4\u7ec7\u3002\u6b64\u5916\uff0c\u6211\u4eec\u53d1\u73b0\u5f53\u53c2\u8003\u6982\u5ff5\u5728\u5176\u8bed\u4e49\u4e2d\u5177\u6709\u76f8\u5173\u6027\uff08\u4f8b\u5982\uff0c\u661f\u671f\u4e00\u3001\u661f\u671f\u4e8c\u7b49\uff09\u65f6\uff0c\u8bed\u5883\u6307\u5b9a\u7684\u56fe\u7ed3\u6784\u4ecd\u7136\u5b58\u5728\u4e8e\u8868\u5f81\u4e2d\uff0c\u4f46\u65e0\u6cd5\u652f\u914d\u9884\u8bad\u7ec3\u7ed3\u6784\u3002\u4e3a\u4e86\u89e3\u91ca\u8fd9\u4e9b\u7ed3\u679c\uff0c\u6211\u4eec\u5c06\u6211\u4eec\u7684\u4efb\u52a1\u7c7b\u6bd4\u4e3a\u9884\u5b9a\u4e49\u56fe\u62d3\u6251\u7684\u80fd\u91cf\u6700\u5c0f\u5316\uff0c\u4e3a\u63a8\u65ad\u8bed\u5883\u6307\u5b9a\u8bed\u4e49\u7684\u9690\u5f0f\u4f18\u5316\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u8bc1\u636e\u3002\u603b\u4f53\u800c\u8a00\uff0c\u6211\u4eec\u7684\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u6269\u5c55\u8bed\u5883\u5927\u5c0f\u53ef\u4ee5\u7075\u6d3b\u5730\u91cd\u65b0\u7ec4\u7ec7\u6a21\u578b\u8868\u5f81\uff0c\u6709\u53ef\u80fd\u89e3\u9501\u65b0\u7684\u529f\u80fd\u3002</paragraph>", "author": "Core Francisco Park et.al.", "authors": "Core Francisco Park, Andrew Lee, Ekdeep Singh Lubana, Yongyi Yang, Maya Okawa, Kento Nishi, Martin Wattenberg, Hidenori Tanaka", "id": "2501.00070v1", "paper_url": "http://arxiv.org/abs/2501.00070v1", "repo": "null"}}