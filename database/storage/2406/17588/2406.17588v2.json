{"2406.17588": {"publish_time": "2024-06-25", "title": "LongIns: A Challenging Long-context Instruction-based Exam for LLMs", "paper_summary": "The long-context capabilities of large language models (LLMs) have been a hot\ntopic in recent years. To evaluate the performance of LLMs in different\nscenarios, various assessment benchmarks have emerged. However, as most of\nthese benchmarks focus on identifying key information to answer questions,\nwhich mainly requires the retrieval ability of LLMs, these benchmarks can\npartially represent the reasoning performance of LLMs from large amounts of\ninformation. Meanwhile, although LLMs often claim to have context windows of\n32k, 128k, 200k, or even longer, these benchmarks fail to reveal the actual\nsupported length of these LLMs. To address these issues, we propose the LongIns\nbenchmark dataset, a challenging long-context instruction-based exam for LLMs,\nwhich is built based on the existing instruction datasets. Specifically, in our\nLongIns, we introduce three evaluation settings: Global Instruction & Single\nTask (GIST), Local Instruction & Single Task (LIST), and Local Instruction &\nMultiple Tasks (LIMT). Based on LongIns, we perform comprehensive evaluations\non existing LLMs and have the following important findings: (1). The\ntop-performing GPT-4 with 128k context length performs poorly on the evaluation\ncontext window of 16k in our LongIns. (2). For the multi-hop reasoning ability\nof many existing LLMs, significant efforts are still needed under short context\nwindows (less than 4k).", "paper_summary_zh": "\u8fd1\u5e74\u4f86\uff0c\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u9577\u6587\u672c\u8655\u7406\u80fd\u529b\u4e00\u76f4\u662f\u71b1\u9580\u8a71\u984c\u3002\u70ba\u4e86\u8a55\u4f30 LLM \u5728\u4e0d\u540c\u5834\u666f\u4e2d\u7684\u8868\u73fe\uff0c\u51fa\u73fe\u4e86\u5404\u7a2e\u8a55\u4f30\u57fa\u6e96\u3002\u7136\u800c\uff0c\u7531\u65bc\u5927\u591a\u6578\u9019\u4e9b\u57fa\u6e96\u90fd\u5c08\u6ce8\u65bc\u8b58\u5225\u95dc\u9375\u8cc7\u8a0a\u4ee5\u56de\u7b54\u554f\u984c\uff0c\u9019\u4e3b\u8981\u9700\u8981 LLM \u7684\u6aa2\u7d22\u80fd\u529b\uff0c\u56e0\u6b64\u9019\u4e9b\u57fa\u6e96\u53ea\u80fd\u90e8\u5206\u4ee3\u8868 LLM \u5f9e\u5927\u91cf\u8cc7\u8a0a\u4e2d\u9032\u884c\u63a8\u7406\u7684\u8868\u73fe\u3002\u540c\u6642\uff0c\u5118\u7ba1 LLM \u7d93\u5e38\u8072\u7a31\u5177\u6709 32k\u3001128k\u3001200k \u751a\u81f3\u66f4\u9577\u7684\u4e0a\u4e0b\u6587\u8996\u7a97\uff0c\u4f46\u9019\u4e9b\u57fa\u6e96\u672a\u80fd\u63ed\u793a\u9019\u4e9b LLM \u7684\u5be6\u969b\u652f\u63f4\u9577\u5ea6\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86 LongIns \u57fa\u6e96\u8cc7\u6599\u96c6\uff0c\u9019\u662f\u4e00\u500b\u57fa\u65bc\u6307\u4ee4\u7684\u5177\u6709\u6311\u6230\u6027\u7684 LLM \u9577\u6587\u672c\u8003\u8a66\uff0c\u5b83\u662f\u6839\u64da\u73fe\u6709\u7684\u6307\u4ee4\u8cc7\u6599\u96c6\u5efa\u7acb\u7684\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u5728\u6211\u5011\u7684 LongIns \u4e2d\uff0c\u6211\u5011\u5f15\u5165\u4e86\u4e09\u7a2e\u8a55\u4f30\u8a2d\u5b9a\uff1a\u5168\u5c40\u6307\u4ee4\u548c\u55ae\u4e00\u4efb\u52d9 (GIST)\u3001\u5c40\u90e8\u6307\u4ee4\u548c\u55ae\u4e00\u4efb\u52d9 (LIST) \u4ee5\u53ca\u5c40\u90e8\u6307\u4ee4\u548c\u591a\u500b\u4efb\u52d9 (LIMT)\u3002\u6839\u64da LongIns\uff0c\u6211\u5011\u5c0d\u73fe\u6709\u7684 LLM \u9032\u884c\u4e86\u5168\u9762\u7684\u8a55\u4f30\uff0c\u4e26\u6709\u4e86\u4ee5\u4e0b\u91cd\u8981\u7684\u767c\u73fe\uff1a(1)\u3002\u5728\u6211\u5011\u7684 LongIns \u4e2d\uff0c\u8868\u73fe\u6700\u4f73\u7684 GPT-4\uff0c\u5176\u4e0a\u4e0b\u6587\u9577\u5ea6\u70ba 128k\uff0c\u5728 16k \u7684\u8a55\u4f30\u4e0a\u4e0b\u6587\u8996\u7a97\u4e2d\u8868\u73fe\u4e0d\u4f73\u3002(2)\u3002\u5c0d\u65bc\u8a31\u591a\u73fe\u6709 LLM \u7684\u591a\u8df3\u63a8\u7406\u80fd\u529b\uff0c\u5728\u77ed\u4e0a\u4e0b\u6587\u8996\u7a97\uff08\u5c0f\u65bc 4k\uff09\u4e0b\u4ecd\u9700\u8981\u5927\u91cf\u7684\u52aa\u529b\u3002", "author": "Shawn Gavin et.al.", "authors": "Shawn Gavin, Tuney Zheng, Jiaheng Liu, Quehry Que, Noah Wang, Jian Yang, Chenchen Zhang, Wenhao Huang, Wenhu Chen, Ge Zhang", "id": "2406.17588v2", "paper_url": "http://arxiv.org/abs/2406.17588v2", "repo": "null"}}