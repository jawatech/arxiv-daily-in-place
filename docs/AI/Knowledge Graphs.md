
### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-07-19**|**Hierarchical Windowed Graph Attention Network and a Large Scale Dataset for Isolated Indian Sign Language Recognition**|Suvajit Patra et.al.|[2407.14224v1](http://arxiv.org/abs/2407.14224v1)|null|
|**2024-07-19**|**Enhancing Data-Limited Graph Neural Networks by Actively Distilling Knowledge from Large Language Models**|Quan Li et.al.|[2407.13989v1](http://arxiv.org/abs/2407.13989v1)|null|
|**2024-07-18**|**A Comprehensive Review of Recommender Systems: Transitioning from Theory to Practice**|Shaina Raza et.al.|[2407.13699v1](http://arxiv.org/abs/2407.13699v1)|null|
|**2024-07-17**|**Is Sarcasm Detection A Step-by-Step Reasoning Process in Large Language Models?**|Ben Yao et.al.|[2407.12725v1](http://arxiv.org/abs/2407.12725v1)|null|
|**2024-07-17**|**Subgraph-Aware Training of Text-based Methods for Knowledge Graph Completion**|Youmin Ko et.al.|[2407.12703v2](http://arxiv.org/abs/2407.12703v2)|null|
|**2024-07-17**|**Abstraction Alignment: Comparing Model and Human Conceptual Relationships**|Angie Boggust et.al.|[2407.12543v1](http://arxiv.org/abs/2407.12543v1)|[link](https://github.com/mitvis/abstraction-alignment)|
|**2024-07-17**|**Struct-X: Enhancing Large Language Models Reasoning with Structured Data**|Xiaoyu Tan et.al.|[2407.12522v1](http://arxiv.org/abs/2407.12522v1)|null|
|**2024-07-17**|**Explainable Biomedical Hypothesis Generation via Retrieval Augmented Generation enabled Large Language Models**|Alexander R. Pelletier et.al.|[2407.12888v1](http://arxiv.org/abs/2407.12888v1)|null|
|**2024-07-16**|**A Comprehensive Evaluation of Large Language Models on Temporal Event Forecasting**|He Chang et.al.|[2407.11638v1](http://arxiv.org/abs/2407.11638v1)|null|
|**2024-07-16**|**Learning on Graphs with Large Language Models(LLMs): A Deep Dive into Model Robustness**|Kai Guo et.al.|[2407.12068v1](http://arxiv.org/abs/2407.12068v1)|null|
|**2024-07-16**|**CIC-BART-SSA: Controllable Image Captioning with Structured Semantic Augmentation**|Kalliopi Basioti et.al.|[2407.11393v2](http://arxiv.org/abs/2407.11393v2)|[link](https://github.com/SamsungLabs/CIC-BART-SSA)|
|**2024-07-15**|**Think-on-Graph 2.0: Deep and Interpretable Large Language Model Reasoning with Knowledge Graph-guided Retrieval**|Shengjie Ma et.al.|[2407.10805v1](http://arxiv.org/abs/2407.10805v1)|null|
|**2024-07-15**|**Graphusion: Leveraging Large Language Models for Scientific Knowledge Graph Fusion and Construction in NLP Education**|Rui Yang et.al.|[2407.10794v1](http://arxiv.org/abs/2407.10794v1)|[link](https://github.com/irenezihuili/cgprompt)|
|**2024-07-15**|**GraphEval: A Knowledge-Graph Based LLM Hallucination Evaluation Framework**|Hannah Sansford et.al.|[2407.10793v1](http://arxiv.org/abs/2407.10793v1)|null|
|**2024-07-15**|**Scaling 3D Reasoning with LMMs to Large Robot Mission Environments Using Datagraphs**|W. J. Meijer et.al.|[2407.10743v1](http://arxiv.org/abs/2407.10743v1)|null|
|**2024-07-14**|**AutoGRAMS: Autonomous Graphical Agent Modeling Software**|Ben Krause et.al.|[2407.10049v1](http://arxiv.org/abs/2407.10049v1)|[link](https://github.com/autograms/autograms)|
|**2024-07-13**|**FarFetched: Entity-centric Reasoning and Claim Validation for the Greek Language based on Textually Represented Environments**|Dimitris Papadopoulos et.al.|[2407.09888v1](http://arxiv.org/abs/2407.09888v1)|[link](https://github.com/lighteternal/farfetched_nlp)|
|**2024-07-12**|**GOFA: A Generative One-For-All Model for Joint Graph Language Modeling**|Lecheng Kong et.al.|[2407.09709v1](http://arxiv.org/abs/2407.09709v1)|[link](https://github.com/jiaruifeng/gofa)|
|**2024-07-12**|**Human-like Episodic Memory for Infinite Context LLMs**|Zafeirios Fountas et.al.|[2407.09450v1](http://arxiv.org/abs/2407.09450v1)|null|
|**2024-07-12**|**The $Î¼\mathcal{G}$ Language for Programming Graph Neural Networks**|Matteo Belenchia et.al.|[2407.09441v1](http://arxiv.org/abs/2407.09441v1)|null|
|**2024-07-12**|**Towards More Trustworthy and Interpretable LLMs for Code through Syntax-Grounded Explanations**|David N. Palacio et.al.|[2407.08983v1](http://arxiv.org/abs/2407.08983v1)|null|
|**2024-07-12**|**Domain-Hierarchy Adaptation via Chain of Iterative Reasoning for Few-shot Hierarchical Text Classification**|Ke Ji et.al.|[2407.08959v1](http://arxiv.org/abs/2407.08959v1)|null|
|**2024-07-11**|**Cloud Atlas: Efficient Fault Localization for Cloud Systems using Language Models and Causal Insight**|Zhiqiang Xie et.al.|[2407.08694v1](http://arxiv.org/abs/2407.08694v1)|null|
|**2024-07-11**|**Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents**|Haoyi Xiong et.al.|[2407.08516v2](http://arxiv.org/abs/2407.08516v2)|null|
|**2024-07-10**|**A Comprehensive Survey on the Security of Smart Grid: Challenges, Mitigations, and Future Research Opportunities**|Arastoo Zibaeirad et.al.|[2407.07966v1](http://arxiv.org/abs/2407.07966v1)|null|
|**2024-07-10**|**Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs**|Hao-Tien Lewis Chiang et.al.|[2407.07775v2](http://arxiv.org/abs/2407.07775v2)|null|
|**2024-07-10**|**Teaching Transformers Causal Reasoning through Axiomatic Training**|Aniket Vashishtha et.al.|[2407.07612v1](http://arxiv.org/abs/2407.07612v1)|null|
|**2024-07-10**|**STAGE: Simplified Text-Attributed Graph Embeddings Using Pre-trained LLMs**|Aaron Zolnai-Lucas et.al.|[2407.12860v1](http://arxiv.org/abs/2407.12860v1)|null|
|**2024-07-10**|**GLBench: A Comprehensive Benchmark for Graph with Large Language Models**|Yuhan Li et.al.|[2407.07457v2](http://arxiv.org/abs/2407.07457v2)|[link](https://github.com/nineabyss/glbench)|
|**2024-07-09**|**Decoding Climate Disagreement: A Graph Neural Network-Based Approach to Understanding Social Media Dynamics**|Ruiran Su et.al.|[2407.07038v1](http://arxiv.org/abs/2407.07038v1)|null|
|**2024-07-09**|**Graph-Based Captioning: Enhancing Visual Descriptions by Interconnecting Region Captions**|Yu-Guan Hsieh et.al.|[2407.06723v1](http://arxiv.org/abs/2407.06723v1)|null|
|**2024-07-09**|**Combining Knowledge Graphs and Large Language Models**|Amanda Kau et.al.|[2407.06564v1](http://arxiv.org/abs/2407.06564v1)|null|
|**2024-07-08**|**MST5 -- Multilingual Question Answering over Knowledge Graphs**|Nikit Srivastava et.al.|[2407.06041v1](http://arxiv.org/abs/2407.06041v1)|[link](https://github.com/dice-group/MST5)|
|**2024-07-08**|**Enhancing Vision-Language Models with Scene Graphs for Traffic Accident Understanding**|Aaron Lohner et.al.|[2407.05910v1](http://arxiv.org/abs/2407.05910v1)|null|
|**2024-07-08**|**Affordances-Oriented Planning using Foundation Models for Continuous Vision-Language Navigation**|Jiaqi Chen et.al.|[2407.05890v1](http://arxiv.org/abs/2407.05890v1)|null|
|**2024-07-08**|**KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions**|Yanxu Zhu et.al.|[2407.05868v1](http://arxiv.org/abs/2407.05868v1)|[link](https://github.com/yanxuzhu/kg-fpq)|
|**2024-07-07**|**Language Models Encode Collaborative Signals in Recommendation**|Leheng Sheng et.al.|[2407.05441v1](http://arxiv.org/abs/2407.05441v1)|[link](https://github.com/lehengthu/alpharec)|
|**2024-07-07**|**LTLBench: Towards Benchmarks for Evaluating Temporal Logic Reasoning in Large Language Models**|Weizhi Tang et.al.|[2407.05434v1](http://arxiv.org/abs/2407.05434v1)|[link](https://github.com/rutatang/ltlbench)|
|**2024-07-05**|**Leveraging Graph Structures to Detect Hallucinations in Large Language Models**|Noa Nonkes et.al.|[2407.04485v1](http://arxiv.org/abs/2407.04485v1)|[link](https://github.com/noanonkes/Hallucination-Detection-in-LLMs)|
|**2024-07-05**|**AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents**|Petr Anokhin et.al.|[2407.04363v1](http://arxiv.org/abs/2407.04363v1)|[link](https://github.com/airi-institute/arigraph)|
|**2024-07-04**|**Semantic Graphs for Syntactic Simplification: A Revisit from the Age of LLM**|Peiran Yao et.al.|[2407.04067v1](http://arxiv.org/abs/2407.04067v1)|[link](https://github.com/U-Alberta/AMRS3)|
|**2024-07-04**|**Functional Faithfulness in the Wild: Circuit Discovery with Differentiable Computation Graph Pruning**|Lei Yu et.al.|[2407.03779v1](http://arxiv.org/abs/2407.03779v1)|null|
|**2024-07-03**|**BACON: Supercharge Your VLM with Bag-of-Concept Graph to Mitigate Hallucinations**|Zhantao Yang et.al.|[2407.03314v1](http://arxiv.org/abs/2407.03314v1)|null|
|**2024-07-03**|**Knowledge-based Consistency Testing of Large Language Models**|Sai Sathiesh Rajan et.al.|[2407.12830v1](http://arxiv.org/abs/2407.12830v1)|null|
|**2024-07-03**|**GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models**|Zike Yuan et.al.|[2407.02936v1](http://arxiv.org/abs/2407.02936v1)|[link](https://github.com/zikeyuan/gracore)|
|**2024-07-03**|**Croppable Knowledge Graph Embedding**|Yushan Zhu et.al.|[2407.02779v1](http://arxiv.org/abs/2407.02779v1)|null|
|**2024-07-02**|**Reasoning in Large Language Models: A Geometric Perspective**|Romain Cosentino et.al.|[2407.02678v1](http://arxiv.org/abs/2407.02678v1)|null|
|**2024-07-02**|**Ensuring Responsible Sourcing of Large Language Model Training Data Through Knowledge Graph Comparison**|Devam Mondal et.al.|[2407.02659v1](http://arxiv.org/abs/2407.02659v1)|null|
|**2024-07-02**|**Multi-Peptide: Multimodality Leveraged Language-Graph Learning of Peptide Properties**|Srivathsan Badrinarayanan et.al.|[2407.03380v1](http://arxiv.org/abs/2407.03380v1)|[link](https://github.com/srivathsanb14/multipeptide)|
|**2024-07-02**|**Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification**|Pritish Sahu et.al.|[2407.02352v1](http://arxiv.org/abs/2407.02352v1)|null|
|**2024-07-02**|**Is Your Large Language Model Knowledgeable or a Choices-Only Cheater?**|Nishant Balepur et.al.|[2407.01992v1](http://arxiv.org/abs/2407.01992v1)|null|
|**2024-07-01**|**CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents**|Tianqi Xu et.al.|[2407.01511v1](http://arxiv.org/abs/2407.01511v1)|[link](https://github.com/camel-ai/crab)|
|**2024-07-01**|**Dynamic Few-Shot Learning for Knowledge Graph Question Answering**|Jacopo D'Abramo et.al.|[2407.01409v1](http://arxiv.org/abs/2407.01409v1)|null|
|**2024-07-01**|**Adapting Multilingual LLMs to Low-Resource Languages with Knowledge Graphs via Adapters**|Daniil Gurgurov et.al.|[2407.01406v1](http://arxiv.org/abs/2407.01406v1)|[link](https://github.com/d-gurgurov/Injecting-Commonsense-Knowledge-into-LLMs)|
|**2024-07-01**|**SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model**|Lingyue Fu et.al.|[2407.01245v1](http://arxiv.org/abs/2407.01245v1)|null|
|**2024-07-01**|**Revisiting Random Walks for Learning on Graphs**|Jinwoo Kim et.al.|[2407.01214v1](http://arxiv.org/abs/2407.01214v1)|[link](https://github.com/jw9730/random-walk)|
|**2024-07-01**|**LLM Uncertainty Quantification through Directional Entailment Graph and Claim Level Response Augmentation**|Longchao Da et.al.|[2407.00994v2](http://arxiv.org/abs/2407.00994v2)|null|
|**2024-06-30**|**Actionable Cyber Threat Intelligence using Knowledge Graphs and Large Language Models**|Romy Fieblinger et.al.|[2407.02528v1](http://arxiv.org/abs/2407.02528v1)|null|
|**2024-06-30**|**Chain-of-Knowledge: Integrating Knowledge Reasoning into Large Language Models by Learning from Knowledge Graphs**|Yifei Zhang et.al.|[2407.00653v1](http://arxiv.org/abs/2407.00653v1)|null|
|**2024-06-29**|**BioKGBench: A Knowledge Graph Checking Benchmark of AI Agent for Biomedical Science**|Xinna Lin et.al.|[2407.00466v1](http://arxiv.org/abs/2407.00466v1)|[link](https://github.com/westlake-autolab/biokgbench.github.io)|
|**2024-06-29**|**GraphArena: Benchmarking Large Language Models on Graph Computational Problems**|Jianheng Tang et.al.|[2407.00379v1](http://arxiv.org/abs/2407.00379v1)|[link](https://github.com/squareroot3/grapharena)|
|**2024-06-29**|**Teola: Towards End-to-End Optimization of LLM-based Applications**|Xin Tan et.al.|[2407.00326v1](http://arxiv.org/abs/2407.00326v1)|null|
|**2024-06-28**|**Into the Unknown: Generating Geospatial Descriptions for New Environments**|Tzuf Paz-Argaman et.al.|[2406.19967v1](http://arxiv.org/abs/2406.19967v1)|null|
|**2024-06-27**|**Investigating How Large Language Models Leverage Internal Knowledge to Perform Complex Reasoning**|Miyoung Ko et.al.|[2406.19502v1](http://arxiv.org/abs/2406.19502v1)|[link](https://github.com/kaistai/knowledge-reasoning)|
|**2024-06-27**|**Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment**|Hao Fei et.al.|[2406.19255v1](http://arxiv.org/abs/2406.19255v1)|null|
|**2024-06-27**|**TrustUQA: A Trustful Framework for Unified Structured Data Question Answering**|Wen Zhang et.al.|[2406.18916v1](http://arxiv.org/abs/2406.18916v1)|null|
|**2024-06-26**|**Fast Optimizer Benchmark**|Simon Blauth et.al.|[2406.18701v1](http://arxiv.org/abs/2406.18701v1)|[link](https://github.com/automl/fob)|
|**2024-06-26**|**Cascading Large Language Models for Salient Event Graph Generation**|Xingwei Tan et.al.|[2406.18449v1](http://arxiv.org/abs/2406.18449v1)|[link](https://github.com/xingwei-warwick/callmsae)|
|**2024-06-26**|**Sanskrit Knowledge-based Systems: Annotation and Computational Tools**|Hrishikesh Terdalkar et.al.|[2406.18276v1](http://arxiv.org/abs/2406.18276v1)|null|
|**2024-06-26**|**Multilingual Knowledge Graph Completion from Pretrained Language Models with Knowledge Constraints**|Ran Song et.al.|[2406.18085v1](http://arxiv.org/abs/2406.18085v1)|[link](https://github.com/Maxpa1n/gcplm-kgc)|
|**2024-06-26**|**AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning**|Yifan Yang et.al.|[2406.18060v1](http://arxiv.org/abs/2406.18060v1)|[link](https://github.com/yifanycc/adazeta)|
|**2024-06-25**|**DARG: Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph**|Zhehao Zhang et.al.|[2406.17271v1](http://arxiv.org/abs/2406.17271v1)|[link](https://github.com/salt-nlp/darg)|
|**2024-06-25**|**CogMG: Collaborative Augmentation Between Large Language Model and Knowledge Graph**|Tong Zhou et.al.|[2406.17231v1](http://arxiv.org/abs/2406.17231v1)|[link](https://github.com/tongzhou21/CogMG)|
|**2024-06-24**|**Link Prediction with Untrained Message Passing Layers**|Lisi Qarkaxhija et.al.|[2406.16687v1](http://arxiv.org/abs/2406.16687v1)|null|
|**2024-06-24**|**CLEAR: Can Language Models Really Understand Causal Graphs?**|Sirui Chen et.al.|[2406.16605v1](http://arxiv.org/abs/2406.16605v1)|[link](https://github.com/opencausalab/clear)|
|**2024-06-24**|**KEHRL: Learning Knowledge-Enhanced Language Representations with Hierarchical Reinforcement Learning**|Dongyang Li et.al.|[2406.16374v1](http://arxiv.org/abs/2406.16374v1)|[link](https://github.com/MatNLP/KEHRL)|
|**2024-06-24**|**Prompt-Consistency Image Generation (PCIG): A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models**|Yichen Sun et.al.|[2406.16333v1](http://arxiv.org/abs/2406.16333v1)|null|
|**2024-06-24**|**Graph-Augmented LLMs for Personalized Health Insights: A Case Study in Sleep Analysis**|Ajan Subramanian et.al.|[2406.16252v2](http://arxiv.org/abs/2406.16252v2)|null|
|**2024-06-23**|**GraphEval2000: Benchmarking and Improving Large Language Models on Graph Datasets**|Qiming Wu et.al.|[2406.16176v1](http://arxiv.org/abs/2406.16176v1)|null|
|**2024-06-23**|**Can LLM Graph Reasoning Generalize beyond Pattern Memorization?**|Yizhuo Zhang et.al.|[2406.15992v1](http://arxiv.org/abs/2406.15992v1)|null|
|**2024-06-22**|**LLM-Powered Explanations: Unraveling Recommendations Through Subgraph Reasoning**|Guangsi Shi et.al.|[2406.15859v2](http://arxiv.org/abs/2406.15859v2)|null|
|**2024-06-22**|**Large Language Models for Link Stealing Attacks Against Graph Neural Networks**|Faqian Guan et.al.|[2406.16963v1](http://arxiv.org/abs/2406.16963v1)|null|
|**2024-06-21**|**Inferring Pluggable Types with Machine Learning**|Kazi Amanul Islam Siddiqui et.al.|[2406.15676v1](http://arxiv.org/abs/2406.15676v1)|null|
|**2024-06-21**|**NLP-KG: A System for Exploratory Search of Scientific Literature in Natural Language Processing**|Tim Schopf et.al.|[2406.15294v2](http://arxiv.org/abs/2406.15294v2)|[link](https://github.com/nlp-knowledge-graph/nlp-kg-webapp)|
|**2024-06-21**|**Unsupervised Extraction of Dialogue Policies from Conversations**|Makesh Narsimhan Sreedhar et.al.|[2406.15214v1](http://arxiv.org/abs/2406.15214v1)|null|
|**2024-06-21**|**Uni-Mol2: Exploring Molecular Pretraining Model at Scale**|Xiaohong Ji et.al.|[2406.14969v2](http://arxiv.org/abs/2406.14969v2)|null|
|**2024-06-20**|**Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks**|Sefika Efeoglu et.al.|[2406.14745v2](http://arxiv.org/abs/2406.14745v2)|null|
|**2024-06-20**|**Do LLMs Have Distinct and Consistent Personality? TRAIT: Personality Testset designed for LLMs with Psychometrics**|Seungbeen Lee et.al.|[2406.14703v1](http://arxiv.org/abs/2406.14703v1)|null|
|**2024-06-20**|**TAGLAS: An atlas of text-attributed graph datasets in the era of large graph and language models**|Jiarui Feng et.al.|[2406.14683v1](http://arxiv.org/abs/2406.14683v1)|[link](https://github.com/jiaruifeng/taglas)|
|**2024-06-20**|**HYPERmotion: Learning Hybrid Behavior Planning for Autonomous Loco-manipulation**|Jin Wang et.al.|[2406.14655v1](http://arxiv.org/abs/2406.14655v1)|null|
|**2024-06-20**|**GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models**|Shilong Li et.al.|[2406.14550v1](http://arxiv.org/abs/2406.14550v1)|null|
|**2024-06-20**|**medIKAL: Integrating Knowledge Graphs as Assistants of LLMs for Enhanced Clinical Diagnosis on EMRs**|Mingyi Jia et.al.|[2406.14326v1](http://arxiv.org/abs/2406.14326v1)|null|
|**2024-06-20**|**Learning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs**|Junjie Wang et.al.|[2406.14282v1](http://arxiv.org/abs/2406.14282v1)|[link](https://github.com/zjukg/lpkg)|
|**2024-06-20**|**ReaLHF: Optimized RLHF Training for Large Language Models through Parameter Reallocation**|Zhiyu Mei et.al.|[2406.14088v1](http://arxiv.org/abs/2406.14088v1)|[link](https://github.com/openpsi-project/realhf)|
|**2024-06-20**|**HIGHT: Hierarchical Graph Tokenization for Graph-Language Alignment**|Yongqiang Chen et.al.|[2406.14021v1](http://arxiv.org/abs/2406.14021v1)|null|
|**2024-06-19**|**A Pure Transformer Pretraining Framework on Text-attributed Graphs**|Yu Song et.al.|[2406.13873v1](http://arxiv.org/abs/2406.13873v1)|[link](https://github.com/songyyyy/gspt)|
|**2024-06-19**|**Knowledge Graph-Enhanced Large Language Models via Path Selection**|Haochen Liu et.al.|[2406.13862v1](http://arxiv.org/abs/2406.13862v1)|[link](https://github.com/haochenliu2000/kelp)|
|**2024-06-19**|**Few-shot Knowledge Graph Relational Reasoning via Subgraph Adaptation**|Haochen Liu et.al.|[2406.15507v1](http://arxiv.org/abs/2406.15507v1)|[link](https://github.com/HaochenLiu2000/SAFER)|
|**2024-06-19**|**Dr.E Bridges Graphs with Large Language Models through Words**|Zipeng Liu et.al.|[2406.15504v1](http://arxiv.org/abs/2406.15504v1)|null|
|**2024-06-19**|**Enhancing Distractor Generation for Multiple-Choice Questions with Retrieval Augmented Pretraining and Knowledge Graph Integration**|Han-Cheng Yu et.al.|[2406.13578v1](http://arxiv.org/abs/2406.13578v1)|null|

#### Abstracts
##### **Hierarchical Windowed Graph Attention Network and a Large Scale Dataset for Isolated Indian Sign Language Recognition**
2407.14224v1 by Suvajit Patra, Arkadip Maitra, Megha Tiwari, K. Kumaran, Swathy Prabhu, Swami Punyeshwarananda, Soumitra Samanta

Automatic Sign Language (SL) recognition is an important task in the computer
vision community. To build a robust SL recognition system, we need a
considerable amount of data which is lacking particularly in Indian sign
language (ISL). In this paper, we propose a large-scale isolated ISL dataset
and a novel SL recognition model based on skeleton graph structure. The dataset
covers 2,002 daily used common words in the deaf community recorded by 20 (10
male and 10 female) deaf adult signers (contains 40033 videos). We propose a SL
recognition model namely Hierarchical Windowed Graph Attention Network (HWGAT)
by utilizing the human upper body skeleton graph structure. The HWGAT tries to
capture distinctive motions by giving attention to different body parts induced
by the human skeleton graph structure. The utility of the proposed dataset and
the usefulness of our model are evaluated through extensive experiments. We
pre-trained the proposed model on the proposed dataset and fine-tuned it across
different sign language datasets further boosting the performance of 1.10,
0.46, 0.78, and 6.84 percentage points on INCLUDE, LSA64, AUTSL and WLASL
respectively compared to the existing state-of-the-art skeleton-based models.

æè¦ï¼èªåæèª (SL) è­å¥æ¯é»è¦è¦è¦ºç¤¾ç¾¤ä¸­çéè¦ä»»åãè¦å»ºç«å¼·å¥ç SL è­å¥ç³»çµ±ï¼æåéè¦å¤§éçè³æï¼èéå¨å°åº¦æèª (ISL) ä¸­ç¹å¥ç¼ºä¹ãå¨æ¬æä¸­ï¼æåæåºä¸åå¤§è¦æ¨¡çå­¤ç« ISL è³æéï¼ä»¥åä¸ååºæ¼éª¨æ¶åçµæ§çæ°å SL è­å¥æ¨¡åãè©²è³æéæ¶µè 2,002 åè¾åç¤¾ç¾¤ä¸­å¸¸ç¨çæ¥å¸¸å®å­ï¼ç± 20 ä½ (10 ç· 10 å¥³) è¾åæäººæèªèéè£½ï¼åå« 40033 é¨å½±çï¼ãæåæåºä¸å SL è­å¥æ¨¡åï¼å³åå±¤è¦çªåæ³¨æåç¶²è·¯ (HWGAT)ï¼å©ç¨äººé«ä¸åèº«éª¨æ¶åçµæ§ãHWGAT åè©¦éééæ³¨ç±äººé«éª¨æ¶åçµæ§èªå°çä¸åèº«é«é¨ä½ä¾ææç¨ç¹çåä½ãééå»£æ³çå¯¦é©è©ä¼°ææåºçè³æéçæç¨åæåæ¨¡åçæç¨æ§ãæåå¨ææåºçè³æéä¸é è¨ç·´ææåºçæ¨¡åï¼ä¸¦å¨ä¸åçæèªè³æéä¸å¾®èª¿å®ï¼é²ä¸æ­¥æåäº INCLUDEãLSA64ãAUTSL å WLASL ä¸ 1.10ã0.46ã0.78 å 6.84 åç¾åé»çæè½ï¼åå¥èç¾æçæåé²çåºæ¼éª¨æ¶çæ¨¡åç¸æ¯ã

##### **Enhancing Data-Limited Graph Neural Networks by Actively Distilling Knowledge from Large Language Models**
2407.13989v1 by Quan Li, Tianxiang Zhao, Lingwei Chen, Junjie Xu, Suhang Wang

Graphs have emerged as critical data structures for content analysis in
various domains, such as social network analysis, bioinformatics, and
recommendation systems. Node classification, a fundamental task in this
context, is typically tackled using graph neural networks (GNNs).
Unfortunately, conventional GNNs still face challenges in scenarios with few
labeled nodes, despite the prevalence of few-shot node classification tasks in
real-world applications. To address this challenge, various approaches have
been proposed, including graph meta-learning, transfer learning, and methods
based on Large Language Models (LLMs). However, traditional meta-learning and
transfer learning methods often require prior knowledge from base classes or
fail to exploit the potential advantages of unlabeled nodes. Meanwhile,
LLM-based methods may overlook the zero-shot capabilities of LLMs and rely
heavily on the quality of generated contexts. In this paper, we propose a novel
approach that integrates LLMs and GNNs, leveraging the zero-shot inference and
reasoning capabilities of LLMs and employing a Graph-LLM-based active learning
paradigm to enhance GNNs' performance. Extensive experiments demonstrate the
effectiveness of our model in improving node classification accuracy with
considerably limited labeled data, surpassing state-of-the-art baselines by
significant margins.

æè¦ï¼åè¡¨å·²æçºåç¨®é åä¸­å§å®¹åæçééµæ¸æçµæ§ï¼ä¾å¦ç¤¾äº¤ç¶²è·¯åæãçç©è³è¨å­¸åæ¨è¦ç³»çµ±ãç¯é»åé¡æ¯æ­¤èçµ¡ä¸­çåºæ¬ä»»åï¼éå¸¸ä½¿ç¨åå½¢ç¥ç¶ç¶²è·¯ (GNN) ä¾èçãä¸å¹¸çæ¯ï¼åç®¡ç¾å¯¦ä¸çæç¨ä¸­æ®éå­å¨å°æ¨£æ¬ç¯é»åé¡ä»»åï¼ä½å³çµ±ç GNN å¨æ¨è¨ç¯é»å¾å°çææ³ä¸ä»é¢è¨ææ°ãçºäºæå°éä¸ææ°ï¼å·²æåºåç¨®æ¹æ³ï¼åæ¬åå½¢åå­¸ç¿ãé·ç§»å­¸ç¿ååºæ¼å¤§åèªè¨æ¨¡å (LLM) çæ¹æ³ãç¶èï¼å³çµ±çåå­¸ç¿åé·ç§»å­¸ç¿æ¹æ³éå¸¸éè¦ä¾èªåºç¤é¡å¥çåé©ç¥è­ï¼æèç¡æ³å©ç¨æªæ¨è¨ç¯é»çæ½å¨åªå¢ãåæï¼åºæ¼ LLM çæ¹æ³å¯è½æå¿½è¦ LLM çé¶æ¨£æ¬è½åï¼ä¸¦ä¸éåº¦ä¾è³´çæèªå¢çåè³ªãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼å®æ´åäº LLM å GNNï¼å©ç¨ LLM çé¶æ¨£æ¬æ¨è«åæ¨çè½åï¼ä¸¦æ¡ç¨åºæ¼ Graph-LLM çä¸»åå­¸ç¿ç¯ä¾ä¾å¢å¼· GNN çæè½ãå»£æ³çå¯¦é©è­æäºæåçæ¨¡åå¨æ¹é²ç¯é»åé¡æºç¢ºåº¦æ¹é¢çæææ§ï¼æ¨è¨æ¸æç¸ç¶æéï¼é¡¯èè¶è¶äºæåé²çåºæºã

##### **A Comprehensive Review of Recommender Systems: Transitioning from Theory to Practice**
2407.13699v1 by Shaina Raza, Mizanur Rahman, Safiullah Kamawal, Armin Toroghi, Ananya Raval, Farshad Navah, Amirmohammad Kazemeini

Recommender Systems (RS) play an integral role in enhancing user experiences
by providing personalized item suggestions. This survey reviews the progress in
RS inclusively from 2017 to 2024, effectively connecting theoretical advances
with practical applications. We explore the development from traditional RS
techniques like content-based and collaborative filtering to advanced methods
involving deep learning, graph-based models, reinforcement learning, and large
language models. We also discuss specialized systems such as context-aware,
review-based, and fairness-aware RS. The primary goal of this survey is to
bridge theory with practice. It addresses challenges across various sectors,
including e-commerce, healthcare, and finance, emphasizing the need for
scalable, real-time, and trustworthy solutions. Through this survey, we promote
stronger partnerships between academic research and industry practices. The
insights offered by this survey aim to guide industry professionals in
optimizing RS deployment and to inspire future research directions, especially
in addressing emerging technological and societal trends

æè¦ï¼æ¨è¦ç³»çµ± (RS) å¨æåä½¿ç¨èé«é©ä¸­æ®æ¼èä¸å¯æç¼ºçè§è²ï¼ééæä¾åäººåçååå»ºè­°ãéé èª¿æ¥åé¡§äº RS å¨ 2017 å¹´å° 2024 å¹´éçé²å±ï¼ææå°å°çè«é²å±èå¯¦éæç¨é£çµèµ·ä¾ãæåæ¢è¨äºå¾å³çµ±ç RS æè¡ï¼ä¾å¦åºæ¼å§å®¹åååéæ¿¾ï¼å°æ¶åæ·±åº¦å­¸ç¿ãåºæ¼åå½¢çæ¨¡åãå¼·åå­¸ç¿åå¤§èªè¨æ¨¡åç­åé²æ¹æ³çç¼å±ãæåä¹è¨è«äºå°éçç³»çµ±ï¼ä¾å¦æå¢æç¥ãåºæ¼è©è«åå¬å¹³æç¥ç RSãéé èª¿æ¥çä¸»è¦ç®æ¨æ¯å°çè«èå¯¦åçµåèµ·ä¾ãå®è§£æ±ºäºååé åçææ°ï¼åæ¬é»å­ååãé«çä¿å¥åéèï¼å¼·èª¿äºå°å¯æ´åãå³æåå¯ä¿¡è³´çè§£æ±ºæ¹æ¡çéæ±ãéééé èª¿æ¥ï¼æåä¿é²äºå­¸è¡ç ç©¶åç¢æ¥­å¯¦åä¹éæ´å¼·å¤§çå¤¥ä¼´éä¿ãéé èª¿æ¥æä¾çè¦è§£æ¨å¨å¼å°ç¢æ¥­å°æ¥­äººå£«åªå RS é¨ç½²ï¼ä¸¦æ¿åµæªä¾çç ç©¶æ¹åï¼ç¹å¥æ¯å¨è§£æ±ºæ°èçæè¡åç¤¾æè¶¨å¢æ¹é¢ã

##### **Is Sarcasm Detection A Step-by-Step Reasoning Process in Large Language Models?**
2407.12725v1 by Ben Yao, Yazhou Zhang, Qiuchi Li, Jing Qin

Elaborating a series of intermediate reasoning steps significantly improves
the ability of large language models (LLMs) to solve complex problems, as such
steps would evoke LLMs to think sequentially. However, human sarcasm
understanding is often considered an intuitive and holistic cognitive process,
in which various linguistic, contextual, and emotional cues are integrated to
form a comprehensive understanding of the speaker's true intention, which is
argued not be limited to a step-by-step reasoning process. To verify this
argument, we introduce a new prompting framework called SarcasmCue, which
contains four prompting strategies, $viz.$ chain of contradiction (CoC), graph
of cues (GoC), bagging of cues (BoC) and tensor of cues (ToC), which elicits
LLMs to detect human sarcasm by considering sequential and non-sequential
prompting methods. Through a comprehensive empirical comparison on four
benchmarking datasets, we show that the proposed four prompting methods
outperforms standard IO prompting, CoT and ToT with a considerable margin, and
non-sequential prompting generally outperforms sequential prompting.

æè¦ï¼ééé¡è¿°ä¸ç³»åä¸­éæ¨çæ­¥é©ï¼å¤§å¹æåå¤§åèªè¨æ¨¡å (LLM) è§£æ±ºè¤éåé¡çè½åï¼å çºéäºæ­¥é©æä¿ä½¿ LLM æé åºæèãç¶èï¼äººé¡çè«·åºçè§£éå¸¸è¢«èªçºæ¯ä¸ç¨®ç´è¦ºä¸å¨é¢çèªç¥éç¨ï¼å¶ä¸­åç¨®èªè¨ãèªå¢åæç·ç·ç´¢æ´åå¨ä¸èµ·ï¼ä»¥å¨é¢äºè§£èªªè©±èççå¯¦æåï¼éè¢«èªçºä¸åéæ¼å¾ªåºæ¼¸é²çæ¨çéç¨ãçºäºé©è­éåè«é»ï¼æåå¼å¥äºä¸åæ°çæç¤ºæ¡æ¶ï¼ç¨±çº SarcasmCueï¼å¶ä¸­åå«åç¨®æç¤ºç­ç¥ï¼å³çç¾é (CoC)ãç·ç´¢å (GoC)ãç·ç´¢è¢ (BoC) åç·ç´¢å¼µé (ToC)ï¼å®å¼ç¼ LLM ééèæ®é åºåéé åºæç¤ºæ¹æ³ä¾æª¢æ¸¬äººé¡çè«·åºãééå°åååºæºæ¸æéé²è¡å¨é¢çå¯¦è­æ¯è¼ï¼æåè¡¨æææåºçåç¨®æç¤ºæ¹æ³ä»¥ç¸ç¶å¤§çå¹åº¦åªæ¼æ¨æº IO æç¤ºãCoT å ToTï¼ä¸¦ä¸éé åºæç¤ºéå¸¸åªæ¼é åºæç¤ºã

##### **Subgraph-Aware Training of Text-based Methods for Knowledge Graph Completion**
2407.12703v2 by Youmin Ko, Hyemin Yang, Taeuk Kim, Hyunjoon Kim

Fine-tuning pre-trained language models (PLMs) has recently shown a potential
to improve knowledge graph completion (KGC). However, most PLM-based methods
encode only textual information, neglecting various topological structures of
knowledge graphs (KGs). In this paper, we empirically validate the significant
relations between the structural properties of KGs and the performance of the
PLM-based methods. To leverage the structural knowledge, we propose a
Subgraph-Aware Training framework for KGC (SATKGC) that combines (i)
subgraph-aware mini-batching to encourage hard negative sampling, and (ii) a
new contrastive learning method to focus more on harder entities and harder
negative triples in terms of the structural properties. To the best of our
knowledge, this is the first study to comprehensively incorporate the
structural inductive bias of the subgraphs into fine-tuning PLMs. Extensive
experiments on four KGC benchmarks demonstrate the superiority of SATKGC. Our
code is available.

æè¦ï¼å¾®è°é¢åè®­ç»çè¯­è¨æ¨¡å (PLM) æè¿æ¾ç¤ºåºæ¹åç¥è¯å¾è°±å®æ (KGC) çæ½åãç¶èï¼å¤§å¤æ°åºäº PLM çæ¹æ³åªç¼ç ææ¬ä¿¡æ¯ï¼èå¿½ç¥äºç¥è¯å¾è°± (KG) çåç§ææç»æãå¨æ¬æä¸­ï¼æä»¬éè¿å®è¯éªè¯äº KG çç»æå±æ§ä¸åºäº PLM çæ¹æ³çæ§è½ä¹é´çéè¦å³ç³»ãä¸ºäºå©ç¨ç»æç¥è¯ï¼æä»¬æåºäºä¸ä¸ªç¨äº KGC çå­å¾æç¥è®­ç»æ¡æ¶ (SATKGC)ï¼å®ç»åäº (i) å­å¾æç¥çå°æ¹éå¤çä»¥é¼å±å°é¾çè´éæ ·ï¼ä»¥å (ii) ä¸ç§æ°çå¯¹æ¯å­¦ä¹ æ¹æ³ï¼ä»¥å¨ç»æå±æ§æ¹é¢æ´å¤å°å³æ³¨æ´å°é¾çå®ä½åæ´å°é¾çè´ä¸åç»ãæ®æä»¬æç¥ï¼è¿æ¯ç¬¬ä¸é¡¹å°å­å¾çç»æå½çº³åå·®å¨é¢çº³å¥å¾®è° PLM çç ç©¶ãå¨åä¸ª KGC åºåä¸çå¹¿æ³å®éªè¯æäº SATKGC çä¼è¶æ§ãæä»¬çä»£ç å¯ç¨ã

##### **Abstraction Alignment: Comparing Model and Human Conceptual Relationships**
2407.12543v1 by Angie Boggust, Hyemin Bang, Hendrik Strobelt, Arvind Satyanarayan

Abstraction -- the process of generalizing specific examples into broad
reusable patterns -- is central to how people efficiently process and store
information and apply their knowledge to new data. Promisingly, research has
shown that ML models learn representations that span levels of abstraction,
from specific concepts like "bolo tie" and "car tire" to more general concepts
like "CEO" and "model". However, existing techniques analyze these
representations in isolation, treating learned concepts as independent
artifacts rather than an interconnected web of abstraction. As a result,
although we can identify the concepts a model uses to produce its output, it is
difficult to assess if it has learned a human-aligned abstraction of the
concepts that will generalize to new data. To address this gap, we introduce
abstraction alignment, a methodology to measure the agreement between a model's
learned abstraction and the expected human abstraction. We quantify abstraction
alignment by comparing model outputs against a human abstraction graph, such as
linguistic relationships or medical disease hierarchies. In evaluation tasks
interpreting image models, benchmarking language models, and analyzing medical
datasets, abstraction alignment provides a deeper understanding of model
behavior and dataset content, differentiating errors based on their agreement
with human knowledge, expanding the verbosity of current model quality metrics,
and revealing ways to improve existing human abstractions.

æè¦ï¼æ½è±¡åââå°ç¹å®ç¯ä¾æ¦æ¬çºå»£æ³å¯éè¤ä½¿ç¨çæ¨¡å¼çéç¨ââæ¯äººåææèçåå²å­è³è¨ï¼ä¸¦å°å¶ç¥è­æç¨æ¼æ°è³æçæ ¸å¿ãæå¸æçæ¯ï¼ç ç©¶é¡¯ç¤º ML æ¨¡åå­¸ç¿è·¨è¶æ½è±¡å±¤ç´çè¡¨å¾µï¼å¾ãç´°é å¸¶ãåãæ±½è»è¼ªèãç­å·é«æ¦å¿µå°ãå·è¡é·ãåãæ¨¡åãç­æ´ä¸è¬çæ¦å¿µãç¶èï¼ç¾æçæè¡å­¤ç«å°åæéäºè¡¨å¾µï¼å°å­¸ç¿å°çæ¦å¿µè¦çºç¨ç«çç¢ç©ï¼èä¸æ¯æ½è±¡çç¸äºé£çµç¶²è·¯ãå æ­¤ï¼åç®¡æåå¯ä»¥è­å¥æ¨¡åç¨ä¾ç¢çå¶è¼¸åºçæ¦å¿µï¼ä½å¾é£è©ä¼°å®æ¯å¦å­¸ç¿å°æ¦å¿µçäººé¡å°é½æ½è±¡ï¼éäºæ¦å¿µå°æ¦æ¬å°æ°çè³æãçºäºè§£æ±ºéåå·®è·ï¼æåå¼å¥äºæ½è±¡å°é½ï¼ä¸ç¨®è¡¡éæ¨¡åå­¸ç¿çæ½è±¡èé æçæ½è±¡ä¹éä¸è´æ§çæ¹æ³ãæåééå°æ¨¡åè¼¸åºèäººé¡æ½è±¡åå½¢ï¼ä¾å¦èªè¨éä¿æé«çç¾çå±¤ç´çµæ§ï¼é²è¡æ¯è¼ä¾éåæ½è±¡å°é½ãå¨è§£éå½±åæ¨¡åãåºæºèªè¨æ¨¡åååæé«çè³æéçè©ä¼°ä»»åä¸­ï¼æ½è±¡å°é½æä¾äºå°æ¨¡åè¡çºåè³æéå§å®¹æ´æ·±å¥ççè§£ï¼æ ¹æèäººé¡ç¥è­çä¸è´æ§ååé¯èª¤ï¼æ´å±ç¶åæ¨¡ååè³ªææ¨çè©³ç´°ç¨åº¦ï¼ä¸¦æ­ç¤ºæ¹åç¾æäººé¡æ½è±¡çæ¹æ³ã

##### **Struct-X: Enhancing Large Language Models Reasoning with Structured Data**
2407.12522v1 by Xiaoyu Tan, Haoyu Wang, Xihe Qiu, Yuan Cheng, Yinghui Xu, Wei Chu, Yuan Qi

Structured data, rich in logical and relational information, has the
potential to enhance the reasoning abilities of large language models (LLMs).
Still, its integration poses a challenge due to the risk of overwhelming LLMs
with excessive tokens and irrelevant context information. To address this, we
propose Struct-X, a novel framework that operates through five key phases:
``read-model-fill-reflect-reason'' efficiently enabling LLMs to utilize
structured data. It begins by encoding structured data into a topological space
using graph embeddings, followed by filling in missing entity information with
knowledge retrieval modules, and filtering out irrelevant tokens via a
self-supervised module. The final phase involves constructing a topological
network with selected tokens to further reduce the total token length for more
effective LLM inference. Additionally, Struct-X includes an Auxiliary Module
trained to generate prompts, aiding LLMs in analyzing structured data.
Extensive experiments on benchmarks, including the knowledge graph
question-answer task and the long document reading comprehension task, show
that Struct-X notably improves LLM reasoning, demonstrating the effectiveness
of structured data augmentation in improving LLM inference with complex input
context.

æè¦ï¼çµæ§åè³æå¯å«éè¼¯åéä¿è³è¨ï¼ææ½åå¢å¼·å¤§åèªè¨æ¨¡å (LLM) çæ¨çè½åãåç®¡å¦æ­¤ï¼ç±æ¼éå¤ç¬¦èåç¡éèçµ¡è³è¨å¯è½æè® LLM ä¸å ªè² è·ï¼å æ­¤æ´åæ­¤é¡è³ææ§æäºä¸é ææ°ãçºäºè§£æ±ºæ­¤åé¡ï¼æåæåº Struct-Xï¼éæ¯ä¸åééäºåééµéæ®µéä½çæ°ç©æ¶æ§ï¼``è®å-å»ºæ¨¡-å¡«è£-åæ-æ¨ç''ï¼ææå°è® LLM è½å¤ å©ç¨çµæ§åè³æãå®é¦åä½¿ç¨åå½¢åµå¥å°çµæ§åè³æç·¨ç¢¼å°ææ²ç©ºéä¸­ï¼æ¥èå©ç¨ç¥è­æ·åæ¨¡çµå¡«è£éºå¤±çå¯¦é«è³è¨ï¼ä¸¦ééèªæç£ç£æ¨¡çµç¯©é¸åºç¡éç¬¦èãæå¾ä¸åéæ®µæ¶åå»ºæ§ä¸åææ²ç¶²è·¯ï¼å¶ä¸­åå«é¸å®çç¬¦èï¼ä»¥é²ä¸æ­¥æ¸å°ç¸½ç¬¦èé·åº¦ï¼ä»¥ä¾¿æ´ææå°é²è¡ LLM æ¨è«ãæ­¤å¤ï¼Struct-X éåæ¬ä¸åè¼å©æ¨¡çµï¼ç¶éè¨ç·´å¯ä»¥ç¢çæç¤ºï¼åå© LLM åæçµæ§åè³æãå¨åºæºä¸çå¤§éå¯¦é©ï¼åæ¬ç¥è­åè­åç­ä»»ååé·ç¯æä»¶é±è®çè§£ä»»åï¼é¡¯ç¤º Struct-X æé¡¯æ¹åäº LLM æ¨çï¼è­æäºçµæ§åè³ææ´åå¨æ¹å LLM æ¨è«æçæææ§ï¼ç¹å¥æ¯å¨è¼¸å¥èçµ¡è¤éçææ³ä¸ã

##### **Explainable Biomedical Hypothesis Generation via Retrieval Augmented Generation enabled Large Language Models**
2407.12888v1 by Alexander R. Pelletier, Joseph Ramirez, Irsyad Adam, Simha Sankar, Yu Yan, Ding Wang, Dylan Steinecke, Wei Wang, Peipei Ping

The vast amount of biomedical information available today presents a
significant challenge for investigators seeking to digest, process, and
understand these findings effectively. Large Language Models (LLMs) have
emerged as powerful tools to navigate this complex and challenging data
landscape. However, LLMs may lead to hallucinatory responses, making Retrieval
Augmented Generation (RAG) crucial for achieving accurate information. In this
protocol, we present RUGGED (Retrieval Under Graph-Guided Explainable disease
Distinction), a comprehensive workflow designed to support investigators with
knowledge integration and hypothesis generation, identifying validated paths
forward. Relevant biomedical information from publications and knowledge bases
are reviewed, integrated, and extracted via text-mining association analysis
and explainable graph prediction models on disease nodes, forecasting potential
links among drugs and diseases. These analyses, along with biomedical texts,
are integrated into a framework that facilitates user-directed mechanism
elucidation as well as hypothesis exploration through RAG-enabled LLMs. A
clinical use-case demonstrates RUGGED's ability to evaluate and recommend
therapeutics for Arrhythmogenic Cardiomyopathy (ACM) and Dilated Cardiomyopathy
(DCM), analyzing prescribed drugs for molecular interactions and unexplored
uses. The platform minimizes LLM hallucinations, offers actionable insights,
and improves the investigation of novel therapeutics.

æè¦ï¼<paragraph>ç¾ä»å¤§éççç©é«å­¸è³è¨å°è©¦åæææ¶åãèçåçè§£éäºç¼ç¾çç ç©¶äººå¡æ§æéå¤§ææ°ãå¤§åèªè¨æ¨¡å (LLM) å·²æçºå¨éåè¤éä¸å·ææ°æ§çè³æç°å¢ä¸­å°èªçå¼·å¤§å·¥å·ãç¶èï¼LLM å¯è½æå°è´å¹»è¦ºåæï¼éä½¿å¾æª¢ç´¢æ´å¢çæ (RAG) å°æ¼ç²å¾æºç¢ºè³è¨è³ééè¦ãå¨éååå®ä¸­ï¼æåæåº RUGGEDï¼åå½¢å°å¼å¯è§£éç¾çååçæª¢ç´¢ï¼ï¼éæ¯ä¸åå¨é¢çå·¥ä½æµç¨ï¼æ¨å¨æ¯æ´ç ç©¶äººå¡é²è¡ç¥è­æ´åååè¨­ç¢çï¼æ¾åºç¶éé©è­çé²å±è·¯å¾ãä¾èªåºçç©åç¥è­åº«çç¸éçç©é«å­¸è³è¨æééææ¬æ¢åéè¯åæåç¾çç¯é»çå¯è§£éåå½¢é æ¸¬æ¨¡åé²è¡æª¢é±ãæ´ååèåï¼é æ¸¬è¥ç©åç¾çä¹éçæ½å¨éè¯ãéäºåæé£åçç©é«å­¸ææ¬ææ´åå°ä¸åæ¶æ§ä¸­ï¼è©²æ¶æ§ä¿é²ä½¿ç¨èå°åçæ©å¶é¡æï¼ä»¥åéé RAG åç¨ç LLM é²è¡åè¨­æ¢è¨ãä¸åè¨åºä½¿ç¨æ¡ä¾å±ç¤ºäº RUGGED è©ä¼°åæ¨è¦ç¨æ¼å¿å¾å¤±å¸¸æ§å¿èçè® (ACM) åæ´å¼µåå¿èçè® (DCM) çæ²»çæ¹æ³çè½åï¼åæèæ¹è¥ç©çåå­äº¤äºä½ç¨åæªæ¢ç´¢çç¨éãéåå¹³å°å° LLM å¹»è¦ºéå°æä½ï¼æä¾å¯æä½çè¦è§£ï¼ä¸¦æ¹åæ°æ²»çæ¹æ³çç ç©¶ã</paragraph>

##### **A Comprehensive Evaluation of Large Language Models on Temporal Event Forecasting**
2407.11638v1 by He Chang, Chenchen Ye, Zhulin Tao, Jie Wu, Zhengmao Yang, Yunshan Ma, Xianglin Huang, Tat-Seng Chua

Recently, Large Language Models (LLMs) have demonstrated great potential in
various data mining tasks, such as knowledge question answering, mathematical
reasoning, and commonsense reasoning. However, the reasoning capability of LLMs
on temporal event forecasting has been under-explored. To systematically
investigate their abilities in temporal event forecasting, we conduct a
comprehensive evaluation of LLM-based methods for temporal event forecasting.
Due to the lack of a high-quality dataset that involves both graph and textual
data, we first construct a benchmark dataset, named MidEast-TE-mini. Based on
this dataset, we design a series of baseline methods, characterized by various
input formats and retrieval augmented generation(RAG) modules. From extensive
experiments, we find that directly integrating raw texts into the input of LLMs
does not enhance zero-shot extrapolation performance. In contrast,
incorporating raw texts in specific complex events and fine-tuning LLMs
significantly improves performance. Moreover, enhanced with retrieval modules,
LLM can effectively capture temporal relational patterns hidden in historical
events. Meanwhile, issues such as popularity bias and the long-tail problem
still persist in LLMs, particularly in the RAG-based method. These findings not
only deepen our understanding of LLM-based event forecasting methods but also
highlight several promising research directions.We consider that this
comprehensive evaluation, along with the identified research opportunities,
will significantly contribute to future research on temporal event forecasting
through LLMs.

æè¦ï¼è¿æï¼å¤§åè¯­è¨æ¨¡å (LLM) å¨åç§èµææ¢åä»»å¡ä¸­å±ç°åºæå¤§çæ½åï¼ä¾å¦ç¥è¯é®ç­ãæ°å­¦æ¨çåå¸¸è¯æ¨çãç¶èï¼LLM å¨æ¶é´äºä»¶é¢æµæ¹é¢çæ¨çè½åå°æªè¢«ååæ¢ç´¢ãä¸ºäºç³»ç»æ§å°è°æ¥å¶å¨æ¶é´äºä»¶é¢æµæ¹é¢çè½åï¼æä»¬å¯¹åºäº LLM çæ¶é´äºä»¶é¢æµæ¹æ³è¿è¡äºå¨é¢çè¯ä¼°ãç±äºç¼ºä¹åæ¶åå«å¾è¡¨åææ¬èµæçé«åè´¨æ°æ®éï¼æä»¬é¦åæå»ºäºä¸ä¸ªåä¸º MidEast-TE-mini çåºåæ°æ®éãåºäºæ­¤æ°æ®éï¼æä»¬è®¾è®¡äºä¸ç³»ååºçº¿æ¹æ³ï¼å¶ç¹ç¹æ¯åç§è¾å¥æ ¼å¼åæ£ç´¢å¢å¼ºçæ (RAG) æ¨¡åãä»å¹¿æ³çå®éªä¸­ï¼æä»¬åç°ç´æ¥å°åå§ææ¬æ´åå° LLM çè¾å¥ä¸­å¹¶ä¸ä¼å¢å¼ºé¶æ¬¡å­¦ä¹ å¤æ¨æ§è½ãç¸æ¯ä¹ä¸ï¼å¨ç¹å®å¤æäºä»¶ä¸­çº³å¥åå§ææ¬å¹¶å¾®è° LLM ä¼æ¾èæé«æ§è½ãæ­¤å¤ï¼éè¿æ£ç´¢æ¨¡åçå¢å¼ºï¼LLM å¯ä»¥ææå°ææéèå¨åå²äºä»¶ä¸­çæ¶é´å³ç³»æ¨¡å¼ãåæ¶ï¼è¯¸å¦æµè¡åº¦åå·®åé¿å°¾é®é¢ç­é®é¢ä»ç¶å­å¨äº LLM ä¸­ï¼å°¤å¶æ¯å¨åºäº RAG çæ¹æ³ä¸­ãè¿äºåç°ä¸ä»å æ·±äºæä»¬å¯¹åºäº LLM çäºä»¶é¢æµæ¹æ³ççè§£ï¼è¿çªåºäºå ä¸ªæåæ¯çç ç©¶æ¹åãæä»¬è®¤ä¸ºï¼è¿é¡¹å¨é¢çè¯ä¼°ï¼è¿åå·²ç¡®å®çç ç©¶æºä¼ï¼å°æå¤§å°ä¿è¿éè¿ LLM è¿è¡æ¶é´äºä»¶é¢æµçæªæ¥ç ç©¶ã

##### **Learning on Graphs with Large Language Models(LLMs): A Deep Dive into Model Robustness**
2407.12068v1 by Kai Guo, Zewen Liu, Zhikai Chen, Hongzhi Wen, Wei Jin, Jiliang Tang, Yi Chang

Large Language Models (LLMs) have demonstrated remarkable performance across
various natural language processing tasks. Recently, several LLMs-based
pipelines have been developed to enhance learning on graphs with text
attributes, showcasing promising performance. However, graphs are well-known to
be susceptible to adversarial attacks and it remains unclear whether LLMs
exhibit robustness in learning on graphs. To address this gap, our work aims to
explore the potential of LLMs in the context of adversarial attacks on graphs.
Specifically, we investigate the robustness against graph structural and
textual perturbations in terms of two dimensions: LLMs-as-Enhancers and
LLMs-as-Predictors. Through extensive experiments, we find that, compared to
shallow models, both LLMs-as-Enhancers and LLMs-as-Predictors offer superior
robustness against structural and textual attacks.Based on these findings, we
carried out additional analyses to investigate the underlying causes.
Furthermore, we have made our benchmark library openly available to facilitate
quick and fair evaluations, and to encourage ongoing innovative research in
this field.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®èªç¶èªè¨èçä»»åä¸­å±ç¾äºåè¶çæè½ãæè¿ï¼å·²ç¶éç¼äºå¤ååºæ¼ LLM çç®¡éï¼ä»¥å¢å¼·åå½¢ä¸å·ææå­å±¬æ§çå­¸ç¿ï¼å±ç¤ºåºæåæ¯çæè½ãç¶èï¼ç¾æå¨ç¥ï¼åå½¢å®¹æåå°å°ææ§æ»æï¼è LLM å¨åå½¢å­¸ç¿ä¸­æ¯å¦è¡¨ç¾åºç©©å¥æ§ä»ä¸æ¸æ¥ãçºäºè§£æ±ºéåå·®è·ï¼æåçç ç©¶æ¨å¨æ¢ç´¢ LLM å¨åå½¢å°ææ»æä¸­çæ½åãå·é«ä¾èªªï¼æåç ç©¶äºå¨ LLM ä½çºå¢å¼·å¨å LLM ä½çºé æ¸¬å¨çå©åé¢åä¸­ï¼éå°åå½¢çµæ§åæå­æ¾åçç©©å¥æ§ãééå»£æ³çå¯¦é©ï¼æåç¼ç¾ï¼èæ·ºå±¤æ¨¡åç¸æ¯ï¼ä½çºå¢å¼·å¨ç LLM åä½çºé æ¸¬å¨ç LLM é½å°çµæ§åæå­æ»ææä¾äºåªç°çç©©å¥æ§ãåºæ¼éäºç¼ç¾ï¼æåé²è¡äºé¡å¤çåæä¾æ¢è¨å¶æ ¹æ¬åå ãæ­¤å¤ï¼æåå·²ç¶å¬éäºæåçåºæºåº«ï¼ä»¥å©æ¼å¿«éä¸å¬å¹³çè©ä¼°ï¼ä¸¦é¼åµå¨éåé åé²è¡æçºçåµæ°ç ç©¶ã

##### **CIC-BART-SSA: Controllable Image Captioning with Structured Semantic Augmentation**
2407.11393v2 by Kalliopi Basioti, Mohamed A. Abdelsalam, Federico Fancellu, Vladimir Pavlovic, Afsaneh Fazly

Controllable Image Captioning (CIC) aims at generating natural language
descriptions for an image, conditioned on information provided by end users,
e.g., regions, entities or events of interest. However, available
image-language datasets mainly contain captions that describe the entirety of
an image, making them ineffective for training CIC models that can potentially
attend to any subset of regions or relationships. To tackle this challenge, we
propose a novel, fully automatic method to sample additional focused and
visually grounded captions using a unified structured semantic representation
built on top of the existing set of captions associated with an image. We
leverage Abstract Meaning Representation (AMR), a cross-lingual graph-based
semantic formalism, to encode all possible spatio-semantic relations between
entities, beyond the typical spatial-relations-only focus of current methods.
We use this Structured Semantic Augmentation (SSA) framework to augment
existing image-caption datasets with the grounded controlled captions,
increasing their spatial and semantic diversity and focal coverage. We then
develop a new model, CIC-BART-SSA, specifically tailored for the CIC task, that
sources its control signals from SSA-diversified datasets. We empirically show
that, compared to SOTA CIC models, CIC-BART-SSA generates captions that are
superior in diversity and text quality, are competitive in controllability,
and, importantly, minimize the gap between broad and highly focused controlled
captioning performance by efficiently generalizing to the challenging highly
focused scenarios. Code is available at
https://github.com/SamsungLabs/CIC-BART-SSA.

æè¦ï¼å¯æ§å¾åæ æ³¨ (CIC) æ¨å¨çæèªç¶è¯­è¨æè¿°ä»¥æè¿°å¾åï¼æ¡ä»¶æ¯æ ¹æ®æç»ç¨æ·æä¾çèµè®¯ï¼ä¾å¦åºåãå®ä½ææå´è¶£çäºä»¶ãç¶èï¼ç°æçå¾åè¯­è¨æ°æ®éä¸»è¦åå«æè¿°æ´ä¸ªå¾åçæ æ³¨ï¼ä½¿å¶æ æ³ææè®­ç» CIC æ¨¡åï¼èè¿äºæ¨¡åæå¯è½å³æ³¨ä»»ä½åºåæå³ç³»çå­éãä¸ºäºåºå¯¹è¿ä¸ææï¼æä»¬æåºäºä¸ç§æ°é¢çãå¨èªå¨çæ¹æ³ï¼ä½¿ç¨å»ºç«å¨ä¸å¾åå³èçç°ææ æ³¨éä¹ä¸çç»ä¸ç»æåè¯­ä¹è¡¨ç¤ºæ¥æ½æ ·å¶ä»èç¦ä¸è§è§æ¥å°çæ æ³¨ãæä»¬å©ç¨è·¨è¯­è¨å¾å¼è¯­ä¹å½¢å¼åæ½è±¡æä¹è¡¨ç¤º (AMR) æ¥ç¼ç å®ä½ä¹é´ææå¯è½çç©ºé´è¯­ä¹å³ç³»ï¼èä¸ä»ä»æ¯å½åæ¹æ³ä¸­ä»å³æ³¨çç©ºé´å³ç³»ãæä»¬ä½¿ç¨è¿ç§ç»æåè¯­ä¹å¢å¼º (SSA) æ¡æ¶æ¥å¢å¼ºç°æçå¾åæ æ³¨æ°æ®éï¼ä½¿å¶æ¥å°ä¸å¯æ§çæ æ³¨ï¼å¢å å®ä»¬çç©ºé´åè¯­ä¹å¤æ ·æ§ä»¥åç¦ç¹è¦çèå´ãç¶åï¼æä»¬å¼åäºä¸ä¸ªæ°æ¨¡å CIC-BART-SSAï¼ä¸é¨éå¯¹ CIC ä»»å¡éèº«å®å¶ï¼å¶æ§å¶ä¿¡å·æ¥èª SSA å¤æ ·åçæ°æ®éãæä»¬å­ç»éªè¡¨æï¼ä¸ SOTA CIC æ¨¡åç¸æ¯ï¼CIC-BART-SSA çæçæ æ³¨å¨å¤æ ·æ§åææ¬è´¨éæ¹é¢æ´èä¸ç­¹ï¼å¨å¯æ§æ§æ¹é¢å·æç«äºåï¼èä¸éè¦çæ¯ï¼éè¿ææå°æ¨å¹¿å°å·ææææ§çé«åº¦èç¦åºæ¯ï¼æå¤§éåº¦å°ç¼©å°äºå¹¿æ³åé«åº¦èç¦çåæ§æ æ³¨æ§è½ä¹é´çå·®è·ãä»£ç å¯ä» https://github.com/SamsungLabs/CIC-BART-SSA è·å¾ã

##### **Think-on-Graph 2.0: Deep and Interpretable Large Language Model Reasoning with Knowledge Graph-guided Retrieval**
2407.10805v1 by Shengjie Ma, Chengjin Xu, Xuhui Jiang, Muzhi Li, Huaren Qu, Jian Guo

Retrieval-augmented generation (RAG) has significantly advanced large
language models (LLMs) by enabling dynamic information retrieval to mitigate
knowledge gaps and hallucinations in generated content. However, these systems
often falter with complex reasoning and consistency across diverse queries. In
this work, we present Think-on-Graph 2.0, an enhanced RAG framework that aligns
questions with the knowledge graph and uses it as a navigational tool, which
deepens and refines the RAG paradigm for information collection and
integration. The KG-guided navigation fosters deep and long-range associations
to uphold logical consistency and optimize the scope of retrieval for precision
and interoperability. In conjunction, factual consistency can be better ensured
through semantic similarity guided by precise directives. ToG${2.0}$ not only
improves the accuracy and reliability of LLMs' responses but also demonstrates
the potential of hybrid structured knowledge systems to significantly advance
LLM reasoning, aligning it closer to human-like performance. We conducted
extensive experiments on four public datasets to demonstrate the advantages of
our method compared to the baseline.

æè¦ï¼æª¢ç´¢å¢å¼·çæï¼RAGï¼ééåç¨åæè³è¨æª¢ç´¢ä¾æ¸è¼çæå§å®¹ä¸­çç¥è­å·®è·åå¹»è¦ºï¼å¤§å¹æåå¤§åèªè¨æ¨¡åï¼LLMï¼ãç¶èï¼éäºç³»çµ±å¨è¤éæ¨çåè·¨ä¸åæ¥è©¢çä¸è´æ§æ¹é¢å¸¸å¸¸è¡¨ç¾ä¸ä½³ãå¨éé å·¥ä½ä¸­ï¼æåæåºäº Think-on-Graph 2.0ï¼ä¸åå¢å¼·ç RAG æ¡æ¶ï¼å®å°åé¡èç¥è­åè­å°é½ï¼ä¸¦å°å¶ç¨ä½å°èªå·¥å·ï¼éå æ·±ä¸¦æ¹é²äº RAG å¸ç¯ï¼ç¨æ¼è³è¨æ¶éåæ´åãåç¥è­åè­å¼å°çå°èªä¿é²äºæ·±å±¤ä¸é·ç¨çéè¯ï¼ä»¥ç¶­æéè¼¯ä¸è´æ§ä¸¦æä½³åæª¢ç´¢ç¯åï¼ä»¥æé«ç²¾ç¢ºåº¦åäºæä½æ§ãåæï¼äºå¯¦ä¸è´æ§å¯ä»¥ééç±ç²¾ç¢ºæç¤ºå¼å°çèªæç¸ä¼¼æ§ç²å¾æ´å¥½çç¢ºä¿ãToG${2.0}$ ä¸åæåäº LLM åæçæºç¢ºæ§åå¯é æ§ï¼ä¹å±ç¤ºäºæ··åçµæ§åç¥è­ç³»çµ±çæ½åï¼å¯ä»¥å¤§å¹æå LLM æ¨çï¼ä½¿å¶æ´æ¥è¿äººé¡è¬çè¡¨ç¾ãæåå¨ååå¬éè³æéä¸é²è¡äºå»£æ³çå¯¦é©ï¼ä»¥å±ç¤ºæåçæ¹æ³ç¸è¼æ¼åºç·çåªå¢ã

##### **Graphusion: Leveraging Large Language Models for Scientific Knowledge Graph Fusion and Construction in NLP Education**
2407.10794v1 by Rui Yang, Boming Yang, Sixun Ouyang, Tianwei She, Aosong Feng, Yuang Jiang, Freddy Lecue, Jinghui Lu, Irene Li

Knowledge graphs (KGs) are crucial in the field of artificial intelligence
and are widely applied in downstream tasks, such as enhancing Question
Answering (QA) systems. The construction of KGs typically requires significant
effort from domain experts. Recently, Large Language Models (LLMs) have been
used for knowledge graph construction (KGC), however, most existing approaches
focus on a local perspective, extracting knowledge triplets from individual
sentences or documents. In this work, we introduce Graphusion, a zero-shot KGC
framework from free text. The core fusion module provides a global view of
triplets, incorporating entity merging, conflict resolution, and novel triplet
discovery. We showcase how Graphusion could be applied to the natural language
processing (NLP) domain and validate it in the educational scenario.
Specifically, we introduce TutorQA, a new expert-verified benchmark for graph
reasoning and QA, comprising six tasks and a total of 1,200 QA pairs. Our
evaluation demonstrates that Graphusion surpasses supervised baselines by up to
10% in accuracy on link prediction. Additionally, it achieves average scores of
2.92 and 2.37 out of 3 in human evaluations for concept entity extraction and
relation recognition, respectively.

æè¦ï¼<paragraph>ç¥è­åè­ (KG) å¨äººå·¥æºæ§é åè³ééè¦ï¼ä¸¦å»£æ³æç¨æ¼ä¸æ¸¸ä»»åï¼ä¾å¦å¢å¼·åç­ (QA) ç³»çµ±ãç¥è­åè­çå»ºæ§éå¸¸éè¦é åå°å®¶çå¤§éå·¥ä½ãæè¿ï¼å¤§åèªè¨æ¨¡å (LLM) å·²è¢«ç¨æ¼ç¥è­åè­å»ºæ§ (KGC)ï¼ç¶èï¼ç¾ææ¹æ³å¤§å¤éæ³¨å±é¨è§é»ï¼å¾åå¥å¥å­ææä»¶ä¸­æåç¥è­ä¸åçµãå¨éé å·¥ä½ä¸­ï¼æåä»ç´¹äº Graphusionï¼ä¸åå¾èªç±ææ¬ä¸­é²è¡é¶æ¬¡å­¸ç¿ç KGC æ¡æ¶ãæ ¸å¿èåæ¨¡çµæä¾ä¸åçµçå¨å±è§é»ï¼åå«å¯¦é«åä½µãè¡çªè§£æ±ºåæ°ä¸åçµç¼ç¾ãæåå±ç¤ºäºå¦ä½å° Graphusion æç¨æ¼èªç¶èªè¨èç (NLP) é åï¼ä¸¦å¨æè²å ´æ¯ä¸­é©è­å®ãå·é«ä¾èªªï¼æåä»ç´¹äº TutorQAï¼ä¸åæ°çç±å°å®¶é©è­çåè­æ¨çååç­åºæºï¼åå«å­é ä»»ååç¸½è¨ 1,200 ååç­å°ãæåçè©ä¼°è¡¨æï¼Graphusion å¨é£çµé æ¸¬çæºç¢ºåº¦ä¸æ¯ç£ç£å¼åºæºé«åº 10%ãæ­¤å¤ï¼å¨æ¦å¿µå¯¦é«æååéä¿è­å¥çäººé¡è©ä¼°ä¸­ï¼å®åå¥ç²å¾äº 3 åä¸­ç 2.92 åå 2.37 åã</paragraph>

##### **GraphEval: A Knowledge-Graph Based LLM Hallucination Evaluation Framework**
2407.10793v1 by Hannah Sansford, Nicholas Richardson, Hermina Petric Maretic, Juba Nait Saada

Methods to evaluate Large Language Model (LLM) responses and detect
inconsistencies, also known as hallucinations, with respect to the provided
knowledge, are becoming increasingly important for LLM applications. Current
metrics fall short in their ability to provide explainable decisions,
systematically check all pieces of information in the response, and are often
too computationally expensive to be used in practice. We present GraphEval: a
hallucination evaluation framework based on representing information in
Knowledge Graph (KG) structures. Our method identifies the specific triples in
the KG that are prone to hallucinations and hence provides more insight into
where in the response a hallucination has occurred, if at all, than previous
methods. Furthermore, using our approach in conjunction with state-of-the-art
natural language inference (NLI) models leads to an improvement in balanced
accuracy on various hallucination benchmarks, compared to using the raw NLI
models. Lastly, we explore the use of GraphEval for hallucination correction by
leveraging the structure of the KG, a method we name GraphCorrect, and
demonstrate that the majority of hallucinations can indeed be rectified.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) åæè©ä¼°æ¹æ³åä¸ä¸è´æ§åµæ¸¬ï¼åç¨±çºå¹»è¦ºï¼ï¼ç¸å°æ¼ææä¾çç¥è­ï¼å°æ¼ LLM æç¨æ­£è®å¾è¶ä¾è¶éè¦ãç®åçææ¨ç¡æ³æä¾å¯è§£éçæ±ºç­ãç³»çµ±æ§å°æª¢æ¥åæä¸­çææè³è¨ï¼èä¸å¨å¯¦åä¸ä½¿ç¨æï¼éå¸¸éæ¼èè²»éç®è³æºãæåæåº GraphEvalï¼ä¸ååºæ¼ç¥è­å (KG) çµæ§ä¾è¡¨ç¤ºè³è¨çå¹»è¦ºè©ä¼°æ¶æ§ãæåçæè¡è­å¥åºå®¹æåºç¾å¹»è¦ºç KG ä¸­ç¹å®ä¸åçµï¼å æ­¤æ¯ä»¥å¾çæ¹æ³æ´æ·±å¥å°äºè§£åæä¸­å¹»è¦ºç¼çå¨åªè£¡ï¼å¦ææçè©±ï¼ãæ­¤å¤ï¼å°æåçæ¹æ³èæåé²çèªç¶èªè¨æ¨è« (NLI) æ¨¡åçµåä½¿ç¨ï¼èä½¿ç¨åå§ NLI æ¨¡åç¸æ¯ï¼å¯ä»¥å¨åç¨®å¹»è¦ºåºæºä¸æé«å¹³è¡¡æºç¢ºåº¦ãæå¾ï¼æåæ¢ç´¢ä½¿ç¨ GraphEval ä¾é²è¡å¹»è¦ºä¿®æ­£ï¼æ¹æ³æ¯å©ç¨ KG ççµæ§ï¼æåå°æ­¤æ¹æ³å½åçº GraphCorrectï¼ä¸¦è­æå¤§å¤æ¸å¹»è¦ºç¢ºå¯¦å¯ä»¥å¾å°ç³¾æ­£ã

##### **Scaling 3D Reasoning with LMMs to Large Robot Mission Environments Using Datagraphs**
2407.10743v1 by W. J. Meijer, A. C. Kemmeren, E. H. J. Riemens, J. E. Fransman, M. van Bekkum, G. J. Burghouts, J. D. van Mil

This paper addresses the challenge of scaling Large Multimodal Models (LMMs)
to expansive 3D environments. Solving this open problem is especially relevant
for robot deployment in many first-responder scenarios, such as
search-and-rescue missions that cover vast spaces. The use of LMMs in these
settings is currently hampered by the strict context windows that limit the
LMM's input size. We therefore introduce a novel approach that utilizes a
datagraph structure, which allows the LMM to iteratively query smaller sections
of a large environment. Using the datagraph in conjunction with graph traversal
algorithms, we can prioritize the most relevant locations to the query, thereby
improving the scalability of 3D scene language tasks. We illustrate the
datagraph using 3D scenes, but these can be easily substituted by other dense
modalities that represent the environment, such as pointclouds or Gaussian
splats. We demonstrate the potential to use the datagraph for two 3D scene
language task use cases, in a search-and-rescue mission example.

æè¦ï¼æ¬æè¨è«äºå°å¤§åå¤æ¨¡ææ¨¡å (LMM) æ´å±å°å»£é 3D ç°å¢çææ°ãè§£æ±ºéåéæ¾æ§åé¡å°æ¼æ©å¨äººå¨è¨±å¤ç¬¬ä¸åæäººå¡å ´æ¯ä¸­çé¨ç½²ç¹å¥ç¸éï¼ä¾å¦æ¶µèå»£éç©ºéçææä»»åãéäºè¨­å®ä¸­ä½¿ç¨ LMM ç®ååå°å´æ ¼çä¸ä¸æè¦çªéå¶ï¼ééå¶äº LMM çè¼¸å¥å¤§å°ãå æ­¤ï¼æåå¼å¥äºä¸ç¨®æ°ç©çæ¹æ³ï¼è©²æ¹æ³å©ç¨è³æåçµæ§ï¼åè¨± LMM è¿­ä»£æ¥è©¢å¤§åç°å¢çè¼å°é¨åãééå°è³æåèåå½¢éæ­·æ¼ç®æ³çµåä½¿ç¨ï¼æåå¯ä»¥åªåèæ®èæ¥è©¢æç¸éçä½ç½®ï¼å¾èæé« 3D å ´æ¯èªè¨ä»»åçå¯æ´åæ§ãæåä½¿ç¨ 3D å ´æ¯èªªæè³æåï¼ä½éäºå ´æ¯å¯ä»¥è¼é¬å°ç±å¶ä»è¡¨ç¤ºç°å¢çå¯éæ¨¡å¼åä»£ï¼ä¾å¦é»é²æé«æ¯é»ãæåå±ç¤ºäºå¨ææä»»åç¯ä¾ä¸­ä½¿ç¨è³æåé²è¡å©å 3D å ´æ¯èªè¨ä»»åç¨ä¾çæ½åã

##### **AutoGRAMS: Autonomous Graphical Agent Modeling Software**
2407.10049v1 by Ben Krause, Lucia Chen, Emmanuel Kahembwe

We introduce the AutoGRAMS framework for programming multi-step interactions
with language models. AutoGRAMS represents AI agents as a graph, where each
node can execute either a language modeling instruction or traditional code.
Likewise, transitions in the graph can be governed by either language modeling
decisions or traditional branch logic. AutoGRAMS supports using variables as
memory and allows nodes to call other AutoGRAMS graphs as functions. We show
how AutoGRAMS can be used to design highly sophisticated agents, including
self-referential agents that can modify their own graph. AutoGRAMS's
graph-centric approach aids interpretability, controllability, and safety
during the design, development, and deployment of AI agents. We provide our
framework as open source at https://github.com/autograms/autograms .

æè¦ï¼æåä»ç´¹ AutoGRAMS æ¡æ¶ï¼ç¨æ¼ç·¨å¯«èèªè¨æ¨¡åçå¤æ­¥é©äºåãAutoGRAMS å° AI ä»£çè¡¨ç¤ºçºä¸ååå½¢ï¼å¶ä¸­æ¯åç¯é»å¯ä»¥å·è¡èªè¨å»ºæ¨¡æä»¤æå³çµ±ä»£ç¢¼ãåæ¨£å°ï¼åå½¢ä¸­çè½æå¯ä»¥ç±èªè¨å»ºæ¨¡æ±ºç­æå³çµ±åæ¯éè¼¯æ§å¶ãAutoGRAMS æ¯æ´ä½¿ç¨è®æ¸ä½çºè¨æ¶é«ï¼ä¸¦åè¨±ç¯é»å¼å«å¶ä» AutoGRAMS åå½¢ä½çºå½å¼ãæåå±ç¤ºå¦ä½ä½¿ç¨ AutoGRAMS è¨­è¨é«åº¦è¤éçä»£çï¼åæ¬å¯ä»¥ä¿®æ¹èªèº«åå½¢çèªåç§ä»£çãAutoGRAMS ä»¥åå½¢çºä¸­å¿çæ¹æ³æå©æ¼å¨ AI ä»£ççè¨­è¨ãéç¼åé¨ç½²éç¨ä¸­æé«å¯è§£éæ§ãå¯æ§æ§åå®å¨æ§ãæåå¨ https://github.com/autograms/autograms æä¾æåçæ¡æ¶ä½çºéæºã

##### **FarFetched: Entity-centric Reasoning and Claim Validation for the Greek Language based on Textually Represented Environments**
2407.09888v1 by Dimitris Papadopoulos, Katerina Metropoulou, Nikolaos Matsatsinis, Nikolaos Papadakis

Our collective attention span is shortened by the flood of online
information. With \textit{FarFetched}, we address the need for automated claim
validation based on the aggregated evidence derived from multiple online news
sources. We introduce an entity-centric reasoning framework in which latent
connections between events, actions, or statements are revealed via entity
mentions and represented in a graph database. Using entity linking and semantic
similarity, we offer a way for collecting and combining information from
diverse sources in order to generate evidence relevant to the user's claim.
Then, we leverage textual entailment recognition to quantitatively determine
whether this assertion is credible, based on the created evidence. Our approach
tries to fill the gap in automated claim validation for less-resourced
languages and is showcased on the Greek language, complemented by the training
of relevant semantic textual similarity (STS) and natural language inference
(NLI) models that are evaluated on translated versions of common benchmarks.

æè¦ï¼ç¶²è·¯è³è¨çæ´ªæµç¸®ç­äºæåçéé«æ³¨æåæéãéé \textit{FarFetched}ï¼æåè§£æ±ºäºæ ¹æå¾å¤åç·ä¸æ°èä¾æºå½ç¸½çè­æé²è¡èªååè²æé©è­çéæ±ãæåå¼å¥äºä¸åä»¥å¯¦é«çºä¸­å¿çæ¨çæ¡æ¶ï¼å¶ä¸­äºä»¶ãåä½æé³è¿°ä¹éçæ½å¨éè¯ééå¯¦é«æåè¢«æ­é²ï¼ä¸¦å¨åå½¢è³æåº«ä¸­è¡¨ç¤ºãä½¿ç¨å¯¦é«é£çµåèªç¾©ç¸ä¼¼æ§ï¼æåæä¾ä¸ç¨®æ¹å¼ä¾æ¶éåçµåä¾èªä¸åä¾æºçè³è¨ï¼ä»¥ç¢çèä½¿ç¨èè²æç¸éçè­æãç¶å¾ï¼æåå©ç¨ææ¬èæ¶µè­å¥ä¾æ ¹æå»ºç«çè­æéåç¢ºå®æ­¤æ·è¨æ¯å¦å¯ä¿¡ãæåçåæ³è©¦åå¡«è£è³æºè¼å°çèªè¨çèªååè²æé©è­æ¹é¢çç©ºç½ï¼ä¸¦å¨å¸èèªä¸­å±ç¤ºï¼è¼ä»¥å°ç¸éèªç¾©ææ¬ç¸ä¼¼æ§ (STS) åèªç¶èªè¨æ¨è« (NLI) æ¨¡åçè¨ç·´ï¼éäºæ¨¡åå¨å¸¸è¦åºæºçç¿»è­¯çæ¬ä¸é²è¡è©ä¼°ã

##### **GOFA: A Generative One-For-All Model for Joint Graph Language Modeling**
2407.09709v1 by Lecheng Kong, Jiarui Feng, Hao Liu, Chengsong Huang, Jiaxin Huang, Yixin Chen, Muhan Zhang

Foundation models, such as Large Language Models (LLMs) or Large Vision
Models (LVMs), have emerged as one of the most powerful tools in the respective
fields. However, unlike text and image data, graph data do not have a
definitive structure, posing great challenges to developing a Graph Foundation
Model (GFM). For example, current attempts at designing general graph models
either transform graph data into a language format for LLM-based prediction or
still train a GNN model with LLM as an assistant. The former can handle
unlimited tasks, while the latter captures graph structure much better -- yet,
no existing work can achieve both simultaneously. In this paper, we identify
three key desirable properties of a GFM: self-supervised pretraining, fluidity
in tasks, and graph awareness. To account for these properties, we extend the
conventional language modeling to the graph domain and propose a novel
generative graph language model GOFA to solve the problem. The model
interleaves randomly initialized GNN layers into a frozen pre-trained LLM so
that the semantic and structural modeling abilities are organically combined.
GOFA is pre-trained on newly proposed graph-level next-word prediction,
question-answering, and structural tasks to obtain the above GFM properties.
The pre-trained model is further fine-tuned on downstream tasks to obtain
task-solving ability. The fine-tuned model is evaluated on various downstream
tasks, demonstrating a strong ability to solve structural and contextual
problems in zero-shot scenarios. The code is available at
https://github.com/JiaruiFeng/GOFA.

æè¦ï¼åºç¤æ¨¡åï¼ä¾å¦å¤§åèªè¨æ¨¡å (LLM) æå¤§åè¦è¦ºæ¨¡å (LVM)ï¼å·²æçºåèªé åä¸­ææåçå·¥å·ä¹ä¸ãç¶èï¼èææ¬åå½±åè³æä¸åï¼åå½¢è³ææ²ææç¢ºççµæ§ï¼å°éç¼åå½¢åºç¤æ¨¡å (GFM) æ§ææ¥µå¤§çææ°ãä¾å¦ï¼ç®åè¨­è¨éç¨åå½¢æ¨¡åçåè©¦ï¼ä¸æ¯å°åå½¢è³æè½æçºèªè¨æ ¼å¼ä»¥ä¾åºæ¼ LLM çé æ¸¬ï¼å°±æ¯è¨ç·´ GNN æ¨¡åï¼ä¸¦ä»¥ LLM ä½çºè¼å©ãåèå¯ä»¥èçç¡éçä»»åï¼èå¾èå¯ä»¥æ´å¥½å°æ·ååå½¢çµæ§ï¼ä½ç¾æçå·¥ä½ç¡æ³åæéæéå©èãå¨æ¬æä¸­ï¼æåæ¾åº GFM çä¸åééµçæ³ç¹æ§ï¼èªæç£ç£é è¨ç·´ãä»»åæµæ¢åº¦ååå½¢æç¥ãçºäºèééäºç¹æ§ï¼æåå°å³çµ±çèªè¨å»ºæ¨¡æ´åå°åå½¢é åï¼ä¸¦æåºä¸åæ°ç©ççæå¼åå½¢èªè¨æ¨¡å GOFA ä¾è§£æ±ºåé¡ãæ­¤æ¨¡åå°é¨æ©åå§åç GNN å±¤äº¤é¯æå¥åçµçé è¨ç·´ LLM ä¸­ï¼ä»¥ä¾¿èªæåçµæ§å»ºæ¨¡è½åææ©çµåãGOFA æ¡ç¨æ°æåºçåå½¢å±¤ç´ä¸ä¸åå­é æ¸¬ãåç­åçµæ§ä»»åé²è¡é è¨ç·´ï¼ä»¥åå¾ä¸è¿° GFM ç¹æ§ãé è¨ç·´æ¨¡åé²ä¸æ­¥å¨ä¸æ¸¸ä»»åä¸é²è¡å¾®èª¿ï¼ä»¥åå¾è§£æ±ºä»»åçè½åãå¾®èª¿æ¨¡åå¨åç¨®ä¸æ¸¸ä»»åä¸é²è¡è©ä¼°ï¼è­æäºå¨é¶æ¬¡å­¸ç¿å ´æ¯ä¸­è§£æ±ºçµæ§åä¸ä¸æåé¡çå¼·å¤§è½åãç¨å¼ç¢¼å¯å¨ https://github.com/JiaruiFeng/GOFA åå¾ã

##### **Human-like Episodic Memory for Infinite Context LLMs**
2407.09450v1 by Zafeirios Fountas, Martin A Benfeghoul, Adnan Oomerjee, Fenia Christopoulou, Gerasimos Lampouras, Haitham Bou-Ammar, Jun Wang

Large language models (LLMs) have shown remarkable capabilities, but still
struggle with processing extensive contexts, limiting their ability to maintain
coherence and accuracy over long sequences. In contrast, the human brain excels
at organising and retrieving episodic experiences across vast temporal scales,
spanning a lifetime. In this work, we introduce EM-LLM, a novel approach that
integrates key aspects of human episodic memory and event cognition into LLMs,
enabling them to effectively handle practically infinite context lengths while
maintaining computational efficiency. EM-LLM organises sequences of tokens into
coherent episodic events using a combination of Bayesian surprise and
graph-theoretic boundary refinement in an on-line fashion. When needed, these
events are retrieved through a two-stage memory process, combining
similarity-based and temporally contiguous retrieval for efficient and
human-like access to relevant information. Experiments on the LongBench dataset
demonstrate EM-LLM's superior performance, outperforming the state-of-the-art
InfLLM model with an overall relative improvement of 4.3% across various tasks,
including a 33% improvement on the PassageRetrieval task. Furthermore, our
analysis reveals strong correlations between EM-LLM's event segmentation and
human-perceived events, suggesting a bridge between this artificial system and
its biological counterpart. This work not only advances LLM capabilities in
processing extended contexts but also provides a computational framework for
exploring human memory mechanisms, opening new avenues for interdisciplinary
research in AI and cognitive science.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾åºéå¡çè½åï¼ä½ä»é£ä»¥èçå»£æ³çèçµ¡ï¼ééå¶äºå®åå¨é·åºåä¸­ç¶­æé£è²«æ§åæºç¢ºæ§çè½åãç¸è¼ä¹ä¸ï¼äººè¦æé·å¨å»£å¤§çæéå°ºåº¦ä¸çµç¹åæåæç¯é«é©ï¼è·¨è¶ä¸çãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äº EM-LLMï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼å®å°äººé¡æç¯è¨æ¶åäºä»¶èªç¥çééµé¢åæ´åå° LLM ä¸­ï¼è®å®åè½å¤ ææå°èçå¯¦éä¸ç¡éçèçµ¡é·åº¦ï¼åæç¶­æéç®æçãEM-LLM ä½¿ç¨è²æ°é©åååè«éçç²¾çççµåï¼ä»¥ç·ä¸æ¹å¼å°åºåæ¨è¨çµç¹æé£è²«çæç¯äºä»¶ãå¨éè¦æï¼éäºäºä»¶æééå©éæ®µçè¨æ¶éç¨ä¾æåï¼çµååºæ¼ç¸ä¼¼æ§åæéé£çºæ§çæåï¼ä»¥ææä¸é¡ä¼¼äººé¡çæ¹å¼å­åç¸éè³è¨ãå¨ LongBench è³æéä¸çå¯¦é©è­æäº EM-LLM çåè¶æè½ï¼å¨åç¨®ä»»åä¸­åªæ¼æåé²ç InfLLM æ¨¡åï¼å¨ PassageRetrieval ä»»åä¸­æ¹é²äº 33%ãæ­¤å¤ï¼æåçåææ­ç¤ºäº EM-LLM çäºä»¶åå²èäººé¡æç¥äºä»¶ä¹éçå¼·ç¸éæ§ï¼é¡¯ç¤ºäºéåäººå·¥ç³»çµ±èå¶çç©å°æç©ä¹éçæ©æ¨ãéé å·¥ä½ä¸åæåäº LLM å¨èçå»¶ä¼¸èçµ¡æ¹é¢çè½åï¼ä¹æä¾äºä¸åéç®æ¶æ§ä¾æ¢ç´¢äººé¡è¨æ¶æ©å¶ï¼çº AI åèªç¥ç§å­¸çè·¨é åç ç©¶éåäºæ°çéå¾ã

##### **The $Î¼\mathcal{G}$ Language for Programming Graph Neural Networks**
2407.09441v1 by Matteo Belenchia, Flavio Corradini, Michela Quadrini, Michele Loreti

Graph neural networks form a class of deep learning architectures
specifically designed to work with graph-structured data. As such, they share
the inherent limitations and problems of deep learning, especially regarding
the issues of explainability and trustworthiness. We propose $\mu\mathcal{G}$,
an original domain-specific language for the specification of graph neural
networks that aims to overcome these issues. The language's syntax is
introduced, and its meaning is rigorously defined by a denotational semantics.
An equivalent characterization in the form of an operational semantics is also
provided and, together with a type system, is used to prove the type soundness
of $\mu\mathcal{G}$. We show how $\mu\mathcal{G}$ programs can be represented
in a more user-friendly graphical visualization, and provide examples of its
generality by showing how it can be used to define some of the most popular
graph neural network models, or to develop any custom graph processing
application.

æè¦ï¼åå½¢ç¥ç¶ç¶²è·¯å½¢æä¸é¡æ·±åº¦å­¸ç¿æ¶æ§ï¼ç¹å¥è¨­è¨ç¨æ¼èçåå½¢çµæ§åçè³æãå æ­¤ï¼å®åå·ææ·±åº¦å­¸ç¿åºæçéå¶ååé¡ï¼ç¹å¥æ¯å¨å¯è§£éæ§åå¯ä¿¡è³´æ§åé¡ä¸ãæåæåº $\mu\mathcal{G}$ï¼ä¸ç¨®ç¨æ¼æå®åå½¢ç¥ç¶ç¶²è·¯çååµé åç¹å®èªè¨ï¼æ¨å¨åæéäºåé¡ãå¼å¥äºèªè¨çèªæ³ï¼ä¸¦ééæç¤ºèªç¾©å´æ ¼å®ç¾©å¶å«ç¾©ãéæä¾äºéç®èªç¾©å½¢å¼çç­æç¹å¾µæè¿°ï¼ä¸¦èé¡åç³»çµ±ä¸èµ·ç¨æ¼è­æ $\mu\mathcal{G}$ çé¡åå¥å¨æ§ãæåå±ç¤ºäºå¦ä½å° $\mu\mathcal{G}$ ç¨å¼è¡¨ç¤ºçºæ´ååçåå½¢è¦è¦ºåï¼ä¸¦ééå±ç¤ºå¦ä½ä½¿ç¨å®å®ç¾©ä¸äºææµè¡çåå½¢ç¥ç¶ç¶²è·¯æ¨¡åæéç¼ä»»ä½èªè¨åå½¢èçæç¨ç¨å¼ï¼ä¾æä¾å¶éç¨æ§çç¯ä¾ã

##### **Towards More Trustworthy and Interpretable LLMs for Code through Syntax-Grounded Explanations**
2407.08983v1 by David N. Palacio, Daniel Rodriguez-Cardenas, Alejandro Velasco, Dipin Khati, Kevin Moran, Denys Poshyvanyk

Trustworthiness and interpretability are inextricably linked concepts for
LLMs. The more interpretable an LLM is, the more trustworthy it becomes.
However, current techniques for interpreting LLMs when applied to code-related
tasks largely focus on accuracy measurements, measures of how models react to
change, or individual task performance instead of the fine-grained explanations
needed at prediction time for greater interpretability, and hence trust. To
improve upon this status quo, this paper introduces ASTrust, an
interpretability method for LLMs of code that generates explanations grounded
in the relationship between model confidence and syntactic structures of
programming languages. ASTrust explains generated code in the context of syntax
categories based on Abstract Syntax Trees and aids practitioners in
understanding model predictions at both local (individual code snippets) and
global (larger datasets of code) levels. By distributing and assigning model
confidence scores to well-known syntactic structures that exist within ASTs,
our approach moves beyond prior techniques that perform token-level confidence
mapping by offering a view of model confidence that directly aligns with
programming language concepts with which developers are familiar. To put
ASTrust into practice, we developed an automated visualization that illustrates
the aggregated model confidence scores superimposed on sequence, heat-map, and
graph-based visuals of syntactic structures from ASTs. We examine both the
practical benefit that ASTrust can provide through a data science study on 12
popular LLMs on a curated set of GitHub repos and the usefulness of ASTrust
through a human study.

æè¦ï¼å¯ä¿¡åº¦åå¯è§£éæ§æ¯ LLM ä¸­å¯ä¸å¯åçæ¦å¿µãLLM çå¯è§£éæ§è¶é«ï¼å®çå¯ä¿¡åº¦å°±è¶é«ãç¶èï¼ç¶æç¨æ¼èç¨å¼ç¢¼ç¸éçä»»åæï¼ç®åè§£é LLM çæè¡ä¸»è¦éä¸­å¨æºç¢ºæ§æ¸¬éãæ¨¡åå°è®åçåææ¸¬éæåå¥ä»»åè¡¨ç¾ï¼èä¸æ¯å¨é æ¸¬æéæéçç´°ç²åº¦è§£éï¼å¾èæé«å¯è§£éæ§åå æ­¤æé«ä¿¡ä»»åº¦ãçºäºæ¹åéç¨®ç¾çï¼æ¬æä»ç´¹äº ASTrustï¼éæ¯ä¸ç¨®ç¨æ¼ç¨å¼ç¢¼ LLM çå¯è§£éæ§æ¹æ³ï¼å®ææ ¹ææ¨¡åä¿¡å¿èç¨å¼èªè¨çèªæ³çµæ§ä¹éçéä¿ç¢çè§£éãASTrust å¨åºæ¼æ½è±¡èªæ³æ¨¹çèªæ³é¡å¥çä¸ä¸æä¸­è§£éç¢ççç¨å¼ç¢¼ï¼ä¸¦å¹«å©å¯¦åäººå¡å¨å±é¨ï¼åå¥ç¨å¼ç¢¼çæ®µï¼åå¨åï¼è¼å¤§çç¨å¼ç¢¼è³æéï¼å±¤ç´äºè§£æ¨¡åé æ¸¬ãééå°æ¨¡åä¿¡å¿åæ¸åéåæå®çµ¦ AST ä¸­å­å¨çç¾æå¨ç¥çèªæ³çµæ§ï¼æåçåæ³è¶è¶äºååçæè¡ï¼éäºæè¡ééæä¾èéç¼äººå¡çæçç¨å¼èªè¨æ¦å¿µç´æ¥å°é½çæ¨¡åä¿¡å¿è¦åä¾å·è¡ä»¤çç´å¥çä¿¡å¿å°æãçºäºå¯¦è¸ ASTrustï¼æåéç¼äºä¸åèªååè¦è¦ºåå·¥å·ï¼å®èªªæäºçå å¨ AST èªæ³çµæ§çåºåãç±åååºæ¼åå½¢çè¦è¦ºææä¸çèåæ¨¡åä¿¡å¿åæ¸ãæåæª¢æ¥äº ASTrust å¯ä»¥ééå° 12 åæµè¡ç LLM å¨ä¸çµç²¾é¸ç GitHub å²å­åº«ä¸é²è¡è³æç§å­¸ç ç©¶æä¾çå¯¦éå¥½èï¼ä»¥åééäººé«ç ç©¶æä¾ç ASTrust çæç¨æ§ã

##### **Domain-Hierarchy Adaptation via Chain of Iterative Reasoning for Few-shot Hierarchical Text Classification**
2407.08959v1 by Ke Ji, Peng Wang, Wenjun Ke, Guozheng Li, Jiajun Liu, Jingsheng Gao, Ziyu Shang

Recently, various pre-trained language models (PLMs) have been proposed to
prove their impressive performances on a wide range of few-shot tasks. However,
limited by the unstructured prior knowledge in PLMs, it is difficult to
maintain consistent performance on complex structured scenarios, such as
hierarchical text classification (HTC), especially when the downstream data is
extremely scarce. The main challenge is how to transfer the unstructured
semantic space in PLMs to the downstream domain hierarchy. Unlike previous work
on HTC which directly performs multi-label classification or uses graph neural
network (GNN) to inject label hierarchy, in this work, we study the HTC problem
under a few-shot setting to adapt knowledge in PLMs from an unstructured manner
to the downstream hierarchy. Technically, we design a simple yet effective
method named Hierarchical Iterative Conditional Random Field (HierICRF) to
search the most domain-challenging directions and exquisitely crafts
domain-hierarchy adaptation as a hierarchical iterative language modeling
problem, and then it encourages the model to make hierarchical consistency
self-correction during the inference, thereby achieving knowledge transfer with
hierarchical consistency preservation. We perform HierICRF on various
architectures, and extensive experiments on two popular HTC datasets
demonstrate that prompt with HierICRF significantly boosts the few-shot HTC
performance with an average Micro-F1 by 28.80% to 1.50% and Macro-F1 by 36.29%
to 1.5% over the previous state-of-the-art (SOTA) baselines under few-shot
settings, while remaining SOTA hierarchical consistency performance.

æè¦ï¼<paragraph>æè¿ï¼å·²ç»æåºäºå¤ç§é¢è®­ç»è¯­è¨æ¨¡å (PLM)ï¼ä»¥è¯æå®ä»¬å¨å¹¿æ³çå°éæ ·æ¬ä»»å¡ä¸å·æä»¤äººå°è±¡æ·±å»çæ§è½ãç¶èï¼ç±äº PLM ä¸­éç»æåçåéªç¥è¯åå°éå¶ï¼å æ­¤é¾ä»¥å¨å¤æç»æååºæ¯ï¼ä¾å¦å±æ¬¡ææ¬åç±» (HTC)ï¼ä¸­ä¿æä¸è´çæ§è½ï¼å°¤å¶æ¯å¨ä¸æ¸¸æ°æ®æå¶ç¨å°çæåµä¸ãä¸»è¦çæææ¯å¦ä½å° PLM ä¸­éç»æåçè¯­ä¹ç©ºé´è½¬ç§»å°ä¸æ¸¸åå±æ¬¡ç»æãä¸ä»¥åç´æ¥æ§è¡å¤æ ç­¾åç±»æä½¿ç¨å¾ç¥ç»ç½ç» (GNN) æ³¨å¥æ ç­¾å±æ¬¡ç»æç HTC å·¥ä½ä¸åï¼å¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å¨å°éæ ·æ¬è®¾ç½®ä¸ç ç©¶ HTC é®é¢ï¼ä»¥å° PLM ä¸­çç¥è¯ä»éç»æåæ¹å¼éåºå°ä¸æ¸¸å±æ¬¡ç»æãä»ææ¯ä¸è®²ï¼æä»¬è®¾è®¡äºä¸ç§ç®åèææçæ¹æ³ï¼ç§°ä¸ºå±æ¬¡è¿­ä»£æ¡ä»¶éæºåº (HierICRF)ï¼ä»¥æç´¢æå·é¢åæææ§çæ¹åï¼å¹¶ç²¾ç»å°å°é¢åå±æ¬¡ç»æéåºä½ä¸ºåå±è¿­ä»£è¯­è¨å»ºæ¨¡é®é¢ï¼ç¶åå®é¼å±æ¨¡åå¨æ¨çæé´è¿è¡å±æ¬¡ä¸è´æ§èªææ ¡æ­£ï¼ä»èå®ç°å·æå±æ¬¡ä¸è´æ§ä¿ççç¥è¯è½¬ç§»ãæä»¬å¨åç§æ¶æä¸æ§è¡ HierICRFï¼å¨ä¸¤ä¸ªæµè¡ç HTC æ°æ®éä¸çå¤§éå®éªè¡¨æï¼ä½¿ç¨ HierICRF çæç¤ºæ¾çæé«äºå°éæ ·æ¬ HTC æ§è½ï¼å¹³å Micro-F1 ä» 28.80% æé«å° 1.50%ï¼Macro-F1 ä» 36.29% æé«å° 1.5% å¨å°éæ ·æ¬è®¾ç½®ä¸è¶è¿äºä»¥åæåè¿ (SOTA) åºåï¼åæ¶ä¿æ SOTA å±æ¬¡ä¸è´æ§æ§è½ã</paragraph>

##### **Cloud Atlas: Efficient Fault Localization for Cloud Systems using Language Models and Causal Insight**
2407.08694v1 by Zhiqiang Xie, Yujia Zheng, Lizi Ottens, Kun Zhang, Christos Kozyrakis, Jonathan Mace

Runtime failure and performance degradation is commonplace in modern cloud
systems. For cloud providers, automatically determining the root cause of
incidents is paramount to ensuring high reliability and availability as prompt
fault localization can enable faster diagnosis and triage for timely
resolution. A compelling solution explored in recent work is causal reasoning
using causal graphs to capture relationships between varied cloud system
performance metrics. To be effective, however, systems developers must
correctly define the causal graph of their system, which is a time-consuming,
brittle, and challenging task that increases in difficulty for large and
dynamic systems and requires domain expertise. Alternatively, automated
data-driven approaches have limited efficacy for cloud systems due to the
inherent rarity of incidents. In this work, we present Atlas, a novel approach
to automatically synthesizing causal graphs for cloud systems. Atlas leverages
large language models (LLMs) to generate causal graphs using system
documentation, telemetry, and deployment feedback. Atlas is complementary to
data-driven causal discovery techniques, and we further enhance Atlas with a
data-driven validation step. We evaluate Atlas across a range of fault
localization scenarios and demonstrate that Atlas is capable of generating
causal graphs in a scalable and generalizable manner, with performance that far
surpasses that of data-driven algorithms and is commensurate to the
ground-truth baseline.

æè¦ï¼å¨ç¾ä»£é²ç«¯ç³»çµ±ä¸­ï¼å·è¡æææéåæè½éä½æ¯å¸ç©ºè¦æ£çäºãå°æ¼é²ç«¯ä¾æåèè¨ï¼èªåæ¾åºäºä»¶çæ ¹æ¬åå å°æ¼ç¢ºä¿é«å¯é æ§åå¯ç¨æ§è³ééè¦ï¼å çºåæçæéå®ä½å¯ä»¥è®è¨ºæ·ååé¡æ´å¿«éï¼ä»¥å©æ¼åæè§£æ±ºåé¡ãæè¿çå·¥ä½ä¸­æ¢è¨äºä¸åå¼äººæ³¨ç®çè§£æ±ºæ¹æ¡ï¼å³ä½¿ç¨å æåä¾æ·ååç¨®é²ç«¯ç³»çµ±æè½ææ¨ä¹ééä¿çå ææ¨çãç¶èï¼ç³»çµ±éç¼äººå¡å¿é æ­£ç¢ºå®ç¾©å¶ç³»çµ±çå æåæè½ç¼æ®æç¨ï¼èéé ä»»åèæãèå¼±ä¸å·æææ°æ§ï¼å°æ¼å¤§åä¸åæçç³»çµ±èè¨é£åº¦æ´é«ï¼èä¸éè¦é åå°å®¶ç¥è­ãæèï¼ç±æ¼äºä»¶çåºæç¨å°æ§ï¼èªååè³æé©åæ¹æ³å°æ¼é²ç«¯ç³»çµ±çæåæéãå¨éé å·¥ä½ä¸­ï¼æåæåº Atlasï¼ä¸ç¨®èªååæé²ç«¯ç³»çµ±å æåçæ°æ¹æ³ãAtlas å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä½¿ç¨ç³»çµ±æä»¶ãéæ¸¬åé¨ç½²åé¥ä¾ç¢çå æåãAtlas æ¯è³æé©åå æç¼ç¾æè¡çè£åï¼æåé²ä¸æ­¥ä½¿ç¨è³æé©åé©è­æ­¥é©ä¾å¢å¼· Atlasãæåå¨åç¨®æéå®ä½æå¢ä¸­è©ä¼° Atlasï¼ä¸¦è­æ Atlas è½å¤ ä»¥å¯æ´åä¸å¯æ¦åçæ¹å¼ç¢çå æåï¼å¶æè½é é è¶éè³æé©åæ¼ç®æ³ï¼ä¸¦ä¸èçå¯¦åºç·ç¸ç¶ã

##### **Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents**
2407.08516v2 by Haoyi Xiong, Zhiyuan Wang, Xuhong Li, Jiang Bian, Zeke Xie, Shahid Mumtaz, Laura E. Barnes

This article explores the convergence of connectionist and symbolic
artificial intelligence (AI), from historical debates to contemporary
advancements. Traditionally considered distinct paradigms, connectionist AI
focuses on neural networks, while symbolic AI emphasizes symbolic
representation and logic. Recent advancements in large language models (LLMs),
exemplified by ChatGPT and GPT-4, highlight the potential of connectionist
architectures in handling human language as a form of symbols. The study argues
that LLM-empowered Autonomous Agents (LAAs) embody this paradigm convergence.
By utilizing LLMs for text-based knowledge modeling and representation, LAAs
integrate neuro-symbolic AI principles, showcasing enhanced reasoning and
decision-making capabilities. Comparing LAAs with Knowledge Graphs within the
neuro-symbolic AI theme highlights the unique strengths of LAAs in mimicking
human-like reasoning processes, scaling effectively with large datasets, and
leveraging in-context samples without explicit re-training. The research
underscores promising avenues in neuro-vector-symbolic integration,
instructional encoding, and implicit reasoning, aimed at further enhancing LAA
capabilities. By exploring the progression of neuro-symbolic AI and proposing
future research trajectories, this work advances the understanding and
development of AI technologies.

æè¦ï¼æ¬ææ¢è¨äºé£ç·ä¸»ç¾©èç¬¦èäººå·¥æºæ§ï¼AIï¼çèåï¼å¾æ­·å²è¾¯è«å°ç¶ä»£é²å±ãé£ç·ä¸»ç¾© AI å³çµ±ä¸è¢«è¦çºä¸åçç¯å¼ï¼å°æ³¨æ¼ç¥ç¶ç¶²è·¯ï¼èç¬¦è AI åå¼·èª¿ç¬¦èè¡¨å¾µèéè¼¯ãå¤§åèªè¨æ¨¡åï¼LLMï¼çææ°é²å±ï¼ä¾å¦ ChatGPT å GPT-4ï¼çªé¡¯äºé£ç·ä¸»ç¾©æ¶æ§å¨å°äººé¡èªè¨è¦çºç¬¦èå½¢å¼èçæ¹é¢çæ½åãç ç©¶èªçºï¼ç± LLM è³¦è½çèªä¸»ä»£çï¼LAAï¼é«ç¾äºéç¨®ç¯å¼èåãééå©ç¨ LLM é²è¡åºæ¼æå­çç¥è­å»ºæ¨¡åè¡¨å¾µï¼LAA æ´åäºç¥ç¶ç¬¦è AI ååï¼å±ç¤ºäºå¢å¼·çæ¨çåæ±ºç­è½åãå¨ç¥ç¶ç¬¦è AI ä¸»é¡ä¸­æ¯è¼ LAA èç¥è­åè­ï¼çªåºäº LAA å¨æ¨¡æ¬é¡äººæ¨çéç¨ãæææ´åå¤§åè³æéä»¥åå©ç¨æå¢ç¯ä¾èç¡éæç¢ºéæ°è¨ç·´æ¹é¢çç¨ç¹åªå¢ãç ç©¶å¼·èª¿äºç¥ç¶åéç¬¦èæ´åãæä»¤ç·¨ç¢¼åé±å¼æ¨çä¸­åæ¯çå¥½çéå¾ï¼æ¨å¨é²ä¸æ­¥å¢å¼· LAA è½åãééæ¢ç´¢ç¥ç¶ç¬¦è AI çé²å±ä¸¦æåºæªä¾çç ç©¶è»è·¡ï¼éé å·¥ä½æ¨åäº AI æè¡ççè§£åç¼å±ã

##### **A Comprehensive Survey on the Security of Smart Grid: Challenges, Mitigations, and Future Research Opportunities**
2407.07966v1 by Arastoo Zibaeirad, Farnoosh Koleini, Shengping Bi, Tao Hou, Tao Wang

In this study, we conduct a comprehensive review of smart grid security,
exploring system architectures, attack methodologies, defense strategies, and
future research opportunities. We provide an in-depth analysis of various
attack vectors, focusing on new attack surfaces introduced by advanced
components in smart grids. The review particularly includes an extensive
analysis of coordinated attacks that incorporate multiple attack strategies and
exploit vulnerabilities across various smart grid components to increase their
adverse impact, demonstrating the complexity and potential severity of these
threats. Following this, we examine innovative detection and mitigation
strategies, including game theory, graph theory, blockchain, and machine
learning, discussing their advancements in counteracting evolving threats and
associated research challenges. In particular, our review covers a thorough
examination of widely used machine learning-based mitigation strategies,
analyzing their applications and research challenges spanning across
supervised, unsupervised, semi-supervised, ensemble, and reinforcement
learning. Further, we outline future research directions and explore new
techniques and concerns. We first discuss the research opportunities for
existing and emerging strategies, and then explore the potential role of new
techniques, such as large language models (LLMs), and the emerging threat of
adversarial machine learning in the future of smart grid security.

æè¦ï¼å¨éé ç ç©¶ä¸­ï¼æåå°æºæ§é»ç¶²å®å¨æ§é²è¡å¨é¢æª¢è¦ï¼æ¢è¨ç³»çµ±æ¶æ§ãæ»ææ¹æ³ãé²ç¦¦ç­ç¥åæªä¾çç ç©¶æ©æãæåæ·±å¥åæåç¨®æ»æåªä»ï¼å°æ³¨æ¼æºæ§é»ç¶²ä¸­åé²çµä»¶æå¼å¥çæ°æ»æé¢ãæ¬æª¢è¦ç¹å¥åå«å°åèª¿æ»æçå»£æ³åæï¼å¶ä¸­åå«å¤ç¨®æ»æç­ç¥ä¸¦å©ç¨åç¨®æºæ§é»ç¶²çµä»¶ä¸­çæ¼æ´ä¾å¢å å¶è² é¢å½±é¿ï¼å±ç¤ºéäºå¨èçè¤éæ§åæ½å¨å´éæ§ãå¨æ­¤ä¹å¾ï¼æåæ¢è¨åµæ°çåµæ¸¬åç·©è§£ç­ç¥ï¼åæ¬åå¼è«ãåè«ãåå¡éåæ©å¨å­¸ç¿ï¼è¨è«å®åå¨å°æä¸æ·æ¼è®çå¨èåç¸éç ç©¶ææ°æ¹é¢çé²å±ãç¹å¥æ¯ï¼æåçæª¢è¦æ¶µèå°å»£æ³ä½¿ç¨çåºæ¼æ©å¨å­¸ç¿çç·©è§£ç­ç¥çå¾¹åºæª¢é©ï¼åæå®åå¨ç£ç£å¼ãéç£ç£å¼ãåç£ç£å¼ãæ´é«å¼åå¼·åå­¸ç¿ä¸­çæç¨åç ç©¶ææ°ãæ­¤å¤ï¼æåæ¦è¿°æªä¾çç ç©¶æ¹åä¸¦æ¢è¨æ°æè¡ååé¡ãæåé¦åè¨è«ç¾æåæ°èç­ç¥çç ç©¶æ©æï¼ç¶å¾æ¢è¨æ°æè¡çæ½å¨ä½ç¨ï¼ä¾å¦å¤§åèªè¨æ¨¡å (LLM)ï¼ä»¥åå°æå¼æ©å¨å­¸ç¿å¨æºæ§é»ç¶²å®å¨æªä¾çå¨èã

##### **Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs**
2407.07775v2 by Hao-Tien Lewis Chiang, Zhuo Xu, Zipeng Fu, Mithun George Jacob, Tingnan Zhang, Tsang-Wei Edward Lee, Wenhao Yu, Connor Schenck, David Rendleman, Dhruv Shah, Fei Xia, Jasmine Hsu, Jonathan Hoech, Pete Florence, Sean Kirmani, Sumeet Singh, Vikas Sindhwani, Carolina Parada, Chelsea Finn, Peng Xu, Sergey Levine, Jie Tan

An elusive goal in navigation research is to build an intelligent agent that
can understand multimodal instructions including natural language and image,
and perform useful navigation. To achieve this, we study a widely useful
category of navigation tasks we call Multimodal Instruction Navigation with
demonstration Tours (MINT), in which the environment prior is provided through
a previously recorded demonstration video. Recent advances in Vision Language
Models (VLMs) have shown a promising path in achieving this goal as it
demonstrates capabilities in perceiving and reasoning about multimodal inputs.
However, VLMs are typically trained to predict textual output and it is an open
research question about how to best utilize them in navigation. To solve MINT,
we present Mobility VLA, a hierarchical Vision-Language-Action (VLA) navigation
policy that combines the environment understanding and common sense reasoning
power of long-context VLMs and a robust low-level navigation policy based on
topological graphs. The high-level policy consists of a long-context VLM that
takes the demonstration tour video and the multimodal user instruction as input
to find the goal frame in the tour video. Next, a low-level policy uses the
goal frame and an offline constructed topological graph to generate robot
actions at every timestep. We evaluated Mobility VLA in a 836m^2 real world
environment and show that Mobility VLA has a high end-to-end success rates on
previously unsolved multimodal instructions such as "Where should I return
this?" while holding a plastic bin. A video demonstrating Mobility VLA can be
found here: https://youtu.be/-Tof__Q8_5s

æè¦ï¼<paragraph>å°èªç ç©¶ä¸­ä¸åé£ä»¥ææ¸çç®æ¨ï¼æ¯å»ºç«ä¸åæºè½ä»£çï¼å®å¯ä»¥çè§£åæ¬èªç¶èªè¨åå½±åçå¤æ¨¡ææä»¤ï¼ä¸¦å·è¡æç¨çå°èªãçºäºéææ­¤ç®æ¨ï¼æåç ç©¶äºä¸é¡å»£æ³æç¨çå°èªä»»åï¼æåç¨±ä¹çºç¤ºç¯å°è¦½çå¤æ¨¡ææä»¤å°èª (MINT)ï¼å¶ä¸­ç°å¢åé©æ¯ééååéè£½çç¤ºç¯å½±çæä¾çãè¦è¦ºèªè¨æ¨¡å (VLM) çè¿æé²å±ï¼å±ç¤ºäºä¸æ¢å¯¦ç¾æ­¤ç®æ¨çæåæ¯è·¯å¾ï¼å çºå®å±ç¤ºäºæç¥åæ¨çå¤æ¨¡æè¼¸å¥çè½åãç¶èï¼VLM éå¸¸è¨ç·´ç¨æ¼é æ¸¬æå­è¼¸åºï¼èå¦ä½æä½³å©ç¨å®åé²è¡å°èªï¼åæ¯ä¸åéæ¾çç ç©¶åé¡ãçºäºè§£æ±º MINTï¼æåæåºäº Mobility VLAï¼éæ¯ä¸ç¨®åå±¤çè¦è¦º-èªè¨-åä½ (VLA) å°èªæ¿ç­ï¼å®çµåäºé·èªå¢ VLM çç°å¢çè§£åå¸¸è­æ¨çè½åï¼ä»¥ååºæ¼ææ²åçå¼·å¥ä½éå°èªæ¿ç­ãé«éæ¿ç­åå«ä¸åé·èªå¢ VLMï¼å®æ¡ç¨ç¤ºç¯å°è¦½å½±çåå¤æ¨¡æä½¿ç¨èæä»¤ä½çºè¼¸å¥ï¼ä»¥å¨å°è¦½å½±çä¸­æ¾å°ç®æ¨å¹ãæ¥ä¸ä¾ï¼ä½éæ¿ç­ä½¿ç¨ç®æ¨å¹åé¢ç·å»ºæ§çææ²åï¼å¨æ¯åæéæ­¥ç¢çæ©å¨äººåä½ãæåå¨ 836 å¹³æ¹å¬å°ºççå¯¦ä¸çç°å¢ä¸­è©ä¼°äº Mobility VLAï¼ä¸¦å±ç¤ºäº Mobility VLA å¨ååæªè§£æ±ºçå¤æ¨¡ææä»¤ï¼ä¾å¦ãææè©²æéåå¡è ç®±æ­¸éå°åªè£¡ï¼ãï¼ä¸å·æå¾é«çç«¯å°ç«¯æåçï¼åææ¿èä¸åå¡è ç®±ãå±ç¤º Mobility VLA çå½±çå¯ä»¥å¨éè£¡æ¾å°ï¼https://youtu.be/-Tof__Q8_5s</paragraph>

##### **Teaching Transformers Causal Reasoning through Axiomatic Training**
2407.07612v1 by Aniket Vashishtha, Abhinav Kumar, Abbavaram Gowtham Reddy, Vineeth N Balasubramanian, Amit Sharma

For text-based AI systems to interact in the real world, causal reasoning is
an essential skill. Since interventional data is costly to generate, we study
to what extent an agent can learn causal reasoning from passive data.
Specifically, we consider an axiomatic training setup where an agent learns
from multiple demonstrations of a causal axiom (or rule), rather than
incorporating the axiom as an inductive bias or inferring it from data values.
A key question is whether the agent would learn to generalize from the axiom
demonstrations to new scenarios. For example, if a transformer model is trained
on demonstrations of the causal transitivity axiom over small graphs, would it
generalize to applying the transitivity axiom over large graphs? Our results,
based on a novel axiomatic training scheme, indicate that such generalization
is possible. We consider the task of inferring whether a variable causes
another variable, given a causal graph structure. We find that a 67 million
parameter transformer model, when trained on linear causal chains (along with
some noisy variations) can generalize well to new kinds of graphs, including
longer causal chains, causal chains with reversed order, and graphs with
branching; even when it is not explicitly trained for such settings. Our model
performs at par (or even better) than many larger language models such as
GPT-4, Gemini Pro, and Phi-3. Overall, our axiomatic training framework
provides a new paradigm of learning causal reasoning from passive data that can
be used to learn arbitrary axioms, as long as sufficient demonstrations can be
generated.

æè¦ï¼<paragraph>å°æ¼åºæ¼æå­çäººå·¥æºæ§ç³»çµ±èçå¯¦ä¸çäºåä¾èªªï¼å ææ¨çæ¯ä¸é å¿è¦çæè½ãç±æ¼ä»å¥è³æçç¢çææ¬å¾é«ï¼æåç ç©¶ä¸ä½ä»£çäººå¾è¢«åè³æä¸­å­¸ç¿å ææ¨ççç¨åº¦ãå·é«ä¾èªªï¼æåèæ®ä¸åå¬çè¨ç·´è¨­ç½®ï¼å¶ä¸­ä¸ä½ä»£çäººå¾å æå¬çï¼æè¦åï¼çå¤åç¤ºç¯ä¸­å­¸ç¿ï¼èä¸æ¯å°å¬çä½çºæ­¸ç´åèª¤æå¾è³æå¼ä¸­æ¨æ·åºä¾ãä¸åééµåé¡æ¯ä»£çäººæ¯å¦æå­¸æå¾å¬çç¤ºç¯æ¨å»£å°æ°çå ´æ¯ãä¾å¦ï¼å¦æä¸åTransformeræ¨¡åå¨å°åè¡¨ä¸å æå³éæ§å¬ççç¤ºç¯ä¸­æ¥åè¨ç·´ï¼å®æ¯å¦ææ¨å»£å°å¨å¤§åè¡¨ä¸æç¨å³éæ§å¬çï¼æåççµæåºæ¼ä¸åæ°ç©çå¬çè¨ç·´æ¹æ¡ï¼è¡¨æéæ¨£çæ¦æ¬æ¯å¯è½çãæåèæ®æ¨è«ä¸åè®æ¸æ¯å¦å°è´å¦ä¸åè®æ¸çä»»åï¼çµ¦å®ä¸åå æåçµæ§ãæåç¼ç¾ä¸å 6700 è¬ååæ¸çTransformeræ¨¡åï¼å¨ç·æ§å æéï¼ä»¥åä¸äºéè¨è®åï¼ä¸è¨ç·´æï¼å¯ä»¥å¾å¥½å°æ¦æ¬å°æ°é¡åçåå½¢ï¼åæ¬æ´é·çå æéãé åºç¸åçå æéåå·æåæ¯çåå½¢ï¼å³ä½¿å®æ²æéå°æ­¤é¡è¨­ç½®é²è¡æç¢ºè¨ç·´ãæåçæ¨¡åè¡¨ç¾èè¨±å¤è¼å¤§çèªè¨æ¨¡åï¼ä¾å¦ GPT-4ãGemini Pro å Phi-3ï¼ç¸ç¶ï¼çè³æ´å¥½ï¼ãç¸½é«èè¨ï¼æåçå¬çè¨ç·´æ¡æ¶æä¾äºä¸åå¾è¢«åè³æä¸­å­¸ç¿å ææ¨ççæ°ç¯ä¾ï¼åªè¦å¯ä»¥ç¢çè¶³å¤ çç¤ºç¯ï¼å°±å¯ä»¥ç¨æ¼å­¸ç¿ä»»æå¬çã</paragraph>

##### **STAGE: Simplified Text-Attributed Graph Embeddings Using Pre-trained LLMs**
2407.12860v1 by Aaron Zolnai-Lucas, Jack Boylan, Chris Hokamp, Parsa Ghaffari

We present Simplified Text-Attributed Graph Embeddings (STAGE), a
straightforward yet effective method for enhancing node features in Graph
Neural Network (GNN) models that encode Text-Attributed Graphs (TAGs). Our
approach leverages Large-Language Models (LLMs) to generate embeddings for
textual attributes. STAGE achieves competitive results on various node
classification benchmarks while also maintaining a simplicity in implementation
relative to current state-of-the-art (SoTA) techniques. We show that utilizing
pre-trained LLMs as embedding generators provides robust features for ensemble
GNN training, enabling pipelines that are simpler than current SoTA approaches
which require multiple expensive training and prompting stages. We also
implement diffusion-pattern GNNs in an effort to make this pipeline scalable to
graphs beyond academic benchmarks.

æè¦ï¼æåæåºäºç°¡åæå­å±¬æ§ååµå¥ (STAGE)ï¼éæ¯ä¸ç¨®ç´æ¥ä½ææçæ¹æ³ï¼ç¨æ¼å¢å¼·åç¥ç¶ç¶²è·¯ (GNN) æ¨¡åä¸­çç¯é»ç¹å¾µï¼éäºæ¨¡åæç·¨ç¢¼æå­å±¬æ§å (TAG)ãæåçåæ³å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾çºæå­å±¬æ§ç¢çåµå¥ãSTAGE å¨åç¨®ç¯é»åé¡åºæºä¸åå¾äºæç«¶ç­åççµæï¼åæå¨å¯¦ä½ä¸ä¹ç¶­æäºç°¡æ½æ§ï¼ç¸è¼æ¼ç®åçæè¡æ°´æº (SoTA)ãæåå±ç¤ºäºä½¿ç¨é è¨ç·´ç LLM ä½çºåµå¥ç¢çå¨ï¼å¯çºæ´é« GNN è¨ç·´æä¾å¼·å¥çç¹å¾µï¼é²èå»ºæ§æ¯ç®å SoTA åæ³æ´ç°¡å®çç®¡éï¼èå¾èéè¦å¤åæè²´çè¨ç·´åæç¤ºéæ®µãæåä¹å¯¦ä½äºæ´æ£æ¨¡å¼ GNNï¼ä»¥æè®éåç®¡éè½æ´åå°å­¸è¡åºæºä¹å¤çåå½¢ã

##### **GLBench: A Comprehensive Benchmark for Graph with Large Language Models**
2407.07457v2 by Yuhan Li, Peisong Wang, Xiao Zhu, Aochuan Chen, Haiyun Jiang, Deng Cai, Victor Wai Kin Chan, Jia Li

The emergence of large language models (LLMs) has revolutionized the way we
interact with graphs, leading to a new paradigm called GraphLLM. Despite the
rapid development of GraphLLM methods in recent years, the progress and
understanding of this field remain unclear due to the lack of a benchmark with
consistent experimental protocols. To bridge this gap, we introduce GLBench,
the first comprehensive benchmark for evaluating GraphLLM methods in both
supervised and zero-shot scenarios. GLBench provides a fair and thorough
evaluation of different categories of GraphLLM methods, along with traditional
baselines such as graph neural networks. Through extensive experiments on a
collection of real-world datasets with consistent data processing and splitting
strategies, we have uncovered several key findings. Firstly, GraphLLM methods
outperform traditional baselines in supervised settings, with LLM-as-enhancers
showing the most robust performance. However, using LLMs as predictors is less
effective and often leads to uncontrollable output issues. We also notice that
no clear scaling laws exist for current GraphLLM methods. In addition, both
structures and semantics are crucial for effective zero-shot transfer, and our
proposed simple baseline can even outperform several models tailored for
zero-shot scenarios. The data and code of the benchmark can be found at
https://github.com/NineAbyss/GLBench.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çåºç¾å¾¹åºæ¹è®äºæåèåè¡¨äºåçæ¹å¼ï¼é²èç¢çä¸ç¨®ç¨±çº GraphLLM çæ°å¸ç¯ãåç®¡è¿å¹´ä¾ GraphLLM æ¹æ³å¿«éç¼å±ï¼ä½ç±æ¼ç¼ºä¹å·æä¸è´å¯¦é©åå®çåºæºï¼å æ­¤è©²é åçé²å±åçè§£ä»ä¸æç¢ºãçºäºå½è£éåå·®è·ï¼æåå¼å¥äº GLBenchï¼éæ¯ç¬¬ä¸åç¨æ¼è©ä¼° GraphLLM æ¹æ³å¨ç£ç£å¼åé¶æ¬¡å­¸ç¿å ´æ¯ä¸­çç¶ååºæºãGLBench æä¾å°ä¸åé¡å¥ç GraphLLM æ¹æ³é²è¡å¬å¹³ä¸å¾¹åºçè©ä¼°ï¼ä»¥åå³çµ±åºæºï¼ä¾å¦åç¥ç¶ç¶²è·¯ãééå°ä¸çµçå¯¦ä¸çè³æéé²è¡å»£æ³å¯¦é©ï¼ä¸¦æ¡ç¨ä¸è´çè³æèçååå²ç­ç¥ï¼æåç¼ç¾äºå¹¾åééµç¼ç¾ãé¦åï¼GraphLLM æ¹æ³å¨ç£ç£å¼è¨­å®ä¸­åªæ¼å³çµ±åºæºï¼å¶ä¸­ LLM ä½çºå¢å¼·å¨é¡¯ç¤ºåºæç©©å¥çæè½ãç¶èï¼ä½¿ç¨ LLM ä½çºé æ¸¬å¨è¼ä¸ææï¼èä¸ç¶å¸¸å°è´ç¡æ³æ§å¶çè¼¸åºåé¡ãæåéæ³¨æå°ï¼å°æ¼ç®åç GraphLLM æ¹æ³ä¸¦ä¸å­å¨æç¢ºçç¸®æ¾å®å¾ãæ­¤å¤ï¼çµæ§åèªç¾©å°æ¼ææçé¶æ¬¡å­¸ç¿å³è¼¸è³ééè¦ï¼èæåæåºçç°¡å®åºæºçè³å¯ä»¥åªæ¼éå°é¶æ¬¡å­¸ç¿å ´æ¯éèº«æé çå¹¾åæ¨¡åãåºæºçè³æåç¨å¼ç¢¼å¯ä»¥å¨ https://github.com/NineAbyss/GLBench ä¸­æ¾å°ã

##### **Decoding Climate Disagreement: A Graph Neural Network-Based Approach to Understanding Social Media Dynamics**
2407.07038v1 by Ruiran Su, Janet B. Pierrehumbert

This work introduces the ClimateSent-GAT Model, an innovative method that
integrates Graph Attention Networks (GATs) with techniques from natural
language processing to accurately identify and predict disagreements within
Reddit comment-reply pairs. Our model classifies disagreements into three
categories: agree, disagree, and neutral. Leveraging the inherent graph
structure of Reddit comment-reply pairs, the model significantly outperforms
existing benchmarks by capturing complex interaction patterns and sentiment
dynamics. This research advances graph-based NLP methodologies and provides
actionable insights for policymakers and educators in climate science
communication.

æè¦ï¼æ¬ç ç©¶ä»ç´¹ ClimateSent-GAT æ¨¡åï¼éæ¯ä¸ç¨®åµæ°çæ¹æ³ï¼å®å°åæ³¨æåç¶²è·¯ (GAT) èèªç¶èªè¨èçæè¡æ´åï¼ä»¥æºç¢ºè­å¥ä¸¦é æ¸¬ Reddit çè¨åè¦å°ä¸­çåæ­§ãæåçæ¨¡åå°åæ­§åçºä¸é¡ï¼åæãä¸åæåä¸­ç«ãééå©ç¨ Reddit çè¨åè¦å°çå§å¨åå½¢çµæ§ï¼æ­¤æ¨¡åè½å¤§å¹è¶è¶ç¾æåºæºï¼ææè¤éçäºåæ¨¡å¼åæç·åæãéé ç ç©¶æ¨åäºåºæ¼åå½¢ç NLP æ¹æ³ï¼ä¸¦çºæ°£åç§å­¸æºéä¸­çæ¿ç­å¶å®èåæè²å·¥ä½èæä¾å¯è¡çè¦è§£ã

##### **Graph-Based Captioning: Enhancing Visual Descriptions by Interconnecting Region Captions**
2407.06723v1 by Yu-Guan Hsieh, Cheng-Yu Hsieh, Shih-Ying Yeh, Louis BÃ©thune, Hadi Pour Ansari, Pavan Kumar Anasosalu Vasu, Chun-Liang Li, Ranjay Krishna, Oncel Tuzel, Marco Cuturi

Humans describe complex scenes with compositionality, using simple text
descriptions enriched with links and relationships. While vision-language
research has aimed to develop models with compositional understanding
capabilities, this is not reflected yet in existing datasets which, for the
most part, still use plain text to describe images. In this work, we propose a
new annotation strategy, graph-based captioning (GBC) that describes an image
using a labelled graph structure, with nodes of various types. The nodes in GBC
are created using, in a first stage, object detection and dense captioning
tools nested recursively to uncover and describe entity nodes, further linked
together in a second stage by highlighting, using new types of nodes,
compositions and relations among entities. Since all GBC nodes hold plain text
descriptions, GBC retains the flexibility found in natural language, but can
also encode hierarchical information in its edges. We demonstrate that GBC can
be produced automatically, using off-the-shelf multimodal LLMs and
open-vocabulary detection models, by building a new dataset, GBC10M, gathering
GBC annotations for about 10M images of the CC12M dataset. We use GBC10M to
showcase the wealth of node captions uncovered by GBC, as measured with CLIP
training. We show that using GBC nodes' annotations -- notably those stored in
composition and relation nodes -- results in significant performance boost on
downstream models when compared to other dataset formats. To further explore
the opportunities provided by GBC, we also propose a new attention mechanism
that can leverage the entire GBC graph, with encouraging experimental results
that show the extra benefits of incorporating the graph structure. Our datasets
are released at \url{https://huggingface.co/graph-based-captions}.

æè¦ï¼<paragraph>äººé¡ä½¿ç¨ç°¡å®çæå­æè¿°ï¼è±å¯çé£çµåéä¿ï¼ä¾æè¿°è¤éçå ´æ¯ãéç¶è¦è¦ºèªè¨çç ç©¶æ¨å¨éç¼å·æçµåçè§£è½åçæ¨¡åï¼ä½ç¾æçæ¸æéå°æªåæ éä¸é»ï¼éäºæ¸æéå¨å¾å¤§ç¨åº¦ä¸ä»ä½¿ç¨ç´ææ¬ä¾æè¿°ååãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°çè¨»éç­ç¥ï¼åºæ¼åè¡¨çæ¨é¡ (GBC)ï¼å®ä½¿ç¨æ¨ç±¤åè¡¨çµæ§ä¾æè¿°ååï¼å¶ä¸­åå«åç¨®é¡åçç¯é»ãGBC ä¸­çç¯é»æ¯ä½¿ç¨ç©é«æª¢æ¸¬åå¯éæ¨é¡å·¥å·å¨ç¬¬ä¸éæ®µåµå»ºçï¼ä»¥éè¿´åµå¥çæ¹å¼ç¼ç¾åæè¿°å¯¦é«ç¯é»ï¼ä¸¦å¨ç¬¬äºéæ®µä½¿ç¨æ°é¡åçç¯é»çªåºé¡¯ç¤ºï¼å¾èå°å®åé²ä¸æ­¥é£çµå¨ä¸èµ·ï¼å¯¦é«ä¹éççµååéä¿ãç±æ¼ææ GBC ç¯é»é½åå«ç´ææ¬æè¿°ï¼å æ­¤ GBC ä¿çäºèªç¶èªè¨ä¸­çéæ´»æ§ï¼ä½ä¹å¯ä»¥å¨å¶éç·£ç·¨ç¢¼åå±¤ä¿¡æ¯ãæåè­æäº GBC å¯ä»¥ä½¿ç¨ç¾æçå¤æ¨¡æ LLM åéæ¾è©å½æª¢æ¸¬æ¨¡åèªåçæï¼ééæ§å»ºä¸åæ°çæ¸æé GBC10Mï¼æ¶éäºå¤§ç´ 10M CC12M æ¸æéååç GBC è¨»éãæåä½¿ç¨ GBC10M ä¾å±ç¤º GBC ç¼ç¾çè±å¯ç¯é»æ¨é¡ï¼ä¸¦ä½¿ç¨ CLIP è¨ç·´é²è¡æ¸¬éãæåè¡¨æï¼èå¶ä»æ¸æéæ ¼å¼ç¸æ¯ï¼ä½¿ç¨ GBC ç¯é»çè¨»éââç¹å¥æ¯å­å²å¨çµååéä¿ç¯é»ä¸­çè¨»éââæé¡¯èæåä¸æ¸¸æ¨¡åçæ§è½ãçºäºé²ä¸æ­¥æ¢ç´¢ GBC æä¾çæ©æï¼æåéæåºäºä¸ç¨®æ°çæ³¨ææ©å¶ï¼å®å¯ä»¥å©ç¨æ´å GBC åè¡¨ï¼ä¸¦ééé¼åµæ§çå¯¦é©çµæå±ç¤ºäºçµååè¡¨çµæ§çé¡å¤å¥½èãæåçæ¸æéç¼å¸å¨ \url{https://huggingface.co/graph-based-captions}ã</paragraph>

##### **Combining Knowledge Graphs and Large Language Models**
2407.06564v1 by Amanda Kau, Xuzeng He, Aishwarya Nambissan, Aland Astudillo, Hui Yin, Amir Aryani

In recent years, Natural Language Processing (NLP) has played a significant
role in various Artificial Intelligence (AI) applications such as chatbots,
text generation, and language translation. The emergence of large language
models (LLMs) has greatly improved the performance of these applications,
showing astonishing results in language understanding and generation. However,
they still show some disadvantages, such as hallucinations and lack of
domain-specific knowledge, that affect their performance in real-world tasks.
These issues can be effectively mitigated by incorporating knowledge graphs
(KGs), which organise information in structured formats that capture
relationships between entities in a versatile and interpretable fashion.
Likewise, the construction and validation of KGs present challenges that LLMs
can help resolve. The complementary relationship between LLMs and KGs has led
to a trend that combines these technologies to achieve trustworthy results.
This work collected 28 papers outlining methods for KG-powered LLMs, LLM-based
KGs, and LLM-KG hybrid approaches. We systematically analysed and compared
these approaches to provide a comprehensive overview highlighting key trends,
innovative techniques, and common challenges. This synthesis will benefit
researchers new to the field and those seeking to deepen their understanding of
how KGs and LLMs can be effectively combined to enhance AI applications
capabilities.

æè¦ï¼è¿å¹´æ¥ï¼èªç¶è¯­è¨å¤ç (NLP) å¨åç§äººå·¥æºè½ (AI) åºç¨ä¸­åæ¥äºéè¦ä½ç¨ï¼ä¾å¦èå¤©æºå¨äººãææ¬çæåè¯­è¨ç¿»è¯ãå¤§è¯­è¨æ¨¡å (LLM) çåºç°æå¤§å°æé«äºè¿äºåºç¨ç¨åºçæ§è½ï¼å¨è¯­è¨çè§£åçææ¹é¢æ¾ç¤ºåºæäººçç»æãç¶èï¼å®ä»¬ä»ç¶è¡¨ç°åºä¸äºç¼ºç¹ï¼ä¾å¦å¹»è§åç¼ºä¹ç¹å®é¢åçç¥è¯ï¼è¿äºç¼ºç¹ä¼å½±åå®ä»¬å¨ç°å®ä¸çä¸­çä»»å¡ä¸­çè¡¨ç°ãéè¿çº³å¥ç¥è¯å¾è°± (KG) å¯ä»¥ææå°åè½»è¿äºé®é¢ï¼ç¥è¯å¾è°±ä»¥ç»æåæ ¼å¼ç»ç»ä¿¡æ¯ï¼ä»¥å¤åè½ä¸å¯è§£éçæ¹å¼æè·å®ä½ä¹é´çå³ç³»ãåæ ·ï¼KG çæå»ºåéªè¯æåºäº LLM å¯ä»¥å¸®å©è§£å³çææãLLM å KG ä¹é´çäºè¡¥å³ç³»å¯¼è´äºä¸ç§å°è¿äºææ¯ç¸ç»åä»¥å®ç°å¯ä¿¡ç»æçè¶å¿ãè¿é¡¹å·¥ä½æ¶éäº 28 ç¯æ¦è¿°äº KG é©±å¨ç LLMãåºäº LLM ç KG å LLM-KG æ··åæ¹æ³çæ¹æ³çè®ºæãæä»¬ç³»ç»å°åæåæ¯è¾äºè¿äºæ¹æ³ï¼ä»¥æä¾ä¸ä¸ªå¨é¢çæ¦è¿°ï¼éç¹ä»ç»å³é®è¶å¿ãåæ°ææ¯åå±åææãè¿ç§ç»¼åå°ä½¿è¯¥é¢åçæ°ç ç©¶äººååé£äºå¯»æ±å æ·±å¯¹å¦ä½ææå°å° KG å LLM ç¸ç»åä»¥å¢å¼º AI åºç¨è½åççè§£çäººåçã

##### **MST5 -- Multilingual Question Answering over Knowledge Graphs**
2407.06041v1 by Nikit Srivastava, Mengshi Ma, Daniel Vollmers, Hamada Zahera, Diego Moussallem, Axel-Cyrille Ngonga Ngomo

Knowledge Graph Question Answering (KGQA) simplifies querying vast amounts of
knowledge stored in a graph-based model using natural language. However, the
research has largely concentrated on English, putting non-English speakers at a
disadvantage. Meanwhile, existing multilingual KGQA systems face challenges in
achieving performance comparable to English systems, highlighting the
difficulty of generating SPARQL queries from diverse languages. In this
research, we propose a simplified approach to enhance multilingual KGQA systems
by incorporating linguistic context and entity information directly into the
processing pipeline of a language model. Unlike existing methods that rely on
separate encoders for integrating auxiliary information, our strategy leverages
a single, pretrained multilingual transformer-based language model to manage
both the primary input and the auxiliary data. Our methodology significantly
improves the language model's ability to accurately convert a natural language
query into a relevant SPARQL query. It demonstrates promising results on the
most recent QALD datasets, namely QALD-9-Plus and QALD-10. Furthermore, we
introduce and evaluate our approach on Chinese and Japanese, thereby expanding
the language diversity of the existing datasets.

æè¦ï¼ç¥è­åè¡¨åç­ (KGQA) ç°¡åäºä½¿ç¨èªç¶èªè¨æ¥è©¢å²å­å¨åå½¢åæ¨¡åä¸­çå¤§éç¥è­ãç¶èï¼ç ç©¶ä¸»è¦éä¸­å¨è±æä¸ï¼éå°éè±èªä½¿ç¨èä¾èªªæ¯ä¸å©çãåæï¼ç¾æçå¤èªè¨ KGQA ç³»çµ±å¨éæèè±æç³»çµ±ç¸åª²ç¾çæè½æ¹é¢é¢è¨ææ°ï¼çªé¡¯äºå¾ä¸åèªè¨ç¢ç SPARQL æ¥è©¢çå°é£æ§ãå¨éé ç ç©¶ä¸­ï¼æåæåºäºä¸ç¨®ç°¡åçæ¹æ³ï¼ééå°èªè¨å­¸èæ¯åå¯¦é«è³è¨ç´æ¥ç´å¥èªè¨æ¨¡åçèçç®¡éï¼ä¾å¢å¼·å¤èªè¨ KGQA ç³»çµ±ãèä¾è³´æ¼å®ç¨ç·¨ç¢¼å¨ä¾æ´åè¼å©è³è¨çç¾ææ¹æ³ä¸åï¼æåçç­ç¥å©ç¨å®ä¸çãé è¨ç·´çå¤èªè¨è½æå¨èªè¨æ¨¡åä¾ç®¡çä¸»è¦è¼¸å¥åè¼å©è³æãæåçæè¡é¡¯èæåäºèªè¨æ¨¡åæºç¢ºå°å°èªç¶èªè¨æ¥è©¢è½æçºç¸é SPARQL æ¥è©¢çè½åãå®å¨ææ°ç QALD è³æéï¼å³ QALD-9-Plus å QALD-10 ä¸å±ç¤ºäºæå¸æççµæãæ­¤å¤ï¼æåå¨ä¸­æåæ¥æä¸­å¼å¥ä¸¦è©ä¼°äºæåçåæ³ï¼å¾èæ´å±äºç¾æè³æéçèªè¨å¤æ¨£æ§ã

##### **Enhancing Vision-Language Models with Scene Graphs for Traffic Accident Understanding**
2407.05910v1 by Aaron Lohner, Francesco Compagno, Jonathan Francis, Alessandro Oltramari

Recognizing a traffic accident is an essential part of any autonomous driving
or road monitoring system. An accident can appear in a wide variety of forms,
and understanding what type of accident is taking place may be useful to
prevent it from reoccurring. The task of being able to classify a traffic scene
as a specific type of accident is the focus of this work. We approach the
problem by likening a traffic scene to a graph, where objects such as cars can
be represented as nodes, and relative distances and directions between them as
edges. This representation of an accident can be referred to as a scene graph,
and is used as input for an accident classifier. Better results can be obtained
with a classifier that fuses the scene graph input with representations from
vision and language. This work introduces a multi-stage, multimodal pipeline to
pre-process videos of traffic accidents, encode them as scene graphs, and align
this representation with vision and language modalities for accident
classification. When trained on 4 classes, our method achieves a balanced
accuracy score of 57.77% on an (unbalanced) subset of the popular Detection of
Traffic Anomaly (DoTA) benchmark, representing an increase of close to 5
percentage points from the case where scene graph information is not taken into
account.

æè¦ï¼è¾¨è­äº¤éäºææ¯ä»»ä½èªåé§é§æéè·¯ç£æ§ç³»çµ±çå¿è¦é¨åãäºæå¯è½ä»¥åç¨®å½¢å¼åºç¾ï¼äºè§£äºæé¡åå¯è½æå©æ¼é²æ­¢åæ¬¡ç¼çãå°äº¤éäºæå ´æ¯åé¡çºç¹å®äºæé¡åçä»»åæ¯éé å·¥ä½çéé»ãæåå°äº¤éäºæå ´æ¯æ¯å»çºåå½¢ä¾è§£æ±ºåé¡ï¼å¶ä¸­æ±½è»ç­ç©é«å¯ä»¥è¡¨ç¤ºçºç¯é»ï¼èå®åä¹éçç¸å°è·é¢åæ¹ååè¡¨ç¤ºçºéç·£ãéç¨®äºæè¡¨ç¤ºå¯ä»¥ç¨±çºå ´æ¯åï¼ä¸¦ç¨ä½äºæåé¡å¨çè¼¸å¥ãä½¿ç¨å°å ´æ¯åè¼¸å¥èè¦è¦ºåèªè¨è¡¨ç¤ºèåçåé¡å¨å¯ä»¥ç²å¾æ´å¥½ççµæãéé å·¥ä½å¼å¥äºä¸åå¤éæ®µãå¤æ¨¡æç®¡éï¼ç¨æ¼é èçäº¤éäºæå½±çãå°å¶ç·¨ç¢¼çºå ´æ¯åï¼ä»¥åå°æ­¤è¡¨ç¤ºèè¦è¦ºåèªè¨æ¨¡å¼å°é½ä»¥é²è¡äºæåé¡ãç¶å¨ 4 åé¡å¥ä¸é²è¡è¨ç·´æï¼æåçæ¨¡åå¨ç±éäº¤éç°å¸¸æª¢æ¸¬ (DoTA) åºæºçï¼ä¸å¹³è¡¡ï¼å­éä¸å¯¦ç¾äº 57.77% çå¹³è¡¡æºç¢ºçï¼æ¯ä¸èæ®å ´æ¯åè³è¨çææ³æé«äºæ¥è¿ 5 åç¾åé»ã

##### **Affordances-Oriented Planning using Foundation Models for Continuous Vision-Language Navigation**
2407.05890v1 by Jiaqi Chen, Bingqian Lin, Xinmin Liu, Xiaodan Liang, Kwan-Yee K. Wong

LLM-based agents have demonstrated impressive zero-shot performance in the
vision-language navigation (VLN) task. However, these zero-shot methods focus
only on solving high-level task planning by selecting nodes in predefined
navigation graphs for movements, overlooking low-level control in realistic
navigation scenarios. To bridge this gap, we propose AO-Planner, a novel
affordances-oriented planning framework for continuous VLN task. Our AO-Planner
integrates various foundation models to achieve affordances-oriented motion
planning and action decision-making, both performed in a zero-shot manner.
Specifically, we employ a visual affordances prompting (VAP) approach, where
visible ground is segmented utilizing SAM to provide navigational affordances,
based on which the LLM selects potential next waypoints and generates low-level
path planning towards selected waypoints. We further introduce a high-level
agent, PathAgent, to identify the most probable pixel-based path and convert it
into 3D coordinates to fulfill low-level motion. Experimental results on the
challenging R2R-CE benchmark demonstrate that AO-Planner achieves
state-of-the-art zero-shot performance (5.5% improvement in SPL). Our method
establishes an effective connection between LLM and 3D world to circumvent the
difficulty of directly predicting world coordinates, presenting novel prospects
for employing foundation models in low-level motion control.

æè¦ï¼åºæ¼ LLM çä»£çå·²å¨è¦è¦ºèªè¨å°èª (VLN) ä»»åä¸­å±ç¤ºåºä»¤äººå°è±¡æ·±å»çé¶æ¬¡å­¸ç¿æè½ãç¶èï¼éäºé¶æ¬¡å­¸ç¿æ¹æ³åå°æ³¨æ¼ééé¸æé å®ç¾©å°èªåå½¢ä¸­çç¯é»ä¾è§£æ±ºé«éä»»åè¦åï¼å¿½ç¥äºå¯¦éå°èªå ´æ¯ä¸­çä½éæ§å¶ãçºäºå½åæ­¤å·®è·ï¼æåæåº AO-Plannerï¼ä¸åç¨æ¼é£çº VLN ä»»åçæ°åä»¥å¯è² ææ§çºå°åçè¦åæ¶æ§ãæåç AO-Planner æ´ååç¨®åºç¤æ¨¡åï¼ä»¥å¯¦ç¾ä»¥å¯è² ææ§çºå°åçåä½è¦åååä½æ±ºç­ï¼å©èé½ä»¥é¶æ¬¡å­¸ç¿çæ¹å¼å·è¡ãå·é«ä¾èªªï¼æåæ¡ç¨è¦è¦ºå¯è² ææ§æç¤º (VAP) æ¹æ³ï¼å¶ä¸­å©ç¨ SAM å°å¯è¦å°é¢é²è¡åå²ï¼ä»¥æä¾å°èªå¯è² ææ§ï¼LLM æ ¹æéäºå¯è² ææ§é¸ææ½å¨çä¸ä¸åèªé»ï¼ä¸¦éå°æé¸èªé»ç¢çä½éè·¯å¾è¦åãæåé²ä¸æ­¥å¼å¥ä¸åé«éä»£ç PathAgentï¼ä»¥è­å¥æå¯è½çåºæ¼åç´ çè·¯å¾ï¼ä¸¦å°å¶è½æçº 3D åº§æ¨ï¼ä»¥å¯¦ç¾ä½éåä½ãå¨å·æææ°æ§ç R2R-CE åºæºæ¸¬è©¦ä¸çå¯¦é©çµæè¡¨æï¼AO-Planner éå°äºæåé²çé¶æ¬¡å­¸ç¿æè½ï¼SPL æå 5.5%ï¼ãæåçæ¨¡åå¨ LLM å 3D ä¸çä¹éå»ºç«äºä¸åææçé£çµï¼ä»¥è¦é¿ç´æ¥é æ¸¬ä¸çåº§æ¨çé£é¡ï¼çºå¨ä½éåä½æ§å¶ä¸­æ¡ç¨åºç¤æ¨¡åæä¾äºæ°çåæ¯ã

##### **KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions**
2407.05868v1 by Yanxu Zhu, Jinlin Xiao, Yuhang Wang, Jitao Sang

Recent studies have demonstrated that large language models (LLMs) are
susceptible to being misled by false premise questions (FPQs), leading to
errors in factual knowledge, know as factuality hallucination. Existing
benchmarks that assess this vulnerability primarily rely on manual
construction, resulting in limited scale and lack of scalability. In this work,
we introduce an automated, scalable pipeline to create FPQs based on knowledge
graphs (KGs). The first step is modifying true triplets extracted from KGs to
create false premises. Subsequently, utilizing the state-of-the-art
capabilities of GPTs, we generate semantically rich FPQs. Based on the proposed
method, we present a comprehensive benchmark, the Knowledge Graph-based False
Premise Questions (KG-FPQ), which contains approximately 178k FPQs across three
knowledge domains, at six levels of confusability, and in two task formats.
Using KG-FPQ, we conduct extensive evaluations on several representative LLMs
and provide valuable insights. The KG-FPQ dataset and code are available
at~https://github.com/yanxuzhu/KG-FPQ.

æè¦ï¼æè¿çç ç©¶è¡¨æï¼å¤§åè¯­è¨æ¨¡å (LLM) å®¹æè¢«éè¯¯åæé®é¢ (FPQ) è¯¯å¯¼ï¼ä»èå¯¼è´äºå®ç¥è¯éè¯¯ï¼å³äºå®å¹»è§ãç¨äºè¯ä¼°æ­¤æ¼æ´çç°æåºåä¸»è¦ä¾èµäºæå¨æå»ºï¼å¯¼è´è§æ¨¡æéä¸ç¼ºä¹å¯æ©å±æ§ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å¼å¥äºä¸ä¸ªåºäºç¥è¯å¾è°± (KG) åå»º FPQ çèªå¨åå¯æ©å±ç®¡éãç¬¬ä¸æ­¥æ¯ä¿®æ¹ä» KG ä¸­æåççä¸åç»ä»¥åå»ºéè¯¯åæãéåï¼å©ç¨ GPT çæåè¿åè½ï¼æä»¬çæäºè¯­ä¹ä¸°å¯ç FPQãåºäºææåºçæ¹æ³ï¼æä»¬æåºäºä¸ä¸ªç»¼ååºåï¼å³åºäºç¥è¯å¾è°±çéè¯¯åæé®é¢ (KG-FPQ)ï¼å®åå«å¤§çº¦ 178k ä¸ª FPQï¼æ¶µçä¸ä¸ªç¥è¯åï¼å­ä¸ªæ··æ·çº§å«åä¸¤ç§ä»»å¡æ ¼å¼ãä½¿ç¨ KG-FPQï¼æä»¬å¯¹å ä¸ªæä»£è¡¨æ§ç LLM è¿è¡äºå¹¿æ³çè¯ä¼°ï¼å¹¶æä¾äºæä»·å¼çè§è§£ãKG-FPQ æ°æ®éåä»£ç å¯å¨~https://github.com/yanxuzhu/KG-FPQ è·å¾ã

##### **Language Models Encode Collaborative Signals in Recommendation**
2407.05441v1 by Leheng Sheng, An Zhang, Yi Zhang, Yuxin Chen, Xiang Wang, Tat-Seng Chua

Recent studies empirically indicate that language models (LMs) encode rich
world knowledge beyond mere semantics, attracting significant attention across
various fields. However, in the recommendation domain, it remains uncertain
whether LMs implicitly encode user preference information. Contrary to the
prevailing understanding that LMs and traditional recommender models learn two
distinct representation spaces due to a huge gap in language and behavior
modeling objectives, this work rethinks such understanding and explores
extracting a recommendation space directly from the language representation
space. Surprisingly, our findings demonstrate that item representations, when
linearly mapped from advanced LM representations, yield superior recommendation
performance. This outcome suggests the homomorphism between the language
representation space and an effective recommendation space, implying that
collaborative signals may indeed be encoded within advanced LMs. Motivated by
these findings, we propose a simple yet effective collaborative filtering (CF)
model named AlphaRec, which utilizes language representations of item textual
metadata (e.g., titles) instead of traditional ID-based embeddings.
Specifically, AlphaRec is comprised of three main components: a multilayer
perceptron (MLP), graph convolution, and contrastive learning (CL) loss
function, making it extremely easy to implement and train. Our empirical
results show that AlphaRec outperforms leading ID-based CF models on multiple
datasets, marking the first instance of such a recommender with text embeddings
achieving this level of performance. Moreover, AlphaRec introduces a new
language-representation-based CF paradigm with several desirable advantages:
being easy to implement, lightweight, rapid convergence, superior zero-shot
recommendation abilities in new domains, and being aware of user intention.

æè¦ï¼<paragraph>æè¿çç ç©¶å¯¦è­è¡¨æï¼èªè¨æ¨¡å (LM) ç·¨ç¢¼è±å¯çä¸çç¥è­ï¼è¶è¶äºå®ç´çèªç¾©ï¼å¸å¼äºååé åçæ¥µå¤§éæ³¨ãç¶èï¼å¨æ¨è¦é åä¸­ï¼LM æ¯å¦é±å«ç·¨ç¢¼ä½¿ç¨èåå¥½è³è¨ä»ä¸ç¢ºå®ãèæ®éèªç¥ç¸åï¼LM åå³çµ±æ¨è¦æ¨¡åç±æ¼èªè¨åè¡çºå»ºæ¨¡ç®æ¨çå·¨å¤§å·®è·èå­¸ç¿å©åä¸åçè¡¨ç¤ºç©ºéï¼éé å·¥ä½éæ°æèéç¨®çè§£ï¼ä¸¦æ¢ç´¢ç´æ¥å¾èªè¨è¡¨ç¤ºç©ºéä¸­æåæ¨è¦ç©ºéãä»¤äººé©è¨çæ¯ï¼æåçç ç©¶çµæè¡¨æï¼ç¶å¾åé²ç LM è¡¨ç¤ºä¸­ç·æ§æ å°æï¼é ç®è¡¨ç¤ºæç¢çåªç°çæ¨è¦æè½ãæ­¤çµæè¡¨æèªè¨è¡¨ç¤ºç©ºéåææçæ¨è¦ç©ºéä¹éå­å¨åææ§ï¼éæå³èåä½è¨èç¢ºå¯¦å¯è½ç·¨ç¢¼å¨åé²ç LM ä¸­ãåéäºç ç©¶çµæçåç¼ï¼æåæåºäºä¸åç°¡å®ä½ææçååéæ¿¾ (CF) æ¨¡åï¼åçº AlphaRecï¼å®å©ç¨é ç®æå­åè³æï¼ä¾å¦æ¨é¡ï¼çèªè¨è¡¨ç¤ºï¼èä¸æ¯å³çµ±åºæ¼ ID çåµå¥ãå·é«ä¾èªªï¼AlphaRec ç±ä¸åä¸»è¦çµæé¨åçµæï¼å¤å±¤æç¥å¨ (MLP)ãåå½¢å·ç©åå°æ¯å­¸ç¿ (CL) æå¤±å½æ¸ï¼ä½¿å¶æ¥µææ¼å¯¦ä½åè¨ç·´ãæåçå¯¦è­çµæè¡¨æï¼AlphaRec å¨å¤åè³æéä¸åªæ¼é åçåºæ¼ ID ç CF æ¨¡åï¼æ¨èªèéç¨®å·ææå­åµå¥çæ¨è¦ç³»çµ±é¦æ¬¡éå°æ­¤æè½æ°´æºãæ­¤å¤ï¼AlphaRec å¼å¥äºä¸åæ°çåºæ¼èªè¨è¡¨ç¤ºç CF å¸ç¯ï¼å·æå¤é çæ³çåªé»ï¼ææ¼å¯¦ä½ãè¼éç´ãå¿«éæ¶æãå¨æ°çé åä¸­å·æåªç°çé¶æ¬¡å­¸ç¿æ¨è¦è½åï¼ä¸¦ä¸å¯ä»¥äºè§£ä½¿ç¨èçæåã</paragraph>

##### **LTLBench: Towards Benchmarks for Evaluating Temporal Logic Reasoning in Large Language Models**
2407.05434v1 by Weizhi Tang, Vaishak Belle

Temporal reasoning (TR) is a critical component of artificial intelligence,
encompassing understanding and processing temporal information and
relationships between events. To discover and study the TR ability in Large
Language Models (LLMs), various datasets have been constructed in different
ways for evaluating various aspects of TR ability. Our work proposes a novel
approach to design and develop a pipeline for constructing datasets to evaluate
the TR ability of LLMs by leveraging random directed graph generation, LTL
formula, and the NuSMV model checker. Based on the pipeline, we have also
constructed a dataset as a benchmark, namely LTLBench, consisting of 2,000 TR
challenges and evaluated six LLMs with it. Furthermore, we have conducted
additional experiments to discover the impact of increasing the number of
events and formula operators on the complexity of TR problems and the
performance of LLMs. We have demonstrated that although LLMs exhibit some
promise in handling TR challenges, they still struggle with complex TR. We
expect this work can offer insights into TR ability in LLMs while also
providing a valuable tool for future TR evaluations.

æè¦ï¼æéæ¨ç (TR) æ¯äººå·¥æºæ§çä¸é ééµçµæé¨åï¼
æ¶µèäºå°æéè³è¨åäºä»¶ä¹ééä¿ççè§£åèçãçºäºç¼ç¾åç ç©¶å¤§åèªè¨æ¨¡å (LLM) ä¸­ç TR è½åï¼å·²ééåç¨®æ¹å¼å»ºæ§åç¨®è³æéï¼ç¨æ¼è©ä¼° TR è½åçååé¢åãæåçå·¥ä½æåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼ç¨æ¼è¨­è¨åéç¼ä¸åå»ºæ§è³æéçç®¡éï¼ä»¥è©ä¼° LLM ç TR è½åï¼æ¹æ³æ¯å©ç¨é¨æ©æååçæãLTL å¬å¼å NuSMV æ¨¡åæª¢æ¥å¨ãæ ¹æéåç®¡éï¼æåéå»ºæ§äºä¸åè³æéä½çºåºæºï¼å³ LTLBenchï¼å¶ä¸­åå« 2,000 å TR ææ°ï¼ä¸¦ç¨å®è©ä¼°äºå­å LLMãæ­¤å¤ï¼æåéé²è¡äºé¡å¤çå¯¦é©ï¼ä»¥ç¼ç¾å¢å äºä»¶æ¸éåå¬å¼éç®å­å° TR åé¡è¤éæ§å LLM æè½çå½±é¿ãæåå·²ç¶è­æï¼åç®¡ LLM å¨èç TR ææ°æ¹é¢è¡¨ç¾åºä¸äºå¸æï¼ä½å®åä»ç¶é£ä»¥èçè¤éç TRãæåé æéé å·¥ä½å¯ä»¥æä¾å° LLM ä¸­ TR è½åçè¦è§£ï¼åæä¹çºæªä¾ç TR è©ä¼°æä¾ä¸åæå¹å¼çå·¥å·ã

##### **Leveraging Graph Structures to Detect Hallucinations in Large Language Models**
2407.04485v1 by Noa Nonkes, Sergei Agaronian, Evangelos Kanoulas, Roxana Petcu

Large language models are extensively applied across a wide range of tasks,
such as customer support, content creation, educational tutoring, and providing
financial guidance. However, a well-known drawback is their predisposition to
generate hallucinations. This damages the trustworthiness of the information
these models provide, impacting decision-making and user confidence. We propose
a method to detect hallucinations by looking at the structure of the latent
space and finding associations within hallucinated and non-hallucinated
generations. We create a graph structure that connects generations that lie
closely in the embedding space. Moreover, we employ a Graph Attention Network
which utilizes message passing to aggregate information from neighboring nodes
and assigns varying degrees of importance to each neighbor based on their
relevance. Our findings show that 1) there exists a structure in the latent
space that differentiates between hallucinated and non-hallucinated
generations, 2) Graph Attention Networks can learn this structure and
generalize it to unseen generations, and 3) the robustness of our method is
enhanced when incorporating contrastive learning. When evaluated against
evidence-based benchmarks, our model performs similarly without access to
search-based methods.

æè¦ï¼å¤§åèªè¨æ¨¡åå»£æ³æç¨æ¼åç¨®ä»»åä¸­ï¼ä¾å¦å®¢æ¶æ¯æ´ãå§å®¹åµä½ãæè²è¼å°åæä¾è²¡åæå°ãç¶èï¼ä¸åç¾æå¨ç¥çç¼ºé»æ¯å®åå¾åæ¼ç¢çå¹»è¦ºãéæå®³äºéäºæ¨¡åææä¾è³è¨çå¯ä¿¡åº¦ï¼å½±é¿äºæ±ºç­å¶å®åä½¿ç¨èä¿¡å¿ãæåæåºäºä¸ç¨®ééè§å¯æ½å¨ç©ºéççµæ§ä¸¦æ¾åºå¹»è¦ºåéå¹»è¦ºçæä¸­çéè¯ä¾åµæ¸¬å¹»è¦ºçæ¹æ³ãæåå»ºç«äºä¸ååå½¢çµæ§ï¼é£æ¥å¨åµå¥ç©ºéä¸­ç·å¯ç¸é£ççæãæ­¤å¤ï¼æåæ¡ç¨äºä¸ååå½¢æ³¨æåç¶²è·¯ï¼å®å©ç¨è¨æ¯å³éä¾å½ç¸½ä¾èªç¸é°ç¯é»çè³è¨ï¼ä¸¦æ ¹ææ¯åç¸é°ç¯é»çç¸éæ§çºå¶æå®ä¸åç¨åº¦çéè¦æ§ãæåçç ç©¶çµæé¡¯ç¤ºï¼1) æ½å¨ç©ºéä¸­å­å¨ä¸åçµæ§ï¼å¯ä»¥ååå¹»è¦ºåéå¹»è¦ºçæï¼2) åå½¢æ³¨æåç¶²è·¯å¯ä»¥å­¸ç¿éåçµæ§ä¸¦å°å¶æ¦æ¬å°æªè¦ççæä¸­ï¼ä»¥å 3) ç¶ç´å¥å°æ¯å­¸ç¿æï¼æåæ¹æ³çç©©å¥æ§æå¾å°å¢å¼·ãç¶æ ¹æåºæ¼è­æçåºæºé²è¡è©ä¼°æï¼æåçæ¨¡åå¨ç¡æ³åå¾åºæ¼æå°çæ¹æ³çææ³ä¸ï¼è¡¨ç¾å¾é¡ä¼¼ã

##### **AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents**
2407.04363v1 by Petr Anokhin, Nikita Semenov, Artyom Sorokin, Dmitry Evseev, Mikhail Burtsev, Evgeny Burnaev

Advancements in generative AI have broadened the potential applications of
Large Language Models (LLMs) in the development of autonomous agents. Achieving
true autonomy requires accumulating and updating knowledge gained from
interactions with the environment and effectively utilizing it. Current
LLM-based approaches leverage past experiences using a full history of
observations, summarization or retrieval augmentation. However, these
unstructured memory representations do not facilitate the reasoning and
planning essential for complex decision-making. In our study, we introduce
AriGraph, a novel method wherein the agent constructs a memory graph that
integrates semantic and episodic memories while exploring the environment. This
graph structure facilitates efficient associative retrieval of interconnected
concepts, relevant to the agent's current state and goals, thus serving as an
effective environmental model that enhances the agent's exploratory and
planning capabilities. We demonstrate that our Ariadne LLM agent, equipped with
this proposed memory architecture augmented with planning and decision-making,
effectively handles complex tasks on a zero-shot basis in the TextWorld
environment. Our approach markedly outperforms established methods such as
full-history, summarization, and Retrieval-Augmented Generation in various
tasks, including the cooking challenge from the First TextWorld Problems
competition and novel tasks like house cleaning and puzzle Treasure Hunting.

æè¦ï¼çæå¼ AI çé²æ­¥æ´å±äºå¤§åèªè¨æ¨¡å (LLM) å¨èªä¸»ä»£çéç¼ä¸­çæ½å¨æç¨ãå¯¦ç¾çæ­£çèªä¸»æ§éè¦ç´¯ç©åæ´æ°å¾èç°å¢äºåä¸­ç²å¾çç¥è­ï¼ä¸¦ææå©ç¨å®ãç¶åçåºæ¼ LLM çæ¹æ³å©ç¨éå»çç¶é©ï¼ä½¿ç¨å®æ´çè§å¯ãæè¦ææª¢ç´¢æ´åãç¶èï¼éäºéçµæ§åçè¨æ¶è¡¨å¾µä¸¦ä¸è½ä¿é²è¤éæ±ºç­å¶å®ä¸­å¿ä¸å¯å°çæ¨çåè¦åãå¨æåçç ç©¶ä¸­ï¼æåä»ç´¹äº AriGraphï¼éæ¯ä¸ç¨®æ°æ¹æ³ï¼å¶ä¸­ä»£çæ§å»ºäºä¸åè¨æ¶åï¼è©²åå¨æ¢ç´¢ç°å¢ææ´åäºèªç¾©åæç¯è¨æ¶ãéç¨®åå½¢çµæ§ä¿é²äºç¸äºè¯ç¹«çæ¦å¿µçææéè¯æ§æª¢ç´¢ï¼èä»£ççç¶åçæåç®æ¨ç¸éï¼å¾èä½çºä¸åææçç°å¢æ¨¡åï¼å¢å¼·äºä»£ççæ¢ç´¢åè¦åè½åãæåå±ç¤ºäºæåç Ariadne LLM ä»£çï¼éåäºéç¨®æè­°çè¨æ¶æ¶æ§ï¼ä¸¦å¢å¼·äºè¦ååæ±ºç­å¶å®ï¼ææå°èçäº TextWorld ç°å¢ä¸­é¶æ¬¡å­¸ç¿çè¤éä»»åãæåçåæ³é¡¯èåªæ¼å·²å»ºç«çæ¹æ³ï¼ä¾å¦å®æ´æ­·å²ãæè¦åæª¢ç´¢å¢å¼·çæï¼å¨åç¨®ä»»åä¸­ï¼åæ¬ä¾èªç¬¬ä¸å TextWorld åé¡ç«¶è³½çç¹é£ªææ°åæ¿å±æ¸æ½åæ¼åå°å¯¶ç­æ°ä»»åã

##### **Semantic Graphs for Syntactic Simplification: A Revisit from the Age of LLM**
2407.04067v1 by Peiran Yao, Kostyantyn Guzhva, Denilson Barbosa

Symbolic sentence meaning representations, such as AMR (Abstract Meaning
Representation) provide expressive and structured semantic graphs that act as
intermediates that simplify downstream NLP tasks. However, the
instruction-following capability of large language models (LLMs) offers a
shortcut to effectively solve NLP tasks, questioning the utility of semantic
graphs. Meanwhile, recent work has also shown the difficulty of using meaning
representations merely as a helpful auxiliary for LLMs. We revisit the position
of semantic graphs in syntactic simplification, the task of simplifying
sentence structures while preserving their meaning, which requires semantic
understanding, and evaluate it on a new complex and natural dataset. The
AMR-based method that we propose, AMRS$^3$, demonstrates that state-of-the-art
meaning representations can lead to easy-to-implement simplification methods
with competitive performance and unique advantages in cost, interpretability,
and generalization. With AMRS$^3$ as an anchor, we discover that syntactic
simplification is a task where semantic graphs are helpful in LLM prompting. We
propose AMRCoC prompting that guides LLMs to emulate graph algorithms for
explicit symbolic reasoning on AMR graphs, and show its potential for improving
LLM on semantic-centered tasks like syntactic simplification.

æè¦ï¼ç¬¦èå¥å­æç¾©è¡¨å¾µï¼ä¾å¦ AMRï¼æ½è±¡æç¾©è¡¨å¾µï¼ï¼æä¾è¡¨éæ§åçµæ§åçèªç¾©åè¡¨ï¼ä½çºç°¡åä¸æ¸¸ NLP ä»»åçä¸­ä»ãç¶èï¼å¤§åèªè¨æ¨¡å (LLM) çæä»¤éµå¾ªè½åæä¾äºä¸åæ·å¾ä¾ææè§£æ±º NLP ä»»åï¼è³ªçèªç¾©åè¡¨çæç¨ãåæï¼æè¿çç ç©¶ä¹è¡¨æåå°æç¾©è¡¨å¾µç¨ä½ LLM çè¼å©å·¥å·çé£åº¦ãæåéæ°å¯©è¦èªç¾©åè¡¨å¨èªæ³ç°¡åä¸­çä½ç½®ï¼èªæ³ç°¡åçä»»åæ¯å¨ä¿çå¥å­çµæ§çåæç°¡åå¥å­çµæ§ï¼ééè¦èªç¾©çè§£ï¼ä¸¦å¨ä¸åæ°çè¤éä¸èªç¶çæ¸æéä¸å°å¶é²è¡è©ä¼°ãæåæåºçåºæ¼ AMR çæ¹æ³ AMRS$^3$ è­æäºæåé²çæç¾©è¡¨å¾µå¯ä»¥å°è´ææ¼å¯¦ç¾çç°¡åæ¹æ³ï¼å¨ææ¬ãå¯è§£éæ§åæ³åæ¹é¢å·æç«¶ç­åªå¢åç¨ç¹åªå¢ãä»¥ AMRS$^3$ çºé¨é»ï¼æåç¼ç¾èªæ³ç°¡åæ¯ä¸é èªç¾©åè¡¨æå©æ¼ LLM æç¤ºçä»»åãæåæåº AMRCoC æç¤ºï¼æå° LLM æ¨¡æ¬åå½¢æ¼ç®æ³ï¼å° AMR åå½¢é²è¡æç¢ºçç¬¦èæ¨çï¼ä¸¦å±ç¤ºå¶å¨æ¹é² LLM å¨ä»¥èªç¾©çºä¸­å¿çä»»åï¼å¦èªæ³ç°¡åï¼æ¹é¢çæ½åã

##### **Functional Faithfulness in the Wild: Circuit Discovery with Differentiable Computation Graph Pruning**
2407.03779v1 by Lei Yu, Jingcheng Niu, Zining Zhu, Gerald Penn

In this paper, we introduce a comprehensive reformulation of the task known
as Circuit Discovery, along with DiscoGP, a novel and effective algorithm based
on differentiable masking for discovering circuits. Circuit discovery is the
task of interpreting the computational mechanisms of language models (LMs) by
dissecting their functions and capabilities into sparse subnetworks (circuits).
We identified two major limitations in existing circuit discovery efforts: (1)
a dichotomy between weight-based and connection-edge-based approaches forces
researchers to choose between pruning connections or weights, thereby limiting
the scope of mechanistic interpretation of LMs; (2) algorithms based on
activation patching tend to identify circuits that are neither functionally
faithful nor complete. The performance of these identified circuits is
substantially reduced, often resulting in near-random performance in isolation.
Furthermore, the complement of the circuit -- i.e., the original LM with the
identified circuit removed -- still retains adequate performance, indicating
that essential components of a complete circuits are missed by existing
methods.
  DiscoGP successfully addresses the two aforementioned issues and demonstrates
state-of-the-art faithfulness, completeness, and sparsity. The effectiveness of
the algorithm and its novel structure open up new avenues of gathering new
insights into the internal workings of generative AI.

æè¦ï¼<paragraph>å¨æ¬æä¸­ï¼æåä»ç´¹äºå°ç¨±çºé»è·¯ç¼ç¾ä»»åçå¨é¢éæ°è¡¨è¿°ï¼ä»¥å DiscoGPï¼ä¸ç¨®åºæ¼å¯å¾®é®ç½©çç¼ç¾é»è·¯çæ°ç©ä¸ææçæ¼ç®æ³ãé»è·¯ç¼ç¾æ¯ééå°å¶åè½åè½åè§£åæç¨çå­ç¶²è·¯ï¼é»è·¯ï¼ä¾è©®éèªè¨æ¨¡åï¼LMï¼çéç®æ©å¶çä»»åãæåå¨ç¾æçé»è·¯ç¼ç¾å·¥ä½ä¸­ç¼ç¾äºå©åä¸»è¦çéå¶ï¼ï¼1ï¼åºæ¼æ¬éååºæ¼é£æ¥éç·£çæ¹æ³ä¹éçäºåæ³è¿«ä½¿ç ç©¶äººå¡å¨ä¿®åªé£æ¥ææ¬éä¹éé²è¡é¸æï¼å¾èéå¶äº LM æ©å¶è©®éçç¯åï¼ï¼2ï¼åºæ¼åç¨ä¿®è£çæ¼ç®æ³å¾åæ¼è­å¥å¨åè½ä¸æ¢ä¸å¿ å¯¦ä¹ä¸å®æ´çé»è·¯ãéäºå·²è­å¥é»è·¯çæè½å¤§å¹éä½ï¼éå¸¸å°è´å­¤ç«çè¿ä¹é¨æ©æè½ãæ­¤å¤ï¼é»è·¯çè£æ¸ââå³ç§»é¤å·²è­å¥é»è·¯çåå§ LMââä»ä¿çäºè¶³å¤ çæè½ï¼éè¡¨ç¤ºç¾ææ¹æ³é¯å¤±äºå®æ´é»è·¯çåºæ¬çµæé¨åã
DiscoGP æåå°è§£æ±ºäºä¸è¿°å©ååé¡ï¼ä¸¦å±ç¤ºäºæåé²çå¿ å¯¦åº¦ãå®æ´æ§åç¨çæ§ãè©²æ¼ç®æ³çæææ§åå¶æ°ç©ççµæ§çºæ·±å¥ç­è§£çæå¼ AI çå§é¨éä½éé¢äºæ°çéå¾ã</paragraph>

##### **BACON: Supercharge Your VLM with Bag-of-Concept Graph to Mitigate Hallucinations**
2407.03314v1 by Zhantao Yang, Ruili Feng, Keyu Yan, Huangji Wang, Zhicai Wang, Shangwen Zhu, Han Zhang, Jie Xiao, Pingyu Wu, Kai Zhu, Jixuan Chen, Chen-Wei Xie, Chaojie Mao, Yue Yang, Hongyang Zhang, Yu Liu, Fan Cheng

This paper presents Bag-of-Concept Graph (BACON) to gift models with limited
linguistic abilities to taste the privilege of Vision Language Models (VLMs)
and boost downstream tasks such as detection, visual question answering (VQA),
and image generation. Since the visual scenes in physical worlds are structured
with complex relations between objects, BACON breaks down annotations into
basic minimum elements and presents them in a graph structure. Element-wise
style enables easy understanding, and structural composition liberates
difficult locating. Careful prompt design births the BACON captions with the
help of public-available VLMs and segmentation methods. In this way, we gather
a dataset with 100K annotated images, which endow VLMs with remarkable
capabilities, such as accurately generating BACON, transforming prompts into
BACON format, envisioning scenarios in the style of BACONr, and dynamically
modifying elements within BACON through interactive dialogue and more. Wide
representative experiments, including detection, VQA, and image generation
tasks, tell BACON as a lifeline to achieve previous out-of-reach tasks or excel
in their current cutting-edge solutions.

æè¦ï¼æ¬ææåº Bag-of-Concept Graph (BACON)ï¼èµäºè¯­è¨è½åæéçæ¨¡ååå°è§è§è¯­è¨æ¨¡å (VLM) çç¹æï¼å¹¶æåä¸æ¸¸ä»»å¡ï¼ä¾å¦æ£æµãè§è§é®ç­ (VQA) åå¾åçæãç±äºç©çä¸çä¸­çè§è§åºæ¯æ¯ç±å¯¹è±¡ä¹é´çå¤æå³ç³»æå»ºèæçï¼å æ­¤ BACON å°æ³¨éåè§£ä¸ºåºæ¬çæå°åç´ ï¼å¹¶ä»¥å¾å½¢ç»æåç°å®ä»¬ãåºäºåç´ çé£æ ¼ä¾¿äºçè§£ï¼ç»æåç»åè§£æ¾äºå°é¾çå®ä½ãå¨å¬å±å¯ç¨ VLM ååå²æ¹æ³çå¸®å©ä¸ï¼ç²¾å¿è®¾è®¡çæç¤ºçæäº BACON æ é¢ãéè¿è¿ç§æ¹å¼ï¼æä»¬æ¶éäºä¸ä¸ªåå« 100K å¼ æ³¨éå¾åçæ°æ®éï¼è¯¥æ°æ®éèµäº VLM æ¾èçè½åï¼ä¾å¦åç¡®çæ BACONãå°æç¤ºè½¬æ¢ä¸º BACON æ ¼å¼ãä»¥ BACONr çé£æ ¼è®¾æ³åºæ¯ï¼ä»¥åéè¿äº¤äºå¼å¯¹è¯å¨æä¿®æ¹ BACON ä¸­çåç´ ç­ç­ãå¹¿æ³çä»£è¡¨æ§å®éªï¼åæ¬æ£æµãVQA åå¾åçæä»»å¡ï¼è¡¨æ BACON ä½ä¸ºä¸æ¡çå½çº¿ï¼å¯ä»¥å®ç°ä»¥åæ æ³å®ç°çä»»å¡ï¼æå¨å½åçå°ç«¯è§£å³æ¹æ¡ä¸­è¡¨ç°åºè²ã

##### **Knowledge-based Consistency Testing of Large Language Models**
2407.12830v1 by Sai Sathiesh Rajan, Ezekiel Soremekun, Sudipta Chattopadhyay

In this work, we systematically expose and measure the inconsistency and
knowledge gaps of Large Language Models (LLMs). Specifically, we propose an
automated testing framework (called KONTEST) which leverages a knowledge graph
to construct test cases. KONTEST probes and measures the inconsistencies in the
LLM's knowledge of the world via a combination of semantically-equivalent
queries and test oracles (metamorphic or ontological oracle). KONTEST further
mitigates knowledge gaps via a weighted LLM model ensemble. Using four
state-of-the-art LLMs (Falcon, Gemini, GPT3.5, and Llama2), we show that
KONTEST generates 19.2% error inducing inputs (1917 errors from 9983 test
inputs). It also reveals a 16.5% knowledge gap across all tested LLMs.
KONTEST's mitigation method reduces LLM knowledge gap by 32.48%. Our ablation
study further shows that GPT3.5 is not suitable for knowledge-based consistency
testing because it is only 60%-68% effective in knowledge construction.

æè¦ï¼å¨éé å·¥ä½ä¸­ï¼æåç³»çµ±æ§å°æ­é²ä¸¦è¡¡éå¤§åèªè¨æ¨¡å (LLM) çä¸ä¸è´æ§åç¥è­å·®è·ãå·é«ä¾èªªï¼æåæåºäºä¸åèªååæ¸¬è©¦æ¡æ¶ (ç¨±çº KONTEST)ï¼å®å©ç¨ç¥è­åè­ä¾å»ºæ§æ¸¬è©¦æ¡ä¾ãKONTEST ééèªç¾©ç­ææ¥è©¢åæ¸¬è©¦é è¨ (è®å½¢ææ¬é«è«é è¨) ççµåä¾æ¢æ¸¬åè¡¡é LLM å°ä¸çç¥è­çä¸ä¸è´æ§ãKONTEST é²ä¸æ­¥ééå æ¬ LLM æ¨¡åéæä¾ç·©è§£ç¥è­å·®è·ãä½¿ç¨åç¨®æåé²ç LLMï¼FalconãGeminiãGPT3.5 å Llama2ï¼ï¼æåè¡¨æ KONTEST çæäº 19.2% çé¯èª¤èªç¼è¼¸å¥ï¼9983 åæ¸¬è©¦è¼¸å¥ä¸­ç 1917 åé¯èª¤ï¼ãå®éæ­ç¤ºäºæææ¸¬è©¦ç LLM ä¸­æ 16.5% çç¥è­å·®è·ãKONTEST çç·©è§£æ¹æ³å° LLM ç¥è­å·®è·æ¸å°äº 32.48%ãæåçæ¶èç ç©¶é²ä¸æ­¥è¡¨æï¼GPT3.5 ä¸é©åç¨æ¼åºæ¼ç¥è­çä¸è´æ§æ¸¬è©¦ï¼å çºå®å¨ç¥è­å»ºæ§ä¸­åªæ 60%-68% çæææ§ã

##### **GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models**
2407.02936v1 by Zike Yuan, Ming Liu, Hui Wang, Bing Qin

Evaluating the graph comprehension and reasoning abilities of Large Language
Models (LLMs) is challenging and often incomplete. Existing benchmarks focus
primarily on pure graph understanding, lacking a comprehensive evaluation
across all graph types and detailed capability definitions. This paper presents
GraCoRe, a benchmark for systematically assessing LLMs' graph comprehension and
reasoning. GraCoRe uses a three-tier hierarchical taxonomy to categorize and
test models on pure graph and heterogeneous graphs, subdividing capabilities
into 10 distinct areas tested through 19 tasks. Our benchmark includes 11
datasets with 5,140 graphs of varying complexity. We evaluated three
closed-source and seven open-source LLMs, conducting thorough analyses from
both ability and task perspectives. Key findings reveal that semantic
enrichment enhances reasoning performance, node ordering impacts task success,
and the ability to process longer texts does not necessarily improve graph
comprehension or reasoning. GraCoRe is open-sourced at
https://github.com/ZIKEYUAN/GraCoRe

æè¦ï¼è©ä¼°å¤§åèªè¨æ¨¡å (LLM) çåå½¢çè§£åæ¨çè½åå·æææ°æ§ï¼ä¸éå¸¸ä¸å®æ´ãç¾æçåºæºä¸»è¦èéæ¼ç´ç²¹çåå½¢çè§£ï¼ç¼ºä¹å°ææåå½¢é¡ååè©³ç´°åè½å®ç¾©çå¨é¢è©ä¼°ãæ¬ææåºäº GraCoReï¼ä¸åç¨æ¼ç³»çµ±è©ä¼° LLM çåå½¢çè§£åæ¨ççåºæºãGraCoRe ä½¿ç¨ä¸å±¤éå±¤åé¡æ³å°æ¨¡åé²è¡åé¡åæ¸¬è©¦ï¼å°åè½ç´°åçº 10 åä¸åçé åï¼ä¸¦éé 19 åä»»åé²è¡æ¸¬è©¦ãæåçåºæºåå« 11 åæ¸æéï¼å¶ä¸­åå« 5,140 åä¸åè¤éåº¦çåå½¢ãæåè©ä¼°äºä¸åéæºåä¸åéæº LLMï¼å¾è½ååä»»åè§åº¦é²è¡äºå¾¹åºçåæãä¸»è¦ç¼ç¾è¡¨æèªç¾©è±å¯åå¢å¼·äºæ¨çæ§è½ï¼ç¯é»æåºå½±é¿ä»»åæåï¼èèçè¼é·ææ¬çè½åä¸¦ä¸ä¸å®è½æ¹ååå½¢çè§£ææ¨çãGraCoRe å¨ https://github.com/ZIKEYUAN/GraCoRe éæº

##### **Croppable Knowledge Graph Embedding**
2407.02779v1 by Yushan Zhu, Wen Zhang, Zhiqiang Liu, Mingyang Chen, Lei Liang, Huajun Chen

Knowledge Graph Embedding (KGE) is a common method for Knowledge Graphs (KGs)
to serve various artificial intelligence tasks. The suitable dimensions of the
embeddings depend on the storage and computing conditions of the specific
application scenarios. Once a new dimension is required, a new KGE model needs
to be trained from scratch, which greatly increases the training cost and
limits the efficiency and flexibility of KGE in serving various scenarios. In
this work, we propose a novel KGE training framework MED, through which we
could train once to get a croppable KGE model applicable to multiple scenarios
with different dimensional requirements, sub-models of the required dimensions
can be cropped out of it and used directly without any additional training. In
MED, we propose a mutual learning mechanism to improve the low-dimensional
sub-models performance and make the high-dimensional sub-models retain the
capacity that low-dimensional sub-models have, an evolutionary improvement
mechanism to promote the high-dimensional sub-models to master the knowledge
that the low-dimensional sub-models can not learn, and a dynamic loss weight to
balance the multiple losses adaptively. Experiments on 3 KGE models over 4
standard KG completion datasets, 3 real application scenarios over a real-world
large-scale KG, and the experiments of extending MED to the language model BERT
show the effectiveness, high efficiency, and flexible extensibility of MED.

æè¦ï¼ç¥è­ååµå¥ (KGE) æ¯ç¥è­å (KG) ç¨æ¼æååç¨®äººå·¥æºæ§ä»»åçå¸¸è¦æ¹æ³ãåµå¥çé©ç¶ç¶­åº¦åæ±ºæ¼ç¹å®æç¨å ´æ¯çå²å­åéç®æ¢ä»¶ãä¸æ¦éè¦æ°çç¶­åº¦ï¼å°±éè¦å¾é ­è¨ç·´æ°ç KGE æ¨¡åï¼éå¤§å¤§å¢å äºè¨ç·´ææ¬ï¼ä¸¦éå¶äº KGE å¨æååç¨®å ´æ¯ä¸­çæçåéæ´»æ§ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°ç©ç KGE è¨ç·´æ¡æ¶ MEDï¼ééå®ï¼æåå¯ä»¥è¨ç·´ä¸æ¬¡ä»¥ç²å¾é©ç¨æ¼å·æä¸åç¶­åº¦éæ±çå¤åå ´æ¯çå¯è£åª KGE æ¨¡åï¼å¯ä»¥å¾ä¸­è£åªåºæéç¶­åº¦çå­æ¨¡åä¸¦ç´æ¥ä½¿ç¨ï¼èç¡éä»»ä½é¡å¤è¨ç·´ãå¨ MED ä¸­ï¼æåæåºäºä¸ç¨®ç¸äºå­¸ç¿æ©å¶ï¼ä»¥æé«ä½ç¶­å­æ¨¡åçæè½ï¼ä¸¦ä½¿é«ç¶­å­æ¨¡åä¿çä½ç¶­å­æ¨¡åå·æçè½åï¼ä¸ç¨®é²åæ¹é²æ©å¶ï¼ä»¥ä¿é²é«ç¶­å­æ¨¡åææ¡ä½ç¶­å­æ¨¡åç¡æ³å­¸ç¿çç¥è­ï¼ä»¥åä¸ç¨®åææå¤±æ¬éï¼ä»¥èªé©æå°å¹³è¡¡å¤éæå¤±ãå¨ 4 åæ¨æº KG å®æè³æéä¸ç 3 å KGE æ¨¡åãä¸åçå¯¦ä¸çå¤§è¦æ¨¡ KG ä¸ç 3 åå¯¦éæç¨å ´æ¯ä»¥åå° MED æ´å±å°èªè¨æ¨¡å BERT çå¯¦é©ä¸­ï¼å±ç¤ºäº MED çæææ§ãé«æçåéæ´»çå¯æ´åæ§ã

##### **Reasoning in Large Language Models: A Geometric Perspective**
2407.02678v1 by Romain Cosentino, Sarath Shekkizhar

The advancement of large language models (LLMs) for real-world applications
hinges critically on enhancing their reasoning capabilities. In this work, we
explore the reasoning abilities of large language models (LLMs) through their
geometrical understanding. We establish a connection between the expressive
power of LLMs and the density of their self-attention graphs. Our analysis
demonstrates that the density of these graphs defines the intrinsic dimension
of the inputs to the MLP blocks. We demonstrate through theoretical analysis
and toy examples that a higher intrinsic dimension implies a greater expressive
capacity of the LLM. We further provide empirical evidence linking this
geometric framework to recent advancements in methods aimed at enhancing the
reasoning capabilities of LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨å¯¦éæç¨ä¸­çé²å±ï¼ééµå¨æ¼æåå¶æ¨çè½åãå¨éé å·¥ä½ä¸­ï¼æåééå¤§åèªè¨æ¨¡å (LLM) çå¹¾ä½çè§£ï¼æ¢è¨å¶æ¨çè½åãæåå»ºç«äº LLM çè¡¨éè½åèå¶èªæ³¨æååå¯åº¦ä¹éçéè¯ãæåçåæè­æï¼éäºåçå¯åº¦å®ç¾©äº MLP å¡è¼¸å¥çå§å¨ç¶­åº¦ãæåééçè«åæåç©å·ç¯ä¾è­æï¼è¼é«çå§å¨ç¶­åº¦æå³è LLM å·ææ´å¤§çè¡¨éè½åãæåé²ä¸æ­¥æä¾ç¶é©è­æï¼å°éåå¹¾ä½æ¡æ¶é£çµå°æè¿å¨æ¨å¨å¢å¼· LLM æ¨çè½åçæ¹æ³ä¸­åå¾çé²å±ã

##### **Ensuring Responsible Sourcing of Large Language Model Training Data Through Knowledge Graph Comparison**
2407.02659v1 by Devam Mondal, Carlo Lipizzi

In light of recent plagiarism allegations Brough by publishers, newspapers,
and other creators of copyrighted corpora against large language model (LLM)
developers, we propose a novel system, a variant of a plagiarism detection
system, that assesses whether a knowledge source has been used in the training
or fine-tuning of a large language model. Unlike current methods, we utilize an
approach that uses Resource Description Framework (RDF) triples to create
knowledge graphs from both a source document and a LLM continuation of that
document. These graphs are then analyzed with respect to content using cosine
similarity and with respect to structure using a normalized version of graph
edit distance that shows the degree of isomorphism. Unlike traditional systems
that focus on content matching and keyword identification between a source and
target corpus, our approach enables a broader evaluation of similarity and thus
a more accurate comparison of the similarity between a source document and LLM
continuation by focusing on relationships between ideas and their organization
with regards to others. Additionally, our approach does not require access to
LLM metrics like perplexity that may be unavailable in closed large language
modeling "black-box" systems, as well as the training corpus. A prototype of
our system will be found on a hyperlinked GitHub repository.

æè¦ï¼é´äºåºçåãæ¥çº¸åå¶ä»åçæä¿æ¤è¯­æåºçåé èæè¿å¯¹å¤§åè¯­è¨æ¨¡å (LLM) å¼åèæåºçå½çªææ§ï¼æä»¬æåºäºä¸ç§æ°é¢çç³»ç»ï¼è¯¥ç³»ç»æ¯å½çªæ£æµç³»ç»çä¸ä¸ªåä½ï¼å®è¯ä¼°ç¥è¯æºæ¯å¦å·²ç¨äºå¤§åè¯­è¨æ¨¡åçè®­ç»æå¾®è°ãä¸å½åæ¹æ³ä¸åï¼æä»¬å©ç¨ä¸ç§ä½¿ç¨èµæºæè¿°æ¡æ¶ (RDF) ä¸åç»çæ¹æ³ä»æºææ¡£åè¯¥ææ¡£ç LLM å»¶ç»­ä¸­åå»ºç¥è¯å¾è°±ãç¶åä½¿ç¨ä½å¼¦ç¸ä¼¼æ§åæè¿äºå¾è°±çåå®¹ï¼å¹¶ä½¿ç¨å¾ç¼è¾è·ç¦»çæ ååçæ¬åæç»æï¼è¯¥çæ¬æ¾ç¤ºåæåº¦ãä¸ä¸æ³¨äºæºè¯­æåºåç®æ è¯­æåºä¹é´çåå®¹å¹éåå³é®è¯è¯å«çä¼ ç»ç³»ç»ä¸åï¼æä»¬çæ¹æ³è½å¤å¯¹ç¸ä¼¼æ§è¿è¡æ´å¹¿æ³çè¯ä¼°ï¼ä»èæ´åç¡®å°æ¯è¾æºææ¡£å LLM å»¶ç»­ä¹é´çç¸ä¼¼æ§ï¼æ¹æ³æ¯å³æ³¨ææ³ä¹é´çå³ç³»ä»¥åå®ä»¬ä¸å¶ä»ææ³çå³ç³»ãæ­¤å¤ï¼æä»¬çæ¹æ³ä¸éè¦è®¿é® LLM ææ ï¼ä¾å¦å°æåº¦ï¼è¿äºææ å¨å°é­çå¤§åè¯­è¨å»ºæ¨¡âé»å£å­âç³»ç»ä»¥åè®­ç»è¯­æåºä¸­å¯è½ä¸å¯ç¨ãæä»¬ç³»ç»çååå°å¨è¶é¾æ¥ç GitHub å­å¨åºä¸­æ¾å°ã

##### **Multi-Peptide: Multimodality Leveraged Language-Graph Learning of Peptide Properties**
2407.03380v1 by Srivathsan Badrinarayanan, Chakradhar Guntuboina, Parisa Mollaei, Amir Barati Farimani

Peptides are essential in biological processes and therapeutics. In this
study, we introduce Multi-Peptide, an innovative approach that combines
transformer-based language models with Graph Neural Networks (GNNs) to predict
peptide properties. We combine PeptideBERT, a transformer model tailored for
peptide property prediction, with a GNN encoder to capture both sequence-based
and structural features. By employing Contrastive Language-Image Pre-training
(CLIP), Multi-Peptide aligns embeddings from both modalities into a shared
latent space, thereby enhancing the model's predictive accuracy. Evaluations on
hemolysis and nonfouling datasets demonstrate Multi-Peptide's robustness,
achieving state-of-the-art 86.185% accuracy in hemolysis prediction. This study
highlights the potential of multimodal learning in bioinformatics, paving the
way for accurate and reliable predictions in peptide-based research and
applications.

æè¦ï¼è½å¨çç©éç¨åæ²»çä¸­è³ééè¦ãå¨æ­¤ç ç©¶ä¸­ï¼æåä»ç´¹äºå¤è½ï¼éæ¯ä¸ç¨®åµæ°çæ¹æ³ï¼çµåäºåºæ¼è½æå¨çèªè¨æ¨¡åååç¥ç¶ç¶²çµ¡ (GNN) ä¾é æ¸¬è½çæ§è³ªãæåçµåäºå°éç¨æ¼è½æ§è³ªé æ¸¬çè½æå¨æ¨¡å PeptideBERT å GNN ç·¨ç¢¼å¨ï¼ä»¥æç²åºæ¼åºååçµæ§çç¹å¾µãééæ¡ç¨å°æ¯èªè¨ååé è¨ç·´ (CLIP)ï¼å¤è½å°ä¾èªå©ç¨®æ¨¡æçåµå¥å°é½å°ä¸åå±äº«çæ½å¨ç©ºéä¸­ï¼å¾èå¢å¼·æ¨¡åçé æ¸¬æºç¢ºåº¦ãå°æº¶è¡åææ±¡æ¸æéçè©ä¼°è­æäºå¤è½çç©©å¥æ§ï¼å¨æº¶è¡é æ¸¬ä¸­å¯¦ç¾äºæåé²ç 86.185% æºç¢ºçãæ¬ç ç©¶å¼·èª¿äºçç©ä¿¡æ¯å­¸ä¸­å¤æ¨¡æå­¸ç¿çæ½åï¼çºåºæ¼è½çç ç©¶åæç¨ä¸­çæºç¢ºä¸å¯é çé æ¸¬éªå¹³äºéè·¯ã

##### **Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification**
2407.02352v1 by Pritish Sahu, Karan Sikka, Ajay Divakaran

Large Visual Language Models (LVLMs) struggle with hallucinations in visual
instruction following task(s), limiting their trustworthiness and real-world
applicability. We propose Pelican -- a novel framework designed to detect and
mitigate hallucinations through claim verification. Pelican first decomposes
the visual claim into a chain of sub-claims based on first-order predicates.
These sub-claims consist of (predicate, question) pairs and can be
conceptualized as nodes of a computational graph. We then use
Program-of-Thought prompting to generate Python code for answering these
questions through flexible composition of external tools. Pelican improves over
prior work by introducing (1) intermediate variables for precise grounding of
object instances, and (2) shared computation for answering the sub-question to
enable adaptive corrections and inconsistency identification. We finally use
reasoning abilities of LLM to verify the correctness of the the claim by
considering the consistency and confidence of the (question, answer) pairs from
each sub-claim. Our experiments reveal a drop in hallucination rate by
$\sim$8%-32% across various baseline LVLMs and a 27% drop compared to
approaches proposed for hallucination mitigation on MMHal-Bench. Results on two
other benchmarks further corroborate our results.

æè¦ï¼å¤§åè§è§è¯­è¨æ¨¡å (LVLMs) å¨è§è§æä»¤éµå¾ªä»»å¡ä¸­ä¼äº§çå¹»è§ï¼è¿éå¶äºå®ä»¬çå¯é æ§åç°å®ä¸ççéç¨æ§ãæä»¬æåºäº Pelicanââä¸ç§æ¨å¨éè¿å£°æéªè¯æ¥æ£æµååè½»å¹»è§çæ°åæ¡æ¶ãPelican é¦åæ ¹æ®ä¸é¶è°è¯å°è§è§å£°æåè§£æä¸ä¸ªå­å£°æé¾ãè¿äºå­å£°æç± (è°è¯ãé®é¢) å¯¹ç»æï¼å¯ä»¥è¢«æ¦å¿µåä¸ºè®¡ç®å¾çèç¹ãç¶åï¼æä»¬ä½¿ç¨ææ³è®¡åæç¤ºæ¥çæ Python ä»£ç ï¼éè¿å¤é¨å·¥å·ççµæ´»ç»åæ¥åç­è¿äºé®é¢ãPelican éè¿å¼å¥ (1) ç¨äºå¯¹è±¡å®ä¾ç²¾ç¡®æ¥å°çä¸­é´åéï¼ä»¥å (2) ç¨äºåç­å­é®é¢ä»¥å®ç°èªéåºæ ¡æ­£åä¸ä¸è´æ§è¯å«çå±äº«è®¡ç®ï¼æ¹è¿äºä¹åçå·¥ä½ãæä»¬æç»ä½¿ç¨ LLM çæ¨çè½åï¼éè¿èèæ¯ä¸ªå­å£°æç (é®é¢ãç­æ¡) å¯¹çä¸è´æ§åç½®ä¿¡åº¦æ¥éªè¯å£°æçæ­£ç¡®æ§ãæä»¬çå®éªè¡¨æï¼å¨åç§åºçº¿ LVLMs ä¸­ï¼å¹»è§çä¸éäºçº¦ 8%-32%ï¼ä¸ MMHal-Bench ä¸æåºçå¹»è§ç¼è§£æ¹æ³ç¸æ¯ï¼ä¸éäº 27%ãå¨å¦å¤ä¸¤ä¸ªåºåä¸çç»æè¿ä¸æ­¥è¯å®äºæä»¬çç»æã

##### **Is Your Large Language Model Knowledgeable or a Choices-Only Cheater?**
2407.01992v1 by Nishant Balepur, Rachel Rudinger

Recent work shows that large language models (LLMs) can answer
multiple-choice questions using only the choices, but does this mean that MCQA
leaderboard rankings of LLMs are largely influenced by abilities in
choices-only settings? To answer this, we use a contrast set that probes if
LLMs over-rely on choices-only shortcuts in MCQA. While previous works build
contrast sets via expensive human annotations or model-generated data which can
be biased, we employ graph mining to extract contrast sets from existing MCQA
datasets. We use our method on UnifiedQA, a group of six commonsense reasoning
datasets with high choices-only accuracy, to build an 820-question contrast
set. After validating our contrast set, we test 12 LLMs, finding that these
models do not exhibit reliance on choice-only shortcuts when given both the
question and choices. Thus, despite the susceptibility~of MCQA to high
choices-only accuracy, we argue that LLMs are not obtaining high ranks on MCQA
leaderboards just due to their ability to exploit choices-only shortcuts.

æè¦ï¼æè¿çç ç©¶è¡¨æï¼å¤§åè¯­è¨æ¨¡å (LLM) ä»ä½¿ç¨éé¡¹å°±è½åç­å¤é¡¹éæ©é¢ï¼ä½è¿æ¯å¦è¡¨ç¤ºå¤é¡¹éæ©é®ç­ (MCQA) æè¡æ¦ä¸ç LLM ä¸»è¦åéäºä»éé¡¹è®¾ç½®ä¸­çè½åï¼ä¸ºäºåç­è¿ä¸ªé®é¢ï¼æä»¬ä½¿ç¨å¯¹æ¯éæ¥æ¢æ¥ LLM å¨ MCQA ä¸­æ¯å¦è¿åº¦ä¾èµä»éé¡¹æ·å¾ãè½ç¶ååçç ç©¶éè¿æè´µçäººå·¥æ³¨éæå¯è½å­å¨åå·®çæ¨¡åçææ°æ®æ¥æå»ºå¯¹æ¯éï¼ä½æä»¬éç¨å¾ææä»ç°æ MCQA æ°æ®éä¸­æåå¯¹æ¯éãæä»¬ä½¿ç¨æä»¬çæ¹æ³å¨ UnifiedQA ä¸ï¼è¿æ¯ä¸ä¸ªç±å­ä¸ªå·æé«ä»éé¡¹åç¡®ççå¸¸è¯æ¨çæ°æ®éç»æçç»ï¼æå»ºäºä¸ä¸ª 820 é¢çå¯¹æ¯éãå¨éªè¯æä»¬çå¯¹æ¯éåï¼æä»¬æµè¯äº 12 ä¸ª LLMï¼åç°å½åæ¶ç»åºé®é¢åéé¡¹æ¶ï¼è¿äºæ¨¡åä¸ä¼è¡¨ç°åºå¯¹ä»éé¡¹æ·å¾çä¾èµãå æ­¤ï¼å°½ç®¡ MCQA å®¹æåå°é«ä»éé¡¹åç¡®ççå½±åï¼ä½æä»¬è®¤ä¸º LLM å¨ MCQA æè¡æ¦ä¸è·å¾é«æåå¹¶éä»ä»å ä¸ºå®ä»¬å©ç¨ä»éé¡¹æ·å¾çè½åã

##### **CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents**
2407.01511v1 by Tianqi Xu, Linyao Chen, Dai-Jie Wu, Yanjun Chen, Zecheng Zhang, Xiang Yao, Zhiqiang Xie, Yongchao Chen, Shilong Liu, Bochen Qian, Philip Torr, Bernard Ghanem, Guohao Li

The development of autonomous agents increasingly relies on Multimodal
Language Models (MLMs) to perform tasks described in natural language with GUI
environments, such as websites, desktop computers, or mobile phones. Existing
benchmarks for MLM agents in interactive environments are limited by their
focus on a single environment, lack of detailed and generalized evaluation
methods, and the complexities of constructing tasks and evaluators. To overcome
these limitations, we introduce Crab, the first agent benchmark framework
designed to support cross-environment tasks, incorporating a graph-based
fine-grained evaluation method and an efficient mechanism for task and
evaluator construction. Our framework supports multiple devices and can be
easily extended to any environment with a Python interface. Leveraging Crab, we
developed a cross-platform Crab Benchmark-v0 comprising 100 tasks in computer
desktop and mobile phone environments. We evaluated four advanced MLMs using
different single and multi-agent system configurations on this benchmark. The
experimental results demonstrate that the single agent with GPT-4o achieves the
best completion ratio of 35.26%. All framework code, agent code, and task
datasets are publicly available at https://github.com/camel-ai/crab.

æè¦ï¼èªä¸»ä»£ççéç¼è¶ä¾è¶ä¾è³´å¤æ¨¡æèªè¨æ¨¡å (MLM)ï¼ä»¥å¨å·æ GUI ç°å¢ï¼ä¾å¦ç¶²ç«ãæ¡ä¸åé»è¦æææ©ï¼çèªç¶èªè¨ä¸­å·è¡ä»»åãç¾æçäºåç°å¢ä¸­ MLM ä»£ççåºæºåå°ä»¥ä¸éå¶ï¼å®åå°æ³¨æ¼å®ä¸ç°å¢ãç¼ºä¹è©³ç´°ä¸éç¨çè©ä¼°æ¹æ³ï¼ä»¥åå»ºæ§ä»»ååè©ä¼°å¨çè¤éæ§ãçºäºåæéäºéå¶ï¼æåå¼å¥äº Crabï¼éæ¯ç¬¬ä¸åä»£çåºæºæ¶æ§ï¼æ¨å¨æ¯æ´è·¨ç°å¢ä»»åï¼ä¸¦çµåäºåºæ¼åå½¢çç´°ç²åº¦è©ä¼°æ¹æ³åä»»åèè©ä¼°å¨å»ºæ§çæææ©å¶ãæåçæ¶æ§æ¯æ´å¤ç¨®è£ç½®ï¼ä¸¦ä¸å¯ä»¥è¼é¬å°æ´åå°ä»»ä½å·æ Python ä»é¢çç°å¢ãå©ç¨ Crabï¼æåéç¼äºä¸åè·¨å¹³å°ç Crab Benchmark-v0ï¼å¶ä¸­åå«é»è¦æ¡ä¸åé»è¦åææ©ç°å¢ä¸­ç 100 åä»»åãæåä½¿ç¨ä¸åçå®ä¸åå¤ä»£çç³»çµ±éç½®ï¼å¨éååºæºä¸è©ä¼°äºåç¨®åé²ç MLMãå¯¦é©çµæè¡¨æï¼å·æ GPT-4o çå®ä¸ä»£çå¯¦ç¾äº 35.26% çæä½³å®æçãæææ¶æ§ç¨å¼ç¢¼ãä»£çç¨å¼ç¢¼åä»»åè³æéé½å¬éæ¼ https://github.com/camel-ai/crabã

##### **Dynamic Few-Shot Learning for Knowledge Graph Question Answering**
2407.01409v1 by Jacopo D'Abramo, Andrea Zugarini, Paolo Torroni

Large language models present opportunities for innovative Question Answering
over Knowledge Graphs (KGQA). However, they are not inherently designed for
query generation. To bridge this gap, solutions have been proposed that rely on
fine-tuning or ad-hoc architectures, achieving good results but limited
out-of-domain distribution generalization. In this study, we introduce a novel
approach called Dynamic Few-Shot Learning (DFSL). DFSL integrates the
efficiency of in-context learning and semantic similarity and provides a
generally applicable solution for KGQA with state-of-the-art performance. We
run an extensive evaluation across multiple benchmark datasets and architecture
configurations.

æè¦ï¼å¤§åèªè¨æ¨¡åçºç¥è­åè­ï¼KGQAï¼çåµæ°åç­æä¾äºæ©æãç¶èï¼å®åä¸¦éå¤©çå°±è¨­è¨ç¨æ¼æ¥è©¢çæãçºäºå½è£éä¸å·®è·ï¼å·²æåºä¾è³´æ¼å¾®èª¿æç¹å®æ¶æ§çè§£æ±ºæ¹æ¡ï¼åå¾äºè¯å¥½ççµæï¼ä½åå¤åä½æ³åè½åæéãå¨æ¬ç ç©¶ä¸­ï¼æåå¼å¥äºä¸ç¨®ç¨±çºåæå°æ¨£æ¬å­¸ç¿ï¼DFSLï¼çæ°æ¹æ³ãDFSL éæäºèªå¢å­¸ç¿åèªç¾©ç¸ä¼¼æ§çæçï¼ä¸¦çº KGQA æä¾äºä¸åæ®éé©ç¨çè§£æ±ºæ¹æ¡ï¼å·ææåé²çæ§è½ãæåå°å¤ååºæºè³æéåæ¶æ§éç½®é²è¡äºå»£æ³çè©ä¼°ã

##### **Adapting Multilingual LLMs to Low-Resource Languages with Knowledge Graphs via Adapters**
2407.01406v1 by Daniil Gurgurov, Mareike Hartmann, Simon Ostermann

This paper explores the integration of graph knowledge from linguistic
ontologies into multilingual Large Language Models (LLMs) using adapters to
improve performance for low-resource languages (LRLs) in sentiment analysis
(SA) and named entity recognition (NER). Building upon successful
parameter-efficient fine-tuning techniques, such as K-ADAPTER and MAD-X, we
propose a similar approach for incorporating knowledge from multilingual
graphs, connecting concepts in various languages with each other through
linguistic relationships, into multilingual LLMs for LRLs. Specifically, we
focus on eight LRLs -- Maltese, Bulgarian, Indonesian, Nepali, Javanese,
Uyghur, Tibetan, and Sinhala -- and employ language-specific adapters
fine-tuned on data extracted from the language-specific section of ConceptNet,
aiming to enable knowledge transfer across the languages covered by the
knowledge graph. We compare various fine-tuning objectives, including standard
Masked Language Modeling (MLM), MLM with full-word masking, and MLM with
targeted masking, to analyse their effectiveness in learning and integrating
the extracted graph data. Through empirical evaluation on language-specific
tasks, we assess how structured graph knowledge affects the performance of
multilingual LLMs for LRLs in SA and NER, providing insights into the potential
benefits of adapting language models for low-resource scenarios.

æè¦ï¼éç¯è«ææ¢è¨äºä½¿ç¨é©éå¨å°èªè¨æ¬é«è«ä¸­çåå½¢ç¥è­æ´åå°å¤èªè¨å¤§åèªè¨æ¨¡å (LLM) ä¸­ï¼ä»¥æ¹åä½è³æºèªè¨ (LRL) å¨æç·åæ (SA) åå½åå¯¦é«è¾¨è­ (NER) ä¸­çæè½ãå»ºç«å¨æåçåæ¸ææå¾®èª¿æè¡ä¸ï¼ä¾å¦ K-ADAPTER å MAD-Xï¼æåæåºäºä¸ç¨®é¡ä¼¼çæ¹æ³ï¼ç¨æ¼å°ä¾èªå¤èªè¨åå½¢ãééèªè¨éä¿å°åç¨®èªè¨ä¸­çæ¦å¿µå½¼æ­¤é£æ¥çç¥è­æ´åå° LRL çå¤èªè¨ LLM ä¸­ãå·é«ä¾èªªï¼æåå°æ³¨æ¼å«ç¨® LRLââé¦¬ç¾ä»èªãä¿å å©äºèªãå°å°¼èªãå°¼æ³ç¾èªãçªåèªãç¶­å¾ç¾èªãèèªåå§ä¼½ç¾èªââä¸¦ä½¿ç¨éå°å¾ ConceptNet çèªè¨ç¹å®é¨åä¸­èåçè³æé²è¡å¾®èª¿çèªè¨ç¹å®é©éå¨ï¼æ¨å¨è®ç¥è­å¨ç¥è­åå½¢æ¶µèçèªè¨ä¹éè½ç§»ãæåæ¯è¼äºåç¨®å¾®èª¿ç®æ¨ï¼åæ¬æ¨æºçé®ç½©èªè¨æ¨¡å (MLM)ãå¸¶æå¨è©é®ç½©ç MLM åå¸¶æç®æ¨é®ç½©ç MLMï¼ä»¥åæå®åå¨å­¸ç¿åæ´åèåçåå½¢è³ææ¹é¢çæææ§ãééå°èªè¨ç¹å®ä»»åçç¶é©è©ä¼°ï¼æåè©ä¼°äºçµæ§åçåå½¢ç¥è­å¦ä½å½±é¿å¤èªè¨ LLM å¨ SA å NER ä¸­çæè½ï¼ä¸¦æ·±å¥äºè§£äºçºä½è³æºå ´æ¯èª¿æ´èªè¨æ¨¡åçæ½å¨å¥½èã

##### **SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model**
2407.01245v1 by Lingyue Fu, Hao Guan, Kounianhua Du, Jianghao Lin, Wei Xia, Weinan Zhang, Ruiming Tang, Yasheng Wang, Yong Yu

Knowledge Tracing (KT) aims to determine whether students will respond
correctly to the next question, which is a crucial task in intelligent tutoring
systems (ITS). In educational KT scenarios, transductive ID-based methods often
face severe data sparsity and cold start problems, where interactions between
individual students and questions are sparse, and new questions and concepts
consistently arrive in the database. In addition, existing KT models only
implicitly consider the correlation between concepts and questions, lacking
direct modeling of the more complex relationships in the heterogeneous graph of
concepts and questions. In this paper, we propose a Structure-aware Inductive
Knowledge Tracing model with large language model (dubbed SINKT), which, for
the first time, introduces large language models (LLMs) and realizes inductive
knowledge tracing. Firstly, SINKT utilizes LLMs to introduce structural
relationships between concepts and constructs a heterogeneous graph for
concepts and questions. Secondly, by encoding concepts and questions with LLMs,
SINKT incorporates semantic information to aid prediction. Finally, SINKT
predicts the student's response to the target question by interacting with the
student's knowledge state and the question representation. Experiments on four
real-world datasets demonstrate that SINKT achieves state-of-the-art
performance among 12 existing transductive KT models. Additionally, we explore
the performance of SINKT on the inductive KT task and provide insights into
various modules.

æè¦ï¼ç¥è­è¿½è¹¤ (KT) æ¨å¨å¤æ·å­¸çæ¯å¦ææ­£ç¢ºåç­ä¸ä¸ååé¡ï¼éå¨æºæ§åæå­¸ç³»çµ± (ITS) ä¸­æ¯ä¸é è³ééè¦çä»»åãå¨æè² KT å ´æ¯ä¸­ï¼åºæ¼è½å° ID çæ¹æ³éå¸¸æé¢è¨å´éçè³æç¨çæ§åå·åååé¡ï¼å¶ä¸­åå¥å­¸çèåé¡ä¹éçäºåå¾ç¨å°ï¼èä¸æ°çåé¡åæ¦å¿µææçºåºç¾å¨è³æåº«ä¸­ãæ­¤å¤ï¼ç¾æç KT æ¨¡ååé±å«å°èæ®æ¦å¿µååé¡ä¹éçéè¯æ§ï¼ç¼ºä¹å°æ¦å¿µååé¡ç°è³ªåä¸­æ´è¤ééä¿çç´æ¥å»ºæ¨¡ãå¨æ¬æä¸­ï¼æåæåºäºä¸åå·æå¤§åèªè¨æ¨¡åççµæ§æç¥æ­¸ç´ç¥è­è¿½è¹¤æ¨¡å (ç¨±çº SINKT)ï¼è©²æ¨¡åé¦æ¬¡å¼å¥äºå¤§åèªè¨æ¨¡å (LLM) ä¸¦å¯¦ç¾äºæ­¸ç´ç¥è­è¿½è¹¤ãé¦åï¼SINKT å©ç¨ LLM ä¾å¼å¥æ¦å¿µä¹éççµæ§éä¿ï¼ä¸¦çºæ¦å¿µååé¡æ§å»ºä¸åç°è³ªåãå¶æ¬¡ï¼ééä½¿ç¨ LLM ç·¨ç¢¼æ¦å¿µååé¡ï¼SINKT ç´å¥äºèªç¾©è³è¨ä»¥åå©é æ¸¬ãæå¾ï¼SINKT ééèå­¸ççç¥è­çæååé¡è¡¨ç¤ºé²è¡äºåä¾é æ¸¬å­¸çå°ç®æ¨åé¡çåæãå¨ååçå¯¦ä¸çè³æéä¸çå¯¦é©è¡¨æï¼SINKT å¨ 12 åç¾æè½å° KT æ¨¡åä¸­éå°äºæåé²çæè½ãæ­¤å¤ï¼æåæ¢è¨äº SINKT å¨æ­¸ç´ KT ä»»åä¸­çæè½ï¼ä¸¦æ·±å¥äºè§£åç¨®æ¨¡çµã

##### **Revisiting Random Walks for Learning on Graphs**
2407.01214v1 by Jinwoo Kim, Olga Zaghen, Ayhan Suleymanzade, Youngmin Ryou, Seunghoon Hong

We revisit a simple idea for machine learning on graphs, where a random walk
on a graph produces a machine-readable record, and this record is processed by
a deep neural network to directly make vertex-level or graph-level predictions.
We refer to these stochastic machines as random walk neural networks, and show
that we can design them to be isomorphism invariant while capable of universal
approximation of graph functions in probability. A useful finding is that
almost any kind of record of random walk guarantees probabilistic invariance as
long as the vertices are anonymized. This enables us to record random walks in
plain text and adopt a language model to read these text records to solve graph
tasks. We further establish a parallelism to message passing neural networks
using tools from Markov chain theory, and show that over-smoothing in message
passing is alleviated by construction in random walk neural networks, while
over-squashing manifests as probabilistic under-reaching. We show that random
walk neural networks based on pre-trained language models can solve several
hard problems on graphs, such as separating strongly regular graphs where the
3-WL test fails, counting substructures, and transductive classification on
arXiv citation network without training. Code is available at
https://github.com/jw9730/random-walk.

æè¦ï¼<paragraph>æåéæ°å¯©è¦åå½¢æ©å¨å­¸ç¿çä¸åç°¡å®æ³æ³ï¼å¶ä¸­åå½¢ä¸çé¨æ©éèµ°æç¢çæ©å¨å¯è®çè¨éï¼èéåè¨éæç±æ·±åº¦ç¥ç¶ç¶²è·¯èçï¼ä»¥ç´æ¥é²è¡é é»å±¤ç´æåå½¢å±¤ç´çé æ¸¬ãæåå°éäºé¨æ©æ©å¨ç¨±çºé¨æ©éèµ°ç¥ç¶ç¶²è·¯ï¼ä¸¦å±ç¤ºæåå¯ä»¥å°å®åè¨­è¨æåæ§ä¸è®ï¼åæå·åæ©çä¸­åå½¢å½æ¸çéç¨è¿ä¼¼è½åãä¸åæç¨çç¼ç¾æ¯ï¼åªè¦é é»æ¯å¿åçï¼å¹¾ä¹ä»»ä½é¡åçé¨æ©éèµ°è¨éé½å¯ä»¥ä¿è­æ©çä¸è®æ§ãéä½¿æåè½å¤ ä»¥ç´æå­è¨éé¨æ©éèµ°ï¼ä¸¦æ¡ç¨èªè¨æ¨¡åä¾è®åéäºæå­è¨éï¼ä»¥è§£æ±ºåå½¢ä»»åãæåé²ä¸æ­¥å»ºç«äºä¸åèè¨æ¯å³éç¥ç¶ç¶²è·¯çå¹³è¡æ§ï¼ä½¿ç¨é¦¬å¯å¤«éçè«çå·¥å·ï¼ä¸¦å±ç¤ºè¨æ¯å³éä¸­çéåº¦å¹³æ»æå é¨æ©éèµ°ç¥ç¶ç¶²è·¯ä¸­çæ§é èå¾å°ç·©è§£ï¼èéåº¦å£ç¸®åè¡¨ç¾çºæ©çæ§ä¸è¶³ãæåå±ç¤ºäºåºæ¼é åè¨ç·´èªè¨æ¨¡åçé¨æ©éèµ°ç¥ç¶ç¶²è·¯å¯ä»¥è§£æ±ºåå½¢ä¸çå¹¾åå°é£åé¡ï¼ä¾å¦åé¢ 3-WL æ¸¬è©¦å¤±æçå¼·æ­£ååå½¢ãè¨ç®å­çµæ§ï¼ä»¥åå¨ arXiv å¼æç¶²è·¯ä¸­é²è¡è½å°åé¡ï¼èç¡éè¨ç·´ãç¨å¼ç¢¼å¯å¨ https://github.com/jw9730/random-walk åå¾ã</paragraph>

##### **LLM Uncertainty Quantification through Directional Entailment Graph and Claim Level Response Augmentation**
2407.00994v2 by Longchao Da, Tiejin Chen, Lu Cheng, Hua Wei

The Large language models (LLMs) have showcased superior capabilities in
sophisticated tasks across various domains, stemming from basic question-answer
(QA), they are nowadays used as decision assistants or explainers for
unfamiliar content. However, they are not always correct due to the data
sparsity in specific domain corpus, or the model's hallucination problems.
Given this, how much should we trust the responses from LLMs? This paper
presents a novel way to evaluate the uncertainty that captures the directional
instability, by constructing a directional graph from entailment probabilities,
and we innovatively conduct Random Walk Laplacian given the asymmetric property
of a constructed directed graph, then the uncertainty is aggregated by the
derived eigenvalues from the Laplacian process. We also provide a way to
incorporate the existing work's semantics uncertainty with our proposed layer.
Besides, this paper identifies the vagueness issues in the raw response set and
proposes an augmentation approach to mitigate such a problem, we conducted
extensive empirical experiments and demonstrated the superiority of our
proposed solutions.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨ååé åçè¤éä»»åä¸­å±ç¾åºåè¶çè½åï¼å¾åºæ¬çåç­ (QA) éå§ï¼å®åç¾å¨è¢«ç¨ä½æ±ºç­å©çæä¸çæå§å®¹çèªªæèãç¶èï¼å®åä¸¦ä¸ç¸½æ¯æ­£ç¢ºçï¼å çºç¹å®é åèªæåº«ä¸­çæ¸æç¨çï¼ææ¨¡åçå¹»è¦ºåé¡ãæéæ¼æ­¤ï¼æåæè©²å¤ç¸ä¿¡ LLM çåæï¼æ¬ææåºäºä¸ç¨®æ°çæ¹æ³ä¾è©ä¼°æææ¹åä¸ç©©å®æ§çä¸ç¢ºå®æ§ï¼ééå¾èæ¶µæ¦çæ§é ä¸åæååï¼ä¸¦ä¸æååµæ°å°é²è¡é¨æ©éèµ°ææ®ææ¯ç®å­ï¼çµ¦å®ä¸åæ§é çæååçä¸å°ç¨±å±¬æ§ï¼ç¶å¾ä¸ç¢ºå®æ§ç±ææ®ææ¯éç¨ä¸­çå°åºç¹å¾µå¼èåãæåéæä¾äºä¸ç¨®å°ç¾æå·¥ä½çèªç¾©ä¸ç¢ºå®æ§èæåæåºçå±¤çµåèµ·ä¾çæ¹æ³ãæ­¤å¤ï¼æ¬æè­å¥äºåå§åæéä¸­æ¨¡ç³çåé¡ï¼ä¸¦æåºäºä¸ç¨®æ´åæ¹æ³ä¾æ¸è¼éç¨®åé¡ï¼æåé²è¡äºå»£æ³çå¯¦è­å¯¦é©ï¼ä¸¦å±ç¤ºäºæåæåºçè§£æ±ºæ¹æ¡çåªè¶æ§ã

##### **Actionable Cyber Threat Intelligence using Knowledge Graphs and Large Language Models**
2407.02528v1 by Romy Fieblinger, Md Tanvirul Alam, Nidhi Rastogi

Cyber threats are constantly evolving. Extracting actionable insights from
unstructured Cyber Threat Intelligence (CTI) data is essential to guide
cybersecurity decisions. Increasingly, organizations like Microsoft, Trend
Micro, and CrowdStrike are using generative AI to facilitate CTI extraction.
This paper addresses the challenge of automating the extraction of actionable
CTI using advancements in Large Language Models (LLMs) and Knowledge Graphs
(KGs). We explore the application of state-of-the-art open-source LLMs,
including the Llama 2 series, Mistral 7B Instruct, and Zephyr for extracting
meaningful triples from CTI texts. Our methodology evaluates techniques such as
prompt engineering, the guidance framework, and fine-tuning to optimize
information extraction and structuring. The extracted data is then utilized to
construct a KG, offering a structured and queryable representation of threat
intelligence. Experimental results demonstrate the effectiveness of our
approach in extracting relevant information, with guidance and fine-tuning
showing superior performance over prompt engineering. However, while our
methods prove effective in small-scale tests, applying LLMs to large-scale data
for KG construction and Link Prediction presents ongoing challenges.

æè¦ï¼ç¶²è·¯å¨èä¸æ·æ¼è®ãå¾éçµæ§åçç¶²è·¯å¨èæå ± (CTI) è³æä¸­èåå¯æ¡åè¡åçè¦è§£ï¼å°æ¼å¼å°ç¶²è·¯å®å¨æ±ºç­è³ééè¦ãè¶ä¾è¶å¤çµç¹ï¼ä¾å¦ Microsoftãè¶¨å¢ç§æå CrowdStrikeï¼ä½¿ç¨çæå¼ AI ä¾ä¿é² CTI èåãæ¬ææ¢è¨äºä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) åç¥è­åè­ (KG) çé²å±ï¼èªåèåå¯æ¡åè¡åç CTI çææ°ãæåæ¢è¨äºæåé²çéæº LLM çæç¨ï¼åæ¬ Llama 2 ç³»åãMistral 7B Instruct å Zephyrï¼ä»¥å¾ CTI æå­ä¸­èåææç¾©çä¸åçµãæåçåæ³è©ä¼°äºæç¤ºå·¥ç¨ãæå°æ¶æ§åå¾®èª¿ç­æè¡ï¼ä»¥æä½³åè³è¨èååçµæ§åãç¶å¾ï¼å°èåçè³æç¨æ¼å»ºæ§ KGï¼æä¾å¨èæå ±ççµæ§åä¸å¯æ¥è©¢çè¡¨ç¤ºãå¯¦é©çµæè­æäºæåæ¹æ³å¨èåç¸éè³è¨æ¹é¢çæææ§ï¼æå°åå¾®èª¿é¡¯ç¤ºåºåªæ¼æç¤ºå·¥ç¨çæè½ãç¶èï¼éç¶æåçåæ³å¨å°è¦æ¨¡æ¸¬è©¦ä¸­è­æææï¼ä½å° LLM æç¨æ¼å¤§è¦æ¨¡è³æä»¥é²è¡ KG å»ºæ§åé£çµé æ¸¬ï¼ä»å­å¨æçºçææ°ã

##### **Chain-of-Knowledge: Integrating Knowledge Reasoning into Large Language Models by Learning from Knowledge Graphs**
2407.00653v1 by Yifei Zhang, Xintao Wang, Jiaqing Liang, Sirui Xia, Lida Chen, Yanghua Xiao

Large Language Models (LLMs) have exhibited impressive proficiency in various
natural language processing (NLP) tasks, which involve increasingly complex
reasoning. Knowledge reasoning, a primary type of reasoning, aims at deriving
new knowledge from existing one.While it has been widely studied in the context
of knowledge graphs (KGs), knowledge reasoning in LLMs remains underexplored.
In this paper, we introduce Chain-of-Knowledge, a comprehensive framework for
knowledge reasoning, including methodologies for both dataset construction and
model learning. For dataset construction, we create KnowReason via rule mining
on KGs. For model learning, we observe rule overfitting induced by naive
training. Hence, we enhance CoK with a trial-and-error mechanism that simulates
the human process of internal knowledge exploration. We conduct extensive
experiments with KnowReason. Our results show the effectiveness of CoK in
refining LLMs in not only knowledge reasoning, but also general reasoning
benchmarkms.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®èªç¶èªè¨èç (NLP) ä»»åä¸­å±ç¾åºé©äººçè½åï¼éäºä»»åæ¶åè¶ä¾è¶è¤éçæ¨çãç¥è­æ¨çä½çºæ¨ççä¸»è¦é¡åï¼æ¨å¨å¾æ¢æç¥è­ä¸­æ¨å°åºæ°ç¥è­ãåç®¡ç¥è­æ¨çå·²å¨ç¥è­åè­ (KG) çèæ¯ä¸å¾å°å»£æ³ç ç©¶ï¼ä½ LLM ä¸­çç¥è­æ¨çä»èæ¼æ¢ç´¢éæ®µãå¨æ¬æä¸­ï¼æåä»ç´¹äºç¥è­æ¨ççç¶åæ¡æ¶ç¥è­éï¼å¶ä¸­åæ¬ç¨æ¼è³æéæ§å»ºåæ¨¡åå­¸ç¿çæ¹æ³ãå°æ¼è³æéæ§å»ºï¼æåééå¨ KG ä¸­é²è¡è¦åææä¾å»ºç« KnowReasonãå°æ¼æ¨¡åå­¸ç¿ï¼æåè§å¯å°ç±å¤©çè¨ç·´å¼ç¼çè¦åéåº¦æ¬åãå æ­¤ï¼æåä½¿ç¨æ¨¡æ¬äººé¡å§é¨ç¥è­æ¢ç´¢éç¨çè©¦é¯æ©å¶ä¾å¢å¼· CoKãæåå° KnowReason é²è¡äºå»£æ³çå¯¦é©ãæåççµæé¡¯ç¤º CoK å¨ç²¾ç LLM ä¸åå¨ç¥è­æ¨çæ¹é¢ï¼éåæ¬ä¸è¬æ¨çåºæºæ¹é¢é½éå¸¸ææã

##### **BioKGBench: A Knowledge Graph Checking Benchmark of AI Agent for Biomedical Science**
2407.00466v1 by Xinna Lin, Siqi Ma, Junjie Shan, Xiaojing Zhang, Shell Xu Hu, Tiannan Guo, Stan Z. Li, Kaicheng Yu

Pursuing artificial intelligence for biomedical science, a.k.a. AI Scientist,
draws increasing attention, where one common approach is to build a copilot
agent driven by Large Language Models (LLMs). However, to evaluate such
systems, people either rely on direct Question-Answering (QA) to the LLM
itself, or in a biomedical experimental manner. How to precisely benchmark
biomedical agents from an AI Scientist perspective remains largely unexplored.
To this end, we draw inspiration from one most important abilities of
scientists, understanding the literature, and introduce BioKGBench. In contrast
to traditional evaluation benchmark that only focuses on factual QA, where the
LLMs are known to have hallucination issues, we first disentangle
"Understanding Literature" into two atomic abilities, i) "Understanding" the
unstructured text from research papers by performing scientific claim
verification, and ii) Ability to interact with structured Knowledge-Graph
Question-Answering (KGQA) as a form of "Literature" grounding. We then
formulate a novel agent task, dubbed KGCheck, using KGQA and domain-based
Retrieval-Augmented Generation (RAG) to identify the factual errors of existing
large-scale knowledge graph databases. We collect over two thousand data for
two atomic tasks and 225 high-quality annotated data for the agent task.
Surprisingly, we discover that state-of-the-art agents, both daily scenarios
and biomedical ones, have either failed or inferior performance on our
benchmark. We then introduce a simple yet effective baseline, dubbed BKGAgent.
On the widely used popular knowledge graph, we discover over 90 factual errors
which provide scenarios for agents to make discoveries and demonstrate the
effectiveness of our approach. The code and data are available at
https://github.com/westlake-autolab/BioKGBench.

æè¦ï¼<paragraph>è¿½æ±çç©é«å­¸ç§å­¸çäººå·¥æºæ§ï¼åç¨± AI ç§å­¸å®¶ï¼
è¶ä¾è¶åå°éæ³¨ï¼å¶ä¸­ä¸ç¨®å¸¸è¦çæ¹æ³æ¯å»ºç«ç±å¤§åèªè¨æ¨¡å (LLM) é©åçå¯é§é§ä»£çãç¶èï¼è¦è©ä¼°æ­¤é¡
ç³»çµ±ï¼äººåè¦ä¹ä¾è³´ LLM æ¬èº«çç´æ¥åç­ (QA)ï¼è¦ä¹ä¾è³´çç©é«å­¸å¯¦é©æ¹å¼ãå¦ä½å¾ AI ç§å­¸å®¶çè§åº¦ç²¾ç¢ºè©é
çç©é«å­¸ä»£çå¨å¾å¤§ç¨åº¦ä¸ä»æªæ¢ç´¢ã
çºæ­¤ï¼æåå¾ç§å­¸å®¶æéè¦çè½åä¹ä¸ï¼å³çè§£æç»ä¸­æ±²åéæï¼ä¸¦ä»ç´¹ BioKGBenchãèåéæ³¨äºå¯¦ QA çå³çµ±è©éåºæºä¸åï¼å·²ç¥ LLM å¨äºå¯¦ QA ä¸­å­å¨å¹»è¦ºåé¡ï¼æåé¦åå°
ãçè§£æç»ãåè§£çºå©ç¨®åºæ¬è½åï¼i) ééå·è¡ç§å­¸ä¸»å¼µé©è­ä¾ãçè§£ãç ç©¶è«æä¸­çéçµæ§åæå­ï¼ä»¥å ii) ä»¥ãæç»ãçºåºç¤ï¼èçµæ§åçç¥è­åè¡¨åç­ (KGQA) äºåçè½åãç¶å¾
æåä½¿ç¨ KGQA ååºæ¼ç¶²åçæª¢ç´¢æ´åç¢ç (RAG) å¶å®äºä¸é æ°ç©çä»£çä»»åï¼ç¨±çº KGCheckï¼ä»¥è­å¥ç¾æå¤§åç¥è­åè¡¨è³æåº«çäºå¯¦é¯èª¤ãæåçº
å©ååºæ¬ä»»åæ¶éäºå©åå¤åè³æï¼ä»¥å 225 åé«åè³ªè¨»è§£è³æï¼ä»¥ä½çºä»£çä»»åãä»¤äººé©è¨çæ¯ï¼æåç¼ç¾æåé²çä»£çï¼ç¡è«æ¯æ¥å¸¸æå¢éæ¯çç©é«å­¸ï¼å¨æåç
åºæºä¸é½è¡¨ç¾ä¸ä½³æè¡¨ç¾è¼å·®ãç¶å¾ï¼æåå¼å¥äºä¸åç°¡å®ä½ææçåºæºï¼ç¨±çº BKGAgentãå¨å»£æ³ä½¿ç¨çç±éç¥è­åè¡¨ä¸ï¼æåç¼ç¾è¶é 90 åäºå¯¦é¯èª¤ï¼éäºé¯èª¤çºä»£çæä¾äºç¼ç¾æå¢ï¼ä¸¦è­æäºæåæ¹æ³çæææ§ãç¨å¼ç¢¼åè³æå¯å¨
https://github.com/westlake-autolab/BioKGBench åå¾ã</paragraph>

##### **GraphArena: Benchmarking Large Language Models on Graph Computational Problems**
2407.00379v1 by Jianheng Tang, Qifan Zhang, Yuhan Li, Jia Li

The "arms race" of Large Language Models (LLMs) demands novel, challenging,
and diverse benchmarks to faithfully examine their progresses. We introduce
GraphArena, a benchmarking tool designed to evaluate LLMs on graph
computational problems using million-scale real-world graphs from diverse
scenarios such as knowledge graphs, social networks, and molecular structures.
GraphArena offers a suite of 10 computational tasks, encompassing four
polynomial-time (e.g., Shortest Distance) and six NP-complete challenges (e.g.,
Travelling Salesman Problem). It features a rigorous evaluation framework that
classifies LLM outputs as correct, suboptimal (feasible but not optimal), or
hallucinatory (properly formatted but infeasible). Evaluation of 10 leading
LLMs, including GPT-4o and LLaMA3-70B-Instruct, reveals that even
top-performing models struggle with larger, more complex graph problems and
exhibit hallucination issues. Despite the application of strategies such as
chain-of-thought prompting, these issues remain unresolved. GraphArena
contributes a valuable supplement to the existing LLM benchmarks and is
open-sourced at https://github.com/squareRoot3/GraphArena.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çãè»åç«¶è³½ãéè¦æ°ç©ãå·ææ°æ§ä¸å¤æ¨£åçåºæºä¾å¿ å¯¦æª¢é©å¶é²åº¦ãæåæ¨åº GraphArenaï¼éæ¯ä¸ååºæºå·¥å·ï¼æ¨å¨ä½¿ç¨ä¾èªç¥è­åè­ãç¤¾äº¤ç¶²è·¯ååå­çµæ§ç­å¤æ¨£åæå¢çæ¸ç¾è¬åçå¯¦ä¸çåå½¢ï¼éå°åå½¢è¨ç®åé¡è©ä¼° LLMãGraphArena æä¾ä¸ç³»å 10 åè¨ç®ä»»åï¼åå«ååå¤é å¼æéï¼ä¾å¦ï¼æç­è·é¢ï¼åå­å NP å®å¨ææ°ï¼ä¾å¦ï¼æè¡æ¨é·å¡åé¡ï¼ãå®å·æä¸åå´è¬¹çè©ä¼°æ¶æ§ï¼å° LLM è¼¸åºåé¡çºæ­£ç¢ºãæ¬¡ä½³ï¼å¯è¡ä½éæä½³ï¼æå¹»è¦ºï¼æ ¼å¼æ­£ç¢ºä½ä¸å¯è¡ï¼ãå°åæ¬ GPT-4o å LLaMA3-70B-Instruct å¨å§ç 10 åé å LLM çè©ä¼°é¡¯ç¤ºï¼å³ä½¿æ¯æè½æä½³çæ¨¡åå¨èçæ´å¤§ãæ´è¤éçåå½¢åé¡æä»æéå°å°é£ï¼ä¸¦åºç¾å¹»è¦ºåé¡ãåç®¡æç¨äºä¸ç³»åç­ç¥ï¼ä¾å¦æèéæç¤ºï¼éäºåé¡ä»æªè§£æ±ºãGraphArena çºç¾æç LLM åºæºæä¾äºæå¹å¼çè£åï¼ä¸¦å¨ https://github.com/squareRoot3/GraphArena éæºã

##### **Teola: Towards End-to-End Optimization of LLM-based Applications**
2407.00326v1 by Xin Tan, Yimin Jiang, Yitao Yang, Hong Xu

Large language model (LLM)-based applications consist of both LLM and non-LLM
components, each contributing to the end-to-end latency. Despite great efforts
to optimize LLM inference, end-to-end workflow optimization has been
overlooked. Existing frameworks employ coarse-grained orchestration with task
modules, which confines optimizations to within each module and yields
suboptimal scheduling decisions. We propose fine-grained end-to-end
orchestration, which utilizes task primitives as the basic units and represents
each query's workflow as a primitive-level dataflow graph. This explicitly
exposes a much larger design space, enables optimizations in parallelization
and pipelining across primitives of different modules, and enhances scheduling
to improve application-level performance. We build Teola, a novel orchestration
framework for LLM-based applications that implements this scheme. Comprehensive
experiments show that Teola can achieve up to 2.09x speedup over existing
systems across various popular LLM applications.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æç¨ç¨å¼ç± LLM åé LLM åä»¶çµæï¼æ¯ååä»¶é½æå½±é¿ç«¯å°ç«¯å»¶é²ãåç®¡å·²éå°æä½³å LLM æ¨è«ååºè¨±å¤åªåï¼ä½ç«¯å°ç«¯å·¥ä½æµç¨æä½³åå»é­å°å¿½ç¥ãç¾ææ¶æ§æ¡ç¨ç²ç¥çç·¨æèä»»åæ¨¡çµï¼å°æä½³åéå¶å¨æ¯åæ¨¡çµå§ï¼ä¸¦ç¢çæ¬¡ä½³çæç¨æ±ºç­ãæåæåºç´°ç·»çç«¯å°ç«¯ç·¨æï¼å®ä½¿ç¨ä»»ååèªä½çºåºæ¬å®ä½ï¼ä¸¦å°æ¯åæ¥è©¢çå·¥ä½æµç¨è¡¨ç¤ºçºåèªå±¤ç´è³ææµåãéæç¢ºå°æ­é²äºæ´å¤§çè¨­è¨ç©ºéï¼å¨ä¸åæ¨¡çµçåèªä¹éåç¨å¹³è¡ååç®¡ç·æä½³åï¼ä¸¦å å¼·æç¨ä»¥æ¹åæç¨ç¨å¼å±¤ç´æè½ãæåå»ºæ§ Teolaï¼ä¸åå¯¦ä½æ­¤æ¶æ§ç LLM æç¨ç¨å¼åµæ°ç·¨ææ¶æ§ãå¨é¢çå¯¦é©é¡¯ç¤ºï¼Teola è½å¨åç¨®ç±é LLM æç¨ç¨å¼ä¸­ï¼æ¯ç¾æç³»çµ±å¿«ä¸ 2.09 åã

##### **Into the Unknown: Generating Geospatial Descriptions for New Environments**
2406.19967v1 by Tzuf Paz-Argaman, John Palowitch, Sayali Kulkarni, Reut Tsarfaty, Jason Baldridge

Similar to vision-and-language navigation (VLN) tasks that focus on bridging
the gap between vision and language for embodied navigation, the new Rendezvous
(RVS) task requires reasoning over allocentric spatial relationships
(independent of the observer's viewpoint) using non-sequential navigation
instructions and maps. However, performance substantially drops in new
environments with no training data. Using opensource descriptions paired with
coordinates (e.g., Wikipedia) provides training data but suffers from limited
spatially-oriented text resulting in low geolocation resolution. We propose a
large-scale augmentation method for generating high-quality synthetic data for
new environments using readily available geospatial data. Our method constructs
a grounded knowledge-graph, capturing entity relationships. Sampled entities
and relations (`shop north of school') generate navigation instructions via (i)
generating numerous templates using context-free grammar (CFG) to embed
specific entities and relations; (ii) feeding the entities and relation into a
large language model (LLM) for instruction generation. A comprehensive
evaluation on RVS, showed that our approach improves the 100-meter accuracy by
45.83% on unseen environments. Furthermore, we demonstrate that models trained
with CFG-based augmentation achieve superior performance compared with those
trained with LLM-based augmentation, both in unseen and seen environments.
These findings suggest that the potential advantages of explicitly structuring
spatial information for text-based geospatial reasoning in previously unknown,
can unlock data-scarce scenarios.

æè¦ï¼é¡ä¼¼æ¼å°æ³¨æ¼å½åå·é«å°èªä¸­è¦è¦ºèèªè¨å·®è·çè¦è¦ºèªè¨å°èª (VLN) ä»»åï¼æ°çæé¢ (RVS) ä»»åéè¦ä½¿ç¨éé åºå°èªæä»¤åå°åæ¨çç°ä¸­å¿ç©ºééä¿ï¼èè§å¯èçè§é»ç¡éï¼ãç¶èï¼å¨æ²æè¨ç·´è³æçæ°ç°å¢ä¸­ï¼æè½æå¤§å¹ä¸éãä½¿ç¨èåº§æ¨éå°çéæºèªªæï¼ä¾å¦ï¼ç¶­åºç¾ç§ï¼æä¾äºè¨ç·´è³æï¼ä½ç±æ¼ç©ºéå°åæå­æéï¼å°è´å°çä½ç½®è§£æåº¦ä½ãæåæåºäºä¸ç¨®å¤§è¦æ¨¡æ´åæ¹æ³ï¼ä½¿ç¨ç¾æçå°çç©ºéè³æçºæ°ç°å¢ç¢çé«åè³ªçåæè³æãæåçå»ºæ§æ¹æ³å»ºç«äºä¸ååºç¤ç¥è­åï¼æ·åå¯¦é«éä¿ãåæ¨£çå¯¦é«åéä¿ï¼ãååºå¨å­¸æ ¡åéãï¼ééä»¥ä¸æ¹å¼ç¢çå°èªæä»¤ï¼(i) ä½¿ç¨ç¡éä¹èªå¢çææ³ (CFG) ç¢çè¨±å¤ç¯æ¬ä¾åµå¥ç¹å®å¯¦é«åéä¿ï¼(ii) å°å¯¦é«åéä¿è¼¸å¥å¤§åèªè¨æ¨¡å (LLM) ä»¥ç¢çæä»¤ãå¨ RVS ä¸çå¨é¢è©ä¼°é¡¯ç¤ºï¼æåçåæ³å°æªè¦éç°å¢ä¸­ç 100 å¬å°ºæºç¢ºåº¦æåäº 45.83%ãæ­¤å¤ï¼æåè­æä½¿ç¨åºæ¼ CFG çæ´åæè¨ç·´çæ¨¡åï¼å¨æªè¦éåè¦éç°å¢ä¸­ï¼é½æ¯ä½¿ç¨åºæ¼ LLM çæ´åæè¨ç·´çæ¨¡åç²å¾äºæ´å¥½çæè½ãéäºç¼ç¾è¡¨æï¼å¨ä»¥åæªç¥çç°å¢ä¸­ï¼æç¢ºå»ºæ§ç¨æ¼åºæ¼æå­çå°çç©ºéæ¨ççç©ºéè³è¨çæ½å¨åªå¢ï¼å¯ä»¥è§£éè³æç¨å°çå ´æ¯ã

##### **Investigating How Large Language Models Leverage Internal Knowledge to Perform Complex Reasoning**
2406.19502v1 by Miyoung Ko, Sue Hyun Park, Joonsuk Park, Minjoon Seo

Despite significant advancements, there is a limited understanding of how
large language models (LLMs) utilize knowledge for reasoning. To address this,
we propose a method that deconstructs complex real-world questions into a
graph, representing each question as a node with parent nodes of background
knowledge needed to solve the question. We develop the DepthQA dataset,
deconstructing questions into three depths: (i) recalling conceptual knowledge,
(ii) applying procedural knowledge, and (iii) analyzing strategic knowledge.
Based on a hierarchical graph, we quantify forward discrepancy, discrepancies
in LLMs' performance on simpler sub-problems versus complex questions. We also
measure backward discrepancy, where LLMs answer complex questions but struggle
with simpler ones. Our analysis shows that smaller models have more
discrepancies than larger models. Additionally, guiding models from simpler to
complex questions through multi-turn interactions improves performance across
model sizes, highlighting the importance of structured intermediate steps in
knowledge reasoning. This work enhances our understanding of LLM reasoning and
suggests ways to improve their problem-solving abilities.

æè¦ï¼åç®¡æé¡¯èçé²å±ï¼ä½å°æ¼å¤§åèªè¨æ¨¡å (LLM) å¦ä½å©ç¨ç¥è­é²è¡æ¨çççè§£ä»ç¶æéãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸ç¨®æ¹æ³ï¼å°è¤éççå¯¦ä¸çåé¡è§£æ§æä¸ååå½¢ï¼å°æ¯ååé¡è¡¨ç¤ºçºä¸åç¯é»ï¼å¶ä¸­åå«è§£æ±ºåé¡æéçèæ¯ç¥è­çç¶ç¯é»ãæåéç¼äº DepthQA è³æéï¼å°åé¡è§£æ§æä¸åæ·±åº¦ï¼(i) åæ¶æ¦å¿µç¥è­ï¼(ii) æç¨ç¨åºç¥è­ï¼ä»¥å (iii) åæç­ç¥ç¥è­ãåºæ¼ä¸åéå±¤åå½¢ï¼æåéåäºæ­£åå·®ç°ï¼LLM å¨è¼ç°¡å®çå­åé¡åè¤éåé¡ä¸çæè½å·®ç°ãæåä¹æ¸¬éäºååå·®ç°ï¼å¶ä¸­ LLM è½åç­è¤éåé¡ï¼ä½å¨è¼ç°¡å®çåé¡ä¸å»æå°é£ãæåçåæé¡¯ç¤ºï¼è¼å°çæ¨¡åæ¯è¼å¤§çæ¨¡åææ´å¤çå·®ç°ãæ­¤å¤ï¼ééå¤ååäºåå¼å°æ¨¡åå¾è¼ç°¡å®å°è¤éçåé¡ï¼å¯ä»¥æ¹åæææ¨¡åè¦æ¨¡çæè½ï¼çªé¡¯äºçµæ§åä¸­éæ­¥é©å¨ç¥è­æ¨çä¸­çéè¦æ§ãéé å·¥ä½å¢é²äºæåå° LLM æ¨çççè§£ï¼ä¸¦æåºäºæ¹åå¶åé¡è§£æ±ºè½åçæ¹æ³ã

##### **Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment**
2406.19255v1 by Hao Fei, Shengqiong Wu, Meishan Zhang, Min Zhang, Tat-Seng Chua, Shuicheng Yan

While pre-training large-scale video-language models (VLMs) has shown
remarkable potential for various downstream video-language tasks, existing VLMs
can still suffer from certain commonly seen limitations, e.g., coarse-grained
cross-modal aligning , under-modeling of temporal dynamics, detached
video-language view. In this work, we target enhancing VLMs with a fine-grained
structural spatio-temporal alignment learning method (namely Finsta). First of
all, we represent the input texts and videos with fine-grained scene graph (SG)
structures, both of which are further unified into a holistic SG (HSG) for
bridging two modalities. Then, an SG-based framework is built, where the
textual SG (TSG) is encoded with a graph Transformer, while the video dynamic
SG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for
spatial and temporal feature propagation. A spatial-temporal Gaussian
differential graph Transformer is further devised to strengthen the sense of
the changes in objects across spatial and temporal dimensions. Next, based on
the fine-grained structural features of TSG and DSG, we perform object-centered
spatial alignment and predicate-centered temporal alignment respectively,
enhancing the video-language grounding in both the spatiality and temporality.
We design our method as a plug&play system, which can be integrated into
existing well-trained VLMs for further representation augmentation, without
training from scratch or relying on SG annotations in downstream applications.
On 6 representative VL modeling tasks over 12 datasets in both standard and
long-form video scenarios, Finsta consistently improves the existing 13
strong-performing VLMs persistently, and refreshes the current state-of-the-art
end task performance significantly in both the fine-tuning and zero-shot
settings.

æè¦ï¼<paragraph>éç¶é è¨ç·´å¤§åè¦è¨èªè¨æ¨¡å (VLM) å·²å±ç¾åºå°åç¨®ä¸æ¸¸è¦è¨èªè¨ä»»åçé¡¯èæ½åï¼ä½ç¾æç VLM ä»å¯è½åå°æäºå¸¸è¦éå¶çå½±é¿ï¼ä¾å¦ç²ç²åº¦çè·¨æ¨¡æå°é½ãå°æéåæçå»ºæ¨¡ä¸è¶³ãåé¢çè¦è¨èªè¨æª¢è¦ãå¨éé å·¥ä½ä¸­ï¼æåä»¥å·åç´°ç²åº¦çµæ§åæç©ºå°é½å­¸ç¿æ¹æ³ (å³ Finsta) çå¢å¼· VLM çºç®æ¨ãé¦åï¼æåä»¥ç´°ç²åº¦çå ´æ¯å (SG) çµæ§è¡¨ç¤ºè¼¸å¥æå­åè¦è¨ï¼å©èé²ä¸æ­¥çµ±ä¸å°ä¸åæ´é« SG (HSG) ä¸­ï¼ä»¥æ©æ¥å©åæ¨¡æãç¶å¾ï¼å»ºç«ä¸ååºæ¼ SG çæ¡æ¶ï¼å¶ä¸­æå­ SG (TSG) ä½¿ç¨åå½¢ Transformer ç·¨ç¢¼ï¼èè¦è¨åæ SG (DSG) å HSG åä½¿ç¨æ°ç©çéè¿´åå½¢ Transformer å»ºæ¨¡ï¼ä»¥é²è¡ç©ºéåæéç¹å¾µå³æ­ãé²ä¸æ­¥è¨­è¨äºä¸åæç©ºé«æ¯å·®ååå½¢ Transformerï¼ä»¥å¢å¼·ç©é«å¨æç©ºç¶­åº¦ä¸­è®åçæè¦ºãæ¥ä¸ä¾ï¼æ ¹æ TSG å DSG çç´°ç²åº¦çµæ§ç¹å¾µï¼æååå¥å·è¡ä»¥ç©ä»¶çºä¸­å¿çç©ºéå°é½åä»¥è¬è©çºä¸­å¿çæåºå°é½ï¼å¢å¼·è¦è¨èªè¨å¨ç©ºéåæéä¸çåºç¤ãæåå°æ¹æ³è¨­è¨çºä¸åå³æå³ç¨çç³»çµ±ï¼å¯ä»¥æ´åå°ç¾æçè¨ç·´è¯å¥½ç VLM ä¸­ï¼ä»¥é²ä¸æ­¥æ´åè¡¨ç¤ºï¼èç¡éå¾é ­éå§è¨ç·´æä¾è³´ä¸æ¸¸æç¨ç¨å¼ä¸­ç SG æ¨è¨»ãå¨ 12 åè³æéä¸ç 6 åä»£è¡¨æ§ VL å»ºæ¨¡ä»»åä¸­ï¼ç¡è«æ¯å¨æ¨æºè¦è¨å ´æ¯éæ¯é·æ ¼å¼è¦è¨å ´æ¯ä¸­ï¼Finsta é½æçºæ¹åç¾æç 13 åæè½å¼·å¤§ç VLMï¼ä¸¦å¨å¾®èª¿åé¶æ¬¡å­¸ç¿è¨­å®ä¸­é¡¯èæ´æ°ç®åçææ°æè¡æçµä»»åæè½ã</paragraph>

##### **TrustUQA: A Trustful Framework for Unified Structured Data Question Answering**
2406.18916v1 by Wen Zhang, Long Jin, Yushan Zhu, Jiaoyan Chen, Zhiwei Huang, Junjie Wang, Yin Hua, Lei Liang, Huajun Chen

Natural language question answering (QA) over structured data sources such as
tables and knowledge graphs (KGs) have been widely investigated, for example
with Large Language Models (LLMs). The main solutions include question to
formal query parsing and retrieval-based answer generation. However, current
methods of the former often suffer from weak generalization, failing to dealing
with multiple sources simultaneously, while the later is limited in
trustfulness. In this paper, we propose UnifiedTQA, a trustful QA framework
that can simultaneously support multiple types of structured data in a unified
way. To this end, it adopts an LLM-friendly and unified knowledge
representation method called Condition Graph (CG), and uses an LLM and
demonstration-based two-level method for CG querying. For enhancement, it is
also equipped with dynamic demonstration retrieval. We have evaluated
UnifiedTQA with 5 benchmarks covering 3 types of structured data. It
outperforms 2 existing unified structured data QA methods and in comparison
with the baselines that are specific to a data type, it achieves
state-of-the-art on 2 of them. Further more, we demonstrates potential of our
method for more general QA tasks, QA over mixed structured data and QA across
structured data.

æè¦ï¼èªç¶èªè¨åç­ (QA) ééçµæ§åè³æä¾æºï¼ä¾å¦è¡¨æ ¼åç¥è­åè­ (KGs)ï¼å·²å»£æ³ç ç©¶ï¼ä¾å¦ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM)ãä¸»è¦è§£æ±ºæ¹æ¡åæ¬åé¡è½ææå½¢å¼åæ¥è©¢è§£æååºæ¼æª¢ç´¢çç­æ¡ç¢çãç¶èï¼åèçç¾è¡æ¹æ³éå¸¸æç¢çå¼±æ³åï¼ç¡æ³åæèçå¤åä¾æºï¼èå¾èååå°å¯ä¿¡åº¦çéå¶ãå¨æ¬æä¸­ï¼æåæåº UnifiedTQAï¼ä¸åå¯ä¿¡è³´ç QA æ¡æ¶ï¼è½å¤ ä»¥çµ±ä¸çæ¹å¼åææ¯æ´å¤ç¨®é¡åççµæ§åè³æãçºæ­¤ï¼å®æ¡ç¨äºä¸ç¨® LLM ååä¸çµ±ä¸çç¥è­è¡¨ç¤ºæ¹æ³ï¼ç¨±çºæ¢ä»¶å (CG)ï¼ä¸¦ä½¿ç¨ LLM ååºæ¼ç¤ºç¯çäºéæ¹æ³é²è¡ CG æ¥è©¢ãçºäºå å¼·ï¼å®ééåäºåæç¤ºç¯æª¢ç´¢ãæåå·²ç¶ä½¿ç¨æ¶µè 3 ç¨®é¡åçµæ§åè³æç 5 ååºæºè©ä¼° UnifiedTQAãå®åªæ¼ 2 ç¨®ç¾æççµ±ä¸çµæ§åè³æ QA æ¹æ³ï¼ä¸¦ä¸èç¹å®æ¼è³æé¡åçåºç·ç¸æ¯ï¼å®å¨å¶ä¸­ 2 ååºæºä¸éå°äºæåé²çæ°´å¹³ãæ­¤å¤ï¼æåå±ç¤ºäºæåçæ¹æ³å¨æ´éç¨ç QA ä»»åãæ··åçµæ§åè³æç QA åè·¨çµæ§åè³æç QA ä¸­çæ½åã

##### **Fast Optimizer Benchmark**
2406.18701v1 by Simon Blauth, Tobias BÃ¼rger, Zacharias HÃ¤ringer, JÃ¶rg Franke, Frank Hutter

In this paper, we present the Fast Optimizer Benchmark (FOB), a tool designed
for evaluating deep learning optimizers during their development. The benchmark
supports tasks from multiple domains such as computer vision, natural language
processing, and graph learning. The focus is on convenient usage, featuring
human-readable YAML configurations, SLURM integration, and plotting utilities.
FOB can be used together with existing hyperparameter optimization (HPO) tools
as it handles training and resuming of runs. The modular design enables
integration into custom pipelines, using it simply as a collection of tasks. We
showcase an optimizer comparison as a usage example of our tool. FOB can be
found on GitHub: https://github.com/automl/FOB.

æè¦ï¼å¨æ¬æä¸­ï¼æåæåºäºå¿«éåªåå¨åºæº (FOB)ï¼éæ¯ä¸åç¨æ¼å¨éç¼éç¨ä¸­è©ä¼°æ·±åº¦å­¸ç¿åªåå¨çå·¥å·ãåºæºæ¯æä¾èªå¤åé åçä»»åï¼ä¾å¦é»è¦è¦è¦ºãèªç¶èªè¨èçååå½¢å­¸ç¿ãéé»å¨æ¼æ¹ä¾¿ä½¿ç¨ï¼å·æäººé¡å¯è®ç YAML éç½®ãSLURM æ´ååç¹ªåç¨å¼ãFOB å¯ä»¥èç¾æçè¶åæ¸åªå (HPO) å·¥å·ä¸èµ·ä½¿ç¨ï¼å çºå®å¯ä»¥èçè¨ç·´åæ¢å¾©éè¡ãæ¨¡çµåè¨­è¨è½å¤ æ´åå°èªè¨ç®¡ç·ä¸­ï¼åªéå°å¶ç¨ä½ä»»åéåå³å¯ãæåå±ç¤ºäºä¸ååªåå¨æ¯è¼ä½çºæåå·¥å·çä½¿ç¨ç¯ä¾ãFOB å¯ä»¥å¾ GitHub æ¾å°ï¼https://github.com/automl/FOBã

##### **Cascading Large Language Models for Salient Event Graph Generation**
2406.18449v1 by Xingwei Tan, Yuxiang Zhou, Gabriele Pergola, Yulan He

Generating event graphs from long documents is challenging due to the
inherent complexity of multiple tasks involved such as detecting events,
identifying their relationships, and reconciling unstructured input with
structured graphs. Recent studies typically consider all events with equal
importance, failing to distinguish salient events crucial for understanding
narratives. This paper presents CALLMSAE, a CAscading Large Language Model
framework for SAlient Event graph generation, which leverages the capabilities
of LLMs and eliminates the need for costly human annotations. We first identify
salient events by prompting LLMs to generate summaries, from which salient
events are identified. Next, we develop an iterative code refinement prompting
strategy to generate event relation graphs, removing hallucinated relations and
recovering missing edges. Fine-tuning contextualised graph generation models on
the LLM-generated graphs outperforms the models trained on CAEVO-generated
data. Experimental results on a human-annotated test set show that the proposed
method generates salient and more accurate graphs, outperforming competitive
baselines.

æè¦ï¼ç±æ¼æ¶åå¤é ä»»åçå§å¨è¤éæ§ï¼ä¾å¦åµæ¸¬äºä»¶ãè­å¥å¶éä¿ï¼ä»¥åèª¿åéçµæ§åè¼¸å¥èçµæ§ååè¡¨ï¼å æ­¤å¾é·ç¯æä»¶ç¢çäºä»¶åè¡¨æ¯ä¸é ææ°ãæè¿çç ç©¶éå¸¸å°ææäºä»¶è¦çºåç­éè¦ï¼æªè½ååå°çè§£æäºè³ééè¦çé¡¯èäºä»¶ãæ¬ææåºäº CALLMSAEï¼ä¸åç¨æ¼çæé¡¯èäºä»¶åè¡¨çå±¤çå¼å¤§åèªè¨æ¨¡åæ¡æ¶ï¼å®å©ç¨äº LLM çåè½ï¼ä¸¦æ¶é¤äºå°æè²´çäººå·¥æ¨è¨»çéæ±ãæåé¦åééæç¤º LLM ç¢çæè¦ä¾è­å¥é¡¯èäºä»¶ï¼å¾ä¸­è­å¥åºé¡¯èäºä»¶ãæ¥ä¸ä¾ï¼æåéç¼äºä¸ç¨®åè¦çç¨å¼ç¢¼ç²¾çæç¤ºç­ç¥ä¾ç¢çäºä»¶éä¿åè¡¨ï¼ç§»é¤å¹»è¦ºéä¿ä¸¦æ¢å¾©éºå¤±çéç·£ãå¨ LLM çæçåè¡¨ä¸å¾®èª¿æå¢ååè¡¨çææ¨¡åï¼å¶è¡¨ç¾åªæ¼å¨ CAEVO çæçè³æä¸è¨ç·´çæ¨¡åãå¨äººå·¥æ¨è¨»çæ¸¬è©¦éä¸çå¯¦é©çµæé¡¯ç¤ºï¼ææåºçæ¹æ³ç¢çäºé¡¯èä¸æ´æºç¢ºçåè¡¨ï¼åªæ¼ç«¶ç­æ§çåºæºã

##### **Sanskrit Knowledge-based Systems: Annotation and Computational Tools**
2406.18276v1 by Hrishikesh Terdalkar

We address the challenges and opportunities in the development of knowledge
systems for Sanskrit, with a focus on question answering. By proposing a
framework for the automated construction of knowledge graphs, introducing
annotation tools for ontology-driven and general-purpose tasks, and offering a
diverse collection of web-interfaces, tools, and software libraries, we have
made significant contributions to the field of computational Sanskrit. These
contributions not only enhance the accessibility and accuracy of Sanskrit text
analysis but also pave the way for further advancements in knowledge
representation and language processing. Ultimately, this research contributes
to the preservation, understanding, and utilization of the rich linguistic
information embodied in Sanskrit texts.

æè¦ï¼æåèæè§£æ±ºæ¢µèªç¥è­ç³»çµ±éç¼ä¸­çææ°åæ©æï¼éé»å¨æ¼åé¡è§£ç­ãééæåºä¸åç¨æ¼èªåå»ºæ§ç¥è­åè­çæ¶æ§ï¼å°å¥ç¨æ¼æ¬é«é©ååä¸è¬ç¨éä»»åçè¨»è§£å·¥å·ï¼ä¸¦æä¾å¤æ¨£åçç¶²è·¯ä»é¢ãå·¥å·åè»é«å½å¼åº«ï¼æåå°è¨ç®æ¢µèªé åååºäºéå¤§è²¢ç»ãéäºè²¢ç»ä¸åå¢å¼·äºæ¢µèªææ¬åæçå¯å­åæ§åæºç¢ºæ§ï¼ä¹çºç¥è­è¡¨å¾µåèªè¨èççé²ä¸æ­¥é²å±éªå¹³äºéè·¯ãæçµï¼éé ç ç©¶æå©æ¼ä¿å­ãçè§£åå©ç¨æ¢µèªææ¬ä¸­èå«çè±å¯èªè¨è³è¨ã

##### **Multilingual Knowledge Graph Completion from Pretrained Language Models with Knowledge Constraints**
2406.18085v1 by Ran Song, Shizhu He, Shengxiang Gao, Li Cai, Kang Liu, Zhengtao Yu, Jun Zhao

Multilingual Knowledge Graph Completion (mKGC) aim at solving queries like
(h, r, ?) in different languages by reasoning a tail entity t thus improving
multilingual knowledge graphs. Previous studies leverage multilingual
pretrained language models (PLMs) and the generative paradigm to achieve mKGC.
Although multilingual pretrained language models contain extensive knowledge of
different languages, its pretraining tasks cannot be directly aligned with the
mKGC tasks. Moreover, the majority of KGs and PLMs currently available exhibit
a pronounced English-centric bias. This makes it difficult for mKGC to achieve
good results, particularly in the context of low-resource languages. To
overcome previous problems, this paper introduces global and local knowledge
constraints for mKGC. The former is used to constrain the reasoning of answer
entities, while the latter is used to enhance the representation of query
contexts. The proposed method makes the pretrained model better adapt to the
mKGC task. Experimental results on public datasets demonstrate that our method
outperforms the previous SOTA on Hits@1 and Hits@10 by an average of 12.32% and
16.03%, which indicates that our proposed method has significant enhancement on
mKGC.

æè¦ï¼å¤èªè¨ç¥è­åè­å®æ (mKGC) æ¨å¨ééæ¨çå°¾é¨å¯¦é« t ä¾è§£æ±ºä¸åèªè¨ä¸­çæ¥è©¢ï¼ä¾å¦ (h, r, ?)ï¼é²èæ¹åå¤èªè¨ç¥è­åè­ãååçç ç©¶å©ç¨å¤èªè¨é è¨ç·´èªè¨æ¨¡å (PLM) åçæç¯ä¾ä¾éæ mKGCãåç®¡å¤èªè¨é è¨ç·´èªè¨æ¨¡ååå«ä¸åèªè¨çå»£æ³ç¥è­ï¼ä½å¶é è¨ç·´ä»»åç¡æ³ç´æ¥è mKGC ä»»åå°é½ãæ­¤å¤ï¼ç®åå¤§å¤æ¸çç¥è­åè­å PLM é½å±ç¾åºæé¡¯çè±èªä¸­å¿åèª¤ãéä½¿å¾ mKGC é£ä»¥éæè¯å¥½ççµæï¼ç¹å¥æ¯å¨ä½è³æºèªè¨çèçµ¡ä¸­ãçºäºåæååçåé¡ï¼æ¬æéå° mKGC å¼å¥äºå¨åèå±é¨ç¥è­éå¶ãåèç¨æ¼éå¶ç­æ¡å¯¦é«çæ¨çï¼èå¾èç¨æ¼å å¼·æ¥è©¢èçµ¡çè¡¨ç¤ºãææåºçæ¹æ³ä½¿å¾é è¨ç·´æ¨¡åè½æ´å¥½å°é©æ mKGC ä»»åãå¬éè³æéä¸çå¯¦é©çµæé¡¯ç¤ºï¼æåçæ¨¡åå¨ Hits@1 å Hits@10 ä¸å¹³ååªæ¼ååç SOTA 12.32% å 16.03%ï¼éè¡¨ç¤ºæåæåºçæ¹æ³é¡¯èå°å¢å¼·äº mKGCã

##### **AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for Memory-Efficient Large Language Models Fine-Tuning**
2406.18060v1 by Yifan Yang, Kai Zhen, Ershad Banijamal, Athanasios Mouchtaris, Zheng Zhang

Fine-tuning large language models (LLMs) has achieved remarkable performance
across various natural language processing tasks, yet it demands more and more
memory as model sizes keep growing. To address this issue, the recently
proposed Memory-efficient Zeroth-order (MeZO) methods attempt to fine-tune LLMs
using only forward passes, thereby avoiding the need for a backpropagation
graph. However, significant performance drops and a high risk of divergence
have limited their widespread adoption. In this paper, we propose the Adaptive
Zeroth-order Tensor-Train Adaption (AdaZeta) framework, specifically designed
to improve the performance and convergence of the ZO methods. To enhance
dimension-dependent ZO estimation accuracy, we introduce a fast-forward,
low-parameter tensorized adapter. To tackle the frequently observed divergence
issue in large-scale ZO fine-tuning tasks, we propose an adaptive query number
schedule that guarantees convergence. Detailed theoretical analysis and
extensive experimental results on Roberta-Large and Llama-2-7B models
substantiate the efficacy of our AdaZeta framework in terms of accuracy, memory
efficiency, and convergence speed.

æè¦ï¼å¾®è°å¤§åè¯­è¨æ¨¡å (LLM) å¨åç§èªç¶è¯­è¨å¤çä»»å¡ä¸­åå¾äºæ¾èçæ§è½ï¼ä½éçæ¨¡åè§æ¨¡çä¸æ­æ©å¤§ï¼å®å¯¹åå­çéæ±ä¹è¶æ¥è¶å¤§ãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æè¿æåºçåå­é«æé¶é¶ (MeZO) æ¹æ³è¯å¾ä»ä½¿ç¨ååä¼ éæ¥å¾®è° LLMï¼ä»èé¿åäºå¯¹ååä¼ æ­å¾çéæ±ãç¶èï¼ä¸¥éçæ§è½ä¸éååæ£çé«é£é©éå¶äºå®ä»¬çå¹¿æ³éç¨ãå¨æ¬æä¸­ï¼æä»¬æåºäºèªéåºé¶é¶å¼ éè®­ç»èªéåº (AdaZeta) æ¡æ¶ï¼ä¸é¨è®¾è®¡ç¨äºæé« ZO æ¹æ³çæ§è½åæ¶ææ§ãä¸ºäºå¢å¼ºç»´åº¦ç¸å³ç ZO ä¼°è®¡ç²¾åº¦ï¼æä»¬å¼å¥äºä¸ä¸ªå¿«éååãä½åæ°å¼ éåééå¨ãä¸ºäºè§£å³å¨å¤§è§æ¨¡ ZO å¾®è°ä»»å¡ä¸­ç»å¸¸è§å¯å°çåæ£é®é¢ï¼æä»¬æåºäºä¸ä¸ªèªéåºæ¥è¯¢æ°éè®¡åï¼ä»¥ä¿è¯æ¶ææ§ãå¯¹ Roberta-Large å Llama-2-7B æ¨¡åçè¯¦ç»çè®ºåæåå¹¿æ³çå®éªç»æè¯æäºæä»¬ç AdaZeta æ¡æ¶å¨åç¡®æ§ãåå­æçåæ¶æéåº¦æ¹é¢çæææ§ã

##### **DARG: Dynamic Evaluation of Large Language Models via Adaptive Reasoning Graph**
2406.17271v1 by Zhehao Zhang, Jiaao Chen, Diyi Yang

The current paradigm of evaluating Large Language Models (LLMs) through
static benchmarks comes with significant limitations, such as vulnerability to
data contamination and a lack of adaptability to the evolving capabilities of
LLMs. Therefore, evaluation methods that can adapt and generate evaluation data
with controlled complexity are urgently needed. In this work, we introduce
Dynamic Evaluation of LLMs via Adaptive Reasoning Graph Evolvement (DARG) to
dynamically extend current benchmarks with controlled complexity and diversity.
Specifically, we first extract the reasoning graphs of data points in current
benchmarks and then perturb the reasoning graphs to generate novel testing
data. Such newly generated test samples can have different levels of complexity
while maintaining linguistic diversity similar to the original benchmarks. We
further use a code-augmented LLM to ensure the label correctness of newly
generated data. We apply our DARG framework to diverse reasoning tasks in four
domains with 15 state-of-the-art LLMs. Experimental results show that almost
all LLMs experience a performance decrease with increased complexity and
certain LLMs exhibit significant drops. Additionally, we find that LLMs exhibit
more biases when being evaluated via the data generated by DARG with higher
complexity levels. These observations provide useful insights into how to
dynamically and adaptively evaluate LLMs. The code is available at
https://github.com/SALT-NLP/DARG.

æè¦ï¼ç®åéééæåºæºè©ä¼°å¤§åèªè¨æ¨¡å (LLM) çç¯ä¾ä¼´é¨èé¡¯èçéå¶ï¼ä¾å¦å®¹æåå°è³ææ±¡æï¼ä»¥åç¼ºä¹é©æ LLM ä¸æ·æ¼é²çè½åãå æ­¤ï¼è¿«åéè¦è½å¤ é©æä¸¦ç¢çå·æåæ§è¤éæ§çè©ä¼°è³æçè©ä¼°æ¹æ³ãå¨éé å·¥ä½ä¸­ï¼æåééèªé©ææ¨çåå½¢æ¼å (DARG) å¼å¥ LLM çåæè©ä¼°ï¼ä»¥åæå»¶ä¼¸ç®åå·æåæ§è¤éæ§åå¤æ¨£æ§çåºæºãå·é«ä¾èªªï¼æåé¦åæ·åç®ååºæºä¸­è³æé»çæ¨çåå½¢ï¼ç¶å¾æ¾åæ¨çåå½¢ä»¥ç¢çæ°çæ¸¬è©¦è³æãéäºæ°ç¢ççæ¸¬è©¦æ¨£æ¬å¯ä»¥æä¸åçè¤éæ§å±¤ç´ï¼åæç¶­æèåå§åºæºé¡ä¼¼çèªè¨å¤æ¨£æ§ãæåé²ä¸æ­¥ä½¿ç¨ç¨å¼ç¢¼å¢å¼·ç LLM ä¾ç¢ºä¿æ°ç¢çè³æçæ¨ç±¤æ­£ç¢ºæ§ãæåå° DARG æ¶æ§å¥ç¨æ¼ååé åä¸­çåç¨®æ¨çä»»åï¼ä¸¦ä½¿ç¨ 15 åæåé²ç LLMãå¯¦é©çµæé¡¯ç¤ºï¼å¹¾ä¹ææ LLM å¨è¤éæ§å¢å çææ³ä¸é½æåºç¾æè½ä¸éï¼èæäº LLM åè¡¨ç¾åºé¡¯èçä¸éãæ­¤å¤ï¼æåç¼ç¾ LLM å¨éé DARG ç¢çå·æè¼é«è¤éæ§å±¤ç´çè³æé²è¡è©ä¼°æï¼æè¡¨ç¾åºæ´å¤åå·®ãéäºè§å¯çµææä¾äºæç¨çè¦è§£ï¼èªªæå¦ä½åæä¸èªé©æå°è©ä¼° LLMãç¨å¼ç¢¼å¯å¨ https://github.com/SALT-NLP/DARG åå¾ã

##### **CogMG: Collaborative Augmentation Between Large Language Model and Knowledge Graph**
2406.17231v1 by Tong Zhou, Yubo Chen, Kang Liu, Jun Zhao

Large language models have become integral to question-answering applications
despite their propensity for generating hallucinations and factually inaccurate
content. Querying knowledge graphs to reduce hallucinations in LLM meets the
challenge of incomplete knowledge coverage in knowledge graphs. On the other
hand, updating knowledge graphs by information extraction and knowledge graph
completion faces the knowledge update misalignment issue. In this work, we
introduce a collaborative augmentation framework, CogMG, leveraging knowledge
graphs to address the limitations of LLMs in QA scenarios, explicitly targeting
the problems of incomplete knowledge coverage and knowledge update
misalignment. The LLMs identify and decompose required knowledge triples that
are not present in the KG, enriching them and aligning updates with real-world
demands. We demonstrate the efficacy of this approach through a supervised
fine-tuned LLM within an agent framework, showing significant improvements in
reducing hallucinations and enhancing factual accuracy in QA responses. Our
code and video are publicly available.

æè¦ï¼å¤§åèªè¨æ¨¡åå·²æçºåç­æç¨ç¨å¼ä¸­ä¸å¯æç¼ºçä¸é¨åï¼åç®¡å®åå¾åæ¼ç¢çå¹»è¦ºåäºå¯¦ä¸æ­£ç¢ºçå§å®¹ãæ¥è©¢ç¥è­åè¡¨ä»¥æ¸å° LLM ä¸­çå¹»è¦ºæéå°ç¥è­åè¡¨ä¸­ç¥è­è¦èä¸å®æ´çææ°ãå¦ä¸æ¹é¢ï¼ééè³è¨èååç¥è­åè¡¨å®æä¾æ´æ°ç¥è­åè¡¨æé¢è¨ç¥è­æ´æ°é¯ä½åé¡ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºåä½æ´åæ¶æ§ CogMGï¼å©ç¨ç¥è­åè¡¨ä¾è§£æ±º LLM å¨ QA å ´æ¯ä¸­çéå¶ï¼æç¢ºéå°ä¸å®æ´çç¥è­è¦èåç¥è­æ´æ°é¯ä½åé¡ãLLM è­å¥ä¸¦åè§£ KG ä¸­ä¸å­å¨çæéç¥è­ä¸åçµï¼è±å¯å®åä¸¦å°æ´æ°èç¾å¯¦ä¸ççéæ±ä¿æä¸è´ãæåééä»£çæ¶æ§ä¸­ç£ç£å¾®èª¿ç LLM å±ç¤ºäºéç¨®æ¹æ³çåæï¼é¡¯ç¤ºåºå¨æ¸å°å¹»è¦ºåå¢å¼· QA åæä¸­çäºå¯¦æºç¢ºæ§æ¹é¢æé¡¯èçæ¹é²ãæåçç¨å¼ç¢¼åå½±çå¬éæä¾ã

##### **Link Prediction with Untrained Message Passing Layers**
2406.16687v1 by Lisi Qarkaxhija, Anatol E. Wegner, Ingo Scholtes

Message passing neural networks (MPNNs) operate on graphs by exchanging
information between neigbouring nodes. MPNNs have been successfully applied to
various node-, edge-, and graph-level tasks in areas like molecular science,
computer vision, natural language processing, and combinatorial optimization.
However, most MPNNs require training on large amounts of labeled data, which
can be costly and time-consuming. In this work, we explore the use of various
untrained message passing layers in graph neural networks, i.e. variants of
popular message passing architecture where we remove all trainable parameters
that are used to transform node features in the message passing step. Focusing
on link prediction, we find that untrained message passing layers can lead to
competitive and even superior performance compared to fully trained MPNNs,
especially in the presence of high-dimensional features. We provide a
theoretical analysis of untrained message passing by relating the inner
products of features implicitly produced by untrained message passing layers to
path-based topological node similarity measures. As such, untrained message
passing architectures can be viewed as a highly efficient and interpretable
approach to link prediction.

æè¦ï¼è¨æ¯å³éç¥ç¶ç¶²è·¯ (MPNN) ééäº¤æé°è¿ç¯é»ä¹éçè³è¨ä¾èçåå½¢ãMPNN å·²æåæç¨æ¼åç¨®ç¯é»ãéç·£ååå½¢å±¤ç´çä»»åï¼ä¾å¦åå­ç§å­¸ãé»è¦è¦è¦ºãèªç¶èªè¨èçåçµåæä½³åãç¶èï¼å¤§å¤æ¸ MPNN éè¦å¤§éæ¨ç±¤è³ææè½é²è¡è¨ç·´ï¼éå¯è½æå¾æè²´ä¸èæãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨äºå¨åå½¢ç¥ç¶ç¶²è·¯ä¸­ä½¿ç¨åç¨®æªè¨ç·´çè¨æ¯å³éå±¤ï¼ä¹å°±æ¯èªªï¼æåç§»é¤äºææç¨æ¼å¨è¨æ¯å³éæ­¥é©ä¸­è½æç¯é»ç¹å¾µçå¯è¨ç·´åæ¸ï¼éæ¯ç±éè¨æ¯å³éæ¶æ§çè®é«ãå°æ³¨æ¼é£çµé æ¸¬ï¼æåç¼ç¾æªè¨ç·´çè¨æ¯å³éå±¤å¯ä»¥ç¢çå·æç«¶ç­åï¼çè³åªæ¼å®å¨è¨ç·´ç MPNN çæè½ï¼å°¤å¶æ¯å¨å­å¨é«ç¶­ç¹å¾µçææ³ä¸ãæåééå°æªè¨ç·´çè¨æ¯å³éå±¤é±å«ç¢ççç¹å¾µçå§ç©èåºæ¼è·¯å¾çææ²ç¯é»ç¸ä¼¼åº¦æ¸¬ééè¯ï¼æä¾æªè¨ç·´è¨æ¯å³éççè«åæãå æ­¤ï¼æªè¨ç·´çè¨æ¯å³éæ¶æ§å¯ä»¥è¦çºä¸ç¨®é«åº¦ææä¸å¯è§£éçé£çµé æ¸¬æ¹æ³ã

##### **CLEAR: Can Language Models Really Understand Causal Graphs?**
2406.16605v1 by Sirui Chen, Mengying Xu, Kun Wang, Xingyu Zeng, Rui Zhao, Shengjie Zhao, Chaochao Lu

Causal reasoning is a cornerstone of how humans interpret the world. To model
and reason about causality, causal graphs offer a concise yet effective
solution. Given the impressive advancements in language models, a crucial
question arises: can they really understand causal graphs? To this end, we
pioneer an investigation into language models' understanding of causal graphs.
Specifically, we develop a framework to define causal graph understanding, by
assessing language models' behaviors through four practical criteria derived
from diverse disciplines (e.g., philosophy and psychology). We then develop
CLEAR, a novel benchmark that defines three complexity levels and encompasses
20 causal graph-based tasks across these levels. Finally, based on our
framework and benchmark, we conduct extensive experiments on six leading
language models and summarize five empirical findings. Our results indicate
that while language models demonstrate a preliminary understanding of causal
graphs, significant potential for improvement remains. Our project website is
at https://github.com/OpenCausaLab/CLEAR.

æè¦ï¼å ææ¨çæ¯äººé¡è©®éä¸ççåºç³ãçºäºå°å æéä¿å»ºæ¨¡åæ¨çï¼å æåæä¾äºä¸åç°¡æ½èææçè§£æ±ºæ¹æ¡ãéæ¼èªè¨æ¨¡åçé©äººé²æ­¥ï¼ä¸åééµåé¡åºç¾äºï¼å®åççè½çè§£å æååï¼çºæ­¤ï¼æåçåå°èªè¨æ¨¡åå°å æåççè§£é²è¡äºèª¿æ¥ãå·é«ä¾èªªï¼æåéç¼äºä¸åæ¡æ¶ä¾å®ç¾©å æåçè§£ï¼ééå¾ä¸åå­¸ç§ï¼ä¾å¦å²å­¸åå¿çå­¸ï¼è¡ççååå¯¦ç¨æ¨æºä¾è©ä¼°èªè¨æ¨¡åçè¡çºãç¶å¾ï¼æåéç¼äº CLEARï¼ä¸åæ°çåºæºï¼å®å®ç¾©äºä¸åè¤éæ§ç´å¥ï¼ä¸¦æ¶µèäºéäºç´å¥ä¸­ç 20 ååºæ¼å æåçä»»åãæå¾ï¼åºæ¼æåçæ¡æ¶ååºæºï¼æåå°å­åé åçèªè¨æ¨¡åé²è¡äºå»£æ³çå¯¦é©ï¼ä¸¦ç¸½çµäºäºé å¯¦è­ç¼ç¾ãæåççµæè¡¨æï¼åç®¡èªè¨æ¨¡åå±ç¤ºäºå°å æåçåæ­¥çè§£ï¼ä½ä»æå¾å¤§çæ¹é²æ½åãæåçé ç®ç¶²ç«ä½æ¼ https://github.com/OpenCausaLab/CLEARã

##### **KEHRL: Learning Knowledge-Enhanced Language Representations with Hierarchical Reinforcement Learning**
2406.16374v1 by Dongyang Li, Taolin Zhang, Longtao Huang, Chengyu Wang, Xiaofeng He, Hui Xue

Knowledge-enhanced pre-trained language models (KEPLMs) leverage relation
triples from knowledge graphs (KGs) and integrate these external data sources
into language models via self-supervised learning. Previous works treat
knowledge enhancement as two independent operations, i.e., knowledge injection
and knowledge integration. In this paper, we propose to learn
Knowledge-Enhanced language representations with Hierarchical Reinforcement
Learning (KEHRL), which jointly addresses the problems of detecting positions
for knowledge injection and integrating external knowledge into the model in
order to avoid injecting inaccurate or irrelevant knowledge. Specifically, a
high-level reinforcement learning (RL) agent utilizes both internal and prior
knowledge to iteratively detect essential positions in texts for knowledge
injection, which filters out less meaningful entities to avoid diverting the
knowledge learning direction. Once the entity positions are selected, a
relevant triple filtration module is triggered to perform low-level RL to
dynamically refine the triples associated with polysemic entities through
binary-valued actions. Experiments validate KEHRL's effectiveness in probing
factual knowledge and enhancing the model's performance on various natural
language understanding tasks.

æè¦ï¼ç¥è­å¢å¼·é è¨ç·´èªè¨æ¨¡å (KEPLM) å©ç¨ç¥è­åè­ (KG) ä¸­çéè¯ä¸åçµï¼ä¸¦ééèªæç£ç£å¼å­¸ç¿å°éäºå¤é¨è³æä¾æºæ´åå°èªè¨æ¨¡åä¸­ãååçç ç©¶å°ç¥è­å¢å¼·è¦çºå©åç¨ç«çæä½ï¼å³ç¥è­æ³¨å¥åç¥è­æ´åãå¨æ¬æä¸­ï¼æåå»ºè­°ä½¿ç¨åå±¤å¼·åå­¸ç¿ (KEHRL) å­¸ç¿ç¥è­å¢å¼·èªè¨è¡¨å¾µï¼éå±åè§£æ±ºäºåµæ¸¬ç¥è­æ³¨å¥ä½ç½®åå°å¤é¨ç¥è­æ´åå°æ¨¡åä¸­çåé¡ï¼ä»¥é¿åæ³¨å¥ä¸æºç¢ºæä¸ç¸éçç¥è­ãå·é«ä¾èªªï¼é«éå¼·åå­¸ç¿ (RL) ä»£çä½¿ç¨å§é¨ååé©ç¥è­ï¼åè¦åµæ¸¬æå­ä¸­ç¥è­æ³¨å¥çéè¦ä½ç½®ï¼éæéæ¿¾æè¼ä¸éè¦çå¯¦é«ï¼ä»¥é¿åè½ç§»ç¥è­å­¸ç¿æ¹åãä¸æ¦é¸å®å¯¦é«ä½ç½®ï¼å°±æè§¸ç¼ç¸éçä¸åçµéæ¿¾æ¨¡çµï¼ééäºé²å¶åä½åæç²¾çèå¤ç¾©å¯¦é«ç¸éçä¸åçµãå¯¦é©é©è­äº KEHRL å¨æ¢æ¥äºå¯¦ç¥è­åå¢å¼·æ¨¡åå¨åç¨®èªç¶èªè¨çè§£ä»»åä¸çæè½ã

##### **Prompt-Consistency Image Generation (PCIG): A Unified Framework Integrating LLMs, Knowledge Graphs, and Controllable Diffusion Models**
2406.16333v1 by Yichen Sun, Zhixuan Chu, Zhan Qin, Kui Ren

The rapid advancement of Text-to-Image(T2I) generative models has enabled the
synthesis of high-quality images guided by textual descriptions. Despite this
significant progress, these models are often susceptible in generating contents
that contradict the input text, which poses a challenge to their reliability
and practical deployment. To address this problem, we introduce a novel
diffusion-based framework to significantly enhance the alignment of generated
images with their corresponding descriptions, addressing the inconsistency
between visual output and textual input. Our framework is built upon a
comprehensive analysis of inconsistency phenomena, categorizing them based on
their manifestation in the image. Leveraging a state-of-the-art large language
module, we first extract objects and construct a knowledge graph to predict the
locations of these objects in potentially generated images. We then integrate a
state-of-the-art controllable image generation model with a visual text
generation module to generate an image that is consistent with the original
prompt, guided by the predicted object locations. Through extensive experiments
on an advanced multimodal hallucination benchmark, we demonstrate the efficacy
of our approach in accurately generating the images without the inconsistency
with the original prompt. The code can be accessed via
https://github.com/TruthAI-Lab/PCIG.

æè¦ï¼ææ¬å°å¾å (T2I) çææ¨¡åçå¿«éè¿æ­¥ä½¿å¾åæç±ææ¬æè¿°å¼å¯¼çé«è´¨éå¾åæä¸ºå¯è½ãå°½ç®¡åå¾äºè¿äºéå¤§è¿å±ï¼ä½è¿äºæ¨¡åå¨çæä¸è¾å¥ææ¬ç¸çç¾çåå®¹æ¹é¢éå¸¸å¾ææï¼è¿å¯¹å®ä»¬çå¯é æ§åå®éé¨ç½²æåºäºææãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æä»¬å¼å¥äºä¸ä¸ªæ°é¢çåºäºæ©æ£çæ¡æ¶ï¼ä»¥æ¾çå¢å¼ºçæå¾åä¸å¶ç¸åºæè¿°çä¸è´æ§ï¼è§£å³è§è§è¾åºåææ¬è¾å¥ä¹é´çä¸ä¸è´æ§ãæä»¬çæ¡æ¶å»ºç«å¨å¯¹ä¸ä¸è´ç°è±¡çå¨é¢åæä¹ä¸ï¼æ ¹æ®å®ä»¬å¨å¾åä¸­çè¡¨ç°å¯¹å®ä»¬è¿è¡åç±»ãå©ç¨æåè¿çå¤§åè¯­è¨æ¨¡åï¼æä»¬é¦åæåå¯¹è±¡å¹¶æå»ºç¥è¯å¾è°±æ¥é¢æµè¿äºå¯¹è±¡å¨æ½å¨çæçå¾åä¸­çä½ç½®ãç¶åï¼æä»¬å°æåè¿çå¯æ§å¾åçææ¨¡åä¸è§è§ææ¬çææ¨¡åéæå¨ä¸èµ·ï¼ä»¥çæä¸åå§æç¤ºä¸è´çå¾åï¼å¹¶ç±é¢æµçå¯¹è±¡ä½ç½®å¼å¯¼ãéè¿å¨é«çº§å¤æ¨¡æå¹»è§åºåä¸è¿è¡å¹¿æ³çå®éªï¼æä»¬å±ç¤ºäºæä»¬çæ¹æ³å¨åç¡®çæå¾åæ¹é¢çæææ§ï¼èä¸ä¼ä¸åå§æç¤ºä¸ä¸è´ãå¯ä»¥éè¿ https://github.com/TruthAI-Lab/PCIG è®¿é®ä»£ç ã

##### **Graph-Augmented LLMs for Personalized Health Insights: A Case Study in Sleep Analysis**
2406.16252v2 by Ajan Subramanian, Zhongqi Yang, Iman Azimi, Amir M. Rahmani

Health monitoring systems have revolutionized modern healthcare by enabling
the continuous capture of physiological and behavioral data, essential for
preventive measures and early health intervention. While integrating this data
with Large Language Models (LLMs) has shown promise in delivering interactive
health advice, traditional methods like Retrieval-Augmented Generation (RAG)
and fine-tuning often fail to fully utilize the complex, multi-dimensional, and
temporally relevant data from wearable devices. These conventional approaches
typically provide limited actionable and personalized health insights due to
their inadequate capacity to dynamically integrate and interpret diverse health
data streams. In response, this paper introduces a graph-augmented LLM
framework designed to significantly enhance the personalization and clarity of
health insights. Utilizing a hierarchical graph structure, the framework
captures inter and intra-patient relationships, enriching LLM prompts with
dynamic feature importance scores derived from a Random Forest Model. The
effectiveness of this approach is demonstrated through a sleep analysis case
study involving 20 college students during the COVID-19 lockdown, highlighting
the potential of our model to generate actionable and personalized health
insights efficiently. We leverage another LLM to evaluate the insights for
relevance, comprehensiveness, actionability, and personalization, addressing
the critical need for models that process and interpret complex health data
effectively. Our findings show that augmenting prompts with our framework
yields significant improvements in all 4 criteria. Through our framework, we
can elicit well-crafted, more thoughtful responses tailored to a specific
patient.

æè¦ï¼å¥åº·ç£æ§ç³»çµ±ééæçºæ¶éççåè¡çºè³æï¼å¾¹åºæ¹è®äºç¾ä»£é«çä¿å¥ï¼éäºè³æå°æ¼é é²æªæ½åæ©æå¥åº·å¹²é è³ééè¦ãéç¶å°éäºè³æèå¤§åèªè¨æ¨¡å (LLM) æ´åï¼å·²å±ç¾åºæä¾äºåå¼å¥åº·å»ºè­°çæ½åï¼ä½å³çµ±æ¹æ³ï¼ä¾å¦æª¢ç´¢æ´åçæ (RAG) åå¾®èª¿ï¼éå¸¸ç¡æ³ååå©ç¨ç©¿æ´å¼è£ç½®ä¸­è¤éãå¤é¢åä¸èæéç¸éçè³æãéäºå³çµ±æ¹æ³éå¸¸ææä¾æéçå¯è¡ä¸åäººåçå¥åº·è¦è§£ï¼å çºå®åç¡æ³åææ´ååè©®éä¸åçå¥åº·è³æä¸²æµãçºäºè§£æ±ºéååé¡ï¼æ¬æä»ç´¹äºä¸ååå½¢æ´å LLM æ¶æ§ï¼æ¨å¨å¤§å¹æåå¥åº·è¦è§£çåäººååæ¸æ°åº¦ãéåæ¶æ§å©ç¨éå±¤å¼åå½¢çµæ§ï¼æ·åæ£èä¹éåæ£èå§é¨çéä¿ï¼ä¸¦ä½¿ç¨å¾ Random Forest æ¨¡åè¡ççåæç¹å¾µéè¦æ§è©åï¼è±å¯ LLM æç¤ºãééä¸é ç¡ç åææ¡ä¾ç ç©¶ï¼å¨ COVID-19 å°éæééå° 20 åå¤§å­¸çé²è¡ï¼è­æäºéåæ¹æ³çæææ§ï¼çªé¡¯äºæåçæ¨¡åå¨ææç¢çå¯è¡ä¸åäººåçå¥åº·è¦è§£æ¹é¢çæ½åãæåå©ç¨å¦ä¸å LLM è©ä¼°è¦è§£çç¸éæ§ãå¨é¢æ§ãå¯è¡æ§ååäººåï¼æ»¿è¶³äºæ¨¡åææèçåè©®éè¤éå¥åº·è³æçééµéæ±ãæåçç ç©¶çµæé¡¯ç¤ºï¼ä½¿ç¨æåçæ¶æ§æ´åæç¤ºï¼å¯ä»¥å¨ææ 4 åæ¨æºä¸­å¤§å¹æ¹åãééæåçæ¶æ§ï¼æåå¯ä»¥å¼ç¼ç²¾å¿è¨­è¨ãæ´å¨å¨çåæï¼éå°ç¹å®æ£èéèº«æé ã

##### **GraphEval2000: Benchmarking and Improving Large Language Models on Graph Datasets**
2406.16176v1 by Qiming Wu, Zichen Chen, Will Corcoran, Misha Sra, Ambuj K. Singh

Large language models (LLMs) have achieved remarkable success in natural
language processing (NLP), demonstrating significant capabilities in processing
and understanding text data. However, recent studies have identified
limitations in LLMs' ability to reason about graph-structured data. To address
this gap, we introduce GraphEval2000, the first comprehensive graph dataset,
comprising 40 graph data structure problems along with 2000 test cases.
Additionally, we introduce an evaluation framework based on GraphEval2000,
designed to assess the graph reasoning abilities of LLMs through coding
challenges. Our dataset categorizes test cases into four primary and four
sub-categories, ensuring a comprehensive evaluation. We evaluate eight popular
LLMs on GraphEval2000, revealing that LLMs exhibit a better understanding of
directed graphs compared to undirected ones. While private LLMs consistently
outperform open-source models, the performance gap is narrowing. Furthermore,
to improve the usability of our evaluation framework, we propose Structured
Symbolic Decomposition (SSD), an instruction-based method designed to enhance
LLM performance on GraphEval2000. Results show that SSD improves the
performance of GPT-3.5, GPT-4, and GPT-4o on complex graph problems, with an
increase of 11.11\%, 33.37\%, and 33.37\%, respectively.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨èªç¶èªè¨èç (NLP) ä¸­åå¾äºé¡¯èçæåï¼å¨èçåçè§£ææ¬æ¸ææ¹é¢è¡¨ç¾åºé¡¯èçè½åãç¶èï¼æè¿çç ç©¶ç¼ç¾ LLM å¨æ¨çåå½¢çµæ§æ¸æçè½åæ¹é¢å­å¨å±éæ§ãçºäºè§£æ±ºéåå·®è·ï¼æåå¼å¥äº GraphEval2000ï¼ç¬¬ä¸åå¨é¢çåå½¢æ¸æéï¼åå« 40 ååå½¢æ¸æçµæ§åé¡ä»¥å 2000 åæ¸¬è©¦ç¨ä¾ãæ­¤å¤ï¼æåéå¼å¥äºåºæ¼ GraphEval2000 çè©ä¼°æ¡æ¶ï¼æ¨å¨ééç·¨ç¢¼ææ°è©ä¼° LLM çåå½¢æ¨çè½åãæåçæ¸æéå°æ¸¬è©¦ç¨ä¾åçºååä¸»è¦é¡å¥åååå­é¡å¥ï¼ç¢ºä¿é²è¡å¨é¢çè©ä¼°ãæåå¨ GraphEval2000 ä¸è©ä¼°äºå«åæµè¡ç LLMï¼çµæè¡¨æï¼èç¡ååç¸æ¯ï¼LLM å°æååççè§£æ´å¥½ãéç¶ç§æ LLM æçºåªæ¼éæºæ¨¡åï¼ä½æ§è½å·®è·æ­£å¨ç¸®å°ãæ­¤å¤ï¼çºäºæé«æåè©ä¼°æ¡æ¶çå¯ç¨æ§ï¼æåæåºäºçµæ§åç¬¦èåè§£ (SSD)ï¼ä¸ç¨®åºæ¼æä»¤çæ¹æ³ï¼æ¨å¨å¢å¼· LLM å¨ GraphEval2000 ä¸çæ§è½ãçµæè¡¨æï¼SSD åå¥æé«äº GPT-3.5ãGPT-4 å GPT-4o å¨è¤éåå½¢åé¡ä¸çæ§è½ï¼åå¥å¢å äº 11.11%ã33.37% å 33.37%ã

##### **Can LLM Graph Reasoning Generalize beyond Pattern Memorization?**
2406.15992v1 by Yizhuo Zhang, Heng Wang, Shangbin Feng, Zhaoxuan Tan, Xiaochuang Han, Tianxing He, Yulia Tsvetkov

Large language models (LLMs) demonstrate great potential for problems with
implicit graphical structures, while recent works seek to enhance the graph
reasoning capabilities of LLMs through specialized instruction tuning. The
resulting 'graph LLMs' are evaluated with in-distribution settings only, thus
it remains underexplored whether LLMs are learning generalizable graph
reasoning skills or merely memorizing patterns in the synthetic training data.
To this end, we propose the NLGift benchmark, an evaluation suite of LLM graph
reasoning generalization: whether LLMs could go beyond semantic, numeric,
structural, reasoning patterns in the synthetic training data and improve
utility on real-world graph-based tasks. Extensive experiments with two LLMs
across four graph reasoning tasks demonstrate that while generalization on
simple patterns (semantic, numeric) is somewhat satisfactory, LLMs struggle to
generalize across reasoning and real-world patterns, casting doubt on the
benefit of synthetic graph tuning for real-world tasks with underlying network
structures. We explore three strategies to improve LLM graph reasoning
generalization, and we find that while post-training alignment is most
promising for real-world tasks, empowering LLM graph reasoning to go beyond
pattern memorization remains an open research question.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å°æ¼å·æé±å¼åå½¢çµæ§çåé¡å±ç¾åºå·¨å¤§çæ½åï¼èè¿æç ç©¶åééå°æ¥­æä»¤èª¿æ´ä¾å¢å¼· LLM çåå½¢æ¨çè½åãç±æ­¤ç¢ççãåå½¢ LLMãåå¨åå¸å§è¨­å®ä¸­é²è¡è©ä¼°ï¼å æ­¤ LLM æ¯å¦å­¸ç¿å°å¯æ¦æ¬çåå½¢æ¨çæè½ï¼æååè¨æ¶åæè¨ç·´è³æä¸­çæ¨¡å¼ï¼ä»æªç²å¾ååæ¢è¨ãçºæ­¤ï¼æåæåº NLGift åºæºï¼éæ¯ä¸å LLM åå½¢æ¨çæ¦æ¬è©ä¼°å¥ä»¶ï¼LLM æ¯å¦å¯ä»¥è¶è¶åæè¨ç·´è³æä¸­çèªç¾©ãæ¸å¼ãçµæ§æ¨çæ¨¡å¼ï¼ä¸¦æåå¨çå¯¦ä¸çåºæ¼åå½¢çä»»åä¸­çæç¨ãééå©å LLM å¨åååå½¢æ¨çä»»åä¸­çå»£æ³å¯¦é©è­æï¼åç®¡å¨ç°¡å®æ¨¡å¼ï¼èªç¾©ãæ¸å¼ï¼ä¸çæ¦æ¬ä»¤äººæ»¿æï¼ä½ LLM é£ä»¥å¨æ¨çåçå¯¦ä¸çæ¨¡å¼ä¸­æ¦æ¬ï¼å°åæåå½¢èª¿æ´å°æ¼å·æåºç¤ç¶²è·¯çµæ§ççå¯¦ä¸çä»»åççèæåºè³ªçãæåæ¢è¨äºä¸ç¨®ç­ç¥ä¾æ¹å LLM åå½¢æ¨çæ¦æ¬ï¼æåç¼ç¾ï¼åç®¡è¨ç·´å¾å°é½å°çå¯¦ä¸çä»»åææå¸æï¼ä½è³¦è½ LLM åå½¢æ¨çä»¥è¶è¶æ¨¡å¼è¨æ¶ä»ç¶æ¯ä¸åéæ¾çç ç©¶åé¡ã

##### **LLM-Powered Explanations: Unraveling Recommendations Through Subgraph Reasoning**
2406.15859v2 by Guangsi Shi, Xiaofeng Deng, Linhao Luo, Lijuan Xia, Lei Bao, Bei Ye, Fei Du, Shirui Pan, Yuxiao Li

Recommender systems are pivotal in enhancing user experiences across various
web applications by analyzing the complicated relationships between users and
items. Knowledge graphs(KGs) have been widely used to enhance the performance
of recommender systems. However, KGs are known to be noisy and incomplete,
which are hard to provide reliable explanations for recommendation results. An
explainable recommender system is crucial for the product development and
subsequent decision-making. To address these challenges, we introduce a novel
recommender that synergies Large Language Models (LLMs) and KGs to enhance the
recommendation and provide interpretable results. Specifically, we first
harness the power of LLMs to augment KG reconstruction. LLMs comprehend and
decompose user reviews into new triples that are added into KG. In this way, we
can enrich KGs with explainable paths that express user preferences. To enhance
the recommendation on augmented KGs, we introduce a novel subgraph reasoning
module that effectively measures the importance of nodes and discovers
reasoning for recommendation. Finally, these reasoning paths are fed into the
LLMs to generate interpretable explanations of the recommendation results. Our
approach significantly enhances both the effectiveness and interpretability of
recommender systems, especially in cross-selling scenarios where traditional
methods falter. The effectiveness of our approach has been rigorously tested on
four open real-world datasets, with our methods demonstrating a superior
performance over contemporary state-of-the-art techniques by an average
improvement of 12%. The application of our model in a multinational engineering
and technology company cross-selling recommendation system further underscores
its practical utility and potential to redefine recommendation practices
through improved accuracy and user trust.

æè¦ï¼æ¨è¦ç³»çµ±å¨åæä½¿ç¨èèé ç®ä¹éè¤éçéä¿ï¼æååç¨®ç¶²è·¯æç¨ç¨å¼çä½¿ç¨èé«é©ä¸­æ®æ¼èééµè§è²ãç¥è­åè­ (KG) å·²è¢«å»£æ³ç¨æ¼æåæ¨è¦ç³»çµ±çæè½ãç¶èï¼KG ç¾æå¨ç¥æ¯æéè¨ä¸ä¸å®æ´çï¼éä½¿å¾é£ä»¥æä¾å¯é çæ¨è¦çµæèªªæãä¸åå¯è§£éçæ¨è¦ç³»çµ±å°æ¼ç¢åéç¼åå¾çºæ±ºç­è³ééè¦ãçºäºæå°éäºææ°ï¼æåå¼å¥äºä¸åæ°ç©çæ¨è¦ç³»çµ±ï¼å®çµåäºå¤§åèªè¨æ¨¡å (LLM) å KG ä¾å å¼·æ¨è¦ä¸¦æä¾å¯è§£éççµæãå·é«ä¾èªªï¼æåé¦åå©ç¨ LLM çåéä¾æ´å KG éå»ºãLLM çè§£ä¸¦å°ä½¿ç¨èè©è«åè§£ææ°çä¸åçµï¼ä¸¦å°å¶æ°å¢å° KG ä¸­ãéééç¨®æ¹å¼ï¼æåå¯ä»¥ç¨è¡¨éä½¿ç¨èåå¥½çå¯è§£éè·¯å¾ä¾è±å¯ KGãçºäºå¢å¼·å¨æ´å KG ä¸çæ¨è¦ï¼æåå¼å¥äºä¸åæ°ç©çå­åæ¨çæ¨¡çµï¼å®å¯ä»¥ææå°è¡¡éç¯é»çéè¦æ§ï¼ä¸¦æ¾åºæ¨è¦ççç±ãæå¾ï¼éäºæ¨çè·¯å¾è¢«è¼¸å¥å° LLM ä¸­ï¼ä»¥ç¢çæ¨è¦çµæçå¯è§£éèªªæãæåçåæ³å¤§å¹æåäºæ¨è¦ç³»çµ±çæææ§åå¯è§£éæ§ï¼ç¹å¥æ¯å¨å³çµ±æ¹æ³å¤±æçäº¤åé·å®æå¢ä¸­ãæåçåæ³çæææ§å·²å¨ååéæ¾ççå¯¦ä¸çè³æéä¸ç¶éå´æ ¼æ¸¬è©¦ï¼æåçåæ³å±ç¤ºåºæ¯ç¶ä»£æåé²æè¡æ´åè¶çæè½ï¼å¹³åæåäº 12%ãæåçæ¨¡åå¨ä¸å®¶è·¨åå·¥ç¨åæè¡å¬å¸äº¤åé·å®æ¨è¦ç³»çµ±ä¸­çæç¨é²ä¸æ­¥çªé¡¯äºå®çå¯¦ç¨æ§ï¼ä»¥åééæåæºç¢ºæ§åä½¿ç¨èä¿¡ä»»ä¾éæ°å®ç¾©æ¨è¦å¯¦åçæ½åã

##### **Large Language Models for Link Stealing Attacks Against Graph Neural Networks**
2406.16963v1 by Faqian Guan, Tianqing Zhu, Hui Sun, Wanlei Zhou, Philip S. Yu

Graph data contains rich node features and unique edge information, which
have been applied across various domains, such as citation networks or
recommendation systems. Graph Neural Networks (GNNs) are specialized for
handling such data and have shown impressive performance in many applications.
However, GNNs may contain of sensitive information and susceptible to privacy
attacks. For example, link stealing is a type of attack in which attackers
infer whether two nodes are linked or not. Previous link stealing attacks
primarily relied on posterior probabilities from the target GNN model,
neglecting the significance of node features. Additionally, variations in node
classes across different datasets lead to different dimensions of posterior
probabilities. The handling of these varying data dimensions posed a challenge
in using a single model to effectively conduct link stealing attacks on
different datasets. To address these challenges, we introduce Large Language
Models (LLMs) to perform link stealing attacks on GNNs. LLMs can effectively
integrate textual features and exhibit strong generalizability, enabling
attacks to handle diverse data dimensions across various datasets. We design
two distinct LLM prompts to effectively combine textual features and posterior
probabilities of graph nodes. Through these designed prompts, we fine-tune the
LLM to adapt to the link stealing attack task. Furthermore, we fine-tune the
LLM using multiple datasets and enable the LLM to learn features from different
datasets simultaneously. Experimental results show that our approach
significantly enhances the performance of existing link stealing attack tasks
in both white-box and black-box scenarios. Our method can execute link stealing
attacks across different datasets using only a single model, making link
stealing attacks more applicable to real-world scenarios.

æè¦ï¼åå½¢æ¸æåå«è±å¯çç¯é»ç¹å¾µåç¨ç¹çéç·£è³è¨ï¼å·²æç¨æ¼åç¨®é åï¼ä¾å¦å¼æç¶²è·¯ææ¨è¦ç³»çµ±ãåå½¢ç¥ç¶ç¶²è·¯ (GNN) å°éç¨æ¼èçæ­¤é¡æ¸æï¼ä¸¦å¨è¨±å¤æç¨ä¸­å±ç¾åºä»¤äººå°è±¡æ·±å»çæè½ãç¶èï¼GNN å¯è½åå«ææè³è¨ï¼ä¸å®¹æåå°é±ç§æ»æãä¾å¦ï¼é£çµç«åæ¯ä¸ç¨®æ»æï¼æ»æèæ¨æ·å©åç¯é»æ¯å¦é£çµãååçé£çµç«åæ»æä¸»è¦ä¾è³´æ¼ç®æ¨ GNN æ¨¡åçå¾é©æ©çï¼å¿½ç¥ç¯é»ç¹å¾µçéè¦æ§ãæ­¤å¤ï¼ä¸åè³æéä¸­çç¯é»é¡å¥è®åå°è´å¾é©æ©ççä¸åç¶­åº¦ãèçéäºä¸åçè³æç¶­åº¦å¨ä½¿ç¨å®ä¸æ¨¡åå°ä¸åè³æéå·è¡é£çµç«åæ»æææ§æä¸é ææ°ãçºäºæå°éäºææ°ï¼æåå¼å¥äºå¤§åèªè¨æ¨¡å (LLM) ä¾å° GNN å·è¡é£çµç«åæ»æãLLM å¯ä»¥æææ´åæå­ç¹å¾µä¸¦å±ç¾å¼·å¤§çæ³åè½åï¼ä½¿æ»æè½å¤ èçä¸åè³æéä¸­çä¸åè³æç¶­åº¦ãæåè¨­è¨äºå©åä¸åç LLM æç¤ºï¼ä»¥ææçµåæå­ç¹å¾µååå½¢ç¯é»çå¾é©æ©çãéééäºè¨­è¨çæç¤ºï¼æåå¾®èª¿ LLM ä»¥é©æé£çµç«åæ»æä»»åãæ­¤å¤ï¼æåä½¿ç¨å¤åè³æéå¾®èª¿ LLMï¼ä¸¦ä½¿ LLM è½å¤ åæå¾ä¸åçè³æéä¸­å­¸ç¿ç¹å¾µãå¯¦é©çµæé¡¯ç¤ºï¼æåçåæ³é¡¯èæåäºç¾æé£çµç«åæ»æä»»åå¨ç½çåé»çå ´æ¯ä¸­çæè½ãæåçæ¨¡ååä½¿ç¨å®ä¸æ¨¡åå°±è½è·¨ä¸åè³æéå·è¡é£çµç«åæ»æï¼ä½¿é£çµç«åæ»ææ´é©ç¨æ¼å¯¦éå ´æ¯ã

##### **Inferring Pluggable Types with Machine Learning**
2406.15676v1 by Kazi Amanul Islam Siddiqui, Martin Kellogg

Pluggable type systems allow programmers to extend the type system of a
programming language to enforce semantic properties defined by the programmer.
Pluggable type systems are difficult to deploy in legacy codebases because they
require programmers to write type annotations manually. This paper investigates
how to use machine learning to infer type qualifiers automatically. We propose
a novel representation, NaP-AST, that encodes minimal dataflow hints for the
effective inference of type qualifiers. We evaluate several model architectures
for inferring type qualifiers, including Graph Transformer Network, Graph
Convolutional Network and Large Language Model. We further validated these
models by applying them to 12 open-source programs from a prior evaluation of
the NullAway pluggable typechecker, lowering warnings in all but one
unannotated project. We discovered that GTN shows the best performance, with a
recall of .89 and precision of 0.6. Furthermore, we conduct a study to estimate
the number of Java classes needed for good performance of the trained model.
For our feasibility study, performance improved around 16k classes, and
deteriorated due to overfitting around 22k classes.

æè¦ï¼å¯ææç±»åç³»ç»åè®¸ç¨åºåæ©å±ç¼ç¨è¯­è¨çç±»åç³»ç»ï¼ä»¥æ§è¡ç¨åºåå®ä¹çè¯­ä¹å±æ§ãå¯ææç±»åç³»ç»é¾ä»¥é¨ç½²å¨éçä»£ç åºä¸­ï¼å ä¸ºå®ä»¬è¦æ±ç¨åºåæå¨ç¼åç±»åæ³¨éãæ¬æç ç©¶å¦ä½ä½¿ç¨æºå¨å­¦ä¹ èªå¨æ¨æ­ç±»åéå®ç¬¦ãæä»¬æåºäºä¸ç§æ°é¢çè¡¨ç¤ºå½¢å¼ NaP-ASTï¼å®å¯¹ç±»åéå®ç¬¦çæææ¨æ­ç¼ç äºæå°çæ°æ®æµæç¤ºãæä»¬è¯ä¼°äºç¨äºæ¨æ­ç±»åéå®ç¬¦çå ç§æ¨¡åæ¶æï¼åæ¬å¾è½¬æ¢å¨ç½ç»ãå¾å·ç§¯ç½ç»åå¤§è¯­è¨æ¨¡åãæä»¬éè¿å°è¿äºæ¨¡ååºç¨äº NullAway å¯ææç±»åæ£æ¥å¨çååè¯ä¼°ä¸­ç 12 ä¸ªå¼æºç¨åºï¼è¿ä¸æ­¥éªè¯äºè¿äºæ¨¡åï¼é¤äºä¸ä¸ªæªæ³¨éçé¡¹ç®å¤ï¼éä½äºææé¡¹ç®çè­¦åãæä»¬åç° GTN è¡¨ç°æä½³ï¼å¬åçä¸º 0.89ï¼ç²¾ç¡®çä¸º 0.6ãæ­¤å¤ï¼æä»¬è¿è¡äºä¸é¡¹ç ç©¶ï¼ä»¥ä¼°è®¡è®­ç»æ¨¡åè¯å¥½æ§è½æéç Java ç±»æ°éãå¯¹äºæä»¬çå¯è¡æ§ç ç©¶ï¼æ§è½æé«äºçº¦ 16k ä¸ªç±»ï¼å¹¶ä¸ç±äºå¨ 22k ä¸ªç±»å·¦å³è¿åº¦æåèæ¶åã

##### **NLP-KG: A System for Exploratory Search of Scientific Literature in Natural Language Processing**
2406.15294v2 by Tim Schopf, Florian Matthes

Scientific literature searches are often exploratory, whereby users are not
yet familiar with a particular field or concept but are interested in learning
more about it. However, existing systems for scientific literature search are
typically tailored to keyword-based lookup searches, limiting the possibilities
for exploration. We propose NLP-KG, a feature-rich system designed to support
the exploration of research literature in unfamiliar natural language
processing (NLP) fields. In addition to a semantic search, NLP-KG allows users
to easily find survey papers that provide a quick introduction to a field of
interest. Further, a Fields of Study hierarchy graph enables users to
familiarize themselves with a field and its related areas. Finally, a chat
interface allows users to ask questions about unfamiliar concepts or specific
articles in NLP and obtain answers grounded in knowledge retrieved from
scientific publications. Our system provides users with comprehensive
exploration possibilities, supporting them in investigating the relationships
between different fields, understanding unfamiliar concepts in NLP, and finding
relevant research literature. Demo, video, and code are available at:
https://github.com/NLP-Knowledge-Graph/NLP-KG-WebApp.

æè¦ï¼ç§å­¸æç»çæå°éå¸¸æ¯æ¢ç´¢æ§çï¼ä½¿ç¨èå¯è½éä¸çææåç¹å®é åææ¦å¿µï¼ä½æèè¶£é²ä¸æ­¥äºè§£å®ãç¶èï¼ç¾æçç§å­¸æç»æå°ç³»çµ±éå¸¸å°ééå°åºæ¼ééµå­çæ¥è©¢æå°ï¼éå¶äºæ¢ç´¢çå¯è½æ§ãæåæåº NLP-KGï¼éæ¯ä¸ååè½è±å¯çç³»çµ±ï¼æ¨å¨æ¯æ´å¨ä¸çæçèªç¶èªè¨èç (NLP) é åä¸­æ¢ç´¢ç ç©¶æç»ãé¤äºèªææå°ä¹å¤ï¼NLP-KG ä½¿ç¨èå¯ä»¥è¼é¬æ¾å°æä¾å°æèè¶£é åçå¿«éä»ç´¹çç¶è¿°è«æãæ­¤å¤ï¼ç ç©¶é åéå±¤åè®ä½¿ç¨èè½å¤ çæä¸åé ååå¶ç¸éé åãæå¾ï¼èå¤©ä»é¢åè¨±ä½¿ç¨èè©¢åæéä¸çæçæ¦å¿µæ NLP ä¸­ç¹å®æç« çåé¡ï¼ä¸¦ç²å¾å¾ç§å­¸åºçç©ä¸­æ·åçç¥è­çºåºç¤çç­æ¡ãæåçç³»çµ±çºä½¿ç¨èæä¾å¨é¢çæ¢ç´¢å¯è½æ§ï¼åå©ä»åèª¿æ¥ä¸åé åä¹éçéä¿ï¼çè§£ NLP ä¸­ä¸çæçæ¦å¿µï¼ä¸¦æ¾å°ç¸éçç ç©¶æç»ãç¤ºç¯ãå½±çåç¨å¼ç¢¼å¯å¨ä»¥ä¸ç¶²ååå¾ï¼
https://github.com/NLP-Knowledge-Graph/NLP-KG-WebAppã

##### **Unsupervised Extraction of Dialogue Policies from Conversations**
2406.15214v1 by Makesh Narsimhan Sreedhar, Traian Rebedea, Christopher Parisien

Dialogue policies play a crucial role in developing task-oriented dialogue
systems, yet their development and maintenance are challenging and typically
require substantial effort from experts in dialogue modeling. While in many
situations, large amounts of conversational data are available for the task at
hand, people lack an effective solution able to extract dialogue policies from
this data. In this paper, we address this gap by first illustrating how Large
Language Models (LLMs) can be instrumental in extracting dialogue policies from
datasets, through the conversion of conversations into a unified intermediate
representation consisting of canonical forms. We then propose a novel method
for generating dialogue policies utilizing a controllable and interpretable
graph-based methodology. By combining canonical forms across conversations into
a flow network, we find that running graph traversal algorithms helps in
extracting dialogue flows. These flows are a better representation of the
underlying interactions than flows extracted by prompting LLMs. Our technique
focuses on giving conversation designers greater control, offering a
productivity tool to improve the process of developing dialogue policies.

æè¦ï¼å°è©±æ¿ç­å¨éç¼ä»»åå°åå°è©±ç³»çµ±ä¸­æ®æ¼èè³ééè¦çè§è²ï¼ç¶èå®åçéç¼åç¶­è­·å·æææ°æ§ï¼ä¸éå¸¸éè¦å°è©±å»ºæ¨¡å°å®¶çå¤§éå·¥ä½ãéç¶å¨è¨±å¤ææ³ä¸ï¼å¤§éå°è©±è³æå¯ç¨æ¼æéçå·¥ä½ï¼ä½äººåç¼ºä¹ä¸ç¨®ææçè§£æ±ºæ¹æ¡ï¼ç¡æ³å¾éäºè³æä¸­æåå°è©±æ¿ç­ãå¨æ¬æä¸­ï¼æåééé¦åèªªæå¤§åèªè¨æ¨¡å (LLM) å¦ä½ééå°å°è©±è½ææç±è¦ç¯å½¢å¼çµæççµ±ä¸ä¸­éè¡¨ç¤ºï¼å¾è³æéä¸­æåå°è©±æ¿ç­ï¼ä¾èªªæå¦ä½è§£æ±ºéåå·®è·ãç¶å¾ï¼æåæåºäºä¸ç¨®å©ç¨å¯æ§ä¸å¯è§£éçåºæ¼åå½¢çæ¹æ³ä¾ç¢çå°è©±æ¿ç­çæ°æ¹æ³ãééå°å°è©±ä¸­çè¦ç¯å½¢å¼çµåææµç¶²è·¯ï¼æåç¼ç¾å·è¡åå½¢éæ­·æ¼ç®æ³æå©æ¼æåå°è©±æµãéäºæµæ¯ééæç¤º LLM æåçæµæ´è½ä»£è¡¨åºå±¤äºåãæåçæè¡å°æ³¨æ¼è®å°è©±è¨­è¨å¸«æææ´å¤§çæ§å¶æ¬ï¼æä¾ä¸ç¨®çç¢åå·¥å·ä¾æ¹åéç¼å°è©±æ¿ç­çéç¨ã

##### **Uni-Mol2: Exploring Molecular Pretraining Model at Scale**
2406.14969v2 by Xiaohong Ji, Zhen Wang, Zhifeng Gao, Hang Zheng, Linfeng Zhang, Guolin Ke, Weinan E

In recent years, pretraining models have made significant advancements in the
fields of natural language processing (NLP), computer vision (CV), and life
sciences. The significant advancements in NLP and CV are predominantly driven
by the expansion of model parameters and data size, a phenomenon now recognized
as the scaling laws. However, research exploring scaling law in molecular
pretraining models remains unexplored. In this work, we present Uni-Mol2 , an
innovative molecular pretraining model that leverages a two-track transformer
to effectively integrate features at the atomic level, graph level, and
geometry structure level. Along with this, we systematically investigate the
scaling law within molecular pretraining models, characterizing the power-law
correlations between validation loss and model size, dataset size, and
computational resources. Consequently, we successfully scale Uni-Mol2 to 1.1
billion parameters through pretraining on 800 million conformations, making it
the largest molecular pretraining model to date. Extensive experiments show
consistent improvement in the downstream tasks as the model size grows. The
Uni-Mol2 with 1.1B parameters also outperforms existing methods, achieving an
average 27% improvement on the QM9 and 14% on COMPAS-1D dataset.

æè¦ï¼è¿å¹´æ¥ï¼é¢è®­ç»æ¨¡åå¨èªç¶è¯­è¨å¤ç (NLP)ãè®¡ç®æºè§è§ (CV) åçå½ç§å­¦é¢ååå¾äºéå¤§è¿å±ãNLP å CV çéå¤§è¿æ­¥ä¸»è¦ç±æ¨¡ååæ°åæ°æ®éçæ©å±æ¨å¨ï¼è¿ä¸ç°è±¡ç°å¨è¢«è®¤ä¸ºæ¯ç¼©æ¾å®å¾ãç¶èï¼æ¢ç´¢åå­é¢è®­ç»æ¨¡åä¸­ç¼©æ¾å®å¾çç ç©¶ä»æªå¾å°æ¢ç´¢ãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬æåºäº Uni-Mol2ï¼ä¸ç§åæ°çåå­é¢è®­ç»æ¨¡åï¼å®å©ç¨åè½¨è½¬æ¢å¨ææå°æ´ååå­çº§ãå¾çº§åå ä½ç»æçº§çç¹å¾ãé¤æ­¤ä¹å¤ï¼æä»¬ç³»ç»å°ç ç©¶äºåå­é¢è®­ç»æ¨¡åä¸­çç¼©æ¾å®å¾ï¼æè¿°äºéªè¯æå¤±ä¸æ¨¡åå¤§å°ãæ°æ®éå¤§å°åè®¡ç®èµæºä¹é´çå¹å¾ç¸å³æ§ãå æ­¤ï¼æä»¬æåå°å° Uni-Mol2 æ©å±å° 11 äº¿ä¸ªåæ°ï¼éè¿å¯¹ 8 äº¿ä¸ªæè±¡è¿è¡é¢è®­ç»ï¼ä½¿å¶æä¸ºè¿ä»ä¸ºæ­¢æå¤§çåå­é¢è®­ç»æ¨¡åãå¤§éçå®éªè¡¨æï¼éçæ¨¡åå¤§å°çå¢é¿ï¼ä¸æ¸¸ä»»å¡æç»­å¾å°æ¹åãå·æ 1.1B åæ°ç Uni-Mol2 ä¹ä¼äºç°ææ¹æ³ï¼å¨ QM9 ä¸å®ç°äºå¹³å 27% çæ¹è¿ï¼å¨ COMPAS-1D æ°æ®éä¸å®ç°äº 14% çæ¹è¿ã

##### **Relation Extraction with Fine-Tuned Large Language Models in Retrieval Augmented Generation Frameworks**
2406.14745v2 by Sefika Efeoglu, Adrian Paschke

Information Extraction (IE) is crucial for converting unstructured data into
structured formats like Knowledge Graphs (KGs). A key task within IE is
Relation Extraction (RE), which identifies relationships between entities in
text. Various RE methods exist, including supervised, unsupervised, weakly
supervised, and rule-based approaches. Recent studies leveraging pre-trained
language models (PLMs) have shown significant success in this area. In the
current era dominated by Large Language Models (LLMs), fine-tuning these models
can overcome limitations associated with zero-shot LLM prompting-based RE
methods, especially regarding domain adaptation challenges and identifying
implicit relations between entities in sentences. These implicit relations,
which cannot be easily extracted from a sentence's dependency tree, require
logical inference for accurate identification. This work explores the
performance of fine-tuned LLMs and their integration into the Retrieval
Augmented-based (RAG) RE approach to address the challenges of identifying
implicit relations at the sentence level, particularly when LLMs act as
generators within the RAG framework. Empirical evaluations on the TACRED,
TACRED-Revisited (TACREV), Re-TACRED, and SemEVAL datasets show significant
performance improvements with fine-tuned LLMs, including Llama2-7B, Mistral-7B,
and T5 (Large). Notably, our approach achieves substantial gains on SemEVAL,
where implicit relations are common, surpassing previous results on this
dataset. Additionally, our method outperforms previous works on TACRED, TACREV,
and Re-TACRED, demonstrating exceptional performance across diverse evaluation
scenarios.

æè¦ï¼è³è¨èåï¼IEï¼å°æ¼å°éçµæ§åè³æè½ææç¥è­åè­ï¼KGï¼ç­çµæ§åæ ¼å¼è³ééè¦ãIE ä¸­çä¸é ééµä»»åæ¯éä¿èåï¼REï¼ï¼ç¨æ¼è­å¥æå­ä¸­å¯¦é«ä¹éçéä¿ãRE æ¹æ³å¤ç¨®å¤æ¨£ï¼åæ¬ç£ç£å¼ãéç£ç£å¼ãå¼±ç£ç£å¼ååºæ¼è¦åçæ¹æ³ãæè¿å©ç¨é è¨ç·´èªè¨æ¨¡åï¼PLMï¼çç ç©¶å·²å¨æ­¤é åå±ç¾é¡¯èææãå¨å¤§åèªè¨æ¨¡åï¼LLMï¼ä¸»å°çç¶åæä»£ï¼å¾®èª¿éäºæ¨¡åå¯ä»¥åæèé¶æ¬¡å­¸ç¿ LLM æç¤ºå¼ RE æ¹æ³ç¸éçéå¶ï¼ç¹å¥æ¯å¨é åé©æææ°åè­å¥å¥å­ä¸­å¯¦é«ä¹éçé±å«éä¿æ¹é¢ãéäºé±å«éä¿ç¡æ³è¼æå¾å¥å­çä¾è³´æ¨¹ä¸­èåï¼éè¦éè¼¯æ¨è«æè½æºç¢ºè­å¥ãéé å·¥ä½æ¢è¨äºå¾®èª¿å¾ç LLM çæè½ï¼ä»¥åå®åæ´åå°æª¢ç´¢å¢å¼·å¼ï¼RAGï¼RE æ¹æ³ä¸­ä»¥è§£æ±ºå¨å¥å­å±¤ç´è­å¥é±å«éä¿çææ°ï¼ç¹å¥æ¯å¨ LLM å¨ RAG æ¡æ¶ä¸­åç¶çæå¨çæå¾ãå¨ TACREDãTACRED-Revisitedï¼TACREVï¼ãRe-TACRED å SemEVAL è³æéä¸çç¶é©è©ä¼°é¡¯ç¤ºï¼å¾®èª¿å¾ç LLMï¼åæ¬ Llama2-7BãMistral-7B å T5ï¼å¤§åï¼ï¼å¤§å¹æåäºæè½ãå¼å¾æ³¨æçæ¯ï¼æåçåæ³å¨ SemEVAL ä¸åå¾äºé¡¯èçé²å±ï¼å çºé±å«éä¿å¾å¸¸è¦ï¼è¶è¶äºéåè³æéä¸çååçµæãæ­¤å¤ï¼æåçåæ³å¨ TACREDãTACREV å Re-TACRED ä¸åªæ¼ååçå·¥ä½ï¼è­æäºå¨ä¸åçè©ä¼°å ´æ¯ä¸­è¡¨ç¾åºè²çæè½ã

##### **Do LLMs Have Distinct and Consistent Personality? TRAIT: Personality Testset designed for LLMs with Psychometrics**
2406.14703v1 by Seungbeen Lee, Seungwon Lim, Seungju Han, Giyeong Oh, Hyungjoo Chae, Jiwan Chung, Minju Kim, Beong-woo Kwak, Yeonsoo Lee, Dongha Lee, Jinyoung Yeo, Youngjae Yu

The idea of personality in descriptive psychology, traditionally defined
through observable behavior, has now been extended to Large Language Models
(LLMs) to better understand their behavior. This raises a question: do LLMs
exhibit distinct and consistent personality traits, similar to humans? Existing
self-assessment personality tests, while applicable, lack the necessary
validity and reliability for precise personality measurements. To address this,
we introduce TRAIT, a new tool consisting of 8K multi-choice questions designed
to assess the personality of LLMs with validity and reliability. TRAIT is built
on the psychometrically validated human questionnaire, Big Five Inventory (BFI)
and Short Dark Triad (SD-3), enhanced with the ATOMIC10X knowledge graph for
testing personality in a variety of real scenarios. TRAIT overcomes the
reliability and validity issues when measuring personality of LLM with
self-assessment, showing the highest scores across three metrics: refusal rate,
prompt sensitivity, and option order sensitivity. It reveals notable insights
into personality of LLM: 1) LLMs exhibit distinct and consistent personality,
which is highly influenced by their training data (i.e., data used for
alignment tuning), and 2) current prompting techniques have limited
effectiveness in eliciting certain traits, such as high psychopathy or low
conscientiousness, suggesting the need for further research in this direction.

æè¦ï¼å¨å³çµ±å¿çå­¸ä¸­ï¼äººæ ¼çæ¦å¿µæ¯ééå¯è§å¯çè¡çºä¾å®ç¾©çï¼ç¾å¨å·²æ´å±å°å¤§åèªè¨æ¨¡å (LLM)ï¼ä»¥æ´äºè§£å¶è¡çºãéå¼ç¼äºä¸ååé¡ï¼LLM æ¯å¦åäººé¡ä¸æ¨£è¡¨ç¾åºç¨ç¹ä¸ä¸è´çäººæ ¼ç¹è³ªï¼ç¾æçèªæè©éäººæ ¼æ¸¬é©éç¶é©ç¨ï¼ä½ç¼ºä¹ç²¾ç¢ºäººæ ¼æ¸¬éæéçæåº¦åä¿¡åº¦ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äº TRAITï¼éæ¯ä¸åç± 8K åå¤éé¸æé¡çµæçå¨æ°å·¥å·ï¼æ¨å¨è©ä¼° LLM çäººæ ¼ï¼ä¸¦å·åæåº¦åä¿¡åº¦ãTRAIT å»ºæ§æ¼ç¶éå¿çæ¸¬éé©è­çäººé¡åå·ï¼å¤§äºäººæ ¼éè¡¨ (BFI) åç°¡ç­é»æä¸åçµ (SD-3)ï¼ä¸¦å¢å¼·äº ATOMIC10X ç¥è­åè­ï¼ä»¥ä¾¿å¨åç¨®å¯¦éå ´æ¯ä¸­æ¸¬è©¦äººæ ¼ãTRAIT åæäºä½¿ç¨èªæè©éæ¸¬é LLM äººæ ¼æçä¿¡åº¦åæåº¦åé¡ï¼å¨ä¸é ææ¨ï¼æçµçãæç¤ºææåº¦åé¸é é åºææåº¦ï¼ä¸­é¡¯ç¤ºåºæé«åãå®æ­ç¤ºäº LLM äººæ ¼çéè¦è¦è§£ï¼1) LLM è¡¨ç¾åºç¨ç¹ä¸ä¸è´çäººæ ¼ï¼éæ·±åå¶è¨ç·´è³æï¼å³ç¨æ¼å°é½èª¿æ´çè³æï¼å½±é¿ï¼ä»¥å 2) ç®åçæç¤ºæè¡å¨å¼ç¼æäºç¹è³ªï¼ä¾å¦é«ç²¾ç¥çè³ªæä½ç¡è²¬æ§ï¼æ¹é¢æææéï¼éè¡¨ç¤ºéè¦é²ä¸æ­¥ç ç©¶éåæ¹åã

##### **TAGLAS: An atlas of text-attributed graph datasets in the era of large graph and language models**
2406.14683v1 by Jiarui Feng, Hao Liu, Lecheng Kong, Yixin Chen, Muhan Zhang

In this report, we present TAGLAS, an atlas of text-attributed graph (TAG)
datasets and benchmarks. TAGs are graphs with node and edge features
represented in text, which have recently gained wide applicability in training
graph-language or graph foundation models. In TAGLAS, we collect and integrate
more than 23 TAG datasets with domains ranging from citation graphs to molecule
graphs and tasks from node classification to graph question-answering. Unlike
previous graph datasets and benchmarks, all datasets in TAGLAS have a unified
node and edge text feature format, which allows a graph model to be
simultaneously trained and evaluated on multiple datasets from various domains.
Further, we provide a standardized, efficient, and simplified way to load all
datasets and tasks. We also provide useful utils like text-to-embedding
conversion, and graph-to-text conversion, which can facilitate different
evaluation scenarios. Finally, we also provide standard and easy-to-use
evaluation utils. The project is open-sourced at
https://github.com/JiaruiFeng/TAGLAS and is still under construction. Please
expect more datasets/features in the future.

æè¦ï¼<paragraph>å¨æ¬æä¸­ï¼æä»¬æåºäº TAGLASï¼ä¸ä¸ªææ¬å±æ§å¾ (TAG)
æ°æ®éååºåçå¾éãTAG æ¯å·æä»¥ææ¬è¡¨ç¤ºçèç¹åè¾¹ç¹å¾çå¾ï¼æè¿å¨è®­ç»
å¾è¯­è¨æå¾åºç¡æ¨¡åä¸­è·å¾äºå¹¿æ³çåºç¨ãå¨ TAGLAS ä¸­ï¼æä»¬æ¶éå¹¶æ´å
äº 23 ä¸ªä»¥ä¸ç TAG æ°æ®éï¼å¶é¢åä»å¼æå¾å°åå­
å¾åä»»å¡ï¼ä»èç¹åç±»å°å¾é®ç­ãä¸
ä»¥åçå¾æ°æ®éååºåä¸åï¼TAGLAS ä¸­çæææ°æ®éé½å·æç»ä¸ç
èç¹åè¾¹ææ¬ç¹å¾æ ¼å¼ï¼è¿åè®¸å¾æ¨¡åå¨æ¥èªä¸åé¢åçå¤ä¸ªæ°æ®éä¸åæ¶è®­ç»åè¯ä¼°ã
æ­¤å¤ï¼æä»¬æä¾äºä¸ç§æ ååãé«æä¸ç®åçæ¹å¼æ¥å è½½ææ
æ°æ®éåä»»å¡ãæä»¬è¿æä¾æç¨çå®ç¨ç¨åºï¼å¦ææ¬å°åµå¥
è½¬æ¢ï¼ä»¥åå¾å°ææ¬è½¬æ¢ï¼è¿å¯ä»¥ä¿è¿ä¸åç
è¯ä¼°åºæ¯ãæåï¼æä»¬è¿æä¾æ åä¸æäºä½¿ç¨ç
è¯ä¼°å®ç¨ç¨åºãè¯¥é¡¹ç®å¨
https://github.com/JiaruiFeng/TAGLAS å¼æºï¼å¹¶ä¸ä»å¨å»ºè®¾ä¸­ãè¯·
æå¾æªæ¥ææ´å¤çæ°æ®é/åè½ã</paragraph>

##### **HYPERmotion: Learning Hybrid Behavior Planning for Autonomous Loco-manipulation**
2406.14655v1 by Jin Wang, Rui Dai, Weijie Wang, Luca Rossini, Francesco Ruscelli, Nikos Tsagarakis

Enabling robots to autonomously perform hybrid motions in diverse
environments can be beneficial for long-horizon tasks such as material
handling, household chores, and work assistance. This requires extensive
exploitation of intrinsic motion capabilities, extraction of affordances from
rich environmental information, and planning of physical interaction behaviors.
Despite recent progress has demonstrated impressive humanoid whole-body control
abilities, they struggle to achieve versatility and adaptability for new tasks.
In this work, we propose HYPERmotion, a framework that learns, selects and
plans behaviors based on tasks in different scenarios. We combine reinforcement
learning with whole-body optimization to generate motion for 38 actuated joints
and create a motion library to store the learned skills. We apply the planning
and reasoning features of the large language models (LLMs) to complex
loco-manipulation tasks, constructing a hierarchical task graph that comprises
a series of primitive behaviors to bridge lower-level execution with
higher-level planning. By leveraging the interaction of distilled spatial
geometry and 2D observation with a visual language model (VLM) to ground
knowledge into a robotic morphology selector to choose appropriate actions in
single- or dual-arm, legged or wheeled locomotion. Experiments in simulation
and real-world show that learned motions can efficiently adapt to new tasks,
demonstrating high autonomy from free-text commands in unstructured scenes.
Videos and website: hy-motion.github.io/

æè¦ï¼<paragraph>è®æ©å¨äººè½å¤ å¨ä¸åç°å¢ä¸­èªä¸»å·è¡æ··ååä½ï¼å°æ¼æææ¬éãå®¶ååå·¥ä½åå©ç­é·æä»»åå¯è½æ¯æççãééè¦å»£æ³å©ç¨å§å¨éåè½åï¼å¾è±å¯çç°å¢è³è¨ä¸­æåå¯è² ææ§ï¼ä»¥åè¦åç©çäºåè¡çºãåç®¡æè¿çé²å±å·²è­æä»¤äººå°è±¡æ·±å»çäººå½¢å¨èº«æ§å¶è½åï¼ä½å®åä»é£ä»¥å¯¦ç¾æ°ä»»åçå¤åè½æ§åé©ææ§ãå¨éé å·¥ä½ä¸­ï¼æåæåº HYPERmotionï¼ä¸ååºæ¼ä¸åå ´æ¯ä¸­çä»»åä¾å­¸ç¿ãé¸æåè¦åè¡çºçæ¡æ¶ãæåçµåå¼·åå­¸ç¿èå¨èº«æä½³åï¼çº 38 ååä½éç¯ç¢çåä½ï¼ä¸¦å»ºç«ä¸ååä½åº«ä¾å²å­å­¸ç¿å°çæè½ãæåå°å¤§åèªè¨æ¨¡å (LLM) çè¦ååæ¨çåè½æç¨æ¼è¤éçéåæç¸±ä»»åï¼æ§å»ºä¸åéå±¤å¼ä»»ååï¼å¶ä¸­åå«ä¸ç³»ååºæ¬è¡çºï¼ä»¥æ©æ¥ä½éå·è¡èé«éè¦åãééå©ç¨è¸é¤¾ç©ºéå¹¾ä½å 2D è§æ¸¬èè¦è¦ºèªè¨æ¨¡å (VLM) çäºåï¼å°ç¥è­åºç¤åçºæ©å¨äººå½¢æé¸æå¨ï¼ä»¥å¨å®èæéèãè¿é¨æè¼ªå¼éåä¸­é¸æé©ç¶çåä½ãæ¨¡æ¬åç¾å¯¦ä¸ççå¯¦é©è¡¨æï¼å­¸ç¿å°çåä½å¯ä»¥ææé©ææ°ä»»åï¼è­æäºå¨éçµæ§åå ´æ¯ä¸­å¾èªç±æå­æä»¤ä¸­ç²å¾é«åº¦èªä¸»æ§ãå½±çåç¶²ç«ï¼hy-motion.github.io/</paragraph>

##### **GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models**
2406.14550v1 by Shilong Li, Yancheng He, Hangyu Guo, Xingyuan Bu, Ge Bai, Jie Liu, Jiaheng Liu, Xingwei Qu, Yangguang Li, Wanli Ouyang, Wenbo Su, Bo Zheng

Long-context capabilities are essential for large language models (LLMs) to
tackle complex and long-input tasks. Despite numerous efforts made to optimize
LLMs for long contexts, challenges persist in robustly processing long inputs.
In this paper, we introduce GraphReader, a graph-based agent system designed to
handle long texts by structuring them into a graph and employing an agent to
explore this graph autonomously. Upon receiving a question, the agent first
undertakes a step-by-step analysis and devises a rational plan. It then invokes
a set of predefined functions to read node content and neighbors, facilitating
a coarse-to-fine exploration of the graph. Throughout the exploration, the
agent continuously records new insights and reflects on current circumstances
to optimize the process until it has gathered sufficient information to
generate an answer. Experimental results on the LV-Eval dataset reveal that
GraphReader, using a 4k context window, consistently outperforms GPT-4-128k
across context lengths from 16k to 256k by a large margin. Additionally, our
approach demonstrates superior performance on four challenging single-hop and
multi-hop benchmarks.

æè¦ï¼é·èªå¢è½åå°æ¼å¤§åèªè¨æ¨¡å (LLM) ä¾èªªè³ééè¦ï¼å¯æå°è¤éä¸è¼¸å¥é·åº¦è¼é·çä»»åãåç®¡å·²éå° LLM é²è¡è¨±å¤æä½³åå·¥ä½ä»¥æå°é·èªå¢ï¼ä½å¼·å¥å°èçé·è¼¸å¥ä»å­å¨ææ°ãå¨æ¬æä¸­ï¼æåä»ç´¹ GraphReaderï¼ä¸ååºæ¼åè¡¨çä»£çç³»çµ±ï¼æ¨å¨ééå°é·ææ¬çµæ§åæä¸ååè¡¨ï¼ä¸¦ä½¿ç¨ä»£çç¨å¼èªä¸»æ¢ç´¢æ­¤åè¡¨ï¼ä¾èçé·ææ¬ãå¨æ¶å°åé¡å¾ï¼ä»£çç¨å¼é¦åé²è¡éæ­¥åæï¼ä¸¦æ¬å®ä¸ååçè¨ç«ãç¶å¾ï¼å®æå¼å«ä¸çµé å®ç¾©çå½å¼ä¾è®åç¯é»å§å®¹åé°è¿ç¯é»ï¼ä¿é²å°åè¡¨çç²ç¥å°ç²¾ç´°æ¢ç´¢ãå¨æ´åæ¢ç´¢éç¨ä¸­ï¼ä»£çç¨å¼ææçºè¨éæ°çè¦è§£ï¼ä¸¦åæç¶åææ³ï¼ä»¥æä½³åèçç¨åºï¼ç´å°æ¶éå°è¶³å¤ çè³è¨ä¾ç¢çç­æ¡ãå¨ LV-Eval è³æéä¸çå¯¦é©çµæé¡¯ç¤ºï¼GraphReader ä½¿ç¨ 4k èªå¢è¦çªï¼å¨ 16k å° 256k çèªå¢é·åº¦ä¸­ï¼å§çµå¤§å¹åªæ¼ GPT-4-128kãæ­¤å¤ï¼æåçåæ³å¨ååå·æææ°æ§çå®è·³åå¤è·³åºæºæ¸¬è©¦ä¸­å±ç¾åºåè¶çæè½ã

##### **medIKAL: Integrating Knowledge Graphs as Assistants of LLMs for Enhanced Clinical Diagnosis on EMRs**
2406.14326v1 by Mingyi Jia, Junwen Duan, Yan Song, Jianxin Wang

Electronic Medical Records (EMRs), while integral to modern healthcare,
present challenges for clinical reasoning and diagnosis due to their complexity
and information redundancy. To address this, we proposed medIKAL (Integrating
Knowledge Graphs as Assistants of LLMs), a framework that combines Large
Language Models (LLMs) with knowledge graphs (KGs) to enhance diagnostic
capabilities. medIKAL assigns weighted importance to entities in medical
records based on their type, enabling precise localization of candidate
diseases within KGs. It innovatively employs a residual network-like approach,
allowing initial diagnosis by the LLM to be merged into KG search results.
Through a path-based reranking algorithm and a fill-in-the-blank style prompt
template, it further refined the diagnostic process. We validated medIKAL's
effectiveness through extensive experiments on a newly introduced open-sourced
Chinese EMR dataset, demonstrating its potential to improve clinical diagnosis
in real-world settings.

æè¦ï¼é»å­çæ­· (EMR) éç¶æ¯ç¾ä»£é«çä¿å¥ä¸å¯æç¼ºçä¸é¨åï¼ä½ç±æ¼å¶è¤éæ§åè³è¨åé¤ï¼å°è¨åºæ¨çåè¨ºæ·æåºäºææ°ãçºäºè§£æ±ºéååé¡ï¼æåæåºäº medIKALï¼å°ç¥è­åè­æ´åçº LLM çå©çï¼ï¼ä¸åå°å¤§åèªè¨æ¨¡å (LLM) èç¥è­åè­ (KG) çµåçæ¡æ¶ï¼ä»¥å¢å¼·è¨ºæ·è½åãmedIKAL æ ¹æé«çè¨éä¸­å¯¦é«çé¡åçºå¶åéå æ¬éè¦æ§ï¼å¾èè½å¤ ç²¾ç¢ºå®ä½ KG ä¸­çåé¸ç¾çãå®åµæ°å°æ¡ç¨äºé¡ä¼¼æ®å·®ç¶²è·¯çæ¹æ³ï¼åè¨± LLM çåæ­¥è¨ºæ·è KG æå°çµæåä½µãééåºæ¼è·¯å¾çéæ°æåºæ¼ç®æ³åå¡«ç©ºå¼æç¤ºç¯æ¬ï¼é²ä¸æ­¥åªåäºè¨ºæ·éç¨ãæåééå°æ°æ¨åºçéæºä¸­æ EMR è³æéé²è¡å»£æ³çå¯¦é©ï¼é©è­äº medIKAL çæææ§ï¼è­æäºå¶å¨ç¾å¯¦ä¸çä¸­æ¹åè¨åºè¨ºæ·çæ½åã

##### **Learning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs**
2406.14282v1 by Junjie Wang, Mingyang Chen, Binbin Hu, Dan Yang, Ziqi Liu, Yue Shen, Peng Wei, Zhiqiang Zhang, Jinjie Gu, Jun Zhou, Jeff Z. Pan, Wen Zhang, Huajun Chen

Improving the performance of large language models (LLMs) in complex
question-answering (QA) scenarios has always been a research focal point.
Recent studies have attempted to enhance LLMs' performance by combining
step-wise planning with external retrieval. While effective for advanced models
like GPT-3.5, smaller LLMs face challenges in decomposing complex questions,
necessitating supervised fine-tuning. Previous work has relied on manual
annotation and knowledge distillation from teacher LLMs, which are
time-consuming and not accurate enough. In this paper, we introduce a novel
framework for enhancing LLMs' planning capabilities by using planning data
derived from knowledge graphs (KGs). LLMs fine-tuned with this data have
improved planning capabilities, better equipping them to handle complex QA
tasks that involve retrieval. Evaluations on multiple datasets, including our
newly proposed benchmark, highlight the effectiveness of our framework and the
benefits of KG-derived planning data.

æè¦ï¼<paragraph>æ¹åå¤§åèªè¨æ¨¡å (LLM) å¨è¤éåç­ (QA) æå¢ä¸­çæè½ä¸ç´æ¯ç ç©¶éé»ãæè¿çç ç©¶åè©¦ééçµåéæ­¥è¦åèå¤é¨æ·åä¾å¢å¼· LLM çæè½ãéç¶å°æ¼ GPT-3.5 ç­é²éæ¨¡åä¾èªªå¾ææï¼ä½è¼å°ç LLM å¨åè§£è¤éåé¡ææé¢è¨ææ°ï¼å æ­¤éè¦ç£ç£å¾®èª¿ãååçç ç©¶ä»°è³´äººå·¥æ¨è¨»åæå¸« LLM çç¥è­èåï¼éèæä¸ä¸å¤ ç²¾ç¢ºãå¨æ¬æä¸­ï¼æåä»ç´¹ä¸ååµæ°çæ¶æ§ï¼ééä½¿ç¨å¾ç¥è­åè­ (KG) ä¸­è¡ççè¦åè³æä¾å¢å¼· LLM çè¦åè½åãä½¿ç¨æ­¤è³æå¾®èª¿ç LLM æ¹åäºè¦åè½åï¼è®å®åæ´è½èçæ¶åæ·åçè¤é QA ä»»åãå¨å¤åè³æéï¼åæ¬æåæ°æåºçåºæºï¼ä¸çè©ä¼°çªé¡¯äºæåæ¶æ§çæææ§ï¼ä»¥å KG è¡çè¦åè³æçå¥½èã</paragraph>

##### **ReaLHF: Optimized RLHF Training for Large Language Models through Parameter Reallocation**
2406.14088v1 by Zhiyu Mei, Wei Fu, Kaiwei Li, Guangju Wang, Huanchen Zhang, Yi Wu

Reinforcement Learning from Human Feedback (RLHF) stands as a pivotal
technique in empowering large language model (LLM) applications. Since RLHF
involves diverse computational workloads and intricate dependencies among
multiple LLMs, directly adopting parallelization techniques from supervised
training can result in sub-optimal performance. To overcome this limitation, we
propose a novel approach named parameter ReaLlocation, which dynamically
redistributes LLM parameters in the cluster and adapts parallelization
strategies during training. Building upon this idea, we introduce ReaLHF, a
pioneering system capable of automatically discovering and running efficient
execution plans for RLHF training given the desired algorithmic and hardware
configurations. ReaLHF formulates the execution plan for RLHF as an augmented
dataflow graph. Based on this formulation, ReaLHF employs a tailored search
algorithm with a lightweight cost estimator to discover an efficient execution
plan. Subsequently, the runtime engine deploys the selected plan by effectively
parallelizing computations and redistributing parameters. We evaluate ReaLHF on
the LLaMA-2 models with up to $4\times70$ billion parameters and 128 GPUs. The
experiment results showcase ReaLHF's substantial speedups of $2.0-10.6\times$
compared to baselines. Furthermore, the execution plans generated by ReaLHF
exhibit an average of $26\%$ performance improvement over heuristic approaches
based on Megatron-LM. The source code of ReaLHF is publicly available at
https://github.com/openpsi-project/ReaLHF .

æè¦ï¼å¼·åå­¸ç¿ä¾èªäººé¡åé¥ (RLHF) æ¯ä¸ç¨®ééµæè¡ï¼ç¨æ¼è³¦è½å¤§åèªè¨æ¨¡å (LLM) æç¨ç¨å¼ãç±æ¼ RLHF æ¶åå¤ç¨®éç®å·¥ä½è² è¼åå¤å LLM ä¹éçè¤éä¾è³´éä¿ï¼ç´æ¥æ¡ç¨ç£ç£å¼è¨ç·´çå¹³è¡åæè¡å¯è½æå°è´æ¬¡ä½³æè½ãçºäºåæéåéå¶ï¼æåæåºäºä¸ç¨®åçºåæ¸éæ°éç½®çæ°æ¹æ³ï¼å®æåæéæ°åéå¢éä¸­ç LLM åæ¸ï¼ä¸¦å¨è¨ç·´æéèª¿æ´å¹³è¡åç­ç¥ãå¨æ­¤æ¦å¿µçåºç¤ä¸ï¼æåå¼å¥äº ReaLHFï¼éæ¯ä¸åéåµæ§çç³»çµ±ï¼è½å¤ èªåç¼ç¾ä¸¦å·è¡ RLHF è¨ç·´çé«æå·è¡è¨ç«ï¼ä¸¦èéæéçæ¼ç®æ³åç¡¬é«çµæãReaLHF å° RLHF çå·è¡è¨ç«å¶å®çºä¸åæ´å¢è³ææµåãåºæ¼æ­¤å¶å®ï¼ReaLHF æ¡ç¨éèº«æé çæå°æ¼ç®æ³ï¼æ­éè¼éç´ææ¬ä¼°è¨å¨ï¼ä»¥ç¼ç¾é«æçå·è¡è¨ç«ãé¨å¾ï¼å·è¡æéå¼æééææå¹³è¡åéç®åéæ°åéåæ¸ï¼ä¾é¨ç½²æé¸çè¨ç«ãæåå¨ LLaMA-2 æ¨¡åä¸è©ä¼° ReaLHFï¼è©²æ¨¡åæå¤æ $4\times70$0 åååæ¸å 128 å GPUãå¯¦é©çµæé¡¯ç¤ºï¼èåºæºç¸æ¯ï¼ReaLHF çéåº¦æåäº $2.0-10.6\times$ãæ­¤å¤ï¼ReaLHF çæçå·è¡è¨ç«æ¯åºæ¼ Megatron-LM çåç¼å¼æ¹æ³ï¼å¹³åæè½æåäº $26\%$ãReaLHF çåå§ç¨å¼ç¢¼å¬éæ¼ https://github.com/openpsi-project/ReaLHFã

##### **HIGHT: Hierarchical Graph Tokenization for Graph-Language Alignment**
2406.14021v1 by Yongqiang Chen, Quanming Yao, Juzheng Zhang, James Cheng, Yatao Bian

Recently there has been a surge of interest in extending the success of large
language models (LLMs) to graph modality, such as social networks and
molecules. As LLMs are predominantly trained with 1D text data, most existing
approaches adopt a graph neural network to represent a graph as a series of
node tokens and feed these tokens to LLMs for graph-language alignment. Despite
achieving some successes, existing approaches have overlooked the hierarchical
structures that are inherent in graph data. Especially, in molecular graphs,
the high-order structural information contains rich semantics of molecular
functional groups, which encode crucial biochemical functionalities of the
molecules. We establish a simple benchmark showing that neglecting the
hierarchical information in graph tokenization will lead to subpar
graph-language alignment and severe hallucination in generated outputs. To
address this problem, we propose a novel strategy called HIerarchical GrapH
Tokenization (HIGHT). HIGHT employs a hierarchical graph tokenizer that
extracts and encodes the hierarchy of node, motif, and graph levels of
informative tokens to improve the graph perception of LLMs. HIGHT also adopts
an augmented graph-language supervised fine-tuning dataset, enriched with the
hierarchical graph information, to further enhance the graph-language
alignment. Extensive experiments on 7 molecule-centric benchmarks confirm the
effectiveness of HIGHT in reducing hallucination by 40%, as well as significant
improvements in various molecule-language downstream tasks.

æè¦ï¼<paragraph>æè¿ï¼äººä»¬å¯¹å°å¤§åè¯­è¨æ¨¡å (LLM) çæåæ©å±å°å¾æ¨¡å¼ï¼ä¾å¦ç¤¾äº¤ç½ç»ååå­ï¼äº§çäºæµåçå´è¶£ãç±äº LLM ä¸»è¦ä½¿ç¨ä¸ç»´ææ¬æ°æ®è¿è¡è®­ç»ï¼å æ­¤å¤§å¤æ°ç°ææ¹æ³éç¨å¾ç¥ç»ç½ç»å°å¾è¡¨ç¤ºä¸ºä¸ç³»åèç¹æ è®°ï¼å¹¶å°è¿äºæ è®°é¦éè³ LLM ä»¥è¿è¡å¾è¯­è¨å¯¹é½ãå°½ç®¡åå¾äºä¸äºæåï¼ä½ç°ææ¹æ³å´å¿½è§äºå¾æ°æ®ä¸­åºæçå±æ¬¡ç»æãç¹å«æ¯å¨åå­å¾ä¸­ï¼é«é¶ç»æä¿¡æ¯åå«ä¸°å¯çåå­å®è½å¢è¯­ä¹ï¼å®å¯¹åå­çå³é®çååè½è¿è¡ç¼ç ãæä»¬å»ºç«äºä¸ä¸ªç®åçåºåï¼è¡¨æå¨å¾æ è®°åä¸­å¿½ç¥å±æ¬¡ä¿¡æ¯ä¼å¯¼è´æ¬¡ä¼çå¾è¯­è¨å¯¹é½ï¼å¹¶å¨çæçè¾åºä¸­åºç°ä¸¥éçå¹»è§ãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æä»¬æåºäºä¸ç§ç§°ä¸ºåå±å¾æ è®°å (HIGHT) çæ°ç­ç¥ãHIGHT éç¨åå±å¾æ è®°å¨ï¼è¯¥æ è®°å¨æååç¼ç ä¿¡æ¯æ è®°çèç¹ãä¸»é¢åå¾çº§å«å±æ¬¡ç»æï¼ä»¥æ¹å LLM çå¾æç¥ãHIGHT è¿éç¨äºä¸ä¸ªç»è¿æ©åçå¾è¯­è¨çç£å¾®è°æ°æ®éï¼è¯¥æ°æ®éåå«åå±å¾ä¿¡æ¯ï¼ä»¥è¿ä¸æ­¥å¢å¼ºå¾è¯­è¨å¯¹é½ãå¨ 7 ä¸ªä»¥åå­ä¸ºä¸­å¿çåºåä¸çå¤§éå®éªè¯å®äº HIGHT å¨å°å¹»è§åå° 40% æ¹é¢çæææ§ï¼ä»¥åå¨åç§åå­è¯­è¨ä¸æ¸¸ä»»å¡ä¸­çæ¾èæ¹è¿ã</paragraph>

##### **A Pure Transformer Pretraining Framework on Text-attributed Graphs**
2406.13873v1 by Yu Song, Haitao Mao, Jiachen Xiao, Jingzhe Liu, Zhikai Chen, Wei Jin, Carl Yang, Jiliang Tang, Hui Liu

Pretraining plays a pivotal role in acquiring generalized knowledge from
large-scale data, achieving remarkable successes as evidenced by large models
in CV and NLP. However, progress in the graph domain remains limited due to
fundamental challenges such as feature heterogeneity and structural
heterogeneity. Recently, increasing efforts have been made to enhance node
feature quality with Large Language Models (LLMs) on text-attributed graphs
(TAGs), demonstrating superiority to traditional bag-of-words or word2vec
techniques. These high-quality node features reduce the previously critical
role of graph structure, resulting in a modest performance gap between Graph
Neural Networks (GNNs) and structure-agnostic Multi-Layer Perceptrons (MLPs).
Motivated by this, we introduce a feature-centric pretraining perspective by
treating graph structure as a prior and leveraging the rich, unified feature
space to learn refined interaction patterns that generalizes across graphs. Our
framework, Graph Sequence Pretraining with Transformer (GSPT), samples node
contexts through random walks and employs masked feature reconstruction to
capture pairwise proximity in the LLM-unified feature space using a standard
Transformer. By utilizing unified text representations rather than varying
structures, our framework achieves significantly better transferability among
graphs within the same domain. GSPT can be easily adapted to both node
classification and link prediction, demonstrating promising empirical success
on various datasets.

æè¦ï¼é è¨ç·´å¨å¾å¤§åè³æä¸­ç²åå»£æ³ç¥è­æ¹é¢ç¼æ®äºééµä½ç¨ï¼å¾ CV å NLP ä¸­çå¤§åæ¨¡åæè­æçé¡¯èæåä¸­å³å¯è¦ä¸æãç¶èï¼ç±æ¼ç¹å¾µç°è³ªæ§åçµæ§ç°è³ªæ§ç­åºæ¬ææ°ï¼åå½¢é åçé²å±ä»ç¶æéãæè¿ï¼äººåå¨ææ¬å±¬æ§å (TAG) ä¸ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾å¢å¼·ç¯é»ç¹å¾µåè³ªï¼ä¸¦å·²ååºè¶ä¾è¶å¤åªåï¼è­æå¶åªæ¼å³çµ±çè©è¢æ word2vec æè¡ãéäºé«åè³ªç¯é»ç¹å¾µéä½äºåå½¢çµæ§ååè³ééè¦çä½ç¨ï¼å°è´åå½¢ç¥ç¶ç¶²è·¯ (GNN) åèçµæ§ç¡éçå¤å±¤æç¥å¨ (MLP) ä¹éçæè½å·®è·ç¸®å°ãåå°æ­¤åç¼ï¼æåééå°åå½¢çµæ§è¦çºåé©ï¼ä¸¦å©ç¨è±å¯ççµ±ä¸ç¹å¾µç©ºéä¾å­¸ç¿å¨åå½¢ä¸­æ¦æ¬çç²¾ç·»äºåæ¨¡å¼ï¼å¼å¥äºä»¥ç¹å¾µçºä¸­å¿çé è¨ç·´è§é»ãæåçæ¶æ§åå½¢åºåé è¨ç·´è Transformer (GSPT)ï¼ééé¨æ©éèµ°åæ¨£ç¯é»èçµ¡ï¼ä¸¦æ¡ç¨é®è½ç¹å¾µéå»ºï¼ä»¥ä½¿ç¨æ¨æº Transformer å¨ LLM çµ±ä¸ç¹å¾µç©ºéä¸­æ·åæå°æ¥è¿åº¦ãééå©ç¨çµ±ä¸çæå­è¡¨å¾µï¼èéè®åççµæ§ï¼æåçæ¶æ§å¨åä¸åç¶²åä¸­çåå½¢ä¹ééå°äºé¡¯èæ´å¥½çå¯å³éæ§ãGSPT å¯ä»¥è¼é¬å°èª¿æ´å°ç¯é»åé¡åé£çµé æ¸¬ï¼å¨åç¨®è³æéä¸å±ç¾åºæå¸æçå¯¦è­æåã

##### **Knowledge Graph-Enhanced Large Language Models via Path Selection**
2406.13862v1 by Haochen Liu, Song Wang, Yaochen Zhu, Yushun Dong, Jundong Li

Large Language Models (LLMs) have shown unprecedented performance in various
real-world applications. However, they are known to generate factually
inaccurate outputs, a.k.a. the hallucination problem. In recent years,
incorporating external knowledge extracted from Knowledge Graphs (KGs) has
become a promising strategy to improve the factual accuracy of LLM-generated
outputs. Nevertheless, most existing explorations rely on LLMs themselves to
perform KG knowledge extraction, which is highly inflexible as LLMs can only
provide binary judgment on whether a certain knowledge (e.g., a knowledge path
in KG) should be used. In addition, LLMs tend to pick only knowledge with
direct semantic relationship with the input text, while potentially useful
knowledge with indirect semantics can be ignored. In this work, we propose a
principled framework KELP with three stages to handle the above problems.
Specifically, KELP is able to achieve finer granularity of flexible knowledge
extraction by generating scores for knowledge paths with input texts via latent
semantic matching. Meanwhile, knowledge paths with indirect semantic
relationships with the input text can also be considered via trained encoding
between the selected paths in KG and the input text. Experiments on real-world
datasets validate the effectiveness of KELP.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®å¯¦éæç¨ä¸­å±ç¾äºåææªæçæè½ãç¶èï¼å®åæç¢çäºå¯¦ä¸ä¸æºç¢ºçè¼¸åºï¼ä¹å°±æ¯æè¬çå¹»è¦ºåé¡ãè¿å¹´ä¾ï¼ç´å¥å¾ç¥è­åè­ (KG) ä¸­èåçå¤é¨ç¥è­å·²æçºæ¹å LLM çæçè¼¸åºäºå¯¦æºç¢ºæ§çæåéç­ç¥ãåç®¡å¦æ­¤ï¼ç¾æçæ¢ç´¢å¤§å¤ä¾è³´ LLM æ¬èº«ä¾å·è¡ KG ç¥è­èåï¼ééå¸¸ä¸éæ´»ï¼å çº LLM åªæå°ç¹å®ç¥è­ï¼ä¾å¦ï¼KG ä¸­çç¥è­è·¯å¾ï¼æ¯å¦æè©²ä½¿ç¨æä¾äºåå¤æ·ãæ­¤å¤ï¼LLM å¾ååæé¸èè¼¸å¥æå­æç´æ¥èªç¾©éä¿çç¥è­ï¼èå¯è½å°èªææéæ¥éè¯çæç¨ç¥è­å¯è½æè¢«å¿½ç¥ãå¨éé å·¥ä½ä¸­ï¼æåæåºä¸åæååç KELP æ¶æ§ï¼åå«ä¸åéæ®µä¾èçä¸è¿°åé¡ãå·é«ä¾èªªï¼KELP è½å¤ ééé±å«èªç¾©æ¯å°çºç¥è­è·¯å¾èè¼¸å¥æå­ç¢çåæ¸ï¼é²èéææ´ç´°ç·»çå½æ§ç¥è­èåãåæï¼ä¹å¯ä»¥ééå¨ KG ä¸­é¸å®çè·¯å¾èè¼¸å¥æå­ä¹éè¨ç·´ç·¨ç¢¼çæ¹å¼ï¼èéèè¼¸å¥æå­æéæ¥èªç¾©éä¿çç¥è­è·¯å¾ãå¨å¯¦éè³æéä¸çå¯¦é©é©è­äº KELP çæææ§ã

##### **Few-shot Knowledge Graph Relational Reasoning via Subgraph Adaptation**
2406.15507v1 by Haochen Liu, Song Wang, Chen Chen, Jundong Li

Few-shot Knowledge Graph (KG) Relational Reasoning aims to predict unseen
triplets (i.e., query triplets) for rare relations in KGs, given only several
triplets of these relations as references (i.e., support triplets). This task
has gained significant traction due to the widespread use of knowledge graphs
in various natural language processing applications. Previous approaches have
utilized meta-training methods and manually constructed meta-relation sets to
tackle this task. Recent efforts have focused on edge-mask-based methods, which
exploit the structure of the contextualized graphs of target triplets (i.e., a
subgraph containing relevant triplets in the KG). However, existing
edge-mask-based methods have limitations in extracting insufficient information
from KG and are highly influenced by spurious information in KG. To overcome
these challenges, we propose SAFER (Subgraph Adaptation for Few-shot Relational
Reasoning), a novel approach that effectively adapts the information in
contextualized graphs to various subgraphs generated from support and query
triplets to perform the prediction. Specifically, SAFER enables the extraction
of more comprehensive information from support triplets while minimizing the
impact of spurious information when predicting query triplets. Experimental
results on three prevalent datasets demonstrate the superiority of our proposed
framework SAFER.

æè¦ï¼å°æ ·æ¬ç¥è¯å¾è°± (KG) å³ç³»æ¨çæ¨å¨é¢æµ KG ä¸­ç½è§å³ç³»ççä¸è§ä¸åç»ï¼å³æ¥è¯¢ä¸åç»ï¼ï¼èä»ç»åºå ä¸ªä¸åç»ä½ä¸ºåèï¼å³æ¯æä¸åç»ï¼ãç±äºç¥è¯å¾è°±å¨åç§èªç¶è¯­è¨å¤çåºç¨ç¨åºä¸­çå¹¿æ³ä½¿ç¨ï¼è¿é¡¹ä»»å¡è·å¾äºæ¾èçå³æ³¨ãä»¥åçæ¹æ³å©ç¨åè®­ç»æ¹æ³åæå¨æå»ºçåå³ç³»éæ¥è§£å³æ­¤ä»»å¡ãæè¿çåªåéä¸­å¨åºäºè¾¹ç¼æ©ç çæ¹æ³ä¸ï¼è¯¥æ¹æ³å©ç¨ç®æ ä¸åç»çä¸ä¸æåå¾çç»æï¼å³åå« KG ä¸­ç¸å³ä¸åç»çå­å¾ï¼ãç¶èï¼ç°æçåºäºè¾¹ç¼æ©ç çæ¹æ³å¨ä» KG ä¸­æåä¸è¶³ä¿¡æ¯æ¹é¢å­å¨å±éæ§ï¼å¹¶ä¸å KG ä¸­èåä¿¡æ¯çæå¤§å½±åãä¸ºäºåæè¿äºææï¼æä»¬æåºäº SAFERï¼ç¨äºå°æ ·æ¬å³ç³»æ¨ççå­å¾èªéåºï¼ï¼ä¸ç§æ°é¢çæ¹æ³ï¼å®ææå°å°ä¸ä¸æåå¾ä¸­çä¿¡æ¯éåºä»æ¯æåæ¥è¯¢ä¸åç»çæçä¸åå­å¾ä»¥æ§è¡é¢æµãå·ä½æ¥è¯´ï¼SAFER è½å¤ä»æ¯æä¸åç»ä¸­æåæ´å¨é¢çä¿¡æ¯ï¼åæ¶å¨é¢æµæ¥è¯¢ä¸åç»æ¶æå¤§ç¨åº¦å°åå°èåä¿¡æ¯çå½±åãå¨ä¸ä¸ªæµè¡æ°æ®éä¸çå®éªç»æè¯æäºæä»¬æåºç SAFER æ¡æ¶çä¼è¶æ§ã

##### **Dr.E Bridges Graphs with Large Language Models through Words**
2406.15504v1 by Zipeng Liu, Likang Wu, Ming He, Zhong Guan, Hongke Zhao, Nan Feng

Significant efforts have been directed toward integrating powerful Large
Language Models (LLMs) with diverse modalities, particularly focusing on the
fusion of vision, language, and audio data. However, the graph-structured data,
inherently rich in structural and domain-specific knowledge, have not yet been
gracefully adapted to LLMs. Existing methods either describe the graph with raw
text, suffering the loss of graph structural information, or feed Graph Neural
Network (GNN) embeddings directly into LLM at the cost of losing semantic
representation. To bridge this gap, we introduce an innovative, end-to-end
modality-aligning framework, equipped with a pretrained Dual-Residual Vector
Quantized-Variational AutoEncoder (Dr.E). This framework is specifically
designed to facilitate token-level alignment with LLMs, enabling an effective
translation of the intrinsic `language' of graphs into comprehensible natural
language. Our experimental evaluations on standard GNN node classification
tasks demonstrate competitive performance against other state-of-the-art
approaches. Additionally, our framework ensures interpretability, efficiency,
and robustness, with its effectiveness further validated under both fine-tuning
and few-shot settings. This study marks the first successful endeavor to
achieve token-level alignment between GNNs and LLMs.

æè¦ï¼å¤§éçåªåå·²æå¥å°å°å¼·å¤§çå¤§åèªè¨æ¨¡å (LLM) èä¸åçæ¨¡ææ´åï¼ç¹å¥æ¯å°æ³¨æ¼è¦è¦ºãèªè¨åé³è¨è³æçèåãç¶èï¼åå½¢çµæ§åçè³ææ¬è³ªä¸å¯å«çµæ§åé åç¹å®çç¥è­ï¼ä½å°æªåªéå°é©æ LLMãç¾ææ¹æ³ä¸æ¯ç¨åå§æå­æè¿°åå½¢ï¼å°è´åå½¢çµæ§è³è¨éºå¤±ï¼å°±æ¯å°åå½¢ç¥ç¶ç¶²è·¯ (GNN) çåµå¥ç´æ¥é¥å¥ LLMï¼ä»£å¹æ¯å¤±å»èªç¾©è¡¨ç¤ºãçºäºå½è£éåå·®è·ï¼æåå¼å¥äºä¸ååµæ°çç«¯å°ç«¯æ¨¡æå°é½æ¡æ¶ï¼éåäºä¸åé åè¨ç·´çéæ®å·®åééåè®åèªç·¨ç¢¼å¨ (Dr.E)ãæ­¤æ¡æ¶ç¹å¥è¨­è¨ç¨æ¼ä¿é²è LLM çæ¨è¨å±¤ç´å°é½ï¼è®åå½¢çå§å¨ãèªè¨ãè½ææè½ææææ¼çè§£çèªç¶èªè¨ãæåå¨æ¨æº GNN ç¯é»åé¡ä»»åä¸çå¯¦é©è©ä¼°é¡¯ç¤ºï¼èå¶ä»æåé²çæ¹æ³ç¸æ¯ï¼æåçè¡¨ç¾å·æç«¶ç­åãæ­¤å¤ï¼æåçæ¡æ¶ç¢ºä¿äºè§£éæ§ãæçåç©©å¥æ§ï¼å¨å¾®èª¿åå°æ¨£æ¬è¨­å®ä¸é²ä¸æ­¥é©è­å¶æææ§ãéé ç ç©¶æ¨èªèå¨ GNN å LLM ä¹éå¯¦ç¾æ¨è¨å±¤ç´å°é½çé¦æ¬¡æååè©¦ã

##### **Enhancing Distractor Generation for Multiple-Choice Questions with Retrieval Augmented Pretraining and Knowledge Graph Integration**
2406.13578v1 by Han-Cheng Yu, Yu-An Shih, Kin-Man Law, Kai-Yu Hsieh, Yu-Chen Cheng, Hsin-Chih Ho, Zih-An Lin, Wen-Chuan Hsu, Yao-Chung Fan

In this paper, we tackle the task of distractor generation (DG) for
multiple-choice questions. Our study introduces two key designs. First, we
propose \textit{retrieval augmented pretraining}, which involves refining the
language model pretraining to align it more closely with the downstream task of
DG. Second, we explore the integration of knowledge graphs to enhance the
performance of DG. Through experiments with benchmarking datasets, we show that
our models significantly outperform the state-of-the-art results. Our
best-performing model advances the F1@3 score from 14.80 to 16.47 in MCQ
dataset and from 15.92 to 16.50 in Sciq dataset.

æè¦ï¼å¨æ¬æä¸­ï¼æä»¬èçå¤é¸é¡çå¹²æ¾å¨çæ (DG) ä»»åãæåçç ç©¶å¼å¥äºå©åééµè¨­è¨ãé¦åï¼æåæåºãæª¢ç´¢å¢å¼·é è¨ç·´ãï¼å¶ä¸­åå«åªåèªè¨æ¨¡åé è¨ç·´ï¼ä½¿å¶è DG çä¸æ¸¸ä»»åæ´ç·å¯å°å°é½ãå¶æ¬¡ï¼æåæ¢è¨ç¥è­åè¡¨çæ´åï¼ä»¥å¢å¼· DG çæè½ãééåºæºè³æéçå¯¦é©ï¼æåè­ææåçæ¨¡åæé¡¯åªæ¼æåé²ççµæãæåæè½æä½³çæ¨¡åå° MCQ è³æéä¸­ç F1@3 åæ¸å¾ 14.80 æåå° 16.47ï¼å¨ Sciq è³æéä¸­å¾ 15.92 æåå° 16.50ã

