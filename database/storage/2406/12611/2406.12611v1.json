{"2406.12611": {"publish_time": "2024-06-18", "title": "Rapid Language Adaptation for Multilingual E2E Speech Recognition Using Encoder Prompting", "paper_summary": "End-to-end multilingual speech recognition models handle multiple languages\nthrough a single model, often incorporating language identification to\nautomatically detect the language of incoming speech. Since the common scenario\nis where the language is already known, these models can perform as\nlanguage-specific by using language information as prompts, which is\nparticularly beneficial for attention-based encoder-decoder architectures.\nHowever, the Connectionist Temporal Classification (CTC) approach, which\nenhances recognition via joint decoding and multi-task training, does not\nnormally incorporate language prompts due to its conditionally independent\noutput tokens. To overcome this, we introduce an encoder prompting technique\nwithin the self-conditioned CTC framework, enabling language-specific\nadaptation of the CTC model in a zero-shot manner. Our method has shown to\nsignificantly reduce errors by 28% on average and by 41% on low-resource\nlanguages.", "paper_summary_zh": "\u7aef\u5230\u7aef\u591a\u8a9e\u8a00\u8a9e\u97f3\u8fa8\u8b58\u6a21\u578b\u900f\u904e\u55ae\u4e00\u6a21\u578b\u8655\u7406\u591a\u7a2e\u8a9e\u8a00\uff0c\u901a\u5e38\u6703\u7d50\u5408\u8a9e\u8a00\u8fa8\u8b58\u4f86\u81ea\u52d5\u5075\u6e2c\u8f38\u5165\u8a9e\u97f3\u7684\u8a9e\u8a00\u3002\u7531\u65bc\u5e38\u898b\u7684\u60c5\u6cc1\u662f\u8a9e\u8a00\u5df2\u7d93\u5df2\u77e5\uff0c\u9019\u4e9b\u6a21\u578b\u53ef\u4ee5\u900f\u904e\u4f7f\u7528\u8a9e\u8a00\u8cc7\u8a0a\u4f5c\u70ba\u63d0\u793a\u4f86\u57f7\u884c\u8a9e\u8a00\u7279\u5b9a\u4efb\u52d9\uff0c\u9019\u5c0d\u65bc\u57fa\u65bc\u6ce8\u610f\u529b\u7684\u7de8\u78bc\u5668-\u89e3\u78bc\u5668\u67b6\u69cb\u7279\u5225\u6709\u5e6b\u52a9\u3002\u7136\u800c\uff0c\u9023\u63a5\u6642\u5e8f\u5206\u985e (CTC) \u65b9\u6cd5\u6703\u900f\u904e\u806f\u5408\u89e3\u78bc\u548c\u591a\u4efb\u52d9\u8a13\u7df4\u4f86\u589e\u5f37\u8fa8\u8b58\uff0c\u901a\u5e38\u4e0d\u6703\u7d50\u5408\u8a9e\u8a00\u63d0\u793a\uff0c\u56e0\u70ba\u5176\u689d\u4ef6\u7368\u7acb\u7684\u8f38\u51fa\u7b26\u865f\u3002\u70ba\u4e86\u514b\u670d\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u5728\u81ea\u689d\u4ef6 CTC \u67b6\u69cb\u4e2d\u5f15\u5165\u7de8\u78bc\u63d0\u793a\u6280\u8853\uff0c\u4ee5\u96f6\u6b21\u5b78\u7fd2\u7684\u65b9\u5f0f\u555f\u7528 CTC \u6a21\u578b\u7684\u8a9e\u8a00\u7279\u5b9a\u9069\u61c9\u3002\u6211\u5011\u7684\u6280\u8853\u5df2\u8b49\u660e\u53ef\u4ee5\u5e73\u5747\u6e1b\u5c11 28% \u7684\u932f\u8aa4\uff0c\u4e26\u6e1b\u5c11\u4f4e\u8cc7\u6e90\u8a9e\u8a00 41% \u7684\u932f\u8aa4\u3002", "author": "Yosuke Kashiwagi et.al.", "authors": "Yosuke Kashiwagi, Hayato Futami, Emiru Tsunoo, Siddhant Arora, Shinji Watanabe", "id": "2406.12611v1", "paper_url": "http://arxiv.org/abs/2406.12611v1", "repo": "null"}}