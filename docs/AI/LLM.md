
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-21**|**Efficient Exploration and Discriminative World Model Learning with an Object-Centric Abstraction**|Anthony GX-Chen et.al.|[2408.11816v1](http://arxiv.org/abs/2408.11816v1)|null|
|**2024-08-21**|**Great Memory, Shallow Reasoning: Limits of $k$NN-LMs**|Shangyi Geng et.al.|[2408.11815v1](http://arxiv.org/abs/2408.11815v1)|[link](https://github.com/gsyfate/knnlm-limits)|
|**2024-08-21**|**Approaching Deep Learning through the Spectral Dynamics of Weights**|David Yunis et.al.|[2408.11804v1](http://arxiv.org/abs/2408.11804v1)|[link](https://github.com/dyunis/spectral_dynamics)|
|**2024-08-21**|**PermitQA: A Benchmark for Retrieval Augmented Generation in Wind Siting and Permitting domain**|Rounak Meyur et.al.|[2408.11800v1](http://arxiv.org/abs/2408.11800v1)|null|
|**2024-08-21**|**Practical token pruning for foundation models in few-shot conversational virtual assistant systems**|Haode Qi et.al.|[2408.11799v1](http://arxiv.org/abs/2408.11799v1)|null|
|**2024-08-21**|**LLM Pruning and Distillation in Practice: The Minitron Approach**|Sharath Turuvekere Sreenivas et.al.|[2408.11796v1](http://arxiv.org/abs/2408.11796v1)|null|
|**2024-08-21**|**Leveraging Chemistry Foundation Models to Facilitate Structure Focused Retrieval Augmented Generation in Multi-Agent Workflows for Catalyst and Materials Design**|Nathaniel H. Park et.al.|[2408.11793v1](http://arxiv.org/abs/2408.11793v1)|null|
|**2024-08-21**|**DreamFactory: Pioneering Multi-Scene Long Video Generation with a Multi-Agent Framework**|Zhifei Xie et.al.|[2408.11788v1](http://arxiv.org/abs/2408.11788v1)|null|
|**2024-08-21**|**Timeline and Boundary Guided Diffusion Network for Video Shadow Detection**|Haipeng Zhou et.al.|[2408.11785v1](http://arxiv.org/abs/2408.11785v1)|[link](https://github.com/haipengzhou856/tbgdiff)|
|**2024-08-21**|**Personality Alignment of Large Language Models**|Minjun Zhu et.al.|[2408.11779v1](http://arxiv.org/abs/2408.11779v1)|[link](https://github.com/zhu-minjun/palign)|
|**2024-08-21**|**Sum of Squares Circuits**|Lorenzo Loconte et.al.|[2408.11778v1](http://arxiv.org/abs/2408.11778v1)|null|
|**2024-08-21**|**Leveraging Fine-Tuned Retrieval-Augmented Generation with Long-Context Support: For 3GPP Standards**|Omar Erak et.al.|[2408.11775v1](http://arxiv.org/abs/2408.11775v1)|[link](https://github.com/Nouf-Alabbasi/oKUmura_AI_Telecom_challenge)|
|**2024-08-21**|**D-RMGPT: Robot-assisted collaborative tasks driven by large multimodal models**|M. Forlini et.al.|[2408.11761v1](http://arxiv.org/abs/2408.11761v1)|null|
|**2024-08-21**|**SBDet: A Symmetry-Breaking Object Detector via Relaxed Rotation-Equivariance**|Zhiqiang Wu et.al.|[2408.11760v1](http://arxiv.org/abs/2408.11760v1)|null|
|**2024-08-21**|**Against All Odds: Overcoming Typology, Script, and Language Confusion in Multilingual Embedding Inversion Attacks**|Yiyi Chen et.al.|[2408.11749v1](http://arxiv.org/abs/2408.11749v1)|null|
|**2024-08-21**|**Open-Ended 3D Point Cloud Instance Segmentation**|Phuc D. A. Nguyen et.al.|[2408.11747v1](http://arxiv.org/abs/2408.11747v1)|null|
|**2024-08-21**|**FocusLLM: Scaling LLM's Context by Parallel Decoding**|Zhenyu Li et.al.|[2408.11745v1](http://arxiv.org/abs/2408.11745v1)|null|
|**2024-08-21**|**JieHua Paintings Style Feature Extracting Model using Stable Diffusion with ControlNet**|Yujia Gu et.al.|[2408.11744v1](http://arxiv.org/abs/2408.11744v1)|null|
|**2024-08-21**|**CluMo: Cluster-based Modality Fusion Prompt for Continual Learning in Visual Question Answering**|Yuliang Cai et.al.|[2408.11742v1](http://arxiv.org/abs/2408.11742v1)|null|
|**2024-08-21**|**Clinical Insights: A Comprehensive Review of Language Models in Medicine**|Nikita Neveditsin et.al.|[2408.11735v1](http://arxiv.org/abs/2408.11735v1)|null|
|**2024-08-21**|**Efficient Detection of Toxic Prompts in Large Language Models**|Yi Liu et.al.|[2408.11727v1](http://arxiv.org/abs/2408.11727v1)|null|
|**2024-08-21**|**Iterative Object Count Optimization for Text-to-image Diffusion Models**|Oz Zafar et.al.|[2408.11721v1](http://arxiv.org/abs/2408.11721v1)|null|
|**2024-08-21**|**Leveraging Large Language Models for Enhancing the Understandability of Generated Unit Tests**|Amirhossein Deljouyi et.al.|[2408.11710v1](http://arxiv.org/abs/2408.11710v1)|null|
|**2024-08-21**|**Physics-informed Discovery of State Variables in Second-Order and Hamiltonian Systems**|Félix Chavelli et.al.|[2408.11691v1](http://arxiv.org/abs/2408.11691v1)|null|
|**2024-08-21**|**5G NR PRACH Detection with Convolutional Neural Networks (CNN): Overcoming Cell Interference Challenges**|Desire Guel et.al.|[2408.11659v1](http://arxiv.org/abs/2408.11659v1)|null|
|**2024-08-21**|**CIPHER: Cybersecurity Intelligent Penetration-testing Helper for Ethical Researcher**|Derry Pratama et.al.|[2408.11650v1](http://arxiv.org/abs/2408.11650v1)|null|
|**2024-08-21**|**Video-to-Text Pedestrian Monitoring (VTPM): Leveraging Computer Vision and Large Language Models for Privacy-Preserve Pedestrian Activity Monitoring at Intersections**|Ahmed S. Abdelrahman et.al.|[2408.11649v1](http://arxiv.org/abs/2408.11649v1)|null|
|**2024-08-21**|**Data-driven Modeling of Combined Sewer Systems for Urban Sustainability: An Empirical Evaluation**|Vipin Singh et.al.|[2408.11619v1](http://arxiv.org/abs/2408.11619v1)|null|
|**2024-08-21**|**Xinyu: An Efficient LLM-based System for Commentary Generation**|Yiquan Wu et.al.|[2408.11609v1](http://arxiv.org/abs/2408.11609v1)|null|
|**2024-08-21**|**Cause-Aware Empathetic Response Generation via Chain-of-Thought Fine-Tuning**|Xinhao Chen et.al.|[2408.11599v1](http://arxiv.org/abs/2408.11599v1)|null|
|**2024-08-21**|**Active learning for efficient data selection in radio-signal based positioning via deep learning**|Vincent Corlay et.al.|[2408.11592v1](http://arxiv.org/abs/2408.11592v1)|null|
|**2024-08-21**|**Large Language Models are Good Attackers: Efficient and Stealthy Textual Backdoor Attacks**|Ziqiang Li et.al.|[2408.11587v1](http://arxiv.org/abs/2408.11587v1)|null|
|**2024-08-21**|**Drama Engine: A Framework for Narrative Agents**|Martin Pichlmair et.al.|[2408.11574v1](http://arxiv.org/abs/2408.11574v1)|null|
|**2024-08-21**|**Differentiating Choices via Commonality for Multiple-Choice Question Answering**|Wenqing Deng et.al.|[2408.11554v1](http://arxiv.org/abs/2408.11554v1)|[link](https://github.com/dwq-vicki/dcqa)|
|**2024-08-21**|**Explainable Deep Learning Framework for Human Activity Recognition**|Yiran Huang et.al.|[2408.11552v1](http://arxiv.org/abs/2408.11552v1)|null|
|**2024-08-21**|**Memorization In In-Context Learning**|Shahriar Golchin et.al.|[2408.11546v1](http://arxiv.org/abs/2408.11546v1)|null|
|**2024-08-21**|**RConE: Rough Cone Embedding for Multi-Hop Logical Query Answering on Multi-Modal Knowledge Graphs**|Mayank Kharbanda et.al.|[2408.11526v1](http://arxiv.org/abs/2408.11526v1)|[link](https://github.com/kracr/rcone-qa-mmkg)|
|**2024-08-21**|**LARR: Large Language Model Aided Real-time Scene Recommendation with Semantic Understanding**|Zhizhong Wan et.al.|[2408.11523v1](http://arxiv.org/abs/2408.11523v1)|null|
|**2024-08-21**|**Imagining from Images with an AI Storytelling Tool**|Edirlei Soares de Lima et.al.|[2408.11517v1](http://arxiv.org/abs/2408.11517v1)|null|
|**2024-08-21**|**IKUN for WMT24 General MT Task: LLMs Are here for Multilingual Machine Translation**|Baohao Liao et.al.|[2408.11512v1](http://arxiv.org/abs/2408.11512v1)|null|
|**2024-08-21**|**Mutagenesis screen to map the functionals of parameters of Large Language Models**|Yue Hu et.al.|[2408.11494v1](http://arxiv.org/abs/2408.11494v1)|null|
|**2024-08-21**|**Estimating Peer Direct and Indirect Effects in Observational Network Data**|Xiaojing Du et.al.|[2408.11492v1](http://arxiv.org/abs/2408.11492v1)|null|
|**2024-08-21**|**Nothing in Excess: Mitigating the Exaggerated Safety for LLMs via Safety-Conscious Activation Steering**|Zouying Cao et.al.|[2408.11491v1](http://arxiv.org/abs/2408.11491v1)|null|
|**2024-08-21**|**DocTabQA: Answering Questions from Long Documents Using Tables**|Haochen Wang et.al.|[2408.11490v1](http://arxiv.org/abs/2408.11490v1)|null|
|**2024-08-21**|**The Self-Contained Negation Test Set**|David Kletz et.al.|[2408.11469v1](http://arxiv.org/abs/2408.11469v1)|null|
|**2024-08-21**|**Expanding FLORES+ Benchmark for more Low-Resource Settings: Portuguese-Emakhuwa Machine Translation Evaluation**|Felermino D. M. Antonio Ali et.al.|[2408.11457v1](http://arxiv.org/abs/2408.11457v1)|null|
|**2024-08-21**|**Using Part-based Representations for Explainable Deep Reinforcement Learning**|Manos Kirtas et.al.|[2408.11455v1](http://arxiv.org/abs/2408.11455v1)|null|
|**2024-08-21**|**Bidirectional Gated Mamba for Sequential Recommendation**|Ziwei Liu et.al.|[2408.11451v1](http://arxiv.org/abs/2408.11451v1)|[link](https://github.com/ziwliu-cityu/simga)|
|**2024-08-21**|**Enabling Small Models for Zero-Shot Classification through Model Label Learning**|Jia Zhang et.al.|[2408.11449v1](http://arxiv.org/abs/2408.11449v1)|null|
|**2024-08-21**|**Lookism: The overlooked bias in computer vision**|Aditya Gulati et.al.|[2408.11448v1](http://arxiv.org/abs/2408.11448v1)|null|
|**2024-08-21**|**Distributional Properties of Subword Regularization**|Marco Cognetta et.al.|[2408.11443v1](http://arxiv.org/abs/2408.11443v1)|null|
|**2024-08-21**|**LAHAJA: A Robust Multi-accent Benchmark for Evaluating Hindi ASR Systems**|Tahir Javed et.al.|[2408.11440v1](http://arxiv.org/abs/2408.11440v1)|[link](https://github.com/ai4bharat/lahaja)|
|**2024-08-21**|**Towards Aligned Data Removal via Twin Machine Unlearning**|Yuyao Sun et.al.|[2408.11433v1](http://arxiv.org/abs/2408.11433v1)|null|
|**2024-08-21**|**Diagnosing and Remedying Knowledge Deficiencies in LLMs via Label-free Curricular Meaningful Learning**|Kai Xiong et.al.|[2408.11431v1](http://arxiv.org/abs/2408.11431v1)|null|
|**2024-08-21**|**Towards "Differential AI Psychology" and in-context Value-driven Statement Alignment with Moral Foundations Theory**|Simon Münker et.al.|[2408.11415v1](http://arxiv.org/abs/2408.11415v1)|null|
|**2024-08-21**|**MoE-LPR: Multilingual Extension of Large Language Models through Mixture-of-Experts with Language Priors Routing**|Hao Zhou et.al.|[2408.11396v1](http://arxiv.org/abs/2408.11396v1)|[link](https://github.com/zjwang21/moe-lpr)|
|**2024-08-21**|**First Activations Matter: Training-Free Methods for Dynamic Activation in Large Language Models**|Chi Ma et.al.|[2408.11393v1](http://arxiv.org/abs/2408.11393v1)|null|
|**2024-08-21**|**Data-Centric Machine Learning for Earth Observation: Necessary and Sufficient Features**|Hiba Najjar et.al.|[2408.11384v1](http://arxiv.org/abs/2408.11384v1)|null|
|**2024-08-21**|**On the Interchangeability of Positional Embeddings in Multilingual Neural Machine Translation Models**|Varun Gumma et.al.|[2408.11382v1](http://arxiv.org/abs/2408.11382v1)|null|
|**2024-08-21**|**RAGLAB: A Modular and Research-Oriented Unified Framework for Retrieval-Augmented Generation**|Xuanwang Zhang et.al.|[2408.11381v1](http://arxiv.org/abs/2408.11381v1)|[link](https://github.com/fate-ubw/raglab)|
|**2024-08-21**|**Reflex-Based Open-Vocabulary Navigation without Prior Knowledge Using Omnidirectional Camera and Multiple Vision-Language Models**|Kento Kawaharazuka et.al.|[2408.11380v1](http://arxiv.org/abs/2408.11380v1)|null|
|**2024-08-21**|**Denoising Pre-Training and Customized Prompt Learning for Efficient Multi-Behavior Sequential Recommendation**|Hao Wang et.al.|[2408.11372v1](http://arxiv.org/abs/2408.11372v1)|null|
|**2024-08-21**|**Solving Decision Theory Problems with Probabilistic Answer Set Programming**|Damiano Azzolini et.al.|[2408.11371v1](http://arxiv.org/abs/2408.11371v1)|null|
|**2024-08-21**|**Graph Classification via Reference Distribution Learning: Theory and Practice**|Zixiao Wang et.al.|[2408.11370v1](http://arxiv.org/abs/2408.11370v1)|null|
|**2024-08-21**|**Towards Probabilistic Inductive Logic Programming with Neurosymbolic Inference and Relaxation**|Fieke Hillerstrom et.al.|[2408.11367v1](http://arxiv.org/abs/2408.11367v1)|null|
|**2024-08-21**|**GeoReasoner: Reasoning On Geospatially Grounded Context For Natural Language Understanding**|Yibo Yan et.al.|[2408.11366v1](http://arxiv.org/abs/2408.11366v1)|null|
|**2024-08-21**|**ProteinGPT: Multimodal LLM for Protein Property Prediction and Structure Understanding**|Yijia Xiao et.al.|[2408.11363v1](http://arxiv.org/abs/2408.11363v1)|null|
|**2024-08-21**|**Hypergraph Learning based Recommender System for Anomaly Detection, Control and Optimization**|Sakhinana Sagar Srinivas et.al.|[2408.11359v1](http://arxiv.org/abs/2408.11359v1)|null|
|**2024-08-21**|**One-step Structure Prediction and Screening for Protein-Ligand Complexes using Multi-Task Geometric Deep Learning**|Kelei He et.al.|[2408.11356v1](http://arxiv.org/abs/2408.11356v1)|null|
|**2024-08-21**|**Vision HgNN: An Electron-Micrograph is Worth Hypergraph of Hypernodes**|Sakhinana Sagar Srinivas et.al.|[2408.11351v1](http://arxiv.org/abs/2408.11351v1)|null|
|**2024-08-21**|**Clinical Context-aware Radiology Report Generation from Medical Images using Transformers**|Sonit Singh et.al.|[2408.11344v1](http://arxiv.org/abs/2408.11344v1)|null|
|**2024-08-21**|**Automatic Dataset Construction (ADC): Sample Collection, Data Curation, and Beyond**|Minghao Liu et.al.|[2408.11338v1](http://arxiv.org/abs/2408.11338v1)|null|
|**2024-08-21**|**BURExtract-Llama: An LLM for Clinical Concept Extraction in Breast Ultrasound Reports**|Yuxuan Chen et.al.|[2408.11334v1](http://arxiv.org/abs/2408.11334v1)|null|
|**2024-08-21**|**Design Principle Transfer in Neural Architecture Search via Large Language Models**|Xun Zhou et.al.|[2408.11330v1](http://arxiv.org/abs/2408.11330v1)|null|
|**2024-08-21**|**Plug, Play, and Fuse: Zero-Shot Joint Decoding via Word-Level Re-ranking Across Diverse Vocabularies**|Sai Koneru et.al.|[2408.11327v1](http://arxiv.org/abs/2408.11327v1)|null|
|**2024-08-21**|**Automating Thought of Search: A Journey Towards Soundness and Completeness**|Daniel Cao et.al.|[2408.11326v1](http://arxiv.org/abs/2408.11326v1)|null|
|**2024-08-21**|**Towards Evaluating Large Language Models on Sarcasm Understanding**|Yazhou Zhang et.al.|[2408.11319v1](http://arxiv.org/abs/2408.11319v1)|null|
|**2024-08-21**|**Probabilistic Medical Predictions of Large Language Models**|Bowen Gu et.al.|[2408.11316v1](http://arxiv.org/abs/2408.11316v1)|null|
|**2024-08-21**|**Unlocking Adversarial Suffix Optimization Without Affirmative Phrases: Efficient Black-box Jailbreaking via LLM as Optimizer**|Weipeng Jiang et.al.|[2408.11313v1](http://arxiv.org/abs/2408.11313v1)|[link](https://github.com/lenijwp/eclipse)|
|**2024-08-21**|**Swarm Intelligence in Geo-Localization: A Multi-Agent Large Vision-Language Model Collaborative Framework**|Xiao Han et.al.|[2408.11312v1](http://arxiv.org/abs/2408.11312v1)|null|
|**2024-08-21**|**EEG-Defender: Defending against Jailbreak through Early Exit Generation of Large Language Models**|Chongwen Zhao et.al.|[2408.11308v1](http://arxiv.org/abs/2408.11308v1)|null|
|**2024-08-21**|**KAN4TSF: Are KAN and KAN-based models Effective for Time Series Forecasting?**|Xiao Han et.al.|[2408.11306v1](http://arxiv.org/abs/2408.11306v1)|[link](https://github.com/2448845600/kan4tsf)|
|**2024-08-21**|**UniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation**|Xiangyu Zhao et.al.|[2408.11305v1](http://arxiv.org/abs/2408.11305v1)|[link](https://github.com/xiangyu-mm/unifashion)|
|**2024-08-21**|**Offline Policy Learning via Skill-step Abstraction for Long-horizon Goal-Conditioned Tasks**|Donghoon Kim et.al.|[2408.11300v1](http://arxiv.org/abs/2408.11300v1)|null|
|**2024-08-21**|**RePair: Automated Program Repair with Process-based Feedback**|Yuze Zhao et.al.|[2408.11296v1](http://arxiv.org/abs/2408.11296v1)|[link](https://github.com/tntwow/repair)|
|**2024-08-21**|**RedWhale: An Adapted Korean LLM Through Efficient Continual Pretraining**|Anh-Dung Vo et.al.|[2408.11294v1](http://arxiv.org/abs/2408.11294v1)|null|
|**2024-08-21**|**Applying and Evaluating Large Language Models in Mental Health Care: A Scoping Review of Human-Assessed Generative Tasks**|Yining Hua et.al.|[2408.11288v1](http://arxiv.org/abs/2408.11288v1)|null|
|**2024-08-21**|**Inference Plans for Hybrid Particle Filtering**|Ellie Y. Cheng et.al.|[2408.11283v1](http://arxiv.org/abs/2408.11283v1)|null|
|**2024-08-21**|**BearLLM: A Prior Knowledge-Enhanced Bearing Health Management Framework with Unified Vibration Signal Representation**|Haotian Peng et.al.|[2408.11281v1](http://arxiv.org/abs/2408.11281v1)|[link](https://github.com/hatton613/bearllm)|
|**2024-08-21**|**Towards Analyzing and Mitigating Sycophancy in Large Vision-Language Models**|Yunpu Zhao et.al.|[2408.11261v1](http://arxiv.org/abs/2408.11261v1)|null|
|**2024-08-21**|**Improving Speech Recognition Error Prediction for Modern and Off-the-shelf Speech Recognizers**|Prashant Serai et.al.|[2408.11258v1](http://arxiv.org/abs/2408.11258v1)|null|
|**2024-08-21**|**Automatic Image Annotation (AIA) of AlmondNet-20 Method for Almond Detection by Improved CNN-based Model**|Mohsen Asghari Ilani et.al.|[2408.11253v1](http://arxiv.org/abs/2408.11253v1)|null|
|**2024-08-21**|**Counterfactuals As a Means for Evaluating Faithfulness of Attribution Methods in Autoregressive Language Models**|Sepehr Kamahi et.al.|[2408.11252v1](http://arxiv.org/abs/2408.11252v1)|null|
|**2024-08-20**|**The Dilemma of Uncertainty Estimation for General Purpose AI in the EU AI Act**|Matias Valdenegro-Toro et.al.|[2408.11249v1](http://arxiv.org/abs/2408.11249v1)|null|
|**2024-08-20**|**Unboxing Occupational Bias: Grounded Debiasing LLMs with U.S. Labor Data**|Atmika Gorti et.al.|[2408.11247v1](http://arxiv.org/abs/2408.11247v1)|null|
|**2024-08-20**|**Do Neural Scaling Laws Exist on Graph Self-Supervised Learning?**|Qian Ma et.al.|[2408.11243v1](http://arxiv.org/abs/2408.11243v1)|[link](https://github.com/graphsslscaling/graphsslscaling)|
|**2024-08-20**|**A Little Confidence Goes a Long Way**|John Scoville et.al.|[2408.11239v1](http://arxiv.org/abs/2408.11239v1)|null|
|**2024-08-20**|**Out-of-Distribution Detection with Attention Head Masking for Multimodal Document Classification**|Christos Constantinou et.al.|[2408.11237v1](http://arxiv.org/abs/2408.11237v1)|null|
|**2024-08-20**|**Unified Deep Learning Model for Global Prediction of Aboveground Biomass, Canopy Height and Cover from High-Resolution, Multi-Sensor Satellite Imagery**|Manuel Weber et.al.|[2408.11234v1](http://arxiv.org/abs/2408.11234v1)|null|
|**2024-08-20**|**OCTCube: A 3D foundation model for optical coherence tomography that improves cross-dataset, cross-disease, cross-device and cross-modality analysis**|Zixuan Liu et.al.|[2408.11227v1](http://arxiv.org/abs/2408.11227v1)|null|

#### Abstracts
##### **Efficient Exploration and Discriminative World Model Learning with an Object-Centric Abstraction**
2408.11816v1 by Anthony GX-Chen, Kenneth Marino, Rob Fergus

In the face of difficult exploration problems in reinforcement learning, we
study whether giving an agent an object-centric mapping (describing a set of
items and their attributes) allow for more efficient learning. We found this
problem is best solved hierarchically by modelling items at a higher level of
state abstraction to pixels, and attribute change at a higher level of temporal
abstraction to primitive actions. This abstraction simplifies the transition
dynamic by making specific future states easier to predict. We make use of this
to propose a fully model-based algorithm that learns a discriminative world
model, plans to explore efficiently with only a count-based intrinsic reward,
and can subsequently plan to reach any discovered (abstract) states.
  We demonstrate the model's ability to (i) efficiently solve single tasks,
(ii) transfer zero-shot and few-shot across item types and environments, and
(iii) plan across long horizons. Across a suite of 2D crafting and MiniHack
environments, we empirically show our model significantly out-performs
state-of-the-art low-level methods (without abstraction), as well as performant
model-free and model-based methods using the same abstraction. Finally, we show
how to reinforce learn low level object-perturbing policies, as well as
supervise learn the object mapping itself.

摘要：在强化学习中面对困难的探索问题时，我们研究给予代理一个以对象为中心的映射（描述一组项目及其属性）是否允许更有效率的学习。我们发现，此问题最适合通过在更高层次的状态抽象中将项目建模为像素，并将属性更改建模为原始动作的更高层次的时间抽象，从而分层解决。这种抽象通过使特定的未来状态更容易预测来简化转换动态。我们利用这一点提出了一个基于模型的算法，该算法学习判别性世界模型，计划仅使用基于计数的内在奖励有效地进行探索，并随后计划达到任何发现的（抽象）状态。我们展示了该模型的能力，包括：(i) 有效地解决单一任务，(ii) 在项目类型和环境中转移零次和少次，以及 (iii) 在较长的范围内进行计划。在 2D 制作和 MiniHack 环境套件中，我们通过实证表明，我们的模型明显优于最先进的低级方法（没有抽象），以及使用相同抽象的高性能无模型和基于模型的方法。最后，我们展示了如何强化学习低级对象扰动策略，以及监督学习对象映射本身。

##### **Great Memory, Shallow Reasoning: Limits of $k$NN-LMs**
2408.11815v1 by Shangyi Geng, Wenting Zhao, Alexander M Rush

$K$-nearest neighbor language models ($k$NN-LMs), which integrate retrieval
with next-word prediction, have demonstrated strong performance in language
modeling as well as downstream NLP benchmarks. These results have led
researchers to argue that models trained on poor quality or outdated data could
perform well by employing a $k$NN extension that has access to a higher-quality
datastore. In this work, we ask whether this improved ability to recall
information really translates into downstream abilities. We extensively
evaluate $k$NN-LMs on a diverse set of tasks, ranging from sentiment
classification and commonsense reasoning to multi-hop reasoning. Results show
that $k$NN-LMs excel at memory-intensive tasks, where utilizing the patterns in
the input is sufficient for determining the output, but struggle with reasoning
tasks that require integrating multiple pieces of information to derive new
knowledge. We further demonstrate through oracle experiments and qualitative
analysis that even with perfect retrieval, $k$NN-LMs still fail to determine
the correct answers, placing an upper bound on their reasoning performance.
Code and datastores are released at https://github.com/GSYfate/knnlm-limits/.

摘要：$K$-近邻语言模型 ($k$NN-LMs) 将检索与下一个词预测整合在一起，在语言建模以及下游 NLP 基准测试中表现出了强大的性能。这些结果促使研究人员争论说，通过使用可以访问更高质量数据存储的 $k$NN 扩展，在低质量或过时数据上训练的模型可以表现良好。在这项工作中，我们询问这种改进的信息召回能力是否真的转化为下游能力。我们在各种任务上广泛评估了 $k$NN-LMs，从情感分类和常识推理到多跳推理。结果表明，$k$NN-LMs 在内存密集型任务中表现出色，其中利用输入中的模式足以确定输出，但在推理任务中遇到了困难，这些任务需要整合多条信息来推导出新知识。我们通过神谕实验和定性分析进一步证明，即使在完美的检索下，$k$NN-LMs 仍然无法确定正确的答案，从而为其推理性能设定了上限。代码和数据存储已在 https://github.com/GSYfate/knnlm-limits/ 发布。

##### **Approaching Deep Learning through the Spectral Dynamics of Weights**
2408.11804v1 by David Yunis, Kumar Kshitij Patel, Samuel Wheeler, Pedro Savarese, Gal Vardi, Karen Livescu, Michael Maire, Matthew R. Walter

We propose an empirical approach centered on the spectral dynamics of weights
-- the behavior of singular values and vectors during optimization -- to unify
and clarify several phenomena in deep learning. We identify a consistent bias
in optimization across various experiments, from small-scale ``grokking'' to
large-scale tasks like image classification with ConvNets, image generation
with UNets, speech recognition with LSTMs, and language modeling with
Transformers. We also demonstrate that weight decay enhances this bias beyond
its role as a norm regularizer, even in practical systems. Moreover, we show
that these spectral dynamics distinguish memorizing networks from generalizing
ones, offering a novel perspective on this longstanding conundrum.
Additionally, we leverage spectral dynamics to explore the emergence of
well-performing sparse subnetworks (lottery tickets) and the structure of the
loss surface through linear mode connectivity. Our findings suggest that
spectral dynamics provide a coherent framework to better understand the
behavior of neural networks across diverse settings.

摘要：我們提出一個專注於權重光譜動態的經驗方法，包括最佳化過程中奇異值和向量的行為，以統一和釐清深度學習中的幾個現象。我們在各種實驗中發現最佳化的持續偏差，從小規模的「理解」到使用 ConvNet 的大規模影像分類任務、使用 UNet 的影像產生、使用 LSTM 的語音辨識，以及使用 Transformer 的語言模型。我們也示範權重衰減會強化這種偏差，超越其作為範例正則化的角色，即使在實際的系統中也是如此。此外，我們顯示這些光譜動態將記憶網路與概括網路區分開來，提供了一個關於這個長期難題的新觀點。此外，我們利用光譜動態來探索效能良好的稀疏子網路（樂透券）的出現，以及透過線性模式連通性了解損失曲面的結構。我們的發現表明，光譜動態提供了一個連貫的架構，以便在不同的設定中更好地理解神經網路的行為。

##### **PermitQA: A Benchmark for Retrieval Augmented Generation in Wind Siting and Permitting domain**
2408.11800v1 by Rounak Meyur, Hung Phan, Sridevi Wagle, Jan Strube, Mahantesh Halappanavar, Sameera Horawalavithana, Anurag Acharya, Sai Munikoti

In the rapidly evolving landscape of Natural Language Processing (NLP) and
text generation, the emergence of Retrieval Augmented Generation (RAG) presents
a promising avenue for improving the quality and reliability of generated text
by leveraging information retrieved from user specified database. Benchmarking
is essential to evaluate and compare the performance of the different RAG
configurations in terms of retriever and generator, providing insights into
their effectiveness, scalability, and suitability for the specific domain and
applications. In this paper, we present a comprehensive framework to generate a
domain relevant RAG benchmark. Our framework is based on automatic
question-answer generation with Human (domain experts)-AI Large Language Model
(LLM) teaming. As a case study, we demonstrate the framework by introducing
PermitQA, a first-of-its-kind benchmark on the wind siting and permitting
domain which comprises of multiple scientific documents/reports related to
environmental impact of wind energy projects. Our framework systematically
evaluates RAG performance using diverse metrics and multiple question types
with varying complexity level. We also demonstrate the performance of different
models on our benchmark.

摘要：在自然語言處理 (NLP) 和文本生成快速演進的領域中，檢索增強生成 (RAG) 的出現提供了一個有前景的方法，透過利用從使用者指定的資料庫中檢索的資訊來提升生成文字的品質和可靠性。基準測試對於評估和比較不同 RAG 組態在檢索器和生成器方面的效能至關重要，提供對其在特定領域和應用中的有效性、可擴充性和適用性的見解。在本文中，我們提出一個全面的架構來產生與領域相關的 RAG 基準測試。我們的架構基於自動問答生成，由人類 (領域專家) 和大型語言模型 (LLM) 團隊合作。作為一個案例研究，我們透過介紹 PermitQA 來展示這個架構，PermitQA 是第一個針對風場選址和許可領域的基準測試，其中包含多份與風能專案環境影響相關的科學文件/報告。我們的架構使用不同的指標和多種類型的問題，並具有不同的複雜程度，系統性地評估 RAG 效能。我們還在我們的基準測試中展示了不同模型的效能。

##### **Practical token pruning for foundation models in few-shot conversational virtual assistant systems**
2408.11799v1 by Haode Qi, Cheng Qian, Jian Ni, Pratyush Singh, Reza Fazeli, Gengyu Wang, Zhongzheng Shu, Eric Wayne, Juergen Bross

In an enterprise Virtual Assistant (VA) system, intent classification is the
crucial component that determines how a user input is handled based on what the
user wants. The VA system is expected to be a cost-efficient SaaS service with
low training and inference time while achieving high accuracy even with a small
number of training samples. We pretrain a transformer-based sentence embedding
model with a contrastive learning objective and leverage the embedding of the
model as features when training intent classification models. Our approach
achieves the state-of-the-art results for few-shot scenarios and performs
better than other commercial solutions on popular intent classification
benchmarks. However, generating features via a transformer-based model
increases the inference time, especially for longer user inputs, due to the
quadratic runtime of the transformer's attention mechanism. On top of model
distillation, we introduce a practical multi-task adaptation approach that
configures dynamic token pruning without the need for task-specific training
for intent classification. We demonstrate that this approach improves the
inference speed of popular sentence transformer models without affecting model
performance.

摘要：在企業虛擬助理 (VA) 系統中，意圖分類是基於使用者想要什麼來決定如何處理使用者輸入的關鍵組成部分。VA 系統預計將成為具有低訓練和推理時間的高成本效益 SaaS 服務，即使訓練樣本數量很少也能達到高準確度。我們使用對比學習目標預訓練基於轉換器的句子嵌入模型，並在訓練意圖分類模型時利用模型的嵌入作為特徵。我們的做法達到了少量場景的最新結果，並且在流行的意圖分類基準上優於其他商業解決方案。然而，通過基於轉換器的模型生成特徵會增加推理時間，特別是對於較長的使用者輸入，這是由於轉換器注意力機制的二次執行時間。在模型蒸餾之上，我們引入了一種實用的多任務適應方法，該方法配置動態令牌修剪，而無需針對意圖分類進行特定任務的訓練。我們證明這種方法提高了流行句子轉換器模型的推理速度，而不會影響模型效能。

##### **LLM Pruning and Distillation in Practice: The Minitron Approach**
2408.11796v1 by Sharath Turuvekere Sreenivas, Saurav Muralidharan, Raviraj Joshi, Marcin Chochowski, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro, Jan Kautz, Pavlo Molchanov

We present a comprehensive report on compressing the Llama 3.1 8B and Mistral
NeMo 12B models to 4B and 8B parameters, respectively, using pruning and
distillation. We explore two distinct pruning strategies: (1) depth pruning and
(2) joint hidden/attention/MLP (width) pruning, and evaluate the results on
common benchmarks from the LM Evaluation Harness. The models are then aligned
with NeMo Aligner and tested in instruct-tuned versions. This approach produces
a compelling 4B model from Llama 3.1 8B and a state-of-the-art
Mistral-NeMo-Minitron-8B (MN-Minitron-8B for brevity) model from Mistral NeMo
12B. We found that with no access to the original data, it is beneficial to
slightly fine-tune teacher models on the distillation dataset. We open-source
our base model weights on Hugging Face with a permissive license.

摘要：我們提出了一份關於使用剪枝和知識蒸餾將 Llama 3.1 8B 和 Mistral NeMo 12B 模型分別壓縮到 4B 和 8B 參數的綜合報告。我們探討了兩種不同的剪枝策略：(1) 深度剪枝和 (2) 聯合隱藏/注意力/MLP (寬度) 剪枝，並在 LM 評估工具包的常見基準上評估結果。然後使用 NeMo Aligner 對齊模型，並在經過微調的版本中進行測試。這種方法從 Llama 3.1 8B 產生了一個引人注目的 4B 模型，並從 Mistral NeMo 12B 產生了一個最先進的 Mistral-NeMo-Minitron-8B (簡稱 MN-Minitron-8B) 模型。我們發現，在無法訪問原始數據的情況下，微調知識蒸餾資料集上的教師模型是有益的。我們在 Hugging Face 上開源了我們的基礎模型權重，並附有寬鬆的許可證。

##### **Leveraging Chemistry Foundation Models to Facilitate Structure Focused Retrieval Augmented Generation in Multi-Agent Workflows for Catalyst and Materials Design**
2408.11793v1 by Nathaniel H. Park, Tiffany J. Callahan, James L. Hedrick, Tim Erdmann, Sara Capponi

Molecular property prediction and generative design via deep learning models
has been the subject of intense research given its potential to accelerate
development of new, high-performance materials. More recently, these workflows
have been significantly augmented with the advent of large language models
(LLMs) and systems of LLM-driven agents capable of utilizing pre-trained models
to make predictions in the context of more complex research tasks. While
effective, there is still room for substantial improvement within the agentic
systems on the retrieval of salient information for material design tasks.
Moreover, alternative uses of predictive deep learning models, such as
leveraging their latent representations to facilitate cross-modal retrieval
augmented generation within agentic systems to enable task-specific materials
design, has remained unexplored. Herein, we demonstrate that large, pre-trained
chemistry foundation models can serve as a basis for enabling semantic
chemistry information retrieval for both small-molecules, complex polymeric
materials, and reactions. Additionally, we show the use of chemistry foundation
models in conjunction with image models such as OpenCLIP facilitate
unprecedented queries and information retrieval across multiple
characterization data domains. Finally, we demonstrate the integration of these
systems within multi-agent systems to facilitate structure and
topological-based natural language queries and information retrieval for
complex research tasks.

摘要：分子特性預測和生成設計透過深度學習模型
一直是密集研究的主題，因為它有潛力加速
開發新的高性能材料。最近，這些工作流程
已透過大型語言模型 (LLM) 和 LLM 驅動代理系統的出現而顯著擴增，這些系統能夠利用預先訓練的模型
在更複雜的研究任務的背景下進行預測。雖然
有效，但代理系統在檢索材料設計任務的顯著資訊方面仍有大幅改善的空間。
此外，預測性深度學習模型的替代用途，例如
利用其潛在表示來促進跨模式檢索
增強代理系統中的生成以實現特定任務的材料
設計，仍然未被探索。在此，我們證明大型預訓練
化學基礎模型可以作為啟用語義
化學資訊檢索的基礎，適用於小分子、複雜聚合物
材料和反應。此外，我們展示了化學基礎
模型與圖像模型（例如 OpenCLIP）結合使用，促進
跨多個
表徵資料網域的空前查詢和資訊檢索。最後，我們展示了這些
系統在多代理系統中的整合，以促進結構和
基於拓撲的自然語言查詢和資訊檢索，用於
複雜的研究任務。

##### **DreamFactory: Pioneering Multi-Scene Long Video Generation with a Multi-Agent Framework**
2408.11788v1 by Zhifei Xie, Daniel Tang, Dingwei Tan, Jacques Klein, Tegawend F. Bissyand, Saad Ezzini

Current video generation models excel at creating short, realistic clips, but
struggle with longer, multi-scene videos. We introduce \texttt{DreamFactory},
an LLM-based framework that tackles this challenge. \texttt{DreamFactory}
leverages multi-agent collaboration principles and a Key Frames Iteration
Design Method to ensure consistency and style across long videos. It utilizes
Chain of Thought (COT) to address uncertainties inherent in large language
models. \texttt{DreamFactory} generates long, stylistically coherent, and
complex videos. Evaluating these long-form videos presents a challenge. We
propose novel metrics such as Cross-Scene Face Distance Score and Cross-Scene
Style Consistency Score. To further research in this area, we contribute the
Multi-Scene Videos Dataset containing over 150 human-rated videos.

摘要：當前的影片生成模型擅長於製作短而逼真的片段，但對於較長的多場景影片則有困難。我們介紹了 \texttt{DreamFactory}，一個基於 LLM 的架構，用於應對此挑戰。\texttt{DreamFactory} 利用多重代理協作原則和關鍵影格迭代設計方法，以確保長影片中的一致性和風格。它利用思考鏈 (COT) 來解決大型語言模型中固有的不確定性。\texttt{DreamFactory} 會產生長、風格一致且複雜的影片。評估這些長篇影片是一個挑戰。我們提出了新的指標，例如跨場景人臉距離分數和跨場景風格一致性分數。為了進一步研究這個領域，我們提供了包含超過 150 個由人類評分的影片的多場景影片資料集。

##### **Timeline and Boundary Guided Diffusion Network for Video Shadow Detection**
2408.11785v1 by Haipeng Zhou, Honqiu Wang, Tian Ye, Zhaohu Xing, Jun Ma, Ping Li, Qiong Wang, Lei Zhu

Video Shadow Detection (VSD) aims to detect the shadow masks with frame
sequence. Existing works suffer from inefficient temporal learning. Moreover,
few works address the VSD problem by considering the characteristic (i.e.,
boundary) of shadow. Motivated by this, we propose a Timeline and Boundary
Guided Diffusion (TBGDiff) network for VSD where we take account of the
past-future temporal guidance and boundary information jointly. In detail, we
design a Dual Scale Aggregation (DSA) module for better temporal understanding
by rethinking the affinity of the long-term and short-term frames for the
clipped video. Next, we introduce Shadow Boundary Aware Attention (SBAA) to
utilize the edge contexts for capturing the characteristics of shadows.
Moreover, we are the first to introduce the Diffusion model for VSD in which we
explore a Space-Time Encoded Embedding (STEE) to inject the temporal guidance
for Diffusion to conduct shadow detection. Benefiting from these designs, our
model can not only capture the temporal information but also the shadow
property. Extensive experiments show that the performance of our approach
overtakes the state-of-the-art methods, verifying the effectiveness of our
components. We release the codes, weights, and results at
\url{https://github.com/haipengzhou856/TBGDiff}.

摘要：影片陰影偵測（VSD）旨在偵測具有序列畫格的陰影遮罩。現有的作品在時間學習方面效率不彰。此外，很少有作品透過考量陰影的特徵（例如邊界）來解決 VSD 問題。有鑑於此，我們提出一個時間軸和邊界引導擴散（TBGDiff）網路用於 VSD，其中我們同時考量過去和未來的時間指引和邊界資訊。詳細來說，我們設計了一個雙重尺度聚合（DSA）模組，透過重新思考長期和短期畫格對剪輯影片的關聯性，以獲得更好的時間理解。接下來，我們引入陰影邊界感知注意力（SBAA）來利用邊緣脈絡以擷取陰影的特徵。此外，我們是第一個在 VSD 中引入擴散模型的人，其中我們探討使用時空編碼嵌入（STEE）來注入時間指引，以讓擴散執行陰影偵測。受益於這些設計，我們的模型不僅能擷取時間資訊，還能擷取陰影屬性。廣泛的實驗顯示，我們方法的效能超越了最先進的方法，驗證了我們元件的有效性。我們在 \url{https://github.com/haipengzhou856/TBGDiff} 釋出程式碼、權重和結果。

##### **Personality Alignment of Large Language Models**
2408.11779v1 by Minjun Zhu, Linyi Yang, Yue Zhang

Current methods for aligning large language models (LLMs) typically aim to
reflect general human values and behaviors, but they often fail to capture the
unique characteristics and preferences of individual users. To address this
gap, we introduce the concept of Personality Alignment. This approach tailors
LLMs' responses and decisions to match the specific preferences of individual
users or closely related groups. Inspired by psychometrics, we created the
Personality Alignment with Personality Inventories (PAPI) dataset, which
includes data from 300,000 real subjects, each providing behavioral preferences
based on the Big Five Personality Factors. This dataset allows us to
quantitatively evaluate the extent to which LLMs can align with each subject's
behavioral patterns. Recognizing the challenges of personality alignments: such
as limited personal data, diverse preferences, and scalability requirements: we
developed an activation intervention optimization method. This method enhances
LLMs' ability to efficiently align with individual behavioral preferences using
minimal data and computational resources. Remarkably, our method, PAS, achieves
superior performance while requiring only 1/5 of the optimization time compared
to DPO, offering practical value for personality alignment. Our work paves the
way for future AI systems to make decisions and reason in truly personality
ways, enhancing the relevance and meaning of AI interactions for each user and
advancing human-centered artificial intelligence.The code has released in
\url{https://github.com/zhu-minjun/PAlign}.

摘要：目前用於校準大型語言模型 (LLM) 的方法通常旨在反映一般人類價值觀和行為，但它們常常無法捕捉個別使用者的獨特特徵和偏好。為了解決這個差距，我們引入了個性校準的概念。此方法根據個別使用者或密切相關群組的特定偏好來調整 LLM 的回應和決策。受到心理測量學的啟發，我們建立了個性校準與個性清單 (PAPI) 資料集，其中包含來自 30 萬名真實受試者的資料，每個人都根據五大個性特質提供行為偏好。這個資料集讓我們能夠定量評估 LLM 與每個受試者行為模式的一致程度。認識到個性校準的挑戰：例如個人資料有限、偏好多元和可擴充性要求：我們開發了一種啟用介入最佳化方法。此方法使用最少的資料和運算資源，增強了 LLM 有效地與個別行為偏好校準的能力。值得注意的是，我們的 PAS 方法表現優異，同時僅需要 DPO 1/5 的最佳化時間，為個性校準提供了實用的價值。我們的研究為未來的 AI 系統鋪路，讓它們能夠以真正個性化的方式做出決策和推理，提升 AI 互動對每個使用者的關聯性和意義，並促進以人為中心的 AI。程式碼已發布在 \url{https://github.com/zhu-minjun/PAlign}。

##### **Sum of Squares Circuits**
2408.11778v1 by Lorenzo Loconte, Stefan Mengel, Antonio Vergari

Designing expressive generative models that support exact and efficient
inference is a core question in probabilistic ML. Probabilistic circuits (PCs)
offer a framework where this tractability-vs-expressiveness trade-off can be
analyzed theoretically. Recently, squared PCs encoding subtractive mixtures via
negative parameters have emerged as tractable models that can be exponentially
more expressive than monotonic PCs, i.e., PCs with positive parameters only. In
this paper, we provide a more precise theoretical characterization of the
expressiveness relationships among these models. First, we prove that squared
PCs can be less expressive than monotonic ones. Second, we formalize a novel
class of PCs -- sum of squares PCs -- that can be exponentially more expressive
than both squared and monotonic PCs. Around sum of squares PCs, we build an
expressiveness hierarchy that allows us to precisely unify and separate
different tractable model classes such as Born Machines and PSD models, and
other recently introduced tractable probabilistic models by using complex
parameters. Finally, we empirically show the effectiveness of sum of squares
circuits in performing distribution estimation.

摘要：<paragraph>設計支援精確且有效率推論的表達式生成模型是機率式 ML 中的核心問題。機率電路 (PC) 提供一個架構，可以在其中從理論上分析這種可追蹤性與表達性之間的取捨。最近，透過負參數編碼減法混合的平方 PC 已成為可追蹤的模型，其表達性可能比單調 PC（即只有正參數的 PC）高出數倍。在本文中，我們提供這些模型之間表達性關係更精確的理論表徵。首先，我們證明平方 PC 的表達性可能低於單調 PC。其次，我們形式化一個新的 PC 類別——平方和 PC——其表達性可能比平方 PC 和單調 PC 都高出數倍。在平方和 PC 的周圍，我們建立一個表達性階層，使我們能夠精確地統一和區分不同的可追蹤模型類別，例如 Born 機器和 PSD 模型，以及其他最近引入的、使用複雜參數的可追蹤機率模型。最後，我們透過實證顯示平方和電路在執行分配估計方面的有效性。</paragraph>

##### **Leveraging Fine-Tuned Retrieval-Augmented Generation with Long-Context Support: For 3GPP Standards**
2408.11775v1 by Omar Erak, Nouf Alabbasi, Omar Alhussein, Ismail Lotfi, Amr Hussein, Sami Muhaidat, Merouane Debbah

Recent studies show that large language models (LLMs) struggle with technical
standards in telecommunications. We propose a fine-tuned retrieval-augmented
generation (RAG) system based on the Phi-2 small language model (SLM) to serve
as an oracle for communication networks. Our developed system leverages
forward-looking semantic chunking to adaptively determine parsing breakpoints
based on embedding similarity, enabling effective processing of diverse
document formats. To handle the challenge of multiple similar contexts in
technical standards, we employ a re-ranking algorithm to prioritize the most
relevant retrieved chunks. Recognizing the limitations of Phi-2's small context
window, we implement a recent technique, namely SelfExtend, to expand the
context window during inference, which not only boosts the performance but also
can accommodate a wider range of user queries and design requirements from
customers to specialized technicians. For fine-tuning, we utilize the low-rank
adaptation (LoRA) technique to enhance computational efficiency during training
and enable effective fine-tuning on small datasets. Our comprehensive
experiments demonstrate substantial improvements over existing
question-answering approaches in the telecom domain, achieving performance that
exceeds larger language models such as GPT-4 (which is about 880 times larger
in size). This work presents a novel approach to leveraging SLMs for
communication networks, offering a balance of efficiency and performance. This
work can serve as a foundation towards agentic language models for networks.

摘要：<paragraph>最近的研究表明，大型語言模型 (LLM) 在電信技術標準方面存在困難。我們提出一個基於 Phi-2 小型語言模型 (SLM) 的微調檢索增強生成 (RAG) 系統，作為通信網路的預言機。我們開發的系統利用前瞻語義切塊，根據嵌入相似性自適應地確定解析斷點，從而有效處理多樣化的文件格式。為了應對技術標準中多個相似語境的挑戰，我們採用重新排序演算法，以優先考慮最相關的檢索區塊。認識到 Phi-2 的小語境視窗的限制，我們實作了一種新的技術，即 SelfExtend，以在推理期間擴展語境視窗，這不僅提升了效能，還能容納更廣泛的使用者查詢和來自客戶到專業技術人員的設計需求。對於微調，我們利用低秩適應 (LoRA) 技術來提升訓練期間的運算效率，並在小型資料集上進行有效的微調。我們全面的實驗證明了電信領域現有問答方法的顯著改進，達到了超越大型語言模型（例如 GPT-4，其大小約為其 880 倍）的效能。這項工作提出了一種利用 SLM 來進行通信網路的新方法，在效率和效能之間取得平衡。這項工作可以作為網路代理語言模型的基礎。</paragraph>

##### **D-RMGPT: Robot-assisted collaborative tasks driven by large multimodal models**
2408.11761v1 by M. Forlini, M. Babcinschi, G. Palmieri, P. Neto

Collaborative robots are increasingly popular for assisting humans at work
and daily tasks. However, designing and setting up interfaces for human-robot
collaboration is challenging, requiring the integration of multiple components,
from perception and robot task control to the hardware itself. Frequently, this
leads to highly customized solutions that rely on large amounts of costly
training data, diverging from the ideal of flexible and general interfaces that
empower robots to perceive and adapt to unstructured environments where they
can naturally collaborate with humans. To overcome these challenges, this paper
presents the Detection-Robot Management GPT (D-RMGPT), a robot-assisted
assembly planner based on Large Multimodal Models (LMM). This system can assist
inexperienced operators in assembly tasks without requiring any markers or
previous training. D-RMGPT is composed of DetGPT-V and R-ManGPT. DetGPT-V,
based on GPT-4V(vision), perceives the surrounding environment through one-shot
analysis of prompted images of the current assembly stage and the list of
components to be assembled. It identifies which components have already been
assembled by analysing their features and assembly requirements. R-ManGPT,
based on GPT-4, plans the next component to be assembled and generates the
robot's discrete actions to deliver it to the human co-worker. Experimental
tests on assembling a toy aircraft demonstrated that D-RMGPT is flexible and
intuitive to use, achieving an assembly success rate of 83% while reducing the
assembly time for inexperienced operators by 33% compared to the manual
process. http://robotics-and-ai.github.io/LMMmodels/

摘要：協作機器人協助人類工作和日常任務的普及率越來越高。然而，設計和設定人機協作介面具有挑戰性，需要整合多種元件，從感知和機器人任務控制到硬體本身。這通常會導致高度客製化的解決方案，仰賴大量昂貴的訓練資料，偏離了靈活且通用的介面理想，而這賦能機器人在可以與人類自然協作的非結構化環境中感知和適應。為了克服這些挑戰，本文介紹了偵測機器人管理 GPT (D-RMGPT)，這是一個基於大型多模態模型 (LMM) 的機器人輔助組裝規劃器。此系統可以協助沒有經驗的操作員進行組裝任務，而無需任何標記或先前的訓練。D-RMGPT 由 DetGPT-V 和 R-ManGPT 組成。DetGPT-V 基於 GPT-4V(視覺)，透過對當前組裝階段提示影像和要組裝的元件清單進行一次性分析，來感知周遭環境。它透過分析元件特徵和組裝需求，來識別哪些元件已經組裝完成。R-ManGPT 基於 GPT-4，規劃要組裝的下一項元件，並產生機器人的離散動作，將其傳遞給人類同事。組裝玩具飛機的實驗測試證明，D-RMGPT 靈活且直觀易用，組裝成功率達到 83%，同時與手動程序相比，可將沒有經驗的操作員的組裝時間縮短 33%。http://robotics-and-ai.github.io/LMMmodels/

##### **SBDet: A Symmetry-Breaking Object Detector via Relaxed Rotation-Equivariance**
2408.11760v1 by Zhiqiang Wu, Yingjie Liu, Hanlin Dong, Xuan Tang, Jian Yang, Bo Jin, Mingsong Chen, Xian Wei

Introducing Group Equivariant Convolution (GConv) empowers models to explore
symmetries hidden in visual data, improving their performance. However, in
real-world scenarios, objects or scenes often exhibit perturbations of a
symmetric system, specifically a deviation from a symmetric architecture, which
can be characterized by a non-trivial action of a symmetry group, known as
Symmetry-Breaking. Traditional GConv methods are limited by the strict
operation rules in the group space, only ensuring features remain strictly
equivariant under limited group transformations, making it difficult to adapt
to Symmetry-Breaking or non-rigid transformations. Motivated by this, we
introduce a novel Relaxed Rotation GConv (R2GConv) with our defined Relaxed
Rotation-Equivariant group $\mathbf{R}_4$. Furthermore, we propose a Relaxed
Rotation-Equivariant Network (R2Net) as the backbone and further develop the
Symmetry-Breaking Object Detector (SBDet) for 2D object detection built upon
it. Experiments demonstrate the effectiveness of our proposed R2GConv in
natural image classification tasks, and SBDet achieves excellent performance in
object detection tasks with improved generalization capabilities and
robustness.

摘要：引入群等變卷積 (GConv) 賦予模型探索隱藏在視覺資料中的對稱性，提升模型效能。然而，在現實世界場景中，物件或場景經常展現對稱系統的擾動，特別是偏離對稱架構，這可以用對稱群的非平凡動作來表徵，稱為對稱性破缺。傳統的 GConv 方法受到群空間中嚴格的運算規則限制，僅確保特徵在有限群變換下保持嚴格等變，這使得難以適應對稱性破缺或非剛性變換。有鑑於此，我們引入了具有我們定義的鬆弛旋轉等變群 $\mathbf{R}_4$ 的新穎鬆弛旋轉 GConv (R2GConv)。此外，我們提出了一個鬆弛旋轉等變網路 (R2Net) 作為主幹，並進一步開發了建立在它上面的 2D 物件偵測對稱性破缺物件偵測器 (SBDet)。實驗證明了我們提出的 R2GConv 在自然影像分類任務中的有效性，而 SBDet 在物件偵測任務中達到了優異的效能，並提升了泛化能力和穩健性。

##### **Against All Odds: Overcoming Typology, Script, and Language Confusion in Multilingual Embedding Inversion Attacks**
2408.11749v1 by Yiyi Chen, Russa Biswas, Heather Lent, Johannes Bjerva

Large Language Models (LLMs) are susceptible to malicious influence by cyber
attackers through intrusions such as adversarial, backdoor, and embedding
inversion attacks. In response, the burgeoning field of LLM Security aims to
study and defend against such threats. Thus far, the majority of works in this
area have focused on monolingual English models, however, emerging research
suggests that multilingual LLMs may be more vulnerable to various attacks than
their monolingual counterparts. While previous work has investigated embedding
inversion over a small subset of European languages, it is challenging to
extrapolate these findings to languages from different linguistic families and
with differing scripts. To this end, we explore the security of multilingual
LLMs in the context of embedding inversion attacks and investigate
cross-lingual and cross-script inversion across 20 languages, spanning over 8
language families and 12 scripts. Our findings indicate that languages written
in Arabic script and Cyrillic script are particularly vulnerable to embedding
inversion, as are languages within the Indo-Aryan language family. We further
observe that inversion models tend to suffer from language confusion, sometimes
greatly reducing the efficacy of an attack. Accordingly, we systematically
explore this bottleneck for inversion models, uncovering predictable patterns
which could be leveraged by attackers. Ultimately, this study aims to further
the field's understanding of the outstanding security vulnerabilities facing
multilingual LLMs and raise awareness for the languages most at risk of
negative impact from these attacks.

摘要：大型語言模型 (LLM) 容易受到網路攻擊者的惡意影響，例如對抗性、後門和嵌入式反轉攻擊等入侵。為了解決這個問題，新興的 LLM 安全領域旨在研究和防禦此類威脅。到目前為止，這個領域的大多數研究都集中在單語的英文模型上，然而，新興的研究表明，多語言 LLM 可能比單語的 LLM 更容易受到各種攻擊。雖然先前的研究已經調查了對少數歐洲語言的嵌入式反轉，但很難將這些發現推廣到來自不同語言家族且具有不同腳本的語言。為此，我們在嵌入式反轉攻擊的背景下探討多語言 LLM 的安全性，並調查跨 20 種語言的跨語言和跨腳本反轉，涵蓋超過 8 個語言家族和 12 種腳本。我們的研究結果表明，使用阿拉伯文字和西里爾文字書寫的語言特別容易受到嵌入式反轉的影響，印歐語系語言也是如此。我們進一步觀察到，反轉模型往往會出現語言混淆，有時會大大降低攻擊的效力。因此，我們系統地探討了反轉模型的這個瓶頸，揭示了攻擊者可以利用的可預測模式。最終，本研究旨在進一步加深該領域對多語言 LLM 面臨的突出安全漏洞的理解，並提高對這些攻擊最容易造成負面影響的語言的認識。

##### **Open-Ended 3D Point Cloud Instance Segmentation**
2408.11747v1 by Phuc D. A. Nguyen, Minh Luu, Anh Tran, Cuong Pham, Khoi Nguyen

Open-Vocab 3D Instance Segmentation methods (OV-3DIS) have recently
demonstrated their ability to generalize to unseen objects. However, these
methods still depend on predefined class names during testing, restricting the
autonomy of agents. To mitigate this constraint, we propose a novel problem
termed Open-Ended 3D Instance Segmentation (OE-3DIS), which eliminates the
necessity for predefined class names during testing. Moreover, we contribute a
comprehensive set of strong baselines, derived from OV-3DIS approaches and
leveraging 2D Multimodal Large Language Models. To assess the performance of
our OE-3DIS system, we introduce a novel Open-Ended score, evaluating both the
semantic and geometric quality of predicted masks and their associated class
names, alongside the standard AP score. Our approach demonstrates significant
performance improvements over the baselines on the ScanNet200 and ScanNet++
datasets. Remarkably, our method surpasses the performance of Open3DIS, the
current state-of-the-art method in OV-3DIS, even in the absence of ground-truth
object class names.

摘要：開放詞彙 3D 實例分割方法 (OV-3DIS) 最近展示了它們概括到未見物件的能力。然而，這些方法在測試期間仍依賴於預定義的類別名稱，限制了代理的自主性。為了減輕這個限制，我們提出了一個新問題，稱為開放式 3D 實例分割 (OE-3DIS)，它消除了測試期間預定義類別名稱的必要性。此外，我們貢獻了一組從 OV-3DIS 方法中衍生並利用 2D 多模態大型語言模型的強大基線。為了評估我們的 OE-3DIS 系統的效能，我們引入了新的開放式評分，除了標準 AP 評分外，還評估了預測遮罩及其相關類別名稱的語義和幾何品質。我們的做法在 ScanNet200 和 ScanNet++ 資料集上展示了比基線顯著的效能提升。值得注意的是，我們的模型超越了 Open3DIS 的效能，Open3DIS 是 OV-3DIS 中目前最先進的方法，即使在沒有 ground-truth 物件類別名稱的情況下也是如此。

##### **FocusLLM: Scaling LLM's Context by Parallel Decoding**
2408.11745v1 by Zhenyu Li, Yike Zhang, Tengyu Pan, Yutao Sun, Zhichao Duan, Junjie Fang, Rong Han, Zixuan Wang, Jianyong Wang

Empowering LLMs with the ability to utilize useful information from a long
context is crucial for many downstream applications. However, achieving long
context lengths with the conventional transformer architecture requires
substantial training and inference resources. In this paper, we present
FocusLLM, a framework designed to extend the context length of any decoder-only
LLM, enabling the model to focus on relevant information from very long
sequences. FocusLLM processes long text inputs by dividing them into chunks
based on the model's original context length to alleviate the issue of
attention distraction. Then, it appends the local context to each chunk as a
prompt to extract essential information from each chunk based on a novel
parallel decoding mechanism, and ultimately integrates the extracted
information into the local context. FocusLLM stands out for great training
efficiency and versatility: trained with an 8K input length with much less
training cost than previous methods, FocusLLM exhibits superior performance
across downstream long-context tasks and maintains strong language modeling
ability when handling extensive long texts, even up to 400K tokens. Our code is
available at https://github.com/leezythu/FocusLLM.

摘要：賦予 LLM 利用長語境中有用資訊的能力對於許多下游應用程式至關重要。然而，使用傳統的 Transformer 架構來實現長語境長度需要大量的訓練和推論資源。在本文中，我們提出 FocusLLM，一個旨在擴展任何僅解碼器 LLM 的語境長度的框架，使模型能夠專注於非常長的序列中的相關資訊。FocusLLM 透過將長文本輸入分割成塊（基於模型的原始語境長度）來處理，以減輕注意力分散的問題。然後，它將局部語境附加到每個塊作為提示，以基於新穎的並行解碼機制從每個塊中提取必要資訊，並最終將提取的資訊整合到局部語境中。FocusLLM 以其出色的訓練效率和多功能性而著稱：使用 8K 輸入長度進行訓練，訓練成本遠低於以前的方法，FocusLLM 在下游長語境任務中表現出優異的效能，並在處理廣泛的長文本（甚至長達 400K 個符號）時保持強大的語言建模能力。我們的程式碼可以在 https://github.com/leezythu/FocusLLM 取得。

##### **JieHua Paintings Style Feature Extracting Model using Stable Diffusion with ControlNet**
2408.11744v1 by Yujia Gu, Haofeng Li, Xinyu Fang, Zihan Peng, Yinan Peng

This study proposes a novel approach to extract stylistic features of Jiehua:
the utilization of the Fine-tuned Stable Diffusion Model with ControlNet
(FSDMC) to refine depiction techniques from artists' Jiehua. The training data
for FSDMC is based on the opensource Jiehua artist's work collected from the
Internet, which were subsequently manually constructed in the format of
(Original Image, Canny Edge Features, Text Prompt). By employing the optimal
hyperparameters identified in this paper, it was observed FSDMC outperforms
CycleGAN, another mainstream style transfer model. FSDMC achieves FID of 3.27
on the dataset and also surpasses CycleGAN in terms of expert evaluation. This
not only demonstrates the model's high effectiveness in extracting Jiehua's
style features, but also preserves the original pre-trained semantic
information. The findings of this study suggest that the application of FSDMC
with appropriate hyperparameters can enhance the efficacy of the Stable
Diffusion Model in the field of traditional art style migration tasks,
particularly within the context of Jiehua.

摘要：本研究提出了一個新穎的方法來提取界畫的風格特徵：
利用經過微調的 Stable Diffusion 模型與 ControlNet（FSDMC）來優化藝術家界畫的描繪技巧。FSDMC 的訓練資料是從網路上收集的開源界畫藝術家的作品，隨後手動建構為（原始影像、Canny 邊緣特徵、文字提示）的格式。透過採用本文中確定的最佳超參數，觀察到 FSDMC 的表現優於另一種主流風格轉移模型 CycleGAN。FSDMC 在資料集上達到了 3.27 的 FID，並且在專家評估方面也超越了 CycleGAN。這不僅證明了該模型在提取界畫風格特徵方面的效能很高，而且還保留了原始預訓練的語義資訊。本研究的發現表明，在傳統藝術風格遷移任務中，使用具有適當超參數的 FSDMC 可以提高 Stable Diffusion 模型的效能，特別是在界畫的背景下。

##### **CluMo: Cluster-based Modality Fusion Prompt for Continual Learning in Visual Question Answering**
2408.11742v1 by Yuliang Cai, Mohammad Rostami

Large vision-language models (VLMs) have shown significant performance boost
in various application domains. However, adopting them to deal with several
sequentially encountered tasks has been challenging because finetuning a VLM on
a task normally leads to reducing its generalization power and the capacity of
learning new tasks as well as causing catastrophic forgetting on previously
learned tasks. Enabling using VLMs in multimodal continual learning (CL)
settings can help to address such scenarios. To improve generalization capacity
and prevent catastrophic forgetting, we propose a novel prompt-based CL method
for VLMs, namely $\textbf{Clu}$ster-based $\textbf{Mo}$dality Fusion Prompt
(\textbf{CluMo}). We design a novel \textbf{Key-Key-Prompt} pair, where each
prompt is associated with a visual prompt key and a textual prompt key. We
adopt a two-stage training strategy. During the first stage, the single-modal
keys are trained via $K$-means clustering algorithm to help select the best
semantically matched prompt. During the second stage, the prompt keys are
frozen, the selected prompt is attached to the input for training the VLM in
the CL scenario. Experiments on two benchmarks demonstrate that our method
achieves SOTA performance.

摘要：大型視覺語言模型 (VLM) 在各種應用領域中展現出顯著的效能提升。然而，將其用於處理多個依序遇到的任務一直具有挑戰性，因為對 VLM 進行微調通常會導致其泛化能力降低，以及學習新任務的能力，並導致先前學習任務的災難性遺忘。在多模態持續學習 (CL) 設定中啟用 VLM，有助於解決此類場景。為了改善泛化能力並防止災難性遺忘，我們針對 VLM 提出了一種新穎的基於提示的 CL 方法，即基於群集的模態融合提示 (CluMo)。我們設計了一對新穎的關鍵關鍵提示，其中每個提示都與視覺提示關鍵和文本提示關鍵相關聯。我們採用兩階段訓練策略。在第一階段中，單模態關鍵是透過 K 平均群集演算法進行訓練，以幫助選擇最佳語義匹配提示。在第二階段中，提示關鍵會被凍結，所選提示會附加到輸入，以訓練 CL 場景中的 VLM。在兩個基準上的實驗證明，我們的模型達到了 SOTA 效能。

##### **Clinical Insights: A Comprehensive Review of Language Models in Medicine**
2408.11735v1 by Nikita Neveditsin, Pawan Lingras, Vijay Mago

This paper provides a detailed examination of the advancements and
applications of large language models in the healthcare sector, with a
particular emphasis on clinical applications. The study traces the evolution of
LLMs from their foundational technologies to the latest developments in
domain-specific models and multimodal integration. It explores the technical
progression from encoder-based models requiring fine-tuning to sophisticated
approaches that integrate textual, visual, and auditory data, thereby
facilitating comprehensive AI solutions in healthcare. The paper discusses both
the opportunities these technologies present for enhancing clinical efficiency
and the challenges they pose in terms of ethics, data privacy, and
implementation. Additionally, it critically evaluates the deployment strategies
of LLMs, emphasizing the necessity of open-source models to ensure data privacy
and adaptability within healthcare environments. Future research directions are
proposed, focusing on empirical studies to evaluate the real-world efficacy of
LLMs in healthcare and the development of open datasets for further research.
This review aims to provide a comprehensive resource for both newcomers and
multidisciplinary researchers interested in the intersection of AI and
healthcare.

摘要：這篇論文詳細探討了大型語言模型在醫療保健領域的進展和應用，特別強調臨床應用。這項研究追溯了 LLM 從其基礎技術到特定領域模型和多模態整合的最新發展。它探討了從需要微調的編碼器模型到整合文本、視覺和聽覺數據的先進方法的技術進步，從而促進了醫療保健中的全面 AI 解決方案。這篇論文討論了這些技術在提高臨床效率方面帶來的機遇，以及它們在道德、數據隱私和實施方面帶來的挑戰。此外，它批判性地評估了 LLM 的部署策略，強調了開源模型對於確保醫療保健環境中的數據隱私和適應性的必要性。提出了未來的研究方向，重點是實證研究，以評估 LLM 在醫療保健中的實際功效和開發開放式數據集以進行進一步的研究。這篇綜述旨在為對 AI 和醫療保健的交叉點感興趣的新手和多學科研究人員提供全面的資源。

##### **Efficient Detection of Toxic Prompts in Large Language Models**
2408.11727v1 by Yi Liu, Junzhe Yu, Huijia Sun, Ling Shi, Gelei Deng, Yuqi Chen, Yang Liu

Large language models (LLMs) like ChatGPT and Gemini have significantly
advanced natural language processing, enabling various applications such as
chatbots and automated content generation. However, these models can be
exploited by malicious individuals who craft toxic prompts to elicit harmful or
unethical responses. These individuals often employ jailbreaking techniques to
bypass safety mechanisms, highlighting the need for robust toxic prompt
detection methods. Existing detection techniques, both blackbox and whitebox,
face challenges related to the diversity of toxic prompts, scalability, and
computational efficiency. In response, we propose ToxicDetector, a lightweight
greybox method designed to efficiently detect toxic prompts in LLMs.
ToxicDetector leverages LLMs to create toxic concept prompts, uses embedding
vectors to form feature vectors, and employs a Multi-Layer Perceptron (MLP)
classifier for prompt classification. Our evaluation on various versions of the
LLama models, Gemma-2, and multiple datasets demonstrates that ToxicDetector
achieves a high accuracy of 96.39\% and a low false positive rate of 2.00\%,
outperforming state-of-the-art methods. Additionally, ToxicDetector's
processing time of 0.0780 seconds per prompt makes it highly suitable for
real-time applications. ToxicDetector achieves high accuracy, efficiency, and
scalability, making it a practical method for toxic prompt detection in LLMs.

摘要：大型語言模型 (LLM)，例如 ChatGPT 和 Gemini，已大幅提升自然語言處理，支援各種應用程式，例如聊天機器人和自動產生內容。然而，惡意人士可能會利用這些模型，建立有毒提示，引發有害或不道德的回應。這些人士通常會採用越獄技術，繞過安全機制，突顯了對強大的有毒提示偵測方法的需求。現有的偵測技術，包括黑盒和白盒，都面臨與有毒提示的多樣性、可擴充性和運算效率相關的挑戰。為了解決這個問題，我們提出 ToxicDetector，一種輕量級灰盒方法，旨在有效率地偵測 LLM 中的有毒提示。ToxicDetector 藉由 LLM 建立有毒概念提示，使用嵌入向量形成特徵向量，並採用多層感知器 (MLP) 分類器進行提示分類。我們對 LLama 模型、Gemma-2 和多個資料集的各種版本進行評估，結果顯示 ToxicDetector 達到 96.39% 的高準確度和 2.00% 的低偽陽性率，優於現有的方法。此外，ToxicDetector 每個提示 0.0780 秒的處理時間，使其非常適合於即時應用程式。ToxicDetector 達到高準確度、效率和可擴充性，使其成為 LLM 中有毒提示偵測的實用方法。

##### **Iterative Object Count Optimization for Text-to-image Diffusion Models**
2408.11721v1 by Oz Zafar, Lior Wolf, Idan Schwartz

We address a persistent challenge in text-to-image models: accurately
generating a specified number of objects. Current models, which learn from
image-text pairs, inherently struggle with counting, as training data cannot
depict every possible number of objects for any given object. To solve this, we
propose optimizing the generated image based on a counting loss derived from a
counting model that aggregates an object\'s potential. Employing an
out-of-the-box counting model is challenging for two reasons: first, the model
requires a scaling hyperparameter for the potential aggregation that varies
depending on the viewpoint of the objects, and second, classifier guidance
techniques require modified models that operate on noisy intermediate diffusion
steps. To address these challenges, we propose an iterated online training mode
that improves the accuracy of inferred images while altering the text
conditioning embedding and dynamically adjusting hyperparameters. Our method
offers three key advantages: (i) it can consider non-derivable counting
techniques based on detection models, (ii) it is a zero-shot plug-and-play
solution facilitating rapid changes to the counting techniques and image
generation methods, and (iii) the optimized counting token can be reused to
generate accurate images without additional optimization. We evaluate the
generation of various objects and show significant improvements in accuracy.
The project page is available at https://ozzafar.github.io/count_token.

摘要：<paragraph>我們解決了文字轉圖像模型中一個持續的挑戰：準確生成指定數量的物件。目前的模型從影像文字對學習，在計算上本質上會遇到困難，因為訓練資料無法描繪任何給定物件的所有可能數量。為了解決這個問題，我們建議根據從聚合物件潛力的計數模型衍生的計數損失來最佳化生成的影像。採用現成的計數模型具有兩個挑戰：首先，該模型需要一個縮放超參數，用於潛力聚合，該超參數會根據物件的觀點而有所不同；其次，分類器引導技術需要修改模型，這些模型會對有雜訊的中間擴散步驟進行操作。為了應對這些挑戰，我們提出了一種反覆的線上訓練模式，該模式在改變文字條件嵌入和動態調整超參數的同時，提升了推論影像的準確度。我們的模型提供三個主要優點：(i) 它可以考慮基於偵測模型的不可導出計數技術，(ii) 它是一種零次學習的即插即用解決方案，有助於快速變更計數技術和影像生成方法，以及 (iii) 最佳化的計數代幣可以重複使用，以在沒有額外最佳化的情況下生成準確的影像。我們評估了各種物件的生成，並展示了準確度的顯著提升。專案頁面可於 https://ozzafar.github.io/count_token 取得。</paragraph>

##### **Leveraging Large Language Models for Enhancing the Understandability of Generated Unit Tests**
2408.11710v1 by Amirhossein Deljouyi, Roham Koohestani, Maliheh Izadi, Andy Zaidman

Automated unit test generators, particularly search-based software testing
tools like EvoSuite, are capable of generating tests with high coverage.
Although these generators alleviate the burden of writing unit tests, they
often pose challenges for software engineers in terms of understanding the
generated tests. To address this, we introduce UTGen, which combines
search-based software testing and large language models to enhance the
understandability of automatically generated test cases. We achieve this
enhancement through contextualizing test data, improving identifier naming, and
adding descriptive comments. Through a controlled experiment with 32
participants from both academia and industry, we investigate how the
understandability of unit tests affects a software engineer's ability to
perform bug-fixing tasks. We selected bug-fixing to simulate a real-world
scenario that emphasizes the importance of understandable test cases. We
observe that participants working on assignments with UTGen test cases fix up
to 33% more bugs and use up to 20% less time when compared to baseline test
cases. From the post-test questionnaire, we gathered that participants found
that enhanced test names, test data, and variable names improved their
bug-fixing process.

摘要：自動化單元測試產生器，特別是像 EvoSuite 這樣的基於搜尋的軟體測試工具，能夠產生覆蓋率高的測試。
雖然這些產生器減輕了撰寫單元測試的負擔，但它們通常在理解所產生的測試方面對軟體工程師造成挑戰。為了解決這個問題，我們引入了 UTGen，它結合了基於搜尋的軟體測試和大型語言模型，以增強自動產生的測試用例的可理解性。我們透過將測試資料脈絡化、改善識別符命名以及加入說明性註解來實現這種增強。透過一項由學術界和業界的 32 位參與者進行的受控實驗，我們探討單元測試的可理解性如何影響軟體工程師執行錯誤修復任務的能力。我們選擇錯誤修復來模擬一個真實世界的場景，強調可理解的測試用例的重要性。我們觀察到處理 UTGen 測試用例的參與者修復的錯誤最多增加了 33%，與基準測試用例相比，使用的時間最多減少了 20%。從測試後的問卷中，我們收集到參與者發現增強的測試名稱、測試資料和變數名稱改善了他們的錯誤修復流程。

##### **Physics-informed Discovery of State Variables in Second-Order and Hamiltonian Systems**
2408.11691v1 by Félix Chavelli, Zi-Yu Khoo, Dawen Wu, Jonathan Sze Choong Low, Stéphane Bressan

The modeling of dynamical systems is a pervasive concern for not only
describing but also predicting and controlling natural phenomena and engineered
systems. Current data-driven approaches often assume prior knowledge of the
relevant state variables or result in overparameterized state spaces. Boyuan
Chen and his co-authors proposed a neural network model that estimates the
degrees of freedom and attempts to discover the state variables of a dynamical
system. Despite its innovative approach, this baseline model lacks a connection
to the physical principles governing the systems it analyzes, leading to
unreliable state variables.
  This research proposes a method that leverages the physical characteristics
of second-order Hamiltonian systems to constrain the baseline model. The
proposed model outperforms the baseline model in identifying a minimal set of
non-redundant and interpretable state variables.

摘要：動態系統的建模不僅是描述，也是預測和控制自然現象和工程系統的普遍關注。目前的資料驅動方法通常假設先前已知相關狀態變數或導致過度參數化的狀態空間。Boyuan Chen 和他的共同作者提出了一個神經網路模型，用以估計自由度並嘗試找出動態系統的狀態變數。儘管採用創新的方法，但這個基準模型缺乏與其分析系統所遵循的物理原理的連結，導致無法信賴狀態變數。
本研究提出了一種方法，利用二階哈密頓系統的物理特性來約束基準模型。所提出的模型在找出最簡的一組非冗餘且可解釋的狀態變數方面，表現優於基準模型。

##### **5G NR PRACH Detection with Convolutional Neural Networks (CNN): Overcoming Cell Interference Challenges**
2408.11659v1 by Desire Guel, Arsene Kabore, Didier Bassole

In this paper, we present a novel approach to interference detection in 5G
New Radio (5G-NR) networks using Convolutional Neural Networks (CNN).
Interference in 5G networks challenges high-quality service due to dense user
equipment deployment and increased wireless environment complexity. Our
CNN-based model is designed to detect Physical Random Access Channel (PRACH)
sequences amidst various interference scenarios, leveraging the spatial and
temporal characteristics of PRACH signals to enhance detection accuracy and
robustness. Comprehensive datasets of simulated PRACH signals under controlled
interference conditions were generated to train and validate the model.
Experimental results show that our CNN-based approach outperforms traditional
PRACH detection methods in accuracy, precision, recall and F1-score. This study
demonstrates the potential of AI/ML techniques in advancing interference
management in 5G networks, providing a foundation for future research and
practical applications in optimizing network performance and reliability.

摘要：在本文中，我們提出了一種使用卷積神經網路 (CNN) 進行 5G 新無線電 (5G-NR) 網路干擾偵測的新穎方法。由於密集的使用者設備部署和無線環境複雜性的增加，5G 網路的干擾對高品質服務構成挑戰。我們的基於 CNN 的模型旨在在各種干擾場景中偵測物理隨機存取通道 (PRACH) 序列，利用 PRACH 訊號的空間和時間特徵來增強偵測準確度和穩健性。產生了在受控干擾條件下模擬 PRACH 訊號的綜合資料集，以訓練和驗證模型。實驗結果表明，我們的基於 CNN 的方法在準確度、精確度、召回率和 F1 分數方面優於傳統的 PRACH 偵測方法。這項研究展示了 AI/ML 技術在推進 5G 網路干擾管理中的潛力，為未來研究和實務應用奠定了基礎，以最佳化網路效能和可靠性。

##### **CIPHER: Cybersecurity Intelligent Penetration-testing Helper for Ethical Researcher**
2408.11650v1 by Derry Pratama, Naufal Suryanto, Andro Aprila Adiputra, Thi-Thu-Huong Le, Ahmada Yusril Kadiptya, Muhammad Iqbal, Howon Kim

Penetration testing, a critical component of cybersecurity, typically
requires extensive time and effort to find vulnerabilities. Beginners in this
field often benefit from collaborative approaches with the community or
experts. To address this, we develop CIPHER (Cybersecurity Intelligent
Penetration-testing Helper for Ethical Researchers), a large language model
specifically trained to assist in penetration testing tasks. We trained CIPHER
using over 300 high-quality write-ups of vulnerable machines, hacking
techniques, and documentation of open-source penetration testing tools.
Additionally, we introduced the Findings, Action, Reasoning, and Results (FARR)
Flow augmentation, a novel method to augment penetration testing write-ups to
establish a fully automated pentesting simulation benchmark tailored for large
language models. This approach fills a significant gap in traditional
cybersecurity Q\&A benchmarks and provides a realistic and rigorous standard
for evaluating AI's technical knowledge, reasoning capabilities, and practical
utility in dynamic penetration testing scenarios. In our assessments, CIPHER
achieved the best overall performance in providing accurate suggestion
responses compared to other open-source penetration testing models of similar
size and even larger state-of-the-art models like Llama 3 70B and Qwen1.5 72B
Chat, particularly on insane difficulty machine setups. This demonstrates that
the current capabilities of general LLMs are insufficient for effectively
guiding users through the penetration testing process. We also discuss the
potential for improvement through scaling and the development of better
benchmarks using FARR Flow augmentation results. Our benchmark will be released
publicly at https://github.com/ibndias/CIPHER.

摘要：滲透測試是網路安全的重要組成部分，通常需要花費大量時間和精力來找出漏洞。此領域的初學者通常會受益於與社群或專家的合作方法。為了解決這個問題，我們開發了 CIPHER（網路安全智慧滲透測試協助程式，專為道德研究人員設計），這是一個大型語言模型，經過特別訓練以協助滲透測試任務。我們使用超過 300 篇高品質的弱點機器撰寫、駭客技術，以及開源滲透測試工具文件來訓練 CIPHER。此外，我們引入了發現、行動、推理和結果 (FARR) 流程擴充功能，這是一種創新的方法，可用於擴充滲透測試撰寫內容，以建立完全自動化的滲透測試模擬基準，專門針對大型語言模型量身打造。這種方法填補了傳統網路安全問答基準的重大空白，並提供了一個現實且嚴格的標準，用於評估 AI 在動態滲透測試場景中的技術知識、推理能力和實際效用。在我們的評估中，與其他類似規模的開源滲透測試模型，甚至是 Llama 3 70B 和 Qwen1.5 72B Chat 等更大的最先進模型相比，CIPHER 在提供準確建議回應方面達到了最佳的整體效能，特別是在困難的機器設定上。這證明了目前一般 LLM 的能力不足以有效引導使用者完成滲透測試流程。我們還討論了透過擴充和使用 FARR 流程擴充結果開發更好的基準來改進的潛力。我們的基準將在 https://github.com/ibndias/CIPHER 公開發布。

##### **Video-to-Text Pedestrian Monitoring (VTPM): Leveraging Computer Vision and Large Language Models for Privacy-Preserve Pedestrian Activity Monitoring at Intersections**
2408.11649v1 by Ahmed S. Abdelrahman, Mohamed Abdel-Aty, Dongdong Wang

Computer vision has advanced research methodologies, enhancing system
services across various fields. It is a core component in traffic monitoring
systems for improving road safety; however, these monitoring systems don't
preserve the privacy of pedestrians who appear in the videos, potentially
revealing their identities. Addressing this issue, our paper introduces
Video-to-Text Pedestrian Monitoring (VTPM), which monitors pedestrian movements
at intersections and generates real-time textual reports, including traffic
signal and weather information. VTPM uses computer vision models for pedestrian
detection and tracking, achieving a latency of 0.05 seconds per video frame.
Additionally, it detects crossing violations with 90.2% accuracy by
incorporating traffic signal data. The proposed framework is equipped with
Phi-3 mini-4k to generate real-time textual reports of pedestrian activity
while stating safety concerns like crossing violations, conflicts, and the
impact of weather on their behavior with latency of 0.33 seconds. To enhance
comprehensive analysis of the generated textual reports, Phi-3 medium is
fine-tuned for historical analysis of these generated textual reports. This
fine-tuning enables more reliable analysis about the pedestrian safety at
intersections, effectively detecting patterns and safety critical events. The
proposed VTPM offers a more efficient alternative to video footage by using
textual reports reducing memory usage, saving up to 253 million percent,
eliminating privacy issues, and enabling comprehensive interactive historical
analysis.

摘要：電腦視覺已進步的研究方法，加強了各個領域的系統服務。它是交通監控系統中改善道路安全的核心組成部分；然而，這些監控系統並未保護影片中行人的隱私，可能會洩露他們的身份。為了解決這個問題，我們的論文介紹了影片轉文字行人監控 (VTPM)，它會監控十字路口的行人動態，並產生即時文字報告，包括交通號誌和天氣資訊。VTPM 使用電腦視覺模型來進行行人偵測和追蹤，每秒影片幀可達到 0.05 秒的延遲。此外，它透過整合交通號誌資料，以 90.2% 的準確度偵測違規穿越。所提出的架構配備了 Phi-3 mini-4k，可產生行人活動的即時文字報告，同時說明安全問題，例如違規穿越、衝突以及天氣對其行為的影響，延遲為 0.33 秒。為了加強對所產生文字報告的全面分析，Phi-3 medium 已針對這些產生的文字報告的歷史分析進行微調。這種微調可針對十字路口的行人安全進行更可靠的分析，有效偵測模式和安全關鍵事件。所提出的 VTPM 提供了比影片片段更有效率的替代方案，透過使用文字報告來減少記憶體使用量，節省高達 2.53 億%，消除隱私問題，並啟用全面的互動式歷史分析。

##### **Data-driven Modeling of Combined Sewer Systems for Urban Sustainability: An Empirical Evaluation**
2408.11619v1 by Vipin Singh, Tianheng Ling, Teodor Chiaburu, Felix Biessmann

Climate change poses complex challenges, with extreme weather events becoming
increasingly frequent and difficult to model. Examples include the dynamics of
Combined Sewer Systems (CSS). Overburdened CSS during heavy rainfall will
overflow untreated wastewater into surface water bodies. Classical approaches
to modeling the impact of extreme rainfall events rely on physical simulations,
which are particularly challenging to create for large urban infrastructures.
Deep Learning (DL) models offer a cost-effective alternative for modeling the
complex dynamics of sewer systems. In this study, we present a comprehensive
empirical evaluation of several state-of-the-art DL time series models for
predicting sewer system dynamics in a large urban infrastructure, utilizing
three years of measurement data. We especially investigate the potential of DL
models to maintain predictive precision during network outages by comparing
global models, which have access to all variables within the sewer system, and
local models, which are limited to data from a restricted set of local sensors.
Our findings demonstrate that DL models can accurately predict the dynamics of
sewer system load, even under network outage conditions. These results suggest
that DL models can effectively aid in balancing the load redistribution in CSS,
thereby enhancing the sustainability and resilience of urban infrastructures.

摘要：氣候變遷帶來複雜的挑戰，極端天氣事件變得越來越頻繁且難以建模。舉例來說，下水道系統 (CSS) 的動態。強降雨時，負擔過重的 CSS 會使未經處理的廢水溢流到地表水體中。模擬極端降雨事件影響的傳統方法依賴於物理模擬，而這對於大型城市基礎設施來說特別難以建立。深度學習 (DL) 模型為模擬下水道系統的複雜動態提供了一個具有成本效益的替代方案。在本研究中，我們對幾個最先進的 DL 時間序列模型進行了全面的經驗評估，以預測大型城市基礎設施中的下水道系統動態，利用三年的測量數據。我們特別研究了 DL 模型在網路中斷期間維持預測精度的潛力，方法是比較全局模型（可以存取下水道系統中的所有變數）和局部模型（僅限於來自一組受限的局部感測器的資料）。我們的研究結果表明，DL 模型可以準確預測下水道系統負載的動態，即使在網路中斷的情況下也是如此。這些結果表明，DL 模型可以有效地幫助平衡 CSS 中的負載重新分配，從而增強城市基礎設施的可持續性和韌性。

##### **Xinyu: An Efficient LLM-based System for Commentary Generation**
2408.11609v1 by Yiquan Wu, Bo Tang, Chenyang Xi, Yu Yu, Pengyu Wang, Yifei Liu, Kun Kuang, Haiying Deng, Zhiyu Li, Feiyu Xiong, Jie Hu, Peng Cheng, Zhonghao Wang, Yi Wang, Yi Luo, Mingchuan Yang

Commentary provides readers with a deep understanding of events by presenting
diverse arguments and evidence. However, creating commentary is a
time-consuming task, even for skilled commentators. Large language models
(LLMs) have simplified the process of natural language generation, but their
direct application in commentary creation still faces challenges due to unique
task requirements. These requirements can be categorized into two levels: 1)
fundamental requirements, which include creating well-structured and logically
consistent narratives, and 2) advanced requirements, which involve generating
quality arguments and providing convincing evidence. In this paper, we
introduce Xinyu, an efficient LLM-based system designed to assist commentators
in generating Chinese commentaries. To meet the fundamental requirements, we
deconstruct the generation process into sequential steps, proposing targeted
strategies and supervised fine-tuning (SFT) for each step. To address the
advanced requirements, we present an argument ranking model for arguments and
establish a comprehensive evidence database that includes up-to-date events and
classic books, thereby strengthening the substantiation of the evidence with
retrieval augmented generation (RAG) technology. To evaluate the generated
commentaries more fairly, corresponding to the two-level requirements, we
introduce a comprehensive evaluation metric that considers five distinct
perspectives in commentary generation. Our experiments confirm the
effectiveness of our proposed system. We also observe a significant increase in
the efficiency of commentators in real-world scenarios, with the average time
spent on creating a commentary dropping from 4 hours to 20 minutes.
Importantly, such an increase in efficiency does not compromise the quality of
the commentaries.

摘要：<paragraph>評論透過提出不同的論點和證據，讓讀者深入了解事件。然而，即使對熟練的評論家而言，撰寫評論都是一項耗時的任務。大型語言模型 (LLM) 簡化了自然語言生成的流程，但由於獨特的任務需求，它們在評論撰寫中的直接應用仍面臨挑戰。這些需求可分為兩個層級：1) 基本需求，包括建立結構良好且合乎邏輯的敘述，以及 2) 進階需求，包括產生高品質的論點和提供令人信服的證據。在本文中，我們介紹 Xinyu，一個基於 LLM 的高效系統，旨在協助評論家產生中文評論。為了滿足基本需求，我們將生成流程解構為循序漸進的步驟，針對每個步驟提出目標策略和監督微調 (SFT)。為了滿足進階需求，我們提出一個論點排名模型，並建立一個包含最新事件和經典書籍的綜合證據資料庫，從而透過檢索擴充生成 (RAG) 技術強化證據的實質內容。為了更公平地評估所生成的評論，針對這兩個層級的需求，我們引入一個綜合評量指標，考量評論生成中的五個不同觀點。我們的實驗證實了我們所提出的系統的有效性。我們也觀察到在實際情況中，評論家的效率顯著提升，撰寫一篇評論所花的平均時間從 4 小時縮短至 20 分鐘。重要的是，效率的提升並未損害評論的品質。</paragraph>

##### **Cause-Aware Empathetic Response Generation via Chain-of-Thought Fine-Tuning**
2408.11599v1 by Xinhao Chen, Chong Yang, Man Lan, Li Cai, Yang Chen, Tu Hu, Xinlin Zhuang, Aimin Zhou

Empathetic response generation endows agents with the capability to
comprehend dialogue contexts and react to expressed emotions. Previous works
predominantly focus on leveraging the speaker's emotional labels, but ignore
the importance of emotion cause reasoning in empathetic response generation,
which hinders the model's capacity for further affective understanding and
cognitive inference. In this paper, we propose a cause-aware empathetic
generation approach by integrating emotions and causes through a well-designed
Chain-of-Thought (CoT) prompt on Large Language Models (LLMs). Our approach can
greatly promote LLMs' performance of empathy by instruction tuning and
enhancing the role awareness of an empathetic listener in the prompt.
Additionally, we propose to incorporate cause-oriented external knowledge from
COMET into the prompt, which improves the diversity of generation and
alleviates conflicts between internal and external knowledge at the same time.
Experimental results on the benchmark dataset demonstrate that our approach on
LLaMA-7b achieves state-of-the-art performance in both automatic and human
evaluations.

摘要：共情回應生成賦予代理人理解對話脈絡並對表達的情緒做出反應的能力。先前的作品主要專注於利用說話者的情緒標籤，但忽略了情緒原因在共情回應生成中的重要性，這阻礙了模型進一步情感理解和認知推論的能力。在本文中，我們提出了一種原因感知共情生成方法，通過在大型語言模型 (LLM) 上精心設計的思想鏈 (CoT) 提示整合情緒和原因。我們的做法可以通過指令調整和增強提示中同理傾聽者的角色意識，極大地提升 LLM 的同理心表現。此外，我們建議將面向原因的外部知識從 COMET 納入提示中，這同時提高了生成的 diversity，並緩解了內部和外部知識之間的衝突。基準數據集上的實驗結果表明，我們在 LLaMA-7b 上的方法在自動和人工評估中都達到了最先進的性能。

##### **Active learning for efficient data selection in radio-signal based positioning via deep learning**
2408.11592v1 by Vincent Corlay, Milan Courcoux-Caro

We consider the problem of user equipment (UE) positioning based on radio
signals via deep learning. As in most supervised-learning tasks, a critical
aspect is the availability of a relevant dataset to train a model. However, in
a cellular network, the data-collection step may induce a high communication
overhead. As a result, to reduce the required size of the dataset, it may be
interesting to carefully choose the positions to be labelled and to be used in
the training. We therefore propose an active learning approach for efficient
data collection. We first show that significant gains (both in terms of
positioning accuracy and size of the required dataset) can be obtained for the
considered positioning problem using a genie. This validates the interest of
active learning for positioning. We then propose a \textcolor{blue}{practical}
method to approximate this genie.

摘要：我們考慮使用深度學習，根據無線電信號進行用戶設備 (UE) 定位的問題。與大多數監督式學習任務一樣，一個關鍵方面是相關資料集的可用性，以訓練模型。然而，在蜂巢式網路中，資料收集步驟可能會導致高通訊開銷。因此，為了減少所需的資料集大小，仔細選擇要標記並用於訓練的位置可能是很重要的。因此，我們提出主動學習方法，以有效收集資料。我們首先表明，對於考慮定位問題，可以使用精靈獲得顯著的收益（無論是在定位準確度還是所需資料集的大小方面）。這驗證了主動學習在定位方面的興趣。然後，我們提出一個實用的方法來近似這個精靈。

##### **Large Language Models are Good Attackers: Efficient and Stealthy Textual Backdoor Attacks**
2408.11587v1 by Ziqiang Li, Yueqi Zeng, Pengfei Xia, Lei Liu, Zhangjie Fu, Bin Li

With the burgeoning advancements in the field of natural language processing
(NLP), the demand for training data has increased significantly. To save costs,
it has become common for users and businesses to outsource the labor-intensive
task of data collection to third-party entities. Unfortunately, recent research
has unveiled the inherent risk associated with this practice, particularly in
exposing NLP systems to potential backdoor attacks. Specifically, these attacks
enable malicious control over the behavior of a trained model by poisoning a
small portion of the training data. Unlike backdoor attacks in computer vision,
textual backdoor attacks impose stringent requirements for attack stealthiness.
However, existing attack methods meet significant trade-off between
effectiveness and stealthiness, largely due to the high information entropy
inherent in textual data. In this paper, we introduce the Efficient and
Stealthy Textual backdoor attack method, EST-Bad, leveraging Large Language
Models (LLMs). Our EST-Bad encompasses three core strategies: optimizing the
inherent flaw of models as the trigger, stealthily injecting triggers with
LLMs, and meticulously selecting the most impactful samples for backdoor
injection. Through the integration of these techniques, EST-Bad demonstrates an
efficient achievement of competitive attack performance while maintaining
superior stealthiness compared to prior methods across various text classifier
datasets.

摘要：隨著自然語言處理 (NLP) 領域的蓬勃發展，對訓練資料的需求大幅增加。為了節省成本，使用者和企業已普遍將資料收集的勞力密集型任務外包給第三方實體。不幸的是，最近的研究揭露了這種做法固有的風險，特別是在將 NLP 系統暴露於潛在後門攻擊時。具體來說，這些攻擊透過毒化訓練資料的一小部分來實現對訓練模型行為的惡意控制。與電腦視覺中的後門攻擊不同，文字後門攻擊對攻擊隱蔽性提出了嚴格的要求。然而，現有的攻擊方法在有效性與隱蔽性之間存在顯著的權衡，這主要是因為文字資料中固有的高資訊熵。在本文中，我們介紹了高效且隱蔽的文字後門攻擊方法 EST-Bad，它利用了大型語言模型 (LLM)。我們的 EST-Bad 涵蓋了三個核心策略：將模型的固有缺陷最佳化為觸發器、使用 LLM 隱蔽地注入觸發器，以及仔細選擇對後門注入影響最大的範例。透過整合這些技術，EST-Bad 展示了在與各種文字分類器資料集相比之下，在維持優異隱蔽性的同時，有效達成具有競爭力的攻擊效能。

##### **Drama Engine: A Framework for Narrative Agents**
2408.11574v1 by Martin Pichlmair, Riddhi Raj, Charlene Putney

This technical report presents the Drama Engine, a novel framework for
agentic interaction with large language models designed for narrative purposes.
The framework adapts multi-agent system principles to create dynamic,
context-aware companions that can develop over time and interact with users and
each other. Key features include multi-agent workflows with delegation, dynamic
prompt assembly, and model-agnostic design. The Drama Engine introduces unique
elements such as companion development, mood systems, and automatic context
summarising. It is implemented in TypeScript. The framework's applications
include multi-agent chats and virtual co-workers for creative writing. The
paper discusses the system's architecture, prompt assembly process, delegation
mechanisms, and moderation techniques, as well as potential ethical
considerations and future extensions.

摘要：這份技術報告介紹了 Drama Engine，這是一個新穎的架構，用於與為敘事目的而設計的大型語言模型進行代理互動。
該架構採用多代理系統原則來創建動態、具備情境感知能力的夥伴，這些夥伴可以隨著時間推移而發展並與使用者和彼此互動。主要功能包括具有委派的多代理工作流程、動態提示組裝和與模型無關的設計。Drama Engine 引入了獨特的元素，例如夥伴開發、情緒系統和自動情境摘要。它使用 TypeScript 實作。該架構的應用包括多代理聊天和虛擬協作者，用於創意寫作。本文討論了系統的架構、提示組裝流程、委派機制和審核技術，以及潛在的道德考量和未來的延伸。

##### **Differentiating Choices via Commonality for Multiple-Choice Question Answering**
2408.11554v1 by Wenqing Deng, Zhe Wang, Kewen Wang, Shirui Pan, Xiaowang Zhang, Zhiyong Feng

Multiple-choice question answering (MCQA) becomes particularly challenging
when all choices are relevant to the question and are semantically similar. Yet
this setting of MCQA can potentially provide valuable clues for choosing the
right answer. Existing models often rank each choice separately, overlooking
the context provided by other choices. Specifically, they fail to leverage the
semantic commonalities and nuances among the choices for reasoning. In this
paper, we propose a novel MCQA model by differentiating choices through
identifying and eliminating their commonality, called DCQA. Our model captures
token-level attention of each choice to the question, and separates tokens of
the question attended to by all the choices (i.e., commonalities) from those by
individual choices (i.e., nuances). Using the nuances as refined contexts for
the choices, our model can effectively differentiate choices with subtle
differences and provide justifications for choosing the correct answer. We
conduct comprehensive experiments across five commonly used MCQA benchmarks,
demonstrating that DCQA consistently outperforms baseline models. Furthermore,
our case study illustrates the effectiveness of the approach in directing the
attention of the model to more differentiating features.

摘要：多選題問答 (MCQA) 在所有選項都與問題相關且語義相似時，會變得特別具有挑戰性。然而，這種 MCQA 設定可以潛在提供有價值的線索，以選擇正確答案。現有的模型通常會分別對每個選項進行排名，忽略其他選項提供的上下文。具體來說，它們無法利用選項之間的語義共性和細微差別進行推理。在本文中，我們提出了通過識別和消除它們的共性來區分選項的新型 MCQA 模型，稱為 DCQA。我們的模型捕捉每個選項對問題的標記級別注意力，並將所有選項關注的問題標記（即共性）與個別選項關注的問題標記（即細微差別）分開。使用細微差別作為選項的精緻上下文，我們的模型可以有效地區分具有細微差別並提供選擇正確答案的理由。我們在五個常用的 MCQA 基準上進行了全面的實驗，證明 DCQA 持續優於基準模型。此外，我們的案例研究說明了該方法在將模型的注意力引導到更多區分性特徵方面的有效性。

##### **Explainable Deep Learning Framework for Human Activity Recognition**
2408.11552v1 by Yiran Huang, Yexu Zhou, Haibin Zhao, Till Riedel, Michael Beigl

In the realm of human activity recognition (HAR), the integration of
explainable Artificial Intelligence (XAI) emerges as a critical necessity to
elucidate the decision-making processes of complex models, fostering
transparency and trust. Traditional explanatory methods like Class Activation
Mapping (CAM) and attention mechanisms, although effective in highlighting
regions vital for decisions in various contexts, prove inadequate for HAR. This
inadequacy stems from the inherently abstract nature of HAR data, rendering
these explanations obscure. In contrast, state-of-th-art post-hoc
interpretation techniques for time series can explain the model from other
perspectives. However, this requires extra effort. It usually takes 10 to 20
seconds to generate an explanation. To overcome these challenges, we proposes a
novel, model-agnostic framework that enhances both the interpretability and
efficacy of HAR models through the strategic use of competitive data
augmentation. This innovative approach does not rely on any particular model
architecture, thereby broadening its applicability across various HAR models.
By implementing competitive data augmentation, our framework provides intuitive
and accessible explanations of model decisions, thereby significantly advancing
the interpretability of HAR systems without compromising on performance.

摘要：在人類活動辨識（HAR）領域中，可解釋人工智慧（XAI）的整合成為關鍵必要性，用於闡明複雜模型的決策過程，促進透明度和信任。傳統的說明方法，例如類別激活對應（CAM）和注意力機制，雖然有效地突顯在各種情境中對決策至關重要的區域，但證明不適用於 HAR。這種不適用性源自於 HAR 資料本質上抽象，導致這些說明模稜兩可。相反地，時間序列的最新事後詮釋技術可以從其他觀點說明模型。然而，這需要額外的努力。通常需要 10 到 20 秒才能產生說明。為了克服這些挑戰，我們提出一個創新的、與模型無關的架構，透過策略性地使用競爭性資料擴充來增強 HAR 模型的可詮釋性和效能。這種創新方法不依賴任何特定的模型架構，從而擴展其在各種 HAR 模型中的適用性。透過實作競爭性資料擴充，我們的架構提供直覺且容易理解的模型決策說明，從而大幅提升 HAR 系統的可詮釋性，同時不損及效能。

##### **Memorization In In-Context Learning**
2408.11546v1 by Shahriar Golchin, Mihai Surdeanu, Steven Bethard, Eduardo Blanco, Ellen Riloff

In-context learning (ICL) has proven to be an effective strategy for
improving the performance of large language models (LLMs) with no additional
training. However, the exact mechanism behind these performance improvements
remains unclear. This study is the first to show how ICL surfaces memorized
training data and to explore the correlation between this memorization and
performance across various ICL regimes: zero-shot, few-shot, and many-shot. Our
most notable findings include: (1) ICL significantly surfaces memorization
compared to zero-shot learning in most cases; (2) demonstrations, without their
labels, are the most effective element in surfacing memorization; (3) ICL
improves performance when the surfaced memorization in few-shot regimes reaches
a high level (about 40%); and (4) there is a very strong correlation between
performance and memorization in ICL when it outperforms zero-shot learning.
Overall, our study uncovers a hidden phenomenon -- memorization -- at the core
of ICL, raising an important question: to what extent do LLMs truly generalize
from demonstrations in ICL, and how much of their success is due to
memorization?

摘要：情境學習 (ICL) 已被證明是一種有效的策略，可以在不進行額外訓練的情況下提升大型語言模型 (LLM) 的效能。然而，這些效能提升背後的確切機制仍不明確。本研究首次展示了 ICL 如何浮現記憶化的訓練資料，並探索此記憶化與各種 ICL 制度（零次學習、少次學習和多次學習）之間的關聯性。我們最顯著的發現包括：(1) 在大多數情況下，與零次學習相比，ICL 會顯著浮現記憶化；(2) 示範（不含標籤）是浮現記憶化最有效的元素；(3) 當少次學習制度中的浮現記憶化達到高水準（約 40%）時，ICL 會提升效能；(4) 當 ICL 勝過零次學習時，效能與記憶化之間存在非常強烈的關聯性。總體而言，我們的研究揭露了一個隱藏的現象——記憶化——這是 ICL 的核心，並提出了一個重要問題：LLM 在多大程度上真正從 ICL 中的示範中概括，而它們的成功有多少歸功於記憶化？

##### **RConE: Rough Cone Embedding for Multi-Hop Logical Query Answering on Multi-Modal Knowledge Graphs**
2408.11526v1 by Mayank Kharbanda, Rajiv Ratn Shah, Raghava Mutharaju

Multi-hop query answering over a Knowledge Graph (KG) involves traversing one
or more hops from the start node to answer a query. Path-based and logic-based
methods are state-of-the-art for multi-hop question answering. The former is
used in link prediction tasks. The latter is for answering complex logical
queries. The logical multi-hop querying technique embeds the KG and queries in
the same embedding space. The existing work incorporates First Order Logic
(FOL) operators, such as conjunction ($\wedge$), disjunction ($\vee$), and
negation ($\neg$), in queries. Though current models have most of the building
blocks to execute the FOL queries, they cannot use the dense information of
multi-modal entities in the case of Multi-Modal Knowledge Graphs (MMKGs). We
propose RConE, an embedding method to capture the multi-modal information
needed to answer a query. The model first shortlists candidate (multi-modal)
entities containing the answer. It then finds the solution (sub-entities)
within those entities. Several existing works tackle path-based
question-answering in MMKGs. However, to our knowledge, we are the first to
introduce logical constructs in querying MMKGs and to answer queries that
involve sub-entities of multi-modal entities as the answer. Extensive
evaluation of four publicly available MMKGs indicates that RConE outperforms
the current state-of-the-art.

摘要：多跳查询回答涉及从起始节点遍历一个或多个跳跃来回答查询。基于路径和基于逻辑的方法是多跳问题回答的最新技术。前者用于链接预测任务。后者用于回答复杂的逻辑查询。逻辑多跳查询技术将知识图谱和查询嵌入到相同的嵌入空间中。现有工作在查询中纳入了第一阶逻辑 (FOL) 运算符，例如合取 ($\wedge$)、析取 ($\vee$) 和否定 ($\neg$)。虽然当前模型具有执行 FOL 查询的大部分构建模块，但它们在多模态知识图谱 (MMKG) 的情况下无法使用多模态实体的密集信息。我们提出了 RConE，这是一种嵌入方法，用于捕获回答查询所需的多模态信息。该模型首先筛选包含答案的候选（多模态）实体。然后在这些实体中找到解决方案（子实体）。一些现有工作解决了 MMKG 中基于路径的问题回答。然而，据我们所知，我们是第一个在查询 MMKG 中引入逻辑结构并回答查询的人，这些查询涉及多模态实体的子实体作为答案。对四个公开可用的 MMKG 的广泛评估表明，RConE 优于当前的最新技术。

##### **LARR: Large Language Model Aided Real-time Scene Recommendation with Semantic Understanding**
2408.11523v1 by Zhizhong Wan, Bin Yin, Junjie Xie, Fei Jiang, Xiang Li, Wei Lin

Click-Through Rate (CTR) prediction is crucial for Recommendation System(RS),
aiming to provide personalized recommendation services for users in many
aspects such as food delivery, e-commerce and so on. However, traditional RS
relies on collaborative signals, which lacks semantic understanding to
real-time scenes. We also noticed that a major challenge in utilizing Large
Language Models (LLMs) for practical recommendation purposes is their
efficiency in dealing with long text input. To break through the problems
above, we propose Large Language Model Aided Real-time Scene
Recommendation(LARR), adopt LLMs for semantic understanding, utilizing
real-time scene information in RS without requiring LLM to process the entire
real-time scene text directly, thereby enhancing the efficiency of LLM-based
CTR modeling. Specifically, recommendation domain-specific knowledge is
injected into LLM and then RS employs an aggregation encoder to build real-time
scene information from separate LLM's outputs. Firstly, a LLM is continual
pretrained on corpus built from recommendation data with the aid of special
tokens. Subsequently, the LLM is fine-tuned via contrastive learning on three
kinds of sample construction strategies. Through this step, LLM is transformed
into a text embedding model. Finally, LLM's separate outputs for different
scene features are aggregated by an encoder, aligning to collaborative signals
in RS, enhancing the performance of recommendation model.

摘要：點擊率 (CTR) 預測對於推薦系統 (RS) 至關重要，旨在為使用者提供個人化的推薦服務，例如送餐、電子商務等許多方面。然而，傳統的 RS 依賴於協作信號，這缺乏對即時場景的語義理解。我們還注意到，將大型語言模型 (LLM) 用於實際推薦目的的主要挑戰在於它們處理長文本輸入的效率。為了突破上述問題，我們提出大型語言模型輔助即時場景推薦 (LARR)，採用 LLM 進行語義理解，在 RS 中利用即時場景資訊，而不需要 LLM 直接處理整個即時場景文字，從而提高基於 LLM 的 CTR 建模的效率。具體來說，推薦領域特定的知識被注入到 LLM 中，然後 RS 使用聚合編碼器從 LLM 的單獨輸出中建立即時場景資訊。首先，LLM 在特殊符號的幫助下，在由推薦資料建立的語料庫上進行持續預訓練。隨後，LLM 透過對比學習在三種樣本建構策略上進行微調。透過這個步驟，LLM 轉變為文字嵌入模型。最後，LLM 針對不同場景特徵的單獨輸出由編碼器聚合，與 RS 中的協作信號對齊，增強推薦模型的效能。

##### **Imagining from Images with an AI Storytelling Tool**
2408.11517v1 by Edirlei Soares de Lima, Marco A. Casanova, Antonio L. Furtado

A method for generating narratives by analyzing single images or image
sequences is presented, inspired by the time immemorial tradition of Narrative
Art. The proposed method explores the multimodal capabilities of GPT-4o to
interpret visual content and create engaging stories, which are illustrated by
a Stable Diffusion XL model. The method is supported by a fully implemented
tool, called ImageTeller, which accepts images from diverse sources as input.
Users can guide the narrative's development according to the conventions of
fundamental genres - such as Comedy, Romance, Tragedy, Satire or Mystery -, opt
to generate data-driven stories, or to leave the prototype free to decide how
to handle the narrative structure. User interaction is provided along the
generation process, allowing the user to request alternative chapters or
illustrations, and even reject and restart the story generation based on the
same input. Additionally, users can attach captions to the input images,
influencing the system's interpretation of the visual content. Examples of
generated stories are provided, along with details on how to access the
prototype.

摘要：<paragraph>一種受自古以來敘事藝術傳統啟發，透過分析單張影像或影像序列來生成敘事的技術。所提出的技術探索 GPT-4o 的多模態能力，以詮釋視覺內容並創造引人入勝的故事，這些故事由 Stable Diffusion XL 模型加以說明。這項技術由一個功能完備的工具支持，稱為 ImageTeller，它接受來自不同來源的影像作為輸入。使用者可以根據基本類型（例如喜劇、愛情、悲劇、諷刺或懸疑）的慣例來引導敘事的發展，選擇生成資料驅動的故事，或讓原型自由決定如何處理敘事結構。使用者互動在生成過程中提供，允許使用者要求替代章節或插圖，甚至基於相同的輸入拒絕並重新開始故事生成。此外，使用者可以為輸入影像附加說明，影響系統對視覺內容的詮釋。提供了生成故事的範例，以及如何存取原型的詳細資訊。</paragraph>

##### **IKUN for WMT24 General MT Task: LLMs Are here for Multilingual Machine Translation**
2408.11512v1 by Baohao Liao, Christian Herold, Shahram Khadivi, Christof Monz

This paper introduces two multilingual systems, IKUN and IKUN-C, developed
for the general machine translation task in WMT24. IKUN and IKUN-C represent an
open system and a constrained system, respectively, built on Llama-3-8b and
Mistral-7B-v0.3. Both systems are designed to handle all 11 language directions
using a single model. According to automatic evaluation metrics, IKUN-C
achieved 6 first-place and 3 second-place finishes among all constrained
systems, while IKUN secured 1 first-place and 2 second-place finishes across
both open and constrained systems. These encouraging results suggest that large
language models (LLMs) are nearing the level of proficiency required for
effective multilingual machine translation. The systems are based on a
two-stage approach: first, continuous pre-training on monolingual data in 10
languages, followed by fine-tuning on high-quality parallel data for 11
language directions. The primary difference between IKUN and IKUN-C lies in
their monolingual pre-training strategy. IKUN-C is pre-trained using
constrained monolingual data, whereas IKUN leverages monolingual data from the
OSCAR dataset. In the second phase, both systems are fine-tuned on parallel
data sourced from NTREX, Flores, and WMT16-23 for all 11 language pairs.

摘要：本文介紹兩個多語言系統 IKUN 和 IKUN-C，這些系統是為 WMT24 中的一般機器翻譯任務開發的。IKUN 和 IKUN-C 分別代表開放系統和受限系統，建立在 Llama-3-8b 和 Mistral-7B-v0.3 上。兩個系統都設計為使用單一模型處理所有 11 種語言方向。根據自動評估指標，IKUN-C 在所有受限系統中獲得 6 個第一名和 3 個第二名，而 IKUN 在開放和受限系統中獲得 1 個第一名和 2 個第二名。這些令人鼓舞的結果表明，大型語言模型 (LLM) 正在接近有效多語言機器翻譯所需的熟練程度。這些系統基於兩階段方法：首先，對 10 種語言的單語資料進行連續預訓練，然後對 11 種語言方向的高品質平行資料進行微調。IKUN 和 IKUN-C 之間的主要區別在於它們的單語預訓練策略。IKUN-C 使用受限的單語資料進行預訓練，而 IKUN 則利用 OSCAR 資料集中的單語資料。在第二階段，兩個系統都針對來自 NTREX、Flores 和 WMT16-23 的所有 11 種語言對的平行資料進行微調。

##### **Mutagenesis screen to map the functionals of parameters of Large Language Models**
2408.11494v1 by Yue Hu, Kai Hu, Patrick X. Zhao, Javed Khan, Chengming Xu

Large Language Models (LLMs) have significantly advanced artificial
intelligence, excelling in numerous tasks. Although the functionality of a
model is inherently tied to its parameters, a systematic method for exploring
the connections between the parameters and the functionality are lacking.
Models sharing similar structure and parameter counts exhibit significant
performance disparities across various tasks, prompting investigations into the
varying patterns that govern their performance. We adopted a mutagenesis screen
approach inspired by the methods used in biological studies, to investigate
Llama2-7b and Zephyr. This technique involved mutating elements within the
models' matrices to their maximum or minimum values to examine the relationship
between model parameters and their functionalities. Our research uncovered
multiple levels of fine structures within both models. Many matrices showed a
mixture of maximum and minimum mutations following mutagenesis, but others were
predominantly sensitive to one type. Notably, mutations that produced
phenotypes, especially those with severe outcomes, tended to cluster along
axes. Additionally, the location of maximum and minimum mutations often
displayed a complementary pattern on matrix in both models, with the Gate
matrix showing a unique two-dimensional asymmetry after rearrangement. In
Zephyr, certain mutations consistently resulted in poetic or conversational
rather than descriptive outputs. These "writer" mutations grouped according to
the high-frequency initial word of the output, with a marked tendency to share
the row coordinate even when they are in different matrices. Our findings
affirm that the mutagenesis screen is an effective tool for deciphering the
complexities of large language models and identifying unexpected ways to expand
their potential, providing deeper insights into the foundational aspects of AI
systems.

摘要：大型語言模型 (LLM) 已大幅推進人工智慧，在眾多任務中表現優異。儘管模型的功能本質上與其參數相關，但缺乏一種系統化的方式來探索參數與功能之間的關聯。具有相似結構和參數計數的模型在各種任務中表現出顯著的差異，促使人們探究影響其效能的不同模式。我們採用了受生物學研究方法啟發的誘變篩選方法，來探究 Llama2-7b 和 Zephyr。此技術涉及將模型矩陣中的元素突變為其最大值或最小值，以檢驗模型參數與其功能之間的關係。我們的研究揭示了這兩個模型中多層次的精細結構。許多矩陣在誘變後顯示出最大和最小突變的混合，但其他矩陣則主要對一種類型敏感。值得注意的是，產生表型的突變，特別是那些具有嚴重後果的突變，往往會沿著軸線聚集。此外，最大和最小突變的位置通常在兩個模型的矩陣上顯示出互補模式，其中 Gate 矩陣在重新排列後顯示出獨特的二維不對稱性。在 Zephyr 中，某些突變始終導致詩意或對話式的輸出，而不是描述性的輸出。這些「寫作」突變根據輸出的高頻率初始字詞進行分組，即使它們位於不同的矩陣中，也表現出明顯的共享列座標的傾向。我們的研究結果證實，誘變篩選是一種解碼大型語言模型複雜性的有效工具，可識別擴展其潛力的意外方法，並提供對 AI 系統基礎層面的更深入見解。

##### **Estimating Peer Direct and Indirect Effects in Observational Network Data**
2408.11492v1 by Xiaojing Du, Jiuyong Li, Debo Cheng, Lin Liu, Wentao Gao, Xiongren Chen

Estimating causal effects is crucial for decision-makers in many
applications, but it is particularly challenging with observational network
data due to peer interactions. Many algorithms have been proposed to estimate
causal effects involving network data, particularly peer effects, but they
often overlook the variety of peer effects. To address this issue, we propose a
general setting which considers both peer direct effects and peer indirect
effects, and the effect of an individual's own treatment, and provide
identification conditions of these causal effects and proofs. To estimate these
causal effects, we utilize attention mechanisms to distinguish the influences
of different neighbors and explore high-order neighbor effects through
multi-layer graph neural networks (GNNs). Additionally, to control the
dependency between node features and representations, we incorporate the
Hilbert-Schmidt Independence Criterion (HSIC) into the GNN, fully utilizing the
structural information of the graph, to enhance the robustness and accuracy of
the model. Extensive experiments on two semi-synthetic datasets confirm the
effectiveness of our approach. Our theoretical findings have the potential to
improve intervention strategies in networked systems, with applications in
areas such as social networks and epidemiology.

摘要：在許多應用中，估計因果關係對於決策者至關重要，但由於同儕互動，在觀察網路資料中特別具有挑戰性。許多演算法已被提出用於估計涉及網路資料的因果關係，特別是同儕效應，但它們常常忽略同儕效應的多樣性。為了解決這個問題，我們提出一個通用的設定，同時考慮同儕直接效應和同儕間接效應，以及個人自身治療的效果，並提供這些因果關係和證明的識別條件。為了估計這些因果關係，我們利用注意力機制來區分不同鄰居的影響，並透過多層圖神經網路 (GNN) 探索高階鄰居效應。此外，為了控制節點特徵和表示之間的依賴性，我們將希爾伯特-施密特獨立準則 (HSIC) 納入 GNN 中，充分利用圖形的結構資訊，以增強模型的穩健性和準確性。在兩個半合成資料集上的大量實驗證實了我們方法的有效性。我們的理論發現有可能改善網路系統中的干預策略，其應用領域包括社交網路和流行病學等。

##### **Nothing in Excess: Mitigating the Exaggerated Safety for LLMs via Safety-Conscious Activation Steering**
2408.11491v1 by Zouying Cao, Yifei Yang, Hai Zhao

Safety alignment is indispensable for Large language models (LLMs) to defend
threats from malicious instructions. However, recent researches reveal
safety-aligned LLMs prone to reject benign queries due to the exaggerated
safety issue, limiting their helpfulness. In this paper, we propose a
Safety-Conscious Activation Steering (SCANS) method to mitigate the exaggerated
safety concerns in aligned LLMs. First, SCANS extracts the refusal steering
vectors within the activation space and utilizes vocabulary projection to
anchor some specific safety-critical layers which influence model refusal
behavior. Second, by tracking the hidden state transition, SCANS identifies the
steering direction and steers the model behavior accordingly, achieving a
balance between exaggerated safety and adequate safety. Experiments show that
SCANS achieves new state-of-the-art performance on XSTest and OKTest
benchmarks, without impairing their defense capability against harmful queries
and maintaining almost unchanged model capability.

摘要：大型語言模型 (LLM) 必須進行安全性校準，才能抵禦惡意指令的威脅。然而，最近的研究顯示，安全性校準的 LLM 容易拒絕良性查詢，因為安全問題被誇大了，這限制了它們的幫助性。在本文中，我們提出了一種安全性意識啟動導向 (SCANS) 方法，以減輕校準 LLM 中誇大的安全問題。首先，SCANS 會在啟動空間中提取拒絕導向向量，並利用詞彙投影來錨定一些特定會影響模型拒絕行為的安全關鍵層。其次，透過追蹤隱藏狀態轉換，SCANS 會識別導向方向，並據此導向模型行為，在誇大的安全性和適當的安全之間取得平衡。實驗顯示，SCANS 在 XSTest 和 OKTest 基準測試中達到了新的最先進效能，而不會損害它們對有害查詢的防禦能力，並維持幾乎不變的模型能力。

##### **DocTabQA: Answering Questions from Long Documents Using Tables**
2408.11490v1 by Haochen Wang, Kai Hu, Haoyu Dong, Liangcai Gao

We study a new problem setting of question answering (QA), referred to as
DocTabQA. Within this setting, given a long document, the goal is to respond to
questions by organizing the answers into structured tables derived directly
from the document's content. Unlike traditional QA approaches which
predominantly rely on unstructured text to formulate responses, DocTabQA aims
to leverage structured tables as answers to convey information clearly and
systematically, thereby enhancing user comprehension and highlighting
relationships between data points. To the best of our knowledge, this problem
has not been previously explored. In this paper, we introduce the QTabA
dataset, encompassing 300 financial documents, accompanied by manually
annotated 1.5k question-table pairs. Initially, we leverage Large Language
Models (LLMs) such as GPT-4 to establish a baseline. However, it is widely
acknowledged that LLMs encounter difficulties when tasked with generating
intricate, structured outputs from long input sequences. To overcome these
challenges, we present a two-stage framework, called DocTabTalk, which
initially retrieves relevant sentences from extensive documents and
subsequently generates hierarchical tables based on these identified sentences.
DocTabTalk incorporates two key technological innovations: AlignLLaMA and
TabTalk, which are specifically tailored to assist GPT-4 in tackling DocTabQA,
enabling it to generate well-structured, hierarchical tables with improved
organization and clarity. Comprehensive experimental evaluations conducted on
both QTabA and RotoWire datasets demonstrate that our DocTabTalk significantly
enhances the performances of the GPT-4 in our proposed DocTabQA task and the
table generation task. The code and dataset are available at
https://github.com/SmileWHC/DocTabQA for further research.

摘要：<paragraph>我們研究了一個新的問題設定，即問答（QA），稱為 DocTabQA。在此設定中，給定一個長文檔，目標是通過將答案組織成直接從文檔內容中得出的結構化表格來回答問題。與傳統的 QA 方法不同，傳統的 QA 方法主要依賴非結構化文本來制定回應，而 DocTabQA 旨在利用結構化表格作為答案來清晰系統地傳達信息，從而增強用戶理解並突出數據點之間的關係。據我們所知，這個問題以前沒有被探索過。在本文中，我們介紹了 QTabA 數據集，其中包含 300 份財務文件，並附有手動註釋的 1.5k 個問題表對。最初，我們利用大型語言模型 (LLM)，例如 GPT-4 來建立基準。然而，人們普遍認為，LLM 在從長輸入序列生成複雜的結構化輸出時會遇到困難。為了克服這些挑戰，我們提出了稱為 DocTabTalk 的兩階段框架，該框架最初從廣泛的文檔中檢索相關句子，然後根據這些已識別的句子生成分層表格。DocTabTalk 結合了兩項關鍵技術創新：AlignLLaMA 和 TabTalk，它們專門定制為協助 GPT-4 處理 DocTabQA，使其能夠生成結構良好、分層清晰且組織性更強的表格。在 QTabA 和 RotoWire 數據集上進行的綜合實驗評估表明，我們的 DocTabTalk 在我們提出的 DocTabQA 任務和表格生成任務中顯著提升了 GPT-4 的性能。代碼和數據集可在 https://github.com/SmileWHC/DocTabQA 上獲得，以供進一步研究。</paragraph>

##### **The Self-Contained Negation Test Set**
2408.11469v1 by David Kletz, Pascal Amsili, Marie Candito

Several methodologies have recently been proposed to evaluate the ability of
Pretrained Language Models (PLMs) to interpret negation. In this article, we
build on Gubelmann and Handschuh (2022), which studies the modification of
PLMs' predictions as a function of the polarity of inputs, in English.
Crucially, this test uses ``self-contained'' inputs ending with a masked
position: depending on the polarity of a verb in the input, a particular token
is either semantically ruled out or allowed at the masked position. By
replicating Gubelmann and Handschuh (2022) experiments, we have uncovered flaws
that weaken the conclusions that can be drawn from this test. We thus propose
an improved version, the Self-Contained Neg Test, which is more controlled,
more systematic, and entirely based on examples forming minimal pairs varying
only in the presence or absence of verbal negation in English. When applying
our test to the roberta and bert base and large models, we show that only
roberta-large shows trends that match the expectations, while bert-base is
mostly insensitive to negation. For all the tested models though, in a
significant number of test instances the top-1 prediction remains the token
that is semantically forbidden by the context, which shows how much room for
improvement remains for a proper treatment of the negation phenomenon.

摘要：最近已提出几种方法来评估预训练语言模型 (PLM) 解释否定的能力。在本文中，我们基于 Gubelmann 和 Handschuh (2022) 的研究，研究了 PLM 预测因输入极性的函数而修改的情况，以英语为例。至关重要的是，此测试使用以掩码位置结尾的“自包含”输入：根据输入中动词的极性，特定标记在掩码位置要么在语义上被排除，要么被允许。通过复制 Gubelmann 和 Handschuh (2022) 的实验，我们发现了削弱了由此测试得出的结论的缺陷。因此，我们提出了一个改进版本，即自包含否定测试，它更受控、更系统，并且完全基于仅在英语中是否存在否定动词而不同的最小对示例。当将我们的测试应用于 roberta 和 bert 基础和大模型时，我们发现只有 roberta-large 显示出符合预期的趋势，而 bert-base 则对否定大多不敏感。然而，对于所有经过测试的模型，在大量的测试实例中，排名前 1 的预测仍然是语义上被上下文禁止的标记，这表明在对否定现象进行适当处理方面还有很大的改进空间。

##### **Expanding FLORES+ Benchmark for more Low-Resource Settings: Portuguese-Emakhuwa Machine Translation Evaluation**
2408.11457v1 by Felermino D. M. Antonio Ali, Henrique Lopes Cardoso, Rui Sousa-Silva

As part of the Open Language Data Initiative shared tasks, we have expanded
the FLORES+ evaluation set to include Emakhuwa, a low-resource language widely
spoken in Mozambique. We translated the dev and devtest sets from Portuguese
into Emakhuwa, and we detail the translation process and quality assurance
measures used. Our methodology involved various quality checks, including
post-editing and adequacy assessments. The resulting datasets consist of
multiple reference sentences for each source. We present baseline results from
training a Neural Machine Translation system and fine-tuning existing
multilingual translation models. Our findings suggest that spelling
inconsistencies remain a challenge in Emakhuwa. Additionally, the baseline
models underperformed on this evaluation set, underscoring the necessity for
further research to enhance machine translation quality for Emakhuwa. The data
is publicly available at https://huggingface.co/datasets/LIACC/Emakhuwa-FLORES.

摘要：作為開放語言資料計畫共享任務的一部分，我們已擴展 FLORES+ 評估集，以納入在莫三比克廣泛使用的低資源語言 Emakhuwa。我們將 dev 和 devtest 集從葡萄牙語翻譯成 Emakhuwa，並詳細說明翻譯過程和使用的品質保證措施。我們的做法涉及各種品質檢查，包括後編輯和適足性評估。產生的資料集包含每個來源的多個參考句子。我們展示了訓練神經機器翻譯系統和微調現有之多語言翻譯模型的基準結果。我們的研究結果表明，拼寫不一致仍然是 Emakhuwa 的一項挑戰。此外，基準模型在此評估集中的表現不佳，強調進一步研究以提升 Emakhuwa 的機器翻譯品質的必要性。資料可於 https://huggingface.co/datasets/LIACC/Emakhuwa-FLORES 公開取得。

##### **Using Part-based Representations for Explainable Deep Reinforcement Learning**
2408.11455v1 by Manos Kirtas, Konstantinos Tsampazis, Loukia Avramelou, Nikolaos Passalis, Nikolaos Passalis

Utilizing deep learning models to learn part-based representations holds
significant potential for interpretable-by-design approaches, as these models
incorporate latent causes obtained from feature representations through simple
addition. However, training a part-based learning model presents challenges,
particularly in enforcing non-negative constraints on the model's parameters,
which can result in training difficulties such as instability and convergence
issues. Moreover, applying such approaches in Deep Reinforcement Learning (RL)
is even more demanding due to the inherent instabilities that impact many
optimization methods. In this paper, we propose a non-negative training
approach for actor models in RL, enabling the extraction of part-based
representations that enhance interpretability while adhering to non-negative
constraints. To this end, we employ a non-negative initialization technique, as
well as a modified sign-preserving training method, which can ensure better
gradient flow compared to existing approaches. We demonstrate the effectiveness
of the proposed approach using the well-known Cartpole benchmark.

摘要：利用深度學習模型來學習基於部分的表示，對於可解釋的設計方法具有顯著的潛力，因為這些模型透過簡單的加法將從特徵表示中獲得的潛在原因納入其中。然而，訓練一個基於部分的學習模型會產生挑戰，特別是在對模型參數強制非負約束時，這可能會導致訓練困難，例如不穩定性和收斂問題。此外，由於影響許多最佳化方法的固有不穩定性，在深度強化學習 (RL) 中應用這種方法甚至更具挑戰性。在本文中，我們提出了一種針對 RL 中的動作模型的非負訓練方法，可以提取基於部分的表示，在遵守非負約束的同時增強可解釋性。為此，我們採用非負初始化技術，以及一種經過修改的符號保持訓練方法，與現有方法相比，它可以確保更好的梯度流。我們使用著名的 Cartpole 基準展示了所提出的方法的有效性。

##### **Bidirectional Gated Mamba for Sequential Recommendation**
2408.11451v1 by Ziwei Liu, Qidong Liu, Yejing Wang, Wanyu Wang, Pengyue Jia, Maolin Wang, Zitao Liu, Yi Chang, Xiangyu Zhao

In various domains, Sequential Recommender Systems (SRS) have become
essential due to their superior capability to discern intricate user
preferences. Typically, SRS utilize transformer-based architectures to forecast
the subsequent item within a sequence. Nevertheless, the quadratic
computational complexity inherent in these models often leads to
inefficiencies, hindering the achievement of real-time recommendations. Mamba,
a recent advancement, has exhibited exceptional performance in time series
prediction, significantly enhancing both efficiency and accuracy. However,
integrating Mamba directly into SRS poses several challenges. Its inherently
unidirectional nature may constrain the model's capacity to capture the full
context of user-item interactions, while its instability in state estimation
can compromise its ability to detect short-term patterns within interaction
sequences.
  To overcome these issues, we introduce a new framework named
\textbf{\underline{S}}elect\textbf{\underline{I}}ve \textbf{\underline{G}}ated
\textbf{\underline{MA}}mba (SIGMA). This framework leverages a Partially
Flipped Mamba (PF-Mamba) to construct a bidirectional architecture specifically
tailored to improve contextual modeling. Additionally, an input-sensitive Dense
Selective Gate (DS Gate) is employed to optimize directional weights and
enhance the processing of sequential information in PF-Mamba. For short
sequence modeling, we have also developed a Feature Extract GRU (FE-GRU) to
efficiently capture short-term dependencies. Empirical results indicate that
SIGMA outperforms current models on five real-world datasets. Our
implementation code is available at \url{https://github.com/ziwliu-cityu/SIMGA}
to ease reproducibility.

摘要：<paragraph>在各個領域中，序列推薦系統 (SRS) 已因其辨別複雜使用者偏好的卓越能力而變得至關重要。通常，SRS 利用基於轉換器的架構來預測序列中的後續項目。然而，這些模型中固有的二次計算複雜度通常會導致效率低下，阻礙即時推薦的實現。Mamba 是一項最近的進展，在時間序列預測中表現出色的效能，顯著提升了效率和準確度。然而，將 Mamba 直接整合到 SRS 中會產生一些挑戰。其固有的單向性質可能會限制模型擷取使用者項目互動的完整脈絡的能力，而其在狀態估計中的不穩定性可能會損害其偵測互動序列中短期模式的能力。
為了克服這些問題，我們引入了名為\textbf{\underline{S}}elect\textbf{\underline{I}}ve \textbf{\underline{G}}ated \textbf{\underline{MA}}mba (SIGMA) 的新架構。此架構利用局部翻轉 Mamba (PF-Mamba) 來建構專門針對改善脈絡建模的雙向架構。此外，採用輸入敏感的密集選擇閘 (DS Gate) 來最佳化方向權重，並增強 PF-Mamba 中序列資訊的處理。對於短序列建模，我們還開發了特徵萃取 GRU (FE-GRU) 來有效擷取短期依賴關係。經驗結果表明，SIGMA 在五個真實世界資料集上優於目前的模型。我們的實作程式碼可在 \url{https://github.com/ziwliu-cityu/SIMGA} 取得，以利於重現性。</paragraph>

##### **Enabling Small Models for Zero-Shot Classification through Model Label Learning**
2408.11449v1 by Jia Zhang, Zhi Zhou, Lan-Zhe Guo, Yu-Feng Li

Vision-language models (VLMs) like CLIP have demonstrated impressive
zero-shot ability in image classification tasks by aligning text and images but
suffer inferior performance compared with task-specific expert models. On the
contrary, expert models excel in their specialized domains but lack zero-shot
ability for new tasks. How to obtain both the high performance of expert models
and zero-shot ability is an important research direction. In this paper, we
attempt to demonstrate that by constructing a model hub and aligning models
with their functionalities using model labels, new tasks can be solved in a
zero-shot manner by effectively selecting and reusing models in the hub. We
introduce a novel paradigm, Model Label Learning (MLL), which bridges the gap
between models and their functionalities through a Semantic Directed Acyclic
Graph (SDAG) and leverages an algorithm, Classification Head Combination
Optimization (CHCO), to select capable models for new tasks. Compared with the
foundation model paradigm, it is less costly and more scalable, i.e., the
zero-shot ability grows with the sizes of the model hub. Experiments on seven
real-world datasets validate the effectiveness and efficiency of MLL,
demonstrating that expert models can be effectively reused for zero-shot tasks.
Our code will be released publicly.

摘要：視覺語言模型（VLM），例如 CLIP，已在影像分類任務中展現令人印象深刻的零次學習能力，方法是對齊文字和影像，但與特定任務的專家模型相比，其效能較差。相反地，專家模型在其專業領域中表現出色，但對於新任務缺乏零次學習能力。如何同時獲得專家模型的高效能和零次學習能力，是一個重要的研究方向。在本文中，我們嘗試透過建立模型中心，並使用模型標籤將模型與其功能對齊，證明可以透過有效選擇和重複使用中心中的模型，以零次學習的方式解決新任務。我們提出了一種新的範例，即模型標籤學習（MLL），它透過語義導向非循環圖（SDAG）彌合模型及其功能之間的差距，並利用一種演算法，即分類頭組合最佳化（CHCO），為新任務選擇有能力的模型。與基礎模型範例相比，它的成本較低且更具可擴充性，也就是說，零次學習能力會隨著模型中心規模的擴大而增長。在七個真實世界資料集上的實驗驗證了 MLL 的有效性和效率，證明了專家模型可以有效地重複用於零次學習任務。我們的程式碼將公開發布。

##### **Lookism: The overlooked bias in computer vision**
2408.11448v1 by Aditya Gulati, Bruno Lepri, Nuria Oliver

In recent years, there have been significant advancements in computer vision
which have led to the widespread deployment of image recognition and generation
systems in socially relevant applications, from hiring to security screening.
However, the prevalence of biases within these systems has raised significant
ethical and social concerns. The most extensively studied biases in this
context are related to gender, race and age. Yet, other biases are equally
pervasive and harmful, such as lookism, i.e., the preferential treatment of
individuals based on their physical appearance. Lookism remains under-explored
in computer vision but can have profound implications not only by perpetuating
harmful societal stereotypes but also by undermining the fairness and
inclusivity of AI technologies. Thus, this paper advocates for the systematic
study of lookism as a critical bias in computer vision models. Through a
comprehensive review of existing literature, we identify three areas of
intersection between lookism and computer vision. We illustrate them by means
of examples and a user study. We call for an interdisciplinary approach to
address lookism, urging researchers, developers, and policymakers to prioritize
the development of equitable computer vision systems that respect and reflect
the diversity of human appearances.

摘要：近年来，计算机视觉领域取得了重大进展，这导致了图像识别和生成系统在社会相关应用中的广泛部署，从招聘到安全筛查。然而，这些系统中存在的偏见盛行引发了重大的伦理和社会问题。在此背景下研究最广泛的偏见与性别、种族和年龄有关。然而，其他偏见同样普遍且有害，例如外貌主义，即根据个人的外貌给予优待。外貌主义在计算机视觉领域仍未得到充分探索，但不仅会通过延续有害的社会刻板印象，还会破坏人工智能技术的公平性和包容性，从而产生深远的影响。因此，本文主张系统地研究外貌主义作为计算机视觉模型中的关键偏见。通过对现有文献进行全面审查，我们确定了外貌主义与计算机视觉之间的三个交叉领域。我们通过示例和用户研究对它们进行了说明。我们呼吁采用跨学科方法来解决外貌主义问题，敦促研究人员、开发人员和政策制定者优先考虑开发公平的计算机视觉系统，尊重和反映人类外貌的多样性。

##### **Distributional Properties of Subword Regularization**
2408.11443v1 by Marco Cognetta, Vilém Zouhar, Naoaki Okazaki

Subword regularization, used widely in NLP, improves model performance by
reducing the dependency on exact tokenizations, augmenting the training corpus,
and exposing the model to more unique contexts during training. BPE and
MaxMatch, two popular subword tokenization schemes, have stochastic dropout
regularization variants. However, there has not been an analysis of the
distributions formed by them. We show that these stochastic variants are
heavily biased towards a small set of tokenizations per word. If the benefits
of subword regularization are as mentioned, we hypothesize that biasedness
artificially limits the effectiveness of these schemes. Thus, we propose an
algorithm to uniformly sample tokenizations that we use as a drop-in
replacement for the stochastic aspects of existing tokenizers, and find that it
improves machine translation quality.

摘要：子詞正規化廣泛用於 NLP，透過減少對精確分詞的依賴性、擴充訓練語料庫以及在訓練期間讓模型接觸更多獨特語境，來提升模型效能。BPE 和 MaxMatch 兩個熱門的子詞分詞架構，都有隨機中斷正規化的變體。然而，尚未針對它們形成的分配進行分析。我們顯示這些隨機變體嚴重偏向每個字詞的一小組分詞。如果子詞正規化的優點如所述，我們假設偏見會人為地限制這些架構的效能。因此，我們提出一個演算法來均勻取樣分詞，並將之用作現有分詞器的隨機面向的替代方案，發現它能提升機器翻譯品質。

##### **LAHAJA: A Robust Multi-accent Benchmark for Evaluating Hindi ASR Systems**
2408.11440v1 by Tahir Javed, Janki Nawale, Sakshi Joshi, Eldho George, Kaushal Bhogale, Deovrat Mehendale, Mitesh M. Khapra

Hindi, one of the most spoken language of India, exhibits a diverse array of
accents due to its usage among individuals from diverse linguistic origins. To
enable a robust evaluation of Hindi ASR systems on multiple accents, we create
a benchmark, LAHAJA, which contains read and extempore speech on a diverse set
of topics and use cases, with a total of 12.5 hours of Hindi audio, sourced
from 132 speakers spanning 83 districts of India. We evaluate existing
open-source and commercial models on LAHAJA and find their performance to be
poor. We then train models using different datasets and find that our model
trained on multilingual data with good speaker diversity outperforms existing
models by a significant margin. We also present a fine-grained analysis which
shows that the performance declines for speakers from North-East and South
India, especially with content heavy in named entities and specialized
terminology.

摘要：印地語是印度最廣泛使用的語言之一，由於使用印地語的人來自不同的語言背景，因此呈現出多種口音。為了對多種口音的印地語 ASR 系統進行穩健的評估，我們建立了一個基準 LAHAJA，其中包含各種主題和使用案例的朗讀和即興演講，總計 12.5 小時的印地語音訊，來自印度 83 個地區的 132 位講者。我們在 LAHAJA 上評估現有的開源和商業模型，發現它們的表現不佳。然後我們使用不同的資料集訓練模型，發現我們在具有良好講者多樣性的多語言資料上訓練的模型比現有模型的表現高出顯著的幅度。我們還提出了一個細粒度的分析，顯示來自印度東北部和南部的講者的表現下降，特別是在內容中包含大量專有名詞和專業術語的情況下。

##### **Towards Aligned Data Removal via Twin Machine Unlearning**
2408.11433v1 by Yuyao Sun, Zhenxing Niu, Gang hua, Rong jin

Modern privacy regulations have spurred the evolution of machine unlearning,
a technique that enables the removal of data from an already trained ML model
without requiring retraining from scratch. Previous unlearning methods tend to
induce the model to achieve lowest classification accuracy on the removal data.
Nonetheless, the authentic objective of machine unlearning is to align the
unlearned model with the gold model, i.e., achieving the same classification
accuracy as the gold model. For this purpose, we present a Twin Machine
Unlearning (TMU) approach, where a twin unlearning problem is defined
corresponding to the original unlearning problem. As a results, the
generalization-label predictor trained on the twin problem can be transferred
to the original problem, facilitating aligned data removal. Comprehensive
empirical experiments illustrate that our approach significantly enhances the
alignment between the unlearned model and the gold model. Meanwhile, our method
allows data removal without compromising the model accuracy.

摘要：現代隱私法規促進了機器去學習的演進，
這是一種技術，可以在不需從頭開始重新訓練的情況下，
從已訓練好的 ML 模型中移除資料。先前的去學習方法傾向於
誘使模型對移除的資料達成最低的分類準確度。
儘管如此，機器去學習的真實目標是將
去學習的模型與黃金模型對齊，亦即達成與黃金模型相同的分類
準確度。為了這個目的，我們提出一個雙機器去學習 (TMU) 方法，
其中定義了一個雙去學習問題，對應到原始的去學習問題。結果是，
在雙重問題上訓練的概化標籤預測器可以轉移到原始問題上，
促進對齊的資料移除。全面的經驗實驗說明我們的做法顯著地加強了
去學習模型和黃金模型之間的對齊。同時，我們的做法
允許資料移除而不影響模型準確度。

##### **Diagnosing and Remedying Knowledge Deficiencies in LLMs via Label-free Curricular Meaningful Learning**
2408.11431v1 by Kai Xiong, Xiao Ding, Li Du, Jiahao Ying, Ting Liu, Bing Qin, Yixin Cao

Large Language Models (LLMs) are versatile and demonstrate impressive
generalization ability by mining and learning information from extensive
unlabeled text. However, they still exhibit reasoning mistakes, often stemming
from knowledge deficiencies, which can affect their trustworthiness and
reliability. Although users can provide diverse and comprehensive queries,
obtaining sufficient and effective feedback is demanding. Furthermore,
evaluating LLMs comprehensively with limited labeled samples is difficult. This
makes it a challenge to diagnose and remedy the deficiencies of LLMs through
rich label-free user queries. To tackle this challenge, we propose a label-free
curricular meaningful learning framework (LaMer). LaMer first employs relative
entropy to automatically diagnose and quantify the knowledge deficiencies of
LLMs in a label-free setting. Next, to remedy the diagnosed knowledge
deficiencies, we apply curricular meaningful learning: first, we adopt
meaningful learning to adaptively synthesize augmentation data according to the
severity of the deficiencies, and then design a curricular deficiency remedy
strategy to remedy the knowledge deficiencies of LLMs progressively.
Experiments show that LaMer efficiently and effectively diagnoses and remedies
knowledge deficiencies in LLMs, improving various LLMs across seven
out-of-distribution (OOD) reasoning and language understanding benchmarks,
achieving comparable results to baselines with just 40\% training data. LaMer
even surpasses methods that rely on labeled datasets for deficiency diagnosis.
In application, our label-free method can offer an effective knowledge
deficiency diagnostic tool for efficient LLM development.

摘要：大型語言模型 (LLM) 具有多功能性，並且透過挖掘和學習大量未標記文字中的資訊，展現出令人印象深刻的概括能力。然而，它們仍然會出現推理錯誤，通常源於知識不足，這可能會影響它們的信賴度和可靠性。儘管使用者可以提供多元且全面的查詢，但取得充足且有效的回饋卻很困難。此外，使用有限的標籤範例全面評估 LLM 也很困難。這使得透過豐富的無標籤使用者查詢來診斷和補救 LLM 的缺陷成為一項挑戰。為了應對此挑戰，我們提出了一個無標籤課程有意義學習架構 (LaMer)。LaMer 首先採用相對熵在無標籤設定中自動診斷和量化 LLM 的知識缺陷。接下來，為了補救診斷出的知識缺陷，我們應用課程有意義學習：首先，我們採用有意義的學習來根據缺陷的嚴重性自適應地合成擴充資料，然後設計一個課程缺陷補救策略來逐步補救 LLM 的知識缺陷。實驗表明，LaMer 有效地診斷和補救了 LLM 中的知識缺陷，改進了七種分佈外 (OOD) 推理和語言理解基準中的各種 LLM，僅使用 40% 的訓練資料就達到了與基線相當的結果。LaMer 甚至超越了依賴標籤資料集進行缺陷診斷的方法。在應用中，我們的無標籤方法可以為高效的 LLM 開發提供一個有效的知識缺陷診斷工具。

##### **Towards "Differential AI Psychology" and in-context Value-driven Statement Alignment with Moral Foundations Theory**
2408.11415v1 by Simon Münker

Contemporary research in social sciences is increasingly utilizing
state-of-the-art statistical language models to annotate or generate content.
While these models perform benchmark-leading on common language tasks and show
exemplary task-independent emergent abilities, transferring them to novel
out-of-domain tasks is only insufficiently explored. The implications of the
statistical black-box approach - stochastic parrots - are prominently
criticized in the language model research community; however, the significance
for novel generative tasks is not.
  This work investigates the alignment between personalized language models and
survey participants on a Moral Foundation Theory questionnaire. We adapt
text-to-text models to different political personas and survey the
questionnaire repetitively to generate a synthetic population of persona and
model combinations. Analyzing the intra-group variance and cross-alignment
shows significant differences across models and personas. Our findings indicate
that adapted models struggle to represent the survey-captured assessment of
political ideologies. Thus, using language models to mimic social interactions
requires measurable improvements in in-context optimization or parameter
manipulation to align with psychological and sociological stereotypes. Without
quantifiable alignment, generating politically nuanced content remains
unfeasible. To enhance these representations, we propose a testable framework
to generate agents based on moral value statements for future research.

摘要：當代社會科學研究正日益利用最先進的統計語言模型來註解或產生內容。雖然這些模型在常見語言任務中表現出領先的基準，並展現出示範性的與任務無關的浮現能力，但將它們轉移到新的領域外任務中卻只被不足地探索。統計黑箱方法（隨機鸚鵡）的含義在語言模型研究社群中受到顯著批評；然而，對於新的生成任務的意義卻不然。這項工作探討了個人化語言模型與道德基礎理論問卷中的調查參與者之間的對齊。我們將文字轉文字模型調整為不同的政治角色，並重複調查問卷以產生一個由角色和模型組合而成的合成族群。分析群內變異和交叉對齊顯示出模型和角色之間有顯著的差異。我們的研究結果表明，調整後的模型難以代表政治意識形態的調查捕捉評估。因此，使用語言模型來模擬社會互動需要在情境優化或參數操作中進行可衡量的改進，以與心理和社會學的刻板印象保持一致。在沒有可量化對齊的情況下，產生政治微妙的內容仍然不可行。為了增強這些表徵，我們提出了一個可測試的框架，以根據道德價值陳述為基礎生成代理，供未來的研究使用。

##### **MoE-LPR: Multilingual Extension of Large Language Models through Mixture-of-Experts with Language Priors Routing**
2408.11396v1 by Hao Zhou, Zhijun Wang, Shujian Huang, Xin Huang, Xue Han, Junlan Feng, Chao Deng, Weihua Luo, Jiajun Chen

Large Language Models (LLMs) are often English-centric due to the
disproportionate distribution of languages in their pre-training data.
Enhancing non-English language capabilities through post-pretraining often
results in catastrophic forgetting of the ability of original languages.
Previous methods either achieve good expansion with severe forgetting or slight
forgetting with poor expansion, indicating the challenge of balancing language
expansion while preventing forgetting. In this paper, we propose a method
called MoE-LPR (Mixture-of-Experts with Language Priors Routing) to alleviate
this problem. MoE-LPR employs a two-stage training approach to enhance the
multilingual capability. First, the model is post-pretrained into a
Mixture-of-Experts (MoE) architecture by upcycling, where all the original
parameters are frozen and new experts are added. In this stage, we focus
improving the ability on expanded languages, without using any original
language data. Then, the model reviews the knowledge of the original languages
with replay data amounting to less than 1% of post-pretraining, where we
incorporate language priors routing to better recover the abilities of the
original languages. Evaluations on multiple benchmarks show that MoE-LPR
outperforms other post-pretraining methods. Freezing original parameters
preserves original language knowledge while adding new experts preserves the
learning ability. Reviewing with LPR enables effective utilization of
multilingual knowledge within the parameters. Additionally, the MoE
architecture maintains the same inference overhead while increasing total model
parameters. Extensive experiments demonstrate MoE-LPR's effectiveness in
improving expanded languages and preserving original language proficiency with
superior scalability. Code and scripts are freely available at
https://github.com/zjwang21/MoE-LPR.git.

摘要：大型語言模型（LLM）通常以英語為中心，因為在預訓練資料中語言分佈不均衡。透過後預訓練增強非英語語言能力通常會導致原本語言能力的災難性遺忘。先前的做法不是達到良好的擴充，但有嚴重的遺忘，就是遺忘輕微但擴充不良，這表示在防止遺忘的同時平衡語言擴充的挑戰。在本文中，我們提出一個稱為 MoE-LPR（混合專家與語言先驗路由）的方法來減輕這個問題。MoE-LPR 採用兩階段的訓練方法來增強多語言能力。首先，模型透過升級後預訓練成混合專家（MoE）架構，其中所有原本的參數都會凍結，並加入新的專家。在這個階段，我們專注於提升擴充語言的能力，而不使用任何原本的語言資料。接著，模型會檢視原本語言的知識，並使用少於 1% 後預訓練的重播資料，其中我們納入語言先驗路由，以便更好地恢復原本語言的能力。在多個基準上的評估顯示，MoE-LPR 的表現優於其他後預訓練方法。凍結原本的參數可以保留原本的語言知識，同時加入新的專家可以保留學習能力。使用 LPR 檢視可以有效利用參數中的多語言知識。此外，MoE 架構在增加總模型參數的同時，維持相同的推論開銷。廣泛的實驗證明了 MoE-LPR 在提升擴充語言和保留原本語言能力方面的效能，並具有優異的可擴充性。程式碼和指令碼可於 https://github.com/zjwang21/MoE-LPR.git 免費取得。

##### **First Activations Matter: Training-Free Methods for Dynamic Activation in Large Language Models**
2408.11393v1 by Chi Ma, Mincong Huang, Ying Zhang, Chao Wang, Yujie Wang, Lei Yu, Chuan Liu, Wei Lin

Dynamic activation (DA) techniques, such as DejaVu and MoEfication, have
demonstrated their potential to significantly enhance the inference efficiency
of large language models (LLMs). However, these techniques often rely on ReLU
activation functions or require additional parameters and training to maintain
performance. This paper introduces a training-free Threshold-based Dynamic
Activation(TDA) method that leverage sequence information to exploit the
inherent sparsity of models across various architectures. This method is
designed to accelerate generation speed by 18-25\% without significantly
compromising task performance, thereby addressing the limitations of existing
DA techniques. Moreover, we delve into the root causes of LLM sparsity and
theoretically analyze two of its critical features: history-related activation
uncertainty and semantic-irrelevant activation inertia. Our comprehensive
analyses not only provide a robust theoretical foundation for DA methods but
also offer valuable insights to guide future research in optimizing LLMs for
greater efficiency and effectiveness.

摘要：動態激活 (DA) 技術，例如 DejaVu 和 MoEfication，已證明其大幅提升大型語言模型 (LLM) 推論效率的潛力。然而，這些技術通常依賴於 ReLU 激活函數或需要額外的參數和訓練來維持效能。本文介紹了一種無需訓練的基於閾值的動態激活 (TDA) 方法，它利用序列資訊來利用各種架構中模型固有的稀疏性。此方法旨在將產生速度提升 18-25%，同時不顯著損害任務效能，從而解決現有 DA 技術的限制。此外，我們深入探討了 LLM 稀疏性的根本原因，並從理論上分析了其兩個關鍵特徵：與歷史相關的激活不確定性和與語義無關的激活慣性。我們全面的分析不僅為 DA 方法提供了穩健的理論基礎，還提供了寶貴的見解，以指導未來優化 LLM 以提高效率和效能的研究。

##### **Data-Centric Machine Learning for Earth Observation: Necessary and Sufficient Features**
2408.11384v1 by Hiba Najjar, Marlon Nuske, Andreas Dengel

The availability of temporal geospatial data in multiple modalities has been
extensively leveraged to enhance the performance of machine learning models.
While efforts on the design of adequate model architectures are approaching a
level of saturation, focusing on a data-centric perspective can complement
these efforts to achieve further enhancements in data usage efficiency and
model generalization capacities. This work contributes to this direction. We
leverage model explanation methods to identify the features crucial for the
model to reach optimal performance and the smallest set of features sufficient
to achieve this performance. We evaluate our approach on three temporal
multimodal geospatial datasets and compare multiple model explanation
techniques. Our results reveal that some datasets can reach their optimal
accuracy with less than 20% of the temporal instances, while in other datasets,
the time series of a single band from a single modality is sufficient.

摘要：時空地理空間資料在多重模式下的可取得性已被廣泛運用於提升機器學習模型的效能。
儘管在適當模型架構的設計上所做的努力已接近飽和的程度，但專注於以資料為中心的觀點可以補充這些努力，以進一步提升資料使用效率和模型概化能力。這項工作有助於此方向。我們運用模型解釋方法來找出對於模型達到最佳效能至關重要的特徵，以及足以達成此效能的最小特徵集。我們在三個時序多模式時空地理空間資料集上評估我們的做法，並比較多種模型解釋技巧。我們的結果顯示，有些資料集可以用不到 20% 的時序實例達到最佳準確度，而在其他資料集中，單一模式中單一頻段的時間序列就已足夠。

##### **On the Interchangeability of Positional Embeddings in Multilingual Neural Machine Translation Models**
2408.11382v1 by Varun Gumma, Pranjal A. Chitale, Kalika Bali

Standard Neural Machine Translation (NMT) models have traditionally been
trained with Sinusoidal Positional Embeddings (PEs), which are inadequate for
capturing long-range dependencies and are inefficient for long-context or
document-level translation. In contrast, state-of-the-art large language models
(LLMs) employ relative PEs, demonstrating superior length generalization. This
work explores the potential for efficiently switching the Positional Embeddings
of pre-trained NMT models from absolute sinusoidal PEs to relative approaches
such as RoPE and ALiBi. Our findings reveal that sinusoidal PEs can be
effectively replaced with RoPE and ALiBi with negligible or no performance
loss, achieved by fine-tuning on a small fraction of high-quality data.
Additionally, models trained without Positional Embeddings (NoPE) are not a
viable solution for Encoder-Decoder architectures, as they consistently
under-perform compared to models utilizing any form of Positional Embedding.
Furthermore, even a model trained from scratch with these relative PEs slightly
under-performs a fine-tuned model, underscoring the efficiency and validity of
our hypothesis.

摘要：標準神經機器翻譯 (NMT) 模型傳統上使用正弦位置嵌入 (PE) 進行訓練，這對於捕捉長距離依賴性是不夠的，並且對於長文或文件級別的翻譯效率低下。相比之下，最先進的大語言模型 (LLM) 使用相對 PE，展示了優越的長度泛化。這項工作探討了有效切換預訓練 NMT 模型的位置嵌入的可能性，從絕對正弦 PE 轉換為相對方法，例如 RoPE 和 ALiBi。我們的研究結果表明，正弦 PE 可以有效地用 RoPE 和 ALiBi 替換，而幾乎不會或不會造成效能損失，這可透過微調一小部分高品質資料來實現。此外，沒有位置嵌入 (NoPE) 訓練的模型並非編碼器-解碼器架構的可行解決方案，因為與使用任何形式的位置嵌入的模型相比，它們始終表現不佳。此外，即使從頭開始使用這些相對 PE 訓練的模型，其效能也略低於微調模型，這強調了我們假設的效率和有效性。

##### **RAGLAB: A Modular and Research-Oriented Unified Framework for Retrieval-Augmented Generation**
2408.11381v1 by Xuanwang Zhang, Yunze Song, Yidong Wang, Shuyun Tang, Xinfeng Li, Zhengran Zeng, Zhen Wu, Wei Ye, Wenyuan Xu, Yue Zhang, Xinyu Dai, Shikun Zhang, Qingsong Wen

Large Language Models (LLMs) demonstrate human-level capabilities in
dialogue, reasoning, and knowledge retention. However, even the most advanced
LLMs face challenges such as hallucinations and real-time updating of their
knowledge. Current research addresses this bottleneck by equipping LLMs with
external knowledge, a technique known as Retrieval Augmented Generation (RAG).
However, two key issues constrained the development of RAG. First, there is a
growing lack of comprehensive and fair comparisons between novel RAG
algorithms. Second, open-source tools such as LlamaIndex and LangChain employ
high-level abstractions, which results in a lack of transparency and limits the
ability to develop novel algorithms and evaluation metrics. To close this gap,
we introduce RAGLAB, a modular and research-oriented open-source library.
RAGLAB reproduces 6 existing algorithms and provides a comprehensive ecosystem
for investigating RAG algorithms. Leveraging RAGLAB, we conduct a fair
comparison of 6 RAG algorithms across 10 benchmarks. With RAGLAB, researchers
can efficiently compare the performance of various algorithms and develop novel
algorithms.

摘要：大型語言模型 (LLM) 在對話、推理和知識保留方面展現出人類等級的能力。然而，即使是最先進的 LLM 也會面臨幻覺和其知識的即時更新等挑戰。目前的研究所透過為 LLM 提供外部知識來解決這個瓶頸，這項技術稱為檢索擴增生成 (RAG)。然而，兩個關鍵問題限制了 RAG 的發展。首先，新的 RAG 演算法之間缺乏全面且公平的比較。其次，LlamaIndex 和 LangChain 等開放原始碼工具採用高階抽象，導致缺乏透明度並限制了開發新演算法和評估指標的能力。為了彌補這個差距，我們引入了 RAGLAB，一個模組化且以研究為導向的開放原始碼程式庫。RAGLAB 重現 6 個現有演算法，並提供一個全面的生態系統來研究 RAG 演算法。利用 RAGLAB，我們對 6 個 RAG 演算法在 10 個基準上進行公平的比較。透過 RAGLAB，研究人員可以有效地比較各種演算法的效能，並開發新的演算法。

##### **Reflex-Based Open-Vocabulary Navigation without Prior Knowledge Using Omnidirectional Camera and Multiple Vision-Language Models**
2408.11380v1 by Kento Kawaharazuka, Yoshiki Obinata, Naoaki Kanazawa, Naoto Tsukamoto, Kei Okada, Masayuki Inaba

Various robot navigation methods have been developed, but they are mainly
based on Simultaneous Localization and Mapping (SLAM), reinforcement learning,
etc., which require prior map construction or learning. In this study, we
consider the simplest method that does not require any map construction or
learning, and execute open-vocabulary navigation of robots without any prior
knowledge to do this. We applied an omnidirectional camera and pre-trained
vision-language models to the robot. The omnidirectional camera provides a
uniform view of the surroundings, thus eliminating the need for complicated
exploratory behaviors including trajectory generation. By applying multiple
pre-trained vision-language models to this omnidirectional image and
incorporating reflective behaviors, we show that navigation becomes simple and
does not require any prior setup. Interesting properties and limitations of our
method are discussed based on experiments with the mobile robot Fetch.

摘要：已開發出各種機器人導航方法，但它們主要基於同時定位與建圖 (SLAM)、強化學習等，需要事先建構地圖或學習。在本研究中，我們考慮最簡單的方法，不需要任何地圖建構或學習，並執行機器人的開放式詞彙導航，無需任何先驗知識即可執行此操作。我們將全景相機和預先訓練的視覺語言模型應用於機器人。全景相機提供周圍環境的統一視圖，因此無需複雜的探索行為，包括軌跡生成。通過將多個預先訓練的視覺語言模型應用於此全景圖像並結合反射行為，我們表明導航變得簡單，並且不需要任何先前的設置。根據使用移動機器人 Fetch 進行的實驗，討論了我們方法的有趣特性和限制。

##### **Denoising Pre-Training and Customized Prompt Learning for Efficient Multi-Behavior Sequential Recommendation**
2408.11372v1 by Hao Wang, Yongqiang Han, Kefan Wang, Kai Cheng, Zhen Wang, Wei Guo, Yong Liu, Defu Lian, Enhong Chen

In the realm of recommendation systems, users exhibit a diverse array of
behaviors when interacting with items. This phenomenon has spurred research
into learning the implicit semantic relationships between these behaviors to
enhance recommendation performance. However, these methods often entail high
computational complexity. To address concerns regarding efficiency,
pre-training presents a viable solution. Its objective is to extract knowledge
from extensive pre-training data and fine-tune the model for downstream tasks.
Nevertheless, previous pre-training methods have primarily focused on
single-behavior data, while multi-behavior data contains significant noise.
Additionally, the fully fine-tuning strategy adopted by these methods still
imposes a considerable computational burden. In response to this challenge, we
propose DPCPL, the first pre-training and prompt-tuning paradigm tailored for
Multi-Behavior Sequential Recommendation. Specifically, in the pre-training
stage, we commence by proposing a novel Efficient Behavior Miner (EBM) to
filter out the noise at multiple time scales, thereby facilitating the
comprehension of the contextual semantics of multi-behavior sequences.
Subsequently, we propose to tune the pre-trained model in a highly efficient
manner with the proposed Customized Prompt Learning (CPL) module, which
generates personalized, progressive, and diverse prompts to fully exploit the
potential of the pre-trained model effectively. Extensive experiments on three
real-world datasets have unequivocally demonstrated that DPCPL not only
exhibits high efficiency and effectiveness, requiring minimal parameter
adjustments but also surpasses the state-of-the-art performance across a
diverse range of downstream tasks.

摘要：<paragraph>在推薦系統領域中，使用者在與項目互動時會表現出各種不同的行為。這種現象促使研究人員學習這些行為之間隱含的語義關係，以提升推薦效能。然而，這些方法通常需要很高的運算複雜度。為了解決效率方面的疑慮，預訓練提供了一個可行的解決方案。它的目標是從大量的預訓練資料中萃取出知識，並針對下游任務微調模型。儘管如此，先前的預訓練方法主要集中在單一行為資料上，而多行為資料包含大量的雜訊。此外，這些方法採用的完全微調策略仍然會帶來相當大的運算負擔。為了應對這個挑戰，我們提出 DPCPL，這是第一個針對多行為順序推薦量身打造的預訓練和提示調整範例。特別是在預訓練階段，我們首先提出一個新穎的有效行為挖掘器 (EBM)，以在多個時間尺度中濾除雜訊，從而促進對多行為序列的脈絡語義理解。隨後，我們提出使用所提出的自訂提示學習 (CPL) 模組以高度有效的方式調整預訓練模型，該模組會產生個人化、漸進式和多樣化的提示，以有效地充分發揮預訓練模型的潛力。在三個真實世界資料集上進行的廣泛實驗明確證明，DPCPL 不僅展現出高效率和高效果，需要最少的參數調整，而且在各種下游任務中都超越了最先進的效能。</paragraph>

##### **Solving Decision Theory Problems with Probabilistic Answer Set Programming**
2408.11371v1 by Damiano Azzolini, Elena Bellodi, Rafael Kiesel, Fabrizio Riguzzi

Solving a decision theory problem usually involves finding the actions, among
a set of possible ones, which optimize the expected reward, possibly accounting
for the uncertainty of the environment. In this paper, we introduce the
possibility to encode decision theory problems with Probabilistic Answer Set
Programming under the credal semantics via decision atoms and utility
attributes. To solve the task we propose an algorithm based on three layers of
Algebraic Model Counting, that we test on several synthetic datasets against an
algorithm that adopts answer set enumeration. Empirical results show that our
algorithm can manage non trivial instances of programs in a reasonable amount
of time. Under consideration in Theory and Practice of Logic Programming
(TPLP).

摘要：解決決策理論問題通常涉及在可能的行動中找出那些最佳化預期獎勵的行動，這可能會考慮環境的不確定性。在本文中，我們介紹了透過決策原子和效用屬性在可信語義下使用機率性答案集合規劃編碼決策理論問題的可能性。為了解決此任務，我們提出了一種基於代數模型計數的三層演算法，我們在幾個合成資料集上對其進行了測試，並針對採用答案集合列舉的演算法進行了測試。實證結果表明，我們的演算法可以在合理的時間內管理程式中非平凡的實例。在邏輯程式設計理論與實務 (TPLP) 中考慮中。

##### **Graph Classification via Reference Distribution Learning: Theory and Practice**
2408.11370v1 by Zixiao Wang, Jicong Fan

Graph classification is a challenging problem owing to the difficulty in
quantifying the similarity between graphs or representing graphs as vectors,
though there have been a few methods using graph kernels or graph neural
networks (GNNs). Graph kernels often suffer from computational costs and manual
feature engineering, while GNNs commonly utilize global pooling operations,
risking the loss of structural or semantic information. This work introduces
Graph Reference Distribution Learning (GRDL), an efficient and accurate graph
classification method. GRDL treats each graph's latent node embeddings given by
GNN layers as a discrete distribution, enabling direct classification without
global pooling, based on maximum mean discrepancy to adaptively learned
reference distributions. To fully understand this new model (the existing
theories do not apply) and guide its configuration (e.g., network architecture,
references' sizes, number, and regularization) for practical use, we derive
generalization error bounds for GRDL and verify them numerically. More
importantly, our theoretical and numerical results both show that GRDL has a
stronger generalization ability than GNNs with global pooling operations.
Experiments on moderate-scale and large-scale graph datasets show the
superiority of GRDL over the state-of-the-art, emphasizing its remarkable
efficiency, being at least 10 times faster than leading competitors in both
training and inference stages.

摘要：圖形分類是一個具有挑戰性的問題，原因在於難以量化圖形之間的相似性或將圖形表示為向量，儘管已經有一些使用圖形核或圖形神經網路 (GNN) 的方法。圖形核通常會受到運算成本和手動特徵工程的影響，而 GNN 通常會使用全域池化運算，冒著結構或語義資訊遺失的風險。本研究介紹圖形參考分佈學習 (GRDL)，這是一種有效且準確的圖形分類方法。GRDL 將 GNN 層提供的每個圖形的潛在節點嵌入視為離散分佈，基於最大平均差異，根據適應性學習的參考分佈，進行直接分類，而無需全域池化。為了充分瞭解這個新模型（現有的理論並不適用）並指導其組態（例如，網路架構、參考大小、數量和正則化）以供實際使用，我們推導了 GRDL 的泛化誤差界限，並對其進行數值驗證。更重要的是，我們的理論和數值結果都表明，GRDL 具有比具有全域池化運算的 GNN 更強的泛化能力。在中小型圖形資料集上的實驗顯示，GRDL 優於現有技術，強調其顯著的效率，在訓練和推論階段都比領先的競爭對手快至少 10 倍。

##### **Towards Probabilistic Inductive Logic Programming with Neurosymbolic Inference and Relaxation**
2408.11367v1 by Fieke Hillerstrom, Gertjan Burghouts

Many inductive logic programming (ILP) methods are incapable of learning
programs from probabilistic background knowledge, e.g. coming from sensory data
or neural networks with probabilities. We propose Propper, which handles flawed
and probabilistic background knowledge by extending ILP with a combination of
neurosymbolic inference, a continuous criterion for hypothesis selection (BCE)
and a relaxation of the hypothesis constrainer (NoisyCombo). For relational
patterns in noisy images, Propper can learn programs from as few as 8 examples.
It outperforms binary ILP and statistical models such as a Graph Neural
Network.

摘要：許多歸納邏輯程式設計 (ILP) 方法無法從機率背景知識學習程式，例如來自感測器資料或具有機率的神經網路。我們提出 Propper，它透過將 ILP 與神經符號推理、用於假設選擇的連續準則 (BCE) 和假設約束鬆弛 (NoisyCombo) 的組合來處理有缺陷且機率性的背景知識。對於雜訊影像中的關係模式，Propper 可以從少至 8 個範例學習程式。它優於二元 ILP 和統計模型，例如圖神經網路。

##### **GeoReasoner: Reasoning On Geospatially Grounded Context For Natural Language Understanding**
2408.11366v1 by Yibo Yan, Joey Lee

In human reading and communication, individuals tend to engage in geospatial
reasoning, which involves recognizing geographic entities and making informed
inferences about their interrelationships. To mimic such cognitive process,
current methods either utilize conventional natural language understanding
toolkits, or directly apply models pretrained on geo-related natural language
corpora. However, these methods face two significant challenges: i) they do not
generalize well to unseen geospatial scenarios, and ii) they overlook the
importance of integrating geospatial context from geographical databases with
linguistic information from the Internet. To handle these challenges, we
propose GeoReasoner, a language model capable of reasoning on geospatially
grounded natural language. Specifically, it first leverages Large Language
Models (LLMs) to generate a comprehensive location description based on
linguistic and geospatial information. It also encodes direction and distance
information into spatial embedding via treating them as pseudo-sentences.
Consequently, the model is trained on both anchor-level and neighbor-level
inputs to learn geo-entity representation. Extensive experimental results
demonstrate GeoReasoner's superiority in three tasks: toponym recognition,
toponym linking, and geo-entity typing, compared to the state-of-the-art
baselines.

摘要：在人類的閱讀和溝通中，個人傾向於從事地理空間推理，這涉及識別地理實體並對它們的相互關係做出明智的推論。為了模擬這種認知過程，當前的做法是利用傳統的自然語言理解工具包，或直接應用預先在與地理相關的自然語言語料庫上訓練的模型。然而，這些方法面臨著兩個重大的挑戰：i) 它們無法很好地推廣到未見過的地理空間場景，以及 ii) 它們忽視了將來自地理資料庫的地理空間背景與來自網際網路的語言資訊整合起來的重要性。為了應對這些挑戰，我們提出了 GeoReasoner，這是一個能夠對地理空間基礎自然語言進行推理的語言模型。具體來說，它首先利用大型語言模型 (LLM) 根據語言和地理空間資訊生成全面的位置描述。它還將方向和距離資訊編碼到空間嵌入中，將它們視為偽句子。因此，該模型在錨點級別和鄰居級別的輸入上進行訓練，以學習地理實體表示。大量的實驗結果證明了 GeoReasoner 在三項任務中的優越性：地名識別、地名連結和地理實體類型，與最先進的基準相比。

##### **ProteinGPT: Multimodal LLM for Protein Property Prediction and Structure Understanding**
2408.11363v1 by Yijia Xiao, Edward Sun, Yiqiao Jin, Qifan Wang, Wei Wang

Understanding biological processes, drug development, and biotechnological
advancements requires detailed analysis of protein structures and sequences, a
task in protein research that is inherently complex and time-consuming when
performed manually. To streamline this process, we introduce ProteinGPT, a
state-of-the-art multi-modal protein chat system, that allows users to upload
protein sequences and/or structures for comprehensive protein analysis and
responsive inquiries. ProteinGPT seamlessly integrates protein sequence and
structure encoders with linear projection layers for precise representation
adaptation, coupled with a large language model (LLM) to generate accurate and
contextually relevant responses. To train ProteinGPT, we construct a
large-scale dataset of 132,092 proteins with annotations, and optimize the
instruction-tuning process using GPT-4o. This innovative system ensures
accurate alignment between the user-uploaded data and prompts, simplifying
protein analysis. Experiments show that ProteinGPT can produce promising
responses to proteins and their corresponding questions.

摘要：了解生物過程、藥物開發和生物技術進展，需要詳細分析蛋白質結構和序列，這項蛋白質研究任務在手動執行時本質上很複雜且耗時。為了簡化此流程，我們引入了 ProteinGPT，這是一個最先進的多模式蛋白質聊天系統，允許使用者上傳蛋白質序列和/或結構，以進行全面的蛋白質分析和回應式查詢。ProteinGPT 將蛋白質序列和結構編碼器與線性投影層無縫整合，以進行精確的表示適應，並結合大型語言模型 (LLM) 來產生準確且與上下文相關的回應。為了訓練 ProteinGPT，我們構建了一個包含 132,092 個蛋白質的大規模註解資料集，並使用 GPT-4o 最佳化指令調整流程。這個創新的系統確保使用者上傳的資料和提示之間的準確對齊，簡化了蛋白質分析。實驗表明，ProteinGPT 可以對蛋白質及其對應問題產生有希望的回應。

##### **Hypergraph Learning based Recommender System for Anomaly Detection, Control and Optimization**
2408.11359v1 by Sakhinana Sagar Srinivas, Rajat Kumar Sarkar, Venkataramana Runkana

Anomaly detection is fundamental yet, challenging problem with practical
applications in industry. The current approaches neglect the higher-order
dependencies within the networks of interconnected sensors in the
high-dimensional time series(multisensor data) for anomaly detection. To this
end, we present a self-adapting anomaly detection framework for joint learning
of (a) discrete hypergraph structure and (b) modeling the temporal trends and
spatial relations among the interdependent sensors using the hierarchical
encoder-decoder architecture to overcome the challenges. The hypergraph
representation learning-based framework exploits the relational inductive
biases in the hypergraph-structured data to learn the pointwise
single-step-ahead forecasts through the self-supervised autoregressive task and
predicts the anomalies based on the forecast error. Furthermore, our framework
incentivizes learning the anomaly-diagnosis ontology through a differentiable
approach. It derives the anomaly information propagation-based computational
hypergraphs for root cause analysis and provides recommendations through an
offline, optimal predictive control policy to remedy an anomaly. We conduct
extensive experiments to evaluate the proposed method on the benchmark datasets
for fair and rigorous comparison with the popular baselines. The proposed
method outperforms the baseline models and achieves SOTA performance. We report
the ablation studies to support the efficacy of the framework.

摘要：異常偵測是基礎且具有挑戰性的問題，在產業中具有實際應用。目前的方法忽略了高維時間序列（多感測器資料）中連接感測器網路內的高階依賴性，以進行異常偵測。為此，我們提出一個自適應異常偵測架構，用於聯合學習 (a) 離散超圖結構和 (b) 使用階層式編碼器 - 解碼器架構，在相互依賴的感測器之間對時間趨勢和空間關係進行建模，以克服挑戰。基於超圖表示學習的框架利用超圖結構資料中的關係歸納偏差，透過自我監督的回歸任務學習逐點單步超前預測，並根據預測誤差預測異常。此外，我們的框架透過可微分的途徑，激勵學習異常診斷本體論。它衍生出基於異常資訊傳播的計算超圖，用於根本原因分析，並透過離線最佳預測控制政策提供建議，以補救異常。我們進行廣泛的實驗，在基準資料集上評估所提出的方法，以進行公平且嚴謹的比較，與流行的基準進行比較。所提出的方法優於基準模型，並達到 SOTA 效能。我們報告消融研究，以支持該框架的效能。

##### **One-step Structure Prediction and Screening for Protein-Ligand Complexes using Multi-Task Geometric Deep Learning**
2408.11356v1 by Kelei He, Tiejun Dong, Jinhui Wu, Junfeng Zhang

Understanding the structure of the protein-ligand complex is crucial to drug
development. Existing virtual structure measurement and screening methods are
dominated by docking and its derived methods combined with deep learning.
However, the sampling and scoring methodology have largely restricted the
accuracy and efficiency. Here, we show that these two fundamental tasks can be
accurately tackled with a single model, namely LigPose, based on multi-task
geometric deep learning. By representing the ligand and the protein pair as a
graph, LigPose directly optimizes the three-dimensional structure of the
complex, with the learning of binding strength and atomic interactions as
auxiliary tasks, enabling its one-step prediction ability without docking
tools. Extensive experiments show LigPose achieved state-of-the-art performance
on major tasks in drug research. Its considerable improvements indicate a
promising paradigm of AI-based pipeline for drug development.

摘要：了解蛋白质-配体复合物的结构对于药物开发至关重要。现有的虚拟结构测量和筛选方法主要以对接及其衍生方法与深度学习相结合为主。然而，采样和评分方法在很大程度上限制了准确性和效率。在此，我们表明这两个基本任务可以通过一个单一模型（即 LigPose）准确解决，该模型基于多任务几何深度学习。通过将配体和蛋白质对表示为图，LigPose 直接优化复合物的三维结构，并以结合强度和原子相互作用的学习作为辅助任务，使其能够在不使用对接工具的情况下进行一步预测。大量的实验表明，LigPose 在药物研究的主要任务中取得了最先进的性能。其显着的改进表明了基于人工智能的药物开发管线的有前景的范例。

##### **Vision HgNN: An Electron-Micrograph is Worth Hypergraph of Hypernodes**
2408.11351v1 by Sakhinana Sagar Srinivas, Rajat Kumar Sarkar, Sreeja Gangasani, Venkataramana Runkana

Material characterization using electron micrographs is a crucial but
challenging task with applications in various fields, such as semiconductors,
quantum materials, batteries, etc. The challenges in categorizing electron
micrographs include but are not limited to the complexity of patterns, high
level of detail, and imbalanced data distribution(long-tail distribution).
Existing methods have difficulty in modeling the complex relational structure
in electron micrographs, hindering their ability to effectively capture the
complex relationships between different spatial regions of micrographs. We
propose a hypergraph neural network(HgNN) backbone architecture, a conceptually
alternative approach, to better model the complex relationships in electron
micrographs and improve material characterization accuracy. By utilizing
cost-effective GPU hardware, our proposed framework outperforms popular
baselines. The results of the ablation studies demonstrate that the proposed
framework is effective in achieving state-of-the-art performance on benchmark
datasets and efficient in terms of computational and memory requirements for
handling large-scale electron micrograph-based datasets.

摘要：使用電子顯微照片進行材料表徵是一項至關重要的任務，但在半導體、量子材料、電池等各個領域的應用中都面臨著挑戰。對電子顯微照片進行分類的挑戰包括但不限於模式的複雜性、高細節程度和不平衡的數據分佈（長尾分佈）。現有的方法難以對電子顯微照片中的複雜關係結構進行建模，這阻礙了它們有效捕捉顯微照片不同空間區域之間複雜關係的能力。我們提出了一種超圖神經網絡（HgNN）主幹架構，這是一種概念上的替代方法，可以更好地對電子顯微照片中的複雜關係進行建模並提高材料表徵的準確性。通過利用經濟高效的 GPU 硬體，我們提出的框架優於流行的基準。消融研究的結果表明，所提出的框架在基準數據集上實現了最先進的性能，並且在處理基於大規模電子顯微照片的數據集時在計算和記憶體需求方面是有效的。

##### **Clinical Context-aware Radiology Report Generation from Medical Images using Transformers**
2408.11344v1 by Sonit Singh

Recent developments in the field of Natural Language Processing, especially
language models such as the transformer have brought state-of-the-art results
in language understanding and language generation. In this work, we investigate
the use of the transformer model for radiology report generation from chest
X-rays. We also highlight limitations in evaluating radiology report generation
using only the standard language generation metrics. We then applied a
transformer based radiology report generation architecture, and also compare
the performance of a transformer based decoder with the recurrence based
decoder. Experiments were performed using the IU-CXR dataset, showing superior
results to its LSTM counterpart and being significantly faster. Finally, we
identify the need of evaluating radiology report generation system using both
language generation metrics and classification metrics, which helps to provide
robust measure of generated reports in terms of their coherence and diagnostic
value.

摘要：自然語言處理領域的最新發展，尤其是Transformer等語言模型，在語言理解和語言生成方面帶來了最先進的成果。在這項工作中，我們研究了使用Transformer模型從胸部 X 射線生成放射學報告。我們還強調了僅使用標準語言生成指標評估放射學報告生成的局限性。然後我們應用基於Transformer的放射學報告生成架構，並將基於Transformer的解碼器的性能與基於遞歸的解碼器進行比較。使用 IU-CXR 數據集進行了實驗，顯示出優於其 LSTM 對應方的結果，並且速度顯著提升。最後，我們確定需要使用語言生成指標和分類指標來評估放射學報告生成系統，這有助於在連貫性和診斷價值方面提供生成的報告的穩健測量。

##### **Automatic Dataset Construction (ADC): Sample Collection, Data Curation, and Beyond**
2408.11338v1 by Minghao Liu, Zonglin Di, Jiaheng Wei, Zhongruo Wang, Hengxiang Zhang, Ruixuan Xiao, Haoyu Wang, Jinlong Pang, Hao Chen, Ankit Shah, Hongxin Wei, Xinlei He, Zhaowei Zhao, Haobo Wang, Lei Feng, Jindong Wang, James Davis, Yang Liu

Large-scale data collection is essential for developing personalized training
data, mitigating the shortage of training data, and fine-tuning specialized
models. However, creating high-quality datasets quickly and accurately remains
a challenge due to annotation errors, the substantial time and costs associated
with human labor. To address these issues, we propose Automatic Dataset
Construction (ADC), an innovative methodology that automates dataset creation
with negligible cost and high efficiency. Taking the image classification task
as a starting point, ADC leverages LLMs for the detailed class design and code
generation to collect relevant samples via search engines, significantly
reducing the need for manual annotation and speeding up the data generation
process. Despite these advantages, ADC also encounters real-world challenges
such as label errors (label noise) and imbalanced data distributions (label
bias). We provide open-source software that incorporates existing methods for
label error detection, robust learning under noisy and biased data, ensuring a
higher-quality training data and more robust model training procedure.
Furthermore, we design three benchmark datasets focused on label noise
detection, label noise learning, and class-imbalanced learning. These datasets
are vital because there are few existing datasets specifically for label noise
detection, despite its importance. Finally, we evaluate the performance of
existing popular methods on these datasets, thereby facilitating further
research in the field.

摘要：大規模數據收集對於開發個人化訓練資料、緩解訓練資料短缺以及微調專業模型至關重要。然而，由於標註錯誤、與人工勞動相關的龐大時間和成本，快速且準確地建立高品質的資料集仍然是一個挑戰。為了解決這些問題，我們提出了自動資料集建構 (ADC)，這是一種創新的方法，可以自動化資料集建立，且成本低且效率高。以影像分類任務作為起點，ADC 利用大型語言模型 (LLM) 進行詳細的類別設計和程式碼生成，以透過搜尋引擎收集相關樣本，大幅降低人工標註的需求，並加速資料產生流程。儘管有這些優點，ADC 也會遇到現實世界的挑戰，例如標籤錯誤（標籤雜訊）和不平衡的資料分佈（標籤偏差）。我們提供開源軟體，其中包含現有標籤錯誤偵測方法、在有雜訊和偏差資料下的穩健學習，確保更高品質的訓練資料和更穩健的模型訓練程序。此外，我們設計了三個基準資料集，專注於標籤雜訊偵測、標籤雜訊學習和類別不平衡學習。這些資料集至關重要，因為儘管標籤雜訊偵測很重要，但現有專門針對標籤雜訊偵測的資料集很少。最後，我們評估了這些資料集上現有熱門方法的效能，從而促進該領域的進一步研究。

##### **BURExtract-Llama: An LLM for Clinical Concept Extraction in Breast Ultrasound Reports**
2408.11334v1 by Yuxuan Chen, Haoyan Yang, Hengkai Pan, Fardeen Siddiqui, Antonio Verdone, Qingyang Zhang, Sumit Chopra, Chen Zhao, Yiqiu Shen

Breast ultrasound is essential for detecting and diagnosing abnormalities,
with radiology reports summarizing key findings like lesion characteristics and
malignancy assessments. Extracting this critical information is challenging due
to the unstructured nature of these reports, with varied linguistic styles and
inconsistent formatting. While proprietary LLMs like GPT-4 are effective, they
are costly and raise privacy concerns when handling protected health
information. This study presents a pipeline for developing an in-house LLM to
extract clinical information from radiology reports. We first use GPT-4 to
create a small labeled dataset, then fine-tune a Llama3-8B model on it.
Evaluated on clinician-annotated reports, our model achieves an average F1
score of 84.6%, which is on par with GPT-4. Our findings demonstrate the
feasibility of developing an in-house LLM that not only matches GPT-4's
performance but also offers cost reductions and enhanced data privacy.

摘要：乳房超音波對於偵測和診斷異常至關重要，
放射科報告會總結關鍵發現，例如病灶特徵和惡性評估。由於這些報告的非結構化性質、語言風格多變且格式不一致，因此提取這些關鍵資訊具有挑戰性。雖然像 GPT-4 這樣的專有 LLM 很有效，但它們在處理受保護的健康資訊時成本高昂且會引起隱私問題。這項研究提出了一個開發內部 LLM 的管道，以從放射科報告中提取臨床資訊。我們首先使用 GPT-4 建立一個小型標籤資料集，然後對 Llama3-8B 模型進行微調。根據臨床醫師註解的報告進行評估，我們的模型達到平均 F1 分數為 84.6%，這與 GPT-4 相當。我們的研究結果證明了開發內部 LLM 的可行性，它不僅能與 GPT-4 的效能相匹配，還能降低成本並增強資料隱私。

##### **Design Principle Transfer in Neural Architecture Search via Large Language Models**
2408.11330v1 by Xun Zhou, Liang Feng, Xingyu Wu, Zhichao Lu, Kay Chen Tan

Transferable neural architecture search (TNAS) has been introduced to design
efficient neural architectures for multiple tasks, to enhance the practical
applicability of NAS in real-world scenarios. In TNAS, architectural knowledge
accumulated in previous search processes is reused to warm up the architecture
search for new tasks. However, existing TNAS methods still search in an
extensive search space, necessitating the evaluation of numerous architectures.
To overcome this challenge, this work proposes a novel transfer paradigm, i.e.,
design principle transfer. In this work, the linguistic description of various
structural components' effects on architectural performance is termed design
principles. They are learned from established architectures and then can be
reused to reduce the search space by discarding unpromising architectures.
Searching in the refined search space can boost both the search performance and
efficiency for new NAS tasks. To this end, a large language model
(LLM)-assisted design principle transfer (LAPT) framework is devised. In LAPT,
LLM is applied to automatically reason the design principles from a set of
given architectures, and then a principle adaptation method is applied to
refine these principles progressively based on the new search results.
Experimental results show that LAPT can beat the state-of-the-art TNAS methods
on most tasks and achieve comparable performance on others.

摘要：可轉移神經架構搜尋 (TNAS) 已被引入，用於設計適用於多項任務的高效神經架構，以增強 NAS 在真實世界場景中的實際可行性。在 TNAS 中，累積於先前搜尋程序中的架構知識被重新用於為新任務熱身架構搜尋。然而，現有的 TNAS 方法仍會在廣泛的搜尋空間中搜尋，需要評估大量的架構。為了解決這個挑戰，這項工作提出了一種新穎的轉移範例，即設計原則轉移。在這項工作中，各種結構元件對架構效能的影響的語言描述被稱為設計原則。它們從已建立的架構中學習，然後可以被重新用於透過捨棄無望的架構來減少搜尋空間。在經過優化的搜尋空間中搜尋可以提升新 NAS 任務的搜尋效能和效率。為此，設計了一個大型語言模型 (LLM) 輔助的設計原則轉移 (LAPT) 架構。在 LAPT 中，LLM 被應用於自動根據一組給定的架構推論設計原則，然後應用一個原則適應方法，根據新的搜尋結果逐步優化這些原則。實驗結果顯示，LAPT 可以擊敗大多數任務中的最先進 TNAS 方法，並在其他任務中達到相當的效能。

##### **Plug, Play, and Fuse: Zero-Shot Joint Decoding via Word-Level Re-ranking Across Diverse Vocabularies**
2408.11327v1 by Sai Koneru, Matthias Huck, Miriam Exel, Jan Niehues

Recent advancements in NLP have resulted in models with specialized
strengths, such as processing multimodal inputs or excelling in specific
domains. However, real-world tasks, like multimodal translation, often require
a combination of these strengths, such as handling both translation and image
processing. While individual translation and vision models are powerful, they
typically lack the ability to perform both tasks in a single system. Combining
these models poses challenges, particularly due to differences in their
vocabularies, which limit the effectiveness of traditional ensemble methods to
post-generation techniques like N-best list re-ranking. In this work, we
propose a novel zero-shot ensembling strategy that allows for the integration
of different models during the decoding phase without the need for additional
training. Our approach re-ranks beams during decoding by combining scores at
the word level, using heuristics to predict when a word is completed. We
demonstrate the effectiveness of this method in machine translation scenarios,
showing that it enables the generation of translations that are both speech-
and image-aware while also improving overall translation quality\footnote{We
will release the code upon paper acceptance.}.

摘要：最近在自然語言處理的進展產生了具有特殊優勢的模型，例如處理多模態輸入或在特定領域表現出色。然而，現實世界的任務，例如多模態翻譯，通常需要這些優勢的組合，例如同時處理翻譯和影像處理。雖然個別翻譯和視覺模型功能強大，但它們通常缺乏在單一系統中執行這兩個任務的能力。結合這些模型會帶來挑戰，特別是因為它們的詞彙不同，這限制了傳統整體方法對後生成技術（例如 N-best 列表重新排序）的有效性。在這項工作中，我們提出了一種新穎的零次方整體策略，它允許在解碼階段整合不同的模型，而無需額外訓練。我們的做法在解碼期間重新排序波束，方法是結合字詞層級的分數，並使用啟發法來預測字詞何時完成。我們在機器翻譯場景中證明了這種方法的有效性，表明它能夠產生同時具備語音和影像感知能力的翻譯，同時也能提升整體翻譯品質\footnote{我們將在論文被接受後釋出程式碼。}。

##### **Automating Thought of Search: A Journey Towards Soundness and Completeness**
2408.11326v1 by Daniel Cao, Michael Katz, Harsha Kokel, Kavitha Srinivas, Shirin Sohrabi

Planning remains one of the last standing bastions for large language models
(LLMs), which now turn their attention to search. Most of the literature uses
the language models as world models to define the search space, forgoing
soundness for the sake of flexibility. A recent work, Thought of Search (ToS),
proposed defining the search space with code, having the language models
produce that code. ToS requires a human in the loop, collaboratively producing
a sound successor function and goal test. The result, however, is worth the
effort: all the tested datasets were solved with 100% accuracy. At the same
time LLMs have demonstrated significant progress in code generation and
refinement for complex reasoning tasks. In this work, we automate ToS
(AutoToS), completely taking the human out of the loop of solving planning
problems. AutoToS guides the language model step by step towards the generation
of sound and complete search components, through feedback from both generic and
domain specific unit tests. We achieve 100% accuracy, with minimal feedback
iterations, using LLMs of various sizes on all evaluated domains.

摘要：規劃仍然是大語言模型 (LLM) 最後的堡壘之一，現在它們將注意力轉向搜尋。大多數文獻將語言模型用作世界模型來定義搜尋空間，為了靈活性而放棄健全性。最近的一項工作《搜尋思考》(ToS) 提議使用程式碼定義搜尋空間，讓語言模型產生該程式碼。ToS 需要人類參與，協作產生健全的後繼函數和目標測試。然而，結果值得付出努力：所有測試的資料集都以 100% 的準確度解決。同時，LLM 在複雜推理任務的程式碼產生和改進方面已展現顯著進展。在這項工作中，我們自動化 ToS (AutoToS)，將人類完全排除在解決規劃問題的迴圈之外。AutoToS 透過一般和領域特定單元測試的回饋，逐步引導語言模型產生健全且完整的搜尋元件。我們在所有評估的領域中使用各種規模的 LLM，以最少的回饋反覆運算，達到了 100% 的準確度。

##### **Towards Evaluating Large Language Models on Sarcasm Understanding**
2408.11319v1 by Yazhou Zhang, Chunwang Zou, Zheng Lian, Prayag Tiwari, Jing Qin

In the era of large language models (LLMs), the task of ``System I''~-~the
fast, unconscious, and intuitive tasks, e.g., sentiment analysis, text
classification, etc., have been argued to be successfully solved. However,
sarcasm, as a subtle linguistic phenomenon, often employs rhetorical devices
like hyperbole and figuration to convey true sentiments and intentions,
involving a higher level of abstraction than sentiment analysis. There is
growing concern that the argument about LLMs' success may not be fully tenable
when considering sarcasm understanding. To address this question, we select
eleven SOTA LLMs and eight SOTA pre-trained language models (PLMs) and present
comprehensive evaluations on six widely used benchmark datasets through
different prompting approaches, i.e., zero-shot input/output (IO) prompting,
few-shot IO prompting, chain of thought (CoT) prompting. Our results highlight
three key findings: (1) current LLMs underperform supervised PLMs based sarcasm
detection baselines across six sarcasm benchmarks. This suggests that
significant efforts are still required to improve LLMs' understanding of human
sarcasm. (2) GPT-4 consistently and significantly outperforms other LLMs across
various prompting methods, with an average improvement of 14.0\%$\uparrow$.
Claude 3 and ChatGPT demonstrate the next best performance after GPT-4. (3)
Few-shot IO prompting method outperforms the other two methods: zero-shot IO
and few-shot CoT. The reason is that sarcasm detection, being a holistic,
intuitive, and non-rational cognitive process, is argued not to adhere to
step-by-step logical reasoning, making CoT less effective in understanding
sarcasm compared to its effectiveness in mathematical reasoning tasks.

摘要：<paragraph>在大語言模型 (LLM) 時代，``系統 I'' 的任務~-~快速、無意識和直覺性的任務，例如情緒分析、文字分類等，已被認為已成功解決。然而，諷刺作為一種微妙的語言現象，通常採用誇飾和比喻等修辭手法來傳達真實的情感和意圖，涉及比情緒分析更高的抽象層次。越來越多人擔心，在考慮諷刺理解時，關於 LLM 成功的主張可能無法完全成立。為了解決這個問題，我們選擇了十一種 SOTA LLM 和八種 SOTA 預訓練語言模型 (PLM)，並通過不同的提示方法對六個廣泛使用的基準數據集進行了全面的評估，即零次輸入/輸出 (IO) 提示、少次 IO 提示、思考鏈 (CoT) 提示。我們的結果突出了三個關鍵發現：(1) 當前 LLM 在六個諷刺基準測試中表現不如基於監督 PLM 的諷刺檢測基準。這表明，仍需要付出巨大的努力來提高 LLM 對人類諷刺的理解。(2) GPT-4 在各種提示方法中始終顯著優於其他 LLM，平均改進了 14.0%$\uparrow$。Claude 3 和 ChatGPT 在 GPT-4 之後表現出次佳的性能。(3) 少次 IO 提示方法優於其他兩種方法：零次 IO 和少次 CoT。原因是諷刺檢測是一個整體的、直覺的和非理性的認知過程，據認為不遵循循序漸進的邏輯推理，這使得 CoT 在理解諷刺方面的效果不如在數學推理任務中的效果。</paragraph>

##### **Probabilistic Medical Predictions of Large Language Models**
2408.11316v1 by Bowen Gu, Rishi J. Desai, Kueiyu Joshua Lin, Jie Yang

Large Language Models (LLMs) have demonstrated significant potential in
clinical applications through prompt engineering, which enables the generation
of flexible and diverse clinical predictions. However, they pose challenges in
producing prediction probabilities, which are essential for transparency and
allowing clinicians to apply flexible probability thresholds in
decision-making. While explicit prompt instructions can lead LLMs to provide
prediction probability numbers through text generation, LLMs' limitations in
numerical reasoning raise concerns about the reliability of these
text-generated probabilities. To assess this reliability, we compared explicit
probabilities derived from text generation to implicit probabilities calculated
based on the likelihood of predicting the correct label token. Experimenting
with six advanced open-source LLMs across five medical datasets, we found that
the performance of explicit probabilities was consistently lower than implicit
probabilities with respect to discrimination, precision, and recall. Moreover,
these differences were enlarged on small LLMs and imbalanced datasets,
emphasizing the need for cautious interpretation and applications, as well as
further research into robust probability estimation methods for LLMs in
clinical contexts.

摘要：大型語言模型 (LLM) 透過提示工程展示了在臨床應用上的顯著潛力，這使得產生靈活多樣的臨床預測成為可能。然而，它們在產生預測機率上遇到了挑戰，而這對於透明度和允許臨床醫師在決策中套用靈活的機率閾值至關重要。儘管明確的提示說明可以引導 LLM 透過文字產生提供預測機率數字，但 LLM 在數字推理上的限制引發了對於這些文字產生的機率可靠性的疑慮。為了評估這種可靠性，我們將從文字產生中衍生的明確機率與根據預測正確標記符號的可能性計算的隱含機率進行比較。我們使用六種先進的開源 LLM 針對五個醫療資料集進行實驗，發現明確機率的表現始終低於隱含機率，無論是在判別、精準度和召回率方面皆是如此。此外，這些差異在小型 LLM 和不平衡資料集上被放大了，這強調了謹慎解讀和應用以及進一步研究 LLM 在臨床情境中穩健機率估計方法的必要性。

##### **Unlocking Adversarial Suffix Optimization Without Affirmative Phrases: Efficient Black-box Jailbreaking via LLM as Optimizer**
2408.11313v1 by Weipeng Jiang, Zhenting Wang, Juan Zhai, Shiqing Ma, Zhengyu Zhao, Chao Shen

Despite prior safety alignment efforts, mainstream LLMs can still generate
harmful and unethical content when subjected to jailbreaking attacks. Existing
jailbreaking methods fall into two main categories: template-based and
optimization-based methods. The former requires significant manual effort and
domain knowledge, while the latter, exemplified by Greedy Coordinate Gradient
(GCG), which seeks to maximize the likelihood of harmful LLM outputs through
token-level optimization, also encounters several limitations: requiring
white-box access, necessitating pre-constructed affirmative phrase, and
suffering from low efficiency. In this paper, we present ECLIPSE, a novel and
efficient black-box jailbreaking method utilizing optimizable suffixes. Drawing
inspiration from LLMs' powerful generation and optimization capabilities, we
employ task prompts to translate jailbreaking goals into natural language
instructions. This guides the LLM to generate adversarial suffixes for
malicious queries. In particular, a harmfulness scorer provides continuous
feedback, enabling LLM self-reflection and iterative optimization to
autonomously and efficiently produce effective suffixes. Experimental results
demonstrate that ECLIPSE achieves an average attack success rate (ASR) of 0.92
across three open-source LLMs and GPT-3.5-Turbo, significantly surpassing GCG
in 2.4 times. Moreover, ECLIPSE is on par with template-based methods in ASR
while offering superior attack efficiency, reducing the average attack overhead
by 83%.

摘要：儘管先前的安全調整工作，主流 LLM 仍可能在遭受越獄攻擊時產生有害且不道德的內容。現有的越獄方法分為兩大類：基於範本和基於最佳化的方法。前者需要大量手動操作和領域知識，而後者以貪婪坐標梯度 (GCG) 為例，透過令牌層級最佳化來最大化有害 LLM 輸出的可能性，也遇到了一些限制：需要白盒存取權限、需要預先建構肯定詞組，且效率低落。在本文中，我們提出 ECLIPSE，一種利用可最佳化字尾的新穎且有效率的黑盒越獄方法。從 LLM 強大的生成和最佳化功能中汲取靈感，我們使用任務提示將越獄目標轉換為自然語言指令。這引導 LLM 為惡意查詢生成對抗性字尾。特別是，一個危害性評分器提供持續的回饋，使 LLM 能夠自我反省和反覆最佳化，以自主且有效率地產生有效的字尾。實驗結果表明，ECLIPSE 在三個開源 LLM 和 GPT-3.5-Turbo 中實現了 0.92 的平均攻擊成功率 (ASR)，顯著超過 GCG 2.4 倍。此外，ECLIPSE 在 ASR 中與基於範本的方法不相上下，同時提供優越的攻擊效率，將平均攻擊開銷減少了 83%。

##### **Swarm Intelligence in Geo-Localization: A Multi-Agent Large Vision-Language Model Collaborative Framework**
2408.11312v1 by Xiao Han, Chen Zhu, Xiangyu Zhao, Hengshu Zhu

Visual geo-localization demands in-depth knowledge and advanced reasoning
skills to associate images with real-world geographic locations precisely. In
general, traditional methods based on data-matching are hindered by the
impracticality of storing adequate visual records of global landmarks.
Recently, Large Vision-Language Models (LVLMs) have demonstrated the capability
of geo-localization through Visual Question Answering (VQA), enabling a
solution that does not require external geo-tagged image records. However, the
performance of a single LVLM is still limited by its intrinsic knowledge and
reasoning capabilities. Along this line, in this paper, we introduce a novel
visual geo-localization framework called \name\ that integrates the inherent
knowledge of multiple LVLM agents via inter-agent communication to achieve
effective geo-localization of images. Furthermore, our framework employs a
dynamic learning strategy to optimize the communication patterns among agents,
reducing unnecessary discussions among agents and improving the efficiency of
the framework. To validate the effectiveness of the proposed framework, we
construct GeoGlobe, a novel dataset for visual geo-localization tasks.
Extensive testing on the dataset demonstrates that our approach significantly
outperforms state-of-the-art methods.

摘要：視覺地理定位需要深入的知識和先進的推理技能，才能精確地將影像與真實世界的地理位置聯繫起來。一般來說，基於資料配對的傳統方法受到儲存全球地標足夠視覺紀錄的不切實際性所阻礙。最近，大型視覺語言模型 (LVLMs) 已透過視覺問答 (VQA) 展示了地理定位的能力，提供一種不需要外部地理標籤影像紀錄的解決方案。然而，單一 LVLM 的效能仍受到其內在知識和推理能力的限制。在這條路线上，我們在本文中介紹了一個名為 \name\ 的新視覺地理定位架構，它透過代理間溝通整合多個 LVLM 代理的內在知識，以達成影像的有效地理定位。此外，我們的架構採用動態學習策略來優化代理之間的溝通模式，減少代理之間不必要的討論，並提高架構的效率。為了驗證所提出架構的有效性，我們建構了 GeoGlobe，一個用於視覺地理定位任務的新資料集。在資料集上的廣泛測試證明，我們的做法顯著優於最先進的方法。

##### **EEG-Defender: Defending against Jailbreak through Early Exit Generation of Large Language Models**
2408.11308v1 by Chongwen Zhao, Zhihao Dou, Kaizhu Huang

Large Language Models (LLMs) are increasingly attracting attention in various
applications. Nonetheless, there is a growing concern as some users attempt to
exploit these models for malicious purposes, including the synthesis of
controlled substances and the propagation of disinformation. In an effort to
mitigate such risks, the concept of "Alignment" technology has been developed.
However, recent studies indicate that this alignment can be undermined using
sophisticated prompt engineering or adversarial suffixes, a technique known as
"Jailbreak." Our research takes cues from the human-like generate process of
LLMs. We identify that while jailbreaking prompts may yield output logits
similar to benign prompts, their initial embeddings within the model's latent
space tend to be more analogous to those of malicious prompts. Leveraging this
finding, we propose utilizing the early transformer outputs of LLMs as a means
to detect malicious inputs, and terminate the generation immediately. Built
upon this idea, we introduce a simple yet significant defense approach called
EEG-Defender for LLMs. We conduct comprehensive experiments on ten jailbreak
methods across three models. Our results demonstrate that EEG-Defender is
capable of reducing the Attack Success Rate (ASR) by a significant margin,
roughly 85\% in comparison with 50\% for the present SOTAs, with minimal impact
on the utility and effectiveness of LLMs.

摘要：大型語言模型 (LLM) 在各種應用中越來越受到關注。儘管如此，隨著一些使用者嘗試將這些模型用於惡意目的，包括合成受控物質和散布錯誤訊息，擔憂也與日俱增。為了減輕此類風險，「比對」技術的概念應運而生。然而，最近的研究表明，這種比對可以使用精密的提示工程或對抗性後綴（一種稱為「越獄」的技術）來破壞。我們的研究從 LLM 類似人類的生成過程汲取靈感。我們發現，儘管越獄提示可能會產生類似於良性提示的輸出 logit，但它們在模型潛在空間中的初始嵌入通常更類似於惡意提示的嵌入。利用這一發現，我們建議利用 LLM 的早期變換器輸出作為偵測惡意輸入並立即終止生成的手段。基於這個想法，我們為 LLM 介紹了一種簡單但重要的防禦方法，稱為 EEG-Defender。我們對三個模型中的十種越獄方法進行了全面的實驗。我們的結果表明，EEG-Defender 能夠將攻擊成功率 (ASR) 大幅降低，與現有的 SOTA 相比，大約降低了 85%，而對 LLM 的效用和有效性的影響最小。

##### **KAN4TSF: Are KAN and KAN-based models Effective for Time Series Forecasting?**
2408.11306v1 by Xiao Han, Xinfeng Zhang, Yiling Wu, Zhenduo Zhang, Zhe Wu

Time series forecasting is a crucial task that predicts the future values of
variables based on historical data. Time series forecasting techniques have
been developing in parallel with the machine learning community, from early
statistical learning methods to current deep learning methods. Although
existing methods have made significant progress, they still suffer from two
challenges. The mathematical theory of mainstream deep learning-based methods
does not establish a clear relation between network sizes and fitting
capabilities, and these methods often lack interpretability. To this end, we
introduce the Kolmogorov-Arnold Network (KAN) into time series forecasting
research, which has better mathematical properties and interpretability. First,
we propose the Reversible Mixture of KAN experts (RMoK) model, which is a
KAN-based model for time series forecasting. RMoK uses a mixture-of-experts
structure to assign variables to KAN experts. Then, we compare performance,
integration, and speed between RMoK and various baselines on real-world
datasets, and the experimental results show that RMoK achieves the best
performance in most cases. And we find the relationship between temporal
feature weights and data periodicity through visualization, which roughly
explains RMoK's mechanism. Thus, we conclude that KAN and KAN-based models
(RMoK) are effective in time series forecasting. Code is available at KAN4TSF:
https://github.com/2448845600/KAN4TSF.

摘要：時間序列預測是一項重要的任務，它根據歷史數據預測變數的未來值。時間序列預測技術已與機器學習社群同步發展，從早期的統計學習方法到目前的深度學習方法。儘管現有方法已取得重大進展，但仍面臨兩項挑戰。主流基於深度學習的方法的數學理論並未建立網路大小與擬合能力之間的明確關係，而且這些方法通常缺乏可解釋性。為此，我們將 Kolmogorov-Arnold 網路 (KAN) 引入時間序列預測研究，它具有更好的數學特性和可解釋性。首先，我們提出 KAN 專家可逆混合 (RMoK) 模型，這是一個基於 KAN 的時間序列預測模型。RMoK 使用專家混合結構將變數分配給 KAN 專家。然後，我們比較 RMoK 與各種基線在真實世界資料集上的效能、整合和速度，實驗結果顯示 RMoK 在大多數情況下都能達成最佳效能。我們透過視覺化找出時間特徵權重與資料週期性之間的關係，這大致說明了 RMoK 的機制。因此，我們得出結論，KAN 和基於 KAN 的模型 (RMoK) 在時間序列預測中是有效的。程式碼可在 KAN4TSF 取得：https://github.com/2448845600/KAN4TSF。

##### **UniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation**
2408.11305v1 by Xiangyu Zhao, Yuehan Zhang, Wenlong Zhang, Xiao-Ming Wu

The fashion domain encompasses a variety of real-world multimodal tasks,
including multimodal retrieval and multimodal generation. The rapid
advancements in artificial intelligence generated content, particularly in
technologies like large language models for text generation and diffusion
models for visual generation, have sparked widespread research interest in
applying these multimodal models in the fashion domain. However, tasks
involving embeddings, such as image-to-text or text-to-image retrieval, have
been largely overlooked from this perspective due to the diverse nature of the
multimodal fashion domain. And current research on multi-task single models
lack focus on image generation. In this work, we present UniFashion, a unified
framework that simultaneously tackles the challenges of multimodal generation
and retrieval tasks within the fashion domain, integrating image generation
with retrieval tasks and text generation tasks. UniFashion unifies embedding
and generative tasks by integrating a diffusion model and LLM, enabling
controllable and high-fidelity generation. Our model significantly outperforms
previous single-task state-of-the-art models across diverse fashion tasks, and
can be readily adapted to manage complex vision-language tasks. This work
demonstrates the potential learning synergy between multimodal generation and
retrieval, offering a promising direction for future research in the fashion
domain. The source code is available at
https://github.com/xiangyu-mm/UniFashion.

摘要：時尚領域包含各種真實世界的多模態任務，包括多模態檢索和多模態生成。人工智慧所產生的內容快速進步，特別是在文本生成的大語言模型和視覺生成擴散模型等技術中，這激發了廣泛的研究興趣，將這些多模態模型應用於時尚領域。然而，由於多模態時尚領域的多樣性，涉及嵌入的任務，例如圖像到文本或文本到圖像檢索，從這個角度來看，在很大程度上被忽視了。目前對多任務單一模型的研究缺乏對圖像生成的關注。在這項工作中，我們提出了 UniFashion，一個統一的框架，同時應對時尚領域內多模態生成和檢索任務的挑戰，將圖像生成與檢索任務和文本生成任務整合在一起。UniFashion 通過整合擴散模型和 LLM 來統一嵌入和生成任務，實現可控且高保真生成。我們的模型在各種時尚任務中明顯優於以前的單任務最先進模型，並且可以輕鬆適應管理複雜的視覺語言任務。這項工作展示了多模態生成和檢索之間的潛在學習協同作用，為時尚領域未來的研究提供了有希望的方向。原始碼可在 https://github.com/xiangyu-mm/UniFashion 獲得。

##### **Offline Policy Learning via Skill-step Abstraction for Long-horizon Goal-Conditioned Tasks**
2408.11300v1 by Donghoon Kim, Minjong Yoo, Honguk Woo

Goal-conditioned (GC) policy learning often faces a challenge arising from
the sparsity of rewards, when confronting long-horizon goals. To address the
challenge, we explore skill-based GC policy learning in offline settings, where
skills are acquired from existing data and long-horizon goals are decomposed
into sequences of near-term goals that align with these skills. Specifically,
we present an `offline GC policy learning via skill-step abstraction' framework
(GLvSA) tailored for tackling long-horizon GC tasks affected by goal
distribution shifts. In the framework, a GC policy is progressively learned
offline in conjunction with the incremental modeling of skill-step abstractions
on the data. We also devise a GC policy hierarchy that not only accelerates GC
policy learning within the framework but also allows for parameter-efficient
fine-tuning of the policy. Through experiments with the maze and Franka kitchen
environments, we demonstrate the superiority and efficiency of our GLvSA
framework in adapting GC policies to a wide range of long-horizon goals. The
framework achieves competitive zero-shot and few-shot adaptation performance,
outperforming existing GC policy learning and skill-based methods.

摘要：目標條件（GC）政策學習在面對長期目標時，經常會面臨獎勵稀疏的挑戰。為了應對這項挑戰，我們在離線設置中探索基於技能的 GC 政策學習，其中技能從現有資料中獲取，而長期目標則分解為與這些技能相符的近期目標序列。具體來說，我們提出了一個「透過技能步驟抽象的離線 GC 政策學習」架構（GLvSA），專門用於處理受目標分佈轉移影響的長期 GC 任務。在這個架構中，GC 政策會逐步在離線中學習，並結合資料中技能步驟抽象的增量建模。我們還設計了一個 GC 政策層級，它不僅加速了架構內的 GC 政策學習，還允許對政策進行參數有效的微調。透過迷宮和 Franka 廚房環境的實驗，我們展示了我們的 GLvSA 架構在將 GC 政策適應到廣泛的長期目標方面的優越性和效率。該架構達到了具有競爭力的零次學習和少次學習適應效能，優於現有的 GC 政策學習和基於技能的方法。

##### **RePair: Automated Program Repair with Process-based Feedback**
2408.11296v1 by Yuze Zhao, Zhenya Huang, Yixiao Ma, Rui Li, Kai Zhang, Hao Jiang, Qi Liu, Linbo Zhu, Yu Su

The gap between the trepidation of program reliability and the expense of
repairs underscores the indispensability of Automated Program Repair (APR). APR
is instrumental in transforming vulnerable programs into more robust ones,
bolstering program reliability while simultaneously diminishing the financial
burden of manual repairs. Commercial-scale language models (LM) have taken APR
to unprecedented levels. However, the emergence reveals that for models fewer
than 100B parameters, making single-step modifications may be difficult to
achieve the desired effect. Moreover, humans interact with the LM through
explicit prompts, which hinders the LM from receiving feedback from compiler
and test cases to automatically optimize its repair policies. In this
literature, we explore how small-scale LM (less than 20B) achieve excellent
performance through process supervision and feedback. We start by constructing
a dataset named CodeNet4Repair, replete with multiple repair records, which
supervises the fine-tuning of a foundational model. Building upon the
encouraging outcomes of reinforcement learning, we develop a reward model that
serves as a critic, providing feedback for the fine-tuned LM's action,
progressively optimizing its policy. During inference, we require the LM to
generate solutions iteratively until the repair effect no longer improves or
hits the maximum step limit. The results show that process-based not only
outperforms larger outcome-based generation methods, but also nearly matches
the performance of closed-source commercial large-scale LMs.

摘要：程式可靠性令人膽戰心驚，而維修費用高昂，這兩者之間的差距突顯了自動化程式修復 (APR) 的不可或缺性。APR 幫助將容易受攻擊的程式轉變為更強大的程式，同時提高程式可靠性，並降低人工維修的財務負擔。商用規模的語言模型 (LM) 已將 APR 提升到前所未有的水準。然而，新興技術顯示，對於參數少於 100B 的模型，進行單步修改可能難以達到預期的效果。此外，人類透過明確的提示與 LM 互動，這會阻礙 LM 從編譯器和測試案例中接收回饋，以自動最佳化其修復政策。在本篇文獻中，我們探討小規模 LM（小於 20B）如何透過流程監督和回饋來達成卓越的效能。我們從建立一個名為 CodeNet4Repair 的資料集開始，其中包含多筆修復記錄，用於監督基礎模型的微調。建立在強化學習的令人振奮的成果之上，我們開發了一個回饋模型，作為一個評論家，提供微調後的 LM 動作的回饋，逐步最佳化其政策。在推論期間，我們要求 LM 迭代產生解決方案，直到修復效果不再改善或達到最大步驟限制。結果顯示，基於流程的方法不僅優於較大型的基於結果的產生方法，而且幾乎與閉源商用大型 LM 的效能相匹配。

##### **RedWhale: An Adapted Korean LLM Through Efficient Continual Pretraining**
2408.11294v1 by Anh-Dung Vo, Minseong Jung, Wonbeen Lee, Daewoo Choi

The field of Natural Language Processing (NLP) has seen significant
advancements with the development of Large Language Models (LLMs). However,
much of this research remains focused on English, often overlooking
low-resource languages like Korean. This oversight presents challenges due to
the unique non-alphabetic token structure of Korean and the substantial memory
and computational demands required for LLM training, which frequently lead to
memory constraints and out-of-memory errors. To address these issues, we
present RedWhale, a model specifically tailored for Korean language processing.
RedWhale is developed using an efficient continual pretraining approach that
includes a comprehensive Korean corpus preprocessing pipeline, a specialized
tokenizer, an optimized model initialization technique, and a multistage
pretraining strategy. These innovations collectively reduce training time and
computational costs while maintaining high levels of accuracy and
comprehension. By leveraging cross-lingual transfer learning, which exploits
shared linguistic similarities across languages, RedWhale builds on English
models to enhance Korean language processing. Experimental results demonstrate
that RedWhale outperforms other leading models on Korean NLP benchmarks,
including the Korean Balanced Evaluation of Significant Tasks (KoBEST), showing
superior understanding and generation of Korean text. Furthermore, RedWhale
showed no signs of convergence even after pretraining on 9.7 billion tokens,
indicating the potential for further improvements with additional training.
This work represents a significant advancement in bridging the linguistic
divide, particularly in enhancing NLP capabilities for the Korean language.

摘要：自然語言處理 (NLP) 領域隨著大型語言模型 (LLM) 的發展取得顯著進展。然而，這項研究大多仍集中於英語，往往忽略韓語等低資源語言。由於韓語獨特的非字母符號結構，以及 LLM 訓練所需的大量記憶體和運算需求，導致記憶體限制和記憶體不足錯誤，因此這種疏忽造成了挑戰。為了解決這些問題，我們提出了 RedWhale，這是一個專門為韓語處理量身打造的模型。RedWhale 是使用一種有效持續預訓練方法開發的，其中包括一個全面的韓語語料庫預處理管道、一個專用分詞器、一個最佳化的模型初始化技術和一個多階段預訓練策略。這些創新共同減少了訓練時間和運算成本，同時保持高準確度和理解力。透過利用跨語言遷移學習，利用語言之間共有的語言相似性，RedWhale 建立在英語模型上，以增強韓語處理。實驗結果證明，RedWhale 在韓語 NLP 基準上優於其他領先模型，包括韓語重要任務的平衡評估 (KoBEST)，顯示出對韓語文本的卓越理解和生成能力。此外，即使在對 97 億個符號進行預訓練後，RedWhale 仍未顯示出收斂的跡象，這表明透過額外訓練有進一步改進的潛力。這項工作代表了縮小語言鴻溝的重大進展，特別是在增強韓語的 NLP 能力方面。

##### **Applying and Evaluating Large Language Models in Mental Health Care: A Scoping Review of Human-Assessed Generative Tasks**
2408.11288v1 by Yining Hua, Hongbin Na, Zehan Li, Fenglin Liu, Xiao Fang, David Clifton, John Torous

Large language models (LLMs) are emerging as promising tools for mental
health care, offering scalable support through their ability to generate
human-like responses. However, the effectiveness of these models in clinical
settings remains unclear. This scoping review aimed to assess the current
generative applications of LLMs in mental health care, focusing on studies
where these models were tested with human participants in real-world scenarios.
A systematic search across APA PsycNet, Scopus, PubMed, and Web of Science
identified 726 unique articles, of which 17 met the inclusion criteria. These
studies encompassed applications such as clinical assistance, counseling,
therapy, and emotional support. However, the evaluation methods were often
non-standardized, with most studies relying on ad hoc scales that limit
comparability and robustness. Privacy, safety, and fairness were also
frequently underexplored. Moreover, reliance on proprietary models, such as
OpenAI's GPT series, raises concerns about transparency and reproducibility.
While LLMs show potential in expanding mental health care access, especially in
underserved areas, the current evidence does not fully support their use as
standalone interventions. More rigorous, standardized evaluations and ethical
oversight are needed to ensure these tools can be safely and effectively
integrated into clinical practice.

摘要：大型語言模型 (LLM) 正作為心理保健的工具浮現，透過產生類人的回應提供可擴充的支持。然而，這些模型在臨床環境中的有效性仍不明確。本範圍探討旨在評估 LLM 在心理保健中的現有生成應用，重點在於在真實世界情境中以人類參與者測試這些模型的研究。系統性搜尋 APA PsycNet、Scopus、PubMed 和 Web of Science 找出 726 篇獨特文章，其中 17 篇符合納入標準。這些研究涵蓋臨床協助、諮詢、治療和情緒支持等應用。然而，評估方法通常未標準化，大多數研究依賴於限制可比較性和穩健性的臨時量表。隱私、安全和公平性也經常未充分探討。此外，依賴於專有模型（例如 OpenAI 的 GPT 系列）會引發對透明度和可複製性的疑慮。雖然 LLM 在擴展心理保健服務方面展現潛力，特別是在服務不足的地區，但目前的證據並不完全支持將其用作獨立干預措施。需要更嚴謹、標準化的評估和倫理監督，以確保這些工具能安全且有效地整合到臨床實務中。

##### **Inference Plans for Hybrid Particle Filtering**
2408.11283v1 by Ellie Y. Cheng, Eric Atkinson, Guillaume Baudart, Louis Mandel, Michael Carbin

Advanced probabilistic programming languages (PPLs) use hybrid inference
systems to combine symbolic exact inference and Monte Carlo methods to improve
inference performance. These systems use heuristics to partition random
variables within the program into variables that are encoded symbolically and
variables that are encoded with sampled values, and the heuristics are not
necessarily aligned with the performance evaluation metrics used by the
developer. In this work, we present inference plans, a programming interface
that enables developers to control the partitioning of random variables during
hybrid particle filtering. We further present Siren, a new PPL that enables
developers to use annotations to specify inference plans the inference system
must implement. To assist developers with statically reasoning about whether an
inference plan can be implemented, we present an abstract-interpretation-based
static analysis for Siren for determining inference plan satisfiability. We
prove the analysis is sound with respect to Siren's semantics. Our evaluation
applies inference plans to three different hybrid particle filtering algorithms
on a suite of benchmarks and shows that the control provided by inference plans
enables speed ups of 1.76x on average and up to 206x to reach target accuracy,
compared to the inference plans implemented by default heuristics; the results
also show that inference plans improve accuracy by 1.83x on average and up to
595x with less or equal runtime, compared to the default inference plans. We
further show that the static analysis is precise in practice, identifying all
satisfiable inference plans in 27 out of the 33 benchmark-algorithm
combinations.

摘要：進階機率程式語言 (PPL) 使用混合推論系統，結合符號精確推論與蒙地卡羅方法，以改善推論效能。這些系統使用啟發式方法，將程式中的隨機變數分割成以符號編碼的變數和以採樣值編碼的變數，而啟發式方法不一定與開發人員使用的效能評估指標相符。在這項工作中，我們提出推論計畫，這是一個程式介面，讓開發人員能夠在混合粒子濾波期間控制隨機變數的分割。我們進一步提出 Siren，這是一個新的 PPL，讓開發人員能夠使用註解來指定推論系統必須執行的推論計畫。為了協助開發人員靜態推理推論計畫是否可執行，我們提出一個基於抽象詮釋的 Siren 靜態分析，用於確定推論計畫的可滿足性。我們證明此分析對於 Siren 的語意是健全的。我們的評估將推論計畫套用於三個不同的混合粒子濾波演算法，針對一組基準進行評估，並顯示與預設啟發式方法執行的推論計畫相比，推論計畫提供的控制平均能加速 1.76 倍，最高可達 206 倍以達到目標準確度；結果也顯示，與預設推論計畫相比，推論計畫平均能改善 1.83 倍的準確度，最高可達 595 倍，且執行時間較短或相等。我們進一步顯示，在實務上，靜態分析是精確的，在 33 個基準演算法組合中，找出所有可滿足的推論計畫，共有 27 個。

##### **BearLLM: A Prior Knowledge-Enhanced Bearing Health Management Framework with Unified Vibration Signal Representation**
2408.11281v1 by Haotian Peng, Jiawei Liu, Jinsong Du, Jie Gao, Wei Wang

We propose a bearing health management framework leveraging large language
models (BearLLM), a novel multimodal model that unifies multiple
bearing-related tasks by processing user prompts and vibration signals.
Specifically, we introduce a prior knowledge-enhanced unified vibration signal
representation to handle various working conditions across multiple datasets.
This involves adaptively sampling the vibration signals based on the sampling
rate of the sensor, incorporating the frequency domain to unify input
dimensions, and using a fault-free reference signal as an auxiliary input. To
extract features from vibration signals, we first train a fault classification
network, then convert and align the extracted features into word embedding, and
finally concatenate these with text embedding as input to an LLM. To evaluate
the performance of the proposed method, we constructed the first large-scale
multimodal bearing health management (MBHM) dataset, including paired vibration
signals and textual descriptions. With our unified vibration signal
representation, BearLLM using one set of pre-trained weights achieves
state-of-the-art performance on nine publicly available fault diagnosis
benchmarks, outperforming specific methods designed for individual datasets. We
provide a dataset, our model, and code to inspire future research on building
more capable industrial multimodal models
(https://github.com/hatton613/BearLLM).

摘要：我們提出一個軸承健康管理架構，利用大型語言模型 (BearLLM)，這是一個新穎的多模態模型，它透過處理使用者提示和振動訊號，統一多個與軸承相關的任務。具體來說，我們引入一個先驗知識增強的統一振動訊號表示，以處理多個資料集中的各種工作條件。這包含根據感測器的取樣率自適應取樣振動訊號、結合頻率域以統一輸入維度，以及使用無故障參考訊號作為輔助輸入。為了從振動訊號中提取特徵，我們首先訓練一個故障分類網路，然後將提取的特徵轉換並對齊到字詞嵌入中，最後將這些特徵與文字嵌入串接作為 LLM 的輸入。為了評估所提出方法的效能，我們建構了第一個大型多模態軸承健康管理 (MBHM) 資料集，其中包括配對的振動訊號和文字描述。透過我們的統一振動訊號表示，使用一組預訓練權重的 BearLLM 在九個公開可用的故障診斷基準測試中達成最先進的效能，優於專門為個別資料集設計的特定方法。我們提供一個資料集、我們的模型和程式碼，以激勵未來在建構更強大的產業多模態模型方面的研究 (https://github.com/hatton613/BearLLM)。

##### **Towards Analyzing and Mitigating Sycophancy in Large Vision-Language Models**
2408.11261v1 by Yunpu Zhao, Rui Zhang, Junbin Xiao, Changxin Ke, Ruibo Hou, Yifan Hao, Qi Guo, Yunji Chen

Large Vision-Language Models (LVLMs) have shown significant capability in
vision-language understanding. However, one critical issue that persists in
these models is sycophancy, which means models are unduly influenced by leading
or deceptive prompts, resulting in biased outputs and hallucinations. Despite
the progress in LVLMs, evaluating and mitigating sycophancy is yet much
under-explored. In this work, we fill this gap by systematically analyzing
sycophancy on various VL benchmarks with curated leading queries and further
proposing a text contrastive decoding method for mitigation. While the specific
sycophantic behavior varies significantly among models, our analysis reveals
the severe deficiency of all LVLMs in resilience of sycophancy across various
tasks. For improvement, we propose Leading Query Contrastive Decoding (LQCD), a
model-agnostic method focusing on calibrating the LVLMs' over-reliance on
leading cues by identifying and suppressing the probabilities of sycophancy
tokens at the decoding stage. Extensive experiments show that LQCD effectively
mitigate sycophancy, outperforming both prompt engineering methods and common
methods for hallucination mitigation. We further demonstrate that LQCD does not
hurt but even slightly improves LVLMs' responses to neutral queries, suggesting
it being a more effective strategy for general-purpose decoding but not limited
to sycophancy.

摘要：大型視覺語言模型 (LVLMs) 在視覺語言理解方面展現出顯著的能力。然而，這些模型中持續存在的一個關鍵問題是阿諛奉承，這表示模型受到引導或具誤導性的提示過度影響，導致有偏差的輸出和幻覺。儘管 LVLMs 有所進展，但評估和減輕阿諛奉承現象的研究仍十分不足。在這項工作中，我們透過系統性分析各種 VL 基準上的阿諛奉承現象（使用策展的引導式查詢），並進一步提出用於緩解的文字對比解碼方法來填補這項空白。雖然具體的阿諛奉承行為在不同模型間差異很大，但我們的分析揭露了所有 LVLMs 在各種任務中抵抗阿諛奉承現象的嚴重不足。為了改進，我們提出引導式查詢對比解碼 (LQCD)，這是一種與模型無關的方法，專注於校準 LVLMs 對引導線索過度依賴，方法是在解碼階段識別並抑制阿諛奉承詞彙的機率。廣泛的實驗顯示，LQCD 有效減輕阿諛奉承現象，優於提示工程方法和常見的幻覺減輕方法。我們進一步證明，LQCD 不會損害 LVLMs 對中立查詢的回應，甚至會略微改善，這表示它是一種更有效的通用解碼策略，而不僅限於阿諛奉承現象。

##### **Improving Speech Recognition Error Prediction for Modern and Off-the-shelf Speech Recognizers**
2408.11258v1 by Prashant Serai, Peidong Wang, Eric Fosler-Lussier

Modeling the errors of a speech recognizer can help simulate errorful
recognized speech data from plain text, which has proven useful for tasks like
discriminative language modeling, improving robustness of NLP systems, where
limited or even no audio data is available at train time. Previous work
typically considered replicating behavior of GMM-HMM based systems, but the
behavior of more modern posterior-based neural network acoustic models is not
the same and requires adjustments to the error prediction model. In this work,
we extend a prior phonetic confusion based model for predicting speech
recognition errors in two ways: first, we introduce a sampling-based paradigm
that better simulates the behavior of a posterior-based acoustic model. Second,
we investigate replacing the confusion matrix with a sequence-to-sequence model
in order to introduce context dependency into the prediction. We evaluate the
error predictors in two ways: first by predicting the errors made by a
Switchboard ASR system on unseen data (Fisher), and then using that same
predictor to estimate the behavior of an unrelated cloud-based ASR system on a
novel task. Sampling greatly improves predictive accuracy within a 100-guess
paradigm, while the sequence model performs similarly to the confusion matrix.

摘要：語音辨識器的錯誤建模有助於模擬純文字中錯誤的辨識語音資料，這已證明對以下任務有幫助，例如辨別語言建模、改善 NLP 系統的穩健性，其中在訓練期間沒有音訊資料或甚至沒有音訊資料。先前的研究通常考量複製基於 GMM-HMM 的系統行為，但更現代的基於後驗的神經網路聲學模型的行為並不相同，需要調整錯誤預測模型。在這項研究中，我們以兩種方式擴充了先前的基於音標混淆的模型，以預測語音辨識錯誤：首先，我們引進一個基於抽樣的範例，能更好地模擬基於後驗的聲學模型的行為。其次，我們研究用序列對序列模型取代混淆矩陣，以便在預測中引進上下文依賴性。我們以兩種方式評估錯誤預測器：首先，預測 Switchboard ASR 系統在未見資料（Fisher）上產生的錯誤，然後使用相同的預測器來估計不相關的雲端 ASR 系統在新的任務上的行為。在 100 次猜測的範例中，抽樣大幅改善了預測準確度，而序列模型的表現與混淆矩陣類似。

##### **Automatic Image Annotation (AIA) of AlmondNet-20 Method for Almond Detection by Improved CNN-based Model**
2408.11253v1 by Mohsen Asghari Ilani, Saba Moftakhar Tehran, Ashkan Kavei, Arian Radmehr

In response to the burgeoning global demand for premium agricultural
products, particularly within the competitive nut market, this paper introduces
an innovative methodology aimed at enhancing the grading process for almonds
and their shells. Leveraging state-of-the-art Deep Convolutional Neural
Networks (CNNs), specifically the AlmondNet-20 architecture, our study achieves
exceptional accuracy exceeding 99%, facilitated by the utilization of a
20-layer CNN model. To bolster robustness in differentiating between almonds
and shells, data augmentation techniques are employed, ensuring the reliability
and accuracy of our classification system. Our model, meticulously trained over
1000 epochs, demonstrates remarkable performance, boasting an accuracy rate of
99% alongside a minimal loss function of 0.0567. Rigorous evaluation through
test datasets further validates the efficacy of our approach, revealing
impeccable precision, recall, and F1-score metrics for almond detection. Beyond
its technical prowess, this advanced classification system offers tangible
benefits to both industry experts and non-specialists alike, ensuring globally
reliable almond classification. The application of deep learning algorithms, as
showcased in our study, not only enhances grading accuracy but also presents
opportunities for product patents, thereby contributing to the economic value
of our nation. Through the adoption of cutting-edge technologies such as the
AlmondNet-20 model, we pave the way for future advancements in agricultural
product classification, ultimately enriching global trade and economic
prosperity.

摘要：為回應全球對優質農業產品日益增長的龐大需求，特別是在競爭激烈的堅果市場中，本文介紹了一種創新方法，旨在加強杏仁及其殼的分類過程。利用最先進的深度卷積神經網路 (CNN)，特別是 AlmondNet-20 架構，我們的研究達到了極高的準確度，超過 99%，這歸功於利用 20 層 CNN 模型。為了加強區分杏仁和殼的穩健性，採用了數據擴充技術，確保了我們分類系統的可靠性和準確性。我們的模型經過 1000 個世代的細心訓練，表現非凡，準確率達到 99%，同時損失函數低至 0.0567。通過測試資料集進行的嚴格評估進一步驗證了我們方法的有效性，揭示了杏仁檢測的完美精確度、召回率和 F1 分數指標。除了技術優勢外，這種先進的分類系統還為產業專家和非專家提供了切實的好處，確保全球杏仁分類的可靠性。如我們研究中展示的那樣，深度學習演算法的應用不僅提高了分級的準確度，還提供了產品專利的機會，從而為我們國家的經濟價值做出了貢獻。透過採用 AlmondNet-20 模型等尖端技術，我們為未來農業產品分類的進步鋪平了道路，最終豐富了全球貿易和經濟繁榮。

##### **Counterfactuals As a Means for Evaluating Faithfulness of Attribution Methods in Autoregressive Language Models**
2408.11252v1 by Sepehr Kamahi, Yadollah Yaghoobzadeh

Despite the widespread adoption of autoregressive language models,
explainability evaluation research has predominantly focused on span infilling
and masked language models (MLMs). Evaluating the faithfulness of an
explanation method -- how accurately the method explains the inner workings and
decision-making of the model -- is very challenging because it is very hard to
separate the model from its explanation. Most faithfulness evaluation
techniques corrupt or remove some input tokens considered important according
to a particular attribution (feature importance) method and observe the change
in the model's output. This approach creates out-of-distribution inputs for
causal language models (CLMs) due to their training objective of next token
prediction. In this study, we propose a technique that leverages counterfactual
generation to evaluate the faithfulness of attribution methods for
autoregressive language modeling scenarios. Our technique creates fluent and
in-distribution counterfactuals that makes evaluation protocol more reliable.
Code is available at https://github.com/Sepehr-Kamahi/faith

摘要：儘管自迴歸語言模型被廣泛採用，
可解釋性評估研究主要集中在跨度填補
和遮蔽語言模型 (MLM)。評估解釋方法的忠實度
——方法多準確地解釋模型的內部運作和
決策制定——極具挑戰性，因為很難
將模型與其解釋分開。大多數忠實度評估
技術會損壞或移除一些輸入代碼，這些代碼被認為很重要，具體取決於
特定歸因（特徵重要性）方法，並觀察模型
輸出的變化。由於下一個代碼預測的訓練目標，這種方法會為
因果語言模型 (CLM) 建立出分布的輸入。在本研究中，我們提出了一種利用反事實
生成來評估自迴歸語言建模場景的歸因方法的忠實度的技術。我們的技術建立流暢且
在分布中的反事實，使評估協定更可靠。
程式碼可在 https://github.com/Sepehr-Kamahi/faith 取得

##### **The Dilemma of Uncertainty Estimation for General Purpose AI in the EU AI Act**
2408.11249v1 by Matias Valdenegro-Toro, Radina Stoykova

The AI act is the European Union-wide regulation of AI systems. It includes
specific provisions for general-purpose AI models which however need to be
further interpreted in terms of technical standards and state-of-art studies to
ensure practical compliance solutions. This paper examines the AI act
requirements for providers and deployers of general-purpose AI and further
proposes uncertainty estimation as a suitable measure for legal compliance and
quality assurance in training of such models. We argue that uncertainty
estimation should be a required component for deploying models in the real
world, and under the EU AI Act, it could fulfill several requirements for
transparency, accuracy, and trustworthiness. However, generally using
uncertainty estimation methods increases the amount of computation, producing a
dilemma, as computation might go over the threshold ($10^{25}$ FLOPS) to
classify the model as a systemic risk system which bears more regulatory
burden.

摘要：《人工智慧法》是歐盟針對人工智慧系統的規範。其中包含通用人工智慧模型的具體條款，但仍需要進一步透過技術標準和現有研究進行詮釋，以確保實務上合規的解決方案。本文探討《人工智慧法》對通用人工智慧的供應商和部署者的要求，並進一步提出不確定性估計作為訓練此類模型的法律合規性和品質保證的適當措施。我們主張不確定性估計應為在現實世界中部署模型的必要組成部分，且根據歐盟《人工智慧法》，它可以滿足透明度、準確性和可信賴性的多項要求。然而，一般而言，使用不確定性估計方法會增加運算量，造成兩難，因為運算量可能會超過門檻（$10^{25}$ FLOPS），將模型分類為承擔更多法規負擔的系統性風險系統。

##### **Unboxing Occupational Bias: Grounded Debiasing LLMs with U.S. Labor Data**
2408.11247v1 by Atmika Gorti, Manas Gaur, Aman Chadha

Large Language Models (LLMs) are prone to inheriting and amplifying societal
biases embedded within their training data, potentially reinforcing harmful
stereotypes related to gender, occupation, and other sensitive categories. This
issue becomes particularly problematic as biased LLMs can have far-reaching
consequences, leading to unfair practices and exacerbating social inequalities
across various domains, such as recruitment, online content moderation, or even
the criminal justice system. Although prior research has focused on detecting
bias in LLMs using specialized datasets designed to highlight intrinsic biases,
there has been a notable lack of investigation into how these findings
correlate with authoritative datasets, such as those from the U.S. National
Bureau of Labor Statistics (NBLS). To address this gap, we conduct empirical
research that evaluates LLMs in a ``bias-out-of-the-box" setting, analyzing how
the generated outputs compare with the distributions found in NBLS data.
Furthermore, we propose a straightforward yet effective debiasing mechanism
that directly incorporates NBLS instances to mitigate bias within LLMs. Our
study spans seven different LLMs, including instructable, base, and
mixture-of-expert models, and reveals significant levels of bias that are often
overlooked by existing bias detection techniques. Importantly, our debiasing
method, which does not rely on external datasets, demonstrates a substantial
reduction in bias scores, highlighting the efficacy of our approach in creating
fairer and more reliable LLMs.

摘要：大型語言模型 (LLM) 容易繼承和放大其訓練資料中內嵌的社會偏見，潛在強化與性別、職業和其他敏感類別相關的有害刻板印象。這個問題變得特別有問題，因為有偏見的 LLM 可能會產生深遠的後果，導致不公平的行為，並加劇各種領域的社會不平等，例如招聘、線上內容審核，甚至是刑事司法系統。儘管先前的研究專注於使用專門設計來強調內在偏見的資料集來偵測 LLM 中的偏見，但對於這些發現如何與權威資料集相關聯的研究卻明顯不足，例如來自美國國家勞工統計局 (NBLS) 的資料集。為了解決這個差距，我們進行實證研究來評估 LLM 在「偏見開箱即用」的設定中，分析產生的輸出與在 NBLS 資料中發現的分配如何比較。此外，我們提出一個簡單但有效的去偏機制，直接納入 NBLS 實例以減輕 LLM 中的偏見。我們的研究涵蓋七種不同的 LLM，包括可指導、基礎和專家混合模型，並揭示出大量偏見，這些偏見通常被現有的偏見偵測技術所忽略。重要的是，我們的去偏方法不依賴於外部資料集，證明了偏見評分顯著降低，突顯了我們的方法在創造更公平、更可靠的 LLM 中的效力。

##### **Do Neural Scaling Laws Exist on Graph Self-Supervised Learning?**
2408.11243v1 by Qian Ma, Haitao Mao, Jingzhe Liu, Zhehua Zhang, Chunlin Feng, Yu Song, Yihan Shao, Tianfan Fu, Yao Ma

Self-supervised learning~(SSL) is essential to obtain foundation models in
NLP and CV domains via effectively leveraging knowledge in large-scale
unlabeled data. The reason for its success is that a suitable SSL design can
help the model to follow the neural scaling law, i.e., the performance
consistently improves with increasing model and dataset sizes. However, it
remains a mystery whether existing SSL in the graph domain can follow the
scaling behavior toward building Graph Foundation Models~(GFMs) with
large-scale pre-training. In this study, we examine whether existing graph SSL
techniques can follow the neural scaling behavior with the potential to serve
as the essential component for GFMs. Our benchmark includes comprehensive SSL
technique implementations with analysis conducted on both the conventional SSL
setting and many new settings adopted in other domains. Surprisingly, despite
the SSL loss continuously decreasing, no existing graph SSL techniques follow
the neural scaling behavior on the downstream performance. The model
performance only merely fluctuates on different data scales and model scales.
Instead of the scales, the key factors influencing the performance are the
choices of model architecture and pretext task design. This paper examines
existing SSL techniques for the feasibility of Graph SSL techniques in
developing GFMs and opens a new direction for graph SSL design with the new
evaluation prototype. Our code implementation is available online to ease
reproducibility on https://github.com/GraphSSLScaling/GraphSSLScaling.

摘要：自監督學習 (SSL) 對於透過有效利用大規模未標記資料中的知識來取得 NLP 和 CV 領域中的基礎模型至關重要。它成功的理由在於，適當的 SSL 設計可以幫助模型遵循神經擴充定律，亦即效能會隨著模型和資料集大小的增加而持續提升。然而，現有的圖形領域 SSL 是否能遵循擴充行為，朝著建構具備大規模預訓練的圖形基礎模型 (GFM) 邁進，仍然是個謎。在本研究中，我們檢視現有的圖形 SSL 技術是否能遵循神經擴充行為，並具備作為 GFM 基本元件的潛力。我們的基準包含全面的 SSL 技術實作，並對傳統 SSL 設定和採用其他領域的許多新設定進行分析。令人驚訝的是，儘管 SSL 損失持續下降，但沒有現有的圖形 SSL 技術在下游效能上遵循神經擴充行為。模型效能僅在不同的資料規模和模型規模上波動。影響效能的關鍵因素不是規模，而是模型架構和預設任務設計的選擇。本文檢視現有的 SSL 技術，探討圖形 SSL 技術在開發 GFM 中的可行性，並透過新的評估原型為圖形 SSL 設計開啟新的方向。我們的程式碼實作可以在線上取得，以簡化在 https://github.com/GraphSSLScaling/GraphSSLScaling 上的重現性。

##### **A Little Confidence Goes a Long Way**
2408.11239v1 by John Scoville, Shang Gao, Devanshu Agrawal, Javed Qadrud-Din

We introduce a group of related methods for binary classification tasks using
probes of the hidden state activations in large language models (LLMs).
Performance is on par with the largest and most advanced LLMs currently
available, but requiring orders of magnitude fewer computational resources and
not requiring labeled data. This approach involves translating class labels
into a semantically rich description, spontaneous symmetry breaking of
multilayer perceptron probes for unsupervised learning and inference, training
probes to generate confidence scores (prior probabilities) from hidden state
activations subject to known constraints via entropy maximization, and
selecting the most confident probe model from an ensemble for prediction. These
techniques are evaluated on four datasets using five base LLMs.

摘要：我們介紹了一組相關方法，用於二元分類任務，使用大型語言模型 (LLM) 中隱藏狀態激活的探針。
效能與目前最大的最先進 LLM 相當，但需要的計算資源少了好幾個數量級，而且不需要標記資料。此方法包括將類別標籤轉換為語意豐富的描述、多層感知器探針的自發對稱性破壞，用於無監督學習和推論、訓練探針以從隱藏狀態激活中產生信心分數（先驗機率），受制於透過熵最大化而得知的約束，以及從一個整體中選出最具信心的探針模型以進行預測。這些技術使用五個基礎 LLM 在四個資料集上進行評估。

##### **Out-of-Distribution Detection with Attention Head Masking for Multimodal Document Classification**
2408.11237v1 by Christos Constantinou, Georgios Ioannides, Aman Chadha, Aaron Elkins, Edwin Simpson

Detecting out-of-distribution (OOD) data is crucial in machine learning
applications to mitigate the risk of model overconfidence, thereby enhancing
the reliability and safety of deployed systems. The majority of existing OOD
detection methods predominantly address uni-modal inputs, such as images or
texts. In the context of multi-modal documents, there is a notable lack of
extensive research on the performance of these methods, which have primarily
been developed with a focus on computer vision tasks. We propose a novel
methodology termed as attention head masking (AHM) for multi-modal OOD tasks in
document classification systems. Our empirical results demonstrate that the
proposed AHM method outperforms all state-of-the-art approaches and
significantly decreases the false positive rate (FPR) compared to existing
solutions up to 7.5\%. This methodology generalizes well to multi-modal data,
such as documents, where visual and textual information are modeled under the
same Transformer architecture. To address the scarcity of high-quality publicly
available document datasets and encourage further research on OOD detection for
documents, we introduce FinanceDocs, a new document AI dataset. Our code and
dataset are publicly available.

摘要：<paragraph>偵測異常資料 (OOD) 在機器學習應用中至關重要，可降低模型過度自信的風險，進而提升已部署系統的可靠性和安全性。現有的 OOD 偵測方法大多以單模態輸入為主，例如影像或文字。在多模態文件脈絡中，對於這些方法的效能缺乏廣泛的研究，而這些方法主要針對電腦視覺任務而開發。我們提出稱為注意力層遮罩 (AHM) 的創新方法，用於文件分類系統中的多模態 OOD 任務。我們的實證結果顯示，所提出的 AHM 方法優於所有現有技術，與現有解決方案相比，將誤報率 (FPR) 大幅降低達 7.5%。此方法能很好地概括到多模態資料，例如文件，其中視覺和文字資訊在相同的 Transformer 架構下建模。為了解決高品質公開文件資料集的稀少性，並鼓勵進一步研究文件的 OOD 偵測，我們引入了 FinanceDocs，一個新的文件 AI 資料集。我們的程式碼和資料集已公開。</paragraph>

##### **Unified Deep Learning Model for Global Prediction of Aboveground Biomass, Canopy Height and Cover from High-Resolution, Multi-Sensor Satellite Imagery**
2408.11234v1 by Manuel Weber, Carly Beneke, Clyde Wheeler

Regular measurement of carbon stock in the world's forests is critical for
carbon accounting and reporting under national and international climate
initiatives, and for scientific research, but has been largely limited in
scalability and temporal resolution due to a lack of ground based assessments.
Increasing efforts have been made to address these challenges by incorporating
remotely sensed data. We present a new methodology which uses multi-sensor,
multi-spectral imagery at a resolution of 10 meters and a deep learning based
model which unifies the prediction of above ground biomass density (AGBD),
canopy height (CH), canopy cover (CC) as well as uncertainty estimations for
all three quantities. The model is trained on millions of globally sampled
GEDI-L2/L4 measurements. We validate the capability of our model by deploying
it over the entire globe for the year 2023 as well as annually from 2016 to
2023 over selected areas. The model achieves a mean absolute error for AGBD
(CH, CC) of 26.1 Mg/ha (3.7 m, 9.9 %) and a root mean squared error of 50.6
Mg/ha (5.4 m, 15.8 %) on a globally sampled test dataset, demonstrating a
significant improvement over previously published results. We also report the
model performance against independently collected ground measurements published
in the literature, which show a high degree of correlation across varying
conditions. We further show that our pre-trained model facilitates seamless
transferability to other GEDI variables due to its multi-head architecture.

摘要：<paragraph>定期测量全球森林的碳儲量對於國家和國際氣候計畫下的碳計量和報告，以及科學研究至關重要，但由於缺乏地面評估，在可擴展性和時間解析度方面受到很大限制。已採取越來越多措施，透過整合遙測資料來應對這些挑戰。我們提出了一種新的方法，它使用解析度為 10 公尺的多感測器、多光譜影像，以及一個深度學習模型，該模型統一了地上生物量密度 (AGBD)、樹冠高度 (CH)、樹冠覆蓋 (CC) 的預測，以及所有三種數量的誤差估計。該模型以數百萬個全球取樣的 GEDI-L2/L4 測量值進行訓練。我們透過在 2023 年以及 2016 年至 2023 年間每年在選定區域部署我們的模型來驗證其能力。該模型對 AGBD (CH、CC) 的平均絕對誤差為 26.1 Mg/ha (3.7 m，9.9%)，均方根誤差為 50.6 Mg/ha (5.4 m，15.8%) 在全球取樣的測試資料集上，顯示出比先前發布的結果有了顯著的改進。我們還根據文獻中發布的獨立收集的地面測量值報告了模型效能，這些測量值顯示出在不同條件下高度相關。我們進一步表明，由於我們的預訓練模型的多頭架構，它促進了向其他 GEDI 變數的無縫遷移。</paragraph>

##### **OCTCube: A 3D foundation model for optical coherence tomography that improves cross-dataset, cross-disease, cross-device and cross-modality analysis**
2408.11227v1 by Zixuan Liu, Hanwen Xu, Addie Woicik, Linda G. Shapiro, Marian Blazes, Yue Wu, Cecilia S. Lee, Aaron Y. Lee, Sheng Wang

Optical coherence tomography (OCT) has become critical for diagnosing retinal
diseases as it enables 3D images of the retina and optic nerve. OCT acquisition
is fast, non-invasive, affordable, and scalable. Due to its broad
applicability, massive numbers of OCT images have been accumulated in routine
exams, making it possible to train large-scale foundation models that can
generalize to various diagnostic tasks using OCT images. Nevertheless, existing
foundation models for OCT only consider 2D image slices, overlooking the rich
3D structure. Here, we present OCTCube, a 3D foundation model pre-trained on
26,605 3D OCT volumes encompassing 1.62 million 2D OCT images. OCTCube is
developed based on 3D masked autoencoders and exploits FlashAttention to reduce
the larger GPU memory usage caused by modeling 3D volumes. OCTCube outperforms
2D models when predicting 8 retinal diseases in both inductive and
cross-dataset settings, indicating that utilizing the 3D structure in the model
instead of 2D data results in significant improvement. OCTCube further shows
superior performance on cross-device prediction and when predicting systemic
diseases, such as diabetes and hypertension, further demonstrating its strong
generalizability. Finally, we propose a
contrastive-self-supervised-learning-based OCT-IR pre-training framework (COIP)
for cross-modality analysis on OCT and infrared retinal (IR) images, where the
OCT volumes are embedded using OCTCube. We demonstrate that COIP enables
accurate alignment between OCT and IR en face images. Collectively, OCTCube, a
3D OCT foundation model, demonstrates significantly better performance against
2D models on 27 out of 29 tasks and comparable performance on the other two
tasks, paving the way for AI-based retinal disease diagnosis.

摘要：光學相干斷層掃描 (OCT) 已成為診斷視網膜疾病的重要工具，因為它可以提供視網膜和視神經的 3D 影像。OCT 獲取快速、非侵入性、負擔得起且可擴充。由於其廣泛的適用性，大量 OCT 影像已在例行檢查中累積，使得訓練大型基礎模型成為可能，這些模型可以使用 OCT 影像推廣到各種診斷任務。儘管如此，現有的 OCT 基礎模型只考慮 2D 影像切片，忽略了豐富的 3D 結構。在此，我們提出 OCTCube，這是一個 3D 基礎模型，預先訓練於 26,605 個 3D OCT 體積，包含 162 萬個 2D OCT 影像。OCTCube 是基於 3D 蒙版自動編碼器開發的，並利用 FlashAttention 來減少建模 3D 體積所造成的較大 GPU 記憶體使用量。OCTCube 在預測 8 種視網膜疾病時優於 2D 模型，無論是在歸納式還是跨資料集設定中，這表示在模型中使用 3D 結構，而不是 2D 資料，會帶來顯著的改進。OCTCube 在跨裝置預測和預測全身性疾病（例如糖尿病和高血壓）時進一步展現出優異的效能，進一步證明了其強大的泛化能力。最後，我們提出一個基於對比自監督學習的 OCT-IR 預訓練架構 (COIP)，用於 OCT 和紅外線視網膜 (IR) 影像的跨模態分析，其中 OCT 體積使用 OCTCube 嵌入。我們證明 COIP 能夠在 OCT 和 IR 正面影像之間進行準確的對齊。總的來說，OCTCube 是一個 3D OCT 基礎模型，在 29 項任務中的 27 項任務中展現出明顯優於 2D 模型的效能，而在其他兩項任務中展現出相當的效能，為基於 AI 的視網膜疾病診斷鋪路。

