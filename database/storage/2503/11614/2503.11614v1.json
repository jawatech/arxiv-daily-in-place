{"2503.11614": {"publish_time": "2025-03-14", "title": "Neutralizing Bias in LLM Reasoning using Entailment Graphs", "paper_summary": "LLMs are often claimed to be capable of Natural Language Inference (NLI),\nwhich is widely regarded as a cornerstone of more complex forms of reasoning.\nHowever, recent works show that LLMs still suffer from hallucinations in NLI\ndue to attestation bias, where LLMs overly rely on propositional memory to\nbuild shortcuts. To solve the issue, we design an unsupervised framework to\nconstruct counterfactual reasoning data and fine-tune LLMs to reduce\nattestation bias. To measure bias reduction, we build bias-adversarial variants\nof NLI datasets with randomly replaced predicates in premises while keeping\nhypotheses unchanged. Extensive evaluations show that our framework can\nsignificantly reduce hallucinations from attestation bias. Then, we further\nevaluate LLMs fine-tuned with our framework on original NLI datasets and their\nbias-neutralized versions, where original entities are replaced with randomly\nsampled ones. Extensive results show that our framework consistently improves\ninferential performance on both original and bias-neutralized NLI datasets.", "paper_summary_zh": "<paragraph>\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5e38\u88ab\u8a8d\u70ba\u5177\u5099\u81ea\u7136\u8a9e\u8a00\u63a8\u7406 (NLI) \u7684\u80fd\u529b\uff0c\u800c NLI \u5ee3\u6cdb\u88ab\u8996\u70ba\u66f4\u8907\u96dc\u63a8\u7406\u5f62\u5f0f\u7684\u57fa\u77f3\u3002\u7136\u800c\uff0c\u6700\u8fd1\u7684\u7814\u7a76\u986f\u793a\uff0c\u7531\u65bc\u8b49\u660e\u504f\u5dee\uff0cLLM \u5728 NLI \u4e2d\u4ecd\u7136\u6703\u51fa\u73fe\u5e7b\u89ba\uff0cLLM \u904e\u5ea6\u4f9d\u8cf4\u547d\u984c\u8a18\u61b6\u4f86\u5efa\u7acb\u6377\u5f91\u3002\u70ba\u4e86\u514b\u670d\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u500b\u7121\u76e3\u7763\u6846\u67b6\u4f86\u5efa\u69cb\u53cd\u4e8b\u5be6\u63a8\u7406\u6578\u64da\uff0c\u4e26\u5fae\u8abf LLM \u4ee5\u6e1b\u5c11\u8b49\u660e\u504f\u5dee\u3002\u70ba\u4e86\u8861\u91cf\u504f\u5dee\u6e1b\u5c11\u7684\u7a0b\u5ea6\uff0c\u6211\u5011\u5efa\u69cb\u4e86 NLI \u6578\u64da\u96c6\u7684\u504f\u5dee\u5c0d\u6297\u8b8a\u9ad4\uff0c\u5728\u524d\u63d0\u4e2d\u96a8\u6a5f\u66ff\u63db\u8b02\u8a5e\uff0c\u540c\u6642\u4fdd\u6301\u5047\u8a2d\u4e0d\u8b8a\u3002\u5927\u91cf\u8a55\u4f30\u986f\u793a\uff0c\u6211\u5011\u7684\u6846\u67b6\u53ef\u4ee5\u986f\u8457\u6e1b\u5c11\u8b49\u660e\u504f\u5dee\u9020\u6210\u7684\u5e7b\u89ba\u3002\u63a5\u8457\uff0c\u6211\u5011\u5728\u539f\u59cb NLI \u6578\u64da\u96c6\u53ca\u5176\u504f\u5dee\u4e2d\u548c\u7248\u672c\u4e0a\u9032\u4e00\u6b65\u8a55\u4f30\u4f7f\u7528\u6211\u5011\u6846\u67b6\u5fae\u8abf\u7684 LLM\uff0c\u5176\u4e2d\u539f\u59cb\u5be6\u9ad4\u88ab\u96a8\u6a5f\u62bd\u6a23\u7684\u5be6\u9ad4\u53d6\u4ee3\u3002\u5927\u91cf\u7d50\u679c\u986f\u793a\uff0c\u6211\u5011\u7684\u6846\u67b6\u6301\u7e8c\u63d0\u5347\u4e86\u539f\u59cb\u548c\u504f\u5dee\u4e2d\u548c NLI \u6578\u64da\u96c6\u7684\u63a8\u7406\u6548\u80fd\u3002</paragraph>\n", "author": "Liang Cheng et.al.", "authors": "Liang Cheng, Tianyi Li, Zhaowei Wang, Tianyang Liu, Mark Steedman", "id": "2503.11614v1", "paper_url": "http://arxiv.org/abs/2503.11614v1", "repo": "null"}}