{"2407.06135": {"publish_time": "2024-07-08", "title": "ANOLE: An Open, Autoregressive, Native Large Multimodal Models for Interleaved Image-Text Generation", "paper_summary": "Previous open-source large multimodal models (LMMs) have faced several\nlimitations: (1) they often lack native integration, requiring adapters to\nalign visual representations with pre-trained large language models (LLMs); (2)\nmany are restricted to single-modal generation; (3) while some support\nmultimodal generation, they rely on separate diffusion models for visual\nmodeling and generation. To mitigate these limitations, we present Anole, an\nopen, autoregressive, native large multimodal model for interleaved image-text\ngeneration. We build Anole from Meta AI's Chameleon, adopting an innovative\nfine-tuning strategy that is both data-efficient and parameter-efficient. Anole\ndemonstrates high-quality, coherent multimodal generation capabilities. We have\nopen-sourced our model, training framework, and instruction tuning data.", "paper_summary_zh": "\u5148\u524d\u7684\u958b\u6e90\u5927\u578b\u591a\u6a21\u614b\u6a21\u578b (LMM) \u5df2\u9762\u81e8\u591a\u9805\u9650\u5236\uff1a(1) \u5b83\u5011\u7d93\u5e38\u7f3a\u4e4f\u539f\u751f\u6574\u5408\uff0c\u9700\u8981\u9069\u914d\u5668\u624d\u80fd\u5c07\u8996\u89ba\u8868\u793a\u8207\u9810\u8a13\u7df4\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5c0d\u9f4a\uff1b(2) \u8a31\u591a\u50c5\u9650\u65bc\u55ae\u6a21\u614b\u751f\u6210\uff1b(3) \u96d6\u7136\u6709\u4e9b\u652f\u63f4\u591a\u6a21\u614b\u751f\u6210\uff0c\u4f46\u5b83\u5011\u4f9d\u8cf4\u65bc\u7528\u65bc\u8996\u89ba\u5efa\u6a21\u548c\u751f\u6210\u7684\u7368\u7acb\u64f4\u6563\u6a21\u578b\u3002\u70ba\u4e86\u6e1b\u8f15\u9019\u4e9b\u9650\u5236\uff0c\u6211\u5011\u63d0\u51fa\u4e86 Anole\uff0c\u4e00\u500b\u958b\u653e\u3001\u81ea\u8ff4\u6b78\u3001\u539f\u751f\u7684\u5927\u578b\u591a\u6a21\u614b\u6a21\u578b\uff0c\u7528\u65bc\u4ea4\u932f\u5f71\u50cf\u6587\u5b57\u751f\u6210\u3002\u6211\u5011\u5f9e Meta AI \u7684 Chameleon \u5efa\u69cb Anole\uff0c\u63a1\u7528\u5275\u65b0\u7684\u5fae\u8abf\u7b56\u7565\uff0c\u65e2\u7bc0\u7701\u8cc7\u6599\uff0c\u53c8\u7bc0\u7701\u53c3\u6578\u3002Anole \u5c55\u793a\u4e86\u9ad8\u54c1\u8cea\u3001\u4e00\u81f4\u7684\u591a\u6a21\u614b\u751f\u6210\u80fd\u529b\u3002\u6211\u5011\u5df2\u958b\u653e\u6211\u5011\u6a21\u578b\u3001\u8a13\u7df4\u67b6\u69cb\u548c\u6307\u4ee4\u5fae\u8abf\u8cc7\u6599\u7684\u539f\u59cb\u78bc\u3002", "author": "Ethan Chern et.al.", "authors": "Ethan Chern, Jiadi Su, Yan Ma, Pengfei Liu", "id": "2407.06135v1", "paper_url": "http://arxiv.org/abs/2407.06135v1", "repo": "https://github.com/gair-nlp/anole"}}