{"2411.02337": {"publish_time": "2024-11-04", "title": "WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning", "paper_summary": "Large language models (LLMs) have shown remarkable potential as autonomous\nagents, particularly in web-based tasks. However, existing LLM web agents\nheavily rely on expensive proprietary LLM APIs, while open LLMs lack the\nnecessary decision-making capabilities. This paper introduces WebRL, a\nself-evolving online curriculum reinforcement learning framework designed to\ntrain high-performance web agents using open LLMs. WebRL addresses three key\nchallenges in building LLM web agents, including the scarcity of training\ntasks, sparse feedback signals, and policy distribution drift in online\nlearning. Specifically, WebRL incorporates 1) a self-evolving curriculum that\ngenerates new tasks from unsuccessful attempts, 2) a robust outcome-supervised\nreward model (ORM), and 3) adaptive reinforcement learning strategies to ensure\nconsistent improvements. We apply WebRL to transform open Llama-3.1 and GLM-4\nmodels into proficient web agents. On WebArena-Lite, WebRL improves the success\nrate of Llama-3.1-8B from 4.8% to 42.4%, and from 6.1% to 43% for GLM-4-9B.\nThese open models significantly surpass the performance of GPT-4-Turbo (17.6%)\nand GPT-4o (13.9%) and outperform previous state-of-the-art web agents trained\non open LLMs (AutoWebGLM, 18.2%). Our findings demonstrate WebRL's\neffectiveness in bridging the gap between open and proprietary LLM-based web\nagents, paving the way for more accessible and powerful autonomous web\ninteraction systems.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5c55\u73fe\u51fa\u4f5c\u70ba\u81ea\u4e3b\u4ee3\u7406\u7684\u986f\u8457\u6f5b\u529b\uff0c\u7279\u5225\u662f\u5728\u57fa\u65bc\u7db2\u8def\u7684\u4efb\u52d9\u4e2d\u3002\u7136\u800c\uff0c\u73fe\u6709\u7684 LLM \u7db2\u8def\u4ee3\u7406\u7a0b\u5f0f\u56b4\u91cd\u4f9d\u8cf4\u6602\u8cb4\u7684\u5c08\u6709 LLM API\uff0c\u800c\u958b\u653e\u5f0f LLM \u7f3a\u4e4f\u5fc5\u8981\u7684\u6c7a\u7b56\u80fd\u529b\u3002\u672c\u6587\u4ecb\u7d39 WebRL\uff0c\u4e00\u500b\u81ea\u6211\u6f14\u5316\u7684\u7dda\u4e0a\u8ab2\u7a0b\u5f37\u5316\u5b78\u7fd2\u67b6\u69cb\uff0c\u65e8\u5728\u4f7f\u7528\u958b\u653e\u5f0f LLM \u8a13\u7df4\u9ad8\u6027\u80fd\u7db2\u8def\u4ee3\u7406\u7a0b\u5f0f\u3002WebRL \u61c9\u5c0d\u4e86\u5efa\u7acb LLM \u7db2\u8def\u4ee3\u7406\u7a0b\u5f0f\u7684\u4e09\u500b\u4e3b\u8981\u6311\u6230\uff0c\u5305\u62ec\u8a13\u7df4\u4efb\u52d9\u7684\u7a00\u7f3a\u6027\u3001\u7a00\u758f\u56de\u994b\u8a0a\u865f\u548c\u7dda\u4e0a\u5b78\u7fd2\u4e2d\u7684\u7b56\u7565\u5206\u4f48\u6f02\u79fb\u3002\u5177\u9ad4\u4f86\u8aaa\uff0cWebRL \u7d50\u5408\u4e86 1) \u4e00\u500b\u81ea\u6211\u6f14\u5316\u7684\u8ab2\u7a0b\uff0c\u5f9e\u4e0d\u6210\u529f\u7684\u5617\u8a66\u4e2d\u7522\u751f\u65b0\u7684\u4efb\u52d9\uff0c2) \u4e00\u500b\u5f37\u5927\u7684\u7d50\u679c\u76e3\u7763\u734e\u52f5\u6a21\u578b (ORM)\uff0c\u4ee5\u53ca 3) \u81ea\u9069\u61c9\u5f37\u5316\u5b78\u7fd2\u7b56\u7565\uff0c\u4ee5\u78ba\u4fdd\u6301\u7e8c\u9032\u6b65\u3002\u6211\u5011\u61c9\u7528 WebRL \u5c07\u958b\u653e\u5f0f Llama-3.1 \u548c GLM-4 \u6a21\u578b\u8f49\u63db\u70ba\u719f\u7df4\u7684\u7db2\u8def\u4ee3\u7406\u7a0b\u5f0f\u3002\u5728 WebArena-Lite \u4e0a\uff0cWebRL \u5c07 Llama-3.1-8B \u7684\u6210\u529f\u7387\u5f9e 4.8% \u63d0\u9ad8\u5230 42.4%\uff0c\u5c07 GLM-4-9B \u7684\u6210\u529f\u7387\u5f9e 6.1% \u63d0\u9ad8\u5230 43%\u3002\u9019\u4e9b\u958b\u653e\u5f0f\u6a21\u578b\u986f\u8457\u8d85\u8d8a\u4e86 GPT-4-Turbo (17.6%) \u548c GPT-4o (13.9%) \u7684\u6548\u80fd\uff0c\u4e26\u4e14\u512a\u65bc\u5148\u524d\u5728\u958b\u653e\u5f0f LLM\uff08AutoWebGLM\uff0c18.2%\uff09\u4e0a\u8a13\u7df4\u7684\u6700\u5148\u9032\u7db2\u8def\u4ee3\u7406\u7a0b\u5f0f\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u8b49\u660e\u4e86 WebRL \u5728\u5f4c\u5408\u958b\u653e\u5f0f\u548c\u5c08\u6709 LLM \u57fa\u65bc\u7db2\u8def\u4ee3\u7406\u7a0b\u5f0f\u4e4b\u9593\u5dee\u8ddd\u7684\u6709\u6548\u6027\uff0c\u70ba\u66f4\u6613\u65bc\u4f7f\u7528\u4e14\u529f\u80fd\u66f4\u5f37\u5927\u7684\u81ea\u4e3b\u7db2\u8def\u4e92\u52d5\u7cfb\u7d71\u92ea\u5e73\u4e86\u9053\u8def\u3002", "author": "Zehan Qi et.al.", "authors": "Zehan Qi, Xiao Liu, Iat Long Iong, Hanyu Lai, Xueqiao Sun, Xinyue Yang, Jiadai Sun, Yu Yang, Shuntian Yao, Tianjie Zhang, Wei Xu, Jie Tang, Yuxiao Dong", "id": "2411.02337v1", "paper_url": "http://arxiv.org/abs/2411.02337v1", "repo": "null"}}