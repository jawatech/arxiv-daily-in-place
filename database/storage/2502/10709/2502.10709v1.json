{"2502.10709": {"publish_time": "2025-02-15", "title": "An Empirical Analysis of Uncertainty in Large Language Model Evaluations", "paper_summary": "As LLM-as-a-Judge emerges as a new paradigm for assessing large language\nmodels (LLMs), concerns have been raised regarding the alignment, bias, and\nstability of LLM evaluators. While substantial work has focused on alignment\nand bias, little research has concentrated on the stability of LLM evaluators.\nIn this paper, we conduct extensive experiments involving 9 widely used LLM\nevaluators across 2 different evaluation settings to investigate the\nuncertainty in model-based LLM evaluations. We pinpoint that LLM evaluators\nexhibit varying uncertainty based on model families and sizes. With careful\ncomparative analyses, we find that employing special prompting strategies,\nwhether during inference or post-training, can alleviate evaluation uncertainty\nto some extent. By utilizing uncertainty to enhance LLM's reliability and\ndetection capability in Out-Of-Distribution (OOD) data, we further fine-tune an\nuncertainty-aware LLM evaluator named ConfiLM using a human-annotated\nfine-tuning set and assess ConfiLM's OOD evaluation ability on a manually\ndesigned test set sourced from the 2024 Olympics. Experimental results\ndemonstrate that incorporating uncertainty as additional information during the\nfine-tuning phase can largely improve the model's evaluation performance in OOD\nscenarios. The code and data are released at:\nhttps://github.com/hasakiXie123/LLM-Evaluator-Uncertainty.", "paper_summary_zh": "\u96a8\u8457 LLM \u4f5c\u70ba\u6cd5\u5b98\u7684\u65b0\u5178\u7bc4\u51fa\u73fe\uff0c\u7528\u65bc\u8a55\u4f30\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684 LLM \u8a55\u4f30\u5668\u5728\u5c0d\u9f4a\u3001\u504f\u5dee\u548c\u7a69\u5b9a\u6027\u65b9\u9762\u5f15\u767c\u4e86\u95dc\u6ce8\u3002\u5118\u7ba1\u5927\u91cf\u5de5\u4f5c\u96c6\u4e2d\u5728\u5c0d\u9f4a\u548c\u504f\u5dee\u4e0a\uff0c\u4f46\u5f88\u5c11\u6709\u7814\u7a76\u96c6\u4e2d\u5728 LLM \u8a55\u4f30\u5668\u7684\u7a69\u5b9a\u6027\u4e0a\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u9032\u884c\u4e86\u5ee3\u6cdb\u7684\u5be6\u9a57\uff0c\u6d89\u53ca 9 \u500b\u5ee3\u6cdb\u4f7f\u7528\u7684 LLM \u8a55\u4f30\u5668\uff0c\u8de8\u8d8a 2 \u500b\u4e0d\u540c\u7684\u8a55\u4f30\u8a2d\u5b9a\uff0c\u4ee5\u8abf\u67e5\u57fa\u65bc\u6a21\u578b\u7684 LLM \u8a55\u4f30\u4e2d\u7684\u4e0d\u78ba\u5b9a\u6027\u3002\u6211\u5011\u7cbe\u78ba\u6307\u51fa LLM \u8a55\u4f30\u5668\u6839\u64da\u6a21\u578b\u7cfb\u5217\u548c\u5927\u5c0f\u8868\u73fe\u51fa\u4e0d\u540c\u7684\u4e0d\u78ba\u5b9a\u6027\u3002\u901a\u904e\u4ed4\u7d30\u7684\u6bd4\u8f03\u5206\u6790\uff0c\u6211\u5011\u767c\u73fe\u63a1\u7528\u7279\u6b8a\u7684\u63d0\u793a\u7b56\u7565\uff08\u7121\u8ad6\u662f\u5728\u63a8\u7406\u904e\u7a0b\u4e2d\u9084\u662f\u8a13\u7df4\u5f8c\uff09\u53ef\u4ee5\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u7de9\u89e3\u8a55\u4f30\u4e0d\u78ba\u5b9a\u6027\u3002\u901a\u904e\u5229\u7528\u4e0d\u78ba\u5b9a\u6027\u4f86\u589e\u5f37 LLM \u5728 Out-Of-Distribution (OOD) \u6578\u64da\u4e2d\u7684\u53ef\u9760\u6027\u548c\u6aa2\u6e2c\u80fd\u529b\uff0c\u6211\u5011\u9032\u4e00\u6b65\u5fae\u8abf\u4e86\u4e00\u500b\u540d\u70ba ConfiLM \u7684\u4e0d\u78ba\u5b9a\u6027\u611f\u77e5 LLM \u8a55\u4f30\u5668\uff0c\u4f7f\u7528\u4eba\u5de5\u8a3b\u91cb\u7684\u5fae\u8abf\u8a2d\u7f6e\uff0c\u4e26\u8a55\u4f30 ConfiLM \u5728\u624b\u52d5\u8a2d\u8a08\u7684\u3001\u4f86\u81ea 2024 \u5e74\u5967\u904b\u6703\u7684\u6e2c\u8a66\u96c6\u4e0a\u7684 OOD \u8a55\u4f30\u80fd\u529b\u3002\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0c\u5728\u5fae\u8abf\u968e\u6bb5\u5c07\u4e0d\u78ba\u5b9a\u6027\u4f5c\u70ba\u9644\u52a0\u4fe1\u606f\u7d0d\u5165\u5176\u4e2d\u53ef\u4ee5\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u63d0\u9ad8\u6a21\u578b\u5728 OOD \u5834\u666f\u4e2d\u7684\u8a55\u4f30\u6027\u80fd\u3002\u4ee3\u78bc\u548c\u6578\u64da\u767c\u5e03\u65bc\uff1a\nhttps://github.com/hasakiXie123/LLM-Evaluator-Uncertainty\u3002", "author": "Qiujie Xie et.al.", "authors": "Qiujie Xie, Qingqiu Li, Zhuohao Yu, Yuejie Zhang, Yue Zhang, Linyi Yang", "id": "2502.10709v1", "paper_url": "http://arxiv.org/abs/2502.10709v1", "repo": "null"}}