{"2406.12655": {"publish_time": "2024-06-18", "title": "Benchmarks and Metrics for Evaluations of Code Generation: A Critical Review", "paper_summary": "With the rapid development of Large Language Models (LLMs), a large number of\nmachine learning models have been developed to assist programming tasks\nincluding the generation of program code from natural language input. However,\nhow to evaluate such LLMs for this task is still an open problem despite of the\ngreat amount of research efforts that have been made and reported to evaluate\nand compare them. This paper provides a critical review of the existing work on\nthe testing and evaluation of these tools with a focus on two key aspects: the\nbenchmarks and the metrics used in the evaluations. Based on the review,\nfurther research directions are discussed.", "paper_summary_zh": "\u96a8\u8457\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u5feb\u901f\u767c\u5c55\uff0c\u5df2\u958b\u767c\u51fa\u5927\u91cf\u6a5f\u5668\u5b78\u7fd2\u6a21\u578b\u4f86\u5354\u52a9\u7a0b\u5f0f\u8a2d\u8a08\u4efb\u52d9\uff0c\u5305\u62ec\u5f9e\u81ea\u7136\u8a9e\u8a00\u8f38\u5165\u7522\u751f\u7a0b\u5f0f\u78bc\u3002\u7136\u800c\uff0c\u5982\u4f55\u8a55\u4f30\u6b64\u985e LLM \u4ecd\u662f\u4e00\u500b\u958b\u653e\u6027\u554f\u984c\uff0c\u5118\u7ba1\u5df2\u6295\u5165\u5927\u91cf\u7814\u7a76\u5de5\u4f5c\u4e26\u64da\u4ee5\u8a55\u4f30\u548c\u6bd4\u8f03\u5b83\u5011\u3002\u672c\u6587\u5c0d\u9019\u4e9b\u5de5\u5177\u7684\u6e2c\u8a66\u548c\u8a55\u4f30\u73fe\u6709\u5de5\u4f5c\u9032\u884c\u4e86\u6279\u5224\u6027\u56de\u9867\uff0c\u91cd\u9ede\u95dc\u6ce8\u5169\u500b\u95dc\u9375\u65b9\u9762\uff1a\u8a55\u4f30\u4e2d\u4f7f\u7528\u7684\u57fa\u6e96\u548c\u6307\u6a19\u3002\u6839\u64da\u56de\u9867\uff0c\u8a0e\u8ad6\u4e86\u9032\u4e00\u6b65\u7684\u7814\u7a76\u65b9\u5411\u3002", "author": "Debalina Ghosh Paul et.al.", "authors": "Debalina Ghosh Paul, Hong Zhu, Ian Bayley", "id": "2406.12655v1", "paper_url": "http://arxiv.org/abs/2406.12655v1", "repo": "null"}}