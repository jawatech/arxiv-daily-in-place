{"2408.16442": {"publish_time": "2024-08-29", "title": "Integrating Features for Recognizing Human Activities through Optimized Parameters in Graph Convolutional Networks and Transformer Architectures", "paper_summary": "Human activity recognition is a major field of study that employs computer\nvision, machine vision, and deep learning techniques to categorize human\nactions. The field of deep learning has made significant progress, with\narchitectures that are extremely effective at capturing human dynamics. This\nstudy emphasizes the influence of feature fusion on the accuracy of activity\nrecognition. This technique addresses the limitation of conventional models,\nwhich face difficulties in identifying activities because of their limited\ncapacity to understand spatial and temporal features. The technique employs\nsensory data obtained from four publicly available datasets: HuGaDB, PKU-MMD,\nLARa, and TUG. The accuracy and F1-score of two deep learning models,\nspecifically a Transformer model and a Parameter-Optimized Graph Convolutional\nNetwork (PO-GCN), were evaluated using these datasets. The feature fusion\ntechnique integrated the final layer features from both models and inputted\nthem into a classifier. Empirical evidence demonstrates that PO-GCN outperforms\nstandard models in activity recognition. HuGaDB demonstrated a 2.3% improvement\nin accuracy and a 2.2% increase in F1-score. TUG showed a 5% increase in\naccuracy and a 0.5% rise in F1-score. On the other hand, LARa and PKU-MMD\nachieved lower accuracies of 64% and 69% respectively. This indicates that the\nintegration of features enhanced the performance of both the Transformer model\nand PO-GCN.", "paper_summary_zh": "\u4eba\u985e\u6d3b\u52d5\u8b58\u5225\u662f\u904b\u7528\u96fb\u8166\u8996\u89ba\u3001\u6a5f\u5668\u8996\u89ba\u548c\u6df1\u5ea6\u5b78\u7fd2\u6280\u8853\u4f86\u5206\u985e\u4eba\u985e\u52d5\u4f5c\u7684\u4e3b\u8981\u7814\u7a76\u9818\u57df\u3002\u6df1\u5ea6\u5b78\u7fd2\u9818\u57df\u5df2\u53d6\u5f97\u986f\u8457\u9032\u5c55\uff0c\u5176\u67b6\u69cb\u5728\u6355\u6349\u4eba\u985e\u52d5\u614b\u65b9\u9762\u975e\u5e38\u6709\u6548\u3002\u672c\u7814\u7a76\u5f37\u8abf\u7279\u5fb5\u878d\u5408\u5c0d\u6d3b\u52d5\u8b58\u5225\u6e96\u78ba\u6027\u7684\u5f71\u97ff\u3002\u6b64\u6280\u8853\u89e3\u6c7a\u4e86\u50b3\u7d71\u6a21\u578b\u7684\u9650\u5236\uff0c\u50b3\u7d71\u6a21\u578b\u7531\u65bc\u7406\u89e3\u7a7a\u9593\u548c\u6642\u9593\u7279\u5fb5\u7684\u80fd\u529b\u6709\u9650\uff0c\u5728\u8b58\u5225\u6d3b\u52d5\u65b9\u9762\u9762\u81e8\u56f0\u96e3\u3002\u6b64\u6280\u8853\u63a1\u7528\u5f9e\u56db\u500b\u516c\u958b\u53ef\u7528\u7684\u6578\u64da\u96c6\u53d6\u5f97\u7684\u611f\u6e2c\u8cc7\u6599\uff1aHuGaDB\u3001PKU-MMD\u3001LARa \u548c TUG\u3002\u4f7f\u7528\u9019\u4e9b\u6578\u64da\u96c6\u8a55\u4f30\u4e86\u5169\u500b\u6df1\u5ea6\u5b78\u7fd2\u6a21\u578b\uff08\u7279\u5225\u662f Transformer \u6a21\u578b\u548c\u53c3\u6578\u512a\u5316\u7684\u5716\u5f62\u5377\u7a4d\u7db2\u8def (PO-GCN)\uff09\u7684\u6e96\u78ba\u6027\u548c F1 \u5206\u6578\u3002\u7279\u5fb5\u878d\u5408\u6280\u8853\u6574\u5408\u4e86\u4f86\u81ea\u5169\u500b\u6a21\u578b\u7684\u6700\u7d42\u5c64\u7279\u5fb5\uff0c\u4e26\u5c07\u5b83\u5011\u8f38\u5165\u5206\u985e\u5668\u3002\u5be6\u8b49\u8b49\u64da\u8868\u660e\uff0cPO-GCN \u5728\u6d3b\u52d5\u8b58\u5225\u65b9\u9762\u512a\u65bc\u6a19\u6e96\u6a21\u578b\u3002HuGaDB \u7684\u6e96\u78ba\u6027\u63d0\u9ad8\u4e86 2.3%\uff0cF1 \u5206\u6578\u63d0\u9ad8\u4e86 2.2%\u3002TUG \u7684\u6e96\u78ba\u6027\u63d0\u9ad8\u4e86 5%\uff0cF1 \u5206\u6578\u63d0\u9ad8\u4e86 0.5%\u3002\u53e6\u4e00\u65b9\u9762\uff0cLARa \u548c PKU-MMD \u5206\u5225\u9054\u5230\u4e86\u8f03\u4f4e\u7684\u6e96\u78ba\u5ea6 64% \u548c 69%\u3002\u9019\u8868\u660e\u7279\u5fb5\u7684\u6574\u5408\u589e\u5f37\u4e86 Transformer \u6a21\u578b\u548c PO-GCN \u7684\u6548\u80fd\u3002", "author": "Mohammad Belal et.al.", "authors": "Mohammad Belal, Taimur Hassan, Abdelfatah Hassan, Nael Alsheikh, Noureldin Elhendawi, Irfan Hussain", "id": "2408.16442v1", "paper_url": "http://arxiv.org/abs/2408.16442v1", "repo": "null"}}