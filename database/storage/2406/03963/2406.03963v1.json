{"2406.03963": {"publish_time": "2024-06-06", "title": "A + B: A General Generator-Reader Framework for Optimizing LLMs to Unleash Synergy Potential", "paper_summary": "Retrieval-Augmented Generation (RAG) is an effective solution to supplement\nnecessary knowledge to large language models (LLMs). Targeting its bottleneck\nof retriever performance, \"generate-then-read\" pipeline is proposed to replace\nthe retrieval stage with generation from the LLM itself. Although promising,\nthis research direction is underexplored and still cannot work in the scenario\nwhen source knowledge is given. In this paper, we formalize a general \"A + B\"\nframework with varying combinations of foundation models and types for\nsystematic investigation. We explore the efficacy of the base and chat versions\nof LLMs and found their different functionalities suitable for generator A and\nreader B, respectively. Their combinations consistently outperform single\nmodels, especially in complex scenarios. Furthermore, we extend the application\nof the \"A + B\" framework to scenarios involving source documents through\ncontinuous learning, enabling the direct integration of external knowledge into\nLLMs. This approach not only facilitates effective acquisition of new knowledge\nbut also addresses the challenges of safety and helpfulness post-adaptation.\nThe paper underscores the versatility of the \"A + B\" framework, demonstrating\nits potential to enhance the practical application of LLMs across various\ndomains.", "paper_summary_zh": "\u64f7\u53d6\u589e\u5f37\u751f\u6210\uff08RAG\uff09\u662f\u4e00\u7a2e\u6709\u6548\u7684\u89e3\u6c7a\u65b9\u6848\uff0c\u53ef\u4ee5\u70ba\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u88dc\u5145\u5fc5\u8981\u7684\u77e5\u8b58\u3002\u91dd\u5c0d\u5176\u64f7\u53d6\u5668\u6548\u80fd\u7684\u74f6\u9838\uff0c\u63d0\u8b70\u4f7f\u7528\u300c\u5148\u7522\u751f\u518d\u95b1\u8b80\u300d\u7ba1\u7dda\uff0c\u4ee5 LLM \u672c\u8eab\u7684\u7522\u751f\u53d6\u4ee3\u64f7\u53d6\u968e\u6bb5\u3002\u5118\u7ba1\u5f88\u6709\u524d\u666f\uff0c\u4f46\u9019\u500b\u7814\u7a76\u65b9\u5411\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u8a0e\uff0c\u800c\u4e14\u5728\u63d0\u4f9b\u4f86\u6e90\u77e5\u8b58\u7684\u60c5\u6cc1\u4e0b\u4ecd\u7136\u7121\u6cd5\u904b\u4f5c\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u6b63\u5f0f\u5236\u5b9a\u4e86\u4e00\u500b\u901a\u7528\u7684\u300cA + B\u300d\u67b6\u69cb\uff0c\u5176\u4e2d\u5305\u542b\u57fa\u790e\u6a21\u578b\u548c\u985e\u578b\u4e0d\u540c\u7684\u7d44\u5408\uff0c\u4ee5\u9032\u884c\u7cfb\u7d71\u6027\u7684\u8abf\u67e5\u3002\u6211\u5011\u63a2\u8a0e\u4e86 LLM \u7684\u57fa\u790e\u7248\u672c\u548c\u804a\u5929\u6a5f\u5668\u4eba\u7248\u672c\u7684\u529f\u6548\uff0c\u4e26\u767c\u73fe\u5b83\u5011\u4e0d\u540c\u7684\u529f\u80fd\u5206\u5225\u9069\u7528\u65bc\u7522\u751f\u5668 A \u548c\u95b1\u8b80\u5668 B\u3002\u5b83\u5011\u7684\u7d44\u5408\u59cb\u7d42\u512a\u65bc\u55ae\u4e00\u6a21\u578b\uff0c\u5c24\u5176\u662f\u5728\u8907\u96dc\u7684\u5834\u666f\u4e2d\u3002\u6b64\u5916\uff0c\u6211\u5011\u900f\u904e\u6301\u7e8c\u5b78\u7fd2\u5c07\u300cA + B\u300d\u67b6\u69cb\u7684\u61c9\u7528\u64f4\u5c55\u5230\u6d89\u53ca\u4f86\u6e90\u6587\u4ef6\u7684\u5834\u666f\uff0c\u8b93\u5916\u90e8\u77e5\u8b58\u80fd\u5920\u76f4\u63a5\u6574\u5408\u5230 LLM \u4e2d\u3002\u9019\u7a2e\u65b9\u6cd5\u4e0d\u50c5\u6709\u52a9\u65bc\u6709\u6548\u7372\u53d6\u65b0\u77e5\u8b58\uff0c\u9084\u80fd\u89e3\u6c7a\u9069\u61c9\u5f8c\u5b89\u5168\u6027\u8207\u6709\u76ca\u6027\u7684\u6311\u6230\u3002\u672c\u6587\u5f37\u8abf\u4e86\u300cA + B\u300d\u67b6\u69cb\u7684\u591a\u529f\u80fd\u6027\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5404\u7a2e\u9818\u57df\u589e\u5f37 LLM \u5be6\u969b\u61c9\u7528\u7684\u6f5b\u529b\u3002", "author": "Wei Tang et.al.", "authors": "Wei Tang, Yixin Cao, Jiahao Ying, Bo Wang, Yuyue Zhao, Yong Liao, Pengyuan Zhou", "id": "2406.03963v1", "paper_url": "http://arxiv.org/abs/2406.03963v1", "repo": "null"}}