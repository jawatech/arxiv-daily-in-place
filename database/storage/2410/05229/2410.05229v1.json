{"2410.05229": {"publish_time": "2024-10-07", "title": "GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models", "paper_summary": "Recent advancements in Large Language Models (LLMs) have sparked interest in\ntheir formal reasoning capabilities, particularly in mathematics. The GSM8K\nbenchmark is widely used to assess the mathematical reasoning of models on\ngrade-school-level questions. While the performance of LLMs on GSM8K has\nsignificantly improved in recent years, it remains unclear whether their\nmathematical reasoning capabilities have genuinely advanced, raising questions\nabout the reliability of the reported metrics. To address these concerns, we\nconduct a large-scale study on several SOTA open and closed models. To overcome\nthe limitations of existing evaluations, we introduce GSM-Symbolic, an improved\nbenchmark created from symbolic templates that allow for the generation of a\ndiverse set of questions. GSM-Symbolic enables more controllable evaluations,\nproviding key insights and more reliable metrics for measuring the reasoning\ncapabilities of models.Our findings reveal that LLMs exhibit noticeable\nvariance when responding to different instantiations of the same question.\nSpecifically, the performance of all models declines when only the numerical\nvalues in the question are altered in the GSM-Symbolic benchmark. Furthermore,\nwe investigate the fragility of mathematical reasoning in these models and show\nthat their performance significantly deteriorates as the number of clauses in a\nquestion increases. We hypothesize that this decline is because current LLMs\ncannot perform genuine logical reasoning; they replicate reasoning steps from\ntheir training data. Adding a single clause that seems relevant to the question\ncauses significant performance drops (up to 65%) across all state-of-the-art\nmodels, even though the clause doesn't contribute to the reasoning chain needed\nfor the final answer. Overall, our work offers a more nuanced understanding of\nLLMs' capabilities and limitations in mathematical reasoning.", "paper_summary_zh": "<paragraph>\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u6700\u8fd1\u7684\u9032\u5c55\uff0c\u6fc0\u767c\u4e86\u4eba\u5011\u5c0d\u5176\u5f62\u5f0f\u63a8\u7406\u80fd\u529b\u7684\u8208\u8da3\uff0c\u7279\u5225\u662f\u5728\u6578\u5b78\u65b9\u9762\u3002GSM8K \u57fa\u6e96\u5ee3\u6cdb\u7528\u65bc\u8a55\u4f30\u6a21\u578b\u5728\u5c0f\u5b78\u7a0b\u5ea6\u554f\u984c\u4e0a\u7684\u6578\u5b78\u63a8\u7406\u80fd\u529b\u3002\u5118\u7ba1\u8fd1\u5e74\u4f86 LLM \u5728 GSM8K \u4e0a\u7684\u8868\u73fe\u6709\u4e86\u986f\u8457\u63d0\u5347\uff0c\u4f46\u5176\u6578\u5b78\u63a8\u7406\u80fd\u529b\u662f\u5426\u771f\u6b63\u9032\u6b65\u4ecd\u4e0d\u6e05\u695a\uff0c\u9019\u5f15\u767c\u4e86\u5c0d\u5831\u544a\u6307\u6a19\u53ef\u9760\u6027\u7684\u8cea\u7591\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u554f\u984c\uff0c\u6211\u5011\u5c0d\u5e7e\u500b SOTA \u958b\u653e\u548c\u5c01\u9589\u6a21\u578b\u9032\u884c\u4e86\u5927\u898f\u6a21\u7814\u7a76\u3002\u70ba\u4e86\u514b\u670d\u73fe\u6709\u8a55\u4f30\u7684\u9650\u5236\uff0c\u6211\u5011\u5f15\u5165\u4e86 GSM-Symbolic\uff0c\u9019\u662f\u4e00\u500b\u5f9e\u7b26\u865f\u6a21\u677f\u5275\u5efa\u7684\u6539\u9032\u57fa\u6e96\uff0c\u5141\u8a31\u751f\u6210\u591a\u6a23\u5316\u7684\u554f\u984c\u96c6\u3002GSM-Symbolic \u80fd\u5920\u9032\u884c\u66f4\u53ef\u63a7\u7684\u8a55\u4f30\uff0c\u70ba\u8861\u91cf\u6a21\u578b\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u95dc\u9375\u898b\u89e3\u548c\u66f4\u53ef\u9760\u7684\u6307\u6a19\u3002\u6211\u5011\u7684\u7814\u7a76\u7d50\u679c\u8868\u660e\uff0cLLM \u5728\u56de\u7b54\u540c\u4e00\u554f\u984c\u7684\u4e0d\u540c\u5be6\u4f8b\u6642\u8868\u73fe\u51fa\u660e\u986f\u7684\u5dee\u7570\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u7576 GSM-Symbolic \u57fa\u6e96\u4e2d\u50c5\u66f4\u6539\u554f\u984c\u4e2d\u7684\u6578\u503c\u6642\uff0c\u6240\u6709\u6a21\u578b\u7684\u6027\u80fd\u90fd\u6703\u4e0b\u964d\u3002\u6b64\u5916\uff0c\u6211\u5011\u7814\u7a76\u4e86\u9019\u4e9b\u6a21\u578b\u4e2d\u6578\u5b78\u63a8\u7406\u7684\u8106\u5f31\u6027\uff0c\u4e26\u8868\u660e\u96a8\u8457\u554f\u984c\u4e2d\u5b50\u53e5\u6578\u91cf\u7684\u589e\u52a0\uff0c\u5b83\u5011\u7684\u6027\u80fd\u6703\u986f\u8457\u4e0b\u964d\u3002\u6211\u5011\u5047\u8a2d\u9019\u7a2e\u4e0b\u964d\u662f\u56e0\u70ba\u7576\u524d\u7684 LLM \u7121\u6cd5\u57f7\u884c\u771f\u6b63\u7684\u908f\u8f2f\u63a8\u7406\uff1b\u5b83\u5011\u5f9e\u8a13\u7df4\u6578\u64da\u4e2d\u8907\u88fd\u63a8\u7406\u6b65\u9a5f\u3002\u6dfb\u52a0\u4e00\u500b\u770b\u4f3c\u8207\u554f\u984c\u76f8\u95dc\u7684\u55ae\u4e00\u5b50\u53e5\u6703\u5c0e\u81f4\u6240\u6709\u6700\u5148\u9032\u6a21\u578b\u7684\u6027\u80fd\u986f\u8457\u4e0b\u964d\uff08\u9ad8\u9054 65%\uff09\uff0c\u5373\u4f7f\u8a72\u5b50\u53e5\u4e0d\u6703\u5f71\u97ff\u6700\u7d42\u7b54\u6848\u6240\u9700\u7684\u63a8\u7406\u93c8\u3002\u7e3d\u7684\u4f86\u8aaa\uff0c\u6211\u5011\u7684\u7814\u7a76\u5c0d LLM \u5728\u6578\u5b78\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\u548c\u5c40\u9650\u6027\u63d0\u4f9b\u4e86\u66f4\u7d30\u7dfb\u7684\u7406\u89e3\u3002</paragraph>", "author": "Iman Mirzadeh et.al.", "authors": "Iman Mirzadeh, Keivan Alizadeh, Hooman Shahrokhi, Oncel Tuzel, Samy Bengio, Mehrdad Farajtabar", "id": "2410.05229v1", "paper_url": "http://arxiv.org/abs/2410.05229v1", "repo": "null"}}