{"2411.11016": {"publish_time": "2024-11-17", "title": "Time Step Generating: A Universal Synthesized Deepfake Image Detector", "paper_summary": "Currently, high-fidelity text-to-image models are developed in an\naccelerating pace. Among them, Diffusion Models have led to a remarkable\nimprovement in the quality of image generation, making it vary challenging to\ndistinguish between real and synthesized images. It simultaneously raises\nserious concerns regarding privacy and security. Some methods are proposed to\ndistinguish the diffusion model generated images through reconstructing.\nHowever, the inversion and denoising processes are time-consuming and heavily\nreliant on the pre-trained generative model. Consequently, if the pre-trained\ngenerative model meet the problem of out-of-domain, the detection performance\ndeclines. To address this issue, we propose a universal synthetic image\ndetector Time Step Generating (TSG), which does not rely on pre-trained models'\nreconstructing ability, specific datasets, or sampling algorithms. Our method\nutilizes a pre-trained diffusion model's network as a feature extractor to\ncapture fine-grained details, focusing on the subtle differences between real\nand synthetic images. By controlling the time step t of the network input, we\ncan effectively extract these distinguishing detail features. Then, those\nfeatures can be passed through a classifier (i.e. Resnet), which efficiently\ndetects whether an image is synthetic or real. We test the proposed TSG on the\nlarge-scale GenImage benchmark and it achieves significant improvements in both\naccuracy and generalizability.", "paper_summary_zh": "\u76ee\u524d\uff0c\u9ad8\u4fdd\u771f\u6587\u5b57\u8f49\u5716\u50cf\u6a21\u578b\u6b63\u4ee5\u52a0\u901f\u7684\u901f\u5ea6\u767c\u5c55\u3002\u5176\u4e2d\uff0c\u64f4\u6563\u6a21\u578b\u5df2\u986f\u8457\u63d0\u5347\u5f71\u50cf\u751f\u6210\u7684\u54c1\u8cea\uff0c\u8b93\u4eba\u96e3\u4ee5\u5340\u5206\u771f\u5be6\u5f71\u50cf\u8207\u5408\u6210\u5f71\u50cf\u3002\u9019\u540c\u6642\u4e5f\u5f15\u767c\u4e86\u5c0d\u65bc\u96b1\u79c1\u548c\u5b89\u5168\u7684\u56b4\u91cd\u7591\u616e\u3002\u6709\u4eba\u63d0\u51fa\u4e86\u4e00\u4e9b\u65b9\u6cd5\uff0c\u900f\u904e\u91cd\u5efa\u4f86\u5340\u5206\u64f4\u6563\u6a21\u578b\u7522\u751f\u7684\u5f71\u50cf\u3002\u7136\u800c\uff0c\u53cd\u8f49\u548c\u53bb\u566a\u7684\u904e\u7a0b\u8017\u6642\u4e14\u9ad8\u5ea6\u4f9d\u8cf4\u9810\u5148\u8a13\u7df4\u7684\u751f\u6210\u6a21\u578b\u3002\u56e0\u6b64\uff0c\u5982\u679c\u9810\u5148\u8a13\u7df4\u7684\u751f\u6210\u6a21\u578b\u9047\u5230\u9818\u57df\u5916\u554f\u984c\uff0c\u5075\u6e2c\u6548\u80fd\u5c31\u6703\u4e0b\u964d\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u7a2e\u901a\u7528\u7684\u5408\u6210\u5f71\u50cf\u5075\u6e2c\u5668\u6642\u9593\u6b65\u9a5f\u751f\u6210 (TSG)\uff0c\u5b83\u4e0d\u4f9d\u8cf4\u9810\u5148\u8a13\u7df4\u6a21\u578b\u7684\u91cd\u5efa\u80fd\u529b\u3001\u7279\u5b9a\u8cc7\u6599\u96c6\u6216\u62bd\u6a23\u6f14\u7b97\u6cd5\u3002\u6211\u5011\u7684\u6280\u8853\u5229\u7528\u9810\u5148\u8a13\u7df4\u7684\u64f4\u6563\u6a21\u578b\u7684\u7db2\u8def\u4f5c\u70ba\u7279\u5fb5\u8403\u53d6\u5668\uff0c\u4ee5\u64f7\u53d6\u7d30\u5fae\u7684\u7d30\u7bc0\uff0c\u4e26\u5c08\u6ce8\u65bc\u771f\u5be6\u5f71\u50cf\u8207\u5408\u6210\u5f71\u50cf\u4e4b\u9593\u7684\u7d30\u5fae\u5dee\u7570\u3002\u900f\u904e\u63a7\u5236\u7db2\u8def\u8f38\u5165\u7684\u6642\u9593\u6b65\u9a5f t\uff0c\u6211\u5011\u53ef\u4ee5\u6709\u6548\u8403\u53d6\u9019\u4e9b\u5340\u5225\u6027\u7684\u7d30\u7bc0\u7279\u5fb5\u3002\u7136\u5f8c\uff0c\u9019\u4e9b\u7279\u5fb5\u53ef\u4ee5\u50b3\u905e\u5230\u5206\u985e\u5668 (\u4f8b\u5982 Resnet)\uff0c\u5b83\u53ef\u4ee5\u6709\u6548\u5075\u6e2c\u5f71\u50cf\u662f\u5426\u70ba\u5408\u6210\u6216\u771f\u5be6\u3002\u6211\u5011\u5728\u5927\u578b GenImage \u57fa\u6e96\u4e0a\u6e2c\u8a66\u6240\u63d0\u51fa\u7684 TSG\uff0c\u7d50\u679c\u5728\u6e96\u78ba\u5ea6\u548c\u6982\u62ec\u6027\u65b9\u9762\u90fd\u6709\u986f\u8457\u7684\u63d0\u5347\u3002", "author": "Ziyue Zeng et.al.", "authors": "Ziyue Zeng, Haoyuan Liu, Dingjie Peng, Luoxu Jing, Hiroshi Watanabe", "id": "2411.11016v1", "paper_url": "http://arxiv.org/abs/2411.11016v1", "repo": "null"}}