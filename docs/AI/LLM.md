
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-01-17**|**Agent4Edu: Generating Learner Response Data by Generative Agents for Intelligent Education Systems**|Weibo Gao et.al.|[2501.10332v1](http://arxiv.org/abs/2501.10332v1)|null|
|**2025-01-17**|**BoK: Introducing Bag-of-Keywords Loss for Interpretable Dialogue Response Generation**|Suvodip Dey et.al.|[2501.10328v1](http://arxiv.org/abs/2501.10328v1)|[link](https://github.com/suvodipdey/bok)|
|**2025-01-17**|**Large language models for automated scholarly paper review: A survey**|Zhenzhen Zhuang et.al.|[2501.10326v1](http://arxiv.org/abs/2501.10326v1)|null|
|**2025-01-17**|**Hierarchical Autoregressive Transformers: Combining Byte-~and Word-Level Processing for Robust, Adaptable Language Models**|Pit Neitemeier et.al.|[2501.10322v1](http://arxiv.org/abs/2501.10322v1)|null|
|**2025-01-17**|**Natural Language Processing of Privacy Policies: A Survey**|Andrick Adhikari et.al.|[2501.10319v1](http://arxiv.org/abs/2501.10319v1)|null|
|**2025-01-17**|**Towards Preventing Overreliance on Task-Oriented Conversational AI Through Accountability Modeling**|Suvodip Dey et.al.|[2501.10316v1](http://arxiv.org/abs/2501.10316v1)|[link](https://github.com/uiuc-conversational-ai-lab/accountable-dst)|
|**2025-01-17**|**Computational Protein Science in the Era of Large Language Models (LLMs)**|Wenqi Fan et.al.|[2501.10282v1](http://arxiv.org/abs/2501.10282v1)|null|
|**2025-01-17**|**SEANN: A Domain-Informed Neural Network for Epidemiological Insights**|Jean-Baptiste Guimbaud et.al.|[2501.10273v1](http://arxiv.org/abs/2501.10273v1)|null|
|**2025-01-17**|**Unsupervised Rhythm and Voice Conversion of Dysarthric to Healthy Speech for ASR**|Karl El Hajal et.al.|[2501.10256v1](http://arxiv.org/abs/2501.10256v1)|null|
|**2025-01-17**|**Challenges and recommendations for Electronic Health Records data extraction and preparation for dynamic prediction modelling in hospitalized patients -- a practical guide**|Elena Albu et.al.|[2501.10240v1](http://arxiv.org/abs/2501.10240v1)|null|
|**2025-01-17**|**Temporal Causal Reasoning with (Non-Recursive) Structural Equation Models**|Maksim Gladyshev et.al.|[2501.10190v1](http://arxiv.org/abs/2501.10190v1)|null|
|**2025-01-17**|**Generative Artificial Intelligence: Implications for Biomedical and Health Professions Education**|William Hersh et.al.|[2501.10186v1](http://arxiv.org/abs/2501.10186v1)|null|
|**2025-01-17**|**A Simple but Effective Closed-form Solution for Extreme Multi-label Learning**|Kazuma Onishi et.al.|[2501.10179v1](http://arxiv.org/abs/2501.10179v1)|[link](https://github.com/cars1015/xml-ridge)|
|**2025-01-17**|**Multi-stage Training of Bilingual Islamic LLM for Neural Passage Retrieval**|Vera Pavlova et.al.|[2501.10175v1](http://arxiv.org/abs/2501.10175v1)|null|
|**2025-01-17**|**CSSDM Ontology to Enable Continuity of Care Data Interoperability**|Subhashis Das et.al.|[2501.10160v1](http://arxiv.org/abs/2501.10160v1)|null|
|**2025-01-17**|**Region-wise stacking ensembles for estimating brain-age using MRI**|Georgios Antonopoulos et.al.|[2501.10153v1](http://arxiv.org/abs/2501.10153v1)|null|
|**2025-01-17**|**Dual Debiasing: Remove Stereotypes and Keep Factual Gender for Fair Language Modeling and Translation**|Tomasz Limisiewicz et.al.|[2501.10150v1](http://arxiv.org/abs/2501.10150v1)|null|
|**2025-01-17**|**Exploring the Impact of Generative Artificial Intelligence in Education: A Thematic Analysis**|Abhishek Kaushik et.al.|[2501.10134v1](http://arxiv.org/abs/2501.10134v1)|null|
|**2025-01-17**|**ComplexFuncBench: Exploring Multi-Step and Constrained Function Calling under Long-Context Scenario**|Lucen Zhong et.al.|[2501.10132v1](http://arxiv.org/abs/2501.10132v1)|[link](https://github.com/thudm/complexfuncbench)|
|**2025-01-17**|**BBPOS: BERT-based Part-of-Speech Tagging for Uzbek**|Latofat Bobojonova et.al.|[2501.10107v1](http://arxiv.org/abs/2501.10107v1)|null|
|**2025-01-17**|**LLM Reasoner and Automated Planner: A new NPC approach**|Israel Puerta-Merino et.al.|[2501.10106v1](http://arxiv.org/abs/2501.10106v1)|null|
|**2025-01-17**|**Universal Actions for Enhanced Embodied Foundation Models**|Jinliang Zheng et.al.|[2501.10105v1](http://arxiv.org/abs/2501.10105v1)|[link](https://github.com/2toinf/uniact)|
|**2025-01-17**|**Robotic World Model: A Neural Network Simulator for Robust Policy Optimization in Robotics**|Chenhao Li et.al.|[2501.10100v1](http://arxiv.org/abs/2501.10100v1)|null|
|**2025-01-17**|**Robust Change Captioning in Remote Sensing: SECOND-CC Dataset and MModalCC Framework**|Ali Can Karaca et.al.|[2501.10075v1](http://arxiv.org/abs/2501.10075v1)|null|
|**2025-01-17**|**SpatialCoT: Advancing Spatial Reasoning through Coordinate Alignment and Chain-of-Thought for Embodied Task Planning**|Yuecheng Liu et.al.|[2501.10074v1](http://arxiv.org/abs/2501.10074v1)|null|
|**2025-01-17**|**Author-Specific Linguistic Patterns Unveiled: A Deep Learning Study on Word Class Distributions**|Patrick Krauss et.al.|[2501.10072v1](http://arxiv.org/abs/2501.10072v1)|null|
|**2025-01-17**|**A Survey on LLM Test-Time Compute via Search: Tasks, LLM Profiling, Search Algorithms, and Relevant Frameworks**|Xinzhe Li et.al.|[2501.10069v1](http://arxiv.org/abs/2501.10069v1)|null|
|**2025-01-17**|**OMoE: Diversifying Mixture of Low-Rank Adaptation by Orthogonal Finetuning**|Jinyuan Feng et.al.|[2501.10062v1](http://arxiv.org/abs/2501.10062v1)|null|
|**2025-01-17**|**MSTS: A Multimodal Safety Test Suite for Vision-Language Models**|Paul Röttger et.al.|[2501.10057v1](http://arxiv.org/abs/2501.10057v1)|[link](https://github.com/paul-rottger/msts-multimodal-safety)|
|**2025-01-17**|**Accelerating Large Language Models through Partially Linear Feed-Forward Network**|Gansen Hu et.al.|[2501.10054v1](http://arxiv.org/abs/2501.10054v1)|null|
|**2025-01-17**|**AirRAG: Activating Intrinsic Reasoning for Retrieval Augmented Generation via Tree-based Search**|Wenfeng Feng et.al.|[2501.10053v1](http://arxiv.org/abs/2501.10053v1)|null|
|**2025-01-17**|**Virtual Nodes Improve Long-term Traffic Prediction**|Xiaoyang Cao et.al.|[2501.10048v1](http://arxiv.org/abs/2501.10048v1)|null|
|**2025-01-17**|**Spatiotemporal Prediction of Secondary Crashes by Rebalancing Dynamic and Static Data with Generative Adversarial Networks**|Junlan Chen et.al.|[2501.10041v1](http://arxiv.org/abs/2501.10041v1)|null|
|**2025-01-17**|**Automatic Speech Recognition for Sanskrit with Transfer Learning**|Bidit Sadhukhan et.al.|[2501.10024v1](http://arxiv.org/abs/2501.10024v1)|null|
|**2025-01-17**|**Enhancing Crash Frequency Modeling Based on Augmented Multi-Type Data by Hybrid VAE-Diffusion-Based Generative Neural Networks**|Junlan Chen et.al.|[2501.10017v1](http://arxiv.org/abs/2501.10017v1)|null|
|**2025-01-17**|**Mitigating Hallucinations on Object Attributes using Multiview Images and Negative Instructions**|Zhijie Tan et.al.|[2501.10011v1](http://arxiv.org/abs/2501.10011v1)|null|
|**2025-01-17**|**Adaptive Spatiotemporal Augmentation for Improving Dynamic Graph Learning**|Xu Chu et.al.|[2501.10010v1](http://arxiv.org/abs/2501.10010v1)|[link](https://github.com/colinneverland/staa)|
|**2025-01-17**|**Deep Learning for Early Alzheimer Disease Detection with MRI Scans**|Mohammad Rafsan et.al.|[2501.09999v1](http://arxiv.org/abs/2501.09999v1)|[link](https://github.com/rafusan/dl-alzheimer)|
|**2025-01-17**|**Attention-guided Self-reflection for Zero-shot Hallucination Detection in Large Language Models**|Qiang Liu et.al.|[2501.09997v1](http://arxiv.org/abs/2501.09997v1)|null|
|**2025-01-17**|**Multi-Modal Attention Networks for Enhanced Segmentation and Depth Estimation of Subsurface Defects in Pulse Thermography**|Mohammed Salah et.al.|[2501.09994v1](http://arxiv.org/abs/2501.09994v1)|[link](https://github.com/mohammedsalah98/pt_fusion)|
|**2025-01-17**|**Agent-as-Judge for Factual Summarization of Long Narratives**|Yeonseok Jeong et.al.|[2501.09993v1](http://arxiv.org/abs/2501.09993v1)|null|
|**2025-01-17**|**RichSpace: Enriching Text-to-Video Prompt Space via Text Embedding Interpolation**|Yuefan Cao et.al.|[2501.09982v1](http://arxiv.org/abs/2501.09982v1)|null|
|**2025-01-17**|**Aneumo: A Large-Scale Comprehensive Synthetic Dataset of Aneurysm Hemodynamics**|Xigui Li et.al.|[2501.09980v1](http://arxiv.org/abs/2501.09980v1)|[link](https://github.com/xigui-li/aneumo)|
|**2025-01-17**|**GVMGen: A General Video-to-Music Generation Model with Hierarchical Attentions**|Heda Zuo et.al.|[2501.09972v1](http://arxiv.org/abs/2501.09972v1)|null|
|**2025-01-17**|**Explainable artificial intelligence (XAI): from inherent explainability to large language models**|Fuseini Mumuni et.al.|[2501.09967v1](http://arxiv.org/abs/2501.09967v1)|null|
|**2025-01-17**|**A Survey on Multi-Turn Interaction Capabilities of Large Language Models**|Chen Zhang et.al.|[2501.09959v1](http://arxiv.org/abs/2501.09959v1)|null|
|**2025-01-17**|**FRAG: A Flexible Modular Framework for Retrieval-Augmented Generation based on Knowledge Graphs**|Zengyi Gao et.al.|[2501.09957v1](http://arxiv.org/abs/2501.09957v1)|null|
|**2025-01-17**|**AIRCHITECT v2: Learning the Hardware Accelerator Design Space through Unified Representations**|Jamin Seo et.al.|[2501.09954v1](http://arxiv.org/abs/2501.09954v1)|[link](https://github.com/maestro-project/airchitect-v2)|
|**2025-01-17**|**Sympathy over Polarization: A Computational Discourse Analysis of Social Media Posts about the July 2024 Trump Assassination Attempt**|Qingcheng Zeng et.al.|[2501.09950v1](http://arxiv.org/abs/2501.09950v1)|null|
|**2025-01-17**|**MultiPruner: Balanced Structure Removal in Foundation Models**|J. Pablo Muñoz et.al.|[2501.09949v1](http://arxiv.org/abs/2501.09949v1)|[link](https://github.com/intellabs/hardware-aware-automated-machine-learning)|
|**2025-01-17**|**AI Explainability for Power Electronics: From a Lipschitz Continuity Perspective**|Xinze Li et.al.|[2501.09948v1](http://arxiv.org/abs/2501.09948v1)|null|
|**2025-01-17**|**Client-Centric Federated Adaptive Optimization**|Jianhui Sun et.al.|[2501.09946v1](http://arxiv.org/abs/2501.09946v1)|null|
|**2025-01-17**|**Indigenous Languages Spoken in Argentina: A Survey of NLP and Speech Resources**|Belu Ticona et.al.|[2501.09943v1](http://arxiv.org/abs/2501.09943v1)|null|
|**2025-01-17**|**HEART: Achieving Timely Multi-Model Training for Vehicle-Edge-Cloud-Integrated Hierarchical Federated Learning**|Xiaohong Yang et.al.|[2501.09934v1](http://arxiv.org/abs/2501.09934v1)|null|
|**2025-01-17**|**Steering Large Language Models with Feature Guided Activation Additions**|Samuel Soo et.al.|[2501.09929v1](http://arxiv.org/abs/2501.09929v1)|null|
|**2025-01-17**|**Dialogue Benchmark Generation from Knowledge Graphs with Cost-Effective Retrieval-Augmented LLMs**|Reham Omar et.al.|[2501.09928v1](http://arxiv.org/abs/2501.09928v1)|null|
|**2025-01-17**|**IE-Bench: Advancing the Measurement of Text-Driven Image Editing for Human Perception Alignment**|Shangkun Sun et.al.|[2501.09927v1](http://arxiv.org/abs/2501.09927v1)|null|
|**2025-01-17**|**GenSC-6G: A Prototype Testbed for Integrated Generative AI, Quantum, and Semantic Communication**|Brian E. Arfeto et.al.|[2501.09918v1](http://arxiv.org/abs/2501.09918v1)|null|
|**2025-01-17**|**Towards A Litmus Test for Common Sense**|Hugo Latapie et.al.|[2501.09913v1](http://arxiv.org/abs/2501.09913v1)|null|
|**2025-01-17**|**Evolving Deeper LLM Thinking**|Kuang-Huei Lee et.al.|[2501.09891v1](http://arxiv.org/abs/2501.09891v1)|null|
|**2025-01-16**|**ASTRA: A Scene-aware TRAnsformer-based model for trajectory prediction**|Izzeddin Teeti et.al.|[2501.09878v1](http://arxiv.org/abs/2501.09878v1)|null|
|**2025-01-16**|**From Explainability to Interpretability: Interpretable Policies in Reinforcement Learning Via Model Explanation**|Peilang Li et.al.|[2501.09858v1](http://arxiv.org/abs/2501.09858v1)|null|
|**2025-01-16**|**CrossModalityDiffusion: Multi-Modal Novel View Synthesis with Unified Intermediate Representation**|Alex Berian et.al.|[2501.09838v1](http://arxiv.org/abs/2501.09838v1)|null|
|**2025-01-16**|**Bridging Language Barriers in Healthcare: A Study on Arabic LLMs**|Nada Saadi et.al.|[2501.09825v1](http://arxiv.org/abs/2501.09825v1)|null|
|**2025-01-16**|**Generalized Single-Image-Based Morphing Attack Detection Using Deep Representations from Vision Transformer**|Haoyu Zhang et.al.|[2501.09817v1](http://arxiv.org/abs/2501.09817v1)|null|
|**2025-01-16**|**Qwen it detect machine-generated text?**|Teodor-George Marchitan et.al.|[2501.09813v1](http://arxiv.org/abs/2501.09813v1)|[link](https://github.com/claudiucreanga/coling-2025-task-1)|
|**2025-01-16**|**Enhancing Generalization in Chain of Thought Reasoning for Smaller Models**|Maxwell J. Yin et.al.|[2501.09804v1](http://arxiv.org/abs/2501.09804v1)|null|
|**2025-01-16**|**Conversational Text Extraction with Large Language Models Using Retrieval-Augmented Systems**|Soham Roy et.al.|[2501.09801v1](http://arxiv.org/abs/2501.09801v1)|null|
|**2025-01-16**|**Computing Optimization-Based Prompt Injections Against Closed-Weights Models By Misusing a Fine-Tuning API**|Andrey Labunets et.al.|[2501.09798v1](http://arxiv.org/abs/2501.09798v1)|null|
|**2025-01-16**|**Learnings from Scaling Visual Tokenizers for Reconstruction and Generation**|Philippe Hansen-Estruch et.al.|[2501.09755v1](http://arxiv.org/abs/2501.09755v1)|null|
|**2025-01-16**|**OmniThink: Expanding Knowledge Boundaries in Machine Writing through Thinking**|Zekun Xi et.al.|[2501.09751v1](http://arxiv.org/abs/2501.09751v1)|null|
|**2025-01-16**|**Enhancing Lexicon-Based Text Embeddings with Large Language Models**|Yibin Lei et.al.|[2501.09749v1](http://arxiv.org/abs/2501.09749v1)|null|
|**2025-01-16**|**Suggesting Code Edits in Interactive Machine Learning Notebooks Using Large Language Models**|Bihui Jin et.al.|[2501.09745v1](http://arxiv.org/abs/2501.09745v1)|null|
|**2025-01-16**|**KU AIGEN ICL EDI@BC8 Track 3: Advancing Phenotype Named Entity Recognition and Normalization for Dysmorphology Physical Examination Reports**|Hajung Kim et.al.|[2501.09744v1](http://arxiv.org/abs/2501.09744v1)|null|
|**2025-01-16**|**Attention based Bidirectional GRU hybrid model for inappropriate content detection in Urdu language**|Ezzah Shoukat et.al.|[2501.09722v1](http://arxiv.org/abs/2501.09722v1)|null|
|**2025-01-16**|**A Simple Aerial Detection Baseline of Multimodal Language Models**|Qingyun Li et.al.|[2501.09720v1](http://arxiv.org/abs/2501.09720v1)|[link](https://github.com/li-qingyun/mllm-mmrotate)|
|**2025-01-16**|**Comparative Insights from 12 Machine Learning Models in Extracting Economic Ideology from Political Text**|Jihed Ncib et.al.|[2501.09719v1](http://arxiv.org/abs/2501.09719v1)|null|
|**2025-01-16**|**CyberMentor: AI Powered Learning Tool Platform to Address Diverse Student Needs in Cybersecurity Education**|Tianyu Wang et.al.|[2501.09709v1](http://arxiv.org/abs/2501.09709v1)|[link](https://github.com/tisage/cybermentor)|
|**2025-01-16**|**The Goofus & Gallant Story Corpus for Practical Value Alignment**|Md Sultan Al Nahian et.al.|[2501.09707v1](http://arxiv.org/abs/2501.09707v1)|null|
|**2025-01-16**|**Domain Adaptation of Foundation LLMs for e-Commerce**|Christian Herold et.al.|[2501.09706v1](http://arxiv.org/abs/2501.09706v1)|null|
|**2025-01-16**|**Practical Continual Forgetting for Pre-trained Vision Models**|Hongbo Zhao et.al.|[2501.09705v1](http://arxiv.org/abs/2501.09705v1)|[link](https://github.com/bjzhb666/GS-LoRA)|
|**2025-01-16**|**Cueless EEG imagined speech for subject identification: dataset and benchmarks**|Ali Derakhshesh et.al.|[2501.09700v1](http://arxiv.org/abs/2501.09700v1)|[link](https://github.com/alidr79/cueless_eeg_subject_identification)|
|**2025-01-16**|**Towards Large Reasoning Models: A Survey on Scaling LLM Reasoning Capabilities**|Fengli Xu et.al.|[2501.09686v2](http://arxiv.org/abs/2501.09686v2)|null|
|**2025-01-16**|**Reward-Guided Controlled Generation for Inference-Time Alignment in Diffusion Models: Tutorial and Review**|Masatoshi Uehara et.al.|[2501.09685v1](http://arxiv.org/abs/2501.09685v1)|null|
|**2025-01-16**|**Authenticated Delegation and Authorized AI Agents**|Tobin South et.al.|[2501.09674v1](http://arxiv.org/abs/2501.09674v1)|null|
|**2025-01-16**|**Robin: a Suite of Multi-Scale Vision-Language Models and the CHIRP Evaluation Benchmark**|Alexis Roger et.al.|[2501.09672v1](http://arxiv.org/abs/2501.09672v1)|null|
|**2025-01-16**|**The Heap: A Contamination-Free Multilingual Code Dataset for Evaluating Large Language Models**|Jonathan Katzy et.al.|[2501.09653v1](http://arxiv.org/abs/2501.09653v1)|null|
|**2025-01-16**|**Monte Carlo Tree Search with Velocity Obstacles for safe and efficient motion planning in dynamic environments**|Lorenzo Bonanni et.al.|[2501.09649v1](http://arxiv.org/abs/2501.09649v1)|null|
|**2025-01-16**|**NS-Gym: Open-Source Simulation Environments and Benchmarks for Non-Stationary Markov Decision Processes**|Nathaniel S. Keplinger et.al.|[2501.09646v1](http://arxiv.org/abs/2501.09646v1)|[link](https://github.com/scope-lab-vu/ns_gym)|
|**2025-01-16**|**CarMem: Enhancing Long-Term Memory in LLM Voice Assistants through Category-Bounding**|Johannes Kirmayr et.al.|[2501.09645v1](http://arxiv.org/abs/2501.09645v1)|null|
|**2025-01-16**|**Electronic Health Records: Towards Digital Twins in Healthcare**|Muhammet Alkan et.al.|[2501.09640v1](http://arxiv.org/abs/2501.09640v1)|null|
|**2025-01-16**|**Platform-Aware Mission Planning**|Stefan Panjkovic et.al.|[2501.09632v1](http://arxiv.org/abs/2501.09632v1)|null|
|**2025-01-16**|**Artificial Intelligence-Driven Clinical Decision Support Systems**|Muhammet Alkan et.al.|[2501.09628v1](http://arxiv.org/abs/2501.09628v1)|null|
|**2025-01-16**|**Sentiment Analysis in Twitter Social Network Centered on Cryptocurrencies Using Machine Learning**|Vahid Amiri et.al.|[2501.09777v1](http://arxiv.org/abs/2501.09777v1)|null|
|**2025-01-16**|**Beyond Reward Hacking: Causal Rewards for Large Language Model Alignment**|Chaoqi Wang et.al.|[2501.09620v1](http://arxiv.org/abs/2501.09620v1)|[link](https://github.com/tatsu-lab/alpaca_farm)|
|**2025-01-16**|**Metric Learning with Progressive Self-Distillation for Audio-Visual Embedding Learning**|Donghuo Zeng et.al.|[2501.09608v1](http://arxiv.org/abs/2501.09608v1)|null|
|**2025-01-16**|**From Scarcity to Capability: Empowering Fake News Detection in Low-Resource Languages with LLMs**|Hrithik Majumdar Shibu et.al.|[2501.09604v1](http://arxiv.org/abs/2501.09604v1)|[link](https://github.com/shibu4064/indonlp)|
|**2025-01-16**|**Reducing the Sensitivity of Neural Physics Simulators to Mesh Topology via Pretraining**|Nathan Vaska et.al.|[2501.09597v1](http://arxiv.org/abs/2501.09597v1)|null|
|**2025-01-16**|**MatrixNet: Learning over symmetry groups using learned group representations**|Lucas Laird et.al.|[2501.09571v1](http://arxiv.org/abs/2501.09571v1)|[link](https://github.com/lucas-laird/matrixnet)|
|**2025-01-16**|**Stylomech: Unveiling Authorship via Computational Stylometry in English and Romanized Sinhala**|Nabeelah Faumi et.al.|[2501.09561v1](http://arxiv.org/abs/2501.09561v1)|null|

#### Abstracts
##### **Agent4Edu: Generating Learner Response Data by Generative Agents for Intelligent Education Systems**
2501.10332v1 by Weibo Gao, Qi Liu, Linan Yue, Fangzhou Yao, Rui Lv, Zheng Zhang, Hao Wang, Zhenya Huang

Personalized learning represents a promising educational strategy within
intelligent educational systems, aiming to enhance learners' practice
efficiency. However, the discrepancy between offline metrics and online
performance significantly impedes their progress. To address this challenge, we
introduce Agent4Edu, a novel personalized learning simulator leveraging recent
advancements in human intelligence through large language models (LLMs).
Agent4Edu features LLM-powered generative agents equipped with learner profile,
memory, and action modules tailored to personalized learning algorithms. The
learner profiles are initialized using real-world response data, capturing
practice styles and cognitive factors. Inspired by human psychology theory, the
memory module records practice facts and high-level summaries, integrating
reflection mechanisms. The action module supports various behaviors, including
exercise understanding, analysis, and response generation. Each agent can
interact with personalized learning algorithms, such as computerized adaptive
testing, enabling a multifaceted evaluation and enhancement of customized
services. Through a comprehensive assessment, we explore the strengths and
weaknesses of Agent4Edu, emphasizing the consistency and discrepancies in
responses between agents and human learners. The code, data, and appendix are
publicly available at https://github.com/bigdata-ustc/Agent4Edu.

摘要：個人化學習代表著智慧教育系統中一個有前途的教育策略，目標是提升學習者的練習效率。然而，離線指標和線上表現之間的差異顯著地阻礙了他們的進度。為了應對這個挑戰，我們引入了 Agent4Edu，一個新穎的個人化學習模擬器，透過大型語言模型 (LLM) 利用人類智慧的最新進展。Agent4Edu 的特色是搭載 LLM 的生成式代理，配備學習者檔案、記憶體和專門針對個人化學習演算法的動作模組。學習者檔案使用真實世界的回應資料初始化，擷取練習風格和認知因素。受到人類心理學理論的啟發，記憶體模組記錄練習事實和高階摘要，整合反思機制。動作模組支援各種行為，包括練習理解、分析和回應產生。每個代理都可以與個人化學習演算法互動，例如電腦化適性測驗，讓客製化服務能夠進行多方面的評量和強化。透過全面的評估，我們探討 Agent4Edu 的優點和缺點，強調代理和人類學習者之間回應的一致性和差異。程式碼、資料和附錄已在 https://github.com/bigdata-ustc/Agent4Edu 公開。

##### **BoK: Introducing Bag-of-Keywords Loss for Interpretable Dialogue Response Generation**
2501.10328v1 by Suvodip Dey, Maunendra Sankar Desarkar

The standard language modeling (LM) loss by itself has been shown to be
inadequate for effective dialogue modeling. As a result, various training
approaches, such as auxiliary loss functions and leveraging human feedback, are
being adopted to enrich open-domain dialogue systems. One such auxiliary loss
function is Bag-of-Words (BoW) loss, defined as the cross-entropy loss for
predicting all the words/tokens of the next utterance. In this work, we propose
a novel auxiliary loss named Bag-of-Keywords (BoK) loss to capture the central
thought of the response through keyword prediction and leverage it to enhance
the generation of meaningful and interpretable responses in open-domain
dialogue systems. BoK loss upgrades the BoW loss by predicting only the
keywords or critical words/tokens of the next utterance, intending to estimate
the core idea rather than the entire response. We incorporate BoK loss in both
encoder-decoder (T5) and decoder-only (DialoGPT) architecture and train the
models to minimize the weighted sum of BoK and LM (BoK-LM) loss. We perform our
experiments on two popular open-domain dialogue datasets, DailyDialog and
Persona-Chat. We show that the inclusion of BoK loss improves the dialogue
generation of backbone models while also enabling post-hoc interpretability. We
also study the effectiveness of BoK-LM loss as a reference-free metric and
observe comparable performance to the state-of-the-art metrics on various
dialogue evaluation datasets.

摘要：標準語言模型 (LM) 損失本身已被證明不足以進行有效的對話建模。因此，各種訓練方法，例如輔助損失函數和利用人類回饋，正被用於豐富開放域對話系統。其中一個這樣的輔助損失函數是詞袋 (BoW) 損失，定義為預測下一個語句的所有字詞/標記的交叉熵損失。在這項工作中，我們提出了一個名為關鍵詞袋 (BoK) 損失的新型輔助損失，以通過關鍵詞預測來捕捉回應的中心思想，並利用它來增強開放域對話系統中生成有意義且可解釋的回應。BoK 損失通過僅預測下一個語句的關鍵詞或關鍵字詞/標記來升級 BoW 損失，旨在估計核心思想，而不是整個回應。我們將 BoK 損失整合到編碼器-解碼器 (T5) 和僅解碼器 (DialoGPT) 架構中，並訓練模型以最小化 BoK 和 LM (BoK-LM) 損失的加權和。我們在兩個流行的開放域對話資料集 DailyDialog 和 Persona-Chat 上執行我們的實驗。我們表明，BoK 損失的加入改善了主幹模型的對話生成，同時也實現了事後可解釋性。我們還研究了 BoK-LM 損失作為無參考指標的有效性，並觀察到在各種對話評估資料集上與最先進的指標具有可比的性能。

##### **Large language models for automated scholarly paper review: A survey**
2501.10326v1 by Zhenzhen Zhuang, Jiandong Chen, Hongfeng Xu, Yuwen Jiang, Jialiang Lin

Large language models (LLMs) have significantly impacted human society,
influencing various domains. Among them, academia is not simply a domain
affected by LLMs, but it is also the pivotal force in the development of LLMs.
In academic publications, this phenomenon is represented during the
incorporation of LLMs into the peer review mechanism for reviewing manuscripts.
We proposed the concept of automated scholarly paper review (ASPR) in our
previous paper. As the incorporation grows, it now enters the coexistence phase
of ASPR and peer review, which is described in that paper. LLMs hold
transformative potential for the full-scale implementation of ASPR, but they
also pose new issues and challenges that need to be addressed. In this survey
paper, we aim to provide a holistic view of ASPR in the era of LLMs. We begin
with a survey to find out which LLMs are used to conduct ASPR. Then, we review
what ASPR-related technological bottlenecks have been solved with the
incorporation of LLM technology. After that, we move on to explore new methods,
new datasets, new source code, and new online systems that come with LLMs for
ASPR. Furthermore, we summarize the performance and issues of LLMs in ASPR, and
investigate the attitudes and reactions of publishers and academia to ASPR.
Lastly, we discuss the challenges associated with the development of LLMs for
ASPR. We hope this survey can serve as an inspirational reference for the
researchers and promote the progress of ASPR for its actual implementation.

摘要：大型語言模型 (LLM) 已顯著影響人類社會，影響了各個領域。其中，學術界不僅是受 LLM 影響的領域，也是 LLM 發展中的關鍵力量。在學術出版物中，這種現象在將 LLM 納入同行評審機制以審查手稿的過程中得到體現。我們在之前的論文中提出了自動學術論文審查 (ASPR) 的概念。隨著納入的增加，它現在進入了 ASPR 和同行評審的共存階段，這在該論文中有所描述。LLM 具有全面實施 ASPR 的轉型潛力，但它們也提出了需要解決的新問題和挑戰。在這篇綜述論文中，我們旨在提供 LLM 時代 ASPR 的整體觀點。我們從一項調查開始，找出哪些 LLM 被用於進行 ASPR。然後，我們回顧了哪些 ASPR 相關技術瓶頸已通過整合 LLM 技術得到解決。在那之後，我們繼續探索 ASPR 隨附的 LLM 的新方法、新數據集、新源代碼和新在線系統。此外，我們總結了 LLM 在 ASPR 中的性能和問題，並調查了出版商和學術界對 ASPR 的態度和反應。最後，我們討論了與 LLM 開發相關的挑戰，以供 ASPR 使用。我們希望這項調查可以作為研究人員的靈感參考，並促進 ASPR 的進展以實際實施。

##### **Hierarchical Autoregressive Transformers: Combining Byte-~and Word-Level Processing for Robust, Adaptable Language Models**
2501.10322v1 by Pit Neitemeier, Björn Deiseroth, Constantin Eichenberg, Lukas Balles

Tokenization is a fundamental step in natural language processing, breaking
text into units that computational models can process. While learned subword
tokenizers have become the de-facto standard, they present challenges such as
large vocabularies, limited adaptability to new domains or languages, and
sensitivity to spelling errors and variations. To overcome these limitations,
we investigate a hierarchical architecture for autoregressive language
modelling that combines character-level and word-level processing. It employs a
lightweight character-level encoder to convert character sequences into word
embeddings, which are then processed by a word-level backbone model and decoded
back into characters via a compact character-level decoder. This method retains
the sequence compression benefits of word-level tokenization without relying on
a rigid, predefined vocabulary. We demonstrate, at scales up to 7 billion
parameters, that hierarchical transformers match the downstream task
performance of subword-tokenizer-based models while exhibiting significantly
greater robustness to input perturbations. Additionally, during continued
pretraining on an out-of-domain language, our model trains almost twice as
fast, achieves superior performance on the target language, and retains more of
its previously learned knowledge. Hierarchical transformers pave the way for
NLP systems that are more robust, flexible, and generalizable across languages
and domains.

摘要：分词是自然語言處理的基本步驟，將文本分解成計算模型可以處理的單位。雖然學習的子詞分詞器已成為事實上的標準，但它們會帶來挑戰，例如詞彙量龐大、對新領域或語言的適應性有限，以及對拼寫錯誤和變化的敏感性。為了克服這些限制，我們研究了自迴歸語言建模的分層架構，它結合了字元級和詞彙級處理。它採用輕量級的字元級編碼器，將字元序列轉換為詞彙嵌入，然後由詞彙級主幹模型處理，並透過一個緊湊的字元級解碼器解碼回字元。這種方法保留了詞彙級分詞的序列壓縮優點，而無需依賴於僵化、預定義的詞彙。我們在高達 70 億個參數的規模上證明，分層Transformer與基於子詞分詞器的模型相匹配的下游任務性能，同時對輸入擾動表現出顯著更高的魯棒性。此外，在持續對領域外語言進行預訓練期間，我們的模型訓練速度幾乎快了一倍，在目標語言上取得了更好的性能，並保留了更多先前學習的知識。分層Transformer為跨語言和領域更強大、更靈活、更具概括性的 NLP 系統鋪平了道路。

##### **Natural Language Processing of Privacy Policies: A Survey**
2501.10319v1 by Andrick Adhikari, Sanchari Das, Rinku Dewri

Natural Language Processing (NLP) is an essential subset of artificial
intelligence. It has become effective in several domains, such as healthcare,
finance, and media, to identify perceptions, opinions, and misuse, among
others. Privacy is no exception, and initiatives have been taken to address the
challenges of usable privacy notifications to users with the help of NLP. To
this aid, we conduct a literature review by analyzing 109 papers at the
intersection of NLP and privacy policies. First, we provide a brief
introduction to privacy policies and discuss various facets of associated
problems, which necessitate the application of NLP to elevate the current state
of privacy notices and disclosures to users. Subsequently, we a) provide an
overview of the implementation and effectiveness of NLP approaches for better
privacy policy communication; b) identify the methodologies that can be further
enhanced to provide robust privacy policies; and c) identify the gaps in the
current state-of-the-art research. Our systematic analysis reveals that several
research papers focus on annotating and classifying privacy texts for analysis
but need to adequately dwell on other aspects of NLP applications, such as
summarization. More specifically, ample research opportunities exist in this
domain, covering aspects such as corpus generation, summarization vectors,
contextualized word embedding, identification of privacy-relevant statement
categories, fine-grained classification, and domain-specific model tuning.

摘要：自然語言處理 (NLP) 是人工智慧的重要子集。它已在醫療保健、金融和媒體等多個領域發揮作用，用於識別感知、意見和濫用等。隱私也不例外，並且已經採取了一些措施，借助 NLP 來解決可用的隱私通知對使用者的挑戰。為此，我們透過分析 109 篇 NLP 和隱私政策交集的論文來進行文獻探討。首先，我們簡要介紹隱私政策，並討論相關問題的各個方面，這需要應用 NLP 來提升當前隱私通知和使用者揭露的狀態。隨後，我們 a) 提供 NLP 方法在改善隱私政策傳達方面的實作和有效性概觀；b) 找出可以進一步增強以提供穩健隱私政策的方法；以及 c) 找出目前最先進的研究現況中的差距。我們的系統分析顯示，許多研究論文專注於註解和分類隱私文字以進行分析，但需要適當地探討 NLP 應用程式的其他方面，例如摘要。更具體地說，這個領域存在大量的研究機會，涵蓋語料庫產生、摘要向量、語境化詞嵌入、隱私相關陳述類別的識別、細粒度分類和特定領域模型調整等方面。

##### **Towards Preventing Overreliance on Task-Oriented Conversational AI Through Accountability Modeling**
2501.10316v1 by Suvodip Dey, Yi-Jyun Sun, Gokhan Tur, Dilek Hakkani-Tur

Recent LLMs have enabled significant advancements for conversational agents.
However, they are also well-known to hallucinate, i.e., they often produce
responses that seem plausible but are not factually correct. On the other hand,
users tend to over-rely on LLM-based AI agents; they accept the AI's suggestion
even when it is wrong. Adding good friction, such as explanations or getting
user confirmations, has been proposed as a mitigation in AI-supported
decision-making systems. In this paper, we propose an accountability model for
LLM-based task-oriented dialogue agents to address user overreliance via
friction turns in cases of model uncertainty and errors associated with
dialogue state tracking (DST). The accountability model is an augmented LLM
with an additional accountability head, which functions as a binary classifier
to predict the slots of the dialogue states. We perform our experiments with
three backbone LLMs (Llama, Mistral, Gemma) on two established task-oriented
datasets (MultiWOZ and Snips). Our empirical findings demonstrate that this
approach not only enables reliable estimation of AI agent errors but also
guides the LLM decoder in generating more accurate actions. We observe around
3% absolute improvement in joint goal accuracy by incorporating accountability
heads in modern LLMs for the MultiWOZ dataset. We also show that this method
enables the agent to self-correct its actions, further boosting its performance
by 3%. Finally, we discuss the application of accountability modeling to
prevent user overreliance by introducing friction.

摘要：<paragraph>最近的大语言模型 (LLM) 为对话代理带来了重大进步。
然而，众所周知，它们也会出现幻觉，即它们经常产生看似合理但事实不正确的反应。另一方面，
用户倾向于过度依赖基于 LLM 的 AI 代理；他们接受 AI 的建议
即使它是错误的。添加良好的摩擦，例如解释或获得
用户确认，已被提议作为人工智能支持的缓解措施
决策系统。在本文中，我们提出了一个问责模型
基于 LLM 的面向任务的对话代理通过
在模型不确定性和与对话状态跟踪 (DST) 相关的错误的情况下摩擦转向来解决用户过度依赖。问责模型是一个增强型 LLM
带有附加的问责负责人，它充当二进制分类器
预测对话状态的槽位。我们使用
三个骨干 LLM（Llama、Mistral、Gemma）在两个已建立的面向任务的
数据集（MultiWOZ 和 Snips）。我们的经验结果表明，这种
方法不仅能够可靠地估计人工智能代理错误，而且还
指导 LLM 解码器生成更准确的动作。我们观察到大约
通过在现代 LLM 中加入问责负责人，在 MultiWOZ 数据集中将联合目标准确性绝对提高了 3%。我们还表明，这种方法
使代理能够自我纠正其动作，进一步提高其性能
3%。最后，我们讨论了问责建模在
通过引入摩擦来防止用户过度依赖。</paragraph>

##### **Computational Protein Science in the Era of Large Language Models (LLMs)**
2501.10282v1 by Wenqi Fan, Yi Zhou, Shijie Wang, Yuyao Yan, Hui Liu, Qian Zhao, Le Song, Qing Li

Considering the significance of proteins, computational protein science has
always been a critical scientific field, dedicated to revealing knowledge and
developing applications within the protein sequence-structure-function
paradigm. In the last few decades, Artificial Intelligence (AI) has made
significant impacts in computational protein science, leading to notable
successes in specific protein modeling tasks. However, those previous AI models
still meet limitations, such as the difficulty in comprehending the semantics
of protein sequences, and the inability to generalize across a wide range of
protein modeling tasks. Recently, LLMs have emerged as a milestone in AI due to
their unprecedented language processing & generalization capability. They can
promote comprehensive progress in fields rather than solving individual tasks.
As a result, researchers have actively introduced LLM techniques in
computational protein science, developing protein Language Models (pLMs) that
skillfully grasp the foundational knowledge of proteins and can be effectively
generalized to solve a diversity of sequence-structure-function reasoning
problems. While witnessing prosperous developments, it's necessary to present a
systematic overview of computational protein science empowered by LLM
techniques. First, we summarize existing pLMs into categories based on their
mastered protein knowledge, i.e., underlying sequence patterns, explicit
structural and functional information, and external scientific languages.
Second, we introduce the utilization and adaptation of pLMs, highlighting their
remarkable achievements in promoting protein structure prediction, protein
function prediction, and protein design studies. Then, we describe the
practical application of pLMs in antibody design, enzyme design, and drug
discovery. Finally, we specifically discuss the promising future directions in
this fast-growing field.

摘要：<paragraph>考量到蛋白质的重要性，计算蛋白质科学一直都是一个重要的科学领域，致力于揭示蛋白质序列-结构-功能范例中的知识并开发应用程序。在过去的几十年中，人工智能 (AI) 在计算蛋白质科学中产生了重大影响，在特定的蛋白质建模任务中取得了显着的成功。然而，那些先前的 AI 模型仍然存在局限性，例如难以理解蛋白质序列的语义，以及无法概括到广泛的蛋白质建模任务。最近，LLM 由于其前所未有的语言处理和概括能力而成为人工智能的一个里程碑。它们可以促进领域的全面进步，而不是解决个别任务。因此，研究人员已积极在计算蛋白质科学中引入 LLM 技术，开发蛋白质语言模型 (pLM)，该模型熟练地掌握蛋白质的基础知识，并且可以有效地概括以解决各种序列-结构-功能推理问题。在见证蓬勃发展的过程中，有必要对 LLM 技术赋能的计算蛋白质科学进行系统概述。首先，我们将现有的 pLM 总结为基于其掌握的蛋白质知识的类别，即基础序列模式、明确的结构和功能信息以及外部科学语言。其次，我们介绍 pLM 的利用和适应，重点介绍他们在促进蛋白质结构预测、蛋白质功能预测和蛋白质设计研究方面取得的显着成就。然后，我们描述了 pLM 在抗体设计、酶设计和药物发现中的实际应用。最后，我们专门讨论了这个快速发展的领域中充满希望的未来方向。</paragraph>

##### **SEANN: A Domain-Informed Neural Network for Epidemiological Insights**
2501.10273v1 by Jean-Baptiste Guimbaud, Marc Plantevit, Léa Maître, Rémy Cazabet

In epidemiology, traditional statistical methods such as logistic regression,
linear regression, and other parametric models are commonly employed to
investigate associations between predictors and health outcomes. However,
non-parametric machine learning techniques, such as deep neural networks
(DNNs), coupled with explainable AI (XAI) tools, offer new opportunities for
this task. Despite their potential, these methods face challenges due to the
limited availability of high-quality, high-quantity data in this field. To
address these challenges, we introduce SEANN, a novel approach for informed
DNNs that leverages a prevalent form of domain-specific knowledge: Pooled
Effect Sizes (PES). PESs are commonly found in published Meta-Analysis studies,
in different forms, and represent a quantitative form of a scientific
consensus. By direct integration within the learning procedure using a custom
loss, we experimentally demonstrate significant improvements in the
generalizability of predictive performances and the scientific plausibility of
extracted relationships compared to a domain-knowledge agnostic neural network
in a scarce and noisy data setting.

摘要：在流行病學中，傳統的統計方法，例如邏輯迴歸、線性迴歸和其他參數模型通常用於調查預測因子與健康結果之間的關聯。然而，非參數機器學習技術，例如深度神經網路 (DNN)，結合可解釋的 AI (XAI) 工具，為這項任務提供了新的機會。儘管這些方法具有潛力，但由於該領域缺乏高品質、高數量資料，因此這些方法面臨挑戰。為了應對這些挑戰，我們引入了 SEANN，這是一種新穎的方法，用於獲取知識的 DNN，它利用了一種流行的領域特定知識形式：彙總效應量 (PES)。PES 通常以不同的形式出現在已發表的 Meta 分析研究中，並代表科學共識的量化形式。通過使用自訂損失函數直接整合在學習程序中，我們以實驗方式證明了預測效能的概括性以及與從缺乏領域知識的神經網路中提取的關係相比，科學合理性的顯著提升，且是在稀少且有雜訊的資料設定中。

##### **Unsupervised Rhythm and Voice Conversion of Dysarthric to Healthy Speech for ASR**
2501.10256v1 by Karl El Hajal, Enno Hermann, Ajinkya Kulkarni, Mathew Magimai. -Doss

Automatic speech recognition (ASR) systems are well known to perform poorly
on dysarthric speech. Previous works have addressed this by speaking rate
modification to reduce the mismatch with typical speech. Unfortunately, these
approaches rely on transcribed speech data to estimate speaking rates and
phoneme durations, which might not be available for unseen speakers. Therefore,
we combine unsupervised rhythm and voice conversion methods based on
self-supervised speech representations to map dysarthric to typical speech. We
evaluate the outputs with a large ASR model pre-trained on healthy speech
without further fine-tuning and find that the proposed rhythm conversion
especially improves performance for speakers of the Torgo corpus with more
severe cases of dysarthria. Code and audio samples are available at
https://idiap.github.io/RnV .

摘要：自動語音辨識 (ASR) 系統在處理構音障礙的語音時，表現普遍不佳。先前的研究透過調整說話速度來解決這個問題，藉此減少與典型語音的差異。遺憾的是，這些方法仰賴轉錄語音資料來估計說話速度和音素長度，而這些資料可能無法取得，特別是針對未曾見過的說話者。因此，我們結合基於自我監督語音表徵的非監督節奏和語音轉換方法，將構音障礙的語音轉換為典型語音。我們使用一個大型 ASR 模型評估輸出，該模型預先在健康語音上進行訓練，且未進一步微調，並發現建議的節奏轉換特別能提升 Torgo 語料庫中構音障礙較為嚴重的說話者的表現。程式碼和音訊範例可於 https://idiap.github.io/RnV 取得。

##### **Challenges and recommendations for Electronic Health Records data extraction and preparation for dynamic prediction modelling in hospitalized patients -- a practical guide**
2501.10240v1 by Elena Albu, Shan Gao, Pieter Stijnen, Frank E. Rademakers, Bas C T van Bussel, Taya Collyer, Tina Hernandez-Boussard, Laure Wynants, Ben Van Calster

Dynamic predictive modeling using electronic health record (EHR) data has
gained significant attention in recent years. The reliability and
trustworthiness of such models depend heavily on the quality of the underlying
data, which is largely determined by the stages preceding the model
development: data extraction from EHR systems and data preparation. We list
over forty challenges encountered during these stages and provide actionable
recommendations for addressing them. These challenges are organized into four
categories: cohort definition, outcome definition, feature engineering, and
data cleaning. This list is designed to serve as a practical guide for data
extraction engineers and researchers, supporting better practices and improving
the quality and real-world applicability of dynamic prediction models in
clinical settings.

摘要：近年來，使用電子健康記錄 (EHR) 資料的動態預測模型獲得了極大的關注。此類模型的可靠性和可信度在很大程度上取決於基礎資料的品質，而這在很大程度上取決於模型開發之前的階段：從 EHR 系統中提取資料和資料準備。我們列出了這些階段中遇到的四十多項挑戰，並提供了具體可行的建議來解決這些挑戰。這些挑戰分為四類：群組定義、結果定義、特徵工程和資料清理。此清單旨在作為資料提取工程師和研究人員的實用指南，支援更好的實務，並改善動態預測模型在臨床環境中的品質和實際應用性。

##### **Temporal Causal Reasoning with (Non-Recursive) Structural Equation Models**
2501.10190v1 by Maksim Gladyshev, Natasha Alechina, Mehdi Dastani, Dragan Doder, Brian Logan

Structural Equation Models (SEM) are the standard approach to representing
causal dependencies between variables in causal models. In this paper we
propose a new interpretation of SEMs when reasoning about Actual Causality, in
which SEMs are viewed as mechanisms transforming the dynamics of exogenous
variables into the dynamics of endogenous variables. This allows us to combine
counterfactual causal reasoning with existing temporal logic formalisms, and to
introduce a temporal logic, CPLTL, for causal reasoning about such structures.
We show that the standard restriction to so-called \textit{recursive} models
(with no cycles in the dependency graph) is not necessary in our approach,
allowing us to reason about mutually dependent processes and feedback loops.
Finally, we introduce new notions of model equivalence for temporal causal
models, and show that CPLTL has an efficient model-checking procedure.

摘要：結構方程模型 (SEM) 是表示因果模型中變數之間因果依賴關係的標準方法。在本文中，我們提出對 SEM 的新詮釋，以推理實際因果關係，其中 SEM 被視為將外生變數的動態轉換為內生變數動態的機制。這讓我們得以將反事實因果推理與現有的時態邏輯形式主義結合，並為此類結構的因果推理引入時態邏輯 CPLTL。我們表明，在我們的做法中，對所謂的「遞迴」模型（依賴圖中沒有循環）的標準限制並非必要，這讓我們得以推理相互依賴的過程和回饋迴路。最後，我們為時態因果模型引入了新的模型等價概念，並表明 CPLTL 有一個有效的模型檢查程序。

##### **Generative Artificial Intelligence: Implications for Biomedical and Health Professions Education**
2501.10186v1 by William Hersh

Generative AI has had a profound impact on biomedicine and health, both in
professional work and in education. Based on large language models (LLMs),
generative AI has been found to perform as well as humans in simulated
situations taking medical board exams, answering clinical questions, solving
clinical cases, applying clinical reasoning, and summarizing information.
Generative AI is also being used widely in education, performing well in
academic courses and their assessments. This review summarizes the successes of
LLMs and highlights some of their challenges in the context of education, most
notably aspects that may undermines the acquisition of knowledge and skills for
professional work. It then provides recommendations for best practices
overcoming shortcomings for LLM use in education. Although there are challenges
for use of generative AI in education, all students and faculty, in biomedicine
and health and beyond, must have understanding and be competent in its use.

摘要：生成式 AI 對生物醫學和健康領域產生了深遠的影響，無論是在專業工作還是教育方面。基於大型語言模型 (LLM)，發現生成式 AI 在模擬醫療委員會考試、回答臨床問題、解決臨床案例、應用臨床推理和總結資訊等情況下，表現得與人類一樣好。生成式 AI 也廣泛應用於教育中，在學術課程及其評估中表現良好。本篇評論總結了 LLM 的成功，並強調了它們在教育背景下的一些挑戰，最值得注意的是可能損害專業工作知識和技能習得的方面。然後，它針對克服 LLM 在教育中使用的缺點提供了最佳實務建議。儘管生成式 AI 在教育中使用存在挑戰，但生物醫學和健康領域以及其他領域的所有學生和教職員工都必須了解並熟練使用它。

##### **A Simple but Effective Closed-form Solution for Extreme Multi-label Learning**
2501.10179v1 by Kazuma Onishi, Katsuhiko Hayashi

Extreme multi-label learning (XML) is a task of assigning multiple labels
from an extremely large set of labels to each data instance. Many current
high-performance XML models are composed of a lot of hyperparameters, which
complicates the tuning process. Additionally, the models themselves are adapted
specifically to XML, which complicates their reimplementation. To remedy this
problem, we propose a simple method based on ridge regression for XML. The
proposed method not only has a closed-form solution but also is composed of a
single hyperparameter. Since there are no precedents on applying ridge
regression to XML, this paper verified the performance of the method by using
various XML benchmark datasets. Furthermore, we enhanced the prediction of
low-frequency labels in XML, which hold informative content. This prediction is
essential yet challenging because of the limited amount of data. Here, we
employed a simple frequency-based weighting. This approach greatly simplifies
the process compared with existing techniques. Experimental results revealed
that it can achieve levels of performance comparable to, or even exceeding,
those of models with numerous hyperparameters. Additionally, we found that the
frequency-based weighting significantly improved the predictive performance for
low-frequency labels, while requiring almost no changes in implementation. The
source code for the proposed method is available on github at
https://github.com/cars1015/XML-ridge.

摘要：極端多標籤學習 (XML) 是一項將極大量的標籤集合中的多個標籤分配給每個資料實例的任務。許多當前的高效能 XML 模型由大量的超參數組成，這使得調整過程變得複雜。此外，這些模型本身特別適用於 XML，這使得它們的重新實作變得複雜。為了解決此問題，我們提出了一種基於 XML 的嶺迴歸的簡單方法。所提出的方法不僅有閉合形式的解，還由單一超參數組成。由於沒有將嶺迴歸應用於 XML 的先例，因此本文使用各種 XML 基準資料集驗證了該方法的效能。此外，我們增強了 XML 中低頻率標籤的預測，這些標籤包含資訊性內容。此預測對於資料量有限的情況而言至關重要且具有挑戰性。在此，我們採用了基於頻率的簡單加權。與現有技術相比，此方法大大簡化了流程。實驗結果顯示，它可以達到與具有大量超參數的模型相當甚至更高的效能水準。此外，我們發現基於頻率的加權顯著改善了低頻率標籤的預測效能，同時幾乎不需要變更實作。所提出的方法的原始程式碼可在 github 上取得，網址為 https://github.com/cars1015/XML-ridge。

##### **Multi-stage Training of Bilingual Islamic LLM for Neural Passage Retrieval**
2501.10175v1 by Vera Pavlova

This study examines the use of Natural Language Processing (NLP) technology
within the Islamic domain, focusing on developing an Islamic neural retrieval
model. By leveraging the robust XLM-R model, the research employs a language
reduction technique to create a lightweight bilingual large language model
(LLM). Our approach for domain adaptation addresses the unique challenges faced
in the Islamic domain, where substantial in-domain corpora exist only in Arabic
while limited in other languages, including English.
  The work utilizes a multi-stage training process for retrieval models,
incorporating large retrieval datasets, such as MS MARCO, and smaller,
in-domain datasets to improve retrieval performance. Additionally, we have
curated an in-domain retrieval dataset in English by employing data
augmentation techniques and involving a reliable Islamic source. This approach
enhances the domain-specific dataset for retrieval, leading to further
performance gains.
  The findings suggest that combining domain adaptation and a multi-stage
training method for the bilingual Islamic neural retrieval model enables it to
outperform monolingual models on downstream retrieval tasks.

摘要：本研究探討自然語言處理 (NLP) 技術在伊斯蘭領域中的應用，重點在於開發伊斯蘭神經網路檢索模型。研究利用強大的 XLM-R 模型，採用語言簡化技術來建立輕量級雙語大型語言模型 (LLM)。我們針對領域適應所採取的方法，因應伊斯蘭領域中所面臨的獨特挑戰，其中大量的領域內語料庫僅存在於阿拉伯語，而其他語言（包括英語）的語料庫則有限。
這項研究採用多階段訓練流程來訓練檢索模型，整合大型檢索資料集（例如 MS MARCO）和較小的領域內資料集，以提升檢索效能。此外，我們透過採用資料擴充技術，並納入可靠的伊斯蘭來源，來策劃一個英語領域內的檢索資料集。這種方法增強了用於檢索的特定領域資料集，進而提升效能。
研究結果顯示，結合領域適應和多階段訓練方法，建構雙語伊斯蘭神經網路檢索模型，使其在後端的檢索任務中優於單語模型。

##### **CSSDM Ontology to Enable Continuity of Care Data Interoperability**
2501.10160v1 by Subhashis Das, Debashis Naskar, Sara Rodriguez Gonzalez, Pamela Hussey

The rapid advancement of digital technologies and recent global pandemic
scenarios have led to a growing focus on how these technologies can enhance
healthcare service delivery and workflow to address crises. Action plans that
consolidate existing digital transformation programs are being reviewed to
establish core infrastructure and foundations for sustainable healthcare
solutions. Reforming health and social care to personalize home care, for
example, can help avoid treatment in overcrowded acute hospital settings and
improve the experiences and outcomes for both healthcare professionals and
service users. In this information-intensive domain, addressing the
interoperability challenge through standards-based roadmaps is crucial for
enabling effective connections between health and social care services. This
approach facilitates safe and trustworthy data workflows between different
healthcare system providers. In this paper, we present a methodology for
extracting, transforming, and loading data through a semi-automated process
using a Common Semantic Standardized Data Model (CSSDM) to create personalized
healthcare knowledge graph (KG). The CSSDM is grounded in the formal ontology
of ISO 13940 ContSys and incorporates FHIR-based specifications to support
structural attributes for generating KGs. We propose that the CSSDM facilitates
data harmonization and linking, offering an alternative approach to
interoperability. This approach promotes a novel form of collaboration between
companies developing health information systems and cloud-enabled health
services. Consequently, it provides multiple stakeholders with access to
high-quality data and information sharing.

摘要：數位科技快速進步和最近的全球大流行病情境已導致越來越多人專注於這些科技如何增強醫療保健服務提供和工作流程以應對危機。整合現有數位轉型計畫的行動計畫正被檢視，以建立永續醫療保健解決方案的核心基礎架構和基礎。例如，改革醫療和社會照護以個人化居家照護，有助於避免在人滿為患的急性醫院環境中接受治療，並改善醫療保健專業人員和服務使用者的經驗和結果。在這個資訊密集的領域，透過基於標準的路徑圖來解決互通性挑戰，對於促成醫療保健服務和社會照護服務之間的有效連結至關重要。此方法促成不同醫療保健系統供應商之間安全且值得信賴的資料工作流程。在本文中，我們提出一個方法，透過半自動化流程使用通用語意標準化資料模型 (CSSDM) 來萃取、轉換和載入資料，以建立個人化的醫療保健知識圖譜 (KG)。CSSDM 以 ISO 13940 ContSys 的正式本体論為基礎，並結合基於 FHIR 的規格來支援用於產生 KG 的結構屬性。我們提出 CSSDM 促進資料調和和連結，提供一種互通性的替代方法。此方法促成開發醫療資訊系統和雲端醫療服務的公司之間的一種新型合作形式。因此，它提供多個利害關係人存取高品質資料和資訊共享。

##### **Region-wise stacking ensembles for estimating brain-age using MRI**
2501.10153v1 by Georgios Antonopoulos, Shammi More, Simon B. Eickhoff, Federico Raimondo, Kaustubh R. Patil

Predictive modeling using structural magnetic resonance imaging (MRI) data is
a prominent approach to study brain-aging. Machine learning algorithms and
feature extraction methods have been employed to improve predictions and
explore healthy and accelerated aging e.g. neurodegenerative and psychiatric
disorders. The high-dimensional MRI data pose challenges to building
generalizable and interpretable models as well as for data privacy. Common
practices are resampling or averaging voxels within predefined parcels, which
reduces anatomical specificity and biological interpretability as voxels within
a region may differently relate to aging. Effectively, naive fusion by
averaging can result in information loss and reduced accuracy. We present a
conceptually novel two-level stacking ensemble (SE) approach. The first level
comprises regional models for predicting individuals' age based on voxel-wise
information, fused by a second-level model yielding final predictions. Eight
data fusion scenarios were explored using as input Gray matter volume (GMV)
estimates from four datasets covering the adult lifespan. Performance, measured
using mean absolute error (MAE), R2, correlation and prediction bias, showed
that SE outperformed the region-wise averages. The best performance was
obtained when first-level regional predictions were obtained as out-of-sample
predictions on the application site with second-level models trained on
independent and site-specific data (MAE=4.75 vs baseline regional mean GMV
MAE=5.68). Performance improved as more datasets were used for training.
First-level predictions showed improved and more robust aging signal providing
new biological insights and enhanced data privacy. Overall, the SE improves
accuracy compared to the baseline while preserving or enhancing data privacy.

摘要：利用結構性磁振造影 (MRI) 資料進行預測建模是研究大腦老化的一種重要方法。機器學習演算法和特徵萃取方法已被用於改善預測，並探討健康和加速老化，例如神經退化性和精神疾病。高維度 MRI 資料在建立可概化且可解釋的模型以及資料隱私方面構成挑戰。常見的做法是在預先定義的區塊中重新取樣或平均體素，這會降低解剖特異性和生物可解釋性，因為區域內的體素可能與老化有不同的關係。實際上，通過平均值進行樸素融合可能會導致資訊遺失和準確性降低。我們提出了一個概念上新穎的兩層堆疊集成 (SE) 方法。第一層包含區域模型，用於根據體素資訊預測個體年齡，並通過第二層模型進行融合，產生最終預測。使用來自涵蓋成年人壽命的四個資料集的灰質體積 (GMV) 估計值作為輸入，探討了八種資料融合場景。使用平均絕對誤差 (MAE)、R2、相關性和預測偏差測量的效能顯示，SE 優於區域平均值。當第一層區域預測作為應用站點上的異樣本預測獲得，而第二層模型在獨立和特定於站點的資料上進行訓練時，獲得了最佳效能 (MAE=4.75，而基線區域平均 GMV MAE=5.68)。隨著用於訓練的資料集增多，效能有所提高。第一層預測顯示出改善且更穩健的老化訊號，提供了新的生物學見解並增強了資料隱私。總體而言，SE 在保留或增強資料隱私的同時，與基線相比提高了準確性。

##### **Dual Debiasing: Remove Stereotypes and Keep Factual Gender for Fair Language Modeling and Translation**
2501.10150v1 by Tomasz Limisiewicz, David Mareček, Tomáš Musil

Mitigation of biases, such as language models' reliance on gender
stereotypes, is a crucial endeavor required for the creation of reliable and
useful language technology. The crucial aspect of debiasing is to ensure that
the models preserve their versatile capabilities, including their ability to
solve language tasks and equitably represent various genders. To address this
issue, we introduce a streamlined Dual Dabiasing Algorithm through Model
Adaptation (2DAMA). Novel Dual Debiasing enables robust reduction of
stereotypical bias while preserving desired factual gender information encoded
by language models. We show that 2DAMA effectively reduces gender bias in
English and is one of the first approaches facilitating the mitigation of
stereotypical tendencies in translation. The proposed method's key advantage is
the preservation of factual gender cues, which are useful in a wide range of
natural language processing tasks.

摘要：減輕偏見（例如語言模型對性別刻板印象的依賴）對於建立可靠且有用的語言技術來說是一項至關重要的工作。去偏見的關鍵方面是確保模型保留其多功能能力，包括其解決語言任務和公平代表各種性別的能力。為了解決這個問題，我們通過模型適應 (2DAMA) 引入了一個簡化的雙重去偏演算法。創新的雙重去偏能夠在保留語言模型編碼的所需事實性別資訊的同時，穩健地減少刻板偏見。我們展示了 2DAMA 有效地減少了英文中的性別偏見，並且是第一批促進減輕翻譯中刻板傾向的方法之一。所提出的方法的主要優點是保留了事實性別線索，這在廣泛的自然語言處理任務中很有用。

##### **Exploring the Impact of Generative Artificial Intelligence in Education: A Thematic Analysis**
2501.10134v1 by Abhishek Kaushik, Sargam Yadav, Andrew Browne, David Lillis, David Williams, Jack Mc Donnell, Peadar Grant, Siobhan Connolly Kernan, Shubham Sharma, Mansi Arora

The recent advancements in Generative Artificial intelligence (GenAI)
technology have been transformative for the field of education. Large Language
Models (LLMs) such as ChatGPT and Bard can be leveraged to automate boilerplate
tasks, create content for personalised teaching, and handle repetitive tasks to
allow more time for creative thinking. However, it is important to develop
guidelines, policies, and assessment methods in the education sector to ensure
the responsible integration of these tools. In this article, thematic analysis
has been performed on seven essays obtained from professionals in the education
sector to understand the advantages and pitfalls of using GenAI models such as
ChatGPT and Bard in education. Exploratory Data Analysis (EDA) has been
performed on the essays to extract further insights from the text. The study
found several themes which highlight benefits and drawbacks of GenAI tools, as
well as suggestions to overcome these limitations and ensure that students are
using these tools in a responsible and ethical manner.

摘要：生成式人工智能 (GenAI) 技術的最新進展對教育領域產生了變革性的影響。大型語言模型 (LLM)，例如 ChatGPT 和 Bard，可以被用於自動化樣板任務、創建個性化教學內容，以及處理重複性任務，從而騰出更多時間進行創造性思考。然而，制定教育部門的指導方針、政策和評估方法以確保這些工具的負責任整合非常重要。在本文中，對來自教育部門專業人士提供的七篇論文進行了主題分析，以了解在教育中使用 ChatGPT 和 Bard 等 GenAI 模型的優點和缺點。對這些論文進行了探索性數據分析 (EDA)，以從文本中提取進一步的見解。研究發現了幾個主題，這些主題突出了 GenAI 工具的優點和缺點，以及克服這些限制並確保學生負責任且合乎道德地使用這些工具的建議。

##### **ComplexFuncBench: Exploring Multi-Step and Constrained Function Calling under Long-Context Scenario**
2501.10132v1 by Lucen Zhong, Zhengxiao Du, Xiaohan Zhang, Haiyi Hu, Jie Tang

Enhancing large language models (LLMs) with real-time APIs can help generate
more accurate and up-to-date responses. However, evaluating the function
calling abilities of LLMs in real-world scenarios remains under-explored due to
the complexity of data collection and evaluation. In this work, we introduce
ComplexFuncBench, a benchmark for complex function calling across five
real-world scenarios. Compared to existing benchmarks, ComplexFuncBench
encompasses multi-step and constrained function calling, which requires
long-parameter filing, parameter value reasoning, and 128k long context.
Additionally, we propose an automatic framework, ComplexEval, for
quantitatively evaluating complex function calling tasks. Through comprehensive
experiments, we demonstrate the deficiencies of state-of-the-art LLMs in
function calling and suggest future directions for optimizing these
capabilities. The data and code are available at
\url{https://github.com/THUDM/ComplexFuncBench}.

摘要：透過即時 API 增強大型語言模型 (LLM)，有助於產生更準確且最新的回應。然而，由於資料收集和評估的複雜性，在真實世界場景中評估 LLM 的函數呼叫能力仍未被充分探討。在這項工作中，我們引入了 ComplexFuncBench，一個跨越五個真實世界場景的複雜函數呼叫基準。與現有基準相比，ComplexFuncBench 涵蓋多步驟和受限函數呼叫，需要長參數歸檔、參數值推理和 128k 長的上下文。此外，我們提出了一個自動化框架 ComplexEval，用於定量評估複雜的函數呼叫任務。透過全面的實驗，我們展示了最先進 LLM 在函數呼叫中的缺陷，並建議了優化這些功能的未來方向。資料和程式碼可在 \url{https://github.com/THUDM/ComplexFuncBench} 取得。

##### **BBPOS: BERT-based Part-of-Speech Tagging for Uzbek**
2501.10107v1 by Latofat Bobojonova, Arofat Akhundjanova, Phil Ostheimer, Sophie Fellenz

This paper advances NLP research for the low-resource Uzbek language by
evaluating two previously untested monolingual Uzbek BERT models on the
part-of-speech (POS) tagging task and introducing the first publicly available
UPOS-tagged benchmark dataset for Uzbek. Our fine-tuned models achieve 91%
average accuracy, outperforming the baseline multi-lingual BERT as well as the
rule-based tagger. Notably, these models capture intermediate POS changes
through affixes and demonstrate context sensitivity, unlike existing rule-based
taggers.

摘要：這篇論文通過在詞性標記任務上評估兩個以前未測試過的單語 Uzbek BERT 模型，推進了低資源烏茲別克語的 NLP 研究，並引入了第一個公開可用的烏茲別克語 UPOS 標記基準數據集。我們微調的模型達到了 91% 的平均準確度，優於基準多語言 BERT 以及基於規則的標記器。值得注意的是，與現有的基於規則的標記器不同，這些模型通過後綴捕獲中間 POS 變化並展示上下文敏感性。

##### **LLM Reasoner and Automated Planner: A new NPC approach**
2501.10106v1 by Israel Puerta-Merino, Jordi Sabater-Mir

In domains requiring intelligent agents to emulate plausible human-like
behaviour, such as formative simulations, traditional techniques like behaviour
trees encounter significant challenges. Large Language Models (LLMs), despite
not always yielding optimal solutions, usually offer plausible and human-like
responses to a given problem. In this paper, we exploit this capability and
propose a novel architecture that integrates an LLM for decision-making with a
classical automated planner that can generate sound plans for that decision.
The combination aims to equip an agent with the ability to make decisions in
various situations, even if they were not anticipated during the design phase.

摘要：在需要智能代理模擬可信的人類行為的領域中，例如形成性模擬，傳統技術，如行為樹，會遇到重大挑戰。大型語言模型 (LLM) 儘管並非總是能產生最佳解決方案，但通常會對給定的問題提供合理且類似人類的回應。在本文中，我們利用此功能並提出了一種新穎的架構，將 LLM 整合用於決策制定，並使用一個可以為該決策產生完善計畫的經典自動規劃器。此組合旨在讓代理具備在各種情況下做出決策的能力，即使在設計階段未預期到這些情況。

##### **Universal Actions for Enhanced Embodied Foundation Models**
2501.10105v1 by Jinliang Zheng, Jianxiong Li, Dongxiu Liu, Yinan Zheng, Zhihao Wang, Zhonghong Ou, Yu Liu, Jingjing Liu, Ya-Qin Zhang, Xianyuan Zhan

Training on diverse, internet-scale data is a key factor in the success of
recent large foundation models. Yet, using the same recipe for building
embodied agents has faced noticeable difficulties. Despite the availability of
many crowd-sourced embodied datasets, their action spaces often exhibit
significant heterogeneity due to distinct physical embodiment and control
interfaces for different robots, causing substantial challenges in developing
embodied foundation models using cross-domain data. In this paper, we introduce
UniAct, a new embodied foundation modeling framework operating in a tokenized
Universal Action Space. Our learned universal actions capture the generic
atomic behaviors across diverse robots by exploiting their shared structural
features, and enable enhanced cross-domain data utilization and
cross-embodiment generalizations by eliminating the notorious heterogeneity.
The universal actions can be efficiently translated back to heterogeneous
actionable commands by simply adding embodiment-specific details, from which
fast adaptation to new robots becomes simple and straightforward. Our 0.5B
instantiation of UniAct outperforms 14X larger SOTA embodied foundation models
in extensive evaluations on various real-world and simulation robots,
showcasing exceptional cross-embodiment control and adaptation capability,
highlighting the crucial benefit of adopting universal actions. Project page:
https://github.com/2toinf/UniAct

摘要：在規模龐大的網際網路資料上進行訓練是近期大型基礎模型成功的關鍵因素。然而，使用相同的食譜來建構具體化代理人卻面臨著顯著的困難。儘管有許多群眾外包的具體化資料集，但由於不同的機器人具有不同的物理具體化和控制介面，因此其動作空間通常會表現出顯著的異質性，這在使用跨領域資料開發具體化基礎模型時會造成重大的挑戰。在本文中，我們介紹 UniAct，一個新的具體化基礎建模框架，在標記化的通用動作空間中運作。我們學習到的通用動作透過利用它們共有的結構特徵來擷取不同機器人之間的通用原子行為，並透過消除臭名昭著的異質性來實現增強的跨領域資料利用和跨具體化概括。通用動作可以透過簡單地加入具體化特定的細節來有效地轉譯回異質化的可操作命令，從而使快速適應新的機器人變得簡單且直接。我們 0.5B 的 UniAct 實例化在各種真實世界和模擬機器人上的廣泛評估中優於 14X 倍更大的 SOTA 具體化基礎模型，展示了非凡的跨具體化控制和適應能力，突顯了採用通用動作的關鍵優勢。專案頁面：https://github.com/2toinf/UniAct

##### **Robotic World Model: A Neural Network Simulator for Robust Policy Optimization in Robotics**
2501.10100v1 by Chenhao Li, Andreas Krause, Marco Hutter

Learning robust and generalizable world models is crucial for enabling
efficient and scalable robotic control in real-world environments. In this
work, we introduce a novel framework for learning world models that accurately
capture complex, partially observable, and stochastic dynamics. The proposed
method employs a dual-autoregressive mechanism and self-supervised training to
achieve reliable long-horizon predictions without relying on domain-specific
inductive biases, ensuring adaptability across diverse robotic tasks. We
further propose a policy optimization framework that leverages world models for
efficient training in imagined environments and seamless deployment in
real-world systems. Through extensive experiments, our approach consistently
outperforms state-of-the-art methods, demonstrating superior autoregressive
prediction accuracy, robustness to noise, and generalization across
manipulation and locomotion tasks. Notably, policies trained with our method
are successfully deployed on ANYmal D hardware in a zero-shot transfer,
achieving robust performance with minimal sim-to-real performance loss. This
work advances model-based reinforcement learning by addressing the challenges
of long-horizon prediction, error accumulation, and sim-to-real transfer. By
providing a scalable and robust framework, the introduced methods pave the way
for adaptive and efficient robotic systems in real-world applications.

摘要：學習強健且可概化的世界模型，對於在真實世界環境中實現高效且可擴充的機器人控制至關重要。在這項工作中，我們引入了一個新穎的框架，用於學習世界模型，以準確捕捉複雜、部分可觀察和隨機動態。所提出的方法採用雙自迴歸機制和自我監督訓練，以實現可靠的長時域預測，而無需依賴特定於領域的歸納偏差，從而確保跨越不同的機器人任務的可適應性。我們進一步提出了一個策略優化框架，該框架利用世界模型在想像的環境中進行高效訓練，並在真實世界系統中實現無縫部署。通過廣泛的實驗，我們的做法始終優於最先進的方法，展示了卓越的自迴歸預測準確性、對噪聲的魯棒性，以及在操作和運動任務上的泛化性。值得注意的是，使用我們的方法訓練的策略成功部署在 ANYmal D 硬體上，實現零次轉移，在模擬到真實的效能損失最小的情況下，實現強健的效能。這項工作透過解決長時域預測、誤差累積和模擬到真實轉移的挑戰，推動了基於模型的強化學習。透過提供可擴充且強健的框架，所引入的方法為真實世界應用中的適應性和高效機器人系統鋪平了道路。

##### **Robust Change Captioning in Remote Sensing: SECOND-CC Dataset and MModalCC Framework**
2501.10075v1 by Ali Can Karaca, M. Enes Ozelbas, Saadettin Berber, Orkhan Karimli, Turabi Yildirim, M. Fatih Amasyali

Remote sensing change captioning (RSICC) aims to describe changes between
bitemporal images in natural language. Existing methods often fail under
challenges like illumination differences, viewpoint changes, blur effects,
leading to inaccuracies, especially in no-change regions. Moreover, the images
acquired at different spatial resolutions and have registration errors tend to
affect the captions. To address these issues, we introduce SECOND-CC, a novel
RSICC dataset featuring high-resolution RGB image pairs, semantic segmentation
maps, and diverse real-world scenarios. SECOND-CC which contains 6,041 pairs of
bitemporal RS images and 30,205 sentences describing the differences between
images. Additionally, we propose MModalCC, a multimodal framework that
integrates semantic and visual data using advanced attention mechanisms,
including Cross-Modal Cross Attention (CMCA) and Multimodal Gated Cross
Attention (MGCA). Detailed ablation studies and attention visualizations
further demonstrate its effectiveness and ability to address RSICC challenges.
Comprehensive experiments show that MModalCC outperforms state-of-the-art RSICC
methods, including RSICCformer, Chg2Cap, and PSNet with +4.6% improvement on
BLEU4 score and +9.6% improvement on CIDEr score. We will make our dataset and
codebase publicly available to facilitate future research at
https://github.com/ChangeCapsInRS/SecondCC

摘要：遙感變動標題（RSICC）旨在以自然語言描述雙時序影像間的變動。現有方法經常在光照差異、視角變動、模糊效果等挑戰下失效，導致不準確，特別是在無變動區域。此外，以不同空間解析度取得的影像和註冊錯誤往往會影響標題。為了解決這些問題，我們引入了 SECOND-CC，這是一個新穎的 RSICC 資料集，具備高解析度 RGB 影像對、語意分割地圖和多元的真實世界場景。SECOND-CC 包含 6,041 對雙時序 RS 影像和 30,205 個描述影像差異的句子。此外，我們提出了 MModalCC，這是一個多模態架構，使用進階注意機制整合語意和視覺資料，包括跨模態交叉注意（CMCA）和多模態閘控交叉注意（MGCA）。詳細的消融研究和注意視覺化進一步證明了其有效性和解決 RSICC 挑戰的能力。綜合實驗顯示，MModalCC 優於現有 RSICC 方法，包括 RSICCformer、Chg2Cap 和 PSNet，在 BLEU4 評分上提升了 +4.6%，在 CIDEr 評分上提升了 +9.6%。我們將公開我們的資料集和程式碼庫，以利於後續研究，網址為 https://github.com/ChangeCapsInRS/SecondCC

##### **SpatialCoT: Advancing Spatial Reasoning through Coordinate Alignment and Chain-of-Thought for Embodied Task Planning**
2501.10074v1 by Yuecheng Liu, Dafeng Chi, Shiguang Wu, Zhanguang Zhang, Yaochen Hu, Lingfeng Zhang, Yingxue Zhang, Shuang Wu, Tongtong Cao, Guowei Huang, Guangjian Tian, Xingyue Quan, Jianye Hao, Yuzheng Zhuang

Spatial reasoning is an essential problem in embodied AI research. Efforts to
enhance spatial reasoning abilities through supplementary spatial data and
fine-tuning have proven limited and ineffective when addressing complex
embodied tasks, largely due to their dependence on language-based outputs.
While some approaches have introduced a point-based action space to mitigate
this issue, they fall short in managing more intricate tasks within complex
environments. This deficiency arises from their failure to fully exploit the
inherent thinking and reasoning capabilities that are fundamental strengths of
Vision-Language Models (VLMs). To address these limitations, we propose a novel
approach named SpatialCoT, specifically designed to bolster the spatial
reasoning capabilities of VLMs. Our approach comprises two stages: spatial
coordinate bi-directional alignment, which aligns vision-language inputs with
spatial coordinates, and chain-of-thought spatial grounding, which harnesses
the reasoning capabilities of language models for advanced spatial reasoning.
We evaluate SpatialCoT on challenging navigation and manipulation tasks, both
in simulation and real-world settings. Experimental results demonstrate that
our method significantly outperforms previous state-of-the-art approaches in
both tasks.

摘要：空間推理是具身人工智慧研究中的基本問題。透過補充空間資料和微調來增強空間推理能力的努力，在處理複雜的具身任務時已被證明是有限且無效的，這主要是因為它們依賴於基於語言的輸出。雖然有些方法引入了基於點的動作空間來減輕這個問題，但它們在管理複雜環境中的更複雜任務時卻力有未逮。這種不足來自於它們未能充分利用作為視覺語言模型 (VLM) 基本優勢的內在思考和推理能力。為了解決這些限制，我們提出了一種名為 SpatialCoT 的新方法，專門設計用來加強 VLM 的空間推理能力。我們的做法包含兩個階段：空間坐標雙向對齊，它將視覺語言輸入與空間坐標對齊；以及思考鏈空間基礎，它利用語言模型的推理能力進行進階空間推理。我們在具挑戰性的導航和操作任務中評估 SpatialCoT，包括模擬和真實世界設定。實驗結果表明，我們的模型在兩種任務中都明顯優於先前的最先進方法。

##### **Author-Specific Linguistic Patterns Unveiled: A Deep Learning Study on Word Class Distributions**
2501.10072v1 by Patrick Krauss, Achim Schilling

Deep learning methods have been increasingly applied to computational
linguistics to uncover patterns in text data. This study investigates
author-specific word class distributions using part-of-speech (POS) tagging and
bigram analysis. By leveraging deep neural networks, we classify literary
authors based on POS tag vectors and bigram frequency matrices derived from
their works. We employ fully connected and convolutional neural network
architectures to explore the efficacy of unigram and bigram-based
representations. Our results demonstrate that while unigram features achieve
moderate classification accuracy, bigram-based models significantly improve
performance, suggesting that sequential word class patterns are more
distinctive of authorial style. Multi-dimensional scaling (MDS) visualizations
reveal meaningful clustering of authors' works, supporting the hypothesis that
stylistic nuances can be captured through computational methods. These findings
highlight the potential of deep learning and linguistic feature analysis for
author profiling and literary studies.

摘要：深度學習方法已日益應用於計算語言學，以揭示文本資料中的模式。本研究使用詞性標記和二元分析調查作者特定的詞類分佈。透過利用深度神經網路，我們根據從其作品中衍生的詞性標記向量和二元頻率矩陣對文學作者進行分類。我們採用全連接和卷積神經網路架構來探討一元和二元表示的功效。我們的結果表明，雖然一元特徵可達成適度的分類準確度，但基於二元的模型顯著提升了效能，這表示連續詞類模式更能區分作者風格。多維度縮放 (MDS) 視覺化揭示了作者作品的意義聚類，支持了風格細微差別可透過計算方法擷取的假設。這些發現突顯了深度學習和語言特徵分析在作者輪廓和文學研究中的潛力。

##### **A Survey on LLM Test-Time Compute via Search: Tasks, LLM Profiling, Search Algorithms, and Relevant Frameworks**
2501.10069v1 by Xinzhe Li

LLM test-time compute (or LLM inference) via search has emerged as a
promising research area with rapid developments. However, current frameworks
often adopt distinct perspectives on three key aspects (task definition, LLM
profiling, and search procedures), making direct comparisons challenging.
Moreover, the search algorithms employed often diverge from standard
implementations, and their specific characteristics are not thoroughly
specified. In this survey, we provide a comprehensive technical review that
unifies task definitions and provides modular definitions of LLM profiling and
search procedures. The definitions enable precise comparisons of various LLM
inference frameworks while highlighting their departures from conventional
search algorithms. We also discuss the applicability, performance, and
efficiency of these methods. For further details and ongoing updates, please
refer to our GitHub repository:
https://github.com/xinzhel/LLM-Agent-Survey/blob/main/search.md

摘要：LLM 測試時間運算（或 LLM 推論）透過搜尋已成為一個有前途的研究領域，並有快速的發展。然而，目前的架構通常在三個關鍵方面（任務定義、LLM 輪廓分析和搜尋程序）採用不同的觀點，這使得直接比較具有挑戰性。此外，所採用的搜尋演算法通常偏離標準實作，而且它們的具體特徵並未徹底說明。在這項調查中，我們提供了一個全面的技術回顧，統一任務定義，並提供 LLM 輪廓分析和搜尋程序的模組化定義。這些定義能夠精確比較各種 LLM 推論架構，同時強調它們與傳統搜尋演算法的差異。我們也討論這些方法的適用性、效能和效率。有關進一步的詳細資訊和持續更新，請參閱我們的 GitHub 儲存庫：
https://github.com/xinzhel/LLM-Agent-Survey/blob/main/search.md

##### **OMoE: Diversifying Mixture of Low-Rank Adaptation by Orthogonal Finetuning**
2501.10062v1 by Jinyuan Feng, Zhiqiang Pu, Tianyi Hu, Dongmin Li, Xiaolin Ai, Huimu Wang

Building mixture-of-experts (MoE) architecture for Low-rank adaptation (LoRA)
is emerging as a potential direction in parameter-efficient fine-tuning (PEFT)
for its modular design and remarkable performance. However, simply stacking the
number of experts cannot guarantee significant improvement. In this work, we
first conduct qualitative analysis to indicate that experts collapse to similar
representations in vanilla MoE, limiting the capacity of modular design and
computational efficiency. Ulteriorly, Our analysis reveals that the performance
of previous MoE variants maybe limited by a lack of diversity among experts.
Motivated by these findings, we propose Orthogonal Mixture-of-Experts (OMoE), a
resource-efficient MoE variant that trains experts in an orthogonal manner to
promote diversity. In OMoE, a Gram-Schmidt process is leveraged to enforce that
the experts' representations lie within the Stiefel manifold. By applying
orthogonal constraints directly to the architecture, OMoE keeps the learning
objective unchanged, without compromising optimality. Our method is simple and
alleviates memory bottlenecks, as it incurs minimal experts compared to vanilla
MoE models. Experiments on diverse commonsense reasoning benchmarks demonstrate
that OMoE can consistently achieve stable and efficient performance improvement
when compared with the state-of-the-art methods while significantly reducing
the number of required experts.

摘要：<paragraph>建立混合专家 (MoE) 架構，用於低秩適應 (LoRA)，由於其模組化設計和卓越的效能，逐漸成為參數有效微調 (PEFT) 中潛在的方向。然而，單純堆疊專家數量無法保證顯著改善。在這項工作中，我們首先進行定性分析，以指出專家在香草 MoE 中會崩潰成類似的表示，限制了模組化設計和運算效率的能力。進一步來說，我們的分析顯示，先前的 MoE 變體效能可能受到專家之間缺乏多樣性的限制。受到這些發現的啟發，我們提出了正交混合專家 (OMoE)，這是一種資源有效率的 MoE 變體，它以正交方式訓練專家，以促進多樣性。在 OMoE 中，利用 Gram-Schmidt 程序來強制執行專家的表示位於 Stiefel 流形內。透過將正交約束直接應用於架構，OMoE 保持學習目標不變，同時不影響最佳性。我們的模型簡單，且可減輕記憶體瓶頸，因為與香草 MoE 模型相比，它會產生最少的專家。在各種常識推理基準測試上的實驗證明，與最先進的方法相比，OMoE 可以持續達成穩定且有效率的效能改善，同時大幅減少所需的專家數量。</paragraph>

##### **MSTS: A Multimodal Safety Test Suite for Vision-Language Models**
2501.10057v1 by Paul Röttger, Giuseppe Attanasio, Felix Friedrich, Janis Goldzycher, Alicia Parrish, Rishabh Bhardwaj, Chiara Di Bonaventura, Roman Eng, Gaia El Khoury Geagea, Sujata Goswami, Jieun Han, Dirk Hovy, Seogyeong Jeong, Paloma Jeretič, Flor Miriam Plaza-del-Arco, Donya Rooein, Patrick Schramowski, Anastassia Shaitarova, Xudong Shen, Richard Willats, Andrea Zugarini, Bertie Vidgen

Vision-language models (VLMs), which process image and text inputs, are
increasingly integrated into chat assistants and other consumer AI
applications. Without proper safeguards, however, VLMs may give harmful advice
(e.g. how to self-harm) or encourage unsafe behaviours (e.g. to consume drugs).
Despite these clear hazards, little work so far has evaluated VLM safety and
the novel risks created by multimodal inputs. To address this gap, we introduce
MSTS, a Multimodal Safety Test Suite for VLMs. MSTS comprises 400 test prompts
across 40 fine-grained hazard categories. Each test prompt consists of a text
and an image that only in combination reveal their full unsafe meaning. With
MSTS, we find clear safety issues in several open VLMs. We also find some VLMs
to be safe by accident, meaning that they are safe because they fail to
understand even simple test prompts. We translate MSTS into ten languages,
showing non-English prompts to increase the rate of unsafe model responses. We
also show models to be safer when tested with text only rather than multimodal
prompts. Finally, we explore the automation of VLM safety assessments, finding
even the best safety classifiers to be lacking.

摘要：視覺語言模型（VLM）處理影像和文字輸入，正逐漸整合到聊天機器人和其他消費者人工智慧應用程式中。然而，在沒有適當的防護措施下，VLM 可能會提供有害的建議（例如如何自殘）或鼓勵不安全的行為（例如吸毒）。儘管有這些明顯的危害，到目前為止，很少有研究評估 VLM 的安全性以及多模態輸入所造成的全新風險。為了解決這個問題，我們引入了 MSTS，這是一個針對 VLM 的多模態安全測試套件。MSTS 包含 40 個細緻的危害類別中 400 個測試提示。每個測試提示都包含一個文字和一個影像，只有將它們組合起來才能揭示其完整的危險含義。透過 MSTS，我們在幾個開放的 VLM 中發現了明顯的安全問題。我們也發現一些 VLM 意外地安全，這表示它們是安全的，因為它們甚至無法理解簡單的測試提示。我們將 MSTS 翻譯成十種語言，顯示非英文提示以增加不安全的模型回應率。我們也發現，當僅使用文字而不是多模態提示進行測試時，模型會更安全。最後，我們探索 VLM 安全評估的自動化，發現即使是最好的安全分類器也有所欠缺。

##### **Accelerating Large Language Models through Partially Linear Feed-Forward Network**
2501.10054v1 by Gansen Hu, Zhaoguo Wang, Jinglin Wei, Wei Huang, Haibo Chen

Large language models (LLMs) demonstrate remarkable capabilities but face
deployment challenges due to their massive parameter counts. While existing
compression techniques like pruning can reduce model size, it leads to
significant accuracy degradation under high compression ratios. We present a
novel perspective inspired by constant folding in compiler optimization. Our
approach enables parameter reduction by treating activation functions in LLMs
as linear functions.
  However, recent LLMs use complex non-linear activations like GELU that
prevent direct application of this technique. We propose TARDIS, which enables
optimization of LLMs with non-linear activations by partially approximating
them with linear functions in frequently occurring input ranges. For outlier
inputs, TARDIS employs an online predictor to dynamically fall back to original
computations.
  Our experiments demonstrate that TARDIS achieves 80% parameter reduction in
feed-forward networks, while significantly outperforming state-of-the-art
pruning methods Wanda and RIA with up to 65% higher accuracy. In practical
deployments for a 7B model, TARDIS achieves 1.6x end-to-end inference speedup
when integrated with the vLLM serving system, and 1.4x speedup with the widely
adopted HuggingFace implementation, while incurring only a 10.9% accuracy
trade-off.

摘要：大型語言模型 (LLM) 展示了非凡的能力，但由於其龐大的參數數量而面臨部署挑戰。雖然現有的壓縮技術（如剪枝）可以縮小模型大小，但它會在高壓縮率下導致顯著的準確性下降。我們提出了一個新穎的觀點，靈感來自編譯器優化中的常數摺疊。我們的做法通過將 LLM 中的激活函數視為線性函數來實現參數減少。
然而，最近的 LLM 使用複雜的非線性激活（如 GELU），這阻止了該技術的直接應用。我們提出了 TARDIS，它通過在頻繁出現的輸入範圍內部分近似線性函數來實現具有非線性激活的 LLM 的優化。對於異常輸入，TARDIS 使用線上預測器動態回退到原始計算。
我們的實驗表明，TARDIS 在前饋網路中實現了 80% 的參數減少，同時顯著優於最先進的剪枝方法 Wanda 和 RIA，準確度提高了 65%。在對 7B 模型的實際部署中，TARDIS 與 vLLM 服務系統集成時實現了 1.6 倍的端到端推理加速，與廣泛採用的 HuggingFace 實現相比加速了 1.4 倍，同時僅產生了 10.9% 的準確性折衷。

##### **AirRAG: Activating Intrinsic Reasoning for Retrieval Augmented Generation via Tree-based Search**
2501.10053v1 by Wenfeng Feng, Chuzhan Hao, Yuewei Zhang, Jingyi Song, Hao Wang

Leveraging the autonomous decision-making capabilities of large language
models (LLMs) demonstrates superior performance in reasoning tasks. Despite the
successes of iterative or recursive retrieval-augmented generation (RAG), they
often are trapped in a single solution space when confronted with complex
tasks. In this paper, we propose a novel thinking pattern in RAG which
integrates system analysis with efficient reasoning actions, significantly
activating intrinsic reasoning capabilities and expanding the solution space of
specific tasks via Monte Carlo Tree Search (MCTS), dubbed AirRAG. Specifically,
our approach designs five fundamental reasoning actions that are expanded to a
wide tree-based reasoning spaces using MCTS. The extension also uses
self-consistency verification to explore potential reasoning paths and
implement inference scaling. In addition, computationally optimal strategies
are used to apply more inference computation to key actions to achieve further
performance improvements. Experimental results demonstrate the effectiveness of
AirRAG through considerable performance gains over complex QA datasets.
Furthermore, AirRAG is flexible and lightweight, making it easy to integrate
with other advanced technologies.

摘要：利用大型語言模型 (LLM) 的自主決策能力，在推理任務中展現出優異的表現。儘管反覆或遞迴檢索增強生成 (RAG) 獲得成功，但它們在面對複雜任務時，常常受限於單一的解空間。在本文中，我們提出 RAG 中一種創新的思考模式，它將系統分析與有效的推理動作整合在一起，透過蒙地卡羅樹狀搜尋 (MCTS) 大幅啟用內在推理能力，並擴展特定任務的解空間，稱為 AirRAG。具體來說，我們的方法設計了五項基本推理動作，並使用 MCTS 將其擴展到一個廣大的樹狀推理空間。這個擴充也使用自我一致性驗證來探索潛在的推理路徑，並實作推理縮放。此外，使用計算最佳策略，將更多的推理運算套用於關鍵動作，以達成進一步的效能提升。實驗結果透過在複雜的問答資料集上獲得顯著的效能提升，證明了 AirRAG 的有效性。此外，AirRAG 具有彈性和輕量化的特性，使其易於與其他先進技術整合。

##### **Virtual Nodes Improve Long-term Traffic Prediction**
2501.10048v1 by Xiaoyang Cao, Dingyi Zhuang, Jinhua Zhao, Shenhao Wang

Effective traffic prediction is a cornerstone of intelligent transportation
systems, enabling precise forecasts of traffic flow, speed, and congestion.
While traditional spatio-temporal graph neural networks (ST-GNNs) have achieved
notable success in short-term traffic forecasting, their performance in
long-term predictions remains limited. This challenge arises from
over-squashing problem, where bottlenecks and limited receptive fields restrict
information flow and hinder the modeling of global dependencies. To address
these challenges, this study introduces a novel framework that incorporates
virtual nodes, which are additional nodes added to the graph and connected to
existing nodes, in order to aggregate information across the entire graph
within a single GNN layer. Our proposed model incorporates virtual nodes by
constructing a semi-adaptive adjacency matrix. This matrix integrates
distance-based and adaptive adjacency matrices, allowing the model to leverage
geographical information while also learning task-specific features from data.
Experimental results demonstrate that the inclusion of virtual nodes
significantly enhances long-term prediction accuracy while also improving
layer-wise sensitivity to mitigate the over-squashing problem. Virtual nodes
also offer enhanced explainability by focusing on key intersections and
high-traffic areas, as shown by the visualization of their adjacency matrix
weights on road network heat maps. Our advanced approach enhances the
understanding and management of urban traffic systems, making it particularly
well-suited for real-world applications.

摘要：有效的交通預測是智慧運輸系統的基石，能精準預測交通流量、速度和擁堵狀況。雖然傳統時空圖形神經網路 (ST-GNN) 在短期交通預測中取得顯著成功，但其在長期預測中的表現仍有待加強。這個挑戰來自過度壓縮問題，其中瓶頸和有限的感受野會限制資訊流動，並阻礙對全局依賴性的建模。為了應對這些挑戰，本研究引入了一個創新的架構，其中包含虛擬節點，這些節點是新增到圖形中並連接到現有節點，以便在單個 GNN 層中彙總整個圖形中的資訊。我們提出的模型透過建構半自適應鄰接矩陣來納入虛擬節點。此矩陣整合了基於距離和自適應的鄰接矩陣，讓模型能夠利用地理資訊，同時也能從資料中學習特定於任務的特性。實驗結果表明，虛擬節點的加入顯著提升了長期預測的準確度，同時也改善了層級敏感度，以減輕過度壓縮問題。虛擬節點還透過關注關鍵路口和高流量區域，提供了增強的可解釋性，如其鄰接矩陣權重在道路網路熱圖上的視覺化所示。我們進階的方法增強了對都市交通系統的理解和管理，使其特別適合於真實世界的應用。

##### **Spatiotemporal Prediction of Secondary Crashes by Rebalancing Dynamic and Static Data with Generative Adversarial Networks**
2501.10041v1 by Junlan Chen, Yiqun Li, Chenyu Ling, Ziyuan Pu, Xiucheng Guo

Data imbalance is a common issue in analyzing and predicting sudden traffic
events. Secondary crashes constitute only a small proportion of all crashes.
These secondary crashes, triggered by primary crashes, significantly exacerbate
traffic congestion and increase the severity of incidents. However, the severe
imbalance of secondary crash data poses significant challenges for prediction
models, affecting their generalization ability and prediction accuracy.
Existing methods fail to fully address the complexity of traffic crash data,
particularly the coexistence of dynamic and static features, and often struggle
to effectively handle data samples of varying lengths. Furthermore, most
current studies predict the occurrence probability and spatiotemporal
distribution of secondary crashes separately, lacking an integrated solution.
To address these challenges, this study proposes a hybrid model named
VarFusiGAN-Transformer, aimed at improving the fidelity of secondary crash data
generation and jointly predicting the occurrence and spatiotemporal
distribution of secondary crashes. The VarFusiGAN-Transformer model employs
Long Short-Term Memory (LSTM) networks to enhance the generation of
multivariate long-time series data, incorporating a static data generator and
an auxiliary discriminator to model the joint distribution of dynamic and
static features. In addition, the model's prediction module achieves
simultaneous prediction of both the occurrence and spatiotemporal distribution
of secondary crashes. Compared to existing methods, the proposed model
demonstrates superior performance in generating high-fidelity data and
improving prediction accuracy.

摘要：數據不平衡是分析和預測突發交通事件的常見問題。二次碰撞只佔所有碰撞的一小部分。這些由主要碰撞引發的二次碰撞會顯著加劇交通擁堵，並增加事故的嚴重性。然而，二次碰撞數據的嚴重不平衡對預測模型提出了重大挑戰，影響了它們的泛化能力和預測準確性。現有方法未能充分解決交通事故數據的複雜性，特別是動態特徵和靜態特徵並存，並且經常難以有效處理長度不同的數據樣本。此外，當前大多數研究分別預測二次碰撞的發生機率和時空分佈，缺乏一個整體的解決方案。為了應對這些挑戰，本研究提出了一個名為 VarFusiGAN-Transformer 的混合模型，旨在提高二次碰撞數據生成的保真度，並聯合預測二次碰撞的發生和時空分佈。VarFusiGAN-Transformer 模型採用長短期記憶 (LSTM) 網路來增強多變量長時間序列數據的生成，並結合一個靜態數據生成器和一個輔助判別器來建模動態特徵和靜態特徵的聯合分佈。此外，該模型的預測模組實現了對二次碰撞的發生和時空分佈的同時預測。與現有方法相比，所提出的模型在生成高保真數據和提高預測準確性方面表現出優異的性能。

##### **Automatic Speech Recognition for Sanskrit with Transfer Learning**
2501.10024v1 by Bidit Sadhukhan, Swami Punyeshwarananda

Sanskrit, one of humanity's most ancient languages, has a vast collection of
books and manuscripts on diverse topics that have been accumulated over
millennia. However, its digital content (audio and text), which is vital for
the training of AI systems, is profoundly limited. Furthermore, its intricate
linguistics make it hard to develop robust NLP tools for wider accessibility.
Given these constraints, we have developed an automatic speech recognition
model for Sanskrit by employing transfer learning mechanism on OpenAI's Whisper
model. After carefully optimising the hyper-parameters, we obtained promising
results with our transfer-learned model achieving a word error rate of 15.42%
on Vaksancayah dataset. An online demo of our model is made available for the
use of public and to evaluate its performance firsthand thereby paving the way
for improved accessibility and technological support for Sanskrit learning in
the modern era.

摘要：梵語是人類最古老的語言之一，擁有大量關於不同主題的書籍和手稿，這些書籍和手稿在數千年來不斷累積。然而，對於 AI 系統訓練至關重要的數位內容（音訊和文字）卻嚴重受限。此外，其複雜的語言學特徵使得難以開發強大的 NLP 工具以利於更廣泛的存取。有鑑於這些限制，我們採用 OpenAI 的 Whisper 模型上的遷移學習機制，開發了梵語自動語音辨識模型。在仔細最佳化超參數後，我們透過遷移學習模型在 Vaksancayah 資料集上獲得了令人滿意的結果，字元錯誤率為 15.42%。我們已公開模型的線上示範，供大眾使用並親自評估其效能，進而為現代梵語學習的普及和技術支援鋪路。

##### **Enhancing Crash Frequency Modeling Based on Augmented Multi-Type Data by Hybrid VAE-Diffusion-Based Generative Neural Networks**
2501.10017v1 by Junlan Chen, Qijie He, Pei Liu, Wei Ma, Ziyuan Pu

Crash frequency modelling analyzes the impact of factors like traffic volume,
road geometry, and environmental conditions on crash occurrences. Inaccurate
predictions can distort our understanding of these factors, leading to
misguided policies and wasted resources, which jeopardize traffic safety. A key
challenge in crash frequency modelling is the prevalence of excessive zero
observations, caused by underreporting, the low probability of crashes, and
high data collection costs. These zero observations often reduce model accuracy
and introduce bias, complicating safety decision making. While existing
approaches, such as statistical methods, data aggregation, and resampling,
attempt to address this issue, they either rely on restrictive assumptions or
result in significant information loss, distorting crash data. To overcome
these limitations, we propose a hybrid VAE-Diffusion neural network, designed
to reduce zero observations and handle the complexities of multi-type tabular
crash data (count, ordinal, nominal, and real-valued variables). We assess the
synthetic data quality generated by this model through metrics like similarity,
accuracy, diversity, and structural consistency, and compare its predictive
performance against traditional statistical models. Our findings demonstrate
that the hybrid VAE-Diffusion model outperforms baseline models across all
metrics, offering a more effective approach to augmenting crash data and
improving the accuracy of crash frequency predictions. This study highlights
the potential of synthetic data to enhance traffic safety by improving crash
frequency modelling and informing better policy decisions.

摘要：車禍頻率模型分析了交通流量、道路幾何形狀和環境條件等因素對車禍發生的影響。不準確的預測會扭曲我們對這些因素的理解，導致錯誤的政策和浪費資源，進而危害交通安全。車禍頻率建模中的關鍵挑戰是過度零觀測的普遍性，這是由於低報、車禍發生的機率低和資料收集成本高所造成的。這些零觀測通常會降低模型準確度並引入偏差，使安全決策制定複雜化。雖然現有的方法，例如統計方法、資料彙總和重新抽樣，嘗試解決這個問題，但它們依賴於限制性假設或導致顯著的資訊損失，扭曲了車禍資料。為了克服這些限制，我們提出一個混合 VAE-Diffusion 神經網路，旨在減少零觀測並處理多種類型表格車禍資料（計數、序數、名義和實值變數）的複雜性。我們透過類似性、準確度、多樣性和結構一致性等指標評估此模型產生的合成資料品質，並將其預測效能與傳統統計模型進行比較。我們的研究結果表明，混合 VAE-Diffusion 模型在所有指標上都優於基線模型，提供一種更有效的方法來擴充車禍資料並提高車禍頻率預測的準確度。本研究突顯了合成資料在透過改善車禍頻率建模和提供更好的政策決策來增強交通安全方面的潛力。

##### **Mitigating Hallucinations on Object Attributes using Multiview Images and Negative Instructions**
2501.10011v1 by Zhijie Tan, Yuzhi Li, Shengwei Meng, Xiang Yuan, Weiping Li, Tong Mo, Bingce Wang, Xu Chu

Current popular Large Vision-Language Models (LVLMs) are suffering from
Hallucinations on Object Attributes (HoOA), leading to incorrect determination
of fine-grained attributes in the input images. Leveraging significant
advancements in 3D generation from a single image, this paper proposes a novel
method to mitigate HoOA in LVLMs. This method utilizes multiview images sampled
from generated 3D representations as visual prompts for LVLMs, thereby
providing more visual information from other viewpoints. Furthermore, we
observe the input order of multiple multiview images significantly affects the
performance of LVLMs. Consequently, we have devised Multiview Image Augmented
VLM (MIAVLM), incorporating a Multiview Attributes Perceiver (MAP) submodule
capable of simultaneously eliminating the influence of input image order and
aligning visual information from multiview images with Large Language Models
(LLMs). Besides, we designed and employed negative instructions to mitigate
LVLMs' bias towards ``Yes" responses. Comprehensive experiments demonstrate the
effectiveness of our method.

摘要：當前流行的大型視覺語言模型 (LVLMs) 飽受物件屬性幻覺 (HoOA) 之苦，導致無法正確判斷輸入影像中的細微屬性。本文利用從單一影像進行 3D 生成的重大進展，提出了一種新穎的方法來減輕 LVLMs 中的 HoOA。此方法利用從生成 3D 表徵中取樣的多分解度影像作為 LVLMs 的視覺提示，從而從其他視角提供更多視覺資訊。此外，我們觀察到多個多分解度影像的輸入順序會顯著影響 LVLMs 的效能。因此，我們設計了多分解度影像擴充 VLM (MIAVLM)，其中包含一個多分解度屬性感知器 (MAP) 子模組，該模組能夠同時消除輸入影像順序的影響，並將多分解度影像的視覺資訊與大型語言模型 (LLMs) 對齊。此外，我們設計並採用負面指令來減輕 LVLMs 對「是」回應的偏見。全面的實驗證明了我們方法的有效性。

##### **Adaptive Spatiotemporal Augmentation for Improving Dynamic Graph Learning**
2501.10010v1 by Xu Chu, Hanlin Xue, Bingce Wang, Xiaoyang Liu, Weiping Li, Tong Mo, Tuoyu Feng, Zhijie Tan

Dynamic graph augmentation is used to improve the performance of dynamic
GNNs. Most methods assume temporal locality, meaning that recent edges are more
influential than earlier edges. However, for temporal changes in edges caused
by random noise, overemphasizing recent edges while neglecting earlier ones may
lead to the model capturing noise. To address this issue, we propose STAA
(SpatioTemporal Activity-Aware Random Walk Diffusion). STAA identifies nodes
likely to have noisy edges in spatiotemporal dimensions. Spatially, it analyzes
critical topological positions through graph wavelet coefficients. Temporally,
it analyzes edge evolution through graph wavelet coefficient change rates.
Then, random walks are used to reduce the weights of noisy edges, deriving a
diffusion matrix containing spatiotemporal information as an augmented
adjacency matrix for dynamic GNN learning. Experiments on multiple datasets
show that STAA outperforms other dynamic graph augmentation methods in node
classification and link prediction tasks.

摘要：動態圖增強用於提升動態 GNN 的效能。大多數方法假設時間局部性，意指最近的邊比較早的邊更有影響力。然而，對於由隨機雜訊所造成的邊的時間變化，過度強調最近的邊而忽略較早的邊可能會導致模型擷取雜訊。為了解決此問題，我們提出 STAA（時空活動感知隨機漫步擴散）。STAA 識別在時空維度中可能有雜訊邊的節點。在空間上，它透過圖小波係數分析臨界拓撲位置。在時間上，它透過圖小波係數變化率分析邊的演變。然後，隨機漫步用於降低雜訊邊的權重，衍生一個包含時空資訊的擴散矩陣，作為動態 GNN 學習的擴增鄰接矩陣。在多個資料集上的實驗顯示，STAA 在節點分類和連結預測任務中優於其他動態圖增強方法。

##### **Deep Learning for Early Alzheimer Disease Detection with MRI Scans**
2501.09999v1 by Mohammad Rafsan, Tamer Oraby, Upal Roy, Sanjeev Kumar, Hansapani Rodrigo

Alzheimer's Disease is a neurodegenerative condition characterized by
dementia and impairment in neurological function. The study primarily focuses
on the individuals above age 40, affecting their memory, behavior, and
cognitive processes of the brain. Alzheimer's disease requires diagnosis by a
detailed assessment of MRI scans and neuropsychological tests of the patients.
This project compares existing deep learning models in the pursuit of enhancing
the accuracy and efficiency of AD diagnosis, specifically focusing on the
Convolutional Neural Network, Bayesian Convolutional Neural Network, and the
U-net model with the Open Access Series of Imaging Studies brain MRI dataset.
Besides, to ensure robustness and reliability in the model evaluations, we
address the challenge of imbalance in data. We then perform rigorous evaluation
to determine strengths and weaknesses for each model by considering
sensitivity, specificity, and computational efficiency. This comparative
analysis would shed light on the future role of AI in revolutionizing AD
diagnostics but also paved ways for future innovation in medical imaging and
the management of neurodegenerative diseases.

摘要：阿茲海默症是一種神經退化性疾病，特徵為失智和神經功能受損。本研究主要針對 40 歲以上的個人，影響他們的記憶力、行為和認知過程。阿茲海默症需要透過詳細評估病患的 MRI 掃描和神經心理測試來診斷。本專案比較現有的深度學習模型，以尋求提升 AD 診斷的準確性和效率，特別著重於卷積神經網路、貝氏卷積神經網路和 U-net 模型，以及開放取用影像研究系列的腦部 MRI 資料集。此外，為了確保模型評估的穩健性和可靠性，我們解決了資料不平衡的挑戰。接著我們執行嚴謹的評估，透過考量敏感度、特異度和計算效率來確定每個模型的優缺點。此比較分析將闡明 AI 在革新 AD 診斷方面的未來角色，也為醫學影像和神經退化性疾病管理的未來創新鋪路。

##### **Attention-guided Self-reflection for Zero-shot Hallucination Detection in Large Language Models**
2501.09997v1 by Qiang Liu, Xinlong Chen, Yue Ding, Shizhen Xu, Shu Wu, Liang Wang

Hallucination has emerged as a significant barrier to the effective
application of Large Language Models (LLMs). In this work, we introduce a novel
Attention-Guided SElf-Reflection (AGSER) approach for zero-shot hallucination
detection in LLMs. The AGSER method utilizes attention contributions to
categorize the input query into attentive and non-attentive queries. Each query
is then processed separately through the LLMs, allowing us to compute
consistency scores between the generated responses and the original answer. The
difference between the two consistency scores serves as a hallucination
estimator. In addition to its efficacy in detecting hallucinations, AGSER
notably reduces computational complexity, requiring only three passes through
the LLM and utilizing two sets of tokens. We have conducted extensive
experiments with four widely-used LLMs across three different hallucination
benchmarks, demonstrating that our approach significantly outperforms existing
methods in zero-shot hallucination detection.

摘要：幻覺已成為大型語言模型 (LLM) 有效應用的一項重大障礙。在這項工作中，我們介紹了一種新穎的注意力引導自我反省 (AGSER) 方法，用於 LLM 中的零次發射幻覺檢測。AGSER 方法利用注意力貢獻將輸入查詢分類為注意力查詢和非注意力查詢。然後通過 LLM 分別處理每個查詢，使我們能夠計算生成回應與原始答案之間的一致性分數。兩個一致性分數之間的差異作為幻覺估計器。除了在檢測幻覺方面有效之外，AGSER 還顯著降低了計算複雜度，只需通過 LLM 執行三次並使用兩組標記。我們對四個廣泛使用的 LLM 進行了廣泛的實驗，涵蓋了三個不同的幻覺基準，證明了我們的方法在零次發射幻覺檢測中顯著優於現有方法。

##### **Multi-Modal Attention Networks for Enhanced Segmentation and Depth Estimation of Subsurface Defects in Pulse Thermography**
2501.09994v1 by Mohammed Salah, Naoufel Werghi, Davor Svetinovic, Yusra Abdulrahman

AI-driven pulse thermography (PT) has become a crucial tool in
non-destructive testing (NDT), enabling automatic detection of hidden anomalies
in various industrial components. Current state-of-the-art techniques feed
segmentation and depth estimation networks compressed PT sequences using either
Principal Component Analysis (PCA) or Thermographic Signal Reconstruction
(TSR). However, treating these two modalities independently constrains the
performance of PT inspection models as these representations possess
complementary semantic features. To address this limitation, this work proposes
PT-Fusion, a multi-modal attention-based fusion network that fuses both PCA and
TSR modalities for defect segmentation and depth estimation of subsurface
defects in PT setups. PT-Fusion introduces novel feature fusion modules,
Encoder Attention Fusion Gate (EAFG) and Attention Enhanced Decoding Block
(AEDB), to fuse PCA and TSR features for enhanced segmentation and depth
estimation of subsurface defects. In addition, a novel data augmentation
technique is proposed based on random data sampling from thermographic
sequences to alleviate the scarcity of PT datasets. The proposed method is
benchmarked against state-of-the-art PT inspection models, including U-Net,
attention U-Net, and 3D-CNN on the Universit\'e Laval IRT-PVC dataset. The
results demonstrate that PT-Fusion outperforms the aforementioned models in
defect segmentation and depth estimation accuracies with a margin of 10%.

摘要：以 AI 為主的脈衝熱像儀 (PT) 已成為非破壞性檢測 (NDT) 中的關鍵工具，可自動偵測各種工業組件中隱藏的異常。目前最先進的技術使用主成分分析 (PCA) 或熱影像信號重建 (TSR) 將壓縮的 PT 序列提供給分割和深度估計網路。然而，獨立處理這兩種方式會限制 PT 檢測模型的效能，因為這些表示具有互補的語義特徵。為了解決此限制，本研究提出 PT-Fusion，一種基於多模式注意力的融合網路，它融合 PCA 和 TSR 模式，用於 PT 設定中地下缺陷的缺陷分割和深度估計。PT-Fusion 引入了新穎的特徵融合模組，編碼器注意力融合閘 (EAFG) 和注意力增強解碼區塊 (AEDB)，以融合 PCA 和 TSR 特徵，以增強地下缺陷的分割和深度估計。此外，還提出了一種基於熱影像序列隨機資料抽樣的資料擴充技術，以緩解 PT 資料集的稀缺性。所提出的方法與最先進的 PT 檢測模型進行基準測試，包括 U-Net、注意力 U-Net 和 Universit\'e Laval IRT-PVC 資料集上的 3D-CNN。結果表明，PT-Fusion 在缺陷分割和深度估計準確率方面優於上述模型，誤差在 10% 以內。

##### **Agent-as-Judge for Factual Summarization of Long Narratives**
2501.09993v1 by Yeonseok Jeong, Minsoo Kim, Seung-won Hwang, Byung-Hak Kim

Large Language Models (LLMs) have demonstrated near-human performance in
summarization tasks based on traditional metrics such as ROUGE and BERTScore.
However, these metrics do not adequately capture critical aspects of
summarization quality, such as factual accuracy, particularly for long
narratives (>100K tokens). Recent advances, such as LLM-as-a-Judge, address the
limitations of metrics based on lexical similarity but still exhibit factual
inconsistencies, especially in understanding character relationships and
states. In this work, we introduce NarrativeFactScore, a novel
"Agent-as-a-Judge" framework for evaluating and refining summaries. By
leveraging a Character Knowledge Graph (CKG) extracted from input and generated
summaries, NarrativeFactScore assesses the factual consistency and provides
actionable guidance for refinement, such as identifying missing or erroneous
facts. We demonstrate the effectiveness of NarrativeFactScore through a
detailed workflow illustration and extensive validation on widely adopted
benchmarks, achieving superior performance compared to competitive methods. Our
results highlight the potential of agent-driven evaluation systems to improve
the factual reliability of LLM-generated summaries.

摘要：大型語言模型 (LLM) 在摘要任務中展現出接近人類的表現，根據傳統指標，例如 ROUGE 和 BERTScore。然而，這些指標並未充分掌握摘要品質的關鍵面向，例如事實準確性，特別是針對長篇敘事 (>100K 個符號)。最近的進展，例如 LLM-as-a-Judge，解決了基於詞彙相似性的指標限制，但仍然表現出事實上的不一致性，特別是在理解角色關係和狀態方面。在這項工作中，我們引入了 NarrativeFactScore，一種新穎的「代理人作為評審」架構，用於評估和精煉摘要。透過利用從輸入和產生的摘要中萃取的角色知識圖譜 (CKG)，NarrativeFactScore 評估事實一致性，並提供可行的精煉指南，例如識別遺漏或錯誤的事實。我們透過詳細的工作流程說明和廣泛驗證在廣泛採用的基準上，證明了 NarrativeFactScore 的有效性，與競爭方法相比，達到了卓越的表現。我們的結果突顯了代理人驅動評估系統的潛力，以改善 LLM 生成的摘要的事實可靠性。

##### **RichSpace: Enriching Text-to-Video Prompt Space via Text Embedding Interpolation**
2501.09982v1 by Yuefan Cao, Chengyue Gong, Xiaoyu Li, Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song

Text-to-video generation models have made impressive progress, but they still
struggle with generating videos with complex features. This limitation often
arises from the inability of the text encoder to produce accurate embeddings,
which hinders the video generation model. In this work, we propose a novel
approach to overcome this challenge by selecting the optimal text embedding
through interpolation in the embedding space. We demonstrate that this method
enables the video generation model to produce the desired videos. Additionally,
we introduce a simple algorithm using perpendicular foot embeddings and cosine
similarity to identify the optimal interpolation embedding. Our findings
highlight the importance of accurate text embeddings and offer a pathway for
improving text-to-video generation performance.

摘要：文字轉影片生成模型已取得令人印象深刻的進展，但它們在生成具有複雜特徵的影片方面仍面臨挑戰。這種限制通常源於文字編碼器無法產生準確的嵌入，這會阻礙影片生成模型。在這項工作中，我們提出了一種新的方法，透過在嵌入空間中進行內插來選擇最佳文字嵌入，以克服此挑戰。我們證明了此方法使影片生成模型能夠產生所需的影片。此外，我們引入了一個使用垂直足嵌入和餘弦相似性的簡單演算法，以識別最佳內插嵌入。我們的研究結果突顯了準確文字嵌入的重要性，並提供了一條途徑來改善文字轉影片的生成效能。

##### **Aneumo: A Large-Scale Comprehensive Synthetic Dataset of Aneurysm Hemodynamics**
2501.09980v1 by Xigui Li, Yuanye Zhou, Feiyang Xiao, Xin Guo, Yichi Zhang, Chen Jiang, Jianchao Ge, Xiansheng Wang, Qimeng Wang, Taiwei Zhang, Chensen Lin, Yuan Cheng, Yuan Qi

Intracranial aneurysm (IA) is a common cerebrovascular disease that is
usually asymptomatic but may cause severe subarachnoid hemorrhage (SAH) if
ruptured. Although clinical practice is usually based on individual factors and
morphological features of the aneurysm, its pathophysiology and hemodynamic
mechanisms remain controversial. To address the limitations of current
research, this study constructed a comprehensive hemodynamic dataset of
intracranial aneurysms. The dataset is based on 466 real aneurysm models, and
10,000 synthetic models were generated by resection and deformation operations,
including 466 aneurysm-free models and 9,534 deformed aneurysm models. The
dataset also provides medical image-like segmentation mask files to support
insightful analysis. In addition, the dataset contains hemodynamic data
measured at eight steady-state flow rates (0.001 to 0.004 kg/s), including
critical parameters such as flow velocity, pressure, and wall shear stress,
providing a valuable resource for investigating aneurysm pathogenesis and
clinical prediction. This dataset will help advance the understanding of the
pathologic features and hemodynamic mechanisms of intracranial aneurysms and
support in-depth research in related fields. Dataset hosted at
https://github.com/Xigui-Li/Aneumo.

摘要：顱內動脈瘤（IA）是一種常見的腦血管疾病，通常無症狀，但如果破裂可能會導致嚴重的蛛網膜下腔出血（SAH）。儘管臨床實務通常基於個體因素和動脈瘤的形態特徵，但其病理生理學和血流動力學機制仍存在爭議。為了解決當前研究的限制，本研究構建了一個顱內動脈瘤的全面血流動力學數據集。該數據集基於 466 個真實動脈瘤模型，並通過切除和變形操作生成了 10,000 個合成模型，包括 466 個無動脈瘤模型和 9,534 個變形動脈瘤模型。該數據集還提供了類醫學影像的分割遮罩檔案，以支持深入分析。此外，該數據集包含在八個穩態流速（0.001 至 0.004 kg/s）下測量的血流動力學數據，包括流速、壓力和壁面剪應力等關鍵參數，為研究動脈瘤發病機制和臨床預測提供了寶貴的資源。此數據集將有助於增進對顱內動脈瘤病理特徵和血流動力學機制的了解，並支持相關領域的深入研究。數據集託管於 https://github.com/Xigui-Li/Aneumo。

##### **GVMGen: A General Video-to-Music Generation Model with Hierarchical Attentions**
2501.09972v1 by Heda Zuo, Weitao You, Junxian Wu, Shihong Ren, Pei Chen, Mingxu Zhou, Yujia Lu, Lingyun Sun

Composing music for video is essential yet challenging, leading to a growing
interest in automating music generation for video applications. Existing
approaches often struggle to achieve robust music-video correspondence and
generative diversity, primarily due to inadequate feature alignment methods and
insufficient datasets. In this study, we present General Video-to-Music
Generation model (GVMGen), designed for generating high-related music to the
video input. Our model employs hierarchical attentions to extract and align
video features with music in both spatial and temporal dimensions, ensuring the
preservation of pertinent features while minimizing redundancy. Remarkably, our
method is versatile, capable of generating multi-style music from different
video inputs, even in zero-shot scenarios. We also propose an evaluation model
along with two novel objective metrics for assessing video-music alignment.
Additionally, we have compiled a large-scale dataset comprising diverse types
of video-music pairs. Experimental results demonstrate that GVMGen surpasses
previous models in terms of music-video correspondence, generative diversity,
and application universality.

摘要：為影片譜曲至關重要卻充滿挑戰，因此自動化影片應用程式音樂生成備受關注。現有做法在達成穩健的音樂影片對應和生成多樣性方面往往會遇到困難，主要是由於特徵對齊方法不足和資料集不足。在本研究中，我們提出通用影片轉音樂生成模型 (GVMGen)，旨在為影片輸入產生高度相關的音樂。我們的模型採用階層式注意力來萃取和對齊影片特徵與音樂在空間和時間維度，確保保留相關特徵並將冗餘降至最低。值得注意的是，我們的方法用途廣泛，能夠從不同的影片輸入中生成多種風格的音樂，即使在零次學習場景中也能做到。我們還提出一個評估模型，並提出兩個新的客觀指標來評估影片音樂對齊。此外，我們編制了一個包含各種影片音樂配對的大規模資料集。實驗結果表明，GVMGen 在音樂影片對應、生成多樣性和應用通用性方面都超越了先前的模型。

##### **Explainable artificial intelligence (XAI): from inherent explainability to large language models**
2501.09967v1 by Fuseini Mumuni, Alhassan Mumuni

Artificial Intelligence (AI) has continued to achieve tremendous success in
recent times. However, the decision logic of these frameworks is often not
transparent, making it difficult for stakeholders to understand, interpret or
explain their behavior. This limitation hinders trust in machine learning
systems and causes a general reluctance towards their adoption in practical
applications, particularly in mission-critical domains like healthcare and
autonomous driving. Explainable AI (XAI) techniques facilitate the
explainability or interpretability of machine learning models, enabling users
to discern the basis of the decision and possibly avert undesirable behavior.
This comprehensive survey details the advancements of explainable AI methods,
from inherently interpretable models to modern approaches for achieving
interpretability of various black box models, including large language models
(LLMs). Additionally, we review explainable AI techniques that leverage LLM and
vision-language model (VLM) frameworks to automate or improve the
explainability of other machine learning models. The use of LLM and VLM as
interpretability methods particularly enables high-level, semantically
meaningful explanations of model decisions and behavior. Throughout the paper,
we highlight the scientific principles, strengths and weaknesses of
state-of-the-art methods and outline different areas of improvement. Where
appropriate, we also present qualitative and quantitative comparison results of
various methods to show how they compare. Finally, we discuss the key
challenges of XAI and directions for future research.

摘要：人工智慧 (AI) 近年持續取得巨大成功。然而，這些架構的決策邏輯通常不透明，讓利害關係人難以理解、詮釋或解釋其行為。此限制阻礙了人們對機器學習系統的信任，並導致普遍不願意在實際應用中採用這些系統，特別是在醫療保健和自動駕駛等任務關鍵領域。可解釋 AI (XAI) 技術促進了機器學習模型的可解釋性或可詮釋性，使用戶能夠辨別決策的基礎，並可能避免不良行為。這項綜合調查詳細說明了可解釋 AI 方法的進展，從本質上可詮釋的模型到實現各種黑盒模型（包括大型語言模型 (LLM)）的可詮釋性的現代方法。此外，我們回顧了可解釋 AI 技術，這些技術利用 LLM 和視覺語言模型 (VLM) 框架來自動化或改善其他機器學習模型的可解釋性。使用 LLM 和 VLM 作為可詮釋性方法特別能對模型決策和行為提供高層次、語義上具有意義的解釋。在整篇論文中，我們強調了最先進方法的科學原理、優點和缺點，並概述了不同的改進領域。在適當的情況下，我們還會提供各種方法的定性和定量比較結果，以顯示它們的比較方式。最後，我們討論了 XAI 的主要挑戰和未來研究方向。

##### **A Survey on Multi-Turn Interaction Capabilities of Large Language Models**
2501.09959v1 by Chen Zhang, Xinyi Dai, Yaxiong Wu, Qu Yang, Yasheng Wang, Ruiming Tang, Yong Liu

Multi-turn interaction in the dialogue system research refers to a system's
ability to maintain context across multiple dialogue turns, enabling it to
generate coherent and contextually relevant responses. Recent advancements in
large language models (LLMs) have significantly expanded the scope of
multi-turn interaction, moving beyond chatbots to enable more dynamic agentic
interactions with users or environments. In this paper, we provide a focused
review of the multi-turn capabilities of LLMs, which are critical for a wide
range of downstream applications, including conversational search and
recommendation, consultation services, and interactive tutoring. This survey
explores four key aspects: (1) the core model capabilities that contribute to
effective multi-turn interaction, (2) how multi-turn interaction is evaluated
in current practice, (3) the general algorithms used to enhance multi-turn
interaction, and (4) potential future directions for research in this field.

摘要：多輪互動在對話系統研究中是指系統在多個對話輪次中維護內容的能力，使其能夠產生連貫且與內容相關的回應。最近大型語言模型 (LLM) 的進展顯著擴展了多輪互動的範圍，超越了聊天機器人，實現了與使用者或環境更動態的代理互動。在本文中，我們提供了對 LLM 多輪功能的重點回顧，這些功能對於廣泛的下游應用至關重要，包括對話式搜尋和推薦、諮詢服務和互動式輔導。這項調查探討了四個關鍵方面：(1) 有助於有效的多輪互動的核心模型功能，(2) 如何在當前實務中評估多輪互動，(3) 用於增強多輪互動的一般演算法，以及 (4) 該領域研究的潛在未來方向。

##### **FRAG: A Flexible Modular Framework for Retrieval-Augmented Generation based on Knowledge Graphs**
2501.09957v1 by Zengyi Gao, Yukun Cao, Hairu Wang, Ao Ke, Yuan Feng, Xike Xie, S Kevin Zhou

To mitigate the hallucination and knowledge deficiency in large language
models (LLMs), Knowledge Graph (KG)-based Retrieval-Augmented Generation (RAG)
has shown promising potential by utilizing KGs as external resource to enhance
LLMs reasoning.However, existing KG-RAG approaches struggle with a trade-off
between flexibility and retrieval quality.Modular methods prioritize
flexibility by avoiding the use of KG-fine-tuned models during retrieval,
leading to fixed retrieval strategies and suboptimal retrieval
quality.Conversely, coupled methods embed KG information within models to
improve retrieval quality, but at the expense of flexibility.In this paper, we
propose a novel flexible modular KG-RAG framework, termed FRAG, which
synergizes the advantages of both approaches.FRAG estimates the hop range of
reasoning paths based solely on the query and classify it as either simple or
complex.To match the complexity of the query, tailored pipelines are applied to
ensure efficient and accurate reasoning path retrieval, thus fostering the
final reasoning process.By using the query text instead of the KG to infer the
structural information of reasoning paths and employing adaptable retrieval
strategies, FRAG improves retrieval quality while maintaining
flexibility.Moreover, FRAG does not require extra LLMs fine-tuning or calls,
significantly boosting efficiency and conserving resources.Extensive
experiments show that FRAG achieves state-of-the-art performance with high
efficiency and low resource consumption.

摘要：為了減輕大型語言模型 (LLM) 中的幻覺和知識不足，基於知識圖譜 (KG) 的檢索增強生成 (RAG) 已透過利用 KG 作為外部資源來增強 LLM 推理，展現出潛在的可能性。然而，現有的 KG-RAG 方法在靈活性與檢索品質之間掙扎著取得平衡。模組化方法透過避免在檢索期間使用針對 KG 微調的模型，優先考量靈活性，導致固定的檢索策略和次佳的檢索品質。相反地，耦合方法將 KG 資訊嵌入模型中以改善檢索品質，但犧牲了靈活性。在本文中，我們提出了一個新穎的靈活模組化 KG-RAG 架構，稱為 FRAG，它協同利用了這兩種方法的優點。FRAG 僅根據查詢估計推理路徑的跳躍範圍，並將其分類為簡單或複雜。為了符合查詢的複雜性，應用客製化管線以確保有效且準確的推理路徑檢索，從而促進最終的推理過程。透過使用查詢文字而非 KG 來推斷推理路徑的結構資訊，並採用可適應的檢索策略，FRAG 在維持靈活性的同時改善了檢索品質。此外，FRAG 不需要額外的 LLM 微調或呼叫，大幅提升效率並節省資源。廣泛的實驗顯示，FRAG 以高效率和低資源消耗實現了最先進的效能。

##### **AIRCHITECT v2: Learning the Hardware Accelerator Design Space through Unified Representations**
2501.09954v1 by Jamin Seo, Akshat Ramachandran, Yu-Chuan Chuang, Anirudh Itagi, Tushar Krishna

Design space exploration (DSE) plays a crucial role in enabling custom
hardware architectures, particularly for emerging applications like AI, where
optimized and specialized designs are essential. With the growing complexity of
deep neural networks (DNNs) and the introduction of advanced foundational
models (FMs), the design space for DNN accelerators is expanding at an
exponential rate. Additionally, this space is highly non-uniform and
non-convex, making it increasingly difficult to navigate and optimize.
Traditional DSE techniques rely on search-based methods, which involve
iterative sampling of the design space to find the optimal solution. However,
this process is both time-consuming and often fails to converge to the global
optima for such design spaces. Recently, AIrchitect v1, the first attempt to
address the limitations of search-based techniques, transformed DSE into a
constant-time classification problem using recommendation networks. In this
work, we propose AIrchitect v2, a more accurate and generalizable
learning-based DSE technique applicable to large-scale design spaces that
overcomes the shortcomings of earlier approaches. Specifically, we devise an
encoder-decoder transformer model that (a) encodes the complex design space
into a uniform intermediate representation using contrastive learning and (b)
leverages a novel unified representation blending the advantages of
classification and regression to effectively explore the large DSE space
without sacrificing accuracy. Experimental results evaluated on 10^5 real DNN
workloads demonstrate that, on average, AIrchitect v2 outperforms existing
techniques by 15% in identifying optimal design points. Furthermore, to
demonstrate the generalizability of our method, we evaluate performance on
unseen model workloads (LLMs) and attain a 1.7x improvement in inference
latency on the identified hardware architecture.

摘要：<paragraph>設計空間探索 (DSE) 在支援客製化硬體架構中扮演著至關重要的角色，特別是對於人工智慧等新興應用，因為最佳化和專業化設計至關重要。隨著深度神經網路 (DNN) 日益複雜，以及進階基礎模型 (FM) 的導入，DNN 加速器的設計空間正以指數級的速度擴張。此外，這個空間高度不均勻且非凸，這使得導航和最佳化變得越來越困難。傳統的 DSE 技術依賴於基於搜尋的方法，這涉及設計空間的迭代抽樣以找出最佳解。然而，這個過程既耗時，而且常常無法收斂到這些設計空間的全局最佳值。最近，AIrchitect v1 是第一個嘗試解決基於搜尋技術限制的嘗試，它使用推薦網路將 DSE 轉變為一個常數時間分類問題。在這項工作中，我們提出 AIrchitect v2，這是一個更準確且可概化的基於學習的 DSE 技術，適用於大規模設計空間，克服了先前方法的缺點。具體來說，我們設計了一個編碼器-解碼器轉換器模型，它 (a) 使用對比學習將複雜的設計空間編碼成一個統一的中間表示，以及 (b) 利用一個新穎的統一表示，融合分類和回歸的優點，以有效探索大型 DSE 空間，而不會犧牲準確性。在 10^5 個真實 DNN 工作負載上評估的實驗結果表明，平均而言，AIrchitect v2 在識別最佳設計點方面比現有技術高出 15%。此外，為了證明我們方法的可概化性，我們評估了在未見過模型工作負載 (LLM) 上的效能，並在已識別的硬體架構上獲得了 1.7 倍的推論延遲改善。</paragraph>

##### **Sympathy over Polarization: A Computational Discourse Analysis of Social Media Posts about the July 2024 Trump Assassination Attempt**
2501.09950v1 by Qingcheng Zeng, Guanhong Liu, Zhaoqian Xue, Diego Ford, Rob Voigt, Loni Hagen, Lingyao Li

On July 13, 2024, at the Trump rally in Pennsylvania, someone attempted to
assassinate Republican Presidential Candidate Donald Trump. This attempt
sparked a large-scale discussion on social media. We collected posts from X
(formerly known as Twitter) one week before and after the assassination attempt
and aimed to model the short-term effects of such a ``shock'' on public
opinions and discussion topics. Specifically, our study addresses three key
questions: first, we investigate how public sentiment toward Donald Trump
shifts over time and across regions (RQ1) and examine whether the assassination
attempt itself significantly affects public attitudes, independent of the
existing political alignments (RQ2). Finally, we explore the major themes in
online conversations before and after the crisis, illustrating how discussion
topics evolved in response to this politically charged event (RQ3). By
integrating large language model-based sentiment analysis,
difference-in-differences modeling, and topic modeling techniques, we find that
following the attempt the public response was broadly sympathetic to Trump
rather than polarizing, despite baseline ideological and regional disparities.

摘要：2024 年 7 月 13 日，在賓夕法尼亞州舉行的川普造勢大會上，有人企圖暗殺共和黨總統候選人唐納·川普。這起暗殺企圖在社群媒體上引發大規模討論。我們收集了 X（前稱 Twitter）在暗殺企圖發生前後一週的貼文，並試圖模擬這種「震驚」對公眾輿論和討論主題的短期影響。具體來說，我們的研究探討了三個關鍵問題：首先，我們調查公眾對唐納·川普的情緒如何隨著時間和地區而轉變（RQ1），並檢視暗殺企圖本身是否顯著影響公眾態度，而不論現有的政治立場（RQ2）。最後，我們探討危機前後網路對話中的主要主題，說明討論主題如何隨著這場政治事件而演變（RQ3）。透過整合大型語言模型的情緒分析、差異中差異建模和主題建模技術，我們發現，儘管存在基本意識形態和區域差異，暗殺企圖發生後，公眾對川普的反應普遍是同情，而非兩極分化。

##### **MultiPruner: Balanced Structure Removal in Foundation Models**
2501.09949v1 by J. Pablo Muñoz, Jinjie Yuan, Nilesh Jain

Recently, state-of-the-art approaches for pruning large pre-trained models
(LPMs) have demonstrated that the training-free removal of non-critical
residual blocks in Transformers is viable for reducing model size, achieving
results that outperform previous training-free pruning approaches. Motivated by
these findings, we extend BlockPruner (Zhong et al., 2024) and propose
MultiPruner, a pruning approach that surpasses recent training-free pruning
methods by adopting a multidimensional, iterative, fine-grained pruning
strategy. In MultiPruner, multidimensional pruning reinstates the structural
balance in block-pruned models by sequentially compressing along three
dimensions: i) residual blocks, ii) channels of multilayer perceptrons (MLP),
and iii) attention heads. This solution enhances zero-shot accuracy on
downstream tasks compared to other techniques while improving model compression
ratios, producing compressed models with fewer computing and memory
requirements. Extensive experiments demonstrate the advantages of the proposed
method across various large pre-trained models. The code and pruning
configurations are available at
https://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning.

摘要：<paragraph>近來，修剪大型預訓練模型 (LPM) 的最新方法已證明，在 Transformer 中移除非必要的殘差區塊無需訓練，就能有效縮小模型大小，並達成優於先前無訓練修剪方法的結果。受這些發現啟發，我們擴充 BlockPruner (Zhong 等人，2024)，並提出 MultiPruner，這是一種修剪方法，採用多維、反覆、細緻的修剪策略，超越了最近的無訓練修剪方法。在 MultiPruner 中，多維修剪透過沿著三個維度順序壓縮來重建區塊修剪模型的結構平衡：i) 殘差區塊、ii) 多層感知器 (MLP) 的通道，以及 iii) 注意力層。與其他技術相比，此解決方案增強了下游任務的零次學習準確度，同時改善模型壓縮率，產生運算和記憶體需求較低的壓縮模型。廣泛的實驗證明了所提出方法在各種大型預訓練模型中的優點。程式碼和修剪組態可在 https://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning 取得。</paragraph>

##### **AI Explainability for Power Electronics: From a Lipschitz Continuity Perspective**
2501.09948v1 by Xinze Li, Fanfan Lin, Homer Alan Mantooth, Juan José Rodríguez-Andina

Lifecycle management of power converters continues to thrive with emerging
artificial intelligence (AI) solutions, yet AI mathematical explainability
remains unexplored in power electronics (PE) community. The lack of theoretical
rigor challenges adoption in mission-critical applications. Therefore, this
letter proposes a generic framework to evaluate mathematical explainability,
highlighting inference stability and training convergence from a Lipschitz
continuity perspective. Inference stability governs consistent outputs under
input perturbations, essential for robust real-time control and fault
diagnosis. Training convergence guarantees stable learning dynamics,
facilitating accurate modeling in PE contexts. Additionally, a Lipschitz-aware
learning rate selection strategy is introduced to accelerate convergence while
mitigating overshoots and oscillations. The feasibility of the proposed
Lipschitz-oriented framework is demonstrated by validating the mathematical
explainability of a state-of-the-art physics-in-architecture neural network,
and substantiated through empirical case studies on dual-active-bridge
converters. This letter serves as a clarion call for the PE community to
embrace mathematical explainability, heralding a transformative era of
trustworthy and explainable AI solutions that potentially redefine the future
of power electronics.

摘要：電力轉換器的生命週期管理持續蓬勃發展，並伴隨著新興的人工智慧 (AI) 解决方案，但人工智慧的數學可解釋性在電力電子 (PE) 社群中仍未被探索。缺乏理論嚴謹性對任務關鍵應用程式的採用構成挑戰。因此，這封信提出了評估數學可解釋性的通用架構，從 Lipschitz 連續性的角度強調推論穩定性和訓練收斂性。推論穩定性控制輸入擾動下的輸出一致性，這對於穩健的即時控制和故障診斷至關重要。訓練收斂性保證穩定的學習動態，有助於在電力電子背景下進行準確建模。此外，引入了一個 Lipschitz 感知學習率選擇策略，以加速收斂，同時減輕過衝和振盪。所提出的面向 Lipschitz 的架構的可行性已通過驗證最先進的架構內物理神經網路的數學可解釋性得到證明，並通過對雙有源橋轉換器的實證案例研究得到證實。這封信作為對電力電子社群的號召，要求其擁抱數學可解釋性，預示著一個值得信賴且可解釋的人工智慧解決方案的變革時代，這可能會重新定義電力電子的未來。

##### **Client-Centric Federated Adaptive Optimization**
2501.09946v1 by Jianhui Sun, Xidong Wu, Heng Huang, Aidong Zhang

Federated Learning (FL) is a distributed learning paradigm where clients
collaboratively train a model while keeping their own data private. With an
increasing scale of clients and models, FL encounters two key challenges,
client drift due to a high degree of statistical/system heterogeneity, and lack
of adaptivity. However, most existing FL research is based on unrealistic
assumptions that virtually ignore system heterogeneity. In this paper, we
propose Client-Centric Federated Adaptive Optimization, which is a class of
novel federated adaptive optimization approaches. We enable several features in
this framework such as arbitrary client participation, asynchronous server
aggregation, and heterogeneous local computing, which are ubiquitous in
real-world FL systems but are missed in most existing works. We provide a
rigorous convergence analysis of our proposed framework for general nonconvex
objectives, which is shown to converge with the best-known rate. Extensive
experiments show that our approaches consistently outperform the baseline by a
large margin across benchmarks.

摘要：聯邦學習 (FL) 是一種分散式學習範例，其中客戶端在保持自身資料私密的情況下，協作訓練模型。隨著客戶端和模型規模的增加，FL 會遇到兩個主要挑戰，由於統計/系統異質性高而產生的客戶端漂移，以及缺乏適應性。然而，大多數現有的 FL 研究都基於不切實際的假設，幾乎忽略了系統異質性。在本文中，我們提出以客戶端為中心的聯邦自適應最佳化，這是一類新穎的聯邦自適應最佳化方法。我們在此架構中啟用多項功能，例如任意客戶端參與、非同步伺服器聚合和異質局部運算，這些功能在真實世界的 FL 系統中無所不在，但在大多數現有作品中卻被遺漏。我們對所提出的架構進行嚴格的收斂分析，以適用於一般的非凸目標，已顯示收斂速度為已知最佳速度。廣泛的實驗表明，我們的做法在各個基準上都持續大幅優於基準。

##### **Indigenous Languages Spoken in Argentina: A Survey of NLP and Speech Resources**
2501.09943v1 by Belu Ticona, Fernando Carranza, Viviana Cotik

Argentina has a diverse, yet little-known, Indigenous language heritage. Most
of these languages are at risk of disappearing, resulting in a significant loss
of world heritage and cultural knowledge. Currently, no unified information on
speakers and computational tools is available for these languages. In this
work, we present a systematization of the Indigenous languages spoken in
Argentina, along with national demographic data on the country's Indigenous
population. The languages are classified into seven families: Mapuche,
Tup\'i-Guaran\'i, Guaycur\'u, Quechua, Mataco-Mataguaya, Aymara, and Chon. We
also provide an introductory survey of the computational resources available
for these languages, whether or not they are specifically developed for
Argentine varieties.

摘要：阿根廷擁有多元且鮮為人知的原住民語言遺產。這些語言大多面臨消失的風險，導致世界遺產和文化知識的重大損失。目前，沒有統一的資訊可供這些語言的使用者和計算工具使用。在這項工作中，我們對阿根廷所說的原住民語言進行了系統化，並提供了該國原住民人口的國家人口統計資料。這些語言被歸類為七個語系：馬普切語、圖皮-瓜拉尼語、瓜亞庫魯語、克丘亞語、馬塔科-馬塔瓜亞語、艾馬拉語和瓊語。我們還提供了這些語言可用的計算資源的簡介調查，無論它們是否專門為阿根廷品種而開發。

##### **HEART: Achieving Timely Multi-Model Training for Vehicle-Edge-Cloud-Integrated Hierarchical Federated Learning**
2501.09934v1 by Xiaohong Yang, Minghui Liwang, Xianbin Wang, Zhipeng Cheng, Seyyedali Hosseinalipour, Huaiyu Dai, Zhenzhen Jiao

The rapid growth of AI-enabled Internet of Vehicles (IoV) calls for efficient
machine learning (ML) solutions that can handle high vehicular mobility and
decentralized data. This has motivated the emergence of Hierarchical Federated
Learning over vehicle-edge-cloud architectures (VEC-HFL). Nevertheless, one
aspect which is underexplored in the literature on VEC-HFL is that vehicles
often need to execute multiple ML tasks simultaneously, where this multi-model
training environment introduces crucial challenges. First, improper aggregation
rules can lead to model obsolescence and prolonged training times. Second,
vehicular mobility may result in inefficient data utilization by preventing the
vehicles from returning their models to the network edge. Third, achieving a
balanced resource allocation across diverse tasks becomes of paramount
importance as it majorly affects the effectiveness of collaborative training.
We take one of the first steps towards addressing these challenges via
proposing a framework for multi-model training in dynamic VEC-HFL with the goal
of minimizing global training latency while ensuring balanced training across
various tasks-a problem that turns out to be NP-hard. To facilitate timely
model training, we introduce a hybrid synchronous-asynchronous aggregation
rule. Building on this, we present a novel method called Hybrid Evolutionary
And gReedy allocaTion (HEART). The framework operates in two stages: first, it
achieves balanced task scheduling through a hybrid heuristic approach that
combines improved Particle Swarm Optimization (PSO) and Genetic Algorithms
(GA); second, it employs a low-complexity greedy algorithm to determine the
training priority of assigned tasks on vehicles. Experiments on real-world
datasets demonstrate the superiority of HEART over existing methods.

摘要：<paragraph>人工智慧驅動的車聯網 (IoV) 快速成長，需要高效的機器學習 (ML) 解決方案，以處理高度的車輛流動性和分散式資料。這促使了車輛邊緣雲架構 (VEC-HFL) 上的階層式聯邦學習的出現。然而，VEC-HFL 文獻中一個未充分探討的方面是，車輛通常需要同時執行多個 ML 任務，而這種多模型訓練環境會帶來嚴峻的挑戰。首先，不適當的聚合規則可能導致模型過時和延長的訓練時間。其次，車輛流動性可能會導致資料利用率低，因為車輛無法將其模型傳回網路邊緣。第三，在不同任務之間實現平衡的資源配置變得至關重要，因為它會嚴重影響協作訓練的效率。我們採取了第一步來解決這些挑戰，提出了一個在動態 VEC-HFL 中進行多模型訓練的框架，目標是在確保不同任務之間訓練平衡的同時，將整體訓練延遲降至最低，而這個問題被證明是 NP 難題。為了促進及時的模型訓練，我們引入了一個混合同步非同步聚合規則。在此基礎上，我們提出了一種稱為混合演化和貪婪分配 (HEART) 的新方法。該框架分兩個階段進行：首先，它通過結合改進的粒子群最佳化 (PSO) 和遺傳演算法 (GA) 的混合啟發式方法，實現了平衡的任務調度；其次，它採用低複雜度的貪婪演算法來確定車輛上分配任務的訓練優先順序。在真實世界資料集上的實驗證明了 HEART 優於現有方法。</paragraph>

##### **Steering Large Language Models with Feature Guided Activation Additions**
2501.09929v1 by Samuel Soo, Wesley Teng, Chandrasekaran Balaganesh

Effective and reliable control over large language model (LLM) behavior is a
significant challenge. While activation steering methods, which add steering
vectors to a model's hidden states, are a promising approach, existing
techniques often lack precision and interpretability in how they influence
model outputs. We introduce Feature Guided Activation Additions (FGAA), a novel
activation steering method that leverages insights from Contrastive Activation
Addition (CAA) and Sparse Autoencoder-Targeted Steering (SAE-TS). By operating
in the latent space of a Sparse Autoencoder (SAE) and employing optimization
techniques to select desired SAE features, FGAA constructs precise steering
vectors that provide better steering effects while maintaining coherence of
steered model outputs. In this regard, evaluations on Gemma-2-2B and Gemma-2-9B
models across various steering tasks demonstrate that FGAA outperforms existing
steering methods of CAA, SAE decoder steering, and SAE-TS. Our results also
highlight important trade-offs between steering scale and general model
capabilities that are consistent across all tested steering methods.

摘要：有效且可靠地控制大型语言模型 (LLM) 行为是一项重大挑战。虽然激活转向方法（向模型的隐藏状态添加转向向量）是一种有前途的方法，但现有技术在如何影响模型输出方面往往缺乏精确性和可解释性。我们引入了特征引导激活加法 (FGAA)，这是一种新颖的激活转向方法，它利用了对比激活加法 (CAA) 和稀疏自编码器目标转向 (SAE-TS) 的见解。通过在稀疏自编码器 (SAE) 的潜在空间中操作并采用优化技术来选择所需的 SAE 特征，FGAA 构建了精确的转向向量，这些向量提供了更好的转向效果，同时保持了转向模型输出的一致性。在这方面，对 Gemma-2-2B 和 Gemma-2-9B 模型在各种转向任务中的评估表明，FGAA 优于现有的 CAA 转向方法、SAE 解码器转向和 SAE-TS。我们的结果还强调了所有测试转向方法中转向规模和一般模型能力之间重要的权衡。

##### **Dialogue Benchmark Generation from Knowledge Graphs with Cost-Effective Retrieval-Augmented LLMs**
2501.09928v1 by Reham Omar, Omij Mangukiya, Essam Mansour

Dialogue benchmarks are crucial in training and evaluating chatbots engaging
in domain-specific conversations. Knowledge graphs (KGs) represent semantically
rich and well-organized data spanning various domains, such as DBLP, DBpedia,
and YAGO. Traditionally, dialogue benchmarks have been manually created from
documents, neglecting the potential of KGs in automating this process. Some
question-answering benchmarks are automatically generated using extensive
preprocessing from KGs, but they do not support dialogue generation. This paper
introduces Chatty-Gen, a novel multi-stage retrieval-augmented generation
platform for automatically generating high-quality dialogue benchmarks tailored
to a specific domain using a KG. Chatty-Gen decomposes the generation process
into manageable stages and uses assertion rules for automatic validation
between stages. Our approach enables control over intermediate results to
prevent time-consuming restarts due to hallucinations. It also reduces reliance
on costly and more powerful commercial LLMs. Chatty-Gen eliminates upfront
processing of the entire KG using efficient query-based retrieval to find
representative subgraphs based on the dialogue context. Our experiments with
several real and large KGs demonstrate that Chatty-Gen significantly
outperforms state-of-the-art systems and ensures consistent model and system
performance across multiple LLMs of diverse capabilities, such as GPT-4o,
Gemini 1.5, Llama 3, and Mistral.

摘要：對話基準在訓練和評估參與特定領域對話的聊天機器人方面至關重要。知識圖譜 (KG) 表示跨越各種領域（例如 DBLP、DBpedia 和 YAGO）的語義豐富且組織良好的資料。傳統上，對話基準是從文件中手動建立的，忽略了 KG 在自動化此過程中潛在的可能性。一些問答基準是使用 KG 中的廣泛預處理自動生成的，但它們不支援對話生成。本文介紹了 Chatty-Gen，這是一個新穎的多階段檢索增強生成平台，用於使用 KG 自動生成針對特定領域量身定制的高品質對話基準。Chatty-Gen 將生成過程分解為可管理的階段，並使用斷言規則在各階段之間進行自動驗證。我們的做法能夠控制中間結果，以防止因幻覺而導致耗時的重新啟動。它還減少了對昂貴且功能更強大的商業 LLM 的依賴。Chatty-Gen 使用基於查詢的有效檢索來消除整個 KG 的前期處理，以根據對話內容找到具代表性的子圖。我們使用幾個真實且大型的 KG 進行的實驗表明，Chatty-Gen 明顯優於最先進的系統，並確保了在 GPT-4o、Gemini 1.5、Llama 3 和 Mistral 等具有不同功能的多個 LLM 中模型和系統的效能一致。

##### **IE-Bench: Advancing the Measurement of Text-Driven Image Editing for Human Perception Alignment**
2501.09927v1 by Shangkun Sun, Bowen Qu, Xiaoyu Liang, Songlin Fan, Wei Gao

Recent advances in text-driven image editing have been significant, yet the
task of accurately evaluating these edited images continues to pose a
considerable challenge. Different from the assessment of text-driven image
generation, text-driven image editing is characterized by simultaneously
conditioning on both text and a source image. The edited images often retain an
intrinsic connection to the original image, which dynamically change with the
semantics of the text. However, previous methods tend to solely focus on
text-image alignment or have not aligned with human perception. In this work,
we introduce the Text-driven Image Editing Benchmark suite (IE-Bench) to
enhance the assessment of text-driven edited images. IE-Bench includes a
database contains diverse source images, various editing prompts and the
corresponding results different editing methods, and total 3,010 Mean Opinion
Scores (MOS) provided by 25 human subjects. Furthermore, we introduce IE-QA, a
multi-modality source-aware quality assessment method for text-driven image
editing. To the best of our knowledge, IE-Bench offers the first IQA dataset
and model tailored for text-driven image editing. Extensive experiments
demonstrate IE-QA's superior subjective-alignments on the text-driven image
editing task compared with previous metrics. We will make all related data and
code available to the public.

摘要：文本驅動的影像編輯技術近期有顯著進展，但準確評估這些編輯影像的任務仍是一項重大挑戰。有別於文本驅動影像產生的評估，文本驅動影像編輯的特徵是同時以文本和原始影像為條件。編輯後的影像通常會保留與原始影像的內在關聯，並會隨著文本的語意而動態改變。然而，先前的技術往往只專注於文字影像對齊，或未與人類的認知對齊。在這項工作中，我們引入了文本驅動影像編輯基準測試套件 (IE-Bench)，以增強對文本驅動編輯影像的評估。IE-Bench 包含一個資料庫，其中包含不同的原始影像、各種編輯提示和對應的不同編輯方法的結果，以及 25 位人類受試者提供的總計 3,010 個平均意見分數 (MOS)。此外，我們還引入了 IE-QA，這是一種針對文本驅動影像編輯的多模態來源感知品質評估方法。據我們所知，IE-Bench 提供了第一個針對文本驅動影像編輯量身打造的 IQA 資料集和模型。廣泛的實驗證明，與先前的指標相比，IE-QA 在文本驅動影像編輯任務中具有優異的主觀對齊性。我們將所有相關資料和程式碼提供給公眾。

##### **GenSC-6G: A Prototype Testbed for Integrated Generative AI, Quantum, and Semantic Communication**
2501.09918v1 by Brian E. Arfeto, Shehbaz Tariq, Uman Khalid, Trung Q. Duong, Hyundong Shin

We introduce a prototyping testbed, GenSC-6G, developed to generate a
comprehensive dataset that supports the integration of generative artificial
intelligence (AI), quantum computing, and semantic communication for emerging
sixth-generation (6G) applications. The GenSC-6G dataset is designed with
noise-augmented synthetic data optimized for semantic decoding, classification,
and localization tasks, significantly enhancing flexibility for diverse
AI-driven communication applications. This adaptable prototype supports
seamless modifications across baseline models, communication modules, and
goal-oriented decoders. Case studies demonstrate its application in lightweight
classification, semantic upsampling, and edge-based language inference under
noise conditions. The GenSC-6G dataset serves as a scalable and robust resource
for developing goal-oriented communication systems tailored to the growing
demands of 6G networks.

摘要：我們引進一個原型測試平台 GenSC-6G，開發用於生成一個綜合性資料集，支援將生成式人工智慧 (AI)、量子運算和語意通訊整合到新興第六代 (6G) 應用中。GenSC-6G 資料集的設計採用針對語意解碼、分類和定位任務最佳化的噪聲擴增合成資料，大幅提升了各種 AI 驅動通訊應用的靈活性。這個可適用的原型支援跨基準模型、通訊模組和目標導向解碼器的無縫修改。案例研究展示了它在輕量級分類、語意上採樣和在噪聲條件下的邊緣語言推論中的應用。GenSC-6G 資料集作為一個可擴充且強健的資源，服務於開發目標導向的通訊系統，以滿足 6G 網路日益增長的需求。

##### **Towards A Litmus Test for Common Sense**
2501.09913v1 by Hugo Latapie

This paper is the second in a planned series aimed at envisioning a path to
safe and beneficial artificial intelligence. Building on the conceptual
insights of "Common Sense Is All You Need," we propose a more formal litmus
test for common sense, adopting an axiomatic approach that combines minimal
prior knowledge (MPK) constraints with diagonal or Godel-style arguments to
create tasks beyond the agent's known concept set. We discuss how this approach
applies to the Abstraction and Reasoning Corpus (ARC), acknowledging
training/test data constraints, physical or virtual embodiment, and large
language models (LLMs). We also integrate observations regarding emergent
deceptive hallucinations, in which more capable AI systems may intentionally
fabricate plausible yet misleading outputs to disguise knowledge gaps. The
overarching theme is that scaling AI without ensuring common sense risks
intensifying such deceptive tendencies, thereby undermining safety and trust.
Aligning with the broader goal of developing beneficial AI without causing
harm, our axiomatic litmus test not only diagnoses whether an AI can handle
truly novel concepts but also provides a stepping stone toward an ethical,
reliable foundation for future safe, beneficial, and aligned artificial
intelligence.

摘要：這篇論文是規劃中系列論文的第二篇，旨在構思一條通往安全且有益的人工智慧的道路。建立在「常識就是你所需要的」的概念見解上，我們提出一個更正式的常識試金石，採用公理方法，結合最小的先驗知識 (MPK) 限制與對角線或哥德爾式論證，以創造出超出代理人已知概念集的任務。我們討論這個方法如何應用於抽象與推理語料庫 (ARC)，承認訓練/測試數據限制、物理或虛擬具身和大型語言模型 (LLM)。我們也整合關於新興欺騙性幻覺的觀察，其中更強大的 AI 系統可能會故意捏造看似合理但具有誤導性的輸出，以掩飾知識差距。整體主題是，在不確保常識的情況下擴大人工智慧的規模，會加劇這種欺騙傾向，從而破壞安全和信任。與開發有益的 AI 而又不造成傷害的更廣泛目標一致，我們的公理試金石不僅診斷出 AI 是否能處理真正新穎的概念，也為未來安全、有益且一致的人工智慧提供了一個邁向倫理、可靠基礎的墊腳石。

##### **Evolving Deeper LLM Thinking**
2501.09891v1 by Kuang-Huei Lee, Ian Fischer, Yueh-Hua Wu, Dave Marwood, Shumeet Baluja, Dale Schuurmans, Xinyun Chen

We explore an evolutionary search strategy for scaling inference time compute
in Large Language Models. The proposed approach, Mind Evolution, uses a
language model to generate, recombine and refine candidate responses. The
proposed approach avoids the need to formalize the underlying inference problem
whenever a solution evaluator is available. Controlling for inference cost, we
find that Mind Evolution significantly outperforms other inference strategies
such as Best-of-N and Sequential Revision in natural language planning tasks.
In the TravelPlanner and Natural Plan benchmarks, Mind Evolution solves more
than 98% of the problem instances using Gemini 1.5 Pro without the use of a
formal solver.

摘要：我們探索了一種演化搜尋策略，用於擴充大型語言模型中的推論時間計算。建議的方法心智演化使用語言模型來產生、重組和改善候選回應。建議的方法避免了在有解算評估器時，將基礎推論問題形式化的需要。控制推論成本，我們發現心智演化明顯優於其他推論策略，例如最佳 N 和自然語言規劃任務中的連續修正。在 TravelPlanner 和 Natural Plan 基準中，心智演化解決了超過 98% 的問題實例，使用 Gemini 1.5 Pro，而無需使用形式求解器。

##### **ASTRA: A Scene-aware TRAnsformer-based model for trajectory prediction**
2501.09878v1 by Izzeddin Teeti, Aniket Thomas, Munish Monga, Sachin Kumar, Uddeshya Singh, Andrew Bradley, Biplab Banerjee, Fabio Cuzzolin

We present ASTRA (A} Scene-aware TRAnsformer-based model for trajectory
prediction), a light-weight pedestrian trajectory forecasting model that
integrates the scene context, spatial dynamics, social inter-agent interactions
and temporal progressions for precise forecasting. We utilised a U-Net-based
feature extractor, via its latent vector representation, to capture scene
representations and a graph-aware transformer encoder for capturing social
interactions. These components are integrated to learn an agent-scene aware
embedding, enabling the model to learn spatial dynamics and forecast the future
trajectory of pedestrians. The model is designed to produce both deterministic
and stochastic outcomes, with the stochastic predictions being generated by
incorporating a Conditional Variational Auto-Encoder (CVAE). ASTRA also
proposes a simple yet effective weighted penalty loss function, which helps to
yield predictions that outperform a wide array of state-of-the-art
deterministic and generative models. ASTRA demonstrates an average improvement
of 27%/10% in deterministic/stochastic settings on the ETH-UCY dataset, and 26%
improvement on the PIE dataset, respectively, along with seven times fewer
parameters than the existing state-of-the-art model (see Figure 1).
Additionally, the model's versatility allows it to generalize across different
perspectives, such as Bird's Eye View (BEV) and Ego-Vehicle View (EVV).

摘要：<paragraph>我們提出 ASTRA（一種場景感知的軌跡預測模型），這是一個輕量級的行人軌跡預測模型，它整合了場景脈絡、空間動態、社會互動代理和時間進程，以進行精確預測。我們利用了基於 U-Net 的特徵提取器，通過其潛在向量表示，來捕獲場景表示和一個圖感知轉換器編碼器，以捕獲社交互動。這些組件被整合起來，以學習一種代理場景感知嵌入，使模型能夠學習空間動態並預測行人的未來軌跡。該模型被設計為既能產生確定性結果，又能產生隨機性結果，隨機性預測是通過整合條件變分自編碼器 (CVAE) 生成的。ASTRA 還提出了一個簡單但有效的加權懲罰損失函數，這有助於產生比各種最先進的確定性和生成模型表現更好的預測。ASTRA 在 ETH-UCY 數據集上的確定性/隨機設置中展示了平均 27%/10% 的改進，在 PIE 數據集上的改進為 26%，同時參數比現有的最先進模型少七倍（見圖 1）。此外，該模型的多功能性允許它在不同的視角之間進行概括，例如鳥瞰圖 (BEV) 和車輛視角 (EVV)。</paragraph>

##### **From Explainability to Interpretability: Interpretable Policies in Reinforcement Learning Via Model Explanation**
2501.09858v1 by Peilang Li, Umer Siddique, Yongcan Cao

Deep reinforcement learning (RL) has shown remarkable success in complex
domains, however, the inherent black box nature of deep neural network policies
raises significant challenges in understanding and trusting the decision-making
processes. While existing explainable RL methods provide local insights, they
fail to deliver a global understanding of the model, particularly in
high-stakes applications. To overcome this limitation, we propose a novel
model-agnostic approach that bridges the gap between explainability and
interpretability by leveraging Shapley values to transform complex deep RL
policies into transparent representations. The proposed approach offers two key
contributions: a novel approach employing Shapley values to policy
interpretation beyond local explanations and a general framework applicable to
off-policy and on-policy algorithms. We evaluate our approach with three
existing deep RL algorithms and validate its performance in two classic control
environments. The results demonstrate that our approach not only preserves the
original models' performance but also generates more stable interpretable
policies.

摘要：深度強化學習 (RL) 在複雜領域中展現出顯著的成功，然而，深度神經網路策略內在的黑箱本質在理解和信任決策制定過程中提出了重大的挑戰。雖然現有的可解釋 RL 方法提供了局部見解，但它們未能提供對模型的整體理解，特別是在高風險應用中。為了克服這個限制，我們提出了一種新穎的模型不可知方法，它利用 Shapley 值將複雜的深度 RL 策略轉換為透明表示，從而彌合可解釋性和可解釋性之間的差距。所提出的方法提供了兩個關鍵貢獻：一種採用 Shapley 值的新方法，用於超越局部解釋的策略解釋，以及一個適用於非策略和策略演算法的一般框架。我們使用三個現有的深度 RL 演算法評估我們的演算法，並在兩個經典控制環境中驗證其效能。結果表明，我們的演算法不僅保留了原始模型的效能，而且還產生了更穩定的可解釋策略。

##### **CrossModalityDiffusion: Multi-Modal Novel View Synthesis with Unified Intermediate Representation**
2501.09838v1 by Alex Berian, Daniel Brignac, JhihYang Wu, Natnael Daba, Abhijit Mahalanobis

Geospatial imaging leverages data from diverse sensing modalities-such as EO,
SAR, and LiDAR, ranging from ground-level drones to satellite views. These
heterogeneous inputs offer significant opportunities for scene understanding
but present challenges in interpreting geometry accurately, particularly in the
absence of precise ground truth data. To address this, we propose
CrossModalityDiffusion, a modular framework designed to generate images across
different modalities and viewpoints without prior knowledge of scene geometry.
CrossModalityDiffusion employs modality-specific encoders that take multiple
input images and produce geometry-aware feature volumes that encode scene
structure relative to their input camera positions. The space where the feature
volumes are placed acts as a common ground for unifying input modalities. These
feature volumes are overlapped and rendered into feature images from novel
perspectives using volumetric rendering techniques. The rendered feature images
are used as conditioning inputs for a modality-specific diffusion model,
enabling the synthesis of novel images for the desired output modality. In this
paper, we show that jointly training different modules ensures consistent
geometric understanding across all modalities within the framework. We validate
CrossModalityDiffusion's capabilities on the synthetic ShapeNet cars dataset,
demonstrating its effectiveness in generating accurate and consistent novel
views across multiple imaging modalities and perspectives.

摘要：地理空間影像利用來自不同感測方式的資料，例如 EO、SAR 和 LiDAR，範圍從地面無人機到衛星影像。這些異質輸入為場景理解提供了顯著的機會，但在準確解讀幾何形狀時會產生挑戰，特別是在缺乏精確地面真實資料的情況下。為了解決這個問題，我們提出 CrossModalityDiffusion，這是一個模組化架構，旨在跨不同方式和觀點生成影像，而無需事先了解場景幾何形狀。CrossModalityDiffusion 使用特定於方式的編碼器，它會擷取多個輸入影像，並產生具有幾何感知特徵量的特徵量，這些特徵量會根據其輸入相機位置對場景結構進行編碼。放置特徵量的空間作為統一輸入方式的共同基礎。這些特徵量會重疊並使用體積渲染技術從新觀點渲染成特徵影像。渲染的特徵影像用作特定於方式的擴散模型的條件輸入，從而能夠為所需的輸出方式合成新影像。在本文中，我們展示了聯合訓練不同模組可確保架構內所有方式的一致幾何理解。我們在合成 ShapeNet 汽車資料集上驗證了 CrossModalityDiffusion 的功能，展示了其跨多種影像方式和觀點生成準確且一致的新觀點的有效性。

##### **Bridging Language Barriers in Healthcare: A Study on Arabic LLMs**
2501.09825v1 by Nada Saadi, Tathagata Raha, Clément Christophe, Marco AF Pimentel, Ronnie Rajan, Praveen K Kanithi

This paper investigates the challenges of developing large language models
(LLMs) proficient in both multilingual understanding and medical knowledge. We
demonstrate that simply translating medical data does not guarantee strong
performance on clinical tasks in the target language. Our experiments reveal
that the optimal language mix in training data varies significantly across
different medical tasks. We find that larger models with carefully calibrated
language ratios achieve superior performance on native-language clinical tasks.
Furthermore, our results suggest that relying solely on fine-tuning may not be
the most effective approach for incorporating new language knowledge into LLMs.
Instead, data and computationally intensive pretraining methods may still be
necessary to achieve optimal performance in multilingual medical settings.
These findings provide valuable guidance for building effective and inclusive
medical AI systems for diverse linguistic communities.

摘要：本文探討了開發既精通多語言理解又精通醫療知識的大型語言模型 (LLM) 的挑戰。我們證明，僅翻譯醫療資料並不能保證在目標語言的臨床任務中表現出色。我們的實驗揭示，訓練資料中的最佳語言組合因不同的醫療任務而異。我們發現，具有仔細校準語言比例的較大模型在母語臨床任務中表現更佳。此外，我們的結果表明，僅依賴微調可能不是將新的語言知識納入 LLM 的最有效方法。相反，資料和計算密集型預訓練方法對於在多語言醫療環境中實現最佳效能可能仍然必要。這些發現為建立有效且包容性的醫療 AI 系統，以服務於不同的語言社群，提供了有價值的指導方針。

##### **Generalized Single-Image-Based Morphing Attack Detection Using Deep Representations from Vision Transformer**
2501.09817v1 by Haoyu Zhang, Raghavendra Ramachandra, Kiran Raja, Christoph Busch

Face morphing attacks have posed severe threats to Face Recognition Systems
(FRS), which are operated in border control and passport issuance use cases.
Correspondingly, morphing attack detection algorithms (MAD) are needed to
defend against such attacks. MAD approaches must be robust enough to handle
unknown attacks in an open-set scenario where attacks can originate from
various morphing generation algorithms, post-processing and the diversity of
printers/scanners. The problem of generalization is further pronounced when the
detection has to be made on a single suspected image. In this paper, we propose
a generalized single-image-based MAD (S-MAD) algorithm by learning the encoding
from Vision Transformer (ViT) architecture. Compared to CNN-based
architectures, ViT model has the advantage on integrating local and global
information and hence can be suitable to detect the morphing traces widely
distributed among the face region. Extensive experiments are carried out on
face morphing datasets generated using publicly available FRGC face datasets.
Several state-of-the-art (SOTA) MAD algorithms, including representative ones
that have been publicly evaluated, have been selected and benchmarked with our
ViT-based approach. Obtained results demonstrate the improved detection
performance of the proposed S-MAD method on inter-dataset testing (when
different data is used for training and testing) and comparable performance on
intra-dataset testing (when the same data is used for training and testing)
experimental protocol.

摘要：人臉變形攻擊對人臉辨識系統 (FRS) 構成嚴重威脅，而人臉辨識系統用於邊境管制和護照簽發的用例中。
相應地，需要變形攻擊偵測演算法 (MAD) 來防範此類攻擊。MAD 方法必須足夠強大，才能在開放式場景中處理未知的攻擊，而攻擊可能來自各種變形產生演算法、後處理以及印表機/掃描器的多樣性。當偵測必須在單一可疑影像上進行時，泛化問題會進一步凸顯。在本文中，我們提出一個廣義的單一影像式 MAD (S-MAD) 演算法，透過學習 Vision Transformer (ViT) 架構的編碼。與基於 CNN 的架構相比，ViT 模型在整合局部和全局資訊方面具有優勢，因此適合偵測廣泛分佈在人臉區域的變形痕跡。在使用公開的 FRGC 人臉資料集產生的臉部變形資料集上進行了廣泛的實驗。已經選擇了多種最先進 (SOTA) 的 MAD 演算法，包括已經公開評估的代表性演算法，並使用我們基於 ViT 的方法進行評量和基準測試。獲得的結果證明了所提出的 S-MAD 方法在跨資料集測試（當不同的資料用於訓練和測試時）的改進偵測效能，以及在資料集內測試（當相同的資料用於訓練和測試時）中具有可比較的效能實驗規範。

##### **Qwen it detect machine-generated text?**
2501.09813v1 by Teodor-George Marchitan, Claudiu Creanga, Liviu P. Dinu

This paper describes the approach of the Unibuc - NLP team in tackling the
Coling 2025 GenAI Workshop, Task 1: Binary Multilingual Machine-Generated Text
Detection. We explored both masked language models and causal models. For
Subtask A, our best model achieved first-place out of 36 teams when looking at
F1 Micro (Auxiliary Score) of 0.8333, and second-place when looking at F1 Macro
(Main Score) of 0.8301

摘要：本文描述了 Unibuc - NLP 團隊在解決 Coling 2025 GenAI 工作坊任務 1：二元多語言機器生成文本檢測中的方法。我們探索了遮罩語言模型和因果模型。對於子任務 A，我們的最佳模型在查看 F1 微觀（輔助分數）為 0.8333 時在 36 個團隊中獲得第一名，在查看 F1 巨觀（主要分數）為 0.8301 時獲得第二名

##### **Enhancing Generalization in Chain of Thought Reasoning for Smaller Models**
2501.09804v1 by Maxwell J. Yin, Dingyi Jiang, Yongbing Chen, Boyu Wang, Charles Ling

Chain-of-Thought (CoT) reasoning in smaller language models is a challenging
natural language process problem yet highly desirable in many real-life
applications. Existing CoT knowledge distillation methods often suffer from
overly conservative memorization in smaller LLMs, leading to low generalization
confidence. As fully preserving the CoT ability of teacher model is impossible,
we hypothesize that adversarial CoT fine-tuning is crucial for developing
smaller LLM with robust CoT generalization. To this end, we propose
\textit{PRompt-Assisted Domain-Adversarial fine-tuning} (PRADA), a principled
fine-tuning framework that integrates diverse CoT domains. Specifically, PRADA
pioneers two CoT improvements in smaller LLM: (1) Recovering the
domain-invariant feature insight which typically lost during distillation with
domain adversarial fine-tuning; (2) Enhancing the domain adaptability of CoT
prompt engineering by employing domain-adversarial approaches. We theoretically
demonstrate the effectiveness of our approach and empirically show that it
significantly outperforms the state of the arts in a wide range of tasks.
Moreover, our empirical findings reveal that the smaller LLM, when leveraging
PRADA, aligns closely with domain knowledge, thereby improving the
explainability of our approach.

摘要：鏈式思考 (CoT) 推理在較小的語言模型中是一個具有挑戰性的自然語言處理問題，但在許多實際應用中卻非常需要。現有的 CoT 知識蒸餾方法通常會導致較小的 LLM 過於保守的記憶，從而降低泛化信心。由於無法完全保留教師模型的 CoT 能力，我們假設對抗性的 CoT 微調對於開發具有強健 CoT 泛化的較小 LLM 至關重要。為此，我們提出了 \textit{提示輔助領域對抗微調} (PRADA)，這是一個整合了不同 CoT 領域的原則性微調框架。具體來說，PRADA 在較小的 LLM 中開創了兩項 CoT 改進：(1) 恢復在蒸餾過程中通常會丟失的與領域無關的特徵見解，並採用領域對抗微調；(2) 通過採用領域對抗方法來增強 CoT 提示工程的領域適應性。我們在理論上證明了我們方法的有效性，並通過實證表明，它在廣泛的任務中顯著優於現有技術。此外，我們的實證結果表明，較小的 LLM 在利用 PRADA 時與領域知識緊密結合，從而提高了我們方法的可解釋性。

##### **Conversational Text Extraction with Large Language Models Using Retrieval-Augmented Systems**
2501.09801v1 by Soham Roy, Mitul Goswami, Nisharg Nargund, Suneeta Mohanty, Prasant Kumar Pattnaik

This study introduces a system leveraging Large Language Models (LLMs) to
extract text and enhance user interaction with PDF documents via a
conversational interface. Utilizing Retrieval-Augmented Generation (RAG), the
system provides informative responses to user inquiries while highlighting
relevant passages within the PDF. Upon user upload, the system processes the
PDF, employing sentence embeddings to create a document-specific vector store.
This vector store enables efficient retrieval of pertinent sections in response
to user queries. The LLM then engages in a conversational exchange, using the
retrieved information to extract text and generate comprehensive, contextually
aware answers. While our approach demonstrates competitive ROUGE values
compared to existing state-of-the-art techniques for text extraction and
summarization, we acknowledge that further qualitative evaluation is necessary
to fully assess its effectiveness in real-world applications. The proposed
system gives competitive ROUGE values as compared to existing state-of-the-art
techniques for text extraction and summarization, thus offering a valuable tool
for researchers, students, and anyone seeking to efficiently extract knowledge
and gain insights from documents through an intuitive question-answering
interface.

摘要：本研究介紹一個系統，利用大型語言模型 (LLM) 來
提取文字，並透過對話式介面增強使用者與 PDF 文件的互動。利用檢索增強生成 (RAG)，這個系統會提供資訊豐富的回應來回答使用者的詢問，同時也會在 PDF 中標示出相關段落。在使用者上傳後，系統會處理 PDF，使用句子嵌入來建立特定於文件向量的儲存庫。這個向量儲存庫可以在回應使用者詢問時，有效率地檢索出相關部分。LLM 接著會進行對話式的交流，使用檢索到的資訊來提取文字，並產生全面且符合脈絡的答案。雖然我們的做法展現出有競爭力的 ROUGE 值，與現有最先進的文字提取和摘要技術相比，我們承認需要進一步的定性評估，才能完整評估其在實際應用中的有效性。與現有的最先進的文字提取和摘要技術相比，所提出的系統給出有競爭力的 ROUGE 值，因此提供了一個有價值的工具，供研究人員、學生和任何尋求透過直覺式的問答介面有效率地提取知識並從文件中獲得見解的人使用。

##### **Computing Optimization-Based Prompt Injections Against Closed-Weights Models By Misusing a Fine-Tuning API**
2501.09798v1 by Andrey Labunets, Nishit V. Pandya, Ashish Hooda, Xiaohan Fu, Earlence Fernandes

We surface a new threat to closed-weight Large Language Models (LLMs) that
enables an attacker to compute optimization-based prompt injections.
Specifically, we characterize how an attacker can leverage the loss-like
information returned from the remote fine-tuning interface to guide the search
for adversarial prompts. The fine-tuning interface is hosted by an LLM vendor
and allows developers to fine-tune LLMs for their tasks, thus providing
utility, but also exposes enough information for an attacker to compute
adversarial prompts. Through an experimental analysis, we characterize the
loss-like values returned by the Gemini fine-tuning API and demonstrate that
they provide a useful signal for discrete optimization of adversarial prompts
using a greedy search algorithm. Using the PurpleLlama prompt injection
benchmark, we demonstrate attack success rates between 65% and 82% on Google's
Gemini family of LLMs. These attacks exploit the classic utility-security
tradeoff - the fine-tuning interface provides a useful feature for developers
but also exposes the LLMs to powerful attacks.

摘要：我們發現了一個對封閉權重大型語言模型 (LLM) 的新威脅，它使攻擊者能夠計算基於最佳化的提示注入。具體來說，我們描述了攻擊者如何利用從遠程微調介面傳回的類似損失的資訊來引導對抗提示的搜尋。微調介面由 LLM 供應商託管，並允許開發人員針對其任務微調 LLM，從而提供效用，但也公開了足夠的資訊供攻擊者計算對抗提示。透過實驗分析，我們描述了 Gemini 微調 API 傳回的類似損失的值，並證明它們提供了有用的訊號，可用於使用貪婪搜尋演算法對抗提示進行離散最佳化。使用 PurpleLlama 提示注入基準，我們展示了在 Google 的 LLM 家族 Gemini 上的攻擊成功率介於 65% 到 82% 之間。這些攻擊利用了經典的效用安全性權衡 - 微調介面為開發人員提供了有用的功能，但也會讓 LLM 遭受強大的攻擊。

##### **Learnings from Scaling Visual Tokenizers for Reconstruction and Generation**
2501.09755v1 by Philippe Hansen-Estruch, David Yan, Ching-Yao Chung, Orr Zohar, Jialiang Wang, Tingbo Hou, Tao Xu, Sriram Vishwanath, Peter Vajda, Xinlei Chen

Visual tokenization via auto-encoding empowers state-of-the-art image and
video generative models by compressing pixels into a latent space. Although
scaling Transformer-based generators has been central to recent advances, the
tokenizer component itself is rarely scaled, leaving open questions about how
auto-encoder design choices influence both its objective of reconstruction and
downstream generative performance. Our work aims to conduct an exploration of
scaling in auto-encoders to fill in this blank. To facilitate this exploration,
we replace the typical convolutional backbone with an enhanced Vision
Transformer architecture for Tokenization (ViTok). We train ViTok on
large-scale image and video datasets far exceeding ImageNet-1K, removing data
constraints on tokenizer scaling. We first study how scaling the auto-encoder
bottleneck affects both reconstruction and generation -- and find that while it
is highly correlated with reconstruction, its relationship with generation is
more complex. We next explored the effect of separately scaling the
auto-encoders' encoder and decoder on reconstruction and generation
performance. Crucially, we find that scaling the encoder yields minimal gains
for either reconstruction or generation, while scaling the decoder boosts
reconstruction but the benefits for generation are mixed. Building on our
exploration, we design ViTok as a lightweight auto-encoder that achieves
competitive performance with state-of-the-art auto-encoders on ImageNet-1K and
COCO reconstruction tasks (256p and 512p) while outperforming existing
auto-encoders on 16-frame 128p video reconstruction for UCF-101, all with 2-5x
fewer FLOPs. When integrated with Diffusion Transformers, ViTok demonstrates
competitive performance on image generation for ImageNet-1K and sets new
state-of-the-art benchmarks for class-conditional video generation on UCF-101.

摘要：<paragraph>透過自動編碼進行視覺標記化，能將像素壓縮成潛在空間，進而增強最先進的影像和影片生成模型。儘管擴充基於 Transformer 的生成器已成為近期進展的核心，但標記化元件本身卻很少被擴充，因此對於自動編碼器設計選擇如何影響其重建目標和下游生成效能，仍有待探討。我們的研究旨在探索自動編碼器的擴充，以填補這項空白。為了促進此探索，我們將典型的卷積主幹替換為增強的 Tokenization 視覺 Transformer 架構 (ViTok)。我們在遠遠超過 ImageNet-1K 的大型影像和影片資料集上訓練 ViTok，消除了標記化擴充的資料限制。我們首先研究擴充自動編碼器瓶頸如何影響重建和生成，並發現儘管它與重建高度相關，但與生成之間的關係更為複雜。接下來，我們探討了分別擴充自動編碼器的編碼器和解碼器對重建和生成效能的影響。至關重要的是，我們發現擴充編碼器對重建或生成而言收益甚微，而擴充解碼器會提升重建，但對生成的益處則是好壞參半。根據我們的探索，我們將 ViTok 設計為一個輕量級自動編碼器，在 ImageNet-1K 和 COCO 重建任務 (256p 和 512p) 上，都能達到與最先進自動編碼器相媲美的效能，同時在 UCF-101 的 16 幀 128p 影片重建上優於現有的自動編碼器，且 FLOP 數減少 2-5 倍。與擴散 Transformer 整合後，ViTok 在 ImageNet-1K 的影像生成上展現了競爭力，並在 UCF-101 的類別條件影片生成上創下新的最先進基準。</paragraph>

##### **OmniThink: Expanding Knowledge Boundaries in Machine Writing through Thinking**
2501.09751v1 by Zekun Xi, Wenbiao Yin, Jizhan Fang, Jialong Wu, Runnan Fang, Ningyu Zhang, Jiang Yong, Pengjun Xie, Fei Huang, Huajun Chen

Machine writing with large language models often relies on
retrieval-augmented generation. However, these approaches remain confined
within the boundaries of the model's predefined scope, limiting the generation
of content with rich information. Specifically, vanilla-retrieved information
tends to lack depth, utility, and suffers from redundancy, which negatively
impacts the quality of generated articles, leading to shallow, repetitive, and
unoriginal outputs. To address these issues, we propose OmniThink, a machine
writing framework that emulates the human-like process of iterative expansion
and reflection. The core idea behind OmniThink is to simulate the cognitive
behavior of learners as they progressively deepen their knowledge of the
topics. Experimental results demonstrate that OmniThink improves the knowledge
density of generated articles without compromising metrics such as coherence
and depth. Human evaluations and expert feedback further highlight the
potential of OmniThink to address real-world challenges in the generation of
long-form articles.

摘要：大型語言模型的機器寫作通常依賴於檢索增強生成。然而，這些方法仍侷限於模型預定義的範圍內，限制了產生具有豐富信息的內容。具體來說，香草檢索信息往往缺乏深度、實用性，並且存在冗餘，這對生成的條目品質產生負面影響，導致膚淺、重複且缺乏原創性的輸出。為了解決這些問題，我們提出了 OmniThink，這是一個模擬人類迭代擴展和反思過程的機器寫作框架。OmniThink 背後的主要思想是模擬學習者在逐漸加深對主題的了解時的認知行為。實驗結果表明，OmniThink 改善了生成條目的知識密度，同時不影響相干性和深度等指標。人類評估和專家回饋進一步突出了 OmniThink 在解決長篇條目生成中的現實世界挑戰的潛力。

##### **Enhancing Lexicon-Based Text Embeddings with Large Language Models**
2501.09749v1 by Yibin Lei, Tao Shen, Yu Cao, Andrew Yates

Recent large language models (LLMs) have demonstrated exceptional performance
on general-purpose text embedding tasks. While dense embeddings have dominated
related research, we introduce the first Lexicon-based EmbeddiNgS (LENS)
leveraging LLMs that achieve competitive performance on these tasks. Regarding
the inherent tokenization redundancy issue and unidirectional attention
limitations in traditional causal LLMs, LENS consolidates the vocabulary space
through token embedding clustering, and investigates bidirectional attention
and various pooling strategies. Specifically, LENS simplifies lexicon matching
by assigning each dimension to a specific token cluster, where semantically
similar tokens are grouped together, and unlocking the full potential of LLMs
through bidirectional attention. Extensive experiments demonstrate that LENS
outperforms dense embeddings on the Massive Text Embedding Benchmark (MTEB),
delivering compact feature representations that match the sizes of dense
counterparts. Notably, combining LENSE with dense embeddings achieves
state-of-the-art performance on the retrieval subset of MTEB (i.e. BEIR).

摘要：最近的大型语言模型 (LLM) 在通用文字嵌入任务中展现出非凡的性能。虽然稠密嵌入主导相关研究，但我们引入了第一个基于词典的嵌入 (LENS)，利用 LLM 在这些任务中实现有竞争力的性能。关于传统因果 LLM 中固有的标记化冗余问题和单向注意限制，LENS 通过标记嵌入聚类巩固词汇空间，并研究双向注意和各种池化策略。具体来说，LENS 通过将每个维度分配给一个特定的标记群集来简化词典匹配，其中语义相似的标记被分组在一起，并通过双向注意释放 LLM 的全部潜力。广泛的实验表明，LENS 在海量文本嵌入基准 (MTEB) 上优于稠密嵌入，提供了与稠密对应物大小匹配的紧凑特征表示。值得注意的是，将 LENSE 与稠密嵌入相结合在 MTEB 的检索子集（即 BEIR）上实现了最先进的性能。

##### **Suggesting Code Edits in Interactive Machine Learning Notebooks Using Large Language Models**
2501.09745v1 by Bihui Jin, Jiayue Wang, Pengyu Nie

Machine learning developers frequently use interactive computational
notebooks, such as Jupyter notebooks, to host code for data processing and
model training. Jupyter notebooks provide a convenient tool for writing machine
learning pipelines and interactively observing outputs, however, maintaining
Jupyter notebooks, e.g., to add new features or fix bugs, can be challenging
due to the length and complexity of the notebooks. Moreover, there is no
existing benchmark related to developer edits on Jupyter notebooks. To address
this, we present the first dataset of 48,398 Jupyter notebook edits derived
from 20,095 revisions of 792 machine learning repositories on GitHub, and
perform the first study of the using LLMs to predict code edits in Jupyter
notebooks. Our dataset captures granular details of cell-level and line-level
modifications, offering a foundation for understanding real-world maintenance
patterns in machine learning workflows. We observed that the edits on Jupyter
notebooks are highly localized, with changes averaging only 166 lines of code
in repositories. While larger models outperform smaller counterparts in code
editing, all models have low accuracy on our dataset even after finetuning,
demonstrating the complexity of real-world machine learning maintenance tasks.
Our findings emphasize the critical role of contextual information in improving
model performance and point toward promising avenues for advancing large
language models' capabilities in engineering machine learning code.

摘要：機器學習開發人員經常使用互動式運算筆記本，例如 Jupyter 筆記本，來儲存資料處理和模型訓練的程式碼。Jupyter 筆記本提供了一個方便的工具來撰寫機器學習管線並互動式地觀察輸出，然而，維護 Jupyter 筆記本（例如，新增功能或修正錯誤）可能會很困難，因為筆記本的長度和複雜性。此外，目前沒有與 Jupyter 筆記本上開發人員編輯相關的基準測試。為了解決這個問題，我們提供了第一個資料集，其中包含來自 GitHub 上 792 個機器學習儲存庫的 20,095 次修訂中衍生的 48,398 次 Jupyter 筆記本編輯，並執行第一個使用 LLM 來預測 Jupyter 筆記本中程式碼編輯的研究。我們的資料集擷取了單元格層級和行層級修改的詳細資料，為了解機器學習工作流程中的真實世界維護模式提供了基礎。我們觀察到 Jupyter 筆記本上的編輯高度局部化，儲存庫中的變更平均只有 166 行程式碼。雖然較大的模型在程式碼編輯方面優於較小的模型，但在微調後，所有模型在我們的資料集上都具有低準確度，這證明了真實世界的機器學習維護任務的複雜性。我們的研究結果強調了背景資訊在改善模型效能方面的重要作用，並指出了推動大型語言模型在機器學習程式碼工程方面的能力的潛在途徑。

##### **KU AIGEN ICL EDI@BC8 Track 3: Advancing Phenotype Named Entity Recognition and Normalization for Dysmorphology Physical Examination Reports**
2501.09744v1 by Hajung Kim, Chanhwi Kim, Jiwoong Sohn, Tim Beck, Marek Rei, Sunkyu Kim, T Ian Simpson, Joram M Posma, Antoine Lain, Mujeen Sung, Jaewoo Kang

The objective of BioCreative8 Track 3 is to extract phenotypic key medical
findings embedded within EHR texts and subsequently normalize these findings to
their Human Phenotype Ontology (HPO) terms. However, the presence of diverse
surface forms in phenotypic findings makes it challenging to accurately
normalize them to the correct HPO terms. To address this challenge, we explored
various models for named entity recognition and implemented data augmentation
techniques such as synonym marginalization to enhance the normalization step.
Our pipeline resulted in an exact extraction and normalization F1 score 2.6\%
higher than the mean score of all submissions received in response to the
challenge. Furthermore, in terms of the normalization F1 score, our approach
surpassed the average performance by 1.9\%. These findings contribute to the
advancement of automated medical data extraction and normalization techniques,
showcasing potential pathways for future research and application in the
biomedical domain.

摘要：BioCreative8 軌道 3 的目標是從電子病歷文本中萃取表型關鍵醫療發現，並將這些發現標準化為人類表型本体 (HPO) 條款。然而，表型發現中存在多樣化的表面形式，這使得將其準確標準化為正確的 HPO 條款具有挑戰性。為了應對這一挑戰，我們探討了命名實體識別的各種模型，並實作了資料擴充技術，例如同義詞邊緣化，以增強標準化步驟。我們的管道產生了精確的萃取和標準化 F1 分數，比回應挑戰所收到的所有提交的平均分數高 2.6%。此外，在標準化 F1 分數方面，我們的做法比平均表現高出 1.9%。這些發現有助於自動化醫療資料萃取和標準化技術的進展，展示了生物醫學領域未來研究和應用的潛在途徑。

##### **Attention based Bidirectional GRU hybrid model for inappropriate content detection in Urdu language**
2501.09722v1 by Ezzah Shoukat, Rabia Irfan, Iqra Basharat, Muhammad Ali Tahir, Sameen Shaukat

With the increased use of the internet and social networks for online
discussions, the spread of toxic and inappropriate content on social networking
sites has also increased. Several studies have been conducted in different
languages. However, there is less work done for South Asian languages for
inappropriate content identification using deep learning techniques. In Urdu
language, the spellings are not unique, and people write different common
spellings for the same word, while mixing it other languages, like English in
the text makes it more challenging, and limited research work is available to
process such language with the finest algorithms. The use of attention layer
with a deep learning model can help handling the long-term dependencies and
increase its efficiency . To explore the effects of the attention layer, this
study proposes attention-based Bidirectional GRU hybrid model for identifying
inappropriate content in Urdu Unicode text language. Four different baseline
deep learning models; LSTM, Bi-LSTM, GRU, and TCN, are used to compare the
performance of the proposed model. The results of these models were compared
based on evaluation metrics, dataset size, and impact of the word embedding
layer. The pre-trained Urdu word2Vec embeddings were utilized for our case. Our
proposed model BiGRU-A outperformed all other baseline models by yielding 84\%
accuracy without using pre-trained word2Vec layer. From our experiments, we
have established that the attention layer improves the model's efficiency, and
pre-trained word2Vec embedding does not work well with an inappropriate content
dataset.

摘要：<paragraph>随着互联网和社交网络在线讨论的使用增加，社交网站上也会出现更多有毒和不当的内容。已经针对不同的语言进行了多项研究。然而，使用深度学习技术对南亚语言进行不当内容识别方面的工作较少。在乌尔都语中，拼写并不唯一，人们为同一个单词书写不同的常用拼写，同时在文本中将其与其他语言（如英语）混合，使其更具挑战性，并且有限的研究工作可以利用最好的算法来处理这种语言。在深度学习模型中使用注意力层可以帮助处理长期依赖关系并提高其效率。为了探索注意力层的效果，本研究提出了基于注意力的双向 GRU 混合模型，用于识别乌尔都语 Unicode 文本语言中的不当内容。四个不同的基线深度学习模型；LSTM、Bi-LSTM、GRU 和 TCN，用于比较所提出模型的性能。这些模型的结果基于评估指标、数据集大小和单词嵌入层的影响进行了比较。我们案例中使用了预训练的乌尔都语 word2Vec 嵌入。我们提出的模型 BiGRU-A 在不使用预训练的 word2Vec 层的情况下，以 84% 的准确率优于所有其他基线模型。从我们的实验中，我们已经确定注意力层提高了模型的效率，并且预训练的 word2Vec 嵌入与不当内容数据集配合得不好。</paragraph>

##### **A Simple Aerial Detection Baseline of Multimodal Language Models**
2501.09720v1 by Qingyun Li, Yushi Chen, Xinya Shu, Dong Chen, Xin He, Yi Yu, Xue Yang

The multimodal language models (MLMs) based on generative pre-trained
Transformer are considered powerful candidates for unifying various domains and
tasks. MLMs developed for remote sensing (RS) have demonstrated outstanding
performance in multiple tasks, such as visual question answering and visual
grounding. In addition to visual grounding that detects specific objects
corresponded to given instruction, aerial detection, which detects all objects
of multiple categories, is also a valuable and challenging task for RS
foundation models. However, aerial detection has not been explored by existing
RS MLMs because the autoregressive prediction mechanism of MLMs differs
significantly from the detection outputs. In this paper, we present a simple
baseline for applying MLMs to aerial detection for the first time, named
LMMRotate. Specifically, we first introduce a normalization method to transform
detection outputs into textual outputs to be compatible with the MLM framework.
Then, we propose a evaluation method, which ensures a fair comparison between
MLMs and conventional object detection models. We construct the baseline by
fine-tuning open-source general-purpose MLMs and achieve impressive detection
performance comparable to conventional detector. We hope that this baseline
will serve as a reference for future MLM development, enabling more
comprehensive capabilities for understanding RS images. Code is available at
https://github.com/Li-Qingyun/mllm-mmrotate.

摘要：基於生成式預訓練 Transformer 的多模態語言模型 (MLM) 被認為是統一各種領域和任務的有力候選者。為遙感 (RS) 開發的 MLM 已在多項任務中展現傑出的效能，例如視覺問題解答和視覺基礎。除了偵測特定物體以對應給定指令的視覺基礎外，偵測所有多類別的物體的空中偵測也是 RS 基礎模型中一項有價值且具有挑戰性的任務。然而，空中偵測尚未被現有的 RS MLM 探索，因為 MLM 的自迴歸預測機制與偵測輸出有顯著的差異。在本文中，我們提出了一個簡單的基準，首次將 MLM 應用於空中偵測，稱為 LMMRotate。具體來說，我們首先引入一種正規化方法，將偵測輸出轉換為文字輸出，以與 MLM 框架相容。然後，我們提出一個評估方法，以確保 MLM 與傳統物體偵測模型之間的公平比較。我們透過微調開源通用 MLM 來建構基準，並獲得與傳統偵測器相當的令人印象深刻的偵測效能。我們希望這個基準能作為未來 MLM 開發的參考，讓理解 RS 影像的能力更全面。程式碼可在 https://github.com/Li-Qingyun/mllm-mmrotate 取得。

##### **Comparative Insights from 12 Machine Learning Models in Extracting Economic Ideology from Political Text**
2501.09719v1 by Jihed Ncib

This study conducts a systematic assessment of the capabilities of 12 machine
learning models and model variations in detecting economic ideology. As an
evaluation benchmark, I use manifesto data spanning six elections in the United
Kingdom and pre-annotated by expert and crowd coders. The analysis assesses the
performance of several generative, fine-tuned, and zero-shot models at the
granular and aggregate levels. The results show that generative models such as
GPT-4o and Gemini 1.5 Flash consistently outperform other models against all
benchmarks. However, they pose issues of accessibility and resource
availability. Fine-tuning yielded competitive performance and offers a reliable
alternative through domain-specific optimization. But its dependency on
training data severely limits scalability. Zero-shot models consistently face
difficulties with identifying signals of economic ideology, often resulting in
negative associations with human coding. Using general knowledge for the
domain-specific task of ideology scaling proved to be unreliable. Other key
findings include considerable within-party variation, fine-tuning benefiting
from larger training data, and zero-shot's sensitivity to prompt content. The
assessments include the strengths and limitations of each model and derive
best-practices for automated analyses of political content.

摘要：本研究對 12 個機器學習模型和模型變異偵測經濟意識形態的能力進行系統性評估。作為評估基準，我使用跨越英國六次選舉的政綱資料，並由專家和群眾編碼員預先註解。分析評估了幾個生成式、微調和零次學習模型在細粒度和彙總層級的效能。結果顯示，GPT-4o 和 Gemini 1.5 Flash 等生成式模型在所有基準上始終優於其他模型。然而，它們提出了可及性和資源可用性的問題。微調產生了競爭力表現，並透過特定領域最佳化提供了一個可靠的替代方案。但它對訓練資料的依賴嚴重限制了可擴充性。零次學習模型始終難以識別經濟意識形態的訊號，通常會導致與人類編碼的負面關聯。使用一般知識來進行意識形態擴充的特定領域任務被證明不可靠。其他關鍵發現包括黨內變異相當大、微調受益於更大的訓練資料，以及零次學習對提示內容的敏感性。評估包括每個模型的優點和缺點，並為政治內容的自動化分析得出最佳實務。

##### **CyberMentor: AI Powered Learning Tool Platform to Address Diverse Student Needs in Cybersecurity Education**
2501.09709v1 by Tianyu Wang, Nianjun Zhou, Zhixiong Chen

Many non-traditional students in cybersecurity programs often lack access to
advice from peers, family members and professors, which can hinder their
educational experiences. Additionally, these students may not fully benefit
from various LLM-powered AI assistants due to issues like content relevance,
locality of advice, minimum expertise, and timing. This paper addresses these
challenges by introducing an application designed to provide comprehensive
support by answering questions related to knowledge, skills, and career
preparation advice tailored to the needs of these students. We developed a
learning tool platform, CyberMentor, to address the diverse needs and pain
points of students majoring in cybersecurity. Powered by agentic workflow and
Generative Large Language Models (LLMs), the platform leverages
Retrieval-Augmented Generation (RAG) for accurate and contextually relevant
information retrieval to achieve accessibility and personalization. We
demonstrated its value in addressing knowledge requirements for cybersecurity
education and for career marketability, in tackling skill requirements for
analytical and programming assignments, and in delivering real time on demand
learning support. Using three use scenarios, we showcased CyberMentor in
facilitating knowledge acquisition and career preparation and providing
seamless skill-based guidance and support. We also employed the LangChain
prompt-based evaluation methodology to evaluate the platform's impact,
confirming its strong performance in helpfulness, correctness, and
completeness. These results underscore the system's ability to support students
in developing practical cybersecurity skills while improving equity and
sustainability within higher education. Furthermore, CyberMentor's open-source
design allows for adaptation across other disciplines, fostering educational
innovation and broadening its potential impact.

摘要：<paragraph>許多非傳統的網路安全課程學生經常缺乏來自同儕、家人和教授的建議，這可能會阻礙他們的教育經驗。此外，由於內容相關性、建議的地域性、最低專業知識和時機等問題，這些學生可能無法充分受益於各種 LLM 驅動的 AI 助理。本文透過介紹一個應用程式來解決這些挑戰，該應用程式旨在透過回答與知識、技能和職業準備建議相關的問題，提供全面的支援，以滿足這些學生的需求。我們開發了一個學習工具平台 CyberMentor，以滿足主修網路安全的學生們的多元需求和痛點。該平台由代理工作流程和生成式大型語言模型 (LLM) 提供支援，利用檢索增強生成 (RAG) 來進行準確且與脈絡相關的資訊檢索，以實現可及性和個人化。我們展示了其在滿足網路安全教育和職業適銷性的知識需求、應對分析和編程作業的技能需求以及提供即時依需求學習支援方面的價值。使用三個使用情境，我們展示了 CyberMentor 在促進知識獲取和職業準備以及提供無縫的技能指導和支援方面的作用。我們還採用了基於提示的 LangChain 評估方法來評估平台的影響，確認其在有幫助性、正確性和完整性方面的強勁表現。這些結果強調了系統在培養學生實務網路安全技能的同時，還能提升高等教育中的公平性和永續性的能力。此外，CyberMentor 的開源設計允許跨其他學科進行調整，促進教育創新並擴大其潛在影響。</paragraph>

##### **The Goofus & Gallant Story Corpus for Practical Value Alignment**
2501.09707v1 by Md Sultan Al Nahian, Tasmia Tasrin, Spencer Frazier, Mark Riedl, Brent Harrison

Values or principles are key elements of human society that influence people
to behave and function according to an accepted standard set of social rules to
maintain social order. As AI systems are becoming ubiquitous in human society,
it is a major concern that they could violate these norms or values and
potentially cause harm. Thus, to prevent intentional or unintentional harm, AI
systems are expected to take actions that align with these principles. Training
systems to exhibit this type of behavior is difficult and often requires a
specialized dataset. This work presents a multi-modal dataset illustrating
normative and non-normative behavior in real-life situations described through
natural language and artistic images. This training set contains curated sets
of images that are designed to teach young children about social principles. We
argue that this is an ideal dataset to use for training socially normative
agents given this fact.

摘要：價值觀或原則是人類社會的關鍵元素，影響著人們根據一套公認的社會規則來行為和運作，以維持社會秩序。由於人工智慧系統在人類社會中正變得無處不在，因此它們可能違反這些規範或價值觀並可能造成傷害，這是一個主要的關注點。因此，為了防止故意或無意的傷害，預期人工智慧系統採取與這些原則一致的行動。訓練系統表現出這種類型的行為很困難，而且通常需要一個專業的資料集。這項工作提供了一個多模態資料集，說明了在透過自然語言和藝術圖像描述的真實生活中，規範性和非規範性行為。這個訓練集包含經過策展的圖像集，旨在教導幼兒有關社會原則。我們認為，鑑於這個事實，這是用於訓練社會規範代理人的理想資料集。

##### **Domain Adaptation of Foundation LLMs for e-Commerce**
2501.09706v1 by Christian Herold, Michael Kozielski, Tala Bazazo, Pavel Petrushkov, Hadi Hashemi, Patrycja Cieplicka, Dominika Basaj, Shahram Khadivi

We present the e-Llama models: 8 billion and 70 billion parameter large
language models that are adapted towards the e-commerce domain. These models
are meant as foundation models with deep knowledge about e-commerce, that form
a base for instruction- and fine-tuning. The e-Llama models are obtained by
continuously pretraining the Llama 3.1 base models on 1 trillion tokens of
domain-specific data.
  We discuss our approach and motivate our choice of hyperparameters with a
series of ablation studies. To quantify how well the models have been adapted
to the e-commerce domain, we define and implement a set of multilingual,
e-commerce specific evaluation tasks.
  We show that, when carefully choosing the training setup, the Llama 3.1
models can be adapted towards the new domain without sacrificing significant
performance on general domain tasks. We also explore the possibility of merging
the adapted model and the base model for a better control of the performance
trade-off between domains.

摘要：我們展示了 e-Llama 模型：80 億和 700 億個參數的大型語言模型，針對電子商務領域進行了調整。這些模型被視為基礎模型，對電子商務有深入的了解，並作為指導和微調的基礎。e-Llama 模型是透過持續對 Llama 3.1 基礎模型進行預訓練，使用 1 兆個特定領域資料的代幣來取得。
我們討論了我們的做法，並透過一系列消融研究說明我們選擇超參數的動機。為了量化模型對電子商務領域的適應程度，我們定義並實作了一組多語言、特定於電子商務的評估任務。
我們展示了，在仔細選擇訓練設定時，Llama 3.1 模型可以適應新領域，而不會犧牲一般領域任務的顯著效能。我們也探索了合併已適應的模型和基礎模型的可能性，以更好地控制領域間的效能取捨。

##### **Practical Continual Forgetting for Pre-trained Vision Models**
2501.09705v1 by Hongbo Zhao, Fei Zhu, Bolin Ni, Feng Zhu, Gaofeng Meng, Zhaoxiang Zhang

For privacy and security concerns, the need to erase unwanted information
from pre-trained vision models is becoming evident nowadays. In real-world
scenarios, erasure requests originate at any time from both users and model
owners, and these requests usually form a sequence. Therefore, under such a
setting, selective information is expected to be continuously removed from a
pre-trained model while maintaining the rest. We define this problem as
continual forgetting and identify three key challenges. (i) For unwanted
knowledge, efficient and effective deleting is crucial. (ii) For remaining
knowledge, the impact brought by the forgetting procedure should be minimal.
(iii) In real-world scenarios, the training samples may be scarce or partially
missing during the process of forgetting. To address them, we first propose
Group Sparse LoRA (GS-LoRA). Specifically, towards (i), we introduce LoRA
modules to fine-tune the FFN layers in Transformer blocks for each forgetting
task independently, and towards (ii), a simple group sparse regularization is
adopted, enabling automatic selection of specific LoRA groups and zeroing out
the others. To further extend GS-LoRA to more practical scenarios, we
incorporate prototype information as additional supervision and introduce a
more practical approach, GS-LoRA++. For each forgotten class, we move the
logits away from its original prototype. For the remaining classes, we pull the
logits closer to their respective prototypes. We conduct extensive experiments
on face recognition, object detection and image classification and demonstrate
that our method manages to forget specific classes with minimal impact on other
classes. Codes have been released on https://github.com/bjzhb666/GS-LoRA.

摘要：<paragraph>由於隱私和安全性考量，如今清除預訓練視覺模型中不需要的資訊的需求已變得明顯。在真實世界的場景中，清除請求隨時來自使用者和模型所有者，而且這些請求通常會形成一個序列。因此，在這樣的設定下，預期會持續從預訓練模型中移除選擇性資訊，同時保留其餘部分。我們將這個問題定義為持續遺忘，並找出三個關鍵挑戰。(i) 對於不需要的知識，有效率且有效的刪除至關重要。(ii) 對於保留的知識，遺忘程序帶來的影響應降到最低。(iii) 在真實世界的場景中，訓練樣本在遺忘過程中可能稀少或部分遺失。為了解決這些問題，我們首先提出群組稀疏 LoRA (GS-LoRA)。具體來說，針對 (i)，我們導入 LoRA 模組，以針對每個遺忘任務獨立微調 Transformer 區塊中的 FFN 層，而針對 (ii)，採用簡單的群組稀疏正則化，能夠自動選擇特定 LoRA 群組並將其他群組歸零。為了進一步將 GS-LoRA 延伸到更實際的場景，我們將原型資訊納入作為額外的監督，並導入更實用的方法，GS-LoRA++。對於每個被遺忘的類別，我們將 logit 遠離其原始原型。對於其餘類別，我們將 logit 拉近它們各自的原型。我們對人臉辨識、物件偵測和影像分類進行廣泛的實驗，並展示我們的模型設法遺忘特定類別，同時對其他類別的影響降到最低。程式碼已在 https://github.com/bjzhb666/GS-LoRA 上發布。</paragraph>

##### **Cueless EEG imagined speech for subject identification: dataset and benchmarks**
2501.09700v1 by Ali Derakhshesh, Zahra Dehghanian, Reza Ebrahimpour, Hamid R. Rabiee

Electroencephalogram (EEG) signals have emerged as a promising modality for
biometric identification. While previous studies have explored the use of
imagined speech with semantically meaningful words for subject identification,
most have relied on additional visual or auditory cues. In this study, we
introduce a cueless EEG-based imagined speech paradigm, where subjects imagine
the pronunciation of semantically meaningful words without any external cues.
This innovative approach addresses the limitations of prior methods by
requiring subjects to select and imagine words from a predefined list
naturally. The dataset comprises over 4,350 trials from 11 subjects across five
sessions. We assess a variety of classification methods, including traditional
machine learning techniques such as Support Vector Machines (SVM) and XGBoost,
as well as time-series foundation models and deep learning architectures
specifically designed for EEG classification, such as EEG Conformer and Shallow
ConvNet. A session-based hold-out validation strategy was employed to ensure
reliable evaluation and prevent data leakage. Our results demonstrate
outstanding classification accuracy, reaching 97.93%. These findings highlight
the potential of cueless EEG paradigms for secure and reliable subject
identification in real-world applications, such as brain-computer interfaces
(BCIs).

摘要：腦電圖 (EEG) 信號已成為生物識別中極具潛力的方式。雖然先前的研究已探討在主題識別中使用具有語義意義字詞的想像語言，但大多依賴額外的視覺或聽覺提示。在本研究中，我們引進一種無提示的 EEG 基於想像語言的範例，受試者在沒有任何外部提示的情況下想像有語義意義字詞的發音。這種創新方法透過要求受試者自然地從預先定義的清單中選擇和想像字詞，來解決先前方法的限制。該資料集包含來自 11 位受試者在五個階段中超過 4,350 次的試驗。我們評估了各種分類方法，包括傳統機器學習技術，例如支援向量機 (SVM) 和 XGBoost，以及專門設計用於 EEG 分類的時間序列基礎模型和深度學習架構，例如 EEG Conformer 和淺層 ConvNet。採用基於階段的保留驗證策略，以確保可靠的評估並防止資料外洩。我們的結果證明了出色的分類準確度，達到 97.93%。這些發現突顯了無提示 EEG 範例在實際應用中安全且可靠的主題識別潛力，例如腦電腦介面 (BCI)。

##### **Towards Large Reasoning Models: A Survey on Scaling LLM Reasoning Capabilities**
2501.09686v2 by Fengli Xu, Qianyue Hao, Zefang Zong, Jingwei Wang, Yunke Zhang, Jingyi Wang, Xiaochong Lan, Jiahui Gong, Tianjian Ouyang, Fanjin Meng, Chenyang Shao, Yuwei Yan, Qinglong Yang, Yiwen Song, Sijian Ren, Xinyuan Hu, Yu Li, Jie Feng, Chen Gao, Yong Li

Language has long been conceived as an essential tool for human reasoning.
The breakthrough of Large Language Models (LLMs) has sparked significant
research interest in leveraging these models to tackle complex reasoning tasks.
Researchers have moved beyond simple autoregressive token generation by
introducing the concept of "thought" -- a sequence of tokens representing
intermediate steps in the reasoning process. This innovative paradigm enables
LLMs' to mimic complex human reasoning processes, such as tree search and
reflective thinking. Recently, an emerging trend of learning to reason has
applied reinforcement learning (RL) to train LLMs to master reasoning
processes. This approach enables the automatic generation of high-quality
reasoning trajectories through trial-and-error search algorithms, significantly
expanding LLMs' reasoning capacity by providing substantially more training
data. Furthermore, recent studies demonstrate that encouraging LLMs to "think"
with more tokens during test-time inference can further significantly boost
reasoning accuracy. Therefore, the train-time and test-time scaling combined to
show a new research frontier -- a path toward Large Reasoning Model. The
introduction of OpenAI's o1 series marks a significant milestone in this
research direction. In this survey, we present a comprehensive review of recent
progress in LLM reasoning. We begin by introducing the foundational background
of LLMs and then explore the key technical components driving the development
of large reasoning models, with a focus on automated data construction,
learning-to-reason techniques, and test-time scaling. We also analyze popular
open-source projects at building large reasoning models, and conclude with open
challenges and future research directions.

摘要：語言長期以來被視為人類推理的必要工具。大型語言模型 (LLM) 的突破激發了顯著的研究興趣，以利用這些模型來解決複雜的推理任務。研究人員已超越簡單的自動迴歸符號生成，引入了「思考」的概念——一個符號序列，代表推理過程中中的中間步驟。這種創新的範例使 LLM 能模擬複雜的人類推理過程，例如樹狀搜尋和反思性思考。最近，一種新興的學習推理趨勢將強化學習 (RL) 應用於訓練 LLM 以掌握推理過程。此方法能透過試錯搜尋演算法自動產生高品質的推理軌跡，藉由提供大量訓練資料，顯著擴充 LLM 的推理能力。此外，最近的研究顯示，鼓勵 LLM 在測試時間推論期間以更多符號「思考」能進一步顯著提升推理準確度。因此，訓練時間和測試時間的擴充結合起來，展示了一個新的研究領域——邁向大型推理模型的道路。OpenAI 的 o1 系列的推出標誌著這個研究方向的重要里程碑。在這項調查中，我們對 LLM 推理的最新進展進行了全面的回顧。我們從介紹 LLM 的基礎背景開始，然後探討推動大型推理模型發展的主要技術組成部分，重點放在自動化資料建構、學習推理技術和測試時間擴充。我們還分析了建立大型推理模型的熱門開源專案，並以開放的挑戰和未來的研究方向作結。

##### **Reward-Guided Controlled Generation for Inference-Time Alignment in Diffusion Models: Tutorial and Review**
2501.09685v1 by Masatoshi Uehara, Yulai Zhao, Chenyu Wang, Xiner Li, Aviv Regev, Sergey Levine, Tommaso Biancalani

This tutorial provides an in-depth guide on inference-time guidance and
alignment methods for optimizing downstream reward functions in diffusion
models. While diffusion models are renowned for their generative modeling
capabilities, practical applications in fields such as biology often require
sample generation that maximizes specific metrics (e.g., stability, affinity in
proteins, closeness to target structures). In these scenarios, diffusion models
can be adapted not only to generate realistic samples but also to explicitly
maximize desired measures at inference time without fine-tuning. This tutorial
explores the foundational aspects of such inference-time algorithms. We review
these methods from a unified perspective, demonstrating that current techniques
-- such as Sequential Monte Carlo (SMC)-based guidance, value-based sampling,
and classifier guidance -- aim to approximate soft optimal denoising processes
(a.k.a. policies in RL) that combine pre-trained denoising processes with value
functions serving as look-ahead functions that predict from intermediate states
to terminal rewards. Within this framework, we present several novel algorithms
not yet covered in the literature. Furthermore, we discuss (1) fine-tuning
methods combined with inference-time techniques, (2) inference-time algorithms
based on search algorithms such as Monte Carlo tree search, which have received
limited attention in current research, and (3) connections between
inference-time algorithms in language models and diffusion models. The code of
this tutorial on protein design is available at
https://github.com/masa-ue/AlignInversePro

摘要：本教程提供了一個關於推論時間指導和對齊方法的深入指南，用於最佳化擴散模型中的下游獎勵函數。儘管擴散模型以其生成模型的能力而聞名，但生物學等領域的實際應用通常需要最大化特定指標（例如穩定性、蛋白質中的親和力、接近目標結構）的樣本生成。在這些場景中，擴散模型不僅可以適應生成真實的樣本，還可以明確最大化推論時間中的所需測量，而無需進行微調。本教程探討了此類推論時間演算法的基本方面。我們從統一的角度回顧了這些方法，證明了當前的技術——例如基於序貫蒙地卡羅 (SMC) 的指導、基於價值的抽樣和分類器指導——旨在近似軟最佳去噪程序（又稱 RL 中的策略），該程序將預訓練的去噪程序與作為預測從中間狀態到終端獎勵的超前函數的值函數相結合。在此框架內，我們提出了幾種文獻中尚未涵蓋的新穎演算法。此外，我們討論了 (1) 與推論時間技術相結合的微調方法，(2) 基於搜尋演算法（例如蒙地卡羅樹搜尋）的推論時間演算法，這些演算法在當前研究中受到的關注有限，以及 (3) 語言模型和擴散模型中推論時間演算法之間的關聯。本蛋白質設計教程的程式碼可在 https://github.com/masa-ue/AlignInversePro 獲得

##### **Authenticated Delegation and Authorized AI Agents**
2501.09674v1 by Tobin South, Samuele Marro, Thomas Hardjono, Robert Mahari, Cedric Deslandes Whitney, Dazza Greenwood, Alan Chan, Alex Pentland

The rapid deployment of autonomous AI agents creates urgent challenges around
authorization, accountability, and access control in digital spaces. New
standards are needed to know whom AI agents act on behalf of and guide their
use appropriately, protecting online spaces while unlocking the value of task
delegation to autonomous agents. We introduce a novel framework for
authenticated, authorized, and auditable delegation of authority to AI agents,
where human users can securely delegate and restrict the permissions and scope
of agents while maintaining clear chains of accountability. This framework
builds on existing identification and access management protocols, extending
OAuth 2.0 and OpenID Connect with agent-specific credentials and metadata,
maintaining compatibility with established authentication and web
infrastructure. Further, we propose a framework for translating flexible,
natural language permissions into auditable access control configurations,
enabling robust scoping of AI agent capabilities across diverse interaction
modalities. Taken together, this practical approach facilitates immediate
deployment of AI agents while addressing key security and accountability
concerns, working toward ensuring agentic AI systems perform only appropriate
actions and providing a tool for digital service providers to enable AI agent
interactions without risking harm from scalable interaction.

摘要：自主 AI 代理的快速部署在數位空間中創造了有關授權、問責制和存取控制的迫切挑戰。需要新的標準來了解 AI 代理代表誰行事並適當地指導其使用，在保護線上空間的同時，釋放將任務委派給自主代理的價值。我們引進了一個創新的架構，用於對 AI 代理進行經過驗證、授權和可稽核的權限委派，其中人類使用者可以在維持明確的問責鏈的同時，安全地委派和限制代理的權限和範圍。此架構建立在現有的識別和存取管理協定上，並使用特定於代理的憑證和元資料來延伸 OAuth 2.0 和 OpenID Connect，同時與既定的驗證和網路基礎架構保持相容性。此外，我們提出一個架構，用於將彈性的自然語言權限轉換為可稽核的存取控制設定，讓 AI 代理功能能夠在各種互動方式中進行穩健的範圍設定。綜合來說，這種實務方法促進了 AI 代理的立即部署，同時解決了主要的安全性與問責問題，朝著確保代理式 AI 系統僅執行適當的動作，並提供數位服務供應商一個工具來啟用 AI 代理互動，而不會冒可擴充互動的風險邁進。

##### **Robin: a Suite of Multi-Scale Vision-Language Models and the CHIRP Evaluation Benchmark**
2501.09672v1 by Alexis Roger, Prateek Humane, Daniel Z. Kaplan, Kshitij Gupta, Qi Sun, George Adamopoulos, Jonathan Siu Chi Lim, Quentin Anthony, Edwin Fennell, Irina Rish

The proliferation of Vision-Language Models (VLMs) in the past several years
calls for rigorous and comprehensive evaluation methods and benchmarks. This
work analyzes existing VLM evaluation techniques, including automated metrics,
AI-based assessments, and human evaluations across diverse tasks. We first
introduce Robin - a novel suite of VLMs that we built by combining Large
Language Models (LLMs) and Vision Encoders (VEs) at multiple scales, and use
Robin to identify shortcomings of current evaluation approaches across scales.
Next, to overcome the identified limitations, we introduce CHIRP - a new long
form response benchmark we developed for more robust and complete VLM
evaluation. We provide open access to the Robin training code, model suite, and
CHIRP benchmark to promote reproducibility and advance VLM research.

摘要：在過去幾年中，視覺語言模型 (VLM) 的激增
需要嚴謹且全面的評估方法和基準。這
項工作分析了現有的 VLM 評估技術，包括自動化指標、
基於 AI 的評估和跨不同任務的人類評估。我們首先
介紹 Robin - 我們通過結合大語言模型 (LLM) 和視覺編碼器 (VE) 在多個規模上構建的一組新穎的 VLM，並使用
Robin 來識別當前評估方法在不同規模上的缺點。
接下來，為了克服已識別的限制，我們引入了 CHIRP - 一個新的長
格式回應基準，我們為更健壯且完整的 VLM
評估而開發。我們提供對 Robin 訓練代碼、模型套件和
CHIRP 基準的開放訪問，以促進可複製性和推進 VLM 研究。

##### **The Heap: A Contamination-Free Multilingual Code Dataset for Evaluating Large Language Models**
2501.09653v1 by Jonathan Katzy, Razvan Mihai Popescu, Arie van Deursen, Maliheh Izadi

The recent rise in the popularity of large language models has spurred the
development of extensive code datasets needed to train them. This has left
limited code available for collection and use in the downstream investigation
of specific behaviors, or evaluation of large language models without suffering
from data contamination. To address this problem, we release The Heap, a large
multilingual dataset covering 57 programming languages that has been
deduplicated with respect to other open datasets of code, enabling researchers
to conduct fair evaluations of large language models without significant data
cleaning overhead.

摘要：近期大型语言模型的普及促进了大量代码数据集的开发，这些数据集用于训练这些模型。这导致可供收集和用于下游特定行为调查的代码有限，或者在不遭受数据污染的情况下评估大型语言模型。为了解决这个问题，我们发布了 The Heap，这是一个包含 57 种编程语言的大型多语言数据集，该数据集已针对其他开放代码数据集进行去重，使研究人员能够在没有大量数据清理开销的情况下对大型语言模型进行公平评估。

##### **Monte Carlo Tree Search with Velocity Obstacles for safe and efficient motion planning in dynamic environments**
2501.09649v1 by Lorenzo Bonanni, Daniele Meli, Alberto Castellini, Alessandro Farinelli

Online motion planning is a challenging problem for intelligent robots moving
in dense environments with dynamic obstacles, e.g., crowds. In this work, we
propose a novel approach for optimal and safe online motion planning with
minimal information about dynamic obstacles. Specifically, our approach
requires only the current position of the obstacles and their maximum speed,
but it does not need any information about their exact trajectories or dynamic
model. The proposed methodology combines Monte Carlo Tree Search (MCTS), for
online optimal planning via model simulations, with Velocity Obstacles (VO),
for obstacle avoidance. We perform experiments in a cluttered simulated
environment with walls, and up to 40 dynamic obstacles moving with random
velocities and directions. With an ablation study, we show the key contribution
of VO in scaling up the efficiency of MCTS, selecting the safest and most
rewarding actions in the tree of simulations. Moreover, we show the superiority
of our methodology with respect to state-of-the-art planners, including
Non-linear Model Predictive Control (NMPC), in terms of improved collision
rate, computational and task performance.

摘要：線上運動規劃對於在充滿動態障礙物（例如人群）的密集環境中移動的智慧型機器人來說是一個具有挑戰性的問題。在這項工作中，我們提出了一個新的方法，用於在對動態障礙物知之甚少的情況下進行最佳且安全的線上運動規劃。具體來說，我們的做法僅需要障礙物的當前位置及其最大速度，但不需要任何有關其確切軌跡或動態模型的資訊。所提出的方法結合了蒙地卡羅樹狀搜尋（MCTS），用於透過模型模擬進行線上最佳規劃，以及速度障礙（VO），用於避免障礙物。我們在一個雜亂的模擬環境中進行實驗，其中有牆壁，以及多達 40 個以隨機速度和方向移動的動態障礙物。透過消融研究，我們展示了 VO 在擴充 MCTS 效率方面的關鍵貢獻，在模擬樹中選擇最安全且最有回報的動作。此外，我們展示了我們的方法優於最先進的規劃器，包括非線性模型預測控制（NMPC），在降低碰撞率、運算和任務執行效能方面表現優異。

##### **NS-Gym: Open-Source Simulation Environments and Benchmarks for Non-Stationary Markov Decision Processes**
2501.09646v1 by Nathaniel S. Keplinger, Baiting Luo, Iliyas Bektas, Yunuo Zhang, Kyle Hollins Wray, Aron Laszka, Abhishek Dubey, Ayan Mukhopadhyay

In many real-world applications, agents must make sequential decisions in
environments where conditions are subject to change due to various exogenous
factors. These non-stationary environments pose significant challenges to
traditional decision-making models, which typically assume stationary dynamics.
Non-stationary Markov decision processes (NS-MDPs) offer a framework to model
and solve decision problems under such changing conditions. However, the lack
of standardized benchmarks and simulation tools has hindered systematic
evaluation and advance in this field. We present NS-Gym, the first simulation
toolkit designed explicitly for NS-MDPs, integrated within the popular
Gymnasium framework. In NS-Gym, we segregate the evolution of the environmental
parameters that characterize non-stationarity from the agent's decision-making
module, allowing for modular and flexible adaptations to dynamic environments.
We review prior work in this domain and present a toolkit encapsulating key
problem characteristics and types in NS-MDPs. This toolkit is the first effort
to develop a set of standardized interfaces and benchmark problems to enable
consistent and reproducible evaluation of algorithms under non-stationary
conditions. We also benchmark six algorithmic approaches from prior work on
NS-MDPs using NS-Gym. Our vision is that NS-Gym will enable researchers to
assess the adaptability and robustness of their decision-making algorithms to
non-stationary conditions.

摘要：在許多真實世界的應用中，代理人必須在環境中做出順序決策，而環境中的條件可能會因各種外生因素而改變。這些非平穩環境對傳統決策制定模型構成重大挑戰，這些模型通常假設平穩動態。非平穩馬可夫決策過程 (NS-MDP) 提供了一個框架，可以在這種變化的條件下對決策問題進行建模和求解。然而，缺乏標準化基準和模擬工具阻礙了系統評估和這一領域的進步。我們展示了 NS-Gym，這是第一個專門為 NS-MDP 設計的模擬工具包，並整合到了流行的 Gymnasium 框架中。在 NS-Gym 中，我們將表徵非平穩性的環境參數的演變與代理人的決策制定模組分開，允許對動態環境進行模組化和靈活的適應。我們回顧了這個領域的先前工作，並展示了一個工具包，其中封裝了 NS-MDP 中的關鍵問題特徵和類型。這個工具包是制定標準化介面和基準問題的第一個努力，以便在非平穩條件下對演算法進行一致且可重現的評估。我們還使用 NS-Gym 對 NS-MDP 中先前工作的六種演算法方法進行基準測試。我們的願景是 NS-Gym 將使研究人員能夠評估其決策制定演算法對非平穩條件的適應性和穩健性。

##### **CarMem: Enhancing Long-Term Memory in LLM Voice Assistants through Category-Bounding**
2501.09645v1 by Johannes Kirmayr, Lukas Stappen, Phillip Schneider, Florian Matthes, Elisabeth André

In today's assistant landscape, personalisation enhances interactions,
fosters long-term relationships, and deepens engagement. However, many systems
struggle with retaining user preferences, leading to repetitive user requests
and disengagement. Furthermore, the unregulated and opaque extraction of user
preferences in industry applications raises significant concerns about privacy
and trust, especially in regions with stringent regulations like Europe. In
response to these challenges, we propose a long-term memory system for voice
assistants, structured around predefined categories. This approach leverages
Large Language Models to efficiently extract, store, and retrieve preferences
within these categories, ensuring both personalisation and transparency. We
also introduce a synthetic multi-turn, multi-session conversation dataset
(CarMem), grounded in real industry data, tailored to an in-car voice assistant
setting. Benchmarked on the dataset, our system achieves an F1-score of .78 to
.95 in preference extraction, depending on category granularity. Our
maintenance strategy reduces redundant preferences by 95% and contradictory
ones by 92%, while the accuracy of optimal retrieval is at .87. Collectively,
the results demonstrate the system's suitability for industrial applications.

摘要：在現今的助理領域中，個人化增強互動，促進長期關係，並加深參與。然而，許多系統在保留使用者偏好上遇到困難，導致重複的使用者要求和脫離。此外，產業應用中對使用者偏好的不受規範且不透明的提取引發了對隱私和信任的重大疑慮，特別是在像歐洲這樣法規嚴格的地區。為了應對這些挑戰，我們為語音助理提出了一個長期記憶系統，其結構圍繞預定義的類別。這種方法利用大型語言模型在這些類別中有效提取、儲存和檢索偏好，確保個人化和透明度。我們還引入了一個合成多輪、多會話對話資料集 (CarMem)，其基礎是真實的產業資料，專門用於車載語音助理設定。在資料集上進行基準測試後，我們的系統在偏好提取中取得了 .78 到 .95 的 F1 分數，具體取決於類別粒度。我們的維護策略將重複的偏好減少了 95%，將矛盾的偏好減少了 92%，而最佳檢索的準確度為 .87。總的來說，這些結果證明了該系統適用於產業應用。

##### **Electronic Health Records: Towards Digital Twins in Healthcare**
2501.09640v1 by Muhammet Alkan, Hester Huijsdens, Yola Jones, Fani Deligianni

The pivotal shift from traditional paper-based records to sophisticated
Electronic Health Records (EHR), enabled systematic collection and analysis of
patient data through descriptive statistics, providing insight into patterns
and trends across patient populations. This evolution continued toward
predictive analytics, allowing healthcare providers to anticipate patient
outcomes and potential complications before they occur. This progression from
basic digital record-keeping to sophisticated predictive modelling and digital
twins reflects healthcare's broader evolution toward more integrated,
patient-centred approaches that combine data-driven insights with personalized
care delivery. This chapter explores the evolution and significance of
healthcare information systems, beginning with an examination of the
implementation of EHR in the UK and the USA. It provides a comprehensive
overview of the International Classification of Diseases (ICD) system, tracing
its development from ICD-9 to ICD-10. Central to this discussion is the
MIMIC-III database, a landmark achievement in healthcare data sharing and
arguably the most comprehensive critical care database freely available to
researchers worldwide. MIMIC-III has democratized access to high-quality
healthcare data, enabling unprecedented opportunities for research and
analysis. The chapter examines its structure, clinical outcome analysis
capabilities, and practical applications through case studies, with a
particular focus on mortality and length of stay metrics, vital signs
extraction, and ICD coding. Through detailed entity-relationship diagrams and
practical examples, the text illustrates MIMIC's complex data structure and
demonstrates how different querying approaches can lead to subtly different
results, emphasizing the critical importance of understanding the database's
architecture for accurate data extraction.

摘要：從傳統紙本記錄轉變為先進的電子健康記錄（EHR），促使透過描述性統計系統性地收集和分析病患資料，進而深入了解病患族群的模式和趨勢。這項演進持續朝向預測分析發展，讓醫療保健提供者能夠在病患出現結果和潛在併發症之前預測這些狀況。從基本的數位記錄保存進展到先進的預測模型和數位雙胞胎，反映了醫療保健朝向更整合、以病患為中心的做法所做的更廣泛演進，這些做法結合了資料驅動的見解與個人化照護服務。本章探討醫療保健資訊系統的演進和重要性，從審查英國和美國實施 EHR 開始。它提供了疾病國際分類（ICD）系統的全面概述，追溯其從 ICD-9 發展到 ICD-10 的過程。此討論的核心是 MIMIC-III 資料庫，這是醫療保健資料共享的一項里程碑式成就，可以說是全球研究人員可以免費取得的最全面的重症照護資料庫。MIMIC-III 民主化了對高品質醫療保健資料的存取，為研究和分析創造了前所未有的機會。本章透過案例研究探討其結構、臨床結果分析能力和實際應用，特別關注死亡率和住院時間指標、生命徵象萃取和 ICD 編碼。透過詳細的實體關係圖和實務範例，本文說明了 MIMIC 複雜的資料結構，並展示了不同的查詢方法如何導致細微不同的結果，強調了了解資料庫架構對於準確萃取資料至關重要的重要性。

##### **Platform-Aware Mission Planning**
2501.09632v1 by Stefan Panjkovic, Alessandro Cimatti, Andrea Micheli, Stefano Tonetta

Planning for autonomous systems typically requires reasoning with models at
different levels of abstraction, and the harmonization of two competing sets of
objectives: high-level mission goals that refer to an interaction of the system
with the external environment, and low-level platform constraints that aim to
preserve the integrity and the correct interaction of the subsystems. The
complicated interplay between these two models makes it very hard to reason on
the system as a whole, especially when the objective is to find plans with
robustness guarantees, considering the non-deterministic behavior of the lower
layers of the system.
  In this paper, we introduce the problem of Platform-Aware Mission Planning
(PAMP), addressing it in the setting of temporal durative actions. The PAMP
problem differs from standard temporal planning for its exists-forall nature:
the high-level plan dealing with mission goals is required to satisfy safety
and executability constraints, for all the possible non-deterministic
executions of the low-level model of the platform and the environment. We
propose two approaches for solving PAMP. The first baseline approach
amalgamates the mission and platform levels, while the second is based on an
abstraction-refinement loop that leverages the combination of a planner and a
verification engine. We prove the soundness and completeness of the proposed
approaches and validate them experimentally, demonstrating the importance of
heterogeneous modeling and the superiority of the technique based on
abstraction-refinement.

摘要：<paragraph>規劃自主系統通常需要使用不同抽象層級的模型進行推理，以及調和兩組相互競爭的目標：指的是系統與外部環境互動的高層級任務目標，以及旨在保留子系統的完整性和正確互動的低層級平台約束。這兩種模型之間複雜的交互作用使得很難對系統整體進行推理，特別是在目標是找出具有穩健性保證的計畫時，考慮到系統較低層級的非確定性行為。
在本論文中，我們介紹了平台感知任務規劃 (PAMP) 的問題，並在時間持續動作的設定中加以解決。PAMP 問題與標準時間規劃不同，在於其存在forall性質：處理任務目標的高層級計畫必須滿足所有平台和環境的低層級模型可能非確定性執行的情況下的安全性和可執行性約束。我們提出了兩種解決 PAMP 的方法。第一種基線方法合併任務和平台層級，而第二種方法基於一個抽象精煉迴圈，該迴圈利用規劃器和驗證引擎的組合。我們證明了所提出的方法的健全性和完整性，並透過實驗驗證它們，證明了異質建模的重要性以及基於抽象精煉的技術的優越性。</paragraph>

##### **Artificial Intelligence-Driven Clinical Decision Support Systems**
2501.09628v1 by Muhammet Alkan, Idris Zakariyya, Samuel Leighton, Kaushik Bhargav Sivangi, Christos Anagnostopoulos, Fani Deligianni

As artificial intelligence (AI) becomes increasingly embedded in healthcare
delivery, this chapter explores the critical aspects of developing reliable and
ethical Clinical Decision Support Systems (CDSS). Beginning with the
fundamental transition from traditional statistical models to sophisticated
machine learning approaches, this work examines rigorous validation strategies
and performance assessment methods, including the crucial role of model
calibration and decision curve analysis. The chapter emphasizes that creating
trustworthy AI systems in healthcare requires more than just technical
accuracy; it demands careful consideration of fairness, explainability, and
privacy. The challenge of ensuring equitable healthcare delivery through AI is
stressed, discussing methods to identify and mitigate bias in clinical
predictive models. The chapter then delves into explainability as a cornerstone
of human-centered CDSS. This focus reflects the understanding that healthcare
professionals must not only trust AI recommendations but also comprehend their
underlying reasoning. The discussion advances in an analysis of privacy
vulnerabilities in medical AI systems, from data leakage in deep learning
models to sophisticated attacks against model explanations. The text explores
privacy-preservation strategies such as differential privacy and federated
learning, while acknowledging the inherent trade-offs between privacy
protection and model performance. This progression, from technical validation
to ethical considerations, reflects the multifaceted challenges of developing
AI systems that can be seamlessly and reliably integrated into daily clinical
practice while maintaining the highest standards of patient care and data
protection.

摘要：隨著人工智慧 (AI) 在醫療保健中的應用日益普及，本章探討了開發可靠且符合道德標準的臨床決策支援系統 (CDSS) 的關鍵面向。從傳統統計模型到複雜機器學習方法的基本轉變開始，這項工作審查了嚴謹的驗證策略和效能評估方法，包括模型校準和決策曲線分析的關鍵角色。本章強調，在醫療保健中建立值得信賴的 AI 系統不只是技術上的準確性；它需要仔細考量公平性、可解釋性和隱私權。本章強調了透過 AI 確保公平的醫療保健服務的挑戰，並討論了識別和減輕臨床預測模型中偏差的方法。接著，本章深入探討可解釋性，作為以人為中心的 CDSS 的基石。這種關注反映了醫療保健專業人員不僅必須信任 AI 建議，還必須理解其背後的推理。討論進一步分析了醫療 AI 系統中的隱私漏洞，從深度學習模型中的資料外洩到針對模型解釋的複雜攻擊。本文探討了隱私保護策略，例如差分隱私和聯合學習，同時承認隱私保護和模型效能之間的固有取捨。這種從技術驗證到道德考量的進展，反映了開發 AI 系統的多面向挑戰，這些系統可以無縫且可靠地整合到日常臨床實務中，同時維持最高的病患照護和資料保護標準。

##### **Sentiment Analysis in Twitter Social Network Centered on Cryptocurrencies Using Machine Learning**
2501.09777v1 by Vahid Amiri, Mahmood Ahmadi

Cryptocurrency is a digital currency that uses blockchain technology with
secure encryption. Due to the decentralization of these currencies, traditional
monetary systems and the capital market of each they, can influence a society.
Therefore, due to the importance of the issue, the need to understand public
opinion and analyze people's opinions in this regard increases. To understand
the opinions and views of people about different topics, you can take help from
social networks because they are a rich source of opinions. The Twitter social
network is one of the main platforms where users discuss various topics,
therefore, in the shortest time and with the lowest cost, the opinion of the
community can be measured on this social network. Twitter Sentiment Analysis
(TSA) is a field that analyzes the sentiment expressed in tweets. Considering
that most of TSA's research efforts on cryptocurrencies are focused on English
language, the purpose of this paper is to investigate the opinions of Iranian
users on the Twitter social network about cryptocurrencies and provide the best
model for classifying tweets based on sentiment. In the case of automatic
analysis of tweets, managers and officials in the field of economy can gain
knowledge from the general public's point of view about this issue and use the
information obtained in order to properly manage this phenomenon. For this
purpose, in this paper, in order to build emotion classification models,
natural language processing techniques such as bag of words (BOW) and FastText
for text vectorization and classical machine learning algorithms including KNN,
SVM and Adaboost learning methods Deep including LSTM and BERT model were used
for classification, and finally BERT linguistic model had the best accuracy
with 83.50%.

摘要：<paragraph>加密貨幣是一種使用區塊鏈技術並具備安全加密功能的數位貨幣。由於這些貨幣的去中心化，傳統的貨幣系統和各個國家的資本市場都可能對社會造成影響。因此，由於這個問題的重要性，了解公眾輿論和分析人們在這方面的意見的需求也隨之增加。要了解人們對不同主題的意見和觀點，可以從社群網路中尋求協助，因為它們是意見的豐富來源。Twitter 社群網路是使用者討論各種主題的主要平台之一，因此，在最短的時間內並以最低的成本，可以在這個社群網路中衡量社群的意見。Twitter 情緒分析 (TSA) 是分析推文中表達的情緒的領域。考量到 TSA 對加密貨幣的大部分研究工作都集中在英語，因此本文的目的是調查伊朗使用者在 Twitter 社群網路中對加密貨幣的看法，並提供用於根據情緒分類推文的最佳模型。在自動分析推文的情況下，經濟領域的管理人員和官員可以從一般民眾的觀點中獲取有關此問題的知識，並利用所獲得的資訊來適當管理這種現象。為了這個目的，本文中，為了建立情緒分類模型，使用了自然語言處理技術，例如詞袋 (BOW) 和 FastText，用於文字向量化和經典機器學習演算法，包括 KNN、SVM 和 Adaboost 學習方法，包括 LSTM 和 BERT 模型在內的深度學習用於分類，最後 BERT 語言模型以 83.50% 的準確率獲得最佳準確度。</paragraph>

##### **Beyond Reward Hacking: Causal Rewards for Large Language Model Alignment**
2501.09620v1 by Chaoqi Wang, Zhuokai Zhao, Yibo Jiang, Zhaorun Chen, Chen Zhu, Yuxin Chen, Jiayi Liu, Lizhu Zhang, Xiangjun Fan, Hao Ma, Sinong Wang

Recent advances in large language models (LLMs) have demonstrated significant
progress in performing complex tasks. While Reinforcement Learning from Human
Feedback (RLHF) has been effective in aligning LLMs with human preferences, it
is susceptible to spurious correlations in reward modeling. Consequently, it
often introduces biases-such as length bias, sycophancy, conceptual bias, and
discrimination that hinder the model's ability to capture true causal
relationships. To address this, we propose a novel causal reward modeling
approach that integrates causal inference to mitigate these spurious
correlations. Our method enforces counterfactual invariance, ensuring reward
predictions remain consistent when irrelevant variables are altered. Through
experiments on both synthetic and real-world datasets, we show that our
approach mitigates various types of spurious correlations effectively,
resulting in more reliable and fair alignment of LLMs with human preferences.
As a drop-in enhancement to the existing RLHF workflow, our causal reward
modeling provides a practical way to improve the trustworthiness and fairness
of LLM finetuning.

摘要：大型語言模型 (LLM) 的最新進展已證明在執行複雜任務方面取得顯著進展。雖然人類回饋強化學習 (RLHF) 已有效地將 LLM 與人類偏好保持一致，但它容易受到獎勵建模中的虛假相關性影響。因此，它常常會引入偏差，例如長度偏差、阿諛奉承、概念偏差和歧視，這些偏差會阻礙模型捕捉真實因果關係的能力。為了解決這個問題，我們提出了一種新穎的因果獎勵建模方法，它整合了因果推理來減輕這些虛假相關性。我們的模型強制執行反事實不變性，確保在改變無關變數時獎勵預測保持一致。透過在合成和真實世界資料集上進行實驗，我們證明了我們的模型有效減輕了各種類型的虛假相關性，從而更可靠、更公平地將 LLM 與人類偏好保持一致。作為對現有 RLHF 工作流程的直接增強，我們的因果獎勵建模提供了一種實用的方法來提升 LLM 微調的可信度和公平性。

##### **Metric Learning with Progressive Self-Distillation for Audio-Visual Embedding Learning**
2501.09608v1 by Donghuo Zeng, Kazushi Ikeda

Metric learning projects samples into an embedded space, where similarities
and dissimilarities are quantified based on their learned representations.
However, existing methods often rely on label-guided representation learning,
where representations of different modalities, such as audio and visual data,
are aligned based on annotated labels. This approach tends to underutilize
latent complex features and potential relationships inherent in the
distributions of audio and visual data that are not directly tied to the
labels, resulting in suboptimal performance in audio-visual embedding learning.
To address this issue, we propose a novel architecture that integrates
cross-modal triplet loss with progressive self-distillation. Our method
enhances representation learning by leveraging inherent distributions and
dynamically refining soft audio-visual alignments -- probabilistic alignments
between audio and visual data that capture the inherent relationships beyond
explicit labels. Specifically, the model distills audio-visual
distribution-based knowledge from annotated labels in a subset of each batch.
This self-distilled knowledge is used t

摘要：度量学习项目样本到一个嵌入空间中，其中相似性和相异性基于学习到的表示进行量化。
然而，现有方法通常依赖于标签指导表示学习，其中不同模态（如音频和视觉数据）的表示基于注释标签对齐。这种方法往往低估了潜在的复杂特征和音频和视觉数据分布中固有的潜在关系，这些关系与标签没有直接联系，导致音频视觉嵌入学习的性能不佳。
为了解决这个问题，我们提出了一种新的架构，它将跨模态三元损失与渐进式自蒸馏相结合。我们的方法通过利用固有分布和动态细化软音频视觉对齐来增强表示学习——音频和视觉数据之间的概率对齐，捕获了超出显式标签的固有关系。具体来说，该模型从每个批次的一个子集中的注释标签中提取基于音频视觉分布的知识。这种自蒸馏知识用于 t

##### **From Scarcity to Capability: Empowering Fake News Detection in Low-Resource Languages with LLMs**
2501.09604v1 by Hrithik Majumdar Shibu, Shrestha Datta, Md. Sumon Miah, Nasrullah Sami, Mahruba Sharmin Chowdhury, Md. Saiful Islam

The rapid spread of fake news presents a significant global challenge,
particularly in low-resource languages like Bangla, which lack adequate
datasets and detection tools. Although manual fact-checking is accurate, it is
expensive and slow to prevent the dissemination of fake news. Addressing this
gap, we introduce BanFakeNews-2.0, a robust dataset to enhance Bangla fake news
detection. This version includes 11,700 additional, meticulously curated fake
news articles validated from credible sources, creating a proportional dataset
of 47,000 authentic and 13,000 fake news items across 13 categories. In
addition, we created a manually curated independent test set of 460 fake and
540 authentic news items for rigorous evaluation. We invest efforts in
collecting fake news from credible sources and manually verified while
preserving the linguistic richness. We develop a benchmark system utilizing
transformer-based architectures, including fine-tuned Bidirectional Encoder
Representations from Transformers variants (F1-87\%) and Large Language Models
with Quantized Low-Rank Approximation (F1-89\%), that significantly outperforms
traditional methods. BanFakeNews-2.0 offers a valuable resource to advance
research and application in fake news detection for low-resourced languages. We
publicly release our dataset and model on Github to foster research in this
direction.

摘要：假新聞快速散播已成為全球性的重大挑戰，特別是在孟加拉語等資源貧乏的語言中，因為缺乏適當的資料集和偵測工具。儘管手動查證事實非常準確，但它昂貴且緩慢，無法有效防止假新聞散播。為了解決這個問題，我們推出了 BanFakeNews-2.0，一個強大的資料集，用於增強孟加拉語假新聞偵測。此版本包含 11,700 篇經過精心策劃的額外假新聞文章，並從可信來源驗證，建立了一個包含 13 個類別的 47,000 篇真實新聞和 13,000 篇假新聞的比例資料集。此外，我們還建立了一個手動策劃的獨立測試集，包含 460 篇假新聞和 540 篇真實新聞，用於嚴格評估。我們投入大量心力從可信來源收集假新聞，並在保留語言豐富性的同時進行手動驗證。我們開發了一個基準系統，利用基於Transformer的架構，包括微調的 Transformer 編碼器表示（F1-87%）和具有量化低秩近似的語言模型（F1-89%），其效能顯著優於傳統方法。BanFakeNews-2.0 為低資源語言的假新聞偵測研究和應用提供了寶貴的資源。我們在 Github 上公開發布我們的資料集和模型，以促進這方面的研究。

##### **Reducing the Sensitivity of Neural Physics Simulators to Mesh Topology via Pretraining**
2501.09597v1 by Nathan Vaska, Justin Goodwin, Robin Walters, Rajmonda S. Caceres

Meshes are used to represent complex objects in high fidelity physics
simulators across a variety of domains, such as radar sensing and aerodynamics.
There is growing interest in using neural networks to accelerate physics
simulations, and also a growing body of work on applying neural networks
directly to irregular mesh data. Since multiple mesh topologies can represent
the same object, mesh augmentation is typically required to handle topological
variation when training neural networks. Due to the sensitivity of physics
simulators to small changes in mesh shape, it is challenging to use these
augmentations when training neural network-based physics simulators. In this
work, we show that variations in mesh topology can significantly reduce the
performance of neural network simulators. We evaluate whether pretraining can
be used to address this issue, and find that employing an established
autoencoder pretraining technique with graph embedding models reduces the
sensitivity of neural network simulators to variations in mesh topology.
Finally, we highlight future research directions that may further reduce neural
simulator sensitivity to mesh topology.

摘要：網格用於在各種領域中以高保真物理模擬器表示複雜的物件，例如雷達感測和空氣動力學。
對於使用神經網路來加速物理模擬的興趣與日俱增，而且也越來越多關於將神經網路直接應用於不規則網格資料的研究。由於多個網格拓撲可以表示相同的物件，因此在訓練神經網路時通常需要網格擴充來處理拓撲變化。由於物理模擬器對網格形狀的微小變化很敏感，因此在訓練基於神經網路的物理模擬器時使用這些擴充很具有挑戰性。在這項工作中，我們展示了網格拓撲的變化會顯著降低神經網路模擬器的效能。我們評估了預訓練是否可用於解決此問題，並發現採用已建立的自動編碼器預訓練技術與圖形嵌入模型會降低神經網路模擬器對網格拓撲變化的敏感性。最後，我們重點說明了未來可能進一步降低神經模擬器對網格拓撲敏感性的研究方向。

##### **MatrixNet: Learning over symmetry groups using learned group representations**
2501.09571v1 by Lucas Laird, Circe Hsu, Asilata Bapat, Robin Walters

Group theory has been used in machine learning to provide a theoretically
grounded approach for incorporating known symmetry transformations in tasks
from robotics to protein modeling. In these applications, equivariant neural
networks use known symmetry groups with predefined representations to learn
over geometric input data. We propose MatrixNet, a neural network architecture
that learns matrix representations of group element inputs instead of using
predefined representations. MatrixNet achieves higher sample efficiency and
generalization over several standard baselines in prediction tasks over the
several finite groups and the Artin braid group. We also show that MatrixNet
respects group relations allowing generalization to group elements of greater
word length than in the training set.

摘要：群論已用於機器學習，以提供一個理論性的基礎方法，用於在從機器人技術到蛋白質建模的任務中納入已知的對稱轉換。在這些應用中，等變神經網路使用已知的對稱群和預定義的表示，以學習幾何輸入數據。我們提出 MatrixNet，這是一種神經網路架構，它學習群元素輸入的矩陣表示，而不是使用預定義的表示。MatrixNet 在預測任務中對幾個標準基準線實現了更高的樣本效率和概括，這些任務涉及幾個有限群和 Artin 編織群。我們還表明，MatrixNet 尊重群關係，允許對比訓練集中詞長更大的群元素進行概括。

##### **Stylomech: Unveiling Authorship via Computational Stylometry in English and Romanized Sinhala**
2501.09561v1 by Nabeelah Faumi, Adeepa Gunathilake, Benura Wickramanayake, Deelaka Dias, TGDK Sumanathilaka

With the advent of Web 2.0, the development in social technology coupled with
global communication systematically brought positive and negative impacts to
society. Copyright claims and Author identification are deemed crucial as there
has been a considerable amount of increase in content violation owing to the
lack of proper ethics in society. The Author's attribution in both English and
Romanized Sinhala became a major requirement in the last few decades. As an
area largely unexplored, particularly within the context of Romanized Sinhala,
the research contributes significantly to the field of computational
linguistics. The proposed author attribution system offers a unique approach,
allowing for the comparison of only two sets of text: suspect author and
anonymous text, a departure from traditional methodologies which often rely on
larger corpora. This work focuses on using the numerical representation of
various pairs of the same and different authors allowing for, the model to
train on these representations as opposed to text, this allows for it to apply
to a multitude of authors and contexts, given that the suspected author text,
and the anonymous text are of reasonable quality. By expanding the scope of
authorship attribution to encompass diverse linguistic contexts, the work
contributes to fostering trust and accountability in digital communication,
especially in Sri Lanka. This research presents a pioneering approach to author
attribution in both English and Romanized Sinhala, addressing a critical need
for content verification and intellectual property rights enforcement in the
digital age.

摘要：隨著 Web 2.0 的出現，社交技術的發展與全球溝通系統性地為社會帶來正面和負面的影響。由於社會缺乏適當的道德規範，版權聲明和作者身分識別被視為至關重要，因為內容侵權事件大幅增加。在過去幾十年，作者在英文和羅馬化僧伽羅語中的署名已成為一項重要要求。作為一個尚未廣泛探索的領域，特別是在羅馬化僧伽羅語的脈絡中，這項研究對計算語言學領域做出了重大貢獻。所提出的作者署名系統提供了一種獨特的方法，允許僅比較兩組文本：可疑作者和匿名文本，這與傳統方法不同，傳統方法通常依賴於更大的語料庫。這項工作專注於使用相同和不同作者的各種配對的數字表示，允許模型在這些表示上進行訓練，而不是文本，這允許它應用於大量作者和脈絡，假設可疑作者文本和匿名文本具有合理的品質。透過擴大作者署名的範圍，涵蓋不同的語言脈絡，這項工作有助於培養數位溝通中的信任和責任感，特別是在斯里蘭卡。這項研究提出了一種在英文和羅馬化僧伽羅語中進行作者署名的先驅方法，滿足了數位時代對內容驗證和智慧財產權執行的迫切需求。

