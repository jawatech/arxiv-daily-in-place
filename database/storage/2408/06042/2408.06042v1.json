{"2408.06042": {"publish_time": "2024-08-12", "title": "Understanding Byzantine Robustness in Federated Learning with A Black-box Server", "paper_summary": "Federated learning (FL) becomes vulnerable to Byzantine attacks where some of\nparticipators tend to damage the utility or discourage the convergence of the\nlearned model via sending their malicious model updates. Previous works propose\nto apply robust rules to aggregate updates from participators against different\ntypes of Byzantine attacks, while at the same time, attackers can further\ndesign advanced Byzantine attack algorithms targeting specific aggregation rule\nwhen it is known. In practice, FL systems can involve a black-box server that\nmakes the adopted aggregation rule inaccessible to participants, which can\nnaturally defend or weaken some Byzantine attacks. In this paper, we provide an\nin-depth understanding on the Byzantine robustness of the FL system with a\nblack-box server. Our investigation demonstrates the improved Byzantine\nrobustness of a black-box server employing a dynamic defense strategy. We\nprovide both empirical evidence and theoretical analysis to reveal that the\nblack-box server can mitigate the worst-case attack impact from a maximum level\nto an expectation level, which is attributed to the inherent inaccessibility\nand randomness offered by a black-box server.The source code is available at\nhttps://github.com/alibaba/FederatedScope/tree/Byzantine_attack_defense to\npromote further research in the community.", "paper_summary_zh": "\u8054\u90a6\u5b66\u4e60 (FL) \u5bb9\u6613\u906d\u53d7\u62dc\u5360\u5ead\u653b\u51fb\uff0c\u5728\u62dc\u5360\u5ead\u653b\u51fb\u4e2d\uff0c\u4e00\u4e9b\u53c2\u4e0e\u8005\u503e\u5411\u4e8e\u901a\u8fc7\u53d1\u9001\u5176\u6076\u610f\u6a21\u578b\u66f4\u65b0\u6765\u7834\u574f\u6548\u7528\u6216\u963b\u6b62\u5b66\u4e60\u6a21\u578b\u7684\u6536\u655b\u3002\u4ee5\u524d\u7684\u5de5\u4f5c\u63d0\u51fa\u5e94\u7528\u7a33\u5065\u89c4\u5219\u6765\u805a\u5408\u53c2\u4e0e\u8005\u9488\u5bf9\u4e0d\u540c\u7c7b\u578b\u7684\u62dc\u5360\u5ead\u653b\u51fb\u7684\u66f4\u65b0\uff0c\u540c\u65f6\uff0c\u653b\u51fb\u8005\u53ef\u4ee5\u8fdb\u4e00\u6b65\u8bbe\u8ba1\u9ad8\u7ea7\u62dc\u5360\u5ead\u653b\u51fb\u7b97\u6cd5\uff0c\u5728\u5df2\u77e5\u7684\u60c5\u51b5\u4e0b\u9488\u5bf9\u7279\u5b9a\u7684\u805a\u5408\u89c4\u5219\u3002\u5728\u5b9e\u8df5\u4e2d\uff0cFL \u7cfb\u7edf\u53ef\u4ee5\u6d89\u53ca\u4e00\u4e2a\u9ed1\u76d2\u670d\u52a1\u5668\uff0c\u8be5\u670d\u52a1\u5668\u4f7f\u53c2\u4e0e\u8005\u65e0\u6cd5\u8bbf\u95ee\u6240\u91c7\u7528\u7684\u805a\u5408\u89c4\u5219\uff0c\u8fd9\u53ef\u4ee5\u81ea\u7136\u5730\u9632\u5fa1\u6216\u524a\u5f31\u4e00\u4e9b\u62dc\u5360\u5ead\u653b\u51fb\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u4eec\u5bf9\u5177\u6709\u9ed1\u76d2\u670d\u52a1\u5668\u7684 FL \u7cfb\u7edf\u7684\u62dc\u5360\u5ead\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u6df1\u5165\u7684\u7406\u89e3\u3002\u6211\u4eec\u7684\u8c03\u67e5\u8bc1\u660e\u4e86\u91c7\u7528\u52a8\u6001\u9632\u5fa1\u7b56\u7565\u7684\u9ed1\u76d2\u670d\u52a1\u5668\u7684\u62dc\u5360\u5ead\u9c81\u68d2\u6027\u5f97\u5230\u4e86\u63d0\u9ad8\u3002\u6211\u4eec\u63d0\u4f9b\u4e86\u7ecf\u9a8c\u8bc1\u636e\u548c\u7406\u8bba\u5206\u6790\u6765\u63ed\u793a\u9ed1\u76d2\u670d\u52a1\u5668\u53ef\u4ee5\u5c06\u6700\u574f\u60c5\u51b5\u4e0b\u7684\u653b\u51fb\u5f71\u54cd\u4ece\u6700\u5927\u7ea7\u522b\u964d\u4f4e\u5230\u671f\u671b\u7ea7\u522b\uff0c\u8fd9\u5f52\u56e0\u4e8e\u9ed1\u76d2\u670d\u52a1\u5668\u56fa\u6709\u7684\u4e0d\u53ef\u8bbf\u95ee\u6027\u548c\u968f\u673a\u6027\u3002\u6e90\u4ee3\u7801\u53ef\u5728 https://github.com/alibaba/FederatedScope/tree/Byzantine_attack_defense \u83b7\u5f97\uff0c\u4ee5\u4fc3\u8fdb\u793e\u533a\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u3002", "author": "Fangyuan Zhao et.al.", "authors": "Fangyuan Zhao, Yuexiang Xie, Xuebin Ren, Bolin Ding, Shusen Yang, Yaliang Li", "id": "2408.06042v1", "paper_url": "http://arxiv.org/abs/2408.06042v1", "repo": "https://github.com/alibaba/federatedscope"}}