{"2408.00523": {"publish_time": "2024-08-01", "title": "Jailbreaking Text-to-Image Models with LLM-Based Agents", "paper_summary": "Recent advancements have significantly improved automated task-solving\ncapabilities using autonomous agents powered by large language models (LLMs).\nHowever, most LLM-based agents focus on dialogue, programming, or specialized\ndomains, leaving gaps in addressing generative AI safety tasks. These gaps are\nprimarily due to the challenges posed by LLM hallucinations and the lack of\nclear guidelines. In this paper, we propose Atlas, an advanced LLM-based\nmulti-agent framework that integrates an efficient fuzzing workflow to target\ngenerative AI models, specifically focusing on jailbreak attacks against\ntext-to-image (T2I) models with safety filters. Atlas utilizes a\nvision-language model (VLM) to assess whether a prompt triggers the T2I model's\nsafety filter. It then iteratively collaborates with both LLM and VLM to\ngenerate an alternative prompt that bypasses the filter. Atlas also enhances\nthe reasoning abilities of LLMs in attack scenarios by leveraging multi-agent\ncommunication, in-context learning (ICL) memory mechanisms, and the\nchain-of-thought (COT) approach. Our evaluation demonstrates that Atlas\nsuccessfully jailbreaks several state-of-the-art T2I models in a black-box\nsetting, which are equipped with multi-modal safety filters. In addition, Atlas\noutperforms existing methods in both query efficiency and the quality of the\ngenerated images.", "paper_summary_zh": "<paragraph>\u6700\u8fd1\u7684\u9032\u5c55\u5df2\u7d93\u5927\u5e45\u6539\u9032\u4e86\u81ea\u52d5\u4efb\u52d9\u89e3\u6c7a\u80fd\u529b\uff0c\u4f7f\u7528\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08LLM\uff09\u9a45\u52d5\u7684\u81ea\u4e3b\u4ee3\u7406\u3002\u7136\u800c\uff0c\u5927\u591a\u6578\u57fa\u65bc LLM \u7684\u4ee3\u7406\u5c08\u6ce8\u65bc\u5c0d\u8a71\u3001\u7a0b\u5f0f\u8a2d\u8a08\u6216\u5c08\u696d\u9818\u57df\uff0c\u5728\u89e3\u6c7a\u751f\u6210\u5f0f AI \u5b89\u5168\u4efb\u52d9\u65b9\u9762\u7559\u4e0b\u4e86\u7a7a\u767d\u3002\u9019\u4e9b\u7a7a\u767d\u4e3b\u8981\u662f\u7531\u65bc LLM \u5e7b\u89ba\u5e36\u4f86\u7684\u6311\u6230\u548c\u7f3a\u4e4f\u660e\u78ba\u7684\u6307\u5c0e\u65b9\u91dd\u3002\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u63d0\u51fa Atlas\uff0c\u4e00\u500b\u57fa\u65bc LLM \u7684\u5148\u9032\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u5b83\u6574\u5408\u4e86\u4e00\u500b\u9ad8\u6548\u7684\u6a21\u7cca\u6e2c\u8a66\u5de5\u4f5c\u6d41\u7a0b\u4f86\u91dd\u5c0d\u751f\u6210\u5f0f AI \u6a21\u578b\uff0c\u7279\u5225\u95dc\u6ce8\u5c0d\u5177\u6709\u5b89\u5168\u904e\u6ffe\u5668\u7684\u6587\u5b57\u5230\u5716\u50cf\uff08T2I\uff09\u6a21\u578b\u7684\u8d8a\u7344\u653b\u64ca\u3002Atlas \u5229\u7528\u8996\u89ba\u8a9e\u8a00\u6a21\u578b\uff08VLM\uff09\u4f86\u8a55\u4f30\u63d0\u793a\u662f\u5426\u89f8\u767c\u4e86 T2I \u6a21\u578b\u7684\u5b89\u5168\u904e\u6ffe\u5668\u3002\u7136\u5f8c\uff0c\u5b83\u8207 LLM \u548c VLM \u9032\u884c\u53cd\u8986\u5354\u4f5c\uff0c\u4ee5\u751f\u6210\u4e00\u500b\u7e5e\u904e\u904e\u6ffe\u5668\u7684\u66ff\u4ee3\u63d0\u793a\u3002Atlas \u9084\u901a\u904e\u5229\u7528\u591a\u4ee3\u7406\u901a\u4fe1\u3001\u60c5\u5883\u5b78\u7fd2\uff08ICL\uff09\u8a18\u61b6\u6a5f\u5236\u548c\u601d\u7dad\u93c8\uff08COT\uff09\u65b9\u6cd5\uff0c\u589e\u5f37\u4e86 LLM \u5728\u653b\u64ca\u5834\u666f\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u3002\u6211\u5011\u7684\u8a55\u4f30\u8868\u660e\uff0cAtlas \u5728\u9ed1\u76d2\u8a2d\u7f6e\u4e2d\u6210\u529f\u8d8a\u7344\u4e86\u5e7e\u500b\u6700\u5148\u9032\u7684 T2I \u6a21\u578b\uff0c\u9019\u4e9b\u6a21\u578b\u914d\u5099\u4e86\u591a\u6a21\u5f0f\u5b89\u5168\u904e\u6ffe\u5668\u3002\u6b64\u5916\uff0cAtlas \u5728\u67e5\u8a62\u6548\u7387\u548c\u751f\u6210\u5716\u50cf\u7684\u54c1\u8cea\u65b9\u9762\u90fd\u512a\u65bc\u73fe\u6709\u65b9\u6cd5\u3002</paragraph>", "author": "Yingkai Dong et.al.", "authors": "Yingkai Dong, Zheng Li, Xiangtao Meng, Ning Yu, Shanqing Guo", "id": "2408.00523v1", "paper_url": "http://arxiv.org/abs/2408.00523v1", "repo": "null"}}