{"2408.11796": {"publish_time": "2024-08-21", "title": "LLM Pruning and Distillation in Practice: The Minitron Approach", "paper_summary": "We present a comprehensive report on compressing the Llama 3.1 8B and Mistral\nNeMo 12B models to 4B and 8B parameters, respectively, using pruning and\ndistillation. We explore two distinct pruning strategies: (1) depth pruning and\n(2) joint hidden/attention/MLP (width) pruning, and evaluate the results on\ncommon benchmarks from the LM Evaluation Harness. The models are then aligned\nwith NeMo Aligner and tested in instruct-tuned versions. This approach produces\na compelling 4B model from Llama 3.1 8B and a state-of-the-art\nMistral-NeMo-Minitron-8B (MN-Minitron-8B for brevity) model from Mistral NeMo\n12B. We found that with no access to the original data, it is beneficial to\nslightly fine-tune teacher models on the distillation dataset. We open-source\nour base model weights on Hugging Face with a permissive license.", "paper_summary_zh": "\u6211\u5011\u63d0\u51fa\u4e86\u4e00\u4efd\u95dc\u65bc\u4f7f\u7528\u526a\u679d\u548c\u77e5\u8b58\u84b8\u993e\u5c07 Llama 3.1 8B \u548c Mistral NeMo 12B \u6a21\u578b\u5206\u5225\u58d3\u7e2e\u5230 4B \u548c 8B \u53c3\u6578\u7684\u7d9c\u5408\u5831\u544a\u3002\u6211\u5011\u63a2\u8a0e\u4e86\u5169\u7a2e\u4e0d\u540c\u7684\u526a\u679d\u7b56\u7565\uff1a(1) \u6df1\u5ea6\u526a\u679d\u548c (2) \u806f\u5408\u96b1\u85cf/\u6ce8\u610f\u529b/MLP (\u5bec\u5ea6) \u526a\u679d\uff0c\u4e26\u5728 LM \u8a55\u4f30\u5de5\u5177\u5305\u7684\u5e38\u898b\u57fa\u6e96\u4e0a\u8a55\u4f30\u7d50\u679c\u3002\u7136\u5f8c\u4f7f\u7528 NeMo Aligner \u5c0d\u9f4a\u6a21\u578b\uff0c\u4e26\u5728\u7d93\u904e\u5fae\u8abf\u7684\u7248\u672c\u4e2d\u9032\u884c\u6e2c\u8a66\u3002\u9019\u7a2e\u65b9\u6cd5\u5f9e Llama 3.1 8B \u7522\u751f\u4e86\u4e00\u500b\u5f15\u4eba\u6ce8\u76ee\u7684 4B \u6a21\u578b\uff0c\u4e26\u5f9e Mistral NeMo 12B \u7522\u751f\u4e86\u4e00\u500b\u6700\u5148\u9032\u7684 Mistral-NeMo-Minitron-8B (\u7c21\u7a31 MN-Minitron-8B) \u6a21\u578b\u3002\u6211\u5011\u767c\u73fe\uff0c\u5728\u7121\u6cd5\u8a2a\u554f\u539f\u59cb\u6578\u64da\u7684\u60c5\u6cc1\u4e0b\uff0c\u5fae\u8abf\u77e5\u8b58\u84b8\u993e\u8cc7\u6599\u96c6\u4e0a\u7684\u6559\u5e2b\u6a21\u578b\u662f\u6709\u76ca\u7684\u3002\u6211\u5011\u5728 Hugging Face \u4e0a\u958b\u6e90\u4e86\u6211\u5011\u7684\u57fa\u790e\u6a21\u578b\u6b0a\u91cd\uff0c\u4e26\u9644\u6709\u5bec\u9b06\u7684\u8a31\u53ef\u8b49\u3002", "author": "Sharath Turuvekere Sreenivas et.al.", "authors": "Sharath Turuvekere Sreenivas, Saurav Muralidharan, Raviraj Joshi, Marcin Chochowski, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro, Jan Kautz, Pavlo Molchanov", "id": "2408.11796v1", "paper_url": "http://arxiv.org/abs/2408.11796v1", "repo": "null"}}