
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-09-12**|**AnySkin: Plug-and-play Skin Sensing for Robotic Touch**|Raunaq Bhirangi et.al.|[2409.08276v1](http://arxiv.org/abs/2409.08276v1)|null|
|**2024-09-12**|**Hand-Object Interaction Pretraining from Videos**|Himanshu Gaurav Singh et.al.|[2409.08273v1](http://arxiv.org/abs/2409.08273v1)|null|
|**2024-09-12**|**Windows Agent Arena: Evaluating Multi-Modal OS Agents at Scale**|Rogerio Bonatti et.al.|[2409.08264v1](http://arxiv.org/abs/2409.08264v1)|[link](https://github.com/microsoft/windowsagentarena)|
|**2024-09-12**|**LoRID: Low-Rank Iterative Diffusion for Adversarial Purification**|Geigh Zollicoffer et.al.|[2409.08255v1](http://arxiv.org/abs/2409.08255v1)|null|
|**2024-09-12**|**The Design of Informative Take-Over Requests for Semi-Autonomous Cyber-Physical Systems: Combining Spoken Language and Visual Icons in a Drone-Controller Setting**|Ashwini Gundappa et.al.|[2409.08253v2](http://arxiv.org/abs/2409.08253v2)|null|
|**2024-09-12**|**OmniQuery: Contextually Augmenting Captured Multimodal Memory to Enable Personal Question Answering**|Jiahao Nick Li et.al.|[2409.08250v1](http://arxiv.org/abs/2409.08250v1)|null|
|**2024-09-12**|**IFAdapter: Instance Feature Control for Grounded Text-to-Image Generation**|Yinwei Wu et.al.|[2409.08240v1](http://arxiv.org/abs/2409.08240v1)|null|
|**2024-09-12**|**Source2Synth: Synthetic Data Generation and Curation Grounded in Real Data Sources**|Alisia Lupidi et.al.|[2409.08239v1](http://arxiv.org/abs/2409.08239v1)|null|
|**2024-09-12**|**LLM Honeypot: Leveraging Large Language Models as Advanced Interactive Honeypot Systems**|Hakan T. Otal et.al.|[2409.08234v1](http://arxiv.org/abs/2409.08234v1)|[link](https://github.com/ai-in-complex-systems-lab/llm-honeypot)|
|**2024-09-12**|**CliquePH: Higher-Order Information for Graph Neural Networks through Persistent Homology on Clique Graphs**|Davide Buffelli et.al.|[2409.08217v1](http://arxiv.org/abs/2409.08217v1)|null|
|**2024-09-12**|**LT3SD: Latent Trees for 3D Scene Diffusion**|Quan Meng et.al.|[2409.08215v1](http://arxiv.org/abs/2409.08215v1)|null|
|**2024-09-12**|**What Makes a Maze Look Like a Maze?**|Joy Hsu et.al.|[2409.08202v1](http://arxiv.org/abs/2409.08202v1)|null|
|**2024-09-12**|**AudioBERT: Audio Knowledge Augmented Language Model**|Hyunjong Ok et.al.|[2409.08199v1](http://arxiv.org/abs/2409.08199v1)|[link](https://github.com/hj-ok/audiobert)|
|**2024-09-12**|**Fine-tuning Large Language Models for Entity Matching**|Aaron Steiner et.al.|[2409.08185v1](http://arxiv.org/abs/2409.08185v1)|[link](https://github.com/wbsg-uni-mannheim/tailormatch)|
|**2024-09-12**|**On the Role of Context in Reading Time Prediction**|Andreas Opedal et.al.|[2409.08160v1](http://arxiv.org/abs/2409.08160v1)|[link](https://github.com/rycolab/context-reading-time)|
|**2024-09-12**|**LLM-POTUS Score: A Framework of Analyzing Presidential Debates with Large Language Models**|Zhengliang Liu et.al.|[2409.08147v1](http://arxiv.org/abs/2409.08147v1)|null|
|**2024-09-12**|**Towards a graph-based foundation model for network traffic analysis**|Louis Van Langendonck et.al.|[2409.08111v1](http://arxiv.org/abs/2409.08111v1)|null|
|**2024-09-12**|**WhisperNER: Unified Open Named Entity and Speech Recognition**|Gil Ayache et.al.|[2409.08107v1](http://arxiv.org/abs/2409.08107v1)|null|
|**2024-09-12**|**The Faetar Benchmark: Speech Recognition in a Very Under-Resourced Language**|Michael Ong et.al.|[2409.08103v1](http://arxiv.org/abs/2409.08103v1)|null|
|**2024-09-12**|**The CLC-UKET Dataset: Benchmarking Case Outcome Prediction for the UK Employment Tribunal**|Huiyuan Xie et.al.|[2409.08098v1](http://arxiv.org/abs/2409.08098v1)|null|
|**2024-09-12**|**TravelAgent: An AI Assistant for Personalized Travel Planning**|Aili Chen et.al.|[2409.08069v1](http://arxiv.org/abs/2409.08069v1)|null|
|**2024-09-12**|**AI-accelerated discovery of high critical temperature superconductors**|Xiao-Qi Han et.al.|[2409.08065v1](http://arxiv.org/abs/2409.08065v1)|null|
|**2024-09-12**|**Unleashing Worms and Extracting Data: Escalating the Outcome of Attacks against RAG-based Inference in Scale and Severity Using Jailbreaking**|Stav Cohen et.al.|[2409.08045v1](http://arxiv.org/abs/2409.08045v1)|null|
|**2024-09-12**|**Enhancing Few-Shot Image Classification through Learnable Multi-Scale Embedding and Attention Mechanisms**|Fatemeh Askari et.al.|[2409.07989v1](http://arxiv.org/abs/2409.07989v1)|[link](https://github.com/FatemehAskari/MSENet)|
|**2024-09-12**|**Games for AI Control: Models of Safety Evaluations of AI Deployment Protocols**|Charlie Griffin et.al.|[2409.07985v1](http://arxiv.org/abs/2409.07985v1)|[link](https://github.com/cj-griffin/gamesforaicontrol)|
|**2024-09-12**|**ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE**|Sichun Wu et.al.|[2409.07966v1](http://arxiv.org/abs/2409.07966v1)|[link](https://github.com/uuembodiedsocialai/probtalk3d)|
|**2024-09-12**|**WirelessAgent: Large Language Model Agents for Intelligent Wireless Networks**|Jingwen Tong et.al.|[2409.07964v1](http://arxiv.org/abs/2409.07964v1)|[link](https://github.com/weiiguo/wireless-agent)|
|**2024-09-12**|**Enhanced Online Grooming Detection Employing Context Determination and Message-Level Analysis**|Jake Street et.al.|[2409.07958v1](http://arxiv.org/abs/2409.07958v1)|null|
|**2024-09-12**|**Reinforcement Learning Discovers Efficient Decentralized Graph Path Search Strategies**|Alexei Pisacane et.al.|[2409.07932v1](http://arxiv.org/abs/2409.07932v1)|null|
|**2024-09-12**|**A convolutional neural network approach to deblending seismic data**|Jing Sun et.al.|[2409.07930v1](http://arxiv.org/abs/2409.07930v1)|null|
|**2024-09-12**|**A framework for measuring the training efficiency of a neural architecture**|Eduardo Cueto-Mendoza et.al.|[2409.07925v1](http://arxiv.org/abs/2409.07925v1)|null|
|**2024-09-12**|**Tidal MerzA: Combining affective modelling and autonomous code generation through Reinforcement Learning**|Elizabeth Wilson et.al.|[2409.07918v1](http://arxiv.org/abs/2409.07918v1)|null|
|**2024-09-12**|**UGAD: Universal Generative AI Detector utilizing Frequency Fingerprints**|Inzamamul Alam et.al.|[2409.07913v1](http://arxiv.org/abs/2409.07913v1)|null|
|**2024-09-12**|**A corpus-based investigation of pitch contours of monosyllabic words in conversational Taiwan Mandarin**|Xiaoyun Jin et.al.|[2409.07891v1](http://arxiv.org/abs/2409.07891v1)|null|
|**2024-09-12**|**Learning Rules from KGs Guided by Language Models**|Zihang Peng et.al.|[2409.07869v1](http://arxiv.org/abs/2409.07869v1)|[link](https://github.com/pzh97/learning-rules-from-kgs-guided-by-language-models)|
|**2024-09-12**|**Enhancing Cross-Market Recommendation System with Graph Isomorphism Networks: A Novel Approach to Personalized User Experience**|Sümeyye Öztürk et.al.|[2409.07850v1](http://arxiv.org/abs/2409.07850v1)|null|
|**2024-09-12**|**FPMT: Enhanced Semi-Supervised Model for Traffic Incident Detection**|Xinying Lu et.al.|[2409.07839v1](http://arxiv.org/abs/2409.07839v1)|null|
|**2024-09-12**|**A Comprehensive Survey on Deep Multimodal Learning with Missing Modality**|Renjie Wu et.al.|[2409.07825v2](http://arxiv.org/abs/2409.07825v2)|null|
|**2024-09-12**|**Online vs Offline: A Comparative Study of First-Party and Third-Party Evaluations of Social Chatbots**|Ekaterina Svikhnushina et.al.|[2409.07823v1](http://arxiv.org/abs/2409.07823v1)|null|
|**2024-09-12**|**Controllable Synthetic Clinical Note Generation with Privacy Guarantees**|Tal Baumel et.al.|[2409.07809v1](http://arxiv.org/abs/2409.07809v1)|null|
|**2024-09-12**|**In-Situ Fine-Tuning of Wildlife Models in IoT-Enabled Camera Traps for Efficient Adaptation**|Mohammad Mehdi Rastikerdar et.al.|[2409.07796v1](http://arxiv.org/abs/2409.07796v1)|null|
|**2024-09-12**|**Full-text Error Correction for Chinese Speech Recognition with Large Language Model**|Zhiyuan Tang et.al.|[2409.07790v1](http://arxiv.org/abs/2409.07790v1)|null|
|**2024-09-12**|**Stable Language Model Pre-training by Reducing Embedding Variability**|Woojin Chung et.al.|[2409.07787v1](http://arxiv.org/abs/2409.07787v1)|null|
|**2024-09-12**|**ASSNet: Adaptive Semantic Segmentation Network for Microtumors and Multi-Organ Segmentation**|Fuchen Zheng et.al.|[2409.07779v1](http://arxiv.org/abs/2409.07779v1)|[link](https://github.com/lzeeorno/assnet)|
|**2024-09-12**|**Training Spiking Neural Networks via Augmented Direct Feedback Alignment**|Yongbo Zhang et.al.|[2409.07776v1](http://arxiv.org/abs/2409.07776v1)|null|
|**2024-09-12**|**Universal Pooling Method of Multi-layer Features from Pretrained Models for Speaker Verification**|Jin Sob Kim et.al.|[2409.07770v1](http://arxiv.org/abs/2409.07770v1)|[link](https://github.com/sadpororo/unipool-sv)|
|**2024-09-12**|**Reimagining Linear Probing: Kolmogorov-Arnold Networks in Transfer Learning**|Sheng Shen et.al.|[2409.07763v1](http://arxiv.org/abs/2409.07763v1)|null|
|**2024-09-12**|**Top-down Activity Representation Learning for Video Question Answering**|Yanan Wang et.al.|[2409.07748v1](http://arxiv.org/abs/2409.07748v1)|null|
|**2024-09-12**|**Multi-object event graph representation learning for Video Question Answering**|Yanan Wang et.al.|[2409.07747v1](http://arxiv.org/abs/2409.07747v1)|null|
|**2024-09-12**|**Ruri: Japanese General Text Embeddings**|Hayato Tsukagoshi et.al.|[2409.07737v1](http://arxiv.org/abs/2409.07737v1)|null|
|**2024-09-12**|**Transfer Learning Applied to Computer Vision Problems: Survey on Current Progress, Limitations, and Opportunities**|Aaryan Panda et.al.|[2409.07736v1](http://arxiv.org/abs/2409.07736v1)|null|
|**2024-09-12**|**GRE^2-MDCL: Graph Representation Embedding Enhanced via Multidimensional Contrastive Learning**|Kaizhe Fan et.al.|[2409.07725v1](http://arxiv.org/abs/2409.07725v1)|null|
|**2024-09-12**|**Advancing Depth Anything Model for Unsupervised Monocular Depth Estimation in Endoscopy**|Bojian Li et.al.|[2409.07723v1](http://arxiv.org/abs/2409.07723v1)|null|
|**2024-09-12**|**FIReStereo: Forest InfraRed Stereo Dataset for UAS Depth Perception in Visually Degraded Environments**|Devansh Dhrafani et.al.|[2409.07715v1](http://arxiv.org/abs/2409.07715v1)|null|
|**2024-09-12**|**Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice**|Jonathan Li et.al.|[2409.07713v1](http://arxiv.org/abs/2409.07713v1)|null|
|**2024-09-12**|**Attack End-to-End Autonomous Driving through Module-Wise Noise**|Lu Wang et.al.|[2409.07706v1](http://arxiv.org/abs/2409.07706v1)|null|
|**2024-09-12**|**DSBench: How Far Are Data Science Agents to Becoming Data Science Experts?**|Liqiang Jing et.al.|[2409.07703v1](http://arxiv.org/abs/2409.07703v1)|[link](https://github.com/liqiangjing/dsbench)|
|**2024-09-12**|**Enhancing Q&A Text Retrieval with Ranking Models: Benchmarking, fine-tuning and deploying Rerankers for RAG**|Gabriel de Souza P. Moreira et.al.|[2409.07691v1](http://arxiv.org/abs/2409.07691v1)|null|
|**2024-09-12**|**Modeling Information Narrative Detection and Evolution on Telegram during the Russia-Ukraine War**|Patrick Gerard et.al.|[2409.07684v1](http://arxiv.org/abs/2409.07684v1)|null|
|**2024-09-12**|**Open-Vocabulary Remote Sensing Image Semantic Segmentation**|Qinglong Cao et.al.|[2409.07683v1](http://arxiv.org/abs/2409.07683v1)|null|
|**2024-09-12**|**An Unsupervised Dialogue Topic Segmentation Model Based on Utterance Rewriting**|Xia Hou et.al.|[2409.07672v1](http://arxiv.org/abs/2409.07672v1)|null|
|**2024-09-11**|**Passed the Turing Test: Living in Turing Futures**|Bernardo Gonçalves et.al.|[2409.07656v1](http://arxiv.org/abs/2409.07656v1)|null|
|**2024-09-11**|**Feature Importance in Pedestrian Intention Prediction: A Context-Aware Review**|Mohsen Azarmi et.al.|[2409.07645v1](http://arxiv.org/abs/2409.07645v1)|null|
|**2024-09-11**|**SimulBench: Evaluating Language Models with Creative Simulation Tasks**|Qi Jia et.al.|[2409.07641v1](http://arxiv.org/abs/2409.07641v1)|null|
|**2024-09-11**|**Can We Count on LLMs? The Fixed-Effect Fallacy and Claims of GPT-4 Capabilities**|Thomas Ball et.al.|[2409.07638v1](http://arxiv.org/abs/2409.07638v1)|null|
|**2024-09-11**|**Weather-Informed Probabilistic Forecasting and Scenario Generation in Power Systems**|Hanyu Zhang et.al.|[2409.07637v1](http://arxiv.org/abs/2409.07637v1)|null|
|**2024-09-11**|**Dividable Configuration Performance Learning**|Jingzhi Gong et.al.|[2409.07629v1](http://arxiv.org/abs/2409.07629v1)|null|
|**2024-09-11**|**Leveraging User-Generated Reviews for Recommender Systems with Dynamic Headers**|Shanu Vashishtha et.al.|[2409.07627v1](http://arxiv.org/abs/2409.07627v1)|null|
|**2024-09-11**|**Ensemble Methods for Sequence Classification with Hidden Markov Models**|Maxime Kawawa-Beaudan et.al.|[2409.07619v1](http://arxiv.org/abs/2409.07619v1)|null|
|**2024-09-11**|**Understanding Foundation Models: Are We Back in 1924?**|Alan F. Smeaton et.al.|[2409.07618v1](http://arxiv.org/abs/2409.07618v1)|null|
|**2024-09-11**|**Zero-Shot Machine-Generated Text Detection Using Mixture of Large Language Models**|Matthieu Dubois et.al.|[2409.07615v1](http://arxiv.org/abs/2409.07615v1)|null|
|**2024-09-11**|**Efficient Localized Adaptation of Neural Weather Forecasting: A Case Study in the MENA Region**|Muhammad Akhtar Munir et.al.|[2409.07585v1](http://arxiv.org/abs/2409.07585v1)|[link](https://github.com/akhtarvision/weather-regional)|
|**2024-09-11**|**DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer's Early Diagnosis**|Ke Chen et.al.|[2409.07584v1](http://arxiv.org/abs/2409.07584v1)|null|
|**2024-09-11**|**A Novel Mathematical Framework for Objective Evaluation of Ideas using a Conversational AI (CAI) System**|B. Sankar et.al.|[2409.07578v1](http://arxiv.org/abs/2409.07578v1)|null|
|**2024-09-11**|**Machine Learning and Constraint Programming for Efficient Healthcare Scheduling**|Aymen Ben Said et.al.|[2409.07547v1](http://arxiv.org/abs/2409.07547v1)|null|
|**2024-09-11**|**"My Grade is Wrong!": A Contestable AI Framework for Interactive Feedback in Evaluating Student Essays**|Shengxin Hong et.al.|[2409.07453v1](http://arxiv.org/abs/2409.07453v1)|null|
|**2024-09-11**|**Still More Shades of Null: A Benchmark for Responsible Missing Value Imputation**|Falaah Arif Khan et.al.|[2409.07510v1](http://arxiv.org/abs/2409.07510v1)|[link](https://github.com/falaaharifkhan/data-cleaning-stability)|
|**2024-09-11**|**SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories**|Ben Bogin et.al.|[2409.07440v1](http://arxiv.org/abs/2409.07440v1)|[link](https://github.com/allenai/super-benchmark)|
|**2024-09-11**|**A Suite for Acoustic Language Model Evaluation**|Gallil Maimon et.al.|[2409.07437v1](http://arxiv.org/abs/2409.07437v1)|[link](https://github.com/slp-rl/salmon)|
|**2024-09-11**|**Synthetic continued pretraining**|Zitong Yang et.al.|[2409.07431v1](http://arxiv.org/abs/2409.07431v1)|[link](https://github.com/zitongyang/synthetic_continued_pretraining)|
|**2024-09-11**|**Agent Workflow Memory**|Zora Zhiruo Wang et.al.|[2409.07429v1](http://arxiv.org/abs/2409.07429v1)|[link](https://github.com/zorazrw/agent-workflow-memory)|
|**2024-09-11**|**Towards Fairer Health Recommendations: finding informative unbiased samples via Word Sense Disambiguation**|Gavin Butts et.al.|[2409.07424v1](http://arxiv.org/abs/2409.07424v1)|null|
|**2024-09-11**|**Enhancing adversarial robustness in Natural Language Inference using explanations**|Alexandros Koulakos et.al.|[2409.07423v1](http://arxiv.org/abs/2409.07423v1)|null|
|**2024-09-11**|**Hierarchical Reinforcement Learning for Temporal Abstraction of Listwise Recommendation**|Luo Ji et.al.|[2409.07416v1](http://arxiv.org/abs/2409.07416v1)|null|
|**2024-09-11**|**SoK: Security and Privacy Risks of Medical AI**|Yuanhaur Chang et.al.|[2409.07415v1](http://arxiv.org/abs/2409.07415v1)|null|
|**2024-09-11**|**CLNX: Bridging Code and Natural Language for C/C++ Vulnerability-Contributing Commits Identification**|Zeqing Qin et.al.|[2409.07407v1](http://arxiv.org/abs/2409.07407v1)|null|
|**2024-09-11**|**AdaCAD: Adaptively Decoding to Balance Conflicts between Contextual and Parametric Knowledge**|Han Wang et.al.|[2409.07394v1](http://arxiv.org/abs/2409.07394v1)|[link](https://github.com/hannight/adacad)|
|**2024-09-11**|**Awaking the Slides: A Tuning-free and Knowledge-regulated AI Tutoring System via Language Model Coordination**|Daniel Zhang-Li et.al.|[2409.07372v1](http://arxiv.org/abs/2409.07372v1)|null|
|**2024-09-11**|**Demo: SGCode: A Flexible Prompt-Optimizing System for Secure Generation of Code**|Khiem Ton et.al.|[2409.07368v1](http://arxiv.org/abs/2409.07368v1)|null|
|**2024-09-11**|**Think Together and Work Better: Combining Humans' and LLMs' Think-Aloud Outcomes for Effective Text Evaluation**|SeongYeub Chu et.al.|[2409.07355v1](http://arxiv.org/abs/2409.07355v1)|[link](https://github.com/BBeeChu/InteractEval)|
|**2024-09-11**|**Securing Vision-Language Models with a Robust Encoder Against Jailbreak and Adversarial Attacks**|Md Zarif Hossain et.al.|[2409.07353v1](http://arxiv.org/abs/2409.07353v1)|[link](https://github.com/speedlab-git/robust-encoder-against-jailbreak-attack)|
|**2024-09-11**|**Federated Impression for Learning with Distributed Heterogeneous Data**|Sana Ayromlou et.al.|[2409.07351v1](http://arxiv.org/abs/2409.07351v1)|null|
|**2024-09-11**|**Online Decision MetaMorphFormer: A Casual Transformer-Based Reinforcement Learning Framework of Universal Embodied Intelligence**|Luo Ji et.al.|[2409.07341v1](http://arxiv.org/abs/2409.07341v1)|null|
|**2024-09-11**|**Explanation, Debate, Align: A Weak-to-Strong Framework for Language Model Generalization**|Mehrdad Zakershahrak et.al.|[2409.07335v1](http://arxiv.org/abs/2409.07335v1)|null|
|**2024-09-11**|**Module-wise Adaptive Adversarial Training for End-to-end Autonomous Driving**|Tianyuan Zhang et.al.|[2409.07321v1](http://arxiv.org/abs/2409.07321v1)|null|
|**2024-09-11**|**MEDIC: Towards a Comprehensive Framework for Evaluating LLMs in Clinical Applications**|Praveen K Kanithi et.al.|[2409.07314v1](http://arxiv.org/abs/2409.07314v1)|null|
|**2024-09-11**|**Exploring User-level Gradient Inversion with a Diffusion Prior**|Zhuohang Li et.al.|[2409.07291v1](http://arxiv.org/abs/2409.07291v1)|null|
|**2024-09-11**|**Using Generative Agents to Create Tip Sheets for Investigative Data Reporting**|Joris Veerbeek et.al.|[2409.07286v1](http://arxiv.org/abs/2409.07286v1)|null|
|**2024-09-11**|**Cross-Dialect Text-To-Speech in Pitch-Accent Language Incorporating Multi-Dialect Phoneme-Level BERT**|Kazuki Yamauchi et.al.|[2409.07265v1](http://arxiv.org/abs/2409.07265v1)|null|
|**2024-09-11**|**Propaganda to Hate: A Multimodal Analysis of Arabic Memes with Multi-Agent LLMs**|Firoj Alam et.al.|[2409.07246v1](http://arxiv.org/abs/2409.07246v1)|null|

#### Abstracts
##### **AnySkin: Plug-and-play Skin Sensing for Robotic Touch**
2409.08276v1 by Raunaq Bhirangi, Venkatesh Pattabiraman, Enes Erciyes, Yifeng Cao, Tess Hellebrekers, Lerrel Pinto

While tactile sensing is widely accepted as an important and useful sensing
modality, its use pales in comparison to other sensory modalities like vision
and proprioception. AnySkin addresses the critical challenges that impede the
use of tactile sensing -- versatility, replaceability, and data reusability.
Building on the simplistic design of ReSkin, and decoupling the sensing
electronics from the sensing interface, AnySkin simplifies integration making
it as straightforward as putting on a phone case and connecting a charger.
Furthermore, AnySkin is the first uncalibrated tactile-sensor with
cross-instance generalizability of learned manipulation policies. To summarize,
this work makes three key contributions: first, we introduce a streamlined
fabrication process and a design tool for creating an adhesive-free, durable
and easily replaceable magnetic tactile sensor; second, we characterize slip
detection and policy learning with the AnySkin sensor; and third, we
demonstrate zero-shot generalization of models trained on one instance of
AnySkin to new instances, and compare it with popular existing tactile
solutions like DIGIT and ReSkin.https://any-skin.github.io/

摘要：儘管觸覺感測被廣泛接受為一種重要且有用的感測方式，但與視覺和本體感覺等其他感官方式相比，它的使用顯得相形見絀。AnySkin 解決了阻礙觸覺感測使用的關鍵挑戰，包括多功能性、可替換性和資料可重用性。AnySkin 建立在 ReSkin 的簡化設計之上，並將感測電子元件與感測介面分開，簡化了整合，使其像戴上手機殼並連接充電器一樣簡單。此外，AnySkin 是第一個未校準的觸覺感測器，具有跨例學習操作策略的概括性。總之，這項工作做出了三項關鍵貢獻：首先，我們引入了一個簡化的製造流程和一個設計工具，用於建立無黏著劑、耐用且易於更換的磁性觸覺感測器；其次，我們利用 AnySkin 感測器來表徵滑動偵測和策略學習；第三，我們展示了在一個 AnySkin 實例上訓練的模型對新實例的零次學習概括性，並將其與 DIGIT 和 ReSkin 等現有的熱門觸覺解決方案進行了比較。https://any-skin.github.io/

##### **Hand-Object Interaction Pretraining from Videos**
2409.08273v1 by Himanshu Gaurav Singh, Antonio Loquercio, Carmelo Sferrazza, Jane Wu, Haozhi Qi, Pieter Abbeel, Jitendra Malik

We present an approach to learn general robot manipulation priors from 3D
hand-object interaction trajectories. We build a framework to use in-the-wild
videos to generate sensorimotor robot trajectories. We do so by lifting both
the human hand and the manipulated object in a shared 3D space and retargeting
human motions to robot actions. Generative modeling on this data gives us a
task-agnostic base policy. This policy captures a general yet flexible
manipulation prior. We empirically demonstrate that finetuning this policy,
with both reinforcement learning (RL) and behavior cloning (BC), enables
sample-efficient adaptation to downstream tasks and simultaneously improves
robustness and generalizability compared to prior approaches. Qualitative
experiments are available at: \url{https://hgaurav2k.github.io/hop/}.

摘要：我們提出一個方法，從 3D 手部物件互動軌跡中學習一般機器人操控先驗。我們建立一個架構，使用野外影片來產生感測運動機器人軌跡。我們這樣做是透過提升人類的手和被操控的物件在一個共用的 3D 空間中，並將人類動作重新設定為機器人動作。這個資料上的生成模型給了我們一個與任務無關的基本策略。此策略捕捉到一般但靈活的操控先驗。我們經驗性地證明，微調此策略，同時使用強化學習 (RL) 和行為複製 (BC)，能有效率地調整下游任務，並同時改善健壯性和概括性，與先前的做法相比。定性實驗可以在以下網址取得：\url{https://hgaurav2k.github.io/hop/}。

##### **Windows Agent Arena: Evaluating Multi-Modal OS Agents at Scale**
2409.08264v1 by Rogerio Bonatti, Dan Zhao, Francesco Bonacci, Dillon Dupont, Sara Abdali, Yinheng Li, Justin Wagle, Kazuhito Koishida, Arthur Bucker, Lawrence Jang, Zack Hui

Large language models (LLMs) show remarkable potential to act as computer
agents, enhancing human productivity and software accessibility in multi-modal
tasks that require planning and reasoning. However, measuring agent performance
in realistic environments remains a challenge since: (i) most benchmarks are
limited to specific modalities or domains (e.g. text-only, web navigation, Q&A,
coding) and (ii) full benchmark evaluations are slow (on order of magnitude of
days) given the multi-step sequential nature of tasks. To address these
challenges, we introduce the Windows Agent Arena: a reproducible, general
environment focusing exclusively on the Windows operating system (OS) where
agents can operate freely within a real Windows OS and use the same wide range
of applications, tools, and web browsers available to human users when solving
tasks. We adapt the OSWorld framework (Xie et al., 2024) to create 150+ diverse
Windows tasks across representative domains that require agent abilities in
planning, screen understanding, and tool usage. Our benchmark is scalable and
can be seamlessly parallelized in Azure for a full benchmark evaluation in as
little as 20 minutes. To demonstrate Windows Agent Arena's capabilities, we
also introduce a new multi-modal agent, Navi. Our agent achieves a success rate
of 19.5% in the Windows domain, compared to 74.5% performance of an unassisted
human. Navi also demonstrates strong performance on another popular web-based
benchmark, Mind2Web. We offer extensive quantitative and qualitative analysis
of Navi's performance, and provide insights into the opportunities for future
research in agent development and data generation using Windows Agent Arena.
  Webpage: https://microsoft.github.io/WindowsAgentArena
  Code: https://github.com/microsoft/WindowsAgentArena

摘要：<paragraph>大型語言模型 (LLM) 展現出作為電腦代理的非凡潛力，在需要規劃和推理的多模態任務中提升人類生產力和軟體可及性。然而，在逼真的環境中測量代理效能仍然是一項挑戰，原因如下：(i) 大多數基準測試僅限於特定模態或領域 (例如純文字、網頁瀏覽、問答、編碼)，以及 (ii) 由於任務的多步驟順序性質，完整的基準測試評估很慢 (以天為單位)。為了應對這些挑戰，我們引入了 Windows 代理競技場：一個可重複、通用的環境，專注於 Windows 作業系統 (OS)，代理可以在真正的 Windows 作業系統中自由運作，並使用與人類使用者在解決任務時可用的相同廣泛的應用程式、工具和網路瀏覽器。我們調整 OSWorld 框架 (Xie 等人，2024 年) 來建立 150 多項跨代表性領域的多元 Windows 任務，這些任務需要代理具備規劃、螢幕理解和工具使用方面的能力。我們的基準測試具有可擴展性，可以在 Azure 中無縫並行處理，在短短 20 分鐘內完成完整的基準測試評估。為了展示 Windows 代理競技場的能力，我們還引入了一個新的多模態代理 Navi。我們的代理在 Windows 領域達到了 19.5% 的成功率，而未受協助的人類效能為 74.5%。Navi 也在另一個流行的網路基準測試 Mind2Web 上展現了強勁的效能。我們對 Navi 的效能進行了廣泛的量化和質化分析，並提供了對使用 Windows 代理競技場進行代理開發和資料生成的未來研究機會的見解。
網站：https://microsoft.github.io/WindowsAgentArena
程式碼：https://github.com/microsoft/WindowsAgentArena</paragraph>

##### **LoRID: Low-Rank Iterative Diffusion for Adversarial Purification**
2409.08255v1 by Geigh Zollicoffer, Minh Vu, Ben Nebgen, Juan Castorena, Boian Alexandrov, Manish Bhattarai

This work presents an information-theoretic examination of diffusion-based
purification methods, the state-of-the-art adversarial defenses that utilize
diffusion models to remove malicious perturbations in adversarial examples. By
theoretically characterizing the inherent purification errors associated with
the Markov-based diffusion purifications, we introduce LoRID, a novel Low-Rank
Iterative Diffusion purification method designed to remove adversarial
perturbation with low intrinsic purification errors. LoRID centers around a
multi-stage purification process that leverages multiple rounds of
diffusion-denoising loops at the early time-steps of the diffusion models, and
the integration of Tucker decomposition, an extension of matrix factorization,
to remove adversarial noise at high-noise regimes. Consequently, LoRID
increases the effective diffusion time-steps and overcomes strong adversarial
attacks, achieving superior robustness performance in CIFAR-10/100, CelebA-HQ,
and ImageNet datasets under both white-box and black-box settings.

摘要：這項工作提出了基於擴散的淨化方法的信息理論檢驗，這是一種最先進的對抗性防禦，利用擴散模型來移除對抗性範例中的惡意擾動。通過理論上表徵與基於馬可夫的擴散淨化相關的固有淨化誤差，我們引入了 LoRID，一種新穎的低秩反覆擴散淨化方法，旨在以低內在淨化誤差移除對抗性擾動。LoRID 以多階段淨化過程為中心，利用擴散模型的早期時間步長進行多輪擴散去噪迴圈，並整合了矩陣分解的延伸 — 塔克分解，以在高噪聲狀態下移除對抗性雜訊。因此，LoRID增加了有效的擴散時間步長，並克服了強大的對抗性攻擊，在白盒和黑盒設定下，在 CIFAR-10/100、CelebA-HQ 和 ImageNet 資料集上達到了優異的穩健性表現。

##### **The Design of Informative Take-Over Requests for Semi-Autonomous Cyber-Physical Systems: Combining Spoken Language and Visual Icons in a Drone-Controller Setting**
2409.08253v2 by Ashwini Gundappa, Emilia Ellsiepen, Lukas Schmitz, Frederik Wiehr, Vera Demberg

The question of how cyber-physical systems should interact with human
partners that can take over control or exert oversight is becoming more
pressing, as these systems are deployed for an ever larger range of tasks.
Drawing on the literatures on handing over control during semi-autonomous
driving and human-robot interaction, we propose a design of a take-over request
that combines an abstract pre-alert with an informative TOR: Relevant sensor
information is highlighted on the controller's display, while a spoken message
verbalizes the reason for the TOR. We conduct our study in the context of a
semi-autonomous drone control scenario as our testbed. The goal of our online
study is to assess in more detail what form a language-based TOR should take.
Specifically, we compare a full sentence condition to shorter fragments, and
test whether the visual highlighting should be done synchronously or
asynchronously with the speech. Participants showed a higher accuracy in
choosing the correct solution with our bi-modal TOR and felt that they were
better able to recognize the critical situation. Using only fragments in the
spoken message rather than full sentences did not lead to improved accuracy or
faster reactions. Also, synchronizing the visual highlighting with the spoken
message did not result in better accuracy and response times were even
increased in this condition.

摘要：隨著這些系統被部署到越來越廣泛的任務中，如何讓網路物理系統與可以接管控制或執行監督的人類夥伴互動的問題變得越來越緊迫。
透過利用關於在半自動駕駛和人機互動中移交控制權的文獻，我們提出了一個接管請求的設計，它結合了一個抽象的預警和一個資訊性的 TOR：相關的感測器資訊會在控制器的顯示器上被凸顯，而一個口語訊息則會表達 TOR 的原因。我們在一個半自動無人機控制場景的背景下進行我們的研究，作為我們的測試平台。我們的線上研究的目標是更詳細地評估基於語言的 TOR 應該採取什麼形式。
具體來說，我們比較一個完整句子的條件和較短的片段，並測試視覺凸顯是否應該與語音同步或異步進行。參與者在使用我們的雙模式 TOR 時展現出更高的準確性，並感覺他們更能夠識別關鍵情況。在口語訊息中只使用片段而不是完整句子並未導致準確性提高或反應更快。此外，將視覺凸顯與口語訊息同步並未導致更好的準確性，而且在此條件下，反應時間甚至增加。

##### **OmniQuery: Contextually Augmenting Captured Multimodal Memory to Enable Personal Question Answering**
2409.08250v1 by Jiahao Nick Li, Zhuohao Jerry Zhang, Jiaju Ma

People often capture memories through photos, screenshots, and videos. While
existing AI-based tools enable querying this data using natural language, they
mostly only support retrieving individual pieces of information like certain
objects in photos and struggle with answering more complex queries that involve
interpreting interconnected memories like event sequences. We conducted a
one-month diary study to collect realistic user queries and generated a
taxonomy of necessary contextual information for integrating with captured
memories. We then introduce OmniQuery, a novel system that is able to answer
complex personal memory-related questions that require extracting and inferring
contextual information. OmniQuery augments single captured memories through
integrating scattered contextual information from multiple interconnected
memories, retrieves relevant memories, and uses a large language model (LLM) to
comprehensive answers. In human evaluations, we show the effectiveness of
OmniQuery with an accuracy of 71.5%, and it outperformed a conventional RAG
system, winning or tying in 74.5% of the time.

摘要：人們經常透過照片、螢幕截圖和影片來捕捉回憶。現有的基於人工智慧的工具，雖然能使用自然語言來查詢這些資料，但它們大多只支援擷取個別資訊，例如照片中的特定物件，而且很難回答涉及解讀相互連結回憶（例如事件順序）的更複雜查詢。我們進行了一項為期一個月的日記研究，以收集實際的使用者查詢，並產生了一個必要的脈絡資訊分類法，用於與擷取的回憶整合。然後，我們介紹 OmniQuery，這是一個新穎的系統，能夠回答複雜的個人記憶相關問題，需要擷取和推斷脈絡資訊。OmniQuery 透過整合來自多個相互連結回憶的零散脈絡資訊，來擴充單一的擷取回憶，擷取相關回憶，並使用大型語言模型 (LLM) 來提供全面的答案。在人類評量中，我們以 71.5% 的準確度展示了 OmniQuery 的有效性，並且它優於傳統的 RAG 系統，在 74.5% 的時間中獲勝或打平。

##### **IFAdapter: Instance Feature Control for Grounded Text-to-Image Generation**
2409.08240v1 by Yinwei Wu, Xianpan Zhou, Bing Ma, Xuefeng Su, Kai Ma, Xinchao Wang

While Text-to-Image (T2I) diffusion models excel at generating visually
appealing images of individual instances, they struggle to accurately position
and control the features generation of multiple instances. The Layout-to-Image
(L2I) task was introduced to address the positioning challenges by
incorporating bounding boxes as spatial control signals, but it still falls
short in generating precise instance features. In response, we propose the
Instance Feature Generation (IFG) task, which aims to ensure both positional
accuracy and feature fidelity in generated instances. To address the IFG task,
we introduce the Instance Feature Adapter (IFAdapter). The IFAdapter enhances
feature depiction by incorporating additional appearance tokens and utilizing
an Instance Semantic Map to align instance-level features with spatial
locations. The IFAdapter guides the diffusion process as a plug-and-play
module, making it adaptable to various community models. For evaluation, we
contribute an IFG benchmark and develop a verification pipeline to objectively
compare models' abilities to generate instances with accurate positioning and
features. Experimental results demonstrate that IFAdapter outperforms other
models in both quantitative and qualitative evaluations.

摘要：文本到图像 (T2I) 扩散模型虽然很擅长生成视觉上吸引人的个体实例图像，但它们在准确定位和控制多个实例的特征生成方面却遇到了困难。布局到图像 (L2I) 任务通过将边界框作为空间控制信号来解决定位难题，但它在生成精确的实例特征方面仍然存在不足。对此，我们提出了实例特征生成 (IFG) 任务，旨在确保生成实例中的位置准确性和特征保真度。为了解决 IFG 任务，我们引入了实例特征适配器 (IFAdapter)。IFAdapter 通过合并额外的外观标记并利用实例语义图将实例级特征与空间位置对齐来增强特征描述。IFAdapter 以即插即用模块的形式指导扩散过程，使其能够适应各种社区模型。为了进行评估，我们贡献了一个 IFG 基准并开发了一个验证管道，以客观地比较模型生成具有准确定位和特征的实例的能力。实验结果表明，IFAdapter 在定量和定性评估中都优于其他模型。

##### **Source2Synth: Synthetic Data Generation and Curation Grounded in Real Data Sources**
2409.08239v1 by Alisia Lupidi, Carlos Gemmell, Nicola Cancedda, Jane Dwivedi-Yu, Jason Weston, Jakob Foerster, Roberta Raileanu, Maria Lomeli

Large Language Models still struggle in challenging scenarios that leverage
structured data, complex reasoning, or tool usage. In this paper, we propose
Source2Synth: a new method that can be used for teaching LLMs new skills
without relying on costly human annotations. Source2Synth takes as input a
custom data source and produces synthetic data points with intermediate
reasoning steps grounded in real-world sources. Source2Synth improves the
dataset quality by discarding low-quality generations based on their
answerability. We demonstrate the generality of this approach by applying it to
two challenging domains: we test reasoning abilities in multi-hop question
answering (MHQA), and tool usage in tabular question answering (TQA). Our
method improves performance by 25.51% for TQA on WikiSQL and 22.57% for MHQA on
HotPotQA compared to the fine-tuned baselines.

摘要：大型語言模型在利用結構化資料、複雜推理或工具使用的情況下仍面臨挑戰。在本文中，我們提出 Source2Synth：一種新的方法，可用於教授 LLM 新技能，而無需依賴昂貴的人工註解。Source2Synth 以自訂資料來源作為輸入，並產生以真實世界來源為基礎的合成資料點，其中包含中間推理步驟。Source2Synth 透過根據其可回答性來捨棄低品質的生成，進而提升資料集品質。我們透過將此方法應用於兩個具有挑戰性的領域來展示此方法的普遍性：我們在多跳問題回答 (MHQA) 中測試推理能力，以及在表格問題回答 (TQA) 中測試工具使用。與微調基線相比，我們的模型在 WikiSQL 上的 TQA 任務中將效能提升了 25.51%，在 HotPotQA 上的 MHQA 任務中提升了 22.57%。

##### **LLM Honeypot: Leveraging Large Language Models as Advanced Interactive Honeypot Systems**
2409.08234v1 by Hakan T. Otal, M. Abdullah Canbaz

The rapid evolution of cyber threats necessitates innovative solutions for
detecting and analyzing malicious activity. Honeypots, which are decoy systems
designed to lure and interact with attackers, have emerged as a critical
component in cybersecurity. In this paper, we present a novel approach to
creating realistic and interactive honeypot systems using Large Language Models
(LLMs). By fine-tuning a pre-trained open-source language model on a diverse
dataset of attacker-generated commands and responses, we developed a honeypot
capable of sophisticated engagement with attackers. Our methodology involved
several key steps: data collection and processing, prompt engineering, model
selection, and supervised fine-tuning to optimize the model's performance.
Evaluation through similarity metrics and live deployment demonstrated that our
approach effectively generates accurate and informative responses. The results
highlight the potential of LLMs to revolutionize honeypot technology, providing
cybersecurity professionals with a powerful tool to detect and analyze
malicious activity, thereby enhancing overall security infrastructure.

摘要：網路威脅的快速演變，需要創新的解決方案來偵測和分析惡意活動。Honeypot 是用來引誘和與攻擊者互動的誘餌系統，已成為網路安全中至關重要的組成部分。在本文中，我們提出了一種使用大型語言模型 (LLM) 來建立逼真且互動式 honeypot 系統的新方法。透過微調預先訓練的開源語言模型，使用攻擊者產生的指令和回應的多元資料集，我們開發了一個 honeypot，能夠與攻擊者進行複雜的互動。我們的做法包含幾個關鍵步驟：資料收集和處理、提示工程、模型選擇，以及監督微調以最佳化模型的效能。透過相似性指標和實際部署的評估，證明了我們的做法有效地產生了準確且有意義的回應。結果凸顯了 LLM 徹底改變 honeypot 技術的潛力，為網路安全專業人員提供了一個強大的工具來偵測和分析惡意活動，進而增強整體的安全基礎架構。

##### **CliquePH: Higher-Order Information for Graph Neural Networks through Persistent Homology on Clique Graphs**
2409.08217v1 by Davide Buffelli, Farzin Soleymani, Bastian Rieck

Graph neural networks have become the default choice by practitioners for
graph learning tasks such as graph classification and node classification.
Nevertheless, popular graph neural network models still struggle to capture
higher-order information, i.e., information that goes \emph{beyond} pairwise
interactions. Recent work has shown that persistent homology, a tool from
topological data analysis, can enrich graph neural networks with topological
information that they otherwise could not capture. Calculating such features is
efficient for dimension 0 (connected components) and dimension 1 (cycles).
However, when it comes to higher-order structures, it does not scale well, with
a complexity of $O(n^d)$, where $n$ is the number of nodes and $d$ is the order
of the structures. In this work, we introduce a novel method that extracts
information about higher-order structures in the graph while still using the
efficient low-dimensional persistent homology algorithm. On standard benchmark
datasets, we show that our method can lead to up to $31\%$ improvements in test
accuracy.

摘要：圖形神經網路已成為從業人員在圖形學習任務（例如圖形分類和節點分類）中的預設選擇。
儘管如此，流行的圖形神經網路模型仍難以擷取高階資訊，即超越成對互動的資訊。最近的研究顯示，作為拓撲資料分析工具的持續同調，可以用拓撲資訊豐富圖形神經網路，而這些資訊是它們無法擷取的。計算此類特徵對於維度 0（連通元件）和維度 1（循環）來說很有效率。
然而，當涉及到高階結構時，它的擴充性不佳，複雜度為 $O(n^d)$，其中 $n$ 是節點數，$d$ 是結構的階數。在這項工作中，我們介紹了一種新方法，用於萃取圖形中高階結構的資訊，同時仍使用高效的低維持續同調演算法。在標準基準資料集上，我們顯示我們的模型可以使測試準確度提升多達 $31\%$。

##### **LT3SD: Latent Trees for 3D Scene Diffusion**
2409.08215v1 by Quan Meng, Lei Li, Matthias Nießner, Angela Dai

We present LT3SD, a novel latent diffusion model for large-scale 3D scene
generation. Recent advances in diffusion models have shown impressive results
in 3D object generation, but are limited in spatial extent and quality when
extended to 3D scenes. To generate complex and diverse 3D scene structures, we
introduce a latent tree representation to effectively encode both
lower-frequency geometry and higher-frequency detail in a coarse-to-fine
hierarchy. We can then learn a generative diffusion process in this latent 3D
scene space, modeling the latent components of a scene at each resolution
level. To synthesize large-scale scenes with varying sizes, we train our
diffusion model on scene patches and synthesize arbitrary-sized output 3D
scenes through shared diffusion generation across multiple scene patches.
Through extensive experiments, we demonstrate the efficacy and benefits of
LT3SD for large-scale, high-quality unconditional 3D scene generation and for
probabilistic completion for partial scene observations.

摘要：我們提出 LT3SD，一種適用於大規模 3D 場景生成的新型潛在擴散模型。擴散模型的最新進展已在 3D 物件生成中展現出令人印象深刻的成果，但當擴展到 3D 場景時，其空間範圍和品質卻受到限制。為了生成複雜且多樣的 3D 場景結構，我們引入潛在樹狀表示法，以在由粗至細的階層結構中有效編碼低頻幾何和高頻細節。然後，我們可以在這個潛在 3D 場景空間中學習生成擴散過程，對場景的潛在組成部分進行建模，並在每個解析度層級中建模。為了合成具有不同大小的大規模場景，我們在場景貼片上訓練我們的擴散模型，並透過多個場景貼片的共享擴散生成合成任意大小的輸出 3D 場景。透過廣泛的實驗，我們證明了 LT3SD 在大規模、高品質無條件 3D 場景生成以及部分場景觀察的機率性完成方面的效能和優點。

##### **What Makes a Maze Look Like a Maze?**
2409.08202v1 by Joy Hsu, Jiayuan Mao, Joshua B. Tenenbaum, Noah D. Goodman, Jiajun Wu

A unique aspect of human visual understanding is the ability to flexibly
interpret abstract concepts: acquiring lifted rules explaining what they
symbolize, grounding them across familiar and unfamiliar contexts, and making
predictions or reasoning about them. While off-the-shelf vision-language models
excel at making literal interpretations of images (e.g., recognizing object
categories such as tree branches), they still struggle to make sense of such
visual abstractions (e.g., how an arrangement of tree branches may form the
walls of a maze). To address this challenge, we introduce Deep Schema Grounding
(DSG), a framework that leverages explicit structured representations of visual
abstractions for grounding and reasoning. At the core of DSG are
schemas--dependency graph descriptions of abstract concepts that decompose them
into more primitive-level symbols. DSG uses large language models to extract
schemas, then hierarchically grounds concrete to abstract components of the
schema onto images with vision-language models. The grounded schema is used to
augment visual abstraction understanding. We systematically evaluate DSG and
different methods in reasoning on our new Visual Abstractions Dataset, which
consists of diverse, real-world images of abstract concepts and corresponding
question-answer pairs labeled by humans. We show that DSG significantly
improves the abstract visual reasoning performance of vision-language models,
and is a step toward human-aligned understanding of visual abstractions.

摘要：人類視覺理解的獨特面向在於靈活詮釋抽象概念的能力：獲取解釋其象徵意義的提升規則，在熟悉和不熟悉的背景下奠定其基礎，並對其進行預測或推理。雖然現成的視覺語言模型擅長對影像進行字面詮釋（例如辨識樹枝等物體類別），但它們在理解此類視覺抽象概念時仍有困難（例如樹枝的排列如何形成迷宮的牆壁）。為了應對此挑戰，我們引入了深度模式基礎（DSG），這是一個框架，利用視覺抽象概念的明確結構化表示來進行基礎和推理。DSG 的核心是模式——抽象概念的依賴圖描述，將其分解為更原始層級的符號。DSG 使用大型語言模型來提取模式，然後將模式的具體組成部分分層基礎到影像上，並使用視覺語言模型。基礎模式用於擴充視覺抽象理解。我們系統性地評估了 DSG 和我們的新視覺抽象資料集上的不同推理方法，該資料集包含各種真實世界的抽象概念影像，以及由人類標記的對應問題解答對。我們證明 DSG 大幅提升了視覺語言模型的抽象視覺推理效能，並且朝著與人類一致的視覺抽象理解邁進一步。

##### **AudioBERT: Audio Knowledge Augmented Language Model**
2409.08199v1 by Hyunjong Ok, Suho Yoo, Jaeho Lee

Recent studies have identified that language models, pretrained on text-only
datasets, often lack elementary visual knowledge, \textit{e.g.,} colors of
everyday objects. Motivated by this observation, we ask whether a similar
shortcoming exists in terms of the \textit{auditory} knowledge. To answer this
question, we construct a new dataset called AuditoryBench, which consists of
two novel tasks for evaluating auditory knowledge. Based on our analysis using
the benchmark, we find that language models also suffer from a severe lack of
auditory knowledge. To address this limitation, we propose AudioBERT, a novel
method to augment the auditory knowledge of BERT through a retrieval-based
approach. First, we detect auditory knowledge spans in prompts to query our
retrieval model efficiently. Then, we inject audio knowledge into BERT and
switch on low-rank adaptation for effective adaptation when audio knowledge is
required. Our experiments demonstrate that AudioBERT is quite effective,
achieving superior performance on the AuditoryBench. The dataset and code are
available at \bulurl{https://github.com/HJ-Ok/AudioBERT}.

摘要：最近的研究發現，在純文字資料集上進行預訓練的語言模型，通常缺乏基本的視覺知識，例如日常物品的顏色。受此觀察結果的啟發，我們想知道在聽覺知識方面是否存在類似的缺點。為了回答這個問題，我們建構了一個名為 AuditoryBench 的新資料集，其中包含兩個評估聽覺知識的新穎任務。根據我們使用基準進行的分析，我們發現語言模型也嚴重缺乏聽覺知識。為了解決這個限制，我們提出了 AudioBERT，這是一種透過檢索為基礎的方法來擴充 BERT 聽覺知識的新方法。首先，我們在提示中偵測聽覺知識範圍，以有效查詢我們的檢索模型。然後，我們將音訊知識注入 BERT，並在需要音訊知識時開啟低階適應以進行有效的適應。我們的實驗證明 AudioBERT 非常有效，在 AuditoryBench 上取得優異的效能。資料集和程式碼可在 https://github.com/HJ-Ok/AudioBERT 取得。

##### **Fine-tuning Large Language Models for Entity Matching**
2409.08185v1 by Aaron Steiner, Ralph Peeters, Christian Bizer

Generative large language models (LLMs) are a promising alternative to
pre-trained language models for entity matching due to their high zero-shot
performance and their ability to generalize to unseen entities. Existing
research on using LLMs for entity matching has focused on prompt engineering
and in-context learning. This paper explores the potential of fine-tuning LLMs
for entity matching. We analyze fine-tuning along two dimensions: 1) The
representation of training examples, where we experiment with adding different
types of LLM-generated explanations to the training set, and 2) the selection
and generation of training examples using LLMs. In addition to the matching
performance on the source dataset, we investigate how fine-tuning affects the
model's ability to generalize to other in-domain datasets as well as across
topical domains. Our experiments show that fine-tuning significantly improves
the performance of the smaller models while the results for the larger models
are mixed. Fine-tuning also improves the generalization to in-domain datasets
while hurting cross-domain transfer. We show that adding structured
explanations to the training set has a positive impact on the performance of
three out of four LLMs, while the proposed example selection and generation
methods only improve the performance of Llama 3.1 8B while decreasing the
performance of GPT-4o Mini.

摘要：生成式大型語言模型 (LLM) 由於其高零次學習表現以及對未見實體進行泛化的能力，是實體配對中預先訓練語言模型的有希望的替代方案。現有關於使用 LLM 進行實體配對的研究已專注於提示工程和情境學習。本文探討了微調 LLM 以進行實體配對的潛力。我們沿著兩個面向分析微調：1) 訓練範例的表徵，我們在其中嘗試將不同類型的 LLM 生成的說明新增到訓練組，以及 2) 使用 LLM 選擇和產生訓練範例。除了在來源資料集上的配對效能之外，我們探討微調如何影響模型對其他領域內資料集以及跨主題領域進行泛化的能力。我們的實驗顯示，微調顯著提升較小型模型的效能，而較大型模型的結果則好壞參半。微調也提升了對領域內資料集的泛化，同時損害了跨領域轉移。我們顯示，將結構化說明新增到訓練組對四個 LLM 中的三個的效能有正面的影響，而所提出的範例選擇和產生方法僅提升了 Llama 3.1 8B 的效能，同時降低了 GPT-4o Mini 的效能。

##### **On the Role of Context in Reading Time Prediction**
2409.08160v1 by Andreas Opedal, Eleanor Chodroff, Ryan Cotterell, Ethan Gotlieb Wilcox

We present a new perspective on how readers integrate context during
real-time language comprehension. Our proposals build on surprisal theory,
which posits that the processing effort of a linguistic unit (e.g., a word) is
an affine function of its in-context information content. We first observe that
surprisal is only one out of many potential ways that a contextual predictor
can be derived from a language model. Another one is the pointwise mutual
information (PMI) between a unit and its context, which turns out to yield the
same predictive power as surprisal when controlling for unigram frequency.
Moreover, both PMI and surprisal are correlated with frequency. This means that
neither PMI nor surprisal contains information about context alone. In response
to this, we propose a technique where we project surprisal onto the orthogonal
complement of frequency, yielding a new contextual predictor that is
uncorrelated with frequency. Our experiments show that the proportion of
variance in reading times explained by context is a lot smaller when context is
represented by the orthogonalized predictor. From an interpretability
standpoint, this indicates that previous studies may have overstated the role
that context has in predicting reading times.

摘要：我們提出了一個新的觀點，說明讀者如何在實時語言理解過程中整合脈絡。我們的提案建立在驚奇理論之上，該理論假設語言單元（例如單詞）的處理工作量是其上下文信息內容的仿射函數。我們首先觀察到，驚奇只是從語言模型中推導上下文預測器的許多潛在方法之一。另一種方法是單元及其上下文之間的逐點互信息 (PMI)，當控制單字頻率時，它產生的預測能力與驚奇相同。此外，PMI 和驚奇都與頻率相關。這表示 PMI 和驚奇都不包含僅關於脈絡的信息。針對此問題，我們提出了一種技術，將驚奇投影到頻率的正交補集上，產生一個與頻率無關的新上下文預測器。我們的實驗表明，當脈絡由正交化預測器表示時，閱讀時間中由脈絡解釋的變異比例要小得多。從可解釋性的角度來看，這表明先前的研究可能誇大了脈絡在預測閱讀時間中所扮演的角色。

##### **LLM-POTUS Score: A Framework of Analyzing Presidential Debates with Large Language Models**
2409.08147v1 by Zhengliang Liu, Yiwei Li, Oleksandra Zolotarevych, Rongwei Yang, Tianming Liu

Large language models have demonstrated remarkable capabilities in natural
language processing, yet their application to political discourse analysis
remains underexplored. This paper introduces a novel approach to evaluating
presidential debate performances using LLMs, addressing the longstanding
challenge of objectively assessing debate outcomes. We propose a framework that
analyzes candidates' "Policies, Persona, and Perspective" (3P) and how they
resonate with the "Interests, Ideologies, and Identity" (3I) of four key
audience groups: voters, businesses, donors, and politicians. Our method
employs large language models to generate the LLM-POTUS Score, a quantitative
measure of debate performance based on the alignment between 3P and 3I. We
apply this framework to analyze transcripts from recent U.S. presidential
debates, demonstrating its ability to provide nuanced, multi-dimensional
assessments of candidate performances. Our results reveal insights into the
effectiveness of different debating strategies and their impact on various
audience segments. This study not only offers a new tool for political analysis
but also explores the potential and limitations of using LLMs as impartial
judges in complex social contexts. In addition, this framework provides
individual citizens with an independent tool to evaluate presidential debate
performances, which enhances democratic engagement and reduces reliance on
potentially biased media interpretations and institutional influence, thereby
strengthening the foundation of informed civic participation.

摘要：大型語言模型在自然語言處理中展現了非凡的能力，但其應用於政治論述分析仍未得到充分探討。本文介紹了一種使用大型語言模型評估總統辯論表現的新穎方法，以解決客觀評估辯論結果的長期挑戰。我們提出了分析候選人的「政策、人格和觀點」(3P) 的架構，以及它們如何與四個主要受眾群體：「選民、企業、捐助者和政治家」的「利益、意識形態和認同」(3I) 產生共鳴。我們的模型採用大型語言模型來產生 LLM-POTUS 分數，這是一個基於 3P 和 3I 之間的一致性的辯論表現量化測量。我們將此架構應用於分析最近美國總統辯論的逐字稿，證明了它提供細緻、多維度候選人表現評估的能力。我們的結果揭示了對不同辯論策略的有效性及其對不同受眾群體的影響的見解。本研究不僅提供了政治分析的新工具，還探討了在複雜的社會環境中使用大型語言模型作為公正評判的潛力和局限性。此外，此架構為個人公民提供了一個獨立工具來評估總統辯論表現，這增強了民主參與，減少了對潛在有偏見的媒體解讀和制度影響的依賴，從而加強了知情公民參與的基礎。

##### **Towards a graph-based foundation model for network traffic analysis**
2409.08111v1 by Louis Van Langendonck, Ismael Castell-Uroz, Pere Barlet-Ros

Foundation models have shown great promise in various fields of study. A
potential application of such models is in computer network traffic analysis,
where these models can grasp the complexities of network traffic dynamics and
adapt to any specific task or network environment with minimal fine-tuning.
Previous approaches have used tokenized hex-level packet data and the model
architecture of large language transformer models. We propose a new, efficient
graph-based alternative at the flow-level. Our approach represents network
traffic as a dynamic spatio-temporal graph, employing a self-supervised link
prediction pretraining task to capture the spatial and temporal dynamics in
this network graph framework. To evaluate the effectiveness of our approach, we
conduct a few-shot learning experiment for three distinct downstream network
tasks: intrusion detection, traffic classification, and botnet classification.
Models finetuned from our pretrained base achieve an average performance
increase of 6.87\% over training from scratch, demonstrating their ability to
effectively learn general network traffic dynamics during pretraining. This
success suggests the potential for a large-scale version to serve as an
operational foundational model.

摘要：基礎模型已在各個研究領域中展現出極大的前景。此類模型的潛在應用之一在於電腦網路流量分析，其中這些模型可以掌握網路流量動態的複雜性，並以最小的微調適應任何特定任務或網路環境。先前的做法已使用標記化十六進位層級封包資料和大型語言轉換器模型的模型架構。我們提出一個新的、有效的流程層級圖形化替代方案。我們的做法將網路流量表示為動態時空圖形，採用自我監督連結預測預訓練任務來捕捉此網路圖形架構中的空間和時間動態。為了評估我們做法的有效性，我們對三個不同的下游網路任務（入侵偵測、流量分類和殭屍網路分類）進行少量學習實驗。從我們的預訓練基礎微調的模型，其平均效能提升 6.87%，高於從頭訓練，這證明了它們在預訓練期間有效學習一般網路流量動態的能力。這項成功顯示出大規模版本有潛力作為運作基礎模型。

##### **WhisperNER: Unified Open Named Entity and Speech Recognition**
2409.08107v1 by Gil Ayache, Menachem Pirchi, Aviv Navon, Aviv Shamsian, Gill Hetz, Joseph Keshet

Integrating named entity recognition (NER) with automatic speech recognition
(ASR) can significantly enhance transcription accuracy and informativeness. In
this paper, we introduce WhisperNER, a novel model that allows joint speech
transcription and entity recognition. WhisperNER supports open-type NER,
enabling recognition of diverse and evolving entities at inference. Building on
recent advancements in open NER research, we augment a large synthetic dataset
with synthetic speech samples. This allows us to train WhisperNER on a large
number of examples with diverse NER tags. During training, the model is
prompted with NER labels and optimized to output the transcribed utterance
along with the corresponding tagged entities. To evaluate WhisperNER, we
generate synthetic speech for commonly used NER benchmarks and annotate
existing ASR datasets with open NER tags. Our experiments demonstrate that
WhisperNER outperforms natural baselines on both out-of-domain open type NER
and supervised finetuning.

摘要：整合命名實體辨識 (NER) 與自動語音辨識 (ASR) 能夠大幅提升轉錄的準確度和資訊量。在這篇論文中，我們介紹了 WhisperNER，一種新穎的模型，可同時進行語音轉錄和實體辨識。WhisperNER 支援開放式 NER，可在推論時辨識出多樣且不斷演進的實體。建構在開放式 NER 研究的最新進展上，我們擴充了一個大型合成資料集，加入了合成語音範例。這讓我們能夠使用大量標有不同 NER 標籤的範例訓練 WhisperNER。在訓練期間，模型會提示 NER 標籤，並最佳化輸出轉錄的語句以及對應標記的實體。為了評估 WhisperNER，我們為常用的 NER 基準產生合成語音，並使用開放式 NER 標籤註解現有的 ASR 資料集。我們的實驗證明，WhisperNER 在開放式 NER 和監督式微調的非領域外任務上都優於自然基準。

##### **The Faetar Benchmark: Speech Recognition in a Very Under-Resourced Language**
2409.08103v1 by Michael Ong, Sean Robertson, Leo Peckham, Alba Jorquera Jimenez de Aberasturi, Paula Arkhangorodsky, Robin Huo, Aman Sakhardande, Mark Hallap, Naomi Nagy, Ewan Dunbar

We introduce the Faetar Automatic Speech Recognition Benchmark, a benchmark
corpus designed to push the limits of current approaches to low-resource speech
recognition. Faetar, a Franco-Proven\c{c}al variety spoken primarily in Italy,
has no standard orthography, has virtually no existing textual or speech
resources other than what is included in the benchmark, and is quite different
from other forms of Franco-Proven\c{c}al. The corpus comes from field
recordings, most of which are noisy, for which only 5 hrs have matching
transcriptions, and for which forced alignment is of variable quality. The
corpus contains an additional 20 hrs of unlabelled speech. We report baseline
results from state-of-the-art multilingual speech foundation models with a best
phone error rate of 30.4%, using a pipeline that continues pre-training on the
foundation model using the unlabelled set.

摘要：我們介紹 Faetar 自動語音辨識基準，一個基準語料庫旨在突破當前低資源語音辨識方法的限制。Faetar，一種主要在義大利使用的法蘭克-普羅旺斯語變體，沒有標準正字法，除了包含在基準中的內容外，幾乎沒有現有的文字或語音資源，並且與法蘭克-普羅旺斯語的其他形式相當不同。語料庫來自現場錄音，其中大部分有雜訊，只有 5 小時有匹配的轉錄，而且強制對齊的品質參差不齊。語料庫包含額外 20 小時的未標記語音。我們報告了最先進的多語言語音基礎模型的基準結果，使用在基礎模型上使用未標記集合繼續預訓練的管道，最佳音素錯誤率為 30.4%。

##### **The CLC-UKET Dataset: Benchmarking Case Outcome Prediction for the UK Employment Tribunal**
2409.08098v1 by Huiyuan Xie, Felix Steffek, Joana Ribeiro de Faria, Christine Carter, Jonathan Rutherford

This paper explores the intersection of technological innovation and access
to justice by developing a benchmark for predicting case outcomes in the UK
Employment Tribunal (UKET). To address the challenge of extensive manual
annotation, the study employs a large language model (LLM) for automatic
annotation, resulting in the creation of the CLC-UKET dataset. The dataset
consists of approximately 19,000 UKET cases and their metadata. Comprehensive
legal annotations cover facts, claims, precedent references, statutory
references, case outcomes, reasons and jurisdiction codes. Facilitated by the
CLC-UKET data, we examine a multi-class case outcome prediction task in the
UKET. Human predictions are collected to establish a performance reference for
model comparison. Empirical results from baseline models indicate that
finetuned transformer models outperform zero-shot and few-shot LLMs on the UKET
prediction task. The performance of zero-shot LLMs can be enhanced by
integrating task-related information into few-shot examples. We hope that the
CLC-UKET dataset, along with human annotations and empirical findings, can
serve as a valuable benchmark for employment-related dispute resolution.

摘要：本文探討了科技創新與司法正義的交集，方法是為英國就業法庭（UKET）的案件結果建立一個基準來預測。為了應對大量手動註解的挑戰，本研究採用大型語言模型（LLM）進行自動註解，進而建立 CLC-UKET 資料集。該資料集包含約 19,000 件英國就業法庭案件及其元資料。全面的法律註解涵蓋事實、主張、判例引用、法定引用、案件結果、理由和司法管轄代碼。在 CLC-UKET 資料的協助下，我們檢視了英國就業法庭中的多類案件結果預測任務。收集人類預測以建立模型比較效能的基準。基準模型的實證結果顯示，微調的轉換器模型在英國就業法庭預測任務上優於零次學習和少次學習的 LLM。零次學習 LLM 的效能可透過將與任務相關的資訊整合到少次學習範例中來提升。我們希望 CLC-UKET 資料集，連同人類註解和實證發現，能作為與就業相關的爭端解決的寶貴基準。

##### **TravelAgent: An AI Assistant for Personalized Travel Planning**
2409.08069v1 by Aili Chen, Xuyang Ge, Ziquan Fu, Yanghua Xiao, Jiangjie Chen

As global tourism expands and artificial intelligence technology advances,
intelligent travel planning services have emerged as a significant research
focus. Within dynamic real-world travel scenarios with multi-dimensional
constraints, services that support users in automatically creating practical
and customized travel itineraries must address three key objectives:
Rationality, Comprehensiveness, and Personalization. However, existing systems
with rule-based combinations or LLM-based planning methods struggle to fully
satisfy these criteria. To overcome the challenges, we introduce TravelAgent, a
travel planning system powered by large language models (LLMs) designed to
provide reasonable, comprehensive, and personalized travel itineraries grounded
in dynamic scenarios. TravelAgent comprises four modules: Tool-usage,
Recommendation, Planning, and Memory Module. We evaluate TravelAgent's
performance with human and simulated users, demonstrating its overall
effectiveness in three criteria and confirming the accuracy of personalized
recommendations.

摘要：隨著全球旅遊業的擴張和人工智慧技術的進步，
智慧型旅遊規劃服務已成為重要的研究重點。在具有多維度限制的動態真實世界旅遊場景中，支援使用者自動建立實用且客製化的旅遊行程的服務必須解決三個關鍵目標：合理性、全面性、個人化。然而，現有基於規則組合或 LLM 的規劃方法的系統難以完全滿足這些標準。為了克服這些挑戰，我們引入了 TravelAgent，一個由大型語言模型 (LLM) 支援的旅遊規劃系統，旨在提供合理、全面且個人化的旅遊行程，並以動態場景為基礎。TravelAgent 包含四個模組：工具使用、推薦、規劃和記憶體模組。我們透過人類和模擬使用者評估 TravelAgent 的效能，證明其在三個標準中的整體效能，並確認個人化建議的準確性。

##### **AI-accelerated discovery of high critical temperature superconductors**
2409.08065v1 by Xiao-Qi Han, Zhenfeng Ouyang, Peng-Jie Guo, Hao Sun, Ze-Feng Gao, Zhong-Yi Lu

The discovery of new superconducting materials, particularly those exhibiting
high critical temperature ($T_c$), has been a vibrant area of study within the
field of condensed matter physics. Conventional approaches primarily rely on
physical intuition to search for potential superconductors within the existing
databases. However, the known materials only scratch the surface of the
extensive array of possibilities within the realm of materials. Here, we
develop an AI search engine that integrates deep model pre-training and
fine-tuning techniques, diffusion models, and physics-based approaches (e.g.,
first-principles electronic structure calculation) for discovery of high-$T_c$
superconductors. Utilizing this AI search engine, we have obtained 74
dynamically stable materials with critical temperatures predicted by the AI
model to be $T_c \geq$ 15 K based on a very small set of samples. Notably,
these materials are not contained in any existing dataset. Furthermore, we
analyze trends in our dataset and individual materials including B$_4$CN$_3$
and B$_5$CN$_2$ whose $T_c$s are 24.08 K and 15.93 K, respectively. We
demonstrate that AI technique can discover a set of new high-$T_c$
superconductors, outline its potential for accelerating discovery of the
materials with targeted properties.

摘要：新超導材料的發現，特別是那些表現出高臨界溫度 ($T_c$) 的材料，一直是凝聚態物理學領域中一個充滿活力的研究領域。傳統方法主要依賴於物理直覺，在現有資料庫中搜尋潛在的超導體。然而，已知的材料僅觸及材料領域內廣泛可能性的表面。在這裡，我們開發了一個 AI 搜尋引擎，它整合了深度模型預訓練和微調技術、擴散模型和基於物理的方法（例如，第一原理電子結構計算），用於發現高 $T_c$ 超導體。利用這個 AI 搜尋引擎，我們已經獲得了 74 種動態穩定材料，其臨界溫度由 AI 模型預測為 $T_c \ge$ 15 K，基於非常小的樣本集。值得注意的是，這些材料不包含在任何現有資料集中。此外，我們分析了我們資料集和個別材料（包括 B$_4$CN$_3$ 和 B$_5$CN$_2$）的趨勢，其 $T_c$ 分別為 24.08 K 和 15.93 K。我們證明了 AI 技術可以發現一組新的高 $T_c$ 超導體，概述了其加速發現具有目標特性的材料的潛力。

##### **Unleashing Worms and Extracting Data: Escalating the Outcome of Attacks against RAG-based Inference in Scale and Severity Using Jailbreaking**
2409.08045v1 by Stav Cohen, Ron Bitton, Ben Nassi

In this paper, we show that with the ability to jailbreak a GenAI model,
attackers can escalate the outcome of attacks against RAG-based GenAI-powered
applications in severity and scale. In the first part of the paper, we show
that attackers can escalate RAG membership inference attacks and RAG entity
extraction attacks to RAG documents extraction attacks, forcing a more severe
outcome compared to existing attacks. We evaluate the results obtained from
three extraction methods, the influence of the type and the size of five
embeddings algorithms employed, the size of the provided context, and the GenAI
engine. We show that attackers can extract 80%-99.8% of the data stored in the
database used by the RAG of a Q&A chatbot. In the second part of the paper, we
show that attackers can escalate the scale of RAG data poisoning attacks from
compromising a single GenAI-powered application to compromising the entire
GenAI ecosystem, forcing a greater scale of damage. This is done by crafting an
adversarial self-replicating prompt that triggers a chain reaction of a
computer worm within the ecosystem and forces each affected application to
perform a malicious activity and compromise the RAG of additional applications.
We evaluate the performance of the worm in creating a chain of confidential
data extraction about users within a GenAI ecosystem of GenAI-powered email
assistants and analyze how the performance of the worm is affected by the size
of the context, the adversarial self-replicating prompt used, the type and size
of the embeddings algorithm employed, and the number of hops in the
propagation. Finally, we review and analyze guardrails to protect RAG-based
inference and discuss the tradeoffs.

摘要：<paragraph>在本文中，我們展示了攻擊者可以利用越獄 GenAI 模型的能力，提升針對基於 RAG 的 GenAI 驅動應用程式的攻擊結果的嚴重性和規模。在本文的第一部分，我們展示了攻擊者可以將 RAG 會員推論攻擊和 RAG 實體抽取攻擊提升到 RAG 文件抽取攻擊，與現有攻擊相比，這會造成更嚴重的後果。我們評估了從三種抽取方法獲得的結果、所使用的五種嵌入演算法的類型和大小、提供的內容大小以及 GenAI 引擎的影響。我們展示了攻擊者可以抽取 Q&A 聊天機器人的 RAG 所使用的資料庫中儲存的 80%-99.8% 的資料。在本文的第二部分，我們展示了攻擊者可以將 RAG 資料投毒攻擊的規模從危害單一 GenAI 驅動應用程式提升到危害整個 GenAI 生態系統，造成更大規模的損害。這是透過製作一個對抗性的自我複製提示來完成的，該提示會在生態系統中觸發電腦蠕蟲的連鎖反應，並迫使每個受影響的應用程式執行惡意活動並危害其他應用程式的 RAG。我們評估了蠕蟲在 GenAI 驅動電子郵件助理的 GenAI 生態系統中建立機密資料抽取鏈的效能，並分析蠕蟲的效能如何受到內容大小、所使用的對抗性自我複製提示、所使用的嵌入演算法的類型和大小以及傳播中的跳躍次數的影響。最後，我們檢視並分析了保護基於 RAG 的推論的護欄，並討論了權衡取捨。</paragraph>

##### **Enhancing Few-Shot Image Classification through Learnable Multi-Scale Embedding and Attention Mechanisms**
2409.07989v1 by Fatemeh Askari, Amirreza Fateh, Mohammad Reza Mohammadi

In the context of few-shot classification, the goal is to train a classifier
using a limited number of samples while maintaining satisfactory performance.
However, traditional metric-based methods exhibit certain limitations in
achieving this objective. These methods typically rely on a single distance
value between the query feature and support feature, thereby overlooking the
contribution of shallow features. To overcome this challenge, we propose a
novel approach in this paper. Our approach involves utilizing multi-output
embedding network that maps samples into distinct feature spaces. The proposed
method extract feature vectors at different stages, enabling the model to
capture both global and abstract features. By utilizing these diverse feature
spaces, our model enhances its performance. Moreover, employing a
self-attention mechanism improves the refinement of features at each stage,
leading to even more robust representations and improved overall performance.
Furthermore, assigning learnable weights to each stage significantly improved
performance and results. We conducted comprehensive evaluations on the
MiniImageNet and FC100 datasets, specifically in the 5-way 1-shot and 5-way
5-shot scenarios. Additionally, we performed a cross-domain task from
MiniImageNet to the CUB dataset, achieving high accuracy in the testing domain.
These evaluations demonstrate the efficacy of our proposed method in comparison
to state-of-the-art approaches. https://github.com/FatemehAskari/MSENet

摘要：在小样本分类的背景下，目标是使用有限数量的样本训练分类器，同时保持令人满意的性能。然而，传统的基于度量的模型在实现这一目标时表现出一定的局限性。这些方法通常依赖于查询特征和支持特征之间的单个距离值，从而忽略了浅层特征的贡献。为了克服这一挑战，我们在本文中提出了一种新颖的方法。我们的方法涉及利用将样本映射到不同特征空间的多输出嵌入网络。所提出的方法在不同的阶段提取特征向量，使模型能够捕捉全局和抽象特征。通过利用这些不同的特征空间，我们的模型增强了其性能。此外，采用自注意力机制改进了每个阶段的特征细化，从而产生了更鲁棒的表示并提高了整体性能。此外，为每个阶段分配可学习的权重显著提高了性能和结果。我们对 MiniImageNet 和 FC100 数据集进行了全面的评估，特别是在 5-way 1-shot 和 5-way 5-shot 场景中。此外，我们从 MiniImageNet 执行了一个跨域任务到 CUB 数据集，在测试域中实现了高精度。这些评估证明了我们提出的方法与最先进的方法相比的有效性。https://github.com/FatemehAskari/MSENet

##### **Games for AI Control: Models of Safety Evaluations of AI Deployment Protocols**
2409.07985v1 by Charlie Griffin, Louis Thomson, Buck Shlegeris, Alessandro Abate

To evaluate the safety and usefulness of deployment protocols for untrusted
AIs, AI Control uses a red-teaming exercise played between a protocol designer
and an adversary. This paper introduces AI-Control Games, a formal
decision-making model of the red-teaming exercise as a multi-objective,
partially observable, stochastic game. We also introduce methods for finding
optimal protocols in AI-Control Games, by reducing them to a set of zero-sum
partially observable stochastic games. We apply our formalism to model,
evaluate and synthesise protocols for deploying untrusted language models as
programming assistants, focusing on Trusted Monitoring protocols, which use
weaker language models and limited human assistance. Finally, we demonstrate
the utility of our formalism by showcasing improvements over empirical studies
in existing settings, evaluating protocols in new settings, and analysing how
modelling assumptions affect the safety and usefulness of protocols.

摘要：為了評估不信任 AI 的部署協定的安全性與實用性，AI 控制使用紅隊演習，由協定設計者與對手之間進行。本文介紹 AI 控制遊戲，作為紅隊演習的多目標、部分可觀察、隨機遊戲的正式決策模型。我們也介紹在 AI 控制遊戲中尋找最佳協定的方法，方法是將其簡化為一組零和部分可觀察隨機遊戲。我們將形式主義應用於建模、評估和綜合部署不信任語言模型的協定，作為程式設計助理，重點放在受信任監控協定，使用較弱的語言模型和有限的人工協助。最後，我們展示形式主義的實用性，展示對現有設定中經驗研究的改進、評估新設定中的協定，以及分析建模假設如何影響協定的安全性與實用性。

##### **ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE**
2409.07966v1 by Sichun Wu, Kazi Injamamul Haque, Zerrin Yumak

Audio-driven 3D facial animation synthesis has been an active field of
research with attention from both academia and industry. While there are
promising results in this area, recent approaches largely focus on lip-sync and
identity control, neglecting the role of emotions and emotion control in the
generative process. That is mainly due to the lack of emotionally rich facial
animation data and algorithms that can synthesize speech animations with
emotional expressions at the same time. In addition, majority of the models are
deterministic, meaning given the same audio input, they produce the same output
motion. We argue that emotions and non-determinism are crucial to generate
diverse and emotionally-rich facial animations. In this paper, we propose
ProbTalk3D a non-deterministic neural network approach for emotion controllable
speech-driven 3D facial animation synthesis using a two-stage VQ-VAE model and
an emotionally rich facial animation dataset 3DMEAD. We provide an extensive
comparative analysis of our model against the recent 3D facial animation
synthesis approaches, by evaluating the results objectively, qualitatively, and
with a perceptual user study. We highlight several objective metrics that are
more suitable for evaluating stochastic outputs and use both in-the-wild and
ground truth data for subjective evaluation. To our knowledge, that is the
first non-deterministic 3D facial animation synthesis method incorporating a
rich emotion dataset and emotion control with emotion labels and intensity
levels. Our evaluation demonstrates that the proposed model achieves superior
performance compared to state-of-the-art emotion-controlled, deterministic and
non-deterministic models. We recommend watching the supplementary video for
quality judgement. The entire codebase is publicly available
(https://github.com/uuembodiedsocialai/ProbTalk3D/).

摘要：<paragraph>音频驱动的 3D 面部动画合成一直是学术界和产业界关注的一个活跃的研究领域。虽然该领域有令人振奋的研究成果，但最近的方法主要集中在唇形同步和身份控制上，忽略了情感和情感控制在生成过程中的作用。这主要是因为缺乏情感丰富的面部动画数据和能够同时合成具有情感表达的语音动画的算法。此外，大多数模型都是确定性的，这意味着给定相同的音频输入，它们会产生相同的输出动作。我们认为，情感和非确定性对于生成多样化且情感丰富的面部动画至关重要。在本文中，我们提出了 ProbTalk3D，这是一种非确定性神经网络方法，用于使用两阶段 VQ-VAE 模型和情感丰富的面部动画数据集 3DMEAD 进行情感可控的语音驱动的 3D 面部动画合成。我们通过客观、定性和感知用户研究评估结果，对我们的模型与最近的 3D 面部动画合成方法进行了广泛的比较分析。我们重点介绍了几个更适合评估随机输出的目标指标，并在主观评估中使用了野外数据和真实数据。据我们所知，这是第一种非确定性 3D 面部动画合成方法，它结合了丰富的表情数据集和带有表情标签和强度等级的表情控制。我们的评估表明，与最先进的情感控制、确定性和非确定性模型相比，所提出的模型取得了卓越的性能。我们建议观看补充视频以进行质量判断。整个代码库已公开（https://github.com/uuembodiedsocialai/ProbTalk3D/）。</paragraph>

##### **WirelessAgent: Large Language Model Agents for Intelligent Wireless Networks**
2409.07964v1 by Jingwen Tong, Jiawei Shao, Qiong Wu, Wei Guo, Zijian Li, Zehong Lin, Jun Zhang

Wireless networks are increasingly facing challenges due to their expanding
scale and complexity. These challenges underscore the need for advanced
AI-driven strategies, particularly in the upcoming 6G networks. In this
article, we introduce WirelessAgent, a novel approach leveraging large language
models (LLMs) to develop AI agents capable of managing complex tasks in
wireless networks. It can effectively improve network performance through
advanced reasoning, multimodal data processing, and autonomous decision making.
Thereafter, we demonstrate the practical applicability and benefits of
WirelessAgent for network slicing management. The experimental results show
that WirelessAgent is capable of accurately understanding user intent,
effectively allocating slice resources, and consistently maintaining optimal
performance.

摘要：隨著無線網路規模與複雜度的擴張，無線網路面臨的挑戰越來越多。這些挑戰凸顯出對先進 AI 驅動策略的需求，特別是在即將到來的 6G 網路中。在本文中，我們介紹 WirelessAgent，這是一種利用大型語言模型 (LLM) 來開發 AI 代理的新方法，此代理能夠管理無線網路中的複雜任務。它可以透過先進的推理、多模態數據處理和自主決策制定，有效地改善網路效能。隨後，我們展示 WirelessAgent 在網路切片管理中的實際適用性和好處。實驗結果顯示，WirelessAgent 能夠準確理解使用者意圖、有效分配切片資源，並持續維持最佳效能。

##### **Enhanced Online Grooming Detection Employing Context Determination and Message-Level Analysis**
2409.07958v1 by Jake Street, Isibor Ihianle, Funminiyi Olajide, Ahmad Lotfi

Online Grooming (OG) is a prevalent threat facing predominately children
online, with groomers using deceptive methods to prey on the vulnerability of
children on social media/messaging platforms. These attacks can have severe
psychological and physical impacts, including a tendency towards
revictimization. Current technical measures are inadequate, especially with the
advent of end-to-end encryption which hampers message monitoring. Existing
solutions focus on the signature analysis of child abuse media, which does not
effectively address real-time OG detection. This paper proposes that OG attacks
are complex, requiring the identification of specific communication patterns
between adults and children. It introduces a novel approach leveraging advanced
models such as BERT and RoBERTa for Message-Level Analysis and a Context
Determination approach for classifying actor interactions, including the
introduction of Actor Significance Thresholds and Message Significance
Thresholds. The proposed method aims to enhance accuracy and robustness in
detecting OG by considering the dynamic and multi-faceted nature of these
attacks. Cross-dataset experiments evaluate the robustness and versatility of
our approach. This paper's contributions include improved detection
methodologies and the potential for application in various scenarios,
addressing gaps in current literature and practices.

摘要：網路誘騙（OG）是一種普遍的威脅，主要針對兒童，誘騙者使用欺騙性方法在社群媒體／傳訊平台上利用兒童的弱點。這些攻擊可能造成嚴重的生理和心理影響，包括容易再次受害。目前的技術措施不足，特別是在端對端加密的出現阻礙了訊息監控。現有的解決方案專注於兒童性虐待媒體的簽名分析，無法有效解決即時 OG 偵測。本文提出 OG 攻擊很複雜，需要找出成人和兒童之間的特定溝通模式。本文介紹一種新方法，利用 BERT 和 RoBERTa 等進階模型進行訊息層級分析，以及一種情境判斷方法，用於分類參與者的互動，包括引入參與者顯著性閾值和訊息顯著性閾值。提出的方法旨在透過考量這些攻擊的動態和多面向性質來提升偵測 OG 的準確性和穩健性。跨資料集實驗評估了我們方法的穩健性和多樣性。本文的貢獻包括改良的偵測方法，以及在各種情境中應用的潛力，解決了目前文獻和實務中的差距。

##### **Reinforcement Learning Discovers Efficient Decentralized Graph Path Search Strategies**
2409.07932v1 by Alexei Pisacane, Victor-Alexandru Darvariu, Mirco Musolesi

Graph path search is a classic computer science problem that has been
recently approached with Reinforcement Learning (RL) due to its potential to
outperform prior methods. Existing RL techniques typically assume a global view
of the network, which is not suitable for large-scale, dynamic, and
privacy-sensitive settings. An area of particular interest is search in social
networks due to its numerous applications. Inspired by seminal work in
experimental sociology, which showed that decentralized yet efficient search is
possible in social networks, we frame the problem as a collaborative task
between multiple agents equipped with a limited local view of the network. We
propose a multi-agent approach for graph path search that successfully
leverages both homophily and structural heterogeneity. Our experiments, carried
out over synthetic and real-world social networks, demonstrate that our model
significantly outperforms learned and heuristic baselines. Furthermore, our
results show that meaningful embeddings for graph navigation can be constructed
using reward-driven learning.

摘要：圖形路徑搜尋是一個經典的電腦科學問題，最近已透過強化學習 (RL) 來處理，因為它有超越先前方法的潛力。現有的 RL 技術通常假設網路的全局觀點，這不適合於大規模、動態和注重隱私的設定。一個特別感興趣的領域是社群網路中的搜尋，因為它的應用很廣泛。受到實驗社會學中具有開創性的研究啟發，該研究顯示在社群網路中分散但有效率的搜尋是可行的，我們將問題設定為多個具備網路有限局部觀點的代理之間的協作任務。我們提出一個圖形路徑搜尋的多代理方法，成功地同時利用同質性和結構異質性。我們的實驗在合成和真實世界的社群網路中進行，證明我們的模型明顯優於已學習和啟發式的基準。此外，我們的結果顯示，可以用獎勵驅動的學習來建構有意義的圖形導航嵌入。

##### **A convolutional neural network approach to deblending seismic data**
2409.07930v1 by Jing Sun, Sigmund Slang, Thomas Elboth, Thomas Larsen Greiner, Steven McDonald, Leiv-J Gelius

For economic and efficiency reasons, blended acquisition of seismic data is
becoming more and more commonplace. Seismic deblending methods are always
computationally demanding and normally consist of multiple processing steps.
Besides, the parameter setting is not always trivial. Machine learning-based
processing has the potential to significantly reduce processing time and to
change the way seismic deblending is carried out. We present a data-driven deep
learning-based method for fast and efficient seismic deblending. The blended
data are sorted from the common source to the common channel domain to
transform the character of the blending noise from coherent events to
incoherent distributions. A convolutional neural network (CNN) is designed
according to the special character of seismic data, and performs deblending
with comparable results to those obtained with conventional industry deblending
algorithms. To ensure authenticity, the blending was done numerically and only
field seismic data were employed, including more than 20000 training examples.
After training and validation of the network, seismic deblending can be
performed in near real time. Experiments also show that the initial signal to
noise ratio (SNR) is the major factor controlling the quality of the final
deblended result. The network is also demonstrated to be robust and adaptive by
using the trained model to firstly deblend a new data set from a different
geological area with a slightly different delay time setting, and secondly
deblend shots with blending noise in the top part of the data.

摘要：<paragraph>基於經濟和效率考量，混合式地震資料取得正變得越來越普遍。地震去混合方法通常在計算上要求很高，且通常包含多個處理步驟。此外，參數設定並不總是微不足道的。基於機器學習的處理有潛力顯著減少處理時間，並改變地震去混合的執行方式。我們提出一個資料驅動的深度學習方法，用於快速且有效率的地震去混合。混合資料從共用來源排序到共用通道網域，將混合雜訊的特性從相干事件轉換為非相干分佈。根據地震資料的特殊特性設計了一個卷積神經網路 (CNN)，並執行去混合，其結果可與傳統產業去混合演算法所獲得的結果相提並論。為了確保真實性，混合是以數值方式完成，且僅採用現場地震資料，其中包含超過 20000 個訓練範例。在網路訓練和驗證後，地震去混合可以在近乎即時的情況下執行。實驗也顯示，初始訊號雜訊比 (SNR) 是控制最終去混合結果品質的主要因素。透過使用訓練好的模型，首先去混合來自不同地質區域的新資料集，並使用稍微不同的延遲時間設定，其次去混合資料頂部具有混合雜訊的射擊，證明了該網路的強健性和適應性。</paragraph>

##### **A framework for measuring the training efficiency of a neural architecture**
2409.07925v1 by Eduardo Cueto-Mendoza, John D. Kelleher

Measuring Efficiency in neural network system development is an open research
problem. This paper presents an experimental framework to measure the training
efficiency of a neural architecture. To demonstrate our approach, we analyze
the training efficiency of Convolutional Neural Networks and Bayesian
equivalents on the MNIST and CIFAR-10 tasks. Our results show that training
efficiency decays as training progresses and varies across different stopping
criteria for a given neural model and learning task. We also find a non-linear
relationship between training stopping criteria, training Efficiency, model
size, and training Efficiency.
  Furthermore, we illustrate the potential confounding effects of overtraining
on measuring the training efficiency of a neural architecture. Regarding
relative training efficiency across different architectures, our results
indicate that CNNs are more efficient than BCNNs on both datasets. More
generally, as a learning task becomes more complex, the relative difference in
training efficiency between different architectures becomes more pronounced.

摘要：神經網路系統開發中，衡量效率是一個開放的研究問題。本文提出了一個實驗架構，用於衡量神經架構的訓練效率。為了展示我們的做法，我們分析了卷積神經網路和貝氏等價在 MNIST 和 CIFAR-10 任務上的訓練效率。我們的結果顯示，訓練效率會隨著訓練進度而衰減，並且會根據給定神經模型和學習任務的不同停止準則而有所不同。我們還發現訓練停止準則、訓練效率、模型大小和訓練效率之間存在非線性關係。此外，我們說明了過度訓練對衡量神經架構訓練效率的潛在混淆影響。關於不同架構之間的相對訓練效率，我們的結果表明，CNN 在兩個資料集上都比 BCNN 更有效率。更一般地說，隨著學習任務變得更複雜，不同架構之間的訓練效率相對差異變得更加明顯。

##### **Tidal MerzA: Combining affective modelling and autonomous code generation through Reinforcement Learning**
2409.07918v1 by Elizabeth Wilson, György Fazekas, Geraint Wiggins

This paper presents Tidal-MerzA, a novel system designed for collaborative
performances between humans and a machine agent in the context of live coding,
specifically focusing on the generation of musical patterns. Tidal-MerzA fuses
two foundational models: ALCAA (Affective Live Coding Autonomous Agent) and
Tidal Fuzz, a computational framework. By integrating affective modelling with
computational generation, this system leverages reinforcement learning
techniques to dynamically adapt music composition parameters within the
TidalCycles framework, ensuring both affective qualities to the patterns and
syntactical correctness. The development of Tidal-MerzA introduces two distinct
agents: one focusing on the generation of mini-notation strings for musical
expression, and another on the alignment of music with targeted affective
states through reinforcement learning. This approach enhances the adaptability
and creative potential of live coding practices and allows exploration of
human-machine creative interactions. Tidal-MerzA advances the field of
computational music generation, presenting a novel methodology for
incorporating artificial intelligence into artistic practices.

摘要：本文介紹 Tidal-MerzA，這是一個新穎的系統，專為現場編碼中人類與機器代理之間的協作表演而設計，特別著重於音樂模式的產生。Tidal-MerzA 融合了兩個基礎模型：ALCAA（情感現場編碼自主代理）和 Tidal Fuzz，一個計算框架。透過整合情感建模與計算產生，此系統利用強化學習技術在 TidalCycles 框架內動態調整音樂組成參數，確保模式的情感品質和語法正確性。Tidal-MerzA 的開發引入了兩個不同的代理：一個專注於產生音樂表達的迷你符號字串，另一個透過強化學習將音樂與目標情感狀態對齊。這種方法增強了現場編碼實務的適應性和創造潛力，並允許探索人機創造互動。Tidal-MerzA 推動了計算音樂生成的領域，提出了一種將人工智慧納入藝術實務的新方法。

##### **UGAD: Universal Generative AI Detector utilizing Frequency Fingerprints**
2409.07913v1 by Inzamamul Alam, Muhammad Shahid Muneer, Simon S. Woo

In the wake of a fabricated explosion image at the Pentagon, an ability to
discern real images from fake counterparts has never been more critical. Our
study introduces a novel multi-modal approach to detect AI-generated images
amidst the proliferation of new generation methods such as Diffusion models.
Our method, UGAD, encompasses three key detection steps: First, we transform
the RGB images into YCbCr channels and apply an Integral Radial Operation to
emphasize salient radial features. Secondly, the Spatial Fourier Extraction
operation is used for a spatial shift, utilizing a pre-trained deep learning
network for optimal feature extraction. Finally, the deep neural network
classification stage processes the data through dense layers using softmax for
classification. Our approach significantly enhances the accuracy of
differentiating between real and AI-generated images, as evidenced by a 12.64%
increase in accuracy and 28.43% increase in AUC compared to existing
state-of-the-art methods.

摘要：在五角大厦伪造爆炸图像事件发生后，辨别真假图像的能力从未如此关键。我们的研究引入了一种新颖的多模态方法，以在扩散模型等新一代方法激增的情况下检测 AI 生成的图像。我们的方法 UGAD 包含三个关键检测步骤：首先，我们将 RGB 图像转换为 YCbCr 通道，并应用积分径向运算来强调显着的径向特征。其次，空间傅里叶提取操作用于空间位移，利用预训练的深度学习网络进行最优特征提取。最后，深度神经网络分类阶段使用 softmax 对数据进行密集层处理以进行分类。我们的方法显着提高了区分真实图像和 AI 生成的图像的准确性，与现有的最先进方法相比，准确性提高了 12.64%，AUC 提高了 28.43%。

##### **A corpus-based investigation of pitch contours of monosyllabic words in conversational Taiwan Mandarin**
2409.07891v1 by Xiaoyun Jin, Mirjam Ernestus, R. Harald Baayen

In Mandarin, the tonal contours of monosyllabic words produced in isolation
or in careful speech are characterized by four lexical tones: a high-level tone
(T1), a rising tone (T2), a dipping tone (T3) and a falling tone (T4). However,
in spontaneous speech, the actual tonal realization of monosyllabic words can
deviate significantly from these canonical tones due to intra-syllabic
co-articulation and inter-syllabic co-articulation with adjacent tones. In
addition, Chuang et al. (2024) recently reported that the tonal contours of
disyllabic Mandarin words with T2-T4 tone pattern are co-determined by their
meanings. Following up on their research, we present a corpus-based
investigation of how the pitch contours of monosyllabic words are realized in
spontaneous conversational Mandarin, focusing on the effects of contextual
predictors on the one hand, and the way in words' meanings co-determine pitch
contours on the other hand. We analyze the F0 contours of 3824 tokens of 63
different word types in a spontaneous Taiwan Mandarin corpus, using the
generalized additive (mixed) model to decompose a given observed pitch contour
into a set of component pitch contours. We show that the tonal context
substantially modify a word's canonical tone. Once the effect of tonal context
is controlled for, T2 and T3 emerge as low flat tones, contrasting with T1 as a
high tone, and with T4 as a high-to-mid falling tone. The neutral tone (T0),
which in standard descriptions, is realized based on the preceding tone,
emerges as a low tone in its own right, modified by the other predictors in the
same way as the standard tones T1, T2, T3, and T4. We also show that word, and
even more so, word sense, co-determine words' F0 contours. Analyses of variable
importance using random forests further supported the substantial effect of
tonal context and an effect of word sense.

摘要：<paragraph>在普通話中，單音節詞在孤立狀態或在謹慎的語音中產生的音調輪廓，具有四種語調：高平調（T1）、升調（T2）、降調（T3）和降調（T4）。然而，在自發的語音中，單音節詞的實際音調實現可能會因音節內共發音和與相鄰音調的音節間共發音而與這些規範音調有顯著的偏差。此外，莊等人（2024 年）最近報導說，具有 T2-T4 音調模式的雙音節普通話詞的音調輪廓是由其含義共同決定的。在他們的研究基礎上，我們提出了一項基於語料庫的調查，探討單音節詞的音高輪廓如何在自發的對話式普通話中實現，一方面著重於上下文預測因素的影響，另一方面著重於詞彙含義共同決定音高輪廓的方式。我們分析了一個自發的台灣普通話語料庫中 63 種不同詞類的 3824 個詞條的 F0 輪廓，使用廣義加法（混合）模型將給定的觀察到的音高輪廓分解為一組組成音高輪廓。我們表明音調語境會大幅修改一個詞的規範音調。一旦控制了音調語境的影響，T2 和 T3 就會呈現為低平調，與 T1 作為高音調形成對比，與 T4 作為高到中降調形成對比。在標準描述中基於前一個音調實現的輕聲調（T0）以其自身的低音調出現，與標準音調 T1、T2、T3 和 T4 以相同的方式受到其他預測因素的修改。我們還表明，詞彙，甚至詞義，共同決定詞彙的 F0 輪廓。使用隨機森林進行的可變重要性分析進一步支持了音調語境和詞義的顯著影響。</paragraph>

##### **Learning Rules from KGs Guided by Language Models**
2409.07869v1 by Zihang Peng, Daria Stepanova, Vinh Thinh Ho, Heike Adel, Alessandra Russo, Simon Ott

Advances in information extraction have enabled the automatic construction of
large knowledge graphs (e.g., Yago, Wikidata or Google KG), which are widely
used in many applications like semantic search or data analytics. However, due
to their semi-automatic construction, KGs are often incomplete. Rule learning
methods, concerned with the extraction of frequent patterns from KGs and
casting them into rules, can be applied to predict potentially missing facts. A
crucial step in this process is rule ranking. Ranking of rules is especially
challenging over highly incomplete or biased KGs (e.g., KGs predominantly
storing facts about famous people), as in this case biased rules might fit the
data best and be ranked at the top based on standard statistical metrics like
rule confidence. To address this issue, prior works proposed to rank rules not
only relying on the original KG but also facts predicted by a KG embedding
model. At the same time, with the recent rise of Language Models (LMs), several
works have claimed that LMs can be used as alternative means for KG completion.
In this work, our goal is to verify to which extent the exploitation of LMs is
helpful for improving the quality of rule learning systems.

摘要：資訊萃取的進展已能自動建構大型知識圖譜（例如 Yago、Wikidata 或 Google KG），這些知識圖譜廣泛用於許多應用程式，例如語意搜尋或資料分析。然而，由於這些知識圖譜是半自動建構的，因此通常並不完整。規則學習方法著重於從知識圖譜中萃取頻繁模式，並將它們轉換為規則，可應用於預測潛在遺失的事實。此過程中的一個關鍵步驟是規則排序。規則排序在高度不完整或有偏差的知識圖譜（例如，主要儲存名人事實的知識圖譜）中特別具有挑戰性，因為在這種情況下，有偏差的規則可能最符合資料，並根據標準統計量度（例如規則信心）排在最前面。為了解決這個問題，先前的研究提出不只依賴原始知識圖譜，還要依賴知識圖譜嵌入模型預測的事實來對規則進行排序。同時，隨著語言模型 (LM) 的興起，一些研究聲稱 LM 可用作知識圖譜完成的替代方法。在這項研究中，我們的目標是驗證利用 LM 在多大程度上有助於提升規則學習系統的品質。

##### **Enhancing Cross-Market Recommendation System with Graph Isomorphism Networks: A Novel Approach to Personalized User Experience**
2409.07850v1 by Sümeyye Öztürk, Ahmed Burak Ercan, Resul Tugay, Şule Gündüz Öğüdücü

In today's world of globalized commerce, cross-market recommendation systems
(CMRs) are crucial for providing personalized user experiences across diverse
market segments. However, traditional recommendation algorithms have
difficulties dealing with market specificity and data sparsity, especially in
new or emerging markets. In this paper, we propose the CrossGR model, which
utilizes Graph Isomorphism Networks (GINs) to improve CMR systems. It
outperforms existing benchmarks in NDCG@10 and HR@10 metrics, demonstrating its
adaptability and accuracy in handling diverse market segments. The CrossGR
model is adaptable and accurate, making it well-suited for handling the
complexities of cross-market recommendation tasks. Its robustness is
demonstrated by consistent performance across different evaluation timeframes,
indicating its potential to cater to evolving market trends and user
preferences. Our findings suggest that GINs represent a promising direction for
CMRs, paving the way for more sophisticated, personalized, and context-aware
recommendation systems in the dynamic landscape of global e-commerce.

摘要：在全球化商業的當今世界中，跨市場推薦系統 (CMR) 對於在各個不同的市場區隔中提供個人化的使用者體驗至關重要。然而，傳統的推薦演算法在處理市場特殊性和資料稀疏性方面有困難，特別是在新興或開發中市場。在本文中，我們提出 CrossGR 模型，它利用圖同構網路 (GIN) 來改善 CMR 系統。它在 NDCG@10 和 HR@10 指標上優於現有的基準，證明了它在處理不同市場區隔時的適應性和準確性。CrossGR 模型具有適應性和準確性，使其非常適合處理跨市場推薦任務的複雜性。它的穩健性在不同的評估時間範圍內表現出一致的效能，表明它有潛力滿足不斷變化的市場趨勢和使用者偏好。我們的研究結果表明，GIN 代表了 CMR 的一個有希望的方向，為在全球電子商務的動態環境中建立更精緻、個性化和具備情境感知的推薦系統鋪平了道路。

##### **FPMT: Enhanced Semi-Supervised Model for Traffic Incident Detection**
2409.07839v1 by Xinying Lu, Jianli Xiao

For traffic incident detection, the acquisition of data and labels is notably
resource-intensive, rendering semi-supervised traffic incident detection both a
formidable and consequential challenge. Thus, this paper focuses on traffic
incident detection with a semi-supervised learning way. It proposes a
semi-supervised learning model named FPMT within the framework of MixText. The
data augmentation module introduces Generative Adversarial Networks to balance
and expand the dataset. During the mix-up process in the hidden space, it
employs a probabilistic pseudo-mixing mechanism to enhance regularization and
elevate model precision. In terms of training strategy, it initiates with
unsupervised training on all data, followed by supervised fine-tuning on a
subset of labeled data, and ultimately completing the goal of semi-supervised
training. Through empirical validation on four authentic datasets, our FPMT
model exhibits outstanding performance across various metrics. Particularly
noteworthy is its robust performance even in scenarios with low label rates.

摘要：對於交通事件偵測，資料與標籤的取得顯著地耗費資源，這使得半監督式交通事件偵測成為一項既艱鉅且重要的挑戰。因此，本文專注於採用半監督式學習方式的交通事件偵測。它在 MixText 框架內提出一個名為 FPMT 的半監督式學習模型。資料擴充模組引入了生成對抗網路，以平衡並擴充資料集。在隱藏空間的 mix-up 程序中，它採用機率偽混合機制來增強正則化並提升模型精確度。在訓練策略方面，它從所有資料的無監督式訓練開始，接著在標籤資料的子集中進行監督式微調，最後完成半監督式訓練的目標。透過在四個真實資料集上的實證驗證，我們的 FPMT 模型展現出跨越各種指標的傑出效能。特別值得注意的是，即使在標籤率低的情況下，它仍有穩健的效能。

##### **A Comprehensive Survey on Deep Multimodal Learning with Missing Modality**
2409.07825v2 by Renjie Wu, Hu Wang, Hsiang-Ting Chen

During multimodal model training and reasoning, data samples may miss certain
modalities and lead to compromised model performance due to sensor limitations,
cost constraints, privacy concerns, data loss, and temporal and spatial
factors. This survey provides an overview of recent progress in Multimodal
Learning with Missing Modality (MLMM), focusing on deep learning techniques. It
is the first comprehensive survey that covers the historical background and the
distinction between MLMM and standard multimodal learning setups, followed by a
detailed analysis of current MLMM methods, applications, and datasets,
concluding with a discussion about challenges and potential future directions
in the field.

摘要：在多模态模型训练和推理期间，数据样本可能会缺少某些模态，并且由于传感器限制、成本限制、隐私问题、数据丢失以及时间和空间因素而导致模型性能受损。本调查概述了缺失模态多模态学习 (MLMM) 的最新进展，重点是深度学习技术。这是第一份涵盖历史背景和 MLMM 与标准多模态学习设置之间区别的综合调查，随后详细分析了当前的 MLMM 方法、应用程序和数据集，最后讨论了该领域的挑战和潜在未来方向。

##### **Online vs Offline: A Comparative Study of First-Party and Third-Party Evaluations of Social Chatbots**
2409.07823v1 by Ekaterina Svikhnushina, Pearl Pu

This paper explores the efficacy of online versus offline evaluation methods
in assessing conversational chatbots, specifically comparing first-party direct
interactions with third-party observational assessments. By extending a
benchmarking dataset of user dialogs with empathetic chatbots with offline
third-party evaluations, we present a systematic comparison between the
feedback from online interactions and the more detached offline third-party
evaluations. Our results reveal that offline human evaluations fail to capture
the subtleties of human-chatbot interactions as effectively as online
assessments. In comparison, automated third-party evaluations using a GPT-4
model offer a better approximation of first-party human judgments given
detailed instructions. This study highlights the limitations of third-party
evaluations in grasping the complexities of user experiences and advocates for
the integration of direct interaction feedback in conversational AI evaluation
to enhance system development and user satisfaction.

摘要：本文探討線上與線下評估方法在評估對話式聊天機器人時的效能，特別是比較第一方直接互動與第三方觀察評估。透過擴充使用者對話的基准資料集，並加入離線的第三方評估，我們對線上互動的回饋與較為抽離的離線第三方評估進行系統性的比較。我們的結果顯示，與線上評估相比，離線的人工評估未能有效捕捉人與聊天機器人互動的細微差別。相較之下，使用 GPT-4 模型的自動化第三方評估，在給予詳細說明的情況下，能提供較佳的近似值，以判斷第一方的人類判斷。本研究強調了第三方評估在掌握使用者體驗的複雜性方面的限制，並主張在對話式 AI 評估中整合直接互動回饋，以增強系統開發和使用者滿意度。

##### **Controllable Synthetic Clinical Note Generation with Privacy Guarantees**
2409.07809v1 by Tal Baumel, Andre Manoel, Daniel Jones, Shize Su, Huseyin Inan, Aaron, Bornstein, Robert Sim

In the field of machine learning, domain-specific annotated data is an
invaluable resource for training effective models. However, in the medical
domain, this data often includes Personal Health Information (PHI), raising
significant privacy concerns. The stringent regulations surrounding PHI limit
the availability and sharing of medical datasets, which poses a substantial
challenge for researchers and practitioners aiming to develop advanced machine
learning models. In this paper, we introduce a novel method to "clone" datasets
containing PHI. Our approach ensures that the cloned datasets retain the
essential characteristics and utility of the original data without compromising
patient privacy. By leveraging differential-privacy techniques and a novel
fine-tuning task, our method produces datasets that are free from identifiable
information while preserving the statistical properties necessary for model
training. We conduct utility testing to evaluate the performance of machine
learning models trained on the cloned datasets. The results demonstrate that
our cloned datasets not only uphold privacy standards but also enhance model
performance compared to those trained on traditional anonymized datasets. This
work offers a viable solution for the ethical and effective utilization of
sensitive medical data in machine learning, facilitating progress in medical
research and the development of robust predictive models.

摘要：在機器學習領域中，特定領域的註解資料是訓練有效模型的寶貴資源。然而，在醫學領域中，此類資料經常包含個人健康資訊 (PHI)，引發重大的隱私問題。圍繞 PHI 的嚴格法規限制了醫療資料集的可用性和共享，這對旨在開發進階機器學習模型的研究人員和從業者構成重大挑戰。在本文中，我們介紹了一種「複製」包含 PHI 的資料集的新方法。我們的做法確保複製的資料集保留原始資料的基本特徵和效用，同時不損害患者隱私。透過利用差分隱私技術和新的微調任務，我們的做法產生了無可辨識資訊的資料集，同時保留了模型訓練所需的統計特性。我們進行效用測試以評估在複製資料集上訓練的機器學習模型的效能。結果表明，我們複製的資料集不僅符合隱私標準，而且與在傳統匿名化資料集上訓練的資料集相比，還能提升模型效能。這項工作為機器學習中敏感醫療資料的道德和有效利用提供了可行的解決方案，促進了醫學研究和穩健預測模型的發展。

##### **In-Situ Fine-Tuning of Wildlife Models in IoT-Enabled Camera Traps for Efficient Adaptation**
2409.07796v1 by Mohammad Mehdi Rastikerdar, Jin Huang, Hui Guan, Deepak Ganesan

Wildlife monitoring via camera traps has become an essential tool in ecology,
but the deployment of machine learning models for on-device animal
classification faces significant challenges due to domain shifts and resource
constraints. This paper introduces WildFit, a novel approach that reconciles
the conflicting goals of achieving high domain generalization performance and
ensuring efficient inference for camera trap applications. WildFit leverages
continuous background-aware model fine-tuning to deploy ML models tailored to
the current location and time window, allowing it to maintain robust
classification accuracy in the new environment without requiring significant
computational resources. This is achieved by background-aware data synthesis,
which generates training images representing the new domain by blending
background images with animal images from the source domain. We further enhance
fine-tuning effectiveness through background drift detection and class
distribution drift detection, which optimize the quality of synthesized data
and improve generalization performance. Our extensive evaluation across
multiple camera trap datasets demonstrates that WildFit achieves significant
improvements in classification accuracy and computational efficiency compared
to traditional approaches.

摘要：野生動物監測透過相機陷阱已成為生態學中不可或缺的工具，
但機器學習模型在裝置上進行動物分類的部署面臨了領域轉移和資源限制的重大挑戰。本文介紹了 WildFit，這是一種新穎的方法，它調和了實現高領域泛化效能和確保相機陷阱應用程式有效推論的衝突目標。WildFit 利用持續的背景感知模型微調來部署針對當前位置和時間視窗量身打造的 ML 模型，使其能夠在新的環境中維持穩健的分類準確性，而無需大量的運算資源。這透過背景感知資料合成來達成，它透過將背景影像與來自原始領域的動物影像混合，產生代表新領域的訓練影像。我們透過背景漂移偵測和類別分佈漂移偵測進一步提升微調的有效性，它們最佳化了合成資料的品質並提升了泛化效能。我們在多個相機陷阱資料集上的廣泛評估顯示，與傳統方法相比，WildFit 在分類準確性和運算效率方面都有顯著的提升。

##### **Full-text Error Correction for Chinese Speech Recognition with Large Language Model**
2409.07790v1 by Zhiyuan Tang, Dong Wang, Shen Huang, Shidong Shang

Large Language Models (LLMs) have demonstrated substantial potential for
error correction in Automatic Speech Recognition (ASR). However, most research
focuses on utterances from short-duration speech recordings, which are the
predominant form of speech data for supervised ASR training. This paper
investigates the effectiveness of LLMs for error correction in full-text
generated by ASR systems from longer speech recordings, such as transcripts
from podcasts, news broadcasts, and meetings. First, we develop a Chinese
dataset for full-text error correction, named ChFT, utilizing a pipeline that
involves text-to-speech synthesis, ASR, and error-correction pair extractor.
This dataset enables us to correct errors across contexts, including both
full-text and segment, and to address a broader range of error types, such as
punctuation restoration and inverse text normalization, thus making the
correction process comprehensive. Second, we fine-tune a pre-trained LLM on the
constructed dataset using a diverse set of prompts and target formats, and
evaluate its performance on full-text error correction. Specifically, we design
prompts based on full-text and segment, considering various output formats,
such as directly corrected text and JSON-based error-correction pairs. Through
various test settings, including homogeneous, up-to-date, and hard test sets,
we find that the fine-tuned LLMs perform well in the full-text setting with
different prompts, each presenting its own strengths and weaknesses. This
establishes a promising baseline for further research. The dataset is available
on the website.

摘要：<paragraph>大型語言模型 (LLM) 已展現出在自動語音辨識 (ASR) 中進行錯誤校正的巨大潛力。然而，大多數研究都著重於短時語音錄音中的語句，而這是監督式 ASR 訓練中主要的語音資料形式。本文探討了 LLM 在 ASR 系統產生的長篇語音錄音全文字錯誤校正中的有效性，例如播客、新聞廣播和會議的逐字稿。首先，我們開發了一個名為 ChFT 的中文全文字錯誤校正資料集，利用了一個包含文字轉語音合成、ASR 和錯誤校正配對萃取器的管道。這個資料集讓我們能夠跨脈絡（包括全文字和片段）校正錯誤，並解決更廣泛的錯誤類型，例如標點符號還原和反向文字正規化，從而使校正過程更全面。其次，我們使用一套不同的提示和目標格式，針對建構的資料集微調一個預先訓練的 LLM，並評估其在全文字錯誤校正中的表現。具體來說，我們根據全文字和片段設計提示，考量各種輸出格式，例如直接校正的文字和基於 JSON 的錯誤校正配對。透過各種測試設定，包括同質、最新和困難的測試集，我們發現微調後的 LLM 在全文字設定中表現良好，並採用不同的提示，每個提示都展現出自己的優勢和劣勢。這為進一步的研究建立了一個有前景的基準。該資料集可在網站上取得。</paragraph>

##### **Stable Language Model Pre-training by Reducing Embedding Variability**
2409.07787v1 by Woojin Chung, Jiwoo Hong, Na Min An, James Thorne, Se-Young Yun

Stable pre-training is essential for achieving better-performing language
models. However, tracking pre-training stability by calculating gradient
variance at every step is impractical due to the significant computational
costs. We explore Token Embedding Variability (TEV) as a simple and efficient
proxy for assessing pre-training stability in language models with pre-layer
normalization, given that shallower layers are more prone to gradient explosion
(section 2.2). Moreover, we propose Multi-head Low-Rank Attention (MLRA) as an
architecture to alleviate such instability by limiting the exponential growth
of output embedding variance, thereby preventing the gradient explosion
(section 3.2). Empirical results on GPT-2 with MLRA demonstrate increased
stability and lower perplexity, particularly in deeper models.

摘要：穩定的預訓練對於達成效能更好的語言模型至關重要。然而，由於顯著的運算成本，透過計算每個步驟的梯度變異數來追蹤預訓練穩定性並不實際。我們探討 Token Embedding Variability (TEV) 作為一個簡單且有效的方法，用於評估具有預層標準化的語言模型中的預訓練穩定性，因為較淺的層更容易發生梯度爆炸（第 2.2 節）。此外，我們提出多頭低秩注意力 (MLRA) 作為一種架構，透過限制輸出嵌入變異數的指數成長來減輕這種不穩定性，從而防止梯度爆炸（第 3.2 節）。在 GPT-2 上使用 MLRA 的經驗結果證明了增加的穩定性和較低的困惑度，特別是在較深的模型中。

##### **ASSNet: Adaptive Semantic Segmentation Network for Microtumors and Multi-Organ Segmentation**
2409.07779v1 by Fuchen Zheng, Xinyi Chen, Xuhang Chen, Haolun Li, Xiaojiao Guo, Guoheng Huang, Chi-Man Pun, Shoujun Zhou

Medical image segmentation, a crucial task in computer vision, facilitates
the automated delineation of anatomical structures and pathologies, supporting
clinicians in diagnosis, treatment planning, and disease monitoring. Notably,
transformers employing shifted window-based self-attention have demonstrated
exceptional performance. However, their reliance on local window attention
limits the fusion of local and global contextual information, crucial for
segmenting microtumors and miniature organs. To address this limitation, we
propose the Adaptive Semantic Segmentation Network (ASSNet), a transformer
architecture that effectively integrates local and global features for precise
medical image segmentation. ASSNet comprises a transformer-based U-shaped
encoder-decoder network. The encoder utilizes shifted window self-attention
across five resolutions to extract multi-scale features, which are then
propagated to the decoder through skip connections. We introduce an augmented
multi-layer perceptron within the encoder to explicitly model long-range
dependencies during feature extraction. Recognizing the constraints of
conventional symmetrical encoder-decoder designs, we propose an Adaptive
Feature Fusion (AFF) decoder to complement our encoder. This decoder
incorporates three key components: the Long Range Dependencies (LRD) block, the
Multi-Scale Feature Fusion (MFF) block, and the Adaptive Semantic Center (ASC)
block. These components synergistically facilitate the effective fusion of
multi-scale features extracted by the decoder while capturing long-range
dependencies and refining object boundaries. Comprehensive experiments on
diverse medical image segmentation tasks, including multi-organ, liver tumor,
and bladder tumor segmentation, demonstrate that ASSNet achieves
state-of-the-art results. Code and models are available at:
\url{https://github.com/lzeeorno/ASSNet}.

摘要：<paragraph>醫學影像分割是電腦視覺中一項重要的任務，有助於自動描繪解剖結構和病理，協助臨床醫師進行診斷、治療計畫和疾病監控。值得注意的是，採用位移視窗自注意力機制的Transformer展現出非凡的效能。然而，它們依賴於區域視窗注意力，這限制了區域和全域脈絡資訊的融合，而這對於分割微小腫瘤和微型器官至關重要。為了解決這個限制，我們提出了自適應語義分割網路 (ASSNet)，這是一個Transformer架構，可以有效整合區域和全域特徵，以進行精確的醫學影像分割。ASSNet 包含一個基於Transformer的 U 型編碼器-解碼器網路。編碼器利用五個解析度的位移視窗自注意力來萃取多尺度特徵，然後透過跳躍連線將這些特徵傳播到解碼器。我們在編碼器中引入了擴增的多層感知器，以便在特徵萃取期間明確地建模長程依賴性。鑑於傳統對稱編碼器-解碼器設計的限制，我們提出了一個自適應特徵融合 (AFF) 解碼器來補充我們的編碼器。此解碼器包含三個關鍵組成部分：長程依賴性 (LRD) 區塊、多尺度特徵融合 (MFF) 區塊和自適應語義中心 (ASC) 區塊。這些組成部分相互配合，促成解碼器萃取的多尺度特徵有效融合，同時捕捉長程依賴性並微調物件邊界。在多器官、肝臟腫瘤和膀胱腫瘤分割等各種醫學影像分割任務上的全面實驗證明，ASSNet 達到了最先進的成果。程式碼和模型可於以下網址取得：\url{https://github.com/lzeeorno/ASSNet}。</paragraph>

##### **Training Spiking Neural Networks via Augmented Direct Feedback Alignment**
2409.07776v1 by Yongbo Zhang, Katsuma Inoue, Mitsumasa Nakajima, Toshikazu Hashimoto, Yasuo Kuniyoshi, Kohei Nakajima

Spiking neural networks (SNNs), the models inspired by the mechanisms of real
neurons in the brain, transmit and represent information by employing discrete
action potentials or spikes. The sparse, asynchronous properties of information
processing make SNNs highly energy efficient, leading to SNNs being promising
solutions for implementing neural networks in neuromorphic devices. However,
the nondifferentiable nature of SNN neurons makes it a challenge to train them.
The current training methods of SNNs that are based on error backpropagation
(BP) and precisely designing surrogate gradient are difficult to implement and
biologically implausible, hindering the implementation of SNNs on neuromorphic
devices. Thus, it is important to train SNNs with a method that is both
physically implementatable and biologically plausible. In this paper, we
propose using augmented direct feedback alignment (aDFA), a gradient-free
approach based on random projection, to train SNNs. This method requires only
partial information of the forward process during training, so it is easy to
implement and biologically plausible. We systematically demonstrate the
feasibility of the proposed aDFA-SNNs scheme, propose its effective working
range, and analyze its well-performing settings by employing genetic algorithm.
We also analyze the impact of crucial features of SNNs on the scheme, thus
demonstrating its superiority and stability over BP and conventional direct
feedback alignment. Our scheme can achieve competitive performance without
accurate prior knowledge about the utilized system, thus providing a valuable
reference for physically training SNNs.

摘要：尖峰神经網路（SNN）是受大腦中真實神經元機制啟發的模型，它透過使用離散動作電位或尖峰來傳輸和表示資訊。資訊處理的稀疏性和非同步性使 SNN 具有高度的能源效率，這使得 SNN 成為在神經形態裝置中實作神經網路的有前途的解決方案。然而，SNN 神經元的不可微分性質使得訓練它們成為一項挑戰。目前基於誤差反向傳播（BP）和精確設計替代梯度的 SNN 訓練方法難以實作且在生物學上難以實現，這阻礙了 SNN 在神經形態裝置上的實作。因此，使用一種在物理上可實作且在生物學上合理的訓練 SNN 的方法非常重要。在本文中，我們建議使用基於隨機投影的無梯度方法擴增直接回饋對齊（aDFA）來訓練 SNN。此方法在訓練過程中僅需要前向過程的部分資訊，因此易於實作且在生物學上合理。我們系統性地證明了所提出的 aDFA-SNN 架構的可行性，提出其有效的運作範圍，並透過採用遺傳演算法分析其效能良好的設定。我們還分析了 SNN 的關鍵特徵對此架構的影響，從而證明了它優於 BP 和傳統直接回饋對齊，且穩定性也較佳。我們的架構可以在沒有關於所使用系統的準確先驗知識的情況下，達到具有競爭力的效能，從而為物理訓練 SNN 提供了寶貴的參考。

##### **Universal Pooling Method of Multi-layer Features from Pretrained Models for Speaker Verification**
2409.07770v1 by Jin Sob Kim, Hyun Joon Park, Wooseok Shin, Sung Won Han

Recent advancements in automatic speaker verification (ASV) studies have been
achieved by leveraging large-scale pretrained networks. In this study, we
analyze the approaches toward such a paradigm and underline the significance of
interlayer information processing as a result. Accordingly, we present a novel
approach for exploiting the multilayered nature of pretrained models for ASV,
which comprises a layer/frame-level network and two steps of pooling
architectures for each layer and frame axis. Specifically, we let convolutional
architecture directly processes a stack of layer outputs.Then, we present a
channel attention-based scheme of gauging layer significance and squeeze the
layer level with the most representative value. Finally, attentive statistics
over frame-level representations yield a single vector speaker embedding.
Comparative experiments are designed using versatile data environments and
diverse pretraining models to validate the proposed approach. The experimental
results demonstrate the stability of the approach using multi-layer outputs in
leveraging pretrained architectures. Then, we verify the superiority of the
proposed ASV backend structure, which involves layer-wise operations, in terms
of performance improvement along with cost efficiency compared to the
conventional method. The ablation study shows how the proposed interlayer
processing aids in maximizing the advantage of utilizing pretrained models.

摘要：最近在自動語音驗證 (ASV) 研究中的進展，是透過利用大規模預訓練網路所達成。在本研究中，我們分析了此範例的方法，並強調了層間資訊處理的重要性。因此，我們提出一個新的方法，用於利用預訓練模型的多層特性來進行 ASV，其中包含一個層級/幀級網路，以及針對每個層級和幀軸的兩個池化架構步驟。具體來說，我們讓卷積架構直接處理一疊層級輸出。然後，我們提出一個基於通道注意力的方案，用於評估層級重要性，並使用最具代表性的值壓縮層級。最後，對幀級表示的關注統計會產生一個單一的向量說話者嵌入。我們使用多功能資料環境和不同的預訓練模型設計了比較實驗，以驗證所提出的方法。實驗結果證明了該方法使用多層輸出在利用預訓練架構時的穩定性。然後，我們驗證了所提出的 ASV 後端結構的優越性，其中涉及層級運算，在效能提升和成本效益方面，優於傳統方法。消融研究顯示，所提出的層間處理如何有助於最大化利用預訓練模型的優勢。

##### **Reimagining Linear Probing: Kolmogorov-Arnold Networks in Transfer Learning**
2409.07763v1 by Sheng Shen, Rabih Younes

This paper introduces Kolmogorov-Arnold Networks (KAN) as an enhancement to
the traditional linear probing method in transfer learning. Linear probing,
often applied to the final layer of pre-trained models, is limited by its
inability to model complex relationships in data. To address this, we propose
substituting the linear probing layer with KAN, which leverages spline-based
representations to approximate intricate functions. In this study, we integrate
KAN with a ResNet-50 model pre-trained on ImageNet and evaluate its performance
on the CIFAR-10 dataset. We perform a systematic hyperparameter search,
focusing on grid size and spline degree (k), to optimize KAN's flexibility and
accuracy. Our results demonstrate that KAN consistently outperforms traditional
linear probing, achieving significant improvements in accuracy and
generalization across a range of configurations. These findings indicate that
KAN offers a more powerful and adaptable alternative to conventional linear
probing techniques in transfer learning.

摘要：本文介紹了 Kolmogorov-Arnold 網路 (KAN)，作為轉移學習中傳統線性探測方法的強化。線性探測通常應用於預訓練模型的最後一層，但其建模資料中複雜關係的能力有限。為了解決這個問題，我們建議用 KAN 取代線性探測層，KAN 利用基於樣條線的表示來近似複雜函數。在這項研究中，我們將 KAN 與在 ImageNet 上預訓練的 ResNet-50 模型整合，並在 CIFAR-10 資料集上評估其效能。我們執行系統性的超參數搜尋，專注於網格大小和樣條線次數 (k)，以最佳化 KAN 的彈性和準確度。我們的結果證明，KAN 持續優於傳統線性探測，在各種組態中都顯著提升準確度和泛化能力。這些發現表明，在轉移學習中，KAN 提供了一個比傳統線性探測技術更強大、更適應性的替代方案。

##### **Top-down Activity Representation Learning for Video Question Answering**
2409.07748v1 by Yanan Wang, Shuichiro Haruta, Donghuo Zeng, Julio Vizcarra, Mori Kurokawa

Capturing complex hierarchical human activities, from atomic actions (e.g.,
picking up one present, moving to the sofa, unwrapping the present) to
contextual events (e.g., celebrating Christmas) is crucial for achieving
high-performance video question answering (VideoQA). Recent works have expanded
multimodal models (e.g., CLIP, LLaVA) to process continuous video sequences,
enhancing the model's temporal reasoning capabilities. However, these
approaches often fail to capture contextual events that can be decomposed into
multiple atomic actions non-continuously distributed over relatively long-term
sequences. In this paper, to leverage the spatial visual context representation
capability of the CLIP model for obtaining non-continuous visual
representations in terms of contextual events in videos, we convert long-term
video sequences into a spatial image domain and finetune the multimodal model
LLaVA for the VideoQA task. Our approach achieves competitive performance on
the STAR task, in particular, with a 78.4% accuracy score, exceeding the
current state-of-the-art score by 2.8 points on the NExTQA task.

摘要：捕捉複雜的分層人類活動，從原子動作（例如，拿起一個禮物、移動到沙發上、拆開禮物）到情境事件（例如，慶祝聖誕節），對於實現高性能影片問答 (VideoQA) 至關重要。最近的研究已擴展多模態模型（例如，CLIP、LLaVA）以處理連續影片序列，增強模型的時間推理能力。然而，這些方法通常無法捕捉情境事件，這些事件可以分解為在相對長期序列中非連續分佈的多個原子動作。在本文中，為了利用 CLIP 模型的空間視覺上下文表示功能，以在影片中以情境事件的形式獲得非連續視覺表示，我們將長期影片序列轉換為空間影像網域，並微調多模態模型 LLaVA 以用於 VideoQA 任務。我們的做法在 STAR 任務中取得了具有競爭力的表現，特別是準確度得分為 78.4%，在 NExTQA 任務中比目前的最新技術得分高出 2.8 分。

##### **Multi-object event graph representation learning for Video Question Answering**
2409.07747v1 by Yanan Wang, Shuichiro Haruta, Donghuo Zeng, Julio Vizcarra, Mori Kurokawa

Video question answering (VideoQA) is a task to predict the correct answer to
questions posed about a given video. The system must comprehend spatial and
temporal relationships among objects extracted from videos to perform causal
and temporal reasoning. While prior works have focused on modeling individual
object movements using transformer-based methods, they falter when capturing
complex scenarios involving multiple objects (e.g., "a boy is throwing a ball
in a hoop"). We propose a contrastive language event graph representation
learning method called CLanG to address this limitation. Aiming to capture
event representations associated with multiple objects, our method employs a
multi-layer GNN-cluster module for adversarial graph representation learning,
enabling contrastive learning between the question text and its relevant
multi-object event graph. Our method outperforms a strong baseline, achieving
up to 2.2% higher accuracy on two challenging VideoQA datasets, NExT-QA and
TGIF-QA-R. In particular, it is 2.8% better than baselines in handling causal
and temporal questions, highlighting its strength in reasoning multiple
object-based events.

摘要：影片問答 (VideoQA) 是一項任務，用於預測針對給定影片提出的問題的正確答案。系統必須了解從影片中提取的物件之間的空間和時間關係，才能執行因果關係和時間推理。雖然先前的研究集中於使用基於Transformer的模型來建模個別物件的動作，但在捕捉涉及多個物件的複雜場景（例如「一個男孩正在將球投進籃框」）時，它們會出現問題。我們提出了一個對比式語言事件圖表表示學習方法，稱為 CLanG，以解決此限制。為了捕捉與多個物件相關的事件表示，我們的模型採用多層 GNN 集群模組進行對抗式圖表表示學習，使問題文字及其相關的多物件事件圖表之間能夠進行對比式學習。我們的模型優於強大的基準，在兩個具有挑戰性的 VideoQA 資料集 NExT-QA 和 TGIF-QA-R 上達到了高達 2.2% 的更高準確度。特別是，在處理因果關係和時間問題方面比基準高出 2.8%，突顯了它在推理多個基於物件的事件方面的優勢。

##### **Ruri: Japanese General Text Embeddings**
2409.07737v1 by Hayato Tsukagoshi, Ryohei Sasano

We report the development of Ruri, a series of Japanese general text
embedding models. While the development of general-purpose text embedding
models in English and multilingual contexts has been active in recent years,
model development in Japanese remains insufficient. The primary reasons for
this are the lack of datasets and the absence of necessary expertise. In this
report, we provide a detailed account of the development process of Ruri.
Specifically, we discuss the training of embedding models using synthesized
datasets generated by LLMs, the construction of the reranker for dataset
filtering and knowledge distillation, and the performance evaluation of the
resulting general-purpose text embedding models.

摘要：我們報告 Ruri 的開發，這是一個日文一般文字嵌入模型的系列。儘管近年來英文和多語言環境中一般用途文字嵌入模型的開發十分活躍，日文模型的開發仍然不足。這主要是因為缺乏資料集和必要的專業知識。在這個報告中，我們提供了 Ruri 開發過程的詳細說明。具體來說，我們討論了使用 LLM 生成的合成資料集訓練嵌入模型、建構用於資料集過濾和知識萃取的重新排名器，以及評估一般用途文字嵌入模型的效能。

##### **Transfer Learning Applied to Computer Vision Problems: Survey on Current Progress, Limitations, and Opportunities**
2409.07736v1 by Aaryan Panda, Damodar Panigrahi, Shaswata Mitra, Sudip Mittal, Shahram Rahimi

The field of Computer Vision (CV) has faced challenges. Initially, it relied
on handcrafted features and rule-based algorithms, resulting in limited
accuracy. The introduction of machine learning (ML) has brought progress,
particularly Transfer Learning (TL), which addresses various CV problems by
reusing pre-trained models. TL requires less data and computing while
delivering nearly equal accuracy, making it a prominent technique in the CV
landscape. Our research focuses on TL development and how CV applications use
it to solve real-world problems. We discuss recent developments, limitations,
and opportunities.

摘要：電腦視覺（CV）領域面臨挑戰。最初，它依賴於手工製作的特徵和基於規則的演算法，導致準確度有限。機器學習（ML）的引入帶來了進展，特別是轉移學習（TL），它透過重複使用預先訓練的模型來解決各種 CV 問題。TL 需要較少資料和運算，同時提供近乎相等的準確度，使其成為 CV 領域中傑出的技術。我們的研究重點在於 TL 的發展，以及 CV 應用如何使用它來解決現實世界中的問題。我們討論了最近的發展、限制和機會。

##### **GRE^2-MDCL: Graph Representation Embedding Enhanced via Multidimensional Contrastive Learning**
2409.07725v1 by Kaizhe Fan, Quanjun Li

Graph representation learning has emerged as a powerful tool for preserving
graph topology when mapping nodes to vector representations, enabling various
downstream tasks such as node classification and community detection. However,
most current graph neural network models face the challenge of requiring
extensive labeled data, which limits their practical applicability in
real-world scenarios where labeled data is scarce. To address this challenge,
researchers have explored Graph Contrastive Learning (GCL), which leverages
enhanced graph data and contrastive learning techniques. While promising,
existing GCL methods often struggle with effectively capturing both local and
global graph structures, and balancing the trade-off between nodelevel and
graph-level representations. In this work, we propose Graph Representation
Embedding Enhanced via Multidimensional Contrastive Learning (GRE2-MDCL). Our
model introduces a novel triple network architecture with a multi-head
attention GNN as the core. GRE2-MDCL first globally and locally augments the
input graph using SVD and LAGNN techniques. It then constructs a
multidimensional contrastive loss, incorporating cross-network, cross-view, and
neighbor contrast, to optimize the model. Extensive experiments on benchmark
datasets Cora, Citeseer, and PubMed demonstrate that GRE2-MDCL achieves
state-of-the-art performance, with average accuracies of 82.5%, 72.5%, and
81.6% respectively. Visualizations further show tighter intra-cluster
aggregation and clearer inter-cluster boundaries, highlighting the
effectiveness of our framework in improving upon baseline GCL models.

摘要：圖形表徵學習已成為一種強大的工具，用於在將節點對應到向量表徵時保留圖形拓撲，進而能進行各種下游任務，例如節點分類和社群偵測。然而，目前大多數圖形神經網路模型都面臨需要大量標籤資料的挑戰，這限制了它們在標籤資料稀少的實際場景中的實際應用性。為了應對這一挑戰，研究人員探索了圖形對比學習 (GCL)，它利用增強的圖形資料和對比學習技術。雖然有前景，但現有的 GCL 方法通常難以有效擷取局部和全域圖形結構，並平衡節點級和圖形級表徵之間的權衡。在這項工作中，我們提出了透過多維度對比學習增強的圖形表徵嵌入 (GRE2-MDCL)。我們的模型引入了一種新穎的三重網路架構，以多頭注意力 GNN 為核心。GRE2-MDCL 首先使用 SVD 和 LAGNN 技術在全域和局部增強輸入圖形。然後，它建構一個多維度對比損失，結合跨網路、跨視圖和鄰近對比，以最佳化模型。在基準資料集 Cora、Citeseer 和 PubMed 上進行的廣泛實驗證明，GRE2-MDCL 達到了最先進的效能，平均準確率分別為 82.5%、72.5% 和 81.6%。可視化進一步顯示出更緊密的群集內聚合和更清晰的群集間界線，突顯了我們的架構在改善基準 GCL 模型方面的有效性。

##### **Advancing Depth Anything Model for Unsupervised Monocular Depth Estimation in Endoscopy**
2409.07723v1 by Bojian Li, Bo Liu, Jinghua Yue, Fugen Zhou

Depth estimation is a cornerstone of 3D reconstruction and plays a vital role
in minimally invasive endoscopic surgeries. However, most current depth
estimation networks rely on traditional convolutional neural networks, which
are limited in their ability to capture global information. Foundation models
offer a promising avenue for enhancing depth estimation, but those currently
available are primarily trained on natural images, leading to suboptimal
performance when applied to endoscopic images. In this work, we introduce a
novel fine-tuning strategy for the Depth Anything Model and integrate it with
an intrinsic-based unsupervised monocular depth estimation framework. Our
approach includes a low-rank adaptation technique based on random vectors,
which improves the model's adaptability to different scales. Additionally, we
propose a residual block built on depthwise separable convolution to compensate
for the transformer's limited ability to capture high-frequency details, such
as edges and textures. Our experimental results on the SCARED dataset show that
our method achieves state-of-the-art performance while minimizing the number of
trainable parameters. Applying this method in minimally invasive endoscopic
surgery could significantly enhance both the precision and safety of these
procedures.

摘要：深度估計是 3D 重建的基石，在微創內視鏡手術中扮演至關重要的角色。然而，目前大多數深度估計網路依賴傳統的卷積神經網路，其捕捉全局資訊的能力有限。基礎模型提供了一個增強深度估計的有希望途徑，但目前可用的基礎模型主要在自然影像上訓練，導致應用於內視鏡影像時效能不佳。在這項研究中，我們為 Depth Anything Model 提出了一種新穎的微調策略，並將其與基於內在的無監督單眼深度估計框架整合。我們的做法包括一種基於隨機向量的低秩適應技術，它改善了模型對不同尺度的適應性。此外，我們提出了一個建立在深度可分離卷積上的殘差區塊，以彌補Transformer捕捉高頻細節（例如邊緣和紋理）的能力有限。我們在 SCARED 資料集上的實驗結果顯示，我們的模型在最小化可訓練參數數量的情況下，達到了最先進的效能。在微創內視鏡手術中應用此方法可以顯著提高這些程序的精確度和安全性。

##### **FIReStereo: Forest InfraRed Stereo Dataset for UAS Depth Perception in Visually Degraded Environments**
2409.07715v1 by Devansh Dhrafani, Yifei Liu, Andrew Jong, Ukcheol Shin, Yao He, Tyler Harp, Yaoyu Hu, Jean Oh, Sebastian Scherer

Robust depth perception in visually-degraded environments is crucial for
autonomous aerial systems. Thermal imaging cameras, which capture infrared
radiation, are robust to visual degradation. However, due to lack of a
large-scale dataset, the use of thermal cameras for unmanned aerial system
(UAS) depth perception has remained largely unexplored. This paper presents a
stereo thermal depth perception dataset for autonomous aerial perception
applications. The dataset consists of stereo thermal images, LiDAR, IMU and
ground truth depth maps captured in urban and forest settings under diverse
conditions like day, night, rain, and smoke. We benchmark representative stereo
depth estimation algorithms, offering insights into their performance in
degraded conditions. Models trained on our dataset generalize well to unseen
smoky conditions, highlighting the robustness of stereo thermal imaging for
depth perception. We aim for this work to enhance robotic perception in
disaster scenarios, allowing for exploration and operations in previously
unreachable areas. The dataset and source code are available at
https://firestereo.github.io.

摘要：對於自主空中系統而言，在視覺退化的環境中擁有穩健的深度感知至關重要。熱像儀可以捕捉紅外線輻射，對於視覺退化具有穩健性。然而，由於缺乏大規模的資料集，熱像儀用於無人機 (UAS) 深度感知的用途仍未被廣泛探索。本文提出了一個用於自主空中感知應用程式的立體熱深度感知資料集。該資料集包含立體熱影像、LiDAR、IMU 和地面實況深度圖，這些資料是在白天、夜晚、雨天和有煙霧的各種條件下於城市和森林環境中擷取的。我們對具代表性的立體深度估計演算法進行基準測試，深入了解它們在退化條件下的效能。使用我們的資料集訓練的模型可以很好地概化到未見過的煙霧條件，凸顯了立體熱影像在深度感知方面的穩健性。我們的目標是增強機器人在災害場景中的感知能力，以便在以前無法到達的地區進行探索和作業。資料集和原始程式碼可在 https://firestereo.github.io/ 取得。

##### **Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice**
2409.07713v1 by Jonathan Li, Rohan Bhambhoria, Samuel Dahan, Xiaodan Zhu

Generative AI models, such as the GPT and Llama series, have significant
potential to assist laypeople in answering legal questions. However, little
prior work focuses on the data sourcing, inference, and evaluation of these
models in the context of laypersons. To this end, we propose a human-centric
legal NLP pipeline, covering data sourcing, inference, and evaluation. We
introduce and release a dataset, LegalQA, with real and specific legal
questions spanning from employment law to criminal law, corresponding answers
written by legal experts, and citations for each answer. We develop an
automatic evaluation protocol for this dataset, then show that
retrieval-augmented generation from only 850 citations in the train set can
match or outperform internet-wide retrieval, despite containing 9 orders of
magnitude less data. Finally, we propose future directions for open-sourced
efforts, which fall behind closed-sourced models.

摘要：生成式 AI 模型（例如 GPT 和 Llama 系列）在協助非專業人士回答法律問題方面具有顯著的潛力。然而，很少有先前的研究專注於在非專業人士的背景下，這些模型的資料來源、推論和評估。為此，我們提出一個以人為中心的法律 NLP 管線，涵蓋資料來源、推論和評估。我們引入並發布一個資料集 LegalQA，其中包含從勞動法到刑法的真實且具體的法律問題，並附有法律專家撰寫的相應答案和每個答案的引文。我們為此資料集開發了一個自動評估協定，然後展示僅從訓練組中的 850 個引文進行檢索增強生成，儘管包含的資料少 9 個數量級，但仍可以匹配或優於網際網路範圍的檢索。最後，我們提出開放原始碼工作的未來方向，這些工作落後於封閉原始碼模型。

##### **Attack End-to-End Autonomous Driving through Module-Wise Noise**
2409.07706v1 by Lu Wang, Tianyuan Zhang, Yikai Han, Muyang Fang, Ting Jin, Jiaqi Kang

With recent breakthroughs in deep neural networks, numerous tasks within
autonomous driving have exhibited remarkable performance. However, deep
learning models are susceptible to adversarial attacks, presenting significant
security risks to autonomous driving systems. Presently, end-to-end
architectures have emerged as the predominant solution for autonomous driving,
owing to their collaborative nature across different tasks. Yet, the
implications of adversarial attacks on such models remain relatively
unexplored. In this paper, we conduct comprehensive adversarial security
research on the modular end-to-end autonomous driving model for the first time.
We thoroughly consider the potential vulnerabilities in the model inference
process and design a universal attack scheme through module-wise noise
injection. We conduct large-scale experiments on the full-stack autonomous
driving model and demonstrate that our attack method outperforms previous
attack methods. We trust that our research will offer fresh insights into
ensuring the safety and reliability of autonomous driving systems.

摘要：隨著深度神經網路的最新突破，在自動駕駛中的許多任務都展現出卓越的效能。然而，深度學習模型容易受到對抗性攻擊，對自動駕駛系統構成重大的安全風險。目前，端到端架構已成為自動駕駛的主要解決方案，因為它們在不同任務中具有協作的性質。然而，對抗性攻擊對此類模型的影響仍相對未經探討。在本文中，我們首次對模組化端到端自動駕駛模型進行全面的對抗性安全研究。我們徹底考慮模型推理過程中潛在的漏洞，並透過模組化雜訊注入設計通用攻擊方案。我們對全堆疊自動駕駛模型進行大規模實驗，並證明我們的攻擊方法優於先前的攻擊方法。我們相信我們的研究將為確保自動駕駛系統的安全性和可靠性提供新的見解。

##### **DSBench: How Far Are Data Science Agents to Becoming Data Science Experts?**
2409.07703v1 by Liqiang Jing, Zhehui Huang, Xiaoyang Wang, Wenlin Yao, Wenhao Yu, Kaixin Ma, Hongming Zhang, Xinya Du, Dong Yu

Large Language Models (LLMs) and Large Vision-Language Models (LVLMs) have
demonstrated impressive language/vision reasoning abilities, igniting the
recent trend of building agents for targeted applications such as shopping
assistants or AI software engineers. Recently, many data science benchmarks
have been proposed to investigate their performance in the data science domain.
However, existing data science benchmarks still fall short when compared to
real-world data science applications due to their simplified settings. To
bridge this gap, we introduce DSBench, a comprehensive benchmark designed to
evaluate data science agents with realistic tasks. This benchmark includes 466
data analysis tasks and 74 data modeling tasks, sourced from Eloquence and
Kaggle competitions. DSBench offers a realistic setting by encompassing long
contexts, multimodal task backgrounds, reasoning with large data files and
multi-table structures, and performing end-to-end data modeling tasks. Our
evaluation of state-of-the-art LLMs, LVLMs, and agents shows that they struggle
with most tasks, with the best agent solving only 34.12% of data analysis tasks
and achieving a 34.74% Relative Performance Gap (RPG). These findings
underscore the need for further advancements in developing more practical,
intelligent, and autonomous data science agents.

摘要：大型語言模型（LLM）和大型視覺語言模型（LVLMs）已展現出令人印象深刻的語言/視覺推理能力，引領了建立針對購物助理或人工智慧軟體工程師等目標應用程式的代理的近期趨勢。最近，許多資料科學基準測試已被提出，以調查其在資料科學領域的效能。然而，現有的資料科學基準測試與實際的資料科學應用相比，由於其簡化的設定，仍有不足之處。為了彌補這個差距，我們引入了 DSBench，一個旨在評估資料科學代理的全面基準測試，其中包含實際任務。此基準測試包括 466 個資料分析任務和 74 個資料建模任務，取自 Eloquence 和 Kaggle 競賽。DSBench 透過涵蓋長語境、多模態任務背景、使用大型資料檔案和多表格結構進行推理，以及執行端對端資料建模任務，提供了一個實際的設定。我們對最先進的 LLM、LVLMs 和代理的評估顯示，它們在處理大多數任務時都面臨困難，最好的代理只解決了 34.12% 的資料分析任務，並達到了 34.74% 的相對效能差距（RPG）。這些發現強調了進一步開發更實用、更智慧、更自主的資料科學代理的需求。

##### **Enhancing Q&A Text Retrieval with Ranking Models: Benchmarking, fine-tuning and deploying Rerankers for RAG**
2409.07691v1 by Gabriel de Souza P. Moreira, Ronay Ak, Benedikt Schifferer, Mengyao Xu, Radek Osmulski, Even Oldridge

Ranking models play a crucial role in enhancing overall accuracy of text
retrieval systems. These multi-stage systems typically utilize either dense
embedding models or sparse lexical indices to retrieve relevant passages based
on a given query, followed by ranking models that refine the ordering of the
candidate passages by its relevance to the query.
  This paper benchmarks various publicly available ranking models and examines
their impact on ranking accuracy. We focus on text retrieval for
question-answering tasks, a common use case for Retrieval-Augmented Generation
systems. Our evaluation benchmarks include models some of which are
commercially viable for industrial applications.
  We introduce a state-of-the-art ranking model, NV-RerankQA-Mistral-4B-v3,
which achieves a significant accuracy increase of ~14% compared to pipelines
with other rerankers. We also provide an ablation study comparing the
fine-tuning of ranking models with different sizes, losses and self-attention
mechanisms.
  Finally, we discuss challenges of text retrieval pipelines with ranking
models in real-world industry applications, in particular the trade-offs among
model size, ranking accuracy and system requirements like indexing and serving
latency / throughput.

摘要：排名模型在提升整體文字檢索系統的準確度方面扮演著至關重要的角色。這些多階段系統通常會利用密集嵌入模型或稀疏詞彙索引來依據給定的查詢檢索相關段落，接著再由排名模型依據候選段落與查詢相關性來優化排序。
  本文對各種公開的排名模型進行基準測試，並檢視它們對排名準確度的影響。我們專注於問答任務的文字檢索，這是檢索增強生成系統的常見使用案例。我們的評估基準包含一些在產業應用中具有商業可行性的模型。
  我們引進了最先進的排名模型 NV-RerankQA-Mistral-4B-v3，與其他重新排名器的管道相比，它達到了約 14% 的顯著準確度提升。我們也提供了一項消融研究，比較不同大小、損失和自注意力機制的排名模型微調。
  最後，我們討論了在實際產業應用中使用排名模型的文字檢索管道的挑戰，特別是在模型大小、排名準確度和系統需求（例如索引和提供服務的延遲/吞吐量）之間的權衡。

##### **Modeling Information Narrative Detection and Evolution on Telegram during the Russia-Ukraine War**
2409.07684v1 by Patrick Gerard, Svitlana Volkova, Louis Penafiel, Kristina Lerman, Tim Weninger

Following the Russian Federation's full-scale invasion of Ukraine in February
2022, a multitude of information narratives emerged within both pro-Russian and
pro-Ukrainian communities online. As the conflict progresses, so too do the
information narratives, constantly adapting and influencing local and global
community perceptions and attitudes. This dynamic nature of the evolving
information environment (IE) underscores a critical need to fully discern how
narratives evolve and affect online communities. Existing research, however,
often fails to capture information narrative evolution, overlooking both the
fluid nature of narratives and the internal mechanisms that drive their
evolution. Recognizing this, we introduce a novel approach designed to both
model narrative evolution and uncover the underlying mechanisms driving them.
In this work we perform a comparative discourse analysis across communities on
Telegram covering the initial three months following the invasion. First, we
uncover substantial disparities in narratives and perceptions between
pro-Russian and pro-Ukrainian communities. Then, we probe deeper into prevalent
narratives of each group, identifying key themes and examining the underlying
mechanisms fueling their evolution. Finally, we explore influences and factors
that may shape the development and spread of narratives.

摘要：在 2022 年 2 月俄罗斯联邦全面入侵乌克兰之后，亲俄罗斯和亲乌克兰的网络社群中出现了许多信息叙事。随着冲突的进展，信息叙事也在不断适应和影响着当地和全球社群的认知和态度。这种不断演变的信息环境 (IE) 的动态特性强调了充分了解叙事如何演变并影响网络社群的迫切需要。然而，现有的研究通常无法捕捉到信息叙事的演变，既忽略了叙事的流动性，也忽略了推动其演变的内在机制。认识到这一点，我们引入了一种新颖的方法，旨在对叙事演变进行建模，并揭示推动其演变的潜在机制。在这项工作中，我们对 Telegram 上的社群进行了比较性话语分析，涵盖了入侵后的最初三个月。首先，我们揭示了亲俄罗斯和亲乌克兰社群之间在叙事和认知上的巨大差异。然后，我们深入探究每组流行的叙事，找出关键主题并检验推动其演变的潜在机制。最后，我们探讨可能影响叙事发展和传播的影响因素。

##### **Open-Vocabulary Remote Sensing Image Semantic Segmentation**
2409.07683v1 by Qinglong Cao, Yuntian Chen, Chao Ma, Xiaokang Yang

Open-vocabulary image semantic segmentation (OVS) seeks to segment images
into semantic regions across an open set of categories. Existing OVS methods
commonly depend on foundational vision-language models and utilize similarity
computation to tackle OVS tasks. However, these approaches are predominantly
tailored to natural images and struggle with the unique characteristics of
remote sensing images, such as rapidly changing orientations and significant
scale variations. These challenges complicate OVS tasks in earth vision,
requiring specialized approaches. To tackle this dilemma, we propose the first
OVS framework specifically designed for remote sensing imagery, drawing
inspiration from the distinct remote sensing traits. Particularly, to address
the varying orientations, we introduce a rotation-aggregative similarity
computation module that generates orientation-adaptive similarity maps as
initial semantic maps. These maps are subsequently refined at both spatial and
categorical levels to produce more accurate semantic maps. Additionally, to
manage significant scale changes, we integrate multi-scale image features into
the upsampling process, resulting in the final scale-aware semantic masks. To
advance OVS in earth vision and encourage reproducible research, we establish
the first open-sourced OVS benchmark for remote sensing imagery, including four
public remote sensing datasets. Extensive experiments on this benchmark
demonstrate our proposed method achieves state-of-the-art performance. All
codes and datasets are available at https://github.com/caoql98/OVRS.

摘要：<paragraph>開放詞彙影像語義分割（OVS）旨在將影像分割成開放類別集的語義區域。現有的 OVS 方法通常依賴基礎視覺語言模型，並利用相似性運算來解決 OVS 任務。然而，這些方法主要針對自然影像進行調整，難以處理遙測影像的獨特特性，例如快速變化的方向和顯著的比例變化。這些挑戰使地球視覺中的 OVS 任務複雜化，需要專門的方法。為了解決這個困境，我們提出了第一個專門為遙測影像設計的 OVS 框架，從不同的遙測特徵中汲取靈感。特別是，為了應對不同的方向，我們引入了一個旋轉聚合相似性運算模組，該模組產生方向適應相似性圖作為初始語義圖。這些圖隨後在空間和類別層級上進行細化，以產生更準確的語義圖。此外，為了管理顯著的比例變化，我們將多比例影像特徵整合到上採樣過程中，產生最終的比例感知語義遮罩。為了推進地球視覺中的 OVS 並鼓勵可複製的研究，我們建立了第一個遙測影像的開源 OVS 基準，包括四個公開的遙測資料集。在這個基準上的廣泛實驗證明，我們提出的方法達到了最先進的效能。所有程式碼和資料集都可以在 https://github.com/caoql98/OVRS 取得。</paragraph>

##### **An Unsupervised Dialogue Topic Segmentation Model Based on Utterance Rewriting**
2409.07672v1 by Xia Hou, Qifeng Li, Tongliang Li

Dialogue topic segmentation plays a crucial role in various types of dialogue
modeling tasks. The state-of-the-art unsupervised DTS methods learn topic-aware
discourse representations from conversation data through adjacent discourse
matching and pseudo segmentation to further mine useful clues in unlabeled
conversational relations. However, in multi-round dialogs, discourses often
have co-references or omissions, leading to the fact that direct use of these
discourses for representation learning may negatively affect the semantic
similarity computation in the neighboring discourse matching task. In order to
fully utilize the useful cues in conversational relations, this study proposes
a novel unsupervised dialog topic segmentation method that combines the
Utterance Rewriting (UR) technique with an unsupervised learning algorithm to
efficiently utilize the useful cues in unlabeled dialogs by rewriting the
dialogs in order to recover the co-referents and omitted words. Compared with
existing unsupervised models, the proposed Discourse Rewriting Topic
Segmentation Model (UR-DTS) significantly improves the accuracy of topic
segmentation. The main finding is that the performance on DialSeg711 improves
by about 6% in terms of absolute error score and WD, achieving 11.42% in terms
of absolute error score and 12.97% in terms of WD. on Doc2Dial the absolute
error score and WD improves by about 3% and 2%, respectively, resulting in SOTA
reaching 35.17% in terms of absolute error score and 38.49% in terms of WD.
This shows that the model is very effective in capturing the nuances of
conversational topics, as well as the usefulness and challenges of utilizing
unlabeled conversations.

摘要：對話主題分段在各種對話建模任務中扮演著至關重要的角色。最先進的無監督 DTS 方法透過相鄰對話比對和偽分段從對話資料中學習與主題相關的對話表徵，以進一步挖掘未標記對話關係中的有用線索。然而，在多輪對話中，對話通常會有共同引用或省略，導致直接使用這些對話進行表徵學習可能會對鄰近對話比對任務中的語意相似性計算產生負面影響。為了充分利用對話關係中的有用線索，本研究提出了一種新的無監督對話主題分段方法，該方法將話語重寫 (UR) 技術與無監督學習演算法相結合，透過重寫對話以恢復共同引用和省略的詞語，從而有效利用未標記對話中的有用線索。與現有的無監督模型相比，所提出的對話重寫主題分段模型 (UR-DTS) 大幅提升了主題分段的準確度。主要發現是 DialSeg711 的效能以絕對誤差分數和 WD 而言提升了約 6%，在絕對誤差分數方面達到 11.42%，在 WD 方面達到 12.97%。在 Doc2Dial 上，絕對誤差分數和 WD 分別提升了約 3% 和 2%，導致 SOTA 在絕對誤差分數方面達到 35.17%，在 WD 方面達到 38.49%。這顯示了該模型在捕捉對話主題的細微差別方面非常有效，以及利用未標記對話的用處和挑戰。

##### **Passed the Turing Test: Living in Turing Futures**
2409.07656v1 by Bernardo Gonçalves

The world has seen the emergence of machines based on pretrained models,
transformers, also known as generative artificial intelligences for their
ability to produce various types of content, including text, images, audio, and
synthetic data. Without resorting to preprogramming or special tricks, their
intelligence grows as they learn from experience, and to ordinary people, they
can appear human-like in conversation. This means that they can pass the Turing
test, and that we are now living in one of many possible Turing futures where
machines can pass for what they are not. However, the learning machines that
Turing imagined would pass his imitation tests were machines inspired by the
natural development of the low-energy human cortex. They would be raised like
human children and naturally learn the ability to deceive an observer. These
``child machines,'' Turing hoped, would be powerful enough to have an impact on
society and nature.

摘要：世界已目睹基於預訓練模型的機器出現，
Transformer，也稱為生成式人工智慧，因為它們
能夠產生各種類型的內容，包括文字、影像、音訊，以及
合成資料。無需訴諸於預先編程或特殊技巧，它們
的智慧會隨著從經驗中學習而增長，對一般人來說，它們
在對話中可能表現得像人類。這表示它們可以通過圖靈
測試，而我們現在生活在許多可能的圖靈未來之一，其中
機器可以假裝成它們不是的東西。然而，圖靈想像中通過他的模仿測試的學習機器是受到
人類低能量皮質自然發展啟發的機器。它們會像
人類兒童一樣長大，並自然而然地學會欺騙觀察者的能力。這些
「孩童機器」，圖靈希望，將強大到足以對
社會和自然產生影響。

##### **Feature Importance in Pedestrian Intention Prediction: A Context-Aware Review**
2409.07645v1 by Mohsen Azarmi, Mahdi Rezaei, He Wang, Ali Arabian

Recent advancements in predicting pedestrian crossing intentions for
Autonomous Vehicles using Computer Vision and Deep Neural Networks are
promising. However, the black-box nature of DNNs poses challenges in
understanding how the model works and how input features contribute to final
predictions. This lack of interpretability delimits the trust in model
performance and hinders informed decisions on feature selection,
representation, and model optimisation; thereby affecting the efficacy of
future research in the field. To address this, we introduce Context-aware
Permutation Feature Importance (CAPFI), a novel approach tailored for
pedestrian intention prediction. CAPFI enables more interpretability and
reliable assessments of feature importance by leveraging subdivided scenario
contexts, mitigating the randomness of feature values through targeted
shuffling. This aims to reduce variance and prevent biased estimations in
importance scores during permutations. We divide the Pedestrian Intention
Estimation (PIE) dataset into 16 comparable context sets, measure the baseline
performance of five distinct neural network architectures for intention
prediction in each context, and assess input feature importance using CAPFI. We
observed nuanced differences among models across various contextual
characteristics. The research reveals the critical role of pedestrian bounding
boxes and ego-vehicle speed in predicting pedestrian intentions, and potential
prediction biases due to the speed feature through cross-context permutation
evaluation. We propose an alternative feature representation by considering
proximity change rate for rendering dynamic pedestrian-vehicle locomotion,
thereby enhancing the contributions of input features to intention prediction.
These findings underscore the importance of contextual features and their
diversity to develop accurate and robust intent-predictive models.

摘要：<paragraph>最近在使用计算机视觉和深度神经网络为自动驾驶汽车预测行人过马路意图方面取得的进展令人振奋。然而，DNN 的黑盒性质对理解模型的工作原理以及输入特征如何促成最终预测提出了挑战。这种缺乏可解释性限制了对模型性能的信任，并阻碍了对特征选择、表示和模型优化做出明智的决策；从而影响了该领域未来研究的效力。为了解决这个问题，我们引入了上下文感知置换特征重要性 (CAPFI)，这是一种针对行人意图预测量身定制的新方法。CAPFI 通过利用细分的场景上下文，通过有针对性的洗牌来减轻特征值的随机性，从而提高了特征重要性的可解释性和可靠性评估。这旨在减少方差，并在置换期间防止重要性评分中的偏差估计。我们将行人意图估计 (PIE) 数据集划分为 16 个可比较的上下文集，测量五个不同的神经网络架构在每个上下文中的意图预测的基线性能，并使用 CAPFI 评估输入特征重要性。我们观察到不同模型在各种上下文特征中存在细微差异。研究表明行人边界框和自车速度在预测行人意图中起着至关重要的作用，并且由于速度特征而导致潜在的预测偏差通过跨上下文置换评估。我们通过考虑邻近变化率来提出一种替代特征表示，用于呈现动态的行人-车辆运动，从而增强输入特征对意图预测的贡献。这些发现强调了上下文特征及其多样性对于开发准确且稳健的意图预测模型的重要性。</paragraph>

##### **SimulBench: Evaluating Language Models with Creative Simulation Tasks**
2409.07641v1 by Qi Jia, Xiang Yue, Tianyu Zheng, Jie Huang, Bill Yuchen Lin

We introduce SimulBench, a benchmark designed to evaluate large language
models (LLMs) across a diverse collection of creative simulation scenarios,
such as acting as a Linux terminal or playing text games with users. While
these simulation tasks serve as effective measures of an LLM's general
intelligence, they are seldom incorporated into existing benchmarks. A major
challenge is to develop an evaluation framework for testing different LLMs
fairly while preserving the multi-round interactive nature of simulation tasks
between users and AI. To tackle this issue, we suggest using a fixed LLM as a
user agent to engage with an LLM to collect dialogues first under different
tasks. Then, challenging dialogue scripts are extracted for evaluating
different target LLMs. To facilitate automatic assessment on \DataName{}, GPT-4
is employed as the evaluator, tasked with reviewing the quality of the final
response generated by the target LLMs given multi-turn dialogue scripts. Our
comprehensive experiments indicate that these simulation tasks continue to pose
a significant challenge with their unique natures and show the gap between
proprietary models and the most advanced open LLMs. For example, GPT-4-turbo
outperforms LLaMA-3-70b-Chat on 18.55\% more cases.

摘要：我們引入了 SimulBench，這是一個基準，旨在評估大型語言模型 (LLM) 在各種創意模擬情境中的表現，例如扮演 Linux 終端機或與使用者玩文字遊戲。雖然這些模擬任務可作為 LLM 一般智能的有效衡量標準，但它們很少納入現有的基準中。一個主要的挑戰是開發一個評估框架，用於公平地測試不同的 LLM，同時保留使用者和 AI 之間模擬任務的多輪互動性質。為了解決這個問題，我們建議使用一個固定的 LLM 作為使用者代理，與 LLM 互動，以便在不同的任務下首先收集對話。然後，擷取具有挑戰性的對話腳本，用於評估不同的目標 LLM。為了促進對 \DataName{} 的自動評估，GPT-4 被用作評估器，負責審查目標 LLM 在給定多輪對話腳本的情況下產生的最終回應的品質。我們全面的實驗表明，這些模擬任務持續構成一個重大的挑戰，具有其獨特的性質，並顯示出專有模型和最先進的開放式 LLM 之間的差距。例如，GPT-4-turbo 在 18.55% 的案例中表現優於 LLaMA-3-70b-Chat。

##### **Can We Count on LLMs? The Fixed-Effect Fallacy and Claims of GPT-4 Capabilities**
2409.07638v1 by Thomas Ball, Shuo Chen, Cormac Herley

In this paper we explore evaluation of LLM capabilities. We present
measurements of GPT-4 performance on several deterministic tasks; each task
involves a basic calculation and takes as input parameter some element drawn
from a large well-defined population (e.g., count elements in a list, multiply
two k-digit numbers, etc). We examine several conditions per-task and perform
enough trials so that statistically significant differences can be detected.
This allows us to investigate the sensitivity of task-accuracy both to query
phrasing and input parameter population. We find that seemingly trivial
modifications in the task-prompt or input population can yield differences far
larger than can be explained by sampling effects. For example, performance on a
simple list-counting task varies with query-phrasing and list-length, but also
with list composition (i.e., the thing-to-be-counted) and object frequency
(e.g., success when an element accounts for $\approx$ 50\% of a list is
different from when it accounts for $\approx$ 70\% etc).
  We conclude that efforts to quantify LLM capabilities easily succumb to the
language-as-fixed-effect fallacy, where experimental observations are
improperly generalized beyond what the data supports. A consequence appears to
be that intuitions that have been formed based on interactions with humans form
a very unreliable guide as to which input modifications should ``make no
difference'' to LLM performance.

摘要：在本文中，我們探討了 LLM 能力的評估。我們提供了 GPT-4 在幾項確定性任務上的效能測量；每項任務都包含一個基本計算，並以從一個定義良好的大型族群中抽取的元素作為輸入參數（例如，計算清單中的元素、將兩個 k 位數字相乘等）。我們針對每個任務檢查幾個條件，並執行足夠的試驗，以便能偵測到具有統計意義的差異。這讓我們能夠探討任務準確度對查詢措辭和輸入參數族群的敏感度。我們發現，任務提示或輸入族群中看似微不足道的修改可能會產生遠大於抽樣效應所能解釋的差異。例如，簡單的清單計數任務的效能會隨著查詢措辭和清單長度而變化，但也會隨著清單組成（即要計數的事物）和物件頻率而變化（例如，當一個元素佔清單的 $\approx$ 50% 時，成功率與其佔 $\approx$ 70% 等等時不同）。
我們得出結論，量化 LLM 能力的努力很容易屈服於語言固定效應謬誤，其中實驗觀察被不適當地概括到資料所支援的範圍之外。後果似乎是，基於與人類互動形成的直覺，對於哪些輸入修改應「對 LLM 效能沒有影響」來說，是一個非常不可靠的指南。

##### **Weather-Informed Probabilistic Forecasting and Scenario Generation in Power Systems**
2409.07637v1 by Hanyu Zhang, Reza Zandehshahvar, Mathieu Tanneau, Pascal Van Hentenryck

The integration of renewable energy sources (RES) into power grids presents
significant challenges due to their intrinsic stochasticity and uncertainty,
necessitating the development of new techniques for reliable and efficient
forecasting. This paper proposes a method combining probabilistic forecasting
and Gaussian copula for day-ahead prediction and scenario generation of load,
wind, and solar power in high-dimensional contexts. By incorporating weather
covariates and restoring spatio-temporal correlations, the proposed method
enhances the reliability of probabilistic forecasts in RES. Extensive numerical
experiments compare the effectiveness of different time series models, with
performance evaluated using comprehensive metrics on a real-world and
high-dimensional dataset from Midcontinent Independent System Operator (MISO).
The results highlight the importance of weather information and demonstrate the
efficacy of the Gaussian copula in generating realistic scenarios, with the
proposed weather-informed Temporal Fusion Transformer (WI-TFT) model showing
superior performance.

摘要：再生能源 (RES) 整合至電網會因其內在隨機性和不確定性而帶來重大挑戰，因此需要開發新的技術來進行可靠且有效的預測。本文提出了一種結合機率預測和高斯藤葛樹的日後預測方法，以及高維度環境中負載、風力和太陽能的場景生成。透過納入天氣協變量並恢復時空關聯性，所提出的方法提升了 RES 中機率預測的可靠性。廣泛的數值實驗比較了不同時間序列模型的有效性，並使用來自中西部獨立系統營運商 (MISO) 的真實世界和高維度資料集上的綜合指標評估效能。結果強調了天氣資訊的重要性，並展示了高斯藤葛樹在生成真實場景中的效能，其中所提出的天氣資訊時間融合Transformer (WI-TFT) 模型顯示出優異的效能。

##### **Dividable Configuration Performance Learning**
2409.07629v1 by Jingzhi Gong, Tao Chen, Rami Bahsoon

Machine/deep learning models have been widely adopted for predicting the
configuration performance of software systems. However, a crucial yet
unaddressed challenge is how to cater for the sparsity inherited from the
configuration landscape: the influence of configuration options (features) and
the distribution of data samples are highly sparse. In this paper, we propose a
model-agnostic and sparsity-robust framework for predicting configuration
performance, dubbed DaL, based on the new paradigm of dividable learning that
builds a model via "divide-and-learn". To handle sample sparsity, the samples
from the configuration landscape are divided into distant divisions, for each
of which we build a sparse local model, e.g., regularized Hierarchical
Interaction Neural Network, to deal with the feature sparsity. A newly given
configuration would then be assigned to the right model of division for the
final prediction. Further, DaL adaptively determines the optimal number of
divisions required for a system and sample size without any extra training or
profiling. Experiment results from 12 real-world systems and five sets of
training data reveal that, compared with the state-of-the-art approaches, DaL
performs no worse than the best counterpart on 44 out of 60 cases with up to
1.61x improvement on accuracy; requires fewer samples to reach the same/better
accuracy; and producing acceptable training overhead. In particular, the
mechanism that adapted the parameter d can reach the optimal value for 76.43%
of the individual runs. The result also confirms that the paradigm of dividable
learning is more suitable than other similar paradigms such as ensemble
learning for predicting configuration performance. Practically, DaL
considerably improves different global models when using them as the underlying
local models, which further strengthens its flexibility.

摘要：機器/深度學習模型已被廣泛採用來預測軟體系統的組態效能。然而，一個至關重要但尚未解決的挑戰是如何迎合從組態環境中繼承而來的稀疏性：組態選項（特徵）的影響和資料樣本的分布非常稀疏。在本文中，我們提出了一個與模型無關且對稀疏性穩健的框架，用於預測組態效能，稱為 DaL，它基於可分割學習的新範例，通過「分割和學習」建立模型。為了處理樣本稀疏性，來自組態環境的樣本被分為距離較遠的區塊，對於每個區塊，我們建立一個稀疏的局部模型，例如正規化的階層式互動神經網路，以處理特徵稀疏性。然後將新給定的組態分配給區塊的正確模型以進行最終預測。此外，DaL 自適應地確定系統和樣本大小所需的最佳區塊數，而無需任何額外的訓練或剖析。來自 12 個真實世界系統和五組訓練資料的實驗結果顯示，與最先進的方法相比，DaL 在 60 個案例中的 44 個案例中表現不比最佳對應物差，準確度提高了 1.61 倍；需要更少的樣本就能達到相同/更好的準確度；並且產生可接受的訓練開銷。特別是，調整參數 d 的機制可以達到 76.43% 的個別執行階段的最佳值。結果還證實，可分割學習的範例比其他類似的範例（例如用於預測組態效能的集成學習）更合適。實際上，DaL 在將不同的全球模型用作底層的局部模型時，顯著地改進了這些模型，這進一步增強了它的靈活性。

##### **Leveraging User-Generated Reviews for Recommender Systems with Dynamic Headers**
2409.07627v1 by Shanu Vashishtha, Abhay Kumar, Lalitesh Morishetti, Kaushiki Nag, Kannan Achan

E-commerce platforms have a vast catalog of items to cater to their
customers' shopping interests. Most of these platforms assist their customers
in the shopping process by offering optimized recommendation carousels,
designed to help customers quickly locate their desired items. Many models have
been proposed in academic literature to generate and enhance the ranking and
recall set of items in these carousels. Conventionally, the accompanying
carousel title text (header) of these carousels remains static. In most
instances, a generic text such as "Items similar to your current viewing" is
utilized. Fixed variations such as the inclusion of specific attributes "Other
items from a similar seller" or "Items from a similar brand" in addition to
"frequently bought together" or "considered together" are observed as well.
This work proposes a novel approach to customize the header generation process
of these carousels. Our work leverages user-generated reviews that lay focus on
specific attributes (aspects) of an item that were favorably perceived by users
during their interaction with the given item. We extract these aspects from
reviews and train a graph neural network-based model under the framework of a
conditional ranking task. We refer to our innovative methodology as Dynamic
Text Snippets (DTS) which generates multiple header texts for an anchor item
and its recall set. Our approach demonstrates the potential of utilizing
user-generated reviews and presents a unique paradigm for exploring
increasingly context-aware recommendation systems.

摘要：<paragraph>電子商務平台擁有龐大的商品目錄，以滿足客戶的購物興趣。這些平台大多數透過提供最佳化推薦輪播，協助客戶進行購物流程，旨在協助客戶快速找到他們想要的商品。許多模型已在學術文獻中提出，以產生和加強這些輪播中商品的排名和召回設定。傳統上，這些輪播的隨附輪播標題文字（標題）保持靜態。在多數情況下，會使用「與您目前瀏覽類似的商品」等一般文字。固定變化，例如包含特定屬性「來自類似賣家的其他商品」或「來自類似品牌的商品」，以及「經常一起購買」或「一起考慮」，也已觀察到。這項工作提出了一個新的方法，用於自訂這些輪播的標題產生流程。我們的作品利用使用者產生的評論，這些評論專注於使用者在與特定商品互動時，對商品的特定屬性（面向）產生良好的看法。我們從評論中擷取這些面向，並在條件式排名任務架構下訓練圖形神經網路模型。我們將我們的創新方法稱為動態文字片段 (DTS)，它會為錨定商品及其召回設定產生多個標題文字。我們的做法展示了利用使用者產生的評論的潛力，並提出了一個獨特的範例，用於探索越來越注重脈絡的推薦系統。</paragraph>

##### **Ensemble Methods for Sequence Classification with Hidden Markov Models**
2409.07619v1 by Maxime Kawawa-Beaudan, Srijan Sood, Soham Palande, Ganapathy Mani, Tucker Balch, Manuela Veloso

We present a lightweight approach to sequence classification using Ensemble
Methods for Hidden Markov Models (HMMs). HMMs offer significant advantages in
scenarios with imbalanced or smaller datasets due to their simplicity,
interpretability, and efficiency. These models are particularly effective in
domains such as finance and biology, where traditional methods struggle with
high feature dimensionality and varied sequence lengths. Our ensemble-based
scoring method enables the comparison of sequences of any length and improves
performance on imbalanced datasets.
  This study focuses on the binary classification problem, particularly in
scenarios with data imbalance, where the negative class is the majority (e.g.,
normal data) and the positive class is the minority (e.g., anomalous data),
often with extreme distribution skews. We propose a novel training approach for
HMM Ensembles that generalizes to multi-class problems and supports
classification and anomaly detection. Our method fits class-specific groups of
diverse models using random data subsets, and compares likelihoods across
classes to produce composite scores, achieving high average precisions and
AUCs.
  In addition, we compare our approach with neural network-based methods such
as Convolutional Neural Networks (CNNs) and Long Short-Term Memory networks
(LSTMs), highlighting the efficiency and robustness of HMMs in data-scarce
environments. Motivated by real-world use cases, our method demonstrates robust
performance across various benchmarks, offering a flexible framework for
diverse applications.

摘要：<paragraph>我們提出了一種使用隱藏馬可夫模型 (HMM) 的集成方法進行序列分類的輕量級方法。HMM 由於其簡單性、可解釋性和效率，在不平衡或較小數據集的場景中提供了顯著的優勢。這些模型在金融和生物學等領域特別有效，在這些領域中，傳統方法難以應對高特徵維度和不同的序列長度。我們基於集成的方法的評分方法能夠比較任何長度的序列，並提高不平衡數據集的性能。
本研究重點關注二元分類問題，特別是在數據不平衡的情況下，負類是多數（例如，正常數據），而正類是少數（例如，異常數據），通常具有極端的分布偏差。我們提出了一種新的 HMM 集成訓練方法，該方法可以推廣到多類問題，並支持分類和異常檢測。我們的模型使用隨機數據子集擬合不同模型的類別特定組，並比較各類的可能性以產生複合分數，從而實現高平均精確度和 AUC。
此外，我們將我們的方法與基於神經網絡的方法（例如卷積神經網絡 (CNN) 和長短期記憶網絡 (LSTM)）進行了比較，強調了 HMM 在數據稀缺環境中的效率和魯棒性。我們的模型受到現實世界用例的啟發，在各種基準測試中展示了穩健的性能，為不同的應用提供了靈活的框架。</paragraph>

##### **Understanding Foundation Models: Are We Back in 1924?**
2409.07618v1 by Alan F. Smeaton

This position paper explores the rapid development of Foundation Models (FMs)
in AI and their implications for intelligence and reasoning. It examines the
characteristics of FMs, including their training on vast datasets and use of
embedding spaces to capture semantic relationships. The paper discusses recent
advancements in FMs' reasoning abilities which we argue cannot be attributed to
increased model size but to novel training techniques which yield learning
phenomena like grokking. It also addresses the challenges in benchmarking FMs
and compares their structure to the human brain. We argue that while FMs show
promising developments in reasoning and knowledge representation, understanding
their inner workings remains a significant challenge, similar to ongoing
efforts in neuroscience to comprehend human brain function. Despite having some
similarities, fundamental differences between FMs and the structure of human
brain warn us against making direct comparisons or expecting neuroscience to
provide immediate insights into FM function.

摘要：本立場文件探討基礎模型 (FM) 在人工智慧的快速發展及其對智慧與推理的影響。文中探討 FM 的特徵，包括在龐大資料集上訓練以及使用嵌入式空間來擷取語義關係。本文討論 FM 推理能力的近期進展，我們認為這不能歸因於模型大小的增加，而是歸因於產生學習現象（如理解）的新穎訓練技術。本文也探討基準化 FM 的挑戰，並將其結構與人腦進行比較。我們認為，雖然 FM 在推理和知識表示方面顯示出有前途的發展，但了解其內部運作仍然是一項重大挑戰，類似於神經科學中了解人腦功能的持續努力。儘管有一些相似之處，但 FM 與人腦結構之間的根本差異警告我們不要進行直接比較或期望神經科學能立即深入了解 FM 功能。

##### **Zero-Shot Machine-Generated Text Detection Using Mixture of Large Language Models**
2409.07615v1 by Matthieu Dubois, François Yvon, Pablo Piantanida

The dissemination of Large Language Models (LLMs), trained at scale, and
endowed with powerful text-generating abilities has vastly increased the
threats posed by generative AI technologies by reducing the cost of producing
harmful, toxic, faked or forged content. In response, various proposals have
been made to automatically discriminate artificially generated from
human-written texts, typically framing the problem as a classification problem.
Most approaches evaluate an input document by a well-chosen detector LLM,
assuming that low-perplexity scores reliably signal machine-made content. As
using one single detector can induce brittleness of performance, we instead
consider several and derive a new, theoretically grounded approach to combine
their respective strengths. Our experiments, using a variety of generator LLMs,
suggest that our method effectively increases the robustness of detection.

摘要：大型語言模型 (LLM) 的傳播，經過大規模訓練，並具備強大的文本生成能力，已大大增加了生成式 AI 技術所帶來的威脅，因為它降低了產生有害、有毒、偽造或偽造內容的成本。作為回應，已經提出了各種建議，以自動區分人工生成的文本和人類編寫的文本，通常將問題構建為分類問題。大多數方法通過精心選擇的檢測器 LLM 來評估輸入文檔，假設低困惑度分數可靠地標誌著機器生成的內容。由於使用單個檢測器會導致性能脆弱，因此我們考慮了幾個檢測器，並採用一種新的、理論上合理的途徑來結合它們各自的優勢。我們的實驗使用各種生成器 LLM，表明我們的方法有效地提高了檢測的穩健性。

##### **Efficient Localized Adaptation of Neural Weather Forecasting: A Case Study in the MENA Region**
2409.07585v1 by Muhammad Akhtar Munir, Fahad Shahbaz Khan, Salman Khan

Accurate weather and climate modeling is critical for both scientific
advancement and safeguarding communities against environmental risks.
Traditional approaches rely heavily on Numerical Weather Prediction (NWP)
models, which simulate energy and matter flow across Earth's systems. However,
heavy computational requirements and low efficiency restrict the suitability of
NWP, leading to a pressing need for enhanced modeling techniques. Neural
network-based models have emerged as promising alternatives, leveraging
data-driven approaches to forecast atmospheric variables. In this work, we
focus on limited-area modeling and train our model specifically for localized
region-level downstream tasks. As a case study, we consider the MENA region due
to its unique climatic challenges, where accurate localized weather forecasting
is crucial for managing water resources, agriculture and mitigating the impacts
of extreme weather events. This targeted approach allows us to tailor the
model's capabilities to the unique conditions of the region of interest. Our
study aims to validate the effectiveness of integrating parameter-efficient
fine-tuning (PEFT) methodologies, specifically Low-Rank Adaptation (LoRA) and
its variants, to enhance forecast accuracy, as well as training speed,
computational resource utilization, and memory efficiency in weather and
climate modeling for specific regions.

摘要：準確的天氣和氣候建模對於科學進步和保障社區免受環境風險至關重要。傳統方法嚴重依賴於數值天氣預測 (NWP) 模型，這些模型模擬地球系統中能量和物質的流動。然而，沉重的計算需求和低效率限制了 NWP 的適用性，導致對增強建模技術的迫切需求。基於神經網路的模型已成為有希望的替代方案，利用數據驅動方法來預測大氣變數。在這項工作中，我們專注於有限區域建模，並針對局部區域級別的下游任務訓練我們的模型。作為一個案例研究，我們考慮了 MENA 地區，因為它具有獨特的氣候挑戰，準確的局部天氣預測對於管理水資源、農業和減輕極端天氣事件的影響至關重要。這種有針對性的方法使我們能夠根據感興趣區域的獨特條件調整模型的能力。我們的研究旨在驗證整合參數高效微調 (PEFT) 方法（特別是低秩適應 (LoRA) 及其變體）的有效性，以增強預測準確性，以及天氣和氣候建模中特定區域的訓練速度、計算資源利用率和記憶體效率。

##### **DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer's Early Diagnosis**
2409.07584v1 by Ke Chen, Yifeng Wang, Yufei Zhou, Haohan Wang

In the field of Alzheimer's disease diagnosis, segmentation and
classification tasks are inherently interconnected. Sharing knowledge between
models for these tasks can significantly improve training efficiency,
particularly when training data is scarce. However, traditional knowledge
distillation techniques often struggle to bridge the gap between segmentation
and classification due to the distinct nature of tasks and different model
architectures. To address this challenge, we propose a dual-stream pipeline
that facilitates cross-task and cross-architecture knowledge sharing. Our
approach introduces a dual-stream embedding module that unifies feature
representations from segmentation and classification models, enabling
dimensional integration of these features to guide the classification model. We
validated our method on multiple 3D datasets for Alzheimer's disease diagnosis,
demonstrating significant improvements in classification performance,
especially on small datasets. Furthermore, we extended our pipeline with a
residual temporal attention mechanism for early diagnosis, utilizing images
taken before the atrophy of patients' brain mass. This advancement shows
promise in enabling diagnosis approximately six months earlier in mild and
asymptomatic stages, offering critical time for intervention.

摘要：在阿茲海默症診斷領域中，分割和分類任務本質上是相互關聯的。在這些任務的模型之間共享知識可以顯著提高訓練效率，特別是在訓練資料稀少的情況下。然而，由於任務的性質不同和模型架構不同，傳統的知識蒸餾技術通常難以彌合分割和分類之間的差距。為了應對這一挑戰，我們提出了一個雙流管線，它促進了跨任務和跨架構的知識共享。我們的做法引入了一個雙流嵌入模組，它統一了分割和分類模型中的特徵表示，從而能夠對這些特徵進行維度整合，以指導分類模型。我們在多個阿茲海默症診斷的 3D 資料集上驗證了我們的方法，證明了分類效能有顯著的提升，特別是在小型資料集上。此外，我們使用在患者腦質萎縮前拍攝的影像，將我們的管線擴充套件了一個殘差時間注意力機制，以進行早期診斷。這一進展顯示出在輕度和無症狀階段提前大約六個月進行診斷的可能性，為干預提供了關鍵時間。

##### **A Novel Mathematical Framework for Objective Evaluation of Ideas using a Conversational AI (CAI) System**
2409.07578v1 by B. Sankar, Dibakar Sen

The demand for innovation in product design necessitates a prolific ideation
phase. Conversational AI (CAI) systems that use Large Language Models (LLMs)
such as GPT (Generative Pre-trained Transformer) have been shown to be fruitful
in augmenting human creativity, providing numerous novel and diverse ideas.
Despite the success in ideation quantity, the qualitative assessment of these
ideas remains challenging and traditionally reliant on expert human evaluation.
This method suffers from limitations such as human judgment errors, bias, and
oversight. Addressing this gap, our study introduces a comprehensive
mathematical framework for automated analysis to objectively evaluate the
plethora of ideas generated by CAI systems and/or humans. This framework is
particularly advantageous for novice designers who lack experience in selecting
promising ideas. By converting the ideas into higher dimensional vectors and
quantitatively measuring the diversity between them using tools such as UMAP,
DBSCAN and PCA, the proposed method provides a reliable and objective way of
selecting the most promising ideas, thereby enhancing the efficiency of the
ideation phase.

摘要：產品設計創新需求，需要豐富的點子發想階段。使用大型語言模型 (LLM) 的對話式 AI (CAI) 系統，例如 GPT (生成式預訓練Transformer)，已被證明有助於提升人類創意，提供大量新穎且多元的點子。儘管在點子發想數量上獲得成功，但對這些點子的品質評估仍然具有挑戰性，且傳統上依賴於專家的人工評估。此方法有其限制，例如人為判斷錯誤、偏見和疏忽。針對此差距，我們的研究提出了一個全面的數學架構，用於自動化分析，以客觀評估 CAI 系統和/或人類產生的大量點子。此架構對於缺乏選擇有潛力點子經驗的新手設計師特別有利。透過將點子轉換為更高維度的向量，並使用 UMAP、DBSCAN 和 PCA 等工具，對它們之間的多樣性進行量化測量，所提出的方法提供了一種可靠且客觀的方式來選擇最有潛力的點子，進而提高點子發想階段的效率。

##### **Machine Learning and Constraint Programming for Efficient Healthcare Scheduling**
2409.07547v1 by Aymen Ben Said, Malek Mouhoub

Solving combinatorial optimization problems involve satisfying a set of hard
constraints while optimizing some objectives. In this context, exact or
approximate methods can be used. While exact methods guarantee the optimal
solution, they often come with an exponential running time as opposed to
approximate methods that trade the solutions quality for a better running time.
In this context, we tackle the Nurse Scheduling Problem (NSP). The NSP consist
in assigning nurses to daily shifts within a planning horizon such that
workload constraints are satisfied while hospitals costs and nurses preferences
are optimized. To solve the NSP, we propose implicit and explicit approaches.
In the implicit solving approach, we rely on Machine Learning methods using
historical data to learn and generate new solutions through the constraints and
objectives that may be embedded in the learned patterns. To quantify the
quality of using our implicit approach in capturing the embedded constraints
and objectives, we rely on the Frobenius Norm, a quality measure used to
compute the average error between the generated solutions and historical data.
To compensate for the uncertainty related to the implicit approach given that
the constraints and objectives may not be concretely visible in the produced
solutions, we propose an alternative explicit approach where we first model the
NSP using the Constraint Satisfaction Problem (CSP) framework. Then we develop
Stochastic Local Search methods and a new Branch and Bound algorithm enhanced
with constraint propagation techniques and variables/values ordering
heuristics. Since our implicit approach may not guarantee the feasibility or
optimality of the generated solution, we propose a data-driven approach to
passively learn the NSP as a constraint network. The learned constraint
network, formulated as a CSP, will then be solved using the methods we listed
earlier.

摘要：<paragraph>解決組合最佳化問題涉及滿足一組硬約束，同時最佳化一些目標。在此背景下，可以使用精確或近似方法。盡管精確方法保證最佳解，但與近似方法相比，它們通常具有指數級運行時間，而近似方法則以解決方案質量換取更好的運行時間。在此背景下，我們解決了護士排班問題 (NSP)。NSP 包括在規劃範圍內將護士分配到每日輪班，以便滿足工作負載約束，同時優化醫院成本和護士偏好。為了解決 NSP，我們提出了隱式和顯式方法。在隱式求解方法中，我們依賴機器學習方法，使用歷史數據通過約束和可能嵌入在學習模式中的目標來學習和生成新的解決方案。為了量化使用我們的隱式方法捕獲嵌入約束和目標的質量，我們依賴於 Frobenius 範數，這是一種用於計算生成解決方案和歷史數據之間平均誤差的質量度量。為了彌補與隱式方法相關的不確定性，因為約束和目標可能在產生的解決方案中並不明確可見，我們提出了一種替代的顯式方法，其中我們首先使用約束滿足問題 (CSP) 框架對 NSP 進行建模。然後，我們開發了隨機局部搜索方法和一種新的分支定界算法，並增強了約束傳播技術和變量/值排序啟發式方法。由於我們的隱式方法可能無法保證生成解決方案的可行性或最優性，因此我們提出了一種數據驅動的方法來被動地將 NSP 作為約束網絡進行學習。然後，將學習到的約束網絡（以 CSP 的形式制定）使用我們前面列出的方法進行求解。</paragraph>

##### **"My Grade is Wrong!": A Contestable AI Framework for Interactive Feedback in Evaluating Student Essays**
2409.07453v1 by Shengxin Hong, Chang Cai, Sixuan Du, Haiyue Feng, Siyuan Liu, Xiuyi Fan

Interactive feedback, where feedback flows in both directions between teacher
and student, is more effective than traditional one-way feedback. However, it
is often too time-consuming for widespread use in educational practice. While
Large Language Models (LLMs) have potential for automating feedback, they
struggle with reasoning and interaction in an interactive setting. This paper
introduces CAELF, a Contestable AI Empowered LLM Framework for automating
interactive feedback. CAELF allows students to query, challenge, and clarify
their feedback by integrating a multi-agent system with computational
argumentation. Essays are first assessed by multiple Teaching-Assistant Agents
(TA Agents), and then a Teacher Agent aggregates the evaluations through formal
reasoning to generate feedback and grades. Students can further engage with the
feedback to refine their understanding. A case study on 500 critical thinking
essays with user studies demonstrates that CAELF significantly improves
interactive feedback, enhancing the reasoning and interaction capabilities of
LLMs. This approach offers a promising solution to overcoming the time and
resource barriers that have limited the adoption of interactive feedback in
educational settings.

摘要：互動式回饋，也就是回饋在老師和學生之間雙向流動，比傳統單向回饋更有效。然而，在教育實務中廣泛使用互動式回饋往往會過於耗時。儘管大型語言模型 (LLM) 有自動化回饋的潛力，但它們在互動式環境中的推理和互動方面仍有困難。本文介紹 CAELF，一個可爭辯的人工智慧強化 LLM 架構，用於自動化互動式回饋。CAELF 透過整合一個具備計算論證的多重代理系統，讓學生可以查詢、質疑和釐清他們的回饋。論文首先由多位教學助理代理 (TA 代理) 評量，然後教師代理透過形式推理彙整這些評量，以產生回饋和評分。學生可以進一步參與回饋，以改善他們的理解。一個針對 500 篇批判性思考論文的案例研究，以及使用者研究，證明 CAELF 大幅改善了互動式回饋，增強了 LLM 的推理和互動能力。這種方法提供了一個有希望的解決方案，可以克服在教育環境中採用互動式回饋的時間和資源障礙。

##### **Still More Shades of Null: A Benchmark for Responsible Missing Value Imputation**
2409.07510v1 by Falaah Arif Khan, Denys Herasymuk, Nazar Protsiv, Julia Stoyanovich

We present Shades-of-NULL, a benchmark for responsible missing value
imputation. Our benchmark includes state-of-the-art imputation techniques, and
embeds them into the machine learning development lifecycle. We model realistic
missingness scenarios that go beyond Rubin's classic Missing Completely at
Random (MCAR), Missing At Random (MAR) and Missing Not At Random (MNAR), to
include multi-mechanism missingness (when different missingness patterns
co-exist in the data) and missingness shift (when the missingness mechanism
changes between training and test). Another key novelty of our work is that we
evaluate imputers holistically, based on the predictive performance, fairness
and stability of the models that are trained and tested on the data they
produce.
  We use Shades-of-NULL to conduct a large-scale empirical study involving
20,952 experimental pipelines, and find that, while there is no single
best-performing imputation approach for all missingness types, interesting
performance patterns do emerge when comparing imputer performance in simpler
vs. more complex missingness scenarios. Further, while predictive performance,
fairness and stability can be seen as orthogonal, we identify trade-offs among
them that arise due to the combination of missingness scenario, the choice of
an imputer, and the architecture of the model trained on the data
post-imputation. We make Shades-of-NULL publicly available, and hope to enable
researchers to comprehensively and rigorously evaluate new missing value
imputation methods on a wide range of evaluation metrics, in plausible and
socially meaningful missingness scenarios.

摘要：<paragraph>我們提出 Shades-of-NULL，這是一個負責任的遺漏值插補基準。我們的基準包含最先進的插補技術，並將它們嵌入機器學習開發生命週期中。我們模擬了超越 Rubin 經典的隨機完全遺失 (MCAR)、隨機遺失 (MAR) 和非隨機遺失 (MNAR) 的現實遺失情境，以納入多機制遺失（當資料中同時存在不同的遺失模式）和遺失轉移（當遺失機制在訓練和測試之間發生變化）。我們工作的另一個關鍵創新是我們根據預測效能、公平性和在他們產生的資料上訓練和測試的模型的穩定性，全面評估插補器。
我們使用 Shades-of-NULL 進行一項涉及 20,952 個實驗管線的大規模實證研究，並發現，雖然對於所有遺失類型沒有單一最佳執行插補方法，但在比較簡單與更複雜的遺失情境中插補器的效能時，出現了有趣的效能模式。此外，雖然預測效能、公平性和穩定性可以被視為正交的，但我們發現它們之間存在權衡，這是由於遺失情境、插補器選擇以及在資料插補後訓練的模型架構的組合所致。我們公開 Shades-of-NULL，並希望讓研究人員能夠在合理且社會有意義的遺失情境中，使用廣泛的評估指標，全面且嚴謹地評估新的遺失值插補方法。</paragraph>

##### **SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories**
2409.07440v1 by Ben Bogin, Kejuan Yang, Shashank Gupta, Kyle Richardson, Erin Bransom, Peter Clark, Ashish Sabharwal, Tushar Khot

Given that Large Language Models (LLMs) have made significant progress in
writing code, can they now be used to autonomously reproduce results from
research repositories? Such a capability would be a boon to the research
community, helping researchers validate, understand, and extend prior work. To
advance towards this goal, we introduce SUPER, the first benchmark designed to
evaluate the capability of LLMs in setting up and executing tasks from research
repositories. SUPERaims to capture the realistic challenges faced by
researchers working with Machine Learning (ML) and Natural Language Processing
(NLP) research repositories. Our benchmark comprises three distinct problem
sets: 45 end-to-end problems with annotated expert solutions, 152 sub problems
derived from the expert set that focus on specific challenges (e.g.,
configuring a trainer), and 602 automatically generated problems for
larger-scale development. We introduce various evaluation measures to assess
both task success and progress, utilizing gold solutions when available or
approximations otherwise. We show that state-of-the-art approaches struggle to
solve these problems with the best model (GPT-4o) solving only 16.3% of the
end-to-end set, and 46.1% of the scenarios. This illustrates the challenge of
this task, and suggests that SUPER can serve as a valuable resource for the
community to make and measure progress.

摘要：鉴于大型语言模型 (LLM) 在编写代码方面取得了显著进展，它们现在可否用于自主复制研究存储库中的结果？这种能力将对研究界大有裨益，有助于研究人员验证、理解和扩展先前的工作。为了实现这一目标，我们引入了 SUPER，这是第一个旨在评估 LLM 在设置和执行研究存储库中的任务的能力的基准。SUPER 旨在解决研究人员在使用机器学习 (ML) 和自然语言处理 (NLP) 研究存储库时面临的实际挑战。我们的基准包含三个不同的问题集：45 个带有专家解决方案注释的端到端问题、152 个从专家集中派生出来的子问题，这些子问题侧重于特定挑战（例如配置训练器），以及 602 个为更大规模开发自动生成的问题。我们引入了各种评估措施来评估任务成功和进度，在有黄金解决方案时使用黄金解决方案，否则使用近似值。我们表明，最先进的方法难以解决这些问题，最好的模型 (GPT-4o) 仅解决了 16.3% 的端到端集和 46.1% 的场景。这说明了这项任务的挑战性，并表明 SUPER 可以作为社区做出和衡量进步的宝贵资源。

##### **A Suite for Acoustic Language Model Evaluation**
2409.07437v1 by Gallil Maimon, Amit Roth, Yossi Adi

Speech language models have recently demonstrated great potential as
universal speech processing systems. Such models have the ability to model the
rich acoustic information existing in audio signals, beyond spoken content,
such as emotion, background noise, etc. Despite this, evaluation benchmarks
which evaluate awareness to a wide range of acoustic aspects, are lacking. To
help bridge this gap, we introduce SALMon, a novel evaluation suite
encompassing background noise, emotion, speaker identity and room impulse
response. The proposed benchmarks both evaluate the consistency of the
inspected element and how much it matches the spoken text. We follow a
modelling based approach, measuring whether a model gives correct samples
higher scores than incorrect ones. This approach makes the benchmark fast to
compute even for large models. We evaluated several speech language models on
SALMon, thus highlighting the strengths and weaknesses of each evaluated
method. Code and data are publicly available at
https://pages.cs.huji.ac.il/adiyoss-lab/salmon/ .

摘要：語音語言模型最近已展現出作為通用語音處理系統的巨大潛力。此類模型有能力對音訊訊號中存在的豐富聲學資訊進行建模，除了口說內容之外，例如情緒、背景噪音等。儘管如此，評估基準會評估對廣泛聲學層面的認識，卻有所欠缺。為了幫助彌補此差距，我們引進 SALMon，一個新穎的評估套件，包含背景噪音、情緒、說話者身分和房間脈衝響應。建議的基準同時評估所檢查元素的一致性，以及它與口說文字的匹配程度。我們採用基於建模的方法，測量模型是否給予正確樣本高於不正確樣本的分數。此方法讓基準即使對於大型模型也能快速運算。我們在 SALMon 上評估了數個語音語言模型，從而突顯每個評估方法的優缺點。程式碼和資料已公開於 https://pages.cs.huji.ac.il/adiyoss-lab/salmon/。

##### **Synthetic continued pretraining**
2409.07431v1 by Zitong Yang, Neil Band, Shuangping Li, Emmanuel Candès, Tatsunori Hashimoto

Pretraining on large-scale, unstructured internet text has enabled language
models to acquire a significant amount of world knowledge. However, this
knowledge acquisition is data-inefficient -- to learn a given fact, models must
be trained on hundreds to thousands of diverse representations of it. This
poses a challenge when adapting a pretrained model to a small corpus of
domain-specific documents, where each fact may appear rarely or only once. We
propose to bridge this gap with synthetic continued pretraining: using the
small domain-specific corpus to synthesize a large corpus more amenable to
learning, and then performing continued pretraining on the synthesized corpus.
We instantiate this proposal with EntiGraph, a synthetic data augmentation
algorithm that extracts salient entities from the source documents and then
generates diverse text by drawing connections between the sampled entities.
Synthetic continued pretraining using EntiGraph enables a language model to
answer questions and follow generic instructions related to the source
documents without access to them. If instead, the source documents are
available at inference time, we show that the knowledge acquired through our
approach compounds with retrieval-augmented generation. To better understand
these results, we build a simple mathematical model of EntiGraph, and show how
synthetic data augmentation can "rearrange" knowledge to enable more
data-efficient learning.

摘要：在规模庞大、结构松散的互联网文本上进行预训练，使语言模型能够获取大量的世界知识。然而，这种知识获取效率低下——为了学习一个给定的事实，模型必须接受数百到数千个不同表示形式的训练。当将预训练模型适应到一个包含特定领域文档的小语料库时，这会带来一个挑战，因为每个事实可能很少出现或只出现一次。我们建议用合成持续预训练来弥合理论差距：使用特定领域的小语料库来合成一个更容易学习的大语料库，然后对合成的语料库进行持续预训练。我们用 EntiGraph 实例化了此提议，这是一种合成数据扩充算法，它从源文档中提取显著实体，然后通过绘制抽样实体之间的联系来生成不同的文本。使用 EntiGraph 进行合成持续预训练使语言模型能够回答问题并遵循与源文档相关的通用说明，而无需访问它们。如果相反，源文档在推理时可用，我们表明通过我们的方法获得的知识与检索增强生成相结合。为了更好地理解这些结果，我们建立了一个 EntiGraph 的简单数学模型，并展示了合成数据扩充如何“重新排列”知识以实现更有效率的数据学习。

##### **Agent Workflow Memory**
2409.07429v1 by Zora Zhiruo Wang, Jiayuan Mao, Daniel Fried, Graham Neubig

Despite the potential of language model-based agents to solve real-world
tasks such as web navigation, current methods still struggle with long-horizon
tasks with complex action trajectories. In contrast, humans can flexibly solve
complex tasks by learning reusable task workflows from past experiences and
using them to guide future actions. To build agents that can similarly benefit
from this process, we introduce Agent Workflow Memory (AWM), a method for
inducing commonly reused routines, i.e., workflows, and selectively providing
workflows to the agent to guide subsequent generations. AWM flexibly applies to
both offline and online scenarios, where agents induce workflows from training
examples beforehand or from test queries on the fly. We experiment on two major
web navigation benchmarks -- Mind2Web and WebArena -- that collectively cover
1000+ tasks from 200+ domains across travel, shopping, and social media, among
others. AWM substantially improves the baseline results by 24.6% and 51.1%
relative success rate on Mind2Web and WebArena while reducing the number of
steps taken to solve WebArena tasks successfully. Furthermore, online AWM
robustly generalizes in cross-task, website, and domain evaluations, surpassing
baselines from 8.9 to 14.0 absolute points as train-test task distribution gaps
widen.

摘要：儘管基於語言模型的代理程式具有解決實際世界任務（例如網頁導覽）的潛力，但目前的方法仍難以應付具有複雜動作軌跡的長時程任務。相反地，人類可以透過從過去經驗中學習可重複使用的任務工作流程並使用它們來指導未來行動，靈活地解決複雜任務。為了建構可以從此過程中受益的代理程式，我們引入了代理程式工作流程記憶體 (AWM)，這是一種誘導常用重複常式（即工作流程）並有選擇性地提供工作流程給代理程式以指導後續世代的方法。AWM 可靈活應用於離線和線上場景，其中代理程式事先從訓練範例或從即時測試查詢中誘導工作流程。我們在兩個主要的網頁導覽基準 -- Mind2Web 和 WebArena -- 上進行實驗，這些基準共同涵蓋了來自旅遊、購物和社群媒體等 200 多個網域的 1000 多項任務。AWM 大幅改善了基準結果，在 Mind2Web 和 WebArena 上的相對成功率分別提高了 24.6% 和 51.1%，同時減少了成功解決 WebArena 任務所需的步驟數。此外，線上 AWM 在跨任務、網站和網域評估中強健地概括，超越了基準 8.9 至 14.0 個絕對點，因為訓練測試任務分佈差距擴大。

##### **Towards Fairer Health Recommendations: finding informative unbiased samples via Word Sense Disambiguation**
2409.07424v1 by Gavin Butts, Pegah Emdad, Jethro Lee, Shannon Song, Chiman Salavati, Willmar Sosa Diaz, Shiri Dori-Hacohen, Fabricio Murai

There have been growing concerns around high-stake applications that rely on
models trained with biased data, which consequently produce biased predictions,
often harming the most vulnerable. In particular, biased medical data could
cause health-related applications and recommender systems to create outputs
that jeopardize patient care and widen disparities in health outcomes. A recent
framework titled Fairness via AI posits that, instead of attempting to correct
model biases, researchers must focus on their root causes by using AI to debias
data. Inspired by this framework, we tackle bias detection in medical curricula
using NLP models, including LLMs, and evaluate them on a gold standard dataset
containing 4,105 excerpts annotated by medical experts for bias from a large
corpus. We build on previous work by coauthors which augments the set of
negative samples with non-annotated text containing social identifier terms.
However, some of these terms, especially those related to race and ethnicity,
can carry different meanings (e.g., "white matter of spinal cord"). To address
this issue, we propose the use of Word Sense Disambiguation models to refine
dataset quality by removing irrelevant sentences. We then evaluate fine-tuned
variations of BERT models as well as GPT models with zero- and few-shot
prompting. We found LLMs, considered SOTA on many NLP tasks, unsuitable for
bias detection, while fine-tuned BERT models generally perform well across all
evaluated metrics.

摘要：隨著仰賴由有偏差資料訓練的模型的高風險應用程式越來越多，人們也對此越來越感到憂心，因為這些模型會產生有偏差的預測，而這些預測通常會傷害到最弱勢的族群。特別是，有偏差的醫療資料可能會導致與健康相關的應用程式和推薦系統產生危害病患照護並擴大健康結果差異的輸出。最近一個名為「透過 AI 達成公平性」的架構主張，研究人員不應嘗試修正模型偏差，而必須透過使用 AI 來消除資料偏差，進而找出偏差的根源。受到這個架構的啟發，我們使用包括 LLM 在內的 NLP 模型來處理醫學課程中的偏差偵測，並在一個由醫學專家標註了 4,105 段摘錄的黃金標準資料集上對這些模型進行評估，該資料集來自一個包含大量語料庫的偏差。我們建立在共同作者之前的工作基礎上，該工作透過包含社會標識符詞彙的未標註文字來擴充負面範例的集合。然而，其中某些詞彙，特別是與種族和民族相關的詞彙，可能會帶有不同的意思（例如：「脊髓白質」）。為了解決這個問題，我們建議使用詞彙辨義模型來移除不相關的句子，進而改善資料集品質。接著，我們評估微調後的 BERT 模型變體，以及採用零次和少量提示的 GPT 模型。我們發現，儘管 LLM 在許多 NLP 任務上被認為是 SOTA，但並不適合用於偏差偵測，而微調後的 BERT 模型在所有評估指標上通常都有良好的表現。

##### **Enhancing adversarial robustness in Natural Language Inference using explanations**
2409.07423v1 by Alexandros Koulakos, Maria Lymperaiou, Giorgos Filandrianos, Giorgos Stamou

The surge of state-of-the-art Transformer-based models has undoubtedly pushed
the limits of NLP model performance, excelling in a variety of tasks. We cast
the spotlight on the underexplored task of Natural Language Inference (NLI),
since models trained on popular well-suited datasets are susceptible to
adversarial attacks, allowing subtle input interventions to mislead the model.
In this work, we validate the usage of natural language explanation as a
model-agnostic defence strategy through extensive experimentation: only by
fine-tuning a classifier on the explanation rather than premise-hypothesis
inputs, robustness under various adversarial attacks is achieved in comparison
to explanation-free baselines. Moreover, since there is no standard strategy of
testing the semantic validity of the generated explanations, we research the
correlation of widely used language generation metrics with human perception,
in order for them to serve as a proxy towards robust NLI models. Our approach
is resource-efficient and reproducible without significant computational
limitations.

摘要：隨著最先進的 Transformer 模型的興起，無疑地推動了 NLP 模型效能的極限，在各種任務中表現出色。我們將焦點放在自然語言推理 (NLI) 這個尚未充分探索的任務上，因為在廣受歡迎且適用的資料集上訓練的模型容易受到對抗性攻擊，允許微妙的輸入干預來誤導模型。在這項工作中，我們透過廣泛的實驗驗證了使用自然語言解釋作為與模型無關的防禦策略：僅透過微調分類器針對解釋，而不是前提假設輸入，與沒有解釋的基線相比，在各種對抗性攻擊下實現了穩健性。此外，由於沒有測試生成解釋的語義有效性的標準策略，我們研究了廣泛使用的語言生成指標與人類感知之間的關聯性，以便它們作為健全 NLI 模型的代理。我們的做法資源有效且可複製，沒有顯著的計算限制。

##### **Hierarchical Reinforcement Learning for Temporal Abstraction of Listwise Recommendation**
2409.07416v1 by Luo Ji, Gao Liu, Mingyang Yin, Hongxia Yang, Jingren Zhou

Modern listwise recommendation systems need to consider both long-term user
perceptions and short-term interest shifts. Reinforcement learning can be
applied on recommendation to study such a problem but is also subject to large
search space, sparse user feedback and long interactive latency. Motivated by
recent progress in hierarchical reinforcement learning, we propose a novel
framework called mccHRL to provide different levels of temporal abstraction on
listwise recommendation. Within the hierarchical framework, the high-level
agent studies the evolution of user perception, while the low-level agent
produces the item selection policy by modeling the process as a sequential
decision-making problem. We argue that such framework has a well-defined
decomposition of the outra-session context and the intra-session context, which
are encoded by the high-level and low-level agents, respectively. To verify
this argument, we implement both a simulator-based environment and an
industrial dataset-based experiment. Results observe significant performance
improvement by our method, compared with several well-known baselines. Data and
codes have been made public.

摘要：現代的清單推薦系統需要考慮長期的使用者感知和短期的興趣轉移。強化學習可以應用在推薦系統上來研究此類問題，但也會受到廣闊的搜尋空間、稀疏的使用者回饋和長的互動延遲影響。受到層級強化學習的最新進展啟發，我們提出了一個名為 mccHRL 的新框架，在清單推薦上提供不同層級的時間抽象。在層級框架中，高層級的代理研究使用者感知的演變，而低層級的代理則透過將流程建模為順序決策問題來產生項目選擇政策。我們認為此框架對超時段脈絡和時段內脈絡有明確的分解，分別由高層級和低層級代理編碼。為了驗證此論點，我們同時實作了基於模擬器的環境和基於產業資料集的實驗。與幾個著名的基準相比，結果觀察到我們的方法有顯著的效能提升。資料和程式碼已經公開。

##### **SoK: Security and Privacy Risks of Medical AI**
2409.07415v1 by Yuanhaur Chang, Han Liu, Evin Jaff, Chenyang Lu, Ning Zhang

The integration of technology and healthcare has ushered in a new era where
software systems, powered by artificial intelligence and machine learning, have
become essential components of medical products and services. While these
advancements hold great promise for enhancing patient care and healthcare
delivery efficiency, they also expose sensitive medical data and system
integrity to potential cyberattacks. This paper explores the security and
privacy threats posed by AI/ML applications in healthcare. Through a thorough
examination of existing research across a range of medical domains, we have
identified significant gaps in understanding the adversarial attacks targeting
medical AI systems. By outlining specific adversarial threat models for medical
settings and identifying vulnerable application domains, we lay the groundwork
for future research that investigates the security and resilience of AI-driven
medical systems. Through our analysis of different threat models and
feasibility studies on adversarial attacks in different medical domains, we
provide compelling insights into the pressing need for cybersecurity research
in the rapidly evolving field of AI healthcare technology.

摘要：科技與醫療的整合開啟了一個新紀元，由人工智慧和機器學習驅動的軟體系統已成為醫療產品和服務的必要組成部分。雖然這些進步對改善患者照護和醫療保健提供效率有很大的幫助，但它們也讓敏感的醫療資料和系統完整性面臨潛在的網路攻擊風險。本文探討了人工智慧/機器學習應用在醫療保健中帶來的安全性和隱私威脅。透過徹底檢視各項醫療領域現有的研究，我們發現了在了解針對醫療人工智慧系統的對抗性攻擊方面有顯著的差距。透過概述醫療環境的特定對抗性威脅模型並找出容易受攻擊的應用領域，我們為未來研究奠定基礎，探討人工智慧驅動醫療系統的安全性與復原力。透過分析不同的威脅模型和針對不同醫療領域的對抗性攻擊可行性研究，我們對人工智慧醫療保健技術快速發展領域中網路安全研究的迫切需求提供了令人信服的見解。

##### **CLNX: Bridging Code and Natural Language for C/C++ Vulnerability-Contributing Commits Identification**
2409.07407v1 by Zeqing Qin, Yiwei Wu, Lansheng Han

Large Language Models (LLMs) have shown great promise in vulnerability
identification. As C/C++ comprises half of the Open-Source Software (OSS)
vulnerabilities over the past decade and updates in OSS mainly occur through
commits, enhancing LLMs' ability to identify C/C++ Vulnerability-Contributing
Commits (VCCs) is essential. However, current studies primarily focus on
further pre-training LLMs on massive code datasets, which is resource-intensive
and poses efficiency challenges. In this paper, we enhance the ability of
BERT-based LLMs to identify C/C++ VCCs in a lightweight manner. We propose
CodeLinguaNexus (CLNX) as a bridge facilitating communication between C/C++
programs and LLMs. Based on commits, CLNX efficiently converts the source code
into a more natural representation while preserving key details. Specifically,
CLNX first applies structure-level naturalization to decompose complex
programs, followed by token-level naturalization to interpret complex symbols.
We evaluate CLNX on public datasets of 25,872 C/C++ functions with their
commits. The results show that CLNX significantly enhances the performance of
LLMs on identifying C/C++ VCCs. Moreover, CLNX-equipped CodeBERT achieves new
state-of-the-art and identifies 38 OSS vulnerabilities in the real world.

摘要：大型語言模型 (LLM) 在漏洞識別方面展現出極大的前景。由於 C/C++ 涵蓋了過去十年中一半的開源軟體 (OSS) 漏洞，而 OSS 更新主要透過提交進行，因此提升 LLM 識別 C/C++ 漏洞貢獻提交 (VCC) 的能力至關重要。然而，目前的研究主要集中於在大量的程式碼資料集上進一步預訓練 LLM，這需要大量的資源且會造成效率方面的挑戰。在本文中，我們以輕量化的方式提升 BERT-based LLM 識別 C/C++ VCC 的能力。我們提出 CodeLinguaNexus (CLNX) 作為促進 C/C++ 程式與 LLM 之間溝通的橋樑。CLNX 基於提交，將原始程式碼有效地轉換為更自然的表示形式，同時保留關鍵細節。具體來說，CLNX 首先應用結構層次自然化來分解複雜的程式，然後應用代碼層次自然化來解釋複雜的符號。我們在包含 25,872 個 C/C++ 函數及其提交的公開資料集上評估 CLNX。結果顯示，CLNX 大幅提升 LLM 識別 C/C++ VCC 的效能。此外，配備 CLNX 的 CodeBERT 達到新的技術水準，並在真實世界中識別出 38 個 OSS 漏洞。

##### **AdaCAD: Adaptively Decoding to Balance Conflicts between Contextual and Parametric Knowledge**
2409.07394v1 by Han Wang, Archiki Prasad, Elias Stengel-Eskin, Mohit Bansal

Knowledge conflict arises from discrepancies between information in the
context of a large language model (LLM) and the knowledge stored in its
parameters. This can hurt performance when using standard decoding techniques,
which tend to ignore the context. Existing test-time contrastive methods seek
to address this by comparing the LLM's output distribution with and without the
context and adjust the model according to the contrast between them. However,
we find that these methods frequently misjudge the degree of conflict and
struggle to handle instances that vary in their amount of conflict, with static
methods over-adjusting when conflict is absent. We propose a fine-grained,
instance-level approach called AdaCAD, which dynamically infers the weight of
adjustment based on the degree of conflict, as measured by the Jensen-Shannon
divergence between distributions representing contextual and parametric
knowledge. Our experiments across four models on six diverse question-answering
(QA) datasets and three summarization tasks demonstrate that our training-free
adaptive method consistently outperforms other decoding methods on QA, with
average accuracy gains of 14.21% (absolute) over a static contrastive baseline,
and improves the factuality of summaries by 5.59 (AlignScore). Furthermore, our
analysis shows that while decoding with contrastive baselines hurts performance
when conflict is absent, AdaCAD mitigates these losses, making it more
applicable to real-world datasets in which some examples have conflict and
others do not.

摘要：知識衝突源自於大型語言模型 (LLM) 中的資訊與儲存在其參數中的知識之間的差異。在使用標準解碼技術時，這可能會損害效能，因為這些技術往往會忽略上下文。現有的測試時間對比方法會透過比較 LLM 的輸出分佈（有上下文和無上下文）來解決這個問題，並根據它們之間的對比調整模型。然而，我們發現這些方法經常誤判衝突程度，且難以處理衝突量不同的實例，而靜態方法在沒有衝突時會過度調整。我們提出一個稱為 AdaCAD 的細緻化、實例層級方法，它會根據衝突程度動態推論調整權重，而衝突程度是由表示情境和參數知識的分佈之間的 Jensen-Shannon 散度所測量。我們在六個不同的問答 (QA) 資料集和三個摘要任務中，針對四個模型所做的實驗證明，我們的無訓練自適應方法在 QA 上始終優於其他解碼方法，平均準確度比靜態對比基準高出 14.21%（絕對值），並將摘要的事實性提高 5.59（AlignScore）。此外，我們的分析顯示，雖然使用對比基準進行解碼在沒有衝突時會損害效能，但 AdaCAD 減輕了這些損失，使其更適用於某些範例有衝突而另一些範例沒有衝突的真實世界資料集。

##### **Awaking the Slides: A Tuning-free and Knowledge-regulated AI Tutoring System via Language Model Coordination**
2409.07372v1 by Daniel Zhang-Li, Zheyuan Zhang, Jifan Yu, Joy Lim Jia Yin, Shangqing Tu, Linlu Gong, Haohua Wang, Zhiyuan Liu, Huiqin Liu, Lei Hou, Juanzi Li

The vast pre-existing slides serve as rich and important materials to carry
lecture knowledge. However, effectively leveraging lecture slides to serve
students is difficult due to the multi-modal nature of slide content and the
heterogeneous teaching actions. We study the problem of discovering effective
designs that convert a slide into an interactive lecture. We develop
Slide2Lecture, a tuning-free and knowledge-regulated intelligent tutoring
system that can (1) effectively convert an input lecture slide into a
structured teaching agenda consisting of a set of heterogeneous teaching
actions; (2) create and manage an interactive lecture that generates responsive
interactions catering to student learning demands while regulating the
interactions to follow teaching actions. Slide2Lecture contains a complete
pipeline for learners to obtain an interactive classroom experience to learn
the slide. For teachers and developers, Slide2Lecture enables customization to
cater to personalized demands. The evaluation rated by annotators and students
shows that Slide2Lecture is effective in outperforming the remaining
implementation. Slide2Lecture's online deployment has made more than 200K
interaction with students in the 3K lecture sessions. We open source
Slide2Lecture's implementation in
https://anonymous.4open.science/r/slide2lecture-4210/.

摘要：既有的豐富簡報投影片，是傳遞課程知識的重要素材。不過，由於簡報投影片的內容多元，教學行為又相當多元，要有效運用簡報投影片來服務學生，相當困難。本研究探討找出有效設計，將簡報投影片轉化為互動式課程。我們開發出 Slide2Lecture，這是一個無需調整參數、知識導向的智慧教學系統，可以：(1) 有效將輸入的課程簡報投影片，轉換成由一系列多元教學行為組成的結構化教學計畫；(2) 建立並管理互動式課程，產生回應式的互動，以滿足學生的學習需求，同時調整互動，以遵循教學行為。Slide2Lecture 包含一個完整的流程，讓學習者可以獲得互動式教室體驗，以學習簡報投影片。對於教師和開發人員，Slide2Lecture 能夠客製化，以滿足個人需求。經由註解者和學生評分，Slide2Lecture 的表現優於其他實作。Slide2Lecture 的線上部署，已在 3K 堂課程中與學生產生超過 20 萬次的互動。我們開放 Slide2Lecture 的實作原始碼，網址為 https://anonymous.4open.science/r/slide2lecture-4210/。

##### **Demo: SGCode: A Flexible Prompt-Optimizing System for Secure Generation of Code**
2409.07368v1 by Khiem Ton, Nhi Nguyen, Mahmoud Nazzal, Abdallah Khreishah, Cristian Borcea, NhatHai Phan, Ruoming Jin, Issa Khalil, Yelong Shen

This paper introduces SGCode, a flexible prompt-optimizing system to generate
secure code with large language models (LLMs). SGCode integrates recent
prompt-optimization approaches with LLMs in a unified system accessible through
front-end and back-end APIs, enabling users to 1) generate secure code, which
is free of vulnerabilities, 2) review and share security analysis, and 3)
easily switch from one prompt optimization approach to another, while providing
insights on model and system performance. We populated SGCode on an AWS server
with PromSec, an approach that optimizes prompts by combining an LLM and
security tools with a lightweight generative adversarial graph neural network
to detect and fix security vulnerabilities in the generated code. Extensive
experiments show that SGCode is practical as a public tool to gain insights
into the trade-offs between model utility, secure code generation, and system
cost. SGCode has only a marginal cost compared with prompting LLMs. SGCode is
available at: http://3.131.141.63:8501/.

摘要：本文介紹 SGCode，這是一個彈性的提示最佳化系統，用於使用大型語言模型 (LLM) 產生安全的程式碼。SGCode 將最近的提示最佳化方法與 LLM 整合在一個統一的系統中，可透過前端和後端 API 存取，使用戶能夠 1) 產生安全的程式碼，沒有漏洞，2) 檢閱並分享安全性分析，以及 3) 輕鬆從一種提示最佳化方法切換到另一種方法，同時提供模型和系統效能的見解。我們在 AWS 伺服器上使用 PromSec 填充 SGCode，這是一種透過結合 LLM 和安全性工具與輕量級生成對抗圖神經網路來最佳化提示的方法，用於偵測並修正產生程式碼中的安全性漏洞。廣泛的實驗顯示，SGCode 是一個實用的公開工具，可用於深入了解模型效用、安全程式碼產生和系統成本之間的權衡。與提示 LLM 相比，SGCode 僅有微小的成本。SGCode 可在以下網址取得：http://3.131.141.63:8501/。

##### **Think Together and Work Better: Combining Humans' and LLMs' Think-Aloud Outcomes for Effective Text Evaluation**
2409.07355v1 by SeongYeub Chu, JongWoo Kim, MunYong Yi

This study introduces \textbf{InteractEval}, a framework that integrates
human expertise and Large Language Models (LLMs) using the Think-Aloud (TA)
method to generate attributes for checklist-based text evaluation. By combining
human flexibility and reasoning with LLM consistency, InteractEval outperforms
traditional non-LLM-based and LLM-based baselines across four distinct
dimensions, consisting of Coherence, Fluency, Consistency, and Relevance. The
experiment also investigates the effectiveness of the TA method, showing that
it promotes divergent thinking in both humans and LLMs, leading to the
generation of a wider range of relevant attributes and enhance text evaluation
performance. Comparative analysis reveals that humans excel at identifying
attributes related to internal quality (Coherence and Fluency), but LLMs
perform better at those attributes related to external alignment (Consistency
and Relevance). Consequently, leveraging both humans and LLMs together produces
the best evaluation outcomes. In other words, this study emphasizes the
necessity of effectively combining humans and LLMs in an automated
checklist-based text evaluation framework. The code is available at
\textbf{\url{https://github.com/BBeeChu/InteractEval.git}}.

摘要：本研究引入了 **InteractEval**，一個整合人類專業知識和大型語言模型 (LLM) 的框架，使用思考出聲 (TA) 方法為基於核對清單的文字評估產生屬性。透過結合人類的靈活性與推理能力和 LLM 的一致性，InteractEval 在四個不同的面向（包括一致性、流暢度、連貫性和相關性）上優於傳統的非 LLM 基準和 LLM 基準。實驗也探討了 TA 方法的有效性，顯示它能促進人類和 LLM 的發散性思考，從而產生更廣泛相關屬性並提升文字評估的表現。比較分析顯示，人類擅於找出與內部品質（一致性和流暢度）相關的屬性，但 LLM 在與外部對齊（連貫性和相關性）相關的屬性上表現得更好。因此，同時利用人類和 LLM 能產生最佳的評估結果。換句話說，本研究強調在自動化的基於核對清單的文字評估框架中有效結合人類和 LLM 的必要性。程式碼可在 **\url{https://github.com/BBeeChu/InteractEval.git}** 取得。

##### **Securing Vision-Language Models with a Robust Encoder Against Jailbreak and Adversarial Attacks**
2409.07353v1 by Md Zarif Hossain, Ahmed Imteaj

Large Vision-Language Models (LVLMs), trained on multimodal big datasets,
have significantly advanced AI by excelling in vision-language tasks. However,
these models remain vulnerable to adversarial attacks, particularly jailbreak
attacks, which bypass safety protocols and cause the model to generate
misleading or harmful responses. This vulnerability stems from both the
inherent susceptibilities of LLMs and the expanded attack surface introduced by
the visual modality. We propose Sim-CLIP+, a novel defense mechanism that
adversarially fine-tunes the CLIP vision encoder by leveraging a Siamese
architecture. This approach maximizes cosine similarity between perturbed and
clean samples, facilitating resilience against adversarial manipulations.
Sim-CLIP+ offers a plug-and-play solution, allowing seamless integration into
existing LVLM architectures as a robust vision encoder. Unlike previous
defenses, our method requires no structural modifications to the LVLM and
incurs minimal computational overhead. Sim-CLIP+ demonstrates effectiveness
against both gradient-based adversarial attacks and various jailbreak
techniques. We evaluate Sim-CLIP+ against three distinct jailbreak attack
strategies and perform clean evaluations using standard downstream datasets,
including COCO for image captioning and OKVQA for visual question answering.
Extensive experiments demonstrate that Sim-CLIP+ maintains high clean accuracy
while substantially improving robustness against both gradient-based
adversarial attacks and jailbreak techniques. Our code and robust vision
encoders are available at
https://github.com/speedlab-git/Robust-Encoder-against-Jailbreak-attack.git.

摘要：<paragraph>大型視覺語言模型 (LVLMs) 接受過多模態大型資料集的訓練，在視覺語言任務中表現出色，大幅提升了人工智慧。然而，這些模型仍然容易受到對抗性攻擊，特別是越獄攻擊，這會繞過安全協定並導致模型產生誤導或有害的回應。此漏洞源於 LLM 本身的易受攻擊性，以及視覺模態所帶來的擴充攻擊面。我們提出 Sim-CLIP+，這是一種新穎的防禦機制，透過利用 Siamese 架構對抗性微調 CLIP 視覺編碼器。此方法最大化擾動和乾淨樣本之間的餘弦相似性，以利於對抗對抗性操作。Sim-CLIP+ 提供即插即用解決方案，可作為強健的視覺編碼器無縫整合至現有的 LVLM 架構。與先前的防禦措施不同，我們的做法不需要對 LVLM 進行結構修改，且運算負擔極小。Sim-CLIP+ 已證實對抗梯度式對抗性攻擊和各種越獄技術有效。我們針對三種不同的越獄攻擊策略評估 Sim-CLIP+，並使用標準下游資料集（包括用於影像標題的 COCO 和用於視覺問題解答的 OKVQA）執行乾淨評估。廣泛的實驗證明，Sim-CLIP+ 在大幅提升對抗梯度式對抗性攻擊和越獄技術的強健性的同時，維持高度的乾淨準確度。我們的程式碼和強健的視覺編碼器可在 https://github.com/speedlab-git/Robust-Encoder-against-Jailbreak-attack.git 取得。</paragraph>

##### **Federated Impression for Learning with Distributed Heterogeneous Data**
2409.07351v1 by Sana Ayromlou, Atrin Arya, Armin Saadat, Purang Abolmaesumi, Xiaoxiao Li

Standard deep learning-based classification approaches may not always be
practical in real-world clinical applications, as they require a centralized
collection of all samples. Federated learning (FL) provides a paradigm that can
learn from distributed datasets across clients without requiring them to share
data, which can help mitigate privacy and data ownership issues. In FL,
sub-optimal convergence caused by data heterogeneity is common among data from
different health centers due to the variety in data collection protocols and
patient demographics across centers. Through experimentation in this study, we
show that data heterogeneity leads to the phenomenon of catastrophic forgetting
during local training. We propose FedImpres which alleviates catastrophic
forgetting by restoring synthetic data that represents the global information
as federated impression. To achieve this, we distill the global model resulting
from each communication round. Subsequently, we use the synthetic data
alongside the local data to enhance the generalization of local training.
Extensive experiments show that the proposed method achieves state-of-the-art
performance on both the BloodMNIST and Retina datasets, which contain label
imbalance and domain shift, with an improvement in classification accuracy of
up to 20%.

摘要：標準的深度學習分類方法在實際的臨床應用中可能並不總是實用的，因為它們需要集中收集所有樣本。聯邦學習 (FL) 提供了一個範例，可以在不讓客戶端分享數據的情況下從分布式數據集學習，這有助於減輕隱私和數據所有權問題。在 FL 中，由於不同醫療中心的數據收集協定和患者人口統計資料的差異，來自不同醫療中心的數據之間常見的數據異質性會導致次最佳收斂。透過本研究中的實驗，我們表明數據異質性會導致局部訓練期間發生災難性遺忘現象。我們提出 FedImpres，它透過還原表示全球資訊的合成資料作為聯邦印象來減輕災難性遺忘。為此，我們提煉出每一輪通訊所產生的全球模型。隨後，我們使用合成資料和本地資料來增強本地訓練的概括性。廣泛的實驗表明，所提出的方法在 BloodMNIST 和 Retina 數據集上都達到了最先進的效能，這些數據集包含標籤不平衡和領域轉移，分類準確度提高了 20%。

##### **Online Decision MetaMorphFormer: A Casual Transformer-Based Reinforcement Learning Framework of Universal Embodied Intelligence**
2409.07341v1 by Luo Ji, Runji Lin

Interactive artificial intelligence in the motion control field is an
interesting topic, especially when universal knowledge is adaptive to multiple
tasks and universal environments. Despite there being increasing efforts in the
field of Reinforcement Learning (RL) with the aid of transformers, most of them
might be limited by the offline training pipeline, which prohibits exploration
and generalization abilities. To address this limitation, we propose the
framework of Online Decision MetaMorphFormer (ODM) which aims to achieve
self-awareness, environment recognition, and action planning through a unified
model architecture. Motivated by cognitive and behavioral psychology, an ODM
agent is able to learn from others, recognize the world, and practice itself
based on its own experience. ODM can also be applied to any arbitrary agent
with a multi-joint body, located in different environments, and trained with
different types of tasks using large-scale pre-trained datasets. Through the
use of pre-trained datasets, ODM can quickly warm up and learn the necessary
knowledge to perform the desired task, while the target environment continues
to reinforce the universal policy. Extensive online experiments as well as
few-shot and zero-shot environmental tests are used to verify ODM's performance
and generalization ability. The results of our study contribute to the study of
general artificial intelligence in embodied and cognitive fields. Code,
results, and video examples can be found on the website
\url{https://rlodm.github.io/odm/}.

摘要：運動控制領域的互動式人工智慧是一個有趣的議題，特別是在通用知識適用於多項任務和通用環境時。儘管在強化學習（RL）領域中，在Transformer的幫助下付出了越來越多的努力，但其中大部分可能受到離線訓練管線的限制，這會禁止探索和概括能力。為了解決這個限制，我們提出了線上決策 MetaMorphFormer（ODM）架構，其目標是透過統一的模型架構來實現自我意識、環境識別和動作規劃。在認知和行為心理學的激勵下，ODM 代理能夠從他人學習、認識世界並根據自己的經驗練習。ODM 也可以應用於任何具有多關節身體、位於不同環境中的任意代理，並使用大型預先訓練的資料集訓練不同類型的任務。透過使用預先訓練的資料集，ODM 可以快速熱身並學習執行所需任務的必要知識，而目標環境會持續強化通用政策。廣泛的線上實驗以及少次嘗試和零次嘗試的環境測試用於驗證 ODM 的效能和概括能力。我們研究的結果有助於具身和認知領域中通用人工智慧的研究。程式碼、結果和影片範例可以在網站上找到：\url{https://rlodm.github.io/odm/}。

##### **Explanation, Debate, Align: A Weak-to-Strong Framework for Language Model Generalization**
2409.07335v1 by Mehrdad Zakershahrak, Samira Ghodratnama

The rapid advancement of artificial intelligence systems has brought the
challenge of AI alignment to the forefront of research, particularly in complex
decision-making and task execution. As these systems surpass human-level
performance in sophisticated problems, ensuring their alignment with human
values, intentions, and ethical guidelines becomes crucial. Building on
previous work in explanation generation for human-agent alignment, we address
the more complex dynamics of multi-agent systems and human-AI teams. This paper
introduces a novel approach to model alignment through weak-to-strong
generalization in the context of language models. We present a framework where
a strong model facilitates the improvement of a weaker model, bridging the gap
between explanation generation and model alignment. Our method, formalized as a
facilitation function, allows for the transfer of capabilities from advanced
models to less capable ones without direct access to extensive training data.
Our results suggest that this facilitation-based approach not only enhances
model performance but also provides insights into the nature of model alignment
and the potential for scalable oversight of AI systems.

摘要：人工智慧系統的快速進步，讓 AI 對齊的挑戰成為研究的最前線，特別是在複雜的決策制定和任務執行中。由於這些系統在複雜問題中超越人類層級的表現，確保它們與人類價值觀、意圖和道德準則保持一致變得至關重要。建立在先前人類代理對齊的解釋產生工作基礎上，我們探討了多代理系統和人類 AI 團隊更複雜的動態。本文介紹了一種透過語言模型中從弱到強概括來建模對齊的新方法。我們提出了一個架構，其中強大的模型促進了較弱模型的改進，縮小了解釋產生和模型對齊之間的差距。我們的這個方法形式化為一個促進功能，允許從進階模型將能力轉移到較弱的模型，而無需直接存取廣泛的訓練資料。我們的結果表明，這種基於促進的方法不僅增強了模型效能，還提供了對模型對齊的本質和 AI 系統可擴充監督的潛力的見解。

##### **Module-wise Adaptive Adversarial Training for End-to-end Autonomous Driving**
2409.07321v1 by Tianyuan Zhang, Lu Wang, Jiaqi Kang, Xinwei Zhang, Siyuan Liang, Yuwei Chen, Aishan Liu, Xianglong Liu

Recent advances in deep learning have markedly improved autonomous driving
(AD) models, particularly end-to-end systems that integrate perception,
prediction, and planning stages, achieving state-of-the-art performance.
However, these models remain vulnerable to adversarial attacks, where
human-imperceptible perturbations can disrupt decision-making processes. While
adversarial training is an effective method for enhancing model robustness
against such attacks, no prior studies have focused on its application to
end-to-end AD models. In this paper, we take the first step in adversarial
training for end-to-end AD models and present a novel Module-wise Adaptive
Adversarial Training (MA2T). However, extending conventional adversarial
training to this context is highly non-trivial, as different stages within the
model have distinct objectives and are strongly interconnected. To address
these challenges, MA2T first introduces Module-wise Noise Injection, which
injects noise before the input of different modules, targeting training models
with the guidance of overall objectives rather than each independent module
loss. Additionally, we introduce Dynamic Weight Accumulation Adaptation, which
incorporates accumulated weight changes to adaptively learn and adjust the loss
weights of each module based on their contributions (accumulated reduction
rates) for better balance and robust training. To demonstrate the efficacy of
our defense, we conduct extensive experiments on the widely-used nuScenes
dataset across several end-to-end AD models under both white-box and black-box
attacks, where our method outperforms other baselines by large margins
(+5-10%). Moreover, we validate the robustness of our defense through
closed-loop evaluation in the CARLA simulation environment, showing improved
resilience even against natural corruption.

摘要：<paragraph>深度學習的最新進展顯著改善了自動駕駛 (AD) 模型，特別是整合感知、預測和規劃階段的端到端系統，達到了最先進的效能。
然而，這些模型仍然容易受到對抗性攻擊，其中人類無法察覺的擾動會破壞決策制定過程。雖然對抗性訓練是一種增強模型對抗此類攻擊的有效方法，但沒有先前的研究專注於將其應用於端到端 AD 模型。在本文中，我們採取了端到端 AD 模型對抗性訓練的第一步，並提出了一種新穎的模組化自適應對抗性訓練 (MA2T)。然而，將傳統的對抗性訓練擴展到這個背景下非常困難，因為模型中的不同階段有不同的目標，並且緊密相連。為了應對這些挑戰，MA2T 首先引入了模組化雜訊注入，它在不同模組的輸入之前注入雜訊，以整體目標的指導訓練模型，而不是每個獨立模組的損失。此外，我們引入了動態權重累積適應，它結合了累積的權重變化，根據其貢獻（累積的減少率）自適應地學習和調整每個模組的損失權重，以獲得更好的平衡和穩健的訓練。為了證明我們防禦的有效性，我們在廣泛使用的 nuScenes 資料集上對多個端到端 AD 模型進行了廣泛的實驗，在白盒和黑盒攻擊下，我們的模型以很大的幅度（+5-10%）優於其他基線。此外，我們通過在 CARLA 模擬環境中進行閉環評估驗證了我們防禦的穩健性，即使面對自然破壞，也顯示出改進的復原力。</paragraph>

##### **MEDIC: Towards a Comprehensive Framework for Evaluating LLMs in Clinical Applications**
2409.07314v1 by Praveen K Kanithi, Clément Christophe, Marco AF Pimentel, Tathagata Raha, Nada Saadi, Hamza Javed, Svetlana Maslenkova, Nasir Hayat, Ronnie Rajan, Shadab Khan

The rapid development of Large Language Models (LLMs) for healthcare
applications has spurred calls for holistic evaluation beyond frequently-cited
benchmarks like USMLE, to better reflect real-world performance. While
real-world assessments are valuable indicators of utility, they often lag
behind the pace of LLM evolution, likely rendering findings obsolete upon
deployment. This temporal disconnect necessitates a comprehensive upfront
evaluation that can guide model selection for specific clinical applications.
We introduce MEDIC, a framework assessing LLMs across five critical dimensions
of clinical competence: medical reasoning, ethics and bias, data and language
understanding, in-context learning, and clinical safety. MEDIC features a novel
cross-examination framework quantifying LLM performance across areas like
coverage and hallucination detection, without requiring reference outputs. We
apply MEDIC to evaluate LLMs on medical question-answering, safety,
summarization, note generation, and other tasks. Our results show performance
disparities across model sizes, baseline vs medically finetuned models, and
have implications on model selection for applications requiring specific model
strengths, such as low hallucination or lower cost of inference. MEDIC's
multifaceted evaluation reveals these performance trade-offs, bridging the gap
between theoretical capabilities and practical implementation in healthcare
settings, ensuring that the most promising models are identified and adapted
for diverse healthcare applications.

摘要：大型語言模型 (LLM) 在醫療保健應用方面的快速發展，促使人們呼籲進行整體評估，超越經常引用的基準（例如 USMLE），以更好地反映實際效能。儘管實際評估是實用性的寶貴指標，但它們通常落後於 LLM 演化的速度，在部署後可能會使研究結果過時。這種時間上的脫節需要進行全面的前期評估，以指導特定臨床應用程式的模型選擇。我們引進 MEDIC，一個評估 LLM 跨越臨床能力的五個關鍵面向的架構：醫療推理、倫理和偏差、資料和語言理解、情境學習和臨床安全性。MEDIC 採用一種新穎的交互式檢查架構，量化 LLM 在涵蓋範圍和幻覺偵測等領域的效能，而不需要參考輸出。我們使用 MEDIC 來評估 LLM 在醫療問題解答、安全性、摘要、筆記產生和其他任務上的表現。我們的結果顯示，不同模型大小、基準與經過醫療微調的模型之間的效能差異，並對需要特定模型優勢的應用程式（例如低幻覺或較低的推論成本）的模型選擇產生影響。MEDIC 的多面向評估揭示了這些效能權衡，縮小了理論能力與醫療保健環境中的實際實作之間的差距，確保找出最有希望的模型，並針對不同的醫療保健應用程式進行調整。

##### **Exploring User-level Gradient Inversion with a Diffusion Prior**
2409.07291v1 by Zhuohang Li, Andrew Lowy, Jing Liu, Toshiaki Koike-Akino, Bradley Malin, Kieran Parsons, Ye Wang

We explore user-level gradient inversion as a new attack surface in
distributed learning. We first investigate existing attacks on their ability to
make inferences about private information beyond training data reconstruction.
Motivated by the low reconstruction quality of existing methods, we propose a
novel gradient inversion attack that applies a denoising diffusion model as a
strong image prior in order to enhance recovery in the large batch setting.
Unlike traditional attacks, which aim to reconstruct individual samples and
suffer at large batch and image sizes, our approach instead aims to recover a
representative image that captures the sensitive shared semantic information
corresponding to the underlying user. Our experiments with face images
demonstrate the ability of our methods to recover realistic facial images along
with private user attributes.

摘要：我們探索使用者層級梯度反轉作為分散式學習中新的攻擊面。我們首先調查現有攻擊，了解它們推論訓練資料重建以外的私人資訊的能力。在現有方法重建品質低落的動機下，我們提出一個新穎的梯度反轉攻擊，它採用去噪擴散模型作為強大的影像先驗，以增強在大批次設定中的復原能力。與傳統攻擊不同的是，傳統攻擊旨在重建個別樣本，並在大量的批次和影像大小中受苦，我們的做法反而旨在復原一個代表性的影像，捕捉與底層使用者相應的敏感共享語義資訊。我們對人臉影像進行的實驗證明了我們的方法能夠復原逼真的臉部影像，以及私人使用者屬性。

##### **Using Generative Agents to Create Tip Sheets for Investigative Data Reporting**
2409.07286v1 by Joris Veerbeek, Nicholas Diakopoulos

This paper introduces a system using generative AI agents to create tip
sheets for investigative data reporting. Our system employs three specialized
agents--an analyst, a reporter, and an editor--to collaboratively generate and
refine tips from datasets. We validate this approach using real-world
investigative stories, demonstrating that our agent-based system generally
generates more newsworthy and accurate insights compared to a baseline model
without agents, although some variability was noted between different stories.
Our findings highlight the potential of generative AI to provide leads for
investigative data reporting.

摘要：本論文介紹一個系統，利用生成式 AI 代理來為調查資料報導建立提示清單。我們的系統採用三個專業代理——分析師、記者和編輯——來協作生成和優化來自資料集的提示。我們使用真實世界的調查報導來驗證此方法，證明我們的基於代理的系統通常會產生比沒有代理的基線模型更多有新聞價值且準確的見解，儘管在不同的報導之間會有一些差異。我們的發現突顯了生成式 AI 為調查資料報導提供線索的潛力。

##### **Cross-Dialect Text-To-Speech in Pitch-Accent Language Incorporating Multi-Dialect Phoneme-Level BERT**
2409.07265v1 by Kazuki Yamauchi, Yuki Saito, Hiroshi Saruwatari

We explore cross-dialect text-to-speech (CD-TTS), a task to synthesize
learned speakers' voices in non-native dialects, especially in pitch-accent
languages. CD-TTS is important for developing voice agents that naturally
communicate with people across regions. We present a novel TTS model comprising
three sub-modules to perform competitively at this task. We first train a
backbone TTS model to synthesize dialect speech from a text conditioned on
phoneme-level accent latent variables (ALVs) extracted from speech by a
reference encoder. Then, we train an ALV predictor to predict ALVs tailored to
a target dialect from input text leveraging our novel multi-dialect
phoneme-level BERT. We conduct multi-dialect TTS experiments and evaluate the
effectiveness of our model by comparing it with a baseline derived from
conventional dialect TTS methods. The results show that our model improves the
dialectal naturalness of synthetic speech in CD-TTS.

摘要：我們探討跨方言文字轉語音 (CD-TTS)，這項任務用於合成學習者在非母語方言中的聲音，特別是在音高重音語言中。CD-TTS 對於開發能與不同地區的人自然溝通的語音代理非常重要。我們提出一個新穎的 TTS 模型，包含三個子模組，以在這個任務中表現出色。我們首先訓練一個主幹 TTS 模型，從一個受語音中由參考編碼器提取的音素級重音潛在變數 (ALV) 條件化的文字中合成方言語音。然後，我們訓練一個 ALV 預測器，利用我們新穎的多方言音素級 BERT 從輸入文字中預測適合目標方言的 ALV。我們進行多方言 TTS 實驗，並透過將我們的模型與源自傳統方言 TTS 方法的基準進行比較，來評估其有效性。結果顯示我們的模型改善了 CD-TTS 中合成語音的方言自然性。

##### **Propaganda to Hate: A Multimodal Analysis of Arabic Memes with Multi-Agent LLMs**
2409.07246v1 by Firoj Alam, Md. Rafiul Biswas, Uzair Shah, Wajdi Zaghouani, Georgios Mikros

In the past decade, social media platforms have been used for information
dissemination and consumption. While a major portion of the content is posted
to promote citizen journalism and public awareness, some content is posted to
mislead users. Among different content types such as text, images, and videos,
memes (text overlaid on images) are particularly prevalent and can serve as
powerful vehicles for propaganda, hate, and humor. In the current literature,
there have been efforts to individually detect such content in memes. However,
the study of their intersection is very limited. In this study, we explore the
intersection between propaganda and hate in memes using a multi-agent LLM-based
approach. We extend the propagandistic meme dataset with coarse and
fine-grained hate labels. Our finding suggests that there is an association
between propaganda and hate in memes. We provide detailed experimental results
that can serve as a baseline for future studies. We will make the experimental
resources publicly available to the community.

摘要：在過去十年中，社群媒體平台已用於資訊傳播和消費。雖然大部分內容是為了推廣公民新聞和公眾意識而發布，但有些內容是為了誤導使用者而發布。在文字、圖片和影片等不同內容類型中，迷因（疊加在圖片上的文字）特別普遍，可用作宣傳、仇恨和幽默的有力媒介。在目前的文獻中，已嘗試個別偵測迷因中的此類內容。然而，對其交集的研究非常有限。在本研究中，我們使用基於多代理 LLM 的方法探討迷因中宣傳和仇恨之間的交集。我們使用粗略和細粒度的仇恨標籤擴充宣傳迷因資料集。我們的研究結果表明，迷因中的宣傳和仇恨之間存在關聯。我們提供了詳細的實驗結果，可作為未來研究的基準。我們將使實驗資源公開提供給社群。

