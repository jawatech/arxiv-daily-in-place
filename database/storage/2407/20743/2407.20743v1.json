{"2407.20743": {"publish_time": "2024-07-30", "title": "Meltemi: The first open Large Language Model for Greek", "paper_summary": "We describe the development and capabilities of Meltemi 7B, the first open\nLarge Language Model for the Greek language. Meltemi 7B has 7 billion\nparameters and is trained on a 40 billion token Greek corpus. For the\ndevelopment of Meltemi 7B, we adapt Mistral, by continuous pretraining on the\nGreek Corpus. Meltemi 7B contains up-to-date information up to September 2023.\nFurthermore, we have translated and curated a Greek instruction corpus, which\nhas been used for the instruction-tuning of a chat model, named Meltemi 7B\nInstruct. Special care has been given to the alignment and the removal of toxic\ncontent for the Meltemi 7B Instruct. The developed models are evaluated on a\nbroad set of collected evaluation corpora, and examples of prompts and\nresponses are presented. Both Meltemi 7B and Meltemi 7B Instruct are available\nat https://huggingface.co/ilsp under the Apache 2.0 license.", "paper_summary_zh": "\u6211\u5011\u63cf\u8ff0\u4e86 Meltemi 7B \u7684\u958b\u767c\u548c\u529f\u80fd\uff0c\u9019\u662f\u7b2c\u4e00\u500b\u958b\u653e\u7684\u5e0c\u81d8\u8a9e\u5927\u578b\u8a9e\u8a00\u6a21\u578b\u3002Meltemi 7B \u6709 70 \u5104\u500b\u53c3\u6578\uff0c\u4e26\u5728 400 \u5104\u500b\u5e0c\u81d8\u8a9e\u8a9e\u6599\u5eab\u4ee4\u724c\u4e0a\u9032\u884c\u8a13\u7df4\u3002\u5c0d\u65bc Meltemi 7B \u7684\u958b\u767c\uff0c\u6211\u5011\u900f\u904e\u5728\u5e0c\u81d8\u8a9e\u8a9e\u6599\u5eab\u4e0a\u6301\u7e8c\u9810\u8a13\u7df4\u4f86\u6539\u7de8 Mistral\u3002Meltemi 7B \u5305\u542b\u622a\u81f3 2023 \u5e74 9 \u6708\u7684\u6700\u65b0\u8cc7\u8a0a\u3002\u6b64\u5916\uff0c\u6211\u5011\u7ffb\u8b6f\u4e26\u7b56\u5283\u4e86\u4e00\u500b\u5e0c\u81d8\u8a9e\u6307\u4ee4\u8a9e\u6599\u5eab\uff0c\u5df2\u7528\u65bc\u540d\u70ba Meltemi 7B Instruct \u7684\u804a\u5929\u6a21\u578b\u7684\u6307\u4ee4\u5fae\u8abf\u3002\u5df2\u7279\u5225\u6ce8\u610f Meltemi 7B Instruct \u7684\u5c0d\u9f4a\u548c\u79fb\u9664\u6709\u6bd2\u5167\u5bb9\u3002\u5df2\u5728\u5ee3\u6cdb\u6536\u96c6\u7684\u8a55\u91cf\u8a9e\u6599\u5eab\u4e0a\u8a55\u4f30\u5df2\u958b\u767c\u7684\u6a21\u578b\uff0c\u4e26\u63d0\u4f9b\u63d0\u793a\u548c\u56de\u61c9\u7bc4\u4f8b\u3002Meltemi 7B \u548c Meltemi 7B Instruct \u90fd\u53ef\u4ee5\u5728 https://huggingface.co/ilsp \u4e0b\u6839\u64da Apache 2.0 \u6388\u6b0a\u53d6\u5f97\u3002", "author": "Leon Voukoutis et.al.", "authors": "Leon Voukoutis, Dimitris Roussis, Georgios Paraskevopoulos, Sokratis Sofianopoulos, Prokopis Prokopidis, Vassilis Papavasileiou, Athanasios Katsamanis, Stelios Piperidis, Vassilis Katsouros", "id": "2407.20743v1", "paper_url": "http://arxiv.org/abs/2407.20743v1", "repo": "null"}}