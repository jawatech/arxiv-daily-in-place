{"2502.13034": {"publish_time": "2025-02-18", "title": "Natural Language Generation from Visual Sequences: Challenges and Future Directions", "paper_summary": "The ability to use natural language to talk about visual content is at the\ncore of human intelligence and a crucial feature of any artificial intelligence\nsystem. Various studies have focused on generating text for single images. In\ncontrast, comparatively little attention has been paid to exhaustively\nanalyzing and advancing work on multiple-image vision-to-text settings. In this\nposition paper, we claim that any task dealing with temporally ordered\nsequences of multiple images or frames is an instance of a broader, more\ngeneral problem involving the understanding of intricate relationships between\nthe visual content and the corresponding text. We comprehensively analyze five\ntasks that are instances of this problem and argue that they pose a common set\nof challenges and share similarities in terms of modeling and evaluation\napproaches. Based on the insights from these various aspects and stages of\nmulti-image-to-text generation, we highlight several open questions and suggest\nfuture research directions. We believe that these directions can advance the\nunderstanding of complex phenomena in this domain and the development of better\nmodels.", "paper_summary_zh": "\u4f7f\u7528\u81ea\u7136\u8a9e\u8a00\u4f86\u8ac7\u8ad6\u8996\u89ba\u5167\u5bb9\u7684\u80fd\u529b\u662f\u4eba\u985e\u667a\u6167\u7684\u6838\u5fc3\uff0c\u4e5f\u662f\u4efb\u4f55\u4eba\u5de5\u667a\u6167\u7cfb\u7d71\u7684\u4e00\u9805\u95dc\u9375\u529f\u80fd\u3002\u5404\u7a2e\u7814\u7a76\u90fd\u5c08\u6ce8\u65bc\u70ba\u55ae\u4e00\u5f71\u50cf\u7522\u751f\u6587\u5b57\u3002\u76f8\u8f03\u4e4b\u4e0b\uff0c\u5c0d\u65bc\u8a73\u76e1\u5206\u6790\u548c\u63a8\u9032\u591a\u91cd\u5f71\u50cf\u8996\u89ba\u8f49\u6587\u5b57\u8a2d\u5b9a\u7684\u5de5\u4f5c\uff0c\u95dc\u6ce8\u8f03\u5c11\u3002\u5728\u6b64\u7acb\u5834\u6587\u4ef6\u4e2d\uff0c\u6211\u5011\u8072\u7a31\u4efb\u4f55\u8655\u7406\u591a\u91cd\u5f71\u50cf\u6216\u756b\u683c\u7684\u6642\u9593\u9806\u5e8f\u5e8f\u5217\u7684\u4efb\u52d9\uff0c\u90fd\u662f\u4e00\u500b\u66f4\u5ee3\u6cdb\u3001\u66f4\u666e\u904d\u554f\u984c\u7684\u7bc4\u4f8b\uff0c\u6d89\u53ca\u7406\u89e3\u8996\u89ba\u5167\u5bb9\u548c\u5c0d\u61c9\u6587\u5b57\u4e4b\u9593\u7684\u8907\u96dc\u95dc\u4fc2\u3002\u6211\u5011\u5168\u9762\u5206\u6790\u4e86\u6b64\u554f\u984c\u7684\u4e94\u500b\u7bc4\u4f8b\u4efb\u52d9\uff0c\u4e26\u8ad6\u8b49\u5b83\u5011\u63d0\u51fa\u4e86\u4e00\u7d44\u5e38\u898b\u7684\u6311\u6230\uff0c\u4e14\u5728\u5efa\u6a21\u548c\u8a55\u4f30\u65b9\u6cd5\u65b9\u9762\u6709\u76f8\u4f3c\u4e4b\u8655\u3002\u6839\u64da\u591a\u91cd\u5f71\u50cf\u8f49\u6587\u5b57\u751f\u6210\u7684\u9019\u4e9b\u4e0d\u540c\u9762\u5411\u548c\u968e\u6bb5\u7684\u898b\u89e3\uff0c\u6211\u5011\u7a81\u51fa\u4e86\u5e7e\u500b\u958b\u653e\u6027\u554f\u984c\uff0c\u4e26\u5efa\u8b70\u672a\u4f86\u7684\u7814\u7a76\u65b9\u5411\u3002\u6211\u5011\u76f8\u4fe1\u9019\u4e9b\u65b9\u5411\u53ef\u4ee5\u63a8\u9032\u5c0d\u6b64\u9818\u57df\u4e2d\u8907\u96dc\u73fe\u8c61\u7684\u7406\u89e3\uff0c\u4ee5\u53ca\u958b\u767c\u51fa\u66f4\u597d\u7684\u6a21\u578b\u3002", "author": "Aditya K Surikuchi et.al.", "authors": "Aditya K Surikuchi, Raquel Fern\u00e1ndez, Sandro Pezzelle", "id": "2502.13034v1", "paper_url": "http://arxiv.org/abs/2502.13034v1", "repo": "null"}}