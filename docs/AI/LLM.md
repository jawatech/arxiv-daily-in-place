
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-12-04**|**Navigation World Models**|Amir Bar et.al.|[2412.03572v1](http://arxiv.org/abs/2412.03572v1)|null|
|**2024-12-04**|**The Matrix: Infinite-Horizon World Generation with Real-Time Moving Control**|Ruili Feng et.al.|[2412.03568v1](http://arxiv.org/abs/2412.03568v1)|null|
|**2024-12-04**|**From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents**|Xinyi Mou et.al.|[2412.03563v1](http://arxiv.org/abs/2412.03563v1)|null|
|**2024-12-04**|**FLAIR: VLM with Fine-grained Language-informed Image Representations**|Rui Xiao et.al.|[2412.03561v1](http://arxiv.org/abs/2412.03561v1)|[link](https://github.com/explainableml/flair)|
|**2024-12-04**|**Best-of-N Jailbreaking**|John Hughes et.al.|[2412.03556v1](http://arxiv.org/abs/2412.03556v1)|null|
|**2024-12-04**|**Perception Tokens Enhance Visual Reasoning in Multimodal Language Models**|Mahtab Bigverdi et.al.|[2412.03548v1](http://arxiv.org/abs/2412.03548v1)|null|
|**2024-12-04**|**NODE-AdvGAN: Improving the transferability and perceptual similarity of adversarial examples by dynamic-system-driven adversarial generative model**|Xinheng Xie et.al.|[2412.03539v1](http://arxiv.org/abs/2412.03539v1)|null|
|**2024-12-04**|**Evaluating Gender Bias Transfer between Pre-trained and Prompt-Adapted Language Models**|Natalie Mackraz et.al.|[2412.03537v1](http://arxiv.org/abs/2412.03537v1)|null|
|**2024-12-04**|**A Review on Scientific Knowledge Extraction using Large Language Models in Biomedical Sciences**|Gabriel Lino Garcia et.al.|[2412.03531v1](http://arxiv.org/abs/2412.03531v1)|null|
|**2024-12-04**|**FANAL -- Financial Activity News Alerting Language Modeling Framework**|Urjitkumar Patel et.al.|[2412.03527v1](http://arxiv.org/abs/2412.03527v1)|null|
|**2024-12-04**|**Feed-Forward Bullet-Time Reconstruction of Dynamic Scenes from Monocular Videos**|Hanxue Liang et.al.|[2412.03526v1](http://arxiv.org/abs/2412.03526v1)|null|
|**2024-12-04**|**You're (Not) My Type -- Can LLMs Generate Feedback of Specific Types for Introductory Programming Tasks?**|Dominic Lohr et.al.|[2412.03516v1](http://arxiv.org/abs/2412.03516v1)|null|
|**2024-12-04**|**KKLIP: Knowledge Distillation Exploiting K-means Clustering for Language-Image Pre-Training**|Kuei-Chun Kao et.al.|[2412.03513v1](http://arxiv.org/abs/2412.03513v1)|null|
|**2024-12-04**|**A Bidirectional Siamese Recurrent Neural Network for Accurate Gait Recognition Using Body Landmarks**|Proma Hossain Progga et.al.|[2412.03498v1](http://arxiv.org/abs/2412.03498v1)|null|
|**2024-12-04**|**Flow Matching with General Discrete Paths: A Kinetic-Optimal Perspective**|Neta Shaul et.al.|[2412.03487v1](http://arxiv.org/abs/2412.03487v1)|null|
|**2024-12-04**|**Training-Free Mitigation of Language Reasoning Degradation After Multimodal Instruction Tuning**|Neale Ratzlaff et.al.|[2412.03467v1](http://arxiv.org/abs/2412.03467v1)|null|
|**2024-12-04**|**From Words to Workflows: Automating Business Processes**|Laura Minkova et.al.|[2412.03446v1](http://arxiv.org/abs/2412.03446v1)|null|
|**2024-12-04**|**PBP: Post-training Backdoor Purification for Malware Classifiers**|Dung Thuy Nguyen et.al.|[2412.03441v1](http://arxiv.org/abs/2412.03441v1)|[link](https://github.com/judydnguyen/pbp-backdoor-purification-official)|
|**2024-12-04**|**BIMCaP: BIM-based AI-supported LiDAR-Camera Pose Refinement**|Miguel Arturo Vega Torres et.al.|[2412.03434v1](http://arxiv.org/abs/2412.03434v1)|[link](https://github.com/migvega/bimcap)|
|**2024-12-04**|**Automated Test-Case Generation for REST APIs Using Model Inference Search Heuristic**|Clinton Cao et.al.|[2412.03420v1](http://arxiv.org/abs/2412.03420v1)|null|
|**2024-12-04**|**Benchmarking Pretrained Attention-based Models for Real-Time Recognition in Robot-Assisted Esophagectomy**|Ronald L. P. D. de Jong et.al.|[2412.03401v1](http://arxiv.org/abs/2412.03401v1)|null|
|**2024-12-04**|**RedStone: Curating General, Code, Math, and QA Data for Large Language Models**|Yaoyao Chang et.al.|[2412.03398v1](http://arxiv.org/abs/2412.03398v1)|null|
|**2024-12-04**|**Enhancing Supply Chain Visibility with Generative AI: An Exploratory Case Study on Relationship Prediction in Knowledge Graphs**|Ge Zheng et.al.|[2412.03390v1](http://arxiv.org/abs/2412.03390v1)|null|
|**2024-12-04**|**DiffStyleTTS: Diffusion-based Hierarchical Prosody Modeling for Text-to-Speech with Diverse and Controllable Styles**|Jiaxuan Liu et.al.|[2412.03388v1](http://arxiv.org/abs/2412.03388v1)|null|
|**2024-12-04**|**WiS Platform: Enhancing Evaluation of LLM-Based Multi-Agent Systems Through Game-Based Analysis**|Chengwei Hu et.al.|[2412.03359v1](http://arxiv.org/abs/2412.03359v1)|null|
|**2024-12-04**|**Intuitive Axial Augmentation Using Polar-Sine-Based Piecewise Distortion for Medical Slice-Wise Segmentation**|Yiqin Zhang et.al.|[2412.03352v1](http://arxiv.org/abs/2412.03352v1)|[link](https://github.com/mgamz/psbpd)|
|**2024-12-04**|**DIVE: Taming DINO for Subject-Driven Video Editing**|Yi Huang et.al.|[2412.03347v1](http://arxiv.org/abs/2412.03347v1)|null|
|**2024-12-04**|**Improving Linguistic Diversity of Large Language Models with Possibility Exploration Fine-Tuning**|Long Mai et.al.|[2412.03343v1](http://arxiv.org/abs/2412.03343v1)|[link](https://github.com/mailong25/peft_diversity)|
|**2024-12-04**|**AI-Driven Day-to-Day Route Choice**|Leizhen Wang et.al.|[2412.03338v1](http://arxiv.org/abs/2412.03338v1)|null|
|**2024-12-04**|**Yankari: A Monolingual Yoruba Dataset**|Maro Akpobi et.al.|[2412.03334v1](http://arxiv.org/abs/2412.03334v1)|null|
|**2024-12-04**|**LuxEmbedder: A Cross-Lingual Approach to Enhanced Luxembourgish Sentence Embeddings**|Fred Philippy et.al.|[2412.03331v1](http://arxiv.org/abs/2412.03331v1)|null|
|**2024-12-04**|**Grounded Language Design for Lightweight Diagramming for Formal Methods**|Siddhartha Prasad et.al.|[2412.03310v1](http://arxiv.org/abs/2412.03310v1)|null|
|**2024-12-04**|**Contextual Data Integration for Bike-sharing Demand Prediction with Graph Neural Networks in Degraded Weather Conditions**|Romain Rochas et.al.|[2412.03307v1](http://arxiv.org/abs/2412.03307v1)|null|
|**2024-12-04**|**Global MMLU: Understanding and Addressing Cultural and Linguistic Biases in Multilingual Evaluation**|Shivalika Singh et.al.|[2412.03304v1](http://arxiv.org/abs/2412.03304v1)|null|
|**2024-12-04**|**Integrating Generative AI into Art Therapy: A Technical Showcase**|Yannis Valentin Schmutz et.al.|[2412.03287v1](http://arxiv.org/abs/2412.03287v1)|[link](https://github.com/bfh-ami/sds24)|
|**2024-12-04**|**Black-Box Forgery Attacks on Semantic Watermarks for Diffusion Models**|Andreas Müller et.al.|[2412.03283v1](http://arxiv.org/abs/2412.03283v1)|null|
|**2024-12-04**|**AntLM: Bridging Causal and Masked Language Models**|Xinru Yu et.al.|[2412.03275v1](http://arxiv.org/abs/2412.03275v1)|null|
|**2024-12-04**|**Intent-driven In-context Learning for Few-shot Dialogue State Tracking**|Zihao Yi et.al.|[2412.03270v1](http://arxiv.org/abs/2412.03270v1)|null|
|**2024-12-04**|**Alignment at Pre-training! Towards Native Alignment for Arabic LLMs**|Juhao Liang et.al.|[2412.03253v1](http://arxiv.org/abs/2412.03253v1)|[link](https://github.com/freedomintelligence/acegpt-v2)|
|**2024-12-04**|**AIM: Adaptive Inference of Multi-Modal LLMs via Token Merging and Pruning**|Yiwu Zhong et.al.|[2412.03248v1](http://arxiv.org/abs/2412.03248v1)|[link](https://github.com/lavi-lab/aim)|
|**2024-12-04**|**Benchmarking terminology building capabilities of ChatGPT on an English-Russian Fashion Corpus**|Anastasiia Bezobrazova et.al.|[2412.03242v1](http://arxiv.org/abs/2412.03242v1)|null|
|**2024-12-04**|**Does Safety Training of LLMs Generalize to Semantically Related Natural Prompts?**|Sravanti Addepalli et.al.|[2412.03235v1](http://arxiv.org/abs/2412.03235v1)|null|
|**2024-12-04**|**PERL: Pinyin Enhanced Rephrasing Language Model for Chinese ASR N-best Error Correction**|Junhong Liang et.al.|[2412.03230v1](http://arxiv.org/abs/2412.03230v1)|null|
|**2024-12-04**|**Linq-Embed-Mistral Technical Report**|Chanyeol Choi et.al.|[2412.03223v1](http://arxiv.org/abs/2412.03223v1)|null|
|**2024-12-04**|**ClusterKV: Manipulating LLM KV Cache in Semantic Space for Recallable Compression**|Guangda Liu et.al.|[2412.03213v1](http://arxiv.org/abs/2412.03213v1)|null|
|**2024-12-04**|**U-MATH: A University-Level Benchmark for Evaluating Mathematical Skills in LLMs**|Konstantin Chernyshev et.al.|[2412.03205v1](http://arxiv.org/abs/2412.03205v1)|null|
|**2024-12-04**|**Semi-decentralized Training of Spatio-Temporal Graph Neural Networks for Traffic Prediction**|Ivan Kralj et.al.|[2412.03188v1](http://arxiv.org/abs/2412.03188v1)|null|
|**2024-12-04**|**Weighted-Reward Preference Optimization for Implicit Model Fusion**|Ziyi Yang et.al.|[2412.03187v1](http://arxiv.org/abs/2412.03187v1)|[link](https://github.com/SLIT-AI/WRPO)|
|**2024-12-04**|**Optimizing Dense Visual Predictions Through Multi-Task Coherence and Prioritization**|Maxime Fontana et.al.|[2412.03179v1](http://arxiv.org/abs/2412.03179v1)|null|
|**2024-12-04**|**Towards Understanding and Quantifying Uncertainty for Text-to-Image Generation**|Gianni Franchi et.al.|[2412.03178v1](http://arxiv.org/abs/2412.03178v1)|null|
|**2024-12-04**|**Automatic detection of diseases in Spanish clinical notes combining medical language models and ontologies**|Leon-Paul Schaub Torre et.al.|[2412.03176v1](http://arxiv.org/abs/2412.03176v1)|null|
|**2024-12-04**|**Physics-Informed Deep Inverse Operator Networks for Solving PDE Inverse Problems**|Sung Woong Cho et.al.|[2412.03161v1](http://arxiv.org/abs/2412.03161v1)|null|
|**2024-12-04**|**Byte BPE Tokenization as an Inverse string Homomorphism**|Saibo Geng et.al.|[2412.03160v1](http://arxiv.org/abs/2412.03160v1)|null|
|**2024-12-04**|**Testing Neural Network Verifiers: A Soundness Benchmark with Hidden Counterexamples**|Xingjian Zhou et.al.|[2412.03154v1](http://arxiv.org/abs/2412.03154v1)|[link](https://github.com/mvp-harry/soundnessbench)|
|**2024-12-04**|**Large Language Models show both individual and collective creativity comparable to humans**|Luning Sun et.al.|[2412.03151v1](http://arxiv.org/abs/2412.03151v1)|null|
|**2024-12-04**|**Fine-Grained Behavior Simulation with Role-Playing Large Language Model on Social Media**|Kun Li et.al.|[2412.03148v1](http://arxiv.org/abs/2412.03148v1)|[link](https://github.com/linkseed18612254945/finerob)|
|**2024-12-04**|**Robust Multi-bit Text Watermark with LLM-based Paraphrasers**|Xiaojun Xu et.al.|[2412.03123v1](http://arxiv.org/abs/2412.03123v1)|[link](https://github.com/xiaojunxu/multi-bit-text-watermark)|
|**2024-12-04**|**Experience-driven discovery of planning strategies**|Ruiqi He et.al.|[2412.03111v1](http://arxiv.org/abs/2412.03111v1)|null|
|**2024-12-04**|**CredID: Credible Multi-Bit Watermark for Large Language Models Identification**|Haoyu Jiang et.al.|[2412.03107v1](http://arxiv.org/abs/2412.03107v1)|null|
|**2024-12-04**|**ChatTS: Aligning Time Series with LLMs via Synthetic Data for Enhanced Understanding and Reasoning**|Zhe Xie et.al.|[2412.03104v1](http://arxiv.org/abs/2412.03104v1)|null|
|**2024-12-04**|**A surprisal oracle for when every layer counts**|Xudong Hong et.al.|[2412.03098v1](http://arxiv.org/abs/2412.03098v1)|[link](https://github.com/asayeed/activebaby)|
|**2024-12-04**|**TOOL-ED: Enhancing Empathetic Response Generation with the Tool Calling Capability of LLM**|Huiying Cao et.al.|[2412.03096v1](http://arxiv.org/abs/2412.03096v1)|null|
|**2024-12-04**|**Revolve: Optimizing AI Systems by Tracking Response Evolution in Textual Optimization**|Peiyan Zhang et.al.|[2412.03092v1](http://arxiv.org/abs/2412.03092v1)|[link](https://github.com/peiyance/revolve)|
|**2024-12-04**|**ASR-EC Benchmark: Evaluating Large Language Models on Chinese ASR Error Correction**|Victor Junqiu Wei et.al.|[2412.03075v1](http://arxiv.org/abs/2412.03075v1)|null|
|**2024-12-04**|**Analytic Study of Text-Free Speech Synthesis for Raw Audio using a Self-Supervised Learning Model**|Joonyong Park et.al.|[2412.03074v1](http://arxiv.org/abs/2412.03074v1)|null|
|**2024-12-04**|**Preference-based opponent shaping in differentiable games**|Xinyu Qiao et.al.|[2412.03072v1](http://arxiv.org/abs/2412.03072v1)|null|
|**2024-12-04**|**UTSD: Unified Time Series Diffusion Model**|Xiangkai Ma et.al.|[2412.03068v1](http://arxiv.org/abs/2412.03068v1)|null|
|**2024-12-04**|**Point-GN: A Non-Parametric Network Using Gaussian Positional Encoding for Point Cloud Classification**|Marzieh Mohammadi et.al.|[2412.03056v1](http://arxiv.org/abs/2412.03056v1)|null|
|**2024-12-04**|**Less is More: A Stealthy and Efficient Adversarial Attack Method for DRL-based Autonomous Driving Policies**|Junchao Fan et.al.|[2412.03051v1](http://arxiv.org/abs/2412.03051v1)|null|
|**2024-12-04**|**MRNet: Multifaceted Resilient Networks for Medical Image-to-Image Translation**|Hyojeong Lee et.al.|[2412.03039v1](http://arxiv.org/abs/2412.03039v1)|null|
|**2024-12-04**|**MILLION: A General Multi-Objective Framework with Controllable Risk for Portfolio Management**|Liwei Deng et.al.|[2412.03038v1](http://arxiv.org/abs/2412.03038v1)|null|
|**2024-12-04**|**Specification Generation for Neural Networks in Systems**|Isha Chaudhary et.al.|[2412.03028v1](http://arxiv.org/abs/2412.03028v1)|null|
|**2024-12-04**|**Human Variability vs. Machine Consistency: A Linguistic Analysis of Texts Generated by Humans and Large Language Models**|Sergio E. Zanotto et.al.|[2412.03025v1](http://arxiv.org/abs/2412.03025v1)|null|
|**2024-12-04**|**PEMF-VVTO: Point-Enhanced Video Virtual Try-on via Mask-free Paradigm**|Tianyu Chang et.al.|[2412.03021v1](http://arxiv.org/abs/2412.03021v1)|null|
|**2024-12-04**|**Human Multi-View Synthesis from a Single-View Model:Transferred Body and Face Representations**|Yu Feng et.al.|[2412.03011v1](http://arxiv.org/abs/2412.03011v1)|null|
|**2024-12-04**|**Advancing Conversational Psychotherapy: Integrating Privacy, Dual-Memory, and Domain Expertise with Large Language Models**|XiuYu Zhang et.al.|[2412.02987v1](http://arxiv.org/abs/2412.02987v1)|null|
|**2024-12-04**|**Surveying the Effects of Quality, Diversity, and Complexity in Synthetic Data From Large Language Models**|Alex Havrilla et.al.|[2412.02980v1](http://arxiv.org/abs/2412.02980v1)|null|
|**2024-12-04**|**Theoretical limitations of multi-layer Transformer**|Lijie Chen et.al.|[2412.02975v1](http://arxiv.org/abs/2412.02975v1)|null|
|**2024-12-04**|**3D Interaction Geometric Pre-training for Molecular Relational Learning**|Namkyeong Lee et.al.|[2412.02957v1](http://arxiv.org/abs/2412.02957v1)|null|
|**2024-12-04**|**Curriculum-style Data Augmentation for LLM-based Metaphor Detection**|Kaidi Jia et.al.|[2412.02956v1](http://arxiv.org/abs/2412.02956v1)|null|
|**2024-12-04**|**Who Brings the Frisbee: Probing Hidden Hallucination Factors in Large Vision-Language Model via Causality Analysis**|Po-Hsuan Huang et.al.|[2412.02946v1](http://arxiv.org/abs/2412.02946v1)|null|
|**2024-12-04**|**STDCformer: A Transformer-Based Model with a Spatial-Temporal Causal De-Confounding Strategy for Crowd Flow Prediction**|Silu He et.al.|[2412.02942v1](http://arxiv.org/abs/2412.02942v1)|null|
|**2024-12-04**|**Dynamic Graph Neural Ordinary Differential Equation Network for Multi-modal Emotion Recognition in Conversation**|Yuntao Shou et.al.|[2412.02935v1](http://arxiv.org/abs/2412.02935v1)|null|
|**2024-12-04**|**Panoptic Diffusion Models: co-generation of images and segmentation maps**|Yinghan Long et.al.|[2412.02929v1](http://arxiv.org/abs/2412.02929v1)|null|
|**2024-12-04**|**Higher Order Transformers: Efficient Attention Mechanism for Tensor Structured Data**|Soroush Omranpour et.al.|[2412.02919v1](http://arxiv.org/abs/2412.02919v1)|null|
|**2024-12-03**|**Single-Cell Omics Arena: A Benchmark Study for Large Language Models on Cell Type Annotation Using Single-Cell Data**|Junhao Liu et.al.|[2412.02915v1](http://arxiv.org/abs/2412.02915v1)|null|
|**2024-12-03**|**Does Few-Shot Learning Help LLM Performance in Code Synthesis?**|Derek Xu et.al.|[2412.02906v1](http://arxiv.org/abs/2412.02906v1)|null|
|**2024-12-03**|**Enhancing Trust in Large Language Models with Uncertainty-Aware Fine-Tuning**|Ranganath Krishnan et.al.|[2412.02904v1](http://arxiv.org/abs/2412.02904v1)|null|
|**2024-12-03**|**MLD-EA: Check and Complete Narrative Coherence by Introducing Emotions and Actions**|Jinming Zhang et.al.|[2412.02897v1](http://arxiv.org/abs/2412.02897v1)|null|
|**2024-12-03**|**Removing Spurious Correlation from Neural Network Interpretations**|Milad Fotouhi et.al.|[2412.02893v1](http://arxiv.org/abs/2412.02893v1)|null|
|**2024-12-03**|**TDD-Bench Verified: Can LLMs Generate Tests for Issues Before They Get Resolved?**|Toufique Ahmed et.al.|[2412.02883v1](http://arxiv.org/abs/2412.02883v1)|null|
|**2024-12-03**|**Modeling and Discovering Direct Causes for Predictive Models**|Yizuo Chen et.al.|[2412.02878v1](http://arxiv.org/abs/2412.02878v1)|null|
|**2024-12-03**|**Constrained Identifiability of Causal Effects**|Yizuo Chen et.al.|[2412.02869v1](http://arxiv.org/abs/2412.02869v1)|null|
|**2024-12-03**|**A Novel Compact LLM Framework for Local, High-Privacy EHR Data Applications**|Yixiang Qu et.al.|[2412.02868v1](http://arxiv.org/abs/2412.02868v1)|null|
|**2024-12-03**|**Unpaired Modality Translation for Pseudo Labeling of Histology Images**|Arthur Boschet et.al.|[2412.02858v1](http://arxiv.org/abs/2412.02858v1)|null|
|**2024-12-03**|**FLAME 3 Dataset: Unleashing the Power of Radiometric Thermal UAV Imagery for Wildfire Management**|Bryce Hopkins et.al.|[2412.02831v1](http://arxiv.org/abs/2412.02831v1)|null|
|**2024-12-03**|**RARE: Retrieval-Augmented Reasoning Enhancement for Large Language Models**|Hieu Tran et.al.|[2412.02830v1](http://arxiv.org/abs/2412.02830v1)|null|
|**2024-12-03**|**Minimization of Boolean Complexity in In-Context Concept Learning**|Leroy Z. Wang et.al.|[2412.02823v1](http://arxiv.org/abs/2412.02823v1)|null|
|**2024-12-03**|**CNNSum: Exploring Long-Conext Summarization with Large Language Models in Chinese Novels**|Lingxiao Wei et.al.|[2412.02819v1](http://arxiv.org/abs/2412.02819v1)|null|
|**2024-12-03**|**Gaussian Splatting Under Attack: Investigating Adversarial Noise in 3D Objects**|Abdurrahman Zeybey et.al.|[2412.02803v1](http://arxiv.org/abs/2412.02803v1)|null|

#### Abstracts
##### **Navigation World Models**
2412.03572v1 by Amir Bar, Gaoyue Zhou, Danny Tran, Trevor Darrell, Yann LeCun

Navigation is a fundamental skill of agents with visual-motor capabilities.
We introduce a Navigation World Model (NWM), a controllable video generation
model that predicts future visual observations based on past observations and
navigation actions. To capture complex environment dynamics, NWM employs a
Conditional Diffusion Transformer (CDiT), trained on a diverse collection of
egocentric videos of both human and robotic agents, and scaled up to 1 billion
parameters. In familiar environments, NWM can plan navigation trajectories by
simulating them and evaluating whether they achieve the desired goal. Unlike
supervised navigation policies with fixed behavior, NWM can dynamically
incorporate constraints during planning. Experiments demonstrate its
effectiveness in planning trajectories from scratch or by ranking trajectories
sampled from an external policy. Furthermore, NWM leverages its learned visual
priors to imagine trajectories in unfamiliar environments from a single input
image, making it a flexible and powerful tool for next-generation navigation
systems.

摘要：導航是具備視覺運動能力的代理人的一項基本技能。
我們引入導航世界模型 (NWM)，這是一個可控制的影片生成模型，它基於過去的觀察和導航動作來預測未來的視覺觀察。為了捕捉複雜的環境動態，NWM 採用條件擴散轉換器 (CDiT)，它在人類和機器人代理人的各種以自我為中心影片的集合上進行訓練，並擴展到 10 億個參數。在熟悉的環境中，NWM 可以透過模擬導航軌跡並評估它們是否達成所需目標，來規劃導航軌跡。與具有固定行為的監督式導航策略不同，NWM 可以動態地將限制納入規劃中。實驗證明了它在從頭開始規劃軌跡或從外部策略中取樣軌跡並對其進行排名方面的有效性。此外，NWM 利用其學習的視覺先驗，從單一輸入影像想像在不熟悉環境中的軌跡，這使其成為下一代導航系統的靈活且強大的工具。

##### **The Matrix: Infinite-Horizon World Generation with Real-Time Moving Control**
2412.03568v1 by Ruili Feng, Han Zhang, Zhantao Yang, Jie Xiao, Zhilei Shu, Zhiheng Liu, Andy Zheng, Yukun Huang, Yu Liu, Hongyang Zhang

We present The Matrix, the first foundational realistic world simulator
capable of generating continuous 720p high-fidelity real-scene video streams
with real-time, responsive control in both first- and third-person
perspectives, enabling immersive exploration of richly dynamic environments.
Trained on limited supervised data from AAA games like Forza Horizon 5 and
Cyberpunk 2077, complemented by large-scale unsupervised footage from
real-world settings like Tokyo streets, The Matrix allows users to traverse
diverse terrains -- deserts, grasslands, water bodies, and urban landscapes --
in continuous, uncut hour-long sequences. Operating at 16 FPS, the system
supports real-time interactivity and demonstrates zero-shot generalization,
translating virtual game environments to real-world contexts where collecting
continuous movement data is often infeasible. For example, The Matrix can
simulate a BMW X3 driving through an office setting--an environment present in
neither gaming data nor real-world sources. This approach showcases the
potential of AAA game data to advance robust world models, bridging the gap
between simulations and real-world applications in scenarios with limited data.

摘要：我們展示了 The Matrix，這是第一個基礎性的逼真世界模擬器
能夠產生連續的 720p 高保真實場景影片串流
在第一人稱和第三人稱
視角中進行即時、靈敏的控制，讓身歷其境的探索豐富動態的環境。
使用來自 AAA 遊戲（例如 Forza Horizon 5 和
Cyberpunk 2077）的有限監督數據進行訓練，並輔以來自
東京街頭等真實世界場景的大規模無監督片段，The Matrix 允許使用者穿越
各種地形——沙漠、草原、水體和城市景觀——
在連續、未剪輯的一小時序列中。系統以 16 FPS 運作
支援即時互動，並展示零次學習泛化，
將虛擬遊戲環境轉換為真實世界的環境，在其中收集
連續的移動數據通常不可行。例如，The Matrix 可以
模擬 BMW X3 在辦公室環境中行駛——一個既不在遊戲數據中也不在真實世界來源中的環境。這種方法展示了
AAA 遊戲數據在推進強健世界模型方面的潛力，縮小了
模擬和真實世界應用之間的差距，在資料有限的情況下。

##### **From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents**
2412.03563v1 by Xinyi Mou, Xuanwen Ding, Qi He, Liang Wang, Jingcong Liang, Xinnong Zhang, Libo Sun, Jiayu Lin, Jie Zhou, Xuanjing Huang, Zhongyu Wei

Traditional sociological research often relies on human participation, which,
though effective, is expensive, challenging to scale, and with ethical
concerns. Recent advancements in large language models (LLMs) highlight their
potential to simulate human behavior, enabling the replication of individual
responses and facilitating studies on many interdisciplinary studies. In this
paper, we conduct a comprehensive survey of this field, illustrating the recent
progress in simulation driven by LLM-empowered agents. We categorize the
simulations into three types: (1) Individual Simulation, which mimics specific
individuals or demographic groups; (2) Scenario Simulation, where multiple
agents collaborate to achieve goals within specific contexts; and (3) Society
Simulation, which models interactions within agent societies to reflect the
complexity and variety of real-world dynamics. These simulations follow a
progression, ranging from detailed individual modeling to large-scale societal
phenomena. We provide a detailed discussion of each simulation type, including
the architecture or key components of the simulation, the classification of
objectives or scenarios and the evaluation method. Afterward, we summarize
commonly used datasets and benchmarks. Finally, we discuss the trends across
these three types of simulation. A repository for the related sources is at
{\url{https://github.com/FudanDISC/SocialAgent}}.

摘要：傳統的社會學研究通常依賴於人類參與，儘管有效，但代價高昂、難以擴展，且有道德上的疑慮。大型語言模型 (LLM) 的最新進展突顯了它們模擬人類行為的潛力，能夠複製個別反應並促進許多跨領域研究的研究。在本文中，我們對這個領域進行全面調查，說明由 LLM 賦能的代理驅動的模擬的最新進展。我們將模擬分類為三種類型：(1) 個體模擬，模擬特定個人或人口群體；(2) 情境模擬，其中多個代理協作在特定情境中達成目標；(3) 社會模擬，模擬代理社會中的互動，以反映現實世界動態的複雜性和多樣性。這些模擬遵循一個進程，從詳細的個體建模到大型社會現象。我們對每種類型的模擬進行詳細討論，包括模擬的架構或關鍵組成部分、目標或情境的分類以及評估方法。之後，我們總結常用資料集和基準。最後，我們討論這三種類型模擬的趨勢。相關資源的存放庫位於 {\url{https://github.com/FudanDISC/SocialAgent}}。

##### **FLAIR: VLM with Fine-grained Language-informed Image Representations**
2412.03561v1 by Rui Xiao, Sanghwan Kim, Mariana-Iuliana Georgescu, Zeynep Akata, Stephan Alaniz

CLIP has shown impressive results in aligning images and texts at scale.
However, its ability to capture detailed visual features remains limited
because CLIP matches images and texts at a global level. To address this issue,
we propose FLAIR, Fine-grained Language-informed Image Representations, an
approach that utilizes long and detailed image descriptions to learn localized
image embeddings. By sampling diverse sub-captions that describe fine-grained
details about an image, we train our vision-language model to produce not only
global embeddings but also text-specific image representations. Our model
introduces text-conditioned attention pooling on top of local image tokens to
produce fine-grained image representations that excel at retrieving detailed
image content. We achieve state-of-the-art performance on both, existing
multimodal retrieval benchmarks, as well as, our newly introduced fine-grained
retrieval task which evaluates vision-language models' ability to retrieve
partial image content. Furthermore, our experiments demonstrate the
effectiveness of FLAIR trained on 30M image-text pairs in capturing
fine-grained visual information, including zero-shot semantic segmentation,
outperforming models trained on billions of pairs. Code is available at
https://github.com/ExplainableML/flair .

摘要：CLIP 在大規模影像和文字比對上展現令人印象深刻的成果。
然而，它擷取詳細視覺特徵的能力仍然有限，
因為 CLIP 在全球層級上比對影像和文字。為了解決這個問題，
我們提出 FLAIR，一種精細化的語言資訊影像表徵，一種
利用長而詳細的影像描述來學習區域化
影像嵌入的方法。透過取樣描述影像精細化
細節的多樣化子標題，我們訓練我們的視覺語言模型，不僅產生
整體嵌入，也產生特定文字的影像表徵。我們的模型
在區域影像標記上引進文字條件注意池化，以
產生精細化的影像表徵，這些表徵擅長擷取詳細
影像內容。我們在現有的
多模態檢索基準上以及我們新推出的精細化
檢索任務上達成最先進的表現，該任務評估視覺語言模型擷取
部分影像內容的能力。此外，我們的實驗證明，在 30M 影像文字對上訓練的 FLAIR 在擷取
精細化的視覺資訊上很有效，包括零次學習語意分割，
表現優於在數十億對上訓練的模型。程式碼可在
https://github.com/ExplainableML/flair 取得。

##### **Best-of-N Jailbreaking**
2412.03556v1 by John Hughes, Sara Price, Aengus Lynch, Rylan Schaeffer, Fazl Barez, Sanmi Koyejo, Henry Sleight, Erik Jones, Ethan Perez, Mrinank Sharma

We introduce Best-of-N (BoN) Jailbreaking, a simple black-box algorithm that
jailbreaks frontier AI systems across modalities. BoN Jailbreaking works by
repeatedly sampling variations of a prompt with a combination of augmentations
- such as random shuffling or capitalization for textual prompts - until a
harmful response is elicited. We find that BoN Jailbreaking achieves high
attack success rates (ASRs) on closed-source language models, such as 89% on
GPT-4o and 78% on Claude 3.5 Sonnet when sampling 10,000 augmented prompts.
Further, it is similarly effective at circumventing state-of-the-art
open-source defenses like circuit breakers. BoN also seamlessly extends to
other modalities: it jailbreaks vision language models (VLMs) such as GPT-4o
and audio language models (ALMs) like Gemini 1.5 Pro, using modality-specific
augmentations. BoN reliably improves when we sample more augmented prompts.
Across all modalities, ASR, as a function of the number of samples (N),
empirically follows power-law-like behavior for many orders of magnitude. BoN
Jailbreaking can also be composed with other black-box algorithms for even more
effective attacks - combining BoN with an optimized prefix attack achieves up
to a 35% increase in ASR. Overall, our work indicates that, despite their
capability, language models are sensitive to seemingly innocuous changes to
inputs, which attackers can exploit across modalities.

摘要：<paragraph>我們推出 Best-of-N (BoN) 越獄，這是一種簡單的黑盒子演算法，可以越獄跨模態的邊界 AI 系統。BoN 越獄透過重複抽樣提示的變異，並結合增強功能（例如隨機洗牌或對文字提示進行大小寫變換），直到引發有害回應為止。我們發現 BoN 越獄在封閉原始碼語言模型上達到很高的攻擊成功率 (ASR)，例如在抽樣 10,000 個增強提示時，GPT-4o 上為 89%，而 Claude 3.5 Sonnet 上為 78%。此外，它在規避電路中斷器等最先進的開源防禦方面也同樣有效。BoN 也能無縫延伸到其他模態：它透過使用特定於模態的增強功能，越獄了視覺語言模型 (VLM)，例如 GPT-4o，以及音訊語言模型 (ALM)，例如 Gemini 1.5 Pro。當我們抽樣更多增強提示時，BoN 會可靠地提升。在所有模態中，ASR 作為樣本數 (N) 的函數，在許多數量級上都經驗性地遵循冪律行為。BoN 越獄也可以與其他黑盒子演算法結合，以進行更有效的攻擊 - 將 BoN 與最佳化字首攻擊結合，可將 ASR 提升多達 35%。總體而言，我們的研究指出，儘管語言模型具有能力，但它們對輸入的看似無害變更很敏感，而攻擊者可以跨模態利用這一點。</paragraph>

##### **Perception Tokens Enhance Visual Reasoning in Multimodal Language Models**
2412.03548v1 by Mahtab Bigverdi, Zelun Luo, Cheng-Yu Hsieh, Ethan Shen, Dongping Chen, Linda G. Shapiro, Ranjay Krishna

Multimodal language models (MLMs) still face challenges in fundamental visual
perception tasks where specialized models excel. Tasks requiring reasoning
about 3D structures benefit from depth estimation, and reasoning about 2D
object instances benefits from object detection. Yet, MLMs can not produce
intermediate depth or boxes to reason over. Finetuning MLMs on relevant data
doesn't generalize well and outsourcing computation to specialized vision tools
is too compute-intensive and memory-inefficient. To address this, we introduce
Perception Tokens, intrinsic image representations designed to assist reasoning
tasks where language is insufficient. Perception tokens act as auxiliary
reasoning tokens, akin to chain-of-thought prompts in language models. For
example, in a depth-related task, an MLM augmented with perception tokens can
reason by generating a depth map as tokens, enabling it to solve the problem
effectively. We propose AURORA, a training method that augments MLMs with
perception tokens for improved reasoning over visual inputs. AURORA leverages a
VQVAE to transform intermediate image representations, such as depth maps into
a tokenized format and bounding box tokens, which is then used in a multi-task
training framework. AURORA achieves notable improvements across counting
benchmarks: +10.8% on BLINK, +11.3% on CVBench, and +8.3% on SEED-Bench,
outperforming finetuning approaches in generalization across datasets. It also
improves on relative depth: over +6% on BLINK. With perception tokens, AURORA
expands the scope of MLMs beyond language-based reasoning, paving the way for
more effective visual reasoning capabilities.

摘要：多模态语言模型 (MLM) 在专门模型表现优异的基本视觉感知任务中仍然面临挑战。需要对 3D 结构进行推理的任务受益于深度估计，而对 2D 对象实例进行推理受益于对象检测。然而，MLM 无法产生中间深度或框来进行推理。针对相关数据微调 MLM 在泛化能力方面表现不佳，而将计算外包给专门的视觉工具则过于计算密集且内存效率低下。为了解决这个问题，我们引入了感知标记，这是旨在辅助语言不足的推理任务的内在图像表示。感知标记充当辅助推理标记，类似于语言模型中的思想链提示。例如，在与深度相关的任务中，使用感知标记增强后的 MLM 可以通过生成深度图作为标记来进行推理，从而有效地解决问题。我们提出了 AURORA，这是一种训练方法，它使用感知标记增强 MLM，以改进对视觉输入的推理。AURORA 利用 VQVAE 将中间图像表示（例如深度图）转换为标记化格式和边界框标记，然后在多任务训练框架中使用。AURORA 在计数基准测试中取得了显着改进：BLINK 提高了 +10.8%，CVBench 提高了 +11.3%，SEED-Bench 提高了 +8.3%，在数据集中的泛化能力方面优于微调方法。它还改进了相对深度：BLINK 提高了 +6% 以上。有了感知标记，AURORA 将 MLM 的范围扩展到了基于语言的推理之外，为更有效的视觉推理能力铺平了道路。

##### **NODE-AdvGAN: Improving the transferability and perceptual similarity of adversarial examples by dynamic-system-driven adversarial generative model**
2412.03539v1 by Xinheng Xie, Yue Wu, Cuiyu He

Understanding adversarial examples is crucial for improving the model's
robustness, as they introduce imperceptible perturbations that deceive models.
Effective adversarial examples, therefore, offer the potential to train more
robust models by removing their singularities. We propose NODE-AdvGAN, a novel
approach that treats adversarial generation as a continuous process and employs
a Neural Ordinary Differential Equation (NODE) for simulating the dynamics of
the generator. By mimicking the iterative nature of traditional gradient-based
methods, NODE-AdvGAN generates smoother and more precise perturbations that
preserve high perceptual similarity when added to benign images. We also
propose a new training strategy, NODE-AdvGAN-T, which enhances transferability
in black-box attacks by effectively tuning noise parameters during training.
Experiments demonstrate that NODE-AdvGAN and NODE-AdvGAN-T generate more
effective adversarial examples that achieve higher attack success rates while
preserving better perceptual quality than traditional GAN-based methods.

摘要：了解對抗性範例對於提升模型的穩健性至關重要，因為它們引入了難以察覺的擾動，欺騙了模型。因此，有效的對抗性範例提供了透過移除其奇異性來訓練更穩健模型的潛力。我們提出了 NODE-AdvGAN，這是一種新穎的方法，將對抗性生成視為一個連續的過程，並採用神經常微分方程式 (NODE) 來模擬生成器的動態。透過模仿傳統基於梯度的迭代方法，NODE-AdvGAN 產生更平滑且更精確的擾動，在添加到良性影像時，仍能保持高度的感知相似性。我們也提出了新的訓練策略 NODE-AdvGAN-T，它透過在訓練期間有效地調整雜訊參數，增強了黑盒攻擊中的可傳遞性。實驗證明，NODE-AdvGAN 和 NODE-AdvGAN-T 產生的對抗性範例更有效，在保持比傳統基於 GAN 的方法更好的感知品質的同時，達到了更高的攻擊成功率。

##### **Evaluating Gender Bias Transfer between Pre-trained and Prompt-Adapted Language Models**
2412.03537v1 by Natalie Mackraz, Nivedha Sivakumar, Samira Khorshidi, Krishna Patel, Barry-John Theobald, Luca Zappella, Nicholas Apostoloff

Large language models (LLMs) are increasingly being adapted to achieve
task-specificity for deployment in real-world decision systems. Several
previous works have investigated the bias transfer hypothesis (BTH) by studying
the effect of the fine-tuning adaptation strategy on model fairness to find
that fairness in pre-trained masked language models have limited effect on the
fairness of models when adapted using fine-tuning. In this work, we expand the
study of BTH to causal models under prompt adaptations, as prompting is an
accessible, and compute-efficient way to deploy models in real-world systems.
In contrast to previous works, we establish that intrinsic biases in
pre-trained Mistral, Falcon and Llama models are strongly correlated (rho >=
0.94) with biases when the same models are zero- and few-shot prompted, using a
pronoun co-reference resolution task. Further, we find that bias transfer
remains strongly correlated even when LLMs are specifically prompted to exhibit
fair or biased behavior (rho >= 0.92), and few-shot length and stereotypical
composition are varied (rho >= 0.97). Our findings highlight the importance of
ensuring fairness in pre-trained LLMs, especially when they are later used to
perform downstream tasks via prompt adaptation.

摘要：大型语言模型 (LLM) 正越来越多地被调整为实现任务特异性，以便部署在现实世界的决策系统中。一些以前的作品通过研究微调调整策略对模型公平性的影响来调查偏差转移假设 (BTH)，发现预先训练的掩蔽语言模型中的公平性对使用微调调整后的模型公平性影响有限。在这项工作中，我们将 BTH 的研究扩展到提示调整下的因果模型，因为提示是一种可访问且计算高效的方法，可以将模型部署到现实世界系统中。与以前的作品相反，我们确定预先训练的 Mistral、Falcon 和 Llama 模型中的内在偏差与使用代词共指解析任务对相同模型进行零次和少次提示时的偏差密切相关（rho >= 0.94）。此外，我们发现，即使 LLM 被明确提示表现出公平或有偏差的行为（rho >= 0.92），并且少次提示长度和刻板印象成分有所不同（rho >= 0.97），偏差转移仍然密切相关。我们的研究结果突出了确保预先训练的 LLM 公平性的重要性，尤其是在它们后来通过提示调整用于执行下游任务时。

##### **A Review on Scientific Knowledge Extraction using Large Language Models in Biomedical Sciences**
2412.03531v1 by Gabriel Lino Garcia, João Renato Ribeiro Manesco, Pedro Henrique Paiola, Lucas Miranda, Maria Paola de Salvo, João Paulo Papa

The rapid advancement of large language models (LLMs) has opened new
boundaries in the extraction and synthesis of medical knowledge, particularly
within evidence synthesis. This paper reviews the state-of-the-art applications
of LLMs in the biomedical domain, exploring their effectiveness in automating
complex tasks such as evidence synthesis and data extraction from a biomedical
corpus of documents. While LLMs demonstrate remarkable potential, significant
challenges remain, including issues related to hallucinations, contextual
understanding, and the ability to generalize across diverse medical tasks. We
highlight critical gaps in the current research literature, particularly the
need for unified benchmarks to standardize evaluations and ensure reliability
in real-world applications. In addition, we propose directions for future
research, emphasizing the integration of state-of-the-art techniques such as
retrieval-augmented generation (RAG) to enhance LLM performance in evidence
synthesis. By addressing these challenges and utilizing the strengths of LLMs,
we aim to improve access to medical literature and facilitate meaningful
discoveries in healthcare.

摘要：大型語言模型 (LLM) 的快速進展開啟了醫療知識萃取和綜合的新領域，特別是在證據綜合中。本文回顧了 LLM 在生物醫學領域的最新應用，探討了它們在自動化複雜任務（例如從生物醫學文件語料庫中進行證據綜合和數據萃取）方面的效能。儘管 LLM 展現了顯著的潛力，但仍有重大的挑戰，包括與幻覺、脈絡理解以及在不同醫療任務中概括的能力相關的問題。我們強調了當前研究文獻中的關鍵差距，特別是需要統一的基準來標準化評估並確保實際應用中的可靠性。此外，我們提出了未來研究的方向，強調整合最先進的技術，例如檢索增強生成 (RAG)，以增強 LLM 在證據綜合中的表現。透過解決這些挑戰並利用 LLM 的優勢，我們旨在改善對醫學文獻的取得，並促進醫療保健中的有意義發現。

##### **FANAL -- Financial Activity News Alerting Language Modeling Framework**
2412.03527v1 by Urjitkumar Patel, Fang-Chun Yeh, Chinmay Gondhalekar, Hari Nalluri

In the rapidly evolving financial sector, the accurate and timely
interpretation of market news is essential for stakeholders needing to navigate
unpredictable events. This paper introduces FANAL (Financial Activity News
Alerting Language Modeling Framework), a specialized BERT-based framework
engineered for real-time financial event detection and analysis, categorizing
news into twelve distinct financial categories. FANAL leverages silver-labeled
data processed through XGBoost and employs advanced fine-tuning techniques,
alongside ORBERT (Odds Ratio BERT), a novel variant of BERT fine-tuned with
ORPO (Odds Ratio Preference Optimization) for superior class-wise probability
calibration and alignment with financial event relevance. We evaluate FANAL's
performance against leading large language models, including GPT-4o, Llama-3.1
8B, and Phi-3, demonstrating its superior accuracy and cost efficiency. This
framework sets a new standard for financial intelligence and responsiveness,
significantly outstripping existing models in both performance and
affordability.

摘要：在快速變化的金融領域中，準確及時地解讀市場新聞對於需要應對不可預測事件的利益相關者至關重要。本文介紹 FANAL（金融活動新聞警示語言建模框架），這是一個基於 BERT 的專用框架，專門設計用於實時金融事件檢測和分析，將新聞歸類為十二個不同的金融類別。FANAL 利用通過 XGBoost 處理的銀標籤數據，並採用先進的微調技術，以及 ORBERT（機率比 BERT），這是一種新的 BERT 變體，經過 ORPO（機率比偏好最佳化）微調，以實現優越的類別機率校準和與金融事件相關性的對齊。我們評估了 FANAL 與領先的大語言模型的效能，包括 GPT-4o、Llama-3.1 8B 和 Phi-3，證明了其優越的準確性和成本效益。這個框架為金融情報和響應能力設定了新的標準，在效能和負擔能力方面都遠遠超過現有的模型。

##### **Feed-Forward Bullet-Time Reconstruction of Dynamic Scenes from Monocular Videos**
2412.03526v1 by Hanxue Liang, Jiawei Ren, Ashkan Mirzaei, Antonio Torralba, Ziwei Liu, Igor Gilitschenski, Sanja Fidler, Cengiz Oztireli, Huan Ling, Zan Gojcic, Jiahui Huang

Recent advancements in static feed-forward scene reconstruction have
demonstrated significant progress in high-quality novel view synthesis.
However, these models often struggle with generalizability across diverse
environments and fail to effectively handle dynamic content. We present BTimer
(short for BulletTimer), the first motion-aware feed-forward model for
real-time reconstruction and novel view synthesis of dynamic scenes. Our
approach reconstructs the full scene in a 3D Gaussian Splatting representation
at a given target ('bullet') timestamp by aggregating information from all the
context frames. Such a formulation allows BTimer to gain scalability and
generalization by leveraging both static and dynamic scene datasets. Given a
casual monocular dynamic video, BTimer reconstructs a bullet-time scene within
150ms while reaching state-of-the-art performance on both static and dynamic
scene datasets, even compared with optimization-based approaches.

摘要：最近靜態前饋場景重建的進展已證明在高品質的新視圖合成方面取得重大進展。
然而，這些模型通常難以適應各種環境，且無法有效處理動態內容。我們提出 BTimer（BulletTimer 的縮寫），這是第一個具有動態感知的前饋模型，用於動態場景的即時重建和新視圖合成。我們的做法是透過彙整所有內容畫面的資訊，在給定的目標（「子彈」）時間戳記中，以 3D 高斯濺射表示法重建整個場景。這種公式化讓 BTimer 能夠透過利用靜態和動態場景資料集來獲得可擴充性和概括性。給定一個隨意的單眼動態影片，BTimer 能在 150 毫秒內重建一個子彈時間場景，同時在靜態和動態場景資料集上達到最先進的效能，即使與基於最佳化的做法相比也是如此。

##### **You're (Not) My Type -- Can LLMs Generate Feedback of Specific Types for Introductory Programming Tasks?**
2412.03516v1 by Dominic Lohr, Hieke Keuning, Natalie Kiesler

Background: Feedback as one of the most influential factors for learning has
been subject to a great body of research. It plays a key role in the
development of educational technology systems and is traditionally rooted in
deterministic feedback defined by experts and their experience. However, with
the rise of generative AI and especially Large Language Models (LLMs), we
expect feedback as part of learning systems to transform, especially for the
context of programming. In the past, it was challenging to automate feedback
for learners of programming. LLMs may create new possibilities to provide
richer, and more individual feedback than ever before.
  Objectives: This paper aims to generate specific types of feedback for
introductory programming tasks using LLMs. We revisit existing feedback
taxonomies to capture the specifics of the generated feedback, such as
randomness, uncertainty, and degrees of variation.
  Methods: We iteratively designed prompts for the generation of specific
feedback types (as part of existing feedback taxonomies) in response to
authentic student programs. We then evaluated the generated output and
determined to what extent it reflected certain feedback types.
  Results and Conclusion: The present work provides a better understanding of
different feedback dimensions and characteristics. The results have
implications for future feedback research with regard to, for example, feedback
effects and learners' informational needs. It further provides a basis for the
development of new tools and learning systems for novice programmers including
feedback generated by AI.

摘要：**背景：**回饋作為學習中最具影響力的因素之一，
一直是許多研究的主題。它在教育科技系統的發展中扮演著關鍵角色，
並且傳統上根植於由專家及其經驗定義的確定性回饋。然而，
隨著生成式 AI 和特別是大語言模型 (LLM) 的興起，我們預期回饋
作為學習系統的一部分會轉型，特別是在程式設計的背景下。在過去，
自動化程式設計學習者的回饋是一項挑戰。LLM 可能創造新的可能性，
提供比以往更豐富、更個人化的回饋。

**目標：**本文旨在使用 LLM 為入門程式設計任務產生特定類型的回饋。我們重新審視現有的回饋分類法，
以擷取所產生回饋的具體特徵，例如隨機性、不確定性和變異程度。

**方法：**我們反覆設計提示，以產生特定回饋類型（作為現有回饋分類法的一部分），
以回應真實的學生程式。然後，我們評估產生的輸出，
並確定它在多大程度上反映了某些回饋類型。

**結果和結論：**目前的研究提供了對不同回饋面向和特徵的更深入了解。這些結果
對未來的回饋研究具有影響，例如回饋效果和學習者的資訊需求。它進一步為
開發新的工具和學習系統奠定了基礎，這些系統包括由 AI 生成的回饋，
適用於新手程式設計師。

##### **KKLIP: Knowledge Distillation Exploiting K-means Clustering for Language-Image Pre-Training**
2412.03513v1 by Kuei-Chun Kao

Recently, CLIP has emerged as a valuable model for aligning image and text
information in multi-modal scenarios. However, researchers have observed
limitations in the ability of CLIP's text and image encoders to extract
detailed knowledge from caption-image pairs. In response, this paper introduces
KKLIP, a novel approach designed to enhance the quality of CLIP by
incorporating a new knowledge distillation (KD) method derived from Llama 2.
Our method comprises three objectives: Text Embedding Distillation, Concept
Learning, and Contrastive Learning. Firstly, Text Embedding Distillation
involves training the KKLIP text encoder to emulate the teacher model, Llama 2.
Secondly, Concept Learning assigns a soft concept label to each caption-image
pair through offline k-means clustering of text information from Llama 2,
allowing KKLIP to learn from these soft concept labels. Finally, Contrastive
Learning harmonizes text and image embeddings. Our experimental results
demonstrate that KKLIP enhances the quality of both text and image encoders.

摘要：最近，CLIP 已成为一种有价值的模型，用于在多模态场景中对齐图像和文本信息。然而，研究人员已经观察到 CLIP 的文本和图像编码器从标题图像对中提取详细知识的能力存在局限性。对此，本文介绍了 KKLIP，这是一种新颖的方法，旨在通过整合源自 Llama 2 的新知识蒸馏 (KD) 方法来增强 CLIP 的质量。我们的方法包括三个目标：文本嵌入蒸馏、概念学习和对比学习。首先，文本嵌入蒸馏涉及训练 KKLIP 文本编码器以模拟教师模型 Llama 2。其次，概念学习通过离线对来自 Llama 2 的文本信息进行 k 均值聚类，为每个标题图像对分配一个软概念标签，从而允许 KKLIP 从这些软概念标签中学习。最后，对比学习协调文本和图像嵌入。我们的实验结果表明，KKLIP 增强了文本和图像编码器的质量。

##### **A Bidirectional Siamese Recurrent Neural Network for Accurate Gait Recognition Using Body Landmarks**
2412.03498v1 by Proma Hossain Progga, Md. Jobayer Rahman, Swapnil Biswas, Md. Shakil Ahmed, Arif Reza Anwary, Swakkhar Shatabda

Gait recognition is a significant biometric technique for person
identification, particularly in scenarios where other physiological biometrics
are impractical or ineffective. In this paper, we address the challenges
associated with gait recognition and present a novel approach to improve its
accuracy and reliability. The proposed method leverages advanced techniques,
including sequential gait landmarks obtained through the Mediapipe pose
estimation model, Procrustes analysis for alignment, and a Siamese
biGRU-dualStack Neural Network architecture for capturing temporal
dependencies. Extensive experiments were conducted on large-scale cross-view
datasets to demonstrate the effectiveness of the approach, achieving high
recognition accuracy compared to other models. The model demonstrated
accuracies of 95.7%, 94.44%, 87.71%, and 86.6% on CASIA-B, SZU RGB-D, OU-MVLP,
and Gait3D datasets respectively. The results highlight the potential
applications of the proposed method in various practical domains, indicating
its significant contribution to the field of gait recognition.

摘要：步態辨識是一種重要的生物特徵技術，用於個人識別，特別是在其他生理生物特徵不切實際或無效的情況下。在本文中，我們探討了與步態辨識相關的挑戰，並提出了一種新的方法來提高其準確性和可靠性。所提出的方法利用了先進的技術，包括通過 Mediapipe 姿勢估計模型獲得的序列步態地標、用於對齊的 Procrustes 分析，以及用於捕捉時間依賴性的 Siamese biGRU-dualStack 神經網路架構。在大型跨視圖數據集上進行了廣泛的實驗，以證明該方法的有效性，與其他模型相比，實現了很高的識別準確率。該模型在 CASIA-B、SZU RGB-D、OU-MVLP 和 Gait3D 數據集上分別展示了 95.7%、94.44%、87.71% 和 86.6% 的準確率。結果突出了所提出方法在各種實際領域的潛在應用，表明其對步態辨識領域做出了重大貢獻。

##### **Flow Matching with General Discrete Paths: A Kinetic-Optimal Perspective**
2412.03487v1 by Neta Shaul, Itai Gat, Marton Havasi, Daniel Severo, Anuroop Sriram, Peter Holderrieth, Brian Karrer, Yaron Lipman, Ricky T. Q. Chen

The design space of discrete-space diffusion or flow generative models are
significantly less well-understood than their continuous-space counterparts,
with many works focusing only on a simple masked construction. In this work, we
aim to take a holistic approach to the construction of discrete generative
models based on continuous-time Markov chains, and for the first time, allow
the use of arbitrary discrete probability paths, or colloquially, corruption
processes. Through the lens of optimizing the symmetric kinetic energy, we
propose velocity formulas that can be applied to any given probability path,
completely decoupling the probability and velocity, and giving the user the
freedom to specify any desirable probability path based on expert knowledge
specific to the data domain. Furthermore, we find that a special construction
of mixture probability paths optimizes the symmetric kinetic energy for the
discrete case. We empirically validate the usefulness of this new design space
across multiple modalities: text generation, inorganic material generation, and
image generation. We find that we can outperform the mask construction even in
text with kinetic-optimal mixture paths, while we can make use of
domain-specific constructions of the probability path over the visual domain.

摘要：離散空間擴散或流動生成模型的設計空間，與其連續空間的對應物相比，顯著地不甚明瞭，許多作品僅專注於簡單的遮罩構造。在這項工作中，我們旨在採用整體方法來建構基於連續時間馬可夫鏈的離散生成模型，並首次允許使用任意離散機率路徑，或通俗地說，損壞程序。透過最佳化對稱動能的觀點，我們提出可以應用於任何給定機率路徑的速度公式，完全解耦機率和速度，並讓使用者能夠根據特定於資料領域的專家知識，指定任何理想的機率路徑。此外，我們發現混合機率路徑的特殊構造，會最佳化離散情況的對稱動能。我們透過多種方式驗證此新設計空間的效用：文字生成、無機材料生成和影像生成。我們發現，即使在具有動能最佳混合路徑的文字中，我們也可以優於遮罩構造，同時我們可以在視覺領域中使用機率路徑的特定於領域的構造。

##### **Training-Free Mitigation of Language Reasoning Degradation After Multimodal Instruction Tuning**
2412.03467v1 by Neale Ratzlaff, Man Luo, Xin Su, Vasudev Lal, Phillip Howard

Multimodal models typically combine a powerful large language model (LLM)
with a vision encoder and are then trained on multimodal data via instruction
tuning. While this process adapts LLMs to multimodal settings, it remains
unclear whether this adaptation compromises their original language reasoning
capabilities. In this work, we explore the effects of multimodal instruction
tuning on language reasoning performance. We focus on LLaVA, a leading
multimodal framework that integrates LLMs such as Vicuna or Mistral with the
CLIP vision encoder. We compare the performance of the original LLMs with their
multimodal-adapted counterparts across eight language reasoning tasks. Our
experiments yield several key insights. First, the impact of multimodal
learning varies between Vicuna and Mistral: we observe a degradation in
language reasoning for Mistral but improvements for Vicuna across most tasks.
Second, while multimodal instruction learning consistently degrades performance
on mathematical reasoning tasks (e.g., GSM8K), it enhances performance on
commonsense reasoning tasks (e.g., CommonsenseQA). Finally, we demonstrate that
a training-free model merging technique can effectively mitigate the language
reasoning degradation observed in multimodal-adapted Mistral and even improve
performance on visual tasks.

摘要：多模态模型通常将强大的大型语言模型 (LLM) 与视觉编码器结合起来，然后通过指令微调在多模态数据上进行训练。虽然此过程使 LLM 适应多模态设置，但尚不清楚这种适应是否会损害其原始语言推理能力。在这项工作中，我们探讨了多模态指令微调对语言推理性能的影响。我们专注于 LLaVA，这是一个领先的多模态框架，它将 Vicuna 或 Mistral 等 LLM 与 CLIP 视觉编码器集成在一起。我们比较了原始 LLM 与其多模态适应对应项在八个语言推理任务中的性能。我们的实验产生了几个关键见解。首先，多模态学习的影响在 Vicuna 和 Mistral 之间有所不同：我们观察到 Mistral 的语言推理能力下降，但大多数任务中 Vicuna 的语言推理能力都有所提高。其次，虽然多模态指令学习持续降低数学推理任务（例如 GSM8K）的性能，但它增强了常识推理任务（例如 CommonsenseQA）的性能。最后，我们证明了一种无训练模型合并技术可以有效缓解在多模态适应的 Mistral 中观察到的语言推理退化，甚至可以提高视觉任务的性能。

##### **From Words to Workflows: Automating Business Processes**
2412.03446v1 by Laura Minkova, Jessica López Espejel, Taki Eddine Toufik Djaidja, Walid Dahhane, El Hassane Ettifouri

As businesses increasingly rely on automation to streamline operations, the
limitations of Robotic Process Automation (RPA) have become apparent,
particularly its dependence on expert knowledge and inability to handle complex
decision-making tasks. Recent advancements in Artificial Intelligence (AI),
particularly Generative AI (GenAI) and Large Language Models (LLMs), have paved
the way for Intelligent Automation (IA), which integrates cognitive
capabilities to overcome the shortcomings of RPA. This paper introduces
Text2Workflow, a novel method that automatically generates workflows from
natural language user requests. Unlike traditional automation approaches,
Text2Workflow offers a generalized solution for automating any business
process, translating user inputs into a sequence of executable steps
represented in JavaScript Object Notation (JSON) format. Leveraging the
decision-making and instruction-following capabilities of LLMs, this method
provides a scalable, adaptable framework that enables users to visualize and
execute workflows with minimal manual intervention. This research outlines the
Text2Workflow methodology and its broader implications for automating complex
business processes.

摘要：<paragraph>隨著企業日益依賴自動化來簡化營運，機器人流程自動化 (RPA) 的限制已變得明顯，特別是其依賴專家知識以及無法處理複雜決策任務。人工智慧 (AI) 的最新進展，特別是生成式 AI (GenAI) 和大型語言模型 (LLM)，已為智慧自動化 (IA) 鋪路，整合認知能力以克服 RPA 的缺點。本文介紹 Text2Workflow，一種從自然語言使用者要求中自動產生工作流程的新方法。與傳統的自動化方法不同，Text2Workflow 提供了一個通用的解決方案，用於自動化任何業務流程，將使用者輸入轉換為以 JavaScript 物件表示法 (JSON) 格式表示的可執行步驟序列。利用 LLM 的決策制定和遵循指令的能力，此方法提供了一個可擴充、可適應的框架，使用戶能夠以最少的 人工干預視覺化和執行工作流程。本研究概述了 Text2Workflow 方法及其對自動化複雜業務流程的更廣泛影響。</paragraph>

##### **PBP: Post-training Backdoor Purification for Malware Classifiers**
2412.03441v1 by Dung Thuy Nguyen, Ngoc N. Tran, Taylor T. Johnson, Kevin Leach

In recent years, the rise of machine learning (ML) in cybersecurity has
brought new challenges, including the increasing threat of backdoor poisoning
attacks on ML malware classifiers. For instance, adversaries could inject
malicious samples into public malware repositories, contaminating the training
data and potentially misclassifying malware by the ML model. Current
countermeasures predominantly focus on detecting poisoned samples by leveraging
disagreements within the outputs of a diverse set of ensemble models on
training data points. However, these methods are not suitable for scenarios
where Machine Learning-as-a-Service (MLaaS) is used or when users aim to remove
backdoors from a model after it has been trained. Addressing this scenario, we
introduce PBP, a post-training defense for malware classifiers that mitigates
various types of backdoor embeddings without assuming any specific backdoor
embedding mechanism. Our method exploits the influence of backdoor attacks on
the activation distribution of neural networks, independent of the
trigger-embedding method. In the presence of a backdoor attack, the activation
distribution of each layer is distorted into a mixture of distributions. By
regulating the statistics of the batch normalization layers, we can guide a
backdoored model to perform similarly to a clean one. Our method demonstrates
substantial advantages over several state-of-the-art methods, as evidenced by
experiments on two datasets, two types of backdoor methods, and various attack
configurations. Notably, our approach requires only a small portion of the
training data -- only 1\% -- to purify the backdoor and reduce the attack
success rate from 100\% to almost 0\%, a 100-fold improvement over the baseline
methods. Our code is available at
\url{https://github.com/judydnguyen/pbp-backdoor-purification-official}.

摘要：近年來，機器學習 (ML) 在網路安全的崛起帶來了新的挑戰，包括針對 ML 惡意軟體分類器越來越嚴重的後門投毒攻擊威脅。例如，攻擊者可以將惡意樣本注入公共惡意軟體儲存庫，污染訓練資料，並可能導致 ML 模型錯誤分類惡意軟體。目前的對策主要集中於透過利用一組多元集成模型在訓練資料點上輸出的分歧來偵測中毒樣本。然而，這些方法不適用於使用機器學習即服務 (MLaaS) 或使用者在訓練模型後希望從模型中移除後門的場景。為了處理這種場景，我們引入了 PBP，這是一種針對惡意軟體分類器的訓練後防禦機制，它能減輕各種類型的後門嵌入，而無需假設任何特定後門嵌入機制。我們的方法利用後門攻擊對神經網路啟用分佈的影響，與觸發嵌入方法無關。在後門攻擊的情況下，每一層的啟用分佈會扭曲成混合分佈。透過調節批次標準化層的統計資料，我們可以引導後門模型執行類似於乾淨模型的任務。我們的模型展現出優於多種最先進方法的顯著優勢，這在兩個資料集、兩種後門方法和各種攻擊配置的實驗中得到證明。值得注意的是，我們的模型僅需要一小部分訓練資料 (僅 1%) 就能淨化後門，並將攻擊成功率從 100% 降低到幾乎 0%，比基準方法提升了 100 倍。我們的程式碼可於以下網址取得：\url{https://github.com/judydnguyen/pbp-backdoor-purification-official}。

##### **BIMCaP: BIM-based AI-supported LiDAR-Camera Pose Refinement**
2412.03434v1 by Miguel Arturo Vega Torres, Anna Ribic, Borja García de Soto, André Borrmann

This paper introduces BIMCaP, a novel method to integrate mobile 3D sparse
LiDAR data and camera measurements with pre-existing building information
models (BIMs), enhancing fast and accurate indoor mapping with affordable
sensors. BIMCaP refines sensor poses by leveraging a 3D BIM and employing a
bundle adjustment technique to align real-world measurements with the model.
Experiments using real-world open-access data show that BIMCaP achieves
superior accuracy, reducing translational error by over 4 cm compared to
current state-of-the-art methods. This advancement enhances the accuracy and
cost-effectiveness of 3D mapping methodologies like SLAM. BIMCaP's improvements
benefit various fields, including construction site management and emergency
response, by providing up-to-date, aligned digital maps for better
decision-making and productivity. Link to the repository:
https://github.com/MigVega/BIMCaP

摘要：這篇論文介紹了 BIMCaP，一種新穎的方法，用於整合行動 3D 稀疏 LiDAR 資料和相機測量，以及預先存在的建築資訊模型 (BIM)，藉由經濟實惠的感測器加強快速且精準的室內建構。BIMCaP 透過利用 3D BIM，並採用束調整技術，將真實世界測量與模型對齊，進而優化感測器姿勢。使用真實世界開放取用資料的實驗顯示，與目前最先進的方法相比，BIMCaP 達到更高的精確度，將平移誤差減少超過 4 公分。此項進展提升了 3D 建構方法（例如 SLAM）的精確度和成本效益。BIMCaP 的改進使各種領域受益，包括建築工地管理和緊急應變，藉由提供最新的對齊數位地圖，以利於更好的決策制定和生產力。儲存庫連結：https://github.com/MigVega/BIMCaP

##### **Automated Test-Case Generation for REST APIs Using Model Inference Search Heuristic**
2412.03420v1 by Clinton Cao, Annibale Panichella, Sicco Verwer

The rising popularity of the microservice architectural style has led to a
growing demand for automated testing approaches tailored to these systems.
EvoMaster is a state-of-the-art tool that uses Evolutionary Algorithms (EAs) to
automatically generate test cases for microservices' REST APIs. One limitation
of these EAs is the use of unit-level search heuristics, such as branch
distances, which focus on fine-grained code coverage and may not effectively
capture the complex, interconnected behaviors characteristic of system-level
testing. To address this limitation, we propose a new search heuristic (MISH)
that uses real-time automaton learning to guide the test case generation
process. We capture the sequential call patterns exhibited by a test case by
learning an automaton from the stream of log events outputted by different
microservices within the same system. Therefore, MISH learns a representation
of the systemwide behavior, allowing us to define the fitness of a test case
based on the path it traverses within the inferred automaton. We empirically
evaluate MISH's effectiveness on six real-world benchmark microservice
applications and compare it against a state-of-the-art technique, MOSA, for
testing REST APIs. Our evaluation shows promising results for using MISH to
guide the automated test case generation within EvoMaster.

摘要：微服務架構風格日益普及，導致對針對這些系統量身打造的自動化測試方法的需求不斷增長。EvoMaster 是一款最先進的工具，它使用演算法 (EA) 自動產生微服務 REST API 的測試案例。這些 EA 的一個限制是使用單元層級的搜尋啟發法，例如分支距離，這種方法專注於精細的程式碼覆蓋率，可能無法有效捕捉系統層級測試特有的複雜、相互關聯的行為。為了解決這個限制，我們提出一個新的搜尋啟發法 (MISH)，它使用即時自動機學習來引導測試案例產生程序。我們透過從同一個系統中不同微服務輸出的日誌事件串流學習自動機，來捕捉測試案例展現的順序呼叫模式。因此，MISH 會學習系統範圍行為的表示，讓我們可以根據測試案例在推論的自動機中所走訪的路徑來定義其適應度。我們對六個真實世界的基準微服務應用程式實證評估了 MISH 的有效性，並將其與最先進的 REST API 測試技術 MOSA 進行比較。我們的評估顯示，使用 MISH 來引導 EvoMaster 中的自動化測試案例產生，具有令人振奮的結果。

##### **Benchmarking Pretrained Attention-based Models for Real-Time Recognition in Robot-Assisted Esophagectomy**
2412.03401v1 by Ronald L. P. D. de Jong, Yasmina al Khalil, Tim J. M. Jaspers, Romy C. van Jaarsveld, Gino M. Kuiper, Yiping Li, Richard van Hillegersberg, Jelle P. Ruurda, Marcel Breeuwer, Fons van der Sommen

Esophageal cancer is among the most common types of cancer worldwide. It is
traditionally treated using open esophagectomy, but in recent years,
robot-assisted minimally invasive esophagectomy (RAMIE) has emerged as a
promising alternative. However, robot-assisted surgery can be challenging for
novice surgeons, as they often suffer from a loss of spatial orientation.
Computer-aided anatomy recognition holds promise for improving surgical
navigation, but research in this area remains limited. In this study, we
developed a comprehensive dataset for semantic segmentation in RAMIE, featuring
the largest collection of vital anatomical structures and surgical instruments
to date. Handling this diverse set of classes presents challenges, including
class imbalance and the recognition of complex structures such as nerves. This
study aims to understand the challenges and limitations of current
state-of-the-art algorithms on this novel dataset and problem. Therefore, we
benchmarked eight real-time deep learning models using two pretraining
datasets. We assessed both traditional and attention-based networks,
hypothesizing that attention-based networks better capture global patterns and
address challenges such as occlusion caused by blood or other tissues. The
benchmark includes our RAMIE dataset and the publicly available CholecSeg8k
dataset, enabling a thorough assessment of surgical segmentation tasks. Our
findings indicate that pretraining on ADE20k, a dataset for semantic
segmentation, is more effective than pretraining on ImageNet. Furthermore,
attention-based models outperform traditional convolutional neural networks,
with SegNeXt and Mask2Former achieving higher Dice scores, and Mask2Former
additionally excelling in average symmetric surface distance.

摘要：食道癌是全球最常見的癌症類型之一。傳統上使用開胸食道切除術進行治療，但近年來，機器人輔助微創食道切除術 (RAMIE) 已成為一種有前景的替代方案。然而，對於新手外科醫生來說，機器人輔助手術可能具有挑戰性，因為他們經常會喪失空間定位能力。電腦輔助解剖識別有望改善手術導航，但這方面的研究仍然有限。在這項研究中，我們為 RAMIE 中的語義分割開發了一個全面的數據集，其中包含迄今為止最大的重要解剖結構和手術器械集合。處理這一組不同的類別會帶來挑戰，包括類別不平衡以及對神經等複雜結構的識別。本研究旨在了解當前最先進演算法在這個新數據集和問題上的挑戰和限制。因此，我們使用兩個預訓練數據集對八個實時深度學習模型進行了基準測試。我們評估了傳統和基於注意力的網路，假設基於注意力的網路可以更好地捕捉全局模式，並解決因血液或其他組織引起的遮擋等挑戰。基準測試包括我們的 RAMIE 數據集和公開的 CholecSeg8k 數據集，可以對外科分割任務進行全面評估。我們的研究結果表明，在 ADE20k（一個用於語義分割的數據集）上進行預訓練比在 ImageNet 上進行預訓練更有效。此外，基於注意力的模型優於傳統的卷積神經網路，其中 SegNeXt 和 Mask2Former 獲得了更高的 Dice 分數，而 Mask2Former 在平均對稱表面距離方面也表現出色。

##### **RedStone: Curating General, Code, Math, and QA Data for Large Language Models**
2412.03398v1 by Yaoyao Chang, Lei Cui, Li Dong, Shaohan Huang, Yangyu Huang, Yupan Huang, Scarlett Li, Tengchao Lv, Shuming Ma, Qinzheng Sun, Wenhui Wang, Furu Wei, Ying Xin, Mao Yang, Qiufeng Yin, Xingxing Zhang

Pre-training Large Language Models (LLMs) on high-quality, meticulously
curated datasets is widely recognized as critical for enhancing their
performance and generalization capabilities. This study explores the untapped
potential of Common Crawl as a comprehensive and flexible resource for
pre-training LLMs, addressing both general-purpose language understanding and
specialized domain knowledge. We introduce RedStone, an innovative and scalable
pipeline engineered to extract and process data from Common Crawl, facilitating
the creation of extensive and varied pre-training datasets. Unlike traditional
datasets, which often require expensive curation and domain-specific expertise,
RedStone leverages the breadth of Common Crawl to deliver datasets tailored to
a wide array of domains. In this work, we exemplify its capability by
constructing pre-training datasets across multiple fields, including general
language understanding, code, mathematics, and question-answering tasks. The
flexibility of RedStone allows for easy adaptation to other specialized
domains, significantly lowering the barrier to creating valuable
domain-specific datasets. Our findings demonstrate that Common Crawl, when
harnessed through effective pipelines like RedStone, can serve as a rich,
renewable source of pre-training data, unlocking new avenues for domain
adaptation and knowledge discovery in LLMs. This work also underscores the
importance of innovative data acquisition strategies and highlights the role of
web-scale data as a powerful resource in the continued evolution of LLMs.
RedStone code and data samples will be publicly available at
\url{https://aka.ms/redstone}.

摘要：<paragraph>在高品質、經過仔細整理的資料集上預先訓練大型語言模型 (LLM) 被廣泛認為對於提升其效能和概化能力至關重要。本研究探討了 Common Crawl 作為一個全面且彈性的資源，在預先訓練 LLM 方面的未開發潛力，同時解決一般用途的語言理解和專業領域知識。我們介紹了 RedStone，這是一個創新且可擴充的管道，設計用於從 Common Crawl 擷取和處理資料，促進建立廣泛且多樣的預先訓練資料集。與傳統資料集不同，傳統資料集通常需要昂貴的整理和特定領域的專業知識，RedStone 利用 Common Crawl 的廣度來提供適合各種領域的資料集。在這項工作中，我們透過建構跨多個領域的預先訓練資料集來證明其能力，包括一般語言理解、程式碼、數學和問答任務。RedStone 的彈性允許輕鬆適應其他專業領域，大幅降低建立有價值的特定領域資料集的門檻。我們的研究結果證明，當透過像 RedStone 這樣的有效管道利用 Common Crawl 時，它可以用作豐富、可再生的預先訓練資料來源，為 LLM 中的領域適應和知識發現開啟新途徑。這項工作也強調了創新資料擷取策略的重要性，並突顯了網路規模資料在 LLM 持續演進中作為強大資源的角色。RedStone 程式碼和資料範例將在 \url{https://aka.ms/redstone} 公開提供。</paragraph>

##### **Enhancing Supply Chain Visibility with Generative AI: An Exploratory Case Study on Relationship Prediction in Knowledge Graphs**
2412.03390v1 by Ge Zheng, Alexandra Brintrup

A key stumbling block in effective supply chain risk management for companies
and policymakers is a lack of visibility on interdependent supply network
relationships. Relationship prediction, also called link prediction is an
emergent area of supply chain surveillance research that aims to increase the
visibility of supply chains using data-driven techniques. Existing methods have
been successful for predicting relationships but struggle to extract the
context in which these relationships are embedded - such as the products being
supplied or locations they are supplied from. Lack of context prevents
practitioners from distinguishing transactional relations from established
supply chain relations, hindering accurate estimations of risk. In this work,
we develop a new Generative Artificial Intelligence (Gen AI) enhanced machine
learning framework that leverages pre-trained language models as embedding
models combined with machine learning models to predict supply chain
relationships within knowledge graphs. By integrating Generative AI techniques,
our approach captures the nuanced semantic relationships between entities,
thereby improving supply chain visibility and facilitating more precise risk
management. Using data from a real case study, we show that GenAI-enhanced link
prediction surpasses all benchmarks, and demonstrate how GenAI models can be
explored and effectively used in supply chain risk management.

摘要：供應鏈風險管理中的一個關鍵障礙在於企業和政策制定者缺乏對相互依存供應網路關係的能見度。關係預測，也稱為連結預測，是供應鏈監控研究中一個新興領域，旨在使用資料驅動技術提高供應鏈的能見度。現有方法已成功預測關係，但難以提取這些關係所嵌入的背景，例如所供應的產品或供應地點。缺乏背景會妨礙從業者區分交易關係和既定的供應鏈關係，進而阻礙風險的準確評估。在這項工作中，我們開發了一個新的生成式人工智慧 (Gen AI) 增強機器學習架構，它利用預先訓練的語言模型作為嵌入模型，並結合機器學習模型來預測知識圖譜中的供應鏈關係。透過整合生成式 AI 技術，我們的做法捕捉到實體之間細微的語義關係，從而提高供應鏈能見度並促進更精確的風險管理。使用來自真實案例研究的資料，我們證明 GenAI 增強連結預測優於所有基準，並展示如何探索和有效地在供應鏈風險管理中使用 GenAI 模型。

##### **DiffStyleTTS: Diffusion-based Hierarchical Prosody Modeling for Text-to-Speech with Diverse and Controllable Styles**
2412.03388v1 by Jiaxuan Liu, Zhaoci Liu, Yajun Hu, Yingying Gao, Shilei Zhang, Zhenhua Ling

Human speech exhibits rich and flexible prosodic variations. To address the
one-to-many mapping problem from text to prosody in a reasonable and flexible
manner, we propose DiffStyleTTS, a multi-speaker acoustic model based on a
conditional diffusion module and an improved classifier-free guidance, which
hierarchically models speech prosodic features, and controls different prosodic
styles to guide prosody prediction. Experiments show that our method
outperforms all baselines in naturalness and achieves superior synthesis speed
compared to three diffusion-based baselines. Additionally, by adjusting the
guiding scale, DiffStyleTTS effectively controls the guidance intensity of the
synthetic prosody.

摘要：人類的語音展現出豐富且靈活的韻律變化。為了以合理且靈活的方式解決文字到韻律的一對多對應問題，我們提出 DiffStyleTTS，這是一個基於條件擴散模組和改進的無分類器引導的多重說話者聲學模型，它以階層方式建構語音韻律特徵，並控制不同的韻律風格以引導韻律預測。實驗顯示，與自然度中的所有基準相比，我們的模型表現優異，並且與三個基於擴散的基準相比，達到了更佳的合成速度。此外，透過調整引導比例，DiffStyleTTS 能有效地控制合成韻律的引導強度。

##### **WiS Platform: Enhancing Evaluation of LLM-Based Multi-Agent Systems Through Game-Based Analysis**
2412.03359v1 by Chengwei Hu, Jianhui Zheng, Yancheng He, Hangyu Guo, Junguang Jiang, Han Zhu, Kai Sun, Yuning Jiang, Wenbo Su, Bo Zheng

Recent advancements in autonomous multi-agent systems (MAS) based on large
language models (LLMs) have enhanced the application scenarios and improved the
capability of LLMs to handle complex tasks. Despite demonstrating
effectiveness, existing studies still evidently struggle to evaluate, analysis,
and reproducibility of LLM-based MAS. In this paper, to facilitate the research
on LLM-based MAS, we introduce an open, scalable, and real-time updated
platform for accessing and analyzing the LLM-based MAS based on the games Who
is Spy?" (WiS). Our platform is featured with three main worths: (1) a unified
model evaluate interface that supports models available on Hugging Face; (2)
real-time updated leaderboard for model evaluation; (3) a comprehensive
evaluation covering game-winning rates, attacking, defense strategies, and
reasoning of LLMs. To rigorously test WiS, we conduct extensive experiments
coverage of various open- and closed-source LLMs, we find that different agents
exhibit distinct and intriguing behaviors in the game. The experimental results
demonstrate the effectiveness and efficiency of our platform in evaluating
LLM-based MAS. Our platform and its documentation are publicly available at
\url{https://whoisspy.ai/}

摘要：<paragraph>基於大型語言模型 (LLM) 的自主多智能體系統 (MAS) 近期的進展，擴展了應用場景，並提升了 LLM 處理複雜任務的能力。儘管證明了其有效性，但現有研究仍明顯難以評估、分析和重現基於 LLM 的 MAS。在本文中，為了促進對基於 LLM 的 MAS 的研究，我們介紹了一個開放、可擴充且即時更新的平台，用於存取和分析基於遊戲「誰是間諜？」(WiS) 的基於 LLM 的 MAS。我們的平台具有三個主要價值：(1) 統一的模型評估介面，支援 Hugging Face 上可用的模型；(2) 即時更新的模型評估排行榜；(3) 全面的評估，涵蓋遊戲獲勝率、攻擊、防禦策略和 LLM 的推理。為了嚴格測試 WiS，我們對各種開源和閉源 LLM 進行廣泛的實驗，我們發現不同的智能體在遊戲中表現出截然不同且有趣的行為。實驗結果證明了我們的平台在評估基於 LLM 的 MAS 時的有效性和效率。我們的平台及其文件在 \url{https://whoisspy.ai/} 公開提供</paragraph>

##### **Intuitive Axial Augmentation Using Polar-Sine-Based Piecewise Distortion for Medical Slice-Wise Segmentation**
2412.03352v1 by Yiqin Zhang, Qingkui Chen, Chen Huang, Zhengjie Zhang, Meiling Chen, Zhibing Fu

Most data-driven models for medical image analysis rely on universal
augmentations to improve performance. Experimental evidence has confirmed their
effectiveness, but the unclear mechanism underlying them poses a barrier to the
widespread acceptance and trust in such methods within the medical community.
We revisit and acknowledge the unique characteristics of medical images apart
from traditional digital images, and consequently, proposed a medical-specific
augmentation algorithm that is more elastic and aligns well with radiology scan
procedure. The method performs piecewise affine with sinusoidal distorted ray
according to radius on polar coordinates, thus simulating uncertain postures of
human lying flat on the scanning table. Our method could generate human
visceral distribution without affecting the fundamental relative position on
axial plane. Two non-adaptive algorithms, namely Meta-based Scan Table Removal
and Similarity-Guided Parameter Search, are introduced to bolster robustness of
our augmentation method. Experiments show our method improves accuracy across
multiple famous segmentation frameworks without requiring more data samples.
Our preview code is available in: https://github.com/MGAMZ/PSBPD.

摘要：大多數用於醫學影像分析的資料驅動模型仰賴通用擴充功能來提升效能。實驗證據已證實其有效性，但其背後不明確的機制對醫學界廣泛接受和信任此類方法構成阻礙。我們重新檢視並承認醫學影像與傳統數位影像的獨特特性，因此提出更具彈性且與放射線掃描程序密切配合的醫學特定擴充演算法。該方法根據極座標上的半徑執行正弦扭曲射線的逐段仿射，從而模擬人平躺在掃描台上時的不確定姿勢。我們的方法可以在不影響軸向平面上基本相對位置的情況下生成人體內臟分佈。引入了兩種非自適應演算法，即基於 Meta 的掃描台移除和相似性導引參數搜尋，以加強我們擴充方法的穩健性。實驗表明，我們的演算法在不需要更多資料樣本的情況下，就能提升多個著名分割架構的準確性。我們的預覽程式碼可在 https://github.com/MGAMZ/PSBPD 中取得。

##### **DIVE: Taming DINO for Subject-Driven Video Editing**
2412.03347v1 by Yi Huang, Wei Xiong, He Zhang, Chaoqi Chen, Jianzhuang Liu, Mingfu Yan, Shifeng Chen

Building on the success of diffusion models in image generation and editing,
video editing has recently gained substantial attention. However, maintaining
temporal consistency and motion alignment still remains challenging. To address
these issues, this paper proposes DINO-guided Video Editing (DIVE), a framework
designed to facilitate subject-driven editing in source videos conditioned on
either target text prompts or reference images with specific identities. The
core of DIVE lies in leveraging the powerful semantic features extracted from a
pretrained DINOv2 model as implicit correspondences to guide the editing
process. Specifically, to ensure temporal motion consistency, DIVE employs DINO
features to align with the motion trajectory of the source video. Extensive
experiments on diverse real-world videos demonstrate that our framework can
achieve high-quality editing results with robust motion consistency,
highlighting the potential of DINO to contribute to video editing. For precise
subject editing, DIVE incorporates the DINO features of reference images into a
pretrained text-to-image model to learn Low-Rank Adaptations (LoRAs),
effectively registering the target subject's identity. Project page:
https://dino-video-editing.github.io

摘要：建立在擴散模型在影像生成和編輯上的成功，影片編輯最近獲得了大量的關注。然而，維持時間一致性和動作對齊仍然具有挑戰性。為了解決這些問題，本文提出了 DINO 引導的影片編輯 (DIVE)，一個旨在促進以主題為導向的編輯，在來源影片中以目標文字提示或具有特定身分的參考影像為條件。DIVE 的核心在於利用從預訓練的 DINOv2 模型中提取的強大語義特徵，作為隱含對應來引導編輯過程。具體來說，為了確保時間動作一致性，DIVE 使用 DINO 特徵與來源影片的動作軌跡對齊。在各種真實世界影片上的大量實驗表明，我們的框架可以在強大的動作一致性下實現高品質的編輯結果，突顯了 DINO 對影片編輯的潛在貢獻。對於精確的主題編輯，DIVE 將參考影像的 DINO 特徵整合到預訓練的文字轉影像模型中，以學習低秩適應 (LoRAs)，有效註冊目標主題的身分。專案頁面：https://dino-video-editing.github.io

##### **Improving Linguistic Diversity of Large Language Models with Possibility Exploration Fine-Tuning**
2412.03343v1 by Long Mai, Julie Carson-Berndsen

While Large Language Models (LLMs) have made significant strides in
replicating human-like abilities, there are concerns about a reduction in the
linguistic diversity of their outputs. This results in the homogenization of
viewpoints and perspectives, as well as the underrepresentation of specific
demographic groups. Although several fine-tuning and prompting techniques have
been suggested to tackle the issue, they are often tailored to specific tasks
or come with a substantial increase in computational cost and latency. This
makes them challenging to apply to applications that demand very low latency,
such as chatbots and virtual assistants. We propose Possibility Exploration
Fine-Tuning (PEFT), a task-agnostic framework that enhances the text diversity
of LLMs without increasing latency or computational cost. Given the same
prompt, models fine-tuned with PEFT can simultaneously generate multiple
diverse responses, each corresponding with a controllable possibility number.
Experiments on dialogue and story generation tasks demonstrate that PEFT
significantly enhances the diversity of LLM outputs, as evidenced by lower
similarity between candidate responses. Since PEFT emphasizes semantic
diversity over lexical diversity, it can also notably reduce demographic bias
in dialogue systems. The implementations and datasets are available in our
repository: https://github.com/mailong25/peft_diversity

摘要：雖然大型語言模型 (LLM) 已在複製類似人類的能力方面取得重大進展，但人們擔憂其輸出的語言多樣性會下降。這導致觀點和觀念的同質化，以及特定人口群體的代表性不足。儘管已提出幾種微調和提示技術來解決此問題，但它們通常針對特定任務進行調整，或伴隨著計算成本和延遲的大幅增加。這使得它們難以應用於需要非常低延遲的應用程式，例如聊天機器人和虛擬助理。我們提出可能性探索微調 (PEFT)，這是一個與任務無關的架構，它可以增強 LLM 的文字多樣性，而不會增加延遲或計算成本。在給定相同的提示下，使用 PEFT 微調的模型可以同時產生多種不同的回應，每個回應都對應一個可控的可能性數字。對話和故事生成任務的實驗表明，PEFT 可以顯著提高 LLM 輸出的多樣性，候選回應之間的相似性較低，即可證明這一點。由於 PEFT 強調語義多樣性而非詞彙多樣性，因此它也可以顯著減少對話系統中的人口統計偏見。實作和資料集可在我們的儲存庫中取得：https://github.com/mailong25/peft_diversity

##### **AI-Driven Day-to-Day Route Choice**
2412.03338v1 by Leizhen Wang, Peibo Duan, Zhengbing He, Cheng Lyu, Xin Chen, Nan Zheng, Li Yao, Zhenliang Ma

Understanding travelers' route choices can help policymakers devise optimal
operational and planning strategies for both normal and abnormal circumstances.
However, existing choice modeling methods often rely on predefined assumptions
and struggle to capture the dynamic and adaptive nature of travel behavior.
Recently, Large Language Models (LLMs) have emerged as a promising alternative,
demonstrating remarkable ability to replicate human-like behaviors across
various fields. Despite this potential, their capacity to accurately simulate
human route choice behavior in transportation contexts remains doubtful. To
satisfy this curiosity, this paper investigates the potential of LLMs for route
choice modeling by introducing an LLM-empowered agent, "LLMTraveler." This
agent integrates an LLM as its core, equipped with a memory system that learns
from past experiences and makes decisions by balancing retrieved data and
personality traits. The study systematically evaluates the LLMTraveler's
ability to replicate human-like decision-making through two stages: (1)
analyzing its route-switching behavior in single origin-destination (OD) pair
congestion game scenarios, where it demonstrates patterns align with laboratory
data but are not fully explained by traditional models, and (2) testing its
capacity to model day-to-day (DTD) adaptive learning behaviors on the Ortuzar
and Willumsen (OW) network, producing results comparable to Multinomial Logit
(MNL) and Reinforcement Learning (RL) models. These experiments demonstrate
that the framework can partially replicate human-like decision-making in route
choice while providing natural language explanations for its decisions. This
capability offers valuable insights for transportation policymaking, such as
simulating traveler responses to new policies or changes in the network.

摘要：<paragraph>了解旅客的路線選擇有助於政策制定者為正常和異常情況制定最佳營運和規劃策略。然而，現有的選擇模型方法通常依賴於預定義的假設，並且難以捕捉旅遊行為的動態和適應性。最近，大型語言模型 (LLM) 已成為一種有希望的替代方案，展示了在各種領域複製類人行為的非凡能力。儘管有這種潛力，它們在運輸環境中準確模擬人類路線選擇行為的能力仍然令人懷疑。為了滿足這種好奇心，本文通過引入 LLM 賦能的代理「LLMTraveler」來探討 LLM 在路線選擇建模中的潛力。此代理整合 LLM 作為其核心，配備一個記憶系統，從過去的經驗中學習，並通過平衡檢索的數據和人格特質來做出決策。該研究系統地評估了 LLMTraveler 通過兩個階段複製類人決策的能力：(1) 分析其在單一起點-目的地 (OD) 對擁塞博弈場景中的路線切換行為，它展示的模式與實驗室數據一致，但無法完全由傳統模型解釋，以及 (2) 測試其在 Ortuzar 和 Willumsen (OW) 網路上對日復一日 (DTD) 適應性學習行為進行建模的能力，產生的結果與多項式 Logit (MNL) 和強化學習 (RL) 模型相當。這些實驗表明，該框架可以部分複製類人路線選擇中的決策，同時為其決策提供自然語言解釋。這種能力為交通政策制定提供了有價值的見解，例如模擬旅客對新政策或網路變化的反應。</paragraph>

##### **Yankari: A Monolingual Yoruba Dataset**
2412.03334v1 by Maro Akpobi

This paper presents Yankari, a large-scale monolingual dataset for the Yoruba
language, aimed at addressing the critical gap in Natural Language Processing
(NLP) resources for this important West African language. Despite being spoken
by over 30 million people, Yoruba has been severely underrepresented in NLP
research and applications. We detail our methodology for creating this dataset,
which includes careful source selection, automated quality control, and
rigorous data cleaning processes. The Yankari dataset comprises 51,407
documents from 13 diverse sources, totaling over 30 million tokens. Our
approach focuses on ethical data collection practices, avoiding problematic
sources and addressing issues prevalent in existing datasets. We provide
thorough automated evaluations of the dataset, demonstrating its quality
compared to existing resources. The Yankari dataset represents a significant
advancement in Yoruba language resources, providing a foundation for developing
more accurate NLP models, supporting comparative linguistic studies, and
contributing to the digital accessibility of the Yoruba language.

摘要：這篇論文提出了 Yankari，一個針對約魯巴語的大型單語資料集，旨在解決這個重要的西非語言在自然語言處理 (NLP) 資源中的關鍵差距。儘管超過 3000 萬人使用約魯巴語，但它在 NLP 研究和應用中嚴重不足。我們詳細說明了建立這個資料集的方法，其中包括仔細的來源選擇、自動化的品質控管和嚴謹的資料清理程序。Yankari 資料集包含來自 13 個不同來源的 51,407 份文件，總計超過 3000 萬個詞彙。我們的做法著重於符合道德的資料收集實務，避免有問題的來源並解決現有資料集中普遍存在的問題。我們提供資料集的徹底自動化評估，證明其品質優於現有資源。Yankari 資料集代表約魯巴語資源的重大進展，為開發更精確的 NLP 模型、支援比較語言學研究和促進約魯巴語的數位可及性奠定基礎。

##### **LuxEmbedder: A Cross-Lingual Approach to Enhanced Luxembourgish Sentence Embeddings**
2412.03331v1 by Fred Philippy, Siwen Guo, Jacques Klein, Tegawendé F. Bissyandé

Sentence embedding models play a key role in various Natural Language
Processing tasks, such as in Topic Modeling, Document Clustering and
Recommendation Systems. However, these models rely heavily on parallel data,
which can be scarce for many low-resource languages, including Luxembourgish.
This scarcity results in suboptimal performance of monolingual and
cross-lingual sentence embedding models for these languages. To address this
issue, we compile a relatively small but high-quality human-generated
cross-lingual parallel dataset to train \tool, an enhanced sentence embedding
model for Luxembourgish with strong cross-lingual capabilities. Additionally,
we present evidence suggesting that including low-resource languages in
parallel training datasets can be more advantageous for other low-resource
languages than relying solely on high-resource language pairs. Furthermore,
recognizing the lack of sentence embedding benchmarks for low-resource
languages, we create a paraphrase detection benchmark specifically for
Luxembourgish, aiming to partially fill this gap and promote further research.

摘要：句子嵌入模型在各種自然語言處理任務中扮演著關鍵角色，例如主題建模、文件分群和推薦系統。然而，這些模型高度依賴平行資料，而這對於許多低資源語言來說可能很稀少，包括盧森堡語。這種稀少性導致了這些語言的單語和跨語言句子嵌入模型的次優性能。為了解決這個問題，我們編制了一個相對較小但高品質的人類生成的跨語言平行資料集，以訓練 \tool，一個具有強大跨語言能力的盧森堡語增強句子嵌入模型。此外，我們提出證據表明，在平行訓練資料集中包含低資源語言對其他低資源語言來說可能比僅依賴於高資源語言對更有利。此外，認識到低資源語言缺乏句子嵌入基準，我們專門為盧森堡語創建了一個同義詞偵測基準，旨在部分填補這一空白並促進進一步的研究。

##### **Grounded Language Design for Lightweight Diagramming for Formal Methods**
2412.03310v1 by Siddhartha Prasad, Ben Greenman, Tim Nelson, Shriram Krishnamurthi

Model finding, as embodied by SAT solvers and similar tools, is used widely,
both in embedding settings and as a tool in its own right. For instance, tools
like Alloy target SAT to enable users to incrementally define, explore, verify,
and diagnose sophisticated specifications for a large number of complex
systems.
  These tools critically include a visualizer that lets users graphically
explore these generated models. As we show, however, default visualizers, which
know nothing about the domain, are unhelpful and even actively violate
presentational and cognitive principles. At the other extreme, full-blown
visualizations require significant effort as well as knowledge a specifier
might not possess; they can also exhibit bad failure modes (including silent
failure). Instead, we need a language to capture essential domain information
for lightweight diagramming. We ground our language design in both the
cognitive science literature on diagrams and on a large number of example
custom visualizations. This identifies the key elements of lightweight
diagrams. We distill these into a small set of orthogonal primitives. We extend
an Alloy-like tool to support these primitives. We evaluate the effectiveness
of the produced diagrams, finding them good for reasoning. We then compare this
against many other drawing languages and tools to show that this work defines a
new niche that is lightweight, effective, and driven by sound principles.

摘要：模型尋找，例如 SAT 解決器和類似工具，被廣泛使用，
既用於嵌入式設定，也作為一種獨立的工具。例如，
Alloy 等工具以 SAT 為目標，使用戶能夠逐步定義、探索、驗證，
並診斷大量複雜系統的高級規格。
這些工具至關重要的是包括一個可視化器，讓用戶以圖形方式
探索這些生成的模型。然而，我們展示了默認的可視化器，
對領域一無所知，沒有幫助，甚至主動違反
展示和認知原則。在另一個極端，全面的
可視化需要大量的精力以及說明者可能不具備的知識；它們也可以表現出不良的故障模式（包括靜默
故障）。相反，我們需要一種語言來捕捉基本領域信息
用於輕量級圖表。我們將我們的語言設計建立在
關於圖表的認知科學文獻和大量示例
自定義可視化。這確定了輕量級
圖表的關鍵元素。我們將這些提煉成一組小的正交基元。我們擴展
一個類似 Alloy 的工具來支持這些基元。我們評估產生的圖表的有效性，發現它們對推理有益。然後我們比較這
與許多其他繪圖語言和工具，以表明這項工作定義了一個
新的利基，它輕量、有效且由合理的原則驅動。

##### **Contextual Data Integration for Bike-sharing Demand Prediction with Graph Neural Networks in Degraded Weather Conditions**
2412.03307v1 by Romain Rochas, Angelo Furno, Nour-Eddin El Faouzi

Demand for bike sharing is impacted by various factors, such as weather
conditions, events, and the availability of other transportation modes. This
impact remains elusive due to the complex interdependence of these factors or
locationrelated user behavior variations. It is also not clear which factor is
additional information which are not already contained in the historical
demand. Intermodal dependencies between bike-sharing and other modes are also
underexplored, and the value of this information has not been studied in
degraded situations. The proposed study analyzes the impact of adding
contextual data, such as weather, time embedding, and road traffic flow, to
predict bike-sharing Origin-Destination (OD) flows in atypical weather
situations Our study highlights a mild relationship between prediction quality
of bike-sharing demand and road traffic flow, while the introduced time
embedding allows outperforming state-of-the-art results, particularly in the
case of degraded weather conditions. Including weather data as an additional
input further improves our model with respect to the basic ST-ED-RMGC
prediction model by reducing of more than 20% the prediction error in degraded
weather condition.

摘要：自行車共享的需求會受到各種因素的影響，例如天氣狀況、活動和其它交通方式的可用性。由於這些因素的複雜相互依賴性或與位置相關的使用者行為變化，這種影響仍然難以捉摸。目前也不清楚哪個因素是歷史需求中尚未包含的附加資訊。自行車共享與其它方式之間的跨模式依賴性也尚未充分探討，而且在惡劣情況下，此資訊的價值尚未獲得研究。所提出的研究分析加入背景資料（例如天氣、時間嵌入和道路交通流量）對預測非典型天氣狀況下的自行車共享起迄點 (OD) 流量的影響。我們的研究強調自行車共享需求預測品質與道路交通流量之間的輕微關係，而所引入的時間嵌入允許超越最先進的結果，特別是在惡劣天氣條件的情況下。將天氣資料作為附加輸入，進一步改善我們的模型，相較於基本的 ST-ED-RMGC 預測模型，在惡劣天氣條件下將預測誤差降低超過 20%。

##### **Global MMLU: Understanding and Addressing Cultural and Linguistic Biases in Multilingual Evaluation**
2412.03304v1 by Shivalika Singh, Angelika Romanou, Clémentine Fourrier, David I. Adelani, Jian Gang Ngui, Daniel Vila-Suero, Peerat Limkonchotiwat, Kelly Marchisio, Wei Qi Leong, Yosephine Susanto, Raymond Ng, Shayne Longpre, Wei-Yin Ko, Madeline Smith, Antoine Bosselut, Alice Oh, Andre F. T. Martins, Leshem Choshen, Daphne Ippolito, Enzo Ferrante, Marzieh Fadaee, Beyza Ermis, Sara Hooker

Cultural biases in multilingual datasets pose significant challenges for
their effectiveness as global benchmarks. These biases stem not only from
language but also from the cultural knowledge required to interpret questions,
reducing the practical utility of translated datasets like MMLU. Furthermore,
translation often introduces artifacts that can distort the meaning or clarity
of questions in the target language. A common practice in multilingual
evaluation is to rely on machine-translated evaluation sets, but simply
translating a dataset is insufficient to address these challenges. In this
work, we trace the impact of both of these issues on multilingual evaluations
and ensuing model performances. Our large-scale evaluation of state-of-the-art
open and proprietary models illustrates that progress on MMLU depends heavily
on learning Western-centric concepts, with 28% of all questions requiring
culturally sensitive knowledge. Moreover, for questions requiring geographic
knowledge, an astounding 84.9% focus on either North American or European
regions. Rankings of model evaluations change depending on whether they are
evaluated on the full portion or the subset of questions annotated as
culturally sensitive, showing the distortion to model rankings when blindly
relying on translated MMLU. We release Global-MMLU, an improved MMLU with
evaluation coverage across 42 languages -- with improved overall quality by
engaging with compensated professional and community annotators to verify
translation quality while also rigorously evaluating cultural biases present in
the original dataset. This comprehensive Global-MMLU set also includes
designated subsets labeled as culturally sensitive and culturally agnostic to
allow for more holistic, complete evaluation.

摘要：多語系資料集中的文化偏見對其作為全球基準的有效性構成重大挑戰。這些偏見不僅源自語言，也源自詮釋問題所需的文化知識，降低了 MMLU 等翻譯資料集的實際效用。此外，翻譯通常會引入人工製品，可能扭曲目標語言中問題的意義或清晰度。多語系評估中的一種常見做法是依賴機器翻譯的評估集，但僅翻譯資料集不足以應對這些挑戰。在這項工作中，我們追蹤了這兩個問題對多語系評估和後續模型效能的影響。我們對最先進的開放和專有模型進行大規模評估，說明 MMLU 的進展在很大程度上取決於學習以西方為中心的觀念，其中 28% 的問題需要文化敏感的知識。此外，對於需要地理知識的問題，驚人的 84.9% 專注於北美或歐洲地區。模型評估的排名會根據它們是在全部部分還是標註為文化敏感的子集問題上進行評估而改變，顯示出在盲目依賴翻譯的 MMLU 時對模型排名的扭曲。我們發布了 Global-MMLU，這是一個改進的 MMLU，其評估涵蓋 42 種語言——透過與獲得報酬的專業和社群註解員合作，驗證翻譯品質，同時嚴格評估原始資料集中存在的文化偏見，從而提高整體品質。這個全面的 Global-MMLU 集還包括標示為文化敏感和文化不可知論的指定子集，以進行更全面、完整的評估。

##### **Integrating Generative AI into Art Therapy: A Technical Showcase**
2412.03287v1 by Yannis Valentin Schmutz, Tetiana Kravchenko, Souhir Ben Souissi, Mascha Kurpicz-Briki

This paper explores the integration of generative AI into the field of art
therapy. Leveraging proven text-to-image models, we introduce a novel technical
design to complement art therapy. The resulting AI-based tools shall enable
patients to refine and customize their creative work, opening up new avenues of
expression and accessibility. Using three illustrative examples, we demonstrate
potential outputs of our solution and evaluate them qualitatively. Furthermore,
we discuss the current limitations and ethical considerations associated with
this integration and provide an outlook into future research efforts. Our
implementations are publicly available at https://github.com/BFH-AMI/sds24.

摘要：本論文探討生成式 AI 與藝術治療領域的整合。利用經過驗證的文字轉圖像模型，我們引進了一種新穎的技術設計，作為藝術治療的補充。所產生的基於 AI 的工具將能讓患者精進並客製化他們的創作，開啟表達和取得管道的新途徑。我們使用三個說明性範例，展示我們解決方案的潛在產出，並對其進行定性評估。此外，我們討論與此整合相關的現有限制和倫理考量，並提供未來研究工作的展望。我們的實作已公開於 https://github.com/BFH-AMI/sds24。

##### **Black-Box Forgery Attacks on Semantic Watermarks for Diffusion Models**
2412.03283v1 by Andreas Müller, Denis Lukovnikov, Jonas Thietke, Asja Fischer, Erwin Quiring

Integrating watermarking into the generation process of latent diffusion
models (LDMs) simplifies detection and attribution of generated content.
Semantic watermarks, such as Tree-Rings and Gaussian Shading, represent a novel
class of watermarking techniques that are easy to implement and highly robust
against various perturbations. However, our work demonstrates a fundamental
security vulnerability of semantic watermarks. We show that attackers can
leverage unrelated models, even with different latent spaces and architectures
(UNet vs DiT), to perform powerful and realistic forgery attacks. Specifically,
we design two watermark forgery attacks. The first imprints a targeted
watermark into real images by manipulating the latent representation of an
arbitrary image in an unrelated LDM to get closer to the latent representation
of a watermarked image. We also show that this technique can be used for
watermark removal. The second attack generates new images with the target
watermark by inverting a watermarked image and re-generating it with an
arbitrary prompt. Both attacks just need a single reference image with the
target watermark. Overall, our findings question the applicability of semantic
watermarks by revealing that attackers can easily forge or remove these
watermarks under realistic conditions.

摘要：將浮水印整合到潛在擴散模型 (LDM) 的生成過程中，簡化了生成內容的偵測和歸因。語義浮水印，例如樹狀環和高斯陰影，代表了一種新穎的浮水印技術，易於實作且對各種擾動具有高度的穩健性。然而，我們的研究展示了語義浮水印的基本安全性漏洞。我們展示攻擊者可以利用不相關的模型，即使它們具有不同的潛在空間和架構 (UNet 與 DiT)，來執行強大且逼真的偽造攻擊。具體來說，我們設計了兩種浮水印偽造攻擊。第一個通過在不相關的 LDM 中操縱任意影像的潛在表示，將目標浮水印印記到真實影像中，以更接近水印影像的潛在表示。我們也展示了此技術可被用於浮水印移除。第二個攻擊透過反轉水印影像並使用任意提示重新生成它，來生成具有目標浮水印的新影像。兩種攻擊都只需要一個具有目標浮水印的參考影像。總的來說，我們的發現質疑了語義浮水印的適用性，揭示了攻擊者可以在現實條件下輕鬆偽造或移除這些浮水印。

##### **AntLM: Bridging Causal and Masked Language Models**
2412.03275v1 by Xinru Yu, Bin Guo, Shiwei Luo, Jie Wang, Tao Ji, Yuanbin Wu

Causal Language Modeling (CLM) and Masked Language Modeling (MLM) are two
mainstream learning paradigms based on Transformer networks, specifically the
Decoder-only and Encoder-only architectures. The strengths of each paradigm in
downstream tasks have shown a mix of advantages and disadvantages. In the past
BabyLM Challenge 2023, although the MLM paradigm achieved the best average
performance, the CLM paradigm demonstrated significantly faster convergence
rates. For the BabyLM Challenge 2024, we propose a novel language modeling
paradigm named $\textbf{AntLM}$, which integrates both CLM and MLM to leverage
the advantages of these two classic paradigms. We chose the strict-small track
and conducted experiments on two foundation models: BabyLlama, representing
CLM, and LTG-BERT, representing MLM. During the training process for specific
foundation models, we alternate between applying CLM or MLM training objectives
and causal or bidirectional attention masks. Experimental results show that
combining the two pretraining objectives leverages their strengths, enhancing
overall training performance. Under the same epochs, $AntLM_{BabyLlama}$
improves Macro-average by 1%, and $AntLM_{LTG-BERT}$ achieves a 2.2% increase
over the baselines.

摘要：因果语言模型 (CLM) 和遮蔽语言模型 (MLM) 是基于 Transformer 网络的两种主流学习范例，特别是仅解码器和仅编码器架构。每种范例在下游任务中的优势都表现出优势和劣势的结合。在过去的 BabyLM Challenge 2023 中，尽管 MLM 范例取得了最佳的平均性能，但 CLM 范例却表现出明显更快的收敛速度。对于 BabyLM Challenge 2024，我们提出了一种名为 $\textbf{AntLM}$ 的新语言建模范例，它整合了 CLM 和 MLM 以利用这两种经典范例的优势。我们选择了严格的小型轨道，并在两个基础模型上进行了实验：代表 CLM 的 BabyLlama 和代表 MLM 的 LTG-BERT。在特定基础模型的训练过程中，我们在应用 CLM 或 MLM 训练目标和因果或双向注意力掩码之间交替进行。实验结果表明，结合这两个预训练目标可以利用它们的优势，从而增强整体训练性能。在相同的 epoch 下，$AntLM_{BabyLlama}$ 将宏平均提高了 1%，而 $AntLM_{LTG-BERT}$ 比基线提高了 2.2%。

##### **Intent-driven In-context Learning for Few-shot Dialogue State Tracking**
2412.03270v1 by Zihao Yi, Zhe Xu, Ying Shen

Dialogue state tracking (DST) plays an essential role in task-oriented
dialogue systems. However, user's input may contain implicit information,
posing significant challenges for DST tasks. Additionally, DST data includes
complex information, which not only contains a large amount of noise unrelated
to the current turn, but also makes constructing DST datasets expensive. To
address these challenges, we introduce Intent-driven In-context Learning for
Few-shot DST (IDIC-DST). By extracting user's intent, we propose an
Intent-driven Dialogue Information Augmentation module to augment the dialogue
information, which can track dialogue states more effectively. Moreover, we
mask noisy information from DST data and rewrite user's input in the
Intent-driven Examples Retrieval module, where we retrieve similar examples. We
then utilize a pre-trained large language model to update the dialogue state
using the augmented dialogue information and examples. Experimental results
demonstrate that IDIC-DST achieves state-of-the-art performance in few-shot
settings on MultiWOZ 2.1 and MultiWOZ 2.4 datasets.

摘要：對話狀態追蹤 (DST) 在任務導向對話系統中扮演著重要的角色。然而，使用者的輸入可能包含隱含資訊，對 DST 任務造成重大的挑戰。此外，DST 資料包含複雜的資訊，不僅包含大量與目前輪次無關的雜訊，也讓建構 DST 資料集變得昂貴。為了應對這些挑戰，我們引入了意圖驅動的脈絡中學習，用於少量 DST (IDIC-DST)。透過提取使用者的意圖，我們提出了一個意圖驅動的對話資訊擴充模組來擴充對話資訊，可以更有效地追蹤對話狀態。此外，我們遮蔽 DST 資料中的雜訊資訊，並在意圖驅動的範例擷取模組中改寫使用者的輸入，在其中我們擷取類似的範例。接著，我們利用預先訓練的大語言模型，使用擴充的對話資訊和範例來更新對話狀態。實驗結果顯示，IDIC-DST 在 MultiWOZ 2.1 和 MultiWOZ 2.4 資料集上的少量設定中，達到了最先進的效能。

##### **Alignment at Pre-training! Towards Native Alignment for Arabic LLMs**
2412.03253v1 by Juhao Liang, Zhenyang Cai, Jianqing Zhu, Huang Huang, Kewei Zong, Bang An, Mosen Alharthi, Juncai He, Lian Zhang, Haizhou Li, Benyou Wang, Jinchao Xu

The alignment of large language models (LLMs) is critical for developing
effective and safe language models. Traditional approaches focus on aligning
models during the instruction tuning or reinforcement learning stages, referred
to in this paper as `post alignment'. We argue that alignment during the
pre-training phase, which we term `native alignment', warrants investigation.
Native alignment aims to prevent unaligned content from the beginning, rather
than relying on post-hoc processing. This approach leverages extensively
aligned pre-training data to enhance the effectiveness and usability of
pre-trained models. Our study specifically explores the application of native
alignment in the context of Arabic LLMs. We conduct comprehensive experiments
and ablation studies to evaluate the impact of native alignment on model
performance and alignment stability. Additionally, we release open-source
Arabic LLMs that demonstrate state-of-the-art performance on various
benchmarks, providing significant benefits to the Arabic LLM community.

摘要：大型語言模型（LLM）的對齊對於開發有效且安全的語言模型至關重要。傳統方法著重於在指令微調或強化學習階段對齊模型，本文稱之為「後對齊」。我們認為，在預訓練階段進行對齊（我們稱之為「原生對齊」）值得探討。原生對齊旨在從一開始就防止未對齊的內容，而不是依賴事後處理。這種方法充分利用經過大量對齊的預訓練資料，以增強預訓練模型的有效性和可用性。我們的研究特別探討了原生對齊在阿拉伯語 LLM 中的應用。我們進行了全面的實驗和消融研究，以評估原生對齊對模型效能和對齊穩定性的影響。此外，我們發布了開放原始碼的阿拉伯語 LLM，這些 LLM 在各種基準測試中表現出最先進的效能，為阿拉伯語 LLM 社群帶來顯著的好處。

##### **AIM: Adaptive Inference of Multi-Modal LLMs via Token Merging and Pruning**
2412.03248v1 by Yiwu Zhong, Zhuoming Liu, Yin Li, Liwei Wang

Large language models (LLMs) have enabled the creation of multi-modal LLMs
that exhibit strong comprehension of visual data such as images and videos.
However, these models usually rely on extensive visual tokens from visual
encoders, leading to high computational demands, which limits their
applicability in resource-constrained environments and for long-context tasks.
In this work, we propose a training-free adaptive inference method for
multi-modal LLMs that can accommodate a broad range of efficiency requirements
with a minimum performance drop. Our method consists of a) iterative token
merging based on embedding similarity before LLMs, and b) progressive token
pruning within LLM layers based on multi-modal importance. With a minimalist
design, our method can be applied to both video and image LLMs. Extensive
experiments on diverse video and image benchmarks demonstrate that, our method
substantially reduces computation load (e.g., a $\textbf{7-fold}$ reduction in
FLOPs) while preserving the performance of video and image LLMs. Further, under
a similar computational cost, our method outperforms the state-of-the-art
methods in long video understanding (e.g., $\textbf{+4.6}$ on MLVU).
Additionally, our in-depth analysis provides insights into token redundancy and
LLM layer behaviors, offering guidance for future research in designing
efficient multi-modal LLMs. Our code will be available at
https://github.com/LaVi-Lab/AIM.

摘要：<paragraph>大型語言模型 (LLM) 已能建立多模態 LLM，能對視覺資料（例如影像和影片）展現強大的理解力。
然而，這些模型通常仰賴視覺編碼器的廣泛視覺符號，導致高運算需求，限制其在資源受限環境和長脈絡任務中的應用。
在這項工作中，我們為多模態 LLM 提出一個免訓練的自適應推論方法，能以最小的效能下降來適應廣泛的效率需求。我們的做法包括 a) 在 LLM 之前根據嵌入相似性進行反覆符號合併，以及 b) 根據多模態重要性在 LLM 層中進行漸進符號修剪。我們的做法採用極簡設計，可應用於影片和影像 LLM。在各種影片和影像基準上的廣泛實驗證明，我們的做法大幅降低運算負載（例如，FLOP 減少了 $\textbf{7 倍}$），同時保留影片和影像 LLM 的效能。此外，在類似的運算成本下，我們的做法在長影片理解方面優於現有技術（例如，在 MLVU 上 $\textbf{+4.6}$）。
此外，我們的深入分析提供了符號冗餘和 LLM 層行為的見解，為未來設計高效多模態 LLM 的研究提供指導。我們的程式碼將於 https://github.com/LaVi-Lab/AIM 上提供。</paragraph>

##### **Benchmarking terminology building capabilities of ChatGPT on an English-Russian Fashion Corpus**
2412.03242v1 by Anastasiia Bezobrazova, Miriam Seghiri, Constantin Orasan

This paper compares the accuracy of the terms extracted using SketchEngine,
TBXTools and ChatGPT. In addition, it evaluates the quality of the definitions
produced by ChatGPT for these terms. The research is carried out on a
comparable corpus of fashion magazines written in English and Russian collected
from the web. A gold standard for the fashion terminology was also developed by
identifying web pages that can be harvested automatically and contain
definitions of terms from the fashion domain in English and Russian. This gold
standard was used to evaluate the quality of the extracted terms and of the
definitions produced. Our evaluation shows that TBXTools and SketchEngine,
while capable of high recall, suffer from reduced precision as the number of
terms increases, which affects their overall performance. Conversely, ChatGPT
demonstrates superior performance, maintaining or improving precision as more
terms are considered. Analysis of the definitions produced by ChatGPT for 60
commonly used terms in English and Russian shows that ChatGPT maintains a
reasonable level of accuracy and fidelity across languages, but sometimes the
definitions in both languages miss crucial specifics and include unnecessary
deviations. Our research reveals that no single tool excels universally; each
has strengths suited to particular aspects of terminology extraction and
application.

摘要：本文比較了使用 SketchEngine、TBXTools 和 ChatGPT 提取術語的準確性。此外，它還評估了 ChatGPT 為這些術語產生的定義的品質。研究是在從網路收集的以英語和俄語寫成的時尚雜誌的同類語料庫上進行的。還通過識別可以自動擷取並包含英語和俄語時尚領域術語定義的網頁，制定了時尚術語的黃金標準。這個黃金標準用於評估提取的術語和產生的定義的品質。我們的評估顯示，TBXTools 和 SketchEngine 雖然具有很高的召回率，但隨著術語數量的增加，它們的準確度會降低，這會影響它們的整體效能。相反，ChatGPT 表現出優異的效能，在考慮更多術語時，它能維持或提高準確度。對 ChatGPT 為英語和俄語中 60 個常用術語產生的定義進行分析，結果顯示 ChatGPT 在不同語言之間維持合理的準確度和保真度，但有時兩種語言的定義都會遺漏關鍵的具體資訊，並包含不必要的偏差。我們的研究表明，沒有單一的工具能普遍勝出；每個工具都有適合術語提取和應用特定方面的優勢。

##### **Does Safety Training of LLMs Generalize to Semantically Related Natural Prompts?**
2412.03235v1 by Sravanti Addepalli, Yerram Varun, Arun Suggala, Karthikeyan Shanmugam, Prateek Jain

Large Language Models (LLMs) are known to be susceptible to crafted
adversarial attacks or jailbreaks that lead to the generation of objectionable
content despite being aligned to human preferences using safety fine-tuning
methods. While the large dimensionality of input token space makes it
inevitable to find adversarial prompts that can jailbreak these models, we aim
to evaluate whether safety fine-tuned LLMs are safe against natural prompts
which are semantically related to toxic seed prompts that elicit safe responses
after alignment. We surprisingly find that popular aligned LLMs such as GPT-4
can be compromised using naive prompts that are NOT even crafted with an
objective of jailbreaking the model. Furthermore, we empirically show that
given a seed prompt that elicits a toxic response from an unaligned model, one
can systematically generate several semantically related natural prompts that
can jailbreak aligned LLMs. Towards this, we propose a method of Response
Guided Question Augmentation (ReG-QA) to evaluate the generalization of safety
aligned LLMs to natural prompts, that first generates several toxic answers
given a seed question using an unaligned LLM (Q to A), and further leverages an
LLM to generate questions that are likely to produce these answers (A to Q). We
interestingly find that safety fine-tuned LLMs such as GPT-4o are vulnerable to
producing natural jailbreak questions from unsafe content (without denial) and
can thus be used for the latter (A to Q) step. We obtain attack success rates
that are comparable to/ better than leading adversarial attack methods on the
JailbreakBench leaderboard, while being significantly more stable against
defenses such as Smooth-LLM and Synonym Substitution, which are effective
against existing all attacks on the leaderboard.

摘要：大型语言模型 (LLM) 已知容易受到精心设计的对抗性攻击或越狱攻击，尽管使用安全微调方法与人类偏好保持一致，但这些攻击或越狱攻击会导致生成令人反感的内容。虽然输入标记空间的大维度使得找到可以越狱这些模型的对抗性提示不可避免，但我们的目标是评估经过安全微调的 LLM 是否可以防止与语义相关的自然提示，这些提示与引发对齐后安全响应的有毒种子提示相关。我们惊讶地发现，诸如 GPT-4 等流行的对齐 LLM 可以使用天真的提示来破坏，甚至这些提示并不是为了越狱模型而设计的。此外，我们凭经验表明，给定一个从未对齐的模型引发出有毒反应的种子提示，人们可以系统地生成几个语义相关的自然提示，这些提示可以越狱对齐的 LLM。为此，我们提出了一种响应引导问题增强 (ReG-QA) 方法来评估安全对齐的 LLM 对自然提示的泛化，该方法首先使用未对齐的 LLM (Q 到 A) 给定一个种子问题生成几个有毒答案，并进一步利用 LLM 生成可能产生这些答案的问题 (A 到 Q)。我们有趣地发现，诸如 GPT-4o 等经过安全微调的 LLM 容易从不安全内容（没有否认）中产生自然的越狱问题，因此可以用于后者（A 到 Q）步骤。我们获得的攻击成功率与 JailbreakBench 排行榜上的领先对抗性攻击方法相当/更好，同时对平滑 LLM 和同义词替换等防御措施的稳定性明显更高，而这些防御措施对排行榜上的所有现有攻击都是有效的。

##### **PERL: Pinyin Enhanced Rephrasing Language Model for Chinese ASR N-best Error Correction**
2412.03230v1 by Junhong Liang

ASR correction methods have predominantly focused on general datasets and
have not effectively utilized Pinyin information, unique to the Chinese
language. In this study, we address this gap by proposing a Pinyin Enhanced
Rephrasing Language Model (PERL), specifically designed for N-best correction
scenarios. Additionally, we implement a length predictor module to address the
variable-length problem. We conduct experiments on the Aishell-1 dataset and
our newly proposed DoAD dataset. The results show that our approach outperforms
baseline methods, achieving a 29.11% reduction in Character Error Rate (CER) on
Aishell-1 and around 70% CER reduction on domain-specific datasets.
Furthermore, our approach leverages Pinyin similarity at the token level,
providing an advantage over baselines and leading to superior performance.

摘要：語音辨識校正方法主要集中在一般資料集，且尚未有效利用中文特有的注音符號資訊。在本研究中，我們透過提出專門設計用於 N-best 校正情境的注音符號增強改述語言模型 (PERL) 來解決此差距。此外，我們實作長度預測模組來解決長度變異的問題。我們在 Aishell-1 資料集和我們新提出的 DoAD 資料集上進行實驗。結果顯示，我們的做法優於基線方法，在 Aishell-1 上將字元錯誤率 (CER) 降低了 29.11%，在特定領域的資料集上將 CER 降低了約 70%。此外，我們的做法在符號層級中利用注音符號相似性，相較於基線方法具有優勢，並帶來更優異的效能。

##### **Linq-Embed-Mistral Technical Report**
2412.03223v1 by Chanyeol Choi, Junseong Kim, Seolhwa Lee, Jihoon Kwon, Sangmo Gu, Yejin Kim, Minkyung Cho, Jy-yong Sohn

This report explores the enhancement of text retrieval performance using
advanced data refinement techniques. We develop
Linq-Embed-Mistral\footnote{\url{https://huggingface.co/Linq-AI-Research/Linq-Embed-Mistral}}
by building on the E5-mistral and Mistral-7B-v0.1 models, focusing on
sophisticated data crafting, data filtering, and negative mining methods, which
are highly tailored to each task, applied to both existing benchmark dataset
and highly tailored synthetic dataset generated via large language models
(LLMs). Linq-Embed-Mistral excels in the MTEB benchmarks (as of May 29, 2024),
achieving an average score of 68.2 across 56 datasets, and ranks 1st among all
models for retrieval tasks on the MTEB leaderboard with a performance score of
60.2. This performance underscores its superior capability in enhancing search
precision and reliability. Our contributions include advanced data refinement
methods that significantly improve model performance on benchmark and synthetic
datasets, techniques for homogeneous task ordering and mixed task fine-tuning
to enhance model generalization and stability, and a streamlined evaluation
process using 4-bit precision and a light retrieval evaluation set, which
accelerates validation without sacrificing accuracy.

摘要：本報告探討使用進階資料精煉技術來提升文字檢索效能。我們在 E5-mistral 和 Mistral-7B-v0.1 模型的基礎上開發 Linq-Embed-Mistral\footnote{\url{https://huggingface.co/Linq-AI-Research/Linq-Embed-Mistral}}，專注於精密的資料製作、資料篩選和負面挖掘方法，這些方法針對每個任務量身打造，應用於現有的基準資料集和透過大型語言模型 (LLM) 生成的量身打造合成資料集。截至 2024 年 5 月 29 日，Linq-Embed-Mistral 在 MTEB 基準中表現出色，在 56 個資料集中取得平均 68.2 分，在 MTEB 排行榜上，檢索任務的所有模型中排名第 1，效能分數為 60.2。此效能突顯其在提升搜尋精準度和可靠度方面的優異能力。我們的貢獻包括進階資料精煉方法，可大幅提升基準和合成資料集上的模型效能、同質任務排序和混合任務微調技術，以提升模型概化和穩定性，以及使用 4 位元精準度和輕量檢索評估集的簡化評估流程，這能在不犧牲精準度的情況下加速驗證。

##### **ClusterKV: Manipulating LLM KV Cache in Semantic Space for Recallable Compression**
2412.03213v1 by Guangda Liu, Chengwei Li, Jieru Zhao, Chenqi Zhang, Minyi Guo

Large Language Models (LLMs) have been widely deployed in a variety of
applications, and the context length is rapidly increasing to handle tasks such
as long-document QA and complex logical reasoning. However, long context poses
significant challenges for inference efficiency, including high memory costs of
key-value (KV) cache and increased latency due to extensive memory accesses.
Recent works have proposed compressing KV cache to approximate computation, but
these methods either evict tokens permanently, never recalling them for later
inference, or recall previous tokens at the granularity of pages divided by
textual positions. Both approaches degrade the model accuracy and output
quality. To achieve efficient and accurate recallable KV cache compression, we
introduce ClusterKV, which recalls tokens at the granularity of semantic
clusters. We design and implement efficient algorithms and systems for
clustering, selection, indexing and caching. Experiment results show that
ClusterKV attains negligible accuracy loss across various tasks with 32k
context lengths, using only a 1k to 2k KV cache budget, and achieves up to a
2$\times$ speedup in latency and a 2.5$\times$ improvement in decoding
throughput. Compared to SoTA recallable KV compression methods, ClusterKV
demonstrates higher model accuracy and output quality, while maintaining or
exceeding inference efficiency.

摘要：大型語言模型 (LLM) 已廣泛部署於各種應用程式中，且背景長度迅速增加，以處理長文件問答和複雜邏輯推理等任務。然而，長背景對推論效率構成重大挑戰，包括鍵值 (KV) 快取的高記憶體成本，以及由於大量記憶體存取而增加的延遲。最近的研究已提出壓縮 KV 快取以近似計算，但這些方法會永久驅逐權杖，永遠不會在後續推論中提取它們，或在由文字位置劃分的頁面粒度中提取先前的權杖。這兩種方法都會降低模型準確度和輸出品質。為了達成有效且準確的可提取 KV 快取壓縮，我們引入了 ClusterKV，它在語義叢集的粒度中提取權杖。我們設計並實作了用於叢集、選擇、索引和快取的有效演算法和系統。實驗結果顯示，ClusterKV 在各種任務中獲得極小的準確度損失，背景長度為 32k，僅使用 1k 到 2k 的 KV 快取預算，並在延遲中實現了高達 2 倍的加速，以及在解碼處理量中實現了 2.5 倍的提升。與 SoTA 可提取 KV 壓縮方法相比，ClusterKV 展示了更高的模型準確度和輸出品質，同時維持或超越推論效率。

##### **U-MATH: A University-Level Benchmark for Evaluating Mathematical Skills in LLMs**
2412.03205v1 by Konstantin Chernyshev, Vitaliy Polshkov, Ekaterina Artemova, Alex Myasnikov, Vlad Stepanov, Alexei Miasnikov, Sergei Tilga

The current evaluation of mathematical skills in LLMs is limited, as existing
benchmarks are either relatively small, primarily focus on elementary and
high-school problems, or lack diversity in topics. Additionally, the inclusion
of visual elements in tasks remains largely under-explored.
  To address these gaps, we introduce U-MATH, a novel benchmark of 1,100
unpublished open-ended university-level problems sourced from teaching
materials. It is balanced across six core subjects, with 20% of multimodal
problems. Given the open-ended nature of U-MATH problems, we employ an LLM to
judge the correctness of generated solutions. To this end, we release
$\mu$-MATH, a dataset to evaluate the LLMs' capabilities in judging solutions.
  The evaluation of general domain, math-specific, and multimodal LLMs
highlights the challenges presented by U-MATH. Our findings reveal that LLMs
achieve a maximum accuracy of only 63% on text-based tasks, with even lower 45%
on visual problems. The solution assessment proves challenging for LLMs, with
the best LLM judge having an F1-score of 80% on $\mu$-MATH.

摘要：現有評估 LLM 數學技能的標準有限，因為現有基準要不規模較小、主要著重於小學和高中問題，要不缺乏主題多元性。此外，任務中包含視覺元素的部分仍未得到充分探討。
為了解決這些差距，我們引入了 U-MATH，這是一個由教學材料中蒐集的 1,100 個未發表的開放式大學程度問題的新基準。它涵蓋六個核心科目，20% 為多模態問題。鑑於 U-MATH 問題的開放式性質，我們採用 LLM 來判斷所產生解法的正確性。為此，我們發布了 $\mu$-MATH，一個用於評估 LLM 判斷解題能力的資料集。
對一般領域、特定數學和多模態 LLM 的評估突顯了 U-MATH 所帶來的挑戰。我們的研究結果顯示，LLM 在基於文字的任務上僅達到 63% 的最高準確度，在視覺問題上甚至更低，只有 45%。解題評估對 LLM 來說具有挑戰性，最佳 LLM 評審在 $\mu$-MATH 上的 F1 分數為 80%。

##### **Semi-decentralized Training of Spatio-Temporal Graph Neural Networks for Traffic Prediction**
2412.03188v1 by Ivan Kralj, Lodovico Giaretta, Gordan Ježić, Ivana Podnar Žarko, Šarūnas Girdzijauskas

In smart mobility, large networks of geographically distributed sensors
produce vast amounts of high-frequency spatio-temporal data that must be
processed in real time to avoid major disruptions. Traditional centralized
approaches are increasingly unsuitable to this task, as they struggle to scale
with expanding sensor networks, and reliability issues in central components
can easily affect the whole deployment. To address these challenges, we explore
and adapt semi-decentralized training techniques for Spatio-Temporal Graph
Neural Networks (ST-GNNs) in smart mobility domain. We implement a simulation
framework where sensors are grouped by proximity into multiple cloudlets, each
handling a subgraph of the traffic graph, fetching node features from other
cloudlets to train its own local ST-GNN model, and exchanging model updates
with other cloudlets to ensure consistency, enhancing scalability and removing
reliance on a centralized aggregator. We perform extensive comparative
evaluation of four different ST-GNN training setups -- centralized, traditional
FL, server-free FL, and Gossip Learning -- on large-scale traffic datasets, the
METR-LA and PeMS-BAY datasets, for short-, mid-, and long-term vehicle speed
predictions. Experimental results show that semi-decentralized setups are
comparable to centralized approaches in performance metrics, while offering
advantages in terms of scalability and fault tolerance. In addition, we
highlight often overlooked issues in existing literature for distributed
ST-GNNs, such as the variation in model performance across different
geographical areas due to region-specific traffic patterns, and the significant
communication overhead and computational costs that arise from the large
receptive field of GNNs, leading to substantial data transfers and increased
computation of partial embeddings.

摘要：<paragraph>在智慧行動領域中，由地理分散感測器組成的龐大網路會產生大量的時空高頻率資料，這些資料必須即時處理，才能避免重大中斷。傳統的集中式方法愈來愈不適合這項任務，因為它們在擴展感測器網路時難以擴充，而中央組件的可靠性問題也可能輕易影響整個部署。為了應對這些挑戰，我們探索並調整了智慧行動領域中時空圖形神經網路 (ST-GNN) 的半分散式訓練技術。我們實作了一個模擬架構，其中感測器會依據接近性分組到多個雲端中，每個雲端處理交通圖形的一個子圖，從其他雲端擷取節點特徵來訓練其自己的局部 ST-GNN 模型，並與其他雲端交換模型更新以確保一致性，進而提升擴充性並消除對集中式彙總器的依賴。我們對四種不同的 ST-GNN 訓練設定進行廣泛的比較評估，包括集中式、傳統 FL、無伺服器 FL 和八卦學習，這些評估是在大規模交通資料集（METR-LA 和 PeMS-BAY 資料集）上進行，用於短期、中期和長期車輛速度預測。實驗結果顯示，半分散式設定在效能指標上可與集中式方法相提並論，同時在擴充性和容錯性方面具有優勢。此外，我們強調了現有分散式 ST-GNN 文獻中經常被忽略的問題，例如由於區域特定交通模式而導致不同地理區域的模型效能差異，以及由於 GNN 的大感受野而產生的顯著通訊開銷和運算成本，導致大量資料傳輸和局部嵌入運算增加。</paragraph>

##### **Weighted-Reward Preference Optimization for Implicit Model Fusion**
2412.03187v1 by Ziyi Yang, Fanqi Wan, Longguang Zhong, Tianyuan Shi, Xiaojun Quan

While fusing heterogeneous open-source LLMs with varying architectures and
sizes can potentially integrate the strengths of different models, existing
fusion methods face significant challenges, such as vocabulary alignment and
merging distribution matrices. These procedures are not only complex but also
prone to introducing noise and errors. In this paper, we propose an implicit
fusion method, Weighted-Reward Preference Optimization (WRPO), which leverages
preference optimization between the source LLMs and the target LLM to transfer
their capabilities effectively. WRPO eliminates the need for vocabulary
alignment and matrix fusion and can be efficiently scaled to accommodate
various LLMs. To address distributional deviations between the source and
target LLMs, WRPO introduces a progressive adaptation strategy that gradually
shifts reliance on preferred examples from the target LLM to the source LLMs.
Extensive experiments on the MT-Bench, AlpacaEval-2, and Arena-Hard benchmarks
demonstrate that WRPO consistently outperforms existing knowledge fusion
methods and various fine-tuning baselines. When applied to LLaMA3-8B-Instruct
as the target model, WRPO achieves a length-controlled win rate of 55.9%
against GPT-4-Preview-1106 on AlpacaEval-2 and a win rate of 46.2% against
GPT-4-0314 on Arena-Hard. Our code is available at
\url{https://github.com/SLIT-AI/WRPO}.

摘要：<paragraph>雖然融合異質開放原始碼 LLM，其架構和規模各異，有整合不同模型優勢的潛力，現有的融合方法卻面臨諸多挑戰，例如詞彙比對和合併分佈矩陣。這些程序不僅複雜，還容易引入雜訊和錯誤。在本文中，我們提出了一種隱式融合方法，即加權獎勵偏好最佳化 (WRPO)，它利用原始 LLM 和目標 LLM 之間的偏好最佳化來有效轉移它們的能力。WRPO 消除了詞彙比對和矩陣融合的需要，並且可以有效擴展以容納各種 LLM。為了解決原始和目標 LLM 之間的分配偏差，WRPO 引入了一種漸進適應策略，逐漸將對目標 LLM 的偏好範例的依賴轉移到原始 LLM。在 MT-Bench、AlpacaEval-2 和 Arena-Hard 基準上的廣泛實驗表明，WRPO 持續優於現有的知識融合方法和各種微調基準。當應用於 LLaMA3-8B-Instruct 作為目標模型時，WRPO 在 AlpacaEval-2 上對 GPT-4-Preview-1106 達到了 55.9% 的長度控制獲勝率，在 Arena-Hard 上對 GPT-4-0314 達到了 46.2% 的獲勝率。我們的程式碼可在以下網址取得：\url{https://github.com/SLIT-AI/WRPO}。</paragraph>

##### **Optimizing Dense Visual Predictions Through Multi-Task Coherence and Prioritization**
2412.03179v1 by Maxime Fontana, Michael Spratling, Miaojing Shi

Multi-Task Learning (MTL) involves the concurrent training of multiple tasks,
offering notable advantages for dense prediction tasks in computer vision. MTL
not only reduces training and inference time as opposed to having multiple
single-task models, but also enhances task accuracy through the interaction of
multiple tasks. However, existing methods face limitations. They often rely on
suboptimal cross-task interactions, resulting in task-specific predictions with
poor geometric and predictive coherence. In addition, many approaches use
inadequate loss weighting strategies, which do not address the inherent
variability in task evolution during training. To overcome these challenges, we
propose an advanced MTL model specifically designed for dense vision tasks. Our
model leverages state-of-the-art vision transformers with task-specific
decoders. To enhance cross-task coherence, we introduce a trace-back method
that improves both cross-task geometric and predictive features. Furthermore,
we present a novel dynamic task balancing approach that projects task losses
onto a common scale and prioritizes more challenging tasks during training.
Extensive experiments demonstrate the superiority of our method, establishing
new state-of-the-art performance across two benchmark datasets. The code is
available at:https://github.com/Klodivio355/MT-CP

摘要：多任務學習 (MTL) 涉及多個任務的並發訓練，為電腦視覺中的密集預測任務提供了顯著優勢。MTL 不僅減少了訓練和推理時間，與擁有多個單任務模型相比，還通過多個任務的交互增強了任務準確性。然而，現有方法面臨限制。它們通常依賴於次優的跨任務交互，導致任務特定的預測具有較差的幾何和預測一致性。此外，許多方法使用不充分的損失加權策略，這無法解決訓練過程中任務演化的固有變異性。為了克服這些挑戰，我們提出了一個專門為密集視覺任務設計的高級 MTL 模型。我們的模型利用了最先進的視覺變換器和任務特定的解碼器。為了增強跨任務一致性，我們引入了一種追溯方法，它改進了跨任務幾何和預測特徵。此外，我們提出了一種新穎的動態任務平衡方法，它將任務損失投影到一個公共尺度上，並在訓練過程中優先考慮更具挑戰性的任務。廣泛的實驗證明了我們方法的優越性，在兩個基準數據集上建立了新的最先進性能。代碼可在以下位置獲得：https://github.com/Klodivio355/MT-CP

##### **Towards Understanding and Quantifying Uncertainty for Text-to-Image Generation**
2412.03178v1 by Gianni Franchi, Dat Nguyen Trong, Nacim Belkhir, Guoxuan Xia, Andrea Pilzer

Uncertainty quantification in text-to-image (T2I) generative models is
crucial for understanding model behavior and improving output reliability. In
this paper, we are the first to quantify and evaluate the uncertainty of T2I
models with respect to the prompt. Alongside adapting existing approaches
designed to measure uncertainty in the image space, we also introduce
Prompt-based UNCertainty Estimation for T2I models (PUNC), a novel method
leveraging Large Vision-Language Models (LVLMs) to better address uncertainties
arising from the semantics of the prompt and generated images. PUNC utilizes a
LVLM to caption a generated image, and then compares the caption with the
original prompt in the more semantically meaningful text space. PUNC also
enables the disentanglement of both aleatoric and epistemic uncertainties via
precision and recall, which image-space approaches are unable to do. Extensive
experiments demonstrate that PUNC outperforms state-of-the-art uncertainty
estimation techniques across various settings. Uncertainty quantification in
text-to-image generation models can be used on various applications including
bias detection, copyright protection, and OOD detection. We also introduce a
comprehensive dataset of text prompts and generation pairs to foster further
research in uncertainty quantification for generative models. Our findings
illustrate that PUNC not only achieves competitive performance but also enables
novel applications in evaluating and improving the trustworthiness of
text-to-image models.

摘要：在文本到图像 (T2I) 生成模型中量化不确定性对于理解模型行为和提高输出可靠性至关重要。在本文中，我们首次量化和评估了 T2I 模型相对于提示的不确定性。除了调整旨在测量图像空间中不确定性的现有方法外，我们还引入了基于提示的不确定性估计用于 T2I 模型 (PUNC)，这是一种利用大型视觉语言模型 (LVLMs) 来更好地解决源自提示语义和生成图像的不确定性。PUNC 利用 LVLM 为生成的图像添加标题，然后在语义上更有意义的文本空间中将标题与原始提示进行比较。PUNC 还能够通过精度和召回率来解开偶然不确定性和认知不确定性，这是图像空间方法无法做到的。大量的实验表明，PUNC 在各种设置下都优于最先进的不确定性估计技术。文本到图像生成模型中的不确定性量化可用于各种应用，包括偏差检测、版权保护和 OOD 检测。我们还引入了一个包含文本提示和生成对的综合数据集，以促进对生成模型不确定性量化的进一步研究。我们的研究结果表明，PUNC 不仅实现了有竞争力的性能，而且还能够在评估和提高文本到图像模型的可信度方面实现新应用。

##### **Automatic detection of diseases in Spanish clinical notes combining medical language models and ontologies**
2412.03176v1 by Leon-Paul Schaub Torre, Pelayo Quiros, Helena Garcia Mieres

In this paper we present a hybrid method for the automatic detection of
dermatological pathologies in medical reports. We use a large language model
combined with medical ontologies to predict, given a first appointment or
follow-up medical report, the pathology a person may suffer from. The results
show that teaching the model to learn the type, severity and location on the
body of a dermatological pathology, as well as in which order it has to learn
these three features, significantly increases its accuracy. The article
presents the demonstration of state-of-the-art results for classification of
medical texts with a precision of 0.84, micro and macro F1-score of 0.82 and
0.75, and makes both the method and the data set used available to the
community.

摘要：在本文中，我們提出了一種混合方法，用於自動檢測醫療報告中的皮膚病理。我們使用大型語言模型結合醫學本体，預測給定初診或後續醫療報告，一個人可能患有的病理。結果表明，教授模型學習皮膚病理的類型、嚴重程度和身體位置，以及按何種順序學習這三個特徵，可以顯著提高其準確性。本文展示了醫學文本分類的最新結果，精確度為 0.84，微觀和巨觀 F1 分數為 0.82 和 0.75，並將方法和數據集提供給社區。

##### **Physics-Informed Deep Inverse Operator Networks for Solving PDE Inverse Problems**
2412.03161v1 by Sung Woong Cho, Hwijae Son

Inverse problems involving partial differential equations (PDEs) can be seen
as discovering a mapping from measurement data to unknown quantities, often
framed within an operator learning approach. However, existing methods
typically rely on large amounts of labeled training data, which is impractical
for most real-world applications. Moreover, these supervised models may fail to
capture the underlying physical principles accurately. To address these
limitations, we propose a novel architecture called Physics-Informed Deep
Inverse Operator Networks (PI-DIONs), which can learn the solution operator of
PDE-based inverse problems without labeled training data. We extend the
stability estimates established in the inverse problem literature to the
operator learning framework, thereby providing a robust theoretical foundation
for our method. These estimates guarantee that the proposed model, trained on a
finite sample and grid, generalizes effectively across the entire domain and
function space. Extensive experiments are conducted to demonstrate that
PI-DIONs can effectively and accurately learn the solution operators of the
inverse problems without the need for labeled data.

摘要：涉及偏微分方程 (PDE) 的反問題可以視為從測量數據中找出對應未知數的對應關係，通常會在運算子學習方法中建構。不過，現有方法通常仰賴大量標籤訓練資料，這在多數真實世界的應用中並不切實際。此外，這些監督式模型可能無法精準捕捉到底層的物理原理。為了解決這些限制，我們提出了一種稱為物理訊息深度反運算子網路 (PI-DION) 的新架構，它可以在沒有標籤訓練資料的情況下學習基於 PDE 的反問題的解運算子。我們將反問題文獻中已建立的穩定性估計值延伸到運算子學習架構中，進而為我們的模型提供穩健的理論基礎。這些估計值保證了所提出的模型在有限樣本和網格上訓練後，可以在整個網域和函數空間中有效地進行概化。我們進行了大量的實驗，以證明 PI-DION 可以有效且精準地學習反問題的解運算子，而且不需要標籤資料。

##### **Byte BPE Tokenization as an Inverse string Homomorphism**
2412.03160v1 by Saibo Geng, Sankalp Gambhir, Chris Wendler, Robert West

Tokenization is an important preprocessing step in the training and inference
of large language models (LLMs). While there has been extensive research on the
expressive power of the neural achitectures used in LLMs, the impact of
tokenization has not been well understood. In this work, we demonstrate that
tokenization, irrespective of the algorithm used, acts as an inverse
homomorphism between strings and tokens. This suggests that the character space
of the source language and the token space of the tokenized language are
homomorphic, preserving the structural properties of the source language.
Additionally, we explore the concept of proper tokenization, which refers to an
unambiguous tokenization returned from the tokenizer. Our analysis reveals that
the expressiveness of neural architectures in recognizing context-free
languages is not affected by tokenization.

摘要：分詞是訓練和推論大型語言模型 (LLM) 中一個重要的預處理步驟。雖然對於 LLM 中使用的神經架構的表現力已有廣泛的研究，但分詞的影響尚未被充分理解。在這項工作中，我們證明了分詞，無論使用何種演算法，都充當字串和符號之間的反同態。這表明原始語言的字元空間和分詞語言的符號空間是同態的，保留了原始語言的結構特性。此外，我們探討了適當分詞的概念，這指的是從分詞器返回的明確分詞。我們的分析表明，神經架構在識別上下文無關語言中的表現力不受分詞的影響。

##### **Testing Neural Network Verifiers: A Soundness Benchmark with Hidden Counterexamples**
2412.03154v1 by Xingjian Zhou, Hongji Xu, Andy Xu, Zhouxing Shi, Cho-Jui Hsieh, Huan Zhang

In recent years, many neural network (NN) verifiers have been developed to
formally verify certain properties of neural networks such as robustness.
Although many benchmarks have been constructed to evaluate the performance of
NN verifiers, they typically lack a ground-truth for hard instances where no
current verifier can verify and no counterexample can be found, which makes it
difficult to check the soundness of a new verifier if it claims to verify hard
instances which no other verifier can do. We propose to develop a soundness
benchmark for NN verification. Our benchmark contains instances with
deliberately inserted counterexamples while we also try to hide the
counterexamples from regular adversarial attacks which can be used for finding
counterexamples. We design a training method to produce neural networks with
such hidden counterexamples. Our benchmark aims to be used for testing the
soundness of NN verifiers and identifying falsely claimed verifiability when it
is known that hidden counterexamples exist. We systematically construct our
benchmark and generate instances across diverse model architectures, activation
functions, input sizes, and perturbation radii. We demonstrate that our
benchmark successfully identifies bugs in state-of-the-art NN verifiers, as
well as synthetic bugs, providing a crucial step toward enhancing the
reliability of testing NN verifiers. Our code is available at
https://github.com/MVP-Harry/SoundnessBench and our benchmark is available at
https://huggingface.co/datasets/SoundnessBench/SoundnessBench.

摘要：近年来，许多神经网络 (NN) 验证器被开发出来，以正式验证神经网络的某些属性，例如鲁棒性。虽然已经构建了许多基准来评估 NN 验证器的性能，但它们通常缺乏难以验证的实例的基本事实，而当前没有验证器可以验证并且找不到反例，这使得如果声称验证其他验证器无法验证的困难实例，则难以检查新验证器的健全性。我们建议为 NN 验证开发一个健全性基准。我们的基准包含故意插入反例的实例，而我们也尝试将反例隐藏在常规对抗性攻击中，该攻击可用于查找反例。我们设计了一种训练方法来生成具有此类隐藏反例的神经网络。我们的基准旨在用于测试 NN 验证器的健全性，并在已知存在隐藏反例的情况下识别错误声称的可验证性。我们系统地构建基准，并在不同的模型架构、激活函数、输入大小和扰动半径中生成实例。我们证明了我们的基准成功地识别了最先进的 NN 验证器中的错误，以及合成的错误，为提高 NN 验证器测试的可靠性提供了至关重要的一步。我们的代码可在 https://github.com/MVP-Harry/SoundnessBench 获得，我们的基准可在 https://huggingface.co/datasets/SoundnessBench/SoundnessBench 获得。

##### **Large Language Models show both individual and collective creativity comparable to humans**
2412.03151v1 by Luning Sun, Yuzhuo Yuan, Yuan Yao, Yanyan Li, Hao Zhang, Xing Xie, Xiting Wang, Fang Luo, David Stillwell

Artificial intelligence has, so far, largely automated routine tasks, but
what does it mean for the future of work if Large Language Models (LLMs) show
creativity comparable to humans? To measure the creativity of LLMs
holistically, the current study uses 13 creative tasks spanning three domains.
We benchmark the LLMs against individual humans, and also take a novel approach
by comparing them to the collective creativity of groups of humans. We find
that the best LLMs (Claude and GPT-4) rank in the 52nd percentile against
humans, and overall LLMs excel in divergent thinking and problem solving but
lag in creative writing. When questioned 10 times, an LLM's collective
creativity is equivalent to 8-10 humans. When more responses are requested, two
additional responses of LLMs equal one extra human. Ultimately, LLMs, when
optimally applied, may compete with a small group of humans in the future of
work.

摘要：目前為止，人工智慧已經自動化了大量的例行工作，但如果大型語言模型 (LLM) 展現出與人類相當的創造力，這對工作的未來而言代表什麼意義？為了全面衡量 LLM 的創造力，目前的研究使用了涵蓋三個領域的 13 項創造力任務。我們以個別人類為基準來評量 LLM，並採用創新的方法，將它們與人類群體的集體創造力進行比較。我們發現，最佳的 LLM（Claude 和 GPT-4）在與人類的比較中排名第 52 個百分位，整體而言，LLM 在發散性思考和問題解決方面表現出色，但在創意寫作方面則落後。當被詢問 10 次時，LLM 的集體創造力等於 8-10 個人類。當要求提供更多回應時，LLM 的兩個額外回應等於一個額外的人類。最終，在最佳應用時，LLM 可能在未來的職場中與一小群人類競爭。

##### **Fine-Grained Behavior Simulation with Role-Playing Large Language Model on Social Media**
2412.03148v1 by Kun Li, Chenwei Dai, Wei Zhou, Songlin Hu

Large language models (LLMs) have demonstrated impressive capabilities in
role-playing tasks. However, there is limited research on whether LLMs can
accurately simulate user behavior in real-world scenarios, such as social
media. This requires models to effectively analyze a user's history and
simulate their role. In this paper, we introduce \textbf{FineRob}, a novel
fine-grained behavior simulation dataset. We collect the complete behavioral
history of 1,866 distinct users across three social media platforms. Each
behavior is decomposed into three fine-grained elements: object, type, and
content, resulting in 78.6k QA records. Based on FineRob, we identify two
dominant reasoning patterns in LLMs' behavior simulation processes and propose
the \textbf{OM-CoT} fine-tuning method to enhance the capability. Through
comprehensive experiments, we conduct an in-depth analysis of key factors of
behavior simulation and also demonstrate the effectiveness of OM-CoT
approach\footnote{Code and dataset are available at
\url{https://github.com/linkseed18612254945/FineRob}}

摘要：大型語言模型 (LLM) 已在角色扮演任務中展示了令人印象深刻的能力。然而，關於 LLM 是否可以在現實世界場景中準確模擬使用者行為（例如社交媒體）的研究有限。這需要模型有效分析使用者的歷史記錄並模擬其角色。在本文中，我們介紹了 FineRob，這是一個新穎的細粒度行為模擬數據集。我們收集了 1,866 個不同使用者在三個社交媒體平台上的完整行為歷史記錄。每個行為被分解為三個細粒度元素：對象、類型和內容，產生了 78.6k 個問答記錄。基於 FineRob，我們在 LLM 的行為模擬過程中識別了兩種主要的推理模式，並提出了 OM-CoT 微調方法來增強能力。通過全面的實驗，我們對行為模擬的關鍵因素進行了深入分析，並展示了 OM-CoT 方法的有效性。

##### **Robust Multi-bit Text Watermark with LLM-based Paraphrasers**
2412.03123v1 by Xiaojun Xu, Jinghan Jia, Yuanshun Yao, Yang Liu, Hang Li

We propose an imperceptible multi-bit text watermark embedded by paraphrasing
with LLMs. We fine-tune a pair of LLM paraphrasers that are designed to behave
differently so that their paraphrasing difference reflected in the text
semantics can be identified by a trained decoder. To embed our multi-bit
watermark, we use two paraphrasers alternatively to encode the pre-defined
binary code at the sentence level. Then we use a text classifier as the decoder
to decode each bit of the watermark. Through extensive experiments, we show
that our watermarks can achieve over 99.99\% detection AUC with small (1.1B)
text paraphrasers while keeping the semantic information of the original
sentence. More importantly, our pipeline is robust under word substitution and
sentence paraphrasing perturbations and generalizes well to
out-of-distributional data. We also show the stealthiness of our watermark with
LLM-based evaluation. We open-source the code:
https://github.com/xiaojunxu/multi-bit-text-watermark.

摘要：我們提出一個由 LLM 釋義嵌入的難以察覺的多位元文字浮水印。我們微調了一對 LLM 釋義器，它們被設計成表現不同，這樣它們的釋義差異反映在文字語意中，就能被一個訓練過的解碼器識別。為了嵌入我們的多位元浮水印，我們交替使用兩個釋義器，在句子層級編碼預定義的二進位碼。然後我們使用文字分類器作為解碼器，解碼浮水印的每一比特。透過廣泛的實驗，我們證明我們的浮水印可以達到超過 99.99% 的偵測 AUC，文字釋義器很小（1.1B），同時保留原始句子的語意資訊。更重要的是，我們的管道在詞彙替換和句子釋義擾動下具有穩健性，並且可以很好地概括到分布外資料。我們還展示了我們浮水印的隱密性，並使用基於 LLM 的評估。我們開放原始碼：
https://github.com/xiaojunxu/multi-bit-text-watermark。

##### **Experience-driven discovery of planning strategies**
2412.03111v1 by Ruiqi He, Falk Lieder

One explanation for how people can plan efficiently despite limited cognitive
resources is that we possess a set of adaptive planning strategies and know
when and how to use them. But how are these strategies acquired? While previous
research has studied how individuals learn to choose among existing strategies,
little is known about the process of forming new planning strategies. In this
work, we propose that new planning strategies are discovered through
metacognitive reinforcement learning. To test this, we designed a novel
experiment to investigate the discovery of new planning strategies. We then
present metacognitive reinforcement learning models and demonstrate their
capability for strategy discovery as well as show that they provide a better
explanation of human strategy discovery than alternative learning mechanisms.
However, when fitted to human data, these models exhibit a slower discovery
rate than humans, leaving room for improvement.

摘要：人們儘管認知資源有限，卻能有效率地規劃，其中一個解釋是我們擁有一組適應性規劃策略，並知道何時以及如何使用它們。但這些策略是如何習得的呢？雖然先前的研究探討了個人如何學習在既有策略中做出選擇，但對於形成新規劃策略的過程所知甚少。在這項研究中，我們提出新的規劃策略是透過元認知強化學習而發現的。為了測試這一點，我們設計了一項新穎的實驗來研究新規劃策略的發現。接著，我們提出元認知強化學習模型，並展示它們發現策略的能力，以及它們比其他學習機制更能解釋人類的策略發現。然而，當這些模型套用於人類資料時，它們表現出比人類更慢的發現率，因此有進步的空間。

##### **CredID: Credible Multi-Bit Watermark for Large Language Models Identification**
2412.03107v1 by Haoyu Jiang, Xuhong Wang, Ping Yi, Shanzhe Lei, Yilun Lin

Large Language Models (LLMs) are widely used in complex natural language
processing tasks but raise privacy and security concerns due to the lack of
identity recognition. This paper proposes a multi-party credible watermarking
framework (CredID) involving a trusted third party (TTP) and multiple LLM
vendors to address these issues. In the watermark embedding stage, vendors
request a seed from the TTP to generate watermarked text without sending the
user's prompt. In the extraction stage, the TTP coordinates each vendor to
extract and verify the watermark from the text. This provides a credible
watermarking scheme while preserving vendor privacy. Furthermore, current
watermarking algorithms struggle with text quality, information capacity, and
robustness, making it challenging to meet the diverse identification needs of
LLMs. Thus, we propose a novel multi-bit watermarking algorithm and an
open-source toolkit to facilitate research. Experiments show our CredID
enhances watermark credibility and efficiency without compromising text
quality. Additionally, we successfully utilized this framework to achieve
highly accurate identification among multiple LLM vendors.

摘要：大型語言模型 (LLM) 廣泛用於複雜的自然語言處理任務，但由於缺乏身分識別，因此引發了隱私和安全問題。本文提出了一個多方可信浮水印架構 (CredID)，其中涉及一個受信任的第三方 (TTP) 和多個 LLM 供應商，以解決這些問題。在浮水印嵌入階段，供應商會向 TTP 要求一個種子，以產生浮水印文字，而不用傳送使用者的提示。在萃取階段，TTP 會協調每個供應商，以從文字中萃取和驗證浮水印。這提供了一個可信的浮水印架構，同時保護供應商的隱私。此外，目前的浮水印演算法在文字品質、資訊容量和穩健性方面都面臨挑戰，這使得難以滿足 LLM 多樣化的識別需求。因此，我們提出了一種新穎的多位元浮水印演算法和一個開源工具包，以利於研究。實驗顯示，我們的 CredID 增強了浮水印的可信度和效率，同時不損害文字品質。此外，我們成功地利用這個架構，在多個 LLM 供應商之間達到了高度準確的識別。

##### **ChatTS: Aligning Time Series with LLMs via Synthetic Data for Enhanced Understanding and Reasoning**
2412.03104v1 by Zhe Xie, Zeyan Li, Xiao He, Longlong Xu, Xidao Wen, Tieying Zhang, Jianjun Chen, Rui Shi, Dan Pei

Understanding time series is crucial for its application in real-world
scenarios. Recently, large language models (LLMs) have been increasingly
applied to time series tasks, leveraging their strong language capabilities to
enhance various applications. However, research on multimodal LLMs (MLLMs) for
time series understanding and reasoning remains limited, primarily due to the
scarcity of high-quality datasets that align time series with textual
information. This paper introduces ChatTS, a novel MLLM designed for time
series analysis. ChatTS treats time series as a modality, similar to how vision
MLLMs process images, enabling it to perform both understanding and reasoning
with time series. To address the scarcity of training data, we propose an
attribute-based method for generating synthetic time series with detailed
attribute descriptions. We further introduce Time Series Evol-Instruct, a novel
approach that generates diverse time series Q&As, enhancing the model's
reasoning capabilities. To the best of our knowledge, ChatTS is the first MLLM
that takes multivariate time series as input, which is fine-tuned exclusively
on synthetic datasets. We evaluate its performance using benchmark datasets
with real-world data, including six alignment tasks and four reasoning tasks.
Our results show that ChatTS significantly outperforms existing vision-based
MLLMs (e.g., GPT-4o) and text/agent-based LLMs, achieving a 46.0% improvement
in alignment tasks and a 25.8% improvement in reasoning tasks.

摘要：<paragraph>了解時間序列對於其在現實世界中的應用至關重要。最近，大型語言模型 (LLM) 已越來越多地應用於時間序列任務，利用其強大的語言能力來增強各種應用。然而，針對時間序列理解和推理的多模態 LLM (MLLM) 的研究仍然有限，這主要是因為缺乏將時間序列與文本信息對齊的高品質數據集。本文介紹了 ChatTS，這是一種專為時間序列分析設計的新型 MLLM。ChatTS 將時間序列視為一種模態，類似於視覺 MLLM 處理圖像的方式，使其能夠對時間序列進行理解和推理。為了解決訓練數據的稀缺性，我們提出了一種基於屬性的方法，用於生成具有詳細屬性描述的合成時間序列。我們進一步引入了時間序列 Evol-Instruct，這是一種生成多樣化時間序列問答的新方法，增強了模型的推理能力。據我們所知，ChatTS 是第一個將多變量時間序列作為輸入的 MLLM，它專門針對合成數據集進行微調。我們使用包含真實世界數據的基準數據集評估其性能，包括六個對齊任務和四個推理任務。我們的結果表明，ChatTS 明顯優於現有的基於視覺的 MLLM（例如 GPT-4o）和基於文本/代理的 LLM，在對齊任務中改進了 46.0%，在推理任務中改進了 25.8%。</paragraph>

##### **A surprisal oracle for when every layer counts**
2412.03098v1 by Xudong Hong, Sharid Loáiciga, Asad Sayeed

Active Curriculum Language Modeling (ACLM; Hong et al., 2023) is a learner
directed approach to training a language model. We proposed the original
version of this process in our submission to the BabyLM 2023 task, and now we
propose an updated ACLM process for the BabyLM 2024 task. ACLM involves an
iteratively- and dynamically-constructed curriculum informed over the training
process by a model of uncertainty; other training items that are similarly
uncertain to a least certain candidate item are prioritized. Our new process
improves the similarity model so that it is more dynamic, and we run ACLM over
the most successful model from the BabyLM 2023 task: ELC-BERT (Charpentier and
Samuel, 2023). We find that while our models underperform on fine-grained
grammatical inferences, they outperform the BabyLM 2024 official base-lines on
common-sense and world-knowledge tasks. We make our code available at https:
//github.com/asayeed/ActiveBaby.

摘要：主動式課程語言模型 (ACLM；Hong 等人，2023) 是一種由學習者引導，用於訓練語言模型的方法。我們在提交給 BabyLM 2023 任務時提出了這個流程的原始版本，現在我們為 BabyLM 2024 任務提出一個更新的 ACLM 流程。ACLM 涉及一個反覆且動態建構的課程，並在訓練過程中由一個不確定性模型提供資訊；其他訓練項目與至少一個最不確定的候選項目相似的不確定項目會被優先處理。我們的流程改進了相似性模型，使其更具動態性，我們在 BabyLM 2023 任務中最成功的模型：ELC-BERT (Charpentier 和 Samuel，2023) 上執行 ACLM。我們發現，儘管我們的模型在細微的語法推論上表現不佳，但它們在常識和世界知識任務上優於 BabyLM 2024 官方基準線。我們在 https://github.com/asayeed/ActiveBaby 上提供我們的程式碼。

##### **TOOL-ED: Enhancing Empathetic Response Generation with the Tool Calling Capability of LLM**
2412.03096v1 by Huiying Cao, Yiqun Zhang, Shi Feng, Xiaocui Yang, Daling Wang, Yifei Zhang

Empathetic conversation is a crucial characteristic in daily conversations
between individuals. Nowadays, Large Language models (LLMs) have shown
outstanding performance in generating empathetic responses. Knowledge bases
like COMET can assist LLMs in mitigating illusions and enhancing the
understanding of users' intentions and emotions. However, models remain heavily
reliant on fixed knowledge bases and unrestricted incorporation of external
knowledge can introduce noise. Tool learning is a flexible end-to-end approach
that assists LLMs in handling complex problems. In this paper, we propose
Emotional Knowledge Tool Calling (EKTC) framework, which encapsulates the
commonsense knowledge bases as empathetic tools, enabling LLMs to integrate
external knowledge flexibly through tool calling. In order to adapt the models
to the new task, we construct a novel dataset TOOL-ED based on the
EMPATHETICMPATHETIC DIALOGUE (ED) dataset. We validate EKTC on the ED dataset,
and the experimental results demonstrate that our framework can enhance the
ability of LLMs to generate empathetic responses effectively.

摘要：同理心對話是個人日常對話中至關重要的特質。如今，大型語言模型 (LLM) 在產生同理心回應方面表現傑出。像 COMET 這樣的知識庫可以協助 LLM 減輕錯覺，並增強對使用者意圖和情緒的理解。然而，模型依舊高度依賴固定知識庫，而外部知識的不受限納入可能會引入雜訊。工具學習是一種靈活的端對端方法，可協助 LLM 處理複雜的問題。在本文中，我們提出情緒知識工具呼叫 (EKTC) 架構，它將常識知識庫封裝為同理心工具，讓 LLM 能夠透過工具呼叫靈活地整合外部知識。為了讓模型適應新任務，我們根據同理心對話 (ED) 資料集建構了一個新穎的資料集 TOOL-ED。我們在 ED 資料集上驗證 EKTC，而實驗結果證明我們的架構可以有效增強 LLM 產生同理心回應的能力。

##### **Revolve: Optimizing AI Systems by Tracking Response Evolution in Textual Optimization**
2412.03092v1 by Peiyan Zhang, Haibo Jin, Leyang Hu, Xinnuo Li, Liying Kang, Man Luo, Yangqiu Song, Haohan Wang

Recent advancements in large language models (LLMs) have significantly
enhanced the ability of LLM-based systems to perform complex tasks through
natural language processing and tool interaction. However, optimizing these
LLM-based systems for specific tasks remains challenging, often requiring
manual interventions like prompt engineering and hyperparameter tuning.
Existing automatic optimization methods, such as textual feedback-based
techniques (e.g., TextGrad), tend to focus on immediate feedback, analogous to
using immediate derivatives in traditional numerical gradient descent. However,
relying solely on such feedback can be limited when the adjustments made in
response to this feedback are either too small or fluctuate irregularly,
potentially slowing down or even stalling the optimization process. To overcome
these challenges, more adaptive methods are needed, especially in situations
where the system's response is evolving slowly or unpredictably. In this paper,
we introduce REVOLVE, an optimization method that tracks how "R"esponses
"EVOLVE" across iterations in LLM systems. By focusing on the evolution of
responses over time, REVOLVE enables more stable and effective optimization by
making thoughtful, progressive adjustments at each step. Experimental results
demonstrate that REVOLVE outperforms competitive baselines, achieving a 7.8%
improvement in prompt optimization, a 20.72% gain in solution refinement, and a
29.17% increase in code optimization. Additionally, REVOLVE converges in fewer
iterations, resulting in significant computational savings. These advantages
highlight its adaptability and efficiency, positioning REVOLVE as a valuable
tool for optimizing LLM-based systems and accelerating the development of
next-generation AI technologies. Code is available at:
https://github.com/Peiyance/REVOLVE.

摘要：<paragraph>大型語言模型 (LLM) 的最新進展顯著提升了 LLM 基於系統透過自然語言處理和工具互動執行複雜任務的能力。然而，針對特定任務最佳化這些 LLM 基於系統仍然具有挑戰性，通常需要手動介入，例如提示工程和超參數調整。現有的自動最佳化方法，例如基於文字回饋的技術 (例如 TextGrad)，傾向於關注立即回饋，類似於在傳統數值梯度下降中使用立即導數。然而，僅依賴此類回饋可能會受到限制，當根據此回饋進行的調整過小或不規則波動時，可能會減慢甚至停止最佳化程序。為了克服這些挑戰，需要更多適應性方法，特別是在系統回應緩慢或難以預測的情況下。在本文中，我們介紹 REVOLVE，這是一種最佳化方法，它追蹤 LLM 系統中「R」esponses 如何在迭代中「EVOLVE」。透過關注回應隨時間的演變，REVOLVE 能夠在每個步驟進行深思熟慮的漸進式調整，進而實現更穩定且有效的最佳化。實驗結果證明 REVOLVE 優於競爭基準，在提示最佳化方面提升了 7.8%，在解決方案精煉方面提升了 20.72%，在程式碼最佳化方面提升了 29.17%。此外，REVOLVE 在較少迭代中收斂，從而節省了大量的運算。這些優點突顯了它的適應性和效率，將 REVOLVE 定位為最佳化 LLM 基於系統和加速下一代 AI 技術發展的寶貴工具。程式碼可在以下位置取得：https://github.com/Peiyance/REVOLVE。</paragraph>

##### **ASR-EC Benchmark: Evaluating Large Language Models on Chinese ASR Error Correction**
2412.03075v1 by Victor Junqiu Wei, Weicheng Wang, Di Jiang, Yuanfeng Song, Lu Wang

Automatic speech Recognition (ASR) is a fundamental and important task in the
field of speech and natural language processing. It is an inherent building
block in many applications such as voice assistant, speech translation, etc.
Despite the advancement of ASR technologies in recent years, it is still
inevitable for modern ASR systems to have a substantial number of erroneous
recognition due to environmental noise, ambiguity, etc. Therefore, the error
correction in ASR is crucial.
  Motivated by this, this paper studies ASR error correction in the Chinese
language, which is one of the most popular languages and enjoys a large number
of users in the world. We first create a benchmark dataset named \emph{ASR-EC}
that contains a wide spectrum of ASR errors generated by industry-grade ASR
systems. To the best of our knowledge, it is the first Chinese ASR error
correction benchmark. Then, inspired by the recent advances in \emph{large
language models (LLMs)}, we investigate how to harness the power of LLMs to
correct ASR errors. We apply LLMs to ASR error correction in three paradigms.
The first paradigm is prompting, which is further categorized as zero-shot,
few-shot, and multi-step. The second paradigm is finetuning, which finetunes
LLMs with ASR error correction data. The third paradigm is multi-modal
augmentation, which collectively utilizes the audio and ASR transcripts for
error correction. Extensive experiments reveal that prompting is not effective
for ASR error correction. Finetuning is effective only for a portion of LLMs.
Multi-modal augmentation is the most effective method for error correction and
achieves state-of-the-art performance.

摘要：<paragraph>自動語音辨識 (ASR) 是語音與自然語言處理領域中的一項基本且重要的任務。它是許多應用程式中固有的組成部分，例如語音助理、語音翻譯等。儘管近年來 ASR 技術進步，但現代 ASR 系統仍難免會因環境噪音、歧義等因素產生大量錯誤辨識。因此，ASR 中的錯誤校正至關重要。
受此啟發，本文研究了中文 ASR 錯誤校正，中文是最流行的語言之一，在全球擁有大量的使用者。我們首先建立了一個名為 \emph{ASR-EC} 的基準資料集，其中包含由產業級 ASR 系統產生的各種 ASR 錯誤。據我們所知，這是第一個中文 ASR 錯誤校正基準。接著，受到 \emph{大型語言模型 (LLM)} 近期進展的啟發，我們探討如何利用 LLM 的力量來校正 ASR 錯誤。我們將 LLM 應用於 ASR 錯誤校正的三種範例。第一個範例是提示，進一步分類為零次學習、少次學習和多步驟。第二個範例是微調，使用 ASR 錯誤校正資料微調 LLM。第三個範例是多模式擴充，共同利用音訊和 ASR 轉錄進行錯誤校正。大量的實驗顯示，提示對於 ASR 錯誤校正無效。微調僅對部分 LLM 有效。多模式擴充是錯誤校正最有效的方法，並達到了最先進的效能。</paragraph>

##### **Analytic Study of Text-Free Speech Synthesis for Raw Audio using a Self-Supervised Learning Model**
2412.03074v1 by Joonyong Park, Daisuke Saito, Nobuaki Minematsu

We examine the text-free speech representations of raw audio obtained from a
self-supervised learning (SSL) model by analyzing the synthesized speech using
the SSL representations instead of conventional text representations. Since raw
audio does not have paired speech representations as transcribed texts do,
obtaining speech representations from unpaired speech is crucial for augmenting
available datasets for speech synthesis. Specifically, the proposed speech
synthesis is conducted using discrete symbol representations from the SSL model
in comparison with text representations, and analytical examinations of the
synthesized speech have been carried out. The results empirically show that
using text representations is advantageous for preserving semantic information,
while using discrete symbol representations is superior for preserving acoustic
content, including prosodic and intonational information.

摘要：我們透過分析合成語音，使用 SSL 表示法而非傳統文字表示法，來檢視從自監督式學習 (SSL) 模型取得的無文字語音表示法。由於原始音訊沒有像轉錄文字那樣的配對語音表示法，因此從未配對的語音中取得語音表示法對於擴充語音合成的可用資料集至關重要。具體來說，建議的語音合成是使用來自 SSL 模型的離散符號表示法，並與文字表示法進行比較，並對合成語音進行分析檢視。結果經驗性地顯示，使用文字表示法有利於保留語意資訊，而使用離散符號表示法則優於保留音響內容，包括韻律和語調資訊。

##### **Preference-based opponent shaping in differentiable games**
2412.03072v1 by Xinyu Qiao, Yudong Hu, Congying Han, Weiyan Wu, Tiande Guo

Strategy learning in game environments with multi-agent is a challenging
problem. Since each agent's reward is determined by the joint strategy, a
greedy learning strategy that aims to maximize its own reward may fall into a
local optimum. Recent studies have proposed the opponent modeling and shaping
methods for game environments. These methods enhance the efficiency of strategy
learning by modeling the strategies and updating processes of other agents.
However, these methods often rely on simple predictions of opponent strategy
changes. Due to the lack of modeling behavioral preferences such as cooperation
and competition, they are usually applicable only to predefined scenarios and
lack generalization capabilities. In this paper, we propose a novel
Preference-based Opponent Shaping (PBOS) method to enhance the strategy
learning process by shaping agents' preferences towards cooperation. We
introduce the preference parameter, which is incorporated into the agent's loss
function, thus allowing the agent to directly consider the opponent's loss
function when updating the strategy. We update the preference parameters
concurrently with strategy learning to ensure that agents can adapt to any
cooperative or competitive game environment. Through a series of experiments,
we verify the performance of PBOS algorithm in a variety of differentiable
games. The experimental results show that the PBOS algorithm can guide the
agent to learn the appropriate preference parameters, so as to achieve better
reward distribution in multiple game environments.

摘要：在具有多智能體的遊戲環境中進行策略學習是一個具有挑戰性的問題。由於每個智能體的獎勵是由聯合策略決定的，因此旨在最大化自身獎勵的貪婪學習策略可能會陷入局部最優。最近的研究提出了對手建模和塑造遊戲環境的方法。這些方法通過對其他智能體的策略和更新過程進行建模，提高了策略學習的效率。然而，這些方法通常依賴於對對手策略變化的簡單預測。由於缺乏對合作和競爭等行為偏好的建模，它們通常僅適用於預定義的場景，並且缺乏泛化能力。在本文中，我們提出了一種新的基於偏好的對手塑造 (PBOS) 方法，通過塑造智能體對合作的偏好來增強策略學習過程。我們引入了偏好參數，該參數被納入智能體的損失函數中，從而允許智能體在更新策略時直接考慮對手的損失函數。我們與策略學習同時更新偏好參數，以確保智能體可以適應任何合作或競爭的遊戲環境。通過一系列實驗，我們驗證了 PBOS 演算法在各種可微分遊戲中的性能。實驗結果表明，PBOS 演算法可以引導智能體學習適當的偏好參數，從而在多個遊戲環境中實現更好的獎勵分配。

##### **UTSD: Unified Time Series Diffusion Model**
2412.03068v1 by Xiangkai Ma, Xiaobin Hong, Wenzhong Li, Sanglu Lu

Transformer-based architectures have achieved unprecedented success in time
series analysis. However, facing the challenge of across-domain modeling,
existing studies utilize statistical prior as prompt engineering fails under
the huge distribution shift among various domains. In this paper, a Unified
Time Series Diffusion (UTSD) model is established for the first time to model
the multi-domain probability distribution, utilizing the powerful probability
distribution modeling ability of Diffusion. Unlike the autoregressive models
that capture the conditional probabilities of the prediction horizon to the
historical sequence, we use a diffusion denoising process to model the mixture
distribution of the cross-domain data and generate the prediction sequence for
the target domain directly utilizing conditional sampling. The proposed UTSD
contains three pivotal designs: (1) The condition network captures the
multi-scale fluctuation patterns from the observation sequence, which are
utilized as context representations to guide the denoising network to generate
the prediction sequence; (2) Adapter-based fine-tuning strategy, the
multi-domain universal representation learned in the pretraining stage is
utilized for downstream tasks in target domains; (3) The diffusion and
denoising process on the actual sequence space, combined with the improved
classifier free guidance as the conditional generation strategy, greatly
improves the stability and accuracy of the downstream task. We conduct
extensive experiments on mainstream benchmarks, and the pre-trained UTSD
outperforms existing foundation models on all data domains, exhibiting superior
zero-shot generalization ability. After training from scratch, UTSD achieves
comparable performance against domain-specific proprietary models. The
empirical results validate the potential of UTSD as a time series foundational
model.

摘要：<paragraph>基於 Transformer 的架構在時間序列分析中獲得了前所未有的成功。然而，面對跨域建模的挑戰，現有的研究利用統計先驗作為提示工程，在各種域之間的巨大分佈轉移下會失敗。在本文中，首次建立了統一時間序列擴散 (UTSD) 模型來對多域機率分佈進行建模，利用擴散的強大機率分佈建模能力。與捕捉預測範圍到歷史序列條件機率的自迴歸模型不同，我們使用擴散去噪程序對跨域資料的混合分佈進行建模，並直接利用條件抽樣為目標域產生預測序列。所提出的 UTSD 包含三個關鍵設計：(1) 條件網路從觀察序列中捕捉多尺度波動模式，這些模式被用作上下文表示，以引導去噪網路產生預測序列；(2) 基於適配器的微調策略，在預訓練階段學習的多域通用表示用於目標域的下游任務；(3) 在實際序列空間上的擴散和去噪程序，結合作為條件生成策略的改良分類器自由引導，極大地提高了下游任務的穩定性和準確性。我們在主流基準上進行了廣泛的實驗，預先訓練的 UTSD 在所有資料域上都優於現有的基礎模型，展現出卓越的零次方泛化能力。從頭開始訓練後，UTSD 在與特定於域的專有模型相比時，達到了相當的效能。實證結果驗證了 UTSD 作為時間序列基礎模型的潛力。</paragraph>

##### **Point-GN: A Non-Parametric Network Using Gaussian Positional Encoding for Point Cloud Classification**
2412.03056v1 by Marzieh Mohammadi, Amir Salarpour

This paper introduces Point-GN, a novel non-parametric network for efficient
and accurate 3D point cloud classification. Unlike conventional deep learning
models that rely on a large number of trainable parameters, Point-GN leverages
non-learnable components-specifically, Farthest Point Sampling (FPS), k-Nearest
Neighbors (k-NN), and Gaussian Positional Encoding (GPE)-to extract both local
and global geometric features. This design eliminates the need for additional
training while maintaining high performance, making Point-GN particularly
suited for real-time, resource-constrained applications. We evaluate Point-GN
on two benchmark datasets, ModelNet40 and ScanObjectNN, achieving
classification accuracies of 85.29% and 85.89%, respectively, while
significantly reducing computational complexity. Point-GN outperforms existing
non-parametric methods and matches the performance of fully trained models, all
with zero learnable parameters. Our results demonstrate that Point-GN is a
promising solution for 3D point cloud classification in practical, real-time
environments.

摘要：本文介紹 Point-GN，一種用於高效且準確的 3D 點雲分類的新型非參數網路。與依賴大量可訓練參數的傳統深度學習模型不同，Point-GN 利用不可學習的元件（具體來說，最遠點取樣 (FPS)、k 最近鄰 (k-NN) 和高斯位置編碼 (GPE)）來提取局部和全局幾何特徵。此設計消除了額外訓練的需求，同時維持高性能，使 Point-GN 特別適合於即時、資源受限的應用程式。我們在兩個基準資料集 ModelNet40 和 ScanObjectNN 上評估 Point-GN，分別達到 85.29% 和 85.89% 的分類準確度，同時大幅降低運算複雜度。Point-GN 優於現有的非參數方法，並與完全訓練模型的性能相匹配，所有這些都無需可學習參數。我們的結果表明，Point-GN 是在實際即時環境中進行 3D 點雲分類的有前途的解決方案。

##### **Less is More: A Stealthy and Efficient Adversarial Attack Method for DRL-based Autonomous Driving Policies**
2412.03051v1 by Junchao Fan, Xuyang Lei, Xiaolin Chang, Jelena Mišić, Vojislav B. Mišić

Despite significant advancements in deep reinforcement learning (DRL)-based
autonomous driving policies, these policies still exhibit vulnerability to
adversarial attacks. This vulnerability poses a formidable challenge to the
practical deployment of these policies in autonomous driving. Designing
effective adversarial attacks is an indispensable prerequisite for enhancing
the robustness of these policies. In view of this, we present a novel stealthy
and efficient adversarial attack method for DRL-based autonomous driving
policies. Specifically, we introduce a DRL-based adversary designed to trigger
safety violations (e.g., collisions) by injecting adversarial samples at
critical moments. We model the attack as a mixed-integer optimization problem
and formulate it as a Markov decision process. Then, we train the adversary to
learn the optimal policy for attacking at critical moments without domain
knowledge. Furthermore, we introduce attack-related information and a
trajectory clipping method to enhance the learning capability of the adversary.
Finally, we validate our method in an unprotected left-turn scenario across
different traffic densities. The experimental results show that our method
achieves more than 90% collision rate within three attacks in most cases.
Furthermore, our method achieves more than 130% improvement in attack
efficiency compared to the unlimited attack method.

摘要：儘管在基於深度強化學習 (DRL) 的自動駕駛政策方面取得了顯著進展，但這些政策仍然容易受到對抗性攻擊。這種脆弱性對在自動駕駛中實際部署這些政策構成了巨大的挑戰。設計有效的對抗性攻擊是增強這些政策穩健性的必要先決條件。有鑑於此，我們提出了一種針對基於 DRL 的自動駕駛政策的新型隱蔽且有效的對抗性攻擊方法。具體來說，我們引入了一個基於 DRL 的對手，旨在通過在關鍵時刻注入對抗性樣本來觸發安全違規（例如碰撞）。我們將攻擊建模為一個混合整數優化問題，並將其表述為馬可夫決策過程。然後，我們訓練對手在沒有領域知識的情況下學習在關鍵時刻攻擊的最佳策略。此外，我們引入了攻擊相關信息和軌跡剪輯方法，以增強對手的學習能力。最後，我們在不同的交通密度下，在一個不受保護的左轉場景中驗證了我們的模型。實驗結果表明，在大多數情況下，我們的模型在三次攻擊中實現了超過 90% 的碰撞率。此外，與無限制攻擊方法相比，我們的模型在攻擊效率方面實現了超過 130% 的改進。

##### **MRNet: Multifaceted Resilient Networks for Medical Image-to-Image Translation**
2412.03039v1 by Hyojeong Lee, Youngwan Jo, Inpyo Hong, Sanghyun Park

We propose a Multifaceted Resilient Network(MRNet), a novel architecture
developed for medical image-to-image translation that outperforms
state-of-the-art methods in MRI-to-CT and MRI-to-MRI conversion. MRNet
leverages the Segment Anything Model (SAM) to exploit frequency-based features
to build a powerful method for advanced medical image transformation. The
architecture extracts comprehensive multiscale features from diverse datasets
using a powerful SAM image encoder and performs resolution-aware feature fusion
that consistently integrates U-Net encoder outputs with SAM-derived features.
This fusion optimizes the traditional U-Net skip connection while leveraging
transformer-based contextual analysis. The translation is complemented by an
innovative dual-mask configuration incorporating dynamic attention patterns and
a specialized loss function designed to address regional mapping mismatches,
preserving both the gross anatomy and tissue details. Extensive validation
studies have shown that MRNet outperforms state-of-the-art architectures,
particularly in maintaining anatomical fidelity and minimizing translation
artifacts.

摘要：我們提出一個多方面的彈性網路 (MRNet)，這是一個創新的架構，
開發用於醫學影像轉影像的翻譯，其優於 MRI 轉 CT 和 MRI 轉 MRI 轉換的最新方法。MRNet
利用 Segment Anything Model (SAM) 來利用基於頻率的特徵，以建立一種強大的方法，用於先進的醫學影像轉換。此
架構使用強大的 SAM 影像編碼器從不同的資料集提取全面的多尺度特徵，並執行解析度感知特徵融合，持續將 U-Net 編碼器輸出與 SAM 衍生的特徵整合在一起。
此融合最佳化傳統的 U-Net 跳躍連接，同時利用基於Transformer的上下文分析。翻譯由一個創新的雙遮罩配置補充，它結合了動態注意模式和一個專門的損失函數，旨在解決區域對應不匹配的問題，同時保留了整體解剖結構和組織細節。廣泛的驗證研究顯示，MRNet 優於最先進的架構，特別是在維持解剖保真度和最小化轉換偽影方面。

##### **MILLION: A General Multi-Objective Framework with Controllable Risk for Portfolio Management**
2412.03038v1 by Liwei Deng, Tianfu Wang, Yan Zhao, Kai Zheng

Portfolio management is an important yet challenging task in AI for FinTech,
which aims to allocate investors' budgets among different assets to balance the
risk and return of an investment. In this study, we propose a general
Multi-objectIve framework with controLLable rIsk for pOrtfolio maNagement
(MILLION), which consists of two main phases, i.e., return-related maximization
and risk control. Specifically, in the return-related maximization phase, we
introduce two auxiliary objectives, i.e., return rate prediction, and return
rate ranking, combined with portfolio optimization to remit the overfitting
problem and improve the generalization of the trained model to future markets.
Subsequently, in the risk control phase, we propose two methods, i.e.,
portfolio interpolation and portfolio improvement, to achieve fine-grained risk
control and fast risk adaption to a user-specified risk level. For the
portfolio interpolation method, we theoretically prove that the risk can be
perfectly controlled if the to-be-set risk level is in a proper interval. In
addition, we also show that the return rate of the adjusted portfolio after
portfolio interpolation is no less than that of the min-variance optimization,
as long as the model in the reward maximization phase is effective.
Furthermore, the portfolio improvement method can achieve greater return rates
while keeping the same risk level compared to portfolio interpolation.
Extensive experiments are conducted on three real-world datasets. The results
demonstrate the effectiveness and efficiency of the proposed framework.

摘要：投資組合管理是金融科技中人工智能的一項重要且具有挑戰性的任務，其目的是在不同的資產之間分配投資者的預算，以平衡投資的風險和報酬。在本研究中，我們提出了一個具有可控風險的多目標投資組合管理框架 (MILLION)，它包含兩個主要階段，即報酬相關最大化和風險控制。具體來說，在報酬相關最大化階段，我們引入了兩個輔助目標，即報酬率預測和報酬率排名，並結合投資組合最佳化來解決過度擬合問題，並提高訓練模型對未來市場的泛化能力。隨後，在風險控制階段，我們提出了兩種方法，即投資組合插值和投資組合改善，以實現細粒度的風險控制和快速風險適應使用者指定的風險水準。對於投資組合插值方法，我們從理論上證明，如果待設定的風險水準在適當的區間內，則風險可以得到完美的控制。此外，我們還表明，只要報酬最大化階段中的模型是有效的，那麼投資組合插值後調整後的投資組合的報酬率不會低於最小變異數最佳化。此外，與投資組合插值相比，投資組合改善方法可以在保持相同風險水準的同時實現更高的報酬率。在三個真實世界資料集上進行了廣泛的實驗。結果證明了所提出的框架的有效性和效率。

##### **Specification Generation for Neural Networks in Systems**
2412.03028v1 by Isha Chaudhary, Shuyi Lin, Cheng Tan, Gagandeep Singh

Specifications - precise mathematical representations of correct
domain-specific behaviors - are crucial to guarantee the trustworthiness of
computer systems. With the increasing development of neural networks as
computer system components, specifications gain more importance as they can be
used to regulate the behaviors of these black-box models. Traditionally,
specifications are designed by domain experts based on their intuition of
correct behavior. However, this is labor-intensive and hence not a scalable
approach as computer system applications diversify. We hypothesize that the
traditional (aka reference) algorithms that neural networks replace for higher
performance can act as effective proxies for correct behaviors of the models,
when available. This is because they have been used and tested for long enough
to encode several aspects of the trustworthy/correct behaviors in the
underlying domain. Driven by our hypothesis, we develop a novel automated
framework, SpecTRA to generate specifications for neural networks using
references. We formulate specification generation as an optimization problem
and solve it with observations of reference behaviors. SpecTRA clusters similar
observations into compact specifications. We present specifications generated
by SpecTRA for neural networks in adaptive bit rate and congestion control
algorithms. Our specifications show evidence of being correct and matching
intuition. Moreover, we use our specifications to show several unknown
vulnerabilities of the SOTA models for computer systems.

摘要：規範 - 正確的特定領域行為的精確數學表示 - 對保證電腦系統的值得信賴性至關重要。隨著神經網路作為電腦系統組件的發展越來越廣泛，規範變得越來越重要，因為它們可用於規範這些黑盒模型的行為。傳統上，規範是由領域專家根據他們對正確行為的直覺設計的。然而，這需要大量的人力，因此隨著電腦系統應用程式多元化，這並非一個可擴充的方法。我們假設神經網路用以替代以獲得更高效能的傳統（又稱參考）演算法，在有需要時可以作為模型正確行為的有效代理。這是因為它們已經被使用和測試了足夠長的時間，足以編碼可信/正確行為的幾個面向在基礎領域中。在我們的假設驅使下，我們開發了一個新穎的自動化框架 SpecTRA，使用參考為神經網路產生規範。我們將規範產生表述為一個最佳化問題，並透過觀察參考行為來解決它。SpecTRA 將類似的觀察結果分群為精簡的規範。我們提供 SpecTRA 為自適應位元率和壅塞控制演算法中的神經網路產生的規範。我們的規範顯示有正確且符合直覺的證據。此外，我們使用我們的規範來顯示電腦系統的 SOTA 模型的幾個未知漏洞。

##### **Human Variability vs. Machine Consistency: A Linguistic Analysis of Texts Generated by Humans and Large Language Models**
2412.03025v1 by Sergio E. Zanotto, Segun Aroyehun

The rapid advancements in large language models (LLMs) have significantly
improved their ability to generate natural language, making texts generated by
LLMs increasingly indistinguishable from human-written texts. Recent research
has predominantly focused on using LLMs to classify text as either
human-written or machine-generated. In our study, we adopt a different approach
by profiling texts spanning four domains based on 250 distinct linguistic
features. We select the M4 dataset from the Subtask B of SemEval 2024 Task 8.
We automatically calculate various linguistic features with the LFTK tool and
additionally measure the average syntactic depth, semantic similarity, and
emotional content for each document. We then apply a two-dimensional PCA
reduction to all the calculated features. Our analyses reveal significant
differences between human-written texts and those generated by LLMs,
particularly in the variability of these features, which we find to be
considerably higher in human-written texts. This discrepancy is especially
evident in text genres with less rigid linguistic style constraints. Our
findings indicate that humans write texts that are less cognitively demanding,
with higher semantic content, and richer emotional content compared to texts
generated by LLMs. These insights underscore the need for incorporating
meaningful linguistic features to enhance the understanding of textual outputs
of LLMs.

摘要：大型語言模型 (LLM) 的快速進展顯著提升了它們生成自然語言的能力，讓 LLM 生成的文字越來越難以與人類寫的文字區分。最近的研究主要集中於使用 LLM 將文字分類為人類寫的或機器生成的。在我們的研究中，我們採用不同的方法，根據 250 個不同的語言特徵對跨越四個領域的文字進行分析。我們從 SemEval 2024 任務 8 的子任務 B 中選取 M4 資料集。我們使用 LFTK 工具自動計算各種語言特徵，並另外測量每個文件的平均句法深度、語義相似度和情緒內容。然後，我們對所有計算出的特徵應用二維 PCA 降維。我們的分析揭示了人類寫的文字和 LLM 生成的文字之間的顯著差異，特別是在這些特徵的可變性方面，我們發現人類寫的文字的可變性顯著較高。這種差異在語言風格約束較少的文字類型中尤其明顯。我們的研究結果表明，人類寫的文字認知要求較低，語義內容較高，與 LLM 生成的文字相比，情緒內容也更豐富。這些見解強調了納入有意義的語言特徵以增強對 LLM 文本輸出的理解的必要性。

##### **PEMF-VVTO: Point-Enhanced Video Virtual Try-on via Mask-free Paradigm**
2412.03021v1 by Tianyu Chang, Xiaohao Chen. Zhichao Wei, Xuanpu Zhang, Qing-Guo Chen, Weihua Luo, Xun Yang

Video Virtual Try-on aims to fluently transfer the garment image to a
semantically aligned try-on area in the source person video. Previous methods
leveraged the inpainting mask to remove the original garment in the source
video, thus achieving accurate garment transfer on simple model videos.
However, when these methods are applied to realistic video data with more
complex scene changes and posture movements, the overly large and incoherent
agnostic masks will destroy the essential spatial-temporal information of the
original video, thereby inhibiting the fidelity and coherence of the try-on
video. To alleviate this problem, %avoid the inherent deficiencies of
mask-based try-on paradigm, we propose a novel point-enhanced mask-free video
virtual try-on framework (PEMF-VVTO). Specifically, we first leverage the
pre-trained mask-based try-on model to construct large-scale paired training
data (pseudo-person samples). Training on these mask-free data enables our
model to perceive the original spatial-temporal information while realizing
accurate garment transfer. Then, based on the pre-acquired sparse frame-cloth
and frame-frame point alignments, we design the point-enhanced spatial
attention (PSA) and point-enhanced temporal attention (PTA) to further improve
the try-on accuracy and video coherence of the mask-free model. Concretely, PSA
explicitly guides the garment transfer to desirable locations through the
sparse semantic alignments of video frames and cloth. PTA exploits the temporal
attention on sparse point correspondences to enhance the smoothness of
generated videos. Extensive qualitative and quantitative experiments clearly
illustrate that our PEMF-VVTO can generate more natural and coherent try-on
videos than existing state-of-the-art methods.

摘要：<paragraph>影片虛擬試穿旨在流暢地將服飾影像傳輸到來源人物影片中語義對齊的試穿區域。先前的做法利用填色遮罩移除來源影片中的原始服飾，進而於簡單的模型影片上實現精準的服飾傳輸。然而，當這些做法套用於場景變換和姿勢動作更複雜的寫實影片資料時，過於龐大且不連貫的非特定遮罩會破壞原始影片中重要的時空資訊，進而抑制試穿影片的保真度和連貫性。為了減輕這個問題，避免基於遮罩的試穿範例中固有的缺點，我們提出一個新穎的點增強無遮罩影片虛擬試穿架構 (PEMF-VVTO)。具體來說，我們首先利用預先訓練的基於遮罩的試穿模型建立大規模配對訓練資料（擬人樣本）。在這些無遮罩資料上進行訓練，能讓我們的模型感知原始時空資訊，同時實現精準的服飾傳輸。然後，根據預先取得的稀疏幀布料和幀幀點對齊，我們設計點增強空間注意力 (PSA) 和點增強時間注意力 (PTA)，進一步提升無遮罩模型的試穿精準度和影片連貫性。具體而言，PSA 透過影片幀和布料的稀疏語義對齊，明確引導服飾傳輸到理想位置。PTA 利用稀疏點對應的時序注意力，提升生成影片的流暢度。廣泛的定性和定量實驗清楚顯示，我們的 PEMF-VVTO 能產生比現有最先進方法更自然且連貫的試穿影片。</paragraph>

##### **Human Multi-View Synthesis from a Single-View Model:Transferred Body and Face Representations**
2412.03011v1 by Yu Feng, Shunsi Zhang, Jian Shu, Hanfeng Zhao, Guoliang Pang, Chi Zhang, Hao Wang

Generating multi-view human images from a single view is a complex and
significant challenge. Although recent advancements in multi-view object
generation have shown impressive results with diffusion models, novel view
synthesis for humans remains constrained by the limited availability of 3D
human datasets. Consequently, many existing models struggle to produce
realistic human body shapes or capture fine-grained facial details accurately.
To address these issues, we propose an innovative framework that leverages
transferred body and facial representations for multi-view human synthesis.
Specifically, we use a single-view model pretrained on a large-scale human
dataset to develop a multi-view body representation, aiming to extend the 2D
knowledge of the single-view model to a multi-view diffusion model.
Additionally, to enhance the model's detail restoration capability, we
integrate transferred multimodal facial features into our trained human
diffusion model. Experimental evaluations on benchmark datasets demonstrate
that our approach outperforms the current state-of-the-art methods, achieving
superior performance in multi-view human synthesis.

摘要：從單一視角生成多視角的人類影像是一項複雜且重大的挑戰。儘管最近在多視角物件生成方面的進展已在擴散模型中展現令人印象深刻的成果，但人類的新視角合成仍受到 3D 人類資料集有限的可用性所限制。因此，許多現有模型難以產生逼真的人體形狀或準確捕捉細緻的面部細節。為了解決這些問題，我們提出了一個創新的架構，該架構利用轉移的身體和面部表示來進行多視角人類合成。具體來說，我們使用在大型人類資料集上預先訓練的單視角模型來開發多視角身體表示，旨在將單視角模型的 2D 知識擴展到多視角擴散模型。此外，為了增強模型的細節還原能力，我們將轉移的多模態面部特徵整合到我們訓練的人類擴散模型中。在基準資料集上的實驗評估表明，我們的做法優於目前的最新方法，在多視角人類合成中取得了卓越的性能。

##### **Advancing Conversational Psychotherapy: Integrating Privacy, Dual-Memory, and Domain Expertise with Large Language Models**
2412.02987v1 by XiuYu Zhang, Zening Luo

Mental health has increasingly become a global issue that reveals the
limitations of traditional conversational psychotherapy, constrained by
location, time, expense, and privacy concerns. In response to these challenges,
we introduce SoulSpeak, a Large Language Model (LLM)-enabled chatbot designed
to democratize access to psychotherapy. SoulSpeak improves upon the
capabilities of standard LLM-enabled chatbots by incorporating a novel
dual-memory component that combines short-term and long-term context via
Retrieval Augmented Generation (RAG) to offer personalized responses while
ensuring the preservation of user privacy and intimacy through a dedicated
privacy module. In addition, it leverages a counseling chat dataset of
therapist-client interactions and various prompting techniques to align the
generated responses with psychotherapeutic methods. We introduce two fine-tuned
BERT models to evaluate the system against existing LLMs and human therapists:
the Conversational Psychotherapy Preference Model (CPPM) to simulate human
preference among responses and another to assess response relevance to user
input. CPPM is useful for training and evaluating psychotherapy-focused
language models independent from SoulSpeak, helping with the constrained
resources available for psychotherapy. Furthermore, the effectiveness of the
dual-memory component and the robustness of the privacy module are also
examined. Our findings highlight the potential and challenge of enhancing
mental health care by offering an alternative that combines the expertise of
traditional therapy with the advantages of LLMs, providing a promising way to
address the accessibility and personalization gap in current mental health
services.

摘要：心理健康已日益成為全球問題，暴露了傳統對話式心理治療的限制，受到地點、時間、費用和隱私問題的約束。為了應對這些挑戰，我們推出了 SoulSpeak，這是一款大型語言模型 (LLM) 啟用的聊天機器人，旨在實現心理治療的民主化。SoulSpeak 通過結合短期和長期語境的創新雙重記憶組件，通過檢索增強生成 (RAG) 來改進標準 LLM 啟用聊天機器人的能力，以提供個性化的回應，同時通過專用的隱私模組確保使用者隱私和親密性的保護。此外，它利用治療師與客戶互動的諮詢聊天資料集和各種提示技術，使生成的回應與心理治療方法保持一致。我們引入了兩個微調的 BERT 模型，以針對現有的 LLM 和人類治療師評估系統：對話式心理治療偏好模型 (CPPM) 用於模擬人類對回應的偏好，另一個用於評估對使用者輸入的回應相關性。CPPM 可用於訓練和評估與心理治療為重點的語言模型，而與 SoulSpeak 無關，有助於應對心理治療的受限資源。此外，還檢驗了雙重記憶組件的有效性及隱私模組的穩健性。我們的研究結果突出了通過提供結合傳統療法專業知識和 LLM 優勢的替代方案來增強心理保健的潛力和挑戰，為解決當前心理健康服務的可及性和個人化差距提供了一個有希望的方法。

##### **Surveying the Effects of Quality, Diversity, and Complexity in Synthetic Data From Large Language Models**
2412.02980v1 by Alex Havrilla, Andrew Dai, Laura O'Mahony, Koen Oostermeijer, Vera Zisler, Alon Albalak, Fabrizio Milo, Sharath Chandra Raparthy, Kanishk Gandhi, Baber Abbasi, Duy Phung, Maia Iyer, Dakota Mahan, Chase Blagden, Srishti Gureja, Mohammed Hamdy, Wen-Ding Li, Giovanni Paolini, Pawan Sasanka Ammanamanchi, Elliot Meyerson

Synthetic data generation with Large Language Models is a promising paradigm
for augmenting natural data over a nearly infinite range of tasks. Given this
variety, direct comparisons among synthetic data generation algorithms are
scarce, making it difficult to understand where improvement comes from and what
bottlenecks exist. We propose to evaluate algorithms via the makeup of
synthetic data generated by each algorithm in terms of data quality, diversity,
and complexity. We choose these three characteristics for their significance in
open-ended processes and the impact each has on the capabilities of downstream
models. We find quality to be essential for in-distribution model
generalization, diversity to be essential for out-of-distribution
generalization, and complexity to be beneficial for both. Further, we emphasize
the existence of Quality-Diversity trade-offs in training data and the
downstream effects on model performance. We then examine the effect of various
components in the synthetic data pipeline on each data characteristic. This
examination allows us to taxonomize and compare synthetic data generation
algorithms through the components they utilize and the resulting effects on
data QDC composition. This analysis extends into a discussion on the importance
of balancing QDC in synthetic data for efficient reinforcement learning and
self-improvement algorithms. Analogous to the QD trade-offs in training data,
often there exist trade-offs between model output quality and output diversity
which impact the composition of synthetic data. We observe that many models are
currently evaluated and optimized only for output quality, thereby limiting
output diversity and the potential for self-improvement. We argue that
balancing these trade-offs is essential to the development of future
self-improvement algorithms and highlight a number of works making progress in
this direction.

摘要：<paragraph>使用大型語言模型進行合成資料生成對於在幾乎無限範圍的任務中擴充自然資料而言是一種有前途的範例。鑒於此種多樣性，合成資料生成演算法之間的直接比較相當稀少，這使得難以理解進步的來源以及瓶頸在哪裡。我們提議透過每種演算法所產生的合成資料的組成，在資料品質、多樣性和複雜性方面評估演算法。我們選擇這三項特徵，是因為它們在開放式流程中具有重要意義，而且每項特徵都會對下游模型的能力產生影響。我們發現品質對於分配中模型的概化至關重要，多樣性對於分配外概化至關重要，而複雜性對於兩者都有利。此外，我們強調在訓練資料中存在品質多樣性權衡，以及對模型效能的下游影響。然後，我們檢查合成資料管道中各種組成對每個資料特徵的影響。此項檢查讓我們能夠透過它們所利用的組成和對資料 QDC 組成的影響，對合成資料生成演算法進行分類和比較。此分析延伸至討論在合成資料中平衡 QDC 以實現有效強化學習和自我改善演算法的重要性。類似於訓練資料中的 QD 權衡，模型輸出品質和輸出多樣性之間通常存在權衡，這會影響合成資料的組成。我們觀察到，目前許多模型僅針對輸出品質進行評估和最佳化，從而限制了輸出多樣性以及自我改善的潛力。我們認為，平衡這些權衡對於未來自我改善演算法的發展至關重要，並強調許多在這個方向上取得進展的作品。</paragraph>

##### **Theoretical limitations of multi-layer Transformer**
2412.02975v1 by Lijie Chen, Binghui Peng, Hongxun Wu

Transformers, especially the decoder-only variants, are the backbone of most
modern large language models; yet we do not have much understanding of their
expressive power except for the simple $1$-layer case.
  Due to the difficulty of analyzing multi-layer models, all previous work
relies on unproven complexity conjectures to show limitations for multi-layer
Transformers. In this work, we prove the first $\textit{unconditional}$ lower
bound against multi-layer decoder-only transformers. For any constant $L$, we
prove that any $L$-layer decoder-only transformer needs a polynomial model
dimension ($n^{\Omega(1)}$) to perform sequential composition of $L$ functions
over an input of $n$ tokens.
  As a consequence, our results give: (1) the first depth-width trade-off for
multi-layer transformers, exhibiting that the $L$-step composition task is
exponentially harder for $L$-layer models compared to $(L+1)$-layer ones; (2)
an unconditional separation between encoder and decoder, exhibiting a hard task
for decoders that can be solved by an exponentially shallower and smaller
encoder; (3) a provable advantage of chain-of-thought, exhibiting a task that
becomes exponentially easier with chain-of-thought.
  On the technical side, we propose the multi-party $\textit{autoregressive}$
$\textit{communication}$ $\textit{model}$ that captures the computation of a
decoder-only Transformer. We also introduce a new proof technique that finds a
certain $\textit{indistinguishable}$ $\textit{decomposition}$ of all possible
inputs iteratively for proving lower bounds in this model. We believe our new
communication model and proof technique will be helpful to further understand
the computational power of transformers.

摘要：<paragraph>Transformer，尤其是僅解碼器變體，是大多數現代大型語言模型的骨幹；然而，除了簡單的 $1$ 層案例之外，我們對它們的表達能力並沒有太多了解。
由於分析多層模型的難度，所有先前的研究都依賴於未經證實的複雜性猜想來顯示多層 Transformer 的限制。在這項研究中，我們證明了對於僅解碼器多層 Transformer 的第一個$\textit{無條件}$下界。對於任何常數 $L$，我們證明任何 $L$ 層僅解碼器 Transformer 需要多項式模型維度 ($n^{\Omega(1)}$) 來執行 $n$ 個 token 輸入的 $L$ 個函數的序列組成。
因此，我們的結果給出：(1) 多層 Transformer 的第一個深度寬度權衡，展示了對於 $L$ 層模型而言，$L$ 步驟組成任務比 $(L+1)$ 層模型難以指數級；(2) 編碼器和解碼器之間的無條件分離，展示了解碼器的一個困難任務，而這個任務可以通過指數級更淺和更小的編碼器來解決；(3) 思想鏈的可證明優勢，展示了一個隨著思想鏈而變得指數級更簡單的任務。
在技術方面，我們提出了多方$\textit{自迴歸}$$\textit{通信}$$\textit{模型}$，它捕獲了僅解碼器 Transformer 的計算。我們還引入了一種新的證明技術，該技術反覆尋找所有可能輸入的某個$\textit{不可區分}$$\textit{分解}$，以證明此模型中的下界。我們相信我們新的通信模型和證明技術有助於進一步了解 Transformer 的計算能力。</paragraph>

##### **3D Interaction Geometric Pre-training for Molecular Relational Learning**
2412.02957v1 by Namkyeong Lee, Yunhak Oh, Heewoong Noh, Gyoung S. Na, Minkai Xu, Hanchen Wang, Tianfan Fu, Chanyoung Park

Molecular Relational Learning (MRL) is a rapidly growing field that focuses
on understanding the interaction dynamics between molecules, which is crucial
for applications ranging from catalyst engineering to drug discovery. Despite
recent progress, earlier MRL approaches are limited to using only the 2D
topological structure of molecules, as obtaining the 3D interaction geometry
remains prohibitively expensive. This paper introduces a novel 3D geometric
pre-training strategy for MRL (3DMRL) that incorporates a 3D virtual
interaction environment, overcoming the limitations of costly traditional
quantum mechanical calculation methods. With the constructed 3D virtual
interaction environment, 3DMRL trains 2D MRL model to learn the overall 3D
geometric information of molecular interaction through contrastive learning.
Moreover, fine-grained interaction between molecules is learned through force
prediction loss, which is crucial in understanding the wide range of molecular
interaction processes. Extensive experiments on various tasks using real-world
datasets, including out-of-distribution and extrapolation scenarios,
demonstrate the effectiveness of 3DMRL, showing up to a 24.93\% improvement in
performance across 40 tasks.

摘要：分子關係學習 (MRL) 是快速成長的領域，專注於了解分子之間的互動動態，這對於從催化劑工程到藥物發現等應用至關重要。儘管最近有進展，但早期的 MRL 方法僅限於使用分子的 2D 拓撲結構，因為獲取 3D 交互幾何結構仍然非常昂貴。本文介紹了一種新穎的 3D 幾何預訓練策略，用於 MRL (3DMRL)，它結合了一個 3D 虛擬交互環境，克服了昂貴的傳統量子力學計算方法的限制。利用構建的 3D 虛擬交互環境，3DMRL 訓練 2D MRL 模型通過對比學習來學習分子交互的整體 3D 幾何資訊。此外，通過力預測損失學習分子之間的細粒度交互，這對於理解廣泛的分子交互過程至關重要。在使用真實世界資料集的各種任務上進行的廣泛實驗，包括分佈外和外推場景，證明了 3DMRL 的有效性，顯示在 40 個任務中的效能提升了 24.93%。

##### **Curriculum-style Data Augmentation for LLM-based Metaphor Detection**
2412.02956v1 by Kaidi Jia, Yanxia Wu, Rongsheng Li

Recently, utilizing large language models (LLMs) for metaphor detection has
achieved promising results. However, these methods heavily rely on the
capabilities of closed-source LLMs, which come with relatively high inference
costs and latency. To address this, we propose a method for metaphor detection
by fine-tuning open-source LLMs, effectively reducing inference costs and
latency with a single inference step. Furthermore, metaphor detection suffers
from a severe data scarcity problem, which hinders effective fine-tuning of
LLMs. To tackle this, we introduce Curriculum-style Data Augmentation (CDA).
Specifically, before fine-tuning, we evaluate the training data to identify
correctly predicted instances for fine-tuning, while incorrectly predicted
instances are used as seed data for data augmentation. This approach enables
the model to quickly learn simpler knowledge and progressively acquire more
complex knowledge, thereby improving performance incrementally. Experimental
results demonstrate that our method achieves state-of-the-art performance
across all baselines. Additionally, we provide detailed ablation studies to
validate the effectiveness of CDA.

摘要：<paragraph>最近，利用大型語言模型 (LLM) 進行隱喻偵測已獲得令人滿意的結果。然而，這些方法嚴重依賴閉源 LLM 的功能，而這會帶來相對高的推論成本和延遲。為了解決這個問題，我們提出了一種透過微調開源 LLM 來進行隱喻偵測的方法，有效地減少了單一推論步驟的推論成本和延遲。此外，隱喻偵測會遭受嚴重的資料稀少問題，這會阻礙 LLM 的有效微調。為了解決這個問題，我們引入了課程式資料擴充 (CDA)。具體來說，在微調之前，我們會評估訓練資料以找出正確預測的微調實例，而錯誤預測的實例則用作資料擴充的種子資料。這種方法讓模型能夠快速學習較簡單的知識，並逐步習得較複雜的知識，從而逐步提升效能。實驗結果證明，我們的模型在所有基準中都達到了最先進的效能。此外，我們提供了詳細的消融研究，以驗證 CDA 的有效性。</paragraph>

##### **Who Brings the Frisbee: Probing Hidden Hallucination Factors in Large Vision-Language Model via Causality Analysis**
2412.02946v1 by Po-Hsuan Huang, Jeng-Lin Li, Chin-Po Chen, Ming-Ching Chang, Wei-Chao Chen

Recent advancements in large vision-language models (LVLM) have significantly
enhanced their ability to comprehend visual inputs alongside natural language.
However, a major challenge in their real-world application is hallucination,
where LVLMs generate non-existent visual elements, eroding user trust. The
underlying mechanism driving this multimodal hallucination is poorly
understood. Minimal research has illuminated whether contexts such as sky,
tree, or grass field involve the LVLM in hallucinating a frisbee. We
hypothesize that hidden factors, such as objects, contexts, and semantic
foreground-background structures, induce hallucination. This study proposes a
novel causal approach: a hallucination probing system to identify these hidden
factors. By analyzing the causality between images, text prompts, and network
saliency, we systematically explore interventions to block these factors. Our
experimental findings show that a straightforward technique based on our
analysis can significantly reduce hallucinations. Additionally, our analyses
indicate the potential to edit network internals to minimize hallucinated
outputs.

摘要：大型視覺語言模型 (LVLM) 的最新進展顯著增強了它們理解自然語言和視覺輸入的能力。然而，在現實世界應用中的一個重大挑戰是幻覺，其中 LVLM 產生不存在的視覺元素，侵蝕了使用者的信任。驅動這種多模態幻覺的底層機制尚未被充分理解。很少有研究探討天空、樹木或草地等背景是否會讓 LVLM 產生飛盤的幻覺。我們假設物體、背景和語義前景背景結構等隱藏因素會誘發幻覺。本研究提出了一種新的因果方法：一種幻覺探測系統，用於識別這些隱藏因素。通過分析影像、文字提示和網路顯著性之間的因果關係，我們系統性地探索了阻止這些因素的干預措施。我們的實驗結果表明，基於我們分析的一種直接技術可以顯著減少幻覺。此外，我們的分析表明有潛力編輯網路內部結構以最小化產生幻覺的輸出。

##### **STDCformer: A Transformer-Based Model with a Spatial-Temporal Causal De-Confounding Strategy for Crowd Flow Prediction**
2412.02942v1 by Silu He, Peng Shen, Pingzhen Xu, Qinyao Luo, Haifeng Li

Existing works typically treat spatial-temporal prediction as the task of
learning a function $F$ to transform historical observations to future
observations. We further decompose this cross-time transformation into three
processes: (1) Encoding ($E$): learning the intrinsic representation of
observations, (2) Cross-Time Mapping ($M$): transforming past representations
into future representations, and (3) Decoding ($D$): reconstructing future
observations from the future representations. From this perspective,
spatial-temporal prediction can be viewed as learning $F = E \cdot M \cdot D$,
which includes learning the space transformations $\left\{{E},{D}\right\}$
between the observation space and the hidden representation space, as well as
the spatial-temporal mapping $M$ from future states to past states within the
representation space. This leads to two key questions: \textbf{Q1: What kind of
representation space allows for mapping the past to the future? Q2: How to
achieve map the past to the future within the representation space?} To address
Q1, we propose a Spatial-Temporal Backdoor Adjustment strategy, which learns a
Spatial-Temporal De-Confounded (STDC) representation space and estimates the
de-confounding causal effect of historical data on future data. This causal
relationship we captured serves as the foundation for subsequent
spatial-temporal mapping. To address Q2, we design a Spatial-Temporal Embedding
(STE) that fuses the information of temporal and spatial confounders, capturing
the intrinsic spatial-temporal characteristics of the representations.
Additionally, we introduce a Cross-Time Attention mechanism, which queries the
attention between the future and the past to guide spatial-temporal mapping.

摘要：<paragraph>現有的作品通常將時空預測視為學習函數 $F$ 的任務，以將歷史觀測值轉換為未來觀測值。我們進一步將這種跨時間轉換分解為三個過程：(1) 編碼 ($E$)：學習觀測值的內在表示，(2) 跨時間映射 ($M$)：將過去的表示轉換為未來的表示，以及 (3) 解碼 ($D$)：從未來的表示重建未來的觀測值。從這個角度來看，時空預測可以視為學習 $F = E \cdot M \cdot D$，其中包括學習觀測空間和隱藏表示空間之間的空間轉換 $\left\{{E},{D}\right\}$，以及表示空間內從未來狀態到過去狀態的時空映射 $M$。這導致了兩個關鍵問題：\textbf{Q1：哪種類型的表示空間允許將過去映射到未來？Q2：如何在表示空間內將過去映射到未來？} 為了回答 Q1，我們提出了時空後門調整策略，該策略學習時空去混淆 (STDC) 表示空間，並估計歷史數據對未來數據的去混淆因果效應。我們捕捉到的這種因果關係作為後續時空映射的基礎。為了回答 Q2，我們設計了一個時空嵌入 (STE)，它融合了時間和空間混淆因素的信息，捕捉了表示的內在時空特徵。此外，我們引入了一個跨時間注意力機制，它查詢未來和過去之間的注意力以指導時空映射。</paragraph>

##### **Dynamic Graph Neural Ordinary Differential Equation Network for Multi-modal Emotion Recognition in Conversation**
2412.02935v1 by Yuntao Shou, Tao Meng, Wei Ai, Keqin Li

Multimodal emotion recognition in conversation (MERC) refers to identifying
and classifying human emotional states by combining data from multiple
different modalities (e.g., audio, images, text, video, etc.). Most existing
multimodal emotion recognition methods use GCN to improve performance, but
existing GCN methods are prone to overfitting and cannot capture the temporal
dependency of the speaker's emotions. To address the above problems, we propose
a Dynamic Graph Neural Ordinary Differential Equation Network (DGODE) for MERC,
which combines the dynamic changes of emotions to capture the temporal
dependency of speakers' emotions, and effectively alleviates the overfitting
problem of GCNs. Technically, the key idea of DGODE is to utilize an adaptive
mixhop mechanism to improve the generalization ability of GCNs and use the
graph ODE evolution network to characterize the continuous dynamics of node
representations over time and capture temporal dependencies. Extensive
experiments on two publicly available multimodal emotion recognition datasets
demonstrate that the proposed DGODE model has superior performance compared to
various baselines. Furthermore, the proposed DGODE can also alleviate the
over-smoothing problem, thereby enabling the construction of a deep GCN
network.

摘要：多模态对话情感识别（MERC）是指通过结合来自多种不同模态（例如音频、图像、文本、视频等）的数据来识别和分类人类情感状态。大多数现有的多模态情感识别方法使用 GCN 来提高性能，但现有的 GCN 方法容易过拟合，并且无法捕捉说话人情感的时间依赖性。为了解决上述问题，我们提出了一种用于 MERC 的动态图神经常微分方程网络 (DGODE)，它结合了情感的动态变化来捕捉说话人情感的时间依赖性，并有效地缓解了 GCN 的过拟合问题。从技术上讲，DGODE 的关键思想是利用自适应混合机制来提高 GCN 的泛化能力，并使用图 ODE 演化网络来表征节点表示随时间变化的连续动态并捕捉时间依赖性。在两个公开的多模态情感识别数据集上进行的广泛实验表明，所提出的 DGODE 模型与各种基线相比具有优越的性能。此外，所提出的 DGODE 还可以缓解过度平滑问题，从而能够构建深度 GCN 网络。

##### **Panoptic Diffusion Models: co-generation of images and segmentation maps**
2412.02929v1 by Yinghan Long, Kaushik Roy

Recently, diffusion models have demonstrated impressive capabilities in
text-guided and image-conditioned image generation. However, existing diffusion
models cannot simultaneously generate a segmentation map of objects and a
corresponding image from the prompt. Previous attempts either generate
segmentation maps based on the images or provide maps as input conditions to
control image generation, limiting their functionality to given inputs.
Incorporating an inherent understanding of the scene layouts can improve the
creativity and realism of diffusion models. To address this limitation, we
present Panoptic Diffusion Model (PDM), the first model designed to generate
both images and panoptic segmentation maps concurrently. PDM bridges the gap
between image and text by constructing segmentation layouts that provide
detailed, built-in guidance throughout the generation process. This ensures the
inclusion of categories mentioned in text prompts and enriches the diversity of
segments within the background. We demonstrate the effectiveness of PDM across
two architectures: a unified diffusion transformer and a two-stream transformer
with a pretrained backbone. To facilitate co-generation with fewer sampling
steps, we incorporate a fast diffusion solver into PDM. Additionally, when
ground-truth maps are available, PDM can function as a text-guided
image-to-image generation model. Finally, we propose a novel metric for
evaluating the quality of generated maps and show that PDM achieves
state-of-the-art results in image generation with implicit scene control.

摘要：<paragraph>近期，扩散模型在文本引导和图像条件图像生成方面展示了令人印象深刻的能力。然而，现有的扩散模型无法同时从提示生成对象的分割图和对应的图像。先前的尝试要么基于图像生成分割图，要么将分割图作为输入条件来控制图像生成，从而将它们的功能限制在给定的输入上。
融入对场景布局的内在理解可以提高扩散模型的创造力和真实感。为了解决这一限制，我们提出了全景扩散模型（PDM），这是第一个旨在同时生成图像和全景分割图的模型。PDM 通过构建分割布局来弥合图像和文本之间的差距，这些布局在整个生成过程中提供了详细的内置指导。这确保了包含文本提示中提到的类别，并丰富了背景中片段的多样性。我们在两种架构中展示了 PDM 的有效性：一个统一的扩散转换器和一个具有预训练主干网络的两流转换器。为了促进使用更少的采样步骤进行共生成，我们在 PDM 中加入了一个快速扩散求解器。此外，当有 ground-truth 图时，PDM 可以用作文本引导的图像到图像生成模型。最后，我们提出了一种新颖的指标来评估生成图的质量，并表明 PDM 在图像生成中实现了最先进的结果，并具有隐式场景控制。</paragraph>

##### **Higher Order Transformers: Efficient Attention Mechanism for Tensor Structured Data**
2412.02919v1 by Soroush Omranpour, Guillaume Rabusseau, Reihaneh Rabbany

Transformers are now ubiquitous for sequence modeling tasks, but their
extension to multi-dimensional data remains a challenge due to the quadratic
cost of the attention mechanism. In this paper, we propose Higher-Order
Transformers (HOT), a novel architecture designed to efficiently process data
with more than two axes, i.e. higher-order tensors. To address the
computational challenges associated with high-order tensor attention, we
introduce a novel Kronecker factorized attention mechanism that reduces the
attention cost to quadratic in each axis' dimension, rather than quadratic in
the total size of the input tensor. To further enhance efficiency, HOT
leverages kernelized attention, reducing the complexity to linear. This
strategy maintains the model's expressiveness while enabling scalable attention
computation. We validate the effectiveness of HOT on two high-dimensional
tasks, including multivariate time series forecasting, and 3D medical image
classification. Experimental results demonstrate that HOT achieves competitive
performance while significantly improving computational efficiency, showcasing
its potential for tackling a wide range of complex, multi-dimensional data.

摘要：變形金剛現在普遍用於序列建模任務，但由於注意力機制的二次方成本，它們擴展到多維數據仍然是一個挑戰。在本文中，我們提出了高階變形金剛 (HOT)，這是一種新穎的架構，旨在有效處理具有兩個以上軸線的數據，即高階張量。為了應對與高階張量注意力相關的計算挑戰，我們引入了一種新穎的克羅內克分解注意力機制，該機制將注意力成本降低到每個軸線維度的二次方，而不是輸入張量的總大小的二次方。為了進一步提高效率，HOT 利用核化注意力，將複雜度降低到線性。此策略保持了模型的表現力，同時實現了可擴展的注意力計算。我們在兩個高維任務上驗證了 HOT 的有效性，包括多元時間序列預測和 3D 醫學影像分類。實驗結果表明，HOT 在顯著提高計算效率的同時實現了競爭力的效能，展示了其應對各種複雜的多維數據的潛力。

##### **Single-Cell Omics Arena: A Benchmark Study for Large Language Models on Cell Type Annotation Using Single-Cell Data**
2412.02915v1 by Junhao Liu, Siwei Xu, Lei Zhang, Jing Zhang

Over the past decade, the revolution in single-cell sequencing has enabled
the simultaneous molecular profiling of various modalities across thousands of
individual cells, allowing scientists to investigate the diverse functions of
complex tissues and uncover underlying disease mechanisms. Among all the
analytical steps, assigning individual cells to specific types is fundamental
for understanding cellular heterogeneity. However, this process is usually
labor-intensive and requires extensive expert knowledge. Recent advances in
large language models (LLMs) have demonstrated their ability to efficiently
process and synthesize vast corpora of text to automatically extract essential
biological knowledge, such as marker genes, potentially promoting more
efficient and automated cell type annotations. To thoroughly evaluate the
capability of modern instruction-tuned LLMs in automating the cell type
identification process, we introduce SOAR, a comprehensive benchmarking study
of LLMs for cell type annotation tasks in single-cell genomics. Specifically,
we assess the performance of 8 instruction-tuned LLMs across 11 datasets,
spanning multiple cell types and species. Our study explores the potential of
LLMs to accurately classify and annotate cell types in single-cell RNA
sequencing (scRNA-seq) data, while extending their application to multiomics
data through cross-modality translation. Additionally, we evaluate the
effectiveness of chain-of-thought (CoT) prompting techniques in generating
detailed biological insights during the annotation process. The results
demonstrate that LLMs can provide robust interpretations of single-cell data
without requiring additional fine-tuning, advancing the automation of cell type
annotation in genomics research.

摘要：<paragraph>在過去十年中，單細胞定序的革命性發展已經能夠
同時對數千個單一細胞進行各種模式的分子分析，讓科學家得以研究
複雜組織的多元功能並揭示潛在的疾病機制。在所有分析步驟中，
將單一細胞分配到特定類型對於了解細胞異質性至關重要。然而，
這個過程通常需要大量人力，並且需要廣泛的專業知識。大型語言
模型 (LLM) 的最新進展已證明它們能夠有效處理和綜合大量的文字
語料庫，以自動提取基本的生物知識，例如標記基因，潛在地促進更
有效率且自動化的細胞類型註解。為了徹底評估現代指令調整 LLM
在自動化細胞類型識別過程中的能力，我們引入了 SOAR，這是一項
針對單細胞基因組學中細胞類型註解任務的 LLM 全面基準研究。具體
來說，我們評估了 8 個指令調整 LLM 在 11 個數據集中的性能，涵蓋
多種細胞類型和物種。我們的研究探討了 LLM 在單細胞 RNA 定序
(scRNA-seq) 資料中準確分類和註解細胞類型的潛力，同時透過跨模
態轉譯將其應用擴展到多組學資料。此外，我們評估了思考鏈 (CoT)
提示技術在註解過程中產生詳細生物見解的有效性。結果表明，LLM
可以對單細胞資料提供強健的詮釋，而不需要額外的微調，推動了
基因組學研究中細胞類型註解的自動化。</paragraph>

##### **Does Few-Shot Learning Help LLM Performance in Code Synthesis?**
2412.02906v1 by Derek Xu, Tong Xie, Botao Xia, Haoyu Li, Yunsheng Bai, Yizhou Sun, Wei Wang

Large language models (LLMs) have made significant strides at code generation
through improved model design, training, and chain-of-thought. However,
prompt-level optimizations remain an important yet under-explored aspect of
LLMs for coding. This work focuses on the few-shot examples present in most
code generation prompts, offering a systematic study on whether few-shot
examples improve LLM's coding capabilities, which few-shot examples have the
largest impact, and how to select impactful examples. Our work offers 2
approaches for selecting few-shot examples, a model-free method,
CODEEXEMPLAR-FREE, and a model-based method, CODEEXEMPLAR-BASED. The 2 methods
offer a trade-off between improved performance and reliance on training data
and interpretability. Both methods significantly improve CodeLlama's coding
ability across the popular HumanEval+ coding benchmark. In summary, our work
provides valuable insights into how to pick few-shot examples in code
generation prompts to improve LLM code generation capabilities.

摘要：大型語言模型（LLM）透過改善模型設計、訓練和思考鏈，在程式碼生成方面取得重大進展。然而，提示層級最佳化仍然是 LLM 編碼的重要但尚未充分探索的方面。這項工作重點在於大多數程式碼生成提示中出現的少數範例，提供一項系統性研究，探討少數範例是否能提升 LLM 的編碼能力，哪些少數範例影響最大，以及如何選擇有影響力的範例。我們的研究提供 2 種選擇少數範例的方法，一種是無模型方法，CODEEXEMPLAR-FREE，一種是基於模型的方法，CODEEXEMPLAR-BASED。這 2 種方法在改善效能和依賴訓練資料及可解釋性之間取得權衡。這兩種方法都大幅提升 CodeLlama 在熱門 HumanEval+ 編碼基準中的編碼能力。總之，我們的研究提供有價值的見解，說明如何在程式碼生成提示中挑選少數範例，以提升 LLM 程式碼生成能力。

##### **Enhancing Trust in Large Language Models with Uncertainty-Aware Fine-Tuning**
2412.02904v1 by Ranganath Krishnan, Piyush Khanna, Omesh Tickoo

Large language models (LLMs) have revolutionized the field of natural
language processing with their impressive reasoning and question-answering
capabilities. However, these models are sometimes prone to generating
credible-sounding but incorrect information, a phenomenon known as LLM
hallucinations. Reliable uncertainty estimation in LLMs is essential for
fostering trust in their generated responses and serves as a critical tool for
the detection and prevention of erroneous or hallucinated outputs. To achieve
reliable and well-calibrated uncertainty quantification in open-ended and
free-form natural language generation, we propose an uncertainty-aware
fine-tuning approach for LLMs. This approach enhances the model's ability to
provide reliable uncertainty estimates without compromising accuracy, thereby
guiding them to produce more trustworthy responses. We introduce a novel
uncertainty-aware causal language modeling loss function, grounded in the
principles of decision theory. Through rigorous evaluation on multiple
free-form question-answering datasets and models, we demonstrate that our
uncertainty-aware fine-tuning approach yields better calibrated uncertainty
estimates in natural language generation tasks than fine-tuning with the
standard causal language modeling loss. Furthermore, the experimental results
show that the proposed method significantly improves the model's ability to
detect hallucinations and identify out-of-domain prompts.

摘要：大型語言模型 (LLM) 以其令人印象深刻的推理和問答能力，徹底改變了自然語言處理領域。然而，這些模型有時容易產生聽起來可信但錯誤的資訊，這種現象稱為 LLM 幻覺。LLM 中可靠的不確定性估計對於建立對其生成回應的信任至關重要，並作為檢測和預防錯誤或幻覺輸出的關鍵工具。為了在開放式和自由形式的自然語言生成中實現可靠且校準良好的不確定性量化，我們提出了一種針對 LLM 的不確定性感知微調方法。這種方法增強了模型提供可靠不確定性估計的能力，同時不影響準確性，從而引導它們產生更可信的回應。我們引入了一種新穎的不確定性感知因果語言建模損失函數，它基於決策理論的原理。通過對多個自由形式問答資料集和模型進行嚴格評估，我們證明了我們的不確定性感知微調方法在自然語言生成任務中產生了比使用標準因果語言建模損失進行微調更好的校準不確定性估計。此外，實驗結果表明，所提出的方法顯著提高了模型檢測幻覺和識別域外提示的能力。

##### **MLD-EA: Check and Complete Narrative Coherence by Introducing Emotions and Actions**
2412.02897v1 by Jinming Zhang, Yunfei Long

Narrative understanding and story generation are critical challenges in
natural language processing (NLP), with much of the existing research focused
on summarization and question-answering tasks. While previous studies have
explored predicting plot endings and generating extended narratives, they often
neglect the logical coherence within stories, leaving a significant gap in the
field. To address this, we introduce the Missing Logic Detector by Emotion and
Action (MLD-EA) model, which leverages large language models (LLMs) to identify
narrative gaps and generate coherent sentences that integrate seamlessly with
the story's emotional and logical flow. The experimental results demonstrate
that the MLD-EA model enhances narrative understanding and story generation,
highlighting LLMs' potential as effective logic checkers in story writing with
logical coherence and emotional consistency. This work fills a gap in NLP
research and advances border goals of creating more sophisticated and reliable
story-generation systems.

摘要：敘事理解和故事生成是自然語言處理 (NLP) 中的重大挑戰，現有許多研究專注於摘要和問答任務。儘管過往的研究已探討預測情節結局和生成延伸敘事，但它們常常忽略故事中的邏輯一致性，在這個領域中留下一個顯著的缺口。為了解決這個問題，我們引入了情緒和動作的遺失邏輯偵測器 (MLD-EA) 模型，它利用大型語言模型 (LLM) 來識別敘事缺口，並生成與故事的情緒和邏輯流暢整合的連貫句子。實驗結果證明，MLD-EA 模型增強了敘事理解和故事生成，突顯了 LLM 作為故事寫作中有效邏輯檢查器的潛力，具備邏輯一致性和情緒一致性。這項工作填補了 NLP 研究中的缺口，並推動了創造更精緻且可靠的故事生成系統的邊界目標。

##### **Removing Spurious Correlation from Neural Network Interpretations**
2412.02893v1 by Milad Fotouhi, Mohammad Taha Bahadori, Oluwaseyi Feyisetan, Payman Arabshahi, David Heckerman

The existing algorithms for identification of neurons responsible for
undesired and harmful behaviors do not consider the effects of confounders such
as topic of the conversation. In this work, we show that confounders can create
spurious correlations and propose a new causal mediation approach that controls
the impact of the topic. In experiments with two large language models, we
study the localization hypothesis and show that adjusting for the effect of
conversation topic, toxicity becomes less localized.

摘要：現有的用於識別對不良和有害行為負責的神經元演算法並未考慮混淆因素的影響，例如對話主題。在這項工作中，我們表明混淆因素會產生虛假的相關性，並提出了一種新的因果中介方法來控制主題的影響。在使用兩個大型語言模型進行的實驗中，我們研究了局部化假說，並表明調整對話主題的影響後，毒性會降低局部化。

##### **TDD-Bench Verified: Can LLMs Generate Tests for Issues Before They Get Resolved?**
2412.02883v1 by Toufique Ahmed, Martin Hirzel, Rangeet Pan, Avraham Shinnar, Saurabh Sinha

Test-driven development (TDD) is the practice of writing tests first and
coding later, and the proponents of TDD expound its numerous benefits. For
instance, given an issue on a source code repository, tests can clarify the
desired behavior among stake-holders before anyone writes code for the
agreed-upon fix. Although there has been a lot of work on automated test
generation for the practice "write code first, test later", there has been
little such automation for TDD. Ideally, tests for TDD should be fail-to-pass
(i.e., fail before the issue is resolved and pass after) and have good adequacy
with respect to covering the code changed during issue resolution. This paper
introduces TDD-Bench Verified, a high-quality benchmark suite of 449 issues
mined from real-world GitHub code repositories. The benchmark's evaluation
harness runs only relevant tests in isolation for simple yet accurate coverage
measurements, and the benchmark's dataset is filtered both by human judges and
by execution in the harness. This paper also presents Auto-TDD, an LLM-based
solution that takes as input an issue description and a codebase (prior to
issue resolution) and returns as output a test that can be used to validate the
changes made for resolving the issue. Our evaluation shows that Auto-TDD yields
a better fail-to-pass rate than the strongest prior work while also yielding
high coverage adequacy. Overall, we hope that this work helps make developers
more productive at resolving issues while simultaneously leading to more robust
fixes.

摘要：測試驅動開發 (TDD) 是一種先撰寫測試再編寫程式碼的做法，而 TDD 的支持者則闡述了它的許多好處。例如，給定原始程式碼儲存庫中的問題，測試可以在任何人為商定的修正程式撰寫程式碼之前，釐清利害關係人之間所需行為。儘管在「先撰寫程式碼，後測試」的做法中，已經有許多關於自動化測試產生的工作，但 TDD 的這種自動化卻很少。理想情況下，TDD 的測試應該是失敗到通過（即在問題解決之前失敗，之後通過），並且在涵蓋問題解決期間變更的程式碼方面具有良好的充分性。本文介紹了 TDD-Bench Verified，這是一個從真實世界的 GitHub 程式碼儲存庫中挖掘出的 449 個問題的高品質基準測試套件。基準測試的評估工具僅針對簡單但準確的涵蓋範圍測量，在隔離環境中執行相關測試，並且基準測試的資料集是由人工評審和在工具中執行所篩選出來的。本文還提出了 Auto-TDD，這是一個基於 LLM 的解決方案，它以問題描述和程式碼庫（在問題解決之前）作為輸入，並回傳一個可以用來驗證為了解決問題而進行的變更的測試。我們的評估顯示，Auto-TDD 產生比最強的前期工作更好的失敗到通過率，同時也產生了很高的涵蓋率。總的來說，我們希望這項工作有助於讓開發人員在解決問題時更有效率，同時也能帶來更強健的修正。

##### **Modeling and Discovering Direct Causes for Predictive Models**
2412.02878v1 by Yizuo Chen, Amit Bhatia

We introduce a causal modeling framework that captures the input-output
behavior of predictive models (e.g., machine learning models) by representing
it using causal graphs. The framework enables us to define and identify
features that directly cause the predictions, which has broad implications for
data collection and model evaluation. We show two assumptions under which the
direct causes can be discovered from data, one of which further simplifies the
discovery process. In addition to providing sound and complete algorithms, we
propose an optimization technique based on an independence rule that can be
integrated with the algorithms to speed up the discovery process both
theoretically and empirically.

摘要：我們引入一個因果模型架構，它透過使用因果圖表，來捕捉預測模型（例如機器學習模型）的輸入輸出行為。這個架構讓我們能夠定義和找出直接導致預測的功能，這對於資料收集和模型評估有廣泛的影響。我們展示了兩個假設，在這些假設下，可以直接從資料中找出原因，其中一個進一步簡化了發現的過程。除了提供健全且完整的演算法之外，我們還提出一個基於獨立性規則的最佳化技術，它可以與演算法整合，在理論上和經驗上加速發現的過程。

##### **Constrained Identifiability of Causal Effects**
2412.02869v1 by Yizuo Chen, Adnan Darwiche

We study the identification of causal effects in the presence of different
types of constraints (e.g., logical constraints) in addition to the causal
graph. These constraints impose restrictions on the models (parameterizations)
induced by the causal graph, reducing the set of models considered by the
identifiability problem. We formalize the notion of constrained
identifiability, which takes a set of constraints as another input to the
classical definition of identifiability. We then introduce a framework for
testing constrained identifiability by employing tractable Arithmetic Circuits
(ACs), which enables us to accommodate constraints systematically. We show that
this AC-based approach is at least as complete as existing algorithms (e.g.,
do-calculus) for testing classical identifiability, which only assumes the
constraint of strict positivity. We use examples to demonstrate the
effectiveness of this AC-based approach by showing that unidentifiable causal
effects may become identifiable under different types of constraints.

摘要：我們研究在因果圖之外，存在不同類型約束（例如邏輯約束）的情況下，因果效應的識別。這些約束對因果圖所引發的模型（參數化）施加限制，減少識別問題所考慮的模型集。我們將受約束識別的概念形式化，這將一組約束作為可識別性的經典定義的另一個輸入。然後，我們引入一個測試受約束識別的框架，通過使用易於處理的算術電路 (AC) 來實現，這使我們能夠系統地適應約束。我們表明，這種基於 AC 的方法至少與現有的演算法（例如，do 演算）一樣完整，用於測試經典可識別性，這僅假設嚴格正定的約束。我們使用範例來證明基於 AC 的方法的有效性，方法是表明不可識別的因果效應在不同類型的約束下可能變得可識別。

##### **A Novel Compact LLM Framework for Local, High-Privacy EHR Data Applications**
2412.02868v1 by Yixiang Qu, Yifan Dai, Shilin Yu, Pradham Tanikella, Travis Schrank, Trevor Hackman, Didong Li, Di Wu

Large Language Models (LLMs) have shown impressive capabilities in natural
language processing, yet their use in sensitive domains like healthcare,
particularly with Electronic Health Records (EHR), faces significant challenges
due to privacy concerns and limited computational resources. This paper
presents a compact LLM framework designed for local deployment in settings with
strict privacy requirements and limited access to high-performance GPUs. We
introduce a novel preprocessing technique that uses information extraction
methods, e.g., regular expressions, to filter and emphasize critical
information in clinical notes, enhancing the performance of smaller LLMs on EHR
data. Our framework is evaluated using zero-shot and few-shot learning
paradigms on both private and publicly available (MIMIC-IV) datasets, and we
also compare its performance with fine-tuned LLMs on the MIMIC-IV dataset. The
results demonstrate that our preprocessing approach significantly boosts the
prediction accuracy of smaller LLMs, making them suitable for high-privacy,
resource-constrained applications. This study offers valuable insights into
optimizing LLM performance for sensitive, data-intensive tasks while addressing
computational and privacy limitations.

摘要：大型語言模型 (LLM) 在自然語言處理方面展現出令人印象深刻的能力，然而它們在醫療保健等敏感領域的使用，特別是電子健康紀錄 (EHR)，由於隱私問題和有限的運算資源而面臨重大挑戰。本文提出了一個緊湊的 LLM 框架，旨在在具有嚴格隱私要求和有限使用高性能 GPU 的環境中進行本地部署。我們引入了一種新穎的預處理技術，它使用資訊萃取方法，例如正規表示法，來過濾和強調臨床筆記中的關鍵資訊，增強較小 LLM 在 EHR 資料上的效能。我們的框架使用零次學習和少次學習範例在私人和公開可用的 (MIMIC-IV) 資料集上進行評估，我們也比較它在 MIMIC-IV 資料集上與微調 LLM 的效能。結果表明，我們的預處理方法顯著提升了較小 LLM 的預測準確度，使其適用於高度隱私、資源受限的應用程式。這項研究提供了寶貴的見解，用於最佳化 LLM 效能以應對敏感、資料密集型任務，同時解決運算和隱私限制。

##### **Unpaired Modality Translation for Pseudo Labeling of Histology Images**
2412.02858v1 by Arthur Boschet, Armand Collin, Nishka Katoch, Julien Cohen-Adad

The segmentation of histological images is critical for various biomedical
applications, yet the lack of annotated data presents a significant challenge.
We propose a microscopy pseudo labeling pipeline utilizing unsupervised image
translation to address this issue. Our method generates pseudo labels by
translating between labeled and unlabeled domains without requiring prior
annotation in the target domain. We evaluate two pseudo labeling strategies
across three image domains increasingly dissimilar from the labeled data,
demonstrating their effectiveness. Notably, our method achieves a mean Dice
score of $0.736 \pm 0.005$ on a SEM dataset using the tutoring path, which
involves training a segmentation model on synthetic data created by translating
the labeled dataset (TEM) to the target modality (SEM). This approach aims to
accelerate the annotation process by providing high-quality pseudo labels as a
starting point for manual refinement.

摘要：組織切片影像的分割對於各種生物醫學應用至關重要，然而缺乏註解資料卻是一個重大的挑戰。
我們提出一個利用非監督式影像轉換的顯微鏡偽標籤處理流程來解決這個問題。我們的技術透過在標籤和未標籤網域間進行轉換來產生偽標籤，而不需要在目標網域中進行事先註解。我們在三個與標籤資料越來越不類似的影像網域中評估了兩種偽標籤策略，並證明了它們的有效性。值得注意的是，我們的技術在使用輔導路徑的 SEM 資料集上達到了平均 Dice 分數 $0.736 \pm 0.005$，這包括在合成資料上訓練分割模型，該合成資料是透過將標籤資料集 (TEM) 轉換到目標模式 (SEM) 而建立的。此方法旨在透過提供高品質的偽標籤作為人工精修的起點，來加速註解程序。

##### **FLAME 3 Dataset: Unleashing the Power of Radiometric Thermal UAV Imagery for Wildfire Management**
2412.02831v1 by Bryce Hopkins, Leo ONeill, Michael Marinaccio, Eric Rowell, Russell Parsons, Sarah Flanary, Irtija Nazim, Carl Seielstad, Fatemeh Afghah

The increasing accessibility of radiometric thermal imaging sensors for
unmanned aerial vehicles (UAVs) offers significant potential for advancing
AI-driven aerial wildfire management. Radiometric imaging provides per-pixel
temperature estimates, a valuable improvement over non-radiometric data that
requires irradiance measurements to be converted into visible images using RGB
color palettes. Despite its benefits, this technology has been underutilized
largely due to a lack of available data for researchers. This study addresses
this gap by introducing methods for collecting and processing synchronized
visual spectrum and radiometric thermal imagery using UAVs at prescribed fires.
The included imagery processing pipeline drastically simplifies and partially
automates each step from data collection to neural network input. Further, we
present the FLAME 3 dataset, the first comprehensive collection of side-by-side
visual spectrum and radiometric thermal imagery of wildland fires. Building on
our previous FLAME 1 and FLAME 2 datasets, FLAME 3 includes radiometric thermal
Tag Image File Format (TIFFs) and nadir thermal plots, providing a new data
type and collection method. This dataset aims to spur a new generation of
machine learning models utilizing radiometric thermal imagery, potentially
trivializing tasks such as aerial wildfire detection, segmentation, and
assessment. A single-burn subset of FLAME 3 for computer vision applications is
available on Kaggle with the full 6 burn set available to readers upon request.

摘要：無人機（UAV）的放射熱影像感測器越來越普及，為推進人工智慧驅動的空中野火管理提供了巨大的潛力。放射熱影像提供每個像素的溫度估計值，這比非放射熱數據的寶貴改進，後者需要將輻照度測量值轉換為使用 RGB 調色板的可見影像。儘管有這些優點，但由於研究人員缺乏可用的數據，這項技術的使用率一直偏低。本研究透過介紹使用無人機在規定的火災中收集和處理同步可見光譜和放射熱影像的方法來解決這個差距。所包含的影像處理管道大幅簡化並部分自動化從數據收集到神經網路輸入的每一個步驟。此外，我們展示了 FLAME 3 資料集，這是第一個並排收集野生火災的可見光譜和放射熱影像的綜合資料集。FLAME 3 建構在我們之前的 FLAME 1 和 FLAME 2 資料集之上，包含放射熱標籤影像檔案格式 (TIFF) 和天底熱區塊，提供新的資料類型和收集方法。此資料集旨在激發新一代機器學習模型，利用放射熱影像，潛在地簡化空中野火偵測、分割和評估等任務。FLAME 3 的單次燃燒子集可供電腦視覺應用程式在 Kaggle 上使用，而完整的 6 次燃燒設定可應讀者要求提供。

##### **RARE: Retrieval-Augmented Reasoning Enhancement for Large Language Models**
2412.02830v1 by Hieu Tran, Zonghai Yao, Junda Wang, Yifan Zhang, Zhichao Yang, Hong Yu

This work introduces RARE (Retrieval-Augmented Reasoning Enhancement), a
versatile extension to the mutual reasoning framework (rStar), aimed at
enhancing reasoning accuracy and factual integrity across large language models
(LLMs) for complex, knowledge-intensive tasks such as commonsense and medical
reasoning. RARE incorporates two innovative actions within the Monte Carlo Tree
Search (MCTS) framework: A6, which generates search queries based on the
initial problem statement, performs information retrieval using those queries,
and augments reasoning with the retrieved data to formulate the final answer;
and A7, which leverages information retrieval specifically for generated
sub-questions and re-answers these sub-questions with the relevant contextual
information. Additionally, a Retrieval-Augmented Factuality Scorer is proposed
to replace the original discriminator, prioritizing reasoning paths that meet
high standards of factuality. Experimental results with LLaMA 3.1 show that
RARE enables open-source LLMs to achieve competitive performance with top
open-source models like GPT-4 and GPT-4o. This research establishes RARE as a
scalable solution for improving LLMs in domains where logical coherence and
factual integrity are critical.

摘要：這項工作介紹了 RARE（檢索增強推理強化），這是對相互推理架構 (rStar) 的多功能擴充，旨在增強大型語言模型 (LLM) 在常識和醫學推理等複雜、知識密集型任務的推理準確性和事實完整性。RARE 在蒙地卡羅樹搜尋 (MCTS) 架構中包含兩個創新的動作：A6，它根據初始問題陳述產生搜尋查詢，使用這些查詢執行資訊檢索，並使用檢索到的資料擴充推理以制定最終答案；以及 A7，它特別針對生成的子問題利用資訊檢索，並使用相關的上下文資訊重新回答這些子問題。此外，還提出了檢索增強事實評分器來取代原始的判別器，優先考慮符合高事實標準的推理路徑。與 LLaMA 3.1 的實驗結果顯示，RARE 能讓開源 LLM 達到與 GPT-4 和 GPT-4o 等頂尖開源模型競爭的效能。這項研究將 RARE 建立為一個可擴充的解決方案，用於改善在邏輯連貫性和事實完整性至關重要的領域中的 LLM。

##### **Minimization of Boolean Complexity in In-Context Concept Learning**
2412.02823v1 by Leroy Z. Wang, R. Thomas McCoy, Shane Steinert-Threlkeld

What factors contribute to the relative success and corresponding
difficulties of in-context learning for Large Language Models (LLMs)? Drawing
on insights from the literature on human concept learning, we test LLMs on
carefully designed concept learning tasks, and show that task performance
highly correlates with the Boolean complexity of the concept. This suggests
that in-context learning exhibits a learning bias for simplicity in a way
similar to humans.

摘要：哪些因素促成了大型語言模型 (LLM) 的情境學習的相對成功和相應的難度？利用人類概念學習文獻中的見解，我們在精心設計的概念學習任務中測試了 LLM，並表明任務表現與概念的布林複雜度高度相關。這表明情境學習表現出類似於人類的簡化學習偏見。

##### **CNNSum: Exploring Long-Conext Summarization with Large Language Models in Chinese Novels**
2412.02819v1 by Lingxiao Wei, He Yan, Xiangju Lu, Junmin Zhu, Jun Wang, Wei Zhang

Large Language Models (LLMs) have been well-researched in many long-context
tasks. However, due to high annotation costs, high-quality long-context summary
datasets for training or evaluation are scarce, limiting further research. In
this work, we introduce CNNSum, a new multi-scale Chinese long-context novel
summarization benchmark, including four subsets, length covering
16k\textasciitilde128k, 695 samples in total, the annotations are human-driven.
We evaluate commercial and open-source models on CNNSum and conduct a detailed
analysis. Based on the observations, we further conduct fine-tuning exploration
with short-context summary data. In our study: (1) GPT-4o underperformed, due
to excessive subjective commentary. (2) Currently, long-context summarization
mainly relies on memory ability, small LLMs with stable longer context lengths
are the most cost-effective. Using long data concatenated from short-context
summaries makes a significant improvement. (3) Prompt templates may cause a
large performance gap but can be mitigated through fine-tuning. (4) Fine-tuned
Chat or Instruction versions may harm the Base model and further fine-tuning
cannot bridge performance gap. (5) while models with RoPE base scaling exhibit
strong extrapolation potential, their performance may vary significantly when
combined with other interpolation methods and need careful selection. (6)
CNNSum provides more reliable and insightful evaluation results than other
benchmarks. We release CNNSum to advance research in this field.

摘要：<paragraph>大型語言模型 (LLM) 已在許多長語境任務中獲得充分研究。然而，由於標註成本高昂，用於訓練或評估的高品質長語境摘要資料集稀少，限制了進一步的研究。在這項工作中，我們介紹了 CNNSum，一個新的多尺度中文長語境小說摘要基準，包括四個子集，長度涵蓋 16k\textasciitilde128k，總共 695 個樣本，標註是由人工驅動的。我們評估了 CNNSum 上的商業和開源模型，並進行了詳細的分析。根據觀察結果，我們進一步使用短語境摘要資料進行微調探索。在我們的研究中：(1) GPT-4o 表現不佳，因為過度的主觀評論。(2) 目前，長語境摘要主要依賴記憶能力，具有穩定較長語境長度的小型 LLM 最具成本效益。使用從短語境摘要串接而成的長資料可以顯著提升。(3) 提示範本可能會導致很大的效能差距，但可以透過微調來減輕。(4) 微調的聊天或指令版本可能會損害基礎模型，進一步的微調無法彌合效能差距。(5) 雖然具有 RoPE 基礎縮放的模型展現出強大的外推潛力，但它們與其他內插方法結合使用時，效能可能會顯著變化，需要仔細選擇。(6) CNNSum 提供比其他基準更可靠且有見地的評估結果。我們發布 CNNSum 以推動此領域的研究。</paragraph>

##### **Gaussian Splatting Under Attack: Investigating Adversarial Noise in 3D Objects**
2412.02803v1 by Abdurrahman Zeybey, Mehmet Ergezer, Tommy Nguyen

3D Gaussian Splatting has advanced radiance field reconstruction, enabling
high-quality view synthesis and fast rendering in 3D modeling. While
adversarial attacks on object detection models are well-studied for 2D images,
their impact on 3D models remains underexplored. This work introduces the
Masked Iterative Fast Gradient Sign Method (M-IFGSM), designed to generate
adversarial noise targeting the CLIP vision-language model. M-IFGSM
specifically alters the object of interest by focusing perturbations on masked
regions, degrading the performance of CLIP's zero-shot object detection
capability when applied to 3D models. Using eight objects from the Common
Objects 3D (CO3D) dataset, we demonstrate that our method effectively reduces
the accuracy and confidence of the model, with adversarial noise being nearly
imperceptible to human observers. The top-1 accuracy in original model renders
drops from 95.4\% to 12.5\% for train images and from 91.2\% to 35.4\% for test
images, with confidence levels reflecting this shift from true classification
to misclassification, underscoring the risks of adversarial attacks on 3D
models in applications such as autonomous driving, robotics, and surveillance.
The significance of this research lies in its potential to expose
vulnerabilities in modern 3D vision models, including radiance fields,
prompting the development of more robust defenses and security measures in
critical real-world applications.

摘要：<paragraph>3D 高斯散射提升了輻照場重建，實現了 3D 建模中的高品質視圖合成和快速渲染。儘管對物體檢測模型的對抗攻擊在 2D 圖像中得到了很好的研究，但它們對 3D 模型的影響仍未得到充分探索。這項工作引入了蒙版迭代快速梯度符號方法 (M-IFGSM)，旨在產生針對 CLIP 視覺語言模型的對抗噪聲。M-IFGSM 通過將擾動集中在蒙版區域來專門改變感興趣的物體，從而降低 CLIP 零次物體檢測能力在應用於 3D 模型時的性能。使用 Common Objects 3D (CO3D) 數據集中的八個物體，我們證明了我們的方法有效地降低了模型的準確性和置信度，而對抗噪聲對人類觀察者來說幾乎是不可察覺的。原始模型渲染中的前 1 準確率從訓練圖像的 95.4% 降至 12.5%，從測試圖像的 91.2% 降至 35.4%，置信度反映了這種從正確分類到錯誤分類的轉變，強調了對抗攻擊對 3D 的風險在自動駕駛、機器人和監控等應用中的模型。這項研究的意義在於它有可能揭示現代 3D 視覺模型（包括輻照場）中的漏洞，促使在關鍵的現實世界應用中開發更強大的防禦和安全措施。</paragraph>

