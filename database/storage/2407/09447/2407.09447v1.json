{"2407.09447": {"publish_time": "2024-07-12", "title": "ASTPrompter: Weakly Supervised Automated Language Model Red-Teaming to Identify Likely Toxic Prompts", "paper_summary": "Typical schemes for automated red-teaming large language models (LLMs) focus\non discovering prompts that trigger a frozen language model (the defender) to\ngenerate toxic text. This often results in the prompting model (the adversary)\nproducing text that is unintelligible and unlikely to arise. Here, we propose a\nreinforcement learning formulation of the LLM red-teaming task which allows us\nto discover prompts that both (1) trigger toxic outputs from a frozen defender\nand (2) have low perplexity as scored by the defender. We argue these cases are\nmost pertinent in a red-teaming setting because of their likelihood to arise\nduring normal use of the defender model. We solve this formulation through a\nnovel online and weakly supervised variant of Identity Preference Optimization\n(IPO) on GPT-2 and GPT-2 XL defenders. We demonstrate that our policy is\ncapable of generating likely prompts that also trigger toxicity. Finally, we\nqualitatively analyze learned strategies, trade-offs of likelihood and\ntoxicity, and discuss implications. Source code is available for this project\nat: https://github.com/sisl/ASTPrompter/.", "paper_summary_zh": "\u5178\u578b\u7684\u81ea\u52d5\u7d05\u968a\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8a08\u756b\u5c08\u6ce8\u65bc\u767c\u73fe\u89f8\u767c\u51cd\u7d50\u8a9e\u8a00\u6a21\u578b (\u9632\u79a6\u8005) \u7522\u751f\u6709\u6bd2\u6587\u5b57\u7684\u63d0\u793a\u3002\u9019\u901a\u5e38\u6703\u5c0e\u81f4\u63d0\u793a\u6a21\u578b (\u5c0d\u624b) \u7522\u751f\u96e3\u4ee5\u7406\u89e3\u4e14\u4e0d\u592a\u53ef\u80fd\u51fa\u73fe\u7684\u6587\u5b57\u3002\u5728\u6b64\uff0c\u6211\u5011\u63d0\u51fa LLM \u7d05\u968a\u4efb\u52d9\u7684\u5f37\u5316\u5b78\u7fd2\u516c\u5f0f\uff0c\u8b93\u6211\u5011\u80fd\u5920\u767c\u73fe\u540c\u6642 (1) \u89f8\u767c\u51cd\u7d50\u9632\u79a6\u8005\u7684\u6709\u6bd2\u8f38\u51fa\uff0c\u4ee5\u53ca (2) \u7531\u9632\u79a6\u8005\u8a55\u5206\u70ba\u56f0\u60d1\u5ea6\u4f4e\u7684\u63d0\u793a\u3002\u6211\u5011\u8a8d\u70ba\u9019\u4e9b\u6848\u4f8b\u5728\u7d05\u968a\u8a2d\u5b9a\u4e2d\u662f\u6700\u76f8\u95dc\u7684\uff0c\u56e0\u70ba\u5b83\u5011\u5728\u9632\u79a6\u8005\u6a21\u578b\u7684\u6b63\u5e38\u4f7f\u7528\u671f\u9593\u51fa\u73fe\u7684\u53ef\u80fd\u6027\u5f88\u9ad8\u3002\u6211\u5011\u900f\u904e GPT-2 \u548c GPT-2 XL \u9632\u79a6\u8005\u4e0a\u8eab\u5206\u504f\u597d\u6700\u4f73\u5316 (IPO) \u7684\u65b0\u7a4e\u7dda\u4e0a\u548c\u5f31\u76e3\u7763\u8b8a\u9ad4\u4f86\u89e3\u6c7a\u9019\u500b\u516c\u5f0f\u3002\u6211\u5011\u8b49\u660e\u6211\u5011\u7684\u653f\u7b56\u80fd\u5920\u7522\u751f\u53ef\u80fd\u89f8\u767c\u6bd2\u6027\u7684\u63d0\u793a\u3002\u6700\u5f8c\uff0c\u6211\u5011\u5b9a\u6027\u5206\u6790\u5b78\u7fd2\u5230\u7684\u7b56\u7565\u3001\u53ef\u80fd\u6027\u548c\u6bd2\u6027\u7684\u6b0a\u8861\uff0c\u4e26\u8a0e\u8ad6\u5f71\u97ff\u3002\u6b64\u5c08\u6848\u7684\u539f\u59cb\u78bc\u53ef\u65bc\u4ee5\u4e0b\u7db2\u5740\u53d6\u5f97\uff1ahttps://github.com/sisl/ASTPrompter/\u3002", "author": "Amelia F. Hardy et.al.", "authors": "Amelia F. Hardy, Houjun Liu, Bernard Lange, Mykel J. Kochenderfer", "id": "2407.09447v1", "paper_url": "http://arxiv.org/abs/2407.09447v1", "repo": "null"}}