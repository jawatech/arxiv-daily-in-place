{"2405.02648": {"publish_time": "2024-05-04", "title": "A Conformal Prediction Score that is Robust to Label Noise", "paper_summary": "Conformal Prediction (CP) quantifies network uncertainty by building a small\nprediction set with a pre-defined probability that the correct class is within\nthis set. In this study we tackle the problem of CP calibration based on a\nvalidation set with noisy labels. We introduce a conformal score that is robust\nto label noise. The noise-free conformal score is estimated using the noisy\nlabeled data and the noise level. In the test phase the noise-free score is\nused to form the prediction set. We applied the proposed algorithm to several\nstandard medical imaging classification datasets. We show that our method\noutperforms current methods by a large margin, in terms of the average size of\nthe prediction set, while maintaining the required coverage.", "paper_summary_zh": "", "author": "Coby Penso et.al.", "authors": "Coby Penso,Jacob Goldberger", "id": "2405.02648v1", "paper_url": "http://arxiv.org/abs/2405.02648v1", "repo": "null"}}