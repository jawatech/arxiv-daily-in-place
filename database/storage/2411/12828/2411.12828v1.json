{"2411.12828": {"publish_time": "2024-11-19", "title": "Probing the Capacity of Language Model Agents to Operationalize Disparate Experiential Context Despite Distraction", "paper_summary": "Large language model (LLM) agents show promise in an increasing number of\ndomains. In many proposed applications, it is expected that the agent reasons\nover accumulated experience presented in an input prompt. We propose the OEDD\n(Operationalize Experience Despite Distraction) corpus, a\nhuman-annotator-validated body of scenarios with pre-scripted agent histories\nwhere the agent must make a decision based on disparate experiential\ninformation in the presence of a distractor. We evaluate three state-of-the-art\nLLMs (GPT-3.5 Turbo, GPT-4o, and Gemini 1.5 Pro) using a minimal\nchain-of-thought prompting strategy and observe that when (1) the input context\ncontains over 1,615 tokens of historical interactions, (2) a crucially\ndecision-informing premise is the rightful conclusion over two disparate\nenvironment premises, and (3) a trivial, but distracting red herring fact\nfollows, all LLMs perform worse than random choice at selecting the better of\ntwo actions. Our code and test corpus are publicly available at:\nhttps://github.com/sonnygeorge/OEDD .", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4ee3\u7406\u5728\u8d8a\u4f86\u8d8a\u591a\u7684\u9818\u57df\u4e2d\u5c55\u73fe\u51fa\u6f5b\u529b\u3002\u5728\u8a31\u591a\u63d0\u8b70\u7684\u61c9\u7528\u4e2d\uff0c\u9810\u8a08\u4ee3\u7406\u6703\u6839\u64da\u8f38\u5165\u63d0\u793a\u4e2d\u5448\u73fe\u7684\u7d2f\u7a4d\u7d93\u9a57\u9032\u884c\u63a8\u7406\u3002\u6211\u5011\u63d0\u51fa OEDD\uff08\u5118\u7ba1\u6709\u5e72\u64fe\u4e5f\u80fd\u64cd\u4f5c\u7d93\u9a57\uff09\u8a9e\u6599\u5eab\uff0c\u9019\u662f\u4e00\u500b\u7531\u4eba\u5de5\u8a3b\u89e3\u54e1\u9a57\u8b49\u7684\u5834\u666f\u4e3b\u9ad4\uff0c\u5176\u4e2d\u5305\u542b\u9810\u5148\u7de8\u5beb\u7684\u4ee3\u7406\u6b77\u53f2\u8a18\u9304\uff0c\u4ee3\u7406\u5fc5\u9808\u6839\u64da\u5206\u6563\u7684\u9ad4\u9a57\u8cc7\u8a0a\u5728\u5e72\u64fe\u56e0\u7d20\u5b58\u5728\u7684\u60c5\u6cc1\u4e0b\u505a\u51fa\u6c7a\u7b56\u3002\u6211\u5011\u4f7f\u7528\u6700\u5c0f\u7684\u601d\u8003\u93c8\u63d0\u793a\u7b56\u7565\u8a55\u4f30\u4e86\u4e09\u500b\u6700\u5148\u9032\u7684 LLM\uff08GPT-3.5 Turbo\u3001GPT-4o \u548c Gemini 1.5 Pro\uff09\uff0c\u4e26\u89c0\u5bdf\u5230\u7576\uff081\uff09\u8f38\u5165\u5167\u5bb9\u5305\u542b\u8d85\u904e 1,615 \u500b\u6b77\u6b21\u4e92\u52d5\u7684\u7b26\u865f\uff0c\uff082\uff09\u4e00\u500b\u81f3\u95dc\u91cd\u8981\u7684\u6c7a\u7b56\u4f9d\u64da\u524d\u63d0\u662f\u5c0d\u5169\u500b\u4e0d\u540c\u7684\u74b0\u5883\u524d\u63d0\u7684\u6b63\u78ba\u7d50\u8ad6\uff0c\u4ee5\u53ca\uff083\uff09\u4e00\u500b\u5fae\u4e0d\u8db3\u9053\u4f46\u4ee4\u4eba\u5206\u5fc3\u7684\u932f\u8aa4\u7dda\u7d22\u4e8b\u5be6\u7dca\u96a8\u5176\u5f8c\uff0c\u6240\u6709 LLM \u5728\u9078\u64c7\u5169\u500b\u52d5\u4f5c\u4e2d\u8f03\u597d\u7684\u52d5\u4f5c\u6642\u8868\u73fe\u90fd\u6bd4\u96a8\u6a5f\u9078\u64c7\u5dee\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u548c\u6e2c\u8a66\u8a9e\u6599\u5eab\u53ef\u65bc\u4ee5\u4e0b\u7db2\u5740\u516c\u958b\u53d6\u5f97\uff1ahttps://github.com/sonnygeorge/OEDD\u3002", "author": "Sonny George et.al.", "authors": "Sonny George, Chris Sypherd, Dylan Cashman", "id": "2411.12828v1", "paper_url": "http://arxiv.org/abs/2411.12828v1", "repo": "https://github.com/sonnygeorge/oedd"}}