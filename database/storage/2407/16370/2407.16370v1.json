{"2407.16370": {"publish_time": "2024-07-23", "title": "Evolutionary Prompt Design for LLM-Based Post-ASR Error Correction", "paper_summary": "Building upon the strength of modern large language models (LLMs), generative\nerror correction (GEC) has emerged as a promising paradigm that can elevate the\nperformance of modern automatic speech recognition (ASR) systems. One\nrepresentative approach is to leverage in-context learning to prompt LLMs so\nthat a better hypothesis can be generated by the LLMs based on a\ncarefully-designed prompt and an $N$-best list of hypotheses produced by ASR\nsystems. However, it is yet unknown whether the existing prompts are the most\neffective ones for the task of post-ASR error correction. In this context, this\npaper first explores alternative prompts to identify an initial set of\neffective prompts, and then proposes to employ an evolutionary prompt\noptimization algorithm to refine the initial prompts. Evaluations results on\nthe CHiME-4 subset of the Task $1$ of the SLT $2024$ GenSEC challenge show the\neffectiveness and potential of the proposed algorithms.", "paper_summary_zh": "\u5efa\u7acb\u5728\u73fe\u4ee3\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u512a\u52e2\u4e0a\uff0c\u751f\u6210\u5f0f\u932f\u8aa4\u4fee\u6b63 (GEC) \u5df2\u6210\u70ba\u4e00\u7a2e\u6709\u524d\u9014\u7684\u7bc4\u4f8b\uff0c\u53ef\u4ee5\u63d0\u5347\u73fe\u4ee3\u81ea\u52d5\u8a9e\u97f3\u8fa8\u8b58 (ASR) \u7cfb\u7d71\u7684\u6548\u80fd\u3002\u4e00\u7a2e\u5177\u4ee3\u8868\u6027\u7684\u65b9\u6cd5\u662f\u5229\u7528\u60c5\u5883\u5b78\u7fd2\u63d0\u793a LLM\uff0c\u4ee5\u4fbf LLM \u80fd\u6839\u64da\u7cbe\u5fc3\u8a2d\u8a08\u7684\u63d0\u793a\u548c ASR \u7cfb\u7d71\u7522\u751f\u7684 N \u500b\u6700\u4f73\u5047\u8a2d\u6e05\u55ae\uff0c\u7522\u751f\u66f4\u597d\u7684\u5047\u8a2d\u3002\u7136\u800c\uff0c\u76ee\u524d\u5c1a\u4e0d\u77e5\u9053\u73fe\u6709\u7684\u63d0\u793a\u662f\u5426\u6700\u9069\u5408\u65bc ASR \u5f8c\u932f\u8aa4\u4fee\u6b63\u4efb\u52d9\u3002\u5728\u6b64\u80cc\u666f\u4e0b\uff0c\u672c\u6587\u9996\u5148\u63a2\u8a0e\u66ff\u4ee3\u63d0\u793a\u4ee5\u627e\u51fa\u521d\u59cb\u7684\u4e00\u7d44\u6709\u6548\u63d0\u793a\uff0c\u7136\u5f8c\u63d0\u51fa\u63a1\u7528\u6f14\u5316\u63d0\u793a\u6700\u4f73\u5316\u6f14\u7b97\u6cd5\u4f86\u6539\u5584\u521d\u59cb\u63d0\u793a\u3002\u5728 SLT 2024 GenSEC \u6311\u6230\u4efb\u52d9 1 \u7684 CHiME-4 \u5b50\u96c6\u4e0a\u9032\u884c\u7684\u8a55\u91cf\u7d50\u679c\u986f\u793a\u4e86\u6240\u63d0\u51fa\u7684\u6f14\u7b97\u6cd5\u7684\u6709\u6548\u6027\u548c\u6f5b\u529b\u3002", "author": "Rithik Sachdev et.al.", "authors": "Rithik Sachdev, Zhong-Qiu Wang, Chao-Han Huck Yang", "id": "2407.16370v1", "paper_url": "http://arxiv.org/abs/2407.16370v1", "repo": "null"}}