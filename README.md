# arxiv-daily
 Automated deployment @ 2024-10-13 20:24:48 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-10**|**Can Knowledge Graphs Make Large Language Models More Trustworthy? An Empirical Study over Open-ended Question Answering**|Yuan Sui et.al.|[2410.08085v1](http://arxiv.org/abs/2410.08085v1)|null|
|**2024-10-10**|**Disease Entity Recognition and Normalization is Improved with Large Language Model Derived Synthetic Normalized Mentions**|Kuleen Sasse et.al.|[2410.07951v1](http://arxiv.org/abs/2410.07951v1)|null|
|**2024-10-10**|**Benchmarking Agentic Workflow Generation**|Shuofei Qiao et.al.|[2410.07869v1](http://arxiv.org/abs/2410.07869v1)|null|
|**2024-10-10**|**KRAG Framework for Enhancing LLMs in the Legal Domain**|Nguyen Ha Thanh et.al.|[2410.07551v1](http://arxiv.org/abs/2410.07551v1)|null|
|**2024-10-10**|**MKGL: Mastery of a Three-Word Language**|Lingbing Guo et.al.|[2410.07526v1](http://arxiv.org/abs/2410.07526v1)|null|
|**2024-10-09**|**InstructG2I: Synthesizing Images from Multimodal Attributed Graphs**|Bowen Jin et.al.|[2410.07157v1](http://arxiv.org/abs/2410.07157v1)|[link](https://github.com/PeterGriffinJin/InstructG2I)|
|**2024-10-09**|**CSSL: Contrastive Self-Supervised Learning for Dependency Parsing on Relatively Free Word Ordered and Morphologically Rich Low Resource Languages**|Pretam Ray et.al.|[2410.06944v1](http://arxiv.org/abs/2410.06944v1)|null|
|**2024-10-09**|**Tree of Problems: Improving structured problem solving with compositionality**|Armel Zebaze et.al.|[2410.06634v1](http://arxiv.org/abs/2410.06634v1)|null|
|**2024-10-09**|**Multi-Task Program Error Repair and Explanatory Diagnosis**|Zhenyu Xu et.al.|[2410.07271v1](http://arxiv.org/abs/2410.07271v1)|null|
|**2024-10-08**|**Counterfactual Causal Inference in Natural Language with Large Language Models**|GaÃ«l Gendron et.al.|[2410.06392v1](http://arxiv.org/abs/2410.06392v1)|[link](https://github.com/strong-ai-lab/counterfactual-llm-inference)|
|**2024-10-08**|**Less is More: Making Smaller Language Models Competent Subgraph Retrievers for Multi-hop KGQA**|Wenyu Huang et.al.|[2410.06121v1](http://arxiv.org/abs/2410.06121v1)|null|
|**2024-10-08**|**LLM-based SPARQL Query Generation from Natural Language over Federated Knowledge Graphs**|Vincent Emonet et.al.|[2410.06062v2](http://arxiv.org/abs/2410.06062v2)|null|
|**2024-10-08**|**Jet Expansions of Residual Computation**|Yihong Chen et.al.|[2410.06024v1](http://arxiv.org/abs/2410.06024v1)|null|
|**2024-10-08**|**A large collection of bioinformatics question-query pairs over federated knowledge graphs: methodology and applications**|Jerven Bolleman et.al.|[2410.06010v1](http://arxiv.org/abs/2410.06010v1)|null|
|**2024-10-08**|**LightRAG: Simple and Fast Retrieval-Augmented Generation**|Zirui Guo et.al.|[2410.05779v1](http://arxiv.org/abs/2410.05779v1)|[link](https://github.com/hkuds/lightrag)|
|**2024-10-08**|**Information Discovery in e-Commerce**|Zhaochun Ren et.al.|[2410.05763v1](http://arxiv.org/abs/2410.05763v1)|null|
|**2024-10-08**|**Vector-ICL: In-context Learning with Continuous Vector Representations**|Yufan Zhuang et.al.|[2410.05629v1](http://arxiv.org/abs/2410.05629v1)|[link](https://github.com/EvanZhuang/vector-icl)|
|**2024-10-07**|**Narrative-of-Thought: Improving Temporal Reasoning of Large Language Models via Recounted Narratives**|Xinliang Frederick Zhang et.al.|[2410.05558v1](http://arxiv.org/abs/2410.05558v1)|null|
|**2024-10-07**|**Scalable and Accurate Graph Reasoning with LLM-based Multi-Agents**|Yuwei Hu et.al.|[2410.05130v1](http://arxiv.org/abs/2410.05130v1)|null|
|**2024-10-07**|**Leverage Knowledge Graph and Large Language Model for Law Article Recommendation: A Case Study of Chinese Criminal Law**|Yongming Chen et.al.|[2410.04949v1](http://arxiv.org/abs/2410.04949v1)|null|
|**2024-10-07**|**GARLIC: LLM-Guided Dynamic Progress Control with Hierarchical Weighted Graph for Long Document QA**|Xinyu Wang et.al.|[2410.04790v1](http://arxiv.org/abs/2410.04790v1)|null|
|**2024-10-06**|**Reasoning-Enhanced Healthcare Predictions with Knowledge Graph Community Retrieval**|Pengcheng Jiang et.al.|[2410.04585v1](http://arxiv.org/abs/2410.04585v1)|[link](https://github.com/pat-jj/KARE)|
|**2024-10-04**|**Empowering Domain-Specific Language Models with Graph-Oriented Databases: A Paradigm Shift in Performance and Model Maintenance**|Ricardo Di Pasquale et.al.|[2410.03867v1](http://arxiv.org/abs/2410.03867v1)|null|
|**2024-10-04**|**GraphRouter: A Graph-based Router for LLM Selections**|Tao Feng et.al.|[2410.03834v1](http://arxiv.org/abs/2410.03834v1)|null|
|**2024-10-04**|**Should Cross-Lingual AMR Parsing go Meta? An Empirical Assessment of Meta-Learning and Joint Learning AMR Parsing**|Jeongwoo Kang et.al.|[2410.03357v1](http://arxiv.org/abs/2410.03357v1)|[link](https://github.com/Emvista/Meta-XAMR-2024)|
|**2024-10-04**|**Enriching Ontologies with Disjointness Axioms using Large Language Models**|Elias Crum et.al.|[2410.03235v1](http://arxiv.org/abs/2410.03235v1)|[link](https://github.com/n28div/llm-disjointness)|
|**2024-10-04**|**How Do Large Language Models Understand Graph Patterns? A Benchmark for Graph Pattern Comprehension**|Xinnan Dai et.al.|[2410.05298v1](http://arxiv.org/abs/2410.05298v1)|null|
|**2024-10-03**|**LLMCO2: Advancing Accurate Carbon Footprint Prediction for LLM Inferences**|Zhenxiao Fu et.al.|[2410.02950v1](http://arxiv.org/abs/2410.02950v1)|null|
|**2024-10-03**|**Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization**|Ryan C. Barron et.al.|[2410.02721v1](http://arxiv.org/abs/2410.02721v1)|null|
|**2024-10-03**|**A Schema-aware Logic Reformulation for Graph Reachability**|Davide Di Pierro et.al.|[2410.02533v1](http://arxiv.org/abs/2410.02533v1)|null|
|**2024-10-03**|**Language Models are Graph Learners**|Zhe Xu et.al.|[2410.02296v1](http://arxiv.org/abs/2410.02296v1)|null|
|**2024-10-03**|**GraphIC: A Graph-Based In-Context Example Retrieval Model for Multi-Step Reasoning**|Jiale Fu et.al.|[2410.02203v1](http://arxiv.org/abs/2410.02203v1)|null|
|**2024-10-03**|**G2T-LLM: Graph-to-Tree Text Encoding for Molecule Generation with Fine-Tuned Large Language Models**|Zhaoning Yu et.al.|[2410.02198v1](http://arxiv.org/abs/2410.02198v1)|null|
|**2024-10-02**|**FLAG: Financial Long Document Classification via AMR-based GNN**|Bolun et.al.|[2410.02024v1](http://arxiv.org/abs/2410.02024v1)|[link](https://github.com/namir0806/flag)|
|**2024-10-02**|**Lost-in-Distance: Impact of Contextual Proximity on LLM Performance in Graph Tasks**|Hamed Firooz et.al.|[2410.01985v1](http://arxiv.org/abs/2410.01985v1)|null|
|**2024-10-02**|**LLM+KG@VLDB'24 Workshop Summary**|Arijit Khan et.al.|[2410.01978v1](http://arxiv.org/abs/2410.01978v1)|null|
|**2024-10-02**|**Conformal Generative Modeling with Improved Sample Efficiency through Sequential Greedy Filtering**|Klaus-Rudolf Kladny et.al.|[2410.01660v1](http://arxiv.org/abs/2410.01660v1)|null|
|**2024-10-02**|**HiReview: Hierarchical Taxonomy-Driven Automatic Literature Review Generation**|Yuntong Hu et.al.|[2410.03761v1](http://arxiv.org/abs/2410.03761v1)|null|
|**2024-10-02**|**LEGO: Learnable Expansion of Graph Operators for Multi-Modal Feature Fusion**|Dexuan Ding et.al.|[2410.01506v2](http://arxiv.org/abs/2410.01506v2)|null|
|**2024-10-02**|**Question-guided Knowledge Graph Re-scoring and Injection for Knowledge Graph Question Answering**|Yu Zhang et.al.|[2410.01401v1](http://arxiv.org/abs/2410.01401v1)|[link](https://github.com/EchoDreamer/Q-KGR)|
|**2024-10-02**|**Unveiling Language Skills under Circuits**|Hang Chen et.al.|[2410.01334v1](http://arxiv.org/abs/2410.01334v1)|[link](https://github.com/zodiark-ch/language-skill-of-llms)|
|**2024-10-01**|**From Natural Language to SQL: Review of LLM-based Text-to-SQL Systems**|Ali Mohammadjafari et.al.|[2410.01066v1](http://arxiv.org/abs/2410.01066v1)|null|
|**2024-09-30**|**GUNDAM: Aligning Large Language Models with Graph Understanding**|Sheng Ouyang et.al.|[2409.20053v2](http://arxiv.org/abs/2409.20053v2)|null|
|**2024-09-30**|**Enhancing High-order Interaction Awareness in LLM-based Recommender Model**|Xinfeng Wang et.al.|[2409.19979v2](http://arxiv.org/abs/2409.19979v2)|[link](https://github.com/WangXFng/ELMRec)|
|**2024-09-29**|**CoTKR: Chain-of-Thought Enhanced Knowledge Rewriting for Complex Knowledge Graph Question Answering**|Yike Wu et.al.|[2409.19753v2](http://arxiv.org/abs/2409.19753v2)|[link](https://github.com/wuyike2000/CoTKR)|
|**2024-09-29**|**Can Large Language Models Analyze Graphs like Professionals? A Benchmark, Datasets and Models**|Xin Li et.al.|[2409.19667v1](http://arxiv.org/abs/2409.19667v1)|[link](https://github.com/bupt-gamma/prograph)|
|**2024-09-28**|**Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs**|Zheng Wang et.al.|[2409.19401v1](http://arxiv.org/abs/2409.19401v1)|null|
|**2024-09-27**|**CLLMate: A Multimodal LLM for Weather and Climate Events Forecasting**|Haobo Li et.al.|[2409.19058v1](http://arxiv.org/abs/2409.19058v1)|null|
|**2024-09-27**|**AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow**|Huizi Yu et.al.|[2409.18924v2](http://arxiv.org/abs/2409.18924v2)|null|
|**2024-09-27**|**Soft Measures for Extracting Causal Collective Intelligence**|Maryam Berijanian et.al.|[2409.18911v1](http://arxiv.org/abs/2409.18911v1)|[link](https://github.com/kuldeep7688/soft-measures-causal-intelligence)|
|**2024-09-27**|**OpenObject-NAV: Open-Vocabulary Object-Oriented Navigation Based on Dynamic Carrier-Relationship Scene Graph**|Yujie Tang et.al.|[2409.18743v1](http://arxiv.org/abs/2409.18743v1)|null|
|**2024-09-27**|**Rehearsing Answers to Probable Questions with Perspective-Taking**|Yung-Yu Shih et.al.|[2409.18678v1](http://arxiv.org/abs/2409.18678v1)|null|
|**2024-09-26**|**LowREm: A Repository of Word Embeddings for 87 Low-Resource Languages Enhanced with Multilingual Graph Knowledge**|Daniil Gurgurov et.al.|[2409.18193v1](http://arxiv.org/abs/2409.18193v1)|null|
|**2024-09-26**|**Enhancing Structured-Data Retrieval with GraphRAG: Soccer Data Case Study**|Zahra Sepasdar et.al.|[2409.17580v1](http://arxiv.org/abs/2409.17580v1)|null|
|**2024-09-25**|**Probing Omissions and Distortions in Transformer-based RDF-to-Text Models**|Juliette Faille et.al.|[2409.16707v1](http://arxiv.org/abs/2409.16707v1)|null|
|**2024-09-25**|**GraphLoRA: Structure-Aware Contrastive Low-Rank Adaptation for Cross-Graph Transfer Learning**|Zhe-Rui Yang et.al.|[2409.16670v1](http://arxiv.org/abs/2409.16670v1)|null|
|**2024-09-24**|**Cyber Knowledge Completion Using Large Language Models**|Braden K Webb et.al.|[2409.16176v1](http://arxiv.org/abs/2409.16176v1)|null|
|**2024-09-24**|**Konstruktor: A Strong Baseline for Simple Knowledge Graph Question Answering**|Maria Lysyuk et.al.|[2409.15902v1](http://arxiv.org/abs/2409.15902v1)|[link](https://github.com/s-nlp/konstruktor)|
|**2024-09-24**|**Symmetries and Expressive Requirements for Learning General Policies**|Dominik Drexler et.al.|[2409.15892v1](http://arxiv.org/abs/2409.15892v1)|null|
|**2024-09-23**|**GEM-RAG: Graphical Eigen Memories For Retrieval Augmented Generation**|Brendan Hogan Rappazzo et.al.|[2409.15566v1](http://arxiv.org/abs/2409.15566v1)|null|
|**2024-09-23**|**KARMA: Augmenting Embodied AI Agents with Long-and-short Term Memory Systems**|Zixuan Wang et.al.|[2409.14908v1](http://arxiv.org/abs/2409.14908v1)|null|
|**2024-09-23**|**End-to-End Graph Flattening Method for Large Language Models**|Bin Hong et.al.|[2409.14880v1](http://arxiv.org/abs/2409.14880v1)|null|
|**2024-09-22**|**RACOON: An LLM-based Framework for Retrieval-Augmented Column Type Annotation with a Knowledge Graph**|Linxi Wei et.al.|[2409.14556v1](http://arxiv.org/abs/2409.14556v1)|null|
|**2024-09-22**|**SAC-KG: Exploiting Large Language Models as Skilled Automatic Constructors for Domain Knowledge Graphs**|Hanzhu Chen et.al.|[2410.02811v1](http://arxiv.org/abs/2410.02811v1)|null|
|**2024-09-21**|**Graph Neural Network Framework for Sentiment Analysis Using Syntactic Feature**|Linxiao Wu et.al.|[2409.14000v1](http://arxiv.org/abs/2409.14000v1)|null|
|**2024-09-20**|**ShizishanGPT: An Agricultural Large Language Model Integrating Tools and Resources**|Shuting Yang et.al.|[2409.13537v1](http://arxiv.org/abs/2409.13537v1)|[link](https://github.com/zaiwen/cropgpt)|
|**2024-09-20**|**LM-assisted keyword biasing with Aho-Corasick algorithm for Transducer-based ASR**|Iuliia Thorbecke et.al.|[2409.13514v1](http://arxiv.org/abs/2409.13514v1)|null|
|**2024-09-20**|**AQA: Adaptive Question Answering in a Society of LLMs via Contextual Multi-Armed Bandit**|Mohanna Hoveyda et.al.|[2409.13447v2](http://arxiv.org/abs/2409.13447v2)|null|
|**2024-09-20**|**GAProtoNet: A Multi-head Graph Attention-based Prototypical Network for Interpretable Text Classification**|Ximing Wen et.al.|[2409.13312v1](http://arxiv.org/abs/2409.13312v1)|null|
|**2024-09-20**|**Leveraging Knowledge Graphs and LLMs to Support and Monitor Legislative Systems**|Andrea Colombo et.al.|[2409.13252v1](http://arxiv.org/abs/2409.13252v1)|null|
|**2024-09-19**|**Enhancing Unsupervised Sentence Embeddings via Knowledge-Driven Data Augmentation and Gaussian-Decayed Contrastive Learning**|Peichao Lai et.al.|[2409.12887v2](http://arxiv.org/abs/2409.12887v2)|null|
|**2024-09-19**|**KnowFormer: Revisiting Transformers for Knowledge Graph Reasoning**|Junnan Liu et.al.|[2409.12865v1](http://arxiv.org/abs/2409.12865v1)|null|
|**2024-09-19**|**A New Perspective on ADHD Research: Knowledge Graph Construction with LLMs and Network Based Insights**|Hakan T. Otal et.al.|[2409.12853v1](http://arxiv.org/abs/2409.12853v1)|null|
|**2024-09-19**|**Enhancing Logical Reasoning in Large Language Models through Graph-based Synthetic Data**|Jiaming Zhou et.al.|[2409.12437v1](http://arxiv.org/abs/2409.12437v1)|[link](https://github.com/riddickzhou/llm-graph-synthetic-reasoning)|
|**2024-09-19**|**Textualized Agent-Style Reasoning for Complex Tasks by Multiple Round LLM Generation**|Chen Liang et.al.|[2409.12411v1](http://arxiv.org/abs/2409.12411v1)|null|
|**2024-09-18**|**GUNet: A Graph Convolutional Network United Diffusion Model for Stable and Diversity Pose Generation**|Shuowen Liang et.al.|[2409.11689v1](http://arxiv.org/abs/2409.11689v1)|null|
|**2024-09-17**|**FedNE: Surrogate-Assisted Federated Neighbor Embedding for Dimensionality Reduction**|Ziwei Li et.al.|[2409.11509v1](http://arxiv.org/abs/2409.11509v1)|null|
|**2024-09-17**|**Reasoning Graph Enhanced Exemplars Retrieval for In-Context Learning**|Yukang Lin et.al.|[2409.11147v1](http://arxiv.org/abs/2409.11147v1)|[link](https://github.com/yukang-lin/rger)|
|**2024-09-17**|**Semformer: Transformer Language Models with Semantic Planning**|Yongjing Yin et.al.|[2409.11143v1](http://arxiv.org/abs/2409.11143v1)|null|
|**2024-09-17**|**KALE: An Artwork Image Captioning System Augmented with Heterogeneous Graph**|Yanbei Jiang et.al.|[2409.10921v1](http://arxiv.org/abs/2409.10921v1)|[link](https://github.com/yanbei-jiang/artwork-interpretation)|
|**2024-09-16**|**A Knowledge-Enhanced Disease Diagnosis Method Based on Prompt Learning and BERT Integration**|Zhang Zheng et.al.|[2409.10403v1](http://arxiv.org/abs/2409.10403v1)|null|
|**2024-09-16**|**MGSA: Multi-Granularity Graph Structure Attention for Knowledge Graph-to-Text Generation**|Shanshan Wang et.al.|[2409.10294v2](http://arxiv.org/abs/2409.10294v2)|null|
|**2024-09-16**|**LLM-DER:A Named Entity Recognition Method Based on Large Language Models for Chinese Coal Chemical Domain**|Le Xiao et.al.|[2409.10077v1](http://arxiv.org/abs/2409.10077v1)|null|
|**2024-09-16**|**On the Diagram of Thought**|Yifan Zhang et.al.|[2409.10038v1](http://arxiv.org/abs/2409.10038v1)|[link](https://github.com/diagram-of-thought/diagram-of-thought)|
|**2024-09-15**|**Entity-Aware Self-Attention and Contextualized GCN for Enhanced Relation Extraction in Long Sentences**|Xin Wang et.al.|[2409.13755v1](http://arxiv.org/abs/2409.13755v1)|null|
|**2024-09-14**|**Automatic Scene Generation: State-of-the-Art Techniques, Models, Datasets, Challenges, and Future Prospects**|Awal Ahmed Fime et.al.|[2410.01816v1](http://arxiv.org/abs/2410.01816v1)|null|
|**2024-09-14**|**Generating Event-oriented Attribution for Movies via Two-Stage Prefix-Enhanced Multimodal LLM**|Yuanjie Lyu et.al.|[2409.09362v1](http://arxiv.org/abs/2409.09362v1)|null|
|**2024-09-14**|**ODE: Open-Set Evaluation of Hallucinations in Multimodal Large Language Models**|Yahan Tu et.al.|[2409.09318v1](http://arxiv.org/abs/2409.09318v1)|null|
|**2024-09-13**|**Towards Leveraging Contrastively Pretrained Neural Audio Embeddings for Recommender Tasks**|Florian GrÃ¶tschla et.al.|[2409.09026v1](http://arxiv.org/abs/2409.09026v1)|null|
|**2024-09-13**|**Contri(e)ve: Context + Retrieve for Scholarly Question Answering**|Kanchan Shivashankar et.al.|[2409.09010v1](http://arxiv.org/abs/2409.09010v1)|null|
|**2024-09-13**|**SGFormer: Single-Layer Graph Transformers with Approximation-Free Linear Complexity**|Qitian Wu et.al.|[2409.09007v1](http://arxiv.org/abs/2409.09007v1)|[link](https://github.com/qitianwu/sgformer)|
|**2024-09-13**|**Exploring Graph Structure Comprehension Ability of Multimodal Large Language Models: Case Studies**|Zhiqiang Zhong et.al.|[2409.08864v1](http://arxiv.org/abs/2409.08864v1)|null|
|**2024-09-13**|**A RAG Approach for Generating Competency Questions in Ontology Engineering**|Xueli Pan et.al.|[2409.08820v1](http://arxiv.org/abs/2409.08820v1)|null|
|**2024-09-13**|**ATFLRec: A Multimodal Recommender System with Audio-Text Fusion and Low-Rank Adaptation via Instruction-Tuned Large Language Model**|Zezheng Qin et.al.|[2409.08543v1](http://arxiv.org/abs/2409.08543v1)|null|
|**2024-09-12**|**What Makes a Maze Look Like a Maze?**|Joy Hsu et.al.|[2409.08202v1](http://arxiv.org/abs/2409.08202v1)|null|
|**2024-09-12**|**Towards a graph-based foundation model for network traffic analysis**|Louis Van Langendonck et.al.|[2409.08111v1](http://arxiv.org/abs/2409.08111v1)|null|
|**2024-09-12**|**Learning Rules from KGs Guided by Language Models**|Zihang Peng et.al.|[2409.07869v1](http://arxiv.org/abs/2409.07869v1)|[link](https://github.com/pzh97/learning-rules-from-kgs-guided-by-language-models)|
|**2024-09-12**|**Multi-object event graph representation learning for Video Question Answering**|Yanan Wang et.al.|[2409.07747v1](http://arxiv.org/abs/2409.07747v1)|null|
|**2024-09-11**|**Demo: SGCode: A Flexible Prompt-Optimizing System for Secure Generation of Code**|Khiem Ton et.al.|[2409.07368v3](http://arxiv.org/abs/2409.07368v3)|null|
|**2024-09-11**|**Semantic Interoperability on Blockchain by Generating Smart Contracts Based on Knowledge Graphs**|William Van Woensel et.al.|[2409.12171v1](http://arxiv.org/abs/2409.12171v1)|null|

#### Abstracts
##### **Can Knowledge Graphs Make Large Language Models More Trustworthy? An Empirical Study over Open-ended Question Answering**
2410.08085v1 by Yuan Sui, Bryan Hooi

Recent works integrating Knowledge Graphs (KGs) have led to promising
improvements in enhancing reasoning accuracy of Large Language Models (LLMs).
However, current benchmarks mainly focus on closed tasks, leaving a gap in the
assessment of more complex, real-world scenarios. This gap has also obscured
the evaluation of KGs' potential to mitigate the problem of hallucination in
LLMs. To fill the gap, we introduce OKGQA, a new benchmark specifically
designed to assess LLMs enhanced with KGs under open-ended, real-world question
answering scenarios. OKGQA is designed to closely reflect the complexities of
practical applications using questions from different types, and incorporates
specific metrics to measure both the reduction in hallucinations and the
enhancement in reasoning capabilities. To consider the scenario in which KGs
may have varying levels of mistakes, we further propose another experiment
setting OKGQA-P to assess model performance when the semantics and structure of
KGs are deliberately perturbed and contaminated. OKGQA aims to (1) explore
whether KGs can make LLMs more trustworthy in an open-ended setting, and (2)
conduct a comparative analysis to shed light on methods and future directions
for leveraging KGs to reduce LLMs' hallucination. We believe that this study
can facilitate a more complete performance comparison and encourage continuous
improvement in integrating KGs with LLMs.

æè¦ï¼è¿æçç¥è¯å¾è°± (KG) æ´åç ç©¶ï¼å·²æåå¤§åè¯­è¨æ¨¡å (LLM) æ¨çåç¡®åº¦çè¡¨ç°ã
ç¶èï¼ç°æçåºåæµè¯ä¸»è¦çéäºå°é­å¼ä»»å¡ï¼å¨è¯ä¼°æ´å¤æãæ´å®éçåºæ¯æ¶å­å¨ç¼ºå£ãæ­¤ç¼ºå£ä¹æ¨¡ç³äºç¥è¯å¾è°±å¨åè½» LLM å¹»è§é®é¢ä¸çæ½åè¯ä¼°ãä¸ºäºå¡«è¡¥æ­¤ç¼ºå£ï¼æä»¬å¼å¥äº OKGQAï¼è¿æ¯ä¸ä¸ªä¸é¨è®¾è®¡ç¨æ¥è¯ä¼°å¨å¼æ¾å¼ãå®éé®ç­åºæ¯ä¸­ï¼å¢å¼ºäºç¥è¯å¾è°±ç LLM çæ°åºåæµè¯ãOKGQA æ¨å¨ç´§å¯åæ å®éåºç¨ä¸­çå¤ææ§ï¼ä½¿ç¨ä¸åç±»åçé¢ç®ï¼å¹¶çº³å¥ç¹å®ææ æ¥è¡¡éå¹»è§çåå°åæ¨çè½åçå¢å¼ºãä¸ºäºèèç¥è¯å¾è°±å¯è½å­å¨ä¸åç¨åº¦éè¯¯çåºæ¯ï¼æä»¬è¿ä¸æ­¥æåºäºå¦ä¸ä¸ªå®éªè®¾ç½® OKGQA-Pï¼ä»¥è¯ä¼°å½ç¥è¯å¾è°±çè¯­ä¹åç»æè¢«æææ°å¨åæ±¡ææ¶çæ¨¡åæ§è½ãOKGQA æ¨å¨ (1) æ¢ç´¢ç¥è¯å¾è°±æ¯å¦è½ä½¿ LLM å¨å¼æ¾å¼è®¾ç½®ä¸­æ´å¼å¾ä¿¡èµï¼ä»¥å (2) è¿è¡æ¯è¾åæï¼ä»¥éæå©ç¨ç¥è¯å¾è°±æ¥åå° LLM å¹»è§çæ¹æ³åæªæ¥æ¹åãæä»¬ç¸ä¿¡è¿é¡¹ç ç©¶å¯ä»¥ä¿è¿æ´å®æ´çæ§è½æ¯è¾ï¼å¹¶é¼å±æç»­æ¹è¿ç¥è¯å¾è°±ä¸ LLM çæ´åã

##### **Disease Entity Recognition and Normalization is Improved with Large Language Model Derived Synthetic Normalized Mentions**
2410.07951v1 by Kuleen Sasse, Shinjitha Vadlakonda, Richard E. Kennedy, John D. Osborne

Background: Machine learning methods for clinical named entity recognition
and entity normalization systems can utilize both labeled corpora and Knowledge
Graphs (KGs) for learning. However, infrequently occurring concepts may have
few mentions in training corpora and lack detailed descriptions or synonyms,
even in large KGs. For Disease Entity Recognition (DER) and Disease Entity
Normalization (DEN), this can result in fewer high quality training examples
relative to the number of known diseases. Large Language Model (LLM) generation
of synthetic training examples could improve performance in these information
extraction tasks.
  Methods: We fine-tuned a LLaMa-2 13B Chat LLM to generate a synthetic corpus
containing normalized mentions of concepts from the Unified Medical Language
System (UMLS) Disease Semantic Group. We measured overall and Out of
Distribution (OOD) performance for DER and DEN, with and without synthetic data
augmentation. We evaluated performance on 3 different disease corpora using 4
different data augmentation strategies, assessed using BioBERT for DER and
SapBERT and KrissBERT for DEN.
  Results: Our synthetic data yielded a substantial improvement for DEN, in all
3 training corpora the top 1 accuracy of both SapBERT and KrissBERT improved by
3-9 points in overall performance and by 20-55 points in OOD data. A small
improvement (1-2 points) was also seen for DER in overall performance, but only
one dataset showed OOD improvement.
  Conclusion: LLM generation of normalized disease mentions can improve DEN
relative to normalization approaches that do not utilize LLMs to augment data
with synthetic mentions. Ablation studies indicate that performance gains for
DEN were only partially attributable to improvements in OOD performance. The
same approach has only a limited ability to improve DER. We make our software
and dataset publicly available.

æè¦ï¼<paragraph>èæ¯ï¼è¨åºå½åå¯¦é«è­å¥çæ©å¨å­¸ç¿æ¹æ³åå¯¦é«æ­£è¦åç³»çµ±å¯ä»¥å©ç¨æ¨è¨èªæåº«åç¥è­åè­ (KG) ä¾å­¸ç¿ãç¶èï¼å¨è¨ç·´èªæåº«ä¸­å¾å°åºç¾çæ¦å¿µå¯è½åªæå°æ¸æåï¼å³ä½¿å¨å¤§åç¥è­åè­ä¸­ä¹ç¼ºä¹è©³ç´°çæè¿°æåç¾©è©ãå°æ¼ç¾çå¯¦é«è­å¥ (DER) åç¾çå¯¦é«æ­£è¦å (DEN)ï¼ç¸å°æ¼å·²ç¥ç¾ççæ¸éï¼éå¯è½æå°è´è¼å°çé«åè³ªè¨ç·´ç¯ä¾ãå¤§åèªè¨æ¨¡å (LLM) çæçåæè¨ç·´ç¯ä¾å¯ä»¥æåéäºè³è¨æ·åä»»åçæè½ã
æ¹æ³ï¼æåå¾®èª¿äºä¸å LLaMa-2 13B èå¤© LLMï¼ä»¥ç¢çä¸ååæèªæåº«ï¼å¶ä¸­åå«ä¾èªçµ±ä¸é«å­¸èªè¨ç³»çµ± (UMLS) ç¾çèªç¾©ç¾¤çæ¨æºåæ¦å¿µæåãæåè¡¡éäº DER å DEN çæ´é«ååå¸å¤ (OOD) æè½ï¼æåæ²æåæè³ææ´åãæåä½¿ç¨ 4 ç¨®ä¸åçè³ææ´åç­ç¥è©ä¼°äº 3 åä¸åç¾çèªæåº«çæè½ï¼ä½¿ç¨ BioBERT è©ä¼° DERï¼ä½¿ç¨ SapBERT å KrissBERT è©ä¼° DENã
çµæï¼æåçåæè³æå° DEN ç¢çäºé¡¯èçæ¹åï¼å¨ææ 3 åè¨ç·´èªæåº«ä¸­ï¼SapBERT å KrissBERT çå 1 åæºç¢ºçå¨æ´é«æè½ä¸æé«äº 3-9 åç¾åé»ï¼å¨ OOD è³æä¸­æé«äº 20-55 åç¾åé»ãå¨ DER çæ´é«æè½ä¸ä¹çå°äºå¾®å°çæ¹åï¼1-2 åç¾åé»ï¼ï¼ä½åªæä¸çµè³æé¡¯ç¤ºåº OOD æ¹åã
çµè«ï¼èä¸å©ç¨ LLM æ´åè³æä»¥åææåçæ­£è¦åæ¹æ³ç¸æ¯ï¼LLM çæçæ¨æºåç¾çæåå¯ä»¥æ¹å DENãæ¶èç ç©¶è¡¨æï¼DEN çæè½æååé¨åæ­¸å æ¼ OOD æè½çæ¹åãç¸åçæ¹æ³å°æ¼æ¹å DER çè½åæéãæåå¬éæåçè»é«åè³æéã</paragraph>

##### **Benchmarking Agentic Workflow Generation**
2410.07869v1 by Shuofei Qiao, Runnan Fang, Zhisong Qiu, Xiaobin Wang, Ningyu Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen

Large Language Models (LLMs), with their exceptional ability to handle a wide
range of tasks, have driven significant advancements in tackling reasoning and
planning tasks, wherein decomposing complex problems into executable workflows
is a crucial step in this process. Existing workflow evaluation frameworks
either focus solely on holistic performance or suffer from limitations such as
restricted scenario coverage, simplistic workflow structures, and lax
evaluation standards. To this end, we introduce WorFBench, a unified workflow
generation benchmark with multi-faceted scenarios and intricate graph workflow
structures. Additionally, we present WorFEval, a systemic evaluation protocol
utilizing subsequence and subgraph matching algorithms to accurately quantify
the LLM agent's workflow generation capabilities. Through comprehensive
evaluations across different types of LLMs, we discover distinct gaps between
the sequence planning capabilities and graph planning capabilities of LLM
agents, with even GPT-4 exhibiting a gap of around 15%. We also train two
open-source models and evaluate their generalization abilities on held-out
tasks. Furthermore, we observe that the generated workflows can enhance
downstream tasks, enabling them to achieve superior performance with less time
during inference. Code and dataset will be available at
https://github.com/zjunlp/WorFBench.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ææèçåç¨®ä»»åçéå¡è½åï¼æ¨åäºè§£æ±ºæ¨çåè¦åä»»åçé¡¯èé²å±ï¼å¶ä¸­å°è¤éåé¡åè§£çºå¯å·è¡å·¥ä½æµç¨æ¯æ­¤éç¨ä¸­è³ééè¦çä¸æ­¥ãç¾æçå·¥ä½æµç¨è©ä¼°æ¡æ¶åªå°æ³¨æ¼æ´é«æè½ï¼æåå°æå¢æ¶µèç¯ååéãå·¥ä½æµç¨çµæ§ç°¡ååè©ä¼°æ¨æºå¯¬é¬ç­éå¶ãçºæ­¤ï¼æåå¼å¥äº WorFBenchï¼ä¸åçµ±ä¸çå·¥ä½æµç¨çæåºæºï¼å·æå¤æ¹é¢çå ´æ¯åè¤éçåå½¢å·¥ä½æµç¨çµæ§ãæ­¤å¤ï¼æåæåºäº WorFEvalï¼ä¸åå©ç¨å­åºååå­åå¹éæ¼ç®æ³ä¾æºç¢ºéå LLM ä»£çå·¥ä½æµç¨çæè½åçç³»çµ±æ§è©ä¼°åå®ãééå°ä¸åé¡å LLM çå¨é¢è©ä¼°ï¼æåç¼ç¾ LLM ä»£ççåºåè¦åè½åååå½¢è¦åè½åä¹éå­å¨æé¡¯çå·®è·ï¼å³ä½¿æ¯ GPT-4 ä¹è¡¨ç¾åºç´ 15% çå·®è·ãæåéè¨ç·´äºå©åéæºæ¨¡åï¼ä¸¦è©ä¼°äºå®åå¨ä¿çä»»åä¸çæ³åè½åãæ­¤å¤ï¼æåè§å¯å°çæççå·¥ä½æµç¨å¯ä»¥å¢å¼·ä¸æ¸¸ä»»åï¼è®å®åå¨æ¨çæéä»¥æ´å°çæéç²å¾æ´å¥½çæè½ãç¨å¼ç¢¼åè³æéå°å¨ https://github.com/zjunlp/WorFBench ä¸æä¾ã

##### **KRAG Framework for Enhancing LLMs in the Legal Domain**
2410.07551v1 by Nguyen Ha Thanh, Ken Satoh

This paper introduces Knowledge Representation Augmented Generation (KRAG), a
novel framework designed to enhance the capabilities of Large Language Models
(LLMs) within domain-specific applications. KRAG points to the strategic
inclusion of critical knowledge entities and relationships that are typically
absent in standard data sets and which LLMs do not inherently learn. In the
context of legal applications, we present Soft PROLEG, an implementation model
under KRAG, which uses inference graphs to aid LLMs in delivering structured
legal reasoning, argumentation, and explanations tailored to user inquiries.
The integration of KRAG, either as a standalone framework or in tandem with
retrieval augmented generation (RAG), markedly improves the ability of language
models to navigate and solve the intricate challenges posed by legal texts and
terminologies. This paper details KRAG's methodology, its implementation
through Soft PROLEG, and potential broader applications, underscoring its
significant role in advancing natural language understanding and processing in
specialized knowledge domains.

æè¦ï¼æ¬æä»ç´¹ç¥è­è¡¨å¾µå¢å¼·çæ (KRAG)ï¼ä¸åæ°ç©çæ¶æ§ï¼æ¨å¨å¢å¼·å¤§åèªè¨æ¨¡å (LLM) å¨ç¹å®é åæç¨ä¸­çè½åãKRAG æåºç­ç¥æ§å°ç´å¥ééµç¥è­å¯¦é«åéä¿ï¼éäºå¯¦é«åéä¿éå¸¸ä¸å­å¨æ¼æ¨æºè³æéä¸­ï¼è LLM ä¹ç¡æ³åºæå°å­¸ç¿ãå¨æ³å¾æç¨æ¹é¢ï¼æåæåº Soft PROLEGï¼éæ¯ä¸åå¨ KRAG ä¸çå¯¦ä½æ¨¡åï¼å®ä½¿ç¨æ¨çåä¾åå© LLM æä¾çµæ§åçæ³å¾æ¨çãè«è­åè§£éï¼ä»¥æ»¿è¶³ä½¿ç¨èçè©¢åãæ´å KRAGï¼ç¡è«æ¯ä½çºç¨ç«æ¶æ§æèæª¢ç´¢å¢å¼·çæ (RAG) çµåä½¿ç¨ï¼é½è½é¡¯èæåèªè¨æ¨¡åå°èªåè§£æ±ºæ³å¾ææ¬åè¡èªæå¸¶ä¾çè¤éææ°çè½åãæ¬æè©³è¿° KRAG çæ¹æ³è«ãéé Soft PROLEG çå¯¦ä½ï¼ä»¥åæ½å¨çæ´å»£æ³æç¨ï¼å¼·èª¿å¶å¨æ¨é²å°æ¥­ç¥è­é åçèªç¶èªè¨çè§£åèçä¸­æ®æ¼çéè¦è§è²ã

##### **MKGL: Mastery of a Three-Word Language**
2410.07526v1 by Lingbing Guo, Zhongpu Bo, Zhuo Chen, Yichi Zhang, Jiaoyan Chen, Yarong Lan, Mengshu Sun, Zhiqiang Zhang, Yangyifei Luo, Qian Li, Qiang Zhang, Wen Zhang, Huajun Chen

Large language models (LLMs) have significantly advanced performance across a
spectrum of natural language processing (NLP) tasks. Yet, their application to
knowledge graphs (KGs), which describe facts in the form of triplets and allow
minimal hallucinations, remains an underexplored frontier. In this paper, we
investigate the integration of LLMs with KGs by introducing a specialized KG
Language (KGL), where a sentence precisely consists of an entity noun, a
relation verb, and ends with another entity noun. Despite KGL's unfamiliar
vocabulary to the LLM, we facilitate its learning through a tailored dictionary
and illustrative sentences, and enhance context understanding via real-time KG
context retrieval and KGL token embedding augmentation. Our results reveal that
LLMs can achieve fluency in KGL, drastically reducing errors compared to
conventional KG embedding methods on KG completion. Furthermore, our enhanced
LLM shows exceptional competence in generating accurate three-word sentences
from an initial entity and interpreting new unseen terms out of KGs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¤§å¹æååç¨®èªç¶èªè¨èç (NLP) ä»»åçæè½ãç¶èï¼å®åå¨ç¥è­åè­ (KG) çæç¨ä¸ä»æå¾éç¼ï¼ç¥è­åè­ä»¥ä¸åçµå½¢å¼æè¿°äºå¯¦ï¼ä¸¦åè¨±æå°çå¹»è¦ºãå¨æ¬æä¸­ï¼æåééå¼å¥ä¸ç¨®å°æ¥­ç KG èªè¨ (KGL) ä¾æ¢è¨ LLM è KG çæ´åï¼å¶ä¸­ä¸åå¥å­ç²¾ç¢ºå°åå«ä¸åå¯¦é«åè©ãä¸åéä¿åè©ï¼ä¸¦ä»¥å¦ä¸åå¯¦é«åè©çµå°¾ãåç®¡ LLM å° KGL çè©å½ä¸çæï¼ä½æåéééèº«æé çå­å¸åèªªææ§å¥å­ä¾ä¿é²å®çå­¸ç¿ï¼ä¸¦ééå³æ KG èæ¯æ·åå KGL ä»£å¹£åµå¥å¼·åä¾æåèæ¯çè§£ãæåççµæé¡¯ç¤ºï¼LLM è½å¤ æµæ¢ä½¿ç¨ KGLï¼å¤§å¹æ¸å°é¯èª¤ï¼åªæ¼ KG å®æä¸­å³çµ±ç KG åµå¥æ¹æ³ãæ­¤å¤ï¼æåå¢å¼·ç LLM å¨å¾åå§å¯¦é«çææºç¢ºçä¸å­è©å¥å­ï¼ä»¥åå¾ KG è§£éæ°çæªè¦è¡èªæ¹é¢å±ç¾åºåè¶çè½åã

##### **InstructG2I: Synthesizing Images from Multimodal Attributed Graphs**
2410.07157v1 by Bowen Jin, Ziqi Pang, Bingjun Guo, Yu-Xiong Wang, Jiaxuan You, Jiawei Han

In this paper, we approach an overlooked yet critical task Graph2Image:
generating images from multimodal attributed graphs (MMAGs). This task poses
significant challenges due to the explosion in graph size, dependencies among
graph entities, and the need for controllability in graph conditions. To
address these challenges, we propose a graph context-conditioned diffusion
model called InstructG2I. InstructG2I first exploits the graph structure and
multimodal information to conduct informative neighbor sampling by combining
personalized page rank and re-ranking based on vision-language features. Then,
a Graph-QFormer encoder adaptively encodes the graph nodes into an auxiliary
set of graph prompts to guide the denoising process of diffusion. Finally, we
propose graph classifier-free guidance, enabling controllable generation by
varying the strength of graph guidance and multiple connected edges to a node.
Extensive experiments conducted on three datasets from different domains
demonstrate the effectiveness and controllability of our approach. The code is
available at https://github.com/PeterGriffinJin/InstructG2I.

æè¦ï¼å¨æ¬æä¸­ï¼æä»¬æ¢è®¨ä¸é¡¹è¢«å¿½è§ä½è³å³éè¦çä»»å¡ Graph2Imageï¼
ä»å¤æ¨¡æå±æ§å¾ (MMAG) çæå¾åãç±äºå¾å¤§å°æ¿å¢ãå¾å®ä½ä¹é´çä¾èµå³ç³»ä»¥åå¯¹å¾æ¡ä»¶çå¯æ§æ§éæ±ï¼æ­¤ä»»å¡å¸¦æ¥äºéå¤§ææãä¸ºäºåºå¯¹è¿äºææï¼æä»¬æåºäºä¸ç§ç§°ä¸º InstructG2I çå¾ä¸ä¸ææ¡ä»¶æ©æ£æ¨¡åãInstructG2I é¦åå©ç¨å¾ç»æåå¤æ¨¡æä¿¡æ¯ï¼éè¿ç»åä¸ªæ§åé¡µé¢æåååºäºè§è§è¯­è¨ç¹å¾çéæ°æåæ¥æ§è¡ä¿¡æ¯ä¸°å¯çé»å±éæ ·ãç¶åï¼Graph-QFormer ç¼ç å¨å°å¾èç¹èªéåºå°ç¼ç ä¸ºä¸ç»è¾å©å¾æç¤ºï¼ä»¥æå¯¼æ©æ£çå»åªè¿ç¨ãæåï¼æä»¬æåºäºæ å¾åç±»å¨æå¯¼ï¼éè¿æ¹åå¾æå¯¼çå¼ºåº¦åä¸èç¹çå¤ä¸ªè¿æ¥è¾¹æ¥å®ç°å¯æ§çæãå¨æ¥èªä¸åé¢åçä¸ç»æ°æ®éä¸è¿è¡çå¹¿æ³å®éªè¯æäºæä»¬æ¹æ³çæææ§åå¯æ§æ§ãä»£ç å¯å¨ https://github.com/PeterGriffinJin/InstructG2I è·å¾ã

##### **CSSL: Contrastive Self-Supervised Learning for Dependency Parsing on Relatively Free Word Ordered and Morphologically Rich Low Resource Languages**
2410.06944v1 by Pretam Ray, Jivnesh Sandhan, Amrith Krishna, Pawan Goyal

Neural dependency parsing has achieved remarkable performance for low
resource morphologically rich languages. It has also been well-studied that
morphologically rich languages exhibit relatively free word order. This prompts
a fundamental investigation: Is there a way to enhance dependency parsing
performance, making the model robust to word order variations utilizing the
relatively free word order nature of morphologically rich languages? In this
work, we examine the robustness of graph-based parsing architectures on 7
relatively free word order languages. We focus on scrutinizing essential
modifications such as data augmentation and the removal of position encoding
required to adapt these architectures accordingly. To this end, we propose a
contrastive self-supervised learning method to make the model robust to word
order variations. Furthermore, our proposed modification demonstrates a
substantial average gain of 3.03/2.95 points in 7 relatively free word order
languages, as measured by the UAS/LAS Score metric when compared to the best
performing baseline.

æè¦ï¼ç¥ç¶ä¾è³´è§£æå°æ¼è³æºè¼å°çå½¢æè±å¯èªè¨å·²éå°é¡¯èçæè½ãå½¢æè±å¯èªè¨å±ç¾ç¸å°èªç±çèªåºï¼éé»ä¹å·²ç²å¾æ·±å¥æ¢è¨ãéå¼ç¼äºä¸é åºç¤èª¿æ¥ï¼æ¯å¦ææ¹æ³å¯ä»¥æåä¾è³´è§£ææè½ï¼è®æ¨¡åè½éééç¨å½¢æè±å¯èªè¨ç¸å°èªç±çèªåºç¹è³ªï¼å°èªåºè®åå·æç©©å¥æ§ï¼å¨éé å·¥ä½ä¸­ï¼æåæª¢è¦äº 7 ç¨®ç¸å°èªç±èªåºèªè¨ä¸­åºæ¼åè¡¨çè§£ææ¶æ§çç©©å¥æ§ãæåå°æ³¨æ¼å¯©è¦å¿è¦çä¿®æ¹ï¼ä¾å¦è³ææ´ååç§»é¤ä½ç½®ç·¨ç¢¼ï¼ä»¥é©ç¶å°èª¿æ´éäºæ¶æ§ãçºæ­¤ï¼æåæåºå°æ¯èªæç£ç£å­¸ç¿æ¹æ³ï¼è®æ¨¡åå°èªåºè®åå·æç©©å¥æ§ãæ­¤å¤ï¼æåæåºçä¿®æ¹å¨ 7 ç¨®ç¸å°èªç±èªåºèªè¨ä¸­å±ç¾äº 3.03/2.95 é»çé¡¯èå¹³åå¢çï¼éæ¯æ ¹æ UAS/LAS åæ¸ææ¨ï¼èæè½æä½³çåºæºç·é²è¡æ¯è¼å¾å¾åºççµæã

##### **Tree of Problems: Improving structured problem solving with compositionality**
2410.06634v1 by Armel Zebaze, BenoÃ®t Sagot, Rachel Bawden

Large Language Models (LLMs) have demonstrated remarkable performance across
multiple tasks through in-context learning. For complex reasoning tasks that
require step-by-step thinking, Chain-of-Thought (CoT) prompting has given
impressive results, especially when combined with self-consistency.
Nonetheless, some tasks remain particularly difficult for LLMs to solve. Tree
of Thoughts (ToT) and Graph of Thoughts (GoT) emerged as alternatives, dividing
the complex problem into paths of subproblems. In this paper, we propose Tree
of Problems (ToP), a simpler version of ToT, which we hypothesise can work
better for complex tasks that can be divided into identical subtasks. Our
empirical results show that our approach outperforms ToT and GoT, and in
addition performs better than CoT on complex reasoning tasks. All code for this
paper is publicly available here:
https://github.com/ArmelRandy/tree-of-problems.

æè¦ï¼å¤§åè¯­è¨æ¨¡å (LLM) å·²éè¿æå¢å­¦ä¹ å¨å¤é¡¹ä»»å¡ä¸­å±ç¤ºåºéå¡çæ§è½ãå¯¹äºéè¦å¾ªåºæ¸è¿æèçå¤ææ¨çä»»å¡ï¼æç»´é¾ (CoT) æç¤ºå·²åå¾ä»¤äººå°è±¡æ·±å»çç»æï¼å°¤å¶æ¯å¨ä¸èªæ´½æ§ç¸ç»åæ¶ãå°½ç®¡å¦æ­¤ï¼LLM ä»ç¶é¾ä»¥è§£å³æäºä»»å¡ãæç»´æ  (ToT) åæç»´å¾ (GoT) ä½ä¸ºæ¿ä»£æ¹æ¡åºç°ï¼å°å¤æé®é¢ååä¸ºå­é®é¢çè·¯å¾ãå¨æ¬æä¸­ï¼æä»¬æåºäºæç»´æ  (ToP)ï¼å®æ¯ ToT çä¸ä¸ªæ´ç®åççæ¬ï¼æä»¬åè®¾å®å¯ä»¥æ´å¥½å°éç¨äºå¯ä»¥ååä¸ºç¸åå­ä»»å¡çå¤æä»»å¡ãæä»¬çå®è¯ç»æè¡¨æï¼æä»¬çæ¹æ³ä¼äº ToT å GoTï¼å¹¶ä¸å¨å¤ææ¨çä»»å¡ä¸çè¡¨ç°ä¹ä¼äº CoTãæ¬æçææä»£ç å¨æ­¤å¬å¼æä¾ï¼
https://github.com/ArmelRandy/tree-of-problemsã

##### **Multi-Task Program Error Repair and Explanatory Diagnosis**
2410.07271v1 by Zhenyu Xu, Victor S. Sheng

Program errors can occur in any type of programming, and can manifest in a
variety of ways, such as unexpected output, crashes, or performance issues. And
program error diagnosis can often be too abstract or technical for developers
to understand, especially for beginners. The goal of this paper is to present a
novel machine-learning approach for Multi-task Program Error Repair and
Explanatory Diagnosis (mPRED). A pre-trained language model is used to encode
the source code, and a downstream model is specifically designed to identify
and repair errors. Programs and test cases will be augmented and optimized from
several perspectives. Additionally, our approach incorporates a "chain of
thoughts" method, which enables the models to produce intermediate reasoning
explanations before providing the final correction. To aid in visualizing and
analyzing the program structure, we use a graph neural network for program
structure visualization. Overall, our approach offers a promising approach for
repairing program errors across different programming languages and providing
helpful explanations to programmers.

æè¦ï¼ç¨å¼é¯èª¤å¯è½ç¼çå¨ä»»ä½é¡åçç¨å¼è¨­è¨ä¸­ï¼ä¸¦å¯è½ä»¥åç¨®æ¹å¼åç¾ï¼ä¾å¦æå¤è¼¸åºãç¶æ©ææè½åé¡ãç¨å¼é¯èª¤è¨ºæ·éå¸¸å°éç¼äººå¡ä¾èªªéæ¼æ½è±¡ææè¡æ§ï¼ç¹å¥æ¯å°æ¼åå­¸èèè¨ãæ¬æçç®çæ¯æåºä¸åæ°ç©çå¤ä»»åç¨å¼é¯èª¤ä¿®å¾©èè§£éæ§è¨ºæ· (mPRED) æ©å¨å­¸ç¿æ¹æ³ãé åè¨ç·´çèªè¨æ¨¡åç¨æ¼ç·¨ç¢¼åå§ç¢¼ï¼èä¸æ¸¸æ¨¡ååå°éè¨­è¨ç¨æ¼è­å¥åä¿®å¾©é¯èª¤ãç¨å¼åæ¸¬è©¦æ¡ä¾å°å¾å¤åè§åº¦é²è¡æ´ååæä½³åãæ­¤å¤ï¼æåçåæ³åå«ãæèéãæ¹æ³ï¼ä½¿æ¨¡åè½å¤ å¨æä¾æçµä¿®æ­£ä¹åç¢çä¸­éæ¨çèªªæãçºäºå¹«å©è¦è¦ºåååæç¨å¼çµæ§ï¼æåä½¿ç¨åå½¢ç¥ç¶ç¶²è·¯é²è¡ç¨å¼çµæ§è¦è¦ºåãç¸½çä¾èªªï¼æåçåæ³æä¾äºä¸åæåæ¯çæ¹æ³ï¼å¯ä»¥ç¨æ¼ä¿®å¾©ä¸åç¨å¼èªè¨ä¸­çç¨å¼é¯èª¤ï¼ä¸¦åç¨å¼è¨­è¨å¸«æä¾æç¨çèªªæã

##### **Counterfactual Causal Inference in Natural Language with Large Language Models**
2410.06392v1 by GaÃ«l Gendron, JoÅ¾e M. RoÅ¾anec, Michael Witbrock, Gillian Dobbie

Causal structure discovery methods are commonly applied to structured data
where the causal variables are known and where statistical testing can be used
to assess the causal relationships. By contrast, recovering a causal structure
from unstructured natural language data such as news articles contains numerous
challenges due to the absence of known variables or counterfactual data to
estimate the causal links. Large Language Models (LLMs) have shown promising
results in this direction but also exhibit limitations. This work investigates
LLM's abilities to build causal graphs from text documents and perform
counterfactual causal inference. We propose an end-to-end causal structure
discovery and causal inference method from natural language: we first use an
LLM to extract the instantiated causal variables from text data and build a
causal graph. We merge causal graphs from multiple data sources to represent
the most exhaustive set of causes possible. We then conduct counterfactual
inference on the estimated graph. The causal graph conditioning allows
reduction of LLM biases and better represents the causal estimands. We use our
method to show that the limitations of LLMs in counterfactual causal reasoning
come from prediction errors and propose directions to mitigate them. We
demonstrate the applicability of our method on real-world news articles.

æè¦ï¼å æç»æåç°æ¹æ³éå¸¸åºç¨äºç»æåæ°æ®ï¼å¶ä¸­å æåéæ¯å·²ç¥çï¼å¹¶ä¸å¯ä»¥ä½¿ç¨ç»è®¡æ£éªæ¥è¯ä¼°å æå³ç³»ãç¸æ¯ä¹ä¸ï¼ä»æ°é»æç« ç­éç»æåçèªç¶è¯­è¨æ°æ®ä¸­æ¢å¤å æç»æç±äºç¼ºå°å·²ç¥åéæåäºå®æ°æ®æ¥ä¼°è®¡å æå³ç³»èåå«ä¼å¤ææãå¤§åè¯­è¨æ¨¡å (LLM) å¨è¿ä¸ªæ¹åä¸æ¾ç¤ºåºæå¸æçç»æï¼ä½ä¹è¡¨ç°åºå±éæ§ãè¿é¡¹å·¥ä½è°æ¥äº LLM ä»ææ¬ææ¡£æå»ºå æå¾åæ§è¡åäºå®å ææ¨ççè½åãæä»¬æåºäºä¸ç§ä»èªç¶è¯­è¨ä¸­è¿è¡ç«¯å°ç«¯å æç»æåç°åå ææ¨ççæ¹æ³ï¼æä»¬é¦åä½¿ç¨ LLM ä»ææ¬æ°æ®ä¸­æåå®ä¾åçå æåéå¹¶æå»ºå æå¾ãæä»¬åå¹¶æ¥èªå¤ä¸ªæ°æ®æºçå æå¾ï¼ä»¥è¡¨ç¤ºå¯è½çæè¯¦å°½çå æéãç¶åï¼æä»¬å¯¹ä¼°è®¡å¾è¿è¡åäºå®æ¨çãå æå¾æ¡ä»¶åè®¸åå° LLM åå·®å¹¶æ´å¥½å°è¡¨ç¤ºå æä¼°è®¡éãæä»¬ä½¿ç¨æä»¬çæ¹æ³è¡¨æ LLM å¨åäºå®å ææ¨çä¸­çå±éæ§æ¥èªé¢æµè¯¯å·®ï¼å¹¶æåºåè½»å®ä»¬çæªæ½ãæä»¬å¨ç°å®ä¸ççæ°é»æç« ä¸­å±ç¤ºäºæä»¬æ¹æ³çéç¨æ§ã

##### **Less is More: Making Smaller Language Models Competent Subgraph Retrievers for Multi-hop KGQA**
2410.06121v1 by Wenyu Huang, Guancheng Zhou, Hongru Wang, Pavlos Vougiouklis, Mirella Lapata, Jeff Z. Pan

Retrieval-Augmented Generation (RAG) is widely used to inject external
non-parametric knowledge into large language models (LLMs). Recent works
suggest that Knowledge Graphs (KGs) contain valuable external knowledge for
LLMs. Retrieving information from KGs differs from extracting it from document
sets. Most existing approaches seek to directly retrieve relevant subgraphs,
thereby eliminating the need for extensive SPARQL annotations, traditionally
required by semantic parsing methods. In this paper, we model the subgraph
retrieval task as a conditional generation task handled by small language
models. Specifically, we define a subgraph identifier as a sequence of
relations, each represented as a special token stored in the language models.
Our base generative subgraph retrieval model, consisting of only 220M
parameters, achieves competitive retrieval performance compared to
state-of-the-art models relying on 7B parameters, demonstrating that small
language models are capable of performing the subgraph retrieval task.
Furthermore, our largest 3B model, when plugged with an LLM reader, sets new
SOTA end-to-end performance on both the WebQSP and CWQ benchmarks. Our model
and data will be made available online: https://github.com/hwy9855/GSR.

æè¦ï¼æª¢ç´¢å¢å¼·çæ (RAG) å»£æ³ç¨æ¼å°å¤é¨éåæ¸ç¥è­æ³¨å¥å¤§åèªè¨æ¨¡å (LLM)ãæè¿çç ç©¶è¡¨æï¼ç¥è­å (KG) åå«å° LLM æå¹å¼çå¤é¨ç¥è­ãå¾ KG ä¸­æ·åè³è¨èå¾æä»¶éä¸­æ·åè³è¨ä¸åãå¤§å¤æ¸ç¾ææ¹æ³å°æ±ç´æ¥æ·åç¸éå­åï¼å¾èæ¶é¤äºå°èªç¾©è§£ææ¹æ³å³çµ±ä¸æéçå»£æ³ SPARQL è¨»è§£çéæ±ãå¨æ¬æä¸­ï¼æåå°å­åæ·åä»»åå»ºæ¨¡çºç±å°åèªè¨æ¨¡åèççæ¢ä»¶çæä»»åãå·é«ä¾èªªï¼æåå°å­åè­å¥ç¬¦å®ç¾©çºéä¿åºåï¼æ¯åéä¿é½è¡¨ç¤ºçºå²å­å¨èªè¨æ¨¡åä¸­çç¹æ®æ¨è¨ãæåçåºç¤çæå¼å­åæ·åæ¨¡åååå« 220M åæ¸ï¼èä¾è³´ 7B åæ¸çææ°æ¨¡åç¸æ¯ï¼éå°äºå·æç«¶ç­åçæ·åæè½ï¼è­æå°åèªè¨æ¨¡åè½å¤ å·è¡å­åæ·åä»»åãæ­¤å¤ï¼ç¶æåæå¤§ç 3B æ¨¡åè LLM é±è®å¨çµåä½¿ç¨æï¼å¨ WebQSP å CWQ åºæºä¸è¨­å®äºæ°çç«¯å°ç«¯æè½ SOTAãæåçæ¨¡ååè³æå°å¨ç·ä¸å¬éï¼https://github.com/hwy9855/GSRã

##### **LLM-based SPARQL Query Generation from Natural Language over Federated Knowledge Graphs**
2410.06062v2 by Vincent Emonet, Jerven Bolleman, Severine Duvaud, Tarcisio Mendes de Farias, Ana Claudia Sima

We introduce a Retrieval-Augmented Generation (RAG) system for translating
user questions into accurate federated SPARQL queries over bioinformatics
knowledge graphs (KGs) leveraging Large Language Models (LLMs). To enhance
accuracy and reduce hallucinations in query generation, our system utilises
metadata from the KGs, including query examples and schema information, and
incorporates a validation step to correct generated queries. The system is
available online at chat.expasy.org.

æè¦ï¼æåå¼å¥æª¢ç´¢å¢å¼·çæ (RAG) ç³»çµ±ï¼ç¨æ¼å°ä½¿ç¨èåé¡ç¿»è­¯ææºç¢ºçè¯å SPARQL æ¥è©¢ï¼ä»¥å©ç¨å¤§åèªè¨æ¨¡å (LLM) é²è¡çç©è³è¨å­¸ç¥è­å (KG)ãçºäºå¢å¼·æºç¢ºæ§ä¸¦æ¸å°æ¥è©¢çæä¸­çå¹»è¦ºï¼æåçç³»çµ±å©ç¨ä¾èª KG çåè³æï¼åæ¬æ¥è©¢ç¯ä¾åæ¶æ§è³è¨ï¼ä¸¦çµåé©è­æ­¥é©ä¾ä¿®æ­£å·²çæçæ¥è©¢ãè©²ç³»çµ±å¯å¨ chat.expasy.org ä¸ç·ä½¿ç¨ã

##### **Jet Expansions of Residual Computation**
2410.06024v1 by Yihong Chen, Xiangxiang Xu, Yao Lu, Pontus Stenetorp, Luca Franceschi

We introduce a framework for expanding residual computational graphs using
jets, operators that generalize truncated Taylor series. Our method provides a
systematic approach to disentangle contributions of different computational
paths to model predictions. In contrast to existing techniques such as
distillation, probing, or early decoding, our expansions rely solely on the
model itself and requires no data, training, or sampling from the model. We
demonstrate how our framework grounds and subsumes logit lens, reveals a
(super-)exponential path structure in the recursive residual depth and opens up
several applications. These include sketching a transformer large language
model with $n$-gram statistics extracted from its computations, and indexing
the models' levels of toxicity knowledge. Our approach enables data-free
analysis of residual computation for model interpretability, development, and
evaluation.

æè¦ï¼æåå¼å¥äºä¸åæ¡æ¶ï¼ç¨å´å°æµæ´å±æ®å·®è¨ç®åï¼å´å°æµæ¯ä¸ç¨®å°æªæ·çæ³°åç´æ¸æ³åçéç®å­ãæåçéåæ¹æ³æä¾äºä¸åç³»çµ±åçéå¾ï¼ç¨ä¾è§£éä¸åè¨ç®è·¯å¾å°æ¨¡åé æ¸¬çè²¢ç»ãèç¾æçæè¡ï¼ä¾å¦è¸é¤¾ãæ¢æ¸¬ææ©æè§£ç¢¼ï¼ç¸åï¼æåçæ´å±åä¾è³´æ¼æ¨¡åæ¬èº«ï¼ä¸éè¦å¾æ¨¡åä¸­ç²åæ¸æãè¨ç·´æåæ¨£ãæåå±ç¤ºäºæåçæ¡æ¶å¦ä½å¥ å®åæ¦æ¬éè¼¯éé¡ï¼æ­ç¤ºäºéæ­¸æ®å·®æ·±åº¦ä¸­çï¼è¶ï¼ææ¸è·¯å¾çµæ§ï¼ä¸¦æéäºå¹¾åæç¨ãéäºæç¨åæ¬ç¨å¾å¶è¨ç®ä¸­æåç n-gram çµ±è¨æ¸æç¹ªè£½ä¸åTransformerå¤§åèªè¨æ¨¡åï¼ä¸¦ç´¢å¼æ¨¡åçæ¯æ§ç¥è­ç´å¥ãæåçéç¨®æ¹æ³è½å¤ å°æ®å·®è¨ç®é²è¡ç¡æ¸æåæï¼ç¨æ¼æ¨¡åçå¯è§£éæ§ãéç¼åè©ä¼°ã

##### **A large collection of bioinformatics question-query pairs over federated knowledge graphs: methodology and applications**
2410.06010v1 by Jerven Bolleman, Vincent Emonet, Adrian Altenhoff, Amos Bairoch, Marie-Claude Blatter, Alan Bridge, Severine Duvaud, Elisabeth Gasteiger, Dmitry Kuznetsov, Sebastien Moretti, Pierre-Andre Michel, Anne Morgat, Marco Pagni, Nicole Redaschi, Monique Zahn-Zabal, Tarcisio Mendes de Farias, Ana Claudia Sima

Background. In the last decades, several life science resources have
structured data using the same framework and made these accessible using the
same query language to facilitate interoperability. Knowledge graphs have seen
increased adoption in bioinformatics due to their advantages for representing
data in a generic graph format. For example, yummydata.org catalogs more than
60 knowledge graphs accessible through SPARQL, a technical query language.
Although SPARQL allows powerful, expressive queries, even across physically
distributed knowledge graphs, formulating such queries is a challenge for most
users. Therefore, to guide users in retrieving the relevant data, many of these
resources provide representative examples. These examples can also be an
important source of information for machine learning, if a sufficiently large
number of examples are provided and published in a common, machine-readable and
standardized format across different resources.
  Findings. We introduce a large collection of human-written natural language
questions and their corresponding SPARQL queries over federated bioinformatics
knowledge graphs (KGs) collected for several years across different research
groups at the SIB Swiss Institute of Bioinformatics. The collection comprises
more than 1000 example questions and queries, including 65 federated queries.
We propose a methodology to uniformly represent the examples with minimal
metadata, based on existing standards. Furthermore, we introduce an extensive
set of open-source applications, including query graph visualizations and smart
query editors, easily reusable by KG maintainers who adopt the proposed
methodology.
  Conclusions. We encourage the community to adopt and extend the proposed
methodology, towards richer KG metadata and improved Semantic Web services.

æè¦ï¼<paragraph>èæ¯ãå¨éå»å¹¾åå¹´ï¼è¨±å¤çå½ç§å­¸è³æºä½¿ç¨ç¸åçæ¶æ§ä¾å»ºæ§è³æï¼ä¸¦ä½¿ç¨ç¸åçæ¥è©¢èªè¨ä¾å­åéäºè³æï¼ä»¥ä¿é²äºæä½æ§ãç¥è­åè­ç±æ¼å¶ä»¥éç¨åå½¢æ ¼å¼è¡¨ç¤ºè³æçåªé»ï¼å æ­¤å¨çç©è³è¨å­¸ä¸­ç²å¾äºè¶ä¾è¶å»£æ³çæ¡ç¨ãä¾å¦ï¼yummydata.org ç·¨éäºè¶é 60 åå¯ééæè¡æ¥è©¢èªè¨ SPARQL å­åçç¥è­åè­ãåç®¡ SPARQL åè¨±é²è¡å¼·å¤§ä¸å·è¡¨éåçæ¥è©¢ï¼çè³è·¨è¶å¯¦é«åå¸çç¥è­åè­ï¼ä½å°å¤§å¤æ¸ä½¿ç¨èä¾èªªï¼å¶å®æ­¤é¡æ¥è©¢æ¯ä¸é ææ°ãå æ­¤ï¼çºäºæå°ä½¿ç¨èæ·åç¸éè³æï¼å¶ä¸­è¨±å¤è³æºæä¾äºå·ä»£è¡¨æ§çç¯ä¾ãå¦ææä¾äºè¶³å¤ å¤§éçç¯ä¾ï¼ä¸¦ä»¥è·¨ä¸åè³æºçéç¨ãæ©å¨å¯è®ä¸æ¨æºåçæ ¼å¼ç¼å¸ï¼éäºç¯ä¾ä¹å¯ä»¥æçºæ©å¨å­¸ç¿çéè¦è³è¨ä¾æºã
  ç¼ç¾ãæåå¼å¥äºå¤§éç±äººé¡æ°å¯«çèªç¶èªè¨åé¡åå¶å°æç SPARQL æ¥è©¢ï¼éäºæ¥è©¢æ¯å¤å¹´ä¾å¨ SIB çå£«çç©è³è¨å­¸ç ç©¶æçä¸åç ç©¶å°çµä¸­æ¶éçï¼æ¶µèäºè¯é¦çç©è³è¨å­¸ç¥è­åè­ (KG)ãè©²éååå« 1000 å¤åç¯ä¾åé¡åæ¥è©¢ï¼åæ¬ 65 åè¯é¦æ¥è©¢ãæåæåºäºä¸ç¨®æ¹æ³ï¼åºæ¼ç¾ææ¨æºï¼ä»¥æå°çåè³æçµ±ä¸è¡¨ç¤ºéäºç¯ä¾ãæ­¤å¤ï¼æåéå¼å¥äºä¸å¥å»£æ³çéæºæç¨ç¨å¼ï¼åæ¬æ¥è©¢åå½¢è¦è¦ºååæºæ§æ¥è©¢ç·¨è¼¯å¨ï¼éäºæç¨ç¨å¼å¾å®¹æè¢«æ¡ç¨ææåºæ¹æ³ç KG ç¶­è­·äººå¡éè¤ä½¿ç¨ã
  çµè«ãæåé¼åµç¤¾ç¾¤æ¡ç¨ä¸¦æ´åææåºçæ¹æ³ï¼ä»¥ç²å¾æ´è±å¯ç KG åè³æåæ¹åçèªæç¶²è·¯æåã</paragraph>

##### **LightRAG: Simple and Fast Retrieval-Augmented Generation**
2410.05779v1 by Zirui Guo, Lianghao Xia, Yanhua Yu, Tu Ao, Chao Huang

Retrieval-Augmented Generation (RAG) systems enhance large language models
(LLMs) by integrating external knowledge sources, enabling more accurate and
contextually relevant responses tailored to user needs. However, existing RAG
systems have significant limitations, including reliance on flat data
representations and inadequate contextual awareness, which can lead to
fragmented answers that fail to capture complex inter-dependencies. To address
these challenges, we propose LightRAG, which incorporates graph structures into
text indexing and retrieval processes. This innovative framework employs a
dual-level retrieval system that enhances comprehensive information retrieval
from both low-level and high-level knowledge discovery. Additionally, the
integration of graph structures with vector representations facilitates
efficient retrieval of related entities and their relationships, significantly
improving response times while maintaining contextual relevance. This
capability is further enhanced by an incremental update algorithm that ensures
the timely integration of new data, allowing the system to remain effective and
responsive in rapidly changing data environments. Extensive experimental
validation demonstrates considerable improvements in retrieval accuracy and
efficiency compared to existing approaches. We have made our LightRAG
open-source and available at the link: https://github.com/HKUDS/LightRAG.

æè¦ï¼æª¢ç´¢å¢å¼·çæ (RAG) ç³»çµ±ééæ´åå¤é¨ç¥è­ä¾æºä¾å¢å¼·å¤§åèªè¨æ¨¡å (LLM)ï¼è½éå°ä½¿ç¨èéæ±æä¾æ´æºç¢ºä¸èèçµ¡ç¸éçåæãç¶èï¼ç¾æç RAG ç³»çµ±æå¾å¤§çéå¶ï¼åæ¬ä¾è³´å¹³é¢è³æè¡¨ç¤ºåä¸è¶³çèçµ¡æç¥ï¼éå¯è½æå°è´ç¡æ³ææè¤éç¸äºä¾è³´æ§ççæ®µå¼ç­æ¡ãçºäºæå°éäºææ°ï¼æåæåº LightRAGï¼å®å°åå½¢çµæ§ç´å¥æå­ç´¢å¼åæª¢ç´¢æµç¨ä¸­ãéååµæ°æ¶æ§æ¡ç¨éå±¤æª¢ç´¢ç³»çµ±ï¼è½å¾ä½å±¤ç´åé«å±¤ç´ç¥è­ç¼ç¾ä¸­å¢å¼·å¨é¢çè³è¨æª¢ç´¢ãæ­¤å¤ï¼å°åå½¢çµæ§èåéè¡¨ç¤ºæ´åï¼æå©æ¼æææª¢ç´¢ç¸éå¯¦é«åå¶éä¿ï¼å¤§å¹æ¹ååææéï¼åæç¶­æèçµ¡ç¸éæ§ãæ­¤åè½é²ä¸æ­¥ééå¢éæ´æ°æ¼ç®æ³å¢å¼·ï¼å¯ç¢ºä¿åææ´åæ°è³æï¼è®ç³»çµ±å¨å¿«éè®åçè³æç°å¢ä¸­ä¿æææä¸å³æåæãå»£æ³çå¯¦é©é©è­é¡¯ç¤ºï¼èç¾ææ¹æ³ç¸æ¯ï¼æª¢ç´¢æºç¢ºåº¦åæçé½æé¡¯èçæ¹åãæåå·²éæ¾ LightRAG åå§ç¢¼ï¼ä¸¦æä¾ä»¥ä¸é£çµï¼https://github.com/HKUDS/LightRAGã

##### **Information Discovery in e-Commerce**
2410.05763v1 by Zhaochun Ren, Xiangnan He, Dawei Yin, Maarten de Rijke

Electronic commerce, or e-commerce, is the buying and selling of goods and
services, or the transmitting of funds or data online. E-commerce platforms
come in many kinds, with global players such as Amazon, Airbnb, Alibaba,
Booking.com, eBay, JD.com and platforms targeting specific geographic regions
such as Bol.com and Flipkart.com.Information retrieval has a natural role to
play in e-commerce, especially in connecting people to goods and services.
Information discovery in e-commerce concerns different types of search (e.g.,
exploratory search vs. lookup tasks), recommender systems, and natural language
processing in e-commerce portals. The rise in popularity of e-commerce sites
has made research on information discovery in e-commerce an increasingly active
research area. This is witnessed by an increase in publications and dedicated
workshops in this space. Methods for information discovery in e-commerce
largely focus on improving the effectiveness of e-commerce search and
recommender systems, on enriching and using knowledge graphs to support
e-commerce, and on developing innovative question answering and bot-based
solutions that help to connect people to goods and services. In this survey, an
overview is given of the fundamental infrastructure, algorithms, and technical
solutions for information discovery in e-commerce. The topics covered include
user behavior and profiling, search, recommendation, and language technology in
e-commerce.

æè¦ï¼é»å­ååï¼æé»å­ååï¼æ¯åååæåçè²·è³£ï¼æå¨ç·å³è¼¸è³éææ¸æãé»å­ååå¹³å°ç¨®é¡ç¹å¤ï¼åæ¬äºé¦¬éãAirbnbãé¿éå·´å·´ãBooking.comãeBayãäº¬æ±ç­å¨çå·¨é ­ï¼ä»¥åéå°ç¹å®å°çååçå¹³å°ï¼ä¾å¦ Bol.com å Flipkart.comãä¿¡æ¯æª¢ç´¢å¨é»å­ååä¸­æ®æ¼èèªç¶çè§è²ï¼ç¹å¥æ¯å¨å°äººèåååæåè¯ç¹«èµ·ä¾æ¹é¢ãé»å­ååä¸­çä¿¡æ¯ç¼ç¾æ¶åä¸åé¡åçæç´¢ï¼ä¾å¦æ¢ç´¢æ§æç´¢èæ¥æ¾ä»»åï¼ãæ¨è¦ç³»çµ±ä»¥åé»å­ååéæ¶ä¸­çèªç¶èªè¨èçãé»å­ååç¶²ç«çæ®åä½¿å¾é»å­ååä¸­çä¿¡æ¯ç¼ç¾ç ç©¶æçºä¸åè¶ä¾è¶æ´»èºçç ç©¶é åãéä¸é»å¯ä»¥å¾è©²é åçåºçç©åå°éç è¨æçå¢å ä¸­å¾å°è­æãé»å­ååä¸­ä¿¡æ¯ç¼ç¾çæ¹æ³ä¸»è¦éä¸­å¨æé«é»å­ååæç´¢åæ¨è¦ç³»çµ±çæææ§ãè±å¯åä½¿ç¨ç¥è­åè­ä¾æ¯æé»å­ååï¼ä»¥åéç¼åµæ°çåé¡è§£ç­ååºæ¼æ©å¨äººçè§£æ±ºæ¹æ¡ï¼ä»¥å¹«å©å°äººèåååæåè¯ç¹«èµ·ä¾ãå¨æ¬æ¬¡èª¿æ¥ä¸­ï¼æ¦è¿°äºé»å­ååä¸­ä¿¡æ¯ç¼ç¾çåºæ¬åºç¤è¨­æ½ãç®æ³åæè¡è§£æ±ºæ¹æ¡ãææ¶µèçä¸»é¡åæ¬é»å­ååä¸­çç¨æ¶è¡çºååæãæç´¢ãæ¨è¦åèªè¨æè¡ã

##### **Vector-ICL: In-context Learning with Continuous Vector Representations**
2410.05629v1 by Yufan Zhuang, Chandan Singh, Liyuan Liu, Jingbo Shang, Jianfeng Gao

Large language models (LLMs) have shown remarkable in-context learning (ICL)
capabilities on textual data. We explore whether these capabilities can be
extended to continuous vectors from diverse domains, obtained from black-box
pretrained encoders. By aligning input data with an LLM's embedding space
through lightweight projectors, we observe that LLMs can effectively process
and learn from these projected vectors, which we term Vector-ICL. In
particular, we find that pretraining projectors with general language modeling
objectives enables Vector-ICL, while task-specific finetuning further enhances
performance. In our experiments across various tasks and modalities, including
text reconstruction, numerical function regression, text classification,
summarization, molecule captioning, time-series classification, graph
classification, and fMRI decoding, Vector-ICL often surpasses both few-shot ICL
and domain-specific model or tuning. We further conduct analyses and case
studies, indicating the potential of LLMs to process vector representations
beyond traditional token-based paradigms.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨ææ¬è³æä¸å±ç¾åºé¡¯èçèªå¢å­¸ç¿ (ICL) è½åãæåæ¢è¨éäºè½åæ¯å¦å¯ä»¥æ´å±å°å¾ä¸åé ååå¾ï¼ä¸¦ç±é»ç®±é è¨ç·´ç·¨ç¢¼å¨ç²å¾çé£çºåéãééè¼éç´æå½±å¨å°è¼¸å¥è³æè LLM çåµå¥ç©ºéå°é½ï¼æåè§å¯å° LLM å¯ä»¥ææå°èçåå­¸ç¿éäºæå½±åéï¼æåç¨±ä¹çº Vector-ICLãç¹å¥æ¯ï¼æåç¼ç¾ä½¿ç¨ä¸è¬èªè¨å»ºæ¨¡ç®æ¨é è¨ç·´æå½±å¨å¯ä»¥åç¨ Vector-ICLï¼èç¹å®ä»»åçå¾®èª¿é²ä¸æ­¥æåäºæè½ãå¨æåè·¨è¶åç¨®ä»»ååæ¨¡æçå¯¦é©ä¸­ï¼åæ¬æå­éå»ºãæ¸å¼å½æ¸åæ­¸ãæå­åé¡ãæè¦ãåå­æ¨é¡ãæéåºååé¡ãåå½¢åé¡å fMRI è§£ç¢¼ï¼Vector-ICL éå¸¸é½åªæ¼å°æ¬¡æ¸ ICL åç¹å®é åæ¨¡åæèª¿æ´ãæåé²ä¸æ­¥é²è¡åæåæ¡ä¾ç ç©¶ï¼æåº LLM èçåéè¡¨ç¤ºçæ½åï¼è¶è¶å³çµ±çåºæ¼æ¨è¨çç¯ä¾ã

##### **Narrative-of-Thought: Improving Temporal Reasoning of Large Language Models via Recounted Narratives**
2410.05558v1 by Xinliang Frederick Zhang, Nick Beauchamp, Lu Wang

Reasoning about time and temporal relations is an integral aspect of human
cognition, essential for perceiving the world and navigating our experiences.
Though large language models (LLMs) have demonstrated impressive performance in
many reasoning tasks, temporal reasoning remains challenging due to its
intrinsic complexity. In this work, we first study an essential task of
temporal reasoning -- temporal graph generation, to unveil LLMs' inherent,
global reasoning capabilities. We show that this task presents great challenges
even for the most powerful LLMs, such as GPT-3.5/4. We also notice a
significant performance gap by small models (<10B) that lag behind LLMs by 50%.
Next, we study how to close this gap with a budget constraint, e.g., not using
model finetuning. We propose a new prompting technique tailored for temporal
reasoning, Narrative-of-Thought (NoT), that first converts the events set to a
Python class, then prompts a small model to generate a temporally grounded
narrative, guiding the final generation of a temporal graph. Extensive
experiments showcase the efficacy of NoT in improving various metrics. Notably,
NoT attains the highest F1 on the Schema-11 evaluation set, while securing an
overall F1 on par with GPT-3.5. NoT also achieves the best structural
similarity across the board, even compared with GPT-3.5/4. Our code is
available at https://github.com/launchnlp/NoT.

æè¦ï¼æ¨çæéåæééä¿æ¯äººé¡èªç¥ä¸­ä¸å¯æç¼ºçä¸ç°ï¼å°æ¼æç¥ä¸çåå°èªæåçç¶é©è³ééè¦ãåç®¡å¤§åèªè¨æ¨¡å (LLM) å¨è¨±å¤æ¨çä»»åä¸­è¡¨ç¾åºè²ï¼ä½ç±æ¼æéæ¨ççå§å¨è¤éæ§ï¼å æ­¤ä»ç¶å·æææ°æ§ãå¨éé å·¥ä½ä¸­ï¼æåé¦åç ç©¶æéæ¨ççä¸é åºæ¬ä»»åââæéåè¡¨çæï¼ä»¥æ­ç¤º LLM åºæçå¨å±æ¨çè½åãæåè¡¨æï¼å³ä½¿å°æ¼åè½æå¼ºå¤§ç LLMï¼ä¾å¦ GPT-3.5/4ï¼æ­¤ä»»åä¹æåºäºå·¨å¤§çææ°ãæåéæ³¨æå°ï¼è½å¾æ¼ LLM 50% çå°åæ¨¡å (<10B) å­å¨é¡¯èçæ§è½å·®è·ãæ¥ä¸ä¾ï¼æåç ç©¶å¦ä½å¨é ç®ç´æä¸ç¸®å°éç¨®å·®è·ï¼ä¾å¦ä¸ä½¿ç¨æ¨¡åå¾®èª¿ãæåæåºäºä¸ç¨®éå°æéæ¨çéèº«å®å¶çæ°æç¤ºæè¡ï¼å³æèæäº (NoT)ï¼å®é¦åå°äºä»¶éè½æçº Python é¡ï¼ç¶å¾æç¤ºä¸åå°åæ¨¡åçæä¸åæéä¾æçæäºï¼æå°æéåè¡¨çæçµçæãå¤§éçå¯¦é©å±ç¤ºäº NoT å¨æ¹ååç¨®ææ¨æ¹é¢çåæãå¼å¾æ³¨æçæ¯ï¼NoT å¨ Schema-11 è©ä¼°éä¸­ç²å¾äºæé«ç F1ï¼åæç¢ºä¿äºè GPT-3.5 ç¸ç¶çæ´é« F1ãå³ä½¿è GPT-3.5/4 ç¸æ¯ï¼NoT ä¹å¨åæ¹é¢å¯¦ç¾äºæä½³çµæ§ç¸ä¼¼æ§ãæåçä»£ç¢¼å¯å¨ https://github.com/launchnlp/NoT ä¸­ç²å¾ã

##### **Scalable and Accurate Graph Reasoning with LLM-based Multi-Agents**
2410.05130v1 by Yuwei Hu, Runlin Lei, Xinyi Huang, Zhewei Wei, Yongchao Liu

Recent research has explored the use of Large Language Models (LLMs) for
tackling complex graph reasoning tasks. However, due to the intricacies of
graph structures and the inherent limitations of LLMs in handling long text,
current approaches often fail to deliver satisfactory accuracy, even on
small-scale graphs and simple tasks. To address these challenges, we introduce
GraphAgent-Reasoner, a fine-tuning-free framework that utilizes a multi-agent
collaboration strategy for explicit and precise graph reasoning. Inspired by
distributed graph computation theory, our framework decomposes graph problems
into smaller, node-centric tasks that are distributed among multiple agents.
The agents collaborate to solve the overall problem, significantly reducing the
amount of information and complexity handled by a single LLM, thus enhancing
the accuracy of graph reasoning. By simply increasing the number of agents,
GraphAgent-Reasoner can efficiently scale to accommodate larger graphs with
over 1,000 nodes. Evaluated on the GraphInstruct dataset, our framework
demonstrates near-perfect accuracy on polynomial-time graph reasoning tasks,
significantly outperforming the best available models, both closed-source and
fine-tuned open-source variants. Our framework also demonstrates the capability
to handle real-world graph reasoning applications such as webpage importance
analysis.

æè¦ï¼è¿æç ç©¶å·²æ¢è¨ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾èçè¤éçåå½¢æ¨çä»»åãç¶èï¼ç±æ¼åå½¢çµæ§çè¤éæ§å LLM å¨èçé·ææ¬æåºæçéå¶ï¼ç¾ææ¹æ³éå¸¸ç¡æ³æä¾ä»¤äººæ»¿æçæºç¢ºæ§ï¼å³ä½¿æ¯å¨å°è¦æ¨¡åå½¢åç°¡å®ä»»åä¸ãçºäºæå°éäºææ°ï¼æåå¼å¥äº GraphAgent-Reasonerï¼éæ¯ä¸åç¡éå¾®èª¿çæ¡æ¶ï¼å®å©ç¨å¤ä¸»é«åä½ç­ç¥é²è¡æç¢ºä¸ç²¾ç¢ºçåå½¢æ¨çãæåçæ¡æ¶åå°åæ£å¼åå½¢è¨ç®çè«çåç¼ï¼å°åå½¢åé¡åè§£ææ´å°çä»¥ç¯é»çºä¸­å¿çä»»åï¼ä¸¦å°éäºä»»ååéçµ¦å¤åä¸»é«ãéäºä¸»é«åä½è§£æ±ºæ´é«åé¡ï¼å¤§å¹æ¸å°å®å LLM èççè³è¨éåè¤éåº¦ï¼å¾èæååå½¢æ¨ççæºç¢ºæ§ãééå®ç´å¢å ä¸»é«æ¸éï¼GraphAgent-Reasoner å¯ä»¥æææ´åä»¥å®¹ç´ç¯é»è¶é 1,000 åçå¤§ååå½¢ãå¨ GraphInstruct è³æéä¸é²è¡è©ä¼°ï¼æåçæ¡æ¶å¨å¤é å¼æéåå½¢æ¨çä»»åä¸å±ç¾åºè¿ä¹å®ç¾çæºç¢ºæ§ï¼å¤§å¹åªæ¼å¸é¢ä¸æå¥½çæ¨¡åï¼åå«éæºåå¾®èª¿éæºçæ¬ãæåçæ¡æ¶ä¹å±ç¾åºèççå¯¦ä¸çåå½¢æ¨çæç¨ç¨å¼çè½åï¼ä¾å¦ç¶²é éè¦æ§åæã

##### **Leverage Knowledge Graph and Large Language Model for Law Article Recommendation: A Case Study of Chinese Criminal Law**
2410.04949v1 by Yongming Chen, Miner Chen, Ye Zhu, Juan Pei, Siyu Chen, Yu Zhou, Yi Wang, Yifan Zhou, Hao Li, Songan Zhang

Court efficiency is vital for social stability. However, in most countries
around the world, the grassroots courts face case backlogs, with decisions
relying heavily on judicial personnel's cognitive labor, lacking intelligent
tools to improve efficiency. To address this issue, we propose an efficient law
article recommendation approach utilizing a Knowledge Graph (KG) and a Large
Language Model (LLM). Firstly, we propose a Case-Enhanced Law Article Knowledge
Graph (CLAKG) as a database to store current law statutes, historical case
information, and correspondence between law articles and historical cases.
Additionally, we introduce an automated CLAKG construction method based on LLM.
On this basis, we propose a closed-loop law article recommendation method.
Finally, through a series of experiments using judgment documents from the
website "China Judgements Online", we have improved the accuracy of law article
recommendation in cases from 0.549 to 0.694, demonstrating that our proposed
method significantly outperforms baseline approaches.

æè¦ï¼æ³é¢æçå°æ¼ç¤¾æç©©å®è³ééè¦ãç¶èï¼å¨ä¸çå¤§å¤æ¸åå®¶ä¸­ï¼åºå±¤æ³é¢é¢è¨æ¡ä»¶ç©å£ï¼å¤æ±ºå´éä¾è³´å¸æ³äººå¡çèªç¥ååï¼ç¼ºä¹æé«æççæºè½å·¥å·ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸åå©ç¨ç¥è­åè­ (KG) åå¤§åèªè¨æ¨¡å (LLM) çé«ææ³å¾æ¢ææ¨è¦æ¹æ³ãé¦åï¼æåæåºä¸åæ¡ä¾å¢å¼·æ³å¾æ¢æç¥è­åè­ (CLAKG) ä½çºä¸åè³æåº«ï¼ç¨æ¼å²å­ç¾è¡æ³å¾æ³è¦ãæ­·å²æ¡ä¾è³è¨åæ³å¾æ¢æèæ­·å²æ¡ä¾ä¹éçå°æéä¿ãæ­¤å¤ï¼æåå¼å¥ä¸ååºæ¼ LLM çèªåå CLAKG æ§å»ºæ¹æ³ãå¨æ­¤åºç¤ä¸ï¼æåæåºäºä¸åéç°æ³å¾æ¢ææ¨è¦æ¹æ³ãæå¾ï¼ééä¸é£ä¸²ä½¿ç¨ä¾èªç¶²ç«ãä¸­åè£å¤ææ¸ç¶²ãçè£å¤ææ¸çå¯¦é©ï¼æåå°æ¡ä»¶ä¸­æ³å¾æ¢ææ¨è¦çæºç¢ºçå¾ 0.549 æåè³ 0.694ï¼è­ææåæåºçæ¹æ³é¡¯èåªæ¼åºæºæ¹æ³ã

##### **GARLIC: LLM-Guided Dynamic Progress Control with Hierarchical Weighted Graph for Long Document QA**
2410.04790v1 by Xinyu Wang, Yanzheng Xiang, Lin Gui, Yulan He

In the past, Retrieval-Augmented Generation (RAG) methods split text into
chunks to enable language models to handle long documents. Recent tree-based
RAG methods are able to retrieve detailed information while preserving global
context. However, with the advent of more powerful LLMs, such as Llama 3.1,
which offer better comprehension and support for longer inputs, we found that
even recent tree-based RAG methods perform worse than directly feeding the
entire document into Llama 3.1, although RAG methods still hold an advantage in
reducing computational costs. In this paper, we propose a new retrieval method,
called LLM-Guided Dynamic Progress Control with Hierarchical Weighted Graph
(GARLIC), which outperforms previous state-of-the-art baselines, including
Llama 3.1, while retaining the computational efficiency of RAG methods. Our
method introduces several improvements: (1) Rather than using a tree structure,
we construct a Hierarchical Weighted Directed Acyclic Graph with many-to-many
summarization, where the graph edges are derived from attention mechanisms, and
each node focuses on a single event or very few events. (2) We introduce a
novel retrieval method that leverages the attention weights of LLMs rather than
dense embedding similarity. Our method allows for searching the graph along
multiple paths and can terminate at any depth. (3) We use the LLM to control
the retrieval process, enabling it to dynamically adjust the amount and depth
of information retrieved for different queries. Experimental results show that
our method outperforms previous state-of-the-art baselines, including Llama
3.1, on two single-document and two multi-document QA datasets, while
maintaining similar computational complexity to traditional RAG methods.

æè¦ï¼<paragraph>å¨éå»ï¼æª¢ç´¢å¢å¼·çæ (RAG) æ¹æ³æå°æå­åå²æå¡ï¼ä»¥ä½¿èªè¨æ¨¡åè½å¤ èçé·ç¯æä»¶ãæè¿çåºæ¼æ¨¹ç RAG æ¹æ³è½å¤ å¨ä¿çæ´é«èçµ¡çåææª¢ç´¢è©³ç´°è³è¨ãç¶èï¼é¨èåè½æ´å¼·å¤§ç LLMï¼ä¾å¦ Llama 3.1ï¼çåºç¾ï¼éäº LLM æä¾äºæ´å¥½ççè§£ååå°æ´é·è¼¸å¥çæ¯æ´ï¼æåç¼ç¾å³ä½¿æ¯æè¿çåºæ¼æ¨¹ç RAG æ¹æ³ä¹æ¯ç´æ¥å°æ´åæä»¶è¼¸å¥ Llama 3.1 çè¡¨ç¾æ´å·®ï¼åç®¡ RAG æ¹æ³å¨éä½éç®ææ¬æ¹é¢ä»å·ååªå¢ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°çæª¢ç´¢æ¹æ³ï¼ç¨±çºå·æåå±¤å æ¬åç LLM å¼å°åæé²åº¦æ§å¶ (GARLIC)ï¼å®åªæ¼ååçæåé²åºæºï¼åæ¬ Llama 3.1ï¼åæä¿çäº RAG æ¹æ³çéç®æçãæåçæ¹é²æ¹æ³å¼å¥äºå¤é æ¹é²ï¼(1) æåæ²æä½¿ç¨æ¨¹ççµæ§ï¼èæ¯æ§å»ºäºä¸åå·æå¤å°å¤æè¦çåå±¤å æ¬æåç¡ç°åï¼å¶ä¸­åéç·£æºèªæ³¨æåæ©å¶ï¼æ¯åç¯é»é½å°æ³¨æ¼å®ä¸äºä»¶ææ¥µå°æ¸äºä»¶ã(2) æåå¼å¥äºä¸ç¨®æ°ç©çæª¢ç´¢æ¹æ³ï¼å®å©ç¨ LLM çæ³¨æåæ¬éï¼èä¸æ¯å¯éåµå¥ç¸ä¼¼æ§ãæåçæ¹é²æ¹æ³åè¨±æ²¿å¤åè·¯å¾æå°åï¼ä¸¦ä¸å¯ä»¥å¨ä»»ä½æ·±åº¦çµæ­¢ã(3) æåä½¿ç¨ LLM ä¾æ§å¶æª¢ç´¢éç¨ï¼ä½¿å¶è½å¤ åæèª¿æ´çºä¸åæ¥è©¢æª¢ç´¢çè³è¨éåæ·±åº¦ãå¯¦é©çµæè¡¨æï¼æåçæ¹é²æ¹æ³å¨å©åå®æä»¶åå©åå¤æä»¶åç­è³æéä¸åªæ¼ååçæåé²åºæºï¼åæ¬ Llama 3.1ï¼åæç¶­æèå³çµ± RAG æ¹æ³é¡ä¼¼çéç®è¤éåº¦ã</paragraph>

##### **Reasoning-Enhanced Healthcare Predictions with Knowledge Graph Community Retrieval**
2410.04585v1 by Pengcheng Jiang, Cao Xiao, Minhao Jiang, Parminder Bhatia, Taha Kass-Hout, Jimeng Sun, Jiawei Han

Large language models (LLMs) have demonstrated significant potential in
clinical decision support. Yet LLMs still suffer from hallucinations and lack
fine-grained contextual medical knowledge, limiting their high-stake healthcare
applications such as clinical diagnosis. Traditional retrieval-augmented
generation (RAG) methods attempt to address these limitations but frequently
retrieve sparse or irrelevant information, undermining prediction accuracy. We
introduce KARE, a novel framework that integrates knowledge graph (KG)
community-level retrieval with LLM reasoning to enhance healthcare predictions.
KARE constructs a comprehensive multi-source KG by integrating biomedical
databases, clinical literature, and LLM-generated insights, and organizes it
using hierarchical graph community detection and summarization for precise and
contextually relevant information retrieval. Our key innovations include: (1) a
dense medical knowledge structuring approach enabling accurate retrieval of
relevant information; (2) a dynamic knowledge retrieval mechanism that enriches
patient contexts with focused, multi-faceted medical insights; and (3) a
reasoning-enhanced prediction framework that leverages these enriched contexts
to produce both accurate and interpretable clinical predictions. Extensive
experiments demonstrate that KARE outperforms leading models by up to
10.8-15.0% on MIMIC-III and 12.6-12.7% on MIMIC-IV for mortality and
readmission predictions. In addition to its impressive prediction accuracy, our
framework leverages the reasoning capabilities of LLMs, enhancing the
trustworthiness of clinical predictions.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨è¨åºæ±ºç­æ¯æ´ä¸­å±ç¾åºé¡¯èçæ½åãç¶èï¼LLM ä»æå¹»è¦ºä¸ç¼ºä¹ç´°ç·»çèæ¯é«çç¥è­ï¼éå¶äºå®åå¨é«é¢¨éªé«çä¿å¥æç¨ä¸­çä½¿ç¨ï¼ä¾å¦è¨åºè¨ºæ·ãå³çµ±çæª¢ç´¢å¢å¼·çæ (RAG) æ¹æ³è©¦åè§£æ±ºéäºéå¶ï¼ä½ç¶å¸¸æª¢ç´¢ç¨çæç¡éçè³è¨ï¼æå®³é æ¸¬æºç¢ºåº¦ãæåå¼å¥äº KAREï¼éæ¯ä¸åæ°ç©çæ¶æ§ï¼æ´åäºç¥è­åè­ (KG) ç¤¾ç¾¤å±¤ç´æª¢ç´¢è LLM æ¨çï¼ä»¥å¢å¼·é«çä¿å¥é æ¸¬ãKARE ééæ´åçç©é«å­¸è³æåº«ãè¨åºæç»å LLM çæçè¦è§£ï¼å»ºæ§äºä¸åå¨é¢çå¤ä¾æº KGï¼ä¸¦ä½¿ç¨éå±¤å¼åå½¢ç¤¾ç¾¤åµæ¸¬åæè¦é²è¡çµç¹ï¼ä»¥é²è¡ç²¾ç¢ºä¸èèæ¯ç¸éçè³è¨æª¢ç´¢ãæåçééµåµæ°åæ¬ï¼(1) ä¸ç¨®å¯éçé«çç¥è­çµæ§åæ¹æ³ï¼è½å¤ æºç¢ºæª¢ç´¢ç¸éè³è¨ï¼(2) ä¸ç¨®åæç¥è­æª¢ç´¢æ©å¶ï¼å®ä½¿ç¨æç¦é»ãå¤é¢åçé«çè¦è§£ä¾è±å¯æ£èèæ¯ï¼ä»¥å (3) ä¸åæ¨çå¢å¼·é æ¸¬æ¶æ§ï¼å®å©ç¨éäºè±å¯çèæ¯ä¾ç¢çæºç¢ºä¸å¯è§£éçè¨åºé æ¸¬ãå»£æ³çå¯¦é©è­æï¼KARE å¨ MIMIC-III ä¸çæ­»äº¡çååå¥é¢é æ¸¬ä¸­æ¯é åæ¨¡åé«åº 10.8-15.0%ï¼å¨ MIMIC-IV ä¸é«åº 12.6-12.7%ãé¤äºä»¤äººå°è±¡æ·±å»çé æ¸¬æºç¢ºåº¦å¤ï¼æåçæ¶æ§éå©ç¨äº LLM çæ¨çè½åï¼å¢å¼·äºè¨åºé æ¸¬çå¯ä¿¡åº¦ã

##### **Empowering Domain-Specific Language Models with Graph-Oriented Databases: A Paradigm Shift in Performance and Model Maintenance**
2410.03867v1 by Ricardo Di Pasquale, Soledad Represa

In an era dominated by data, the management and utilization of
domain-specific language have emerged as critical challenges in various
application domains, particularly those with industry-specific requirements.
Our work is driven by the need to effectively manage and process large volumes
of short text documents inherent in specific application domains. By leveraging
domain-specific knowledge and expertise, our approach aims to shape factual
data within these domains, thereby facilitating enhanced utilization and
understanding by end-users. Central to our methodology is the integration of
domain-specific language models with graph-oriented databases, facilitating
seamless processing, analysis, and utilization of textual data within targeted
domains. Our work underscores the transformative potential of the partnership
of domain-specific language models and graph-oriented databases. This
cooperation aims to assist researchers and engineers in metric usage,
mitigation of latency issues, boosting explainability, enhancing debug and
improving overall model performance. Moving forward, we envision our work as a
guide AI engineers, providing valuable insights for the implementation of
domain-specific language models in conjunction with graph-oriented databases,
and additionally provide valuable experience in full-life cycle maintenance of
this kind of products.

æè¦ï¼å¨è³æç¶éçæä»£ï¼ç¹å®é åèªè¨çç®¡çåæç¨å·²æçºåæç¨é åä¸­çééµææ°ï¼å°¤å¶æ¯é£äºå·æç¢æ¥­ç¹å®éæ±çé åãæåçç ç©¶åæ©æ¯ææç®¡çåèçç¹å®æç¨é åä¸­åºæçæµ·éç°¡ç­ææ¬æä»¶ãéééç¨ç¹å®é åçç¥è­åå°æ¥­ç¥è­ï¼æåçåæ³æ¨å¨å½¢å¡éäºé åä¸­çäºå¯¦è³æï¼é²èä¿é²æçµä½¿ç¨èå¢å¼·å©ç¨åçè§£ãæåæ¹æ³çæ ¸å¿æ¯å°ç¹å®é åçèªè¨æ¨¡åèåå½¢å°åè³æåº«æ´åï¼ä¿é²ç®æ¨é åä¸­æå­è³æçç¡ç¸«èçãåæåå©ç¨ãæåçç ç©¶å¼·èª¿äºç¹å®é åèªè¨æ¨¡åèåå½¢å°åè³æåº«åä½çè½åæ½åãéç¨®åä½æ¨å¨åå©ç ç©¶äººå¡åå·¥ç¨å¸«é²è¡ææ¨ä½¿ç¨ãæ¸è¼å»¶é²åé¡ãæåå¯è§£éæ§ãå¢å¼·é¤é¯ï¼ä¸¦æ¹åæ´é«æ¨¡åæè½ãå±ææªä¾ï¼æåé ææåçç ç©¶å°æçºäººå·¥æºæ§å·¥ç¨å¸«çæåï¼æä¾æå¹å¼çè¦è§£ï¼ä¾ä»åå°ç¹å®é åèªè¨æ¨¡åèåå½¢å°åè³æåº«çµåå¯¦ä½ï¼ä¸¦é²ä¸æ­¥æä¾æ­¤é¡ç¢åå¨çå½é±æç¶­è­·çå¯¶è²´ç¶é©ã

##### **GraphRouter: A Graph-based Router for LLM Selections**
2410.03834v1 by Tao Feng, Yanzhen Shen, Jiaxuan You

The rapidly growing number and variety of Large Language Models (LLMs)
present significant challenges in efficiently selecting the appropriate LLM for
a given query, especially considering the trade-offs between performance and
computational cost. Current LLM selection methods often struggle to generalize
across new LLMs and different tasks because of their limited ability to
leverage contextual interactions among tasks, queries, and LLMs, as well as
their dependence on a transductive learning framework. To address these
shortcomings, we introduce a novel inductive graph framework, named as
GraphRouter, which fully utilizes the contextual information among tasks,
queries, and LLMs to enhance the LLM selection process. GraphRouter constructs
a heterogeneous graph comprising task, query, and LLM nodes, with interactions
represented as edges, which efficiently captures the contextual information
between the query's requirements and the LLM's capabilities. Through an
innovative edge prediction mechanism, GraphRouter is able to predict attributes
(the effect and cost of LLM response) of potential edges, allowing for
optimized recommendations that adapt to both existing and newly introduced LLMs
without requiring retraining. Comprehensive experiments across three distinct
effect-cost weight scenarios have shown that GraphRouter substantially
surpasses existing routers, delivering a minimum performance improvement of
12.3%. In addition, it achieves enhanced generalization across new LLMs
settings and supports diverse tasks with at least a 9.5% boost in effect and a
significant reduction in computational demands. This work endeavors to apply a
graph-based approach for the contextual and adaptive selection of LLMs,
offering insights for real-world applications. Our codes for GraphRouter will
soon be released at https://github.com/ulab-uiuc/GraphRouter.

æè¦ï¼<paragraph>å¤§åèªè¨æ¨¡å (LLM) çæ¸éåç¨®é¡å¿«éå¢é·ï¼å¨ææå°éå°ç¹å®æ¥è©¢é¸æé©ç¶ç LLM ææå¸¶ä¾éå¤§çææ°ï¼ç¹å¥æ¯èæ®å°æè½åéç®ææ¬ä¹éçæ¬è¡¡ãç®åç LLM é¸ææ¹æ³éå¸¸é£ä»¥æ¦æ¬å°æ°ç LLM åä¸åçä»»åï¼å çºå®åå¨å©ç¨ä»»åãæ¥è©¢å LLM ä¹éçèçµ¡äºåæ¹é¢çè½åæéï¼èä¸ä¾è³´æ¼è½å°å­¸ç¿æ¶æ§ãçºäºè§£æ±ºéäºç¼ºé»ï¼æåå¼é²äºä¸ååçº GraphRouter çæ°æ­¸ç´åå½¢æ¶æ§ï¼å®ååå©ç¨ä»»åãæ¥è©¢å LLM ä¹éçèçµ¡è³è¨ä¾å¢å¼· LLM é¸ææµç¨ãGraphRouter æ§å»ºäºä¸åç°è³ªåå½¢ï¼åå«ä»»åãæ¥è©¢å LLM ç¯é»ï¼ä¸¦å°äºåè¡¨ç¤ºçºéç·£ï¼ææå°æ·åæ¥è©¢éæ±å LLM è½åä¹éçèçµ¡è³è¨ãééåµæ°çéç·£é æ¸¬æ©å¶ï¼GraphRouter è½å¤ é æ¸¬æ½å¨éç·£çå±¬æ§ï¼LLM åæçææåææ¬ï¼ï¼åè¨±æä½³åå»ºè­°ï¼ä»¥é©æç¾æåæ°æ¨åºç LLMï¼èç¡ééæ°è¨ç·´ãå¨ä¸åä¸åçææææ¬æ¬éæå¢ä¸­é²è¡çå¨é¢å¯¦é©é¡¯ç¤ºï¼GraphRouter æé¡¯è¶è¶ç¾æçè·¯ç±å¨ï¼æè½è³å°æå 12.3%ãæ­¤å¤ï¼å®å¨æ°ç LLM è¨­å®ä¸­å¯¦ç¾äºå¢å¼·çæ¦æ¬æ§ï¼ä¸¦æ¯æ´å¤æ¨£åçä»»åï¼ææè³å°æå 9.5%ï¼ä¸¦å¤§å¹éä½éç®éæ±ãéé å·¥ä½è´åæ¼æç¨åºæ¼åå½¢çæ¹æ³ï¼ä»¥é²è¡ LLM çèçµ¡åé©ææ§é¸æï¼çºçå¯¦ä¸ççæç¨æä¾è¦è§£ãæåç GraphRouter ç¨å¼ç¢¼å°å¾å¿«å¨ https://github.com/ulab-uiuc/GraphRouter ç¼å¸ã</paragraph>

##### **Should Cross-Lingual AMR Parsing go Meta? An Empirical Assessment of Meta-Learning and Joint Learning AMR Parsing**
2410.03357v1 by Jeongwoo Kang, Maximin Coavoux, CÃ©dric Lopez, Didier Schwab

Cross-lingual AMR parsing is the task of predicting AMR graphs in a target
language when training data is available only in a source language. Due to the
small size of AMR training data and evaluation data, cross-lingual AMR parsing
has only been explored in a small set of languages such as English, Spanish,
German, Chinese, and Italian. Taking inspiration from Langedijk et al. (2022),
who apply meta-learning to tackle cross-lingual syntactic parsing, we
investigate the use of meta-learning for cross-lingual AMR parsing. We evaluate
our models in $k$-shot scenarios (including 0-shot) and assess their
effectiveness in Croatian, Farsi, Korean, Chinese, and French. Notably, Korean
and Croatian test sets are developed as part of our work, based on the existing
The Little Prince English AMR corpus, and made publicly available. We
empirically study our method by comparing it to classical joint learning. Our
findings suggest that while the meta-learning model performs slightly better in
0-shot evaluation for certain languages, the performance gain is minimal or
absent when $k$ is higher than 0.

æè¦ï¼è·¨èªè¨ AMR è§£ææ¯ä¸é ä»»åï¼å¨åå¨æºèªè¨ä¸­æä¾è¨ç·´è³ææï¼é æ¸¬ç®æ¨èªè¨ä¸­ç AMR åå½¢ãç±æ¼ AMR è¨ç·´è³æåè©ä¼°è³æçè¦æ¨¡å¾å°ï¼å æ­¤è·¨èªè¨ AMR è§£æåå¨å°æ¸èªè¨ä¸­é²è¡éæ¢ç´¢ï¼ä¾å¦è±èªãè¥¿ç­çèªãå¾·èªãä¸­æåç¾©å¤§å©èªãåå° Langedijk ç­äºº (2022) çåç¼ï¼ä»åæç¨åå­¸ç¿ä¾èçè·¨èªè¨å¥æ³è§£æï¼æåç ç©¶äºä½¿ç¨åå­¸ç¿é²è¡è·¨èªè¨ AMR è§£æãæåå¨ $k$-shot å ´æ¯ï¼åæ¬ 0-shotï¼ä¸­è©ä¼°æåçæ¨¡åï¼ä¸¦è©ä¼°å®åå¨åç¾åè¥¿äºèªãæ³¢æ¯èªãéèªãä¸­æåæ³èªä¸­çæææ§ãå¼å¾æ³¨æçæ¯ï¼éèªååç¾åè¥¿äºèªæ¸¬è©¦éæ¯æ ¹æç¾æçãå°çå­ãè±èª AMR èªæåº«éç¼çï¼ä¸¦å¬éæä¾ãæåééå°æåçæ¨¡åèå³çµ±è¯åå­¸ç¿é²è¡æ¯è¼ï¼å°æåçæ¨¡åé²è¡å¯¦è­ç ç©¶ãæåçç ç©¶çµæè¡¨æï¼éç¶åå­¸ç¿æ¨¡åå¨æäºèªè¨ç 0-shot è©ä¼°ä¸­è¡¨ç¾ç¥å¥½ï¼ä½æ¯ç¶ $k$ é«æ¼ 0 æï¼æè½æåå¾å°ææ²æã

##### **Enriching Ontologies with Disjointness Axioms using Large Language Models**
2410.03235v1 by Elias Crum, Antonio De Santis, Manon Ovide, Jiaxin Pan, Alessia Pisu, Nicolas Lazzari, Sebastian Rudolph

Ontologies often lack explicit disjointness declarations between classes,
despite their usefulness for sophisticated reasoning and consistency checking
in Knowledge Graphs. In this study, we explore the potential of Large Language
Models (LLMs) to enrich ontologies by identifying and asserting class
disjointness axioms. Our approach aims at leveraging the implicit knowledge
embedded in LLMs, using prompt engineering to elicit this knowledge for
classifying ontological disjointness. We validate our methodology on the
DBpedia ontology, focusing on open-source LLMs. Our findings suggest that LLMs,
when guided by effective prompt strategies, can reliably identify disjoint
class relationships, thus streamlining the process of ontology completion
without extensive manual input. For comprehensive disjointness enrichment, we
propose a process that takes logical relationships between disjointness and
subclass statements into account in order to maintain satisfiability and reduce
the number of calls to the LLM. This work provides a foundation for future
applications of LLMs in automated ontology enhancement and offers insights into
optimizing LLM performance through strategic prompt design. Our code is
publicly available on GitHub at https://github.com/n28div/llm-disjointness.

æè¦ï¼æ¬ä½è«éå¸¸ç¼ºä¹é¡å¥ä¹éæç¢ºçä¸ç¸äº¤è²æï¼åç®¡å®åå°æ¼ç¥è­åè­ä¸­çç²¾å¯æ¨çåä¸è´æ§æª¢æ¥å¾æç¨ãå¨æ¬ç ç©¶ä¸­ï¼æåæ¢è¨äºå¤§åèªè¨æ¨¡å (LLM) çæ½åï¼ééè­å¥åæ·è¨é¡å¥ä¸ç¸äº¤å¬çä¾è±å¯æ¬ä½è«ãæåçåæ³æ¨å¨å©ç¨åµå¥å¨ LLM ä¸­çé±å¼ç¥è­ï¼å©ç¨æç¤ºå·¥ç¨ä¾å¼åºéç¨®ç¥è­ä»¥åé¡æ¬ä½è«ä¸ç¸äº¤ãæåå¨ DBpedia æ¬ä½è«ä¸é©è­äºæåçæ¹æ³ï¼éé»éæ³¨éæº LLMãæåçç ç©¶çµæè¡¨æï¼LLM å¨æææç¤ºç­ç¥çæå°ä¸ï¼å¯ä»¥å¯é å°è­å¥ä¸ç¸äº¤é¡å¥éä¿ï¼å¾èç°¡åæ¬ä½è«å®æéç¨ï¼èç¡éå¤§éæåè¼¸å¥ãå°æ¼å¨é¢çä¸ç¸äº¤è±å¯ï¼æåæåºäºä¸åéç¨ï¼è©²éç¨èæ®äºä¸ç¸äº¤åå­é¡å¥é³è¿°ä¹éçéè¼¯éä¿ï¼ä»¥ç¶­æå¯æ»¿è¶³æ§ä¸¦æ¸å°å° LLM çèª¿ç¨æ¬¡æ¸ãéé å·¥ä½çº LLM å¨èªåæ¬ä½è«å¢å¼·ä¸­çæªä¾æç¨å¥ å®äºåºç¤ï¼ä¸¦æä¾äºééç­ç¥æç¤ºè¨­è¨åªå LLM æ§è½çè¦è§£ãæåçä»£ç¢¼å¨ GitHub ä¸å¬éï¼ç¶²åçº https://github.com/n28div/llm-disjointnessã

##### **How Do Large Language Models Understand Graph Patterns? A Benchmark for Graph Pattern Comprehension**
2410.05298v1 by Xinnan Dai, Haohao Qu, Yifen Shen, Bohang Zhang, Qihao Wen, Wenqi Fan, Dongsheng Li, Jiliang Tang, Caihua Shan

Benchmarking the capabilities and limitations of large language models (LLMs)
in graph-related tasks is becoming an increasingly popular and crucial area of
research. Recent studies have shown that LLMs exhibit a preliminary ability to
understand graph structures and node features. However, the potential of LLMs
in graph pattern mining remains largely unexplored. This is a key component in
fields such as computational chemistry, biology, and social network analysis.
To bridge this gap, this work introduces a comprehensive benchmark to assess
LLMs' capabilities in graph pattern tasks. We have developed a benchmark that
evaluates whether LLMs can understand graph patterns based on either
terminological or topological descriptions. Additionally, our benchmark tests
the LLMs' capacity to autonomously discover graph patterns from data. The
benchmark encompasses both synthetic and real datasets, and a variety of
models, with a total of 11 tasks and 7 models. Our experimental framework is
designed for easy expansion to accommodate new models and datasets. Our
findings reveal that: (1) LLMs have preliminary abilities to understand graph
patterns, with O1-mini outperforming in the majority of tasks; (2) Formatting
input data to align with the knowledge acquired during pretraining can enhance
performance; (3) The strategies employed by LLMs may differ from those used in
conventional algorithms.

æè¦ï¼è©éå¤§åèªè¨æ¨¡å (LLM) å¨åå½¢ç¸éä»»åä¸­çè½ååéå¶ï¼æ­£æçºä¸åè¶ä¾è¶åæ­¡è¿ä¸è³ééè¦çç ç©¶é åãæè¿çç ç©¶è¡¨æï¼LLM å±ç¾åºåæ­¥çè§£åå½¢çµæ§åç¯é»ç¹å¾µçè½åãç¶èï¼LLM å¨åå½¢æ¨¡å¼ææä¸­çæ½åä»æªè¢«å»£æ³æ¢ç´¢ãéæ¯è¨ç®åå­¸ãçç©å­¸åç¤¾äº¤ç¶²è·¯åæç­é åçééµçµæé¨åãçºäºå½åéåå·®è·ï¼éé å·¥ä½æåºäºä¸åå¨é¢çåºæºä¾è©ä¼° LLM å¨åå½¢æ¨¡å¼ä»»åä¸­çè½åãæåéç¼äºä¸ååºæºï¼ç¨ä¾è©ä¼° LLM è½å¦æ ¹æè¡èªæææ²æè¿°ä¾çè§£åå½¢æ¨¡å¼ãæ­¤å¤ï¼æåçåºæºæ¸¬è©¦ LLM å¾è³æä¸­èªä¸»ç¼ç¾åå½¢æ¨¡å¼çè½åãè©²åºæºæ¶µèäºåæåçå¯¦è³æéï¼ä»¥ååç¨®æ¨¡åï¼ç¸½å±æ 11 é ä»»åå 7 åæ¨¡åãæåçå¯¦é©æ¶æ§è¨­è¨çºææ¼æ´åï¼ä»¥å®¹ç´æ°çæ¨¡ååè³æéãæåçç ç©¶çµæé¡¯ç¤ºï¼(1) LLM å·æåæ­¥çè§£åå½¢æ¨¡å¼çè½åï¼å¶ä¸­ O1-mini å¨å¤§å¤æ¸ä»»åä¸­è¡¨ç¾åªç°ï¼(2) å°è¼¸å¥è³ææ ¼å¼åçºèé è¨ç·´æéç¿å¾çç¥è­ä¸è´ï¼å¯ä»¥å¢å¼·æè½ï¼(3) LLM ä½¿ç¨çç­ç¥å¯è½èå³çµ±æ¼ç®æ³ä¸­ä½¿ç¨çç­ç¥ä¸åã

##### **LLMCO2: Advancing Accurate Carbon Footprint Prediction for LLM Inferences**
2410.02950v1 by Zhenxiao Fu, Fan Chen, Shan Zhou, Haitong Li, Lei Jiang

Throughout its lifecycle, a large language model (LLM) generates a
substantially larger carbon footprint during inference than training. LLM
inference requests vary in batch size, prompt length, and token generation
number, while cloud providers employ different GPU types and quantities to meet
diverse service-level objectives for accuracy and latency. It is crucial for
both users and cloud providers to have a tool that quickly and accurately
estimates the carbon impact of LLM inferences based on a combination of
inference request and hardware configurations before execution. Estimating the
carbon footprint of LLM inferences is more complex than training due to lower
and highly variable model FLOPS utilization, rendering previous equation-based
models inaccurate. Additionally, existing machine learning (ML) prediction
methods either lack accuracy or demand extensive training data, as they
inadequately handle the distinct prefill and decode phases, overlook
hardware-specific features, and inefficiently sample uncommon inference
configurations. We introduce \coo, a graph neural network (GNN)-based model
that greatly improves the accuracy of LLM inference carbon footprint
predictions compared to previous methods.

æè¦ï¼å¨æ´åçå½é±æä¸­ï¼å¤§åèªè¨æ¨¡å (LLM) å¨æ¨çæéç¢ççç¢³è¶³è·¡é å¤§æ¼è¨ç·´æéãLLM æ¨çè«æ±å¨æ¹æ¬¡å¤§å°ãæç¤ºé·åº¦åæ¬æçææ¸éæ¹é¢ææä¸åï¼èé²ç«¯ä¾æåæ¡ç¨ä¸åç GPU é¡ååæ¸éä¾æ»¿è¶³æºç¢ºæ§åå»¶é²çåç¨®æåå±¤ç´ç®æ¨ãå°æ¼ä½¿ç¨èåé²ç«¯ä¾æåä¾èªªï¼å¨å·è¡åæ ¹ææ¨çè«æ±åç¡¬é«éç½®çµåå¿«éä¸æºç¢ºå°ä¼°è¨ LLM æ¨ççç¢³å½±é¿è³ééè¦ãä¼°è¨ LLM æ¨ççç¢³è¶³è·¡æ¯è¨ç·´æ´è¤éï¼å çºæ¨¡å FLOPS å©ç¨çè¼ä½ä¸è®åå¾å¤§ï¼å°è´ååçåºæ¼æ¹ç¨å¼çæ¨¡åä¸æºç¢ºãæ­¤å¤ï¼ç¾æçæ©å¨å­¸ç¿ (ML) é æ¸¬æ¹æ³è¦ä¹ç¼ºä¹æºç¢ºæ§ï¼è¦ä¹éè¦å¤§éçè¨ç·´è³æï¼å çºå®åç¡æ³ååèçä¸åçé å¡«ååè§£ç¢¼éæ®µï¼å¿½ç¥ç¡¬é«ç¹å®çåè½ï¼ä¸¦ä¸ä½æçå°åæ¨£ä¸å¸¸è¦çæ¨çéç½®ãæåå¼å¥äº \cooï¼éæ¯ä¸ååºæ¼åç¥ç¶ç¶²è·¯ (GNN) çæ¨¡åï¼èååçæ¨¡åç¸æ¯ï¼å®å¤§å¤§æé«äº LLM æ¨çç¢³è¶³è·¡é æ¸¬çæºç¢ºæ§ã

##### **Domain-Specific Retrieval-Augmented Generation Using Vector Stores, Knowledge Graphs, and Tensor Factorization**
2410.02721v1 by Ryan C. Barron, Ves Grantcharov, Selma Wanna, Maksim E. Eren, Manish Bhattarai, Nicholas Solovyev, George Tompkins, Charles Nicholas, Kim Ã. Rasmussen, Cynthia Matuszek, Boian S. Alexandrov

Large Language Models (LLMs) are pre-trained on large-scale corpora and excel
in numerous general natural language processing (NLP) tasks, such as question
answering (QA). Despite their advanced language capabilities, when it comes to
domain-specific and knowledge-intensive tasks, LLMs suffer from hallucinations,
knowledge cut-offs, and lack of knowledge attributions. Additionally, fine
tuning LLMs' intrinsic knowledge to highly specific domains is an expensive and
time consuming process. The retrieval-augmented generation (RAG) process has
recently emerged as a method capable of optimization of LLM responses, by
referencing them to a predetermined ontology. It was shown that using a
Knowledge Graph (KG) ontology for RAG improves the QA accuracy, by taking into
account relevant sub-graphs that preserve the information in a structured
manner. In this paper, we introduce SMART-SLIC, a highly domain-specific LLM
framework, that integrates RAG with KG and a vector store (VS) that store
factual domain specific information. Importantly, to avoid hallucinations in
the KG, we build these highly domain-specific KGs and VSs without the use of
LLMs, but via NLP, data mining, and nonnegative tensor factorization with
automatic model selection. Pairing our RAG with a domain-specific: (i) KG
(containing structured information), and (ii) VS (containing unstructured
information) enables the development of domain-specific chat-bots that
attribute the source of information, mitigate hallucinations, lessen the need
for fine-tuning, and excel in highly domain-specific question answering tasks.
We pair SMART-SLIC with chain-of-thought prompting agents. The framework is
designed to be generalizable to adapt to any specific or specialized domain. In
this paper, we demonstrate the question answering capabilities of our framework
on a corpus of scientific publications on malware analysis and anomaly
detection.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ç¶éå¤§éèªæåº«çé åè¨ç·´ï¼å¨è¨±å¤ä¸è¬èªç¶èªè¨èç (NLP) ä»»åä¸­è¡¨ç¾åºè²ï¼ä¾å¦åé¡è§£ç­ (QA)ãåç®¡å®åå·æåé²çèªè¨è½åï¼ä½ LLM å¨ç¹å®é ååç¥è­å¯éåä»»åæ¹é¢æåºç¾å¹»è¦ºãç¥è­æ·å±¤åç¼ºä¹ç¥è­æ­¸å ãæ­¤å¤ï¼å¾®èª¿ LLM çå§å¨ç¥è­ä»¥é©æé«åº¦ç¹å®é åæ¯ä¸åæè²´ä¸èæçéç¨ãæª¢ç´¢å¢å¼·çæ (RAG) æµç¨æè¿å·²æçºä¸ç¨®åªå LLM åæçæ¹æ³ï¼æ¹æ³æ¯å°å®ååç§é åç¢ºå®çæ¬ä½ãç ç©¶è¡¨æï¼å°ç¥è­åè­ (KG) æ¬ä½ç¨æ¼ RAG å¯ééèæ®ä»¥çµæ§åæ¹å¼ä¿çè³è¨çç¸éå­åï¼ä¾æé« QA çæºç¢ºæ§ãå¨æ¬æä¸­ï¼æåä»ç´¹äº SMART-SLICï¼éæ¯ä¸åé«åº¦ç¹å®é åç LLM æ¡æ¶ï¼å®å° RAG è KG åä¸åå²å­äºå¯¦ç¹å®é åè³è¨çåéå²å­ (VS) æ´åå¨ä¸èµ·ãéè¦çæ¯ï¼çºäºé¿å KG ä¸­çå¹»è¦ºï¼æåå¨ä¸ä½¿ç¨ LLM çææ³ä¸å»ºç«äºéäºé«åº¦ç¹å®é åç KG å VSï¼èæ¯éé NLPãè³ææ¢ååå·æèªåæ¨¡åé¸æçéè² å¼µéåè§£ãå°æåç RAG èç¹å®é åéå°ï¼(i) KGï¼åå«çµæ§åè³è¨ï¼ï¼å (ii) VSï¼åå«éçµæ§åè³è¨ï¼è½å¤ éç¼ç¹å®é åçèå¤©æ©å¨äººï¼éäºèå¤©æ©å¨äººææ­¸å æ¼è³è¨ä¾æºãæ¸è¼å¹»è¦ºãæ¸å°å¾®èª¿çéè¦ï¼ä¸¦å¨é«åº¦ç¹å®é åçåé¡è§£ç­ä»»åä¸­è¡¨ç¾åºè²ãæåå° SMART-SLIC èæèéæç¤ºä»£çéå°ãè©²æ¡æ¶è¢«è¨­è¨æå¯æ¦æ¬ä»¥é©æä»»ä½ç¹å®æå°æ¥­é åãå¨æ¬æä¸­ï¼æåå¨æ¡æè»é«åæåç°å¸¸åµæ¸¬çç§å­¸åºçç©èªæåº«ä¸å±ç¤ºäºæåæ¡æ¶çåé¡è§£ç­è½åã

##### **A Schema-aware Logic Reformulation for Graph Reachability**
2410.02533v1 by Davide Di Pierro, Stefano Ferilli

Graph reachability is the task of understanding whether two distinct points
in a graph are interconnected by arcs to which in general a semantic is
attached. Reachability has plenty of applications, ranging from motion planning
to routing. Improving reachability requires structural knowledge of relations
so as to avoid the complexity of traditional depth-first and breadth-first
strategies, implemented in logic languages. In some contexts, graphs are
enriched with their schema definitions establishing domain and range for every
arc. The introduction of a schema-aware formalization for guiding the search
may result in a sensitive improvement by cutting out unuseful paths and
prioritising those that, in principle, reach the target earlier. In this work,
we propose a strategy to automatically exclude and sort certain graph paths by
exploiting the higher-level conceptualization of instances. The aim is to
obtain a new first-order logic reformulation of the graph reachability
scenario, capable of improving the traditional algorithms in terms of time,
space requirements, and number of backtracks. The experiments exhibit the
expected advantages of the approach in reducing the number of backtracks during
the search strategy, resulting in saving time and space as well.

æè¦ï¼åå½¢å¯éæ§æ¯äºè§£åå½¢ä¸­å©åä¸åé»æ¯å¦ç±å¼§ç·ç¸äºé£æ¥çä»»åï¼éäºå¼§ç·éå¸¸éå¸¶èªç¾©ãå¯éæ§æå¾å¤æç¨ï¼å¾éåè¦åå°è·¯ç±ãæé«å¯éæ§éè¦çµæ§éä¿ç¥è­ï¼ä»¥é¿åéè¼¯èªè¨ä¸­å¯¦ç¾çå³çµ±æ·±åº¦åªååå»£åº¦åªåç­ç¥çè¤éæ§ãå¨æäºææ³ä¸ï¼åå½¢æééå¶æ¶æ§å®ç¾©å¾å°è±å¯ï¼çºæ¯åå¼§ç·å»ºç«ååç¯åãå¼å¥æ¶æ§æç¥å½¢å¼åä»¥æå°æå°å¯è½æééåæ·ç¡ç¨çè·¯å¾ååªåèæ®ååä¸è¼æ©å°éç®æ¨çè·¯å¾èç¢çé¡¯èçæ¹é²ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®ç­ç¥ï¼ééå©ç¨å¯¦ä¾çé«éæ¦å¿µåä¾èªåæé¤åæåºæäºåå½¢è·¯å¾ãç®çæ¯ç²å¾åå½¢å¯éæ§å ´æ¯çæ°ä¸ééè¼¯éæ°è¡¨è¿°ï¼è½å¤ å¨æéãç©ºééæ±ååæº¯æ¬¡æ¸æ¹é¢æ¹é²å³çµ±æ¼ç®æ³ãå¯¦é©å±ç¤ºäºè©²æ¹æ³å¨æ¸å°æå°ç­ç¥æéåæº¯æ¬¡æ¸æ¹é¢çé æåªé»ï¼å¾èç¯çäºæéåç©ºéã

##### **Language Models are Graph Learners**
2410.02296v1 by Zhe Xu, Kaveh Hassani, Si Zhang, Hanqing Zeng, Michihiro Yasunaga, Limei Wang, Dongqi Fu, Ning Yao, Bo Long, Hanghang Tong

Language Models (LMs) are increasingly challenging the dominance of
domain-specific models, including Graph Neural Networks (GNNs) and Graph
Transformers (GTs), in graph learning tasks. Following this trend, we propose a
novel approach that empowers off-the-shelf LMs to achieve performance
comparable to state-of-the-art GNNs on node classification tasks, without
requiring any architectural modification. By preserving the LM's original
architecture, our approach retains a key benefit of LM instruction tuning: the
ability to jointly train on diverse datasets, fostering greater flexibility and
efficiency. To achieve this, we introduce two key augmentation strategies: (1)
Enriching LMs' input using topological and semantic retrieval methods, which
provide richer contextual information, and (2) guiding the LMs' classification
process through a lightweight GNN classifier that effectively prunes class
candidates. Our experiments on real-world datasets show that backbone Flan-T5
models equipped with these augmentation strategies outperform state-of-the-art
text-output node classifiers and are comparable to top-performing vector-output
node classifiers. By bridging the gap between specialized task-specific node
classifiers and general LMs, this work paves the way for more versatile and
widely applicable graph learning models. We will open-source the code upon
publication.

æè¦ï¼èªè¨æ¨¡åï¼LMï¼æ­£æ¥çææ°ç¹å®é åæ¨¡åå¨åå½¢å­¸ç¿ä»»åä¸­çä¸»å°å°ä½ï¼åæ¬åå½¢ç¥ç¶ç¶²è·¯ï¼GNNï¼ååå½¢è½æå¨ï¼GTï¼ãéµå¾ªæ­¤è¶¨å¢ï¼æåæåºäºä¸ç¨®åµæ°æ¹æ³ï¼ä½¿ç¾æç LM è½å¤ å¨ç¯é»åé¡ä»»åä¸­å¯¦ç¾èæåé²ç GNN ç¸ç¶çæè½ï¼èç¡éä»»ä½æ¶æ§ä¿®æ¹ãééä¿ç LM çåå§æ¶æ§ï¼æåçåæ³ä¿çäº LM æä»¤èª¿æ´çä¸é ä¸»è¦åªé»ï¼è½å¤ å¨ä¸åçè³æéä¸é²è¡è¯åè¨ç·´ï¼ä¿é²æ´å¤§çéæ´»æ§åæçãçºæ­¤ï¼æåå¼å¥äºå©åä¸»è¦çæ´åç­ç¥ï¼(1) ä½¿ç¨ææ²åèªç¾©æª¢ç´¢æ¹æ³è±å¯ LM çè¼¸å¥ï¼æä¾æ´è±å¯çä¸ä¸æè³è¨ï¼ä»¥å (2) ééè¼éç´ GNN åé¡å¨å¼å° LM çåé¡éç¨ï¼ææå°ä¿®åªé¡å¥åé¸ãæåå¨çå¯¦ä¸çè³æéä¸çå¯¦é©è¡¨æï¼éåéäºæ´åç­ç¥çä¸»å¹¹ Flan-T5 æ¨¡ååªæ¼æåé²çæå­è¼¸åºç¯é»åé¡å¨ï¼ä¸¦ä¸èæè½æä½³çåéè¼¸åºç¯é»åé¡å¨ç¸ç¶ãééç¸®å°å°éçç¹å®ä»»åç¯é»åé¡å¨åä¸è¬ LM ä¹éçå·®è·ï¼éé å·¥ä½çºæ´å¤ååä¸å»£æ³é©ç¨çåå½¢å­¸ç¿æ¨¡åéªå¹³äºéè·¯ãæåå°å¨åºçå¾éæºç¨å¼ç¢¼ã

##### **GraphIC: A Graph-Based In-Context Example Retrieval Model for Multi-Step Reasoning**
2410.02203v1 by Jiale Fu, Yaqing Wang, Simeng Han, Jiaming Fan, Chen Si, Xu Yang

In-context learning (ICL) enables large language models (LLMs) to generalize
to new tasks by incorporating a few in-context examples (ICEs) directly in the
input, without updating parameters. However, the effectiveness of ICL heavily
relies on the selection of ICEs, and conventional text-based embedding methods
are often inadequate for tasks that require multi-step reasoning, such as
mathematical and logical problem solving. This is due to the bias introduced by
shallow semantic similarities that fail to capture the deeper reasoning
structures required for these tasks. We present GraphIC, a novel approach that
leverages graph-based representations of reasoning processes, coupled with
Bayesian Networks (BNs) to select ICEs. Graph structures inherently filter out
shallow semantics while preserving the core reasoning structure. Importantly,
BNs capture the dependency of a node's attributes on its parent nodes, closely
mirroring the hierarchical nature of human cognition-where each thought is
shaped by preceding ones. This makes BNs particularly well-suited for
multi-step reasoning tasks, aligning the process more closely with human-like
reasoning. Extensive experiments across three types of reasoning tasks
(mathematical reasoning, code generation, and logical reasoning) demonstrate
that GraphIC outperforms both training-free and training-based models in
selecting ICEs, excelling in terms of both effectiveness and efficiency. We
show that GraphIC enhances ICL's performance and interoperability,
significantly advancing ICE selection for multi-step reasoning tasks.

æè¦ï¼<paragraph>æå¢å­¸ç¿ (ICL) è®å¤§åèªè¨æ¨¡å (LLM) è½å¤ ééç´æ¥å¨è¼¸å¥ä¸­å å¥å°æ¸æå¢ç¯ä¾ (ICE)ï¼èç¡éæ´æ°åæ¸ï¼ä¾æ¦åå°æ°çä»»åä¸­ãç¶èï¼ICL çæææ§æ¥µåº¦ä»°è³´ ICE çé¸æï¼èå³çµ±çåºæ¼æå­çåµå¥æ¹æ³éå¸¸ä¸è¶³ä»¥æä»éè¦å¤æ­¥é©æ¨ççä»»åï¼ä¾å¦æ¸å­¸åéè¼¯åé¡è§£æ±ºãéæ¯ç±æ¼æ·ºå±¤èªæç¸ä¼¼æ§å¸¶ä¾çåå·®ï¼èéç¨®åå·®ç¡æ³ææéäºä»»åæéçæ´æ·±å¥æ¨ççµæ§ãæåæåº GraphICï¼éæ¯ä¸ç¨®åµæ°çæ¹æ³ï¼å®å©ç¨æ¨çéç¨çåå½¢åè¡¨å¾µï¼çµåè²æ°ç¶²è·¯ (BN) ä¾é¸æ ICEãåå½¢çµæ§æåºæå°æ¿¾é¤æ·ºå±¤èªæï¼åæä¿çæ ¸å¿æ¨ççµæ§ãéè¦çæ¯ï¼BN ææç¯é»å±¬æ§å°å¶ç¶ç¯é»çä¾è³´æ§ï¼ç·å¯åæ äººé¡èªç¥çéå±¤æ§è³ªï¼å¶ä¸­æ¯åæ³æ³é½æ¯ç±åä¸åæ³æ³æå½¢å¡ãéä½¿å¾ BN ç¹å¥é©åå¤æ­¥é©æ¨çä»»åï¼è®æµç¨æ´è²¼è¿é¡ä¼¼äººé¡çæ¨çãæ©«è·¨ä¸ç¨®é¡åçæ¨çä»»åï¼æ¸å­¸æ¨çãç¨å¼ç¢¼ç¢çåéè¼¯æ¨çï¼çå¤§éå¯¦é©è­æï¼GraphIC å¨é¸æ ICE æåªæ¼ç¡è¨ç·´ååºæ¼è¨ç·´çæ¨¡åï¼å¨æææ§åæçæ¹é¢é½è¡¨ç¾åºè²ãæåå±ç¤ºäº GraphIC å¢å¼·äº ICL çæè½åäºæä½æ§ï¼é¡¯èå°æ¨é²äºå¤æ­¥é©æ¨çä»»åç ICE é¸æã</paragraph>

##### **G2T-LLM: Graph-to-Tree Text Encoding for Molecule Generation with Fine-Tuned Large Language Models**
2410.02198v1 by Zhaoning Yu, Xiangyang Xu, Hongyang Gao

We introduce G2T-LLM, a novel approach for molecule generation that uses
graph-to-tree text encoding to transform graph-based molecular structures into
a hierarchical text format optimized for large language models (LLMs). This
encoding converts complex molecular graphs into tree-structured formats, such
as JSON and XML, which LLMs are particularly adept at processing due to their
extensive pre-training on these types of data. By leveraging the flexibility of
LLMs, our approach allows for intuitive interaction using natural language
prompts, providing a more accessible interface for molecular design. Through
supervised fine-tuning, G2T-LLM generates valid and coherent chemical
structures, addressing common challenges like invalid outputs seen in
traditional graph-based methods. While LLMs are computationally intensive, they
offer superior generalization and adaptability, enabling the generation of
diverse molecular structures with minimal task-specific customization. The
proposed approach achieved comparable performances with state-of-the-art
methods on various benchmark molecular generation datasets, demonstrating its
potential as a flexible and innovative tool for AI-driven molecular design.

æè¦ï¼æåä»ç´¹ G2T-LLMï¼ä¸ç¨®éå°åå­çæçåµæ°æ¹æ³ï¼å®ä½¿ç¨åå½¢è½æ¨¹çæå­ç·¨ç¢¼ï¼å°åºæ¼åå½¢çåå­çµæ§è½æçºéå±¤å¼æå­æ ¼å¼ï¼éå°å¤§åèªè¨æ¨¡å (LLM) é²è¡æä½³åãæ­¤ç·¨ç¢¼æå°è¤éçåå­åå½¢è½æçºæ¨¹ççµæ§æ ¼å¼ï¼ä¾å¦ JSON å XMLï¼ç±æ¼ LLM å¨éäºé¡åè³æçå»£æ³é åè¨ç·´ï¼å æ­¤ç¹å¥æé·èçéäºæ ¼å¼ãééå©ç¨ LLM çéæ´»æ§ï¼æåçåæ³åè¨±ä½¿ç¨èªç¶èªè¨æç¤ºé²è¡ç´è¦ºå¼äºåï¼æä¾ä¸åæ´å®¹æå­åçåå­è¨­è¨ä»é¢ãééç£ç£å¾®èª¿ï¼G2T-LLM æç¢çææä¸é£è²«çåå­¸çµæ§ï¼è§£æ±ºå³çµ±åºæ¼åå½¢æ¹æ³ä¸­å¸¸è¦çç¡æè¼¸åºç­ææ°ãéç¶ LLM å¨è¨ç®ä¸å¾å¯éï¼ä½å®åæä¾åªç°çæ¦æ¬æ§åé©ææ§ï¼è½å¤ ç¢çå¤æ¨£åçåå­çµæ§ï¼ä¸ä»»åç¹å®èªè¨åéæ±æ¥µä½ãææåºçæ¹æ³å¨åç¨®åºæºåå­çæè³æéä¸éå°äºèæåé²æ¹æ³ç¸ç¶çæè½ï¼è­æäºå¶ä½çº AI é©ååå­è¨­è¨çéæ´»ä¸åµæ°çå·¥å·çæ½åã

##### **FLAG: Financial Long Document Classification via AMR-based GNN**
2410.02024v1 by Bolun, Xia, Mohammed J. Zaki, Aparna Gupta

The advent of large language models (LLMs) has initiated much research into
their various financial applications. However, in applying LLMs on long
documents, semantic relations are not explicitly incorporated, and a full or
arbitrarily sparse attention operation is employed. In recent years, progress
has been made in Abstract Meaning Representation (AMR), which is a graph-based
representation of text to preserve its semantic relations. Since AMR can
represent semantic relationships at a deeper level, it can be beneficially
utilized by graph neural networks (GNNs) for constructing effective
document-level graph representations built upon LLM embeddings to predict
target metrics in the financial domain. We propose FLAG: Financial Long
document classification via AMR-based GNN, an AMR graph based framework to
generate document-level embeddings for long financial document classification.
We construct document-level graphs from sentence-level AMR graphs, endow them
with specialized LLM word embeddings in the financial domain, apply a deep
learning mechanism that utilizes a GNN, and examine the efficacy of our
AMR-based approach in predicting labeled target data from long financial
documents. Extensive experiments are conducted on a dataset of quarterly
earnings calls transcripts of companies in various sectors of the economy, as
well as on a corpus of more recent earnings calls of companies in the S&P 1500
Composite Index. We find that our AMR-based approach outperforms fine-tuning
LLMs directly on text in predicting stock price movement trends at different
time horizons in both datasets. Our work also outperforms previous work
utilizing document graphs and GNNs for text classification.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çåºç¾å·²éåäºå°å¶åç¨®éèæç¨ç¨å¼çè¨±å¤ç ç©¶ãç¶èï¼å¨é·ç¯æä»¶ä¸­æç¨ LLM æï¼èªç¾©éä¿ä¸¦æªæç¢ºç´å¥ï¼ä¸æ¡ç¨äºå®å¨æä»»æç¨ççæ³¨æåæä½ãè¿å¹´ä¾ï¼æ½è±¡æç¾©è¡¨å¾µ (AMR) å·²åå¾é²å±ï¼AMR æ¯ä¸ç¨®åºæ¼åå½¢çæå­è¡¨å¾µï¼ç¨æ¼ä¿çå¶èªç¾©éä¿ãç±æ¼ AMR è½å¨æ´æ·±å±¤æ¬¡è¡¨å¾µèªç¾©éä¿ï¼å æ­¤å¯ç±åå½¢ç¥ç¶ç¶²è·¯ (GNN) ææå©ç¨ï¼ç¨æ¼å»ºæ§å»ºç«å¨ LLM åµå¥å¼ä¸çæææä»¶å±¤ç´åå½¢è¡¨å¾µï¼ä»¥é æ¸¬éèé åä¸­çç®æ¨ææ¨ãæåæåº FLAGï¼ééåºæ¼ AMR ç GNN é²è¡è²¡åé·ç¯æä»¶åé¡ï¼ä¸ç¨®åºæ¼ AMR åå½¢çæ¶æ§ï¼ç¨æ¼ç¢çé·ç¯è²¡åæä»¶åé¡çæä»¶å±¤ç´åµå¥å¼ãæåå¾å¥å­å±¤ç´ AMR åå½¢å»ºæ§æä»¶å±¤ç´åå½¢ï¼å¨è²¡åé åè³¦äºå®åå°æ¥­ç LLM å­è©åµå¥å¼ï¼æç¨ä¸åå©ç¨ GNN çæ·±åº¦å­¸ç¿æ©å¶ï¼ä¸¦æª¢è¦æåçåºæ¼ AMR çæ¹æ³å¨é æ¸¬ä¾èªé·ç¯è²¡åæä»¶çæ¨ç±¤åç®æ¨è³ææ¹é¢çåæãæåå°ç¶æ¿ååé¨éçå¬å¸å­£è²¡å ±é»è©±æè­°è¨éè³æéï¼ä»¥åæ¨æ® 1500 ç¶åææ¸å¬å¸è¼è¿æçè²¡å ±é»è©±æè­°èªæåº«é²è¡äºå»£æ³çå¯¦é©ãæåç¼ç¾ï¼æåçåºæ¼ AMR çæ¹æ³å¨é æ¸¬å©åè³æéçä¸åæéç¯åå§çè¡å¹è®åè¶¨å¢æ¹é¢ï¼è¡¨ç¾åªæ¼ç´æ¥éå°æå­å¾®èª¿ LLMãæåçç ç©¶ä¹åªæ¼ååå©ç¨æä»¶åå½¢å GNN é²è¡æå­åé¡çç ç©¶ã

##### **Lost-in-Distance: Impact of Contextual Proximity on LLM Performance in Graph Tasks**
2410.01985v1 by Hamed Firooz, Maziar Sanjabi, Wenlong Jiang, Xiaoling Zhai

Despite significant advancements, Large Language Models (LLMs) exhibit blind
spots that impair their ability to retrieve and process relevant contextual
data effectively. We demonstrate that LLM performance in graph tasks with
complexities beyond the "needle-in-a-haystack" scenario-where solving the
problem requires cross-referencing and reasoning across multiple subproblems
jointly-is influenced by the proximity of relevant information within the
context, a phenomenon we term "lost-in-distance". We examine two fundamental
graph tasks: identifying common connections between two nodes and assessing
similarity among three nodes, and show that the model's performance in these
tasks significantly depends on the relative positioning of common edges. We
evaluate three publicly available LLMs-Llama-3-8B, Llama-3-70B, and GPT-4-using
various graph encoding techniques that represent graph structures for LLM
input. We propose a formulation for the lost-in-distance phenomenon and
demonstrate that lost-in-distance and lost-in-the middle phenomenas occur
independently. Results indicate that model accuracy can decline by up to 6x as
the distance between node connections increases, independent of graph encoding
and model size.

æè¦ï¼åç®¡æé¡¯èçé²å±ï¼å¤§åèªè¨æ¨¡åï¼LLMï¼ä»å­å¨ç²é»ï¼ææå®³å®åæææ·ååèçç¸éèçµ¡è³æçè½åãæåè­æäº LLM å¨åå½¢ä»»åä¸­çè¡¨ç¾ï¼å¶è¤éåº¦è¶åºäºãå¤§æµ·æéãæå¢ï¼å¶ä¸­è§£æ±ºåé¡éè¦è·¨å¤åå­åé¡é²è¡äº¤ååç§åæ¨çï¼ä¸¦åå°èçµ¡ä¸­ç¸éè³è¨çæ¥è¿ç¨åº¦å½±é¿ï¼æåå°æ­¤ç¾è±¡ç¨±çºãå¤±ä¹è·é¢ããæåæª¢é©äºå©ååºæ¬çåå½¢ä»»åï¼è­å¥å©åç¯é»ä¹éçå±åé£æ¥ï¼ä»¥åè©ä¼°ä¸åç¯é»ä¹éçç¸ä¼¼æ§ï¼ä¸¦é¡¯ç¤ºæ¨¡åå¨éäºä»»åä¸­çè¡¨ç¾é¡¯èå°åæ±ºæ¼å±åéç·£çç¸å°ä½ç½®ãæåè©ä¼°äºä¸åå¬éå¯ç¨ç LLMï¼åå¥çº Llama-3-8BãLlama-3-70B å GPT-4ï¼ä½¿ç¨åç¨®åå½¢ç·¨ç¢¼æè¡ï¼éäºæè¡è¡¨ç¤º LLM è¼¸å¥çåå½¢çµæ§ãæåæåºäºå¤±ä¹è·é¢ç¾è±¡çå¬å¼ï¼ä¸¦è­æäºå¤±ä¹è·é¢åå¤±ä¹æ¼ä¸­éç¾è±¡æç¨ç«ç¼çãçµæè¡¨æï¼é¨èç¯é»é£æ¥ä¹éçè·é¢å¢å ï¼æ¨¡åæºç¢ºåº¦æå¤å¯è½æä¸é 6 åï¼èåå½¢ç·¨ç¢¼åæ¨¡åå¤§å°ç¡éã

##### **LLM+KG@VLDB'24 Workshop Summary**
2410.01978v1 by Arijit Khan, Tianxing Wu, Xi Chen

The unification of large language models (LLMs) and knowledge graphs (KGs)
has emerged as a hot topic. At the LLM+KG'24 workshop, held in conjunction with
VLDB 2024 in Guangzhou, China, one of the key themes explored was important
data management challenges and opportunities due to the effective interaction
between LLMs and KGs. This report outlines the major directions and approaches
presented by various speakers during the LLM+KG'24 workshop.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) åç¥è­åè­ (KG) ççµ±ä¸å·²æçºç±éè©±é¡ãå¨ä¸­åå»£å·èè¡ç 2024 å¹´ VLDB æè­°æéèè¾¦ç LLM+KG'24 ç è¨æä¸ï¼æ¢ç´¢çä¸åééµä¸»é¡æ¯ LLM å KG ä¹éçææäºåæå¸¶ä¾çéè¦çæ¸æç®¡çææ°åæ©éãæ¬å ±åæ¦è¿°äº LLM+KG'24 ç è¨ææéåæ¼è¬èæåºçä¸»è¦æ¹ååæ¹æ³ã

##### **Conformal Generative Modeling with Improved Sample Efficiency through Sequential Greedy Filtering**
2410.01660v1 by Klaus-Rudolf Kladny, Bernhard SchÃ¶lkopf, Michael Muehlebach

Generative models lack rigorous statistical guarantees for their outputs and
are therefore unreliable in safety-critical applications. In this work, we
propose Sequential Conformal Prediction for Generative Models (SCOPE-Gen), a
sequential conformal prediction method producing prediction sets that satisfy a
rigorous statistical guarantee called conformal admissibility control. This
guarantee states that with high probability, the prediction sets contain at
least one admissible (or valid) example. To this end, our method first samples
an initial set of i.i.d. examples from a black box generative model. Then, this
set is iteratively pruned via so-called greedy filters. As a consequence of the
iterative generation procedure, admissibility of the final prediction set
factorizes as a Markov chain. This factorization is crucial, because it allows
to control each factor separately, using conformal prediction. In comparison to
prior work, our method demonstrates a large reduction in the number of
admissibility evaluations during calibration. This reduction is important in
safety-critical applications, where these evaluations must be conducted
manually by domain experts and are therefore costly and time consuming. We
highlight the advantages of our method in terms of admissibility evaluations
and cardinality of the prediction sets through experiments in natural language
generation and molecular graph extension tasks.

æè¦ï¼çææ¨¡åç¼ºä¹å°å¶è¼¸åºé²è¡å´æ ¼ççµ±è¨ä¿è­ï¼å æ­¤å¨å®å¨ééµæç¨ä¸­ä¸å¯é ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºçææ¨¡åçé åºå±å½¢é æ¸¬ (SCOPE-Gen)ï¼éæ¯ä¸ç¨®é åºå±å½¢é æ¸¬æ¹æ³ï¼ç¢çæ»¿è¶³ç¨±çºå±å½¢å¯æ¡æ§æ§å¶çå´æ ¼çµ±è¨ä¿è­çé æ¸¬éãæ­¤ä¿è­è¡¨ç¤ºï¼é æ¸¬éå¨é«æ©çä¸è³å°åå«ä¸åå¯æ¡ (æææ) çç¯ä¾ãçºæ­¤ï¼æåçæ¨¡åé¦åå¾é»ççææ¨¡åä¸­æ½åä¸çµ i.i.d. ç¯ä¾ãç¶å¾ï¼ééæè¬çè²ªå©ªéæ¿¾å¨åè¦ä¿®åªæ­¤çµãä½çºåè¦çæç¨åºççµæï¼æçµé æ¸¬éçå¯æ¡æ§åè§£çºé¦¬å¯å¤«éãæ­¤åè§£è³ééè¦ï¼å çºå®åè¨±ä½¿ç¨å±å½¢é æ¸¬åå¥æ§å¶æ¯åå å­ãèååçå·¥ä½ç¸æ¯ï¼æåçæ¨¡åé¡¯ç¤ºå¨æ ¡æºéç¨ä¸­å¯å¤§å¹æ¸å°å¯æ¡æ§è©ä¼°çæ¸éãæ­¤æ¸å°å¨å®å¨ééµæç¨ä¸­å¾éè¦ï¼å¨éäºæç¨ä¸­ï¼éäºè©ä¼°å¿é ç±é åå°å®¶æåé²è¡ï¼å æ­¤ææ¬é«æä¸èæãæåééèªç¶èªè¨çæååå­åå½¢å»¶ä¼¸ä»»åä¸­çå¯¦é©ï¼çªé¡¯æåçæ¨¡åå¨å¯æ¡æ§è©ä¼°åé æ¸¬éåºæ¸æ¹é¢çåªé»ã

##### **HiReview: Hierarchical Taxonomy-Driven Automatic Literature Review Generation**
2410.03761v1 by Yuntong Hu, Zhuofeng Li, Zheng Zhang, Chen Ling, Raasikh Kanjiani, Boxin Zhao, Liang Zhao

In this work, we present HiReview, a novel framework for hierarchical
taxonomy-driven automatic literature review generation. With the exponential
growth of academic documents, manual literature reviews have become
increasingly labor-intensive and time-consuming, while traditional
summarization models struggle to generate comprehensive document reviews
effectively. Large language models (LLMs), with their powerful text processing
capabilities, offer a potential solution; however, research on incorporating
LLMs for automatic document generation remains limited. To address key
challenges in large-scale automatic literature review generation (LRG), we
propose a two-stage taxonomy-then-generation approach that combines graph-based
hierarchical clustering with retrieval-augmented LLMs. First, we retrieve the
most relevant sub-community within the citation network, then generate a
hierarchical taxonomy tree by clustering papers based on both textual content
and citation relationships. In the second stage, an LLM generates coherent and
contextually accurate summaries for clusters or topics at each hierarchical
level, ensuring comprehensive coverage and logical organization of the
literature. Extensive experiments demonstrate that HiReview significantly
outperforms state-of-the-art methods, achieving superior hierarchical
organization, content relevance, and factual accuracy in automatic literature
review generation tasks.

æè¦ï¼å¨æ¬æä¸­ï¼æåæåºäº HiReviewï¼ä¸åç¨æ¼åå±¤åé¡é©åçèªåæç»åé¡§çæçå¨æ°æ¡æ¶ãé¨èå­¸è¡æç»çææ¸ç´å¢é·ï¼æåæç»åé¡§è®å¾è¶ä¾è¶ååå¯éä¸èæï¼èå³çµ±çæè¦æ¨¡åé£ä»¥ææå°çæå¨é¢çæä»¶åé¡§ãå¤§åèªè¨æ¨¡å (LLM) æèå¶å¼·å¤§çææ¬èçè½åæä¾äºä¸åæ½å¨çè§£æ±ºæ¹æ¡ï¼ç¶èï¼å° LLM ç´å¥èªåæä»¶çæçç ç©¶ä»ç¶æéãçºäºæå°å¤§è¦æ¨¡èªåæç»åé¡§çæ (LRG) ä¸­çä¸»è¦ææ°ï¼æåæåºäºä¸ç¨®å©éæ®µçåé¡åçææ¹æ³ï¼è©²æ¹æ³å°åºæ¼åå½¢çå±¤æ¬¡èé¡èæª¢ç´¢å¢å¼·ç LLM ç¸çµåãé¦åï¼æåæª¢ç´¢å¼æç¶²è·¯ä¸­æç¸éçå­ç¤¾ç¾¤ï¼ç¶å¾æ ¹æææ¬å§å®¹åå¼æéä¿å°è«æé²è¡èé¡ï¼çæä¸ååå±¤åé¡æ¨¹ãå¨ç¬¬äºéæ®µï¼LLM çºæ¯åå±¤ç´çç¾¤éæä¸»é¡çæé£è²«ä¸å¨èªå¢ä¸æºç¢ºçæè¦ï¼ç¢ºä¿æç»çå¨é¢è¦èåéè¼¯çµç¹ãå»£æ³çå¯¦é©è¡¨æï¼HiReview æé¡¯åªæ¼æåé²çæ¹æ³ï¼å¨èªåæç»åé¡§çæä»»åä¸­å¯¦ç¾äºåºè²çå±¤æ¬¡çµç¹ãå§å®¹ç¸éæ§åäºå¯¦æºç¢ºæ§ã

##### **LEGO: Learnable Expansion of Graph Operators for Multi-Modal Feature Fusion**
2410.01506v2 by Dexuan Ding, Lei Wang, Liyun Zhu, Tom Gedeon, Piotr Koniusz

In computer vision tasks, features often come from diverse representations,
domains, and modalities, such as text, images, and videos. Effectively fusing
these features is essential for robust performance, especially with the
availability of powerful pre-trained models like vision-language models.
However, common fusion methods, such as concatenation, element-wise operations,
and non-linear techniques, often fail to capture structural relationships, deep
feature interactions, and suffer from inefficiency or misalignment of features
across domains. In this paper, we shift from high-dimensional feature space to
a lower-dimensional, interpretable graph space by constructing similarity
graphs that encode feature relationships at different levels, e.g., clip,
frame, patch, token, etc. To capture deeper interactions, we use graph power
expansions and introduce a learnable graph fusion operator to combine these
graph powers for more effective fusion. Our approach is relationship-centric,
operates in a homogeneous space, and is mathematically principled, resembling
element-wise similarity score aggregation via multilinear polynomials. We
demonstrate the effectiveness of our graph-based fusion method on video anomaly
detection, showing strong performance across multi-representational,
multi-modal, and multi-domain feature fusion tasks.

æè¦ï¼<paragraph>å¨é»è¦è¦è¦ºä»»åä¸­ï¼ç¹å¾µéå¸¸ä¾èªä¸åçè¡¨ç¤ºã
é ååæ¨¡å¼ï¼ä¾å¦æå­ãå½±ååå½±çãææèå
éäºç¹å¾µå°æ¼å¼·å¥çæè½è³ééè¦ï¼ç¹å¥æ¯å¨
å·åå¼·å¤§é è¨ç·´æ¨¡åï¼ä¾å¦è¦è¦ºèªè¨æ¨¡åï¼çææ³ä¸ã
ç¶èï¼å¸¸è¦çèåæ¹æ³ï¼ä¾å¦ä¸²æ¥ãéåç´ éç®ï¼
åéç·æ§æè¡ï¼éå¸¸ç¡æ³ææçµæ§éä¿ãæ·±åº¦
ç¹å¾µäºåï¼ä¸¦ä¸æåå°éæçæç¹å¾µå¨ä¸åé åä¸­æªå°é½çå½±é¿ãå¨æ¬æä¸­ï¼æåå¾é«ç¶­ç¹å¾µç©ºéè½ç§»å°
ä½ç¶­ãå¯è§£éçåå½¢ç©ºéï¼ééå»ºæ§ç¸ä¼¼æ§
åå½¢ä¾ç·¨ç¢¼ä¸åå±¤ç´çç¹å¾µéä¿ï¼ä¾å¦åªè¼¯ã
å½±æ ¼ãè²¼çãæ¨è¨ç­ãçºäºæææ´æ·±å¥çäºåï¼æåä½¿ç¨åå½¢åª
å±éï¼ä¸¦å¼å¥å¯å­¸ç¿çåå½¢èåéç®å­ï¼ä»¥çµåéäº
åå½¢åªï¼ä»¥å¯¦ç¾æ´ææçèåãæåçåæ³ä»¥éä¿çºä¸­å¿ï¼
å¨åè³ªç©ºéä¸­éä½ï¼ä¸¦ä¸å·ææ¸å­¸åçï¼é¡ä¼¼æ¼
ééå¤ç·æ§å¤é å¼é²è¡éåç´ ç¸ä¼¼åº¦åæ¸èåãæå
å¨å½±çç°å¸¸åµæ¸¬ä¸­å±ç¤ºäºåºæ¼åå½¢çèåæ¹æ³çæææ§ï¼å¨å¤è¡¨ç¤ºã
å¤æ¨¡å¼åå¤é åç¹å¾µèåä»»åä¸­å±ç¾å¼·å¤§çæè½ã</paragraph>

##### **Question-guided Knowledge Graph Re-scoring and Injection for Knowledge Graph Question Answering**
2410.01401v1 by Yu Zhang, Kehai Chen, Xuefeng Bai, zhao kang, Quanjiang Guo, Min Zhang

Knowledge graph question answering (KGQA) involves answering natural language
questions by leveraging structured information stored in a knowledge graph.
Typically, KGQA initially retrieve a targeted subgraph from a large-scale
knowledge graph, which serves as the basis for reasoning models to address
queries. However, the retrieved subgraph inevitably brings distraction
information for knowledge utilization, impeding the model's ability to perform
accurate reasoning. To address this issue, we propose a Question-guided
Knowledge Graph Re-scoring method (Q-KGR) to eliminate noisy pathways for the
input question, thereby focusing specifically on pertinent factual knowledge.
Moreover, we introduce Knowformer, a parameter-efficient method for injecting
the re-scored knowledge graph into large language models to enhance their
ability to perform factual reasoning. Extensive experiments on multiple KGQA
benchmarks demonstrate the superiority of our method over existing systems.

æè¦ï¼ç¥è­åè¡¨åç­ (KGQA) æ¶åå©ç¨å²å­å¨ç¥è­åè¡¨ä¸­ççµæ§åè³è¨ä¾åç­èªç¶èªè¨åé¡ãéå¸¸ï¼KGQA æåæå¾å¤§è¦æ¨¡ç¥è­åè¡¨ä¸­æ·åç®æ¨å­åï¼ä½çºæ¨çæ¨¡åèçæ¥è©¢çåºç¤ãç¶èï¼æ·åçå­åé£åæå¸¶ä¾éè¨è³è¨ï¼é»ç¤æ¨¡åå·è¡ç²¾ç¢ºæ¨ççè½åãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸ååé¡å°åç¥è­åè¡¨éæ°è©åæ¹æ³ (Q-KGR)ï¼ä»¥æ¶é¤è¼¸å¥åé¡çéè¨è·¯å¾ï¼å¾èå°æ³¨æ¼ç¸éçäºå¯¦ç¥è­ãæ­¤å¤ï¼æåå¼å¥äº Knowformerï¼éæ¯ä¸ç¨®åæ¸æçé«çæ¹æ³ï¼ç¨æ¼å°éæ°è©åçç¥è­åè¡¨æ³¨å¥å¤§åèªè¨æ¨¡åï¼ä»¥å¢å¼·å®åå·è¡äºå¯¦æ¨ççè½åãå¨å¤å KGQA åºæºä¸çå»£æ³å¯¦é©è­æäºæåçæ¹æ³åªæ¼ç¾æç³»çµ±ã

##### **Unveiling Language Skills under Circuits**
2410.01334v1 by Hang Chen, Jiaying Zhu, Xinyu Yang, Wenya Wang

The exploration of language skills in language models (LMs) has always been
one of the central goals in mechanistic interpretability. However, existing
circuit analyses often fall short in representing the full functional scope of
these models, primarily due to the exclusion of Feed-Forward layers.
Additionally, isolating the effect of a single language skill from a text,
which inherently involves multiple entangled skills, poses a significant
challenge. To address these gaps, we introduce a novel concept, Memory Circuit,
a minimum unit that fully and independently manipulates the memory-reading
functionality of a language model, and disentangle the transformer model
precisely into a circuit graph which is an ensemble of paths connecting
different memory circuits. Based on this disentanglement, we identify salient
circuit paths, named as skill paths, responsible for three crucial language
skills, i.e., the Previous Token Skill, Induction Skill and In-Context Learning
(ICL) Skill, leveraging causal effect estimation through interventions and
counterfactuals. Our experiments on various datasets confirm the correspondence
between our identified skill paths and language skills, and validate three
longstanding hypotheses: 1) Language skills are identifiable through circuit
dissection; 2) Simple language skills reside in shallow layers, whereas complex
language skills are found in deeper layers; 3) Complex language skills are
formed on top of simpler language skills. Our codes are available at:
https://github.com/Zodiark-ch/Language-Skill-of-LLMs.

æè¦ï¼<paragraph>å¨èªè¨æ¨¡å (LM) ä¸­æ¢ç´¢èªè¨æè½ä¸ç´æ¯æ©æ¢°å¯è§£éæ§çæ ¸å¿ç®æ¨ä¹ä¸ãç¶èï¼ç¾æçé»è·¯åæå¾å¾ç¡æ³è¡¨ç¤ºéäºæ¨¡åçå¨é¨åè½ç¯åï¼ä¸»è¦æ¯ç±æ¼æé¤äºåé¥å±¤ãæ­¤å¤ï¼å¾ææ¬ä¸­åé¢åºå®ä¸èªè¨æè½çå½±é¿ï¼éæ¬è³ªä¸æ¶åå¤ç¨®ç³¾çºçæè½ï¼æ§æäºä¸é éå¤§ææ°ãçºäºè§£æ±ºéäºå·®è·ï¼æåå¼å¥äº Memory Circuitï¼éæ¯ä¸åæ°ç©çæ¦å¿µï¼å®æ¯ä¸åæå°å®åï¼å¯ä»¥å®æ´ä¸ç¨ç«å°æä½èªè¨æ¨¡åçè¨æ¶é«è®ååè½ï¼ä¸¦å° Transformer æ¨¡åç²¾ç¢ºå°è§£éæä¸åé»è·¯åï¼å®æ¯ä¸åé£æ¥ä¸åè¨æ¶é«é»è·¯çè·¯å¾éåãåºæ¼éç¨®è§£éï¼æåè­å¥åºé¡¯èçé»è·¯è·¯å¾ï¼ç¨±çºæè½è·¯å¾ï¼å®è² è²¬ä¸é ééµçèªè¨æè½ï¼å³åä¸åç¬¦èæè½ãæ­¸ç´æè½åèªå¢å­¸ç¿ (ICL) æè½ï¼å©ç¨å æææä¼°è¨ééå¹²é ååäºå¯¦ãæåå¨åç¨®è³æéä¸çå¯¦é©è­å¯¦äºæåè­å¥åºçæè½è·¯å¾èèªè¨æè½ä¹éçå°æéä¿ï¼ä¸¦é©è­äºä¸åé·æçåè¨­ï¼1) èªè¨æè½å¯ä»¥ééé»è·¯è§£åä¾è­å¥ï¼2) ç°¡å®çèªè¨æè½å­å¨æ¼æ·ºå±¤ä¸­ï¼èè¤éçèªè¨æè½åå­å¨æ¼æ·±å±¤ä¸­ï¼3) è¤éçèªè¨æè½å»ºç«å¨æ´ç°¡å®çèªè¨æè½ä¹ä¸ãæåçç¨å¼ç¢¼å¯å¨ https://github.com/Zodiark-ch/Language-Skill-of-LLMs åå¾ã</paragraph>

##### **From Natural Language to SQL: Review of LLM-based Text-to-SQL Systems**
2410.01066v1 by Ali Mohammadjafari, Anthony S. Maida, Raju Gottumukkala

Since the onset of LLMs, translating natural language queries to structured
SQL commands is assuming increasing. Unlike the previous reviews, this survey
provides a comprehensive study of the evolution of LLM-based text-to-SQL
systems, from early rule-based models to advanced LLM approaches, and how LLMs
impacted this field. We discuss benchmarks, evaluation methods and evaluation
metrics. Also, we uniquely study the role of integration of knowledge graphs
for better contextual accuracy and schema linking in these systems. The current
techniques fall into two categories: in-context learning of corpus and
fine-tuning, which then leads to approaches such as zero-shot, few-shot
learning from the end, and data augmentation. Finally, we highlight key
challenges such as computational efficiency, model robustness, and data privacy
with perspectives toward their development and improvements in potential areas
for future of LLM-based text-to-SQL system.

æè¦ï¼èª LLM åºç¾ä»¥ä¾ï¼å°èªç¶èªè¨æ¥è©¢è½æçºçµæ§å SQL æä»¤æ­£è®å¾è¶ä¾è¶æ®éãèååçè©è«ä¸åï¼æ¬èª¿æ¥å°åºæ¼ LLM çæå­è½ SQL ç³»çµ±çæ¼è®é²è¡äºå¨é¢çç ç©¶ï¼å¾æ©æçåºæ¼è¦åçæ¨¡åå°åé²ç LLM æ¹æ³ï¼ä»¥å LLM å¦ä½å½±é¿éåé åãæåè¨è«äºåºæºãè©ä¼°æ¹æ³åè©ä¼°ææ¨ãæ­¤å¤ï¼æåéç¨ç¹å°ç ç©¶äºç¥è­åè­æ´åå¨éäºç³»çµ±ä¸­ç¼æ®çä½ç¨ï¼ä»¥æé«èªå¢æºç¢ºæ§åæ¨¡å¼é£çµãç®åçæè¡åçºå©é¡ï¼èªæåº«çèªå¢å­¸ç¿åå¾®èª¿ï¼éé²èå°è´äºé¶æ¬¡å­¸ç¿ãå°æ¬¡å­¸ç¿ç­æ¹æ³ï¼æå¾æ¯è³ææ´åãæå¾ï¼æåéé»ä»ç´¹äºè¨ç®æçãæ¨¡åç©©å¥æ§åè³æé±ç§ç­ééµææ°ï¼ä¸¦å±æäºå®åå¨æªä¾åºæ¼ LLM çæå­è½ SQL ç³»çµ±çç¼å±åæ¹é²çæ½å¨é åã

##### **GUNDAM: Aligning Large Language Models with Graph Understanding**
2409.20053v2 by Sheng Ouyang, Yulan Hu, Ge Chen, Yong Liu

Large Language Models (LLMs) have achieved impressive results in processing
text data, which has sparked interest in applying these models beyond textual
data, such as graphs. In the field of graph learning, there is a growing
interest in harnessing LLMs to comprehend and manipulate graph-structured data.
Existing research predominantly focuses on graphs with rich textual features,
such as knowledge graphs or text attribute graphs, leveraging LLMs' ability to
process text but inadequately addressing graph structure. This work
specifically aims to assess and enhance LLMs' abilities to comprehend and
utilize the structural knowledge inherent in graph data itself, rather than
focusing solely on graphs rich in textual content. To achieve this, we
introduce the \textbf{G}raph \textbf{U}nderstanding for \textbf{N}atural
Language \textbf{D}riven \textbf{A}nalytical \textbf{M}odel (\model). This
model adapts LLMs to better understand and engage with the structure of graph
data, enabling them to perform complex reasoning tasks by leveraging the
graph's structure itself. Our experimental evaluations on graph reasoning
benchmarks not only substantiate that \model~ outperforms the SOTA baselines
for comparisons. But also reveals key factors affecting the graph reasoning
capabilities of LLMs. Moreover, we provide a theoretical analysis illustrating
how reasoning paths can enhance LLMs' reasoning capabilities.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨èçæå­è³ææ¹é¢åå¾ä»¤äººå°è±¡æ·±å»çææï¼éæ¿ç¼äºå°éäºæ¨¡åæç¨æ¼æå­è³æä»¥å¤é åçèè¶£ï¼ä¾å¦åè¡¨ãå¨åè¡¨å­¸ç¿é åï¼å©ç¨ LLM ä¾çè§£åèçåå½¢çµæ§è³æçèè¶£èæ¥ä¿±å¢ãç¾æçç ç©¶ä¸»è¦éä¸­æ¼å·æè±å¯æå­ç¹å¾µçåè¡¨ï¼ä¾å¦ç¥è­åè¡¨ææå­å±¬æ§åè¡¨ï¼å©ç¨ LLM èçæå­çè½åï¼ä½æªè½ååè§£æ±ºåè¡¨çµæ§ãéé å·¥ä½ç¹å¥æ¨å¨è©ä¼°åå¢å¼· LLM çè§£åå©ç¨åè¡¨è³ææ¬èº«åºæçµæ§ç¥è­çè½åï¼èä¸æ¯åå°æ³¨æ¼å¯å«æå­å§å®¹çåè¡¨ãçºæ­¤ï¼æåå¼å¥äºèªç¶èªè¨é©ååææ¨¡å (\model) çåè¡¨çè§£ãæ­¤æ¨¡åèª¿æ´ LLM ä»¥ä¾¿æ´å¥½å°çè§£ååèåè¡¨è³æççµæ§ï¼ä½¿å®åè½å¤ ééå©ç¨åè¡¨ççµæ§æ¬èº«ä¾å·è¡è¤éçæ¨çä»»åãæåå¨åè¡¨æ¨çåºæºä¸çå¯¦é©è©ä¼°ä¸åè­å¯¦ \model~ åªæ¼æ¯è¼ä¸­ç SOTA åºæºãéæ­ç¤ºäºå½±é¿ LLM åè¡¨æ¨çè½åçä¸»è¦å ç´ ãæ­¤å¤ï¼æåæä¾äºçè«åæï¼èªªææ¨çè·¯å¾å¦ä½å¢å¼· LLM çæ¨çè½åã

##### **Enhancing High-order Interaction Awareness in LLM-based Recommender Model**
2409.19979v2 by Xinfeng Wang, Jin Cui, Fumiyo Fukumoto, Yoshimi Suzuki

Large language models (LLMs) have demonstrated prominent reasoning
capabilities in recommendation tasks by transforming them into text-generation
tasks. However, existing approaches either disregard or ineffectively model the
user-item high-order interactions. To this end, this paper presents an enhanced
LLM-based recommender (ELMRec). We enhance whole-word embeddings to
substantially enhance LLMs' interpretation of graph-constructed interactions
for recommendations, without requiring graph pre-training. This finding may
inspire endeavors to incorporate rich knowledge graphs into LLM-based
recommenders via whole-word embedding. We also found that LLMs often recommend
items based on users' earlier interactions rather than recent ones, and present
a reranking solution. Our ELMRec outperforms state-of-the-art (SOTA) methods in
both direct and sequential recommendations.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²è­æå¨æ¨è¦ä»»åä¸­å·æé¡¯èçæ¨çè½åï¼æ¹æ³æ¯å°å¶è½æçºææ¬çæä»»åãç¶èï¼ç¾ææ¹æ³ä¸æ¯å¿½ç¥ç¨æ¶é ç®é«éäºåï¼å°±æ¯å°å¶å»ºæ¨¡ææä¸ä½³ãçºæ­¤ï¼æ¬ææåºäºä¸ç¨®å¢å¼·çåºæ¼ LLM çæ¨è¦å¨ (ELMRec)ãæåå¢å¼·äºå¨è©åµå¥ï¼ä»¥å¤§å¹å¢å¼· LLM å°åå½¢æ§å»ºäºåçè§£è®ï¼ç¨æ¼æ¨è¦ï¼èä¸éè¦åå½¢é è¨ç·´ãéä¸ç¼ç¾å¯è½ææ¿åµå°è±å¯çç¥è­åè­ééå¨è©åµå¥æ´åå°åºæ¼ LLM çæ¨è¦å¨ä¸­çåªåãæåéç¼ç¾ï¼LLM éå¸¸æ ¹æç¨æ¶æ©æçäºåèéæè¿çäºåä¾æ¨è¦é ç®ï¼ä¸¦æåºäºä¸ç¨®éæ°æåºçè§£æ±ºæ¹æ¡ãæåç ELMRec å¨ç´æ¥åé åºæ¨è¦ä¸­é½åªæ¼æåé² (SOTA) æ¹æ³ã

##### **CoTKR: Chain-of-Thought Enhanced Knowledge Rewriting for Complex Knowledge Graph Question Answering**
2409.19753v2 by Yike Wu, Yi Huang, Nan Hu, Yuncheng Hua, Guilin Qi, Jiaoyan Chen, Jeff Z. Pan

Recent studies have explored the use of Large Language Models (LLMs) with
Retrieval Augmented Generation (RAG) for Knowledge Graph Question Answering
(KGQA). They typically require rewriting retrieved subgraphs into natural
language formats comprehensible to LLMs. However, when tackling complex
questions, the knowledge rewritten by existing methods may include irrelevant
information, omit crucial details, or fail to align with the question's
semantics. To address them, we propose a novel rewriting method CoTKR,
Chain-of-Thought Enhanced Knowledge Rewriting, for generating reasoning traces
and corresponding knowledge in an interleaved manner, thereby mitigating the
limitations of single-step knowledge rewriting. Additionally, to bridge the
preference gap between the knowledge rewriter and the question answering (QA)
model, we propose a training strategy PAQAF, Preference Alignment from Question
Answering Feedback, for leveraging feedback from the QA model to further
optimize the knowledge rewriter. We conduct experiments using various LLMs
across several KGQA benchmarks. Experimental results demonstrate that, compared
with previous knowledge rewriting methods, CoTKR generates the most beneficial
knowledge representation for QA models, which significantly improves the
performance of LLMs in KGQA.

æè¦ï¼æè¿çç ç©¶æ¢ç´¢äºå°å¤§åèªè¨æ¨¡å (LLM) èæª¢ç´¢æ´å¢çæ (RAG) çµåç¨æ¼ç¥è­åè¡¨åç­ (KGQA)ãå®åéå¸¸éè¦å°æª¢ç´¢å°çå­åæ¹å¯«æ LLM å¯ä»¥çè§£çèªç¶èªè¨æ ¼å¼ãç¶èï¼å¨èçè¤éåé¡æï¼ç¾ææ¹æ³æ¹å¯«çç¥è­å¯è½åå«ä¸ç¸éçè³è¨ãéºæ¼ééµç´°ç¯ï¼æç¡æ³èåé¡çèªç¾©å°é½ãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäºä¸ç¨®æ°çæ¹å¯«æ¹æ³ CoTKRï¼å³åºæ¼æèéçç¥è­å¢å¼·æ¹å¯«ï¼ç¨æ¼äº¤é¯çææ¨çè»è·¡åå°æçç¥è­ï¼å¾èæ¸è¼å®æ­¥ç¥è­æ¹å¯«çéå¶ãæ­¤å¤ï¼çºäºå½åç¥è­æ¹å¯«å¨ååç­ (QA) æ¨¡åä¹éçåå¥½å·®è·ï¼æåæåºäºä¸ç¨®è¨ç·´ç­ç¥ PAQAFï¼å³åºæ¼åç­åé¥çåå¥½å°é½ï¼ç¨æ¼å©ç¨ QA æ¨¡åçåé¥é²ä¸æ­¥æä½³åç¥è­æ¹å¯«å¨ãæåä½¿ç¨åç¨® LLM å¨å¤å KGQA åºæºä¸é²è¡äºå¯¦é©ãå¯¦é©çµæè¡¨æï¼èååçç¥è­æ¹å¯«æ¹æ³ç¸æ¯ï¼CoTKR çº QA æ¨¡åçæäºææççç¥è­è¡¨ç¤ºï¼éé¡¯èæé«äº LLM å¨ KGQA ä¸­çæè½ã

##### **Can Large Language Models Analyze Graphs like Professionals? A Benchmark, Datasets and Models**
2409.19667v1 by Xin Li, Weize Chen, Qizhi Chu, Haopeng Li, Zhaojun Sun, Ran Li, Chen Qian, Yiwei Wei, Zhiyuan Liu, Chuan Shi, Maosong Sun, Cheng Yang

The need to analyze graphs is ubiquitous across various fields, from social
networks to biological research and recommendation systems. Therefore, enabling
the ability of large language models (LLMs) to process graphs is an important
step toward more advanced general intelligence. However, current LLM benchmarks
on graph analysis require models to directly reason over the prompts describing
graph topology, and are thus limited to small graphs with only a few dozens of
nodes. In contrast, human experts typically write programs based on popular
libraries for task solving, and can thus handle graphs with different scales.
To this end, a question naturally arises: can LLMs analyze graphs like
professionals? In this paper, we introduce ProGraph, a manually crafted
benchmark containing 3 categories of graph tasks. The benchmark expects
solutions based on programming instead of directly reasoning over raw inputs.
Our findings reveal that the performance of current LLMs is unsatisfactory,
with the best model achieving only 36% accuracy. To bridge this gap, we propose
LLM4Graph datasets, which include crawled documents and auto-generated codes
based on 6 widely used graph libraries. By augmenting closed-source LLMs with
document retrieval and fine-tuning open-source ones on the codes, we show
11-32% absolute improvements in their accuracies. Our results underscore that
the capabilities of LLMs in handling structured data are still under-explored,
and show the effectiveness of LLM4Graph in enhancing LLMs' proficiency of graph
analysis. The benchmark, datasets and enhanced open-source models are available
at https://github.com/BUPT-GAMMA/ProGraph.

æè¦ï¼<paragraph>å¨å¾ç¤¾äº¤ç¶²è·¯å°çç©ç ç©¶åæ¨è¦ç³»çµ±çåç¨®é åä¸­ï¼åæåå½¢çéæ±ç¡èä¸å¨ãå æ­¤ï¼è³¦äºå¤§åèªè¨æ¨¡å (LLM) èçåå½¢çè½åï¼æ¯éåæ´åé²çéç¨æºæ§çéè¦ä¸æ­¥ãç¶èï¼ç®ååå½¢åæä¸ç LLM åºæºè¦æ±æ¨¡åç´æ¥å°æè¿°åå½¢ææ²çµæ§çæç¤ºé²è¡æ¨çï¼å æ­¤åéæ¼åªææ¸ååç¯é»çå°ååå½¢ãç¸æ¯ä¹ä¸ï¼äººé¡å°å®¶éå¸¸ææ ¹ææµè¡çå½å¼åº«æ°å¯«ç¨å¼ä¾è§£æ±ºä»»åï¼å æ­¤å¯ä»¥èçä¸åè¦æ¨¡çåå½¢ãçºæ­¤ï¼èªç¶æç¢çä¸ååé¡ï¼LLM è½åå°æ¥­äººå£«ä¸æ¨£åæåå½¢åï¼å¨æ¬æä¸­ï¼æåä»ç´¹ ProGraphï¼ä¸ååå« 3 é¡åå½¢ä»»åçæå·¥è£½ä½åºæºãè©²åºæºé æè§£æ±ºæ¹æ¡æ¯åºæ¼ç¨å¼è¨­è¨ï¼èä¸æ¯ç´æ¥å°åå§è¼¸å¥é²è¡æ¨çãæåçç¼ç¾é¡¯ç¤ºï¼ç®å LLM çæè½ä¸¦ä¸ä»¤äººæ»¿æï¼æä½³æ¨¡ååéå° 36% çæºç¢ºåº¦ãçºäºå½è£éåå·®è·ï¼æåæåºäº LLM4Graph è³æéï¼å¶ä¸­åå«æ ¹æ 6 åå»£æ³ä½¿ç¨çåå½¢å½å¼åº«ç¬åççæä»¶åèªåçæçç¨å¼ç¢¼ãééä½¿ç¨æä»¶æª¢ç´¢ä¾æ´åéæº LLMï¼ä¸¦éå°ç¨å¼ç¢¼å¾®èª¿éæº LLMï¼æåå±ç¤ºäºæºç¢ºåº¦æåäº 11-32%ãæåççµæå¼·èª¿ï¼LLM å¨èççµæ§åè³ææ¹é¢çè½åä»æªè¢«ååæ¢ç´¢ï¼ä¸¦é¡¯ç¤ºäº LLM4Graph å¨æå LLM åå½¢åæè½åæ¹é¢çæææ§ãåºæºãè³æéåå¢å¼·çéæºæ¨¡åå¯å¨ https://github.com/BUPT-GAMMA/ProGraph åå¾ã</paragraph>

##### **Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs**
2409.19401v1 by Zheng Wang, Zhongyang Li, Zeren Jiang, Dandan Tu, Wei Shi

In the age of mobile internet, user data, often referred to as memories, is
continuously generated on personal devices. Effectively managing and utilizing
this data to deliver services to users is a compelling research topic. In this
paper, we introduce a novel task of crafting personalized agents powered by
large language models (LLMs), which utilize a user's smartphone memories to
enhance downstream applications with advanced LLM capabilities. To achieve this
goal, we introduce EMG-RAG, a solution that combines Retrieval-Augmented
Generation (RAG) techniques with an Editable Memory Graph (EMG). This approach
is further optimized using Reinforcement Learning to address three distinct
challenges: data collection, editability, and selectability. Extensive
experiments on a real-world dataset validate the effectiveness of EMG-RAG,
achieving an improvement of approximately 10% over the best existing approach.
Additionally, the personalized agents have been transferred into a real
smartphone AI assistant, which leads to enhanced usability.

æè¦ï¼å¨è¡åç¶²è·¯æä»£ï¼ä½¿ç¨èè³æï¼å¸¸ç¨±çºè¨æ¶ï¼ææçºå¨åäººè£ç½®ä¸ç¢çãææç®¡çä¸¦å©ç¨éäºè³æï¼çºä½¿ç¨èæä¾æåï¼æ¯ä¸åå¼äººå¥åçç ç©¶ä¸»é¡ãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸é åµæ°çä»»åï¼å³å©ç¨å¤§åèªè¨æ¨¡åï¼LLMï¼æé åäººåä»£çï¼å©ç¨ä½¿ç¨èçæºæ§åææ©è¨æ¶é«ï¼ä»¥é²é LLM åè½å¼·åä¸æ¸¸æç¨ç¨å¼ãçºäºéæéåç®æ¨ï¼æåä»ç´¹äº EMG-RAGï¼ä¸ç¨®çµåæª¢ç´¢æ´åçæï¼RAGï¼æè¡èå¯ç·¨è¼¯è¨æ¶åï¼EMGï¼çè§£æ±ºæ¹æ¡ãéç¨®æ¹æ³é²ä¸æ­¥ééå¼·åå­¸ç¿é²è¡æä½³åï¼ä»¥è§£æ±ºä¸åä¸åçææ°ï¼è³ææ¶éãå¯ç·¨è¼¯æ§èå¯é¸ææ§ãå¨çå¯¦ä¸çè³æéä¸çå»£æ³å¯¦é©é©è­äº EMG-RAG çæææ§ï¼æ¯ç¾ææä½³æ¹æ³æåäºç´ 10%ãæ­¤å¤ï¼åäººåä»£çå·²è½ç§»å°çæ­£çæºæ§åææ© AI å©çä¸­ï¼éæåäºå¯ç¨æ§ã

##### **CLLMate: A Multimodal LLM for Weather and Climate Events Forecasting**
2409.19058v1 by Haobo Li, Zhaowei Wang, Jiachen Wang, Alexis Kai Hon Lau, Huamin Qu

Forecasting weather and climate events is crucial for making appropriate
measures to mitigate environmental hazards and minimize associated losses.
Previous research on environmental forecasting focuses on predicting numerical
meteorological variables related to closed-set events rather than forecasting
open-set events directly, which limits the comprehensiveness of event
forecasting. We propose Weather and Climate Event Forecasting (WCEF), a new
task that leverages meteorological raster data and textual event data to
predict potential weather and climate events. However, due to difficulties in
aligning multimodal data and the lack of sufficient supervised datasets, this
task is challenging to accomplish. Therefore, we first propose a framework to
align historical meteorological data with past weather and climate events using
the large language model (LLM). In this framework, we construct a knowledge
graph by using LLM to extract information about weather and climate events from
a corpus of over 41k highly environment-focused news articles. Subsequently, we
mapped these events with meteorological raster data, creating a supervised
dataset, which is the largest and most novel for LLM tuning on the WCEF task.
Finally, we introduced our aligned models, CLLMate (LLM for climate), a
multimodal LLM to forecast weather and climate events using meteorological
raster data. In evaluating CLLMate, we conducted extensive experiments. The
results indicate that CLLMate surpasses both the baselines and other multimodal
LLMs, showcasing the potential of utilizing LLM to align weather and climate
events with meteorological data and highlighting the promising future for
research on the WCEF task.

æè¦ï¼é æ¸¬å¤©æ°£åæ°£åäºä»¶å°æ¼æ¡åé©ç¶æªæ½æ¸è¼ç°å¢å±å®³åå°ç¸éæå¤±éè³æä½è³ééè¦ã
ååæéç°å¢é æ¸¬çç ç©¶èéæ¼é æ¸¬èå°ééäºä»¶ç¸éçæ¸å¼æ°£è±¡è®æ¸ï¼èéç´æ¥é æ¸¬éæ¾éäºä»¶ï¼ééå¶äºäºä»¶é æ¸¬çå¨é¢æ§ã
æåæåºå¤©æ°£åæ°£åäºä»¶é æ¸¬ (WCEF)ï¼éæ¯ä¸é å©ç¨æ°£è±¡æµæ ¼è³æåæå­äºä»¶è³æä¾é æ¸¬æ½å¨å¤©æ°£åæ°£åäºä»¶çæ°ä»»åã
ç¶èï¼ç±æ¼å¤æ¨¡æè³æå°é½çå°é£ä»¥åç¼ºä¹è¶³å¤ çç£ç£å¼è³æéï¼å æ­¤æ­¤ä»»åé£ä»¥éæã
å æ­¤ï¼æåé¦åæåºä¸åæ¶æ§ï¼ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) å°æ­·å²æ°£è±¡è³æèéå»çå¤©æ°£åæ°£åäºä»¶å°é½ã
å¨æ­¤æ¶æ§ä¸­ï¼æåééä½¿ç¨ LLM å¾è¶é 41,000 ç¯é«åº¦éæ³¨ç°å¢çæ°èæç« ä¸­æ·åæéå¤©æ°£åæ°£åäºä»¶çè³è¨ä¾å»ºæ§ç¥è­åè­ã
é¨å¾ï¼æåå°éäºäºä»¶å°æå°æ°£è±¡æµæ ¼è³æï¼å»ºç«ä¸åç£ç£å¼è³æéï¼éæ¯ LLM å¨ WCEF ä»»åä¸èª¿æ´ä¸­æå¤§ä¸ææ°ç©çè³æéã
æå¾ï¼æåå¼å¥äºæåçå°é½æ¨¡åï¼CLLMateï¼æ°£åç LLMï¼ï¼éæ¯ä¸åå¤æ¨¡æ LLMï¼ä½¿ç¨æ°£è±¡æµæ ¼è³æä¾é æ¸¬å¤©æ°£åæ°£åäºä»¶ã
å¨è©ä¼° CLLMate æï¼æåé²è¡äºå¤§éçå¯¦é©ã
çµæè¡¨æï¼CLLMate è¶è¶äºåºæºåå¶ä»çå¤æ¨¡æ LLMï¼å±ç¤ºäºå©ç¨ LLM å°å¤©æ°£åæ°£åäºä»¶èæ°£è±¡è³æå°é½çæ½åï¼ä¸¦å¼·èª¿äº WCEF ä»»åç ç©¶çæªä¾åæ¯ã

##### **AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow**
2409.18924v2 by Huizi Yu, Jiayan Zhou, Lingyao Li, Shan Chen, Jack Gallifant, Anye Shi, Xiang Li, Wenyue Hua, Mingyu Jin, Guang Chen, Yang Zhou, Zhao Li, Trisha Gupte, Ming-Li Chen, Zahra Azizi, Yongfeng Zhang, Themistocles L. Assimes, Xin Ma, Danielle S. Bitterman, Lin Lu, Lizhou Fan

Simulated patient systems play a crucial role in modern medical education and
research, providing safe, integrative learning environments and enabling
clinical decision-making simulations. Large Language Models (LLM) could advance
simulated patient systems by replicating medical conditions and patient-doctor
interactions with high fidelity and low cost. However, ensuring the
effectiveness and trustworthiness of these systems remains a challenge, as they
require a large, diverse, and precise patient knowledgebase, along with a
robust and stable knowledge diffusion to users. Here, we developed AIPatient,
an advanced simulated patient system with AIPatient Knowledge Graph (AIPatient
KG) as the input and the Reasoning Retrieval-Augmented Generation (Reasoning
RAG) agentic workflow as the generation backbone. AIPatient KG samples data
from Electronic Health Records (EHRs) in the Medical Information Mart for
Intensive Care (MIMIC)-III database, producing a clinically diverse and
relevant cohort of 1,495 patients with high knowledgebase validity (F1 0.89).
Reasoning RAG leverages six LLM powered agents spanning tasks including
retrieval, KG query generation, abstraction, checker, rewrite, and
summarization. This agentic framework reaches an overall accuracy of 94.15% in
EHR-based medical Question Answering (QA), outperforming benchmarks that use
either no agent or only partial agent integration. Our system also presents
high readability (median Flesch Reading Ease 77.23; median Flesch Kincaid Grade
5.6), robustness (ANOVA F-value 0.6126, p>0.1), and stability (ANOVA F-value
0.782, p>0.1). The promising performance of the AIPatient system highlights its
potential to support a wide range of applications, including medical education,
model evaluation, and system integration.

æè¦ï¼æ¨¡æ¬çäººç³»çµ±å¨ç¾ä»£é«å­¸æè²åç ç©¶ä¸­æ®æ¼èè³ééè¦çè§è²ï¼æä¾å®å¨ãæ´åçå­¸ç¿ç°å¢ï¼ä¸¦è½é²è¡è¨åºæ±ºç­æ¨¡æ¬ãå¤§åèªè¨æ¨¡å (LLM) è½ééé«ä¿çåº¦åä½ææ¬è¤è£½é«ççæ³åé«çäºåï¼é²èæåæ¨¡æ¬çäººç³»çµ±ãç¶èï¼ç¢ºä¿éäºç³»çµ±çæææ§åå¯ä¿¡åº¦ä»ç¶æ¯ä¸é ææ°ï¼å çºå®åéè¦ä¸åé¾å¤§ãå¤åä¸ç²¾ç¢ºççäººç¥è­åº«ï¼ä»¥åç©©å¥ä¸ç©©å®çç¥è­å³æ­çµ¦ä½¿ç¨èãå¨æ­¤ï¼æåéç¼äº AIPatientï¼ä¸åé²éçæ¨¡æ¬çäººç³»çµ±ï¼ä»¥ AIPatient ç¥è­åè­ (AIPatient KG) ä½çºè¼¸å¥ï¼ä¸¦ä»¥æ¨çæª¢ç´¢å¢å¼·çæ (Reasoning RAG) ä»£çå·¥ä½æµç¨ä½çºçæä¸»å¹¹ãAIPatient KG å¾éçç£è­·é«å­¸è³è¨ä¸­å¿ (MIMIC)-III è³æåº«ä¸­çé»å­å¥åº·ç´é (EHR) ä¸­æ½åè³æï¼ç¢çä¸åè¨åºå¤æ¨£ä¸ç¸éç 1,495 åçæ£ç¾¤çµï¼å·æå¾é«çç¥è­åº«æåº¦ (F1 0.89)ãæ¨ç RAG æ§æ¡¿äºå­å LLM é©åçä»£çï¼è·¨è¶æª¢ç´¢ãKG æ¥è©¢ç¢çãæ½è±¡ãæª¢æ¥å¨ãéå¯«åæè¦ç­ä»»åãéåä»£çæ¡æ¶å¨åºæ¼ EHR çé«çåç­ (QA) ä¸­éå°äº 94.15% çæ´é«æºç¢ºåº¦ï¼åªæ¼ä¸ä½¿ç¨ä»£çæåé¨åä»£çæ´åçåºæºãæåçç³»çµ±éå·æå¾é«çå¯è®æ§ (Flesch é±è®ç°¡ä¾¿æ§ä¸­ä½æ¸ 77.23ï¼Flesch Kincaid ç­ç´ä¸­ä½æ¸ 5.6)ãç©©å¥æ§ (ANOVA F å¼ 0.6126ï¼p>0.1) åç©©å®æ§ (ANOVA F å¼ 0.782ï¼p>0.1)ãAIPatient ç³»çµ±çåºè²è¡¨ç¾çªé¡¯äºå®å¨æ¯æ´åç¨®æç¨ç¨å¼çæ½åï¼åæ¬é«å­¸æè²ãæ¨¡åè©ä¼°åç³»çµ±æ´åã

##### **Soft Measures for Extracting Causal Collective Intelligence**
2409.18911v1 by Maryam Berijanian, Spencer Dork, Kuldeep Singh, Michael Riley Millikan, Ashlin Riggs, Aadarsh Swaminathan, Sarah L. Gibbs, Scott E. Friedman, Nathan Brugnone

Understanding and modeling collective intelligence is essential for
addressing complex social systems. Directed graphs called fuzzy cognitive maps
(FCMs) offer a powerful tool for encoding causal mental models, but extracting
high-integrity FCMs from text is challenging. This study presents an approach
using large language models (LLMs) to automate FCM extraction. We introduce
novel graph-based similarity measures and evaluate them by correlating their
outputs with human judgments through the Elo rating system. Results show
positive correlations with human evaluations, but even the best-performing
measure exhibits limitations in capturing FCM nuances. Fine-tuning LLMs
improves performance, but existing measures still fall short. This study
highlights the need for soft similarity measures tailored to FCM extraction,
advancing collective intelligence modeling with NLP.

æè¦ï¼äºè§£åå»ºæ¨¡éä½æºæ§å¯¹äºè§£å³å¤æçç¤¾ä¼ç³»ç»è³å³éè¦ãç§°ä¸ºæ¨¡ç³è®¤ç¥å¾ï¼FCMï¼çæåå¾æä¾äºä¸ç§å¼ºå¤§çå·¥å·æ¥ç¼ç å æå¿æºæ¨¡åï¼ä½ä»ææ¬ä¸­æåé«å®æ´æ§ç FCM å·ææææ§ãæ¬ç ç©¶æåºäºä¸ç§ä½¿ç¨å¤§åè¯­è¨æ¨¡åï¼LLMï¼æ¥èªå¨å FCM æåçæ¹æ³ãæä»¬å¼å¥äºæ°é¢çåºäºå¾çç¸ä¼¼æ§åº¦éï¼å¹¶éè¿éè¿ Elo è¯çº§ç³»ç»å°å¶è¾åºä¸äººç±»å¤æ­ç¸å³èæ¥è¯ä¼°å®ä»¬ãç»æè¡¨æä¸äººç±»è¯ä¼°åæ­£ç¸å³ï¼ä½å³ä½¿æ¯è¡¨ç°æå¥½çåº¦éå¨ææ FCM ç»å¾®å·®å«æ¹é¢ä¹è¡¨ç°åºå±éæ§ãå¾®è° LLM å¯ä»¥æé«æ§è½ï¼ä½ç°ææªæ½ä»ç¶ä¸è¶³ãæ¬ç ç©¶å¼ºè°äºéå¯¹ FCM æåéèº«å®å¶çè½¯ç¸ä¼¼æ§åº¦éçå¿è¦æ§ï¼éè¿ NLP æ¨è¿äºéä½æºè½å»ºæ¨¡ã

##### **OpenObject-NAV: Open-Vocabulary Object-Oriented Navigation Based on Dynamic Carrier-Relationship Scene Graph**
2409.18743v1 by Yujie Tang, Meiling Wang, Yinan Deng, Zibo Zheng, Jiagui Zhong, Yufeng Yue

In everyday life, frequently used objects like cups often have unfixed
positions and multiple instances within the same category, and their carriers
frequently change as well. As a result, it becomes challenging for a robot to
efficiently navigate to a specific instance. To tackle this challenge, the
robot must capture and update scene changes and plans continuously. However,
current object navigation approaches primarily focus on semantic-level and lack
the ability to dynamically update scene representation. This paper captures the
relationships between frequently used objects and their static carriers. It
constructs an open-vocabulary Carrier-Relationship Scene Graph (CRSG) and
updates the carrying status during robot navigation to reflect the dynamic
changes of the scene. Based on the CRSG, we further propose an instance
navigation strategy that models the navigation process as a Markov Decision
Process. At each step, decisions are informed by Large Language Model's
commonsense knowledge and visual-language feature similarity. We designed a
series of long-sequence navigation tasks for frequently used everyday items in
the Habitat simulator. The results demonstrate that by updating the CRSG, the
robot can efficiently navigate to moved targets. Additionally, we deployed our
algorithm on a real robot and validated its practical effectiveness.

æè¦ï¼æ¥å¸¸çæ´»ä¸­ï¼ç¶å¸¸ä½¿ç¨çç©åï¼ä¾å¦æ¯å­ï¼éå¸¸æ²æåºå®çä½ç½®ï¼èä¸åä¸é¡å¥ä¸­æå¤åå¯¦ä¾ï¼å¶æ¿è¼èä¹ç¶å¸¸è®æ´ãå æ­¤ï¼æ©å¨äººè¦ææå°å°èªå°ç¹å®å¯¦ä¾è®å¾å·æææ°æ§ãçºäºæå°éä¸ææ°ï¼æ©å¨äººå¿é ä¸æ·ææåæ´æ°å ´æ¯è®æ´åè¨ç«ãç¶èï¼ç®åçç©ä»¶å°èªæ¹æ³ä¸»è¦éä¸­å¨èªç¾©å±¤ç´ï¼ä¸¦ä¸ç¼ºä¹åææ´æ°å ´æ¯è¡¨ç¤ºçè½åãæ¬æææäºç¶å¸¸ä½¿ç¨çç©ä»¶åå¶éææ¿è¼èä¹éçéä¿ãå®æ§å»ºäºä¸åéæ¾è©å½çæ¿è¼èéä¿å ´æ¯å (CRSG)ï¼ä¸¦å¨æ©å¨äººå°èªæéæ´æ°æ¿è¼çæä»¥åæ å ´æ¯çåæè®åãåºæ¼ CRSGï¼æåé²ä¸æ­¥æåºäºä¸ç¨®å°å°èªéç¨å»ºæ¨¡çºé¦¬å¯å¤«æ±ºç­éç¨çå¯¦ä¾å°èªç­ç¥ãå¨æ¯ä¸æ­¥ä¸­ï¼æ±ºç­é½ç±å¤§åèªè¨æ¨¡åçå¸¸è­ç¥è­åè¦è¦ºèªè¨ç¹å¾µç¸ä¼¼æ§ä¾åç¥ãæåçº Habitat æ¨¡æ¬å¨ä¸­çæ¥å¸¸å¸¸ç¨ç©åè¨­è¨äºä¸ç³»åé·åºåå°èªä»»åãçµæè¡¨æï¼ééæ´æ° CRSGï¼æ©å¨äººå¯ä»¥ææå°å°èªå°ç§»åçç®æ¨ãæ­¤å¤ï¼æåå¨çå¯¦æ©å¨äººä¸é¨ç½²äºæåçæ¼ç®æ³ï¼ä¸¦é©è­äºå¶å¯¦éæè½ã

##### **Rehearsing Answers to Probable Questions with Perspective-Taking**
2409.18678v1 by Yung-Yu Shih, Ziwei Xu, Hiroya Takamura, Yun-Nung Chen, Chung-Chi Chen

Question answering (QA) has been a long-standing focus in the NLP field,
predominantly addressing reading comprehension and common sense QA. However,
scenarios involving the preparation of answers to probable questions during
professional oral presentations remain underexplored. In this paper, we pioneer
the examination of this crucial yet overlooked topic by utilizing real-world QA
conversation transcripts between company managers and professional analysts. We
explore the proposed task using three causal knowledge graphs (KGs) and three
large language models (LLMs). This work provides foundational insights into the
application of LLMs in professional QA scenarios, highlighting the importance
of causal KGs and perspective-taking in generating effective responses.

æè¦ï¼åé¡è§£ç­ (QA) ä¸ç´æ¯èªç¶èªè¨èç (NLP) é åçé·æéæ³¨éé»ï¼
ä¸»è¦è§£æ±ºé±è®çè§£åå¸¸è­åé¡è§£ç­ãç¶èï¼
å¨å°æ¥­å£é ­ç°¡å ±ä¸­æºååç­å¯è½åé¡çå ´æ¯ä»æªå¾å°ååæ¢è¨ãå¨æ¬æä¸­ï¼æåçå
å©ç¨å¬å¸ç¶çåå°æ¥­åæå¸«ä¹éççå¯¦ä¸çåç­å°è©±è¨éï¼æ¢è¨éåè³ééè¦ä½è¢«å¿½è¦çä¸»é¡ãæå
ä½¿ç¨ä¸åå æç¥è­åè­ (KG) åä¸åå¤§åèªè¨æ¨¡å (LLM) ä¾æ¢è¨æåºçä»»åãéé å·¥ä½çº LLM å¨å°æ¥­åç­å ´æ¯ä¸­çæç¨æä¾äºåºç¤è¦è§£ï¼å¼·èª¿äºå æ KG åè§é»æ¡åå¨ç¢çææåæä¸­çéè¦æ§ã

##### **LowREm: A Repository of Word Embeddings for 87 Low-Resource Languages Enhanced with Multilingual Graph Knowledge**
2409.18193v1 by Daniil Gurgurov, Rishu Kumar, Simon Ostermann

Contextualized embeddings based on large language models (LLMs) are available
for various languages, but their coverage is often limited for lower resourced
languages. Training LLMs for such languages is often difficult due to
insufficient data and high computational cost. Especially for very low resource
languages, static word embeddings thus still offer a viable alternative. There
is, however, a notable lack of comprehensive repositories with such embeddings
for diverse languages. To address this, we present LowREm, a centralized
repository of static embeddings for 87 low-resource languages. We also propose
a novel method to enhance GloVe-based embeddings by integrating multilingual
graph knowledge, utilizing another source of knowledge. We demonstrate the
superior performance of our enhanced embeddings as compared to contextualized
embeddings extracted from XLM-R on sentiment analysis. Our code and data are
publicly available under https://huggingface.co/DFKI.

æè¦ï¼åºæ¼å¤§åèªè¨æ¨¡å (LLM) çèªå¢ååµå¥å¯ä¾åç¨®èªè¨ä½¿ç¨ï¼ä½å¶æ¶µèç¯åéå¸¸åéæ¼è³æºè¼å°çèªè¨ãç±æ¼è³æä¸è¶³åé«éç®ææ¬ï¼çºæ­¤é¡èªè¨è¨ç·´ LLM éå¸¸å¾å°é£ãç¹å¥æ¯å°æ¼è³æºéå¸¸å°çèªè¨ï¼å æ­¤éæå­è©åµå¥ä»æä¾å¯è¡çæ¿ä»£æ¹æ¡ãç¶èï¼å°æ¼åç¨®èªè¨ä¾èªªï¼æ­¤é¡åµå¥ç¼ºä¹å¨é¢çå²å­åº«ãçºäºè§£æ±ºéååé¡ï¼æåæåºäº LowREmï¼ä¸åéå° 87 ç¨®ä½è³æºèªè¨çéæåµå¥éä¸­å¼å²å­åº«ãæåéæåºäºä¸ç¨®æ°æ¹æ³ï¼ééæ´åå¤èªè¨åå½¢ç¥è­ä¾å¢å¼·åºæ¼ GloVe çåµå¥ï¼å©ç¨å¦ä¸åç¥è­ä¾æºãæåå±ç¤ºäºæåå¢å¼·çåµå¥å¨æç·åæä¸åªæ¼å¾ XLM-R æåçèªå¢ååµå¥ãæåçç¨å¼ç¢¼åè³æå·²å¬éå¨ https://huggingface.co/DFKI ä¸ã

##### **Enhancing Structured-Data Retrieval with GraphRAG: Soccer Data Case Study**
2409.17580v1 by Zahra Sepasdar, Sushant Gautam, Cise Midoglu, Michael A. Riegler, PÃ¥l Halvorsen

Extracting meaningful insights from large and complex datasets poses
significant challenges, particularly in ensuring the accuracy and relevance of
retrieved information. Traditional data retrieval methods such as sequential
search and index-based retrieval often fail when handling intricate and
interconnected data structures, resulting in incomplete or misleading outputs.
To overcome these limitations, we introduce Structured-GraphRAG, a versatile
framework designed to enhance information retrieval across structured datasets
in natural language queries. Structured-GraphRAG utilizes multiple knowledge
graphs, which represent data in a structured format and capture complex
relationships between entities, enabling a more nuanced and comprehensive
retrieval of information. This graph-based approach reduces the risk of errors
in language model outputs by grounding responses in a structured format,
thereby enhancing the reliability of results. We demonstrate the effectiveness
of Structured-GraphRAG by comparing its performance with that of a recently
published method using traditional retrieval-augmented generation. Our findings
show that Structured-GraphRAG significantly improves query processing
efficiency and reduces response times. While our case study focuses on soccer
data, the framework's design is broadly applicable, offering a powerful tool
for data analysis and enhancing language model applications across various
structured domains.

æè¦ï¼å¾é¾å¤§ä¸è¤éçè³æéä¸­èååºææç¾©çè¦è§£æå¸¶ä¾é¡¯èçææ°ï¼ç¹å¥æ¯å¨ç¢ºä¿æ·åè³è¨çæºç¢ºæ§åç¸éæ§æ¹é¢ãå³çµ±çè³ææ·åæ¹æ³ï¼ä¾å¦é åºæå°ååºæ¼ç´¢å¼çæ·åï¼å¨èçè¤éä¸ç¸äºé£çµçè³æçµæ§æï¼å¸¸å¸¸æå¤±æï¼å°è´ä¸å®æ´æèª¤å°æ§çè¼¸åºãçºäºåæéäºéå¶ï¼æåå¼å¥äºçµæ§ååå½¢ RAGï¼éæ¯ä¸åéç¨æ¡æ¶ï¼æ¨å¨å¢å¼·èªç¶èªè¨æ¥è©¢ä¸­çµæ§åè³æéçè³è¨æ·åãçµæ§ååå½¢ RAG å©ç¨å¤åç¥è­åå½¢ï¼å®åä»¥çµæ§åæ ¼å¼è¡¨ç¤ºè³æï¼ä¸¦æ·åå¯¦é«ä¹éçè¤ééä¿ï¼å¾èå¯¦ç¾æ´ç´°ç·»ä¸å¨é¢çè³è¨æ·åãéç¨®åºæ¼åå½¢çåæ³ééä»¥çµæ§åæ ¼å¼çºåºç¤åæï¼éä½èªè¨æ¨¡åè¼¸åºä¸­åºç¾é¯èª¤çé¢¨éªï¼å¾èæé«çµæçå¯é æ§ãæåééå°çµæ§ååå½¢ RAG çæè½èæè¿ç¼è¡¨çå³çµ±æ·åå¢å¼·çææ¹æ³é²è¡æ¯è¼ï¼ä¾è­æå¶æææ§ãæåçç ç©¶çµæé¡¯ç¤ºï¼çµæ§ååå½¢ RAG å¤§å¹æåäºæ¥è©¢èçæçï¼ä¸¦ç¸®ç­äºåææéãéç¶æåçæ¡ä¾ç ç©¶å°æ³¨æ¼è¶³çè³æï¼ä½éåæ¶æ§çè¨­è¨å·æå»£æ³çé©ç¨æ§ï¼æä¾äºä¸åå¼·å¤§çè³æåæå·¥å·ï¼ä¸¦å¢å¼·äºåç¨®çµæ§åé åçèªè¨æ¨¡åæç¨ã

##### **Probing Omissions and Distortions in Transformer-based RDF-to-Text Models**
2409.16707v1 by Juliette Faille, Albert Gatt, Claire Gardent

In Natural Language Generation (NLG), important information is sometimes
omitted in the output text. To better understand and analyse how this type of
mistake arises, we focus on RDF-to-Text generation and explore two methods of
probing omissions in the encoder output of BART (Lewis et al, 2020) and of T5
(Raffel et al, 2019): (i) a novel parameter-free probing method based on the
computation of cosine similarity between embeddings of RDF graphs and of RDF
graphs in which we removed some entities and (ii) a parametric probe which
performs binary classification on the encoder embeddings to detect omitted
entities. We also extend our analysis to distorted entities, i.e. entities that
are not fully correctly mentioned in the generated text (e.g. misspelling of
entity, wrong units of measurement). We found that both omitted and distorted
entities can be probed in the encoder's output embeddings. This suggests that
the encoder emits a weaker signal for these entities and therefore is
responsible for some loss of information. This also shows that probing methods
can be used to detect mistakes in the output of NLG models.

æè¦ï¼å¨èªç¶èªè¨çæ (NLG) ä¸­ï¼éè¦è³è¨æææå¨è¼¸åºæå­ä¸­è¢«çç¥ãçºäºæ´äºè§£ä¸¦åæéé¡é¯èª¤æ¯å¦ä½ç¢ççï¼æåå°æ³¨æ¼ RDF è½æå­ççæï¼ä¸¦æ¢è¨å©ç¨®æ¢æ¸¬ BART (Lewis ç­äººï¼2020) å T5 (Raffel ç­äººï¼2019) çç·¨ç¢¼å¨è¼¸åºä¸­éºæ¼çæ¹æ³ï¼(i) ä¸ç¨®åºæ¼ RDF åå½¢åµå¥åæåç§»é¤ä¸äºå¯¦é«ç RDF åå½¢ä¹éçé¤å¼¦ç¸ä¼¼åº¦è¨ç®çæ°åç¡åæ¸æ¢æ¸¬æ¹æ³ï¼ä»¥å (ii) ä¸ç¨®å¨ç·¨ç¢¼å¨åµå¥ä¸­å·è¡äºååé¡ä»¥åµæ¸¬éºæ¼å¯¦é«çåæ¸åæ¢æ¸¬ãæåä¹å°æåçåæå»¶ä¼¸å°æ­æ²çå¯¦é«ï¼ä¹å°±æ¯å¨ç¢ççæå­ä¸­æ²æè¢«å®å¨æ­£ç¢ºæåçå¯¦é« (ä¾å¦å¯¦é«æ¼å¯«é¯èª¤ãæ¸¬éå®ä½é¯èª¤)ãæåç¼ç¾éºæ¼åæ­æ²çå¯¦é«é½å¯ä»¥è¢«æ¢æ¸¬å°å¨ç·¨ç¢¼å¨çè¼¸åºåµå¥ä¸­ãéè¡¨ç¤ºç·¨ç¢¼å¨éå°éäºå¯¦é«ç¼å°è¼å¼±çè¨èï¼å æ­¤å°è´ä¸äºè³è¨éºå¤±ãéä¹é¡¯ç¤ºæ¢æ¸¬æ¹æ³å¯ä»¥ç¨æ¼åµæ¸¬ NLG æ¨¡åè¼¸åºä¸­çé¯èª¤ã

##### **GraphLoRA: Structure-Aware Contrastive Low-Rank Adaptation for Cross-Graph Transfer Learning**
2409.16670v1 by Zhe-Rui Yang, Jindong Han, Chang-Dong Wang, Hao Liu

Graph Neural Networks (GNNs) have demonstrated remarkable proficiency in
handling a range of graph analytical tasks across various domains, such as
e-commerce and social networks. Despite their versatility, GNNs face
significant challenges in transferability, limiting their utility in real-world
applications. Existing research in GNN transfer learning overlooks
discrepancies in distribution among various graph datasets, facing challenges
when transferring across different distributions. How to effectively adopt a
well-trained GNN to new graphs with varying feature and structural
distributions remains an under-explored problem. Taking inspiration from the
success of Low-Rank Adaptation (LoRA) in adapting large language models to
various domains, we propose GraphLoRA, an effective and parameter-efficient
method for transferring well-trained GNNs to diverse graph domains.
Specifically, we first propose a Structure-aware Maximum Mean Discrepancy
(SMMD) to align divergent node feature distributions across source and target
graphs. Moreover, we introduce low-rank adaptation by injecting a small
trainable GNN alongside the pre-trained one, effectively bridging structural
distribution gaps while mitigating the catastrophic forgetting. Additionally, a
structure-aware regularization objective is proposed to enhance the
adaptability of the pre-trained GNN to target graph with scarce supervision
labels. Extensive experiments on six real-world datasets demonstrate the
effectiveness of GraphLoRA against eleven baselines by tuning only 20% of
parameters, even across disparate graph domains. The code is available at
https://anonymous.4open.science/r/GraphLoRA.

æè¦ï¼åå½¢ç¥ç¶ç¶²è·¯ (GNN) å·²å±ç¾åºå¨åç¨®é åèçä¸ç³»ååå½¢åæä»»åçåè¶è½åï¼ä¾å¦é»å­åååç¤¾ç¾¤ç¶²è·¯ãåç®¡ GNN å·æå¤åè½æ§ï¼ä½å¨å¯è½ç§»æ§æ¹é¢ä»é¢è¨éå¤§ææ°ï¼éå¶äºå®åå¨ç¾å¯¦ä¸çæç¨ä¸­çæç¨ãç¾æç GNN è½ç§»å­¸ç¿ç ç©¶å¿½è¦äºåç¨®åå½¢è³æéä¹éçåå¸å·®ç°ï¼å¨è·¨ä¸ååå¸è½ç§»æé¢è¨ææ°ãå¦ä½ææå°å°è¨ç·´è¯å¥½ç GNN æç¨æ¼å·æä¸åç¹å¾µåçµæ§åå¸çæ°åå½¢ï¼ä»ç¶æ¯ä¸åå°æªååæ¢è¨çåé¡ãå¾ä½ç§©é©æ (LoRA) å¨å°å¤§åèªè¨æ¨¡åé©æå°åç¨®é åæ¹é¢ç²å¾çæåä¸­æ±²åéæï¼æåæåºäº GraphLoRAï¼éæ¯ä¸ç¨®ææä¸åæ¸æçé«çæ¹æ³ï¼å¯ç¨æ¼å°è¨ç·´è¯å¥½ç GNN è½ç§»å°ä¸åçåå½¢é åãå·é«ä¾èªªï¼æåé¦åæåºä¸åçµæ§æç¥æå¤§å¹³åå·®ç° (SMMD) ä¾èª¿æ´ä¾æºåç®æ¨åå½¢ä¸­çä¸åç¯é»ç¹å¾µåå¸ãæ­¤å¤ï¼æåééå¨é åè¨ç·´ç GNN æéæ³¨å¥ä¸åå°çå¯è¨ç·´ GNN ä¾å¼å¥ä½ç§©é©æï¼å¾èææå°å½åçµæ§åå¸å·®è·ï¼åææ¸è¼ç½é£æ§éºå¿ãæ­¤å¤ï¼éæåºäºçµæ§æç¥æ­£ååç®æ¨ï¼ä»¥å¢å¼·é åè¨ç·´ç GNN å°å·æç¨çç£ç£æ¨ç±¤çç®æ¨åå½¢çé©ææ§ãå¨å­åçå¯¦ä¸çè³æéä¸çå¤§éå¯¦é©è­æäº GraphLoRA çæææ§ï¼å®åèª¿æ´äº 20% çåæ¸ï¼å³ä½¿å¨ä¸åçåå½¢é åä¸­ä¹è½å¤ åéåä¸ç¨®åºæºãç¨å¼ç¢¼å¯å¨ https://anonymous.4open.science/r/GraphLoRA åå¾ã

##### **Cyber Knowledge Completion Using Large Language Models**
2409.16176v1 by Braden K Webb, Sumit Purohit, Rounak Meyur

The integration of the Internet of Things (IoT) into Cyber-Physical Systems
(CPSs) has expanded their cyber-attack surface, introducing new and
sophisticated threats with potential to exploit emerging vulnerabilities.
Assessing the risks of CPSs is increasingly difficult due to incomplete and
outdated cybersecurity knowledge. This highlights the urgent need for
better-informed risk assessments and mitigation strategies. While previous
efforts have relied on rule-based natural language processing (NLP) tools to
map vulnerabilities, weaknesses, and attack patterns, recent advancements in
Large Language Models (LLMs) present a unique opportunity to enhance
cyber-attack knowledge completion through improved reasoning, inference, and
summarization capabilities. We apply embedding models to encapsulate
information on attack patterns and adversarial techniques, generating mappings
between them using vector embeddings. Additionally, we propose a
Retrieval-Augmented Generation (RAG)-based approach that leverages pre-trained
models to create structured mappings between different taxonomies of threat
patterns. Further, we use a small hand-labeled dataset to compare the proposed
RAG-based approach to a baseline standard binary classification model. Thus,
the proposed approach provides a comprehensive framework to address the
challenge of cyber-attack knowledge graph completion.

æè¦ï¼ç©è¯ç¶² (IoT) èç¶²è·¯å¯¦é«ç³»çµ± (CPS) çæ´åæ´å¤§äºå¶ç¶²è·¯æ»æé¢ï¼å¼å¥äºæ°çåè¤éçå¨èï¼å·æå©ç¨æ°èæ¼æ´çæ½åãç±æ¼ç¶²è·¯å®å¨ç¥è­ä¸å®æ´ä¸éæï¼è©ä¼° CPS çé¢¨éªè®å¾è¶ä¾è¶å°é£ãéçªé¡¯äºè¿«åéè¦æ´å®åçé¢¨éªè©ä¼°åç·©è§£ç­ç¥ãéç¶ååçåªåä¾è³´æ¼åºæ¼è¦åçèªç¶èªè¨èç (NLP) å·¥å·ä¾ç¹ªè£½æ¼æ´ãå¼±é»åæ»ææ¨¡å¼ï¼ä½å¤§åèªè¨æ¨¡å (LLM) çææ°é²å±æä¾äºä¸åç¨ç¹çæ©æï¼å¯ä»¥ééæ¹é²çæ¨çãæ¨è«åæè¦è½åä¾å¢å¼·ç¶²è·¯æ»æç¥è­çå®æåº¦ãæåæç¨åµå¥æ¨¡åä¾å°è£æéæ»ææ¨¡å¼åå°ææè¡çè³è¨ï¼ä½¿ç¨åéåµå¥å¨å®åä¹éç¢çå°æéä¿ãæ­¤å¤ï¼æåæåºäºä¸ååºæ¼æª¢ç´¢å¢å¼·çæ (RAG) çæ¹æ³ï¼è©²æ¹æ³å©ç¨é åè¨ç·´çæ¨¡åå¨å¨èæ¨¡å¼çä¸ååé¡æ³ä¹éå»ºç«çµæ§åçå°æéä¿ãæ­¤å¤ï¼æåä½¿ç¨ä¸åå°åçæåæ¨è¨è³æéä¾æ¯è¼ææåºçåºæ¼ RAG çæ¹æ³èåºç·æ¨æºäºååé¡æ¨¡åãå æ­¤ï¼ææåºçæ¹æ³æä¾äºä¸åå¨é¢çæ¶æ§ä¾è§£æ±ºç¶²è·¯æ»æç¥è­åå®æçææ°ã

##### **Konstruktor: A Strong Baseline for Simple Knowledge Graph Question Answering**
2409.15902v1 by Maria Lysyuk, Mikhail Salnikov, Pavel Braslavski, Alexander Panchenko

While being one of the most popular question types, simple questions such as
"Who is the author of Cinderella?", are still not completely solved.
Surprisingly, even the most powerful modern Large Language Models are prone to
errors when dealing with such questions, especially when dealing with rare
entities. At the same time, as an answer may be one hop away from the question
entity, one can try to develop a method that uses structured knowledge graphs
(KGs) to answer such questions. In this paper, we introduce Konstruktor - an
efficient and robust approach that breaks down the problem into three steps:
(i) entity extraction and entity linking, (ii) relation prediction, and (iii)
querying the knowledge graph. Our approach integrates language models and
knowledge graphs, exploiting the power of the former and the interpretability
of the latter. We experiment with two named entity recognition and entity
linking methods and several relation detection techniques. We show that for
relation detection, the most challenging step of the workflow, a combination of
relation classification/generation and ranking outperforms other methods. We
report Konstruktor's strong results on four datasets.

æè¦ï¼åç®¡æ¯æå¸¸è¦çåé¡é¡åä¹ä¸ï¼ä½è«¸å¦ãç°å§å¨çä½èæ¯èª°ï¼ãéé¡ç°¡å®çåé¡ä»æªå®å¨ç²å¾è§£ç­ãä»¤äººé©è¨çæ¯ï¼å³ä½¿æ¯æå¼·å¤§çç¾ä»£å¤§åèªè¨æ¨¡åå¨èçæ­¤é¡åé¡æä¹å®¹æåºé¯ï¼ç¹å¥æ¯å¨èçç½è¦å¯¦é«æãèæ­¤åæï¼ç±æ¼ç­æ¡å¯è½è·é¢åé¡å¯¦é«åä¸æ­¥ä¹éï¼å æ­¤å¯ä»¥åè©¦éç¼ä¸ç¨®ä½¿ç¨çµæ§åç¥è­åè­ (KG) ä¾åç­æ­¤é¡åé¡çæ¹æ³ãå¨æ¬æä¸­ï¼æåä»ç´¹ Konstruktor - ä¸ç¨®é«æä¸å¼·å¤§çæ¹æ³ï¼å®å°åé¡åè§£çºä¸åæ­¥é©ï¼(i) å¯¦é«èååå¯¦é«é£çµã(ii) éä¿é æ¸¬ä»¥å (iii) æ¥è©¢ç¥è­åè­ãæåçåæ³æ´åäºèªè¨æ¨¡ååç¥è­åè­ï¼ç¼æ®äºåèçè½ååå¾èçå¯è§£éæ§ãæåå¯¦é©äºå©ç¨®å½åå¯¦é«è­å¥åå¯¦é«é£çµæ¹æ³ä»¥åå¤ç¨®éä¿åµæ¸¬æè¡ãæåè¡¨æï¼å°æ¼éä¿åµæ¸¬ï¼ä¹å°±æ¯å·¥ä½æµç¨ä¸­æå·ææ°æ§çæ­¥é©ï¼éä¿åé¡/çæåæåç¸çµåççµååªæ¼å¶ä»æ¹æ³ãæåå ±åäº Konstruktor å¨ååè³æéä¸çå¼·åææã

##### **Symmetries and Expressive Requirements for Learning General Policies**
2409.15892v1 by Dominik Drexler, Simon StÃ¥hlberg, Blai Bonet, Hector Geffner

State symmetries play an important role in planning and generalized planning.
In the first case, state symmetries can be used to reduce the size of the
search; in the second, to reduce the size of the training set. In the case of
general planning, however, it is also critical to distinguish non-symmetric
states, i.e., states that represent non-isomorphic relational structures.
However, while the language of first-order logic distinguishes non-symmetric
states, the languages and architectures used to represent and learn general
policies do not. In particular, recent approaches for learning general policies
use state features derived from description logics or learned via graph neural
networks (GNNs) that are known to be limited by the expressive power of C_2,
first-order logic with two variables and counting. In this work, we address the
problem of detecting symmetries in planning and generalized planning and use
the results to assess the expressive requirements for learning general policies
over various planning domains. For this, we map planning states to plain
graphs, run off-the-shelf algorithms to determine whether two states are
isomorphic with respect to the goal, and run coloring algorithms to determine
if C_2 features computed logically or via GNNs distinguish non-isomorphic
states. Symmetry detection results in more effective learning, while the
failure to detect non-symmetries prevents general policies from being learned
at all in certain domains.

æè¦ï¼çæå°ç¨±æ§å¨è¦ååå»£ç¾©è¦åä¸­æ®æ¼èéè¦çè§è²ã
å¨ç¬¬ä¸ç¨®ææ³ä¸­ï¼çæå°ç¨±æ§å¯ç¨æ¼ç¸®å°æå°çè¦æ¨¡ï¼å¨ç¬¬äºç¨®ææ³ä¸­ï¼å¯ç¨æ¼ç¸®å°è¨ç·´éçè¦æ¨¡ãç¶èï¼å¨å»£ç¾©è¦åçææ³ä¸­ï¼ååéå°ç¨±çæï¼å³è¡¨ç¤ºéåæ§éä¿çµæ§ççæï¼ä¹å¾éè¦ãç¶èï¼éç¶ä¸ééè¼¯çèªè¨ååäºéå°ç¨±çæï¼ä½ç¨æ¼è¡¨ç¤ºåå­¸ç¿ä¸è¬ç­ç¥çèªè¨åæ¶æ§å»æ²æãç¹å¥æ¯ï¼æè¿ç¨æ¼å­¸ç¿ä¸è¬ç­ç¥çæ¹æ³ä½¿ç¨å¾æè¿°éè¼¯ä¸­è¡çççæç¹å¾µï¼æééåç¥ç¶ç¶²è·¯ (GNN) å­¸ç¿ï¼å·²ç¥éäºç¹å¾µåå°å·æå©åè®æ¸åè¨æ¸çä¸ééè¼¯ C_2 çè¡¨éè½åéå¶ãå¨éé å·¥ä½ä¸­ï¼æåè§£æ±ºäºå¨è¦ååå»£ç¾©è¦åä¸­æª¢æ¸¬å°ç¨±æ§çåé¡ï¼ä¸¦ä½¿ç¨çµæè©ä¼°å¨åç¨®è¦åé åä¸­å­¸ç¿ä¸è¬ç­ç¥çè¡¨ééæ±ãçºæ­¤ï¼æåå°è¦åçææ å°å°å¹³é¢åå½¢ï¼å·è¡ç¾æçæ¼ç®æ³ä¾ç¢ºå®å©åçææ¯å¦ç¸å°æ¼ç®æ¨åæ§ï¼ä¸¦å·è¡èè²æ¼ç®æ³ä¾ç¢ºå®éééè¼¯æ GNN è¨ç®ç C_2 ç¹å¾µæ¯å¦ååéåæ§çæãå°ç¨±æ§æª¢æ¸¬æå¸¶ä¾æ´ææçå­¸ç¿ï¼èç¡æ³æª¢æ¸¬éå°ç¨±æ§åæå®å¨é»æ­¢å¨æäºé åä¸­å­¸ç¿ä¸è¬ç­ç¥ã

##### **GEM-RAG: Graphical Eigen Memories For Retrieval Augmented Generation**
2409.15566v1 by Brendan Hogan Rappazzo, Yingheng Wang, Aaron Ferber, Carla Gomes

The ability to form, retrieve, and reason about memories in response to
stimuli serves as the cornerstone for general intelligence - shaping entities
capable of learning, adaptation, and intuitive insight. Large Language Models
(LLMs) have proven their ability, given the proper memories or context, to
reason and respond meaningfully to stimuli. However, they are still unable to
optimally encode, store, and retrieve memories - the ability to do this would
unlock their full ability to operate as AI agents, and to specialize to niche
domains. To remedy this, one promising area of research is Retrieval Augmented
Generation (RAG), which aims to augment LLMs by providing them with rich
in-context examples and information. In question-answering (QA) applications,
RAG methods embed the text of interest in chunks, and retrieve the most
relevant chunks for a prompt using text embeddings. Motivated by human memory
encoding and retrieval, we aim to improve over standard RAG methods by
generating and encoding higher-level information and tagging the chunks by
their utility to answer questions. We introduce Graphical Eigen Memories For
Retrieval Augmented Generation (GEM-RAG). GEM-RAG works by tagging each chunk
of text in a given text corpus with LLM generated ``utility'' questions,
connecting chunks in a graph based on the similarity of both their text and
utility questions, and then using the eigendecomposition of the memory graph to
build higher level summary nodes that capture the main themes of the text. We
evaluate GEM-RAG, using both UnifiedQA and GPT-3.5 Turbo as the LLMs, with
SBERT, and OpenAI's text encoders on two standard QA tasks, showing that
GEM-RAG outperforms other state-of-the-art RAG methods on these tasks. We also
discuss the implications of having a robust RAG system and future directions.

æè¦ï¼<paragraph>æ ¹æåºæ¿å½¢æãæª¢ç´¢åæ¨çè¨æ¶çè½åæ¯éç¨æºæ§çåºç³ï¼å¡é äºå·åå­¸ç¿ãé©æåç´è¦ºæ´å¯åçå¯¦é«ãå¤§åèªè¨æ¨¡å (LLM) å·²è­æå¶è½åï¼å¨é©ç¶çè¨æ¶æèæ¯ä¸ï¼å°åºæ¿é²è¡æ¨çåææç¾©å°åæãç¶èï¼å®åä»ç¶ç¡æ³æä½³å°ç·¨ç¢¼ãå²å­åæª¢ç´¢è¨æ¶ï¼å·è¡æ­¤æä½çè½åå°è§£éå®åä½çº AI ä»£çéä½ä¸¦å°éåçºå©åºé åçå¨é¨è½åãçºäºè£ææ­¤åé¡ï¼ä¸åæåæ¯çç ç©¶é åæ¯æª¢ç´¢å¢å¼·çæ (RAG)ï¼å¶ç®æ¨æ¯ééæä¾è±å¯çä¸ä¸æç¯ä¾åè³è¨ä¾æ´å LLMãå¨åç­ (QA) æç¨ç¨å¼ä¸­ï¼RAG æ¹æ³å°æèè¶£çæå­åå¡åµå¥ï¼ä¸¦ä½¿ç¨æå­åµå¥çºæç¤ºæª¢ç´¢æç¸éçåå¡ãåäººé¡è¨æ¶ç·¨ç¢¼åæª¢ç´¢çåç¼ï¼æåæ¨å¨ééç¢çåç·¨ç¢¼æ´é«ç´å¥çè³è¨ä¸¦æ ¹æåå¡åç­åé¡çæç¨æ¨è¨åå¡ï¼å¾èæ¹é²æ¨æº RAG æ¹æ³ãæåå¼å¥äºç¨æ¼æª¢ç´¢å¢å¼·çæçåå½¢ç¹å¾µè¨æ¶ (GEM-RAG)ãGEM-RAG çå·¥ä½åçæ¯ä½¿ç¨ LLM çæçãæç¨ãåé¡æ¨è¨çµ¦å®æå­èªæåº«ä¸­æ¯åæå­åå¡ï¼æ ¹ææå­åæç¨åé¡çç¸ä¼¼æ§å°åå¡é£æ¥å¨åå½¢ä¸­ï¼ç¶å¾ä½¿ç¨è¨æ¶åå½¢çç¹å¾µåè§£ä¾å»ºç«æ·åæå­ä¸»é¡çé«éæè¦ç¯é»ãæåä½¿ç¨ UnifiedQA å GPT-3.5 Turbo ä½çº LLMï¼ä»¥å SBERT å OpenAI çæå­ç·¨ç¢¼å¨ï¼å¨å©åæ¨æº QA ä»»åä¸­è©ä¼° GEM-RAGï¼é¡¯ç¤º GEM-RAG å¨éäºä»»åä¸­åªæ¼å¶ä»æåé²ç RAG æ¹æ³ãæåéè¨è«äºææå¼·å¤§ç RAG ç³»çµ±çå«æåæªä¾çæ¹åã</paragraph>

##### **KARMA: Augmenting Embodied AI Agents with Long-and-short Term Memory Systems**
2409.14908v1 by Zixuan Wang, Bo Yu, Junzhe Zhao, Wenhao Sun, Sai Hou, Shuai Liang, Xing Hu, Yinhe Han, Yiming Gan

Embodied AI agents responsible for executing interconnected, long-sequence
household tasks often face difficulties with in-context memory, leading to
inefficiencies and errors in task execution. To address this issue, we
introduce KARMA, an innovative memory system that integrates long-term and
short-term memory modules, enhancing large language models (LLMs) for planning
in embodied agents through memory-augmented prompting. KARMA distinguishes
between long-term and short-term memory, with long-term memory capturing
comprehensive 3D scene graphs as representations of the environment, while
short-term memory dynamically records changes in objects' positions and states.
This dual-memory structure allows agents to retrieve relevant past scene
experiences, thereby improving the accuracy and efficiency of task planning.
Short-term memory employs strategies for effective and adaptive memory
replacement, ensuring the retention of critical information while discarding
less pertinent data. Compared to state-of-the-art embodied agents enhanced with
memory, our memory-augmented embodied AI agent improves success rates by 1.3x
and 2.3x in Composite Tasks and Complex Tasks within the AI2-THOR simulator,
respectively, and enhances task execution efficiency by 3.4x and 62.7x.
Furthermore, we demonstrate that KARMA's plug-and-play capability allows for
seamless deployment on real-world robotic systems, such as mobile manipulation
platforms.Through this plug-and-play memory system, KARMA significantly
enhances the ability of embodied agents to generate coherent and contextually
appropriate plans, making the execution of complex household tasks more
efficient. The experimental videos from the work can be found at
https://youtu.be/4BT7fnw9ehs.

æè¦ï¼è² è²¬å·è¡ç¸äºé£æ¥çé·åºåå®¶åº­ä»»åçå·èº«å AI ä»£çç¶å¸¸é¢è¨æå¢è¨æ¶çå°é£ï¼å°è´ä»»åå·è¡æçä½ä¸åé¯èª¤ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äº KARMAï¼éæ¯ä¸ååµæ°çè¨æ¶ç³»çµ±ï¼å®æ´åäºé·æåç­æè¨æ¶æ¨¡çµï¼ééè¨æ¶å¢å¼·æç¤ºï¼å¢å¼·å·èº«åä»£çä¸­ç¨æ¼è¦åçå¤§èªè¨æ¨¡å (LLM)ãKARMA ååé·æåç­æè¨æ¶ï¼é·æè¨æ¶æ·åå¨é¢ç 3D å ´æ¯åå½¢ä½çºç°å¢çè¡¨ç¤ºï¼èç­æè¨æ¶ååæè¨éç©ä»¶ä½ç½®åçæçè®åãéç¨®ééè¨æ¶çµæ§åè¨±ä»£çæ·åç¸éçéå»å ´æ¯ç¶é©ï¼å¾èæé«ä»»åè¦åçæºç¢ºæ§åæçãç­æè¨æ¶æ¡ç¨ç­ç¥ä¾é²è¡ææåé©ææ§çè¨æ¶æ¿æï¼ç¢ºä¿ä¿çééµè³è¨ï¼åææ¨æ£è¼ä¸ç¸éçè³æãèå·åå¢å¼·è¨æ¶åè½çææ°å·èº«åä»£çç¸æ¯ï¼æåçè¨æ¶å¢å¼·å·èº«å AI ä»£çå¨ AI2-THOR æ¨¡æ¬å¨ä¸­çè¤åä»»ååè¤éä»»åä¸­ï¼åå¥å°æåçæé«äº 1.3 åå 2.3 åï¼ä¸¦å°ä»»åå·è¡æçæé«äº 3.4 åå 62.7 åãæ­¤å¤ï¼æåè­æäº KARMA çå³æå³ç¨åè½åè¨±å¨çå¯¦ä¸ççæ©å¨äººç³»çµ±ä¸é²è¡ç¡ç¸«é¨ç½²ï¼ä¾å¦è¡åæä½å¹³å°ãéééåå³æå³ç¨è¨æ¶ç³»çµ±ï¼KARMA å¤§å¹å¢å¼·äºå·èº«åä»£çç¢çä¸è´ä¸ç¬¦åæå¢çè¨ç«çè½åï¼ä½¿è¤éå®¶åº­ä»»åçå·è¡æ´ææçãéé å·¥ä½çå¯¦é©å½±çå¯ä»¥å¨ https://youtu.be/4BT7fnw9ehs æ¾å°ã

##### **End-to-End Graph Flattening Method for Large Language Models**
2409.14880v1 by Bin Hong, Jinze Wu, Jiayu Liu, Liang Ding, Jing Sha, Kai Zhang, Shijin Wang, Zhenya Huang

In recent years, the breakthrough of Large Language Models (LLMs) offers new
ideas for achieving universal methods on graph data. The common practice of
converting graphs into natural language for LLMs, which refers to graph
flattening, exhibits good generalizability and interpretability. However, the
poor organization of the textual format results in poor performance in
long-distance scenario understanding. Inspired by human cognitive reasoning
habits, we propose a novel method for graph flattening to fit LLMs, termed as
End-to-End DAG-Path prompting (EEDP). Experiments on real-world datasets show
that EEDP enhances the reasoning performance of LLMs in long-distance scenarios
while maintaining excellent performance in short-distance scenarios,
demonstrating good robustness in the face of distance variations.

æè¦ï¼è¿å¹´ä¾ï¼å¤§åèªè¨æ¨¡å (LLM) ççªç ´çºå¨åå½¢è³æä¸­éæéç¨æ¹æ³æä¾äºæ°æ³æ³ãå°åå½¢è½æçºèªç¶èªè¨ä»¥ä¾ LLM ä½¿ç¨çå¸¸è¦åæ³ï¼å³åå½¢æå¹³åï¼å±ç¾åºè¯å¥½çéç¨æ§åå¯è§£éæ§ãç¶èï¼ææ¬æ ¼å¼çµç¹ä¸ä½³å°è´å¨é·è·é¢å ´æ¯çè§£ä¸­è¡¨ç¾ä¸ä½³ãåå°äººé¡èªç¥æ¨çç¿æ£çåç¼ï¼æåæåºäºä¸ç¨®æ°ç©çæ¹æ³ä¾é²è¡åå½¢æå¹³åä»¥éå LLMï¼ç¨±çºç«¯å°ç«¯ DAG è·¯å¾æç¤º (EEDP)ãå¨çå¯¦ä¸çè³æéä¸çå¯¦é©è¡¨æï¼EEDP å¢å¼·äº LLM å¨é·è·é¢å ´æ¯ä¸­çæ¨çæ§è½ï¼åæå¨ç­è·é¢å ´æ¯ä¸­ä¿æäºåºè²çæ§è½ï¼å¨é¢å°è·é¢è®åæè¡¨ç¾åºè¯å¥½çé­¯æ£æ§ã

##### **RACOON: An LLM-based Framework for Retrieval-Augmented Column Type Annotation with a Knowledge Graph**
2409.14556v1 by Linxi Wei, Guorui Xiao, Magdalena Balazinska

As an important component of data exploration and integration, Column Type
Annotation (CTA) aims to label columns of a table with one or more semantic
types. With the recent development of Large Language Models (LLMs), researchers
have started to explore the possibility of using LLMs for CTA, leveraging their
strong zero-shot capabilities. In this paper, we build on this promising work
and improve on LLM-based methods for CTA by showing how to use a Knowledge
Graph (KG) to augment the context information provided to the LLM. Our
approach, called RACOON, combines both pre-trained parametric and
non-parametric knowledge during generation to improve LLMs' performance on CTA.
Our experiments show that RACOON achieves up to a 0.21 micro F-1 improvement
compared against vanilla LLM inference.

æè¦ï¼ä½çºè³ææ¢åèæ´åçéè¦çµæé¨åï¼æ¬ä½é¡åè¨»è§£ (CTA) çç®æ¨æ¯ä½¿ç¨ä¸åæå¤åèªæé¡åæ¨è¨è¡¨æ ¼æ¬ä½ãé¨èå¤§åèªè¨æ¨¡å (LLM) çè¿æç¼å±ï¼ç ç©¶äººå¡å·²éå§æ¢è¨ä½¿ç¨ LLM ä¾é²è¡ CTA çå¯è½æ§ï¼ä¸¦å©ç¨å¶å¼·å¤§çé¶æ¬¡å­¸ç¿è½åãå¨æ¬æä¸­ï¼æåå»ºç«å¨éåæåæ¯çç ç©¶ä¸ï¼ä¸¦ééå±ç¤ºå¦ä½ä½¿ç¨ç¥è­åè­ (KG) ä¾æ´åæä¾çµ¦ LLM çèçµ¡è³è¨ï¼é²èæ¹ååºæ¼ LLM ç CTA æ¹æ³ãæåçæ¹æ³ç¨±çº RACOONï¼å®å¨çæéç¨ä¸­çµåé åè¨ç·´çåæ¸å¼åéåæ¸å¼ç¥è­ï¼ä»¥æ¹å LLM å¨ CTA ä¸çæè½ãæåçå¯¦é©é¡¯ç¤ºï¼èç´ç²¹ç LLM æ¨è«ç¸æ¯ï¼RACOON å¨å¾®å F-1 ä¸çé²æ­¥é«é 0.21ã

##### **SAC-KG: Exploiting Large Language Models as Skilled Automatic Constructors for Domain Knowledge Graphs**
2410.02811v1 by Hanzhu Chen, Xu Shen, Qitan Lv, Jie Wang, Xiaoqi Ni, Jieping Ye

Knowledge graphs (KGs) play a pivotal role in knowledge-intensive tasks
across specialized domains, where the acquisition of precise and dependable
knowledge is crucial. However, existing KG construction methods heavily rely on
human intervention to attain qualified KGs, which severely hinders the
practical applicability in real-world scenarios. To address this challenge, we
propose a general KG construction framework, named SAC-KG, to exploit large
language models (LLMs) as Skilled Automatic Constructors for domain Knowledge
Graph. SAC-KG effectively involves LLMs as domain experts to generate
specialized and precise multi-level KGs. Specifically, SAC-KG consists of three
components: Generator, Verifier, and Pruner. For a given entity, Generator
produces its relations and tails from raw domain corpora, to construct a
specialized single-level KG. Verifier and Pruner then work together to ensure
precision by correcting generation errors and determining whether newly
produced tails require further iteration for the next-level KG.Experiments
demonstrate that SAC-KG automatically constructs a domain KG at the scale of
over one million nodes and achieves a precision of 89.32%, leading to a
superior performance with over 20% increase in precision rate compared to
existing state-of-the-art methods for the KG construction task.

æè¦ï¼ç¥è­åè­ (KG) å¨å°æ¥­é åä¸­æ®æ¼èééµè§è²ï¼å¨éäºé åä¸­ï¼åå¾ç²¾ç¢ºä¸å¯é çç¥è­è³ééè¦ãç¶èï¼ç¾æç KG å»ºæ§æ¹æ³å´éä¾è³´äººå·¥ä»å¥æè½ç²å¾åæ ¼ç KGï¼éå´éé»ç¤äºå¨å¯¦éå ´æ¯ä¸­çå¯¦ç¨æ§ãçºäºæå°éé ææ°ï¼æåæåºäºä¸åéç¨ç KG å»ºæ§æ¶æ§ï¼åçº SAC-KGï¼ä»¥å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä½çºå°æ¥­çèªåå»ºæ§å¨ï¼ç¨æ¼é åç¥è­åè­ãSAC-KG ææå°å° LLM è¦çºé åå°å®¶ï¼ä»¥ç¢çå°æ¥­ä¸ç²¾ç¢ºçå¤å±¤ç´ KGãå·é«ä¾èªªï¼SAC-KG åå«ä¸åçµæé¨åï¼çæå¨ãé©è­å¨åä¿®åªå¨ãå°æ¼çµ¦å®çå¯¦é«ï¼çæå¨æå¾åå§é åèªæåº«ä¸­ç¢çå¶éä¿åå°¾é¨ï¼ä»¥å»ºæ§å°æ¥­çå®å±¤ç´ KGãç¶å¾ï¼é©è­å¨åä¿®åªå¨æå±åç¢ºä¿ç²¾ç¢ºæ§ï¼æ¹æ³æ¯æ´æ­£ç¢çé¯èª¤ä¸¦ç¢ºå®æ°ç¢ççå°¾é¨æ¯å¦éè¦é²ä¸æ­¥è¿­ä»£ä»¥ç¨æ¼ä¸ä¸å±¤ç´ç KGãå¯¦é©è­æï¼SAC-KG èªåå»ºæ§äºä¸åè¦æ¨¡è¶éä¸ç¾è¬åç¯é»çé å KGï¼ä¸¦éå°äº 89.32% çç²¾ç¢ºåº¦ï¼èç¾æç KG å»ºæ§ä»»åçææ°æ¹æ³ç¸æ¯ï¼ç²¾ç¢ºåº¦æé«äº 20% ä»¥ä¸ï¼è¡¨ç¾åªç°ã

##### **Graph Neural Network Framework for Sentiment Analysis Using Syntactic Feature**
2409.14000v1 by Linxiao Wu, Yuanshuai Luo, Binrong Zhu, Guiran Liu, Rui Wang, Qian Yu

Amidst the swift evolution of social media platforms and e-commerce
ecosystems, the domain of opinion mining has surged as a pivotal area of
exploration within natural language processing. A specialized segment within
this field focuses on extracting nuanced evaluations tied to particular
elements within textual contexts. This research advances a composite framework
that amalgamates the positional cues of topical descriptors. The proposed
system converts syntactic structures into a matrix format, leveraging
convolutions and attention mechanisms within a graph to distill salient
characteristics. Incorporating the positional relevance of descriptors relative
to lexical items enhances the sequential integrity of the input. Trials have
substantiated that this integrated graph-centric scheme markedly elevates the
efficacy of evaluative categorization, showcasing preeminence.

æè¦ï¼é¨èç¤¾ç¾¤åªé«å¹³å°åé»å­ååçæç³»çµ±çå¿«éæ¼é²ï¼æè¦æ¢åé åå·²æçºèªç¶èªè¨èçä¸­ä¸é ééµçæ¢ç´¢é åãæ­¤é åä¸­çå°éåå¡èéæ¼å¾æå­èçµ¡ä¸­çç¹å®åç´ ä¸­èååºç´°å¾®çè©å¹ãæ¬ç ç©¶æåºä¸åè¤åæ¶æ§ï¼å°ä¸»é¡æè¿°è©çä½ç½®ç·ç´¢åä½µå¨ä¸èµ·ãææåºçç³»çµ±å°å¥æ³çµæ§è½ææç©é£æ ¼å¼ï¼ä¸¦å¨åå½¢ä¸­éç¨å·ç©åæ³¨æåæ©å¶ä¾èååºé¡¯èç¹å¾µãç´å¥æè¿°è©ç¸å°æ¼è©å½é ç®çä½ç½®ç¸éæ§ï¼å¯å¼·åè¼¸å¥çé åºå®æ´æ§ãè©¦é©è­å¯¦ï¼éç¨®æ´ååå½¢çºä¸­å¿çæ¶æ§é¡¯èæåäºè©ä¼°åé¡çæè½ï¼å±ç¾åºåè¶æ§ã

##### **ShizishanGPT: An Agricultural Large Language Model Integrating Tools and Resources**
2409.13537v1 by Shuting Yang, Zehui Liu, Wolfgang Mayer

Recent developments in large language models (LLMs) have led to significant
improvements in intelligent dialogue systems'ability to handle complex
inquiries. However, current LLMs still exhibit limitations in specialized
domain knowledge, particularly in technical fields such as agriculture. To
address this problem, we propose ShizishanGPT, an intelligent question
answering system for agriculture based on the Retrieval Augmented Generation
(RAG) framework and agent architecture. ShizishanGPT consists of five key
modules: including a generic GPT-4 based module for answering general
questions; a search engine module that compensates for the problem that the
large language model's own knowledge cannot be updated in a timely manner; an
agricultural knowledge graph module for providing domain facts; a retrieval
module which uses RAG to supplement domain knowledge; and an agricultural agent
module, which invokes specialized models for crop phenotype prediction, gene
expression analysis, and so on. We evaluated the ShizishanGPT using a dataset
containing 100 agricultural questions specially designed for this study. The
experimental results show that the tool significantly outperforms general LLMs
as it provides more accurate and detailed answers due to its modular design and
integration of different domain knowledge sources. Our source code, dataset,
and model weights are publicly available at https://github.com/Zaiwen/CropGPT.

æè¦ï¼è¿ä¾å¤§åèªè¨æ¨¡åï¼LLMï¼çç¼å±ï¼å¤§å¹æåäºæºæ§å°è©±ç³»çµ±èçè¤éè©¢åçè½åãç¶èï¼ç¾æç LLM ä»å±ç¾åºå¨å°æ¥­é åç¥è­çéå¶ï¼ç¹å¥æ¯å¨è¾²æ¥­ç­æè¡é åãçºäºè§£æ±ºéååé¡ï¼æåæåº ShizishanGPTï¼ä¸ååºæ¼æª¢ç´¢æ´åçæï¼RAGï¼æ¶æ§åä»£çæ¶æ§çè¾²æ¥­æºæ§åç­ç³»çµ±ãShizishanGPT åå«äºåééµæ¨¡çµï¼åå«ä¸åç¨æ¼åç­ä¸è¬åé¡çéç¨ GPT-4 åºç¤æ¨¡çµï¼ä¸åæå°å¼ææ¨¡çµï¼ç¨æ¼å½è£å¤§åèªè¨æ¨¡åæ¬èº«çç¥è­ç¡æ³åææ´æ°çåé¡ï¼ä¸åè¾²æ¥­ç¥è­åè­æ¨¡çµï¼ç¨æ¼æä¾é åäºå¯¦ï¼ä¸åä½¿ç¨ RAG ä¾è£åé åç¥è­çæª¢ç´¢æ¨¡çµï¼ä»¥åä¸åè¾²æ¥­ä»£çæ¨¡çµï¼ç¨æ¼å¼å«ç¨æ¼ä½ç©è¡¨åé æ¸¬ãåºå è¡¨ç¾åæç­çå°æ¥­æ¨¡åãæåä½¿ç¨ä¸åç¹å¥çºéé ç ç©¶è¨­è¨çï¼åå« 100 åè¾²æ¥­åé¡çè³æéä¾è©ä¼° ShizishanGPTãå¯¦é©çµæé¡¯ç¤ºï¼ç±æ¼å¶æ¨¡çµåè¨­è¨åæ´åäºä¸åçé åç¥è­ä¾æºï¼æ­¤å·¥å·é¡¯èåªæ¼ä¸è¬ç LLMï¼å çºå®æä¾äºæ´æºç¢ºä¸è©³ç´°çç­æ¡ãæåçåå§ç¢¼ãè³æéåæ¨¡åæ¬éå·²å¬éæ¼ https://github.com/Zaiwen/CropGPTã

##### **LM-assisted keyword biasing with Aho-Corasick algorithm for Transducer-based ASR**
2409.13514v1 by Iuliia Thorbecke, Juan Zuluaga-Gomez, EsaÃº Villatoro-Tello, Andres Carofilis, Shashi Kumar, Petr Motlicek, Karthik Pandia, Aravind Ganapathiraju

Despite the recent success of end-to-end models for automatic speech
recognition, recognizing special rare and out-of-vocabulary words, as well as
fast domain adaptation with text, are still challenging. It often happens that
biasing to the special entities leads to a degradation in the overall
performance. We propose a light on-the-fly method to improve automatic speech
recognition performance by combining a bias list of named entities with a
word-level n-gram language model with the shallow fusion approach based on the
Aho-Corasick string matching algorithm. The Aho-Corasick algorithm has proved
to be more efficient than other methods and allows fast context adaptation. An
n-gram language model is introduced as a graph with fail and output arcs, where
the arc weights are adapted from the n-gram probabilities. The language model
is used as an additional support to keyword biasing when the language model is
combined with bias entities in a single context graph to take care of the
overall performance. We demonstrate our findings on 4 languages, 2 public and 1
private datasets including performance on named entities and out-of-vocabulary
entities. We achieve up to 21.6% relative improvement in the general word error
rate with no practical difference in the inverse real-time factor.

æè¦ï¼åç®¡ç«¯å°ç«¯æ¨¡åå¨èªåèªé³è¾¨è­ä¸ç²å¾è¿ææåï¼è¾¨è­ç¹æ®ç½è¦ä¸ä¸å¨è©å½è¡¨ä¸­çå­è©ï¼ä»¥åééæå­é²è¡å¿«éé åé©æï¼ä»å·æææ°æ§ãååç¹æ®å¯¦é«ç¶å¸¸å°è´æ´é«æè½éä½ãæåæåºä¸åå³æè¼éæ¹æ³ï¼ééå°å½åå¯¦é«çåå·®æ¸å®ï¼èåºæ¼ Aho-Corasick å­ä¸²éå°æ¼ç®æ³çæ·ºå±¤èåæ¹æ³ï¼çµåå­åç­ç´ n-gram èªè¨æ¨¡åï¼ä¾æ¹åèªåèªé³è¾¨è­æè½ãAho-Corasick æ¼ç®æ³å·²è¢«è­ææ¯å¶ä»æ¹æ³æ´ææçï¼ä¸¦åè¨±å¿«éèçµ¡é©æãn-gram èªè¨æ¨¡åè¢«å¼å¥çºå·æå¤±æèè¼¸åºå¼§ç·çåå½¢ï¼å¶ä¸­å¼§ç·æ¬éå¾ n-gram æ©çæ¹ç·¨èä¾ãèªè¨æ¨¡åç¨ä½ééµå­åå·®çé¡å¤æ¯æ´ï¼ç¶èªè¨æ¨¡åèåå·®å¯¦é«çµåå¨å®ä¸èçµ¡åå½¢ä¸­æï¼ç¨æ¼ç§é¡§æ´é«æè½ãæåå¨ 4 ç¨®èªè¨ã2 åå¬éå 1 åç§äººè³æéä¸å±ç¤ºæåçç¼ç¾ï¼åæ¬å½åå¯¦é«åä¸å¨è©å½è¡¨ä¸­çå¯¦é«çæè½ãæåå¨ä¸è¬å­åé¯èª¤çä¸ç²å¾é«é 21.6% çç¸å°æ¹åï¼ä¸å¨ååå³æå å­ä¸­æ²æå¯¦éå·®ç°ã

##### **AQA: Adaptive Question Answering in a Society of LLMs via Contextual Multi-Armed Bandit**
2409.13447v2 by Mohanna Hoveyda, Arjen P. de Vries, Maarten de Rijke, Harrie Oosterhuis, Faegheh Hasibi

In question answering (QA), different questions can be effectively addressed
with different answering strategies. Some require a simple lookup, while others
need complex, multi-step reasoning to be answered adequately. This observation
motivates the development of a dynamic method that adaptively selects the most
suitable QA strategy for each question, enabling more efficient and effective
systems capable of addressing a broader range of question types. To this aim,
we build on recent advances in the orchestration of multiple large language
models (LLMs) and formulate adaptive QA as a dynamic orchestration challenge.
We define this as a contextual multi-armed bandit problem, where the context is
defined by the characteristics of the incoming question and the action space
consists of potential communication graph configurations among the LLM agents.
We then train a linear upper confidence bound model to learn an optimal mapping
between different question types and their corresponding optimal multi-LLM
communication graph representation. Our experiments show that the proposed
solution is viable for adaptive orchestration of a QA system with multiple
modules, as it combines the superior performance of more complex strategies
while avoiding their costs when simpler strategies suffice.

æè¦ï¼å¨åç­ (QA) ä¸­ï¼ä¸åçåé¡å¯ä»¥ç¨ä¸åçåç­ç­ç¥ææå°è§£æ±ºãæäºåé¡åªéè¦ç°¡å®çæ¥è©¢ï¼èå¦ä¸äºåé¡åéè¦è¤éçå¤æ­¥é©æ¨çæè½å¾å°ååçåç­ãéåè§å¯ä¿ä½¿éç¼ä¸ç¨®åææ¹æ³ï¼è½é©ææ§å°çºæ¯ååé¡é¸ææåé©ç QA ç­ç¥ï¼å¾èå¯¦ç¾æ´é«æä¸ææçç³»çµ±ï¼è½è§£æ±ºæ´å»£æ³çé¡ååé¡ãçºæ­¤ï¼æåå»ºç«å¨å¤åå¤§åèªè¨æ¨¡å (LLM) ç·¨æçææ°é²å±ä¹ä¸ï¼ä¸¦å°é©ææ§ QA å¶å®çºä¸ååæç·¨æææ°ãæåå°å¶å®ç¾©çºä¸åæå¢å¤éé¸æåé¡ï¼å¶ä¸­æå¢ç±è¼¸å¥åé¡çç¹å¾µå®ç¾©ï¼èåä½ç©ºéç± LLM ä»£çä¹éçæ½å¨éä¿¡åå½¢éç½®çµæãç¶å¾ï¼æåè¨ç·´ä¸åç·æ§ä¸éç½®ä¿¡çæ¨¡åï¼ä»¥å­¸ç¿ä¸ååé¡é¡ååå¶å°æçæä½³å¤ LLM éä¿¡åå½¢è¡¨ç¤ºä¹éçæä½³æ å°ãæåçå¯¦é©è¡¨æï¼ææåºçè§£æ±ºæ¹æ¡é©ç¨æ¼å·æå¤åæ¨¡çµç QA ç³»çµ±çé©ææ§ç·¨æï¼å çºå®çµåäºæ´è¤éç­ç¥çåªè¶æè½ï¼åæå¨è¼ç°¡å®çç­ç¥è¶³å¤ æé¿åäºå¶ææ¬ã

##### **GAProtoNet: A Multi-head Graph Attention-based Prototypical Network for Interpretable Text Classification**
2409.13312v1 by Ximing Wen, Wenjuan Tan, Rosina O. Weber

Pretrained transformer-based Language Models (LMs) are well-known for their
ability to achieve significant improvement on text classification tasks with
their powerful word embeddings, but their black-box nature, which leads to a
lack of interpretability, has been a major concern. In this work, we introduce
GAProtoNet, a novel white-box Multi-head Graph Attention-based Prototypical
Network designed to explain the decisions of text classification models built
with LM encoders. In our approach, the input vector and prototypes are regarded
as nodes within a graph, and we utilize multi-head graph attention to
selectively construct edges between the input node and prototype nodes to learn
an interpretable prototypical representation. During inference, the model makes
decisions based on a linear combination of activated prototypes weighted by the
attention score assigned for each prototype, allowing its choices to be
transparently explained by the attention weights and the prototypes projected
into the closest matching training examples. Experiments on multiple public
datasets show our approach achieves superior results without sacrificing the
accuracy of the original black-box LMs. We also compare with four alternative
prototypical network variations and our approach achieves the best accuracy and
F1 among all. Our case study and visualization of prototype clusters also
demonstrate the efficiency in explaining the decisions of black-box models
built with LMs.

æè¦ï¼é è¨ç·´ç Transformer åºæ¼èªè¨æ¨¡å (LM) ä»¥å¶å¼·å¤§çè©åµå¥åè½èèåï¼è½å¤ å¨ææ¬åé¡ä»»åä¸­ç²å¾é¡¯èçæ¹é²ï¼ä½å¶é»çæ§è³ªå°è´ç¼ºä¹å¯è§£éæ§ï¼ä¸ç´æ¯ä¸åä¸»è¦åé¡ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äº GAProtoNetï¼éæ¯ä¸åæ°ç©çç½çå¤é ­åæ³¨æåååç¶²è·¯ï¼æ¨å¨è§£éä½¿ç¨ LM ç·¨ç¢¼å¨å»ºç«çææ¬åé¡æ¨¡åçæ±ºç­ãå¨æåçåæ³ä¸­ï¼è¼¸å¥åéåååè¢«è¦çºåå½¢ä¸­çç¯é»ï¼æåå©ç¨å¤é ­åæ³¨æåå¨è¼¸å¥ç¯é»åååç¯é»ä¹éæé¸æå°æ§é éç·£ï¼ä»¥å­¸ç¿å¯è§£éçååè¡¨ç¤ºãå¨æ¨çéç¨ä¸­ï¼æ¨¡åæ ¹ææ¿æ´»ååçç·æ§çµåååºæ±ºç­ï¼è©²çµåç±åéçµ¦æ¯åååçæ³¨æååæ¸å æ¬ï¼å¾èåè¨±ééæ³¨æåæ¬éåæå½±å°ææ¥è¿å¹éè¨ç·´ç¯ä¾çååä¾éæå°è§£éå¶é¸æãå¨å¤åå¬å±è³æéä¸çå¯¦é©è¡¨æï¼æåçåæ³å¨ä¸ç§ç²åå§é»ç LM çæºç¢ºæ§çææ³ä¸ï¼åå¾äºåªç°ççµæãæåéèåç¨®æ¿ä»£ååç¶²è·¯è®é«é²è¡äºæ¯è¼ï¼æåçåæ³å¨ææè®é«ä¸­åå¾äºæä½³çæºç¢ºæ§å F1ãæåçæ¡ä¾ç ç©¶åååç¾¤éçå¯è¦åä¹è­æäºä½¿ç¨ LM å»ºç«çé»çæ¨¡åæ±ºç­çè§£éæçã

##### **Leveraging Knowledge Graphs and LLMs to Support and Monitor Legislative Systems**
2409.13252v1 by Andrea Colombo

Knowledge Graphs (KGs) have been used to organize large datasets into
structured, interconnected information, enhancing data analytics across various
fields. In the legislative context, one potential natural application of KGs is
modeling the intricate set of interconnections that link laws and their
articles with each other and the broader legislative context.
  At the same time, the rise of large language models (LLMs) such as GPT has
opened new opportunities in legal applications, such as text generation and
document drafting. Despite their potential, the use of LLMs in legislative
contexts is critical since it requires the absence of hallucinations and
reliance on up-to-date information, as new laws are published on a daily basis.
  This work investigates how Legislative Knowledge Graphs and LLMs can
synergize and support legislative processes. We address three key questions:
the benefits of using KGs for legislative systems, how LLM can support
legislative activities by ensuring an accurate output, and how we can allow
non-technical users to use such technologies in their activities. To this aim,
we develop Legis AI Platform, an interactive platform focused on Italian
legislation that enhances the possibility of conducting legislative analysis
and that aims to support lawmaking activities.

æè¦ï¼ç¥è­åè­ (KG) å·²è¢«ç¨æ¼å°å¤§åè³æéæ´çæçµæ§åãç¸äºéè¯çè³è¨ï¼ä»¥å¢å¼·åç¨®é åçè³æåæãå¨ç«æ³èæ¯ä¸ï¼KG çä¸åæ½å¨èªç¶æç¨æ¯å»ºæ¨¡é£çµæ³å¾åå¶æ¢æå½¼æ­¤ä¹éä»¥åæ´å»£æ³ç«æ³èæ¯çè¤éç¸äºé£çµéã
èæ­¤åæï¼å¤§åèªè¨æ¨¡å (LLM)ï¼ä¾å¦ GPTï¼çèèµ·çºæ³å¾æç¨éé¢äºæ°çæ©æï¼ä¾å¦æå­ç¢çåæä»¶èµ·èãåç®¡æå¶æ½åï¼å¨ç«æ³èæ¯ä¸ä½¿ç¨ LLM è³ééè¦ï¼å çºå®éè¦æ²æå¹»è¦ºä¸¦ä¸ä¾è³´æ¼ææ°çè³è¨ï¼å çºæ¯å¤©é½æå¬ä½æ°çæ³å¾ã
éé å·¥ä½æ¢è¨äºç«æ³ç¥è­åè­å LLM å¦ä½ç¢çååææä¸¦æ¯æ´ç«æ³ç¨åºãæåæ¢è¨äºä¸åééµåé¡ï¼ä½¿ç¨ KG å°ç«æ³ç³»çµ±çå¥½èãLLM å¦ä½ééç¢ºä¿æºç¢ºçè¼¸åºæ¯æ´ç«æ³æ´»åï¼ä»¥åæåå¦ä½è®éæè¡ä½¿ç¨èå¨ä»åçæ´»åä¸­ä½¿ç¨éäºæè¡ãçºæ­¤ï¼æåéç¼äº Legis AI Platformï¼éæ¯ä¸åå°æ³¨æ¼ç¾©å¤§å©ç«æ³çäºåå¼å¹³å°ï¼å¯å¢å¼·é²è¡ç«æ³åæçå¯è½æ§ï¼ä¸¦æ¨å¨æ¯æ´ç«æ³æ´»åã

##### **Enhancing Unsupervised Sentence Embeddings via Knowledge-Driven Data Augmentation and Gaussian-Decayed Contrastive Learning**
2409.12887v2 by Peichao Lai, Zhengfeng Zhang, Wentao Zhang, Fangcheng Fu, Bin Cui

Recently, using large language models (LLMs) for data augmentation has led to
considerable improvements in unsupervised sentence embedding models. However,
existing methods encounter two primary challenges: limited data diversity and
high data noise. Current approaches often neglect fine-grained knowledge, such
as entities and quantities, leading to insufficient diversity. Additionally,
unsupervised data frequently lacks discriminative information, and the
generated synthetic samples may introduce noise. In this paper, we propose a
pipeline-based data augmentation method via LLMs and introduce the
Gaussian-decayed gradient-assisted Contrastive Sentence Embedding (GCSE) model
to enhance unsupervised sentence embeddings. To tackle the issue of low data
diversity, our pipeline utilizes knowledge graphs (KGs) to extract entities and
quantities, enabling LLMs to generate more diverse, knowledge-enriched samples.
To address high data noise, the GCSE model uses a Gaussian-decayed function to
limit the impact of false hard negative samples, enhancing the model's
discriminative capability. Experimental results show that our approach achieves
state-of-the-art performance in semantic textual similarity (STS) tasks, using
fewer data samples and smaller LLMs, demonstrating its efficiency and
robustness across various models.

æè¦ï¼<paragraph>æè¿ï¼ä½¿ç¨å¤§åè¯­è¨æ¨¡å (LLM) è¿è¡æ°æ®æ©åå·²å¯¼è´æ çç£å¥å­åµå¥æ¨¡åå¤§å¹æ¹åãç¶èï¼ç°ææ¹æ³ä¼éå°ä¸¤ä¸ªä¸»è¦ææï¼æ°æ®å¤æ ·æ§æéåæ°æ®åªé³é«ãå½åæ¹æ³éå¸¸å¿½ç¥ç»ç²åº¦ç¥è¯ï¼ä¾å¦å®ä½åæ°éï¼å¯¼è´å¤æ ·æ§ä¸è¶³ãæ­¤å¤ï¼æ çç£æ°æ®ç»å¸¸ç¼ºä¹å¤å«ä¿¡æ¯ï¼å¹¶ä¸çæçåææ ·æ¬å¯è½ä¼å¼å¥åªé³ãå¨æ¬æä¸­ï¼æä»¬æåºäºä¸ç§åºäºç®¡éçæ°æ®æ©åæ¹æ³ï¼éè¿ LLMï¼å¹¶å¼å¥äºé«æ¯è¡°åæ¢¯åº¦è¾å©å¯¹æ¯å¥å­åµå¥ (GCSE) æ¨¡åæ¥å¢å¼ºæ çç£å¥å­åµå¥ãä¸ºäºè§£å³æ°æ®å¤æ ·æ§ä½çé®é¢ï¼æä»¬çç®¡éå©ç¨ç¥è¯å¾è°± (KG) æ¥æåå®ä½åæ°éï¼ä½¿ LLM è½å¤çææ´å¤æ ·åãç¥è¯ä¸°å¯çæ ·æ¬ãä¸ºäºè§£å³æ°æ®åªé³é«çé®é¢ï¼GCSE æ¨¡åä½¿ç¨é«æ¯è¡°åå½æ°æ¥éå¶éè¯¯å°é¾è´æ ·æ¬çå½±åï¼ä»èå¢å¼ºæ¨¡åçå¤å«è½åãå®éªç»æè¡¨æï¼æä»¬çæ¹æ³å¨è¯­ä¹ææ¬ç¸ä¼¼æ§ (STS) ä»»å¡ä¸­å®ç°äºæåè¿çæ§è½ï¼ä½¿ç¨è¾å°çæ°æ®æ ·æ¬åè¾å°ç LLMï¼å±ç¤ºäºå¶å¨åç§æ¨¡åä¸­çæçåé²æ£æ§ã</paragraph>

##### **KnowFormer: Revisiting Transformers for Knowledge Graph Reasoning**
2409.12865v1 by Junnan Liu, Qianren Mao, Weifeng Jiang, Jianxin Li

Knowledge graph reasoning plays a vital role in various applications and has
garnered considerable attention. Recently, path-based methods have achieved
impressive performance. However, they may face limitations stemming from
constraints in message-passing neural networks, such as missing paths and
information over-squashing. In this paper, we revisit the application of
transformers for knowledge graph reasoning to address the constraints faced by
path-based methods and propose a novel method KnowFormer.KnowFormer utilizes a
transformer architecture to perform reasoning on knowledge graphs from the
message-passing perspective, rather than reasoning by textual information like
previous pretrained language model based methods. Specifically, we define the
attention computation based on the query prototype of knowledge graph
reasoning, facilitating convenient construction and efficient optimization. To
incorporate structural information into the self-attention mechanism, we
introduce structure-aware modules to calculate query, key, and value
respectively. Additionally, we present an efficient attention computation
method for better scalability. Experimental results demonstrate the superior
performance of KnowFormer compared to prominent baseline methods on both
transductive and inductive benchmarks.

æè¦ï¼ç¥è­åè­æ¨çå¨åç¨®æç¨ä¸­æ®æ¼èè³ééè¦çè§è²ï¼ä¸¦å·²ç²å¾ç¸ç¶å¤§çéæ³¨ãæè¿ï¼åºæ¼è·¯å¾çæ¹æ³å·²åå¾ä»¤äººå°è±¡æ·±å»çè¡¨ç¾ãç¶èï¼å®åå¯è½æé¢è¨æºèªè¨æ¯å³éç¥ç¶ç¶²è·¯ä¸­çéå¶ï¼ä¾å¦è·¯å¾éºå¤±åè³è¨éåº¦å£ç¸®ãå¨æ¬æä¸­ï¼æåéæ°æ¢è¨Transformerå¨ç¥è­åè­æ¨çä¸­çæç¨ï¼ä»¥è§£æ±ºåºæ¼è·¯å¾çæ¹æ³æé¢è¨çéå¶ï¼ä¸¦æåºä¸åæ°ç©çæ¹æ³ KnowFormerãKnowFormer å©ç¨Transformeræ¶æ§å¾è¨æ¯å³éçè§åº¦å°ç¥è­åè­å·è¡æ¨çï¼èä¸æ¯åä¹åçé è¨ç·´èªè¨æ¨¡åæä¾è³´çææ¬è³è¨é£æ¨£é²è¡æ¨çãå·é«ä¾èªªï¼æåæ ¹æç¥è­åè­æ¨ççæ¥è©¢ååå®ç¾©æ³¨æåçéç®ï¼ä¿é²ä¾¿å©çå»ºæ§åææçæä½³åãçºäºå°çµæ§è³è¨ç´å¥èªæ³¨æåæ©å¶ï¼æåå¼å¥çµæ§æç¥æ¨¡çµä¾åå¥è¨ç®æ¥è©¢ãéµåå¼ãæ­¤å¤ï¼æåæåºä¸åææççæ³¨æåéç®æ¹æ³ä»¥ç²å¾æ´å¥½çå¯æ´åæ§ãå¯¦é©çµæè­æï¼KnowFormer å¨è½å°åæ­¸ç´åºæºä¸é½åªæ¼ååºçåºç·æ¹æ³ã

##### **A New Perspective on ADHD Research: Knowledge Graph Construction with LLMs and Network Based Insights**
2409.12853v1 by Hakan T. Otal, Stephen V. Faraone, M. Abdullah Canbaz

Attention-Deficit/Hyperactivity Disorder (ADHD) is a challenging disorder to
study due to its complex symptomatology and diverse contributing factors. To
explore how we can gain deeper insights on this topic, we performed a network
analysis on a comprehensive knowledge graph (KG) of ADHD, constructed by
integrating scientific literature and clinical data with the help of
cutting-edge large language models. The analysis, including k-core techniques,
identified critical nodes and relationships that are central to understanding
the disorder. Building on these findings, we developed a context-aware chatbot
using Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG),
enabling accurate and informed interactions. Our knowledge graph not only
advances the understanding of ADHD but also provides a powerful tool for
research and clinical applications.

æè¦ï¼æ³¨æåç¼ºé·éåç (ADHD) æ¯ä¸ç¨®å·æææ°æ§çç¾çï¼ç±æ¼å¶è¤éçççåå¤æ¨£åçæå ãçºäºæ¢è¨å¦ä½æ·±å¥äºè§£éåä¸»é¡ï¼æåå°ä¸åç±ç§å­¸æç»åè¨åºæ¸ææ´åèæç ADHD å¨é¢ç¥è­åè­ (KG) é²è¡äºç¶²è·¯åæï¼ä¸¦åå©å°ç«¯çèªè¨æ¨¡åãåæï¼åæ¬ k-core æè¡ï¼è­å¥åºå°æ¼çè§£æ­¤ç¾çè³ééè¦çééµç¯é»åéä¿ãæ ¹æéäºç¼ç¾ï¼æåä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) åæª¢ç´¢å¢å¼·çæ (RAG) éç¼äºä¸åå·åæå¢æç¥è½åçèå¤©æ©å¨äººï¼ä»¥å¯¦ç¾æºç¢ºä¸ææ ¹æçäºåãæåçç¥è­åè­ä¸åä¿é²äºå° ADHD ççè§£ï¼éçºç ç©¶åè¨åºæç¨æä¾äºå¼·å¤§çå·¥å·ã

##### **Enhancing Logical Reasoning in Large Language Models through Graph-based Synthetic Data**
2409.12437v1 by Jiaming Zhou, Abbas Ghaddar, Ge Zhang, Liheng Ma, Yaochen Hu, Soumyasundar Pal, Mark Coates, Bin Wang, Yingxue Zhang, Jianye Hao

Despite recent advances in training and prompting strategies for Large
Language Models (LLMs), these models continue to face challenges with complex
logical reasoning tasks that involve long reasoning chains. In this work, we
explore the potential and limitations of using graph-based synthetic reasoning
data as training signals to enhance LLMs' reasoning capabilities. Our extensive
experiments, conducted on two established natural language reasoning tasks --
inductive reasoning and spatial reasoning -- demonstrate that supervised
fine-tuning (SFT) with synthetic graph-based reasoning data effectively
enhances LLMs' reasoning performance without compromising their effectiveness
on other standard evaluation benchmarks.

æè¦ï¼åç®¡å¨å¤§åèªè¨æ¨¡å (LLM) çè¨ç·´åæç¤ºç­ç¥æ¹é¢æè¿æçé²å±ï¼éäºæ¨¡åå¨æ¶åé·æ¨çéçè¤ééè¼¯æ¨çä»»åä¸­ä»é¢è¨ææ°ãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨äºä½¿ç¨åºæ¼åå½¢çåææ¨çæ¸æä½çºè¨ç·´è¨èä»¥å¢å¼· LLM æ¨çè½åçæ½ååéå¶ãæåå¨å©åæ¢å®çèªç¶èªè¨æ¨çä»»åï¼æ­¸ç´æ¨çåç©ºéæ¨çï¼ä¸é²è¡äºå»£æ³çå¯¦é©ï¼è­æäºä½¿ç¨åºæ¼åå½¢çåææ¨çæ¸æé²è¡ç£ç£å¾®èª¿ (SFT) ææå°å¢å¼·äº LLM çæ¨çæ§è½ï¼èä¸ææå®³å¶å¨å¶ä»æ¨æºè©ä¼°åºæºä¸çæè½ã

##### **Textualized Agent-Style Reasoning for Complex Tasks by Multiple Round LLM Generation**
2409.12411v1 by Chen Liang, Zhifan Feng, Zihe Liu, Wenbin Jiang, Jinan Xu, Yufeng Chen, Yong Wang

Chain-of-thought prompting significantly boosts the reasoning ability of
large language models but still faces three issues: hallucination problem,
restricted interpretability, and uncontrollable generation. To address these
challenges, we present AgentCOT, a llm-based autonomous agent framework, which
can solve complex problems in an agent-style manner by multiple round LLM
generation. At each step, AgentCOT selects an action and executes it to yield
an intermediate result with supporting evidence. In addition, we integrate the
step's index into the reasoning process to form a graph structure for complex
inference logic. We introduce two new strategies to enhance the performance of
AgentCOT.We conduct extensive experiments to verify the effectiveness of our
method on six common benchmarks. Results exhibit that our method brings in
substantial improvements over current competitive approaches.

æè¦ï¼éæ¢æèæç¤ºé¡¯èæåå¤§åèªè¨æ¨¡åçæ¨çè½åï¼ä½ä»é¢è¨ä¸ååé¡ï¼å¹»è¦ºåé¡ãåéçå¯è§£éæ§ï¼ä»¥åç¡æ³æ§å¶ççæãçºäºæå°éäºææ°ï¼æåæåºäº AgentCOTï¼ä¸ååºæ¼ llm çèªä¸»ä»£çæ¶æ§ï¼å®å¯ä»¥ééå¤è¼ª LLM çæä»¥ä»£çæ¨£å¼è§£æ±ºè¤éåé¡ãå¨æ¯ä¸æ­¥ä¸­ï¼AgentCOT é¸æä¸ååä½ä¸¦å·è¡å®ï¼ä»¥ç¢çä¸åå·ææ¯æè­æçä¸­éçµæãæ­¤å¤ï¼æåå°æ­¥é©ç´¢å¼æ´åå°æ¨çéç¨ä¸­ï¼ä»¥å½¢æä¸ååå½¢çµæ§ï¼ç¨æ¼è¤éçæ¨çéè¼¯ãæåå¼å¥äºå©ç¨®æ°ç­ç¥ä¾å¢å¼· AgentCOT çæ§è½ãæåé²è¡äºå»£æ³çå¯¦é©ï¼ä»¥é©è­æåçæ¹æ³å¨å­åå¸¸è¦åºæºä¸çæææ§ãçµæè¡¨æï¼æåççæ¹æ³æ¯ç¶åçç«¶ç­æ¹æ³æäºé¡¯èçæ¹é²ã

##### **GUNet: A Graph Convolutional Network United Diffusion Model for Stable and Diversity Pose Generation**
2409.11689v1 by Shuowen Liang, Sisi Li, Qingyun Wang, Cen Zhang, Kaiquan Zhu, Tian Yang

Pose skeleton images are an important reference in pose-controllable image
generation. In order to enrich the source of skeleton images, recent works have
investigated the generation of pose skeletons based on natural language. These
methods are based on GANs. However, it remains challenging to perform diverse,
structurally correct and aesthetically pleasing human pose skeleton generation
with various textual inputs. To address this problem, we propose a framework
with GUNet as the main model, PoseDiffusion. It is the first generative
framework based on a diffusion model and also contains a series of variants
fine-tuned based on a stable diffusion model. PoseDiffusion demonstrates
several desired properties that outperform existing methods. 1) Correct
Skeletons. GUNet, a denoising model of PoseDiffusion, is designed to
incorporate graphical convolutional neural networks. It is able to learn the
spatial relationships of the human skeleton by introducing skeletal information
during the training process. 2) Diversity. We decouple the key points of the
skeleton and characterise them separately, and use cross-attention to introduce
textual conditions. Experimental results show that PoseDiffusion outperforms
existing SoTA algorithms in terms of stability and diversity of text-driven
pose skeleton generation. Qualitative analyses further demonstrate its
superiority for controllable generation in Stable Diffusion.

æè¦ï¼å§¿å¢éª¨æ¶ååæ¯å§¿å¢å¯æ§ååçæä¸­éè¦çåèãçºäºè±å¯éª¨æ¶ååçä¾æºï¼æè¿çç ç©¶èª¿æ¥äºåºæ¼èªç¶èªè¨çå§¿å¢éª¨æ¶çæãéäºæ¹æ³åºæ¼ GANãç¶èï¼è¦å·è¡å¤æ¨£åãçµæ§æ­£ç¢ºä¸ç¾è§çäººé«å§¿å¢éª¨æ¶çæï¼ä¸¦å·æåç¨®ææ¬è¼¸å¥ï¼ä»ç¶å·æææ°æ§ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä»¥ GUNet çºä¸»è¦æ¨¡åçæ¡æ¶ï¼PoseDiffusionãå®æ¯åºæ¼æ´æ£æ¨¡åçç¬¬ä¸åçææ¡æ¶ï¼éåå«ä¸ç³»ååºæ¼ç©©å®æ´æ£æ¨¡åé²è¡å¾®èª¿çè®é«ãPoseDiffusion å±ç¤ºäºå¤é åªæ¼ç¾ææ¹æ³ççæ³å±¬æ§ã1) æ­£ç¢ºçéª¨æ¶ãPoseDiffusion çå»åªæ¨¡å GUNet è¢«è¨­è¨çºçµååå½¢å·ç©ç¥ç¶ç¶²è·¯ãå®è½å¤ ééå¨è¨ç·´éç¨ä¸­å¼å¥éª¨æ¶è³è¨ä¾å­¸ç¿äººé«éª¨æ¶çç©ºééä¿ã2) å¤æ¨£æ§ãæåè§£è¦éª¨æ¶çééµé»ä¸¦åå¥å°å¶é²è¡è¡¨å¾µï¼ä¸¦ä½¿ç¨äº¤åæ³¨æåä¾å¼å¥ææ¬æ¢ä»¶ãå¯¦é©çµæè¡¨æï¼PoseDiffusion å¨ææ¬é©åå§¿å¢éª¨æ¶çæçç©©å®æ§åå¤æ¨£æ§æ¹é¢åªæ¼ç¾æç SoTA æ¼ç®æ³ãå®æ§åæé²ä¸æ­¥è­æäºå®å¨ Stable Diffusion ä¸­å¯æ§çæçåªè¶æ§ã

##### **FedNE: Surrogate-Assisted Federated Neighbor Embedding for Dimensionality Reduction**
2409.11509v1 by Ziwei Li, Xiaoqi Wang, Hong-You Chen, Han-Wei Shen, Wei-Lun Chao

Federated learning (FL) has rapidly evolved as a promising paradigm that
enables collaborative model training across distributed participants without
exchanging their local data. Despite its broad applications in fields such as
computer vision, graph learning, and natural language processing, the
development of a data projection model that can be effectively used to
visualize data in the context of FL is crucial yet remains heavily
under-explored. Neighbor embedding (NE) is an essential technique for
visualizing complex high-dimensional data, but collaboratively learning a joint
NE model is difficult. The key challenge lies in the objective function, as
effective visualization algorithms like NE require computing loss functions
among pairs of data. In this paper, we introduce \textsc{FedNE}, a novel
approach that integrates the \textsc{FedAvg} framework with the contrastive NE
technique, without any requirements of shareable data. To address the lack of
inter-client repulsion which is crucial for the alignment in the global
embedding space, we develop a surrogate loss function that each client learns
and shares with each other. Additionally, we propose a data-mixing strategy to
augment the local data, aiming to relax the problems of invisible neighbors and
false neighbors constructed by the local $k$NN graphs. We conduct comprehensive
experiments on both synthetic and real-world datasets. The results demonstrate
that our \textsc{FedNE} can effectively preserve the neighborhood data
structures and enhance the alignment in the global embedding space compared to
several baseline methods.

æè¦ï¼è¯åå¼å­¸ç¿ (FL) å·²è¿éæ¼è®çºä¸ç¨®æåéçç¯ä¾ï¼å®å¯ä»¥å¨åå¸å¼åèèä¹éé²è¡åä½æ¨¡åè¨ç·´ï¼èç¡éäº¤æä»åçæ¬å°æ¸æãåç®¡å®å¨é»è¦è¦è¦ºãåå½¢å­¸ç¿åèªç¶èªè¨èçç­é åæå»£æ³çæç¨ï¼ä½éç¼ä¸åæ¸ææå½±æ¨¡åï¼å¯ææç¨æ¼å¨ FL çèæ¯ä¸è¦è¦ºåæ¸æï¼éä¸é»è³ééè¦ï¼ä½ä»æªå¾å°ååçæ¢ç´¢ãé°ååµå¥ (NE) æ¯ç¨æ¼è¦è¦ºåè¤éé«ç¶­æ¸æçä¸é åºæ¬æè¡ï¼ä½åä½å­¸ç¿ä¸åè¯å NE æ¨¡åå¾å°é£ãä¸»è¦çææ°å¨æ¼ç®æ¨å½æ¸ï¼å çºå NE éæ¨£çææè¦è¦ºåæ¼ç®æ³éè¦è¨ç®æ¸æå°ä¹éçæå¤±å½æ¸ãå¨æ¬æä¸­ï¼æåä»ç´¹äº \textsc{FedNE}ï¼éæ¯ä¸ç¨®æ°ç©çæ¹æ³ï¼å®å° \textsc{FedAvg} æ¡æ¶èå°æ¯ NE æè¡ç¸æ´åï¼èç¡éä»»ä½å¯å±äº«æ¸æçè¦æ±ãçºäºè§£æ±ºå°æ¼å¨å¨å±åµå¥ç©ºéä¸­å°é½è³ééè¦çå®¢æ¶ç«¯éææ¥åä¸è¶³çåé¡ï¼æåéç¼äºä¸åä»£çæå¤±å½æ¸ï¼æ¯åå®¢æ¶ç«¯å­¸ç¿æ­¤å½æ¸ä¸¦èå½¼æ­¤å±äº«ãæ­¤å¤ï¼æåæåºäºä¸ç¨®æ¸ææ··åç­ç¥ä¾æ´åæ¬å°æ¸æï¼æ¨å¨ç·©è§£ç±æ¬å° $k$NN åå½¢æ§é çä¸å¯è¦é°ååé¯èª¤é°åçåé¡ãæåå¨åæåçå¯¦ä¸çæ¸æéä¸é²è¡äºå¨é¢çå¯¦é©ãçµæè¡¨æï¼èå¹¾ç¨®åºç·æ¹æ³ç¸æ¯ï¼æåç \textsc{FedNE} å¯ä»¥ææå°ä¿çé°åæ¸æçµæ§ä¸¦å¢å¼·å¨å¨å±åµå¥ç©ºéä¸­çå°é½ã

##### **Reasoning Graph Enhanced Exemplars Retrieval for In-Context Learning**
2409.11147v1 by Yukang Lin, Bingchen Zhong, Shuoran Jiang, Joanna Siebert, Qingcai Chen

Large language models(LLMs) have exhibited remarkable few-shot learning
capabilities and unified the paradigm of NLP tasks through the in-context
learning(ICL) technique. Despite the success of ICL, the quality of the
exemplar demonstrations can significantly influence the LLM's performance.
Existing exemplar selection methods mainly focus on the semantic similarity
between queries and candidate exemplars. On the other hand, the logical
connections between reasoning steps can be beneficial to depict the
problem-solving process as well. In this paper, we proposes a novel method
named Reasoning Graph-enhanced Exemplar Retrieval(RGER). RGER first quires LLM
to generate an initial response, then expresses intermediate problem-solving
steps to a graph structure. After that, it employs graph kernel to select
exemplars with semantic and structural similarity. Extensive experiments
demonstrate the structural relationship is helpful to the alignment of queries
and candidate exemplars. The efficacy of RGER on math and logit reasoning tasks
showcases its superiority over state-of-the-art retrieval-based approaches. Our
code is released at https://github.com/Yukang-Lin/RGER.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾åºåè¶çå°éå­¸ç¿è½åï¼ä¸¦ééæå¢å­¸ç¿ (ICL) æè¡çµ±ä¸äº NLP ä»»åçç¯ä¾ãåç®¡ ICL å·²æåï¼ç¯ä¾ç¤ºç¯çåè³ªæé¡¯èå½±é¿ LLM çæè½ãç¾æçç¯ä¾é¸ææ¹æ³ä¸»è¦èéæ¼æ¥è©¢èåé¸ç¯ä¾ä¹éçèªæç¸ä¼¼æ§ãå¦ä¸æ¹é¢ï¼æ¨çæ­¥é©ä¹éçéè¼¯é£çµæå©æ¼æç¹ªåé¡è§£æ±ºæµç¨ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®ç¨±çºæ¨çåå¢å¼·ç¯ä¾æª¢ç´¢ (RGER) çæ°æ¹æ³ãRGER é¦åè¦æ± LLM ç¢çä¸ååå§åæï¼ç¶å¾å°ä¸­éåé¡è§£æ±ºæ­¥é©è¡¨ç¤ºçºåå½¢çµæ§ãä¹å¾ï¼å®æ¡ç¨åå½¢æ ¸é¸åå·æèªæåçµæ§ç¸ä¼¼æ§çç¯ä¾ãå»£æ³çå¯¦é©è­æï¼çµæ§éä¿æå©æ¼æ¥è©¢ååé¸ç¯ä¾çå°é½ãRGER å¨æ¸å­¸åéè¼¯æ¨çä»»åä¸çåæå±ç¤ºäºå®åªæ¼æåé²çåºæ¼æª¢ç´¢çæ¹æ³ãæåçç¨å¼ç¢¼å·²ç¼å¸æ¼ https://github.com/Yukang-Lin/RGERã

##### **Semformer: Transformer Language Models with Semantic Planning**
2409.11143v1 by Yongjing Yin, Junran Ding, Kai Song, Yue Zhang

Next-token prediction serves as the dominant component in current neural
language models. During the training phase, the model employs teacher forcing,
which predicts tokens based on all preceding ground truth tokens. However, this
approach has been found to create shortcuts, utilizing the revealed prefix to
spuriously fit future tokens, potentially compromising the accuracy of the
next-token predictor. In this paper, we introduce Semformer, a novel method of
training a Transformer language model that explicitly models the semantic
planning of response. Specifically, we incorporate a sequence of planning
tokens into the prefix, guiding the planning token representations to predict
the latent semantic representations of the response, which are induced by an
autoencoder. In a minimal planning task (i.e., graph path-finding), our model
exhibits near-perfect performance and effectively mitigates shortcut learning,
a feat that standard training methods and baseline models have been unable to
accomplish. Furthermore, we pretrain Semformer from scratch with 125M
parameters, demonstrating its efficacy through measures of perplexity,
in-context learning, and fine-tuning on summarization tasks.

æè¦ï¼å¨ç¶åçèªè¨æ¨¡åä¸­ï¼ä¸ä¸åè©å½é æ¸¬æ¯ä¸»å°çµæé¨åãå¨è¨ç·´éæ®µï¼æ¨¡åæ¡ç¨æå¸«å¼·å¶æ³ï¼æ ¹æææåä¸åççå¯¦è©å½ä¾é æ¸¬è©å½ãç¶èï¼ç¼ç¾éç¨®æ¹æ³æç¢çæ·å¾ï¼å©ç¨å·²æ­é²çåç¶´ä¾èåå°ç¬¦åå¾çºçè©å½ï¼æ½å¨æå±å®³ä¸ä¸åè©å½é æ¸¬å¨çæºç¢ºåº¦ãå¨æ¬æä¸­ï¼æåä»ç´¹ Semformerï¼ä¸ç¨®è¨ç·´ Transformer èªè¨æ¨¡åçæ°æ¹æ³ï¼æç¢ºå°å»ºæ§åæçèªæè¦åãå·é«ä¾èªªï¼æåå°ä¸ç³»åè¦åè©å½ç´å¥åç¶´ï¼å¼å°è¦åè©å½çè¡¨å¾µå»é æ¸¬åæçæ½å¨èªæè¡¨å¾µï¼éäºè¡¨å¾µæ¯ç±èªåç·¨ç¢¼å¨èªå°çãå¨ä¸åæå°çè¦åä»»åï¼å³åå½¢è·¯å¾å°æ¾ï¼ä¸­ï¼æåçæ¨¡åè¡¨ç¾åºæ¥è¿å®ç¾çæè½ï¼ä¸¦ææå°æ¸è¼æ·å¾å­¸ç¿ï¼éæ¯æ¨æºè¨ç·´æ¹æ³ååºç·æ¨¡åç¡æ³éæçå£¯èãæ­¤å¤ï¼æåå¾é ­éå§ä½¿ç¨ 1.25 åååæ¸é è¨ç·´ Semformerï¼ééå°æåº¦ãèªå¢å­¸ç¿åå¨æè¦ä»»åä¸çå¾®èª¿ä¾è­æå¶åæã

##### **KALE: An Artwork Image Captioning System Augmented with Heterogeneous Graph**
2409.10921v1 by Yanbei Jiang, Krista A. Ehinger, Jey Han Lau

Exploring the narratives conveyed by fine-art paintings is a challenge in
image captioning, where the goal is to generate descriptions that not only
precisely represent the visual content but also offer a in-depth interpretation
of the artwork's meaning. The task is particularly complex for artwork images
due to their diverse interpretations and varied aesthetic principles across
different artistic schools and styles. In response to this, we present KALE
Knowledge-Augmented vision-Language model for artwork Elaborations), a novel
approach that enhances existing vision-language models by integrating artwork
metadata as additional knowledge. KALE incorporates the metadata in two ways:
firstly as direct textual input, and secondly through a multimodal
heterogeneous knowledge graph. To optimize the learning of graph
representations, we introduce a new cross-modal alignment loss that maximizes
the similarity between the image and its corresponding metadata. Experimental
results demonstrate that KALE achieves strong performance (when evaluated with
CIDEr, in particular) over existing state-of-the-art work across several
artwork datasets. Source code of the project is available at
https://github.com/Yanbei-Jiang/Artwork-Interpretation.

æè¦ï¼æ¢ç´¢ç±ç¾æ¯ç»ç»ä¼ è¾¾çåäºæ¯å¾åå­å¹ä¸­çææï¼å¶ç®æ æ¯çæä¸ä»åç¡®å°è¡¨ç¤ºè§è§åå®¹èä¸è¿æä¾å¯¹èºæ¯åå«ä¹çæ·±å¥è§£éçæè¿°ãç±äºå¶ä¸åçè§£éåè·¨ä¸åèºæ¯æµæ´¾åé£æ ¼çä¸åç¾å­¦ååï¼è¿é¡¹ä»»å¡å¯¹äºèºæ¯åå¾åæ¥è¯´å°¤å¶å¤æãä¸ºäºåºå¯¹è¿ç§æåµï¼æä»¬æåºäº KALE ç¥è¯å¢å¼ºè§è§è¯­è¨æ¨¡åç¨äºèºæ¯åééï¼ä¸ç§éè¿å°èºæ¯ååæ°æ®ä½ä¸ºéå ç¥è¯æ¥å¢å¼ºç°æè§è§è¯­è¨æ¨¡åçæ°æ¹æ³ãKALE ä»¥ä¸¤ç§æ¹å¼åå¹¶åæ°æ®ï¼é¦åä½ä¸ºç´æ¥ææ¬è¾å¥ï¼å¶æ¬¡éè¿å¤æ¨¡æå¼æç¥è¯å¾ãä¸ºäºä¼åå¾è¡¨çå­¦ä¹ è¡¨ç¤ºï¼æä»¬å¼å¥äºä¸ç§æ°çè·¨æ¨¡æå¯¹é½æå¤±ï¼å®æå¤§åå¾åä¸å¶å¯¹åºåæ°æ®ä¹é´çç¸ä¼¼æ§ãå®éªç»æè¡¨æï¼KALE å¨ä½¿ç¨ CIDEr è¯ä¼°æ¶ï¼å¨å ä¸ªèºæ¯åæ°æ®éä¸åå¾äºä¼å¼çæ§è½ï¼ç¹å«æ¯ä¸ç°æçæåè¿çå·¥ä½ç¸æ¯ï¼ãè¯¥é¡¹ç®çæºä»£ç å¯å¨ https://github.com/Yanbei-Jiang/Artwork-Interpretation è·å¾ã

##### **A Knowledge-Enhanced Disease Diagnosis Method Based on Prompt Learning and BERT Integration**
2409.10403v1 by Zhang Zheng

This paper proposes a knowledge-enhanced disease diagnosis method based on a
prompt learning framework. The method retrieves structured knowledge from
external knowledge graphs related to clinical cases, encodes it, and injects it
into the prompt templates to enhance the language model's understanding and
reasoning capabilities for the task.We conducted experiments on three public
datasets: CHIP-CTC, IMCS-V2-NER, and KUAKE-QTR. The results show that the
proposed method significantly outperforms existing models across multiple
evaluation metrics, with an F1 score improvement of 2.4% on the CHIP-CTC
dataset, 3.1% on the IMCS-V2-NER dataset,and 4.2% on the KUAKE-QTR dataset.
Additionally,ablation studies confirmed the critical role of the knowledge
injection module,as the removal of this module resulted in a significant drop
in F1 score. The experimental results demonstrate that the proposed method not
only effectively improves the accuracy of disease diagnosis but also enhances
the interpretability of the predictions, providing more reliable support and
evidence for clinical diagnosis.

æè¦ï¼æ¬ææåºäºä¸ç§åºäºæç¤ºå­¦ä¹ æ¡æ¶çç¥è¯å¢å¼ºç¾çè¯æ­æ¹æ³ãè¯¥æ¹æ³ä»ä¸ä¸´åºçä¾ç¸å³çå¤é¨ç¥è¯å¾è°±ä¸­æ£ç´¢ç»æåç¥è¯ï¼å¯¹å¶è¿è¡ç¼ç ï¼å¹¶å°å¶æ³¨å¥å°æç¤ºæ¨¡æ¿ä¸­ï¼ä»¥å¢å¼ºè¯­è¨æ¨¡åå¯¹ä»»å¡ççè§£åæ¨çè½åãæä»¬å¨ä¸ä¸ªå¬å±æ°æ®éä¸è¿è¡äºå®éªï¼CHIP-CTCãIMCS-V2-NER å KUAKE-QTRãç»æè¡¨æï¼ææåºçæ¹æ³å¨å¤ä¸ªè¯ä¼°ææ ä¸ææ¾ä¼äºç°ææ¨¡åï¼å¨ CHIP-CTC æ°æ®éä¸ç F1 å¾åæé«äº 2.4%ï¼å¨ IMCS-V2-NER æ°æ®éä¸æé«äº 3.1%ï¼å¨ KUAKE-QTR æ°æ®éä¸æé«äº 4.2%ãæ­¤å¤ï¼æ¶èç ç©¶è¯å®äºç¥è¯æ³¨å¥æ¨¡åçå³é®ä½ç¨ï¼å ä¸ºç§»é¤æ­¤æ¨¡åä¼å¯¼è´ F1 å¾åæ¾çä¸éãå®éªç»æè¡¨æï¼ææåºçæ¹æ³ä¸ä»æææé«äºç¾çè¯æ­çåç¡®æ§ï¼èä¸å¢å¼ºäºé¢æµçå¯è§£éæ§ï¼ä¸ºä¸´åºè¯æ­æä¾äºæ´å¯é çæ¯æåè¯æ®ã

##### **MGSA: Multi-Granularity Graph Structure Attention for Knowledge Graph-to-Text Generation**
2409.10294v2 by Shanshan Wang, Chun Zhang, Ning Zhang

The Knowledge Graph-to-Text Generation task aims to convert structured
knowledge graphs into coherent and human-readable natural language text. Recent
efforts in this field have focused on enhancing pre-trained language models
(PLMs) by incorporating graph structure information to capture the intricate
structure details of knowledge graphs. However, most of these approaches tend
to capture only single-granularity structure information, concentrating either
on the relationships between entities within the original graph or on the
relationships between words within the same entity or across different
entities. This narrow focus results in a significant limitation: models that
concentrate solely on entity-level structure fail to capture the nuanced
semantic relationships between words, while those that focus only on word-level
structure overlook the broader relationships between original entire entities.
To overcome these limitations, this paper introduces the Multi-granularity
Graph Structure Attention (MGSA), which is based on PLMs. The encoder of the
model architecture features an entity-level structure encoding module, a
word-level structure encoding module, and an aggregation module that
synthesizes information from both structure. This multi-granularity structure
encoding approach allows the model to simultaneously capture both entity-level
and word-level structure information, providing a more comprehensive
understanding of the knowledge graph's structure information, thereby
significantly improving the quality of the generated text. We conducted
extensive evaluations of the MGSA model using two widely recognized KG-to-Text
Generation benchmark datasets, WebNLG and EventNarrative, where it consistently
outperformed models that rely solely on single-granularity structure
information, demonstrating the effectiveness of our approach.

æè¦ï¼ç¥è­åè­è½æå­çæä»»åæ¨å¨å°çµæ§åçç¥è­åè­è½æçºé£è²«ä¸äººé¡å¯è®çèªç¶èªè¨æå­ãæè¿å¨éåé åçåªåéä¸­å¨ééç´å¥åå½¢çµæ§è³è¨ä¾å¢å¼·é åè¨ç·´çèªè¨æ¨¡å (PLM)ï¼ä»¥æ·åç¥è­åè­çè¤éçµæ§ç´°ç¯ãç¶èï¼éäºæ¹æ³ä¸­çå¤§å¤æ¸å¾åæ¼åæ·åå®ä¸ç²åº¦ççµæ§è³è¨ï¼å°æ³¨æ¼åå§åå½¢ä¸­å¯¦é«ä¹éçéä¿æåä¸åå¯¦é«æä¸åå¯¦é«ä¹éçè©å½éä¿ãéç¨®ç¹éçç¦é»å°è´äºä¸åéå¤§çéå¶ï¼åå°æ³¨æ¼å¯¦é«å±¤ç´çµæ§çæ¨¡åç¡æ³æ·åè©å½ä¹éçç´°å¾®èªç¾©éä¿ï¼èåå°æ³¨æ¼è©å½å±¤ç´çµæ§çæ¨¡ååå¿½ç¥äºåå§æ´åå¯¦é«ä¹éçæ´å»£æ³éä¿ãçºäºåæéäºéå¶ï¼æ¬æå¼å¥äºåºæ¼ PLM çå¤ç²åº¦åå½¢çµæ§æ³¨æå (MGSA)ãæ¨¡åæ¶æ§çç·¨ç¢¼å¨å·æä¸åå¯¦é«å±¤ç´çµæ§ç·¨ç¢¼æ¨¡çµãä¸åè©å½å±¤ç´çµæ§ç·¨ç¢¼æ¨¡çµï¼ä»¥åä¸åå¾å©åçµæ§ä¸­ç¶åè³è¨çèåæ¨¡çµãéç¨®å¤ç²åº¦çµæ§ç·¨ç¢¼æ¹æ³åè¨±æ¨¡ååææ·åå¯¦é«å±¤ç´åè©å½å±¤ç´ççµæ§è³è¨ï¼æä¾å°ç¥è­åè­çµæ§è³è¨æ´å¨é¢ççè§£ï¼å¾èé¡¯èæåæçææå­çåè³ªãæåä½¿ç¨å©åå»£æ³èªå¯ç KG è½æå­çæåºæºè³æé WebNLG å EventNarrative å° MGSA æ¨¡åé²è¡äºå»£æ³çè©ä¼°ï¼å®å§çµåªæ¼åä¾è³´å®ä¸ç²åº¦çµæ§è³è¨çæ¨¡åï¼è­æäºæåæ¹æ³çæææ§ã

##### **LLM-DER:A Named Entity Recognition Method Based on Large Language Models for Chinese Coal Chemical Domain**
2409.10077v1 by Le Xiao, Yunfei Xu, Jing Zhao

Domain-specific Named Entity Recognition (NER), whose goal is to recognize
domain-specific entities and their categories, provides an important support
for constructing domain knowledge graphs. Currently, deep learning-based
methods are widely used and effective in NER tasks, but due to the reliance on
large-scale labeled data. As a result, the scarcity of labeled data in a
specific domain will limit its application.Therefore, many researches started
to introduce few-shot methods and achieved some results. However, the entity
structures in specific domains are often complex, and the current few-shot
methods are difficult to adapt to NER tasks with complex features.Taking the
Chinese coal chemical industry domain as an example,there exists a complex
structure of multiple entities sharing a single entity, as well as multiple
relationships for the same pair of entities, which affects the NER task under
the sample less condition.In this paper, we propose a Large Language Models
(LLMs)-based entity recognition framework LLM-DER for the domain-specific
entity recognition problem in Chinese, which enriches the entity information by
generating a list of relationships containing entity types through LLMs, and
designing a plausibility and consistency evaluation method to remove
misrecognized entities, which can effectively solve the complex structural
entity recognition problem in a specific domain.The experimental results of
this paper on the Resume dataset and the self-constructed coal chemical dataset
Coal show that LLM-DER performs outstandingly in domain-specific entity
recognition, not only outperforming the existing GPT-3.5-turbo baseline, but
also exceeding the fully-supervised baseline, verifying its effectiveness in
entity recognition.

æè¦ï¼<paragraph>é åç¹å®å½åå¯¦é«è¾¨è­ï¼NERï¼ï¼å¶ç®æ¨æ¯è¾¨è­é åç¹å®å¯¦é«åå¶é¡å¥ï¼çºå»ºæ§é åç¥è­åè­æä¾éè¦çæ¯æ´ãç®åï¼åºæ¼æ·±åº¦å­¸ç¿çæ¹æ³å»£æ³ç¨æ¼ NER ä»»åä¸ååææï¼ä½ç±æ¼ä¾è³´æ¼å¤§è¦æ¨¡æ¨è¨è³æãå æ­¤ï¼ç¹å®é åä¸­æ¨è¨è³æçç¨å°æéå¶å¶æç¨ãå æ­¤ï¼è¨±å¤ç ç©¶éå§å¼å¥å°éæ¨£æ¬æ¹æ³ä¸¦ç²å¾ä¸äºææãç¶èï¼ç¹å®é åä¸­çå¯¦é«çµæ§éå¸¸å¾è¤éï¼èç®åçå°éæ¨£æ¬æ¹æ³é£ä»¥é©æå·æè¤éç¹å¾µç NER ä»»åãä»¥ä¸­åç¤åå·¥ç¢æ¥­é åçºä¾ï¼å­å¨å¤åå¯¦é«å±ç¨å®ä¸å¯¦é«çè¤éçµæ§ï¼ä»¥ååä¸å°å¯¦é«æå¤ééä¿ï¼éæå½±é¿æ¨£æ¬è¼å°æ¢ä»¶ä¸ç NER ä»»åãå¨æ¬æä¸­ï¼æåæåºäºä¸ååºæ¼å¤§åèªè¨æ¨¡åï¼LLMï¼çå¯¦é«è¾¨è­æ¶æ§ LLM-DERï¼ç¨æ¼ä¸­æé åç¹å®å¯¦é«è¾¨è­åé¡ï¼éé LLM çæåå«å¯¦é«é¡åçéä¿æ¸å®ï¼ä¸¦è¨­è¨ä¸ååçæ§åä¸è´æ§è©ä¼°æ¹æ³ä¾ç§»é¤è¾¨è­é¯èª¤çå¯¦é«ï¼å¾èå¯ä»¥ææè§£æ±ºç¹å®é åä¸­è¤éçµæ§å¯¦é«è¾¨è­åé¡ãæ¬æå¨ Resume è³æéåèªå»ºç¤åå·¥è³æé Coal ä¸çå¯¦é©çµæè¡¨æï¼LLM-DER å¨é åç¹å®å¯¦é«è¾¨è­ä¸­è¡¨ç¾åºè²ï¼ä¸ååªæ¼ç¾æç GPT-3.5-turbo åºæºï¼éè¶éäºå®å¨ç£ç£çåºç·ï¼é©è­äºå¶å¨å¯¦é«è¾¨è­ä¸­çæææ§ã</paragraph>

##### **On the Diagram of Thought**
2409.10038v1 by Yifan Zhang, Yang Yuan, Andrew Chi-Chih Yao

We introduce Diagram of Thought (DoT), a framework that models iterative
reasoning in large language models (LLMs) as the construction of a directed
acyclic graph (DAG) within a single model. Unlike traditional approaches that
represent reasoning as linear chains or trees, DoT organizes propositions,
critiques, refinements, and verifications into a cohesive DAG structure,
allowing the model to explore complex reasoning pathways while maintaining
logical consistency. Each node in the diagram corresponds to a proposition that
has been proposed, critiqued, refined, or verified, enabling the LLM to
iteratively improve its reasoning through natural language feedback. By
leveraging auto-regressive next-token prediction with role-specific tokens, DoT
facilitates seamless transitions between proposing ideas and critically
evaluating them, providing richer feedback than binary signals. Furthermore, we
formalize the DoT framework using Topos Theory, providing a mathematical
foundation that ensures logical consistency and soundness in the reasoning
process. This approach enhances both the training and inference processes
within a single LLM, eliminating the need for multiple models or external
control mechanisms. DoT offers a conceptual framework for designing
next-generation reasoning-specialized models, emphasizing training efficiency,
robust reasoning capabilities, and theoretical grounding. The code is available
at https://github.com/diagram-of-thought/diagram-of-thought.

æè¦ï¼æåä»ç´¹äºææ³åï¼DoTï¼ï¼éæ¯ä¸åæ¡æ¶ï¼å®å°å¤§åèªè¨æ¨¡åï¼LLMï¼ä¸­çè¿­ä»£æ¨çå»ºæ¨¡çºå¨å®ä¸æ¨¡åå§å»ºæ§ä¸åæåç¡ç°åï¼DAGï¼ãèå°æ¨çè¡¨ç¤ºçºç·æ§éææ¨¹çå³çµ±æ¹æ³ä¸åï¼DoT å°å½é¡ãæ¹å¤ãä¿®æ­£åé©è­çµç¹æä¸åæåèåç DAG çµæ§ï¼åè¨±æ¨¡åæ¢ç´¢è¤éçæ¨çè·¯å¾ï¼åæä¿æéè¼¯ä¸è´æ§ãåè¡¨ä¸­çæ¯åç¯é»å°ææ¼ä¸åå·²è¢«æåºãæ¹å¤ãä¿®æ­£æé©è­çå½é¡ï¼ä½¿ LLM è½å¤ ééèªç¶èªè¨åé¥è¿­ä»£å°æ¹é²å¶æ¨çãééå©ç¨å·æè§è²ç¹å®æ¨è¨çèªååæ­¸ä¸ä¸åæ¨è¨é æ¸¬ï¼DoT ä¿é²äºæåºæ³æ³åæ¹å¤æ§è©ä¼°å®åä¹éçç¡ç¸«éæ¸¡ï¼æä¾äºæ¯äºåä¿¡èæ´è±å¯çåé¥ãæ­¤å¤ï¼æåä½¿ç¨ææ²çè«å½¢å¼åäº DoT æ¡æ¶ï¼æä¾äºä¸åæ¸å­¸åºç¤ï¼ä»¥ç¢ºä¿æ¨çéç¨ä¸­çéè¼¯ä¸è´æ§åå¥å¨æ§ãéç¨®æ¹æ³å¢å¼·äºå®ä¸ LLM å§çè¨ç·´åæ¨çéç¨ï¼æ¶é¤äºå°å¤åæ¨¡åæå¤é¨æ§å¶æ©å¶çéè¦ãDoT çºè¨­è¨ä¸ä¸ä»£æ¨çå°ç¨æ¨¡åæä¾äºä¸åæ¦å¿µæ¡æ¶ï¼å¼·èª¿è¨ç·´æçãå¼·å¤§çæ¨çè½ååçè«åºç¤ãä»£ç¢¼å¯å¨ https://github.com/diagram-of-thought/diagram-of-thought ç²å¾ã

##### **Entity-Aware Self-Attention and Contextualized GCN for Enhanced Relation Extraction in Long Sentences**
2409.13755v1 by Xin Wang, Xinyi Bai

Relation extraction as an important natural Language processing (NLP) task is
to identify relations between named entities in text. Recently, graph
convolutional networks over dependency trees have been widely used to capture
syntactic features and achieved attractive performance. However, most existing
dependency-based approaches ignore the positive influence of the words outside
the dependency trees, sometimes conveying rich and useful information on
relation extraction. In this paper, we propose a novel model, Entity-aware
Self-attention Contextualized GCN (ESC-GCN), which efficiently incorporates
syntactic structure of input sentences and semantic context of sequences. To be
specific, relative position self-attention obtains the overall semantic
pairwise correlation related to word position, and contextualized graph
convolutional networks capture rich intra-sentence dependencies between words
by adequately pruning operations. Furthermore, entity-aware attention layer
dynamically selects which token is more decisive to make final relation
prediction. In this way, our proposed model not only reduces the noisy impact
from dependency trees, but also obtains easily-ignored entity-related semantic
representation. Extensive experiments on various tasks demonstrate that our
model achieves encouraging performance as compared to existing dependency-based
and sequence-based models. Specially, our model excels in extracting relations
between entities of long sentences.

æè¦ï¼éä¿èåä½çºä¸é éè¦çèªç¶èªè¨èç (NLP) ä»»åï¼æ¯çºäºè¾¨è­ææ¬ä¸­å½åå¯¦é«ä¹éçéä¿ãæè¿ï¼ä¾å­æ¨¹ä¸çåå½¢å·ç©ç¶²è·¯å·²å»£æ³ç¨æ¼æ·åå¥æ³ç¹å¾µï¼ä¸¦ç²å¾ä»¤äººæ»¿æçæè½ãç¶èï¼ç¾æçåºæ¼ä¾å­çæ¼ç®æ³å¤§å¤å¿½ç¥ä¾å­æ¨¹å¤å®å­çæ­£é¢å½±é¿ï¼éäºå®å­æææå³éè±å¯ä¸æç¨çéä¿èåè³è¨ãå¨æ¬æä¸­ï¼æåæåºä¸åæ°ç©çæ¨¡åï¼å¯¦é«æç¥èªææ³¨æèçµ¡å GCN (ESC-GCN)ï¼å®ææå°æ´åè¼¸å¥å¥å­çå¥æ³çµæ§ååºåçèªæèçµ¡ãå·é«ä¾èªªï¼ç¸å°ä½ç½®èªææ³¨ææåå¾èå®å­ä½ç½®ç¸éçæ´é«èªææå°éè¯æ§ï¼èèçµ¡ååå½¢å·ç©ç¶²è·¯åééé©ç¶çä¿®åªéç®ï¼æ·åå®å­ä¹éè±å¯çå¥å­å§ä¾å­éä¿ãæ­¤å¤ï¼å¯¦é«æç¥æ³¨æå±¤æåæå°é¸æåªåè¨èå°æ¼ååºæçµéä¿é æ¸¬è¼çºæ±ºå®æ§ãèç±éç¨®æ¹å¼ï¼æåæåºçæ¨¡åä¸åæ¸å°äºä¾å­æ¨¹å¸¶ä¾çéè¨å½±é¿ï¼éè½åå¾å®¹æè¢«å¿½ç¥çå¯¦é«ç¸éèªæè¡¨å¾µãå¨åç¨®ä»»åä¸çå»£æ³å¯¦é©è­æï¼èç¾æçåºæ¼ä¾å­ååºæ¼åºåçæ¨¡åç¸æ¯ï¼æåçæ¨¡åéå°äºä»¤äººé¼èçæè½ãç¹å¥æ¯ï¼æåçæ¨¡åå¨èåé·å¥ä¸­å¯¦é«ä¹éçéä¿æ¹é¢è¡¨ç¾åºè²ã

##### **Automatic Scene Generation: State-of-the-Art Techniques, Models, Datasets, Challenges, and Future Prospects**
2410.01816v1 by Awal Ahmed Fime, Saifuddin Mahmud, Arpita Das, Md. Sunzidul Islam, Hong-Hoon Kim

Automatic scene generation is an essential area of research with applications
in robotics, recreation, visual representation, training and simulation,
education, and more. This survey provides a comprehensive review of the current
state-of-the-arts in automatic scene generation, focusing on techniques that
leverage machine learning, deep learning, embedded systems, and natural
language processing (NLP). We categorize the models into four main types:
Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs),
Transformers, and Diffusion Models. Each category is explored in detail,
discussing various sub-models and their contributions to the field.
  We also review the most commonly used datasets, such as COCO-Stuff, Visual
Genome, and MS-COCO, which are critical for training and evaluating these
models. Methodologies for scene generation are examined, including image-to-3D
conversion, text-to-3D generation, UI/layout design, graph-based methods, and
interactive scene generation. Evaluation metrics such as Frechet Inception
Distance (FID), Kullback-Leibler (KL) Divergence, Inception Score (IS),
Intersection over Union (IoU), and Mean Average Precision (mAP) are discussed
in the context of their use in assessing model performance.
  The survey identifies key challenges and limitations in the field, such as
maintaining realism, handling complex scenes with multiple objects, and
ensuring consistency in object relationships and spatial arrangements. By
summarizing recent advances and pinpointing areas for improvement, this survey
aims to provide a valuable resource for researchers and practitioners working
on automatic scene generation.

æè¦ï¼èªåå ´æ¯çææ¯ç ç©¶çéè¦é åï¼å¶æç¨åæ¬æ©å¨äººæè¡ãå¨æ¨ãè¦è¦ºè¡¨ç¤ºãè¨ç·´èæ¨¡æ¬ãæè²ç­ç­ãéé èª¿æ¥å¨é¢åé¡§äºèªåå ´æ¯çæä¸­ç¶åæåé²çæè¡ï¼éé»å¨æ¼å©ç¨æ©å¨å­¸ç¿ãæ·±åº¦å­¸ç¿ãåµå¥å¼ç³»çµ±åèªç¶èªè¨èç (NLP) çæè¡ãæåå°æ¨¡ååé¡çºåç¨®é¡åï¼è®ç°èªåç·¨ç¢¼å¨ (VAE)ãçæå°æç¶²è·¯ (GAN)ãTransformer åæ´æ£æ¨¡åãæåè©³ç´°æ¢è¨äºæ¯åé¡å¥ï¼è¨è«äºåç¨®å­æ¨¡ååå¶å°è©²é åçè²¢ç»ã
  æåä¹åé¡§äºæå¸¸ä½¿ç¨çè³æéï¼ä¾å¦ COCO-StuffãVisual Genome å MS-COCOï¼éäºè³æéå°æ¼è¨ç·´åè©ä¼°éäºæ¨¡åè³ééè¦ãæåæª¢è¦äºå ´æ¯çæçæ¹æ³ï¼åæ¬å½±åè½ 3Dãæå­è½ 3D çæãUI/çé¢è¨­è¨ãåºæ¼åå½¢çæ¨¡ååäºåå¼å ´æ¯çæãæåå¨è©ä¼°æ¨¡åæè½çèçµ¡ä¸­è¨è«äºè©ä¼°ææ¨ï¼ä¾å¦ FrÃ©chet èµ·å§è·é¢ (FID)ãKullback-Leibler (KL) å·®ç°ãèµ·å§åæ¸ (IS)ãäº¤éæ¯è¯é (IoU) åå¹³åæºç¢ºç (mAP)ã
  éé èª¿æ¥æ¾åºè©²é åçä¸»è¦ææ°åéå¶ï¼ä¾å¦ç¶­æçå¯¦æ§ãèçåå«å¤åç©ä»¶çè¤éå ´æ¯ï¼ä»¥åç¢ºä¿ç©ä»¶éä¿åç©ºééç½®çä¸è´æ§ãééç¸½çµæè¿çé²å±ä¸¦æ¾åºéè¦æ¹é²çå°æ¹ï¼éé èª¿æ¥æ¨å¨çºå¾äºèªåå ´æ¯çæçç ç©¶äººå¡åå¾æ¥­äººå¡æä¾å¯¶è²´çè³æºã

##### **Generating Event-oriented Attribution for Movies via Two-Stage Prefix-Enhanced Multimodal LLM**
2409.09362v1 by Yuanjie Lyu, Tong Xu, Zihan Niu, Bo Peng, Jing Ke, Enhong Chen

The prosperity of social media platforms has raised the urgent demand for
semantic-rich services, e.g., event and storyline attribution. However, most
existing research focuses on clip-level event understanding, primarily through
basic captioning tasks, without analyzing the causes of events across an entire
movie. This is a significant challenge, as even advanced multimodal large
language models (MLLMs) struggle with extensive multimodal information due to
limited context length. To address this issue, we propose a Two-Stage
Prefix-Enhanced MLLM (TSPE) approach for event attribution, i.e., connecting
associated events with their causal semantics, in movie videos. In the local
stage, we introduce an interaction-aware prefix that guides the model to focus
on the relevant multimodal information within a single clip, briefly
summarizing the single event. Correspondingly, in the global stage, we
strengthen the connections between associated events using an inferential
knowledge graph, and design an event-aware prefix that directs the model to
focus on associated events rather than all preceding clips, resulting in
accurate event attribution. Comprehensive evaluations of two real-world
datasets demonstrate that our framework outperforms state-of-the-art methods.

æè¦ï¼ç¤¾ç¾¤åªé«å¹³å°çè¬åç¼å±ï¼æåäºå°èªæè±å¯æåï¼ä¾å¦äºä»¶åæäºç·æ­¸å ï¼çè¿«åéæ±ãç¶èï¼ç¾æçç ç©¶å¤§å¤èéæ¼çæ®µå±¤ç´çäºä»¶çè§£ï¼ä¸»è¦æ¯ééåºç¤çå­å¹ä»»åï¼èæªåææ´é¨é»å½±ä¸­äºä»¶ç¼ççåå ãéæ¯ä¸åéå¤§çææ°ï¼å çºå³ä½¿æ¯é²éçå¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) ä¹æå çºåéçèçµ¡é·åº¦èé£ä»¥èçå»£æ³çå¤æ¨¡æè³è¨ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸åå©éæ®µåç½®è©å¢å¼· MLLM (TSPE) æ¹æ³ï¼ç¨æ¼é»å½±å½±çä¸­çäºä»¶æ­¸å ï¼ä¹å°±æ¯å°ç¸éäºä»¶èå¶å æèªæé£çµèµ·ä¾ãå¨å±é¨éæ®µï¼æåå¼å¥äºä¸åäºåæç¥åç½®è©ï¼å¼å°æ¨¡åå°æ³¨æ¼å®ä¸çæ®µä¸­çç¸éå¤æ¨¡æè³è¨ï¼ç°¡è¦å°ç¸½çµå®ä¸äºä»¶ãç¸æå°ï¼å¨æ´é«éæ®µï¼æåä½¿ç¨æ¨çç¥è­åè­å¼·åç¸éäºä»¶ä¹éçé£çµï¼ä¸¦è¨­è¨äºä¸åäºä»¶æç¥åç½®è©ï¼å¼å°æ¨¡åå°æ³¨æ¼ç¸éäºä»¶ï¼èéææåç½®çæ®µï¼é²èç¢çæºç¢ºçäºä»¶æ­¸å ãå°å©åçå¯¦ä¸çè³æéçå¨é¢è©ä¼°é¡¯ç¤ºï¼æåçæ¶æ§åªæ¼ç¾æçæåé²æ¹æ³ã

##### **ODE: Open-Set Evaluation of Hallucinations in Multimodal Large Language Models**
2409.09318v1 by Yahan Tu, Rui Hu, Jitao Sang

Hallucination poses a significant challenge for multimodal large language
models (MLLMs). However, existing benchmarks for evaluating hallucinations are
static, which can lead to potential data contamination. This paper introduces
ODE, an open-set, dynamic protocol for evaluating object existence
hallucinations in MLLMs. Our framework employs graph structures to model
associations between real-word concepts and generates novel samples for both
general and domain-specific scenarios. The dynamic combination of concepts,
along with various combination principles, ensures a broad sample distribution.
Experimental results show that MLLMs exhibit higher hallucination rates with
ODE-generated samples, effectively avoiding data contamination. Moreover, these
samples can also be used for fine-tuning to improve MLLM performance on
existing benchmarks.

æè¦ï¼å¹»è¦ºå°å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) æ§æéå¤§ææ°ãç¶èï¼ç¾æçè©ä¼°å¹»è¦ºåºæºæ¯éæçï¼éå¯è½å°è´æ½å¨çè³ææ±¡æãæ¬æä»ç´¹äº ODEï¼ä¸ç¨®éæ¾å¼ãåæçåå®ï¼ç¨æ¼è©ä¼° MLLM ä¸­çç©ä»¶å­å¨å¹»è¦ºãæåçæ¶æ§æ¡ç¨åå½¢çµæ§ä¾å»ºæ¨¡çå¯¦ä¸çæ¦å¿µä¹éçéè¯ï¼ä¸¦çºä¸è¬åç¹å®é åæå¢ç¢çæ°çç¯ä¾ãæ¦å¿µçåæçµåï¼ä»¥ååç¨®çµåååï¼ç¢ºä¿äºå»£æ³çç¯ä¾åä½ãå¯¦é©çµæé¡¯ç¤ºï¼MLLM å¨ ODE çæçç¯ä¾ä¸­è¡¨ç¾åºè¼é«çå¹»è¦ºçï¼ææé¿åäºè³ææ±¡æãæ­¤å¤ï¼éäºç¯ä¾ä¹å¯è¢«ç¨æ¼å¾®èª¿ï¼ä»¥æ¹å MLLM å¨ç¾æåºæºä¸çæè½ã

##### **Towards Leveraging Contrastively Pretrained Neural Audio Embeddings for Recommender Tasks**
2409.09026v1 by Florian GrÃ¶tschla, Luca StrÃ¤ssle, Luca A. LanzendÃ¶rfer, Roger Wattenhofer

Music recommender systems frequently utilize network-based models to capture
relationships between music pieces, artists, and users. Although these
relationships provide valuable insights for predictions, new music pieces or
artists often face the cold-start problem due to insufficient initial
information. To address this, one can extract content-based information
directly from the music to enhance collaborative-filtering-based methods. While
previous approaches have relied on hand-crafted audio features for this
purpose, we explore the use of contrastively pretrained neural audio embedding
models, which offer a richer and more nuanced representation of music. Our
experiments demonstrate that neural embeddings, particularly those generated
with the Contrastive Language-Audio Pretraining (CLAP) model, present a
promising approach to enhancing music recommendation tasks within graph-based
frameworks.

æè¦ï¼é³æ¨æ¨è¦ç³»çµ±ç¶å¸¸ä½¿ç¨åºæ¼ç¶²è·¯çæ¨¡åä¾æ·åé³æ¨ä½åãèè¡å®¶åä½¿ç¨èä¹éçéä¿ãåç®¡éäºéä¿çºé æ¸¬æä¾äºæå¹å¼çè¦è§£ï¼ä½ç±æ¼åå§è³è¨ä¸è¶³ï¼æ°çé³æ¨ä½åæèè¡å®¶ç¶å¸¸é¢è¨å·åååé¡ãçºäºè§£æ±ºéååé¡ï¼å¯ä»¥å¾é³æ¨ä¸­ç´æ¥æ·ååºæ¼å§å®¹çè³è¨ï¼ä»¥å¢å¼·åºæ¼ååéæ¿¾çæ¹æ³ãéç¶ååçåæ³å·²ä¾è³´æå·¥è£½ä½çé³è¨ç¹å¾µä¾éææ­¤ç®çï¼ä½æåæ¢ç´¢ä½¿ç¨å°æ¯é è¨ç·´ç¥ç¶é³è¨åµå¥æ¨¡åï¼éæä¾äºæ´è±å¯ä¸æ´ç´°ç·»çé³æ¨è¡¨ç¤ºãæåçå¯¦é©è­æäºç¥ç¶åµå¥ï¼ç¹å¥æ¯ä½¿ç¨å°æ¯èªè¨é³è¨é è¨ç·´ (CLAP) æ¨¡åç¢ççåµå¥ï¼å±ç¤ºäºä¸ç¨®æåæ¯çæ¹æ³ï¼å¯ä»¥ç¨æ¼å¢å¼·åå½¢åæ¡æ¶ä¸­çé³æ¨æ¨è¦ä»»åã

##### **Contri(e)ve: Context + Retrieve for Scholarly Question Answering**
2409.09010v1 by Kanchan Shivashankar, Nadine Steinmetz

Scholarly communication is a rapid growing field containing a wealth of
knowledge. However, due to its unstructured and document format, it is
challenging to extract useful information from them through conventional
document retrieval methods. Scholarly knowledge graphs solve this problem, by
representing the documents in a semantic network, providing, hidden insights,
summaries and ease of accessibility through queries. Naturally, question
answering for scholarly graphs expands the accessibility to a wider audience.
But some of the knowledge in this domain is still presented as unstructured
text, thus requiring a hybrid solution for question answering systems. In this
paper, we present a two step solution using open source Large Language
Model(LLM): Llama3.1 for Scholarly-QALD dataset. Firstly, we extract the
context pertaining to the question from different structured and unstructured
data sources: DBLP, SemOpenAlex knowledge graphs and Wikipedia text. Secondly,
we implement prompt engineering to improve the information retrieval
performance of the LLM. Our approach achieved an F1 score of 40% and also
observed some anomalous responses from the LLM, that are discussed in the final
part of the paper.

æè¦ï¼å­¸è¡äº¤æµæ¯ä¸åå¿«éæé·çé åï¼åå«äºè±å¯çç¥è­ãç¶èï¼ç±æ¼å¶éçµæ§ååæä»¶æ ¼å¼ï¼ééå³çµ±çæä»¶æª¢ç´¢æ¹æ³å¾é£å¾ä¸­èååºæç¨çè³è¨ãå­¸è¡ç¥è­åè­è§£æ±ºäºéååé¡ï¼å®ä»¥èªç¾©ç¶²è·¯åç¾æä»¶ï¼æä¾é±èçè¦è§£ãæè¦åééæ¥è©¢è¼é¬å­åãèªç¶å°ï¼å­¸è¡åè­çåç­æ´å±äºå°æ´å»£æ³åç¾çå­åæ§ãä½éåé åä¸­çä¸äºç¥è­ä»ç¶ä»¥éçµæ§åæå­åç¾ï¼å æ­¤éè¦ä¸åæ··åè§£æ±ºæ¹æ¡ä¾é²è¡åç­ç³»çµ±ãå¨æ¬æä¸­ï¼æåæåºäºä¸åä½¿ç¨éæ¾åå§ç¢¼å¤§åèªè¨æ¨¡å (LLM) çå©æ­¥é©è§£æ±ºæ¹æ¡ï¼Llama3.1 for Scholarly-QALD è³æéãé¦åï¼æåå¾ä¸åççµæ§ååéçµæ§åè³æä¾æºä¸­èåèåé¡ç¸éçèçµ¡ï¼DBLPãSemOpenAlex ç¥è­åè­åç¶­åºç¾ç§æå­ãå¶æ¬¡ï¼æåå¯¦ä½æç¤ºå·¥ç¨ä»¥æ¹å LLM çè³è¨æª¢ç´¢æè½ãæåçåæ³éå°äº 40% ç F1 åæ¸ï¼ä¸¦ä¸ä¹è§å¯å° LLM çä¸äºç°å¸¸åæï¼éäºåæå¨æ¬æçæå¾ä¸é¨åä¸­é²è¡äºè¨è«ã

##### **SGFormer: Single-Layer Graph Transformers with Approximation-Free Linear Complexity**
2409.09007v1 by Qitian Wu, Kai Yang, Hengrui Zhang, David Wipf, Junchi Yan

Learning representations on large graphs is a long-standing challenge due to
the inter-dependence nature. Transformers recently have shown promising
performance on small graphs thanks to its global attention for capturing
all-pair interactions beyond observed structures. Existing approaches tend to
inherit the spirit of Transformers in language and vision tasks, and embrace
complicated architectures by stacking deep attention-based propagation layers.
In this paper, we attempt to evaluate the necessity of adopting multi-layer
attentions in Transformers on graphs, which considerably restricts the
efficiency. Specifically, we analyze a generic hybrid propagation layer,
comprised of all-pair attention and graph-based propagation, and show that
multi-layer propagation can be reduced to one-layer propagation, with the same
capability for representation learning. It suggests a new technical path for
building powerful and efficient Transformers on graphs, particularly through
simplifying model architectures without sacrificing expressiveness. As
exemplified by this work, we propose a Simplified Single-layer Graph
Transformers (SGFormer), whose main component is a single-layer global
attention that scales linearly w.r.t. graph sizes and requires none of any
approximation for accommodating all-pair interactions. Empirically, SGFormer
successfully scales to the web-scale graph ogbn-papers100M, yielding
orders-of-magnitude inference acceleration over peer Transformers on
medium-sized graphs, and demonstrates competitiveness with limited labeled
data.

æè¦ï¼å¨å¤§ååè¡¨ä¸å­¸ç¿è¡¨å¾µç±æ¼ç¸äºä¾è³´çæ§è³ªèæçºä¸é é·æçææ°ãç±æ¼ Transfomer è½å¤ éå°æææå°äºåé²è¡å¨å±éæ³¨ï¼è¶è¶è§æ¸¬çµæ§ï¼å æ­¤æè¿å¨å°ååè¡¨ä¸å±ç¾åºä»¤äººæ»¿æçæè½ãç¾æçæ¹æ³å¾åæ¼ç¹¼æ¿ Transformer å¨èªè¨åè¦è¦ºä»»åä¸­çç²¾ç¥ï¼ä¸¦ééå çåºæ¼æ·±åº¦éæ³¨çå³æ­å±¤ä¾æ¡ç¨è¤éçæ¶æ§ãå¨æ¬æä¸­ï¼æååè©¦è©ä¼°å¨åè¡¨ä¸æ¡ç¨å¤å±¤æ³¨æå Transformer çå¿è¦æ§ï¼éæ¥µå¤§å°éå¶äºæçãå·é«ä¾èªªï¼æååæäºä¸åéç¨çæ··åå³æ­å±¤ï¼å®åå«æææå°æ³¨æåååºæ¼åè¡¨çå³æ­ï¼ä¸¦è¡¨æå¤å±¤å³æ­å¯ä»¥ç°¡åçºå®å±¤å³æ­ï¼å·æç¸åçè¡¨å¾µå­¸ç¿è½åãéçºå¨åè¡¨ä¸æ§å»ºå¼·å¤§èé«æç Transformer æä¾äºä¸æ¢æ°çæè¡è·¯å¾ï¼ç¹å¥æ¯ééç°¡åæ¨¡åæ¶æ§ï¼èç¡éç§ç²è¡¨éè½åãæ­£å¦éé å·¥ä½æä¾è­çï¼æåæåºäºä¸åç°¡åçå®å±¤åå½¢ Transformer (SGFormer)ï¼å¶ä¸»è¦çµæé¨åæ¯ä¸åå®å±¤å¨å±æ³¨æåï¼å®èåå½¢å¤§å°æç·æ§æ¯ä¾ï¼ä¸¦ä¸ä¸éè¦ä»»ä½è¿ä¼¼ä¾é©ææææå°äºåãæ ¹æç¶é©ï¼SGFormer æåå°æ´å±å°ç¶²è·¯è¦æ¨¡çåè¡¨ ogbn-papers100Mï¼å¨ä¸­ç­å¤§å°çåè¡¨ä¸ç¢çäºæ¯åå Transformer å¿«å¹¾åæ¸éç´çæ¨è«å éï¼ä¸¦è­æäºå¨æ¨ç±¤è³ææéçææ³ä¸å·æç«¶ç­åã

##### **Exploring Graph Structure Comprehension Ability of Multimodal Large Language Models: Case Studies**
2409.08864v1 by Zhiqiang Zhong, Davide Mottin

Large Language Models (LLMs) have shown remarkable capabilities in processing
various data structures, including graphs. While previous research has focused
on developing textual encoding methods for graph representation, the emergence
of multimodal LLMs presents a new frontier for graph comprehension. These
advanced models, capable of processing both text and images, offer potential
improvements in graph understanding by incorporating visual representations
alongside traditional textual data. This study investigates the impact of graph
visualisations on LLM performance across a range of benchmark tasks at node,
edge, and graph levels. Our experiments compare the effectiveness of multimodal
approaches against purely textual graph representations. The results provide
valuable insights into both the potential and limitations of leveraging visual
graph modalities to enhance LLMs' graph structure comprehension abilities.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨èçåç¨®æ¸æçµæ§ï¼åæ¬åå½¢ï¼æ¹é¢è¡¨ç¾åºéå¡çè½åãåç®¡ååçç ç©¶èéæ¼éç¼åå½¢è¡¨ç¤ºçææ¬ç·¨ç¢¼æ¹æ³ï¼ä½å¤æ¨¡æ LLM çåºç¾çºåå½¢çè§£æä¾äºæ°çé åãéäºåé²çæ¨¡åè½å¤ èçææ¬åååï¼ééçµåè¦è¦ºè¡¨ç¤ºèå³çµ±ææ¬è³æï¼æä¾åå½¢çè§£çæ½å¨æ¹é²ãæ¬ç ç©¶æ¢è¨åå½¢è¦è¦ºåå° LLM å¨ç¯é»ãéç·£ååå½¢å±¤ç´ä¸ç³»ååºæºä»»åçæè½å½±é¿ãæåçå¯¦é©æ¯è¼äºå¤æ¨¡ææ¹æ³èç´ææ¬åå½¢è¡¨ç¤ºçæææ§ãçµææä¾äºæå¹å¼çè¦è§£ï¼äºè§£å©ç¨è¦è¦ºåå½¢æ¨¡æä¾å¢å¼· LLM åå½¢çµæ§çè§£è½åçæ½åèéå¶ã

##### **A RAG Approach for Generating Competency Questions in Ontology Engineering**
2409.08820v1 by Xueli Pan, Jacco van Ossenbruggen, Victor de Boer, Zhisheng Huang

Competency question (CQ) formulation is central to several ontology
development and evaluation methodologies. Traditionally, the task of crafting
these competency questions heavily relies on the effort of domain experts and
knowledge engineers which is often time-consuming and labor-intensive. With the
emergence of Large Language Models (LLMs), there arises the possibility to
automate and enhance this process. Unlike other similar works which use
existing ontologies or knowledge graphs as input to LLMs, we present a
retrieval-augmented generation (RAG) approach that uses LLMs for the automatic
generation of CQs given a set of scientific papers considered to be a domain
knowledge base. We investigate its performance and specifically, we study the
impact of different number of papers to the RAG and different temperature
setting of the LLM. We conduct experiments using GPT-4 on two domain ontology
engineering tasks and compare results against ground-truth CQs constructed by
domain experts. Empirical assessments on the results, utilizing evaluation
metrics (precision and consistency), reveal that compared to zero-shot
prompting, adding relevant domain knowledge to the RAG improves the performance
of LLMs on generating CQs for concrete ontology engineering tasks.

æè¦ï¼è½ååé¡ (CQ) çå¶å®æ¯å¹¾åæ¬ä½è«ç¼å±åè©ä¼°æ¹æ³çä¸­å¿ãå³çµ±ä¸ï¼å¶å®éäºè½ååé¡çä»»åå¾å¤§ç¨åº¦ä¸ä¾è³´æ¼é åå°å®¶åç¥è­å·¥ç¨å¸«çåªåï¼ééå¸¸æ¯èæä¸ååå¯éçãé¨èå¤§åèªè¨æ¨¡å (LLM) çåºç¾ï¼èªåååå¢å¼·æ­¤éç¨çå¯è½æ§åºç¾äºãèå¶ä»ä½¿ç¨ç¾ææ¬ä½è«æç¥è­åè­ä½çº LLM è¼¸å¥çé¡ä¼¼å·¥ä½ä¸åï¼æåæåºäºä¸ç¨®æª¢ç´¢å¢å¼·çæ (RAG) æ¹æ³ï¼è©²æ¹æ³ä½¿ç¨ LLM èªåçæè¢«èªçºæ¯é åç¥è­åº«çä¸çµç§å­¸è«æç CQãæåç ç©¶å¶æ§è½ï¼ç¹å¥æ¯æåç ç©¶ä¸åæ¸éçè«æå° RAG çå½±é¿å LLM çä¸åæº«åº¦è¨­ç½®ãæåä½¿ç¨ GPT-4 å°å©åé åæ¬ä½è«å·¥ç¨ä»»åé²è¡å¯¦é©ï¼ä¸¦å°çµæèç±é åå°å®¶æ§é ççå¯¦ CQ é²è¡æ¯è¼ãå©ç¨è©ä¼°ææ¨ï¼ç²¾ç¢ºåº¦åä¸è´æ§ï¼å°çµæé²è¡çå¯¦è­è©ä¼°è¡¨æï¼èé¶æ¬¡æç¤ºç¸æ¯ï¼å°ç¸éé åç¥è­æ·»å å° RAG å¯ä»¥æé« LLM å¨çºå·é«æ¬ä½è«å·¥ç¨ä»»åçæ CQ æ¹é¢çæ§è½ã

##### **ATFLRec: A Multimodal Recommender System with Audio-Text Fusion and Low-Rank Adaptation via Instruction-Tuned Large Language Model**
2409.08543v1 by Zezheng Qin

Recommender Systems (RS) play a pivotal role in boosting user satisfaction by
providing personalized product suggestions in domains such as e-commerce and
entertainment. This study examines the integration of multimodal data text and
audio into large language models (LLMs) with the aim of enhancing
recommendation performance. Traditional text and audio recommenders encounter
limitations such as the cold-start problem, and recent advancements in LLMs,
while promising, are computationally expensive. To address these issues,
Low-Rank Adaptation (LoRA) is introduced, which enhances efficiency without
compromising performance. The ATFLRec framework is proposed to integrate audio
and text modalities into a multimodal recommendation system, utilizing various
LoRA configurations and modality fusion techniques. Results indicate that
ATFLRec outperforms baseline models, including traditional and graph neural
network-based approaches, achieving higher AUC scores. Furthermore, separate
fine-tuning of audio and text data with distinct LoRA modules yields optimal
performance, with different pooling methods and Mel filter bank numbers
significantly impacting performance. This research offers valuable insights
into optimizing multimodal recommender systems and advancing the integration of
diverse data modalities in LLMs.

æè¦ï¼æ¨è¦ç³»çµ± (RS) å¨æåä½¿ç¨èæ»¿æåº¦ä¸­æ®æ¼èèè¶³è¼éçè§è²ï¼å®å¨é»å­åååå¨æ¨ç­é åæä¾åäººåçç¢åå»ºè­°ãæ¬ç ç©¶æ¢è¨å°å¤æ¨¡æè³ææå­åé³è¨æ´åå°å¤§åèªè¨æ¨¡å (LLM) ä¸­ï¼ä»¥å¢å¼·æ¨è¦æè½ãå³çµ±çæå­åé³è¨æ¨è¦å¨æéå°å·åååé¡ç­éå¶ï¼è LLM çææ°é²å±éç¶å¾æåæ¯ï¼ä½è¨ç®ææ¬å¾é«ãçºäºè§£æ±ºéäºåé¡ï¼å¼å¥äºä½ç§©é©æ (LoRA)ï¼å®å¨ä¸å½±é¿æè½çææ³ä¸æåäºæçãATFLRec æ¡æ¶è¢«æåºä¾å°é³è¨åæå­æ¨¡ææ´åå°å¤æ¨¡ææ¨è¦ç³»çµ±ä¸­ï¼å©ç¨åç¨® LoRA éç½®åæ¨¡æèåæè¡ãçµæè¡¨æï¼ATFLRec åªæ¼åºç·æ¨¡åï¼åæ¬å³çµ±ååºæ¼åç¥ç¶ç¶²è·¯çæ¹æ³ï¼éå°äºæ´é«ç AUC åæ¸ãæ­¤å¤ï¼ä½¿ç¨ä¸åç LoRA æ¨¡çµå°é³è¨åæå­è³æé²è¡å®ç¨å¾®èª¿æç¢çæä½³æè½ï¼ä¸åçæ± åæ¹æ³å Mel æ¿¾æ³¢å¨çµæ¸æå°æè½ç¢çé¡¯èå½±é¿ãæ¬ç ç©¶æä¾äºå¯¶è²´çè¦è§£ï¼ç¨æ¼æä½³åå¤æ¨¡ææ¨è¦ç³»çµ±ï¼ä¸¦æ¨åå°ä¸åçè³ææ¨¡ææ´åå° LLM ä¸­ã

##### **What Makes a Maze Look Like a Maze?**
2409.08202v1 by Joy Hsu, Jiayuan Mao, Joshua B. Tenenbaum, Noah D. Goodman, Jiajun Wu

A unique aspect of human visual understanding is the ability to flexibly
interpret abstract concepts: acquiring lifted rules explaining what they
symbolize, grounding them across familiar and unfamiliar contexts, and making
predictions or reasoning about them. While off-the-shelf vision-language models
excel at making literal interpretations of images (e.g., recognizing object
categories such as tree branches), they still struggle to make sense of such
visual abstractions (e.g., how an arrangement of tree branches may form the
walls of a maze). To address this challenge, we introduce Deep Schema Grounding
(DSG), a framework that leverages explicit structured representations of visual
abstractions for grounding and reasoning. At the core of DSG are
schemas--dependency graph descriptions of abstract concepts that decompose them
into more primitive-level symbols. DSG uses large language models to extract
schemas, then hierarchically grounds concrete to abstract components of the
schema onto images with vision-language models. The grounded schema is used to
augment visual abstraction understanding. We systematically evaluate DSG and
different methods in reasoning on our new Visual Abstractions Dataset, which
consists of diverse, real-world images of abstract concepts and corresponding
question-answer pairs labeled by humans. We show that DSG significantly
improves the abstract visual reasoning performance of vision-language models,
and is a step toward human-aligned understanding of visual abstractions.

æè¦ï¼äººé¡è¦è¦ºçè§£çç¨ç¹é¢åå¨æ¼éæ´»è©®éæ½è±¡æ¦å¿µçè½åï¼ç²åè§£éå¶è±¡å¾µæç¾©çæåè¦åï¼å¨çæåä¸çæçèæ¯ä¸å¥ å®å¶åºç¤ï¼ä¸¦å°å¶é²è¡é æ¸¬ææ¨çãéç¶ç¾æçè¦è¦ºèªè¨æ¨¡åæé·å°å½±åé²è¡å­é¢è©®éï¼ä¾å¦è¾¨è­æ¨¹æç­ç©é«é¡å¥ï¼ï¼ä½å®åå¨çè§£æ­¤é¡è¦è¦ºæ½è±¡æ¦å¿µæä»æå°é£ï¼ä¾å¦æ¨¹æçæåå¦ä½å½¢æè¿·å®®ççå£ï¼ãçºäºæå°æ­¤ææ°ï¼æåå¼å¥äºæ·±åº¦æ¨¡å¼åºç¤ï¼DSGï¼ï¼éæ¯ä¸åæ¡æ¶ï¼å©ç¨è¦è¦ºæ½è±¡æ¦å¿µçæç¢ºçµæ§åè¡¨ç¤ºä¾é²è¡åºç¤åæ¨çãDSG çæ ¸å¿æ¯æ¨¡å¼ââæ½è±¡æ¦å¿µçä¾è³´åæè¿°ï¼å°å¶åè§£çºæ´åå§å±¤ç´çç¬¦èãDSG ä½¿ç¨å¤§åèªè¨æ¨¡åä¾æåæ¨¡å¼ï¼ç¶å¾å°æ¨¡å¼çå·é«çµæé¨ååå±¤åºç¤å°å½±åä¸ï¼ä¸¦ä½¿ç¨è¦è¦ºèªè¨æ¨¡åãåºç¤æ¨¡å¼ç¨æ¼æ´åè¦è¦ºæ½è±¡çè§£ãæåç³»çµ±æ§å°è©ä¼°äº DSG åæåçæ°è¦è¦ºæ½è±¡è³æéä¸çä¸åæ¨çæ¹æ³ï¼è©²è³æéåå«åç¨®çå¯¦ä¸ççæ½è±¡æ¦å¿µå½±åï¼ä»¥åç±äººé¡æ¨è¨çå°æåé¡è§£ç­å°ãæåè­æ DSG å¤§å¹æåäºè¦è¦ºèªè¨æ¨¡åçæ½è±¡è¦è¦ºæ¨çæè½ï¼ä¸¦ä¸æèèäººé¡ä¸è´çè¦è¦ºæ½è±¡çè§£éé²ä¸æ­¥ã

##### **Towards a graph-based foundation model for network traffic analysis**
2409.08111v1 by Louis Van Langendonck, Ismael Castell-Uroz, Pere Barlet-Ros

Foundation models have shown great promise in various fields of study. A
potential application of such models is in computer network traffic analysis,
where these models can grasp the complexities of network traffic dynamics and
adapt to any specific task or network environment with minimal fine-tuning.
Previous approaches have used tokenized hex-level packet data and the model
architecture of large language transformer models. We propose a new, efficient
graph-based alternative at the flow-level. Our approach represents network
traffic as a dynamic spatio-temporal graph, employing a self-supervised link
prediction pretraining task to capture the spatial and temporal dynamics in
this network graph framework. To evaluate the effectiveness of our approach, we
conduct a few-shot learning experiment for three distinct downstream network
tasks: intrusion detection, traffic classification, and botnet classification.
Models finetuned from our pretrained base achieve an average performance
increase of 6.87\% over training from scratch, demonstrating their ability to
effectively learn general network traffic dynamics during pretraining. This
success suggests the potential for a large-scale version to serve as an
operational foundational model.

æè¦ï¼åºç¤æ¨¡åå·²å¨ååç ç©¶é åä¸­å±ç¾åºæ¥µå¤§çåæ¯ãæ­¤é¡æ¨¡åçæ½å¨æç¨ä¹ä¸å¨æ¼é»è¦ç¶²è·¯æµéåæï¼å¶ä¸­éäºæ¨¡åå¯ä»¥ææ¡ç¶²è·¯æµéåæçè¤éæ§ï¼ä¸¦ä»¥æå°çå¾®èª¿é©æä»»ä½ç¹å®ä»»åæç¶²è·¯ç°å¢ãååçåæ³å·²ä½¿ç¨æ¨è¨ååå­é²ä½å±¤ç´å°åè³æåå¤§åèªè¨è½æå¨æ¨¡åçæ¨¡åæ¶æ§ãæåæåºä¸åæ°çãææçæµç¨å±¤ç´åå½¢åæ¿ä»£æ¹æ¡ãæåçåæ³å°ç¶²è·¯æµéè¡¨ç¤ºçºåææç©ºåå½¢ï¼æ¡ç¨èªæç£ç£é£çµé æ¸¬é è¨ç·´ä»»åä¾æææ­¤ç¶²è·¯åå½¢æ¶æ§ä¸­çç©ºéåæéåæãçºäºè©ä¼°æååæ³çæææ§ï¼æåå°ä¸åä¸åçä¸æ¸¸ç¶²è·¯ä»»åï¼å¥ä¾µåµæ¸¬ãæµéåé¡åæ®­å±ç¶²è·¯åé¡ï¼é²è¡å°éå­¸ç¿å¯¦é©ãå¾æåçé è¨ç·´åºç¤å¾®èª¿çæ¨¡åï¼å¶å¹³åæè½æå 6.87%ï¼é«æ¼å¾é ­è¨ç·´ï¼éè­æäºå®åå¨é è¨ç·´æéææå­¸ç¿ä¸è¬ç¶²è·¯æµéåæçè½åãéé æåé¡¯ç¤ºåºå¤§è¦æ¨¡çæ¬ææ½åä½çºéä½åºç¤æ¨¡åã

##### **Learning Rules from KGs Guided by Language Models**
2409.07869v1 by Zihang Peng, Daria Stepanova, Vinh Thinh Ho, Heike Adel, Alessandra Russo, Simon Ott

Advances in information extraction have enabled the automatic construction of
large knowledge graphs (e.g., Yago, Wikidata or Google KG), which are widely
used in many applications like semantic search or data analytics. However, due
to their semi-automatic construction, KGs are often incomplete. Rule learning
methods, concerned with the extraction of frequent patterns from KGs and
casting them into rules, can be applied to predict potentially missing facts. A
crucial step in this process is rule ranking. Ranking of rules is especially
challenging over highly incomplete or biased KGs (e.g., KGs predominantly
storing facts about famous people), as in this case biased rules might fit the
data best and be ranked at the top based on standard statistical metrics like
rule confidence. To address this issue, prior works proposed to rank rules not
only relying on the original KG but also facts predicted by a KG embedding
model. At the same time, with the recent rise of Language Models (LMs), several
works have claimed that LMs can be used as alternative means for KG completion.
In this work, our goal is to verify to which extent the exploitation of LMs is
helpful for improving the quality of rule learning systems.

æè¦ï¼è³è¨èåçé²å±å·²è½èªåå»ºæ§å¤§åç¥è­åè­ï¼ä¾å¦ YagoãWikidata æ Google KGï¼ï¼éäºç¥è­åè­å»£æ³ç¨æ¼è¨±å¤æç¨ç¨å¼ï¼ä¾å¦èªææå°æè³æåæãç¶èï¼ç±æ¼éäºç¥è­åè­æ¯åèªåå»ºæ§çï¼å æ­¤éå¸¸ä¸¦ä¸å®æ´ãè¦åå­¸ç¿æ¹æ³èéæ¼å¾ç¥è­åè­ä¸­èåé »ç¹æ¨¡å¼ï¼ä¸¦å°å®åè½æçºè¦åï¼å¯æç¨æ¼é æ¸¬æ½å¨éºå¤±çäºå¯¦ãæ­¤éç¨ä¸­çä¸åééµæ­¥é©æ¯è¦åæåºãè¦åæåºå¨é«åº¦ä¸å®æ´ææåå·®çç¥è­åè­ï¼ä¾å¦ï¼ä¸»è¦å²å­åäººäºå¯¦çç¥è­åè­ï¼ä¸­ç¹å¥å·æææ°æ§ï¼å çºå¨éç¨®ææ³ä¸ï¼æåå·®çè¦åå¯è½æç¬¦åè³æï¼ä¸¦æ ¹ææ¨æºçµ±è¨éåº¦ï¼ä¾å¦è¦åä¿¡å¿ï¼æå¨æåé¢ãçºäºè§£æ±ºéååé¡ï¼ååçç ç©¶æåºä¸åªä¾è³´åå§ç¥è­åè­ï¼éè¦ä¾è³´ç¥è­åè­åµå¥æ¨¡åé æ¸¬çäºå¯¦ä¾å°è¦åé²è¡æåºãåæï¼é¨èèªè¨æ¨¡å (LM) çèèµ·ï¼ä¸äºç ç©¶è²ç¨± LM å¯ç¨ä½ç¥è­åè­å®æçæ¿ä»£æ¹æ³ãå¨éé ç ç©¶ä¸­ï¼æåçç®æ¨æ¯é©è­å©ç¨ LM å¨å¤å¤§ç¨åº¦ä¸æå©æ¼æåè¦åå­¸ç¿ç³»çµ±çåè³ªã

##### **Multi-object event graph representation learning for Video Question Answering**
2409.07747v1 by Yanan Wang, Shuichiro Haruta, Donghuo Zeng, Julio Vizcarra, Mori Kurokawa

Video question answering (VideoQA) is a task to predict the correct answer to
questions posed about a given video. The system must comprehend spatial and
temporal relationships among objects extracted from videos to perform causal
and temporal reasoning. While prior works have focused on modeling individual
object movements using transformer-based methods, they falter when capturing
complex scenarios involving multiple objects (e.g., "a boy is throwing a ball
in a hoop"). We propose a contrastive language event graph representation
learning method called CLanG to address this limitation. Aiming to capture
event representations associated with multiple objects, our method employs a
multi-layer GNN-cluster module for adversarial graph representation learning,
enabling contrastive learning between the question text and its relevant
multi-object event graph. Our method outperforms a strong baseline, achieving
up to 2.2% higher accuracy on two challenging VideoQA datasets, NExT-QA and
TGIF-QA-R. In particular, it is 2.8% better than baselines in handling causal
and temporal questions, highlighting its strength in reasoning multiple
object-based events.

æè¦ï¼å½±çåç­ (VideoQA) æ¯ä¸é ä»»åï¼ç¨æ¼é æ¸¬éå°çµ¦å®å½±çæåºçåé¡çæ­£ç¢ºç­æ¡ãç³»çµ±å¿é äºè§£å¾å½±çä¸­æåçç©ä»¶ä¹éçç©ºéåæééä¿ï¼æè½å·è¡å æéä¿åæéæ¨çãéç¶ååçç ç©¶éä¸­æ¼ä½¿ç¨åºæ¼Transformerçæ¨¡åä¾å»ºæ¨¡åå¥ç©ä»¶çåä½ï¼ä½å¨æææ¶åå¤åç©ä»¶çè¤éå ´æ¯ï¼ä¾å¦ãä¸åç·å­©æ­£å¨å°çæé²ç±æ¡ãï¼æï¼å®åæåºç¾åé¡ãæåæåºäºä¸åå°æ¯å¼èªè¨äºä»¶åè¡¨è¡¨ç¤ºå­¸ç¿æ¹æ³ï¼ç¨±çº CLanGï¼ä»¥è§£æ±ºæ­¤éå¶ãçºäºææèå¤åç©ä»¶ç¸éçäºä»¶è¡¨ç¤ºï¼æåçæ¨¡åæ¡ç¨å¤å±¤ GNN éç¾¤æ¨¡çµé²è¡å°æå¼åè¡¨è¡¨ç¤ºå­¸ç¿ï¼ä½¿åé¡æå­åå¶ç¸éçå¤ç©ä»¶äºä»¶åè¡¨ä¹éè½å¤ é²è¡å°æ¯å¼å­¸ç¿ãæåçæ¨¡ååªæ¼å¼·å¤§çåºæºï¼å¨å©åå·æææ°æ§ç VideoQA è³æé NExT-QA å TGIF-QA-R ä¸éå°äºé«é 2.2% çæ´é«æºç¢ºåº¦ãç¹å¥æ¯ï¼å¨èçå æéä¿åæéåé¡æ¹é¢æ¯åºæºé«åº 2.8%ï¼çªé¡¯äºå®å¨æ¨çå¤ååºæ¼ç©ä»¶çäºä»¶æ¹é¢çåªå¢ã

##### **Demo: SGCode: A Flexible Prompt-Optimizing System for Secure Generation of Code**
2409.07368v3 by Khiem Ton, Nhi Nguyen, Mahmoud Nazzal, Abdallah Khreishah, Cristian Borcea, NhatHai Phan, Ruoming Jin, Issa Khalil, Yelong Shen

This paper introduces SGCode, a flexible prompt-optimizing system to generate
secure code with large language models (LLMs). SGCode integrates recent
prompt-optimization approaches with LLMs in a unified system accessible through
front-end and back-end APIs, enabling users to 1) generate secure code, which
is free of vulnerabilities, 2) review and share security analysis, and 3)
easily switch from one prompt optimization approach to another, while providing
insights on model and system performance. We populated SGCode on an AWS server
with PromSec, an approach that optimizes prompts by combining an LLM and
security tools with a lightweight generative adversarial graph neural network
to detect and fix security vulnerabilities in the generated code. Extensive
experiments show that SGCode is practical as a public tool to gain insights
into the trade-offs between model utility, secure code generation, and system
cost. SGCode has only a marginal cost compared with prompting LLMs. SGCode is
available at: https://sgcode.codes/.

æè¦ï¼æ¬æä»ç´¹ SGCodeï¼ä¸åå½æ§çæç¤ºæä½³åç³»çµ±ï¼ç¨æ¼çæå¤§åèªè¨æ¨¡å (LLM) çå®å¨ç¨å¼ç¢¼ãSGCode å°æè¿çæç¤ºæä½³åæ¹æ³è LLM æ´åå¨ä¸åçµ±ä¸çç³»çµ±ä¸­ï¼å¯ééåç«¯åå¾ç«¯ API å­åï¼ä½¿ç¨æ¶è½å¤  1) ç¢çå®å¨çç¨å¼ç¢¼ï¼æ²ææ¼æ´ï¼2) æª¢é±ååäº«å®å¨æ§åæï¼ä»¥å 3) å¾ä¸ç¨®æç¤ºæä½³åæ¹æ³è¼é¬åæå°å¦ä¸ç¨®ï¼åææä¾æ¨¡ååç³»çµ±æè½çè¦è§£ãæåå¨ AWS ä¼ºæå¨ä¸ä½¿ç¨ PromSec å¡«å SGCodeï¼éæ¯ä¸ç¨®ééçµå LLM åå®å¨æ§å·¥å·ï¼ä»¥åè¼éç´çæå°æåå½¢ç¥ç¶ç¶²è·¯ä¾æä½³åæç¤ºï¼ä»¥åµæ¸¬åä¿®å¾©ç¢çç¨å¼ç¢¼ä¸­çå®å¨æ§æ¼æ´çæ¹æ³ãå»£æ³çå¯¦é©é¡¯ç¤ºï¼SGCode ä½çºä¸åå¬ç¨å·¥å·ï¼å¨æ¨¡åæç¨ãå®å¨ç¨å¼ç¢¼ç¢çåç³»çµ±ææ¬ä¹éçæ¬è¡¡ä¸­ç²å¾è¦è§£ï¼æ¯å¯¦ç¨çãèæç¤º LLM ç¸æ¯ï¼SGCode åªæééææ¬ãSGCode å¯å¨ https://sgcode.codes/ åå¾ã

##### **Semantic Interoperability on Blockchain by Generating Smart Contracts Based on Knowledge Graphs**
2409.12171v1 by William Van Woensel, Oshani Seneviratne

Background: Health 3.0 allows decision making to be based on longitudinal
data from multiple institutions, from across the patient's healthcare journey.
In such a distributed setting, blockchain smart contracts can act as neutral
intermediaries to implement trustworthy decision making.
  Objective: In a distributed setting, transmitted data will be structured
using standards (such as HL7 FHIR) for semantic interoperability. In turn, the
smart contract will require interoperability with this standard, implement a
complex communication setup (e.g., using oracles), and be developed using
blockchain languages (e.g., Solidity). We propose the encoding of smart
contract logic using a high-level semantic Knowledge Graph, using concepts from
the domain standard. We then deploy this semantic KG on blockchain.
  Methods: Off-chain, a code generation pipeline compiles the KG into a
concrete smart contract, which is then deployed on-chain. Our pipeline targets
an intermediary bridge representation, which can be transpiled into a specific
blockchain language. Our choice avoids on-chain rule engines, with
unpredictable and likely higher computational cost; it is thus in line with the
economic rules of blockchain.
  Results: We applied our code generation approach to generate smart contracts
for 3 health insurance cases from Medicare. We discuss the suitability of our
approach - the need for a neutral intermediary - for a number of healthcare use
cases. Our evaluation finds that the generated contracts perform well in terms
of correctness and execution cost ("gas") on blockchain.
  Conclusions: We showed that it is feasible to automatically generate smart
contract code based on a semantic KG, in a way that respects the economic rules
of blockchain. Future work includes studying the use of Large Language Models
(LLM) in our approach, and evaluations on other blockchains.

æè¦ï¼<paragraph>èæ¯ï¼Health 3.0 åè¨±æ±ºç­å¶å®åºæ¼ä¾èªå¤åæ©æ§çç¸±åæ¸æï¼ä¾èªæ£èçé«çä¿å¥æ­·ç¨ãå¨éç¨®åå¸å¼è¨­ç½®ä¸­ï¼åå¡éæºè½åç´å¯ä»¥ä½çºä¸­ç«çä»²ä»ä¾å¯¦æ½å¼å¾ä¿¡è³´çæ±ºç­å¶å®ãç®æ¨ï¼å¨åå¸å¼è¨­ç½®ä¸­ï¼å³è¼¸çæ¸æå°ä½¿ç¨æ¨æºï¼ä¾å¦ HL7 FHIRï¼é²è¡çµæ§åï¼ä»¥å¯¦ç¾èªç¾©äºæä½æ§ãåéä¾ï¼æºè½åç´å°éè¦èæ­¤æ¨æºäºæä½ï¼å¯¦æ½è¤éçéä¿¡è¨­ç½®ï¼ä¾å¦ï¼ä½¿ç¨é è¨æ©ï¼ï¼ä¸¦ä½¿ç¨åå¡éèªè¨ï¼ä¾å¦ï¼Solidityï¼éç¼ãæåæè­°ä½¿ç¨ä¾èªé åæ¨æºçæ¦å¿µï¼ä½¿ç¨é«ç´èªç¾©ç¥è­åå°æºè½åç´éè¼¯é²è¡ç·¨ç¢¼ãç¶å¾æåå°éåèªç¾©ç¥è­åé¨ç½²å¨åå¡éä¸ãæ¹æ³ï¼éä¸ï¼ä¸åä»£ç¢¼çæç®¡éå°ç¥è­åç·¨è­¯æå·é«çæºè½åç´ï¼ç¶å¾å°å¶é¨ç½²å°éä¸ãæåçç®¡ééå°ä¸­éæ©æ¥è¡¨ç¤ºï¼å¯ä»¥è½è­¯æç¹å®çåå¡éèªè¨ãæåçé¸æé¿åäºéä¸è¦åå¼æï¼å¶ä¸å¯é æ¸¬ä¸å¯è½è¨ç®ææ¬æ´é«ï¼å æ­¤ï¼å®ç¬¦ååå¡éçç¶æ¿è¦åãçµæï¼æåæç¨æåçä»£ç¢¼çææ¹æ³ä¾çæä¾èª Medicare ç 3 åå¥åº·ä¿éªæ¡ä¾çæºè½åç´ãæåè¨è«äºæåçæ¹æ³çé©ç¨æ§ââå°ä¸­ç«ä»²ä»çéæ±ââå°æ¼è¨±å¤é«çä¿å¥ç¨ä¾ãæåçè©ä¼°ç¼ç¾ï¼çæçåç´å¨åå¡éä¸çæ­£ç¢ºæ§åå·è¡ææ¬ï¼âgasâï¼æ¹é¢è¡¨ç¾è¯å¥½ãçµè«ï¼æåè¡¨æï¼ä»¥ç¬¦ååå¡éç¶æ¿è¦åçæ¹å¼èªåçæåºæ¼èªç¾©ç¥è­åçæºè½åç´ä»£ç¢¼æ¯å¯è¡çãæªä¾çç ç©¶åæ¬ç ç©¶æåçæ¹æ³ä¸­ä½¿ç¨å¤§åèªè¨æ¨¡å (LLM)ï¼ä»¥åå°å¶ä»åå¡éçè©ä¼°ã</paragraph>


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-10**|**LatteCLIP: Unsupervised CLIP Fine-Tuning via LMM-Synthetic Texts**|Anh-Quan Cao et.al.|[2410.08211v1](http://arxiv.org/abs/2410.08211v1)|null|
|**2024-10-10**|**PointOBB-v2: Towards Simpler, Faster, and Stronger Single Point Supervised Oriented Object Detection**|Botao Ren et.al.|[2410.08210v1](http://arxiv.org/abs/2410.08210v1)|null|
|**2024-10-10**|**Emerging Pixel Grounding in Large Multimodal Models Without Grounding Supervision**|Shengcao Cao et.al.|[2410.08209v1](http://arxiv.org/abs/2410.08209v1)|null|
|**2024-10-10**|**SPA: 3D Spatial-Awareness Enables Effective Embodied Representation**|Haoyi Zhu et.al.|[2410.08208v1](http://arxiv.org/abs/2410.08208v1)|null|
|**2024-10-10**|**Mono-InternVL: Pushing the Boundaries of Monolithic Multimodal Large Language Models with Endogenous Visual Pre-training**|Gen Luo et.al.|[2410.08202v1](http://arxiv.org/abs/2410.08202v1)|null|
|**2024-10-10**|**From Exploration to Mastery: Enabling LLMs to Master Tools via Self-Driven Interactions**|Changle Qu et.al.|[2410.08197v1](http://arxiv.org/abs/2410.08197v1)|[link](https://github.com/quchangle1/DRAFT)|
|**2024-10-10**|**MathCoder2: Better Math Reasoning from Continued Pretraining on Model-translated Mathematical Code**|Zimu Lu et.al.|[2410.08196v1](http://arxiv.org/abs/2410.08196v1)|[link](https://github.com/mathllm/mathcoder2)|
|**2024-10-10**|**GenARM: Reward Guided Generation with Autoregressive Reward Model for Test-time Alignment**|Yuancheng Xu et.al.|[2410.08193v1](http://arxiv.org/abs/2410.08193v1)|null|
|**2024-10-10**|**DifFRelight: Diffusion-Based Facial Performance Relighting**|Mingming He et.al.|[2410.08188v1](http://arxiv.org/abs/2410.08188v1)|null|
|**2024-10-10**|**MRAG-Bench: Vision-Centric Evaluation for Retrieval-Augmented Multimodal Models**|Wenbo Hu et.al.|[2410.08182v1](http://arxiv.org/abs/2410.08182v1)|null|
|**2024-10-10**|**Sample then Identify: A General Framework for Risk Control and Assessment in Multimodal Large Language Models**|Qingni Wang et.al.|[2410.08174v1](http://arxiv.org/abs/2410.08174v1)|null|
|**2024-10-10**|**On the Evaluation of Generative Robotic Simulations**|Feng Chen et.al.|[2410.08172v1](http://arxiv.org/abs/2410.08172v1)|null|
|**2024-10-10**|**Agent S: An Open Agentic Framework that Uses Computers Like a Human**|Saaket Agashe et.al.|[2410.08164v1](http://arxiv.org/abs/2410.08164v1)|[link](https://github.com/simular-ai/agent-s)|
|**2024-10-10**|**The Effect of Surprisal on Reading Times in Information Seeking and Repeated Reading**|Keren Gruteke Klein et.al.|[2410.08162v1](http://arxiv.org/abs/2410.08162v1)|[link](https://github.com/lacclab/surprisal-non-ordinary-reading)|
|**2024-10-10**|**Rewarding Progress: Scaling Automated Process Verifiers for LLM Reasoning**|Amrith Setlur et.al.|[2410.08146v1](http://arxiv.org/abs/2410.08146v1)|null|
|**2024-10-10**|**Insight Over Sight? Exploring the Vision-Knowledge Conflicts in Multimodal LLMs**|Xiaoyuan Liu et.al.|[2410.08145v1](http://arxiv.org/abs/2410.08145v1)|null|
|**2024-10-10**|**DelTA: An Online Document-Level Translation Agent Based on Multi-Level Memory**|Yutong Wang et.al.|[2410.08143v1](http://arxiv.org/abs/2410.08143v1)|[link](https://github.com/yutongwang1216/docmtagent)|
|**2024-10-10**|**Steering Masked Discrete Diffusion Models via Discrete Denoising Posterior Prediction**|Jarrid Rector-Brooks et.al.|[2410.08134v1](http://arxiv.org/abs/2410.08134v1)|null|
|**2024-10-10**|**Assessing Episodic Memory in LLMs with Sequence Order Recall Tasks**|Mathis Pink et.al.|[2410.08133v1](http://arxiv.org/abs/2410.08133v1)|null|
|**2024-10-10**|**Think Beyond Size: Dynamic Prompting for More Effective Reasoning**|Kamesh R et.al.|[2410.08130v1](http://arxiv.org/abs/2410.08130v1)|null|
|**2024-10-10**|**Mars: Situated Inductive Reasoning in an Open-World Environment**|Xiaojuan Tang et.al.|[2410.08126v1](http://arxiv.org/abs/2410.08126v1)|null|
|**2024-10-10**|**Heterogeneous Graph Auto-Encoder for CreditCard Fraud Detection**|Moirangthem Tiken Singh et.al.|[2410.08121v1](http://arxiv.org/abs/2410.08121v1)|null|
|**2024-10-10**|**Optima: Optimizing Effectiveness and Efficiency for LLM-Based Multi-Agent System**|Weize Chen et.al.|[2410.08115v1](http://arxiv.org/abs/2410.08115v1)|null|
|**2024-10-10**|**Robust AI-Generated Text Detection by Restricted Embeddings**|Kristian Kuznetsov et.al.|[2410.08113v1](http://arxiv.org/abs/2410.08113v1)|null|
|**2024-10-10**|**Active Fourier Auditor for Estimating Distributional Properties of ML Models**|Ayoub Ajarra et.al.|[2410.08111v1](http://arxiv.org/abs/2410.08111v1)|null|
|**2024-10-10**|**A Closer Look at Machine Unlearning for Large Language Models**|Xiaojian Yuan et.al.|[2410.08109v1](http://arxiv.org/abs/2410.08109v1)|[link](https://github.com/sail-sg/closer-look-llm-unlearning)|
|**2024-10-10**|**What Makes Large Language Models Reason in (Multi-Turn) Code Generation?**|Kunhao Zheng et.al.|[2410.08105v1](http://arxiv.org/abs/2410.08105v1)|null|
|**2024-10-10**|**Multi-Agent Collaborative Data Selection for Efficient LLM Pretraining**|Tianyi Bai et.al.|[2410.08102v1](http://arxiv.org/abs/2410.08102v1)|null|
|**2024-10-10**|**A Generative AI Technique for Synthesizing a Digital Twin for U.S. Residential Solar Adoption and Generation**|Aparna Kishore et.al.|[2410.08098v1](http://arxiv.org/abs/2410.08098v1)|null|
|**2024-10-10**|**Can Knowledge Graphs Make Large Language Models More Trustworthy? An Empirical Study over Open-ended Question Answering**|Yuan Sui et.al.|[2410.08085v1](http://arxiv.org/abs/2410.08085v1)|null|
|**2024-10-10**|**Packing Analysis: Packing Is More Appropriate for Large Models or Datasets in Supervised Fine-tuning**|Shuhe Wang et.al.|[2410.08081v1](http://arxiv.org/abs/2410.08081v1)|[link](https://github.com/shuhewang1998/packing-analysis)|
|**2024-10-10**|**Unlearning-based Neural Interpretations**|Ching Lam Choi et.al.|[2410.08069v1](http://arxiv.org/abs/2410.08069v1)|null|
|**2024-10-10**|**Teaching-Inspired Integrated Prompting Framework: A Novel Approach for Enhancing Reasoning in Large Language Models**|Wenting Tan et.al.|[2410.08068v1](http://arxiv.org/abs/2410.08068v1)|[link](https://github.com/sallytan13/teaching-inspired-prompting)|
|**2024-10-10**|**Reward-Augmented Data Enhances Direct Preference Alignment of LLMs**|Shenao Zhang et.al.|[2410.08067v1](http://arxiv.org/abs/2410.08067v1)|[link](https://github.com/shenao-zhang/reward-augmented-preference)|
|**2024-10-10**|**Closing the Loop: Learning to Generate Writing Feedback via Language Model Simulated Student Revisions**|Inderjeet Nair et.al.|[2410.08058v1](http://arxiv.org/abs/2410.08058v1)|[link](https://github.com/launchnlp/PROF)|
|**2024-10-10**|**A Target-Aware Analysis of Data Augmentation for Hate Speech Detection**|Camilla Casula et.al.|[2410.08053v1](http://arxiv.org/abs/2410.08053v1)|null|
|**2024-10-10**|**VerifierQ: Enhancing LLM Test Time Compute with Q-Learning-based Verifiers**|Jianing Qi et.al.|[2410.08048v1](http://arxiv.org/abs/2410.08048v1)|null|
|**2024-10-10**|**Scaling Up Your Kernels: Large Kernel Design in ConvNets towards Universal Representations**|Yiyuan Zhang et.al.|[2410.08049v1](http://arxiv.org/abs/2410.08049v1)|[link](https://github.com/ailab-cvc/unireplknet)|
|**2024-10-10**|**Divide and Translate: Compositional First-Order Logic Translation and Verification for Complex Logical Reasoning**|Hyun Ryu et.al.|[2410.08047v1](http://arxiv.org/abs/2410.08047v1)|null|
|**2024-10-10**|**The Rise of AI-Generated Content in Wikipedia**|Creston Brooks et.al.|[2410.08044v1](http://arxiv.org/abs/2410.08044v1)|[link](https://github.com/brooksca3/wiki_collection)|
|**2024-10-10**|**Strategic Classification With Externalities**|Yiling Chen et.al.|[2410.08032v1](http://arxiv.org/abs/2410.08032v1)|null|
|**2024-10-10**|**Private Language Models via Truncated Laplacian Mechanism**|Tianhao Huang et.al.|[2410.08027v1](http://arxiv.org/abs/2410.08027v1)|null|
|**2024-10-10**|**The Computational Complexity of Circuit Discovery for Inner Interpretability**|Federico Adolfi et.al.|[2410.08025v1](http://arxiv.org/abs/2410.08025v1)|null|
|**2024-10-10**|**Pretraining Graph Transformers with Atom-in-a-Molecule Quantum Properties for Improved ADMET Modeling**|Alessio Fallani et.al.|[2410.08024v1](http://arxiv.org/abs/2410.08024v1)|[link](https://github.com/aidd-msca/GraphQPT)|
|**2024-10-10**|**GrabDAE: An Innovative Framework for Unsupervised Domain Adaptation Utilizing Grab-Mask and Denoise Auto-Encoder**|Junzhou Chen et.al.|[2410.08023v1](http://arxiv.org/abs/2410.08023v1)|null|
|**2024-10-10**|**Efficiently Learning at Test-Time: Active Fine-Tuning of LLMs**|Jonas HÃ¼botter et.al.|[2410.08020v1](http://arxiv.org/abs/2410.08020v1)|null|
|**2024-10-10**|**LLM Cascade with Multi-Objective Optimal Consideration**|Kai Zhang et.al.|[2410.08014v1](http://arxiv.org/abs/2410.08014v1)|null|
|**2024-10-10**|**Towards Synergistic, Generalized, and Efficient Dual-System for Robotic Manipulation**|Qingwen Bu et.al.|[2410.08001v1](http://arxiv.org/abs/2410.08001v1)|null|
|**2024-10-10**|**Human and LLM Biases in Hate Speech Annotations: A Socio-Demographic Analysis of Annotators and Targets**|Tommaso Giorgi et.al.|[2410.07991v1](http://arxiv.org/abs/2410.07991v1)|null|
|**2024-10-10**|**Omni-MATH: A Universal Olympiad Level Mathematic Benchmark For Large Language Models**|Bofei Gao et.al.|[2410.07985v1](http://arxiv.org/abs/2410.07985v1)|null|
|**2024-10-10**|**MolMix: A Simple Yet Effective Baseline for Multimodal Molecular Representation Learning**|Andrei Manolache et.al.|[2410.07981v1](http://arxiv.org/abs/2410.07981v1)|null|
|**2024-10-10**|**Doob's Lagrangian: A Sample-Efficient Variational Approach to Transition Path Sampling**|Yuanqi Du et.al.|[2410.07974v1](http://arxiv.org/abs/2410.07974v1)|null|
|**2024-10-10**|**Towards Assurance of LLM Adversarial Robustness using Ontology-Driven Argumentation**|Tomas Bueno Momcilovic et.al.|[2410.07962v1](http://arxiv.org/abs/2410.07962v1)|null|
|**2024-10-10**|**COMPL-AI Framework: A Technical Interpretation and LLM Benchmarking Suite for the EU Artificial Intelligence Act**|Philipp Guldimann et.al.|[2410.07959v1](http://arxiv.org/abs/2410.07959v1)|null|
|**2024-10-10**|**Disease Entity Recognition and Normalization is Improved with Large Language Model Derived Synthetic Normalized Mentions**|Kuleen Sasse et.al.|[2410.07951v1](http://arxiv.org/abs/2410.07951v1)|null|
|**2024-10-10**|**The Function-Representation Unification Framework**|Alfredo Ibias et.al.|[2410.07928v1](http://arxiv.org/abs/2410.07928v1)|null|
|**2024-10-10**|**InstructBioMol: Advancing Biomolecule Understanding and Design Following Human Instructions**|Xiang Zhuang et.al.|[2410.07919v1](http://arxiv.org/abs/2410.07919v1)|null|
|**2024-10-10**|**ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation**|LÃ©o Machado et.al.|[2410.07908v1](http://arxiv.org/abs/2410.07908v1)|null|
|**2024-10-10**|**Executing Arithmetic: Fine-Tuning Large Language Models as Turing Machines**|Junyu Lai et.al.|[2410.07896v1](http://arxiv.org/abs/2410.07896v1)|[link](https://github.com/NJUDeepEngine/CAEF)|
|**2024-10-10**|**Unsupervised Data Validation Methods for Efficient Model Training**|Yurii Paniv et.al.|[2410.07880v1](http://arxiv.org/abs/2410.07880v1)|null|
|**2024-10-10**|**Benchmarking Agentic Workflow Generation**|Shuofei Qiao et.al.|[2410.07869v1](http://arxiv.org/abs/2410.07869v1)|null|
|**2024-10-10**|**System-2 Reasoning via Generality and Adaptation**|Sejin Kim et.al.|[2410.07866v1](http://arxiv.org/abs/2410.07866v1)|null|
|**2024-10-10**|**RDT-1B: a Diffusion Foundation Model for Bimanual Manipulation**|Songming Liu et.al.|[2410.07864v1](http://arxiv.org/abs/2410.07864v1)|null|
|**2024-10-10**|**From Logits to Hierarchies: Hierarchical Clustering made Simple**|Emanuele Palumbo et.al.|[2410.07858v1](http://arxiv.org/abs/2410.07858v1)|null|
|**2024-10-10**|**Enhancing Language Model Reasoning via Weighted Reasoning in Self-Consistency**|Tim Knappe et.al.|[2410.07839v1](http://arxiv.org/abs/2410.07839v1)|null|
|**2024-10-10**|**MinorityPrompt: Text to Minority Image Generation via Prompt Optimization**|Soobin Um et.al.|[2410.07838v1](http://arxiv.org/abs/2410.07838v1)|[link](https://github.com/anonymous-6898/MinorityPrompt)|
|**2024-10-10**|**Masked Generative Priors Improve World Models Sequence Modelling Capabilities**|Cristian Meo et.al.|[2410.07836v1](http://arxiv.org/abs/2410.07836v1)|null|
|**2024-10-10**|**NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models**|William Tan et.al.|[2410.07830v1](http://arxiv.org/abs/2410.07830v1)|null|
|**2024-10-10**|**Why do objects have many names? A study on word informativeness in language use and lexical systems**|Eleonora Gualdoni et.al.|[2410.07827v1](http://arxiv.org/abs/2410.07827v1)|null|
|**2024-10-10**|**Fine-Tuning Language Models for Ethical Ambiguity: A Comparative Study of Alignment with Human Responses**|Pranav Senthilkumar et.al.|[2410.07826v1](http://arxiv.org/abs/2410.07826v1)|null|
|**2024-10-10**|**Extracting and Transferring Abilities For Building Multi-lingual Ability-enhanced Large Language Models**|Zhipeng Chen et.al.|[2410.07825v1](http://arxiv.org/abs/2410.07825v1)|null|
|**2024-10-10**|**Mitigating Gender Bias in Code Large Language Models via Model Editing**|Zhanyue Qin et.al.|[2410.07820v1](http://arxiv.org/abs/2410.07820v1)|null|
|**2024-10-10**|**Uncovering Overfitting in Large Language Model Editing**|Mengqi Zhang et.al.|[2410.07819v1](http://arxiv.org/abs/2410.07819v1)|null|
|**2024-10-10**|**Temporal-Difference Variational Continual Learning**|Luckeciano C. Melo et.al.|[2410.07812v1](http://arxiv.org/abs/2410.07812v1)|[link](https://github.com/luckeciano/TD-VCL)|
|**2024-10-10**|**Linguistically-Informed Multilingual Instruction Tuning: Is There an Optimal Set of Languages to Tune?**|GÃ¼rkan Soykan et.al.|[2410.07809v1](http://arxiv.org/abs/2410.07809v1)|[link](https://github.com/gglab-ku/ling-informed-mit)|
|**2024-10-10**|**Rewriting Conversational Utterances with Instructed Large Language Models**|Elnara Galimzhanova et.al.|[2410.07797v1](http://arxiv.org/abs/2410.07797v1)|null|
|**2024-10-10**|**Do Current Language Models Support Code Intelligence for R Programming Language?**|ZiXiao Zhao et.al.|[2410.07793v1](http://arxiv.org/abs/2410.07793v1)|null|
|**2024-10-10**|**Modeling User Preferences with Automatic Metrics: Creating a High-Quality Preference Dataset for Machine Translation**|Sweta Agrawal et.al.|[2410.07779v1](http://arxiv.org/abs/2410.07779v1)|null|
|**2024-10-10**|**Full-Rank No More: Low-Rank Weight Training for Modern Speech Recognition Models**|Adriana Fernandez-Lopez et.al.|[2410.07771v1](http://arxiv.org/abs/2410.07771v1)|null|
|**2024-10-10**|**Dialectical Behavior Therapy Approach to LLM Prompting**|Oxana Vitman et.al.|[2410.07768v1](http://arxiv.org/abs/2410.07768v1)|null|
|**2024-10-10**|**GameTraversalBenchmark: Evaluating Planning Abilities Of Large Language Models Through Traversing 2D Game Maps**|Muhammad Umair Nasir et.al.|[2410.07765v1](http://arxiv.org/abs/2410.07765v1)|[link](https://github.com/umair-nasir14/game-traversal-benchmark)|
|**2024-10-10**|**HARIVO: Harnessing Text-to-Image Models for Video Generation**|Mingi Kwon et.al.|[2410.07763v1](http://arxiv.org/abs/2410.07763v1)|null|
|**2024-10-10**|**$\textit{Jump Your Steps}$: Optimizing Sampling Schedule of Discrete Diffusion Models**|Yong-Hyun Park et.al.|[2410.07761v1](http://arxiv.org/abs/2410.07761v1)|null|
|**2024-10-10**|**Learning Low-Level Causal Relations using a Simulated Robotic Arm**|Miroslav Cibula et.al.|[2410.07751v1](http://arxiv.org/abs/2410.07751v1)|null|
|**2024-10-10**|**StepTool: A Step-grained Reinforcement Learning Framework for Tool Learning in LLMs**|Yuanqing Yu et.al.|[2410.07745v1](http://arxiv.org/abs/2410.07745v1)|[link](https://github.com/yuyq18/steptool)|
|**2024-10-10**|**SLIM: Let LLM Learn More and Forget Less with Soft LoRA and Identity Mixture**|Jiayi Han et.al.|[2410.07739v1](http://arxiv.org/abs/2410.07739v1)|null|
|**2024-10-10**|**Enhancing Federated Domain Adaptation with Multi-Domain Prototype-Based Federated Fine-Tuning**|Jingyuan Zhang et.al.|[2410.07738v1](http://arxiv.org/abs/2410.07738v1)|null|
|**2024-10-10**|**On the Generalization Properties of Deep Learning for Aircraft Fuel Flow Estimation Models**|Gabriel Jarry et.al.|[2410.07717v1](http://arxiv.org/abs/2410.07717v1)|null|
|**2024-10-10**|**Learning Tree Pattern Transformations**|Daniel Neider et.al.|[2410.07708v1](http://arxiv.org/abs/2410.07708v1)|null|
|**2024-10-10**|**AgentBank: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories**|Yifan Song et.al.|[2410.07706v1](http://arxiv.org/abs/2410.07706v1)|null|
|**2024-10-10**|**Multi-Facet Counterfactual Learning for Content Quality Evaluation**|Jiasheng Zheng et.al.|[2410.07693v1](http://arxiv.org/abs/2410.07693v1)|null|
|**2024-10-10**|**Smart Audit System Empowered by LLM**|Xu Yao et.al.|[2410.07677v1](http://arxiv.org/abs/2410.07677v1)|null|
|**2024-10-10**|**Adversarial Robustness Overestimation and Instability in TRADES**|Jonathan Weiping Li et.al.|[2410.07675v1](http://arxiv.org/abs/2410.07675v1)|null|
|**2024-10-10**|**Multimodal Clickbait Detection by De-confounding Biases Using Causal Representation Inference**|Jianxing Yu et.al.|[2410.07673v1](http://arxiv.org/abs/2410.07673v1)|null|
|**2024-10-10**|**MACPO: Weak-to-Strong Alignment via Multi-Agent Contrastive Preference Optimization**|Yougang Lyu et.al.|[2410.07672v1](http://arxiv.org/abs/2410.07672v1)|null|
|**2024-10-10**|**DISCO: A Hierarchical Disentangled Cognitive Diagnosis Framework for Interpretable Job Recommendation**|Xiaoshan Yu et.al.|[2410.07671v1](http://arxiv.org/abs/2410.07671v1)|null|
|**2024-10-10**|**StablePrompt: Automatic Prompt Tuning using Reinforcement Learning for Large Language Models**|Minchan Kwon et.al.|[2410.07652v1](http://arxiv.org/abs/2410.07652v1)|null|
|**2024-10-10**|**Almost Minimax Optimal Best Arm Identification in Piecewise Stationary Linear Bandits**|Yunlong Hou et.al.|[2410.07638v1](http://arxiv.org/abs/2410.07638v1)|[link](https://github.com/Y-Hou/BAI-in-PSLB)|
|**2024-10-10**|**Automatic Curriculum Expert Iteration for Reliable LLM Reasoning**|Zirui Zhao et.al.|[2410.07627v1](http://arxiv.org/abs/2410.07627v1)|null|
|**2024-10-10**|**Moyun: A Diffusion-Based Model for Style-Specific Chinese Calligraphy Generation**|Kaiyuan Liu et.al.|[2410.07618v1](http://arxiv.org/abs/2410.07618v1)|null|

#### Abstracts
##### **LatteCLIP: Unsupervised CLIP Fine-Tuning via LMM-Synthetic Texts**
2410.08211v1 by Anh-Quan Cao, Maximilian Jaritz, Matthieu Guillaumin, Raoul de Charette, Loris Bazzani

Large-scale vision-language pre-trained (VLP) models (e.g., CLIP) are
renowned for their versatility, as they can be applied to diverse applications
in a zero-shot setup. However, when these models are used in specific domains,
their performance often falls short due to domain gaps or the
under-representation of these domains in the training data. While fine-tuning
VLP models on custom datasets with human-annotated labels can address this
issue, annotating even a small-scale dataset (e.g., 100k samples) can be an
expensive endeavor, often requiring expert annotators if the task is complex.
To address these challenges, we propose LatteCLIP, an unsupervised method for
fine-tuning CLIP models on classification with known class names in custom
domains, without relying on human annotations. Our method leverages Large
Multimodal Models (LMMs) to generate expressive textual descriptions for both
individual images and groups of images. These provide additional contextual
information to guide the fine-tuning process in the custom domains. Since
LMM-generated descriptions are prone to hallucination or missing details, we
introduce a novel strategy to distill only the useful information and stabilize
the training. Specifically, we learn rich per-class prototype representations
from noisy generated texts and dual pseudo-labels. Our experiments on 10
domain-specific datasets show that LatteCLIP outperforms pre-trained zero-shot
methods by an average improvement of +4.74 points in top-1 accuracy and other
state-of-the-art unsupervised methods by +3.45 points.

æè¦ï¼å¤§åè¦è¦ºèªè¨é è¨ç·´ (VLP) æ¨¡å (ä¾å¦ CLIP) ä»¥å¶å¤åè½æ§èèåï¼å çºå®åå¯ä»¥ç¨æ¼åç¨®æç¨ç¨å¼ä¸­ï¼èç¡éé²è¡ä»»ä½è¨­å®ãç¶èï¼ç¶éäºæ¨¡åç¨æ¼ç¹å®é åæï¼å®åçæè½éå¸¸æå é åå·®è·æè¨ç·´è³æä¸­éäºé åçä»£è¡¨æ§ä¸è¶³èä¸éãéç¶å¨å·æäººå·¥æ¨è¨æ¨ç±¤çå®¢è£½åè³æéä¸å¾®èª¿ VLP æ¨¡åå¯ä»¥è§£æ±ºéååé¡ï¼ä½å³ä½¿æ¯æ¨è¨å°è¦æ¨¡è³æé (ä¾å¦ 100k åæ¨£æ¬) ä¹å¯è½æ¯ä¸é æè²´çå·¥ä½ï¼å¦æä»»åå¾è¤éï¼éå¸¸éè¦å°å®¶æ¨è¨å¡ãçºäºæå°éäºææ°ï¼æåæåºäº LatteCLIPï¼éæ¯ä¸ç¨®ç¡ç£ç£æ¹æ³ï¼ç¨æ¼å¨å®¢è£½åé åä¸­å° CLIP æ¨¡åé²è¡å¾®èª¿ï¼ä»¥å°å·²ç¥çé¡å¥åç¨±é²è¡åé¡ï¼èä¸éè¦ä¾è³´äººå·¥æ¨è¨ãæåçæ¨¡åå©ç¨å¤§åå¤æ¨¡ææ¨¡å (LMM) çºåå¥å½±ååå½±åç¾¤çµç¢çå·è¡¨ç¾åçæå­æè¿°ãéäºæè¿°æä¾äºé¡å¤çèçµ¡è³è¨ï¼ä»¥æå°å®¢è£½åé åä¸­çå¾®èª¿éç¨ãç±æ¼ LMM çæçæè¿°å®¹æåºç¾å¹»è¦ºæéºæ¼ç´°ç¯ï¼å æ­¤æåå¼å¥äºä¸ç¨®æ°ç­ç¥ï¼åæåæç¨çè³è¨ä¸¦ç©©å®è¨ç·´ãå·é«ä¾èªªï¼æåå¾éè¨ç¢ççæå­åééå½æ¨ç±¤ä¸­å­¸ç¿è±å¯çæ¯åé¡å¥ååè¡¨ç¤ºãæåå¨ 10 åç¹å®é åçè³æéä¸é²è¡çå¯¦é©è¡¨æï¼LatteCLIP å¨å 1 åæºç¢ºçä¸æ¯é åè¨ç·´çé¶æ¬¡å­¸ç¿æ¹æ³å¹³åæé«äº +4.74 åç¾åé»ï¼æ¯å¶ä»æåé²çç¡ç£ç£æ¹æ³æé«äº +3.45 åç¾åé»ã

##### **PointOBB-v2: Towards Simpler, Faster, and Stronger Single Point Supervised Oriented Object Detection**
2410.08210v1 by Botao Ren, Xue Yang, Yi Yu, Junwei Luo, Zhidong Deng

Single point supervised oriented object detection has gained attention and
made initial progress within the community. Diverse from those approaches
relying on one-shot samples or powerful pretrained models (e.g. SAM), PointOBB
has shown promise due to its prior-free feature. In this paper, we propose
PointOBB-v2, a simpler, faster, and stronger method to generate pseudo rotated
boxes from points without relying on any other prior. Specifically, we first
generate a Class Probability Map (CPM) by training the network with non-uniform
positive and negative sampling. We show that the CPM is able to learn the
approximate object regions and their contours. Then, Principal Component
Analysis (PCA) is applied to accurately estimate the orientation and the
boundary of objects. By further incorporating a separation mechanism, we
resolve the confusion caused by the overlapping on the CPM, enabling its
operation in high-density scenarios. Extensive comparisons demonstrate that our
method achieves a training speed 15.58x faster and an accuracy improvement of
11.60%/25.15%/21.19% on the DOTA-v1.0/v1.5/v2.0 datasets compared to the
previous state-of-the-art, PointOBB. This significantly advances the cutting
edge of single point supervised oriented detection in the modular track.

æè¦ï¼å®é»ç£ç£å°åçç®æ¨åµæ¸¬å·²ç²å¾éæ³¨ï¼ä¸¦å¨ç¤¾ç¾¤ä¸­åå¾åæ­¥é²å±ãä¸åæ¼ä¾è³´å®æ¬¡æ¨£æ¬æå¼·å¤§é è¨ç·´æ¨¡åï¼ä¾å¦ SAMï¼çé£äºæ¹æ³ï¼PointOBB ç±æ¼å¶ç¡åé©ç¹å¾µèé¡¯ç¤ºåºåæ¯ãå¨æ¬æä¸­ï¼æåæåº PointOBB-v2ï¼éæ¯ä¸ç¨®æ´ç°¡å®ãæ´å¿«éä¸æ´å¼·å¤§çæ¹æ³ï¼ç¨æ¼å¨ä¸ä¾è³´ä»»ä½å¶ä»åé©çææ³ä¸å¾é»çæå½æè½æ¡ãå·é«ä¾èªªï¼æåé¦åééä½¿ç¨éåå»æ­£è² åæ¨£ä¾è¨ç·´ç¶²è·¯ï¼ä¾çæé¡å¥æ©çå (CPM)ãæåè¡¨æ CPM è½å¤ å­¸ç¿è¿ä¼¼çç©ä»¶åååå¶è¼ªå»ãç¶å¾ï¼æç¨ä¸»æååæ (PCA) ä¾æºç¢ºä¼°è¨ç©é«çæ¹ååéçãééé²ä¸æ­¥ç´å¥åé¢æ©å¶ï¼æåè§£æ±ºäº CPM ä¸éçæé æçæ··æ·ï¼ä½¿å¶è½å¤ å¨é«å¯åº¦å ´æ¯ä¸­æä½ãå»£æ³çæ¯è¼è¡¨æï¼èååçæè¡ PointOBB ç¸æ¯ï¼æåçæ¨¡åå¨ DOTA-v1.0/v1.5/v2.0 è³æéä¸å¯¦ç¾äºå¿« 15.58 åçè¨ç·´éåº¦ï¼ä»¥å 11.60%/25.15%/21.19% çæºç¢ºåº¦æåãéé¡¯èæåäºæ¨¡çµåè»éä¸­å®é»ç£ç£å°ååµæ¸¬çå°ç«¯æè¡ã

##### **Emerging Pixel Grounding in Large Multimodal Models Without Grounding Supervision**
2410.08209v1 by Shengcao Cao, Liang-Yan Gui, Yu-Xiong Wang

Current large multimodal models (LMMs) face challenges in grounding, which
requires the model to relate language components to visual entities. Contrary
to the common practice that fine-tunes LMMs with additional grounding
supervision, we find that the grounding ability can in fact emerge in LMMs
trained without explicit grounding supervision. To reveal this emerging
grounding, we introduce an "attend-and-segment" method which leverages
attention maps from standard LMMs to perform pixel-level segmentation.
Furthermore, to enhance the grounding ability, we propose DIFFLMM, an LMM
utilizing a diffusion-based visual encoder, as opposed to the standard CLIP
visual encoder, and trained with the same weak supervision. Without being
constrained by the biases and limited scale of grounding-specific supervision
data, our approach is more generalizable and scalable. We achieve competitive
performance on both grounding-specific and general visual question answering
benchmarks, compared with grounding LMMs and generalist LMMs, respectively.
Notably, we achieve a 44.2 grounding mask recall on grounded conversation
generation without any grounding supervision, outperforming the extensively
supervised model GLaMM. Project page: https://groundLMM.github.io.

æè¦ï¼ç®åçå¤§åå¤æ¨¡ææ¨¡å (LMM) é¢è¨èåºç¤åé¡ï¼ééè¦æ¨¡åå°èªè¨çµæé¨åèè¦è¦ºå¯¦é«éè¯èµ·ä¾ãèä½¿ç¨é¡å¤çåºç¤ç£ç£å¾®èª¿ LMM çå¸¸è¦åæ³ç¸åï¼æåç¼ç¾åºç¤è½åå¯¦éä¸å¯ä»¥å¨æ²ææç¢ºåºç¤ç£ç£çææ³ä¸è¨ç·´ç LMM ä¸­åºç¾ãçºäºæ­ç¤ºéç¨®æ°èçåºç¤ï¼æåå¼å¥äºä¸åãéæ³¨ä¸¦åå²ãæ¹æ³ï¼è©²æ¹æ³å©ç¨æ¨æº LMM çæ³¨æååä¾å·è¡åç´ ç´åå²ãæ­¤å¤ï¼çºäºå¢å¼·åºç¤è½åï¼æåæåºäº DIFFLMMï¼éæ¯ä¸ç¨® LMMï¼å®ä½¿ç¨åºæ¼æ´æ£çè¦è¦ºç·¨ç¢¼å¨ï¼èä¸æ¯æ¨æº CLIP è¦è¦ºç·¨ç¢¼å¨ï¼ä¸¦ä½¿ç¨ç¸åçå¼±ç£ç£é²è¡è¨ç·´ãå¨ä¸ååºç¤ç¹å®ç£ç£æ¸æçåå·®åæéè¦æ¨¡çç´æä¸ï¼æåçåæ³æ´å·éç¨æ§åå¯æ´å±æ§ãèåºç¤ LMM åéæ LMM ç¸æ¯ï¼æåå¨åºç¤ç¹å®åä¸è¬è¦è¦ºåé¡è§£ç­åºæºä¸å¯¦ç¾äºç«¶ç­åãå¼å¾æ³¨æçæ¯ï¼æåå¨æ²æä»»ä½åºç¤ç£ç£çææ³ä¸ï¼å°åºç¤å°è©±çæå¯¦ç¾äº 44.2 çåºç¤é®ç½©å¬åçï¼åªæ¼å»£æ³ç£ç£çæ¨¡å GLaMMãå°æ¡é é¢ï¼https://groundLMM.github.ioã

##### **SPA: 3D Spatial-Awareness Enables Effective Embodied Representation**
2410.08208v1 by Haoyi Zhu, Honghui Yang, Yating Wang, Jiange Yang, Limin Wang, Tong He

In this paper, we introduce SPA, a novel representation learning framework
that emphasizes the importance of 3D spatial awareness in embodied AI. Our
approach leverages differentiable neural rendering on multi-view images to
endow a vanilla Vision Transformer (ViT) with intrinsic spatial understanding.
We present the most comprehensive evaluation of embodied representation
learning to date, covering 268 tasks across 8 simulators with diverse policies
in both single-task and language-conditioned multi-task scenarios. The results
are compelling: SPA consistently outperforms more than 10 state-of-the-art
representation methods, including those specifically designed for embodied AI,
vision-centric tasks, and multi-modal applications, while using less training
data. Furthermore, we conduct a series of real-world experiments to confirm its
effectiveness in practical scenarios. These results highlight the critical role
of 3D spatial awareness for embodied representation learning. Our strongest
model takes more than 6000 GPU hours to train and we are committed to
open-sourcing all code and model weights to foster future research in embodied
representation learning. Project Page: https://haoyizhu.github.io/spa/.

æè¦ï¼<paragraph>å¨æ¬æä¸­ï¼æåä»ç´¹ SPAï¼ä¸ç¨®æ°ç©çè¡¨å¾µå­¸ç¿æ¡æ¶ï¼å¼·èª¿äº 3D ç©ºéæç¥å¨å·èº« AI ä¸­çéè¦æ§ãæåçåæ³å©ç¨å¤è¦åå½±åä¸çå¯å¾®åç¥ç¶æ¸²æï¼è³¦äº vanilla è¦è¦º Transformer (ViT) å§å¨çç©ºéçè§£ãæåå±ç¤ºäºè¿ä»çºæ­¢æå¨é¢çå·èº«è¡¨å¾µå­¸ç¿è©ä¼°ï¼æ¶µèäº 8 åæ¨¡æ¬å¨ä¸­ç 268 åä»»åï¼å¨å®ä¸ä»»ååèªè¨æ¢ä»¶çå¤ä»»åå ´æ¯ä¸­æ¡ç¨ä¸åçç­ç¥ãçµæä»¤äººä¿¡æï¼SPA æçºåªæ¼ 10 ç¨®ä»¥ä¸çææ°è¡¨å¾µæ¹æ³ï¼åæ¬å°éçºå·èº« AIãä»¥è¦è¦ºçºä¸­å¿çä»»ååå¤æ¨¡ææç¨ç¨å¼è¨­è¨çæ¹æ³ï¼åæä½¿ç¨è¼å°çè¨ç·´è³æãæ­¤å¤ï¼æåé²è¡äºä¸ç³»åçå¯¦ä¸ççå¯¦é©ï¼ä»¥ç¢ºèªå¶å¨å¯¦éå ´æ¯ä¸­çæææ§ãéäºçµæçªåºäº 3D ç©ºéæç¥å°æ¼å·èº«è¡¨å¾µå­¸ç¿çééµä½ç¨ãæåæå¼·å¤§çæ¨¡åéè¦è¶é 6000 å GPU å°ææè½è¨ç·´ï¼æåè´åæ¼éæ¾åå§ç¢¼åæææ¨¡åæ¬éï¼ä»¥ä¿é²å·èº«è¡¨å¾µå­¸ç¿çæªä¾ç ç©¶ãå°æ¡é é¢ï¼https://haoyizhu.github.io/spa/ã</paragraph>

##### **Mono-InternVL: Pushing the Boundaries of Monolithic Multimodal Large Language Models with Endogenous Visual Pre-training**
2410.08202v1 by Gen Luo, Xue Yang, Wenhan Dou, Zhaokai Wang, Jifeng Dai, Yu Qiao, Xizhou Zhu

The rapid advancement of Large Language Models (LLMs) has led to an influx of
efforts to extend their capabilities to multimodal tasks. Among them, growing
attention has been focused on monolithic Multimodal Large Language Models
(MLLMs) that integrate visual encoding and language decoding into a single LLM.
Despite the structural simplicity and deployment-friendliness, training a
monolithic MLLM with promising performance still remains challenging. In
particular, the popular approaches adopt continuous pre-training to extend a
pre-trained LLM to a monolithic MLLM, which suffers from catastrophic
forgetting and leads to performance degeneration. In this paper, we aim to
overcome this limitation from the perspective of delta tuning. Specifically,
our core idea is to embed visual parameters into a pre-trained LLM, thereby
incrementally learning visual knowledge from massive data via delta tuning,
i.e., freezing the LLM when optimizing the visual parameters. Based on this
principle, we present Mono-InternVL, a novel monolithic MLLM that seamlessly
integrates a set of visual experts via a multimodal mixture-of-experts
structure. Moreover, we propose an innovative pre-training strategy to maximize
the visual capability of Mono-InternVL, namely Endogenous Visual Pre-training
(EViP). In particular, EViP is designed as a progressive learning process for
visual experts, which aims to fully exploit the visual knowledge from noisy
data to high-quality data. To validate our approach, we conduct extensive
experiments on 16 benchmarks. Experimental results not only validate the
superior performance of Mono-InternVL compared to the state-of-the-art MLLM on
6 multimodal benchmarks, e.g., +113 points over InternVL-1.5 on OCRBench, but
also confirm its better deployment efficiency, with first token latency reduced
by up to 67%.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çå¿«éé²å±å·²å°è´å¤§éåªåå°å¶è½åæ´å±å°å¤æ¨¡æä»»åãå¶ä¸­ï¼è¶ä¾è¶å¤çéæ³¨éä¸­å¨å®é«å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) ä¸ï¼å®å°è¦è¦ºç·¨ç¢¼åèªè¨è§£ç¢¼æ´åå°ä¸å LLM ä¸­ãåç®¡çµæ§ç°¡å®ä¸ææ¼é¨ç½²ï¼ä½è¨ç·´ä¸åå·æè¯å¥½æ§è½çå®é« MLLM ä»ç¶å·æææ°æ§ãå·é«èè¨ï¼æµè¡çæ¹æ³æ¡ç¨é£çºé è¨ç·´å°é è¨ç·´ç LLM æ´å±å°å®é« MLLMï¼éæå°è´ç½é£æ§éºå¿ä¸¦å°è´æ§è½ä¸éãå¨æ¬æä¸­ï¼æåæ¨å¨å¾å¢éèª¿æ´çè§åº¦åæéä¸éå¶ãå·é«ä¾èªªï¼æåçæ ¸å¿ææ³æ¯å°è¦è¦ºåæ¸åµå¥å°é è¨ç·´ç LLM ä¸­ï¼å¾èééå¢éèª¿æ´å¾æµ·éæ¸æä¸­å¢éå­¸ç¿è¦è¦ºç¥è­ï¼å³å¨åªåè¦è¦ºåæ¸æåçµ LLMãåºæ¼éä¸åçï¼æåæåºäº Mono-InternVLï¼éæ¯ä¸åæ°ç©çå®é« MLLMï¼å®ééå¤æ¨¡æå°å®¶æ··åçµæ§ç¡ç¸«æ´åäºä¸çµè¦è¦ºå°å®¶ãæ­¤å¤ï¼æåæåºäºä¸ç¨®åµæ°çé è¨ç·´ç­ç¥ï¼ä»¥æå¤§å Mono-InternVL çè¦è¦ºè½åï¼å³å§çè¦è¦ºé è¨ç·´ (EViP)ãå·é«ä¾èªªï¼EViP è¢«è¨­è¨çºè¦è¦ºå°å®¶çæ¼¸é²å­¸ç¿éç¨ï¼æ¨å¨ååå©ç¨å¾åªè²æ¸æå°é«è³ªéæ¸æçè¦è¦ºç¥è­ãçºäºé©è­æåçåæ³ï¼æåå¨ 16 ååºæºä¸é²è¡äºå»£æ³çå¯¦é©ãå¯¦é©çµæä¸åé©è­äº Mono-InternVL èæåé²ç MLLM å¨ 6 åå¤æ¨¡æåºæºä¸çåè¶æ§è½ï¼ä¾å¦ï¼å¨ OCRBench ä¸æ¯ InternVL-1.5 é« 113 åï¼èä¸éç¢ºèªäºå¶æ´å¥½çé¨ç½²æçï¼é¦åä»¤çå»¶é²éä½äºé«é 67%ã

##### **From Exploration to Mastery: Enabling LLMs to Master Tools via Self-Driven Interactions**
2410.08197v1 by Changle Qu, Sunhao Dai, Xiaochi Wei, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Jun Xu, Ji-Rong Wen

Tool learning enables Large Language Models (LLMs) to interact with external
environments by invoking tools, serving as an effective strategy to mitigate
the limitations inherent in their pre-training data. In this process, tool
documentation plays a crucial role by providing usage instructions for LLMs,
thereby facilitating effective tool utilization. This paper concentrates on the
critical challenge of bridging the comprehension gap between LLMs and external
tools due to the inadequacies and inaccuracies inherent in existing
human-centric tool documentation. We propose a novel framework, DRAFT, aimed at
Dynamically Refining tool documentation through the Analysis of Feedback and
Trails emanating from LLMs' interactions with external tools. This methodology
pivots on an innovative trial-and-error approach, consisting of three distinct
learning phases: experience gathering, learning from experience, and
documentation rewriting, to iteratively enhance the tool documentation. This
process is further optimized by implementing a diversity-promoting exploration
strategy to ensure explorative diversity and a tool-adaptive termination
mechanism to prevent overfitting while enhancing efficiency. Extensive
experiments on multiple datasets demonstrate that DRAFT's iterative,
feedback-based refinement significantly ameliorates documentation quality,
fostering a deeper comprehension and more effective utilization of tools by
LLMs. Notably, our analysis reveals that the tool documentation refined via our
approach demonstrates robust cross-model generalization capabilities.

æè¦ï¼å·¥å·å­¸ç¿è®å¤§åèªè¨æ¨¡å (LLM) è½å¤ ééå¼å«å·¥å·èå¤é¨ç°å¢äºåï¼ä½çºä¸ç¨®ææçç­ç¥ä¾æ¸è¼å¶é è¨ç·´è³æä¸­åºæçéå¶ãå¨æ­¤éç¨ä¸­ï¼å·¥å·æä»¶æ®æ¼äºééµçè§è²ï¼çº LLM æä¾ä½¿ç¨èªªæï¼å¾èä¿é²ææçå·¥å·å©ç¨ãæ¬æå°æ³¨æ¼ç±æ¼ç¾æäººé¡çºä¸­å¿çå·¥å·æä»¶ä¸­çä¸è¶³åä¸æºç¢ºæ§ï¼å¨ LLM åå¤é¨å·¥å·ä¹éå½åçè§£å·®è·çéå¤§ææ°ãæåæåºäºä¸åæ°çæ¡æ¶ DRAFTï¼æ¨å¨ééåæ LLM èå¤é¨å·¥å·äºåç¢ççåé¥åè»è·¡ï¼åæç²¾çå·¥å·æä»¶ãæ­¤æ¹æ³åºæ¼åµæ°çè©¦é¯æ³ï¼åå«ä¸åä¸åçå­¸ç¿éæ®µï¼ç¶é©æ¶éãå¾ç¶é©ä¸­å­¸ç¿åæä»¶éå¯«ï¼ä»¥åè¦å¢å¼·å·¥å·æä»¶ãæ­¤æµç¨é²ä¸æ­¥ééå¯¦æ½ä¿é²å¤æ¨£æ§çæ¢ç´¢ç­ç¥ä¾æä½³åï¼ä»¥ç¢ºä¿æ¢ç´¢çå¤æ¨£æ§ï¼ä¸¦ééå·¥å·é©æçµæ­¢æ©å¶ä¾é²æ­¢éåº¦æ¬åï¼åææé«æçãå¨å¤åè³æéä¸é²è¡çå»£æ³å¯¦é©è¡¨æï¼DRAFT çè¿­ä»£å¼ãåºæ¼åé¥çç²¾çé¡¯èæ¹åäºæä»¶åè³ªï¼ä¿é² LLM å°å·¥å·çæ´æ·±å¥çè§£åæ´ææçå©ç¨ãå¼å¾æ³¨æçæ¯ï¼æåçåæè¡¨æï¼ééæåçæ¹æ³ç²¾ççå·¥å·æä»¶å±ç¤ºäºå¼·å¤§çè·¨æ¨¡åæ³åè½åã

##### **MathCoder2: Better Math Reasoning from Continued Pretraining on Model-translated Mathematical Code**
2410.08196v1 by Zimu Lu, Aojun Zhou, Ke Wang, Houxing Ren, Weikang Shi, Junting Pan, Mingjie Zhan, Hongsheng Li

Code has been shown to be effective in enhancing the mathematical reasoning
abilities of large language models due to its precision and accuracy. Previous
works involving continued mathematical pretraining often include code that
utilizes math-related packages, which are primarily designed for fields such as
engineering, machine learning, signal processing, or module testing, rather
than being directly focused on mathematical reasoning. In this paper, we
introduce a novel method for generating mathematical code accompanied with
corresponding reasoning steps for continued pretraining. Our approach begins
with the construction of a high-quality mathematical continued pretraining
dataset by incorporating math-related web data, code using mathematical
packages, math textbooks, and synthetic data. Next, we construct reasoning
steps by extracting LaTeX expressions, the conditions needed for the
expressions, and the results of the expressions from the previously collected
dataset. Based on this extracted information, we generate corresponding code to
accurately capture the mathematical reasoning process. Appending the generated
code to each reasoning step results in data consisting of paired natural
language reasoning steps and their corresponding code. Combining this data with
the original dataset results in a 19.2B-token high-performing mathematical
pretraining corpus, which we name MathCode-Pile. Training several popular base
models with this corpus significantly improves their mathematical abilities,
leading to the creation of the MathCoder2 family of models. All of our data
processing and training code is open-sourced, ensuring full transparency and
easy reproducibility of the entire data collection and training pipeline. The
code is released at https://github.com/mathllm/MathCoder2 .

æè¦ï¼<paragraph>ç¨å¼ç¢¼å·²è¢«è­å¯¦è½æææåå¤§åèªè¨æ¨¡åçæ¸å­¸æ¨çè½åï¼å çºå®ç²¾æºä¸æºç¢ºãååæ¶åæçºæ¸å­¸é è¨ç·´çç ç©¶ï¼éå¸¸åå«ä½¿ç¨èæ¸å­¸ç¸éå¥ä»¶çç¨å¼ç¢¼ï¼éäºå¥ä»¶ä¸»è¦è¨­è¨çµ¦å·¥ç¨ãæ©å¨å­¸ç¿ãè¨èèçææ¨¡çµæ¸¬è©¦ç­é åï¼èä¸æ¯ç´æ¥å°æ³¨æ¼æ¸å­¸æ¨çãå¨æ¬æä¸­ï¼æåä»ç´¹ä¸ç¨®æ°çæ¹æ³ï¼ç¨æ¼ç¢çæ¸å­¸ç¨å¼ç¢¼ï¼ä¸¦éä¸å°æçæ¨çæ­¥é©ï¼ä»¥æçºé²è¡é è¨ç·´ãæåçåæ³å¾å»ºç«ä¸åé«åè³ªçæ¸å­¸æçºé è¨ç·´è³æééå§ï¼æ¹æ³æ¯ç´å¥èæ¸å­¸ç¸éçç¶²è·¯è³æãä½¿ç¨æ¸å­¸å¥ä»¶çç¨å¼ç¢¼ãæ¸å­¸æç§æ¸ååæè³æãæ¥ä¸ä¾ï¼æåééå¾ååæ¶éçè³æéä¸­èå LaTeX è¡¨éå¼ãè¡¨éå¼æéçæ¢ä»¶ï¼ä»¥åè¡¨éå¼ççµæï¼ä¾å»ºæ§æ¨çæ­¥é©ãæ ¹æéäºèåçè³è¨ï¼æåç¢çå°æçç¨å¼ç¢¼ï¼ä»¥æºç¢ºæææ¸å­¸æ¨çéç¨ãå°ç¢ççç¨å¼ç¢¼éå å°æ¯åæ¨çæ­¥é©ï¼å°±æç¢çç±æå°çèªç¶èªè¨æ¨çæ­¥é©åå¶å°æç¨å¼ç¢¼çµæçè³æãå°éäºè³æèåå§è³æéçµåï¼å°±æç¢çä¸å 19.2B åç¬¦èçé«æè½æ¸å­¸é è¨ç·´èªæåº«ï¼æåå°å¶å½åçº MathCode-Pileãä½¿ç¨éåèªæåº«è¨ç·´å¹¾åç±éçåºæ¬æ¨¡åï¼å¤§å¹æåäºå®åçæ¸å­¸è½åï¼é²èåµé åº MathCoder2 æ¨¡åå®¶æãæåææçè³æèçåè¨ç·´ç¨å¼ç¢¼é½æ¯éæºçï¼ç¢ºä¿æ´åè³ææ¶éåè¨ç·´ç®¡ç·çå®å¨éæåº¦åå®¹æéç¾æ§ãç¨å¼ç¢¼å·²æ¼ https://github.com/mathllm/MathCoder2 ç¼å¸ã</paragraph>

##### **GenARM: Reward Guided Generation with Autoregressive Reward Model for Test-time Alignment**
2410.08193v1 by Yuancheng Xu, Udari Madhushani Sehwag, Alec Koppel, Sicheng Zhu, Bang An, Furong Huang, Sumitra Ganesh

Large Language Models (LLMs) exhibit impressive capabilities but require
careful alignment with human preferences. Traditional training-time methods
finetune LLMs using human preference datasets but incur significant training
costs and require repeated training to handle diverse user preferences.
Test-time alignment methods address this by using reward models (RMs) to guide
frozen LLMs without retraining. However, existing test-time approaches rely on
trajectory-level RMs which are designed to evaluate complete responses, making
them unsuitable for autoregressive text generation that requires computing
next-token rewards from partial responses. To address this, we introduce
GenARM, a test-time alignment approach that leverages the Autoregressive Reward
Model--a novel reward parametrization designed to predict next-token rewards
for efficient and effective autoregressive generation. Theoretically, we
demonstrate that this parametrization can provably guide frozen LLMs toward any
distribution achievable by traditional RMs within the KL-regularized
reinforcement learning framework. Experimental results show that GenARM
significantly outperforms prior test-time alignment baselines and matches the
performance of training-time methods. Additionally, GenARM enables efficient
weak-to-strong guidance, aligning larger LLMs with smaller RMs without the high
costs of training larger models. Furthermore, GenARM supports multi-objective
alignment, allowing real-time trade-offs between preference dimensions and
catering to diverse user preferences without retraining.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å±ç¤ºäºä»¤äººå°è±¡æ·±å»çè½åï¼ä½éè¦ä»ç´°éåäººé¡çåå¥½ãå³çµ±çè¨ç·´æéæ¹æ³ä½¿ç¨äººé¡åå¥½è³æéå¾®èª¿ LLMï¼ä½æç¢çå¤§éçè¨ç·´ææ¬ï¼ä¸¦ä¸éè¦åè¦è¨ç·´æè½èçä¸åçä½¿ç¨èåå¥½ãæ¸¬è©¦æéå°é½æ¹æ³ééä½¿ç¨çåµæ¨¡å (RM) ä¾æå°åçµç LLM èç¡ééæ°è¨ç·´ä¾è§£æ±ºéååé¡ãç¶èï¼ç¾æçæ¸¬è©¦æéæ¹æ³ä¾è³´æ¼è»è·¡ç´å¥ç RMï¼éäº RM è¢«è¨­è¨ç¨æ¼è©ä¼°å®æ´çåæï¼éä½¿å¾å®åä¸é©åéè¦å¾é¨ååæä¸­è¨ç®ä¸ä¸åä»£å¹£çåµçèªè¿´æ­¸ææ¬çæãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äº GenARMï¼ä¸ç¨®æ¸¬è©¦æéå°é½æ¹æ³ï¼å®å©ç¨èªè¿´æ­¸çåµæ¨¡åââä¸ç¨®æ°ç©ççåµåæ¸åï¼æ¨å¨é æ¸¬ä¸ä¸åä»£å¹£çåµï¼ä»¥å¯¦ç¾é«æä¸ææçèªè¿´æ­¸çæãå¨çè«ä¸ï¼æåè­æäºéååæ¸åå¯ä»¥è­æå¼å°åçµç LLM æèä»»ä½å¨ KL æ­£ååå¼·åå­¸ç¿æ¡æ¶å§ç±å³çµ± RM å¯å¯¦ç¾çåå¸ãå¯¦é©çµæè¡¨æï¼GenARM æé¡¯åªæ¼ååçæ¸¬è©¦æéå°é½åºæºï¼ä¸¦ä¸èè¨ç·´æéæ¹æ³çæ§è½ç¸å¹éãæ­¤å¤ï¼GenARM è½å¤ å¯¦ç¾é«æçå¼±å°å¼·å¼å°ï¼å¨ä¸å¢å è¨ç·´å¤§åæ¨¡åçé«ææ¬çææ³ä¸ï¼å°è¼å¤§ç LLM èè¼å°ç RM å°é½ãæ­¤å¤ï¼GenARM æ¯æ´å¤ç®æ¨å°é½ï¼åè¨±å¨åå¥½ç¶­åº¦ä¹éé²è¡å¯¦ææ¬è¡¡ï¼ä¸¦å¨ä¸éæ°è¨ç·´çææ³ä¸è¿åä¸åçä½¿ç¨èåå¥½ã

##### **DifFRelight: Diffusion-Based Facial Performance Relighting**
2410.08188v1 by Mingming He, Pascal Clausen, Ahmet Levent TaÅel, Li Ma, Oliver Pilarski, Wenqi Xian, Laszlo Rikker, Xueming Yu, Ryan Burgert, Ning Yu, Paul Debevec

We present a novel framework for free-viewpoint facial performance relighting
using diffusion-based image-to-image translation. Leveraging a subject-specific
dataset containing diverse facial expressions captured under various lighting
conditions, including flat-lit and one-light-at-a-time (OLAT) scenarios, we
train a diffusion model for precise lighting control, enabling high-fidelity
relit facial images from flat-lit inputs. Our framework includes
spatially-aligned conditioning of flat-lit captures and random noise, along
with integrated lighting information for global control, utilizing prior
knowledge from the pre-trained Stable Diffusion model. This model is then
applied to dynamic facial performances captured in a consistent flat-lit
environment and reconstructed for novel-view synthesis using a scalable dynamic
3D Gaussian Splatting method to maintain quality and consistency in the relit
results. In addition, we introduce unified lighting control by integrating a
novel area lighting representation with directional lighting, allowing for
joint adjustments in light size and direction. We also enable high dynamic
range imaging (HDRI) composition using multiple directional lights to produce
dynamic sequences under complex lighting conditions. Our evaluations
demonstrate the models efficiency in achieving precise lighting control and
generalizing across various facial expressions while preserving detailed
features such as skintexture andhair. The model accurately reproduces complex
lighting effects like eye reflections, subsurface scattering, self-shadowing,
and translucency, advancing photorealism within our framework.

æè¦ï¼<paragraph>æåæåºä¸åæ°ç©çæ¶æ§ï¼ç¨æ¼èªç±è¦é»äººèæ§è½éæ°æåï¼ä½¿ç¨åºæ¼æ´æ£çå½±åè½å½±åè½æãå©ç¨åå«å¨åç¨®åç§æ¢ä»¶ä¸æ·åçåç¨®é¢é¨è¡¨æçä¸»é¡ç¹å®è³æéï¼åæ¬å¹³é¢ååä¸æ¬¡ä¸åï¼OLATï¼å ´æ¯ï¼æåè¨ç·´ä¸åæ´æ£æ¨¡åä»¥é²è¡ç²¾ç¢ºçåç§æ§å¶ï¼å¾å¹³é¢åè¼¸å¥ä¸­åç¨é«ä¿çéæ°é»äº®çé¢é¨å½±åãæåçæ¶æ§åæ¬å¹³é¢åæ·ååé¨æ©éè¨çç©ºéå°é½æ¢ä»¶ï¼ä»¥åç¨æ¼å¨å±æ§å¶çæ´ååç§è³è¨ï¼å©ç¨é åè¨ç·´ç Stable Diffusion æ¨¡åçåé©ç¥è­ãç¶å¾å°æ­¤æ¨¡åæç¨æ¼å¨ä¸è´çå¹³é¢åç°å¢ä¸­æ·åçåæé¢é¨è¡¨æ¼ï¼ä¸¦ä½¿ç¨å¯æ´åçåæ 3D é«æ¯å´ç¹ªæ¹æ³éå»ºä»¥é²è¡æ°è¦ååæï¼ä»¥ç¶­æéæ°é»äº®çµæçåè³ªåä¸è´æ§ãæ­¤å¤ï¼æåééæ´åä¸åæ°ç©åååç§è¡¨ç¤ºèæ¹ååç§ä¾å¼å¥çµ±ä¸åç§æ§å¶ï¼åè¨±å°åç§å¤§å°åæ¹åé²è¡è¯åèª¿æ´ãæåéåç¨ä½¿ç¨å¤åæ¹ååçé«åæç¯åæåï¼HDRIï¼åæï¼ä»¥å¨è¤éçåç§æ¢ä»¶ä¸ç¢çåæåºåãæåçè©ä¼°è­æäºè©²æ¨¡åå¨å¯¦ç¾ç²¾ç¢ºåç§æ§å¶åæ¦æ¬åç¨®é¢é¨è¡¨ææ¹é¢çæçï¼åæä¿çäºç®èç´çåé ­é«®ç­è©³ç´°ç¹å¾µãè©²æ¨¡åæºç¢ºå°éç¾äºè¤éçåç§ææï¼ä¾å¦ç¼çåå°ãæ¬¡è¡¨é¢æ£å°ãèªé®è½ååéæï¼æ¨åäºæåæ¶æ§ä¸­çå¯«å¯¦ä¸»ç¾©ã</paragraph>

##### **MRAG-Bench: Vision-Centric Evaluation for Retrieval-Augmented Multimodal Models**
2410.08182v1 by Wenbo Hu, Jia-Chen Gu, Zi-Yi Dou, Mohsen Fayyaz, Pan Lu, Kai-Wei Chang, Nanyun Peng

Existing multimodal retrieval benchmarks primarily focus on evaluating
whether models can retrieve and utilize external textual knowledge for question
answering. However, there are scenarios where retrieving visual information is
either more beneficial or easier to access than textual data. In this paper, we
introduce a multimodal retrieval-augmented generation benchmark, MRAG-Bench, in
which we systematically identify and categorize scenarios where visually
augmented knowledge is better than textual knowledge, for instance, more images
from varying viewpoints. MRAG-Bench consists of 16,130 images and 1,353
human-annotated multiple-choice questions across 9 distinct scenarios. With
MRAG-Bench, we conduct an evaluation of 10 open-source and 4 proprietary large
vision-language models (LVLMs). Our results show that all LVLMs exhibit greater
improvements when augmented with images compared to textual knowledge,
confirming that MRAG-Bench is vision-centric. Additionally, we conduct
extensive analysis with MRAG-Bench, which offers valuable insights into
retrieval-augmented LVLMs. Notably, the top-performing model, GPT-4o, faces
challenges in effectively leveraging retrieved knowledge, achieving only a
5.82% improvement with ground-truth information, in contrast to a 33.16%
improvement observed in human participants. These findings highlight the
importance of MRAG-Bench in encouraging the community to enhance LVLMs' ability
to utilize retrieved visual knowledge more effectively.

æè¦ï¼ç¾æçå¤æ¨¡ææª¢ç´¢åºæºä¸»è¦éä¸­å¨è©ä¼°æ¨¡åæ¯å¦è½æª¢ç´¢åå©ç¨å¤é¨ææ¬ç¥è­ä¾åç­åé¡ãç¶èï¼å¨æäºææ³ä¸ï¼æª¢ç´¢è¦è¦ºè³è¨æ¯æª¢ç´¢æå­è³ææ´æå©ææ´å®¹æãå¨æ¬æä¸­ï¼æåå¼é²äºä¸åå¤æ¨¡ææª¢ç´¢å¢å¼·çæåºæº MRAG-Benchï¼å¶ä¸­æåç³»çµ±æ§å°æ¾åºä¸¦åé¡åºè¦è¦ºå¢å¼·ç¥è­åªæ¼æå­ç¥è­çææ³ï¼ä¾å¦æ´å¤ä¾èªä¸åè¦è§çå½±åãMRAG-Bench åå« 16,130 å¼µå½±åå 1,353 åç±äººé¡è¨»è§£çå¤éé¸æé¡ï¼æ¶µè 9 ç¨®ä¸åçææ³ãéé MRAG-Benchï¼æåå° 10 åéæºå 4 åå°æçå¤§åè¦è¦ºèªè¨æ¨¡å (LVLMs) é²è¡è©ä¼°ãæåççµæé¡¯ç¤ºï¼ææ LVLMs å¨å å¥å½±åå¾é½å±ç¾åºæ¯å å¥æå­ç¥è­ææ´å¤§çé²æ­¥ï¼è­å¯¦ MRAG-Bench ä»¥è¦è¦ºçºä¸­å¿ãæ­¤å¤ï¼æåä½¿ç¨ MRAG-Bench é²è¡å»£æ³çåæï¼éæä¾äºæå¹å¼çè¦è§£ï¼è®æåæ·±å¥äºè§£æª¢ç´¢å¢å¼· LVLMsãå¼å¾æ³¨æçæ¯ï¼è¡¨ç¾æä½³çæ¨¡å GPT-4o å¨ææå©ç¨æª¢ç´¢å°çç¥è­æ¹é¢é¢è¨ææ°ï¼åç²å¾ 5.82% ççå¯¦è³è¨é²æ­¥ï¼èäººé¡åèèè§å¯å°ç 33.16% é²æ­¥å½¢æå°æ¯ãéäºç¼ç¾çªé¡¯äº MRAG-Bench çéè¦æ§ï¼å®é¼åµç¤¾ç¾¤æå LVLMs æ´ææå°å©ç¨æª¢ç´¢å°çè¦è¦ºç¥è­çè½åã

##### **Sample then Identify: A General Framework for Risk Control and Assessment in Multimodal Large Language Models**
2410.08174v1 by Qingni Wang, Tiantian Geng, Zhiyuan Wang, Teng Wang, Bo Fu, Feng Zheng

Multimodal Large Language Models (MLLMs) exhibit promising advancements
across various tasks, yet they still encounter significant trustworthiness
issues. Prior studies apply Split Conformal Prediction (SCP) in language
modeling to construct prediction sets with statistical guarantees. However,
these methods typically rely on internal model logits or are restricted to
multiple-choice settings, which hampers their generalizability and adaptability
in dynamic, open-ended environments. In this paper, we introduce TRON, a
two-step framework for risk control and assessment, applicable to any MLLM that
supports sampling in both open-ended and closed-ended scenarios. TRON comprises
two main components: (1) a novel conformal score to sample response sets of
minimum size, and (2) a nonconformity score to identify high-quality responses
based on self-consistency theory, controlling the error rates by two specific
risk levels. Furthermore, we investigate semantic redundancy in prediction sets
within open-ended contexts for the first time, leading to a promising
evaluation metric for MLLMs based on average set size. Our comprehensive
experiments across four Video Question-Answering (VideoQA) datasets utilizing
eight MLLMs show that TRON achieves desired error rates bounded by two
user-specified risk levels. Additionally, deduplicated prediction sets maintain
adaptiveness while being more efficient and stable for risk assessment under
different risk levels.

æè¦ï¼å¤æ¨¡æå¤§åè¯­è¨æ¨¡å (MLLM) å¨åç§ä»»å¡ä¸­è¡¨ç°åºæå¸æçè¿æ­¥ï¼ä½å®ä»¬ä»ç¶éå°éå¤§çå¯ä¿¡åº¦é®é¢ãååçç ç©¶å¨è¯­è¨å»ºæ¨¡ä¸­åºç¨åè£ä¿å½¢é¢æµ (SCP) æ¥æå»ºå·æç»è®¡ä¿è¯çé¢æµéãç¶èï¼è¿äºæ¹æ³éå¸¸ä¾èµäºåé¨æ¨¡å logit æä»éäºå¤é¡¹éæ©è®¾ç½®ï¼è¿é»ç¢äºå®ä»¬å¨å¨æãå¼æ¾å¼ç¯å¢ä¸­çæ³åæ§åéåºæ§ãå¨æ¬æä¸­ï¼æä»¬ä»ç»äº TRONï¼è¿æ¯ä¸ä¸ªéç¨äºä»»ä½æ¯æå¨å¼æ¾å¼åå°é­å¼åºæ¯ä¸­è¿è¡éæ ·ç MLLM çé£é©æ§å¶åè¯ä¼°çä¸¤æ­¥æ¡æ¶ãTRON åå«ä¸¤ä¸ªä¸»è¦ç»ä»¶ï¼(1) ä¸ä¸ªæ°é¢çä¿å½¢åæ°ï¼ç¨äºå¯¹æå°å¤§å°çååºéè¿è¡éæ ·ï¼ä»¥å (2) ä¸ä¸ªä¸ç¬¦ååæ°ï¼ç¨äºæ ¹æ®èªæ´½æ§çè®ºè¯å«é«è´¨éçååºï¼éè¿ä¸¤ä¸ªç¹å®çé£é©çº§å«æ§å¶éè¯¯çãæ­¤å¤ï¼æä»¬é¦æ¬¡ç ç©¶äºå¼æ¾å¼è¯­å¢ä¸­é¢æµéä¸­çè¯­ä¹åä½ï¼ä»èä¸ºåºäºå¹³åéå¤§å°ç MLLM æä¾äºä¸ä¸ªæå¸æçè¯ä¼°ææ ãæä»¬å¨å©ç¨å«ä¸ª MLLM çåä¸ªè§é¢é®ç­ (VideoQA) æ°æ®éä¸è¿è¡çå¨é¢å®éªè¡¨æï¼TRON å®ç°äºç±ä¸¤ä¸ªç¨æ·æå®çé£é©çº§å«éå®çææéè¯¯çãæ­¤å¤ï¼éå¤æ°æ®å é¤çé¢æµéä¿æéåºæ§ï¼åæ¶å¨ä¸åé£é©çº§å«ä¸å¯¹é£é©è¯ä¼°æ´ææãæ´ç¨³å®ã

##### **On the Evaluation of Generative Robotic Simulations**
2410.08172v1 by Feng Chen, Botian Xu, Pu Hua, Peiqi Duan, Yanchao Yang, Yi Ma, Huazhe Xu

Due to the difficulty of acquiring extensive real-world data, robot
simulation has become crucial for parallel training and sim-to-real transfer,
highlighting the importance of scalable simulated robotic tasks. Foundation
models have demonstrated impressive capacities in autonomously generating
feasible robotic tasks. However, this new paradigm underscores the challenge of
adequately evaluating these autonomously generated tasks. To address this, we
propose a comprehensive evaluation framework tailored to generative
simulations. Our framework segments evaluation into three core aspects:
quality, diversity, and generalization. For single-task quality, we evaluate
the realism of the generated task and the completeness of the generated
trajectories using large language models and vision-language models. In terms
of diversity, we measure both task and data diversity through text similarity
of task descriptions and world model loss trained on collected task
trajectories. For task-level generalization, we assess the zero-shot
generalization ability on unseen tasks of a policy trained with multiple
generated tasks. Experiments conducted on three representative task generation
pipelines demonstrate that the results from our framework are highly consistent
with human evaluations, confirming the feasibility and validity of our
approach. The findings reveal that while metrics of quality and diversity can
be achieved through certain methods, no single approach excels across all
metrics, suggesting a need for greater focus on balancing these different
metrics. Additionally, our analysis further highlights the common challenge of
low generalization capability faced by current works. Our anonymous website:
https://sites.google.com/view/evaltasks.

æè¦ï¼<paragraph>ç±æ¼é£ä»¥åå¾å»£æ³ççå¯¦ä¸çè³æï¼æ©å¨äººæ¨¡æ¬å·²æçºå¹³è¡è¨ç·´åæ¨¡æ¬å°çå¯¦è½ç§»çééµï¼å¼·èª¿å¯æ´åæ¨¡æ¬æ©å¨äººä»»åçéè¦æ§ãåºç¤æ¨¡åå·²å±ç¤ºåºèªä¸»ç¢çå¯è¡æ©å¨äººä»»åçé©äººè½åãç¶èï¼éåæ°ç¯ä¾å¼·èª¿äºååè©ä¼°éäºèªä¸»ç¢çä»»åçææ°ãçºäºè§£æ±ºéååé¡ï¼æåæåºä¸åéèº«æé çç¶åè©ä¼°æ¶æ§ï¼é©ç¨æ¼çææ¨¡æ¬ãæåçæ¶æ§å°è©ä¼°åçºä¸åæ ¸å¿é¢åï¼åè³ªãå¤æ¨£æ§åæ¦åãå°æ¼å®ä¸ä»»ååè³ªï¼æåä½¿ç¨å¤§åèªè¨æ¨¡ååè¦è¦ºèªè¨æ¨¡åè©ä¼°çæä»»åççå¯¦æ§åçæè»è·¡çå®æ´æ§ãå¨å¤æ¨£æ§æ¹é¢ï¼æåééä»»åæè¿°çæå­ç¸ä¼¼æ§åå¨æ¶éçä»»åè»è·¡ä¸è¨ç·´çä¸çæ¨¡åæå¤±ï¼ä¾è¡¡éä»»ååè³æçå¤æ¨£æ§ãå°æ¼ä»»åå±¤ç´çæ¦åï¼æåè©ä¼°å¨ä½¿ç¨å¤åçæä»»åè¨ç·´çç­ç¥ä¸­ï¼å°æªè¦ä»»åçé¶æ¬¡å­¸ç¿æ¦åè½åãå¨ä¸åä»£è¡¨æ§ä»»åçæç®¡ç·ä¸é²è¡çå¯¦é©è­æï¼æåæ¶æ§ççµæèäººé¡è©ä¼°é«åº¦ä¸è´ï¼è­å¯¦æåæ¹æ³çå¯è¡æ§åæææ§ãç ç©¶çµæé¡¯ç¤ºï¼éç¶åè³ªåå¤æ¨£æ§çææ¨å¯ééç¹å®æ¹æ³éæï¼ä½æ²æå®ä¸æ¹æ³å¨ææææ¨ä¸é½è¡¨ç¾åºè²ï¼éè¡¨ç¤ºéè¦æ´å°æ³¨æ¼å¹³è¡¡éäºä¸åçææ¨ãæ­¤å¤ï¼æåçåæé²ä¸æ­¥å¼·èª¿äºç¶åå·¥ä½é¢è¨çä½æ¦åè½åçå±åææ°ãæåçå¿åç¶²ç«ï¼https://sites.google.com/view/evaltasksã</paragraph>

##### **Agent S: An Open Agentic Framework that Uses Computers Like a Human**
2410.08164v1 by Saaket Agashe, Jiuzhou Han, Shuyu Gan, Jiachen Yang, Ang Li, Xin Eric Wang

We present Agent S, an open agentic framework that enables autonomous
interaction with computers through a Graphical User Interface (GUI), aimed at
transforming human-computer interaction by automating complex, multi-step
tasks. Agent S aims to address three key challenges in automating computer
tasks: acquiring domain-specific knowledge, planning over long task horizons,
and handling dynamic, non-uniform interfaces. To this end, Agent S introduces
experience-augmented hierarchical planning, which learns from external
knowledge search and internal experience retrieval at multiple levels,
facilitating efficient task planning and subtask execution. In addition, it
employs an Agent-Computer Interface (ACI) to better elicit the reasoning and
control capabilities of GUI agents based on Multimodal Large Language Models
(MLLMs). Evaluation on the OSWorld benchmark shows that Agent S outperforms the
baseline by 9.37% on success rate (an 83.6% relative improvement) and achieves
a new state-of-the-art. Comprehensive analysis highlights the effectiveness of
individual components and provides insights for future improvements.
Furthermore, Agent S demonstrates broad generalizability to different operating
systems on a newly-released WindowsAgentArena benchmark. Code available at
https://github.com/simular-ai/Agent-S.

æè¦ï¼<paragraph>æåæåº Agent Sï¼ä¸åéæ¾çä»£çæ¡æ¶ï¼å¯ééåå½¢ä½¿ç¨èä»é¢ (GUI) èé»è¦é²è¡èªä¸»äºåï¼æ¨å¨ééèªååè¤éçå¤æ­¥é©ä»»åä¾è½è®äººæ©äºåãAgent S æ¨å¨è§£æ±ºèªååé»è¦ä»»åä¸­çä¸åééµææ°ï¼æ·åç¹å®é åç¥è­ãè¦åé·ä»»åæç¨ï¼ä»¥åèçåæãéçµ±ä¸çä»é¢ãçºæ­¤ï¼Agent S å°å¥äºç¶é©å¢å¼·éå±¤å¼è¦åï¼å®æå¾å¤åå±¤ç´çå¤é¨ç¥è­æå°åå§é¨ç¶é©æ·åä¸­å­¸ç¿ï¼ä¿é²ææççä»»åè¦ååå­ä»»åå·è¡ãæ­¤å¤ï¼å®æ¡ç¨ä»£çé»è¦ä»é¢ (ACI)ï¼ä»¥æ ¹æå¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) æ´ä½³å°å¼åº GUI ä»£ççæ¨çåæ§å¶è½åãå¨ OSWorld åºæºä¸çè©ä¼°é¡¯ç¤ºï¼Agent S å¨æåçä¸æ¯åºæºé«åº 9.37%ï¼ç¸å°æå 83.6%ï¼ï¼ä¸¦åµä¸æ°çæè¡æ°´æºãå¨é¢çåæçªé¡¯äºåå¥åä»¶çæææ§ï¼ä¸¦çºæªä¾çæ¹é²æä¾è¦è§£ãæ­¤å¤ï¼Agent S å¨æ°ç¼å¸ç WindowsAgentArena åºæºä¸å±ç¤ºäºå°ä¸åä½æ¥­ç³»çµ±çå»£æ³éç¨æ§ãç¨å¼ç¢¼å¯æ¼ https://github.com/simular-ai/Agent-S åå¾ã</paragraph>

##### **The Effect of Surprisal on Reading Times in Information Seeking and Repeated Reading**
2410.08162v1 by Keren Gruteke Klein, Yoav Meiri, Omer Shubi, Yevgeni Berzak

The effect of surprisal on processing difficulty has been a central topic of
investigation in psycholinguistics. Here, we use eyetracking data to examine
three language processing regimes that are common in daily life but have not
been addressed with respect to this question: information seeking, repeated
processing, and the combination of the two. Using standard regime-agnostic
surprisal estimates we find that the prediction of surprisal theory regarding
the presence of a linear effect of surprisal on processing times, extends to
these regimes. However, when using surprisal estimates from regime-specific
contexts that match the contexts and tasks given to humans, we find that in
information seeking, such estimates do not improve the predictive power of
processing times compared to standard surprisals. Further, regime-specific
contexts yield near zero surprisal estimates with no predictive power for
processing times in repeated reading. These findings point to misalignments of
task and memory representations between humans and current language models, and
question the extent to which such models can be used for estimating cognitively
relevant quantities. We further discuss theoretical challenges posed by these
results.

æè¦ï¼é©è¨å°èçé£åº¦ä¹å½±é¿ä¸ç´æ¯å¿çèªè¨å­¸èª¿æ¥çä¸­å¿è­°é¡ãå¨æ­¤ï¼æåä½¿ç¨ç¼åè¿½è¹¤è³æä¾æª¢è¦æ¥å¸¸çæ´»ä¸­å¸¸è¦çä¸ç¨®èªè¨èçæ¨¡å¼ï¼ä½å°æªéå°æ­¤åé¡å ä»¥æ¢è¨ï¼è³è¨å°æ±ãéè¤èçï¼ä»¥åå©èççµåãä½¿ç¨æ¨æºçèæ¨¡å¼ç¡éçé©è¨ä¼°è¨ï¼æåç¼ç¾é©è¨çè«å°èçæéä¸­é©è¨ç·æ§ææå­å¨çé æ¸¬ï¼å»¶ä¼¸è³éäºæ¨¡å¼ãç¶èï¼ç¶ä½¿ç¨ä¾èªèäººé¡æçµ¦äºçèçµ¡åä»»åç¸ç¬¦çæ¨¡å¼ç¹å®èçµ¡çé©è¨ä¼°è¨æï¼æåç¼ç¾ï¼å¨è³è¨å°æ±ä¸­ï¼æ­¤é¡ä¼°è¨ä¸¦æªæ¹åèçæéçé æ¸¬è½åï¼èæ¨æºé©è¨ç¸æ¯ãæ­¤å¤ï¼æ¨¡å¼ç¹å®èçµ¡ç¢çæ¥è¿æ¼é¶çé©è¨ä¼°è¨ï¼å¨éè¤é±è®ä¸­å°èçæéæ²æé æ¸¬è½åãéäºç¼ç¾æåºäººé¡èç¶åèªè¨æ¨¡åä¹éçä»»ååè¨æ¶è¡¨å¾µçä¸ä¸è´ï¼ä¸¦è³ªçæ­¤é¡æ¨¡åå¯ç¨æ¼ä¼°è¨èªç¥ç¸éæ¸éãæåé²ä¸æ­¥è¨è«éäºçµææåºççè«ææ°ã

##### **Rewarding Progress: Scaling Automated Process Verifiers for LLM Reasoning**
2410.08146v1 by Amrith Setlur, Chirag Nagpal, Adam Fisch, Xinyang Geng, Jacob Eisenstein, Rishabh Agarwal, Alekh Agarwal, Jonathan Berant, Aviral Kumar

A promising approach for improving reasoning in large language models is to
use process reward models (PRMs). PRMs provide feedback at each step of a
multi-step reasoning trace, potentially improving credit assignment over
outcome reward models (ORMs) that only provide feedback at the final step.
However, collecting dense, per-step human labels is not scalable, and training
PRMs from automatically-labeled data has thus far led to limited gains. To
improve a base policy by running search against a PRM or using it as dense
rewards for reinforcement learning (RL), we ask: "How should we design process
rewards?". Our key insight is that, to be effective, the process reward for a
step should measure progress: a change in the likelihood of producing a correct
response in the future, before and after taking the step, corresponding to the
notion of step-level advantages in RL. Crucially, this progress should be
measured under a prover policy distinct from the base policy. We theoretically
characterize the set of good provers and our results show that optimizing
process rewards from such provers improves exploration during test-time search
and online RL. In fact, our characterization shows that weak prover policies
can substantially improve a stronger base policy, which we also observe
empirically. We validate our claims by training process advantage verifiers
(PAVs) to predict progress under such provers, and show that compared to ORMs,
test-time search against PAVs is $>8\%$ more accurate, and $1.5-5\times$ more
compute-efficient. Online RL with dense rewards from PAVs enables one of the
first results with $5-6\times$ gain in sample efficiency, and $>6\%$ gain in
accuracy, over ORMs.

æè¦ï¼ä¸ç¨®æ¹åå¤§åèªè¨æ¨¡åä¸­æ¨çè½åç promising æ¹æ³æ¯ä½¿ç¨éç¨çåµæ¨¡å (PRM)ãPRM å¨å¤æ­¥é©æ¨çè¿½è¹¤çæ¯ä¸æ­¥æä¾åé¥ï¼æ½å¨æ¹åäºå°çµæçåµæ¨¡å (ORM) çä¿¡ç¨åéï¼èå¾èåå¨æå¾ä¸æ­¥æä¾åé¥ã
ç¶èï¼æ¶éå¯éçãææ­¥é©é²è¡çäººé¡æ¨ç±¤ä¸¦éå¯æ´åçï¼èå¾èªåæ¨ç±¤è³æè¨ç·´ PRM è³ä»åç²å¾æéçé²å±ãçºäºéééå° PRM å·è¡æå°æå°å¶ç¨ä½å¼·åå­¸ç¿ (RL) çå¯éçåµä¾æ¹ååºç¤æ¿ç­ï¼æåæåºçåï¼ãæåæå¦ä½è¨­è¨éç¨çåµï¼ãæåçééµè¦è§£å¨æ¼ï¼éç¨çåµè¥è¦ææï¼å°æ¼æåæ­¥é©èè¨ï¼æè¡¡éé²åº¦ï¼å¨æ¡åæ­¥é©ä¹ååä¹å¾ï¼ç¢çæ­£ç¢ºåæçå¯è½æ§ç¼çè®åï¼éå°ææ¼ RL ä¸­æ­¥é©å±¤ç´åªå¢çæ¦å¿µãè³ééè¦çæ¯ï¼æå¨èåºç¤æ¿ç­ä¸åçè­æèæ¿ç­ä¸è¡¡éæ­¤é²åº¦ãæåå¨çè«ä¸æè¿°äºè¯å¥½çè­æèçµåï¼æåççµæé¡¯ç¤ºï¼æä½³åä¾èªæ­¤é¡è­æèçéç¨çåµææ¹åæ¸¬è©¦æéæå°åç·ä¸ RL ä¸­çæ¢ç´¢ãäºå¯¦ä¸ï¼æåçæè¿°é¡¯ç¤ºï¼å¼±è­æèæ¿ç­å¯ä»¥å¤§å¹æ¹åè¼å¼·çåºç¤æ¿ç­ï¼éä¹æ¯æåå¨ç¶é©ä¸è§å¯å°çãæåééè¨ç·´éç¨åªå¢é©è­å¨ (PAV) ä¾é©è­æåçèªªæ³ï¼ä»¥é æ¸¬å¨éäºè­æèä¸çé²åº¦ï¼ä¸¦é¡¯ç¤ºè ORM ç¸æ¯ï¼éå° PAV çæ¸¬è©¦æéæå°æºç¢ºåº¦æé«äº $>8\%$ï¼è¨ç®æçæé«äº $1.5-5\times$ãéé PAV çå¯éçåµé²è¡ç·ä¸ RLï¼ç²å¾äºæ¨£æ¬æçæé« $5-6\times$ãæºç¢ºåº¦æé« $>6\%$ çé¦æ¹çµæï¼åªæ¼ ORMã

##### **Insight Over Sight? Exploring the Vision-Knowledge Conflicts in Multimodal LLMs**
2410.08145v1 by Xiaoyuan Liu, Wenxuan Wang, Youliang Yuan, Jen-tse Huang, Qiuzhi Liu, Pinjia He, Zhaopeng Tu

This paper explores the problem of commonsense-level vision-knowledge
conflict in Multimodal Large Language Models (MLLMs), where visual information
contradicts model's internal commonsense knowledge (see Figure 1). To study
this issue, we introduce an automated pipeline, augmented with
human-in-the-loop quality control, to establish a benchmark aimed at simulating
and assessing the conflicts in MLLMs. Utilizing this pipeline, we have crafted
a diagnostic benchmark comprising 374 original images and 1,122 high-quality
question-answer (QA) pairs. This benchmark covers two types of conflict target
and three question difficulty levels, providing a thorough assessment tool.
Through this benchmark, we evaluate the conflict-resolution capabilities of
nine representative MLLMs across various model families and find a noticeable
over-reliance on textual queries. Drawing on these findings, we propose a novel
prompting strategy, "Focus-on-Vision" (FoV), which markedly enhances MLLMs'
ability to favor visual data over conflicting textual knowledge. Our detailed
analysis and the newly proposed strategy significantly advance the
understanding and mitigating of vision-knowledge conflicts in MLLMs. The data
and code are made publicly available.

æè¦ï¼æ¬ææ¢è¨å¤æ¨¡æå¤§åèªè¨æ¨¡å (MLLM) ä¸­å¸¸è­å±¤ç´è¦è¦ºç¥è­è¡çªçåé¡ï¼å¶ä¸­è¦è¦ºè³è¨èæ¨¡åçå§é¨å¸¸è­ç¥è­ç¸çç¾ï¼è¦å 1ï¼ãçºäºç ç©¶éååé¡ï¼æåå¼é²äºä¸åèªååç®¡éï¼ä¸¦çµåäººå·¥è¿´ååè³ªæ§ç®¡ï¼ä»¥å»ºç«ä¸ååºæºï¼ç¨æ¼æ¨¡æ¬åè©ä¼° MLLM ä¸­çè¡çªãå©ç¨æ­¤ç®¡éï¼æåè£½ä½äºä¸åè¨ºæ·åºæºï¼åå« 374 å¼µåå§åçå 1,122 åé«åè³ªçåç­ (QA) éå°ãæ­¤åºæºæ¶µèå©ç¨®è¡çªç®æ¨åä¸ååé¡é£åº¦ç­ç´ï¼æä¾äºä¸åå¨é¢çè©ä¼°å·¥å·ãééæ­¤åºæºï¼æåè©ä¼°äºä¹åä»£è¡¨æ§ MLLM å¨ä¸åæ¨¡åç³»åä¸­çè¡çªè§£æ±ºè½åï¼ä¸¦ç¼ç¾æé¡¯éåº¦ä¾è³´æå­æ¥è©¢ãæ ¹æéäºç¼ç¾ï¼æåæåºäºä¸ç¨®æ°ç©çæç¤ºç­ç¥ãå°æ³¨æ¼è¦è¦ºã(FoV)ï¼å®é¡¯èå¢å¼·äº MLLM åªåè¦è¦ºè³æèéè¡çªæå­ç¥è­çè½åãæåè©³ç´°çåæåæ°æåºçç­ç¥å¤§å¹æ¨é²äºå° MLLM ä¸­è¦è¦ºç¥è­è¡çªççè§£åç·©è§£ãè³æåç¨å¼ç¢¼å·²å¬éæä¾ã

##### **DelTA: An Online Document-Level Translation Agent Based on Multi-Level Memory**
2410.08143v1 by Yutong Wang, Jiali Zeng, Xuebo Liu, Derek F. Wong, Fandong Meng, Jie Zhou, Min Zhang

Large language models (LLMs) have achieved reasonable quality improvements in
machine translation (MT). However, most current research on MT-LLMs still faces
significant challenges in maintaining translation consistency and accuracy when
processing entire documents. In this paper, we introduce DelTA, a
Document-levEL Translation Agent designed to overcome these limitations. DelTA
features a multi-level memory structure that stores information across various
granularities and spans, including Proper Noun Records, Bilingual Summary,
Long-Term Memory, and Short-Term Memory, which are continuously retrieved and
updated by auxiliary LLM-based components. Experimental results indicate that
DelTA significantly outperforms strong baselines in terms of translation
consistency and quality across four open/closed-source LLMs and two
representative document translation datasets, achieving an increase in
consistency scores by up to 4.58 percentage points and in COMET scores by up to
3.16 points on average. DelTA employs a sentence-by-sentence translation
strategy, ensuring no sentence omissions and offering a memory-efficient
solution compared to the mainstream method. Furthermore, DelTA improves pronoun
translation accuracy, and the summary component of the agent also shows promise
as a tool for query-based summarization tasks. We release our code and data at
https://github.com/YutongWang1216/DocMTAgent.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨æ©å¨ç¿»è­¯ (MT) ä¸­ç²å¾äºåççåè³ªæåãç¶èï¼ç®åå¤§å¤æ¸éæ¼ MT-LLM çç ç©¶å¨èçå®æ´æä»¶æï¼å¨ç¶­æç¿»è­¯çä¸è´æ§åæºç¢ºæ§æ¹é¢ä»é¢è¨éå¤§ææ°ãå¨æ¬æä¸­ï¼æåä»ç´¹äº DelTAï¼éæ¯ä¸åæä»¶ç´å¥ç¿»è­¯ä»£çï¼æ¨å¨åæéäºéå¶ãDelTA å·æå¤å±¤ç´è¨æ¶é«çµæ§ï¼å¯å¨åç¨®ç²åº¦åç¯åå§å²å­è³è¨ï¼åæ¬å°æåè©è¨éãéèªæè¦ãé·æè¨æ¶é«åç­æè¨æ¶é«ï¼éäºè¨æ¶é«æç±è¼å©çåºæ¼ LLM ççµä»¶æçºæ·ååæ´æ°ãå¯¦é©çµæè¡¨æï¼å¨ç¿»è­¯ä¸è´æ§ååè³ªæ¹é¢ï¼DelTA æé¡¯åªæ¼å¼·å¤§çåºæºï¼æ¶µèååéæ¾/éæº LLM åå©åå·ä»£è¡¨æ§çæä»¶ç¿»è­¯è³æéï¼å¨ä¸è´æ§è©åæ¹é¢æé«äºå¤é 4.58 åç¾åé»ï¼å¨ COMET è©åæ¹é¢å¹³åæé«äºå¤é 3.16 åãDelTA æ¡ç¨éå¥ç¿»è­¯ç­ç¥ï¼ç¢ºä¿ä¸éºæ¼å¥å­ï¼ä¸¦æä¾èä¸»æµæ¹æ³ç¸æ¯è¨æ¶é«æçé«çè§£æ±ºæ¹æ¡ãæ­¤å¤ï¼DelTA æ¹åäºä»£åè©ç¿»è­¯çæºç¢ºæ§ï¼èä»£ççæè¦çµä»¶ä¹é¡¯ç¤ºåºä½çºåºæ¼æ¥è©¢çæè¦ä»»åå·¥å·çæ½åãæåå¨ https://github.com/YutongWang1216/DocMTAgent éåºæåçç¨å¼ç¢¼åè³æã

##### **Steering Masked Discrete Diffusion Models via Discrete Denoising Posterior Prediction**
2410.08134v1 by Jarrid Rector-Brooks, Mohsin Hasan, Zhangzhi Peng, Zachary Quinn, Chenghao Liu, Sarthak Mittal, Nouha Dziri, Michael Bronstein, Yoshua Bengio, Pranam Chatterjee, Alexander Tong, Avishek Joey Bose

Generative modeling of discrete data underlies important applications
spanning text-based agents like ChatGPT to the design of the very building
blocks of life in protein sequences. However, application domains need to exert
control over the generated data by steering the generative process - typically
via RLHF - to satisfy a specified property, reward, or affinity metric. In this
paper, we study the problem of steering Masked Diffusion Models (MDMs), a
recent class of discrete diffusion models that offer a compelling alternative
to traditional autoregressive models. We introduce Discrete Denoising Posterior
Prediction (DDPP), a novel framework that casts the task of steering
pre-trained MDMs as a problem of probabilistic inference by learning to sample
from a target Bayesian posterior. Our DDPP framework leads to a family of three
novel objectives that are all simulation-free, and thus scalable while applying
to general non-differentiable reward functions. Empirically, we instantiate
DDPP by steering MDMs to perform class-conditional pixel-level image modeling,
RLHF-based alignment of MDMs using text-based rewards, and finetuning protein
language models to generate more diverse secondary structures and shorter
proteins. We substantiate our designs via wet-lab validation, where we observe
transient expression of reward-optimized protein sequences.

æè¦ï¼çæå¼ç¦»æ£æ°æ®å»ºæ¨¡æ¯éè¦åºç¨çåºç¡ï¼æ¶µçäºåºäºææ¬çä»£çï¼å¦ ChatGPTï¼å°èç½è´¨åºåä¸­çå½åºæ¬ç»æé¨åçè®¾è®¡ãç¶èï¼åºç¨é¢åéè¦éè¿æ§å¶çæè¿ç¨ï¼éå¸¸éè¿ RLHFï¼æ¥æ§å¶çæçæ°æ®ï¼ä»¥æ»¡è¶³æå®çå±æ§ãå¥å±æäº²ååº¦ææ ãå¨æ¬æä¸­ï¼æä»¬ç ç©¶äºæ§å¶æ©ç æ©æ£æ¨¡å (MDM) çé®é¢ï¼MDM æ¯ç¦»æ£æ©æ£æ¨¡åçææ°ç±»å«ï¼ä¸ºä¼ ç»çèªåå½æ¨¡åæä¾äºå¼äººæ³¨ç®çæ¿ä»£æ¹æ¡ãæä»¬å¼å¥äºç¦»æ£å»åªåéªé¢æµ (DDPP)ï¼è¿æ¯ä¸ç§æ°é¢çæ¡æ¶ï¼å®å°æ§å¶é¢è®­ç» MDM çä»»å¡è½¬åä¸ºæ¦çæ¨çé®é¢ï¼æ¹æ³æ¯å­¦ä¹ ä»ç®æ è´å¶æ¯åéªä¸­éæ ·ãæä»¬ç DDPP æ¡æ¶äº§çäºä¸ç³»åä¸ä¸ªæ°é¢çç®æ ï¼å®ä»¬é½æ¯æ æ¨¡æçï¼å æ­¤å¨åºç¨äºä¸è¬ä¸å¯å¾®åå¥å±å½æ°æ¶å·æå¯æ©å±æ§ãå­ç»éªï¼æä»¬éè¿æ§å¶ MDM æ¥æ§è¡åºäºç±»çåç´ çº§å¾åå»ºæ¨¡ãä½¿ç¨åºäºææ¬å¥å±ç MDM ç RLHF å¯¹é½ï¼ä»¥åå¾®è°èç½è´¨è¯­è¨æ¨¡åæ¥çææ´å¤æ ·åçäºçº§ç»æåæ´ç­çèç½è´¨ï¼ä»èå®ä¾å DDPPãæä»¬éè¿æ¹¿å®éªå®¤éªè¯æ¥è¯å®æä»¬çè®¾è®¡ï¼å¨è¯¥éªè¯ä¸­ï¼æä»¬è§å¯å°äºå¥å±ä¼åèç½è´¨åºåçç¬æ¶è¡¨è¾¾ã

##### **Assessing Episodic Memory in LLMs with Sequence Order Recall Tasks**
2410.08133v1 by Mathis Pink, Vy A. Vo, Qinyuan Wu, Jianing Mu, Javier S. Turek, Uri Hasson, Kenneth A. Norman, Sebastian Michelmann, Alexander Huth, Mariya Toneva

Current LLM benchmarks focus on evaluating models' memory of facts and
semantic relations, primarily assessing semantic aspects of long-term memory.
However, in humans, long-term memory also includes episodic memory, which links
memories to their contexts, such as the time and place they occurred. The
ability to contextualize memories is crucial for many cognitive tasks and
everyday functions. This form of memory has not been evaluated in LLMs with
existing benchmarks. To address the gap in evaluating memory in LLMs, we
introduce Sequence Order Recall Tasks (SORT), which we adapt from tasks used to
study episodic memory in cognitive psychology. SORT requires LLMs to recall the
correct order of text segments, and provides a general framework that is both
easily extendable and does not require any additional annotations. We present
an initial evaluation dataset, Book-SORT, comprising 36k pairs of segments
extracted from 9 books recently added to the public domain. Based on a human
experiment with 155 participants, we show that humans can recall sequence order
based on long-term memory of a book. We find that models can perform the task
with high accuracy when relevant text is given in-context during the SORT
evaluation. However, when presented with the book text only during training,
LLMs' performance on SORT falls short. By allowing to evaluate more aspects of
memory, we believe that SORT will aid in the emerging development of
memory-augmented models.

æè¦ï¼ç¾æç LLM åºæºå´éæ¼è©ä¼°æ¨¡åå°äºå¯¦åèªç¾©éä¿çè¨æ¶ï¼ä¸»è¦è©ä¼°é·æè¨æ¶çèªç¾©æ¹é¢ãç¶èï¼å¨äººé¡ä¸­ï¼é·æè¨æ¶ä¹åæ¬æç¯è¨æ¶ï¼å®å°è¨æ¶èå¶èæ¯è¯ç¹«èµ·ä¾ï¼ä¾å¦å®åç¼ççæéåå°é»ãå°è¨æ¶æå¢åçè½åå°æ¼è¨±å¤èªç¥ä»»ååæ¥å¸¸åè½è³ééè¦ãéç¨®å½¢å¼çè¨æ¶å°æªå¨ç¾æåºæºä¸­ä½¿ç¨ LLM é²è¡è©ä¼°ãçºäºè§£æ±ºè©ä¼° LLM ä¸­è¨æ¶çå·®è·ï¼æåå¼å¥äºåºåé åºå¬åä»»å (SORT)ï¼æåæ ¹æç¨æ¼ç ç©¶èªç¥å¿çå­¸ä¸­æç¯è¨æ¶çä»»åå°å¶é²è¡äºæ¹ç·¨ãSORT è¦æ± LLM å¬åææ¬çæ®µçæ­£ç¢ºé åºï¼ä¸¦æä¾äºä¸åæ¢å®¹ææ´å±åä¸éè¦ä»»ä½é¡å¤è¨»éçéç¨æ¡æ¶ãæåæåºäºåå§è©ä¼°æ¸æé Book-SORTï¼å¶ä¸­åå«å¾æè¿æ·»å å°å¬å±é åç 9 æ¬æ¸ä¸­æåç 36k å°çæ®µãæ ¹æå° 155 ååèèçå¯¦é©ï¼æåè¡¨æäººé¡å¯ä»¥æ ¹æä¸æ¬æ¸çé·æè¨æ¶ä¾åæ¶åºåé åºãæåç¼ç¾ï¼ç¶å¨ SORT è©ä¼°æéå¨ä¸ä¸æä¸­çµ¦åºç¸éææ¬æï¼æ¨¡åå¯ä»¥éå¸¸æºç¢ºå°å·è¡ä»»åãç¶èï¼ç¶å¨è¨ç·´æéåæä¾æ¸ç±ææ¬æï¼LLM å¨ SORT ä¸çè¡¨ç¾æä¸éãééåè¨±è©ä¼°è¨æ¶çæ´å¤æ¹é¢ï¼æåç¸ä¿¡ SORT å°æå©æ¼è¨æ¶å¢å¼·æ¨¡åçæ°èç¼å±ã

##### **Think Beyond Size: Dynamic Prompting for More Effective Reasoning**
2410.08130v1 by Kamesh R

This paper presents Dynamic Prompting, a novel framework aimed at improving
the reasoning capabilities of Large Language Models (LLMs). In contrast to
conventional static prompting methods, Dynamic Prompting enables the adaptive
modification of prompt sequences and step counts based on real-time task
complexity and model performance. This dynamic adaptation facilitates more
efficient problem-solving, particularly in smaller models, by reducing
hallucinations and repetitive cycles. Our empirical evaluations demonstrate
that Dynamic Prompting allows smaller LLMs to perform competitively with much
larger models, thereby challenging the conventional emphasis on model size as
the primary determinant of reasoning efficacy.

æè¦ï¼æ¬ææåºåææç¤ºï¼éæ¯ä¸åæ°ç©çæ¶æ§ï¼æ¨å¨æ¹åå¤§åèªè¨æ¨¡å (LLM) çæ¨çè½åãèå³çµ±çéææç¤ºæ¹æ³ç¸æ¯ï¼åææç¤ºè½å¤ æ ¹æå¯¦æä»»åè¤éåº¦åæ¨¡åæè½ï¼èªé©æå°ä¿®æ¹æç¤ºåºååæ­¥é©æ¸ãéç¨®åæé©ææå©æ¼æ´ææå°è§£æ±ºåé¡ï¼ç¹å¥æ¯å¨è¼å°çæ¨¡åä¸­ï¼å çºå®è½æ¸å°å¹»è¦ºåéè¤çå¾ªç°ãæåçå¯¦è­è©ä¼°è¡¨æï¼åææç¤ºè®è¼å°ç LLM è½èè¼å¤§çæ¨¡åç«¶ç­ï¼å¾èææ°äºå³çµ±ä¸å¼·èª¿æ¨¡åå¤§å°ä½çºæ¨çæè½ä¸»è¦æ±ºå®å ç´ çè§é»ã

##### **Mars: Situated Inductive Reasoning in an Open-World Environment**
2410.08126v1 by Xiaojuan Tang, Jiaqi Li, Yitao Liang, Song-chun Zhu, Muhan Zhang, Zilong Zheng

Large Language Models (LLMs) trained on massive corpora have shown remarkable
success in knowledge-intensive tasks. Yet, most of them rely on pre-stored
knowledge. Inducing new general knowledge from a specific environment and
performing reasoning with the acquired knowledge -- \textit{situated inductive
reasoning}, is crucial and challenging for machine intelligence. In this paper,
we design Mars, an interactive environment devised for situated inductive
reasoning. It introduces counter-commonsense game mechanisms by modifying
terrain, survival setting and task dependency while adhering to certain
principles. In Mars, agents need to actively interact with their surroundings,
derive useful rules and perform decision-making tasks in specific contexts. We
conduct experiments on various RL-based and LLM-based methods, finding that
they all struggle on this challenging situated inductive reasoning benchmark.
Furthermore, we explore \textit{Induction from Reflection}, where we instruct
agents to perform inductive reasoning from history trajectory. The superior
performance underscores the importance of inductive reasoning in Mars. Through
Mars, we aim to galvanize advancements in situated inductive reasoning and set
the stage for developing the next generation of AI systems that can reason in
an adaptive and context-sensitive way.

æè¦ï¼<paragraph>å¨é¾å¤§èªæåº«ä¸è¨ç·´çå¤§åèªè¨æ¨¡å (LLM) å·²å¨ç¥è­å¯éåä»»åä¸­å±ç¾åºé©äººçææãç¶èï¼å®åå¤§å¤ä¾è³´æ¼é åå²å­çç¥è­ãå¾ç¹å®ç°å¢ä¸­æ¨æ¼åºæ°çå¸¸è­ï¼ä¸¦å©ç¨ç²å¾çç¥è­é²è¡æ¨çââãæå¢æ­¸ç´æ¨çãï¼å°æ¼æ©å¨æºæ§èè¨è³ééè¦ä¸å·æææ°æ§ãå¨æ¬æä¸­ï¼æåè¨­è¨äºç«æï¼ä¸åå°çºæå¢æ­¸ç´æ¨çèè¨­è¨çäºåå¼ç°å¢ãå®ééä¿®æ¹å°å½¢ãçå­è¨­å®åä»»åä¾è³´éä¿ï¼å¼å¥äºåå¸¸è­çéæ²æ©å¶ï¼åæéµå®æäºååãå¨ç«æä¸­ï¼ä»£çäººéè¦ç©æ¥µèå¨åç°å¢äºåï¼æ¨å°åºæç¨çè¦åï¼ä¸¦å¨ç¹å®æå¢ä¸­å·è¡æ±ºç­ä»»åãæåå°åç¨®åºæ¼ RL ååºæ¼ LLM çæ¹æ³é²è¡å¯¦é©ï¼ç¼ç¾å®åå¨éåå·æææ°æ§çæå¢æ­¸ç´æ¨çåºæºä¸é½é¢è¨å°é£ãæ­¤å¤ï¼æåæ¢è¨äºãå¾åæä¸­æ­¸ç´ãï¼å¶ä¸­æåæç¤ºä»£çäººå¾æ­·å²è»è·¡ä¸­å·è¡æ­¸ç´æ¨çãåªç°çè¡¨ç¾å¼·èª¿äºæ­¸ç´æ¨çå¨ç«æä¸­çéè¦æ§ãééç«æï¼æåæ¨å¨æ¿åµæå¢æ­¸ç´æ¨ççé²å±ï¼ä¸¦çºéç¼ä¸ä¸ä»£è½å¤ ä»¥é©ææ§åæå¢ææçæ¹å¼æ¨ççäººå·¥æºæ§ç³»çµ±å¥ å®åºç¤ã</paragraph>

##### **Heterogeneous Graph Auto-Encoder for CreditCard Fraud Detection**
2410.08121v1 by Moirangthem Tiken Singh, Rabinder Kumar Prasad, Gurumayum Robert Michael, N K Kaphungkui, N. Hemarjit Singh

The digital revolution has significantly impacted financial transactions,
leading to a notable increase in credit card usage. However, this convenience
comes with a trade-off: a substantial rise in fraudulent activities.
Traditional machine learning methods for fraud detection often struggle to
capture the inherent interconnectedness within financial data. This paper
proposes a novel approach for credit card fraud detection that leverages Graph
Neural Networks (GNNs) with attention mechanisms applied to heterogeneous graph
representations of financial data. Unlike homogeneous graphs, heterogeneous
graphs capture intricate relationships between various entities in the
financial ecosystem, such as cardholders, merchants, and transactions,
providing a richer and more comprehensive data representation for fraud
analysis. To address the inherent class imbalance in fraud data, where genuine
transactions significantly outnumber fraudulent ones, the proposed approach
integrates an autoencoder. This autoencoder, trained on genuine transactions,
learns a latent representation and flags deviations during reconstruction as
potential fraud. This research investigates two key questions: (1) How
effectively can a GNN with an attention mechanism detect and prevent credit
card fraud when applied to a heterogeneous graph? (2) How does the efficacy of
the autoencoder with attention approach compare to traditional methods? The
results are promising, demonstrating that the proposed model outperforms
benchmark algorithms such as Graph Sage and FI-GRL, achieving a superior AUC-PR
of 0.89 and an F1-score of 0.81. This research significantly advances fraud
detection systems and the overall security of financial transactions by
leveraging GNNs with attention mechanisms and addressing class imbalance
through an autoencoder.

æè¦ï¼<paragraph>æ¸ä½é©å½å°éèäº¤æç¢çéå¤§å½±é¿ï¼å°è´ä¿¡ç¨å¡ä½¿ç¨çå¤§å¹å¢å ãç¶èï¼éç¨®ä¾¿å©æ§ä¹å¸¶ä¾äºä¸ååæ¨ï¼è©é¨æ´»åå¤§å¹å¢å ãå³çµ±çæ©å¨å­¸ç¿æ¹æ³å¸¸é£ä»¥ææéèè³æä¸­åºæçç¸äºéè¯æ§ãæ¬ææåºäºä¸ç¨®æ°çä¿¡ç¨å¡è©é¨åµæ¸¬æ¹æ³ï¼å®å©ç¨åç¥ç¶ç¶²è·¯ (GNN) åæ³¨ææ©å¶ï¼æç¨æ¼éèè³æçç°è³ªåè¡¨è¡¨ç¤ºãèåè³ªåè¡¨ä¸åï¼ç°è³ªåè¡¨ææäºéèçæç³»çµ±ä¸­åç¨®å¯¦é«ä¹éçè¤ééä¿ï¼ä¾å¦æå¡äººãåå®¶åäº¤æï¼çºè©é¨åææä¾æ´è±å¯ãæ´å¨é¢çè³æè¡¨ç¤ºãçºäºè§£æ±ºè©é¨è³æä¸­åºæçé¡å¥ä¸å¹³è¡¡åé¡ï¼å¶ä¸­çå¯¦äº¤æé å¤æ¼è©é¨äº¤æï¼ææåºçæ¹æ³æ´åäºä¸åèªåç·¨ç¢¼å¨ãéåèªåç·¨ç¢¼å¨å¨çå¯¦äº¤æä¸­è¨ç·´ï¼å­¸ç¿æ½å¨è¡¨ç¤ºï¼ä¸¦å¨éå»ºéç¨ä¸­æ¨è¨åå·®çºæ½å¨è©é¨ãæ¬ç ç©¶æ¢è¨äºå©åééµåé¡ï¼(1) ç¶æç¨æ¼ç°è³ªåè¡¨æï¼å·ææ³¨æåæ©å¶ç GNN å¨åµæ¸¬åé é²ä¿¡ç¨å¡è©é¨æ¹é¢æå¤ææï¼(2) å·ææ³¨æåæ¹æ³çèªåç·¨ç¢¼å¨çæè½èå³çµ±æ¹æ³ç¸æ¯å¦ä½ï¼çµæä»¤äººæ»¿æï¼è­æææåºçæ¨¡ååªæ¼åºæºæ¼ç®æ³ï¼ä¾å¦ Graph Sage å FI-GRLï¼éå° 0.89 çåªç° AUC-PR å 0.81 ç F1 åæ¸ãæ¬ç ç©¶ééå©ç¨å·ææ³¨æåæ©å¶ç GNNï¼ä¸¦ééèªåç·¨ç¢¼å¨è§£æ±ºé¡å¥ä¸å¹³è¡¡åé¡ï¼å¤§å¹æåäºè©é¨åµæ¸¬ç³»çµ±åéèäº¤æçæ´é«å®å¨æ§ã</paragraph>

##### **Optima: Optimizing Effectiveness and Efficiency for LLM-Based Multi-Agent System**
2410.08115v1 by Weize Chen, Jiarui Yuan, Chen Qian, Cheng Yang, Zhiyuan Liu, Maosong Sun

Large Language Model (LLM) based multi-agent systems (MAS) show remarkable
potential in collaborative problem-solving, yet they still face critical
challenges: low communication efficiency, poor scalability, and a lack of
effective parameter-updating optimization methods. We present Optima, a novel
framework that addresses these issues by significantly enhancing both
communication efficiency and task effectiveness in LLM-based MAS through LLM
training. Optima employs an iterative generate, rank, select, and train
paradigm with a reward function balancing task performance, token efficiency,
and communication readability. We explore various RL algorithms, including
Supervised Fine-Tuning, Direct Preference Optimization, and their hybrid
approaches, providing insights into their effectiveness-efficiency trade-offs.
We integrate Monte Carlo Tree Search-inspired techniques for DPO data
generation, treating conversation turns as tree nodes to explore diverse
interaction paths. Evaluated on common multi-agent tasks, including
information-asymmetric question answering and complex reasoning, Optima shows
consistent and substantial improvements over single-agent baselines and vanilla
MAS based on Llama 3 8B, achieving up to 2.8x performance gain with less than
10\% tokens on tasks requiring heavy information exchange. Moreover, Optima's
efficiency gains open new possibilities for leveraging inference-compute more
effectively, leading to improved inference-time scaling laws. By addressing
fundamental challenges in LLM-based MAS, Optima shows the potential towards
scalable, efficient, and effective MAS
(https://chenweize1998.github.io/optima-project-page).

æè¦ï¼<paragraph>å¤§åèªè¨æ¨¡å (LLM) çºåºç¤çå¤éä»£çç³»çµ± (MAS) å¨åä½åé¡è§£æ±ºæ¹é¢å±ç¾äºéå¡çæ½åï¼ä½ä»é¢è¨ééµææ°ï¼ä½æºéæçãå¯æ´åæ§å·®ï¼ä»¥åç¼ºä¹ææçåæ¸æ´æ°æä½³åæ¹æ³ãæåæåº Optimaï¼ä¸åæ°ç©çæ¶æ§ï¼éé LLM è¨ç·´å¤§å¹æå LLM çºåºç¤ç MAS ä¸­çæºéæçåä»»åæè½ï¼ä¾è§£æ±ºéäºåé¡ãOptima æ¡ç¨åè¦çæãæåãé¸æåè¨ç·´çç¯ä¾ï¼å¶çåµå½æ¸å¹³è¡¡äºä»»åè¡¨ç¾ãç¬¦èæçåæºéå¯è®æ§ãæåæ¢è¨äºåç¨® RL æ¼ç®æ³ï¼åæ¬ç£ç£å¾®èª¿ãç´æ¥åå¥½æä½³åï¼ä»¥åå¶æ··åæ¹æ³ï¼é²ä¸æ­¥äºè§£å¶æè½æççæ¬è¡¡åæ¨ãæåæ´åäºèå°å¡ç¾æ¨¹çæå°åç¼çæè¡ï¼ç¨æ¼ DPO è³æç¢çï¼å°å°è©±ååè¦çºæ¨¹çç¯é»ï¼ä»¥æ¢ç´¢å¤æ¨£åçäºåè·¯å¾ãå¨å¸¸è¦çå¤éä»£çä»»åä¸­é²è¡è©ä¼°ï¼åæ¬è³è¨ä¸å°ç¨±åç­åè¤éæ¨çï¼Optima å¨å®ä¸ä»£çåºæºååºæ¼ Llama 3 8B çé¦è MAS ä¸å±ç¾äºä¸è´ä¸é¡¯èçé²æ­¥ï¼å¨éè¦å¤§éè³è¨äº¤æçä»»åä¸­ï¼ä»¥ä¸å° 10% çç¬¦èç²å¾äºé«é 2.8 åçæè½æåãæ­¤å¤ï¼Optima çæçæåçºæ´ææå°éç¨æ¨çéç®éåäºæ°çå¯è½æ§ï¼é²èæ¹åæ¨çæéçç¸®æ¾å®å¾ãééè§£æ±º LLM çºåºç¤ç MAS ä¸­çåºæ¬ææ°ï¼Optima å±ç¾äºéåå¯æ´åãé«æåææç MAS çæ½å
(https://chenweize1998.github.io/optima-project-page)ã</paragraph>

##### **Robust AI-Generated Text Detection by Restricted Embeddings**
2410.08113v1 by Kristian Kuznetsov, Eduard Tulchinskii, Laida Kushnareva, German Magai, Serguei Barannikov, Sergey Nikolenko, Irina Piontkovskaya

Growing amount and quality of AI-generated texts makes detecting such content
more difficult. In most real-world scenarios, the domain (style and topic) of
generated data and the generator model are not known in advance. In this work,
we focus on the robustness of classifier-based detectors of AI-generated text,
namely their ability to transfer to unseen generators or semantic domains. We
investigate the geometry of the embedding space of Transformer-based text
encoders and show that clearing out harmful linear subspaces helps to train a
robust classifier, ignoring domain-specific spurious features. We investigate
several subspace decomposition and feature selection strategies and achieve
significant improvements over state of the art methods in cross-domain and
cross-generator transfer. Our best approaches for head-wise and
coordinate-based subspace removal increase the mean out-of-distribution (OOD)
classification score by up to 9% and 14% in particular setups for RoBERTa and
BERT embeddings respectively. We release our code and data:
https://github.com/SilverSolver/RobustATD

æè¦ï¼äººå·¥æºè½çæææ¬çæ°éåè´¨éä¸æ­æé«ï¼ä½¿å¾æ£æµæ­¤ç±»åå®¹åå¾æ´å å°é¾ãå¨å¤§å¤æ°å®éåºæ¯ä¸­ï¼çææ°æ®çåï¼æ ·å¼åä¸»é¢ï¼åçæå¨æ¨¡åäºåå¹¶ä¸ç¥éãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬ä¸æ³¨äºåºäºåç±»å¨ç AI çæçææ¬æ£æµå¨çé²æ£æ§ï¼å³å®ä»¬è½¬ç§»å°æªè§ççæå¨æè¯­ä¹åçè½åãæä»¬ç ç©¶äºåºäº Transformer çææ¬ç¼ç å¨çåµå¥ç©ºé´çå ä½å½¢ç¶ï¼å¹¶è¡¨ææ¸é¤æå®³ççº¿æ§å­ç©ºé´æå©äºè®­ç»é²æ£åç±»å¨ï¼å¿½ç¥ç¹å®äºåçèåç¹å¾ãæä»¬ç ç©¶äºå ä¸ªå­ç©ºé´åè§£åç¹å¾éæ©ç­ç¥ï¼å¹¶å¨è·¨ååè·¨çæå¨è½¬ç§»ä¸­å®ç°äºå¯¹ç°æææ¯çéå¤§æ¹è¿ãæä»¬ç¨äºéå¤´ååºäºåæ çå­ç©ºé´ç§»é¤çæä½³æ¹æ³å°å¹³ååå¸å¤ (OOD) åç±»åæ°åå«æé«äº RoBERTa å BERT åµå¥çç¹å®è®¾ç½®ä¸­ç 9% å 14%ãæä»¬åå¸æä»¬çä»£ç åæ°æ®ï¼https://github.com/SilverSolver/RobustATD

##### **Active Fourier Auditor for Estimating Distributional Properties of ML Models**
2410.08111v1 by Ayoub Ajarra, Bishwamittra Ghosh, Debabrota Basu

With the pervasive deployment of Machine Learning (ML) models in real-world
applications, verifying and auditing properties of ML models have become a
central concern. In this work, we focus on three properties: robustness,
individual fairness, and group fairness. We discuss two approaches for auditing
ML model properties: estimation with and without reconstruction of the target
model under audit. Though the first approach is studied in the literature, the
second approach remains unexplored. For this purpose, we develop a new
framework that quantifies different properties in terms of the Fourier
coefficients of the ML model under audit but does not parametrically
reconstruct it. We propose the Active Fourier Auditor (AFA), which queries
sample points according to the Fourier coefficients of the ML model, and
further estimates the properties. We derive high probability error bounds on
AFA's estimates, along with the worst-case lower bounds on the sample
complexity to audit them. Numerically we demonstrate on multiple datasets and
models that AFA is more accurate and sample-efficient to estimate the
properties of interest than the baselines.

æè¦ï¼é¨èæ©å¨å­¸ç¿ (ML) æ¨¡åå¨å¯¦éæç¨ä¸­å»£æ³é¨ç½²ï¼é©è­åå¯©æ ¸ ML æ¨¡åçå±¬æ§å·²æçºä¸é æ ¸å¿éæ³¨äºé ãå¨éé å·¥ä½ä¸­ï¼æåå°æ³¨æ¼ä¸åå±¬æ§ï¼ç©©å¥æ§ãåå¥å¬å¹³æ§åç¾¤é«å¬å¹³æ§ãæåè¨è«äºå¯©æ ¸ ML æ¨¡åå±¬æ§çå©ç¨®æ¹æ³ï¼å¨æåæ²æéå»ºå¯©æ ¸ç®æ¨æ¨¡åçææ³ä¸é²è¡ä¼°è¨ãåç®¡ç¬¬ä¸ç¨®æ¹æ³å¨æç»ä¸­å¾å°äºç ç©¶ï¼ä½ç¬¬äºç¨®æ¹æ³ä»æªå¾å°æ¢ç´¢ãçºæ­¤ï¼æåéç¼äºä¸åæ°çæ¡æ¶ï¼è©²æ¡æ¶æ ¹æå¯©æ ¸ä¸­ç ML æ¨¡åçåç«èä¿æ¸å°ä¸åçå±¬æ§é²è¡éåï¼ä½ä¸æå°å¶é²è¡åæ¸åéå»ºãæåæåºäºä¸»ååç«èå¯©æ ¸å¨ (AFA)ï¼å®æ ¹æ ML æ¨¡åçåç«èä¿æ¸æ¥è©¢æ¨£æ¬é»ï¼ä¸¦é²ä¸æ­¥ä¼°è¨å±¬æ§ãæåæ¨å°åº AFA ä¼°è¨çé«æ©çèª¤å·®çéï¼ä»¥åå¯©æ ¸å®åçæ¨£æ¬è¤éåº¦çæå£ææ³ä¸çãæåå¨å¤åæ¸æéåæ¨¡åä¸æ¸å¼è­æï¼AFA æ¯åºæºç·æ´æºç¢ºä¸æ´å·æ¨£æ¬æçï¼å¯ä»¥ä¼°è¨æèè¶£çå±¬æ§ã

##### **A Closer Look at Machine Unlearning for Large Language Models**
2410.08109v1 by Xiaojian Yuan, Tianyu Pang, Chao Du, Kejiang Chen, Weiming Zhang, Min Lin

Large language models (LLMs) may memorize sensitive or copyrighted content,
raising privacy and legal concerns. Due to the high cost of retraining from
scratch, researchers attempt to employ machine unlearning to remove specific
content from LLMs while preserving the overall performance. In this paper, we
discuss several issues in machine unlearning for LLMs and provide our insights
on possible approaches. To address the issue of inadequate evaluation of model
outputs after unlearning, we introduce three additional metrics to evaluate
token diversity, sentence semantics, and factual correctness. We then
categorize unlearning methods into untargeted and targeted, and discuss their
issues respectively. Specifically, the behavior that untargeted unlearning
attempts to approximate is unpredictable and may involve hallucinations, and
existing regularization is insufficient for targeted unlearning. To alleviate
these issues, we propose using the objective of maximizing entropy (ME) for
untargeted unlearning and incorporate answer preservation (AP) loss as
regularization for targeted unlearning. Experimental results across three
scenarios, i.e., fictitious unlearning, continual unlearning, and real-world
unlearning, demonstrate the effectiveness of our approaches. The code is
available at https://github.com/sail-sg/closer-look-LLM-unlearning.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¯è½æè¨æ¶æææåçæ¬ä¿è­·çå§å®¹ï¼å¼ç¼é±ç§åæ³å¾åé¡ãç±æ¼å¾é ­éå§éæ°è¨ç·´çææ¬å¾é«ï¼ç ç©¶äººå¡åè©¦æ¡ç¨æ©å¨éºå¿ä¾ç§»é¤ LLM ä¸­çç¹å®å§å®¹ï¼åæä¿çæ´é«æè½ãå¨æ¬æä¸­ï¼æåè¨è«äº LLM æ©å¨éºå¿çå¹¾ååé¡ï¼ä¸¦æä¾æåå°å¯è½æ¹æ³çè¦è§£ãçºäºè§£æ±ºéºå¿å¾æ¨¡åè¼¸åºçè©ä¼°ä¸è¶³åé¡ï¼æåå¼å¥äºä¸åé¡å¤çææ¨ä¾è©ä¼°ä»£å¹£å¤æ¨£æ§ãå¥å­èªç¾©åäºå¯¦æ­£ç¢ºæ§ãç¶å¾ï¼æåå°éºå¿æ¹æ³åé¡çºéç®æ¨åç®æ¨ï¼ä¸¦åå¥è¨è«å®åçåé¡ãå·é«ä¾èªªï¼éç®æ¨éºå¿åè©¦è¿ä¼¼çè¡çºæ¯ä¸å¯é æ¸¬çï¼å¯è½æ¶åå¹»è¦ºï¼èç¾æçæ­£ååä¸è¶³ä»¥é²è¡ç®æ¨éºå¿ãçºäºç·©è§£éäºåé¡ï¼æåå»ºè­°ä½¿ç¨æå¤§åçµ (ME) çç®æ¨é²è¡éç®æ¨éºå¿ï¼ä¸¦å°ç­æ¡ä¿ç (AP) æå¤±ç´å¥ç®æ¨éºå¿çæ­£ååãå¨èæ§éºå¿ãæçºéºå¿åçå¯¦ä¸çéºå¿éä¸ç¨®å ´æ¯ä¸­çå¯¦é©çµæè­æäºæåæ¹æ³çæææ§ãç¨å¼ç¢¼å¯å¨ https://github.com/sail-sg/closer-look-LLM-unlearning åå¾ã

##### **What Makes Large Language Models Reason in (Multi-Turn) Code Generation?**
2410.08105v1 by Kunhao Zheng, Juliette Decugis, Jonas Gehring, Taco Cohen, Benjamin Negrevergne, Gabriel Synnaeve

Prompting techniques such as chain-of-thought have established themselves as
a popular vehicle for improving the outputs of large language models (LLMs).
For code generation, however, their exact mechanics and efficacy are
under-explored. We thus investigate the effects of a wide range of prompting
strategies with a focus on automatic re-prompting over multiple turns and
computational requirements. After systematically decomposing reasoning,
instruction, and execution feedback prompts, we conduct an extensive grid
search on the competitive programming benchmarks CodeContests and TACO for
multiple LLM families and sizes (Llama 3.0 and 3.1, 8B, 70B, 405B, and GPT-4o).
Our study reveals strategies that consistently improve performance across all
models with small and large sampling budgets. We then show how finetuning with
such an optimal configuration allows models to internalize the induced
reasoning process and obtain improvements in performance and scalability for
multi-turn code generation.

æè¦ï¼æç¤ºæè¡ï¼ä¾å¦ææ³éï¼å·²ç¢ºç«çºæ¹åå¤§åèªè¨æ¨¡å (LLM) è¼¸åºçç±éè¼é«ã
ç¶èï¼å°æ¼ç¨å¼ç¢¼ç¢çï¼å®åç¢ºåçæ©å¶åæåå°æªå¾å°ååæ¢è¨ãå æ­¤ï¼æåç ç©¶äºåç¨®æç¤ºç­ç¥çå½±é¿ï¼éé»éæ³¨å¤è¼ªèªåéæ°æç¤ºåéç®éæ±ãå¨ç³»çµ±åè§£æ¨çãæä»¤åå·è¡åé¥æç¤ºå¾ï¼æåå°ç«¶ç­æ§ç¨å¼è¨­è¨åºæº CodeContests å TACO é²è¡äºå»£æ³çç¶²æ ¼æå°ï¼ä»¥æ¶µèå¤å LLM å®¶æåè¦æ¨¡ï¼Llama 3.0 å 3.1ã8Bã70Bã405B å GPT-4oï¼ã
æåçç ç©¶æ­ç¤ºäºå¨æææ¨¡åä¸­æçºæ¹åæè½çç­ç¥ï¼éäºæ¨¡åå·æå°åå¤§æ½æ¨£é ç®ãç¶å¾ï¼æåå±ç¤ºäºå¦ä½ä½¿ç¨æ­¤é¡æä½³éç½®é²è¡å¾®èª¿ï¼ä½¿æ¨¡åè½å¤ å§åèªå°æ¨çéç¨ï¼ä¸¦ç²å¾å¤è¼ªç¨å¼ç¢¼ç¢ççæè½åå¯æ´åæ§æ¹åã

##### **Multi-Agent Collaborative Data Selection for Efficient LLM Pretraining**
2410.08102v1 by Tianyi Bai, Ling Yang, Zhen Hao Wong, Jiahui Peng, Xinlin Zhuang, Chi Zhang, Lijun Wu, Qiu Jiantao, Wentao Zhang, Binhang Yuan, Conghui He

Efficient data selection is crucial to accelerate the pretraining of large
language models (LLMs). While various methods have been proposed to enhance
data efficiency, limited research has addressed the inherent conflicts between
these approaches to achieve optimal data selection for LLM pretraining. To
tackle this problem, we propose a novel multi-agent collaborative data
selection mechanism. In this framework, each data selection method serves as an
independent agent, and an agent console is designed to dynamically integrate
the information from all agents throughout the LLM training process. We conduct
extensive empirical studies to evaluate our multi-agent framework. The
experimental results demonstrate that our approach significantly improves data
efficiency, accelerates convergence in LLM training, and achieves an average
performance gain of 10.5% across multiple language model benchmarks compared to
the state-of-the-art methods.

æè¦ï¼ææççè³æé¸åå°æ¼å éå¤§åèªè¨æ¨¡å (LLM) çé è¨ç·´è³ééè¦ãéç¶å·²ç¶æåºäºåç¨®æ¹æ³ä¾æåè³ææçï¼ä½éå°éäºæ¹æ³ä¹éçåºæè¡çªä»¥éæ LLM é è¨ç·´çæä½³è³æé¸åï¼ç¸éç ç©¶å»å¾æéãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸ç¨®æ°ç©çå¤éä»£çäººåä½è³æé¸åæ©å¶ãå¨éåæ¶æ§ä¸­ï¼æ¯åè³æé¸åæ¹æ³é½ä½çºä¸åç¨ç«çä»£çäººï¼èä¸åä»£çäººæ§å¶å°åè¢«è¨­è¨æå¨ LLM è¨ç·´éç¨ä¸­åææ´åææä»£çäººçè³è¨ãæåé²è¡äºå»£æ³çå¯¦è­ç ç©¶ä¾è©ä¼°æåçå¤éä»£çäººæ¶æ§ãå¯¦é©çµæè­æï¼æåçæ¹æ³é¡¯èæåäºè³ææçï¼å éäº LLM è¨ç·´ä¸­çæ¶æéåº¦ï¼ä¸¦ä¸å¨å¤åèªè¨æ¨¡ååºæºæ¸¬è©¦ä¸­ï¼èæåé²çæ¹æ³ç¸æ¯ï¼éå°äºå¹³å 10.5% çæè½æåã

##### **A Generative AI Technique for Synthesizing a Digital Twin for U.S. Residential Solar Adoption and Generation**
2410.08098v1 by Aparna Kishore, Swapna Thorve, Madhav Marathe

Residential rooftop solar adoption is considered crucial for reducing carbon
emissions. The lack of photovoltaic (PV) data at a finer resolution (e.g.,
household, hourly levels) poses a significant roadblock to informed
decision-making. We discuss a novel methodology to generate a highly granular,
residential-scale realistic dataset for rooftop solar adoption across the
contiguous United States. The data-driven methodology consists of: (i)
integrated machine learning models to identify PV adopters, (ii) methods to
augment the data using explainable AI techniques to glean insights about key
features and their interactions, and (iii) methods to generate household-level
hourly solar energy output using an analytical model. The resulting synthetic
datasets are validated using real-world data and can serve as a digital twin
for modeling downstream tasks. Finally, a policy-based case study utilizing the
digital twin for Virginia demonstrated increased rooftop solar adoption with
the 30\% Federal Solar Investment Tax Credit, especially in
Low-to-Moderate-Income communities.

æè¦ï¼ä½å®å±é å¤ªé½è½æ¡ç¨è¢«èªçºæ¯æ¸å°ç¢³ææ¾çééµãç¼ºä¹æ´ç´°ç·»è§£æåº¦ï¼ä¾å¦å®¶åº­ãæ¯å°æç­ç´ï¼çåé»ï¼PVï¼æ¸æï¼å°ææºæ±ºç­å¶å®æ§æéå¤§éç¤ãæåè¨è«ä¸ç¨®æ°æ¹æ³ï¼ä»¥ç¢çä¸åé«åº¦ç´°ç·»ãä½å®è¦æ¨¡çå¯¦éæ¸æéï¼ç¨æ¼ç¾åæ¬åçå±é å¤ªé½è½æ¡ç¨ãè³æé©åçæ¹æ³åæ¬ï¼(i) æ´åæ©å¨å­¸ç¿æ¨¡åä»¥è­å¥åé»æ¡ç¨èï¼(ii) ä½¿ç¨å¯è§£é AI æè¡æ´åæ¸æçæ¹æ³ï¼ä»¥æ¶ééæ¼ééµç¹å¾µåå¶äº¤äºä½ç¨çè¦è§£ï¼ä»¥å (iii) ä½¿ç¨åææ¨¡åç¢çå®¶åº­ç­ç´æ¯å°æå¤ªé½è½è¼¸åºçæ¹æ³ãç¢ççåææ¸æéä½¿ç¨çå¯¦ä¸çæ¸æé©è­ï¼ä¸¦ä¸å¯ä»¥ç¨ä½å»ºæ¨¡ä¸æ¸¸ä»»åçæ¸ä½éèèãæå¾ï¼å©ç¨æ¸ä½éèèéå°ç¶­åå°¼äºå·é²è¡çåºæ¼æ¿ç­çæ¡ä¾ç ç©¶ï¼è­æå±é å¤ªé½è½æ¡ç¨çé¨è 30% è¯é¦å¤ªé½è½æè³ç¨æ¶æµåèå¢å ï¼å°¤å¶æ¯å¨ä¸­ä½æ¶å¥ç¤¾åã

##### **Can Knowledge Graphs Make Large Language Models More Trustworthy? An Empirical Study over Open-ended Question Answering**
2410.08085v1 by Yuan Sui, Bryan Hooi

Recent works integrating Knowledge Graphs (KGs) have led to promising
improvements in enhancing reasoning accuracy of Large Language Models (LLMs).
However, current benchmarks mainly focus on closed tasks, leaving a gap in the
assessment of more complex, real-world scenarios. This gap has also obscured
the evaluation of KGs' potential to mitigate the problem of hallucination in
LLMs. To fill the gap, we introduce OKGQA, a new benchmark specifically
designed to assess LLMs enhanced with KGs under open-ended, real-world question
answering scenarios. OKGQA is designed to closely reflect the complexities of
practical applications using questions from different types, and incorporates
specific metrics to measure both the reduction in hallucinations and the
enhancement in reasoning capabilities. To consider the scenario in which KGs
may have varying levels of mistakes, we further propose another experiment
setting OKGQA-P to assess model performance when the semantics and structure of
KGs are deliberately perturbed and contaminated. OKGQA aims to (1) explore
whether KGs can make LLMs more trustworthy in an open-ended setting, and (2)
conduct a comparative analysis to shed light on methods and future directions
for leveraging KGs to reduce LLMs' hallucination. We believe that this study
can facilitate a more complete performance comparison and encourage continuous
improvement in integrating KGs with LLMs.

æè¦ï¼è¿æçç¥è¯å¾è°± (KG) æ´åç ç©¶ï¼å·²æåå¤§åè¯­è¨æ¨¡å (LLM) æ¨çåç¡®åº¦çè¡¨ç°ã
ç¶èï¼ç°æçåºåæµè¯ä¸»è¦çéäºå°é­å¼ä»»å¡ï¼å¨è¯ä¼°æ´å¤æãæ´å®éçåºæ¯æ¶å­å¨ç¼ºå£ãæ­¤ç¼ºå£ä¹æ¨¡ç³äºç¥è¯å¾è°±å¨åè½» LLM å¹»è§é®é¢ä¸çæ½åè¯ä¼°ãä¸ºäºå¡«è¡¥æ­¤ç¼ºå£ï¼æä»¬å¼å¥äº OKGQAï¼è¿æ¯ä¸ä¸ªä¸é¨è®¾è®¡ç¨æ¥è¯ä¼°å¨å¼æ¾å¼ãå®éé®ç­åºæ¯ä¸­ï¼å¢å¼ºäºç¥è¯å¾è°±ç LLM çæ°åºåæµè¯ãOKGQA æ¨å¨ç´§å¯åæ å®éåºç¨ä¸­çå¤ææ§ï¼ä½¿ç¨ä¸åç±»åçé¢ç®ï¼å¹¶çº³å¥ç¹å®ææ æ¥è¡¡éå¹»è§çåå°åæ¨çè½åçå¢å¼ºãä¸ºäºèèç¥è¯å¾è°±å¯è½å­å¨ä¸åç¨åº¦éè¯¯çåºæ¯ï¼æä»¬è¿ä¸æ­¥æåºäºå¦ä¸ä¸ªå®éªè®¾ç½® OKGQA-Pï¼ä»¥è¯ä¼°å½ç¥è¯å¾è°±çè¯­ä¹åç»æè¢«æææ°å¨åæ±¡ææ¶çæ¨¡åæ§è½ãOKGQA æ¨å¨ (1) æ¢ç´¢ç¥è¯å¾è°±æ¯å¦è½ä½¿ LLM å¨å¼æ¾å¼è®¾ç½®ä¸­æ´å¼å¾ä¿¡èµï¼ä»¥å (2) è¿è¡æ¯è¾åæï¼ä»¥éæå©ç¨ç¥è¯å¾è°±æ¥åå° LLM å¹»è§çæ¹æ³åæªæ¥æ¹åãæä»¬ç¸ä¿¡è¿é¡¹ç ç©¶å¯ä»¥ä¿è¿æ´å®æ´çæ§è½æ¯è¾ï¼å¹¶é¼å±æç»­æ¹è¿ç¥è¯å¾è°±ä¸ LLM çæ´åã

##### **Packing Analysis: Packing Is More Appropriate for Large Models or Datasets in Supervised Fine-tuning**
2410.08081v1 by Shuhe Wang, Guoyin Wang, Jiwei Li, Eduard Hovy, Chen Guo

Packing, initially utilized in the pre-training phase, is an optimization
technique designed to maximize hardware resource efficiency by combining
different training sequences to fit the model's maximum input length. Although
it has demonstrated effectiveness during pre-training, there remains a lack of
comprehensive analysis for the supervised fine-tuning (SFT) stage on the
following points: (1) whether packing can effectively enhance training
efficiency while maintaining performance, (2) the suitable size of the model
and dataset for fine-tuning with the packing method, and (3) whether packing
unrelated or related training samples might cause the model to either
excessively disregard or over-rely on the context.
  In this paper, we perform extensive comparisons between SFT methods using
padding and packing, covering SFT datasets ranging from 69K to 1.2M and models
from 8B to 70B. This provides the first comprehensive analysis of the
advantages and limitations of packing versus padding, as well as practical
considerations for implementing packing in various training scenarios. Our
analysis covers various benchmarks, including knowledge, reasoning, and coding,
as well as GPT-based evaluations, time efficiency, and other fine-tuning
parameters. We also open-source our code for fine-tuning and evaluation and
provide checkpoints fine-tuned on datasets of different sizes, aiming to
advance future research on packing methods. Code is available at:
https://github.com/ShuheWang1998/Packing-Analysis?tab=readme-ov-file.

æè¦ï¼<paragraph>å¨é è¨ç·´éæ®µæåä½¿ç¨çå°è£æ¯ä¸ç¨®æä½³åæè¡ï¼æ¨å¨ééçµåä¸åçè¨ç·´åºåä»¥ç¬¦åæ¨¡åçæå¤§è¼¸å¥é·åº¦ä¾æå¤§åç¡¬é«è³æºæçãåç®¡å®å·²å¨é è¨ç·´éç¨ä¸­è­æå¶æææ§ï¼ä½éå°ç£ç£å¼å¾®èª¿ (SFT) éæ®µä»ç¼ºä¹ä»¥ä¸æ¹é¢çå¨é¢åæï¼(1) å°è£æ¯å¦è½æææåè¨ç·´æçï¼åæç¶­ææè½ï¼(2) é©ç¨æ¼å°è£æ¹æ³å¾®èª¿çæ¨¡ååè³æéçé©ç¶å¤§å°ï¼ä»¥å (3) å°è£ç¡éæç¸éçè¨ç·´æ¨£æ¬æ¯å¦å¯è½å°è´æ¨¡åéåº¦å¿½ç¥æéåº¦ä¾è³´ä¸ä¸æã
å¨æ¬è«æä¸­ï¼æåå°ä½¿ç¨å¡«ååå°è£ç SFT æ¹æ³é²è¡å»£æ³æ¯è¼ï¼æ¶µèå¾ 69K å° 1.2M ç SFT è³æéåå¾ 8B å° 70B çæ¨¡åãéæä¾äºå°è£ç¸å°æ¼å¡«åçåªç¼ºé»ï¼ä»¥åå¨åç¨®è¨ç·´å ´æ¯ä¸­å¯¦ä½å°è£çå¯¦åèéçé¦æ¬¡å¨é¢åæãæåçåææ¶µèåç¨®åºæºï¼åæ¬ç¥è­ãæ¨çåç·¨ç¢¼ï¼ä»¥ååºæ¼ GPT çè©ä¼°ãæéæçåå¶ä»å¾®èª¿åæ¸ãæåä¹éæ¾åå§ç¢¼é²è¡å¾®èª¿åè©ä¼°ï¼ä¸¦æä¾éå°ä¸åå¤§å°è³æéå¾®èª¿çæª¢æ¥é»ï¼ç®æ¨æ¯æ¨é²å°è£æ¹æ³çæªä¾ç ç©¶ãç¨å¼ç¢¼å¯æ¼æ­¤èåå¾ï¼
https://github.com/ShuheWang1998/Packing-Analysis?tab=readme-ov-fileã</paragraph>

##### **Unlearning-based Neural Interpretations**
2410.08069v1 by Ching Lam Choi, Alexandre Duplessis, Serge Belongie

Gradient-based interpretations often require an anchor point of comparison to
avoid saturation in computing feature importance. We show that current
baselines defined using static functions--constant mapping, averaging or
blurring--inject harmful colour, texture or frequency assumptions that deviate
from model behaviour. This leads to accumulation of irregular gradients,
resulting in attribution maps that are biased, fragile and manipulable.
Departing from the static approach, we propose UNI to compute an (un)learnable,
debiased and adaptive baseline by perturbing the input towards an unlearning
direction of steepest ascent. Our method discovers reliable baselines and
succeeds in erasing salient features, which in turn locally smooths the
high-curvature decision boundaries. Our analyses point to unlearning as a
promising avenue for generating faithful, efficient and robust interpretations.

æè¦ï¼åºæ¼æ¢¯åº¦çè©®ééå¸¸éè¦ä¸åæ¯è¼é¨é»ä¾é¿åå¨è¨ç®ç¹å¾µéè¦æ§æé£½åãæåé¡¯ç¤ºç®åä½¿ç¨éæå½æ¸å®ç¾©çåºæºç·ï¼æå®æ å°ãå¹³åææ¨¡ç³ï¼ææ³¨å¥æå®³çé¡è²ãç´çæé »çåè¨­ï¼éäºåè¨­æåé¢æ¨¡åè¡çºãéæå°è´ä¸è¦åæ¢¯åº¦çç´¯ç©ï¼é²èç¢çæåå·®ãèå¼±ä¸å¯æç¸±çæ­¸å åãæåè·³è«éææ¹æ³ï¼æåº UNI ä¾è¨ç®ä¸åï¼ä¸å¯ï¼å­¸ç¿ãå»åä¸èªé©æçåºæºç·ï¼æ¹æ³æ¯æåæé¡ä¸åçåæ¶å­¸ç¿æ¹åæ¾åè¼¸å¥ãæåçæ¨¡åç¼ç¾å¯é çåºæºç·ï¼ä¸¦æåæ¶é¤é¡¯èç¹å¾µï¼é²èå±é¨å¹³æ»é«æ²çæ±ºç­éçãæåçåææåºåæ¶å­¸ç¿æ¯ä¸åæå¸æçéå¾ï¼å¯ä»¥ç¢çå¿ å¯¦ãææä¸å¼·å¥çè©®éã

##### **Teaching-Inspired Integrated Prompting Framework: A Novel Approach for Enhancing Reasoning in Large Language Models**
2410.08068v1 by Wenting Tan, Dongxiao Chen, Jieting Xue, Zihao Wang, Taijie Chen

Large Language Models (LLMs) exhibit impressive performance across various
domains but still struggle with arithmetic reasoning tasks. Recent work shows
the effectiveness of prompt design methods in enhancing reasoning capabilities.
However, these approaches overlook crucial requirements for prior knowledge of
specific concepts, theorems, and tricks to tackle most arithmetic reasoning
problems successfully. To address this issue, we propose a novel and effective
Teaching-Inspired Integrated Framework, which emulates the instructional
process of a teacher guiding students. This method equips LLMs with essential
concepts, relevant theorems, and similar problems with analogous solution
approaches, facilitating the enhancement of reasoning abilities. Additionally,
we introduce two new Chinese datasets, MathMC and MathToF, both with detailed
explanations and answers. Experiments are conducted on nine benchmarks which
demonstrates that our approach improves the reasoning accuracy of LLMs. With
GPT-4 and our framework, we achieve new state-of-the-art performance on four
math benchmarks (AddSub, SVAMP, Math23K and AQuA) with accuracies of 98.2%
(+3.3%), 93.9% (+0.2%), 94.3% (+7.2%) and 81.1% (+1.2%). Our data and code are
available at https://github.com/SallyTan13/Teaching-Inspired-Prompting.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨åç¨®é åå±ç¾åºä»¤äººå°è±¡æ·±å»çè¡¨ç¾ï¼ä½å¨ç®è¡æ¨çä»»åä¸­ä»æå°é£ãæè¿çç ç©¶é¡¯ç¤ºï¼æç¤ºè¨­è¨æ¹æ³å¨å¢å¼·æ¨çè½åæ¹é¢å¾ææãç¶èï¼éäºæ¹æ³å¿½ç¥äºå°ç¹å®æ¦å¿µãå®çåæå·§çååç¥è­ï¼éäºç¥è­å°æ¼æåè§£æ±ºå¤§å¤æ¸ç®è¡æ¨çåé¡è³ééè¦ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸åæ°ç©ä¸ææçæå­¸éææ´åæ¡æ¶ï¼æ¨¡æ¬èå¸«æå°å­¸ççæå­¸éç¨ãæ­¤æ¹æ³çº LLM æä¾äºå¿è¦çæ¦å¿µãç¸éå®çåé¡ä¼¼åé¡ï¼ä»¥åé¡ä¼¼çè§£æ±ºæ¹æ³ï¼æå©æ¼å¢å¼·æ¨çè½åãæ­¤å¤ï¼æåéä»ç´¹äºå©åæ°çä¸­æè³æé MathMC å MathToFï¼å®åé½æä¾äºè©³ç´°çè§£éåç­æ¡ãå¨ä¹ååºæºä¸é²è¡äºå¯¦é©ï¼çµæè¡¨ææåçåæ³æé«äº LLM çæ¨çæºç¢ºåº¦ãéé GPT-4 åæåçæ¡æ¶ï¼æåå¨ååæ¸å­¸åºæº (AddSubãSVAMPãMath23K å AQuA) ä¸éå°äºæ°çæåé²æ§è½ï¼æºç¢ºåº¦åå¥çº 98.2% (+3.3%)ã93.9% (+0.2%)ã94.3% (+7.2%) å 81.1% (+1.2%)ãæåçè³æåç¨å¼ç¢¼å¯å¨ https://github.com/SallyTan13/Teaching-Inspired-Prompting åå¾ã

##### **Reward-Augmented Data Enhances Direct Preference Alignment of LLMs**
2410.08067v1 by Shenao Zhang, Zhihan Liu, Boyi Liu, Yufeng Zhang, Yingxiang Yang, Yongfei Liu, Liyu Chen, Tao Sun, Zhaoran Wang

Preference alignment in Large Language Models (LLMs) has significantly
improved their ability to adhere to human instructions and intentions. However,
existing direct alignment algorithms primarily focus on relative preferences
and often overlook the qualitative aspects of responses. Striving to maximize
the implicit reward gap between the chosen and the slightly inferior rejected
responses can cause overfitting and unnecessary unlearning of the high-quality
rejected responses. The unawareness of the reward scores also drives the LLM to
indiscriminately favor the low-quality chosen responses and fail to generalize
to responses with the highest rewards, which are sparse in data. To overcome
these shortcomings, our study introduces reward-conditioned LLM policies that
discern and learn from the entire spectrum of response quality within the
dataset, helping extrapolate to more optimal regions. We propose an effective
yet simple data relabeling method that conditions the preference pairs on
quality scores to construct a reward-augmented dataset. This dataset is easily
integrated with existing direct alignment algorithms and is applicable to any
preference dataset. The experimental results across instruction-following
benchmarks including AlpacaEval, MT-Bench, and Arena-Hard-Auto demonstrate that
our approach consistently boosts the performance of DPO by a considerable
margin across diverse models. Additionally, our method improves the average
accuracy on various academic benchmarks. When applying our method to on-policy
data, the resulting DPO model achieves SOTA results on AlpacaEval. Through
ablation studies, we demonstrate that our method not only maximizes the utility
of preference data but also mitigates the issue of unlearning, demonstrating
its broad effectiveness beyond mere dataset expansion. Our code is available at
https://github.com/shenao-zhang/reward-augmented-preference.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ä¸­çåå¥½å°é½é¡¯èæåäºå®åéµå®äººé¡æä»¤åæåçè½åãç¶èï¼ç¾æçç´æ¥å°é½æ¼ç®æ³ä¸»è¦éæ³¨ç¸å°åå¥½ï¼ä¸å¸¸å¸¸å¿½ç¥åæçè³ªåé¢åãåªåæå¤§åæé¸åæåç¥éä¸ç±çè¢«æçµåæä¹éçé±å«çåµå·®è·ï¼å¯è½å°è´éåº¦æ¬ååä¸å¿è¦å°éºå¿é«åè³ªçè¢«æçµåæãå°çåµåæ¸çç¡ç¥ä¹é©ä½¿ LLM æ¯«ç¡åå¥å°åå¥½ä½åè³ªçæé¸åæï¼ä¸ç¡æ³æ¦æ¬å°çåµæé«çåæï¼èéäºåæå¨è³æä¸­æ¯ç¨ççãçºäºåæéäºç¼ºé»ï¼æåçç ç©¶å¼å¥äºçåµæ¢ä»¶ç LLM æ¿ç­ï¼å®è½è¾¨å¥ä¸¦å¾è³æéå§åæåè³ªçæ´åç¯åä¸­å­¸ç¿ï¼æå©æ¼å¤æ¨å°æ´ä½³çååãæåæåºä¸åææä¸ç°¡å®çè³æéæ°æ¨ç±¤æ¹æ³ï¼å®ä»¥åè³ªåæ¸çºæ¢ä»¶çåå¥½å°ä¾å»ºæ§ä¸åçåµå¢å¼·çè³æéãéåè³æéå¾å®¹æèç¾æçç´æ¥å°é½æ¼ç®æ³æ´åï¼ä¸é©ç¨æ¼ä»»ä½åå¥½è³æéãå¨åæ¬ AlpacaEvalãMT-Bench å Arena-Hard-Auto å¨å§çæä»¤éµå¾ªåºæºä¸­çå¯¦é©çµæé¡¯ç¤ºï¼æåçåæ³ä¸è´å°ä»¥ç¸ç¶å¤§çå¹åº¦æåäºä¸åæ¨¡åç DPO æè½ãæ­¤å¤ï¼æåçåæ³ä¹æåäºåç¨®å­¸è¡åºæºçå¹³åæºç¢ºåº¦ãç¶å°æåçåæ³æç¨æ¼ç­ç¥è³ææï¼ç¢çç DPO æ¨¡åå¨ AlpacaEval ä¸éå°äº SOTA çµæãééæ¶èç ç©¶ï¼æåè­æäºæåçåæ³ä¸åæå¤§åäºåå¥½è³æçæç¨ï¼ä¹æ¸è¼äºéºå¿çåé¡ï¼è­æäºå®è¶è¶å®ç´çè³æéæ´åçå»£æ³æåãæåçç¨å¼ç¢¼å¯ä»¥å¨ https://github.com/shenao-zhang/reward-augmented-preference åå¾ã

##### **Closing the Loop: Learning to Generate Writing Feedback via Language Model Simulated Student Revisions**
2410.08058v1 by Inderjeet Nair, Jiaye Tan, Xiaotian Su, Anne Gere, Xu Wang, Lu Wang

Providing feedback is widely recognized as crucial for refining students'
writing skills. Recent advances in language models (LMs) have made it possible
to automatically generate feedback that is actionable and well-aligned with
human-specified attributes. However, it remains unclear whether the feedback
generated by these models is truly effective in enhancing the quality of
student revisions. Moreover, prompting LMs with a precise set of instructions
to generate feedback is nontrivial due to the lack of consensus regarding the
specific attributes that can lead to improved revising performance. To address
these challenges, we propose PROF that PROduces Feedback via learning from LM
simulated student revisions. PROF aims to iteratively optimize the feedback
generator by directly maximizing the effectiveness of students' overall
revising performance as simulated by LMs. Focusing on an economic essay
assignment, we empirically test the efficacy of PROF and observe that our
approach not only surpasses a variety of baseline methods in effectiveness of
improving students' writing but also demonstrates enhanced pedagogical values,
even though it was not explicitly trained for this aspect.

æè¦ï¼æä¾åé¥è¢«å»£æ³èªçºå°æ¼ç²¾é²å­¸ççå¯«ä½æå·§è³ééè¦ãèªè¨æ¨¡å (LM) çææ°é²å±è®èªåç¢çåé¥æçºå¯è½ï¼èéäºåé¥å·æå¯æä½æ§ï¼ä¸èäººé¡æå®çå±¬æ§é«åº¦ä¸è´ãç¶èï¼ç±éäºæ¨¡åç¢ççåé¥æ¯å¦ççè½æææåå­¸çä¿®æ¹çåè³ªï¼ä»ä¸æ¸æ¥ãæ­¤å¤ï¼ç±æ¼å°æ¼å¯è½å°è´ä¿®æ¹è¡¨ç¾æåçç¹å®å±¬æ§ç¼ºä¹å±è­ï¼å æ­¤æç¤º LM ç¢çåé¥æï¼ä½¿ç¨ä¸çµç²¾ç¢ºçèªªæä¸¦éæäºãçºäºæå°éäºææ°ï¼æåæåº PROFï¼å®ééå­¸ç¿ LM æ¨¡æ¬çå­¸çä¿®æ¹ä¾ç¢çåé¥ãPROF çç®æ¨æ¯ééç´æ¥æå¤§åå­¸çæ´é«ä¿®æ¹è¡¨ç¾çæææ§ï¼ç± LM æ¨¡æ¬ï¼ï¼ä¾åè¦æä½³ååé¥ç¢çå¨ãæåèéæ¼ç¶æ¿è«æä½æ¥­ï¼å¯¦è­æ¸¬è©¦ PROF çæè½ï¼ä¸¦è§å¯å°æåçåæ³ä¸åå¨æåå­¸çå¯«ä½çæææ§æ¹é¢è¶è¶åç¨®åºæºæ¹æ³ï¼å³ä½¿å¨éåé¢åä¸¦æªç¶éæç¢ºè¨ç·´ï¼ä¹å±ç¾åºå¢å¼·çæå­¸å¹å¼ã

##### **A Target-Aware Analysis of Data Augmentation for Hate Speech Detection**
2410.08053v1 by Camilla Casula, Sara Tonelli

Hate speech is one of the main threats posed by the widespread use of social
networks, despite efforts to limit it. Although attention has been devoted to
this issue, the lack of datasets and case studies centered around scarcely
represented phenomena, such as ableism or ageism, can lead to hate speech
detection systems that do not perform well on underrepresented identity groups.
Given the unpreceded capabilities of LLMs in producing high-quality data, we
investigate the possibility of augmenting existing data with generative
language models, reducing target imbalance. We experiment with augmenting 1,000
posts from the Measuring Hate Speech corpus, an English dataset annotated with
target identity information, adding around 30,000 synthetic examples using both
simple data augmentation methods and different types of generative models,
comparing autoregressive and sequence-to-sequence approaches. We find
traditional DA methods to often be preferable to generative models, but the
combination of the two tends to lead to the best results. Indeed, for some hate
categories such as origin, religion, and disability, hate speech classification
using augmented data for training improves by more than 10% F1 over the no
augmentation baseline. This work contributes to the development of systems for
hate speech detection that are not only better performing but also fairer and
more inclusive towards targets that have been neglected so far.

æè¦ï¼ä»æ¨è¨è«æ¯ç¤¾äº¤ç¶²è·¯å»£æ³ä½¿ç¨æå¸¶ä¾çä¸»è¦å¨èä¹ä¸ï¼åç®¡å·²æ¡åæªæ½å ä»¥éå¶ãåç®¡å·²å°æ­¤åé¡çµ¦äºéæ³¨ï¼ä½ç¼ºä¹ä»¥é®®å°è¢«ä»£è¡¨çç¾è±¡ï¼ä¾å¦æ­§è¦æ®ç¾ææ­§è¦å¹´é½¡ï¼çºä¸­å¿çè³æéåæ¡ä¾ç ç©¶ï¼å¯è½å°è´ä»æ¨è¨è«åµæ¸¬ç³»çµ±ç¡æ³å°ä»£è¡¨æ§ä¸è¶³çèº«åç¾¤é«ç¼æ®è¯å¥½æç¨ãèéå° LLM å¨ç¢çé«åè³ªè³ææ¹é¢çç¡èå«æ¯è½åï¼æåæ¢è¨äºä½¿ç¨çæå¼èªè¨æ¨¡åæ´åç¾æè³æçå¯è½æ§ï¼ä»¥æ¸å°ç®æ¨å¤±è¡¡ãæååè©¦æ´åãè¡¡éä»æ¨è¨è«ãèªæåº«ä¸­ç 1,000 ç¯è²¼æï¼éæ¯ä¸åæ¨è¨»æç®æ¨èº«åè³è¨çè±æè³æéï¼ä½¿ç¨ç°¡å®çè³ææ´åæ¹æ³åä¸åé¡åççæå¼æ¨¡åæ°å¢ç´ 30,000 ååæç¯ä¾ï¼æ¯è¼èªè¿´æ­¸ååºåå°åºåçæ¹æ³ãæåç¼ç¾å³çµ±ç DA æ¹æ³éå¸¸åªæ¼çæå¼æ¨¡åï¼ä½å©èççµåå¾å¾æå¸¶ä¾æä½³çµæãäºå¯¦ä¸ï¼å°æ¼æäºä»æ¨é¡å¥ï¼ä¾å¦åºèº«ãå®æåæ®ç¾ï¼ä½¿ç¨æ´åè³æé²è¡è¨ç·´çä»æ¨è¨è«åé¡å¨ F1 ä¸æ¯æ²ææ´åçåºæºç·æ¹é²äº 10% ä»¥ä¸ãéé å·¥ä½æå©æ¼éç¼ä»æ¨è¨è«åµæ¸¬ç³»çµ±ï¼ä¸åæè½æ´å¥½ï¼èä¸å°è¿ä»è¢«å¿½è¦çç®æ¨æ´å¬å¹³ãæ´å·åå®¹æ§ã

##### **VerifierQ: Enhancing LLM Test Time Compute with Q-Learning-based Verifiers**
2410.08048v1 by Jianing Qi, Hao Tang, Zhigang Zhu

Recent advancements in test time compute, particularly through the use of
verifier models, have significantly enhanced the reasoning capabilities of
Large Language Models (LLMs). This generator-verifier approach closely
resembles the actor-critic framework in reinforcement learning (RL). However,
current verifier models in LLMs often rely on supervised fine-tuning without
temporal difference learning such as Q-learning. This paper introduces
VerifierQ, a novel approach that integrates Offline Q-learning into LLM
verifier models. We address three key challenges in applying Q-learning to
LLMs: (1) handling utterance-level Markov Decision Processes (MDPs), (2)
managing large action spaces, and (3) mitigating overestimation bias. VerifierQ
introduces a modified Bellman update for bounded Q-values, incorporates
Implicit Q-learning (IQL) for efficient action space management, and integrates
a novel Conservative Q-learning (CQL) formulation for balanced Q-value
estimation. Our method enables parallel Q-value computation and improving
training efficiency. While recent work has explored RL techniques like MCTS for
generators, VerifierQ is among the first to investigate the verifier (critic)
aspect in LLMs through Q-learning. This integration of RL principles into
verifier models complements existing advancements in generator techniques,
potentially enabling more robust and adaptive reasoning in LLMs. Experimental
results on mathematical reasoning tasks demonstrate VerifierQ's superior
performance compared to traditional supervised fine-tuning approaches, with
improvements in efficiency, accuracy and robustness. By enhancing the synergy
between generation and evaluation capabilities, VerifierQ contributes to the
ongoing evolution of AI systems in addressing complex cognitive tasks across
various domains.

æè¦ï¼<paragraph>æè¿å¨æ¸¬è©¦æéè¨ç®æ¹é¢çé²å±ï¼ç¹å¥æ¯ééé©è­æ¨¡åçä½¿ç¨ï¼å¤§å¹æåäºå¤§åèªè¨æ¨¡å (LLM) çæ¨çè½åãéç¨®çæå¨é©è­æ¹æ³èå¼·åå­¸ç¿ (RL) ä¸­çè¡åè-è©è«èæ¶æ§éå¸¸ç¸ä¼¼ãç¶èï¼LLM ä¸­ç®åçé©è­æ¨¡åéå¸¸ä¾è³´æ¼ç£ç£å¾®èª¿ï¼èæ²ææéå·®å­¸ç¿ï¼ä¾å¦ Q å­¸ç¿ãæ¬æä»ç´¹äº VerifierQï¼éæ¯ä¸ç¨®æ°æ¹æ³ï¼å°é¢ç· Q å­¸ç¿æ´åå° LLM é©è­æ¨¡åä¸­ãæåè§£æ±ºäºå° Q å­¸ç¿æç¨æ¼ LLM çä¸åä¸»è¦ææ°ï¼(1) èçè©±èªç´é¦¬å¯å¤«æ±ºç­éç¨ (MDP)ï¼(2) ç®¡çå¤§ååä½ç©ºéï¼ä»¥å (3) æ¸è¼é«ä¼°åå·®ãVerifierQ éå°æç Q å¼å¼å¥äºä¿®æ¹å¾ç Bellman æ´æ°ï¼çµåäºé±å¼ Q å­¸ç¿ (IQL) ä»¥é²è¡ææçåä½ç©ºéç®¡çï¼ä¸¦æ´åäºä¸ç¨®æ°çä¿å® Q å­¸ç¿ (CQL) å¬å¼ï¼ä»¥é²è¡å¹³è¡¡ç Q å¼ä¼°è¨ãæåçæ¨¡åæ¯æ´ä¸¦è¡ Q å¼è¨ç®ï¼ä¸¦æé«è¨ç·´æçãéç¶æè¿çç ç©¶æ¢ç´¢äº MCTS ç­ RL æè¡ä»¥ç¨æ¼çæå¨ï¼ä½ VerifierQ æ¯ç¬¬ä¸åéé Q å­¸ç¿æ¢è¨ LLM ä¸­é©è­èï¼è©è«èï¼æ¹é¢çç ç©¶ãéç¨®å° RL ååæ´åå°é©è­æ¨¡åä¸­çåæ³ï¼è£åäºçæå¨æè¡ä¸­ç¾æçé²å±ï¼æ½å¨å°è® LLM è½å¤ é²è¡æ´å¼·å¥ä¸é©ææ§æ´å¼·çæ¨çãæ¸å­¸æ¨çä»»åçå¯¦é©çµæè­æäº VerifierQ åªæ¼å³çµ±ç£ç£å¾®èª¿æ¹æ³ï¼å¨æçãæºç¢ºæ§åå¼·å¥æ§æ¹é¢é½æææåãééå å¼·çæèè©ä¼°è½åä¹éçååä½ç¨ï¼VerifierQ æå©æ¼ AI ç³»çµ±æçºæ¼é²ï¼ä»¥è§£æ±ºåç¨®é åä¸­çè¤éèªç¥ä»»åã</paragraph>

##### **Scaling Up Your Kernels: Large Kernel Design in ConvNets towards Universal Representations**
2410.08049v1 by Yiyuan Zhang, Xiaohan Ding, Xiangyu Yue

This paper proposes the paradigm of large convolutional kernels in designing
modern Convolutional Neural Networks (ConvNets). We establish that employing a
few large kernels, instead of stacking multiple smaller ones, can be a superior
design strategy. Our work introduces a set of architecture design guidelines
for large-kernel ConvNets that optimize their efficiency and performance. We
propose the UniRepLKNet architecture, which offers systematical architecture
design principles specifically crafted for large-kernel ConvNets, emphasizing
their unique ability to capture extensive spatial information without deep
layer stacking. This results in a model that not only surpasses its
predecessors with an ImageNet accuracy of 88.0%, an ADE20K mIoU of 55.6%, and a
COCO box AP of 56.4% but also demonstrates impressive scalability and
performance on various modalities such as time-series forecasting, audio, point
cloud, and video recognition. These results indicate the universal modeling
abilities of large-kernel ConvNets with faster inference speed compared with
vision transformers. Our findings reveal that large-kernel ConvNets possess
larger effective receptive fields and a higher shape bias, moving away from the
texture bias typical of smaller-kernel CNNs. All codes and models are publicly
available at https://github.com/AILab-CVC/UniRepLKNet promoting further
research and development in the community.

æè¦ï¼æ¬ææåºå¨è¨­è¨ç¾ä»£å·ç©ç¥ç¶ç¶²è·¯ (ConvNets) æä½¿ç¨å¤§åå·ç©æ ¸çç¯ä¾ãæåç¢ºç«ä½¿ç¨å°æ¸å¤§åæ ¸ï¼èä¸æ¯å çå¤åè¼å°çæ ¸ï¼å¯è½æ¯ä¸ç¨®åªè¶çè¨­è¨ç­ç¥ãæåçç ç©¶å¼å¥äºä¸çµå¤§åæ ¸ ConvNets çæ¶æ§è¨­è¨æºåï¼ä»¥æä½³åå¶æçåæè½ãæåæåº UniRepLKNet æ¶æ§ï¼å®æä¾äºå°éçºå¤§åæ ¸ ConvNets è¨­è¨çç³»çµ±åæ¶æ§è¨­è¨ååï¼å¼·èª¿å®åå¨ä¸é²è¡æ·±åº¦å±¤å ççææ³ä¸æ·åå»£æ³ç©ºéè³è¨çç¨ç¹è½åãéç¢çäºä¸åæ¨¡åï¼ä¸åä»¥ 88.0% ç ImageNet æºç¢ºåº¦ã55.6% ç ADE20K mIoU å 56.4% ç COCO çå­ AP è¶è¶å¶åèº«ï¼éå±ç¤ºäºä»¤äººå°è±¡æ·±å»çå¯æ´åæ§åæè½å¨åç¨®æ¨¡å¼ä¸çè¡¨ç¾ï¼ä¾å¦æéåºåé æ¸¬ãé³è¨ãé»é²åå½±çè¾¨è­ãéäºçµæè¡¨æï¼èè¦è¦ºè½æå¨ç¸æ¯ï¼å¤§åæ ¸ ConvNets å·æéç¨çå»ºæ¨¡è½åï¼ä¸æ¨çéåº¦æ´å¿«ãæåçç ç©¶çµæè¡¨æï¼å¤§åæ ¸ ConvNets å·ææ´å¤§çæææåéåæ´é«çå½¢çåå·®ï¼é é¢äºè¼å°æ ¸ CNN çå¸åç´çåå·®ãææç¨å¼ç¢¼åæ¨¡åé½å¬éå¨ https://github.com/AILab-CVC/UniRepLKNetï¼ä»¥ä¿é²ç¤¾ç¾¤é²ä¸æ­¥çç ç©¶åéç¼ã

##### **Divide and Translate: Compositional First-Order Logic Translation and Verification for Complex Logical Reasoning**
2410.08047v1 by Hyun Ryu, Gyeongman Kim, Hyemin S. Lee, Eunho Yang

Complex logical reasoning tasks require a long sequence of reasoning, which a
large language model (LLM) with chain-of-thought prompting still falls short.
To alleviate this issue, neurosymbolic approaches incorporate a symbolic
solver. Specifically, an LLM only translates a natural language problem into a
satisfiability (SAT) problem that consists of first-order logic formulas, and a
sound symbolic solver returns a mathematically correct solution. However, we
discover that LLMs have difficulties to capture complex logical semantics
hidden in the natural language during translation. To resolve this limitation,
we propose a Compositional First-Order Logic Translation. An LLM first parses a
natural language sentence into newly defined logical dependency structures that
consist of an atomic subsentence and its dependents, then sequentially
translate the parsed subsentences. Since multiple logical dependency structures
and sequential translations are possible for a single sentence, we also
introduce two Verification algorithms to ensure more reliable results. We
utilize an SAT solver to rigorously compare semantics of generated first-order
logic formulas and select the most probable one. We evaluate the proposed
method, dubbed CLOVER, on seven logical reasoning benchmarks and show that it
outperforms the previous neurosymbolic approaches and achieves new
state-of-the-art results.

æè¦ï¼è¤éçéè¼¯æ¨çä»»åéè¦ä¸é£ä¸²çæ¨çï¼èå·ææèéæç¤ºçå¤§èªè¨æ¨¡å (LLM) ä»ç¡æ³éæã
çºäºç·©è§£éååé¡ï¼ç¥ç¶ç¬¦èæ¹æ³æ´åäºä¸åç¬¦èæ±è§£å¨ãå·é«ä¾èªªï¼LLM åªæå°èªç¶èªè¨åé¡è½æçºç±ä¸ééè¼¯å¬å¼çµæçå¯æ»¿è¶³æ§ (SAT) åé¡ï¼èå¥å¨çç¬¦èæ±è§£å¨æåå³ä¸åæ¸å­¸ä¸æ­£ç¢ºçè§£ãç¶èï¼æåç¼ç¾ LLM é£ä»¥å¨è½æéç¨ä¸­æ·åé±èå¨èªç¶èªè¨ä¸­çè¤ééè¼¯èªç¾©ãçºäºè§£æ±ºéåéå¶ï¼æåæåºäºä¸åçµåä¸ééè¼¯è½æãLLM æåå°ä¸åèªç¶èªè¨å¥å­è§£æææ°å®ç¾©çéè¼¯ä¾è³´çµæ§ï¼å¶ä¸­åå«ä¸ååå­å­å¥åå¶ä¾è³´é ï¼ç¶å¾ä¾åºè½æè§£æå¾çå­å¥ãç±æ¼å®ä¸å¥å­æå¤åå¯è½çéè¼¯ä¾è³´çµæ§åé åºè½æï¼æåä¹å¼å¥äºå©åé©è­æ¼ç®æ³ä¾ç¢ºä¿çµææ´å¯é ãæåå©ç¨ SAT æ±è§£å¨å´æ ¼æ¯è¼ç¢ççéè¼¯å¬å¼çèªç¾©ï¼ä¸¦é¸åºæå¯è½çå¬å¼ãæåå¨ä¸åéè¼¯æ¨çåºæºä¸è©ä¼°ææåºçæ¹æ³ï¼ç¨±çº CLOVERï¼ä¸¦é¡¯ç¤ºå®åªæ¼ååçç¥ç¶ç¬¦èæ¹æ³ï¼ä¸¦åå¾æ°çæåé²çµæã

##### **The Rise of AI-Generated Content in Wikipedia**
2410.08044v1 by Creston Brooks, Samuel Eggert, Denis Peskoff

The rise of AI-generated content in popular information sources raises
significant concerns about accountability, accuracy, and bias amplification.
Beyond directly impacting consumers, the widespread presence of this content
poses questions for the long-term viability of training language models on vast
internet sweeps. We use GPTZero, a proprietary AI detector, and Binoculars, an
open-source alternative, to establish lower bounds on the presence of
AI-generated content in recently created Wikipedia pages. Both detectors reveal
a marked increase in AI-generated content in recent pages compared to those
from before the release of GPT-3.5. With thresholds calibrated to achieve a 1%
false positive rate on pre-GPT-3.5 articles, detectors flag over 5% of newly
created English Wikipedia articles as AI-generated, with lower percentages for
German, French, and Italian articles. Flagged Wikipedia articles are typically
of lower quality and are often self-promotional or partial towards a specific
viewpoint on controversial topics.

æè¦ï¼äººå·¥æºè½çæå§å®¹å¨ç±éè³è¨ä¾æºä¸­èèµ·ï¼å¼ç¼äºå°æ¼åè²¬å¶ãæºç¢ºæ§ååè¦æ´æ£çéå¤§çæ®ã
é¤äºç´æ¥å½±é¿æ¶è²»èä¹å¤ï¼æ­¤é¡å§å®¹çå»£æ³å­å¨ä¹å°å¨å»£æ³ç¶²éç¶²è·¯ææä¸­è¨ç·´èªè¨æ¨¡åçé·æå¯è¡æ§æåºäºè³ªçãæåä½¿ç¨å°æç AI åµæ¸¬å¨ GPTZero åéæ¾åå§ç¢¼æ¿ä»£æ¹æ¡ Binocularsï¼ä¾å»ºç«æè¿å»ºç«çç¶­åºç¾ç§é é¢ä¸­ AI çæçå§å®¹å­å¨çä¸éãè GPT-3.5 ç¼å¸ä¹åçé é¢ç¸æ¯ï¼å©ååµæ¸¬å¨é½é¡¯ç¤ºæè¿çé é¢ä¸­ AI çæçå§å®¹é¡¯èå¢å ãè¨­å®é¾å¼ä»¥å¨ GPT-3.5 ä¹åçæç« ä¸­éå° 1% çèª¤å¤çï¼åµæ¸¬å¨å°è¶é 5% çæ°å»ºç«çè±æç¶­åºç¾ç§æç« æ¨è¨çº AI çæçï¼å¾·æãæ³æåç¾©å¤§å©ææç« çç¾åæ¯è¼ä½ãæ¨è¨çç¶­åºç¾ç§æç« éå¸¸åè³ªè¼ä½ï¼èä¸ç¶å¸¸èªæå®£å³æååæ¼æç­è­°æ§ä¸»é¡çç¹å®è§é»ã

##### **Strategic Classification With Externalities**
2410.08032v1 by Yiling Chen, Safwan Hossain, Evi Micha, Ariel Procaccia

We propose a new variant of the strategic classification problem: a principal
reveals a classifier, and $n$ agents report their (possibly manipulated)
features to be classified. Motivated by real-world applications, our model
crucially allows the manipulation of one agent to affect another; that is, it
explicitly captures inter-agent externalities. The principal-agent interactions
are formally modeled as a Stackelberg game, with the resulting agent
manipulation dynamics captured as a simultaneous game. We show that under
certain assumptions, the pure Nash Equilibrium of this agent manipulation game
is unique and can be efficiently computed. Leveraging this result, PAC learning
guarantees are established for the learner: informally, we show that it is
possible to learn classifiers that minimize loss on the distribution, even when
a random number of agents are manipulating their way to a pure Nash
Equilibrium. We also comment on the optimization of such classifiers through
gradient-based approaches. This work sets the theoretical foundations for a
more realistic analysis of classifiers that are robust against multiple
strategic actors interacting in a common environment.

æè¦ï¼æåæåºç­ç¥åé¡åé¡çæ°è®é«ï¼ä¸åå§è¨äººæ­é²ä¸ååé¡å¨ï¼è $n$ åä»£çå ±åä»åï¼å¯è½ç¶éèª¿æ´ï¼çç¹æ§ä»¥é²è¡åé¡ãæåçæ¨¡ååå°çå¯¦ä¸çæç¨çåç¼ï¼è³ééè¦çæ¯åè¨±ä¸åä»£ççèª¿æ´å½±é¿å¦ä¸åä»£çï¼ä¹å°±æ¯èªªï¼å®æç¢ºå°ææå°ä»£çéçå¤é¨æ§ãå§è¨-ä»£çäºåè¢«æ­£å¼å»ºæ¨¡çºä¸å Stackelberg éæ²ï¼ä¸¦å°ç±æ­¤ç¢ççä»£çèª¿æ´åæææçºä¸ååæ­¥éæ²ãæåè¡¨æå¨æäºåè¨­ä¸ï¼éåä»£çèª¿æ´éæ²çç´ç´è¨±åè¡¡æ¯å¯ä¸çï¼ä¸¦ä¸å¯ä»¥ææå°è¨ç®ãå©ç¨éåçµæï¼çºå­¸ç¿èå»ºç«äº PAC å­¸ç¿ä¿è­ï¼éæ­£å¼å°ï¼æåè¡¨ææå¯è½å­¸ç¿æå°ååéæå¤±çåé¡å¨ï¼å³ä½¿å¨é¨æ©æ¸éçä»£çæ­£å¨èª¿æ´ä»åçæ¹å¼ä»¥éå°ç´ç´è¨±åè¡¡æä¹æ¯å¦æ­¤ãæåéè©è«äºééåºæ¼æ¢¯åº¦çéå¾å°æ­¤é¡åé¡å¨é²è¡åªåçåé¡ãéé å·¥ä½çºå°å¨å±åç°å¢ä¸­äºåçãéå°å¤åç­ç¥åèèå·æé­¯æ£æ§çåé¡å¨çæ´ç¾å¯¦çåæå¥ å®äºçè«åºç¤ã

##### **Private Language Models via Truncated Laplacian Mechanism**
2410.08027v1 by Tianhao Huang, Tao Yang, Ivan Habernal, Lijie Hu, Di Wang

Deep learning models for NLP tasks are prone to variants of privacy attacks.
To prevent privacy leakage, researchers have investigated word-level
perturbations, relying on the formal guarantees of differential privacy (DP) in
the embedding space. However, many existing approaches either achieve
unsatisfactory performance in the high privacy regime when using the Laplacian
or Gaussian mechanism, or resort to weaker relaxations of DP that are inferior
to the canonical DP in terms of privacy strength. This raises the question of
whether a new method for private word embedding can be designed to overcome
these limitations. In this paper, we propose a novel private embedding method
called the high dimensional truncated Laplacian mechanism. Specifically, we
introduce a non-trivial extension of the truncated Laplacian mechanism, which
was previously only investigated in one-dimensional space cases. Theoretically,
we show that our method has a lower variance compared to the previous private
word embedding methods. To further validate its effectiveness, we conduct
comprehensive experiments on private embedding and downstream tasks using three
datasets. Remarkably, even in the high privacy regime, our approach only incurs
a slight decrease in utility compared to the non-private scenario.

æè¦ï¼æ·±åº¦å­¸ç¿æ¨¡åå°æ¼èªç¶èªè¨èçä»»åå®¹æåå°åç¨®é±ç§æ»æã
çºäºé²æ­¢é±ç§å¤æ´©ï¼ç ç©¶äººå¡å·²ç¶ç ç©¶äºè©ç´æ¾åï¼ä¾è³´æ¼åµå¥ç©ºéä¸­å·®åé±ç§ (DP) çæ­£å¼ä¿è­ãç¶èï¼è¨±å¤ç¾ææ¹æ³å¨ä½¿ç¨ææ®ææ¯æé«æ¯æ©å¶æï¼å¨é«é±ç§æ©å¶ä¸­ç¡æ³éå°ä»¤äººæ»¿æçæè½ï¼æè¨´è«¸æ¼ DP çè¼å¼±æ¾å¯¬ï¼å¶é±ç§å¼·åº¦ä½æ¼æ­£è¦ DPãéå¼ç¼äºä¸ååé¡ï¼å³æ¯å¦å¯ä»¥è¨­è¨ä¸ç¨®æ°çç§æè©åµå¥æ¹æ³ä¾åæéäºéå¶ãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°çç§æåµå¥æ¹æ³ï¼ç¨±çºé«ç¶­æªæ·ææ®ææ¯æ©å¶ãå·é«ä¾èªªï¼æåå¼å¥äºæªæ·ææ®ææ¯æ©å¶çéå¹³å¡æ´åï¼è©²æ©å¶ä»¥ååå¨ Ð¾Ð´Ð½Ð¾Ð¼ÐµÑÐ½Ð¾Ð¼ ç©ºéæ¡ä¾ä¸­é²è¡ç ç©¶ãå¨çè«ä¸ï¼æåè¡¨æèååçç§æè©åµå¥æ¹æ³ç¸æ¯ï¼æåçæ¹ââæ³å·æè¼ä½çè®ç°æ§ãçºäºé²ä¸æ­¥é©è­å¶æææ§ï¼æåä½¿ç¨ä¸åè³æéå°ç§æåµå¥åä¸æ¸¸ä»»åé²è¡äºå¨é¢çå¯¦é©ãå¼å¾æ³¨æçæ¯ï¼å³ä½¿å¨é«é±ç§æ©å¶ä¸­ï¼èéç§æå ´æ¯ç¸æ¯ï¼æåçæ¹ââæ³åå°è´æç¨ç¥æä¸éã

##### **The Computational Complexity of Circuit Discovery for Inner Interpretability**
2410.08025v1 by Federico Adolfi, Martina G. Vilas, Todd Wareham

Many proposed applications of neural networks in machine learning,
cognitive/brain science, and society hinge on the feasibility of inner
interpretability via circuit discovery. This calls for empirical and
theoretical explorations of viable algorithmic options. Despite advances in the
design and testing of heuristics, there are concerns about their scalability
and faithfulness at a time when we lack understanding of the complexity
properties of the problems they are deployed to solve. To address this, we
study circuit discovery with classical and parameterized computational
complexity theory: (1) we describe a conceptual scaffolding to reason about
circuit finding queries in terms of affordances for description, explanation,
prediction and control; (2) we formalize a comprehensive set of queries that
capture mechanistic explanation, and propose a formal framework for their
analysis; (3) we use it to settle the complexity of many query variants and
relaxations of practical interest on multi-layer perceptrons (part of, e.g.,
transformers). Our findings reveal a challenging complexity landscape. Many
queries are intractable (NP-hard, $\Sigma^p_2$-hard), remain fixed-parameter
intractable (W[1]-hard) when constraining model/circuit features (e.g., depth),
and are inapproximable under additive, multiplicative, and probabilistic
approximation schemes. To navigate this landscape, we prove there exist
transformations to tackle some of these hard problems (NP- vs.
$\Sigma^p_2$-complete) with better-understood heuristics, and prove the
tractability (PTIME) or fixed-parameter tractability (FPT) of more modest
queries which retain useful affordances. This framework allows us to understand
the scope and limits of interpretability queries, explore viable options, and
compare their resource demands among existing and future architectures.

æè¦ï¼è¨±å¤ç¥ç¶ç¶²è·¯å¨æ©å¨å­¸ç¿ãèªç¥/è¦ç§å­¸åç¤¾æä¸­çæç¨ææ¡ï¼é½åæ±ºæ¼ééé»è·¯ç¼ç¾ä¾é²è¡å§å¨å¯è§£éæ§çå¯è¡æ§ãééè¦å°å¯è¡çæ¼ç®æ³é¸é é²è¡å¯¦è­åçè«ä¸çæ¢è¨ãåç®¡å¨åç¼æ³çè¨­è¨åæ¸¬è©¦æ¹é¢æé²å±ï¼ä½æåå°å¶å¯æ´å±æ§åå¿ å¯¦åº¦ä»æçæ®ï¼å çºæåç®åéç¼ºä¹å°å¶ç¨æ¼è§£æ±ºåé¡çè¤éæ§å±¬æ§ççè§£ãçºäºè§£æ±ºéååé¡ï¼æåä½¿ç¨å¤å¸ååæ¸åè¨ç®è¤éåº¦çè«ä¾ç ç©¶é»è·¯ç¼ç¾ï¼(1) æåæè¿°ä¸åæ¦å¿µæ§æ¯æ¶ï¼ä»¥æè¿°ãèªªæãé æ¸¬åæ§å¶çä¾¿å©æ§ä¾æ¨è«é»è·¯å°æ¾æ¥è©¢ï¼(2) æåæ­£å¼åä¸åå¨é¢çæ¥è©¢éï¼ä»¥æææ©å¶æ§èªªæï¼ä¸¦æåºä¸åæ­£å¼çåææ¶æ§ï¼(3) æåä½¿ç¨å®ä¾è§£æ±ºå¤å±¤æç¥å¨ï¼ä¾å¦Transformerçä¸é¨åï¼ä¸­è¨±å¤æ¥è©¢è®é«åæ¾å¯¬å¯¦éèè¶£çè¤éæ§ãæåçç¼ç¾æ­ç¤ºäºä¸åå·æææ°æ§çè¤éæ§æ ¼å±ãè¨±å¤æ¥è©¢æ¯é£ä»¥èçç (NP-hardã$\Sigma^p_2$-hard)ï¼ç¶ç´ææ¨¡å/é»è·¯ç¹å¾µï¼ä¾å¦æ·±åº¦ï¼æï¼ä»ç¶æ¯åºå®åæ¸é£ä»¥èçç (W[1]-hard)ï¼ä¸¦ä¸å¨å æ³ãä¹æ³åæ©çè¿ä¼¼æ¹æ¡ä¸æ¯ä¸å¯è¿ä¼¼çãçºäºæå°éç¨®ææ³ï¼æåè­æå­å¨è½æä¾è§£æ±ºä¸äºéäºå°é£çåé¡ (NP- å°æ¯ $\Sigma^p_2$-complete) ä½¿ç¨æ´ææ¼çè§£çåç¼æ³ï¼ä¸¦è­æäºæ´é©åº¦çæ¥è©¢çå¯èçæ§ (PTIME) æåºå®åæ¸å¯èçæ§ (FPT)ï¼éäºæ¥è©¢ä¿çäºæç¨çä¾¿å©æ§ãéåæ¶æ§è®æåè½å¤ äºè§£å¯è§£éæ§æ¥è©¢çç¯ååéå¶ï¼æ¢ç´¢å¯è¡çé¸é ï¼ä¸¦æ¯è¼å®åå¨ç¾æåæªä¾æ¶æ§ä¸­çè³æºéæ±ã

##### **Pretraining Graph Transformers with Atom-in-a-Molecule Quantum Properties for Improved ADMET Modeling**
2410.08024v1 by Alessio Fallani, Ramil Nugmanov, Jose Arjona-Medina, JÃ¶rg Kurt Wegner, Alexandre Tkatchenko, Kostiantyn Chernichenko

We evaluate the impact of pretraining Graph Transformer architectures on
atom-level quantum-mechanical features for the modeling of absorption,
distribution, metabolism, excretion, and toxicity (ADMET) properties of
drug-like compounds. We compare this pretraining strategy with two others: one
based on molecular quantum properties (specifically the HOMO-LUMO gap) and one
using a self-supervised atom masking technique. After fine-tuning on
Therapeutic Data Commons ADMET datasets, we evaluate the performance
improvement in the different models observing that models pretrained with
atomic quantum mechanical properties produce in general better results. We then
analyse the latent representations and observe that the supervised strategies
preserve the pretraining information after finetuning and that different
pretrainings produce different trends in latent expressivity across layers.
Furthermore, we find that models pretrained on atomic quantum mechanical
properties capture more low-frequency laplacian eigenmodes of the input graph
via the attention weights and produce better representations of atomic
environments within the molecule. Application of the analysis to a much larger
non-public dataset for microsomal clearance illustrates generalizability of the
studied indicators. In this case the performances of the models are in
accordance with the representation analysis and highlight, especially for the
case of masking pretraining and atom-level quantum property pretraining, how
model types with similar performance on public benchmarks can have different
performances on large scale pharmaceutical data.

æè¦ï¼æåè©ä¼°é è¨ç·´åå½¢è½æå¨æ¶æ§å°åå­å±¤ç´éå­åå­¸ç¹å¾µçå½±é¿ï¼ç¨æ¼å»ºæ§é¡è¥ç©ååç©çå¸æ¶ãåä½ãä»£è¬ãææ³åæ¯æ§ (ADMET) å±¬æ§æ¨¡åãæåå°æ­¤é è¨ç·´ç­ç¥èå¶ä»å©åç­ç¥é²è¡æ¯è¼ï¼ä¸ååºæ¼åå­éå­å±¬æ§ï¼ç¹å¥æ¯ HOMO-LUMO å·®è·ï¼ï¼å¦ä¸åä½¿ç¨èªç£ç£åå­é®ç½©æè¡ãå¨ Therapeutic Data Commons ADMET è³æéä¸å¾®èª¿å¾ï¼æåè©ä¼°ä¸åæ¨¡åçæè½æåï¼è§å¯å°ä½¿ç¨åå­éå­åå­¸å±¬æ§é è¨ç·´çæ¨¡åéå¸¸æç¢çæ´å¥½ççµæãæ¥èæååææ½å¨è¡¨ç¤ºï¼ä¸¦è§å¯å°ç£ç£ç­ç¥å¨å¾®èª¿å¾æä¿çé è¨ç·´è³è¨ï¼èä¸ä¸åçé è¨ç·´æå¨ä¸åå±¤ç´ç¢çæ½å¨è¡¨éåçä¸åè¶¨å¢ãæ­¤å¤ï¼æåç¼ç¾é è¨ç·´æ¼åå­éå­åå­¸å±¬æ§çæ¨¡åæééæ³¨æåæ¬éæ·åè¼¸å¥åå½¢çæ´å¤ä½é »ææ®ææ¯ç¹å¾µæ¨¡å¼ï¼ä¸¦ç¢çåå­å§åå­ç°å¢çæ´ä½³è¡¨ç¤ºãå°åææç¨æ¼ä¸åæ´å¤§çéå¬éå¾®é«æ¸é¤è³æéï¼èªªæäºæç ç©¶ææ¨çæ¦æ¬æ§ãå¨éç¨®ææ³ä¸ï¼æ¨¡åçæè½ç¬¦åè¡¨ç¤ºåæï¼ä¸¦ç¹å¥å¼·èª¿é®ç½©é è¨ç·´ååå­å±¤ç´éå­å±¬æ§é è¨ç·´çææ³ï¼èªªæå¨å¬éåºæºä¸æè½ç¸ä¼¼çæ¨¡åé¡åå¨å¤§åè¥åè³æä¸å¯è½ææä¸åçæè½ã

##### **GrabDAE: An Innovative Framework for Unsupervised Domain Adaptation Utilizing Grab-Mask and Denoise Auto-Encoder**
2410.08023v1 by Junzhou Chen, Xuan Wen, Ronghui Zhang, Bingtao Ren, Di Wu, Zhigang Xu, Danwei Wang

Unsupervised Domain Adaptation (UDA) aims to adapt a model trained on a
labeled source domain to an unlabeled target domain by addressing the domain
shift. Existing Unsupervised Domain Adaptation (UDA) methods often fall short
in fully leveraging contextual information from the target domain, leading to
suboptimal decision boundary separation during source and target domain
alignment. To address this, we introduce GrabDAE, an innovative UDA framework
designed to tackle domain shift in visual classification tasks. GrabDAE
incorporates two key innovations: the Grab-Mask module, which blurs background
information in target domain images, enabling the model to focus on essential,
domain-relevant features through contrastive learning; and the Denoising
Auto-Encoder (DAE), which enhances feature alignment by reconstructing features
and filtering noise, ensuring a more robust adaptation to the target domain.
These components empower GrabDAE to effectively handle unlabeled target domain
data, significantly improving both classification accuracy and robustness.
Extensive experiments on benchmark datasets, including VisDA-2017, Office-Home,
and Office31, demonstrate that GrabDAE consistently surpasses state-of-the-art
UDA methods, setting new performance benchmarks. By tackling UDA's critical
challenges with its novel feature masking and denoising approach, GrabDAE
offers both significant theoretical and practical advancements in domain
adaptation.

æè¦ï¼ç¡ç£ç£åé©æ (UDA) æ¨å¨ééè§£æ±ºåè½ç§»ï¼å°å¨æ¨ç±¤ä¾æºåä¸è¨ç·´çæ¨¡åé©æå°æªæ¨ç±¤ç®æ¨åãç¾æçç¡ç£ç£åé©æ (UDA) æ¹æ³éå¸¸ç¡æ³ååå©ç¨ä¾èªç®æ¨åçä¸ä¸æè³è¨ï¼å°è´å¨ä¾æºåç®æ¨åæ¯å°æéï¼æ¬¡ä½³æ±ºç­éçåé¢ãçºäºè§£æ±ºéååé¡ï¼æåå¼å¥äº GrabDAEï¼éæ¯ä¸ååµæ°ç UDA æ¶æ§ï¼æ¨å¨èçè¦è¦ºåé¡ä»»åä¸­çåè½ç§»ãGrabDAE çµåäºå©é ééµåµæ°ï¼Grab-Mask æ¨¡çµï¼å®æ¨¡ç³äºç®æ¨åå½±åä¸­çèæ¯è³è¨ï¼ä½¿æ¨¡åè½å¤ ééå°æ¯å­¸ç¿å°æ³¨æ¼å¿è¦çãèåç¸éçç¹å¾µï¼ä»¥åå»éè¨èªåç·¨ç¢¼å¨ (DAE)ï¼å®éééå»ºç¹å¾µåéæ¿¾éè¨ä¾å¢å¼·ç¹å¾µæ¯å°ï¼ç¢ºä¿æ´å¼·å¥çç®æ¨åé©æãéäºåä»¶è³¦äº GrabDAE ææèçæªæ¨ç±¤ç®æ¨åè³æçè½åï¼å¤§å¹æååé¡æºç¢ºåº¦åå¼·å¥æ§ãå¨åæ¬ VisDA-2017ãOffice-Home å Office31 å¨å§çåºæºè³æéä¸é²è¡çå»£æ³å¯¦é©è­æï¼GrabDAE æçºè¶è¶æåé²ç UDA æ¹æ³ï¼è¨­å®æ°çæè½åºæºãééå©ç¨å¶æ°ç©çç¹å¾µé®ç½©åå»éè¨æ¹æ³ä¾è§£æ±º UDA çééµææ°ï¼GrabDAE å¨åé©æä¸­æä¾äºéè¦ççè«åå¯¦åé²å±ã

##### **Efficiently Learning at Test-Time: Active Fine-Tuning of LLMs**
2410.08020v1 by Jonas HÃ¼botter, Sascha Bongni, Ido Hakimi, Andreas Krause

Recent efforts in fine-tuning language models often rely on automatic data
selection, commonly using Nearest Neighbors retrieval from large datasets.
However, we theoretically show that this approach tends to select redundant
data, limiting its effectiveness or even hurting performance. To address this,
we introduce SIFT, a data selection algorithm designed to reduce uncertainty
about the model's response given a prompt, which unifies ideas from retrieval
and active learning. Whereas Nearest Neighbor retrieval typically fails in the
presence of information duplication, SIFT accounts for information duplication
and optimizes the overall information gain of the selected examples. We focus
our evaluations on fine-tuning at test-time for prompt-specific language
modeling on the Pile dataset, and show that SIFT consistently outperforms
Nearest Neighbor retrieval, with minimal computational overhead. Moreover, we
show that our uncertainty estimates can predict the performance gain of
test-time fine-tuning, and use this to develop an adaptive algorithm that
invests test-time compute proportional to realized performance gains. We
provide the $\texttt{activeft}$ (Active Fine-Tuning) library which can be used
as a drop-in replacement for Nearest Neighbor retrieval.

æè¦ï¼è¿æ¥å¾®è°è¯­è¨æ¨¡åçåªåç»å¸¸ä»°èµèªå¨æ°æ®éåï¼éå¸¸ä½¿ç¨å¤§åæ°æ®éä¸­çæè¿é»æ£ç´¢ãç¶èï¼æä»¬å¨çè®ºä¸è¯æï¼æ­¤æ¹æ³å¾åäºéååä½æ°æ®ï¼éå¶å¶æè½ï¼çè³æå®³æè½ãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æä»¬å¼å¥äº SIFTï¼è¿æ¯ä¸ç§æ°æ®éåç®æ³ï¼æ¨å¨åå°æ¨¡åå¨ç»å®æç¤ºæ¶çååºä¸ç¡®å®æ§ï¼å®ç»ä¸äºæ£ç´¢åä¸»å¨å­¦ä¹ çææ³ãæè¿é»æ£ç´¢å¨å­å¨ä¿¡æ¯éå¤çæåµä¸éå¸¸ä¼å¤±è´¥ï¼è SIFT åèèäºä¿¡æ¯éå¤ï¼å¹¶ä¼åäºæéèä¾çæ»ä½ä¿¡æ¯å¢çãæä»¬ä¸æ³¨äºå¨æµè¯æ¶éå¯¹æç¤ºç¹å®è¯­è¨æ¨¡åçå¾®è°å¨ Pile æ°æ®éä¸è¿è¡è¯ä¼°ï¼å¹¶è¡¨æ SIFT å§ç»ä¼äºæè¿é»æ£ç´¢ï¼ä¸è®¡ç®å¼éæå°ãæ­¤å¤ï¼æä»¬è¡¨æï¼æä»¬çä¸ç¡®å®æ§ä¼°è®¡å¯ä»¥é¢æµæµè¯æ¶å¾®è°çæ§è½å¢çï¼å¹¶å©ç¨æ­¤æ¥å¼åä¸ç§èªéåºç®æ³ï¼è¯¥ç®æ³æ ¹æ®å®ç°çæ§è½å¢çææ¯ä¾å°æå¥æµè¯æ¶è®¡ç®ãæä»¬æä¾äº $\texttt{activeft}$ï¼ä¸»å¨å¾®è°ï¼åºï¼å¯ä»¥ç¨ä½æè¿é»æ£ç´¢çæ¿ä»£æ¹æ¡ã

##### **LLM Cascade with Multi-Objective Optimal Consideration**
2410.08014v1 by Kai Zhang, Liqian Peng, Congchao Wang, Alec Go, Xiaozhong Liu

Large Language Models (LLMs) have demonstrated exceptional capabilities in
understanding and generating natural language. However, their high deployment
costs often pose a barrier to practical applications, especially. Cascading
local and server models offers a promising solution to this challenge. While
existing studies on LLM cascades have primarily focused on the performance-cost
trade-off, real-world scenarios often involve more complex requirements. This
paper introduces a novel LLM Cascade strategy with Multi-Objective
Optimization, enabling LLM cascades to consider additional objectives (e.g.,
privacy) and better align with the specific demands of real-world applications
while maintaining their original cascading abilities. Extensive experiments on
three benchmarks validate the effectiveness and superiority of our approach.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾åºå¨çè§£åç¢çèªç¶èªè¨æ¹é¢çåè¶è½åãç¶èï¼å®åçé«é¨ç½²ææ¬éå¸¸æå°å¯¦éæç¨æ§æéç¤ï¼å°¤å¶æ¯ä¸²æ¥æ¬å°åä¼ºæå¨æ¨¡åçºæ­¤ææ°æä¾äºæå¸æçè§£æ±ºæ¹æ¡ãéç¶ç¾æéæ¼ LLM ä¸²æ¥çç ç©¶ä¸»è¦éæ³¨æ¼æè½ææ¬æ¬è¡¡ï¼ä½å¯¦éææ³éå¸¸æ¶åæ´è¤éçè¦æ±ãæ¬æä»ç´¹äºä¸åæ°ç LLM ä¸²æ¥ç­ç¥ï¼å·æå¤ç®æ¨æä½³åï¼è® LLM ä¸²æ¥è½å¤ èæ®å¶ä»ç®æ¨ï¼ä¾å¦é±ç§ï¼ï¼ä¸¦å¨ç¶­æå¶åå§ä¸²æ¥è½åçåæï¼æ´å¥½å°ç¬¦åå¯¦éæç¨ç¨å¼çç¹å®éæ±ãå¨ä¸ååºæºä¸é²è¡çå»£æ³å¯¦é©é©è­äºæåæ¹æ³çæææ§ååªè¶æ§ã

##### **Towards Synergistic, Generalized, and Efficient Dual-System for Robotic Manipulation**
2410.08001v1 by Qingwen Bu, Hongyang Li, Li Chen, Jisong Cai, Jia Zeng, Heming Cui, Maoqing Yao, Yu Qiao

The increasing demand for versatile robotic systems to operate in diverse and
dynamic environments has emphasized the importance of a generalist policy,
which leverages a large cross-embodiment data corpus to facilitate broad
adaptability and high-level reasoning. However, the generalist would struggle
with inefficient inference and cost-expensive training. The specialist policy,
instead, is curated for specific domain data and excels at task-level precision
with efficiency. Yet, it lacks the generalization capacity for a wide range of
applications. Inspired by these observations, we introduce RoboDual, a
synergistic dual-system that supplements the merits of both generalist and
specialist policy. A diffusion transformer-based specialist is devised for
multi-step action rollouts, exquisitely conditioned on the high-level task
understanding and discretized action output of a vision-language-action (VLA)
based generalist. Compared to OpenVLA, RoboDual achieves 26.7% improvement in
real-world setting and 12% gain on CALVIN by introducing a specialist policy
with merely 20M trainable parameters. It maintains strong performance with 5%
of demonstration data only, and enables a 3.8 times higher control frequency in
real-world deployment. Code would be made publicly available. Our project page
is hosted at: https://opendrivelab.com/RoboDual/

æè¦ï¼é¨èå°å¤åè½æ©å¨äººç³»çµ±å¨å¤æ¨£ä¸åæç°å¢ä¸­éä½çéæ±æ¥çå¢å ï¼å¼·èª¿äºéææ¿ç­çéè¦æ§ï¼è©²æ¿ç­å©ç¨å¤§éçè·¨å·ç¾æ¸æèªæåº«ä¾ä¿é²å»£æ³çé©ææ§åé«å±¤æ¬¡æ¨çãç¶èï¼éæå¨ä½æççæ¨è«åææ¬æè²´çè¨ç·´ä¸­æéå°å°é£ãç¸åå°ï¼å°å®¶æ¿ç­æ¯éå°ç¹å®é åæ¸æé²è¡ç­åï¼ä¸¦å¨ä»»åå±¤ç´ç²¾ç¢ºåº¦åæçæ¹é¢è¡¨ç¾åºè²ãç¶èï¼å®ç¼ºä¹å»£æ³æç¨çä¸è¬åè½åãåå°éäºè§å¯çåç¼ï¼æåå¼å¥äº RoboDualï¼ä¸åååéç³»çµ±ï¼å®è£åäºéæåå°å®¶æ¿ç­çåªé»ãä¸ååºæ¼æ´æ£Transformerçå°å®¶è¢«è¨­è¨ç¨æ¼å¤æ­¥é©åä½å±éï¼ä¸¦æ ¹æåºæ¼è¦è¦ºèªè¨åä½ (VLA) çéæçé«å±¤æ¬¡ä»»åçè§£åé¢æ£ååä½è¼¸åºé²è¡ç²¾ç¢ºèª¿æ´ãè OpenVLA ç¸æ¯ï¼RoboDual å¨ç¾å¯¦ä¸çè¨­ç½®ä¸­æåäº 26.7%ï¼ä¸¦ééåä½¿ç¨ 20M å¯è¨ç·´åæ¸å¼å¥å°å®¶æ¿ç­ï¼å¨ CALVIN ä¸å¢å äº 12%ãå®åä½¿ç¨ 5% çç¤ºç¯æ¸æå°±è½ç¶­æå¼·åçæè½ï¼ä¸¦å¨å¯¦éé¨ç½²ä¸­å¯¦ç¾äºé«åº 3.8 åçæ§å¶é »çãç¨å¼ç¢¼å°å¬éæä¾ãæåçå°æ¡é é¢ç¶²åçºï¼https://opendrivelab.com/RoboDual/

##### **Human and LLM Biases in Hate Speech Annotations: A Socio-Demographic Analysis of Annotators and Targets**
2410.07991v1 by Tommaso Giorgi, Lorenzo Cima, Tiziano Fagni, Marco Avvenuti, Stefano Cresci

The rise of online platforms exacerbated the spread of hate speech, demanding
scalable and effective detection. However, the accuracy of hate speech
detection systems heavily relies on human-labeled data, which is inherently
susceptible to biases. While previous work has examined the issue, the
interplay between the characteristics of the annotator and those of the target
of the hate are still unexplored. We fill this gap by leveraging an extensive
dataset with rich socio-demographic information of both annotators and targets,
uncovering how human biases manifest in relation to the target's attributes.
Our analysis surfaces the presence of widespread biases, which we
quantitatively describe and characterize based on their intensity and
prevalence, revealing marked differences. Furthermore, we compare human biases
with those exhibited by persona-based LLMs. Our findings indicate that while
persona-based LLMs do exhibit biases, these differ significantly from those of
human annotators. Overall, our work offers new and nuanced results on human
biases in hate speech annotations, as well as fresh insights into the design of
AI-driven hate speech detection systems.

æè¦ï¼ç·ä¸å¹³å°çèèµ·å åäºä»æ¨è¨è«çæ£æ­ï¼éè¦å¯æ´åä¸ææçåµæ¸¬æ©å¶ãç¶èï¼ä»æ¨è¨è«åµæ¸¬ç³»çµ±çæºç¢ºæ§é«åº¦ä¾è³´æ¼äººå·¥æ¨è¨çè³æï¼èéäºè³ææ¬è³ªä¸å®¹æåå°åè¦çå½±é¿ãéç¶ååçç ç©¶å·²æ¢è¨æ­¤è­°é¡ï¼ä½æ¨è¨èç¹å¾µèä»æ¨ç®æ¨ç¹å¾µä¹éçäº¤äºä½ç¨ä»æªè¢«æ¢è¨ãæåééå©ç¨åå«æ¨è¨èèç®æ¨è±å¯çç¤¾æäººå£çµ±è¨è³è¨ä¹å»£æ³è³æéï¼å¡«è£äºéé ç©ºç½ï¼æ­é²äººé¡åè¦å¦ä½èç®æ¨å±¬æ§ç¸éè¯ãæåçåææµ®ç¾äºå»£æ³åè¦çå­å¨ï¼æåæ ¹æåè¦çå¼·åº¦åæ®éæ§ï¼ä»¥éåçæ¹å¼æè¿°åæè¿°åè¦ï¼æ­é²æé¡¯çå·®ç°ãæ­¤å¤ï¼æåå°äººé¡åè¦èåºæ¼è§è²ç LLM æå±ç¾çåè¦é²è¡æ¯è¼ãæåçç ç©¶çµææåºï¼éç¶åºæ¼è§è²ç LLM ç¢ºå¯¦æå±ç¾åè¦ï¼ä½éäºåè¦èäººå·¥æ¨è¨èçåè¦æé¡¯èçä¸åãç¸½é«èè¨ï¼æåçç ç©¶éå°ä»æ¨è¨è«æ¨è¨ä¸­çäººé¡åè¦æä¾äºæ°çä¸ç´°ç·»ççµæï¼ä¸¦å° AI é©åçä»æ¨è¨è«åµæ¸¬ç³»çµ±çè¨­è¨æä¾äºæ°çè¦è§£ã

##### **Omni-MATH: A Universal Olympiad Level Mathematic Benchmark For Large Language Models**
2410.07985v1 by Bofei Gao, Feifan Song, Zhe Yang, Zefan Cai, Yibo Miao, Qingxiu Dong, Lei Li, Chenghao Ma, Liang Chen, Runxin Xu, Zhengyang Tang, Benyou Wang, Daoguang Zan, Shanghaoran Quan, Ge Zhang, Lei Sha, Yichang Zhang, Xuancheng Ren, Tianyu Liu, Baobao Chang

Recent advancements in large language models (LLMs) have led to significant
breakthroughs in mathematical reasoning capabilities. However, existing
benchmarks like GSM8K or MATH are now being solved with high accuracy (e.g.,
OpenAI o1 achieves 94.8% on MATH dataset), indicating their inadequacy for
truly challenging these models. To bridge this gap, we propose a comprehensive
and challenging benchmark specifically designed to assess LLMs' mathematical
reasoning at the Olympiad level. Unlike existing Olympiad-related benchmarks,
our dataset focuses exclusively on mathematics and comprises a vast collection
of 4428 competition-level problems with rigorous human annotation. These
problems are meticulously categorized into over 33 sub-domains and span more
than 10 distinct difficulty levels, enabling a holistic assessment of model
performance in Olympiad-mathematical reasoning. Furthermore, we conducted an
in-depth analysis based on this benchmark. Our experimental results show that
even the most advanced models, OpenAI o1-mini and OpenAI o1-preview, struggle
with highly challenging Olympiad-level problems, with 60.54% and 52.55%
accuracy, highlighting significant challenges in Olympiad-level mathematical
reasoning.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) è¿æçé²å±å·²å°è´æ¸å­¸æ¨çè½åçéå¤§çªç ´ãç¶èï¼ç¾æçåºæºï¼ä¾å¦ GSM8K æ MATHï¼ç¾å¨æ­£ä»¥é«æºç¢ºåº¦è¢«è§£æ±ºï¼ä¾å¦ï¼OpenAI o1 å¨ MATH è³æéä¸éå° 94.8%ï¼ï¼è¡¨æå®åä¸è¶³ä»¥çæ­£ææ°éäºæ¨¡åãçºäºå½åéä¸å·®è·ï¼æåæåºäºä¸åå¨é¢ä¸å·æææ°æ§çåºæºï¼å°éè¨­è¨ç¨æ¼è©ä¼°å¥§æå¹åç´å¥ç LLM æ¸å­¸æ¨çè½åãèç¾æçå¥§æå¹åç¸éåºæºä¸åï¼æåçè³æéå°æ³¨æ¼æ¸å­¸ï¼ä¸¦åå«å¤§é 4428 åç«¶è³½ç´å¥åé¡ï¼ä¸¦éæäººå·¥ä»ç´°è¨»è§£ãéäºåé¡è¢«ç´°ç·»å°åçº 33 åå­é åï¼ä¸¦è·¨è¶ 10 åä¸åçé£åº¦ç´å¥ï¼å¾èè½å¤ å¨é¢è©ä¼°æ¨¡åå¨å¥§æå¹åæ¸å­¸æ¨çä¸­çè¡¨ç¾ãæ­¤å¤ï¼æåæ ¹ææ­¤åºæºé²è¡äºæ·±å¥åæãæåçå¯¦é©çµæè¡¨æï¼å³ä½¿æ¯æåé²çæ¨¡å OpenAI o1-mini å OpenAI o1-previewï¼å¨æ¥µå·ææ°æ§çå¥§æå¹åç´å¥åé¡ä¸ä¹é£ä»¥æä»ï¼æºç¢ºçåå¥çº 60.54% å 52.55%ï¼çªé¡¯äºå¥§æå¹åç´å¥æ¸å­¸æ¨çä¸­çéå¤§ææ°ã

##### **MolMix: A Simple Yet Effective Baseline for Multimodal Molecular Representation Learning**
2410.07981v1 by Andrei Manolache, Dragos Tantaru, Mathias Niepert

In this work, we propose a simple transformer-based baseline for multimodal
molecular representation learning, integrating three distinct modalities:
SMILES strings, 2D graph representations, and 3D conformers of molecules. A key
aspect of our approach is the aggregation of 3D conformers, allowing the model
to account for the fact that molecules can adopt multiple conformations-an
important factor for accurate molecular representation. The tokens for each
modality are extracted using modality-specific encoders: a transformer for
SMILES strings, a message-passing neural network for 2D graphs, and an
equivariant neural network for 3D conformers. The flexibility and modularity of
this framework enable easy adaptation and replacement of these encoders, making
the model highly versatile for different molecular tasks. The extracted tokens
are then combined into a unified multimodal sequence, which is processed by a
downstream transformer for prediction tasks. To efficiently scale our model for
large multimodal datasets, we utilize Flash Attention 2 and bfloat16 precision.
Despite its simplicity, our approach achieves state-of-the-art results across
multiple datasets, demonstrating its effectiveness as a strong baseline for
multimodal molecular representation learning.

æè¦ï¼å¨éé å·¥ä½ä¸­ï¼æåæåºä¸åç°¡å®çåºæ¼ Transformer çåºç·ï¼ç¨æ¼å¤æ¨¡æåå­è¡¨ç¤ºå­¸ç¿ï¼æ´åäºä¸ç¨®ä¸åçæ¨¡æï¼SMILES å­ç¬¦ä¸²ã2D åå½¢è¡¨ç¤ºååå­ç 3D æ§è±¡ãæåæ¹æ³çä¸åééµæ¹é¢æ¯ 3D æ§è±¡çèåï¼åè¨±æ¨¡åèæ®åå­å¯ä»¥æ¡ç¨å¤ç¨®æ§è±¡çäºå¯¦ - éæ¯æºç¢ºåå­è¡¨ç¤ºçä¸åéè¦å ç´ ãæ¯åæ¨¡æçç¬¦èé½æ¯ä½¿ç¨ç¹å®æ¼æ¨¡æçç·¨ç¢¼å¨æåçï¼SMILES å­ç¬¦ä¸²ç Transformerã2D åå½¢çè¨æ¯å³éç¥ç¶ç¶²è·¯å 3D æ§è±¡çç­è®ç¥ç¶ç¶²è·¯ãéåæ¶æ§çéæ´»æ§èæ¨¡çµååè¨±è¼é¬èª¿æ´åæ¿æéäºç·¨ç¢¼å¨ï¼ä½¿æ¨¡åå°ä¸åçåå­ä»»åå·æé«åº¦éç¨æ§ãæåçç¬¦èç¶å¾çµåæä¸åçµ±ä¸çå¤æ¨¡æåºåï¼ç±ä¸æ¸¸ Transformer èçä»¥é²è¡é æ¸¬ä»»åãçºäºææå°æ´å±æåçæ¨¡åä»¥é©æå¤§åå¤æ¨¡ææ¸æéï¼æåå©ç¨ Flash Attention 2 å bfloat16 ç²¾åº¦ãåç®¡å¾ç°¡å®ï¼ä½æåçåæ³å¨å¤åæ¸æéä¸é½åå¾äºæåé²ççµæï¼è­æäºå¶ä½çºå¤æ¨¡æåå­è¡¨ç¤ºå­¸ç¿çå¼·å¤§åºç·çæææ§ã

##### **Doob's Lagrangian: A Sample-Efficient Variational Approach to Transition Path Sampling**
2410.07974v1 by Yuanqi Du, Michael Plainer, Rob Brekelmans, Chenru Duan, Frank NoÃ©, Carla P. Gomes, Alan Apsuru-Guzik, Kirill Neklyudov

Rare event sampling in dynamical systems is a fundamental problem arising in
the natural sciences, which poses significant computational challenges due to
an exponentially large space of trajectories. For settings where the dynamical
system of interest follows a Brownian motion with known drift, the question of
conditioning the process to reach a given endpoint or desired rare event is
definitively answered by Doob's h-transform. However, the naive estimation of
this transform is infeasible, as it requires simulating sufficiently many
forward trajectories to estimate rare event probabilities. In this work, we
propose a variational formulation of Doob's $h$-transform as an optimization
problem over trajectories between a given initial point and the desired ending
point. To solve this optimization, we propose a simulation-free training
objective with a model parameterization that imposes the desired boundary
conditions by design. Our approach significantly reduces the search space over
trajectories and avoids expensive trajectory simulation and inefficient
importance sampling estimators which are required in existing methods. We
demonstrate the ability of our method to find feasible transition paths on
real-world molecular simulation and protein folding tasks.

æè¦ï¼ååç³»çµ±ä¸­çç½è¦äºä»¶åæ¨£æ¯ä¸åèªç¶ç§å­¸ä¸­åºç¾çåºæ¬åé¡ï¼ç±æ¼è»è·¡ç©ºéåææ¸ç´å¢é·ï¼å æ­¤æé æéå¤§çè¨ç®ææ°ãå°æ¼èè¶£ååç³»çµ±éµå¾ªå·²ç¥æ¼ç§»çå¸æéåçè¨­å®ï¼æ¢ä»¶åèçä»¥å°éçµ¦å®çµé»ææéç½è¦äºä»¶çåé¡ï¼å·²æç¢ºç± Doob ç h è½æè§£ç­ãç¶èï¼éåè½æçæ¨¸ç´ ä¼°è¨ä¸å¯è¡ï¼å çºå®éè¦æ¨¡æ¬è¶³å¤ å¤çååè»è·¡ä¾ä¼°è¨ç½è¦äºä»¶æ©çãå¨éé å·¥ä½ä¸­ï¼æåæåº Doob ç h è½æçè®åå¬å¼ï¼ä½çºçµ¦å®åå§é»åæéçµé»ä¹éè»è·¡çæä½³ååé¡ãçºäºè§£æ±ºéåæä½³ååé¡ï¼æåæåºä¸åç¡æ¨¡æ¬è¨ç·´ç®æ¨ï¼å¶ä¸­æ¨¡ååæ¸åå¨è¨­è¨ä¸æ½å æéçéçæ¢ä»¶ãæåçåæ³å¤§å¹æ¸å°è»è·¡ä¸çæå°ç©ºéï¼ä¸¦é¿åç¾ææ¹æ³ä¸­æéçæè²´è»è·¡æ¨¡æ¬åä½æçéè¦æ§åæ¨£ä¼°è¨å¨ãæåå±ç¤ºæåçæ¹æ³å¨çå¯¦ä¸ççåå­æ¨¡æ¬åèç½è³ªæºçä»»åä¸­æ¾å°å¯è¡è½æè·¯å¾çè½åã

##### **Towards Assurance of LLM Adversarial Robustness using Ontology-Driven Argumentation**
2410.07962v1 by Tomas Bueno Momcilovic, Beat Buesser, Giulio Zizzo, Mark Purcell, Dian Balta

Despite the impressive adaptability of large language models (LLMs),
challenges remain in ensuring their security, transparency, and
interpretability. Given their susceptibility to adversarial attacks, LLMs need
to be defended with an evolving combination of adversarial training and
guardrails. However, managing the implicit and heterogeneous knowledge for
continuously assuring robustness is difficult. We introduce a novel approach
for assurance of the adversarial robustness of LLMs based on formal
argumentation. Using ontologies for formalization, we structure
state-of-the-art attacks and defenses, facilitating the creation of a
human-readable assurance case, and a machine-readable representation. We
demonstrate its application with examples in English language and code
translation tasks, and provide implications for theory and practice, by
targeting engineers, data scientists, users, and auditors.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) å·æä»¤äººå°è±¡æ·±å»çé©ææ§ï¼
ä½å¨ç¢ºä¿å¶å®å¨æ§ãéæåº¦å
å¯è§£éæ§æ¹é¢ä»å­å¨ææ°ãéæ¼å¶å®¹æåå°å°ææ§æ»æï¼LLM
éè¦çµåå°ææ§è¨ç·´å
è­·æ¬ä¾é²è¡é²ç¦¦ãç¶èï¼ç®¡çé±å«ä¸ç°è³ªçç¥è­ä»¥æçºç¢ºä¿
ç©©å¥æ§å¾å°é£ãæåå¼å¥äºä¸ç¨®æ°æ¹æ³ï¼
ç¨æ¼åºæ¼å½¢å¼åè«è­ç¢ºä¿ LLM çå°ææ§ç©©å¥æ§ãä½¿ç¨æ¬é«è«é²è¡å½¢å¼åï¼æåæ¶æ§
æåé²çæ»æåé²ç¦¦ï¼ä¿é²å»ºç«
äººé¡å¯è®çä¿è­æ¡ä¾åæ©å¨å¯è®çè¡¨ç¤ºãæå
ééä»¥å·¥ç¨å¸«ãè³æç§å­¸å®¶ãä½¿ç¨èåå¯©è¨å¡çºç®æ¨ï¼å¨è±èªèªè¨åç¨å¼ç¢¼ä¸­å±ç¤ºå¶æç¨ç¯ä¾
ç¿»è­¯ä»»åï¼ä¸¦æä¾å°çè«åå¯¦åçå½±é¿ã

##### **COMPL-AI Framework: A Technical Interpretation and LLM Benchmarking Suite for the EU Artificial Intelligence Act**
2410.07959v1 by Philipp Guldimann, Alexander Spiridonov, Robin Staab, Nikola JovanoviÄ, Mark Vero, Velko Vechev, Anna Gueorguieva, Mislav BalunoviÄ, Nikola Konstantinov, Pavol Bielik, Petar Tsankov, Martin Vechev

The EU's Artificial Intelligence Act (AI Act) is a significant step towards
responsible AI development, but lacks clear technical interpretation, making it
difficult to assess models' compliance. This work presents COMPL-AI, a
comprehensive framework consisting of (i) the first technical interpretation of
the EU AI Act, translating its broad regulatory requirements into measurable
technical requirements, with the focus on large language models (LLMs), and
(ii) an open-source Act-centered benchmarking suite, based on thorough
surveying and implementation of state-of-the-art LLM benchmarks. By evaluating
12 prominent LLMs in the context of COMPL-AI, we reveal shortcomings in
existing models and benchmarks, particularly in areas like robustness, safety,
diversity, and fairness. This work highlights the need for a shift in focus
towards these aspects, encouraging balanced development of LLMs and more
comprehensive regulation-aligned benchmarks. Simultaneously, COMPL-AI for the
first time demonstrates the possibilities and difficulties of bringing the
Act's obligations to a more concrete, technical level. As such, our work can
serve as a useful first step towards having actionable recommendations for
model providers, and contributes to ongoing efforts of the EU to enable
application of the Act, such as the drafting of the GPAI Code of Practice.

æè¦ï¼æ­ççäººå·¥æºæ§æ³æ¡ï¼AI æ³æ¡ï¼æ¯éåè² è²¬ä»»ç AI éç¼çéè¦ä¸æ­¥ï¼ä½ç¼ºä¹æç¢ºçæè¡è©®éï¼éä½¿å¾è©ä¼°æ¨¡åçåè¦æ§è®å¾å°é£ãéé å·¥ä½æåº COMPL-AIï¼ä¸åå¨é¢çæ¶æ§ï¼åå« (i) å°æ­ç AI æ³æ¡çç¬¬ä¸åæè¡è©®éï¼å°å¶å»£æ³çç£ç®¡è¦æ±è½åçºå¯è¡¡éçæè¡è¦æ±ï¼éé»éæ³¨å¤§åèªè¨æ¨¡å (LLM)ï¼ä»¥å (ii) ä¸åä»¥æ³æ¡çºä¸­å¿çéæºåºæºæ¸¬è©¦å¥ä»¶ï¼åºæ¼å°æåé²ç LLM åºæºæ¸¬è©¦çå¾¹åºèª¿æ¥åå¯¦æ½ãééå¨ COMPL-AI çèæ¯ä¸è©ä¼° 12 åååºç LLMï¼æåæ­é²äºç¾ææ¨¡åååºæºæ¸¬è©¦çç¼ºé»ï¼ç¹å¥æ¯å¨å¥å£¯æ§ãå®å¨æ§ãå¤æ¨£æ§åå¬å¹³æ§ç­é åãéé å·¥ä½å¼·èª¿äºéè¦å°ç¦é»è½ç§»å°éäºæ¹é¢ï¼é¼åµ LLM çå¹³è¡¡ç¼å±åæ´å¨é¢çæ³è¦å°é½åºæºæ¸¬è©¦ãåæï¼COMPL-AI é¦æ¬¡å±ç¤ºäºå°æ³æ¡çç¾©åå·é«åå°æè¡å±¤é¢çå¯è½æ§åé£åº¦ãå æ­¤ï¼æåçç ç©¶å¯ä»¥ä½çºéåå°æ¨¡åä¾æåæåºå¯è¡çå»ºè­°çç¬¬ä¸æ­¥ï¼ä¸¦æå©æ¼æ­ççºå¯¦æ½æ³æ¡æåçæçºåªåï¼ä¾å¦èµ·è GPAI è¡çºå®åã

##### **Disease Entity Recognition and Normalization is Improved with Large Language Model Derived Synthetic Normalized Mentions**
2410.07951v1 by Kuleen Sasse, Shinjitha Vadlakonda, Richard E. Kennedy, John D. Osborne

Background: Machine learning methods for clinical named entity recognition
and entity normalization systems can utilize both labeled corpora and Knowledge
Graphs (KGs) for learning. However, infrequently occurring concepts may have
few mentions in training corpora and lack detailed descriptions or synonyms,
even in large KGs. For Disease Entity Recognition (DER) and Disease Entity
Normalization (DEN), this can result in fewer high quality training examples
relative to the number of known diseases. Large Language Model (LLM) generation
of synthetic training examples could improve performance in these information
extraction tasks.
  Methods: We fine-tuned a LLaMa-2 13B Chat LLM to generate a synthetic corpus
containing normalized mentions of concepts from the Unified Medical Language
System (UMLS) Disease Semantic Group. We measured overall and Out of
Distribution (OOD) performance for DER and DEN, with and without synthetic data
augmentation. We evaluated performance on 3 different disease corpora using 4
different data augmentation strategies, assessed using BioBERT for DER and
SapBERT and KrissBERT for DEN.
  Results: Our synthetic data yielded a substantial improvement for DEN, in all
3 training corpora the top 1 accuracy of both SapBERT and KrissBERT improved by
3-9 points in overall performance and by 20-55 points in OOD data. A small
improvement (1-2 points) was also seen for DER in overall performance, but only
one dataset showed OOD improvement.
  Conclusion: LLM generation of normalized disease mentions can improve DEN
relative to normalization approaches that do not utilize LLMs to augment data
with synthetic mentions. Ablation studies indicate that performance gains for
DEN were only partially attributable to improvements in OOD performance. The
same approach has only a limited ability to improve DER. We make our software
and dataset publicly available.

æè¦ï¼<paragraph>èæ¯ï¼è¨åºå½åå¯¦é«è­å¥çæ©å¨å­¸ç¿æ¹æ³åå¯¦é«æ­£è¦åç³»çµ±å¯ä»¥å©ç¨æ¨è¨èªæåº«åç¥è­åè­ (KG) ä¾å­¸ç¿ãç¶èï¼å¨è¨ç·´èªæåº«ä¸­å¾å°åºç¾çæ¦å¿µå¯è½åªæå°æ¸æåï¼å³ä½¿å¨å¤§åç¥è­åè­ä¸­ä¹ç¼ºä¹è©³ç´°çæè¿°æåç¾©è©ãå°æ¼ç¾çå¯¦é«è­å¥ (DER) åç¾çå¯¦é«æ­£è¦å (DEN)ï¼ç¸å°æ¼å·²ç¥ç¾ççæ¸éï¼éå¯è½æå°è´è¼å°çé«åè³ªè¨ç·´ç¯ä¾ãå¤§åèªè¨æ¨¡å (LLM) çæçåæè¨ç·´ç¯ä¾å¯ä»¥æåéäºè³è¨æ·åä»»åçæè½ã
æ¹æ³ï¼æåå¾®èª¿äºä¸å LLaMa-2 13B èå¤© LLMï¼ä»¥ç¢çä¸ååæèªæåº«ï¼å¶ä¸­åå«ä¾èªçµ±ä¸é«å­¸èªè¨ç³»çµ± (UMLS) ç¾çèªç¾©ç¾¤çæ¨æºåæ¦å¿µæåãæåè¡¡éäº DER å DEN çæ´é«ååå¸å¤ (OOD) æè½ï¼æåæ²æåæè³ææ´åãæåä½¿ç¨ 4 ç¨®ä¸åçè³ææ´åç­ç¥è©ä¼°äº 3 åä¸åç¾çèªæåº«çæè½ï¼ä½¿ç¨ BioBERT è©ä¼° DERï¼ä½¿ç¨ SapBERT å KrissBERT è©ä¼° DENã
çµæï¼æåçåæè³æå° DEN ç¢çäºé¡¯èçæ¹åï¼å¨ææ 3 åè¨ç·´èªæåº«ä¸­ï¼SapBERT å KrissBERT çå 1 åæºç¢ºçå¨æ´é«æè½ä¸æé«äº 3-9 åç¾åé»ï¼å¨ OOD è³æä¸­æé«äº 20-55 åç¾åé»ãå¨ DER çæ´é«æè½ä¸ä¹çå°äºå¾®å°çæ¹åï¼1-2 åç¾åé»ï¼ï¼ä½åªæä¸çµè³æé¡¯ç¤ºåº OOD æ¹åã
çµè«ï¼èä¸å©ç¨ LLM æ´åè³æä»¥åææåçæ­£è¦åæ¹æ³ç¸æ¯ï¼LLM çæçæ¨æºåç¾çæåå¯ä»¥æ¹å DENãæ¶èç ç©¶è¡¨æï¼DEN çæè½æååé¨åæ­¸å æ¼ OOD æè½çæ¹åãç¸åçæ¹æ³å°æ¼æ¹å DER çè½åæéãæåå¬éæåçè»é«åè³æéã</paragraph>

##### **The Function-Representation Unification Framework**
2410.07928v1 by Alfredo Ibias, Hector Antona, Guillem Ramirez-Miranda, Enric Guinovart, Eduard Alarcon

Cognitive Architectures are the forefront of our research into developing an
artificial cognition. However, they approach the problem from a separated
memory and program model of computation. This model of computation poses a
fundamental problem: the knowledge retrieval heuristic. In this paper we
propose to solve this problem by using a new model of computation, one where
the memory and the program are united: the Function-Representation. We propose
a whole framework about how to implement and use these
Function-Representations, and we explore their potential through mathematical
definitions and proofs. We also talk about different ways to organise multiple
Function-Representations, and explore the kind of functions that these
Function-Representations can implement. Finally, we also explore the
limitations of our proposal.

æè¦ï¼èªç¥æ¶æ§æ¯æåéç¼äººå·¥èªç¥ç ç©¶çåæ²¿ãç¶èï¼ä»åå¾åé¢çè¨æ¶åç¨å¼è¨ç®æ¨¡åä¾æ¢è¨åé¡ãéåè¨ç®æ¨¡åæåºäºåºæ¬åé¡ï¼ç¥è­æ·ååç¼æ³ãå¨æ¬æä¸­ï¼æåæè­°ä½¿ç¨æ°çè¨ç®æ¨¡åä¾è§£æ±ºéååé¡ï¼ä¸åè¨æ¶é«åç¨å¼çµåçæ¨¡åï¼å½æ¸è¡¨ç¤ºãæåæåºä¸åéæ¼å¦ä½å¯¦ä½åä½¿ç¨éäºå½æ¸è¡¨ç¤ºçå®æ´æ¶æ§ï¼ä¸¦ééæ¸å­¸å®ç¾©åè­æä¾æ¢è¨å®åçæ½åãæåä¹è¨è«çµç¹å¤åå½æ¸è¡¨ç¤ºçä¸åæ¹æ³ï¼ä¸¦æ¢è¨éäºå½æ¸è¡¨ç¤ºå¯ä»¥å¯¦ä½çå½æ¸é¡åãæå¾ï¼æåä¹æ¢è¨æåæè­°çéå¶ã

##### **InstructBioMol: Advancing Biomolecule Understanding and Design Following Human Instructions**
2410.07919v1 by Xiang Zhuang, Keyan Ding, Tianwen Lyu, Yinuo Jiang, Xiaotong Li, Zhuoyi Xiang, Zeyuan Wang, Ming Qin, Kehua Feng, Jike Wang, Qiang Zhang, Huajun Chen

Understanding and designing biomolecules, such as proteins and small
molecules, is central to advancing drug discovery, synthetic biology, and
enzyme engineering. Recent breakthroughs in Artificial Intelligence (AI) have
revolutionized biomolecular research, achieving remarkable accuracy in
biomolecular prediction and design. However, a critical gap remains between
AI's computational power and researchers' intuition, using natural language to
align molecular complexity with human intentions. Large Language Models (LLMs)
have shown potential to interpret human intentions, yet their application to
biomolecular research remains nascent due to challenges including specialized
knowledge requirements, multimodal data integration, and semantic alignment
between natural language and biomolecules. To address these limitations, we
present InstructBioMol, a novel LLM designed to bridge natural language and
biomolecules through a comprehensive any-to-any alignment of natural language,
molecules, and proteins. This model can integrate multimodal biomolecules as
input, and enable researchers to articulate design goals in natural language,
providing biomolecular outputs that meet precise biological needs. Experimental
results demonstrate InstructBioMol can understand and design biomolecules
following human instructions. Notably, it can generate drug molecules with a
10% improvement in binding affinity and design enzymes that achieve an ESP
Score of 70.4, making it the only method to surpass the enzyme-substrate
interaction threshold of 60.0 recommended by the ESP developer. This highlights
its potential to transform real-world biomolecular research.

æè¦ï¼<paragraph>äºè§£åè¨­è¨çç©åå­ï¼ä¾å¦èç½è³ªåå°åå­ï¼å°æ¼æ¨é²è¥ç©ç¼ç¾ãåæçç©å­¸åé¶å·¥ç¨è³ééè¦ãæè¿äººå·¥æºè½ (AI) ççªç ´å¾¹åºæ¹è®äºçç©åå­ç ç©¶ï¼å¨çç©åå­é æ¸¬åè¨­è¨æ¹é¢åå¾äºé¡¯èçæºç¢ºæ§ãç¶èï¼AI çè¨ç®è½ååç ç©¶äººå¡çç´è¦ºä¹éä»ç¶å­å¨ééµå·®è·ï¼ä½¿ç¨èªç¶èªè¨å°åå­è¤éæ§èäººé¡æåå°é½ãå¤§åèªè¨æ¨¡å (LLM) å·²é¡¯ç¤ºåºè§£éäººé¡æåçæ½åï¼ä½ç±æ¼åæ¬å°æ¥­ç¥è­è¦æ±ãå¤æ¨¡å¼æ¸ææ´åä»¥åèªç¶èªè¨åçç©åå­ä¹éçèªç¾©å°é½å¨å§çææ°ï¼å®åå¨çç©åå­ç ç©¶ä¸­çæç¨ä»ç¶èæ¼èè½éæ®µãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäº InstructBioMolï¼éæ¯ä¸ç¨®æ°ç©ç LLMï¼æ¨å¨ééèªç¶èªè¨ãåå­åèç½è³ªçå¨é¢ä»»æå°é½ä¾æ©æ¥èªç¶èªè¨åçç©åå­ãæ­¤æ¨¡åå¯ä»¥æ´åå¤æ¨¡å¼çç©åå­ä½çºè¼¸å¥ï¼ä¸¦ä½¿ç ç©¶äººå¡è½å¤ ç¨èªç¶èªè¨è¡¨éè¨­è¨ç®æ¨ï¼æä¾æ»¿è¶³ç²¾ç¢ºçç©éæ±ççç©åå­è¼¸åºãå¯¦é©çµæè¡¨æï¼InstructBioMol å¯ä»¥çè§£åè¨­è¨éµå¾ªäººé¡æä»¤ççç©åå­ãå¼å¾æ³¨æçæ¯ï¼å®å¯ä»¥çæçµåè¦ªååæé« 10% çè¥ç©åå­ï¼ä¸¦è¨­è¨åº ESP å¾åéå° 70.4 çé¶ï¼ä½¿å¶æçºå¯ä¸ä¸ç¨®è¶è¶ ESP éç¼äººå¡æ¨è¦ç 60.0 é¶åºç©ç¸äºä½ç¨é¾å¼çæè¡ãéçªé¡¯äºå¶è½è®ç¾å¯¦ä¸ççç©åå­ç ç©¶çæ½åã</paragraph>

##### **ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation**
2410.07908v1 by LÃ©o Machado, HÃ©lÃ¨ne Philippe, Ãlodie Ferreres, Julien Khlaut, Julie Dupuis, Korentin Le Floch, Denis Habip Gatenyo, Pascal Roux, Jules GrÃ©gory, Maxime Ronot, Corentin Dancette, Daniel Tordjman, Pierre Manceron, Paul HÃ©rent

Carcinogenesis is a proteiform phenomenon, with tumors emerging in various
locations and displaying complex, diverse shapes. At the crucial intersection
of research and clinical practice, it demands precise and flexible assessment.
However, current biomarkers, such as RECIST 1.1's long and short axis
measurements, fall short of capturing this complexity, offering an approximate
estimate of tumor burden and a simplistic representation of a more intricate
process. Additionally, existing supervised AI models face challenges in
addressing the variability in tumor presentations, limiting their clinical
utility. These limitations arise from the scarcity of annotations and the
models' focus on narrowly defined tasks.
  To address these challenges, we developed ONCOPILOT, an interactive
radiological foundation model trained on approximately 7,500 CT scans covering
the whole body, from both normal anatomy and a wide range of oncological cases.
ONCOPILOT performs 3D tumor segmentation using visual prompts like point-click
and bounding boxes, outperforming state-of-the-art models (e.g., nnUnet) and
achieving radiologist-level accuracy in RECIST 1.1 measurements. The key
advantage of this foundation model is its ability to surpass state-of-the-art
performance while keeping the radiologist in the loop, a capability that
previous models could not achieve. When radiologists interactively refine the
segmentations, accuracy improves further. ONCOPILOT also accelerates
measurement processes and reduces inter-reader variability, facilitating
volumetric analysis and unlocking new biomarkers for deeper insights.
  This AI assistant is expected to enhance the precision of RECIST 1.1
measurements, unlock the potential of volumetric biomarkers, and improve
patient stratification and clinical care, while seamlessly integrating into the
radiological workflow.

æè¦ï¼<paragraph>è´çä½ç¨æ¯ä¸ç¨®è®å½¢ç¾è±¡ï¼è«ç¤åºç¾å¨åç¨®ä½ç½®ï¼ä¸¦åç¾åºè¤éå¤æ¨£çå½¢çãå¨ç ç©¶åè¨åºå¯¦åçéè¦äº¤æé»ï¼å®éè¦ç²¾ç¢ºä¸å½æ§çè©ä¼°ãç¶èï¼ç®åççç©æ¨è¨ï¼ä¾å¦ RECIST 1.1 çé·è»¸åç­è»¸æ¸¬éï¼ä¸¦ç¡æ³ææå°éç¨®è¤éæ§ï¼åªè½æä¾è«ç¤è² æçè¿ä¼¼ä¼°è¨ï¼ä»¥åå°æ´è¤ééç¨çç°¡åè¡¨ç¤ºãæ­¤å¤ï¼ç¾æçç£ç£å¼ AI æ¨¡åå¨èçè«ç¤è¡¨ç¾çå¯è®æ§æé¢è¨ææ°ï¼éå¶äºå®åçè¨åºæç¨ãéäºéå¶ä¾èªæ¼è¨»è§£çç¨å°æ§ï¼ä»¥åæ¨¡åå°æ³¨æ¼ç¹ç¾©å®ç¾©çä»»åã
çºäºæå°éäºææ°ï¼æåéç¼äº ONCOPILOTï¼éæ¯ä¸åäºåå¼æ¾å°å­¸åºç¤æ¨¡åï¼è¨ç·´æ¼æ¶µèå¨èº«çç´ 7,500 åé»è¦æ·å±¤ææï¼åæ¬æ­£å¸¸è§£åçµæ§åå»£æ³çè«ç¤çä¾ãONCOPILOT ä½¿ç¨è¦è¦ºæç¤ºï¼ä¾å¦é»é¸åéçæ¡ï¼å·è¡ 3D è«ç¤åå²ï¼åªæ¼æåé²çæ¨¡åï¼ä¾å¦ nnUnetï¼ï¼ä¸¦å¨ RECIST 1.1 æ¸¬éä¸­éå°æ¾å°ç§é«å¸«ç­ç´çæºç¢ºåº¦ãéååºç¤æ¨¡åçä¸»è¦åªé»æ¯å®è½å¤ è¶è¶æåé²çæè½ï¼åæè®æ¾å°ç§é«å¸«åèå¶ä¸­ï¼éæ¯ä»¥åçæ¨¡åç¡æ³éå°çåè½ãç¶æ¾å°ç§é«å¸«äºåå¼å°åªååå²æï¼æºç¢ºåº¦æé²ä¸æ­¥æé«ãONCOPILOT éå éäºæ¸¬ééç¨ï¼ä¸¦æ¸å°äºè®èéçè®ç°æ§ï¼ä¿è¿äºé«ç©åæï¼ä¸¦è§£éäºæ°ççç©æ¨è¨ï¼ä»¥ç²å¾æ´æ·±å¥çè¦è§£ã
é è¨éå AI å©çå°æé« RECIST 1.1 æ¸¬éçæºç¢ºåº¦ï¼éæ¾é«ç©çç©æ¨è¨çæ½åï¼ä¸¦æ¹åæ£èåå±¤åè¨åºç§è­·ï¼åæç¡ç¸«æ´åå°æ¾å°å­¸å·¥ä½æµç¨ä¸­ã</paragraph>

##### **Executing Arithmetic: Fine-Tuning Large Language Models as Turing Machines**
2410.07896v1 by Junyu Lai, Jiahe Xu, Yao Yang, Yunpeng Huang, Chun Cao, Jingwei Xu

Large Language Models (LLMs) have demonstrated remarkable capabilities across
a wide range of natural language processing and reasoning tasks. However, their
performance in the foundational domain of arithmetic remains unsatisfactory.
When dealing with arithmetic tasks, LLMs often memorize specific examples
rather than learning the underlying computational logic, limiting their ability
to generalize to new problems. In this paper, we propose a Composable
Arithmetic Execution Framework (CAEF) that enables LLMs to learn to execute
step-by-step computations by emulating Turing Machines, thereby gaining a
genuine understanding of computational logic. Moreover, the proposed framework
is highly scalable, allowing composing learned operators to significantly
reduce the difficulty of learning complex operators. In our evaluation, CAEF
achieves nearly 100% accuracy across seven common mathematical operations on
the LLaMA 3.1-8B model, effectively supporting computations involving operands
with up to 100 digits, a level where GPT-4o falls short noticeably in some
settings.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨å»£æ³çèªç¶èªè¨èçåæ¨çä»»åä¸­å±ç¾åºéå¡çè½åãç¶èï¼å®åå¨ç®è¡åºç¤é åçè¡¨ç¾ä»ä¸ç¡äººæãå¨èçç®è¡ä»»åæï¼LLM å¸¸å¸¸è¨ä½ç¹å®ç¯ä¾ï¼èä¸æ¯å­¸ç¿åºå±¤çéç®éè¼¯ï¼ééå¶äºå®åå°æ°åé¡çæ¦åè½åãå¨æ¬æä¸­ï¼æåæåºäºä¸åå¯çµåéç®å·è¡æ¡æ¶ (CAEF)ï¼å®è½è® LLM å­¸ç¿ééæ¨¡æ¬åéæ©ä¾å·è¡å¾ªåºæ¼¸é²çéç®ï¼å¾èçæ­£çè§£éç®éè¼¯ãæ­¤å¤ï¼ææåºçæ¡æ¶å·æé«åº¦å¯æ´åæ§ï¼åè¨±çµåå·²å­¸ç¿çéç®å­ï¼ä»¥é¡¯èéä½å­¸ç¿è¤ééç®å­çé£åº¦ãå¨æåçè©ä¼°ä¸­ï¼CAEF å¨ LLaMA 3.1-8B æ¨¡åä¸å°ä¸é å¸¸è¦çæ¸å­¸éç®éå°äºè¿ 100% çæºç¢ºåº¦ï¼ææå°æ¯æ´æ¶åå¤é 100 ä½æ¸éç®åçéç®ï¼éæ¯ GPT-4o å¨æäºè¨­å®ä¸­æé¡¯ä¸è¶³çå±¤ç´ã

##### **Unsupervised Data Validation Methods for Efficient Model Training**
2410.07880v1 by Yurii Paniv

This paper investigates the challenges and potential solutions for improving
machine learning systems for low-resource languages. State-of-the-art models in
natural language processing (NLP), text-to-speech (TTS), speech-to-text (STT),
and vision-language models (VLM) rely heavily on large datasets, which are
often unavailable for low-resource languages. This research explores key areas
such as defining "quality data," developing methods for generating appropriate
data and enhancing accessibility to model training. A comprehensive review of
current methodologies, including data augmentation, multilingual transfer
learning, synthetic data generation, and data selection techniques, highlights
both advancements and limitations. Several open research questions are
identified, providing a framework for future studies aimed at optimizing data
utilization, reducing the required data quantity, and maintaining high-quality
model performance. By addressing these challenges, the paper aims to make
advanced machine learning models more accessible for low-resource languages,
enhancing their utility and impact across various sectors.

æè¦ï¼éç¯è«ææ¢è¨äºæ¹åä½è³æºèªè¨æ©å¨å­¸ç¿ç³»çµ±çææ°åæ½å¨è§£æ±ºæ¹æ¡ãèªç¶èªè¨èç (NLP)ãæå­è½èªé³ (TTS)ãèªé³è½æå­ (STT) åè¦è¦ºèªè¨æ¨¡å (VLM) ä¸­çææ°æ¨¡åå´éä¾è³´å¤§åè³æéï¼èéäºè³æééå¸¸ç¡æ³ç¨æ¼ä½è³æºèªè¨ãæ¬ç ç©¶æ¢è¨äºå¹¾åééµé åï¼ä¾å¦å®ç¾©ãåªè³ªè³æããéç¼çæé©ç¶è³æçæ¹æ³ï¼ä»¥åå¢å¼·æ¨¡åè¨ç·´çå¯å­åæ§ãå°ç¶åæ¹æ³è«çå¨é¢åé¡§ï¼åæ¬è³ææ´åãå¤èªè¨è½ç§»å­¸ç¿ãåæè³æçæåè³æé¸ææè¡ï¼çªåºäºé²å±åéå¶ãç¢ºå®äºå¹¾åéæ¾çç ç©¶åé¡ï¼çºæ¨å¨æä½³åè³æå©ç¨ãæ¸å°æéè³ææ¸éåç¶­æé«åè³ªæ¨¡åæè½çæªä¾ç ç©¶æä¾äºæ¶æ§ãééè§£æ±ºéäºææ°ï¼æ¬ææ¨å¨è®é²éæ©å¨å­¸ç¿æ¨¡åæ´ææ¼ç¨æ¼ä½è³æºèªè¨ï¼é²èæåå¶å¨ååé åçå¯¦ç¨æ§åå½±é¿åã

##### **Benchmarking Agentic Workflow Generation**
2410.07869v1 by Shuofei Qiao, Runnan Fang, Zhisong Qiu, Xiaobin Wang, Ningyu Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen

Large Language Models (LLMs), with their exceptional ability to handle a wide
range of tasks, have driven significant advancements in tackling reasoning and
planning tasks, wherein decomposing complex problems into executable workflows
is a crucial step in this process. Existing workflow evaluation frameworks
either focus solely on holistic performance or suffer from limitations such as
restricted scenario coverage, simplistic workflow structures, and lax
evaluation standards. To this end, we introduce WorFBench, a unified workflow
generation benchmark with multi-faceted scenarios and intricate graph workflow
structures. Additionally, we present WorFEval, a systemic evaluation protocol
utilizing subsequence and subgraph matching algorithms to accurately quantify
the LLM agent's workflow generation capabilities. Through comprehensive
evaluations across different types of LLMs, we discover distinct gaps between
the sequence planning capabilities and graph planning capabilities of LLM
agents, with even GPT-4 exhibiting a gap of around 15%. We also train two
open-source models and evaluate their generalization abilities on held-out
tasks. Furthermore, we observe that the generated workflows can enhance
downstream tasks, enabling them to achieve superior performance with less time
during inference. Code and dataset will be available at
https://github.com/zjunlp/WorFBench.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) ææèçåç¨®ä»»åçéå¡è½åï¼æ¨åäºè§£æ±ºæ¨çåè¦åä»»åçé¡¯èé²å±ï¼å¶ä¸­å°è¤éåé¡åè§£çºå¯å·è¡å·¥ä½æµç¨æ¯æ­¤éç¨ä¸­è³ééè¦çä¸æ­¥ãç¾æçå·¥ä½æµç¨è©ä¼°æ¡æ¶åªå°æ³¨æ¼æ´é«æè½ï¼æåå°æå¢æ¶µèç¯ååéãå·¥ä½æµç¨çµæ§ç°¡ååè©ä¼°æ¨æºå¯¬é¬ç­éå¶ãçºæ­¤ï¼æåå¼å¥äº WorFBenchï¼ä¸åçµ±ä¸çå·¥ä½æµç¨çæåºæºï¼å·æå¤æ¹é¢çå ´æ¯åè¤éçåå½¢å·¥ä½æµç¨çµæ§ãæ­¤å¤ï¼æåæåºäº WorFEvalï¼ä¸åå©ç¨å­åºååå­åå¹éæ¼ç®æ³ä¾æºç¢ºéå LLM ä»£çå·¥ä½æµç¨çæè½åçç³»çµ±æ§è©ä¼°åå®ãééå°ä¸åé¡å LLM çå¨é¢è©ä¼°ï¼æåç¼ç¾ LLM ä»£ççåºåè¦åè½åååå½¢è¦åè½åä¹éå­å¨æé¡¯çå·®è·ï¼å³ä½¿æ¯ GPT-4 ä¹è¡¨ç¾åºç´ 15% çå·®è·ãæåéè¨ç·´äºå©åéæºæ¨¡åï¼ä¸¦è©ä¼°äºå®åå¨ä¿çä»»åä¸çæ³åè½åãæ­¤å¤ï¼æåè§å¯å°çæççå·¥ä½æµç¨å¯ä»¥å¢å¼·ä¸æ¸¸ä»»åï¼è®å®åå¨æ¨çæéä»¥æ´å°çæéç²å¾æ´å¥½çæè½ãç¨å¼ç¢¼åè³æéå°å¨ https://github.com/zjunlp/WorFBench ä¸æä¾ã

##### **System-2 Reasoning via Generality and Adaptation**
2410.07866v1 by Sejin Kim, Sundong Kim

While significant progress has been made in task-specific applications,
current models struggle with deep reasoning, generality, and adaptation -- key
components of System-2 reasoning that are crucial for achieving Artificial
General Intelligence (AGI). Despite the promise of approaches such as program
synthesis, language models, and transformers, these methods often fail to
generalize beyond their training data and to adapt to novel tasks, limiting
their ability to perform human-like reasoning. This paper explores the
limitations of existing approaches in achieving advanced System-2 reasoning and
highlights the importance of generality and adaptation for AGI. Moreover, we
propose four key research directions to address these gaps: (1) learning human
intentions from action sequences, (2) combining symbolic and neural models, (3)
meta-learning for unfamiliar environments, and (4) reinforcement learning to
reason multi-step. Through these directions, we aim to advance the ability to
generalize and adapt, bringing computational models closer to the reasoning
capabilities required for AGI.

æè¦ï¼åç®¡å¨ç¹å®ä»»åæç¨ç¨å¼æ¹é¢å·²åå¾éå¤§é²å±ï¼
ç®åçæ¨¡åå¨æ·±åº¦æ¨çãæ®éæ§åé©ææ§æ¹é¢ä»æå°é£ï¼èéäºæ¯ç³»çµ± 2 æ¨çä¸­è³ééè¦çééµçµæé¨åï¼å°æ¼å¯¦ç¾äººå·¥éç¨æºæ§ (AGI) è³ééè¦ãåç®¡æç¨å¼åæãèªè¨æ¨¡ååè½æå¨ç­æ¹æ³ï¼ä½éäºæ¹æ³éå¸¸ç¡æ³æ¨å»£å°è¨ç·´è³æä¹å¤ä¸¦é©ææ°ä»»åï¼ééå¶äºå®åå·è¡é¡äººæ¨ççè½åãæ¬ææ¢è¨äºç¾ææ¹æ³å¨å¯¦ç¾é²éç³»çµ± 2 æ¨çæ¹é¢çéå¶ï¼ä¸¦å¼·èª¿äºæ®éæ§åé©ææ§å° AGI çéè¦æ§ãæ­¤å¤ï¼æåæåºäºååééµç ç©¶æ¹åä¾è§£æ±ºéäºå·®è·ï¼(1) å¾åä½åºåä¸­å­¸ç¿äººé¡æåï¼(2) çµåç¬¦èåç¥ç¶æ¨¡åï¼(3) éå°ä¸çæçç°å¢é²è¡åå­¸ç¿ï¼ä»¥å (4) ééå¼·åå­¸ç¿é²è¡å¤æ­¥é©æ¨çãéééäºæ¹åï¼æåæ¨å¨æåæ¨å»£åé©æçè½åï¼è®è¨ç®æ¨¡åæ´æ¥è¿ AGI æéçæ¨çè½åã

##### **RDT-1B: a Diffusion Foundation Model for Bimanual Manipulation**
2410.07864v1 by Songming Liu, Lingxuan Wu, Bangguo Li, Hengkai Tan, Huayu Chen, Zhengyi Wang, Ke Xu, Hang Su, Jun Zhu

Bimanual manipulation is essential in robotics, yet developing foundation
models is extremely challenging due to the inherent complexity of coordinating
two robot arms (leading to multi-modal action distributions) and the scarcity
of training data. In this paper, we present the Robotics Diffusion Transformer
(RDT), a pioneering diffusion foundation model for bimanual manipulation. RDT
builds on diffusion models to effectively represent multi-modality, with
innovative designs of a scalable Transformer to deal with the heterogeneity of
multi-modal inputs and to capture the nonlinearity and high frequency of
robotic data. To address data scarcity, we further introduce a Physically
Interpretable Unified Action Space, which can unify the action representations
of various robots while preserving the physical meanings of original actions,
facilitating learning transferrable physical knowledge. With these designs, we
managed to pre-train RDT on the largest collection of multi-robot datasets to
date and scaled it up to 1.2B parameters, which is the largest diffusion-based
foundation model for robotic manipulation. We finally fine-tuned RDT on a
self-created multi-task bimanual dataset with over 6K+ episodes to refine its
manipulation capabilities. Experiments on real robots demonstrate that RDT
significantly outperforms existing methods. It exhibits zero-shot
generalization to unseen objects and scenes, understands and follows language
instructions, learns new skills with just 1~5 demonstrations, and effectively
handles complex, dexterous tasks. We refer to
https://rdt-robotics.github.io/rdt-robotics/ for the code and videos.

æè¦ï¼éææä½å¨æ©å¨äººæè¡ä¸­è³ééè¦ï¼ç¶èç±æ¼åèª¿å©åæ©å¨æèï¼å°è´å¤æ¨¡å¼åä½åä½ï¼çåºæè¤éæ§ä»¥åè¨ç·´æ¸æçç¨ç¼ºæ§ï¼éç¼åºç¤æ¨¡åæ¥µå·ææ°æ§ãå¨æ¬æä¸­ï¼æåæåºäºæ©å¨äººæ´æ£Transformer (RDT)ï¼éæ¯ä¸åç¨æ¼éææä½çéåµæ§æ´æ£åºç¤æ¨¡åãRDT å»ºç«å¨æ´æ£æ¨¡åä¹ä¸ï¼ä»¥ææè¡¨ç¤ºå¤æ¨¡æï¼ä¸¦æ¡ç¨å¯æ´åTransformerçåµæ°è¨­è¨ä¾èçå¤æ¨¡æè¼¸å¥çç°è³ªæ§ï¼ä¸¦æææ©å¨äººæ¸æçéç·æ§åé«é »çãçºäºè§£æ±ºæ¸æç¨ç¼ºåé¡ï¼æåé²ä¸æ­¥å¼å¥äºä¸åç©çå¯è§£éçµ±ä¸åä½ç©ºéï¼å®å¯ä»¥çµ±ä¸åç¨®æ©å¨äººçåä½è¡¨ç¤ºï¼åæä¿çåå§åä½çç©çæç¾©ï¼ä¿é²å­¸ç¿å¯è½ç§»çç©çç¥è­ãæäºéäºè¨­è¨ï¼æåè¨­æ³å¨è¿ä»çºæ­¢æå¤§çå¤æ©å¨äººæ¸æééåä¸å° RDT é²è¡é è¨ç·´ï¼ä¸¦å°å¶æ´å±å° 1.2B åæ¸ï¼éæ¯æå¤§çåºæ¼æ´æ£çæ©å¨äººæä½åºç¤æ¨¡åãæåæçµå¨ä¸åèªåµçå¤ä»»åéææ¸æéä¸å° RDT é²è¡å¾®èª¿ï¼è©²æ¸æéåå«è¶é 6K åæç¯ï¼ä»¥æåå¶æä½è½åãå¨çå¯¦æ©å¨äººä¸çå¯¦é©è¡¨æï¼RDT æé¡¯åªæ¼ç¾ææ¹æ³ãå®å°æªè¦éçç©é«åå ´æ¯è¡¨ç¾åºé¶æ¬¡å­¸ç¿æ³åï¼çè§£ä¸¦éµå¾ªèªè¨æä»¤ï¼åªé 1~5 æ¬¡ç¤ºç¯å°±è½å­¸ç¿æ°æè½ï¼ä¸¦ææèçè¤éçéå·§ä»»åãæååè https://rdt-robotics.github.io/rdt-robotics/ ç²åä»£ç¢¼åå½±çã

##### **From Logits to Hierarchies: Hierarchical Clustering made Simple**
2410.07858v1 by Emanuele Palumbo, Moritz Vandenhirtz, Alain Ryser, Imant Daunhawer, Julia E. Vogt

The structure of many real-world datasets is intrinsically hierarchical,
making the modeling of such hierarchies a critical objective in both
unsupervised and supervised machine learning. Recently, novel approaches for
hierarchical clustering with deep architectures have been proposed. In this
work, we take a critical perspective on this line of research and demonstrate
that many approaches exhibit major limitations when applied to realistic
datasets, partly due to their high computational complexity. In particular, we
show that a lightweight procedure implemented on top of pre-trained
non-hierarchical clustering models outperforms models designed specifically for
hierarchical clustering. Our proposed approach is computationally efficient and
applicable to any pre-trained clustering model that outputs logits, without
requiring any fine-tuning. To highlight the generality of our findings, we
illustrate how our method can also be applied in a supervised setup, recovering
meaningful hierarchies from a pre-trained ImageNet classifier.

æè¦ï¼è¨±å¤çå¯¦ä¸çè³æéççµæ§æ¬è³ªä¸æ¯éå±¤å¼çï¼
ä½¿å¾å°æ­¤é¡éå±¤å»ºæ¨¡æçºç¡ç£ç£åç£ç£æ©å¨å­¸ç¿ä¸­çéè¦ç®æ¨ãæè¿ï¼
å·²ç¶æåºå·ææ·±åº¦æ¶æ§çéå±¤å¼èé¡æ°æ¹æ³ãå¨éå
å·¥ä½ä¸­ï¼æåå°éæ¢ç ç©¶è·¯ç·æ¡åæ¹å¤æ§çè§é»ï¼ä¸¦è­æ
è¨±å¤æ¹æ³å¨æç¨æ¼å¯¦é
è³æéæè¡¨ç¾åºéå¤§çéå¶ï¼é¨ååå æ¯å®åçé«è¨ç®è¤éåº¦ãç¹å¥æ¯ï¼æå
è¡¨æå¨é åè¨ç·´ç
ééå±¤å¼èé¡æ¨¡åä¹ä¸å¯¦ä½çè¼éç´ç¨åºåªæ¼å°éçº
éå±¤å¼èé¡è¨­è¨çæ¨¡åãæåæåºçæ¹æ³å¨è¨ç®ä¸æ¯ææçï¼ä¸¦ä¸
é©ç¨æ¼ä»»ä½è¼¸åº logit çé åè¨ç·´èé¡æ¨¡åï¼èç¡é
é²è¡ä»»ä½å¾®èª¿ãçºäºå¼·èª¿æåç¼ç¾çæ®éæ§ï¼æå
èªªææåçæ¨¡åå¦ä½ä¹å¯ä»¥æç¨å¨æç£ç£çè¨­å®ä¸­ï¼å¾é åè¨ç·´ç ImageNet åé¡å¨ä¸­æ¢å¾©
ææç¾©çéå±¤ã

##### **Enhancing Language Model Reasoning via Weighted Reasoning in Self-Consistency**
2410.07839v1 by Tim Knappe, Ryan Li, Ayush Chauhan, Kaylee Chhua, Kevin Zhu, Sean O'Brien

While large language models (LLMs) have rapidly improved their performance on
a broad number of tasks, they still often fall short on reasoning tasks. As
LLMs become more integrated in diverse real-world tasks, advancing their
reasoning capabilities is crucial to their effectiveness in nuanced, complex
problems. Wang et al's self-consistency framework reveals that sampling
multiple rationales before taking a majority vote reliably improves model
performance across various closed-answer reasoning tasks. Standard methods
based on this framework aggregate the final decisions of these rationales but
fail to utilize the detailed step-by-step reasoning paths applied by these
paths. Our work enhances this approach by incorporating and analyzing both the
reasoning paths of these rationales in addition to their final decisions before
taking a majority vote. These methods not only improve the reliability of
reasoning paths but also cause more robust performance on complex reasoning
tasks.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) å¨è¨±å¤ä»»åä¸çè¡¨ç¾è¿éæåï¼ä½å®åå¨æ¨çä»»åä¸ä»ç¶å¸¸è¡¨ç¾ä¸ä½³ãé¨è LLM æ´å¤åå°æ´åå¨åç¨®å¯¦éä»»åä¸­ï¼æåå¶æ¨çè½åå°æ¼å®åå¨ç´°å¾®è¤éåé¡ä¸­çææè³ééè¦ãWang ç­äººçèªæ´½æ¶æ§é¡¯ç¤ºï¼å¨é²è¡å¤æ¸æ±ºæç¥¨åå°å¤åä¾æåæ¨£ï¼å¯ä»¥å¤§å¹æåæ¨¡åå¨åç¨®å°éå¼åç­æ¨çä»»åä¸­çè¡¨ç¾ãåºæ¼æ­¤æ¶æ§çæ¨æºæ¹æ³æå½ç¸½éäºä¾æçæçµæ±ºå®ï¼ä½ç¡æ³å©ç¨éäºä¾æææç¨çè©³ç´°éæ­¥æ¨çè·¯å¾ãæåçç ç©¶ééå¨é²è¡å¤æ¸æ±ºæç¥¨åç´å¥ååæéäºä¾æçæ¨çè·¯å¾ï¼ä»¥åå¶æçµæ±ºå®ï¼ä¾å¼·åæ­¤æ¹æ³ãéäºæ¹æ³ä¸åæåæ¨çè·¯å¾çå¯é æ§ï¼ä¹è®æ¨¡åå¨è¤éæ¨çä»»åä¸­çè¡¨ç¾æ´å¼·å¥ã

##### **MinorityPrompt: Text to Minority Image Generation via Prompt Optimization**
2410.07838v1 by Soobin Um, Jong Chul Ye

We investigate the generation of minority samples using pretrained
text-to-image (T2I) latent diffusion models. Minority instances, in the context
of T2I generation, can be defined as ones living on low-density regions of
text-conditional data distributions. They are valuable for various applications
of modern T2I generators, such as data augmentation and creative AI.
Unfortunately, existing pretrained T2I diffusion models primarily focus on
high-density regions, largely due to the influence of guided samplers (like
CFG) that are essential for producing high-quality generations. To address
this, we present a novel framework to counter the high-density-focus of T2I
diffusion models. Specifically, we first develop an online prompt optimization
framework that can encourage the emergence of desired properties during
inference while preserving semantic contents of user-provided prompts. We
subsequently tailor this generic prompt optimizer into a specialized solver
that promotes the generation of minority features by incorporating a
carefully-crafted likelihood objective. Our comprehensive experiments,
conducted across various types of T2I models, demonstrate that our approach
significantly enhances the capability to produce high-quality minority
instances compared to existing samplers.

æè¦ï¼æåç ç©¶ä½¿ç¨é è¨ç·´çæå­è½åå (T2I) æ½å¨æ´æ£æ¨¡åçæå°æ¸æ¨£æ¬ãå¨ T2I çæçèæ¯ä¸ï¼å°æ¸å¯¦ä¾å¯ä»¥å®ç¾©çºå­å¨æ¼æå­æ¢ä»¶æ¸æåä½çä½å¯åº¦ååä¸­çå¯¦ä¾ãå®åå°æ¼ç¾ä»£ T2I çæå¨çåç¨®æç¨å¾æå¹å¼ï¼ä¾å¦æ¸ææ´åååµæ AIãä¸å¹¸çæ¯ï¼ç¾æçé è¨ç·´ T2I æ´æ£æ¨¡åä¸»è¦éæ³¨é«å¯åº¦ååï¼éå¨å¾å¤§ç¨åº¦ä¸æ¯åå°å¼å°åæ¨£å¨ï¼å¦ CFGï¼çå½±é¿ï¼èå¼å°åæ¨£å¨å°æ¼ç¢çé«åè³ªçæè³ééè¦ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸åæ°æ¡æ¶ä¾æå° T2I æ´æ£æ¨¡åçé«å¯åº¦éæ³¨ãå·é«ä¾èªªï¼æåé¦åéç¼ä¸åç·ä¸æç¤ºæä½³åæ¡æ¶ï¼å®å¯ä»¥å¨æ¨çéç¨ä¸­é¼åµæéå±¬æ§çåºç¾ï¼åæä¿çä½¿ç¨èæä¾çæç¤ºçèªç¾©å§å®¹ãæåé¨å¾å°éåéç¨æç¤ºæä½³åå¨èª¿æ´çºä¸åå°éçæ±è§£å¨ï¼ééç´å¥ç²¾å¿è£½ä½çä¼¼ç¶ç®æ¨ä¾ä¿é²å°æ¸ç¹å¾µççæãæåå¨åç¨® T2I æ¨¡åä¸é²è¡çç¶åå¯¦é©è¡¨æï¼èç¾æçåæ¨£å¨ç¸æ¯ï¼æåçåæ³é¡¯èå¢å¼·äºç¢çé«åè³ªå°æ¸å¯¦ä¾çè½åã

##### **Masked Generative Priors Improve World Models Sequence Modelling Capabilities**
2410.07836v1 by Cristian Meo, Mircea Lica, Zarif Ikram, Akihiro Nakano, Vedant Shah, Aniket Rajiv Didolkar, Dianbo Liu, Anirudh Goyal, Justin Dauwels

Deep Reinforcement Learning (RL) has become the leading approach for creating
artificial agents in complex environments. Model-based approaches, which are RL
methods with world models that predict environment dynamics, are among the most
promising directions for improving data efficiency, forming a critical step
toward bridging the gap between research and real-world deployment. In
particular, world models enhance sample efficiency by learning in imagination,
which involves training a generative sequence model of the environment in a
self-supervised manner. Recently, Masked Generative Modelling has emerged as a
more efficient and superior inductive bias for modelling and generating token
sequences. Building on the Efficient Stochastic Transformer-based World Models
(STORM) architecture, we replace the traditional MLP prior with a Masked
Generative Prior (e.g., MaskGIT Prior) and introduce GIT-STORM. We evaluate our
model on two downstream tasks: reinforcement learning and video prediction.
GIT-STORM demonstrates substantial performance gains in RL tasks on the Atari
100k benchmark. Moreover, we apply Transformer-based World Models to continuous
action environments for the first time, addressing a significant gap in prior
research. To achieve this, we employ a state mixer function that integrates
latent state representations with actions, enabling our model to handle
continuous control tasks. We validate this approach through qualitative and
quantitative analyses on the DeepMind Control Suite, showcasing the
effectiveness of Transformer-based World Models in this new domain. Our results
highlight the versatility and efficacy of the MaskGIT dynamics prior, paving
the way for more accurate world models and effective RL policies.

æè¦ï¼æ·±åº¦å¼·åå­¸ç¿ (RL) å·²æçºå¨è¤éç°å¢ä¸­å»ºç«äººå·¥ä»£çç¨å¼çä¸»è¦æ¹æ³ãåºæ¼æ¨¡åçæ¹æ³ï¼å³å·åé æ¸¬ç°å¢åæçä¸çæ¨¡åç RL æ¹æ³ï¼æ¯æ¹åè³ææççææå¸æçæ¹åä¹ä¸ï¼æ§æäºç¸®å°ç ç©¶èå¯¦éé¨ç½²ä¹éå·®è·çééµæ­¥é©ãç¹å¥æ¯ï¼ä¸çæ¨¡åééå¨æ³åä¸­å­¸ç¿ä¾å¢å¼·æ¨£æ¬æçï¼å¶ä¸­æ¶åä»¥èªæç£ç£çæ¹å¼è¨ç·´ç°å¢ççæå¼åºåæ¨¡åãæè¿ï¼é®ç½©çææ¨¡åå·²æçºä¸ç¨®æ´ææçä¸æ´åªè¶çæ­¸ç´åèª¤ï¼ç¨æ¼å»ºæ¨¡åç¢çç¬¦èåºåãå¨åºæ¼ææé¨æ©è®æå¨ä¸çæ¨¡å (STORM) æ¶æ§çåºç¤ä¸ï¼æåç¨é®ç½©çæåé© (ä¾å¦ MaskGIT åé©) åä»£å³çµ±ç MLP åé©ï¼ä¸¦å¼å¥ GIT-STORMãæåå¨å©åä¸æ¸¸ä»»åä¸­è©ä¼°æåçæ¨¡åï¼å¼·åå­¸ç¿åå½±çé æ¸¬ãGIT-STORM å¨ Atari 100k åºæºæ¸¬è©¦ä¸­ç RL ä»»åä¸­å±ç¾åºé¡¯èçæè½æåãæ­¤å¤ï¼æåé¦æ¬¡å°åºæ¼è®æå¨çä¸çæ¨¡åæç¨æ¼é£çºåä½ç°å¢ï¼è§£æ±ºäºååç ç©¶ä¸­çéå¤§å·®è·ãçºæ­¤ï¼æåæ¡ç¨ä¸åçææ··åå¨å½æ¸ï¼å°æ½å¨çæè¡¨ç¤ºèåä½æ´åå¨ä¸èµ·ï¼ä½¿æåçæ¨¡åè½å¤ èçé£çºæ§å¶ä»»åãæåééå¨ DeepMind Control Suite ä¸é²è¡å®æ§åå®éåæä¾é©è­æ­¤æ¹æ³ï¼å±ç¤ºäºåºæ¼è®æå¨çä¸çæ¨¡åå¨æ­¤æ°é åä¸­çæææ§ãæåççµæçªé¡¯äº MaskGIT åæåé©çå¤åè½æ§åæææ§ï¼çºæ´æºç¢ºçä¸çæ¨¡ååææç RL æ¿ç­éªå¹³äºéè·¯ã

##### **NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models**
2410.07830v1 by William Tan, Kevin Zhu

Large Language Models (LLMs) have demonstrated exceptional promise in
translation tasks for high-resource languages. However, their performance in
low-resource languages is limited by the scarcity of both parallel and
monolingual corpora, as well as the presence of noise. Consequently, such LLMs
suffer with alignment and have lagged behind State-of-The-Art (SoTA) neural
machine translation (NMT) models in these settings. This paper introduces
NusaMT-7B, an LLM-based machine translation model for low-resource Indonesian
languages, starting with Balinese and Minangkabau. Leveraging the pretrained
LLaMA2-7B, our approach integrates continued pre-training on monolingual data,
Supervised Fine-Tuning (SFT), self-learning, and an LLM-based data cleaner to
reduce noise in parallel sentences. In the FLORES-200 multilingual translation
benchmark, NusaMT-7B outperforms SoTA models in the spBLEU metric by up to
+6.69 spBLEU in translations into Balinese and Minangkabau, but underperforms
by up to -3.38 spBLEU in translations into higher-resource languages. Our
results show that fine-tuned LLMs can enhance translation quality for
low-resource languages, aiding in linguistic preservation and cross-cultural
communication.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨é«è³æºèªè¨çç¿»è­¯ä»»åä¸­å±ç¾åºéå¡çæ½åãç¶èï¼å®åå¨ä½è³æºèªè¨ä¸­çè¡¨ç¾åå°å¹³è¡èªæåå®èªèªæåº«çç¨ç¼ºä»¥åéè¨çå­å¨æéå¶ãå æ­¤ï¼æ­¤é¡ LLM å¨å°é½æ¹é¢å­å¨åé¡ï¼ä¸¦ä¸å¨éäºè¨­å®ä¸­è½å¾æ¼æåé² (SoTA) ç¥ç¶æ©å¨ç¿»è­¯ (NMT) æ¨¡åãæ¬æä»ç´¹ NusaMT-7Bï¼ä¸ç¨®åºæ¼ LLM çæ©å¨ç¿»è­¯æ¨¡åï¼é©ç¨æ¼ä½è³æºå°å°¼èªè¨ï¼å¾å·´åèªåç±³åå¡ä¿èªéå§ãå©ç¨é åè¨ç·´ç LLaMA2-7Bï¼æåçåæ³æ´åäºå°å®èªæ¸æçæçºé è¨ç·´ãç£ç£å¾®èª¿ (SFT)ãèªå­¸ä»¥ååºæ¼ LLM çæ¸ææ¸çå¨ï¼ä»¥æ¸å°å¹³è¡å¥å­ä¸­çéè¨ãå¨ FLORES-200 å¤èªè¨ç¿»è­¯åºæºä¸­ï¼NusaMT-7B å¨ spBLEU ææ¨ä¸­åªæ¼ SoTA æ¨¡åï¼å¨ç¿»è­¯æå·´åèªåç±³åå¡ä¿èªæï¼spBLEU æé«å¯æé« +6.69ï¼ä½å¨ç¿»è­¯æé«è³æºèªè¨æï¼spBLEU æä½å¯éä½ -3.38ãæåççµæè¡¨æï¼å¾®èª¿å¾ç LLM å¯ä»¥æé«ä½è³æºèªè¨çç¿»è­¯åè³ªï¼æå©æ¼èªè¨ä¿å­åè·¨æåæºéã

##### **Why do objects have many names? A study on word informativeness in language use and lexical systems**
2410.07827v1 by Eleonora Gualdoni, Gemma Boleda

Human lexicons contain many different words that speakers can use to refer to
the same object, e.g., "purple" or "magenta" for the same shade of color. On
the one hand, studies on language use have explored how speakers adapt their
referring expressions to successfully communicate in context, without focusing
on properties of the lexical system. On the other hand, studies in language
evolution have discussed how competing pressures for informativeness and
simplicity shape lexical systems, without tackling in-context communication. We
aim at bridging the gap between these traditions, and explore why a soft
mapping between referents and words is a good solution for communication, by
taking into account both in-context communication and the structure of the
lexicon. We propose a simple measure of informativeness for words and lexical
systems, grounded in a visual space, and analyze color naming data for English
and Mandarin Chinese. We conclude that optimal lexical systems are those where
multiple words can apply to the same referent, conveying different amounts of
information. Such systems allow speakers to maximize communication accuracy and
minimize the amount of information they convey when communicating about
referents in contexts.

æè¦ï¼äººç±»è¯æ±åå«è®¸å¤ä¸åçåè¯ï¼è¯´è¯èå¯ä»¥ä½¿ç¨è¿äºåè¯æ¥æä»£åä¸ä¸ªå¯¹è±¡ï¼ä¾å¦ï¼å¯¹äºåä¸ç§é¢è²çè²è°ï¼å¯ä»¥ä½¿ç¨âç´«è²âæâæ´çº¢è²âãä¸æ¹é¢ï¼è¯­è¨ä½¿ç¨ç ç©¶æ¢è®¨äºè¯´è¯èå¦ä½è°æ´ä»ä»¬çæç§°è¡¨è¾¾ï¼ä»¥ä¾¿å¨ä¸ä¸æä¸­æåå°è¿è¡äº¤æµï¼èæ²¡æä¸æ³¨äºè¯æ±ç³»ç»çå±æ§ãå¦ä¸æ¹é¢ï¼è¯­è¨æ¼åç ç©¶è®¨è®ºäºä¿¡æ¯æ§åç®åæ§ä¹é´çç«äºååå¦ä½å¡é è¯æ±ç³»ç»ï¼èæ²¡æå¤çä¸ä¸æä¸­äº¤æµãæä»¬çç®æ æ¯å¼¥åè¿äºä¼ ç»ä¹é´çå·®è·ï¼å¹¶æ¢è®¨ä¸ºä»ä¹æç§°ç©ååè¯ä¹é´çè½¯æ å°æ¯éè¿èèä¸ä¸æä¸­çäº¤æµåè¯æ±ç»ææ¥è¿è¡äº¤æµçä¸ä¸ªå¥½è§£å³æ¹æ¡ãæä»¬æåºäºä¸ç§ç®åçåè¯åè¯æ±ç³»ç»ä¿¡æ¯æ§åº¦éï¼å®åºäºè§è§ç©ºé´ï¼å¹¶åæäºè±è¯­åæ®éè¯çè²å½©å½åæ°æ®ãæä»¬å¾åºç»è®ºï¼æä½³è¯æ±ç³»ç»æ¯å¤ä¸ªåè¯å¯ä»¥åºç¨äºåä¸æç§°ç©ï¼ä¼ è¾¾ä¸åæ°éçä¿¡æ¯ãè¿æ ·çç³»ç»åè®¸è¯´è¯èæå¤§åäº¤æµåç¡®æ§ï¼å¹¶å¨ä¸ä¸æä¸­äº¤æµæç§°ç©æ¶æå°åä»ä»¬ä¼ è¾¾çä¿¡æ¯éã

##### **Fine-Tuning Language Models for Ethical Ambiguity: A Comparative Study of Alignment with Human Responses**
2410.07826v1 by Pranav Senthilkumar, Visshwa Balasubramanian, Prisha Jain, Aneesa Maity, Jonathan Lu, Kevin Zhu

Language models often misinterpret human intentions due to their handling of
ambiguity, a limitation well-recognized in NLP research. While morally clear
scenarios are more discernible to LLMs, greater difficulty is encountered in
morally ambiguous contexts. In this investigation, we explored LLM calibration
to show that human and LLM judgments are poorly aligned in such scenarios. We
used two curated datasets from the Scruples project for evaluation: DILEMMAS,
which involves pairs of distinct moral scenarios to assess the model's ability
to compare and contrast ethical situations, and ANECDOTES, which presents
individual narratives to evaluate the model's skill in drawing out details,
interpreting, and analyzing distinct moral scenarios. Model answer
probabilities were extracted for all possible choices and compared with human
annotations to benchmark the alignment of three models: Llama-3.1-8b,
Zephyr-7b-beta, and Mistral-7b. Significant improvements were observed after
fine-tuning, with notable enhancements in both cross-entropy and Dirichlet
scores, particularly in the latter. Notably, after fine-tuning, the performance
of Mistral-7B-Instruct-v0.3 was on par with GPT-4o. However, the experimental
models that were examined were all still outperformed by the BERT and RoBERTa
models in terms of cross-entropy scores. Our fine-tuning approach, which
improves the model's understanding of text distributions in a text-to-text
format, effectively enhances performance and alignment in complex
decision-making contexts, underscoring the need for further research to refine
ethical reasoning techniques and capture human judgment nuances.

æè¦ï¼èªè¨æ¨¡åç¶å¸¸æèª¤è§£äººé¡çæåï¼å çºå®åèçæ­§ç¾©çæ¹å¼ï¼éå¨ NLP ç ç©¶ä¸­æ¯ä¸åå»£çºäººç¥çéå¶ãéç¶å°æ¼ LLM ä¾èªªï¼éå¾·æç¢ºçå ´æ¯æ´å®¹æè¾¨è­ï¼ä½å¨éå¾·æ¨¡ç³çèªå¢ä¸­æéå°æ´å¤§çå°é£ãå¨æ­¤ç ç©¶ä¸­ï¼æåæ¢è¨äº LLM æ ¡æ­£ï¼ä»¥è­æäººé¡å LLM çå¤æ·å¨éç¨®å ´æ¯ä¸­å°é½å¾ä¸å¥½ãæåä½¿ç¨äºä¾èª Scruples å°æ¡çå©åæ´çéçè³æéé²è¡è©ä¼°ï¼DILEMMASï¼å¶ä¸­åå«å©çµä¸åçéå¾·å ´æ¯ï¼ç¨æ¼è©ä¼°æ¨¡åæ¯è¼åå°æ¯éå¾·æå¢ççè½åï¼ä»¥å ANECDOTESï¼å¶ä¸­æä¾äºåå¥æè¿°ï¼ç¨æ¼è©ä¼°æ¨¡åå¨æåç´°ç¯ãè©®éååæä¸åçéå¾·å ´æ¯æ¹é¢çæè½ãæ¨¡åç­æ¡æ©çæè¢«æååºä¾ï¼ä»¥ä¾ææå¯è½çé¸æä½¿ç¨ï¼ä¸¦èäººé¡è¨»è§£é²è¡æ¯è¼ï¼ä»¥åºæºæ¸¬è©¦ä¸åæ¨¡åçå°é½ç¨åº¦ï¼Llama-3.1-8bãZephyr-7b-beta å Mistral-7bãå¨å¾®èª¿å¾è§å¯å°é¡¯èçé²æ­¥ï¼ç¹å¥æ¯å¨å¾èä¸­ï¼äº¤åçµå Dirichlet åæ¸é½æé¡¯èçæåãç¹å¥å¼å¾æ³¨æçæ¯ï¼å¾®èª¿å¾ï¼Mistral-7B-Instruct-v0.3 çæè½è GPT-4o ç¸ç¶ãç¶èï¼å¨äº¤åçµåæ¸æ¹é¢ï¼ææª¢é©çå¯¦é©æ¨¡åä»å¨é½è¢« BERT å RoBERTa æ¨¡åè¶è¶ãæåçå¾®èª¿æ¹æ³æ¹é²äºæ¨¡åå°æå­å°æå­æ ¼å¼ä¸­æå­åä½ççè§£ï¼ææå°æåäºå¨è¤éæ±ºç­å¶å®èªå¢ä¸­çæè½åå°é½ç¨åº¦ï¼å¼·èª¿äºé²ä¸æ­¥ç ç©¶ä»¥æ¹åéå¾·æ¨çæè¡åææäººé¡å¤æ·ç´°å¾®å·®å«çå¿è¦æ§ã

##### **Extracting and Transferring Abilities For Building Multi-lingual Ability-enhanced Large Language Models**
2410.07825v1 by Zhipeng Chen, Liang Song, Kun Zhou, Wayne Xin Zhao, Bingning Wang, Weipeng Chen, Ji-Rong Wen

Multi-lingual ability transfer has become increasingly important for the
broad application of large language models (LLMs). Existing work highly relies
on training with the multi-lingual ability-related data, which may be not
available for low-resource languages. To solve it, we propose a Multi-lingual
Ability Extraction and Transfer approach, named as MAET. Our key idea is to
decompose and extract language-agnostic ability-related weights from LLMs, and
transfer them across different languages by simple addition and subtraction
operations without training. Specially, our MAET consists of the extraction and
transfer stages. In the extraction stage, we firstly locate key neurons that
are highly related to specific abilities, and then employ them to extract the
transferable ability-specific weights. In the transfer stage, we further select
the ability-related parameter tensors, and design the merging strategy based on
the linguistic and ability specific weights, to build the multi-lingual
ability-enhanced LLM. To demonstrate the effectiveness of our proposed
approach, we conduct extensive experiments on mathematical and scientific tasks
in both high-resource lingual and low-resource lingual scenarios. Experiment
results have shown that MAET can effectively and efficiently extract and
transfer the advanced abilities, and outperform training-based baseline
methods. Our code and data are available at
\url{https://github.com/RUCAIBox/MAET}.

æè¦ï¼å¤è¯­è¨è½åè¿ç§»å¯¹äºå¤§è¯­è¨æ¨¡å (LLM) çå¹¿æ³åºç¨åå¾è¶æ¥è¶éè¦ãç°æå·¥ä½é«åº¦ä¾èµäºä½¿ç¨ä¸å¤è¯­è¨è½åç¸å³çæ°æ®è¿è¡è®­ç»ï¼è¿å¯¹äºä½èµæºè¯­è¨æ¥è¯´å¯è½ä¸å¯ç¨ãä¸ºäºè§£å³è¿ä¸ªé®é¢ï¼æä»¬æåºäºä¸ç§åä¸º MAET çå¤è¯­è¨è½åæååè¿ç§»æ¹æ³ãæä»¬çå³é®ææ³æ¯ä» LLM ä¸­åè§£åæåä¸è¯­è¨æ å³çè½åç¸å³æéï¼å¹¶éè¿ç®åçå æ³ååæ³è¿ç®å¨ä¸åè¯­è¨ä¹é´è½¬ç§»å®ä»¬ï¼èæ éè®­ç»ãç¹å«å°ï¼æä»¬ç MAET åå«æååè½¬ç§»é¶æ®µãå¨æåé¶æ®µï¼æä»¬é¦åå®ä½ä¸ç¹å®è½åé«åº¦ç¸å³çå³é®ç¥ç»åï¼ç¶åä½¿ç¨å®ä»¬æ¥æåå¯è½¬ç§»çè½åç¹å®æéãå¨è½¬ç§»é¶æ®µï¼æä»¬è¿ä¸æ­¥éæ©ä¸è½åç¸å³çåæ°å¼ éï¼å¹¶æ ¹æ®è¯­è¨åè½åç¹å®æéè®¾è®¡åå¹¶ç­ç¥ï¼ä»¥æå»ºå¤è¯­è¨è½åå¢å¼ºç LLMãä¸ºäºè¯ææä»¬æåºçæ¹æ³çæææ§ï¼æä»¬å¨é«èµæºè¯­è¨åä½èµæºè¯­è¨åºæ¯ä¸­å¯¹æ°å­¦åç§å­¦ä»»å¡è¿è¡äºå¹¿æ³çå®éªãå®éªç»æè¡¨æï¼MAET å¯ä»¥ææå°æååè½¬ç§»é«çº§è½åï¼å¹¶ä¸ä¼äºåºäºè®­ç»çåºçº¿æ¹æ³ãæä»¬çä»£ç åæ°æ®å¯å¨ \url{https://github.com/RUCAIBox/MAET} è·å¾ã

##### **Mitigating Gender Bias in Code Large Language Models via Model Editing**
2410.07820v1 by Zhanyue Qin, Haochuan Wang, Zecheng Wang, Deyuan Liu, Cunhang Fan, Zhao Lv, Zhiying Tu, Dianhui Chu, Dianbo Sui

In recent years, with the maturation of large language model (LLM) technology
and the emergence of high-quality programming code datasets, researchers have
become increasingly confident in addressing the challenges of program synthesis
automatically. However, since most of the training samples for LLMs are
unscreened, it is inevitable that LLMs' performance may not align with
real-world scenarios, leading to the presence of social bias. To evaluate and
quantify the gender bias in code LLMs, we propose a dataset named CodeGenBias
(Gender Bias in the Code Generation) and an evaluation metric called FB-Score
(Factual Bias Score) based on the actual gender distribution of correlative
professions. With the help of CodeGenBias and FB-Score, we evaluate and analyze
the gender bias in eight mainstream Code LLMs. Previous work has demonstrated
that model editing methods that perform well in knowledge editing have the
potential to mitigate social bias in LLMs. Therefore, we develop a model
editing approach named MG-Editing (Multi-Granularity model Editing), which
includes the locating and editing phases. Our model editing method MG-Editing
can be applied at five different levels of model parameter granularity: full
parameters level, layer level, module level, row level, and neuron level.
Extensive experiments not only demonstrate that our MG-Editing can effectively
mitigate the gender bias in code LLMs while maintaining their general code
generation capabilities, but also showcase its excellent generalization. At the
same time, the experimental results show that, considering both the gender bias
of the model and its general code generation capability, MG-Editing is most
effective when applied at the row and neuron levels of granularity.

æè¦ï¼<paragraph>è¿å¹´æ¥ï¼éçå¤§è¯­è¨æ¨¡å (LLM) ææ¯çæç
ä»¥åé«è´¨éç¼ç¨ä»£ç æ°æ®éçåºç°ï¼ç ç©¶äººåå¯¹
èªå¨è§£å³ç¨åºåæçææè¶æ¥è¶æä¿¡å¿ãç¶èï¼ç±äº LLM çå¤§å¤æ°è®­ç»æ ·æ¬æ¯
æªç»ç­éçï¼å æ­¤ LLM çæ§è½ä¸å¯é¿åå°å¯è½ä¸
ç°å®ä¸çåºæ¯ä¸ä¸è´ï¼ä»èå¯¼è´ç¤¾ä¼åè§çå­å¨ãä¸ºäºè¯ä¼°å
éåä»£ç  LLM ä¸­çæ§å«åè§ï¼æä»¬æåºäºä¸ä¸ªåä¸º CodeGenBias çæ°æ®é
ï¼ä»£ç çæä¸­çæ§å«åè§ï¼åä¸ä¸ªåºäºç¸å³èä¸çå®éæ§å«åå¸çè¯ä¼°ææ ï¼ç§°ä¸º FB-Score
ï¼äºå®åè§åæ°ï¼ãå¨ CodeGenBias å FB-Score çå¸®å©ä¸ï¼æä»¬è¯ä¼°ååæ
äºå«ä¸ªä¸»æµä»£ç  LLM ä¸­çæ§å«åè§ãä»¥åçå·¥ä½å·²ç»è¯æ
å¨ç¥è¯ç¼è¾ä¸­è¡¨ç°è¯å¥½çæ¨¡åç¼è¾æ¹æ³å·æ
åè½» LLM ä¸­ç¤¾ä¼åè§ãå æ­¤ï¼æä»¬å¼åäºä¸ä¸ªåä¸º MG-Editing çæ¨¡å
ç¼è¾æ¹æ³ï¼å¤ç²åº¦æ¨¡åç¼è¾ï¼ï¼å¶ä¸­åæ¬å®ä½åç¼è¾é¶æ®µãæä»¬çæ¨¡åç¼è¾æ¹æ³ MG-Editing
å¯ä»¥å¨æ¨¡ååæ°ç²åº¦çäºä¸ªä¸åçº§å«ä¸åºç¨ï¼å®æ´
åæ°çº§å«ãå±çº§å«ãæ¨¡åçº§å«ãè¡çº§å«åç¥ç»åçº§å«ã
å¤§éçå®éªä¸ä»è¯æäºæä»¬ç MG-Editing å¯ä»¥ææ
åè½»ä»£ç  LLM ä¸­çæ§å«åè§ï¼åæ¶ä¿æå¶éç¨ä»£ç 
çæè½åï¼ä½ä¹å±ç¤ºäºå¶åºè²çæ³åè½åãåæ¶ï¼å®éªç»æè¡¨æï¼èèæ¨¡åçæ§å«åè§
åå¶éç¨ä»£ç çæè½åï¼MG-Editing å¨è¡åç¥ç»åçº§å«åºç¨æ¶æææ
ç²åº¦ã</paragraph>

##### **Uncovering Overfitting in Large Language Model Editing**
2410.07819v1 by Mengqi Zhang, Xiaotian Ye, Qiang Liu, Pengjie Ren, Shu Wu, Zhumin Chen

Knowledge editing has been proposed as an effective method for updating and
correcting the internal knowledge of Large Language Models (LLMs). However,
existing editing methods often struggle with complex tasks, such as multi-hop
reasoning. In this paper, we identify and investigate the phenomenon of Editing
Overfit, where edited models assign disproportionately high probabilities to
the edit target, hindering the generalization of new knowledge in complex
scenarios. We attribute this issue to the current editing paradigm, which
places excessive emphasis on the direct correspondence between the input prompt
and the edit target for each edit sample. To further explore this issue, we
introduce a new benchmark, EVOKE (EValuation of Editing Overfit in Knowledge
Editing), along with fine-grained evaluation metrics. Through comprehensive
experiments and analysis, we demonstrate that Editing Overfit is prevalent in
current editing methods and that common overfitting mitigation strategies are
of limited effectiveness in knowledge editing. To overcome this, inspired by
LLMs' knowledge recall mechanisms, we propose a new plug-and-play strategy
called Learn to Inference (LTI), which introduce a Multi-stage Inference
Constraint module to guide the edited models in recalling new knowledge
similarly to how unedited LLMs leverage knowledge through in-context learning.
Extensive experimental results across a wide range of tasks validate the
effectiveness of LTI in mitigating Editing Overfit.

æè¦ï¼ç¥è­ç·¨è¼¯å·²è¢«æè­°çºæ´æ°åä¿®æ­£å¤§åèªè¨æ¨¡å (LLM) å§é¨ç¥è­çæææ¹æ³ãç¶èï¼ç¾æçç·¨è¼¯æ¹æ³éå¸¸é£ä»¥èçè¤éçä»»åï¼ä¾å¦å¤è·³æ¨çãå¨æ¬æä¸­ï¼æåæ¾åºä¸¦ç ç©¶ç·¨è¼¯éåº¦æ¬åçç¾è±¡ï¼å¶ä¸­å·²ç·¨è¼¯æ¨¡åæå°ä¸ææ¯ä¾çé«æ©çåéçµ¦ç·¨è¼¯ç®æ¨ï¼é»ç¤è¤éå ´æ¯ä¸­æ°ç¥è­çæ¦åãæåå°æ­¤åé¡æ­¸å æ¼ç®åçç·¨è¼¯ç¯ä¾ï¼è©²ç¯ä¾éåº¦å¼·èª¿è¼¸å¥æç¤ºåæ¯åç·¨è¼¯ç¯ä¾çç·¨è¼¯ç®æ¨ä¹éçç´æ¥å°æéä¿ãçºäºé²ä¸æ­¥æ¢è¨éååé¡ï¼æåå¼å¥äºä¸åæ°çåºæº EVOKEï¼ç¥è­ç·¨è¼¯ä¸­ç·¨è¼¯éåº¦æ¬åçè©ä¼°ï¼ï¼ä»¥åç´°ç²åº¦çè©ä¼°ææ¨ãééå¨é¢çå¯¦é©ååæï¼æåè­æç·¨è¼¯éåº¦æ¬åå¨ç®åçç·¨è¼¯æ¹æ³ä¸­å¾æ®éï¼èå¸¸è¦çéåº¦æ¬åç·©è§£ç­ç¥å¨ç¥è­ç·¨è¼¯ä¸­çæææéãçºäºåæéååé¡ï¼åå° LLM ç¥è­åæº¯æ©å¶çåç¼ï¼æåæåºäºä¸ç¨®æ°çå³æå³ç¨ç­ç¥ï¼ç¨±çºå­¸ç¿æ¨è« (LTI)ï¼å®å¼å¥äºä¸åå¤éæ®µæ¨è«ç´ææ¨¡çµï¼ä»¥å¼å°å·²ç·¨è¼¯çæ¨¡ååæº¯æ°ç¥è­ï¼é¡ä¼¼æ¼æªç·¨è¼¯ç LLM å¦ä½ééæå¢å­¸ç¿ä¾å©ç¨ç¥è­ãå¨åç¨®ä»»åä¸­é²è¡çå»£æ³å¯¦é©çµæé©è­äº LTI å¨ç·©è§£ç·¨è¼¯éåº¦æ¬åæ¹é¢çæææ§ã

##### **Temporal-Difference Variational Continual Learning**
2410.07812v1 by Luckeciano C. Melo, Alessandro Abate, Yarin Gal

A crucial capability of Machine Learning models in real-world applications is
the ability to continuously learn new tasks. This adaptability allows them to
respond to potentially inevitable shifts in the data-generating distribution
over time. However, in Continual Learning (CL) settings, models often struggle
to balance learning new tasks (plasticity) with retaining previous knowledge
(memory stability). Consequently, they are susceptible to Catastrophic
Forgetting, which degrades performance and undermines the reliability of
deployed systems. Variational Continual Learning methods tackle this challenge
by employing a learning objective that recursively updates the posterior
distribution and enforces it to stay close to the latest posterior estimate.
Nonetheless, we argue that these methods may be ineffective due to compounding
approximation errors over successive recursions. To mitigate this, we propose
new learning objectives that integrate the regularization effects of multiple
previous posterior estimations, preventing individual errors from dominating
future posterior updates and compounding over time. We reveal insightful
connections between these objectives and Temporal-Difference methods, a popular
learning mechanism in Reinforcement Learning and Neuroscience. We evaluate the
proposed objectives on challenging versions of popular CL benchmarks,
demonstrating that they outperform standard Variational CL methods and
non-variational baselines, effectively alleviating Catastrophic Forgetting.

æè¦ï¼æ©å¨å­¸ç¿æ¨¡åå¨å¯¦éæç¨ä¸­çä¸é ééµè½åæ¯
æçºå­¸ç¿æ°ä»»åçè½åãéç¨®é©ææ§è®å®åè½å¤ 
é¨èæéæ¨ç§»å°è³æç¢çåä½ä¸­æ½å¨çä¸å¯é¿åçè½è®ååºåæãç¶èï¼å¨æçºå­¸ç¿ (CL) è¨­å®ä¸­ï¼æ¨¡åéå¸¸é£ä»¥å¨å­¸ç¿æ°ä»»åï¼å¯å¡æ§ï¼èä¿çååç¥è­ï¼è¨æ¶ç©©å®æ§ï¼ä¹éåå¾å¹³è¡¡ãå æ­¤ï¼å®åå®¹æç¼çç½é£æ§éºå¿ï¼éæéä½æè½ä¸¦æå®³å·²é¨ç½²ç³»çµ±çå¯é æ§ãè®ç°æçºå­¸ç¿æ¹æ³ééæ¡ç¨å­¸ç¿ç®æ¨ä¾æå°éåææ°ï¼è©²ç®æ¨æéè¿´æ´æ°å¾é©åä½ä¸¦å¼·å¶å¶ç¶­æå¨ææ°çå¾é©ä¼°è¨å¼éè¿ãåç®¡å¦æ­¤ï¼æåèªçºéäºæ¹æ³å¯è½å é£çºéè¿´çè¿ä¼¼èª¤å·®èç¡æãçºäºæ¸è¼éååé¡ï¼æåæåºæ°çå­¸ç¿ç®æ¨ï¼çµåå¤åååå¾é©ä¼°è¨å¼çæ­£ååææï¼é²æ­¢åå¥èª¤å·®ä¸»å°æªä¾çå¾é©æ´æ°ä¸¦é¨èæéæ¨ç§»èç´¯ç©ãæåæ­ç¤ºäºéäºç®æ¨èæåºå·®åæ¹æ³ä¹éçæ·±å¥éè¯ï¼æåºå·®åæ¹æ³æ¯å¼·åå­¸ç¿åç¥ç¶ç§å­¸ä¸­ä¸ç¨®æµè¡çå­¸ç¿æ©å¶ãæåå¨ç±é CL åºæºçææ°çæ¬ä¸è©ä¼°ææåºçç®æ¨ï¼è­æå®ååªæ¼æ¨æºçè®ç° CL æ¹æ³åéè®ç°åºæºï¼ææå°æ¸è¼äºç½é£æ§éºå¿ã

##### **Linguistically-Informed Multilingual Instruction Tuning: Is There an Optimal Set of Languages to Tune?**
2410.07809v1 by GÃ¼rkan Soykan, GÃ¶zde GÃ¼l Åahin

Multilingual language models often perform unevenly across different
languages due to limited generalization capabilities for some languages. This
issue is significant because of the growing interest in making universal
language models that work well for all languages. Instruction tuning with
multilingual instruction-response pairs has been used to improve model
performance across various languages. However, this approach is challenged by
high computational costs, a lack of quality tuning data for all languages, and
the "curse of multilinguality" -- the performance drop per language after
adding many languages. Recent studies have found that working with datasets
with few languages and a smaller number of instances can be beneficial. Yet,
there exists no systematic investigation into how choosing different languages
affects multilingual instruction tuning. Our study proposes a method to select
languages for instruction tuning in a linguistically informed way, aiming to
boost model performance across languages and tasks. We use a simple algorithm
to choose diverse languages and test their effectiveness on various benchmarks
and open-ended questions. Our results show that this careful selection
generally leads to better outcomes than choosing languages at random. We
suggest a new and simple way of enhancing multilingual models by selecting
diverse languages based on linguistic features that could help develop better
multilingual systems and guide dataset creation efforts. All resources,
including the code for language selection and multilingual instruction tuning,
are made available in our official repository at
https://github.com/GGLAB-KU/ling-informed-mit enabling reproducibility and
further research in this area.

æè¦ï¼å¤èªè¨èªè¨æ¨¡åéå¸¸å¨ä¸åèªè¨ä¹éè¡¨ç¾ä¸åï¼éæ¯å çºæäºèªè¨çæ¦æ¬è½åæéãéååé¡å¾éè¦ï¼å çºäººåè¶ä¾è¶æèè¶£å»ºç«å°ææèªè¨é½ææçéç¨èªè¨æ¨¡åãééå¤èªè¨æä»¤åæéå°é²è¡æä»¤èª¿æ´ï¼å·²ç¨æ¼æ¹ååç¨®èªè¨çæ¨¡åæè½ãç¶èï¼éåæ¹æ³åå°é«éç®ææ¬ãç¼ºä¹ææèªè¨çåè³ªèª¿æ´è³æï¼ä»¥åãå¤èªè¨çè©åãçææ°ï¼ä¹å°±æ¯å¨å å¥è¨±å¤èªè¨å¾ï¼æ¯åèªè¨çæè½é½æä¸éãæè¿çç ç©¶ç¼ç¾ï¼ä½¿ç¨èªè¨è¼å°ä¸å¯¦ä¾æ¸éè¼å°çè³æéæå¾æå¹«å©ãç¶èï¼ç®åå°æªç³»çµ±æ§å°æ¢è¨é¸æä¸åèªè¨å¦ä½å½±é¿å¤èªè¨æä»¤èª¿æ´ãæåçç ç©¶æåºäºä¸ç¨®æ¹æ³ä¾ä»¥èªè¨å­¸çºåºç¤çæ¹å¼é¸ææä»¤èª¿æ´çèªè¨ï¼ç®çæ¯æåè·¨èªè¨åä»»åçæ¨¡åæè½ãæåä½¿ç¨ä¸åç°¡å®çæ¼ç®æ³ä¾é¸æä¸åçèªè¨ï¼ä¸¦å¨åç¨®åºæºåéæ¾å¼åé¡ä¸æ¸¬è©¦å¶æææ§ãæåççµæé¡¯ç¤ºï¼éç¨®ä»ç´°çé¸æéå¸¸ææ¯é¨æ©é¸æèªè¨å¸¶ä¾æ´å¥½çææãæåå»ºè­°ä¸ç¨®æ°ä¸ç°¡å®çæ¹æ³ï¼ééæ ¹æèªè¨ç¹å¾µé¸æä¸åçèªè¨ä¾å¢å¼·å¤èªè¨æ¨¡åï¼éæå©æ¼éç¼æ´å¥½çå¤èªè¨ç³»çµ±ï¼ä¸¦å¼å°è³æéå»ºç«å·¥ä½ãææè³æºï¼åæ¬èªè¨é¸æåå¤èªè¨æä»¤èª¿æ´çç¨å¼ç¢¼ï¼é½å¯ä»¥å¨æåçå®æ¹å­æ¾åº«ä¸­åå¾ï¼https://github.com/GGLAB-KU/ling-informed-mitï¼ä»¥å©æ¼åç¾æ§ï¼ä¸¦é²ä¸æ­¥ç ç©¶éåé åã

##### **Rewriting Conversational Utterances with Instructed Large Language Models**
2410.07797v1 by Elnara Galimzhanova, Cristina Ioana Muntean, Franco Maria Nardini, Raffaele Perego, Guido Rocchietti

Many recent studies have shown the ability of large language models (LLMs) to
achieve state-of-the-art performance on many NLP tasks, such as question
answering, text summarization, coding, and translation. In some cases, the
results provided by LLMs are on par with those of human experts. These models'
most disruptive innovation is their ability to perform tasks via zero-shot or
few-shot prompting. This capability has been successfully exploited to train
instructed LLMs, where reinforcement learning with human feedback is used to
guide the model to follow the user's requests directly. In this paper, we
investigate the ability of instructed LLMs to improve conversational search
effectiveness by rewriting user questions in a conversational setting. We study
which prompts provide the most informative rewritten utterances that lead to
the best retrieval performance. Reproducible experiments are conducted on
publicly-available TREC CAST datasets. The results show that rewriting
conversational utterances with instructed LLMs achieves significant
improvements of up to 25.2% in MRR, 31.7% in Precision@1, 27% in NDCG@3, and
11.5% in Recall@500 over state-of-the-art techniques.

æè¦ï¼è¨±å¤æè¿çç ç©¶é¡¯ç¤ºï¼å¤§åèªè¨æ¨¡å (LLM) å¨è¨±å¤ NLP ä»»åä¸å±ç¾åºæåé²çæè½ï¼ä¾å¦åç­ãæå­æè¦ãç·¨ç¢¼åç¿»è­¯ãå¨æäºææ³ä¸ï¼LLM æä¾ççµæèäººé¡å°å®¶ççµæä¸ç¸ä¸ä¸ãéäºæ¨¡åæå·ç ´å£æ§çåµæ°æ¯å®åè½å¤ ééé¶æ¬¡å­¸ç¿æå°æ¬¡å­¸ç¿æç¤ºä¾å·è¡ä»»åãéç¨®è½åå·²æåç¨æ¼è¨ç·´æç¤ºå¼ LLMï¼å¶ä¸­ä½¿ç¨å·æäººé¡åé¥çå¼·åå­¸ç¿ä¾å¼å°æ¨¡åç´æ¥éµå¾ªä½¿ç¨èçè«æ±ãå¨æ¬æä¸­ï¼æåæ¢è¨æç¤ºå¼ LLM å¨å°è©±å¼è¨­å®ä¸­æ¹å¯«ä½¿ç¨èåé¡ï¼ä»¥æåå°è©±å¼æå°æè½çè½åãæåç ç©¶åªäºæç¤ºæä¾äºæå¤è³è¨çæ¹å¯«èªå¥ï¼éäºèªå¥å¯å¸¶ä¾æä½³çæª¢ç´¢æè½ãå¯å¨å¬éç TREC CAST è³æéä¸é²è¡å¯è¤è£½çå¯¦é©ãçµæé¡¯ç¤ºï¼ä½¿ç¨æç¤ºå¼ LLM æ¹å¯«å°è©±å¼èªå¥ï¼å¨ MRR æ¹é¢ç²å¾é«é 25.2% çé¡¯èæåï¼å¨ Precision@1 æ¹é¢ç²å¾ 31.7% çæåï¼å¨ NDCG@3 æ¹é¢ç²å¾ 27% çæåï¼å¨ Recall@500 æ¹é¢ç²å¾ 11.5% çæåï¼åªæ¼æåé²çæè¡ã

##### **Do Current Language Models Support Code Intelligence for R Programming Language?**
2410.07793v1 by ZiXiao Zhao, Fatemeh H. Fard

Recent advancements in developing Pre-trained Language Models for Code
(Code-PLMs) have urged many areas of Software Engineering (SE) and brought
breakthrough results for many SE tasks. Though these models have achieved the
state-of-the-art performance for SE tasks for many popular programming
languages, such as Java and Python, the Scientific Software and its related
languages like R programming language have rarely benefited or even been
evaluated with the Code-PLMs. Research has shown that R has many differences
with other programming languages and requires specific techniques. In this
study, we provide the first insights for code intelligence for R. For this
purpose, we collect and open source an R dataset, and evaluate Code-PLMs for
the two tasks of code summarization and method name prediction using several
settings and strategies, including the differences in two R styles, Tidy-verse
and Base R. Our results demonstrate that the studied models have experienced
varying degrees of performance degradation when processing R programming
language code, which is supported by human evaluation. Additionally, not all
models show performance improvement in R-specific tasks even after
multi-language fine-tuning. The dual syntax paradigms in R significantly impact
the models' performance, particularly in code summarization tasks. Furthermore,
the project-specific context inherent in R codebases significantly impacts the
performance when attempting cross-project training.

æè¦ï¼æè¿å¨éç¼ç¨å¼ç¢¼é è¨ç·´èªè¨æ¨¡å (Code-PLM) æ¹é¢åå¾çé²å±ï¼å·²ä¿ä½¿è»é«å·¥ç¨ (SE) çè¨±å¤é åï¼ä¸¦çºè¨±å¤ SE ä»»åå¸¶ä¾çªç ´æ§çææãåç®¡éäºæ¨¡åå·²éå°è¨±å¤ç±éç¨å¼èªè¨ï¼ä¾å¦ Java å Pythonï¼ç SE ä»»åéå°äºæåé²çæè½ï¼ä½ç§å­¸è»é«åå¶ç¸éèªè¨ï¼ä¾å¦ R ç¨å¼èªè¨ï¼å¾å°åçï¼çè³å¾å°ä½¿ç¨ Code-PLM é²è¡è©ä¼°ãç ç©¶è¡¨æï¼R èå¶ä»ç¨å¼èªè¨æè¨±å¤ä¸åä¹èï¼éè¦ç¹å®çæè¡ãå¨éé ç ç©¶ä¸­ï¼æåæä¾äº R çç¨å¼ç¢¼æºæ§çç¬¬ä¸åè¦è§£ãçºæ­¤ï¼æåæ¶éä¸¦éæ¾åå§ç¢¼ R è³æéï¼ä¸¦ä½¿ç¨å¤ç¨®è¨­å®åç­ç¥ï¼åæ¬å©ç¨® R é¢¨æ ¼çå·®ç°ï¼Tidy-verse å Base Rï¼ä¾è©ä¼° Code-PLM çç¨å¼ç¢¼æè¦åæ¹æ³åç¨±é æ¸¬éå©åä»»åãæåççµæè¡¨æï¼å¨èç R ç¨å¼èªè¨ç¨å¼ç¢¼æï¼æç ç©¶çæ¨¡åç¶æ­·äºä¸åç¨åº¦çæè½ä¸éï¼éå¾å°äºäººå·¥è©ä¼°çæ¯æ´ãæ­¤å¤ï¼å³ä½¿å¨å¤èªè¨å¾®èª¿ä¹å¾ï¼ä¸¦éæææ¨¡åå¨ R ç¹å®ä»»åä¸­é½é¡¯ç¤ºåºæè½æåãR ä¸­çééèªæ³ç¯ä¾é¡¯èå½±é¿æ¨¡åçæè½ï¼ç¹å¥æ¯å¨ç¨å¼ç¢¼æè¦ä»»åä¸­ãæ­¤å¤ï¼R ç¨å¼ç¢¼åº«ä¸­åºæçå°æ¡ç¹å®å§å®¹ï¼å¨åè©¦è·¨å°æ¡è¨ç·´æï¼æé¡¯èå½±é¿æè½ã

##### **Modeling User Preferences with Automatic Metrics: Creating a High-Quality Preference Dataset for Machine Translation**
2410.07779v1 by Sweta Agrawal, JosÃ© G. C. de Souza, Ricardo Rei, AntÃ³nio Farinhas, GonÃ§alo Faria, Patrick Fernandes, Nuno M Guerreiro, Andre Martins

Alignment with human preferences is an important step in developing accurate
and safe large language models. This is no exception in machine translation
(MT), where better handling of language nuances and context-specific variations
leads to improved quality. However, preference data based on human feedback can
be very expensive to obtain and curate at a large scale. Automatic metrics, on
the other hand, can induce preferences, but they might not match human
expectations perfectly. In this paper, we propose an approach that leverages
the best of both worlds. We first collect sentence-level quality assessments
from professional linguists on translations generated by multiple high-quality
MT systems and evaluate the ability of current automatic metrics to recover
these preferences. We then use this analysis to curate a new dataset, MT-Pref
(metric induced translation preference) dataset, which comprises 18k instances
covering 18 language directions, using texts sourced from multiple domains
post-2022. We show that aligning TOWER models on MT-Pref significantly improves
translation quality on WMT23 and FLORES benchmarks.

æè¦ï¼èäººé¡åå¥½ä¸è´æ¯éç¼æºç¢ºä¸å®å¨çå·¨éèªè¨æ¨¡åçéè¦æ­¥é©ãæ©å¨ç¿»è­¯ (MT) ä¹ä¸ä¾å¤ï¼å¶ä¸­å°èªè¨å·®ç°ç´°å¾®å·®å¥åç¹å®æ¼èçµ¡çè®åçæ´å¥½èçææååè³ªãç¶èï¼åºæ¼äººé¡åé¥çåå¥½è³æå¨åå¾åæ´çä¸å¯è½éå¸¸æè²´ãå¦ä¸æ¹é¢ï¼èªååææ¨å¯ä»¥èªç¼åå¥½ï¼ä½å®åå¯è½ç¡æ³å®ç¾ç¬¦åäººé¡çææãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®çµåå©å¨å¶ç¾çåæ³ãæåé¦åå¾å°æ¥­èªè¨å­¸å®¶æ¶éç±å¤åé«åè³ª MT ç³»çµ±ç¢ççç¿»è­¯çå¥å­å±¤ç´åè³ªè©ä¼°ï¼ä¸¦è©ä¼°ç¶åèªååææ¨æ¢å¾©éäºåå¥½çè½åãç¶å¾ï¼æåä½¿ç¨æ­¤åææ´çä¸åæ°çè³æé MT-Prefï¼ææ¨èªç¼çç¿»è­¯åå¥½ï¼è³æéï¼å¶ä¸­åå« 18k åå¯¦ä¾ï¼æ¶µè 18 ç¨®èªè¨æ¹åï¼ä½¿ç¨ä¾èª 2022 å¹´ä¹å¾å¤åç¶²åçæå­ãæåå±ç¤ºäºå¨ MT-Pref ä¸èª¿æ´ TOWER æ¨¡åæå¨ WMT23 å FLORES åºæºä¸é¡¯èæåç¿»è­¯åè³ªã

##### **Full-Rank No More: Low-Rank Weight Training for Modern Speech Recognition Models**
2410.07771v1 by Adriana Fernandez-Lopez, Shiwei Liu, Lu Yin, Stavros Petridis, Maja Pantic

This paper investigates the under-explored area of low-rank weight training
for large-scale Conformer-based speech recognition models from scratch. Our
study demonstrates the viability of this training paradigm for such models,
yielding several notable findings. Firstly, we discover that applying a
low-rank structure exclusively to the attention modules can unexpectedly
enhance performance, even with a significant rank reduction of 12%. In
contrast, feed-forward layers present greater challenges, as they begin to
exhibit performance degradation with a moderate 50% rank reduction.
Furthermore, we find that both initialization and layer-wise rank assignment
play critical roles in successful low-rank training. Specifically, employing
SVD initialization and linear layer-wise rank mapping significantly boosts the
efficacy of low-rank weight training. Building on these insights, we introduce
the Low-Rank Speech Model from Scratch (LR-SMS), an approach that achieves
performance parity with full-rank training while delivering substantial
reductions in parameters count (by at least 2x), and training time speedups (by
1.3x for ASR and 1.15x for AVSR).

æè¦ï¼æ¬ææ¢è¨äºå¾é ­éå§è¨ç·´å¤§ååºæ¼ Conformer çèªé³è­å¥æ¨¡åçä½ç§©æ¬éè¨ç·´éåå°æªååæ¢ç´¢çé åãæåçç ç©¶è­æäºéç¨®è¨ç·´ç¯ä¾å°æ­¤é¡æ¨¡åçå¯è¡æ§ï¼ä¸¦ç¢çäºå¹¾é å¼å¾æ³¨æçç¼ç¾ãé¦åï¼æåç¼ç¾åå°ä½ç§©çµæ§æç¨æ¼æ³¨æåæ¨¡çµå°±è½æå¤å°æåæè½ï¼å³ä½¿ç§©å¤§å¹éä½äº 12%ãç¸æ¯ä¹ä¸ï¼åé¥å±¤æå¸¶ä¾æ´å¤§çææ°ï¼å çºå®åæå¨ç§©é©åº¦éä½ 50% çææ³ä¸éå§è¡¨ç¾åºæè½ä¸éãæ­¤å¤ï¼æåç¼ç¾åå§ååéå±¤ç§©ææ´¾å¨ä½ç§©è¨ç·´çæåä¸­é½æ®æ¼èééµè§è²ãå·é«ä¾èªªï¼æ¡ç¨ SVD åå§ååç·æ§éå±¤ç§©å°ææé¡¯èæåä½ç§©æ¬éè¨ç·´çæè½ãåºæ¼éäºè¦è§£ï¼æåå¼å¥äºå¾é ­éå§è¨ç·´çä½ç§©èªé³æ¨¡å (LR-SMS)ï¼éæ¯ä¸ç¨®æ¹æ³ï¼å¯ä»¥å¨åæ¸æ¸éå¤§å¹æ¸å°ï¼è³å° 2 åï¼åè¨ç·´æéå å¿«ï¼ASR çº 1.3 åï¼AVSR çº 1.15 åï¼çææ³ä¸ï¼éå°èå¨ç§©è¨ç·´ç¸ç¶çæè½ã

##### **Dialectical Behavior Therapy Approach to LLM Prompting**
2410.07768v1 by Oxana Vitman, Nika Amaglobeli, Paul Plachinda

Large language models demonstrated state-of-the-art results on various
reasoning tasks when applying the chain-of-thought (CoT) prompting technique.
CoT prompting guides the model into breaking tasks into a few intermediate
steps and provides step-by-step demonstrations. However, solving complex
reasoning tasks remains a challenge. In this paper, we propose a novel
prompting strategy inspired by Dialectical Behavioral Therapy (DBT). DBT, a
form of cognitive-behavioral therapy, aims to help individuals cope with stress
by developing a system of reasoning. We applied DBT's basic concepts of shaping
dialog to construct prompts and conducted experiments on different datasets and
LLMs with various numbers of parameters. Our results show that prompts crafted
with DBT techniques significantly improve results on smaller models, achieving
a 7% increase in accuracy on the StrategyQA, 4.8% on Aqua dataset using 8b
parameters model, and a 16.2% increase on the StrategyQA, 5.3% on GSM8K dataset
with 14b parameters model.

æè¦ï¼å¤§åè¯­è¨æ¨¡åå¨åºç¨æç»´é¾ï¼CoTï¼æç¤ºææ¯æ¶ï¼å¨åç§æ¨çä»»å¡ä¸­å±ç¤ºäºæåè¿çç»æãCoT æç¤ºå¼å¯¼æ¨¡åå°ä»»å¡åè§£ä¸ºå ä¸ªä¸­é´æ­¥éª¤ï¼å¹¶æä¾éæ­¥æ¼ç¤ºãç¶èï¼è§£å³å¤æçæ¨çä»»å¡ä»ç¶æ¯ä¸ä¸ªææãå¨æ¬æä¸­ï¼æä»¬æåºäºä¸ç§åè¾©è¯è¡ä¸ºçæ³ (DBT) å¯åçå¨æ°æç¤ºç­ç¥ãDBT æ¯ä¸ç§è®¤ç¥è¡ä¸ºçæ³ï¼æ¨å¨éè¿å»ºç«æ¨çç³»ç»æ¥å¸®å©ä¸ªäººåºå¯¹ååãæä»¬åºç¨äº DBT å¡é å¯¹è¯çåºæ¬æ¦å¿µæ¥æå»ºæç¤ºï¼å¹¶å¨ä¸åçæ°æ®éåå·æä¸åæ°éåæ°ç LLM ä¸è¿è¡äºå®éªãæä»¬çç»æè¡¨æï¼ä½¿ç¨ DBT ææ¯ç²¾å¿è®¾è®¡çæç¤ºå¯ä»¥æ¾çæé«è¾å°æ¨¡åçç»æï¼å¨ StrategyQA ä¸åç¡®çæé«äº 7%ï¼å¨ä½¿ç¨ 8b åæ°æ¨¡åç Aqua æ°æ®éä¸æé«äº 4.8%ï¼å¨ StrategyQA ä¸æé«äº 16.2%ï¼å¨ä½¿ç¨ 14b åæ°æ¨¡åç GSM8K æ°æ®éä¸æé«äº 5.3%ã

##### **GameTraversalBenchmark: Evaluating Planning Abilities Of Large Language Models Through Traversing 2D Game Maps**
2410.07765v1 by Muhammad Umair Nasir, Steven James, Julian Togelius

Large language models (LLMs) have recently demonstrated great success in
generating and understanding natural language. While they have also shown
potential beyond the domain of natural language, it remains an open question as
to what extent and in which way these LLMs can plan. We investigate their
planning capabilities by proposing GameTraversalBenchmark (GTB), a benchmark
consisting of diverse 2D grid-based game maps. An LLM succeeds if it can
traverse through given objectives, with a minimum number of steps and a minimum
number of generation errors. We evaluate a number of LLMs on GTB and found that
GPT-4-Turbo achieved the highest score of 44.97% on GTB\_Score (GTBS), a
composite score that combines the three above criteria. Furthermore, we
preliminarily test large reasoning models, namely o1, which scores $67.84\%$ on
GTBS, indicating that the benchmark remains challenging for current models.
Code, data, and documentation are available at
https://github.com/umair-nasir14/Game-Traversal-Benchmark.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) æè¿å¨çæåçè§£èªç¶èªè¨æ¹é¢åå¾äºå·¨å¤§çæåãåç®¡å®åä¹å±ç¾äºè¶è¶èªç¶èªè¨é åçæ½åï¼ä½éäº LLM è½å¨å¤å¤§ç¨åº¦ä¸ä»¥åä»¥ä½ç¨®æ¹å¼é²è¡è¦åï¼ä»ç¶æ¯ä¸åéæ¾æ§çåé¡ãæåééæåº GameTraversalBenchmark (GTB) ä¾æ¢è¨å®åçè¦åè½åï¼GTB æ¯ç±å¤ç¨® 2D ç¶²æ ¼åéæ²å°åçµæçåºæºãå¦æ LLM è½ä»¥æå°çæ­¥é©æ¸åæå°ççæé¯èª¤ï¼ç©¿éçµ¦å®çç®æ¨ï¼åè¡¨ç¤ºå®æåäºãæåå¨ GTB ä¸è©ä¼°äºå¤å LLMï¼ç¼ç¾ GPT-4-Turbo å¨ GTB\_Score (GTBS) ä¸åå¾äº 44.97% çæé«åï¼GTBS æ¯çµåä¸è¿°ä¸åæ¨æºçç¶ååæ¸ãæ­¤å¤ï¼æååæ­¥æ¸¬è©¦äºå¤§åæ¨çæ¨¡åï¼å³ o1ï¼å®å¨ GTBS ä¸çå¾åçº 67.84%ï¼éè¡¨ç¤ºè©²åºæºå°æ¼ç®åçæ¨¡åä¾èªªä»ç¶å·æææ°æ§ãå¯ä»¥å¨ https://github.com/umair-nasir14/Game-Traversal-Benchmark æ¾å°ç¨å¼ç¢¼ãè³æåæä»¶ã

##### **HARIVO: Harnessing Text-to-Image Models for Video Generation**
2410.07763v1 by Mingi Kwon, Seoung Wug Oh, Yang Zhou, Difan Liu, Joon-Young Lee, Haoran Cai, Baqiao Liu, Feng Liu, Youngjung Uh

We present a method to create diffusion-based video models from pretrained
Text-to-Image (T2I) models. Recently, AnimateDiff proposed freezing the T2I
model while only training temporal layers. We advance this method by proposing
a unique architecture, incorporating a mapping network and frame-wise tokens,
tailored for video generation while maintaining the diversity and creativity of
the original T2I model. Key innovations include novel loss functions for
temporal smoothness and a mitigating gradient sampling technique, ensuring
realistic and temporally consistent video generation despite limited public
video data. We have successfully integrated video-specific inductive biases
into the architecture and loss functions. Our method, built on the frozen
StableDiffusion model, simplifies training processes and allows for seamless
integration with off-the-shelf models like ControlNet and DreamBooth. project
page: https://kwonminki.github.io/HARIVO

æè¦ï¼æåæåºä¸åæ¹æ³ï¼å¯ä»¥å¾é è¨ç·´çæå­è½åå (T2I) æ¨¡åä¸­å»ºç«åºæ¼æ´æ£çå½±çæ¨¡åãæè¿ï¼AnimateDiff æè­°åçµ T2I æ¨¡åï¼åæåè¨ç·´æéå±¤ãæåééæåºä¸åç¨ç¹çæ¶æ§ä¾æ¨é²æ­¤æ¹æ³ï¼çµåä¸åå°æç¶²è·¯åéå¹ä»£å¹£ï¼å°éç¨æ¼å½±ççæï¼åæç¶­æåå§ T2I æ¨¡åçå¤æ¨£æ§ååµé åãééµåµæ°åæ¬æéå¹³æ»åº¦çæ°æå¤±å½æ¸åç·©è§£æ¢¯åº¦åæ¨£æè¡ï¼ç¢ºä¿é¼çä¸æéä¸è´çå½±ççæï¼åç®¡åéæ¼å¬éå½±çè³æãæåå·²æåå°å½±çç¹å®çæ­¸ç´åå·®æ´åå°æ¶æ§åæå¤±å½æ¸ä¸­ãæåçæ¨¡åå»ºç«å¨åçµç StableDiffusion æ¨¡åä¸ï¼ç°¡åäºè¨ç·´æµç¨ï¼ä¸¦åè¨±è ControlNet å DreamBooth ç­ç¾ææ¨¡åç¡ç¸«æ´åãå°æ¡é é¢ï¼https://kwonminki.github.io/HARIVO

##### **$\textit{Jump Your Steps}$: Optimizing Sampling Schedule of Discrete Diffusion Models**
2410.07761v1 by Yong-Hyun Park, Chieh-Hsin Lai, Satoshi Hayakawa, Yuhta Takida, Yuki Mitsufuji

Diffusion models have seen notable success in continuous domains, leading to
the development of discrete diffusion models (DDMs) for discrete variables.
Despite recent advances, DDMs face the challenge of slow sampling speeds. While
parallel sampling methods like $\tau$-leaping accelerate this process, they
introduce $\textit{Compounding Decoding Error}$ (CDE), where discrepancies
arise between the true distribution and the approximation from parallel token
generation, leading to degraded sample quality. In this work, we present
$\textit{Jump Your Steps}$ (JYS), a novel approach that optimizes the
allocation of discrete sampling timesteps by minimizing CDE without extra
computational cost. More precisely, we derive a practical upper bound on CDE
and propose an efficient algorithm for searching for the optimal sampling
schedule. Extensive experiments across image, music, and text generation show
that JYS significantly improves sampling quality, establishing it as a
versatile framework for enhancing DDM performance for fast sampling.

æè¦ï¼æ´æ£æ¨¡åå¨é£çºåä¸­å·²ç²å¾é¡¯èçæåï¼é²èä¿æäºé¢æ£è®æ¸çé¢æ£æ´æ£æ¨¡å (DDM) çç¼å±ãåç®¡æè¿æçé²å±ï¼DDM é¢è¨èåæ¨£éåº¦ç·©æ¢çææ°ãéç¶å $\tau$-èºé·ç­ä¸¦è¡åæ¨£æ¹æ³å éäºéåéç¨ï¼ä½å®åå¼å¥äº$\textit{è¤åè§£ç¢¼èª¤å·®}$ (CDE)ï¼å¶ä¸­çå¯¦åä½èä¸¦è¡ç¬¦èç¢ççè¿ä¼¼å¼ä¹éåºç¾å·®ç°ï¼å°è´æ¨£æ¬åè³ªä¸éãå¨éé å·¥ä½ä¸­ï¼æåæåºäº$\textit{è·³èºä½ çæ­¥é©}$ (JYS)ï¼éæ¯ä¸ç¨®æ°æ¹æ³ï¼ééæå°å CDE ä¾æä½³åé¢æ£åæ¨£æéæ­¥é·çéç½®ï¼èç¡éé¡å¤çéç®ææ¬ãæ´ç²¾ç¢ºå°èªªï¼æåæ¨å°åº CDE çå¯¦ç¨ä¸éï¼ä¸¦æåºäºä¸ç¨®ç¨æ¼æå°æä½³åæ¨£æç¨çæææ¼ç®æ³ãè·¨è¶å½±åãé³æ¨åæå­çæçå»£æ³å¯¦é©é¡¯ç¤ºï¼JYS å¤§å¹æ¹åäºåæ¨£åè³ªï¼ç¢ºç«äºå®ä½çºä¸åéç¨çæ¡æ¶ï¼ç¨æ¼å¢å¼· DDM æè½ä»¥é²è¡å¿«éåæ¨£ã

##### **Learning Low-Level Causal Relations using a Simulated Robotic Arm**
2410.07751v1 by Miroslav Cibula, Matthias Kerzel, Igor FarkaÅ¡

Causal learning allows humans to predict the effect of their actions on the
known environment and use this knowledge to plan the execution of more complex
actions. Such knowledge also captures the behaviour of the environment and can
be used for its analysis and the reasoning behind the behaviour. This type of
knowledge is also crucial in the design of intelligent robotic systems with
common sense. In this paper, we study causal relations by learning the forward
and inverse models based on data generated by a simulated robotic arm involved
in two sensorimotor tasks. As a next step, we investigate feature attribution
methods for the analysis of the forward model, which reveals the low-level
causal effects corresponding to individual features of the state vector related
to both the arm joints and the environment features. This type of analysis
provides solid ground for dimensionality reduction of the state
representations, as well as for the aggregation of knowledge towards the
explainability of causal effects at higher levels.

æè¦ï¼å æå­¸ç¿è®äººåè½å¤ é æ¸¬å¶è¡çºå°å·²ç¥ç°å¢çå½±é¿ï¼ä¸¦å©ç¨æ­¤ç¥è­ä¾è¦åå·è¡æ´è¤éçè¡çºãæ­¤é¡ç¥è­ä¹ææç°å¢çè¡çºï¼å¯ä¾å¶åæåè¡çºèå¾çæ¨çä½¿ç¨ãæ­¤é¡åçç¥è­å¨å·åå¸¸è­çæºæ§åæ©å¨äººç³»çµ±è¨­è¨ä¸­ä¹è³ééè¦ãå¨æ¬æä¸­ï¼æåééå­¸ç¿åºæ¼æ¨¡æ¬æ©å¨æèåèå©é ææ¸¬éåä»»åæç¢çè³æçæ­£ååååæ¨¡åä¾ç ç©¶å æéä¿ãä½çºä¸ä¸æ­¥ï¼æåèª¿æ¥æ­£åæ¨¡ååæçåè½å±¬æ§æ¹æ³ï¼æ­ç¤ºèæèéç¯åç°å¢ç¹å¾µç¸éççæåéçåå¥ç¹å¾µå°æçä½éå æææãæ­¤é¡åçåæçºçæè¡¨ç¤ºçç¶­åº¦ç¸®æ¸æä¾äºå å¯¦çåºç¤ï¼ä¸¦çºæ´é«å±¤ç´å æææçå¯è§£éæ§å½æ´ç¥è­ã

##### **StepTool: A Step-grained Reinforcement Learning Framework for Tool Learning in LLMs**
2410.07745v1 by Yuanqing Yu, Zhefan Wang, Weizhi Ma, Zhicheng Guo, Jingtao Zhan, Shuai Wang, Chuhan Wu, Zhiqiang Guo, Min Zhang

Despite having powerful reasoning and inference capabilities, Large Language
Models (LLMs) still need external tools to acquire real-time information
retrieval or domain-specific expertise to solve complex tasks, which is
referred to as tool learning. Existing tool learning methods primarily rely on
tuning with expert trajectories, focusing on token-sequence learning from a
linguistic perspective. However, there are several challenges: 1) imitating
static trajectories limits their ability to generalize to new tasks. 2) even
expert trajectories can be suboptimal, and better solution paths may exist. In
this work, we introduce StepTool, a novel step-grained reinforcement learning
framework to improve tool learning in LLMs. It consists of two components:
Step-grained Reward Shaping, which assigns rewards at each tool interaction
based on tool invocation success and its contribution to the task, and
Step-grained Optimization, which uses policy gradient methods to optimize the
model in a multi-step manner. Experimental results demonstrate that StepTool
significantly outperforms existing methods in multi-step, tool-based tasks,
providing a robust solution for complex task environments. Codes are available
at https://github.com/yuyq18/StepTool.

æè¦ï¼åç®¡å¤§åèªè¨æ¨¡å (LLM) ææå¼·å¤§çæ¨çåæ¨è«è½åï¼ä½ä»éè¦å¤é¨å·¥å·ä¾ç²åå³æè³è¨æª¢ç´¢æç¹å®é åçå°æ¥­ç¥è­ï¼ä»¥è§£æ±ºè¤éä»»åï¼éè¢«ç¨±çºå·¥å·å­¸ç¿ãç¾æçå·¥å·å­¸ç¿æ¹æ³ä¸»è¦ä¾è³´æ¼å°å®¶è»è·¡çèª¿æ´ï¼å°æ³¨æ¼å¾èªè¨å­¸çè§åº¦é²è¡ä»¤çåºåå­¸ç¿ãç¶èï¼æå¹¾åææ°ï¼1) æ¨¡ä»¿éæè»è·¡éå¶äºå®åæ³åå°æ°ä»»åçè½åã2) å³ä½¿æ¯å°å®¶è»è·¡ä¹å¯è½ä¸æ¯æä½³çï¼ä¸¦ä¸å¯è½å­å¨æ´å¥½çè§£æ±ºæ¹æ¡è·¯å¾ãå¨éé å·¥ä½ä¸­ï¼æåä»ç´¹äº StepToolï¼éæ¯ä¸åæ°ç©çæ­¥é©åå¼·åå­¸ç¿æ¡æ¶ï¼ç¨æ¼æ¹é² LLM ä¸­çå·¥å·å­¸ç¿ãå®åå«å©åçµæé¨åï¼æ­¥é©åçåµèª¿æ´ï¼å®æ ¹æå·¥å·èª¿ç¨æååå¶å°ä»»åçè²¢ç»å¨æ¯æ¬¡å·¥å·äºåæåéçåµï¼ä»¥åæ­¥é©åæä½³åï¼å®ä½¿ç¨ç­ç¥æ¢¯åº¦æ¹æ³ä»¥å¤æ­¥é©çæ¹å¼æä½³åæ¨¡åãå¯¦é©çµæè¡¨æï¼StepTool å¨åºæ¼å·¥å·çå¤æ­¥é©ä»»åä¸­é¡¯èåªæ¼ç¾ææ¹æ³ï¼çºè¤éä»»åç°å¢æä¾äºä¸åç©©å¥çè§£æ±ºæ¹æ¡ãç¨å¼ç¢¼å¯å¨ https://github.com/yuyq18/StepTool ç²å¾ã

##### **SLIM: Let LLM Learn More and Forget Less with Soft LoRA and Identity Mixture**
2410.07739v1 by Jiayi Han, Liang Du, Hongwei Du, Xiangguo Zhou, Yiwen Wu, Weibo Zheng, Donghong Han

Although many efforts have been made, it is still a challenge to balance the
training budget, downstream performance, and the general capabilities of the
LLMs in many applications. Training the whole model for downstream tasks is
expensive, and could easily result in catastrophic forgetting. By introducing
parameter-efficient fine-tuning (PEFT), the training cost could be reduced, but
it still suffers from forgetting, and limits the learning on the downstream
tasks. To efficiently fine-tune the LLMs with less limitation to their
downstream performance while mitigating the forgetting of general capabilities,
we propose a novel mixture of expert (MoE) framework based on Soft LoRA and
Identity Mixture (SLIM), that allows dynamic routing between LoRA adapters and
skipping connection, enables the suppression of forgetting. We adopt
weight-yielding with sliding clustering for better out-of-domain distinguish to
enhance the routing. We also propose to convert the mixture of low-rank
adapters to the model merging formulation and introduce fast dynamic merging of
LoRA adapters to keep the general capabilities of the base model. Extensive
experiments demonstrate that the proposed SLIM is comparable to the
state-of-the-art PEFT approaches on the downstream tasks while achieving the
leading performance in mitigating catastrophic forgetting.

æè¦ï¼åç®¡å·²ååºè¨±å¤åªåï¼ä½å¨è¨±å¤æç¨ä¸­å¹³è¡¡ LLM çè¨ç·´é ç®ãä¸æ¸¸æè½åä¸è¬åè½ä»æ¯ä¸é ææ°ãéå°ä¸æ¸¸ä»»åè¨ç·´æ´åæ¨¡åå¾æè²´ï¼èä¸å¾å®¹æå°è´ç½é£æ§éºå¿ãééå¼å¥åæ¸ææå¾®èª¿ (PEFT)ï¼è¨ç·´ææ¬å¯ä»¥éä½ï¼ä½å®ä»ç¶æéºå¿ï¼ä¸¦éå¶ä¸æ¸¸ä»»åçå­¸ç¿ãçºäºææå¾®èª¿ LLMï¼åææ¸å°å°å¶ä¸æ¸¸æè½çéå¶ï¼ä¸¦æ¸è¼ä¸è¬åè½çéºå¿ï¼æåæåºä¸ååºæ¼ Soft LoRA åèº«åæ··å (SLIM) çå°å®¶æ··å (MoE) æ¡æ¶ï¼åè¨±å¨ LoRA é©éå¨åè·³æ¥é£æ¥ä¹éé²è¡åæè·¯ç±ï¼ä¸¦æå¶éºå¿ãæåæ¡ç¨å¸¶ææ»åèé¡çæ¬éè®æ­¥ï¼ä»¥ç²å¾æ´å¥½çç¶²åå¤ååï¼ä»¥å¢å¼·è·¯ç±ãæåéå»ºè­°å°ä½éé©éå¨çæ··åè½æçºæ¨¡ååä½µå¬å¼ï¼ä¸¦å¼å¥ LoRA é©éå¨çå¿«éåæåä½µï¼ä»¥ä¿æåºç¤æ¨¡åçä¸è¬åè½ãå»£æ³çå¯¦é©è­æï¼ææåºç SLIM å¨ä¸æ¸¸ä»»åä¸å¯èæåé²ç PEFT æ¹æ³ç¸åª²ç¾ï¼åæå¨æ¸è¼ç½é£æ§éºå¿æ¹é¢åå¾é åçæè½ã

##### **Enhancing Federated Domain Adaptation with Multi-Domain Prototype-Based Federated Fine-Tuning**
2410.07738v1 by Jingyuan Zhang, Yiyang Duan, Shuaicheng Niu, Yang Cao, Wei Yang Bryan Lim

Federated Domain Adaptation (FDA) is a Federated Learning (FL) scenario where
models are trained across multiple clients with unique data domains but a
shared category space, without transmitting private data. The primary challenge
in FDA is data heterogeneity, which causes significant divergences in gradient
updates when using conventional averaging-based aggregation methods, reducing
the efficacy of the global model. This further undermines both in-domain and
out-of-domain performance (within the same federated system but outside the
local client). To address this, we propose a novel framework called
\textbf{M}ulti-domain \textbf{P}rototype-based \textbf{F}ederated
Fine-\textbf{T}uning (MPFT). MPFT fine-tunes a pre-trained model using
multi-domain prototypes, i.e., pretrained representations enriched with
domain-specific information from category-specific local data. This enables
supervised learning on the server to derive a globally optimized adapter that
is subsequently distributed to local clients, without the intrusion of data
privacy. Empirical results show that MPFT significantly improves both in-domain
and out-of-domain accuracy over conventional methods, enhancing knowledge
preservation and adaptation in FDA. Notably, MPFT achieves convergence within a
single communication round, greatly reducing computation and communication
costs. To ensure privacy, MPFT applies differential privacy to protect the
prototypes. Additionally, we develop a prototype-based feature space hijacking
attack to evaluate robustness, confirming that raw data samples remain
unrecoverable even after extensive training epochs. The complete implementation
of MPFL is available at \url{https://anonymous.4open.science/r/DomainFL/}.

æè¦ï¼<paragraph>è¯é¦åé©æï¼FDAï¼æ¯ä¸ç¨®è¯é¦å­¸ç¿ï¼FLï¼å ´æ¯ï¼å¶ä¸­
æ¨¡åå¨å·æå¯ä¸æ¸æåä½å±äº«é¡å¥ç©ºéçå¤åå®¢æ¶ç«¯ä¸é²è¡è¨ç·´ï¼èä¸æå³è¼¸ç§äººæ¸æãFDA ä¸­çä¸»è¦ææ°æ¯æ¸æç°è³ªæ§ï¼éæå°è´ä½¿ç¨å³çµ±åºæ¼å¹³åçèåæ¹æ³ææ¢¯åº¦æ´æ°åºç¾é¡¯èå·®ç°ï¼å¾èéä½å¨å±æ¨¡åçæè½ãéé²ä¸æ­¥æå®³äºåå§ååå¤æè½ï¼å¨åä¸åè¯é¦ç³»çµ±ä¸­ï¼ä½å¨æ¬å°å®¢æ¶ç«¯ä¹å¤ï¼ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸ååçº
\textbf{M}ulti-domain \textbf{P}rototype-based \textbf{F}ederated
Fine-\textbf{T}uning (MPFT) çæ°æ¡æ¶ãMPFT ä½¿ç¨å¤åååå¾®èª¿é è¨ç·´æ¨¡åï¼å³é è¨ç·´è¡¨ç¤ºï¼å¶ä¸­åå«ä¾èªé¡å¥ç¹å®æ¬å°æ¸æçç¹å®æ¼åçä¿¡æ¯ãéä½¿å¾ä¼ºæå¨ä¸çç£ç£å­¸ç¿è½å¤ æ¨å°åºä¸åå¨å±æä½³åçé©éå¨ï¼é¨å¾å°å¶åç¼å°æ¬å°å®¢æ¶ç«¯ï¼èä¸æä¾µç¯æ¸æé±ç§ãç¶é©çµæè¡¨æï¼MPFT å¨åå§ååå¤æºç¢ºåº¦æ¹é¢é½é¡¯èåªæ¼å³çµ±æ¹æ³ï¼å¢å¼·äº FDA ä¸­çç¥è­ä¿çåé©æãå¼å¾æ³¨æçæ¯ï¼MPFT å¨å®æ¬¡éä¿¡ååå§å¯¦ç¾æ¶æï¼å¤§å¤§éä½äºè¨ç®åéä¿¡ææ¬ãçºäºç¢ºä¿é±ç§ï¼MPFT æç¨å·®åé±ç§ä¾ä¿è­·ååãæ­¤å¤ï¼æåéç¼äºä¸ååºæ¼ååçç¹å¾µç©ºéå«ææ»æä¾è©ä¼°é­¯æ£æ§ï¼ç¢ºèªå³ä½¿ç¶éå¤§éçè¨ç·´ææï¼åå§æ¸ææ¨£æ¬ä»ç¶ç¡æ³æ¢å¾©ãMPFL çå®æ´å¯¦ä½å¯å¨ \url{https://anonymous.4open.science/r/DomainFL/} ä¸­åå¾ã</paragraph>

##### **On the Generalization Properties of Deep Learning for Aircraft Fuel Flow Estimation Models**
2410.07717v1 by Gabriel Jarry, Ramon Dalmau, Philippe Very, Junzi Sun

Accurately estimating aircraft fuel flow is essential for evaluating new
procedures, designing next-generation aircraft, and monitoring the
environmental impact of current aviation practices. This paper investigates the
generalization capabilities of deep learning models in predicting fuel
consumption, focusing particularly on their performance for aircraft types
absent from the training data. We propose a novel methodology that integrates
neural network architectures with domain generalization techniques to enhance
robustness and reliability across a wide range of aircraft. A comprehensive
dataset containing 101 different aircraft types, separated into training and
generalization sets, with each aircraft type set containing 1,000 flights. We
employed the base of aircraft data (BADA) model for fuel flow estimates,
introduced a pseudo-distance metric to assess aircraft type similarity, and
explored various sampling strategies to optimize model performance in
data-sparse regions. Our results reveal that for previously unseen aircraft
types, the introduction of noise into aircraft and engine parameters improved
model generalization. The model is able to generalize with acceptable mean
absolute percentage error between 2\% and 10\% for aircraft close to existing
aircraft, while performance is below 1\% error for known aircraft in the
training set. This study highlights the potential of combining domain-specific
insights with advanced machine learning techniques to develop scalable,
accurate, and generalizable fuel flow estimation models.

æè¦ï¼æºç¢ºä¼°è¨é£æ©çææµéå°æ¼è©ä¼°æ°ç¨åºãè¨­è¨æ°ä¸ä»£é£æ©ä»¥åç£æ§ç¾è¡èªç©ºå¯¦åçç°å¢å½±é¿è³ééè¦ãæ¬ææ¢è¨æ·±åº¦å­¸ç¿æ¨¡åå¨é æ¸¬çææ¶èæ¹é¢çæ³åè½åï¼ç¹å¥éæ³¨å®åå¨è¨ç·´è³æä¸­æ²æçé£æ©é¡åçæè½ãæåæåºä¸ååµæ°çæ¹æ³è«ï¼å°ç¥ç¶ç¶²è·¯æ¶æ§èé åæ³åæè¡æ´åï¼ä»¥å¢å¼·åç¨®é£æ©çç©©å¥æ§åå¯é æ§ãä¸ååå« 101 ç¨®ä¸åé£æ©é¡åçç¶åè³æéï¼åçºè¨ç·´éåæ³åéï¼æ¯åé£æ©é¡åéåå« 1,000 åèªç­ãæåæ¡ç¨é£æ©è³æåº« (BADA) æ¨¡åä¾ä¼°è¨çææµéï¼å¼é²ä¸åå½è·é¢éåº¦ä¾è©ä¼°é£æ©é¡åçç¸ä¼¼æ§ï¼ä¸¦æ¢ç´¢åç¨®åæ¨£ç­ç¥ï¼ä»¥æä½³åè³æç¨çååçæ¨¡åæè½ãæåççµæé¡¯ç¤ºï¼å°æ¼ä»¥åæªè¦çé£æ©é¡åï¼å¨é£æ©åå¼æåæ¸ä¸­å¼å¥éè¨å¯ä»¥æ¹åæ¨¡åæ³åãå°æ¼æ¥è¿ç¾æé£æ©çé£æ©ï¼è©²æ¨¡åè½å¤ ä»¥ 2% å° 10% ä¹éçå¯æ¥åå¹³åçµå°ç¾åæ¯èª¤å·®é²è¡æ³åï¼èå°æ¼è¨ç·´éä¸­å·²ç¥çé£æ©ï¼æè½ä½æ¼ 1% çèª¤å·®ãéé ç ç©¶å¼·èª¿äºçµåç¹å®é åè¦è§£èé²éæ©å¨å­¸ç¿æè¡ä»¥éç¼å¯æ´åãæºç¢ºä¸å¯æ³åççææµéä¼°è¨æ¨¡åçæ½åã

##### **Learning Tree Pattern Transformations**
2410.07708v1 by Daniel Neider, Leif Sabellek, Johannes Schmidt, Fabian Vehlken, Thomas Zeume

Explaining why and how a tree $t$ structurally differs from another tree
$t^*$ is a question that is encountered throughout computer science, including
in understanding tree-structured data such as XML or JSON data. In this
article, we explore how to learn explanations for structural differences
between pairs of trees from sample data: suppose we are given a set $\{(t_1,
t_1^*),\dots, (t_n, t_n^*)\}$ of pairs of labelled, ordered trees; is there a
small set of rules that explains the structural differences between all pairs
$(t_i, t_i^*)$? This raises two research questions: (i) what is a good notion
of "rule" in this context?; and (ii) how can sets of rules explaining a data
set be learnt algorithmically?
  We explore these questions from the perspective of database theory by (1)
introducing a pattern-based specification language for tree transformations;
(2) exploring the computational complexity of variants of the above algorithmic
problem, e.g. showing NP-hardness for very restricted variants; and (3)
discussing how to solve the problem for data from CS education research using
SAT solvers.

æè¦ï¼<paragraph>è§£éæ¨¹ $t$ å¨çµæ§ä¸èå¦ä¸æ£µæ¨¹ $t^*$ æä½ä¸åï¼ä»¥ååå çºä½ï¼æ¯é»è¦ç§å­¸é åä¸­ç¶å¸¸éå°çåé¡ï¼åæ¬å¨çè§£æ¨¹ççµæ§è³æï¼ä¾å¦ XML æ JSON è³æï¼æãå¨æ¬æä¸­ï¼æåæ¢è¨å¦ä½å¾ç¯ä¾è³æä¸­å­¸ç¿æ¨¹å°ä¹éçµæ§å·®ç°çè§£éï¼åè¨­æåçµ¦å®ä¸çµæ¨ç±¤ãæåºæ¨¹å° $\{(t_1, t_1^*),\dots, (t_n, t_n^*)\}$ï¼æ¯å¦å­å¨ä¸çµå°è¦åï¼å¯ä»¥è§£éææå° $(t_i, t_i^*)$ ä¹éççµæ§å·®ç°ï¼éæåºäºå©åç ç©¶åé¡ï¼(i) å¨éåèçµ¡ä¸­ï¼ãè¦åãçè¯å¥½æ¦å¿µæ¯ä»éº¼ï¼(ii) å¦ä½æ¼ç®æ³å­¸ç¿è§£éè³æéçè¦åéï¼
æåå¾è³æåº«çè«çè§åº¦æ¢è¨éäºåé¡ï¼æ¹æ³æ¯ï¼(1) ä»ç´¹æ¨¹çè½æçåºæ¼æ¨¡å¼çè¦ç¯èªè¨ï¼(2) æ¢è¨ä¸è¿°æ¼ç®æ³åé¡è®é«çè¨ç®è¤éåº¦ï¼ä¾å¦é¡¯ç¤ºéå¸¸åéè®é«ç NP é£åº¦ï¼ä»¥å (3) è¨è«å¦ä½ä½¿ç¨ SAT æ±è§£å¨è§£æ±ºä¾èªé»è¦ç§å­¸æè²ç ç©¶çè³æåé¡ã</paragraph>

##### **AgentBank: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories**
2410.07706v1 by Yifan Song, Weimin Xiong, Xiutian Zhao, Dawei Zhu, Wenhao Wu, Ke Wang, Cheng Li, Wei Peng, Sujian Li

Fine-tuning on agent-environment interaction trajectory data holds
significant promise for surfacing generalized agent capabilities in open-source
large language models (LLMs). In this work, we introduce AgentBank, by far the
largest trajectory tuning data collection featuring more than 50k diverse
high-quality interaction trajectories which comprises 16 tasks covering five
distinct agent skill dimensions. Leveraging a novel annotation pipeline, we are
able to scale the annotated trajectories and generate a trajectory dataset with
minimized difficulty bias. Furthermore, we fine-tune LLMs on AgentBank to get a
series of agent models, Samoyed. Our comparative experiments demonstrate the
effectiveness of scaling the interaction trajectory data to acquire generalized
agent capabilities. Additional studies also reveal some key observations
regarding trajectory tuning and agent skill generalization.

æè¦ï¼å¨ä»£çç°å¢äºåè»è·¡è³æä¸é²è¡å¾®èª¿ï¼å°æ¼å¨éæºå¤§åèªè¨æ¨¡å (LLM) ä¸­æµ®ç¾å»£ç¾©çä»£çåè½å·æé¡¯èçå¸æãå¨éåå·¥ä½ä¸­ï¼æåä»ç´¹äº AgentBankï¼ç®åçºæ­¢æå¤§çè»è·¡èª¿æ ¡è³ææ¶éï¼å·æè¶é 50k åå¤æ¨£åçåªè³ªäºåè»è·¡ï¼å¶ä¸­åå«æ¶µèäºåä¸åä»£çæè½ç¶­åº¦ç 16 åä»»åãå©ç¨æ°ç©çè¨»éç®¡éï¼æåè½å¤ æ´å±è¨»éçè»è·¡ä¸¦çæå·ææå°åé£åº¦åå·®çè»è·¡è³æéãæ­¤å¤ï¼æåå¨ AgentBank ä¸å¾®èª¿ LLM ä»¥ç²å¾ä¸ç³»åä»£çæ¨¡åï¼Samoyedãæåçæ¯è¼å¯¦é©è­æäºæ´å±äºåè»è·¡è³æä»¥ç²åå»£ç¾©ä»£çåè½çæææ§ãå¶ä»ç ç©¶ä¹æ­ç¤ºäºä¸äºéæ¼è»è·¡èª¿æ ¡åä»£çæè½æ¦æ¬åçééµè§å¯ã

##### **Multi-Facet Counterfactual Learning for Content Quality Evaluation**
2410.07693v1 by Jiasheng Zheng, Hongyu Lin, Boxi Cao, Meng Liao, Yaojie Lu, Xianpei Han, Le Sun

Evaluating the quality of documents is essential for filtering valuable
content from the current massive amount of information. Conventional approaches
typically rely on a single score as a supervision signal for training content
quality evaluators, which is inadequate to differentiate documents with quality
variations across multiple facets. In this paper, we propose Multi-facet
cOunterfactual LEarning (MOLE), a framework for efficiently constructing
evaluators that perceive multiple facets of content quality evaluation. Given a
specific scenario, we prompt large language models to generate counterfactual
content that exhibits variations in critical quality facets compared to the
original document. Furthermore, we leverage a joint training strategy based on
contrastive learning and supervised learning to enable the evaluator to
distinguish between different quality facets, resulting in more accurate
predictions of content quality scores. Experimental results on 2 datasets
across different scenarios demonstrate that our proposed MOLE framework
effectively improves the correlation of document content quality evaluations
with human judgments, which serve as a valuable toolkit for effective
information acquisition.

æè¦ï¼è©ä¼°æä»¶åè³ªå°æ¼å¾ç¶åå¤§éçè³è¨ä¸­éæ¿¾åºæå¹å¼çå§å®¹è³ééè¦ãå³çµ±æ¹æ³éå¸¸ä¾è³´å®ä¸è©åä½çºè¨ç·´å§å®¹åè³ªè©ä¼°å¡çç£ç£è¨èï¼éä¸è¶³ä»¥ååå¨å¤åé¢åå·æåè³ªå·®ç°çæä»¶ãå¨æ¬æä¸­ï¼æåæåºå¤é¢ååäºå¯¦å­¸ç¿ (MOLE)ï¼ä¸åç¨æ¼ææå»ºæ§è©ä¼°å¡çæ¶æ§ï¼è©²è©ä¼°å¡è½æç¥å§å®¹åè³ªè©ä¼°çå¤åé¢åãéå°ç¹å®æå¢ï¼æåæç¤ºå¤§åèªè¨æ¨¡åç¢çåäºå¯¦å§å®¹ï¼èåå§æä»¶ç¸æ¯ï¼éäºå§å®¹å¨ééµåè³ªé¢åä¸­è¡¨ç¾åºå·®ç°ãæ­¤å¤ï¼æåå©ç¨åºæ¼å°æ¯å­¸ç¿åç£ç£å­¸ç¿çè¯åè¨ç·´ç­ç¥ï¼è®è©ä¼°å¡è½å¤ ååä¸åçåè³ªé¢åï¼é²èæ´æºç¢ºå°é æ¸¬å§å®¹åè³ªè©åãå¨ä¸åæå¢ä¸­ç 2 åè³æéä¸çå¯¦é©çµæè¡¨æï¼æåæåºç MOLE æ¡æ¶ææå°æ¹åäºæä»¶å§å®¹åè³ªè©ä¼°èäººé¡å¤æ·ä¹éçç¸éæ§ï¼éæ¯ä¸åç¨æ¼ææè³è¨ç²åçæå¹å¼å·¥å·åã

##### **Smart Audit System Empowered by LLM**
2410.07677v1 by Xu Yao, Xiaoxu Wu, Xi Li, Huan Xu, Chenlei Li, Ping Huang, Si Li, Xiaoning Ma, Jiulong Shan

Manufacturing quality audits are pivotal for ensuring high product standards
in mass production environments. Traditional auditing processes, however, are
labor-intensive and reliant on human expertise, posing challenges in
maintaining transparency, accountability, and continuous improvement across
complex global supply chains. To address these challenges, we propose a smart
audit system empowered by large language models (LLMs). Our approach introduces
three innovations: a dynamic risk assessment model that streamlines audit
procedures and optimizes resource allocation; a manufacturing compliance
copilot that enhances data processing, retrieval, and evaluation for a
self-evolving manufacturing knowledge base; and a Re-act framework commonality
analysis agent that provides real-time, customized analysis to empower
engineers with insights for supplier improvement. These enhancements elevate
audit efficiency and effectiveness, with testing scenarios demonstrating an
improvement of over 24%.

æè¦ï¼è£½é åè³ªç¨½æ ¸å°æ¼ç¢ºä¿å¤§éçç¢ç°å¢ä¸­çé«ç¢åæ¨æºè³ééè¦ãç¶èï¼å³çµ±çç¨½æ ¸ç¨åºéè¦å¤§éäººåï¼ä¸ä¾è³´æ¼äººçºå°æ¥­ç¥è­ï¼å¨ç¶­æéæåº¦ãè²¬ä»»å¶åè·¨è¤éå¨çä¾æéçæçºæ¹é²æ¹é¢æ§æææ°ãçºäºæå°éäºææ°ï¼æåæåºä¸åç±å¤§åèªè¨æ¨¡å (LLM) è³¦è½çæºæ§ç¨½æ ¸ç³»çµ±ãæåçåæ³å¼é²äºä¸é åµæ°ï¼ç°¡åç¨½æ ¸ç¨åºä¸¦æä½³åè³æºéç½®çåæé¢¨éªè©ä¼°æ¨¡åï¼å¢å¼·è³æèçãæ·ååè©ä¼°ä»¥å»ºç«èªæ¼åè£½é ç¥è­åº«çè£½é åè¦è¼å©ç³»çµ±ï¼ä»¥åæä¾å³æãå®¢è£½ååæä»¥è³¦äºå·¥ç¨å¸«ä¾æåæ¹åè¦è§£ç Re-act æ¶æ§å±æ§åæä»£çãéäºå¼·åæåäºç¨½æ ¸æçåæè½ï¼æ¸¬è©¦æå¢é¡¯ç¤ºæ¹åå¹åº¦è¶é 24%ã

##### **Adversarial Robustness Overestimation and Instability in TRADES**
2410.07675v1 by Jonathan Weiping Li, Ren-Wei Liang, Cheng-Han Yeh, Cheng-Chang Tsai, Kuanchun Yu, Chun-Shien Lu, Shang-Tse Chen

This paper examines the phenomenon of probabilistic robustness overestimation
in TRADES, a prominent adversarial training method. Our study reveals that
TRADES sometimes yields disproportionately high PGD validation accuracy
compared to the AutoAttack testing accuracy in the multiclass classification
task. This discrepancy highlights a significant overestimation of robustness
for these instances, potentially linked to gradient masking. We further analyze
the parameters contributing to unstable models that lead to overestimation. Our
findings indicate that smaller batch sizes, lower beta values (which control
the weight of the robust loss term in TRADES), larger learning rates, and
higher class complexity (e.g., CIFAR-100 versus CIFAR-10) are associated with
an increased likelihood of robustness overestimation. By examining metrics such
as the First-Order Stationary Condition (FOSC), inner-maximization, and
gradient information, we identify the underlying cause of this phenomenon as
gradient masking and provide insights into it. Furthermore, our experiments
show that certain unstable training instances may return to a state without
robust overestimation, inspiring our attempts at a solution. In addition to
adjusting parameter settings to reduce instability or retraining when
overestimation occurs, we recommend incorporating Gaussian noise in inputs when
the FOSC score exceed the threshold. This method aims to mitigate robustness
overestimation of TRADES and other similar methods at its source, ensuring more
reliable representation of adversarial robustness during evaluation.

æè¦ï¼éç¯è«ææ¢è¨äº TRADES ä¸­æ©çç©©å¥æ§é«ä¼°çç¾è±¡ï¼TRADES æ¯ä¸ç¨®èåçå°ææ§è¨ç·´æ¹æ³ãæåçç ç©¶é¡¯ç¤ºï¼å¨å¤é¡å¥åé¡ä»»åä¸­ï¼è AutoAttack æ¸¬è©¦æºç¢ºåº¦ç¸æ¯ï¼TRADES æææç¢çä¸ææ¯ä¾çé« PGD é©è­æºç¢ºåº¦ãéç¨®å·®ç°çªé¡¯äºå°éäºå¯¦ä¾çç©©å¥æ§é«ä¼°ï¼å¯è½èæ¢¯åº¦é®è½æéãæåé²ä¸æ­¥åæäºå°è´é«ä¼°çä¸ç©©å®æ¨¡åçåæ¸ãæåçç¼ç¾è¡¨æï¼è¼å°çæ¹æ¬¡å¤§å°ãè¼ä½ç beta å¼ï¼æ§å¶ TRADES ä¸­ç©©å¥æå¤±é çæ¬éï¼ãè¼é«çå­¸ç¿çåè¼é«çé¡å¥è¤éåº¦ï¼ä¾å¦ï¼CIFAR-100 è CIFAR-10ï¼èç©©å¥æ§é«ä¼°çå¯è½æ§å¢å æéãééæª¢æ¥ä¸éå¹³ç©©æ¢ä»¶ (FOSC)ãå§é¨æå¤§ååæ¢¯åº¦è³è¨ç­ææ¨ï¼æåå°éç¨®ç¾è±¡çæ ¹æ¬åå ç¢ºå®çºæ¢¯åº¦é®è½ï¼ä¸¦å°å¶æä¾äºè¦è§£ãæ­¤å¤ï¼æåçå¯¦é©è¡¨æï¼æäºä¸ç©©å®çè¨ç·´å¯¦ä¾å¯è½æè¿åå°æ²æç©©å¥é«ä¼°ççæï¼éæ¿ç¼äºæååè©¦è§£æ±ºæ¹æ¡ãé¤äºèª¿æ´åæ¸è¨­å®ä»¥æ¸å°ä¸ç©©å®æ§æå¨ç¼çé«ä¼°æéæ°è¨ç·´ä¹å¤ï¼æåå»ºè­°å¨ FOSC åæ¸è¶éé¾å¼æå¨è¼¸å¥ä¸­å å¥é«æ¯åªè²ãéç¨®æ¹æ³æ¨å¨å¾æºé ­æ¸è¼ TRADES åå¶ä»é¡ä¼¼æ¹æ³çç©©å¥æ§é«ä¼°ï¼ç¢ºä¿å¨è©ä¼°éç¨ä¸­æ´å¯é å°è¡¨ç¤ºå°ææ§ç©©å¥æ§ã

##### **Multimodal Clickbait Detection by De-confounding Biases Using Causal Representation Inference**
2410.07673v1 by Jianxing Yu, Shiqi Wang, Han Yin, Zhenlong Sun, Ruobing Xie, Bo Zhang, Yanghui Rao

This paper focuses on detecting clickbait posts on the Web. These posts often
use eye-catching disinformation in mixed modalities to mislead users to click
for profit. That affects the user experience and thus would be blocked by
content provider. To escape detection, malicious creators use tricks to add
some irrelevant non-bait content into bait posts, dressing them up as legal to
fool the detector. This content often has biased relations with non-bait
labels, yet traditional detectors tend to make predictions based on simple
co-occurrence rather than grasping inherent factors that lead to malicious
behavior. This spurious bias would easily cause misjudgments. To address this
problem, we propose a new debiased method based on causal inference. We first
employ a set of features in multiple modalities to characterize the posts.
Considering these features are often mixed up with unknown biases, we then
disentangle three kinds of latent factors from them, including the invariant
factor that indicates intrinsic bait intention; the causal factor which
reflects deceptive patterns in a certain scenario, and non-causal noise. By
eliminating the noise that causes bias, we can use invariant and causal factors
to build a robust model with good generalization ability. Experiments on three
popular datasets show the effectiveness of our approach.

æè¦ï¼æ¬è«æå°æ³¨æ¼åµæ¸¬ç¶²è·¯ä¸çè³åæ¨é¡è²¼æãéäºè²¼æéå¸¸ä½¿ç¨å¼äººæ³¨ç®çé¯èª¤è³è¨ï¼ä¸¦ä»¥æ··åæ¨¡å¼èª¤å°ä½¿ç¨èé»æä»¥ç²å©ãéæå½±é¿ä½¿ç¨èé«é©ï¼å æ­¤æè¢«å§å®¹æä¾èå°éãçºäºéé¿åµæ¸¬ï¼æ¡æåµä½èæä½¿ç¨æå·§å°ä¸äºç¡éçéèªé¤å§å®¹å å¥èªé¤è²¼æä¸­ï¼å°å®åå½è£æåæ³çè²¼æä»¥æå¼åµæ¸¬å¨ãéäºå§å®¹éå¸¸èéèªé¤æ¨ç±¤æåèª¤çéè¯ï¼ä½å³çµ±çåµæ¸¬å¨å¾åæ¼æ ¹æç°¡å®çå±ç¾ï¼èä¸æ¯ææ¡å°è´æ¡æè¡çºçå§å¨å ç´ ä¾ååºé æ¸¬ãéç¨®èåçåèª¤å¾å®¹æé æé¯èª¤å¤æ·ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸ç¨®æ°çåºæ¼å ææ¨è«çå»åæ¹æ³ãæåé¦åä½¿ç¨å¤ç¨®æ¨¡å¼ä¸­çä¸çµç¹å¾µä¾æè¿°è²¼æãèæ®å°éäºç¹å¾µéå¸¸èæªç¥çåèª¤æ··å¨ä¸èµ·ï¼æåæ¥èå¾ä¸­è§£éä¸ç¨®é¡åçæ½å¨å ç´ ï¼åæ¬è¡¨ç¤ºå§å¨èªé¤æåçä¸è®å ç´ ï¼å¨ç¹å®å ´æ¯ä¸­åæ æ¬ºé¨æ¨¡å¼çå æå ç´ ï¼ä»¥åéå æåªé³ãééæ¶é¤é æåèª¤çåªé³ï¼æåå¯ä»¥ä½¿ç¨ä¸è®åå æå ç´ ä¾å»ºç«ä¸åå·æè¯å¥½æ³åè½åçå¼·å¥æ¨¡åãå¨ä¸åç±éè³æéä¸çå¯¦é©é¡¯ç¤ºäºæåæ¹æ³çæææ§ã

##### **MACPO: Weak-to-Strong Alignment via Multi-Agent Contrastive Preference Optimization**
2410.07672v1 by Yougang Lyu, Lingyong Yan, Zihan Wang, Dawei Yin, Pengjie Ren, Maarten de Rijke, Zhaochun Ren

As large language models (LLMs) are rapidly advancing and achieving
near-human capabilities, aligning them with human values is becoming more
urgent. In scenarios where LLMs outperform humans, we face a weak-to-strong
alignment problem where we need to effectively align strong student LLMs
through weak supervision generated by weak teachers. Existing alignment methods
mainly focus on strong-to-weak alignment and self-alignment settings, and it is
impractical to adapt them to the much harder weak-to-strong alignment setting.
To fill this gap, we propose a multi-agent contrastive preference optimization
(MACPO) framework. MACPO facilitates weak teachers and strong students to learn
from each other by iteratively reinforcing unfamiliar positive behaviors while
penalizing familiar negative ones. To get this, we devise a mutual positive
behavior augmentation strategy to encourage weak teachers and strong students
to learn from each other's positive behavior and further provide higher quality
positive behavior for the next iteration. Additionally, we propose a hard
negative behavior construction strategy to induce weak teachers and strong
students to generate familiar negative behavior by fine-tuning on negative
behavioral data. Experimental results on the HH-RLHF and PKU-SafeRLHF datasets,
evaluated using both automatic metrics and human judgments, demonstrate that
MACPO simultaneously improves the alignment performance of strong students and
weak teachers. Moreover, as the number of weak teachers increases, MACPO
achieves better weak-to-strong alignment performance through more iteration
optimization rounds.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) å¿«éé²æ­¥ä¸¦éå°æ¥è¿äººé¡çè½åï¼ä½¿å¶èäººé¡å¹å¼è§ä¿æä¸è´è®å¾æ´å è¿«åãå¨ LLM åªæ¼äººé¡çå ´æ¯ä¸­ï¼æåé¢è¨ä¸åå¼±å°å¼·çä¸è´æ§åé¡ï¼æåéè¦ééå¼±æå¸«ç¢ççå¼±ç£ç£ä¾ææå°èª¿æ´å¼·å­¸ç LLMãç¾æçä¸è´æ§æ¹æ³ä¸»è¦éæ³¨å¼·å°å¼±çä¸è´æ§åèªå°é½è¨­å®ï¼èä¸å°å®åé©æå°æ´å°é£çå¼±å°å¼·çä¸è´æ§è¨­å®æ¯ä¸åå¯¦éçãçºäºå¡«è£éä¸ç©ºç½ï¼æåæåºäºä¸åå¤ä¸»é«å°æ¯åå¥½æä½³å (MACPO) æ¡æ¶ãMACPO ä¿é²å¼±æå¸«åå¼·å­¸çééåè¦å å¼·ä¸çæçæ­£é¢è¡çºä¸¦æ²ç½°çæçè² é¢è¡çºä¾ç¸äºå­¸ç¿ãçºäºå¯¦ç¾éä¸ç®æ¨ï¼æåè¨­è¨äºä¸åç¸äºçæ­£é¢è¡çºå¢å¼·ç­ç¥ä¾é¼åµå¼±æå¸«åå¼·å­¸çç¸äºå­¸ç¿å½¼æ­¤çæ­£é¢è¡çºï¼ä¸¦é²ä¸æ­¥çºä¸ä¸æ¬¡è¿­ä»£æä¾æ´é«åè³ªçæ­£é¢è¡çºãæ­¤å¤ï¼æåæåºäºä¸åç¡¬è² é¢è¡çºæ§å»ºç­ç¥ï¼ä»¥èªå°å¼±æå¸«åå¼·å­¸çééå°è² é¢è¡çºæ¸æé²è¡å¾®èª¿ä¾ç¢ççæçè² é¢è¡çºãå¨ HH-RLHF å PKU-SafeRLHF æ¸æéä¸çå¯¦é©çµæï¼ä½¿ç¨èªåææ¨åäººé¡å¤æ·é²è¡è©ä¼°ï¼è¡¨æ MACPO åææé«äºå¼·å­¸çåå¼±æå¸«çä¸è´æ§è¡¨ç¾ãæ­¤å¤ï¼é¨èå¼±æå¸«çæ¸éå¢å ï¼MACPO ééæ´å¤çè¿­ä»£æä½³åååå¯¦ç¾äºæ´å¥½çå¼±å°å¼·çä¸è´æ§è¡¨ç¾ã

##### **DISCO: A Hierarchical Disentangled Cognitive Diagnosis Framework for Interpretable Job Recommendation**
2410.07671v1 by Xiaoshan Yu, Chuan Qin, Qi Zhang, Chen Zhu, Haiping Ma, Xingyi Zhang, Hengshu Zhu

The rapid development of online recruitment platforms has created
unprecedented opportunities for job seekers while concurrently posing the
significant challenge of quickly and accurately pinpointing positions that
align with their skills and preferences. Job recommendation systems have
significantly alleviated the extensive search burden for job seekers by
optimizing user engagement metrics, such as clicks and applications, thus
achieving notable success. In recent years, a substantial amount of research
has been devoted to developing effective job recommendation models, primarily
focusing on text-matching based and behavior modeling based methods. While
these approaches have realized impressive outcomes, it is imperative to note
that research on the explainability of recruitment recommendations remains
profoundly unexplored. To this end, in this paper, we propose DISCO, a
hierarchical Disentanglement based Cognitive diagnosis framework, aimed at
flexibly accommodating the underlying representation learning model for
effective and interpretable job recommendations. Specifically, we first design
a hierarchical representation disentangling module to explicitly mine the
hierarchical skill-related factors implied in hidden representations of job
seekers and jobs. Subsequently, we propose level-aware association modeling to
enhance information communication and robust representation learning both
inter- and intra-level, which consists of the interlevel knowledge influence
module and the level-wise contrastive learning. Finally, we devise an
interaction diagnosis module incorporating a neural diagnosis function for
effectively modeling the multi-level recruitment interaction process between
job seekers and jobs, which introduces the cognitive measurement theory.

æè¦ï¼ç·ä¸æåå¹³å°çå¿«éç¼å±çºæ±è·èåµé äºåææªæçæ©æï¼åæä¹å¸¶ä¾äºå¿«éä¸æºç¢ºæ¾åºèå¶æè½ååå¥½ç¸ç¬¦è·ä½çéå¤§ææ°ãæ±è·æ¨è¦ç³»çµ±ééæä½³åä½¿ç¨èåèåº¦ææ¨ï¼ä¾å¦é»æåæå¾µï¼ï¼å¤§å¹æ¸è¼æ±è·èçå»£æ³æå°è² æï¼å èç²å¾é¡¯èçæåãè¿å¹´ä¾ï¼å¤§éç ç©¶è´åæ¼éç¼ææçæ±è·æ¨è¦æ¨¡åï¼ä¸»è¦èéæ¼åºæ¼æå­æ¯å°ååºæ¼è¡çºå»ºæ¨¡çæ¹æ³ãåç®¡éäºæ¹æ³å·²å¯¦ç¾ä»¤äººå°è±¡æ·±å»çææï¼ä½å¿é æ³¨æçæ¯ï¼å°æ¼æåæ¨è¦çå¯è§£éæ§ç ç©¶ä»æªæ·±å¥æ¢è¨ãçºæ­¤ï¼æåå¨æ¬æä¸­æåº DISCOï¼ä¸ååºæ¼éå±¤å¼è§£éçèªç¥è¨ºæ·æ¶æ§ï¼æ¨å¨éæ´»å®¹ç´åºç¤è¡¨å¾µå­¸ç¿æ¨¡åï¼ä»¥æä¾ææä¸å¯è§£éçæ±è·æ¨è¦ãå·é«ä¾èªªï¼æåé¦åè¨­è¨ä¸åéå±¤å¼è¡¨å¾µè§£éæ¨¡çµï¼ä»¥æç¢ºæ¾åºé±å«å¨æ±è·èåè·åçé±èè¡¨å¾µä¸­çéå±¤å¼æè½ç¸éå ç´ ãé¨å¾ï¼æåæåºå±¤ç´æç¥éè¯å»ºæ¨¡ï¼ä»¥å¢å¼·è³è¨å³éåå¼·å¥è¡¨å¾µå­¸ç¿ï¼åæ¬å±¤ç´éç¥è­å½±é¿æ¨¡çµåå±¤ç´å°æ¯å­¸ç¿ãæå¾ï¼æåè¨­è¨äºä¸åäºåè¨ºæ·æ¨¡çµï¼çµåç¥ç¶è¨ºæ·å½æ¸ï¼ä»¥ææå»ºæ¨¡æ±è·èèè·åä¹éçå¤å±¤æ¬¡æåäºåéç¨ï¼ä¸¦å¼å¥èªç¥æ¸¬éçè«ã

##### **StablePrompt: Automatic Prompt Tuning using Reinforcement Learning for Large Language Models**
2410.07652v1 by Minchan Kwon, Gaeun Kim, Jongsuk Kim, Haeil Lee, Junmo Kim

Finding appropriate prompts for the specific task has become an important
issue as the usage of Large Language Models (LLM) has expanded. Reinforcement
Learning (RL) is widely used for prompt tuning, but its inherent instability
and environmental dependency make it difficult to use in practice. In this
paper, we propose StablePrompt, which strikes a balance between training
stability and search space, mitigating the instability of RL and producing
high-performance prompts. We formulate prompt tuning as an online RL problem
between the agent and target LLM and introduce Adaptive Proximal Policy
Optimization (APPO). APPO introduces an LLM anchor model to adaptively adjust
the rate of policy updates. This allows for flexible prompt search while
preserving the linguistic ability of the pre-trained LLM. StablePrompt
outperforms previous methods on various tasks including text classification,
question answering, and text generation. Our code can be found in github.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) çä½¿ç¨æ´å¤§ï¼æ¾å°ç¹å®ä»»åçé©ç¶æç¤ºå·²æçºä¸åéè¦è­°é¡ãå¼·åå­¸ç¿ (RL) å»£æ³ç¨æ¼æç¤ºèª¿æ´ï¼ä½å¶å§å¨çä¸ç©©å®æ§èç°å¢ä¾è³´æ§ä½¿å¶é£ä»¥å¨å¯¦åä¸­ä½¿ç¨ãå¨æ¬æä¸­ï¼æåæåº StablePromptï¼å®å¨è¨ç·´ç©©å®æ§èæå°ç©ºéä¹éåå¾å¹³è¡¡ï¼æ¸è¼ RL çä¸ç©©å®æ§ä¸¦ç¢çé«æ§è½æç¤ºãæåå°æç¤ºèª¿æ´å¶å®çºä»£çèç®æ¨ LLM ä¹éçç·ä¸ RL åé¡ï¼ä¸¦å¼å¥é©ææ§è¿ç«¯ç­ç¥æä½³å (APPO)ãAPPO å¼å¥ LLM é¨å®æ¨¡åä¾é©ææ§èª¿æ´ç­ç¥æ´æ°çéçãéåè¨±éæ´»çæç¤ºæå°ï¼åæä¿çé åè¨ç·´ LLM çèªè¨è½åãStablePrompt å¨åç¨®ä»»åä¸åªæ¼ååçåç¨®æ¹æ³ï¼åæ¬æå­åé¡ãåé¡è§£ç­åæå­çæãæåçç¨å¼ç¢¼å¯ä»¥å¨ github ä¸­æ¾å°ã

##### **Almost Minimax Optimal Best Arm Identification in Piecewise Stationary Linear Bandits**
2410.07638v1 by Yunlong Hou, Vincent Y. F. Tan, Zixin Zhong

We propose a {\em novel} piecewise stationary linear bandit (PSLB) model,
where the environment randomly samples a context from an unknown probability
distribution at each changepoint, and the quality of an arm is measured by its
return averaged over all contexts. The contexts and their distribution, as well
as the changepoints are unknown to the agent. We design {\em
Piecewise-Stationary $\varepsilon$-Best Arm Identification$^+$}
(PS$\varepsilon$BAI$^+$), an algorithm that is guaranteed to identify an
$\varepsilon$-optimal arm with probability $\ge 1-\delta$ and with a minimal
number of samples. PS$\varepsilon$BAI$^+$ consists of two subroutines,
PS$\varepsilon$BAI and {\sc Na\"ive $\varepsilon$-BAI} (N$\varepsilon$BAI),
which are executed in parallel. PS$\varepsilon$BAI actively detects
changepoints and aligns contexts to facilitate the arm identification process.
When PS$\varepsilon$BAI and N$\varepsilon$BAI are utilized judiciously in
parallel, PS$\varepsilon$BAI$^+$ is shown to have a finite expected sample
complexity. By proving a lower bound, we show the expected sample complexity of
PS$\varepsilon$BAI$^+$ is optimal up to a logarithmic factor. We compare
PS$\varepsilon$BAI$^+$ to baseline algorithms using numerical experiments which
demonstrate its efficiency. Both our analytical and numerical results
corroborate that the efficacy of PS$\varepsilon$BAI$^+$ is due to the delicate
change detection and context alignment procedures embedded in
PS$\varepsilon$BAI.

æè¦ï¼<paragraph>æåæåºä¸å{\em æ°ç©ç}åæ®µå¹³ç©©ç·æ§è³­å¾æ© (PSLB) æ¨¡åï¼
å¶ä¸­ç°å¢å¨æ¯åè®æ´é»å¾æªç¥æ©çåä½ä¸­é¨æ©æ½æ¨£ä¸åæå¢ï¼èæèçåè³ªåç±å¶å¨æææå¢ä¸­å¹³ååå ±ä¾è¡¡éãæå¢åå¶åä½ä»¥åè®æ´é»å°ä»£çäººèè¨é½æ¯æªç¥çãæåè¨­è¨äº{\em åæ®µå¹³ç©© $\varepsilon$-æä½³æèè¾¨è­$^+$}
(PS$\varepsilon$BAI$^+$)ï¼éæ¯ä¸åæ¼ç®æ³ï¼ä¿è­è½ä»¥æ©ç $\ge 1-\delta$ ä¸æå°çåæ¨£æ¸ç®æ¾åºä¸å $\varepsilon$-æåªæèãPS$\varepsilon$BAI$^+$ åå«å©åå­å¸¸å¼ï¼PS$\varepsilon$BAI å {\sc æ¨¸ç´  $\varepsilon$-BAI} (N$\varepsilon$BAI)ï¼å®åä¸¦è¡å·è¡ãPS$\varepsilon$BAI ä¸»ååµæ¸¬è®æ´é»ä¸¦èª¿æ´æå¢ä»¥å©æ¼æèè¾¨è­æµç¨ãç¶ PS$\varepsilon$BAI å N$\varepsilon$BAI ä¸¦è¡ææºå°ä½¿ç¨æï¼PS$\varepsilon$BAI$^+$ å·²é¡¯ç¤ºå·ææéé æåæ¨£è¤éåº¦ãééè­æä¸çï¼æåé¡¯ç¤º PS$\varepsilon$BAI$^+$ çé æåæ¨£è¤éåº¦æä½³ï¼æå¤å·®ä¸åå°æ¸å å­ãæåä½¿ç¨æ¸å¼å¯¦é©å° PS$\varepsilon$BAI$^+$ èåºç·æ¼ç®æ³é²è¡æ¯è¼ï¼è­æå¶æçãæåçåæåæ¸å¼çµæé½è­å¯¦ PS$\varepsilon$BAI$^+$ çæè½æ­¸å æ¼ PS$\varepsilon$BAI ä¸­åµå¥çç²¾ç´°è®æ´åµæ¸¬åæå¢èª¿æ´ç¨åºã</paragraph>

##### **Automatic Curriculum Expert Iteration for Reliable LLM Reasoning**
2410.07627v1 by Zirui Zhao, Hanze Dong, Amrita Saha, Caiming Xiong, Doyen Sahoo

Hallucinations (i.e., generating plausible but inaccurate content) and
laziness (i.e. excessive refusals or defaulting to "I don't know") persist as
major challenges in LLM reasoning. Current efforts to reduce hallucinations
primarily focus on factual errors in knowledge-grounded tasks, often neglecting
hallucinations related to faulty reasoning. Meanwhile, some approaches render
LLMs overly conservative, limiting their problem-solving capabilities. To
mitigate hallucination and laziness in reasoning tasks, we propose Automatic
Curriculum Expert Iteration (Auto-CEI) to enhance LLM reasoning and align
responses to the model's capabilities--assertively answering within its limits
and declining when tasks exceed them. In our method, Expert Iteration explores
the reasoning trajectories near the LLM policy, guiding incorrect paths back on
track to reduce compounding errors and improve robustness; it also promotes
appropriate "I don't know" responses after sufficient reasoning attempts. The
curriculum automatically adjusts rewards, incentivizing extended reasoning
before acknowledging incapability, thereby pushing the limits of LLM reasoning
and aligning its behaviour with these limits. We compare Auto-CEI with various
SOTA baselines across logical reasoning, mathematics, and planning tasks, where
Auto-CEI achieves superior alignment by effectively balancing assertiveness and
conservativeness.

æè¦ï¼å¹»è¦ºï¼ä¾å¦ç¢çä¼¼æ¯èéä½æèª¤çå§å®¹ï¼åæ¶æ°ï¼ä¾å¦éåº¦æçµæé è¨­çºãæä¸ç¥éãï¼ä»ç¶æ¯ LLM æ¨çä¸­çä¸»è¦ææ°ãç®åæ¸å°å¹»è¦ºçåªåä¸»è¦éä¸­æ¼åºæ¼ç¥è­çä»»åä¸­çäºå¯¦é¯èª¤ï¼èç¶å¸¸å¿½ç¥èé¯èª¤æ¨çç¸éçå¹»è¦ºãåæï¼æäºæ¹æ³æè® LLM éæ¼ä¿å®ï¼éå¶å¶åé¡è§£æ±ºè½åãçºäºæ¸è¼æ¨çä»»åä¸­çå¹»è¦ºåæ¶æ°ï¼æåæåºèªåèª²ç¨å°å®¶è¿­ä»£ (Auto-CEI) ä¾å¢å¼· LLM æ¨çï¼ä¸¦è®åæèæ¨¡åçè½åä¿æä¸è´ââå¨å¶éå¶ç¯åå§èªä¿¡å°åç­ï¼ä¸¦å¨ä»»åè¶åºå¶è½åç¯åææçµãå¨æåçæ¨¡åä¸­ï¼å°å®¶è¿­ä»£æ¢ç´¢ LLM ç­ç¥éè¿çæ¨çè»è·¡ï¼å¼å°ä¸æ­£ç¢ºçè·¯ç·åå°æ­£è»ï¼ä»¥æ¸å°ç´¯ç©é¯èª¤ä¸¦æé«ç©©å¥æ§ï¼å®éé©ç¶å°å¨ç¶éè¶³å¤ çæ¨çåè©¦å¾ä¿é²ãæä¸ç¥éãçåæãèª²ç¨æèªåèª¿æ´çåµï¼å¨æ¿èªç¡è½çºåä¹åæ¿åµå»¶ä¼¸æ¨çï¼å¾èæ´å± LLM æ¨ççéå¶ï¼ä¸¦è®å¶è¡çºèéäºéå¶ä¿æä¸è´ãæåå¨éè¼¯æ¨çãæ¸å­¸åè¦åä»»åä¸­å° Auto-CEI èåç¨® SOTA åºæºé²è¡æ¯è¼ï¼çµæç¼ç¾ Auto-CEI ééææå¹³è¡¡èªä¿¡åä¿å®æåº¦ï¼éå°äºåè¶çä¸è´æ§ã

##### **Moyun: A Diffusion-Based Model for Style-Specific Chinese Calligraphy Generation**
2410.07618v1 by Kaiyuan Liu, Jiahao Mei, Hengyu Zhang, Yihuai Zhang, Xingjiao Wu, Daoguo Dong, Liang He

Although Chinese calligraphy generation has achieved style transfer,
generating calligraphy by specifying the calligrapher, font, and character
style remains challenging. To address this, we propose a new Chinese
calligraphy generation model 'Moyun' , which replaces the Unet in the Diffusion
model with Vision Mamba and introduces the TripleLabel control mechanism to
achieve controllable calligraphy generation. The model was tested on our
large-scale dataset 'Mobao' of over 1.9 million images, and the results
demonstrate that 'Moyun' can effectively control the generation process and
produce calligraphy in the specified style. Even for calligraphy the
calligrapher has not written, 'Moyun' can generate calligraphy that matches the
style of the calligrapher.

æè¦ï¼åç®¡ä¸­ææ¸æ³çæå·²éæé¢¨æ ¼è½ç§»ï¼ä½ééæå®æ¸æ³å®¶ãå­ååå­é«é¢¨æ ¼ä¾çææ¸æ³ä»å·ææ°æ§ãçºäºè§£æ±ºéååé¡ï¼æåæåºä¸åæ°çä¸­ææ¸æ³çææ¨¡åãå¢¨é²ãï¼å®ç¨ Vision Mamba åä»£ Diffusion æ¨¡åä¸­ç Unetï¼ä¸¦å¼å¥ TripleLabel æ§å¶æ©å¶ä¾éæå¯æ§çæ¸æ³çæãè©²æ¨¡åå·²å¨æåè¶é 190 è¬å¼µåççå¤§è¦æ¨¡è³æéãå¢¨å¯¶ãä¸­é²è¡æ¸¬è©¦ï¼çµæè¡¨æãå¢¨é²ãå¯ä»¥ææå°æ§å¶çæéç¨ï¼ä¸¦ç¢çæå®é¢¨æ ¼çæ¸æ³ãå³ä½¿å°æ¼æ¸æ³å®¶æªå¯«éçæ¸æ³ï¼ãå¢¨é²ãä¹è½çæèæ¸æ³å®¶é¢¨æ ¼ç¸ç¬¦çæ¸æ³ã


### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-07**|**CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**|Ekaterina Sviridova et.al.|[2410.05235v2](http://arxiv.org/abs/2410.05235v2)|null|
|**2024-10-01**|**Explainable Diagnosis Prediction through Neuro-Symbolic Integration**|Qiuhao Lu et.al.|[2410.01855v1](http://arxiv.org/abs/2410.01855v1)|null|
|**2024-10-01**|**Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**|Prasenjit Maji et.al.|[2410.00366v1](http://arxiv.org/abs/2410.00366v1)|null|
|**2024-09-20**|**Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**|Tirtha Chanda et.al.|[2409.13476v1](http://arxiv.org/abs/2409.13476v1)|null|
|**2024-09-19**|**Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**|Suryansh Vidya et.al.|[2409.15374v1](http://arxiv.org/abs/2409.15374v1)|null|
|**2024-09-19**|**Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**|Daniel Flores-Araiza et.al.|[2409.12883v1](http://arxiv.org/abs/2409.12883v1)|null|
|**2024-09-18**|**Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**|Yubo Li et.al.|[2409.12087v1](http://arxiv.org/abs/2409.12087v1)|null|
|**2024-09-09**|**Explainable AI: Definition and attributes of a good explanation for health AI**|Evangelia Kyrimi et.al.|[2409.15338v1](http://arxiv.org/abs/2409.15338v1)|null|
|**2024-08-30**|**Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**|Antonio Rago et.al.|[2408.17401v1](http://arxiv.org/abs/2408.17401v1)|null|
|**2024-08-29**|**A Survey for Large Language Models in Biomedicine**|Chong Wang et.al.|[2409.00133v1](http://arxiv.org/abs/2409.00133v1)|null|
|**2024-08-27**|**Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**|Francesco Sovrano et.al.|[2408.15121v1](http://arxiv.org/abs/2408.15121v1)|null|
|**2024-08-24**|**Towards Case-based Interpretability for Medical Federated Learning**|Laura Latorre et.al.|[2408.13626v1](http://arxiv.org/abs/2408.13626v1)|null|
|**2024-08-22**|**AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**|Douwe J. Spaanderman et.al.|[2408.12491v1](http://arxiv.org/abs/2408.12491v1)|null|
|**2024-08-14**|**Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**|Kimji N. Pellano et.al.|[2409.00001v1](http://arxiv.org/abs/2409.00001v1)|null|
|**2024-08-06**|**MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**|Hanchen David Wang et.al.|[2408.11837v1](http://arxiv.org/abs/2408.11837v1)|null|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**|Michele Fiori et.al.|[2408.06352v1](http://arxiv.org/abs/2408.06352v1)|null|
|**2024-07-21**|**Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**|Naseem Khan et.al.|[2408.03335v1](http://arxiv.org/abs/2408.03335v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v2](http://arxiv.org/abs/2407.05440v2)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v2](http://arxiv.org/abs/2407.15851v2)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v3](http://arxiv.org/abs/2406.16908v3)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. ZajÄc et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel MirÃ³-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|SÃ©amus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Cause and Effect: Can Large Language Models Truly Understand Causality?**|Swagata Ashwani et.al.|[2402.18139v3](http://arxiv.org/abs/2402.18139v3)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|TimothÃ©e Schmude et.al.|[2401.13324v5](http://arxiv.org/abs/2401.13324v5)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|
|**2023-11-21**|**Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**|Robert Gorwa et.al.|[2311.12573v3](http://arxiv.org/abs/2311.12573v3)|null|
|**2023-11-20**|**Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**|Muta Tah Hira et.al.|[2311.11932v1](http://arxiv.org/abs/2311.11932v1)|null|
|**2023-11-18**|**Representing visual classification as a linear combination of words**|Shobhit Agarwal et.al.|[2311.10933v1](http://arxiv.org/abs/2311.10933v1)|[link](https://github.com/lotterlab/task_word_explainability)|
|**2023-11-03**|**Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**|Emma A. M. Stanley et.al.|[2311.02115v2](http://arxiv.org/abs/2311.02115v2)|[link](https://github.com/estanley16/simba)|
|**2023-10-29**|**Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**|Adam White et.al.|[2310.19174v1](http://arxiv.org/abs/2310.19174v1)|null|
|**2023-10-03**|**Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**|Hossein Shreim et.al.|[2310.01828v2](http://arxiv.org/abs/2310.01828v2)|[link](https://github.com/geoaigroup/geoai-ecrs2023)|
|**2023-09-26**|**Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**|Muhammad Aurangzeb Ahmad et.al.|[2311.01463v1](http://arxiv.org/abs/2311.01463v1)|null|
|**2023-09-20**|**When to Trust AI: Advances and Challenges for Certification of Neural Networks**|Marta Kwiatkowska et.al.|[2309.11196v1](http://arxiv.org/abs/2309.11196v1)|null|
|**2023-09-19**|**Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**|Juan M. GarcÃ­a-GÃ³mez et.al.|[2309.10424v1](http://arxiv.org/abs/2309.10424v1)|null|
|**2023-09-19**|**QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**|Thanveer Shaik et.al.|[2309.10293v3](http://arxiv.org/abs/2309.10293v3)|null|
|**2023-09-18**|**Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**|Adarsa Sivaprasad et.al.|[2309.09917v1](http://arxiv.org/abs/2309.09917v1)|null|
|**2023-08-28**|**Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**|Yanjun Gao et.al.|[2308.14321v1](http://arxiv.org/abs/2308.14321v1)|null|
|**2023-08-18**|**Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**|Yun Xin Teoh et.al.|[2308.09380v1](http://arxiv.org/abs/2308.09380v1)|null|
|**2023-08-16**|**Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**|Munib Mesinovic et.al.|[2308.08407v1](http://arxiv.org/abs/2308.08407v1)|null|
|**2023-08-11**|**FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**|Karim Lekadir et.al.|[2309.12325v3](http://arxiv.org/abs/2309.12325v3)|null|
|**2023-08-10**|**Explainable AI applications in the Medical Domain: a systematic review**|Nicoletta Prentzas et.al.|[2308.05411v1](http://arxiv.org/abs/2308.05411v1)|null|
|**2023-08-01**|**Exploring the Role of Explainability in AI-Assisted Embryo Selection**|Lucia Urcelay et.al.|[2308.02534v1](http://arxiv.org/abs/2308.02534v1)|null|
|**2023-07-26**|**A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**|Timo Speith et.al.|[2307.14246v1](http://arxiv.org/abs/2307.14246v1)|null|
|**2023-07-26**|**Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**|Barnaby Crook et.al.|[2307.14239v1](http://arxiv.org/abs/2307.14239v1)|null|

#### Abstracts
##### **CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**
2410.05235v2 by Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri

Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.

æè¦ï¼è§£éäººå·¥æºæ§ (AI) çæ±ºç­æ¯ç¾å¨ AI çä¸é éå¤§ææ°ï¼ç¹å¥æ¯æç¨æ¼åé«å­¸åæ³å¾ç­æææå¢æãç¶èï¼è§£éæ±ºç­èå¾çç±çéæ±ä¹æ¯åºæ¼äººé¡çèéçä¸åä¸»è¦åé¡ï¼å çºæå¿è¦è­æçºä»éº¼ååºæåæ±ºç­ãä¾å¦ï¼ä½é¢é«å¸«ä¸åéè¦æä¾ï¼å¯è½æ¯æ­£ç¢ºçï¼è¨ºæ·ï¼ééè¦è§£éä»åå¦ä½éææåçµè«ãå æ­¤ï¼éç¼æ°çå·¥å·ä¾å¹«å©ä½é¢é«å¸«è¨ç·´ä»åçè§£éæå·§æ¯æè²ä¸­ AI çä¸é æ ¸å¿ç®æ¨ãå¨æ¬æä¸­ï¼æåéµå¾ªéåæ¹åï¼ä¸¦ä¸æ ¹ææåçäºè§£ï¼æåºç¬¬ä¸åå¤èªè¨é«å­¸åç­è³æéï¼å¶ä¸­è¨åºçä¾çæ­£ç¢ºåä¸æ­£ç¢ºè¨ºæ·é½éæç±é«çæ°å¯«çèªç¶èªè¨è§£éãéäºè§£éå·²ä½¿ç¨è«è­çµæï¼å³åæãä¸»å¼µï¼åè«è­éä¿ï¼å³æ»æãæ¯æï¼é²è¡æåè¨»è§£ï¼ç¢çå¤èªè¨ CasiMedicos-Arg è³æéï¼å¶ä¸­åå« 558 åå·æè§£éçåç¨®èªè¨ï¼è±èªãè¥¿ç­çèªãæ³èªãç¾©å¤§å©èªï¼çè¨åºçä¾ï¼æåè¨»è§£äº 5021 åä¸»å¼µã2313 ååæã2431 åæ¯æéä¿å 1106 åæ»æéä¿ãæåæå¾å±ç¤ºäºç«¶ç­åºæºå¦ä½éå°è«è­æ¢åä»»åå·è¡æ­¤å·ææ°æ§çè³æéã

##### **Explainable Diagnosis Prediction through Neuro-Symbolic Integration**
2410.01855v1 by Qiuhao Lu, Rui Li, Elham Sagheb, Andrew Wen, Jinlian Wang, Liwei Wang, Jungwei W. Fan, Hongfang Liu

Diagnosis prediction is a critical task in healthcare, where timely and
accurate identification of medical conditions can significantly impact patient
outcomes. Traditional machine learning and deep learning models have achieved
notable success in this domain but often lack interpretability which is a
crucial requirement in clinical settings. In this study, we explore the use of
neuro-symbolic methods, specifically Logical Neural Networks (LNNs), to develop
explainable models for diagnosis prediction. Essentially, we design and
implement LNN-based models that integrate domain-specific knowledge through
logical rules with learnable thresholds. Our models, particularly
$M_{\text{multi-pathway}}$ and $M_{\text{comprehensive}}$, demonstrate superior
performance over traditional models such as Logistic Regression, SVM, and
Random Forest, achieving higher accuracy (up to 80.52\%) and AUROC scores (up
to 0.8457) in the case study of diabetes prediction. The learned weights and
thresholds within the LNN models provide direct insights into feature
contributions, enhancing interpretability without compromising predictive
power. These findings highlight the potential of neuro-symbolic approaches in
bridging the gap between accuracy and explainability in healthcare AI
applications. By offering transparent and adaptable diagnostic models, our work
contributes to the advancement of precision medicine and supports the
development of equitable healthcare solutions. Future research will focus on
extending these methods to larger and more diverse datasets to further validate
their applicability across different medical conditions and populations.

æè¦ï¼è¨ºæ·é æ¸¬æ¯é«çä¿å¥ä¸­çä¸é ééµä»»åï¼åæä¸æºç¢ºå°è­å¥é«ççæ³æå°æ£èççµæç¢çéå¤§å½±é¿ãå³çµ±æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åå·²å¨æ­¤é ååå¾é¡¯èæåï¼ä½éå¸¸ç¼ºä¹å¯è§£éæ§ï¼éæ¯è¨åºç°å¢ä¸­çééµè¦æ±ãå¨æ¬ç ç©¶ä¸­ï¼æåæ¢è¨äºç¥ç¶ç¬¦èæ¹æ³ï¼ç¹å¥æ¯éè¼¯ç¥ç¶ç¶²è·¯ (LNN)ï¼ä»¥éç¼å¯è§£éçè¨ºæ·é æ¸¬æ¨¡åãåºæ¬ä¸ï¼æåè¨­è¨ä¸¦å¯¦ä½äºåºæ¼ LNN çæ¨¡åï¼è©²æ¨¡åéééè¼¯è¦ååå¯å­¸ç¿çé¾å¼æ´åé åç¹å®çç¥è­ãæåçæ¨¡åï¼ç¹å¥æ¯ $M_{\text{multi-pathway}}$ å $M_{\text{comprehensive}}$ï¼è¡¨ç¾åºåªæ¼å³çµ±æ¨¡åï¼å¦éè¼¯è¿´æ­¸ãSVM åé¨æ©æ£®æï¼çåè¶æè½ï¼å¨ç³å°¿çé æ¸¬çæ¡ä¾ç ç©¶ä¸­ï¼éå°äºæ´é«çæºç¢ºåº¦ï¼é«é 80.52%ï¼å AUROC åæ¸ï¼é«é 0.8457ï¼ãLNN æ¨¡åä¸­å­¸ç¿çæ¬éåé¾å¼æä¾äºå°ç¹å¾µè²¢ç»çç´æ¥è¦è§£ï¼å¢å¼·äºå¯è§£éæ§ï¼åæä¸æå®³é æ¸¬è½åãéäºç¼ç¾çªé¡¯äºç¥ç¶ç¬¦èæ¹æ³å¨å½åé«çä¿å¥ AI æç¨ä¸­æºç¢ºæ§åå¯è§£éæ§å·®è·æ¹é¢çæ½åãééæä¾éæä¸é©ææ§å¼·çè¨ºæ·æ¨¡åï¼æåçç ç©¶æå©æ¼ç²¾æºé«ççé²æ­¥ï¼ä¸¦æ¯æ´å¬å¹³é«çä¿å¥è§£æ±ºæ¹æ¡çéç¼ãæªä¾çç ç©¶å°å°æ³¨æ¼å°éäºæ¹æ³æ´å±å°æ´å¤§ä¸æ´å¤æ¨£åçè³æéï¼ä»¥é²ä¸æ­¥é©è­å¶å¨ä¸åé«ççæ³åäººç¾¤ä¸­çé©ç¨æ§ã

##### **Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**
2410.00366v1 by Prasenjit Maji, Amit Kumar Mondal, Hemanta Kumar Mondal, Saraju P. Mohanty

The rapid advancements in artificial intelligence (AI) have revolutionized
smart healthcare, driving innovations in wearable technologies, continuous
monitoring devices, and intelligent diagnostic systems. However, security,
explainability, robustness, and performance optimization challenges remain
critical barriers to widespread adoption in clinical environments. This
research presents an innovative algorithmic method using the Adaptive Feature
Evaluator (AFE) algorithm to improve feature selection in healthcare datasets
and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable
Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT),
the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby
enhancing predictive accuracy and interpretability. The proposed method is
validated across three diverse healthcare datasets using six distinct machine
learning algorithms, demonstrating its robustness and superiority over
conventional feature selection techniques. The results underscore the
transformative potential of AFE in smart healthcare, enabling personalized and
transparent patient care. Notably, the AFE algorithm, when combined with a
Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting
its capability to improve clinical decision-making processes in real-world
healthcare applications.

æè¦ï¼äººå·¥æºæ§ (AI) çå¿«éé²å±å¾¹åºæ¹è®äºæºæ§é«çä¿å¥ï¼æ¨åäºå¯ç©¿æ´æè¡ãæçºç£æ§è£ç½®åæºæ§è¨ºæ·ç³»çµ±çåµæ°ãç¶èï¼å®å¨æ§ãå¯è§£éæ§ãç©©å¥æ§åæè½æä½³åææ°ä»ç¶æ¯è¨åºç°å¢ä¸­å»£æ³æ¡ç¨çééµéç¤ãæ¬ç ç©¶æåºä¸ååµæ°çæ¼ç®æ³æ¹æ³ï¼ä½¿ç¨èªé©æç¹å¾µè©ä¼°å¨ (AFE) æ¼ç®æ³ä¾æ¹åé«çä¿å¥è³æéä¸­çç¹å¾µé¸åä¸¦åæåé¡ãAFE æ´åäºéºå³æ¼ç®æ³ (GA)ãå¯è§£éäººå·¥æºæ§ (XAI) åæåçµåæè¡ (PCT)ï¼è©²æ¼ç®æ³æä½³åäºè¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS)ï¼å¾èæé«äºé æ¸¬æºç¢ºæ§åå¯è§£éæ§ãææåºçæ¹æ³ä½¿ç¨å­ç¨®ä¸åçæ©å¨å­¸ç¿æ¼ç®æ³é©è­äºä¸åä¸åçé«çä¿å¥è³æéï¼è­æäºå¶ç©©å¥æ§ååªæ¼å³çµ±ç¹å¾µé¸åæè¡ãçµæå¼·èª¿äº AFE å¨æºæ§é«çä¿å¥ä¸­çè½è®æ½åï¼å¯¦ç¾äºåäººååéæçæ£èç§è­·ãå¼å¾æ³¨æçæ¯ï¼AFE æ¼ç®æ³èå¤å±¤æç¥å¨ (MLP) çµåä½¿ç¨æï¼æºç¢ºåº¦é«é 98.5%ï¼çªé¡¯äºå¶æ¹åå¯¦éé«çä¿å¥æç¨ä¸­è¨åºæ±ºç­å¶å®æµç¨çè½åã

##### **Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**
2409.13476v1 by Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker

Artificial intelligence (AI) systems have substantially improved
dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI)
systems further enhancing clinicians' confidence and trust in AI-driven
decisions. Despite these advancements, there remains a critical need for
objective evaluation of how dermatologists engage with both AI and XAI tools.
In this study, 76 dermatologists participated in a reader study, diagnosing 16
dermoscopic images of melanomas and nevi using an XAI system that provides
detailed, domain-specific explanations. Eye-tracking technology was employed to
assess their interactions. Diagnostic performance was compared with that of a
standard AI system lacking explanatory features. Our findings reveal that XAI
systems improved balanced diagnostic accuracy by 2.8 percentage points relative
to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and
complex lesions were associated with elevated cognitive load, as evidenced by
increased ocular fixations. These insights have significant implications for
clinical practice, the design of AI tools for visual tasks, and the broader
development of XAI in medical diagnostics.

æè¦ï¼äººå·¥æºæ§ (AI) ç³»çµ±å·²å¤§å¹æ¹åç®èç§é«å¸«å°é»è²ç´ ç¤çè¨ºæ·æºç¢ºåº¦ï¼èå¯è§£é AI (XAI) ç³»çµ±é²ä¸æ­¥æåè¨åºé«å¸«å° AI é©åæ±ºç­çä¿¡å¿èä¿¡è³´ãåç®¡æéäºé²å±ï¼å°æ¼ç®èç§é«å¸«å¦ä½ä½¿ç¨ AI å XAI å·¥å·ï¼ä»æå®¢è§è©ä¼°çè¿«åéæ±ãå¨éé ç ç©¶ä¸­ï¼76 ä½ç®èç§é«å¸«åèäºä¸é è®èç ç©¶ï¼ä½¿ç¨ XAI ç³»çµ±è¨ºæ· 16 å¼µé»è²ç´ ç¤åç£çç®èé¡å½±åï¼è©²ç³»çµ±æä¾è©³ç´°çé åç¹å®èªªæãæ¡ç¨ç¼çè¿½è¹¤æè¡ä¾è©ä¼°ä»åçäºåãå°è¨ºæ·è¡¨ç¾èç¼ºä¹èªªæåè½çæ¨æº AI ç³»çµ±é²è¡æ¯è¼ãæåçç ç©¶çµæé¡¯ç¤ºï¼XAI ç³»çµ±ç¸è¼æ¼æ¨æº AIï¼å°å¹³è¡¡è¨ºæ·æºç¢ºåº¦æåäº 2.8 åç¾åé»ãæ­¤å¤ï¼è AI/XAI ç³»çµ±çè¨ºæ·åæ­§åè¤éççç¶èèªç¥è² æåé«æéï¼éç±å¢å çç¼çæ³¨è¦æ¬¡æ¸æè­å¯¦ãéäºè¦è§£å°è¨åºå¯¦åãè¦è¦ºä»»å AI å·¥å·çè¨­è¨åé«å­¸è¨ºæ·ä¸­ XAI çå»£æ³ç¼å±å·æéå¤§æç¾©ã

##### **Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**
2409.15374v1 by Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar

Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been
shown to significantly improve the quality of life of autistic individuals.
However, diagnostics methods for ASD rely on assessments based on clinical
presentation that are prone to bias and can be challenging to arrive at an
early diagnosis. There is a need for objective biomarkers of ASD which can help
improve diagnostic accuracy. Deep learning (DL) has achieved outstanding
performance in diagnosing diseases and conditions from medical imaging data.
Extensive research has been conducted on creating models that classify ASD
using resting-state functional Magnetic Resonance Imaging (fMRI) data. However,
existing models lack interpretability. This research aims to improve the
accuracy and interpretability of ASD diagnosis by creating a DL model that can
not only accurately classify ASD but also provide explainable insights into its
working. The dataset used is a preprocessed version of the Autism Brain Imaging
Data Exchange (ABIDE) with 884 samples. Our findings show a model that can
accurately classify ASD and highlight critical brain regions differing between
ASD and typical controls, with potential implications for early diagnosis and
understanding of the neural basis of ASD. These findings are validated by
studies in the literature that use different datasets and modalities,
confirming that the model actually learned characteristics of ASD and not just
the dataset. This study advances the field of explainable AI in medical imaging
by providing a robust and interpretable model, thereby contributing to a future
with objective and reliable ASD diagnostics.

æè¦ï¼èªéçè­ç³»éç¤ (ASD) çæ©æè¨ºæ·åä»å¥å·²è¢«è­å¯¦è½é¡¯èæ¹åèªéçæ£èççæ´»åè³ªãç¶èï¼ASD çè¨ºæ·æ¹æ³ä¾è³´æ¼åºæ¼è¨åºè¡¨ç¾çè©ä¼°ï¼å®¹æç¢çåè¦ï¼ä¸å¯è½é£ä»¥ååºæ©æè¨ºæ·ãæå¿è¦æ¾åº ASD çå®¢è§çç©æ¨è¨ï¼ä»¥å¹«å©æé«è¨ºæ·æºç¢ºæ§ãæ·±åº¦å­¸ç¿ (DL) å¨å¾é«å­¸å½±åè³æè¨ºæ·ç¾çåççæ¹é¢åå¾ååºçè¡¨ç¾ãå·²ç¶éå°å»ºç«ä½¿ç¨éæåè½æ§ç£æ¯é å½± (fMRI) è³æå° ASD é²è¡åé¡çæ¨¡åé²è¡å»£æ³çç ç©¶ãç¶èï¼ç¾æçæ¨¡åç¼ºä¹å¯è§£éæ§ãæ¬ç ç©¶æ¨å¨ééå»ºç«ä¸åä¸åè½æºç¢ºåé¡ ASDï¼éè½æä¾å¯è§£éè¦è§£èªªæå¶éä½åçç DL æ¨¡åï¼ä¾æ¹å ASD è¨ºæ·çæºç¢ºæ§åå¯è§£éæ§ãæä½¿ç¨çè³æéæ¯èªéçå¤§è¦å½±åè³æäº¤æ (ABIDE) çé èççæ¬ï¼åå« 884 åæ¨£æ¬ãæåçç ç©¶çµæé¡¯ç¤ºï¼è©²æ¨¡åè½æºç¢ºåé¡ ASDï¼ä¸¦å¼·èª¿ ASD èå¸åå°ç§çµä¹éå­å¨å·®ç°çééµè¦åï¼å°æ¼ ASD çæ©æè¨ºæ·åç¥ç¶åºç¤ççè§£å·ææ½å¨çæç¾©ãéäºç ç©¶çµæå·²ç±ä½¿ç¨ä¸åè³æéåæ¹å¼çæç»ç ç©¶é©è­ï¼è­å¯¦è©²æ¨¡åå¯¦éä¸å­¸ç¿äº ASD çç¹å¾µï¼èä¸ååæ¯è³æéãæ¬ç ç©¶ééæä¾ä¸åå¼·å¥ä¸å¯è§£éçæ¨¡åï¼æ¨åäºé«å­¸å½±åä¸­å¯è§£é AI çé åï¼å¾èçºæªä¾æä¾å®¢è§ä¸å¯é ç ASD è¨ºæ·ååºè²¢ç»ã

##### **Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**
2409.12883v1 by Daniel Flores-Araiza, Francisco Lopez-Tiro, ClÃ©ment Larose, Salvador Hinojosa, Andres Mendez-Vazquez, Miguel Gonzalez-Mendoza, Gilberto Ochoa-Ruiz, Christian Daul

The in-vivo identification of the kidney stone types during an ureteroscopy
would be a major medical advance in urology, as it could reduce the time of the
tedious renal calculi extraction process, while diminishing infection risks.
Furthermore, such an automated procedure would make possible to prescribe
anti-recurrence treatments immediately. Nowadays, only few experienced
urologists are able to recognize the kidney stone types in the images of the
videos displayed on a screen during the endoscopy. Thus, several deep learning
(DL) models have recently been proposed to automatically recognize the kidney
stone types using ureteroscopic images. However, these DL models are of black
box nature whicl limits their applicability in clinical settings. This
contribution proposes a case-based reasoning DL model which uses prototypical
parts (PPs) and generates local and global descriptors. The PPs encode for each
class (i.e., kidney stone type) visual feature information (hue, saturation,
intensity and textures) similar to that used by biologists. The PPs are
optimally generated due a new loss function used during the model training.
Moreover, the local and global descriptors of PPs allow to explain the
decisions ("what" information, "where in the images") in an understandable way
for biologists and urologists. The proposed DL model has been tested on a
database including images of the six most widespread kidney stone types. The
overall average classification accuracy was 90.37. When comparing this results
with that of the eight other DL models of the kidney stone state-of-the-art, it
can be seen that the valuable gain in explanability was not reached at the
expense of accuracy which was even slightly increased with respect to that
(88.2) of the best method of the literature. These promising and interpretable
results also encourage urologists to put their trust in AI-based solutions.

æè¦ï¼å°¿è·¯é¡æª¢æ¥ä¸­èçµç³é¡åçé«å§è­å¥å°æ¯æ³å°¿ç§çä¸é éå¤§é²å±ï¼å çºå®å¯ä»¥æ¸å°ç¹ç£çèçµç³ååºéç¨çæéï¼åæéä½ææé¢¨éªãæ­¤å¤ï¼éç¨®èªååç¨åºå°ä½¿ç«å³éç«æå¾©ç¼æ²»çæçºå¯è½ãå¦ä»ï¼åªæå°æ¸ç¶é©è±å¯çæ³å°¿ç§é«çè½å¤ å¨å§è¦é¡æª¢æ¥æéå±å¹ä¸é¡¯ç¤ºçè¦é »ååä¸­è­å¥èçµç³é¡åãå æ­¤ï¼æè¿å·²æåºå¤ç¨®æ·±åº¦å­¸ç¿ (DL) æ¨¡åï¼ä»¥ä½¿ç¨è¼¸å°¿ç®¡é¡ååèªåè­å¥èçµç³é¡åãç¶èï¼éäº DL æ¨¡åæ¬è³ªä¸æ¯é»çå­ï¼ééå¶äºå®åå¨è¨åºç°å¢ä¸­çæç¨æ§ãæ¬ææåºäºä¸ååºæ¼æ¡ä¾æ¨çç DL æ¨¡åï¼å®ä½¿ç¨ååé¨å (PP) ä¸¦çæå±é¨åå¨å±æè¿°ç¬¦ãPP çºæ¯ç¨®é¡åï¼å³èçµç³é¡åï¼ç·¨ç¢¼è¦è¦ºç¹å¾µä¿¡æ¯ï¼è²èª¿ãé£½ååº¦ãå¼·åº¦åç´çï¼ï¼é¡ä¼¼æ¼çç©å­¸å®¶ä½¿ç¨çä¿¡æ¯ãç±æ¼å¨æ¨¡åè¨ç·´æéä½¿ç¨çæ°æå¤±å½æ¸ï¼PP å¾å°äºæä½³çæãæ­¤å¤ï¼PP çå±é¨åå¨å±æè¿°ç¬¦åè¨±ä»¥çç©å­¸å®¶åæ³å°¿ç§é«çå¯ä»¥çè§£çæ¹å¼è§£éæ±ºç­ï¼âä»éº¼âä¿¡æ¯ï¼âååä¸­çä»éº¼ä½ç½®âï¼ãææåºç DL æ¨¡åå·²å¨ä¸ååå«å­ç¨®æå»£æ³çèçµç³é¡åååçæ¸æåº«ä¸é²è¡äºæ¸¬è©¦ãç¸½é«å¹³ååé¡æºç¢ºççº 90.37ãå°æ­¤çµæèèçµç³æåé²çå«åå¶ä» DL æ¨¡åççµæé²è¡æ¯è¼æï¼å¯ä»¥çåºï¼å¯è§£éæ§çå¯¶è²´å¢çä¸¦æªä»¥æºç¢ºæ§çºä»£å¹ï¼çè³ç¥æå¢å èæç»ä¸­æå¥½çæ¹æ³ (88.2) ç¸æ¯ãéäºæå¸æä¸å¯è§£éççµæä¹é¼åµæ³å°¿ç§é«çç¸ä¿¡åºæ¼äººå·¥æºè½çè§£æ±ºæ¹æ¡ã

##### **Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**
2409.12087v1 by Yubo Li, Saba Al-Sayouri, Rema Padman

This study explores the potential of utilizing administrative claims data,
combined with advanced machine learning and deep learning techniques, to
predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal
Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major
health insurance organization to develop prediction models for multiple
observation windows using traditional machine learning methods such as Random
Forest and XGBoost as well as deep learning approaches such as Long Short-Term
Memory (LSTM) networks. Our findings demonstrate that the LSTM model,
particularly with a 24-month observation window, exhibits superior performance
in predicting ESRD progression, outperforming existing models in the
literature. We further apply SHapley Additive exPlanations (SHAP) analysis to
enhance interpretability, providing insights into the impact of individual
features on predictions at the individual patient level. This study underscores
the value of leveraging administrative claims data for CKD management and
predicting ESRD progression.

æè¦ï¼æ¬ç ç©¶æ¢è¨å©ç¨è¡æ¿ç´¢è³ è³æçæ½åï¼çµåé²éæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æè¡ï¼é æ¸¬æ¢æ§èèç (CKD) é²å±è³æ«æèèç¾ç (ESRD)ãæååæç±ä¸å®¶å¤§åå¥åº·ä¿éªçµç¹æä¾çåå¹´ç¶åè³æéï¼ä½¿ç¨å³çµ±æ©å¨å­¸ç¿æ¹æ³ï¼ä¾å¦é¨æ©æ£®æå XGBoostï¼ä»¥åæ·±åº¦å­¸ç¿æ¹æ³ï¼ä¾å¦é·ç­æè¨æ¶ (LSTM) ç¶²è·¯ï¼éç¼å¤åè§å¯ææ®µçé æ¸¬æ¨¡åãæåçç ç©¶çµæè¡¨æï¼LSTM æ¨¡åï¼ç¹å¥æ¯å·æ 24 åæçè§å¯ææ®µï¼å¨é æ¸¬ ESRD é²å±æ¹é¢è¡¨ç¾åªç°ï¼åªæ¼æç»ä¸­çç¾ææ¨¡åãæåé²ä¸æ­¥æç¨ SHapley å æ³è§£é (SHAP) åæä¾å¢å¼·å¯è§£éæ§ï¼æ·±å¥äºè§£åå¥ç¹å¾µå°åå¥æ£èå±¤ç´é æ¸¬çå½±é¿ãæ¬ç ç©¶å¼·èª¿äºå©ç¨è¡æ¿ç´¢è³ è³æé²è¡ CKD ç®¡çåé æ¸¬ ESRD é²å±çå¹å¼ã

##### **Explainable AI: Definition and attributes of a good explanation for health AI**
2409.15338v1 by Evangelia Kyrimi, Scott McLachlan, Jared M Wohlgemut, Zane B Perkins, David A. Lagnado, William Marsh, the ExAIDSS Expert Group

Proposals of artificial intelligence (AI) solutions based on increasingly
complex and accurate predictive models are becoming ubiquitous across many
disciplines. As the complexity of these models grows, transparency and users'
understanding often diminish. This suggests that accurate prediction alone is
insufficient for making an AI-based solution truly useful. In the development
of healthcare systems, this introduces new issues related to accountability and
safety. Understanding how and why an AI system makes a recommendation may
require complex explanations of its inner workings and reasoning processes.
Although research on explainable AI (XAI) has significantly increased in recent
years and there is high demand for XAI in medicine, defining what constitutes a
good explanation remains ad hoc, and providing adequate explanations continues
to be challenging. To fully realize the potential of AI, it is critical to
address two fundamental questions about explanations for safety-critical AI
applications, such as health-AI: (1) What is an explanation in health-AI? and
(2) What are the attributes of a good explanation in health-AI? In this study,
we examined published literature and gathered expert opinions through a
two-round Delphi study. The research outputs include (1) a definition of what
constitutes an explanation in health-AI and (2) a comprehensive list of
attributes that characterize a good explanation in health-AI.

æè¦ï¼é¨èè¶ä¾è¶è¤éä¸æºç¢ºçé æ¸¬æ¨¡åï¼åºæ¼äººå·¥æºæ§ (AI) è§£æ±ºæ¹æ¡çææ¡å¨è¨±å¤é åä¸­è®å¾ç¡èä¸å¨ãé¨èéäºæ¨¡åè¤éæ§çå¢å ï¼éæåº¦åä½¿ç¨èççè§£åå¾å¾æéä½ãéè¡¨ç¤ºåææºç¢ºçé æ¸¬ä¸¦ä¸è¶³ä»¥è® AI è§£æ±ºæ¹æ¡çæ­£æç¨ãå¨é«çä¿å¥ç³»çµ±çéç¼ä¸­ï¼éå¼å¥äºèåè²¬å¶åå®å¨æ§ç¸éçæ°åé¡ãç­è§£ AI ç³»çµ±å¦ä½ä»¥åçºä½æåºå»ºè­°å¯è½éè¦å°å¶å§é¨éä½åæ¨çéç¨é²è¡è¤éçèªªæãåç®¡è¿å¹´ä¾å°å¯è§£é AI (XAI) çç ç©¶å·²å¤§å¹å¢å ï¼ä¸é«å­¸é åå° XAI æå¾é«çéæ±ï¼ä½å®ç¾©ä»éº¼æ§æä¸åå¥½çè§£éä»æ¯è¨ææ§çï¼èæä¾é©ç¶çè§£éä»ç¶å·æææ°æ§ãçºäºååç¼æ® AI çæ½åï¼å°æ¼å®å¨ééµå AI æç¨ï¼ä¾å¦å¥åº· AIï¼çè§£éï¼æ¢è¨å©ååºæ¬åé¡è³ééè¦ï¼(1) ä»éº¼æ¯å¥åº· AI ä¸­çè§£éï¼ä»¥å (2) å¥åº· AI ä¸­ä¸åå¥½çè§£éæåªäºå±¬æ§ï¼å¨æ¬ç ç©¶ä¸­ï¼æåæª¢è¦äºå·²ç¼è¡¨çæç»ï¼ä¸¦ééå©è¼ªå¾·ç¾è²ç ç©¶æ¶éäºå°å®¶æè¦ãç ç©¶ææåæ¬ï¼(1) å¥åº· AI ä¸­ä»éº¼æ§æè§£éçå®ç¾©ï¼ä»¥å (2) å¥åº· AI ä¸­ä¸åå¥½è§£éçå±¬æ§æ¸å®ã

##### **Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**
2408.17401v1 by Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni

In recent years, various methods have been introduced for explaining the
outputs of "black-box" AI models. However, it is not well understood whether
users actually comprehend and trust these explanations. In this paper, we focus
on explanations for a regression tool for assessing cancer risk and examine the
effect of the explanations' content and format on the user-centric metrics of
comprehension and trust. Regarding content, we experiment with two explanation
methods: the popular SHAP, based on game-theoretic notions and thus potentially
complex for everyday users to comprehend, and occlusion-1, based on feature
occlusion which may be more comprehensible. Regarding format, we present SHAP
explanations as charts (SC), as is conventional, and occlusion-1 explanations
as charts (OC) as well as text (OT), to which their simpler nature also lends
itself. The experiments amount to user studies questioning participants, with
two different levels of expertise (the general population and those with some
medical training), on their subjective and objective comprehension of and trust
in explanations for the outputs of the regression tool. In both studies we
found a clear preference in terms of subjective comprehension and trust for
occlusion-1 over SHAP explanations in general, when comparing based on content.
However, direct comparisons of explanations when controlling for format only
revealed evidence for OT over SC explanations in most cases, suggesting that
the dominance of occlusion-1 over SHAP explanations may be driven by a
preference for text over charts as explanations. Finally, we found no evidence
of a difference between the explanation types in terms of objective
comprehension. Thus overall, the choice of the content and format of
explanations needs careful attention, since in some contexts format, rather
than content, may play the critical role in improving user experience.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼å·²ç¶å¼é²åç¨®æ¹æ³ä¾è§£éãé»ç®±ãAI æ¨¡åçè¼¸åºãç¶èï¼ç®åä¸¦ä¸æ¸æ¥ä½¿ç¨èæ¯å¦å¯¦éçè§£åä¿¡ä»»éäºè§£éãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼è©ä¼°ççé¢¨éªçåæ­¸å·¥å·çè§£éï¼ä¸¦æ¢è¨è§£éçå§å®¹åæ ¼å¼å°ä»¥ä½¿ç¨èçºä¸­å¿ççè§£åä¿¡ä»»ææ¨çå½±é¿ãéæ¼å§å®¹ï¼æåå¯¦é©äºå©ç¨®è§£éæ¹æ³ï¼æµè¡ç SHAPï¼åºæ¼åå¼è«æ¦å¿µï¼å æ­¤å°æ¼æ¥å¸¸ä½¿ç¨èä¾èªªå¯è½å¾è¤éï¼ä»¥ååºæ¼ç¹å¾µé®è½ç occlusion-1ï¼å¯è½æ´ææ¼çè§£ãéæ¼æ ¼å¼ï¼æåå° SHAP è§£éåç¾çºåè¡¨ (SC)ï¼éæ¯æ£ä¾ï¼èå° occlusion-1 è§£éåç¾çºåè¡¨ (OC) ä»¥åæå­ (OT)ï¼å¶è¼çºç°¡å®çæ§è³ªä¹é©ç¨æ¼æ­¤ãéäºå¯¦é©ç­åæ¼ä½¿ç¨èç ç©¶ï¼è©¢ååèèï¼å·æå©ç¨®ä¸åç¨åº¦çå°æ¥­ç¥è­ï¼ä¸è¬æ°ç¾åå·åä¸äºé«å­¸è¨ç·´çäººï¼ï¼ä»åå°åæ­¸å·¥å·è¼¸åºè§£éçä¸»è§åå®¢è§çè§£åä¿¡ä»»ãå¨å©é ç ç©¶ä¸­ï¼æåç¼ç¾ï¼å¨åºæ¼å§å®¹é²è¡æ¯è¼æï¼ä¸è¬ä¾èªªï¼occlusion-1 åªæ¼ SHAP è§£éï¼å¨ä¸»è§çè§£åä¿¡ä»»æ¹é¢ææé¡¯çåå¥½ãç¶èï¼å¨åæ§å¶æ ¼å¼çææ³ä¸ç´æ¥æ¯è¼è§£éï¼å¨å¤§å¤æ¸ææ³ä¸åªé¡¯ç¤º OT åªæ¼ SC è§£éçè­æï¼éè¡¨æ occlusion-1 åªæ¼ SHAP è§£éçä¸»å°å°ä½å¯è½æ¯ç±åå¥½æå­èéåè¡¨ä½çºè§£éæé©åçãæå¾ï¼æåæ²æç¼ç¾è§£éé¡åå¨å®¢è§çè§£æ¹é¢çå·®ç°è­æãå æ­¤ï¼ç¸½é«èè¨ï¼å°è§£éçå§å®¹åæ ¼å¼çé¸æéè¦ä»ç´°æ³¨æï¼å çºå¨æäºææ³ä¸ï¼æ ¼å¼èéå§å®¹ï¼å¯è½å¨æ¹åä½¿ç¨èé«é©æ¹é¢ç¼æ®ééµä½ç¨ã</paragraph>

##### **A Survey for Large Language Models in Biomedicine**
2409.00133v1 by Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro LiÃ², Tianyun Wang, Yu Guang Wang, Yiqing Shen

Recent breakthroughs in large language models (LLMs) offer unprecedented
natural language understanding and generation capabilities. However, existing
surveys on LLMs in biomedicine often focus on specific applications or model
architectures, lacking a comprehensive analysis that integrates the latest
advancements across various biomedical domains. This review, based on an
analysis of 484 publications sourced from databases including PubMed, Web of
Science, and arXiv, provides an in-depth examination of the current landscape,
applications, challenges, and prospects of LLMs in biomedicine, distinguishing
itself by focusing on the practical implications of these models in real-world
biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot
learning across a broad spectrum of biomedical tasks, including diagnostic
assistance, drug discovery, and personalized medicine, among others, with
insights drawn from 137 key studies. Then, we discuss adaptation strategies of
LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to
enhance their performance in specialized biomedical contexts where zero-shot
fails to achieve, such as medical question answering and efficient processing
of biomedical literature. Finally, we discuss the challenges that LLMs face in
the biomedicine domain including data privacy concerns, limited model
interpretability, issues with dataset quality, and ethics due to the sensitive
nature of biomedical data, the need for highly reliable model outputs, and the
ethical implications of deploying AI in healthcare. To address these
challenges, we also identify future research directions of LLM in biomedicine
including federated learning methods to preserve data privacy and integrating
explainable AI methodologies to enhance the transparency of LLMs.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çææ°çªç ´æä¾äºåææªæçèªç¶èªè¨çè§£åçæè½åãç¶èï¼ç¾æéæ¼çç©é«å­¸ä¸­ LLM çèª¿æ¥éå¸¸å°æ³¨æ¼ç¹å®æç¨ææ¨¡åæ¶æ§ï¼ç¼ºä¹æ´ååç¨®çç©é«å­¸é åææ°é²å±çå¨é¢åæãæ¬ç¶è¿°åºæ¼å°ä¾èª PubMedãWeb of Science å arXiv ç­æ¸æåº«ç 484 ç¯åºçç©çåæï¼æ·±å¥æ¢è¨äºçç©é«å­¸ä¸­ LLM çç¶åç¾æ³ãæç¨ãææ°ååæ¯ï¼å¶ç¹é»æ¯éæ³¨éäºæ¨¡åå¨ç¾å¯¦ä¸ççç©é«å­¸èæ¯ä¸­çå¯¦éæç¨ãé¦åï¼æåæ¢è¨äº LLM å¨å»£æ³ççç©é«å­¸ä»»åä¸­çé¶æ¬¡å­¸ç¿è½åï¼åæ¬è¨ºæ·è¼å©ãè¥ç©ç¼ç¾ååæ§åé«çç­ï¼ä¸¦å¾ 137 é ééµç ç©¶ä¸­æ±²åè¦è§£ãç¶å¾ï¼æåè¨è«äº LLM çé©æç­ç¥ï¼åæ¬å®æ¨¡æåå¤æ¨¡æ LLM çå¾®èª¿æ¹æ³ï¼ä»¥å¢å¼·å®åå¨é¶æ¬¡å­¸ç¿ç¡æ³å¯¦ç¾çå°æ¥­çç©é«å­¸èæ¯ä¸­çæ§è½ï¼ä¾å¦é«çåé¡è§£ç­åçç©é«å­¸æç»çææèçãæå¾ï¼æåè¨è«äº LLM å¨çç©é«å­¸é åé¢è¨çææ°ï¼åæ¬æ¸æé±ç§åé¡ãæ¨¡åå¯è§£éæ§æéãæ¸æéè³ªéåé¡ä»¥åç±æ¼çç©é«å­¸æ¸æçæææ§ãå°é«åº¦å¯é æ¨¡åè¼¸åºçéæ±ä»¥åå¨é«çä¿å¥ä¸­é¨ç½² AI çå«çå½±é¿èç¢ççå«çåé¡ãçºäºæå°éäºææ°ï¼æåéç¢ºå®äºçç©é«å­¸ä¸­ LLM æªä¾çç ç©¶æ¹åï¼åæ¬ç¨æ¼ä¿è­·æ¸æé±ç§çè¯åå­¸ç¿æ¹æ³ä»¥åæ´åå¯è§£é AI æ¹æ³ä»¥å¢å¼· LLM çéæåº¦ã

##### **Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**
2408.15121v1 by Francesco Sovrano, Michael Lognoul, Giulia Vilone

Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å¨é«çåä¿å¥æç¨ä¸­æå¥äºå¤§éçæè³åéç¼ï¼é²èå°è´é«çæè¡ä¸­çåé²æ§å¶ç³»çµ±ãç¶èï¼AI ç³»çµ±çä¸éææ§å¼ç¼äºå°æ­¤é¡æææç¨ä¸­æéåºæ¬ç¹æ§çææï¼ä¾å¦éæåº¦åå¯ä¿¡åº¦ãæåçç ç©¶ééèª¿æ¥ä¸åç¨åºä¾è§£æ±ºéäºåé¡ï¼ç¨æ¼é¸ææååçå¯è§£é AIï¼XAIï¼æ¹æ³ï¼ä»¥ç¬¦åæ­çæ³è¦å¨é«çå¨æçæºæ§åçç©é»å­å­¸ä¸­çèªªæè¦æ±ãæ¡ç¨çæ¹æ³å¾ééå¶æ§å¶æ©å¶ï¼éè¿´è·¯ãéè¿´è·¯ååéè¿´è·¯ç³»çµ±ï¼å°æºæ§åè£ç½®é²è¡åé¡ï¼ä¸¦æ·±å¥æ¢è¨å¶æè¡éå§ãç¶å¾ï¼æååæéäºæ³è¦ä»¥å®ç¾©å¶å°åç¨®è£ç½®åç¸éç®æ¨çå¯è§£éæ§è¦æ±ãåæï¼æåééå¶èªªæç®æ¨å° XAI æ¹æ³é²è¡åé¡ãéåè¨±å°æ³å¾å¯è§£éæ§è¦æ±è XAI èªªæç®æ¨ç¸å¹éï¼ä¸¦ç¢ºå®é©ç¶ç XAI æ¼ç®æ³ä¾éæå®åãæåçç ç©¶çµææä¾äºå°åªäº XAI æ¼ç®æ³æ´ç¬¦åæ­çæ³è¦ä»¥é©ç¨æ¼ä¸åé¡åçé«çå¨æçç´°ç·»çè§£ãæåééä¸åç¥ç¶æ¤å¥ç©çå¯¦éæ¡ä¾ç ç©¶ä¾è­æéä¸é»ï¼å¾æ¢æ§ç¾çç®¡çå°åé²çç¾©è¢ãéé ç ç©¶å¡«è£äºå°çç©é»å­å­¸ä¸­ç XAI æç¨èæ­çæ³è¦çå´æ ¼è¦å®ç¸ç¬¦çéè¦ç©ºç½ãå®çºéç¼äººå¡åç ç©¶äººå¡æä¾äºä¸åå¯¦ç¨çæ¶æ§ï¼ç¢ºä¿å¶ AI åµæ°è½ä¿é²é«çæè¡ä¸¦éµå®æ³å¾åéå¾·æ¨æºã

##### **Towards Case-based Interpretability for Medical Federated Learning**
2408.13626v1 by Laura Latorre, Liliana Petrychenko, Regina Beets-Tan, Taisiya Kopytova, Wilson Silva

We explore deep generative models to generate case-based explanations in a
medical federated learning setting. Explaining AI model decisions through
case-based interpretability is paramount to increasing trust and allowing
widespread adoption of AI in clinical practice. However, medical AI training
paradigms are shifting towards federated learning settings in order to comply
with data protection regulations. In a federated scenario, past data is
inaccessible to the current user. Thus, we use a deep generative model to
generate synthetic examples that protect privacy and explain decisions. Our
proof-of-concept focuses on pleural effusion diagnosis and uses publicly
available Chest X-ray data.

æè¦ï¼æåæ¢ç´¢æ·±åº¦çææ¨¡åï¼å¨é«çè¯é¦å­¸ç¿è¨­ç½®ä¸­çæåºæ¼æ¡ä¾çèªªæãééåºæ¼æ¡ä¾çå¯è§£éæ§ä¾è§£é AI æ¨¡åæ±ºç­ï¼å°æ¼å¢å ä¿¡ä»»ä¸¦åè¨± AI å¨è¨åºå¯¦åä¸­å»£æ³æ¡ç¨è³ééè¦ãç¶èï¼é«ç AI è¨ç·´ç¯ä¾æ­£è½åè¯é¦å­¸ç¿è¨­ç½®ï¼ä»¥ç¬¦åè³æä¿è­·æ³è¦ãå¨è¯é¦æå¢ä¸­ï¼éå»çè³æå°ç®åçä½¿ç¨èèè¨æ¯ç¡æ³åå¾çãå æ­¤ï¼æåä½¿ç¨æ·±åº¦çææ¨¡åä¾ç¢çä¿è­·é±ç§åè§£éæ±ºç­çåæç¯ä¾ãæåçæ¦å¿µé©è­èéæ¼è¸èç©æ¶²è¨ºæ·ï¼ä¸¦ä½¿ç¨å¬éå¯åå¾çè¸é¨ X åè³æã

##### **AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**
2408.12491v1 by Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, Jacob J. Visser, Robert Hemke, Kirsten van Langevelde, David F. Hanff, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. GruÃ¼hagen, Wiro J. Niessen, Stefan Klein, Martijn P. A. Starmans

Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging
lesions with variable clinical behaviours and treatment approaches. This
systematic review provides an overview of Artificial Intelligence (AI) methods
using radiological imaging for diagnosis and prognosis of these tumours,
highlighting challenges in clinical translation, and evaluating study alignment
with the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI
international consensus guidelines for trustworthy and deployable AI to promote
the clinical translation of AI methods. The review covered literature from
several bibliographic databases, including papers published before 17/07/2024.
Original research in peer-reviewed journals focused on radiology-based AI for
diagnosing or prognosing primary STBT was included. Exclusion criteria were
animal, cadaveric, or laboratory studies, and non-English papers. Abstracts
were screened by two of three independent reviewers for eligibility. Eligible
papers were assessed against guidelines by one of three independent reviewers.
The search identified 15,015 abstracts, from which 325 articles were included
for evaluation. Most studies performed moderately on CLAIM, averaging a score
of 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 out
of 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,
indicating significant room for improvement. Future efforts by AI developers
should focus on design (e.g. define unmet clinical need, intended clinical
setting and how AI would be integrated in clinical workflow), development (e.g.
build on previous work, explainability), evaluation (e.g. evaluating and
addressing biases, evaluating AI against best practices), and data
reproducibility and availability (making documented code and data publicly
available). Following these recommendations could improve clinical translation
of AI methods.

æè¦ï¼è»çµç¹åéª¨éª¼è«ç¤ï¼STBTï¼æ¯ç½è¦ãè¨ºæ·å·æææ°æ§ççç¶ï¼å¶è¨åºè¡çºåæ²»çæ¹æ³åä¸ç¸åãéç¯ç³»çµ±æ§åé¡§æä¾äºä½¿ç¨æ¾å°å½±åé²è¡è¨ºæ·åé å¾çäººå·¥æºæ§ (AI) æ¹æ³çæ¦è§ï¼éé»èªªæäºè¨åºè½è­¯çææ°ï¼ä¸¦è©ä¼°ç ç©¶èé«çå½±å AI æ ¸æ¥è¡¨ (CLAIM) å FUTURE-AI å¯ä¿¡è³´ä¸å¯é¨ç½² AI çåéå±è­æºåçä¸è´æ§ï¼ä»¥ä¿é² AI æ¹æ³çè¨åºè½è­¯ãéç¯åé¡§æ¶µèäºå¹¾åæ¸ç®è³æåº«ä¸­çæç»ï¼åæ¬å¨ 2024 å¹´ 7 æ 17 æ¥ä¹åç¼è¡¨çè«æãç´å¥äºä»¥æ¾å°çºåºç¤ç AI è¨ºæ·æé å¾åç¼æ§ STBT çåè¡è©å¯©æåä¸­çåå§ç ç©¶ãæé¤æ¨æºæ¯åç©ãå±é«æå¯¦é©å®¤ç ç©¶ï¼ä»¥åéè±æè«æãæè¦ç±ä¸ä½ç¨ç«å¯©æ¥å¡ä¸­çå©ä½ç¯©é¸è³æ ¼ãåæ ¼çè«æç±ä¸ä½ç¨ç«å¯©æ¥å¡ä¸­çä¸ä½æ ¹ææºåé²è¡è©ä¼°ãæç´¢è­å¥åº 15,015 ç¯æè¦ï¼å¶ä¸­ 325 ç¯æç« è¢«ç´å¥è©ä¼°ãå¤§å¤æ¸ç ç©¶å¨ CLAIM ä¸­è¡¨ç¾ä¸­ç­ï¼å¹³åå¾åçº 53 åä¸­ç 28.9Â±7.5 åï¼ä½å¨ FUTURE-AI ä¸­è¡¨ç¾ä¸ä½³ï¼å¹³åå¾åçº 30 åä¸­ç 5.1Â±2.1 åãSTBT çå½±å AI å·¥å·ä»èæ¼æ¦å¿µé©è­éæ®µï¼è¡¨ææé¡¯èçæ¹é²ç©ºéãAI éç¼äººå¡æªä¾çåªåæéä¸­å¨è¨­è¨ï¼ä¾å¦å®ç¾©æªæ»¿è¶³çè¨åºéæ±ãé æçè¨åºç°å¢ä»¥å AI å¦ä½æ´åå°è¨åºå·¥ä½æµç¨ä¸­ï¼ãéç¼ï¼ä¾å¦å»ºç«å¨ååçå·¥ä½ãå¯è§£éæ§ï¼ãè©ä¼°ï¼ä¾å¦è©ä¼°åè§£æ±ºåå·®ãè©ä¼° AI èæä½³å¯¦åï¼ãä»¥åæ¸æå¯è¤è£½æ§åå¯ç¨æ§ï¼å¬éæä¾æä»¶åçä»£ç¢¼åæ¸æï¼ãéµå¾ªéäºå»ºè­°å¯ä»¥æ¹å AI æ¹æ³çè¨åºè½è­¯ã

##### **Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**
2409.00001v1 by Kimji N. Pellano, Inga StrÃ¼mke, Daniel Groos, Lars Adde, Espen Alexander F. Ihlen

Early detection of Cerebral Palsy (CP) is crucial for effective intervention
and monitoring. This paper tests the reliability and applicability of
Explainable AI (XAI) methods using a deep learning method that predicts CP by
analyzing skeletal data extracted from video recordings of infant movements.
Specifically, we use XAI evaluation metrics -- namely faithfulness and
stability -- to quantitatively assess the reliability of Class Activation
Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this
specific medical application. We utilize a unique dataset of infant movements
and apply skeleton data perturbations without distorting the original dynamics
of the infant movements. Our CP prediction model utilizes an ensemble approach,
so we evaluate the XAI metrics performances for both the overall ensemble and
the individual models. Our findings indicate that both XAI methods effectively
identify key body points influencing CP predictions and that the explanations
are robust against minor data perturbations. Grad-CAM significantly outperforms
CAM in the RISv metric, which measures stability in terms of velocity. In
contrast, CAM performs better in the RISb metric, which relates to bone
stability, and the RRS metric, which assesses internal representation
robustness. Individual models within the ensemble show varied results, and
neither CAM nor Grad-CAM consistently outperform the other, with the ensemble
approach providing a representation of outcomes from its constituent models.

æè¦ï¼è¦æ§éº»çº (CP) çæ©æåµæ¸¬å°æ¼ææçä»å¥åç£æ¸¬è³ééè¦ãæ¬ææ¸¬è©¦äºå¯è§£é AI (XAI) æ¹æ³çå¯é æ§åé©ç¨æ§ï¼ä½¿ç¨æ·±åº¦å­¸ç¿æ¹æ³ï¼ééåæå¾å¬°ååä½å½±çè¨éä¸­æåçéª¨éª¼è³æä¾é æ¸¬ CPãå·é«ä¾èªªï¼æåä½¿ç¨ XAI è©ä¼°ææ¨ï¼å³å¿ å¯¦åº¦åç©©å®æ§ï¼ä¾éåè©ä¼°é¡å¥æ¿æ´»æ å° (CAM) åæ¢¯åº¦å æ¬é¡å¥æ¿æ´»æ å° (Grad-CAM) å¨éåç¹å®é«çæç¨ä¸­çå¯é æ§ãæåå©ç¨ä¸åç¨ç¹çå¬°ååä½è³æéï¼ä¸¦æç¨éª¨éª¼è³ææ¾åï¼èä¸ææ­æ²å¬°ååä½çåå§ååãæåç CP é æ¸¬æ¨¡åå©ç¨æ´é«æ¹æ³ï¼å æ­¤æåè©ä¼°äºæ´é«æ´é«ååå¥æ¨¡åç XAI ææ¨è¡¨ç¾ãæåçç ç©¶çµæè¡¨æï¼å©ç¨® XAI æ¹æ³é½è½ææè­å¥å½±é¿ CP é æ¸¬çééµèº«é«é¨ä½ï¼ä¸¦ä¸éäºè§£éå°æ¼å¾®å°çè³ææ¾åå·æé­¯æ£æ§ãGrad-CAM å¨ RISv ææ¨ä¸­é¡¯èåªæ¼ CAMï¼è©²ææ¨è¡¡ééåº¦æ¹é¢çç©©å®æ§ãç¸æ¯ä¹ä¸ï¼CAM å¨ RISb ææ¨ä¸­è¡¨ç¾å¾æ´å¥½ï¼è©²ææ¨èéª¨éª¼ç©©å®æ§æéï¼è RRS ææ¨åè©ä¼°å§é¨è¡¨ç¤ºçé­¯æ£æ§ãæ´é«ä¸­çåå¥æ¨¡åé¡¯ç¤ºåºä¸åççµæï¼CAM å Grad-CAM é½ä¸ä¸è´å°åªæ¼å¦ä¸ç¨®ï¼æ´é«æ¹æ³æä¾äºå¶çµææ¨¡åçµæçè¡¨ç¤ºã

##### **MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**
2408.11837v1 by Hanchen David Wang, Nibraas Khan, Anna Chen, Nilanjan Sarkar, Pamela Wisniewski, Meiyi Ma

Recent global estimates suggest that as many as 2.41 billion individuals have
health conditions that would benefit from rehabilitation services. Home-based
Physical Therapy (PT) faces significant challenges in providing interactive
feedback and meaningful observation for therapists and patients. To fill this
gap, we present MicroXercise, which integrates micro-motion analysis with
wearable sensors, providing therapists and patients with a comprehensive
feedback interface, including video, text, and scores. Crucially, it employs
multi-dimensional Dynamic Time Warping (DTW) and attribution-based explainable
methods to analyze the existing deep learning neural networks in monitoring
exercises, focusing on a high granularity of exercise. This synergistic
approach is pivotal, providing output matching the input size to precisely
highlight critical subtleties and movements in PT, thus transforming complex AI
analysis into clear, actionable feedback. By highlighting these micro-motions
in different metrics, such as stability and range of motion, MicroXercise
significantly enhances the understanding and relevance of feedback for
end-users. Comparative performance metrics underscore its effectiveness over
traditional methods, such as a 39% and 42% improvement in Feature Mutual
Information (FMI) and Continuity. MicroXercise is a step ahead in home-based
physical therapy, providing a technologically advanced and intuitively helpful
solution to enhance patient care and outcomes.

æè¦ï¼æè¿çå¨çä¼°è¨è¡¨æï¼å¤é 24.1 åäººæ
å¥åº·çæ³å¯å¾å¾©å¥æåä¸­åçãå±å®¶
ç©çæ²»ç (PT) å¨æä¾äºåå¼
åé¥åææç¾©çè§å¯æ¹é¢é¢è¨éå¤§ææ°ï¼ä¾æ²»çå¸«åæ£èä½¿ç¨ãçºäºå¡«è£é
åç¼ºå£ï¼æåæåº MicroXerciseï¼å®å°å¾®åä½åæè
å¯ç©¿æ´å¼ææ¸¬å¨æ´åå¨ä¸èµ·ï¼çºæ²»çå¸«åæ£èæä¾ä¸åå¨é¢ç
åé¥ä»é¢ï¼åæ¬å½±çãæå­ååæ¸ãè³ééè¦çæ¯ï¼å®æ¡ç¨
å¤ç¶­åææéè¦æ´ (DTW) ååºæ¼æ­¸å çå¯è§£é
æ¹æ³ä¾åæç£æ§éåä¸­ç¾æçæ·±åº¦å­¸ç¿ç¥ç¶ç¶²è·¯ï¼å°æ³¨æ¼éåçé«ç²åº¦ãéç¨®åå
æ¹æ³è³ééè¦ï¼æä¾èè¼¸å¥å¤§å°å¹éçè¼¸åºï¼ä»¥ç²¾ç¢ºå°
çªåº PT ä¸­ééµçç´°å¾®å·®å¥ååä½ï¼å¾èå°è¤éç AI
åæè½æçºæ¸æ°ãå¯æä½çåé¥ãééå¨ä¸åææ¨ä¸­çªé¡¯éäºå¾®åä½ï¼ä¾å¦ç©©å®æ§ååä½ç¯åï¼MicroXercise
é¡¯èæåæçµä½¿ç¨èå°åé¥ççè§£åç¸éæ§ãæ¯è¼æè½ææ¨å¼·èª¿å¶åªæ¼
å³çµ±æ¹æ³çæææ§ï¼ä¾å¦ç¹å¾µäºæ è³è¨ (FMI) åé£çºæ§åå¥æåäº 39% å 42%ãMicroXercise å¨å±å®¶
ç©çæ²»çæ¹é¢æ´é²ä¸æ­¥ï¼æä¾æè¡åé²ä¸ç´è¦ºæç¨ç
è§£æ±ºæ¹æ¡ï¼ä»¥æåæ£èç§è­·åçµæã

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah RÃ¶sman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

æè¦ï¼ç³»çµ±æ§æç»åé¡§æ¯ç ç©¶ä¸­è­æåè³ªæé«çãç¶èï¼åé¡§éç¨åå°é¡¯èè³æºåè³æéå¶çé»ç¤ãæç»åé¡§ç¶²è·¯ (LRN) æ¯ç¬¬ä¸åéµå¾ª PRISMA 2020 æ¨æºçå¯è§£é AI å¹³å°ï¼æ¨å¨èªååæ´åæç»åé¡§éç¨ãLRN å¨å¤ç§æå¥å¯¦åé åä¸­é²è¡è©ä¼°ï¼ä½¿ç¨å°å®¶éç¼ç 3 åæå°å­ä¸²ä¾æ¥è©¢ PubMedãéå°å®¶è¨ç·´ææ LRN æ¨¡åãæè½ä»¥å°å®¶æååé¡§ä½çºåºæºãå¯è§£éæ§åæè½ææ¨è©ä¼° LRN è¤è£½å°å®¶åé¡§çè½åãä¸è´æ§ä»¥ Jaccard ææ¸åæ··æ·ç©é£æ¸¬éãç ç©¶äººå¡å¨ç ç©¶å®æåå°å½¼æ­¤ççµæä¿å¯ãéççç ç©¶æ´åå° LRN çæçç³»çµ±æ§åé¡§ä¸­ãLRN æ¨¡åå¨æ²æå°å®¶è¨ç·´çææ³ä¸å±ç¾åºåªç°çåé¡æºç¢ºçï¼éå° 84.78% å 85.71% çæºç¢ºçãæè½æé«çæ¨¡åéå°äºé«è©åèéä¿¡è³´åº¦ (k = 0.4953) åå¯è§£éæ§ææ¨ï¼å°ãæ¸å°ãããæå¤ãåãé³å©ãèãééæ´æå¥ãé£çµå¨ä¸èµ·ãå¦ä¸å LRN æ¨¡åæ¶µèäº 91.51% çç¸éæç»ï¼åç®¡èéå°å®¶çå¤æ·ä¸å (k = 0.2174)ï¼ä½åå«äºãä¹³è ãããééãï¼æå¥ï¼åãé©æçãç­è©å½ãLRN åªæ¼æååé¡§ï¼11 åæè¶é 19,920 åéï¼ï¼å°æ´åéç¨ç¸®ç­çº 5 å¤©è¶é 288.6 åéãéé ç ç©¶é¡¯ç¤ºï¼å¯è§£éç AI ä¸éè¦å°å®¶è¨ç·´å³å¯æåé²è¡å°å®¶ç­ç´ç PRISMA ç¸å®¹ç³»çµ±æ§æç»åé¡§ãLRN ç¸½çµäºå¤ç§æå¥ç ç©¶ççµæï¼ä¸¦æ¾åºèè¨åºç ç©¶äººå¡ç¼ç¾å¹¾ä¹ç¸åçä¸»é¢ãå¯è§£éç AI å¯ä»¥æºç¢ºå°å å¿«æåå°è¨åºå¯¦åççè§£ï¼ææ½åé©æ°é«çä¿å¥ç ç©¶ã

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

æè¦ï¼æ¬ç ç©¶ä½¿ç¨çå­å­¸æ¡æ¶åææ··åäººå·¥æºæ§ç³»çµ±çè¨­è¨æ¨¡å¼åå¶å¨è¨åºæ±ºç­ä¸­çæææ§ãå®åé¡ä¸¦æ¯è¼çµåæ©å¨å­¸ç¿ååºæ¼è¦åçæ¨ççåç¨®æ¶æ§ï¼ä»¥æ·±å¥äºè§£å¶çµæ§åºç¤åé«çä¿å¥æç¨ãéå°å©åä¸»è¦åé¡ï¼å¦ä½æ ¹ææ¢å®çè¨­è¨æ¨¡å¼å°éäºç³»çµ±é²è¡åé¡ï¼ä»¥åå¦ä½ééæ¯è¼åææåè¦è§£ï¼æ¬ç ç©¶ä½¿ç¨è»é«å·¥ç¨ä¸­çè¨­è¨æ¨¡å¼ä¾äºè§£ååªåé«çä¿å¥äººå·¥æºæ§ç³»çµ±ãçå­å­¸æå©æ¼è­å¥å±æ§ä¸¦å»ºç«å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡ï¼å¾èå¢å¼·éäºç³»çµ±çå¯æ´åæ§ãå¯é æ§åæè½ãæª¢æ¥äºäºç¨®ä¸»è¦çæ¶æ§ï¼REMLãMLRBãRBMLãRMLT å PERMLãæ¯ç¨®æ¶æ§é½æç¨ç¹çåªç¼ºé»ï¼å¼·èª¿äºå¨è¨åºä»»åä¸­éè¦éèº«æé çæ¹æ³ãREML å¨è³ææéçè³æéä¸­è¡¨ç¾åºé«ç²¾åº¦çé æ¸¬ï¼MLRB å¨èçå¤§åè³æéåè¤éè³ææ´åæ¹é¢è¡¨ç¾åºè²ï¼RBML å¨å¯è§£éæ§åå¯ä¿¡åº¦æ¹é¢è¡¨ç¾åºè²ï¼RMLT å¨ç®¡çé«ç¶­è³ææ¹é¢è¡¨ç¾åºè²ï¼è PERML åç®¡å¨åææ¹é¢æéï¼ä½å¨ç·æ¥ç§è­·å ´æ¯ä¸­è¡¨ç¾åºæ½åãæ¬ç ç©¶å¼å¥äºåç¨®æ°æ¨¡å¼ï¼å»ºç«äºäºç¨®æ½è±¡åé¡æ¨¡å¼ï¼ä¸¦é²ä¸æ­¥å°éäºç¨®æ¨¡å¼ç´°åçºå·é«çç³»çµ±ãéäºè²¢ç»å¢å¼·äºçå­å­¸çåé¡çµç¹ï¼ä¸¦æä¾äºå°å°å®¶ç¥è­èæ©å¨å­¸ç¿æ´åçæ°æ¹æ³ãçå­å­¸ççµæ§åãæ¨¡çµåæ¹æ³å¨éç¼ååææ··åäººå·¥æºæ§ç³»çµ±ãæ­ç¤ºå±æ§ä»¥åæ¨å»£å¯éè¤ä½¿ç¨çè§£æ±ºæ¹æ¡æ¹é¢å·æé¡¯èåªå¢ãç¸½ä¹ï¼æ¬ç ç©¶å¼·èª¿äºæ··åäººå·¥æºæ§ç³»çµ±å¨æ¨é²é«çä¿å¥ä¸­çééµä½ç¨ï¼ä»¥åçå­å­¸å¨æ¨åäººå·¥æºæ§æ´åé²ä¸æ­¥åµæ°æ¹é¢çæ½åï¼æçµæ¹åè¨åºæ±ºç­æ¯æ´åæ£èçæ²»çææã

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

æè¦ï¼ç±æ¼å¶å¼·å¤§çé æ¸¬è½åï¼æ·±åº¦å­¸ç¿å·²æçºè¨±å¤ç¢æ¥­ä¸­ä¸å¯æç¼ºçå·¥å·ï¼åæ¬é«çä¿å¥ãç¶èï¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åéå¸¸ç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸å¿½ç¥äºå°é æ¸¬ä¸ç¢ºå®æ§ç´å¥èéï¼èéå©åå ç´ æ¯è¨åºæ±ºç­å¶å®çééµçµæé¨åãçºäºç¢çå¯è§£éä¸å·æä¸ç¢ºå®æ§æè­çé æ¸¬ï¼æ¬ç ç©¶æåºäºä¸ååçºè²æ°æ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯ (BKAN) çæ°æ¶æ§ï¼å®çµåäºæ¯ç¾è«å¥æ´å¤«é¿è«¾å¾·ç¶²è·¯çè¡¨éè½åèè²æ°æ¨è«ãæåå¨å©åé«å­¸è³æéä¸ä½¿ç¨ BKANï¼éäºè³æéæ¯è©ä¼°æ©å¨å­¸ç¿æ¨¡åå¨é«å­¸è¨ºæ·ä¸­çå»£æ³ä½¿ç¨åºæºï¼ç®é¦¬å°ç¬¬å®äººç³å°¿çè³æéååéå¤«è­å¿èçè³æéãæåçæ¨¡åæä¾äºå°é æ¸¬ä¿¡å¿åæ±ºç­éççæçè¦è§£ï¼ä¸¦ä¸å¨é æ¸¬æºç¢ºåº¦æ¹é¢åªæ¼å³çµ±çæ·±åº¦å­¸ç¿æ¨¡åãæ­¤å¤ï¼BKAN è¡¨ç¾é¨æ©åèªè­ä¸ç¢ºå®æ§çè½åï¼å¯ç¢ºä¿é«çç²å¾æ´å¯é ä¸å¼å¾ä¿¡è³´çæ±ºç­æ¯æ´ãæ ¹æå¯¦é©çµæï¼æåçè²æ°ç­ç¥æé«äºæ¨¡åçå¯è§£éæ§ï¼ä¸¦å¤§å¹æ¸å°äºéåº¦æ¬åï¼éå°æ¼å°åä¸ä¸å¹³è¡¡çé«å­¸è³æééå¸¸éè¦ãæåæåºäºå¯è½çæ´ååè½ï¼ä»¥é²ä¸æ­¥å° BKAN ç¨æ¼æ´è¤éçå¤æ¨¡å¼è³æéï¼ä¸¦æ¢è¨éäºç¼ç¾å°æ¼æªä¾å»ºç«å¯é çé«çä¿å¥ AI ç³»çµ±ç ç©¶çéè¦æ§ãéé å·¥ä½çºæ·±åº¦å­¸ç¿æ¨¡åé¨ç½²å¨éæåº¦åå¯é æ§è³ééè¦çéè¦é åä¸­éåäºä¸åæ°çå¸ç¯ã

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

æè¦ï¼å¨ç¾ä»£é«çä¿å¥ä¸­ï¼è§£æ±ºæºç¢ºç¾çé æ¸¬ååæ§åå»ºè­°çè¤éæ§æ¢è³ééè¦åå·æææ°æ§ãæ¬ç ç©¶å¼å¥äº MLtoGAIï¼å®å°èªç¾©ç¶²è·¯æè¡èæ©å¨å­¸ç¿ (ML) ç¸çµåï¼ä»¥å¢å¼·ç¾çé æ¸¬ä¸¦éé ChatGPT æä¾ä½¿ç¨èååçèªªæãè©²ç³»çµ±åå«ä¸åééµçµæé¨åï¼ä¸åå¯éè¤ä½¿ç¨çç¾çæ¬ä½ï¼å¶ä¸­åå«æéåç¨®ç¾ççè©³ç´°ç¥è­ï¼ä¸åè¨ºæ·åé¡æ¨¡åï¼å®ä½¿ç¨æ£èççä¾æºç¢ºæª¢æ¸¬ç¹å®ç¾çï¼ä»¥åèªç¾©ç¶²è·¯è¦åèªè¨ (SWRL) èæ¬ä½å ChatGPT çæ´åï¼ä»¥ç¢çæ¸æ°ãåæ§åçå¥åº·å»ºè­°ãéç¨®æ¹æ³é¡¯èæé«äºé æ¸¬æºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºææ¼çè§£ççµæï¼è§£æ±ºäºç¾çåä¸åçççè¤éæ§ãMLtoGAI ç³»çµ±å±ç¤ºäºæºç¢ºæ§åä½¿ç¨èæ»¿æåº¦çå¯¦è³ªæ§é²æ­¥ï¼æå©æ¼éç¼æ´æºæ§ä¸æ´ææ¼åå¾çé«çä¿å¥è§£æ±ºæ¹æ¡ãéç¨®åµæ°çæ¹æ³çµåäº ML æ¼ç®æ³çåªé»ï¼ä»¥åéé ChatGPT æä¾éæä¸äººé¡å¯ä»¥çè§£çèªªæçè½åï¼å¨é æ¸¬æºç¢ºæ§åä½¿ç¨èçè§£æ¹é¢åå¾äºé¡¯èçé²æ­¥ãééå©ç¨èªç¾©æè¡åå¯è§£éç AIï¼è©²ç³»çµ±æé«äºç¾çé æ¸¬çæºç¢ºæ§ï¼ä¸¦ç¢ºä¿äºå»ºè­°èåå¥æ£èç¸éä¸ææ¼çè§£ãæåçç ç©¶å¼·èª¿äºæ´ååé²æè¡ä»¥åæé«çè¨ºæ·ä¸­ç¾æææ°çæ½åï¼çºæºæ§é«çä¿å¥ç³»çµ±çæªä¾ç¼å±éªè·¯ãæ­¤å¤ï¼è©²ç³»çµ±ä½¿ç¨ 200 ååææ£èè³æè¨éé²è¡é©è­ï¼ç¢ºä¿äºç©©å¥çæè½åå¯é æ§ã

##### **Introducing Î´-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) æ¯å°äººå·¥æºæ§ (AI) åæ©å¨å­¸ç¿ (ML) æ¼ç®æ³æ´åå°è¨åºå¯¦åä¸­çè¾¯è«æ ¸å¿ãé«å·è¡æè½ç AI/ML æ¨¡åï¼ä¾å¦æ´é«å­¸ç¿å¨åæ·±åº¦ç¥ç¶ç¶²è·¯ï¼éå¸¸ç¼ºä¹å¯è§£éæ§ï¼é»ç¤è¨åºé«çå°å¶é æ¸¬çä¿¡ä»»ãçºäºè§£æ±ºéååé¡ï¼æ­£å¨éç¼ XAI æè¡ï¼ä»¥äººé¡å¯ä»¥çè§£çè¡èªæè¿° AI/ML é æ¸¬ãä¸åæå¸æçæ¹åæ¯æ¡ç¨ææåº¦åæ (SA) åå¨çææåº¦åæ (GSA)ï¼å®åæ¬è³ªä¸æä¾ææ¨¡åè¼¸å¥å°é æ¸¬çå½±é¿ä¾å°å¶é²è¡æåãå¨æ­¤ï¼æåä»ç´¹ä¸ç¨®æ°ç delta-XAI æ¹æ³ï¼ééæ´å GSA ææ¨ delta ææ¸ä¾æä¾ ML æ¨¡åé æ¸¬çå±é¨è§£éãdelta-XAI ææ¸è©ä¼°æ¯åç¹å¾µå¼å°åæ­¸ååé¡åé¡ä¸­åå¥ä¾é çé æ¸¬è¼¸åºä¹å½±é¿ãæåå° delta-XAI ææ¸å½¢å¼åï¼ä¸¦æä¾å¶å¯¦ä½çç¨å¼ç¢¼ãä½¿ç¨ç·æ§åæ­¸æ¨¡åå°æ¨¡æ¬æå¢è©ä¼° delta-XAI æ¹æ³ï¼ä¸¦ä»¥ Shapley å¼ä½çºåºæºãçµæé¡¯ç¤º delta-XAI ææ¸éå¸¸è Shapley å¼ä¸è´ï¼ä½å¨å·æé«åº¦å½±é¿åææ¥µç«¯ç¹å¾µå¼çæ¨¡åä¸­å­å¨é¡¯èå·®ç°ãdelta-XAI ææ¸å¨åµæ¸¬ä¸»è¦ç¹å¾µåèçæ¥µç«¯ç¹å¾µå¼æ¹é¢è¡¨ç¾åºæ´é«çææåº¦ãå®æ§å°ä¾èªªï¼delta-XAI ééå©ç¨æ©çå¯åº¦å½æ¸æä¾ç´è§çè§£éï¼ä½¿ç¹å¾µæåæ´æ¸æ°ä¸å°å¾æ¥­äººå¡ä¾èªªæ´å·å¯è§£éæ§ãç¸½é«èè¨ï¼delta-XAI æ¹æ³å°æ¼ç©©å¥å°åå¾ ML æ¨¡åé æ¸¬çå±é¨è§£éä¼¼ä¹å¾æå¸æãå°å¨çå¯¦ä¸ççè¨åºç°å¢ä¸­é²è¡é²ä¸æ­¥èª¿æ¥ï¼ä»¥è©ä¼°å¶å° AI è¼å©è¨åºå·¥ä½æµç¨çå½±é¿ã

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

æè¦ï¼å¤±æºçæ¯ä¸ç¨®å½±é¿å¨çæ¸ç¾è¬äººçè¡°å¼±æ§ç¥ç¶ç¾çï¼å¨è¨ºæ·ä¸å·æéå¤§ææ°ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°çæ¹æ³ï¼ç¨æ¼å°å¤±æºåéå¤±æºèå¹´æ£èé²è¡åé¡ï¼ä½¿ç¨ 3D å¤§è¦ç£æ¯é å½± (MRI) ææãæåçåæ³æ¡ç¨äºä¸ç¨®ç¨ç¹æè¡ï¼ç¨æ¼é¸ææ§èç MRI åçï¼éé»éæ³¨æç¸éçå¤§è¦ååï¼ä¸¦æé¤ä¿¡æ¯éè¼å°çé¨åãéç¨®æ¹æ³ç±ä¸ååºæ¼ä¿¡å¿çåé¡å§å¡æè£åï¼è©²å§å¡æç±ä¸åèªå®ç¾©æ·±åº¦å­¸ç¿æ¨¡åçµæï¼Dem3D ResNetãDem3D CNN å Dem3D EfficientNetãéäºæ¨¡åååå·¥ä½ä»¥å¢å¼·æ±ºç­çæºç¢ºæ§ï¼å©ç¨å®åçéé«åªå¢ãå¨å½±åç ç©¶éæ¾å­åç³»å (OASIS) è³æéä¸é²è¡æ¸¬è©¦ï¼æåçæ¨¡åéå°äº 94.12% çé©äººæºç¢ºåº¦ï¼è¶éäºç¾ææ¹æ³ãæ­¤å¤ï¼å¨é¿è²æµ·é»çç¥ç¶å½±åå¡è­° (ADNI) è³æéä¸çé©è­è­å¯¦äºæåæ¹æ³çç©©å¥æ§åæ®éæ§ãå¯è§£é AI (XAI) æè¡åå¨é¢çæ¶èç ç©¶é²ä¸æ­¥è­å¯¦äºæåæè¡çæææ§ï¼æä¾äºå°æ±ºç­éç¨åæåæ¹æ³éè¦æ§çè¦è§£ãéé ç ç©¶çºå¤±æºçè¨ºæ·æä¾äºéå¤§é²å±ï¼çºè¨åºæç¨æä¾äºä¸åé«åº¦æºç¢ºä¸é«æçå·¥å·ã

##### **Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**
2408.06352v1 by Michele Fiori, Gabriele Civitarese, Claudio Bettini

Recognizing daily activities with unobtrusive sensors in smart environments
enables various healthcare applications. Monitoring how subjects perform
activities at home and their changes over time can reveal early symptoms of
health issues, such as cognitive decline. Most approaches in this field use
deep learning models, which are often seen as black boxes mapping sensor data
to activities. However, non-expert users like clinicians need to trust and
understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human
Activity Recognition have emerged to provide intuitive natural language
explanations from these models. Different XAI methods generate different
explanations, and their effectiveness is typically evaluated through user
surveys, that are often challenging in terms of costs and fairness. This paper
proposes an automatic evaluation method using Large Language Models (LLMs) to
identify, in a pool of candidates, the best XAI approach for non-expert users.
Our preliminary results suggest that LLM evaluation aligns with user surveys.

æè¦ï¼èç±æºæ§ç°å¢ä¸­ä¸å¼äººæ³¨ç®çææ¸¬å¨è¾¨è­æ¥å¸¸æ´»åï¼è½åç¨åç¨®é«çä¿å¥æç¨ãç£æ§åè©¦èå¨å®¶ä¸­å¦ä½å·è¡æ´»åï¼ä»¥åå¶é¨èæéçè®åï¼å¯ä»¥æ­ç¤ºå¥åº·åé¡çæ©æççï¼ä¾å¦èªç¥è½åä¸éãæ­¤é åä¸­çå¤§å¤æ¸æ¹æ³é½ä½¿ç¨æ·±åº¦å­¸ç¿æ¨¡åï¼éäºæ¨¡åéå¸¸è¢«è¦çºå°ææ¸¬å¨è³æå°æè³æ´»åçé»çå­ãç¶èï¼éå°å®¶ä½¿ç¨èï¼ä¾å¦è¨åºé«å¸«ï¼éè¦ä¿¡ä»»ä¸¦äºè§£éäºæ¨¡åçè¼¸åºãå æ­¤ï¼äººé¡æ´»åè¾¨è­çå¯è§£é AI (XAI) æ¹æ³æéèçï¼ä»¥æä¾ä¾èªéäºæ¨¡åçç´è¦ºèªç¶èªè¨èªªæãä¸åç XAI æ¹æ³æç¢çä¸åçèªªæï¼èå¶æææ§éå¸¸ééä½¿ç¨èèª¿æ¥ä¾è©ä¼°ï¼éå¨ææ¬åå¬å¹³æ§æ¹é¢éå¸¸å·æææ°æ§ãæ¬ææåºä½¿ç¨å¤§åèªè¨æ¨¡å (LLM) çèªåè©ä¼°æ¹æ³ï¼ä»¥å¨åé¸èä¸­æ¾åºæé©åéå°å®¶ä½¿ç¨èç XAI æ¹æ³ãæåçåæ­¥çµæè¡¨æï¼LLM è©ä¼°èä½¿ç¨èèª¿æ¥ä¸è´ã

##### **Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**
2408.03335v1 by Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil

Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.

æè¦ï¼å·¥æ¥­ 5.0 èéæ¼äººé¡èäººå·¥æºæ§ (AI) åä½å·è¡è£½é ä¸­çä¸åä»»åï¼æ¶åæ´å¤æ©å¨äººãç©è¯ç¶² (IoT) è£ç½®åäºé£ãæ´å¢/èæ¬å¯¦å¢ (AR) åå¶ä»æºæ§è£ç½®ãéäºè£ç½®åäºé£å¨ç¶æ¿ãé«çä¿å¥ãæè²ååé²ç³»çµ±ç­åç¨®ééµé åçå»£æ³åèï¼å¼ç¼äºå¤ç¨®é¡åçæ½å¨å®å¨æ¼æ´ãAI æ¬èº«å·²è¢«è­ææ¯ç¶²è·¯å®å¨ä¸åé åä¸­éå¸¸ææä¸å¼·å¤§çå·¥å·ï¼ä¾å¦å¥ä¾µåµæ¸¬ãæ¡æè»é«åµæ¸¬åç¶²è·¯é£é­åµæ¸¬ç­ãå°±åå¨è¨±å¤æç¨é åä¸æ¨£ï¼ç¶²è·¯å®å¨å°æ¥­äººå¡ä¸é¡ææ¥åé»ç ML è§£æ±ºæ¹æ¡ä¾æç¨æ¼ç¶²è·¯å®å¨ãéç¨®ä¸é¡æä¿ä½¿å¯è§£éäººå·¥æºæ§ (XAI) ä½çºä¸ç¨®å·¥å·è¢«æ¡ç¨ï¼æå©æ¼èªªæå¨åºæ¼ ML çç³»çµ±ä¸­å¦ä½ååºæ±ºç­ãå¨éé èª¿æ¥ä¸­ï¼æåå°å·¥æ¥­ 5.0 çä¸ååºæ¼ XAI çå¥ä¾µåµæ¸¬ç³»çµ±é²è¡äºå¨é¢çç ç©¶ï¼ä¸¦ä¸æåä¹ééå°æå¼ XIDS (Adv-XIDS) æ¹æ³çè§é»ä¾æ¢è¨å¯è§£éæ§åå¯è©®éæ§å°ç¶²è·¯å®å¨å¯¦åçå½±é¿ãæ­¤å¤ï¼æååæäºå·¥æ¥­ 5.0 ç XAI ç¶²è·¯å®å¨ç³»çµ±ä¸­å¯è½å­å¨çæ©æåææ°ï¼å¼ç¼äºæªä¾éå° XAI åºç¤è§£æ±ºæ¹æ¡çç ç©¶ï¼ä»¥ä¾é«é¢¨éªçå·¥æ¥­ 5.0 æç¨æ¡ç¨ãæåç¸ä¿¡éé å´è¬¹çåæå°çºæå®é åå§çå¾çºç ç©¶å·¥ä½å»ºç«åºç¤æ¶æ§ã

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

æè¦ï¼æ¬ç ç©¶æ¨å¨æ¢è¨å°èªç¶èªè¨èç (NLP) åæ©å¨å­¸ç¿ (ML) æè¡å¯¦ä½æ¼é«çä¿¡å½ç·¨ç¢¼èªååï¼ä¸¦å·åè¦è¦ºåèªªæè½ååè¼éåçæ¬å°é»è¦è¨­å®ãç®åå¨è¨åºç°å¢ä¸­ï¼ç·¨ç¢¼æ¯ä¸ç¨®æåæµç¨ï¼æ¶åçºçæ£æä»¶ä¸­çæ¯é ççãç¨åºåè¥ç©ææ´¾ä»£ç¢¼ (ä¾å¦ï¼ä½¿ç¨ SNOMED CT ä»£ç¢¼ 56265001 è¡¨ç¤ºå¿èç)ãæ­¤é åæä½¿ç¨ææ° ML æ¨¡åé²è¡èªåç·¨ç¢¼çåæ­¥ç ç©¶ï¼ç¶èï¼ç±æ¼æ¨¡åçè¤éæ§åå¤§å°ï¼ä¸¦æªå¯¦ç¾å¯¦éé¨ç½²ãçºäºé²ä¸æ­¥ä¿é²èªåç·¨ç¢¼å¯¦åçå¯è½æ§ï¼æåå¨æ¬å°é»è¦è¨­å®ä¸­æ¢è¨äºä¸äºè§£æ±ºæ¹æ¡ï¼æ­¤å¤ï¼æåæ¢è¨äºèªªæåè½å¨ AI æ¨¡åéæåº¦ä¸­çåè½ãæåä½¿ç¨å¬éç MIMIC-III è³æåº«å HAN/HLAN ç¶²è·¯æ¨¡åé²è¡ ICD ä»£ç¢¼é æ¸¬ãæåéè©¦é©äº ICD å SNOMED CT ç¥è­åº«ä¹éçå°æãå¨æåçå¯¦é©ä¸­ï¼éäºæ¨¡åæä¾äº 97.98% ä»£ç¢¼çæç¨è³è¨ãéé èª¿æ¥çµæå¯ä»¥çºå¯¦åä¸­çèªåè¨åºç·¨ç¢¼å¯¦ä½æä¾ä¸äºè¦è§£ï¼ä¾å¦å¨é«é¢ç°å¢ä¸­ï¼ç±è¨åºé«çä½¿ç¨çæ¬å°é»è¦ï¼å°æ¡é é¢ \url{https://github.com/Glenj01/Medical-Coding}ã

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

æè¦ï¼äººå·¥æºè½ (AI) æ¯æçæ±ºç­å¶å®æ¯æªä¾ 6G ç¶²è·¯ä¸­çééµåç´ ï¼å¶ä¸­å°å¼å¥åç AI çæ¦å¿µãæ­¤å¤ï¼AI å»£æ³ç¨æ¼ä¸åçééµæç¨ä¸­ï¼ä¾å¦èªåé§é§åé«çè¨ºæ·ãå¨éäºæç¨ä¸­ï¼ä½¿ç¨ AI ä½çºé»çæ¨¡åæ¯æé¢¨éªä¸å·æææ°æ§çãå æ­¤ï¼çè§£åä¿¡ä»»éäºæ¨¡åååºçæ±ºç­è³ééè¦ãè§£æ±ºæ­¤åé¡çæ¹æ³æ¯éç¼å¯è§£é AI (XAI) æ¶æ§ï¼æ¨å¨è§£éé»çæ¨¡åè¡çºèå¾çéè¼¯ï¼å¾èç¢ºä¿å¶ææä¸å®å¨çé¨ç½²ãæè¿ï¼æåæåºäºä¸åæ°çåºæ¼æ¾åç XAI-CHEST æ¡æ¶ï¼è©²æ¡æ¶é¢åç¡ç·éä¿¡ä¸­çä¿¡éä¼°è¨ãXAI-CHEST æ¡æ¶çæ ¸å¿ææ³æ¯ééå¨ç¡éè¼¸å¥ä¸å¼å¥é«åªè²ä¾è­å¥ç¸éæ¨¡åè¼¸å¥ãéä»½æç¨¿æä¾äº XAI-CHEST æ¡æ¶çè©³ç´°çè«åºç¤ãç¹å¥æ¯ï¼æåæ¨å°äº XAI-CHEST æå¤±å½æ¸ååªè²é¾å¼å¾®èª¿åªååé¡çè§£æè¡¨éå¼ãå æ­¤ï¼è¨­è¨ç XAI-CHEST æä¾äºä¸ç¨®æºè½è¼¸å¥ç¹å¾µé¸ææ¹æ³ï¼å¯ä»¥å¨åªåæç¨æ¨¡åçæ¶æ§çåæé²ä¸æ­¥æé«æ´é«æ§è½ãæ¨¡æ¬çµæè¡¨æï¼XAI-CHEST æ¡æ¶æä¾äºææçè§£éï¼å¨éä½æéçè¨ç®è¤éåº¦çåæï¼æä¾äºæ¹é²çæ¯ç¹é¯èª¤çæ§è½ï¼èéèåºæ¼å³çµ± DL çä¿¡éä¼°è¨ç¸æ¯ã

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v2 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

æè¦ï¼è¿ç¯è®ºææåºäºç¨äºä»è§ç½èç¼åºå¾åè¿è¡ç¾çåç±»çæ©å¼ æ®å·®ç½ç» (ResNet) æ¨¡åãæ©å¼ å·ç§¯æ»¤æ³¢å¨ç¨äºæ¿æ¢ ResNet æ¨¡åè¾é«å±ä¸­çæ­£å¸¸å·ç§¯æ»¤æ³¢å¨ï¼æ©å¼  ResNetï¼ï¼ä»¥æ¹åæç¥åºï¼ä»èéå¯¹ç¾çåç±»å¯¹æ­£å¸¸ ResNet æ¨¡åè¿è¡æ¹è¿ãæ¬ç ç©¶å¼å¥äºéç¨æ·±åº¦å­¦ä¹ çè®¡ç®æºè¾å©è¯æ­å·¥å·ï¼å¹¶éè¿å¯è§£éç AI ææ¯è¿è¡äºå¢å¼ºãè¿äºææ¯æ¨å¨ä½¿è¯¥å·¥å·çå³ç­è¿ç¨éæåï¼ä»èä½¿å»å­¦ä¸ä¸äººå£«è½å¤çè§£åä¿¡ä»» AI çè¯æ­å³ç­ãå®ä»¬ä¸å½ä»çå»çä¿å¥é¢åå°¤ä¸ºç¸å³ï¼å¨è¯¥é¢åï¼å¯¹ AI åºç¨çéæåº¦éæ±ä¸æ­å¢é¿ï¼ä»¥ç¡®ä¿å¶å¯é æ§ååä¹éå¾·çä½¿ç¨ãæ©å¼  ResNet ç¨ä½æ­£å¸¸ ResNet çæ¿ä»£åï¼ä»¥æé«è§ç½èç¼é¨ç¾ççåç±»åç¡®æ§å¹¶åå°æéçè®¡ç®æ¶é´ãæ¬å·¥ä½ä¸­ä½¿ç¨çæ°æ®éæ¯ç¼ç§ç¾çæºè½è¯å« (ODIR) æ°æ®éï¼è¿æ¯ä¸ä¸ªç»æåçç¼ç§æ°æ®åºï¼åå«å«ç±»æ¶µçå¤§å¤æ°å¸¸è§è§ç½èç¼é¨ç¾çãæ¬å·¥ä½ä¸­ä½¿ç¨çè¯ä¼°ææ åæ¬ç²¾ç¡®åº¦ãå¬åçãåç¡®åº¦å F1 å¾åãå¨è¿é¡¹å·¥ä½ä¸­ï¼å¯¹ ResNet-18ãResNet-34ãResNet-50ãResNet-101 å ResNet-152 äºä¸ªåä½çæ­£å¸¸ ResNet æ¨¡ååæ©å¼  ResNet æ¨¡åè¿è¡äºæ¯è¾ç ç©¶ãä¸æ­£å¸¸ ResNet ç¸æ¯ï¼æ©å¼  ResNet æ¨¡åæ¾ç¤ºåºæå¸æçç»æï¼å¨ ODIR å¤ç±»ç¾çåç±»ä¸­ï¼ä¸è¿°åä¸ªåä½çå¹³å F1 å¾åä¸º 0.71ã0.70ã0.69ã0.67 å 0.70ã

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v2 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
existing surveys on the trustworthiness of foundation models do not adequately
address their specific variations and applications within the medical imaging
domain. This survey aims to fill that gap by presenting a novel taxonomy of
foundation models used in medical imaging and analyzing the key motivations for
ensuring their trustworthiness. We review current research on foundation models
in major medical imaging applications, focusing on segmentation, medical report
generation, medical question and answering (Q\&A), and disease diagnosis. These
areas are highlighted because they have seen a relatively mature and
substantial number of foundation models compared to other applications. We
focus on literature that discusses trustworthiness in medical image analysis
manuscripts. We explore the complex challenges of building trustworthy
foundation models for each application, summarizing current concerns and
strategies for enhancing trustworthiness. Furthermore, we examine the potential
of these models to revolutionize patient care. Our analysis underscores the
imperative for advancing towards trustworthy AI in medical image analysis,
advocating for a balanced approach that fosters innovation while ensuring
ethical and equitable healthcare delivery.

æè¦ï¼åºç¤æ¨¡åå¨é«å­¸å½±åæ¹é¢çå¿«éé²å±ï¼ä»£è¡¨èå¨å å¼·è¨ºæ·æºç¢ºæ§ååäººåæ²»çæ¹é¢éåºä¸å¤§æ­¥ãç¶èï¼åºç¤æ¨¡åå¨é«çä¿å¥ä¸­çé¨ç½²éè¦å°å¶å¯ä¿¡åº¦é²è¡å´æ ¼çå¯©æ¥ï¼åæ¬é±ç§ãç©©å¥æ§ãå¯é æ§ãå¯è§£éæ§åå¬å¹³æ§ãç®åéæ¼é«å­¸å½±åä¸­åºç¤æ¨¡åçèª¿æ¥æç»ä¸­é¡¯ç¤ºåºç¸ç¶å¤§çå·®è·ï¼ç¹å¥æ¯å¨å¯ä¿¡åº¦æ¹é¢ãæ­¤å¤ï¼ç¾æéæ¼åºç¤æ¨¡åå¯ä¿¡åº¦çèª¿æ¥ä¸¦æªååè§£æ±ºå¶å¨é«å­¸å½±åé åä¸­çç¹å®è®ååæç¨ãæ¬èª¿æ¥æ¨å¨ééæåºé«å­¸å½±åä¸­ä½¿ç¨çåºç¤æ¨¡åçæ°åé¡æ³ä¸¦åæç¢ºä¿å¶å¯ä¿¡åº¦çééµåæ©ï¼ä¾å¡«è£éä¸ç©ºç½ãæååé¡§äºåºç¤æ¨¡åå¨ä¸»è¦é«å­¸å½±åæç¨ä¸­çç¶åç ç©¶ï¼éé»éæ³¨åå²ãé«çå ±åçæãé«çåé¡ååç­ (Q&A) ä»¥åç¾çè¨ºæ·ãéäºé åä¹æä»¥è¢«å¼·èª¿ï¼æ¯å çºèå¶ä»æç¨ç¸æ¯ï¼å®åå·²ç¶çå°ç¸å°æçä¸å¤§éçåºç¤æ¨¡åãæåå°æ³¨æ¼æ¢è¨é«å­¸å½±ååææç¨¿ä¸­å¯ä¿¡åº¦çæç»ãæåæ¢è¨äºçºæ¯åæç¨æ§å»ºå¯ä¿¡åºç¤æ¨¡åçè¤éææ°ï¼ç¸½çµäºç¶åéæ³¨é»åå¢å¼·å¯ä¿¡åº¦çç­ç¥ãæ­¤å¤ï¼æåæ¢è¨äºéäºæ¨¡åå¨é©æ°æ£èè­·çæ¹é¢çæ½åãæåçåæå¼·èª¿äºå¨é«å­¸å½±ååæä¸­æèå¯ä¿¡è³´çäººå·¥æºæ§éé²çå¿è¦æ§ï¼ä¸¦å¡å°ä¸ç¨®å¹³è¡¡çæ¹æ³ï¼æ¢è½ä¿é²åµæ°ï¼åè½ç¢ºä¿éå¾·åå¬å¹³çé«çä¿å¥æåã

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

æè¦ï¼åºéè¶é³æ³¢ (POCUS) æ¯è¨åºé«å¸«å¨æ£èåºéé²è¡åè§£è®è¶é³æ³¢ææçå¯¦åãç¶èï¼è§£è®éäºå½±åæéçå°æ¥­ç¥è­ç¸ç¶å¯è§ï¼èä¸å¨ç·æ¥ææ³ä¸å¯è½ä¸¦éé¨æå·åãéç¨®ç¾å¯¦ææ³ä½¿å¾æ©å¨å­¸ç¿åé¡å¨ç­æ¼ç®æ³å°æ¼å å¼·äººé¡æ±ºç­è®å¾æ¥µçºæå¹å¼ãPOCUS è£ç½®æ­£ä»¥åçææ¬æ¨åºï¼å°ºå¯¸çºææ©å¤§å°ãå° POCUS è£ç½®è½è®çºæçå·¥å·çææ°å¨æ¼ï¼è§£è®è¶é³æ³¢å½±åéè¦å°éè¨ç·´åç¶é©ãä¸å¹¸çæ¯ï¼åå¾æ­£åè¨ç·´å½±åçå°é£åº¦ä»£è¡¨èå»ºç½®ææçä¸æºç¢ºçåé¡å¨çä¸å¤§éç¤ãå æ­¤ï¼æååè©¦æ¢è¨çåé¡æ¯å¦ä½æ¢ç´¢ç­ç¥ï¼ä»¥æé«ä½¿ç¨ç¨çè³æè¨ç·´çåé¡å¨çæºç¢ºåº¦ãæååè¨­ä½¿ç¨å°æ¸è³æå¯¦ä¾é²è¡è¨ç·´å¯è½ä¸è¶³ä»¥è®åé¡å¨æ¦æ¬ï¼å°è´å®åéåº¦æ¬åãæåçåæ³ä½¿ç¨å¯è§£é AI å¢å¼·æ¹æ³ï¼ä»¥åå©æ¼ç®æ³å¾è¼å°çè³æä¸­å­¸ç¿æ´å¤ï¼ä¸¦æ½å¨åå©åé¡å¨æ´å¥½å°æ¦æ¬ã

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

æè¦ï¼è¿å¹´ä¾ï¼ç¾åè¦è­äºé»å­çæé»å­é¦è¸ä½¿ç¨çå¤§å¹æ¿å¢ï¼å°è´é»å­çåé»å­çä½¿ç¨ç¸éèºæå· (EVALI) çä¾é¡¯èå¢å ï¼å¨ 2019 å¹´ EVALI çç¼æéé æä½é¢åæ­»äº¡ï¼å¸é¡¯äºçè§£é»å­çè¡çºåå¶å®æææè¸ç­ç¥çè¿«åæ§ãç±æ¼ç¤¾ç¾¤åªé«å¹³å°çæ®åï¼å¨çè¶é 47 åä½¿ç¨èä½¿ç¨å®åé²è¡é£çµãæºéãæ°èåå¨æ¨ï¼å¶ä¸­å¾å¤§ä¸é¨åèå¥åº·ç¸éï¼å æ­¤å°ç¤¾ç¾¤åªé«è³æå»ºç«çºå¬å±è¡çç ç©¶ä¸­ç¡å¹çææ©è³æè³æºãå¨æ¬ç ç©¶ä¸­ï¼æåå¾ Reddit ä¸ä¸åé»å­çå­ç¤¾ç¾¤ä¸­æåä¸åç¯ä¾è³æéï¼ä»¥åæä½¿ç¨èçæé»å­çæåãå©ç¨ OpenAI ææ°çå¤§åèªè¨æ¨¡å GPT-4 é²è¡å¥å­å±¤ç´çæé»å­çæååµæ¸¬ï¼æ¬ç ç©¶æ¯è¼äºæ­¤æ¨¡åççµæèå¤è¡äººåè¨åºå°å®¶è¨»è§£ãä½¿ç¨ä¸åçæç¤ºç­ç¥ï¼ä¾å¦é¶æ¬¡å­¸ç¿ãä¸æ¬¡å­¸ç¿ãå°æ¬¡å­¸ç¿åæèéæç¤ºï¼æåéç¼äº 8 åæç¤ºï¼è©³ç´°ç¨åº¦ä¸åï¼å GPT-4 è§£éä»»åï¼ä¸¦è©ä¼°éäºç­ç¥å½¼æ­¤ä¹éçæè½ãéäºåæ­¥ç¼ç¾å¼·èª¿äº GPT-4 å¨ç¤¾ç¾¤åªé«è³æåæä¸­çæ½åï¼ç¹å¥æ¯å¨è­å¥äººé¡åµæ¸¬å¯è½ç¡æ³å¯è¦ºçä½¿ç¨èå¾®å¦æåæ¹é¢ã

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

æè¦ï¼<paragraph>äººå·¥æºæ§ï¼AIï¼ç®åå¨å¾å¤§ç¨åº¦ä¸ä¾è³´æ¼ç¼ºä¹å¯è§£éæ§çé»çæ©å¨å­¸ç¿æ¨¡åãå¯è§£éæ§äººå·¥æºæ§ï¼XAIï¼é åè´åæ¼è§£æ±ºéåä¸»è¦åé¡ï¼éå¨éèãæ³å¾åå¥åº·ç­é«é¢¨éªé åè³ééè¦ã
æåæåºäºä¸ç¨®åºæ¼ç¯çè«å®ç¾© AI æ¨¡ååå¶å¯è§£éæ§çæ¹æ³ãçºæ­¤ï¼æåæ¡ç¨çµåæ¨¡åçæ¦å¿µï¼å®ä»¥å½¢å¼å¼¦åçå½¢å¼çå¾æ¨¡åï¼éäºå¼¦åæç²äºæ¨¡åçæ½è±¡çµæ§åå¶å·é«å¯¦ç¾ãéç¨®ç¶åè§é»åå«äºç¢ºå®æ§ãæ¦çæ§åéå­æ¨¡åãæåå°åç¨® AI æ¨¡åä½çºçµåæ¨¡åé²è¡æ¯è¼ï¼åæ¬ç·æ§ååºæ¼è¦åçæ¨¡åãï¼éè¿´ï¼ç¥ç¶ç¶²è·¯ãTransformerãVAEï¼ä»¥åå æå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåæ ¹ææ¨¡åççµåçµæ§çµ¦åºæ¨¡åè§£éçå®ç¾©ï¼å±ç¤ºå¦ä½åææ¨¡åçå¯è§£éæ§ï¼ä¸¦ä½¿ç¨å®ä¾æ¾æ¸ XAI ä¸­çå¸¸è¦ä¸»é¡ãæåç¼ç¾ï¼è®æ¨æºçãå§å¨å¯è§£éãæ¨¡åå¦æ­¤éæçåå å¨åè¡¨ä¸­è¡¨ç¾å¾æçºæ¸æ¥ãéå¼å°æåå¾åºæ´ä¸è¬ççµåå¯è§£éï¼CIï¼æ¨¡åæ¦å¿µï¼å®å¦å¤éåæ¬å æãæ¦å¿µç©ºéå DisCoCirc æ¨¡åã
æ¥ä¸ä¾ï¼æåå±ç¤ºäº CI æ¨¡åçå¯è§£éæ§åªå¢ãé¦åï¼å®åççµåçµæ§åè¨±è¨ç®å¶ä»æèè¶£çéï¼ä¸¦å¯è½ééå¹éæ¨¡åççµæ§ä¾ä¿é²å¾æ¨¡åå°è¢«å»ºæ¨¡ç¾è±¡çæ¨çãå¶æ¬¡ï¼å®ååè¨±å°å¶è¡çºé²è¡åè§£èªªæï¼éäºèªªæåºæ¼å½±é¿ç´æãåè§£æè¡åéå¯«èªªæãæå¾ï¼æåè¨è«äºéç¨®æ¹æ³çè¨±å¤æªä¾æ¹åï¼æåºäºå¦ä½å¨å¯¦è¸ä¸­å­¸ç¿éç¨®ææç¾©ççµæ§åæ¨¡åçåé¡ã</paragraph>

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

æè¦ï¼åå®å®çæ¦å¿µå¨ååé åé½ååéæ³¨ï¼å¶éè¦æç¨ä¹ä¸ä¾¿æ¯é«çä¿å¥ãåå®å®æå·¨å¤§çæ½åééæ¹è®çæ£ç§è­·ãé«å­¸æè²ï¼ä»¥åæå­¸/å­¸ç¿åç ç©¶çæ¹å¼ä¾è½åé«çä¿å¥ãæ¬ç ç©¶çç®çæ¯æä¾åå®å®åºæ¬æ¦å¿µååºç¤æè¡çä»ç´¹ãæ¬ææ¢è¨äºåå®å®å¨é«çä¿å¥èæ¯ä¸çåªç¼ºé»ï¼ä¸¦å¾æè¡å AI çè§åº¦åæå¶æ½åãç¹å¥æ¯ï¼è¨è«äºæ©å¨å­¸ç¿æ¹æ³çè§è²ï¼æåå°èªªæå¦ä½å°æ©å¨å­¸ç¿æ¼ç®æ³æç¨æ¼åå®å®ç¢ççè³æï¼ä»¥ç²å¾é«çä¿å¥æç¨æ¹é¢çæ´ä½³è¦è§£ãæ­¤å¤ï¼æåééæ¢è¨åå¡éç­æ°èæè¡ï¼ä¸¦è§£æ±ºé±ç§åé¡ï¼ä¾æ¢è¨åå®å®å¨é«çä¿å¥æ¹é¢çæªä¾é¡æ¯ãæ¬ç ç©¶çç¼ç¾æå©æ¼æ´æ·±å¥å°äºè§£åå®å®å¨é«çä¿å¥ä¸­çæç¨ï¼ä»¥åå¶å¨é«çæåæä¾æ¹é¢ç¼æ®é©å½æ§è®é©çæ½åã

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

æè¦ï¼æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®å»£æ³çæ¢æ§ç¾çï¼æ²æå·²ç¥çæçµçæ³ä¸ç¼ççå¾é«ãç ç©¶è¡¨æï¼é²è¡æ§æ¢æ§èèçï¼CKDï¼æ¯ä¸ç¨®ç°è³ªæ§ç¾çï¼æé¡¯èå½±é¿èèçµæ§ååè½ï¼æçµå°è´èè¡°ç«­ãé¨èæéçæ¨ç§»ï¼æ¢æ§èèçå·²å¾å½±é¿å°æ¸äººçè´å½ç¾çè½è®çºä¸ç¨®å´éç¨åº¦ä¸åçå¸¸è¦ç¾çãæ¬ç ç©¶çç®æ¨æ¯ä½¿ç¨éæå­¸ç¿åå¯è§£éç AI é²è¡æ©æé å¾å CKD æª¢æ¸¬ï¼ä¸¦è¦è¦ºåä¸»å°ç¹å¾µãç¹å¾µåæ¸åè¡¨ç¾åºçå¼ãçºæ­¤ï¼æåºäºä¸ç¨® AI é©åçé æ¸¬åææ¹æ³ï¼ä»¥å¹«å©è¨åºé«ççºåå¥æ£èéå·çæ´»æ¹å¼ä¿®æ¹å»ºè­°ï¼ä»¥éä½éç¨®ç¾ççé²å±éåº¦ãæåçæ¸æéæ¯å¾ CKD æ£èåå¥åº·åè©¦èçèº«é«çå½é«å¾µä¸­æ¶éçï¼ä»¥æºç¢ºéç¼æåæåºç AI é©åçè§£æ±ºæ¹æ¡ãå¨éæ¹é¢ï¼æä¾äºè¡æ¶²åå°¿æ¶²æª¢æ¸¬çµæï¼ä¸¦æç¨åºæ¼éææ¨¹çæ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬æªç¼ç¾ç CKD çä¾ãæåçç ç©¶çµæç¶éèèèç§é«ççé·æè«®è©¢å¾å¾å°é©è­ãæåçå¯¦é©åè§£éçµæèåç¨®é«çä¿å¥é åä¸­ç¾æçå¯è§£é AI æç¨é²è¡äºæ¯è¼ï¼åæ¬ CKDãæ¯è¼è¡¨æï¼æåéç¼ç AI æ¨¡åï¼ç¹å¥æ¯é¨æ©æ£®ææ¨¡åï¼å·²ç¶ç¢ºå®äºæ¯ XgBoost æ´å¤ä½çºéè¦è²¢ç»èçç¹å¾µãå¯è§£éæ§ (I) è¡¡ééè¦ç¹å¾µèæ©èç¹å¾µçæ¯çï¼è¡¨ææåç XgBoost æ¨¡åå¨éåææ¨ä¸­ç²å¾äºæ´é«çåæ¸ï¼ç¹å¥æ¯ 98% çä¿çåº¦ï¼ä¸¦ä¸å¨ FII ææ¸ä¸­èªç¶é«æ¼ç«¶ç­æ¨¡åã

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

æè¦ï¼å¿çå¥åº·æ§æäºä¸é è¤éä¸æ®éçå¨çææ°ï¼å½±é¿äºæ¸ç¾è¬äººççæ´»ï¼ä¸¦ç¶å¸¸å°è´å´éçå¾æãå¨æ¬æä¸­ï¼æåé²è¡äºä¸é å¾¹åºçèª¿æ¥ï¼ä»¥æ¢ç´¢æ¸æç§å­¸ãäººå·¥æºæ§åå¿çä¿å¥çäº¤éï¼éé»éæ³¨ééç·ä¸ç¤¾äº¤åªé« (OSM) é²è¡å¿çç¾çæª¢æ¸¬çææ°ç¼å±ãå¾å¤§ä¸é¨åäººå£ç©æ¥µåè OSM å¹³å°ï¼åµé äºä¸åé¾å¤§çäººå¡è³æåº«ï¼å°å¿çå¥åº·åæå·æå·¨å¤§çæ½åãæ¬ææ¢è¨äºå³çµ±çè¨ºæ·æ¹æ³ãæåé²çè³æå AI é©åçç ç©¶ï¼ä»¥åå¿çä¿å¥ä¸­å¯è§£é AI (XAI) æ¨¡åçåºç¾ãæååé¡§äºæåé²çæ©å¨å­¸ç¿æ¹æ³ï¼ç¹å¥æ¯é£äºåºæ¼ç¾ä»£æ·±åº¦å­¸ç¿çæ¹æ³ï¼åæå¼·èª¿äºé«çä¿å¥ AI æ¨¡åä¸­å¯è§£éæ§çå¿è¦æ§ãå¯¦é©è¨­è¨é¨åæä¾äºå°æ®éåæ³çè¦è§£ï¼åæ¬å¯ç¨çè³æéåè©ä¼°æ¹æ³ãæåéæ¾åºè©²é åçä¸»è¦åé¡åææ°ï¼ä¸¦æåºäºæå¸æçæªä¾ç ç©¶æ¹åãç±æ¼å¿çå¥åº·æ±ºç­éè¦éæåº¦ãå¯è§£éæ§åéå¾·èéï¼æ¬ææå©æ¼æ¨é²å¿çä¿å¥ä¸­ééç¤¾äº¤åªé«æ¨é² XAI çæçºè¨è«ãéè£¡æåºçå¨é¢æ¦è¿°æ¨å¨å¼å°ç ç©¶äººå¡ãå¾æ¥­äººå¡åæ¿ç­å¶å®èç¼å±å¿çç¾çæª¢æ¸¬é åã

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

æè¦ï¼<paragraph>é«çç§è­·ä¸­éè¦ AI è¼å©çè¨åºè¨ºæ·ãç¾æçæ·±åº¦å­¸ç¿æ¨¡åç¼ºä¹å¯è§£éæ§ï¼ä¸¦ä¸ä¸»è¦å°æ³¨æ¼å½±ååæãæè¿éç¼çåæä¸ç¢ºå®å æéä¿å (DUCG) æ¹æ³æ¯å æé©åçãå¯è§£éçï¼ä¸¦ä¸å¨ä¸åçæç¨å ´æ¯ä¸­æ¯ä¸è®çï¼æ²æè³ææ¶éãæ¨è¨ãæ¬åãé±ç§ãåè¦ãæ¦åãé«ææ¬åé«è½èçåé¡ãééè¨åºå°å®¶å DUCG æè¡äººå¡ä¹éçå¯ååä½ï¼æ§å»ºäºæ¶µè 54 åä¸»è¨´ç 46 å DUCG æ¨¡åãå¯ä»¥å¨æ²æåæµçææ³ä¸è¨ºæ·åº 1,000 å¤ç¨®ç¾çãå¨æç¨æ¼å¯¦éä¸çä¹åï¼46 å DUCG æ¨¡åå·²ç±ç¬¬ä¸æ¹é«é¢åæº¯æ§é©è­ãé©è­çè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 95%ï¼å¶ä¸­åæ¬ç½è¦ç¾çå¨å§çæ¯ç¨®ç¾ççè¨ºæ·ç²¾åº¦ä¸ä½æ¼ 80%ãé©è­å¾ï¼46 å DUCG æ¨¡åå·²å¨ä¸­åå¯¦éæç¨ãå·²ç¶å·è¡äºè¶éä¸ç¾è¬åçå¯¦è¨ºæ·æ¡ä¾ï¼åç¼ç¾ 17 åä¸æ­£ç¢ºçè¨ºæ·ãç±æ¼ DUCG çéææ§ï¼ç¼ç¾ä¸¦ç³¾æ­£äºå°è´ä¸æ­£ç¢ºè¨ºæ·çé¯èª¤ãé »ç¹æç¨ DUCG çè¨åºé«ççè¨ºæ·è½åå¾å°äºé¡¯èæé«ãå¨ä»ç´¹äºåé¢æåºç DUCG æ¹æ³è«ä¹å¾ï¼æåºäºæ½å¨å¥åº·æª¢æ¥çæ¨è¦æ¼ç®æ³ï¼ä¸¦æåäº DUCG çééµææ³ã</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

æè¦ï¼ç²¾ç¢ºä¸åæå°åµæ¸¬ä¹³çå°æ¼æ¹åæ£èé å¾è³ééè¦ãè¨ºæ·æ¹æ³å³çµ±ä¸ä¾è³´æ¼å®ä¸æ¨¡å¼æ¹æ³ï¼ç¶èï¼é«çè³æåææ­£å¨æ´åè¶è¶å³çµ±å½±åçåç¨®è³æä¾æºãä½¿ç¨æ´åå½±ååéå½±åè³æçå¤æ¨¡å¼æè¡ï¼æ¨èªèä¹³çè¨ºæ·çè®é©æ§é²å±ãæ¬ç¯ç¶è¿°çç®çæ¯æ¢è¨å¤æ¨¡å¼æè¡çæ°èé åï¼ç¹å¥æ¯å°çµç¹ççå­¸å½±åèéå½±åè³æèåãæ­¤å¤ï¼å¯è§£éäººå·¥æºæ§ (XAI) å°ç¨æ¼é¡æè¤éæ¼ç®æ³çæ±ºç­éç¨ï¼å¼·èª¿è¨ºæ·éç¨ä¸­å¯è§£éæ§çå¿è¦æ§ãæ¬ç¶è¿°å©ç¨å¤æ¨¡å¼è³æä¸¦å¼·èª¿å¯è§£éæ§ï¼ä»¥æé«è¨ºæ·æºç¢ºæ§ãè¨åºé«å¸«çä¿¡å¿åæ£èåèåº¦ï¼æçµä¿é²ä¹³çæ´åäººåçæ²»çç­ç¥ï¼åæä¹æ¾åºå¤æ¨¡å¼åå¯è§£éæ§çç ç©¶å·®è·ï¼å¼å°æªä¾çç ç©¶ï¼ä¸¦çºè©²é åçç­ç¥æ¹åååºè²¢ç»ã

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

æè¦ï¼èªæ³¨æåæ©å¶å·²è¢«æ¡ç¨æ¼å¤åå»£æ³ä½¿ç¨çè¨æ¯å³éç¥ç¶ç¶²è·¯ (MPNN)ï¼ä¾å¦ GATï¼ï¼å®å¯ä»¥èªé©æå°æ§å¶æ²¿èåºå±¤åå½¢éç·£æµåçè³è¨éãéç¨®æ³¨æåçä½¿ç¨ä½¿å¾æ­¤é¡æ¨¡åæçºå¯è§£é AI (XAI) ç ç©¶çåºç·ï¼å çºééæ³¨æåçè©®éå·²å¨åç¨®é åï¼ä¾å¦èªç¶èªè¨èçåé»è¦è¦è¦ºï¼ä¸­æ®åãç¶èï¼ç¾æçç ç©¶éå¸¸ä½¿ç¨å¤©ççè¨ç®æ¹æ³å¾æ³¨æåä¸­æ¨å°åºæ­¸å åæ¸ï¼ä¸¦ä¸æ²æèæ®å°éç·£æ­¸å çç²¾ç¢ºä¸ä»ç´°çè¨ç®ãå¨æåçç ç©¶ä¸­ï¼æåæ¨å¨å¡«è£æ³¨æååç¨ MPNN çå»£æ³ä½¿ç¨èå®åå¨å¾å¤§ç¨åº¦ä¸æªè¢«ååæ¢ç´¢çå¯è§£éæ§ä¹éçå·®è·ï¼éåä¸»é¡å·²å¨å¶ä»é åç©æ¥µç ç©¶ãçºæ­¤ï¼ä½çºç¬¬ä¸æ¬¡åè©¦ï¼æåå° GNN ä¸­æ³¨æåæ¬éçéç·£æ­¸å åé¡å½¢å¼åãç¶å¾ï¼æåæåº GATTï¼ä¸ç¨®å»ºç«å¨è¨ç®æ¨¹ä¸çéç·£æ­¸å è¨ç®æ¹æ³ãééå¨é¢çå¯¦é©ï¼æåå±ç¤ºäºæåæåºçæ¹æ³å¨è©ä¼° GAT çæ­¸å ææå·æçææãç¸åå°ï¼æåæç¶é©é©è­äºåå°åæ³¨æåå±¤ä¸çæ³¨æåæ¬éåå¹³åå¼ä¸è¶³ä»¥è©®é GAT æ¨¡åçè¡çºãç¨å¼ç¢¼å·²å¬éæ¼ https://github.com/jordan7186/GAtt/tree/mainã

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v3 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

æè¦ï¼æ°çåææ¯å¤§è¦ç¼è²æèå¼±çææï¼å®¹æåºç¾ç²çç¼ä½ãå¤§è¦ç¼è²ä¸æçæåºç¾ç²çç¼ä½æé æä¸è¯å¾æï¼å æ­¤éè¦åæ©è¨ºæ·ãç®åæ°çåç²çç¼ä½çé»éæ¨æºä¾è³´æ¼é£çºçè¦è¨è¦é»å (EEG) ç£æ¸¬ï¼å¶ä¸­åæ¬å¨æ°çåå è­·çæ¿ (NICU) å§åæé²è¡å¤é »éè¦é»å (EEG) è¨éåå³æè¦è¨ç£æ§ãç¶èï¼è¦è¨è¦é»åç£æ§æè¡éè¦è¨åºå°æ¥­ç¥è­ï¼èä¸éå¸¸åéæ¼æè¡åé²ä¸è³æºè±å¯çç°å¢ãå·ææ¬æççæ°æè¡å¯ä»¥å¹«å©é«ççæºç¢ºè¨ºæ·ä¸¦ç«å³æå¡æ²»çãå¨éé å·¥ä½ä¸­ï¼æåºäºä¸åæ°ç©çå¯è§£éæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥èªååæ°çåç²çç¼ä½åµæ¸¬éç¨ï¼ä¸¦æ¡ç¨æ¸å°çè¦é»åè£ç½®ï¼å¶ä¸­æ¡ç¨äºå·ç©ç¥ç¶ç¶²è·¯ãåå½¢æ³¨æåå±¤åå¨é£æ¥å±¤ãé¤äºè½å¤ ä½¿ç¨æ¸å°çè£ç½®å³æåµæ¸¬ç²çç¼ä½å¤ï¼æ­¤æ¨¡åéæä¾äºå³æå¯è§£éæ§çç¨ç¹åªå¢ãééå¨ Zenodo è³æéä¸ä½¿ç¨ 10 åäº¤åé©è­è©ä¼°æè½ï¼ææåºçæ¨¡åå¨æ²ç·ä¸é¢ç© (AUC) åå¬åçæ¹é¢åå¥éå°äº 8.31% å 42.86% ççµå°æ¹åã

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

æè¦ï¼ä¹³ç (BC) æ¯å½±é¿å¨çå¥³æ§æå¸¸è¦çæ¡æ§è«ç¤ä¹ä¸ï¼å æ­¤éè¦é²æ­¥çè¨ºæ·æ¹æ³ï¼ä»¥æ¹åè¨åºçµæãæ¬æå¨é¢æ¢è¨äºå¯è§£éäººå·¥æºæ§ (XAI) æè¡å¨ä¹³çåµæ¸¬åè¨ºæ·ä¸­çæç¨ãé¨èäººå·¥æºæ§ (AI) æè¡æçºæ»²éé«çä¿å¥é åï¼ç¹å¥æ¯å¨è«ç¤å­¸ä¸­ï¼éæä¸å¯è§£éçæ¨¡åéæ±è®å¾å¢å¨å¿è¡ï¼ä»¥å¢å¼·è¨åºæ±ºç­å¶å®åæ£èç§è­·ãæ­¤ç¯è©è«æ¢è¨äºåç¨® XAI æ¹æ³çæ´åï¼ä¾å¦ SHAPãLIMEãGrad-CAM ç­ï¼ä»¥åç¨æ¼ä¹³çåµæ¸¬ååé¡çæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åãééæ¢è¨ä¹³çè³æéçæ¨¡å¼ï¼åæ¬ä¹³æ¿æå½±ãè¶é³æ³¢åå¶å¨ AI ä¸­çèçï¼æ¬æéé»èªªæ XAI å¦ä½è½å°è´æ´æºç¢ºçè¨ºæ·ååäººåæ²»çè¨ç«ãå®ä¹æ¢è¨äºå¯¦æ½éäºæè¡çææ°ï¼ä»¥åå¶å®æ¨æºåè©éææ¨ä»¥è©ä¼° XAI å¨è¨åºç°å¢ä¸­çæææ§çéè¦æ§ãééè©³ç´°çåæåè¨è«ï¼æ¬ææ¨å¨å¼·èª¿ XAI å¨ç¸®å°è¤é AI æ¨¡åèå¯¦åé«çä¿å¥æç¨ä¹éå·®è·çæ½åï¼é²èä¿é²é«çå°æ¥­äººå¡ä¹éçä¿¡ä»»èçè§£ï¼ä¸¦æ¹åæ£èççµæã

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

æè¦ï¼èªé³æç·è¾¨è­ (SER) ç±æ¼å¶å¨å¿çå¥åº·ãæè²åäººæ©äºåç­å¤åæç¨é åèååéæ³¨ãç¶èï¼SER ç³»çµ±çæºç¢ºæ§åå°é«ç¶­ç¹å¾µéçé»ç¤ï¼éäºç¹å¾µéå¯è½åå«ä¸ç¸éååé¤çè³è¨ãçºäºåæéåææ°ï¼æ¬ç ç©¶æåºäºä¸ç¨®ç¨æ¼ SER çè¿­ä»£ç¹å¾µæåæ¹æ³ï¼è©²æ¹æ³å¼·èª¿ç¹å¾µç¸éæ§åå¯è§£éæ§ï¼ä»¥å¢å¼·æ©å¨å­¸ç¿æ¨¡åçæè½ãæåçåæ³æ¶åä»ç´°çç¹å¾µé¸æååæï¼ä»¥å»ºç«é«æç SER ç³»çµ±ãçºäºééæ¨¡åå¯è§£éæ§è§£æ±ºæåçæ ¸å¿åé¡ï¼æåæ¡ç¨äºå·æ Shapley å¼çç¹å¾µè©ä¼°è¿´åï¼ä»¥åè¦æ¹åç¹å¾µéãéåéç¨å¨æ¨¡åæè½åéæåº¦ä¹éåå¾å¹³è¡¡ï¼éä½¿å¾æåè½å¤ å¨é¢äºè§£æ¨¡åçé æ¸¬ãææåºçæ¹æ³æä¾äºå¤é åªé»ï¼åæ¬è­å¥åç§»é¤ä¸ç¸éååé¤çç¹å¾µï¼å¾èå»ºç«æ´ææçæ¨¡åãæ­¤å¤ï¼å®ä¿é²äºå¯è§£éæ§ï¼æå©æ¼çè§£æ¨¡åçé æ¸¬ä»¥åè­å¥æç·æ±ºå®çééµç¹å¾µãææåºçæ¹æ³çæææ§å·²å¨å¤å«å¤æç·èªé³é (TESS)ãæææç·èªé³è³æåº« (EMO-DB)ãè³´ç¾æ£®é³è¨è¦è¦ºæç·èªé³åæ­æ²è³æåº« (RAVDESS) åè©éé³è¨è¦è¦ºè¡¨éæç· (SAVEE) è³æéç SER åºæºä¸å¾å°é©è­ï¼å¶æè½åªæ¼ç¾ææ¹æ³ãææåæç¥ï¼éæ¯ç¬¬ä¸åå°æ¨¡åå¯è§£éæ§ç´å¥ SER æ¶æ§çç ç©¶ãæ¬æçåå§ç¢¼å¯ééæ­¤é£çµå¬éåå¾ï¼https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognitionã

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, HÃ©loÃ¯se de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

æè¦ï¼å¯è§£éæ§éå¸¸å¯¹äºäººå·¥æºè½ (AI) çå¯æ¥åå®æ½è³å³éè¦ãå¨å»çä¿å¥é¢åï¼è¿ä¸ç¹å°¤ä¸ºéè¦ï¼å ä¸ºå³ç­ç´æ¥å½±åæ£èï¼å¹¶ä¸å¯¹ AI ç³»ç»çä¿¡ä»»è³å³éè¦ãè¿ç§ä¿¡ä»»éå¸¸å»ºç«å¨ AI æä¾çè§£éåè¯ éä¹ä¸ãå°½ç®¡ AI å¯è§£éæ§åå¾äºéå¤§è¿å±ï¼ä½ä»ç¶éè¦æç¡®çæå¯¼æ¹éï¼è¯´æå¨å»çç¯å¢ä¸­ä½æ¶ä»¥åå¨å¤å¤§ç¨åº¦ä¸éè¦è§£éãæä»¬æåºäºä¸ç§æ°é¢çåç±»ç³»ç»ï¼è¯¥ç³»ç»å·æåç§ä¸åçè§£éå¿è¦æ§ç±»å«ï¼æå¯¼æéçè§£éçº§å«ï¼æ£èææ ·æ¬ï¼å±é¨ï¼çº§å«ãéåææ°æ®éï¼å¨å±ï¼çº§å«ï¼æä¸¤ä¸ªçº§å«ãæä»¬å¼å¥äºä¸ä¸ªæ°å­¦å¬å¼ï¼è¯¥å¬å¼åºåäºè¿äºç±»å«ï¼å¹¶ä¸ºç ç©¶äººåæä¾äºä¸ä¸ªå®ç¨æ¡æ¶ï¼ä»¥ç¡®å®å»ç AI åºç¨ä¸­æéçè§£éçå¿è¦æ§åæ·±åº¦ãèèäºä¸ä¸ªå³é®å ç´ ï¼è¯ä¼°åè®®çç¨³å¥æ§ãä¸å®¶è§å¯çå¯åæ§ä»¥ååºç¨ç¨åºçè¡¨ç¤ºç»´æ°ãä»è¿ä¸ªè§åº¦æ¥çï¼æä»¬è§£å³äºè¿ä¸ªé®é¢ï¼AI å»çåºç¨ä½æ¶éè¦è§£éï¼ä»¥åéè¦è§£éå°ä½ç§ç¨åº¦ï¼

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

æè¦ï¼äººå·¥æºæ§ (AI) é åæ­£å¿«éå½±é¿èå¥åº·èé«çä¿å¥ï¼ä½å°æ¼é¢è¨å»£æ³çµæ§æ§å£è¿«çäººç¾¤ä¾èªªï¼åè¦åä¸è¯è¡¨ç¾ä¾ç¶å­å¨ãååçç ç©¶å·²æ¸æ¥èªªæï¼éè¦æ´å´æ ¼å°æ³¨æè³æä»£è¡¨æ§åæ¨¡åæè½ï¼ä»¥ä¿é²å¬å¹³æ§ä¸¦æ¸å°åè¦ãç¶èï¼æåææ©æéééç¨ç¤¾ææµè¡çå­¸åå¥åº·å¬å¹³çæä½³å¯¦åï¼ä¾æ¹å AI çå¯è§£éæ§ï¼ä»¥å¹«å©æåéå°ç¼ç¾çéè¯æ§ï¼ç¼å±åè¨­ãå¨æ¬æä¸­ï¼æåå°æ³¨æ¼å¯è§£é AI (XAI)ï¼ä¸¦æè¿°ä¸åè·¨é åå°å®¶å°çµå¯©æ¥æ¶æ§ï¼ä»¥å¾å¤éè§é»è¨è«åæ¹å¤æ§è©ä¼° AI æ¨¡åçè§£éï¼ä¸¦æ¾åºåè¦é ååæªä¾ç ç©¶çæ¹åãæåå¼·èª¿è·¨é åå°å®¶å°çµå°æ¼ç¢çæ´æºç¢ºãå¬å¹³çè©®éè³ééè¦ï¼èéäºè©®éæ¯æ ¹ææ­·å²åèçµ¡èä¾çãè·¨é åå°çµè¨è«æå©æ¼æ¸å°åè¦ãæ¾åºæ½å¨çæ··æ·å ç´ ï¼ä¸¦å¨æç»ä¸­æç¼ºå£ææ¾åºé¡å¤ç ç©¶çæ©æãåéä¾ï¼éäºè¦è§£å¯ä»¥å»ºè­° AI æ¨¡åæ¹é²çæ©æã

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. ZajÄc, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å¨å¯¦é©å®¤å¯¦é©ä¸­ä¸æ·å°èæ¾å°ç§é«å¸«å¹æµæè¡¨ç¾å¾æ´åºè²ãç¶èï¼ç¼ç¾æ¾å°ç§ AI çºåºç¤ç³»çµ±çå¯¦éå·è¡å¹¾ä¹æ²ææä¾è¨åºå¹å¼ãæ¬ææ¢è¨å¦ä½çº AI è¨­è¨å¨ä¸åæå¢ä¸­è¨åºä¸çæç¨ãæåæ ¹æåè½æ§ AI çºåºç¤ååçä¸æ¬¡è¿­ä»£ï¼å¨ä¸¹éº¥åè¯äºç 7 åè¨åºå ´åè 13 ä½æ¾å°ç§é«å¸«é²è¡äº 19 æ¬¡è¨­è¨æè­°åè¨­è¨ä»å¥ãååç¤¾ææè¡ä¾è³´éä¿è¢«èªçºå°æ¼æ¾å°ç§ä¸­ AI çè¨­è¨è³ééè¦ãæåæ¦å¿µåäºååæè¡é¢åï¼å¿é æ ¹æé æçè¨åºä½¿ç¨æå¢é²è¡è¨­å®ï¼AI åè½ãAI é«çéé»ãAI æ±ºç­éæª»ï¼ä»¥å AI å¯è§£éæ§ãæåæåºåé è¨­è¨å»ºè­°ï¼èªªæå¦ä½èçèé«çç¥è­ãè¨ºæé¡åãä½¿ç¨èå°æ¥­ç¥è­ç­ç´ãæ£èæå¢ï¼ä»¥åå½±é¿éäºæè¡é¢åè¨­å®çä½¿ç¨èæå¢ç¸éçä¾è³´éä¿ã

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

æè¦ï¼é¨èåé²ç AI/MLï¼å°å¯è§£é AI (XAI) çç ç©¶ä¸æ·å¢å ï¼ä»¥åéæ¼äººé¡å¦ä½è AI å XAI äºåä»¥é²è¡ææçäººå·¥æºæ§åä½æ±ºç­å¶å®ãç¶èï¼æåä»ç¶ç¼ºä¹å° AI ç³»çµ±å XAI æå¦ä½é¦ååç¾çµ¦æ²ææè¡èæ¯çç¨æ¶çäºè§£ãå¨æ¬æä¸­ï¼æåå±ç¤ºäºèé«çå°æ¥­äººå¡ (n=12) åä¸»ä¿®é«å­¸åå¥åº·çå­¸ç (n=4) é²è¡åçµæ§åè¨ªè«ççµæï¼ä»¥ç ç©¶å¦ä½æ¹å AI å XAI çå¥éãå°æ¼è¨ªè«ï¼æåå»ºç«å¨äººæ©äºåæºåä¹ä¸ï¼çºä¸­é¢¨åº·å¾©è©ä¼°å AI è§£éç AI ç³»çµ±åµå»ºå¥éææï¼ä¸¦å°å®åä»ç´¹çµ¦åèèãæåçç ç©¶çµæè¡¨æï¼é¤äºåç¾å³çµ±ç AI æ§è½ææ¨å¤ï¼åèèéå¸æåºåä¿¡æ¯ãAI çå¯¦éå¥½èä»¥åäº¤äºè©¦é©ï¼ä»¥æ´å¥½å°å° AI æ§è½æå¢åï¼ä¸¦å®å AI çç®æ¨åæ§è½ãæ ¹æéäºç¼ç¾ï¼æåå¼·èª¿äºæ¹é² AI å XAI ä»¥åäººæ©åä½æ±ºç­å¶å®çå¥éæ¹åã

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

æè¦ï¼æ¬æä½¿ç¨æ©å¨å­¸ç¿ (ML) åå¯è§£éäººå·¥æºæ§ (XAI) æè¡ä¾æ¢è¨çé¤çæ³èé¿è²æµ·é»ç (AD) ç¸éçæ­»äº¡çä¹éçéä¿ãæ¡ç¨ç¬¬ä¸æ¬¡å¨åå¥åº·èçé¤æª¢æ¥èª¿æ¥ (NHANES III) è³æåº«é²è¡åæãé¸æé¨æ©æ£®ææ¨¡åä½çº XAI åæçåºç¤æ¨¡åï¼ä¸¦ä½¿ç¨ Shapley Additive Explanations (SHAP) æ¹æ³ä¾è©ä¼°ç¹å¾µéè¦æ§ãçµæçªé¡¯äºéè¦ççé¤å ç´ ï¼ä¾å¦è¡æ¸ç¶­çç´  B12 åç³åè¡ç´èç½ãè©²ç ç©¶è­æäºé¨æ©æ£®æå¨é æ¸¬ AD æ­»äº¡çæ¹é¢ç¸è¼æ¼å¶ä»ç¾ççæææ§ãæ¬ç ç©¶æä¾äºçé¤å° AD çå½±é¿çè¦è§£ï¼ä¸¦æå©æ¼æ´æ·±å¥å°äºè§£ç¾ççé²å±ã

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

æè¦ï¼<paragraph>åç´ä¿å¥æä¾èå°æ¼æåçåæµåè½è¨ºå°å°ç§ç§è­·è³ééè¦ãå¨éåç¼çææ³ä¸ï¼ç¡ççä¸å¿«éæ¡åå¯è½å°è´è¦ååªå¤±ï¼å æ­¤éè¦åæè½è¨ºçµ¦å°å®¶ãç¶èï¼åç´ç¼ç§ä¿å¥æä¾èå¯è½ç¡æ³è­å¥ç·æ¥ææ³ï¼å¯è½æå»¶èª¤ç§è­·ãæä¾è§£éçäººå·¥æºæ§ (AI) å¯ä»¥å å¼·ä»åçè½è¨ºæ±ºç­ãæåç ç©¶åç¨® AI è§£éå¦ä½å¹«å©æä¾èååéè¦ç«å³æéç·æ¥å°ç§è½è¨ºçæ£èãæåå»ºç«äºè§£éæ§ AI æ¼ç®æ³ï¼ä»¥å¾ä¾è¡ç¼ç§è­·çè³æé æ¸¬éåç¼æè¡éæ±ï¼ä½çºè­å¥é«é¢¨éªæ£èçä»£çãæåç´å¥äºå§å¨åäºå¾è§£éæ§ï¼ä¸¦èé©åå¸«é²è¡äºä¸é ç·ä¸ç ç©¶ï¼ä»¥è©ä¼°äººæ©åéçè¡¨ç¾ï¼è¡¡éè½è¨ºæºç¢ºåº¦ä¸¦åæè AI çäºåï¼åæ¬åæçãä»»åæéåä½¿ç¨èé«é©æç¥ãå¨ 87 ååèèä¸­ï¼AI æ¯æ´æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½¿ç¨ AI/æªä½¿ç¨çæ¯ä¾çº 59.9%/50.8%ï¼ï¼åç®¡äººæ©åéçè¡¨ç¾ä¸å¦å®ç¨ä½¿ç¨ AIãåèèèªçºä»åå¨ä½¿ç¨å§å¨æ¨¡åææ´å¤å°ç´å¥äº AI å»ºè­°ï¼ä¸¦èªçºå®æ´æç¨ä¸æ´æå¸æãæ²æè§£éï¼AI å»ºè­°çåå·®æå¢å ãAI æ¯æ´ä¸¦æªå¢å å·¥ä½éãä¿¡å¿åä¿¡ä»»ï¼ä½æ¸å°äºææ°ãå¨ä¸åå®ç¨çæ¸¬è©¦éä¸­ï¼æåçé»çå­åå§å¨æ¨¡åå¨é æ¸¬æè¡çµææ¹é¢åå¥éå°äº 77% å 71% çæºç¢ºåº¦ãæåæ¾åºå¨åç´ç¼ç§ä¿å¥ä¸­ï¼äººæ©åéåä½ç®¡çéåç¼çæ©æï¼ä¸¦æ³¨æå°éç¶ AI æé«äºè½è¨ºæºç¢ºåº¦ï¼ä½å³ä½¿æè§£éï¼å®ä¹é¡¯ç¤ºåºèå®ç¨ä½¿ç¨ AI ç¸æ¯çæè½å·®è·ãäººé¡åèå¨é«çæ±ºç­ä¸­ä»ç¶è³ééè¦ï¼éå¼·èª¿äºæªä¾ç ç©¶åªååä½ãç¢ºä¿æ­£é¢ç¶é©åå®å¨ä½¿ç¨ AI çå¿è¦æ§ã</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

æè¦ï¼å¨é«å­¸å½±åä¸­ï¼ç¹å¥æ¯å¨æ©æç¾çæª¢æ¸¬åé å¾ä»»åä¸­ï¼è¾¨å¥ AI æ¨¡åé æ¸¬èå¾çåçå°æ¼è©ä¼°å¶æ±ºç­çå¯é æ§è³ééè¦ãå³çµ±çè§£éæ¹æ³å¨è­å¥é«å­¸å½±ååé¡ä¸­å¯è­å¥çæ±ºå®æ§ç¹å¾µæé¢è¨ææ°ï¼å¶ä¸­åå¥æ§ç¹å¾µå¾å¾®å¦æä¸¦ä¸æé¡¯ãçºäºå½åéä¸å·®è·ï¼æåæåºäºä¸åå¯è§£éçæ¨¡åï¼è©²æ¨¡åå·åæ±ºç­æ¨çåç¹å¾µè­å¥è½åãæåçåæ³ä¸åæª¢æ¸¬æå½±é¿åçå½±åæ¨¡å¼ï¼éæ­ç¤ºäºæ¨åæ¨¡åæçµé æ¸¬çæ±ºå®æ§ç¹å¾µãééå¯¦æ½æåçæ¨¡åï¼æåå¯ä»¥ææè­å¥åè¦è¦ºåç±æ¸æé©åæ¨¡åå©ç¨çé¡ç¹å®ç¹å¾µï¼å¾èæ·±å¥äºè§£æ·±åº¦å­¸ç¿æ¨¡åçæ±ºç­éç¨ãæåå¨è¦æ±å´æ ¼çé«å­¸é å¾ä»»åé åé©è­äºæåçæ¨¡åï¼å±ç¤ºäºå¶å¨æé« AI å¨é«çä¿å¥ä¸­çå¯é æ§åç¼ç¾é å¾çè§£åéç¾ççæ°ç¥è­æ¹é¢çåæåæ½åã

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

æè¦ï¼æ¬ç ç©¶æ¢è¨ç·ä¸å¥åº·ç¤¾ç¾¤ä¸­å°æ±è³è¨æ¯æçåé¡ãåæï¼ä»¥åæå¹«å©çè©åä¹éçéä¿ãæåå»ºç«äºä¸çµæ¨è¨çåç­éå°è³æéï¼ä¸¦éç¼äºå¤æ¨¡ææ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥å¯é å°é æ¸¬è³è¨æ¯æåé¡ååæãæåæ¡ç¨å¯è§£éç AI ä¾æ­ç¤ºè³è¨æ¯æäº¤æµä¸­èå«çæç·ï¼è­ææç·å¨æä¾è³è¨æ¯æä¸­çéè¦æ§ãéç¨®æç·æ¯æåè³è¨æ¯æä¹éçè¤éäº¤äºä½ç¨ä»¥åä¸¦æªè¢«ç ç©¶éãæ¬ç ç©¶æ¹é²äºç¤¾ææ¯æçè«ï¼ä¸¦çºä½¿ç¨èæ±ºç­è¼å©å·¥å·çéç¼å¥ å®äºåºç¤ãè¨è«äºé²ä¸æ­¥çå½±é¿ã

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

æè¦ï¼å¨ç§æé£éç¼å±çæä»£ï¼ä¸ä½æå¤çè¨ªå®¢å·²å¨å¨çæå®¤ä¸­ä½æä¸å¸­ä¹å°ï¼é£å°±æ¯äººå·¥æºæ§ãçæå¼ AIï¼ä¾å¦ ChatGPTï¼æ¿è«¾å¨æè²é åæèµ·ä¸å ´é©å½ï¼ä½å®å»æ¯ä¸æéé¢åãå®å¨åäººåå­¸ç¿æ¹é¢çæ½åï¼å»å ä½å¼ãä¸æºç¢ºä»¥åæè²å·¥ä½èé£ä»¥å°å¶ææèå¥æå­¸è¨­è¨ç­åé¡èæµé·ãæåæ­£ç«å¨éæè²åæ²¿çéç·£ï¼é¡¯ç¶æåéè¦éå¸¸å°å¿å°æ¢ç´¢éçé åãéæ¯ä¸åéå¤§çææ°ï¼å¯è½ææå®³æåæè²éç¨çå®æ´æ§åå¹å¼ãé£éº¼ï¼æåå¦ä½å°éäºææ°è½åçºæ©éï¼ç¶ä¸é©ç¶å°ä½¿ç¨æï¼AI å·¥å·å¯è½ææçºè¤è£½è²¼ä¸å¿æçå®ç¾å·¥å·ï¼ä¸¦è¿éèèæ¹å¤æ§æç¶­ãåµé ååæ·±å¥çè§£ï¼éäºé½æ¯æåå¿«éè®åçä¸çä¸­æéè¦çæè½ãæå¸«åè¦ºå¾ä»åæ²æè½åå©ç¨éé æè¡ï¼éæ´å¤§äºæè²å·¥ä½èåæ©æ§ä¹éçæ¸ä½é´»æºãè§£æ±ºéäºåé¡éè¦æ·±å¥çç ç©¶æ¹æ³ãæåå°æ¡ç¨å¯¦è­ç ç©¶ï¼åéæè¡æ¥åæ¨¡åï¼ä¾è©ä¼°æè²å·¥ä½èåå­¸çå°çæå¼ AI çæåº¦ãäºè§£ä»åççæ³ãä½¿ç¨æ¨¡å¼åéç¤æ¯åµé ææè§£æ±ºæ¹æ¡çç¬¬ä¸åééµæ­¥é©ãæ¬ç ç©¶å°ä½çºæªä¾ç ç©¶äººå¡æç¨çæµç¨æåï¼æ ¹ææ­¤èèªªæçæ­¥é©éè¡ä»åèªå·±çæ¸æ

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike GrÃ¼ne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, AndrÃ© Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

æè¦ï¼é¨èé«çä¿å¥ç³»çµ±çæ¸ä½åï¼äººå·¥æºæ§å¨é«å­¸é åä¸­è®å¾æ´å æ®åãç¹å¥æ¯æ©å¨å­¸ç¿å¨æéåºååé¡ç­è¤éä»»åä¸­å±ç¾åºæ¥µå¤§çæ½åï¼ä½éå¸¸æ¯ä»¥éæåº¦åå¯çè§£æ§çºä»£å¹ãéå°è´äººé¡ç¼ºä¹ä¿¡ä»»ï¼å¾èé»ç¤äºå¶ç©æ¥µä½¿ç¨ãå¯è§£éçäººå·¥æºæ§è©¦åééæä¾å°æ±ºç­éç¨çæ´å¯ä¾å½è£éä¸å·®è·ï¼ä½å¶ä¸åæ¹æ³çå¯¦éæç¨å°ä¸æ¸æ¥ãæ¬ææåºäºä¸ååºæ¼ä½¿ç¨èç ç©¶çè©ä¼°ï¼å¶ä¸­åå«äº Grad-CAM è§£éæ¹æ³ï¼ä¸¦å°å¶æç¨æ¼ç¥ç¶ç¶²è·¯ä»¥åé¡æéåºåæ°çåå¼å¸æ¸æä¸­çå¼å¸ãæåå±ç¤ºäºä¸åå©çç¸éèå°å¯è§£éæ§æ¹æ³çæç¥æç¨ï¼æ­ç¤ºäºå¯¦ç¾å¯¦ééæåº¦çé£åº¦ï¼ä»¥åè¨±å¤åèèå¸æç²å¾æ´æ·±å¥çè§£éã

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) èé«çè¨ºæ·æ´å
çºè¨åºæ±ºç­æä¾äºä¸åæåæ¯çéå¾ãæ¬ç ç©¶æ¦è¿°äºä¸ç¨®æ°ç©æ¹æ³çéç¼ï¼ç¨æ¼é¶æ¬¡å­¸ç¿/å°éå­¸ç¿æå¢å­¸ç¿ (ICL)ï¼æ¹æ³æ¯ä½¿ç¨å¤å±¤çµæ§åæç¤ºæ´åé«çé åç¥è­ãæåéæ¢è¨äºä½¿ç¨èè LLM ä¹éå©ç¨®æºéæ¹å¼çåæï¼æ¸å¼å°è©± (NC) æ¹å¼ï¼å®æéæ­¥èçè³æï¼ä»¥åèªç¶èªè¨å®åå (NL-ST) æ¹å¼ï¼å®æä½¿ç¨é·ç¯æäºæç¤ºã
æåçç ç©¶ç³»çµ±æ§å°è©ä¼°äºè¨ºæ·æºç¢ºæ§åé¢¨éªå å­ï¼åæ¬æ§å¥åè¦ååé°æ§çï¼ä½¿ç¨äºä¸ååå« 920 åæ£èè¨éçè³æéï¼æ¡ç¨åç¨®å°éå­¸ç¿æå¢ãçµæè¡¨æï¼å³çµ±çè¨åºæ©å¨å­¸ç¿ (ML) æ¨¡åéå¸¸å¨é¶æ¬¡å­¸ç¿åå°éå­¸ç¿è¨­å®ä¸­è¡¨ç¾åªæ¼ LLMãç¶èï¼ç¶ä½¿ç¨å°éå­¸ç¿ç¯ä¾ä»¥åææçå¯è§£é AI (XAI) æ¹æ³ä½çºé åç¥è­ä¾æºæï¼æè½å·®è·æé¡¯èç¸®å°ãæ­¤å¤ï¼é¨èæéåè¶³åç¯ä¾æ¸éå¢å ï¼å°è©±æ¹å¼ (NC) å¹¾ä¹å¯ä»¥åª²ç¾ ML æ¨¡åçæè½ãæå¼å¾æ³¨æçæ¯ï¼LLM ç¸å°æ¼ ML æ¨¡åå±ç¾åºç¸ç¶ææ´ä½³çææ¬æææºç¢ºåº¦ã
æ¬ç ç©¶è­å¯¦ï¼ééé©ç¶çé åç¥è­åéèº«æé çæºéç­ç¥ï¼LLM å¯ä»¥é¡¯èå¢å¼·è¨ºæ·ç¨åºãéäºç¼ç¾çªé¡¯äºæä½³åè¨ç·´ç¯ä¾æ¸éåæºéæ¹å¼çéè¦æ§ï¼ä»¥æé«æºç¢ºåº¦ä¸¦æ¸å° LLM æç¨ä¸­çåå·®ã

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel MirÃ³-Nicolau, Gabriel MoyÃ -Alcover, Antoni Jaume-i-CapÃ³, Manuel GonzÃ¡lez-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

æè¦ï¼é¨èå°æ·±åº¦å­¸ç¿æ¨¡åä¾è³´æ§çå¢å ï¼å ä¸å¶åºæçéæåº¦ä¸è¶³ï¼ä¿ä½¿ä¸åæ°çç ç©¶é åç¼å±ï¼ç¨±çºå¯è§£é AI (XAI) æ¹æ³ãéäºæ¹æ³æ¨å¨ééæ·±å¥äºè§£æ±ºç­èå¾çåçï¼ä¾æåæçµä½¿ç¨èå°èªååç³»çµ±çä¿¡è³´ãæ¬ææåºäºä¸ç¨®è¡¡éä½¿ç¨èå° XAI ç³»çµ±ä¿¡è³´åº¦çæ°ç©æ¹æ³ï¼åè¨±å°å¶é²è¡æ¹é²ãæåæåºçææ¨çµåäºå®¢è§è§é»ä¸çæè½ææ¨åä¿¡è³´ææ¨ãçºäºé©è­éåæ°ç©çæ¹æ³ï¼æåå¨ä¸åçå¯¦çé«çå ´æ¯ä¸­é²è¡äºä¸åæ¡ä¾ç ç©¶ï¼ä½¿ç¨ XAI ç³»çµ±å¾ X åå½±åä¸­åµæ¸¬èºçã

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

æè¦ï¼COVID-19 ç«æå°å¨çå¬å±è¡çé æå£åï¼å¿é é²è¡æºç¢ºçè¨ºæ·åå¹²é ï¼ä»¥æ§å¶ç¾çå³æ­ä¸¦éä½æ­»äº¡çãæ¬æä»ç´¹äºä¸åå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åï¼å°éè¨­è¨ç¨æ¼ééè¸é¨ X å (CXR) å½±åæ¹åå° COVID-19 é å¾ççè§£åä¿¡è³´ãééæ´åå¤§è¦æ¨¡é è¨ç·´å½±åç·¨ç¢¼å¨ãé¢¨éªç¹å® Grad-CAM åè§£ååååµæ¸¬æè¡ï¼æåçåæ³ç¢çååå¯è§£éççµæï¼ææææå¿è¦çç¾çç¹å¾µï¼åæå°æ³¨æ¼ç½è¦ä½ééµçç°å¸¸ååãæåçæ¨¡åé æ¸¬çµæééé¢¨éªååå®ä½æä¾å¢å¼·çæ¸æ°åº¦åéæåº¦ï¼è®è¨åºé«çè½å¤ å¨æ´äºè§£é å¾è¦è§£çææ³ä¸ï¼å°± COVID-19 è¨ºæ·ååºææºçæ±ºç­ãæåå¨å¤ä¸­å¿çå­è³æéä¸è©ä¼°ææåºçæ¹æ³ï¼ä¸¦éééååè³ªåè©ä¼°è­æå¶æææ§ï¼éå°åªç°ç C ææ¸ï¼0.764 å 0.727ï¼åæéç¸é AUCï¼0.799 å 0.691ï¼ãéäºçµæè¡¨æï¼æåå¯è§£éçæ·±åº¦çå­é æ¸¬æ¨¡åå¨é¢¨éªé æ¸¬æ¹é¢è¶è¶å³çµ±ççå­åææ¹æ³ï¼æåè¨åºæ±ºç­çè§£éæ§ï¼ä¸¦å¢å¼· AI ç³»çµ±çä¿¡è³´åº¦ã

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

æè¦ï¼<paragraph>å¨éå»å¹¾å¹´ï¼è¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS) ä¸­çäººå·¥æºæ§ (AI) å¨å©ç¨æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¶æ§æ¹é¢ç¼æ®äºééµä½ç¨ãåç®¡ AI æ¨¡åå·æä»¤äººæ»¿æçè½åï¼ä½ç¼ºä¹éæåº¦åå¯è§£éæ§ï¼ç¹å¥æ¯å¨å¯é æ§çºå¿è¦èéçé«çèæ¯ä¸ï¼éå¸¶ä¾äºéå¤§çææ°ãå¨ä¸å½±é¿é æ¸¬ç²¾æºåº¦çææ³ä¸å¯¦ç¾éæåº¦ä»ç¶æ¯ä¸é ééµææ°ãæ¬ææåºäºä¸ç¨®æ°æ¹æ³ï¼å³ Rad4XCNNï¼ä»¥å¢å¼· CNN è¡çç¹å¾µçé æ¸¬è½åï¼åæå·åæ¾å°ç¹å¾µåºæçå¯è§£éæ§ãRad4XCNN ä¸åæ¼åºæ¼é¡¯èæ§åçå³çµ±æ¹æ³ï¼å®ééæ¾å°çµå­¸å°å¯çè§£çå«ç¾©è CNN è¡çç¹å¾µéè¯èµ·ä¾ï¼çºè¶è¶è¦è¦ºååè¡¨çè§£éæ¹æ³æä¾äºæ°çè§é»ãæåä»¥ä¹³çåé¡ä»»åä½çºæ¡ä¾ç ç©¶ï¼å¨è¶é³æ³¢å½±åè³æéä¸è©ä¼° Rad4XCNNï¼åæ¬ä¸åç·ä¸è³æéåå©åç¨æ¼å§é¨åå¤é¨é©è­çå§é¨è³æéãä¸äºééµçµæå¦ä¸ï¼i) è ViT è¡çç¹å¾µåæ¾å°ç¹å¾µç¸æ¯ï¼CNN è¡çç¹å¾µä¿è­äºæ´ç©©å¥çæºç¢ºåº¦ï¼ii) å³çµ±çè¦è¦ºååè§£éæ¹æ³å­å¨ä¸äºç¼ºé·ï¼iii) Rad4XCNN æ²æç§ç²æ¨¡åæºç¢ºåº¦ä¾æåå¶å¯è§£éæ§ï¼iv) Rad4XCNN æä¾äºå¨å±è§£éè¦è§£ï¼ä½¿é«å¸«è½å¤ åææ¨¡åè¼¸åºåç¼ç¾ãæ­¤å¤ï¼æåå¼·èª¿å°å¯è§£éæ§æ´åå° AI æ¨¡åä¸­å°æ¼å¢å¼·è¨åºå¯¦åä¸­çä¿¡ä»»åæ¡ç¨è³ééè¦ï¼ä¸¦å¼·èª¿äºæåçæ¹æ³å¦ä½è½ç·©è§£èå¯è§£é AI æ¹æ³ç¸éçä¸äºçæ®ã</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

æè¦ï¼é¨èäººå·¥æºæ§ (AI) çæ®åæ´åï¼å¨æ¶å AI é©åç³»çµ±çäºæä¸­ï¼è²¬ä»»åç¾©åæ­¸å±¬ç¢çäºè¤éçææ°ãéäºç³»çµ±çäºé£æ§ãAI å¼ç¼äºæçå«çåé¡ï¼å ä¸ AI æè¡çä¸ç¢ºå®æ§åç¼ºä¹ç¸ææ³è¦ï¼ä½¿å¾å³çµ±è²¬ä»»æ­¸å±¬é¢è¨ææ°ãçºæ­¤ï¼æ¬ç ç©¶æåºäºä¸ç¨®è¨ç®åæåè¡¡ (CRE) æ¹æ³ï¼ä»¥å»ºç«ä¸åé£è²«ä¸å¨å«çä¸å¯æ¥åçè²¬ä»»æ­¸å±¬æ¶æ§ï¼é©ç¨æ¼ææå©å®³éä¿äººãè¨ç®æ¹æ³æä¾äºçµæ§åçåæï¼åæäºæ¦å¿µæ¹æ³å¨èçåæä¸å¤é¢åæå¢æçéå¶ï¼å±ç¤ºäºè©²æ¶æ§å¨è²¬ä»»æ­¸å±¬éç¨ä¸­å·åçå¯è§£éæ§ãé£è²«æ§åé©ææ§ãæåæ¢è¨äºèåè¡¡è¨ç®ä¸­ç´¢è³ ç¸éçåå§ååå±¤ç´çééµä½ç¨ãæåä»¥ AI è¼å©é«çæ±ºç­æ¯æ´ç³»çµ±çºæ¡ä¾ç ç©¶ï¼èªªæä¸åçåå§åå¦ä½å°è´ä¸åçè²¬ä»»åéãè©²æ¶æ§æä¾äºå° AI å¼ç¼äºæä¸­åè²¬å¶çå¯¶è²´è¦è§£ï¼ééæçºç£æ§ãä¿®è¨ååæï¼ä¿é²äºæ°¸çºä¸æéæ§çç³»çµ±ç¼å±ã

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

æè¦ï¼äººå·¥æºæ§ééé æ¸¬æ¨¡ååå©é«çå°æ¥­äººå¡ï¼å¤§å¹è½è®äºè¨åºæ±ºç­å¶å®ãæ¬ç ç©¶æ¢è¨äºå¨é«çä¿å¥ä¸­ä½¿ç¨äººå·¥æºæ§æç¨ç¨å¼æå¬å¹³æ§åå¯è§£éæ§çééµéæ±ï¼ä»¥ç¢ºä¿å¨ä¸åçæ£èäººå£çµ±è¨è³æä¸­ç²å¾å¬å¹³ççµæãééå°æ³¨æ¼æè¡çç¸éæ­»äº¡ççé æ¸¬æ¨¡åï¼æåæåºäºä¸ç¨®æ¹æ³ï¼è©²æ¹æ³æå­¸ç¿ä¸åæè½æä½³åçé æ¸¬æ¨¡åï¼ç¶å¾æ¡ç¨è½ç§»å­¸ç¿éç¨ä¾ç¢çä¸åå·ææ´å¥½å¬å¹³æ§çæ¨¡åãæåçæ¨¡åéå¼å¥äºä¸ç¨®æ°ç©çåºæ¼æåçç¹å¾µéè¦æ§æ¼ç®æ³ï¼æ¨å¨é¡ææ¯åç¹å¾µå¨å¢å¼·é æ¸¬å¬å¹³æ§æ¹é¢çè²¢ç»ãèç¾æçå¯è§£éæ§æ¹æ³å°æ³¨æ¼è§£éç¹å¾µå°é æ¸¬æè½çè²¢ç»ä¸åï¼æåæåºçæ¹æ³ç¨ç¹å°å½è£äºçè§£æ¯åç¹å¾µå¦ä½æå©æ¼å¬å¹³æ§çå·®è·ãéé é²å±è³ééè¦ï¼å çºæè¡ççæ­»äº¡çå¾é«ï¼ä¸å¨ä¸åä¹ä¸çé«é¢æ­»äº¡ä¸­æ®æ¼èè§è²ãæåçæ¨¡åä¸åæå©æ¼è­å¥åæ¸è¼é æ¸¬æ¨¡åä¸­çåå·®ï¼éè½ééæé«æ¨¡åé æ¸¬çéæåº¦åå¬å¹³æ§ä¾å¹é¤é«çä¿å¥å©çç¸éèä¹éçä¿¡ä»»ï¼é²èæå©æ¼æä¾æ´å¬å¹³ä¸å¼å¾ä¿¡è³´çé«çä¿å¥æåã

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

æè¦ï¼ç¾ä»ï¼æé¬±çæ¯ä¸åéè¦çè­°é¡ãæ ¹æä¸çè¡ççµç¹ (WHO) çè³æï¼å¨ 2023 å¹´ï¼è¶é 2.8 åäººæ­£å¨èæé¬±çæé¬¥ãéæ¯ä¸åé¾å¤§çæ¸å­ï¼å¦æä¸èªççå¾ï¼éäºæ¸å­å°æå¿«éå¢å ãå¤§ç´æ 48.9 åäººæ¯ç¤¾ç¾¤åªé«ä½¿ç¨èãäººåå¨ TwitterãFacebookãRedditãInstagram ç­å¹³å°ä¸è¡¨éèªå·±çæååæç·ãéäºå¹³å°åå«æå¹å¼çè³è¨ï¼å¯ç¨æ¼ç ç©¶ç®çãå·²ç¶å¨åç¨®ç¤¾ç¾¤åªé«å¹³å°ä¸é²è¡äºå¤§éçç ç©¶ãç¶èï¼éäºåªåä»å­å¨æäºéå¶ãç¹å¥æ¯ï¼ååçç ç©¶åå°æ³¨æ¼åµæ¸¬æ¨æä¸­çæé¬±çåæé¬±ççå¼·åº¦ãæ­¤å¤ï¼è³æéæ¨ç±¤ä¸­å­å¨ä¸æºç¢ºçææ³ãå¨éé ç ç©¶å·¥ä½ä¸­ï¼ä½¿ç¨åºæ¼è©å½æ¨ç±¤ç Twitter è³æåº«ä¸­çæ¨æé æ¸¬äºäºç¨®é¡åçæé¬±çï¼éæ¥µåãéåº¦ãç²¾ç¥çåãéå¸ååç¢å¾ï¼ãå¯è§£éç AI ç¨æ¼ééå¼·èª¿ä»£è¡¨æé¬±çé¡åçæ¨æé¨åä¾æä¾æ¨çãå¾ Transformersï¼BERTï¼ä¸­æåçéåç·¨ç¢¼å¨è¡¨ç¤ºç¨æ¼ç¹å¾µæååè¨ç·´ãæ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¹æ³ç¨æ¼è¨ç·´æ¨¡åãBERT æ¨¡ååç¾åºææå¸æççµæï¼éå° 0.96 çæ´é«æºç¢ºåº¦ã

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

æè¦ï¼æ·±åº¦å­¦ä¹ æ­£å¤§å¹è½è®é«å­¸å½±ååæ¾å°ç·å­¸é åï¼è½è¾¨è­é«å­¸å½±åä¸­çççï¼åæ¬é»è¦æ·å±¤ææ (CT) å X åææãç¶èï¼æ·±åº¦å­¸ç¿æ¨¡åçæè½ï¼ç¹å¥æ¯å¨åå²ä»»åä¸­ï¼å¸¸å¸¸åå°å»£æ³è¨»è§£è³æééæ±çéå¶ãçºäºæå°æ­¤ææ°ï¼ééå¯è§£é AI ååäºå¯¦è§£éçç¢çï¼æ¢ç´¢å¼±ç£ç£èªæåå²çè½åãæ¬ç ç©¶çç¯åæ¯éç¼ä¸ç¨®æ°çåäºå¯¦å§ææ¹æ³ (COIN)ï¼è©²æ¹æ³ä½¿ç¨çææ¨¡åå°é æ¸¬çåé¡æ¨ç±¤å¾ç°å¸¸ç¿»è½çºæ­£å¸¸ãä¾å¦ï¼å¦æåé¡å¨å°è¼¸å¥çé«å­¸å½±å X è¦çºç°å¸¸ï¼è¡¨ç¤ºå­å¨ççï¼åçææ¨¡åæ¨å¨å§æç°å¸¸ååï¼å¾èéè½åé¡å¨çåå§é æ¸¬æ¨ç±¤ãæ­¤æ¹æ³ä½¿æåè½å¤ ç¢ççççç²¾ç¢ºåå²ï¼èç¡éä¾è³´æ¼é åå­å¨çåå²é®ç½©ãè³ééè¦çæ¯ï¼å©ç¨å½±åå±¤ç´æ¨ç±¤ï¼éæ¯å»ºç«è©³ç´°çåå²é®ç½©å®¹æåå¾ãè©²æ¹æ³çæææ§ééåå²åæç®æ¨åå¾ææ²å°¼äºå¡ç¾åå¤§å­¸é«é¢åå¾ç CT å½±åä¸­çå¯¦éèèè«ç¤ä¾è­æãç ç©¶çµæè¡¨æï¼COIN é é è¶éå·²å»ºç«çæ­¸å æ¹æ³ï¼ä¾å¦ RISEãScoreCAM å LayerCAMï¼ä»¥å Singla ç­äººæåºçå¦ä¸ç¨®åäºå¯¦è§£éæ¹æ³ãæ­¤è­æè¡¨æï¼COIN æ¯ä¸ç¨®å¾æåéç CT å½±åä¸­è«ç¤èªæåå²æ¹æ³ï¼ä¸¦å¨é«çä¿å¥ä¸­è®æ·±åº¦å­¸ç¿æç¨æ´ææ¼åå¾åæ´ææçéé²ä¸æ­¥ï¼å¶ä¸­è¨»è§£è³æå¾ç¨å°ã

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

æè¦ï¼å¨æ¬æä¸­ï¼æåæ¢è¨æ¸ä½äººæå­¸ç§ (DH) ä½çºä¸éå­¸ç§èæ··åæºè½ (HI) ä½çºä¸åç ç©¶å¸ç¯ä¹éçååä½ç¨ãå¨ DH ç ç©¶ä¸­ï¼æ¸ä½æ¹æ³çä½¿ç¨ï¼ç¹å¥æ¯äººå·¥æºæ§çä½¿ç¨ï¼åå°ä¸ç³»åè¦æ±åéå¶ãæåèªçºéäºè¦æ±åéå¶ç²å¾ HI çè½ååç®æ¨çååæ¯æãæåçè²¢ç»åæ¬æ¾åºäºåéæ¨£ç DH è¦æ±ï¼æåç AI ç³»çµ±éè¦è½å¤  1) èï¼äººé¡ï¼å­¸èåä½ï¼2) æ¯æ´è³ææ¹è©ï¼3) æ¯æ´å·¥å·æ¹è©ï¼4) å¯è¦ºä¸¦è¿ååç¨®è§é»ï¼5) æ¯æ´é è·åè¿è·é¢é±è®ãæåå°æ··åæºè½ç CARE ååï¼åä½ãé©æãè² è²¬åå¯è§£éï¼ä½çºçè«æ¶æ§ï¼ä¸¦å°éäºååå°æå° DH è¦æ±ãå¨æ­¤å°æä¸­ï¼æåç´å¥ç¯ä¾ç ç©¶å°æ¡ãæå¾ï¼æåæ¢è¨å¦ä½å° DH çè¦è§£æç¨æ¼ HIï¼ä¸¦è¨è«çµåéå©åå­¸ç§çéæ¾ææ°ã

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

æè¦ï¼åºç¤æ¨¡å (FM) å·æå¾¹åºæ¹è®é«å­¸å½±åçå·¨å¤§æ½åãç¶èï¼å®åå¨ç¾å¯¦ä¸çè¨åºç°å¢ä¸­çé¨ç½²éè¦å»£æ³çå«çèéãæ¬ææ¨å¨å¼·èª¿è FM ç¸éçå«çåé¡ï¼ä¸¦æåºä¸åæ¡æ¶ä¾æå°å®åå¨é«å­¸ä¸­çè² è²¬ä»»éç¼åå¯¦æ½ãæåä»ç´°å¯©æ¥äºå«çåé¡ï¼ä¾å¦æ£èæ¸æé±ç§ãåå·®ç·©è§£ãæ¼ç®æ³éæåº¦ãå¯è§£éæ§ååè²¬å¶ãææåºçæ¡æ¶æ¨å¨åªåèæ®æ£èç¦å©ãæ¸è¼æ½å¨é¢¨éªï¼ä¸¦å¹é¤å° AI è¼å©é«çä¿å¥çä¿¡ä»»ã

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

æè¦ï¼ç²çèºçæ¯ä¸ç¨®æ¥çå´éçå¨çå¥åº·åé¡ï¼éè¦åé²çè¨ºæ·æ¹æ³ãæ¬ç¯è©è«æ¢è¨äºäººå·¥æºè½èæ¾å°ç¹å¾µåæå¨ç²çèºçè¨ºæ·ä¸­çæç¨ãå¨ç¬¦å PRISMA æåçææ³ä¸ï¼å°å¤åè³æåº«é²è¡äºåé¡§ï¼ç´å° 2023 å¹´ 10 æãééçµåééµå­ï¼ç¼ç¾äºä¸ç¯éæ¼ç²çèºçåç¸éä¸»é¡çè±æå­¸è¡åºçç©ãå¨ç§»é¤ 109 ç¯éè¤æç»å¾ï¼åå§æå°å±åå³ 267 ç¯è«æãå¨æ ¹æé åç¢ºå®çæ¨æºï¼æ·æ±°äº 124 ç¯æç« çæè¦åæ¨é¡å¾ï¼é¸åºäºç¸éç ç©¶ãå¨é²è¡å¨é¢åæå¾ï¼é¡å¤æé¤äºå­é ç ç©¶ãå¨ç´å¥ç 28 é ç ç©¶ä¸­ï¼çµåè¶é³æ³¢ (US) å½±åçæ¾å°ç¹å¾µåæï¼è­æäºå¶å¨è¨ºæ·ç²çèºçæ¹é¢çæææ§ãç ç©¶çµæä¸ä¸ï¼æäºç ç©¶æåºäºåªæ¼ç¾ççæ°ç­ç¥ãæç»å¼·èª¿äºäººå·¥æºè½æ¨¡åé¢è¨çåç¨®ææ°ï¼åæ¬å¯è§£éæ§åé¡ãè³æééå¶åæä½å¡ä¾è³´æ§ã28 é ç´å¥ç ç©¶çç¶åç¼ç¾æå°ï¼éè¦æ¨æºåå·¥ä½ååç»æ§å¤ä¸­å¿ç ç©¶ä¾è§£æ±ºéäºåé¡ãæ­¤å¤ï¼éç¢ºå®äºåæéäºéç¤çæ¹æ³ï¼ä¾å¦å¯è§£éäººå·¥æºè½æè¡ååäººåé«çæè¡çé²æ­¥ãæ¬ç¯è©è«éé»æ¢è¨äºäººå·¥æºè½åæ¾å°ç¹å¾µåæå¦ä½è½è®ç²çèºççè¨ºæ·åæ²»çãåç®¡å­å¨ææ°ï¼ä½æªä¾å°å¤å­¸ç§åä½ãè¨åºé©ç¨æ§é©è­åæ¼ç®æ³æ¹é²çç ç©¶ï¼ä»ææ½åæ¹åç²çèºçæ²»çä¸­çæ£èé å¾åè¨ºæ·ç²¾æºåº¦ã

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

æè¦ï¼<paragraph>è¿å¹´ä¾ï¼ä¹³çççè¡çè¿éå¢å ï¼ä½¿å¶æçºå¨çä¸»è¦çæ­»äº¡åå ä¹ä¸ãå¨ææççä¸­ï¼ä¹³çè¿ä»çºæ­¢æ¯æå¸¸è¦çãæåè¨ºæ·æ­¤ç¾çéè¦å¤§éçæéåå°æ¥­ç¥è­ãç±æ¼ä¹³ççæª¢æ¸¬éç¨èæï¼å æ­¤ééå»ºç«æ©å¨å­¸ç¿æ¨¡åä¾é æ¸¬ï¼æå©æ¼é²æ­¢å¶é²ä¸æ­¥æ´æ£ãæ©å¨å­¸ç¿åå¯è§£é AI å¨åé¡ä¸­è³ééè¦ï¼å çºå®åä¸åå¯ä»¥æä¾æºç¢ºçé æ¸¬ï¼éå¯ä»¥æ·±å¥äºè§£æ¨¡åå¦ä½ååºæ±ºç­ï¼æå©æ¼çè§£åä¿¡è³´åé¡çµæãå¨æ­¤ç ç©¶ä¸­ï¼æåè©ä¼°ä¸¦æ¯è¼äºäºç¨®ä¸åçæ©å¨å­¸ç¿æ¹æ³çåé¡æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä½¿ç¨äºä¸åä¸»è¦çè³æéï¼éå¡é«å­¸é¢é«é¢ç 500 åæ£èï¼ãäºç¨®ä¸åçç£ç£å¼æ©å¨å­¸ç¿æè¡ï¼åæ¬æ±ºç­æ¨¹ãé¨æ©æ£®æãéè¼¯è¿´æ­¸ãæ´ç´ è²æ°å XGBoostï¼å·²ç¨æ¼å¨æåçè³æéä¸åå¾æä½³çµæãæ­¤å¤ï¼æ¬ç ç©¶å° SHAP åææç¨æ¼ XGBoost æ¨¡åï¼ä»¥è§£éæ¨¡åçé æ¸¬ä¸¦äºè§£æ¯åç¹å¾µå°æ¨¡åè¼¸åºçå½±é¿ãæåæ¯è¼äºå¹¾ç¨®æ¼ç®æ³å°è³æé²è¡åé¡çæºç¢ºåº¦ï¼ä¸¦èè©²é åçå¶ä»æç»é²è¡å°æ¯ãå¨æå¾è©ä¼°å¾ï¼æ¬ç ç©¶ç¼ç¾ XGBoost éå°äºæä½³çæ¨¡åæºç¢ºåº¦ï¼çº 97%ã</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

æè¦ï¼æ·±åº¦å­¸ç¿ (DL) ç¨æ¼å¾ä¹³æ¿æå½±è¡å½±åè¨ºæ·ä¹³ççæ¨¡åéå¸¸ä»¥ãé»çå­ãæ¹å¼éä½ï¼éä½¿å¾é«çä¿å¥å°æ¥­äººå¡é£ä»¥ä¿¡ä»»åçè§£å¶æ±ºç­éç¨ãæ¬ç ç©¶æåºä¸åæ´åæ¶æ§ï¼çµåå·ç©ç¥ç¶ç¶²è·¯ (CNN) åå¯è§£éäººå·¥æºæ§ (XAI)ï¼ä»¥ä½¿ç¨ CBIS-DDSM è³æéå¢å¼·ä¹³ççè¨ºæ·ãæ¹æ³åå«ä¸åç²¾ç´°çè³æåèçç®¡ç·åé²éè³ææ´åæè¡ï¼ä»¥å°æè³æééå¶ï¼ä¸¦æ¡ç¨é åè¨ç·´çç¶²è·¯ï¼ä¾å¦ VGG-16ãInception-V3 å ResNetï¼é²è¡é·ç§»å­¸ç¿ãæåç ç©¶çéé»æ¯è©ä¼° XAI å¨è§£éæ¨¡åé æ¸¬ä¸­çæææ§ï¼éé»å©ç¨è±ªæ¯å¤å¤«æ¸¬åº¦éåè©ä¼° AI çæçè§£éåå°å®¶è¨»è§£ä¹éçä¸è´æ§ãéç¨®æ¹æ³å°æ¼ XAI å¨ä¿é² AI è¼å©è¨ºæ·ä¸­çå¯ä¿¡åº¦åå«çå¬å¹³æ§è³ééè¦ãæåç ç©¶çç¼ç¾èªªæäº CNN å XAI å¨æ¨é²ä¹³çè¨ºæ·æ¹æ³ä¸­çææåä½ï¼å¾èä¿é²äºåé² AI æè¡å¨è¨åºç°å¢ä¸­çæ´é æ¢æ´åãééå¢å¼· AI é©åæ±ºç­çå¯è§£éæ§ï¼éé å·¥ä½çº AI ç³»çµ±åé«çå¾æ¥­äººå¡ä¹éçæ¹ååä½å¥ å®äºåºç¤ï¼æçµè±å¯äºæ£èç§è­·ãæ­¤å¤ï¼æåç ç©¶çå½±é¿é é è¶åºäºç®åçæè¡ãå®é¼åµé²ä¸æ­¥ç ç©¶å¦ä½çµåå¤æ¨¡å¼è³æä¸¦æ¹å AI è§£éï¼ä»¥æ»¿è¶³è¨åºå¯¦åçéæ±ã

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

æè¦ï¼æ¬ç ç©¶æåºäºä¸ç¨®åµæ°çå¤æ¨¡ææ¸æèåæ¹æ³ï¼ç¨æ¼ç¼çè¡çºè­å¥ï¼å°çµ±è¨ç¸éåæèä»¥äººçºä¸­å¿çè¦è§£ç¸çµåãæåçåæ³å¼å¥äºå©é ééµåµæ°ï¼1) å°æ¸æé©åççµ±è¨ç¸éæ¬éæ´åå°èåç­ç¥ä¸­ï¼ä»¥ææå©ç¨ä¾èªç°è³ªæ¨¡æçè£åä¿¡æ¯ï¼ä»¥å 2) å°ä»¥äººçºä¸­å¿çéåç¹å¾µç´å¥å¤æ¨¡æè¡¨ç¤ºå­¸ç¿ä¸­ï¼ä»¥è©³ç´°å»ºæ¨¡ç¼çè¡çºãæåçæ¨¡åå¨åç¨®æ·±åº¦å­¸ç¿æ¶æ§ä¸­å¾å°é©è­ï¼å±ç¤ºäºåè¶çæ§è½åå»£æ³çé©ç¨æ§ãæåæåºäºä¸åå¯èªå®ç¾©çæ¡æ¶ï¼æ ¹æçµ±è¨é¡¯èæ§å°æ¯åæ¨¡æèåé©çåé¡å¨å°é½ï¼æ¨é²åæ§ååææçå¤æ¨¡æèåãæ­¤å¤ï¼æåçæ¨¡åæä¾å°å¤æ¨¡ææ¸æçå¯è§£éåæï¼æå©æ¼é«çä¿å¥ä¸­çå¯è§£éåå¯è§£é AIãééå¼·èª¿æ¸æå¤æ¨£æ§åæ¨¡æç¹å®è¡¨ç¤ºçéè¦æ§ï¼æåå¢å¼·äºå³çµ±çèåæè¡ï¼ä¸¦çºè­å¥è¤éçç¼çè¡çºè¨­å®äºæ°çæ¨æºãæåçç¼ç¾å°ä¿é²ä»¥æ£èçºä¸­å¿çé«çä¿å¥å¹²é åæ¯æå¯è§£éçè¨åºæ±ºç­å¶å®å·æéè¦æç¾©ã

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

æè¦ï¼ä»¥äººä¸ºæ¬çå¯è§£é AI (HCXAI) å¡å¯¼å°ç¤¾ä¼å±é¢æ´åå° AI è§£éä¸­ãHCXAI è¯è¯­çæ ¸å¿æ¯ç¤¾ä¼éæåº¦ (ST) æ¡æ¶ï¼å¶ç®æ æ¯è®© AI ç³»ç»çç¤¾ä¼ç»ç»èæ¯å¯¹ç¨æ·æ¥è¯´æ¯å¯çè§£çãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬å»ºè®®æ©å± ST æ¡æ¶ä»¥è§£å³å¤§åè¯­è¨æ¨¡å (LLM) ä¸­ç¤¾ä¼éè¯¯å½å çé£é©ï¼å°¤å¶æ¯å¨å¿çå¥åº·ç­ææé¢åãäºå®ä¸ï¼LLM è½å¤åºè²å°æ¨¡æè§è²åäººæ ¼ï¼è¿å¯è½å¯¼è´è®¾è®¡èçæå¾åç¨æ·å¯¹ç¤¾ä¼å±æ§çè®¤ç¥ä¹é´åºç°ééï¼ä»èæé£é©ä¿è¿æç»ªæçºµåå±é©è¡ä¸ºãè®¤ç¥ä¸å¬æ­£åä¸åççä¿¡ä»»ãä¸ºäºè§£å³è¿äºé®é¢ï¼æä»¬å»ºè®®ç¨ç¬¬äºä¸ªâW é®é¢âæ¥å¢å¼º ST æ¡æ¶ï¼ä»¥æç¡®è®¾è®¡èåç¨æ·èµäº LLM çå·ä½ç¤¾ä¼å±æ§ãæ­¤è¡¥åæ¨å¨å¼¥å LLM è½ååç¨æ·è®¤ç¥ä¹é´çå·®è·ï¼ä¿è¿åºäº LLM çææ¯å¨éå¾·ä¸è´è´£ä»»å°å¼ååä½¿ç¨ã

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

æè¦ï¼<paragraph>èæ¯ï¼æ°£è¸æ¯ä¸ç¨®å èºé¨èè¸å£ä¹éç°å¸¸éæ°£æå¼èµ·çæ¥æ§è¸èç¾çãçºäºè§£æ±ºæ·±åº¦å­¸ç¿ï¼DLï¼æ¨¡åç¶å¸¸ä¼´é¨çä¸éææ§ï¼å¯è§£éäººå·¥æºæ§ï¼XAIï¼æ¹æ³å·²è¢«å¼å¥ï¼ç¨æ¼æ¦è¿°è DL æ¨¡åååºçæ°£è¸è¨ºæ·ç¸éçååãç¶èï¼éäºè§£éæææèå¯¦éçç¶ååææåºå¥ï¼çªé¡¯åºé²ä¸æ­¥æ¹é²çå¿è¦æ§ãæ¹æ³ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼å°æ°£è¸çè¨åºç¥è­ç´å¥ XAI æ¹æ³ç¢ççæ¨¡åè§£éä¸­ï¼å¾èæåéäºè§£éçåè³ªãå©ç¨æ¾å°ç§é«å¸«å»ºç«ççç¶æç¹ªï¼æåçåæ³é¦åç¢çä¸åæ¨¡æ¿ï¼ç¨æ¼è¡¨ç¤ºæ°£è¸å¯è½ç¼ççååãç¶å¾å°æ­¤æ¨¡æ¿çå å¨æ¨¡åè§£éä¸ï¼ä»¥ç¯©é¸åºè¶åºæ¨¡æ¿éççç¡éè§£éãçºäºé©è­å¶æåï¼æåå°ä¸ç¨® XAI æ¹æ³é²è¡äºæ¯è¼åæï¼å¨å©åçå¯¦ä¸çè³æéä¸­è§£éå©å DL æ¨¡åæï¼åå¥æ¡ç¨åä¸æ¡ç¨æåçæ¨¡æ¿å¼å°ãçµæï¼ææåºçæ¹æ³å¨å»ºç«æ¼ä¸ç¨® XAI æ¹æ³ãå©å DL æ¨¡ååå©åè³æéçåäºç¨®åºæºæå¢ä¸­ï¼å§çµæ¹åäºåºæº XAI æ¹æ³ãå¨æ¯è¼æ¨¡åè§£éåçå¯¦çç¶ååæï¼ééåºæºæè½çæè½æ¹é²è¨ç®åºçå¹³åå¢éç¾åæ¯çºäº¤éæ¯ï¼IoUï¼ç 97.8% åéª°å­ç¸ä¼¼æ§ä¿æ¸ï¼DSCï¼ç 94.1%ãçµè«ï¼å¨æ°£è¸è¨ºæ·çèæ¯ä¸ï¼æåæåºäºä¸ç¨®æ¨¡æ¿å¼å°å¼æ¹æ³ï¼ç¨æ¼æ¹å AI è§£éãæåé ææåçæ¨¡æ¿å¼å°å°ééæ´åè¨åºé åå°æ¥­ç¥è­ï¼çºé¡æ AI æ¨¡åå»ºç«ä¸ç¨®æ°æ¹æ³ã</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by SÃ©amus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

æè¦ï¼<paragraph>å¨ç¶åæ©å¨ç¿»è­¯ (MT) é åä¸­ï¼Transformer æ¶æ§è«ç©èåºï¼æçºé»éæ¨æºï¼ç¹å¥æ¯å°æ¼é«è³æºèªè¨å°ãæ¬ç ç©¶æ¢è¨å¶å°ä½è³æºèªè¨å°çæè½ï¼åæ¬è±èªâæç¾è­èªåè±èªâé¦¬æå°èªèªè¨å°ãå¼å¾æ³¨æçæ¯ï¼æ¬ç ç©¶è­å¥åºæä½³è¶åæ¸åå­è©æ¨¡åé¡åï¼ä»¥é¡¯èæé« Transformer æ¨¡åå°ä½è³æºèªè¨å°çç¿»è­¯åè³ªã
ä½è³æºèªè¨çå¹³è¡è³æéçç¨ç¼ºæé»ç¤ MT çç¼å±ãçºäºè§£æ±ºéååé¡ï¼éç¼äº gaHealthï¼éæ¯æç¾è­èªçç¬¬ä¸åéèªå¥åº·è³æèªæåº«ãå°æ³¨æ¼å¥åº·é åï¼ä½¿ç¨æ­¤åå§è³æééç¼çæ¨¡åå¨ BLEU å¾åæ¹é¢è¡¨ç¾åºéå¸¸é¡¯èçé²æ­¥ï¼è LoResMT2021 å±äº«ä»»åä¸­çæ¨¡åç¸æ¯ãé¨å¾ä½¿ç¨å¤ç¶­åè³ªææ¨é¯èª¤åé¡æ³é²è¡çäººå·¥è©ä¼°é¡¯ç¤ºï¼èåºæ¼ RNN çå°ææ¨¡åç¸æ¯ï¼Transformer ç³»çµ±å¨æ¸å°æºç¢ºæ§åæµæ¢æ§é¯èª¤æ¹é¢è¡¨ç¾åºåªç°çæ§è½ã
æ­¤å¤ï¼æ¬è«æä»ç´¹äº adaptNMT å adaptMLLMï¼éå©åéæºæç¨ç¨å¼ç°¡åäºç¥ç¶æ©å¨ç¿»è­¯æ¨¡åçéç¼ãå¾®èª¿åé¨ç½²ãéäºå·¥å·å¤§å¹ç°¡åäºè¨­å®åè©ä¼°æµç¨ï¼è® MT æ´å®¹æè®éç¼äººå¡åç¿»è­¯äººå¡ä½¿ç¨ãå¼å¾æ³¨æçæ¯ï¼adaptNMT ä»¥ OpenNMT çæç³»çµ±çºåºç¤ï¼ééå¼·èª¿æ¨¡åéç¼çç°å¢è¶³è·¡ä¾ä¿é²çæåå¥½çèªç¶èªè¨èçç ç©¶ãè LoResMT2021 å±äº«ä»»åä¸­çåºæºç¸æ¯ï¼adaptMLLM å° MLLM çå¾®èª¿è­æäºè±èªâæç¾è­èªåè±èªâé¦¬æå°èªéå©åä½è³æºèªè¨å°çç¿»è­¯æ§è½é²æ­¥ã</paragraph>

##### **Cause and Effect: Can Large Language Models Truly Understand Causality?**
2402.18139v3 by Swagata Ashwani, Kshiteesh Hegde, Nishith Reddy Mannuru, Mayank Jindal, Dushyant Singh Sengar, Krishna Chaitanya Rao Kathala, Dishant Banga, Vinija Jain, Aman Chadha

With the rise of Large Language Models(LLMs), it has become crucial to
understand their capabilities and limitations in deciphering and explaining the
complex web of causal relationships that language entails. Current methods use
either explicit or implicit causal reasoning, yet there is a strong need for a
unified approach combining both to tackle a wide array of causal relationships
more effectively. This research proposes a novel architecture called Context
Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to
enhance causal reasoning and explainability. The proposed framework
incorporates an explicit causal detection module with ConceptNet and
counterfactual statements, as well as implicit causal detection through LLMs.
Our framework goes one step further with a layer of counterfactual explanations
to accentuate LLMs understanding of causality. The knowledge from ConceptNet
enhances the performance of multiple causal reasoning tasks such as causal
discovery, causal identification and counterfactual reasoning. The
counterfactual sentences add explicit knowledge of the not caused by scenarios.
By combining these powerful modules, our model aims to provide a deeper
understanding of causal relationships, enabling enhanced interpretability.
Evaluation of benchmark datasets shows improved performance across all metrics,
such as accuracy, precision, recall, and F1 scores. We also introduce
CausalNet, a new dataset accompanied by our code, to facilitate further
research in this domain.

æè¦ï¼é¨èå¤§åèªè¨æ¨¡å (LLM) çèèµ·ï¼äºè§£å®åå¨è§£ç¢¼åè§£éèªè¨æèå«çè¤éå æéä¿ç¶²è·¯ä¸­çè½ååéå¶è®å¾è³ééè¦ãç®åçæè¡ä½¿ç¨æç¢ºæé±å«çå ææ¨çï¼ä½å¼·çéè¦ä¸ç¨®çµ±ä¸çæ¹æ³ï¼çµåå©èä»¥æ´ææå°èçå»£æ³çå æéä¿ãæ¬ç ç©¶æåºäºä¸ç¨®ç¨±çºæå¢æç¥æ¨çå¢å¼·èåäºå¯¦åæ (CARE CA) æ¡æ¶çæ°æ¶æ§ï¼ä»¥å¢å¼·å ææ¨çåå¯è§£éæ§ãæåºçæ¡æ¶çµåäºä½¿ç¨ ConceptNet ååäºå¯¦é³è¿°çæç¢ºå ææª¢æ¸¬æ¨¡çµï¼ä»¥åéé LLM é²è¡çé±å«å ææª¢æ¸¬ãæåçæ¡æ¶æ´é²ä¸æ­¥ï¼å å¥ä¸å±¤åäºå¯¦è§£éï¼ä»¥å¼·èª¿ LLM å°å æéä¿ççè§£ãä¾èª ConceptNet çç¥è­å¢å¼·äºå¤é å ææ¨çä»»åçå·è¡ï¼ä¾å¦å æç¼ç¾ãå æè­å¥ååäºå¯¦æ¨çãåäºå¯¦å¥å å¥äºæªç±æå¢é æçæç¢ºç¥è­ãééçµåéäºå¼·å¤§çæ¨¡çµï¼æåçæ¨¡åæ¨å¨æä¾å°å æéä¿æ´æ·±å¥ççè§£ï¼å¯¦ç¾å¢å¼·çå¯è§£éæ§ãåºæºè³æéçè©ä¼°é¡¯ç¤ºå¨ææææ¨ï¼ä¾å¦æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä¸é½æææåãæåéå¼å¥äº CausalNetï¼ä¸åæ°çè³æéï¼ä¸¦éä¸äºæåçç¨å¼ç¢¼ï¼ä»¥ä¿é²å¨éåé åçé²ä¸æ­¥ç ç©¶ã

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

æè¦ï¼ç³å°¿çï¼DMï¼ä½¿æ£èå®¹æåºç¾è¡ç®¡ä½µç¼çã
è¦ç¶²èå½±ååè¡ç®¡åæ èº«é«çå¾®è¡ç®¡åå·¨è¡ç®¡å¥åº·çæ³ãå®åå¯ç¨æ¼è¨ºæ·ç³å°¿çä½µç¼çï¼åæ¬ç³å°¿çè¦ç¶²èçè®ï¼DRï¼ãç¥ç¶çè®ãèçååèç²¥æ¨£ç¡¬åæ§å¿è¡ç®¡ç¾çï¼ä»¥åé æ¸¬å¿è¡ç®¡äºä»¶çé¢¨éªãçºä½¿ç¨æ¸ä½åè¦ç¶²èå½±åé²è¡é«éé DR æª¢æ¸¬èéç¼çäººå·¥æºæ§ï¼AIï¼åç¨ç³»çµ±å·²å¨è¨åºæ¡ç¨ãé¤äº DR ç¯©æª¢å¤ï¼AI æ´åä¹å·æå·¨å¤§çæ½åä¾æå°èç³å°¿çæ£èæ´é«ç§è­·ç¸éçææ°ãå¨éé å·¥ä½ä¸­ï¼æåæ¨å¨å¨é¢åé¡§åºæ¼è¦ç¶²èå½±åç AI æç¨ç¸éç ç©¶çæç»ï¼éäºç ç©¶èç³å°¿ççè¨ºæ·ãé å¾åç®¡çæéãæåå°æè¿°æ´é« AI è¼å©ç³å°¿çç§è­·çç¼ç¾ï¼åæ¬ä½ä¸éæ¼ DR ç¯©æª¢ï¼ä¸¦è¨è«å¯¦æ½æ­¤é¡ç³»çµ±çéç¤ï¼åæ¬èå«çãè³æé±ç§ãå¬å¹³å­ååå¯è§£éæ§æéçåé¡ãééè©ä¼°æ£èçå¥åº·çæ³ï¼åæèéç³å°¿çä½µç¼çä»¥åæªä¾å¿è¡ç®¡ä½µç¼ççé¢¨éªé å¾ï¼AI è¼å©è¦ç¶²èå½±ååæææ½åæçºç³å°¿çæ£èç¾ä»£ååäººåé«ççä¸­å¿å·¥å·ã

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

æè¦ï¼éé ç ç©¶å¾å¤åå©å®³éä¿äººçè§åº¦æ¢è¨ä¸åçäººå·¥æºæ§ (AI) æç¨å¨æè²ä¸çå¯æ¥åæ§ï¼åæ¬å­¸çãèå¸«åå®¶é·ãæ¿èª AI å¨æè²ä¸çè½åæ½åï¼å®è§£æ±ºäºèè³æé±ç§ãAI ä»£çãéæåº¦ãå¯è§£éæ§å AI çéå¾·é¨ç½²ç¸éççæ®ãééå°ææ²æ¹æ³ï¼åèèè¢«åç¾äºåç¨®æå¢ï¼å¶ä¸­ AI çä»£çãéæåº¦ãå¯è§£éæ§åé±ç§åå°æç¸±ãå¨æ¯åæå¢å¾ï¼åèèå®æäºä¸é èª¿æ¥ï¼è©²èª¿æ¥ææäºä»åå° AI çæ´é«æç¨ãåäººæç¨ãæ­£ç¾©ãä¿¡å¿ãé¢¨éªåå¦æå¯ç¨ï¼ä½¿ç¨æ¯åæå¢ç AI çæåççæ³ãè³æèéåå«ä¾èªåä½æ©æ§åç¤¾ç¾¤åªé«æ´»åç 1198 ä½å¤å©å®³éä¿äººåèèçæçµæ¨£æ¬ï¼ä¸¦å°æ³¨æ¼å°åå AI ä½¿ç¨æ¡ä¾çåå¥åæãå°è³æçèª¿è§£åæè¡¨æï¼å° AI çæ¥ååº¦åä¿¡ä»»å¨å©å®³éä¿äººåé«ä¹éæé¡¯èå·®ç°ãæåç¼ç¾ï¼AI çä»£çãéæåº¦åå¯è§£éæ§é«ä½ç¨åº¦ä¹éçééµèª¿è§£èï¼ä»¥åä½¿ç¨ä¸åæè² AI çæåï¼åæ¬æç¥å°çæ´é«æç¨ãæ­£ç¾©åä¿¡å¿ãéé ç ç©¶å¼·èª¿ï¼æ¥å AI å¨æè²ä¸çæç¨æ¯ä¸åå¾®å¦ä¸å¤é¢åçåé¡ï¼é¤äºä¸åçå©å®³éä¿äººççæ³å¤ï¼ééè¦ä»ç´°èæ®å·é«ç AI æç¨åå¶ç¹å¾µã

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

æè¦ï¼<paragraph>åºæ¼å¯ç©¿æ´å¼å®å°ç¨å¿é»å (ECG) è£ç½®çé ç«¯çæ£ç£æ¸¬å¨æ©æåµæ¸¬å¿èç¾çæ¹é¢å·æé¡¯èçæ½åï¼ç¹å¥æ¯èç¨æ¼èªååå¿èç¾çåµæ¸¬çäººå·¥æºæ§ (AI) æ¹æ³çµåä½¿ç¨æãååå·²æç ç©¶æç¨åºæ¼æ·±åº¦å­¸ç¿ç AI æ¹æ³é²è¡å¿èç¾çåµæ¸¬ãç¶èï¼éäºæ¨¡åå°æªè¢«å»£æ³æ¥åçºè¨åºè¨ºæ·çå¯é è¼å©å·¥å·ï¼é¨ååå å¨æ¼åç¹è¨±å¤ AI æ¼ç®æ³çç¶åé»ç®±æç¥ãç¹å¥æ¯ï¼æå¿è¦æ¾åºæå©æ¼ååºæºç¢ºè¨ºæ·ç ECG è¨èééµç¹å¾µï¼å¾èå¢å¼·æ¨¡åçå¯è§£éæ§ãå¨æ¬ç ç©¶ä¸­ï¼æåéç¼äºä¸ç¨®è¦è¦ºè½æå¨æ¹æ³ï¼ä»¥æ ¹æå®å°ç¨ ECG è³ææ¾åºå¿æ¿é¡«åãæ®å·®ç¶²è·¯ (ResNet) æ¹æ³ä¹å·²éç¼åºä¾ï¼ä»¥ä¾¿èè¦è¦ºè½æå¨æ¹æ³é²è¡æ¯è¼ãéäºæ¨¡åæç¨æ¼ Chapman-Shaoxing è³æéï¼ä»¥åé¡å¿æ¿é¡«åï¼ä»¥åå¦ä¸ç¨®å¸¸è¦çå¿å¾ä¸æ´ï¼ç«æ§å¿åéç·©ï¼åæ­£å¸¸ç«æ§å¿å¾çå¿è·³ãéäºæ¨¡åè½å¤ æ¾åºæ±ºå®æçµåé¡çå¿è·³ééµååï¼ä¸¦å¼·èª¿ P æ³¢å T æ³¢ï¼ä»¥åå¿è·³æçºæéåè¨èæ¯å¹å¨ååæ­£å¸¸ç«æ§å¿å¾èå¿æ¿é¡«ååç«æ§å¿åéç·©æ¹é¢çéè¦æ§ã</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

æè¦ï¼æ¬æä»ç´¹äºä¸ç¨®ä½¿ç¨åé²å¤§åèªè¨æ¨¡å (LLM) é²è¡æé¬±çåµæ¸¬åæ²»ççæ°æ¨¡å¼ï¼çæå¼é è¨ç·´Transformer 4 (GPT-4)ãLlama 2 èå¤©æ©å¨äººå Geminiãéäº LLM ç¶éå¾®èª¿ï¼å·åå°æ¥­æç¤ºï¼å¯è¨ºæ·ãè§£éä¸¦å»ºè­°æé¬±ççæ²»çä»å¥æ¹æ³ãä¸ç¨®ç¨ç¹çå°æ¬¡æç¤ºæ¹æ³å¢å¼·äºæ¨¡åæ ¹æ DSM-5 æ¨æºåæåè§£éæé¬±çççè½åãå¨äºåéæ®µï¼éäºæ¨¡åæåèåçå¿å°è©±ç®¡çï¼å¾ PsychDB åèªç¥è¡çºçæ³ (CBT) æåç­è³æºä¸­æ±²åï¼ä¿é²èç¶æ­·éåº¦æé¬±ççäººåçæ¯ææ§äºåãæ­¤å¤ï¼éé ç ç©¶éä»ç´¹äº Illuminate è³æåº«ï¼å¶ä¸­åå«åç¨® CBT æ¨¡çµï¼æå©æ¼åæ§åæ²»çå»ºè­°ãéé ç ç©¶ä½¿ç¨ F1 åæ¸ãæºç¢ºçãå¬åçãé¤å¼¦ç¸ä¼¼åº¦åé¢åå¬åçç Gisting è©ä¼°æ¿èº« (ROUGE) ç­ææ¨ï¼å¨ä¸åçæ¸¬è©¦éä¸­è©ä¼° LLM çè¡¨ç¾ï¼è­æäºå®åçæææ§ãéç¨®ç¶åæ¹æ³çµåäºå°ç«¯ç AI èæ¢å®çå¿çæ¹æ³ï¼çºå¿çä¿å¥æä¾äºæ°çå¯è½æ§ï¼ä¸¦å±ç¤ºäº LLM å¨é©æ°æé¬±çè¨ºæ·åæ²»çç­ç¥æ¹é¢çæ½åã

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v5 by TimothÃ©e Schmude, Laura Koesten, Torsten MÃ¶ller, Sebastian Tschiatschek

Every AI system that makes decisions about people has a group of stakeholders
that are personally affected by these decisions. However, explanations of AI
systems rarely address the information needs of this stakeholder group, who
often are AI novices. This creates a gap between conveyed information and
information that matters to those who are impacted by the system's decisions,
such as domain experts and decision subjects. To address this, we present the
"XAI Novice Question Bank," an extension of the XAI Question Bank containing a
catalog of information needs from AI novices in two use cases: employment
prediction and health monitoring. The catalog covers the categories of data,
system context, system usage, and system specifications. We gathered
information needs through task-based interviews where participants asked
questions about two AI systems to decide on their adoption and received verbal
explanations in response. Our analysis showed that participants' confidence
increased after receiving explanations but that their understanding faced
challenges. These included difficulties in locating information and in
assessing their own understanding, as well as attempts to outsource
understanding. Additionally, participants' prior perceptions of the systems'
risks and benefits influenced their information needs. Participants who
perceived high risks sought explanations about the intentions behind a system's
deployment, while those who perceived low risks rather asked about the system's
operation. Our work aims to support the inclusion of AI novices in
explainability efforts by highlighting their information needs, aims, and
challenges. We summarize our findings as five key implications that can inform
the design of future explanations for lay stakeholder audiences.

æè¦ï¼<paragraph>æ¯åå°äººé²è¡æ±ºç­ç AI ç³»çµ±é½æä¸ç¾¤åäººåå°éäºæ±ºç­å½±é¿çå©çéä¿äººãç¶èï¼AI ç³»çµ±çèªªæå¾å°éå°éç¾¤å©çéä¿äººçè³è¨éæ±ï¼ä»åéå¸¸æ¯ AI æ°æãéå¨å³éçè³è¨åå°åç³»çµ±æ±ºç­å½±é¿çäººä¾èªªéè¦çè³è¨ä¹éï¼é æäºä¸éé´»æºï¼ä¾å¦é åå°å®¶åæ±ºç­ä¸»é«ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºãXAI æ°æåé¡åº«ãï¼éæ¯ XAI åé¡åº«çå»¶ä¼¸ï¼åå«ä¾èªå©åä½¿ç¨æ¡ä¾ä¸­ AI æ°æçè³è¨éæ±ç®éï¼å°±æ¥­é æ¸¬åå¥åº·ç£æ§ãç®éæ¶µèäºè³æãç³»çµ±èæ¯ãç³»çµ±ä½¿ç¨åç³»çµ±è¦æ ¼ç­é¡å¥ãæåééä»»ååè¨ªè«æ¶éè³è¨éæ±ï¼åèèå¨å¶ä¸­è©¢åäºå©å AI ç³»çµ±çåé¡ï¼ä»¥æ±ºå®æ¡ç¨èå¦ï¼ä¸¦æ¶å°å£é ­èªªæä½çºåæãæåçåæé¡¯ç¤ºï¼åèèå¨æ¶å°èªªæå¾ï¼ä¿¡å¿æææåï¼ä½ä»åççè§£é¢è¨ææ°ãéäºææ°åæ¬é£ä»¥æ¾å°è³è¨åè©ä¼°èªå·±ççè§£ï¼ä»¥åè©¦åå¤åçè§£ãæ­¤å¤ï¼åèèå°ç³»çµ±é¢¨éªåå¥½èçååèªç¥å½±é¿äºä»åçè³è¨éæ±ãèªçºé¢¨éªé«çäººå°æ±æéç³»çµ±é¨ç½²èå¾æåçèªªæï¼èèªçºé¢¨éªä½çäººåè©¢åç³»çµ±çéä½ãæåçç ç©¶æ¨å¨ééå¼·èª¿ä»åçè³è¨éæ±ãç®æ¨åææ°ï¼ä¾æ¯æå° AI æ°æç´å¥å¯è§£éæ§å·¥ä½ãæåå°æåçç ç©¶çµæç¸½çµçºäºåééµå½±é¿ï¼éäºå½±é¿å¯ä»¥çºæªä¾éå°éå°æ¥­å©çç¸éèåç¾çèªªæè¨­è¨æä¾åèã</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet GÃ¼rkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

æè¦ï¼äººå·¥æºæ§ (AI) çå¿«éæ¼é²ï¼å°¤å¶æ¯å¨å¤§åèªè¨æ¨¡å (LLM) åçæå¼ AI çé åï¼çºååé åçæç¨éåäºæ°éå¾ï¼ä½å¶å¨åæ¥­æè²ä¸­çè§è²ä»æªè¢«ååæ¢è¨ãæ¬ç ç©¶é¦æ¬¡å¼å¥äºåºæºï¼ç¨ä»¥è©ä¼°ä¸åä¸»è¦ LLM çæè½ï¼åæ¬ OpenAI çæ¨¡å (GPT-3.5 TurboãGPT-4 å GPT-4 Turbo)ãGoogle çæ¨¡å (PaLM 2ãGemini 1.0 Pro) å Anthropic çæ¨¡å (Claude 2 å Claude 2.1)ï¼éäºæ¨¡åå°ç¨æ¼ç ç©¶çåæ¥­èª²ç¨å¥å­¸ç¨åºä¸­çééµèè©¦ GMATãæåçåæé¡¯ç¤ºï¼å¤§å¤æ¸ LLM çè¡¨ç¾é½åªæ¼äººé¡èçï¼å¶ä¸­ GPT-4 Turbo ä¸ååªæ¼å¶ä»æ¨¡åï¼æ´è¶è¶äºé å°åå­¸é¢çç ç©¶çå¹³ååæ¸ãééæ¡ä¾ç ç©¶ï¼æ¬ç ç©¶æ¢è¨äº GPT-4 Turbo å¨è§£éç­æ¡ãè©ä¼°åæãè¾¨è­é¯èª¤ãèª¿æ´èªªæåç¢çæ¿ä»£æå¢æ¹é¢çè½åãèåä¸ä»£çæ¬ç¸æ¯ï¼ææ°ç LLM çæ¬ GPT-4 TurboãClaude 2.1 å Gemini 1.0 Pro å¨æ¨çä»»åæ¹é¢æé¡¯èçé²æ­¥ï¼å¸é¡¯äºå¶å¨è§£æ±ºè¤éåé¡æ¹é¢çæ½åãåç®¡ AI å¨æè²ãè©éåè¼å°æ¹é¢çæ¿è«¾å¾æç¢ºï¼ä½ä»æææ°å­å¨ãæåçç ç©¶ä¸åé¡æäº LLM çå­¸è¡æ½åï¼ä¹å¼·èª¿äºå¨æè²ä¸­å¯©æéç¼åæç¨ AI çå¿è¦æ§ãé¨è AI æè¡çé²æ­¥ï¼å»ºç« AI äºåçæ¶æ§ååå®ãé©è­ AI çæçå§å®¹çæºç¢ºæ§ãç¢ºä¿å¨çåå°å¤åå­¸ç¿èçå­åæ¬ï¼ä»¥ååµé ä¸å AI æ¯æäººé¡å°æ¥­ç¥è­çæè²ç°å¢è³ééè¦ãæ¬ç ç©¶çºé²ä¸æ­¥æ¢ç´¢è² è²¬ä»»å°ä½¿ç¨ AI ä¾è±å¯æè²é«é©ä¸¦æ¹åèè©¦æºååè©éæ¹æ³å¥ å®äºåºç¤ã

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

æè¦ï¼é æ¸¬å è­·çæ¿ (ICU) çæ£çé¢å§æ­»äº¡çæ¯æçµè¨åºçµæçééµãAI å·²å±ç¾åºåªç°çæºç¢ºåº¦ï¼ä½å»ç¼ºä¹å¯è§£éæ§ãçºäºè§£æ±ºéååé¡ï¼æ¬ææåºäºä¸åå¯è§£éçå¤æ¨¡å¼æ­»äº¡çé æ¸¬å¨ (X-MMP)ï¼æ¡ç¨ææä¸å¯è§£éç AI æ¹å¼ï¼èç±å¤æ¨¡å¼ ICU è³æä¾é æ¸¬é¢å§æ­»äº¡çãæåå¨æ¶æ§ä¸­æ¡ç¨å¤æ¨¡å¼å­¸ç¿ï¼å¯ä»¥æ¥æ¶ä¾èªè¨åºè³æçç°è³ªè¼¸å¥ä¸¦ååºæ±ºç­ãæ­¤å¤ï¼æåå¼å¥äºä¸åå¯è§£éçæ¹æ³ï¼ä¹å°±æ¯åå±¤å³æ­è³ Transformerï¼ä½çº LRP æ¹æ³é©ç¶å°å»¶ä¼¸è³ Transformerï¼å°å¤æ¨¡å¼è¼¸å¥ç¢çè§£éï¼ä¸¦æ­é²æ­¸å æ¼é æ¸¬çé¡¯èç¹å¾µãæ­¤å¤ï¼æ¯åæ¨¡å¼å°è¨åºçµæçè²¢ç»å¯ä»¥è¦è¦ºåï¼åå©è¨åºé«å¸«äºè§£æ±ºç­èå¾ççç±ãæåæ ¹æ MIMIC-III å MIMIC-III æ³¢å½¢è³æåº«æ¯å°å­éå»ºæ§äºä¸åå¤æ¨¡å¼è³æéãå¨åºæºè³æéä¸çå¨é¢å¯¦é©è­æï¼æåæåºçæ¶æ§å¯ä»¥éæåççè©®éï¼ä¸¦å·åç«¶ç­åçé æ¸¬æºç¢ºåº¦ãç¹å¥æ¯ï¼æåçæ¶æ§å¯ä»¥è¼é¬å°è½ç§»å°å¶ä»è¨åºä»»åï¼éæå©æ¼å¨é«çä¿å¥ç ç©¶ä¸­ç¼ç¾ééµå ç´ ã

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian GeiÃler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, BjÃ¶rn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias KÃ¼ster, AndrÃ© Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

æè¦ï¼å¨éå»çåå¹´ä¸­ï¼ççå­¸ä¸­çäººå·¥æºæ§ (AI) æ¹æ³å·²å¤§å¹é²æ­¥ãç¶èï¼ç±æ¼è¨±å¤ææ°ï¼åæ¬å°ç ç©¶çµæè½åçºè¨åºè¨ºæ·ç¢åå¨æè¡åæ³è¦æ¹é¢çéç¤ï¼ä»¥åç¼ºä¹æ¨æºåä»é¢ï¼å°è´æ´åå°å¸¸è¦è¨åºå¯¦åä¸­é²å±ç·©æ¢ãéæ¾ä¸èä¾æåç¡éç EMPAIA è¨ç«æå°äºéäºææ°ãå¨æ­¤ï¼æåæä¾ EMPAIA çæå°±åç¶é©æè¨çæ¦è¿°ãEMPAIA æ´åäºççå­¸ AI çæç³»çµ±çååå©å®³éä¿äººï¼å³ççå­¸å®¶ãé»è¦ç§å­¸å®¶åç¢æ¥­ãå¨å¯ååä½ä¸ï¼æåå¶å®äºæè¡äºéæ§æ¨æºãAI æ¸¬è©¦åç¢åéç¼å»ºè­°ï¼ä»¥åå¯è§£éæ§æ¹æ³ãæåå¯¦ä½äºæ¨¡çµåä¸éæ¾åå§ç¢¼ç EMPAIA å¹³èºï¼ä¸¦æåæ´åäºä¾èª 8 åä¸åä¾æåç 14 ååºæ¼ AI çå½±ååææç¨ç¨å¼ï¼å±ç¤ºäºä¸åçæç¨ç¨å¼å¦ä½ä½¿ç¨å®ä¸çæ¨æºåä»é¢ãæååªåèæ®éæ±ï¼ä¸¦è©ä¼°äº AI å¨æ­æ´²åäºæ´²ç 14 åä¸åççå¯¦é©å®¤ä¸­çå¯¦éè¨åºæç¨ãé¤äºæè¡éç¼å¤ï¼æåéçºææå©å®³éä¿äººå»ºç«äºä¸åè«å£ï¼ä»¥åäº«æ¸ä½ççå­¸å AI çè³è¨åç¶é©ãåæ¥­ãè¨åºåå­¸è¡å©å®³éä¿äººç¾å¨å¯ä»¥æ¡ç¨ EMPAIA çå¸¸è¦éæ¾åå§ç¢¼ä»é¢ï¼éçºå¤§è¦æ¨¡æ¨æºååç°¡åæµç¨æä¾äºç¨ç¹çæ©æãéè¦é²ä¸æ­¥çåªåæè½ææä¸å»£æ³å°å»ºç«ä¾è¡å¯¦é©å®¤ä½¿ç¨ä¸­ç AI è¼å©ãçºæ­¤ï¼å·²æç«éçå©åæ EMPAIA Internationalï¼ä»¥ä½çºæ°¸çºåºç¤æ¶æ§ï¼ç¹¼çºé²è¡æ¨æºåï¼ä¸¦æ¯æ´å»£æ³å¯¦ä½åå¡å° AI è¼å©æ¸ä½ççå­¸çæªä¾ã

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

æè¦ï¼åäºå¯¦è§£é (CE) æè¡å·²å¼èµ·éæ³¨ï¼ä½çºä¸ç¨®çºè AI ç³»çµ±äºåçä½¿ç¨èæä¾è¦è§£çæ¹æ³ãéç¶å¨é«å­¸å½±ååèªåé§é§æ±½è»ç­é åå»£æ³ç ç©¶ï¼åå½¢åäºå¯¦è§£é (GCE) æ¹æ³ç¸å°è¼å°è¢«æ¢ç´¢ãGCE æç¢çä¸åé¡ä¼¼æ¼åå§åå½¢çæ°åå½¢ï¼ä¸¦æ ¹æåºç¤é æ¸¬æ¨¡åç¢çä¸åççµæãå¨éäº GCE æè¡ä¸­ï¼åç®¡å¨å¶ä»é åï¼ä¾å¦èè¡é¢¨æ ¼åèªç¶èªè¨å»ºæ¨¡ï¼ä¸­å±ç¾åºä»¤äººå°è±¡æ·±å»çæå°±ï¼ä½æ¤åºæ¼çææ©å¶çæè¡ç²å¾çéæ³¨ç¸å°æéãå°çæå¼è§£éå¨çåå¥½æºæ¼å®åå¨æ¨çæéç¢çåäºå¯¦å¯¦ä¾çè½åï¼å©ç¨è¼¸å¥åå½¢çèªä¸»ç²åæ¾åãåºæ¼ä¸è¿°çç±ï¼æåçç ç©¶å¼å¥äº RSGG-CEï¼ä¸ç¨®ç¨æ¼åäºå¯¦è§£éçæ°åç©©å¥é¨æ©åå½¢çæå¨ï¼è½å¤ å¾å­¸ç¿å°çæ½å¨ç©ºéä¸­ç¢çåäºå¯¦ç¯ä¾ï¼èæ®é¨åæåºççæåºåãæ­¤å¤ï¼æåé²è¡å®éåå®æ§åæï¼ä»¥æ¯è¼ RSGG-CE çæè½è SoA çæå¼è§£éå¨ï¼å¼·èª¿å¶å¢å¼·äºç¢çåçè§£éåé¸çè½åã

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

æè¦ï¼å¯è§£é AI çåæ©ä¹ä¸æ¯è®äººåå¨ä½¿ç¨åé¨ç½² AI æ¨¡åæååºæ´å¥½ãæ´ææºçæ±ºç­ãä½éè¦ä»ç´°è©ä¼°ä»¥è©ä¼°æ¯å¦å·²éå°æ­¤é æãç®åçè©ä¼°ä¸»è¦éä¸­å¨è§£éçæ¼ç®æ³ç¹æ§ï¼èæ¶åäººé¡åè©¦èçè©ä¼°éå¸¸æ¡ç¨ä¸»è§åé¡ä¾æ¸¬è©¦äººé¡å°è§£éæç¨æ§ççæ³ï¼èæ²æåºæ¼å®¢è§ææ¨åæ¸¬éãå¨éé å·¥ä½ä¸­ï¼æåè©ä¼°è§£éæ¯å¦å¯ä»¥å¨æ©å¨å­¸ç¿æ¨¡åéç¼çå¯¦éå ´æ¯ä¸­æ¹åäººé¡æ±ºç­å¶å®ãæåé²è¡äºä¸é æ¶åå½±åè³æçæ··åæ¹æ³ä½¿ç¨èç ç©¶ï¼ä»¥è©ä¼° SmoothGradãGradCAM åé è¨è§£éå¨å©åä»»åä¸­ç¢ççé¡¯èæ§åï¼æ¨¡åé¸æååäºå¯¦æ¨¡æ¬ãä»¤äººé©è¨çæ¯ï¼æåæ²æç¼ç¾ä»»ä½é¡¯èæ§åï¼å³ä½¿æ¯è¨­è¨çºææ¼çè§£ä¸é«åº¦æç¤ºç­æ¡çåæé è¨è§£éï¼è½è®ä½¿ç¨èå¨éäºä»»åä¸é¡¯èæ¹åçè­æãåç®¡å¦æ­¤ï¼è§£éç¢ºå¯¦æå©æ¼ä½¿ç¨èæ´æºç¢ºå°æè¿°æ¨¡åãéäºç¼ç¾æç¤ºæåè¦å°åºæ¼é¡¯èæ§çè§£éä¸­å¯è½å­å¨èª¤è§£çæç¨æ§ä¿æè¬¹æã

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

æè¦ï¼å¯è§£éæ§åå®å¨æ§å»ºç«ä¿¡ä»»ãéäºéè¦ä¸åæ¨¡åä¾å±ç¤ºä¸è´æ§åå¯é æ§ãçºäºå¯¦ç¾éäºï¼æå¿è¦ä½¿ç¨ååææ¸æåç¥è­ï¼ä¸¦ä½¿ç¨è AI æç¨ç¸éççµ±è¨åç¬¦è AI æ¹æ³ - å®ç¨ä½¿ç¨ä»»ä½ä¸ç¨®æ¹æ³é½ä¸æå¥æãå æ­¤ï¼æåä¸»å¼µä¸¦è©¦åè­æ NeuroSymbolic AI æ¹æ³æ´é©åæ¼ä½¿ AI æçºåä¿¡ä»»ç AI ç³»çµ±ãæåæåºäº CREST æ¡æ¶ï¼å±ç¤ºäºä¸è´æ§ãå¯é æ§ãä½¿ç¨èå±¤ç´çå¯è§£éæ§åå®å¨æ§æ¯å¦ä½å»ºç«å¨ NeuroSymbolic æ¹æ³ä¸çï¼è©²æ¹æ³ä½¿ç¨æ¸æåç¥è­ä¾æ¯æééµæç¨ï¼ä¾å¦å¥åº·åç¦ç¥ï¼çè¦æ±ãæ¬æéé»éæ³¨å¤§åèªè¨æ¨¡å (LLM)ï¼å çºå®æ¯ CREST æ¡æ¶ä¸­é¸æç AI ç³»çµ±ãLLM å å¶å¨èçå»£æ³çèªç¶èªè¨èç (NLP) å ´æ¯æ¹é¢çå¤åè½æ§èååç ç©¶äººå¡çéæ³¨ãä¾å¦ï¼ChatGPT å Google ç MedPaLM å·²æçºæä¾ä¸è¬åå¥åº·ç¸éæ¥è©¢ä¿¡æ¯çæ¥µæå¸æçå¹³å°ãåç®¡å¦æ­¤ï¼éäºæ¨¡åä»ç¶æ¯é»çå­ï¼åç®¡ç´å¥äºäººé¡åé¥åæä»¤å¼å°çèª¿æ´ãä¾å¦ï¼åç®¡å¶å®äºå®å¨é²è­·æªæ½ï¼ChatGPT ä»å¯è½ç¢çä¸å®å¨çåæãCREST æåºäºä¸ç¨®åççæ¹æ³ï¼å¨ NeuroSymbolic æ¡æ¶ä¸­å©ç¨ç¨åºååºæ¼åè¡¨çç¥è­ï¼ä»¥é¡æè LLM ç¸éçææ°ã

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano, Stephen Glass, Ravi P. Ramachandran, Sharad Patel, Aaron J. Masino, Ghulam Rasool

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

æè¦ï¼æ¬ç ç©¶è°æ¥äºå¨ COVID-19 ç«ææé´åä»¥åé¢æµæ­»äº¡çæ¶ï¼å·²é¨ç½²äººå·¥æºè½ (AI) æ¨¡åçæ§è½ãå¯è§£éæ§åç¨³å¥æ§ãä½ä¸ºåç±»ç ç©¶ä¸­çé¦ä¾ï¼æä»¬åç°è´å¶æ¯ç¥ç»ç½ç» (BNN) åæºè½è®­ç»ææ¯è®©æä»¬çæ¨¡åå¨æ°æ®åçéå¤§ååæ¶ä»è½ä¿ææ§è½ãæä»¬çç»æå¼ºè°äºå¼åç¨³å¥ç AI æ¨¡åçéè¦æ§ï¼å³ä½¿å¨å·ææææ§çæ¡ä»¶ä¸ï¼è¿äºæ¨¡åä¹è½å¹éæè¶è¶ä¸´åºå»ççé¢æµãæä»¬å¯¹æ¨¡åå¯è§£éæ§çæ¢ç´¢è¡¨æï¼éæºæ¨¡åä¼äº§çæ´å¤æ ·åä¸ä¸ªæ§åçè§£éï¼ä»èçªåºäºå¨ç°å®ä¸ççä¸´åºç¯å¢ä¸­æä¾è¯¦ç»ä¸ä¸ªæ§åè§è§£ç AI æ¨¡åçå¿è¦æ§ãæ­¤å¤ï¼æä»¬å¼ºè°äºéå AI æ¨¡åä¸­ä¸ç¡®å®æ§çéè¦æ§ï¼è¿ä½¿ä¸´åºå»çè½å¤æ ¹æ®å¯é çé¢æµååºæ´ææºçå³ç­ãæä»¬çç ç©¶æå¡å¨å»çä¿å¥ç AI ç ç©¶ä¸­ä¼åèèå®æ½ç§å­¦ï¼å¹¶ç¡®ä¿ AI è§£å³æ¹æ¡å¨ç°å®ä¸ççä¸´åºç¯å¢ä¸­å®ç¨ãæçä¸å¯æç»­ãéè¿è§£å³å»çä¿å¥ç¯å¢ä¸­çç¬ç¹ææåå¤ææ§ï¼ç ç©¶äººåå¯ä»¥å¼ååºæææ¹åä¸´åºå®è·µåæ£èé¢åç AI æ¨¡åã

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel, Aaron Quyn, David Jayne, Samuel D. Relton

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

æè¦ï¼èºçå è±åççæ­»äº¡äººæ¸ç 21%ï¼äºå¹´å­æ´»çå¾å¤§ç¨åº¦åæ±ºæ¼ççè¢«ç¼ç¾çéæ®µãæè¿çç ç©¶å·²è­æäººå·¥æºè½æ¹æ³å·æå¾ä¾è¡ææä¸­æºç¢ºåæ©è¨ºæ·èºççè½åãç¶èï¼æ­¤è­æå°æªè½åçºè¨åºå¯¦åï¼å¶ä¸­ä¸åéç¤æ¯ç¼ºä¹å¯è§£éçæ¨¡åãæ¬ç ç©¶æ¢è¨äºæç¨è®åèªåç·¨ç¢¼å¨ (VAE)ï¼ä¸ç¨®çæå¼äººå·¥æºè½æ¨¡åï¼æ¼èºççç¶ãå°æåºçæ¨¡åè¨ç·´æ¼å¾ LIDC-IDRI å¬å±æ¸æéä¸­æåç 3D é»è¦æ·å±¤ææçç¶ãééèé¡æ¢ç´¢äº VAE çæç 2D åççæ½å¨åéè¡¨ç¤ºï¼ä»¥è­æå¶åè³ªï¼ä¸¦ç¨æ¼èºçè¨ºæ·ç MLP åé¡å¨æ¨¡åï¼æä½³æ¨¡åéå°äº AUC 0.98 å 93.1% æºç¢ºåº¦çæåé²ææ¨ãèé¡åæé¡¯ç¤ºï¼VAE æ½å¨ç©ºéæ ¹æææç¾©çç¹å¾µçµæï¼åæ¬è«ç¤å¤§å°ãå½¢çãæ£èåæ¡æ§é¡å¥ï¼å°æ¡æ§åè¯æ§çç¶çæ¸æéåéãæåéåæ¬æ¨æºé«æ¯ VAE (GVAE) åæ´æ°ççå©åé· VAE (DirVAE) çæ¯è¼åæï¼å¾èç¨çå©åé·åä½åä»£åé©ï¼ä»¥ä¿é²å·æè§£éç¹å¾µè¡¨ç¤ºçæ´å·å¯è§£éæ§çæ½å¨ç©ºéãæå¾ï¼æåå±ç¤ºäºèè¨åºææç¾©çç¹å¾µè®åç¸æçæ½å¨ç©ºéæ©«è¶çæ½åã

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

æè¦ï¼ç¾æçåååé¡å¨è¼¸åºè§£éå·¥å·å¯åçºä¾è³´æ¼æ¨¡åå§é¨å­åæ¬éçç½çï¼ä»¥åèæ¨¡åç¡éçé»çãé¨è AI å¨é«çé åçä½¿ç¨å¢å ï¼å¯è§£éæ§å·¥å·çä½¿ç¨ä¹é¨ä¹å¢å ãç¾æé«å­¸å½±åè§£éçå·¥ä½éé»å¨æ¼ç½çå·¥å·ï¼ä¾å¦ gradcamãç¶èï¼åæå°é»çå·¥å·ææé¡¯çåªé»ï¼åæ¬è½å¤ èä»»ä½åé¡å¨ä¸èµ·ä½¿ç¨ï¼ä»¥åå»£æ³çé»çå·¥å·å¯ä¾é¸æãå¨æ¨æºå½±åä¸ï¼é»çå·¥å·èç½çä¸æ¨£ç²¾ç¢ºãå¨æ¬æä¸­ï¼æåæ¯è¼äºå¤ç¨®é»çæ¹æ³å¨è¦ç MRI è³æéä¸è gradcam çæè½ãæåè­æå¤§å¤æ¸é»çå·¥å·ä¸é©åè§£éé«å­¸å½±ååé¡ï¼ä¸¦è©³ç´°åæå¶ç¼ºé»çåå ãæåéè¡¨æä¸ç¨®é»çå·¥å·ï¼åºæ¼å æå¯è§£éæ§ç rexï¼è¡¨ç¾è \gradcam ä¸æ¨£å¥½ã

##### **Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**
2311.12573v3 by Robert Gorwa, Michael Veale

The AI development community is increasingly making use of hosting
intermediaries such as Hugging Face provide easy access to user-uploaded models
and training data. These model marketplaces lower technical deployment barriers
for hundreds of thousands of users, yet can be used in numerous potentially
harmful and illegal ways. In this article, we explain ways in which AI systems,
which can both `contain' content and be open-ended tools, present one of the
trickiest platform governance challenges seen to date. We provide case studies
of several incidents across three illustrative platforms -- Hugging Face,
GitHub and Civitai -- to examine how model marketplaces moderate models.
Building on this analysis, we outline important (and yet nevertheless limited)
practices that industry has been developing to respond to moderation demands:
licensing, access and use restrictions, automated content moderation, and open
policy development. While the policy challenge at hand is a considerable one,
we conclude with some ideas as to how platforms could better mobilize resources
to act as a careful, fair, and proportionate regulatory access point.

æè¦ï¼AI éç¼ç¤¾ç¾¤æ¥çå©ç¨ Hugging Face ç­è¨ç®¡ä¸­ä»æ©æ§æä¾ç¨æ¶ä¸å³çæ¨¡ååè¨ç·´è³æçç°¡æå­åæ¬éãéäºæ¨¡åå¸ééä½äºæ¸åè¬åç¨æ¶çæè¡é¨ç½²éç¤ï¼ä½å¯è½æè¢«ç¨æ¼è¨±å¤æ½å¨æå®³åéæ³çæ¹å¼ãå¨æ¬æä¸­ï¼æåèªªæ AI ç³»çµ±æ¢å¯ä»¥ãåå«ãå§å®¹ï¼åå¯ä»¥ä½çºéæ¾å¼å·¥å·ï¼éæåºäºè¿ä»çºæ­¢ææ£æçå¹³å°æ²»çææ°ä¹ä¸ãæåæä¾ Hugging FaceãGitHub å Civitai ç­ä¸åèªªææ§å¹³å°ä¸æ¸èµ·äºä»¶çæ¡ä¾ç ç©¶ï¼ä»¥æª¢è¦æ¨¡åå¸éå¦ä½å¯©æ ¸æ¨¡åãæ ¹ææ­¤åæï¼æåæ¦è¿°ç¢æ¥­çºåæå¯©æ ¸éæ±èéç¼çéè¦ï¼ä½ä»æéï¼å¯¦åï¼ææ¬ãå­ååä½¿ç¨éå¶ãèªååå§å®¹å¯©æ ¸åéæ¾æ¿ç­å¶å®ãéç¶ç¶åæ¿ç­ææ°ç¸ç¶å¯è§ï¼æåæå¾æåºä¸äºæ§æ³ï¼èªªæå¹³å°å¦ä½è½æ´å¥½å°åå¡è³æºï¼ä½çºè¬¹æãå¬å¹³ä¸é©åº¦çæ³è¦å­åé»ã

##### **Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**
2311.11932v1 by Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker

Background and objectives: By extracting this information, Machine or Deep
Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and
cancer researchers in discovering patterns and relationships from complex data
sets. Many DL-based analyses on ovarian cancer (OC) data have recently been
published. These analyses are highly diverse in various aspects of cancer
(e.g., subdomain(s) and cancer type they address) and data analysis features.
However, a comprehensive understanding of these analyses in terms of these
features and AI assurance (AIA) is currently lacking. This systematic review
aims to fill this gap by examining the existing literature and identifying
important aspects of OC data analysis using DL, explicitly focusing on the key
features and AI assurance perspectives. Methods: The PRISMA framework was used
to conduct comprehensive searches in three journal databases. Only studies
published between 2015 and 2023 in peer-reviewed journals were included in the
analysis. Results: In the review, a total of 96 DL-driven analyses were
examined. The findings reveal several important insights regarding DL-driven
ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on
detection and diagnosis, while no study addressed the prediction and prevention
of OC. - The analyses were predominantly based on samples from a non-diverse
population (75% (72/96 studies)), limited to a geographic location or country.
- Only a small proportion of studies (only 33% (32/96)) performed integrated
analyses, most of which used homogeneous data (clinical or omics). - Notably, a
mere 8.3% (8/96) of the studies validated their models using external and
diverse data sets, highlighting the need for enhanced model validation, and -
The inclusion of AIA in cancer data analysis is in a very early stage; only
2.1% (2/96) explicitly addressed AIA through explainability.

æè¦ï¼<paragraph>èæ¯åç®æ¨ï¼ééæåéäºè³è¨ï¼æ©å¨ææ·±åº¦å­¸ç¿ (ML/DL) åºæ¼èªä¸»æ¸æåæå·¥å·å¯ä»¥åå©è¨åºé«çåççç ç©¶äººå¡å¾è¤éçæ¸æéä¸­ç¼ç¾æ¨¡å¼åéä¿ãæè¿å·²ç¼è¡¨è¨±å¤åºæ¼ DL çåµå·¢ç (OC) æ¸æåæãéäºåæå¨çççååæ¹é¢ï¼ä¾å¦ï¼å®åæ¶åçå­é ååççé¡åï¼åæ¸æåæåè½æ¹é¢é«åº¦å¤æ¨£åãç¶èï¼ç®åç¼ºä¹å°éäºåæå¨éäºç¹å¾µå AI ä¿è­ (AIA) æ¹é¢çå¨é¢çè§£ãéç¯ç³»çµ±æ§åé¡§æ¨å¨ééæª¢è¦ç¾ææç»ä¸¦æç¢ºéæ³¨ééµç¹å¾µå AI ä¿è­è§é»ï¼ä¾å¡«è£éåç©ºç½ãæ¹æ³ï¼ä½¿ç¨ PRISMA æ¶æ§å¨ä¸åæåè³æåº«ä¸­é²è¡å¨é¢æå°ãåæååæ¬ 2015 å¹´è³ 2023 å¹´éç¼è¡¨æ¼åè¡è©å¯©æåçç ç©¶ãçµæï¼å¨åé¡§ä¸­ï¼ç¸½å±æª¢è¦äº 96 é ç± DL é©åçåæãç ç©¶çµææ­ç¤ºäºå¹¾åéæ¼ç± DL é©åçåµå·¢çæ¸æåæçéè¦è¦è§£ï¼- å¤§å¤æ¸ç ç©¶ 71%ï¼96 é ä¸­æ 68 é ï¼å°æ³¨æ¼æª¢æ¸¬åè¨ºæ·ï¼èæ²æç ç©¶æ¢è¨ OC çé æ¸¬åé é²ã- éäºåæä¸»è¦åºæ¼ä¾èªéå¤åæç¾¤çæ¨£æ¬ï¼75%ï¼96 é ç ç©¶ä¸­ç 72 é ï¼ï¼ï¼åéæ¼æåå°çä½ç½®æåå®¶ã- åªæå°é¨åç ç©¶ï¼å 33%ï¼96 é ç ç©¶ä¸­ç 32 é ï¼å·è¡æ´ååæï¼å¶ä¸­å¤§å¤æ¸ä½¿ç¨åè³ªæ¸æï¼è¨åºæçµå­¸ï¼ã- å¼å¾æ³¨æçæ¯ï¼åªæ 8.3%ï¼96 é ç ç©¶ä¸­ç 8 é ï¼ä½¿ç¨å¤é¨åå¤åæ¸æéé©è­äºå¶æ¨¡åï¼å¼·èª¿äºå å¼·æ¨¡åé©è­çå¿è¦æ§ï¼ä»¥å- å° AIA ç´å¥ççæ¸æåæä»èæ¼éå¸¸æ©æçéæ®µï¼åªæ 2.1%ï¼96 é ç ç©¶ä¸­ç 2 é ï¼ééå¯è§£éæ§æç¢ºæ¢è¨äº AIAã</paragraph>

##### **Representing visual classification as a linear combination of words**
2311.10933v1 by Shobhit Agarwal, Yevgeniy R. Semenov, William Lotter

Explainability is a longstanding challenge in deep learning, especially in
high-stakes domains like healthcare. Common explainability methods highlight
image regions that drive an AI model's decision. Humans, however, heavily rely
on language to convey explanations of not only "where" but "what".
Additionally, most explainability approaches focus on explaining individual AI
predictions, rather than describing the features used by an AI model in
general. The latter would be especially useful for model and dataset auditing,
and potentially even knowledge generation as AI is increasingly being used in
novel tasks. Here, we present an explainability strategy that uses a
vision-language model to identify language-based descriptors of a visual
classification task. By leveraging a pre-trained joint embedding space between
images and text, our approach estimates a new classification task as a linear
combination of words, resulting in a weight for each word that indicates its
alignment with the vision-based classifier. We assess our approach using two
medical imaging classification tasks, where we find that the resulting
descriptors largely align with clinical knowledge despite a lack of
domain-specific language training. However, our approach also identifies the
potential for 'shortcut connections' in the public datasets used. Towards a
functional measure of explainability, we perform a pilot reader study where we
find that the AI-identified words can enable non-expert humans to perform a
specialized medical task at a non-trivial level. Altogether, our results
emphasize the potential of using multimodal foundational models to deliver
intuitive, language-based explanations of visual tasks.

æè¦ï¼<paragraph>è§£éæ§æ¯æ·±åº¦å­¸ç¿ä¸­é·æçææ°ï¼ç¹å¥æ¯å¨é«çä¿å¥ç­é«é¢¨éªé åãå¸¸è¦çè§£éæ§æ¹æ³æå¼·èª¿é©å AI æ¨¡åæ±ºç­çå½±åååãç¶èï¼äººé¡å¾å¤§ç¨åº¦ä¾è³´èªè¨ä¾å³éä¸åæ¯ãå¨åªè£¡ãï¼éæãæ¯ä»éº¼ãçè§£éãæ­¤å¤ï¼å¤§å¤æ¸è§£éæ§æ¹æ³é½å°æ³¨æ¼è§£éåå¥ AI é æ¸¬ï¼èä¸æ¯æè¿° AI æ¨¡åä¸è¬ä½¿ç¨çç¹å¾µãå¾èå°æ¼æ¨¡ååè³æéç¨½æ ¸ç¹å¥æç¨ï¼çè³å¯è½å¨ AI æä¾æç¨æ¼æ°ç©ä»»åæç¢çç¥è­ãå¨æ­¤ï¼æåæåºä¸åä½¿ç¨è¦è¦ºèªè¨æ¨¡åä¾è¾¨è­è¦è¦ºåé¡ä»»åçèªè¨æè¿°ç¬¦çè§£éæ§ç­ç¥ãééå©ç¨å½±ååæå­ä¹éé åè¨ç·´çè¯ååµå¥ç©ºéï¼æåçåæ³å°æ°çåé¡ä»»åä¼°è¨çºä¸åç·æ§æå­çµåï¼å°è´æ¯åæå­é½ææ¬éï¼è¡¨ç¤ºå®èåºæ¼è¦è¦ºçåé¡å¨å°é½ãæåä½¿ç¨å©åé«å­¸å½±ååé¡ä»»åä¾è©ä¼°æåçåæ³ï¼æåç¼ç¾ç¢ççæè¿°ç¬¦å¨å¾å¤§ç¨åº¦ä¸èè¨åºç¥è­ä¸è´ï¼åç®¡ç¼ºä¹ç¹å®é åçèªè¨è¨ç·´ãç¶èï¼æåçåæ³ä¹ç¼ç¾äºæç¨å¬éè³æéä¸­çãæ·å¾é£ç·ãçå¯è½æ§ãçºäºéå°è§£éæ§çåè½æ§è¡¡éï¼æåé²è¡äºä¸é è©¦é©è®èç ç©¶ï¼ç¼ç¾ AI è­å¥çæå­è½è®éå°å®¶äººé¡å¨éå¹³å¡çå±¤ç´å·è¡å°æ¥­çé«çä»»åãç¸½ä¹ï¼æåççµæå¼·èª¿äºä½¿ç¨å¤æ¨¡å¼åºç¤æ¨¡åä¾æä¾ç´è§çãåºæ¼èªè¨çè¦è¦ºä»»åè§£éçæ½åã</paragraph>

##### **Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**
2311.02115v2 by Emma A. M. Stanley, Raissa Souza, Anthony Winder, Vedant Gulve, Kimberly Amador, Matthias Wilms, Nils D. Forkert

Artificial intelligence (AI) models trained using medical images for clinical
tasks often exhibit bias in the form of disparities in performance between
subgroups. Since not all sources of biases in real-world medical imaging data
are easily identifiable, it is challenging to comprehensively assess how those
biases are encoded in models, and how capable bias mitigation methods are at
ameliorating performance disparities. In this article, we introduce a novel
analysis framework for systematically and objectively investigating the impact
of biases in medical images on AI models. We developed and tested this
framework for conducting controlled in silico trials to assess bias in medical
imaging AI using a tool for generating synthetic magnetic resonance images with
known disease effects and sources of bias. The feasibility is showcased by
using three counterfactual bias scenarios to measure the impact of simulated
bias effects on a convolutional neural network (CNN) classifier and the
efficacy of three bias mitigation strategies. The analysis revealed that the
simulated biases resulted in expected subgroup performance disparities when the
CNN was trained on the synthetic datasets. Moreover, reweighing was identified
as the most successful bias mitigation strategy for this setup, and we
demonstrated how explainable AI methods can aid in investigating the
manifestation of bias in the model using this framework. Developing fair AI
models is a considerable challenge given that many and often unknown sources of
biases can be present in medical imaging datasets. In this work, we present a
novel methodology to objectively study the impact of biases and mitigation
strategies on deep learning pipelines, which can support the development of
clinical AI that is robust and responsible.

æè¦ï¼<paragraph>ä½¿ç¨é«çå½±åè¨ç·´çäººå·¥æºæ§ (AI) æ¨¡åï¼ç¨æ¼è¨åºä»»åæï¼å¸¸æå¨æè½ä¸å±ç¾åºæ¬¡ç¾¤é«ä¹éçå·®ç°ï¼å½¢æåè¦ãç±æ¼ä¸¦éææçå¯¦ä¸çé«çå½±åè³æä¸­çåè¦ä¾æºé½å®¹æè¾¨è­ï¼å æ­¤å¨é¢è©ä¼°éäºåè¦æ¯å¦ä½ç·¨ç¢¼å°æ¨¡åä¸­ï¼ä»¥ååè¦ç·©è§£æ¹æ³å¨æ¹åæè½å·®ç°æ¹é¢çè½åï¼æ¯ä¸é ææ°ãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸åæ°ç©çåææ¶æ§ï¼ç¨æ¼ç³»çµ±åä¸å®¢è§å°èª¿æ¥é«çå½±åä¸­çåè¦å° AI æ¨¡åçå½±é¿ãæåéç¼ä¸¦æ¸¬è©¦äºéåæ¶æ§ï¼ä»¥é²è¡åæ§çé»è¦æ¨¡æ¬è©¦é©ï¼ä½¿ç¨ä¸åå·¥å·ä¾è©ä¼°é«çå½±å AI ä¸­çåè¦ï¼è©²å·¥å·ç¨æ¼ç¢çå·æå·²ç¥ç¾çå½±é¿ååè¦ä¾æºçåæç£å±æ¯å½±åãå¯è¡æ§ééä½¿ç¨ä¸ååäºå¯¦åè¦æå¢ä¾è¡¡éæ¨¡æ¬åè¦ææå°å·ç©ç¥ç¶ç¶²è·¯ (CNN) åé¡å¨åä¸ååè¦ç·©è§£ç­ç¥çå½±é¿ï¼ä¸¦å±ç¤ºåºä¾ãåæé¡¯ç¤ºï¼ç¶ CNN å¨åæè³æéä¸åè¨æï¼æ¨¡æ¬åè¦æå°è´é æçæ¬¡ç¾¤é«æè½å·®ç°ãæ­¤å¤ï¼éæ°å æ¬è¢«èªçºæ¯æ­¤è¨­å®ä¸­ææåçåè¦ç·©è§£ç­ç¥ï¼æåå±ç¤ºäºè§£éæ§ AI æ¹æ³å¦ä½åå©ä½¿ç¨éåæ¶æ§èª¿æ¥æ¨¡åä¸­åè¦çè¡¨ç¾ãéç¼å¬å¹³ç AI æ¨¡åæ¯ä¸é éå¤§çææ°ï¼å çºé«çå½±åè³æéä¸­å¯è½å­å¨è¨±å¤ä¸ç¶å¸¸æªç¥çåè¦ä¾æºãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°ç©çæ¹æ³ï¼ç¨æ¼å®¢è§å°ç ç©¶åè¦åç·©è§£ç­ç¥å°æ·±åº¦å­¸ç¿ç®¡ç·çå½±é¿ï¼éå¯ä»¥æ¯æ´å¥å¨ä¸è² è²¬ä»»çè¨åº AI çéç¼ã</paragraph>

##### **Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**
2310.19174v1 by Adam White, Margarita Saranti, Artur d'Avila Garcez, Thomas M. H. Hope, Cathy J. Price, Howard Bowman

Machine learning offers great potential for automated prediction of
post-stroke symptoms and their response to rehabilitation. Major challenges for
this endeavour include the very high dimensionality of neuroimaging data, the
relatively small size of the datasets available for learning, and how to
effectively combine neuroimaging and tabular data (e.g. demographic information
and clinical characteristics). This paper evaluates several solutions based on
two strategies. The first is to use 2D images that summarise MRI scans. The
second is to select key features that improve classification accuracy.
Additionally, we introduce the novel approach of training a convolutional
neural network (CNN) on images that combine regions-of-interest extracted from
MRIs, with symbolic representations of tabular data. We evaluate a series of
CNN architectures (both 2D and a 3D) that are trained on different
representations of MRI and tabular data, to predict whether a composite measure
of post-stroke spoken picture description ability is in the aphasic or
non-aphasic range. MRI and tabular data were acquired from 758 English speaking
stroke survivors who participated in the PLORAS study. The classification
accuracy for a baseline logistic regression was 0.678 for lesion size alone,
rising to 0.757 and 0.813 when initial symptom severity and recovery time were
successively added. The highest classification accuracy 0.854 was observed when
8 regions-of-interest was extracted from each MRI scan and combined with lesion
size, initial severity and recovery time in a 2D Residual Neural Network.Our
findings demonstrate how imaging and tabular data can be combined for high
post-stroke classification accuracy, even when the dataset is small in machine
learning terms. We conclude by proposing how the current models could be
improved to achieve even higher levels of accuracy using images from hospital
scanners.

æè¦ï¼æ©å¨å­¸ç¿çºèªåé æ¸¬ä¸­é¢¨å¾ççåå¶å°å¾©å¥çåææä¾äºæ¥µå¤§çæ½åãéé å·¥ä½çéå¤§ææ°åæ¬ç¥ç¶å½±åè³æçç¶­åº¦éå¸¸é«ãå¯ç¨æ¼å­¸ç¿çè³æéè¦æ¨¡ç¸å°è¼å°ï¼ä»¥åå¦ä½ææçµåç¥ç¶å½±ååè¡¨æ ¼è³æï¼ä¾å¦äººå£çµ±è¨è³è¨åè¨åºç¹å¾µï¼ãæ¬ææ ¹æå©ç¨®ç­ç¥è©ä¼°äºå¤ç¨®è§£æ±ºæ¹æ¡ãç¬¬ä¸ç¨®æ¯ä½¿ç¨ç¸½çµ MRI ææç 2D å½±åãç¬¬äºç¨®æ¯é¸ææå©æ¼æé«åé¡ç²¾ç¢ºåº¦çééµç¹å¾µãæ­¤å¤ï¼æåå¼å¥äºå¨çµåå¾ MRI ä¸­æåçæèè¶£ååèè¡¨æ ¼è³æçç¬¦èè¡¨ç¤ºçå½±åä¸è¨ç·´å·ç©ç¥ç¶ç¶²è·¯ (CNN) çæ°ç©æ¹æ³ãæåè©ä¼°äºä¸ç³»å CNN æ¶æ§ï¼2D å 3Dï¼ï¼éäºæ¶æ§å¨ MRI åè¡¨æ ¼è³æçä¸åè¡¨ç¤ºä¸é²è¡è¨ç·´ï¼ä»¥é æ¸¬ä¸­é¢¨å¾å£è¿°åçæè¿°è½åçç¶åæ¸¬éæ¯å¦å¨å¤±èªçæéå¤±èªçç¯åå§ãMRI åè¡¨æ ¼è³æä¾èª 758 ååè PLORAS ç ç©¶çè±èªä¸­é¢¨åå­èãåéå°çç¶å¤§å°çåºç·éè¼¯è¿´æ­¸åé¡æºç¢ºåº¦çº 0.678ï¼ç¶ä¾åºå å¥åå§ççå´éç¨åº¦åæ¢å¾©æéæï¼ä¸åè³ 0.757 å 0.813ãå¨å¾æ¯å MRI ææä¸­æå 8 åæèè¶£ååä¸¦å¨ 2D æ®å·®ç¥ç¶ç¶²è·¯ä¸­èçç¶å¤§å°ãåå§å´éç¨åº¦åæ¢å¾©æéçµåæï¼è§å¯å°æé«çåé¡æºç¢ºåº¦ 0.854ãæåçç ç©¶çµæå±ç¤ºäºå¦ä½å°å½±ååè¡¨æ ¼è³æçµåèµ·ä¾ä»¥ç²å¾é«æ¼ä¸­é¢¨å¾åé¡æºç¢ºåº¦ï¼å³ä½¿å¨æ©å¨å­¸ç¿è¡èªä¸­è³æéå¾å°çææ³ä¸ä¹æ¯å¦æ­¤ãæå¾ï¼æåæåºå¦ä½æ¹é²ç®åçæ¨¡åï¼ä»¥ä½¿ç¨ä¾èªé«é¢ææåçå½±åä¾å¯¦ç¾æ´é«çæºç¢ºåº¦ã

##### **Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**
2310.01828v2 by Hossein Shreim, Abdul Karim Gizzini, Ali J. Ghandour

eXplainable Artificial Intelligence (XAI) has emerged as an essential
requirement when dealing with mission-critical applications, ensuring
transparency and interpretability of the employed black box AI models. The
significance of XAI spans various domains, from healthcare to finance, where
understanding the decision-making process of deep learning algorithms is
essential. Most AI-based computer vision models are often black boxes; hence,
providing explainability of deep neural networks in image processing is crucial
for their wide adoption and deployment in medical image analysis, autonomous
driving, and remote sensing applications. Recently, several XAI methods for
image classification tasks have been introduced. On the contrary, image
segmentation has received comparatively less attention in the context of
explainability, although it is a fundamental task in computer vision
applications, especially in remote sensing. Only some research proposes
gradient-based XAI algorithms for image segmentation. This paper adapts the
recent gradient-free Sobol XAI method for semantic segmentation. To measure the
performance of the Sobol method for segmentation, we propose a quantitative XAI
evaluation method based on a learnable noise model. The main objective of this
model is to induce noise on the explanation maps, where higher induced noise
signifies low accuracy and vice versa. A benchmark analysis is conducted to
evaluate and compare performance of three XAI methods, including Seg-Grad-CAM,
Seg-Grad-CAM++ and Seg-Sobol using the proposed noise-based evaluation
technique. This constitutes the first attempt to run and evaluate XAI methods
using high-resolution satellite images.

æè¦ï¼å¯è§£éäººå·¥æºæ§ (XAI) å·²æçºèçä»»åééµæç¨ç¨å¼æçä¸é åºæ¬éæ±ï¼ç¢ºä¿æ¡ç¨é»ç AI æ¨¡åçéæåº¦åå¯è§£éæ§ãXAI çéè¦æ§æ¶µèå¾é«çä¿å¥å°éèçåç¨®é åï¼å¨éäºé åä¸­ï¼äºè§£æ·±åº¦å­¸ç¿æ¼ç®æ³çæ±ºç­å¶å®éç¨è³ééè¦ãå¤§å¤æ¸åºæ¼ AI çé»è¦è¦è¦ºæ¨¡åéå¸¸æ¯é»çå­ï¼å æ­¤ï¼å¨å½±åèçä¸­æä¾æ·±åº¦ç¥ç¶ç¶²è·¯çå¯è§£éæ§å°æ¼å¶å¨é«å­¸å½±ååæãèªåé§é§åéæ¸¬æç¨ä¸­çå»£æ³æ¡ç¨åé¨ç½²è³ééè¦ãæè¿ï¼å·²éå°å½±ååé¡ä»»åå¼å¥äºå¤ç¨® XAI æ¹æ³ãç¸åå°ï¼å½±ååå²å¨å¯è§£éæ§çèæ¯ä¸åå°çéæ³¨ç¸å°è¼å°ï¼åç®¡å®æ¯é»è¦è¦è¦ºæç¨ä¸­çä¸é åºæ¬ä»»åï¼ç¹å¥æ¯å¨éæ¸¬ä¸­ãåªæé¨åç ç©¶æåºç¨æ¼å½±ååå²çåºæ¼æ¢¯åº¦ç XAI æ¼ç®æ³ãæ¬ææ¹ç·¨äºæè¿çç¡æ¢¯åº¦ Sobol XAI æ¹æ³ä»¥é²è¡èªæåå²ãçºäºè¡¡é Sobol æ¹æ³å¨åå²ä¸­çæè½ï¼æåæåºäºä¸ç¨®åºæ¼å¯å­¸ç¿éè¨æ¨¡åçå®é XAI è©ä¼°æ¹æ³ãæ­¤æ¨¡åçä¸»è¦ç®çæ¯å¨è§£éåä¸èªç¼éè¨ï¼å¶ä¸­è¼é«çèªç¼éè¨è¡¨ç¤ºè¼ä½çæºç¢ºåº¦ï¼åä¹äº¦ç¶ãé²è¡åºæºåæä»¥è©ä¼°åæ¯è¼ä¸ç¨® XAI æ¹æ³çæè½ï¼åæ¬ Seg-Grad-CAMãSeg-Grad-CAM++ å Seg-Sobolï¼ä¸¦ä½¿ç¨ææåºçåºæ¼éè¨çè©ä¼°æè¡ãéæ§æäºä½¿ç¨é«è§£æåº¦è¡æå½±åå·è¡åè©ä¼° XAI æ¹æ³çé¦æ¬¡åè©¦ã

##### **Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI**
2311.01463v1 by Muhammad Aurangzeb Ahmad, Ilker Yaramis, Taposh Dutta Roy

Large language models have proliferated across multiple domains in as short
period of time. There is however hesitation in the medical and healthcare
domain towards their adoption because of issues like factuality, coherence, and
hallucinations. Give the high stakes nature of healthcare, many researchers
have even cautioned against its usage until these issues are resolved. The key
to the implementation and deployment of LLMs in healthcare is to make these
models trustworthy, transparent (as much possible) and explainable. In this
paper we describe the key elements in creating reliable, trustworthy, and
unbiased models as a necessary condition for their adoption in healthcare.
Specifically we focus on the quantification, validation, and mitigation of
hallucinations in the context in healthcare. Lastly, we discuss how the future
of LLMs in healthcare may look like.

æè¦ï¼å¤§åèªè¨æ¨¡åå¨ç­æéå§å·²å¨å¤åé åä¸­å¤§éæ¿å¢ãç¶èï¼ç±æ¼äºå¯¦æ§ãé£è²«æ§åå¹»è¦ºç­åé¡ï¼é«çåä¿å¥é åå°å¶æ¡ç¨ç¶è±«ä¸æ±ºãéæ¼é«çä¿å¥çé«é¢¨éªæ§è³ªï¼è¨±å¤ç ç©¶äººå¡çè³è­¦åä¸è¦ä½¿ç¨å®ï¼ç´å°éäºåé¡å¾å°è§£æ±ºãå¨é«çä¿å¥ä¸­å¯¦æ½åé¨ç½² LLM çééµæ¯ä½¿éäºæ¨¡åå¼å¾ä¿¡è³´ãéæï¼ç¡å¯è½å¤ï¼ä¸å¯è§£éãå¨æ¬æä¸­ï¼æåæè¿°äºå»ºç«å¯é ãå¼å¾ä¿¡è³´åç¡åè¦æ¨¡åçééµè¦ç´ ï¼ä½çºå®åå¨é«çä¿å¥ä¸­å¾å°æ¡ç¨çå¿è¦æ¢ä»¶ãå·é«ä¾èªªï¼æåå°æ³¨æ¼å¨é«çä¿å¥èæ¯ä¸å°å¹»è¦ºé²è¡éåãé©è­åç·©è§£ãæå¾ï¼æåè¨è«äº LLM å¨é«çä¿å¥ä¸­çæªä¾å¯è½æ¯ä»éº¼æ¨£å­ã

##### **When to Trust AI: Advances and Challenges for Certification of Neural Networks**
2309.11196v1 by Marta Kwiatkowska, Xiyue Zhang

Artificial intelligence (AI) has been advancing at a fast pace and it is now
poised for deployment in a wide range of applications, such as autonomous
systems, medical diagnosis and natural language processing. Early adoption of
AI technology for real-world applications has not been without problems,
particularly for neural networks, which may be unstable and susceptible to
adversarial examples. In the longer term, appropriate safety assurance
techniques need to be developed to reduce potential harm due to avoidable
system failures and ensure trustworthiness. Focusing on certification and
explainability, this paper provides an overview of techniques that have been
developed to ensure safety of AI decisions and discusses future challenges.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å·²å¿«éé²æ­¥ï¼ç¾å·²æºåé¨ç½²æ¼å»£æ³çæç¨ç¨å¼ä¸­ï¼ä¾å¦èªä¸»ç³»çµ±ãé«çè¨ºæ·åèªç¶èªè¨èçãåæ©æ¡ç¨ AI æè¡æ¼å¯¦éæç¨ç¨å¼ä¸¦éæ²æåé¡ï¼ç¹å¥æ¯å°æ¼ç¥ç¶ç¶²è·¯ï¼å®å¯è½ä¸ç©©å®ä¸å®¹æåå°å°ææ§ç¯ä¾çå½±é¿ãå¾é·é ä¾çï¼éè¦éç¼é©ç¶çå®å¨ä¿è­æè¡ï¼ä»¥æ¸å°å å¯é¿åçç³»çµ±æéèé æçæ½å¨å·å®³ï¼ä¸¦ç¢ºä¿å¯ä¿¡è³´æ§ãæ¬æèéæ¼èªè­åå¯è§£éæ§ï¼æ¦è¿°äºå·²éç¼ç¨æ¼ç¢ºä¿ AI æ±ºç­å®å¨çæè¡ï¼ä¸¦è¨è«æªä¾çææ°ã

##### **Functional requirements to mitigate the Risk of Harm to Patients from Artificial Intelligence in Healthcare**
2309.10424v1 by Juan M. GarcÃ­a-GÃ³mez, Vicent Blanes-Selva, JosÃ© Carlos de BartolomÃ© Cenzano, Jaime Cebolla-Cornejo, AscensiÃ³n DoÃ±ate-MartÃ­nez

The Directorate General for Parliamentary Research Services of the European
Parliament has prepared a report to the Members of the European Parliament
where they enumerate seven main risks of Artificial Intelligence (AI) in
medicine and healthcare: patient harm due to AI errors, misuse of medical AI
tools, bias in AI and the perpetuation of existing inequities, lack of
transparency, privacy and security issues, gaps in accountability, and
obstacles in implementation.
  In this study, we propose fourteen functional requirements that AI systems
may implement to reduce the risks associated with their medical purpose: AI
passport, User management, Regulation check, Academic use only disclaimer, data
quality assessment, Clinicians double check, Continuous performance evaluation,
Audit trail, Continuous usability test, Review of retrospective/simulated
cases, Bias check, eXplainable AI, Encryption and use of field-tested
libraries, and Semantic interoperability.
  Our intention here is to provide specific high-level specifications of
technical solutions to ensure continuous good performance and use of AI systems
to benefit patients in compliance with the future EU regulatory framework.

æè¦ï¼æ­æ´²è­°æè­°æç ç©¶æåç¸½å±å·²çºæ­æ´²è­°æè­°å¡æºåäºä¸ä»½å ±åï¼å¶ä¸­åèäºäººå·¥æºè½ (AI) å¨é«çä¿å¥é åçä¸é ä¸»è¦é¢¨éªï¼AI é¯èª¤å°è´æ£èåå°å·å®³ãé«ç AI å·¥å·è¢«æ¿«ç¨ãAI å­å¨åè¦ä¸¦å°è´ç¾æ inequities æçºå­å¨ãç¼ºä¹éæåº¦ãé±ç§åå®å¨åé¡ãåè²¬å·®è·ä»¥åå¯¦æ½éç¤ã
  å¨éé ç ç©¶ä¸­ï¼æåæåºäºååé åè½æ§è¦æ±ï¼AI ç³»çµ±å¯ä»¥å¯¦æ½éäºè¦æ±ä¾éä½èå¶é«çç®çç¸éçé¢¨éªï¼AI è­·ç§ãä½¿ç¨èç®¡çãæ³è¦æª¢æ¥ãåéå­¸è¡ç¨éåè²¬è²æãè³æåè³ªè©ä¼°ãè¨åºé«çééæª¢æ¥ãæçºæè½è©ä¼°ãç¨½æ ¸è¿½è¹¤ãæçºå¯ç¨æ§æ¸¬è©¦ãåé¡§åæº¯/æ¨¡æ¬æ¡ä¾ãåè¦æª¢æ¥ãå¯è§£é AIãå å¯åä½¿ç¨ç¶éå¯¦å°æ¸¬è©¦çç¨å¼åº«ï¼ä»¥åèªæäºéæ§ã
  æåå¨æ­¤çç®çæ¯æä¾æè¡è§£æ±ºæ¹æ¡çç¹å®é«éè¦æ ¼ï¼ä»¥ç¢ºä¿æçºè¯å¥½çæè½ï¼ä¸¦ä½¿ç¨ AI ç³»çµ±ï¼ä»¥ç¬¦åæªä¾çæ­çæ³è¦æ¶æ§ï¼å¾èä½¿æ£èåçã

##### **QXAI: Explainable AI Framework for Quantitative Analysis in Patient Monitoring Systems**
2309.10293v3 by Thanveer Shaik, Xiaohui Tao, Haoran Xie, Lin Li, Juan D. Velasquez, Niall Higgins

Artificial Intelligence techniques can be used to classify a patient's
physical activities and predict vital signs for remote patient monitoring.
Regression analysis based on non-linear models like deep learning models has
limited explainability due to its black-box nature. This can require
decision-makers to make blind leaps of faith based on non-linear model results,
especially in healthcare applications. In non-invasive monitoring, patient data
from tracking sensors and their predisposing clinical attributes act as input
features for predicting future vital signs. Explaining the contributions of
various features to the overall output of the monitoring application is
critical for a clinician's decision-making. In this study, an Explainable AI
for Quantitative analysis (QXAI) framework is proposed with post-hoc model
explainability and intrinsic explainability for regression and classification
tasks in a supervised learning approach. This was achieved by utilizing the
Shapley values concept and incorporating attention mechanisms in deep learning
models. We adopted the artificial neural networks (ANN) and attention-based
Bidirectional LSTM (BiLSTM) models for the prediction of heart rate and
classification of physical activities based on sensor data. The deep learning
models achieved state-of-the-art results in both prediction and classification
tasks. Global explanation and local explanation were conducted on input data to
understand the feature contribution of various patient data. The proposed QXAI
framework was evaluated using PPG-DaLiA data to predict heart rate and mobile
health (MHEALTH) data to classify physical activities based on sensor data.
Monte Carlo approximation was applied to the framework to overcome the time
complexity and high computation power requirements required for Shapley value
calculations.

æè¦ï¼äººå·¥æºæ§æè¡å¯ç¨æ¼åé¡çæ£çèº«é«æ´»åä¸¦é æ¸¬é è·çæ£ç£æ§çéè¦çå½å¾µè±¡ãåºæ¼æ·±åº¦å­¸ç¿æ¨¡åç­éç·æ§æ¨¡åçåæ­¸åæç±æ¼å¶é»çå­çæ§è³ªèå·ææéçå¯è§£éæ§ãéå¯è½éè¦æ±ºç­èæ ¹æéç·æ§æ¨¡åçµæååºç²ç®çä¿¡ä»°é£èºï¼ç¹å¥æ¯å¨é«çä¿å¥æç¨ä¸­ãå¨éä¾µå¥æ§ç£æ§ä¸­ï¼ä¾èªè¿½è¹¤ææ¸¬å¨åå¶ææè¨åºå±¬æ§ççæ£è³æåç¶é æ¸¬æªä¾çå½å¾µè±¡çè¼¸å¥ç¹å¾µãè§£éåç¨®ç¹å¾µå°ç£æ§æç¨ç¨å¼æ´é«è¼¸åºçè²¢ç»å°æ¼è¨åºé«ççæ±ºç­è³ééè¦ãå¨æ¬ç ç©¶ä¸­ï¼æåºäºä¸åç¨æ¼éååæçå¯è§£éäººå·¥æºæ§ (QXAI) æ¶æ§ï¼è©²æ¶æ§å·æç£ç£å¼å­¸ç¿æ¹æ³ä¸­åæ­¸ååé¡ä»»åçäºå¾æ¨¡åå¯è§£éæ§åå§å¨å¯è§£éæ§ãéééå©ç¨ Shapley å¼æ¦å¿µä¸¦å°æ³¨æåæ©å¶ç´å¥æ·±åº¦å­¸ç¿æ¨¡åä¾å¯¦ç¾ãæåæ¡ç¨äººå·¥ç¥ç¶ç¶²è·¯ (ANN) ååºæ¼æ³¨æåçéå LSTM (BiLSTM) æ¨¡åï¼æ ¹æææ¸¬å¨è³æé æ¸¬å¿çååé¡èº«é«æ´»åãæ·±åº¦å­¸ç¿æ¨¡åå¨é æ¸¬ååé¡ä»»åä¸­é½åå¾äºæåé²çææãå°è¼¸å¥è³æé²è¡å¨å±è§£éåå±é¨è§£éï¼ä»¥äºè§£åç¨®çæ£è³æçç¹å¾µè²¢ç»ãææåºç QXAI æ¶æ§ä½¿ç¨ PPG-DaLiA è³æè©ä¼°ï¼ä»¥é æ¸¬å¿çï¼ä¸¦ä½¿ç¨è¡åå¥åº· (MHEALTH) è³ææ ¹æææ¸¬å¨è³æå°èº«é«æ´»åé²è¡åé¡ãèå°å¡ç¾è¿ä¼¼æ³æç¨æ¼è©²æ¶æ§ï¼ä»¥åæ Shapley å¼è¨ç®æéçæéè¤éåº¦åé«éç®è½åéæ±ã

##### **Evaluation of Human-Understandability of Global Model Explanations using Decision Tree**
2309.09917v1 by Adarsa Sivaprasad, Ehud Reiter, Nava Tintarev, Nir Oren

In explainable artificial intelligence (XAI) research, the predominant focus
has been on interpreting models for experts and practitioners. Model agnostic
and local explanation approaches are deemed interpretable and sufficient in
many applications. However, in domains like healthcare, where end users are
patients without AI or domain expertise, there is an urgent need for model
explanations that are more comprehensible and instil trust in the model's
operations. We hypothesise that generating model explanations that are
narrative, patient-specific and global(holistic of the model) would enable
better understandability and enable decision-making. We test this using a
decision tree model to generate both local and global explanations for patients
identified as having a high risk of coronary heart disease. These explanations
are presented to non-expert users. We find a strong individual preference for a
specific type of explanation. The majority of participants prefer global
explanations, while a smaller group prefers local explanations. A task based
evaluation of mental models of these participants provide valuable feedback to
enhance narrative global explanations. This, in turn, guides the design of
health informatics systems that are both trustworthy and actionable.

æè¦ï¼å¨å¯è§£éäººå·¥æºè½ (XAI) ç ç©¶ä¸­ï¼ä¸»è¦éç¹å¨äºä¸ºä¸å®¶åä»ä¸èè§£éæ¨¡åãæ¨¡åä¸å¯ç¥åå±é¨è§£éæ¹æ³å¨è®¸å¤åºç¨ä¸­è¢«è®¤ä¸ºæ¯å¯è§£éä¸è¶³å¤çãç¶èï¼å¨å»çä¿å¥ç­é¢åï¼æç»ç¨æ·æ¯ç¼ºä¹äººå·¥æºè½æé¢åä¸ä¸ç¥è¯çæ£èï¼å æ­¤è¿«åéè¦æ´æäºçè§£ä¸è½æ¿åå¯¹æ¨¡åæä½çä¿¡ä»»çæ¨¡åè§£éãæä»¬åè®¾çæåè¿°æ§ãæ£èç¹å®ä¸å¨å±ï¼æ¨¡åæ´ä½ï¼çæ¨¡åè§£éå°è½å¤æé«å¯çè§£æ§å¹¶æ¯æå³ç­å¶å®ãæä»¬ä½¿ç¨å³ç­æ æ¨¡åå¯¹æ­¤è¿è¡æµè¯ï¼ä¸ºè¢«è¯å«ä¸ºæ£æå å¿çé«é£é©çæ£èçæå±é¨åå¨å±è§£éãè¿äºè§£éä¼åç°ç»éä¸å®¶ç¨æ·ãæä»¬åç°ç¨æ·å¼ºçåå¥½ç¹å®ç±»åçè§£éãå¤§å¤æ°åä¸èåå¥½å¨å±è§£éï¼èè¾å°çä¸ç»åä¸èåå¥½å±é¨è§£éãåºäºä»»å¡çå¿çæ¨¡åè¯ä¼°ä¸ºè¿äºåä¸èæä¾äºæä»·å¼çåé¦ï¼ä»¥å¢å¼ºåè¿°æ§å¨å±è§£éãè¿åè¿æ¥åæå¯¼äºæ¢å¼å¾ä¿¡èµåå¯æä½çå¥åº·ä¿¡æ¯å­¦ç³»ç»çè®¾è®¡ã

##### **Leveraging A Medical Knowledge Graph into Large Language Models for Diagnosis Prediction**
2308.14321v1 by Yanjun Gao, Ruizhe Li, John Caskey, Dmitriy Dligach, Timothy Miller, Matthew M. Churpek, Majid Afshar

Electronic Health Records (EHRs) and routine documentation practices play a
vital role in patients' daily care, providing a holistic record of health,
diagnoses, and treatment. However, complex and verbose EHR narratives overload
healthcare providers, risking diagnostic inaccuracies. While Large Language
Models (LLMs) have showcased their potential in diverse language tasks, their
application in the healthcare arena needs to ensure the minimization of
diagnostic errors and the prevention of patient harm. In this paper, we outline
an innovative approach for augmenting the proficiency of LLMs in the realm of
automated diagnosis generation, achieved through the incorporation of a medical
knowledge graph (KG) and a novel graph model: Dr.Knows, inspired by the
clinical diagnostic reasoning process. We derive the KG from the National
Library of Medicine's Unified Medical Language System (UMLS), a robust
repository of biomedical knowledge. Our method negates the need for
pre-training and instead leverages the KG as an auxiliary instrument aiding in
the interpretation and summarization of complex medical concepts. Using
real-world hospital datasets, our experimental results demonstrate that the
proposed approach of combining LLMs with KG has the potential to improve the
accuracy of automated diagnosis generation. More importantly, our approach
offers an explainable diagnostic pathway, edging us closer to the realization
of AI-augmented diagnostic decision support systems.

æè¦ï¼é»å­å¥åº·ç´é (EHR) åä¾è¡æä»¶è¨éå¯¦åå¨çæ£çæ¥å¸¸ç§è­·ä¸­æ®æ¼èè³ééè¦çè§è²ï¼æä¾å¥åº·ãè¨ºæ·åæ²»ççæ´é«ç´éãç¶èï¼è¤éä¸åé·ç EHR æè¿°æè®é«çä¿å¥æä¾èè¶è¼ï¼æè¨ºæ·ä¸æºç¢ºçé¢¨éªãå¤§åèªè¨æ¨¡å (LLM) å·²å±ç¾å¶å¨åç¨®èªè¨ä»»åä¸çæ½åï¼ä½å¶å¨é«çä¿å¥é åçæç¨éè¦ç¢ºä¿å°è¨ºæ·é¯èª¤éå°æä½ï¼ä¸¦é²æ­¢çæ£åå°å·å®³ãå¨æ¬æä¸­ï¼æåæ¦è¿°ä¸ç¨®åµæ°çæ¹æ³ï¼ééæ´åé«å­¸ç¥è­åè­ (KG) åä¸ç¨®æ°ç©çåè­æ¨¡åï¼Dr.Knowsï¼éæä¾èªè¨åºè¨ºæ·æ¨çéç¨ï¼ï¼ä¾å¢å¼· LLM å¨èªååè¨ºæ·ç¢çé åçè½åãæåå¾ç¾ååå®¶é«å­¸åæ¸é¤¨ççµ±ä¸é«å­¸èªè¨ç³»çµ± (UMLS) ä¸­è¡çåº KGï¼éæ¯ä¸åå¼·å¤§ççç©é«å­¸ç¥è­å²å­åº«ãæåçåæ³å¦å®äºé åè¨ç·´çéè¦ï¼èæ¯å° KG ä½çºè¼å©å·¥å·ï¼åå©è§£éåç¸½çµè¤éçé«å­¸æ¦å¿µãä½¿ç¨çå¯¦ä¸ççé«é¢è³æéï¼æåçå¯¦é©çµæè­æï¼å° LLM è KG çµåçå»ºè­°æ¹æ³ææ½åæé«èªååè¨ºæ·ç¢ççæºç¢ºæ§ãæ´éè¦çæ¯ï¼æåçåæ³æä¾äºä¸æ¢å¯è§£éçè¨ºæ·éå¾ï¼è®æåæ´æ¥è¿å¯¦ç¾ AI å¢å¼·çè¨ºæ·æ±ºç­æ¯æ´ç³»çµ±ã

##### **Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review**
2308.09380v1 by Yun Xin Teoh, Alice Othmani, Siew Li Goh, Juliana Usman, Khin Wee Lai

Existing artificial intelligence (AI) models for diagnosing knee
osteoarthritis (OA) have faced criticism for their lack of transparency and
interpretability, despite achieving medical-expert-like performance. This
opacity makes them challenging to trust in clinical practice. Recently,
explainable artificial intelligence (XAI) has emerged as a specialized
technique that can provide confidence in the model's prediction by revealing
how the prediction is derived, thus promoting the use of AI systems in
healthcare. This paper presents the first survey of XAI techniques used for
knee OA diagnosis. The XAI techniques are discussed from two perspectives: data
interpretability and model interpretability. The aim of this paper is to
provide valuable insights into XAI's potential towards a more reliable knee OA
diagnosis approach and encourage its adoption in clinical practice.

æè¦ï¼ç¾æçç¨æ¼è¨ºæ·èéª¨éç¯ç (OA) çäººå·¥æºæ§ (AI) æ¨¡åå å¶ç¼ºä¹éæåº¦åå¯è§£éæ§èåå°æ¹è©ï¼åç®¡å®åéå°äºé¡ä¼¼é«å­¸å°å®¶çè¡¨ç¾ãéç¨®ä¸éææ§ä½¿å¾å®åå¨è¨åºå¯¦åä¸­é£ä»¥è¢«ä¿¡ä»»ãæè¿ï¼å¯è§£éäººå·¥æºæ§ (XAI) å·²æçºä¸ç¨®å°éæè¡ï¼å®è½ééæ­ç¤ºé æ¸¬çæ¨å°æ¹å¼ä¾æä¾å°æ¨¡åé æ¸¬çä¿¡å¿ï¼å¾èä¿é²å¨é«çä¿å¥ä¸­ä½¿ç¨ AI ç³»çµ±ãæ¬ææä¾äºéå°èéª¨éç¯çè¨ºæ·æä½¿ç¨ç XAI æè¡çç¬¬ä¸ä»½èª¿æ¥ãXAI æè¡å¾å©åè§åº¦é²è¡è¨è«ï¼è³æå¯è§£éæ§åæ¨¡åå¯è§£éæ§ãæ¬æçç®çæ¯æä¾å° XAI å¨æ´å¯é çèéª¨éç¯çè¨ºæ·æ¹æ³ä¸­çæ½åçå¯¶è²´è¦è§£ï¼ä¸¦é¼åµå¨è¨åºå¯¦åä¸­æ¡ç¨å®ã

##### **Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities**
2308.08407v1 by Munib Mesinovic, Peter Watkinson, Tingting Zhu

Recent advancements in AI applications to healthcare have shown incredible
promise in surpassing human performance in diagnosis and disease prognosis.
With the increasing complexity of AI models, however, concerns regarding their
opacity, potential biases, and the need for interpretability. To ensure trust
and reliability in AI systems, especially in clinical risk prediction models,
explainability becomes crucial. Explainability is usually referred to as an AI
system's ability to provide a robust interpretation of its decision-making
logic or the decisions themselves to human stakeholders. In clinical risk
prediction, other aspects of explainability like fairness, bias, trust, and
transparency also represent important concepts beyond just interpretability. In
this review, we address the relationship between these concepts as they are
often used together or interchangeably. This review also discusses recent
progress in developing explainable models for clinical risk prediction,
highlighting the importance of quantitative and clinical evaluation and
validation across multiple common modalities in clinical practice. It
emphasizes the need for external validation and the combination of diverse
interpretability methods to enhance trust and fairness. Adopting rigorous
testing, such as using synthetic datasets with known generative factors, can
further improve the reliability of explainability methods. Open access and
code-sharing resources are essential for transparency and reproducibility,
enabling the growth and trustworthiness of explainable research. While
challenges exist, an end-to-end approach to explainability in clinical risk
prediction, incorporating stakeholders from clinicians to developers, is
essential for success.

æè¦ï¼æè¿å¨é«çä¿å¥ä¸­çäººå·¥æºæ§æç¨é²å±é¡¯ç¤ºåºä»¤äººé£ä»¥ç½®ä¿¡çæ¿è«¾ï¼å¨è¨ºæ·åç¾çé å¾æ¹é¢è¶è¶äººé¡è¡¨ç¾ãç¶èï¼é¨èäººå·¥æºè½æ¨¡åçæ¥çè¤éï¼äººåå°å¶ä¸éææ§ãæ½å¨åå·®åå°å¯è§£éæ§çéæ±æå°ææãçºäºç¢ºä¿äººå·¥æºè½ç³»çµ±çä¿¡ä»»åå¯é æ§ï¼å°¤å¶æ¯å¨è¨åºé¢¨éªé æ¸¬æ¨¡åä¸­ï¼å¯è§£éæ§è®å¾è³ééè¦ãå¯è§£éæ§éå¸¸è¢«ç¨±çºäººå·¥æºè½ç³»çµ±æä¾å¶æ±ºç­éè¼¯ææ±ºç­æ¬èº«å°äººé¡å©çç¸éèçå¼·æåè§£éçè½åãå¨è¨åºé¢¨éªé æ¸¬ä¸­ï¼å¯è§£éæ§çå¶ä»æ¹é¢ï¼å¦å¬å¹³æ§ãåè¦ãä¿¡ä»»åéæåº¦ï¼ä¹ä»£è¡¨äºè¶è¶å¯è§£éæ§çéè¦æ¦å¿µãå¨æ¬æ¬¡å¯©æ¥ä¸­ï¼æåæ¢è¨äºéäºæ¦å¿µä¹éçéä¿ï¼å çºå®åç¶å¸¸ä¸èµ·æäºæä½¿ç¨ãæ¬å¯©æ¥éè¨è«äºçºè¨åºé¢¨éªé æ¸¬éç¼å¯è§£éæ¨¡åçææ°é²å±ï¼å¼·èª¿äºå¨è¨åºå¯¦è¸ä¸­å°å¤ç¨®å¸¸è¦æ¨¡å¼é²è¡å®éåè¨åºè©ä¼°åé©è­çéè¦æ§ãå®å¼·èª¿äºå¤é¨é©è­åå¤æ¨£åå¯è§£éæ§æ¹æ³ç¸çµåçå¿è¦æ§ï¼ä»¥å¢å¼·ä¿¡ä»»åå¬å¹³æ§ãæ¡ç¨å´æ ¼çæ¸¬è©¦ï¼ä¾å¦ä½¿ç¨å·æå·²ç¥çæå ç´ çåææ¸æéï¼å¯ä»¥é²ä¸æ­¥æé«å¯è§£éæ§æ¹æ³çå¯é æ§ãéæ¾ç²ååä»£ç¢¼å±äº«è³æºå°æ¼éæåº¦åå¯éè¤æ§è³ééè¦ï¼å¾èä¿é²å¯è§£éç ç©¶çå¢é·åå¯ä¿¡åº¦ãåç®¡å­å¨ææ°ï¼ä½å¾è¨åºé«çå°éç¼äººå¡ï¼æ¡ç¨ç«¯å°ç«¯çå¯è§£éæ§æ¹æ³å°æ¼è¨åºé¢¨éªé æ¸¬çæåè³ééè¦ã

##### **FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare**
2309.12325v3 by Karim Lekadir, Aasa Feragen, Abdul Joseph Fofanah, Alejandro F Frangi, Alena Buyx, Anais Emelie, Andrea Lara, Antonio R Porras, An-Wen Chan, Arcadi Navarro, Ben Glocker, Benard O Botwe, Bishesh Khanal, Brigit Beger, Carol C Wu, Celia Cintas, Curtis P Langlotz, Daniel Rueckert, Deogratias Mzurikwao, Dimitrios I Fotiadis, Doszhan Zhussupov, Enzo Ferrante, Erik Meijering, Eva Weicken, Fabio A GonzÃ¡lez, Folkert W Asselbergs, Fred Prior, Gabriel P Krestin, Gary Collins, Geletaw S Tegenaw, Georgios Kaissis, Gianluca Misuraca, Gianna Tsakou, Girish Dwivedi, Haridimos Kondylakis, Harsha Jayakody, Henry C Woodruf, Horst Joachim Mayer, Hugo JWL Aerts, Ian Walsh, Ioanna Chouvarda, IrÃ¨ne Buvat, Isabell Tributsch, Islem Rekik, James Duncan, Jayashree Kalpathy-Cramer, Jihad Zahir, Jinah Park, John Mongan, Judy W Gichoya, Julia A Schnabel, Kaisar Kushibar, Katrine Riklund, Kensaku Mori, Kostas Marias, Lameck M Amugongo, Lauren A Fromont, Lena Maier-Hein, Leonor CerdÃ¡ Alberich, Leticia Rittner, Lighton Phiri, Linda Marrakchi-Kacem, LluÃ­s Donoso-Bach, Luis MartÃ­-BonmatÃ­, M Jorge Cardoso, Maciej Bobowicz, Mahsa Shabani, Manolis Tsiknakis, Maria A Zuluaga, Maria Bielikova, Marie-Christine Fritzsche, Marina Camacho, Marius George Linguraru, Markus Wenzel, Marleen De Bruijne, Martin G Tolsgaard, Marzyeh Ghassemi, Md Ashrafuzzaman, Melanie Goisauf, Mohammad Yaqub, MÃ³nica Cano AbadÃ­a, Mukhtar M E Mahmoud, Mustafa Elattar, Nicola Rieke, Nikolaos Papanikolaou, Noussair Lazrak, Oliver DÃ­az, Olivier Salvado, Oriol Pujol, Ousmane Sall, Pamela Guevara, Peter Gordebeke, Philippe Lambin, Pieta Brown, Purang Abolmaesumi, Qi Dou, Qinghua Lu, Richard Osuala, Rose Nakasi, S Kevin Zhou, Sandy Napel, Sara Colantonio, Shadi Albarqouni, Smriti Joshi, Stacy Carter, Stefan Klein, Steffen E Petersen, Susanna AussÃ³, Suyash Awate, Tammy Riklin Raviv, Tessa Cook, Tinashe E M Mutsvangwa, Wendy A Rogers, Wiro J Niessen, XÃ¨nia Puig-Bosch, Yi Zeng, Yunusa G Mohammed, Yves Saint James Aquino, Zohaib Salahuddin, Martijn P A Starmans

Despite major advances in artificial intelligence (AI) for medicine and
healthcare, the deployment and adoption of AI technologies remain limited in
real-world clinical practice. In recent years, concerns have been raised about
the technical, clinical, ethical and legal risks associated with medical AI. To
increase real world adoption, it is essential that medical AI tools are trusted
and accepted by patients, clinicians, health organisations and authorities.
This work describes the FUTURE-AI guideline as the first international
consensus framework for guiding the development and deployment of trustworthy
AI tools in healthcare. The FUTURE-AI consortium was founded in 2021 and
currently comprises 118 inter-disciplinary experts from 51 countries
representing all continents, including AI scientists, clinicians, ethicists,
and social scientists. Over a two-year period, the consortium defined guiding
principles and best practices for trustworthy AI through an iterative process
comprising an in-depth literature review, a modified Delphi survey, and online
consensus meetings. The FUTURE-AI framework was established based on 6 guiding
principles for trustworthy AI in healthcare, i.e. Fairness, Universality,
Traceability, Usability, Robustness and Explainability. Through consensus, a
set of 28 best practices were defined, addressing technical, clinical, legal
and socio-ethical dimensions. The recommendations cover the entire lifecycle of
medical AI, from design, development and validation to regulation, deployment,
and monitoring. FUTURE-AI is a risk-informed, assumption-free guideline which
provides a structured approach for constructing medical AI tools that will be
trusted, deployed and adopted in real-world practice. Researchers are
encouraged to take the recommendations into account in proof-of-concept stages
to facilitate future translation towards clinical practice of medical AI.

æè¦ï¼åç®¡å¨é«å­¸åé«çä¿å¥æ¹é¢çäººå·¥æºæ§ (AI) æéå¤§çé²å±ï¼ä½ AI æè¡çé¨ç½²åæ¡ç¨å¨ç¾å¯¦ä¸ççè¨åºå¯¦åä¸­ä»ç¶æéãè¿å¹´ä¾ï¼äººåå°æ¼èé«ç AI ç¸éçæè¡ãè¨åºãå«çåæ³å¾é¢¨éªæåºäºçæ®ãçºäºå¢å ç¾å¯¦ä¸ççæ¡ç¨çï¼é«ç AI å·¥å·å¿é ç²å¾æ£èãè¨åºé«çãé«çæ©æ§åç¶å±çä¿¡ä»»åæ¥åãéé å·¥ä½å° FUTURE-AI æåæè¿°çºæå°é«çä¿å¥ä¸­å¯ä¿¡è³´ AI å·¥å·éç¼åé¨ç½²çç¬¬ä¸ååéå±è­æ¶æ§ãFUTURE-AI è¯çæç«æ¼ 2021 å¹´ï¼ç®åç±ä¾èª 51 ååå®¶ç 118 ä½è·¨é åå°å®¶çµæï¼ä»£è¡¨æææ´²ï¼åæ¬ AI ç§å­¸å®¶ãè¨åºé«çãå«çå­¸å®¶åç¤¾æç§å­¸å®¶ãå¨å©å¹´çæéè£¡ï¼è©²è¯çééä¸ååè¦éç®çéç¨å®ç¾©äºå¯ä¿¡è³´ AI çæå°åååæä½³å¯¦åï¼åæ¬æ·±å¥çæç»åé¡§ãä¿®æ¹å¾çå¾·ç¾è²èª¿æ¥åç·ä¸å±è­æè­°ãFUTURE-AI æ¶æ§æ¯åºæ¼é«çä¿å¥ä¸­å¯ä¿¡è³´ AI ç 6 é æå°ååå»ºç«çï¼å³å¬å¹³æ§ãæ®éæ§ãå¯è¿½æº¯æ§ãå¯ç¨æ§ãç©©å¥æ§åå¯è§£éæ§ãééå±è­ï¼å®ç¾©äºä¸çµ 28 é æä½³å¯¦åï¼æ¶µèæè¡ãè¨åºãæ³å¾åç¤¾æå«çå±¤é¢ãå»ºè­°æ¶µèäºé«ç AI çæ´åçå½é±æï¼å¾è¨­è¨ãéç¼åé©è­å°æ³è¦ãé¨ç½²åç£æ§ãFUTURE-AI æ¯ä¸ååºæ¼é¢¨éªãç¡åè¨­çæåï¼æä¾äºä¸åçµæ§åçæ¹æ³ï¼ç¨æ¼å»ºæ§å°å¨ç¾å¯¦ä¸çå¯¦åä¸­åå°ä¿¡ä»»ãé¨ç½²åæ¡ç¨çé«ç AI å·¥å·ãé¼åµç ç©¶äººå¡å¨æ¦å¿µé©è­éæ®µèæ®éäºå»ºè­°ï¼ä»¥ä¿é²æªä¾å°é«ç AI è½åçºè¨åºå¯¦åã

##### **Explainable AI applications in the Medical Domain: a systematic review**
2308.05411v1 by Nicoletta Prentzas, Antonis Kakas, Constantinos S. Pattichis

Artificial Intelligence in Medicine has made significant progress with
emerging applications in medical imaging, patient care, and other areas. While
these applications have proven successful in retrospective studies, very few of
them were applied in practice.The field of Medical AI faces various challenges,
in terms of building user trust, complying with regulations, using data
ethically.Explainable AI (XAI) aims to enable humans understand AI and trust
its results. This paper presents a literature review on the recent developments
of XAI solutions for medical decision support, based on a representative sample
of 198 articles published in recent years. The systematic synthesis of the
relevant articles resulted in several findings. (1) model-agnostic XAI
techniques were mostly employed in these solutions, (2) deep learning models
are utilized more than other types of machine learning models, (3)
explainability was applied to promote trust, but very few works reported the
physicians participation in the loop, (4) visual and interactive user interface
is more useful in understanding the explanation and the recommendation of the
system. More research is needed in collaboration between medical and AI
experts, that could guide the development of suitable frameworks for the
design, implementation, and evaluation of XAI solutions in medicine.

æè¦ï¼äººå·¥æºæ§å¨é«çé åä¸­å·²åå¾é¡¯èé²å±ï¼å¨é«å­¸å½±åãçäººç§è­·åå¶ä»é åä¸­åºç¾äºæ°èæç¨ãéç¶éäºæç¨å·²å¨åé¡§æ§ç ç©¶ä¸­è¢«è­å¯¦æ¯æåçï¼ä½å¯¦éä¸åªææ¥µå°æ¸æç¨æ¼å¯¦åãé«ç AI é åé¢è¨èåç¨®ææ°ï¼åæ¬å»ºç«ä½¿ç¨èä¿¡ä»»ãéµå®æ³è¦ãä½¿ç¨è³æç¬¦åå«çãå¯è§£é AI (XAI) çç®æ¨æ¯è®äººé¡äºè§£ AI ä¸¦ç¸ä¿¡å¶çµæãæ¬æéå°æè¿å¹¾å¹´ç¼è¡¨ç 198 ç¯æç« çå·ä»£è¡¨æ§æ¨£æ¬ï¼æåºæéé«çæ±ºç­æ¯æ´ç XAI è§£æ±ºæ¹æ¡çææ°ç¼å±çæç»åé¡§ãç¸éæç« çç³»çµ±æ§ç¶åæ´çç¢çäºå¤é ç¼ç¾ï¼(1) éäºè§£æ±ºæ¹æ¡å¤§å¤æ¡ç¨èæ¨¡åç¡éç XAI æè¡ï¼(2) æ·±åº¦å­¸ç¿æ¨¡åçä½¿ç¨çé«æ¼å¶ä»é¡åçæ©å¨å­¸ç¿æ¨¡åï¼(3) å¯è§£éæ§è¢«ç¨æ¼ä¿é²ä¿¡ä»»ï¼ä½å¾å°æç ç©¶å ±åé«å¸«åèè¿´åï¼(4) è¦è¦ºåäºåå¼ä½¿ç¨èä»é¢å°æ¼çè§£ç³»çµ±çè§£éåå»ºè­°æ´æç¨ãéè¦æ´å¤é«çå AI å°å®¶åä½é²è¡ç ç©¶ï¼éæå©æ¼çºé«çé åç XAI è§£æ±ºæ¹æ¡çè¨­è¨ãå¯¦ä½åè©ä¼°æä¾é©ç¶æ¶æ§ã

##### **Exploring the Role of Explainability in AI-Assisted Embryo Selection**
2308.02534v1 by Lucia Urcelay, Daniel Hinjos, Pablo A. Martin-Torres, Marta Gonzalez, Marta Mendez, Salva CÃ­vico, Sergio Ãlvarez-Napagao, Dario Garcia-Gasulla

In Vitro Fertilization is among the most widespread treatments for
infertility. One of its main challenges is the evaluation and selection of
embryo for implantation, a process with large inter- and intra-clinician
variability. Deep learning based methods are gaining attention, but their
opaque nature compromises their acceptance in the clinical context, where
transparency in the decision making is key. In this paper we analyze the
current work in the explainability of AI-assisted embryo analysis models,
identifying the limitations. We also discuss how these models could be
integrated in the clinical context as decision support systems, considering the
needs of clinicians and patients. Finally, we propose guidelines for the sake
of increasing interpretability and trustworthiness, pushing this technology
forward towards established clinical practice.

æè¦ï¼é«å¤åç²¾æ¯æ²»çä¸å­çæå»£æ³çæ¹æ³ä¹ä¸ãå¶ä¸»è¦ææ°ä¹ä¸æ¯è©ä¼°åé¸æèèé²è¡æ¤å¥ï¼æ­¤éç¨å·æå¾å¤§çè¨åºéåè¨åºå§è®ç°æ§ãåºæ¼æ·±åº¦å­¸ç¿çæ¹æ³æ­£åå°éæ³¨ï¼ä½å¶ä¸éæçæ§è³ªæå½±é¿å¶å¨è¨åºç°å¢ä¸­çæ¥ååº¦ï¼èéæåº¦å¨æ±ºç­å¶å®ä¸­è³ééè¦ãå¨æ¬æä¸­ï¼æååæäº AI è¼å©èèåææ¨¡åçå¯è§£éæ§æ¹é¢çç¾æå·¥ä½ï¼ä¸¦æ¾åºå¶å±éæ§ãæåéè¨è«äºå¦ä½å°éäºæ¨¡åä½çºæ±ºç­æ¯æç³»çµ±æ´åå°è¨åºç°å¢ä¸­ï¼åæèæ®è¨åºé«çåæ£èçéæ±ãæå¾ï¼æåæåºäºæé«å¯è§£éæ§åå¯ä¿¡åº¦çæºåï¼æ¨é²éé æè¡æèæ¢å®çè¨åºå¯¦åéé²ã

##### **A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)**
2307.14246v1 by Timo Speith, Markus Langer

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

æè¦ï¼å¨éæ±å·¥ç¨ (RE) é åä¸­ï¼å¯è§£éäººå·¥æºæ§ (XAI) å¨å° AI æ¯æçç³»çµ±èä½¿ç¨èéæ±ãç¤¾æææåæ³è¦æ¨æºç¸ç¬¦æ¹é¢çéè¦æ§æ¥çé¡¯èï¼å·²ç²å¾èªå¯ãä¸è¬ä¾èªªï¼å¯è§£éæ§å·²æçºå½±é¿ç³»çµ±åè³ªçéè¦éåè½éæ±ãç¶èï¼å¯è§£éæ§èæè½ä¹éçåå®æ¬è¡¡ææ°äºå¯è§£éæ§çåå®æ­£é¢å½±é¿ãå¦ææ»¿è¶³å¯è§£éæ§çéæ±éè¦éä½ç³»çµ±æè½ï¼é£éº¼å¿é ä»ç´°èæ®éäºåè³ªé¢åä¸­åªä¸ååªåï¼ä»¥åå¦ä½å¨å®åä¹éé²è¡æè¡·ãå¨æ¬æä¸­ï¼æåæ¹å¤æ§å°æ¢è¨äºéç¨®åå®çæ¬è¡¡ãæåèªçºï¼æå¥½çæ¹æ³æ¯ä»¥ä¸ç¨®ç´°ç·»çæ¹å¼ä¾èçï¼éç¨®æ¹å¼åå«è³æºå¯ç¨æ§ãé åç¹æ§åé¢¨éªèéãééæä¾æªä¾ç ç©¶åæä½³å¯¦åçåºç¤ï¼éé å·¥ä½æ¨å¨æå AI ç RE é åã

##### **Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)**
2307.14239v1 by Barnaby Crook, Maximilian SchlÃ¼ter, Timo Speith

Within the field of Requirements Engineering (RE), the increasing
significance of Explainable Artificial Intelligence (XAI) in aligning
AI-supported systems with user needs, societal expectations, and regulatory
standards has garnered recognition. In general, explainability has emerged as
an important non-functional requirement that impacts system quality. However,
the supposed trade-off between explainability and performance challenges the
presumed positive influence of explainability. If meeting the requirement of
explainability entails a reduction in system performance, then careful
consideration must be given to which of these quality aspects takes precedence
and how to compromise between them. In this paper, we critically examine the
alleged trade-off. We argue that it is best approached in a nuanced way that
incorporates resource availability, domain characteristics, and considerations
of risk. By providing a foundation for future research and best practices, this
work aims to advance the field of RE for AI.

æè¦ï¼å¨éæ±å·¥ç¨ï¼REï¼é¢åï¼å¯è§£éäººå·¥æºè½ï¼XAIï¼å¨å°äººå·¥æºè½æ¯æçç³»ç»ä¸ç¨æ·éæ±ãç¤¾ä¼ææåçç®¡æ åç¸ä¸è´æ¹é¢çéè¦æ§æ¥çå¸æ¾ï¼å¹¶è·å¾äºè®¤å¯ãä¸è¬æ¥è¯´ï¼å¯è§£éæ§å·²æä¸ºå½±åç³»ç»è´¨éçéè¦éåè½æ§éæ±ãç¶èï¼å¯è§£éæ§åæ§è½ä¹é´çæè¡¡ææäºå¯è§£éæ§çæ­£é¢å½±åãå¦ææ»¡è¶³å¯è§£éæ§çè¦æ±éè¦éä½ç³»ç»æ§è½ï¼é£ä¹å¿é¡»ä»ç»èèè¿äºè´¨éæ¹é¢ä¸­çåªä¸ä¸ªä¼åï¼ä»¥åå¦ä½å¨å®ä»¬ä¹é´è¿è¡æè¡¡ãå¨æ¬æä¸­ï¼æä»¬æ¹å¤æ§å°èå¯äºæè°çæè¡¡ãæä»¬è®¤ä¸ºï¼æå¥½ä»¥ä¸ç§ç»è´å¥å¾®çæ¹å¼æ¥å¤çå®ï¼è¿ç§æ¹å¼ç»åäºèµæºå¯ç¨æ§ãé¢åç¹å¾åé£é©èèãéè¿ä¸ºæªæ¥çç ç©¶åæä½³å®è·µæä¾åºç¡ï¼è¿é¡¹å·¥ä½æ¨å¨æ¨è¿äººå·¥æºè½ç RE é¢åã


### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-10-10**|**ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation**|LÃ©o Machado et.al.|[2410.07908v1](http://arxiv.org/abs/2410.07908v1)|null|
|**2024-10-10**|**Offline Inverse Constrained Reinforcement Learning for Safe-Critical Decision Making in Healthcare**|Nan Fang et.al.|[2410.07525v1](http://arxiv.org/abs/2410.07525v1)|null|
|**2024-10-09**|**Unlocking Real-Time Fluorescence Lifetime Imaging: Multi-Pixel Parallelism for FPGA-Accelerated Processing**|Ismail Erbas et.al.|[2410.07364v1](http://arxiv.org/abs/2410.07364v1)|null|
|**2024-10-09**|**Taking a turn for the better: Conversation redirection throughout the course of mental-health therapy**|Vivian Nguyen et.al.|[2410.07147v1](http://arxiv.org/abs/2410.07147v1)|null|
|**2024-10-09**|**Mental Disorders Detection in the Era of Large Language Models**|Gleb Kuzmin et.al.|[2410.07129v1](http://arxiv.org/abs/2410.07129v1)|null|
|**2024-10-09**|**MentalArena: Self-play Training of Language Models for Diagnosis and Treatment of Mental Health Disorders**|Cheng Li et.al.|[2410.06845v1](http://arxiv.org/abs/2410.06845v1)|[link](https://github.com/scarelette/mentalarena)|
|**2024-10-09**|**An Improved Approach for Cardiac MRI Segmentation based on 3D UNet Combined with Papillary Muscle Exclusion**|Narjes Benameur et.al.|[2410.06818v1](http://arxiv.org/abs/2410.06818v1)|null|
|**2024-10-09**|**Deep Learning for Surgical Instrument Recognition and Segmentation in Robotic-Assisted Surgeries: A Systematic Review**|Fatimaelzahraa Ali Ahmed et.al.|[2410.07269v1](http://arxiv.org/abs/2410.07269v1)|null|
|**2024-10-08**|**Multimodal Representation Learning using Adaptive Graph Construction**|Weichen Huang et.al.|[2410.06395v1](http://arxiv.org/abs/2410.06395v1)|null|
|**2024-10-08**|**Skin Cancer Machine Learning Model Tone Bias**|James Pope et.al.|[2410.06385v1](http://arxiv.org/abs/2410.06385v1)|null|
|**2024-10-08**|**HumVI: A Multilingual Dataset for Detecting Violent Incidents Impacting Humanitarian Aid**|Hemank Lamba et.al.|[2410.06370v1](http://arxiv.org/abs/2410.06370v1)|[link](https://github.com/dataminr-ai/humvi-dataset)|
|**2024-10-08**|**A Comparative Study of Hybrid Models in Health Misinformation Text Classification**|Mkululi Sikosana et.al.|[2410.06311v1](http://arxiv.org/abs/2410.06311v1)|null|
|**2024-10-08**|**KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server**|Wenhao Wang et.al.|[2410.05725v2](http://arxiv.org/abs/2410.05725v2)|[link](https://github.com/wwh0411/knowledgesg)|
|**2024-10-08**|**Copiloting Diagnosis of Autism in Real Clinical Scenarios via LLMs**|Yi Jiang et.al.|[2410.05684v2](http://arxiv.org/abs/2410.05684v2)|null|
|**2024-10-08**|**NegMerge: Consensual Weight Negation for Strong Machine Unlearning**|Hyoseo Kim et.al.|[2410.05583v1](http://arxiv.org/abs/2410.05583v1)|[link](https://github.com/naver-ai/negmerge)|
|**2024-10-07**|**AI-Driven Early Mental Health Screening with Limited Data: Analyzing Selfies of Pregnant Women**|Gustavo A. BasÃ­lio et.al.|[2410.05450v1](http://arxiv.org/abs/2410.05450v1)|null|
|**2024-10-07**|**Improving Predictor Reliability with Selective Recalibration**|Thomas P. Zollo et.al.|[2410.05407v1](http://arxiv.org/abs/2410.05407v1)|null|
|**2024-10-07**|**CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**|Ekaterina Sviridova et.al.|[2410.05235v2](http://arxiv.org/abs/2410.05235v2)|null|
|**2024-10-07**|**RespLLM: Unifying Audio and Text with Multimodal LLMs for Generalized Respiratory Health Prediction**|Yuwei Zhang et.al.|[2410.05361v1](http://arxiv.org/abs/2410.05361v1)|null|
|**2024-10-07**|**Synthetic Generation of Dermatoscopic Images with GAN and Closed-Form Factorization**|Rohan Reddy Mekala et.al.|[2410.05114v1](http://arxiv.org/abs/2410.05114v1)|null|
|**2024-10-07**|**Named Clinical Entity Recognition Benchmark**|Wadood M Abdul et.al.|[2410.05046v1](http://arxiv.org/abs/2410.05046v1)|[link](https://github.com/wadoodabdul/clinical_ner_benchmark)|
|**2024-10-07**|**Learning Interpretable Hierarchical Dynamical Systems Models from Time Series Data**|Manuel Brenner et.al.|[2410.04814v1](http://arxiv.org/abs/2410.04814v1)|null|
|**2024-10-07**|**$\textbf{Only-IF}$:Revealing the Decisive Effect of Instruction Diversity on Generalization**|Dylan Zhang et.al.|[2410.04717v1](http://arxiv.org/abs/2410.04717v1)|null|
|**2024-10-07**|**Rule-based Data Selection for Large Language Models**|Xiaomin Li et.al.|[2410.04715v1](http://arxiv.org/abs/2410.04715v1)|null|
|**2024-10-07**|**Knowledge Graph Based Agent for Complex, Knowledge-Intensive QA in Medicine**|Xiaorui Su et.al.|[2410.04660v1](http://arxiv.org/abs/2410.04660v1)|null|
|**2024-10-06**|**Multi-Tiered Self-Contrastive Learning for Medical Microwave Radiometry (MWR) Breast Cancer Detection**|Christoforos Galazis et.al.|[2410.04636v1](http://arxiv.org/abs/2410.04636v1)|[link](https://github.com/cgalaz01/self_contrastive_mwr)|
|**2024-10-06**|**Semi-Markovian Planning to Coordinate Aerial and Maritime Medical Evacuation Platforms**|Mahdi Al-Husseini et.al.|[2410.04523v1](http://arxiv.org/abs/2410.04523v1)|null|
|**2024-10-06**|**RespDiff: An End-to-End Multi-scale RNN Diffusion Model for Respiratory Waveform Estimation from PPG Signals**|Yuyang Miao et.al.|[2410.04366v1](http://arxiv.org/abs/2410.04366v1)|null|
|**2024-10-05**|**Applying Quantum Autoencoders for Time Series Anomaly Detection**|Robin Frehner et.al.|[2410.04154v2](http://arxiv.org/abs/2410.04154v2)|null|
|**2024-10-05**|**DAMMI:Daily Activities in a Psychologically Annotated Multi-Modal IoT dataset**|Mohsen Falah Rad et.al.|[2410.04152v1](http://arxiv.org/abs/2410.04152v1)|null|
|**2024-10-05**|**From Hospital to Portables: A Universal ECG Foundation Model Built on 10+ Million Diverse Recordings**|Jun Li et.al.|[2410.04133v1](http://arxiv.org/abs/2410.04133v1)|null|
|**2024-10-05**|**Taming the Tail: Leveraging Asymmetric Loss and Pade Approximation to Overcome Medical Image Long-Tailed Class Imbalance**|Pankhi Kashyap et.al.|[2410.04084v1](http://arxiv.org/abs/2410.04084v1)|null|
|**2024-10-04**|**Still Not Quite There! Evaluating Large Language Models for Comorbid Mental Health Diagnosis**|Amey Hengle et.al.|[2410.03908v1](http://arxiv.org/abs/2410.03908v1)|null|
|**2024-10-04**|**Not All Diffusion Model Activations Have Been Evaluated as Discriminative Features**|Benyuan Meng et.al.|[2410.03558v2](http://arxiv.org/abs/2410.03558v2)|[link](https://github.com/darkbblue/generic-diffusion-feature)|
|**2024-10-04**|**Towards Real-time Intrahepatic Vessel Identification in Intraoperative Ultrasound-Guided Liver Surgery**|Karl-Philippe Beaudet et.al.|[2410.03420v2](http://arxiv.org/abs/2410.03420v2)|null|
|**2024-10-04**|**Make Interval Bound Propagation great again**|Patryk Krukowski et.al.|[2410.03373v1](http://arxiv.org/abs/2410.03373v1)|[link](https://github.com/gmum/make-interval-bound-propagation-great-again)|
|**2024-10-04**|**An Enhanced Harmonic Densely Connected Hybrid Transformer Network Architecture for Chronic Wound Segmentation Utilising Multi-Colour Space Tensor Merging**|Bill Cassidy et.al.|[2410.03359v1](http://arxiv.org/abs/2410.03359v1)|null|
|**2024-10-04**|**Comparative Analysis and Ensemble Enhancement of Leading CNN Architectures for Breast Cancer Classification**|Gary Murphy et.al.|[2410.03333v1](http://arxiv.org/abs/2410.03333v1)|null|
|**2024-10-04**|**Manikin-Recorded Cardiopulmonary Sounds Dataset Using Digital Stethoscope**|Yasaman Torabi et.al.|[2410.03280v1](http://arxiv.org/abs/2410.03280v1)|[link](https://github.com/torabiy/hls-cmds)|
|**2024-10-04**|**Looking into Concept Explanation Methods for Diabetic Retinopathy Classification**|Andrea M. StorÃ¥s et.al.|[2410.03188v1](http://arxiv.org/abs/2410.03188v1)|[link](https://github.com/andreastoraas/conceptexplanations_dr_grading)|
|**2024-10-04**|**Remaining Useful Life Prediction: A Study on Multidimensional Industrial Signal Processing and Efficient Transfer Learning Based on Large Language Models**|Yan Chen et.al.|[2410.03134v1](http://arxiv.org/abs/2410.03134v1)|null|
|**2024-10-04**|**Image First or Text First? Optimising the Sequencing of Modalities in Large Language Model Prompting and Reasoning Tasks**|Grant Wardle et.al.|[2410.03062v1](http://arxiv.org/abs/2410.03062v1)|null|
|**2024-10-03**|**Is Your Paper Being Reviewed by an LLM? Investigating AI Text Detectability in Peer Review**|Sungduk Yu et.al.|[2410.03019v1](http://arxiv.org/abs/2410.03019v1)|null|
|**2024-10-03**|**DailyDilemmas: Revealing Value Preferences of LLMs with Quandaries of Daily Life**|Yu Ying Chiu et.al.|[2410.02683v1](http://arxiv.org/abs/2410.02683v1)|null|
|**2024-10-03**|**Plots Unlock Time-Series Understanding in Multimodal Models**|Mayank Daswani et.al.|[2410.02637v1](http://arxiv.org/abs/2410.02637v1)|null|
|**2024-10-03**|**IC3M: In-Car Multimodal Multi-object Monitoring for Abnormal Status of Both Driver and Passengers**|Zihan Fang et.al.|[2410.02592v3](http://arxiv.org/abs/2410.02592v3)|null|
|**2024-10-03**|**Deep Regression 2D-3D Ultrasound Registration for Liver Motion Correction in Focal Tumor Thermal Ablation**|Shuwei Xing et.al.|[2410.02579v1](http://arxiv.org/abs/2410.02579v1)|[link](https://github.com/xingorno/deepregs2v)|
|**2024-10-03**|**ColaCare: Enhancing Electronic Health Record Modeling through Large Language Model-Driven Multi-Agent Collaboration**|Zixiang Wang et.al.|[2410.02551v1](http://arxiv.org/abs/2410.02551v1)|null|
|**2024-10-03**|**SAFLEX: Self-Adaptive Augmentation via Feature Label Extrapolation**|Mucong Ding et.al.|[2410.02512v1](http://arxiv.org/abs/2410.02512v1)|null|
|**2024-10-03**|**Clinnova Federated Learning Proof of Concept: Key Takeaways from a Cross-border Collaboration**|Julia Alekseenko et.al.|[2410.02443v1](http://arxiv.org/abs/2410.02443v1)|null|
|**2024-10-03**|**A Comprehensive Survey of Mamba Architectures for Medical Image Analysis: Classification, Segmentation, Restoration and Beyond**|Shubhi Bansal et.al.|[2410.02362v1](http://arxiv.org/abs/2410.02362v1)|[link](https://github.com/madhavaprasath23/awesome-mamba-papers-on-medical-domain)|
|**2024-10-03**|**CTARR: A fast and robust method for identifying anatomical regions on CT images via atlas registration**|Thomas Buddenkotte et.al.|[2410.02316v1](http://arxiv.org/abs/2410.02316v1)|[link](https://github.com/thomasbudd/ctarr)|
|**2024-10-02**|**Multi-Omic and Quantum Machine Learning Integration for Lung Subtypes Classification**|Mandeep Kaur Saggi et.al.|[2410.02085v1](http://arxiv.org/abs/2410.02085v1)|null|
|**2024-10-02**|**Zodiac: A Cardiologist-Level LLM Framework for Multi-Agent Diagnostics**|Yuan Zhou et.al.|[2410.02026v1](http://arxiv.org/abs/2410.02026v1)|null|
|**2024-10-02**|**UlcerGPT: A Multimodal Approach Leveraging Large Language and Vision Models for Diabetic Foot Ulcer Image Transcription**|Reza Basiri et.al.|[2410.01989v1](http://arxiv.org/abs/2410.01989v1)|null|
|**2024-10-02**|**A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model**|Xueshen Li et.al.|[2410.03770v1](http://arxiv.org/abs/2410.03770v1)|null|
|**2024-10-02**|**DeFine: Enhancing LLM Decision-Making with Factor Profiles and Analogical Reasoning**|Yebowen Hu et.al.|[2410.01772v1](http://arxiv.org/abs/2410.01772v1)|null|
|**2024-10-02**|**Towards a vision foundation model for comprehensive assessment of Cardiac MRI**|Athira J Jacob et.al.|[2410.01665v2](http://arxiv.org/abs/2410.01665v2)|null|
|**2024-10-02**|**Imaging foundation model for universal enhancement of non-ideal measurement CT**|Yuxin Liu et.al.|[2410.01591v1](http://arxiv.org/abs/2410.01591v1)|[link](https://github.com/yutinghe-list/tamp)|
|**2024-10-02**|**OpenMathInstruct-2: Accelerating AI for Math with Massive Open-Source Instruction Data**|Shubham Toshniwal et.al.|[2410.01560v2](http://arxiv.org/abs/2410.01560v2)|[link](https://github.com/kipok/nemo-skills)|
|**2024-10-02**|**MedQA-CS: Benchmarking Large Language Models Clinical Skills Using an AI-SCE Framework**|Zonghai Yao et.al.|[2410.01553v1](http://arxiv.org/abs/2410.01553v1)|[link](https://github.com/bio-nlp/medqa-cs)|
|**2024-10-02**|**On the Convergence of FedProx with Extrapolation and Inexact Prox**|Hanmin Li et.al.|[2410.01410v1](http://arxiv.org/abs/2410.01410v1)|null|
|**2024-10-02**|**See Me and Believe Me: Causality and Intersectionality in Testimonial Injustice in Healthcare**|Kenya S. Andrews et.al.|[2410.01227v1](http://arxiv.org/abs/2410.01227v1)|null|
|**2024-10-01**|**Explainable Diagnosis Prediction through Neuro-Symbolic Integration**|Qiuhao Lu et.al.|[2410.01855v1](http://arxiv.org/abs/2410.01855v1)|null|
|**2024-10-01**|**Heterogeneous sound classification with the Broad Sound Taxonomy and Dataset**|Panagiota Anastasopoulou et.al.|[2410.00980v1](http://arxiv.org/abs/2410.00980v1)|[link](https://github.com/allholy/bsd10k)|
|**2024-10-01**|**The Gradient of Health Data Privacy**|Baihan Lin et.al.|[2410.00897v1](http://arxiv.org/abs/2410.00897v1)|null|
|**2024-10-01**|**GAMMA-PD: Graph-based Analysis of Multi-Modal Motor Impairment Assessments in Parkinson's Disease**|Favour Nerrise et.al.|[2410.00944v1](http://arxiv.org/abs/2410.00944v1)|null|
|**2024-10-01**|**Contrastive Abstraction for Reinforcement Learning**|Vihang Patil et.al.|[2410.00704v1](http://arxiv.org/abs/2410.00704v1)|null|
|**2024-10-01**|**Arges: Spatio-Temporal Transformer for Ulcerative Colitis Severity Assessment in Endoscopy Videos**|Krishna Chaitanya et.al.|[2410.00536v1](http://arxiv.org/abs/2410.00536v1)|null|
|**2024-10-01**|**Bayes-CATSI: A variational Bayesian deep learning framework for medical time series data imputation**|Omkar Kulkarni et.al.|[2410.01847v2](http://arxiv.org/abs/2410.01847v2)|[link](https://github.com/pingala-institute/Bayes-medicaldataimputation)|
|**2024-10-01**|**ReXplain: Translating Radiology into Patient-Friendly Video Reports**|Luyang Luo et.al.|[2410.00441v1](http://arxiv.org/abs/2410.00441v1)|null|
|**2024-10-01**|**Towards Democratization of Subspeciality Medical Expertise**|Jack W. O'Sullivan et.al.|[2410.03741v1](http://arxiv.org/abs/2410.03741v1)|null|
|**2024-10-01**|**CXPMRG-Bench: Pre-training and Benchmarking for X-ray Medical Report Generation on CheXpert Plus Dataset**|Xiao Wang et.al.|[2410.00379v1](http://arxiv.org/abs/2410.00379v1)|[link](https://github.com/event-ahu/medical_image_analysis)|
|**2024-10-01**|**Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**|Prasenjit Maji et.al.|[2410.00366v1](http://arxiv.org/abs/2410.00366v1)|null|
|**2024-09-30**|**The age of spiritual machines: Language quietus induces synthetic altered states of consciousness in artificial intelligence**|Jeremy I Skipper et.al.|[2410.00257v1](http://arxiv.org/abs/2410.00257v1)|null|
|**2024-09-30**|**CliMB: An AI-enabled Partner for Clinical Predictive Modeling**|Evgeny Saveliev et.al.|[2410.03736v1](http://arxiv.org/abs/2410.03736v1)|null|
|**2024-09-30**|**Adapting LLMs for the Medical Domain in Portuguese: A Study on Fine-Tuning and Model Evaluation**|Pedro Henrique Paiola et.al.|[2410.00163v1](http://arxiv.org/abs/2410.00163v1)|null|
|**2024-09-30**|**The Perfect Blend: Redefining RLHF with Mixture of Judges**|Tengyu Xu et.al.|[2409.20370v1](http://arxiv.org/abs/2409.20370v1)|null|
|**2024-09-30**|**Forecasting Disease Progression with Parallel Hyperplanes in Longitudinal Retinal OCT**|Arunava Chakravarty et.al.|[2409.20195v2](http://arxiv.org/abs/2409.20195v2)|[link](https://github.com/arunava555/Forecast_parallel_hyperplanes)|
|**2024-09-30**|**Classification of Radiological Text in Small and Imbalanced Datasets in a Non-English Language**|Vincent Beliveau et.al.|[2409.20147v1](http://arxiv.org/abs/2409.20147v1)|[link](https://github.com/vbeliveau/radiology-text-classification)|
|**2024-09-30**|**Positive-Sum Fairness: Leveraging Demographic Attributes to Achieve Fair AI Outcomes Without Sacrificing Group Gains**|Samia Belhadj et.al.|[2409.19940v1](http://arxiv.org/abs/2409.19940v1)|null|
|**2024-09-29**|**InfantCryNet: A Data-driven Framework for Intelligent Analysis of Infant Cries**|Mengze Hong et.al.|[2409.19689v1](http://arxiv.org/abs/2409.19689v1)|null|
|**2024-09-29**|**See Detail Say Clear: Towards Brain CT Report Generation via Pathological Clue-driven Representation Learning**|Chengxin Zheng et.al.|[2409.19676v2](http://arxiv.org/abs/2409.19676v2)|[link](https://github.com/chauncey-jheng/pcrl-mrg)|
|**2024-09-29**|**Assessment and manipulation of latent constructs in pre-trained language models using psychometric scales**|Maor Reuben et.al.|[2409.19655v1](http://arxiv.org/abs/2409.19655v1)|[link](https://github.com/cnai-lab/qlatent)|
|**2024-09-29**|**A Survey on Graph Neural Networks for Remaining Useful Life Prediction: Methodologies, Evaluation and Future Trends**|Yucheng Wang et.al.|[2409.19629v1](http://arxiv.org/abs/2409.19629v1)|[link](https://github.com/Frank-Wang-oss/GNN_RUL_Benchmarking)|
|**2024-09-29**|**MCDDPM: Multichannel Conditional Denoising Diffusion Model for Unsupervised Anomaly Detection in Brain MRI**|Vivek Kumar Trivedi et.al.|[2409.19623v1](http://arxiv.org/abs/2409.19623v1)|[link](https://github.com/vivekkumartri/mcddpm)|
|**2024-09-29**|**Understanding Clinical Decision-Making in Traditional East Asian Medicine through Dimensionality Reduction: An Empirical Investigation**|Hyojin Bae et.al.|[2409.19531v1](http://arxiv.org/abs/2409.19531v1)|null|
|**2024-09-29**|**MedHalu: Hallucinations in Responses to Healthcare Queries by Large Language Models**|Vibhor Agarwal et.al.|[2409.19492v1](http://arxiv.org/abs/2409.19492v1)|null|
|**2024-09-28**|**INSIGHTBUDDY-AI: Medication Extraction and Entity Linking using Large Language Models and Ensemble Learning**|Pablo Romero et.al.|[2409.19467v1](http://arxiv.org/abs/2409.19467v1)|null|
|**2024-09-28**|**Mind the Gap: Promoting Missing Modality Brain Tumor Segmentation with Alignment**|Tianyi Liu et.al.|[2409.19366v1](http://arxiv.org/abs/2409.19366v1)|null|
|**2024-09-28**|**3D-CT-GPT: Generating 3D Radiology Reports through Integration of Large Vision-Language Models**|Hao Chen et.al.|[2409.19330v1](http://arxiv.org/abs/2409.19330v1)|null|
|**2024-09-28**|**Epidemiology-Aware Neural ODE with Continuous Disease Transmission Graph**|Guancheng Wan et.al.|[2410.00049v1](http://arxiv.org/abs/2410.00049v1)|[link](https://github.com/emory-melody/epilearn)|
|**2024-09-27**|**A GEN AI Framework for Medical Note Generation**|Hui Yi Leong et.al.|[2410.01841v1](http://arxiv.org/abs/2410.01841v1)|null|
|**2024-09-27**|**Secure Multiparty Generative AI**|Manil Shrestha et.al.|[2409.19120v1](http://arxiv.org/abs/2409.19120v1)|null|
|**2024-09-27**|**Differential privacy for protecting patient data in speech disorder detection using deep learning**|Soroosh Tayebi Arasteh et.al.|[2409.19078v1](http://arxiv.org/abs/2409.19078v1)|null|
|**2024-09-27**|**AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow**|Huizi Yu et.al.|[2409.18924v2](http://arxiv.org/abs/2409.18924v2)|null|
|**2024-09-27**|**Suicide Phenotyping from Clinical Notes in Safety-Net Psychiatric Hospital Using Multi-Label Classification with Pre-Trained Language Models**|Zehan Li et.al.|[2409.18878v2](http://arxiv.org/abs/2409.18878v2)|null|
|**2024-09-27**|**Early diagnosis of Alzheimer's disease from MRI images with deep learning model**|Sajjad Aghasi Javid et.al.|[2409.18814v1](http://arxiv.org/abs/2409.18814v1)|null|
|**2024-09-27**|**State-of-the-Art Periorbital Distance Prediction and Disease Classification Using Periorbital Features**|George R. Nahass et.al.|[2409.18769v2](http://arxiv.org/abs/2409.18769v2)|null|
|**2024-09-27**|**Multi-modal Medical Image Fusion For Non-Small Cell Lung Cancer Classification**|Salma Hassan et.al.|[2409.18715v1](http://arxiv.org/abs/2409.18715v1)|null|

#### Abstracts
##### **ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation**
2410.07908v1 by LÃ©o Machado, HÃ©lÃ¨ne Philippe, Ãlodie Ferreres, Julien Khlaut, Julie Dupuis, Korentin Le Floch, Denis Habip Gatenyo, Pascal Roux, Jules GrÃ©gory, Maxime Ronot, Corentin Dancette, Daniel Tordjman, Pierre Manceron, Paul HÃ©rent

Carcinogenesis is a proteiform phenomenon, with tumors emerging in various
locations and displaying complex, diverse shapes. At the crucial intersection
of research and clinical practice, it demands precise and flexible assessment.
However, current biomarkers, such as RECIST 1.1's long and short axis
measurements, fall short of capturing this complexity, offering an approximate
estimate of tumor burden and a simplistic representation of a more intricate
process. Additionally, existing supervised AI models face challenges in
addressing the variability in tumor presentations, limiting their clinical
utility. These limitations arise from the scarcity of annotations and the
models' focus on narrowly defined tasks.
  To address these challenges, we developed ONCOPILOT, an interactive
radiological foundation model trained on approximately 7,500 CT scans covering
the whole body, from both normal anatomy and a wide range of oncological cases.
ONCOPILOT performs 3D tumor segmentation using visual prompts like point-click
and bounding boxes, outperforming state-of-the-art models (e.g., nnUnet) and
achieving radiologist-level accuracy in RECIST 1.1 measurements. The key
advantage of this foundation model is its ability to surpass state-of-the-art
performance while keeping the radiologist in the loop, a capability that
previous models could not achieve. When radiologists interactively refine the
segmentations, accuracy improves further. ONCOPILOT also accelerates
measurement processes and reduces inter-reader variability, facilitating
volumetric analysis and unlocking new biomarkers for deeper insights.
  This AI assistant is expected to enhance the precision of RECIST 1.1
measurements, unlock the potential of volumetric biomarkers, and improve
patient stratification and clinical care, while seamlessly integrating into the
radiological workflow.

æè¦ï¼<paragraph>è´çä½ç¨æ¯ä¸ç¨®è®å½¢ç¾è±¡ï¼è«ç¤åºç¾å¨åç¨®ä½ç½®ï¼ä¸¦åç¾åºè¤éå¤æ¨£çå½¢çãå¨ç ç©¶åè¨åºå¯¦åçéè¦äº¤æé»ï¼å®éè¦ç²¾ç¢ºä¸å½æ§çè©ä¼°ãç¶èï¼ç®åççç©æ¨è¨ï¼ä¾å¦ RECIST 1.1 çé·è»¸åç­è»¸æ¸¬éï¼ä¸¦ç¡æ³ææå°éç¨®è¤éæ§ï¼åªè½æä¾è«ç¤è² æçè¿ä¼¼ä¼°è¨ï¼ä»¥åå°æ´è¤ééç¨çç°¡åè¡¨ç¤ºãæ­¤å¤ï¼ç¾æçç£ç£å¼ AI æ¨¡åå¨èçè«ç¤è¡¨ç¾çå¯è®æ§æé¢è¨ææ°ï¼éå¶äºå®åçè¨åºæç¨ãéäºéå¶ä¾èªæ¼è¨»è§£çç¨å°æ§ï¼ä»¥åæ¨¡åå°æ³¨æ¼ç¹ç¾©å®ç¾©çä»»åã
çºäºæå°éäºææ°ï¼æåéç¼äº ONCOPILOTï¼éæ¯ä¸åäºåå¼æ¾å°å­¸åºç¤æ¨¡åï¼è¨ç·´æ¼æ¶µèå¨èº«çç´ 7,500 åé»è¦æ·å±¤ææï¼åæ¬æ­£å¸¸è§£åçµæ§åå»£æ³çè«ç¤çä¾ãONCOPILOT ä½¿ç¨è¦è¦ºæç¤ºï¼ä¾å¦é»é¸åéçæ¡ï¼å·è¡ 3D è«ç¤åå²ï¼åªæ¼æåé²çæ¨¡åï¼ä¾å¦ nnUnetï¼ï¼ä¸¦å¨ RECIST 1.1 æ¸¬éä¸­éå°æ¾å°ç§é«å¸«ç­ç´çæºç¢ºåº¦ãéååºç¤æ¨¡åçä¸»è¦åªé»æ¯å®è½å¤ è¶è¶æåé²çæè½ï¼åæè®æ¾å°ç§é«å¸«åèå¶ä¸­ï¼éæ¯ä»¥åçæ¨¡åç¡æ³éå°çåè½ãç¶æ¾å°ç§é«å¸«äºåå¼å°åªååå²æï¼æºç¢ºåº¦æé²ä¸æ­¥æé«ãONCOPILOT éå éäºæ¸¬ééç¨ï¼ä¸¦æ¸å°äºè®èéçè®ç°æ§ï¼ä¿è¿äºé«ç©åæï¼ä¸¦è§£éäºæ°ççç©æ¨è¨ï¼ä»¥ç²å¾æ´æ·±å¥çè¦è§£ã
é è¨éå AI å©çå°æé« RECIST 1.1 æ¸¬éçæºç¢ºåº¦ï¼éæ¾é«ç©çç©æ¨è¨çæ½åï¼ä¸¦æ¹åæ£èåå±¤åè¨åºç§è­·ï¼åæç¡ç¸«æ´åå°æ¾å°å­¸å·¥ä½æµç¨ä¸­ã</paragraph>

##### **Offline Inverse Constrained Reinforcement Learning for Safe-Critical Decision Making in Healthcare**
2410.07525v1 by Nan Fang, Guiliang Liu, Wei Gong

Reinforcement Learning (RL) applied in healthcare can lead to unsafe medical
decisions and treatment, such as excessive dosages or abrupt changes, often due
to agents overlooking common-sense constraints. Consequently, Constrained
Reinforcement Learning (CRL) is a natural choice for safe decisions. However,
specifying the exact cost function is inherently difficult in healthcare.
Recent Inverse Constrained Reinforcement Learning (ICRL) is a promising
approach that infers constraints from expert demonstrations. ICRL algorithms
model Markovian decisions in an interactive environment. These settings do not
align with the practical requirement of a decision-making system in healthcare,
where decisions rely on historical treatment recorded in an offline dataset. To
tackle these issues, we propose the Constraint Transformer (CT). Specifically,
1) we utilize a causal attention mechanism to incorporate historical decisions
and observations into the constraint modeling, while employing a Non-Markovian
layer for weighted constraints to capture critical states. 2) A generative
world model is used to perform exploratory data augmentation, enabling offline
RL methods to simulate unsafe decision sequences. In multiple medical
scenarios, empirical results demonstrate that CT can capture unsafe states and
achieve strategies that approximate lower mortality rates, reducing the
occurrence probability of unsafe behaviors.

æè¦ï¼å¼·åå­¸ç¿ (RL) æç¨æ¼é«çä¿å¥å¯è½æå°è´ä¸å®å¨çé«çæ±ºç­åæ²»çï¼ä¾å¦ééåéæçªç¶è®åï¼ééå¸¸æ¯å çºä»£çå¿½ç¥äºå¸¸è­ç´æãå æ­¤ï¼ç´æå¼·åå­¸ç¿ (CRL) æ¯å®å¨æ±ºç­çèªç¶é¸æãç¶èï¼å¨é«çä¿å¥ä¸­æç¢ºæå®ç¢ºåçææ¬å½æ¸æ¬è³ªä¸æ¯å°é£çãæè¿çéç´æå¼·åå­¸ç¿ (ICRL) æ¯ä¸ç¨®æåéçæ¹æ³ï¼å®å¾å°å®¶ç¤ºç¯ä¸­æ¨æ·åºç´æãICRL æ¼ç®æ³å¨äºåç°å¢ä¸­å°é¦¬å¯å¤«æ±ºç­é²è¡å»ºæ¨¡ãéäºè¨­å®èé«çä¿å¥ä¸­æ±ºç­ç³»çµ±çå¯¦ééæ±ä¸ç¬¦ï¼å¨é«çä¿å¥ä¸­ï¼æ±ºç­ä¾è³´æ¼é¢ç·è³æéä¸­è¨éçæ­·å²æ²»çãçºäºè§£æ±ºéäºåé¡ï¼æåæåºäºç´æè½æå¨ (CT)ãå·é«ä¾èªªï¼1) æåå©ç¨å ææ³¨ææ©å¶å°æ­·å²æ±ºç­åè§å¯ç´å¥ç´æå»ºæ¨¡ï¼åææ¡ç¨éé¦¬å¯å¤«å±¤ä¾å°å æ¬ç´æé²è¡å»ºæ¨¡ï¼ä»¥ææééµçæã2) çæå¼ä¸çæ¨¡åç¨æ¼å·è¡æ¢ç´¢æ§è³ææ´åï¼ä½¿é¢ç· RL æ¹æ³è½å¤ æ¨¡æ¬ä¸å®å¨çæ±ºç­åºåãå¨å¤ç¨®é«çå ´æ¯ä¸­ï¼å¯¦è­çµæè¡¨æï¼CT è½å¤ ææä¸å®å¨ççæï¼ä¸¦å¶å®åºè¿ä¼¼æ¼è¼ä½æ­»äº¡ççç­ç¥ï¼å¾èéä½ä¸å®å¨è¡çºç¼ççæ©çã

##### **Unlocking Real-Time Fluorescence Lifetime Imaging: Multi-Pixel Parallelism for FPGA-Accelerated Processing**
2410.07364v1 by Ismail Erbas, Aporva Amarnath, Vikas Pandey, Karthik Swaminathan, Naigang Wang, Xavier Intes

Fluorescence lifetime imaging (FLI) is a widely used technique in the
biomedical field for measuring the decay times of fluorescent molecules,
providing insights into metabolic states, protein interactions, and
ligand-receptor bindings. However, its broader application in fast biological
processes, such as dynamic activity monitoring, and clinical use, such as in
guided surgery, is limited by long data acquisition times and computationally
demanding data processing. While deep learning has reduced post-processing
times, time-resolved data acquisition remains a bottleneck for real-time
applications. To address this, we propose a method to achieve real-time FLI
using an FPGA-based hardware accelerator. Specifically, we implemented a
GRU-based sequence-to-sequence (Seq2Seq) model on an FPGA board compatible with
time-resolved cameras. The GRU model balances accurate processing with the
resource constraints of FPGAs, which have limited DSP units and BRAM. The
limited memory and computational resources on the FPGA require efficient
scheduling of operations and memory allocation to deploy deep learning models
for low-latency applications. We address these challenges by using STOMP, a
queue-based discrete-event simulator that automates and optimizes task
scheduling and memory management on hardware. By integrating a GRU-based
Seq2Seq model and its compressed version, called Seq2SeqLite, generated through
knowledge distillation, we were able to process multiple pixels in parallel,
reducing latency compared to sequential processing. We explore various levels
of parallelism to achieve an optimal balance between performance and resource
utilization. Our results indicate that the proposed techniques achieved a 17.7x
and 52.0x speedup over manual scheduling for the Seq2Seq model and the
Seq2SeqLite model, respectively.

æè¦ï¼è¢åçå½é±æå½±å (FLI) æ¯çç©é«å­¸é åä¸­å»£æ³ä½¿ç¨çæè¡ï¼ç¨æ¼æ¸¬éè¢ååå­çè¡°è®æéï¼æä¾ä»£è¬çæãèç½è³ªäº¤äºä½ç¨åéé«åé«çµåçè¦è§£ãç¶èï¼å¶å¨å¿«éçç©éç¨ï¼ä¾å¦åææ´»åç£æ¸¬ï¼åè¨åºç¨éï¼ä¾å¦å¼å°å¼æè¡ï¼ä¸­çå»£æ³æç¨åå°é·æéè³ææ·ååè¨ç®éæ±é«çè³æèççéå¶ãåç®¡æ·±åº¦å­¸ç¿æ¸å°äºå¾èçæéï¼ä½æéè§£æè³ææ·åä»ç¶æ¯å³ææç¨ç¨å¼çç¶é ¸ãçºäºè§£æ±ºéååé¡ï¼æåæåºäºä¸ç¨®ä½¿ç¨åºæ¼ FPGA çç¡¬é«å éå¨ä¾å¯¦ç¾å³æ FLI çæ¹æ³ãå·é«ä¾èªªï¼æåå¨èæéè§£æç¸æ©ç¸å®¹ç FPGA æ¿ä¸å¯¦ä½äºåºæ¼ GRU çåºåå°åºå (Seq2Seq) æ¨¡åãGRU æ¨¡åå¹³è¡¡äºæºç¢ºçèçè FPGA çè³æºéå¶ï¼FPGA ç DSP å®åå BRAM æéãFPGA ä¸æéçè¨æ¶é«åè¨ç®è³æºéè¦ææå°æç¨ä½æ¥­åè¨æ¶é«éç½®ï¼æè½é¨ç½²æ·±åº¦å­¸ç¿æ¨¡åä»¥é²è¡ä½å»¶é²æç¨ç¨å¼ãæåééä½¿ç¨ STOMP ä¾è§£æ±ºéäºææ°ï¼éæ¯ä¸ååºæ¼ä½åçé¢æ£äºä»¶æ¨¡æ¬å¨ï¼å¯èªåååæä½³åç¡¬é«ä¸çä»»åæç¨åè¨æ¶é«ç®¡çãééæ´ååºæ¼ GRU ç Seq2Seq æ¨¡ååå¶å£ç¸®çæ¬ Seq2SeqLiteï¼ééç¥è­èåç¢çï¼ï¼æåè½å¤ å¹³è¡èçå¤ååç´ ï¼èé åºèçç¸æ¯ï¼å¯æ¸å°å»¶é²ãæåæ¢ç´¢äºåç¨®å¹³è¡å±¤ç´ï¼ä»¥å¨æè½åè³æºå©ç¨çä¹éåå¾æä½³å¹³è¡¡ãæåççµæè¡¨æï¼è Seq2Seq æ¨¡åå Seq2SeqLite æ¨¡åçæåæç¨ç¸æ¯ï¼ææåºçæè¡åå¥éå°äº 17.7 åå 52.0 åçå éã

##### **Taking a turn for the better: Conversation redirection throughout the course of mental-health therapy**
2410.07147v1 by Vivian Nguyen, Sang Min Jung, Lillian Lee, Thomas D. Hull, Cristian Danescu-Niculescu-Mizil

Mental-health therapy involves a complex conversation flow in which patients
and therapists continuously negotiate what should be talked about next. For
example, therapists might try to shift the conversation's direction to keep the
therapeutic process on track and avoid stagnation, or patients might push the
discussion towards issues they want to focus on.
  How do such patient and therapist redirections relate to the development and
quality of their relationship? To answer this question, we introduce a
probabilistic measure of the extent to which a certain utterance immediately
redirects the flow of the conversation, accounting for both the intention and
the actual realization of such a change. We apply this new measure to
characterize the development of patient-therapist relationships over multiple
sessions in a very large, widely-used online therapy platform. Our analysis
reveals that (1) patient control of the conversation's direction generally
increases relative to that of the therapist as their relationship progresses;
and (2) patients who have less control in the first few sessions are
significantly more likely to eventually express dissatisfaction with their
therapist and terminate the relationship.

æè¦ï¼å¿çå¥åº·æ²»çæ¶åè¤éçå°è©±æµç¨ï¼å¶ä¸­æ£èåæ²»çå¸«æçºååæ¥ä¸ä¾æè¨è«ä»éº¼ãä¾å¦ï¼æ²»çå¸«å¯è½æåè©¦æ¹è®å°è©±æ¹åï¼ä»¥ä½¿æ²»çéç¨ä¿æå¨æ­£è»ä¸¦é¿ååæ»¯ï¼æèæ£èå¯è½æå°è¨è«å¼åä»åæ³éæ³¨çåé¡ã
æ£èåæ²»çå¸«çéç¨®éæ°å®åèä»åéä¿çç¼å±ååè³ªæä½éä¿ï¼çºäºåç­éååé¡ï¼æåå¼å¥äºä¸åæ©çæ¸¬éï¼ç¨æ¼è¡¡éæåè©±èªå¨å¤å¤§ç¨åº¦ä¸ç«å³éæ°å®åå°è©±æµç¨ï¼åæèéæ­¤é¡è®åçæååå¯¦éå¯¦ç¾ãæåå°æ­¤æ°æ¸¬éæç¨æ¼æè¿°æ£è-æ²»çå¸«éä¿å¨ä¸åéå¸¸é¾å¤§ãå»£æ³ä½¿ç¨çç·ä¸æ²»çå¹³å°ä¸ï¼å¨å¤åçç¨ä¸­çç¼å±ãæåçåæé¡¯ç¤ºï¼(1) é¨èæ£èèæ²»çå¸«éä¿çé²å±ï¼æ£èå°å°è©±æ¹åçæ§å¶éå¸¸æç¸å°æ¼æ²»çå¸«èå¢å ï¼(2) å¨æåå¹¾æ¬¡çç¨ä¸­æ§å¶è¼å°çæ£èï¼æçµé¡¯èæ´æå¯è½å°å¶æ²»çå¸«è¡¨éä¸æ»¿ä¸¦çµæ­¢éä¿ã

##### **Mental Disorders Detection in the Era of Large Language Models**
2410.07129v1 by Gleb Kuzmin, Petr Strepetov, Maksim Stankevich, Ivan Smirnov, Artem Shelmanov

This paper compares the effectiveness of traditional machine learning
methods, encoder-based models, and large language models (LLMs) on the task of
detecting depression and anxiety. Five datasets were considered, each differing
in format and the method used to define the target pathology class. We tested
AutoML models based on linguistic features, several variations of encoder-based
Transformers such as BERT, and state-of-the-art LLMs as pathology
classification models. The results demonstrated that LLMs outperform
traditional methods, particularly on noisy and small datasets where training
examples vary significantly in text length and genre. However, psycholinguistic
features and encoder-based models can achieve performance comparable to
language models when trained on texts from individuals with clinically
confirmed depression, highlighting their potential effectiveness in targeted
clinical applications.

æè¦ï¼æ¬ææ¯è¼äºå³çµ±æ©å¨å­¸ç¿æ¹æ³ãç·¨ç¢¼å¨æ¨¡ååå¤§åèªè¨æ¨¡å (LLM) å¨æé¬±åç¦æ®çåµæ¸¬ä»»åä¸çæææ§ãèæ®äºäºåè³æéï¼æ¯åè³æéå¨æ ¼å¼åç¨æ¼å®ç¾©ç®æ¨ççé¡å¥çæ¹æ³ä¸é½ä¸åãæåæ¸¬è©¦äºåºæ¼èªè¨ç¹å¾µç AutoML æ¨¡åãå¤ç¨®ç·¨ç¢¼å¨æ¨¡åï¼å¦ BERTï¼çè®é«ï¼ä»¥åææ°ç LLM ä½çºççåé¡æ¨¡åãçµæè¡¨æï¼LLM åªæ¼å³çµ±æ¹æ³ï¼ç¹å¥æ¯å¨è¨ç·´ç¯ä¾å¨æå­é·åº¦åé¡åä¸å·®ç°å¾å¤§çåéä¸å°çè³æéä¸ãç¶èï¼ç¶ä½¿ç¨ç¶è¨åºè­å¯¦æ£ææé¬±ççåäººçæå­é²è¡è¨ç·´æï¼å¿çèªè¨å­¸ç¹å¾µåç·¨ç¢¼å¨æ¨¡åå¯ä»¥éå°èèªè¨æ¨¡åç¸ç¶çæ§è½ï¼çªé¡¯äºå®åå¨ç®æ¨è¨åºæç¨ä¸­çæ½å¨æææ§ã

##### **MentalArena: Self-play Training of Language Models for Diagnosis and Treatment of Mental Health Disorders**
2410.06845v1 by Cheng Li, May Fung, Qingyun Wang, Chi Han, Manling Li, Jindong Wang, Heng Ji

Mental health disorders are one of the most serious diseases in the world.
Most people with such a disease lack access to adequate care, which highlights
the importance of training models for the diagnosis and treatment of mental
health disorders. However, in the mental health domain, privacy concerns limit
the accessibility of personalized treatment data, making it challenging to
build powerful models. In this paper, we introduce MentalArena, a self-play
framework to train language models by generating domain-specific personalized
data, where we obtain a better model capable of making a personalized diagnosis
and treatment (as a therapist) and providing information (as a patient). To
accurately model human-like mental health patients, we devise Symptom Encoder,
which simulates a real patient from both cognition and behavior perspectives.
To address intent bias during patient-therapist interactions, we propose
Symptom Decoder to compare diagnosed symptoms with encoded symptoms, and
dynamically manage the dialogue between patient and therapist according to the
identified deviations. We evaluated MentalArena against 6 benchmarks, including
biomedicalQA and mental health tasks, compared to 6 advanced models. Our
models, fine-tuned on both GPT-3.5 and Llama-3-8b, significantly outperform
their counterparts, including GPT-4o. We hope that our work can inspire future
research on personalized care. Code is available in
https://github.com/Scarelette/MentalArena/tree/main

æè¦ï¼å¿çå¥åº·éç¤æ¯ä¸çä¸æå´éçç¾çä¹ä¸ã
å¤§å¤æ¸æ£æéç¨®ç¾ççäººç¡æ³ç²å¾é©ç¶çç§è­·ï¼éå¸é¡¯äºè¨ç·´æ¨¡åä»¥è¨ºæ·åæ²»çå¿çå¥åº·éç¤çéè¦æ§ãç¶èï¼å¨å¿çå¥åº·é åï¼é±ç§åé¡éå¶äºåäººåæ²»çè³æçå¯åæ§ï¼éä½¿å¾å»ºç«å¼·å¤§çæ¨¡åè®å¾å·æææ°æ§ãå¨æ¬æä¸­ï¼æåä»ç´¹äº MentalArenaï¼ä¸åèªç©æ¡æ¶ï¼ééçæç¹å®é åçåäººåè³æä¾è¨ç·´èªè¨æ¨¡åï¼å¨å¶ä¸­æåç²å¾äºä¸åæ´å¥½çæ¨¡åï¼è½å¤ é²è¡åäººåè¨ºæ·åæ²»çï¼ä½çºæ²»çå¸«ï¼ä¸¦æä¾è³è¨ï¼ä½çºæ£èï¼ãçºäºæºç¢ºæ¨¡æ¬é¡ä¼¼äººé¡çå¿çå¥åº·æ£èï¼æåè¨­è¨äºççç·¨ç¢¼å¨ï¼å®å¾èªç¥åè¡çºçè§åº¦æ¨¡æ¬ä¸åçå¯¦çæ£èãçºäºè§£æ±ºæ£èèæ²»çå¸«äºåæéçæååå·®ï¼æåæåºäºççè§£ç¢¼å¨ï¼å°è¨ºæ·åºçççèç·¨ç¢¼ççé²è¡æ¯è¼ï¼ä¸¦æ ¹æè­å¥åºçåå·®åæç®¡çæ£èèæ²»çå¸«ä¹éçå°è©±ãæåéå° 6 ååºæºå° MentalArena é²è¡äºè©ä¼°ï¼åæ¬çç©é«å­¸åç­åå¿çå¥åº·ä»»åï¼ä¸¦è 6 ååé²æ¨¡åé²è¡äºæ¯è¼ãæåçæ¨¡åå¨ GPT-3.5 å Llama-3-8b ä¸é½é²è¡äºå¾®èª¿ï¼é¡¯èåªæ¼å¶å°ææ¨¡åï¼åæ¬ GPT-4oãæåå¸ææåçç ç©¶è½æ¿åµæªä¾å°åäººåç§è­·çç ç©¶ãç¨å¼ç¢¼å¯å¨ https://github.com/Scarelette/MentalArena/tree/main ä¸­ç²å¾

##### **An Improved Approach for Cardiac MRI Segmentation based on 3D UNet Combined with Papillary Muscle Exclusion**
2410.06818v1 by Narjes Benameur, Ramzi Mahmoudi, Mohamed Deriche, Amira fayouka, Imene Masmoudi, Nessrine Zoghlami

Left ventricular ejection fraction (LVEF) is the most important clinical
parameter of cardiovascular function. The accuracy in estimating this parameter
is highly dependent upon the precise segmentation of the left ventricle (LV)
structure at the end diastole and systole phases. Therefore, it is crucial to
develop robust algorithms for the precise segmentation of the heart structure
during different phases. Methodology: In this work, an improved 3D UNet model
is introduced to segment the myocardium and LV, while excluding papillary
muscles, as per the recommendation of the Society for Cardiovascular Magnetic
Resonance. For the practical testing of the proposed framework, a total of
8,400 cardiac MRI images were collected and analysed from the military hospital
in Tunis (HMPIT), as well as the popular ACDC public dataset. As performance
metrics, we used the Dice coefficient and the F1 score for validation/testing
of the LV and the myocardium segmentation. Results: The data was split into
70%, 10%, and 20% for training, validation, and testing, respectively. It is
worth noting that the proposed segmentation model was tested across three axis
views: basal, medio basal and apical at two different cardiac phases: end
diastole and end systole instances. The experimental results showed a Dice
index of 0.965 and 0.945, and an F1 score of 0.801 and 0.799, at the end
diastolic and systolic phases, respectively. Additionally, clinical evaluation
outcomes revealed a significant difference in the LVEF and other clinical
parameters when the papillary muscles were included or excluded.

æè¦ï¼å·¦å¿å®¤å°è¡åæ¸ (LVEF) æ¯å¿è¡ç®¡åè½æéè¦çè¨åºåæ¸ãä¼°è¨æ­¤åæ¸çæºç¢ºæ§é«åº¦ä¾è³´æ¼å·¦å¿å®¤ (LV) çµæ§å¨èå¼µæ«æåæ¶ç¸®æçç²¾ç¢ºåå²ãå æ­¤ï¼éç¼ç¨æ¼ç²¾ç¢ºåå²ä¸åææå¿èçµæ§çå¼·å¥æ¼ç®æ³è³ééè¦ãæ¹æ³ï¼å¨æ­¤å·¥ä½ä¸­ï¼å¼é²äºä¸åæ¹è¯ç 3D UNet æ¨¡åä¾åå²å¿èåå·¦å¿å®¤ï¼åææ ¹æå¿è¡ç®¡ç£å±æ¯å­¸æçå»ºè­°æé¤ä¹³é ­èãçºäºå°æåºçæ¶æ§é²è¡å¯¦éæ¸¬è©¦ï¼å¾çªå°¼æ¯çè»äºé«é¢ (HMPIT) åæµè¡ç ACDC å¬å±è³æéæ¶éä¸¦åæäºç¸½å± 8,400 å¼µå¿è MRI å½±åãä½çºæè½ææ¨ï¼æåä½¿ç¨ Dice ä¿æ¸å F1 åæ¸ä¾é©è­/æ¸¬è©¦å·¦å¿å®¤åå¿èåå²ãçµæï¼è³æè¢«åæ 70%ã10% å 20% åå¥ç¨æ¼è¨ç·´ãé©è­åæ¸¬è©¦ãå¼å¾æ³¨æçæ¯ï¼ææåºçåå²æ¨¡åå¨ä¸åè»¸åè¦åä¸­é²è¡äºæ¸¬è©¦ï¼åºåºãä¸­åºåºåå¿å°ï¼å¨å©åä¸åçå¿èææï¼èå¼µæ«æåæ¶ç¸®æ«æãå¯¦é©çµæé¡¯ç¤ºï¼å¨èå¼µæ«æåæ¶ç¸®æï¼Dice ææ¸åå¥çº 0.965 å 0.945ï¼F1 åæ¸åå¥çº 0.801 å 0.799ãæ­¤å¤ï¼è¨åºè©ä¼°çµæé¡¯ç¤ºï¼ç¶ä¹³é ­èè¢«ç´å¥ææé¤æï¼LVEF åå¶ä»è¨åºåæ¸å­å¨é¡¯èå·®ç°ã

##### **Deep Learning for Surgical Instrument Recognition and Segmentation in Robotic-Assisted Surgeries: A Systematic Review**
2410.07269v1 by Fatimaelzahraa Ali Ahmed, Mahmoud Yousef, Mariam Ali Ahmed, Hasan Omar Ali, Anns Mahboob, Hazrat Ali, Zubair Shah, Omar Aboumarzouk, Abdulla Al Ansari, Shidin Balakrishnan

Applying deep learning (DL) for annotating surgical instruments in
robot-assisted minimally invasive surgeries (MIS) represents a significant
advancement in surgical technology. This systematic review examines 48 studies
that and advanced DL methods and architectures. These sophisticated DL models
have shown notable improvements in the precision and efficiency of detecting
and segmenting surgical tools. The enhanced capabilities of these models
support various clinical applications, including real-time intraoperative
guidance, comprehensive postoperative evaluations, and objective assessments of
surgical skills. By accurately identifying and segmenting surgical instruments
in video data, DL models provide detailed feedback to surgeons, thereby
improving surgical outcomes and reducing complication risks. Furthermore, the
application of DL in surgical education is transformative. The review
underscores the significant impact of DL on improving the accuracy of skill
assessments and the overall quality of surgical training programs. However,
implementing DL in surgical tool detection and segmentation faces challenges,
such as the need for large, accurately annotated datasets to train these models
effectively. The manual annotation process is labor-intensive and
time-consuming, posing a significant bottleneck. Future research should focus
on automating the detection and segmentation process and enhancing the
robustness of DL models against environmental variations. Expanding the
application of DL models across various surgical specialties will be essential
to fully realize this technology's potential. Integrating DL with other
emerging technologies, such as augmented reality (AR), also offers promising
opportunities to further enhance the precision and efficacy of surgical
procedures.

æè¦ï¼æç¨æ·±åº¦å­¸ç¿ (DL) ä¾è¨»è§£æ©å¨äººè¼å©å¾®åµæè¡ (MIS) ä¸­çå¤ç§å¨æ¢°ä»£è¡¨äºå¤ç§æè¡çéå¤§é²æ­¥ãéé ç³»çµ±æ§åé¡§å¯©æ¥äº 48 é ç ç©¶ï¼éäºç ç©¶æ¡ç¨åé²ç DL æ¹æ³åæ¶æ§ãéäºè¤éç DL æ¨¡åå¨åµæ¸¬ååå²å¤ç§æè¡å·¥å·çç²¾æºåº¦åæçæ¹é¢å·²å±ç¾åºé¡¯èçé²æ­¥ãéäºæ¨¡åå¢å¼·çåè½æ¯æ´åç¨®è¨åºæç¨ï¼åæ¬å³æè¡ä¸­å¼å°ãå¨é¢çè¡å¾è©ä¼°åå¤ç§æè¡çå®¢è§è©ä¼°ãééå¨å½±çè³æä¸­ç²¾ç¢ºè­å¥ååå²å¤ç§å¨æ¢°ï¼DL æ¨¡åè½æä¾è©³ç´°çåé¥çµ¦å¤ç§é«çï¼é²èæ¹åæè¡çµæä¸¦éä½ä½µç¼çé¢¨éªãæ­¤å¤ï¼DL å¨å¤ç§æè²ä¸­çæç¨å·æè®é©æ§ãéé åé¡§å¼·èª¿äº DL å¨æ¹åæè½è©ä¼°æºç¢ºåº¦åæ´é«å¤ç§è¨ç·´è¨ç«åè³ªæ¹é¢çéå¤§å½±é¿ãç¶èï¼å¨å¤ç§å·¥å·åµæ¸¬ååå²ä¸­å¯¦æ½ DL é¢è¨ææ°ï¼ä¾å¦éè¦å¤§éæºç¢ºè¨»è§£çè³æéæè½ææè¨ç·´éäºæ¨¡åãæåè¨»è§£éç¨èæä¸è²»åï¼æ§æäºä¸é éå¤§çç¶é ¸ãæªä¾çç ç©¶æå°æ³¨æ¼èªåååµæ¸¬ååå²æµç¨ï¼ä¸¦å¢å¼· DL æ¨¡åå°ç°å¢è®åçé­¯æ£æ§ãæ´å± DL æ¨¡åå¨åç¨®å¤ç§å°ç§çæç¨å°æ¼ååå¯¦ç¾éé æè¡çæ½åè³ééè¦ãå° DL èå¶ä»æ°èæè¡ï¼ä¾å¦æ´å¢å¯¦å¢ (AR)ï¼æ´åä¹æä¾äºææé²ä¸æ­¥å¢å¼·å¤ç§æè¡ç²¾æºåº¦åæççæ©æã

##### **Multimodal Representation Learning using Adaptive Graph Construction**
2410.06395v1 by Weichen Huang

Multimodal contrastive learning train neural networks by levergaing data from
heterogeneous sources such as images and text. Yet, many current multimodal
learning architectures cannot generalize to an arbitrary number of modalities
and need to be hand-constructed. We propose AutoBIND, a novel contrastive
learning framework that can learn representations from an arbitrary number of
modalites through graph optimization. We evaluate AutoBIND on Alzhiemer's
disease detection because it has real-world medical applicability and it
contains a broad range of data modalities. We show that AutoBIND outperforms
previous methods on this task, highlighting the generalizablility of the
approach.

æè¦ï¼å¤æ¨¡æå°æ¯å­¸ç¿ééå©ç¨ä¾èªç°è³ªä¾æºï¼ä¾å¦åååæå­ï¼çè³æä¾è¨ç·´ç¥ç¶ç¶²è·¯ãç¶èï¼è¨±å¤ç®åçå¤æ¨¡æå­¸ç¿æ¶æ§ç¡æ³æ¨å»£å°ä»»ææ¸éçæ¨¡æï¼ä¸¦ä¸éè¦æåå»ºæ§ãæåæåºäº AutoBINDï¼ä¸åæ°ç©çå°æ¯å­¸ç¿æ¶æ§ï¼å®å¯ä»¥ééåå½¢æä½³åå¾ä»»ææ¸éçæ¨¡æä¸­å­¸ç¿è¡¨å¾µãæåå¨é¿è²æµ·é»ççåµæ¸¬ä¸è©ä¼° AutoBINDï¼å çºå®å·æå¯¦éçé«çæç¨æ§ï¼èä¸å®åå«å»£æ³çè³ææ¨¡æãæåå±ç¤º AutoBIND å¨éé ä»»åä¸åªæ¼ååçåç¨®æ¹æ³ï¼çªé¡¯äºæ­¤æ¹æ³çæ³åè½åã

##### **Skin Cancer Machine Learning Model Tone Bias**
2410.06385v1 by James Pope, Md Hassanuzzaman, Mingmar Sherpa, Omar Emara, Ayush Joshi, Nirmala Adhikari

Background: Many open-source skin cancer image datasets are the result of
clinical trials conducted in countries with lighter skin tones. Due to this
tone imbalance, machine learning models derived from these datasets can perform
well at detecting skin cancer for lighter skin tones. Any tone bias in these
models could introduce fairness concerns and reduce public trust in the
artificial intelligence health field.
  Methods: We examine a subset of images from the International Skin Imaging
Collaboration (ISIC) archive that provide tone information. The subset has a
significant tone imbalance. These imbalances could explain a model's tone bias.
To address this, we train models using the imbalanced dataset and a balanced
dataset to compare against. The datasets are used to train a deep convolutional
neural network model to classify the images as malignant or benign. We then
evaluate the models' disparate impact, based on selection rate, relative to
dark or light skin tone.
  Results: Using the imbalanced dataset, we found that the model is
significantly better at detecting malignant images in lighter tone resulting in
a disparate impact of 0.577. Using the balanced dataset, we found that the
model is also significantly better at detecting malignant images in lighter
versus darker tones with a disparate impact of 0.684. Using the imbalanced or
balanced dataset to train the model still results in a disparate impact well
below the standard threshold of 0.80 which suggests the model is biased with
respect to skin tone.
  Conclusion: The results show that typical skin cancer machine learning models
can be tone biased. These results provide evidence that diagnosis or tone
imbalance is not the cause of the bias. Other techniques will be necessary to
identify and address the bias in these models, an area of future investigation.

æè¦ï¼<paragraph>èæ¯ï¼è¨±å¤éæ¾åå§ç¢¼ç®èçååè³æéæ¯æ ¹æå¨èè²è¼æ·ºçåå®¶é²è¡çè¨åºè©¦é©ççµæãç±æ¼éç¨®è²èª¿ä¸å¹³è¡¡ï¼å¾éäºè³æéæ´¾ççæ©å¨å­¸ç¿æ¨¡åå¨æª¢æ¸¬èè²è¼æ·ºçç®èçæ¹é¢è¡¨ç¾è¯å¥½ãéäºæ¨¡åä¸­çä»»ä½è²èª¿åå·®é½å¯è½å¼ç¼å¬å¹³æ§çåé¡ï¼ä¸¦éä½å¬ç¾å°äººå·¥æºæ§å¥åº·é åçä¿¡ä»»ã
æ¹æ³ï¼æåæª¢æ¥äºåéç®èå½±ååä½çµç¹ (ISIC) æªæ¡åº«ä¸­æä¾è²èª¿è³è¨çååå­éãè©²å­éå·æé¡¯èçè²èª¿ä¸å¹³è¡¡ãéäºä¸å¹³è¡¡å¯è½è§£éäºæ¨¡åçè²èª¿åå·®ãçºäºè§£æ±ºéååé¡ï¼æåä½¿ç¨ä¸å¹³è¡¡çè³æéåå¹³è¡¡çè³æéè¨ç·´æ¨¡åï¼ä»¥ä¾¿é²è¡æ¯è¼ãéäºè³æéç¨æ¼è¨ç·´æ·±åº¦å·ç©ç¥ç¶ç¶²è·¯æ¨¡åï¼å°å½±ååé¡çºæ¡æ§æè¯æ§ãç¶å¾ï¼æåæ ¹æé¸æçè©ä¼°æ¨¡åçä¸åå½±é¿ï¼ç¸å°æ¼æ·±è²ææ·ºè²èè²ã
çµæï¼ä½¿ç¨ä¸å¹³è¡¡çè³æéï¼æåç¼ç¾è©²æ¨¡åå¨æª¢æ¸¬æ·ºè²è²èª¿ä¸­çæ¡æ§å½±åæ¹é¢é¡¯èåªæ¼å¨æ·±è²è²èª¿ä¸­æª¢æ¸¬æ¡æ§å½±åï¼å°è´ 0.577 çä¸åå½±é¿ãä½¿ç¨å¹³è¡¡çè³æéï¼æåç¼ç¾è©²æ¨¡åå¨æª¢æ¸¬æ·ºè²è²èª¿ä¸­çæ¡æ§å½±åæ¹é¢ä¹é¡¯èåªæ¼æ·±è²è²èª¿ï¼ä¸åå½±é¿çº 0.684ãä½¿ç¨ä¸å¹³è¡¡æå¹³è¡¡çè³æéè¨ç·´æ¨¡åä»ç¶æå°è´ä¸åå½±é¿ï¼é ä½æ¼ 0.80 çæ¨æºé¾å¼ï¼éè¡¨ææ¨¡åå¨èè²æ¹é¢æåå·®ã
çµè«ï¼çµæè¡¨æï¼å¸åçç®èçæ©å¨å­¸ç¿æ¨¡åå¯è½æç¢çè²èª¿åå·®ãéäºçµææä¾äºè­æè¡¨æï¼è¨ºæ·æè²èª¿ä¸å¹³è¡¡ä¸¦éé æåå·®çåå ãéè¦å¶ä»æè¡ä¾è­å¥åè§£æ±ºéäºæ¨¡åä¸­çåå·®ï¼éæ¯æªä¾ç ç©¶çä¸åé åã</paragraph>

##### **HumVI: A Multilingual Dataset for Detecting Violent Incidents Impacting Humanitarian Aid**
2410.06370v1 by Hemank Lamba, Anton Abilov, Ke Zhang, Elizabeth M. Olson, Henry k. Dambanemuya, JoÃ£o c. BÃ¡rcia, David S. Batista, Christina Wille, Aoife Cahill, Joel Tetreault, Alex Jaimes

Humanitarian organizations can enhance their effectiveness by analyzing data
to discover trends, gather aggregated insights, manage their security risks,
support decision-making, and inform advocacy and funding proposals. However,
data about violent incidents with direct impact and relevance for humanitarian
aid operations is not readily available. An automatic data collection and
NLP-backed classification framework aligned with humanitarian perspectives can
help bridge this gap. In this paper, we present HumVI - a dataset comprising
news articles in three languages (English, French, Arabic) containing instances
of different types of violent incidents categorized by the humanitarian sector
they impact, e.g., aid security, education, food security, health, and
protection. Reliable labels were obtained for the dataset by partnering with a
data-backed humanitarian organization, Insecurity Insight. We provide multiple
benchmarks for the dataset, employing various deep learning architectures and
techniques, including data augmentation and mask loss, to address different
task-related challenges, e.g., domain expansion. The dataset is publicly
available at https://github.com/dataminr-ai/humvi-dataset.

æè¦ï¼äººéä¸»ç¾©çµç¹å¯ä»¥ééåæè³æä¾æåå¶æè½ï¼ä»¥ç¼ç¾è¶¨å¢ãæ¶éå½ç¸½çè¦è§£ãç®¡çå¶å®å¨é¢¨éªãæ¯æ´æ±ºç­å¶å®ï¼ä¸¦æä¾å¡è­°åè³éææ¡çè³è¨ãç¶èï¼éæ¼æ´åäºä»¶çè³æï¼å¶ç´æ¥å½±é¿åèäººéä¸»ç¾©æ´å©è¡åç¸éæ§ï¼ä¸¦ä¸å®¹æåå¾ãä¸åèªåè³ææ¶éå NLP æ¯æ´çåé¡æ¶æ§ï¼èäººéä¸»ç¾©è§é»ä¸è´ï¼æå©æ¼å½åæ­¤å·®è·ãå¨æ¬æä¸­ï¼æåæåº HumVI - ä¸ååå«ä¸ç¨®èªè¨ï¼è±èªãæ³èªãé¿æä¼¯èªï¼æ°èæç« çè³æéï¼å¶ä¸­åå«äººéä¸»ç¾©é¨éåé¡çä¸åé¡åæ´åäºä»¶çæ¡ä¾ï¼ä¾å¦æ´å©å®å¨ãæè²ãç³§é£å®å¨ãå¥åº·åä¿è­·ãééèè³ææ¯æ´çäººéä¸»ç¾©çµç¹ Insecurity Insight åä½ï¼åå¾è³æéçå¯é æ¨ç±¤ãæåçºè³æéæä¾å¤ååºæºï¼æ¡ç¨åç¨®æ·±åº¦å­¸ç¿æ¶æ§åæè¡ï¼åæ¬è³ææ´ååé®ç½©æå¤±ï¼ä»¥è§£æ±ºä¸åçä»»åç¸éææ°ï¼ä¾å¦é åæ´åãè³æéå¬éæ¼ https://github.com/dataminr-ai/humvi-datasetã

##### **A Comparative Study of Hybrid Models in Health Misinformation Text Classification**
2410.06311v1 by Mkululi Sikosana, Oluwaseun Ajao, Sean Maudsley-Barton

This study evaluates the effectiveness of machine learning (ML) and deep
learning (DL) models in detecting COVID-19-related misinformation on online
social networks (OSNs), aiming to develop more effective tools for countering
the spread of health misinformation during the pan-demic. The study trained and
tested various ML classifiers (Naive Bayes, SVM, Random Forest, etc.), DL
models (CNN, LSTM, hybrid CNN+LSTM), and pretrained language models
(DistilBERT, RoBERTa) on the "COVID19-FNIR DATASET". These models were
evaluated for accuracy, F1 score, recall, precision, and ROC, and used
preprocessing techniques like stemming and lemmatization. The results showed
SVM performed well, achieving a 94.41% F1-score. DL models with Word2Vec
embeddings exceeded 98% in all performance metrics (accuracy, F1 score, recall,
precision & ROC). The CNN+LSTM hybrid models also exceeded 98% across
performance metrics, outperforming pretrained models like DistilBERT and
RoBERTa. Our study concludes that DL and hybrid DL models are more effective
than conventional ML algorithms for detecting COVID-19 misinformation on OSNs.
The findings highlight the importance of advanced neural network approaches and
large-scale pretraining in misinformation detection. Future research should
optimize these models for various misinformation types and adapt to changing
OSNs, aiding in combating health misinformation.

æè¦ï¼éé ç ç©¶è©ä¼°æ©å¨å­¸ç¿ (ML) åæ·±åº¦å­¸ç¿ (DL) æ¨¡åå¨åµæ¸¬ç·ä¸ç¤¾ç¾¤ç¶²è·¯ (OSN) ä¸è COVID-19 ç¸éçé¯èª¤è¨æ¯çæææ§ï¼ç®æ¨æ¯éç¼æ´ææçå·¥å·ä¾å°æå¤§æµè¡æéå¥åº·é¯èª¤è¨æ¯çæ£å¸ãéé ç ç©¶è¨ç·´ä¸¦æ¸¬è©¦äºåç¨® ML åé¡å¨ï¼æ¨¸ç´ è²æ°ãSVMãé¨æ©æ£®æç­ï¼ãDL æ¨¡åï¼CNNãLSTMãæ··å CNN+LSTMï¼åé è¨ç·´èªè¨æ¨¡åï¼DistilBERTãRoBERTaï¼å¨ãCOVID19-FNIR è³æéãä¸ãéäºæ¨¡åç¶éè©ä¼°ï¼æ¨æºçºæºç¢ºåº¦ãF1 åæ¸ãå¬åçãç²¾ç¢ºåº¦å ROCï¼ä¸¦ä½¿ç¨äºè©å¹¹ååè©å½¢éåç­åèçæè¡ãçµæé¡¯ç¤º SVM è¡¨ç¾è¯å¥½ï¼éå° 94.41% ç F1 åæ¸ãä½¿ç¨ Word2Vec åµå¥ç DL æ¨¡åå¨æææè½ææ¨ï¼æºç¢ºåº¦ãF1 åæ¸ãå¬åçãç²¾ç¢ºåº¦å ROCï¼ä¸­é½è¶é 98%ãCNN+LSTM æ··åæ¨¡åå¨æææè½ææ¨ä¸­ä¹è¶é 98%ï¼åªæ¼ DistilBERT å RoBERTa ç­é è¨ç·´æ¨¡åãæåçç ç©¶çµè«æ¯ï¼DL åæ··å DL æ¨¡åæ¯å³çµ± ML æ¼ç®æ³æ´è½ææåµæ¸¬ OSN ä¸ç COVID-19 é¯èª¤è¨æ¯ãéäºç¼ç¾çªé¡¯äºé²éç¥ç¶ç¶²è·¯æ¹æ³åé¯èª¤è¨æ¯åµæ¸¬ä¸­å¤§è¦æ¨¡é è¨ç·´çéè¦æ§ãæªä¾çç ç©¶æéå°åç¨®é¯èª¤è¨æ¯é¡åæä½³åéäºæ¨¡åï¼ä¸¦é©æä¸æ·è®åç OSNï¼åå©ææå¥åº·é¯èª¤è¨æ¯ã

##### **KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server**
2410.05725v2 by Wenhao Wang, Xiaoyu Liang, Rui Ye, Jingyi Chai, Siheng Chen, Yanfeng Wang

The success of large language models (LLMs) facilitate many parties to
fine-tune LLMs on their own private data. However, this practice raises privacy
concerns due to the memorization of LLMs. Existing solutions, such as utilizing
synthetic data for substitution, struggle to simultaneously improve performance
and preserve privacy. They either rely on a local model for generation,
resulting in a performance decline, or take advantage of APIs, directly
exposing the data to API servers. To address this issue, we propose
KnowledgeSG, a novel client-server framework which enhances synthetic data
quality and improves model performance while ensuring privacy. We achieve this
by learning local knowledge from the private data with differential privacy
(DP) and distilling professional knowledge from the server. Additionally,
inspired by federated learning, we transmit models rather than data between the
client and server to prevent privacy leakage. Extensive experiments in medical
and financial domains demonstrate the effectiveness of KnowledgeSG. Our code is
now publicly available at https://github.com/wwh0411/KnowledgeSG.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) çæåè®è¨±å¤äººå¯ä»¥å¾®èª¿ LLM ä»¥ç¬¦åä»åçç§äººè³æãç¶èï¼ç±æ¼ LLM çè¨æ¶åè½ï¼æ­¤åæ³å¼ç¼äºé±ç§åé¡ãç¾æçè§£æ±ºæ¹æ¡ï¼ä¾å¦ä½¿ç¨åæè³æé²è¡æ¿æï¼é£ä»¥åææ¹åæè½ä¸¦ç¶­è­·é±ç§ãå®åä¾è³´æ¼ååæ¨¡åé²è¡ç¢çï¼å°è´æè½ä¸éï¼æå©ç¨ APIï¼ç´æ¥å°è³æå¬éçµ¦ API ä¼ºæå¨ãçºäºè§£æ±ºæ­¤åé¡ï¼æåæåº KnowledgeSGï¼ä¸ç¨®æ°ç©çå®¢æ¶ç«¯ä¼ºæå¨æ¶æ§ï¼å®è½æååæè³æåè³ªä¸¦æ¹åæ¨¡åæè½ï¼åæç¢ºä¿é±ç§ãæåééä½¿ç¨å·®åé±ç§ (DP) å¾ç§äººè³æä¸­å­¸ç¿ååç¥è­ï¼ä¸¦å¾ä¼ºæå¨ä¸­èåå°æ¥­ç¥è­ä¾éææ­¤ç®æ¨ãæ­¤å¤ï¼åå°è¯é¦å­¸ç¿çåç¼ï¼æåå³è¼¸æ¨¡åèéè³æå¨å®¢æ¶ç«¯åä¼ºæå¨ä¹éï¼ä»¥é²æ­¢é±ç§å¤æ´©ãå¨é«çåéèé åçå»£æ³å¯¦é©è­æäº KnowledgeSG çæææ§ãæåçç¨å¼ç¢¼ç¾å¨å¬éæ¼ https://github.com/wwh0411/KnowledgeSGã

##### **Copiloting Diagnosis of Autism in Real Clinical Scenarios via LLMs**
2410.05684v2 by Yi Jiang, Qingyang Shen, Shuzhong Lai, Shunyu Qi, Qian Zheng, Lin Yao, Yueming Wang, Gang Pan

Autism spectrum disorder(ASD) is a pervasive developmental disorder that
significantly impacts the daily functioning and social participation of
individuals. Despite the abundance of research focused on supporting the
clinical diagnosis of ASD, there is still a lack of systematic and
comprehensive exploration in the field of methods based on Large Language
Models (LLMs), particularly regarding the real-world clinical diagnostic
scenarios based on Autism Diagnostic Observation Schedule, Second Edition
(ADOS-2). Therefore, we have proposed a framework called ADOS-Copilot, which
strikes a balance between scoring and explanation and explored the factors that
influence the performance of LLMs in this task. The experimental results
indicate that our proposed framework is competitive with the diagnostic results
of clinicians, with a minimum MAE of 0.4643, binary classification F1-score of
81.79\%, and ternary classification F1-score of 78.37\%. Furthermore, we have
systematically elucidated the strengths and limitations of current LLMs in this
task from the perspectives of ADOS-2, LLMs' capabilities, language, and model
scale aiming to inspire and guide the future application of LLMs in a broader
fields of mental health disorders. We hope for more research to be transferred
into real clinical practice, opening a window of kindness to the world for
eccentric children.

æè¦ï¼èªéçè­ç³»éç¤ (ASD) æ¯ä¸ç¨®å»£æ³çç¼å±éç¤ï¼æé¡¯èå½±é¿åé«çæ¥å¸¸çæ´»åè½åç¤¾äº¤åèãåç®¡æå¤§éçç ç©¶å°æ³¨æ¼æ¯æ ASD çè¨åºè¨ºæ·ï¼ä½å¨åºæ¼å¤§åèªè¨æ¨¡å (LLM) çæ¹æ³é åä¸­ï¼ä»ç¶ç¼ºä¹ç³»çµ±ä¸å¨é¢çæ¢ç´¢ï¼ç¹å¥æ¯éæ¼åºæ¼èªéçè¨ºæ·è§å¯éè¡¨ç¬¬äºçççå¯¦ä¸çè¨åºè¨ºæ·æå¢ (ADOS-2)ãå æ­¤ï¼æåæåºäºä¸ååçº ADOS-Copilot çæ¡æ¶ï¼å®å¨è©ååè§£éä¹éåå¾å¹³è¡¡ï¼ä¸¦æ¢è¨äºå½±é¿ LLM å¨æ­¤ä»»åä¸­è¡¨ç¾çå ç´ ãå¯¦é©çµæè¡¨æï¼æåæåºçæ¡æ¶èè¨åºé«ççè¨ºæ·çµæå·æç«¶ç­åï¼MAE æå°çº 0.4643ï¼äºååé¡ F1 åæ¸çº 81.79%ï¼ä¸ååé¡ F1 åæ¸çº 78.37%ãæ­¤å¤ï¼æåå¾ ADOS-2ãLLM çè½åãèªè¨åæ¨¡åè¦æ¨¡çè§åº¦ç³»çµ±å°é¡æäºç¶å LLM å¨æ­¤ä»»åä¸­çåªå¢åå±éæ§ï¼æ¨å¨æ¿åµåæå° LLM å¨æ´å»£æ³çç²¾ç¥ç¾çé åä¸­çæªä¾æç¨ãæåå¸ææ´å¤çç ç©¶è½è½åçºçæ­£çè¨åºå¯¦è¸ï¼çºå¤æªçå­©å­åæéä¸æéå¾ä¸ççåæä¹çªã

##### **NegMerge: Consensual Weight Negation for Strong Machine Unlearning**
2410.05583v1 by Hyoseo Kim, Dongyoon Han, Junsuk Choe

Machine unlearning aims to selectively remove specific knowledge from a
model. Current methods, such as task arithmetic, rely on fine-tuning models on
the forget set, generating a task vector, and subtracting it from the original
model. However, we argue the effectiveness of this approach is highly sensitive
to hyperparameter selection, necessitating careful validation to identify the
best model among many fine-tuned candidates. In this paper, we propose a novel
method that leverages all given fine-tuned models rather than selecting a
single one. By constructing task vectors from models trained with varied
hyperparameters and merging only the components of the task vectors with
consistent signs, we perform unlearning by negating the merged task vector from
the original model. Given that existing methods also utilize multiple
fine-tuned models, our approach delivers more effective unlearning without
incurring additional computational costs. We demonstrate the effectiveness of
our method on both vision-language models and standard image classification
models, showing improved unlearning performance with minimal degradation on the
retain set, outperforming state-of-the-art techniques.

æè¦ï¼æ©å¨å»å­¸ç¿æ¨å¨é¸ææ§å°å¾æ¨¡åä¸­ç§»é¤ç¹å®ç¥è­ãç®åçæ¹æ³ï¼ä¾å¦ä»»åç®è¡ï¼ä¾è³´æ¼å¨éºå¿éä¸å¾®èª¿æ¨¡åï¼çæä»»ååéï¼ä¸¦å¾åå§æ¨¡åä¸­æ¸å»å®ãç¶èï¼æåèªçºéç¨®æ¹æ³çæææ§å°è¶åæ¸é¸æé«åº¦ææï¼éè¦ä»ç´°é©è­ä»¥å¨è¨±å¤å¾®èª¿åé¸èä¸­æ¾åºæä½³æ¨¡åãå¨æ¬æä¸­ï¼æåæåºäºä¸ç¨®æ°æ¹æ³ï¼è©²æ¹æ³å©ç¨ææçµ¦å®çå¾®èª¿æ¨¡åï¼èä¸æ¯é¸æä¸åãééä½¿ç¨å·æä¸åè¶åæ¸è¨ç·´çæ¨¡åæ§å»ºä»»ååéï¼ä¸¦ååä½µå·æç¸åç¬¦èçä»»ååéççµæé¨åï¼æåééå¾åå§æ¨¡åä¸­å¦å®åä½µçä»»ååéä¾å·è¡å»å­¸ç¿ãéæ¼ç¾ææ¹æ³ä¹å©ç¨å¤åå¾®èª¿æ¨¡åï¼æåçåæ³å¨ä¸ç¢çé¡å¤è¨ç®ææ¬çææ³ä¸æä¾äºæ´ææçå»å­¸ç¿ãæåå¨è¦è¦ºèªè¨æ¨¡ååæ¨æºåååé¡æ¨¡åä¸å±ç¤ºäºæåæ¹æ³çæææ§ï¼é¡¯ç¤ºåºæ¹é²çå»å­¸ç¿æ§è½ï¼åæå°ä¿çéçä¸éå¹åº¦æå°ï¼åªæ¼æåé²çæè¡ã

##### **AI-Driven Early Mental Health Screening with Limited Data: Analyzing Selfies of Pregnant Women**
2410.05450v1 by Gustavo A. BasÃ­lio, Thiago B. Pereira, Alessandro L. Koerich, Ludmila Dias, Maria das GraÃ§as da S. Teixeira, Rafael T. Sousa, Wilian H. Hisatugu, Amanda S. Mota, Anilton S. Garcia, Marco AurÃ©lio K. Galletta, Hermano Tavares, Thiago M. PaixÃ£o

Major Depressive Disorder and anxiety disorders affect millions globally,
contributing significantly to the burden of mental health issues. Early
screening is crucial for effective intervention, as timely identification of
mental health issues can significantly improve treatment outcomes. Artificial
intelligence (AI) can be valuable for improving the screening of mental
disorders, enabling early intervention and better treatment outcomes. AI-driven
screening can leverage the analysis of multiple data sources, including facial
features in digital images. However, existing methods often rely on controlled
environments or specialized equipment, limiting their broad applicability. This
study explores the potential of AI models for ubiquitous depression-anxiety
screening given face-centric selfies. The investigation focuses on high-risk
pregnant patients, a population that is particularly vulnerable to mental
health issues. To cope with limited training data resulting from our clinical
setup, pre-trained models were utilized in two different approaches:
fine-tuning convolutional neural networks (CNNs) originally designed for facial
expression recognition and employing vision-language models (VLMs) for
zero-shot analysis of facial expressions. Experimental results indicate that
the proposed VLM-based method significantly outperforms CNNs, achieving an
accuracy of 77.6% and an F1-score of 56.0%. Although there is significant room
for improvement, the results suggest that VLMs can be a promising approach for
mental health screening, especially in scenarios with limited data.

æè¦ï¼éåº¦æé¬±çåç¦æ®çå½±é¿å¨çæ¸ç¾è¬äººï¼
å°å¿çå¥åº·åé¡çè² ææé¡¯èçå½±é¿ãæ©æ
ç¯©æª¢å°æ¼ææå¹²é è³ééè¦ï¼å çºåæè­å¥
å¿çå¥åº·åé¡å¯ä»¥é¡¯èæ¹åæ²»ççµæãäººå·¥
æºæ§ (AI) å¯ä»¥çºæ¹åå¿çç¾ççç¯©æª¢æä¾æå¹å¼çå¹«å©ï¼
å¯¦ç¾æ©æå¹²é åæ´å¥½çæ²»ççµæãAI é©åç
ç¯©æª¢å¯ä»¥å©ç¨å¤åæ¸æä¾æºçåæï¼åæ¬æ¸ä½å½±åä¸­çèé¨
ç¹å¾µãç¶èï¼ç¾ææ¹æ³éå¸¸ä¾è³´åæ§
ç°å¢æå°æ¥­è¨­åï¼éå¶äºå®åçå»£æ³é©ç¨æ§ãæ¬
ç ç©¶æ¢è¨ AI æ¨¡åå¨ç¡æä¸å¨çæé¬±çç¦æ®ç
ç¯©æª¢ä¸­ï¼ä»¥èé¨çºä¸­å¿çèªæçæ½åãèª¿æ¥éé»éæ³¨é«é¢¨éª
å­å©¦ï¼éæ¯ä¸åç¹å¥å®¹æåå°å¿çå¥åº·åé¡å½±é¿çäººç¾¤ãçºäºæå°å æåçè¨åº
è¨­ç½®èç¢ççæéè¨ç·´è³æï¼é åè¨ç·´çæ¨¡åè¢«ç¨æ¼å©ç¨®ä¸åçæ¹æ³ï¼
å¾®èª¿åæ¬è¨­è¨ç¨æ¼èé¨è¡¨æè¾¨è­çå·ç©ç¥ç¶ç¶²è·¯ (CNN)ï¼ä¸¦æ¡ç¨è¦è¦ºèªè¨æ¨¡å (VLM) é²è¡
é¶æ¬¡å­¸ç¿çèé¨è¡¨æåæãå¯¦é©çµæè¡¨æ
æåºçåºæ¼ VLM çæ¹æ³é¡¯èåªæ¼ CNNï¼éå° 77.6% çæºç¢ºçå 56.0% ç F1 åæ¸ãåç®¡æé¡¯èçæ¹é²ç©ºéï¼
çµæè¡¨æ VLM å¯ä»¥æçºå¿çå¥åº·ç¯©æª¢çä¸ç¨®æåéçæ¹æ³ï¼ç¹å¥æ¯å¨è³ææéçææ³ä¸ã

##### **Improving Predictor Reliability with Selective Recalibration**
2410.05407v1 by Thomas P. Zollo, Zhun Deng, Jake C. Snell, Toniann Pitassi, Richard Zemel

A reliable deep learning system should be able to accurately express its
confidence with respect to its predictions, a quality known as calibration. One
of the most effective ways to produce reliable confidence estimates with a
pre-trained model is by applying a post-hoc recalibration method. Popular
recalibration methods like temperature scaling are typically fit on a small
amount of data and work in the model's output space, as opposed to the more
expressive feature embedding space, and thus usually have only one or a handful
of parameters. However, the target distribution to which they are applied is
often complex and difficult to fit well with such a function. To this end we
propose \textit{selective recalibration}, where a selection model learns to
reject some user-chosen proportion of the data in order to allow the
recalibrator to focus on regions of the input space that can be well-captured
by such a model. We provide theoretical analysis to motivate our algorithm, and
test our method through comprehensive experiments on difficult medical imaging
and zero-shot classification tasks. Our results show that selective
recalibration consistently leads to significantly lower calibration error than
a wide range of selection and recalibration baselines.

æè¦ï¼ä¸åå¯é çæ·±åº¦å­¸ç¿ç³»çµ±æè©²è½å¤ æºç¢ºå°è¡¨éå¶å°é æ¸¬çä¿¡å¿ï¼éé åè³ªç¨±çºæ ¡æºãä½¿ç¨é åè¨ç·´çæ¨¡åç¢çå¯é çä¿¡å¿ä¼°è¨å¼æææçæ¹æ³ä¹ä¸æ¯æç¨äºå¾éæ°æ ¡æºæ¹æ³ãç±éçéæ°æ ¡æºæ¹æ³ï¼ä¾å¦æº«åº¦ç¸®æ¾ï¼éå¸¸é©ç¨æ¼å°éè³æï¼ä¸¦å¨æ¨¡åçè¼¸åºç©ºéä¸­éä½ï¼èä¸æ¯æ´å·è¡¨ç¾åçç¹å¾µåµå¥ç©ºéï¼å æ­¤éå¸¸åªæä¸åæå°æ¸å¹¾ååæ¸ãç¶èï¼å®åææç¨çç®æ¨åä½éå¸¸å¾è¤éï¼ä¸é£ä»¥ç¨æ­¤é¡å½æ¸åè¯å¥½çæ¬åãçºæ­¤ï¼æåæåºãé¸ææ§éæ°æ ¡æºãï¼å¶ä¸­é¸ææ¨¡åæå­¸ç¿æçµä½¿ç¨èé¸æçæäºè³ææ¯ä¾ï¼ä»¥åè¨±éæ°æ ¡æºå¨å°æ³¨æ¼è¼¸å¥ç©ºéä¸­è½è¢«æ­¤é¡æ¨¡åè¯å¥½ææå°çååãæåæä¾çè«åæä¾æ¿åµæåçæ¼ç®æ³ï¼ä¸¦ééå¨å°é£çé«å­¸å½±ååé¶æ¬¡åé¡ä»»åä¸­é²è¡å¨é¢çå¯¦é©ä¾æ¸¬è©¦æåçæ¨¡åãæåççµæé¡¯ç¤ºï¼é¸ææ§éæ°æ ¡æºæçºå°è´æ ¡æºèª¤å·®é¡¯èä½æ¼åç¨®é¸æåéæ°æ ¡æºåºç·ã

##### **CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**
2410.05235v2 by Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri

Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.

æè¦ï¼è§£éäººå·¥æºæ§ (AI) çæ±ºç­æ¯ç¾å¨ AI çä¸é éå¤§ææ°ï¼ç¹å¥æ¯æç¨æ¼åé«å­¸åæ³å¾ç­æææå¢æãç¶èï¼è§£éæ±ºç­èå¾çç±çéæ±ä¹æ¯åºæ¼äººé¡çèéçä¸åä¸»è¦åé¡ï¼å çºæå¿è¦è­æçºä»éº¼ååºæåæ±ºç­ãä¾å¦ï¼ä½é¢é«å¸«ä¸åéè¦æä¾ï¼å¯è½æ¯æ­£ç¢ºçï¼è¨ºæ·ï¼ééè¦è§£éä»åå¦ä½éææåçµè«ãå æ­¤ï¼éç¼æ°çå·¥å·ä¾å¹«å©ä½é¢é«å¸«è¨ç·´ä»åçè§£éæå·§æ¯æè²ä¸­ AI çä¸é æ ¸å¿ç®æ¨ãå¨æ¬æä¸­ï¼æåéµå¾ªéåæ¹åï¼ä¸¦ä¸æ ¹ææåçäºè§£ï¼æåºç¬¬ä¸åå¤èªè¨é«å­¸åç­è³æéï¼å¶ä¸­è¨åºçä¾çæ­£ç¢ºåä¸æ­£ç¢ºè¨ºæ·é½éæç±é«çæ°å¯«çèªç¶èªè¨è§£éãéäºè§£éå·²ä½¿ç¨è«è­çµæï¼å³åæãä¸»å¼µï¼åè«è­éä¿ï¼å³æ»æãæ¯æï¼é²è¡æåè¨»è§£ï¼ç¢çå¤èªè¨ CasiMedicos-Arg è³æéï¼å¶ä¸­åå« 558 åå·æè§£éçåç¨®èªè¨ï¼è±èªãè¥¿ç­çèªãæ³èªãç¾©å¤§å©èªï¼çè¨åºçä¾ï¼æåè¨»è§£äº 5021 åä¸»å¼µã2313 ååæã2431 åæ¯æéä¿å 1106 åæ»æéä¿ãæåæå¾å±ç¤ºäºç«¶ç­åºæºå¦ä½éå°è«è­æ¢åä»»åå·è¡æ­¤å·ææ°æ§çè³æéã

##### **RespLLM: Unifying Audio and Text with Multimodal LLMs for Generalized Respiratory Health Prediction**
2410.05361v1 by Yuwei Zhang, Tong Xia, Aaqib Saeed, Cecilia Mascolo

The high incidence and mortality rates associated with respiratory diseases
underscores the importance of early screening. Machine learning models can
automate clinical consultations and auscultation, offering vital support in
this area. However, the data involved, spanning demographics, medical history,
symptoms, and respiratory audio, are heterogeneous and complex. Existing
approaches are insufficient and lack generalizability, as they typically rely
on limited training data, basic fusion techniques, and task-specific models. In
this paper, we propose RespLLM, a novel multimodal large language model (LLM)
framework that unifies text and audio representations for respiratory health
prediction. RespLLM leverages the extensive prior knowledge of pretrained LLMs
and enables effective audio-text fusion through cross-modal attentions.
Instruction tuning is employed to integrate diverse data from multiple sources,
ensuring generalizability and versatility of the model. Experiments on five
real-world datasets demonstrate that RespLLM outperforms leading baselines by
an average of 4.6% on trained tasks, 7.9% on unseen datasets, and facilitates
zero-shot predictions for new tasks. Our work lays the foundation for
multimodal models that can perceive, listen to, and understand heterogeneous
data, paving the way for scalable respiratory health diagnosis.

æè¦ï¼é«ç¼ççåæ­»äº¡ççå¼å¸éç¾ççªé¡¯äºæ©æç¯©æª¢çéè¦æ§ãæ©å¨å­¸ç¿æ¨¡åå¯ä»¥èªååè¨åºè«®è©¢åè½è¨ºï¼å¨æ­¤é åæä¾éè¦çæ¯æ´ãç¶èï¼ææ¶åçè³ææ¶µèäººå£çµ±è¨ãçå²ãççåå¼å¸é³è¨ï¼æ¢ç°è³ªåè¤éãç¾æçæ¹æ³ä¸è¶³ä¸ç¼ºä¹æ¦æ¬æ§ï¼å çºå®åéå¸¸ä¾è³´æ¼æéçè¨ç·´è³æãåºæ¬çèåæè¡åç¹å®æ¼ä»»åçæ¨¡åãå¨æ¬æä¸­ï¼æåæåº RespLLMï¼éæ¯ä¸åæ°ç©çå¤æ¨¡æå¤§åèªè¨æ¨¡å (LLM) æ¡æ¶ï¼å®çµ±ä¸äºææ¬åé³è¨è¡¨ç¤ºï¼ä»¥é²è¡å¼å¸éå¥åº·é æ¸¬ãRespLLM å©ç¨é è¨ç·´ LLM çå»£æ³åé©ç¥è­ï¼ä¸¦ééè·¨æ¨¡ææ³¨æåå¯¦ç¾ææçé³è¨ææ¬èåãæç¤ºèª¿æ´ç¨æ¼æ´åä¾èªå¤åä¾æºçä¸åè³æï¼ç¢ºä¿æ¨¡åçæ¦æ¬æ§åå¤åè½æ§ãå¨äºåçå¯¦ä¸çè³æéä¸çå¯¦é©è¡¨æï¼RespLLM å¨è¨ç·´ä»»åä¸æ¯é åçåºæºé«åºå¹³å 4.6%ï¼å¨æªè¦è³æéä¸é«åº 7.9%ï¼ä¸¦ä¿é²æ°ä»»åçé¶æ¬¡å­¸ç¿é æ¸¬ãæåçç ç©¶çºå¤æ¨¡ææ¨¡åå¥ å®äºåºç¤ï¼éäºæ¨¡åå¯ä»¥æç¥ãèè½åçè§£ç°è³ªè³æï¼çºå¯æ´åçå¼å¸éå¥åº·è¨ºæ·éªå¹³éè·¯ã

##### **Synthetic Generation of Dermatoscopic Images with GAN and Closed-Form Factorization**
2410.05114v1 by Rohan Reddy Mekala, Frederik Pahde, Simon Baur, Sneha Chandrashekar, Madeline Diep, Markus Wenzel, Eric L. Wisotzky, Galip Ãmit Yolcu, Sebastian Lapuschkin, Jackie Ma, Peter Eisert, Mikael Lindvall, Adam Porter, Wojciech Samek

In the realm of dermatological diagnoses, where the analysis of dermatoscopic
and microscopic skin lesion images is pivotal for the accurate and early
detection of various medical conditions, the costs associated with creating
diverse and high-quality annotated datasets have hampered the accuracy and
generalizability of machine learning models. We propose an innovative
unsupervised augmentation solution that harnesses Generative Adversarial
Network (GAN) based models and associated techniques over their latent space to
generate controlled semiautomatically-discovered semantic variations in
dermatoscopic images. We created synthetic images to incorporate the semantic
variations and augmented the training data with these images. With this
approach, we were able to increase the performance of machine learning models
and set a new benchmark amongst non-ensemble based models in skin lesion
classification on the HAM10000 dataset; and used the observed analytics and
generated models for detailed studies on model explainability, affirming the
effectiveness of our solution.

æè¦ï¼å¨ç®èç§è¨ºæ·é åï¼ç®èé¡æª¢æ¥åé¡¯å¾®é¡ç®èçè®å½±åçåæå°æ¼æºç¢ºä¸æ©æåµæ¸¬åç¨®é«ççæ³è³ééè¦ï¼ä½å»ºç«å¤æ¨£åä¸é«åè³ªçæ¨è¨è³æéç¸éææ¬å·²é»ç¤æ©å¨å­¸ç¿æ¨¡åçæºç¢ºæ§åæ®éæ§ãæåæåºåµæ°çéç£ç£å¼æ´åè§£æ±ºæ¹æ¡ï¼å©ç¨çæå°æç¶²è·¯ (GAN) åºç¤æ¨¡ååå¶å¨æ½å¨ç©ºéä¸çç¸éæè¡ï¼ä»¥å¨ç®èé¡å½±åä¸­ç¢çåæ§çåèªåç¼ç¾èªç¾©è®åãæåå»ºç«åæå½±åä»¥ç´å¥èªç¾©è®åï¼ä¸¦ä½¿ç¨éäºå½±åæ´åè¨ç·´è³æãééæ­¤æ¹æ³ï¼æåå¾ä»¥æåæ©å¨å­¸ç¿æ¨¡åçæè½ï¼ä¸¦å¨ HAM10000 è³æéçç®èçè®åé¡ä¸­è¨­å®éæ´é«å¼æ¨¡åçæ°åºæºï¼ä¸¦ä½¿ç¨è§å¯å°çåæåå»ºç«çæ¨¡åé²è¡æ¨¡åå¯è§£éæ§çè©³ç´°ç ç©¶ï¼ç¢ºèªæåè§£æ±ºæ¹æ¡çæææ§ã

##### **Named Clinical Entity Recognition Benchmark**
2410.05046v1 by Wadood M Abdul, Marco AF Pimentel, Muhammad Umar Salman, Tathagata Raha, ClÃ©ment Christophe, Praveen K Kanithi, Nasir Hayat, Ronnie Rajan, Shadab Khan

This technical report introduces a Named Clinical Entity Recognition
Benchmark for evaluating language models in healthcare, addressing the crucial
natural language processing (NLP) task of extracting structured information
from clinical narratives to support applications like automated coding,
clinical trial cohort identification, and clinical decision support.
  The leaderboard provides a standardized platform for assessing diverse
language models, including encoder and decoder architectures, on their ability
to identify and classify clinical entities across multiple medical domains. A
curated collection of openly available clinical datasets is utilized,
encompassing entities such as diseases, symptoms, medications, procedures, and
laboratory measurements. Importantly, these entities are standardized according
to the Observational Medical Outcomes Partnership (OMOP) Common Data Model,
ensuring consistency and interoperability across different healthcare systems
and datasets, and a comprehensive evaluation of model performance. Performance
of models is primarily assessed using the F1-score, and it is complemented by
various assessment modes to provide comprehensive insights into model
performance. The report also includes a brief analysis of models evaluated to
date, highlighting observed trends and limitations.
  By establishing this benchmarking framework, the leaderboard aims to promote
transparency, facilitate comparative analyses, and drive innovation in clinical
entity recognition tasks, addressing the need for robust evaluation methods in
healthcare NLP.

æè¦ï¼éä»½æè¡å ±åä»ç´¹äºä¸åå½åè¨åºå¯¦é«è¾¨è­åºæºï¼ç¨æ¼è©ä¼°é«çä¿å¥ä¸­çèªè¨æ¨¡åï¼è§£æ±ºå¾è¨åºæè¿°ä¸­èåçµæ§åè³è¨çééµèªç¶èªè¨èç (NLP) ä»»åï¼ä»¥æ¯æ´èªåç·¨ç¢¼ãè¨åºè©¦é©ç¾¤çµè­å¥åè¨åºæ±ºç­æ¯æ´ç­æç¨ç¨å¼ã
æè¡æ¦æä¾ä¸åæ¨æºåå¹³å°ï¼ç¨æ¼è©ä¼°åç¨®èªè¨æ¨¡åï¼åæ¬ç·¨ç¢¼å¨åè§£ç¢¼å¨æ¶æ§ï¼ä»¥åå®åè·¨å¤åé«çé åè­å¥ååé¡è¨åºå¯¦é«çè½åãå©ç¨ç²¾å¿æ´ççå¬éè¨åºè³æéï¼æ¶µèç¾çãççãè¥ç©ãç¨åºåå¯¦é©å®¤æ¸¬éç­å¯¦é«ãéè¦çæ¯ï¼éäºå¯¦é«æ ¹æè§å¯æ§é«ççµæåä½å¤¥ä¼´éä¿ (OMOP) å¸¸è¦è³ææ¨¡åæ¨æºåï¼ç¢ºä¿ä¸åé«çä¿å¥ç³»çµ±åè³æéä¹éçä¸è´æ§åäºéæ§ï¼ä»¥åæ¨¡åæè½çå¨é¢è©ä¼°ãæ¨¡åæè½ä¸»è¦ä½¿ç¨ F1 åæ¸è©ä¼°ï¼ä¸¦è¼ä»¥åç¨®è©ä¼°æ¨¡å¼ï¼æä¾å°æ¨¡åæè½çå¨é¢è¦è§£ãå ±åéåæ¬å°è¿ä»è©ä¼°æ¨¡åçç°¡è¦åæï¼éé»èªªæè§å¯å°çè¶¨å¢åéå¶ã
ééå»ºç«æ­¤åºæºæ¶æ§ï¼æè¡æ¦æ¨å¨ä¿é²éæåº¦ãä¿é²æ¯è¼åæï¼ä¸¦æ¨åè¨åºå¯¦é«è¾¨è­ä»»åçåµæ°ï¼æ»¿è¶³é«çä¿å¥ NLP ä¸­å°å¥å¨è©ä¼°æ¹æ³çéæ±ã

##### **Learning Interpretable Hierarchical Dynamical Systems Models from Time Series Data**
2410.04814v1 by Manuel Brenner, Elias Weber, Georgia Koppe, Daniel Durstewitz

In science, we are often interested in obtaining a generative model of the
underlying system dynamics from observed time series. While powerful methods
for dynamical systems reconstruction (DSR) exist when data come from a single
domain, how to best integrate data from multiple dynamical regimes and leverage
it for generalization is still an open question. This becomes particularly
important when individual time series are short, and group-level information
may help to fill in for gaps in single-domain data. At the same time, averaging
is not an option in DSR, as it will wipe out crucial dynamical properties
(e.g., limit cycles in one domain vs. chaos in another). Hence, a framework is
needed that enables to efficiently harvest group-level (multi-domain)
information while retaining all single-domain dynamical characteristics. Here
we provide such a hierarchical approach and showcase it on popular DSR
benchmarks, as well as on neuroscientific and medical time series. In addition
to faithful reconstruction of all individual dynamical regimes, our
unsupervised methodology discovers common low-dimensional feature spaces in
which datasets with similar dynamics cluster. The features spanning these
spaces were further dynamically highly interpretable, surprisingly in often
linear relation to control parameters that govern the dynamics of the
underlying system. Finally, we illustrate transfer learning and generalization
to new parameter regimes.

æè¦ï¼å¨ç§å­¸ä¸­ï¼æåå¸¸å¸¸æèè¶£å¾è§å¯å°çæéåºåä¸­ç²å¾åºç¤ç³»çµ±åæççææ¨¡åãéç¶ç¶è³æä¾èªå®ä¸é åæï¼å¼·å¤§çåæç³»çµ±éå»º (DSR) æ¹æ³å·²ç¶å­å¨ï¼ä½å¦ä½æä½³æ´åä¾èªå¤ååææ©å¶çè³æä¸¦å©ç¨å®é²è¡æ¦æ¬ä»ç¶æ¯ä¸åéæ¾çåé¡ãç¶åå¥æéåºåå¾ç­æï¼éä¸é»å°¤å¶éè¦ï¼èä¸ç¾¤çµå±¤ç´çè³è¨å¯è½æå©æ¼å¡«è£å®ä¸é åè³æä¸­çç©ºç½ãåæï¼å¹³ååä¸¦é DSR ä¸­çé¸é ï¼å çºå®ææ¶é¤ééµçåæç¹æ§ï¼ä¾å¦ï¼ä¸åé åä¸­çæ¥µéé±æç¸å°æ¼å¦ä¸åé åä¸­çæ··äºï¼ãå æ­¤ï¼éè¦ä¸åæ¡æ¶ï¼è½å¤ æææ¶éç¾¤çµå±¤ç´ï¼å¤é åï¼è³è¨ï¼åæä¿çææå®ä¸é ååæç¹æ§ãå¨éè£¡ï¼æåæä¾éç¨®éå±¤å¼æ¹æ³ï¼ä¸¦å¨æµè¡ç DSR åºæºä»¥åç¥ç¶ç§å­¸åé«å­¸æéåºåä¸­å±ç¤ºå®ãé¤äºå¿ å¯¦éå»ºææåå¥åææ©å¶ä¹å¤ï¼æåçéç£ç£æ¹æ³éç¼ç¾äºå¸¸è¦çä½ç¶­ç¹å¾µç©ºéï¼å¶ä¸­å·æç¸ä¼¼åæçè³æéææç¾¤ãè·¨è¶éäºç©ºéçç¹å¾µå¨åæä¸é²ä¸æ­¥å·æé«åº¦å¯è§£éæ§ï¼ä»¤äººé©è¨çæ¯ï¼å®åéå¸¸èæ§å¶åºç¤ç³»çµ±åæçæ§å¶åæ¸åç·æ§éä¿ãæå¾ï¼æåèªªæäºé·ç§»å¼å­¸ç¿åå°æ°åæ¸æ©å¶çæ¦æ¬ã

##### **$\textbf{Only-IF}$:Revealing the Decisive Effect of Instruction Diversity on Generalization**
2410.04717v1 by Dylan Zhang, Justin Wang, Francois Charton

Understanding and accurately following instructions is critical for large
language models (LLMs) to be effective across diverse tasks. In this work, we
rigorously examine the key factors that enable models to generalize to unseen
instructions, providing insights to guide the collection of data for
instruction-tuning. Through controlled experiments, inspired by the
Turing-complete Markov algorithm, we demonstrate that such generalization
$\textbf{only emerges}$ when training data is diversified enough across
semantic domains. Our findings also reveal that merely diversifying within
limited domains fails to ensure robust generalization. In contrast,
cross-domain data diversification, even under constrained data budgets,
significantly enhances a model's adaptability. We further extend our analysis
to real-world scenarios, including fine-tuning of
$\textit{$\textbf{specialist}$}$ and $\textit{$\textbf{generalist}$}$ models.
In both cases, we demonstrate that 1) better performance can be achieved by
increasing the diversity of an established dataset while keeping the data size
constant, and 2) when scaling up the data, diversifying the semantics of
instructions is more effective than simply increasing the quantity of similar
data. Our research provides important insights for dataset collation,
particularly when optimizing model performance by expanding training data for
both specialist and generalist scenarios. We show that careful consideration of
data diversification is key: training specialist models with data extending
beyond their core domain leads to significant performance improvements, while
generalist models benefit from diverse data mixtures that enhance their overall
instruction-following capabilities across a wide range of applications. Our
results highlight the critical role of strategic diversification and offer
clear guidelines for improving data quality.

æè¦ï¼<paragraph>å°æ¼å¤§åèªè¨æ¨¡å (LLM) ä¾èªªï¼çè§£ä¸¦æºç¢ºéµå¾ªæç¤ºå°æ¼å¨åç¨®ä»»åä¸­ç¼æ®ä½ç¨è³ééè¦ãå¨éé å·¥ä½ä¸­ï¼æåå´æ ¼å¯©æ¥äºä½¿æ¨¡åè½å¤ æ¦æ¬å°æªè¦æç¤ºçééµå ç´ ï¼ä¸¦æä¾è¦è§£ä»¥æå°æç¤ºèª¿æ´æ¸æçæ¶éãééååéå®åé¦¬å¯å¤«æ¼ç®æ³åç¼çåæ§å¯¦é©ï¼æåè­æäºéç¨®æ¦æ¬åç¶è¨ç·´æ¸æå¨èªç¾©é åä¸­è¶³å¤ å¤æ¨£åæææåºç¾ãæåçç¼ç¾éè¡¨æï¼åå¨æéçé åå§é²è¡å¤æ¨£åä¸è¶³ä»¥ç¢ºä¿ç©©å¥çæ¦æ¬ãç¸æ¯ä¹ä¸ï¼å³ä½¿å¨åéçæ¸æé ç®ä¸ï¼è·¨é åæ¸æå¤æ¨£åä¹æé¡¯èå¢å¼·æ¨¡åçé©ææ§ãæåé²ä¸æ­¥å°æåçåææ´å±å°ç¾å¯¦ä¸çå ´æ¯ï¼åæ¬å¾®èª¿å°å®¶åéææ¨¡åãå¨éå©ç¨®ææ³ä¸ï¼æåè­æäº 1) å¯ä»¥å¨ä¿ææ¸æå¤§å°ä¸è®çåæééå¢å æ¢å®æ¸æéçå¤æ¨£æ§ä¾å¯¦ç¾æ´å¥½çæ§è½ï¼ä»¥å 2) å¨æ´å±æ¸ææï¼å¤æ¨£åæä»¤çèªç¾©æ¯ç°¡å®å°å¢å ç¸ä¼¼æ¸æçæ¸éæ´ææãæåçç ç©¶çºæ¸æéæ´çæä¾äºéè¦çè¦è§£ï¼ç¹å¥æ¯å¨ééæ´å±å°å®¶åéæå ´æ¯çè¨ç·´æ¸æä¾åªåæ¨¡åæ§è½æãæåè¡¨æï¼ä»ç´°èæ®æ¸æå¤æ¨£åæ¯ééµï¼ä½¿ç¨è¶åºå¶æ ¸å¿é åçæ¸æè¨ç·´å°å®¶æ¨¡åæå°è´æ§è½é¡¯èæåï¼èéææ¨¡ååçæ¼å¤æ¨£åçæ¸ææ··åï¼éäºæ··åå¢å¼·äºå®åå¨å»£æ³æç¨ä¸­çæ´é«æä»¤éµå¾ªè½åãæåççµæçªåºäºç­ç¥å¤æ¨£åçééµä½ç¨ï¼ä¸¦çºæé«æ¸æè³ªéæä¾äºæç¢ºçæå°æ¹éã</paragraph>

##### **Rule-based Data Selection for Large Language Models**
2410.04715v1 by Xiaomin Li, Mingye Gao, Zhiwei Zhang, Chang Yue, Hong Hu

The quality of training data significantly impacts the performance of large
language models (LLMs). There are increasing studies using LLMs to rate and
select data based on several human-crafted metrics (rules). However, these
conventional rule-based approaches often depend too heavily on human
heuristics, lack effective metrics for assessing rules, and exhibit limited
adaptability to new tasks. In our study, we introduce an innovative rule-based
framework that utilizes the orthogonality of score vectors associated with
rules as a novel metric for rule evaluations. Our approach includes an
automated pipeline that first uses LLMs to generate a diverse set of rules,
encompassing various rating dimensions to evaluate data quality. Then it rates
a batch of data based on these rules and uses the determinantal point process
(DPP) from random matrix theory to select the most orthogonal score vectors,
thereby identifying a set of independent rules. These rules are subsequently
used to evaluate all data, selecting samples with the highest average scores
for downstream tasks such as LLM training. We verify the effectiveness of our
method through two experimental setups: 1) comparisons with ground truth
ratings and 2) benchmarking LLMs trained with the chosen data. Our
comprehensive experiments cover a range of scenarios, including general
pre-training and domain-specific fine-tuning in areas such as IMDB, Medical,
Math, and Code. The outcomes demonstrate that our DPP-based rule rating method
consistently outperforms other approaches, including rule-free rating, uniform
sampling, importance resampling, and QuRating, in terms of both rating
precision and model performance.

æè¦ï¼è¨ç·´è³æçåè³ªæé¡¯èå½±é¿å¤§åèªè¨æ¨¡å (LLM) çæè½ãææä¾æå¤ç ç©¶ä½¿ç¨ LLM ä¾è©åä¸¦æ ¹æå¤é äººçºå»ºç«çææ¨ (è¦å) é¸æè³æãç¶èï¼éäºå³çµ±çåºæ¼è¦åçæ¹æ³éå¸¸éåº¦ä¾è³´äººé¡çåç¼æ³ï¼ç¼ºä¹è©ä¼°è¦åçææææ¨ï¼ä¸å¨é©ææ°ä»»åæ¹é¢å±ç¾åºæéçéæ´»æ§ãå¨æåçç ç©¶ä¸­ï¼æåå¼é²ä¸ååµæ°çåºæ¼è¦åçæ¶æ§ï¼å®å©ç¨èè¦åç¸éè¯çåæ¸åéçæ­£äº¤æ§ä½çºè¦åè©ä¼°çæ°ææ¨ãæåçåæ³åæ¬ä¸åèªååæµç¨ï¼è©²æµç¨é¦åä½¿ç¨ LLM ç¢çä¸çµå¤æ¨£åçè¦åï¼æ¶µèåç¨®è©åé¢åä»¥è©ä¼°è³æåè³ªãæ¥èï¼å®æ ¹æéäºè¦åè©åä¸æ¹è³æï¼ä¸¦ä½¿ç¨é¨æ©ç©é£çè«ä¸­çè¡åå¼é»éç¨ (DPP) ä¾é¸åºææ­£äº¤çåæ¸åéï¼å¾èæ¾åºç¨ç«è¦åçéåãéäºè¦åé¨å¾ç¨æ¼è©ä¼°ææè³æï¼éå°ä¸æ¸¸ä»»åï¼ä¾å¦ LLM è¨ç·´ï¼é¸åºå¹³ååæ¸æé«çæ¨£æ¬ãæåééå©åå¯¦é©è¨­å®é©è­æåæ¹æ³çæææ§ï¼1) èçå¯¦è©åé²è¡æ¯è¼ï¼ä»¥å 2) å°ä½¿ç¨æé¸è³æè¨ç·´ç LLM é²è¡åºæºæ¸¬è©¦ãæåå¨é¢çå¯¦é©æ¶µèä¸ç³»åæå¢ï¼åæ¬å¨ IMDBãé«å­¸ãæ¸å­¸åç¨å¼ç¢¼ç­é åçä¸è¬é è¨ç·´åç¹å®é åçå¾®èª¿ãçµæé¡¯ç¤ºï¼æåçåºæ¼ DPP çè¦åè©åæ¹æ³å¨è©åç²¾æºåº¦åæ¨¡åæè½æ¹é¢å§çµåªæ¼å¶ä»æ¹æ³ï¼åæ¬ç¡è¦åè©åãåå»æ½æ¨£ãéè¦æ§åæ½æ¨£å QuRatingã

##### **Knowledge Graph Based Agent for Complex, Knowledge-Intensive QA in Medicine**
2410.04660v1 by Xiaorui Su, Yibo Wang, Shanghua Gao, Xiaolong Liu, Valentina Giunchiglia, Djork-ArnÃ© Clevert, Marinka Zitnik

Biomedical knowledge is uniquely complex and structured, requiring distinct
reasoning strategies compared to other scientific disciplines like physics or
chemistry. Biomedical scientists do not rely on a single approach to reasoning;
instead, they use various strategies, including rule-based, prototype-based,
and case-based reasoning. This diversity calls for flexible approaches that
accommodate multiple reasoning strategies while leveraging in-domain knowledge.
We introduce KGARevion, a knowledge graph (KG) based agent designed to address
the complexity of knowledge-intensive medical queries. Upon receiving a query,
KGARevion generates relevant triplets by using the knowledge base of the LLM.
These triplets are then verified against a grounded KG to filter out erroneous
information and ensure that only accurate, relevant data contribute to the
final answer. Unlike RAG-based models, this multi-step process ensures
robustness in reasoning while adapting to different models of medical
reasoning. Evaluations on four gold-standard medical QA datasets show that
KGARevion improves accuracy by over 5.2%, outperforming 15 models in handling
complex medical questions. To test its capabilities, we curated three new
medical QA datasets with varying levels of semantic complexity, where KGARevion
achieved a 10.4% improvement in accuracy.

æè¦ï¼çç©å»å­¦ç¥è­ç¨ç¹å°è¤éä¸çµæ§åï¼éè¦èå¶ä»ç§å­¸é åï¼å¦ç©çæåå­¸ï¼ä¸åçæ¨çç­ç¥ãçç©é«å­¸ç§å­¸å®¶ä¸ä¾è³´å®ä¸çæ¨çæ¹æ³ï¼ç¸åï¼ä»åä½¿ç¨åç¨®ç­ç¥ï¼åæ¬åºæ¼è¦åãåºæ¼ååååºæ¼æ¡ä¾çæ¨çãéç¨®å¤æ¨£æ§éè¦éæ´»çæ¹æ³ï¼åæå©ç¨é åç¥è­ä¾é©æå¤ç¨®æ¨çç­ç¥ãæåä»ç´¹äº KGARevionï¼éæ¯ä¸ååºæ¼ç¥è­åè­ (KG) çä»£çï¼æ¨å¨è§£æ±ºç¥è­å¯éåé«çæ¥è©¢çè¤éæ§ãå¨æ¶å°æ¥è©¢å¾ï¼KGARevion ä½¿ç¨ LLM çç¥è­åº«çæç¸éçä¸åçµãç¶å¾å°éäºä¸åçµèåºç¤ KG é²è¡é©è­ï¼ä»¥éæ¿¾æé¯èª¤ä¿¡æ¯ä¸¦ç¢ºä¿åªææºç¢ºãç¸éçæ¸ææå©æ¼æçµç­æ¡ãèåºæ¼ RAG çæ¨¡åä¸åï¼éç¨®å¤æ­¥é©éç¨ç¢ºä¿äºæ¨ççç©©å¥æ§ï¼åæé©æä¸åçé«çæ¨çæ¨¡åãå°ååé»éæ¨æºé«ç QA æ¸æéçè©ä¼°è¡¨æï¼KGARevion å°æºç¢ºçæé«äº 5.2%ï¼å¨èçè¤éçé«çåé¡æ¹é¢åªæ¼ 15 åæ¨¡åãçºäºæ¸¬è©¦å¶è½åï¼æåç­åäºä¸åæ°çé«ç QA æ¸æéï¼å·æä¸åçèªç¾©è¤éæ§ï¼å¶ä¸­ KGARevion å¨æºç¢ºçä¸æé«äº 10.4%ã

##### **Multi-Tiered Self-Contrastive Learning for Medical Microwave Radiometry (MWR) Breast Cancer Detection**
2410.04636v1 by Christoforos Galazis, Huiyi Wu, Igor Goryanin

The pursuit of enhanced breast cancer detection and monitoring techniques is
a paramount healthcare objective, driving the need for innovative imaging
technologies and diagnostic approaches. This study introduces a novel
multi-tiered self-contrastive model tailored for the application of microwave
radiometry (MWR) breast cancer detection. Our approach encompasses three
distinct models: Local-MWR (L-MWR), Regional-MWR (R-MWR), and Global-MWR
(G-MWR), each engineered to analyze varying sub-regional comparisons within the
breasts. These models are cohesively integrated through the Joint-MWR (J-MWR)
network, which leverages the self-contrastive data generated at each analytical
level to enhance detection capabilities. Employing a dataset comprising 4,932
cases of female patients, our research showcases the effectiveness of our
proposed models. Notably, the J-MWR model distinguishes itself by achieving a
Matthews correlation coefficient of 0.74 $\pm$ 0.018, surpassing existing MWR
neural networks and contrastive methods. These results highlight the
significant potential of self-contrastive learning techniques in improving both
the diagnostic accuracy and generalizability of MWR-based breast cancer
detection processes. Such advancements hold considerable promise for further
investigative and clinical endeavors. The source code is available at:
https://github.com/cgalaz01/self_contrastive_mwr

æè¦ï¼è¿½æ±å¢å¼·ä¹³çæª¢æ¸¬åç£æ¸¬æè¡æ¯ä¸é è³ééè¦çé«çä¿å¥ç®æ¨ï¼æ¨åäºåµæ°å½±åæè¡åè¨ºæ·æ¹æ³çéæ±ãæ¬ç ç©¶ä»ç´¹äºä¸ç¨®æ°ç©çå¤å±¤èªå°æ¯æ¨¡åï¼å°éç¨æ¼å¾®æ³¢è¼»å°æ¸¬é (MWR) ä¹³çæª¢æ¸¬ãæåçåæ³åå«ä¸åä¸åçæ¨¡åï¼å±é¨ MWR (L-MWR)ãåå MWR (R-MWR) åå¨å± MWR (G-MWR)ï¼æ¯åæ¨¡åé½è¨­è¨ç¨æ¼åæä¹³æ¿å§ä¸åçæ¬¡ååæ¯è¼ãéäºæ¨¡åééè¯å MWR (J-MWR) ç¶²è·¯ç·å¯æ´åï¼å©ç¨å¨æ¯ååæå±¤ç´ç¢ççèªå°æ¯è³æä¾å¢å¼·æª¢æ¸¬è½åãæåçç ç©¶æ¡ç¨åå« 4,932 ä¾å¥³æ§æ£èçè³æéï¼å±ç¤ºäºæåæåºçæ¨¡åçæææ§ãå¼å¾æ³¨æçæ¯ï¼J-MWR æ¨¡åä»¥éå° 0.74 Â± 0.018 çé¦¬ä¿®æ¯ç¸éä¿æ¸èåå¥æ¼å¶ä»æ¨¡åï¼è¶è¶äºç¾æç MWR ç¥ç¶ç¶²è·¯åå°æ¯æ¹æ³ãéäºçµæçªé¡¯äºèªå°æ¯å­¸ç¿æè¡å¨æ¹ååºæ¼ MWR çä¹³çæª¢æ¸¬ç¨åºçè¨ºæ·æºç¢ºæ§åæ¦æ¬æ§æ¹é¢å·æé¡¯èçæ½åãéäºé²å±çºé²ä¸æ­¥çèª¿æ¥åè¨åºå·¥ä½æä¾äºç¸ç¶å¤§çå¸æãåå§ç¢¼å¯å¨ä»¥ä¸ç¶²ååå¾ï¼https://github.com/cgalaz01/self_contrastive_mwr

##### **Semi-Markovian Planning to Coordinate Aerial and Maritime Medical Evacuation Platforms**
2410.04523v1 by Mahdi Al-Husseini, Kyle H. Wray, Mykel J. Kochenderfer

The transfer of patients between two aircraft using an underway watercraft
increases medical evacuation reach and flexibility in maritime environments.
The selection of any one of multiple underway watercraft for patient exchange
is complicated by participating aircraft utilization history and a
participating watercraft position and velocity. The selection problem is
modeled as a semi-Markov decision process with an action space including both
fixed land and moving watercraft exchange points. Monte Carlo tree search with
root parallelization is used to select optimal exchange points and determine
aircraft dispatch times. Model parameters are varied in simulation to identify
representative scenarios where watercraft exchange points reduce incident
response times. We find that an optimal policy with watercraft exchange points
outperforms an optimal policy without watercraft exchange points and a greedy
policy by 35% and 40%, respectively. In partnership with the United States
Army, we deploy for the first time the watercraft exchange point by executing a
mock patient transfer with a manikin between two HH-60M medical evacuation
helicopters and an underway Army Logistic Support Vessel south of the Hawaiian
island of Oahu. Both helicopters were dispatched in accordance with our
optimized decision strategy.

æè¦ï¼ä½¿ç¨èªè¡ä¸­çæ°´ä¸äº¤éå·¥å·å¨ä¸¤æ¶é£æºä¹é´è½¬è¿æ£èï¼å¯å¢å æµ·ä¸ç¯å¢ä¸­çå»çåéèå´åçµæ´»æ§ã
ç±äºåä¸é£æºçä½¿ç¨åå²ä»¥ååä¸æ°´ä¸äº¤éå·¥å·çä½ç½®åéåº¦ï¼éæ©å¤ä¸ªèªè¡ä¸­çæ°´ä¸äº¤éå·¥å·ä¸­çä»»ä½ä¸ä¸ªè¿è¡æ£èäº¤æ¢åå¾å¤æãéæ©é®é¢è¢«å»ºæ¨¡ä¸ºåé©¬å°å¯å¤«å³ç­è¿ç¨ï¼å¶å¨ä½ç©ºé´åæ¬åºå®éå°åç§»å¨æ°´ä¸äº¤éå·¥å·äº¤æ¢ç¹ãä½¿ç¨æ ¹å¹¶è¡åçèç¹å¡ç½æ æç´¢æ¥éæ©æä½³äº¤æ¢ç¹å¹¶ç¡®å®é£æºè°åº¦æ¶é´ãå¨ä»¿çä¸­æ¹åæ¨¡ååæ°ï¼ä»¥è¯å«æ°´ä¸äº¤éå·¥å·äº¤æ¢ç¹åå°äºä»¶ååºæ¶é´çä»£è¡¨æ§åºæ¯ãæä»¬åç°ï¼å·ææ°´ä¸äº¤éå·¥å·äº¤æ¢ç¹çæä¼ç­ç¥æ¯æ²¡ææ°´ä¸äº¤éå·¥å·äº¤æ¢ç¹çæä¼ç­ç¥åè´ªå©ªç­ç¥åå«é«åº 35% å 40%ãä¸ç¾å½éååä½ï¼æä»¬é¦æ¬¡éè¿å¨ä¸¤æ¶ HH-60M å»çåéç´åæºåå¤å¨å¤·æ¬§è¡å²åé¨èªè¡ä¸­çéååå¤æ¯æ´è¹ä¹é´æ§è¡æ¨¡ææ£èè½¬è¿ï¼é¨ç½²äºæ°´ä¸äº¤éå·¥å·äº¤æ¢ç¹ãä¸¤æ¶ç´åæºåæç§æä»¬ä¼åçå³ç­ç­ç¥è¿è¡è°åº¦ã

##### **RespDiff: An End-to-End Multi-scale RNN Diffusion Model for Respiratory Waveform Estimation from PPG Signals**
2410.04366v1 by Yuyang Miao, Zehua Chen, Chang Li, Danilo Mandic

Respiratory rate (RR) is a critical health indicator often monitored under
inconvenient scenarios, limiting its practicality for continuous monitoring.
Photoplethysmography (PPG) sensors, increasingly integrated into wearable
devices, offer a chance to continuously estimate RR in a portable manner. In
this paper, we propose RespDiff, an end-to-end multi-scale RNN diffusion model
for respiratory waveform estimation from PPG signals. RespDiff does not require
hand-crafted features or the exclusion of low-quality signal segments, making
it suitable for real-world scenarios. The model employs multi-scale encoders,
to extract features at different resolutions, and a bidirectional RNN to
process PPG signals and extract respiratory waveform. Additionally, a spectral
loss term is introduced to optimize the model further. Experiments conducted on
the BIDMC dataset demonstrate that RespDiff outperforms notable previous works,
achieving a mean absolute error (MAE) of 1.18 bpm for RR estimation while
others range from 1.66 to 2.15 bpm, showing its potential for robust and
accurate respiratory monitoring in real-world applications.

æè¦ï¼å¼å¸éç (RR) æ¯ä¸é éè¦çå¥åº·ææ¨ï¼éå¸¸å¨ä¸æ¹ä¾¿çææ³ä¸é²è¡ç£æ¸¬ï¼ééå¶äºå¶å¨æçºç£æ¸¬ä¸­çå¯¦ç¨æ§ãåé»å®¹ç©æè¨æ³ (PPG) ææ¸¬å¨æ¥çæ´åå°å¯ç©¿æ´è£ç½®ä¸­ï¼æä¾äºä¸ç¨®ä»¥å¯æå¼æ¹å¼æçºä¼°è¨ RR çæ©æãå¨æ¬æä¸­ï¼æåæåºäº RespDiffï¼éæ¯ä¸åç«¯å°ç«¯çå¤åè¾¨ç RNN æ´æ£æ¨¡åï¼ç¨æ¼å¾ PPG è¨èä¸­ä¼°è¨å¼å¸æ³¢å½¢ãRespDiff ä¸éè¦äººå·¥ç¹å¾µææé¤ä½åè³ªè¨èçæ®µï¼ä½¿å¶é©ç¨æ¼å¯¦éå ´æ¯ãè©²æ¨¡åæ¡ç¨å¤åè¾¨çç·¨ç¢¼å¨ï¼ä»¥ä¸åè§£æåº¦æåç¹å¾µï¼ä¸¦æ¡ç¨éå RNN ä¾èç PPG è¨èåæåå¼å¸æ³¢å½¢ãæ­¤å¤ï¼éå¼å¥äºé »è­æå¤±é ä»¥é²ä¸æ­¥æä½³åæ¨¡åãå¨ BIDMC è³æéä¸é²è¡çå¯¦é©è¡¨æï¼RespDiff åªæ¼ä¹åçé¡¯èç ç©¶ï¼å¨ RR ä¼°è¨ä¸­å¯¦ç¾äº 1.18 bpm çå¹³åçµå°èª¤å·® (MAE)ï¼èå¶ä»èª¤å·®ç¯åå¾ 1.66 å° 2.15 bpmï¼é¡¯ç¤ºäºå¶å¨å¯¦éæç¨ä¸­é²è¡ç©©å¥ä¸æºç¢ºçå¼å¸ç£æ¸¬çæ½åã

##### **Applying Quantum Autoencoders for Time Series Anomaly Detection**
2410.04154v2 by Robin Frehner, Kurt Stockinger

Anomaly detection is an important problem with applications in various
domains such as fraud detection, pattern recognition or medical diagnosis.
Several algorithms have been introduced using classical computing approaches.
However, using quantum computing for solving anomaly detection problems in time
series data is a widely unexplored research field.
  This paper explores the application of quantum autoencoders to time series
anomaly detection. We investigate two primary techniques for classifying
anomalies: (1) Analyzing the reconstruction error generated by the quantum
autoencoder and (2) latent representation analysis. Our simulated experimental
results, conducted across various ansaetze, demonstrate that quantum
autoencoders consistently outperform classical deep learning-based autoencoders
across multiple datasets. Specifically, quantum autoencoders achieve superior
anomaly detection performance while utilizing 60-230 times fewer parameters and
requiring five times fewer training iterations. In addition, we implement our
quantum encoder on real quantum hardware. Our experimental results demonstrate
that quantum autoencoders achieve anomaly detection performance on par with
their simulated counterparts.

æè¦ï¼ç°å¸¸åµæ¸¬æ¯ä¸åéè¦çåé¡ï¼å¨ååé åé½ææç¨ï¼ä¾å¦è©æ¬ºåµæ¸¬ãæ¨¡å¼è¾¨è­æé«çè¨ºæ·ã
å·²ç¶æä½¿ç¨å³çµ±éç®æ¹æ³æåºçå¤ç¨®æ¼ç®æ³ã
ç¶èï¼ä½¿ç¨éå­éç®ä¾è§£æ±ºæéåºåè³æä¸­çç°å¸¸åµæ¸¬åé¡æ¯ä¸åå»£æ³æªéç¼çç ç©¶é åã
æ¬ææ¢è¨éå­èªåç·¨ç¢¼å¨å¨æéåºåç°å¸¸åµæ¸¬çæç¨ãæåç ç©¶äºå©ç¨®åé¡ç°å¸¸çä¸»è¦æè¡ï¼(1) åæéå­èªåç·¨ç¢¼å¨ç¢ççéå»ºèª¤å·®ï¼ä»¥å (2) æ½å¨è¡¨ç¤ºåæãæåå¨åç¨® ansaetze ä¸é²è¡æ¨¡æ¬å¯¦é©ï¼çµæè¡¨æï¼éå­èªåç·¨ç¢¼å¨å¨å¤åè³æéä¸å§çµåªæ¼åºæ¼ç¶å¸æ·±åº¦å­¸ç¿çèªåç·¨ç¢¼å¨ãå·é«ä¾èªªï¼éå­èªåç·¨ç¢¼å¨å¨ä½¿ç¨å° 60-230 åçåæ¸åéè¦å°äºåçè¨ç·´åè¦éç®çææ³ä¸ï¼å¯¦ç¾äºåè¶çç°å¸¸åµæ¸¬æè½ãæ­¤å¤ï¼æåå¨çå¯¦éå­ç¡¬é«ä¸å¯¦ç¾äºæåçéå­ç·¨ç¢¼å¨ãæåçå¯¦é©çµæè¡¨æï¼éå­èªåç·¨ç¢¼å¨å¯¦ç¾äºèå¶æ¨¡æ¬å°æç©ç¸ç¶çç°å¸¸åµæ¸¬æè½ã

##### **DAMMI:Daily Activities in a Psychologically Annotated Multi-Modal IoT dataset**
2410.04152v1 by Mohsen Falah Rad, Kamrad Khoshhal Roudposhti, Mohammad Hassan Khoobkar, Mohsen Shirali, Zahra Ahmadi, Carlos Fernandez-Llatas

The growth in the elderly population and the shift in the age pyramid have
increased the demand for healthcare and well-being services. To address this
concern, alongside the rising cost of medical care, the concept of ageing at
home has emerged, driven by recent advances in medical and technological
solutions. Experts in computer science, communication technology, and
healthcare have collaborated to develop affordable health solutions by
employing sensors in living environments, wearable devices, and smartphones, in
association with advanced data mining and intelligent systems with learning
capabilities, to monitor, analyze, and predict the health status of elderly
individuals. However, implementing intelligent healthcare systems and
developing analytical techniques requires testing and evaluating algorithms on
real-world data. Despite the need, there is a shortage of publicly available
datasets that meet these requirements. To address this gap, we present the
DAMMI dataset in this work, designed to support researchers in the field. The
dataset includes daily activity data of an elderly individual collected via
home-installed sensors, smartphone data, and a wristband over 146 days. It also
contains daily psychological reports provided by a team of psychologists.
Furthermore, the data collection spans significant events such as the COVID-19
pandemic, New Year's holidays, and the religious month of Ramadan, offering
additional opportunities for analysis. In this paper, we outline detailed
information about the data collection system, the types of data recorded, and
pre-processed event logs. This dataset is intended to assist professionals in
IoT and data mining in evaluating and implementing their research ideas.

æè¦ï¼é¨èèå¹´äººå£çå¢é·åå¹´é½¡éå­å¡çè½è®ï¼å°é«çä¿å¥åç¦ç¥æåçéæ±ä¹é¨ä¹å¢å ãçºäºè§£æ±ºéååé¡ï¼å ä¸é«çä¿å¥ææ¬çä¸åï¼å¨å®¶ä¸­èåçæ¦å¿µæéèçï¼éå¾çæ¼é«çåæè¡è§£æ±ºæ¹æ¡çææ°é²å±ãé»è¦ç§å­¸ãéè¨æè¡åé«çä¿å¥æ¹é¢çå°å®¶åä½éç¼äºç¶æ¿å¯¦æ çå¥åº·è§£æ±ºæ¹æ¡ï¼æ¹æ³æ¯å¨çæ´»ç°å¢ä¸­ä½¿ç¨ææ¸¬å¨ãç©¿æ´å¼è£ç½®åæºæ§åææ©ï¼ä¸¦çµååé²çè³ææ¢ååå·åå­¸ç¿è½åçæºæ§ç³»çµ±ï¼ä¾ç£æ§ãåæåé æ¸¬èå¹´äººçå¥åº·çæ³ãç¶èï¼å¯¦æ½æºæ§åé«çä¿å¥ç³»çµ±åéç¼åææè¡éè¦å¨çå¯¦ä¸çè³æä¸æ¸¬è©¦åè©ä¼°æ¼ç®æ³ãåç®¡æéåéæ±ï¼ä½ç¬¦åéäºè¦æ±çå¬éå¯ç¨è³æéå»å¾ç¼ºä¹ãçºäºè§£æ±ºéåå·®è·ï¼æåå¨éé å·¥ä½ä¸­æåºäº DAMMI è³æéï¼æ¨å¨æ¯æ´è©²é åçç ç©¶äººå¡ãè©²è³æéåæ¬ééå®è£å¨å®¶çææ¸¬å¨ãæºæ§åææ©è³æåä¸åæç°å¨ 146 å¤©å§æ¶éå°çèå¹´äººæ¥å¸¸æ´»åè³æãå®éåå«ç±å¿çå­¸å®¶åéæä¾çæ¯æ¥å¿çå ±åãæ­¤å¤ï¼è³ææ¶éæ¶µèäºéè¦çäºä»¶ï¼ä¾å¦ COVID-19 å¤§æµè¡ãæ°å¹´åæåé½ææï¼çºåææä¾äºé¡å¤çæ©æãå¨æ¬æä¸­ï¼æåæ¦è¿°äºæéè³ææ¶éç³»çµ±ãè¨éçè³æé¡ååé èçäºä»¶è¨éçè©³ç´°è³è¨ãæ­¤è³æéæ¨å¨åå©ç©è¯ç¶²åè³ææ¢åæ¹é¢çå°æ¥­äººå¡è©ä¼°åå¯¦æ½å¶ç ç©¶æ§æ³ã

##### **From Hospital to Portables: A Universal ECG Foundation Model Built on 10+ Million Diverse Recordings**
2410.04133v1 by Jun Li, Aaron Aguirre, Junior Moura, Che Liu, Lanhai Zhong, Chenxi Sun, Gari Clifford, Brandon Westover, Shenda Hong

Artificial Intelligence (AI) has shown great promise in electrocardiogram
(ECG) analysis and cardiovascular disease detection. However, developing a
general AI-ECG model has been challenging due to inter-individual variability
and the diversity of ECG diagnoses, limiting existing models to specific
diagnostic tasks and datasets. Moreover, current AI-ECG models struggle to
achieve comparable performance between single-lead and 12-lead ECGs, limiting
the application of AI-ECG to portable and wearable ECG devices. To address
these limitations, we introduce an ECG Foundation Model (ECGFounder), a
general-purpose model that leverages real-world ECG annotations from cardiology
experts to broaden the diagnostic capabilities of ECG analysis. ECGFounder is
trained on over 10 million ECGs with 150 label categories from the
Harvard-Emory ECG Database, enabling comprehensive cardiovascular disease
diagnosis through ECG analysis. The model is designed to be both effective
out-of-the-box and fine-tunable for downstream tasks, maximizing usability.
More importantly, we extend its application to single-lead ECGs, enabling
complex condition diagnoses and supporting various downstream tasks in mobile
and remote monitoring scenarios. Experimental results demonstrate that
ECGFounder achieves expert-level performance on internal validation sets for
both 12-lead and single-lead ECGs, while also exhibiting strong classification
performance and generalization across various diagnoses on external validation
sets. When fine-tuned, ECGFounder outperforms baseline models in demographics
detection, clinical event detection, and cross-modality cardiac rhythm
diagnosis. The trained model and data will be publicly released upon
publication through the bdsp.io. Our code is available at
https://github.com/bdsp-core/ECGFounder.

æè¦ï¼äººå·¥æºæ§ï¼AIï¼å¨å¿é»åï¼ECGï¼åæåå¿è¡ç®¡ç¾çæª¢æ¸¬æ¹é¢å·²å±ç¾æ¥µä½³çåæ¯ãç¶èï¼ç±æ¼åé«éè®ç°æ§å ECG è¨ºæ·çå¤æ¨£æ§ï¼éç¼éç¨ AI-ECG æ¨¡åä¸ç´æ¯ä¸é ææ°ï¼ééå¶äºç¾ææ¨¡ååªè½ç¨æ¼ç¹å®çè¨ºæ·ä»»ååè³æéãæ­¤å¤ï¼ç®åç AI-ECG æ¨¡åé£ä»¥å¨å®å°ç¨å 12 å°ç¨ ECG ä¹éåå¾ç¸ç¶çæè½ï¼ééå¶äº AI-ECG æç¨æ¼å¯æå¼åå¯ç©¿æ´ ECG è£ç½®ãçºäºåæéäºéå¶ï¼æåå¼é²äºä¸ç¨® ECG åºç¤æ¨¡åï¼ECGFounderï¼ï¼éæ¯ä¸ç¨®éç¨æ¨¡åï¼å®å©ç¨ä¾èªå¿èçå°å®¶ççå¯¦ä¸ç ECG æ¨è¨»ï¼ä»¥æ´å± ECG åæçè¨ºæ·è½åãECGFounder ç¶ç±åä½-è¾é»é ECG è³æåº«ä¸­è¶é 1 åè¬å ECG å 150 åæ¨ç±¤é¡å¥é²è¡è¨ç·´ï¼è½éé ECG åæé²è¡å¨é¢çå¿è¡ç®¡ç¾çè¨ºæ·ãè©²æ¨¡åè¢«è¨­è¨çºéç®±å³ç¨ä¸å¯å¾®èª¿ä»¥é²è¡ä¸æ¸¸ä»»åï¼ä»¥æå¤§åå¯ç¨æ§ãæ´éè¦çæ¯ï¼æåå°å¶æç¨å»¶ä¼¸è³å®å°ç¨ ECGï¼è½é²è¡è¤éçæ³è¨ºæ·ï¼ä¸¦æ¯æ´è¡ååé ç«¯ç£æ§æå¢ä¸­çåç¨®ä¸æ¸¸ä»»åãå¯¦é©çµæé¡¯ç¤ºï¼ECGFounder å¨ 12 å°ç¨åå®å°ç¨ ECG çå§é¨é©è­éä¸­éå°äºå°å®¶ç´çæè½ï¼åæå¨å¤é¨é©è­éä¸­å°åç¨®è¨ºæ·ä¹å±ç¾åºå¼·å¤§çåé¡æè½åæ³åè½åãç¶éå¾®èª¿å¾ï¼ECGFounder å¨äººå£çµ±è¨è³ææª¢æ¸¬ãè¨åºäºä»¶æª¢æ¸¬åè·¨æ¨¡æå¿å¾è¨ºæ·æ¹é¢åªæ¼åºæºæ¨¡åãè¨ç·´å¥½çæ¨¡ååè³æå°å¨åºçå¾éé bdsp.io å¬éç¼å¸ãæåçç¨å¼ç¢¼å¯å¨ https://github.com/bdsp-core/ECGFounder åå¾ã

##### **Taming the Tail: Leveraging Asymmetric Loss and Pade Approximation to Overcome Medical Image Long-Tailed Class Imbalance**
2410.04084v1 by Pankhi Kashyap, Pavni Tandon, Sunny Gupta, Abhishek Tiwari, Ritwik Kulkarni, Kshitij Sharad Jadhav

Long-tailed problems in healthcare emerge from data imbalance due to
variability in the prevalence and representation of different medical
conditions, warranting the requirement of precise and dependable classification
methods. Traditional loss functions such as cross-entropy and binary
cross-entropy are often inadequate due to their inability to address the
imbalances between the classes with high representation and the classes with
low representation found in medical image datasets. We introduce a novel
polynomial loss function based on Pade approximation, designed specifically to
overcome the challenges associated with long-tailed classification. This
approach incorporates asymmetric sampling techniques to better classify
under-represented classes. We conducted extensive evaluations on three publicly
available medical datasets and a proprietary medical dataset. Our
implementation of the proposed loss function is open-sourced in the public
repository:https://github.com/ipankhi/ALPA.

æè¦ï¼é«çä¿å¥ä¸­çé·å°¾åé¡æºæ¼æ¸æä¸å¹³è¡¡ï¼éæ¯ç±æ¼ä¸åé«ççæ³çæµè¡çåè¡¨ç¾å­å¨è®ç°æ§ï¼éä¿è­äºå°ç²¾ç¢ºä¸å¯é çåé¡æ¹æ³çéæ±ãå³çµ±æå¤±å½æ¸ï¼ä¾å¦äº¤åçµåäºåäº¤åçµï¼éå¸¸ä¸è¶³ï¼å çºå®åç¡æ³è§£æ±ºé«çå½±åè³æéä¸­è¡¨ç¤ºçé«çé¡å¥èè¡¨ç¤ºçä½çé¡å¥ä¹éçä¸å¹³è¡¡ãæåå¼å¥äºä¸ç¨®åºæ¼ Pade è¿ä¼¼çå¤é å¼æå¤±å½æ¸ï¼å°éè¨­è¨ç¨æ¼åæèé·å°¾åé¡ç¸éçææ°ãæ­¤æ¹æ³çµåäºéå°ç¨±æ½æ¨£æè¡ï¼ä»¥æ´å¥½å°å°ä»£è¡¨æ§ä¸è¶³çé¡å¥é²è¡åé¡ãæåå°ä¸åå¬éçé«çè³æéåä¸åå°æé«çè³æéé²è¡äºå»£æ³çè©ä¼°ãæåå°æè­°æå¤±å½æ¸çå¯¦ä½å·²å¨å¬å±å²å­åº«ä¸­éæºï¼https://github.com/ipankhi/ALPAã

##### **Still Not Quite There! Evaluating Large Language Models for Comorbid Mental Health Diagnosis**
2410.03908v1 by Amey Hengle, Atharva Kulkarni, Shantanu Patankar, Madhumitha Chandrasekaran, Sneha D'Silva, Jemima Jacob, Rashmi Gupta

In this study, we introduce ANGST, a novel, first-of-its kind benchmark for
depression-anxiety comorbidity classification from social media posts. Unlike
contemporary datasets that often oversimplify the intricate interplay between
different mental health disorders by treating them as isolated conditions,
ANGST enables multi-label classification, allowing each post to be
simultaneously identified as indicating depression and/or anxiety. Comprising
2876 meticulously annotated posts by expert psychologists and an additional
7667 silver-labeled posts, ANGST posits a more representative sample of online
mental health discourse. Moreover, we benchmark ANGST using various
state-of-the-art language models, ranging from Mental-BERT to GPT-4. Our
results provide significant insights into the capabilities and limitations of
these models in complex diagnostic scenarios. While GPT-4 generally outperforms
other models, none achieve an F1 score exceeding 72% in multi-class comorbid
classification, underscoring the ongoing challenges in applying language models
to mental health diagnostics.

æè¦ï¼å¨éé ç ç©¶ä¸­ï¼æåä»ç´¹ ANGSTï¼éæ¯ä¸åæ°ç©çãåé¡é¦åµçåºæºï¼ç¨æ¼å¾ç¤¾ç¾¤åªé«è²¼æä¸­åé¡æé¬±çåç¦æ®çå±çãèç¶ä»£çè³æéä¸åï¼ç¶ä»£çè³æééå¸¸æéåº¦ç°¡åä¸åå¿çå¥åº·éç¤ä¹éçè¤éäº¤äºä½ç¨ï¼å°å®åè¦çºå­¤ç«ççæ³ï¼è ANGST è½å¤ é²è¡å¤æ¨ç±¤åé¡ï¼è®æ¯åè²¼æé½è½åæè¢«è¾¨è­çºè¡¨ç¤ºæé¬±çå/æç¦æ®çãANGST åå«äº 2876 åç±å°å®¶å¿çå­¸å®¶ä»ç´°è¨»è§£çè²¼æï¼ä»¥åå¦å¤ 7667 åæ¨è¨çºéç´çè²¼æï¼å®æåºäºæ´å·ä»£è¡¨æ§çç·ä¸å¿çå¥åº·è«è¿°ç¯ä¾ãæ­¤å¤ï¼æåä½¿ç¨å¾ Mental-BERT å° GPT-4 ç­åç¨®æåé²çèªè¨æ¨¡åå° ANGST é²è¡åºæºæ¸¬è©¦ãæåççµææä¾äºéè¦çè¦è§£ï¼èªªæäºéäºæ¨¡åå¨è¤éçè¨ºæ·æå¢ä¸­çè½ååéå¶ãéç¶ GPT-4 éå¸¸åªæ¼å¶ä»æ¨¡åï¼ä½æ²æä»»ä½æ¨¡åå¨å¤é¡å±çåé¡ä¸­éå°è¶é 72% ç F1 åæ¸ï¼éå¸é¡¯äºå°èªè¨æ¨¡åæç¨æ¼å¿çå¥åº·è¨ºæ·çæçºææ°ã

##### **Not All Diffusion Model Activations Have Been Evaluated as Discriminative Features**
2410.03558v2 by Benyuan Meng, Qianqian Xu, Zitai Wang, Xiaochun Cao, Qingming Huang

Diffusion models are initially designed for image generation. Recent research
shows that the internal signals within their backbones, named activations, can
also serve as dense features for various discriminative tasks such as semantic
segmentation. Given numerous activations, selecting a small yet effective
subset poses a fundamental problem. To this end, the early study of this field
performs a large-scale quantitative comparison of the discriminative ability of
the activations. However, we find that many potential activations have not been
evaluated, such as the queries and keys used to compute attention scores.
Moreover, recent advancements in diffusion architectures bring many new
activations, such as those within embedded ViT modules. Both combined,
activation selection remains unresolved but overlooked. To tackle this issue,
this paper takes a further step with a much broader range of activations
evaluated. Considering the significant increase in activations, a full-scale
quantitative comparison is no longer operational. Instead, we seek to
understand the properties of these activations, such that the activations that
are clearly inferior can be filtered out in advance via simple qualitative
evaluation. After careful analysis, we discover three properties universal
among diffusion models, enabling this study to go beyond specific models. On
top of this, we present effective feature selection solutions for several
popular diffusion models. Finally, the experiments across multiple
discriminative tasks validate the superiority of our method over the SOTA
competitors. Our code is available at
https://github.com/Darkbblue/generic-diffusion-feature.

æè¦ï¼æ´æ£æ¨¡åæåæ¯çºå½±åçæèè¨­è¨ãæè¿çç ç©¶é¡¯ç¤ºï¼å¶ä¸»å¹¹ä¸­çå§é¨è¨èï¼ç¨±çºæ¿æ´»ï¼ä¹å¯ä»¥ä½çºåç¨®å¤å¥ä»»åï¼ä¾å¦èªæåå²ï¼çç¨ å¯ç¹å¾µãå¨çµ¦å®å¤§éæ¿æ´»çææ³ä¸ï¼é¸æä¸åå°ä½ææçå­éæ¯ä¸ååºæ¬åé¡ãçºæ­¤ï¼æ­¤é åçæ©æç ç©¶å°æ¿æ´»çå¤å¥è½åé²è¡äºå¤§è¦æ¨¡çå®éæ¯è¼ãç¶èï¼æåç¼ç¾è¨±å¤æ½å¨çæ¿æ´»å°æªç¶éè©ä¼°ï¼ä¾å¦ç¨æ¼è¨ç®æ³¨æååæ¸çæ¥è©¢åéµãæ­¤å¤ï¼æ´æ£æ¶æ§çææ°é²å±å¸¶ä¾äºè¨±å¤æ°çæ¿æ´»ï¼ä¾å¦åµå¥å¼ ViT æ¨¡çµä¸­çé£äºãå©èçµåï¼æ¿æ´»é¸æä»ç¶æªè§£æ±ºï¼ä½è¢«å¿½è¦äºãçºäºè§£æ±ºéååé¡ï¼æ¬ææ¡ç¨æ´å»£æ³çæ¿æ´»è©ä¼°ç¯åï¼é²ä¸æ­¥éåºäºä¸æ­¥ãèæ®å°æ¿æ´»çé¡¯èå¢å ï¼å¨é¢å®éæ¯è¼ä¸åå¯è¡ãç¸åï¼æåå°æ±äºè§£éäºæ¿æ´»çç¹æ§ï¼ä»¥ä¾¿å¯ä»¥ééç°¡å®çå®æ§è©ä¼°äºåç¯©é¸åºæé¡¯è¼å·®çæ¿æ´»ãç¶éä»ç´°åæï¼æåç¼ç¾æ´æ£æ¨¡åä¸­æ®éå­å¨ä¸åç¹æ§ï¼ä½¿æ¬ç ç©¶è½å¤ è¶è¶ç¹å®æ¨¡åãé¤æ­¤ä¹å¤ï¼æåéå°å¹¾ç¨®æµè¡çæ´æ£æ¨¡åæåºäºææçç¹å¾µé¸æè§£æ±ºæ¹æ¡ãæå¾ï¼è·¨å¤åå¤å¥ä»»åçå¯¦é©é©è­äºæåçæ¹æ³åªæ¼ SOTA ç«¶ç­å°æãæåçç¨å¼ç¢¼å¯å¨ https://github.com/Darkbblue/generic-diffusion-feature åå¾ã

##### **Towards Real-time Intrahepatic Vessel Identification in Intraoperative Ultrasound-Guided Liver Surgery**
2410.03420v2 by Karl-Philippe Beaudet, Alexandros Karargyris, Sidaty El Hadramy, StÃ©phane Cotin, Jean-Paul Mazellier, Nicolas Padoy, Juan Verde

While laparoscopic liver resection is less prone to complications and
maintains patient outcomes compared to traditional open surgery, its complexity
hinders widespread adoption due to challenges in representing the liver's
internal structure. Laparoscopic intraoperative ultrasound offers efficient,
cost-effective and radiation-free guidance. Our objective is to aid physicians
in identifying internal liver structures using laparoscopic intraoperative
ultrasound. We propose a patient-specific approach using preoperative 3D
ultrasound liver volume to train a deep learning model for real-time
identification of portal tree and branch structures. Our personalized AI model,
validated on ex vivo swine livers, achieved superior precision (0.95) and
recall (0.93) compared to surgeons, laying groundwork for precise vessel
identification in ultrasound-based liver resection. Its adaptability and
potential clinical impact promise to advance surgical interventions and improve
patient care.

æè¦ï¼è¹èé¡èåé¤è¡èå³çµ±éæ¾å¼æè¡ç¸æ¯ï¼è¼ä¸æç¢çä½µç¼çï¼ä¸è½ç¶­ææ£èçæ²»ççµæï¼ä½å¶è¤éæ§é»ç¤äºå»£æ³æ¡ç¨ï¼åå å¨æ¼é£ä»¥åç¾èèçå§é¨çµæ§ãè¹èé¡è¡ä¸­è¶é³æ³¢æä¾ææãç¶æ¿ä¸ç¡è¼»å°çå°å¼ãæåçç®æ¨æ¯åå©é«å¸«ä½¿ç¨è¹èé¡è¡ä¸­è¶é³æ³¢ä¾è¾¨è­èèçå§é¨çµæ§ãæåæåºä¸åä½¿ç¨è¡å 3D è¶é³æ³¢èèé«ç©ä¾è¨ç·´æ·±åº¦å­¸ç¿æ¨¡åï¼ä»¥å³æè¾¨è­éèæ¨¹ååæ¯çµæ§çæ£èç¹å®æ¹æ³ãæåçåäººåäººå·¥æºæ§æ¨¡åå¨é¢é«è±¬èèä¸é©è­ï¼èå¤ç§é«å¸«ç¸æ¯ï¼éå°äºæ´é«çç²¾ç¢ºåº¦ (0.95) åå¬åç (0.93)ï¼çºåºæ¼è¶é³æ³¢çèèåé¤è¡ä¸­ç²¾ç¢ºè¡ç®¡è¾¨è­å¥ å®äºåºç¤ãå¶é©ææ§åæ½å¨çè¨åºå½±é¿æææ¨é²å¤ç§æè¡ï¼ä¸¦æ¹åæ£èç§è­·ã

##### **Make Interval Bound Propagation great again**
2410.03373v1 by Patryk Krukowski, Daniel Wilczak, Jacek Tabor, Anna Bielawska, PrzemysÅaw Spurek

In various scenarios motivated by real life, such as medical data analysis,
autonomous driving, and adversarial training, we are interested in robust deep
networks. A network is robust when a relatively small perturbation of the input
cannot lead to drastic changes in output (like change of class, etc.). This
falls under the broader scope field of Neural Network Certification (NNC). Two
crucial problems in NNC are of profound interest to the scientific community:
how to calculate the robustness of a given pre-trained network and how to
construct robust networks. The common approach to constructing robust networks
is Interval Bound Propagation (IBP). This paper demonstrates that IBP is
sub-optimal in the first case due to its susceptibility to the wrapping effect.
Even for linear activation, IBP gives strongly sub-optimal bounds.
Consequently, one should use strategies immune to the wrapping effect to obtain
bounds close to optimal ones. We adapt two classical approaches dedicated to
strict computations -- Dubleton Arithmetic and Affine Arithmetic -- to mitigate
the wrapping effect in neural networks. These techniques yield precise results
for networks with linear activation functions, thus resisting the wrapping
effect. As a result, we achieve bounds significantly closer to the optimal
level than IBPs.

æè¦ï¼å¨åç¨®åç¾å¯¦çæ´»æ¿åµçå ´æ¯ä¸­ï¼ä¾å¦é«å­¸æ¸æåæãèªåé§é§åå°ææ§è¨ç·´ï¼æåå°å¼·å¥çæ·±åº¦ç¶²è·¯æèè¶£ãç¶è¼¸å¥çå¾®å°æ¾åä¸æå°è´è¼¸åºç¼çåçè®åï¼ä¾å¦é¡å¥æ¹è®ç­ï¼æï¼ç¶²è·¯å°±æ¯å¼·å¥çãéå±¬æ¼ç¥ç¶ç¶²è·¯èªè­ (NNC) çå»£æ³ç¯çãNNC ä¸­çå©åééµåé¡å¼èµ·äºç§å­¸ççæ¿åèè¶£ï¼å¦ä½è¨ç®çµ¦å®é è¨ç·´ç¶²è·¯çå¼·å¥æ§ï¼ä»¥åå¦ä½æ§å»ºå¼·å¥ç¶²è·¯ãæ§å»ºå¼·å¥ç¶²è·¯çå¸¸è¦æ¹æ³æ¯åééçå³æ­ (IBP)ãæ¬æè­æï¼ç±æ¼ IBP å®¹æåå°åè¦ææçå½±é¿ï¼å æ­¤å¨ç¬¬ä¸ç¨®ææ³ä¸å®æ¯æ¬¡åªçãå³ä½¿å°æ¼ç·æ§æ¿æ´»ï¼IBP ä¹æçµ¦åºå¼·ççæ¬¡åªéçãå æ­¤ï¼æä½¿ç¨å°åè¦ææåç«çç­ç¥ä¾ç²å¾æ¥è¿æåªéççéçãæåèª¿æ´äºå°éç¨æ¼å´æ ¼è¨ç®çå©ç¨®ç¶å¸æ¹æ³ââéåéç®åä»¿å°éç®ââä»¥æ¸è¼ç¥ç¶ç¶²è·¯ä¸­çåè¦ææãéäºæè¡å°å·æç·æ§æ¿æ´»å½æ¸çç¶²è·¯ç¢çç²¾ç¢ºççµæï¼å¾èæµæåè¦ææãå æ­¤ï¼æåå¯¦ç¾çéçé¡¯èæ¥è¿æ¼ IBP çæåªç´å¥ã

##### **An Enhanced Harmonic Densely Connected Hybrid Transformer Network Architecture for Chronic Wound Segmentation Utilising Multi-Colour Space Tensor Merging**
2410.03359v1 by Bill Cassidy, Christian Mcbride, Connah Kendrick, Neil D. Reeves, Joseph M. Pappachan, Cornelius J. Fernandez, Elias Chacko, Raphael BrÃ¼ngel, Christoph M. Friedrich, Metib Alotaibi, Abdullah Abdulaziz AlWabel, Mohammad Alderwish, Kuan-Ying Lai, Moi Hoon Yap

Chronic wounds and associated complications present ever growing burdens for
clinics and hospitals world wide. Venous, arterial, diabetic, and pressure
wounds are becoming increasingly common globally. These conditions can result
in highly debilitating repercussions for those affected, with limb amputations
and increased mortality risk resulting from infection becoming more common. New
methods to assist clinicians in chronic wound care are therefore vital to
maintain high quality care standards. This paper presents an improved HarDNet
segmentation architecture which integrates a contrast-eliminating component in
the initial layers of the network to enhance feature learning. We also utilise
a multi-colour space tensor merging process and adjust the harmonic shape of
the convolution blocks to facilitate these additional features. We train our
proposed model using wound images from light-skinned patients and test the
model on two test sets (one set with ground truth, and one without) comprising
only darker-skinned cases. Subjective ratings are obtained from clinical wound
experts with intraclass correlation coefficient used to determine inter-rater
reliability. For the dark-skin tone test set with ground truth, we demonstrate
improvements in terms of Dice similarity coefficient (+0.1221) and intersection
over union (+0.1274). Qualitative analysis showed high expert ratings, with
improvements of >3% demonstrated when comparing the baseline model with the
proposed model. This paper presents the first study to focus on darker-skin
tones for chronic wound segmentation using models trained only on wound images
exhibiting lighter skin. Diabetes is highly prevalent in countries where
patients have darker skin tones, highlighting the need for a greater focus on
such cases. Additionally, we conduct the largest qualitative study to date for
chronic wound segmentation.

æè¦ï¼<paragraph>æ¢æ§å·å£åå¶ä½µç¼çå°å¨çè¨ºæåé«é¢èè¨ï¼å¸¶ä¾æ¥çæ²éçè² æãéèæ§ãåèæ§ãç³å°¿çæ§åå£ç¡å¨å¨çæä¾ææ®éãéäºç¾çæå°æ£èé æé«åº¦è¡°å¼±çå½±é¿ï¼æªè¢åå ææèå°è´çæ­»äº¡é¢¨éªä¹æ¥çæ®éãå æ­¤ï¼æ°çæ¹æ³åå©è¨åºé«çé²è¡æ¢æ§å·å£ç§è­·è³ééè¦ï¼ä»¥ç¶­æé«åè³ªçç§è­·æ¨æºãæ¬ææåºä¸åæ¹è¯ç HarDNet åå²æ¶æ§ï¼å°å°æ¯æ¶é¤åä»¶æ´åå°ç¶²è·¯çåå§å±¤ï¼ä»¥å¢å¼·ç¹å¾µå­¸ç¿ãæåä¹å©ç¨å¤è²å½©ç©ºéå¼µéåä½µç¨åºï¼ä¸¦èª¿æ´å·ç©åå¡çè«§æ³¢å½¢çï¼ä»¥å©æ¼éäºé¡å¤ç¹å¾µãæåä½¿ç¨æ·ºèè²æ£èçå·å£å½±åè¨ç·´æåæåºçæ¨¡åï¼ä¸¦å¨å©åæ¸¬è©¦çµï¼ä¸åçµæåºæ¬äºå¯¦ï¼ä¸åçµæ²æï¼ä¸æ¸¬è©¦æ¨¡åï¼éäºçµååå«è¼æ·±èè²ççä¾ãå¾è¨åºå·å£å°å®¶åå¾ä¸»è§è©åï¼ä¸¦ä½¿ç¨é¡å§ç¸éä¿æ¸ä¾ç¢ºå®è©åèéä¿¡è³´åº¦ãå°æ¼æåºæ¬äºå¯¦çæ·±èè²æ¸¬è©¦çµï¼æåå±ç¤ºäºéª°å­ç¸ä¼¼ä¿æ¸ (+0.1221) åè¯éæ¯äº¤é (+0.1274) çæ¹é²ãå®æ§åæé¡¯ç¤ºå°å®¶è©åå¾é«ï¼èåºæºæ¨¡åç¸æ¯ï¼æåºçæ¨¡åé¡¯ç¤ºåº >3% çæ¹é²ãæ¬ææåºç¬¬ä¸åç ç©¶ï¼å°æ³¨æ¼ä½¿ç¨åå¨è¡¨ç¾åºè¼æ·ºèè²çå·å£å½±åä¸è¨ç·´çæ¨¡åï¼é²è¡æ·±èè²æ¢æ§å·å£åå²ãç³å°¿çå¨æ£èèè²è¼æ·±çåå®¶éå¸¸æ®éï¼å¼·èª¿éè¦æ´å¤éæ³¨æ­¤é¡çä¾ãæ­¤å¤ï¼æåé²è¡äºè¿ä»çºæ­¢æå¤§çæ¢æ§å·å£åå²å®æ§ç ç©¶ã</paragraph>

##### **Comparative Analysis and Ensemble Enhancement of Leading CNN Architectures for Breast Cancer Classification**
2410.03333v1 by Gary Murphy, Raghubir Singh

This study introduces a novel and accurate approach to breast cancer
classification using histopathology images. It systematically compares leading
Convolutional Neural Network (CNN) models across varying image datasets,
identifies their optimal hyperparameters, and ranks them based on
classification efficacy. To maximize classification accuracy for each model we
explore, the effects of data augmentation, alternative fully-connected layers,
model training hyperparameter settings, and, the advantages of retraining
models versus using pre-trained weights. Our methodology includes several
original concepts, including serializing generated datasets to ensure
consistent data conditions across training runs and significantly reducing
training duration. Combined with automated curation of results, this enabled
the exploration of over 2,000 training permutations -- such a comprehensive
comparison is as yet unprecedented. Our findings establish the settings
required to achieve exceptional classification accuracy for standalone CNN
models and rank them by model efficacy. Based on these results, we propose
ensemble architectures that stack three high-performing standalone CNN models
together with diverse classifiers, resulting in improved classification
accuracy. The ability to systematically run so many model permutations to get
the best outcomes gives rise to very high quality results, including 99.75% for
BreakHis x40 and BreakHis x200 and 95.18% for the Bach datasets when split into
train, validation and test datasets. The Bach Online blind challenge, yielded
89% using this approach. Whilst this study is based on breast cancer
histopathology image datasets, the methodology is equally applicable to other
medical image datasets.

æè¦ï¼æ¬ç ç©¶å¼å¥äºä¸ç¨®æ°ç©ä¸æºç¢ºçæ¹æ³ï¼ä½¿ç¨çµç¹ççå­¸å½±åä¾å°ä¹³çé²è¡åé¡ãå®ç³»çµ±æ§å°æ¯è¼äºå¨ä¸åå½±åè³æéä¸­çé åå·ç©ç¥ç¶ç¶²è·¯ (CNN) æ¨¡åï¼æ¾åºå®åæä½³çè¶åæ¸ï¼ä¸¦æ ¹æåé¡æè½å°å®åé²è¡æåãçºäºæå¤§åæåæ¢ç´¢çæ¯åæ¨¡åçåé¡æºç¢ºåº¦ï¼æåæ¢è¨äºè³ææ´åãæ¿ä»£å¨é£æ¥å±¤ãæ¨¡åè¨ç·´è¶åæ¸è¨­å®ï¼ä»¥åéæ°è¨ç·´æ¨¡åèä½¿ç¨é è¨ç·´æ¬éçåªé»ãæåçåæ³åå«äºå¹¾ååå§æ¦å¿µï¼åæ¬åºååç¢ççè³æéï¼ä»¥ç¢ºä¿å¨è¨ç·´éç¨ä¸­è³ææ¢ä»¶ä¸è´ï¼ä¸¦å¤§å¹ç¸®ç­è¨ç·´æéãçµåèªååçµææ´çï¼éä½¿å¾æåè½å¤ æ¢ç´¢è¶é 2,000 åè¨ç·´æåçµåââå¦æ­¤å¨é¢çæ¯è¼å¨ç®åçºæ­¢æ¯åææªæçãæåçç¼ç¾å»ºç«äºéæååºåé¡æºç¢ºåº¦æéçè¨­å®ï¼ä¸¦æ ¹ææ¨¡åæè½å°ç¨ç«ç CNN æ¨¡åé²è¡æåãæ ¹æéäºçµæï¼æåæåºäºå°ä¸åé«æ§è½ç¨ç« CNN æ¨¡åèä¸åçåé¡å¨å çå¨ä¸èµ·çæ´é«æ¶æ§ï¼é²èæåäºåé¡æºç¢ºåº¦ãç³»çµ±æ§å°å·è¡ééº¼å¤æ¨¡åæåçµåä»¥ç²å¾æä½³çµæçè½åï¼ç¢çäºéå¸¸é«åè³ªççµæï¼åæ¬å° BreakHis x40 å BreakHis x200 åå²æè¨ç·´ãé©è­åæ¸¬è©¦è³æéæï¼æºç¢ºåº¦éå° 99.75%ï¼è Bach è³æéçæºç¢ºåº¦éå° 95.18%ãä½¿ç¨éç¨®æ¹æ³ï¼Bach Online ç²æ¸¬çæºç¢ºåº¦éå° 89%ãéç¶æ¬ç ç©¶æ¯åºæ¼ä¹³ççµç¹ççå­¸å½±åè³æéï¼ä½æ­¤æ¹æ³åæ¨£é©ç¨æ¼å¶ä»é«å­¸å½±åè³æéã

##### **Manikin-Recorded Cardiopulmonary Sounds Dataset Using Digital Stethoscope**
2410.03280v1 by Yasaman Torabi, Shahram Shirani, James P. Reilly

Heart and lung sounds are crucial for healthcare monitoring. Recent
improvements in stethoscope technology have made it possible to capture patient
sounds with enhanced precision. In this dataset, we used a digital stethoscope
to capture both heart and lung sounds, including individual and mixed
recordings. To our knowledge, this is the first dataset to offer both separate
and mixed cardiorespiratory sounds. The recordings were collected from a
clinical manikin, a patient simulator designed to replicate human physiological
conditions, generating clean heart and lung sounds at different body locations.
This dataset includes both normal sounds and various abnormalities (i.e.,
murmur, atrial fibrillation, tachycardia, atrioventricular block, third and
fourth heart sound, wheezing, crackles, rhonchi, pleural rub, and gurgling
sounds). The dataset includes audio recordings of chest examinations performed
at different anatomical locations, as determined by specialist nurses. Each
recording has been enhanced using frequency filters to highlight specific sound
types. This dataset is useful for applications in artificial intelligence, such
as automated cardiopulmonary disease detection, sound classification,
unsupervised separation techniques, and deep learning algorithms related to
audio signal processing.

æè¦ï¼å¿èèèºé¨è²é³å°æ¼é«çä¿å¥ç£æ¸¬è³ééè¦ãæè¿å¨è½è¨ºå¨æè¡æ¹é¢çé²æ­¥ï¼ä½¿å¾ä»¥æ´é«çç²¾æºåº¦æ·åæ£èè²é³æçºå¯è½ãå¨éåè³æéä¸­ï¼æåä½¿ç¨æ¸ä½è½è¨ºå¨æ·åå¿èèèºé¨è²é³ï¼åæ¬åå¥åæ··åçéé³ãææåæç¥ï¼éæ¯ç¬¬ä¸åæä¾åå¥åæ··åçå¿èºè²é³çè³æéãéäºéé³æ¯å¾è¨åºåäººæ¶éçï¼è¨åºåäººæ¯ä¸ç¨®æ¨¡æ¬äººé«çççæ³çæ£èæ¨¡æ¬å¨ï¼å¯å¨ä¸åèº«é«é¨ä½ç¢çä¹¾æ·¨çå¿èåèºé¨è²é³ãéåè³æéåå«æ­£å¸¸è²é³ååç¨®ç°å¸¸ï¼ä¾å¦ï¼éé³ãå¿æ¿é¡«åãå¿åééãæ¿å®¤å³å°é»æ»¯ãç¬¬ä¸åç¬¬åå¿é³ãåé³´ãçè£é³ãåé³ãè¸èæ©æ¦é³åååè²ï¼ãéåè³æéåå«å¨ä¸åè§£åä½ç½®é²è¡è¸é¨æª¢æ¥çé³è¨éé³ï¼ç±å°ç§è­·çå¸«ç¢ºå®ãæ¯åéé³é½ä½¿ç¨é »çæ¿¾æ³¢å¨é²è¡å å¼·ï¼ä»¥çªé¡¯ç¹å®çè²é³é¡åãéåè³æéå°æ¼äººå·¥æºæ§çæç¨å¾æç¨ï¼ä¾å¦èªåå¿èºç¾çåµæ¸¬ãè²é³åé¡ãç¡ç£ç£åé¢æè¡åèé³è¨è¨èèçç¸éçæ·±åº¦å­¸ç¿æ¼ç®æ³ã

##### **Looking into Concept Explanation Methods for Diabetic Retinopathy Classification**
2410.03188v1 by Andrea M. StorÃ¥s, Josefine V. Sundgaard

Diabetic retinopathy is a common complication of diabetes, and monitoring the
progression of retinal abnormalities using fundus imaging is crucial. Because
the images must be interpreted by a medical expert, it is infeasible to screen
all individuals with diabetes for diabetic retinopathy. Deep learning has shown
impressive results for automatic analysis and grading of fundus images. One
drawback is, however, the lack of interpretability, which hampers the
implementation of such systems in the clinic. Explainable artificial
intelligence methods can be applied to explain the deep neural networks.
Explanations based on concepts have shown to be intuitive for humans to
understand, but have not yet been explored in detail for diabetic retinopathy
grading. This work investigates and compares two concept-based explanation
techniques for explaining deep neural networks developed for automatic
diagnosis of diabetic retinopathy: Quantitative Testing with Concept Activation
Vectors and Concept Bottleneck Models. We found that both methods have
strengths and weaknesses, and choice of method should take the available data
and the end user's preferences into account.

æè¦ï¼ç³å°¿çè¦ç¶²èçè®æ¯ç³å°¿ççå¸¸è¦ä½µç¼çï¼ä½¿ç¨ç¼åºæåç£æ§è¦ç¶²èç°å¸¸çé²å±è³ééè¦ãç±æ¼å½±åå¿é ç±é«çå°å®¶è§£éï¼å æ­¤ä¸å¯è½ç¯©é¸åºæææ£æç³å°¿çè¦ç¶²èçè®çç³å°¿çæ£èãæ·±åº¦å­¸ç¿å·²å¨ç¼åºå½±åçèªååæååç´æ¹é¢å±ç¾åºä»¤äººå°è±¡æ·±å»çææãç¶èï¼å¶ä¸­ä¸åç¼ºé»æ¯ç¼ºä¹å¯è§£éæ§ï¼éé»ç¤äºæ­¤é¡ç³»çµ±å¨è¨åºä¸çå¯¦æ½ãå¯è§£éçäººå·¥æºæ§æ¹æ³å¯æç¨æ¼è§£éæ·±åº¦ç¥ç¶ç¶²è·¯ãåºæ¼æ¦å¿µçè§£éå·²è¢«è­æå°äººé¡ä¾èªªç´è§ææï¼ä½å°æªè©³ç´°æ¢è¨ç³å°¿çè¦ç¶²èçè®åç´ãéé å·¥ä½æ¢è¨ä¸¦æ¯è¼äºå©ç¨®åºæ¼æ¦å¿µçè§£éæè¡ï¼ç¨æ¼è§£éçºç³å°¿çè¦ç¶²èçè®èªåè¨ºæ·èéç¼çæ·±åº¦ç¥ç¶ç¶²è·¯ï¼ä½¿ç¨æ¦å¿µæ¿æ´»åéé²è¡çå®éæ¸¬è©¦åæ¦å¿µç¶é ¸æ¨¡åãæåç¼ç¾éå©ç¨®æ¹æ³åæåªç¼ºé»ï¼æ¹æ³çé¸ææèæ®å¯ç¨çè³æåæçµä½¿ç¨èçåå¥½ã

##### **Remaining Useful Life Prediction: A Study on Multidimensional Industrial Signal Processing and Efficient Transfer Learning Based on Large Language Models**
2410.03134v1 by Yan Chen, Cheng Liu

Remaining useful life (RUL) prediction is crucial for maintaining modern
industrial systems, where equipment reliability and operational safety are
paramount. Traditional methods, based on small-scale deep learning or
physical/statistical models, often struggle with complex, multidimensional
sensor data and varying operating conditions, limiting their generalization
capabilities. To address these challenges, this paper introduces an innovative
regression framework utilizing large language models (LLMs) for RUL prediction.
By leveraging the modeling power of LLMs pre-trained on corpus data, the
proposed model can effectively capture complex temporal dependencies and
improve prediction accuracy. Extensive experiments on the Turbofan engine's RUL
prediction task show that the proposed model surpasses state-of-the-art (SOTA)
methods on the challenging FD002 and FD004 subsets and achieves near-SOTA
results on the other subsets. Notably, different from previous research, our
framework uses the same sliding window length and all sensor signals for all
subsets, demonstrating strong consistency and generalization. Moreover,
transfer learning experiments reveal that with minimal target domain data for
fine-tuning, the model outperforms SOTA methods trained on full target domain
data. This research highlights the significant potential of LLMs in industrial
signal processing and RUL prediction, offering a forward-looking solution for
health management in future intelligent industrial systems.

æè¦ï¼å©é¤ä½¿ç¨å£½å½ (RUL) é æ¸¬å°æ¼ç¶­è­·ç¾ä»£å·¥æ¥­ç³»çµ±è³ééè¦ï¼å¨éäºç³»çµ±ä¸­ï¼è¨­åå¯é æ§åæä½å®å¨è³ä¸ãå³çµ±æ¹æ³åºæ¼å°è¦æ¨¡æ·±åº¦å­¸ç¿æç©ç/çµ±è¨æ¨¡åï¼éå¸¸é£ä»¥èçè¤éãå¤ç¶­åº¦çææ¸¬å¨è³æåä¸åçæä½æ¢ä»¶ï¼éå¶äºå®åçæ³åè½åãçºäºæå°éäºææ°ï¼æ¬æä»ç´¹äºä¸ååµæ°çåæ­¸æ¶æ§ï¼å©ç¨å¤§åèªè¨æ¨¡å (LLM) ä¾é²è¡ RUL é æ¸¬ãééå©ç¨å¨èªæè³æä¸é åè¨ç·´ç LLM çå»ºæ¨¡è½åï¼ææåºçæ¨¡åå¯ä»¥ææå°ææè¤éçæéä¾è³´æ§ä¸¦æé«é æ¸¬æºç¢ºåº¦ãå¨æ¸¦è¼ªé¢¨æå¼æç RUL é æ¸¬ä»»åä¸é²è¡çå»£æ³å¯¦é©è¡¨æï¼ææåºçæ¨¡åå¨å·æææ°æ§ç FD002 å FD004 å­éä¸­è¶è¶äºæåé² (SOTA) çæ¹æ³ï¼ä¸¦å¨å¶ä»å­éä¸­éå°äºæ¥è¿ SOTA ççµæãå¼å¾æ³¨æçæ¯ï¼èååçç ç©¶ä¸åï¼æåçæ¡æ¶å°ææå­éé½ä½¿ç¨ç¸åçæ»åçªå£é·åº¦åææææ¸¬å¨è¨èï¼å±ç¤ºäºå¼·å¤§çç¸å®¹æ§åæ³åè½åãæ­¤å¤ï¼è½ç§»å­¸ç¿å¯¦é©è¡¨æï¼ééå°å¾®èª¿é²è¡æå°çç®æ¨ç¶²åè³æï¼è©²æ¨¡åçè¡¨ç¾åªæ¼å¨å®æ´ç®æ¨ç¶²åè³æä¸è¨ç·´ç SOTA æ¹æ³ãéé ç ç©¶çªé¡¯äº LLM å¨å·¥æ¥­è¨èèçå RUL é æ¸¬ä¸­çå·¨å¤§æ½åï¼çºæªä¾æºæ§å·¥æ¥­ç³»çµ±ä¸­çå¥åº·ç®¡çæä¾äºåç»æ§çè§£æ±ºæ¹æ¡ã

##### **Image First or Text First? Optimising the Sequencing of Modalities in Large Language Model Prompting and Reasoning Tasks**
2410.03062v1 by Grant Wardle, Teo Susnjak

This paper examines how the sequencing of images and text within multi-modal
prompts influences the reasoning performance of large language models (LLMs).
We performed empirical evaluations using three commercial LLMs. Our results
demonstrate that the order in which modalities are presented can significantly
affect performance, particularly in tasks of varying complexity. For simpler
tasks involving a single image, modality sequencing had a clear impact on
accuracy. However, in more complex tasks involving multiple images and
intricate reasoning steps, the effect of sequencing diminished, likely due to
the increased cognitive demands of the task. Our findings also highlight the
importance of question/prompt structure. In nested and multi-step reasoning
tasks, modality sequencing played a key role in shaping model performance.
While LLMs excelled in the initial stages of reasoning, they struggled to
re-incorporate earlier information, underscoring the challenges of multi-hop
reasoning within transformer architectures. This suggests that aligning the
sequence of modalities with the logical flow of reasoning steps is more
critical than modality order alone. These insights offer valuable implications
for improving multi-modal prompt design, with broader applications across
fields such as education, medical imaging, and cross-modal learning.

æè¦ï¼æ¬ææ¢è¨å¨å¤æ¨¡ææç¤ºä¸­å½±ååæå­çé åºå¦ä½å½±é¿å¤§åèªè¨æ¨¡å (LLM) çæ¨çè¡¨ç¾ãæåä½¿ç¨ä¸ååç¨ LLM é²è¡å¯¦è­è©ä¼°ãæåççµæè¡¨æï¼æ¨¡æåç¾çé åºæé¡¯èå½±é¿è¡¨ç¾ï¼ç¹å¥æ¯å¨ä¸åè¤éåº¦ä»»åä¸­ãå°æ¼æ¶åå®ä¸å½±åçè¼ç°¡å®ä»»åï¼æ¨¡æé åºå°æºç¢ºåº¦ææé¡¯å½±é¿ãç¶èï¼å¨æ¶åå¤åå½±ååè¤éæ¨çæ­¥é©çè¼è¤éä»»åä¸­ï¼é åºçå½±é¿æ¸å¼±ï¼éå¯è½æ¯ç±æ¼ä»»åçèªç¥éæ±å¢å ãæåçç¼ç¾ä¹çªé¡¯äºåé¡/æç¤ºçµæ§çéè¦æ§ãå¨åµå¥åå¤æ­¥é©æ¨çä»»åä¸­ï¼æ¨¡æé åºå¨å¡é æ¨¡åè¡¨ç¾ä¸­æ®æ¼ééµè§è²ãéç¶ LLM å¨æ¨ççåå§éæ®µè¡¨ç¾åºè²ï¼ä½å®åé£ä»¥éæ°æ´åæ©æçè³è¨ï¼éå¸é¡¯äºTransformeræ¶æ§ä¸­å¤è·³æ¨ççææ°ãéè¡¨æå°æ¨¡æé åºèæ¨çæ­¥é©çéè¼¯æµç¨å°é½æ¯å®ç¨çæ¨¡æé åºæ´çºéè¦ãéäºè¦è§£çºæ¹åå¤æ¨¡ææç¤ºè¨­è¨æä¾äºå¯¶è²´çåç¤ºï¼ä¸¦å¨æè²ãé«å­¸å½±ååè·¨æ¨¡æå­¸ç¿ç­é åææ´å»£æ³çæç¨ã

##### **Is Your Paper Being Reviewed by an LLM? Investigating AI Text Detectability in Peer Review**
2410.03019v1 by Sungduk Yu, Man Luo, Avinash Madasu, Vasudev Lal, Phillip Howard

Peer review is a critical process for ensuring the integrity of published
scientific research. Confidence in this process is predicated on the assumption
that experts in the relevant domain give careful consideration to the merits of
manuscripts which are submitted for publication. With the recent rapid
advancements in the linguistic capabilities of large language models (LLMs), a
new potential risk to the peer review process is that negligent reviewers will
rely on LLMs to perform the often time consuming process of reviewing a paper.
In this study, we investigate the ability of existing AI text detection
algorithms to distinguish between peer reviews written by humans and different
state-of-the-art LLMs. Our analysis shows that existing approaches fail to
identify many GPT-4o written reviews without also producing a high number of
false positive classifications. To address this deficiency, we propose a new
detection approach which surpasses existing methods in the identification of
GPT-4o written peer reviews at low levels of false positive classifications.
Our work reveals the difficulty of accurately identifying AI-generated text at
the individual review level, highlighting the urgent need for new tools and
methods to detect this type of unethical application of generative AI.

æè¦ï¼ååå¯©æ¥æ¯ç¢ºä¿å·²ç¼è¡¨çç§å­¸ç ç©¶çå®æ´æ§çééµéç¨ãå°æ­¤éç¨çä¿¡å¿å»ºç«å¨ä¸ååè¨­ä¹ä¸ï¼å³ç¸éé åçå°å®¶æä»ç´°èæ®æäº¤åºççç¨¿ä»¶çåªé»ãé¨èå¤§åèªè¨æ¨¡å (LLM) çèªè¨è½åæè¿çå¿«éé²å±ï¼å°ååå¯©æ¥éç¨çä¸åæ°çæ½å¨é¢¨éªæ¯ï¼çå¿½çå¯©æ¥å¡æä¾è³´ LLM ä¾å·è¡å¯©æ¥è«æéåå¸¸å¸¸å¾èæçéç¨ãå¨æ¬ç ç©¶ä¸­ï¼æåèª¿æ¥äºç¾æ AI æå­åµæ¸¬æ¼ç®æ³ååç±äººé¡æ°å¯«çååå¯©æ¥åä¸åçæåé² LLM çè½åãæåçåæé¡¯ç¤ºï¼ç¾æçæ¹æ³ç¡æ³è­å¥è¨±å¤ GPT-4o å¯«çè©è«ï¼åæä¹ä¸æç¢çå¤§éçåé½æ§åé¡ãçºäºè§£æ±ºéåç¼ºé·ï¼æåæåºäºä¸ç¨®æ°çåµæ¸¬æ¹æ³ï¼å®å¨ä½æ°´å¹³çåé½æ§åé¡ä¸­è¶è¶äºç¾æçæ¹æ³ï¼è­å¥ GPT-4o å¯«çååå¯©æ¥ãæåçç ç©¶æ­ç¤ºäºå¨åå¥å¯©æ¥å±¤ç´æºç¢ºè­å¥ AI çæçæå­çé£åº¦ï¼å¼·èª¿äºè¿«åéè¦æ°çå·¥å·åæ¹æ³ä¾åµæ¸¬éç¨®ä¸éå¾·ççæå¼ AI æç¨ã

##### **DailyDilemmas: Revealing Value Preferences of LLMs with Quandaries of Daily Life**
2410.02683v1 by Yu Ying Chiu, Liwei Jiang, Yejin Choi

As we increasingly seek guidance from LLMs for decision-making in daily life,
many of these decisions are not clear-cut and depend significantly on the
personal values and ethical standards of the users. We present DailyDilemmas, a
dataset of 1,360 moral dilemmas encountered in everyday life. Each dilemma
includes two possible actions and with each action, the affected parties and
human values invoked. Based on these dilemmas, we consolidated a set of human
values across everyday topics e.g., interpersonal relationships, workplace, and
environmental issues. We evaluated LLMs on these dilemmas to determine what
action they will take and the values represented by these actions. Then, we
analyzed these values through the lens of five popular theories inspired by
sociology, psychology and philosophy. These theories are: World Value Survey,
Moral Foundation Theory, Maslow's Hierarchy of Needs, Aristotle's Virtues, and
Plutchik Wheel of Emotion. We find that LLMs are most aligned with the
self-expression over survival values in terms of World Value Survey, care over
loyalty in Moral Foundation Theory. Interestingly, we find large preferences
differences in models for some core values such as truthfulness e.g.,
Mixtral-8x7B model tends to neglect it by 9.7% while GPT-4-turbo model tends to
select it by 9.4%. We also study the recent guidance released by OpenAI
(ModelSpec), and Anthropic (Constitutional AI) to understand how their released
principles reflect their actual value prioritization when facing nuanced moral
reasoning in daily-life settings. We find that end users cannot effectively
steer such prioritization using system prompts.

æè¦ï¼<paragraph>é¨èæåå¨æ¥å¸¸çæ´»ä¸­è¶ä¾è¶ä¾è³´ LLM ä¾é²è¡æ±ºç­ï¼
å¶ä¸­è¨±å¤æ±ºç­ä¸¦éæç¢ºï¼èä¸å¨å¾å¤§ç¨åº¦ä¸åæ±ºæ¼
ä½¿ç¨èçåäººå¹å¼è§åéå¾·æ¨æºãæåæåºäºæ¥å¸¸å°å¢ï¼ä¸å
å¨æ¥å¸¸çæ´»ä¸­éå°ç 1,360 åéå¾·å°å¢çæ¸æéãæ¯åå°å¢
åå«å©åå¯è½çè¡åï¼ä¸¦éå°æ¯åè¡åï¼åå°å½±é¿çåæ¹å
å¼ç¼çäººé¡å¹å¼è§ãæ ¹æéäºå°å¢ï¼æåå½æ´äºä¸çµäººé¡
å¹å¼è§ï¼æ¶µèæ¥å¸¸ä¸»é¡ï¼ä¾å¦äººééä¿ãè·å ´å
ç°å¢åé¡ãæåéå°éäºå°å¢è©ä¼° LLMï¼ä»¥ç¢ºå®å®åå°æ¡åä»éº¼
è¡åä»¥åéäºè¡åæä»£è¡¨çå¹å¼è§ãæ¥èï¼æå
ééç¤¾æå­¸ãå¿çå­¸åå²å­¸åç¼çäºç¨®æµè¡çè«ä¾åæéäºå¹å¼è§ãéäºçè«çºï¼ä¸çå¹å¼è§èª¿æ¥ã
éå¾·åºç¤çè«ãé¦¬æ¯æ´éæ±å±¤æ¬¡çè«ãäºéæ¯å¤å¾·ç¾å¾·ï¼ä»¥å
æ®æå¥åæç·ä¹è¼ªãæåç¼ç¾ LLM å¨ä¸çå¹å¼è§èª¿æ¥ä¸­è
çå­å¹å¼è§ç¸æ¯ï¼æ´å¾åæ¼èªæè¡¨éï¼å¨éå¾·åºç¤çè«ä¸­ï¼æ´å¾åæ¼éæ·èéå¿ èª ãæè¶£çæ¯ï¼æåç¼ç¾å°æ¼æäºæ ¸å¿å¹å¼è§ï¼ä¾å¦èª å¯¦ï¼ä¸åæ¨¡åä¹éå­å¨å¾å¤§çåå¥½å·®ç°ï¼ä¾å¦ï¼
Mixtral-8x7B æ¨¡åå¾åæ¼å¿½ç¥å® 9.7%ï¼è GPT-4-turbo æ¨¡åå¾åæ¼é¸æå® 9.4%ãæåéç ç©¶äº OpenAI
(ModelSpec) å Anthropic (Constitutional AI) æè¿ç¼å¸çæå°æ¹éï¼ä»¥äºè§£ä»åç¼å¸çååå¦ä½å¨é¢å°æ¥å¸¸çæ´»ä¸­å¾®å¦çéå¾·æ¨çæåæ ä»åçå¯¦éå¹å¼åªåé åºãæåç¼ç¾ï¼æçµä½¿ç¨èç¡æ³ææå°
ä½¿ç¨ç³»çµ±æç¤ºä¾å¼å°æ­¤é¡åªåé åºã</paragraph>

##### **Plots Unlock Time-Series Understanding in Multimodal Models**
2410.02637v1 by Mayank Daswani, Mathias M. J. Bellaiche, Marc Wilson, Desislav Ivanov, Mikhail Papkov, Eva Schnider, Jing Tang, Kay Lamerigts, Gabriela Botea, Michael A. Sanchez, Yojan Patel, Shruthi Prabhakara, Shravya Shetty, Umesh Telang

While multimodal foundation models can now natively work with data beyond
text, they remain underutilized in analyzing the considerable amounts of
multi-dimensional time-series data in fields like healthcare, finance, and
social sciences, representing a missed opportunity for richer, data-driven
insights. This paper proposes a simple but effective method that leverages the
existing vision encoders of these models to "see" time-series data via plots,
avoiding the need for additional, potentially costly, model training. Our
empirical evaluations show that this approach outperforms providing the raw
time-series data as text, with the additional benefit that visual time-series
representations demonstrate up to a 90% reduction in model API costs. We
validate our hypothesis through synthetic data tasks of increasing complexity,
progressing from simple functional form identification on clean data, to
extracting trends from noisy scatter plots. To demonstrate generalizability
from synthetic tasks with clear reasoning steps to more complex, real-world
scenarios, we apply our approach to consumer health tasks - specifically fall
detection, activity recognition, and readiness assessment - which involve
heterogeneous, noisy data and multi-step reasoning. The overall success in plot
performance over text performance (up to an 120% performance increase on
zero-shot synthetic tasks, and up to 150% performance increase on real-world
tasks), across both GPT and Gemini model families, highlights our approach's
potential for making the best use of the native capabilities of foundation
models.

æè¦ï¼åç®¡å¤æ¨¡æåºç¤æ¨¡åç¾å¨å¯ä»¥åçèçæå­ä»¥å¤çè³æï¼ä½å®åå¨åæé«çä¿å¥ãéèåç¤¾æç§å­¸ç­é åä¸­å¤§éå¤ç¶­æéåºåè³ææä»æªè¢«ååå©ç¨ï¼éä»£è¡¨é¯å¤±äºç²å¾æ´è±å¯è³æé©åè¦è§£çæ©æãæ¬ææåºäºä¸ç¨®ç°¡å®ä½ææçæ¹æ³ï¼å©ç¨éäºæ¨¡åç¾æçè¦è¦ºç·¨ç¢¼å¨ééåè¡¨ãæ¥çãæéåºåè³æï¼é¿åéè¦é¡å¤ä¸å¯è½æè²´çæ¨¡åè¨ç·´ãæåçç¶é©è©ä¼°é¡¯ç¤ºï¼éç¨®æ¹æ³åªæ¼æä¾åå§æéåºåè³æä½çºæå­ï¼é¡å¤çå¥½èæ¯è¦è¦ºæéåºåè¡¨ç¤ºå¯ä»¥æ¸å°é«é 90% çæ¨¡å API ææ¬ãæåééæ¥çè¤éçåæè³æä»»åé©è­æåçåè¨­ï¼å¾ä¹¾æ·¨è³æä¸çç°¡å®å½æ¸å½¢å¼è­å¥ï¼å°å¾éè¨æ£ä½åä¸­èåè¶¨å¢ãçºäºè­æå¾å·ææç¢ºæ¨çæ­¥é©çåæä»»åå°æ´è¤éççå¯¦ä¸çå ´æ¯çæ¦æ¬æ§ï¼æåå°æåçåæ³æç¨æ¼æ¶è²»èå¥åº·ä»»åï¼ç¹å¥æ¯è·ååµæ¸¬ãæ´»åè­å¥åæºåè©ä¼°ï¼éäºä»»åæ¶åç°è³ªãéè¨è³æåå¤æ­¥é©æ¨çãå¨ GPT å Gemini æ¨¡åç³»åä¸­ï¼åè¡¨è¡¨ç¾åªæ¼æå­è¡¨ç¾çæ´é«æåï¼å¨é¶æ¬¡å­¸ç¿åæä»»åä¸­è¡¨ç¾æåé«é 120%ï¼å¨çå¯¦ä¸çä»»åä¸­è¡¨ç¾æåé«é 150%ï¼ï¼çªé¡¯äºæåçæ¹æ³å¨æä½³å©ç¨åºç¤æ¨¡ååçåè½æ¹é¢çæ½åã

##### **IC3M: In-Car Multimodal Multi-object Monitoring for Abnormal Status of Both Driver and Passengers**
2410.02592v3 by Zihan Fang, Zheng Lin, Senkang Hu, Hangcheng Cao, Yiqin Deng, Xianhao Chen, Yuguang Fang

Recently, in-car monitoring has emerged as a promising technology for
detecting early-stage abnormal status of the driver and providing timely alerts
to prevent traffic accidents. Although training models with multimodal data
enhances the reliability of abnormal status detection, the scarcity of labeled
data and the imbalance of class distribution impede the extraction of critical
abnormal state features, significantly deteriorating training performance.
Furthermore, missing modalities due to environment and hardware limitations
further exacerbate the challenge of abnormal status identification. More
importantly, monitoring abnormal health conditions of passengers, particularly
in elderly care, is of paramount importance but remains underexplored. To
address these challenges, we introduce our IC3M, an efficient
camera-rotation-based multimodal framework for monitoring both driver and
passengers in a car. Our IC3M comprises two key modules: an adaptive threshold
pseudo-labeling strategy and a missing modality reconstruction. The former
customizes pseudo-labeling thresholds for different classes based on the class
distribution, generating class-balanced pseudo labels to guide model training
effectively, while the latter leverages crossmodality relationships learned
from limited labels to accurately recover missing modalities by distribution
transferring from available modalities. Extensive experimental results
demonstrate that IC3M outperforms state-of-the-art benchmarks in accuracy,
precision, and recall while exhibiting superior robustness under limited
labeled data and severe missing modality.

æè¦ï¼<paragraph>æè¿ï¼è»è¼ç£æ§å·²æçºä¸ç¨®æåéçæè¡ï¼ç¨æ¼æª¢æ¸¬é§é§å¡çæ©æç°å¸¸çæï¼ä¸¦æä¾åæè­¦å ±ä»¥é²æ­¢äº¤éäºæãåç®¡ä½¿ç¨å¤æ¨¡ææ¸æè¨ç·´æ¨¡åå¢å¼·äºç°å¸¸çææª¢æ¸¬çå¯é æ§ï¼ä½æ¨è¨æ¸æçç¨ç¼ºæ§åé¡å¥åä½çä¸å¹³è¡¡é»ç¤äºééµç°å¸¸çæç¹å¾µçæåï¼é¡¯èéä½äºè¨ç·´æ§è½ãæ­¤å¤ï¼ç±æ¼ç°å¢åç¡¬é«éå¶èå°è´çæ¨¡æç¼ºå¤±é²ä¸æ­¥å åäºç°å¸¸çæè­å¥çææ°ãæ´éè¦çæ¯ï¼ç£æ§ä¹å®¢çç°å¸¸å¥åº·çæ³ï¼ç¹å¥æ¯å¨èå¹´è­·çä¸­ï¼è³ééè¦ï¼ä½ä»æªå¾å°ååæ¢ç´¢ãçºäºæå°éäºææ°ï¼æåå¼å¥äºæåç IC3Mï¼éæ¯ä¸ååºæ¼ç¸æ©æè½çé«æå¤æ¨¡ææ¡æ¶ï¼ç¨æ¼ç£æ§æ±½è»ä¸­çé§é§å¡åä¹å®¢ãæåç IC3M åå«å©åééµæ¨¡çµï¼èªé©æé¾å¼å½æ¨ç±¤ç­ç¥åç¼ºå¤±æ¨¡æéå»ºãåèæ ¹æé¡å¥åä½çºä¸åçé¡å¥èªè¨å½æ¨ç±¤é¾å¼ï¼çæé¡å¥å¹³è¡¡çå½æ¨ç±¤ä»¥ææå°æå°æ¨¡åè¨ç·´ï¼èå¾èåå©ç¨å¾æéæ¨ç±¤ä¸­å­¸ç¿å°çè·¨æ¨¡æéä¿ï¼ééå¾å¯ç¨æ¨¡æé²è¡åä½è½ç§»ä¾æºç¢ºæ¢å¾©ç¼ºå¤±çæ¨¡æãå»£æ³çå¯¦é©çµæè¡¨æï¼IC3M å¨æºç¢ºæ§ãç²¾ç¢ºåº¦åå¬åçæ¹é¢åªæ¼æåé²çåºæºï¼åæå¨æ¨è¨æ¸ææéåå´éç¼ºå¤±æ¨¡æçææ³ä¸è¡¨ç¾åºåè¶çé­¯æ£æ§ã</paragraph>

##### **Deep Regression 2D-3D Ultrasound Registration for Liver Motion Correction in Focal Tumor Thermal Ablation**
2410.02579v1 by Shuwei Xing, Derek W. Cool, David Tessier, Elvis C. S. Chen, Terry M. Peters, Aaron Fenster

Liver tumor ablation procedures require accurate placement of the needle
applicator at the tumor centroid. The lower-cost and real-time nature of
ultrasound (US) has advantages over computed tomography (CT) for applicator
guidance, however, in some patients, liver tumors may be occult on US and tumor
mimics can make lesion identification challenging. Image registration
techniques can aid in interpreting anatomical details and identifying tumors,
but their clinical application has been hindered by the tradeoff between
alignment accuracy and runtime performance, particularly when compensating for
liver motion due to patient breathing or movement. Therefore, we propose a
2D-3D US registration approach to enable intra-procedural alignment that
mitigates errors caused by liver motion. Specifically, our approach can
correlate imbalanced 2D and 3D US image features and use continuous 6D rotation
representations to enhance the model's training stability. The dataset was
divided into 2388, 196 and 193 image pairs for training, validation and
testing, respectively. Our approach achieved a mean Euclidean distance error of
2.28 mm $\pm$ 1.81 mm and a mean geodesic angular error of 2.99$^{\circ}$ $\pm$
1.95$^{\circ}$, with a runtime of 0.22 seconds per 2D-3D US image pair. These
results demonstrate that our approach can achieve accurate alignment and
clinically acceptable runtime, indicating potential for clinical translation.

æè¦ï¼èèè«ç¤æ¶èæè¡éè¦å°éé ­æ½ç¨å¨ç²¾æºç½®æ¼è«ç¤ä¸­å¿é»ãè¶é³æ³¢ (US) ææ¬è¼ä½ä¸çºå³æå½±åï¼ç¸è¼æ¼é»è¦æ·å±¤ææ (CT)ï¼å¨æ½ç¨å¨å°å¼æ¹é¢æåªå¢ï¼ç¶èï¼å°æ¼æäºæ£èï¼èèè«ç¤å¨è¶é³æ³¢å½±åä¸å¯è½ä¸æé¡¯ï¼èè«ç¤æ¨¡æ¬æè®çç¶è¾¨è­æ´å·ææ°æ§ãå½±åéæºæè¡æå©æ¼è§£è®è§£åç´°ç¯åè¾¨è­è«ç¤ï¼ä½ç±æ¼å¹³è¡¡æ ¡æºæºç¢ºåº¦åå·è¡æè½ï¼å¶è¨åºæç¨åå°é»ç¤ï¼ç¹å¥æ¯å¨è£åå æ£èå¼å¸æç§»åèç¢ççèèéåæãå æ­¤ï¼æåæåº 2D-3D è¶é³æ³¢éæºæ¹æ³ï¼ä»¥é²è¡è¡ä¸­æ ¡æºï¼æ¸è¼å èèéåèç¢ççèª¤å·®ãå·é«ä¾èªªï¼æåçåæ³å¯ä»¥éè¯å¤±è¡¡ç 2D å 3D è¶é³æ³¢å½±åç¹å¾µï¼ä¸¦ä½¿ç¨é£çºç 6D æè½è¡¨ç¤ºä¾å¢å¼·æ¨¡åçè¨ç·´ç©©å®åº¦ãè³æéåçº 2388ã196 å 193 å½±åå°ï¼åå¥ç¨æ¼è¨ç·´ãé©è­åæ¸¬è©¦ãæåçåæ³éæå¹³åæ­æ°è·é¢èª¤å·® 2.28 mm $\pm$ 1.81 mmï¼ä»¥åå¹³åæ¸¬å°è§èª¤å·® 2.99$^{\circ}$ $\pm$ 1.95$^{\circ}$ï¼å·è¡æéçºæ¯ 2D-3D è¶é³æ³¢å½±åå° 0.22 ç§ãéäºçµæè­ææåçåæ³å¯ä»¥éæç²¾æºæ ¡æºåè¨åºä¸å¯æ¥åçå·è¡æéï¼é¡¯ç¤ºåºè¨åºè½è­¯çæ½åã

##### **ColaCare: Enhancing Electronic Health Record Modeling through Large Language Model-Driven Multi-Agent Collaboration**
2410.02551v1 by Zixiang Wang, Yinghao Zhu, Huiya Zhao, Xiaochen Zheng, Tianlong Wang, Wen Tang, Yasha Wang, Chengwei Pan, Ewen M. Harrison, Junyi Gao, Liantao Ma

We introduce ColaCare, a framework that enhances Electronic Health Record
(EHR) modeling through multi-agent collaboration driven by Large Language
Models (LLMs). Our approach seamlessly integrates domain-specific expert models
with LLMs to bridge the gap between structured EHR data and text-based
reasoning. Inspired by clinical consultations, ColaCare employs two types of
agents: DoctorAgent and MetaAgent, which collaboratively analyze patient data.
Expert models process and generate predictions from numerical EHR data, while
LLM agents produce reasoning references and decision-making reports within the
collaborative consultation framework. We additionally incorporate the Merck
Manual of Diagnosis and Therapy (MSD) medical guideline within a
retrieval-augmented generation (RAG) module for authoritative evidence support.
Extensive experiments conducted on four distinct EHR datasets demonstrate
ColaCare's superior performance in mortality prediction tasks, underscoring its
potential to revolutionize clinical decision support systems and advance
personalized precision medicine. The code, complete prompt templates, more case
studies, etc. are publicly available at the anonymous link:
https://colacare.netlify.app.

æè¦ï¼æåæ¨åº ColaCareï¼ä¸åééå¤§åèªè¨æ¨¡å (LLM) é©åçå¤éä»£çåä½ï¼ä¾å¢å¼·é»å­å¥åº·ç´é (EHR) å»ºæ¨¡çæ¡æ¶ãæåçåæ³å°é åç¹å®å°å®¶æ¨¡åè LLM ç¡ç¸«æ´åï¼ä»¥å½åçµæ§å EHR è³æèåºæ¼æå­çæ¨çä¹éçå·®è·ãColaCare åå°è¨åºè«®è©¢çåç¼ï¼æ¡ç¨äºå©ç¨®ä»£çï¼DoctorAgent å MetaAgentï¼å®ååä½åææ£èè³æãå°å®¶æ¨¡åèçä¸¦å¾æ¸å¼ EHR è³æç¢çé æ¸¬ï¼è LLM ä»£çåå¨åä½è«®è©¢æ¡æ¶å§ç¢çæ¨çåèåæ±ºç­å ±åãæåå¦å¤å¨ä¸åæª¢ç´¢å¢å¼·çæ (RAG) æ¨¡çµä¸­ç´å¥äºé»åè¨ºæ·èæ²»çæå (MSD) é«çæåï¼ä»¥ç²å¾æ¬å¨è­ææ¯æãå¨ååä¸åç EHR è³æéä¸é²è¡çå»£æ³å¯¦é©è­æäº ColaCare å¨æ­»äº¡çé æ¸¬ä»»åä¸­çåªç°æè½ï¼å¼·èª¿äºå¶é©æ°è¨åºæ±ºç­æ¯æ´ç³»çµ±åæ¨é²åäººåç²¾æºé«ççæ½åãç¨å¼ç¢¼ãå®æ´çæç¤ºç¯æ¬ãæ´å¤æ¡ä¾ç ç©¶ç­ï¼é½å¯ä»¥å¨å¿åé£çµä¸­å¬éåå¾ï¼https://colacare.netlify.appã

##### **SAFLEX: Self-Adaptive Augmentation via Feature Label Extrapolation**
2410.02512v1 by Mucong Ding, Bang An, Yuancheng Xu, Anirudh Satheesh, Furong Huang

Data augmentation, a cornerstone technique in deep learning, is crucial in
enhancing model performance, especially with scarce labeled data. While
traditional techniques are effective, their reliance on hand-crafted methods
limits their applicability across diverse data types and tasks. Although modern
learnable augmentation methods offer increased adaptability, they are
computationally expensive and challenging to incorporate within prevalent
augmentation workflows. In this work, we present a novel, efficient method for
data augmentation, effectively bridging the gap between existing augmentation
strategies and emerging datasets and learning tasks. We introduce SAFLEX
(Self-Adaptive Augmentation via Feature Label EXtrapolation), which learns the
sample weights and soft labels of augmented samples provided by any given
upstream augmentation pipeline, using a specifically designed efficient bilevel
optimization algorithm. Remarkably, SAFLEX effectively reduces the noise and
label errors of the upstream augmentation pipeline with a marginal
computational cost. As a versatile module, SAFLEX excels across diverse
datasets, including natural and medical images and tabular data, showcasing its
prowess in few-shot learning and out-of-distribution generalization. SAFLEX
seamlessly integrates with common augmentation strategies like RandAug, CutMix,
and those from large pre-trained generative models like stable diffusion and is
also compatible with frameworks such as CLIP's fine-tuning. Our findings
highlight the potential to adapt existing augmentation pipelines for new data
types and tasks, signaling a move towards more adaptable and resilient training
frameworks.

æè¦ï¼è³ææ´åæ¯æ·±åº¦å­¸ç¿çåºç³æè¡ï¼å¨æåæ¨¡åæè½æ¹é¢è³ééè¦ï¼ç¹å¥æ¯å¨æ¨ç±¤è³æç¨å°çææ³ä¸ãéç¶å³çµ±æè¡å¾ææï¼ä½å®åä¾è³´æ¼æå·¥è£½ä½çæ¹æ³ï¼éå¶äºå®åå¨ä¸åè³æé¡ååä»»åä¸­çé©ç¨æ§ãåç®¡ç¾ä»£å¯å­¸ç¿çæ´åæ¹æ³æä¾äºæ´é«çé©ææ§ï¼ä½å®åå¨è¨ç®ä¸å¾æè²´ï¼ä¸¦ä¸é£ä»¥æ´åå°æ®éçæ´åå·¥ä½æµç¨ä¸­ãå¨éé å·¥ä½ä¸­ï¼æåæåºäºä¸ç¨®æ°ç©ãææççè³ææ´åæ¹æ³ï¼ææå°å½åäºç¾ææ´åç­ç¥èæ°èè³æéåå­¸ç¿ä»»åä¹éçå·®è·ãæåå¼å¥äº SAFLEXï¼ééç¹å¾µæ¨ç±¤å¤æ¨é²è¡èªé©ææ´åï¼ï¼å®ä½¿ç¨å°éè¨­è¨çææéå±¤æ¬¡æä½³åæ¼ç®æ³ï¼å­¸ç¿ç±ä»»ä½çµ¦å®çä¸æ¸¸æ´åç®¡éæä¾çæ´åæ¨£æ¬çæ¨£æ¬æ¬éåè»æ¨ç±¤ãå¼å¾æ³¨æçæ¯ï¼SAFLEX ææå°éä½äºä¸æ¸¸æ´åç®¡éçéè¨åæ¨ç±¤é¯èª¤ï¼ä¸è¨ç®ææ¬å¾ä½ãä½çºä¸åå¤åè½æ¨¡çµï¼SAFLEX å¨åç¨®è³æéä¸­è¡¨ç¾åºè²ï¼åæ¬èªç¶åé«å­¸å½±åä»¥åè¡¨æ ¼è³æï¼å±ç¤ºäºå®å¨å°æ¨£æ¬å­¸ç¿ååå¸å¤æ¦æ¬ä¸­çåªç°è½åãSAFLEX èå¸¸è¦çæ´åç­ç¥ï¼å¦ RandAugãCutMixï¼ä»¥åä¾èªå¤§åé è¨ç·´çææ¨¡åï¼å¦ç©©å®æ´æ£ï¼çæ´åç­ç¥ï¼ç¡ç¸«æ´åï¼ä¸¦ä¸ä¹ç¸å®¹æ¼ CLIP çå¾®èª¿ç­æ¡æ¶ãæåçç ç©¶çµæçªé¡¯äºèª¿æ´ç¾ææ´åç®¡éä»¥é©ææ°è³æé¡ååä»»åçæ½åï¼æ¨èªèæåæ´å·é©ææ§åéæ§çè¨ç·´æ¡æ¶éé²ã

##### **Clinnova Federated Learning Proof of Concept: Key Takeaways from a Cross-border Collaboration**
2410.02443v1 by Julia Alekseenko, Bram Stieltjes, Michael Bach, Melanie Boerries, Oliver Opitz, Alexandros Karargyris, Nicolas Padoy

Clinnova, a collaborative initiative involving France, Germany, Switzerland,
and Luxembourg, is dedicated to unlocking the power of precision medicine
through data federation, standardization, and interoperability. This European
Greater Region initiative seeks to create an interoperable European standard
using artificial intelligence (AI) and data science to enhance healthcare
outcomes and efficiency. Key components include multidisciplinary research
centers, a federated biobanking strategy, a digital health innovation platform,
and a federated AI strategy. It targets inflammatory bowel disease, rheumatoid
diseases, and multiple sclerosis (MS), emphasizing data quality to develop AI
algorithms for personalized treatment and translational research.
  The IHU Strasbourg (Institute of Minimal-invasive Surgery) has the lead in
this initiative to develop the federated learning (FL) proof of concept (POC)
that will serve as a foundation for advancing AI in healthcare. At its core,
Clinnova-MS aims to enhance MS patient care by using FL to develop more
accurate models that detect disease progression, guide interventions, and
validate digital biomarkers across multiple sites. This technical report
presents insights and key takeaways from the first cross-border federated POC
on MS segmentation of MRI images within the Clinnova framework. While our work
marks a significant milestone in advancing MS segmentation through cross-border
collaboration, it also underscores the importance of addressing technical,
logistical, and ethical considerations to realize the full potential of FL in
healthcare settings.

æè¦ï¼Clinnova æ¯ä¸é ç±æ³åãå¾·åãçå£«åç§æ£®å ¡åä½ç¼èµ·çè¨ç«ï¼è´åæ¼ééè³æè¯åãæ¨æºååäºéæ§ä¾éæ¾ç²¾æºé«ççåéãéåæ­æ´²å¤§åè¨ç«æ¨å¨ä½¿ç¨äººå·¥æºæ§ (AI) åè³æç§å­¸å»ºç«ä¸åå¯äºéçæ­æ´²æ¨æºï¼ä»¥æåé«çä¿å¥ææåæçãä¸»è¦çµæé¨ååæ¬è·¨é åç ç©¶ä¸­å¿ãè¯åçç©éè¡ç­ç¥ãæ¸ä½å¥åº·åµæ°å¹³å°åè¯å AI ç­ç¥ãå®éå°ç¼çæ§è¸éç¾çãé¡é¢¨æ¿æ§ç¾çåå¤ç¼æ§ç¡¬åç (MS) é²è¡ç ç©¶ï¼å¼·èª¿è³æåè³ªä»¥éç¼ AI æ¼ç®æ³ï¼ç¨æ¼åäººåæ²»çåè½è­¯ç ç©¶ã
å²ç¹ææ¯å ¡ IHUï¼å¾®åµæè¡ç ç©¶æï¼å¨éåè¨ç«ä¸­é åéç¼è¯åå­¸ç¿ (FL) æ¦å¿µé©è­ (POC)ï¼éå°ä½çºå¨é«çä¿å¥ä¸­æ¨é² AI çåºç¤ãClinnova-MS çæ ¸å¿ç®æ¨æ¯ééä½¿ç¨ FL ä¾æå MS æ£èç§è­·ï¼ä»¥éç¼æ´ç²¾ç¢ºçæ¨¡åä¾åµæ¸¬ç¾çé²ç¨ãå¼å°ä»å¥æªæ½ï¼ä¸¦é©è­å¤åå°é»çæ¸ä½çç©æ¨è¨ãéä»½æè¡å ±åæä¾äº Clinnova æ¶æ§å§ MS ç£æ¯é å½±å½±ååå²é¦æ¬¡è·¨å¢è¯å POC çè¦è§£åä¸»è¦çµè«ãéç¶æåçææå¨ééè·¨å¢åä½æ¨é² MS åå²æ¹é¢æ¯ä¸åéè¦çéç¨ç¢ï¼ä½ä¹å¼·èª¿äºå¨é«çä¿å¥ç°å¢ä¸­å¯¦ç¾ FL çå¨é¨æ½åæï¼è§£æ±ºæè¡ãå¾å¤åå«çèéçå¿è¦æ§ã

##### **A Comprehensive Survey of Mamba Architectures for Medical Image Analysis: Classification, Segmentation, Restoration and Beyond**
2410.02362v1 by Shubhi Bansal, Sreeharish A, Madhava Prasath J, Manikandan S, Sreekanth Madisetty, Mohammad Zia Ur Rehman, Chandravardhan Singh Raghaw, Gaurav Duggal, Nagendra Kumar

Mamba, a special case of the State Space Model, is gaining popularity as an
alternative to template-based deep learning approaches in medical image
analysis. While transformers are powerful architectures, they have drawbacks,
including quadratic computational complexity and an inability to address
long-range dependencies efficiently. This limitation affects the analysis of
large and complex datasets in medical imaging, where there are many spatial and
temporal relationships. In contrast, Mamba offers benefits that make it
well-suited for medical image analysis. It has linear time complexity, which is
a significant improvement over transformers. Mamba processes longer sequences
without attention mechanisms, enabling faster inference and requiring less
memory. Mamba also demonstrates strong performance in merging multimodal data,
improving diagnosis accuracy and patient outcomes. The organization of this
paper allows readers to appreciate the capabilities of Mamba in medical imaging
step by step. We begin by defining core concepts of SSMs and models, including
S4, S5, and S6, followed by an exploration of Mamba architectures such as pure
Mamba, U-Net variants, and hybrid models with convolutional neural networks,
transformers, and Graph Neural Networks. We also cover Mamba optimizations,
techniques and adaptations, scanning, datasets, applications, experimental
results, and conclude with its challenges and future directions in medical
imaging. This review aims to demonstrate the transformative potential of Mamba
in overcoming existing barriers within medical imaging while paving the way for
innovative advancements in the field. A comprehensive list of Mamba
architectures applied in the medical field, reviewed in this work, is available
at Github.

æè¦ï¼Mamba æ¯ä¸ç¨®ç¹æ®é¡åççæç©ºéæ¨¡åï¼éæ¼¸åå°éè¦ï¼æçºé«å­¸å½±ååæä¸­åºæ¼ç¯æ¬çæ·±åº¦å­¸ç¿æ¹æ³çæ¿ä»£æ¹æ¡ãåç®¡Transformeræ¯å¼·å¤§çæ¶æ§ï¼ä½å®åæç¼ºé»ï¼åæ¬äºæ¬¡è¨ç®è¤éåº¦ï¼ä»¥åç¡æ³ææèçé·è·é¢ä¾è³´æ§ãéç¨®éå¶æå½±é¿é«å­¸å½±åä¸­å¤§åè¤éè³æéçåæï¼å¶ä¸­æè¨±å¤ç©ºéåæééä¿ãç¸æ¯ä¹ä¸ï¼Mamba æä¾çåªé»ä½¿å¶éå¸¸é©åé«å­¸å½±ååæãå®å·æç·æ§æéè¤éåº¦ï¼éæ¯ä¸åæ¯Transformeré¡¯èçæ¹é²ãMamba å¨æ²ææ³¨ææ©å¶çææ³ä¸èçæ´é·çåºåï¼å¾èå¯¦ç¾æ´å¿«çæ¨çä¸¦éè¦æ´å°çè¨æ¶é«ãMamba å¨åä½µå¤æ¨¡ææ¸ææ¹é¢ä¹è¡¨ç¾åºå¼·å¤§çæè½ï¼æé«äºè¨ºæ·æºç¢ºæ§åæ£èé å¾ãæ¬æççµç¹æ¹å¼è®è®èå¯ä»¥éæ­¥äºè§£ Mamba å¨é«å­¸å½±åä¸­çåè½ãæåå¾å®ç¾© SSM åæ¨¡åçæ ¸å¿æ¦å¿µéå§ï¼åæ¬ S4ãS5 å S6ï¼ç¶å¾æ¢è¨ Mamba æ¶æ§ï¼ä¾å¦ç´ MambaãU-Net è®é«ï¼ä»¥åå¸¶æå·ç©ç¥ç¶ç¶²è·¯ãTransformerååç¥ç¶ç¶²è·¯çæ··åæ¨¡åãæåéæ¶µèäº Mamba æä½³åãæè¡åæ¹ç·¨ãææãè³æéãæç¨ãå¯¦é©çµæï¼ä¸¦ä»¥å¶å¨é«å­¸å½±åä¸­çææ°åæªä¾æ¹åä½çºçµè«ãæ¬ç¯è©è«æ¨å¨å±ç¤º Mamba å¨åæé«å­¸å½±åä¸­ç¾æéç¤æ¹é¢çè½åæ½åï¼åæçºè©²é åçåµæ°é²æ­¥éªå¹³éè·¯ãå¨éé å·¥ä½ä¸­åé¡§çæç¨æ¼é«å­¸é åç Mamba æ¶æ§çç¶åæ¸å®å¯å¨ Github ä¸åå¾ã

##### **CTARR: A fast and robust method for identifying anatomical regions on CT images via atlas registration**
2410.02316v1 by Thomas Buddenkotte, Roland Opfer, Julia KrÃ¼ger, Alessa Hering, Mireia Crispin-Ortuzar

Medical image analysis tasks often focus on regions or structures located in
a particular location within the patient's body. Often large parts of the image
may not be of interest for the image analysis task. When using deep-learning
based approaches, this causes an unnecessary increases the computational burden
during inference and raises the chance of errors. In this paper, we introduce
CTARR, a novel generic method for CT Anatomical Region Recognition. The method
serves as a pre-processing step for any deep learning-based CT image analysis
pipeline by automatically identifying the pre-defined anatomical region that is
relevant for the follow-up task and removing the rest. It can be used in (i)
image segmentation to prevent false positives in anatomically implausible
regions and speeding up the inference, (ii) image classification to produce
image crops that are consistent in their anatomical context, and (iii) image
registration by serving as a fast pre-registration step. Our proposed method is
based on atlas registration and provides a fast and robust way to crop any
anatomical region encoded as one or multiple bounding box(es) from any
unlabeled CT scan of the brain, chest, abdomen and/or pelvis. We demonstrate
the utility and robustness of the proposed method in the context of medical
image segmentation by evaluating it on six datasets of public segmentation
challenges. The foreground voxels in the regions of interest are preserved in
the vast majority of cases and tasks (97.45-100%) while taking only fractions
of a seconds to compute (0.1-0.21s) on a deep learning workstation and greatly
reducing the segmentation runtime (2.0-12.7x). Our code is available at
https://github.com/ThomasBudd/ctarr.

æè¦ï¼<paragraph>å»å­¦å½±ååæä»»å¡éå¸¸ä¸æ³¨äºæ£èä½åç¹å®ä½ç½®çåºåæç»æãéå¸¸ï¼å½±åçå¤§é¨åå¯è½ä¸å½±ååæä»»å¡æ å³ãå¨ä½¿ç¨åºäºæ·±åº¦å­¦ä¹ çæ¹æ³æ¶ï¼è¿ä¼å¯¼è´å¨æ¨çè¿ç¨ä¸­ä¸å¿è¦å°å¢å è®¡ç®è´æå¹¶å¢å åºéçå¯è½æ§ãå¨æ¬æä¸­ï¼æä»¬ä»ç»äº CTARRï¼ä¸ç§ç¨äº CT è§£ååºåè¯å«çéç¨æ°æ¹æ³ãè¯¥æ¹æ³ä½ä¸ºä»»ä½åºäºæ·±åº¦å­¦ä¹ ç CT å½±ååæç®¡éçé¢å¤çæ­¥éª¤ï¼éè¿èªå¨è¯å«ä¸åç»­ä»»å¡ç¸å³çé¢å®ä¹è§£ååºåå¹¶ç§»é¤å¶ä½é¨åãå®å¯ç¨äº (i) å½±ååå²ï¼ä»¥é²æ­¢å¨è§£åä¸ä¸å¯è½çåºåä¸­åºç°åé³æ§å¹¶å å¿«æ¨çï¼(ii) å½±ååç±»ï¼ä»¥äº§çå¨è§£åèæ¯ä¸ä¸è´çå½±åè£åªï¼ä»¥å (iii) å½±åéåï¼ä½ä¸ºå¿«éé¢éåæ­¥éª¤ãæä»¬æåºçæ¹æ³åºäºå¾è°±éåï¼å¹¶æä¾äºä¸ç§å¿«éä¸ç¨³å¥çæ¹å¼ï¼å¯ä»¥ä»å¤§èãè¸é¨ãè¹é¨å/æéª¨ççä»»ä½æªæ è®° CT æ«æä¸­è£åªç¼ç ä¸ºä¸ä¸ªæå¤ä¸ªè¾¹çæ¡çä»»ä½è§£ååºåãæä»¬éè¿å¨å­ä¸ªå¬å±åå²æææ°æ®éä¸å¯¹å¶è¿è¡è¯ä¼°ï¼è¯æäºææåºæ¹æ³å¨å»å­¦å½±ååå²æ¹é¢çå®ç¨æ§åç¨³å¥æ§ãå¨ç»å¤§å¤æ°æåµä¸åä»»å¡ä¸­ï¼97.45-100%ï¼ï¼æå´è¶£åºåä¸­çåæ¯ä½ç´ å¾ä»¥ä¿çï¼åæ¶ä»éå¨æ·±åº¦å­¦ä¹ å·¥ä½ç«ä¸è±è´¹å åä¹ä¸ç§ï¼0.1-0.21 ç§ï¼è¿è¡è®¡ç®ï¼å¹¶ä¸æå¤§å°ç¼©ç­äºåå²è¿è¡æ¶é´ï¼2.0-12.7 åï¼ãæä»¬çä»£ç å¯å¨ https://github.com/ThomasBudd/ctarr ä¸è·åã</paragraph>

##### **Multi-Omic and Quantum Machine Learning Integration for Lung Subtypes Classification**
2410.02085v1 by Mandeep Kaur Saggi, Amandeep Singh Bhatia, Mensah Isaiah, Humaira Gowher, Sabre Kais

Quantum Machine Learning (QML) is a red-hot field that brings novel
discoveries and exciting opportunities to resolve, speed up, or refine the
analysis of a wide range of computational problems. In the realm of biomedical
research and personalized medicine, the significance of multi-omics integration
lies in its ability to provide a thorough and holistic comprehension of complex
biological systems. This technology links fundamental research to clinical
practice. The insights gained from integrated omics data can be translated into
clinical tools for diagnosis, prognosis, and treatment planning. The fusion of
quantum computing and machine learning holds promise for unraveling complex
patterns within multi-omics datasets, providing unprecedented insights into the
molecular landscape of lung cancer. Due to the heterogeneity, complexity, and
high dimensionality of multi-omic cancer data, characterized by the vast number
of features (such as gene expression, micro-RNA, and DNA methylation) relative
to the limited number of lung cancer patient samples, our prime motivation for
this paper is the integration of multi-omic data, unique feature selection, and
diagnostic classification of lung subtypes: lung squamous cell carcinoma
(LUSC-I) and lung adenocarcinoma (LUAD-II) using quantum machine learning. We
developed a method for finding the best differentiating features between LUAD
and LUSC datasets, which has the potential for biomarker discovery.

æè¦ï¼éå­æ©å¨å­¸ç¿ (QML) æ¯åç±éé åï¼å®å¸¶ä¾æ°ç©çç¼ç¾åä»¤äººèå¥®çæ©æï¼ç¨æ¼è§£æ±ºãå éææ¹é²å°åç¨®è¨ç®åé¡çåæãå¨çç©é«å­¸ç ç©¶ååäººåé«çé åï¼å¤çµå­¸æ´åçéè¦æ§å¨æ¼å®è½å¤ æä¾å°è¤éçç©ç³»çµ±å¨é¢ä¸æ´é«ççè§£ãéé æè¡å°åºç¤ç ç©¶èè¨åºå¯¦åé£çµèµ·ä¾ãå¾æ´åçµå­¸è³æä¸­ç²å¾çè¦è§£å¯ä»¥è½åçºè¨ºæ·ãé å¾åæ²»çè¨ç«çè¨åºå·¥å·ãéå­éç®åæ©å¨å­¸ç¿çèåææè§£éå¤çµå­¸è³æéä¸­çè¤éæ¨¡å¼ï¼æä¾åææªæçè¦è§£ï¼æ·±å¥äºè§£èºççåå­å±¤é¢ãç±æ¼å¤çµå­¸ççè³æçç°è³ªæ§ãè¤éæ§åé«ç¶­åº¦ï¼å¶ç¹å¾µï¼ä¾å¦åºå è¡¨ç¾ãå¾®å RNA å DNA ç²åºåï¼çæ¸éç¸å°æ¼èºçæ£èæ¨£æ¬çæ¸éèè¨éå¸¸é¾å¤§ï¼å æ­¤æåæ°å¯«éç¯è«æçä¸»è¦åæ©æ¯æ´åå¤çµå­¸è³æãç¨ç¹çç¹å¾µé¸æï¼ä»¥åä½¿ç¨éå­æ©å¨å­¸ç¿å°èºçäºåé²è¡è¨ºæ·åé¡ï¼èºé±çç´°èç (LUSC-I) åèºèºç (LUAD-II)ãæåéç¼äºä¸ç¨®æ¹æ³ä¾æ¾åº LUAD å LUSC è³æéä¹éæä½³çååç¹å¾µï¼éææ½åç¨æ¼çç©æ¨è¨çç¼ç¾ã

##### **Zodiac: A Cardiologist-Level LLM Framework for Multi-Agent Diagnostics**
2410.02026v1 by Yuan Zhou, Peng Zhang, Mengya Song, Alice Zheng, Yiwen Lu, Zhiheng Liu, Yong Chen, Zhaohan Xi

Large language models (LLMs) have demonstrated remarkable progress in
healthcare. However, a significant gap remains regarding LLMs' professionalism
in domain-specific clinical practices, limiting their application in real-world
diagnostics. In this work, we introduce ZODIAC, an LLM-powered framework with
cardiologist-level professionalism designed to engage LLMs in cardiological
diagnostics. ZODIAC assists cardiologists by extracting clinically relevant
characteristics from patient data, detecting significant arrhythmias, and
generating preliminary reports for the review and refinement by cardiologists.
To achieve cardiologist-level professionalism, ZODIAC is built on a multi-agent
collaboration framework, enabling the processing of patient data across
multiple modalities. Each LLM agent is fine-tuned using real-world patient data
adjudicated by cardiologists, reinforcing the model's professionalism. ZODIAC
undergoes rigorous clinical validation with independent cardiologists,
evaluated across eight metrics that measure clinical effectiveness and address
security concerns. Results show that ZODIAC outperforms industry-leading
models, including OpenAI's GPT-4o, Meta's Llama-3.1-405B, and Google's
Gemini-pro, as well as medical-specialist LLMs like Microsoft's BioGPT. ZODIAC
demonstrates the transformative potential of specialized LLMs in healthcare by
delivering domain-specific solutions that meet the stringent demands of medical
practice. Notably, ZODIAC has been successfully integrated into
electrocardiography (ECG) devices, exemplifying the growing trend of embedding
LLMs into Software-as-Medical-Device (SaMD).

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å·²å¨é«çä¿å¥é åå±ç¾åºé¡¯èçé²å±ãç¶èï¼LLM å¨ç¹å®é åçè¨åºå¯¦åä¸­å°æ¥­æ§æ¹é¢ä»å­å¨é¡¯èå·®è·ï¼ééå¶äºå®åå¨çå¯¦ä¸çè¨ºæ·ä¸­çæç¨ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äº ZODIACï¼ä¸åç± LLM é©åçæ¶æ§ï¼å·åå¿èçå°ç§é«å¸«ç­ç´çå°æ¥­ç´ é¤ï¼æ¨å¨è® LLM åèå¿èçè¨ºæ·ãZODIAC ééå¾æ£èè³æä¸­æåè¨åºç¸éç¹å¾µãåµæ¸¬é¡¯èå¿å¾ä¸æ´ï¼ä»¥åç¢çåæ­¥å ±åä¾å¿èçå°ç§é«å¸«æª¢é±åä¿®æ¹ï¼ä¾åå©å¿èçå°ç§é«å¸«ãçºäºéå°å¿èçå°ç§é«å¸«ç­ç´çå°æ¥­ç´ é¤ï¼ZODIAC å»ºç«å¨å¤ä»£çåä½æ¶æ§ä¸ï¼è®ä¸åæ¹å¼çæ£èè³æè½å¤ èçãæ¯å LLM ä»£çä½¿ç¨ç±å¿èçå°ç§é«å¸«è£å®ççå¯¦ä¸çæ£èè³æé²è¡å¾®èª¿ï¼å¼·åæ¨¡åçå°æ¥­ç´ é¤ãZODIAC é²è¡å´æ ¼çè¨åºé©è­ï¼ç±ç¨ç«çå¿èçå°ç§é«å¸«é²è¡è©ä¼°ï¼è©éå«é è¡¡éè¨åºæææ§ä¸¦è§£æ±ºå®å¨åé¡çææ¨ãçµæé¡¯ç¤ºï¼ZODIAC çè¡¨ç¾åªæ¼æ¥­çé åçæ¨¡åï¼åæ¬ OpenAI ç GPT-4oãMeta ç Llama-3.1-405Bï¼ä»¥å Google ç Gemini-proï¼ä»¥åå Microsoft ç BioGPT ç­é«çå°å®¶ LLMãZODIAC ééæä¾ç¬¦åé«çå¯¦åå´æ ¼è¦æ±çç¹å®é åè§£æ±ºæ¹æ¡ï¼è­æäºå°æ¥­ LLM å¨é«çä¿å¥é åçè®é©æ½åãå¼å¾æ³¨æçæ¯ï¼ZODIAC å·²æåæ´åå°å¿é»å (ECG) è¨­åä¸­ï¼éé«ç¾äºå° LLM åµå¥è»é«å³é«çè¨­å (SaMD) çè¶¨å¢ã

##### **UlcerGPT: A Multimodal Approach Leveraging Large Language and Vision Models for Diabetic Foot Ulcer Image Transcription**
2410.01989v1 by Reza Basiri, Ali Abedi, Chau Nguyen, Milos R. Popovic, Shehroz S. Khan

Diabetic foot ulcers (DFUs) are a leading cause of hospitalizations and lower
limb amputations, placing a substantial burden on patients and healthcare
systems. Early detection and accurate classification of DFUs are critical for
preventing serious complications, yet many patients experience delays in
receiving care due to limited access to specialized services. Telehealth has
emerged as a promising solution, improving access to care and reducing the need
for in-person visits. The integration of artificial intelligence and pattern
recognition into telemedicine has further enhanced DFU management by enabling
automatic detection, classification, and monitoring from images. Despite
advancements in artificial intelligence-driven approaches for DFU image
analysis, the application of large language models for DFU image transcription
has not yet been explored. To address this gap, we introduce UlcerGPT, a novel
multimodal approach leveraging large language and vision models for DFU image
transcription. This framework combines advanced vision and language models,
such as Large Language and Vision Assistant and Chat Generative Pre-trained
Transformer, to transcribe DFU images by jointly detecting, classifying, and
localizing regions of interest. Through detailed experiments on a public
dataset, evaluated by expert clinicians, UlcerGPT demonstrates promising
results in the accuracy and efficiency of DFU transcription, offering potential
support for clinicians in delivering timely care via telemedicine.

æè¦ï¼ç³å°¿çè¶³æ½°ç (DFU) æ¯å°è´ä½é¢åä¸è¢æªè¢çä¸»è¦åå ï¼å°æ£èåé«çä¿å¥ç³»çµ±é ææ²éè² æãæ©æç¼ç¾åæºç¢ºåé¡ DFU å°æ¼é é²å´éä½µç¼çè³ééè¦ï¼ä½è¨±å¤æ£èå ç¡æ³ç²å¾å°æ¥­æåèå»¶èª¤å°±é«ãé è·é«çå·²æçºä¸åæåéçè§£æ±ºæ¹æ¡ï¼æ¹åäºå°±é«ç®¡éä¸¦æ¸å°è¦ªèªå°±è¨ºçéæ±ãå°äººå·¥æºæ§åæ¨¡å¼è­å¥æ´åå°é è·é«çé²ä¸æ­¥å¢å¼·äº DFU ç®¡çï¼è½å¾å½±åä¸­èªååµæ¸¬ãåé¡åç£æ§ãåç®¡å¨äººå·¥æºæ§é©åç DFU å½±ååææ¹æ³æ¹é¢æé²å±ï¼ä½å°æªæ¢ç´¢å°å¤§åèªè¨æ¨¡åæç¨æ¼ DFU å½±åè½éãçºäºè§£æ±ºéåå·®è·ï¼æåå¼å¥äº UlcerGPTï¼éæ¯ä¸ç¨®æ°ç©çå¤æ¨¡ææ¹æ³ï¼å©ç¨å¤§åèªè¨åè¦è¦ºæ¨¡åé²è¡ DFU å½±åè½éãæ­¤æ¶æ§çµåäºåé²çè¦è¦ºåèªè¨æ¨¡åï¼ä¾å¦å¤§åèªè¨åè¦è¦ºå©çä»¥åèå¤©çæå¼é è¨ç·´è½æå¨ï¼ééå±ååµæ¸¬ãåé¡åå®ä½æèè¶£ååä¾è½é DFU å½±åãééå¨å¬éè³æéä¸é²è¡è©³ç´°å¯¦é©ï¼ä¸¦ç±å°å®¶è¨åºé«å¸«è©ä¼°ï¼UlcerGPT å¨ DFU è½éçæºç¢ºæ§åæçæ¹é¢å±ç¾äºæåæ¯ççµæï¼çºè¨åºé«å¸«ééé è·é«çæä¾åæç§è­·æä¾äºæ½å¨æ¯æ´ã

##### **A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model**
2410.03770v1 by Xueshen Li, Xinlong Hou, Nirupama Ravi, Ziyi Huang, Yu Gan

Efficient patient-doctor interaction is among the key factors for a
successful disease diagnosis. During the conversation, the doctor could query
complementary diagnostic information, such as the patient's symptoms, previous
surgery, and other related information that goes beyond medical evidence data
(test results) to enhance disease diagnosis. However, this procedure is usually
time-consuming and less-efficient, which can be potentially optimized through
computer-assisted systems. As such, we propose a diagnostic dialogue system to
automate the patient information collection procedure. By exploiting medical
history and conversation logic, our conversation agents, particularly the
doctor agent, can pose multi-round clinical queries to effectively collect the
most relevant disease diagnostic information. Moreover, benefiting from our
two-stage recommendation structure, carefully designed ranking criteria, and
interactive patient agent, our model is able to overcome the under-exploration
and non-flexible challenges in dialogue generation. Our experimental results on
a real-world medical conversation dataset show that our model can generate
clinical queries that mimic the conversation style of real doctors, with
efficient fluency, professionalism, and safety, while effectively collecting
relevant disease diagnostic information.

æè¦ï¼<paragraph>ææçççæ£èé«çäºåæ¯ç¾çè¨ºæ·æåçééµè¦ç´ ä¹ä¸ãå¨å°è©±ä¸­ï¼é«çå¯ä»¥æ¥è©¢è£åæ§çè¨ºæ·è³è¨ï¼ä¾å¦çæ£çççãååçå¤ç§æè¡ï¼ä»¥åå¶ä»ç¸éçè³è¨ï¼éäºè³è¨è¶åºäºé«çè­æè³æï¼æª¢é©çµæï¼çç¯åï¼å¯ä»¥å¢å¼·ç¾çè¨ºæ·ãç¶èï¼æ­¤ç¨åºéå¸¸èæä¸æçè¼ä½ï¼å¯ä»¥ééé»è¦è¼å©ç³»çµ±é²è¡æ½å¨çæä½³åãå æ­¤ï¼æåæåºä¸åè¨ºæ·å°è©±ç³»çµ±ä¾èªååçæ£è³è¨æ¶éç¨åºãééå©ç¨çå²åå°è©±éè¼¯ï¼æåçå°è©±ä»£çï¼ç¹å¥æ¯é«çä»£çï¼å¯ä»¥æåºå¤è¼ªçè¨åºæ¥è©¢ï¼ä»¥æææ¶éæç¸éçç¾çè¨ºæ·è³è¨ãæ­¤å¤ï¼å¾çæ¼æåçå©éæ®µå»ºè­°çµæ§ãç²¾å¿è¨­è¨çæåæºååäºåå¼çæ£ä»£çï¼æåçæ¨¡åè½å¤ åæå°è©±ç¢çä¸­çæ¢ç´¢ä¸è¶³åä¸éæ´»çææ°ãæåå¨çå¯¦ä¸ççé«çå°è©±è³æéä¸çå¯¦é©çµæé¡¯ç¤ºï¼æåçæ¨¡åå¯ä»¥ç¢çæ¨¡æ¬çå¯¦é«çå°è©±é¢¨æ ¼çè¨åºæ¥è©¢ï¼å·ææµæ¢ãå°æ¥­åå®å¨çæçï¼åææææ¶éç¸éçç¾çè¨ºæ·è³è¨ã</paragraph>

##### **DeFine: Enhancing LLM Decision-Making with Factor Profiles and Analogical Reasoning**
2410.01772v1 by Yebowen Hu, Xiaoyang Wang, Wenlin Yao, Yiming Lu, Daoan Zhang, Hassan Foroosh, Dong Yu, Fei Liu

LLMs are ideal for decision-making due to their ability to reason over long
contexts and identify critical factors. However, challenges arise when
processing transcripts of spoken speech describing complex scenarios. These
transcripts often contain ungrammatical or incomplete sentences, repetitions,
hedging, and vagueness. For example, during a company's earnings call, an
executive might project a positive revenue outlook to reassure investors,
despite significant uncertainty regarding future earnings. It is crucial for
LLMs to incorporate this uncertainty systematically when making decisions. In
this paper, we introduce DeFine, a new framework that constructs probabilistic
factor profiles from complex scenarios. DeFine then integrates these profiles
with analogical reasoning, leveraging insights from similar past experiences to
guide LLMs in making critical decisions in novel situations. Our framework
separates the tasks of quantifying uncertainty in complex scenarios and
incorporating it into LLM decision-making. This approach is particularly useful
in fields such as medical consultations, negotiations, and political debates,
where making decisions under uncertainty is vital.

æè¦ï¼LLM éå¸¸é©åç¨æ¼æ±ºç­å¶å®ï¼å çºå®åè½å¤ å°é·ç¯èçµ¡é²è¡æ¨çä¸¦æ¾åºééµå ç´ ãç¶èï¼å¨èçæè¿°è¤éå ´æ¯çå£èªè½éææç¢çææ°ãéäºè½ééå¸¸åå«ä¸ç¬¦åææ³æä¸å®æ´çå¥å­ãéè¤ãè¿´é¿åæ¨¡ç³ãä¾å¦ï¼å¨å¬å¸çæ¶çé»è©±æè­°ä¸­ï¼ä¸ä½ä¸»ç®¡å¯è½æé æ¸¬æ­£é¢çæ¶çåæ¯ä»¥å®æ«æè³äººï¼åç®¡å°æªä¾çæ¶çæå¾å¤§çä¸ç¢ºå®æ§ãå°æ¼ LLM ä¾èªªï¼å¨åæ±ºç­æç³»çµ±æ§å°ç´å¥éç¨®ä¸ç¢ºå®æ§è³ééè¦ãå¨æ¬æä¸­ï¼æåä»ç´¹äº DeFineï¼ä¸åå¾è¤éå ´æ¯æ§å»ºæ©çå å­è¼ªå»çæ°æ¶æ§ãç¶å¾ï¼DeFine å°éäºè¼ªå»èé¡æ¯æ¨çæ´åï¼å©ç¨éå»é¡ä¼¼ç¶é©ä¸­çè¦è§£ä¾å¼å° LLM å¨æ°ææ³ä¸­ååºééµæ±ºç­ãæåçæ¶æ§å°éåè¤éå ´æ¯ä¸­çä¸ç¢ºå®æ§ä»¥åå°å¶ç´å¥ LLM æ±ºç­å¶å®çä»»ååéãéç¨®æ¹æ³å¨é«çè«®è©¢ãè«å¤åæ¿æ²»è¾¯è«ç­é åç¹å¥æç¨ï¼å¨éäºé åä¸­ï¼å¨ä¸ç¢ºå®æ§ä¸ååºæ±ºç­è³ééè¦ã

##### **Towards a vision foundation model for comprehensive assessment of Cardiac MRI**
2410.01665v2 by Athira J Jacob, Indraneel Borgohain, Teodora Chitiboi, Puneet Sharma, Dorin Comaniciu, Daniel Rueckert

Cardiac magnetic resonance imaging (CMR), considered the gold standard for
noninvasive cardiac assessment, is a diverse and complex modality requiring a
wide variety of image processing tasks for comprehensive assessment of cardiac
morphology and function. Advances in deep learning have enabled the development
of state-of-the-art (SoTA) models for these tasks. However, model training is
challenging due to data and label scarcity, especially in the less common
imaging sequences. Moreover, each model is often trained for a specific task,
with no connection between related tasks. In this work, we introduce a vision
foundation model trained for CMR assessment, that is trained in a
self-supervised fashion on 36 million CMR images. We then finetune the model in
supervised way for 9 clinical tasks typical to a CMR workflow, across
classification, segmentation, landmark localization, and pathology detection.
We demonstrate improved accuracy and robustness across all tasks, over a range
of available labeled dataset sizes. We also demonstrate improved few-shot
learning with fewer labeled samples, a common challenge in medical image
analyses. We achieve an out-of-box performance comparable to SoTA for most
clinical tasks. The proposed method thus presents a resource-efficient, unified
framework for CMR assessment, with the potential to accelerate the development
of deep learning-based solutions for image analysis tasks, even with few
annotated data available.

æè¦ï¼å¿èç£æ¯é å½± (CMR) è¢«è¦çºéä¾µå¥æ§å¿èè©ä¼°çéæ¨æºï¼æ¯ä¸ç¨®å¤åä¸è¤éçæ¨¡å¼ï¼éè¦å»£æ³çå½±åèçä»»åæè½å¨é¢è©ä¼°å¿èå½¢æååè½ãæ·±åº¦å­¸ç¿çé²æ­¥ä½¿å¾éç¼éäºä»»åçææ°æè¡ (SoTA) æ¨¡åæçºå¯è½ãç¶èï¼æ¨¡åè¨ç·´ç±æ¼è³æåæ¨ç±¤çç¨å°æ§èå·æææ°æ§ï¼å°¤å¶æ¯å¨è¼ä¸å¸¸è¦çå½±ååºåä¸­ãæ­¤å¤ï¼æ¯åæ¨¡åéå¸¸éå°ç¹å®ä»»åé²è¡è¨ç·´ï¼èç¸éä»»åä¹éæ²æéè¯æ§ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºä¸åéå° CMR è©ä¼°è¨ç·´çè¦è¦ºåºç¤æ¨¡åï¼è©²æ¨¡åä»¥èªç£ç£çæ¹å¼å¨ 3600 è¬å¼µ CMR å½±åä¸é²è¡è¨ç·´ãç¶å¾ï¼æåä»¥ç£ç£æ¹å¼å°æ¨¡åé²è¡å¾®èª¿ï¼ä»¥å·è¡ CMR å·¥ä½æµç¨ä¸­å¸åç 9 é è¨åºä»»åï¼åæ¬åé¡ãåå²ãå°æ¨å®ä½åççæª¢æ¸¬ãæåè­æäºå¨åç¨®å¯ç¨æ¨ç±¤è³æéå¤§å°ä¸­ï¼ææä»»åçæºç¢ºæ§åç©©å¥æ§é½æææé«ãæåéå±ç¤ºäºå¨æ¨ç±¤æ¨£æ¬è¼å°çææ³ä¸æ¹é²ç few-shot å­¸ç¿ï¼éæ¯é«å­¸å½±ååæä¸­å¸¸è¦çææ°ãæåå¯¦ç¾äºèå¤§å¤æ¸è¨åºä»»åç SoTA ç¸ç¶çéç®±å³ç¨æè½ãå æ­¤ï¼ææåºçæ¹æ³æä¾äºä¸åè³æºé«æççµ±ä¸æ¡æ¶ï¼ç¨æ¼ CMR è©ä¼°ï¼ä¸¦æå¯è½å éåºæ¼æ·±åº¦å­¸ç¿çå½±ååæä»»åçè§£æ±ºæ¹æ¡éç¼ï¼å³ä½¿åªæå°éçè¨»è§£è³æå¯ç¨ã

##### **Imaging foundation model for universal enhancement of non-ideal measurement CT**
2410.01591v1 by Yuxin Liu, Rongjun Ge, Yuting He, Zhan Wu, Chenyu You, Shuo Li, Yang Chen

Non-ideal measurement computed tomography (NICT), which sacrifices optimal
imaging standards for new advantages in CT imaging, is expanding the clinical
application scope of CT images. However, with the reduction of imaging
standards, the image quality has also been reduced, extremely limiting the
clinical acceptability. Although numerous studies have demonstrated the
feasibility of deep learning for the NICT enhancement in specific scenarios,
their high data cost and limited generalizability have become large obstacles.
The recent research on the foundation model has brought new opportunities for
building a universal NICT enhancement model - bridging the image quality
degradation with minimal data cost. However, owing to the challenges in the
collection of large pre-training datasets and the compatibility of data
variation, no success has been reported. In this paper, we propose a
multi-scale integrated Transformer AMPlifier (TAMP), the first imaging
foundation model for universal NICT enhancement. It has been pre-trained on a
large-scale physical-driven simulation dataset with 3.6 million NICT-ICT image
pairs, and is able to directly generalize to the NICT enhancement tasks with
various non-ideal settings and body regions. Via the adaptation with few data,
it can further achieve professional performance in real-world specific
scenarios. Our extensive experiments have demonstrated that the proposed TAMP
has significant potential for promoting the exploration and application of NICT
and serving a wider range of medical scenarios.

æè¦ï¼éçæ³æ¸¬éé»è¦æ·å±¤ææ (NICT) ç§ç²äºæä½³å½±åæ¨æºä»¥æåé»è¦æ·å±¤ææå½±åçæ°åªå¢ï¼æ­£å¨æ´å±é»è¦æ·å±¤å½±åçè¨åºæç¨ç¯åãç¶èï¼é¨èå½±åæ¨æºçéä½ï¼å½±ååè³ªä¹é¨ä¹éä½ï¼æ¥µå¤§å°éå¶äºè¨åºå¯æ¥åæ§ãåç®¡è¨±å¤ç ç©¶å·²è­ææ·±åº¦å­¸ç¿å¨ç¹å®å ´æ¯ä¸­å¯è¡ï¼ä½å¶é«è³æææ¬åæéçæ¦æ¬æ§å·²æçºéå¤§çéç¤ãæè¿å°åºç¤æ¨¡åçç ç©¶çºå»ºç«éç¨ NICT å¢å¼·æ¨¡åå¸¶ä¾äºæ°çæ©æï¼ä»¥æå°çè³æææ¬å½åå½±ååè³ªä¸éçåé¡ãç¶èï¼ç±æ¼æ¶éå¤§åé è¨ç·´è³æéåè³æè®ç°çç¸å®¹æ§æ¹é¢çææ°ï¼å°æªå ±åæåãå¨æ¬æä¸­ï¼æåæåºäºä¸åå¤å°ºåº¦æ´åTransformeræ¾å¤§å¨ (TAMP)ï¼éæ¯ç¬¬ä¸åç¨æ¼éç¨ NICT å¢å¼·çå½±ååºç¤æ¨¡åãå®å·²å¨ä¸ååå« 360 è¬å NICT-ICT å½±åå°çå¤§åç©çé©åæ¨¡æ¬è³æéä¸é²è¡é è¨ç·´ï¼ä¸¦ä¸è½å¤ ç´æ¥æ¦æ¬å°å·æåç¨®éçæ³è¨­å®åèº«é«ååç NICT å¢å¼·ä»»åãééå°æ¸è³æçé©æï¼å®å¯ä»¥å¨ç¾å¯¦ä¸ççç¹å®å ´æ¯ä¸­é²ä¸æ­¥å¯¦ç¾å°æ¥­æè½ãæåçå»£æ³å¯¦é©è¡¨æï¼ææåºç TAMP å·æä¿é² NICT çæ¢ç´¢åæç¨ä¸¦æåæ¼æ´å»£æ³çé«çå ´æ¯çå·¨å¤§æ½åã

##### **OpenMathInstruct-2: Accelerating AI for Math with Massive Open-Source Instruction Data**
2410.01560v2 by Shubham Toshniwal, Wei Du, Ivan Moshkov, Branislav Kisacanin, Alexan Ayrapetyan, Igor Gitman

Mathematical reasoning continues to be a critical challenge in large language
model (LLM) development with significant interest. However, most of the
cutting-edge progress in mathematical reasoning with LLMs has become
\emph{closed-source} due to lack of access to training data. This lack of data
access limits researchers from understanding the impact of different choices
for synthesizing and utilizing the data. With the goal of creating a
high-quality finetuning (SFT) dataset for math reasoning, we conduct careful
ablation experiments on data synthesis using the recently released
\texttt{Llama3.1} family of models. Our experiments show that: (a) solution
format matters, with excessively verbose solutions proving detrimental to SFT
performance, (b) data generated by a strong teacher outperforms equally-sized
data generated by a weak student model, (c) SFT is robust to low-quality
solutions, allowing for imprecise data filtering, and (d) question diversity is
crucial for achieving data scaling gains. Based on these insights, we create
the OpenMathInstruct-2 dataset, which consists of 14M question-solution pairs
($\approx$ 600K unique questions), making it nearly eight times larger than the
previous largest open-source math reasoning dataset. Finetuning the
\texttt{Llama-3.1-8B-Base} using OpenMathInstruct-2 outperforms
\texttt{Llama3.1-8B-Instruct} on MATH by an absolute 15.9\% (51.9\%
$\rightarrow$ 67.8\%). Finally, to accelerate the open-source efforts, we
release the code, the finetuned models, and the OpenMathInstruct-2 dataset
under a commercially permissive license.

æè¦ï¼<paragraph>æ¸å­¸æ¨çå¨å¤§åèªè¨æ¨¡å (LLM) çç¼å±ä¸­æçºæçºä¸é ééµææ°ï¼ä¸¦å¼èµ·æ¥µå¤§çèè¶£ãç¶èï¼ç±æ¼ç¼ºä¹è¨ç·´è³æçå­åï¼å¤§å¤æ¸ LLM å¨æ¸å­¸æ¨çæ¹é¢çå°ç«¯é²å±å·²æçºãå°éåå§ç¢¼ããéç¨®è³æå­åçç¼ºä¹éå¶äºç ç©¶äººå¡äºè§£ä¸åé¸æå°ç¶ååå©ç¨è³æçå½±é¿ãçºäºå»ºç«ä¸åç¨æ¼æ¸å­¸æ¨ççé«åè³ªå¾®èª¿ (SFT) è³æéï¼æåä½¿ç¨æè¿ç¼å¸ç \texttt{Llama3.1} æ¨¡åç³»åå°è³æåæé²è¡äºä»ç´°çæ¶èå¯¦é©ãæåçå¯¦é©è¡¨æï¼(a) è§£ç­æ ¼å¼å¾éè¦ï¼éæ¼åé·çè§£ç­æå° SFT æè½é ææå®³ï¼(b) ç±å¼·èå¸«ç¢ççè³æåªæ¼ç±å¼±å­¸çæ¨¡åç¢ççç¸åå¤§å°è³æï¼(c) SFT å°ä½åè³ªè§£ç­å·æé­¯æ£æ§ï¼åè¨±é²è¡ä¸ç²¾ç¢ºçè³æéæ¿¾ï¼ä»¥å (d) åé¡çå¤æ¨£æ§å°æ¼å¯¦ç¾è³ææ´åå¢çè³ééè¦ãæ ¹æéäºè¦è§£ï¼æåå»ºç«äº OpenMathInstruct-2 è³æéï¼å¶ä¸­åå« 1400 è¬ååé¡è§£ç­å°ï¼ç´ 60 è¬åç¨ç¹åé¡ï¼ï¼ä½¿å¶è¦æ¨¡å¹¾ä¹æ¯ä¹åæå¤§çéæºæ¸å­¸æ¨çè³æéçå«åãä½¿ç¨ OpenMathInstruct-2 å¾®èª¿ \texttt{Llama-3.1-8B-Base} å¨ MATH ä¸çè¡¨ç¾åªæ¼ \texttt{Llama3.1-8B-Instruct}ï¼çµå°åªå¢ 15.9%ï¼51.9% â 67.8%ï¼ãæå¾ï¼çºäºå ééæºå·¥ä½ï¼æåå¨åæ¥­è¨±å¯ä¸ç¼å¸äºç¨å¼ç¢¼ãå¾®èª¿æ¨¡åå OpenMathInstruct-2 è³æéã</paragraph>

##### **MedQA-CS: Benchmarking Large Language Models Clinical Skills Using an AI-SCE Framework**
2410.01553v1 by Zonghai Yao, Zihao Zhang, Chaolong Tang, Xingyu Bian, Youxia Zhao, Zhichao Yang, Junda Wang, Huixue Zhou, Won Seok Jang, Feiyun Ouyang, Hong Yu

Artificial intelligence (AI) and large language models (LLMs) in healthcare
require advanced clinical skills (CS), yet current benchmarks fail to evaluate
these comprehensively. We introduce MedQA-CS, an AI-SCE framework inspired by
medical education's Objective Structured Clinical Examinations (OSCEs), to
address this gap. MedQA-CS evaluates LLMs through two instruction-following
tasks, LLM-as-medical-student and LLM-as-CS-examiner, designed to reflect real
clinical scenarios. Our contributions include developing MedQA-CS, a
comprehensive evaluation framework with publicly available data and expert
annotations, and providing the quantitative and qualitative assessment of LLMs
as reliable judges in CS evaluation. Our experiments show that MedQA-CS is a
more challenging benchmark for evaluating clinical skills than traditional
multiple-choice QA benchmarks (e.g., MedQA). Combined with existing benchmarks,
MedQA-CS enables a more comprehensive evaluation of LLMs' clinical capabilities
for both open- and closed-source LLMs.

æè¦ï¼äººå·¥æºæ§ (AI) åå¤§åèªè¨æ¨¡å (LLM) å¨é«çä¿å¥ä¸­
éè¦é²éçè¨åºæè½ (CS)ï¼ä½ç®åçåºæºç¡æ³å¨é¢è©ä¼°
éäºæè½ãæåå¼å¥äº MedQA-CSï¼ä¸åå
é«å­¸æè²çå®¢è§çµæ§åè¨åºèè©¦ (OSCE) åç¼ç AI-SCE æ¶æ§ï¼ä»¥
è§£æ±ºéåå·®è·ãMedQA-CS ééå©åæä»¤éµå¾ªä»»åä¾è©ä¼° LLMï¼LLM
æ®æ¼é«å­¸çå LLM æ®æ¼ CS èå®ï¼æ¨å¨åæ çå¯¦
çè¨åºå ´æ¯ãæåçè²¢ç»åæ¬éç¼ MedQA-CSï¼ä¸å
åå«å¬éå¯ç¨è³æåå°å®¶è¨»è§£çç¶åè©ä¼°æ¶æ§ï¼ä¸¦æä¾ LLM
ä½çº CS è©ä¼°ä¸­å¯é è©åèçéååè³ªæ§è©ä¼°ãæåçå¯¦é©é¡¯ç¤ºï¼MedQA-CS æ¯
ä¸åæ¯å³çµ±å¤é¸é¡ QA åºæºï¼ä¾å¦ MedQAï¼æ´å·ææ°æ§çè¨åºæè½è©ä¼°åºæºãçµåç¾æåºæºï¼
MedQA-CS è½å¤ æ´å¨é¢å°è©ä¼° LLM çè¨åºè½åï¼é©ç¨æ¼éæ¾åå§ç¢¼åéæº LLMã

##### **On the Convergence of FedProx with Extrapolation and Inexact Prox**
2410.01410v1 by Hanmin Li, Peter RichtÃ¡rik

Enhancing the FedProx federated learning algorithm (Li et al., 2020) with
server-side extrapolation, Li et al. (2024a) recently introduced the FedExProx
method. Their theoretical analysis, however, relies on the assumption that each
client computes a certain proximal operator exactly, which is impractical since
this is virtually never possible to do in real settings. In this paper, we
investigate the behavior of FedExProx without this exactness assumption in the
smooth and globally strongly convex setting. We establish a general convergence
result, showing that inexactness leads to convergence to a neighborhood of the
solution. Additionally, we demonstrate that, with careful control, the adverse
effects of this inexactness can be mitigated. By linking inexactness to biased
compression (Beznosikov et al., 2023), we refine our analysis, highlighting
robustness of extrapolation to inexact proximal updates. We also examine the
local iteration complexity required by each client to achieved the required
level of inexactness using various local optimizers. Our theoretical insights
are validated through comprehensive numerical experiments.

æè¦ï¼ééä¼ºæå¨ç«¯å¤æ¨å¢å¼· FedProx è¯é¦å­¸ç¿æ¼ç®æ³ï¼Li ç­äººï¼2020ï¼ï¼Li ç­äººï¼2024aï¼æè¿å¼å¥äº FedExProx æ¹æ³ãç¶èï¼ä»åççè«åæä¾è³´æ¼æ¯åå®¢æ¶ç«¯é½ç²¾ç¢ºè¨ç®åºæåè¿ç«¯ç®å­çåè¨­ï¼éå¨å¯¦éç°å¢ä¸­å¹¾ä¹ä¸å¯è½åå°ï¼å æ­¤ä¸åå¯¦éãå¨æ¬æä¸­ï¼æåç ç©¶äºå¨å¹³æ»ä¸å¨å±å¼·å¸è¨­å®ä¸­ï¼æ²ææ­¤ç²¾ç¢ºåº¦åè¨­ç FedExProx è¡çºãæåå»ºç«äºä¸åéç¨çæ¶æçµæï¼è¡¨æä¸ç²¾ç¢ºåº¦æå°è´æ¶æå°è§£çé°åãæ­¤å¤ï¼æåè­æééä»ç´°æ§å¶ï¼å¯ä»¥æ¸è¼éç¨®ä¸ç²¾ç¢ºåº¦çè² é¢å½±é¿ãééå°ä¸ç²¾ç¢ºåº¦é£çµå°æåå£ç¸®ï¼Beznosikov ç­äººï¼2023ï¼ï¼æåæ¹é²äºåæï¼å¼·èª¿å¤æ¨å°ä¸ç²¾ç¢ºè¿ç«¯æ´æ°çç©©å¥æ§ãæåéç ç©¶äºæ¯åå®¢æ¶ç«¯éå°çä¸ç²¾ç¢ºåº¦æéçå°æ¹åè¦éç®è¤éåº¦ï¼ä¸¦ä½¿ç¨åç¨®å°æ¹æä½³åå¨ãæåççè«è¦è§£å·²ééå¨é¢çæ¸å¼å¯¦é©é©è­ã

##### **See Me and Believe Me: Causality and Intersectionality in Testimonial Injustice in Healthcare**
2410.01227v1 by Kenya S. Andrews, Mesrob I. Ohannessian, Elena Zheleva

In medical settings, it is critical that all who are in need of care are
correctly heard and understood. When this is not the case due to prejudices a
listener has, the speaker is experiencing \emph{testimonial injustice}, which,
building upon recent work, we quantify by the presence of several categories of
unjust vocabulary in medical notes. In this paper, we use FCI, a causal
discovery method, to study the degree to which certain demographic features
could lead to marginalization (e.g., age, gender, and race) by way of
contributing to testimonial injustice. To achieve this, we review physicians'
notes for each patient, where we identify occurrences of unjust vocabulary,
along with the demographic features present, and use causal discovery to build
a Structural Causal Model (SCM) relating those demographic features to
testimonial injustice. We analyze and discuss the resulting SCMs to show the
interaction of these factors and how they influence the experience of
injustice. Despite the potential presence of some confounding variables, we
observe how one contributing feature can make a person more prone to
experiencing another contributor of testimonial injustice. There is no single
root of injustice and thus intersectionality cannot be ignored. These results
call for considering more than singular or equalized attributes of who a person
is when analyzing and improving their experiences of bias and injustice. This
work is thus a first foray at using causal discovery to understand the nuanced
experiences of patients in medical settings, and its insights could be used to
guide design principles throughout healthcare, to build trust and promote
better patient care.

æè¦ï¼å¨é«çå ´æ¯ä¸­ï¼ææéè¦ç§è­·çäººé½è½è¢«æ­£ç¢ºå°èè½åçè§£è³ééè¦ãç¶éå çºè½èçåè¦èç¡æ³ç¼çæï¼èªªè©±èä¾¿æç¶æ­·ãè¦è­ä¸æ­£ç¾©ãï¼èæåæ ¹æè¿æçç ç©¶ï¼ééé«çç´éä¸­åºç¾çä¸å¬æ­£è©å½é¡å¥ä¾éåè¦è­ä¸æ­£ç¾©ãå¨æ¬æä¸­ï¼æåä½¿ç¨å æç¼ç¾æ¹æ³ FCI ä¾ç ç©¶æäºäººå£ç¹å¾µå¯è½ééä¿æè¦è­ä¸æ­£ç¾©ï¼é²èå°è´éç·£åï¼ä¾å¦å¹´é½¡ãæ§å¥åç¨®æï¼çç¨åº¦ãçºéææ­¤ç®çï¼æåæª¢è¦æ¯ä½çæ£çé«å¸«ç´éï¼æ¾åºä¸å¬æ­£è©å½åºç¾çææ©ä»¥åå­å¨çäººå£ç¹å¾µï¼ä¸¦ä½¿ç¨å æç¼ç¾å»ºç«çµæ§å ææ¨¡å (SCM)ï¼å°éäºäººå£ç¹å¾µèè¦è­ä¸æ­£ç¾©éè¯èµ·ä¾ãæååæä¸¦è¨è«ç¢çç SCMï¼ä»¥é¡¯ç¤ºéäºå ç´ çäº¤äºä½ç¨ï¼ä»¥åå®åå¦ä½å½±é¿ä¸æ­£ç¾©çé«é©ãåç®¡å­å¨ä¸äºæ½å¨çæ··æ·è®å ï¼æåè§å¯å°ä¸åä¿æå ç´ å¦ä½è®ä¸åäººæ´å®¹æç¶æ­·å¦ä¸åè¦è­ä¸æ­£ç¾©çä¿æå ç´ ãä¸æ­£ç¾©æ²æå®ä¸æ ¹æºï¼å æ­¤ç¡æ³å¿½è¦äº¤åæ§ãéäºçµæå¼ç±²å¨åæåæ¹åäººåçåè¦åä¸æ­£ç¾©é«é©æï¼èéçä¸åªæ¯åäººçå®ä¸æå¹³ç­å±¬æ§ãå æ­¤ï¼éé ç ç©¶æ¯ä½¿ç¨å æç¼ç¾ä¾äºè§£é«çå ´æ¯ä¸­çæ£ç´°å¾®é«é©çé¦æ¬¡åè©¦ï¼èå¶è¦è§£å¯ç¨æ¼å¼å°æ´åé«çä¿å¥çè¨­è¨ååï¼å»ºç«ä¿¡ä»»ä¸¦ä¿é²æ´å¥½ççæ£ç§è­·ã

##### **Explainable Diagnosis Prediction through Neuro-Symbolic Integration**
2410.01855v1 by Qiuhao Lu, Rui Li, Elham Sagheb, Andrew Wen, Jinlian Wang, Liwei Wang, Jungwei W. Fan, Hongfang Liu

Diagnosis prediction is a critical task in healthcare, where timely and
accurate identification of medical conditions can significantly impact patient
outcomes. Traditional machine learning and deep learning models have achieved
notable success in this domain but often lack interpretability which is a
crucial requirement in clinical settings. In this study, we explore the use of
neuro-symbolic methods, specifically Logical Neural Networks (LNNs), to develop
explainable models for diagnosis prediction. Essentially, we design and
implement LNN-based models that integrate domain-specific knowledge through
logical rules with learnable thresholds. Our models, particularly
$M_{\text{multi-pathway}}$ and $M_{\text{comprehensive}}$, demonstrate superior
performance over traditional models such as Logistic Regression, SVM, and
Random Forest, achieving higher accuracy (up to 80.52\%) and AUROC scores (up
to 0.8457) in the case study of diabetes prediction. The learned weights and
thresholds within the LNN models provide direct insights into feature
contributions, enhancing interpretability without compromising predictive
power. These findings highlight the potential of neuro-symbolic approaches in
bridging the gap between accuracy and explainability in healthcare AI
applications. By offering transparent and adaptable diagnostic models, our work
contributes to the advancement of precision medicine and supports the
development of equitable healthcare solutions. Future research will focus on
extending these methods to larger and more diverse datasets to further validate
their applicability across different medical conditions and populations.

æè¦ï¼è¨ºæ·é æ¸¬æ¯é«çä¿å¥ä¸­çä¸é ééµä»»åï¼åæä¸æºç¢ºå°è­å¥é«ççæ³æå°æ£èççµæç¢çéå¤§å½±é¿ãå³çµ±æ©å¨å­¸ç¿åæ·±åº¦å­¸ç¿æ¨¡åå·²å¨æ­¤é ååå¾é¡¯èæåï¼ä½éå¸¸ç¼ºä¹å¯è§£éæ§ï¼éæ¯è¨åºç°å¢ä¸­çééµè¦æ±ãå¨æ¬ç ç©¶ä¸­ï¼æåæ¢è¨äºç¥ç¶ç¬¦èæ¹æ³ï¼ç¹å¥æ¯éè¼¯ç¥ç¶ç¶²è·¯ (LNN)ï¼ä»¥éç¼å¯è§£éçè¨ºæ·é æ¸¬æ¨¡åãåºæ¬ä¸ï¼æåè¨­è¨ä¸¦å¯¦ä½äºåºæ¼ LNN çæ¨¡åï¼è©²æ¨¡åéééè¼¯è¦ååå¯å­¸ç¿çé¾å¼æ´åé åç¹å®çç¥è­ãæåçæ¨¡åï¼ç¹å¥æ¯ $M_{\text{multi-pathway}}$ å $M_{\text{comprehensive}}$ï¼è¡¨ç¾åºåªæ¼å³çµ±æ¨¡åï¼å¦éè¼¯è¿´æ­¸ãSVM åé¨æ©æ£®æï¼çåè¶æè½ï¼å¨ç³å°¿çé æ¸¬çæ¡ä¾ç ç©¶ä¸­ï¼éå°äºæ´é«çæºç¢ºåº¦ï¼é«é 80.52%ï¼å AUROC åæ¸ï¼é«é 0.8457ï¼ãLNN æ¨¡åä¸­å­¸ç¿çæ¬éåé¾å¼æä¾äºå°ç¹å¾µè²¢ç»çç´æ¥è¦è§£ï¼å¢å¼·äºå¯è§£éæ§ï¼åæä¸æå®³é æ¸¬è½åãéäºç¼ç¾çªé¡¯äºç¥ç¶ç¬¦èæ¹æ³å¨å½åé«çä¿å¥ AI æç¨ä¸­æºç¢ºæ§åå¯è§£éæ§å·®è·æ¹é¢çæ½åãééæä¾éæä¸é©ææ§å¼·çè¨ºæ·æ¨¡åï¼æåçç ç©¶æå©æ¼ç²¾æºé«ççé²æ­¥ï¼ä¸¦æ¯æ´å¬å¹³é«çä¿å¥è§£æ±ºæ¹æ¡çéç¼ãæªä¾çç ç©¶å°å°æ³¨æ¼å°éäºæ¹æ³æ´å±å°æ´å¤§ä¸æ´å¤æ¨£åçè³æéï¼ä»¥é²ä¸æ­¥é©è­å¶å¨ä¸åé«ççæ³åäººç¾¤ä¸­çé©ç¨æ§ã

##### **Heterogeneous sound classification with the Broad Sound Taxonomy and Dataset**
2410.00980v1 by Panagiota Anastasopoulou, Jessica Torrey, Xavier Serra, Frederic Font

Automatic sound classification has a wide range of applications in machine
listening, enabling context-aware sound processing and understanding. This
paper explores methodologies for automatically classifying heterogeneous sounds
characterized by high intra-class variability. Our study evaluates the
classification task using the Broad Sound Taxonomy, a two-level taxonomy
comprising 28 classes designed to cover a heterogeneous range of sounds with
semantic distinctions tailored for practical user applications. We construct a
dataset through manual annotation to ensure accuracy, diverse representation
within each class and relevance in real-world scenarios. We compare a variety
of both traditional and modern machine learning approaches to establish a
baseline for the task of heterogeneous sound classification. We investigate the
role of input features, specifically examining how acoustically derived sound
representations compare to embeddings extracted with pre-trained deep neural
networks that capture both acoustic and semantic information about sounds.
Experimental results illustrate that audio embeddings encoding acoustic and
semantic information achieve higher accuracy in the classification task. After
careful analysis of classification errors, we identify some underlying reasons
for failure and propose actions to mitigate them. The paper highlights the need
for deeper exploration of all stages of classification, understanding the data
and adopting methodologies capable of effectively handling data complexity and
generalizing in real-world sound environments.

æè¦ï¼èªåè²é³åé¡å¨æ©å¨èè½ä¸­å·æå»£æ³çæç¨ï¼å¯å¯¦ç¾æå¢æç¥çè²é³èçåçè§£ãæ¬ææ¢è¨äºèªååé¡ç°è³ªè²é³çæ¹æ³ï¼å¶ç¹é»æ¯é¡å§è®ç°æ§é«ãæåçç ç©¶ä½¿ç¨å»£æ³è²é³åé¡æ³è©ä¼°åé¡ä»»åï¼å»£æ³è²é³åé¡æ³æ¯ä¸ç¨®å©ç´åé¡æ³ï¼åå« 28 åé¡å¥ï¼æ¨å¨æ¶µèç¯åå»£æ³çç°è³ªè²é³ï¼ä¸¦éå°å¯¦éä½¿ç¨èæç¨éèº«æé èªç¾©åå¥ãæåééæåè¨»è§£æ§å»ºä¸åæ¸æéï¼ä»¥ç¢ºä¿æºç¢ºæ§ãæ¯åé¡å¥ä¸­çå¤æ¨£æ§è¡¨ç¤ºåå¨ç¾å¯¦ä¸çå ´æ¯ä¸­çç¸éæ§ãæåæ¯è¼äºåç¨®å³çµ±åç¾ä»£æ©å¨å­¸ç¿æ¹æ³ï¼ä»¥å»ºç«ç°è³ªè²é³åé¡ä»»åçåºç·ãæåç ç©¶äºè¼¸å¥ç¹å¾µçä½ç¨ï¼ç¹å¥èå¯äºå¾è²å­¸æ´¾ççè²é³è¡¨ç¤ºå¦ä½èä½¿ç¨é è¨ç·´æ·±åº¦ç¥ç¶ç¶²è·¯æåçåµå¥é²è¡æ¯è¼ï¼éäºç¶²è·¯å¯ä»¥æ·åè²é³çè²å­¸åèªç¾©è³è¨ãå¯¦é©çµæè¡¨æï¼ç·¨ç¢¼è²å­¸åèªç¾©è³è¨çé³è¨åµå¥å¨åé¡ä»»åä¸­å¯¦ç¾äºæ´é«çæºç¢ºæ§ãå¨ä»ç´°åæåé¡é¯èª¤å¾ï¼æåæ¾åºäºä¸äºå¤±æçæ ¹æ¬åå ï¼ä¸¦æåºäºä¸äºæ¸è¼éäºåå çæªæ½ãæ¬æå¼·èª¿éè¦å°åé¡çææéæ®µé²è¡æ´æ·±å¥çæ¢è¨ï¼äºè§£æ¸æä¸¦æ¡ç¨è½å¤ ææèçæ¸æè¤éæ§ä¸¦å¨ç¾å¯¦ä¸çè²é³ç°å¢ä¸­é²è¡æ¦æ¬çæ¹æ³ã

##### **The Gradient of Health Data Privacy**
2410.00897v1 by Baihan Lin

In the era of digital health and artificial intelligence, the management of
patient data privacy has become increasingly complex, with significant
implications for global health equity and patient trust. This paper introduces
a novel "privacy gradient" approach to health data governance, offering a more
nuanced and adaptive framework than traditional binary privacy models. Our
multidimensional concept considers factors such as data sensitivity,
stakeholder relationships, purpose of use, and temporal aspects, allowing for
context-sensitive privacy protections. Through policy analyses, ethical
considerations, and case studies spanning adolescent health, integrated care,
and genomic research, we demonstrate how this approach can address critical
privacy challenges in diverse healthcare settings worldwide. The privacy
gradient model has the potential to enhance patient engagement, improve care
coordination, and accelerate medical research while safeguarding individual
privacy rights. We provide policy recommendations for implementing this
approach, considering its impact on healthcare systems, research
infrastructures, and global health initiatives. This work aims to inform
policymakers, healthcare leaders, and digital health innovators, contributing
to a more equitable, trustworthy, and effective global health data ecosystem in
the digital age.

æè¦ï¼å¨æ¸ä½å¥åº·èäººå·¥æºæ§çæä»£ï¼çæ£è³æé±ç§çç®¡çè®å¾è¶ä¾è¶è¤éï¼å°å¨ççå¥åº·å¬å¹³èçæ£ä¿¡ä»»æéå¤§çå½±é¿ãæ¬æä»ç´¹äºä¸åæ°çãé±ç§æ¢¯åº¦ãæ¹æ³ä¾ç®¡çå¥åº·è³æï¼æä¾æ¯å³çµ±äºåé±ç§æ¨¡åæ´ç´°ç·»ä¸æ´å·é©ææ§çæ¶æ§ãæåçå¤é¢åæ¦å¿µèéäºè³æææåº¦ãå©å®³éä¿äººçéä¿ãä½¿ç¨ç®çåæéé¢åç­å ç´ ï¼åè¨±éå°èçµ¡ææçé±ç§ä¿è­·ãééæ¿ç­åæãå«çèéï¼ä»¥åæ¶µèéå°å¹´å¥åº·ãæ´åç§è­·ååºå çµç ç©¶çæ¡ä¾ç ç©¶ï¼æåå±ç¤ºäºæ­¤æ¹æ³å¦ä½è§£æ±ºå¨çä¸åé«çä¿å¥ç°å¢ä¸­çééµé±ç§ææ°ãé±ç§æ¢¯åº¦æ¨¡åææ½åæåçæ£åèãæ¹åç§è­·åèª¿ï¼ä»¥åå éé«å­¸ç ç©¶ï¼åæä¿éåé«çé±ç§æ¬ãæåæä¾å¯¦æ½æ­¤æ¹æ³çæ¿ç­å»ºè­°ï¼èéå¶å°é«çä¿å¥ç³»çµ±ãç ç©¶åºç¤è¨­æ½åå¨çå¥åº·è¨ç«çå½±é¿ãéé å·¥ä½æ¨å¨æä¾è³è¨çµ¦æ¿ç­å¶å®èãé«çä¿å¥é å°èåæ¸ä½å¥åº·åµæ°èï¼å¨æ¸ä½æä»£ä¸­ä¿ææ´å¬å¹³ãæ´å¼å¾ä¿¡è³´ä¸æ´ææçå¨çå¥åº·è³æçæç³»çµ±ã

##### **GAMMA-PD: Graph-based Analysis of Multi-Modal Motor Impairment Assessments in Parkinson's Disease**
2410.00944v1 by Favour Nerrise, Alice Louise Heiman, Ehsan Adeli

The rapid advancement of medical technology has led to an exponential
increase in multi-modal medical data, including imaging, genomics, and
electronic health records (EHRs). Graph neural networks (GNNs) have been widely
used to represent this data due to their prominent performance in capturing
pairwise relationships. However, the heterogeneity and complexity of
multi-modal medical data still pose significant challenges for standard GNNs,
which struggle with learning higher-order, non-pairwise relationships. This
paper proposes GAMMA-PD (Graph-based Analysis of Multi-modal Motor Impairment
Assessments in Parkinson's Disease), a novel heterogeneous hypergraph fusion
framework for multi-modal clinical data analysis. GAMMA-PD integrates imaging
and non-imaging data into a "hypernetwork" (patient population graph) by
preserving higher-order information and similarity between patient profiles and
symptom subtypes. We also design a feature-based attention-weighted mechanism
to interpret feature-level contributions towards downstream decision tasks. We
evaluate our approach with clinical data from the Parkinson's Progression
Markers Initiative (PPMI) and a private dataset. We demonstrate gains in
predicting motor impairment symptoms in Parkinson's disease. Our end-to-end
framework also learns associations between subsets of patient characteristics
to generate clinically relevant explanations for disease and symptom profiles.
The source code is available at https://github.com/favour-nerrise/GAMMA-PD.

æè¦ï¼é«çæè¡çå¿«éé²æ­¥å°è´å¤æ¨¡å¼é«çè³æåææ¸æé·ï¼åæ¬å½±åãåºå çµå­¸åé»å­å¥åº·ç´é (EHR)ãåå½¢ç¥ç¶ç¶²è·¯ (GNN) å å¶å¨æææå°éä¿ä¸çåºè²è¡¨ç¾èè¢«å»£æ³ç¨æ¼è¡¨ç¤ºéäºè³æãç¶èï¼å¤æ¨¡å¼é«çè³æçç°è³ªæ§åè¤éæ§å°æ¨æº GNN ä¾èªªä»ç¶æ§æéå¤§ææ°ï¼è GNN é£ä»¥å­¸ç¿é«éãéæå°éä¿ãæ¬ææåº GAMMA-PDï¼åºæ¼åå½¢åæå¸éæ£®æ°çå¤æ¨¡å¼éåéç¤è©ä¼°ï¼ï¼ä¸åç¨æ¼å¤æ¨¡å¼è¨åºè³æåæçæ°åç°è³ªè¶åèåæ¶æ§ãGAMMA-PD ééä¿çé«éè³è¨åæ£èç¹å¾µèççå­é¡åä¹éçç¸ä¼¼æ§ï¼å°å½±ååéå½±åè³ææ´åå°ãè¶ç¶²è·¯ãï¼æ£èæç¾¤åï¼ä¸­ãæåéè¨­è¨äºä¸ååºæ¼ç¹å¾µçæ³¨æåå æ¬æ©å¶ï¼ä»¥è§£éç¹å¾µå±¤ç´çè²¢ç»å°ä¸æ¸¸æ±ºç­ä»»åçå½±é¿ãæåä½¿ç¨å¸éæ£®æ°çé²å±æ¨è¨è¨ç« (PPMI) çè¨åºè³æåä¸åç§äººè³æéä¾è©ä¼°æåçåæ³ãæåå±ç¤ºäºå¨é æ¸¬å¸éæ£®æ°çéåéç¤ççæ¹é¢çé²å±ãæåçç«¯å°ç«¯æ¶æ§ä¹å­¸ç¿æ£èç¹å¾µå­éä¹éçéè¯ï¼ä»¥ç¢çå°ç¾çåççç¹å¾µå·æè¨åºæç¾©çè§£éãåå§ç¢¼å¯å¨ https://github.com/favour-nerrise/GAMMA-PD åå¾ã

##### **Contrastive Abstraction for Reinforcement Learning**
2410.00704v1 by Vihang Patil, Markus Hofmarcher, Elisabeth Rumetshofer, Sepp Hochreiter

Learning agents with reinforcement learning is difficult when dealing with
long trajectories that involve a large number of states. To address these
learning problems effectively, the number of states can be reduced by abstract
representations that cluster states. In principle, deep reinforcement learning
can find abstract states, but end-to-end learning is unstable. We propose
contrastive abstraction learning to find abstract states, where we assume that
successive states in a trajectory belong to the same abstract state. Such
abstract states may be basic locations, achieved subgoals, inventory, or health
conditions. Contrastive abstraction learning first constructs clusters of state
representations by contrastive learning and then applies modern Hopfield
networks to determine the abstract states. The first phase of contrastive
abstraction learning is self-supervised learning, where contrastive learning
forces states with sequential proximity to have similar representations. The
second phase uses modern Hopfield networks to map similar state representations
to the same fixed point, i.e.\ to an abstract state. The level of abstraction
can be adjusted by determining the number of fixed points of the modern
Hopfield network. Furthermore, \textit{contrastive abstraction learning} does
not require rewards and facilitates efficient reinforcement learning for a wide
range of downstream tasks. Our experiments demonstrate the effectiveness of
contrastive abstraction learning for reinforcement learning.

æè¦ï¼ä½¿ç¨å¼·åå­¸ç¿çå­¸ç¿ä»£çå¨èçåå«å¤§éçæçé·è»è·¡æå¾å°é£ãçºäºææè§£æ±ºéäºå­¸ç¿åé¡ï¼å¯ä»¥ééå°çæåç¾¤çæ½è±¡è¡¨ç¤ºä¾æ¸å°çææ¸éãååä¸ï¼æ·±åº¦å¼·åå­¸ç¿å¯ä»¥æ¾å°æ½è±¡çæï¼ä½ç«¯å°ç«¯å­¸ç¿æ¯ä¸ç©©å®çãæåæåºå°æ¯æ½è±¡å­¸ç¿ä¾å°æ¾æ½è±¡çæï¼æååè¨­è»è·¡ä¸­çé£çºçæå±¬æ¼åä¸åæ½è±¡çæãéæ¨£çæ½è±¡çæå¯è½æ¯åºæ¬ä½ç½®ãå·²éæçå­ç®æ¨ãåº«å­æå¥åº·çæ³ãå°æ¯æ½è±¡å­¸ç¿é¦åééå°æ¯å­¸ç¿å»ºæ§çæè¡¨ç¤ºçç¾¤éï¼ç¶å¾æç¨ç¾ä»£ Hopfield ç¶²è·¯ä¾ç¢ºå®æ½è±¡çæãå°æ¯æ½è±¡å­¸ç¿çç¬¬ä¸éæ®µæ¯èªæç£ç£å­¸ç¿ï¼å¶ä¸­å°æ¯å­¸ç¿æå¼·å¶å·æé åºæ¥è¿æ§ççæå·æç¸ä¼¼çè¡¨ç¤ºãç¬¬äºéæ®µä½¿ç¨ç¾ä»£ Hopfield ç¶²è·¯å°ç¸ä¼¼ççæè¡¨ç¤ºå°æå°åä¸åå®é»ï¼å³æ½è±¡çæãæ½è±¡å±¤ç´å¯ä»¥ééç¢ºå®ç¾ä»£ Hopfield ç¶²è·¯çå®é»æ¸éä¾èª¿æ´ãæ­¤å¤ï¼å°æ¯æ½è±¡å­¸ç¿ä¸éè¦çåµï¼ä¸¦ä¿é²åç¨®ä¸æ¸¸ä»»åçææå¼·åå­¸ç¿ãæåçå¯¦é©è­æäºå°æ¯æ½è±¡å­¸ç¿å°æ¼å¼·åå­¸ç¿çæææ§ã

##### **Arges: Spatio-Temporal Transformer for Ulcerative Colitis Severity Assessment in Endoscopy Videos**
2410.00536v1 by Krishna Chaitanya, Pablo F. Damasceno, Shreyas Fadnavis, Pooya Mobadersany, Chaitanya Parmar, Emily Scherer, Natalia Zemlianskaia, Lindsey Surace, Louis R. Ghanem, Oana Gabriela Cula, Tommaso Mansi, Kristopher Standish

Accurate assessment of disease severity from endoscopy videos in ulcerative
colitis (UC) is crucial for evaluating drug efficacy in clinical trials.
Severity is often measured by the Mayo Endoscopic Subscore (MES) and Ulcerative
Colitis Endoscopic Index of Severity (UCEIS) score. However, expert MES/UCEIS
annotation is time-consuming and susceptible to inter-rater variability,
factors addressable by automation. Automation attempts with frame-level labels
face challenges in fully-supervised solutions due to the prevalence of
video-level labels in clinical trials. CNN-based weakly-supervised models (WSL)
with end-to-end (e2e) training lack generalization to new disease scores and
ignore spatio-temporal information crucial for accurate scoring. To address
these limitations, we propose "Arges", a deep learning framework that utilizes
a transformer with positional encoding to incorporate spatio-temporal
information from frame features to estimate disease severity scores in
endoscopy video. Extracted features are derived from a foundation model
(ArgesFM), pre-trained on a large diverse dataset from multiple clinical trials
(61M frames, 3927 videos). We evaluate four UC disease severity scores,
including MES and three UCEIS component scores. Test set evaluation indicates
significant improvements, with F1 scores increasing by 4.1% for MES and 18.8%,
6.6%, 3.8% for the three UCEIS component scores compared to state-of-the-art
methods. Prospective validation on previously unseen clinical trial data
further demonstrates the model's successful generalization.

æè¦ï¼<paragraph>å¨æ½°çæ§çµè¸ç (UC) ä¸­ï¼æºç¢ºè©ä¼°å§è¦é¡è¦é »ä¸­çç¾çå´éç¨åº¦å°æ¼è©ä¼°è¨åºè©¦é©ä¸­çè¥ç©çæè³ééè¦ãå´éç¨åº¦éå¸¸éé Mayo å§è¦é¡äºåæ¸ (MES) åæ½°çæ§çµè¸çå§è¦é¡å´éç¨åº¦ææ¸ (UCEIS) åæ¸ä¾è¡¡éãç¶èï¼å°å®¶ MES/UCEIS æ³¨éæ¢è²»æåå®¹æåå°è©åèéè®ç°æ§çå½±é¿ï¼èèªååå¯ä»¥è§£æ±ºéäºå ç´ ãç±æ¼è¨åºè©¦é©ä¸­è¦é »ç´å¥æ¨ç±¤çæ®éå­å¨ï¼ä½¿ç¨å¹ç´æ¨ç±¤çèªåååè©¦å¨å®å¨ç£ç£çè§£æ±ºæ¹æ¡ä¸­é¢è¨ææ°ãå·æç«¯å°ç«¯ (e2e) è¨ç·´çåºæ¼ CNN çå¼±ç£ç£æ¨¡å (WSL) ç¼ºä¹å°æ°ç¾çè©åçæ³åï¼ä¸¦ä¸å¿½è¦äºå°æºç¢ºè©åè³ééè¦çæç©ºä¿¡æ¯ãçºäºè§£æ±ºéäºéå¶ï¼æåæåºäºãArgesãï¼éæ¯ä¸åæ·±åº¦å­¸ç¿æ¡æ¶ï¼å®å©ç¨å·æä½ç½®ç·¨ç¢¼çTransformerå°æç©ºä¿¡æ¯å¾å¹ç¹å¾µä¸­æååºä¾ï¼ä»¥ä¼°è¨å§è¦é¡è¦é »ä¸­çç¾çå´éç¨åº¦è©åãæåçç¹å¾µä¾èªåºç¤æ¨¡å (ArgesFM)ï¼è©²æ¨¡åå¨ä¾èªå¤åè¨åºè©¦é©çå¤§åå¤æ¨£åæ¸æéï¼6100 è¬å¹ï¼3927 åè¦é »ï¼ä¸é²è¡äºé è¨ç·´ãæåè©ä¼°äºåå UC ç¾çå´éç¨åº¦è©åï¼åæ¬ MES åä¸å UCEIS çµæé¨åè©åãæ¸¬è©¦éè©ä¼°è¡¨ææé¡¯èæ¹åï¼èæåé²çæ¹æ³ç¸æ¯ï¼MES ç F1 åæ¸æé«äº 4.1%ï¼ä¸å UCEIS çµæé¨åè©åç F1 åæ¸åå¥æé«äº 18.8%ã6.6% å 3.8%ãå¨ä»¥åæªè¦çè¨åºè©¦é©æ¸æä¸çåç»æ§é©è­é²ä¸æ­¥è­æäºè©²æ¨¡åæåçæ³åã</paragraph>

##### **Bayes-CATSI: A variational Bayesian deep learning framework for medical time series data imputation**
2410.01847v2 by Omkar Kulkarni, Rohitash Chandra

Medical time series datasets feature missing values that need data imputation
methods, however, conventional machine learning models fall short due to a lack
of uncertainty quantification in predictions. Among these models, the CATSI
(Context-Aware Time Series Imputation) stands out for its effectiveness by
incorporating a context vector into the imputation process, capturing the
global dependencies of each patient. In this paper, we propose a Bayesian
Context-Aware Time Series Imputation (Bayes-CATSI) framework which leverages
uncertainty quantification offered by variational inference. We consider the
time series derived from electroencephalography (EEG), electrooculography
(EOG), electromyography (EMG), electrocardiology (EKG). Variational Inference
assumes the shape of the posterior distribution and through minimization of the
Kullback-Leibler(KL) divergence it finds variational densities that are closest
to the true posterior distribution. Thus , we integrate the variational
Bayesian deep learning layers into the CATSI model. Our results show that
Bayes-CATSI not only provides uncertainty quantification but also achieves
superior imputation performance compared to the CATSI model. Specifically, an
instance of Bayes-CATSI outperforms CATSI by 9.57 %. We provide an open-source
code implementation for applying Bayes-CATSI to other medical data imputation
problems.

æè¦ï¼é«çæéåºåè³æéç¹å¾µæéºå¤±å¼ï¼éè¦è³æä¼°è¨æ¹æ³ï¼ç¶èï¼å³çµ±çæ©å¨å­¸ç¿æ¨¡åç±æ¼ç¼ºä¹é æ¸¬ä¸­çä¸ç¢ºå®éåèä¸è¶³ãå¨éäºæ¨¡åä¸­ï¼CATSIï¼æå¢æç¥æéåºåä¼°è¨ï¼å å¶å°æå¢åéç´å¥ä¼°è¨éç¨ä¸­èè«ç©èåºï¼æææ¯åçäººçæ´é«ä¾è³´æ§ãå¨æ¬æä¸­ï¼æåæåºä¸åè²æ°æå¢æç¥æéåºåä¼°è¨ï¼Bayes-CATSIï¼æ¶æ§ï¼å®å©ç¨è®ç°æ¨è«æä¾çæªç¢ºå®éåãæåèæ®ä¾èªè¦é»åï¼EEGï¼ãç¼ååï¼EOGï¼ãèé»åï¼EMGï¼ãå¿é»åï¼EKGï¼çæéåºåãè®ç°æ¨è«åè¨­å¾é©åéçå½¢çï¼ä¸¦ééæå°å Kullback-Leiblerï¼KLï¼æ£åº¦ï¼å®æ¾åºææ¥è¿çå¯¦å¾é©åéçè®ç°å¯åº¦ãå æ­¤ï¼æåå°è®ç°è²æ°æ·±åº¦å­¸ç¿å±¤æ´åå° CATSI æ¨¡åä¸­ãæåççµæè¡¨æï¼Bayes-CATSI ä¸åæä¾ä¸ç¢ºå®æ§éåï¼èä¸è CATSI æ¨¡åç¸æ¯ï¼éå¯¦ç¾äºåè¶çä¼°è¨æ§è½ãå·é«ä¾èªªï¼Bayes-CATSI çä¸åå¯¦ä¾æ¯ CATSI é«åº 9.57%ãæåæä¾ä¸åéæºç¨å¼ç¢¼å¯¦ä½ï¼å° Bayes-CATSI æç¨æ¼å¶ä»é«çè³æä¼°è¨åé¡ã

##### **ReXplain: Translating Radiology into Patient-Friendly Video Reports**
2410.00441v1 by Luyang Luo, Jenanan Vairavamurthy, Xiaoman Zhang, Abhinav Kumar, Ramon R. Ter-Oganesyan, Stuart T. Schroff, Dan Shilo, Rydhwana Hossain, Mike Moritz, Pranav Rajpurkar

Radiology reports often remain incomprehensible to patients, undermining
patient-centered care. We present ReXplain (Radiology eXplanation), an
innovative AI-driven system that generates patient-friendly video reports for
radiology findings. ReXplain uniquely integrates a large language model for
text simplification, an image segmentation model for anatomical region
identification, and an avatar generation tool, producing comprehensive
explanations with plain language, highlighted imagery, and 3D organ renderings.
Our proof-of-concept study with five board-certified radiologists indicates
that ReXplain could accurately deliver radiological information and effectively
simulate one-on-one consultations. This work demonstrates a new paradigm in
AI-assisted medical communication, potentially improving patient engagement and
satisfaction in radiology care, and opens new avenues for research in
multimodal medical communication.

æè¦ï¼æ¾å°ç§å ±åéå¸¸ä»¤æ£èé£ä»¥çè§£ï¼ç ´å£äºä»¥æ£èçºä¸­å¿çç§è­·ãæåæåº ReXplainï¼æ¾å°ç§è§£éï¼ï¼ä¸ååµæ°ç AI é©åç³»çµ±ï¼å®æçºæ¾å°ç§æª¢æ¥çµæç¢çå°æ£èååçå½±çå ±åãReXplain ç¨ç¹å°æ´åäºä¸åç¨æ¼æå­ç°¡åçèªè¨æ¨¡åãä¸åç¨æ¼è§£åååè­å¥çå½±ååå²æ¨¡åï¼ä»¥åä¸åé ­åç¢çå·¥å·ï¼ç¢çäºåå«æ·ºé¡¯ææçèªè¨ãéé»å½±åå 3D å¨å®æ¸²æçå¨é¢è§£éãæåèäºä½ééèªè­çæ¾å°ç§é«å¸«é²è¡çé©è­æ¦å¿µç ç©¶æåºï¼ReXplain è½å¤ æºç¢ºå°å³éæ¾å°ç§è³è¨ï¼ä¸¦ææå°æ¨¡æ¬ä¸å°ä¸çè«®è©¢ãéé å·¥ä½å±ç¤ºäº AI è¼å©é«çæºéçæ°å¸ç¯ï¼å®ææ½åæ¹åæ£èåèåº¦åæ¾å°ç§ç§è­·çæ»¿æåº¦ï¼ä¸¦çºå¤æ¨¡å¼é«çæºéçç ç©¶éåäºæ°éå¾ã

##### **Towards Democratization of Subspeciality Medical Expertise**
2410.03741v1 by Jack W. O'Sullivan, Anil Palepu, Khaled Saab, Wei-Hung Weng, Yong Cheng, Emily Chu, Yaanik Desai, Aly Elezaby, Daniel Seung Kim, Roy Lan, Wilson Tang, Natalie Tapaskar, Victoria Parikh, Sneha S. Jain, Kavita Kulkarni, Philip Mansfield, Dale Webster, Juraj Gottweis, Joelle Barral, Mike Schaekermann, Ryutaro Tanno, S. Sara Mahdavi, Vivek Natarajan, Alan Karthikesalingam, Euan Ashley, Tao Tu

The scarcity of subspecialist medical expertise, particularly in rare,
complex and life-threatening diseases, poses a significant challenge for
healthcare delivery. This issue is particularly acute in cardiology where
timely, accurate management determines outcomes. We explored the potential of
AMIE (Articulate Medical Intelligence Explorer), a large language model
(LLM)-based experimental AI system optimized for diagnostic dialogue, to
potentially augment and support clinical decision-making in this challenging
context. We curated a real-world dataset of 204 complex cases from a
subspecialist cardiology practice, including results for electrocardiograms,
echocardiograms, cardiac MRI, genetic tests, and cardiopulmonary stress tests.
We developed a ten-domain evaluation rubric used by subspecialists to evaluate
the quality of diagnosis and clinical management plans produced by general
cardiologists or AMIE, the latter enhanced with web-search and self-critique
capabilities. AMIE was rated superior to general cardiologists for 5 of the 10
domains (with preference ranging from 9% to 20%), and equivalent for the rest.
Access to AMIE's response improved cardiologists' overall response quality in
63.7% of cases while lowering quality in just 3.4%. Cardiologists' responses
with access to AMIE were superior to cardiologist responses without access to
AMIE for all 10 domains. Qualitative examinations suggest AMIE and general
cardiologist could complement each other, with AMIE thorough and sensitive,
while general cardiologist concise and specific. Overall, our results suggest
that specialized medical LLMs have the potential to augment general
cardiologists' capabilities by bridging gaps in subspecialty expertise, though
further research and validation are essential for wide clinical utility.

æè¦ï¼<paragraph>å¨ç½è§ãå¤æä¸å±åçå½çç¾çä¸­ï¼ç¹å«æ¯ç¼ºä¹æ¬¡ä¸ç§å»å­¦ä¸ä¸ç¥è¯ï¼è¿å¯¹å»çä¿å¥çæä¾ææäºéå¤§ææãæ­¤é®é¢å¨å¿èçå­¦ä¸­å°¤ä¸ºä¸¥éï¼å ä¸ºåæ¶çåç¡®ç®¡çå³å®äºç»æãæä»¬æ¢ç´¢äº AMIEï¼Articulate Medical Intelligence Explorerï¼çæ½åï¼å®æ¯ä¸ç§åºäºå¤§è¯­è¨æ¨¡å (LLM) çå®éªæ§äººå·¥æºè½ç³»ç»ï¼éå¯¹è¯æ­å¯¹è¯è¿è¡äºä¼åï¼å¯ä»¥å¢å¼ºåæ¯æå¨è¿ç§å·ææææ§çæåµä¸è¿è¡ä¸´åºå³ç­ãæä»¬ä»æ¬¡ä¸ç§å¿èçå®è·µä¸­æ´çäºä¸ä¸ªåå« 204 ä¸ªå¤æçä¾ççå®ä¸çæ°æ®éï¼åæ¬å¿çµå¾ãè¶å£°å¿å¨å¾ãå¿èæ ¸ç£å±æ¯ãåºå æ£æµåå¿èºååæµè¯çç»æãæä»¬å¶å®äºä¸ä¸ªç±æ¬¡ä¸ç§å»çä½¿ç¨çåä¸ªé¢åè¯ä¼°æ åï¼ç¨äºè¯ä¼°æ®éå¿èçä¸å®¶æ AMIE äº§ççè¯æ­åä¸´åºç®¡çè®¡åçè´¨éï¼åèéè¿ç½ç»æç´¢åèªææ¹è¯è½åå¾å°äºå¢å¼ºãå¨ 10 ä¸ªé¢åä¸­ï¼AMIE è¢«è¯ä¸ºä¼äºæ®éå¿èçä¸å®¶ï¼åå¥½èå´ä¸º 9% è³ 20%ï¼ï¼å¶ä½é¢ååç¸å½ãå¨ 63.7% ççä¾ä¸­ï¼è·å¾ AMIE çååºæ¹åäºå¿èçä¸å®¶çæ´ä½ååºè´¨éï¼èå¨ 3.4% ççä¾ä¸­éä½äºè´¨éãè·å¾ AMIE çå¿èçä¸å®¶çååºä¼äºæ²¡æè·å¾ AMIE çå¿èçä¸å®¶çååºï¼éç¨äºææ 10 ä¸ªé¢åãå®æ§æ£æ¥è¡¨æï¼AMIE åæ®éå¿èçä¸å®¶å¯ä»¥äºä¸ºè¡¥åï¼AMIE å¨é¢èææï¼èæ®éå¿èçä¸å®¶åç®æ´èå·ä½ãæ»ä½èè¨ï¼æä»¬çç ç©¶ç»æè¡¨æï¼ä¸ä¸çå»å­¦ LLM æå¯è½éè¿å¼¥åæ¬¡ä¸ç§ä¸ä¸ç¥è¯çå·®è·æ¥å¢å¼ºæ®éå¿èçä¸å®¶çè½åï¼å°½ç®¡è¿ä¸æ­¥çç ç©¶åéªè¯å¯¹äºå¹¿æ³çä¸´åºåºç¨è³å³éè¦ã</paragraph>

##### **CXPMRG-Bench: Pre-training and Benchmarking for X-ray Medical Report Generation on CheXpert Plus Dataset**
2410.00379v1 by Xiao Wang, Fuling Wang, Yuehang Li, Qingchuan Ma, Shiao Wang, Bo Jiang, Chuanfu Li, Jin Tang

X-ray image-based medical report generation (MRG) is a pivotal area in
artificial intelligence which can significantly reduce diagnostic burdens and
patient wait times. Despite significant progress, we believe that the task has
reached a bottleneck due to the limited benchmark datasets and the existing
large models' insufficient capability enhancements in this specialized domain.
Specifically, the recently released CheXpert Plus dataset lacks comparative
evaluation algorithms and their results, providing only the dataset itself.
This situation makes the training, evaluation, and comparison of subsequent
algorithms challenging. Thus, we conduct a comprehensive benchmarking of
existing mainstream X-ray report generation models and large language models
(LLMs), on the CheXpert Plus dataset. We believe that the proposed benchmark
can provide a solid comparative basis for subsequent algorithms and serve as a
guide for researchers to quickly grasp the state-of-the-art models in this
field. More importantly, we propose a large model for the X-ray image report
generation using a multi-stage pre-training strategy, including self-supervised
autoregressive generation and Xray-report contrastive learning, and supervised
fine-tuning. Extensive experimental results indicate that the autoregressive
pre-training based on Mamba effectively encodes X-ray images, and the
image-text contrastive pre-training further aligns the feature spaces,
achieving better experimental results. Source code can be found on
\url{https://github.com/Event-AHU/Medical_Image_Analysis}.

æè¦ï¼åºæ¼ X åå½±åçé«çå ±åçæ (MRG) æ¯äººå·¥æºæ§ä¸­çä¸åééµé åï¼å®å¯ä»¥å¤§å¹æ¸å°è¨ºæ·è² æåçæ£çç­å¾æéãåç®¡æé¡¯èçé²å±ï¼æåèªçºéé ä»»åå·²ç¶éå°ç¶é ¸ï¼åå æ¯åºæºè³æéæéï¼èä¸ç¾æçå¤§åæ¨¡åå¨éé å°æ¥­é åä¸­è½åå¢å¼·ä¸è¶³ãå·é«èè¨ï¼æè¿ç¼å¸ç CheXpert Plus è³æéç¼ºä¹æ¯è¼è©ä¼°æ¼ç®æ³åå¶çµæï¼åªæä¾è³æéæ¬èº«ãéç¨®ææ³ä½¿å¾å¾çºæ¼ç®æ³çè¨ç·´ãè©ä¼°åæ¯è¼å·æææ°æ§ãå æ­¤ï¼æåå°ç¾æçä¸»æµ X åå ±åçææ¨¡ååå¤§åèªè¨æ¨¡å (LLM) é²è¡äºå¨é¢çåºæºæ¸¬è©¦ï¼è³æéçº CheXpert Plusãæåç¸ä¿¡ï¼ææåºçåºæºæ¸¬è©¦å¯ä»¥çºå¾çºæ¼ç®æ³æä¾ç©©åºçæ¯è¼åºç¤ï¼ä¸¦ä½çºç ç©¶äººå¡å¿«éææ¡æ­¤é åæåé²æ¨¡åçæåãæ´éè¦çæ¯ï¼æåæåºä¸åä½¿ç¨å¤éæ®µé è¨ç·´ç­ç¥çå¤§åæ¨¡åï¼ç¨æ¼ X åå½±åå ±åçæï¼åæ¬èªç£ç£èªè¿´æ­¸çæå X åå ±åå°æ¯å­¸ç¿ï¼ä»¥åç£ç£å¾®èª¿ãå»£æ³çå¯¦é©çµæè¡¨æï¼åºæ¼ Mamba çèªè¿´æ­¸é è¨ç·´ææå°ç·¨ç¢¼äº X åå½±åï¼èå½±åæå­å°æ¯é è¨ç·´é²ä¸æ­¥å°é½äºç¹å¾µç©ºéï¼éå°äºæ´å¥½çå¯¦é©çµæãåå§ç¢¼å¯ä»¥å¨ \url{https://github.com/Event-AHU/Medical_Image_Analysis} æ¾å°ã

##### **Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**
2410.00366v1 by Prasenjit Maji, Amit Kumar Mondal, Hemanta Kumar Mondal, Saraju P. Mohanty

The rapid advancements in artificial intelligence (AI) have revolutionized
smart healthcare, driving innovations in wearable technologies, continuous
monitoring devices, and intelligent diagnostic systems. However, security,
explainability, robustness, and performance optimization challenges remain
critical barriers to widespread adoption in clinical environments. This
research presents an innovative algorithmic method using the Adaptive Feature
Evaluator (AFE) algorithm to improve feature selection in healthcare datasets
and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable
Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT),
the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby
enhancing predictive accuracy and interpretability. The proposed method is
validated across three diverse healthcare datasets using six distinct machine
learning algorithms, demonstrating its robustness and superiority over
conventional feature selection techniques. The results underscore the
transformative potential of AFE in smart healthcare, enabling personalized and
transparent patient care. Notably, the AFE algorithm, when combined with a
Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting
its capability to improve clinical decision-making processes in real-world
healthcare applications.

æè¦ï¼äººå·¥æºæ§ (AI) çå¿«éé²å±å¾¹åºæ¹è®äºæºæ§é«çä¿å¥ï¼æ¨åäºå¯ç©¿æ´æè¡ãæçºç£æ§è£ç½®åæºæ§è¨ºæ·ç³»çµ±çåµæ°ãç¶èï¼å®å¨æ§ãå¯è§£éæ§ãç©©å¥æ§åæè½æä½³åææ°ä»ç¶æ¯è¨åºç°å¢ä¸­å»£æ³æ¡ç¨çééµéç¤ãæ¬ç ç©¶æåºä¸ååµæ°çæ¼ç®æ³æ¹æ³ï¼ä½¿ç¨èªé©æç¹å¾µè©ä¼°å¨ (AFE) æ¼ç®æ³ä¾æ¹åé«çä¿å¥è³æéä¸­çç¹å¾µé¸åä¸¦åæåé¡ãAFE æ´åäºéºå³æ¼ç®æ³ (GA)ãå¯è§£éäººå·¥æºæ§ (XAI) åæåçµåæè¡ (PCT)ï¼è©²æ¼ç®æ³æä½³åäºè¨åºæ±ºç­æ¯æ´ç³»çµ± (CDSS)ï¼å¾èæé«äºé æ¸¬æºç¢ºæ§åå¯è§£éæ§ãææåºçæ¹æ³ä½¿ç¨å­ç¨®ä¸åçæ©å¨å­¸ç¿æ¼ç®æ³é©è­äºä¸åä¸åçé«çä¿å¥è³æéï¼è­æäºå¶ç©©å¥æ§ååªæ¼å³çµ±ç¹å¾µé¸åæè¡ãçµæå¼·èª¿äº AFE å¨æºæ§é«çä¿å¥ä¸­çè½è®æ½åï¼å¯¦ç¾äºåäººååéæçæ£èç§è­·ãå¼å¾æ³¨æçæ¯ï¼AFE æ¼ç®æ³èå¤å±¤æç¥å¨ (MLP) çµåä½¿ç¨æï¼æºç¢ºåº¦é«é 98.5%ï¼çªé¡¯äºå¶æ¹åå¯¦éé«çä¿å¥æç¨ä¸­è¨åºæ±ºç­å¶å®æµç¨çè½åã

##### **The age of spiritual machines: Language quietus induces synthetic altered states of consciousness in artificial intelligence**
2410.00257v1 by Jeremy I Skipper, Joanna Kuc, Greg Cooper, Christopher Timmermann

How is language related to consciousness? Language functions to categorise
perceptual experiences (e.g., labelling interoceptive states as 'happy') and
higher-level constructs (e.g., using 'I' to represent the narrative self).
Psychedelic use and meditation might be described as altered states that impair
or intentionally modify the capacity for linguistic categorisation. For
example, psychedelic phenomenology is often characterised by 'oceanic
boundlessness' or 'unity' and 'ego dissolution', which might be expected of a
system unburdened by entrenched language categories. If language breakdown
plays a role in producing such altered behaviour, multimodal artificial
intelligence might align more with these phenomenological descriptions when
attention is shifted away from language. We tested this hypothesis by comparing
the semantic embedding spaces from simulated altered states after manipulating
attentional weights in CLIP and FLAVA models to embedding spaces from altered
states questionnaires before manipulation. Compared to random text and various
other altered states including anxiety, models were more aligned with
disembodied, ego-less, spiritual, and unitive states, as well as minimal
phenomenal experiences, with decreased attention to language and vision.
Reduced attention to language was associated with distinct linguistic patterns
and blurred embeddings within and, especially, across semantic categories
(e.g., 'giraffes' become more like 'bananas'). These results lend support to
the role of language categorisation in the phenomenology of altered states of
consciousness, like those experienced with high doses of psychedelics or
concentration meditation, states that often lead to improved mental health and
wellbeing.

æè¦ï¼èªè¨å¦ä½èæè­ç¸éï¼èªè¨åè½ç¨æ¼åé¡æç¥ç¶é©ï¼ä¾å¦ï¼å°å§æåçææ¨è¨çºãå¿«æ¨ãï¼åæ´é«å±¤æ¬¡çå»ºæ§ï¼ä¾å¦ï¼ä½¿ç¨ãæãä¾ä»£è¡¨æäºèªæï¼ãè¿·å¹»è¥çä½¿ç¨åå¥æ³å¯ä»¥è¢«æè¿°çºæ¹è®çæï¼ææå®³æææä¿®æ¹èªè¨åé¡çè½åãä¾å¦ï¼è¿·å¹»ç¾è±¡å­¸éå¸¸ä»¥ãæµ·æ´è¬çç¡çãæãçµ±ä¸ãåãèªæè§£é«ãçºç¹å¾µï¼éå¯è½æ¯æ²ææ ¹æ·±èåºçèªè¨é¡å¥çç³»çµ±æé æçãå¦æèªè¨å´©æ½°å¨ç¢çéç¨®æ¹è®çè¡çºä¸­ç¼æ®ä½ç¨ï¼é£éº¼ç¶æ³¨æåå¾èªè¨è½ç§»æï¼å¤æ¨¡æäººå·¥æºè½å¯è½æ´ç¬¦åéäºç¾è±¡å­¸æè¿°ãæåééæ¯è¼å¨ CLIP å FLAVA æ¨¡åä¸­æç¸±æ³¨æåæ¬éå¾æ¨¡æ¬çæ¹è®çæçèªç¾©åµå¥ç©ºéèæç¸±åçæ¹è®çæåå·çåµå¥ç©ºéä¾æ¸¬è©¦éååè¨­ãèé¨æ©ææ¬ååæ¬ç¦æ®å¨å§çåç¨®å¶ä»æ¹è®çæç¸æ¯ï¼éäºæ¨¡åæ´ç¬¦åç¡èèº«ãç¡èªæãç²¾ç¥åçµ±ä¸çæï¼ä»¥åæå°çç¾è±¡é«é©ï¼ä¸¦ä¸å°èªè¨åè¦è¦ºçæ³¨æåéä½ãå°èªè¨çæ³¨æåéä½èä¸åçèªè¨æ¨¡å¼åæ¨¡ç³çåµå¥ç¸éï¼ç¹å¥æ¯å¨èªç¾©é¡å¥ä¸­ï¼ä¾å¦ï¼ãé·é ¸é¹¿ãè®å¾æ´åãé¦èãï¼ãéäºçµææ¯æäºèªè¨åé¡å¨æ¹è®æè­çæçç¾è±¡å­¸ä¸­çä½ç¨ï¼ä¾å¦æç¨é«åéè¿·å¹»è¥æå°æ³¨å¥æ³æç¶æ­·ççæï¼éäºçæéå¸¸æå°è´å¿çå¥åº·åå¹¸ç¦æçæ¹åã

##### **CliMB: An AI-enabled Partner for Clinical Predictive Modeling**
2410.03736v1 by Evgeny Saveliev, Tim Schubert, Thomas Pouplin, Vasilis Kosmoliaptsis, Mihaela van der Schaar

Despite its significant promise and continuous technical advances, real-world
applications of artificial intelligence (AI) remain limited. We attribute this
to the "domain expert-AI-conundrum": while domain experts, such as clinician
scientists, should be able to build predictive models such as risk scores, they
face substantial barriers in accessing state-of-the-art (SOTA) tools. While
automated machine learning (AutoML) has been proposed as a partner in clinical
predictive modeling, many additional requirements need to be fulfilled to make
machine learning accessible for clinician scientists.
  To address this gap, we introduce CliMB, a no-code AI-enabled partner
designed to empower clinician scientists to create predictive models using
natural language. CliMB guides clinician scientists through the entire medical
data science pipeline, thus empowering them to create predictive models from
real-world data in just one conversation. CliMB also creates structured reports
and interpretable visuals. In evaluations involving clinician scientists and
systematic comparisons against a baseline GPT-4, CliMB consistently
demonstrated superior performance in key areas such as planning, error
prevention, code execution, and model performance. Moreover, in blinded
assessments involving 45 clinicians from diverse specialties and career stages,
more than 80% preferred CliMB over GPT-4. Overall, by providing a no-code
interface with clear guidance and access to SOTA methods in the fields of
data-centric AI, AutoML, and interpretable ML, CliMB empowers clinician
scientists to build robust predictive models.

æè¦ï¼åç®¡äººå·¥æºè½ (AI) æ¿è«¾éå¤§ä¸æè¡æçºé²æ­¥ï¼ä½å¯¦éä¸çä¸­çäººå·¥æºæ§æç¨ä»æéãæåå°æ­¤æ­¸å æ¼ãé åå°å®¶-AI-é£é¡ãï¼åç®¡é åå°å®¶ï¼ä¾å¦è¨åºç§å­¸å®¶ï¼æè½å»ºç«é æ¸¬æ¨¡åï¼ä¾å¦é¢¨éªè©åï¼ï¼ä½ä»åå¨åå¾æåé² (SOTA) å·¥å·æé¢è¨éå¤§éç¤ãåç®¡å·²æåºèªåæ©å¨å­¸ç¿ (AutoML) ä½çºè¨åºé æ¸¬æ¨¡åçåä½å¤¥ä¼´ï¼ä½ä»éè¦æ»¿è¶³è¨±å¤é¡å¤éæ±ï¼æè½è®è¨åºç§å­¸å®¶ä½¿ç¨æ©å¨å­¸ç¿ã
çºäºè§£æ±ºæ­¤å·®è·ï¼æåå¼å¥äº CliMBï¼éæ¯ä¸ååç·¨ç¢¼ãAI é©åçåä½å¤¥ä¼´ï¼æ¨å¨è®è¨åºç§å­¸å®¶è½å¤ ä½¿ç¨èªç¶èªè¨å»ºç«é æ¸¬æ¨¡åãCliMB å¼å°è¨åºç§å­¸å®¶å®ææ´åé«å­¸æ¸æç§å­¸æµç¨ï¼å¾èè®ä»åè½å¤ å¨ä¸æ¬¡å°è©±ä¸­å¾çå¯¦ä¸çè³æå»ºç«é æ¸¬æ¨¡åãCliMB ä¹æå»ºç«çµæ§åå ±ååå¯è§£éçè¦è¦ºåãå¨æ¶åè¨åºç§å­¸å®¶åç³»çµ±æ§æ¯è¼åºæº GPT-4 çè©ä¼°ä¸­ï¼CliMB å¨è¦åãé¯èª¤é é²ãç¨å¼ç¢¼å·è¡åæ¨¡åæè½ç­ééµé åæçºå±ç¾åºåè¶çæè½ãæ­¤å¤ï¼å¨æ¶åä¾èªä¸åå°ç§åè·æ¥­éæ®µç 45 ä½è¨åºé«ççç²æ¸¬è©ä¼°ä¸­ï¼è¶é 80% çäººåå¥½ CliMB åé GPT-4ãæ´é«èè¨ï¼ééæä¾åç·¨ç¢¼ä»é¢ãæç¢ºæåï¼ä¸¦åå¾è³æçºä¸­å¿ AIãAutoML åå¯è§£é ML é åç SOTA æ¹æ³ï¼CliMB è½è®è¨åºç§å­¸å®¶å»ºç«ç©©å¥çé æ¸¬æ¨¡åã

##### **Adapting LLMs for the Medical Domain in Portuguese: A Study on Fine-Tuning and Model Evaluation**
2410.00163v1 by Pedro Henrique Paiola, Gabriel Lino Garcia, JoÃ£o Renato Ribeiro Manesco, Mateus Roder, Douglas Rodrigues, JoÃ£o Paulo Papa

This study evaluates the performance of large language models (LLMs) as
medical agents in Portuguese, aiming to develop a reliable and relevant virtual
assistant for healthcare professionals. The HealthCareMagic-100k-en and MedQuAD
datasets, translated from English using GPT-3.5, were used to fine-tune the
ChatBode-7B model using the PEFT-QLoRA method. The InternLM2 model, with
initial training on medical data, presented the best overall performance, with
high precision and adequacy in metrics such as accuracy, completeness and
safety. However, DrBode models, derived from ChatBode, exhibited a phenomenon
of catastrophic forgetting of acquired medical knowledge. Despite this, these
models performed frequently or even better in aspects such as grammaticality
and coherence. A significant challenge was low inter-rater agreement,
highlighting the need for more robust assessment protocols. This work paves the
way for future research, such as evaluating multilingual models specific to the
medical field, improving the quality of training data, and developing more
consistent evaluation methodologies for the medical field.

æè¦ï¼æ¬ç ç©¶è©ä¼°å¤§åèªè¨æ¨¡å (LLM) å¨è¡èçèªä¸­ä½çºé«çä»£ççè¡¨ç¾ï¼æ¨å¨çºé«çå°æ¥­äººå¡éç¼ä¸åå¯é ä¸ç¸éçèæ¬å©çãHealthCareMagic-100k-en å MedQuAD è³æéï¼ä½¿ç¨ GPT-3.5 å¾è±èªç¿»è­¯ï¼ç¨æ¼ä½¿ç¨ PEFT-QLoRA æ¹æ³å¾®èª¿ ChatBode-7B æ¨¡åãInternLM2 æ¨¡åï¼å¨é«çè³æä¸é²è¡åå§è¨ç·´ï¼è¡¨ç¾åºæå¥½çæ´é«è¡¨ç¾ï¼å¨æºç¢ºæ§ãå®æ´æ§åå®å¨æ§ç­ææ¨ä¸å·æå¾é«çç²¾åº¦åååæ§ãç¶èï¼æºèª ChatBode ç DrBode æ¨¡åè¡¨ç¾åºå°ç²å¾çé«çç¥è­ç½é£æ§éºå¿çç¾è±¡ãåç®¡å¦æ­¤ï¼éäºæ¨¡åå¨èªæ³æ§åé£è²«æ§ç­æ¹é¢è¡¨ç¾å¾å¾å¥½çè³æ´å¥½ãä¸åéå¤§çææ°æ¯è©åèä¹éçåè­°ä½ï¼éå¸é¡¯äºå°æ´å¼·å¤§çè©ä¼°åè­°çéæ±ãéé å·¥ä½çºæªä¾çç ç©¶éªå¹³äºéè·¯ï¼ä¾å¦è©ä¼°ç¹å®æ¼é«çé åçå¤èªè¨æ¨¡åãæé«è¨ç·´è³æçåè³ªï¼ä»¥åçºé«çé åéç¼æ´ä¸è´çè©ä¼°æ¹æ³ã

##### **The Perfect Blend: Redefining RLHF with Mixture of Judges**
2409.20370v1 by Tengyu Xu, Eryk Helenowski, Karthik Abinav Sankararaman, Di Jin, Kaiyan Peng, Eric Han, Shaoliang Nie, Chen Zhu, Hejia Zhang, Wenxuan Zhou, Zhouhao Zeng, Yun He, Karishma Mandyam, Arya Talabzadeh, Madian Khabsa, Gabriel Cohen, Yuandong Tian, Hao Ma, Sinong Wang, Han Fang

Reinforcement learning from human feedback (RLHF) has become the leading
approach for fine-tuning large language models (LLM). However, RLHF has
limitations in multi-task learning (MTL) due to challenges of reward hacking
and extreme multi-objective optimization (i.e., trade-off of multiple and/or
sometimes conflicting objectives). Applying RLHF for MTL currently requires
careful tuning of the weights for reward model and data combinations. This is
often done via human intuition and does not generalize. In this work, we
introduce a novel post-training paradigm which we called Constrained Generative
Policy Optimization (CGPO). The core of CGPO is Mixture of Judges (MoJ) with
cost-efficient constrained policy optimization with stratification, which can
identify the perfect blend in RLHF in a principled manner. It shows strong
empirical results with theoretical guarantees, does not require extensive
hyper-parameter tuning, and is plug-and-play in common post-training pipelines.
Together, this can detect and mitigate reward hacking behaviors while reaching
a pareto-optimal point across an extremely large number of objectives.
  Our empirical evaluations demonstrate that CGPO significantly outperforms
standard RLHF algorithms like PPO and DPO across various tasks including
general chat, STEM questions, instruction following, and coding. Specifically,
CGPO shows improvements of 7.4% in AlpacaEval-2 (general chat), 12.5% in
Arena-Hard (STEM & reasoning), and consistent gains in other domains like math
and coding. Notably, PPO, while commonly used, is prone to severe reward
hacking in popular coding benchmarks, which CGPO successfully addresses. This
breakthrough in RLHF not only tackles reward hacking and extreme
multi-objective optimization challenges but also advances the state-of-the-art
in aligning general-purpose LLMs for diverse applications.

æè¦ï¼äººé¡åé¥å¼·åå­¸ç¿ (RLHF) å·²æçºå¾®èª¿å¤§åèªè¨æ¨¡å (LLM) çé åæ¹æ³ãç¶èï¼RLHF å¨å¤ä»»åå­¸ç¿ (MTL) ä¸­åå°çåµç ´è§£åæ¥µç«¯å¤ç®æ¨æä½³åï¼ä¾å¦ï¼å¤éå/æææç¸äºè¡çªçç®æ¨ä¹éçåæ¨ï¼çææ°èææéå¶ãç®åï¼å° RLHF æç¨æ¼ MTL éè¦ä»ç´°èª¿æ´çåµæ¨¡ååè³æçµåçæ¬éãééå¸¸æ¯ééäººé¡ç´è¦ºä¾å®æï¼èä¸ç¡æ³æ¦æ¬ãå¨éé å·¥ä½ä¸­ï¼æåå¼å¥äºä¸ç¨®æ°ç©çè¨ç·´å¾ç¯ä¾ï¼æåç¨±ä¹çºåç´æçæç­ç¥æä½³å (CGPO)ãCGPO çæ ¸å¿æ¯æ³å®æ··å (MoJ)ï¼ééåå±¤é²è¡å·æææ¬æççåç´æç­ç¥æä½³åï¼å®å¯ä»¥ä»¥ååæ§çæ¹å¼æ¾åº RLHF ä¸­çå®ç¾èåãå®å¨çè«ä¿è­ä¸å±ç¾å¼·å¤§çå¯¦è­çµæï¼ä¸éè¦å»£æ³çè¶åæ¸èª¿æ´ï¼ä¸¦ä¸å¯ä»¥å³æå³ç¨æ¼å¸¸è¦çè¨ç·´å¾ç®¡éãç¸½ä¹ï¼å®å¯ä»¥å¨æ¥µå¤§éçç®æ¨ä¸­åµæ¸¬åæ¸è¼çåµç ´è§£è¡çºï¼åæéå°å¸é·ææåªé»ãæåçå¯¦è­è©ä¼°è­æï¼CGPO å¨åç¨®ä»»åä¸­é¡¯èåªæ¼æ¨æº RLHF æ¼ç®æ³ï¼ä¾å¦ä¸è¬èå¤©ãSTEM åé¡ãæä»¤éµå¾ªåç·¨ç¢¼ãå·é«ä¾èªªï¼CGPO å¨ AlpacaEval-2ï¼ä¸è¬èå¤©ï¼ä¸­æåäº 7.4%ï¼å¨ Arena-Hardï¼STEM åæ¨çï¼ä¸­æåäº 12.5%ï¼ä¸¦ä¸å¨æ¸å­¸åç·¨ç¢¼ç­å¶ä»é åä¸­æçºç²å¾æ¶çãå¼å¾æ³¨æçæ¯ï¼PPO éç¶æ®éä½¿ç¨ï¼ä½å¨æµè¡çç·¨ç¢¼åºæºä¸­å®¹æåå°å´éççåµç ´è§£ï¼è CGPO æåå°è§£æ±ºäºéååé¡ãRLHF çéé çªç ´ä¸åè§£æ±ºäºçåµç ´è§£åæ¥µç«¯å¤ç®æ¨æä½³åçææ°ï¼èä¸éæ¨åäºå°éç¨ LLM èåç¨®æç¨ç¨å¼ç¸çµåçææ°æè¡ã

##### **Forecasting Disease Progression with Parallel Hyperplanes in Longitudinal Retinal OCT**
2409.20195v2 by Arunava Chakravarty, Taha Emre, Dmitrii Lachinov, Antoine Rivail, Hendrik Scholl, Lars Fritsche, Sobha Sivaprasad, Daniel Rueckert, Andrew Lotery, Ursula Schmidt-Erfurth, Hrvoje BogunoviÄ

Predicting future disease progression risk from medical images is challenging
due to patient heterogeneity, and subtle or unknown imaging biomarkers.
Moreover, deep learning (DL) methods for survival analysis are susceptible to
image domain shifts across scanners. We tackle these issues in the task of
predicting late dry Age-related Macular Degeneration (dAMD) onset from retinal
OCT scans. We propose a novel DL method for survival prediction to jointly
predict from the current scan a risk score, inversely related to
time-to-conversion, and the probability of conversion within a time interval
$t$. It uses a family of parallel hyperplanes generated by parameterizing the
bias term as a function of $t$. In addition, we develop unsupervised losses
based on intra-subject image pairs to ensure that risk scores increase over
time and that future conversion predictions are consistent with AMD stage
prediction using actual scans of future visits. Such losses enable
data-efficient fine-tuning of the trained model on new unlabeled datasets
acquired with a different scanner. Extensive evaluation on two large datasets
acquired with different scanners resulted in a mean AUROCs of 0.82 for
Dataset-1 and 0.83 for Dataset-2, across prediction intervals of 6,12 and 24
months.

æè¦ï¼é¢æµæªæ¥ç¾çè¿å±é£é©ä»å»å­¦å½±åä¸­å·ææææ§
ç±äºçäººå¼è´¨æ§ï¼åç»å¾®ææªç¥çå½±åçç©æ è®°ã
æ­¤å¤ï¼æ·±åº¦å­¦ä¹ ï¼DLï¼æ¹æ³ç¨äºå­æ´»åæå®¹æåå°
è·¨æ«æä»ªçå½±åé¢åè½¬ç§»ãæä»¬å¨é¢æµææå¹²æ§å¹´é¾ç¸å³æ§é»æé¨çåï¼dAMDï¼åä½çä»»å¡ä¸­è§£å³è¿äºé®é¢ï¼ä»è§ç½è
OCT æ«æãæä»¬æåºä¸ç§æ°ç DL æ¹æ³ç¨äºå­æ´»é¢æµï¼ä»å½åæ«æä¸­èå
é¢æµä¸ä¸ªé£é©è¯åï¼ä¸è½¬æ¢æ¶é´æåæ¯ï¼ä»¥åå¨æ¶é´é´éåè½¬æ¢çå¯è½æ§
$t$ãå®ä½¿ç¨ä¸ç»å¹³è¡çè¶å¹³é¢ï¼éè¿å°åå·®é¡¹åæ°åä¸º $t$ çå½æ°æ¥çæãæ­¤å¤ï¼æä»¬å¼åæ çç£æå¤±
åºäºåè¯èåå½±åå¯¹ï¼ä»¥ç¡®ä¿é£é©è¯åéç
æ¶é´å¢å ï¼å¹¶ä¸æªæ¥çè½¬æ¢é¢æµä¸ AMD é¶æ®µ
é¢æµä½¿ç¨æªæ¥è®¿é®çå®éæ«ææ¯ä¸è´çãæ­¤ç±»æå¤±åè®¸
å¨ä½¿ç¨ä¸åæ«æä»ªè·åçæ°æªæ è®°æ°æ®éä¸å¯¹è®­ç»æ¨¡åè¿è¡æ°æ®é«æå¾®è°ãå¯¹ä¸¤ä¸ªå¤§åæ°æ®éçå¹¿æ³è¯ä¼°
ä½¿ç¨ä¸åçæ«æä»ªè·å¾çï¼å¹³å AUROC ä¸º 0.82ï¼å¯¹äºæ°æ®é 1 å 0.83ï¼å¯¹äºæ°æ®é 2ï¼è·¨é¢æµé´é 6,12 å 24
ä¸ªæã

##### **Classification of Radiological Text in Small and Imbalanced Datasets in a Non-English Language**
2409.20147v1 by Vincent Beliveau, Helene Kaas, Martin Prener, Claes N. Ladefoged, Desmond Elliott, Gitte M. Knudsen, Lars H. Pinborg, Melanie Ganz

Natural language processing (NLP) in the medical domain can underperform in
real-world applications involving small datasets in a non-English language with
few labeled samples and imbalanced classes. There is yet no consensus on how to
approach this problem. We evaluated a set of NLP models including BERT-like
transformers, few-shot learning with sentence transformers (SetFit), and
prompted large language models (LLM), using three datasets of radiology reports
on magnetic resonance images of epilepsy patients in Danish, a low-resource
language. Our results indicate that BERT-like models pretrained in the target
domain of radiology reports currently offer the optimal performances for this
scenario. Notably, the SetFit and LLM models underperformed compared to
BERT-like models, with LLM performing the worst. Importantly, none of the
models investigated was sufficiently accurate to allow for text classification
without any supervision. However, they show potential for data filtering, which
could reduce the amount of manual labeling required.

æè¦ï¼èªç¶èªè¨èç (NLP) å¨é«çé åä¸­ï¼å¨æ¶åéè±èªèªè¨ä¸­å°åè³æéãæ¨è¨æ¨£æ¬å°åé¡å¥ä¸å¹³è¡¡çå¯¦éæç¨ä¸­è¡¨ç¾ä¸ä½³ãå°æ¼å¦ä½è§£æ±ºéååé¡ï¼ç®åå°æªéæå±è­ãæåä½¿ç¨ä¸çµä¸¹éº¥èªç²çæ£èç£å±æ¯å½±åçæ¾å°å ±åè³æéï¼è©ä¼°äºä¸çµ NLP æ¨¡åï¼åæ¬é¡ BERT è½æå¨ãä½¿ç¨å¥å­è½æå¨ (SetFit) çå°æ¨£æ¬å­¸ç¿ï¼ä»¥åæç¤ºçå¤§åèªè¨æ¨¡å (LLM)ãæåççµæè¡¨æï¼ç®åå¨æ¾å°å ±åç®æ¨é åä¸­é è¨ç·´çé¡ BERT æ¨¡åçºæ­¤æå¢æä¾æä½³æè½ãå¼å¾æ³¨æçæ¯ï¼èé¡ BERT æ¨¡åç¸æ¯ï¼SetFit å LLM æ¨¡åè¡¨ç¾ä¸ä½³ï¼è LLM è¡¨ç¾æå·®ãéè¦çæ¯ï¼æç ç©¶çæ¨¡åä¸­æ²æä¸åè¶³å¤ æºç¢ºï¼å¯ä»¥å¨æ²æä»»ä½ç£ç£çææ³ä¸é²è¡æå­åé¡ãç¶èï¼å®åé¡¯ç¤ºåºè³æéæ¿¾çæ½åï¼éå¯ä»¥æ¸å°æéçæåæ¨è¨éã

##### **Positive-Sum Fairness: Leveraging Demographic Attributes to Achieve Fair AI Outcomes Without Sacrificing Group Gains**
2409.19940v1 by Samia Belhadj, Sanguk Park, Ambika Seth, Hesham Dar, Thijs Kooi

Fairness in medical AI is increasingly recognized as a crucial aspect of
healthcare delivery. While most of the prior work done on fairness emphasizes
the importance of equal performance, we argue that decreases in fairness can be
either harmful or non-harmful, depending on the type of change and how
sensitive attributes are used. To this end, we introduce the notion of
positive-sum fairness, which states that an increase in performance that
results in a larger group disparity is acceptable as long as it does not come
at the cost of individual subgroup performance. This allows sensitive
attributes correlated with the disease to be used to increase performance
without compromising on fairness.
  We illustrate this idea by comparing four CNN models that make different use
of the race attribute in the training phase. The results show that removing all
demographic encodings from the images helps close the gap in performance
between the different subgroups, whereas leveraging the race attribute as a
model's input increases the overall performance while widening the disparities
between subgroups. These larger gaps are then put in perspective of the
collective benefit through our notion of positive-sum fairness to distinguish
harmful from non harmful disparities.

æè¦ï¼é«ç AI ä¸­çå¬å¹³æ§æ¥çè¢«è¦çºé«çä¿å¥æä¾ä¸­è³ééè¦çä¸ç°ãéç¶å¤§å¤æ¸ååéæ¼å¬å¹³æ§çç ç©¶é½å¼·èª¿åç­è¡¨ç¾çéè¦æ§ï¼æåèªçºå¬å¹³æ§çä¸éå¯è½æ¯æå®³çæç¡å®³çï¼å·é«åæ±ºæ¼è®åçé¡ååææå±¬æ§çä½¿ç¨æ¹å¼ãçºæ­¤ï¼æåå¼å¥äºæ­£åå¬å¹³æ§çæ¦å¿µï¼å®æåºï¼åªè¦ä¸ä»¥ç§ç²åå¥å­ç¾¤é«è¡¨ç¾çºä»£å¹ï¼é£éº¼å°è´ç¾¤é«å·®ç°æ´å¤§çè¡¨ç¾æåæ¯å¯ä»¥æ¥åçãéåè¨±å°èç¾çç¸éçææå±¬æ§ç¨æ¼æé«è¡¨ç¾ï¼èä¸ææå®³å¬å¹³æ§ã
æåééæ¯è¼ååå¨è¨ç·´éæ®µå°ç¨®æå±¬æ§ä½¿ç¨ä¸åç CNN æ¨¡åä¾èªªæéåæ³æ³ãçµæé¡¯ç¤ºï¼å¾ååä¸­ç§»é¤ææäººå£ç·¨ç¢¼æå©æ¼ç¸®å°ä¸åå­ç¾¤é«ä¹éçè¡¨ç¾å·®è·ï¼èå°ç¨®æå±¬æ§ç¨ä½æ¨¡åçè¼¸å¥ææé«æ´é«è¡¨ç¾ï¼åææ´å¤§å­ç¾¤é«ä¹éçå·®ç°ãç¶å¾ï¼ééæåæ­£åå¬å¹³æ§çæ¦å¿µå°éäºæ´å¤§çå·®è·ç½®æ¼æ´é«æççè§åº¦ï¼ä»¥ååæå®³åç¡å®³çå·®ç°ã

##### **InfantCryNet: A Data-driven Framework for Intelligent Analysis of Infant Cries**
2409.19689v1 by Mengze Hong, Chen Jason Zhang, Lingxiao Yang, Yuanfeng Song, Di Jiang

Understanding the meaning of infant cries is a significant challenge for
young parents in caring for their newborns. The presence of background noise
and the lack of labeled data present practical challenges in developing systems
that can detect crying and analyze its underlying reasons. In this paper, we
present a novel data-driven framework, "InfantCryNet," for accomplishing these
tasks. To address the issue of data scarcity, we employ pre-trained audio
models to incorporate prior knowledge into our model. We propose the use of
statistical pooling and multi-head attention pooling techniques to extract
features more effectively. Additionally, knowledge distillation and model
quantization are applied to enhance model efficiency and reduce the model size,
better supporting industrial deployment in mobile devices. Experiments on
real-life datasets demonstrate the superior performance of the proposed
framework, outperforming state-of-the-art baselines by 4.4% in classification
accuracy. The model compression effectively reduces the model size by 7%
without compromising performance and by up to 28% with only an 8% decrease in
accuracy, offering practical insights for model selection and system design.

æè¦ï¼äºè§£å¬°åå­è²çå«ç¾©å°æ¼å¹´è¼ç¶æ¯ç§é¡§æ°çåä¾èªªæ¯ä¸é éå¤§ææ°ãèæ¯åªé³çå­å¨åæ¨ç±¤è³æçç¼ºä¹å¨éç¼å¯ä»¥åµæ¸¬å­è²ä¸¦åæå¶èå¾åå çç³»çµ±ææåºäºå¯¦éææ°ãå¨æ¬æä¸­ï¼æåæåºäºä¸åæ°ç©çè³æé©åæ¡æ¶ãInfantCryNetãä¾å®æéäºä»»åãçºäºè§£æ±ºè³æç¨ç¼ºçåé¡ï¼æåæ¡ç¨é åè¨ç·´çé³è¨æ¨¡åï¼å°åé©ç¥è­ç´å¥æåçæ¨¡åä¸­ãæåæåºä½¿ç¨çµ±è¨æ± ååå¤é ­æ³¨æåæ± åæè¡ä¾æ´ææå°æåç¹å¾µãæ­¤å¤ï¼ç¥è­è¸é¤¾åæ¨¡åéåè¢«æç¨æ¼å¢å¼·æ¨¡åæçä¸¦ç¸®å°æ¨¡åå¤§å°ï¼æ´å¥½å°æ¯æ´è¡åè£ç½®ä¸­çç¢æ¥­é¨ç½²ãå°çå¯¦è³æéçå¯¦é©è­æäºææåºçæ¡æ¶çåªç°æè½ï¼å¨åé¡æºç¢ºåº¦ä¸æ¯æåé²çåºæºé«åº 4.4%ãæ¨¡åå£ç¸®ææå°å°æ¨¡åå¤§å°æ¸å°äº 7%ï¼èä¸ææå®³æè½ï¼ä¸¦å¨æºç¢ºåº¦åä¸é 8% çææ³ä¸å°æ¨¡åå¤§å°æ¸å°äº 28%ï¼çºæ¨¡åé¸æåç³»çµ±è¨­è¨æä¾äºå¯¦ç¨çè¦è§£ã

##### **See Detail Say Clear: Towards Brain CT Report Generation via Pathological Clue-driven Representation Learning**
2409.19676v2 by Chengxin Zheng, Junzhong Ji, Yanzhao Shi, Xiaodan Zhang, Liangqiong Qu

Brain CT report generation is significant to aid physicians in diagnosing
cranial diseases. Recent studies concentrate on handling the consistency
between visual and textual pathological features to improve the coherence of
report. However, there exist some challenges: 1) Redundant visual representing:
Massive irrelevant areas in 3D scans distract models from representing salient
visual contexts. 2) Shifted semantic representing: Limited medical corpus
causes difficulties for models to transfer the learned textual representations
to generative layers. This study introduces a Pathological Clue-driven
Representation Learning (PCRL) model to build cross-modal representations based
on pathological clues and naturally adapt them for accurate report generation.
Specifically, we construct pathological clues from perspectives of segmented
regions, pathological entities, and report themes, to fully grasp visual
pathological patterns and learn cross-modal feature representations. To adapt
the representations for the text generation task, we bridge the gap between
representation learning and report generation by using a unified large language
model (LLM) with task-tailored instructions. These crafted instructions enable
the LLM to be flexibly fine-tuned across tasks and smoothly transfer the
semantic representation for report generation. Experiments demonstrate that our
method outperforms previous methods and achieves SoTA performance. Our code is
available at "https://github.com/Chauncey-Jheng/PCRL-MRG".

æè¦ï¼è¦é¨é»è¦æ·å±¤ææå ±åçææå©æ¼é«çè¨ºæ·é¡±éª¨ç¾çãæè¿çç ç©¶å°æ³¨æ¼èçè¦è¦ºåæå­ççç¹å¾µä¹éçä¸è´æ§ï¼ä»¥æé«å ±åçä¸è´æ§ãç¶èï¼å­å¨ä¸äºææ°ï¼1) å¤é¤çè¦è¦ºè¡¨ç¤ºï¼3D ææä¸­çå¤§éç¡éååæåæ£æ¨¡åå°é¡¯èè¦è¦ºèæ¯çè¡¨ç¤ºã2) è½ç§»çèªç¾©è¡¨ç¤ºï¼æéçé«å­¸èªæåº«å°è´æ¨¡åé£ä»¥å°å­¸ç¿å°çæå­è¡¨ç¤ºè½ç§»å°çæå±¤ãæ¬ç ç©¶å¼å¥äºççç·ç´¢é©åè¡¨ç¤ºå­¸ç¿ (PCRL) æ¨¡åï¼åºæ¼ççç·ç´¢æ§å»ºè·¨æ¨¡æè¡¨ç¤ºï¼ä¸¦èªç¶å°èª¿æ´å®åä»¥é²è¡æºç¢ºçå ±åçæãå·é«ä¾èªªï¼æåå¾åå²ååãççå¯¦é«åå ±åä¸»é¡çè§åº¦æ§å»ºççç·ç´¢ï¼ä»¥ååææ¡è¦è¦ºççæ¨¡å¼ä¸¦å­¸ç¿è·¨æ¨¡æç¹å¾µè¡¨ç¤ºãçºäºèª¿æ´è¡¨ç¤ºä»¥é©æææ¬çæä»»åï¼æåééä½¿ç¨å·æä»»åå®å¶æä»¤ççµ±ä¸å¤§åèªè¨æ¨¡å (LLM) ä¾å½åè¡¨ç¤ºå­¸ç¿åå ±åçæä¹éçå·®è·ãéäºç²¾å¿è£½ä½çæä»¤ä½¿ LLM è½å¤ éæ´»å°è·¨ä»»åé²è¡å¾®èª¿ï¼ä¸¦é å©å°å°èªç¾©è¡¨ç¤ºè½ç§»å°å ±åçæä¸­ãå¯¦é©è¡¨æï¼æåçæ¨¡ååªæ¼ååçæ¨¡åï¼ä¸¦éå°äºæåé²çæ§è½ãæåçç¨å¼ç¢¼å¯å¨ãhttps://github.com/Chauncey-Jheng/PCRL-MRGãåå¾ã

##### **Assessment and manipulation of latent constructs in pre-trained language models using psychometric scales**
2409.19655v1 by Maor Reuben, Ortal Slobodin, Aviad Elyshar, Idan-Chaim Cohen, Orna Braun-Lewensohn, Odeya Cohen, Rami Puzis

Human-like personality traits have recently been discovered in large language
models, raising the hypothesis that their (known and as yet undiscovered)
biases conform with human latent psychological constructs. While large
conversational models may be tricked into answering psychometric
questionnaires, the latent psychological constructs of thousands of simpler
transformers, trained for other tasks, cannot be assessed because appropriate
psychometric methods are currently lacking. Here, we show how standard
psychological questionnaires can be reformulated into natural language
inference prompts, and we provide a code library to support the psychometric
assessment of arbitrary models. We demonstrate, using a sample of 88 publicly
available models, the existence of human-like mental health-related constructs
(including anxiety, depression, and Sense of Coherence) which conform with
standard theories in human psychology and show similar correlations and
mitigation strategies. The ability to interpret and rectify the performance of
language models by using psychological tools can boost the development of more
explainable, controllable, and trustworthy models.

æè¦ï¼å¤§åèªè¨æ¨¡åæè¿ç¼ç¾äºé¡äººçäººæ ¼ç¹è³ªï¼æåºäºä¸ååè¨­ï¼å³å®åï¼å·²ç¥åå°æªç¼ç¾çï¼åè¦ç¬¦åäººé¡æ½å¨çå¿ççµæ§ãéç¶å¤§åå°è©±æ¨¡åå¯è½æè¢«èªé¨åç­å¿çæ¸¬é©åå·ï¼ä½æ¸ååç¶éè¨ç·´ä»¥å·è¡å¶ä»ä»»åçè¼ç°¡å®è½æå¨çæ½å¨å¿ççµæ§ç¡æ³è©ä¼°ï¼å çºç®åç¼ºä¹é©ç¶çå¿çæ¸¬éæ¹æ³ãå¨éè£¡ï¼æåå±ç¤ºäºå¦ä½å°æ¨æºå¿çåå·éæ°è¡¨è¿°çºèªç¶èªè¨æ¨çæç¤ºï¼ä¸¦æä¾ä¸åä»£ç¢¼åº«ä¾æ¯æä»»ææ¨¡åçå¿çæ¸¬éè©ä¼°ãæåä½¿ç¨ 88 åå¬éå¯ç¨çæ¨¡åçæ¨£æ¬ï¼è­æäºé¡äººå¿çå¥åº·ç¸éçµæ§ï¼åæ¬ç¦æ®ãæé¬±åä¸è´æï¼çå­å¨ï¼éäºçµæ§ç¬¦åäººé¡å¿çå­¸çæ¨æºçè«ï¼ä¸¦é¡¯ç¤ºåºé¡ä¼¼çç¸éæ§åç·©è§£ç­ç¥ãä½¿ç¨å¿çå·¥å·è§£éåç³¾æ­£èªè¨æ¨¡åçæ§è½çè½åå¯ä»¥ä¿é²æ´å·å¯è§£éæ§ãå¯æ§æ§åå¯ä¿¡åº¦çæ¨¡åçéç¼ã

##### **A Survey on Graph Neural Networks for Remaining Useful Life Prediction: Methodologies, Evaluation and Future Trends**
2409.19629v1 by Yucheng Wang, Min Wu, Xiaoli Li, Lihua Xie, Zhenghua Chen

Remaining Useful Life (RUL) prediction is a critical aspect of Prognostics
and Health Management (PHM), aimed at predicting the future state of a system
to enable timely maintenance and prevent unexpected failures. While existing
deep learning methods have shown promise, they often struggle to fully leverage
the spatial information inherent in complex systems, limiting their
effectiveness in RUL prediction. To address this challenge, recent research has
explored the use of Graph Neural Networks (GNNs) to model spatial information
for more accurate RUL prediction. This paper presents a comprehensive review of
GNN techniques applied to RUL prediction, summarizing existing methods and
offering guidance for future research. We first propose a novel taxonomy based
on the stages of adapting GNNs to RUL prediction, systematically categorizing
approaches into four key stages: graph construction, graph modeling, graph
information processing, and graph readout. By organizing the field in this way,
we highlight the unique challenges and considerations at each stage of the GNN
pipeline. Additionally, we conduct a thorough evaluation of various
state-of-the-art (SOTA) GNN methods, ensuring consistent experimental settings
for fair comparisons. This rigorous analysis yields valuable insights into the
strengths and weaknesses of different approaches, serving as an experimental
guide for researchers and practitioners working in this area. Finally, we
identify and discuss several promising research directions that could further
advance the field, emphasizing the potential for GNNs to revolutionize RUL
prediction and enhance the effectiveness of PHM strategies. The benchmarking
codes are available in GitHub:
https://github.com/Frank-Wang-oss/GNN\_RUL\_Benchmarking.

æè¦ï¼å©é¤ä½¿ç¨å£½å½ (RUL) é æ¸¬æ¯é æ¸¬èå¥åº·ç®¡ç (PHM) çä¸åééµé¢åï¼æ¨å¨é æ¸¬ç³»çµ±çæªä¾çæï¼ä»¥å©æ¼é©æç¶­è­·ä¸¦é é²æå¤æéãéç¶ç¾æçæ·±åº¦å­¸ç¿æ¹æ³å·²å±ç¾åæ¯ï¼ä½å®åå¾å¾é£ä»¥ååå©ç¨è¤éç³»çµ±ä¸­åºæçç©ºéè³è¨ï¼éå¶äºå®åå¨ RUL é æ¸¬ä¸­çæè½ãçºäºè§£æ±ºæ­¤ææ°ï¼æè¿çç ç©¶å·²æ¢è¨ä½¿ç¨åç¥ç¶ç¶²è·¯ (GNN) ä¾å»ºæ¨¡ç©ºéè³è¨ï¼ä»¥é²è¡æ´æºç¢ºç RUL é æ¸¬ãæ¬ææä¾äºæç¨æ¼ RUL é æ¸¬ç GNN æè¡çå¨é¢åé¡§ï¼ç¸½çµäºç¾ææ¹æ³ï¼ä¸¦çºæªä¾çç ç©¶æä¾æå°ãæåé¦åæ ¹æé©æ GNN è³ RUL é æ¸¬çéæ®µæåºä¸åæ°ç©çåé¡æ³ï¼ç³»çµ±æ§å°å°æ¹æ³åé¡çºååééµéæ®µï¼åå½¢å»ºæ§ãåå½¢å»ºæ¨¡ãåå½¢è³è¨èçååå½¢è®åãéééç¨®æ¹å¼çµç¹é åï¼æåå¼·èª¿äº GNN ç®¡ç·ä¸­æ¯åéæ®µçç¨ç¹ææ°åèéãæ­¤å¤ï¼æåå°åç¨®æåé² (SOTA) GNN æ¹æ³é²è¡äºå¾¹åºçè©ä¼°ï¼ç¢ºä¿äºä¸è´çå¯¦é©è¨­å®ä»¥é²è¡å¬å¹³çæ¯è¼ãéç¨®å´è¬¹çåæå°ä¸åæ¹æ³çåªç¼ºé»ç¢çäºå¯¶è²´çè¦è§£ï¼ä½çºå¨éåé åå·¥ä½çç ç©¶äººå¡åå¯¦åèçå¯¦é©æåãæå¾ï¼æåæ¾åºä¸¦è¨è«äºå¹¾åæåæ¯çç ç©¶æ¹åï¼éäºæ¹åå¯ä»¥é²ä¸æ­¥æ¨é²æ­¤é åï¼å¼·èª¿ GNN å·æé©æ° RUL é æ¸¬åæå PHM ç­ç¥æè½çæ½åãåºæºä»£ç¢¼å¯å¨ GitHub ä¸­åå¾ï¼https://github.com/Frank-Wang-oss/GNN\_RUL\_Benchmarkingã

##### **MCDDPM: Multichannel Conditional Denoising Diffusion Model for Unsupervised Anomaly Detection in Brain MRI**
2409.19623v1 by Vivek Kumar Trivedi, Bheeshm Sharma, P. Balamurugan

Detecting anomalies in brain MRI scans using supervised deep learning methods
presents challenges due to anatomical diversity and labor-intensive requirement
of pixel-level annotations. Generative models like Denoising Diffusion
Probabilistic Model (DDPM) and their variants like pDDPM, mDDPM, cDDPM have
recently emerged to be powerful alternatives to perform unsupervised anomaly
detection in brain MRI scans. These methods leverage frame-level labels of
healthy brains to generate healthy tissues in brain MRI scans. During
inference, when an anomalous (or unhealthy) scan image is presented as an
input, these models generate a healthy scan image corresponding to the input
anomalous scan, and the difference map between the generated healthy scan image
and the original anomalous scan image provide the necessary pixel level
identification of abnormal tissues. The generated healthy images from the DDPM,
pDDPM and mDDPM models however suffer from fidelity issues and contain
artifacts that do not have medical significance. While cDDPM achieves slightly
better fidelity and artifact suppression, it requires huge memory footprint and
is computationally expensive than the other DDPM based models. In this work, we
propose an improved version of DDPM called Multichannel Conditional Denoising
Diffusion Probabilistic Model (MCDDPM) for unsupervised anomaly detection in
brain MRI scans. Our proposed model achieves high fidelity by making use of
additional information from the healthy images during the training process,
enriching the representation power of DDPM models, with a computational cost
and memory requirements on par with DDPM, pDDPM and mDDPM models. Experimental
results on multiple datasets (e.g. BraTS20, BraTS21) demonstrate promising
performance of the proposed method. The code is available at
https://github.com/vivekkumartri/MCDDPM.

æè¦ï¼ä½¿ç¨çç£å¼æ·±åº¦å­¦ä¹ æ¹æ³æ£æµèé¨ MRI æ«æä¸­çå¼å¸¸ç°è±¡ä¼é¢ä¸´è§£åå­¦å¤æ ·æ§ä»¥ååç´ çº§æ³¨éçå³å¨å¯éåéæ±çææãå»åªæ©æ£æ¦çæ¨¡å (DDPM) åå¶åä½å¦ pDDPMãmDDPMãcDDPM ç­çææ¨¡åæè¿æµ®åºæ°´é¢ï¼æä¸ºå¨èé¨ MRI æ«æä¸­æ§è¡æ çç£å¼å¸¸æ£æµçå¼ºå¤§æ¿ä»£æ¹æ¡ãè¿äºæ¹æ³å©ç¨å¥åº·èé¨çå¸§çº§æ ç­¾å¨èé¨ MRI æ«æä¸­çæå¥åº·ç»ç»ãå¨æ¨çè¿ç¨ä¸­ï¼å½å¼å¸¸ï¼æä¸å¥åº·ï¼æ«æå¾åä½ä¸ºè¾å¥åç°æ¶ï¼è¿äºæ¨¡åä¼çæä¸è¾å¥å¼å¸¸æ«æå¯¹åºçå¥åº·æ«æå¾åï¼èçæçå¥åº·æ«æå¾åä¸åå§å¼å¸¸æ«æå¾åä¹é´çå·®å¼å¾æä¾äºå¼å¸¸ç»ç»çå¿è¦åç´ çº§è¯å«ãç¶èï¼DDPMãpDDPM å mDDPM æ¨¡åçæçå¥åº·å¾åå­å¨ä¿çåº¦é®é¢ï¼å¹¶ä¸åå«æ²¡æå»å­¦æä¹çä¼ªåãè½ç¶ cDDPM å®ç°äºç¨å¾®æ´å¥½çä¿çåº¦åä¼ªåæå¶ï¼ä½å®éè¦å·¨å¤§çåå­å ç¨ï¼å¹¶ä¸æ¯å¶ä»åºäº DDPM çæ¨¡åå¨è®¡ç®ä¸æ´æè´µãå¨è¿é¡¹å·¥ä½ä¸­ï¼æä»¬æåºäºä¸ä¸ªç§°ä¸ºå¤ééæ¡ä»¶å»åªæ©æ£æ¦çæ¨¡å (MCDDPM) ç DDPM æ¹è¿çæ¬ï¼ç¨äºå¨èé¨ MRI æ«æä¸­è¿è¡æ çç£å¼å¸¸æ£æµãæä»¬æåºçæ¨¡åéè¿å¨è®­ç»è¿ç¨ä¸­å©ç¨å¥åº·å¾åä¸­çéå ä¿¡æ¯æ¥å®ç°é«ä¿çåº¦ï¼ä»èä¸°å¯äº DDPM æ¨¡åçè¡¨ç¤ºè½åï¼å¹¶ä¸è®¡ç®ææ¬ååå­éæ±ä¸ DDPMãpDDPM å mDDPM æ¨¡åç¸å½ãå¨å¤ä¸ªæ°æ®éï¼ä¾å¦ BraTS20ãBraTS21ï¼ä¸çå®éªç»æè¯æäºææåºæ¹æ³çè¯å¥½æ§è½ãä»£ç å¯å¨ https://github.com/vivekkumartri/MCDDPM è·å¾ã

##### **Understanding Clinical Decision-Making in Traditional East Asian Medicine through Dimensionality Reduction: An Empirical Investigation**
2409.19531v1 by Hyojin Bae, Bongsu Kang, Chang-Eop Kim

This study examines the clinical decision-making processes in Traditional
East Asian Medicine (TEAM) by reinterpreting pattern identification (PI)
through the lens of dimensionality reduction. Focusing on the Eight Principle
Pattern Identification (EPPI) system and utilizing empirical data from the
Shang-Han-Lun, we explore the necessity and significance of prioritizing the
Exterior-Interior pattern in diagnosis and treatment selection. We test three
hypotheses: whether the Ext-Int pattern contains the most information about
patient symptoms, represents the most abstract and generalizable symptom
information, and facilitates the selection of appropriate herbal prescriptions.
Employing quantitative measures such as the abstraction index,
cross-conditional generalization performance, and decision tree regression, our
results demonstrate that the Exterior-Interior pattern represents the most
abstract and generalizable symptom information, contributing to the efficient
mapping between symptom and herbal prescription spaces. This research provides
an objective framework for understanding the cognitive processes underlying
TEAM, bridging traditional medical practices with modern computational
approaches. The findings offer insights into the development of AI-driven
diagnostic tools in TEAM and conventional medicine, with the potential to
advance clinical practice, education, and research.

æè¦ï¼æ¬ç ç©¶éééç¶­éè¦éæ°è©®éè­åè¾¨è­ï¼PIï¼ï¼æ¢è¨å³çµ±æ±äºé«å­¸ï¼TEAMï¼çè¨åºæ±ºç­å¶å®éç¨ãæåå°æ³¨æ¼å«ç¶±è­åè¾¨è­ï¼EPPIï¼ç³»çµ±ï¼ä¸¦å©ç¨å·å¯è«çç¶é©è³æï¼æ¢è¨å¨è¨ºæ·åæ²»çé¸æä¸­åªåèæ®è¡¨è£¡è­çå¿è¦æ§åéè¦æ§ãæåæª¢é©äºä¸ååè¨­ï¼è¡¨è£¡è­æ¯å¦åå«æå¤éæ¼æ£èçççè³è¨ãæ¯å¦ä»£è¡¨ææ½è±¡ä¸å¯æ¦æ¬çççè³è¨ï¼ä»¥åæ¯å¦è½ä¿é²é©ç¶èè¥èæ¹çé¸æãæåççµææ¡ç¨äºæ½è±¡ææ¸ãäº¤åæ¢ä»¶æ¦åæè½åæ±ºç­æ¨¹åæ­¸ç­éåæ¸¬éï¼è­æè¡¨è£¡è­ä»£è¡¨ææ½è±¡ä¸å¯æ¦æ¬çççè³è¨ï¼æå©æ¼ççèèè¥èæ¹ç©ºéä¹éçææå°æãæ¬ç ç©¶çºçè§£ TEAM èå¾çèªç¥éç¨æä¾äºå®¢è§æ¶æ§ï¼çµåå³çµ±é«å­¸å¯¦åèç¾ä»£éç®æ¹æ³ãç ç©¶çµææä¾äºè¦è§£ï¼æå©æ¼éç¼ TEAM åå³çµ±é«å­¸ä¸­ç± AI é©åçè¨ºæ·å·¥å·ï¼ä¸¦ææ½åä¿é²è¨åºå¯¦åãæè²åç ç©¶ã

##### **MedHalu: Hallucinations in Responses to Healthcare Queries by Large Language Models**
2409.19492v1 by Vibhor Agarwal, Yiqiao Jin, Mohit Chandra, Munmun De Choudhury, Srijan Kumar, Nishanth Sastry

The remarkable capabilities of large language models (LLMs) in language
understanding and generation have not rendered them immune to hallucinations.
LLMs can still generate plausible-sounding but factually incorrect or
fabricated information. As LLM-empowered chatbots become popular, laypeople may
frequently ask health-related queries and risk falling victim to these LLM
hallucinations, resulting in various societal and healthcare implications. In
this work, we conduct a pioneering study of hallucinations in LLM-generated
responses to real-world healthcare queries from patients. We propose MedHalu, a
carefully crafted first-of-its-kind medical hallucination dataset with a
diverse range of health-related topics and the corresponding hallucinated
responses from LLMs with labeled hallucination types and hallucinated text
spans. We also introduce MedHaluDetect framework to evaluate capabilities of
various LLMs in detecting hallucinations. We also employ three groups of
evaluators -- medical experts, LLMs, and laypeople -- to study who are more
vulnerable to these medical hallucinations. We find that LLMs are much worse
than the experts. They also perform no better than laypeople and even worse in
few cases in detecting hallucinations. To fill this gap, we propose
expert-in-the-loop approach to improve hallucination detection through LLMs by
infusing expert reasoning. We observe significant performance gains for all the
LLMs with an average macro-F1 improvement of 6.3 percentage points for GPT-4.

æè¦ï¼å¤§åèªè¨æ¨¡å (LLM) å¨èªè¨çè§£åçææ¹é¢çåè¶è½åä¸¦æªè®å®ååæ¼åºç¾å¹»è¦ºãLLM ä»ç¶å¯ä»¥çæè½èµ·ä¾åçä½äºå¯¦ä¸ä¸æ­£ç¢ºææé çä¿¡æ¯ãé¨èç± LLM é©åçèå¤©æ©å¨äººè®å¾æµè¡ï¼å¤è¡äººå¯è½æé »ç¹è©¢åèå¥åº·ç¸éçåé¡ï¼ä¸¦åèæçºéäº LLM å¹»è¦ºåå®³èçé¢¨éªï¼å¾èç¢çåç¨®ç¤¾æåé«çä¿å¥å½±é¿ãå¨éé å·¥ä½ä¸­ï¼æåå°æ£èç¾å¯¦ä¸ççé«çä¿å¥æ¥è©¢ä¸­ç± LLM çæçåæä¸­çå¹»è¦ºé²è¡äºéåµæ§çç ç©¶ãæåæåºäº MedHaluï¼éæ¯ä¸åç²¾å¿è£½ä½çåé¡é¦åµçé«å­¸å¹»è¦ºæ¸æéï¼å¶ä¸­åå«åç¨®èå¥åº·ç¸éçä¸»é¡ä»¥åä¾èª LLM çå°æå¹»è¦ºåæï¼ä¸¦æ¨è¨äºå¹»è¦ºé¡ååå¹»è¦ºææ¬è·¨åº¦ãæåéå¼å¥äº MedHaluDetect æ¡æ¶ä¾è©ä¼°åç¨® LLM å¨æª¢æ¸¬å¹»è¦ºæ¹é¢çè½åãæåéèè«äºä¸çµè©ä¼°äººå¡ââé«å­¸å°å®¶ãLLM åå¤è¡äººââä¾ç ç©¶èª°æ´å®¹æåå°éäºé«çå¹»è¦ºçå½±é¿ãæåç¼ç¾ LLM é ä¸å¦å°å®¶ãå¨æª¢æ¸¬å¹»è¦ºæ¹é¢ï¼å®åçè¡¨ç¾ä¹ä¸æ¯å¤è¡äººå¥½ï¼çè³å¨æäºææ³ä¸è¡¨ç¾å¾æ´ç³ãçºäºå¡«è£éä¸ç©ºç½ï¼æåæåºäºå°å®¶å¾ªç°æ¹æ³ï¼ééæ³¨å¥å°å®¶æ¨çä¾æ¹é² LLM çå¹»è¦ºæª¢æ¸¬ãæåè§å¯å°ææ LLM çæ§è½é½æé¡¯èæåï¼GPT-4 çå¹³åå®è§ F1 æåäº 6.3 åç¾åé»ã

##### **INSIGHTBUDDY-AI: Medication Extraction and Entity Linking using Large Language Models and Ensemble Learning**
2409.19467v1 by Pablo Romero, Lifeng Han, Goran Nenadic

Medication Extraction and Mining play an important role in healthcare NLP
research due to its practical applications in hospital settings, such as their
mapping into standard clinical knowledge bases (SNOMED-CT, BNF, etc.). In this
work, we investigate state-of-the-art LLMs in text mining tasks on medications
and their related attributes such as dosage, route, strength, and adverse
effects. In addition, we explore different ensemble learning methods
(\textsc{Stack-Ensemble} and \textsc{Voting-Ensemble}) to augment the model
performances from individual LLMs. Our ensemble learning result demonstrated
better performances than individually fine-tuned base models BERT, RoBERTa,
RoBERTa-L, BioBERT, BioClinicalBERT, BioMedRoBERTa, ClinicalBERT, and
PubMedBERT across general and specific domains. Finally, we build up an entity
linking function to map extracted medical terminologies into the SNOMED-CT
codes and the British National Formulary (BNF) codes, which are further mapped
to the Dictionary of Medicines and Devices (dm+d), and ICD. Our model's toolkit
and desktop applications are publicly available at
\url{https://github.com/HECTA-UoM/ensemble-NER}.

æè¦ï¼è¥ç©èååæ¢åå¨é«çä¿å¥èªç¶èªè¨èçç ç©¶ä¸­æ®æ¼éè¦çè§è²ï¼å çºå®å¨é«é¢ç°å¢ä¸­æå¯¦éæç¨ï¼ä¾å¦å°å®åå°æå°æ¨æºè¨åºç¥è­åº«ï¼SNOMED-CTãBNF ç­ï¼ãå¨éé å·¥ä½ä¸­ï¼æåæ¢è¨äºæåé²ç LLM å¨è¥ç©åå¶ç¸éå±¬æ§ï¼ä¾å¦åéãéå¾ãå¼·åº¦åä¸è¯åæï¼çæå­æ¢åä»»åãæ­¤å¤ï¼æåæ¢ç´¢äºä¸åçæ´åå­¸ç¿æ¹æ³ï¼\textsc{Stack-Ensemble} å \textsc{Voting-Ensemble}ï¼ä»¥å¢å¼·åå¥ LLM çæ¨¡åæè½ãæåçæ´åå­¸ç¿çµæè­æäºæ¯åå¥å¾®èª¿åºç¤æ¨¡å BERTãRoBERTaãRoBERTa-LãBioBERTãBioClinicalBERTãBioMedRoBERTaãClinicalBERT å PubMedBERT å¨ä¸è¬åç¹å®é åä¸­è¡¨ç¾å¾æ´å¥½ãæå¾ï¼æåå»ºç«äºä¸åå¯¦é«é£çµå½æ¸ï¼å°èåçé«å­¸è¡èªå°æå° SNOMED-CT ä»£ç¢¼åè±ååå®¶èæ¹é (BNF) ä»£ç¢¼ï¼é²ä¸æ­¥å°æå°è¥ååå¨æå­å¸ (dm+d) å ICDãæåçæ¨¡åå·¥å·çµåæ¡é¢æç¨ç¨å¼å¬éæ¼\url{https://github.com/HECTA-UoM/ensemble-NER}ã

##### **Mind the Gap: Promoting Missing Modality Brain Tumor Segmentation with Alignment**
2409.19366v1 by Tianyi Liu, Zhaorui Tan, Haochuan Jiang, Xi Yang, Kaizhu Huang

Brain tumor segmentation is often based on multiple magnetic resonance
imaging (MRI). However, in clinical practice, certain modalities of MRI may be
missing, which presents an even more difficult scenario. To cope with this
challenge, knowledge distillation has emerged as one promising strategy.
However, recent efforts typically overlook the modality gaps and thus fail to
learn invariant feature representations across different modalities. Such
drawback consequently leads to limited performance for both teachers and
students. To ameliorate these problems, in this paper, we propose a novel
paradigm that aligns latent features of involved modalities to a well-defined
distribution anchor. As a major contribution, we prove that our novel training
paradigm ensures a tight evidence lower bound, thus theoretically certifying
its effectiveness. Extensive experiments on different backbones validate that
the proposed paradigm can enable invariant feature representations and produce
a teacher with narrowed modality gaps. This further offers superior guidance
for missing modality students, achieving an average improvement of 1.75 on dice
score.

æè¦ï¼è¦è«ç¤åå²éå¸¸åºæ¼å¤ç¨®ç£å±æ¯å½±å (MRI)ãç¶èï¼å¨è¨åºå¯¦åä¸­ï¼æäº MRI çæ¹å¼å¯è½ç¼ºå¤±ï¼éææ§ææ´å°é£çæå¢ãçºäºæå°æ­¤ä¸ææ°ï¼ç¥è­è¸é¤¾å·²æçºä¸é æåéçç­ç¥ãç¶èï¼æè¿çåªåéå¸¸å¿½ç¥æ¹å¼çå·®è·ï¼å æ­¤ç¡æ³å­¸ç¿è·¨ä¸åæ¹å¼çä¸è®ç¹å¾µè¡¨ç¤ºãéæ¨£çç¼ºé»å°è´æå¸«åå­¸çå©èçè¡¨ç¾æéãçºäºæ¹åéäºåé¡ï¼æåå¨æ¬æä¸­æåºä¸åæ°çç¯ä¾ï¼å°ç¸éæ¹å¼çæ½å¨ç¹å¾µèæç¢ºå®ç¾©çåå¸é¨é»å°é½ãä½çºä¸é éå¤§è²¢ç»ï¼æåè­ææåæ°çè¨ç·´ç¯ä¾ç¢ºä¿å´è¬¹çè­æä¸çï¼å¾èçè«ä¸è­æå¶æææ§ãå¨ä¸åéª¨å¹¹ä¸çå»£æ³å¯¦é©é©è­äºææåºçç¯ä¾è½å¤ åç¨ä¸è®ç¹å¾µè¡¨ç¤ºï¼ä¸¦ç¢çæ¹å¼å·®è·ç¸®å°çæå¸«ãéé²ä¸æ­¥çºéºå¤±æ¹å¼çå­¸çæä¾åªç°çæå°ï¼å¨éª°å­åæ¸ä¸å¹³åæå 1.75ã

##### **3D-CT-GPT: Generating 3D Radiology Reports through Integration of Large Vision-Language Models**
2409.19330v1 by Hao Chen, Wei Zhao, Yingli Li, Tianyang Zhong, Yisong Wang, Youlan Shang, Lei Guo, Junwei Han, Tianming Liu, Jun Liu, Tuo Zhang

Medical image analysis is crucial in modern radiological diagnostics,
especially given the exponential growth in medical imaging data. The demand for
automated report generation systems has become increasingly urgent. While prior
research has mainly focused on using machine learning and multimodal language
models for 2D medical images, the generation of reports for 3D medical images
has been less explored due to data scarcity and computational complexities.
This paper introduces 3D-CT-GPT, a Visual Question Answering (VQA)-based
medical visual language model specifically designed for generating radiology
reports from 3D CT scans, particularly chest CTs. Extensive experiments on both
public and private datasets demonstrate that 3D-CT-GPT significantly
outperforms existing methods in terms of report accuracy and quality. Although
current methods are few, including the partially open-source CT2Rep and the
open-source M3D, we ensured fair comparison through appropriate data conversion
and evaluation methodologies. Experimental results indicate that 3D-CT-GPT
enhances diagnostic accuracy and report coherence, establishing itself as a
robust solution for clinical radiology report generation. Future work will
focus on expanding the dataset and further optimizing the model to enhance its
performance and applicability.

æè¦ï¼é«çå½±ååæå¨ç¾ä»£æ¾å°è¨ºæ·ä¸­è³ééè¦ï¼ç¹å¥æ¯èæ®å°é«å­¸å½±åè³æçææ¸æé·ãå°èªååå ±åç¢çç³»çµ±çéæ±å·²è®å¾è¶ä¾è¶è¿«åãéç¶ååçç ç©¶ä¸»è¦éä¸­æ¼ä½¿ç¨æ©å¨å­¸ç¿åå¤æ¨¡æèªè¨æ¨¡åé²è¡ 2D é«çå½±åï¼ä½ç±æ¼è³æç¨å°åè¨ç®è¤éåº¦ï¼3D é«çå½±åçå ±åç¢çè¼å°è¢«æ¢è¨ãæ¬æä»ç´¹ 3D-CT-GPTï¼ä¸ç¨®å°éè¨­è¨ç¨æ¼å¾ 3D CT ææï¼ç¹å¥æ¯è¸é¨ CTï¼ç¢çæ¾å°ç§å ±åçåºæ¼è¦è¦ºåç­ (VQA) çé«å­¸è¦è¦ºèªè¨æ¨¡åãå¨å¬å±åç§äººè³æéä¸çå»£æ³å¯¦é©è¡¨æï¼3D-CT-GPT å¨å ±åæºç¢ºæ§ååè³ªæ¹é¢é¡¯èåªæ¼ç¾ææ¹æ³ãéç¶ç®åçæ¹æ³å¾å°ï¼åæ¬é¨åéæºç CT2Rep åéæºç M3Dï¼ä½æåééé©ç¶çè³æè½æåè©ä¼°æ¹æ³ç¢ºä¿äºå¬å¹³çæ¯è¼ãå¯¦é©çµæè¡¨æï¼3D-CT-GPT å¢å¼·äºè¨ºæ·æºç¢ºæ§åå ±åä¸è´æ§ï¼ç¢ºç«äºå¶ä½çºè¨åºæ¾å°ç§å ±åç¢ççå¼·å¤§è§£æ±ºæ¹æ¡ãæªä¾çç ç©¶å°å°æ³¨æ¼æ´åè³æéåé²ä¸æ­¥æä½³åæ¨¡åï¼ä»¥å¢å¼·å¶æè½åé©ç¨æ§ã

##### **Epidemiology-Aware Neural ODE with Continuous Disease Transmission Graph**
2410.00049v1 by Guancheng Wan, Zewen Liu, Max S. Y. Lau, B. Aditya Prakash, Wei Jin

Effective epidemic forecasting is critical for public health strategies and
efficient medical resource allocation, especially in the face of rapidly
spreading infectious diseases. However, existing deep-learning methods often
overlook the dynamic nature of epidemics and fail to account for the specific
mechanisms of disease transmission. In response to these challenges, we
introduce an innovative end-to-end framework called Epidemiology-Aware Neural
ODE with Continuous Disease Transmission Graph (EARTH) in this paper. To learn
continuous and regional disease transmission patterns, we first propose EANO,
which seamlessly integrates the neural ODE approach with the epidemic
mechanism, considering the complex spatial spread process during epidemic
evolution. Additionally, we introduce GLTG to model global infection trends and
leverage these signals to guide local transmission dynamically. To accommodate
both the global coherence of epidemic trends and the local nuances of epidemic
transmission patterns, we build a cross-attention approach to fuse the most
meaningful information for forecasting. Through the smooth synergy of both
components, EARTH offers a more robust and flexible approach to understanding
and predicting the spread of infectious diseases. Extensive experiments show
EARTH superior performance in forecasting real-world epidemics compared to
state-of-the-art methods. The code will be available at
https://github.com/Emory-Melody/EpiLearn.

æè¦ï¼<paragraph>ææçç«æé¢æµå¯¹äºå¬å±å«çç­ç¥åé«æçå»çèµæºåéè³å³éè¦ï¼å°¤å¶æ¯å¨å¿«éä¼ æ­çä¼ æçé¢åãç¶èï¼ç°æçæ·±åº¦å­¦ä¹ æ¹æ³å¸¸å¸¸å¿½è§ç«æçå¨æç¹æ§ï¼å¹¶ä¸æ æ³è§£éç¾çä¼ æ­çå·ä½æºå¶ãä¸ºäºåºå¯¹è¿äºææï¼æä»¬å¨æ¬æä¸­ä»ç»äºä¸ä¸ªåæ°çç«¯å°ç«¯æ¡æ¶ï¼ç§°ä¸ºå·æè¿ç»­ç¾çä¼ æ­å¾çæµè¡çæç¥ç¥ç» ODEï¼EARTHï¼ãä¸ºäºå­¦ä¹ è¿ç»­çåºåæ§ç¾çä¼ æ­æ¨¡å¼ï¼æä»¬é¦åæåºäº EANOï¼å®å°ç¥ç» ODE æ¹æ³ä¸æµè¡çæºå¶æ ç¼éæï¼èèäºæµè¡çæ¼åè¿ç¨ä¸­çå¤æç©ºé´ä¼ æ­è¿ç¨ãæ­¤å¤ï¼æä»¬å¼å¥äº GLTG æ¥å»ºæ¨¡å¨çææè¶å¿ï¼å¹¶å©ç¨è¿äºä¿¡å·å¨æå°æå¯¼å±é¨ä¼ æ­ãä¸ºäºéåºæµè¡çè¶å¿çå¨å±ä¸è´æ§åæµè¡çä¼ æ­æ¨¡å¼çå±é¨ç»å¾®å·®å«ï¼æä»¬æå»ºäºä¸ç§äº¤åæ³¨ææ¹æ³æ¥èåæææä¹çé¢æµä¿¡æ¯ãéè¿è¿ä¸¤ä¸ªç»ä»¶çå¹³ç¨³ååä½ç¨ï¼EARTH ä¸ºçè§£åé¢æµä¼ æççä¼ æ­æä¾äºä¸ç§æ´ç¨³å¥ãæ´çµæ´»çæ¹æ³ãå¤§éçå®éªè¡¨æï¼ä¸æåè¿çæ¹æ³ç¸æ¯ï¼EARTH å¨é¢æµç°å®ä¸ççæµè¡çæ¹é¢å·æåè¶çæ§è½ãä»£ç å°å¨ https://github.com/Emory-Melody/EpiLearn ä¸æä¾ã</paragraph>

##### **A GEN AI Framework for Medical Note Generation**
2410.01841v1 by Hui Yi Leong, Yi Fan Gao, Shuai Ji, Bora Kalaycioglu, Uktu Pamuksuz

The increasing administrative burden of medical documentation, particularly
through Electronic Health Records (EHR), significantly reduces the time
available for direct patient care and contributes to physician burnout. To
address this issue, we propose MediNotes, an advanced generative AI framework
designed to automate the creation of SOAP (Subjective, Objective, Assessment,
Plan) notes from medical conversations. MediNotes integrates Large Language
Models (LLMs), Retrieval-Augmented Generation (RAG), and Automatic Speech
Recognition (ASR) to capture and process both text and voice inputs in real
time or from recorded audio, generating structured and contextually accurate
medical notes. The framework also incorporates advanced techniques like
Quantized Low-Rank Adaptation (QLoRA) and Parameter-Efficient Fine-Tuning
(PEFT) for efficient model fine-tuning in resource-constrained environments.
Additionally, MediNotes offers a query-based retrieval system, allowing
healthcare providers and patients to access relevant medical information
quickly and accurately. Evaluations using the ACI-BENCH dataset demonstrate
that MediNotes significantly improves the accuracy, efficiency, and usability
of automated medical documentation, offering a robust solution to reduce the
administrative burden on healthcare professionals while improving the quality
of clinical workflows.

æè¦ï¼é¨èé»å­çæ­· (EHR) çåºç¾ï¼é«çæä»¶ç®¡ççè¡æ¿è² ææ¥çå éï¼éé¡¯èæ¸å°äºç´æ¥æ£èç§è­·çæéï¼ä¸¦å°è´é«å¸«å¦æ ãçºäºè§£æ±ºéååé¡ï¼æåæåº MediNotesï¼ä¸ååé²ççæå¼ AI æ¡æ¶ï¼æ¨å¨èªåå SOAPï¼ä¸»è§ãå®¢è§ãè©ä¼°ãè¨ç«ï¼ç­è¨çå»ºç«ï¼éäºç­è¨ä¾èªæ¼é«çå°è©±ãMediNotes æ´åäºå¤§åèªè¨æ¨¡å (LLM)ãæª¢ç´¢å¢å¼·çæ (RAG) åèªåèªé³è¾¨è­ (ASR)ï¼ä»¥å³ææå¾éè£½çé³è¨ä¸­æ·ååèçæå­åèªé³è¼¸å¥ï¼ç¢ççµæ§åä¸å¨èçµ¡ä¸æºç¢ºçé«çç­è¨ãéåæ¡æ¶ä¹çµåäºåé²çæè¡ï¼ä¾å¦éåä½ç§©é©æ (QLoRA) ååæ¸ææå¾®èª¿ (PEFT)ï¼ä»¥å¨è³æºåéçç°å¢ä¸­é²è¡ææççæ¨¡åå¾®èª¿ãæ­¤å¤ï¼MediNotes æä¾ä¸ååºæ¼æ¥è©¢çæª¢ç´¢ç³»çµ±ï¼è®é«çä¿å¥æä¾èåæ£èå¯ä»¥å¿«éä¸æºç¢ºå°å­åç¸éçé«çè³è¨ãä½¿ç¨ ACI-BENCH è³æéçè©ä¼°é¡¯ç¤ºï¼MediNotes å¤§å¹æåäºèªååé«çæä»¶ç®¡ççæºç¢ºæ§ãæçåå¯ç¨æ§ï¼æä¾äºä¸åå¼·å¥çè§£æ±ºæ¹æ¡ï¼ä»¥æ¸è¼é«çä¿å¥å°æ¥­äººå¡çè¡æ¿è² æï¼åææ¹åè¨åºå·¥ä½æµç¨çåè³ªã

##### **Secure Multiparty Generative AI**
2409.19120v1 by Manil Shrestha, Yashodha Ravichandran, Edward Kim

As usage of generative AI tools skyrockets, the amount of sensitive
information being exposed to these models and centralized model providers is
alarming. For example, confidential source code from Samsung suffered a data
leak as the text prompt to ChatGPT encountered data leakage. An increasing
number of companies are restricting the use of LLMs (Apple, Verizon, JPMorgan
Chase, etc.) due to data leakage or confidentiality issues. Also, an increasing
number of centralized generative model providers are restricting, filtering,
aligning, or censoring what can be used. Midjourney and RunwayML, two of the
major image generation platforms, restrict the prompts to their system via
prompt filtering. Certain political figures are restricted from image
generation, as well as words associated with women's health care, rights, and
abortion.
  In our research, we present a secure and private methodology for generative
artificial intelligence that does not expose sensitive data or models to
third-party AI providers. Our work modifies the key building block of modern
generative AI algorithms, e.g. the transformer, and introduces confidential and
verifiable multiparty computations in a decentralized network to maintain the
1) privacy of the user input and obfuscation to the output of the model, and 2)
introduce privacy to the model itself. Additionally, the sharding process
reduces the computational burden on any one node, enabling the distribution of
resources of large generative AI processes across multiple, smaller nodes. We
show that as long as there exists one honest node in the decentralized
computation, security is maintained. We also show that the inference process
will still succeed if only a majority of the nodes in the computation are
successful. Thus, our method offers both secure and verifiable computation in a
decentralized network.

æè¦ï¼<paragraph>é¨èçæå¼ AI å·¥å·çä½¿ç¨éæ¿å¢ï¼æ´é²çµ¦éäºæ¨¡ååéä¸­å¼æ¨¡åæä¾èçææè³è¨æ¸éä»¤äººææãä¾å¦ï¼ä¾èªä¸æçæ©å¯åå§ç¢¼ç¼çè³æå¤æ´©ï¼å çº ChatGPT çæå­æç¤ºéå°äºè³æå¤æ´©ãç±æ¼è³æå¤æ´©ææ©å¯æ§åé¡ï¼è¶ä¾è¶å¤çå¬å¸æ­£å¨éå¶ä½¿ç¨ LLMï¼AppleãVerizonãJPMorgan Chase ç­ï¼ãæ­¤å¤ï¼è¶ä¾è¶å¤çéä¸­å¼çææ¨¡åæä¾èæ­£å¨éå¶ãéæ¿¾ãèª¿æ´æå¯©æ¥å¯ä»¥ä½¿ç¨ä»éº¼ãMidjourney å RunwayML æ¯å©åä¸»è¦çå½±åçæå¹³å°ï¼å®åééæç¤ºéæ¿¾éå¶ç³»çµ±çæç¤ºãæäºæ¿æ²»äººç©è¢«ç¦æ­¢çæå½±åï¼ä»¥åèå©¦å¥³ä¿å¥ãæ¬å©åå¢®èç¸éçå­è©ã
å¨æåçç ç©¶ä¸­ï¼æåæåºäºä¸ç¨®å®å¨ä¸ç§å¯ççæå¼äººå·¥æºæ§æ¹æ³ï¼ä¸æå°ææè³æææ¨¡åæ´é²çµ¦ç¬¬ä¸æ¹ AI æä¾èãæåçç ç©¶ä¿®æ¹äºç¾ä»£çæå¼ AI æ¼ç®æ³çä¸»è¦å»ºæ§åå¡ï¼ä¾å¦Transformerï¼ä¸¦å¨åæ£å¼ç¶²è·¯ä¸­å¼å¥äºæ©å¯ä¸å¯é©è­çå¤æ¹éç®ï¼ä»¥ç¶­è­· 1) ä½¿ç¨èè¼¸å¥çé±ç§åæ¨¡åè¼¸åºçæ··æ·ï¼ä»¥å 2) çºæ¨¡åæ¬èº«å¼å¥é±ç§ãæ­¤å¤ï¼åçèçæéä½ä»»ä½ä¸åç¯é»çéç®è² æï¼è®å¤§åçæå¼ AI èççè³æºå¯ä»¥åå¸å¨å¤åè¼å°çç¯é»ä¸ãæåè¡¨æï¼åªè¦å¨åæ£å¼éç®ä¸­å­å¨ä¸åèª å¯¦çç¯é»ï¼å°±è½ç¶­æå®å¨æ§ãæåä¹è¡¨æï¼å¦æéç®ä¸­åªæå¤æ¸ç¯é»æåï¼æ¨çç¨åºä»ç¶ææåãå æ­¤ï¼æåçæ¨¡åå¨åæ£å¼ç¶²è·¯ä¸­æä¾äºå®å¨ä¸å¯é©è­çéç®ã</paragraph>

##### **Differential privacy for protecting patient data in speech disorder detection using deep learning**
2409.19078v1 by Soroosh Tayebi Arasteh, Mahshad Lotfinia, Paula Andrea Perez-Toro, Tomas Arias-Vergara, Juan Rafael Orozco-Arroyave, Maria Schuster, Andreas Maier, Seung Hee Yang

Speech pathology has impacts on communication abilities and quality of life.
While deep learning-based models have shown potential in diagnosing these
disorders, the use of sensitive data raises critical privacy concerns. Although
differential privacy (DP) has been explored in the medical imaging domain, its
application in pathological speech analysis remains largely unexplored despite
the equally critical privacy concerns. This study is the first to investigate
DP's impact on pathological speech data, focusing on the trade-offs between
privacy, diagnostic accuracy, and fairness. Using a large, real-world dataset
of 200 hours of recordings from 2,839 German-speaking participants, we observed
a maximum accuracy reduction of 3.85% when training with DP with a privacy
budget, denoted by {\epsilon}, of 7.51. To generalize our findings, we
validated our approach on a smaller dataset of Spanish-speaking Parkinson's
disease patients, demonstrating that careful pretraining on large-scale
task-specific datasets can maintain or even improve model accuracy under DP
constraints. We also conducted a comprehensive fairness analysis, revealing
that reasonable privacy levels (2<{\epsilon}<10) do not introduce significant
gender bias, though age-related disparities may require further attention. Our
results suggest that DP can effectively balance privacy and utility in speech
disorder detection, but also highlight the unique challenges in the speech
domain, particularly regarding the privacy-fairness trade-off. This provides a
foundation for future work to refine DP methodologies and address fairness
across diverse patient groups in real-world deployments.

æè¦ï¼<paragraph>è¨èªççå­¸å°æºéè½ååçæ´»åè³ªæå½±é¿ã
åç®¡åºæ¼æ·±åº¦å­¸ç¿çæ¨¡åå¨è¨ºæ·éäºç¾çæ¹é¢å·²å±ç¾æ½åï¼ä½ææè³æçä½¿ç¨å¼ç¼äºå´éçé±ç§åé¡ãåç®¡å·®åé±ç§ (DP) å·²å¨é«å­¸å½±åé åä¸­å¾å°æ¢è¨ï¼ä½å¶å¨ççèªè¨åæä¸­çæç¨ä»æªå¾å°ååæ¢è¨ï¼åç®¡å¶é±ç§åé¡åæ¨£å´éãæ¬ç ç©¶é¦æ¬¡æ¢è¨äº DP å°ççèªè¨è³æçå½±é¿ï¼éé»éæ³¨é±ç§ãè¨ºæ·æºç¢ºæ§åå¬å¹³æ§ä¹éçæ¬è¡¡ãæåä½¿ç¨äºä¸åå¤§åççå¯¦ä¸çè³æéï¼å¶ä¸­åå«ä¾èª 2,839 åå¾·èªåèèç 200 å°æéé³ï¼æåè§å¯å°å¨ä½¿ç¨ DP é²è¡è¨ç·´æï¼é±ç§é ç®ï¼ä»¥ {\epsilon} è¡¨ç¤ºï¼çº 7.51 æï¼æºç¢ºåº¦æé«éä½äº 3.85%ãçºäºæ¨å»£æåçç¼ç¾ï¼æåå¨ä¸åè¦æ¨¡è¼å°çè¥¿ç­çèªå¸éæ£®çæ£èè³æéä¸é©è­äºæåçåæ³ï¼è­æäºå¨å¤§è¦æ¨¡ç¹å®ä»»åè³æéä¸é²è¡ä»ç´°çé è¨ç·´å¯ä»¥å¨ DP ç´æä¸ç¶­æçè³æé«æ¨¡åæºç¢ºåº¦ãæåéé²è¡äºå¨é¢çå¬å¹³æ§åæï¼çµæé¡¯ç¤ºåççé±ç§ç­ç´ï¼2<{\epsilon}<10ï¼ä¸æå¼å¥é¡¯èçæ§å¥åè¦ï¼åç®¡èå¹´é½¡ç¸éçå·®ç°å¯è½éè¦é²ä¸æ­¥éæ³¨ãæåççµæè¡¨æï¼DP å¯ä»¥ææå°å¨èªè¨éç¤æª¢æ¸¬ä¸­å¹³è¡¡é±ç§åæç¨ï¼ä½ä¹çªåºäºèªè¨é åä¸­ç¨ç¹çææ°ï¼ç¹å¥æ¯éæ¼é±ç§å¬å¹³æ§çæ¬è¡¡ãéçºæªä¾çç ç©¶æä¾äºåºç¤ï¼ä»¥å®å DP æ¹æ³ä¸¦å¨å¯¦éé¨ç½²ä¸­è§£æ±ºä¸åæ£èç¾¤é«ä¸­çå¬å¹³æ§åé¡ã</paragraph>

##### **AIPatient: Simulating Patients with EHRs and LLM Powered Agentic Workflow**
2409.18924v2 by Huizi Yu, Jiayan Zhou, Lingyao Li, Shan Chen, Jack Gallifant, Anye Shi, Xiang Li, Wenyue Hua, Mingyu Jin, Guang Chen, Yang Zhou, Zhao Li, Trisha Gupte, Ming-Li Chen, Zahra Azizi, Yongfeng Zhang, Themistocles L. Assimes, Xin Ma, Danielle S. Bitterman, Lin Lu, Lizhou Fan

Simulated patient systems play a crucial role in modern medical education and
research, providing safe, integrative learning environments and enabling
clinical decision-making simulations. Large Language Models (LLM) could advance
simulated patient systems by replicating medical conditions and patient-doctor
interactions with high fidelity and low cost. However, ensuring the
effectiveness and trustworthiness of these systems remains a challenge, as they
require a large, diverse, and precise patient knowledgebase, along with a
robust and stable knowledge diffusion to users. Here, we developed AIPatient,
an advanced simulated patient system with AIPatient Knowledge Graph (AIPatient
KG) as the input and the Reasoning Retrieval-Augmented Generation (Reasoning
RAG) agentic workflow as the generation backbone. AIPatient KG samples data
from Electronic Health Records (EHRs) in the Medical Information Mart for
Intensive Care (MIMIC)-III database, producing a clinically diverse and
relevant cohort of 1,495 patients with high knowledgebase validity (F1 0.89).
Reasoning RAG leverages six LLM powered agents spanning tasks including
retrieval, KG query generation, abstraction, checker, rewrite, and
summarization. This agentic framework reaches an overall accuracy of 94.15% in
EHR-based medical Question Answering (QA), outperforming benchmarks that use
either no agent or only partial agent integration. Our system also presents
high readability (median Flesch Reading Ease 77.23; median Flesch Kincaid Grade
5.6), robustness (ANOVA F-value 0.6126, p>0.1), and stability (ANOVA F-value
0.782, p>0.1). The promising performance of the AIPatient system highlights its
potential to support a wide range of applications, including medical education,
model evaluation, and system integration.

æè¦ï¼æ¨¡æ¬çäººç³»çµ±å¨ç¾ä»£é«å­¸æè²åç ç©¶ä¸­æ®æ¼èè³ééè¦çè§è²ï¼æä¾å®å¨ãæ´åçå­¸ç¿ç°å¢ï¼ä¸¦è½é²è¡è¨åºæ±ºç­æ¨¡æ¬ãå¤§åèªè¨æ¨¡å (LLM) è½ééé«ä¿çåº¦åä½ææ¬è¤è£½é«ççæ³åé«çäºåï¼é²èæåæ¨¡æ¬çäººç³»çµ±ãç¶èï¼ç¢ºä¿éäºç³»çµ±çæææ§åå¯ä¿¡åº¦ä»ç¶æ¯ä¸é ææ°ï¼å çºå®åéè¦ä¸åé¾å¤§ãå¤åä¸ç²¾ç¢ºççäººç¥è­åº«ï¼ä»¥åç©©å¥ä¸ç©©å®çç¥è­å³æ­çµ¦ä½¿ç¨èãå¨æ­¤ï¼æåéç¼äº AIPatientï¼ä¸åé²éçæ¨¡æ¬çäººç³»çµ±ï¼ä»¥ AIPatient ç¥è­åè­ (AIPatient KG) ä½çºè¼¸å¥ï¼ä¸¦ä»¥æ¨çæª¢ç´¢å¢å¼·çæ (Reasoning RAG) ä»£çå·¥ä½æµç¨ä½çºçæä¸»å¹¹ãAIPatient KG å¾éçç£è­·é«å­¸è³è¨ä¸­å¿ (MIMIC)-III è³æåº«ä¸­çé»å­å¥åº·ç´é (EHR) ä¸­æ½åè³æï¼ç¢çä¸åè¨åºå¤æ¨£ä¸ç¸éç 1,495 åçæ£ç¾¤çµï¼å·æå¾é«çç¥è­åº«æåº¦ (F1 0.89)ãæ¨ç RAG æ§æ¡¿äºå­å LLM é©åçä»£çï¼è·¨è¶æª¢ç´¢ãKG æ¥è©¢ç¢çãæ½è±¡ãæª¢æ¥å¨ãéå¯«åæè¦ç­ä»»åãéåä»£çæ¡æ¶å¨åºæ¼ EHR çé«çåç­ (QA) ä¸­éå°äº 94.15% çæ´é«æºç¢ºåº¦ï¼åªæ¼ä¸ä½¿ç¨ä»£çæåé¨åä»£çæ´åçåºæºãæåçç³»çµ±éå·æå¾é«çå¯è®æ§ (Flesch é±è®ç°¡ä¾¿æ§ä¸­ä½æ¸ 77.23ï¼Flesch Kincaid ç­ç´ä¸­ä½æ¸ 5.6)ãç©©å¥æ§ (ANOVA F å¼ 0.6126ï¼p>0.1) åç©©å®æ§ (ANOVA F å¼ 0.782ï¼p>0.1)ãAIPatient ç³»çµ±çåºè²è¡¨ç¾çªé¡¯äºå®å¨æ¯æ´åç¨®æç¨ç¨å¼çæ½åï¼åæ¬é«å­¸æè²ãæ¨¡åè©ä¼°åç³»çµ±æ´åã

##### **Suicide Phenotyping from Clinical Notes in Safety-Net Psychiatric Hospital Using Multi-Label Classification with Pre-Trained Language Models**
2409.18878v2 by Zehan Li, Yan Hu, Scott Lane, Salih Selek, Lokesh Shahani, Rodrigo Machado-Vieira, Jair Soares, Hua Xu, Hongfang Liu, Ming Huang

Accurate identification and categorization of suicidal events can yield
better suicide precautions, reducing operational burden, and improving care
quality in high-acuity psychiatric settings. Pre-trained language models offer
promise for identifying suicidality from unstructured clinical narratives. We
evaluated the performance of four BERT-based models using two fine-tuning
strategies (multiple single-label and single multi-label) for detecting
coexisting suicidal events from 500 annotated psychiatric evaluation notes. The
notes were labeled for suicidal ideation (SI), suicide attempts (SA), exposure
to suicide (ES), and non-suicidal self-injury (NSSI). RoBERTa outperformed
other models using multiple single-label classification strategy (acc=0.86,
F1=0.78). MentalBERT (acc=0.83, F1=0.74) also exceeded BioClinicalBERT
(acc=0.82, F1=0.72) which outperformed BERT (acc=0.80, F1=0.70). RoBERTa
fine-tuned with single multi-label classification further improved the model
performance (acc=0.88, F1=0.81). The findings highlight that the model
optimization, pretraining with domain-relevant data, and the single multi-label
classification strategy enhance the model performance of suicide phenotyping.
Keywords: EHR-based Phenotyping; Natural Language Processing; Secondary Use of
EHR Data; Suicide Classification; BERT-based Model; Psychiatry; Mental Health

æè¦ï¼<paragraph>æºç¢ºè¾¨è­ååé¡èªæ®ºäºä»¶ï¼å¯ä»¥ç¢çæ´å¥½çèªæ®ºé é²æªæ½ï¼éä½éä½è² æï¼ä¸¦æåé«æç²¾ç¥ç§ç°å¢ä¸­çç§è­·åè³ªãé åè¨ç·´çèªè¨æ¨¡åææå¾éçµæ§åçè¨åºæè¿°ä¸­è¾¨è­åºèªæ®ºå¾åãæåè©ä¼°äºåå BERT æ¨¡åçæè½ï¼ä½¿ç¨å©ç¨®å¾®èª¿ç­ç¥ï¼å¤éå®æ¨ç±¤åå®ä¸å¤æ¨ç±¤ï¼ä¾åµæ¸¬ 500 åè¨»è§£çç²¾ç¥ç§è©ä¼°è¨éä¸­ä¸¦å­çèªæ®ºäºä»¶ãéäºè¨éæ¨è¨çºèªæ®ºæå¿µï¼SIï¼ãèªæ®ºä¼åï¼SAï¼ãæ¥è§¸èªæ®ºï¼ESï¼åéèªæ®ºèªå·ï¼NSSIï¼ãRoBERTa ä½¿ç¨å¤éå®æ¨ç±¤åé¡ç­ç¥è¡¨ç¾åªæ¼å¶ä»æ¨¡åï¼acc=0.86ï¼F1=0.78ï¼ãMentalBERTï¼acc=0.83ï¼F1=0.74ï¼ä¹è¶é BioClinicalBERTï¼acc=0.82ï¼F1=0.72ï¼ï¼è BioClinicalBERT ååªæ¼ BERTï¼acc=0.80ï¼F1=0.70ï¼ãä½¿ç¨å®ä¸å¤æ¨ç±¤åé¡å¾®èª¿ç RoBERTa é²ä¸æ­¥æåäºæ¨¡åæè½ï¼acc=0.88ï¼F1=0.81ï¼ãç ç©¶çµæå¼·èª¿ï¼æ¨¡åæä½³åãä½¿ç¨èé åç¸éè³æé²è¡é è¨ç·´ï¼ä»¥åå®ä¸å¤æ¨ç±¤åé¡ç­ç¥ï¼å¯ä»¥æåèªæ®ºè¡¨ååæçæ¨¡åæè½ãééµå­ï¼åºæ¼é»å­çæ­·çè¡¨ååæï¼èªç¶èªè¨èçï¼é»å­çæ­·è³æçäºæ¬¡ä½¿ç¨ï¼èªæ®ºåé¡ï¼åºæ¼ BERT çæ¨¡åï¼ç²¾ç¥ç§ï¼å¿çå¥åº·</paragraph>

##### **Early diagnosis of Alzheimer's disease from MRI images with deep learning model**
2409.18814v1 by Sajjad Aghasi Javid, Mahmood Mohassel Feghhi

It is acknowledged that the most common cause of dementia worldwide is
Alzheimer's disease (AD). This condition progresses in severity from mild to
severe and interferes with people's everyday routines. Early diagnosis plays a
critical role in patient care and clinical trials. Convolutional neural
networks (CNN) are used to create a framework for identifying specific disease
features from MRI scans Classification of dementia involves approaches such as
medical history review, neuropsychological tests, and magnetic resonance
imaging (MRI). However, the image dataset obtained from Kaggle faces a
significant issue of class imbalance, which requires equal distribution of
samples from each class to address. In this article, to address this imbalance,
the Synthetic Minority Oversampling Technique (SMOTE) is utilized. Furthermore,
a pre-trained convolutional neural network has been applied to the DEMNET
dementia network to extract key features from AD images. The proposed model
achieved an impressive accuracy of 98.67%.

æè¦ï¼å¨çå¬èªæå¸¸è¦çå¤±æºçæå æ¯
é¿è²æµ·é»çï¼ADï¼ãéç¨®ç¾ççå´éç¨åº¦å¾è¼åº¦å°éåº¦ï¼ä¸¦æå¹²æ¾äººåçæ¥å¸¸ä½æ¯ãæ©æè¨ºæ·å¨æ£èç§è­·åè¨åºè©¦é©ä¸­æ®æ¼è³ééè¦çè§è²ãå·ç©ç¥ç¶ç¶²è·¯ï¼CNNï¼ç¨æ¼å»ºç«ä¸åæ¶æ§ï¼ä»¥å¾ MRI ææä¸­è¾¨è­ç¹å®çç¾çç¹å¾µãå¤±æºççåé¡æ¶åçæ­·åé¡§ãç¥ç¶å¿çæ¸¬é©åç£æ¯é å½±ï¼MRIï¼ç­æ¹æ³ãç¶èï¼å¾ Kaggle åå¾çå½±åè³æéé¢è¨é¡å¥ä¸å¹³è¡¡çéå¤§åé¡ï¼ééè¦æ¯åé¡å¥çæ¨£æ¬æ¸éç¸ç­æè½è§£æ±ºãå¨æ¬æä¸­ï¼çºäºè§£æ±ºéç¨®ä¸å¹³è¡¡ï¼ä½¿ç¨äºåæå°æ¸éæ¡æ¨£æè¡ï¼SMOTEï¼ãæ­¤å¤ï¼å·²å°é åè¨ç·´å¥½çå·ç©ç¥ç¶ç¶²è·¯æç¨æ¼ DEMNET å¤±æºçç¶²è·¯ï¼ä»¥å¾ AD å½±åä¸­èåééµç¹å¾µãææåºçæ¨¡åéå°äºä»¤äººå°è±¡æ·±å»ç 98.67% æºç¢ºçã

##### **State-of-the-Art Periorbital Distance Prediction and Disease Classification Using Periorbital Features**
2409.18769v2 by George R. Nahass, Ghasem Yazdanpanah, Madison Cheung, Alex Palacios, Jeffery Peterson, Kevin Heinze, Sasha Hubschman, Chad A. Purnell, Pete Setabutr, Ann Q. Tran, Darvin Yi

Periorbital distances and features around the eyes and lids hold valuable
information for disease quantification and monitoring of surgical and medical
intervention. These distances are commonly measured manually, a process that is
both subjective and highly time-consuming. Here, we set out to developed three
deep-learning methods for segmentation and periorbital distance prediction, and
also evaluate the utility of periorbital distances for disease classification.
The MAE of our deep learning predicted distances was less than or very close to
the error observed between trained human annotators. We compared our models to
the current state-of-the-art (SOTA) method for periorbital distance prediction
and found that our methods outperformed SOTA on all of our datasets on all but
one periorbital measurement. We also show that robust segmentation can be
achieved on diseased eyes using models trained on open-source, healthy eyes,
and that periorbital distances have can be used as high-quality features in
downstream classification models. Leveraging segmentation networks as
intermediary steps in classification has broad implications for increasing the
generalizability of classification models in ophthalmic plastic and
craniofacial surgery by avoiding the out-of-distribution problem observed in
traditional convolutional neural networks.

æè¦ï¼ç¼ç¶å¨åçè·é¢åç¹å¾µä»¥åç¼ç¼å°æ¼ç¾çéååå¤ç§åé«çå¹²é çç£æ§å·æå¯¶è²´çä¿¡æ¯ãéäºè·é¢éå¸¸æ¯æåæ¸¬éçï¼éæ¯ä¸åæ¢ä¸»è§åéå¸¸èæçéç¨ãå¨æ­¤ï¼æåèæéç¼äºä¸ç¨®ç¨æ¼åå²åç¼ç¶å¨åè·é¢é æ¸¬çæ·±åº¦å­¸ç¿æ¹æ³ï¼ä¸¦è©ä¼°äºç¼ç¶å¨åè·é¢å°ç¾çåé¡çæç¨ãæåçæ·±åº¦å­¸ç¿é æ¸¬è·é¢ç MAE å°æ¼æéå¸¸æ¥è¿è¨ç·´æç´ çäººé¡è¨»éèä¹éè§å¯å°çèª¤å·®ãæåå°æåçæ¨¡åèç¼ç¶å¨åè·é¢é æ¸¬çç¶åæåé² (SOTA) æ¹æ³é²è¡äºæ¯è¼ï¼ç¼ç¾æåçæ¨¡åå¨æåçæææ¸æéä¸é½åªæ¼ SOTAï¼åªæä¸åç¼ç¶å¨åæ¸¬éé¤å¤ãæåéè¡¨æï¼ä½¿ç¨å¨éæ¾æºä»£ç¢¼ãå¥åº·çç¼çä¸è¨ç·´çæ¨¡åå¯ä»¥å¨æ£ççç¼çä¸å¯¦ç¾ç©©å¥çåå²ï¼ä¸¦ä¸ç¼ç¶å¨åè·é¢å¯ç¨ä½ä¸æ¸¸åé¡æ¨¡åä¸­çé«è³ªéç¹å¾µãå©ç¨åå²ç¶²çµ¡ä½çºåé¡ä¸­çä¸­éæ­¥é©å°æé«ç¼ç§æ´å½¢åé¡±é¢å¤ç§ä¸­åé¡æ¨¡åçæ¦æ¬æ§å·æå»£æ³çå½±é¿ï¼å çºå®é¿åäºå¨å³çµ±å·ç©ç¥ç¶ç¶²çµ¡ä¸­è§å¯å°çåå¸å¤åé¡ã

##### **Multi-modal Medical Image Fusion For Non-Small Cell Lung Cancer Classification**
2409.18715v1 by Salma Hassan, Hamad Al Hammadi, Ibrahim Mohammed, Muhammad Haris Khan

The early detection and nuanced subtype classification of non-small cell lung
cancer (NSCLC), a predominant cause of cancer mortality worldwide, is a
critical and complex issue. In this paper, we introduce an innovative
integration of multi-modal data, synthesizing fused medical imaging (CT and PET
scans) with clinical health records and genomic data. This unique fusion
methodology leverages advanced machine learning models, notably MedClip and
BEiT, for sophisticated image feature extraction, setting a new standard in
computational oncology. Our research surpasses existing approaches, as
evidenced by a substantial enhancement in NSCLC detection and classification
precision. The results showcase notable improvements across key performance
metrics, including accuracy, precision, recall, and F1-score. Specifically, our
leading multi-modal classifier model records an impressive accuracy of 94.04%.
We believe that our approach has the potential to transform NSCLC diagnostics,
facilitating earlier detection and more effective treatment planning and,
ultimately, leading to superior patient outcomes in lung cancer care.

æè¦ï¼æ©ææª¢æ¸¬åç´°ç·»çéå°ç´°èèºç (NSCLC) äºååé¡ï¼æ¯å¨çççæ­»äº¡ççä¸»è¦åå ï¼æ¯ä¸åééµä¸è¤éçåé¡ãå¨æ¬æä¸­ï¼æåä»ç´¹äºä¸ååµæ°çå¤æ¨¡å¼æ¸ææ´åï¼å°èåçé«å­¸å½±å (CT å PET ææ) èè¨åºå¥åº·è¨éååºå çµæ¸æåæãéç¨®ç¨ç¹çèåæ¹æ³å©ç¨äºåé²çæ©å¨å­¸ç¿æ¨¡åï¼ç¹å¥æ¯ MedClip å BEiTï¼é²è¡è¤éçå½±åç¹å¾µæåï¼çºè¨ç®è«ç¤å­¸è¨­å®äºæ°çæ¨æºãæåçç ç©¶è¶è¶äºç¾ææ¹æ³ï¼éå¾ NSCLC æª¢æ¸¬ååé¡ç²¾åº¦çé¡¯èæé«ä¸­å¾å°è­æãçµæå±ç¤ºäºå¨ééµæè½ææ¨ï¼åæ¬æºç¢ºåº¦ãç²¾ç¢ºåº¦ãå¬åçå F1 åæ¸ï¼ä¸çé¡¯èæ¹é²ãå·é«ä¾èªªï¼æåé åçå¤æ¨¡å¼åé¡å¨æ¨¡åè¨éäºä»¤äººå°è±¡æ·±å»ç 94.04% æºç¢ºåº¦ãæåç¸ä¿¡æåçåæ³ææ½åè½è® NSCLC è¨ºæ·ï¼ä¿é²æ©ææª¢æ¸¬åæ´ææçæ²»çè¨ç«ï¼ä¸¦æçµæ¹åèºçç§è­·ä¸­çæ£èé å¾ã

