{"2407.05557": {"publish_time": "2024-07-08", "title": "$R^2$-Guard: Robust Reasoning Enabled LLM Guardrail via Knowledge-Enhanced Logical Reasoning", "paper_summary": "As LLMs become increasingly prevalent across various applications, it is\ncritical to establish safety guardrails to moderate input/output content of\nLLMs. Existing guardrail models treat various safety categories independently\nand fail to explicitly capture the intercorrelations among them. This has led\nto limitations such as ineffectiveness due to inadequate training on long-tail\ndata from correlated safety categories, susceptibility to jailbreaking attacks,\nand inflexibility regarding new safety categories. To address these\nlimitations, we propose $R^2$-Guard, a robust reasoning enabled LLM guardrail\nvia knowledge-enhanced logical reasoning. Specifically, $R^2$-Guard comprises\ntwo parts: data-driven category-specific learning and reasoning components. The\ndata-driven guardrail models provide unsafety probabilities of moderated\ncontent on different safety categories. We then encode safety knowledge among\ndifferent categories as first-order logical rules and embed them into a\nprobabilistic graphic model (PGM) based reasoning component. The unsafety\nprobabilities of different categories from data-driven guardrail models are\nsent to the reasoning component for final inference. We employ two types of\nPGMs: Markov logic networks (MLNs) and probabilistic circuits (PCs), and\noptimize PCs to achieve precision-efficiency balance via improved graph\nstructure. To further perform stress tests for guardrail models, we employ a\npairwise construction method to construct a new safety benchmark TwinSafety,\nwhich features principled categories. We demonstrate the effectiveness of\n$R^2$-Guard by comparisons with eight strong guardrail models on six safety\nbenchmarks, and demonstrate the robustness of $R^2$-Guard against four SOTA\njailbreaking attacks. $R^2$-Guard significantly surpasses SOTA method\nLlamaGuard by 30.2% on ToxicChat and by 59.5% against jailbreaking attacks.", "paper_summary_zh": "\u96a8\u8457 LLM \u5728\u5404\u7a2e\u61c9\u7528\u7a0b\u5f0f\u4e2d\u8b8a\u5f97\u8d8a\u4f86\u8d8a\u666e\u904d\uff0c\u5efa\u7acb\u5b89\u5168\u9632\u8b77\u63aa\u65bd\u4ee5\u8abf\u7bc0 LLM \u7684\u8f38\u5165/\u8f38\u51fa\u5167\u5bb9\u81f3\u95dc\u91cd\u8981\u3002\u73fe\u6709\u7684\u9632\u8b77\u63aa\u65bd\u6a21\u578b\u7368\u7acb\u8655\u7406\u5404\u7a2e\u5b89\u5168\u985e\u5225\uff0c\u672a\u80fd\u660e\u78ba\u6355\u6349\u5b83\u5011\u4e4b\u9593\u7684\u76f8\u4e92\u95dc\u806f\u6027\u3002\u9019\u5c0e\u81f4\u4e86\u8af8\u591a\u9650\u5236\uff0c\u4f8b\u5982\u7531\u65bc\u5c0d\u76f8\u95dc\u5b89\u5168\u985e\u5225\u4e2d\u7684\u9577\u5c3e\u8cc7\u6599\u8a13\u7df4\u4e0d\u8db3\u800c\u5c0e\u81f4\u7684\u7121\u6548\u6027\u3001\u6613\u53d7\u8d8a\u7344\u653b\u64ca\u4ee5\u53ca\u5c0d\u65b0\u5b89\u5168\u985e\u5225\u7f3a\u4e4f\u9748\u6d3b\u6027\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u4e9b\u9650\u5236\uff0c\u6211\u5011\u63d0\u51fa\u4e86 $R^2$-Guard\uff0c\u9019\u662f\u4e00\u500b\u901a\u904e\u77e5\u8b58\u589e\u5f37\u908f\u8f2f\u63a8\u7406\u5be6\u73fe\u7684\u5f37\u5927\u63a8\u7406\u555f\u7528 LLM \u9632\u8b77\u63aa\u65bd\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c$R^2$-Guard \u5305\u542b\u5169\u90e8\u5206\uff1a\u8cc7\u6599\u9a45\u52d5\u7684\u985e\u5225\u7279\u5b9a\u5b78\u7fd2\u548c\u63a8\u7406\u7d44\u4ef6\u3002\u8cc7\u6599\u9a45\u52d5\u7684\u9632\u8b77\u63aa\u65bd\u6a21\u578b\u63d0\u4f9b\u4e86\u4e0d\u540c\u5b89\u5168\u985e\u5225\u4e2d\u5df2\u8abf\u7bc0\u5167\u5bb9\u7684\u4e0d\u5b89\u5168\u6027\u6a5f\u7387\u3002\u7136\u5f8c\uff0c\u6211\u5011\u5c07\u4e0d\u540c\u985e\u5225\u4e4b\u9593\u7684\u5b89\u5168\u77e5\u8b58\u7de8\u78bc\u70ba\u4e00\u968e\u908f\u8f2f\u898f\u5247\uff0c\u4e26\u5c07\u5b83\u5011\u5d4c\u5165\u57fa\u65bc\u6a5f\u7387\u5716\u5f62\u6a21\u578b (PGM) \u7684\u63a8\u7406\u7d44\u4ef6\u4e2d\u3002\u4f86\u81ea\u8cc7\u6599\u9a45\u52d5\u9632\u8b77\u63aa\u65bd\u6a21\u578b\u7684\u4e0d\u540c\u985e\u5225\u7684\u4e0d\u5b89\u5168\u6027\u6a5f\u7387\u88ab\u50b3\u9001\u81f3\u63a8\u7406\u7d44\u4ef6\u4ee5\u9032\u884c\u6700\u7d42\u63a8\u8ad6\u3002\u6211\u5011\u63a1\u7528\u5169\u7a2e PGM\uff1a\u99ac\u53ef\u592b\u908f\u8f2f\u7db2\u8def (MLN) \u548c\u6a5f\u7387\u96fb\u8def (PC)\uff0c\u4e26\u6700\u4f73\u5316 PC \u4ee5\u900f\u904e\u6539\u5584\u5716\u5f62\u7d50\u69cb\u4f86\u5be6\u73fe\u7cbe\u6e96\u5ea6\u8207\u6548\u7387\u7684\u5e73\u8861\u3002\u70ba\u4e86\u9032\u4e00\u6b65\u5c0d\u9632\u8b77\u63aa\u65bd\u6a21\u578b\u57f7\u884c\u58d3\u529b\u6e2c\u8a66\uff0c\u6211\u5011\u63a1\u7528\u6210\u5c0d\u5efa\u69cb\u65b9\u6cd5\u5efa\u69cb\u4e00\u500b\u65b0\u7684\u5b89\u5168\u57fa\u6e96 TwinSafety\uff0c\u5176\u7279\u9ede\u662f\u539f\u5247\u6027\u985e\u5225\u3002\u6211\u5011\u900f\u904e\u8207\u516b\u500b\u5f37\u5927\u7684\u9632\u8b77\u63aa\u65bd\u6a21\u578b\u5728\u516d\u500b\u5b89\u5168\u57fa\u6e96\u4e0a\u7684\u6bd4\u8f03\u4f86\u8b49\u660e $R^2$-Guard \u7684\u6709\u6548\u6027\uff0c\u4e26\u5c55\u793a $R^2$-Guard \u5c0d\u56db\u7a2e SOTA \u8d8a\u7344\u653b\u64ca\u7684\u5f37\u5065\u6027\u3002$R^2$-Guard \u5728 ToxicChat \u4e0a\u6bd4 SOTA \u65b9\u6cd5 LlamaGuard \u9ad8\u51fa 30.2%\uff0c\u5728\u5c0d\u6297\u8d8a\u7344\u653b\u64ca\u65b9\u9762\u9ad8\u51fa 59.5%\u3002", "author": "Mintong Kang et.al.", "authors": "Mintong Kang, Bo Li", "id": "2407.05557v1", "paper_url": "http://arxiv.org/abs/2407.05557v1", "repo": "null"}}