{"2406.09334": {"publish_time": "2024-06-13", "title": "ProxyLM: Predicting Language Model Performance on Multilingual Tasks via Proxy Models", "paper_summary": "Performance prediction is a method to estimate the performance of Language\nModels (LMs) on various Natural Language Processing (NLP) tasks, mitigating\ncomputational costs associated with model capacity and data for fine-tuning.\nOur paper introduces ProxyLM, a scalable framework for predicting LM\nperformance using proxy models in multilingual tasks. These proxy models act as\nsurrogates, approximating the performance of the LM of interest. By leveraging\nproxy models, ProxyLM significantly reduces computational overhead on task\nevaluations, achieving up to a 37.08x speedup compared to traditional methods,\neven with our smallest proxy models. Additionally, our methodology showcases\nadaptability to previously unseen languages in pre-trained LMs, outperforming\nthe state-of-the-art performance by 1.89x as measured by root-mean-square error\n(RMSE). This framework streamlines model selection, enabling efficient\ndeployment and iterative LM enhancements without extensive computational\nresources.", "paper_summary_zh": "\u6548\u80fd\u9810\u6e2c\u662f\u4e00\u7a2e\u4f30\u8a08\u8a9e\u8a00\u6a21\u578b (LM) \u5728\u5404\u7a2e\u81ea\u7136\u8a9e\u8a00\u8655\u7406 (NLP) \u4efb\u52d9\u4e0a\u6548\u80fd\u7684\u65b9\u6cd5\uff0c\u53ef\u964d\u4f4e\u8207\u6a21\u578b\u5bb9\u91cf\u548c\u5fae\u8abf\u8cc7\u6599\u76f8\u95dc\u7684\u904b\u7b97\u6210\u672c\u3002\u6211\u5011\u7684\u8ad6\u6587\u4ecb\u7d39\u4e86 ProxyLM\uff0c\u9019\u662f\u4e00\u500b\u53ef\u64f4\u5145\u7684\u6846\u67b6\uff0c\u53ef\u7528\u65bc\u4f7f\u7528\u591a\u8a9e\u8a00\u4efb\u52d9\u4e2d\u7684\u4ee3\u7406\u6a21\u578b\u9810\u6e2c LM \u6548\u80fd\u3002\u9019\u4e9b\u4ee3\u7406\u6a21\u578b\u626e\u6f14\u4ee3\u7406\u89d2\u8272\uff0c\u8fd1\u4f3c\u611f\u8208\u8da3\u7684 LM \u6548\u80fd\u3002\u900f\u904e\u5229\u7528\u4ee3\u7406\u6a21\u578b\uff0cProxyLM \u5927\u5e45\u964d\u4f4e\u4e86\u4efb\u52d9\u8a55\u4f30\u7684\u904b\u7b97\u8ca0\u64d4\uff0c\u8207\u50b3\u7d71\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5373\u4f7f\u4f7f\u7528\u6211\u5011\u6700\u5c0f\u7684\u4ee3\u7406\u6a21\u578b\uff0c\u4e5f\u80fd\u9054\u5230\u9ad8\u9054 37.08 \u500d\u7684\u52a0\u901f\u3002\u6b64\u5916\uff0c\u6211\u5011\u7684\u6280\u8853\u5c55\u793a\u4e86\u5c0d\u9810\u5148\u8a13\u7df4 LM \u4e2d\u4ee5\u524d\u672a\u898b\u8a9e\u8a00\u7684\u9069\u61c9\u6027\uff0c\u4ee5\u5747\u65b9\u6839\u8aa4\u5dee (RMSE) \u8861\u91cf\uff0c\u5176\u6548\u80fd\u512a\u65bc\u73fe\u6709\u6280\u8853 1.89 \u500d\u3002\u6b64\u6846\u67b6\u7c21\u5316\u4e86\u6a21\u578b\u9078\u64c7\uff0c\u5373\u4f7f\u6c92\u6709\u5927\u91cf\u7684\u904b\u7b97\u8cc7\u6e90\uff0c\u4e5f\u80fd\u9032\u884c\u6709\u6548\u7387\u7684\u90e8\u7f72\u548c\u53cd\u8986 LM \u589e\u5f37\u3002", "author": "David Anugraha et.al.", "authors": "David Anugraha, Genta Indra Winata, Chenyue Li, Patrick Amadeus Irawan, En-Shiun Annie Lee", "id": "2406.09334v2", "paper_url": "http://arxiv.org/abs/2406.09334v2", "repo": "https://github.com/davidanugraha/proxylm"}}