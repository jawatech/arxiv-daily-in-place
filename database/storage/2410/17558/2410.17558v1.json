{"2410.17558": {"publish_time": "2024-10-23", "title": "CLR-Bench: Evaluating Large Language Models in College-level Reasoning", "paper_summary": "Large language models (LLMs) have demonstrated their remarkable performance\nacross various language understanding tasks. While emerging benchmarks have\nbeen proposed to evaluate LLMs in various domains such as mathematics and\ncomputer science, they merely measure the accuracy in terms of the final\nprediction on multi-choice questions. However, it remains insufficient to\nverify the essential understanding of LLMs given a chosen choice. To fill this\ngap, we present CLR-Bench to comprehensively evaluate the LLMs in complex\ncollege-level reasoning. Specifically, (i) we prioritize 16 challenging college\ndisciplines in computer science and artificial intelligence. The dataset\ncontains 5 types of questions, while each question is associated with detailed\nexplanations from experts. (ii) To quantify a fair evaluation of LLMs'\nreasoning ability, we formalize the criteria with two novel metrics.\nQ$\\rightarrow$A is utilized to measure the performance of direct answer\nprediction, and Q$\\rightarrow$AR effectively considers the joint ability to\nanswer the question and provide rationale simultaneously. Extensive experiments\nare conducted with 40 LLMs over 1,018 discipline-specific questions. The\nresults demonstrate the key insights that LLMs, even the best closed-source\nLLM, i.e., GPT-4 turbo, tend to `guess' the college-level answers. It shows a\ndramatic decrease in accuracy from 63.31% Q$\\rightarrow$A to 39.00%\nQ$\\rightarrow$AR, indicating an unsatisfactory reasoning ability.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5c55\u73fe\u5176\u5728\u5404\u7a2e\u8a9e\u8a00\u7406\u89e3\u4efb\u52d9\u4e2d\u7684\u5091\u51fa\u8868\u73fe\u3002\u96d6\u7136\u5df2\u63d0\u51fa\u65b0\u8208\u57fa\u6e96\u4f86\u8a55\u4f30 LLM \u5728\u6578\u5b78\u548c\u96fb\u8166\u79d1\u5b78\u7b49\u4e0d\u540c\u9818\u57df\u4e2d\u7684\u8868\u73fe\uff0c\u4f46\u9019\u4e9b\u57fa\u6e96\u50c5\u5c31\u591a\u9078\u984c\u7684\u6700\u7d42\u9810\u6e2c\u6e2c\u91cf\u6e96\u78ba\u6027\u3002\u7136\u800c\uff0c\u5c0d\u65bc LLM \u5728\u9078\u64c7\u9078\u9805\u5f8c\u7684\u57fa\u672c\u7406\u89e3\uff0c\u4ecd\u4e0d\u8db3\u4ee5\u9a57\u8b49\u3002\u70ba\u4e86\u586b\u88dc\u9019\u500b\u7a7a\u767d\uff0c\u6211\u5011\u63d0\u51fa CLR-Bench \u4f86\u5168\u9762\u8a55\u4f30 LLM \u5728\u8907\u96dc\u7684\u5927\u5c08\u7a0b\u5ea6\u63a8\u7406\u4e2d\u7684\u8868\u73fe\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\uff08\u4e00\uff09\u6211\u5011\u512a\u5148\u8003\u616e\u96fb\u8166\u79d1\u5b78\u548c\u4eba\u5de5\u667a\u6167\u4e2d\u7684 16 \u500b\u5177\u6709\u6311\u6230\u6027\u7684\u5927\u5b78\u79d1\u7cfb\u3002\u8a72\u8cc7\u6599\u96c6\u5305\u542b 5 \u7a2e\u985e\u578b\u7684\u554f\u984c\uff0c\u800c\u6bcf\u500b\u554f\u984c\u90fd\u9644\u6709\u5c08\u5bb6\u7684\u8a73\u7d30\u8aaa\u660e\u3002\uff08\u4e8c\uff09\u70ba\u4e86\u91cf\u5316 LLM \u63a8\u7406\u80fd\u529b\u7684\u516c\u5e73\u8a55\u4f30\uff0c\u6211\u5011\u4ee5\u5169\u500b\u65b0\u7a4e\u7684\u6307\u6a19\u5f62\u5f0f\u5316\u6a19\u6e96\u3002Q\u2192A \u7528\u65bc\u6e2c\u91cf\u76f4\u63a5\u7b54\u6848\u9810\u6e2c\u7684\u8868\u73fe\uff0c\u800c Q\u2192AR \u6709\u6548\u5730\u8003\u616e\u4e86\u540c\u6642\u56de\u7b54\u554f\u984c\u548c\u63d0\u4f9b\u7406\u7531\u7684\u7d9c\u5408\u80fd\u529b\u3002\u6211\u5011\u91dd\u5c0d 40 \u500b LLM \u9032\u884c\u4e86\u8d85\u904e 1,018 \u500b\u7279\u5b9a\u9818\u57df\u554f\u984c\u7684\u5ee3\u6cdb\u5be6\u9a57\u3002\u7d50\u679c\u8b49\u660e\u4e86\u95dc\u9375\u898b\u89e3\uff0c\u5373 LLM\uff0c\u751a\u81f3\u662f\u6700\u597d\u7684\u9589\u6e90 LLM\uff0c\u5373 GPT-4 turbo\uff0c\u90fd\u50be\u5411\u65bc\u300c\u731c\u6e2c\u300d\u5927\u5b78\u7a0b\u5ea6\u7684\u7b54\u6848\u3002\u5b83\u986f\u793a\u6e96\u78ba\u5ea6\u5f9e 63.31% Q\u2192A \u5927\u5e45\u4e0b\u964d\u81f3 39.00% Q\u2192AR\uff0c\u9019\u8868\u793a\u63a8\u7406\u80fd\u529b\u4e0d\u4ee4\u4eba\u6eff\u610f\u3002", "author": "Junnan Dong et.al.", "authors": "Junnan Dong, Zijin Hong, Yuanchen Bei, Feiran Huang, Xinrun Wang, Xiao Huang", "id": "2410.17558v1", "paper_url": "http://arxiv.org/abs/2410.17558v1", "repo": "null"}}