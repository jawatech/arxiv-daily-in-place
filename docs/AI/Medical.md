
### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-06-12**|**AWGUNET: Attention-Aided Wavelet Guided U-Net for Nuclei Segmentation in Histopathology Images**|Ayush Roy et.al.|[2406.08425v1](http://arxiv.org/abs/2406.08425v1)|[link](https://github.com/ayushroy2001/awgunet)|
|**2024-06-12**|**2.5D Multi-view Averaging Diffusion Model for 3D Medical Image Translation: Application to Low-count PET Reconstruction with CT-less Attenuation Correction**|Tianqi Chen et.al.|[2406.08374v1](http://arxiv.org/abs/2406.08374v1)|null|
|**2024-06-12**|**Making AI Intelligible: Philosophical Foundations**|Herman Cappelen et.al.|[2406.08134v1](http://arxiv.org/abs/2406.08134v1)|null|
|**2024-06-12**|**Graph Transductive Defense: a Two-Stage Defense for Graph Membership Inference Attacks**|Peizhi Niu et.al.|[2406.07917v1](http://arxiv.org/abs/2406.07917v1)|null|
|**2024-06-11**|**Cognitive Insights Across Languages: Enhancing Multimodal Interview Analysis**|David Ortiz-Perez et.al.|[2406.07542v1](http://arxiv.org/abs/2406.07542v1)|[link](https://github.com/davidorp/taukadial)|
|**2024-06-11**|**CADS: A Systematic Literature Review on the Challenges of Abstractive Dialogue Summarization**|Frederic Kirstein et.al.|[2406.07494v2](http://arxiv.org/abs/2406.07494v2)|null|
|**2024-06-11**|**Benchmarking and Boosting Radiology Report Generation for 3D High-Resolution Medical Images**|Che Liu et.al.|[2406.07146v2](http://arxiv.org/abs/2406.07146v2)|null|
|**2024-06-11**|**Unlocking the Potential of the Metaverse for Innovative and Immersive Digital Care**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v1](http://arxiv.org/abs/2406.07114v1)|null|
|**2024-06-11**|**Heterogeneous Learning Rate Scheduling for Neural Architecture Search on Long-Tailed Datasets**|Chenxia Tang et.al.|[2406.07028v1](http://arxiv.org/abs/2406.07028v1)|null|
|**2024-06-10**|**Taxes Are All You Need: Integration of Taxonomical Hierarchy Relationships into the Contrastive Loss**|Kiran Kokilepersaud et.al.|[2406.06848v1](http://arxiv.org/abs/2406.06848v1)|null|
|**2024-06-10**|**SciRIFF: A Resource to Enhance Language Model Instruction-Following over Scientific Literature**|David Wadden et.al.|[2406.07835v1](http://arxiv.org/abs/2406.07835v1)|null|
|**2024-06-10**|**BTS: Bridging Text and Sound Modalities for Metadata-Aided Respiratory Sound Classification**|June-Woo Kim et.al.|[2406.06786v1](http://arxiv.org/abs/2406.06786v1)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Merlin: A Vision Language Foundation Model for 3D Computed Tomography**|Louis Blankemeier et.al.|[2406.06512v1](http://arxiv.org/abs/2406.06512v1)|null|
|**2024-06-10**|**Towards a Personal Health Large Language Model**|Justin Cosentino et.al.|[2406.06474v1](http://arxiv.org/abs/2406.06474v1)|null|
|**2024-06-10**|**Transforming Wearable Data into Health Insights using Large Language Model Agents**|Mike A. Merrill et.al.|[2406.06464v2](http://arxiv.org/abs/2406.06464v2)|null|
|**2024-06-10**|**A Large Language Model Pipeline for Breast Cancer Oncology**|Tristen Pool et.al.|[2406.06455v1](http://arxiv.org/abs/2406.06455v1)|null|
|**2024-06-10**|**Language Models are Alignable Decision-Makers: Dataset and Application to the Medical Triage Domain**|Brian Hu et.al.|[2406.06435v1](http://arxiv.org/abs/2406.06435v1)|[link](https://github.com/itm-kitware/llm-alignable-dm)|
|**2024-06-10**|**Improving Deep Learning-based Automatic Cranial Defect Reconstruction by Heavy Data Augmentation: From Image Registration to Latent Diffusion Models**|Marek Wodzinski et.al.|[2406.06372v1](http://arxiv.org/abs/2406.06372v1)|null|
|**2024-06-10**|**MedExQA: Medical Question Answering Benchmark with Multiple Explanations**|Yunsoo Kim et.al.|[2406.06331v1](http://arxiv.org/abs/2406.06331v1)|null|
|**2024-06-10**|**BrainChat: Decoding Semantic Information from fMRI using Vision-language Pretrained Models**|Wanaiu Huang et.al.|[2406.07584v1](http://arxiv.org/abs/2406.07584v1)|null|
|**2024-06-10**|**A Dual-View Approach to Classifying Radiology Reports by Co-Training**|Yutong Han et.al.|[2406.05995v1](http://arxiv.org/abs/2406.05995v1)|[link](https://github.com/manga-uofa/radiology-cotrain)|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-10**|**Decision-Making Behavior Evaluation Framework for LLMs under Uncertain Context**|Jingru Jia et.al.|[2406.05972v1](http://arxiv.org/abs/2406.05972v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-09**|**From Basic to Extra Features: Hypergraph Transformer Pretrain-then-Finetuning for Balanced Clinical Predictions on EHR**|Ran Xu et.al.|[2406.05682v1](http://arxiv.org/abs/2406.05682v1)|null|
|**2024-06-09**|**CCSI: Continual Class-Specific Impression for Data-free Class Incremental Learning**|Sana Ayromlou et.al.|[2406.05631v1](http://arxiv.org/abs/2406.05631v1)|[link](https://github.com/ubc-tea/continual-impression-ccsi)|
|**2024-06-09**|**Which Backbone to Use: A Resource-efficient Domain Specific Comparison for Computer Vision**|Pranav Jeevan et.al.|[2406.05612v1](http://arxiv.org/abs/2406.05612v1)|[link](https://github.com/pranavphoenix/Backbones)|
|**2024-06-08**|**I-SIRch: AI-Powered Concept Annotation Tool For Equitable Extraction And Analysis Of Safety Insights From Maternity Investigations**|Mohit Kumar Singh et.al.|[2406.05505v1](http://arxiv.org/abs/2406.05505v1)|null|
|**2024-06-08**|**DeviceBERT: Applied Transfer Learning With Targeted Annotations and Vocabulary Enrichment to Identify Medical Device and Component Terminology in FDA Recall Summaries**|Miriam Farrington et.al.|[2406.05307v1](http://arxiv.org/abs/2406.05307v1)|null|
|**2024-06-07**|**Analyzing the factors that are involved in length of inpatient stay at the hospital for diabetes patients**|Jorden Lam et.al.|[2406.05189v1](http://arxiv.org/abs/2406.05189v1)|null|
|**2024-06-07**|**Benchmarking Deep Jansen-Rit Parameter Inference: An in Silico Study**|Deepa Tilwani et.al.|[2406.05002v1](http://arxiv.org/abs/2406.05002v1)|[link](https://github.com/lina-usc/jansen-rit-model-benchmarking-deep-learning)|
|**2024-06-07**|**DualTime: A Dual-Adapter Multimodal Language Model for Time Series Representation**|Weiqi Zhang et.al.|[2406.06620v1](http://arxiv.org/abs/2406.06620v1)|null|
|**2024-06-07**|**CarbonSense: A Multimodal Dataset and Baseline for Carbon Flux Modelling**|Matthew Fortier et.al.|[2406.04940v1](http://arxiv.org/abs/2406.04940v1)|null|
|**2024-06-07**|**PANDORA: Deep graph learning based COVID-19 infection risk level forecasting**|Shuo Yu et.al.|[2406.06618v1](http://arxiv.org/abs/2406.06618v1)|null|
|**2024-06-07**|**Transforming Dental Diagnostics with Artificial Intelligence: Advanced Integration of ChatGPT and Large Language Models for Patient Care**|Masoumeh Farhadi Nia et.al.|[2406.06616v1](http://arxiv.org/abs/2406.06616v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-06**|**Rare Class Prediction Model for Smart Industry in Semiconductor Manufacturing**|Abdelrahman Farrag et.al.|[2406.04533v1](http://arxiv.org/abs/2406.04533v1)|null|
|**2024-06-06**|**Single Exposure Quantitative Phase Imaging with a Conventional Microscope using Diffusion Models**|Gabriel della Maggiora et.al.|[2406.04388v1](http://arxiv.org/abs/2406.04388v1)|null|
|**2024-06-06**|**Promoting Fairness and Diversity in Speech Datasets for Mental Health and Neurological Disorders Research**|Eleonora Mancini et.al.|[2406.04116v1](http://arxiv.org/abs/2406.04116v1)|null|
|**2024-06-06**|**Leveraging SPD Matrices on Riemannian Manifolds in Quantum Classical Hybrid Models for Structural Health Monitoring**|Azadeh Alavi et.al.|[2406.04055v1](http://arxiv.org/abs/2406.04055v1)|null|
|**2024-06-05**|**Speech-based Clinical Depression Screening: An Empirical Study**|Yangbin Chen et.al.|[2406.03510v2](http://arxiv.org/abs/2406.03510v2)|null|
|**2024-06-05**|**Robust Prediction Model for Multidimensional and Unbalanced Datasets**|Pooja Thakar et.al.|[2406.03507v1](http://arxiv.org/abs/2406.03507v1)|null|
|**2024-06-05**|**Stochastic Diffusion: A Diffusion Probabilistic Model for Stochastic Time Series Forecasting**|Yuansan Liu et.al.|[2406.02827v1](http://arxiv.org/abs/2406.02827v1)|null|
|**2024-06-04**|**Pancreatic Tumor Segmentation as Anomaly Detection in CT Images Using Denoising Diffusion Models**|Reza Babaei et.al.|[2406.02653v1](http://arxiv.org/abs/2406.02653v1)|null|
|**2024-06-04**|**Learning Image Priors through Patch-based Diffusion Models for Solving Inverse Problems**|Jason Hu et.al.|[2406.02462v1](http://arxiv.org/abs/2406.02462v1)|null|
|**2024-06-04**|**Multiple Choice Questions and Large Languages Models: A Case Study with Fictional Medical Data**|Maxime Griot et.al.|[2406.02394v1](http://arxiv.org/abs/2406.02394v1)|[link](https://github.com/maximegmd/glianorex-gen)|
|**2024-06-04**|**LlamaCare: A Large Medical Language Model for Enhancing Healthcare Knowledge Sharing**|Maojun Sun et.al.|[2406.02350v2](http://arxiv.org/abs/2406.02350v2)|[link](https://github.com/stephen-smj/llamacare)|
|**2024-06-04**|**A Comparative Study of Sampling Methods with Cross-Validation in the FedHome Framework**|Arash Ahmadi et.al.|[2406.01950v1](http://arxiv.org/abs/2406.01950v1)|null|
|**2024-06-03**|**Enhancing Clinical Documentation with Synthetic Data: Leveraging Generative Models for Improved Accuracy**|Anjanava Biswas et.al.|[2406.06569v1](http://arxiv.org/abs/2406.06569v1)|null|
|**2024-06-03**|**Compute-Efficient Medical Image Classification with Softmax-Free Transformers and Sequence Normalization**|Firas Khader et.al.|[2406.01314v1](http://arxiv.org/abs/2406.01314v1)|null|
|**2024-06-03**|**TCMBench: A Comprehensive Benchmark for Evaluating Large Language Models in Traditional Chinese Medicine**|Wenjing Yue et.al.|[2406.01126v1](http://arxiv.org/abs/2406.01126v1)|null|
|**2024-06-03**|**Effective Subset Selection Through The Lens of Neural Network Pruning**|Noga Bar et.al.|[2406.01086v1](http://arxiv.org/abs/2406.01086v1)|null|
|**2024-06-03**|**Causal prompting model-based offline reinforcement learning**|Xuehui Yu et.al.|[2406.01065v1](http://arxiv.org/abs/2406.01065v1)|null|
|**2024-06-03**|**Synthetic Data Generation for 3D Myocardium Deformation Analysis**|Shahar Zuler et.al.|[2406.01040v1](http://arxiv.org/abs/2406.01040v1)|[link](https://github.com/shaharzuler/cardio_volume_skewer)|
|**2024-06-03**|**MEDIQ: Question-Asking LLMs for Adaptive and Reliable Clinical Reasoning**|Shuyue Stella Li et.al.|[2406.00922v2](http://arxiv.org/abs/2406.00922v2)|[link](https://github.com/stellali7/mediq)|
|**2024-06-02**|**Bayesian Joint Additive Factor Models for Multiview Learning**|Niccolo Anceschi et.al.|[2406.00778v1](http://arxiv.org/abs/2406.00778v1)|[link](https://github.com/niccoloanceschi/jafar)|
|**2024-06-02**|**An Early Investigation into the Utility of Multimodal Large Language Models in Medical Imaging**|Sulaiman Khan et.al.|[2406.00667v1](http://arxiv.org/abs/2406.00667v1)|null|
|**2024-06-02**|**SimSAM: Zero-shot Medical Image Segmentation via Simulated Interaction**|Benjamin Towle et.al.|[2406.00663v1](http://arxiv.org/abs/2406.00663v1)|[link](https://github.com/benjamintowle/simsam)|
|**2024-06-02**|**Multimodal Deep Learning for Low-Resource Settings: A Vector Embedding Alignment Approach for Healthcare Applications**|David Restrepo et.al.|[2406.02601v1](http://arxiv.org/abs/2406.02601v1)|null|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**CASE: Curricular Data Pre-training for Building Generative and Discriminative Assistive Psychology Expert Models**|Sarthak Harne et.al.|[2406.00314v1](http://arxiv.org/abs/2406.00314v1)|[link](https://github.com/sarthakharne/case)|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-31**|**DYNA: Disease-Specific Language Model for Variant Pathogenicity**|Huixin Zhan et.al.|[2406.00164v1](http://arxiv.org/abs/2406.00164v1)|null|
|**2024-05-31**|**Recurrent neural networks: vanishing and exploding gradients are not the end of the story**|Nicolas Zucchet et.al.|[2405.21064v1](http://arxiv.org/abs/2405.21064v1)|null|
|**2024-05-31**|**Generative Adversarial Networks in Ultrasound Imaging: Extending Field of View Beyond Conventional Limits**|Matej Gazda et.al.|[2405.20981v1](http://arxiv.org/abs/2405.20981v1)|null|
|**2024-05-31**|**OR-Bench: An Over-Refusal Benchmark for Large Language Models**|Justin Cui et.al.|[2405.20947v1](http://arxiv.org/abs/2405.20947v1)|null|
|**2024-05-31**|**ABodyBuilder3: Improved and scalable antibody structure predictions**|Henry Kenlay et.al.|[2405.20863v1](http://arxiv.org/abs/2405.20863v1)|[link](https://github.com/exscientia/abodybuilder3)|
|**2024-05-31**|**Maximum Temperature Prediction Using Remote Sensing Data Via Convolutional Neural Network**|Lorenzo Innocenti et.al.|[2405.20731v1](http://arxiv.org/abs/2405.20731v1)|null|
|**2024-05-31**|**GAMedX: Generative AI-based Medical Entity Data Extractor Using Large Language Models**|Mohammed-Khalil Ghali et.al.|[2405.20585v1](http://arxiv.org/abs/2405.20585v1)|null|
|**2024-05-31**|**The Point of View of a Sentiment: Towards Clinician Bias Detection in Psychiatric Notes**|Alissa A. Valentine et.al.|[2405.20582v1](http://arxiv.org/abs/2405.20582v1)|null|
|**2024-05-31**|**Can Machine Learning Assist in Diagnosis of Primary Immune Thrombocytopenia? A feasibility study**|Haroon Miah et.al.|[2405.20562v1](http://arxiv.org/abs/2405.20562v1)|null|
|**2024-05-30**|**Enhancing Performance for Highly Imbalanced Medical Data via Data Regularization in a Federated Learning Setting**|Georgios Tsoumplekas et.al.|[2405.20430v1](http://arxiv.org/abs/2405.20430v1)|null|
|**2024-05-30**|**Worse than Random? An Embarrassingly Simple Probing Evaluation of Large Multimodal Models in Medical VQA**|Qianqi Yan et.al.|[2405.20421v1](http://arxiv.org/abs/2405.20421v1)|[link](https://github.com/eric-ai-lab/probmed)|
|**2024-05-30**|**Enhancing Antibiotic Stewardship using a Natural Language Approach for Better Feature Representation**|Simon A. Lee et.al.|[2405.20419v1](http://arxiv.org/abs/2405.20419v1)|null|
|**2024-05-30**|**MSSC-BiMamba: Multimodal Sleep Stage Classification and Early Diagnosis of Sleep Disorders with Bidirectional Mamba**|Chao Zhang et.al.|[2405.20142v2](http://arxiv.org/abs/2405.20142v2)|null|
|**2024-05-30**|**Out-of-distribution Reject Option Method for Dataset Shift Problem in Early Disease Onset Prediction**|Taisei Tosaki et.al.|[2405.19864v1](http://arxiv.org/abs/2405.19864v1)|null|
|**2024-05-30**|**Dynamic feature selection in medical predictive monitoring by reinforcement learning**|Yutong Chen et.al.|[2405.19729v1](http://arxiv.org/abs/2405.19729v1)|null|
|**2024-05-30**|**Unlocking the Power of Spatial and Temporal Information in Medical Multimodal Pre-training**|Jinxia Yang et.al.|[2405.19654v1](http://arxiv.org/abs/2405.19654v1)|[link](https://github.com/svt-yang/medst)|
|**2024-05-30**|**Leveraging Open-Source Large Language Models for encoding Social Determinants of Health using an Intelligent Router**|Akul Goel et.al.|[2405.19631v1](http://arxiv.org/abs/2405.19631v1)|null|
|**2024-05-29**|**Dr-LLaVA: Visual Instruction Tuning with Symbolic Clinical Grounding**|Shenghuan Sun et.al.|[2405.19567v1](http://arxiv.org/abs/2405.19567v1)|null|
|**2024-05-29**|**Unlocking the Potential of Large Language Models for Clinical Text Anonymization: A Comparative Study**|David Pissarra et.al.|[2406.00062v1](http://arxiv.org/abs/2406.00062v1)|null|
|**2024-05-29**|**CheXpert Plus: Augmenting a Large Chest X-ray Dataset with Text Radiology Reports, Patient Demographics and Additional Image Formats**|Pierre Chambon et.al.|[2405.19538v2](http://arxiv.org/abs/2405.19538v2)|[link](https://github.com/stanford-aimi/chexpert-plus)|
|**2024-05-29**|**Participation in the age of foundation models**|Harini Suresh et.al.|[2405.19479v1](http://arxiv.org/abs/2405.19479v1)|null|
|**2024-05-29**|**MemControl: Mitigating Memorization in Medical Diffusion Models via Automated Parameter Selection**|Raman Dutt et.al.|[2405.19458v1](http://arxiv.org/abs/2405.19458v1)|null|
|**2024-05-29**|**Conformal Depression Prediction**|Yonghong Li et.al.|[2405.18723v1](http://arxiv.org/abs/2405.18723v1)|null|
|**2024-05-28**|**D-CoRP: Differentiable Connectivity Refinement for Functional Brain Networks**|Haoyu Hu et.al.|[2405.18658v1](http://arxiv.org/abs/2405.18658v1)|null|
|**2024-05-28**|**DTR-Bench: An in silico Environment and Benchmark Platform for Reinforcement Learning Based Dynamic Treatment Regime**|Zhiyao Luo et.al.|[2405.18610v1](http://arxiv.org/abs/2405.18610v1)|[link](https://github.com/gilesluo/dtr-bench)|
|**2024-05-28**|**Low-rank finetuning for LLMs: A fairness perspective**|Saswat Das et.al.|[2405.18572v1](http://arxiv.org/abs/2405.18572v1)|null|
|**2024-05-28**|**Reinforcement Learning in Dynamic Treatment Regimes Needs Critical Reexamination**|Zhiyao Luo et.al.|[2405.18556v2](http://arxiv.org/abs/2405.18556v2)|[link](https://github.com/gilesluo/reassessdtr)|
|**2024-05-28**|**FAIIR: Building Toward A Conversational AI Agent Assistant for Youth Mental Health Service Provision**|Stephen Obadinma et.al.|[2405.18553v2](http://arxiv.org/abs/2405.18553v2)|null|
|**2024-05-28**|**An Empirical Analysis on Large Language Models in Debate Evaluation**|Xinyi Liu et.al.|[2406.00050v2](http://arxiv.org/abs/2406.00050v2)|null|
|**2024-05-28**|**Improved Emotional Alignment of AI and Humans: Human Ratings of Emotions Expressed by Stable Diffusion v1, DALL-E 2, and DALL-E 3**|James Derek Lomas et.al.|[2405.18510v1](http://arxiv.org/abs/2405.18510v1)|null|
|**2024-05-28**|**A Review and Implementation of Object Detection Models and Optimizations for Real-time Medical Mask Detection during the COVID-19 Pandemic**|Ioanna Gogou et.al.|[2405.18387v1](http://arxiv.org/abs/2405.18387v1)|[link](https://github.com/joangog/object-detection)|
|**2024-05-28**|**Brain Tumor Segmentation (BraTS) Challenge 2024: Meningioma Radiotherapy Planning Automated Segmentation**|Dominic LaBella et.al.|[2405.18383v1](http://arxiv.org/abs/2405.18383v1)|null|
|**2024-05-28**|**Intelligent Clinical Documentation: Harnessing Generative AI for Patient-Centric Clinical Note Generation**|Anjanava Biswas et.al.|[2405.18346v1](http://arxiv.org/abs/2405.18346v1)|null|
|**2024-05-28**|**Histopathology Based AI Model Predicts Anti-Angiogenic Therapy Response in Renal Cancer Clinical Trial**|Jay Jasti et.al.|[2405.18327v1](http://arxiv.org/abs/2405.18327v1)|null|
|**2024-05-28**|**Edinburgh Clinical NLP at MEDIQA-CORR 2024: Guiding Large Language Models with Hints**|Aryo Pradipta Gema et.al.|[2405.18028v1](http://arxiv.org/abs/2405.18028v1)|null|
|**2024-05-28**|**Towards Clinical AI Fairness: Filling Gaps in the Puzzle**|Mingxuan Liu et.al.|[2405.17921v1](http://arxiv.org/abs/2405.17921v1)|null|

#### Abstracts
##### **AWGUNET: Attention-Aided Wavelet Guided U-Net for Nuclei Segmentation in Histopathology Images**
2406.08425v1 by Ayush Roy, Payel Pramanik, Dmitrii Kaplun, Sergei Antonov, Ram Sarkar

Accurate nuclei segmentation in histopathological images is crucial for
cancer diagnosis. Automating this process offers valuable support to clinical
experts, as manual annotation is time-consuming and prone to human errors.
However, automating nuclei segmentation presents challenges due to uncertain
cell boundaries, intricate staining, and diverse structures. In this paper, we
present a segmentation approach that combines the U-Net architecture with a
DenseNet-121 backbone, harnessing the strengths of both to capture
comprehensive contextual and spatial information. Our model introduces the
Wavelet-guided channel attention module to enhance cell boundary delineation,
along with a learnable weighted global attention module for channel-specific
attention. The decoder module, composed of an upsample block and convolution
block, further refines segmentation in handling staining patterns. The
experimental results conducted on two publicly accessible histopathology
datasets, namely Monuseg and TNBC, underscore the superiority of our proposed
model, demonstrating its potential to advance histopathological image analysis
and cancer diagnosis. The code is made available at:
https://github.com/AyushRoy2001/AWGUNET.

摘要：組織病理學影像中精確的細胞核分割對於癌症診斷至關重要。自動化此程序可為臨床專家提供有價值的支援，因為手動註解既耗時又容易發生人為錯誤。然而，由於細胞邊界不確定、染色複雜且結構多樣，自動化細胞核分割會產生挑戰。在本文中，我們提出了一種分割方法，將 U-Net 架構與 DenseNet-121 主幹結合，利用兩者的優勢來擷取全面的上下文和空間資訊。我們的模型引入了小波導向通道注意模組，以增強細胞邊界的描繪，以及一個可學習的加權全局注意模組，用於特定通道的注意。解碼器模組由上採樣區塊和卷積區塊組成，進一步優化了處理染色模式的分割。在兩個公開可用的組織病理學資料集（即 Monuseg 和 TNBC）上進行的實驗結果，突顯了我們提出的模型的優越性，證明了其在推進組織病理學影像分析和癌症診斷方面的潛力。程式碼可在以下位置取得：https://github.com/AyushRoy2001/AWGUNET。

##### **2.5D Multi-view Averaging Diffusion Model for 3D Medical Image Translation: Application to Low-count PET Reconstruction with CT-less Attenuation Correction**
2406.08374v1 by Tianqi Chen, Jun Hou, Yinchi Zhou, Huidong Xie, Xiongchao Chen, Qiong Liu, Xueqi Guo, Menghua Xia, James S. Duncan, Chi Liu, Bo Zhou

Positron Emission Tomography (PET) is an important clinical imaging tool but
inevitably introduces radiation hazards to patients and healthcare providers.
Reducing the tracer injection dose and eliminating the CT acquisition for
attenuation correction can reduce the overall radiation dose, but often results
in PET with high noise and bias. Thus, it is desirable to develop 3D methods to
translate the non-attenuation-corrected low-dose PET (NAC-LDPET) into
attenuation-corrected standard-dose PET (AC-SDPET). Recently, diffusion models
have emerged as a new state-of-the-art deep learning method for image-to-image
translation, better than traditional CNN-based methods. However, due to the
high computation cost and memory burden, it is largely limited to 2D
applications. To address these challenges, we developed a novel 2.5D Multi-view
Averaging Diffusion Model (MADM) for 3D image-to-image translation with
application on NAC-LDPET to AC-SDPET translation. Specifically, MADM employs
separate diffusion models for axial, coronal, and sagittal views, whose outputs
are averaged in each sampling step to ensure the 3D generation quality from
multiple views. To accelerate the 3D sampling process, we also proposed a
strategy to use the CNN-based 3D generation as a prior for the diffusion model.
Our experimental results on human patient studies suggested that MADM can
generate high-quality 3D translation images, outperforming previous CNN-based
and Diffusion-based baseline methods.

摘要：正子發射斷層掃描 (PET) 是一種重要的臨床影像工具，但不可避免地會對患者和醫療保健提供者造成輻射危害。降低示蹤劑注射劑量並消除電腦斷層掃描以進行衰減校正可以降低整體輻射劑量，但通常會導致 PET 產生高雜訊和偏差。因此，開發 3D 方法將非衰減校正低劑量 PET (NAC-LDPET) 轉換為衰減校正標準劑量 PET (AC-SDPET) 是很重要的。最近，擴散模型已成為一種新的最先進的深度學習方法，用於影像轉換影像，優於傳統的基於 CNN 的方法。然而，由於高運算成本和記憶體負擔，它在很大程度上僅限於 2D 應用程式。為了應對這些挑戰，我們開發了一種新穎的 2.5D 多視圖平均擴散模型 (MADM)，用於 3D 影像轉換影像，並應用於 NAC-LDPET 轉換為 AC-SDPET。具體來說，MADM 為軸向、冠狀和矢狀視圖採用了單獨的擴散模型，其輸出在每個採樣步驟中取平均值，以確保從多個視圖中進行 3D 生成品質。為了加速 3D 採樣過程，我們還提出了一種策略，將基於 CNN 的 3D 生成用作擴散模型的先驗。我們在人體患者研究中得到的實驗結果表明，MADM 可以生成高品質的 3D 轉換影像，優於先前的基於 CNN 和基於擴散的基線方法。

##### **Making AI Intelligible: Philosophical Foundations**
2406.08134v1 by Herman Cappelen, Josh Dever

Can humans and artificial intelligences share concepts and communicate?
'Making AI Intelligible' shows that philosophical work on the metaphysics of
meaning can help answer these questions. Herman Cappelen and Josh Dever use the
externalist tradition in philosophy to create models of how AIs and humans can
understand each other. In doing so, they illustrate ways in which that
philosophical tradition can be improved.
  The questions addressed in the book are not only theoretically interesting,
but the answers have pressing practical implications. Many important decisions
about human life are now influenced by AI. In giving that power to AI, we
presuppose that AIs can track features of the world that we care about (for
example, creditworthiness, recidivism, cancer, and combatants). If AIs can
share our concepts, that will go some way towards justifying this reliance on
AI. This ground-breaking study offers insight into how to take some first steps
towards achieving Interpretable AI.

摘要：人類與人工智慧能共享概念並溝通嗎？
「讓人工智慧易於理解」一書表明，關於意義的形上學哲學著作有助於回答這些問題。赫爾曼·卡佩倫和喬希·德弗利用哲學中的外在主義傳統，建立了關於人工智慧和人類如何理解彼此的模型。在這樣做的過程中，他們說明了哲學傳統可以得到改善的方式。
書中探討的問題不僅在理論上很有趣，而且答案具有迫切的實際意義。許多關於人類生活的重要決定現在都受到人工智慧的影響。在將這種力量賦予人工智慧時，我們預設人工智慧可以追蹤我們關心的世界特徵（例如，信用評分、累犯率、癌症和戰鬥人員）。如果人工智慧能共享我們的概念，這將有助於證明依賴人工智慧的合理性。這項開創性的研究提供了如何採取一些第一步來實現可解釋人工智慧的見解。

##### **Graph Transductive Defense: a Two-Stage Defense for Graph Membership Inference Attacks**
2406.07917v1 by Peizhi Niu, Chao Pan, Siheng Chen, Olgica Milenkovic

Graph neural networks (GNNs) have become instrumental in diverse real-world
applications, offering powerful graph learning capabilities for tasks such as
social networks and medical data analysis. Despite their successes, GNNs are
vulnerable to adversarial attacks, including membership inference attacks
(MIA), which threaten privacy by identifying whether a record was part of the
model's training data. While existing research has explored MIA in GNNs under
graph inductive learning settings, the more common and challenging graph
transductive learning setting remains understudied in this context. This paper
addresses this gap and proposes an effective two-stage defense, Graph
Transductive Defense (GTD), tailored to graph transductive learning
characteristics. The gist of our approach is a combination of a train-test
alternate training schedule and flattening strategy, which successfully reduces
the difference between the training and testing loss distributions. Extensive
empirical results demonstrate the superior performance of our method (a
decrease in attack AUROC by $9.42\%$ and an increase in utility performance by
$18.08\%$ on average compared to LBP), highlighting its potential for seamless
integration into various classification models with minimal overhead.

摘要：圖形神經網路 (GNN) 已成為各種真實世界應用中不可或缺的工具，為社交網路和醫療數據分析等任務提供強大的圖形學習能力。儘管取得成功，GNN 仍容易受到對抗性攻擊，包括成員推論攻擊 (MIA)，這會透過辨識記錄是否為模型訓練資料的一部分來威脅隱私。雖然現有研究已探討圖形歸納學習設定下的 GNN 中的 MIA，但更常見且更具挑戰性的圖形轉導學習設定在此背景下仍未獲得充分研究。本文探討此差距，並提出一個有效的分兩階段防禦機制，圖形轉導防禦 (GTD)，專門針對圖形轉導學習特性量身打造。我們方法的要點是結合訓練測試交替訓練時程和扁平化策略，成功縮小訓練和測試損失分佈之間的差異。廣泛的實證結果證明我們方法的優異效能（與 LBP 相比，攻擊 AUROC 減少 9.42%，效用效能平均增加 18.08%），突顯其在各種分類模型中無縫整合的潛力，且開銷極小。

##### **Cognitive Insights Across Languages: Enhancing Multimodal Interview Analysis**
2406.07542v1 by David Ortiz-Perez, Jose Garcia-Rodriguez, David Tomás

Cognitive decline is a natural process that occurs as individuals age. Early
diagnosis of anomalous decline is crucial for initiating professional treatment
that can enhance the quality of life of those affected. To address this issue,
we propose a multimodal model capable of predicting Mild Cognitive Impairment
and cognitive scores. The TAUKADIAL dataset is used to conduct the evaluation,
which comprises audio recordings of clinical interviews. The proposed model
demonstrates the ability to transcribe and differentiate between languages used
in the interviews. Subsequently, the model extracts audio and text features,
combining them into a multimodal architecture to achieve robust and generalized
results. Our approach involves in-depth research to implement various features
obtained from the proposed modalities.

摘要：認知能力下降是個人隨著年齡增長而發生的自然過程。及早診斷異常下降對於啟動專業治療至關重要，可提升受影響者的生活品質。為了解決此問題，我們提出一個多模態模型，能夠預測輕度認知障礙和認知評分。TAUKADIAL 資料集用於進行評估，其中包含臨床訪談的音訊錄製。所提出的模型展示了轉錄和區分訪談中所用語言的能力。隨後，模型會擷取音訊和文字特徵，將它們組合成多模態架構，以達成穩健且廣泛的結果。我們的做法涉及深入研究，以實作從所提出的模態中取得的各種特徵。

##### **CADS: A Systematic Literature Review on the Challenges of Abstractive Dialogue Summarization**
2406.07494v2 by Frederic Kirstein, Jan Philip Wahle, Bela Gipp, Terry Ruas

Abstractive dialogue summarization is the task of distilling conversations
into informative and concise summaries. Although reviews have been conducted on
this topic, there is a lack of comprehensive work detailing the challenges of
dialogue summarization, unifying the differing understanding of the task, and
aligning proposed techniques, datasets, and evaluation metrics with the
challenges. This article summarizes the research on Transformer-based
abstractive summarization for English dialogues by systematically reviewing
1262 unique research papers published between 2019 and 2024, relying on the
Semantic Scholar and DBLP databases. We cover the main challenges present in
dialog summarization (i.e., language, structure, comprehension, speaker,
salience, and factuality) and link them to corresponding techniques such as
graph-based approaches, additional training tasks, and planning strategies,
which typically overly rely on BART-based encoder-decoder models. We find that
while some challenges, like language, have seen considerable progress, mainly
due to training methods, others, such as comprehension, factuality, and
salience, remain difficult and hold significant research opportunities. We
investigate how these approaches are typically assessed, covering the datasets
for the subdomains of dialogue (e.g., meeting, medical), the established
automatic metrics and human evaluation approaches for assessing scores and
annotator agreement. We observe that only a few datasets span across all
subdomains. The ROUGE metric is the most used, while human evaluation is
frequently reported without sufficient detail on inner-annotator agreement and
annotation guidelines. Additionally, we discuss the possible implications of
the recently explored large language models and conclude that despite a
potential shift in relevance and difficulty, our described challenge taxonomy
remains relevant.

摘要：<paragraph>抽象式對話摘要是將對話濃縮成具有資訊性且簡潔的摘要。儘管已針對此主題進行審查，但仍缺乏詳細說明對話摘要挑戰、統一對任務的不同理解，以及將建議的技術、資料集和評估指標與挑戰相符的全面性研究。本文透過系統性地檢閱 2019 年至 2024 年間發表的 1262 篇獨特研究論文，依賴語義學者和 DBLP 資料庫，總結了基於 Transformer 的英語對話抽象式摘要的研究。我們涵蓋對話摘要中出現的主要挑戰（即語言、結構、理解、說話者、顯著性和真實性），並將它們連結到對應的技術，例如基於圖形的方法、額外的訓練任務和規劃策略，這些策略通常過度依賴於基於 BART 的編碼器-解碼器模型。我們發現，雖然語言等一些挑戰在很大程度上取得了進展，這主要是由於訓練方法，但其他挑戰，例如理解、真實性和顯著性，仍然很困難，並具有重大的研究機會。我們探討了通常如何評估這些方法，涵蓋了對話子領域（例如會議、醫療）的資料集，既定的自動化指標和用於評估分數和註解者一致性的評估方法。我們觀察到，只有少數資料集跨越所有子領域。ROUGE 指標使用最頻繁，而人類評估通常在沒有足夠的註解者內部一致性和註解指南的詳細資訊下進行報告。此外，我們討論了近期探索的大語言模型的可能影響，並得出結論，儘管相關性和難度可能發生轉變，但我們所描述的挑戰分類法仍然相關。</paragraph>

##### **Benchmarking and Boosting Radiology Report Generation for 3D High-Resolution Medical Images**
2406.07146v2 by Che Liu, Zhongwei Wan, Yuqi Wang, Hui Shen, Haozhe Wang, Kangyu Zheng, Mi Zhang, Rossella Arcucci

Automatic radiology report generation can significantly benefit the
labor-intensive process of report writing by radiologists, especially for 3D
radiographs like CT scans, which are crucial for broad clinical diagnostics yet
underexplored compared to 2D radiographs. Existing methods often handle 3D
volumes either slice-wise or with aggressive downsampling due to current GPU
memory limitations, which results in a loss of the inherent 3D nature and
critical details. To overcome these issues, we introduce a novel framework that
efficiently and effectively generates radiology reports for high-resolution
(HR) 3D volumes, based on large language models (LLMs). Specifically, our
framework utilizes low-resolution (LR) visual tokens as queries to mine
information from HR tokens, preserving detailed HR information while reducing
computational costs by only processing HR informed LR visual queries. Further
benefiting the field, we curate and release BIMCV-RG, a new dataset with 5,328
HR 3D volumes and paired reports, establishing the first benchmarks for report
generation from 3D HR medical images. Our method consistently surpasses
existing methods on this benchmark across three different settings:
normal-resolution, high-resolution inputs, and zero-shot domain transfer, all
at an acceptable computational cost, trainable on a single A100-80G.

摘要：自動放射線報告生成可以大幅降低放射科醫師撰寫報告的勞力密集程序，特別是對於 3D 射線照片（例如電腦斷層掃描），這對廣泛的臨床診斷至關重要，但與 2D 射線照片相比，仍未被充分探索。現有方法通常會以切片方式或透過激進的降採樣來處理 3D 體積，這是因為目前的 GPU 記憶體有限，這會導致固有的 3D 特性和關鍵細節遺失。為了克服這些問題，我們引入了一個新架構，可有效率且有效地為高解析度 (HR) 3D 體積生成放射線報告，其基礎是大語言模型 (LLM)。具體來說，我們的架構利用低解析度 (LR) 視覺標記作為查詢，從 HR 標記中挖掘資訊，同時保留詳細的 HR 資訊，並透過僅處理 HR 資訊的 LR 視覺查詢來降低運算成本。我們整理並發布 BIMCV-RG，一個包含 5,328 個 HR 3D 體積和配對報告的新資料集，進一步造福這個領域，為從 3D HR 醫學影像生成報告建立了第一個基準。我們的模型在三個不同的設定中持續超越現有的模型：正常解析度、高解析度輸入和零次學習領域轉移，所有設定的運算成本都在可接受的範圍內，且可以在單個 A100-80G 上訓練。

##### **Unlocking the Potential of the Metaverse for Innovative and Immersive Digital Care**
2406.07114v1 by Fatemeh Ebrahimzadeh, Ramin Safa

The Metaverse, a persistent, immersive virtual environment, has the immense
potential to revolutionize healthcare by transforming patient care, medical
education, and research. This paper explores the applications, benefits, and
challenges associated with this transformative technology, highlighting its
ability to improve patient engagement, communication, access to information,
and health outcomes. The paper also examines how the analysis of Metaverse data
using machine learning techniques can unlock insights to further enhance
healthcare applications. The discussion summarizes key findings, analyzes the
significance and practical implications of Metaverse integration, and
identifies areas for future research. It underscores the role of major tech
companies in developing Metaverse-based solutions and the importance of
addressing emerging opportunities and challenges to unlock the transformative
potential of this technology in healthcare. The paper concludes by emphasizing
the need for collaboration between stakeholders to ensure the ethical and
effective implementation of these technologies, ultimately leading to a more
accessible, personalized, and efficient healthcare system.

摘要：元宇宙，一個持續性的沉浸式虛擬環境，具有通過轉變患者照護、醫療教育和研究來徹底改變醫療保健的巨大潛力。本文探討了與這項變革性技術相關的應用、優點和挑戰，重點說明其改善患者參與度、溝通、獲取資訊和健康結果的能力。本文還探討了如何使用機器學習技術分析元宇宙資料，以解鎖見解，進一步增強醫療保健應用。討論總結了主要發現，分析了元宇宙整合的意義和實際影響，並找出未來研究領域。它強調了大型科技公司在開發基於元宇宙的解決方案中的作用，以及解決新興機會和挑戰以釋放這項技術在醫療保健中的轉型潛力的重要性。本文最後強調了利益相關者之間合作的必要性，以確保這些技術的道德和有效實施，最終建立一個更易於使用、更個性化和更有效的醫療保健系統。

##### **Heterogeneous Learning Rate Scheduling for Neural Architecture Search on Long-Tailed Datasets**
2406.07028v1 by Chenxia Tang

In this paper, we attempt to address the challenge of applying Neural
Architecture Search (NAS) algorithms, specifically the Differentiable
Architecture Search (DARTS), to long-tailed datasets where class distribution
is highly imbalanced. We observe that traditional re-sampling and re-weighting
techniques, which are effective in standard classification tasks, lead to
performance degradation when combined with DARTS. To mitigate this, we propose
a novel adaptive learning rate scheduling strategy tailored for the
architecture parameters of DARTS when integrated with the Bilateral Branch
Network (BBN) for handling imbalanced datasets. Our approach dynamically
adjusts the learning rate of the architecture parameters based on the training
epoch, preventing the disruption of well-trained representations in the later
stages of training. Additionally, we explore the impact of branch mixing
factors on the algorithm's performance. Through extensive experiments on the
CIFAR-10 dataset with an artificially induced long-tailed distribution, we
demonstrate that our method achieves comparable accuracy to using DARTS alone.
And the experiment results suggest that re-sampling methods inherently harm the
performance of the DARTS algorithm. Our findings highlight the importance of
careful data augment when applying DNAS to imbalanced learning scenarios.

摘要：<paragraph>在本文中，我们尝试解决将神经架构搜索 (NAS) 算法（特别是可微架构搜索 (DARTS)）应用于长尾数据集的挑战，其中类分布高度不平衡。我们观察到传统的重新采样和重新加权技术（在标准分类任务中有效）与 DARTS 结合使用时会导致性能下降。为了缓解这个问题，我们提出了一种新的自适应学习率调度策略，该策略针对 DARTS 的架构参数量身定制，并与双边分支网络 (BBN) 集成以处理不平衡数据集。我们的方法根据训练时期动态调整架构参数的学习率，防止在训练后期破坏训练良好的表示。此外，我们探讨了分支混合因子对算法性能的影响。通过在人工诱导的长尾分布的 CIFAR-10 数据集上进行广泛的实验，我们证明了我们的方法与单独使用 DARTS 实现了相当的准确性。实验结果表明，重新采样方法本质上会损害 DARTS 算法的性能。我们的研究结果突出了在将 DNAS 应用于不平衡学习场景时仔细进行数据扩充的重要性。</paragraph>

##### **Taxes Are All You Need: Integration of Taxonomical Hierarchy Relationships into the Contrastive Loss**
2406.06848v1 by Kiran Kokilepersaud, Yavuz Yarici, Mohit Prabhushankar, Ghassan AlRegib

In this work, we propose a novel supervised contrastive loss that enables the
integration of taxonomic hierarchy information during the representation
learning process. A supervised contrastive loss operates by enforcing that
images with the same class label (positive samples) project closer to each
other than images with differing class labels (negative samples). The advantage
of this approach is that it directly penalizes the structure of the
representation space itself. This enables greater flexibility with respect to
encoding semantic concepts. However, the standard supervised contrastive loss
only enforces semantic structure based on the downstream task (i.e. the class
label). In reality, the class label is only one level of a \emph{hierarchy of
different semantic relationships known as a taxonomy}. For example, the class
label is oftentimes the species of an animal, but between different classes
there are higher order relationships such as all animals with wings being
``birds". We show that by explicitly accounting for these relationships with a
weighting penalty in the contrastive loss we can out-perform the supervised
contrastive loss. Additionally, we demonstrate the adaptability of the notion
of a taxonomy by integrating our loss into medical and noise-based settings
that show performance improvements by as much as 7%.

摘要：在這項工作中，我們提出了一種新穎的監督對比損失，它可以在表示學習過程中整合分類層級資訊。監督對比損失透過強制具有相同類別標籤（正樣本）的影像比具有不同類別標籤（負樣本）的影像更接近彼此來運作。這種方法的優點是它直接懲罰表示空間本身的結構。這使得在編碼語意概念方面具有更大的靈活性。然而，標準的監督對比損失僅根據下游任務（即類別標籤）來強制語意結構。實際上，類別標籤只是稱為分類法的一種不同語意關係層級中的其中一層。例如，類別標籤通常是動物的物種，但在不同的類別之間存在更高階的關係，例如所有有翅膀的動物都是「鳥類」。我們表明，透過在對比損失中使用加權懲罰來明確說明這些關係，我們可以優於監督對比損失。此外，我們展示了分類法概念的適應性，方法是將我們的損失整合到醫療和基於雜訊的設定中，這些設定顯示效能提升了 7%。

##### **SciRIFF: A Resource to Enhance Language Model Instruction-Following over Scientific Literature**
2406.07835v1 by David Wadden, Kejian Shi, Jacob Morrison, Aakanksha Naik, Shruti Singh, Nitzan Barzilay, Kyle Lo, Tom Hope, Luca Soldaini, Shannon Zejiang Shen, Doug Downey, Hannaneh Hajishirzi, Arman Cohan

We present SciRIFF (Scientific Resource for Instruction-Following and
Finetuning), a dataset of 137K instruction-following demonstrations for 54
tasks covering five essential scientific literature understanding capabilities:
information extraction, summarization, question answering, claim verification,
and classification. SciRIFF demonstrations are notable for their long input
contexts, detailed task specifications, and complex structured outputs. While
instruction-following resources are available in specific domains such as
clinical medicine and chemistry, SciRIFF is the first dataset focused on
extracting and synthesizing information from research literature across a wide
range of scientific fields. To demonstrate the utility of SciRIFF, we develop a
sample-efficient strategy to adapt a general instruction-following model for
science by performing additional finetuning on a mix of general-domain and
SciRIFF demonstrations. In evaluations on nine held-out scientific tasks, our
model -- called SciTulu -- improves over a strong LLM baseline by 28.1% and
6.5% at the 7B and 70B scales respectively, while maintaining general
instruction-following performance within 2% of the baseline. We are optimistic
that SciRIFF will facilitate the development and evaluation of LLMs to help
researchers navigate the ever-growing body of scientific literature. We release
our dataset, model checkpoints, and data processing and evaluation code to
enable further research.

摘要：<paragraph>我們提出 SciRIFF（科學資源，用於遵循說明和微調），這是一個包含 137K 遵循說明的示範資料集，涵蓋 54 項任務，涵蓋五項重要的科學文獻理解能力：資訊擷取、摘要、問答、聲明驗證和分類。SciRIFF 示範以其長的輸入內容、詳細的任務規格和複雜的結構化輸出而聞名。雖然特定領域（例如臨床醫學和化學）有遵循說明的資源，但 SciRIFF 是第一個專注於從各種科學領域的研究文獻中提取和綜合資訊的資料集。為了展示 SciRIFF 的效用，我們制定了一種樣本有效率的策略，透過在一般領域和 SciRIFF 示範的組合上執行額外的微調，來調整一般遵循說明的模型以適應科學。在九項已暫停的科學任務的評估中，我們的模型（稱為 SciTulu）在 7B 和 70B 規模分別比強大的 LLM 基準提高了 28.1% 和 6.5%，同時將一般遵循說明的效能維持在基準的 2% 以內。我們樂觀地認為 SciRIFF 將有助於開發和評估 LLM，以幫助研究人員瀏覽不斷增長的科學文獻。我們釋出我們的資料集、模型檢查點，以及資料處理和評估程式碼，以利進一步的研究。</paragraph>

##### **BTS: Bridging Text and Sound Modalities for Metadata-Aided Respiratory Sound Classification**
2406.06786v1 by June-Woo Kim, Miika Toikkanen, Yera Choi, Seoung-Eun Moon, Ho-Young Jung

Respiratory sound classification (RSC) is challenging due to varied acoustic
signatures, primarily influenced by patient demographics and recording
environments. To address this issue, we introduce a text-audio multimodal model
that utilizes metadata of respiratory sounds, which provides useful
complementary information for RSC. Specifically, we fine-tune a pretrained
text-audio multimodal model using free-text descriptions derived from the sound
samples' metadata which includes the gender and age of patients, type of
recording devices, and recording location on the patient's body. Our method
achieves state-of-the-art performance on the ICBHI dataset, surpassing the
previous best result by a notable margin of 1.17%. This result validates the
effectiveness of leveraging metadata and respiratory sound samples in enhancing
RSC performance. Additionally, we investigate the model performance in the case
where metadata is partially unavailable, which may occur in real-world clinical
setting.

摘要：呼吸音分類 (RSC) 由於聲學特徵變化多端，主要受患者人口統計資料及錄音環境影響，因此具有挑戰性。為了解決此問題，我們引入一個文字音訊多模態模型，其利用呼吸音的元資料，提供有用的補充資訊以進行 RSC。具體來說，我們使用從音訊範例的元資料衍生的自由文字描述，微調一個預訓練的文字音訊多模態模型，其中包括患者的性別和年齡、錄音裝置類型，以及患者身體上的錄音位置。我們的模型在 ICBHI 資料集上達到最先進的效能，以 1.17% 的顯著幅度超越先前的最佳結果。此結果驗證了利用元資料和呼吸音範例來提升 RSC 效能的有效性。此外，我們探討模型在元資料部分不可用的情況下的效能，這種情況可能會發生在真實世界的臨床環境中。

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

摘要：慢性腎臟病（CKD）是一種廣泛的慢性疾病，沒有已知的最終療法且發病率很高。研究表明，進行性慢性腎臟病（CKD）是一種異質性疾病，會顯著影響腎臟結構和功能，最終導致腎衰竭。隨著時間的推移，慢性腎臟病已從影響少數人的致命疾病轉變為一種嚴重程度不同的常見疾病。本研究的目標是使用集成學習和可解釋的 AI 進行早期預後和 CKD 檢測，並視覺化主導特徵、特徵分數和表現出的值。為此，提出了一種 AI 驅動的預測分析方法，以幫助臨床醫生為個別患者開具生活方式修改建議，以降低這種疾病的進展速度。我們的數據集是從 CKD 患者和健康受試者的身體生命體徵中收集的，以準確開發我們提出的 AI 驅動的解決方案。在這方面，提供了血液和尿液檢測結果，並應用基於集成樹的機器學習模型來預測未發現的 CKD 病例。我們的研究結果經過與腎臟科醫生的長期諮詢後得到驗證。我們的實驗和解釋結果與各種醫療保健領域中現有的可解釋 AI 應用進行了比較，包括 CKD。比較表明，我們開發的 AI 模型，特別是隨機森林模型，已經確定了比 XgBoost 更多作為重要貢獻者的特徵。可解釋性 (I) 衡量重要特徵與掩蓋特徵的比率，表明我們的 XgBoost 模型在這個指標中獲得了更高的分數，特別是 98% 的保真度，並且在 FII 指數中自然高於競爭模型。

##### **Merlin: A Vision Language Foundation Model for 3D Computed Tomography**
2406.06512v1 by Louis Blankemeier, Joseph Paul Cohen, Ashwin Kumar, Dave Van Veen, Syed Jamal Safdar Gardezi, Magdalini Paschali, Zhihong Chen, Jean-Benoit Delbrouck, Eduardo Reis, Cesar Truyts, Christian Bluethgen, Malte Engmann Kjeldskov Jensen, Sophie Ostmeier, Maya Varma, Jeya Maria Jose Valanarasu, Zhongnan Fang, Zepeng Huo, Zaid Nabulsi, Diego Ardila, Wei-Hung Weng, Edson Amaro Junior, Neera Ahuja, Jason Fries, Nigam H. Shah, Andrew Johnston, Robert D. Boutin, Andrew Wentland, Curtis P. Langlotz, Jason Hom, Sergios Gatidis, Akshay S. Chaudhari

Over 85 million computed tomography (CT) scans are performed annually in the
US, of which approximately one quarter focus on the abdomen. Given the current
radiologist shortage, there is a large impetus to use artificial intelligence
to alleviate the burden of interpreting these complex imaging studies. Prior
state-of-the-art approaches for automated medical image interpretation leverage
vision language models (VLMs). However, current medical VLMs are generally
limited to 2D images and short reports, and do not leverage electronic health
record (EHR) data for supervision. We introduce Merlin - a 3D VLM that we train
using paired CT scans (6+ million images from 15,331 CTs), EHR diagnosis codes
(1.8+ million codes), and radiology reports (6+ million tokens). We evaluate
Merlin on 6 task types and 752 individual tasks. The non-adapted
(off-the-shelf) tasks include zero-shot findings classification (31 findings),
phenotype classification (692 phenotypes), and zero-shot cross-modal retrieval
(image to findings and image to impressions), while model adapted tasks include
5-year disease prediction (6 diseases), radiology report generation, and 3D
semantic segmentation (20 organs). We perform internal validation on a test set
of 5,137 CTs, and external validation on 7,000 clinical CTs and on two public
CT datasets (VerSe, TotalSegmentator). Beyond these clinically-relevant
evaluations, we assess the efficacy of various network architectures and
training strategies to depict that Merlin has favorable performance to existing
task-specific baselines. We derive data scaling laws to empirically assess
training data needs for requisite downstream task performance. Furthermore,
unlike conventional VLMs that require hundreds of GPUs for training, we perform
all training on a single GPU.

摘要：<paragraph>美國每年執行超過 8500 萬次電腦斷層掃描 (CT)，其中約四分之一針對腹部。鑑於目前放射科醫師短缺，因此有很大的動力使用人工智慧來減輕詮釋這些複雜影像研究的負擔。先前自動化醫學影像詮釋的最新方法利用視覺語言模型 (VLM)。然而，目前的醫學 VLM 通常僅限於 2D 影像和簡短報告，而且不會利用電子健康紀錄 (EHR) 資料進行監督。我們介紹 Merlin，這是一個 3D VLM，我們使用配對的 CT 掃描（來自 15,331 個 CT 的 600 多萬張影像）、EHR 診斷碼（180 多萬個碼）和放射科報告（600 多萬個代碼）來訓練它。我們在 6 個任務類型和 752 個個別任務上評估 Merlin。非適應型（現成的）任務包括零次學習結果分類（31 個結果）、表型分類（692 個表型）和零次學習跨模態檢索（影像到結果和影像到印象），而模型適應任務包括 5 年疾病預測（6 種疾病）、放射科報告產生和 3D 語意分割（20 個器官）。我們在 5,137 個 CT 的測試集上執行內部驗證，並在 7,000 個臨床 CT 和兩個公開 CT 資料集（VerSe、TotalSegmentator）上執行外部驗證。除了這些與臨床相關的評估之外，我們還評估各種網路架構和訓練策略的效能，以說明 Merlin 在現有的特定任務基線上具有良好的效能。我們推導出資料擴充法則，以根據經驗評估下游任務效能所需的訓練資料需求。此外，與需要數百個 GPU 才能進行訓練的傳統 VLM 不同，我們在單一 GPU 上執行所有訓練。</paragraph>

##### **Towards a Personal Health Large Language Model**
2406.06474v1 by Justin Cosentino, Anastasiya Belyaeva, Xin Liu, Nicholas A. Furlotte, Zhun Yang, Chace Lee, Erik Schenck, Yojan Patel, Jian Cui, Logan Douglas Schneider, Robby Bryant, Ryan G. Gomes, Allen Jiang, Roy Lee, Yun Liu, Javier Perez, Jameson K. Rogers, Cathy Speed, Shyam Tailor, Megan Walker, Jeffrey Yu, Tim Althoff, Conor Heneghan, John Hernandez, Mark Malhotra, Leor Stern, Yossi Matias, Greg S. Corrado, Shwetak Patel, Shravya Shetty, Jiening Zhan, Shruthi Prabhakara, Daniel McDuff, Cory Y. McLean

In health, most large language model (LLM) research has focused on clinical
tasks. However, mobile and wearable devices, which are rarely integrated into
such tasks, provide rich, longitudinal data for personal health monitoring.
Here we present Personal Health Large Language Model (PH-LLM), fine-tuned from
Gemini for understanding and reasoning over numerical time-series personal
health data. We created and curated three datasets that test 1) production of
personalized insights and recommendations from sleep patterns, physical
activity, and physiological responses, 2) expert domain knowledge, and 3)
prediction of self-reported sleep outcomes. For the first task we designed 857
case studies in collaboration with domain experts to assess real-world
scenarios in sleep and fitness. Through comprehensive evaluation of
domain-specific rubrics, we observed that Gemini Ultra 1.0 and PH-LLM are not
statistically different from expert performance in fitness and, while experts
remain superior for sleep, fine-tuning PH-LLM provided significant improvements
in using relevant domain knowledge and personalizing information for sleep
insights. We evaluated PH-LLM domain knowledge using multiple choice sleep
medicine and fitness examinations. PH-LLM achieved 79% on sleep and 88% on
fitness, exceeding average scores from a sample of human experts. Finally, we
trained PH-LLM to predict self-reported sleep quality outcomes from textual and
multimodal encoding representations of wearable data, and demonstrate that
multimodal encoding is required to match performance of specialized
discriminative models. Although further development and evaluation are
necessary in the safety-critical personal health domain, these results
demonstrate both the broad knowledge and capabilities of Gemini models and the
benefit of contextualizing physiological data for personal health applications
as done with PH-LLM.

摘要：在健康領域，大多數大型語言模型 (LLM) 研究都專注於臨床任務。然而，行動裝置和穿戴式裝置很少整合到此類任務中，但它們會提供豐富的縱向資料，用於個人健康監控。在這裡，我們提出個人健康大型語言模型 (PH-LLM)，經過 Gemini 微調，用於理解和推理數值時間序列個人健康資料。我們建立並策劃了三個測試資料集，用於測試 1) 從睡眠模式、身體活動和生理反應中產生個人化見解和建議，2) 專家領域知識，以及 3) 預測自我報告的睡眠結果。對於第一個任務，我們與領域專家合作設計了 857 個案例研究，以評估睡眠和健身的真實情況。透過對特定領域評分標準的全面評估，我們觀察到 Gemini Ultra 1.0 和 PH-LLM 在健身方面的表現與專家表現沒有統計學差異，而專家在睡眠方面的表現仍然較佳，但微調 PH-LLM 在使用相關領域知識和個人化睡眠見解資訊方面提供了顯著改進。我們使用多選題睡眠醫學和健身檢查評估 PH-LLM 領域知識。PH-LLM 在睡眠方面達到 79%，在健身方面達到 88%，超過了部分人類專家的平均分數。最後，我們訓練 PH-LLM 從可穿戴資料的文字和多模態編碼表示中預測自我報告的睡眠品質結果，並證明多模態編碼對於匹配特殊辨別模型的效能是必要的。儘管在安全關鍵的個人健康領域中需要進一步的開發和評估，但這些結果證明了 Gemini 模型的廣泛知識和功能，以及使用 PH-LLM 對生理資料進行情境化以用於個人健康應用程式的優點。

##### **Transforming Wearable Data into Health Insights using Large Language Model Agents**
2406.06464v2 by Mike A. Merrill, Akshay Paruchuri, Naghmeh Rezaei, Geza Kovacs, Javier Perez, Yun Liu, Erik Schenck, Nova Hammerquist, Jake Sunshine, Shyam Tailor, Kumar Ayush, Hao-Wei Su, Qian He, Cory Y. McLean, Mark Malhotra, Shwetak Patel, Jiening Zhan, Tim Althoff, Daniel McDuff, Xin Liu

Despite the proliferation of wearable health trackers and the importance of
sleep and exercise to health, deriving actionable personalized insights from
wearable data remains a challenge because doing so requires non-trivial
open-ended analysis of these data. The recent rise of large language model
(LLM) agents, which can use tools to reason about and interact with the world,
presents a promising opportunity to enable such personalized analysis at scale.
Yet, the application of LLM agents in analyzing personal health is still
largely untapped. In this paper, we introduce the Personal Health Insights
Agent (PHIA), an agent system that leverages state-of-the-art code generation
and information retrieval tools to analyze and interpret behavioral health data
from wearables. We curate two benchmark question-answering datasets of over
4000 health insights questions. Based on 650 hours of human and expert
evaluation we find that PHIA can accurately address over 84% of factual
numerical questions and more than 83% of crowd-sourced open-ended questions.
This work has implications for advancing behavioral health across the
population, potentially enabling individuals to interpret their own wearable
data, and paving the way for a new era of accessible, personalized wellness
regimens that are informed by data-driven insights.

摘要：儘管穿戴式健康追蹤器大量普及，且睡眠和運動對健康至關重要，但從穿戴式資料中衍生出可操作的個人化見解仍然是一項挑戰，因為這樣做需要對這些資料進行非平凡的開放式分析。大型語言模型 (LLM) 代理程式近來崛起，它可以使用工具對世界進行推理和互動，提供了大規模啟用此類個人化分析的絕佳機會。然而，LLM 代理程式在分析個人健康方面的應用仍未得到充分開發。在本文中，我們介紹了個人健康見解代理程式 (PHIA)，這是一個代理系統，它利用最先進的程式碼生成和資訊檢索工具來分析和詮釋來自穿戴式裝置的行為健康資料。我們整理了兩個基准問答資料集，其中包含超過 4000 個健康見解問題。根據 650 小時的人類和專家評估，我們發現 PHIA 能夠準確回答超過 84% 的事實性數字問題和超過 83% 的群眾外包開放式問題。這項工作對促進全體人口的行為健康具有影響，潛在地使個人能夠詮釋自己的穿戴式資料，並為一個由資料驅動的見解所告知的可存取、個人化健康養生法的新時代鋪路。

##### **A Large Language Model Pipeline for Breast Cancer Oncology**
2406.06455v1 by Tristen Pool, Dennis Trujillo

Large language models (LLMs) have demonstrated potential in the innovation of
many disciplines. However, how they can best be developed for oncology remains
underdeveloped. State-of-the-art OpenAI models were fine-tuned on a clinical
dataset and clinical guidelines text corpus for two important cancer treatment
factors, adjuvant radiation therapy and chemotherapy, using a novel Langchain
prompt engineering pipeline. A high accuracy (0.85+) was achieved in the
classification of adjuvant radiation therapy and chemotherapy for breast cancer
patients. Furthermore, a confidence interval was formed from observational data
on the quality of treatment from human oncologists to estimate the proportion
of scenarios in which the model must outperform the original oncologist in its
treatment prediction to be a better solution overall as 8.2% to 13.3%. Due to
indeterminacy in the outcomes of cancer treatment decisions, future
investigation, potentially a clinical trial, would be required to determine if
this threshold was met by the models. Nevertheless, with 85% of U.S. cancer
patients receiving treatment at local community facilities, these kinds of
models could play an important part in expanding access to quality care with
outcomes that lie, at minimum, close to a human oncologist.

摘要：大型語言模型 (LLM) 已在許多領域的創新中展現其潛力。然而，如何才能最佳地開發它們以用於腫瘤學仍處於未開發狀態。最先進的 OpenAI 模型針對臨床資料集和臨床指南文字語料庫進行微調，以針對兩個重要的癌症治療因素，輔助放射治療和化療，使用創新的 Langchain 提示工程管道。在乳癌患者的輔助放射治療和化療分類中，達到了很高的準確度 (0.85+)。此外，根據人類腫瘤學家對治療品質的觀察資料，形成了一個信心區間，以估計在模型必須在其治療預測中優於原始腫瘤學家的情況下，作為整體更好的解決方案的比例，為 8.2% 至 13.3%。由於癌症治療決策結果的不確定性，未來的調查（可能是臨床試驗）將被要求確定模型是否達到此閾值。儘管如此，由於 85% 的美國癌症患者在當地社區設施接受治療，這些類型的模型可以在擴大獲得品質照護的機會中發揮重要作用，其結果至少接近人類腫瘤學家。

##### **Language Models are Alignable Decision-Makers: Dataset and Application to the Medical Triage Domain**
2406.06435v1 by Brian Hu, Bill Ray, Alice Leung, Amy Summerville, David Joy, Christopher Funk, Arslan Basharat

In difficult decision-making scenarios, it is common to have conflicting
opinions among expert human decision-makers as there may not be a single right
answer. Such decisions may be guided by different attributes that can be used
to characterize an individual's decision. We introduce a novel dataset for
medical triage decision-making, labeled with a set of decision-maker attributes
(DMAs). This dataset consists of 62 scenarios, covering six different DMAs,
including ethical principles such as fairness and moral desert. We present a
novel software framework for human-aligned decision-making by utilizing these
DMAs, paving the way for trustworthy AI with better guardrails. Specifically,
we demonstrate how large language models (LLMs) can serve as ethical
decision-makers, and how their decisions can be aligned to different DMAs using
zero-shot prompting. Our experiments focus on different open-source models with
varying sizes and training techniques, such as Falcon, Mistral, and Llama 2.
Finally, we also introduce a new form of weighted self-consistency that
improves the overall quantified performance. Our results provide new research
directions in the use of LLMs as alignable decision-makers. The dataset and
open-source software are publicly available at:
https://github.com/ITM-Kitware/llm-alignable-dm.

摘要：在困難的決策情境中，專家人類決策者之間產生相互衝突的意見是很常見的，因為可能沒有單一的正確答案。此類決策可能受到用於描述個人決策的不同屬性的指導。我們引入了一個新穎的醫療分流決策制定資料集，並標記了一組決策者屬性 (DMA)。此資料集包含 62 個情境，涵蓋六個不同的 DMA，包括公平性和道德沙漠等道德原則。我們提出了一個新穎的軟體架構，用於透過利用這些 DMA 進行與人類一致的決策制定，為具有更好護欄的值得信賴的 AI 鋪平道路。具體來說，我們展示了大型語言模型 (LLM) 如何作為道德決策者，以及如何使用零次提示將其決策與不同的 DMA 對齊。我們的實驗重點關注具有不同大小和訓練技術的不同開源模型，例如 Falcon、Mistral 和 Llama 2。最後，我們還引入了一種新的加權自一致性形式，它改進了整體量化效能。我們的結果為 LLM 作為可對齊決策者的使用提供了新的研究方向。資料集和開源軟體可在以下位置公開取得：
https://github.com/ITM-Kitware/llm-alignable-dm。

##### **Improving Deep Learning-based Automatic Cranial Defect Reconstruction by Heavy Data Augmentation: From Image Registration to Latent Diffusion Models**
2406.06372v1 by Marek Wodzinski, Kamil Kwarciak, Mateusz Daniol, Daria Hemmerling

Modeling and manufacturing of personalized cranial implants are important
research areas that may decrease the waiting time for patients suffering from
cranial damage. The modeling of personalized implants may be partially
automated by the use of deep learning-based methods. However, this task suffers
from difficulties with generalizability into data from previously unseen
distributions that make it difficult to use the research outcomes in real
clinical settings. Due to difficulties with acquiring ground-truth annotations,
different techniques to improve the heterogeneity of datasets used for training
the deep networks have to be considered and introduced. In this work, we
present a large-scale study of several augmentation techniques, varying from
classical geometric transformations, image registration, variational
autoencoders, and generative adversarial networks, to the most recent advances
in latent diffusion models. We show that the use of heavy data augmentation
significantly increases both the quantitative and qualitative outcomes,
resulting in an average Dice Score above 0.94 for the SkullBreak and above 0.96
for the SkullFix datasets. Moreover, we show that the synthetically augmented
network successfully reconstructs real clinical defects. The work is a
considerable contribution to the field of artificial intelligence in the
automatic modeling of personalized cranial implants.

摘要：客製化顱骨植入物的建模和製造是重要的研究領域，可能會縮短遭受顱骨損傷患者的等待時間。客製化植入物的建模可以透過使用基於深度學習的方法來部分自動化。然而，此任務會受到先前未見過分佈資料的概括性困難影響，這使得在實際臨床環境中使用研究結果變得困難。由於難以取得地面實況註解，必須考量並引入不同的技術來改善用於訓練深度網路的資料集異質性。在這項工作中，我們提出多種擴充技術的大規模研究，從古典幾何轉換、影像配準、變異自動編碼器和生成對抗網路，到潛在擴散模型的最新進展。我們顯示使用大量資料擴充會顯著增加量化和質化結果，導致 SkullBreak 的平均 Dice 分數高於 0.94，而 SkullFix 資料集則高於 0.96。此外，我們顯示合成擴充網路成功重建真實的臨床缺陷。這項工作為人工智慧在客製化顱骨植入物自動建模領域做出了重大貢獻。

##### **MedExQA: Medical Question Answering Benchmark with Multiple Explanations**
2406.06331v1 by Yunsoo Kim, Jinge Wu, Yusuf Abdulle, Honghan Wu

This paper introduces MedExQA, a novel benchmark in medical
question-answering, to evaluate large language models' (LLMs) understanding of
medical knowledge through explanations. By constructing datasets across five
distinct medical specialties that are underrepresented in current datasets and
further incorporating multiple explanations for each question-answer pair, we
address a major gap in current medical QA benchmarks which is the absence of
comprehensive assessments of LLMs' ability to generate nuanced medical
explanations. Our work highlights the importance of explainability in medical
LLMs, proposes an effective methodology for evaluating models beyond
classification accuracy, and sheds light on one specific domain, speech
language pathology, where current LLMs including GPT4 lack good understanding.
Our results show generation evaluation with multiple explanations aligns better
with human assessment, highlighting an opportunity for a more robust automated
comprehension assessment for LLMs. To diversify open-source medical LLMs
(currently mostly based on Llama2), this work also proposes a new medical
model, MedPhi-2, based on Phi-2 (2.7B). The model outperformed medical LLMs
based on Llama2-70B in generating explanations, showing its effectiveness in
the resource-constrained medical domain. We will share our benchmark datasets
and the trained model.

摘要：本文介绍了 MedExQA，这是一个医学问答领域的新基准，用于通过解释评估大型语言模型 (LLM) 对医学知识的理解。通过在当前数据集中的五个代表性不足的不同医学专业领域构建数据集，并为每个问题-答案对进一步纳入多个解释，我们解决了当前医学问答基准中的一大缺陷，即缺乏对 LLM 生成细微医学解释的能力的全面评估。我们的工作强调了可解释性在医学 LLM 中的重要性，提出了一种超越分类准确度来评估模型的有效方法，并阐明了一个特定领域，即语言病理学，其中包括 GPT4 在内的当前 LLM 缺乏良好的理解。我们的结果表明，使用多个解释进行生成评估与人类评估更一致，突显了对 LLM 进行更稳健的自动理解评估的机会。为了使开源医学 LLM 多样化（目前主要基于 Llama2），这项工作还提出了一种新的医学模型 MedPhi-2，基于 Phi-2 (2.7B)。该模型在生成解释方面优于基于 Llama2-70B 的医学 LLM，显示了其在资源受限的医学领域的有效性。我们将分享我们的基准数据集和训练好的模型。

##### **BrainChat: Decoding Semantic Information from fMRI using Vision-language Pretrained Models**
2406.07584v1 by Wanaiu Huang

Semantic information is vital for human interaction, and decoding it from
brain activity enables non-invasive clinical augmentative and alternative
communication. While there has been significant progress in reconstructing
visual images, few studies have focused on the language aspect. To address this
gap, leveraging the powerful capabilities of the decoder-based vision-language
pretrained model CoCa, this paper proposes BrainChat, a simple yet effective
generative framework aimed at rapidly accomplishing semantic information
decoding tasks from brain activity, including fMRI question answering and fMRI
captioning. BrainChat employs the self-supervised approach of Masked Brain
Modeling to encode sparse fMRI data, obtaining a more compact embedding
representation in the latent space. Subsequently, BrainChat bridges the gap
between modalities by applying contrastive loss, resulting in aligned
representations of fMRI, image, and text embeddings. Furthermore, the fMRI
embeddings are mapped to the generative Brain Decoder via cross-attention
layers, where they guide the generation of textual content about fMRI in a
regressive manner by minimizing caption loss. Empirically, BrainChat exceeds
the performance of existing state-of-the-art methods in the fMRI captioning
task and, for the first time, implements fMRI question answering. Additionally,
BrainChat is highly flexible and can achieve high performance without image
data, making it better suited for real-world scenarios with limited data.

摘要：語義資訊對於人類互動至關重要，而從大腦活動中解碼語義資訊則能實現非侵入性的臨床擴增和替代溝通。儘管在重建視覺影像方面已取得顯著進展，但鮮少有研究關注語言面向。為了解決這個落差，本文利用編碼器為基礎的視覺語言預訓練模型 CoCa 的強大功能，提出 BrainChat，這是一個簡單但有效的生成式架構，旨在快速完成大腦活動的語義資訊解碼任務，包括 fMRI 問答和 fMRI 標題。BrainChat 採用遮罩大腦建模的自我監督方法來編碼稀疏的 fMRI 資料，在潛在空間中取得更緊湊的嵌入表示。隨後，BrainChat 透過套用對比損失來彌合模態之間的差距，產生 fMRI、影像和文字嵌入的對齊表示。此外，fMRI 嵌入透過交叉注意力層對應到生成式大腦解碼器，其中它們以遞減方式引導產生有關 fMRI 的文字內容，藉此最小化標題損失。根據經驗，BrainChat 在 fMRI 標題任務中超越現有最先進方法的效能，並首次實作 fMRI 問答。此外，BrainChat 具有高度彈性，且無需影像資料就能達成高效能，使其更適合資料有限的真實世界場景。

##### **A Dual-View Approach to Classifying Radiology Reports by Co-Training**
2406.05995v1 by Yutong Han, Yan Yuan, Lili Mou

Radiology report analysis provides valuable information that can aid with
public health initiatives, and has been attracting increasing attention from
the research community. In this work, we present a novel insight that the
structure of a radiology report (namely, the Findings and Impression sections)
offers different views of a radiology scan. Based on this intuition, we further
propose a co-training approach, where two machine learning models are built
upon the Findings and Impression sections, respectively, and use each other's
information to boost performance with massive unlabeled data in a
semi-supervised manner. We conducted experiments in a public health
surveillance study, and results show that our co-training approach is able to
improve performance using the dual views and surpass competing supervised and
semi-supervised methods.

摘要：放射學報告分析提供有價值的資訊，有助於公共衛生計畫，並已吸引研究社群越來越多的關注。在這項工作中，我們提出一個新的見解，即放射學報告的結構（即「發現」和「印象」部分）提供放射學掃描的不同觀點。基於這個直覺，我們進一步提出一個共同訓練方法，其中兩個機器學習模型分別建立在「發現」和「印象」部分之上，並使用彼此的資訊以大量未標記資料以半監督的方式提升效能。我們在公共衛生監測研究中進行實驗，結果顯示我們的共同訓練方法能夠使用雙重觀點來提升效能，並超越競爭的監督式和半監督式方法。

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

摘要：心理健康構成了一項複雜且普遍的全球挑戰，影響了數百萬人的生活，並經常導致嚴重的後果。在本文中，我們進行了一項徹底的調查，以探索數據科學、人工智慧和心理保健的交集，重點關注通過線上社交媒體 (OSM) 進行心理疾病檢測的最新發展。很大一部分人口積極參與 OSM 平台，創造了一個龐大的人員資料庫，對心理健康分析具有巨大的潛力。本文探討了傳統的診斷方法、最先進的資料和 AI 驅動的研究，以及心理保健中可解釋 AI (XAI) 模型的出現。我們回顧了最先進的機器學習方法，特別是那些基於現代深度學習的方法，同時強調了醫療保健 AI 模型中可解釋性的必要性。實驗設計部分提供了對普遍做法的見解，包括可用的資料集和評估方法。我們還找出該領域的主要問題和挑戰，並提出了有希望的未來研究方向。由於心理健康決策需要透明度、可解釋性和道德考量，本文有助於推進心理保健中透過社交媒體推進 XAI 的持續討論。這裡提出的全面概述旨在引導研究人員、從業人員和政策制定者發展心理疾病檢測領域。

##### **Decision-Making Behavior Evaluation Framework for LLMs under Uncertain Context**
2406.05972v1 by Jingru Jia, Zehua Yuan, Junhao Pan, Paul McNamara, Deming Chen

When making decisions under uncertainty, individuals often deviate from
rational behavior, which can be evaluated across three dimensions: risk
preference, probability weighting, and loss aversion. Given the widespread use
of large language models (LLMs) in decision-making processes, it is crucial to
assess whether their behavior aligns with human norms and ethical expectations
or exhibits potential biases. Several empirical studies have investigated the
rationality and social behavior performance of LLMs, yet their internal
decision-making tendencies and capabilities remain inadequately understood.
This paper proposes a framework, grounded in behavioral economics, to evaluate
the decision-making behaviors of LLMs. Through a multiple-choice-list
experiment, we estimate the degree of risk preference, probability weighting,
and loss aversion in a context-free setting for three commercial LLMs:
ChatGPT-4.0-Turbo, Claude-3-Opus, and Gemini-1.0-pro. Our results reveal that
LLMs generally exhibit patterns similar to humans, such as risk aversion and
loss aversion, with a tendency to overweight small probabilities. However,
there are significant variations in the degree to which these behaviors are
expressed across different LLMs. We also explore their behavior when embedded
with socio-demographic features, uncovering significant disparities. For
instance, when modeled with attributes of sexual minority groups or physical
disabilities, Claude-3-Opus displays increased risk aversion, leading to more
conservative choices. These findings underscore the need for careful
consideration of the ethical implications and potential biases in deploying
LLMs in decision-making scenarios. Therefore, this study advocates for
developing standards and guidelines to ensure that LLMs operate within ethical
boundaries while enhancing their utility in complex decision-making
environments.

摘要：<paragraph>在不確定情況下做出決策時，個人通常會偏離理性行為，這可以用三個面向來評估：風險偏好、機率加權和損失規避。鑒於大型語言模型 (LLM) 在決策過程中被廣泛使用，因此評估其行為是否符合人類規範和道德期望或表現出潛在偏見至關重要。多項實證研究調查了 LLM 的理性與社會行為表現，但其內部決策傾向和能力仍未被充分理解。本文提出了一個基於行為經濟學的架構，用於評估 LLM 的決策行為。透過多選題實驗，我們估計了三個商業 LLM：ChatGPT-4.0-Turbo、Claude-3-Opus 和 Gemini-1.0-pro 在無背景設定下的風險偏好、機率加權和損失規避程度。我們的結果顯示，LLM 通常表現出類似於人類的模式，例如風險規避和損失規避，並傾向於高估小機率。然而，這些行為在不同 LLM 中表現的程度存在顯著差異。我們也探討了它們在嵌入社會人口特徵時的行為，發現了顯著的差異。例如，當以性少數群體或身體殘疾的屬性建模時，Claude-3-Opus 會表現出更高的風險規避，導致更保守的選擇。這些發現強調了在決策場景中部署 LLM 時，需要仔細考量其道德意涵和潛在偏見。因此，本研究主張制定標準和準則，以確保 LLM 在道德界限內運作，同時提升其在複雜決策環境中的效用。</paragraph>

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

摘要：<paragraph>醫療照護中需要 AI 輔助的臨床診斷。現有的深度學習模型缺乏可解釋性，並且主要專注於影像分析。最近開發的動態不確定因果關係圖 (DUCG) 方法是因果驅動的、可解釋的，並且在不同的應用場景中是不變的，沒有資料收集、標記、擬合、隱私、偏見、概化、高成本和高能耗的問題。通過臨床專家和 DUCG 技術人員之間的密切合作，構建了涵蓋 54 個主訴的 46 個 DUCG 模型。可以在沒有分流的情況下診斷出 1,000 多種疾病。在應用於實際世界之前，46 個 DUCG 模型已由第三方醫院回溯性驗證。驗證的診斷精度不低於 95%，其中包括罕見疾病在內的每種疾病的診斷精度不低於 80%。驗證後，46 個 DUCG 模型已在中國實際應用。已經執行了超過一百萬個真實診斷案例，僅發現 17 個不正確的診斷。由於 DUCG 的透明性，發現並糾正了導致不正確診斷的錯誤。頻繁應用 DUCG 的臨床醫生的診斷能力得到了顯著提高。在介紹了前面提出的 DUCG 方法論之後，提出了潛在健康檢查的推薦演算法，並提取了 DUCG 的關鍵思想。</paragraph>

##### **From Basic to Extra Features: Hypergraph Transformer Pretrain-then-Finetuning for Balanced Clinical Predictions on EHR**
2406.05682v1 by Ran Xu, Yiwen Lu, Chang Liu, Yong Chen, Yan Sun, Xiao Hu, Joyce C Ho, Carl Yang

Electronic Health Records (EHRs) contain rich patient information and are
crucial for clinical research and practice. In recent years, deep learning
models have been applied to EHRs, but they often rely on massive features,
which may not be readily available for all patients. We propose HTP-Star, which
leverages hypergraph structures with a pretrain-then-finetune framework for
modeling EHR data, enabling seamless integration of additional features.
Additionally, we design two techniques, namely (1) Smoothness-inducing
Regularization and (2) Group-balanced Reweighting, to enhance the model's
robustness during fine-tuning. Through experiments conducted on two real EHR
datasets, we demonstrate that HTP-Star consistently outperforms various
baselines while striking a balance between patients with basic and extra
features.

摘要：電子健康紀錄 (EHR) 包含豐富的患者資訊，對於臨床研究和實務至關重要。近年來，深度學習模型已應用於 EHR，但它們通常依賴大量特徵，而這些特徵可能並非所有患者都能輕易取得。我們提出 HTP-Star，它利用超圖結構搭配預訓練再微調架構來建模 EHR 資料，讓額外特徵能無縫整合。此外，我們設計了兩種技術，即 (1) 平滑誘導正則化和 (2) 群組平衡重新加權，以增強模型在微調期間的穩健性。透過在兩個真實 EHR 資料集上進行的實驗，我們證明 HTP-Star 在為具有基本和額外特徵的患者取得平衡的同時，始終優於各種基線。

##### **CCSI: Continual Class-Specific Impression for Data-free Class Incremental Learning**
2406.05631v1 by Sana Ayromlou, Teresa Tsang, Purang Abolmaesumi, Xiaoxiao Li

In real-world clinical settings, traditional deep learning-based
classification methods struggle with diagnosing newly introduced disease types
because they require samples from all disease classes for offline training.
Class incremental learning offers a promising solution by adapting a deep
network trained on specific disease classes to handle new diseases. However,
catastrophic forgetting occurs, decreasing the performance of earlier classes
when adapting the model to new data. Prior proposed methodologies to overcome
this require perpetual storage of previous samples, posing potential practical
concerns regarding privacy and storage regulations in healthcare. To this end,
we propose a novel data-free class incremental learning framework that utilizes
data synthesis on learned classes instead of data storage from previous
classes. Our key contributions include acquiring synthetic data known as
Continual Class-Specific Impression (CCSI) for previously inaccessible trained
classes and presenting a methodology to effectively utilize this data for
updating networks when introducing new classes. We obtain CCSI by employing
data inversion over gradients of the trained classification model on previous
classes starting from the mean image of each class inspired by common landmarks
shared among medical images and utilizing continual normalization layers
statistics as a regularizer in this pixel-wise optimization process.
Subsequently, we update the network by combining the synthesized data with new
class data and incorporate several losses, including an intra-domain
contrastive loss to generalize the deep network trained on the synthesized data
to real data, a margin loss to increase separation among previous classes and
new ones, and a cosine-normalized cross-entropy loss to alleviate the adverse
effects of imbalanced distributions in training data.

摘要：<paragraph>在真實世界臨床環境中，傳統的深度學習分類方法難以診斷新引入的疾病類型，因為它們需要離線訓練所有疾病類別的樣本。類別增量學習提供了一個有前途的解決方案，通過調整在特定疾病類別上訓練的深度網路來處理新疾病。然而，會發生災難性遺忘，在將模型調整到新數據時降低早期類別的性能。先前提出的克服此問題的方法論需要持續儲存先前的樣本，對醫療保健中的隱私和儲存法規造成潛在的實際問題。為此，我們提出一個新穎的無數據類別增量學習框架，利用已學習類別的數據合成，而不是先前類別的數據儲存。我們的關鍵貢獻包括獲取合成數據，稱為連續類別特定印象 (CCSI)，用於先前無法存取的已訓練類別，並提出一個方法論，在引入新類別時有效地利用此數據來更新網路。我們通過對先前類別的訓練分類模型的梯度進行數據反演來獲取 CCSI，從每個類別的平均影像開始，靈感來自醫學影像中共享的共同地標，並利用連續正規化層統計作為此逐像素最佳化過程中的正則化器。隨後，我們通過將合成數據與新類別數據結合來更新網路，並結合多種損失，包括域內對比損失，以將在合成數據上訓練的深度網路推廣到真實數據，邊際損失以增加先前類別和新類別之間的分離，以及餘弦正規化交叉熵損失以減輕訓練數據中不平衡分佈的不利影響。</paragraph>

##### **Which Backbone to Use: A Resource-efficient Domain Specific Comparison for Computer Vision**
2406.05612v1 by Pranav Jeevan, Amit Sethi

In contemporary computer vision applications, particularly image
classification, architectural backbones pre-trained on large datasets like
ImageNet are commonly employed as feature extractors. Despite the widespread
use of these pre-trained convolutional neural networks (CNNs), there remains a
gap in understanding the performance of various resource-efficient backbones
across diverse domains and dataset sizes. Our study systematically evaluates
multiple lightweight, pre-trained CNN backbones under consistent training
settings across a variety of datasets, including natural images, medical
images, galaxy images, and remote sensing images. This comprehensive analysis
aims to aid machine learning practitioners in selecting the most suitable
backbone for their specific problem, especially in scenarios involving small
datasets where fine-tuning a pre-trained network is crucial. Even though
attention-based architectures are gaining popularity, we observed that they
tend to perform poorly under low data finetuning tasks compared to CNNs. We
also observed that some CNN architectures such as ConvNeXt, RegNet and
EfficientNet performs well compared to others on a diverse set of domains
consistently. Our findings provide actionable insights into the performance
trade-offs and effectiveness of different backbones, facilitating informed
decision-making in model selection for a broad spectrum of computer vision
domains. Our code is available here: https://github.com/pranavphoenix/Backbones

摘要：<paragraph>在當代電腦視覺應用中，特別是影像分類，預先在大型資料集（例如 ImageNet）上訓練的架構主幹通常用作特徵萃取器。儘管廣泛使用這些預先訓練的卷積神經網路 (CNN)，但對於各種資源效率主幹在不同網域和資料集大小上的效能仍缺乏了解。我們的研究系統性地評估多個輕量級、預先訓練的 CNN 主幹，在各種資料集（包括自然影像、醫學影像、星系影像和遙測影像）上採用一致的訓練設定。這項全面的分析旨在協助機器學習從業人員為其特定問題選擇最合適的主幹，特別是在涉及小型資料集的情況下，其中微調預先訓練的網路至關重要。儘管基於注意力的架構越來越受歡迎，但我們觀察到，與 CNN 相比，它們在低資料量微調任務中的表現往往較差。我們還觀察到，與其他架構相比，某些 CNN 架構（例如 ConvNeXt、RegNet 和 EfficientNet）在各種網域上表現良好且一致。我們的研究結果提供了可操作的見解，說明不同主幹的效能取捨和有效性，有助於在廣泛的電腦視覺網域中進行模型選擇的明智決策。我們的程式碼可在此取得：https://github.com/pranavphoenix/Backbones</paragraph>

##### **I-SIRch: AI-Powered Concept Annotation Tool For Equitable Extraction And Analysis Of Safety Insights From Maternity Investigations**
2406.05505v1 by Mohit Kumar Singh, Georgina Cosma, Patrick Waterson, Jonathan Back, Gyuchan Thomas Jun

Maternity care is a complex system involving treatments and interactions
between patients, providers, and the care environment. To improve patient
safety and outcomes, understanding the human factors (e.g. individuals
decisions, local facilities) influencing healthcare delivery is crucial.
However, most current tools for analysing healthcare data focus only on
biomedical concepts (e.g. health conditions, procedures and tests), overlooking
the importance of human factors. We developed a new approach called I-SIRch,
using artificial intelligence to automatically identify and label human factors
concepts in maternity healthcare investigation reports describing adverse
maternity incidents produced by England's Healthcare Safety Investigation
Branch (HSIB). These incident investigation reports aim to identify
opportunities for learning and improving maternal safety across the entire
healthcare system. I-SIRch was trained using real data and tested on both real
and simulated data to evaluate its performance in identifying human factors
concepts. When applied to real reports, the model achieved a high level of
accuracy, correctly identifying relevant concepts in 90\% of the sentences from
97 reports. Applying I-SIRch to analyse these reports revealed that certain
human factors disproportionately affected mothers from different ethnic groups.
Our work demonstrates the potential of using automated tools to identify human
factors concepts in maternity incident investigation reports, rather than
focusing solely on biomedical concepts. This approach opens up new
possibilities for understanding the complex interplay between social,
technical, and organisational factors influencing maternal safety and
population health outcomes. By taking a more comprehensive view of maternal
healthcare delivery, we can develop targeted interventions to address
disparities and improve maternal outcomes.

摘要：產科照護是一個複雜的系統，涉及患者、提供者和照護環境之間的治療和互動。為了改善患者安全和照護結果，了解影響醫療保健服務的人為因素（例如個人決策、當地設施）至關重要。然而，目前大多數用於分析醫療保健資料的工具只關注生物醫學概念（例如健康狀況、程序和檢驗），而忽略了人為因素的重要性。我們開發了一種稱為 I-SIRch 的新方法，利用人工智慧自動識別和標記英國醫療安全調查部門 (HSIB) 產生的描述不良產科事件的產科醫療保健調查報告中的人為因素概念。這些事件調查報告旨在找出機會，以學習並改善整個醫療保健系統中的產婦安全。I-SIRch 使用真實資料進行訓練，並在真實和模擬資料上進行測試，以評估其在識別人為因素概念方面的表現。當應用於真實報告時，該模型達到了很高的準確度，在 97 份報告的 90% 的句子中正確識別了相關概念。將 I-SIRch 應用於分析這些報告顯示，某些人為因素對不同種族群體的母親產生了不成比例的影響。我們的研究證明了使用自動化工具來識別人為因素概念在產科事件調查報告中的潛力，而不是僅關注生物醫學概念。這種方法為理解影響產婦安全和人口健康結果的社會、技術和組織因素之間的複雜相互作用開闢了新的可能性。通過更全面地了解產科醫療保健服務，我們可以制定有針對性的干預措施來解決差異並改善產婦結果。

##### **DeviceBERT: Applied Transfer Learning With Targeted Annotations and Vocabulary Enrichment to Identify Medical Device and Component Terminology in FDA Recall Summaries**
2406.05307v1 by Miriam Farrington

FDA Medical Device recalls are critical and time-sensitive events, requiring
swift identification of impacted devices to inform the public of a recall event
and ensure patient safety. The OpenFDA device recall dataset contains valuable
information about ongoing device recall actions, but manually extracting
relevant device information from the recall action summaries is a
time-consuming task. Named Entity Recognition (NER) is a task in Natural
Language Processing (NLP) that involves identifying and categorizing named
entities in unstructured text. Existing NER models, including domain-specific
models like BioBERT, struggle to correctly identify medical device trade names,
part numbers and component terms within these summaries. To address this, we
propose DeviceBERT, a medical device annotation, pre-processing and enrichment
pipeline, which builds on BioBERT to identify and label medical device
terminology in the device recall summaries with improved accuracy. Furthermore,
we demonstrate that our approach can be applied effectively for performing
entity recognition tasks where training data is limited or sparse.

摘要：食品藥物管理局醫療器材召回是關鍵且時間敏感的事件，需要迅速找出受影響的器材，以告知大眾召回事件並確保病患安全。OpenFDA 器材召回資料集包含有關持續進行器材召回行動的寶貴資訊，但手動從召回行動摘要中擷取相關器材資訊是一項耗時的任務。命名實體辨識 (NER) 是自然語言處理 (NLP) 中的一項任務，涉及在非結構化文字中辨識和分類命名實體。現有的 NER 模型（包括像 BioBERT 這類特定領域模型）難以正確辨識這些摘要中的醫療器材商品名、零件編號和組成術語。為了解決這個問題，我們提出 DeviceBERT，這是一個醫療器材註解、前處理和豐富處理管線，它建構於 BioBERT 之上，以更高的準確度辨識和標記器材召回摘要中的醫療器材術語。此外，我們證明我們的做法可以有效應用於執行訓練資料受限或稀疏的實體辨識任務。

##### **Analyzing the factors that are involved in length of inpatient stay at the hospital for diabetes patients**
2406.05189v1 by Jorden Lam, Kunpeng Xu

The paper investigates the escalating concerns surrounding the surge in
diabetes cases, exacerbated by the COVID-19 pandemic, and the subsequent strain
on medical resources. The research aims to construct a predictive model
quantifying factors influencing inpatient hospital stay durations for diabetes
patients, offering insights to hospital administrators for improved patient
management strategies. The literature review highlights the increasing
prevalence of diabetes, emphasizing the need for continued attention and
analysis of urban-rural disparities in healthcare access. International studies
underscore the financial implications and healthcare burden associated with
diabetes-related hospitalizations and complications, emphasizing the
significance of effective management strategies. The methodology involves a
quantitative approach, utilizing a dataset comprising 10,000 observations of
diabetic inpatient encounters in U.S. hospitals from 1999 to 2008. Predictive
modeling techniques, particularly Generalized Linear Models (GLM), are employed
to develop a model predicting hospital stay durations based on patient
demographics, admission types, medical history, and treatment regimen. The
results highlight the influence of age, medical history, and treatment regimen
on hospital stay durations for diabetes patients. Despite model limitations,
such as heteroscedasticity and deviations from normality in residual analysis,
the findings offer valuable insights for hospital administrators in patient
management. The paper concludes with recommendations for future research to
address model limitations and explore the implications of predictive models on
healthcare management strategies, ensuring equitable patient care and resource
allocation.

摘要：本文探討了糖尿病病例激增引發的日益嚴重的問題，而 COVID-19 大流行使問題更加惡化，並對醫療資源造成後續負擔。本研究旨在建構一個預測模型，量化影響糖尿病患者住院天數的因素，並提供見解給醫院管理員，以改善病患管理策略。文獻回顧強調了糖尿病患病率的上升，並強調需要持續關注和分析城鄉之間在醫療保健取得方面的差異。國際研究強調了與糖尿病相關的住院和併發症所帶來的財務影響和醫療負擔，並強調了有效管理策略的重要性。方法涉及一種量化方法，利用一個資料集，其中包含了 1999 年至 2008 年間美國醫院中 10,000 筆糖尿病住院患者的觀察結果。預測模型技術，尤其是廣義線性模型 (GLM)，被用於開發一個模型，根據患者人口統計資料、入院類型、病史和治療方案來預測住院天數。結果重點說明了年齡、病史和治療方案對糖尿病患者住院天數的影響。儘管模型有其限制，例如殘差分析中的異質變異數和常態分佈偏差，但研究結果仍為醫院管理員在病患管理方面提供了寶貴的見解。本文最後提出了未來研究建議，以解決模型限制並探討預測模型對醫療管理策略的影響，確保公平的病患照護和資源分配。

##### **Benchmarking Deep Jansen-Rit Parameter Inference: An in Silico Study**
2406.05002v1 by Deepa Tilwani, Christian O'Reilly

The study of effective connectivity (EC) is essential in understanding how
the brain integrates and responds to various sensory inputs. Model-driven
estimation of EC is a powerful approach that requires estimating global and
local parameters of a generative model of neural activity. Insights gathered
through this process can be used in various applications, such as studying
neurodevelopmental disorders. However, accurately determining EC through
generative models remains a significant challenge due to the complexity of
brain dynamics and the inherent noise in neural recordings, e.g., in
electroencephalography (EEG). Current model-driven methods to study EC are
computationally complex and cannot scale to all brain regions as required by
whole-brain analyses. To facilitate EC assessment, an inference algorithm must
exhibit reliable prediction of parameters in the presence of noise. Further,
the relationship between the model parameters and the neural recordings must be
learnable. To progress toward these objectives, we benchmarked the performance
of a Bi-LSTM model for parameter inference from the Jansen-Rit neural mass
model (JR-NMM) simulated EEG under various noise conditions. Additionally, our
study explores how the JR-NMM reacts to changes in key biological parameters
(i.e., sensitivity analysis) like synaptic gains and time constants, a crucial
step in understanding the connection between neural mechanisms and observed
brain activity. Our results indicate that we can predict the local JR-NMM
parameters from EEG, supporting the feasibility of our deep-learning-based
inference approach. In future work, we plan to extend this framework to
estimate local and global parameters from real EEG in clinically relevant
applications.

摘要：有效连通性 (EC) 的研究对于理解大脑如何整合和响应各种感官输入至关重要。EC 的模型驱动估计是一种强大的方法，需要估计神经活动生成模型的全局和局部参数。通过此过程收集的见解可用于各种应用中，例如研究神经发育障碍。然而，由于大脑动力学复杂且神经记录中固有噪声（例如脑电图 (EEG) 中的噪声），通过生成模型准确确定 EC 仍然是一项重大挑战。当前用于研究 EC 的模型驱动方法计算复杂，并且无法扩展到全脑分析所需的所有大脑区域。为了促进 EC 评估，推理算法必须在存在噪声的情况下对参数进行可靠预测。此外，模型参数与神经记录之间的关系必须是可学习的。为了实现这些目标，我们对双向 LSTM 模型在各种噪声条件下从 Jansen-Rit 神经质量模型 (JR-NMM) 模拟脑电图中进行参数推理的性能进行了基准测试。此外，我们的研究探索了 JR-NMM 如何对关键生物学参数（即敏感性分析）的变化做出反应，例如突触增益和时间常数，这是理解神经机制与观察到的脑活动之间联系的关键步骤。我们的结果表明，我们可以从脑电图中预测局部 JR-NMM 参数，从而支持我们基于深度学习的推理方法的可行性。在未来的工作中，我们计划将此框架扩展到从临床相关应用中的真实脑电图估计局部和全局参数。

##### **DualTime: A Dual-Adapter Multimodal Language Model for Time Series Representation**
2406.06620v1 by Weiqi Zhang, Jiexia Ye, Ziyue Li, Jia Li, Fugee Tsung

The recent rapid development of language models (LMs) has attracted attention
in the field of time series, including multimodal time series modeling.
However, we note that current time series multimodal methods are biased, often
assigning a primary role to one modality while the other assumes a secondary
role. They overlook the mutual benefits and complementary of different
modalities. For example, in seizure diagnosis, relying solely on textual
clinical reports makes it difficult to pinpoint the area and type of the
disease, while electroencephalograms (EEGs) alone cannot provide an accurate
diagnosis without considering the symptoms. In this study, based on the
complementary information mining of time series multimodal data, we propose
DualTime, a Dual-adapter multimodal language model for Time series
representation implementing temporal-primary and textual-primary modeling
simultaneously. By injecting lightweight adaption tokens, the LM pipeline
shared by dual adapters encourages embedding alignment and achieves efficient
fine-tuning. Empirically, our method outperforms state-of-the-art models in
both supervised and unsupervised settings, highlighting the complementary
benefits of different modalities. In addition, we conduct few-shot label
transfer experiments, which further verifies the transferability and
expressiveness of our proposed DualTime.

摘要：近期語言模型 (LM) 的快速發展，吸引了時間序列領域的關注，包括多模態時間序列建模。然而，我們注意到目前的時間序列多模態方法有偏見，通常將主要角色分配給一種模態，而另一種則扮演次要角色。它們忽視了不同模態的互惠利益和互補性。例如，在癲癇診斷中，僅依賴文字臨床報告很難精確指出疾病的區域和類型，而單獨的腦電圖 (EEG) 在不考慮症狀的情況下無法提供準確的診斷。在本研究中，基於時間序列多模態資料的互補資訊探勘，我們提出了 DualTime，一種用於時間序列表示的雙適配器多模態語言模型，同時實作時間優先和文字優先建模。透過注入輕量級適應權杖，由雙適配器共用的 LM 管線鼓勵嵌入對齊，並實現有效率的微調。根據經驗，我們的模型在監督式和非監督式設定中都優於最先進的模型，突顯了不同模態的互補優勢。此外，我們進行了小樣本標籤轉移實驗，進一步驗證了我們提出的 DualTime 的可轉移性和表達能力。

##### **CarbonSense: A Multimodal Dataset and Baseline for Carbon Flux Modelling**
2406.04940v1 by Matthew Fortier, Mats L. Richter, Oliver Sonnentag, Chris Pal

Terrestrial carbon fluxes provide vital information about our biosphere's
health and its capacity to absorb anthropogenic CO$_2$ emissions. The
importance of predicting carbon fluxes has led to the emerging field of
data-driven carbon flux modelling (DDCFM), which uses statistical techniques to
predict carbon fluxes from biophysical data. However, the field lacks a
standardized dataset to promote comparisons between models. To address this
gap, we present CarbonSense, the first machine learning-ready dataset for
DDCFM. CarbonSense integrates measured carbon fluxes, meteorological
predictors, and satellite imagery from 385 locations across the globe, offering
comprehensive coverage and facilitating robust model training. Additionally, we
provide a baseline model using a current state-of-the-art DDCFM approach and a
novel transformer based model. Our experiments illustrate the potential gains
that multimodal deep learning techniques can bring to this domain. By providing
these resources, we aim to lower the barrier to entry for other deep learning
researchers to develop new models and drive new advances in carbon flux
modelling.

摘要：陸地碳通量提供我們生物圈健康和吸收人為 CO$_2$ 排放的能力的重要資訊。預測碳通量的重要性導致資料驅動碳通量建模 (DDCFM) 新興領域的出現，它使用統計技術從生物物理資料預測碳通量。然而，該領域缺乏標準化資料集來促進模型之間的比較。為了解決這個差距，我們提出 CarbonSense，這是第一個適用於 DDCFM 的機器學習準備資料集。CarbonSense 整合了來自全球 385 個地點的測量碳通量、氣象預測因子和衛星影像，提供全面的涵蓋範圍並促進穩健的模型訓練。此外，我們使用當前最先進的 DDCFM 方法和基於新穎Transformer的模型提供基準模型。我們的實驗說明了多模態深度學習技術可以為這個領域帶來的潛在收益。透過提供這些資源，我們旨在降低其他深度學習研究人員進入門檻，以開發新模型並推動碳通量建模的新進展。

##### **PANDORA: Deep graph learning based COVID-19 infection risk level forecasting**
2406.06618v1 by Shuo Yu, Feng Xia, Yueru Wang, Shihao Li, Falih Febrinanto, Madhu Chetty

COVID-19 as a global pandemic causes a massive disruption to social stability
that threatens human life and the economy. Policymakers and all elements of
society must deliver measurable actions based on the pandemic's severity to
minimize the detrimental impact of COVID-19. A proper forecasting system is
arguably important to provide an early signal of the risk of COVID-19 infection
so that the authorities are ready to protect the people from the worst.
However, making a good forecasting model for infection risks in different
cities or regions is not an easy task, because it has a lot of influential
factors that are difficult to be identified manually. To address the current
limitations, we propose a deep graph learning model, called PANDORA, to predict
the infection risks of COVID-19, by considering all essential factors and
integrating them into a geographical network. The framework uses geographical
position relations and transportation frequency as higher-order structural
properties formulated by higher-order network structures (i.e., network
motifs). Moreover, four significant node attributes (i.e., multiple features of
a particular area, including climate, medical condition, economy, and human
mobility) are also considered. We propose three different aggregators to better
aggregate node attributes and structural features, namely, Hadamard, Summation,
and Connection. Experimental results over real data show that PANDORA
outperforms the baseline method with higher accuracy and faster convergence
speed, no matter which aggregator is chosen. We believe that PANDORA using deep
graph learning provides a promising approach to get superior performance in
infection risk level forecasting and help humans battle the COVID-19 crisis.

摘要：COVID-19 作為全球大流行病對社會穩定造成大規模的破壞，威脅到人類生命和經濟。政策制定者和社會各階層必須根據疫情的嚴重程度採取可衡量的行動，以將 COVID-19 的不利影響降到最低。一個適當的預測系統無疑對於提供 COVID-19 感染風險的早期信號非常重要，以便當局做好準備保護人民免於最壞的狀況。然而，為不同城市或地區的感染風險建立一個良好的預測模型並非易事，因為它有許多影響因素，難以人工識別。為了解決目前的局限性，我們提出了一個名為 PANDORA 的深度圖學習模型，通過考慮所有必要因素並將它們整合到一個地理網路中，來預測 COVID-19 的感染風險。該框架使用地理位置關係和運輸頻率作為由高階網路結構（即網路主題）制定的高階結構屬性。此外，還考慮了四個重要的節點屬性（即特定區域的氣候、醫療條件、經濟和人類流動性等多種特徵）。我們提出了三個不同的聚合器來更好地聚合節點屬性和結構特徵，即 Hadamard、Summation 和 Connection。在真實資料上的實驗結果表明，無論選擇哪個聚合器，PANDORA 都以更高的準確性和更快的收斂速度優於基線方法。我們相信使用深度圖學習的 PANDORA 提供了一種有前景的方法，可以在感染風險等級預測中獲得卓越的性能，並幫助人類戰勝 COVID-19 危機。

##### **Transforming Dental Diagnostics with Artificial Intelligence: Advanced Integration of ChatGPT and Large Language Models for Patient Care**
2406.06616v1 by Masoumeh Farhadi Nia, Mohsen Ahmadi, Elyas Irankhah

Artificial intelligence has dramatically reshaped our interaction with
digital technologies, ushering in an era where advancements in AI algorithms
and Large Language Models (LLMs) have natural language processing (NLP) systems
like ChatGPT. This study delves into the impact of cutting-edge LLMs, notably
OpenAI's ChatGPT, on medical diagnostics, with a keen focus on the dental
sector. Leveraging publicly accessible datasets, these models augment the
diagnostic capabilities of medical professionals, streamline communication
between patients and healthcare providers, and enhance the efficiency of
clinical procedures. The advent of ChatGPT-4 is poised to make substantial
inroads into dental practices, especially in the realm of oral surgery. This
paper sheds light on the current landscape and explores potential future
research directions in the burgeoning field of LLMs, offering valuable insights
for both practitioners and developers. Furthermore, it critically assesses the
broad implications and challenges within various sectors, including academia
and healthcare, thus mapping out an overview of AI's role in transforming
dental diagnostics for enhanced patient care.

摘要：人工智慧徹底改變了我們與數位科技的互動，引領我們進入一個 AI 演算法和大型語言模型 (LLM) 蓬勃發展的時代，擁有自然語言處理 (NLP) 系統，例如 ChatGPT。本研究深入探討尖端 LLM，特別是 OpenAI 的 ChatGPT，對醫療診斷的影響，並特別關注牙科領域。透過運用公開存取的資料集，這些模型增強了醫療專業人員的診斷能力，簡化了患者與醫療保健提供者之間的溝通，並提高了臨床程序的效率。ChatGPT-4 的出現準備在牙科實務中取得重大進展，尤其是在口腔外科領域。本文闡明了目前的現況，並探討了蓬勃發展的 LLM 領域中潛在的未來研究方向，為實務工作者和開發人員提供寶貴的見解。此外，它批判性地評估了各個領域（包括學術界和醫療保健）中的廣泛影響和挑戰，從而概述了 AI 在轉變牙科診斷以增強患者照護中的角色。

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

摘要：自注意力機制已被採用於多個廣泛使用的訊息傳遞神經網路 (MPNN)（例如 GAT），它可以自適應地控制沿著底層圖形邊緣流動的資訊量。這種注意力的使用使得此類模型成為可解釋 AI (XAI) 研究的基線，因為透過注意力的詮釋已在各種領域（例如自然語言處理和電腦視覺）中普及。然而，現有的研究通常使用天真的計算方法從注意力中推導出歸因分數，並且沒有考慮到邊緣歸因的精確且仔細的計算。在我們的研究中，我們旨在填補注意力啟用 MPNN 的廣泛使用與它們在很大程度上未被充分探索的可解釋性之間的差距，這個主題已在其他領域積極研究。為此，作為第一次嘗試，我們將 GNN 中注意力權重的邊緣歸因問題形式化。然後，我們提出 GATT，一種建立在計算樹上的邊緣歸因計算方法。透過全面的實驗，我們展示了我們提出的方法在評估 GAT 的歸因時所具有的效果。相反地，我們憑經驗驗證了僅對圖注意力層上的注意力權重取平均值不足以詮釋 GAT 模型的行為。程式碼已公開於 https://github.com/jordan7186/GAtt/tree/main。

##### **Rare Class Prediction Model for Smart Industry in Semiconductor Manufacturing**
2406.04533v1 by Abdelrahman Farrag, Mohammed-Khalil Ghali, Yu Jin

The evolution of industry has enabled the integration of physical and digital
systems, facilitating the collection of extensive data on manufacturing
processes. This integration provides a reliable solution for improving process
quality and managing equipment health. However, data collected from real
manufacturing processes often exhibit challenging properties, such as severe
class imbalance, high rates of missing values, and noisy features, which hinder
effective machine learning implementation. In this study, a rare class
prediction approach is developed for in situ data collected from a smart
semiconductor manufacturing process. The primary objective is to build a model
that addresses issues of noise and class imbalance, enhancing class separation.
The developed approach demonstrated promising results compared to existing
literature, which would allow the prediction of new observations that could
give insights into future maintenance plans and production quality. The model
was evaluated using various performance metrics, with ROC curves showing an AUC
of 0.95, a precision of 0.66, and a recall of 0.96

摘要：產業的演進使得實體與數位系統得以整合，促使製造流程中能收集到廣泛的資料。此整合提供了一個可靠的解決方案，用於改善流程品質並管理設備健康。然而，從真實製造流程收集到的資料通常會表現出具有挑戰性的特性，例如嚴重的類別不平衡、高比率的遺失值和有雜訊的特徵，這些都會阻礙有效的機器學習實作。在這項研究中，開發了一種稀有類別預測方法，用於從智慧半導體製造流程收集的現場資料。主要目標是建立一個模型，用於解決雜訊和類別不平衡的問題，並增強類別分離。與現有的文獻相比，所開發的方法展現出有前景的結果，這將允許預測新的觀察結果，這些觀察結果可以提供對未來維護計畫和生產品質的見解。使用各種效能指標評估此模型，ROC 曲線顯示 AUC 為 0.95、精確度為 0.66、召回率為 0.96

##### **Single Exposure Quantitative Phase Imaging with a Conventional Microscope using Diffusion Models**
2406.04388v1 by Gabriel della Maggiora, Luis Alberto Croquevielle, Harry Horsley, Thomas Heinis, Artur Yakimovich

Phase imaging is gaining importance due to its applications in fields like
biomedical imaging and material characterization. In biomedical applications,
it can provide quantitative information missing in label-free microscopy
modalities. One of the most prominent methods in phase quantification is the
Transport-of-Intensity Equation (TIE). TIE often requires multiple acquisitions
at different defocus distances, which is not always feasible in a clinical
setting. To address this issue, we propose to use chromatic aberrations to
induce the required through-focus images with a single exposure, effectively
generating a through-focus stack. Since the defocus distance induced by the
aberrations is small, conventional TIE solvers are insufficient to address the
resulting artifacts. We propose Zero-Mean Diffusion, a modified version of
diffusion models designed for quantitative image prediction, and train it with
synthetic data to ensure robust phase retrieval. Our contributions offer an
alternative TIE approach that leverages chromatic aberrations, achieving
accurate single-exposure phase measurement with white light and thus improving
the efficiency of phase imaging. Moreover, we present a new class of diffusion
models that are well-suited for quantitative data and have a sound theoretical
basis. To validate our approach, we employ a widespread brightfield microscope
equipped with a commercially available color camera. We apply our model to
clinical microscopy of patients' urine, obtaining accurate phase measurements.

摘要：相位影像由於在生物醫學影像和材料表徵等領域的應用而日益重要。在生物醫學應用中，它可以提供標籤顯微鏡模式中缺少的量化資訊。相位量化的最顯著方法之一是強度傳輸方程式 (TIE)。TIE 通常需要在不同的散焦距離下進行多次擷取，這在臨床環境中並不總是可行的。為了解決這個問題，我們建議使用色差來誘導所需的透過焦點影像，並透過單次曝光有效地產生透過焦點堆疊。由於色差所產生的散焦距離很小，因此傳統的 TIE 解決器不足以解決產生的偽像。我們提出零均值擴散，一種針對量化影像預測而設計的擴散模型的修改版本，並使用合成資料訓練它以確保穩健的相位擷取。我們的貢獻提供了一種利用色差的替代 TIE 方法，實現了準確的單次曝光相位測量，從而提高了相位影像的效率。此外，我們提出了一類新的擴散模型，它們非常適合量化資料，並具有良好的理論基礎。為了驗證我們的做法，我們採用配備市售彩色相機的廣泛使用明場顯微鏡。我們將我們的模型應用於患者尿液的臨床顯微鏡檢查，獲得準確的相位測量。

##### **Promoting Fairness and Diversity in Speech Datasets for Mental Health and Neurological Disorders Research**
2406.04116v1 by Eleonora Mancini, Ana Tanevska, Andrea Galassi, Alessio Galatolo, Federico Ruggeri, Paolo Torroni

Current research in machine learning and artificial intelligence is largely
centered on modeling and performance evaluation, less so on data collection.
However, recent research demonstrated that limitations and biases in data may
negatively impact trustworthiness and reliability. These aspects are
particularly impactful on sensitive domains such as mental health and
neurological disorders, where speech data are used to develop AI applications
aimed at improving the health of patients and supporting healthcare providers.
In this paper, we chart the landscape of available speech datasets for this
domain, to highlight possible pitfalls and opportunities for improvement and
promote fairness and diversity. We present a comprehensive list of desiderata
for building speech datasets for mental health and neurological disorders and
distill it into a checklist focused on ethical concerns to foster more
responsible research.

摘要：目前的機器學習和人工智慧研究主要集中在建模和效能評估上，較少著重於資料收集。然而，最近的研究表明，資料中的限制和偏見可能會對可信度和可靠性產生負面影響。這些面向在心理健康和神經疾病等敏感領域中特別具有影響力，在這些領域中，語音資料用於開發人工智慧應用程式，旨在改善患者健康並支援醫療保健提供者。在本文中，我們繪製了此領域可用的語音資料集概況，以強調可能的陷阱和改進機會，並促進公平性和多樣性。我們提供了一個全面的清單，說明了建立心理健康和神經疾病語音資料集的理想條件，並將其濃縮成一個專注於道德考量的檢查清單，以促進更負責任的研究。

##### **Leveraging SPD Matrices on Riemannian Manifolds in Quantum Classical Hybrid Models for Structural Health Monitoring**
2406.04055v1 by Azadeh Alavi, Sanduni Jayasinghe

Realtime finite element modeling of bridges assists modern structural health
monitoring systems by providing comprehensive insights into structural
integrity. This capability is essential for ensuring the safe operation of
bridges and preventing sudden catastrophic failures. However, FEM computational
cost and the need for realtime analysis pose significant challenges.
Additionally, the input data is a 7 dimensional vector, while the output is a
1017 dimensional vector, making accurate and efficient analysis particularly
difficult. In this study, we propose a novel hybrid quantum classical
Multilayer Perceptron pipeline leveraging Symmetric Positive Definite matrices
and Riemannian manifolds for effective data representation. To maintain the
integrity of the qubit structure, we utilize SPD matrices, ensuring data
representation is well aligned with the quantum computational framework.
Additionally, the method leverages polynomial feature expansion to capture
nonlinear relationships within the data. The proposed pipeline combines
classical fully connected neural network layers with quantum circuit layers to
enhance model performance and efficiency. Our experiments focused on various
configurations of such hybrid models to identify the optimal structure for
accurate and efficient realtime analysis. The best performing model achieved a
Mean Squared Error of 0.00031, significantly outperforming traditional methods.

摘要：橋樑的即時有限元素建模透過提供結構完整性的全面見解，協助現代結構健康監控系統。此功能對於確保橋樑安全操作和防止突然災難性故障至關重要。然而，有限元素方法的運算成本和即時分析的需求帶來了重大挑戰。此外，輸入資料是 7 維向量，而輸出是 1017 維向量，這使得準確而有效的分析特別困難。在本研究中，我們提出了一種新穎的混合量子經典多層感知器管道，利用對稱正定矩陣和黎曼流形進行有效的資料表示。為了維護量子位元結構的完整性，我們利用對稱正定矩陣，確保資料表示與量子運算框架完全一致。此外，此方法利用多項式特徵展開來擷取資料中的非線性關係。所提出的管道結合了經典全連接神經網路層和量子電路層，以增強模型效能和效率。我們的實驗專注於此類混合模型的各種配置，以識別準確且有效的即時分析的最佳結構。效能最佳的模型達到了 0.00031 的平均平方誤差，顯著優於傳統方法。

##### **Speech-based Clinical Depression Screening: An Empirical Study**
2406.03510v2 by Yangbin Chen, Chenyang Xu, Chunfeng Liang, Yanbao Tao, Chuan Shi

This study investigates the utility of speech signals for AI-based depression
screening across varied interaction scenarios, including psychiatric
interviews, chatbot conversations, and text readings. Participants include
depressed patients recruited from the outpatient clinics of Peking University
Sixth Hospital and control group members from the community, all diagnosed by
psychiatrists following standardized diagnostic protocols. We extracted
acoustic and deep speech features from each participant's segmented recordings.
Classifications were made using neural networks or SVMs, with aggregated clip
outcomes determining final assessments. Our analysis across interaction
scenarios, speech processing techniques, and feature types confirms speech as a
crucial marker for depression screening. Specifically, human-computer
interaction matches clinical interview efficacy, surpassing reading tasks.
Segment duration and quantity significantly affect model performance, with deep
speech features substantially outperforming traditional acoustic features.

摘要：本研究調查了語音訊號在基於人工智慧的憂鬱症篩檢中的效用，涵蓋各種互動情境，包括精神科訪談、聊天機器人對話和文本朗讀。參與者包括從北京大學第六醫院門診部招募的憂鬱症患者和來自社區的對照組成員，所有參與者均由精神科醫師根據標準化診斷協定進行診斷。我們從每個參與者的分段錄音中提取了聲學和深度語音特徵。分類是使用神經網路或支援向量機進行的，並以匯總的片段結果確定最終評估。我們對互動情境、語音處理技術和特徵類型的分析證實了語音是憂鬱症篩檢的關鍵標記。具體來說，人機互動與臨床訪談效能相符，優於閱讀任務。分段持續時間和數量會顯著影響模型效能，深度語音特徵明顯優於傳統聲學特徵。

##### **Robust Prediction Model for Multidimensional and Unbalanced Datasets**
2406.03507v1 by Pooja Thakar, Anil Mehta, Manisha

Data Mining is a promising field and is applied in multiple domains for its
predictive capabilities. Data in the real world cannot be readily used for data
mining as it suffers from the problems of multidimensionality, unbalance and
missing values. It is difficult to use its predictive capabilities by novice
users. It is difficult for a beginner to find the relevant set of attributes
from a large pool of data available. The paper presents a Robust Prediction
Model that finds a relevant set of attributes; resolves the problems of
unbalanced and multidimensional real-life datasets and helps in finding
patterns for informed decision making. Model is tested upon five different
datasets in the domain of Health Sector, Education, Business and Fraud
Detection. The results showcase the robust behaviour of the model and its
applicability in various domains.

摘要：資料探勘是一個很有前景的領域，並因其預測能力而應用於多個領域。現實世界中的資料並不能直接用於資料探勘，因為它會受到多維性、不平衡和遺失值的問題影響。新手用戶很難使用其預測能力。對於初學者來說，從大量可用的資料中找出相關的屬性集是一件困難的事。本文提出了一個穩健的預測模型，該模型可以找到相關的屬性集；解決不平衡和多維的現實生活中資料集的問題，並幫助找出模式以進行明智的決策。該模型在醫療保健、教育、商業和詐欺偵測領域的五個不同資料集上進行了測試。結果展示了該模型的穩健行為及其在各種領域中的適用性。

##### **Stochastic Diffusion: A Diffusion Probabilistic Model for Stochastic Time Series Forecasting**
2406.02827v1 by Yuansan Liu, Sudanthi Wijewickrema, Dongting Hu, Christofer Bester, Stephen O'Leary, James Bailey

Recent innovations in diffusion probabilistic models have paved the way for
significant progress in image, text and audio generation, leading to their
applications in generative time series forecasting. However, leveraging such
abilities to model highly stochastic time series data remains a challenge. In
this paper, we propose a novel Stochastic Diffusion (StochDiff) model which
learns data-driven prior knowledge at each time step by utilizing the
representational power of the stochastic latent spaces to model the variability
of the multivariate time series data. The learnt prior knowledge helps the
model to capture complex temporal dynamics and the inherent uncertainty of the
data. This improves its ability to model highly stochastic time series data.
Through extensive experiments on real-world datasets, we demonstrate the
effectiveness of our proposed model on stochastic time series forecasting.
Additionally, we showcase an application of our model for real-world surgical
guidance, highlighting its potential to benefit the medical community.

摘要：最近在擴散機率模型的創新為影像、文字和音訊生成領域的顯著進展鋪路，並應用於生成式時序預測。然而，利用這些能力來建模高度隨機的時序資料仍然是一項挑戰。在本文中，我們提出一個新的隨機擴散 (StochDiff) 模型，它利用隨機潛在空間的表示能力在每個時間步長學習資料驅動的先驗知識，以建模多變量時序資料的變異性。學習到的先驗知識有助於模型捕捉複雜的時間動態和資料的內在不確定性。這改善了它建模高度隨機時序資料的能力。透過對真實世界資料集的廣泛實驗，我們展示了我們提出的模型在隨機時序預測上的有效性。此外，我們展示了我們模型在真實世界手術指導中的應用，突顯了它對醫學界潛在的益處。

##### **Pancreatic Tumor Segmentation as Anomaly Detection in CT Images Using Denoising Diffusion Models**
2406.02653v1 by Reza Babaei, Samuel Cheng, Theresa Thai, Shangqing Zhao

Despite the advances in medicine, cancer has remained a formidable challenge.
Particularly in the case of pancreatic tumors, characterized by their diversity
and late diagnosis, early detection poses a significant challenge crucial for
effective treatment. The advancement of deep learning techniques, particularly
supervised algorithms, has significantly propelled pancreatic tumor detection
in the medical field. However, supervised deep learning approaches necessitate
extensive labeled medical images for training, yet acquiring such annotations
is both limited and costly. Conversely, weakly supervised anomaly detection
methods, requiring only image-level annotations, have garnered interest.
Existing methodologies predominantly hinge on generative adversarial networks
(GANs) or autoencoder models, which can pose complexity in training and, these
models may face difficulties in accurately preserving fine image details. This
research presents a novel approach to pancreatic tumor detection, employing
weak supervision anomaly detection through denoising diffusion algorithms. By
incorporating a deterministic iterative process of adding and removing noise
along with classifier guidance, the method enables seamless translation of
images between diseased and healthy subjects, resulting in detailed anomaly
maps without requiring complex training protocols and segmentation masks. This
study explores denoising diffusion models as a recent advancement over
traditional generative models like GANs, contributing to the field of
pancreatic tumor detection. Recognizing the low survival rates of pancreatic
cancer, this study emphasizes the need for continued research to leverage
diffusion models' efficiency in medical segmentation tasks.

摘要：儘管醫學進步，癌症仍然是一個巨大的挑戰。
特別是在胰臟腫瘤的情況下，其特徵是多樣性和晚期診斷，早期檢測對有效治療至關重要，是一個重大的挑戰。深度學習技術的進步，特別是監督式演算法，已顯著推動了醫學領域的胰臟腫瘤檢測。然而，監督式深度學習方法需要大量的標籤醫學影像進行訓練，但取得此類註解既有限又昂貴。相反地，僅需要影像層級註解的弱監督異常檢測方法引起了興趣。現有的方法論主要依賴於生成對抗網路 (GAN) 或自動編碼器模型，這可能會在訓練中造成複雜性，而且這些模型可能難以準確地保留精細的影像細節。本研究提出了一種新的胰臟腫瘤檢測方法，採用去噪擴散演算法進行弱監督異常檢測。通過結合添加和移除雜訊的確定性迭代過程以及分類器指導，該方法能夠在患病和健康受試者之間無縫地轉換影像，從而產生詳細的異常圖，而不需要複雜的訓練協定和分割遮罩。本研究將去噪擴散模型探索為傳統生成模型（如 GAN）的最新進展，為胰臟腫瘤檢測領域做出貢獻。鑑於胰臟癌的存活率低，本研究強調需要持續研究以利用擴散模型在醫學分割任務中的效率。

##### **Learning Image Priors through Patch-based Diffusion Models for Solving Inverse Problems**
2406.02462v1 by Jason Hu, Bowen Song, Xiaojian Xu, Liyue Shen, Jeffrey A. Fessler

Diffusion models can learn strong image priors from underlying data
distribution and use them to solve inverse problems, but the training process
is computationally expensive and requires lots of data. Such bottlenecks
prevent most existing works from being feasible for high-dimensional and
high-resolution data such as 3D images. This paper proposes a method to learn
an efficient data prior for the entire image by training diffusion models only
on patches of images. Specifically, we propose a patch-based position-aware
diffusion inverse solver, called PaDIS, where we obtain the score function of
the whole image through scores of patches and their positional encoding and
utilize this as the prior for solving inverse problems. First of all, we show
that this diffusion model achieves an improved memory efficiency and data
efficiency while still maintaining the capability to generate entire images via
positional encoding. Additionally, the proposed PaDIS model is highly flexible
and can be plugged in with different diffusion inverse solvers (DIS). We
demonstrate that the proposed PaDIS approach enables solving various inverse
problems in both natural and medical image domains, including CT
reconstruction, deblurring, and superresolution, given only patch-based priors.
Notably, PaDIS outperforms previous DIS methods trained on entire image priors
in the case of limited training data, demonstrating the data efficiency of our
proposed approach by learning patch-based prior.

摘要：扩散模型可以从底层数据分布中学习强图像先验，并利用它们来解决逆问题，但训练过程在计算上很昂贵，需要大量数据。此类瓶颈阻碍了大多数现有工作对高维和高分辨率数据（例如 3D 图像）的可行性。本文提出了一种方法，仅通过训练图像的块来学习整个图像的有效数据先验，以扩散模型。具体来说，我们提出了一个基于块的位置感知扩散逆求解器，称为 PaDIS，其中我们通过块及其位置编码获得整个图像的分数函数，并将其用作解决逆问题的先验。首先，我们表明该扩散模型实现了改进的内存效率和数据效率，同时仍保持通过位置编码生成整个图像的能力。此外，提出的 PaDIS 模型非常灵活，可以插入不同的扩散逆求解器 (DIS)。我们证明了所提出的 PaDIS 方法能够解决自然和医学图像域中的各种逆问题，包括 CT 重建、去模糊和超分辨率，仅给出基于块的先验。值得注意的是，在训练数据有限的情况下，PaDIS 优于以前在整个图像先验上训练的 DIS 方法，证明了我们提出的方法通过学习基于块的先验的数据效率。

##### **Multiple Choice Questions and Large Languages Models: A Case Study with Fictional Medical Data**
2406.02394v1 by Maxime Griot, Jean Vanderdonckt, Demet Yuksel, Coralie Hemptinne

Large Language Models (LLMs) like ChatGPT demonstrate significant potential
in the medical field, often evaluated using multiple-choice questions (MCQs)
similar to those found on the USMLE. Despite their prevalence in medical
education, MCQs have limitations that might be exacerbated when assessing LLMs.
To evaluate the effectiveness of MCQs in assessing the performance of LLMs, we
developed a fictional medical benchmark focused on a non-existent gland, the
Glianorex. This approach allowed us to isolate the knowledge of the LLM from
its test-taking abilities. We used GPT-4 to generate a comprehensive textbook
on the Glianorex in both English and French and developed corresponding
multiple-choice questions in both languages. We evaluated various open-source,
proprietary, and domain-specific LLMs using these questions in a zero-shot
setting. The models achieved average scores around 67%, with minor performance
differences between larger and smaller models. Performance was slightly higher
in English than in French. Fine-tuned medical models showed some improvement
over their base versions in English but not in French. The uniformly high
performance across models suggests that traditional MCQ-based benchmarks may
not accurately measure LLMs' clinical knowledge and reasoning abilities,
instead highlighting their pattern recognition skills. This study underscores
the need for more robust evaluation methods to better assess the true
capabilities of LLMs in medical contexts.

摘要：大型語言模型（LLM），例如 ChatGPT，在醫療領域展現出顯著的潛力，通常使用與美國執業醫師資格考試 (USMLE) 中類似的多選題 (MCQ) 進行評估。儘管 MCQ 在醫學教育中很普遍，但在評估 LLM 時，其限制可能會被放大。為了評估 MCQ 在評估 LLM 效能方面的有效性，我們開發了一個虛構的醫療基準，重點關注一個不存在的腺體：Glianorex。這種方法讓我們能夠將 LLM 的知識與其應試能力隔離開來。我們使用 GPT-4 以英文和法文生成了關於 Glianorex 的一本綜合教科書，並開發了相應的多選題。我們在零次學習設定中使用這些問題評估了各種開源、專有和特定領域的 LLM。這些模型達到了平均約 67% 的分數，較大和較小模型之間的效能差異很小。英文的效能略高於法文。微調後的醫療模型在英文方面表現出比其基礎版本略有進步，但在法文方面則沒有。所有模型的效能均一致地高，這表明傳統基於 MCQ 的基準可能無法準確衡量 LLM 的臨床知識和推理能力，而僅突顯了它們的模式識別技能。這項研究強調了需要更強大的評估方法，以更好地評估 LLM 在醫療環境中的真實能力。

##### **LlamaCare: A Large Medical Language Model for Enhancing Healthcare Knowledge Sharing**
2406.02350v2 by Maojun Sun

Large language models (LLMs) have shown amazing capabilities in knowledge
memorization and the present. However, when it comes to domain-specific
knowledge and downstream tasks like medical, general LLMs are often unable to
give precise answers. In addition, when people want LLMs to answer
classification questions, they usually go through instruction tuning first.
However, LLMs do not always give a direct index of the categorization after
instruction tuning. In this paper, we proposed LlamaCare, a fine-tuned medical
language model, and Extended Classification Integration(ECI), a module to
handle classification problems of LLMs. Our contributions are : (i) We
fine-tuned a large language model of medical knowledge with very low carbon
emissions and achieved similar performance with ChatGPT by a 24G GPU. (ii) We
solved the problem of redundant categorical answers and improved the
performance of LLMs by proposing a new module called Extended Classification
Integration. (iii) We released our processed data for one-shot and few-shot
training for some benchmarks such as PubMedQA and USMLE 1-3 step. Our method
achieves a close performance comparable to some state-of-the-art models with
the same quantity of parameters on benchmarks, while being more environmentally
friendly by using less GPU computation time. Our models, codes, and datasets
can be found at \url{https://github.com/Stephen-SMJ/LLamaCare}.

摘要：大型語言模型 (LLM) 在知識記憶和現在展現出驚人的能力。然而，當涉及到特定領域的知識和下游任務（如醫療），一般的 LLM 通常無法給出精確的答案。此外，當人們希望 LLM 回答分類問題時，他們通常會先進行指令調整。然而，LLM 在指令調整後並非總是給出分類的直接指標。在本文中，我們提出了 LlamaCare，一種經過微調的醫學語言模型，以及擴展分類整合 (ECI)，一個用於處理 LLM 分類問題的模組。我們的貢獻是：(i) 我們微調了一個醫療知識的大語言模型，碳排放非常低，並通過 24G GPU 達到了與 ChatGPT 相似的效能。(ii) 我們解決了冗餘類別答案的問題，並通過提出一個稱為擴展分類整合的新模組來提升 LLM 的效能。(iii) 我們釋出了我們處理過的資料，用於 PubMedQA 和 USMLE 1-3 步驟等一些基準的單次和少次訓練。我們的模型在基準上達到了與一些最先進的模型相當的效能，同時透過減少 GPU 計算時間，對環境更友善。我們的模型、程式碼和資料集可以在 \url{https://github.com/Stephen-SMJ/LLamaCare} 找到。

##### **A Comparative Study of Sampling Methods with Cross-Validation in the FedHome Framework**
2406.01950v1 by Arash Ahmadi, Sarah S. Sharif, Yaser M. Banad

This paper presents a comparative study of sampling methods within the
FedHome framework, designed for personalized in-home health monitoring. FedHome
leverages federated learning (FL) and generative convolutional autoencoders
(GCAE) to train models on decentralized edge devices while prioritizing data
privacy. A notable challenge in this domain is the class imbalance in health
data, where critical events such as falls are underrepresented, adversely
affecting model performance. To address this, the research evaluates six
oversampling techniques using Stratified K-fold cross-validation: SMOTE,
Borderline-SMOTE, Random OverSampler, SMOTE-Tomek, SVM-SMOTE, and SMOTE-ENN.
These methods are tested on FedHome's public implementation over 200 training
rounds with and without stratified K-fold cross-validation. The findings
indicate that SMOTE-ENN achieves the most consistent test accuracy, with a
standard deviation range of 0.0167-0.0176, demonstrating stable performance
compared to other samplers. In contrast, SMOTE and SVM-SMOTE exhibit higher
variability in performance, as reflected by their wider standard deviation
ranges of 0.0157-0.0180 and 0.0155-0.0180, respectively. Similarly, the Random
OverSampler method shows a significant deviation range of 0.0155-0.0176.
SMOTE-Tomek, with a deviation range of 0.0160-0.0175, also shows greater
stability but not as much as SMOTE-ENN. This finding highlights the potential
of SMOTE-ENN to enhance the reliability and accuracy of personalized health
monitoring systems within the FedHome framework.

摘要：<paragraph>本文針對 FedHome 架構內的抽樣方法進行比較研究，該架構旨在進行個人化的居家健康監控。FedHome 採用聯邦學習 (FL) 和生成式卷積自動編碼器 (GCAE) 來訓練分散式邊緣裝置上的模型，同時優先考慮資料隱私。此領域的一項顯著挑戰是健康資料中的類別不平衡，其中跌倒等關鍵事件的代表性不足，對模型效能產生負面影響。為了解決此問題，本研究使用分層 K 倍交叉驗證評估六種過採樣技術：SMOTE、Borderline-SMOTE、隨機過採樣器、SMOTE-Tomek、SVM-SMOTE 和 SMOTE-ENN。這些方法在 FedHome 的公開實作中經過 200 輪訓練，使用和不使用分層 K 倍交叉驗證進行測試。研究結果表明，SMOTE-ENN 達到最穩定的測試準確度，標準差範圍為 0.0167-0.0176，與其他採樣器相比，表現出穩定的效能。相比之下，SMOTE 和 SVM-SMOTE 的效能變異性較高，標準差範圍分別為 0.0157-0.0180 和 0.0155-0.0180。同樣地，隨機過採樣器方法顯示出顯著的偏差範圍 0.0155-0.0176。偏差範圍為 0.0160-0.0175 的 SMOTE-Tomek 也顯示出較高的穩定性，但不如 SMOTE-ENN。此發現突顯了 SMOTE-ENN 在 FedHome 架構中增強個人化健康監控系統的可靠性和準確性的潛力。</paragraph>

##### **Enhancing Clinical Documentation with Synthetic Data: Leveraging Generative Models for Improved Accuracy**
2406.06569v1 by Anjanava Biswas, Wrick Talukdar

Accurate and comprehensive clinical documentation is crucial for delivering
high-quality healthcare, facilitating effective communication among providers,
and ensuring compliance with regulatory requirements. However, manual
transcription and data entry processes can be time-consuming, error-prone, and
susceptible to inconsistencies, leading to incomplete or inaccurate medical
records. This paper proposes a novel approach to augment clinical documentation
by leveraging synthetic data generation techniques to generate realistic and
diverse clinical transcripts. We present a methodology that combines
state-of-the-art generative models, such as Generative Adversarial Networks
(GANs) and Variational Autoencoders (VAEs), with real-world clinical transcript
and other forms of clinical data to generate synthetic transcripts. These
synthetic transcripts can then be used to supplement existing documentation
workflows, providing additional training data for natural language processing
models and enabling more accurate and efficient transcription processes.
Through extensive experiments on a large dataset of anonymized clinical
transcripts, we demonstrate the effectiveness of our approach in generating
high-quality synthetic transcripts that closely resemble real-world data.
Quantitative evaluation metrics, including perplexity scores and BLEU scores,
as well as qualitative assessments by domain experts, validate the fidelity and
utility of the generated synthetic transcripts. Our findings highlight
synthetic data generation's potential to address clinical documentation
challenges, improving patient care, reducing administrative burdens, and
enhancing healthcare system efficiency.

摘要：精確且全面的臨床文件對於提供高品質的醫療保健、促進提供者之間的有效溝通，以及確保符合法規要求至關重要。然而，手動轉錄和資料輸入程序可能耗時、容易出錯，且容易產生不一致，導致病歷不完整或不準確。本文提出了一種新穎的方法來擴充臨床文件，方法是利用合成資料生成技術來產生逼真且多樣的臨床轉錄。我們提出了一種結合了最先進的生成模型（例如生成對抗網路 (GAN) 和變分自動編碼器 (VAE)）的方法，並結合了真實世界的臨床轉錄和其他形式的臨床資料來產生合成轉錄。這些合成轉錄然後可以用於補充現有的文件工作流程，為自然語言處理模型提供額外的訓練資料，並實現更準確、更有效的轉錄流程。透過對大量的匿名化臨床轉錄進行廣泛的實驗，我們證明了我們的方法在產生與真實世界資料非常相似的優質合成轉錄方面的有效性。定量評估指標，包括困惑度分數和 BLEU 分數，以及領域專家的定性評估，驗證了生成的合成轉錄的保真度和效用。我們的研究結果強調了合成資料生成在解決臨床文件挑戰、改善患者照護、減輕行政負擔和提高醫療保健系統效率方面的潛力。

##### **Compute-Efficient Medical Image Classification with Softmax-Free Transformers and Sequence Normalization**
2406.01314v1 by Firas Khader, Omar S. M. El Nahhas, Tianyu Han, Gustav Müller-Franzes, Sven Nebelung, Jakob Nikolas Kather, Daniel Truhn

The Transformer model has been pivotal in advancing fields such as natural
language processing, speech recognition, and computer vision. However, a
critical limitation of this model is its quadratic computational and memory
complexity relative to the sequence length, which constrains its application to
longer sequences. This is especially crucial in medical imaging where
high-resolution images can reach gigapixel scale. Efforts to address this issue
have predominantely focused on complex techniques, such as decomposing the
softmax operation integral to the Transformer's architecture. This paper
addresses this quadratic computational complexity of Transformer models and
introduces a remarkably simple and effective method that circumvents this issue
by eliminating the softmax function from the attention mechanism and adopting a
sequence normalization technique for the key, query, and value tokens. Coupled
with a reordering of matrix multiplications this approach reduces the memory-
and compute complexity to a linear scale. We evaluate this approach across
various medical imaging datasets comprising fundoscopic, dermascopic,
radiologic and histologic imaging data. Our findings highlight that these
models exhibit a comparable performance to traditional transformer models,
while efficiently handling longer sequences.

摘要：Transformer 模型在自然語言處理、語音辨識和電腦視覺等領域的進展中發揮了關鍵作用。然而，此模型的一個重大限制是其二次計算和記憶體複雜度相對於序列長度，這限制了其在較長序列中的應用。這在醫療影像中尤其重要，其中高解析度影像可以達到吉像素等級。解決此問題的努力主要集中在複雜技術上，例如分解 Transformer 架構中不可或缺的 softmax 運算。本文探討了 Transformer 模型的二次計算複雜度，並介紹了一種非常簡單且有效的方法，透過從注意力機制中移除 softmax 函數並採用關鍵、查詢和值符號的序列正規化技術來解決此問題。結合矩陣乘法的重新排序，此方法將記憶體和運算複雜度降低到線性等級。我們在包含眼底鏡、皮膚鏡、放射學和組織學影像資料的各種醫學影像資料集上評估此方法。我們的發現強調，這些模型表現出與傳統 Transformer 模型相當的效能，同時有效地處理較長的序列。

##### **TCMBench: A Comprehensive Benchmark for Evaluating Large Language Models in Traditional Chinese Medicine**
2406.01126v1 by Wenjing Yue, Xiaoling Wang, Wei Zhu, Ming Guan, Huanran Zheng, Pengfei Wang, Changzhi Sun, Xin Ma

Large language models (LLMs) have performed remarkably well in various
natural language processing tasks by benchmarking, including in the Western
medical domain. However, the professional evaluation benchmarks for LLMs have
yet to be covered in the traditional Chinese medicine(TCM) domain, which has a
profound history and vast influence. To address this research gap, we introduce
TCM-Bench, an comprehensive benchmark for evaluating LLM performance in TCM. It
comprises the TCM-ED dataset, consisting of 5,473 questions sourced from the
TCM Licensing Exam (TCMLE), including 1,300 questions with authoritative
analysis. It covers the core components of TCMLE, including TCM basis and
clinical practice. To evaluate LLMs beyond accuracy of question answering, we
propose TCMScore, a metric tailored for evaluating the quality of answers
generated by LLMs for TCM related questions. It comprehensively considers the
consistency of TCM semantics and knowledge. After conducting comprehensive
experimental analyses from diverse perspectives, we can obtain the following
findings: (1) The unsatisfactory performance of LLMs on this benchmark
underscores their significant room for improvement in TCM. (2) Introducing
domain knowledge can enhance LLMs' performance. However, for in-domain models
like ZhongJing-TCM, the quality of generated analysis text has decreased, and
we hypothesize that their fine-tuning process affects the basic LLM
capabilities. (3) Traditional metrics for text generation quality like Rouge
and BertScore are susceptible to text length and surface semantic ambiguity,
while domain-specific metrics such as TCMScore can further supplement and
explain their evaluation results. These findings highlight the capabilities and
limitations of LLMs in the TCM and aim to provide a more profound assistance to
medical research.

摘要：<paragraph>大型語言模型 (LLM) 在各種自然語言處理任務中表現出色，包括在西方醫學領域。然而，LLM 的專業評估基準尚未涵蓋中醫領域，而中醫領域擁有深厚的歷史和廣泛的影響力。為了彌補這一研究空白，我們引入了 TCM-Bench，這是一個用於評估 LLM 在中醫領域表現的綜合基準。它包含 TCM-ED 數據集，其中包含 5,473 個來自中醫執照考試 (TCMLE) 的問題，包括 1,300 個具有權威分析的問題。它涵蓋了 TCMLE 的核心組成部分，包括中醫基礎和臨床實踐。為了評估 LLM 超越問題回答的準確性，我們提出了 TCMScore，這是一個專門用於評估 LLM 為中醫相關問題生成的答案質量的指標。它全面考慮了中醫語義和知識的一致性。在從不同角度進行綜合實驗分析後，我們可以得出以下發現：(1) LLM 在此基準上的表現不盡人意，這凸顯了它們在中醫領域有很大的改進空間。(2) 引入領域知識可以提升 LLM 的表現。然而，對於像 ZhongJing-TCM 這樣的領域模型，生成的分析文本的質量有所下降，我們假設它們的微調過程影響了基本的 LLM 能力。(3) 傳統的文本生成質量指標，例如 Rouge 和 BertScore，容易受到文本長度和表面語義模糊性的影響，而像 TCMScore 這樣的特定領域指標可以進一步補充和解釋它們的評估結果。這些發現突出了 LLM 在中醫領域的能力和局限性，並旨在為醫學研究提供更深入的幫助。</paragraph>

##### **Effective Subset Selection Through The Lens of Neural Network Pruning**
2406.01086v1 by Noga Bar, Raja Giryes

Having large amounts of annotated data significantly impacts the
effectiveness of deep neural networks. However, the annotation task can be very
expensive in some domains, such as medical data. Thus, it is important to
select the data to be annotated wisely, which is known as the subset selection
problem. We investigate the relationship between subset selection and neural
network pruning, which is more widely studied, and establish a correspondence
between them. Leveraging insights from network pruning, we propose utilizing
the norm criterion of neural network features to improve subset selection
methods. We empirically validate our proposed strategy on various networks and
datasets, demonstrating enhanced accuracy. This shows the potential of
employing pruning tools for subset selection.

摘要：擁有大量的註釋資料會顯著影響深度神經網路的效益。然而，在某些領域（例如醫學資料），註釋任務可能會非常昂貴。因此，明智地選擇要註釋的資料非常重要，這稱為子集選擇問題。我們探討子集選擇與神經網路剪枝之間的關係，後者研究得更廣泛，並在它們之間建立對應關係。利用網路剪枝的見解，我們建議利用神經網路特徵的範數準則來改善子集選擇方法。我們在各種網路和資料集上根據經驗驗證我們提出的策略，證明了增強的準確性。這顯示了使用剪枝工具進行子集選擇的潛力。

##### **Causal prompting model-based offline reinforcement learning**
2406.01065v1 by Xuehui Yu, Yi Guan, Rujia Shen, Xin Li, Chen Tang, Jingchi Jiang

Model-based offline Reinforcement Learning (RL) allows agents to fully
utilise pre-collected datasets without requiring additional or unethical
explorations. However, applying model-based offline RL to online systems
presents challenges, primarily due to the highly suboptimal (noise-filled) and
diverse nature of datasets generated by online systems. To tackle these issues,
we introduce the Causal Prompting Reinforcement Learning (CPRL) framework,
designed for highly suboptimal and resource-constrained online scenarios. The
initial phase of CPRL involves the introduction of the Hidden-Parameter Block
Causal Prompting Dynamic (Hip-BCPD) to model environmental dynamics. This
approach utilises invariant causal prompts and aligns hidden parameters to
generalise to new and diverse online users. In the subsequent phase, a single
policy is trained to address multiple tasks through the amalgamation of
reusable skills, circumventing the need for training from scratch. Experiments
conducted across datasets with varying levels of noise, including
simulation-based and real-world offline datasets from the Dnurse APP,
demonstrate that our proposed method can make robust decisions in
out-of-distribution and noisy environments, outperforming contemporary
algorithms. Additionally, we separately verify the contributions of Hip-BCPDs
and the skill-reuse strategy to the robustness of performance. We further
analyse the visualised structure of Hip-BCPD and the interpretability of
sub-skills. We released our source code and the first ever real-world medical
dataset for precise medical decision-making tasks.

摘要：<paragraph>基於模型的離線強化學習 (RL) 讓代理人能夠充分利用預先收集的資料集，而不需要額外的或不道德的探索。然而，將基於模型的離線 RL 應用於線上系統會帶來挑戰，主要是由於線上系統所產生的資料集具有高度次佳（充滿雜訊）和多樣化的特性。為了解決這些問題，我們引入了因果提示強化學習 (CPRL) 框架，專為高度次佳和資源受限的線上場景而設計。CPRL 的初始階段涉及引入隱藏參數區塊因果提示動態 (Hip-BCPD) 來建模環境動態。此方法利用不變的因果提示並調整隱藏參數以概括到新的和多樣化的線上使用者。在後續階段，訓練單一政策以透過合併可重複使用的技能來處理多項任務，規避從頭開始訓練的需要。在具有不同雜訊層級的資料集上進行的實驗，包括來自 Dnurse APP 的基於模擬和真實世界的離線資料集，證明我們提出的方法可以在超出分佈和雜訊環境中做出穩健的決策，優於當代演算法。此外，我們分別驗證了 Hip-BCPD 和技能重用策略對效能穩健性的貢獻。我們進一步分析了 Hip-BCPD 的可視化結構和子技能的可解釋性。我們發布了我們的原始碼和第一個用於精確醫療決策任務的真實世界醫療資料集。</paragraph>

##### **Synthetic Data Generation for 3D Myocardium Deformation Analysis**
2406.01040v1 by Shahar Zuler, Dan Raviv

Accurate analysis of 3D myocardium deformation using high-resolution
computerized tomography (CT) datasets with ground truth (GT) annotations is
crucial for advancing cardiovascular imaging research. However, the scarcity of
such datasets poses a significant challenge for developing robust myocardium
deformation analysis models. To address this, we propose a novel approach to
synthetic data generation for enriching cardiovascular imaging datasets.
  We introduce a synthetic data generation method, enriched with crucial GT 3D
optical flow annotations. We outline the data preparation from a cardiac
four-dimensional (4D) CT scan, selection of parameters, and the subsequent
creation of synthetic data from the same or other sources of 3D cardiac CT data
for training.
  Our work contributes to overcoming the limitations imposed by the scarcity of
high-resolution CT datasets with precise annotations, thereby facilitating the
development of accurate and reliable myocardium deformation analysis algorithms
for clinical applications and diagnostics.
  Our code is available at:
http://www.github.com/shaharzuler/cardio_volume_skewer

摘要：使用帶有真實 (GT) 標註的高解析度電腦斷層掃描 (CT) 資料集準確分析 3D 心肌變形對於推進心血管影像研究至關重要。然而，此類資料集的稀少對開發強健的心肌變形分析模型構成重大挑戰。為了解決這個問題，我們提出了一種創新的合成資料生成方法，用於豐富心血管影像資料集。
  我們介紹了一種合成資料生成方法，其中包含了重要的 GT 3D 光流標註。我們概述了從心臟四維 (4D) CT 掃描中準備資料、選擇參數，以及隨後從相同或其他來源的 3D 心臟 CT 資料中建立合成資料以進行訓練的過程。
  我們的研究有助於克服高解析度 CT 資料集標註不精確的限制，從而促進開發適用於臨床應用和診斷的準確且可靠的心肌變形分析演算法。
  我們的程式碼可在以下網址取得：
http://www.github.com/shaharzuler/cardio_volume_skewer

##### **MEDIQ: Question-Asking LLMs for Adaptive and Reliable Clinical Reasoning**
2406.00922v2 by Shuyue Stella Li, Vidhisha Balachandran, Shangbin Feng, Jonathan Ilgen, Emma Pierson, Pang Wei Koh, Yulia Tsvetkov

In high-stakes domains like clinical reasoning, AI assistants powered by
large language models (LLMs) are yet to be reliable and safe. We identify a key
obstacle towards reliability: existing LLMs are trained to answer any question,
even with incomplete context in the prompt or insufficient parametric
knowledge. We propose to change this paradigm to develop more careful LLMs that
ask follow-up questions to gather necessary and sufficient information and
respond reliably. We introduce MEDIQ, a framework to simulate realistic
clinical interactions, which incorporates a Patient System and an adaptive
Expert System. The Patient may provide incomplete information in the beginning;
the Expert refrains from making diagnostic decisions when unconfident, and
instead elicits missing details from the Patient via follow-up questions. To
evaluate MEDIQ, we convert MEDQA and CRAFT-MD -- medical benchmarks for
diagnostic question answering -- into an interactive setup. We develop a
reliable Patient system and prototype several Expert systems, first showing
that directly prompting state-of-the-art LLMs to ask questions degrades the
quality of clinical reasoning, indicating that adapting LLMs to interactive
information-seeking settings is nontrivial. We then augment the Expert with a
novel abstention module to better estimate model confidence and decide whether
to ask more questions, thereby improving diagnostic accuracy by 20.3%; however,
performance still lags compared to an (unrealistic in practice) upper bound
when full information is given upfront. Further analyses reveal that
interactive performance can be improved by filtering irrelevant contexts and
reformatting conversations. Overall, our paper introduces a novel problem
towards LLM reliability, a novel MEDIQ framework, and highlights important
future directions to extend the information-seeking abilities of LLM assistants
in critical domains.

摘要：<paragraph>在臨床推理等高風險領域，由大型語言模型 (LLM) 提供支援的 AI 助理仍未達到可靠和安全的程度。我們找出可靠性的一個主要障礙：現有的 LLM 經過訓練可以回答任何問題，即使提示中的內容不完整或參數知識不足。我們建議改變這種模式，開發出更謹慎的 LLM，它們會提出後續問題來收集必要且充分的資訊，並做出可靠的回應。我們推出 MEDIQ，一個模擬現實臨床互動的架構，它包含一個病人系統和一個適應性專家系統。病人一開始可能會提供不完整的資訊；專家在不確定的時候會避免做出診斷決策，而是透過後續問題從病人那裡引出遺漏的細節。為了評估 MEDIQ，我們將 MEDQA 和 CRAFT-MD（用於診斷性問答的醫療基準）轉換為互動式設定。我們開發了一個可靠的病人系統和幾個專家系統原型，首先表明直接提示最先進的 LLM 提出問題會降低臨床推理的品質，這表示將 LLM 適應到互動式資訊尋求設定並非易事。然後，我們使用一個新穎的棄權模組擴充專家，以更好地估計模型的信心並決定是否要提出更多問題，從而將診斷準確率提高 20.3%；然而，與在最開始就給予完整資訊的（在實務上不切實際的）上限相比，效能仍然落後。進一步的分析顯示，互動效能可以透過過濾不相關的內容和重新格式化對話來改善。總體而言，我們的論文針對 LLM 可靠性提出一個新問題、一個新穎的 MEDIQ 架構，並強調在關鍵領域擴展 LLM 助理資訊尋求能力的重要未來方向。</paragraph>

##### **Bayesian Joint Additive Factor Models for Multiview Learning**
2406.00778v1 by Niccolo Anceschi, Federico Ferrari, David B. Dunson, Himel Mallick

It is increasingly common in a wide variety of applied settings to collect
data of multiple different types on the same set of samples. Our particular
focus in this article is on studying relationships between such multiview
features and responses. A motivating application arises in the context of
precision medicine where multi-omics data are collected to correlate with
clinical outcomes. It is of interest to infer dependence within and across
views while combining multimodal information to improve the prediction of
outcomes. The signal-to-noise ratio can vary substantially across views,
motivating more nuanced statistical tools beyond standard late and early
fusion. This challenge comes with the need to preserve interpretability, select
features, and obtain accurate uncertainty quantification. We propose a joint
additive factor regression model (JAFAR) with a structured additive design,
accounting for shared and view-specific components. We ensure identifiability
via a novel dependent cumulative shrinkage process (D-CUSP) prior. We provide
an efficient implementation via a partially collapsed Gibbs sampler and extend
our approach to allow flexible feature and outcome distributions. Prediction of
time-to-labor onset from immunome, metabolome, and proteome data illustrates
performance gains against state-of-the-art competitors. Our open-source
software (R package) is available at https://github.com/niccoloanceschi/jafar.

摘要：在各种应用设置中，针对同一组样本收集多种不同类型的数据变得越来越普遍。本文的重点是研究此类多视图特征和响应之间的关系。一个激励性的应用出现在精准医学的背景中，其中收集多组学数据以与临床结果相关联。在结合多模式信息以改善结果预测时，推断视图内和视图之间的依赖性非常重要。信噪比在不同视图之间可能会有很大差异，这促使人们在标准的后期和早期融合之外采用更细致的统计工具。这一挑战伴随着需要保持可解释性、选择特征和获得准确的不确定性量化。我们提出了一个具有结构化加法设计的联合加法因子回归模型 (JAFAR)，它考虑了共享和特定于视图的组件。我们通过一个新颖的依赖累积收缩过程 (D-CUSP) 先验确保可识别性。我们通过部分折叠的 Gibbs 采样器提供高效的实现，并扩展我们的方法以允许灵活的特征和结果分布。从免疫组、代谢组和蛋白质组数据预测分娩开始时间说明了针对最先进竞争对手的性能提升。我们的开源软件（R 包）可在 https://github.com/niccoloanceschi/jafar 获得。

##### **An Early Investigation into the Utility of Multimodal Large Language Models in Medical Imaging**
2406.00667v1 by Sulaiman Khan, Md. Rafiul Biswas, Alina Murad, Hazrat Ali, Zubair Shah

Recent developments in multimodal large language models (MLLMs) have spurred
significant interest in their potential applications across various medical
imaging domains. On the one hand, there is a temptation to use these generative
models to synthesize realistic-looking medical image data, while on the other
hand, the ability to identify synthetic image data in a pool of data is also
significantly important. In this study, we explore the potential of the Gemini
(\textit{gemini-1.0-pro-vision-latest}) and GPT-4V (gpt-4-vision-preview)
models for medical image analysis using two modalities of medical image data.
Utilizing synthetic and real imaging data, both Gemini AI and GPT-4V are first
used to classify real versus synthetic images, followed by an interpretation
and analysis of the input images. Experimental results demonstrate that both
Gemini and GPT-4 could perform some interpretation of the input images. In this
specific experiment, Gemini was able to perform slightly better than the GPT-4V
on the classification task. In contrast, responses associated with GPT-4V were
mostly generic in nature. Our early investigation presented in this work
provides insights into the potential of MLLMs to assist with the classification
and interpretation of retinal fundoscopy and lung X-ray images. We also
identify key limitations associated with the early investigation study on MLLMs
for specialized tasks in medical image analysis.

摘要：最近多模态大型语言模型 (MLLM) 的发展激发了人们对其在各种医学影像领域的潜在应用的浓厚兴趣。一方面，人们很想使用这些生成模型来合成逼真的医学影像数据，而另一方面，在数据池中识别合成影像数据的能力也极其重要。在本研究中，我们探讨了 Gemini (\textit{gemini-1.0-pro-vision-latest}) 和 GPT-4V (gpt-4-vision-preview) 模型在使用两种医学影像数据模态进行医学影像分析方面的潜力。利用合成和真实成像数据，Gemini AI 和 GPT-4V 首先用于对真实图像和合成图像进行分类，然后对输入图像进行解释和分析。实验结果表明，Gemini 和 GPT-4 都可以对输入图像进行一些解释。在这个具体实验中，Gemini 在分类任务上的表现略好于 GPT-4V。相比之下，与 GPT-4V 相关的响应大多是通用的。我们在这项工作中提出的早期调查提供了关于 MLLM 协助分类和解释视网膜眼底镜和肺部 X 射线图像的潜力的见解。我们还确定了与针对医学影像分析中的专门任务的 MLLM 早期调查研究相关的关键限制。

##### **SimSAM: Zero-shot Medical Image Segmentation via Simulated Interaction**
2406.00663v1 by Benjamin Towle, Xin Chen, Ke Zhou

The recently released Segment Anything Model (SAM) has shown powerful
zero-shot segmentation capabilities through a semi-automatic annotation setup
in which the user can provide a prompt in the form of clicks or bounding boxes.
There is growing interest around applying this to medical imaging, where the
cost of obtaining expert annotations is high, privacy restrictions may limit
sharing of patient data, and model generalisation is often poor. However, there
are large amounts of inherent uncertainty in medical images, due to unclear
object boundaries, low-contrast media, and differences in expert labelling
style. Currently, SAM is known to struggle in a zero-shot setting to adequately
annotate the contours of the structure of interest in medical images, where the
uncertainty is often greatest, thus requiring significant manual correction. To
mitigate this, we introduce \textbf{Sim}ulated Interaction for \textbf{S}egment
\textbf{A}nything \textbf{M}odel (\textsc{\textbf{SimSAM}}), an approach that
leverages simulated user interaction to generate an arbitrary number of
candidate masks, and uses a novel aggregation approach to output the most
compatible mask. Crucially, our method can be used during inference directly on
top of SAM, without any additional training requirement. Quantitatively, we
evaluate our method across three publicly available medical imaging datasets,
and find that our approach leads to up to a 15.5\% improvement in contour
segmentation accuracy compared to zero-shot SAM. Our code is available at
\url{https://github.com/BenjaminTowle/SimSAM}.

摘要：最近发布的 Segment Anything Model (SAM) 已通过半自动注释设置展示了强大的零次分段能力，其中用户可以通过单击或边界框的形式提供提示。人们越来越有兴趣将此应用于医学影像，其中获得专家注释的成本很高，隐私限制可能会限制患者数据的共享，并且模型泛化通常很差。然而，由于对象的边界不清、介质对比度低以及专家标记风格的差异，医学影像中存在大量固有的不确定性。目前，已知 SAM 在零次设置中难以充分注释医学影像中感兴趣结构的轮廓，其中不确定性通常最大，因此需要大量的手动校正。为了缓解这种情况，我们引入了 \textbf{S}imulated \textbf{I}nteraction for \textbf{S}egment \textbf{A}nything \textbf{M}odel (\textsc{\textbf{SimSAM}}），这是一种利用模拟用户交互来生成任意数量的候选掩码的方法，并使用新颖的聚合方法来输出最兼容的掩码。至关重要的是，我们的方法可以直接在 SAM 之上使用，而无需任何额外的训练要求。在数量方面，我们对三种公开的医学影像数据集评估了我们的方法，并发现与零次 SAM 相比，我们的方法在轮廓分段准确性方面提高了 15.5%。我们的代码可在 \url{https://github.com/BenjaminTowle/SimSAM} 获得。

##### **Multimodal Deep Learning for Low-Resource Settings: A Vector Embedding Alignment Approach for Healthcare Applications**
2406.02601v1 by David Restrepo, Chenwei Wu, Sebastián Andrés Cajas, Luis Filipe Nakayama, Leo Anthony Celi, Diego M López

Large-scale multi-modal deep learning models have revolutionized domains such
as healthcare, highlighting the importance of computational power. However, in
resource-constrained regions like Low and Middle-Income Countries (LMICs),
limited access to GPUs and data poses significant challenges, often leaving
CPUs as the sole resource. To address this, we advocate for leveraging vector
embeddings to enable flexible and efficient computational methodologies,
democratizing multimodal deep learning across diverse contexts.
  Our paper investigates the efficiency and effectiveness of using vector
embeddings from single-modal foundation models and multi-modal Vision-Language
Models (VLMs) for multimodal deep learning in low-resource environments,
particularly in healthcare. Additionally, we propose a simple yet effective
inference-time method to enhance performance by aligning image-text embeddings.
Comparing these approaches with traditional methods, we assess their impact on
computational efficiency and model performance using metrics like accuracy,
F1-score, inference time, training time, and memory usage across three medical
modalities: BRSET (ophthalmology), HAM10000 (dermatology), and SatelliteBench
(public health).
  Our findings show that embeddings reduce computational demands without
compromising model performance. Furthermore, our alignment method improves
performance in medical tasks. This research promotes sustainable AI practices
by optimizing resources in constrained environments, highlighting the potential
of embedding-based approaches for efficient multimodal learning. Vector
embeddings democratize multimodal deep learning in LMICs, particularly in
healthcare, enhancing AI adaptability in varied use cases.

摘要：<paragraph>大型多模态深度学习模型已经彻底改变了医疗保健等领域，突出了计算能力的重要性。然而，在资源受限的地区，如低收入和中等收入国家 (LMIC)，受限的 GPU 和数据访问带来了重大挑战，通常只剩下 CPU 作为唯一资源。为了解决这个问题，我们提倡利用向量嵌入来实现灵活高效的计算方法，让多模态深度学习在不同的环境中实现民主化。
我们的论文研究了在资源受限的环境中，使用来自单模态基础模型和多模态视觉语言模型 (VLM) 的向量嵌入进行多模态深度学习的效率和有效性，特别是在医疗保健领域。此外，我们提出了一种简单而有效推理时间方法，通过对齐图像文本嵌入来增强性能。将这些方法与传统方法进行比较，我们评估了它们对计算效率和模型性能的影响，使用准确度、F1 分数、推理时间、训练时间和内存使用等指标，跨越三个医学模态：BRSET（眼科）、HAM10000（皮肤病学）和 SatelliteBench（公共卫生）。
我们的研究结果表明，嵌入可以降低计算需求，同时不影响模型性能。此外，我们的对齐方法提高了医学任务的性能。这项研究通过优化受限环境中的资源，促进了可持续的 AI 实践，突出了基于嵌入的方法在高效多模态学习中的潜力。向量嵌入让 LMIC 中的多模态深度学习实现民主化，特别是在医疗保健领域，增强了 AI 在各种用例中的适应性。</paragraph>

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

摘要：乳癌 (BC) 是影響全球女性最常見的惡性腫瘤之一，因此需要進步的診斷方法，以改善臨床結果。本文全面探討了可解釋人工智慧 (XAI) 技術在乳癌偵測和診斷中的應用。隨著人工智慧 (AI) 技術持續滲透醫療保健領域，特別是在腫瘤學中，透明且可解釋的模型需求變得勢在必行，以增強臨床決策制定和患者照護。此篇評論探討了各種 XAI 方法的整合，例如 SHAP、LIME、Grad-CAM 等，以及用於乳癌偵測和分類的機器學習和深度學習模型。透過探討乳癌資料集的模式，包括乳房攝影、超音波及其在 AI 中的處理，本文重點說明 XAI 如何能導致更準確的診斷和個人化治療計畫。它也探討了實施這些技術的挑戰，以及制定標準化評量指標以評估 XAI 在臨床環境中的有效性的重要性。透過詳細的分析和討論，本文旨在強調 XAI 在縮小複雜 AI 模型與實務醫療保健應用之間差距的潛力，進而促進醫療專業人員之間的信任與理解，並改善患者的結果。

##### **CASE: Curricular Data Pre-training for Building Generative and Discriminative Assistive Psychology Expert Models**
2406.00314v1 by Sarthak Harne, Monjoy Narayan Choudhury, Madhav Rao, TK Srikanth, Seema Mehrotra, Apoorva Vashisht, Aarushi Basu, Manjit Sodhi

The limited availability of psychologists necessitates efficient
identification of individuals requiring urgent mental healthcare. This study
explores the use of Natural Language Processing (NLP) pipelines to analyze text
data from online mental health forums used for consultations. By analyzing
forum posts, these pipelines can flag users who may require immediate
professional attention. A crucial challenge in this domain is data privacy and
scarcity. To address this, we propose utilizing readily available curricular
texts used in institutes specializing in mental health for pre-training the NLP
pipelines. This helps us mimic the training process of a psychologist. Our work
presents two models: a discriminative BERT-based model called CASE-BERT that
flags potential mental health disorders based on forum text, and a generative
model called CASE-Gemma that extracts key features for a preliminary diagnosis.
CASE-BERT demonstrates superior performance compared to existing methods,
achieving an f1 score of 0.91 for Depression and 0.88 for Anxiety, two of the
most commonly reported mental health disorders. CASE-Gemma can achieve a BERT
Score of 0.849 on generating diagnoses based on forum text. The effectiveness
of CASE-Gemma is evaluated through both human evaluation and qualitative
methods, with the collaboration of clinical psychologists who provide us with a
set of annotated data for fine-tuning and evaluation. Our code is available at
https://github.com/sarthakharne/CASE

摘要：由於心理學家數量有限，因此有必要有效找出需要緊急心理保健的個人。本研究探討使用自然語言處理 (NLP) 管線來分析線上心理健康論壇中用於諮詢的文字資料。透過分析論壇文章，這些管線可以標記可能需要立即專業協助的使用者。此領域中的關鍵挑戰是資料隱私和稀少性。為了解決此問題，我們建議利用心理健康專門機構中現成的課程文本，作為 NLP 管線預訓練。這有助於我們模擬心理學家的訓練過程。我們的研究提出了兩個模型：一個稱為 CASE-BERT 的判別式 BERT 模型，可根據論壇文字標記潛在的心理健康障礙；以及一個稱為 CASE-Gemma 的生成式模型，可萃取初步診斷的關鍵特徵。與現有方法相比，CASE-BERT 展現出優異的效能，在憂鬱症和焦慮症（兩種最常報告的心理健康障礙）的 f1 分數分別達到 0.91 和 0.88。CASE-Gemma 可以根據論壇文字產生診斷，並在 BERT 分數上達到 0.849。我們透過人為評估和質性方法，以及與臨床心理學家的合作（他們提供我們一組註解資料，用於微調和評估），來評估 CASE-Gemma 的有效性。我們的程式碼可在 https://github.com/sarthakharne/CASE 取得

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

摘要：語音情緒辨識 (SER) 由於其在心理健康、教育和人機互動等多個應用領域而備受關注。然而，SER 系統的準確性受到高維特徵集的阻礙，這些特徵集可能包含不相關和冗餘的資訊。為了克服這個挑戰，本研究提出了一種用於 SER 的迭代特徵提升方法，該方法強調特徵相關性和可解釋性，以增強機器學習模型的效能。我們的做法涉及仔細的特徵選擇和分析，以建立高效的 SER 系統。為了透過模型可解釋性解決我們的核心問題，我們採用了具有 Shapley 值的特徵評估迴圈，以反覆改善特徵集。這個過程在模型效能和透明度之間取得平衡，這使得我們能夠全面了解模型的預測。所提出的方法提供了多項優點，包括識別和移除不相關和冗餘的特徵，從而建立更有效的模型。此外，它促進了可解釋性，有助於理解模型的預測以及識別情緒決定的關鍵特徵。所提出的方法的有效性已在多倫多情緒語音集 (TESS)、柏林情緒語音資料庫 (EMO-DB)、賴爾森音訊視覺情緒語音和歌曲資料庫 (RAVDESS) 和薩里音訊視覺表達情緒 (SAVEE) 資料集的 SER 基準上得到驗證，其效能優於現有方法。據我們所知，這是第一個將模型可解釋性納入 SER 架構的研究。本文的原始碼可透過此連結公開取得：https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition。

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, Héloïse de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

摘要：可解释性通常对于人工智能 (AI) 的可接受实施至关重要。在医疗保健领域，这一点尤为重要，因为决策直接影响患者，并且对 AI 系统的信任至关重要。这种信任通常建立在 AI 提供的解释和诠释之上。尽管 AI 可解释性取得了重大进展，但仍然需要明确的指导方针，说明在医疗环境中何时以及在多大程度上需要解释。我们提出了一种新颖的分类系统，该系统具有四种不同的解释必要性类别，指导所需的解释级别：患者或样本（局部）级别、队列或数据集（全局）级别，或两个级别。我们引入了一个数学公式，该公式区分了这些类别，并为研究人员提供了一个实用框架，以确定医疗 AI 应用中所需的解释的必要性和深度。考虑了三个关键因素：评估协议的稳健性、专家观察的可变性以及应用程序的表示维数。从这个角度来看，我们解决了这个问题：AI 医疗应用何时需要解释，以及需要解释到何种程度？

##### **DYNA: Disease-Specific Language Model for Variant Pathogenicity**
2406.00164v1 by Huixin Zhan, Zijun Zhang

Clinical variant classification of pathogenic versus benign genetic variants
remains a challenge in clinical genetics. Recently, the proposition of genomic
foundation models has improved the generic variant effect prediction (VEP)
accuracy via weakly-supervised or unsupervised training. However, these VEPs
are not disease-specific, limiting their adaptation at the point of care. To
address this problem, we propose DYNA: Disease-specificity fine-tuning via a
Siamese neural network broadly applicable to all genomic foundation models for
more effective variant effect predictions in disease-specific contexts. We
evaluate DYNA in two distinct disease-relevant tasks. For coding VEPs, we focus
on various cardiovascular diseases, where gene-disease relationships of
loss-of-function vs. gain-of-function dictate disease-specific VEP. For
non-coding VEPs, we apply DYNA to an essential post-transcriptional regulatory
axis of RNA splicing, the most common non-coding pathogenic mechanism in
established clinical VEP guidelines. In both cases, DYNA fine-tunes various
pre-trained genomic foundation models on small, rare variant sets. The DYNA
fine-tuned models show superior performance in the held-out rare variant
testing set and are further replicated in large, clinically-relevant variant
annotations in ClinVAR. Thus, DYNA offers a potent disease-specific variant
effect prediction method, excelling in intra-gene generalization and
generalization to unseen genetic variants, making it particularly valuable for
disease associations and clinical applicability.

摘要：臨床遺傳學中，致病性遺傳變異與良性遺傳變異的臨床變異分類仍然是一項挑戰。最近，基因體基礎模型的提議透過弱監督或無監督訓練改善了通用變異效應預測 (VEP) 的準確性。然而，這些 VEP 沒有疾病特異性，限制了它們在照護點的適應性。為了解決這個問題，我們提出了 DYNA：透過 Siamese 神經網路進行疾病特異性微調，廣泛適用於所有基因體基礎模型，以在疾病特異性背景中進行更有效的變異效應預測。我們在兩個不同的疾病相關任務中評估 DYNA。對於編碼 VEP，我們專注於各種心血管疾病，其中致病性與功能獲得之間的基因疾病關係決定了疾病特異性 VEP。對於非編碼 VEP，我們將 DYNA 應用於 RNA 剪接的基本轉錄後調控軸，這是已建立的臨床 VEP 指南中最常見的非編碼致病機制。在兩種情況下，DYNA 都微調了各種預訓練的基因體基礎模型，針對小型、罕見的變異組。DYNA 微調模型在保留的罕見變異測試組中表現出優異的效能，並進一步複製於 ClinVAR 中大型、臨床上相關的變異註解。因此，DYNA 提供了一種有效的疾病特異性變異效應預測方法，在基因內概化和對未見遺傳變異的概化方面表現出色，使其對於疾病關聯和臨床應用特別有價值。

##### **Recurrent neural networks: vanishing and exploding gradients are not the end of the story**
2405.21064v1 by Nicolas Zucchet, Antonio Orvieto

Recurrent neural networks (RNNs) notoriously struggle to learn long-term
memories, primarily due to vanishing and exploding gradients. The recent
success of state-space models (SSMs), a subclass of RNNs, to overcome such
difficulties challenges our theoretical understanding. In this paper, we delve
into the optimization challenges of RNNs and discover that, as the memory of a
network increases, changes in its parameters result in increasingly large
output variations, making gradient-based learning highly sensitive, even
without exploding gradients. Our analysis further reveals the importance of the
element-wise recurrence design pattern combined with careful parametrizations
in mitigating this effect. This feature is present in SSMs, as well as in other
architectures, such as LSTMs. Overall, our insights provide a new explanation
for some of the difficulties in gradient-based learning of RNNs and why some
architectures perform better than others.

摘要：遞迴神經網路 (RNN) 惡名昭彰地難以學習長期記憶，主要是由於消失和爆炸梯度。最近，作為 RNN 子類的狀態空間模型 (SSM) 在克服此類困難方面獲得成功，這挑戰了我們的理論理解。在本文中，我們深入探討 RNN 的最佳化挑戰，並發現隨著網路記憶的增加，其參數的變化會導致越來越大的輸出變化，使得基於梯度的學習高度敏感，即使沒有爆炸梯度。我們的分析進一步揭示了逐元素遞迴設計模式與仔細參數化相結合在減輕此效應方面的重要性。此功能存在於 SSM 以及其他架構中，例如 LSTM。總體而言，我們的見解為 RNN 基於梯度的學習中的一些困難提供了一個新的解釋，並說明了為什麼某些架構的表現優於其他架構。

##### **Generative Adversarial Networks in Ultrasound Imaging: Extending Field of View Beyond Conventional Limits**
2405.20981v1 by Matej Gazda, Samuel Kadoury, Jakub Gazda, Peter Drotar

Transthoracic Echocardiography (TTE) is a fundamental, non-invasive
diagnostic tool in cardiovascular medicine, enabling detailed visualization of
cardiac structures crucial for diagnosing various heart conditions. Despite its
widespread use, TTE ultrasound imaging faces inherent limitations, notably the
trade-off between field of view (FoV) and resolution. This paper introduces a
novel application of conditional Generative Adversarial Networks (cGANs),
specifically designed to extend the FoV in TTE ultrasound imaging while
maintaining high resolution. Our proposed cGAN architecture, termed echoGAN,
demonstrates the capability to generate realistic anatomical structures through
outpainting, effectively broadening the viewable area in medical imaging. This
advancement has the potential to enhance both automatic and manual ultrasound
navigation, offering a more comprehensive view that could significantly reduce
the learning curve associated with ultrasound imaging and aid in more accurate
diagnoses. The results confirm that echoGAN reliably reproduce detailed cardiac
features, thereby promising a significant step forward in the field of
non-invasive cardiac naviagation and diagnostics.

摘要：經胸超音波心臟圖 (TTE) 是心血管醫學中的一項基本非侵入性診斷工具，能詳細視覺化心臟結構，對於診斷各種心臟疾病至關重要。儘管 TTE 超音波影像廣泛使用，但它面臨著固有的限制，特別是在視野 (FoV) 和解析度之間的權衡。本文介紹了一種條件生成對抗網路 (cGANs) 的新應用，專門設計用於擴展 TTE 超音波影像的視野，同時保持高解析度。我們提出的 cGAN 架構稱為 echoGAN，它展示了透過外繪來生成逼真的解剖結構的能力，有效地擴展了醫學影像中的可視區域。這項進展有可能增強自動和手動超音波導航，提供更全面的視野，這可以大幅縮短與超音波影像相關的學習曲線，並有助於更準確的診斷。結果證實，echoGAN 可靠地重現詳細的心臟特徵，從而有望在非侵入性心臟導航和診斷領域邁出重要一步。

##### **OR-Bench: An Over-Refusal Benchmark for Large Language Models**
2405.20947v1 by Justin Cui, Wei-Lin Chiang, Ion Stoica, Cho-Jui Hsieh

Large Language Models (LLMs) require careful safety alignment to prevent
malicious outputs. While significant research focuses on mitigating harmful
content generation, the enhanced safety often come with the side effect of
over-refusal, where the LLMs may reject innocuous prompts and become less
helpful. Although the issue of over-refusal has been empirically observed, a
systematic measurement is challenging due to the difficulty of crafting prompts
that appear harmful but are benign. This study proposes a novel method for
automatically generating large-scale sets of ``seemingly toxic prompts''
(benign prompts likely rejected by LLMs). Leveraging this technique, we
introduce OR-Bench, the first large-scale over-refusal benchmark. OR-Bench
comprises 80,000 seemingly toxic prompts across 10 common rejection categories,
a subset of around 1,000 hard prompts that are challenging even for
state-of-the-art LLMs, and an additional 600 toxic prompts to prevent
indiscriminate responses. We then conduct a comprehensive study to measure the
over-refusal of 25 popular LLMs across 8 model families. Our datasets are
available at https://huggingface.co/datasets/bench-llm/OR-Bench and the
corresponding demo can be found at
https://huggingface.co/spaces/bench-llm/or-bench. We hope this benchmark can
help the community develop better safety aligned models.

摘要：大型語言模型 (LLM) 需要謹慎的安全調整，以防止惡意輸出。雖然重要的研究專注於減輕有害內容的產生，但增強的安全通常會產生過度拒絕的副作用，LLM 可能拒絕無害的提示並變得不那麼有幫助。儘管已經經驗性地觀察到過度拒絕的問題，但由於難以撰寫看似有害但良性的提示，因此系統性的測量具有挑戰性。本研究提出了一種自動產生大量「看似有毒的提示」集合（可能被 LLM 拒絕的良性提示）的新方法。利用此技術，我們引入了 OR-Bench，這是第一個大規模的過度拒絕基準。OR-Bench 包含 10 個常見拒絕類別中的 80,000 個看似有毒的提示，一個由約 1,000 個即使對於最先進的 LLM 來說也很有挑戰性的困難提示子集，以及額外的 600 個有毒提示，以防止不加區別的回應。然後，我們進行了一項全面研究，以測量 8 個模型系列中的 25 個流行 LLM 的過度拒絕。我們的數據集可在 https://huggingface.co/datasets/bench-llm/OR-Bench 獲得，可以在 https://huggingface.co/spaces/bench-llm/or-bench 找到對應的示範。我們希望此基準可以幫助社群開發更好的安全調整模型。

##### **ABodyBuilder3: Improved and scalable antibody structure predictions**
2405.20863v1 by Henry Kenlay, Frédéric A. Dreyer, Daniel Cutting, Daniel Nissley, Charlotte M. Deane

Accurate prediction of antibody structure is a central task in the design and
development of monoclonal antibodies, notably to understand both their
developability and their binding properties. In this article, we introduce
ABodyBuilder3, an improved and scalable antibody structure prediction model
based on ImmuneBuilder. We achieve a new state-of-the-art accuracy in the
modelling of CDR loops by leveraging language model embeddings, and show how
predicted structures can be further improved through careful relaxation
strategies. Finally, we incorporate a predicted Local Distance Difference Test
into the model output to allow for a more accurate estimation of uncertainties.

摘要：精準預測抗體結構是單株抗體設計和開發中的核心任務，特別是為了了解它們的可開發性和結合特性。在本文中，我們介紹了 ABodyBuilder3，這是一個基於 ImmuneBuilder 的改良且可擴充的抗體結構預測模型。我們透過利用語言模型嵌入，在 CDR 迴圈建模中達到了新的最先進準確度，並展示了如何透過謹慎的放鬆策略進一步改善預測結構。最後，我們將預測的局部距離差異測試納入模型輸出，以更準確地估計不確定性。

##### **Maximum Temperature Prediction Using Remote Sensing Data Via Convolutional Neural Network**
2405.20731v1 by Lorenzo Innocenti, Giacomo Blanco, Luca Barco, Claudio Rossi

Urban heat islands, defined as specific zones exhibiting substantially higher
temperatures than their immediate environs, pose significant threats to
environmental sustainability and public health. This study introduces a novel
machine-learning model that amalgamates data from the Sentinel-3 satellite,
meteorological predictions, and additional remote sensing inputs. The primary
aim is to generate detailed spatiotemporal maps that forecast the peak
temperatures within a 24-hour period in Turin. Experimental results validate
the model's proficiency in predicting temperature patterns, achieving a Mean
Absolute Error (MAE) of 2.09 degrees Celsius for the year 2023 at a resolution
of 20 meters per pixel, thereby enriching our knowledge of urban climatic
behavior. This investigation enhances the understanding of urban microclimates,
emphasizing the importance of cross-disciplinary data integration, and laying
the groundwork for informed policy-making aimed at alleviating the negative
impacts of extreme urban temperatures.

摘要：都市熱島效應是指特定區域的溫度明顯高於周圍環境，對環境永續性與公共健康造成重大威脅。本研究提出一個創新的機器學習模型，結合 Sentinel-3 衛星、氣象預測和額外遙測輸入的資料。主要目的是產生詳細的時空地圖，預測都靈 24 小時內的最高溫度。實驗結果驗證了模型在預測溫度模式方面的熟練度，在 2023 年以每像素 20 公尺解析度達到 2.09 度攝氏的平均絕對誤差 (MAE)，從而豐富了我們對都市氣候行為的認識。此研究增強了對都市微氣候的了解，強調跨領域資料整合的重要性，並為旨在減輕極端都市溫度負面影響的明智政策制定奠定基礎。

##### **GAMedX: Generative AI-based Medical Entity Data Extractor Using Large Language Models**
2405.20585v1 by Mohammed-Khalil Ghali, Abdelrahman Farrag, Hajar Sakai, Hicham El Baz, Yu Jin, Sarah Lam

In the rapidly evolving field of healthcare and beyond, the integration of
generative AI in Electronic Health Records (EHRs) represents a pivotal
advancement, addressing a critical gap in current information extraction
techniques. This paper introduces GAMedX, a Named Entity Recognition (NER)
approach utilizing Large Language Models (LLMs) to efficiently extract entities
from medical narratives and unstructured text generated throughout various
phases of the patient hospital visit. By addressing the significant challenge
of processing unstructured medical text, GAMedX leverages the capabilities of
generative AI and LLMs for improved data extraction. Employing a unified
approach, the methodology integrates open-source LLMs for NER, utilizing
chained prompts and Pydantic schemas for structured output to navigate the
complexities of specialized medical jargon. The findings reveal significant
ROUGE F1 score on one of the evaluation datasets with an accuracy of 98\%. This
innovation enhances entity extraction, offering a scalable, cost-effective
solution for automated forms filling from unstructured data. As a result,
GAMedX streamlines the processing of unstructured narratives, and sets a new
standard in NER applications, contributing significantly to theoretical and
practical advancements beyond the medical technology sphere.

摘要：在快速发展的醫療保健及其他領域中，生成式 AI 整合到電子健康紀錄 (EHR) 中代表著關鍵進展，解決了當前資訊擷取技術中的重大差距。本文介紹 GAMedX，一種命名實體辨識 (NER) 方法，利用大型語言模型 (LLM) 從醫療敘述和患者醫院就診各個階段產生的非結構化文字中有效率地擷取實體。透過解決處理非結構化醫療文字的重大挑戰，GAMedX 充分利用生成式 AI 和 LLM 的能力，以改善資料擷取。採用統一方法，此方法整合開放原始碼 LLM 以進行 NER，利用串連提示和 Pydantic 架構進行結構化輸出，以應對專業醫療術語的複雜性。研究結果顯示，在其中一個評量資料集上，ROUGE F1 得分顯著，準確度為 98%。這項創新增強了實體擷取，提供了一個可擴充、具成本效益的解決方案，用於從非結構化資料中自動填寫表格。因此，GAMedX 簡化了非結構化敘述的處理，並在 NER 應用程式中設定了新的標準，為醫療技術領域之外的理論和實務進展做出了重大貢獻。

##### **The Point of View of a Sentiment: Towards Clinician Bias Detection in Psychiatric Notes**
2405.20582v1 by Alissa A. Valentine, Lauren A. Lepow, Alexander W. Charney, Isotta Landi

In psychiatry, negative patient descriptions and stigmatizing language can
contribute to healthcare disparities in two ways: (1) read by patients they can
harm their trust and engagement with the medical center; (2) read by future
providers they may negatively influence the future perspective of a patient. By
leveraging large language models, this work aims to identify the sentiment
expressed in psychiatric clinical notes based on the reader's point of view.
Extracting sentences from the Mount Sinai Health System's large and diverse
clinical notes, we used prompts and in-context learning to adapt three large
language models (GPT-3.5, Llama 2, Mistral) to classify the sentiment conveyed
by the sentences according to the provider or non-provider point of view.
Results showed that GPT-3.5 aligns best to provider point of view, whereas
Mistral aligns best to non-provider point of view.

摘要：在精神病學中，負面的病人描述和污名化的語言可能透過兩種方式造成醫療保健差異：(1) 病人讀到後會損害他們對醫療中心的信任和參與；(2) 未來的提供者讀到後，可能會對病人的未來觀點產生負面影響。透過利用大型語言模型，這項工作旨在根據讀者的觀點，找出精神病臨床筆記中表達的情緒。從西奈山健康系統的大量且多樣化的臨床筆記中摘錄句子，我們使用提示和情境學習來調整三個大型語言模型 (GPT-3.5、Llama 2、Mistral)，以根據提供者或非提供者觀點對句子傳達的情緒進行分類。結果顯示，GPT-3.5 最符合提供者觀點，而 Mistral 最符合非提供者觀點。

##### **Can Machine Learning Assist in Diagnosis of Primary Immune Thrombocytopenia? A feasibility study**
2405.20562v1 by Haroon Miah, Dimitrios Kollias, Giacinto Luca Pedone, Drew Provan, Frederick Chen

Primary Immune thrombocytopenia (ITP) is a rare autoimmune disease
characterised by immune-mediated destruction of peripheral blood platelets in
patients leading to low platelet counts and bleeding. The diagnosis and
effective management of ITP is challenging because there is no established test
to confirm the disease and no biomarker with which one can predict the response
to treatment and outcome. In this work we conduct a feasibility study to check
if machine learning can be applied effectively for diagnosis of ITP using
routine blood tests and demographic data in a non-acute outpatient setting.
Various ML models, including Logistic Regression, Support Vector Machine,
k-Nearest Neighbor, Decision Tree and Random Forest, were applied to data from
the UK Adult ITP Registry and a general hematology clinic. Two different
approaches were investigated: a demographic-unaware and a demographic-aware
one. We conduct extensive experiments to evaluate the predictive performance of
these models and approaches, as well as their bias. The results revealed that
Decision Tree and Random Forest models were both superior and fair, achieving
nearly perfect predictive and fairness scores, with platelet count identified
as the most significant variable. Models not provided with demographic
information performed better in terms of predictive accuracy but showed lower
fairness score, illustrating a trade-off between predictive performance and
fairness.

摘要：原發性免疫性血小板減少症（ITP）是一種罕見的自體免疫疾病
其特徵在於免疫介導的外周血小板破壞導致患者血小板數量減少和出血。ITP 的診斷和有效管理具有挑戰性，因為沒有既定的檢測方法來確認疾病，也沒有生物標誌物可以預測對治療和結果的反應。在這項工作中，我們進行了一項可行性研究，以檢查機器學習是否可以有效應用於使用非急性門診環境中的常規血液檢查和人口統計數據診斷 ITP。各種 ML 模型，包括邏輯迴歸、支持向量機、k 最近鄰、決策樹和隨機森林，被應用於來自英國成人 ITP 登記處和普通血液學診所的數據。研究了兩種不同的方法：一種是不知道人口統計數據的方法，另一種是知道人口統計數據的方法。我們進行了廣泛的實驗來評估這些模型和方法的預測性能以及它們的偏差。結果表明，決策樹和隨機森林模型都優越且公平，實現了接近完美的預測和公平分數，血小板計數被確定為最重要的變量。未提供人口統計信息的模型在預測準確性方面表現得更好，但公平分數較低，說明了預測性能和公平性之間的權衡。

##### **Enhancing Performance for Highly Imbalanced Medical Data via Data Regularization in a Federated Learning Setting**
2405.20430v1 by Georgios Tsoumplekas, Ilias Siniosoglou, Vasileios Argyriou, Ioannis D. Moscholios, Panagiotis Sarigiannidis

The increased availability of medical data has significantly impacted
healthcare by enabling the application of machine / deep learning approaches in
various instances. However, medical datasets are usually small and scattered
across multiple providers, suffer from high class-imbalance, and are subject to
stringent data privacy constraints. In this paper, the application of a data
regularization algorithm, suitable for learning under high class-imbalance, in
a federated learning setting is proposed. Specifically, the goal of the
proposed method is to enhance model performance for cardiovascular disease
prediction by tackling the class-imbalance that typically characterizes
datasets used for this purpose, as well as by leveraging patient data available
in different nodes of a federated ecosystem without compromising their privacy
and enabling more resource sensitive allocation. The method is evaluated across
four datasets for cardiovascular disease prediction, which are scattered across
different clients, achieving improved performance. Meanwhile, its robustness
under various hyperparameter settings, as well as its ability to adapt to
different resource allocation scenarios, is verified.

摘要：醫療數據的普及大幅影響了醫療保健，因為它能讓機器／深度學習方法應用在各種情況。然而，醫療數據集通常很小，且分散在多個供應商中，因此會面臨高度類別不平衡的問題，且受到嚴格的資料隱私限制。本文提出了一種資料正則化演算法的應用，它適用於在高度類別不平衡的情況下學習，並用於聯邦學習設定中。具體來說，所提出方法的目標是透過處理通常用於此目的的數據集中特有的類別不平衡，以及透過利用聯邦生態系統中不同節點中可用的患者資料，並在不損害其隱私和實現更具資源敏感性的配置下，來提升心血管疾病預測的模型效能。該方法在四個心血管疾病預測數據集中進行評估，這些數據集分散在不同的客戶端中，並獲得了更好的效能。同時，驗證了它在各種超參數設定下的穩健性，以及適應不同資源配置場景的能力。

##### **Worse than Random? An Embarrassingly Simple Probing Evaluation of Large Multimodal Models in Medical VQA**
2405.20421v1 by Qianqi Yan, Xuehai He, Xiang Yue, Xin Eric Wang

Large Multimodal Models (LMMs) have shown remarkable progress in the field of
medical Visual Question Answering (Med-VQA), achieving high accuracy on
existing benchmarks. However, their reliability under robust evaluation is
questionable. This study reveals that state-of-the-art models, when subjected
to simple probing evaluation, perform worse than random guessing on medical
diagnosis questions. To address this critical evaluation problem, we introduce
the Probing Evaluation for Medical Diagnosis (ProbMed) dataset to rigorously
assess LMM performance in medical imaging through probing evaluation and
procedural diagnosis. Particularly, probing evaluation features pairing
original questions with negation questions with hallucinated attributes, while
procedural diagnosis requires reasoning across various diagnostic dimensions
for each image, including modality recognition, organ identification, clinical
findings, abnormalities, and positional grounding. Our evaluation reveals that
top-performing models like GPT-4V and Gemini Pro perform worse than random
guessing on specialized diagnostic questions, indicating significant
limitations in handling fine-grained medical inquiries. Besides, models like
LLaVA-Med struggle even with more general questions, and results from CheXagent
demonstrate the transferability of expertise across different modalities of the
same organ, showing that specialized domain knowledge is still crucial for
improving performance. This study underscores the urgent need for more robust
evaluation to ensure the reliability of LMMs in critical fields like medical
diagnosis, and current LMMs are still far from applicable to those fields.

摘要：大型多模态模型 (LMM) 在医学视觉问答 (Med-VQA) 领域取得了显著进展，在现有基准测试中实现了高准确度。然而，它们在稳健评估下的可靠性值得怀疑。本研究表明，当最先进的模型经过简单的探测评估时，在医学诊断问题上的表现比随机猜测还要差。为了解决这个关键的评估问题，我们引入了医学诊断探测评估 (ProbMed) 数据集，通过探测评估和程序诊断严格评估 LMM 在医学影像中的性能。特别是，探测评估的特点是将原始问题与带有幻觉属性的否定问题配对，而程序诊断则需要针对每个图像推理各种诊断维度，包括模态识别、器官识别、临床发现、异常和位置基础。我们的评估表明，像 GPT-4V 和 Gemini Pro 这样的高性能模型在专门的诊断问题上表现比随机猜测还要差，表明在处理细粒度的医学查询方面存在明显的局限性。此外，像 LLaVA-Med 这样的模型甚至在更一般的问题上也难以应付，而 CheXagent 的结果证明了专业知识在同一器官的不同模态之间具有可转移性，表明专门的领域知识对于提高性能仍然至关重要。本研究强调了对更稳健的评估的迫切需求，以确保 LMM 在医学诊断等关键领域的可靠性，而当前的 LMM 仍然远不能应用于这些领域。

##### **Enhancing Antibiotic Stewardship using a Natural Language Approach for Better Feature Representation**
2405.20419v1 by Simon A. Lee, Trevor Brokowski, Jeffrey N. Chiang

The rapid emergence of antibiotic-resistant bacteria is recognized as a
global healthcare crisis, undermining the efficacy of life-saving antibiotics.
This crisis is driven by the improper and overuse of antibiotics, which
escalates bacterial resistance. In response, this study explores the use of
clinical decision support systems, enhanced through the integration of
electronic health records (EHRs), to improve antibiotic stewardship. However,
EHR systems present numerous data-level challenges, complicating the effective
synthesis and utilization of data. In this work, we transform EHR data into a
serialized textual representation and employ pretrained foundation models to
demonstrate how this enhanced feature representation can aid in antibiotic
susceptibility predictions. Our results suggest that this text representation,
combined with foundation models, provides a valuable tool to increase
interpretability and support antibiotic stewardship efforts.

摘要：抗生素抗藥性細菌的快速出現被視為全球醫療保健危機，破壞了救命抗生素的效力。此危機是由抗生素的不當和過度使用所驅動，這會增加細菌的抗藥性。為了解決這個問題，本研究探討了臨床決策支援系統的使用，透過整合電子健康記錄 (EHR) 來加強，以改善抗生素管理。然而，EHR 系統提出了許多資料層級的挑戰，使資料的有效合成和利用變得複雜。在這項工作中，我們將 EHR 資料轉換成序列化的文字表示，並採用預先訓練好的基礎模型，以展示這種增強的功能表示如何有助於抗生素敏感性預測。我們的結果表明，這種文字表示與基礎模型結合，提供了一個有價值的工具來增加可解釋性，並支持抗生素管理工作。

##### **MSSC-BiMamba: Multimodal Sleep Stage Classification and Early Diagnosis of Sleep Disorders with Bidirectional Mamba**
2405.20142v2 by Chao Zhang, Weirong Cui, Jingjing Guo

Monitoring sleep states is essential for evaluating sleep quality and
diagnosing sleep disorders. Traditional manual staging is time-consuming and
prone to subjective bias, often resulting in inconsistent outcomes. Here, we
developed an automated model for sleep staging and disorder classification to
enhance diagnostic accuracy and efficiency. Considering the characteristics of
polysomnography (PSG) multi-lead sleep monitoring, we designed a multimodal
sleep state classification model, MSSC-BiMamba, that combines an Efficient
Channel Attention (ECA) mechanism with a Bidirectional State Space Model
(BSSM). The ECA module allows for weighting data from different sensor
channels, thereby amplifying the influence of diverse sensor inputs.
Additionally, the implementation of bidirectional Mamba (BiMamba) enables the
model to effectively capture the multidimensional features and long-range
dependencies of PSG data. The developed model demonstrated impressive
performance on sleep stage classification tasks on both the ISRUC-S3 and
ISRUC-S1 datasets, respectively containing data with healthy and unhealthy
sleep patterns. Also, the model exhibited a high accuracy for sleep health
prediction when evaluated on a combined dataset consisting of ISRUC and
Sleep-EDF. Our model, which can effectively handle diverse sleep conditions, is
the first to apply BiMamba to sleep staging with multimodal PSG data, showing
substantial gains in computational and memory efficiency over traditional
Transformer-style models. This method enhances sleep health management by
making monitoring more accessible and extending advanced healthcare through
innovative technology.

摘要：監控睡眠狀態對於評估睡眠品質和診斷睡眠障礙至關重要。傳統的手動分期耗時且容易產生主觀偏見，經常導致不一致的結果。在此，我們開發了一個自動化模型，用於睡眠分期和疾病分類，以提高診斷準確性和效率。考慮到多導睡眠檢查 (PSG) 多導程睡眠監測的特徵，我們設計了一個多模態睡眠狀態分類模型 MSSC-BiMamba，它將高效通道注意 (ECA) 機制與雙向狀態空間模型 (BSSM) 結合在一起。ECA 模組允許對來自不同感測器通道的資料進行加權，從而放大不同感測器輸入的影響。此外，雙向 Mamba (BiMamba) 的實作讓模型能夠有效擷取 PSG 資料的多維特徵和長程依賴性。開發的模型在 ISRUC-S3 和 ISRUC-S1 資料集上展現出令人印象深刻的睡眠分期分類任務效能，這些資料集分別包含健康和不健康的睡眠模式資料。此外，在由 ISRUC 和 Sleep-EDF 組成的合併資料集上進行評估時，該模型展現出很高的睡眠健康預測準確度。我們的模型可以有效處理不同的睡眠狀況，是第一個將 BiMamba 應用於具有多模態 PSG 資料的睡眠分期的模型，在運算和記憶體效率方面展現出比傳統 Transformer 風格模型更顯著的進步。這種方法透過讓監控更容易取得，並透過創新技術擴展先進的醫療保健，進而增強睡眠健康管理。

##### **Out-of-distribution Reject Option Method for Dataset Shift Problem in Early Disease Onset Prediction**
2405.19864v1 by Taisei Tosaki, Eiichiro Uchino, Ryosuke Kojima, Yohei Mineharu, Mikio Arita, Nobuyuki Miyai, Yoshinori Tamada, Tatsuya Mikami, Koichi Murashita, Shigeyuki Nakaji, Yasushi Okuno

Machine learning is increasingly used to predict lifestyle-related disease
onset using health and medical data. However, the prediction effectiveness is
hindered by dataset shift, which involves discrepancies in data distribution
between the training and testing datasets, misclassifying out-of-distribution
(OOD) data. To diminish dataset shift effects, this paper proposes the
out-of-distribution reject option for prediction (ODROP), which integrates OOD
detection models to preclude OOD data from the prediction phase. We
investigated the efficacy of five OOD detection methods (variational
autoencoder, neural network ensemble std, neural network ensemble epistemic,
neural network energy, and neural network gaussian mixture based energy
measurement) across two datasets, the Hirosaki and Wakayama health checkup
data, in the context of three disease onset prediction tasks: diabetes,
dyslipidemia, and hypertension. To evaluate the ODROP method, we trained
disease onset prediction models and OOD detection models on Hirosaki data and
used AUROC-rejection curve plots from Wakayama data. The variational
autoencoder method showed superior stability and magnitude of improvement in
Area Under the Receiver Operating Curve (AUROC) in five cases: AUROC in the
Wakayama data was improved from 0.80 to 0.90 at a 31.1% rejection rate for
diabetes onset and from 0.70 to 0.76 at a 34% rejection rate for dyslipidemia.
We categorized dataset shifts into two types using SHAP clustering - those that
considerably affect predictions and those that do not. We expect that this
classification will help standardize measuring instruments. This study is the
first to apply OOD detection to actual health and medical data, demonstrating
its potential to substantially improve the accuracy and reliability of disease
prediction models amidst dataset shift.

摘要：機器學習正日益用於預測與生活方式相關的疾病發作，並使用健康和醫療數據。然而，預測效果會受到資料集轉移的阻礙，這涉及訓練和測試資料集之間的資料分佈差異，將分布外 (OOD) 資料分類錯誤。為了減少資料集轉移效應，本文提出用於預測的分布外拒絕選項 (ODROP)，它整合 OOD 偵測模型以排除預測階段的 OOD 資料。我們調查了五種 OOD 偵測方法 (變異自動編碼器、神經網路整體標準差、神經網路整體認識論、神經網路能量和基於神經網路高斯混合能量測量) 的效能，跨兩個資料集，弘前和和歌山健康檢查資料，在糖尿病、血脂異常和高血壓這三個疾病發作預測任務的脈絡中。為了評估 ODROP 方法，我們訓練了弘前資料的疾病發作預測模型和 OOD 偵測模型，並使用和歌山資料的 AUROC 排斥曲線圖。變異自動編碼器方法在五種情況下展現出優異的穩定性和改善幅度：在接受者操作特徵曲線 (AUROC) 下方區域中，和歌山資料的 AUROC 從糖尿病發作的 31.1% 排斥率改善到 0.90，從血脂異常的 34% 排斥率改善到 0.76。我們使用 SHAP 聚類將資料集轉移分為兩種類型，一種會顯著影響預測，另一種則不會。我們預期這種分類將有助於標準化測量儀器。這項研究首次將 OOD 偵測應用於實際的健康和醫療資料，證明了其在資料集轉移中大幅改善疾病預測模型的準確性和可靠性的潛力。

##### **Dynamic feature selection in medical predictive monitoring by reinforcement learning**
2405.19729v1 by Yutong Chen, Jiandong Gao, Ji Wu

In this paper, we investigate dynamic feature selection within multivariate
time-series scenario, a common occurrence in clinical prediction monitoring
where each feature corresponds to a bio-test result. Many existing feature
selection methods fall short in effectively leveraging time-series information,
primarily because they are designed for static data. Our approach addresses
this limitation by enabling the selection of time-varying feature subsets for
each patient. Specifically, we employ reinforcement learning to optimize a
policy under maximum cost restrictions. The prediction model is subsequently
updated using synthetic data generated by trained policy. Our method can
seamlessly integrate with non-differentiable prediction models. We conducted
experiments on a sizable clinical dataset encompassing regression and
classification tasks. The results demonstrate that our approach outperforms
strong feature selection baselines, particularly when subjected to stringent
cost limitations. Code will be released once paper is accepted.

摘要：在本文中，我们研究多變量時間序列場景中的動態特徵選擇，這在臨床上預測監控中很常見，其中每個特徵對應於一個生物檢測結果。許多現有的特徵選擇方法在有效利用時間序列資訊方面做得並不好，主要是因為它們是為靜態資料而設計的。我們的做法通過為每個患者啟用時間變異特徵子集的選擇來解決這個限制。具體來說，我們採用強化學習來在最大成本限制下最佳化一個策略。預測模型隨後使用由訓練策略產生的合成資料更新。我們的做法可以與不可微分預測模型無縫整合。我們在一個包含回歸和分類任務的大型臨床資料集上進行了實驗。結果表明，我們的做法優於強大的特徵選擇基線，特別是在受到嚴格成本限制時。一旦論文被接受，程式碼將會發布。

##### **Unlocking the Power of Spatial and Temporal Information in Medical Multimodal Pre-training**
2405.19654v1 by Jinxia Yang, Bing Su, Wayne Xin Zhao, Ji-Rong Wen

Medical vision-language pre-training methods mainly leverage the
correspondence between paired medical images and radiological reports. Although
multi-view spatial images and temporal sequences of image-report pairs are
available in off-the-shelf multi-modal medical datasets, most existing methods
have not thoroughly tapped into such extensive supervision signals. In this
paper, we introduce the Med-ST framework for fine-grained spatial and temporal
modeling to exploit information from multiple spatial views of chest
radiographs and temporal historical records. For spatial modeling, Med-ST
employs the Mixture of View Expert (MoVE) architecture to integrate different
visual features from both frontal and lateral views. To achieve a more
comprehensive alignment, Med-ST not only establishes the global alignment
between whole images and texts but also introduces modality-weighted local
alignment between text tokens and spatial regions of images. For temporal
modeling, we propose a novel cross-modal bidirectional cycle consistency
objective by forward mapping classification (FMC) and reverse mapping
regression (RMR). By perceiving temporal information from simple to complex,
Med-ST can learn temporal semantics. Experimental results across four distinct
tasks demonstrate the effectiveness of Med-ST, especially in temporal
classification tasks. Our code and model are available at
https://github.com/SVT-Yang/MedST.

摘要：醫學視覺語言預訓練方法主要利用配對醫學影像與放射科報告之間的對應關係。儘管現成的多模式醫學資料集中提供了多視角空間影像和影像報告對的時間序列，但大多數現有方法尚未徹底利用如此廣泛的監督訊號。在本文中，我們介紹了 Med-ST 架構，用於精細的空間和時間建模，以利用胸部 X 光片的視角和時間歷史記錄的資訊。對於空間建模，Med-ST 採用視角專家混合 (MoVE) 架構，以整合來自正面和側面視角的不同視覺特徵。為了實現更全面的對齊，Med-ST 不僅建立了整個影像和文字之間的全局對齊，還引入了文字符號和影像空間區域之間的模態加權局部對齊。對於時間建模，我們提出了一個新穎的跨模態雙向循環一致性目標，通過正向映射分類 (FMC) 和反向映射回歸 (RMR)。通過從簡單到複雜地感知時間資訊，Med-ST 可以學習時間語義。四個不同任務的實驗結果證明了 Med-ST 的有效性，特別是在時間分類任務中。我們的程式碼和模型可在 https://github.com/SVT-Yang/MedST 取得。

##### **Leveraging Open-Source Large Language Models for encoding Social Determinants of Health using an Intelligent Router**
2405.19631v1 by Akul Goel, Surya Narayanan Hari, Belinda Waltman, Matt Thomson

Social Determinants of Health (SDOH) play a significant role in patient
health outcomes. The Center of Disease Control (CDC) introduced a subset of
ICD-10 codes called Z-codes in an attempt to officially recognize and measure
SDOH in the health care system. However, these codes are rarely annotated in a
patient's Electronic Health Record (EHR), and instead, in many cases, need to
be inferred from clinical notes. Previous research has shown that large
language models (LLMs) show promise on extracting unstructured data from EHRs.
However, with thousands of models to choose from with unique architectures and
training sets, it's difficult to choose one model that performs the best on
coding tasks. Further, clinical notes contain trusted health information making
the use of closed-source language models from commercial vendors difficult, so
the identification of open source LLMs that can be run within health
organizations and exhibits high performance on SDOH tasks is an urgent problem.
Here, we introduce an intelligent routing system for SDOH coding that uses a
language model router to direct medical record data to open source LLMs that
demonstrate optimal performance on specific SDOH codes. The intelligent routing
system exhibits state of the art performance of 97.4% accuracy averaged across
5 codes, including homelessness and food insecurity, on par with closed models
such as GPT-4o. In order to train the routing system and validate models, we
also introduce a synthetic data generation and validation paradigm to increase
the scale of training data without needing privacy protected medical records.
Together, we demonstrate an architecture for intelligent routing of inputs to
task-optimal language models to achieve high performance across a set of
medical coding sub-tasks.

摘要：<paragraph>健康社會決定因素 (SDOH) 在患者健康結果中扮演著重要的角色。疾病控制中心 (CDC) 引入了一組稱為 Z 碼的 ICD-10 代碼，試圖在醫療保健系統中正式識別和衡量 SDOH。然而，這些代碼很少在患者的電子健康記錄 (EHR) 中註解，而且在許多情況下，需要從臨床筆記中推斷出來。先前的研究表明，大型語言模型 (LLM) 在從 EHR 中提取非結構化數據方面很有前景。然而，有數千個模型可供選擇，它們具有獨特的架構和訓練集，因此很難選擇一個在編碼任務上表現最佳的模型。此外，臨床筆記包含受信任的健康資訊，這使得難以使用商業供應商的閉源語言模型，因此，識別可以在醫療機構內運作且在 SDOH 任務上表現出高性能的開源 LLM 是個迫切的問題。在此，我們介紹了一個用於 SDOH 編碼的智慧路由系統，它使用語言模型路由器將病歷資料導向在特定 SDOH 代碼上表現出最佳性能的開源 LLM。智慧路由系統展現了最先進的性能，在 5 個代碼（包括無家可歸和糧食不安全）的平均準確度為 97.4%，與 GPT-4o 等閉合模型不相上下。為了訓練路由系統和驗證模型，我們還引入了一個合成資料生成和驗證範例，以增加訓練資料的規模，而無需受隱私保護的病歷。總之，我們展示了一個智慧路由架構，用於將輸入路由到任務最佳語言模型，以在醫療編碼子任務中實現高性能。</paragraph>

##### **Dr-LLaVA: Visual Instruction Tuning with Symbolic Clinical Grounding**
2405.19567v1 by Shenghuan Sun, Gregory M. Goldgof, Alexander Schubert, Zhiqing Sun, Thomas Hartvigsen, Atul J. Butte, Ahmed Alaa

Vision-Language Models (VLM) can support clinicians by analyzing medical
images and engaging in natural language interactions to assist in diagnostic
and treatment tasks. However, VLMs often exhibit "hallucinogenic" behavior,
generating textual outputs not grounded in contextual multimodal information.
This challenge is particularly pronounced in the medical domain, where we do
not only require VLM outputs to be accurate in single interactions but also to
be consistent with clinical reasoning and diagnostic pathways throughout
multi-turn conversations. For this purpose, we propose a new alignment
algorithm that uses symbolic representations of clinical reasoning to ground
VLMs in medical knowledge. These representations are utilized to (i) generate
GPT-4-guided visual instruction tuning data at scale, simulating clinician-VLM
conversations with demonstrations of clinical reasoning, and (ii) create an
automatic reward function that evaluates the clinical validity of VLM
generations throughout clinician-VLM interactions. Our algorithm eliminates the
need for human involvement in training data generation or reward model
construction, reducing costs compared to standard reinforcement learning with
human feedback (RLHF). We apply our alignment algorithm to develop Dr-LLaVA, a
conversational VLM finetuned for analyzing bone marrow pathology slides,
demonstrating strong performance in multi-turn medical conversations.

摘要：視覺語言模型 (VLM) 可透過分析醫療影像並進行自然語言互動來協助臨床醫生，以協助診斷和治療任務。然而，VLM 經常表現出「幻覺」行為，產生未基於脈絡多模態資訊的文字輸出。這個挑戰在醫療領域特別明顯，因為我們不僅要求 VLM 輸出在單一互動中準確，還必須在多輪對話中與臨床推理和診斷途徑保持一致。為此，我們提出了一種新的對齊演算法，它使用臨床推理的符號表示法將 VLM 建立在醫學知識上。這些表示法用於：(i) 生成 GPT-4 引導的視覺指令調整資料，模擬臨床醫生-VLM 對話，並展示臨床推理，以及 (ii) 建立一個自動獎勵函數，用於評估 VLM 生成在臨床醫生-VLM 互動中的臨床有效性。我們的演算法消除了在訓練資料生成或獎勵模型建構中需要人工參與，與需要人工回饋（RLHF）的標準強化學習相比，降低了成本。我們將我們的對齊演算法應用於開發 Dr-LLaVA，這是一個針對分析骨髓病理切片進行微調的對話式 VLM，在多輪醫療對話中展現出強大的效能。

##### **Unlocking the Potential of Large Language Models for Clinical Text Anonymization: A Comparative Study**
2406.00062v1 by David Pissarra, Isabel Curioso, João Alveira, Duarte Pereira, Bruno Ribeiro, Tomás Souper, Vasco Gomes, André V. Carreiro, Vitor Rolla

Automated clinical text anonymization has the potential to unlock the
widespread sharing of textual health data for secondary usage while assuring
patient privacy and safety. Despite the proposal of many complex and
theoretically successful anonymization solutions in literature, these
techniques remain flawed. As such, clinical institutions are still reluctant to
apply them for open access to their data. Recent advances in developing Large
Language Models (LLMs) pose a promising opportunity to further the field, given
their capability to perform various tasks. This paper proposes six new
evaluation metrics tailored to the challenges of generative anonymization with
LLMs. Moreover, we present a comparative study of LLM-based methods, testing
them against two baseline techniques. Our results establish LLM-based models as
a reliable alternative to common approaches, paving the way toward trustworthy
anonymization of clinical text.

摘要：自動化臨床文字匿名化有潛力解鎖廣泛分享文字健康資料以供二次使用，同時確保病患隱私和安全。儘管文獻中提出了許多複雜且理論上成功的匿名化解決方案，但這些技術仍有缺陷。因此，臨床機構仍不願意將其應用於資料的開放存取。最近在開發大型語言模型 (LLM) 方面的進展為進一步推動該領域提供了絕佳的機會，因為它們有能力執行各種任務。本文提出了六項新的評估指標，針對使用 LLM 進行生成式匿名化的挑戰量身打造。此外，我們針對基於 LLM 的方法進行比較研究，並針對它們測試兩項基準技術。我們的結果確立了基於 LLM 的模型作為常見方法的可靠替代方案，為臨床文字的值得信賴的匿名化鋪平了道路。

##### **CheXpert Plus: Augmenting a Large Chest X-ray Dataset with Text Radiology Reports, Patient Demographics and Additional Image Formats**
2405.19538v2 by Pierre Chambon, Jean-Benoit Delbrouck, Thomas Sounack, Shih-Cheng Huang, Zhihong Chen, Maya Varma, Steven QH Truong, Chu The Chuong, Curtis P. Langlotz

Since the release of the original CheXpert paper five years ago, CheXpert has
become one of the most widely used and cited clinical AI datasets. The
emergence of vision language models has sparked an increase in demands for
sharing reports linked to CheXpert images, along with a growing interest among
AI fairness researchers in obtaining demographic data. To address this,
CheXpert Plus serves as a new collection of radiology data sources, made
publicly available to enhance the scaling, performance, robustness, and
fairness of models for all subsequent machine learning tasks in the field of
radiology. CheXpert Plus is the largest text dataset publicly released in
radiology, with a total of 36 million text tokens, including 13 million
impression tokens. To the best of our knowledge, it represents the largest text
de-identification effort in radiology, with almost 1 million PHI spans
anonymized. It is only the second time that a large-scale English paired
dataset has been released in radiology, thereby enabling, for the first time,
cross-institution training at scale. All reports are paired with high-quality
images in DICOM format, along with numerous image and patient metadata covering
various clinical and socio-economic groups, as well as many pathology labels
and RadGraph annotations. We hope this dataset will boost research for AI
models that can further assist radiologists and help improve medical care. Data
is available at the following URL:
https://stanfordaimi.azurewebsites.net/datasets/5158c524-d3ab-4e02-96e9-6ee9efc110a1
Models are available at the following URL:
https://github.com/Stanford-AIMI/chexpert-plus

摘要：自 5 年前发布原始 CheXpert 论文以来，CheXpert 已成为使用最广泛且引用最多的临床 AI 数据集之一。视觉语言模型的出现引发了对共享与 CheXpert 图像关联的报告的需求增加，以及 AI 公平性研究人员对获取人口统计数据的兴趣日益浓厚。为了解决这个问题，CheXpert Plus 作为放射学数据源的新集合，公开提供，以增强放射学领域所有后续机器学习任务的模型的扩展性、性能、鲁棒性和公平性。CheXpert Plus 是放射学领域公开发布的最大的文本数据集，总共有 3600 万个文本标记，其中包括 1300 万个印象标记。据我们所知，它代表了放射学领域最大的文本去标识化工作，其中将近 100 万个 PHI 跨度匿名化。这是放射学领域第二次发布大规模英语配对数据集，从而首次实现了大规模跨机构训练。所有报告都与 DICOM 格式的高质量图像配对，以及涵盖各种临床和社会经济群体的众多图像和患者元数据，以及许多病理标签和 RadGraph 注释。我们希望该数据集将促进对 AI 模型的研究，这些模型可以进一步协助放射科医生并帮助改善医疗保健。数据可在以下网址获取：
https://stanfordaimi.azurewebsites.net/datasets/5158c524-d3ab-4e02-96e9-6ee9efc110a1
模型可在以下网址获取：
https://github.com/Stanford-AIMI/chexpert-plus

##### **Participation in the age of foundation models**
2405.19479v1 by Harini Suresh, Emily Tseng, Meg Young, Mary L. Gray, Emma Pierson, Karen Levy

Growing interest and investment in the capabilities of foundation models has
positioned such systems to impact a wide array of public services. Alongside
these opportunities is the risk that these systems reify existing power
imbalances and cause disproportionate harm to marginalized communities.
Participatory approaches hold promise to instead lend agency and
decision-making power to marginalized stakeholders. But existing approaches in
participatory AI/ML are typically deeply grounded in context - how do we apply
these approaches to foundation models, which are, by design, disconnected from
context? Our paper interrogates this question.
  First, we examine existing attempts at incorporating participation into
foundation models. We highlight the tension between participation and scale,
demonstrating that it is intractable for impacted communities to meaningfully
shape a foundation model that is intended to be universally applicable. In
response, we develop a blueprint for participatory foundation models that
identifies more local, application-oriented opportunities for meaningful
participation. In addition to the "foundation" layer, our framework proposes
the "subfloor'' layer, in which stakeholders develop shared technical
infrastructure, norms and governance for a grounded domain, and the "surface''
layer, in which affected communities shape the use of a foundation model for a
specific downstream task. The intermediate "subfloor'' layer scopes the range
of potential harms to consider, and affords communities more concrete avenues
for deliberation and intervention. At the same time, it avoids duplicative
effort by scaling input across relevant use cases. Through three case studies
in clinical care, financial services, and journalism, we illustrate how this
multi-layer model can create more meaningful opportunities for participation
than solely intervening at the foundation layer.

摘要：<paragraph>對於基礎模型能力的興趣和投資日益增長，已使此類系統能夠影響廣泛的公共服務。除了這些機會之外，這些系統還存在強化既有權力失衡並對邊緣化社群造成不成比例傷害的風險。參與式方法有望賦予邊緣化利益相關者代理權和決策權。但現有的參與式 AI/ML 方法通常深植於脈絡中 - 我們如何將這些方法應用於基礎模型，而這些模型在設計上與脈絡無關？我們的論文審視了這個問題。
首先，我們檢視將參與納入基礎模型的既有嘗試。我們強調參與與規模之間的緊張關係，證明受影響的社群難以有意義地塑造一個旨在普遍適用的基礎模型。為了解決這個問題，我們制定了一個參與式基礎模型藍圖，找出更在地化、更以應用為導向的有意義參與機會。除了「基礎」層，我們的架構還提出了「次層」層，在其中，利益相關者會為一個紮根的領域開發共享技術基礎設施、規範和治理，以及「表面」層，在其中，受影響的社群會塑造基礎模型在特定下游任務中的使用方式。中間的「次層」層界定了要考量的潛在危害範圍，並為社群提供了更具體的審議和介入管道。同時，它透過擴展輸入到相關用例中來避免重複的努力。透過臨床照護、金融服務和新聞業中的三個案例研究，我們說明了這個多層模型如何能創造出比僅在基礎層進行介入更有意義的參與機會。</paragraph>

##### **MemControl: Mitigating Memorization in Medical Diffusion Models via Automated Parameter Selection**
2405.19458v1 by Raman Dutt, Pedro Sanchez, Ondrej Bohdal, Sotirios A. Tsaftaris, Timothy Hospedales

Diffusion models show a remarkable ability in generating images that closely
mirror the training distribution. However, these models are prone to training
data memorization, leading to significant privacy, ethical, and legal concerns,
particularly in sensitive fields such as medical imaging. We hypothesize that
memorization is driven by the overparameterization of deep models, suggesting
that regularizing model capacity during fine-tuning could be an effective
mitigation strategy. Parameter-efficient fine-tuning (PEFT) methods offer a
promising approach to capacity control by selectively updating specific
parameters. However, finding the optimal subset of learnable parameters that
balances generation quality and memorization remains elusive. To address this
challenge, we propose a bi-level optimization framework that guides automated
parameter selection by utilizing memorization and generation quality metrics as
rewards. Our framework successfully identifies the optimal parameter set to be
updated to satisfy the generation-memorization tradeoff. We perform our
experiments for the specific task of medical image generation and outperform
existing state-of-the-art training-time mitigation strategies by fine-tuning as
few as 0.019% of model parameters. Furthermore, we show that the strategies
learned through our framework are transferable across different datasets and
domains. Our proposed framework is scalable to large datasets and agnostic to
the choice of reward functions. Finally, we show that our framework can be
combined with existing approaches for further memorization mitigation.

摘要：擴散模型在生成與訓練分佈密切相關的圖像方面表現出卓越的能力。然而，這些模型容易訓練資料記憶，導致嚴重的隱私、倫理和法律問題，特別是在醫療影像等敏感領域。我們假設記憶是由深度模型的過度參數化驅動的，這表明在微調期間規範模型容量可能是有效的緩解策略。參數有效微調 (PEFT) 方法提供了一種有希望的容量控制方法，通過選擇性地更新特定參數。然而，找到平衡生成品質和記憶的最佳可學習參數子集仍然難以捉摸。為了應對這一挑戰，我們提出了一個雙層優化框架，通過利用記憶和生成品質指標作為獎勵來指導自動化參數選擇。我們的框架成功地識別了要更新的最佳參數集，以滿足生成記憶權衡。我們針對醫療影像生成具體任務執行我們的實驗，並且透過微調僅 0.019% 的模型參數，就優於現有的最先進的訓練時間緩解策略。此外，我們表明透過我們的框架學習到的策略可以轉移到不同的資料集和領域。我們提出的框架可擴充到大型資料集，並且與獎勵函數的選擇無關。最後，我們表明我們的框架可以與現有方法結合，以進一步減少記憶。

##### **Conformal Depression Prediction**
2405.18723v1 by Yonghong Li, Shan Qu, Xiuzhuang Zhou

While existing depression recognition methods based on deep learning show
promise, their practical application is hindered by the lack of
trustworthiness, as these deep models are often deployed as \textit{black box}
models, leaving us uncertain about the confidence of the model predictions. For
high-risk clinical applications like depression recognition, uncertainty
quantification is essential in decision-making. In this paper, we introduce
conformal depression prediction (CDP), a depression recognition method with
uncertainty quantification based on conformal prediction (CP), giving valid
confidence intervals with theoretical coverage guarantees for the model
predictions. CDP is a plug-and-play module that requires neither model
retraining nor an assumption about the depression data distribution. As CDP
provides only an average performance guarantee across all inputs rather than
per-input performance guarantee, we propose CDP-ACC, an improved conformal
prediction with approximate conditional coverage. CDP-ACC firstly estimates the
prediction distribution through neighborhood relaxation, and then introduces a
conformal score function by constructing nested sequences, so as to provide
tighter prediction interval for each specific input. We empirically demonstrate
the application of uncertainty quantification in depression recognition, and
the effectiveness and superiority of CDP and CDP-ACC on the AVEC 2013 and AVEC
2014 datasets

摘要：儘管現有的基於深度學習的憂鬱症辨識方法顯示出前景，其實際應用卻受到可信度的不足所阻礙，因為這些深度模型經常被部署為「黑箱」模型，讓我們無法確定模型預測的置信度。對於憂鬱症辨識等高風險的臨床應用，不確定性量化在決策制定中至關重要。在本文中，我們介紹了共形憂鬱症預測 (CDP)，這是一種基於共形預測 (CP) 的憂鬱症辨識方法，具有不確定性量化，可提供模型預測的有效置信區間，並保證理論涵蓋率。CDP 是一個即插即用的模組，既不需要重新訓練模型，也不需要假設憂鬱症資料分佈。由於 CDP 僅提供所有輸入的平均效能保證，而不是每個輸入的效能保證，因此我們提出了 CDP-ACC，這是一種具有近似條件涵蓋率的改良共形預測。CDP-ACC 首先透過鄰域放鬆來估計預測分佈，然後透過建構巢狀序列來引入共形評分函數，以便為每個特定輸入提供更嚴格的預測區間。我們憑經驗證明了不確定性量化在憂鬱症辨識中的應用，以及 CDP 和 CDP-ACC 在 AVEC 2013 和 AVEC 2014 資料集上的有效性和優越性

##### **D-CoRP: Differentiable Connectivity Refinement for Functional Brain Networks**
2405.18658v1 by Haoyu Hu, Hongrun Zhang, Chao Li

Brain network is an important tool for understanding the brain, offering
insights for scientific research and clinical diagnosis. Existing models for
brain networks typically primarily focus on brain regions or overlook the
complexity of brain connectivities. MRI-derived brain network data is commonly
susceptible to connectivity noise, underscoring the necessity of incorporating
connectivities into the modeling of brain networks. To address this gap, we
introduce a differentiable module for refining brain connectivity. We develop
the multivariate optimization based on information bottleneck theory to address
the complexity of the brain network and filter noisy or redundant connections.
Also, our method functions as a flexible plugin that is adaptable to most graph
neural networks. Our extensive experimental results show that the proposed
method can significantly improve the performance of various baseline models and
outperform other state-of-the-art methods, indicating the effectiveness and
generalizability of the proposed method in refining brain network connectivity.
The code will be released for public availability.

摘要：大腦網路是理解大腦的重要工具，為科學研究和臨床診斷提供見解。現有的大腦網路模型通常主要關注大腦區域或忽略大腦連接的複雜性。源自 MRI 的大腦網路資料通常容易受到連接雜訊的影響，這強調了將連接納入大腦網路建模的必要性。為了解決這個差距，我們引入了一個可區分的模組來精煉大腦連接性。我們根據資訊瓶頸理論開發多變數最佳化，以解決大腦網路的複雜性並過濾雜訊或冗餘連接。此外，我們的模型可作為一個靈活的外掛程式，適用於大多數圖形神經網路。我們廣泛的實驗結果表明，所提出的模型可以顯著改善各種基準模型的效能，並優於其他最先進的模型，這表明所提出的模型在精煉大腦網路連接性方面的有效性和概括性。該程式碼將公開發布。

##### **DTR-Bench: An in silico Environment and Benchmark Platform for Reinforcement Learning Based Dynamic Treatment Regime**
2405.18610v1 by Zhiyao Luo, Mingcheng Zhu, Fenglin Liu, Jiali Li, Yangchen Pan, Jiandong Zhou, Tingting Zhu

Reinforcement learning (RL) has garnered increasing recognition for its
potential to optimise dynamic treatment regimes (DTRs) in personalised
medicine, particularly for drug dosage prescriptions and medication
recommendations. However, a significant challenge persists: the absence of a
unified framework for simulating diverse healthcare scenarios and a
comprehensive analysis to benchmark the effectiveness of RL algorithms within
these contexts. To address this gap, we introduce \textit{DTR-Bench}, a
benchmarking platform comprising four distinct simulation environments tailored
to common DTR applications, including cancer chemotherapy, radiotherapy,
glucose management in diabetes, and sepsis treatment. We evaluate various
state-of-the-art RL algorithms across these settings, particularly highlighting
their performance amidst real-world challenges such as
pharmacokinetic/pharmacodynamic (PK/PD) variability, noise, and missing data.
Our experiments reveal varying degrees of performance degradation among RL
algorithms in the presence of noise and patient variability, with some
algorithms failing to converge. Additionally, we observe that using temporal
observation representations does not consistently lead to improved performance
in DTR settings. Our findings underscore the necessity of developing robust,
adaptive RL algorithms capable of effectively managing these complexities to
enhance patient-specific healthcare. We have open-sourced our benchmark and
code at https://github.com/GilesLuo/DTR-Bench.

摘要：強化學習 (RL) 因其最佳化個人化醫療中的動態治療方案 (DTR) 的潛力而獲得越來越多的認可，特別是在藥物劑量處方和藥物建議方面。然而，一個重大的挑戰仍然存在：缺乏一個統一的框架來模擬不同的醫療保健場景，以及一個全面的分析來比較 RL 演算法在這些場景中的有效性。為了解決這個差距，我們引入了 \textit{DTR-Bench}，一個基準測試平台，包含四個不同的模擬環境，針對常見的 DTR 應用，包括癌症化療、放射治療、糖尿病中的葡萄糖管理和敗血症治療。我們在這些設定中評估了各種最先進的 RL 演算法，特別強調它們在藥代動力學/藥效動力學 (PK/PD) 變異性、雜訊和資料遺失等現實世界挑戰中的表現。我們的實驗揭示了在雜訊和患者變異性存在的情況下，RL 演算法之間的效能下降程度不同，有些演算法無法收斂。此外，我們觀察到使用時間觀察表示並不會持續導致 DTR 設定中的效能提升。我們的研究結果強調了開發強健、適應性 RL 演算法的必要性，這些演算法能夠有效管理這些複雜性，以增強特定患者的醫療保健。我們已在 https://github.com/GilesLuo/DTR-Bench 開源了我們的基準測試和程式碼。

##### **Low-rank finetuning for LLMs: A fairness perspective**
2405.18572v1 by Saswat Das, Marco Romanelli, Cuong Tran, Zarreen Reza, Bhavya Kailkhura, Ferdinando Fioretto

Low-rank approximation techniques have become the de facto standard for
fine-tuning Large Language Models (LLMs) due to their reduced computational and
memory requirements. This paper investigates the effectiveness of these methods
in capturing the shift of fine-tuning datasets from the initial pre-trained
data distribution. Our findings reveal that there are cases in which low-rank
fine-tuning falls short in learning such shifts. This, in turn, produces
non-negligible side effects, especially when fine-tuning is adopted for
toxicity mitigation in pre-trained models, or in scenarios where it is
important to provide fair models. Through comprehensive empirical evidence on
several models, datasets, and tasks, we show that low-rank fine-tuning
inadvertently preserves undesirable biases and toxic behaviors. We also show
that this extends to sequential decision-making tasks, emphasizing the need for
careful evaluation to promote responsible LLMs development.

摘要：低秩近似技术已成为微调大型语言模型 (LLM) 的事实标准，因为它们降低了计算和内存需求。本文探讨了这些方法在从初始预训练数据分布中捕获微调数据集的变化方面的有效性。我们的发现表明，在某些情况下，低秩微调无法学习这种变化。这反过来又会产生不可忽视的副作用，尤其是在微调被用于预训练模型中的毒性缓解时，或在提供公平模型很重要的场景中。通过对多个模型、数据集和任务进行全面的实证证据，我们表明低秩微调无意中保留了不良偏见和有害行为。我们还表明这扩展到了顺序决策任务，强调了仔细评估以促进负责任的 LLM 开发的必要性。

##### **Reinforcement Learning in Dynamic Treatment Regimes Needs Critical Reexamination**
2405.18556v2 by Zhiyao Luo, Yangchen Pan, Peter Watkinson, Tingting Zhu

In the rapidly changing healthcare landscape, the implementation of offline
reinforcement learning (RL) in dynamic treatment regimes (DTRs) presents a mix
of unprecedented opportunities and challenges. This position paper offers a
critical examination of the current status of offline RL in the context of
DTRs. We argue for a reassessment of applying RL in DTRs, citing concerns such
as inconsistent and potentially inconclusive evaluation metrics, the absence of
naive and supervised learning baselines, and the diverse choice of RL
formulation in existing research. Through a case study with more than 17,000
evaluation experiments using a publicly available Sepsis dataset, we
demonstrate that the performance of RL algorithms can significantly vary with
changes in evaluation metrics and Markov Decision Process (MDP) formulations.
Surprisingly, it is observed that in some instances, RL algorithms can be
surpassed by random baselines subjected to policy evaluation methods and reward
design. This calls for more careful policy evaluation and algorithm development
in future DTR works. Additionally, we discussed potential enhancements toward
more reliable development of RL-based dynamic treatment regimes and invited
further discussion within the community. Code is available at
https://github.com/GilesLuo/ReassessDTR.

摘要：在快速變化的醫療保健領域中，在動態治療方案 (DTR) 中實施離線強化學習 (RL) 帶來了一系列前所未有的機遇和挑戰。本立場文件對 DTR 背景下的離線 RL 的現狀進行了批判性審查。我們主張重新評估在 DTR 中應用 RL，並提出了一些問題，例如不一致且可能不具決定性的評估指標、缺乏幼稚和監督學習基準，以及現有研究中 RL 公式的多樣選擇。通過一個案例研究，使用一個公開可用的敗血症數據集進行了 17,000 多次評估實驗，我們證明了 RL 演算法的性能可以隨著評估指標和馬可夫決策過程 (MDP) 公式的變化而發生顯著變化。令人驚訝的是，我們觀察到在某些情況下，RL 演算法可以被隨機基準線超越，這些基準線採用策略評估方法和獎勵設計。這需要在未來的 DTR 工作中進行更仔細的策略評估和演算法開發。此外，我們討論了朝著更可靠的基於 RL 的動態治療方案開發的潛在改進，並邀請社區內進一步討論。程式碼可在 https://github.com/GilesLuo/ReassessDTR 獲得。

##### **FAIIR: Building Toward A Conversational AI Agent Assistant for Youth Mental Health Service Provision**
2405.18553v2 by Stephen Obadinma, Alia Lachana, Maia Norman, Jocelyn Rankin, Joanna Yu, Xiaodan Zhu, Darren Mastropaolo, Deval Pandya, Roxana Sultan, Elham Dolatabadi

World's healthcare systems and mental health agencies face both a growing
demand for youth mental health services, alongside a simultaneous challenge of
limited resources. Given these constraints, this work presents our experience
in the creation and evaluation of the FAIIR (Frontline Assistant: Issue
Identification and Recommendation) tool, an ensemble of domain-adapted and
fine-tuned transformer models, leveraging natural language processing to
identify issues that youth may be experiencing. We explore the technical
development, performance, and validation processes leveraged for the FAIIR tool
in application to situations of frontline crisis response via Kids Help Phone.
Frontline Crisis Responders assign an issue tag from a defined list following
each conversation. Assisting with the identification of issues of relevance
helps reduce the burden on CRs, ensuring that appropriate resources can be
provided and that active rescues and mandatory reporting can take place in
critical situations requiring immediate de-escalation.

摘要：全球醫療保健系統和心理健康機構面臨著對青少年心理健康服務不斷增長的需求，同時也面臨著資源有限的挑戰。鑑於這些限制，這項工作展示了我們在建立和評估 FAIIR（前線助理：問題識別和建議）工具方面的經驗，這是一個領域適應和微調的Transformer模型的集合，利用自然語言處理來識別青少年可能遇到的問題。我們探討了在 Kids Help Phone 的一線危機應對情況中，FAIIR 工具所利用的技術開發、效能和驗證過程。一線危機應變人員會在每次對話後從定義的清單中分配一個問題標籤。協助識別相關問題有助於減輕危機應變人員的負擔，確保可以在關鍵情況下提供適當的資源，並進行積極救援和強制報告，這些情況需要立即降級。

##### **An Empirical Analysis on Large Language Models in Debate Evaluation**
2406.00050v2 by Xinyi Liu, Pinxin Liu, Hangfeng He

In this study, we investigate the capabilities and inherent biases of
advanced large language models (LLMs) such as GPT-3.5 and GPT-4 in the context
of debate evaluation. We discover that LLM's performance exceeds humans and
surpasses the performance of state-of-the-art methods fine-tuned on extensive
datasets in debate evaluation. We additionally explore and analyze biases
present in LLMs, including positional bias, lexical bias, order bias, which may
affect their evaluative judgments. Our findings reveal a consistent bias in
both GPT-3.5 and GPT-4 towards the second candidate response presented,
attributed to prompt design. We also uncover lexical biases in both GPT-3.5 and
GPT-4, especially when label sets carry connotations such as numerical or
sequential, highlighting the critical need for careful label verbalizer
selection in prompt design. Additionally, our analysis indicates a tendency of
both models to favor the debate's concluding side as the winner, suggesting an
end-of-discussion bias.

摘要：在這項研究中，我們探討了大型語言模型 (LLM) 例如 GPT-3.5 和 GPT-4 在辯論評估中的能力和內在偏差。我們發現 LLM 的表現超越人類，並且超越了在廣泛的辯論評估資料集上進行微調的最新方法的表現。我們進一步探討和分析 LLM 中存在的偏差，包括位置偏差、詞彙偏差、順序偏差，這些偏差可能會影響他們的評估判斷。我們的研究結果揭示了 GPT-3.5 和 GPT-4 對提出的第二個候選人回應都存在一致的偏差，這歸因於提示設計。我們還在 GPT-3.5 和 GPT-4 中發現了詞彙偏差，特別是在標籤集帶有數值或順序等含義時，這突顯了在提示設計中仔細選擇標籤文字器的關鍵需求。此外，我們的分析表明這兩個模型都有傾向於支持辯論的結論方為獲勝者，這表明存在討論結束偏差。

##### **Improved Emotional Alignment of AI and Humans: Human Ratings of Emotions Expressed by Stable Diffusion v1, DALL-E 2, and DALL-E 3**
2405.18510v1 by James Derek Lomas, Willem van der Maden, Sohhom Bandyopadhyay, Giovanni Lion, Nirmal Patel, Gyanesh Jain, Yanna Litowsky, Haian Xue, Pieter Desmet

Generative AI systems are increasingly capable of expressing emotions via
text and imagery. Effective emotional expression will likely play a major role
in the efficacy of AI systems -- particularly those designed to support human
mental health and wellbeing. This motivates our present research to better
understand the alignment of AI expressed emotions with the human perception of
emotions. When AI tries to express a particular emotion, how might we assess
whether they are successful? To answer this question, we designed a survey to
measure the alignment between emotions expressed by generative AI and human
perceptions. Three generative image models (DALL-E 2, DALL-E 3 and Stable
Diffusion v1) were used to generate 240 examples of images, each of which was
based on a prompt designed to express five positive and five negative emotions
across both humans and robots. 24 participants recruited from the Prolific
website rated the alignment of AI-generated emotional expressions with a text
prompt used to generate the emotion (i.e., "A robot expressing the emotion
amusement"). The results of our evaluation suggest that generative AI models
are indeed capable of producing emotional expressions that are well-aligned
with a range of human emotions; however, we show that the alignment
significantly depends upon the AI model used and the emotion itself. We analyze
variations in the performance of these systems to identify gaps for future
improvement. We conclude with a discussion of the implications for future AI
systems designed to support mental health and wellbeing.

摘要：生成式 AI 系統越來越能夠透過文字和圖像表達情緒。有效的表達情緒很可能會在 AI 系統的效能中扮演重要角色，尤其是那些設計用來支持人類心理健康和福祉的系統。這激勵了我們目前的這項研究，以期能更了解 AI 表達的情緒與人類對情緒的感知之間的對齊。當 AI 嘗試表達特定情緒時，我們該如何評估他們是否成功？為了回答這個問題，我們設計了一項調查，以衡量生成式 AI 表達的情緒與人類感知之間的對齊。三個生成式影像模型（DALL-E 2、DALL-E 3 和 Stable Diffusion v1）用於產生 240 個影像範例，每個範例都基於一個提示，旨在表達人類和機器人五種正向和五種負向情緒。從 Prolific 網站招募的 24 位參與者評估了 AI 生成的表情與用於產生情緒的文字提示之間的對齊（例如，「表達娛樂情緒的機器人」）。我們的評估結果表明，生成式 AI 模型確實能夠產生與一系列人類情緒高度對齊的情緒表達；然而，我們表明，對齊在很大程度上取決於所使用的 AI 模型和情緒本身。我們分析這些系統效能的變化，以找出未來改進的差距。我們最後討論了對未來旨在支持心理健康和福祉的 AI 系統的影響。

##### **A Review and Implementation of Object Detection Models and Optimizations for Real-time Medical Mask Detection during the COVID-19 Pandemic**
2405.18387v1 by Ioanna Gogou, Dimitrios Koutsomitropoulos

Convolutional Neural Networks (CNN) are commonly used for the problem of
object detection thanks to their increased accuracy. Nevertheless, the
performance of CNN-based detection models is ambiguous when detection speed is
considered. To the best of our knowledge, there has not been sufficient
evaluation of the available methods in terms of the speed/accuracy trade-off in
related literature. This work assesses the most fundamental object detection
models on the Common Objects in Context (COCO) dataset with respect to this
trade-off, their memory consumption, and computational and storage cost. Next,
we select a highly efficient model called YOLOv5 to train on the topical and
unexplored dataset of human faces with medical masks, the Properly-Wearing
Masked Faces Dataset (PWMFD), and analyze the benefits of specific optimization
techniques for real-time medical mask detection: transfer learning, data
augmentations, and a Squeeze-and-Excitation attention mechanism. Using our
findings in the context of the COVID-19 pandemic, we propose an optimized model
based on YOLOv5s using transfer learning for the detection of correctly and
incorrectly worn medical masks that surpassed more than two times in speed (69
frames per second) the state-of-the-art model SE-YOLOv3 on the PWMFD dataset
while maintaining the same level of mean Average Precision (67%).

摘要：卷積神經網路 (CNN) 因其準確度高而常被用於目標偵測問題。然而，當考量偵測速度時，基於 CNN 的偵測模型效能卻模稜兩可。據我們所知，相關文獻中尚未對可用方法進行足夠的評估，以了解速度/準確度的權衡取捨。本研究針對 Common Objects in Context (COCO) 資料集評估最基本的目標偵測模型，考量上述權衡取捨、記憶體消耗，以及運算和儲存成本。接著，我們選擇一個名為 YOLOv5 的高效率模型，在主題性且尚未探索的人臉戴醫用口罩資料集 Properly-Wearing Masked Faces Dataset (PWMFD) 上進行訓練，並分析特定最佳化技術對即時醫用口罩偵測的優點：遷移學習、資料擴充，以及 Squeeze-and-Excitation 注意力機制。我們在 COVID-19 疫情的背景下運用研究結果，提出一個基於 YOLOv5s 的最佳化模型，使用遷移學習偵測正確和錯誤配戴的醫用口罩，在 PWMFD 資料集上的速度比最先進的 SE-YOLOv3 模型快兩倍以上 (每秒 69 幀)，同時維持相同等級的平均準確度 (67%)。

##### **Brain Tumor Segmentation (BraTS) Challenge 2024: Meningioma Radiotherapy Planning Automated Segmentation**
2405.18383v1 by Dominic LaBella, Katherine Schumacher, Michael Mix, Kevin Leu, Shan McBurney-Lin, Pierre Nedelec, Javier Villanueva-Meyer, Jonathan Shapey, Tom Vercauteren, Kazumi Chia, Omar Al-Salihi, Justin Leu, Lia Halasz, Yury Velichko, Chunhao Wang, John Kirkpatrick, Scott Floyd, Zachary J. Reitman, Trey Mullikin, Ulas Bagci, Sean Sachdev, Jona A. Hattangadi-Gluth, Tyler Seibert, Nikdokht Farid, Connor Puett, Matthew W. Pease, Kevin Shiue, Syed Muhammad Anwar, Shahriar Faghani, Muhammad Ammar Haider, Pranav Warman, Jake Albrecht, András Jakab, Mana Moassefi, Verena Chung, Alejandro Aristizabal, Alexandros Karargyris, Hasan Kassem, Sarthak Pati, Micah Sheller, Christina Huang, Aaron Coley, Siddharth Ghanta, Alex Schneider, Conrad Sharp, Rachit Saluja, Florian Kofler, Philipp Lohmann, Phillipp Vollmuth, Louis Gagnon, Maruf Adewole, Hongwei Bran Li, Anahita Fathi Kazerooni, Nourel Hoda Tahon, Udunna Anazodo, Ahmed W. Moawad, Bjoern Menze, Marius George Linguraru, Mariam Aboian, Benedikt Wiestler, Ujjwal Baid, Gian-Marco Conte, Andreas M. T. Rauschecker, Ayman Nada, Aly H. Abayazeed, Raymond Huang, Maria Correia de Verdier, Jeffrey D. Rudie, Spyridon Bakas, Evan Calabrese

The 2024 Brain Tumor Segmentation Meningioma Radiotherapy (BraTS-MEN-RT)
challenge aims to advance automated segmentation algorithms using the largest
known multi-institutional dataset of radiotherapy planning brain MRIs with
expert-annotated target labels for patients with intact or post-operative
meningioma that underwent either conventional external beam radiotherapy or
stereotactic radiosurgery. Each case includes a defaced 3D post-contrast
T1-weighted radiotherapy planning MRI in its native acquisition space,
accompanied by a single-label "target volume" representing the gross tumor
volume (GTV) and any at-risk post-operative site. Target volume annotations
adhere to established radiotherapy planning protocols, ensuring consistency
across cases and institutions. For pre-operative meningiomas, the target volume
encompasses the entire GTV and associated nodular dural tail, while for
post-operative cases, it includes at-risk resection cavity margins as
determined by the treating institution. Case annotations were reviewed and
approved by expert neuroradiologists and radiation oncologists. Participating
teams will develop, containerize, and evaluate automated segmentation models
using this comprehensive dataset. Model performance will be assessed using the
lesion-wise Dice Similarity Coefficient and the 95% Hausdorff distance. The
top-performing teams will be recognized at the Medical Image Computing and
Computer Assisted Intervention Conference in October 2024. BraTS-MEN-RT is
expected to significantly advance automated radiotherapy planning by enabling
precise tumor segmentation and facilitating tailored treatment, ultimately
improving patient outcomes.

摘要：2024 年腦瘤分割腦膜瘤放射治療 (BraTS-MEN-RT) 挑戰旨在使用已知最大的放射治療規劃腦部 MRI 多機構資料集，來推進自動分割演算法，其中包含接受傳統體外放射治療或立體定向放射外科手術的完整或術後腦膜瘤患者的專家標註目標標籤。每個案例都包含一個去識別化的 3D 對比後 T1 加權放射治療規劃 MRI，在原生擷取空間中，並附有一個代表總腫瘤體積 (GTV) 和任何有風險的術後部位的單標籤「目標體積」。目標體積註解遵循既定的放射治療規劃協議，確保各個案例和機構之間的一致性。對於術前腦膜瘤，目標體積包含整個 GTV 和相關結節性硬腦膜尾，而對於術後病例，則包括由治療機構確定的有風險的切除腔隙邊緣。案例註解已由專家神經放射科醫師和放射腫瘤科醫師審查並核准。參與團隊將使用這個全面的資料集來開發、封裝和評估自動分割模型。模型效能將使用病灶明智的 Dice 相似性係數和 95% Hausdorff 距離進行評估。表現最佳的團隊將在 2024 年 10 月的醫學影像運算和電腦輔助介入會議上獲得肯定。預計 BraTS-MEN-RT 將透過實現精確的腫瘤分割和促進客製化治療來大幅推進自動放射治療規劃，最終改善患者的治療結果。

##### **Intelligent Clinical Documentation: Harnessing Generative AI for Patient-Centric Clinical Note Generation**
2405.18346v1 by Anjanava Biswas, Wrick Talukdar

Comprehensive clinical documentation is crucial for effective healthcare
delivery, yet it poses a significant burden on healthcare professionals,
leading to burnout, increased medical errors, and compromised patient safety.
This paper explores the potential of generative AI (Artificial Intelligence) to
streamline the clinical documentation process, specifically focusing on
generating SOAP (Subjective, Objective, Assessment, Plan) and BIRP (Behavior,
Intervention, Response, Plan) notes. We present a case study demonstrating the
application of natural language processing (NLP) and automatic speech
recognition (ASR) technologies to transcribe patient-clinician interactions,
coupled with advanced prompting techniques to generate draft clinical notes
using large language models (LLMs). The study highlights the benefits of this
approach, including time savings, improved documentation quality, and enhanced
patient-centered care. Additionally, we discuss ethical considerations, such as
maintaining patient confidentiality and addressing model biases, underscoring
the need for responsible deployment of generative AI in healthcare settings.
The findings suggest that generative AI has the potential to revolutionize
clinical documentation practices, alleviating administrative burdens and
enabling healthcare professionals to focus more on direct patient care.

摘要：全面的臨床文件對於有效的醫療保健服務至關重要，但它對醫療保健專業人員造成了重大負擔，導致倦怠、醫療錯誤增加以及患者安全受到影響。本文探討了生成式 AI（人工智慧）簡化臨床文件流程的可能性，特別專注於生成 SOAP（主觀、客觀、評估、計畫）和 BIRP（行為、介入、反應、計畫）記錄。我們提出了一個案例研究，展示了自然語言處理（NLP）和自動語音辨識（ASR）技術在轉錄患者與臨床醫師互動方面的應用，以及結合先進的提示技術，使用大型語言模型（LLM）生成臨床記錄草稿。這項研究強調了這種方法的好處，包括節省時間、改善文件品質，以及增強以患者為中心的照護。此外，我們討論了道德考量，例如維護患者機密性和解決模型偏差，強調在醫療保健環境中負責任地部署生成式 AI 的必要性。研究結果表明，生成式 AI 有可能徹底改變臨床文件實務，減輕行政負擔，並使醫療保健專業人員能夠更多地專注於直接的患者照護。

##### **Histopathology Based AI Model Predicts Anti-Angiogenic Therapy Response in Renal Cancer Clinical Trial**
2405.18327v1 by Jay Jasti, Hua Zhong, Vandana Panwar, Vipul Jarmale, Jeffrey Miyata, Deyssy Carrillo, Alana Christie, Dinesh Rakheja, Zora Modrusan, Edward Ernest Kadel III, Niha Beig, Mahrukh Huseni, James Brugarolas, Payal Kapur, Satwik Rajaram

Predictive biomarkers of treatment response are lacking for metastatic clear
cell renal cell carcinoma (ccRCC), a tumor type that is treated with
angiogenesis inhibitors, immune checkpoint inhibitors, mTOR inhibitors and a
HIF2 inhibitor. The Angioscore, an RNA-based quantification of angiogenesis, is
arguably the best candidate to predict anti-angiogenic (AA) response. However,
the clinical adoption of transcriptomic assays faces several challenges
including standardization, time delay, and high cost. Further, ccRCC tumors are
highly heterogenous, and sampling multiple areas for sequencing is impractical.
Here we present a novel deep learning (DL) approach to predict the Angioscore
from ubiquitous histopathology slides. To overcome the lack of
interpretability, one of the biggest limitations of typical DL models, our
model produces a visual vascular network which is the basis of the model's
prediction. To test its reliability, we applied this model to multiple cohorts
including a clinical trial dataset. Our model accurately predicts the RNA-based
Angioscore on multiple independent cohorts (spearman correlations of 0.77 and
0.73). Further, the predictions help unravel meaningful biology such as
association of angiogenesis with grade, stage, and driver mutation status.
Finally, we find our model can predict response to AA therapy, in both a
real-world cohort and the IMmotion150 clinical trial. The predictive power of
our model vastly exceeds that of CD31, a marker of vasculature, and nearly
rivals the performance (c-index 0.66 vs 0.67) of the ground truth RNA-based
Angioscore at a fraction of the cost. By providing a robust yet interpretable
prediction of the Angioscore from histopathology slides alone, our approach
offers insights into angiogenesis biology and AA treatment response.

摘要：<paragraph>對於轉移性透明細胞腎細胞癌 (ccRCC)，一種用於治療血管生成抑制劑、免疫檢查點抑制劑、mTOR 抑制劑和 HIF2 抑制劑的腫瘤類型，目前缺乏治療反應的預測性生物標記。Angioscore 是一種基於 RNA 的血管生成量化，可以說是預測抗血管生成 (AA) 反應的最佳候選者。然而，轉錄組檢測的臨床應用面臨著標準化、時間延遲和高成本等多項挑戰。此外，ccRCC 腫瘤高度異質，對多個區域進行取樣以進行測序並不切實際。在此，我們提出了一種新穎的深度學習 (DL) 方法，可從普遍存在的組織病理切片中預測 Angioscore。為了克服可解釋性的缺乏，這是典型 DL 模型最大的限制之一，我們的模型產生了一個視覺血管網路，這是模型預測的基礎。為了測試其可靠性，我們將此模型應用於多個群組，包括臨床試驗資料集。我們的模型準確預測了多個獨立群組的基於 RNA 的 Angioscore（spearman 相關係數為 0.77 和 0.73）。此外，這些預測有助於解開有意義的生物學，例如血管生成與等級、階段和驅動突變狀態的關聯。最後，我們發現我們的模型可以預測對 AA 治療的反應，無論是在現實世界群組還是 IMmotion150 臨床試驗中。我們模型的預測能力遠遠超過血管標記 CD31，並且幾乎與基於 RNA 的真實 Angioscore 的效能（c 指數 0.66 對 0.67）相當，而成本卻只是後者的零頭。通過僅從組織病理切片中提供對 Angioscore 的強大且可解釋的預測，我們的方法提供了對血管生成生物學和 AA 治療反應的見解。</paragraph>

##### **Edinburgh Clinical NLP at MEDIQA-CORR 2024: Guiding Large Language Models with Hints**
2405.18028v1 by Aryo Pradipta Gema, Chaeeun Lee, Pasquale Minervini, Luke Daines, T. Ian Simpson, Beatrice Alex

The MEDIQA-CORR 2024 shared task aims to assess the ability of Large Language
Models (LLMs) to identify and correct medical errors in clinical notes. In this
study, we evaluate the capability of general LLMs, specifically GPT-3.5 and
GPT-4, to identify and correct medical errors with multiple prompting
strategies. Recognising the limitation of LLMs in generating accurate
corrections only via prompting strategies, we propose incorporating error-span
predictions from a smaller, fine-tuned model in two ways: 1) by presenting it
as a hint in the prompt and 2) by framing it as multiple-choice questions from
which the LLM can choose the best correction. We found that our proposed
prompting strategies significantly improve the LLM's ability to generate
corrections. Our best-performing solution with 8-shot + CoT + hints ranked
sixth in the shared task leaderboard. Additionally, our comprehensive analyses
show the impact of the location of the error sentence, the prompted role, and
the position of the multiple-choice option on the accuracy of the LLM. This
prompts further questions about the readiness of LLM to be implemented in
real-world clinical settings.

摘要：MEDIQA-CORR 2024 共享任務旨在評估大型語言模型 (LLM) 在臨床筆記中識別和更正醫療錯誤的能力。在此研究中，我們評估通用 LLM，特別是 GPT-3.5 和 GPT-4，識別和更正醫療錯誤的能力，並採用多種提示策略。認識到 LLM 僅通過提示策略生成準確更正的限制，我們建議以兩種方式整合來自較小的微調模型的錯誤範圍預測：1) 在提示中將其表示為提示，以及 2) 將其設定為多選題，LLM 可以從中選擇最佳更正。我們發現我們提出的提示策略顯著提高了 LLM 生成更正的能力。我們在共享任務排行榜中排名第六的最佳執行方案是 8 次嘗試 + CoT + 提示。此外，我們全面的分析顯示了錯誤句子位置、提示角色和多選項位置對 LLM 準確性的影響。這引發了進一步的問題，即 LLM 是否已準備好實施在現實世界的臨床環境中。

##### **Towards Clinical AI Fairness: Filling Gaps in the Puzzle**
2405.17921v1 by Mingxuan Liu, Yilin Ning, Salinelat Teixayavong, Xiaoxuan Liu, Mayli Mertens, Yuqing Shang, Xin Li, Di Miao, Jie Xu, Daniel Shu Wei Ting, Lionel Tim-Ee Cheng, Jasmine Chiat Ling Ong, Zhen Ling Teo, Ting Fang Tan, Narrendar RaviChandran, Fei Wang, Leo Anthony Celi, Marcus Eng Hock Ong, Nan Liu

The ethical integration of Artificial Intelligence (AI) in healthcare
necessitates addressing fairness-a concept that is highly context-specific
across medical fields. Extensive studies have been conducted to expand the
technical components of AI fairness, while tremendous calls for AI fairness
have been raised from healthcare. Despite this, a significant disconnect
persists between technical advancements and their practical clinical
applications, resulting in a lack of contextualized discussion of AI fairness
in clinical settings. Through a detailed evidence gap analysis, our review
systematically pinpoints several deficiencies concerning both healthcare data
and the provided AI fairness solutions. We highlight the scarcity of research
on AI fairness in many medical domains where AI technology is increasingly
utilized. Additionally, our analysis highlights a substantial reliance on group
fairness, aiming to ensure equality among demographic groups from a macro
healthcare system perspective; in contrast, individual fairness, focusing on
equity at a more granular level, is frequently overlooked. To bridge these
gaps, our review advances actionable strategies for both the healthcare and AI
research communities. Beyond applying existing AI fairness methods in
healthcare, we further emphasize the importance of involving healthcare
professionals to refine AI fairness concepts and methods to ensure contextually
relevant and ethically sound AI applications in healthcare.

摘要：人工智慧 (AI) 在醫療保健中的倫理整合需要處理公平性——這個概念在各個醫療領域中高度特定於情境。已經進行了廣泛的研究來擴展 AI 公平性的技術組成，而來自醫療保健的 AI 公平性呼聲也很大。儘管如此，技術進步與其實際臨床應用之間仍然存在顯著的脫節，導致在臨床環境中缺乏對 AI 公平性的情境化討論。透過詳細的證據差距分析，我們的回顧系統性地找出了與醫療保健資料和提供的 AI 公平性解決方案相關的幾個缺陷。我們強調在許多醫療領域中缺乏對 AI 公平性的研究，而這些領域中 AI 技術的使用越來越多。此外，我們的分析強調了對群體公平性的實質依賴，旨在從巨觀醫療保健系統的角度確保人口群體之間的平等；相比之下，關注更細緻層級公平性的個別公平性常常被忽視。為了彌補這些差距，我們的回顧提出了針對醫療保健和 AI 研究社群的可行策略。除了在醫療保健中應用現有的 AI 公平性方法之外，我們進一步強調了讓醫療保健專業人員參與的重要性，以完善 AI 公平性概念和方法，以確保在醫療保健中具有情境相關性和符合倫理的 AI 應用。

