{"2411.13476": {"publish_time": "2024-11-20", "title": "When Precision Meets Position: BFloat16 Breaks Down RoPE in Long-Context Training", "paper_summary": "Extending context window sizes allows large language models (LLMs) to process\nlonger sequences and handle more complex tasks. Rotary Positional Embedding\n(RoPE) has become the de facto standard due to its relative positional encoding\nproperties that benefit long-context training. However, we observe that using\nRoPE with BFloat16 format results in numerical issues, causing it to deviate\nfrom its intended relative positional encoding, especially in long-context\nscenarios. This issue arises from BFloat16's limited precision and accumulates\nas context length increases, with the first token contributing significantly to\nthis problem. To address this, we develop AnchorAttention, a plug-and-play\nattention method that alleviates numerical issues caused by BFloat16, improves\nlong-context capabilities, and speeds up training. AnchorAttention reduces\nunnecessary attention computations, maintains semantic coherence, and boosts\ncomputational efficiency by treating the first token as a shared anchor with a\nconsistent position ID, making it visible to all documents within the training\ncontext. Experiments on three types of LLMs demonstrate that AnchorAttention\nsignificantly improves long-context performance and reduces training time by\nover 50\\% compared to standard full attention mechanisms, while preserving the\noriginal LLM's capabilities on general tasks. Our code is available at\nhttps://github.com/haonan3/AnchorContext.", "paper_summary_zh": "\u64f4\u5c55\u4e0a\u4e0b\u6587\u8996\u7a97\u5927\u5c0f\u5141\u8a31\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u8655\u7406\u66f4\u9577\u7684\u5e8f\u5217\u4e26\u8655\u7406\u66f4\u8907\u96dc\u7684\u4efb\u52d9\u3002\u65cb\u8f49\u4f4d\u7f6e\u5d4c\u5165 (RoPE) \u5df2\u6210\u70ba\u4e8b\u5be6\u4e0a\u7684\u6a19\u6e96\uff0c\u56e0\u70ba\u5b83\u5177\u6709\u76f8\u5c0d\u4f4d\u7f6e\u7de8\u78bc\u7279\u6027\uff0c\u6709\u5229\u65bc\u9577\u6587\u8108\u8a13\u7df4\u3002\u7136\u800c\uff0c\u6211\u5011\u89c0\u5bdf\u5230\u4f7f\u7528 BFloat16 \u683c\u5f0f\u7684 RoPE \u6703\u5c0e\u81f4\u6578\u503c\u554f\u984c\uff0c\u5c0e\u81f4\u5b83\u504f\u96e2\u5176\u9810\u671f\u7684\u76f8\u5c0d\u4f4d\u7f6e\u7de8\u78bc\uff0c\u7279\u5225\u662f\u5728\u9577\u6587\u8108\u5834\u666f\u4e2d\u3002\u6b64\u554f\u984c\u6e90\u81ea BFloat16 \u7684\u6709\u9650\u7cbe\u5ea6\uff0c\u4e26\u96a8\u8457\u6587\u8108\u9577\u5ea6\u7684\u589e\u52a0\u800c\u7d2f\u7a4d\uff0c\u5176\u4e2d\u7b2c\u4e00\u500b\u6a19\u8a18\u5c0d\u6b64\u554f\u984c\u6709\u986f\u8457\u7684\u5f71\u97ff\u3002\u70ba\u4e86\u89e3\u6c7a\u9019\u500b\u554f\u984c\uff0c\u6211\u5011\u958b\u767c\u4e86 AnchorAttention\uff0c\u9019\u662f\u4e00\u7a2e\u5373\u63d2\u5373\u7528\u7684\u6ce8\u610f\u529b\u65b9\u6cd5\uff0c\u53ef\u4ee5\u6e1b\u8f15\u7531 BFloat16 \u5f15\u8d77\u7684\u6578\u503c\u554f\u984c\uff0c\u6539\u5584\u9577\u6587\u8108\u80fd\u529b\uff0c\u4e26\u52a0\u5feb\u8a13\u7df4\u901f\u5ea6\u3002AnchorAttention \u6e1b\u5c11\u4e86\u4e0d\u5fc5\u8981\u7684\u6ce8\u610f\u529b\u8a08\u7b97\uff0c\u7dad\u6301\u8a9e\u7fa9\u4e00\u81f4\u6027\uff0c\u4e26\u901a\u904e\u5c07\u7b2c\u4e00\u500b\u6a19\u8a18\u8996\u70ba\u5177\u6709\u56fa\u5b9a\u4f4d\u7f6e ID \u7684\u5171\u4eab\u9328\u9ede\u4f86\u63d0\u5347\u904b\u7b97\u6548\u7387\uff0c\u4f7f\u5176\u5728\u8a13\u7df4\u6587\u8108\u4e2d\u7684\u6240\u6709\u6587\u4ef6\u90fd\u53ef\u898b\u3002\u5728\u4e09\u7a2e\u985e\u578b\u7684 LLM \u4e0a\u9032\u884c\u7684\u5be6\u9a57\u8868\u660e\uff0c\u8207\u6a19\u6e96\u5168\u6ce8\u610f\u529b\u6a5f\u5236\u76f8\u6bd4\uff0cAnchorAttention \u5927\u5e45\u63d0\u5347\u4e86\u9577\u6587\u8108\u6548\u80fd\uff0c\u4e26\u5c07\u8a13\u7df4\u6642\u9593\u7e2e\u77ed\u4e86 50% \u4ee5\u4e0a\uff0c\u540c\u6642\u4fdd\u7559\u4e86 LLM \u5728\u4e00\u822c\u4efb\u52d9\u4e0a\u7684\u539f\u59cb\u80fd\u529b\u3002\u6211\u5011\u7684\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/haonan3/AnchorContext \u53d6\u5f97\u3002", "author": "Haonan Wang et.al.", "authors": "Haonan Wang, Qian Liu, Chao Du, Tongyao Zhu, Cunxiao Du, Kenji Kawaguchi, Tianyu Pang", "id": "2411.13476v1", "paper_url": "http://arxiv.org/abs/2411.13476v1", "repo": "https://github.com/haonan3/anchorcontext"}}