{"2406.14969": {"publish_time": "2024-06-21", "title": "Uni-Mol2: Exploring Molecular Pretraining Model at Scale", "paper_summary": "In recent years, pretraining models have made significant advancements in the\nfields of natural language processing (NLP), computer vision (CV), and life\nsciences. The significant advancements in NLP and CV are predominantly driven\nby the expansion of model parameters and data size, a phenomenon now recognized\nas the scaling laws. However, research exploring scaling law in molecular\npretraining models remains unexplored. In this work, we present Uni-Mol2 , an\ninnovative molecular pretraining model that leverages a two-track transformer\nto effectively integrate features at the atomic level, graph level, and\ngeometry structure level. Along with this, we systematically investigate the\nscaling law within molecular pretraining models, characterizing the power-law\ncorrelations between validation loss and model size, dataset size, and\ncomputational resources. Consequently, we successfully scale Uni-Mol2 to 1.1\nbillion parameters through pretraining on 800 million conformations, making it\nthe largest molecular pretraining model to date. Extensive experiments show\nconsistent improvement in the downstream tasks as the model size grows. The\nUni-Mol2 with 1.1B parameters also outperforms existing methods, achieving an\naverage 27% improvement on the QM9 and 14% on COMPAS-1D dataset.", "paper_summary_zh": "\u8fd1\u5e74\u6765\uff0c\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406 (NLP)\u3001\u8ba1\u7b97\u673a\u89c6\u89c9 (CV) \u548c\u751f\u547d\u79d1\u5b66\u9886\u57df\u53d6\u5f97\u4e86\u91cd\u5927\u8fdb\u5c55\u3002NLP \u548c CV \u7684\u91cd\u5927\u8fdb\u6b65\u4e3b\u8981\u7531\u6a21\u578b\u53c2\u6570\u548c\u6570\u636e\u91cf\u7684\u6269\u5c55\u63a8\u52a8\uff0c\u8fd9\u4e00\u73b0\u8c61\u73b0\u5728\u88ab\u8ba4\u4e3a\u662f\u7f29\u653e\u5b9a\u5f8b\u3002\u7136\u800c\uff0c\u63a2\u7d22\u5206\u5b50\u9884\u8bad\u7ec3\u6a21\u578b\u4e2d\u7f29\u653e\u5b9a\u5f8b\u7684\u7814\u7a76\u4ecd\u672a\u5f97\u5230\u63a2\u7d22\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86 Uni-Mol2\uff0c\u4e00\u79cd\u521b\u65b0\u7684\u5206\u5b50\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5b83\u5229\u7528\u53cc\u8f68\u8f6c\u6362\u5668\u6709\u6548\u5730\u6574\u5408\u539f\u5b50\u7ea7\u3001\u56fe\u7ea7\u548c\u51e0\u4f55\u7ed3\u6784\u7ea7\u7684\u7279\u5f81\u3002\u9664\u6b64\u4e4b\u5916\uff0c\u6211\u4eec\u7cfb\u7edf\u5730\u7814\u7a76\u4e86\u5206\u5b50\u9884\u8bad\u7ec3\u6a21\u578b\u4e2d\u7684\u7f29\u653e\u5b9a\u5f8b\uff0c\u63cf\u8ff0\u4e86\u9a8c\u8bc1\u635f\u5931\u4e0e\u6a21\u578b\u5927\u5c0f\u3001\u6570\u636e\u96c6\u5927\u5c0f\u548c\u8ba1\u7b97\u8d44\u6e90\u4e4b\u95f4\u7684\u5e42\u5f8b\u76f8\u5173\u6027\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u6210\u529f\u5730\u5c06 Uni-Mol2 \u6269\u5c55\u5230 11 \u4ebf\u4e2a\u53c2\u6570\uff0c\u901a\u8fc7\u5bf9 8 \u4ebf\u4e2a\u6784\u8c61\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u4f7f\u5176\u6210\u4e3a\u8fc4\u4eca\u4e3a\u6b62\u6700\u5927\u7684\u5206\u5b50\u9884\u8bad\u7ec3\u6a21\u578b\u3002\u5927\u91cf\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u968f\u7740\u6a21\u578b\u5927\u5c0f\u7684\u589e\u957f\uff0c\u4e0b\u6e38\u4efb\u52a1\u6301\u7eed\u5f97\u5230\u6539\u5584\u3002\u5177\u6709 1.1B \u53c2\u6570\u7684 Uni-Mol2 \u4e5f\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728 QM9 \u4e0a\u5b9e\u73b0\u4e86\u5e73\u5747 27% \u7684\u6539\u8fdb\uff0c\u5728 COMPAS-1D \u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86 14% \u7684\u6539\u8fdb\u3002", "author": "Xiaohong Ji et.al.", "authors": "Xiaohong Ji, Zhen Wang, Zhifeng Gao, Hang Zheng, Linfeng Zhang, Guolin Ke, Weinan E", "id": "2406.14969v2", "paper_url": "http://arxiv.org/abs/2406.14969v2", "repo": "null"}}