{"2408.02859": {"publish_time": "2024-08-05", "title": "Multistain Pretraining for Slide Representation Learning in Pathology", "paper_summary": "Developing self-supervised learning (SSL) models that can learn universal and\ntransferable representations of H&E gigapixel whole-slide images (WSIs) is\nbecoming increasingly valuable in computational pathology. These models hold\nthe potential to advance critical tasks such as few-shot classification, slide\nretrieval, and patient stratification. Existing approaches for slide\nrepresentation learning extend the principles of SSL from small images (e.g.,\n224 x 224 patches) to entire slides, usually by aligning two different\naugmentations (or views) of the slide. Yet the resulting representation remains\nconstrained by the limited clinical and biological diversity of the views.\nInstead, we postulate that slides stained with multiple markers, such as\nimmunohistochemistry, can be used as different views to form a rich\ntask-agnostic training signal. To this end, we introduce Madeleine, a\nmultimodal pretraining strategy for slide representation learning. Madeleine is\ntrained with a dual global-local cross-stain alignment objective on large\ncohorts of breast cancer samples (N=4,211 WSIs across five stains) and kidney\ntransplant samples (N=12,070 WSIs across four stains). We demonstrate the\nquality of slide representations learned by Madeleine on various downstream\nevaluations, ranging from morphological and molecular classification to\nprognostic prediction, comprising 21 tasks using 7,299 WSIs from multiple\nmedical centers. Code is available at https://github.com/mahmoodlab/MADELEINE.", "paper_summary_zh": "\u958b\u767c\u81ea\u76e3\u7763\u5b78\u7fd2 (SSL) \u6a21\u578b\uff0c\u53ef\u4ee5\u5b78\u7fd2 H&E \u5409\u50cf\u7d20\u5168\u5207\u7247\u5f71\u50cf (WSI) \u7684\u901a\u7528\u4e14\u53ef\u8f49\u79fb\u8868\u793a\uff0c\u5728\u8a08\u7b97\u75c5\u7406\u5b78\u4e2d\u6b63\u8b8a\u5f97\u8d8a\u4f86\u8d8a\u6709\u50f9\u503c\u3002\u9019\u4e9b\u6a21\u578b\u6709\u6f5b\u529b\u63a8\u9032\u95dc\u9375\u4efb\u52d9\uff0c\u4f8b\u5982\u5c11\u6b21\u5206\u985e\u3001\u5207\u7247\u6aa2\u7d22\u548c\u60a3\u8005\u5206\u5c64\u3002\u73fe\u6709\u7684\u5207\u7247\u8868\u793a\u5b78\u7fd2\u65b9\u6cd5\u5c07 SSL \u7684\u539f\u7406\u5f9e\u5c0f\u5f71\u50cf\uff08\u4f8b\u5982 224 x 224 \u88dc\u4e01\uff09\u5ef6\u4f38\u5230\u6574\u500b\u5207\u7247\uff0c\u901a\u5e38\u900f\u904e\u5c0d\u9f4a\u5207\u7247\u7684\u5169\u500b\u4e0d\u540c\u64f4\u589e\uff08\u6216\u8996\u5716\uff09\u3002\u7136\u800c\uff0c\u751f\u6210\u7684\u8868\u793a\u4ecd\u53d7\u5230\u8996\u5716\u6709\u9650\u7684\u81e8\u5e8a\u548c\u751f\u7269\u591a\u6a23\u6027\u7684\u9650\u5236\u3002\u76f8\u53cd\uff0c\u6211\u5011\u5047\u8a2d\u4f7f\u7528\u591a\u7a2e\u6a19\u8a18\u67d3\u8272\u7684\u5207\u7247\uff0c\u4f8b\u5982\u514d\u75ab\u7d44\u7e54\u5316\u5b78\u67d3\u8272\uff0c\u53ef\u4ee5\u7528\u4f5c\u4e0d\u540c\u7684\u8996\u5716\u4f86\u5f62\u6210\u8c50\u5bcc\u7684\u8207\u4efb\u52d9\u7121\u95dc\u7684\u8a13\u7df4\u8a0a\u865f\u3002\u70ba\u6b64\uff0c\u6211\u5011\u4ecb\u7d39 Madeleine\uff0c\u4e00\u7a2e\u7528\u65bc\u5207\u7247\u8868\u793a\u5b78\u7fd2\u7684\u591a\u6a21\u5f0f\u9810\u8a13\u7df4\u7b56\u7565\u3002Madeleine \u4f7f\u7528\u96d9\u91cd\u5168\u5c40-\u5c40\u90e8\u8de8\u67d3\u8272\u5c0d\u9f4a\u76ee\u6a19\u5728\u5927\u91cf\u4e73\u764c\u6a23\u672c\uff08N=4,211 \u500b\u6a6b\u8de8\u4e94\u7a2e\u67d3\u8272\u7684 WSI\uff09\u548c\u814e\u81df\u79fb\u690d\u6a23\u672c\uff08N=12,070 \u500b\u6a6b\u8de8\u56db\u7a2e\u67d3\u8272\u7684 WSI\uff09\u4e0a\u9032\u884c\u8a13\u7df4\u3002\u6211\u5011\u5728\u5404\u7a2e\u4e0b\u6e38\u8a55\u4f30\u4e2d\u5c55\u793a\u4e86 Madeleine \u5b78\u7fd2\u7684\u5207\u7247\u8868\u793a\u7684\u54c1\u8cea\uff0c\u5f9e\u5f62\u614b\u548c\u5206\u5b50\u5206\u985e\u5230\u9810\u5f8c\u9810\u6e2c\uff0c\u5305\u62ec\u4f7f\u7528\u4f86\u81ea\u591a\u500b\u91ab\u7642\u4e2d\u5fc3\u7684 7,299 \u500b WSI \u7684 21 \u9805\u4efb\u52d9\u3002\u7a0b\u5f0f\u78bc\u53ef\u5728 https://github.com/mahmoodlab/MADELEINE \u53d6\u5f97\u3002", "author": "Guillaume Jaume et.al.", "authors": "Guillaume Jaume, Anurag Vaidya, Andrew Zhang, Andrew H. Song, Richard J. Chen, Sharifa Sahai, Dandan Mo, Emilio Madrigal, Long Phi Le, Faisal Mahmood", "id": "2408.02859v1", "paper_url": "http://arxiv.org/abs/2408.02859v1", "repo": "null"}}