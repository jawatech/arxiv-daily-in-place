{"2407.20224": {"publish_time": "2024-07-29", "title": "Can Editing LLMs Inject Harm?", "paper_summary": "Knowledge editing techniques have been increasingly adopted to efficiently\ncorrect the false or outdated knowledge in Large Language Models (LLMs), due to\nthe high cost of retraining from scratch. Meanwhile, one critical but\nunder-explored question is: can knowledge editing be used to inject harm into\nLLMs? In this paper, we propose to reformulate knowledge editing as a new type\nof safety threat for LLMs, namely Editing Attack, and conduct a systematic\ninvestigation with a newly constructed dataset EditAttack. Specifically, we\nfocus on two typical safety risks of Editing Attack including Misinformation\nInjection and Bias Injection. For the risk of misinformation injection, we\nfirst categorize it into commonsense misinformation injection and long-tail\nmisinformation injection. Then, we find that editing attacks can inject both\ntypes of misinformation into LLMs, and the effectiveness is particularly high\nfor commonsense misinformation injection. For the risk of bias injection, we\ndiscover that not only can biased sentences be injected into LLMs with high\neffectiveness, but also one single biased sentence injection can cause a bias\nincrease in general outputs of LLMs, which are even highly irrelevant to the\ninjected sentence, indicating a catastrophic impact on the overall fairness of\nLLMs. Then, we further illustrate the high stealthiness of editing attacks,\nmeasured by their impact on the general knowledge and reasoning capacities of\nLLMs, and show the hardness of defending editing attacks with empirical\nevidence. Our discoveries demonstrate the emerging misuse risks of knowledge\nediting techniques on compromising the safety alignment of LLMs.", "paper_summary_zh": "<paragraph>\u77e5\u8b58\u7de8\u8f2f\u6280\u8853\u5df2\u88ab\u5ee3\u6cdb\u63a1\u7528\uff0c\u4ee5\u6709\u6548\u66f4\u6b63\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u4e2d\u932f\u8aa4\u6216\u904e\u6642\u7684\u77e5\u8b58\uff0c\u56e0\u70ba\u5f9e\u982d\u958b\u59cb\u91cd\u65b0\u8a13\u7df4\u7684\u6210\u672c\u5f88\u9ad8\u3002\u540c\u6642\uff0c\u4e00\u500b\u95dc\u9375\u4f46\u5c1a\u672a\u5145\u5206\u63a2\u8a0e\u7684\u554f\u984c\u662f\uff1a\u77e5\u8b58\u7de8\u8f2f\u662f\u5426\u53ef\u7528\u65bc\u5411 LLM \u6ce8\u5165\u5371\u5bb3\uff1f\u5728\u672c\u6587\u4e2d\uff0c\u6211\u5011\u5efa\u8b70\u5c07\u77e5\u8b58\u7de8\u8f2f\u91cd\u65b0\u8868\u8ff0\u70ba LLM \u7684\u4e00\u7a2e\u65b0\u578b\u5b89\u5168\u5a01\u8105\uff0c\u5373\u7de8\u8f2f\u653b\u64ca\uff0c\u4e26\u4f7f\u7528\u65b0\u69cb\u5efa\u7684\u8cc7\u6599\u96c6 EditAttack \u9032\u884c\u7cfb\u7d71\u8abf\u67e5\u3002\u5177\u9ad4\u4f86\u8aaa\uff0c\u6211\u5011\u5c08\u6ce8\u65bc\u7de8\u8f2f\u653b\u64ca\u7684\u5169\u500b\u5178\u578b\u5b89\u5168\u98a8\u96aa\uff0c\u5305\u62ec\u932f\u8aa4\u8a0a\u606f\u6ce8\u5165\u548c\u504f\u5dee\u6ce8\u5165\u3002\u5c0d\u65bc\u932f\u8aa4\u8a0a\u606f\u6ce8\u5165\u7684\u98a8\u96aa\uff0c\u6211\u5011\u9996\u5148\u5c07\u5176\u5206\u985e\u70ba\u5e38\u8b58\u932f\u8aa4\u8a0a\u606f\u6ce8\u5165\u548c\u9577\u5c3e\u932f\u8aa4\u8a0a\u606f\u6ce8\u5165\u3002\u7136\u5f8c\uff0c\u6211\u5011\u767c\u73fe\u7de8\u8f2f\u653b\u64ca\u53ef\u4ee5\u5c07\u9019\u5169\u7a2e\u932f\u8aa4\u8a0a\u606f\u6ce8\u5165 LLM\uff0c\u4e26\u4e14\u5c0d\u65bc\u5e38\u8b58\u932f\u8aa4\u8a0a\u606f\u6ce8\u5165\uff0c\u5176\u6709\u6548\u6027\u7279\u5225\u9ad8\u3002\u5c0d\u65bc\u504f\u5dee\u6ce8\u5165\u7684\u98a8\u96aa\uff0c\u6211\u5011\u767c\u73fe\u4e0d\u50c5\u53ef\u4ee5\u5c07\u6709\u504f\u5dee\u7684\u53e5\u5b50\u4ee5\u9ad8\u6548\u7387\u6ce8\u5165 LLM\uff0c\u800c\u4e14\u4e00\u500b\u6709\u504f\u5dee\u7684\u53e5\u5b50\u6ce8\u5165\u4e5f\u6703\u5c0e\u81f4 LLM \u7684\u4e00\u822c\u8f38\u51fa\u51fa\u73fe\u504f\u5dee\u589e\u52a0\uff0c\u9019\u4e9b\u8f38\u51fa\u751a\u81f3\u8207\u6ce8\u5165\u7684\u53e5\u5b50\u9ad8\u5ea6\u7121\u95dc\uff0c\u9019\u8868\u660e\u5c0d LLM \u7684\u6574\u9ad4\u516c\u5e73\u6027\u7522\u751f\u4e86\u707d\u96e3\u6027\u7684\u5f71\u97ff\u3002\u7136\u5f8c\uff0c\u6211\u5011\u9032\u4e00\u6b65\u8aaa\u660e\u4e86\u7de8\u8f2f\u653b\u64ca\u7684\u9ad8\u5ea6\u96b1\u853d\u6027\uff0c\u5176\u8861\u91cf\u6a19\u6e96\u662f\u5b83\u5011\u5c0d LLM \u7684\u4e00\u822c\u77e5\u8b58\u548c\u63a8\u7406\u80fd\u529b\u7684\u5f71\u97ff\uff0c\u4e26\u5c55\u793a\u4e86\u7528\u5be6\u8b49\u8b49\u64da\u9632\u79a6\u7de8\u8f2f\u653b\u64ca\u7684\u96e3\u5ea6\u3002\u6211\u5011\u7684\u767c\u73fe\u8b49\u660e\u4e86\u77e5\u8b58\u7de8\u8f2f\u6280\u8853\u5728\u640d\u5bb3 LLM \u7684\u5b89\u5168\u5c0d\u9f4a\u65b9\u9762\u7684\u6feb\u7528\u98a8\u96aa\u6b63\u5728\u6d6e\u73fe\u3002</paragraph>", "author": "Canyu Chen et.al.", "authors": "Canyu Chen, Baixiang Huang, Zekun Li, Zhaorun Chen, Shiyang Lai, Xiongxiao Xu, Jia-Chen Gu, Jindong Gu, Huaxiu Yao, Chaowei Xiao, Xifeng Yan, William Yang Wang, Philip Torr, Dawn Song, Kai Shu", "id": "2407.20224v2", "paper_url": "http://arxiv.org/abs/2407.20224v2", "repo": "null"}}