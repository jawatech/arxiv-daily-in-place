
### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-08-07**|**SLIM-RAFT: A Novel Fine-Tuning Approach to Improve Cross-Linguistic Performance for Mercosur Common Nomenclature**|Vin√≠cius Di Oliveira et.al.|[2408.03936v1](http://arxiv.org/abs/2408.03936v1)|null|
|**2024-08-07**|**From Words to Worth: Newborn Article Impact Prediction with LLM**|Penghai Zhao et.al.|[2408.03934v1](http://arxiv.org/abs/2408.03934v1)|null|
|**2024-08-07**|**CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases**|Xiangyan Liu et.al.|[2408.03910v1](http://arxiv.org/abs/2408.03910v1)|[link](https://github.com/modelscope/modelscope-agent)|
|**2024-08-07**|**Decoding Biases: Automated Methods and LLM Judges for Gender Bias Detection in Language Models**|Shachi H Kumar et.al.|[2408.03907v1](http://arxiv.org/abs/2408.03907v1)|null|
|**2024-08-07**|**Speech-MASSIVE: A Multilingual Speech Dataset for SLU and Beyond**|Beomseok Lee et.al.|[2408.03900v1](http://arxiv.org/abs/2408.03900v1)|[link](https://github.com/hlt-mt/speech-massive)|
|**2024-08-07**|**Simplifying Scholarly Abstracts for Accessible Digital Libraries**|Haining Wang et.al.|[2408.03899v1](http://arxiv.org/abs/2408.03899v1)|null|
|**2024-08-07**|**MORTAR: A Model-based Runtime Action Repair Framework for AI-enabled Cyber-Physical Systems**|Renzhi Wang et.al.|[2408.03892v1](http://arxiv.org/abs/2408.03892v1)|null|
|**2024-08-07**|**Personalized Clinical Note Generation from Doctor-Patient Conversations**|Nathan Brake et.al.|[2408.03874v1](http://arxiv.org/abs/2408.03874v1)|null|
|**2024-08-07**|**Inter-Series Transformer: Attending to Products in Time Series Forecasting**|Rares Cristian et.al.|[2408.03872v1](http://arxiv.org/abs/2408.03872v1)|null|
|**2024-08-07**|**BeeManc at the PLABA Track of TAC-2023: Investigating LLMs and Controllable Attributes for Improving Biomedical Text Readability**|Zihao Li et.al.|[2408.03871v1](http://arxiv.org/abs/2408.03871v1)|[link](https://github.com/hecta-uom/plaba-mu)|
|**2024-08-07**|**Why transformers are obviously good models of language**|Felix Hill et.al.|[2408.03855v1](http://arxiv.org/abs/2408.03855v1)|null|
|**2024-08-07**|**Hate Speech Detection and Classification in Amharic Text with Deep Learning**|Samuel Minale Gashe et.al.|[2408.03849v1](http://arxiv.org/abs/2408.03849v1)|null|
|**2024-08-07**|**MaxMind: A Memory Loop Network to Enhance Software Productivity based on Large Language Models**|Yuchen Dong et.al.|[2408.03841v1](http://arxiv.org/abs/2408.03841v1)|null|
|**2024-08-07**|**WalledEval: A Comprehensive Safety Evaluation Toolkit for Large Language Models**|Prannaya Gupta et.al.|[2408.03837v1](http://arxiv.org/abs/2408.03837v1)|null|
|**2024-08-07**|**Target Prompting for Information Extraction with Vision Language Model**|Dipankar Medhi et.al.|[2408.03834v1](http://arxiv.org/abs/2408.03834v1)|null|
|**2024-08-07**|**Automated Code Fix Suggestions for Accessibility Issues in Mobile Apps**|Forough Mehralian et.al.|[2408.03827v1](http://arxiv.org/abs/2408.03827v1)|null|
|**2024-08-07**|**Leveraging Variation Theory in Counterfactual Data Augmentation for Optimized Active Learning**|Simret Araya Gebreegziabher et.al.|[2408.03819v1](http://arxiv.org/abs/2408.03819v1)|null|
|**2024-08-07**|**Generative Language Models with Retrieval Augmented Generation for Automated Short Answer Scoring**|Zifan Wang et.al.|[2408.03811v1](http://arxiv.org/abs/2408.03811v1)|null|
|**2024-08-07**|**Navigating the Human Maze: Real-Time Robot Pathfinding with Generative Imitation Learning**|Martin Moder et.al.|[2408.03807v1](http://arxiv.org/abs/2408.03807v1)|null|
|**2024-08-07**|**Relevance meets Diversity: A User-Centric Framework for Knowledge Exploration through Recommendations**|Erica Coppolillo et.al.|[2408.03772v1](http://arxiv.org/abs/2408.03772v1)|[link](https://github.com/ericacoppolillo/explore)|
|**2024-08-07**|**'Finance Wizard' at the FinLLM Challenge Task: Financial Text Summarization**|Meisin Lee et.al.|[2408.03762v1](http://arxiv.org/abs/2408.03762v1)|null|
|**2024-08-07**|**Online Model-based Anomaly Detection in Multivariate Time Series: Taxonomy, Survey, Research Challenges and Future Directions**|Lucas Correia et.al.|[2408.03747v1](http://arxiv.org/abs/2408.03747v1)|null|
|**2024-08-07**|**Flexible Bayesian Last Layer Models Using Implicit Priors and Diffusion Posterior Sampling**|Jian Xu et.al.|[2408.03746v1](http://arxiv.org/abs/2408.03746v1)|null|
|**2024-08-07**|**Intuitionistic Fuzzy Cognitive Maps for Interpretable Image Classification**|Georgia Sovatzidi et.al.|[2408.03745v1](http://arxiv.org/abs/2408.03745v1)|null|
|**2024-08-07**|**Advancing Multimodal Large Language Models with Quantization-Aware Scale Learning for Efficient Adaptation**|Jingjing Xie et.al.|[2408.03735v1](http://arxiv.org/abs/2408.03735v1)|[link](https://github.com/xjjxmu/qslaw)|
|**2024-08-07**|**Question Rephrasing for Quantifying Uncertainty in Large Language Models: Applications in Molecular Chemistry Tasks**|Zizhang Chen et.al.|[2408.03732v1](http://arxiv.org/abs/2408.03732v1)|null|
|**2024-08-07**|**Local Topology Measures of Contextual Language Model Latent Spaces With Applications to Dialogue Term Extraction**|Benjamin Matthias Ruppik et.al.|[2408.03706v1](http://arxiv.org/abs/2408.03706v1)|null|
|**2024-08-07**|**A Blockchain-based Reliable Federated Meta-learning for Metaverse: A Dual Game Framework**|Emna Baccour et.al.|[2408.03694v1](http://arxiv.org/abs/2408.03694v1)|null|
|**2024-08-07**|**NACL: A General and Effective KV Cache Eviction Framework for LLMs at Inference Time**|Yilong Chen et.al.|[2408.03675v2](http://arxiv.org/abs/2408.03675v2)|[link](https://github.com/PaddlePaddle/Research)|
|**2024-08-07**|**mucAI at WojoodNER 2024: Arabic Named Entity Recognition with Nearest Neighbor Search**|Ahmed Abdou et.al.|[2408.03652v1](http://arxiv.org/abs/2408.03652v1)|null|
|**2024-08-07**|**HiQuE: Hierarchical Question Embedding Network for Multimodal Depression Detection**|Juho Jung et.al.|[2408.03648v1](http://arxiv.org/abs/2408.03648v1)|null|
|**2024-08-07**|**CARE: A Clue-guided Assistant for CSRs to Read User Manuals**|Weihong Du et.al.|[2408.03633v2](http://arxiv.org/abs/2408.03633v2)|null|
|**2024-08-07**|**Concept Conductor: Orchestrating Multiple Personalized Concepts in Text-to-Image Synthesis**|Zebin Yao et.al.|[2408.03632v1](http://arxiv.org/abs/2408.03632v1)|null|
|**2024-08-07**|**Large Language Models for Base Station Siting: Intelligent Deployment based on Prompt or Agent**|Yanhu Wang et.al.|[2408.03631v1](http://arxiv.org/abs/2408.03631v1)|null|
|**2024-08-07**|**PAGED: A Benchmark for Procedural Graphs Extraction from Documents**|Weihong Du et.al.|[2408.03630v2](http://arxiv.org/abs/2408.03630v2)|null|
|**2024-08-07**|**Improving the quality of Persian clinical text with a novel spelling correction system**|Seyed Mohammad Sadegh Dashti et.al.|[2408.03622v1](http://arxiv.org/abs/2408.03622v1)|null|
|**2024-08-07**|**A Logical Fallacy-Informed Framework for Argument Generation**|Luca Mouchel et.al.|[2408.03618v1](http://arxiv.org/abs/2408.03618v1)|null|
|**2024-08-07**|**Is Child-Directed Speech Effective Training Data for Language Models?**|Steven Y. Feng et.al.|[2408.03617v1](http://arxiv.org/abs/2408.03617v1)|null|
|**2024-08-07**|**Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon Tasks**|Zaijing Li et.al.|[2408.03615v1](http://arxiv.org/abs/2408.03615v1)|null|
|**2024-08-07**|**EnJa: Ensemble Jailbreak on Large Language Models**|Jiahao Zhang et.al.|[2408.03603v1](http://arxiv.org/abs/2408.03603v1)|null|
|**2024-08-07**|**Facing the Music: Tackling Singing Voice Separation in Cinematic Audio Source Separation**|Karn N. Watcharasupat et.al.|[2408.03588v1](http://arxiv.org/abs/2408.03588v1)|null|
|**2024-08-07**|**Hierarchical Neural Constructive Solver for Real-world TSP Scenarios**|Yong Liang Goh et.al.|[2408.03585v1](http://arxiv.org/abs/2408.03585v1)|null|
|**2024-08-07**|**Teach CLIP to Develop a Number Sense for Ordinal Regression**|Yao Du et.al.|[2408.03574v1](http://arxiv.org/abs/2408.03574v1)|null|
|**2024-08-07**|**Active Testing of Large Language Model via Multi-Stage Sampling**|Yuheng Huang et.al.|[2408.03573v1](http://arxiv.org/abs/2408.03573v1)|null|
|**2024-08-07**|**2D-OOB: Attributing Data Contribution through Joint Valuation Framework**|Yifan Sun et.al.|[2408.03572v1](http://arxiv.org/abs/2408.03572v1)|null|
|**2024-08-07**|**Unlocking Exocentric Video-Language Data for Egocentric Video Representation Learning**|Zi-Yi Dou et.al.|[2408.03567v1](http://arxiv.org/abs/2408.03567v1)|null|
|**2024-08-07**|**A Comparison of LLM Finetuning Methods & Evaluation Metrics with Travel Chatbot Use Case**|Sonia Meyer et.al.|[2408.03562v1](http://arxiv.org/abs/2408.03562v1)|null|
|**2024-08-07**|**MPC-Minimized Secure LLM Inference**|Deevashwer Rathee et.al.|[2408.03561v1](http://arxiv.org/abs/2408.03561v1)|null|
|**2024-08-07**|**Empirical Analysis of Large Vision-Language Models against Goal Hijacking via Visual Prompt Injection**|Subaru Kimura et.al.|[2408.03554v1](http://arxiv.org/abs/2408.03554v1)|null|
|**2024-08-07**|**Unlocking the Non-Native Language Context Limitation: Native Language Prompting Facilitates Knowledge Elicitation**|Baixuan Li et.al.|[2408.03544v1](http://arxiv.org/abs/2408.03544v1)|[link](https://github.com/anonynlp/natlan)|
|**2024-08-07**|**EXAONE 3.0 7.8B Instruction Tuned Language Model**|LG AI Research et.al.|[2408.03541v2](http://arxiv.org/abs/2408.03541v2)|null|
|**2024-08-07**|**Lifelong Personalized Low-Rank Adaptation of Large Language Models for Recommendation**|Jiachen Zhu et.al.|[2408.03533v1](http://arxiv.org/abs/2408.03533v1)|null|
|**2024-08-07**|**Exploring the extent of similarities in software failures across industries using LLMs**|Martin Detloff et.al.|[2408.03528v2](http://arxiv.org/abs/2408.03528v2)|null|
|**2024-08-07**|**EgyBERT: A Large Language Model Pretrained on Egyptian Dialect Corpora**|Faisal Qarah et.al.|[2408.03524v1](http://arxiv.org/abs/2408.03524v1)|null|
|**2024-08-07**|**RepoMasterEval: Evaluating Code Completion via Real-World Repositories**|Qinyun Wu et.al.|[2408.03519v1](http://arxiv.org/abs/2408.03519v1)|null|
|**2024-08-07**|**A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems**|Wenxiao Zhang et.al.|[2408.03515v1](http://arxiv.org/abs/2408.03515v1)|null|
|**2024-08-07**|**MoExtend: Tuning New Experts for Modality and Task Extension**|Shanshan Zhong et.al.|[2408.03511v1](http://arxiv.org/abs/2408.03511v1)|null|
|**2024-08-07**|**1.5-Pints Technical Report: Pretraining in Days, Not Months -- Your Language Model Thrives on Quality Data**|Calvin Tan et.al.|[2408.03506v1](http://arxiv.org/abs/2408.03506v1)|[link](https://github.com/Pints-AI/1.5-Pints)|
|**2024-08-07**|**Optimus: Accelerating Large-Scale Multi-Modal LLM Training by Bubble Exploitation**|Weiqi Feng et.al.|[2408.03505v1](http://arxiv.org/abs/2408.03505v1)|null|
|**2024-08-07**|**Advanced User Credit Risk Prediction Model using LightGBM, XGBoost and Tabnet with SMOTEENN**|Chang Yu et.al.|[2408.03497v1](http://arxiv.org/abs/2408.03497v1)|null|
|**2024-08-07**|**Automated Theorem Provers Help Improve Large Language Model Reasoning**|Lachlan McGinness et.al.|[2408.03492v1](http://arxiv.org/abs/2408.03492v1)|null|
|**2024-08-07**|**Harnessing the Power of LLMs in Source Code Vulnerability Detection**|Andrew A Mahyari et.al.|[2408.03489v1](http://arxiv.org/abs/2408.03489v1)|null|
|**2024-08-06**|**Can LLMs Serve As Time Series Anomaly Detectors?**|Manqing Dong et.al.|[2408.03475v1](http://arxiv.org/abs/2408.03475v1)|null|
|**2024-08-06**|**Identifying treatment response subgroups in observational time-to-event data**|Vincent Jeanselme et.al.|[2408.03463v1](http://arxiv.org/abs/2408.03463v1)|null|
|**2024-08-06**|**EEGMobile: Enhancing Speed and Accuracy in EEG-Based Gaze Prediction with Advanced Mobile Architectures**|Teng Liang et.al.|[2408.03449v1](http://arxiv.org/abs/2408.03449v1)|null|
|**2024-08-06**|**Logistic Regression makes small LLMs strong and explainable "tens-of-shot" classifiers**|Marcus Buckmann et.al.|[2408.03414v1](http://arxiv.org/abs/2408.03414v1)|null|
|**2024-08-06**|**Combining Diverse Information for Coordinated Action: Stochastic Bandit Algorithms for Heterogeneous Agents**|Lucia Gordon et.al.|[2408.03405v1](http://arxiv.org/abs/2408.03405v1)|[link](https://github.com/lgordon99/heterogeneous-stochastic-bandits)|
|**2024-08-06**|**ULLME: A Unified Framework for Large Language Model Embeddings with Generation-Augmented Learning**|Hieu Man et.al.|[2408.03402v1](http://arxiv.org/abs/2408.03402v1)|[link](https://github.com/nlp-uoregon/ullme)|
|**2024-08-06**|**Attacks and Defenses for Generative Diffusion Models: A Comprehensive Survey**|Vu Tuan Truong et.al.|[2408.03400v1](http://arxiv.org/abs/2408.03400v1)|null|
|**2024-08-06**|**RHiOTS: A Framework for Evaluating Hierarchical Time Series Forecasting Algorithms**|Luis Roque et.al.|[2408.03399v1](http://arxiv.org/abs/2408.03399v1)|null|
|**2024-08-06**|**A Non-negative VAE:the Generalized Gamma Belief Network**|Zhibin Duan et.al.|[2408.03388v1](http://arxiv.org/abs/2408.03388v1)|null|
|**2024-08-06**|**LLaVA-OneVision: Easy Visual Task Transfer**|Bo Li et.al.|[2408.03326v1](http://arxiv.org/abs/2408.03326v1)|null|
|**2024-08-06**|**CoverBench: A Challenging Benchmark for Complex Claim Verification**|Alon Jacovi et.al.|[2408.03325v1](http://arxiv.org/abs/2408.03325v1)|null|
|**2024-08-06**|**Training LLMs to Recognize Hedges in Spontaneous Narratives**|Amie J. Paige et.al.|[2408.03319v1](http://arxiv.org/abs/2408.03319v1)|null|
|**2024-08-06**|**Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters**|Charlie Snell et.al.|[2408.03314v1](http://arxiv.org/abs/2408.03314v1)|null|
|**2024-08-06**|**Prioritize Alignment in Dataset Distillation**|Zekai Li et.al.|[2408.03360v1](http://arxiv.org/abs/2408.03360v1)|null|
|**2024-08-06**|**KaPO: Knowledge-aware Preference Optimization for Controllable Knowledge Selection in Retrieval-Augmented Language Models**|Ruizhe Zhang et.al.|[2408.03297v1](http://arxiv.org/abs/2408.03297v1)|null|
|**2024-08-06**|**Static IR Drop Prediction with Attention U-Net and Saliency-Based Explainability**|Lizi Zhang et.al.|[2408.03292v1](http://arxiv.org/abs/2408.03292v1)|null|
|**2024-08-06**|**SARA: Singular-Value Based Adaptive Low-Rank Adaption**|Jihao Gu et.al.|[2408.03290v1](http://arxiv.org/abs/2408.03290v1)|null|
|**2024-08-06**|**StructEval: Deepen and Broaden Large Language Model Assessment via Structured Evaluation**|Boxi Cao et.al.|[2408.03281v2](http://arxiv.org/abs/2408.03281v2)|[link](https://github.com/c-box/structeval)|
|**2024-08-06**|**Compress and Compare: Interactively Evaluating Efficiency and Behavior Across ML Model Compression Experiments**|Angie Boggust et.al.|[2408.03274v1](http://arxiv.org/abs/2408.03274v1)|null|
|**2024-08-06**|**LAMPO: Large Language Models as Preference Machines for Few-shot Ordinal Classification**|Zhen Qin et.al.|[2408.03359v1](http://arxiv.org/abs/2408.03359v1)|null|
|**2024-08-06**|**Synthesizing Text-to-SQL Data from Weak and Strong LLMs**|Jiaxi Yang et.al.|[2408.03256v1](http://arxiv.org/abs/2408.03256v1)|null|
|**2024-08-06**|**Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons**|Yifei Wang et.al.|[2408.03247v1](http://arxiv.org/abs/2408.03247v1)|null|
|**2024-08-06**|**Making Long-Context Language Models Better Multi-Hop Reasoners**|Yanyang Li et.al.|[2408.03246v1](http://arxiv.org/abs/2408.03246v1)|[link](https://github.com/lavi-lab/longcontextreasoner)|
|**2024-08-06**|**MLC-GCN: Multi-Level Generated Connectome Based GCN for AD Analysis**|Wenqi Zhu et.al.|[2408.03358v1](http://arxiv.org/abs/2408.03358v1)|null|
|**2024-08-06**|**Personalizing Federated Instrument Segmentation with Visual Trait Priors in Robotic Surgery**|Jialang Xu et.al.|[2408.03208v1](http://arxiv.org/abs/2408.03208v1)|null|
|**2024-08-06**|**A Debiased Nearest Neighbors Framework for Multi-Label Text Classification**|Zifeng Cheng et.al.|[2408.03202v1](http://arxiv.org/abs/2408.03202v1)|null|
|**2024-08-06**|**Adversarial Safety-Critical Scenario Generation using Naturalistic Human Driving Priors**|Kunkun Hao et.al.|[2408.03200v2](http://arxiv.org/abs/2408.03200v2)|null|
|**2024-08-06**|**Leveraging Parameter Efficient Training Methods for Low Resource Text Classification: A Case Study in Marathi**|Pranita Deshmukh et.al.|[2408.03172v1](http://arxiv.org/abs/2408.03172v1)|null|
|**2024-08-06**|**Training on the Fly: On-device Self-supervised Learning aboard Nano-drones within 20 mW**|Elia Cereda et.al.|[2408.03168v1](http://arxiv.org/abs/2408.03168v1)|null|
|**2024-08-06**|**Dilated Convolution with Learnable Spacings makes visual models more aligned with humans: a Grad-CAM study**|Rabih Chamas et.al.|[2408.03164v1](http://arxiv.org/abs/2408.03164v1)|[link](https://github.com/rabihchamas/dcls-gradcam-eval)|
|**2024-08-06**|**Conditioning LLMs with Emotion in Neural Machine Translation**|Charles Brazier et.al.|[2408.03150v1](http://arxiv.org/abs/2408.03150v1)|null|
|**2024-08-06**|**Leveraging Entity Information for Cross-Modality Correlation Learning: The Entity-Guided Multimodal Summarization**|Yanghai Zhang et.al.|[2408.03149v1](http://arxiv.org/abs/2408.03149v1)|null|
|**2024-08-06**|**Inference Optimizations for Large Language Models: Effects, Challenges, and Practical Considerations**|Leo Donisch et.al.|[2408.03130v1](http://arxiv.org/abs/2408.03130v1)|null|
|**2024-08-06**|**Lisbon Computational Linguists at SemEval-2024 Task 2: Using A Mistral 7B Model and Data Augmentation**|Artur Guimar√£es et.al.|[2408.03127v1](http://arxiv.org/abs/2408.03127v1)|null|
|**2024-08-06**|**COMMENTATOR: A Code-mixed Multilingual Text Annotation Framework**|Rajvee Sheth et.al.|[2408.03125v1](http://arxiv.org/abs/2408.03125v1)|[link](https://github.com/lingo-iitgn/commentator)|
|**2024-08-06**|**Evaluating the Translation Performance of Large Language Models Based on Euas-20**|Yan Huang et.al.|[2408.03119v1](http://arxiv.org/abs/2408.03119v1)|null|
|**2024-08-06**|**Topic Modeling with Fine-tuning LLMs and Bag of Sentences**|Johannes Schneider et.al.|[2408.03099v1](http://arxiv.org/abs/2408.03099v1)|[link](https://github.com/johntailor/ft-topic)|
|**2024-08-06**|**500xCompressor: Generalized Prompt Compression for Large Language Models**|Zongqian Li et.al.|[2408.03094v1](http://arxiv.org/abs/2408.03094v1)|null|

#### Abstracts
##### **SLIM-RAFT: A Novel Fine-Tuning Approach to Improve Cross-Linguistic Performance for Mercosur Common Nomenclature**
2408.03936v1 by Vin√≠cius Di Oliveira, Yuri Fa√ßanha Bezerra, Li Weigang, Pedro Carvalho Brom, Victor Rafael R. Celestino

Natural language processing (NLP) has seen significant advancements with the
advent of large language models (LLMs). However, substantial improvements are
still needed for languages other than English, especially for specific domains
like the applications of Mercosur Common Nomenclature (NCM), a Brazilian
Harmonized System (HS). To address this gap, this study uses TeenyTineLLaMA, a
foundational Portuguese LLM, as an LLM source to implement the NCM application
processing. Additionally, a simplified Retrieval-Augmented Fine-Tuning (RAFT)
technique, termed SLIM-RAFT, is proposed for task-specific fine-tuning of LLMs.
This approach retains the chain-of-thought (CoT) methodology for prompt
development in a more concise and streamlined manner, utilizing brief and
focused documents for training. The proposed model demonstrates an efficient
and cost-effective alternative for fine-tuning smaller LLMs, significantly
outperforming TeenyTineLLaMA and ChatGPT-4 in the same task. Although the
research focuses on NCM applications, the methodology can be easily adapted for
HS applications worldwide.

ÊëòË¶ÅÔºöËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) Èö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÂá∫ÁèæËÄåÁç≤ÂæóÈ°ØËëóÈÄ≤Â±ï„ÄÇÁÑ∂ËÄåÔºåÂ∞çÊñºËã±Ë™û‰ª•Â§ñÁöÑË™ûË®ÄÔºåÁâπÂà•ÊòØÂÉèÂ∑¥Ë•øÁµ±‰∏ÄÂà∂Â∫¶ (HS) ÁöÑÂçóÊñπÂÖ±ÂêåÂ∏ÇÂ†¥ÂÖ±ÂêåÊ≥ïË¶è (NCM) ÊáâÁî®Á≠âÁâπÂÆöÈ†òÂüüÔºå‰ªçÈúÄË¶ÅÂ§ßÂπÖÊîπÈÄ≤„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊú¨Á†îÁ©∂‰ΩøÁî® TeenyTineLLaMAÔºà‰∏ÄÁ®ÆÂü∫Á§éÁöÑËë°ËêÑÁâôË™û LLMÔºâ‰ΩúÁÇ∫ LLM ‰æÜÊ∫êÔºå‰æÜÂØ¶‰Ωú NCM ÊáâÁî®ËôïÁêÜ„ÄÇÊ≠§Â§ñÔºåÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÁ∞°ÂåñÁöÑÊ™¢Á¥¢Â¢ûÂº∑ÂæÆË™ø (RAFT) ÊäÄË°ìÔºåÁ®±ÁÇ∫ SLIM-RAFTÔºåÁî®Êñº LLM ÁöÑ‰ªªÂãôÁâπÂÆöÂæÆË™ø„ÄÇÈÄôÁ®ÆÊñπÊ≥ï‰øùÁïô‰∫ÜÊÄùËÄÉÈèà (CoT) ÊñπÊ≥ïÔºåÁî®Êñº‰ª•Êõ¥Á∞°ÊΩîÂíåÊµÅÊö¢ÁöÑÊñπÂºèÈñãÁôºÊèêÁ§∫Ôºå‰∏¶Âà©Áî®Á∞°Áü≠‰∏îÈáçÈªûÊòéÁ¢∫ÁöÑÊñá‰ª∂ÈÄ≤Ë°åË®ìÁ∑¥„ÄÇÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂ±ïÁ§∫‰∫Ü‰∏ÄÂÄãÊúâÊïà‰∏îÁ∂ìÊøüÁöÑÊõø‰ª£ÊñπÊ°àÔºåÁî®ÊñºÂæÆË™øËºÉÂ∞èÁöÑ LLMÔºåÂú®Áõ∏ÂêåÁöÑ‰ªªÂãô‰∏≠È°ØËëóÂÑ™Êñº TeenyTineLLaMA Âíå ChatGPT-4„ÄÇÂÑòÁÆ°Á†îÁ©∂ÈáçÈªûÂú®Êñº NCM ÊáâÁî®Ôºå‰ΩÜË©≤ÊñπÊ≥ïÂèØ‰ª•ÂæàÂÆπÊòìÂú∞ÈÅ©Áî®ÊñºÂÖ®ÁêÉÁöÑ HS ÊáâÁî®„ÄÇ

##### **From Words to Worth: Newborn Article Impact Prediction with LLM**
2408.03934v1 by Penghai Zhao, Qinghua Xing, Kairan Dou, Jinyu Tian, Ying Tai, Jian Yang, Ming-Ming Cheng, Xiang Li

As the academic landscape expands, the challenge of efficiently identifying
potentially high-impact articles among the vast number of newly published works
becomes critical. This paper introduces a promising approach, leveraging the
capabilities of fine-tuned LLMs to predict the future impact of newborn
articles solely based on titles and abstracts. Moving beyond traditional
methods heavily reliant on external information, the proposed method discerns
the shared semantic features of highly impactful papers from a large collection
of title-abstract and potential impact pairs. These semantic features are
further utilized to regress an improved metric, TNCSI_SP, which has been
endowed with value, field, and time normalization properties. Additionally, a
comprehensive dataset has been constructed and released for fine-tuning the
LLM, containing over 12,000 entries with corresponding titles, abstracts, and
TNCSI_SP. The quantitative results, with an NDCG@20 of 0.901, demonstrate that
the proposed approach achieves state-of-the-art performance in predicting the
impact of newborn articles when compared to competitive counterparts. Finally,
we demonstrate a real-world application for predicting the impact of newborn
journal articles to demonstrate its noteworthy practical value. Overall, our
findings challenge existing paradigms and propose a shift towards a more
content-focused prediction of academic impact, offering new insights for
assessing newborn article impact.

ÊëòË¶ÅÔºöÈö®ËëóÂ≠∏Ë°ìÈ†òÂüüÁöÑÊì¥Â±ïÔºåÂú®Â§ßÈáèÊñ∞Âá∫ÁâàÁöÑ‰ΩúÂìÅ‰∏≠ÊúâÊïàÊâæÂá∫ÊΩõÂú®È´òÂΩ±ÈüøÂäõÊñáÁ´†ÁöÑÊåëÊà∞ËÆäÂæóËá≥ÈóúÈáçË¶Å„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÊúâÂâçÈÄîÁöÑÊñπÊ≥ïÔºåÂà©Áî®ÂæÆË™ø LLM ÁöÑËÉΩÂäõ‰æÜÈ†êÊ∏¨Êñ∞ÁîüÊñáÁ´†ÁöÑÊú™‰æÜÂΩ±ÈüøÔºåÂÉÖÊ†πÊìöÊ®ôÈ°åÂíåÊëòË¶Å„ÄÇË∂ÖË∂ä‰∫ÜÂÇ≥Áµ±ÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ï‰æùË≥¥ÊñºÂ§ñÈÉ®Ë≥áË®äÔºåÊèêÂá∫ÁöÑÊñπÊ≥ïÂæûÂ§ßÈáèÁöÑÊ®ôÈ°åÊëòË¶ÅÂíåÊΩõÂú®ÂΩ±ÈüøÂ∞ç‰∏≠Ëæ®Âà•Âá∫È´òÂΩ±ÈüøÂäõË´ñÊñáÁöÑÂÖ±Áî®Ë™ûÁæ©ÁâπÂæµ„ÄÇÈÄô‰∫õË™ûÁæ©ÁâπÂæµÈÄ≤‰∏ÄÊ≠•Áî®ÊñºÂõûÊ≠∏‰∏ÄÂÄãÊîπÈÄ≤ÁöÑÊåáÊ®ô TNCSI_SPÔºåË©≤ÊåáÊ®ôÂ∑≤Ë≥¶‰∫àÂÄº„ÄÅÊ¨Ñ‰ΩçÂíåÊôÇÈñìÊ≠£Ë¶èÂåñÂ±¨ÊÄß„ÄÇÊ≠§Â§ñÔºåÈÇÑÊßãÂª∫‰∏¶ÁôºÂ∏É‰∫Ü‰∏ÄÂÄãÁ∂úÂêàË≥áÊñôÈõÜÔºåÁî®ÊñºÂæÆË™ø LLMÔºåÂÖ∂‰∏≠ÂåÖÂê´Ë∂ÖÈÅé 12,000 ÂÄãÊ¢ùÁõÆÔºå‰ª•ÂèäÂ∞çÊáâÁöÑÊ®ôÈ°å„ÄÅÊëòË¶ÅÂíå TNCSI_SP„ÄÇÂÆöÈáèÁµêÊûúÔºåNDCG@20 ÁÇ∫ 0.901ÔºåË≠âÊòé‰∫ÜËàáÁ´∂Áà≠Â∞çÊâãÁõ∏ÊØîÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®È†êÊ∏¨Êñ∞ÁîüÊñáÁ´†ÁöÑÂΩ±ÈüøÊñπÈù¢ÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩ„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰∏ÄÂÄãÁèæÂØ¶‰∏ñÁïåÁöÑÊáâÁî®ÔºåÁî®ÊñºÈ†êÊ∏¨Êñ∞ÁîüÊúüÂàäÊñáÁ´†ÁöÑÂΩ±ÈüøÔºå‰ª•Ë≠âÊòéÂÖ∂È°ØËëóÁöÑÂØ¶Áî®ÂÉπÂÄº„ÄÇÁ∏ΩÁöÑ‰æÜË™™ÔºåÊàëÂÄëÁöÑÁôºÁèæÊåëÊà∞‰∫ÜÁèæÊúâÁöÑÁØÑ‰æãÔºå‰∏¶Âª∫Ë≠∞ËΩâÂêëÊõ¥Ê≥®ÈáçÂÖßÂÆπÁöÑÂ≠∏Ë°ìÂΩ±ÈüøÈ†êÊ∏¨ÔºåÁÇ∫Ë©ï‰º∞Êñ∞ÁîüÊñáÁ´†ÂΩ±ÈüøÊèê‰æõ‰∫ÜÊñ∞ÁöÑË¶ãËß£„ÄÇ

##### **CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases**
2408.03910v1 by Xiangyan Liu, Bo Lan, Zhiyuan Hu, Yang Liu, Zhicheng Zhang, Wenmeng Zhou, Fei Wang, Michael Shieh

Large Language Models (LLMs) excel in stand-alone code tasks like HumanEval
and MBPP, but struggle with handling entire code repositories. This challenge
has prompted research on enhancing LLM-codebase interaction at a repository
scale. Current solutions rely on similarity-based retrieval or manual tools and
APIs, each with notable drawbacks. Similarity-based retrieval often has low
recall in complex tasks, while manual tools and APIs are typically
task-specific and require expert knowledge, reducing their generalizability
across diverse code tasks and real-world applications. To mitigate these
limitations, we introduce \framework, a system that integrates LLM agents with
graph database interfaces extracted from code repositories. By leveraging the
structural properties of graph databases and the flexibility of the graph query
language, \framework enables the LLM agent to construct and execute queries,
allowing for precise, code structure-aware context retrieval and code
navigation. We assess \framework using three benchmarks: CrossCodeEval,
SWE-bench, and EvoCodeBench. Additionally, we develop five real-world coding
applications. With a unified graph database schema, \framework demonstrates
competitive performance and potential in both academic and real-world
environments, showcasing its versatility and efficacy in software engineering.
Our application demo:
https://github.com/modelscope/modelscope-agent/tree/master/apps/codexgraph_agent.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Áç®Á´ãÁ®ãÂºèÁ¢º‰ªªÂãô‰∏≠Ë°®ÁèæÂá∫Ëâ≤Ôºå‰æãÂ¶Ç HumanEval Âíå MBPPÔºå‰ΩÜËôïÁêÜÊï¥ÂÄãÁ®ãÂºèÁ¢ºÂÑ≤Â≠òÂ∫´ÊôÇÂçªÈÅáÂà∞Âõ∞Èõ£„ÄÇÈÄôÂÄãÊåëÊà∞‰øÉ‰ΩøÁ†îÁ©∂‰∫∫Âì°Âä†Âº∑ LLM ËàáÁ®ãÂºèÁ¢ºÂ∫´ÁöÑ‰∫íÂãïÔºå‰∏¶‰ª•ÂÑ≤Â≠òÂ∫´ÁÇ∫Ë¶èÊ®°„ÄÇÁõÆÂâçÁöÑËß£Ê±∫ÊñπÊ°à‰æùË≥¥ÊñºÂü∫ÊñºÁõ∏‰ººÊÄßÁöÑÊì∑ÂèñÊàñÊâãÂãïÂ∑•ÂÖ∑Âíå APIÔºåÊØèÁ®ÆÊñπÊ≥ïÈÉΩÊúâÈ°ØËëóÁöÑÁº∫Èªû„ÄÇÂü∫ÊñºÁõ∏‰ººÊÄßÁöÑÊì∑ÂèñÂú®Ë§áÈõú‰ªªÂãô‰∏≠ÈÄöÂ∏∏Âè¨ÂõûÁéá‰ΩéÔºåËÄåÊâãÂãïÂ∑•ÂÖ∑Âíå API ÈÄöÂ∏∏ÊòØÁâπÂÆöÊñº‰ªªÂãôÁöÑÔºåÈúÄË¶ÅÂ∞àÂÆ∂Áü•Ë≠òÔºåÈÄôÊúÉÈôç‰ΩéÂÆÉÂÄëÂú®‰∏çÂêåÁ®ãÂºèÁ¢º‰ªªÂãôÂíåÂØ¶ÈöõÊáâÁî®‰∏≠ÁöÑÊ¶ÇÊã¨ÊÄß„ÄÇÁÇ∫‰∫ÜÊ∏õËºïÈÄô‰∫õÈôêÂà∂ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü \frameworkÔºå‰∏ÄÂÄãÂ∞á LLM ‰ª£ÁêÜËàáÂæûÁ®ãÂºèÁ¢ºÂÑ≤Â≠òÂ∫´‰∏≠ÊèêÂèñÁöÑÂúñÂΩ¢Ë≥áÊñôÂ∫´‰ªãÈù¢Êï¥ÂêàÁöÑÁ≥ªÁµ±„ÄÇÈÄèÈÅéÂà©Áî®ÂúñÂΩ¢Ë≥áÊñôÂ∫´ÁöÑÁµêÊßãÁâπÊÄßÂíåÂúñÂΩ¢Êü•Ë©¢Ë™ûË®ÄÁöÑÈùàÊ¥ªÊÄßÔºå\framework ‰Ωø LLM ‰ª£ÁêÜËÉΩÂ§†Âª∫ÊßãÂíåÂü∑Ë°åÊü•Ë©¢ÔºåÂÖÅË®±Á≤æÁ¢∫„ÄÅÊúâÁ®ãÂºèÁ¢ºÁµêÊßãÊÑèË≠òÁöÑÂÖßÂÆπÊì∑ÂèñÂíåÁ®ãÂºèÁ¢ºÂ∞éË¶Ω„ÄÇÊàëÂÄë‰ΩøÁî®‰∏âÂÄãÂü∫Ê∫ñ‰æÜË©ï‰º∞ \frameworkÔºöCrossCodeEval„ÄÅSWE-bench Âíå EvoCodeBench„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∫îÂÄãÂØ¶ÈöõÁöÑÁ®ãÂºèÁ¢ºÊáâÁî®Á®ãÂºè„ÄÇÊúâ‰∫ÜÁµ±‰∏ÄÁöÑÂúñÂΩ¢Ë≥áÊñôÂ∫´Êû∂ÊßãÔºå\framework Âú®Â≠∏Ë°ìÂíåÂØ¶ÈöõÁí∞Â¢É‰∏≠ÈÉΩÂ±ïÁèæÂá∫Á´∂Áà≠ÂäõÁöÑÊïàËÉΩÂíåÊΩõÂäõÔºåÂ±ïÁ§∫‰∫ÜÂÆÉÂú®ËªüÈ´îÂ∑•Á®ã‰∏≠ÁöÑÂ§öÂäüËÉΩÊÄßÂíåÊúâÊïàÊÄß„ÄÇÊàëÂÄëÁöÑÊáâÁî®Á®ãÂºèÁ§∫ÁØÑÔºöhttps://github.com/modelscope/modelscope-agent/tree/master/apps/codexgraph_agent„ÄÇ

##### **Decoding Biases: Automated Methods and LLM Judges for Gender Bias Detection in Language Models**
2408.03907v1 by Shachi H Kumar, Saurav Sahay, Sahisnu Mazumder, Eda Okur, Ramesh Manuvinakurike, Nicole Beckage, Hsuan Su, Hung-yi Lee, Lama Nachman

Large Language Models (LLMs) have excelled at language understanding and
generating human-level text. However, even with supervised training and human
alignment, these LLMs are susceptible to adversarial attacks where malicious
users can prompt the model to generate undesirable text. LLMs also inherently
encode potential biases that can cause various harmful effects during
interactions. Bias evaluation metrics lack standards as well as consensus and
existing methods often rely on human-generated templates and annotations which
are expensive and labor intensive. In this work, we train models to
automatically create adversarial prompts to elicit biased responses from target
LLMs. We present LLM- based bias evaluation metrics and also analyze several
existing automatic evaluation methods and metrics. We analyze the various
nuances of model responses, identify the strengths and weaknesses of model
families, and assess where evaluation methods fall short. We compare these
metrics to human evaluation and validate that the LLM-as-a-Judge metric aligns
with human judgement on bias in response generation.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Ë™ûË®ÄÁêÜËß£ÂíåÁî¢Áîü‰∫∫È°ûÂ±§Á¥öÊñáÂ≠óÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤„ÄÇÁÑ∂ËÄåÔºåÂç≥‰ΩøÁ∂ìÈÅéÁõ£Áù£ÂºèË®ìÁ∑¥Âíå‰∫∫È°ûÊ†°Ê∫ñÔºåÈÄô‰∫õ LLM ‰ªçÂÆπÊòìÂèóÂà∞Â∞çÊäóÊÄßÊîªÊìäÔºåÊÉ°ÊÑè‰ΩøÁî®ËÄÖÂèØ‰ª•ÊèêÁ§∫Ê®°ÂûãÁî¢Áîü‰∏çËâØÊñáÂ≠ó„ÄÇLLM Êú¨Ë∫´‰πüÁ∑®Á¢º‰∫ÜÊΩõÂú®ÂÅèË¶ãÔºåÂèØËÉΩÂú®‰∫íÂãïÈÅéÁ®ã‰∏≠ÈÄ†ÊàêÂêÑÁ®ÆÊúâÂÆ≥ÂΩ±Èüø„ÄÇÂÅèË¶ãË©ï‰º∞ÊåáÊ®ôÁº∫‰πèÊ®ôÊ∫ñÂíåÂÖ±Ë≠òÔºåÁèæÊúâÊñπÊ≥ïÈÄöÂ∏∏‰æùË≥¥Êñº‰∫∫Â∑•Áî¢ÁîüÁöÑÁØÑÊú¨ÂíåË®ªËß£ÔºåÈÄô‰∫õÁØÑÊú¨ÂíåË®ªËß£ÊòÇË≤¥‰∏îËÄóË≤ª‰∫∫Âäõ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëË®ìÁ∑¥Ê®°ÂûãËá™ÂãïÂª∫Á´ãÂ∞çÊäóÊÄßÊèêÁ§∫ÔºåÂæûÁõÆÊ®ô LLM ÂºïÂá∫ÊúâÂÅèË¶ãÁöÑÂõûÊáâ„ÄÇÊàëÂÄëÊèêÂá∫Âü∫Êñº LLM ÁöÑÂÅèË¶ãË©ï‰º∞ÊåáÊ®ôÔºå‰∏¶ÂàÜÊûê‰∫ÜÂπæÁ®ÆÁèæÊúâÁöÑËá™ÂãïË©ï‰º∞ÊñπÊ≥ïÂíåÊåáÊ®ô„ÄÇÊàëÂÄëÂàÜÊûêÊ®°ÂûãÂõûÊáâÁöÑÂêÑÁ®ÆÁ¥∞ÂæÆÂ∑ÆÂà•ÔºåÊâæÂá∫Ê®°ÂûãÁ≥ªÂàóÁöÑÂÑ™Áº∫ÈªûÔºå‰∏¶Ë©ï‰º∞Ë©ï‰º∞ÊñπÊ≥ïÁöÑ‰∏çË∂≥‰πãËôï„ÄÇÊàëÂÄëÂ∞áÈÄô‰∫õÊåáÊ®ôËàá‰∫∫È°ûË©ï‰º∞ÈÄ≤Ë°åÊØîËºÉÔºå‰∏¶È©óË≠â LLM ‰ΩúÁÇ∫Ë©ïÂà§ÊåáÊ®ôËàá‰∫∫È°ûÂ∞çÂõûÊáâ‰∏≠ÂÅèË¶ãÁöÑÂà§Êñ∑‰∏ÄËá¥„ÄÇ

##### **Speech-MASSIVE: A Multilingual Speech Dataset for SLU and Beyond**
2408.03900v1 by Beomseok Lee, Ioan Calapodescu, Marco Gaido, Matteo Negri, Laurent Besacier

We present Speech-MASSIVE, a multilingual Spoken Language Understanding (SLU)
dataset comprising the speech counterpart for a portion of the MASSIVE textual
corpus. Speech-MASSIVE covers 12 languages from different families and inherits
from MASSIVE the annotations for the intent prediction and slot-filling tasks.
Our extension is prompted by the scarcity of massively multilingual SLU
datasets and the growing need for versatile speech datasets to assess
foundation models (LLMs, speech encoders) across languages and tasks. We
provide a multimodal, multitask, multilingual dataset and report SLU baselines
using both cascaded and end-to-end architectures in various training scenarios
(zero-shot, few-shot, and full fine-tune). Furthermore, we demonstrate the
suitability of Speech-MASSIVE for benchmarking other tasks such as speech
transcription, language identification, and speech translation. The dataset,
models, and code are publicly available at:
https://github.com/hlt-mt/Speech-MASSIVE

ÊëòË¶ÅÔºöÊàëÂÄëÊèêÂá∫ Speech-MASSIVEÔºå‰∏ÄÂÄãÂ§öË™ûË®ÄÁöÑÂè£Ë™ûÁêÜËß£ (SLU)
Ë≥áÊñôÈõÜÔºåÂåÖÂê´ MASSIVE ÊñáÊú¨Ë™ûÊñôÂ∫´‰∏ÄÈÉ®ÂàÜÁöÑÂè£Ë™ûÂ∞çÊáâÈÉ®ÂàÜ„ÄÇSpeech-MASSIVE Ê∂µËìã‰∫Ü‰æÜËá™‰∏çÂêåË™ûÁ≥ªÁöÑ 12 Á®ÆË™ûË®ÄÔºå‰∏¶ÁπºÊâø‰∫Ü MASSIVE ‰∏≠Áî®ÊñºÊÑèÂúñÈ†êÊ∏¨ÂíåÊßΩ‰ΩçÂ°´Ë£ú‰ªªÂãôÁöÑË®ªËß£„ÄÇ
ÊàëÂÄëÁöÑÊì¥Â±ïÊòØÁî±Â§ßÈáèÁöÑÂ§öË™ûË®Ä SLU Ë≥áÊñôÈõÜÁöÑÁ®ÄÁº∫ÊÄß‰ª•ÂèäË©ï‰º∞Ë∑®Ë™ûË®ÄÂíå‰ªªÂãôÁöÑÂü∫Á§éÊ®°Âûã (LLM„ÄÅË™ûÈü≥Á∑®Á¢ºÂô®) Â∞çÈÄöÁî®Ë™ûÈü≥Ë≥áÊñôÈõÜÊó•ÁõäÂ¢ûÈï∑ÁöÑÈúÄÊ±ÇÊâÄÊé®ÂãïÁöÑ„ÄÇÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãÂ§öÊ®°ÊÖã„ÄÅÂ§ö‰ªªÂãô„ÄÅÂ§öË™ûË®ÄÁöÑË≥áÊñôÈõÜÔºå‰∏¶Âú®ÂêÑÁ®ÆË®ìÁ∑¥Â†¥ÊôØÔºàÈõ∂Ê¨°Â≠∏Áøí„ÄÅÂ∞ëÊ¨°Â≠∏ÁøíÂíåÂÆåÂÖ®ÂæÆË™øÔºâ‰∏≠Â†±Âëä‰∫Ü‰ΩøÁî®‰∏≤ËÅØÂíåÁ´ØÂà∞Á´ØÊû∂ÊßãÁöÑ SLU Âü∫Á∑ö„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü Speech-MASSIVE ÈÅ©Áî®ÊñºÂ∞çÂÖ∂‰ªñ‰ªªÂãôÔºà‰æãÂ¶ÇË™ûÈü≥ËΩâÈåÑ„ÄÅË™ûË®ÄË≠òÂà•ÂíåË™ûÈü≥ÁøªË≠ØÔºâÈÄ≤Ë°åÂü∫Ê∫ñÊ∏¨Ë©¶„ÄÇË≥áÊñôÈõÜ„ÄÅÊ®°ÂûãÂíåÁ®ãÂºèÁ¢ºÂèØÂú®‰ª•‰∏ã‰ΩçÁΩÆÂÖ¨ÈñãÁç≤ÂæóÔºö
https://github.com/hlt-mt/Speech-MASSIVE

##### **Simplifying Scholarly Abstracts for Accessible Digital Libraries**
2408.03899v1 by Haining Wang, Jason Clark

Standing at the forefront of knowledge dissemination, digital libraries
curate vast collections of scientific literature. However, these scholarly
writings are often laden with jargon and tailored for domain experts rather
than the general public. As librarians, we strive to offer services to a
diverse audience, including those with lower reading levels. To extend our
services beyond mere access, we propose fine-tuning a language model to rewrite
scholarly abstracts into more comprehensible versions, thereby making scholarly
literature more accessible when requested. We began by introducing a corpus
specifically designed for training models to simplify scholarly abstracts. This
corpus consists of over three thousand pairs of abstracts and significance
statements from diverse disciplines. We then fine-tuned four language models
using this corpus. The outputs from the models were subsequently examined both
quantitatively for accessibility and semantic coherence, and qualitatively for
language quality, faithfulness, and completeness. Our findings show that the
resulting models can improve readability by over three grade levels, while
maintaining fidelity to the original content. Although commercial
state-of-the-art models still hold an edge, our models are much more compact,
can be deployed locally in an affordable manner, and alleviate the privacy
concerns associated with using commercial models. We envision this work as a
step toward more inclusive and accessible libraries, improving our services for
young readers and those without a college degree.

ÊëòË¶ÅÔºö‰ΩúÁÇ∫Áü•Ë≠òÂÇ≥Êí≠ÁöÑÊúÄÂâçÁ∑öÔºåÊï∏‰ΩçÂúñÊõ∏È§®ÁÆ°ÁêÜËëóÈæêÂ§ßÁßëÂ≠∏ÊñáÁçªÁöÑÈõÜÂêà„ÄÇÁÑ∂ËÄåÔºåÈÄô‰∫õÂ≠∏Ë°ìÂØ´‰ΩúÈÄöÂ∏∏ÂÖÖÊªøË°ìË™ûÔºå‰∏¶ÈáùÂ∞çÈ†òÂüüÂ∞àÂÆ∂ÈáèË∫´ÊâìÈÄ†ÔºåËÄåÈùû‰∏ÄËà¨Â§ßÁúæ„ÄÇË∫´ÁÇ∫ÂúñÊõ∏È§®Âì°ÔºåÊàëÂÄëËá¥ÂäõÊñºÁÇ∫Â§öÂÖÉÂèóÁúæÊèê‰æõÊúçÂãôÔºåÂåÖÊã¨Èñ±ËÆÄËÉΩÂäõËºÉ‰ΩéËÄÖ„ÄÇÁÇ∫‰∫ÜÂ∞áÊàëÂÄëÁöÑÊúçÂãôÊì¥Â±ïÂà∞ÂñÆÁ¥îÂ≠òÂèñ‰πãÂ§ñÔºåÊàëÂÄëÂª∫Ë≠∞ÂæÆË™øË™ûË®ÄÊ®°ÂûãÔºåÂ∞áÂ≠∏Ë°ìÊëòË¶ÅÊîπÂØ´ÁÇ∫Êõ¥ÊòìÊñºÁêÜËß£ÁöÑÁâàÊú¨ÔºåÂæûËÄåËÆìÂ≠∏Ë°ìÊñáÁçªÂú®ÈúÄË¶ÅÊôÇÊõ¥ÊòìÊñºÂ≠òÂèñ„ÄÇÊàëÂÄëÈ¶ñÂÖàÂºïÂÖ•‰∏ÄÂÄãÂ∞àÈñÄË®≠Ë®àÁî®ÊñºË®ìÁ∑¥Ê®°Âûã‰ª•Á∞°ÂåñÂ≠∏Ë°ìÊëòË¶ÅÁöÑË™ûÊñôÂ∫´„ÄÇÊ≠§Ë™ûÊñôÂ∫´ÂåÖÂê´‰æÜËá™‰∏çÂêåÈ†òÂüüÁöÑ‰∏âÂçÉÂ§öÂ∞çÊëòË¶ÅÂíåÈáçË¶ÅÊÄßËÅ≤Êòé„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄë‰ΩøÁî®Ê≠§Ë™ûÊñôÂ∫´ÂæÆË™ø‰∫ÜÂõõÂÄãË™ûË®ÄÊ®°Âûã„ÄÇÊé•ËëóÔºåÂæûÊ®°ÂûãËº∏Âá∫ÁöÑÁµêÊûú‰∏≠ÔºåÊàëÂÄëÂÆöÈáèÊ™¢Êü•‰∫ÜÂèØÂ≠òÂèñÊÄßÂíåË™ûÁæ©Áõ∏Âπ≤ÊÄßÔºå‰∏¶ÂÆöÊÄßÊ™¢Êü•‰∫ÜË™ûË®ÄÂìÅË≥™„ÄÅÂø†ÂØ¶Â∫¶ÂíåÂÆåÊï¥ÊÄß„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåÈÄô‰∫õÊ®°ÂûãÂèØ‰ª•Â∞áÂèØËÆÄÊÄßÊèêÂçáË∂ÖÈÅé‰∏âÂÄãÂπ¥Á¥öÁ®ãÂ∫¶ÔºåÂêåÊôÇÁ∂≠ÊåÅÂ∞çÂéüÂßãÂÖßÂÆπÁöÑÂø†ÂØ¶Â∫¶„ÄÇÂÑòÁÆ°ÂïÜÊ•≠ÊúÄÂÖàÈÄ≤ÁöÑÊ®°Âûã‰ªç‰ΩîÊúâ‰∏ÄÂ∏≠‰πãÂú∞Ôºå‰ΩÜÊàëÂÄëÁöÑÊ®°ÂûãÊõ¥ÁÇ∫Á≤æÁ∞°ÔºåÂèØ‰ª•Á∂ìÊøüÂØ¶ÊÉ†ÁöÑÊñπÂºèÂú®Êú¨Âú∞ÈÉ®ÁΩ≤Ôºå‰∏¶Ê∏õËºïËàá‰ΩøÁî®ÂïÜÊ•≠Ê®°ÂûãÁõ∏ÈóúÁöÑÈö±ÁßÅÂïèÈ°å„ÄÇÊàëÂÄëÂ∞áÈÄôÈ†ÖÂ∑•‰ΩúË¶ñÁÇ∫ÈÇÅÂêëÊõ¥ÂÖ∑ÂåÖÂÆπÊÄßÂíåÂèØÂ≠òÂèñÊÄßÁöÑÂúñÊõ∏È§®ÁöÑ‰∏ÄÊ≠•ÔºåÊîπÂñÑÊàëÂÄëÂ∞çÂπ¥ËºïËÆÄËÄÖÂíåÊ≤íÊúâÂ§ßÂ≠∏Â≠∏‰ΩçÁöÑËÆÄËÄÖÁöÑÊúçÂãô„ÄÇ

##### **MORTAR: A Model-based Runtime Action Repair Framework for AI-enabled Cyber-Physical Systems**
2408.03892v1 by Renzhi Wang, Zhehua Zhou, Jiayang Song, Xuan Xie, Xiaofei Xie, Lei Ma

Cyber-Physical Systems (CPSs) are increasingly prevalent across various
industrial and daily-life domains, with applications ranging from robotic
operations to autonomous driving. With recent advancements in artificial
intelligence (AI), learning-based components, especially AI controllers, have
become essential in enhancing the functionality and efficiency of CPSs.
However, the lack of interpretability in these AI controllers presents
challenges to the safety and quality assurance of AI-enabled CPSs (AI-CPSs).
Existing methods for improving the safety of AI controllers often involve
neural network repair, which requires retraining with additional adversarial
examples or access to detailed internal information of the neural network.
Hence, these approaches have limited applicability for black-box policies,
where only the inputs and outputs are accessible during operation. To overcome
this, we propose MORTAR, a runtime action repair framework designed for AI-CPSs
in this work. MORTAR begins by constructing a prediction model that forecasts
the quality of actions proposed by the AI controller. If an unsafe action is
detected, MORTAR then initiates a repair process to correct it. The generation
of repaired actions is achieved through an optimization process guided by the
safety estimates from the prediction model. We evaluate the effectiveness of
MORTAR across various CPS tasks and AI controllers. The results demonstrate
that MORTAR can efficiently improve task completion rates of AI controllers
under specified safety specifications. Meanwhile, it also maintains minimal
computational overhead, ensuring real-time operation of the AI-CPSs.

ÊëòË¶ÅÔºöÁ∂≤Ë∑ØÁâ©ÁêÜÁ≥ªÁµ± (CPS) Âú®ÂêÑÁ®ÆÁî¢Ê•≠ÂíåÊó•Â∏∏ÁîüÊ¥ªÈ†òÂüü‰∏≠Ë∂ä‰æÜË∂äÊôÆÈÅçÔºåÊáâÁî®ÁØÑÂúçÂæûÊ©üÂô®‰∫∫‰ΩúÊ•≠Âà∞Ëá™ÂãïÈßïÈßõ„ÄÇÈö®Ëëó‰∫∫Â∑•Êô∫ÊÖß (AI) ÁöÑÊúÄÊñ∞ÈÄ≤Â±ïÔºåÂü∫ÊñºÂ≠∏ÁøíÁöÑÂÖÉ‰ª∂ÔºåÂ∞§ÂÖ∂ÊòØ AI ÊéßÂà∂Âô®ÔºåÂ∑≤ÊàêÁÇ∫Â¢ûÂº∑ CPS ÂäüËÉΩÂíåÊïàÁéáÁöÑÂøÖË¶ÅÊ¢ù‰ª∂„ÄÇ
ÁÑ∂ËÄåÔºåÈÄô‰∫õ AI ÊéßÂà∂Âô®Áº∫‰πèÂèØËß£ÈáãÊÄßÔºåÂ∞ç AI È©ÖÂãïÁöÑ CPS (AI-CPS) ÁöÑÂÆâÂÖ®ÊÄßËàáÂìÅË≥™‰øùË≠âÊèêÂá∫‰∫ÜÊåëÊà∞„ÄÇÁèæÊúâÁöÑÊîπÂñÑ AI ÊéßÂà∂Âô®ÂÆâÂÖ®ÊÄßÁöÑÊñπÊ≥ïÈÄöÂ∏∏Ê∂âÂèäÁ•ûÁ∂ìÁ∂≤Ë∑Ø‰øÆÂæ©ÔºåÈÄôÈúÄË¶Å‰ΩøÁî®È°çÂ§ñÁöÑÂ∞çÊäóÊÄßÁØÑ‰æãÈáçÊñ∞Ë®ìÁ∑¥ÊàñÂèñÂæóÁ•ûÁ∂ìÁ∂≤Ë∑ØÁöÑË©≥Á¥∞ÂÖßÈÉ®Ë≥áË®ä„ÄÇ
Âõ†Ê≠§ÔºåÈÄô‰∫õÊñπÊ≥ïÂ∞çÊñºÈªëÁõíÊîøÁ≠ñÁöÑÈÅ©Áî®ÊÄßÊúâÈôêÔºåÂõ†ÁÇ∫Âú®Êìç‰ΩúÊúüÈñìÂè™ËÉΩÂ≠òÂèñËº∏ÂÖ•ÂíåËº∏Âá∫„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÊèêÂá∫‰∫Ü MORTARÔºå‰∏ÄÂÄãÂ∞àÁÇ∫ AI-CPS Ë®≠Ë®àÁöÑÂü∑Ë°åÊôÇÈñìÂãï‰Ωú‰øÆÂæ©Êû∂Êßã„ÄÇMORTAR È¶ñÂÖàÂª∫Á´ã‰∏ÄÂÄãÈ†êÊ∏¨Ê®°ÂûãÔºåÁî®ÊñºÈ†êÊ∏¨ AI ÊéßÂà∂Âô®Âª∫Ë≠∞ÁöÑÂãï‰ΩúÂìÅË≥™„ÄÇÂ¶ÇÊûúÂÅµÊ∏¨Âà∞‰∏çÂÆâÂÖ®ÁöÑÂãï‰ΩúÔºåMORTAR Êé•ËëóÊúÉÂïüÂãï‰∏ÄÂÄã‰øÆÂæ©Á®ãÂ∫è‰æÜ‰øÆÊ≠£ÂÆÉ„ÄÇ‰øÆÂæ©Âãï‰ΩúÁöÑÁî¢ÁîüÊòØÈÄèÈÅé‰∏ÄÂÄãÊúÄ‰Ω≥ÂåñÁ®ãÂ∫èÈÅîÊàêÔºåÈÄôÂÄãÁ®ãÂ∫èÁî±È†êÊ∏¨Ê®°ÂûãÁöÑÂÆâÂÖ®‰º∞Ë®àÂÄºÂºïÂ∞é„ÄÇÊàëÂÄëË©ï‰º∞‰∫Ü MORTAR Âú®ÂêÑÁ®Æ CPS ‰ªªÂãôÂíå AI ÊéßÂà∂Âô®‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇÁµêÊûúË≠âÊòé MORTAR ËÉΩÂú®ÊåáÂÆöÁöÑÂÆâÂÖ®ÊÄßË¶èÁØÑ‰∏ãÊúâÊïàÁéáÂú∞ÊîπÂñÑ AI ÊéßÂà∂Âô®ÁöÑ‰ªªÂãôÂÆåÊàêÁéá„ÄÇÂêåÊôÇÔºåÂÆÉ‰πüÁ∂≠ÊåÅÊúÄÂ∞èÁöÑÈÅãÁÆóË≤†ÊìîÔºåÁ¢∫‰øù AI-CPS ÁöÑÂç≥ÊôÇÊìç‰Ωú„ÄÇ

##### **Personalized Clinical Note Generation from Doctor-Patient Conversations**
2408.03874v1 by Nathan Brake, Thomas Schaaf

In this work, we present a novel technique to improve the quality of draft
clinical notes for physicians. This technique is concentrated on the ability to
model implicit physician conversation styles and note preferences. We also
introduce a novel technique for the enrollment of new physicians when a limited
number of clinical notes paired with conversations are available for that
physician, without the need to re-train a model to support them. We show that
our technique outperforms the baseline model by improving the ROUGE-2 score of
the History of Present Illness section by 13.8%, the Physical Examination
section by 88.6%, and the Assessment & Plan section by 50.8%.

ÊëòË¶ÅÔºöÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊäÄË°ì‰æÜÊîπÂñÑÈÜ´Â∏´ÁöÑËá®Â∫äËçâÁ®øÁ≠ÜË®òÂìÅË≥™„ÄÇÊ≠§ÊäÄË°ìÈõÜ‰∏≠Âú®Ê®°Êì¨Èö±Âê´ÁöÑÈÜ´Â∏´Â∞çË©±È¢®Ê†ºÂíåÁ≠ÜË®òÂÅèÂ•ΩÁöÑËÉΩÂäõ„ÄÇÊàëÂÄëÈÇÑÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÊäÄË°ìÔºåÁî®ÊñºÂú®Âè™ÊúâÂ∞ëÊï∏ÈÖçÂ∞çÂ∞çË©±ÁöÑËá®Â∫äÁ≠ÜË®òÂèØÁî®ÊñºË©≤ÈÜ´Â∏´ÊôÇË®ªÂÜäÊñ∞ÈÜ´Â∏´ÔºåËÄåÁÑ°ÈúÄÈáçÊñ∞Ë®ìÁ∑¥Ê®°Âûã‰æÜÊîØÊè¥‰ªñÂÄë„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊàëÂÄëÁöÑÊäÄË°ìÈÄöÈÅéÂ∞áÁèæÁóÖÂè≤ÈÉ®ÂàÜÁöÑ ROUGE-2 ÂàÜÊï∏ÊèêÈ´ò 13.8%„ÄÅË∫´È´îÊ™¢Êü•ÈÉ®ÂàÜÊèêÈ´ò 88.6%„ÄÅË©ï‰º∞ÂíåË®àÁï´ÈÉ®ÂàÜÊèêÈ´ò 50.8%ÔºåË°®ÁèæÂÑ™ÊñºÂü∫Ê∫ñÊ®°Âûã„ÄÇ

##### **Inter-Series Transformer: Attending to Products in Time Series Forecasting**
2408.03872v1 by Rares Cristian, Pavithra Harsha, Clemente Ocejo, Georgia Perakis, Brian Quanz, Ioannis Spantidakis, Hamza Zerhouni

Time series forecasting is an important task in many fields ranging from
supply chain management to weather forecasting. Recently, Transformer neural
network architectures have shown promising results in forecasting on common
time series benchmark datasets. However, application to supply chain demand
forecasting, which can have challenging characteristics such as sparsity and
cross-series effects, has been limited.
  In this work, we explore the application of Transformer-based models to
supply chain demand forecasting. In particular, we develop a new
Transformer-based forecasting approach using a shared, multi-task per-time
series network with an initial component applying attention across time series,
to capture interactions and help address sparsity. We provide a case study
applying our approach to successfully improve demand prediction for a medical
device manufacturing company. To further validate our approach, we also apply
it to public demand forecasting datasets as well and demonstrate competitive to
superior performance compared to a variety of baseline and state-of-the-art
forecast methods across the private and public datasets.

ÊëòË¶ÅÔºöÊôÇÈñìÂ∫èÂàóÈ†êÊ∏¨Âú®Ë®±Â§öÈ†òÂüü‰∏≠ÈÉΩÊòØ‰∏ÄÈ†ÖÈáçË¶ÅÁöÑ‰ªªÂãôÔºåÂæû‰æõÊáâÈèàÁÆ°ÁêÜÂà∞Â§©Ê∞£È†êÊ∏¨ÈÉΩÊúâÊ∂âÂèä„ÄÇÊúÄËøëÔºåTransformer Á•ûÁ∂ìÁ∂≤Ë∑ØÊû∂ÊßãÂú®Â∏∏Ë¶ãÊôÇÈñìÂ∫èÂàóÂü∫Ê∫ñË≥áÊñôÈõÜÁöÑÈ†êÊ∏¨‰∏≠Â±ïÁèæ‰∫Ü‰ª§‰∫∫ÊªøÊÑèÁöÑÊàêÊûú„ÄÇÁÑ∂ËÄåÔºåÊáâÁî®Êñº‰æõÊáâÈèàÈúÄÊ±ÇÈ†êÊ∏¨ÁöÑÁØÑÁñáÂèóÂà∞ÈôêÂà∂ÔºåÂõ†ÁÇ∫‰æõÊáâÈèàÈúÄÊ±ÇÈ†êÊ∏¨ÂèØËÉΩÂÖ∑ÊúâÁ®ÄÁñèÊÄßÂíåË∑®Á≥ªÂàóÊïàÊáâÁ≠âÂÖ∑ÊåëÊà∞ÊÄßÁöÑÁâπÂæµ„ÄÇ
  Âú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂ∞áÂü∫Êñº Transformer ÁöÑÊ®°ÂûãÊáâÁî®Êñº‰æõÊáâÈèàÈúÄÊ±ÇÈ†êÊ∏¨„ÄÇÁâπÂà•ÊòØÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑÂü∫Êñº Transformer ÁöÑÈ†êÊ∏¨ÊñπÊ≥ïÔºå‰ΩøÁî®‰∏ÄÂÄãÂÖ±Áî®ÁöÑ„ÄÅÊØèÂÄãÊôÇÈñìÂ∫èÂàóÁöÑÂ§ö‰ªªÂãôÁ∂≤Ë∑ØÔºå‰∏¶Âú®ÂàùÂßãÂÖÉ‰ª∂‰∏≠Â•óÁî®Ë∑®ÊôÇÈñìÂ∫èÂàóÁöÑÊ≥®ÊÑèÂäõÔºå‰ª•Êì∑Âèñ‰∫íÂãï‰∏¶ÂçîÂä©Ëß£Ê±∫Á®ÄÁñèÊÄßÂïèÈ°å„ÄÇÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÂÄãÊ°à‰æãÁ†îÁ©∂ÔºåÊáâÁî®ÊàëÂÄëÁöÑÂÅöÊ≥ïÊàêÂäüÊîπÂñÑ‰∫Ü‰∏ÄÂÆ∂ÈÜ´ÁôÇÂô®ÊùêË£ΩÈÄ†ÂÖ¨Âè∏ÁöÑÈúÄÊ±ÇÈ†êÊ∏¨„ÄÇÁÇ∫‰∫ÜÈÄ≤‰∏ÄÊ≠•È©óË≠âÊàëÂÄëÁöÑÂÅöÊ≥ïÔºåÊàëÂÄë‰πüÂ∞áÂÖ∂ÊáâÁî®ÊñºÂÖ¨ÈñãÁöÑÈúÄÊ±ÇÈ†êÊ∏¨Ë≥áÊñôÈõÜÔºå‰∏¶Ë≠âÊòéËàáÂêÑÁ®ÆÂü∫Á∑öÂíåÊúÄÂÖàÈÄ≤ÁöÑÈ†êÊ∏¨ÊñπÊ≥ïÁõ∏ÊØîÔºåÂú®ÁßÅÊúâÂíåÂÖ¨ÈñãË≥áÊñôÈõÜ‰∏≠ÁöÑË°®ÁèæÂÖ∑ÊúâÁ´∂Áà≠ÂäõÊàñÂÑ™ÊñºÈÄô‰∫õÊñπÊ≥ï„ÄÇ

##### **BeeManc at the PLABA Track of TAC-2023: Investigating LLMs and Controllable Attributes for Improving Biomedical Text Readability**
2408.03871v1 by Zihao Li, Samuel Belkadi, Nicolo Micheletti, Lifeng Han, Matthew Shardlow, Goran Nenadic

In this system report, we describe the models and methods we used for our
participation in the PLABA2023 task on biomedical abstract simplification, part
of the TAC 2023 tracks. The system outputs we submitted come from the following
three categories: 1) domain fine-tuned T5-like models including Biomedical-T5
and Lay-SciFive; 2) fine-tuned BARTLarge model with controllable attributes
(via tokens) BART-w-CTs; 3) ChatGPTprompting. We also present the work we
carried out for this task on BioGPT finetuning. In the official automatic
evaluation using SARI scores, BeeManc ranks 2nd among all teams and our model
LaySciFive ranks 3rd among all 13 evaluated systems. In the official human
evaluation, our model BART-w-CTs ranks 2nd on Sentence-Simplicity (score
92.84), 3rd on Term-Simplicity (score 82.33) among all 7 evaluated systems; It
also produced a high score 91.57 on Fluency in comparison to the highest score
93.53. In the second round of submissions, our team using ChatGPT-prompting
ranks the 2nd in several categories including simplified term accuracy score
92.26 and completeness score 96.58, and a very similar score on faithfulness
score 95.3 to re-evaluated PLABA-base-1 (95.73) via human evaluations. Our
codes, fine-tuned models, prompts, and data splits from the system development
stage will be available at https://github.com/ HECTA-UoM/PLABA-MU

ÊëòË¶ÅÔºö<paragraph>Âú®ÈÄôÂÄãÁ≥ªÁµ±Â†±Âëä‰∏≠ÔºåÊàëÂÄëÊèèËø∞‰∫ÜÊàëÂÄëÂú® TAC 2023 ËªåÈÅìÁöÑ‰∏ÄÈÉ®ÂàÜÔºåPLABA2023 ÁîüÁâ©ÈÜ´Â≠∏ÊëòË¶ÅÁ∞°Âåñ‰ªªÂãô‰∏≠ÊâÄ‰ΩøÁî®ÁöÑÊ®°ÂûãÂíåÊñπÊ≥ï„ÄÇÊàëÂÄëÊèê‰∫§ÁöÑÁ≥ªÁµ±Ëº∏Âá∫‰æÜËá™‰ª•‰∏ã‰∏âÁ®ÆÈ°ûÂà•Ôºö1) È†òÂüüÂæÆË™øÁöÑ T5 È°û‰ººÊ®°ÂûãÔºåÂåÖÊã¨ Biomedical-T5 Âíå Lay-SciFiveÔºõ2) ÂæÆË™ø BARTLarge Ê®°ÂûãÔºåÂÖ∑ÊúâÂèØÊéßÂ±¨ÊÄßÔºàÈÄöÈÅé‰ª£Âπ£ÔºâBART-w-CTsÔºõ3) ChatGPT ÊèêÁ§∫„ÄÇÊàëÂÄëÈÇÑÂ±ïÁ§∫‰∫ÜÊàëÂÄëÂú® BioGPT ÂæÆË™ø‰∏≠ÁÇ∫ÈÄôÈ†Ö‰ªªÂãôÊâÄÂÅöÁöÑÂ∑•‰Ωú„ÄÇÂú®‰ΩøÁî® SARI ÂàÜÊï∏ÁöÑÂÆòÊñπËá™ÂãïË©ï‰º∞‰∏≠ÔºåBeeManc Âú®ÊâÄÊúâÂúòÈöä‰∏≠ÊéíÂêçÁ¨¨ 2ÔºåÊàëÂÄëÁöÑÊ®°Âûã LaySciFive Âú®ÊâÄÊúâ 13 ÂÄãË©ï‰º∞Á≥ªÁµ±‰∏≠ÊéíÂêçÁ¨¨ 3„ÄÇÂú®ÂÆòÊñπ‰∫∫Â∑•Ë©ï‰º∞‰∏≠ÔºåÊàëÂÄëÁöÑÊ®°Âûã BART-w-CTs Âú®Âè•Â≠êÁ∞°ÊΩîÊÄßÔºàÂàÜÊï∏ 92.84Ôºâ‰∏≠ÊéíÂêçÁ¨¨ 2ÔºåÂú®Ë°ìË™ûÁ∞°ÊΩîÊÄßÔºàÂàÜÊï∏ 82.33Ôºâ‰∏≠ÊéíÂêçÁ¨¨ 3ÔºåÂú®ÊâÄÊúâ 7 ÂÄãË©ï‰º∞Á≥ªÁµ±‰∏≠ÊéíÂêçÁ¨¨ 3ÔºõÂÆÉÈÇÑÁî¢Áîü‰∫Ü 91.57 ÁöÑÈ´òÊµÅÊö¢Â∫¶ÂàÜÊï∏ÔºåËÄåÊúÄÈ´òÂàÜÁÇ∫ 93.53„ÄÇÂú®Á¨¨‰∫åËº™Êèê‰∫§‰∏≠ÔºåÊàëÂÄë‰ΩøÁî® ChatGPT ÊèêÁ§∫ÁöÑÂúòÈöäÂú®ÂπæÂÄãÈ°ûÂà•‰∏≠ÊéíÂêçÁ¨¨ 2ÔºåÂåÖÊã¨Á∞°ÂåñË°ìË™ûÊ∫ñÁ¢∫Â∫¶ÂàÜÊï∏ 92.26 ÂíåÂÆåÊï¥ÊÄßÂàÜÊï∏ 96.58Ôºå‰ª•ÂèäÂ∞ç PLABA-base-1Ôºà95.73ÔºâÈáçÊñ∞Ë©ï‰º∞ÁöÑÂø†ÂØ¶Â∫¶ÂàÜÊï∏ 95.3 ÈùûÂ∏∏Áõ∏‰ººÈÄöÈÅé‰∫∫Â∑•Ë©ï‰º∞„ÄÇÊàëÂÄëÁöÑ‰ª£Á¢º„ÄÅÂæÆË™øÊ®°Âûã„ÄÅÊèêÁ§∫ÂíåÁ≥ªÁµ±ÈñãÁôºÈöéÊÆµÁöÑÊï∏ÊìöÂàÜÂâ≤Â∞áÂú® https://github.com/ HECTA-UoM/PLABA-MU ‰∏≠Êèê‰æõ</paragraph>

##### **Why transformers are obviously good models of language**
2408.03855v1 by Felix Hill

Nobody knows how language works, but many theories abound. Transformers are a
class of neural networks that process language automatically with more success
than alternatives, both those based on neural computations and those that rely
on other (e.g. more symbolic) mechanisms. Here, I highlight direct connections
between the transformer architecture and certain theoretical perspectives on
language. The empirical success of transformers relative to alternative models
provides circumstantial evidence that the linguistic approaches that
transformers embody should be, at least, evaluated with greater scrutiny by the
linguistics community and, at best, considered to be the currently best
available theories.

ÊëòË¶ÅÔºöÊ≤íÊúâ‰∫∫Áü•ÈÅìË™ûË®ÄÊòØÂ¶Ç‰ΩïÈÅã‰ΩúÁöÑÔºå‰ΩÜÊúâË®±Â§öÁêÜË´ñÊµÅÂÇ≥„ÄÇTransformerÊòØ‰∏ÄÁ®ÆÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºåÂèØ‰ª•Ëá™ÂãïËôïÁêÜË™ûË®ÄÔºåÊØîÂÖ∂‰ªñÂü∫ÊñºÁ•ûÁ∂ìÈÅãÁÆóÂíå‰æùË≥¥ÂÖ∂‰ªñÔºà‰æãÂ¶ÇÊõ¥ÂÖ∑Ë±°ÂæµÊÄßÁöÑÔºâÊ©üÂà∂ÁöÑÊõø‰ª£ÊñπÊ°àÊõ¥ÊàêÂäü„ÄÇÂú®Ê≠§ÔºåÊàëÈáçÈªûË™™ÊòéTransformerÊû∂ÊßãËàáË™ûË®ÄÁöÑÊüê‰∫õÁêÜË´ñËßÄÈªû‰πãÈñìÁöÑÁõ¥Êé•ÈóúËÅØ„ÄÇTransformerÁõ∏Â∞çÊñºÊõø‰ª£Ê®°ÂûãÁöÑÁ∂ìÈ©óÊàêÂäüÊèê‰æõ‰∫ÜÁí∞Â¢ÉË≠âÊìöÔºåË≠âÊòéTransformerÊâÄÈ´îÁèæÁöÑË™ûË®ÄÊñπÊ≥ïÊáâËá≥Â∞ëÂèóÂà∞Ë™ûË®ÄÂ≠∏ÁïåÁöÑÊõ¥Âö¥Ê†ºË©ï‰º∞Ôºå‰∏¶Âú®ÊúÄÂ•ΩÁöÑÊÉÖÊ≥Å‰∏ãË¢´Ë™çÁÇ∫ÊòØÁï∂ÂâçÂèØÁî®ÁöÑÊúÄ‰Ω≥ÁêÜË´ñ„ÄÇ

##### **Hate Speech Detection and Classification in Amharic Text with Deep Learning**
2408.03849v1 by Samuel Minale Gashe, Seid Muhie Yimam, Yaregal Assabie

Hate speech is a growing problem on social media. It can seriously impact
society, especially in countries like Ethiopia, where it can trigger conflicts
among diverse ethnic and religious groups. While hate speech detection in
resource rich languages are progressing, for low resource languages such as
Amharic are lacking. To address this gap, we develop Amharic hate speech data
and SBi-LSTM deep learning model that can detect and classify text into four
categories of hate speech: racial, religious, gender, and non-hate speech. We
have annotated 5k Amharic social media post and comment data into four
categories. The data is annotated using a custom annotation tool by a total of
100 native Amharic speakers. The model achieves a 94.8 F1-score performance.
Future improvements will include expanding the dataset and develop state-of-the
art models.
  Keywords: Amharic hate speech detection, classification, Amharic dataset,
Deep Learning, SBi-LSTM

ÊëòË¶ÅÔºö‰ªáÊÅ®Ë®ÄË´ñÊòØÁ§æÁæ§Â™íÈ´î‰∏äÊó•ÁõäÂö¥ÈáçÁöÑÂïèÈ°å„ÄÇÂÆÉÊúÉÂö¥ÈáçÂΩ±ÈüøÁ§æÊúÉÔºåÁâπÂà•ÊòØÂú®ÂÉèË°£Á¥¢ÊØî‰∫ûÈÄôÊ®£ÁöÑÂúãÂÆ∂ÔºåÂÆÉÊúÉÂºïÁôº‰∏çÂêåÁ®ÆÊóèÂíåÂÆóÊïôÂúòÈ´î‰πãÈñìÁöÑË°ùÁ™Å„ÄÇÈõñÁÑ∂Ë≥áÊ∫êË±êÂØåÁöÑË™ûË®Ä‰ªáÊÅ®Ë®ÄË´ñÂÅµÊ∏¨Ê≠£Âú®ÈÄ≤Â±ï‰∏≠Ôºå‰ΩÜÂÉèÈòøÂßÜÂìàÊãâË™ûÈÄôÊ®£ÁöÑ‰ΩéË≥áÊ∫êË™ûË®ÄÂçªÁº∫‰πè„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂ∑ÆË∑ùÔºåÊàëÂÄëÈñãÁôº‰∫ÜÈòøÂßÜÂìàÊãâË™û‰ªáÊÅ®Ë®ÄË´ñË≥áÊñôÂíå SBi-LSTM Ê∑±Â∫¶Â≠∏ÁøíÊ®°ÂûãÔºåÂèØ‰ª•ÂÅµÊ∏¨‰∏¶Â∞áÊñáÂ≠óÂàÜÈ°ûÁÇ∫ÂõõÁ®ÆÈ°ûÂà•ÁöÑ‰ªáÊÅ®Ë®ÄË´ñÔºöÁ®ÆÊóè„ÄÅÂÆóÊïô„ÄÅÊÄßÂà•ÂíåÈùû‰ªáÊÅ®Ë®ÄË´ñ„ÄÇÊàëÂÄëÂ∑≤Â∞á 5 ÂçÉÂÄãÈòøÂßÜÂìàÊãâË™ûÁ§æÁæ§Â™íÈ´îË≤ºÊñáÂíåÁïôË®ÄË≥áÊñôË®ªËß£ÁÇ∫ÂõõÁ®ÆÈ°ûÂà•„ÄÇË≥áÊñôÊòØÁî±Á∏ΩÂÖ± 100 ‰ΩçÊØçË™ûÁÇ∫ÈòøÂßÜÂìàÊãâË™ûÁöÑË¨õËÄÖ‰ΩøÁî®Ëá™Ë®ÇË®ªËß£Â∑•ÂÖ∑ÈÄ≤Ë°åË®ªËß£„ÄÇË©≤Ê®°ÂûãÈÅîÂà∞‰∫Ü 94.8 ÁöÑ F1 ÂàÜÊï∏Ë°®Áèæ„ÄÇÊú™‰æÜÁöÑÊîπÈÄ≤Â∞áÂåÖÊã¨Êì¥ÂÖÖË≥áÊñôÈõÜÂíåÈñãÁôºÊúÄÂÖàÈÄ≤ÁöÑÊ®°Âûã„ÄÇ
ÈóúÈçµÂ≠óÔºöÈòøÂßÜÂìàÊãâË™û‰ªáÊÅ®Ë®ÄË´ñÂÅµÊ∏¨„ÄÅÂàÜÈ°û„ÄÅÈòøÂßÜÂìàÊãâË™ûË≥áÊñôÈõÜ„ÄÅÊ∑±Â∫¶Â≠∏Áøí„ÄÅSBi-LSTM

##### **MaxMind: A Memory Loop Network to Enhance Software Productivity based on Large Language Models**
2408.03841v1 by Yuchen Dong, XiaoXiang Fang, Yuchen Hu, Renshuang Jiang, Zhe Jiang

The application of large language models to facilitate automated software
operations and tool generation (SOTG), thus augmenting software productivity,
mirrors the early stages of human evolution when the ability to create and use
tools accelerated the progress of civilization. These complex tasks require AI
to continuously summarize and improve. Current research often overlooks the
importance of converting real-time task experiences into system memory and
differentiating the value of existing knowledge for future reference. This
paper addresses these issues by evolving external memory models into
Memory-Loop Networks for timely memorization and experience referencing. We
also enhance a RAG mechanism with knowledge precision segmentation to utilize
memory based on value differentiation, and design the MaxMind model for SOTG
accordingly.To demonstrate our approach, we developed MaxMind4Sheet, an
electronic spreadsheet processing system aligned with the MaxMind philosophy.
Comparative experiments with SheetCopilot have demonstrated that the
accumulation and recycling of task memories lead to a steady enhancement in
task success rate, with an improvement rate of approximately 3%-6% per round in
this implementation example. Note that as the memories continue to grow, this
cumulative improvement may be substantial. The inclusion of memory recycling
can also boost the system's task execution efficiency by up to 25%, and it can
address the retraining issue faced by LLMs when handling specialized tasks
through memories transfer.These suggest that MaxMind has significant potential
to enhance the capabilities and productivity of LLM systems in SOTG.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÊáâÁî®ÊúâÂä©Êñº‰øÉÈÄ≤Ëá™ÂãïÂåñËªüÈ´îÊìç‰ΩúÂíåÂ∑•ÂÖ∑ÁîüÊàê (SOTG)ÔºåÈÄ≤ËÄåÊèêÂçáËªüÈ´îÁîüÁî¢ÂäõÔºåÈÄôÂèçÊò†‰∫Ü‰∫∫È°ûÊºîÂåñÁöÑÊó©ÊúüÈöéÊÆµÔºåÁï∂ÊôÇÂâµÈÄ†Âíå‰ΩøÁî®Â∑•ÂÖ∑ÁöÑËÉΩÂäõÂä†ÈÄü‰∫ÜÊñáÊòéÁöÑÈÄ≤Ê≠•„ÄÇÈÄô‰∫õË§áÈõúÁöÑ‰ªªÂãôÈúÄË¶Å AI ÊåÅÁ∫åÁ∏ΩÁµêÂíåÊîπÈÄ≤„ÄÇÁõÆÂâçÁöÑË®±Â§öÁ†îÁ©∂Â∏∏Â∏∏ÂøΩÁï•Â∞áÂç≥ÊôÇ‰ªªÂãôÁ∂ìÈ©óËΩâÊèõÁÇ∫Á≥ªÁµ±Ë®òÊÜ∂Ôºå‰ª•ÂèäÂçÄÂàÜÁèæÊúâÁü•Ë≠òÂ∞çÊú™‰æÜÂèÉËÄÉÂÉπÂÄºÁöÑÈáçË¶ÅÊÄß„ÄÇÊú¨ÊñáÈÄèÈÅéÂ∞áÂ§ñÈÉ®Ë®òÊÜ∂Ê®°ÂûãÊºîËÆäÊàêË®òÊÜ∂Ëø¥ÂúàÁ∂≤Ë∑ØÔºå‰ª•ÂØ¶ÁèæÂèäÊôÇË®òÊÜ∂ÂíåÁ∂ìÈ©óÂèÉËÄÉÔºå‰æÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°å„ÄÇÊàëÂÄë‰πüÈÄèÈÅéÁü•Ë≠òÁ≤æÊ∫ñÂàÜÊÆµ‰æÜÂº∑Âåñ RAG Ê©üÂà∂Ôºå‰ª•Ê†πÊìöÂÉπÂÄºÂçÄÂàÜ‰æÜÂà©Áî®Ë®òÊÜ∂Ôºå‰∏¶ÊìöÊ≠§Ë®≠Ë®àÁî®Êñº SOTG ÁöÑ MaxMind Ê®°Âûã„ÄÇÁÇ∫‰∫ÜÂ±ïÁ§∫ÊàëÂÄëÁöÑÂÅöÊ≥ïÔºåÊàëÂÄëÈñãÁôº‰∫Ü MaxMind4SheetÔºåÈÄôÊòØ‰∏ÄÂÄãËàá MaxMind ÁêÜÂøµ‰∏ÄËá¥ÁöÑÈõªÂ≠êË©¶ÁÆóË°®ËôïÁêÜÁ≥ªÁµ±„ÄÇËàá SheetCopilot ÈÄ≤Ë°åÁöÑÊØîËºÉÂØ¶È©óÂ∑≤Ë≠âÊòéÔºå‰ªªÂãôË®òÊÜ∂ÁöÑÁ¥ØÁ©çÂíåÂÜçÂà©Áî®ÊúÉÊåÅÁ∫åÊèêÂçá‰ªªÂãôÊàêÂäüÁéáÔºåÂú®Ê≠§ÂØ¶‰ΩúÁØÑ‰æã‰∏≠ÔºåÊØèÂõûÂêàÁöÑÊèêÂçáÁéáÁ¥ÑÁÇ∫ 3%-6%„ÄÇË´ãÊ≥®ÊÑèÔºåÈö®ËëóË®òÊÜ∂ÁöÑÊåÅÁ∫åÂ¢ûÂä†ÔºåÈÄôÁ®ÆÁ¥ØÁ©çÊèêÂçáÂèØËÉΩÊúÉÂæàÂèØËßÄ„ÄÇÁ¥çÂÖ•Ë®òÊÜ∂ÂÜçÂà©Áî®‰πüËÉΩÊèêÂçáÁ≥ªÁµ±ÁöÑ‰ªªÂãôÂü∑Ë°åÊïàÁéáÔºåÊúÄÈ´òÂèØÈÅî 25%ÔºåËÄå‰∏îÂÆÉËÉΩÈÄèÈÅéË®òÊÜ∂ËΩâÁßª‰æÜËß£Ê±∫ LLM Âú®ËôïÁêÜÂ∞àÊ•≠‰ªªÂãôÊôÇÊâÄÈù¢Ëá®ÁöÑÈáçÊñ∞Ë®ìÁ∑¥ÂïèÈ°å„ÄÇÈÄô‰∫õÈÉΩÈ°ØÁ§∫Âá∫ MaxMind Âú®ÊèêÂçá LLM Á≥ªÁµ±Âú® SOTG ‰∏≠ÁöÑËÉΩÂäõÂíåÁîüÁî¢ÂäõÊñπÈù¢ÂÖ∑ÊúâÈ°ØËëóÁöÑÊΩõÂäõ„ÄÇ

##### **WalledEval: A Comprehensive Safety Evaluation Toolkit for Large Language Models**
2408.03837v1 by Prannaya Gupta, Le Qi Yau, Hao Han Low, I-Shiang Lee, Hugo Maximus Lim, Yu Xin Teoh, Jia Hng Koh, Dar Win Liew, Rishabh Bhardwaj, Rajat Bhardwaj, Soujanya Poria

WalledEval is a comprehensive AI safety testing toolkit designed to evaluate
large language models (LLMs). It accommodates a diverse range of models,
including both open-weight and API-based ones, and features over 35 safety
benchmarks covering areas such as multilingual safety, exaggerated safety, and
prompt injections. The framework supports both LLM and judge benchmarking, and
incorporates custom mutators to test safety against various text-style
mutations such as future tense and paraphrasing. Additionally, WalledEval
introduces WalledGuard, a new, small and performant content moderation tool,
and SGXSTest, a benchmark for assessing exaggerated safety in cultural
contexts. We make WalledEval publicly available at
https://github.com/walledai/walledevalA.

ÊëòË¶ÅÔºöWalledEval ÊòØ‰∏ÄÂÄãÂÖ®Èù¢ÁöÑ AI ÂÆâÂÖ®Ê∏¨Ë©¶Â∑•ÂÖ∑ÂåÖÔºåÊó®Âú®Ë©ï‰º∞Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)„ÄÇÂÆÉÂÆπÁ¥ç‰∫ÜÂêÑÁ®ÆÊ®°ÂûãÔºåÂåÖÊã¨ÈñãÊîæÊ¨äÈáçÂíåÂü∫Êñº API ÁöÑÊ®°ÂûãÔºå‰∏¶ÂÖ∑ÊúâË∂ÖÈÅé 35 ÂÄãÂÆâÂÖ®Âü∫Ê∫ñÔºåÊ∂µËìãÂ§öË™ûË®ÄÂÆâÂÖ®„ÄÅË™áÂºµÂÆâÂÖ®ÂíåÊèêÁ§∫Ê≥®ÂÖ•Á≠âÈ†òÂüü„ÄÇË©≤Ê°ÜÊû∂ÊîØÊè¥ LLM ÂíåË©ïÂØ©Âü∫Ê∫ñÊ∏¨Ë©¶Ôºå‰∏¶Êï¥ÂêàËá™Ë®ÇËÆäÁï∞Âô®Ôºå‰ª•ÈáùÂ∞çÂêÑÁ®ÆÊñáÂ≠óÊ®£ÂºèËÆäÁï∞Ôºà‰æãÂ¶ÇÊú™‰æÜÂºèÂíåÂêåÁæ©ÊîπÂØ´ÔºâÊ∏¨Ë©¶ÂÆâÂÖ®ÊÄß„ÄÇÊ≠§Â§ñÔºåWalledEval ÂºïÂÖ•‰∫Ü WalledGuardÔºåÈÄôÊòØ‰∏ÄÂÄãÊñ∞ÁöÑ„ÄÅÂ∞èÂ∑ß‰∏îÈ´òÊïàÁöÑÂÖßÂÆπÂØ©Ê†∏Â∑•ÂÖ∑Ôºå‰ª•Âèä SGXSTestÔºå‰∏ÄÂÄãÁî®ÊñºË©ï‰º∞ÊñáÂåñËÉåÊôØ‰∏≠Ë™áÂ§ßÂÆâÂÖ®ÊÄßÁöÑÂü∫Ê∫ñ„ÄÇÊàëÂÄëÂú® https://github.com/walledai/walledevalA ‰∏äÂÖ¨Èñã WalledEval„ÄÇ

##### **Target Prompting for Information Extraction with Vision Language Model**
2408.03834v1 by Dipankar Medhi

The recent trend in the Large Vision and Language model has brought a new
change in how information extraction systems are built. VLMs have set a new
benchmark with their State-of-the-art techniques in understanding documents and
building question-answering systems across various industries. They are
significantly better at generating text from document images and providing
accurate answers to questions. However, there are still some challenges in
effectively utilizing these models to build a precise conversational system.
General prompting techniques used with large language models are often not
suitable for these specially designed vision language models. The output
generated by such generic input prompts is ordinary and may contain information
gaps when compared with the actual content of the document. To obtain more
accurate and specific answers, a well-targeted prompt is required by the vision
language model, along with the document image. In this paper, a technique is
discussed called Target prompting, which focuses on explicitly targeting parts
of document images and generating related answers from those specific regions
only. The paper also covers the evaluation of response for each prompting
technique using different user queries and input prompts.

ÊëòË¶ÅÔºöËøëÊúüÂ§ßÂûãË¶ñË¶∫ËàáË™ûË®ÄÊ®°ÂûãÁöÑË∂®Âã¢ÁÇ∫Ë≥áË®äËêÉÂèñÁ≥ªÁµ±ÁöÑÂª∫ÁΩÆÊñπÂºèÂ∏∂‰æÜ‰∫ÜÊñ∞ÁöÑËÆäÂåñ„ÄÇVLMs ‰ª•ÂÖ∂Âú®ÁêÜËß£Êñá‰ª∂ÂíåÂª∫Á´ãË∑®Áî¢Ê•≠ÂïèÁ≠îÁ≥ªÁµ±ÁöÑÊúÄÊñ∞ÊäÄË°ìÊ®πÁ´ã‰∫ÜÊñ∞ÁöÑÂü∫Ê∫ñ„ÄÇÂÆÉÂÄëÂú®ÂæûÊñá‰ª∂ÂΩ±ÂÉèÁî¢ÁîüÊñáÂ≠óÂíåÊèê‰æõÊ∫ñÁ¢∫ÁöÑÁ≠îÊ°àÊñπÈù¢È°ØËëóÂú∞Êõ¥Âá∫Ëâ≤„ÄÇÁÑ∂ËÄåÔºåÂú®ÊúâÊïàÂà©Áî®ÈÄô‰∫õÊ®°Âûã‰æÜÂª∫Á´ãÁ≤æÁ¢∫ÁöÑÂ∞çË©±Á≥ªÁµ±ÊñπÈù¢‰ªçÊúâ‰∏Ä‰∫õÊåëÊà∞„ÄÇËàáÂ§ßÂûãË™ûË®ÄÊ®°Âûã‰∏ÄËµ∑‰ΩøÁî®ÁöÑ‰∏ÄËà¨ÊèêÁ§∫ÊäÄË°ìÈÄöÂ∏∏‰∏çÈÅ©ÂêàÈÄô‰∫õÁâπÂà•Ë®≠Ë®àÁöÑË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã„ÄÇÊ≠§È°û‰∏ÄËà¨Ëº∏ÂÖ•ÊèêÁ§∫Áî¢ÁîüÁöÑËº∏Âá∫ÂæàÊôÆÈÄöÔºåËàáÊñá‰ª∂ÁöÑÂØ¶ÈöõÂÖßÂÆπÁõ∏ÊØîÊôÇÂèØËÉΩÊúÉÂåÖÂê´Ë≥áË®äÂ∑ÆË∑ù„ÄÇÁÇ∫‰∫ÜÁç≤ÂæóÊõ¥Ê∫ñÁ¢∫‰∏îÂÖ∑È´îÁöÑÁ≠îÊ°àÔºåË¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÈúÄË¶Å‰∏ÄÂÄãÊòéÁ¢∫ÁöÑÁõÆÊ®ôÊèêÁ§∫Ôºå‰ª•ÂèäÊñá‰ª∂ÂΩ±ÂÉè„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåË®éË´ñ‰∫Ü‰∏ÄÁ®ÆÁ®±ÁÇ∫ÁõÆÊ®ôÊèêÁ§∫ÁöÑÊäÄË°ìÔºåÂÖ∂Â∞àÊ≥®ÊñºÊòéÁ¢∫ÈéñÂÆöÊñá‰ª∂ÂΩ±ÂÉèÁöÑÈÉ®ÂàÜÔºå‰∏¶ÂÉÖÂæûÈÇ£‰∫õÁâπÂÆöÂçÄÂüüÁî¢ÁîüÁõ∏ÈóúÁ≠îÊ°à„ÄÇÊú¨ÊñáÈÇÑÊ∂µËìã‰∫Ü‰ΩøÁî®‰∏çÂêåÁöÑ‰ΩøÁî®ËÄÖÊü•Ë©¢ÂíåËº∏ÂÖ•ÊèêÁ§∫Â∞çÊØèÁ®ÆÊèêÁ§∫ÊäÄË°ìÁöÑÂõûÊáâË©ï‰º∞„ÄÇ

##### **Automated Code Fix Suggestions for Accessibility Issues in Mobile Apps**
2408.03827v1 by Forough Mehralian, Titus Barik, Jeff Nichols, Amanda Swearngin

Accessibility is crucial for inclusive app usability, yet developers often
struggle to identify and fix app accessibility issues due to a lack of
awareness, expertise, and inadequate tools. Current accessibility testing tools
can identify accessibility issues but may not always provide guidance on how to
address them. We introduce FixAlly, an automated tool designed to suggest
source code fixes for accessibility issues detected by automated accessibility
scanners. FixAlly employs a multi-agent LLM architecture to generate fix
strategies, localize issues within the source code, and propose code
modification suggestions to fix the accessibility issue. Our empirical study
demonstrates FixAlly's capability in suggesting fixes that resolve issues found
by accessibility scanners -- with an effectiveness of 77% in generating
plausible fix suggestions -- and our survey of 12 iOS developers finds they
would be willing to accept 69.4% of evaluated fix suggestions.

ÊëòË¶ÅÔºöÁÑ°ÈöúÁ§ôÂäüËÉΩÂ∞çÊñºÂåÖÂÆπÊÄßÊáâÁî®Á®ãÂºèÂèØÁî®ÊÄßËá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÈñãÁôº‰∫∫Âì°Á∂ìÂ∏∏Âõ†Áº∫‰πèÊÑèË≠ò„ÄÅÂ∞àÊ•≠Áü•Ë≠òÂíåÂ∑•ÂÖ∑‰∏çË∂≥ËÄåÈõ£‰ª•Ë≠òÂà•Âíå‰øÆÂæ©ÊáâÁî®Á®ãÂºèÁÑ°ÈöúÁ§ôÊÄßÂïèÈ°å„ÄÇÁõÆÂâçÁöÑÁÑ°ÈöúÁ§ôÊÄßÊ∏¨Ë©¶Â∑•ÂÖ∑ÂèØ‰ª•Ë≠òÂà•ÁÑ°ÈöúÁ§ôÊÄßÂïèÈ°åÔºå‰ΩÜÂèØËÉΩÁÑ°Ê≥ïÂßãÁµÇÊèê‰æõÂ¶Ç‰ΩïËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÁöÑÊåáÂ∞é„ÄÇÊàëÂÄë‰ªãÁ¥π FixAllyÔºåÈÄôÊòØ‰∏ÄÂÄãËá™ÂãïÂåñÂ∑•ÂÖ∑ÔºåÊó®Âú®ÁÇ∫Ëá™ÂãïÂåñÁÑ°ÈöúÁ§ôÊÄßÊéÉÊèèÂô®Ê™¢Ê∏¨Âà∞ÁöÑÁÑ°ÈöúÁ§ôÊÄßÂïèÈ°åÂª∫Ë≠∞ÂéüÂßãÁ¢º‰øÆÂæ©Á®ãÂºè„ÄÇFixAlly Êé°Áî®Â§ö‰ª£ÁêÜ LLM Êû∂Êßã‰æÜÁî¢Áîü‰øÆÂæ©Á≠ñÁï•ÔºåÂú®ÂéüÂßãÁ¢º‰∏≠ÊâæÂá∫ÂïèÈ°åÔºå‰∏¶ÊèêÂá∫‰øÆÂæ©ÁÑ°ÈöúÁ§ôÊÄßÂïèÈ°åÁöÑÁ®ãÂºèÁ¢º‰øÆÊîπÂª∫Ë≠∞„ÄÇÊàëÂÄëÁöÑÂØ¶Ë≠âÁ†îÁ©∂Ë≠âÊòé‰∫Ü FixAlly Âú®Âª∫Ë≠∞‰øÆÂæ©Á®ãÂºè‰ª•Ëß£Ê±∫ÁÑ°ÈöúÁ§ôÊÄßÊéÉÊèèÂô®ÁôºÁèæÁöÑÂïèÈ°åÊñπÈù¢ÁöÑËÉΩÂäõ‚Äî‚ÄîÂú®Áî¢ÁîüÁúã‰ººÂêàÁêÜÁöÑ‰øÆÂæ©Âª∫Ë≠∞ÊñπÈù¢ÊúâÊïàÁéáÁÇ∫ 77%‚Äî‚ÄîËÄå‰∏îÊàëÂÄëÂ∞ç 12 ‰Ωç iOS ÈñãÁôº‰∫∫Âì°ÁöÑË™øÊü•ÁôºÁèæÔºå‰ªñÂÄëÈ°òÊÑèÊé•Âèó 69.4% ÁöÑË©ï‰º∞‰øÆÂæ©Âª∫Ë≠∞„ÄÇ

##### **Leveraging Variation Theory in Counterfactual Data Augmentation for Optimized Active Learning**
2408.03819v1 by Simret Araya Gebreegziabher, Kuangshi Ai, Zheng Zhang, Elena L. Glassman, Toby Jia-Jun Li

Active Learning (AL) allows models to learn interactively from user feedback.
This paper introduces a counterfactual data augmentation approach to AL,
particularly addressing the selection of datapoints for user querying, a
pivotal concern in enhancing data efficiency. Our approach is inspired by
Variation Theory, a theory of human concept learning that emphasizes the
essential features of a concept by focusing on what stays the same and what
changes. Instead of just querying with existing datapoints, our approach
synthesizes artificial datapoints that highlight potential key similarities and
differences among labels using a neuro-symbolic pipeline combining large
language models (LLMs) and rule-based models. Through an experiment in the
example domain of text classification, we show that our approach achieves
significantly higher performance when there are fewer annotated data. As the
annotated training data gets larger the impact of the generated data starts to
diminish showing its capability to address the cold start problem in AL. This
research sheds light on integrating theories of human learning into the
optimization of AL.

ÊëòË¶ÅÔºö‰∏ªÂãïÂ≠∏Áøí (AL) ÂÖÅË®±Ê®°ÂûãÂæû‰ΩøÁî®ËÄÖÂõûÈ•ã‰∏≠‰∫íÂãïÂºèÂú∞Â≠∏Áøí„ÄÇ
Êú¨Êñá‰ªãÁ¥π‰∏ÄÁ®ÆÂèç‰∫ãÂØ¶Ë≥áÊñôÊì¥ÂÖÖÊñπÊ≥ïÂà∞ ALÔºå
ÁâπÂà•ËôïÁêÜ‰ΩøÁî®ËÄÖÊü•Ë©¢Ë≥áÊñôÈªûÁöÑÈÅ∏ÊìáÔºåÈÄôÊòØÊèêÂçáË≥áÊñôÊïàÁéáÁöÑÈóúÈçµÂïèÈ°å„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÂèóÂà∞ËÆäÁï∞ÁêÜË´ñÁöÑÂïüÁôºÔºå‰∏ÄÁ®ÆÂº∑Ë™øÊ¶ÇÂøµÁöÑÊú¨Ë≥™ÁâπÂæµÔºåËëóÈáçÊñº‰ªÄÈ∫º‰øùÊåÅ‰∏çËÆäÂíå‰ªÄÈ∫ºÊîπËÆäÁöÑ‰∫∫È°ûÊ¶ÇÂøµÂ≠∏ÁøíÁêÜË´ñ„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ï‰∏¶ÈùûÂÉÖ‰ΩøÁî®ÁèæÊúâË≥áÊñôÈªûÊü•Ë©¢ÔºåËÄåÊòØ‰ΩøÁî®ÁµêÂêàÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂíåÂü∫ÊñºË¶èÂâáÊ®°ÂûãÁöÑÁ•ûÁ∂ìÁ¨¶ËôüÁÆ°Á∑öÔºåÂêàÊàê‰∫∫Â∑•Ë≥áÊñôÈªûÔºå‰ª•Á™ÅÈ°ØÊ®ôÁ±§‰πãÈñìÁöÑÊΩõÂú®ÈóúÈçµÁõ∏‰ººÊÄßÂíåÂ∑ÆÁï∞„ÄÇÈÄèÈÅéÂú®ÊñáÂ≠óÂàÜÈ°ûÁØÑ‰æãÈ†òÂüü‰∏≠ÁöÑÂØ¶È©óÔºåÊàëÂÄëÈ°ØÁ§∫ÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®Ë®ªËß£Ë≥áÊñôËºÉÂ∞ëÊôÇÔºåÂèØÈÅîÂà∞È°ØËëóÊõ¥È´òÁöÑÊïàËÉΩ„ÄÇÈö®ËëóË®ªËß£Ë®ìÁ∑¥Ë≥áÊñôËÆäÂ§ßÔºåÁîüÊàêË≥áÊñôÁöÑÂΩ±ÈüøÈñãÂßãÊ∏õÂº±ÔºåÈ°ØÁ§∫ÂÖ∂Ëß£Ê±∫ AL ‰∏≠ÂÜ∑ÂïüÂãïÂïèÈ°åÁöÑËÉΩÂäõ„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Ë™™Êòé‰∫ÜÂ∞á‰∫∫È°ûÂ≠∏ÁøíÁêÜË´ñÊï¥ÂêàÂà∞ AL ÊúÄ‰Ω≥Âåñ‰∏≠ÁöÑÊñπÊ≥ï„ÄÇ

##### **Generative Language Models with Retrieval Augmented Generation for Automated Short Answer Scoring**
2408.03811v1 by Zifan Wang, Christopher Ormerod

Automated Short Answer Scoring (ASAS) is a critical component in educational
assessment. While traditional ASAS systems relied on rule-based algorithms or
complex deep learning methods, recent advancements in Generative Language
Models (GLMs) offer new opportunities for improvement. This study explores the
application of GLMs to ASAS, leveraging their off-the-shelf capabilities and
performance in various domains. We propose a novel pipeline that combines
vector databases, transformer-based encoders, and GLMs to enhance short answer
scoring accuracy. Our approach stores training responses in a vector database,
retrieves semantically similar responses during inference, and employs a GLM to
analyze these responses and determine appropriate scores. We further optimize
the system through fine-tuned retrieval processes and prompt engineering.
Evaluation on the SemEval 2013 dataset demonstrates a significant improvement
on the SCIENTSBANK 3-way and 2-way tasks compared to existing methods,
highlighting the potential of GLMs in advancing ASAS technology.

ÊëòË¶ÅÔºöËá™ÂãïÂåñÁ∞°Á≠îË©ïÂàÜ (ASAS) ÊòØÊïôËÇ≤Ë©ïÈáè‰∏≠ÁöÑÈóúÈçµÁµÑÊàêÈÉ®ÂàÜ„ÄÇÈõñÁÑ∂ÂÇ≥Áµ±ÁöÑ ASAS Á≥ªÁµ±‰æùË≥¥ÊñºÂü∫ÊñºË¶èÂâáÁöÑÊºîÁÆóÊ≥ïÊàñË§áÈõúÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊñπÊ≥ïÔºå‰ΩÜÁîüÊàêÂºèË™ûË®ÄÊ®°Âûã (GLM) ÁöÑËøëÊúüÈÄ≤Â±ïÁÇ∫ÊîπÈÄ≤Êèê‰æõ‰∫ÜÊñ∞ÁöÑÊ©üÊúÉ„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫Ü GLM Âú® ASAS ‰∏≠ÁöÑÊáâÁî®ÔºåÂà©Áî®ÂÆÉÂÄëÁöÑÁèæÊàêÂäüËÉΩÂíåÂú®ÂêÑÁ®ÆÈ†òÂüüÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÁÆ°ÈÅìÔºåÁµêÂêà‰∫ÜÂêëÈáèË≥áÊñôÂ∫´„ÄÅÂü∫ÊñºËΩâÊèõÂô®ÁöÑÁ∑®Á¢ºÂô®Âíå GLMÔºå‰ª•ÊèêÈ´òÁ∞°Á≠îË©ïÂàÜÊ∫ñÁ¢∫Â∫¶„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊòØÂ∞áË®ìÁ∑¥ÂõûÊáâÂÑ≤Â≠òÂú®ÂêëÈáèË≥áÊñôÂ∫´‰∏≠ÔºåÂú®Êé®Ë´ñÈÅéÁ®ã‰∏≠Êì∑ÂèñË™ûÁæ©‰∏äÁõ∏‰ººÁöÑÂõûÊáâÔºå‰∏¶Êé°Áî® GLM ‰æÜÂàÜÊûêÈÄô‰∫õÂõûÊáâ‰∏¶Á¢∫ÂÆöÈÅ©Áï∂ÁöÑÂàÜÊï∏„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÈÄèÈÅéÂæÆË™øÊì∑ÂèñÊµÅÁ®ãÂíåÊèêÁ§∫Â∑•Á®ã‰æÜÂÑ™ÂåñÁ≥ªÁµ±„ÄÇÂú® SemEval 2013 Ë≥áÊñôÈõÜ‰∏äÁöÑË©ï‰º∞È°ØÁ§∫ÔºåËàáÁèæÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåÂú® SCIENTSBANK ‰∏âÂêëÂíå‰∫åÂêë‰ªªÂãô‰∏äÊúâ‰∫ÜÈ°ØËëóÁöÑÊîπÈÄ≤ÔºåÁ™ÅÈ°Ø‰∫Ü GLM Âú®Êé®ÈÄ≤ ASAS ÊäÄË°ìÊñπÈù¢ÁöÑÊΩõÂäõ„ÄÇ

##### **Navigating the Human Maze: Real-Time Robot Pathfinding with Generative Imitation Learning**
2408.03807v1 by Martin Moder, Stephen Adhisaputra, Josef Pauli

This paper addresses navigation in crowded environments by integrating
goal-conditioned generative models with Sampling-based Model Predictive Control
(SMPC). We introduce goal-conditioned autoregressive models to generate crowd
behaviors, capturing intricate interactions among individuals. The model
processes potential robot trajectory samples and predicts the reactions of
surrounding individuals, enabling proactive robotic navigation in complex
scenarios. Extensive experiments show that this algorithm enables real-time
navigation, significantly reducing collision rates and path lengths, and
outperforming selected baseline methods. The practical effectiveness of this
algorithm is validated on an actual robotic platform, demonstrating its
capability in dynamic settings.

ÊëòË¶ÅÔºöÊú¨ÊñáÈÄèÈÅéÊï¥ÂêàÁõÆÊ®ôÊ¢ù‰ª∂ÁîüÊàêÊ®°ÂûãËàáÂü∫ÊñºÂèñÊ®£ÁöÑÊ®°ÂûãÈ†êÊ∏¨ÊéßÂà∂ (SMPC) ‰æÜÊé¢Ë®éÊìÅÊì†Áí∞Â¢É‰∏≠ÁöÑÂ∞éËà™„ÄÇÊàëÂÄëÂºïÈÄ≤ÁõÆÊ®ôÊ¢ù‰ª∂Ëá™Ëø¥Ê≠∏Ê®°Âûã‰æÜÁî¢ÁîüÁæ§ÁúæË°åÁÇ∫ÔºåÊçïÊçâÂÄã‰∫∫‰πãÈñìÁöÑË§áÈõú‰∫íÂãï„ÄÇÊ≠§Ê®°ÂûãËôïÁêÜÊΩõÂú®Ê©üÂô®‰∫∫ËªåË∑°ÁØÑ‰æãÔºå‰∏¶È†êÊ∏¨Âë®ÂúçÂÄãÈ´îÁöÑÂèçÊáâÔºåËÆìÊ©üÂô®‰∫∫Âú®Ë§áÈõúÂ†¥ÊôØ‰∏≠ËÉΩÈÄ≤Ë°å‰∏ªÂãïÂ∞éËà™„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåÊ≠§ÊºîÁÆóÊ≥ïËÉΩÈÄ≤Ë°åÂç≥ÊôÇÂ∞éËà™ÔºåÂ§ßÂπÖÈôç‰ΩéÁ¢∞ÊíûÁéáÂíåË∑ØÂæëÈï∑Â∫¶Ôºå‰∏¶‰∏îÂÑ™ÊñºÈÅ∏ÂÆöÁöÑÂü∫Á∑öÊñπÊ≥ï„ÄÇÊ≠§ÊºîÁÆóÊ≥ïÁöÑÂØ¶Áî®ÊúâÊïàÊÄßÂ∑≤Âú®ÂØ¶ÈöõÊ©üÂô®‰∫∫Âπ≥Âè∞‰∏äÈ©óË≠âÔºåË≠âÊòéÂÖ∂Âú®ÂãïÊÖãË®≠ÂÆö‰∏≠ÁöÑËÉΩÂäõ„ÄÇ

##### **Relevance meets Diversity: A User-Centric Framework for Knowledge Exploration through Recommendations**
2408.03772v1 by Erica Coppolillo, Giuseppe Manco, Aristides Gionis

Providing recommendations that are both relevant and diverse is a key
consideration of modern recommender systems. Optimizing both of these measures
presents a fundamental trade-off, as higher diversity typically comes at the
cost of relevance, resulting in lower user engagement. Existing recommendation
algorithms try to resolve this trade-off by combining the two measures,
relevance and diversity, into one aim and then seeking recommendations that
optimize the combined objective, for a given number of items to recommend.
Traditional approaches, however, do not consider the user interaction with the
recommended items.
  In this paper, we put the user at the central stage, and build on the
interplay between relevance, diversity, and user behavior. In contrast to
applications where the goal is solely to maximize engagement, we focus on
scenarios aiming at maximizing the total amount of knowledge encountered by the
user. We use diversity as a surrogate of the amount of knowledge obtained by
the user while interacting with the system, and we seek to maximize diversity.
We propose a probabilistic user-behavior model in which users keep interacting
with the recommender system as long as they receive relevant recommendations,
but they may stop if the relevance of the recommended items drops. Thus, for a
recommender system to achieve a high-diversity measure, it will need to produce
recommendations that are both relevant and diverse.
  Finally, we propose a novel recommendation strategy that combines relevance
and diversity by a copula function. We conduct an extensive evaluation of the
proposed methodology over multiple datasets, and we show that our strategy
outperforms several state-of-the-art competitors. Our implementation is
publicly available at https://github.com/EricaCoppolillo/EXPLORE.

ÊëòË¶ÅÔºöÊèê‰æõÊó¢Áõ∏ÈóúÂèàÂ§öÊ®£ÂåñÁöÑÂª∫Ë≠∞ÊòØÁèæ‰ª£Êé®Ëñ¶Á≥ªÁµ±ÁöÑ‰∏ÄÈ†ÖÈáçË¶ÅËÄÉÈáè„ÄÇÊúÄ‰Ω≥ÂåñÈÄôÂÖ©ÂÄãÊåáÊ®ôÊúÉÁî¢ÁîüÊ†πÊú¨ÊÄßÁöÑÂèñÊç®ÔºåÂõ†ÁÇ∫Êõ¥È´òÁöÑÂ§öÊ®£ÊÄßÈÄöÂ∏∏ÊúÉ‰ª•Áõ∏ÈóúÊÄßÁÇ∫‰ª£ÂÉπÔºåÂ∞éËá¥‰ΩøÁî®ËÄÖÁöÑÂèÉËàáÂ∫¶Èôç‰Ωé„ÄÇÁèæÊúâÁöÑÊé®Ëñ¶ÊºîÁÆóÊ≥ïÊúÉÂòóË©¶ÈÄèÈÅéÂ∞áÈÄôÂÖ©ÂÄãÊåáÊ®ôÔºàÁõ∏ÈóúÊÄßÂíåÂ§öÊ®£ÊÄßÔºâÁµêÂêàÁÇ∫‰∏ÄÂÄãÁõÆÊ®ôÔºåÁÑ∂ÂæåÂ∞ãÊâæÊúÄ‰Ω≥ÂåñÁµêÂêàÁõÆÊ®ôÁöÑÂª∫Ë≠∞Ôºå‰ª•Êé®Ëñ¶Áµ¶ÂÆöÁöÑÈ†ÖÁõÆÊï∏Èáè‰æÜËß£Ê±∫Ê≠§ÂèñÊç®„ÄÇÁÑ∂ËÄåÔºåÂÇ≥Áµ±ÊñπÊ≥ï‰∏¶Êú™ËÄÉÈáè‰ΩøÁî®ËÄÖËàáÊé®Ëñ¶È†ÖÁõÆÁöÑ‰∫íÂãï„ÄÇ
  
Âú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞á‰ΩøÁî®ËÄÖÁΩÆÊñºÊ†∏ÂøÉÈöéÊÆµÔºå‰∏¶Âª∫Á´ãÂú®Áõ∏ÈóúÊÄß„ÄÅÂ§öÊ®£ÊÄßÂíå‰ΩøÁî®ËÄÖË°åÁÇ∫‰πãÈñìÁöÑ‰∫§‰∫í‰ΩúÁî®‰∏ä„ÄÇËàáÁõÆÊ®ôÂÉÖÁÇ∫ÊúÄÂ§ßÂåñÂèÉËàáÂ∫¶ÁöÑÊáâÁî®Á®ãÂºèÁõ∏ÂèçÔºåÊàëÂÄëÂ∞àÊ≥®ÊñºÊó®Âú®ÊúÄÂ§ßÂåñ‰ΩøÁî®ËÄÖÊâÄÈÅ≠ÈÅáÁöÑÁ∏ΩÁü•Ë≠òÈáèÁöÑÂ†¥ÊôØ„ÄÇÊàëÂÄëÂ∞áÂ§öÊ®£ÊÄßÁî®‰Ωú‰ΩøÁî®ËÄÖËàáÁ≥ªÁµ±‰∫íÂãïÊôÇÊâÄÁç≤ÂæóÁü•Ë≠òÈáèÁöÑÊõø‰ª£ÊåáÊ®ôÔºå‰∏¶‰∏îÊàëÂÄëÂ∞ãÊ±ÇÊúÄÂ§ßÂåñÂ§öÊ®£ÊÄß„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊ©üÁéáÊÄßÁöÑ‰ΩøÁî®ËÄÖË°åÁÇ∫Ê®°ÂûãÔºåÂú®ÂÖ∂‰∏≠‰ΩøÁî®ËÄÖÊúÉÊåÅÁ∫åËàáÊé®Ëñ¶Á≥ªÁµ±‰∫íÂãïÔºåÂè™Ë¶Å‰ªñÂÄëÊî∂Âà∞Áõ∏ÈóúÁöÑÂª∫Ë≠∞Ôºå‰ΩÜÂ¶ÇÊûúÊé®Ëñ¶È†ÖÁõÆÁöÑÁõ∏ÈóúÊÄß‰∏ãÈôçÔºå‰ªñÂÄëÂèØËÉΩÊúÉÂÅúÊ≠¢‰∫íÂãï„ÄÇÂõ†Ê≠§ÔºåÂ∞çÊñºÊé®Ëñ¶Á≥ªÁµ±‰æÜË™™ÔºåËã•Ë¶ÅÈÅîÊàêÈ´òÂ§öÊ®£ÊÄßÊåáÊ®ôÔºåÂÆÉÈúÄË¶ÅÁî¢ÁîüÊó¢Áõ∏ÈóúÂèàÂ§öÊ®£ÂåñÁöÑÂª∫Ë≠∞„ÄÇ
  
ÊúÄÂæåÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÊé®Ëñ¶Á≠ñÁï•ÔºåÈÄèÈÅé‰∏ÄÂÄãÈÄ£Êé•ÂáΩÊï∏Â∞áÁõ∏ÈóúÊÄßÂíåÂ§öÊ®£ÊÄßÁµêÂêàËµ∑‰æÜ„ÄÇÊàëÂÄëÂ∞çÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂú®Â§öÂÄãË≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÂª£Ê≥õÁöÑË©ï‰º∞Ôºå‰∏¶‰∏îÊàëÂÄëÈ°ØÁ§∫ÊàëÂÄëÁöÑÁ≠ñÁï•ÂÑ™ÊñºÊï∏ÂÄãÊúÄÂÖàÈÄ≤ÁöÑÁ´∂Áà≠ËÄÖ„ÄÇÊàëÂÄëÁöÑÂØ¶‰ΩúÂÖ¨ÈñãÊñº https://github.com/EricaCoppolillo/EXPLORE„ÄÇ

##### **'Finance Wizard' at the FinLLM Challenge Task: Financial Text Summarization**
2408.03762v1 by Meisin Lee, Soon Lay-Ki

This paper presents our participation under the team name `Finance Wizard' in
the FinNLP-AgentScen 2024 shared task #2: Financial Text Summarization. It
documents our pipeline approach of fine-tuning a foundation model into a
task-specific model for Financial Text Summarization. It involves (1) adapting
Llama3 8B, a foundation model, to the Finance domain via continued
pre-training, (2) multi-task instruction-tuning to further equip the model with
more finance-related capabilities, (3) finally fine-tuning the model into a
task-specific `expert'. Our model, FinLlama3\_sum, yielded commendable results,
securing the third position in its category with a ROUGE-1 score of 0.521.

ÊëòË¶ÅÔºöÊú¨Êñá‰ªãÁ¥πÊàëÂÄëÂú® FinNLP-AgentScen 2024 ÂÖ±‰∫´‰ªªÂãô #2ÔºöË≤°ÂãôÊñáÊú¨ÊëòË¶Å‰∏≠‰ª•„ÄåFinance Wizard„ÄçÁÇ∫ÈöäÂêçÂèÉËàáÁöÑÈÅéÁ®ã„ÄÇÂÆÉË®òÈåÑ‰∫ÜÊàëÂÄëÂ∞áÂü∫Á§éÊ®°ÂûãÂæÆË™øÁÇ∫Ë≤°ÂãôÊñáÊú¨ÊëòË¶Å‰ªªÂãôÁâπÂÆöÊ®°ÂûãÁöÑÁÆ°ÈÅìÊñπÊ≥ï„ÄÇÂÆÉÂåÖÊã¨ (1) ÈÄèÈÅéÊåÅÁ∫åÈ†êË®ìÁ∑¥Â∞áÂü∫Á§éÊ®°Âûã Llama3 8B Ë™øÊï¥ÁÇ∫Ë≤°ÂãôÈ†òÂüüÔºå(2) Â§ö‰ªªÂãôÊåá‰ª§ÂæÆË™øÔºåÈÄ≤‰∏ÄÊ≠•ÁÇ∫Ê®°ÂûãË£ùÂÇôÊõ¥Â§öËàáË≤°ÂãôÁõ∏ÈóúÁöÑËÉΩÂäõÔºå(3) ÊúÄÂæåÂæÆË™øÊ®°ÂûãÊàêÁÇ∫‰ªªÂãôÁâπÂÆöÁöÑ„ÄåÂ∞àÂÆ∂„Äç„ÄÇÊàëÂÄëÁöÑÊ®°Âûã FinLlama3_sum Áç≤Âæó‰∫Ü‰ª§‰∫∫Á®±ÈÅìÁöÑÁµêÊûúÔºåÂú® ROUGE-1 ÂàÜÊï∏ÁÇ∫ 0.521 ÁöÑÈ°ûÂà•‰∏≠Áç≤Âæó‰∫ÜÁ¨¨‰∏âÂêç„ÄÇ

##### **Online Model-based Anomaly Detection in Multivariate Time Series: Taxonomy, Survey, Research Challenges and Future Directions**
2408.03747v1 by Lucas Correia, Jan-Christoph Goos, Philipp Klein, Thomas B√§ck, Anna V. Kononova

Time-series anomaly detection plays an important role in engineering
processes, like development, manufacturing and other operations involving
dynamic systems. These processes can greatly benefit from advances in the
field, as state-of-the-art approaches may aid in cases involving, for example,
highly dimensional data. To provide the reader with understanding of the
terminology, this survey introduces a novel taxonomy where a distinction
between online and offline, and training and inference is made. Additionally,
it presents the most popular data sets and evaluation metrics used in the
literature, as well as a detailed analysis. Furthermore, this survey provides
an extensive overview of the state-of-the-art model-based online semi- and
unsupervised anomaly detection approaches for multivariate time-series data,
categorising them into different model families and other properties. The
biggest research challenge revolves around benchmarking, as currently there is
no reliable way to compare different approaches against one another. This
problem is two-fold: on the one hand, public data sets suffers from at least
one fundamental flaw, while on the other hand, there is a lack of intuitive and
representative evaluation metrics in the field. Moreover, the way most
publications choose a detection threshold disregards real-world conditions,
which hinders the application in the real world. To allow for tangible advances
in the field, these issues must be addressed in future work.

ÊëòË¶ÅÔºöÊôÇÈñìÂ∫èÂàóÁï∞Â∏∏ÂÅµÊ∏¨Âú®Â∑•Á®ãË£ΩÁ®ã‰∏≠ÊâÆÊºîËëóÈáçË¶ÅÁöÑËßíËâ≤Ôºå‰æãÂ¶ÇÈñãÁôº„ÄÅË£ΩÈÄ†ÂíåÊ∂âÂèäÂãïÊÖãÁ≥ªÁµ±ÁöÑÂÖ∂‰ªñ‰ΩúÊ•≠„ÄÇÈÄô‰∫õË£ΩÁ®ãÂèØ‰ª•ÂæûË©≤È†òÂüüÁöÑÈÄ≤Â±ï‰∏≠Áç≤ÁõäËâØÂ§öÔºåÂõ†ÁÇ∫ÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÂèØ‰ª•ÂçîÂä©ËôïÁêÜ‰æãÂ¶ÇÈ´òÁ∂≠Â∫¶Ë≥áÊñôÁöÑÊ°à‰æã„ÄÇÁÇ∫‰∫ÜËÆìËÆÄËÄÖ‰∫ÜËß£Ë°ìË™ûÔºåÊú¨Ë™øÊü•ÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞ÁöÑÂàÜÈ°ûÊ≥ïÔºåÂÖ∂‰∏≠ÂçÄÂàÜ‰∫ÜÁ∑ö‰∏äÂíåÈõ¢Á∑öÔºå‰ª•ÂèäË®ìÁ∑¥ÂíåÊé®Ë´ñ„ÄÇÊ≠§Â§ñÔºåÂÆÉÈÇÑ‰ªãÁ¥π‰∫ÜÊñáÁçª‰∏≠‰ΩøÁî®ÊúÄÂª£Ê≥õÁöÑË≥áÊñôÈõÜÂíåË©ï‰º∞ÊåáÊ®ôÔºå‰ª•ÂèäË©≥Á¥∞ÁöÑÂàÜÊûê„ÄÇÊ≠§Â§ñÔºåÊú¨Ë™øÊü•Êèê‰æõ‰∫ÜÂü∫ÊñºÊ®°ÂûãÁöÑÁ∑ö‰∏äÂçäÁõ£Áù£ÂíåÈùûÁõ£Áù£Áï∞Â∏∏ÂÅµÊ∏¨ÊñπÊ≥ïÁöÑÊúÄÊñ∞ÊäÄË°ìÁöÑÂª£Ê≥õÊ¶ÇËø∞Ôºå‰∏¶Â∞áÂÖ∂ÂàÜÈ°ûÁÇ∫‰∏çÂêåÁöÑÊ®°ÂûãÂÆ∂ÊóèÂíåÂÖ∂‰ªñÂ±¨ÊÄß„ÄÇÊúÄÂ§ßÁöÑÁ†îÁ©∂ÊåëÊà∞ÂúçÁπûËëóÂü∫Ê∫ñÊ∏¨Ë©¶ÔºåÂõ†ÁÇ∫ÁõÆÂâçÊ≤íÊúâÂèØÈù†ÁöÑÊñπÊ≥ïÂèØ‰ª•Â∞á‰∏çÂêåÁöÑÊñπÊ≥ïÁõ∏‰∫íÊØîËºÉ„ÄÇÈÄôÂÄãÂïèÈ°åÊúâÂÖ©ÂÄãÊñπÈù¢Ôºö‰∏ÄÊñπÈù¢ÔºåÂÖ¨ÈñãË≥áÊñôÈõÜËá≥Â∞ëÂ≠òÂú®‰∏ÄÂÄãÂü∫Êú¨Áº∫Èô∑ÔºåÂè¶‰∏ÄÊñπÈù¢ÔºåË©≤È†òÂüüÁº∫‰πèÁõ¥ËßÄ‰∏îÂÖ∑‰ª£Ë°®ÊÄßÁöÑË©ï‰º∞ÊåáÊ®ô„ÄÇÊ≠§Â§ñÔºåÂ§ßÂ§öÊï∏Âá∫ÁâàÁâ©ÈÅ∏ÊìáÂÅµÊ∏¨ÈñæÂÄºÁöÑÊñπÂºè‰∏çËÄÉÊÖÆÁèæÂØ¶‰∏ñÁïåÁöÑÊ¢ù‰ª∂ÔºåÈÄôÈòªÁ§ô‰∫ÜÂú®ÁèæÂØ¶‰∏ñÁïå‰∏≠ÁöÑÊáâÁî®„ÄÇÁÇ∫‰∫ÜËÆìË©≤È†òÂüüÊúâÂÖ∑È´îÁöÑÈÄ≤Â±ïÔºåÈÄô‰∫õÂïèÈ°åÂøÖÈ†àÂú®Êú™‰æÜÁöÑÁ†îÁ©∂‰∏≠Âä†‰ª•Ëß£Ê±∫„ÄÇ

##### **Flexible Bayesian Last Layer Models Using Implicit Priors and Diffusion Posterior Sampling**
2408.03746v1 by Jian Xu, Zhiqi Lin, Shigui Li, Min Chen, Junmei Yang, Delu Zeng, John Paisley

Bayesian Last Layer (BLL) models focus solely on uncertainty in the output
layer of neural networks, demonstrating comparable performance to more complex
Bayesian models. However, the use of Gaussian priors for last layer weights in
Bayesian Last Layer (BLL) models limits their expressive capacity when faced
with non-Gaussian, outlier-rich, or high-dimensional datasets. To address this
shortfall, we introduce a novel approach that combines diffusion techniques and
implicit priors for variational learning of Bayesian last layer weights. This
method leverages implicit distributions for modeling weight priors in BLL,
coupled with diffusion samplers for approximating true posterior predictions,
thereby establishing a comprehensive Bayesian prior and posterior estimation
strategy. By delivering an explicit and computationally efficient variational
lower bound, our method aims to augment the expressive abilities of BLL models,
enhancing model accuracy, calibration, and out-of-distribution detection
proficiency. Through detailed exploration and experimental validation, We
showcase the method's potential for improving predictive accuracy and
uncertainty quantification while ensuring computational efficiency.

ÊëòË¶ÅÔºöË≤ùÊ∞èÊúÄÂæå‰∏ÄÂ±§ (BLL) Ê®°ÂûãÂ∞àÊ≥®ÊñºÁ•ûÁ∂ìÁ∂≤Ë∑ØËº∏Âá∫Â±§ÁöÑ‰∏çÁ¢∫ÂÆöÊÄßÔºåÂ±ïÁèæÂá∫ËàáÊõ¥Ë§áÈõúÁöÑË≤ùÊ∞èÊ®°ÂûãÁõ∏ËøëÁöÑÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÂú®Ë≤ùÊ∞èÊúÄÂæå‰∏ÄÂ±§ (BLL) Ê®°Âûã‰∏≠Ôºå‰ΩøÁî®È´òÊñØÂÖàÈ©ó‰æÜ‰ΩúÁÇ∫ÊúÄÂæå‰∏ÄÂ±§Ê¨äÈáçÔºåÊúÉÂú®Èù¢Â∞çÈùûÈ´òÊñØ„ÄÅÁï∞Â∏∏ÂÄºË±êÂØåÊàñÈ´òÁ∂≠Â∫¶Ë≥áÊñôÈõÜÊôÇÔºåÈôêÂà∂ÂÖ∂Ë°®ÈÅîËÉΩÂäõ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÁº∫ÈªûÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÁµêÂêàÊì¥Êï£ÊäÄË°ìÂíåÈö±ÂºèÂÖàÈ©óÔºåÁî®ÊñºË≤ùÊ∞èÊúÄÂæå‰∏ÄÂ±§Ê¨äÈáçÁöÑËÆäÁï∞Â≠∏Áøí„ÄÇÊ≠§ÊñπÊ≥ïÂà©Áî®Èö±ÂºèÂàÜ‰Ωà‰æÜÂ∞ç BLL ‰∏≠ÁöÑÊ¨äÈáçÂÖàÈ©óÈÄ≤Ë°åÂª∫Ê®°Ôºå‰∏¶ÁµêÂêàÊì¥Êï£Êé°Ê®£Âô®‰æÜÈÄºËøëÁúüÂØ¶ÂæåÈ©óÈ†êÊ∏¨ÔºåÂæûËÄåÂª∫Á´ã‰∏ÄÂÄãÂÖ®Èù¢ÁöÑË≤ùÊ∞èÂÖàÈ©óÂíåÂæåÈ©ó‰º∞Ë®àÁ≠ñÁï•„ÄÇÈÄèÈÅéÊèê‰æõ‰∏ÄÂÄãÊòéÁ¢∫‰∏îË®àÁÆóÊïàÁéáÈ´òÁöÑËÆäÁï∞‰∏ãÁïåÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÊó®Âú®Êì¥ÂÖÖ BLL Ê®°ÂûãÁöÑË°®ÈÅîËÉΩÂäõÔºåÊèêÂçáÊ®°ÂûãÊ∫ñÁ¢∫Â∫¶„ÄÅÊ†°Ê∫ñÂíåÁï∞Â∏∏ÂÅµÊ∏¨ËÉΩÂäõ„ÄÇÈÄèÈÅéË©≥Á¥∞ÁöÑÊé¢Ë®éÂíåÂØ¶È©óÈ©óË≠âÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊ≠§ÊñπÊ≥ïÂú®ÊèêÂçáÈ†êÊ∏¨Ê∫ñÁ¢∫Â∫¶Âíå‰∏çÁ¢∫ÂÆöÊÄßÈáèÂåñÁöÑÊΩõÂäõÔºåÂêåÊôÇÁ¢∫‰øùË®àÁÆóÊïàÁéá„ÄÇ

##### **Intuitionistic Fuzzy Cognitive Maps for Interpretable Image Classification**
2408.03745v1 by Georgia Sovatzidi, Michael D. Vasilakakis, Dimitris K. Iakovidis

The interpretability of machine learning models is critical, as users may be
reluctant to rely on their inferences. Intuitionistic FCMs (iFCMs) have been
proposed as an extension of FCMs offering a natural mechanism to assess the
quality of their output through the estimation of hesitancy, a concept
resembling to human hesitation in decision making. To address the challenge of
interpretable image classification, this paper introduces a novel framework,
named Interpretable Intuitionistic FCM (I2FCM) which is domain-independent,
simple to implement, and can be applied on Convolutional Neural Network (CNN)
models, rendering them interpretable. To the best of our knowledge this is the
first time iFCMs are applied for image classification. Further novel
contributions include: a feature extraction process focusing on the most
informative image regions; a learning algorithm for data-driven determination
of the intuitionistic fuzzy interconnections of the iFCM; an inherently
interpretable classification approach based on image contents. In the context
of image classification, hesitancy is considered as a degree of inconfidence
with which an image is categorized to a class. The constructed iFCM model
distinguishes the most representative image semantics and analyses them
utilizing cause-and-effect relations. The effectiveness of the introduced
framework is evaluated on publicly available datasets, and the experimental
results confirm that it can provide enhanced classification performance, while
providing interpretable inferences.

ÊëòË¶ÅÔºöÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãÁöÑÂèØËß£ÈáãÊÄßËá≥ÈóúÈáçË¶ÅÔºåÂõ†ÁÇ∫‰ΩøÁî®ËÄÖÂèØËÉΩ‰∏çÈ°òÊÑè‰æùË≥¥ÂÖ∂Êé®Ë´ñ„ÄÇÁõ¥Ë¶∫‰∏ªÁæ©Ê®°Á≥äËÅöÈ°ûÔºàiFCMÔºâÂ∑≤Ë¢´ÊèêÂá∫‰ΩúÁÇ∫ FCM ÁöÑÂª∂‰º∏ÔºåÊèê‰æõ‰∏ÄÁ®ÆËá™ÁÑ∂Ê©üÂà∂ÔºåÈÄöÈÅé‰º∞Ë®àÁå∂Ë±´Á®ãÂ∫¶‰æÜË©ï‰º∞ÂÖ∂Ëº∏Âá∫ÁöÑÂìÅË≥™ÔºåÁå∂Ë±´Á®ãÂ∫¶ÊòØ‰∏ÄÂÄãÈ°û‰ººÊñº‰∫∫È°ûÂú®Ê±∫Á≠ñ‰∏≠Áå∂Ë±´ÁöÑÊ¶ÇÂøµ„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÂèØËß£ÈáãÂΩ±ÂÉèÂàÜÈ°ûÁöÑÊåëÊà∞ÔºåÊú¨Êñá‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÊ°ÜÊû∂ÔºåÁ®±ÁÇ∫ÂèØËß£ÈáãÁõ¥Ë¶∫‰∏ªÁæ©Ê®°Á≥äËÅöÈ°ûÔºàI2FCMÔºâÔºåÂÆÉËàáÈ†òÂüüÁÑ°ÈóúÔºåÊòìÊñºÂØ¶‰ΩúÔºå‰∏¶‰∏îÂèØ‰ª•ÊáâÁî®ÊñºÂç∑Á©çÁ•ûÁ∂ìÁ∂≤Ë∑ØÔºàCNNÔºâÊ®°ÂûãÔºå‰ΩøÂÖ∂ÂèØËß£Èáã„ÄÇÊìöÊàëÂÄëÊâÄÁü•ÔºåÈÄôÊòØ iFCM È¶ñÊ¨°ÊáâÁî®ÊñºÂΩ±ÂÉèÂàÜÈ°û„ÄÇÈÄ≤‰∏ÄÊ≠•ÁöÑÊñ∞Á©éË≤¢ÁçªÂåÖÊã¨ÔºöÂ∞àÊ≥®ÊñºÊúÄÊúâÊÑèÁæ©ÂΩ±ÂÉèÂçÄÂüüÁöÑÁâπÂæµËêÉÂèñÈÅéÁ®ãÔºõÁî®ÊñºË≥áÊñôÈ©ÖÂãïÁöÑ iFCM Áõ¥Ë¶∫Ê®°Á≥ä‰∫íÈÄ£Á¢∫ÂÆöÁöÑÂ≠∏ÁøíÊºîÁÆóÊ≥ïÔºõ‰∏ÄÁ®ÆÂü∫ÊñºÂΩ±ÂÉèÂÖßÂÆπÁöÑÂÖßÂú®ÂèØËß£ÈáãÂàÜÈ°ûÊñπÊ≥ï„ÄÇÂú®ÂΩ±ÂÉèÂàÜÈ°ûÁöÑËÉåÊôØ‰∏ãÔºåÁå∂Ë±´Á®ãÂ∫¶Ë¢´Ë¶ñÁÇ∫Â∞áÂΩ±ÂÉèÂàÜÈ°ûÂà∞È°ûÂà•ÁöÑ‰∏çÁ¢∫ÂÆöÁ®ãÂ∫¶„ÄÇÂª∫ÊßãÁöÑ iFCM Ê®°ÂûãÂçÄÂàÜÊúÄÂÖ∑‰ª£Ë°®ÊÄßÁöÑÂΩ±ÂÉèË™ûÁæ©Ôºå‰∏¶Âà©Áî®Âõ†ÊûúÈóú‰øÇÂ∞çÂÖ∂ÈÄ≤Ë°åÂàÜÊûê„ÄÇÊâÄÊèêÂá∫ÁöÑÊ°ÜÊû∂ÁöÑÊúâÊïàÊÄßÂú®ÂÖ¨ÈñãÂèØÁî®ÁöÑË≥áÊñôÈõÜ‰∏äÂæóÂà∞Ë©ï‰º∞ÔºåÂØ¶È©óÁµêÊûúË≠âÂØ¶ÂÆÉÂèØ‰ª•Êèê‰æõÂ¢ûÂº∑ÁöÑÂàÜÈ°ûÊïàËÉΩÔºåÂêåÊôÇÊèê‰æõÂèØËß£ÈáãÁöÑÊé®Ë´ñ„ÄÇ

##### **Advancing Multimodal Large Language Models with Quantization-Aware Scale Learning for Efficient Adaptation**
2408.03735v1 by Jingjing Xie, Yuxin Zhang, Mingbao Lin, Liujuan Cao, Rongrong Ji

This paper presents the first study to explore the potential of parameter
quantization for multimodal large language models to alleviate the significant
resource constraint encountered during vision-language instruction tuning. We
introduce a Quantization-aware Scale LeArning method based on multimodal
Warmup, termed QSLAW. This method is grounded in two key innovations: (1) The
learning of group-wise scale factors for quantized LLM weights to mitigate the
quantization error arising from activation outliers and achieve more effective
vision-language instruction tuning; (2) The implementation of a multimodal
warmup that progressively integrates linguistic and multimodal training
samples, thereby preventing overfitting of the quantized model to multimodal
data while ensuring stable adaptation of multimodal large language models to
downstream vision-language tasks. Extensive experiments demonstrate that models
quantized by QSLAW perform on par with, or even surpass, their full-precision
counterparts, while facilitating up to 1.4 times reduction in VL tuning time
and GPU consumption. Our code is released at https://github.com/xjjxmu/QSLAW.

ÊëòË¶ÅÔºöÊú¨ÊñáÊèêÂá∫‰∫ÜÁ¨¨‰∏ÄÈ°πÁ†îÁ©∂ÔºåÊé¢ËÆ®ÂèÇÊï∞ÈáèÂåñÂú®Â§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã‰∏≠ÁöÑÊΩúÂäõÔºå‰ª•ÁºìËß£Âú®ËßÜËßâËØ≠Ë®ÄÊåá‰ª§Ë∞ÉÊï¥ÊúüÈó¥ÈÅáÂà∞ÁöÑÈáçÂ§ßËµÑÊ∫êÈôêÂà∂„ÄÇÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏ÄÁßçÂü∫‰∫éÂ§öÊ®°ÊÄÅÈ¢ÑÁÉ≠ÈáèÂåñÊÑüÁü•ÈáèÂåñÂ≠¶‰π†ÊñπÊ≥ïÔºåÁß∞‰∏∫ QSLAW„ÄÇÊ≠§ÊñπÊ≥ïÂü∫‰∫é‰∏§È°πÂÖ≥ÈîÆÂàõÊñ∞Ôºö(1) Â≠¶‰π†ÈáèÂåñ LLM ÊùÉÈáçÁöÑÁªÑÁ∫ßÊØî‰æãÂõ†Â≠êÔºå‰ª•ÂáèËΩªÁî±ÊøÄÊ¥ªÂÄºÂºÇÂ∏∏ÂÄºÂºïËµ∑ÁöÑÈáèÂåñËØØÂ∑ÆÔºåÂπ∂ÂÆûÁé∞Êõ¥ÊúâÊïàÁöÑËßÜËßâËØ≠Ë®ÄÊåá‰ª§Ë∞ÉÊï¥Ôºõ(2) ÂÆûÊñΩÂ§öÊ®°ÊÄÅÈ¢ÑÁÉ≠ÔºåÈÄêÊ∏êÈõÜÊàêËØ≠Ë®ÄÂíåÂ§öÊ®°ÊÄÅËÆ≠ÁªÉÊ†∑Êú¨Ôºå‰ªéËÄåÈò≤Ê≠¢ÈáèÂåñÊ®°ÂûãËøáÂ∫¶ÊãüÂêàÂ§öÊ®°ÊÄÅÊï∞ÊçÆÔºåÂêåÊó∂Á°Æ‰øùÂ§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁ®≥ÂÆöÈÄÇÂ∫î‰∏ãÊ∏∏ËßÜËßâËØ≠Ë®Ä‰ªªÂä°„ÄÇÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåÁî± QSLAW ÈáèÂåñÁöÑÊ®°ÂûãÊÄßËÉΩ‰∏éÂÆÉ‰ª¨ÁöÑÂÆåÂÖ®Á≤æÂ∫¶ÂØπÂ∫îÊ®°ÂûãÁõ∏ÂΩìÔºåÁîöËá≥Ë∂ÖËøáÂÆÉ‰ª¨ÔºåÂêåÊó∂Â∞Ü VL Ë∞ÉÊï¥Êó∂Èó¥Âíå GPU Ê∂àËÄóÂáèÂ∞ë‰∫Ü 1.4 ÂÄç„ÄÇÊàë‰ª¨ÁöÑ‰ª£Á†ÅÂ∑≤ÂèëÂ∏ÉÂú® https://github.com/xjjxmu/QSLAW„ÄÇ

##### **Question Rephrasing for Quantifying Uncertainty in Large Language Models: Applications in Molecular Chemistry Tasks**
2408.03732v1 by Zizhang Chen, Pengyu Hong, Sandeep Madireddy

Uncertainty quantification enables users to assess the reliability of
responses generated by large language models (LLMs). We present a novel
Question Rephrasing technique to evaluate the input uncertainty of LLMs, which
refers to the uncertainty arising from equivalent variations of the inputs
provided to LLMs. This technique is integrated with sampling methods that
measure the output uncertainty of LLMs, thereby offering a more comprehensive
uncertainty assessment. We validated our approach on property prediction and
reaction prediction for molecular chemistry tasks.

ÊëòË¶ÅÔºö‰∏çÁ¢∫ÂÆöÈáèÂåñ‰ΩøÁî®Êà∂ËÉΩÂ§†Ë©ï‰º∞Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊâÄÁî¢ÁîüÁöÑÂõûÊáâÂèØÈù†ÊÄß„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÂïèÈ°åÈáçËø∞ÊäÄË°ìÔºåÁî®ÊñºË©ï‰º∞ LLM ÁöÑËº∏ÂÖ•‰∏çÁ¢∫ÂÆöÊÄßÔºåÈÄôÊåáÁöÑÊòØÊèê‰æõÁµ¶ LLM ÁöÑËº∏ÂÖ•Á≠âÊïàËÆäÂåñÊâÄÁî¢ÁîüÁöÑ‰∏çÁ¢∫ÂÆöÊÄß„ÄÇÊ≠§ÊäÄË°ìËàáÁî®ÊñºÊ∏¨Èáè LLM Ëº∏Âá∫‰∏çÁ¢∫ÂÆöÊÄßÁöÑÊäΩÊ®£ÊñπÊ≥ïÊï¥ÂêàÂú®‰∏ÄËµ∑ÔºåÂæûËÄåÊèê‰æõÊõ¥ÂÖ®Èù¢ÁöÑ‰∏çÁ¢∫ÂÆöÊÄßË©ï‰º∞„ÄÇÊàëÂÄëÈ©óË≠â‰∫ÜÊàëÂÄëÂú®ÂàÜÂ≠êÂåñÂ≠∏‰ªªÂãô‰∏≠Â∞çÊÄßË≥™È†êÊ∏¨ÂíåÂèçÊáâÈ†êÊ∏¨ÁöÑÊñπÊ≥ï„ÄÇ

##### **Local Topology Measures of Contextual Language Model Latent Spaces With Applications to Dialogue Term Extraction**
2408.03706v1 by Benjamin Matthias Ruppik, Michael Heck, Carel van Niekerk, Renato Vukovic, Hsien-chin Lin, Shutong Feng, Marcus Zibrowius, Milica Ga≈°iƒá

A common approach for sequence tagging tasks based on contextual word
representations is to train a machine learning classifier directly on these
embedding vectors. This approach has two shortcomings. First, such methods
consider single input sequences in isolation and are unable to put an
individual embedding vector in relation to vectors outside the current local
context of use. Second, the high performance of these models relies on
fine-tuning the embedding model in conjunction with the classifier, which may
not always be feasible due to the size or inaccessibility of the underlying
feature-generation model. It is thus desirable, given a collection of embedding
vectors of a corpus, i.e., a datastore, to find features of each vector that
describe its relation to other, similar vectors in the datastore. With this in
mind, we introduce complexity measures of the local topology of the latent
space of a contextual language model with respect to a given datastore. The
effectiveness of our features is demonstrated through their application to
dialogue term extraction. Our work continues a line of research that explores
the manifold hypothesis for word embeddings, demonstrating that local structure
in the space carved out by word embeddings can be exploited to infer semantic
properties.

ÊëòË¶ÅÔºöÂü∫Êñº‰∏ä‰∏ãÊñáË©ûÂΩôË°®ÂæµÁöÑÂ∫èÂàóÊ®ôË®ª‰ªªÂãôÔºåÂ∏∏Ë¶ãÊñπÊ≥ïÊòØÁõ¥Êé•Âú®ÈÄô‰∫õÂµåÂÖ•ÂêëÈáè‰∏äË®ìÁ∑¥Ê©üÂô®Â≠∏ÁøíÂàÜÈ°ûÂô®„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÊúâÂÖ©ÂÄãÁº∫Èªû„ÄÇÈ¶ñÂÖàÔºåÊ≠§È°ûÊñπÊ≥ïÂ≠§Á´ãÂú∞ËÄÉÊÖÆÂñÆ‰∏ÄËº∏ÂÖ•Â∫èÂàóÔºåÁÑ°Ê≥ïÂ∞áÂÄãÂà•ÂµåÂÖ•ÂêëÈáèËàáÁï∂ÂâçÂ±ÄÈÉ®‰ΩøÁî®ÊÉÖÂ¢ÉÂ§ñÁöÑÂêëÈáèÂª∫Á´ãÈóú‰øÇ„ÄÇÂÖ∂Ê¨°ÔºåÈÄô‰∫õÊ®°ÂûãÁöÑÈ´òÊïàËÉΩ‰ª∞Ë≥¥ÊñºÂ∞áÂµåÂÖ•Ê®°ÂûãËàáÂàÜÈ°ûÂô®ÁµêÂêàÈÄ≤Ë°åÂæÆË™øÔºå‰ΩÜÁî±ÊñºÂ∫ïÂ±§ÁâπÂæµÁîüÊàêÊ®°ÂûãÁöÑË¶èÊ®°ÊàñÈõ£‰ª•ÂèñÂæóÔºåÈÄô‰∏¶‰∏çÁ∏ΩÊòØÂèØË°å„ÄÇÂõ†Ê≠§ÔºåÂÅáË®≠Áµ¶ÂÆöË™ûÊñôÂ∫´ÁöÑÂµåÂÖ•ÂêëÈáèÈõÜÂêàÔºåÂç≥Ë≥áÊñôÂÑ≤Â≠òÂ∫´ÔºåÁêÜÊÉ≥ÁöÑÂÅöÊ≥ïÊòØÊâæÂá∫ÊØèÂÄãÂêëÈáèÁöÑÁâπÂæµÔºåÊèèËø∞ÂÖ∂ËàáË≥áÊñôÂÑ≤Â≠òÂ∫´‰∏≠ÂÖ∂‰ªñÈ°û‰ººÂêëÈáèÁöÑÈóú‰øÇ„ÄÇÂü∫ÊñºÈÄôÂÄãÊÉ≥Ê≥ïÔºåÊàëÂÄëÈáùÂ∞ç‰∏ä‰∏ãÊñáË™ûË®ÄÊ®°ÂûãÁöÑÊΩõÂú®Á©∫ÈñìÂ±ÄÈÉ®ÊãìÊí≤ÁµêÊßãÔºåÁõ∏Â∞çÊñºÁµ¶ÂÆöË≥áÊñôÂÑ≤Â≠òÂ∫´ÔºåÂºïÂÖ•‰∫ÜË§áÈõúÊÄßÊ∏¨Èáè„ÄÇÊàëÂÄëÁâπÂæµÁöÑÊúâÊïàÊÄßÈÄèÈÅéÊáâÁî®ÊñºÂ∞çË©±Ë°ìË™ûËêÉÂèñ‰æÜË≠âÊòé„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂Âª∂Á∫å‰∫Ü‰∏ÄÁ≥ªÂàóÊé¢Ë®éË©ûÂΩôÂµåÂÖ•ÊµÅÂΩ¢ÂÅáË™™ÁöÑÊé¢Á©∂ÔºåË≠âÊòéË©ûÂΩôÂµåÂÖ•ÊâÄÊßãÊàêÁöÑÁ©∫Èñì‰∏≠ÁöÑÂ±ÄÈÉ®ÁµêÊßãÂèØÁî®ÊñºÊé®Ë´ñË™ûÁæ©Â±¨ÊÄß„ÄÇ

##### **A Blockchain-based Reliable Federated Meta-learning for Metaverse: A Dual Game Framework**
2408.03694v1 by Emna Baccour, Aiman Erbad, Amr Mohamed, Mounir Hamdi, Mohsen Guizani

The metaverse, envisioned as the next digital frontier for avatar-based
virtual interaction, involves high-performance models. In this dynamic
environment, users' tasks frequently shift, requiring fast model
personalization despite limited data. This evolution consumes extensive
resources and requires vast data volumes. To address this, meta-learning
emerges as an invaluable tool for metaverse users, with federated meta-learning
(FML), offering even more tailored solutions owing to its adaptive
capabilities. However, the metaverse is characterized by users heterogeneity
with diverse data structures, varied tasks, and uneven sample sizes,
potentially undermining global training outcomes due to statistical difference.
Given this, an urgent need arises for smart coalition formation that accounts
for these disparities. This paper introduces a dual game-theoretic framework
for metaverse services involving meta-learners as workers to manage FML. A
blockchain-based cooperative coalition formation game is crafted, grounded on a
reputation metric, user similarity, and incentives. We also introduce a novel
reputation system based on users' historical contributions and potential
contributions to present tasks, leveraging correlations between past and new
tasks. Finally, a Stackelberg game-based incentive mechanism is presented to
attract reliable workers to participate in meta-learning, minimizing users'
energy costs, increasing payoffs, boosting FML efficacy, and improving
metaverse utility. Results show that our dual game framework outperforms
best-effort, random, and non-uniform clustering schemes - improving training
performance by up to 10%, cutting completion times by as much as 30%, enhancing
metaverse utility by more than 25%, and offering up to 5% boost in training
efficiency over non-blockchain systems, effectively countering misbehaving
users.

ÊëòË¶ÅÔºöÂÖÉÂÆáÂÆôË¢´ËÆæÊÉ≥‰∏∫Âü∫‰∫éÂåñË∫´ÁöÑËôöÊãü‰∫§‰∫íÁöÑ‰∏ã‰∏Ä‰∏™Êï∞Â≠óÂâçÊ≤øÔºåÊ∂âÂèäÈ´òÊÄßËÉΩÊ®°Âûã„ÄÇÂú®Ëøô‰∏™Âä®ÊÄÅÁéØÂ¢É‰∏≠ÔºåÁî®Êà∑ÁöÑ‰ªªÂä°ÁªèÂ∏∏ÂèëÁîüÂèòÂåñÔºåÈúÄË¶ÅÂø´ÈÄüÊ®°Âûã‰∏™ÊÄßÂåñÔºåÂ∞ΩÁÆ°Êï∞ÊçÆÊúâÈôê„ÄÇËøôÁßçÊºîÂèòÊ∂àËÄó‰∫ÜÂ§ßÈáèËµÑÊ∫êÔºåÈúÄË¶ÅÂ§ßÈáèÊï∞ÊçÆ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÂÖÉÂ≠¶‰π†‰Ωú‰∏∫ÂÖÉÂÆáÂÆôÁî®Êà∑ÁöÑÂÆùË¥µÂ∑•ÂÖ∑Âá∫Áé∞ÔºåÂÖ∂‰∏≠ËÅîÈÇ¶ÂÖÉÂ≠¶‰π† (FML) Áî±‰∫éÂÖ∂Ëá™ÈÄÇÂ∫îËÉΩÂäõËÄåÊèê‰æõ‰∫ÜÊõ¥Â§öÂÆöÂà∂ÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇÁÑ∂ËÄåÔºåÂÖÉÂÆáÂÆôÁöÑÁâπÁÇπÊòØÁî®Êà∑ÂºÇÊûÑÊÄßÔºåÊï∞ÊçÆÁªìÊûÑÂ§öÊ†∑Ôºå‰ªªÂä°ÂêÑÂºÇÔºåÊ†∑Êú¨Èáè‰∏çÂùáÔºåËøôÂèØËÉΩ‰ºöÂõ†ÁªüËÆ°Â∑ÆÂºÇËÄåÁ†¥ÂùèÂÖ®Â±ÄËÆ≠ÁªÉÁªìÊûú„ÄÇÈâ¥‰∫éÊ≠§ÔºåËø´ÂàáÈúÄË¶ÅÂª∫Á´ãËÄÉËôëËøô‰∫õÂ∑ÆÂºÇÁöÑÊô∫ËÉΩËÅîÁõü„ÄÇÊú¨Êñá‰ªãÁªç‰∫Ü‰∏Ä‰∏™ÂèåÈáçÂçöÂºàËÆ∫Ê°ÜÊû∂ÔºåÁî®‰∫éÂÖÉÂÆáÂÆôÊúçÂä°ÔºåÂÖ∂‰∏≠Ê∂âÂèäÂÖÉÂ≠¶‰π†ËÄÖ‰Ωú‰∏∫Â∑•‰∫∫Êù•ÁÆ°ÁêÜ FML„ÄÇÂü∫‰∫éÂ£∞Ë™âÊåáÊ†á„ÄÅÁî®Êà∑Áõ∏‰ººÊÄßÂíåÊøÄÂä±Êé™ÊñΩÔºåÊûÑÂª∫‰∫Ü‰∏Ä‰∏™Âü∫‰∫éÂå∫ÂùóÈìæÁöÑÂêà‰ΩúËÅîÁõüÂΩ¢ÊàêÂçöÂºà„ÄÇÊàë‰ª¨ËøòÂºïÂÖ•‰∫Ü‰∏Ä‰∏™Âü∫‰∫éÁî®Êà∑ÂéÜÂè≤Ë¥°ÁåÆÂíåÂØπÂΩìÂâç‰ªªÂä°ÁöÑÊΩúÂú®Ë¥°ÁåÆÁöÑÊñ∞Â£∞Ë™âÁ≥ªÁªüÔºåÂà©Áî®ËøáÂéªÂíåÊñ∞‰ªªÂä°‰πãÈó¥ÁöÑÁõ∏ÂÖ≥ÊÄß„ÄÇÊúÄÂêéÔºåÊèêÂá∫‰∫Ü‰∏Ä‰∏™Âü∫‰∫é Stackelberg ÂçöÂºàÁöÑÊøÄÂä±Êú∫Âà∂Ôºå‰ª•Âê∏ÂºïÂèØÈù†ÁöÑÂ∑•‰∫∫ÂèÇ‰∏éÂÖÉÂ≠¶‰π†ÔºåÊúÄÂ§ßÈôêÂ∫¶Âú∞Èôç‰ΩéÁî®Êà∑ÁöÑËÉΩÊ∫êÊàêÊú¨ÔºåÂ¢ûÂä†Êî∂ÁõäÔºåÊèêÈ´ò FML ÊïàËÉΩÔºåÂπ∂ÊèêÈ´òÂÖÉÂÆáÂÆôÊïàÁî®„ÄÇÁªìÊûúË°®ÊòéÔºåÊàë‰ª¨ÁöÑÂèåÈáçÂçöÂºàÊ°ÜÊû∂‰ºò‰∫éÂ∞ΩÂäõËÄå‰∏∫„ÄÅÈöèÊú∫ÂíåÈùûÂùáÂåÄËÅöÁ±ªÊñπÊ°à‚Äî‚ÄîÂ∞ÜËÆ≠ÁªÉÊÄßËÉΩÊèêÈ´ò‰∫Ü 10%ÔºåÂ∞ÜÂÆåÊàêÊó∂Èó¥Áº©Áü≠‰∫Ü 30%ÔºåÂ∞ÜÂÖÉÂÆáÂÆôÊïàÁî®ÊèêÈ´ò‰∫Ü 25%ÔºåÂπ∂‰∏îÊØîÈùûÂå∫ÂùóÈìæÁ≥ªÁªüÊèêÈ´ò‰∫Ü 5% ÁöÑËÆ≠ÁªÉÊïàÁéáÔºåÊúâÊïàÂú∞ÂØπÊäó‰∫ÜË°å‰∏∫‰∏çÁ´ØÁöÑÁî®Êà∑„ÄÇ

##### **NACL: A General and Effective KV Cache Eviction Framework for LLMs at Inference Time**
2408.03675v2 by Yilong Chen, Guoxia Wang, Junyuan Shang, Shiyao Cui, Zhenyu Zhang, Tingwen Liu, Shuohuan Wang, Yu Sun, Dianhai Yu, Hua Wu

Large Language Models (LLMs) have ignited an innovative surge of AI
applications, marking a new era of exciting possibilities equipped with
extended context windows. However, hosting these models is cost-prohibitive
mainly due to the extensive memory consumption of KV Cache involving
long-context modeling. Despite several works proposing to evict unnecessary
tokens from the KV Cache, most of them rely on the biased local statistics of
accumulated attention scores and report performance using unconvincing metric
like perplexity on inadequate short-text evaluation. In this paper, we propose
NACL, a general framework for long-context KV cache eviction that achieves more
optimal and efficient eviction in a single operation during the encoding phase.
Due to NACL's efficiency, we combine more accurate attention score statistics
in PROXY TOKENS EVICTION with the diversified random eviction strategy of
RANDOM EVICTION, aiming to alleviate the issue of attention bias and enhance
the robustness in maintaining pivotal tokens for long-context modeling tasks.
Notably, our method significantly improves the performance on short- and
long-text tasks by 80% and 76% respectively, reducing KV Cache by up to 50%
with over 95% performance maintenance. The code is available at
https://github.com/PaddlePaddle/Research/tree/master/NLP/ACL2024-NACL.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Á∂ìÈªûÁáÉ‰∫Ü AI ÊáâÁî®ÂâµÊñ∞ÁöÑÊµ™ÊΩÆÔºåÊ®ôË™åËëó‰∏ÄÂÄãÊñ∞ÁöÑÊôÇ‰ª£ÔºåÈÄôÂÄãÊôÇ‰ª£ÂÖÖÊªø‰∫Ü‰ª§‰∫∫ËààÂ•ÆÁöÑÂèØËÉΩÊÄßÔºå‰∏¶ÈÖçÂÇô‰∫ÜÊì¥Â±ïÁöÑ‰∏ä‰∏ãÊñáÁ™óÂè£„ÄÇÁÑ∂ËÄåÔºåË®óÁÆ°ÈÄô‰∫õÊ®°ÂûãÁöÑÊàêÊú¨ÈÅéÈ´òÔºåÈÄô‰∏ªË¶ÅÊòØÂõ†ÁÇ∫ KV Âø´ÂèñÊ∂âÂèäÈï∑‰∏ä‰∏ãÊñáÂª∫Ê®°ÔºåÊúÉÊ∂àËÄóÂ§ßÈáèË®òÊÜ∂È´î„ÄÇÂÑòÁÆ°ÊúâÂπæÈ†ÖÂ∑•‰ΩúÂª∫Ë≠∞Âæû KV Âø´Âèñ‰∏≠È©ÖÈÄê‰∏çÂøÖË¶ÅÁöÑÊ¨äÊùñÔºå‰ΩÜÂÆÉÂÄëÂ§ßÂ§ö‰æùË≥¥ÊñºÁ¥ØÁ©çÊ≥®ÊÑèÂäõÂàÜÊï∏ÁöÑÂÅèÈ†óÂ±ÄÈÉ®Áµ±Ë®àË≥áÊñôÔºå‰∏¶‰ΩøÁî®‰ª§‰∫∫‰ø°ÊúçÁöÑÊåáÊ®ôÔºà‰æãÂ¶ÇÂú®‰∏çÂÖÖÂàÜÁöÑÁü≠ÊñáÊú¨Ë©ï‰º∞‰∏≠‰ΩøÁî®Âõ∞ÊÉëÂ∫¶Ôºâ‰æÜÂ†±ÂëäÊïàËÉΩ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ NACLÔºåÈÄôÊòØ‰∏ÄÂÄãÁî®ÊñºÈï∑‰∏ä‰∏ãÊñá KV Âø´ÂèñÈ©ÖÈÄêÁöÑÈÄöÁî®Ê°ÜÊû∂ÔºåÂèØ‰ª•Âú®Á∑®Á¢ºÈöéÊÆµÁöÑÂñÆ‰∏ÄÊìç‰Ωú‰∏≠ÂØ¶ÁèæÊõ¥‰Ω≥‰∏îÊõ¥ÊúâÊïàÁöÑÈ©ÖÈÄê„ÄÇÁî±Êñº NACL ÁöÑÊïàÁéáÔºåÊàëÂÄëÂ∞áÊõ¥Ê∫ñÁ¢∫ÁöÑÊ≥®ÊÑèÂäõÂàÜÊï∏Áµ±Ë®àË≥áÊñôËàá RANDOM EVICTION ÁöÑÂ§öÊ®£ÂåñÈö®Ê©üÈ©ÖÈÄêÁ≠ñÁï•ÁµêÂêàÂú® PROXY TOKENS EVICTION ‰∏≠ÔºåÊó®Âú®Ê∏õËºïÊ≥®ÊÑèÂäõÂÅèÂ∑ÆÁöÑÂïèÈ°åÔºå‰∏¶Â¢ûÂº∑Âú®Á∂≠Ë≠∑Èï∑‰∏ä‰∏ãÊñáÂª∫Ê®°‰ªªÂãôÁöÑÈóúÈçµÊ¨äÊùñÊôÇÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂàÜÂà•Â∞áÁü≠ÊñáÊú¨ÂíåÈï∑ÊñáÊú¨‰ªªÂãôÁöÑÊïàËÉΩÈ°ØËëóÊèêÂçá‰∫Ü 80% Âíå 76%ÔºåÂ∞á KV Âø´ÂèñÊ∏õÂ∞ë‰∫Ü 50%ÔºåÂêåÊôÇÊïàËÉΩÁ∂≠ÊåÅÂú® 95% ‰ª•‰∏ä„ÄÇÁ®ãÂºèÁ¢ºÂèØ‰ª•Âú® https://github.com/PaddlePaddle/Research/tree/master/NLP/ACL2024-NACL ‰∏≠ÂèñÂæó„ÄÇ

##### **mucAI at WojoodNER 2024: Arabic Named Entity Recognition with Nearest Neighbor Search**
2408.03652v1 by Ahmed Abdou, Tasneem Mohsen

Named Entity Recognition (NER) is a task in Natural Language Processing (NLP)
that aims to identify and classify entities in text into predefined categories.
However, when applied to Arabic data, NER encounters unique challenges stemming
from the language's rich morphological inflections, absence of capitalization
cues, and spelling variants, where a single word can comprise multiple
morphemes. In this paper, we introduce Arabic KNN-NER, our submission to the
Wojood NER Shared Task 2024 (ArabicNLP 2024). We have participated in the
shared sub-task 1 Flat NER. In this shared sub-task, we tackle fine-grained
flat-entity recognition for Arabic text, where we identify a single main entity
and possibly zero or multiple sub-entities for each word. Arabic KNN-NER
augments the probability distribution of a fine-tuned model with another label
probability distribution derived from performing a KNN search over the cached
training data. Our submission achieved 91% on the test set on the WojoodFine
dataset, placing Arabic KNN-NER on top of the leaderboard for the shared task.

ÊëòË¶ÅÔºöÂëΩÂêçÂØ¶È´îËæ®Ë≠ò (NER) ÊòØËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ‰∏≠ÁöÑ‰∏ÄÈ†Ö‰ªªÂãôÔºåÊó®Âú®Ë≠òÂà•ÂíåÂ∞áÊñáÂ≠ó‰∏≠ÁöÑÂØ¶È´îÂàÜÈ°ûÂà∞È†êÂÖàÂÆöÁæ©ÁöÑÈ°ûÂà•‰∏≠„ÄÇÁÑ∂ËÄåÔºåÁï∂ÊáâÁî®ÊñºÈòøÊãâ‰ºØË™ûË≥áÊñôÊôÇÔºåNER ÊúÉÈÅáÂà∞Áç®ÁâπÁöÑÊåëÊà∞ÔºåÈÄô‰∫õÊåëÊà∞Ê∫êÊñºË©≤Ë™ûË®ÄË±êÂØåÁöÑÂΩ¢ÊÖãËÆäÂåñ„ÄÅÁº∫‰πèÂ§ßÂØ´Á∑öÁ¥¢‰ª•ÂèäÊãºÂØ´ËÆäÈ´îÔºåÂÖ∂‰∏≠‰∏ÄÂÄãÂñÆÂ≠óÂèØËÉΩÂåÖÂê´Â§öÂÄãË™ûÁ¥†„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫ÜÈòøÊãâ‰ºØË™û KNN-NERÔºåÈÄôÊòØÊàëÂÄëÊèê‰∫§Áµ¶ Wojood NER ÂÖ±‰∫´‰ªªÂãô 2024ÔºàArabicNLP 2024ÔºâÁöÑÂÖßÂÆπ„ÄÇÊàëÂÄëÂèÉËàá‰∫ÜÂÖ±‰∫´Â≠ê‰ªªÂãô 1 Âπ≥Èù¢ NER„ÄÇÂú®ÈÄôÂÄãÂÖ±‰∫´Â≠ê‰ªªÂãô‰∏≠ÔºåÊàëÂÄëËôïÁêÜÈòøÊãâ‰ºØË™ûÊñáÂ≠óÁöÑÁ¥∞Á≤íÂ∫¶Âπ≥Èù¢ÂØ¶È´îËæ®Ë≠òÔºåÂÖ∂‰∏≠ÊàëÂÄëË≠òÂà•ÊØèÂÄãÂñÆÂ≠óÁöÑÂñÆ‰∏Ä‰∏ªË¶ÅÂØ¶È´î‰ª•ÂèäÂèØËÉΩÁÇ∫Èõ∂ÊàñÂ§öÂÄãÂ≠êÂØ¶È´î„ÄÇÈòøÊãâ‰ºØË™û KNN-NER ‰ΩøÁî®ÂæûÂø´ÂèñË®ìÁ∑¥Ë≥áÊñô‰∏≠Âü∑Ë°å KNN ÊêúÂ∞ãË°çÁîüÁöÑÂè¶‰∏ÄÂÄãÊ®ôÁ±§Ê©üÁéáÂàÜ‰ΩàÔºå‰æÜÊì¥ÂÖÖÂæÆË™øÊ®°ÂûãÁöÑÊ©üÁéáÂàÜ‰Ωà„ÄÇÊàëÂÄëÂú® WojoodFine Ë≥áÊñôÈõÜÁöÑÊ∏¨Ë©¶ÈõÜ‰∏≠Áç≤Âæó 91%ÔºåËÆìÈòøÊãâ‰ºØË™û KNN-NER ÂêçÂàóÂÖ±‰∫´‰ªªÂãôÊéíË°åÊ¶úÈ¶ñ‰Ωç„ÄÇ

##### **HiQuE: Hierarchical Question Embedding Network for Multimodal Depression Detection**
2408.03648v1 by Juho Jung, Chaewon Kang, Jeewoo Yoon, Seungbae Kim, Jinyoung Han

The utilization of automated depression detection significantly enhances
early intervention for individuals experiencing depression. Despite numerous
proposals on automated depression detection using recorded clinical interview
videos, limited attention has been paid to considering the hierarchical
structure of the interview questions. In clinical interviews for diagnosing
depression, clinicians use a structured questionnaire that includes routine
baseline questions and follow-up questions to assess the interviewee's
condition. This paper introduces HiQuE (Hierarchical Question Embedding
network), a novel depression detection framework that leverages the
hierarchical relationship between primary and follow-up questions in clinical
interviews. HiQuE can effectively capture the importance of each question in
diagnosing depression by learning mutual information across multiple
modalities. We conduct extensive experiments on the widely-used clinical
interview data, DAIC-WOZ, where our model outperforms other state-of-the-art
multimodal depression detection models and emotion recognition models,
showcasing its clinical utility in depression detection.

ÊëòË¶ÅÔºöËá™ÂãïÊÜÇÈ¨±ÁóáÂÅµÊ∏¨ÁöÑÂà©Áî®È°ØËëóÊèêÂçá‰∫ÜÊÜÇÈ¨±ÁóáÊÇ£ËÄÖÁöÑÊó©Êúü‰ªãÂÖ•„ÄÇÂÑòÁÆ°ÊúâË®±Â§ö‰ΩøÁî®ÈåÑË£ΩËá®Â∫äË®™Ë´áÂΩ±ÁâáÁöÑËá™ÂãïÊÜÇÈ¨±ÁóáÂÅµÊ∏¨ÊèêÊ°àÔºå‰ΩÜÂ∞çÊñºËÄÉÈáèË®™Ë´áÂïèÈ°åÁöÑÈöéÂ±§ÁµêÊßãÈÄôÊñπÈù¢ÂçªÈÆÆÂ∞ëÈóúÊ≥®„ÄÇÂú®Áî®ÊñºË®∫Êñ∑ÊÜÇÈ¨±ÁóáÁöÑËá®Â∫äË®™Ë´á‰∏≠ÔºåËá®Â∫äÈÜ´Â∏´ÊúÉ‰ΩøÁî®ÂåÖÂê´‰æãË°åÂü∫Ê∫ñÂïèÈ°åÂíåËøΩËπ§ÂïèÈ°åÁöÑÁµêÊßãÂåñÂïèÂç∑‰æÜË©ï‰º∞ÂèóË®™ËÄÖÁöÑÁãÄÊ≥Å„ÄÇÊú¨Êñá‰ªãÁ¥π‰∫Ü HiQuEÔºàÈöéÂ±§ÂºèÂïèÈ°åÂµåÂÖ•Á∂≤Ë∑ØÔºâÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊÜÇÈ¨±ÁóáÂÅµÊ∏¨Êû∂ÊßãÔºåÂÆÉÂà©Áî®‰∫ÜËá®Â∫äË®™Ë´á‰∏≠‰∏ªË¶ÅÂïèÈ°åÂíåËøΩËπ§ÂïèÈ°å‰πãÈñìÁöÑÈöéÂ±§Èóú‰øÇ„ÄÇHiQuE ËÉΩÂ§†ÈÄèÈÅéÂ≠∏ÁøíÂ§öÁ®ÆÊñπÂºè‰πãÈñìÁöÑ‰∫íÊÉ†Ë≥áË®äÔºåÊúâÊïàÂú∞Êì∑ÂèñÊØèÂÄãÂïèÈ°åÂú®ÊÜÇÈ¨±ÁóáË®∫Êñ∑‰∏≠ÁöÑÈáçË¶ÅÊÄß„ÄÇÊàëÂÄëÂú®Âª£Ê≥õ‰ΩøÁî®ÁöÑËá®Â∫äË®™Ë´áË≥áÊñô DAIC-WOZ ‰∏äÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂÑ™ÊñºÂÖ∂‰ªñÊúÄÂÖàÈÄ≤ÁöÑÂ§öÊ®°ÊÖãÊÜÇÈ¨±ÁóáÂÅµÊ∏¨Ê®°ÂûãÂíåÊÉÖÁ∑íËæ®Ë≠òÊ®°ÂûãÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ÊÜÇÈ¨±ÁóáÂÅµÊ∏¨‰∏≠ÁöÑËá®Â∫äÊïàÁî®„ÄÇ

##### **CARE: A Clue-guided Assistant for CSRs to Read User Manuals**
2408.03633v2 by Weihong Du, Jia Liu, Zujie Wen, Dingnan Jin, Hongru Liang, Wenqiang Lei

It is time-saving to build a reading assistant for customer service
representations (CSRs) when reading user manuals, especially information-rich
ones. Current solutions don't fit the online custom service scenarios well due
to the lack of attention to user questions and possible responses. Hence, we
propose to develop a time-saving and careful reading assistant for CSRs, named
CARE. It can help the CSRs quickly find proper responses from the user manuals
via explicit clue chains. Specifically, each of the clue chains is formed by
inferring over the user manuals, starting from the question clue aligned with
the user question and ending at a possible response. To overcome the shortage
of supervised data, we adopt the self-supervised strategy for model learning.
The offline experiment shows that CARE is efficient in automatically inferring
accurate responses from the user manual. The online experiment further
demonstrates the superiority of CARE to reduce CSRs' reading burden and keep
high service quality, in particular with >35% decrease in time spent and
keeping a >0.75 ICC score.

ÊëòË¶ÅÔºöÂª∫Êßã‰∏ÄÂÄãÈñ±ËÆÄÂä©ÁêÜÔºåÂçîÂä©ÂÆ¢Êúç‰ª£Ë°® (CSR) Èñ±ËÆÄ‰ΩøÁî®ËÄÖÊâãÂÜäÔºåÁâπÂà•ÊòØË≥áË®äË±êÂØåÁöÑÊâãÂÜäÔºåÂèØ‰ª•ÁØÄÁúÅÊôÇÈñì„ÄÇÁõÆÂâçÁöÑËß£Ê±∫ÊñπÊ°àÁî±ÊñºÁº∫‰πèÂ∞ç‰ΩøÁî®ËÄÖÂïèÈ°åÂíåÂèØËÉΩÂõûÊáâÁöÑÈóúÊ≥®ÔºåÂõ†Ê≠§‰∏çÂ§™ÈÅ©ÂêàÁ∑ö‰∏äÂÆ¢ÊúçÂ†¥ÊôØ„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêË≠∞ÈñãÁôº‰∏ÄÂÄãÁØÄÁúÅÊôÇÈñì‰∏î‰ªîÁ¥∞ÁöÑÈñ±ËÆÄÂä©ÁêÜÔºåÂêçÁÇ∫ CAREÔºåÂÆÉÂèØ‰ª•ÈÄèÈÅéÊòéÁ¢∫ÁöÑÁ∑öÁ¥¢ÈèàÂπ´Âä©ÂÆ¢Êúç‰ª£Ë°®Âø´ÈÄüÂæû‰ΩøÁî®ËÄÖÊâãÂÜä‰∏≠ÊâæÂà∞ÈÅ©Áï∂ÁöÑÂõûÊáâ„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊØèÂÄãÁ∑öÁ¥¢ÈèàÈÉΩÊòØÈÄèÈÅéÊé®Ë´ñ‰ΩøÁî®ËÄÖÊâãÂÜäÂΩ¢ÊàêÁöÑÔºåÂæûËàá‰ΩøÁî®ËÄÖÂïèÈ°å‰∏ÄËá¥ÁöÑÂïèÈ°åÁ∑öÁ¥¢ÈñãÂßãÔºå‰∏¶Âú®ÂèØËÉΩÁöÑÂõûÊáâ‰∏≠ÁµêÊùü„ÄÇÁÇ∫‰∫ÜÂÖãÊúçÁõ£Áù£ÂºèË≥áÊñôÁöÑ‰∏çË∂≥ÔºåÊàëÂÄëÊé°Áî®Ëá™Áõ£Áù£Á≠ñÁï•ÈÄ≤Ë°åÊ®°ÂûãÂ≠∏Áøí„ÄÇÈõ¢Á∑öÂØ¶È©óË°®ÊòéÔºåCARE ÂèØ‰ª•Âæû‰ΩøÁî®ËÄÖÊâãÂÜä‰∏≠Ëá™ÂãïÊé®Ë´ñÂá∫Ê∫ñÁ¢∫ÁöÑÂõûÊáâ„ÄÇÁ∑ö‰∏äÂØ¶È©óÈÄ≤‰∏ÄÊ≠•Ë≠âÊòé‰∫Ü CARE Âú®Ê∏õËºïÂÆ¢Êúç‰ª£Ë°®ÁöÑÈñ±ËÆÄË≤†ÊìîÂíå‰øùÊåÅÈ´òÊúçÂãôÂìÅË≥™ÊñπÈù¢ÁöÑÂÑ™Ë∂äÊÄßÔºåÁâπÂà•ÊòØÂ∞áËä±Ë≤ªÊôÇÈñìÊ∏õÂ∞ë >35%Ôºå‰∏¶‰øùÊåÅ >0.75 ICC ÂàÜÊï∏„ÄÇ

##### **Concept Conductor: Orchestrating Multiple Personalized Concepts in Text-to-Image Synthesis**
2408.03632v1 by Zebin Yao, Fangxiang Feng, Ruifan Li, Xiaojie Wang

The customization of text-to-image models has seen significant advancements,
yet generating multiple personalized concepts remains a challenging task.
Current methods struggle with attribute leakage and layout confusion when
handling multiple concepts, leading to reduced concept fidelity and semantic
consistency. In this work, we introduce a novel training-free framework,
Concept Conductor, designed to ensure visual fidelity and correct layout in
multi-concept customization. Concept Conductor isolates the sampling processes
of multiple custom models to prevent attribute leakage between different
concepts and corrects erroneous layouts through self-attention-based spatial
guidance. Additionally, we present a concept injection technique that employs
shape-aware masks to specify the generation area for each concept. This
technique injects the structure and appearance of personalized concepts through
feature fusion in the attention layers, ensuring harmony in the final image.
Extensive qualitative and quantitative experiments demonstrate that Concept
Conductor can consistently generate composite images with accurate layouts
while preserving the visual details of each concept. Compared to existing
baselines, Concept Conductor shows significant performance improvements. Our
method supports the combination of any number of concepts and maintains high
fidelity even when dealing with visually similar concepts. The code and models
are available at https://github.com/Nihukat/Concept-Conductor.

ÊëòË¶ÅÔºöÊñáÂ≠óËΩâÂúñÂÉèÊ®°ÂûãÁöÑÂÆ¢Ë£ΩÂåñÂ∑≤ÂèñÂæóÈ°ØËëóÈÄ≤Â±ïÔºå
‰ΩÜÁî¢ÁîüÂ§öÂÄãÂÄã‰∫∫ÂåñÊ¶ÇÂøµ‰ªçÁÑ∂ÊòØ‰∏ÄÈ†ÖÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ‰ªªÂãô„ÄÇ
ÁèæÊúâÊñπÊ≥ïÂú®ËôïÁêÜÂ§öÂÄãÊ¶ÇÂøµÊôÇÊúÉÂá∫ÁèæÂ±¨ÊÄßÂ§ñÊ¥©ÂíåÁâàÈù¢Ê∑∑Ê∑ÜÁöÑÂïèÈ°åÔºåÂ∞éËá¥Ê¶ÇÂøµ‰øùÁúüÂ∫¶Èôç‰ΩéÂíåË™ûÁæ©‰∏ÄËá¥ÊÄß„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑÁÑ°Ë®ìÁ∑¥Ê°ÜÊû∂ÔºåÊ¶ÇÂøµÊåáÊèÆÂô®ÔºåÊó®Âú®Á¢∫‰øùÂ§öÊ¶ÇÂøµÂÆ¢Ë£ΩÂåñ‰∏≠ÁöÑË¶ñË¶∫‰øùÁúüÂ∫¶ÂíåÊ≠£Á¢∫ÁâàÈù¢„ÄÇÊ¶ÇÂøµÊåáÊèÆÂô®ÈöîÈõ¢Â§öÂÄãËá™Ë®ÇÊ®°ÂûãÁöÑÂèñÊ®£ÈÅéÁ®ãÔºå‰ª•Èò≤Ê≠¢‰∏çÂêåÊ¶ÇÂøµ‰πãÈñìÁöÑÂ±¨ÊÄßÂ§ñÊ¥©Ôºå‰∏¶ÈÄèÈÅéÂü∫ÊñºËá™ÊàëÊ≥®ÊÑèÂäõÁöÑÁ©∫ÈñìÂºïÂ∞é‰æÜ‰øÆÊ≠£ÈåØË™§ÁöÑÁâàÈù¢„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊ¶ÇÂøµÊ≥®ÂÖ•ÊäÄË°ìÔºåÊé°Áî®ÂΩ¢ÁãÄÊÑüÁü•ÈÅÆÁΩ©‰æÜÊåáÂÆöÊØèÂÄãÊ¶ÇÂøµÁöÑÁîüÊàêÂçÄÂüü„ÄÇÊ≠§ÊäÄË°ìÈÄèÈÅéÊ≥®ÊÑèÂ±§‰∏≠ÁöÑÁâπÂæµËûçÂêà‰æÜÊ≥®ÂÖ•ÂÄã‰∫∫ÂåñÊ¶ÇÂøµÁöÑÁµêÊßãÂíåÂ§ñËßÄÔºåÁ¢∫‰øùÊúÄÁµÇÂΩ±ÂÉèÁöÑÂíåË´ß„ÄÇÂª£Ê≥õÁöÑÂÆöÊÄßÂíåÂÆöÈáèÂØ¶È©óË≠âÊòéÔºåÊ¶ÇÂøµÊåáÊèÆÂô®ÂèØ‰ª•ÊåÅÁ∫åÁî¢ÁîüÂÖ∑ÊúâÊ∫ñÁ¢∫ÁâàÈù¢‰∏î‰øùÁïôÊØèÂÄãÊ¶ÇÂøµË¶ñË¶∫Á¥∞ÁØÄÁöÑË§áÂêàÂΩ±ÂÉè„ÄÇËàáÁèæÊúâÁöÑÂü∫Á∑öÁõ∏ÊØîÔºåÊ¶ÇÂøµÊåáÊèÆÂô®È°ØÁ§∫Âá∫È°ØËëóÁöÑÊïàËÉΩÊèêÂçá„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÊîØÊè¥‰ªªÊÑèÊï∏ÈáèÁöÑÊ¶ÇÂøµÁµÑÂêàÔºåÂç≥‰ΩøÂú®ËôïÁêÜË¶ñË¶∫‰∏äÁõ∏‰ººÁöÑÊ¶ÇÂøµÊôÇ‰πüËÉΩÁ∂≠ÊåÅÈ´ò‰øùÁúüÂ∫¶„ÄÇÁ®ãÂºèÁ¢ºÂíåÊ®°ÂûãÂèØÂú® https://github.com/Nihukat/Concept-Conductor ÂèñÂæó„ÄÇ

##### **Large Language Models for Base Station Siting: Intelligent Deployment based on Prompt or Agent**
2408.03631v1 by Yanhu Wang, Muhammad Muzammil Afzal, Zhengyang Li, Jie Zhou, Chenyuan Feng, Shuaishuai Guo, Tony Q. S. Quek

Traditional base station siting (BSS) methods rely heavily on drive testing
and user feedback, which are laborious and require extensive expertise in
communication, networking, and optimization. As large language models (LLMs)
and their associated technologies advance, particularly in the realms of prompt
engineering and agent engineering, network optimization will witness a
revolutionary approach. This approach entails the strategic use of well-crafted
prompts to infuse human experience and knowledge into these sophisticated LLMs,
and the deployment of autonomous agents as a communication bridge to seamlessly
connect the machine language based LLMs with human users using natural
language. This integration represents the future paradigm of artificial
intelligence (AI) as a service and AI for more ease. As a preliminary
exploration, this research first develops a novel LLM-empowered BSS
optimization framework, and heuristically proposes four different potential
implementations: the strategies based on Prompt-optimized LLM (PoL),
human-in-the-Loop LLM (HiLL), LLM-empowered autonomous BSS agent (LaBa), and
Cooperative multiple LLM-based autonomous BSS agents (CLaBa). Through
evaluation on real-world data, the experiments demonstrate that prompt-assisted
LLMs and LLM-based agents can generate more efficient, cost-effective, and
reliable network deployments, noticeably enhancing the efficiency of BSS
optimization and reducing trivial manual participation.

ÊëòË¶ÅÔºöÂÇ≥Áµ±Âü∫Âú∞Âè∞ÈÅ∏ÂùÄÔºàBSSÔºâÊñπÊ≥ïÈÅéÂ∫¶‰æùË≥¥Ë∑ØÊ∏¨Âíå‰ΩøÁî®ËÄÖÂõûÈ•ãÔºåÈÄôÂæàË≤ªÂäõÔºå‰∏îÈúÄË¶ÅÂú®ÈÄöË®ä„ÄÅÁ∂≤Ë∑ØÂíåÊúÄ‰Ω≥ÂåñÊñπÈù¢ÂÖ∑ÂÇôË±êÂØåÁöÑÂ∞àÊ•≠Áü•Ë≠ò„ÄÇÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂèäÂÖ∂Áõ∏ÈóúÊäÄË°ìÁöÑÈÄ≤Â±ïÔºåÁâπÂà•ÊòØÂú®ÊèêÁ§∫Â∑•Á®ãÂíå‰ª£ÁêÜÂ∑•Á®ãÈ†òÂüüÔºåÁ∂≤Ë∑ØÊúÄ‰Ω≥ÂåñÂ∞áË¶ãË≠â‰∏ÄÂ†¥Èù©ÂëΩÊÄßÁöÑÊñπÊ≥ï„ÄÇÊ≠§ÊñπÊ≥ïÈúÄË¶ÅÁ≠ñÁï•ÊÄßÂú∞‰ΩøÁî®Á≤æÂøÉË£Ω‰ΩúÁöÑÊèêÁ§∫ÔºåÂ∞á‰∫∫È°ûÁ∂ìÈ©óÂíåÁü•Ë≠òÊ≥®ÂÖ•ÈÄô‰∫õË§áÈõúÁöÑ LLMÔºå‰∏¶ÈÉ®ÁΩ≤Ëá™‰∏ª‰ª£ÁêÜ‰ΩúÁÇ∫ÈÄöË®äÊ©ãÊ¢ÅÔºå‰ΩøÁî®Ëá™ÁÑ∂Ë™ûË®ÄÂ∞áÂü∫ÊñºÊ©üÂô®Ë™ûË®ÄÁöÑ LLM Ëàá‰∫∫È°û‰ΩøÁî®ËÄÖÁÑ°Á∏´ÈÄ£Êé•„ÄÇÈÄôÁ®ÆÊï¥Âêà‰ª£Ë°®‰∫Ü‰∫∫Â∑•Êô∫ÊÖßÔºàAIÔºâ‰ΩúÁÇ∫ÊúçÂãôÂíå AI ÁöÑÊú™‰æÜÂÖ∏ÁØÑÔºåËÆì AI Êõ¥ËºïÈ¨Ü„ÄÇ‰ΩúÁÇ∫ÂàùÊ≠•Êé¢Á¥¢ÔºåÊú¨Á†îÁ©∂È¶ñÂÖàÈñãÁôº‰∫Ü‰∏ÄÂÄãÊñ∞Á©éÁöÑ LLM Âº∑Âåñ BSS ÊúÄ‰Ω≥ÂåñÊû∂ÊßãÔºå‰∏¶ÂïüÁôºÂºèÂú∞ÊèêÂá∫‰∫ÜÂõõÁ®Æ‰∏çÂêåÁöÑÊΩõÂú®ÂØ¶‰ΩúÔºöÂü∫ÊñºÊèêÁ§∫ÊúÄ‰Ω≥Âåñ LLMÔºàPoLÔºâÁöÑÁ≠ñÁï•„ÄÅ‰∫∫Ê©üÂçî‰Ωú LLMÔºàHiLLÔºâ„ÄÅLLM Âº∑ÂåñËá™‰∏ª BSS ‰ª£ÁêÜÔºàLaBaÔºâÂíåÂçî‰ΩúÂºèÂ§öÂÄã LLM Âü∫Á§éËá™‰∏ª BSS ‰ª£ÁêÜÔºàCLaBaÔºâ„ÄÇÈÄèÈÅéÂ∞çÁúüÂØ¶‰∏ñÁïåË≥áÊñôÁöÑË©ï‰º∞ÔºåÂØ¶È©óË≠âÊòéÊèêÁ§∫ËºîÂä© LLM ÂíåÂü∫Êñº LLM ÁöÑ‰ª£ÁêÜÂèØ‰ª•Áî¢ÁîüÊõ¥È´òÊïàÁéá„ÄÅÊõ¥ÂÖ∑ÊàêÊú¨ÊïàÁõä‰∏îÊõ¥ÂèØÈù†ÁöÑÁ∂≤Ë∑ØÈÉ®ÁΩ≤ÔºåÈ°ØËëóÊèêÂçá BSS ÊúÄ‰Ω≥ÂåñÁöÑÊïàÁéáÔºå‰∏¶Ê∏õÂ∞ëÁë£Á¢éÁöÑ‰∫∫Â∑•ÂèÉËàá„ÄÇ

##### **PAGED: A Benchmark for Procedural Graphs Extraction from Documents**
2408.03630v2 by Weihong Du, Wenrui Liao, Hongru Liang, Wenqiang Lei

Automatic extraction of procedural graphs from documents creates a low-cost
way for users to easily understand a complex procedure by skimming visual
graphs. Despite the progress in recent studies, it remains unanswered: whether
the existing studies have well solved this task (Q1) and whether the emerging
large language models (LLMs) can bring new opportunities to this task (Q2). To
this end, we propose a new benchmark PAGED, equipped with a large high-quality
dataset and standard evaluations. It investigates five state-of-the-art
baselines, revealing that they fail to extract optimal procedural graphs well
because of their heavy reliance on hand-written rules and limited available
data. We further involve three advanced LLMs in PAGED and enhance them with a
novel self-refine strategy. The results point out the advantages of LLMs in
identifying textual elements and their gaps in building logical structures. We
hope PAGED can serve as a major landmark for automatic procedural graph
extraction and the investigations in PAGED can offer insights into the research
on logic reasoning among non-sequential elements.

ÊëòË¶ÅÔºöËá™ÂãïÂæûÊñá‰ª∂‰∏≠ËêÉÂèñÁ®ãÂ∫èÂúñË°®ÊòØ‰∏ÄÁ®Æ‰ΩéÊàêÊú¨ÁöÑÊñπÂºèÔºåËÆì‰ΩøÁî®ËÄÖËÉΩÈÄèÈÅéÁÄèË¶ΩË¶ñË¶∫ÂåñÂúñË°®ÔºåËºïÈ¨ÜÁêÜËß£Ë§áÈõúÁöÑÁ®ãÂ∫è„ÄÇÂÑòÁÆ°ËøëÊúüÁ†îÁ©∂Â∑≤ÊúâÊâÄÈÄ≤Â±ïÔºå‰ΩÜ‰ªçÊúâÂæÖËß£Á≠îÁöÑÂïèÈ°åÔºöÁèæÊúâÁöÑÁ†îÁ©∂ÊòØÂê¶Â∑≤Â¶•ÂñÑËß£Ê±∫Ê≠§‰ªªÂãôÔºàQ1ÔºâÔºå‰ª•ÂèäÊñ∞ËààÁöÑÂ§ßË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÊòØÂê¶ËÉΩÁÇ∫Ê≠§‰ªªÂãôÂ∏∂‰æÜÊñ∞ÁöÑÂ•ëÊ©üÔºàQ2Ôºâ„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑÂü∫Ê∫ñ PAGEDÔºåÈÖçÂÇôÂ§ßÂûãÈ´òÂìÅË≥™Ë≥áÊñôÈõÜÂíåÊ®ôÊ∫ñË©ïÈáè„ÄÇÂÆÉÊé¢Ë®é‰∫Ü‰∫îÂÄãÊúÄÂÖàÈÄ≤ÁöÑÂü∫Á∑öÔºåÊè≠Á§∫‰∫ÜÂÆÉÂÄëÁÑ°Ê≥ïËâØÂ•ΩÂú∞ËêÉÂèñÊúÄ‰Ω≥Á®ãÂ∫èÂúñË°®ÔºåÂéüÂõ†Âú®ÊñºÂÆÉÂÄëÈÅéÂ∫¶‰æùË≥¥ÊâãÂØ´Ë¶èÂâáÂíåÊúâÈôêÁöÑÂèØÁî®Ë≥áÊñô„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Âú® PAGED ‰∏≠Á¥çÂÖ•‰∏âÂÄãÂÖàÈÄ≤ÁöÑ LLMÔºå‰∏¶ÈÄèÈÅéÊñ∞Á©éÁöÑËá™Á≤æÈÄ≤Á≠ñÁï•Âä†‰ª•Âº∑Âåñ„ÄÇÁµêÊûúÊåáÂá∫ LLM Âú®Ë≠òÂà•ÊñáÊú¨ÂÖÉÁ¥†ÊñπÈù¢ÁöÑÂÑ™Âã¢Ôºå‰ª•ÂèäÂÆÉÂÄëÂú®Âª∫Á´ãÈÇèËºØÁµêÊßãÊñπÈù¢ÁöÑÂ∑ÆË∑ù„ÄÇÊàëÂÄëÂ∏åÊúõ PAGED ËÉΩÊàêÁÇ∫Ëá™ÂãïÁ®ãÂ∫èÂúñË°®ËêÉÂèñÁöÑ‰∏ªË¶ÅÈáåÁ®ãÁ¢ëÔºåËÄå PAGED ‰∏≠ÁöÑÊé¢Ë®éËÉΩÁÇ∫ÈùûÈ†ÜÂ∫èÂÖÉÁ¥†ÈñìÁöÑÈÇèËºØÊé®ÁêÜÁ†îÁ©∂Êèê‰æõË¶ãËß£„ÄÇ

##### **Improving the quality of Persian clinical text with a novel spelling correction system**
2408.03622v1 by Seyed Mohammad Sadegh Dashti, Seyedeh Fatemeh Dashti

Background: The accuracy of spelling in Electronic Health Records (EHRs) is a
critical factor for efficient clinical care, research, and ensuring patient
safety. The Persian language, with its abundant vocabulary and complex
characteristics, poses unique challenges for real-word error correction. This
research aimed to develop an innovative approach for detecting and correcting
spelling errors in Persian clinical text.
  Methods: Our strategy employs a state-of-the-art pre-trained model that has
been meticulously fine-tuned specifically for the task of spelling correction
in the Persian clinical domain. This model is complemented by an innovative
orthographic similarity matching algorithm, PERTO, which uses visual similarity
of characters for ranking correction candidates.
  Results: The evaluation of our approach demonstrated its robustness and
precision in detecting and rectifying word errors in Persian clinical text. In
terms of non-word error correction, our model achieved an F1-Score of 90.0%
when the PERTO algorithm was employed. For real-word error detection, our model
demonstrated its highest performance, achieving an F1-Score of 90.6%.
Furthermore, the model reached its highest F1-Score of 91.5% for real-word
error correction when the PERTO algorithm was employed.
  Conclusions: Despite certain limitations, our method represents a substantial
advancement in the field of spelling error detection and correction for Persian
clinical text. By effectively addressing the unique challenges posed by the
Persian language, our approach paves the way for more accurate and efficient
clinical documentation, contributing to improved patient care and safety.
Future research could explore its use in other areas of the Persian medical
domain, enhancing its impact and utility.

ÊëòË¶ÅÔºöËÉåÊôØÔºöÈõªÂ≠êÁóÖÊ≠∑ (EHR) ‰∏≠ÊãºÂØ´ÁöÑÊ∫ñÁ¢∫ÊÄßÊòØÊúâÊïàËá®Â∫äÁÖßË≠∑„ÄÅÁ†îÁ©∂ÂíåÁ¢∫‰øùÊÇ£ËÄÖÂÆâÂÖ®ÊÄßÁöÑÈóúÈçµÂõ†Á¥†„ÄÇÊ≥¢ÊñØË™ûÊìÅÊúâË±êÂØåÁöÑË©ûÂΩôÂíåË§áÈõúÁöÑÁâπÂæµÔºåÂ∞çÁúüÂØ¶‰∏ñÁïåÁöÑÈåØË™§Êõ¥Ê≠£ÊèêÂá∫‰∫ÜÁç®ÁâπÁöÑÊåëÊà∞„ÄÇÊú¨Á†îÁ©∂Êó®Âú®ÈñãÁôº‰∏ÄÁ®ÆÂâµÊñ∞ÁöÑÊñπÊ≥ï‰æÜÂÅµÊ∏¨ÂíåÊõ¥Ê≠£Ê≥¢ÊñØË™ûËá®Â∫äÊñáÊú¨‰∏≠ÁöÑÊãºÂØ´ÈåØË™§„ÄÇ
ÊñπÊ≥ïÔºöÊàëÂÄëÁöÑÁ≠ñÁï•Êé°Áî®‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÈ†êË®ìÁ∑¥Ê®°ÂûãÔºåË©≤Ê®°ÂûãÁ∂ìÈÅéÁ≤æÂøÉÂæÆË™øÔºåÂ∞àÈñÄÁî®ÊñºÊ≥¢ÊñØË™ûËá®Â∫äÈ†òÂüü‰∏≠ÁöÑÊãºÂØ´Êõ¥Ê≠£‰ªªÂãô„ÄÇÊ≠§Ê®°ÂûãÁî±ÂâµÊñ∞ÁöÑÊ≠£Â≠óÊ≥ïÁõ∏‰ººÊÄßÂåπÈÖçÊºîÁÆóÊ≥ï PERTO Ë£úÂÖÖÔºåË©≤ÊºîÁÆóÊ≥ï‰ΩøÁî®Â≠óÂÖÉÁöÑË¶ñË¶∫Áõ∏‰ººÊÄß‰æÜÂ∞çÊõ¥Ê≠£ÂÄôÈÅ∏È†ÖÈÄ≤Ë°åÊéíÂêç„ÄÇ
ÁµêÊûúÔºöÂ∞çÊàëÂÄëÊñπÊ≥ïÁöÑË©ï‰º∞Ë≠âÊòé‰∫ÜÂÖ∂Âú®ÂÅµÊ∏¨ÂíåÁ≥æÊ≠£Ê≥¢ÊñØË™ûËá®Â∫äÊñáÊú¨‰∏≠ÁöÑÊñáÂ≠óÈåØË™§ÊñπÈù¢ÁöÑÁ©©ÂÅ•ÊÄßÂíåÊ∫ñÁ¢∫ÊÄß„ÄÇÂú®ÈùûÊñáÂ≠óÈåØË™§Êõ¥Ê≠£ÊñπÈù¢ÔºåÁï∂‰ΩøÁî® PERTO ÊºîÁÆóÊ≥ïÊôÇÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂØ¶Áèæ‰∫Ü 90.0% ÁöÑ F1 ÂàÜÊï∏„ÄÇÂ∞çÊñºÁúüÂØ¶‰∏ñÁïåÁöÑÈåØË™§ÂÅµÊ∏¨ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂ±ïÁ§∫‰∫ÜÂÖ∂ÊúÄÈ´òÁöÑÊïàËÉΩÔºåÂØ¶Áèæ‰∫Ü 90.6% ÁöÑ F1 ÂàÜÊï∏„ÄÇÊ≠§Â§ñÔºåÁï∂‰ΩøÁî® PERTO ÊºîÁÆóÊ≥ïÊôÇÔºåË©≤Ê®°ÂûãÈÅîÂà∞‰∫ÜÂÖ∂ÊúÄÈ´òÁöÑ F1 ÂàÜÊï∏ 91.5%ÔºåÁî®ÊñºÁúüÂØ¶‰∏ñÁïåÁöÑÈåØË™§Êõ¥Ê≠£„ÄÇ
ÁµêË´ñÔºöÂÑòÁÆ°Â≠òÂú®Êüê‰∫õÈôêÂà∂Ôºå‰ΩÜÊàëÂÄëÁöÑÊ®°Âûã‰ª£Ë°®‰∫ÜÊ≥¢ÊñØË™ûËá®Â∫äÊñáÊú¨ÊãºÂØ´ÈåØË™§ÂÅµÊ∏¨ÂíåÊõ¥Ê≠£È†òÂüüÁöÑÈáçÂ§ßÈÄ≤Â±ï„ÄÇÈÄèÈÅéÊúâÊïàËß£Ê±∫Ê≥¢ÊñØË™ûÊâÄÂ∏∂‰æÜÁöÑÁç®ÁâπÊåëÊà∞ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÁÇ∫Êõ¥Ê∫ñÁ¢∫ÂíåÊúâÊïàÁöÑËá®Â∫äÊñá‰ª∂Èã™Ë∑ØÔºåÊúâÂä©ÊñºÊîπÂñÑÊÇ£ËÄÖÁÖßË≠∑ÂíåÂÆâÂÖ®ÊÄß„ÄÇÊú™‰æÜÁöÑÁ†îÁ©∂ÂèØ‰ª•Êé¢Ë®éÂÖ∂Âú®Ê≥¢ÊñØË™ûÈÜ´Â≠∏È†òÂüüÂÖ∂‰ªñÈ†òÂüüÁöÑÊáâÁî®Ôºå‰ª•Â¢ûÂº∑ÂÖ∂ÂΩ±ÈüøÂäõÂíåÂØ¶Áî®ÊÄß„ÄÇ

##### **A Logical Fallacy-Informed Framework for Argument Generation**
2408.03618v1 by Luca Mouchel, Debjit Paul, Shaobo Cui, Robert West, Antoine Bosselut, Boi Faltings

Despite the remarkable performance of Large Language Models (LLMs), they
still struggle with generating logically sound arguments, resulting in
potential risks such as spreading misinformation. An important factor
contributing to LLMs' suboptimal performance in generating coherent arguments
is their oversight of logical fallacies. To address this issue, we introduce
FIPO, a fallacy-informed framework that leverages preference optimization
methods to steer LLMs toward logically sound arguments. FIPO includes a
classification loss, to capture the fine-grained information on fallacy
categories. Our results on argumentation datasets show that our method reduces
the fallacy errors by up to 17.5%. Furthermore, our human evaluation results
indicate that the quality of the generated arguments by our method
significantly outperforms the fine-tuned baselines, as well as prior preference
optimization methods, such as DPO. These findings highlight the importance of
ensuring models are aware of logical fallacies for effective argument
generation.

ÊëòË¶ÅÔºöÂÑòÁÆ°Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊìÅÊúâÂÇëÂá∫ÁöÑË°®ÁèæÔºåÂÆÉÂÄëÂú®Áî¢ÁîüÂêà‰πéÈÇèËºØÁöÑË´ñËø∞‰∏ä‰ªçÊúâÂõ∞Èõ£ÔºåÂ∞éËá¥ÊΩõÂú®È¢®Èö™Ôºå‰æãÂ¶ÇÊï£Â∏ÉÈåØË™§Ë®äÊÅØ„ÄÇÈÄ†Êàê LLM Âú®Áî¢ÁîüÈÄ£Ë≤´Ë´ñËø∞ÊôÇË°®Áèæ‰∏ç‰Ω≥ÁöÑ‰∏ÄÂÄãÈáçË¶ÅÂõ†Á¥†ÔºåÊòØÂÆÉÂÄëÂøΩÁï•‰∫ÜÈÇèËºØË¨¨Ë™§„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü FIPOÔºå‰∏ÄÂÄã‰ª•Ë¨¨Ë™§ÁÇ∫Âü∫Á§éÁöÑÊû∂ÊßãÔºåÂÆÉÂà©Áî®ÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÊñπÊ≥ïÂ∞á LLM ÂºïÂ∞éËá≥Âêà‰πéÈÇèËºØÁöÑË´ñËø∞„ÄÇFIPO ÂåÖÂê´‰∏ÄÂÄãÂàÜÈ°ûÊêçÂ§±Ôºå‰ª•Êì∑ÂèñÈóúÊñºË¨¨Ë™§È°ûÂà•ÁöÑÁ¥∞ÂæÆË≥áË®ä„ÄÇÊàëÂÄëÂú®Ë´ñË≠âË≥áÊñôÈõÜ‰∏äÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÂ∞áË¨¨Ë™§ÈåØË™§Ê∏õÂ∞ë‰∫Ü 17.5%„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑ‰∫∫Â∑•Ë©ï‰º∞ÁµêÊûúÊåáÂá∫ÔºåÊàëÂÄëÁöÑÊ®°ÂûãÁî¢ÁîüÁöÑË´ñËø∞ÂìÅË≥™È°ØËëóÂÑ™ÊñºÂæÆË™øÂü∫Á∑öÔºå‰ª•ÂèäÂÖàÂâçÁöÑÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÊñπÊ≥ïÔºå‰æãÂ¶Ç DPO„ÄÇÈÄô‰∫õÁôºÁèæÂº∑Ë™ø‰∫ÜÁ¢∫‰øùÊ®°Âûã‰∫ÜËß£ÈÇèËºØË¨¨Ë™§Â∞çÊñºÊúâÊïàÁî¢ÁîüË´ñËø∞ÁöÑÈáçË¶ÅÊÄß„ÄÇ

##### **Is Child-Directed Speech Effective Training Data for Language Models?**
2408.03617v1 by Steven Y. Feng, Noah D. Goodman, Michael C. Frank

While high-performing language models are typically trained on hundreds of
billions of words, human children become fluent language users with a much
smaller amount of data. What are the features of the data they receive, and how
do these features support language modeling objectives? To investigate this
question, we train GPT-2 models on 29M words of English-language child-directed
speech and a new matched, synthetic dataset (TinyDialogues), comparing to a
heterogeneous blend of datasets from the BabyLM challenge. We evaluate both the
syntactic and semantic knowledge of these models using developmentally-inspired
evaluations. Through pretraining experiments, we test whether the global
developmental ordering or the local discourse ordering of children's training
data support high performance relative to other datasets. The local properties
of the data affect model results, but somewhat surprisingly, global properties
do not. Further, child language input is not uniquely valuable for training
language models. These findings support the hypothesis that, rather than
proceeding from better data, children's learning is instead substantially more
efficient than current language modeling techniques.

ÊëòË¶ÅÔºöÂÑòÁÆ°È´òÊÄßËÉΩË™ûË®ÄÊ®°ÂûãÈÄöÂ∏∏ÊúÉÂú®Êï∏ÁôæÂÑÑÂÄãÂñÆÂ≠ó‰∏äÈÄ≤Ë°åË®ìÁ∑¥Ôºå‰ΩÜ‰∫∫È°ûÂ≠©Á´•Âè™ÈúÄ‰ΩøÁî®Êõ¥Â∞ëÈáèÁöÑË≥áÊñôÔºåÂ∞±ËÉΩÊàêÁÇ∫ÊµÅÂà©ÁöÑË™ûË®Ä‰ΩøÁî®ËÄÖ„ÄÇ‰ªñÂÄëÊé•Êî∂ÁöÑË≥áÊñôÊúâÂì™‰∫õÁâπÂæµÔºåÈÄô‰∫õÁâπÂæµÂ¶Ç‰ΩïÊîØÊè¥Ë™ûË®ÄÂª∫Ê®°ÁõÆÊ®ôÔºüÁÇ∫‰∫ÜÊé¢Ë®éÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂú® 2900 Ëê¨ÂÄãÂñÆÂ≠óÁöÑËã±Ë™ûÂÖíÁ´•Â∞éÂêëË™ûË®ÄÂíå‰∏ÄÂÄãÊñ∞ÁöÑÂåπÈÖçÂºèÂêàÊàêË≥áÊñôÈõÜ (TinyDialogues) ‰∏äË®ìÁ∑¥ GPT-2 Ê®°ÂûãÔºå‰∏¶Ëàá BabyLM ÊåëÊà∞‰∏≠ÂêÑÁ®ÆÁï∞Ë≥™Ë≥áÊñôÈõÜÈÄ≤Ë°åÊØîËºÉ„ÄÇÊàëÂÄë‰ΩøÁî®ÁôºÂ±ïÈùàÊÑüË©ï‰º∞‰æÜË©ï‰º∞ÈÄô‰∫õÊ®°ÂûãÁöÑÂè•Ê≥ïÂíåË™ûÁæ©Áü•Ë≠ò„ÄÇÈÄèÈÅéÈ†êË®ìÁ∑¥ÂØ¶È©óÔºåÊàëÂÄëÊ∏¨Ë©¶ÂÖíÁ´•Ë®ìÁ∑¥Ë≥áÊñôÁöÑÊï¥È´îÁôºÂ±ïÈ†ÜÂ∫èÊàñÂ±ÄÈÉ®Ë™ûÁØáÈ†ÜÂ∫èÊòØÂê¶Áõ∏Â∞çÊñºÂÖ∂‰ªñË≥áÊñôÈõÜÊîØÊè¥È´òÊÄßËÉΩ„ÄÇË≥áÊñôÁöÑÂ±ÄÈÉ®Â±¨ÊÄßÊúÉÂΩ±ÈüøÊ®°ÂûãÁµêÊûúÔºå‰ΩÜ‰ª§‰∫∫È©öË®ùÁöÑÊòØÔºåÊï¥È´îÂ±¨ÊÄß‰∏¶‰∏çÊúÉ„ÄÇÊ≠§Â§ñÔºåÂÖíÁ´•Ë™ûË®ÄËº∏ÂÖ•‰∏¶ÈùûË®ìÁ∑¥Ë™ûË®ÄÊ®°ÂûãÁöÑÂîØ‰∏ÄÊúâÂÉπÂÄºË≥áÊñô„ÄÇÈÄô‰∫õÁôºÁèæÊîØÊåÅ‰ª•‰∏ãÂÅáË®≠ÔºöÂÖíÁ´•ÁöÑÂ≠∏Áøí‰∏¶Èùû‰æÜËá™Êõ¥Â•ΩÁöÑË≥áÊñôÔºåËÄåÊòØÊØîÁõÆÂâçÁöÑË™ûË®ÄÂª∫Ê®°ÊäÄË°ìÊúâÊïàÁéáË®±Â§ö„ÄÇ

##### **Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon Tasks**
2408.03615v1 by Zaijing Li, Yuquan Xie, Rui Shao, Gongwei Chen, Dongmei Jiang, Liqiang Nie

Building a general-purpose agent is a long-standing vision in the field of
artificial intelligence. Existing agents have made remarkable progress in many
domains, yet they still struggle to complete long-horizon tasks in an open
world. We attribute this to the lack of necessary world knowledge and
multimodal experience that can guide agents through a variety of long-horizon
tasks. In this paper, we propose a Hybrid Multimodal Memory module to address
the above challenges. It 1) transforms knowledge into Hierarchical Directed
Knowledge Graph that allows agents to explicitly represent and learn world
knowledge, and 2) summarises historical information into Abstracted Multimodal
Experience Pool that provide agents with rich references for in-context
learning. On top of the Hybrid Multimodal Memory module, a multimodal agent,
Optimus-1, is constructed with dedicated Knowledge-guided Planner and
Experience-Driven Reflector, contributing to a better planning and reflection
in the face of long-horizon tasks in Minecraft. Extensive experimental results
show that Optimus-1 significantly outperforms all existing agents on
challenging long-horizon task benchmarks, and exhibits near human-level
performance on many tasks. In addition, we introduce various Multimodal Large
Language Models (MLLMs) as the backbone of Optimus-1. Experimental results show
that Optimus-1 exhibits strong generalization with the help of the Hybrid
Multimodal Memory module, outperforming the GPT-4V baseline on many tasks.

ÊëòË¶ÅÔºöÊâìÈÄ†‰∏ÄÂÄãÈÄöÁî®‰ª£ÁêÜÊòØ‰∫∫Â∑•Êô∫ÊÖßÈ†òÂüüÈï∑‰πÖ‰ª•‰æÜÁöÑÈ°òÊôØ„ÄÇÁèæÊúâÁöÑ‰ª£ÁêÜÂú®Ë®±Â§öÈ†òÂüüÈÉΩÊúâÈ°ØËëóÁöÑÈÄ≤Ê≠•Ôºå‰ΩÜÂÆÉÂÄë‰ªçÈõ£‰ª•Âú®ÈñãÊîæ‰∏ñÁïå‰∏≠ÂÆåÊàêÈï∑ÊôÇÁ®ã‰ªªÂãô„ÄÇÊàëÂÄëÂ∞áÊ≠§Ê≠∏Âõ†ÊñºÁº∫‰πèÂøÖË¶ÅÁöÑÁü•Ë≠òÂíåÂ§öÊ®°ÊÖãÁ∂ìÈ©óÔºåÈÄô‰∫õÁü•Ë≠òÂíåÁ∂ìÈ©óÂèØ‰ª•ÂºïÂ∞é‰ª£ÁêÜÂÆåÊàêÂêÑÁ®ÆÈï∑ÊôÇÁ®ã‰ªªÂãô„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊ∑∑ÂêàÂ§öÊ®°ÊÖãË®òÊÜ∂È´îÊ®°ÁµÑ‰æÜËß£Ê±∫‰∏äËø∞ÊåëÊà∞„ÄÇÂÆÉ 1) Â∞áÁü•Ë≠òËΩâÊèõÁÇ∫ÈöéÂ±§ÂºèÂ∞éÂêëÁü•Ë≠òÂúñÔºåËÆì‰ª£ÁêÜËÉΩÂ§†ÊòéÁ¢∫Âú∞Ë°®Á§∫ÂíåÂ≠∏Áøí‰∏ñÁïåÁü•Ë≠òÔºå‰ª•Âèä 2) Â∞áÊ≠∑Âè≤Ë≥áË®äÊëòË¶ÅÊàêÊäΩË±°ÁöÑÂ§öÊ®°ÊÖãÁ∂ìÈ©óÊ±†ÔºåÁÇ∫‰ª£ÁêÜÊèê‰æõË±êÂØåÁöÑÂèÉËÄÉÔºå‰ª•‰æøÈÄ≤Ë°åÊÉÖÂ¢ÉÂ≠∏Áøí„ÄÇÂú®Ê∑∑ÂêàÂ§öÊ®°ÊÖãË®òÊÜ∂È´îÊ®°ÁµÑ‰πã‰∏äÔºåÂª∫Êßã‰∫Ü‰∏ÄÂÄãÂ§öÊ®°ÊÖã‰ª£ÁêÜÔºåOptimus-1ÔºåÂÆÉÂÖ∑ÂÇôÂ∞àÁî®ÁöÑÁü•Ë≠òÂ∞éÂêëË¶èÂäÉÂô®ÂíåÁ∂ìÈ©óÈ©ÖÂãïÁöÑÂèçÂ∞ÑÂô®ÔºåÊúâÂä©ÊñºÂú® Minecraft ‰∏≠Èù¢Â∞çÈï∑ÊôÇÁ®ã‰ªªÂãôÊôÇÈÄ≤Ë°åÊõ¥Â•ΩÁöÑË¶èÂäÉÂíåÂèçÊÄù„ÄÇÂª£Ê≥õÁöÑÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåOptimus-1 Âú®ÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÈï∑ÊôÇÁ®ã‰ªªÂãôÂü∫Ê∫ñ‰∏äÈ°ØËëóÂÑ™ÊñºÊâÄÊúâÁèæÊúâ‰ª£ÁêÜÔºå‰∏¶‰∏îÂú®Ë®±Â§ö‰ªªÂãô‰∏äÂ±ïÁèæÂá∫Êé•Ëøë‰∫∫È°ûÁöÑÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•ÂêÑÁ®ÆÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) ‰ΩúÁÇ∫ Optimus-1 ÁöÑÈ™®Âππ„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåOptimus-1 Âú®Ê∑∑ÂêàÂ§öÊ®°ÊÖãË®òÊÜ∂È´îÊ®°ÁµÑÁöÑÂπ´Âä©‰∏ãÂ±ïÁèæÂá∫Âº∑Â§ßÁöÑÊ≥õÂåñËÉΩÂäõÔºåÂú®Ë®±Â§ö‰ªªÂãô‰∏äÂÑ™Êñº GPT-4V Âü∫Ê∫ñ„ÄÇ

##### **EnJa: Ensemble Jailbreak on Large Language Models**
2408.03603v1 by Jiahao Zhang, Zilong Wang, Ruofan Wang, Xingjun Ma, Yu-Gang Jiang

As Large Language Models (LLMs) are increasingly being deployed in
safety-critical applications, their vulnerability to potential jailbreaks --
malicious prompts that can disable the safety mechanism of LLMs -- has
attracted growing research attention. While alignment methods have been
proposed to protect LLMs from jailbreaks, many have found that aligned LLMs can
still be jailbroken by carefully crafted malicious prompts, producing content
that violates policy regulations. Existing jailbreak attacks on LLMs can be
categorized into prompt-level methods which make up stories/logic to circumvent
safety alignment and token-level attack methods which leverage gradient methods
to find adversarial tokens. In this work, we introduce the concept of Ensemble
Jailbreak and explore methods that can integrate prompt-level and token-level
jailbreak into a more powerful hybrid jailbreak attack. Specifically, we
propose a novel EnJa attack to hide harmful instructions using prompt-level
jailbreak, boost the attack success rate using a gradient-based attack, and
connect the two types of jailbreak attacks via a template-based connector. We
evaluate the effectiveness of EnJa on several aligned models and show that it
achieves a state-of-the-art attack success rate with fewer queries and is much
stronger than any individual jailbreak.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÊó•ÁõäÂª£Ê≥õÂú∞ÈÉ®ÁΩ≤Âú®ÂÆâÂÖ®ÈóúÈçµÂûãÊáâÁî®Á®ãÂºè‰∏≠ÔºåÂÆÉÂÄëÂÆπÊòìÂèóÂà∞ÊΩõÂú®Ë∂äÁçÑÁöÑÊîªÊìäÔºåÊÉ°ÊÑèÊèêÁ§∫ÂèØ‰ª•ÂÅúÁî® LLM ÁöÑÂÆâÂÖ®Ê©üÂà∂ÔºåÈÄôÂºïËµ∑‰∫ÜË∂ä‰æÜË∂äÂ§öÁöÑÁ†îÁ©∂ÈóúÊ≥®„ÄÇÂÑòÁÆ°Â∑≤ÊèêÂá∫ÊØîÂ∞çÊñπÊ≥ï‰æÜ‰øùË≠∑ LLM ‰∏çÂèóË∂äÁçÑÊîªÊìäÔºå‰ΩÜË®±Â§ö‰∫∫ÁôºÁèæÔºåÁ≤æÂøÉË®≠Ë®àÁöÑÊÉ°ÊÑèÊèêÁ§∫‰ªçÁÑ∂ÂèØ‰ª•Ë∂äÁçÑÊØîÂ∞çÂæåÁöÑ LLMÔºåÁî¢ÁîüÈÅïÂèçÊîøÁ≠ñÊ≥ïË¶èÁöÑÂÖßÂÆπ„ÄÇÁèæÊúâÁöÑÈáùÂ∞ç LLM ÁöÑË∂äÁçÑÊîªÊìäÂèØÂàÜÁÇ∫ÊèêÁ§∫Â±§Á¥öÊñπÊ≥ïÔºåË©≤ÊñπÊ≥ïÁ∑®ÈÄ†ÊïÖ‰∫ã/ÈÇèËºØ‰æÜË¶èÈÅøÂÆâÂÖ®ÊØîÂ∞çÔºå‰ª•ÂèäÂà©Áî®Ê¢ØÂ∫¶ÊñπÊ≥ï‰æÜÂ∞ãÊâæÂ∞çÊäóÊÄßÊ¨äÊùñÁöÑÊ¨äÊùñÂ±§Á¥öÊîªÊìäÊñπÊ≥ï„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÊï¥È´îË∂äÁçÑÁöÑÊ¶ÇÂøµÔºå‰∏¶Êé¢Ë®é‰∫ÜÂèØ‰ª•Â∞áÊèêÁ§∫Â±§Á¥öÂíåÊ¨äÊùñÂ±§Á¥öË∂äÁçÑÊï¥ÂêàÂà∞Êõ¥Âº∑Â§ßÁöÑÊ∑∑ÂêàË∂äÁçÑÊîªÊìä‰∏≠ÁöÑÊñπÊ≥ï„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑ EnJa ÊîªÊìäÔºå‰ΩøÁî®ÊèêÁ§∫Â±§Á¥öË∂äÁçÑ‰æÜÈö±ËóèÊúâÂÆ≥Êåá‰ª§Ôºå‰ΩøÁî®Âü∫ÊñºÊ¢ØÂ∫¶ÁöÑÊîªÊìä‰æÜÊèêÈ´òÊîªÊìäÊàêÂäüÁéáÔºå‰∏¶ÈÄöÈÅéÂü∫ÊñºÁØÑÊú¨ÁöÑÈÄ£Êé•Âô®ÈÄ£Êé•ÂÖ©Á®ÆÈ°ûÂûãÁöÑË∂äÁçÑÊîªÊìä„ÄÇÊàëÂÄëË©ï‰º∞‰∫Ü EnJa Âú®Â§öÂÄãÊØîÂ∞çÊ®°Âûã‰∏äÁöÑÊúâÊïàÊÄßÔºå‰∏¶Ë°®ÊòéÂÆÉ‰ª•ËºÉÂ∞ëÁöÑÊü•Ë©¢ÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊîªÊìäÊàêÂäüÁéáÔºå‰∏¶‰∏îÊØî‰ªª‰ΩïÂñÆÁç®ÁöÑË∂äÁçÑÊîªÊìäÈÉΩÂº∑ÂæóÂ§ö„ÄÇ

##### **Facing the Music: Tackling Singing Voice Separation in Cinematic Audio Source Separation**
2408.03588v1 by Karn N. Watcharasupat, Chih-Wei Wu, Iroro Orife

Cinematic audio source separation (CASS) is a fairly new subtask of audio
source separation. A typical setup of CASS is a three-stem problem, with the
aim of separating the mixture into the dialogue stem (DX), music stem (MX), and
effects stem (FX). In practice, however, several edge cases exist as some sound
sources do not fit neatly in either of these three stems, necessitating the use
of additional auxiliary stems in production. One very common edge case is the
singing voice in film audio, which may belong in either the DX or MX, depending
heavily on the cinematic context. In this work, we demonstrate a very
straightforward extension of the dedicated-decoder Bandit and query-based
single-decoder Banquet models to a four-stem problem, treating non-musical
dialogue, instrumental music, singing voice, and effects as separate stems.
Interestingly, the query-based Banquet model outperformed the dedicated-decoder
Bandit model. We hypothesized that this is due to a better feature alignment at
the bottleneck as enforced by the band-agnostic FiLM layer. Dataset and model
implementation will be made available at
https://github.com/kwatcharasupat/source-separation-landing.

ÊëòË¶ÅÔºöÈõªÂΩ±Èü≥Ë®ä‰æÜÊ∫êÂàÜÈõ¢ (CASS) ÊòØÈü≥Ë®ä‰æÜÊ∫êÂàÜÈõ¢‰∏≠Áõ∏Áï∂Êñ∞ÁöÑÂ≠ê‰ªªÂãô„ÄÇCASS ÁöÑÂÖ∏ÂûãË®≠ÂÆöÊòØ‰∏âÂππÂïèÈ°åÔºåÁõÆÊ®ôÊòØÂ∞áÊ∑∑ÂêàÁâ©ÂàÜÈõ¢ÁÇ∫Â∞çË©±Âππ (DX)„ÄÅÈü≥Ê®ÇÂππ (MX) ÂíåÊïàÊûúÂππ (FX)„ÄÇÁÑ∂ËÄåÔºåÂú®ÂØ¶ÈöõÊáâÁî®‰∏≠ÔºåÂ≠òÂú®Ë®±Â§öÈÇäÁ∑£ÊÉÖÊ≥ÅÔºåÂõ†ÁÇ∫Êúâ‰∫õÈü≥Ë®ä‰æÜÊ∫êÁÑ°Ê≥ïÂÆåÂÖ®Á¨¶ÂêàÈÄô‰∏âÂÄãÂππ‰∏≠ÁöÑ‰ªª‰Ωï‰∏ÄÂÄãÔºåÂõ†Ê≠§Âú®Ë£Ω‰ΩúÈÅéÁ®ã‰∏≠ÈúÄË¶Å‰ΩøÁî®È°çÂ§ñÁöÑËºîÂä©Âππ„ÄÇ‰∏ÄÂÄãÈùûÂ∏∏Â∏∏Ë¶ãÁöÑÈÇäÁ∑£ÊÉÖÊ≥ÅÊòØÈõªÂΩ±Èü≥Ë®ä‰∏≠ÁöÑÊ≠åÂî±ËÅ≤ÔºåÂÆÉÂèØËÉΩÂ±¨Êñº DX Êàñ MXÔºåÂæàÂ§ßÁ®ãÂ∫¶‰∏äÂèñÊ±∫ÊñºÈõªÂΩ±ËÉåÊôØ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰∏ÄÂÄãÈùûÂ∏∏Áõ¥Êé•ÁöÑÂª∂‰º∏ÔºåÂ∞áÂ∞àÁî®Ëß£Á¢ºÂô® Bandit ÂíåÂü∫ÊñºÊü•Ë©¢ÁöÑÂñÆ‰∏ÄËß£Á¢ºÂô® Banquet Ê®°ÂûãÊì¥Â±ïÂà∞ÂõõÂππÂïèÈ°åÔºåÂ∞áÈùûÈü≥Ê®ÇÂ∞çË©±„ÄÅÂô®Ê®Ç„ÄÅÊ≠åÂî±ÂíåÊïàÊûúË¶ñÁÇ∫Áç®Á´ãÁöÑÂππ„ÄÇÊúâË∂£ÁöÑÊòØÔºåÂü∫ÊñºÊü•Ë©¢ÁöÑ Banquet Ê®°ÂûãÂÑ™ÊñºÂ∞àÁî®Ëß£Á¢ºÂô® Bandit Ê®°Âûã„ÄÇÊàëÂÄëÂÅáË®≠ÈÄôÊòØÂõ†ÁÇ∫È†ªÂ∏∂‰∏çÂèØÁü•ÁöÑ FiLM Â±§Âº∑Âà∂Âü∑Ë°åÁöÑÁì∂È†∏ËôïÊúâÊõ¥Â•ΩÁöÑÁâπÂæµÂ∞çÈΩä„ÄÇË≥áÊñôÈõÜÂíåÊ®°ÂûãÂØ¶‰ΩúÂ∞áÂú® https://github.com/kwatcharasupat/source-separation-landing Êèê‰æõ„ÄÇ

##### **Hierarchical Neural Constructive Solver for Real-world TSP Scenarios**
2408.03585v1 by Yong Liang Goh, Zhiguang Cao, Yining Ma, Yanfei Dong, Mohammed Haroon Dupty, Wee Sun Lee

Existing neural constructive solvers for routing problems have predominantly
employed transformer architectures, conceptualizing the route construction as a
set-to-sequence learning task. However, their efficacy has primarily been
demonstrated on entirely random problem instances that inadequately capture
real-world scenarios. In this paper, we introduce realistic Traveling Salesman
Problem (TSP) scenarios relevant to industrial settings and derive the
following insights: (1) The optimal next node (or city) to visit often lies
within proximity to the current node, suggesting the potential benefits of
biasing choices based on current locations. (2) Effectively solving the TSP
requires robust tracking of unvisited nodes and warrants succinct grouping
strategies. Building upon these insights, we propose integrating a learnable
choice layer inspired by Hypernetworks to prioritize choices based on the
current location, and a learnable approximate clustering algorithm inspired by
the Expectation-Maximization algorithm to facilitate grouping the unvisited
cities. Together, these two contributions form a hierarchical approach towards
solving the realistic TSP by considering both immediate local neighbourhoods
and learning an intermediate set of node representations. Our hierarchical
approach yields superior performance compared to both classical and recent
transformer models, showcasing the efficacy of the key designs.

ÊëòË¶ÅÔºöÁèæÊúâÁöÑÁ•ûÁ∂ìÂª∫ÊßãÊ±ÇËß£Âô®‰∏ªË¶Å‰ΩøÁî®TransformerÊû∂ÊßãÔºåÂ∞áË∑ØÁ∑öÂª∫ÊßãÊ¶ÇÂøµÂåñÁÇ∫ÈõÜÂêàÂà∞Â∫èÂàóÁöÑÂ≠∏Áøí‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÁöÑÊïàËÉΩ‰∏ªË¶ÅÂ±ïÁèæÂú®ÂÆåÂÖ®Èö®Ê©üÁöÑÂïèÈ°åÂØ¶‰æã‰∏äÔºåÁÑ°Ê≥ïÂÖÖÂàÜÊçïÊçâÁèæÂØ¶‰∏ñÁïåÁöÑÂ†¥ÊôØ„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜËàáÂ∑•Ê•≠Áí∞Â¢ÉÁõ∏ÈóúÁöÑÁèæÂØ¶ÊóÖË°åÂïÜÂïèÈ°å (TSP) Â†¥ÊôØÔºå‰∏¶ÂæóÂá∫‰ª•‰∏ãË¶ãËß£Ôºö(1) ‰∏ã‰∏ÄÂÄãË¶ÅÊãúË®™ÁöÑÊúÄ‰Ω≥ÁØÄÈªûÔºàÊàñÂüéÂ∏ÇÔºâÈÄöÂ∏∏‰ΩçÊñºÁï∂ÂâçÁØÄÈªûÁöÑÈôÑËøëÔºåÈÄôË°®ÊòéÊ†πÊìöÁï∂Ââç‰ΩçÁΩÆË™øÊï¥ÈÅ∏ÊìáÁöÑÊΩõÂú®Â•ΩËôï„ÄÇ(2) ÊúâÊïàÂú∞Ëß£Ê±∫ TSP ÈúÄË¶ÅÁ©©ÂÅ•Âú∞ËøΩËπ§Êú™ÊãúË®™ÁöÑÁØÄÈªûÔºå‰∏¶‰øùË≠âÁ∞°ÊΩîÁöÑÂàÜÁµÑÁ≠ñÁï•„ÄÇÊ†πÊìöÈÄô‰∫õË¶ãËß£ÔºåÊàëÂÄëÂª∫Ë≠∞Êï¥ÂêàÂèó Hypernetworks ÂïüÁôºÁöÑÂèØÂ≠∏ÁøíÈÅ∏ÊìáÂ±§Ôºå‰ª•Ê†πÊìöÁï∂Ââç‰ΩçÁΩÆÂÑ™ÂÖàÈÅ∏ÊìáÔºå‰ª•ÂèäÂèóÊúüÊúõÊúÄÂ§ßÂåñÊºîÁÆóÊ≥ïÂïüÁôºÁöÑÂèØÂ≠∏ÁøíËøë‰ººÂàÜÁæ§ÊºîÁÆóÊ≥ïÔºå‰ª•Âà©ÊñºÂ∞çÊú™ÊãúË®™ÁöÑÂüéÂ∏ÇÈÄ≤Ë°åÂàÜÁµÑ„ÄÇÈÄôÂÖ©ÂÄãË≤¢ÁçªÂÖ±ÂêåÂΩ¢Êàê‰∫Ü‰∏ÄÂÄãÈöéÂ±§ÂºèÊñπÊ≥ïÔºåÈÄèÈÅéËÄÉÊÖÆÈÑ∞ËøëÁöÑÂ±ÄÈÉ®ÈÑ∞ÂüüÂíåÂ≠∏Áøí‰∏ÄÁµÑ‰∏≠ÈñìÁØÄÈªûË°®Á§∫Ôºå‰æÜËß£Ê±∫ÁèæÂØ¶ÁöÑ TSP„ÄÇËàáÂÇ≥Áµ±ÂíåÊúÄËøëÁöÑTransformerÊ®°ÂûãÁõ∏ÊØîÔºåÊàëÂÄëÁöÑÈöéÂ±§ÂºèÊñπÊ≥ïÁî¢Áîü‰∫ÜÊõ¥Â•ΩÁöÑÊïàËÉΩÔºåÂ±ïÁ§∫‰∫ÜÈóúÈçµË®≠Ë®àÁöÑÊïàËÉΩ„ÄÇ

##### **Teach CLIP to Develop a Number Sense for Ordinal Regression**
2408.03574v1 by Yao Du, Qiang Zhai, Weihang Dai, Xiaomeng Li

Ordinal regression is a fundamental problem within the field of computer
vision, with customised well-trained models on specific tasks. While
pre-trained vision-language models (VLMs) have exhibited impressive performance
on various vision tasks, their potential for ordinal regression has received
less exploration. In this study, we first investigate CLIP's potential for
ordinal regression, from which we expect the model could generalise to
different ordinal regression tasks and scenarios. Unfortunately, vanilla CLIP
fails on this task, since current VLMs have a well-documented limitation of
encapsulating compositional concepts such as number sense. We propose a simple
yet effective method called NumCLIP to improve the quantitative understanding
of VLMs. We disassemble the exact image to number-specific text matching
problem into coarse classification and fine prediction stages. We discretize
and phrase each numerical bin with common language concept to better leverage
the available pre-trained alignment in CLIP. To consider the inherent
continuous property of ordinal regression, we propose a novel fine-grained
cross-modal ranking-based regularisation loss specifically designed to keep
both semantic and ordinal alignment in CLIP's feature space. Experimental
results on three general ordinal regression tasks demonstrate the effectiveness
of NumCLIP, with 10% and 3.83% accuracy improvement on historical image dating
and image aesthetics assessment task, respectively. Code is publicly available
at https://github.com/xmed-lab/NumCLIP.

ÊëòË¶ÅÔºöÂ∫èÊï∏Ëø¥Ê≠∏ÊòØÈõªËÖ¶Ë¶ñË¶∫È†òÂüü‰∏≠ÁöÑÂü∫Êú¨ÂïèÈ°åÔºåÂÖ∂‰∏≠ÂåÖÂê´ÁâπÂÆö‰ªªÂãô‰∏äÁöÑÂÆ¢Ë£ΩÂåñË®ìÁ∑¥Ê®°Âûã„ÄÇÈõñÁÑ∂È†êÂÖàË®ìÁ∑¥ÁöÑË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (VLM) Â∑≤Âú®ÂêÑÁ®ÆË¶ñË¶∫‰ªªÂãô‰∏≠Â±ïÁèæÂá∫‰ª§‰∫∫Âç∞Ë±°Ê∑±ÂàªÁöÑÊïàËÉΩÔºå‰ΩÜÂ∞çÊñºÂ∫èÊï∏Ëø¥Ê≠∏ÁöÑÊΩõÂäõÂâáËºÉÂ∞ëÊé¢Á¥¢„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖàÊé¢Ë®é CLIP Â∞çÂ∫èÊï∏Ëø¥Ê≠∏ÁöÑÊΩõÂäõÔºåÊàëÂÄëÈ†êÊúüÊ®°ÂûãÂèØ‰ª•Ê¶ÇÊã¨Âà∞‰∏çÂêåÁöÑÂ∫èÊï∏Ëø¥Ê≠∏‰ªªÂãôÂíåÂ†¥ÊôØ„ÄÇ‰∏çÂπ∏ÁöÑÊòØÔºåÈ¶ôËçâ CLIP Âú®Ê≠§‰ªªÂãô‰∏äÂ§±ÊïóÔºåÂõ†ÁÇ∫ÁõÆÂâçÁöÑ VLM Â∑≤ÊúâÊñá‰ª∂Ë®òËºâÁöÑÈôêÂà∂ÔºåÁÑ°Ê≥ïÂ∞ÅË£ùË´∏Â¶ÇÊï∏Â≠óÊÑüÁ≠âÁµÑÂêàÊ¶ÇÂøµ„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÁ∞°ÂñÆ‰ΩÜÊúâÊïàÁöÑÊñπÊ≥ïÔºåÁ®±ÁÇ∫ NumCLIPÔºå‰ª•ÊîπÂñÑ VLM ÁöÑÈáèÂåñÁêÜËß£„ÄÇÊàëÂÄëÂ∞áÁ≤æÁ¢∫ÂΩ±ÂÉèÂàÜËß£ÁÇ∫Êï∏Â≠óÁâπÂÆöÊñáÂ≠óÊØîÂ∞çÂïèÈ°åÔºåÂÜçÁ¥∞ÂàÜÁÇ∫Á≤óÁï•ÂàÜÈ°ûÂíåÁ≤æÁ¥∞È†êÊ∏¨ÈöéÊÆµ„ÄÇÊàëÂÄëÂ∞áÊØèÂÄãÊï∏Â≠óÁÆ±Èõ¢Êï£Âåñ‰∏¶‰ª•Â∏∏Ë¶ãË™ûË®ÄÊ¶ÇÂøµË°®ÈÅîÔºå‰ª•Êõ¥Â•ΩÂú∞Âà©Áî® CLIP ‰∏≠ÂèØÁî®ÁöÑÈ†êÂÖàË®ìÁ∑¥Â∞çÈΩä„ÄÇÁÇ∫‰∫ÜËÄÉÈáèÂ∫èÊï∏Ëø¥Ê≠∏ÁöÑÂÖßÂú®ÈÄ£Á∫åÁâπÊÄßÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞Á©éÁöÑÁ¥∞Á≤íÂ∫¶Ë∑®Ê®°ÊÖãÊéíÂ∫èÂü∫Á§éÊ≠£ÂâáÂåñÊêçÂ§±ÔºåÁâπÂà•Ë®≠Ë®àÁî®ÊñºÂú® CLIP ÁöÑÁâπÂæµÁ©∫Èñì‰∏≠‰øùÊåÅË™ûÊÑèÂíåÂ∫èÊï∏Â∞çÈΩä„ÄÇÂú®‰∏âÂÄã‰∏ÄËà¨Â∫èÊï∏Ëø¥Ê≠∏‰ªªÂãô‰∏äÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé‰∫Ü NumCLIP ÁöÑÊúâÊïàÊÄßÔºåÂú®Ê≠∑Âè≤ÂΩ±ÂÉèÁ¥ÑÊúÉÂíåÂΩ±ÂÉèÁæéÂ≠∏Ë©ï‰º∞‰ªªÂãô‰∏äÂàÜÂà•ÊèêÈ´ò‰∫Ü 10% Âíå 3.83% ÁöÑÊ∫ñÁ¢∫Â∫¶„ÄÇÁ®ãÂºèÁ¢ºÂ∑≤ÂÖ¨ÈñãÊñº https://github.com/xmed-lab/NumCLIP„ÄÇ

##### **Active Testing of Large Language Model via Multi-Stage Sampling**
2408.03573v1 by Yuheng Huang, Jiayang Song, Qiang Hu, Felix Juefei-Xu, Lei Ma

Performance evaluation plays a crucial role in the development life cycle of
large language models (LLMs). It estimates the model's capability, elucidates
behavior characteristics, and facilitates the identification of potential
issues and limitations, thereby guiding further improvement. Given that LLMs'
diverse task-handling abilities stem from large volumes of training data, a
comprehensive evaluation also necessitates abundant, well-annotated, and
representative test data to assess LLM performance across various downstream
tasks. However, the demand for high-quality test data often entails substantial
time, computational resources, and manual efforts, sometimes causing the
evaluation to be inefficient or impractical. To address these challenges,
researchers propose active testing, which estimates the overall performance by
selecting a subset of test data. Nevertheless, the existing active testing
methods tend to be inefficient, even inapplicable, given the unique new
challenges of LLMs (e.g., diverse task types, increased model complexity, and
unavailability of training data). To mitigate such limitations and expedite the
development cycle of LLMs, in this work, we introduce AcTracer, an active
testing framework tailored for LLMs that strategically selects a small subset
of test data to achieve a nearly optimal performance estimation for LLMs.
AcTracer utilizes both internal and external information from LLMs to guide the
test sampling process, reducing variance through a multi-stage pool-based
active selection. Our experiment results demonstrate that AcTracer achieves
state-of-the-art performance compared to existing methods across various tasks,
with up to 38.83% improvement over previous SOTA.

ÊëòË¶ÅÔºöÊïàËÉΩË©ï‰º∞Âú®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÈñãÁôºÁîüÂëΩÈÄ±Êúü‰∏≠ÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤„ÄÇÂÆÉË©ï‰º∞Ê®°ÂûãÁöÑËÉΩÂäõ„ÄÅÈó°ÊòéË°åÁÇ∫ÁâπÂæµÔºå‰∏¶ÂçîÂä©ÊâæÂá∫ÊΩõÂú®ÁöÑÂïèÈ°åÂíåÈôêÂà∂ÔºåÈÄ≤ËÄåÂºïÂ∞éÂæåÁ∫åÁöÑÊîπÂñÑ„ÄÇÁî±Êñº LLM ËôïÁêÜÂêÑÁ®Æ‰ªªÂãôÁöÑËÉΩÂäõÊ∫êËá™ÊñºÂ§ßÈáèÁöÑË®ìÁ∑¥Ë≥áÊñôÔºåÂõ†Ê≠§ÂÖ®Èù¢ÁöÑË©ï‰º∞‰πüÈúÄË¶ÅË±êÂØå„ÄÅÊ®ôË®ªÂÆåÂñÑ‰∏îÂÖ∑‰ª£Ë°®ÊÄßÁöÑÊ∏¨Ë©¶Ë≥áÊñôÔºåÊâçËÉΩË©ï‰º∞ LLM Âú®ÂêÑÁ®Æ‰∏ãÊ∏∏‰ªªÂãô‰∏≠ÁöÑÊïàËÉΩ„ÄÇÁÑ∂ËÄåÔºåÈ´òÂìÅË≥™Ê∏¨Ë©¶Ë≥áÊñôÁöÑÈúÄÊ±ÇÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèÁöÑÊôÇÈñì„ÄÅÈÅãÁÆóË≥áÊ∫êÂíå‰∫∫Â∑•ÔºåÊúâÊôÇÊúÉÂ∞éËá¥Ë©ï‰º∞ÊïàÁéá‰ΩéËêΩÊàñ‰∏çÂàáÂØ¶Èöõ„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õÊåëÊà∞ÔºåÁ†îÁ©∂‰∫∫Âì°ÊèêÂá∫‰∏ªÂãïÊ∏¨Ë©¶ÔºåÈÄèÈÅéÈÅ∏ÂèñÊ∏¨Ë©¶Ë≥áÊñôÁöÑÂ≠êÈõÜ‰æÜË©ï‰º∞Êï¥È´îÊïàËÉΩ„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÁèæÊúâÁöÑ‰∏ªÂãïÊ∏¨Ë©¶ÊñπÊ≥ïÂæÄÂæÄÊïàÁéá‰∏çÂΩ∞ÔºåÁîöËá≥ÁÑ°Ê≥ïÈÅ©Áî®ÔºåÂõ†ÁÇ∫ LLM ÂÖ∑ÊúâÁç®ÁâπÁöÑÊñ∞ÊåëÊà∞Ôºà‰æãÂ¶ÇÔºåÂ§öÊ®£ÂåñÁöÑ‰ªªÂãôÈ°ûÂûã„ÄÅÂ¢ûÂä†ÁöÑÊ®°ÂûãË§áÈõúÂ∫¶ÂíåË®ìÁ∑¥Ë≥áÊñôÁöÑ‰∏çÂèØÁî®ÊÄßÔºâ„ÄÇÁÇ∫‰∫ÜÊ∏õËºïÈÄô‰∫õÈôêÂà∂‰∏¶Âä†ÈÄü LLM ÁöÑÈñãÁôºÈÄ±ÊúüÔºåÊàëÂÄëÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÂºïÂÖ•‰∫Ü AcTracerÔºå‰∏ÄÂÄãÂ∞àÁÇ∫ LLM ÈáèË∫´ÊâìÈÄ†ÁöÑ‰∏ªÂãïÊ∏¨Ë©¶Ê°ÜÊû∂ÔºåÂÆÉÁ≠ñÁï•ÊÄßÂú∞ÈÅ∏ÂèñÊ∏¨Ë©¶Ë≥áÊñôÁöÑÂ∞èÂ≠êÈõÜÔºå‰ª•ÈÅîÊàê LLM Ëøë‰πéÊúÄ‰Ω≥ÁöÑÊïàËÉΩË©ï‰º∞„ÄÇAcTracer Âà©Áî®‰æÜËá™ LLM ÁöÑÂÖßÈÉ®ÂíåÂ§ñÈÉ®Ë≥áË®ä‰æÜÂºïÂ∞éÊ∏¨Ë©¶ÊäΩÊ®£Á®ãÂ∫èÔºåÈÄèÈÅéÂ§öÈöéÊÆµÂü∫ÊñºÊ±†ÁöÑ‰∏ªÂãïÈÅ∏Êìá‰æÜÈôç‰ΩéËÆäÁï∞„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË≠âÊòéÔºåAcTracer Âú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠ÈÉΩÈÅîÂà∞ËàáÁèæÊúâÊñπÊ≥ïÁõ∏ÊØîÁöÑÊúÄÊñ∞ÊïàËÉΩÔºåÁõ∏ËºÉÊñºÂÖàÂâçÁöÑ SOTAÔºåÈÄ≤Ê≠•ÂπÖÂ∫¶È´òÈÅî 38.83%„ÄÇ

##### **2D-OOB: Attributing Data Contribution through Joint Valuation Framework**
2408.03572v1 by Yifan Sun, Jingyan Shen, Yongchan Kwon

Data valuation has emerged as a powerful framework to quantify the
contribution of each datum to the training of a particular machine learning
model. However, it is crucial to recognize that the quality of various cells
within a single data point can vary greatly in practice. For example, even in
the case of an abnormal data point, not all cells are necessarily noisy. The
single scalar valuation assigned by existing methods blurs the distinction
between noisy and clean cells of a data point, thereby compromising the
interpretability of the valuation. In this paper, we propose 2D-OOB, an
out-of-bag estimation framework for jointly determining helpful (or
detrimental) samples, as well as the particular cells that drive them. Our
comprehensive experiments demonstrate that 2D-OOB achieves state-of-the-art
performance across multiple use cases, while being exponentially faster. 2D-OOB
excels in detecting and rectifying fine-grained outliers at the cell level, as
well as localizing backdoor triggers in data poisoning attacks.

ÊëòË¶ÅÔºöË≥áÊñôË©ï‰º∞Â∑≤ÊàêÁÇ∫ÈáèÂåñÊØèÂÄãË≥áÊñôÂ∞çÁâπÂÆöÊ©üÂô®Â≠∏ÁøíÊ®°ÂûãË®ìÁ∑¥Ë≤¢ÁçªÁöÑÂº∑Â§ßÊ°ÜÊû∂„ÄÇÁÑ∂ËÄåÔºåËá≥ÈóúÈáçË¶ÅÁöÑÊòØË¶ÅË™çË≠òÂà∞ÂñÆ‰∏ÄË≥áÊñôÈªû‰∏≠ÂêÑÂÄãÂñÆÂÖÉÁöÑÂìÅË≥™Âú®ÂØ¶Âãô‰∏äÂèØËÉΩÂ∑ÆÁï∞ÂæàÂ§ß„ÄÇËàâ‰æã‰æÜË™™ÔºåÂç≥‰ΩøÂú®Áï∞Â∏∏Ë≥áÊñôÈªûÁöÑÊÉÖÊ≥Å‰∏ãÔºå‰πü‰∏¶ÈùûÊâÄÊúâÂñÆÂÖÉÈÉΩÂøÖÁÑ∂ÊúâÈõúË®ä„ÄÇÁèæÊúâÊñπÊ≥ïÊâÄÂàÜÈÖçÁöÑÂñÆ‰∏ÄÊ®ôÈáèË©ï‰º∞Ê®°Á≥ä‰∫ÜË≥áÊñôÈªû‰∏≠ÈõúË®äÂñÆÂÖÉËàá‰πæÊ∑®ÂñÆÂÖÉ‰πãÈñìÁöÑÂçÄÂà•ÔºåÂõ†ËÄåÊêçÂÆ≥‰∫ÜË©ï‰º∞ÁöÑÂèØËß£ÈáãÊÄß„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ 2D-OOBÔºå‰∏ÄÂÄãË¢ãÂ§ñ‰º∞Ë®àÊ°ÜÊû∂ÔºåÁî®ÊñºÂÖ±ÂêåÁ¢∫ÂÆöÊúâÂπ´Âä©ÔºàÊàñÊúâÂÆ≥ÔºâÁöÑÊ®£Êú¨Ôºå‰ª•ÂèäÈ©ÖÂãïÂÆÉÂÄëÁöÑÁâπÂÆöÂñÆÂÖÉ„ÄÇÊàëÂÄëÁöÑÂÖ®Èù¢ÂØ¶È©óË≠âÊòéÔºå2D-OOB Âú®Â§öÂÄã‰ΩøÁî®Ê°à‰æã‰∏≠ÈÉΩÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊïàËÉΩÔºåÂêåÊôÇÈÄüÂ∫¶ÂëàÊåáÊï∏Á¥öÊèêÂçá„ÄÇ2D-OOB Âú®ÂÅµÊ∏¨Âíå‰øÆÊ≠£ÂñÆÂÖÉÂ±§Á¥öÁöÑÁ¥∞Á≤íÂ∫¶Áï∞Â∏∏ÂÄºÊñπÈù¢Ë°®ÁèæÂá∫Ëâ≤ÔºåÂêåÊôÇ‰πüËÉΩÂú®Ë≥áÊñô‰∏≠ÊØíÊîªÊìä‰∏≠ÂÆö‰ΩçÂæåÈñÄËß∏ÁôºÂô®„ÄÇ

##### **Unlocking Exocentric Video-Language Data for Egocentric Video Representation Learning**
2408.03567v1 by Zi-Yi Dou, Xitong Yang, Tushar Nagarajan, Huiyu Wang, Jing Huang, Nanyun Peng, Kris Kitani, Fu-Jen Chu

We present EMBED (Egocentric Models Built with Exocentric Data), a method
designed to transform exocentric video-language data for egocentric video
representation learning. Large-scale exocentric data covers diverse activities
with significant potential for egocentric learning, but inherent disparities
between egocentric and exocentric data pose challenges in utilizing one view
for the other seamlessly. Egocentric videos predominantly feature close-up
hand-object interactions, whereas exocentric videos offer a broader perspective
on human activities. Additionally, narratives in egocentric datasets are
typically more action-centric and closely linked with the visual content, in
contrast to the narrative styles found in exocentric datasets. To address these
challenges, we employ a data transformation framework to adapt exocentric data
for egocentric training, focusing on identifying specific video clips that
emphasize hand-object interactions and transforming narration styles to align
with egocentric perspectives. By applying both vision and language style
transfer, our framework creates a new egocentric dataset derived from
exocentric video-language data. Through extensive evaluations, we demonstrate
the effectiveness of EMBED, achieving state-of-the-art results across various
egocentric downstream tasks, including an absolute improvement of 4.7% on the
Epic-Kitchens-100 multi-instance retrieval and 6.2% on the EGTEA classification
benchmarks in zero-shot settings. Furthermore, EMBED enables egocentric
video-language models to perform competitively in exocentric tasks. Finally, we
showcase EMBED's application across various exocentric datasets, exhibiting
strong generalization capabilities when applied to different exocentric
datasets.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄëÊèêÂá∫ EMBEDÔºà‰ª•Áï∞ÂøÉË≥áÊñôÂª∫ÊßãÁöÑËá™ÂøÉÊ®°ÂûãÔºâÔºå‰∏ÄÁ®ÆÊñπÊ≥ï
Êó®Âú®Â∞áÁï∞ÂøÉÂΩ±ÁâáË™ûË®ÄË≥áÊñôËΩâÊèõÁÇ∫Ëá™ÂøÉÂΩ±Áâá
Ë°®ÂæµÂ≠∏Áøí„ÄÇÂ§ßË¶èÊ®°Áï∞ÂøÉË≥áÊñôÊ∂µËìãÂêÑÁ®ÆÊ¥ªÂãï
ÂÖ∑ÊúâËá™ÂøÉÂ≠∏ÁøíÁöÑÊΩõÂäõÔºå‰ΩÜÁï∞ÂøÉËàáËá™ÂøÉË≥áÊñô‰πãÈñìÁöÑÂõ∫ÊúâÂ∑ÆÁï∞
Âú®ÁÑ°Á∏´‰ΩøÁî®‰∏ÄÂÄãË¶ñËßíÊôÇÈÄ†ÊàêÊåëÊà∞„ÄÇËá™ÂøÉÂΩ±Áâá‰∏ªË¶ÅÁâπÂØ´
ÊâãÈÉ®Áâ©È´î‰∫íÂãïÔºåËÄåÁï∞ÂøÉÂΩ±ÁâáÂâáÊèê‰æõÊõ¥Âª£Ê≥õÁöÑ‰∫∫È°ûÊ¥ªÂãïËßÄÈªû„ÄÇÊ≠§Â§ñÔºåËá™ÂøÉË≥áÊñôÈõÜ‰∏≠ÁöÑÊïòËø∞
ÈÄöÂ∏∏Êõ¥‰ª•Âãï‰ΩúÁÇ∫‰∏≠ÂøÉÔºå‰∏¶‰∏îËàáË¶ñË¶∫ÂÖßÂÆπÁ∑äÂØÜÈÄ£ÁµêÔºåÈÄôËàáÁï∞ÂøÉË≥áÊñôÈõÜ‰∏≠ÁôºÁèæÁöÑÊïò‰∫ãÈ¢®Ê†ºÂΩ¢ÊàêÂ∞çÊØî„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÈÄô‰∫õ
ÊåëÊà∞ÔºåÊàëÂÄëÊé°Áî®Ë≥áÊñôËΩâÊèõÊ°ÜÊû∂‰æÜË™øÊï¥Áï∞ÂøÉË≥áÊñô
Áî®ÊñºËá™ÂøÉË®ìÁ∑¥ÔºåÂ∞àÊ≥®ÊñºË≠òÂà•Âº∑Ë™øÊâãÈÉ®Áâ©È´î‰∫íÂãï‰∏¶ËΩâÊèõÊïò‰∫ãÈ¢®Ê†º‰ª•ËàáËá™ÂøÉËßÄÈªû‰∏ÄËá¥ÁöÑÁâπÂÆöÂΩ±ÁâáÁâáÊÆµ„ÄÇÈÄèÈÅéÊáâÁî®Ë¶ñË¶∫ÂíåË™ûË®ÄÈ¢®Ê†º
ËΩâÁßªÔºåÊàëÂÄëÁöÑÊ°ÜÊû∂Âª∫Á´ã‰∏ÄÂÄãÊñ∞ÁöÑËá™ÂøÉË≥áÊñôÈõÜÔºåÊ∫êËá™
Áï∞ÂøÉÂΩ±ÁâáË™ûË®ÄË≥áÊñô„ÄÇÈÄèÈÅéÂª£Ê≥õÁöÑË©ï‰º∞ÔºåÊàëÂÄëË≠âÊòé EMBED ÁöÑÊúâÊïàÊÄßÔºåÂú®ÂêÑÁ®Æ
Ëá™ÂøÉ‰∏ãÊ∏∏‰ªªÂãô‰∏≠ÈÅîÊàêÊúÄÂÖàÈÄ≤ÁöÑÁµêÊûúÔºåÂåÖÊã¨Âú® Epic-Kitchens-100 Â§öÂØ¶‰æãÊ™¢Á¥¢‰∏≠ÁµïÂ∞çÊîπÂñÑ 4.7%Ôºå‰ª•ÂèäÂú® EGTEA ÂàÜÈ°û‰∏≠ÊîπÂñÑ 6.2%
Èõ∂Ê¨°Ë®≠ÂÆö‰∏≠ÁöÑÂü∫Ê∫ñ„ÄÇÊ≠§Â§ñÔºåEMBED ‰ΩøËá™ÂøÉ
ÂΩ±ÁâáË™ûË®ÄÊ®°ÂûãËÉΩÂ§†Âú®Áï∞ÂøÉ‰ªªÂãô‰∏≠ÂÖ∑ÊúâÁ´∂Áà≠Âäõ„ÄÇÊúÄÂæåÔºåÊàëÂÄë
Â±ïÁ§∫ EMBED Âú®ÂêÑÁ®ÆÁï∞ÂøÉË≥áÊñôÈõÜ‰∏≠ÁöÑÊáâÁî®ÔºåÂú®ÊáâÁî®Êñº‰∏çÂêåÁï∞ÂøÉÊôÇÂ±ïÁèæÂº∑Â§ßÁöÑÊ¶ÇÂåñËÉΩÂäõ
Ë≥áÊñôÈõÜ„ÄÇ</paragraph>

##### **A Comparison of LLM Finetuning Methods & Evaluation Metrics with Travel Chatbot Use Case**
2408.03562v1 by Sonia Meyer, Shreya Singh, Bertha Tam, Christopher Ton, Angel Ren

This research compares large language model (LLM) fine-tuning methods,
including Quantized Low Rank Adapter (QLoRA), Retrieval Augmented fine-tuning
(RAFT), and Reinforcement Learning from Human Feedback (RLHF), and additionally
compared LLM evaluation methods including End to End (E2E) benchmark method of
"Golden Answers", traditional natural language processing (NLP) metrics, RAG
Assessment (Ragas), OpenAI GPT-4 evaluation metrics, and human evaluation,
using the travel chatbot use case. The travel dataset was sourced from the the
Reddit API by requesting posts from travel-related subreddits to get
travel-related conversation prompts and personalized travel experiences, and
augmented for each fine-tuning method. We used two pretrained LLMs utilized for
fine-tuning research: LLaMa 2 7B, and Mistral 7B. QLoRA and RAFT are applied to
the two pretrained models. The inferences from these models are extensively
evaluated against the aforementioned metrics. The best model according to human
evaluation and some GPT-4 metrics was Mistral RAFT, so this underwent a
Reinforcement Learning from Human Feedback (RLHF) training pipeline, and
ultimately was evaluated as the best model. Our main findings are that: 1)
quantitative and Ragas metrics do not align with human evaluation, 2) Open AI
GPT-4 evaluation most aligns with human evaluation, 3) it is essential to keep
humans in the loop for evaluation because, 4) traditional NLP metrics
insufficient, 5) Mistral generally outperformed LLaMa, 6) RAFT outperforms
QLoRA, but still needs postprocessing, 7) RLHF improves model performance
significantly. Next steps include improving data quality, increasing data
quantity, exploring RAG methods, and focusing data collection on a specific
city, which would improve data quality by narrowing the focus, while creating a
useful product.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂ÊØîËºÉ‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂæÆË™øÊñπÊ≥ïÔºåÂåÖÊã¨ÈáèÂåñ‰ΩéÁß©ÈÅ©ÈÖçÂô® (QLoRA)„ÄÅÊ™¢Á¥¢Êì¥Â¢ûÂæÆË™ø (RAFT) Âíå‰∫∫È°ûÂõûÈ•ãÂº∑ÂåñÂ≠∏Áøí (RLHF)Ôºå‰∏¶È°çÂ§ñÊØîËºÉ‰∫Ü LLM Ë©ï‰º∞ÊñπÊ≥ïÔºåÂåÖÊã¨„ÄåÈªÉÈáëÁ≠îÊ°à„ÄçÁöÑÁ´ØÂ∞çÁ´Ø (E2E) Âü∫Ê∫ñÊñπÊ≥ï„ÄÅÂÇ≥Áµ±Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÊåáÊ®ô„ÄÅRAG Ë©ï‰º∞ (Ragas)„ÄÅOpenAI GPT-4 Ë©ï‰º∞ÊåáÊ®ôÂíå‰∫∫È°ûË©ï‰º∞Ôºå‰∏¶‰ΩøÁî®ÊóÖÈÅäËÅäÂ§©Ê©üÂô®‰∫∫Áî®‰æã„ÄÇÊóÖÈÅäË≥áÊñôÈõÜ‰æÜËá™ Reddit APIÔºåÈÄèÈÅéË¶ÅÊ±ÇÊóÖÈÅäÁõ∏ÈóúÂ≠êÁâàÂ°äÁöÑË≤ºÊñá‰æÜÂèñÂæóÊóÖÈÅäÁõ∏ÈóúÂ∞çË©±ÊèêÁ§∫ÂíåÂÄã‰∫∫ÂåñÊóÖÈÅäÈ´îÈ©óÔºå‰∏¶ÈáùÂ∞çÊØèÁ®ÆÂæÆË™øÊñπÊ≥ïÈÄ≤Ë°åÊì¥ÂÖÖ„ÄÇÊàëÂÄë‰ΩøÁî®‰∫ÜÂÖ©ÂÄãÈ†êË®ìÁ∑¥ LLMÔºåÁî®ÊñºÂæÆË™øÁ†îÁ©∂ÔºöLLaMa 2 7B Âíå Mistral 7B„ÄÇQLoRA Âíå RAFT ÊáâÁî®ÊñºÈÄôÂÖ©ÂÄãÈ†êË®ìÁ∑¥Ê®°Âûã„ÄÇÂª£Ê≥õË©ï‰º∞ÈÄô‰∫õÊ®°ÂûãÁöÑÊé®Ë´ñÁµêÊûúÔºå‰∏¶‰ΩøÁî®‰∏äËø∞ÊåáÊ®ô„ÄÇÊ†πÊìö‰∫∫È°ûË©ï‰º∞Âíå‰∏Ä‰∫õ GPT-4 ÊåáÊ®ôÔºåÊúÄÂ•ΩÁöÑÊ®°ÂûãÊòØ Mistral RAFTÔºåÂõ†Ê≠§ÂÆÉÊé•Âèó‰∫Ü‰∫∫È°ûÂõûÈ•ãÂº∑ÂåñÂ≠∏Áøí (RLHF) Ë®ìÁ∑¥ÊµÅÁ®ãÔºå‰∏¶ÊúÄÁµÇË¢´Ë©ïÁÇ∫ÊúÄ‰Ω≥Ê®°Âûã„ÄÇÊàëÂÄëÁöÑÁôºÁèæ‰∏ªË¶ÅÊúâÔºö1) ÂÆöÈáèÂíå Ragas ÊåáÊ®ôËàá‰∫∫È°ûË©ï‰º∞‰∏ç‰∏ÄËá¥Ôºå2) Open AI GPT-4 Ë©ï‰º∞ÊúÄÁ¨¶Âêà‰∫∫È°ûË©ï‰º∞Ôºå3) ÂøÖÈ†àËÆì‰∫∫È°ûÂèÉËàáË©ï‰º∞ÔºåÂõ†ÁÇ∫ 4) ÂÇ≥Áµ± NLP ÊåáÊ®ô‰∏çË∂≥Ôºå5) Mistral ÈÄöÂ∏∏ÂÑ™Êñº LLaMaÔºå6) RAFT ÂÑ™Êñº QLoRAÔºå‰ΩÜ‰ªçÈúÄË¶ÅÂæåËôïÁêÜÔºå7) RLHF Â§ßÂπÖÊèêÂçá‰∫ÜÊ®°ÂûãÊïàËÉΩ„ÄÇÂæåÁ∫åÊ≠•È©üÂåÖÊã¨ÊèêÂçáË≥áÊñôÂìÅË≥™„ÄÅÂ¢ûÂä†Ë≥áÊñôÊï∏Èáè„ÄÅÊé¢Á¥¢ RAG ÊñπÊ≥ïÔºå‰ª•ÂèäÂ∞àÊ≥®ÊñºÁâπÂÆöÂüéÂ∏ÇÁöÑË≥áÊñôÊî∂ÈõÜÔºåÈÄôÂ∞áÈÄèÈÅéÁ∏ÆÂ∞èÁÑ¶Èªû‰æÜÊèêÂçáË≥áÊñôÂìÅË≥™ÔºåÂêåÊôÇÂâµÈÄ†ÊúâÁî®ÁöÑÁî¢ÂìÅ„ÄÇ

##### **MPC-Minimized Secure LLM Inference**
2408.03561v1 by Deevashwer Rathee, Dacheng Li, Ion Stoica, Hao Zhang, Raluca Popa

Many inference services based on large language models (LLMs) pose a privacy
concern, either revealing user prompts to the service or the proprietary
weights to the user. Secure inference offers a solution to this problem through
secure multi-party computation (MPC), however, it is still impractical for
modern LLM workload due to the large overhead imposed by MPC. To address this
overhead, we propose Marill, a framework that adapts LLM fine-tuning to
minimize MPC usage during secure inference. Marill introduces high-level
architectural changes during fine-tuning that significantly reduce the number
of expensive operations needed within MPC during inference, by removing some
and relocating others outside MPC without compromising security. As a result,
Marill-generated models are more efficient across all secure inference
protocols and our approach complements MPC-friendly approximations for such
operations. Compared to standard fine-tuning, Marill results in 3.6-11.3x
better runtime and 2.4-6.9x better communication during secure inference across
various MPC settings, while typically preserving over 90% performance across
downstream tasks.

ÊëòË¶ÅÔºöË®±Â§öÂü∫ÊñºÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊé®Ë´ñÊúçÂãôÊúÉÈÄ†ÊàêÈö±ÁßÅÂïèÈ°åÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÊúÉÂêëÊúçÂãôÊè≠Èú≤‰ΩøÁî®ËÄÖÁöÑÊèêÁ§∫ÔºåÊàñÂêë‰ΩøÁî®ËÄÖÊè≠Èú≤Â∞àÊúâÊ¨äÈáç„ÄÇÂÆâÂÖ®Êé®Ë´ñÈÄèÈÅéÂÆâÂÖ®Â§öÊñπÈÅãÁÆó (MPC) Êèê‰æõ‰∫ÜËß£Ê±∫Ê≠§ÂïèÈ°åÁöÑÊñπÊ≥ïÔºåÁÑ∂ËÄåÔºåÁî±Êñº MPC Â∏∂‰æÜÁöÑÈæêÂ§ßÈñãÈä∑ÔºåÂ∞çÊñºÁèæ‰ª£ LLM Â∑•‰ΩúË≤†ËºâËÄåË®ÄÔºåÂÆÉ‰ªçÁÑ∂‰∏çÂàáÂØ¶Èöõ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÈñãÈä∑ÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü MarillÔºå‰∏ÄÂÄãÊ°ÜÊû∂ÔºåÂÆÉÊé°Áî® LLM ÂæÆË™ø‰æÜÂ∞áÂÆâÂÖ®Êé®Ë´ñÊúüÈñìÁöÑ MPC ‰ΩøÁî®ÈáèÈôçËá≥ÊúÄ‰Ωé„ÄÇMarill Âú®ÂæÆË™øÊúüÈñìÂºïÂÖ•‰∫ÜÈ´òÈöéÊû∂ÊßãËÆäÊõ¥ÔºåËóâÁî±ÁßªÈô§‰∏Ä‰∫õÊòÇË≤¥ÈÅãÁÆóÔºå‰∏¶Â∞áÂÖ∂‰ªñÈÅãÁÆóÁßªËá≥ MPC Â§ñÈÉ®ÔºåÂ§ßÂπÖÊ∏õÂ∞ëÂú®Êé®Ë´ñÊúüÈñì MPC ÂÖßÈÉ®ÊâÄÈúÄÁöÑÊòÇË≤¥ÈÅãÁÆóÊï∏ÈáèÔºåÂêåÊôÇ‰∏çÊêçÂÆ≥ÂÆâÂÖ®ÊÄß„ÄÇÂõ†Ê≠§ÔºåMarill ÁîüÊàêÁöÑÊ®°ÂûãÂú®ÊâÄÊúâÂÆâÂÖ®Êé®Ë´ñÂçîÂÆö‰∏≠ÈÉΩÊõ¥ÊúâÊïàÁéáÔºåËÄå‰∏îÊàëÂÄëÁöÑÊñπÊ≥ïË£úÂÖÖ‰∫ÜÈÄô‰∫õÈÅãÁÆóÁöÑ MPC ÂèãÂñÑËøë‰ººÂÄº„ÄÇËàáÊ®ôÊ∫ñÂæÆË™øÁõ∏ÊØîÔºåMarill Âú®ÂêÑÁ®Æ MPC Ë®≠ÂÆö‰∏ãÁöÑÂÆâÂÖ®Êé®Ë´ñ‰∏≠ÔºåÂü∑Ë°åÊôÇÈñìÊîπÂñÑ‰∫Ü 3.6-11.3 ÂÄçÔºåÈÄöË®äÊîπÂñÑ‰∫Ü 2.4-6.9 ÂÄçÔºåÂêåÊôÇÂú®‰∏ãÊ∏∏‰ªªÂãô‰∏≠ÈÄöÂ∏∏‰øùÁïô‰∫ÜË∂ÖÈÅé 90% ÁöÑÊïàËÉΩ„ÄÇ

##### **Empirical Analysis of Large Vision-Language Models against Goal Hijacking via Visual Prompt Injection**
2408.03554v1 by Subaru Kimura, Ryota Tanaka, Shumpei Miyawaki, Jun Suzuki, Keisuke Sakaguchi

We explore visual prompt injection (VPI) that maliciously exploits the
ability of large vision-language models (LVLMs) to follow instructions drawn
onto the input image. We propose a new VPI method, "goal hijacking via visual
prompt injection" (GHVPI), that swaps the execution task of LVLMs from an
original task to an alternative task designated by an attacker. The
quantitative analysis indicates that GPT-4V is vulnerable to the GHVPI and
demonstrates a notable attack success rate of 15.8%, which is an unignorable
security risk. Our analysis also shows that successful GHVPI requires high
character recognition capability and instruction-following ability in LVLMs.

ÊëòË¶ÅÔºöÊàëÂÄëÊé¢Ë®éÊÉ°ÊÑèÂà©Áî®Â§ßÂûãË¶ñË¶∫Ë™ûË®ÄÊ®°Âûã (LVLMs) ÈÅµÂæ™Áπ™Ë£ΩÂú®Ëº∏ÂÖ•ÂΩ±ÂÉè‰∏äÁöÑÊåá‰ª§ÁöÑËÉΩÂäõÁöÑË¶ñË¶∫ÊèêÁ§∫Ê≥®ÂÖ• (VPI)„ÄÇÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÊñ∞ÁöÑ VPI ÊñπÊ≥ïÔºåÂç≥„ÄåÈÄèÈÅéË¶ñË¶∫ÊèêÁ§∫Ê≥®ÂÖ•ÈÄ≤Ë°åÁõÆÊ®ôÂä´ÊåÅ„Äç(GHVPI)ÔºåÂÆÉÂ∞á LVLMs ÁöÑÂü∑Ë°å‰ªªÂãôÂæûÂéüÂßã‰ªªÂãôÊõøÊèõÁÇ∫ÊîªÊìäËÄÖÊåáÂÆöÁöÑÊõø‰ª£‰ªªÂãô„ÄÇÂÆöÈáèÂàÜÊûêË°®Êòé GPT-4V ÂÆπÊòìÂèóÂà∞ GHVPI ÊîªÊìäÔºå‰∏¶Â±ïÁ§∫Âá∫È°ØËëóÁöÑ 15.8% ÊîªÊìäÊàêÂäüÁéáÔºåÈÄôÊòØ‰∏ÄÂÄã‰∏çÂÆπÂøΩË¶ñÁöÑÂÆâÂÖ®È¢®Èö™„ÄÇÊàëÂÄëÁöÑÂàÜÊûêÈÇÑË°®ÊòéÔºåÊàêÂäüÁöÑ GHVPI ÈúÄË¶Å LVLMs ÂÖ∑ÂÇôÈ´òÂ≠óÁ¨¶Ëæ®Ë≠òËÉΩÂäõÂíåÈÅµÂæ™Êåá‰ª§ÁöÑËÉΩÂäõ„ÄÇ

##### **Unlocking the Non-Native Language Context Limitation: Native Language Prompting Facilitates Knowledge Elicitation**
2408.03544v1 by Baixuan Li, Yunlong Fan, Zhiqiang Gao

Multilingual large language models (MLLMs) struggle to answer questions posed
in non-dominant languages, even though they have already acquired the relevant
knowledge from their dominant language corpus. In contrast, human multilinguals
can overcome this issue by invoking the relatively rich knowledge acquired from
native language texts through Positive Native Language Transfer (PNLT).
Inspired by this, we analogize the dominant language of MLLMs to the native
language of human multilinguals, and propose Native Language Prompting (NatLan)
to simulate the PNLT observed in human multilinguals. It explicitly creates
native language contexts for MLLMs to facilitate the elicitation of the rich
native language knowledge during question-answering, unlocking the limitations
imposed by non-native language contexts on the effective application of
knowledge. By employing multi-MLLM collaboration, NatLan reduces the workload
on each MLLM in simulating PNLT and refines semantic transfer. On the C-Eval
benchmark, NatLan provides up to a 10.1% average accuracy improvement and up to
a 5.0% increase in the hard-level subset across five MLLMs, surpassing all
top-notch related methods. Our code is available at
https://github.com/AnonyNLP/NatLan.

ÊëòË¶ÅÔºöÂ§öË™ûË®ÄÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) Èõ£‰ª•ÂõûÁ≠î‰ª•Èùû‰∏ªË¶ÅË™ûË®ÄÊèêÂá∫ÁöÑÂïèÈ°åÔºåÂç≥‰ΩøÂÆÉÂÄëÂ∑≤Á∂ìÂæûÂÖ∂‰∏ªË¶ÅË™ûË®ÄË™ûÊñôÂ∫´‰∏≠Áç≤ÂæóÁõ∏ÈóúÁü•Ë≠ò„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºå‰∫∫È°ûÂ§öË™ûË®Ä‰ΩøÁî®ËÄÖÂèØ‰ª•ÈÄèÈÅéË™øÁî®ÂæûÊØçË™ûÊñáÊú¨‰∏≠Áç≤ÂæóÁöÑÁõ∏Â∞çË±êÂØåÁü•Ë≠ò‰æÜÂÖãÊúçÈÄôÂÄãÂïèÈ°åÔºåÈÄèÈÅéÊ≠£ÂêëÊØçË™ûËΩâÁßª (PNLT) ÂØ¶Áèæ„ÄÇÂèóÂà∞Ê≠§ÂïüÁôºÔºåÊàëÂÄëÂ∞á MLLM ÁöÑ‰∏ªË¶ÅË™ûË®ÄÈ°ûÊØîÁÇ∫‰∫∫È°ûÂ§öË™ûË®Ä‰ΩøÁî®ËÄÖÁöÑÊØçË™ûÔºå‰∏¶ÊèêÂá∫ÊØçË™ûÊèêÁ§∫ (NatLan) ‰æÜÊ®°Êì¨‰∫∫È°ûÂ§öË™ûË®Ä‰ΩøÁî®ËÄÖ‰∏≠ËßÄÂØüÂà∞ÁöÑ PNLT„ÄÇÂÆÉÊòéÁ¢∫ÁÇ∫ MLLM Âª∫Á´ãÊØçË™ûËÑàÁµ°Ôºå‰ª•Âà©ÊñºÂú®ÂïèÁ≠îÈÅéÁ®ã‰∏≠ÂºïÂá∫Ë±êÂØåÁöÑÊØçË™ûÁü•Ë≠òÔºåÊâìÁ†¥ÈùûÊØçË™ûËÑàÁµ°Â∞çÁü•Ë≠òÊúâÊïàÊáâÁî®ÈÄ†ÊàêÁöÑÈôêÂà∂„ÄÇÈÄèÈÅéÊé°Áî®Â§ö MLLM Âçî‰ΩúÔºåNatLan Ê∏õÂ∞ë‰∫ÜÊØèÂÄã MLLM Âú®Ê®°Êì¨ PNLT ÊôÇÁöÑÂ∑•‰ΩúÈáèÔºå‰∏¶ÊîπÂñÑ‰∫ÜË™ûÁæ©ËΩâÁßª„ÄÇÂú® C-Eval Âü∫Ê∫ñÊ∏¨Ë©¶‰∏≠ÔºåNatLan Âú®‰∫îÂÄã MLLM ‰∏≠Êèê‰æõ‰∫ÜÈ´òÈÅî 10.1% ÁöÑÂπ≥ÂùáÊ∫ñÁ¢∫Â∫¶ÊèêÂçáÔºå‰ª•ÂèäÈõ£Â∫¶Â≠êÈõÜÈ´òÈÅî 5.0% ÁöÑÊèêÂçáÔºåË∂ÖË∂äÊâÄÊúâÈ†ÇÂ∞ñÁõ∏ÈóúÊñπÊ≥ï„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂèØÊñº https://github.com/AnonyNLP/NatLan ÂèñÂæó„ÄÇ

##### **EXAONE 3.0 7.8B Instruction Tuned Language Model**
2408.03541v2 by LG AI Research, :, Soyoung An, Kyunghoon Bae, Eunbi Choi, Stanley Jungkyu Choi, Yemuk Choi, Seokhee Hong, Yeonjung Hong, Junwon Hwang, Hyojin Jeon, Gerrard Jeongwon Jo, Hyunjik Jo, Jiyeon Jung, Yountae Jung, Euisoon Kim, Hyosang Kim, Joonkee Kim, Seonghwan Kim, Soyeon Kim, Sunkyoung Kim, Yireun Kim, Youchul Kim, Edward Hwayoung Lee, Haeju Lee, Honglak Lee, Jinsik Lee, Kyungmin Lee, Moontae Lee, Seungjun Lee, Woohyung Lim, Sangha Park, Sooyoun Park, Yongmin Park, Boseong Seo, Sihoon Yang, Heuiyeen Yeen, Kyungjae Yoo, Hyeongu Yun

We introduce EXAONE 3.0 instruction-tuned language model, the first open
model in the family of Large Language Models (LLMs) developed by LG AI
Research. Among different model sizes, we publicly release the 7.8B
instruction-tuned model to promote open research and innovations. Through
extensive evaluations across a wide range of public and in-house benchmarks,
EXAONE 3.0 demonstrates highly competitive real-world performance with
instruction-following capability against other state-of-the-art open models of
similar size. Our comparative analysis shows that EXAONE 3.0 excels
particularly in Korean, while achieving compelling performance across general
tasks and complex reasoning. With its strong real-world effectiveness and
bilingual proficiency, we hope that EXAONE keeps contributing to advancements
in Expert AI. Our EXAONE 3.0 instruction-tuned model is available at
https://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct

ÊëòË¶ÅÔºöÊàëÂÄëÊé®Âá∫ EXAONE 3.0 Êåá‰ª§Ë™øÊï¥Ë™ûË®ÄÊ®°ÂûãÔºåÊòØ LG AI Á†îÁ©∂ÈñãÁôºÁöÑÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÂÆ∂Êóè‰∏≠ÁöÑÁ¨¨‰∏ÄÂÄãÈñãÊîæÊ®°Âûã„ÄÇÂú®‰∏çÂêåÁöÑÊ®°ÂûãË¶èÊ®°‰∏≠ÔºåÊàëÂÄëÂÖ¨ÈñãÁôºÂ∏É 7.8B Êåá‰ª§Ë™øÊï¥Ê®°ÂûãÔºå‰ª•‰øÉÈÄ≤ÈñãÊîæÁ†îÁ©∂ÂíåÂâµÊñ∞„ÄÇÈÄèÈÅéÂ∞çÂª£Ê≥õÁöÑÂÖ¨ÈñãÂíåÂÖßÈÉ®Âü∫Ê∫ñÈÄ≤Ë°åÂª£Ê≥õÁöÑË©ï‰º∞ÔºåEXAONE 3.0 Â±ïÁèæ‰∫ÜÈ´òÂ∫¶Á´∂Áà≠ÁöÑÁúüÂØ¶‰∏ñÁïåÊïàËÉΩÔºå‰∏¶ÂÖ∑ÂÇôËàáÂÖ∂‰ªñÈ°û‰ººË¶èÊ®°ÁöÑÊúÄÊñ∞ÈñãÊîæÊ®°ÂûãÁõ∏ÊäóË°°ÁöÑÊåá‰ª§ÈÅµÂæ™ËÉΩÂäõ„ÄÇÊàëÂÄëÁöÑÊØîËºÉÂàÜÊûêÈ°ØÁ§∫ÔºåEXAONE 3.0 ÁâπÂà•ÊìÖÈï∑ÈüìË™ûÔºåÂêåÊôÇÂú®‰∏ÄËà¨‰ªªÂãôÂíåË§áÈõúÊé®ÁêÜ‰∏≠ÈÉΩËÉΩÈÅîÂà∞‰ª§‰∫∫‰ø°ÊúçÁöÑÊïàËÉΩ„ÄÇÊÜëËóâÂÖ∂Âº∑Â§ßÁöÑÁúüÂØ¶‰∏ñÁïåÊïàËÉΩÂíåÈõôË™ûËÉΩÂäõÔºåÊàëÂÄëÂ∏åÊúõ EXAONE ËÉΩÊåÅÁ∫åÁÇ∫Â∞àÂÆ∂ AI ÁöÑÈÄ≤Ê≠•ÂÅöÂá∫Ë≤¢Áçª„ÄÇÊàëÂÄëÁöÑ EXAONE 3.0 Êåá‰ª§Ë™øÊï¥Ê®°ÂûãÂèØÂú® https://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct ÂèñÂæó

##### **Lifelong Personalized Low-Rank Adaptation of Large Language Models for Recommendation**
2408.03533v1 by Jiachen Zhu, Jianghao Lin, Xinyi Dai, Bo Chen, Rong Shan, Jieming Zhu, Ruiming Tang, Yong Yu, Weinan Zhang

We primarily focus on the field of large language models (LLMs) for
recommendation, which has been actively explored recently and poses a
significant challenge in effectively enhancing recommender systems with logical
reasoning abilities and open-world knowledge. Current mainstream efforts mainly
center around injecting personalized information from recommendation models
into LLMs by customizing input templates or aligning representations between
semantic and recommendation spaces at the prediction layer. However, they face
three significant limitations: (1) LoRA is mostly used as a core component in
existing works, but personalization is not well established in LoRA parameters
as the LoRA matrix shared by every user may not cater to different users'
characteristics, leading to suboptimal performance. (2) Although lifelong
personalized behavior sequences are ideal for personalization, their use raises
effectiveness and efficiency issues since LLMs require escalating training and
inference time to extend text lengths. (3) Existing approaches aren't scalable
for large datasets due to training efficiency constraints. Thus, LLMs only see
a small fraction of the datasets (e.g., less than 10%) instead of the whole
datasets, limiting their exposure to the full training space. To address these
problems, we propose RecLoRA. This model incorporates a Personalized LoRA
module that maintains independent LoRAs for different users and a Long-Short
Modality Retriever that retrieves different history lengths for different
modalities, significantly improving performance while adding minimal time cost.
Furthermore, we design a Few2Many Learning Strategy, using a conventional
recommendation model as a lens to magnify small training spaces to full spaces.
Extensive experiments on public datasets demonstrate the efficacy of our
RecLoRA compared to existing baseline models.

ÊëòË¶ÅÔºöÊàëÂÄë‰∏ªË¶ÅÈóúÊ≥®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Êé®Ëñ¶È†òÂüüÁöÑÊáâÁî®ÔºåÈÄôÊòØ‰∏ÄÂÄãËøëÊúüÁ©çÊ•µÊé¢Á¥¢ÁöÑÈ†òÂüüÔºå‰∏¶Â∞çÊúâÊïàÊèêÂçáÊé®Ëñ¶Á≥ªÁµ±ÁöÑÈÇèËºØÊé®ÁêÜËÉΩÂäõÂíåÈñãÊîæ‰∏ñÁïåÁü•Ë≠òÊßãÊàêÈáçÂ§ßÊåëÊà∞„ÄÇÁõÆÂâçÁöÑÊôÆÈÅçÂÅöÊ≥ï‰∏ªË¶ÅÂúçÁπûËëóÈÄèÈÅéËá™Ë®ÇËº∏ÂÖ•ÁØÑÊú¨ÊàñÂú®È†êÊ∏¨Â±§Â∞çÈΩäË™ûÊÑèÂíåÊé®Ëñ¶Á©∫ÈñìÁöÑË°®ÂæµÔºåÂ∞áÊé®Ëñ¶Ê®°Âûã‰∏≠ÁöÑÂÄã‰∫∫ÂåñË≥áË®äÊ≥®ÂÖ• LLM„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÈù¢Ëá®‰∏âÈ†ÖÈáçÂ§ßÁöÑÈôêÂà∂Ôºö(1) LoRA ‰∏ªË¶ÅÁî®‰ΩúÁèæÊúâ‰ΩúÂìÅ‰∏≠ÁöÑÊ†∏ÂøÉÂÖÉ‰ª∂Ôºå‰ΩÜÂÄã‰∫∫Âåñ‰∏¶Êú™Âú® LoRA ÂèÉÊï∏‰∏≠Âª∫Á´ãÂÆåÂñÑÔºåÂõ†ÁÇ∫ÊØèÂÄã‰ΩøÁî®ËÄÖÂÖ±Áî®ÁöÑ LoRA Áü©Èô£ÂèØËÉΩÁÑ°Ê≥ïÊªøË∂≥‰∏çÂêå‰ΩøÁî®ËÄÖÁöÑÁâπÊÄßÔºåÂ∞éËá¥ÊïàËÉΩ‰∏ç‰Ω≥„ÄÇ(2) ÂÑòÁÆ°ÁµÇË∫´ÂÄã‰∫∫ÂåñË°åÁÇ∫Â∫èÂàóÊòØÂÄã‰∫∫ÂåñÁöÑÁêÜÊÉ≥ÈÅ∏ÊìáÔºå‰ΩÜÂÆÉÂÄëÁöÑ‰ΩøÁî®ÊúÉÂºïÁôºÊïàËÉΩÂíåÊïàÁéáÂïèÈ°åÔºåÂõ†ÁÇ∫ LLM ÈúÄË¶ÅÂ¢ûÂä†Ë®ìÁ∑¥ÂíåÊé®Ë´ñÊôÇÈñì‰ª•Âª∂‰º∏ÊñáÂ≠óÈï∑Â∫¶„ÄÇ(3) ÁèæÊúâÊñπÊ≥ïÁî±ÊñºË®ìÁ∑¥ÊïàÁéáÈôêÂà∂ÔºåÁÑ°Ê≥ïÊì¥ÂÖÖÂà∞Â§ßÂûãË≥áÊñôÈõÜ„ÄÇÂõ†Ê≠§ÔºåLLM ÂÉÖÁúãÂà∞Ë≥áÊñôÈõÜÁöÑ‰∏ÄÂ∞èÈÉ®ÂàÜÔºà‰æãÂ¶ÇÔºå‰∏çÂà∞ 10%ÔºâÔºåËÄå‰∏çÊòØÊï¥ÂÄãË≥áÊñôÈõÜÔºåÈÄôÈôêÂà∂‰∫ÜÂÆÉÂÄëÊé•Ëß∏ÂÆåÊï¥Ë®ìÁ∑¥Á©∫ÈñìÁöÑÊ©üÊúÉ„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫ RecLoRA„ÄÇÊ≠§Ê®°ÂûãÂåÖÂê´‰∏ÄÂÄãÂÄã‰∫∫Âåñ LoRA Ê®°ÁµÑÔºåÁÇ∫‰∏çÂêåÁöÑ‰ΩøÁî®ËÄÖÁ∂≠Ë≠∑Áç®Á´ãÁöÑ LoRAÔºå‰ª•Âèä‰∏ÄÂÄãÈï∑Áü≠ÊúüÂûãÊÖãÊì∑ÂèñÂô®ÔºåÁÇ∫‰∏çÂêåÁöÑÂûãÊÖãÊì∑Âèñ‰∏çÂêåÁöÑÊ≠∑Âè≤Èï∑Â∫¶ÔºåÂú®Â¢ûÂä†Ê•µÂ∞ëÊôÇÈñìÊàêÊú¨ÁöÑÂêåÊôÇÂ§ßÂπÖÊèêÂçáÊïàËÉΩ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË®≠Ë®à‰∫Ü‰∏ÄÂÄãÂ∞ëÂ∞çÂ§öÂ≠∏ÁøíÁ≠ñÁï•Ôºå‰ΩøÁî®ÂÇ≥Áµ±ÁöÑÊé®Ëñ¶Ê®°Âûã‰ΩúÁÇ∫ÈÄèÈè°ÔºåÂ∞áÂ∞èÂûãË®ìÁ∑¥Á©∫ÈñìÊîæÂ§ßÂà∞ÂÆåÊï¥Á©∫Èñì„ÄÇÂú®ÂÖ¨ÈñãË≥áÊñôÈõÜ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÁöÑ RecLoRA ËàáÁèæÊúâÁöÑÂü∫Ê∫ñÊ®°ÂûãÁõ∏ÊØîÁöÑÊïàËÉΩ„ÄÇ

##### **Exploring the extent of similarities in software failures across industries using LLMs**
2408.03528v2 by Martin Detloff

The rapid evolution of software development necessitates enhanced safety
measures. Extracting information about software failures from companies is
becoming increasingly more available through news articles.
  This research utilizes the Failure Analysis Investigation with LLMs (FAIL)
model to extract industry-specific information. Although the FAIL model's
database is rich in information, it could benefit from further categorization
and industry-specific insights to further assist software engineers.
  In previous work news articles were collected from reputable sources and
categorized by incidents inside a database. Prompt engineering and Large
Language Models (LLMs) were then applied to extract relevant information
regarding the software failure. This research extends these methods by
categorizing articles into specific domains and types of software failures. The
results are visually represented through graphs.
  The analysis shows that throughout the database some software failures occur
significantly more often in specific industries. This categorization provides a
valuable resource for software engineers and companies to identify and address
common failures.
  This research highlights the synergy between software engineering and Large
Language Models (LLMs) to automate and enhance the analysis of software
failures. By transforming data from the database into an industry specific
model, we provide a valuable resource that can be used to identify common
vulnerabilities, predict potential risks, and implement proactive measures for
preventing software failures. Leveraging the power of the current FAIL database
and data visualization, we aim to provide an avenue for safer and more secure
software in the future.

ÊëòË¶ÅÔºö<paragraph>ËªüÈ´îÈñãÁôºÂø´ÈÄüÊºîÈÄ≤ÔºåËø´ÂàáÈúÄË¶ÅÂ¢ûÂº∑ÂÆâÂÖ®Êé™ÊñΩ„ÄÇÂæûÂÖ¨Âè∏Êñ∞ËÅûÊñáÁ´†‰∏≠ËêÉÂèñËªüÈ´îÊïÖÈöúË≥áË®äÊ≠£ËÆäÂæóË∂ä‰æÜË∂äÂÆπÊòì„ÄÇ
Ê≠§Á†îÁ©∂Âà©Áî®Â§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÊïÖÈöúÂàÜÊûêË™øÊü•ÔºàFAILÔºâÊ®°ÂûãËêÉÂèñÁî¢Ê•≠ÁâπÂÆöË≥áË®ä„ÄÇÂÑòÁÆ° FAIL Ê®°ÂûãÁöÑË≥áÊñôÂ∫´Ë≥áË®äË±êÂØåÔºå‰ΩÜËã•ËÉΩÈÄ≤‰∏ÄÊ≠•ÂàÜÈ°û‰∏¶Êèê‰æõÁî¢Ê•≠ÁâπÂÆöË¶ãËß£ÔºåÂ∞áÊúâÂä©ÊñºËªüÈ´îÂ∑•Á®ãÂ∏´„ÄÇ
Âú®ÂÖàÂâçÁöÑÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÂæû‰ø°Ë≠ΩËâØÂ•ΩÁöÑ‰æÜÊ∫êÊî∂ÈõÜÊñ∞ËÅûÊñáÁ´†Ôºå‰∏¶Â∞áÂÖ∂ÂàÜÈ°ûÁÇ∫Ë≥áÊñôÂ∫´‰∏≠ÁöÑ‰∫ã‰ª∂„ÄÇÊé•ËëóÊáâÁî®ÊèêÁ§∫Â∑•Á®ãÂíåÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâËêÉÂèñËàáËªüÈ´îÊïÖÈöúÁõ∏ÈóúÁöÑË≥áË®ä„ÄÇÊ≠§Á†îÁ©∂ÈÄèÈÅéÂ∞áÊñáÁ´†ÂàÜÈ°ûÂà∞ÁâπÂÆöÈ†òÂüüÂíåËªüÈ´îÊïÖÈöúÈ°ûÂûãÔºåÂª∂‰º∏‰∫ÜÈÄô‰∫õÊñπÊ≥ï„ÄÇÁµêÊûúÈÄèÈÅéÂúñË°®Ë¶ñË¶∫ÂåñÂëàÁèæ„ÄÇ
ÂàÜÊûêÈ°ØÁ§∫ÔºåÂú®Êï¥ÂÄãË≥áÊñôÂ∫´‰∏≠ÔºåÊüê‰∫õËªüÈ´îÊïÖÈöúÂú®ÁâπÂÆöÁî¢Ê•≠‰∏≠ÁôºÁîüÁöÑÈ†ªÁéáÈ°ØËëóËºÉÈ´ò„ÄÇÊ≠§ÂàÜÈ°ûÁÇ∫ËªüÈ´îÂ∑•Á®ãÂ∏´ÂíåÂÖ¨Âè∏Êèê‰æõ‰∫ÜÂØ∂Ë≤¥ÁöÑË≥áÊ∫êÔºåÂèØË≠òÂà•‰∏¶Ëß£Ê±∫Â∏∏Ë¶ãÊïÖÈöú„ÄÇ
Ê≠§Á†îÁ©∂Âº∑Ë™ø‰∫ÜËªüÈ´îÂ∑•Á®ãËàáÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâ‰πãÈñìÁöÑÁ∂úÊïà‰ΩúÁî®ÔºåÂèØËá™ÂãïÂåñ‰∏¶Â¢ûÂº∑ËªüÈ´îÊïÖÈöúÂàÜÊûê„ÄÇÈÄèÈÅéÂ∞áË≥áÊñôÂ∫´‰∏≠ÁöÑË≥áÊñôËΩâÊèõÁÇ∫Áî¢Ê•≠ÁâπÂÆöÊ®°ÂûãÔºåÊàëÂÄëÊèê‰æõ‰∫Ü‰∏ÄÈ†ÖÂØ∂Ë≤¥ÁöÑË≥áÊ∫êÔºåÂèØÁî®ÊñºË≠òÂà•Â∏∏Ë¶ãÊºèÊ¥û„ÄÅÈ†êÊ∏¨ÊΩõÂú®È¢®Èö™Ôºå‰∏¶ÂØ¶ÊñΩ‰∏ªÂãïÊé™ÊñΩ‰æÜÈ†êÈò≤ËªüÈ´îÊïÖÈöú„ÄÇÊàëÂÄëÂà©Áî®ÁèæÊúâ FAIL Ë≥áÊñôÂ∫´ÂíåË≥áÊñôË¶ñË¶∫ÂåñÁöÑÂÑ™Âã¢ÔºåÊó®Âú®ÁÇ∫Êú™‰æÜÊèê‰æõÊõ¥ÂÆâÂÖ®‰∏îÁ©©ÂÆöÁöÑËªüÈ´î„ÄÇ</paragraph>

##### **EgyBERT: A Large Language Model Pretrained on Egyptian Dialect Corpora**
2408.03524v1 by Faisal Qarah

This study presents EgyBERT, an Arabic language model pretrained on 10.4 GB
of Egyptian dialectal texts. We evaluated EgyBERT's performance by comparing it
with five other multidialect Arabic language models across 10 evaluation
datasets. EgyBERT achieved the highest average F1-score of 84.25% and an
accuracy of 87.33%, significantly outperforming all other comparative models,
with MARBERTv2 as the second best model achieving an F1-score 83.68% and an
accuracy 87.19%. Additionally, we introduce two novel Egyptian dialectal
corpora: the Egyptian Tweets Corpus (ETC), containing over 34.33 million tweets
(24.89 million sentences) amounting to 2.5 GB of text, and the Egyptian Forums
Corpus (EFC), comprising over 44.42 million sentences (7.9 GB of text)
collected from various Egyptian online forums. Both corpora are used in
pretraining the new model, and they are the largest Egyptian dialectal corpora
to date reported in the literature. Furthermore, this is the first study to
evaluate the performance of various language models on Egyptian dialect
datasets, revealing significant differences in performance that highlight the
need for more dialect-specific models. The results confirm the effectiveness of
EgyBERT model in processing and analyzing Arabic text expressed in Egyptian
dialect, surpassing other language models included in the study. EgyBERT model
is publicly available on \url{https://huggingface.co/faisalq/EgyBERT}.

ÊëòË¶ÅÔºöÊú¨Á†îÁ©∂Â±ïÁ§∫‰∫Ü EgyBERTÔºåÈÄôÊòØ‰∏ÄÂÄãÂú® 10.4 GB ÁöÑÂüÉÂèäÊñπË®ÄÊñáÊú¨‰∏äÈ†êÂÖàË®ìÁ∑¥ÁöÑÈòøÊãâ‰ºØË™ûË™ûË®ÄÊ®°Âûã„ÄÇÊàëÂÄëÈÄèÈÅéËàá‰∫îÂÄãÂÖ∂‰ªñÂ§öÊñπË®ÄÈòøÊãâ‰ºØË™ûË™ûË®ÄÊ®°ÂûãÂú® 10 ÂÄãË©ï‰º∞Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÊØîËºÉÔºå‰æÜË©ï‰º∞ EgyBERT ÁöÑÊïàËÉΩ„ÄÇEgyBERT ÈÅîÂà∞‰∫ÜÊúÄÈ´òÁöÑÂπ≥Âùá F1 ÂàÜÊï∏ÁÇ∫ 84.25% ÂíåÊ∫ñÁ¢∫ÁéáÁÇ∫ 87.33%ÔºåÈ°ØËëóÂÑ™ÊñºÊâÄÊúâÂÖ∂‰ªñÊØîËºÉÊ®°ÂûãÔºåÂÖ∂‰∏≠ MARBERTv2 ‰ΩúÁÇ∫Á¨¨‰∫åÂ•ΩÁöÑÊ®°ÂûãÔºåÈÅîÂà∞‰∫Ü F1 ÂàÜÊï∏ 83.68% ÂíåÊ∫ñÁ¢∫Áéá 87.19%„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂºïÂÖ•‰∫ÜÂÖ©ÂÄãÊñ∞Á©éÁöÑÂüÉÂèäÊñπË®ÄË™ûÊñôÂ∫´ÔºöÂüÉÂèäÊé®ÊñáË™ûÊñôÂ∫´ (ETC)ÔºåÂåÖÂê´Ë∂ÖÈÅé 3433 Ëê¨Ê¢ùÊé®ÊñáÔºà2489 Ëê¨ÂÄãÂè•Â≠êÔºâÔºåÁõ∏Áï∂Êñº 2.5 GB ÁöÑÊñáÂ≠óÔºå‰ª•ÂèäÂüÉÂèäË´ñÂ£áË™ûÊñôÂ∫´ (EFC)ÔºåÂåÖÂê´Ë∂ÖÈÅé 4442 Ëê¨ÂÄãÂè•Â≠êÔºà7.9 GB ÁöÑÊñáÂ≠óÔºâÔºåÂæûÂêÑÁ®ÆÂüÉÂèäÁ∑ö‰∏äË´ñÂ£áÊî∂ÈõÜËÄå‰æÜ„ÄÇÈÄôÂÖ©ÂÄãË™ûÊñôÂ∫´ÈÉΩÁî®ÊñºÈ†êÂÖàË®ìÁ∑¥Êñ∞Ê®°ÂûãÔºåËÄå‰∏îÂÆÉÂÄëÊòØËøÑ‰ªäÁÇ∫Ê≠¢Âú®ÊñáÁçª‰∏≠Â†±Â∞éÁöÑÊúÄÂ§ßÁöÑÂüÉÂèäÊñπË®ÄË™ûÊñôÂ∫´„ÄÇÊ≠§Â§ñÔºåÈÄôÊòØÁ¨¨‰∏ÄÂÄãË©ï‰º∞ÂêÑÁ®ÆË™ûË®ÄÊ®°ÂûãÂú®ÂüÉÂèäÊñπË®ÄË≥áÊñôÈõÜ‰∏äÁöÑÊïàËÉΩÁöÑÁ†îÁ©∂ÔºåÊè≠Á§∫‰∫ÜÊïàËÉΩ‰∏äÁöÑÈ°ØËëóÂ∑ÆÁï∞ÔºåÈÄôÁ™ÅÈ°Ø‰∫ÜÂ∞çÊõ¥Â§öÁâπÂÆöÊñπË®ÄÊ®°ÂûãÁöÑÈúÄÊ±Ç„ÄÇÁµêÊûúË≠âÂØ¶‰∫Ü EgyBERT Ê®°ÂûãÂú®ËôïÁêÜÂíåÂàÜÊûê‰ª•ÂüÉÂèäÊñπË®ÄË°®ÈÅîÁöÑÈòøÊãâ‰ºØË™ûÊñáÊú¨ÊñπÈù¢ÁöÑÊúâÊïàÊÄßÔºåÂÑ™ÊñºÁ†îÁ©∂‰∏≠ÂåÖÂê´ÁöÑÂÖ∂‰ªñË™ûË®ÄÊ®°Âûã„ÄÇEgyBERT Ê®°ÂûãÂ∑≤ÂÖ¨ÈñãÁôºÂ∏ÉÂú® \url{https://huggingface.co/faisalq/EgyBERT}„ÄÇ

##### **RepoMasterEval: Evaluating Code Completion via Real-World Repositories**
2408.03519v1 by Qinyun Wu, Chao Peng, Pengfei Gao, Ruida Hu, Haoyu Gan, Bo Jiang, Jinhe Tang, Zhiwen Deng, Zhanming Guan, Cuiyun Gao, Xia Liu, Ping Yang

With the growing reliance on automated code completion tools in software
development, the need for robust evaluation benchmarks has become critical.
However, existing benchmarks focus more on code generation tasks in function
and class level and provide rich text description to prompt the model. By
contrast, such descriptive prompt is commonly unavailable in real development
and code completion can occur in wider range of situations such as in the
middle of a function or a code block. These limitations makes the evaluation
poorly align with the practical scenarios of code completion tools. In this
paper, we propose RepoMasterEval, a novel benchmark for evaluating code
completion models constructed from real-world Python and TypeScript
repositories. Each benchmark datum is generated by masking a code snippet
(ground truth) from one source code file with existing test suites. To improve
test accuracy of model generated code, we employ mutation testing to measure
the effectiveness of the test cases and we manually crafted new test cases for
those test suites with low mutation score. Our empirical evaluation on 6
state-of-the-art models shows that test argumentation is critical in improving
the accuracy of the benchmark and RepoMasterEval is able to report difference
in model performance in real-world scenarios. The deployment of RepoMasterEval
in a collaborated company for one month also revealed that the benchmark is
useful to give accurate feedback during model training and the score is in high
correlation with the model's performance in practice. Based on our findings, we
call for the software engineering community to build more LLM benchmarks
tailored for code generation tools taking the practical and complex development
environment into consideration.

ÊëòË¶ÅÔºö<paragraph>Èö®ËëóËªüÈ´îÈñãÁôº‰∏≠Ë∂ä‰æÜË∂ä‰æùË≥¥Ëá™ÂãïÂåñÁ®ãÂºèÁ¢ºÂÆåÊàêÂ∑•ÂÖ∑ÔºåÂ∞çÂÅ•ÂÖ®ÁöÑË©ï‰º∞Âü∫Ê∫ñÁöÑÈúÄÊ±ÇËÆäÂæóËá≥ÈóúÈáçË¶Å„ÄÇ
ÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÂü∫Ê∫ñÊõ¥Ê≥®ÈáçÂáΩÂºèÂíåÈ°ûÂà•Â±§Á¥öÁöÑÁ®ãÂºèÁ¢ºÁî¢Áîü‰ªªÂãôÔºå‰∏¶Êèê‰æõË±êÂØåÁöÑÊñáÂ≠óÊèèËø∞‰æÜÊèêÁ§∫Ê®°Âûã„ÄÇ
Áõ∏ÂèçÂú∞ÔºåÈÄôÁ®ÆÊèèËø∞ÊÄßÊèêÁ§∫ÈÄöÂ∏∏Âú®ÂØ¶ÈöõÈñãÁôº‰∏≠‰∏çÂèØÁî®ÔºåËÄå‰∏îÁ®ãÂºèÁ¢ºÂÆåÊàêÂèØ‰ª•Âú®Êõ¥Âª£Ê≥õÁöÑÊÉÖÊ≥Å‰∏ãÁôºÁîüÔºå‰æãÂ¶ÇÂú®ÂáΩÂºèÊàñÁ®ãÂºèÁ¢ºÂçÄÂ°äÁöÑ‰∏≠Èñì„ÄÇ
ÈÄô‰∫õÈôêÂà∂‰ΩøÂæóË©ï‰º∞ËàáÁ®ãÂºèÁ¢ºÂÆåÊàêÂ∑•ÂÖ∑ÁöÑÂØ¶ÈöõÂ†¥ÊôØÂ∞çÈΩä‰∏ç‰Ω≥„ÄÇ
Âú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫ RepoMasterEvalÔºåÈÄôÊòØ‰∏ÄÂÄãÁî®ÊñºË©ï‰º∞ÂæûÁúüÂØ¶‰∏ñÁïå Python Âíå TypeScript ÂÑ≤Â≠òÂ∫´Âª∫ÊßãÁöÑÁ®ãÂºèÁ¢ºÂÆåÊàêÊ®°ÂûãÁöÑÊñ∞Âü∫Ê∫ñ„ÄÇ
ÊØèÂÄãÂü∫Ê∫ñË≥áÊñôÈÉΩÊòØÈÄèÈÅéÈÅÆËîΩ‰æÜËá™‰∏ÄÂÄãÂéüÂßãÁ¢ºÊ™îÊ°àÁöÑÁ®ãÂºèÁ¢ºÁâáÊÆµÔºàÂü∫Êú¨‰∫ãÂØ¶ÔºâÂíåÁèæÊúâÁöÑÊ∏¨Ë©¶Â•ó‰ª∂‰æÜÁî¢ÁîüÁöÑ„ÄÇ
ÁÇ∫‰∫ÜÊèêÈ´òÊ®°ÂûãÁî¢ÁîüÁ®ãÂºèÁ¢ºÁöÑÊ∏¨Ë©¶Ê∫ñÁ¢∫Â∫¶ÔºåÊàëÂÄëÊé°Áî®Á™ÅËÆäÊ∏¨Ë©¶‰æÜË°°ÈáèÊ∏¨Ë©¶Ê°à‰æãÁöÑÊúâÊïàÊÄßÔºå‰∏¶ÁÇ∫Á™ÅËÆäÂàÜÊï∏‰ΩéÁöÑÈÇ£‰∫õÊ∏¨Ë©¶Â•ó‰ª∂ÊâãÂãïÂª∫Á´ãÊñ∞ÁöÑÊ∏¨Ë©¶Ê°à‰æã„ÄÇ
ÊàëÂÄëÂ∞ç 6 ÂÄãÊúÄÂÖàÈÄ≤ÁöÑÊ®°ÂûãÈÄ≤Ë°åÁöÑÂØ¶Ë≠âË©ï‰º∞È°ØÁ§∫ÔºåÊ∏¨Ë©¶Ë´ñË≠âÂ∞çÊñºÊèêÈ´òÂü∫Ê∫ñÁöÑÊ∫ñÁ¢∫Â∫¶Ëá≥ÈóúÈáçË¶ÅÔºåËÄå RepoMasterEval ËÉΩÂ§†Â†±ÂëäÁúüÂØ¶‰∏ñÁïåÂ†¥ÊôØ‰∏≠Ê®°ÂûãÊïàËÉΩÁöÑÂ∑ÆÁï∞„ÄÇ
Âú®‰∏ÄÂÆ∂Âêà‰ΩúÂÖ¨Âè∏‰∏≠ÈÉ®ÁΩ≤ RepoMasterEval ‰∏ÄÂÄãÊúàÂæåÔºå‰πüÁôºÁèæË©≤Âü∫Ê∫ñÊúâÂä©ÊñºÂú®Ê®°ÂûãË®ìÁ∑¥ÊúüÈñìÊèê‰æõÊ∫ñÁ¢∫ÁöÑÂõûÈ•ãÔºåËÄå‰∏îÂàÜÊï∏ËàáÊ®°ÂûãÂú®ÂØ¶Èöõ‰∏≠ÁöÑÊïàËÉΩÈ´òÂ∫¶Áõ∏Èóú„ÄÇ
Ê†πÊìöÊàëÂÄëÁöÑÁôºÁèæÔºåÊàëÂÄëÂëºÁ±≤ËªüÈ´îÂ∑•Á®ãÁ§æÁæ§Âª∫Á´ãÊõ¥Â§öÈáùÂ∞çÁ®ãÂºèÁ¢ºÁî¢ÁîüÂ∑•ÂÖ∑ÈáèË∫´ÊâìÈÄ†ÁöÑ LLM Âü∫Ê∫ñÔºå‰∏¶Â∞áÂØ¶Èöõ‰∏îË§áÈõúÁöÑÈñãÁôºÁí∞Â¢ÉÁ¥çÂÖ•ËÄÉÈáè„ÄÇ</paragraph>

##### **A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems**
2408.03515v1 by Wenxiao Zhang, Xiangrui Kong, Conan Dewitt, Thomas Braunl, Jin B. Hong

The integration of Large Language Models (LLMs) like GPT-4o into robotic
systems represents a significant advancement in embodied artificial
intelligence. These models can process multi-modal prompts, enabling them to
generate more context-aware responses. However, this integration is not without
challenges. One of the primary concerns is the potential security risks
associated with using LLMs in robotic navigation tasks. These tasks require
precise and reliable responses to ensure safe and effective operation.
Multi-modal prompts, while enhancing the robot's understanding, also introduce
complexities that can be exploited maliciously. For instance, adversarial
inputs designed to mislead the model can lead to incorrect or dangerous
navigational decisions. This study investigates the impact of prompt injections
on mobile robot performance in LLM-integrated systems and explores secure
prompt strategies to mitigate these risks. Our findings demonstrate a
substantial overall improvement of approximately 30.8% in both attack detection
and system performance with the implementation of robust defence mechanisms,
highlighting their critical role in enhancing security and reliability in
mission-oriented tasks.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â¶Ç GPT-4o Êï¥ÂêàÂà∞Ê©üÂô®‰∫∫Á≥ªÁµ±‰∏≠Ôºå‰ª£Ë°®‰∫ÜÂÖ∑Ë∫´‰∫∫Â∑•Êô∫ÊÖßÁöÑÈáçÂ§ßÈÄ≤Ê≠•„ÄÇÈÄô‰∫õÊ®°ÂûãÂèØ‰ª•ËôïÁêÜÂ§öÊ®°ÊÖãÊèêÁ§∫Ôºå‰ΩøÂÆÉÂÄëËÉΩÂ§†Áî¢ÁîüÊõ¥Â§öÂü∫ÊñºÂÖßÂÆπÁöÑÂõûÊáâ„ÄÇÁÑ∂ËÄåÔºåÈÄôÁ®ÆÊï¥Âêà‰∏¶ÈùûÊ≤íÊúâÊåëÊà∞„ÄÇ‰∏ªË¶ÅÂïèÈ°å‰πã‰∏ÄÊòØËàáÂú®Ê©üÂô®‰∫∫Â∞éËà™‰ªªÂãô‰∏≠‰ΩøÁî® LLM Áõ∏ÈóúÁöÑÊΩõÂú®ÂÆâÂÖ®È¢®Èö™„ÄÇÈÄô‰∫õ‰ªªÂãôÈúÄË¶ÅÊ∫ñÁ¢∫‰∏îÂèØÈù†ÁöÑÂõûÊáâÔºå‰ª•Á¢∫‰øùÂÆâÂÖ®‰∏îÊúâÊïàÁöÑÊìç‰Ωú„ÄÇÂ§öÊ®°ÊÖãÊèêÁ§∫Âú®Â¢ûÂº∑Ê©üÂô®‰∫∫ÁêÜËß£ÂäõÁöÑÂêåÊôÇÔºå‰πüÂºïÂÖ•‰∫ÜÂèØËÉΩÊúÉË¢´ÊÉ°ÊÑèÂà©Áî®ÁöÑË§áÈõúÊÄß„ÄÇ‰æãÂ¶ÇÔºåÊó®Âú®Ë™§Â∞éÊ®°ÂûãÁöÑÂ∞çÊäóÊÄßËº∏ÂÖ•ÂèØËÉΩÊúÉÂ∞éËá¥‰∏çÊ≠£Á¢∫ÊàñÂç±Èö™ÁöÑÂ∞éËà™Ê±∫Á≠ñ„ÄÇÊú¨Á†îÁ©∂Êé¢Ë®é‰∫ÜÊèêÁ§∫Ê≥®ÂÖ•Â∞ç LLM Êï¥ÂêàÁ≥ªÁµ±‰∏≠ÁßªÂãïÊ©üÂô®‰∫∫ÊïàËÉΩÁöÑÂΩ±ÈüøÔºå‰∏¶Êé¢Ë®é‰∫ÜÂÆâÂÖ®ÁöÑÊèêÁ§∫Á≠ñÁï•‰ª•Èôç‰ΩéÈÄô‰∫õÈ¢®Èö™„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË≠âÊòéÔºåÈÄèÈÅéÂØ¶ÊñΩÂº∑Â§ßÁöÑÈò≤Á¶¶Ê©üÂà∂ÔºåÊîªÊìäÂÅµÊ∏¨ÂíåÁ≥ªÁµ±ÊïàËÉΩÊï¥È´îÂ§ßÂπÖÊèêÂçá‰∫ÜÁ¥Ñ 30.8%ÔºåÁ™ÅÈ°Ø‰∫ÜÂÆÉÂÄëÂú®ÊèêÂçá‰ªªÂãôÂ∞éÂêë‰ªªÂãô‰∏≠ÁöÑÂÆâÂÖ®ÊÄßËàáÂèØÈù†ÊÄßÁöÑÈóúÈçµ‰ΩúÁî®„ÄÇ

##### **MoExtend: Tuning New Experts for Modality and Task Extension**
2408.03511v1 by Shanshan Zhong, Shanghua Gao, Zhongzhan Huang, Wushao Wen, Marinka Zitnik, Pan Zhou

Large language models (LLMs) excel in various tasks but are primarily trained
on text data, limiting their application scope. Expanding LLM capabilities to
include vision-language understanding is vital, yet training them on multimodal
data from scratch is challenging and costly. Existing instruction tuning
methods, e.g., LLAVA, often connects a pretrained CLIP vision encoder and LLMs
via fully fine-tuning LLMs to bridge the modality gap. However, full
fine-tuning is plagued by catastrophic forgetting, i.e., forgetting previous
knowledge, and high training costs particularly in the era of increasing tasks
and modalities. To solve this issue, we introduce MoExtend, an effective
framework designed to streamline the modality adaptation and extension of
Mixture-of-Experts (MoE) models. MoExtend seamlessly integrates new experts
into pre-trained MoE models, endowing them with novel knowledge without the
need to tune pretrained models such as MoE and vision encoders. This approach
enables rapid adaptation and extension to new modal data or tasks, effectively
addressing the challenge of accommodating new modalities within LLMs.
Furthermore, MoExtend avoids tuning pretrained models, thus mitigating the risk
of catastrophic forgetting. Experimental results demonstrate the efficacy and
efficiency of MoExtend in enhancing the multimodal capabilities of LLMs,
contributing to advancements in multimodal AI research. Code:
https://github.com/zhongshsh/MoExtend.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂêÑÁ®Æ‰ªªÂãô‰∏≠Ë°®ÁèæÂá∫Ëâ≤Ôºå‰ΩÜ‰∏ªË¶ÅË®ìÁ∑¥
ÊñáÊú¨Ë≥áÊñôÔºåÈôêÂà∂‰∫ÜÂÖ∂ÊáâÁî®ÁØÑÂúç„ÄÇÊì¥Â±ï LLM ËÉΩÂäõ‰ª•
ÂåÖÂê´Ë¶ñË¶∫Ë™ûË®ÄÁêÜËß£Ëá≥ÈóúÈáçË¶ÅÔºå‰ΩÜÂæûÈ†≠ÈñãÂßãË®ìÁ∑¥ÂÆÉÂÄëÂ§öÊ®°ÊÖã
Ë≥áÊñôÂÖ∑ÊúâÊåëÊà∞ÊÄß‰∏îÊàêÊú¨È´òÊòÇ„ÄÇÁèæÊúâÁöÑÊåá‰ª§Ë™øÊï¥
ÊñπÊ≥ïÔºå‰æãÂ¶Ç LLAVAÔºåÈÄöÂ∏∏ÈÄöÈÅéÂÆåÂÖ®ÂæÆË™ø LLM ‰æÜÈÄ£Êé•È†êË®ìÁ∑¥ÁöÑ CLIP Ë¶ñË¶∫Á∑®Á¢ºÂô®Âíå LLM
ÂΩåÂêàÊ®°ÊÖãÂ∑ÆË∑ù„ÄÇÁÑ∂ËÄåÔºåÂÆåÂÖ®ÂæÆË™øÊúÉÂèóÂà∞ÁÅΩÈõ£ÊÄßÈÅ∫ÂøòÁöÑÂõ∞ÊìæÔºåÂç≥ÂøòË®ò‰πãÂâçÁöÑ
Áü•Ë≠òÔºåÁâπÂà•ÊòØÂú®‰ªªÂãôÂíåÊ®°ÊÖãÂ¢ûÂä†ÁöÑÊôÇ‰ª£ÔºåË®ìÁ∑¥ÊàêÊú¨ÂæàÈ´ò
ÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂºïÂÖ•‰∫Ü MoExtendÔºå‰∏ÄÂÄãÊúâÊïàÁöÑ
Êû∂ÊßãË®≠Ë®àÁî®ÊñºÁ∞°ÂåñÊ®°ÊÖãÈÅ©ÊáâÂíåÊì¥Â±ï
Ê∑∑ÂêàÂ∞àÂÆ∂ (MoE) Ê®°Âûã„ÄÇMoExtend Â∞áÊñ∞ÁöÑÂ∞àÂÆ∂ÁÑ°Á∏´ÈõÜÊàêÂà∞È†êË®ìÁ∑¥ÁöÑ MoE Ê®°Âûã‰∏≠ÔºåË≥¶‰∫àÂÆÉÂÄëÊñ∞ÁöÑÁü•Ë≠òÔºåËÄåÁÑ°ÈúÄË™øÊï¥È†êË®ìÁ∑¥ÁöÑÊ®°ÂûãÔºå‰æãÂ¶Ç MoE ÂíåË¶ñË¶∫Á∑®Á¢ºÂô®„ÄÇÈÄôÁ®ÆÊñπÊ≥ï
ËÉΩÂ§†Âø´ÈÄüÈÅ©ÊáâÂíåÊì¥Â±ïÂà∞Êñ∞ÁöÑÊ®°ÊÖãË≥áÊñôÊàñ‰ªªÂãôÔºåÊúâÊïàÂú∞
Ëß£Ê±∫‰∫ÜÂú® LLM ‰∏≠ÂÆπÁ¥çÊñ∞Ê®°ÊÖãÁöÑÊåëÊà∞„ÄÇ
Ê≠§Â§ñÔºåMoExtend ÈÅøÂÖçË™øÊï¥È†êË®ìÁ∑¥ÁöÑÊ®°ÂûãÔºåÂæûËÄåÈôç‰Ωé‰∫ÜÈ¢®Èö™
ÁÅΩÈõ£ÊÄßÈÅ∫Âøò„ÄÇÂØ¶È©óÁµêÊûúË≠âÊòé‰∫Ü MoExtend Âú®Â¢ûÂº∑ LLM ÁöÑÂ§öÊ®°ÊÖãËÉΩÂäõÊñπÈù¢ÁöÑÊúâÊïàÊÄßÂíåÊïàÁéáÔºå
‰øÉÈÄ≤Â§öÊ®°ÊÖã AI Á†îÁ©∂ÁöÑÈÄ≤Ê≠•„ÄÇÁ®ãÂºèÁ¢ºÔºö
https://github.com/zhongshsh/MoExtend„ÄÇ

##### **1.5-Pints Technical Report: Pretraining in Days, Not Months -- Your Language Model Thrives on Quality Data**
2408.03506v1 by Calvin Tan, Jerome Wang

This paper presents a compute-efficient approach to pre-training a Language
Model-the "1.5-Pints"-in only 9 days, while outperforming state-of-the-art
models as an instruction-following assistant.Based on MT-Bench (a benchmark
that emulates human judgments), 1.5-Pints outperforms Apple's OpenELM and
Microsoft's Phi.This is achieved by a carefully curated pre-training dataset of
57 billion tokens, using a mix of automated workflows and manual human review.
The selection of the dataset prioritizes content that is considered expository
and "textbook-like" to aid the model in reasoning and logical deduction,
culminating in its overall ability as a strong and versatile AI model. In terms
of the model architecture, we employed a modified Mistral tokenizer, alongside
a Llama-2 architecture for wider compatibility. For training, we adopted the
methodologies used by StableLM, TinyLlama, and Huggingface Zephyr. 1.5-Pints
demonstrates that by focusing on data quality over quantity in LLM training, we
can significantly reduce training time and resources required. We believe this
approach will not only make pre-training more accessible but also reduce our
carbon footprint. Our findings and resources from this research are
open-sourced, aiming to facilitate further advancements in the field. The
1.5-Pints model is available in two versions: 2K and 16K context windows.

ÊëòË¶ÅÔºö<paragraph>Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÂÄãË®àÁÆóÊïàÁéáÈ´òÁöÑË®ìÁ∑¥ÊñπÊ≥ïÔºåÂèØ‰ª•Âú®Áü≠Áü≠ 9 Â§©ÂÖßÈ†êË®ìÁ∑¥‰∏ÄÂÄãË™ûË®ÄÊ®°Âûã„Äå1.5-Pints„ÄçÔºåÂêåÊôÇÂú®‰ΩúÁÇ∫Êåá‰ª§ËøΩËπ§Âä©ÁêÜÁöÑË°®Áèæ‰∏äÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑÊ®°Âûã„ÄÇÊ†πÊìö MT-BenchÔºà‰∏ÄÂÄãÊ®°Êì¨‰∫∫È°ûÂà§Êñ∑ÁöÑÂü∫Ê∫ñÊ∏¨Ë©¶ÔºâÔºå1.5-Pints ÂÑ™Êñº Apple ÁöÑ OpenELM Âíå Microsoft ÁöÑ Phi„ÄÇÈÄôÊòØÈÄèÈÅé‰∏ÄÂÄãÁ∂ìÈÅé‰ªîÁ¥∞Á≠ñÂäÉÁöÑ 570 ÂÑÑÂÄãÁ¨¶ËôüÁöÑÈ†êË®ìÁ∑¥Ë≥áÊñôÈõÜÂØ¶ÁèæÁöÑÔºåÁµêÂêà‰∫ÜËá™ÂãïÂåñÂ∑•‰ΩúÊµÅÁ®ãÂíå‰∫∫Â∑•ÂØ©Êü•„ÄÇË≥áÊñôÈõÜÁöÑÈÅ∏ÊìáÂÑ™ÂÖàËÄÉÊÖÆË¢´Ë¶ñÁÇ∫Ë™™ÊòéÊÄßÂíå„ÄåÊïôÁßëÊõ∏Âºè„ÄçÁöÑÂÖßÂÆπÔºå‰ª•Âπ´Âä©Ê®°ÂûãÈÄ≤Ë°åÊé®ÁêÜÂíåÈÇèËºØÊºîÁππÔºåÊúÄÁµÇÂΩ¢ÊàêÂÖ∂‰ΩúÁÇ∫‰∏ÄÂÄãÂº∑Â§ß‰∏îÁî®ÈÄîÂª£Ê≥õÁöÑ AI Ê®°ÂûãÁöÑÊï¥È´îËÉΩÂäõ„ÄÇÂú®Ê®°ÂûãÊû∂ÊßãÊñπÈù¢ÔºåÊàëÂÄëÊé°Áî®‰∫Ü‰∏ÄÂÄã‰øÆÊîπÈÅéÁöÑ Mistral ÂàÜË©ûÂô®Ôºå‰ª•Âèä‰∏ÄÂÄã Llama-2 Êû∂Êßã‰ª•ÂØ¶ÁèæÊõ¥Âª£Ê≥õÁöÑÁõ∏ÂÆπÊÄß„ÄÇÂú®Ë®ìÁ∑¥ÊñπÈù¢ÔºåÊàëÂÄëÊé°Áî®‰∫Ü StableLM„ÄÅTinyLlama Âíå Huggingface Zephyr ÊâÄ‰ΩøÁî®ÁöÑË®ìÁ∑¥ÊñπÊ≥ï„ÄÇ1.5-Pints Ë≠âÊòé‰∫ÜÈÄèÈÅéÂú® LLM Ë®ìÁ∑¥‰∏≠ÈáçË¶ñË≥áÊñôÂìÅË≥™ËÄåÈùûÊï∏ÈáèÔºåÊàëÂÄëÂèØ‰ª•Â§ßÂπÖÊ∏õÂ∞ëË®ìÁ∑¥ÊôÇÈñìÂíåÊâÄÈúÄÁöÑË≥áÊ∫ê„ÄÇÊàëÂÄëÁõ∏‰ø°ÈÄôÁ®ÆÊñπÊ≥ï‰∏çÂÉÖÊúÉËÆìÈ†êË®ìÁ∑¥Êõ¥ÂÆπÊòìÂèñÂæóÔºåÈÇÑËÉΩÊ∏õÂ∞ëÊàëÂÄëÁöÑÁ¢≥Ë∂≥Ë∑°„ÄÇÊàëÂÄëÂæûÈÄôÈ†ÖÁ†îÁ©∂‰∏≠Áç≤ÂæóÁöÑÁôºÁèæÂíåË≥áÊ∫êÈÉΩÊòØÈñãÊ∫êÁöÑÔºåÁõÆÁöÑÊòØ‰øÉÈÄ≤Ë©≤È†òÂüüÁöÑÈÄ≤‰∏ÄÊ≠•ÁôºÂ±ï„ÄÇ1.5-Pints Ê®°ÂûãÊèê‰æõÂÖ©ÂÄãÁâàÊú¨Ôºö2K Âíå 16K ÁöÑ‰∏ä‰∏ãÊñáË¶ñÁ™ó„ÄÇ</paragraph>

##### **Optimus: Accelerating Large-Scale Multi-Modal LLM Training by Bubble Exploitation**
2408.03505v1 by Weiqi Feng, Yangrui Chen, Shaoyu Wang, Yanghua Peng, Haibin Lin, Minlan Yu

Multimodal large language models (MLLMs) have extended the success of large
language models (LLMs) to multiple data types, such as image, text and audio,
achieving significant performance in various domains, including multimodal
translation, visual question answering and content generation. Nonetheless,
existing systems are inefficient to train MLLMs due to substantial GPU bubbles
caused by the heterogeneous modality models and complex data dependencies in 3D
parallelism. This paper proposes Optimus, a distributed MLLM training system
that reduces end-to-end MLLM training time. Optimus is based on our principled
analysis that scheduling the encoder computation within the LLM bubbles can
reduce bubbles in MLLM training. To make scheduling encoder computation
possible for all GPUs, Optimus searches the separate parallel plans for encoder
and LLM, and adopts a bubble scheduling algorithm to enable exploiting LLM
bubbles without breaking the original data dependencies in the MLLM model
architecture. We further decompose encoder layer computation into a series of
kernels, and analyze the common bubble pattern of 3D parallelism to carefully
optimize the sub-millisecond bubble scheduling, minimizing the overall training
time. Our experiments in a production cluster show that Optimus accelerates
MLLM training by 20.5%-21.3% with ViT-22B and GPT-175B model over 3072 GPUs
compared to baselines.

ÊëòË¶ÅÔºöÂ§öÊ®°ÊÖãÂ§ßÂûãË™ûË®ÄÊ®°Âûã (MLLM) Â∑≤Â∞áÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÁöÑÊàêÂäüÊì¥Â±ïÂà∞Â§öÁ®ÆË≥áÊñôÈ°ûÂûãÔºå‰æãÂ¶ÇÂΩ±ÂÉè„ÄÅÊñáÂ≠óÂíåÈü≥Ë®äÔºåÂú®Â§öÊ®°ÊÖãÁøªË≠Ø„ÄÅË¶ñË¶∫ÂïèÁ≠îÂíåÂÖßÂÆπÁî¢ÁîüÁ≠âÂêÑÁ®ÆÈ†òÂüü‰∏≠ÂùáÂèñÂæóÈ°ØËëóÁöÑË°®Áèæ„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÁèæÊúâÁöÑÁ≥ªÁµ±Áî±ÊñºÁï∞Ë≥™Ê®°ÊÖãÊ®°ÂûãÂíå 3D ‰∏¶Ë°åËôïÁêÜ‰∏≠Ë§áÈõúÁöÑË≥áÊñô‰æùË≥¥ÊÄßËÄåÂ∞éËá¥Â§ßÈáèÁöÑ GPU Êö´ÂÅúÔºåÂõ†Ê≠§Ë®ìÁ∑¥ MLLM ÁöÑÊïàÁéáÂæà‰Ωé„ÄÇÊú¨ÊñáÊèêÂá∫ OptimusÔºåÈÄôÊòØ‰∏ÄÂÄãÂàÜÊï£ÂºèÁöÑ MLLM Ë®ìÁ∑¥Á≥ªÁµ±ÔºåÂèØÊ∏õÂ∞ëÁ´ØÂ∞çÁ´ØÁöÑ MLLM Ë®ìÁ∑¥ÊôÇÈñì„ÄÇOptimus ÊòØÂü∫ÊñºÊàëÂÄëÊúâÂéüÂâáÁöÑÂàÜÊûêÔºåÂç≥Âú® LLM Êö´ÂÅú‰∏≠ÊéíÁ®ãÁ∑®Á¢ºÂô®ÈÅãÁÆóÂèØ‰ª•Ê∏õÂ∞ë MLLM Ë®ìÁ∑¥‰∏≠ÁöÑÊö´ÂÅú„ÄÇÁÇ∫‰ΩøÊâÄÊúâ GPU ÈÉΩËÉΩÊéíÁ®ãÁ∑®Á¢ºÂô®ÈÅãÁÆóÔºåOptimus ÊúÉÊêúÂ∞ãÁ∑®Á¢ºÂô®Âíå LLM ÁöÑÁç®Á´ã‰∏¶Ë°åË®àÁï´Ôºå‰∏¶Êé°Áî®Êö´ÂÅúÊéíÁ®ãÊºîÁÆóÊ≥ïÔºå‰ª•Âà©Áî® LLM Êö´ÂÅúÔºåËÄå‰∏çÊúÉ‰∏≠Êñ∑ MLLM Ê®°ÂûãÊû∂Êßã‰∏≠ÁöÑÂéüÂßãË≥áÊñô‰æùË≥¥ÊÄß„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Â∞áÁ∑®Á¢ºÂô®Â±§ÈÅãÁÆóÂàÜËß£Êàê‰∏ÄÁ≥ªÂàóÁöÑÊ†∏Ôºå‰∏¶ÂàÜÊûê 3D ‰∏¶Ë°åËôïÁêÜÁöÑÂ∏∏Ë¶ãÊö´ÂÅúÊ®°ÂºèÔºå‰ª•‰ªîÁ¥∞ÊúÄ‰Ω≥ÂåñÊ¨°ÊØ´ÁßíÁöÑÊö´ÂÅúÊéíÁ®ãÔºåÂ∞áÊï¥È´îË®ìÁ∑¥ÊôÇÈñìÈôçËá≥ÊúÄ‰Ωé„ÄÇÊàëÂÄëÂú®ÁîüÁî¢Âè¢ÈõÜ‰∏≠ÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåËàáÂü∫Ê∫ñÁõ∏ÊØîÔºåOptimus Âú® 3072 ÂÄã GPU ‰∏ä‰ΩøÁî® ViT-22B Âíå GPT-175B Ê®°ÂûãÔºåÂ∞á MLLM Ë®ìÁ∑¥ÈÄüÂ∫¶Âä†Âø´‰∫Ü 20.5%-21.3%„ÄÇ

##### **Advanced User Credit Risk Prediction Model using LightGBM, XGBoost and Tabnet with SMOTEENN**
2408.03497v1 by Chang Yu, Yixin Jin, Qianwen Xing, Ye Zhang, Shaobo Guo, Shuchen Meng

Bank credit risk is a significant challenge in modern financial transactions,
and the ability to identify qualified credit card holders among a large number
of applicants is crucial for the profitability of a bank'sbank's credit card
business. In the past, screening applicants'applicants' conditions often
required a significant amount of manual labor, which was time-consuming and
labor-intensive. Although the accuracy and reliability of previously used ML
models have been continuously improving, the pursuit of more reliable and
powerful AI intelligent models is undoubtedly the unremitting pursuit by major
banks in the financial industry. In this study, we used a dataset of over
40,000 records provided by a commercial bank as the research object. We
compared various dimensionality reduction techniques such as PCA and T-SNE for
preprocessing high-dimensional datasets and performed in-depth adaptation and
tuning of distributed models such as LightGBM and XGBoost, as well as deep
models like Tabnet. After a series of research and processing, we obtained
excellent research results by combining SMOTEENN with these techniques. The
experiments demonstrated that LightGBM combined with PCA and SMOTEENN
techniques can assist banks in accurately predicting potential high-quality
customers, showing relatively outstanding performance compared to other models.

ÊëòË¶ÅÔºöÈäÄË°å‰ø°Ë≤∏È¢®Èö™ÊòØÁèæ‰ª£ÈáëËûç‰∫§Êòì‰∏≠ÁöÑÈáçÂ§ßÊåëÊà∞ÔºåÂú®ÁúæÂ§öÁî≥Ë´ã‰∫∫‰∏≠Ë≠òÂà•Âá∫ÂêàÊ†ºÁöÑ‰ø°Áî®Âç°ÊåÅÊúâ‰∫∫Â∞çÊñºÈäÄË°åÁöÑ‰ø°Áî®Âç°Ê•≠ÂãôÁç≤Âà©Ëá≥ÈóúÈáçË¶Å„ÄÇÈÅéÂéªÔºåÁØ©ÈÅ∏Áî≥Ë´ã‰∫∫ÁöÑÊ¢ù‰ª∂ÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèÁöÑ‰∫∫Â∑•ÂãûÂãïÔºåÈÄôÊó¢ËÄóÊôÇÂèàË≤ªÂäõ„ÄÇÂÑòÁÆ°ÂÖàÂâç‰ΩøÁî®ÁöÑ ML Ê®°ÂûãÁöÑÊ∫ñÁ¢∫ÊÄßÂíåÂèØÈù†ÊÄßÊåÅÁ∫åÊèêÂçáÔºå‰ΩÜËøΩÊ±ÇÊõ¥ÂèØÈù†‰∏îÂº∑Â§ßÁöÑ AI Êô∫ËÉΩÊ®°ÂûãÁÑ°ÁñëÊòØÈáëËûçÁî¢Ê•≠‰∏≠ÂêÑÂ§ßÈäÄË°åÁöÑ‰∏çÊáàËøΩÊ±Ç„ÄÇÂú®Êú¨Á†îÁ©∂‰∏≠ÔºåÊàëÂÄë‰ΩøÁî®‰∏ÄÂÆ∂ÂïÜÊ•≠ÈäÄË°åÊèê‰æõÁöÑË∂ÖÈÅé 40,000 Á≠ÜË®òÈåÑÁöÑË≥áÊñôÈõÜ‰ΩúÁÇ∫Á†îÁ©∂Â∞çË±°„ÄÇÊàëÂÄëÊØîËºÉ‰∫Ü PCA Âíå T-SNE Á≠âÂêÑÁ®ÆÈôçÁ∂≠ÊäÄË°ì‰ª•È†êËôïÁêÜÈ´òÁ∂≠Â∫¶Ë≥áÊñôÈõÜÔºå‰∏¶Â∞ç LightGBM Âíå XGBoost Á≠âÂàÜÊï£ÂºèÊ®°Âûã‰ª•Âèä Tabnet Á≠âÊ∑±Â∫¶Ê®°ÂûãÈÄ≤Ë°åÊ∑±Â∫¶Ë™øÊï¥ÂíåÂæÆË™ø„ÄÇÁ∂ìÈÅé‰∏ÄÁ≥ªÂàóÁöÑÁ†îÁ©∂ÂíåËôïÁêÜÔºåÊàëÂÄëÁµêÂêà SMOTEENN ËàáÈÄô‰∫õÊäÄË°ìÁç≤Âæó‰∫ÜÂÑ™Áï∞ÁöÑÁ†îÁ©∂ÊàêÊûú„ÄÇÂØ¶È©óË≠âÊòéÔºåLightGBM ÁµêÂêà PCA Âíå SMOTEENN ÊäÄË°ìÂèØ‰ª•ÂçîÂä©ÈäÄË°åÊ∫ñÁ¢∫È†êÊ∏¨ÊΩõÂú®ÁöÑÈ´òÂìÅË≥™ÂÆ¢Êà∂ÔºåËàáÂÖ∂‰ªñÊ®°ÂûãÁõ∏ÊØîË°®ÁèæÁõ∏Â∞çÂá∫Ëâ≤„ÄÇ

##### **Automated Theorem Provers Help Improve Large Language Model Reasoning**
2408.03492v1 by Lachlan McGinness, Peter Baumgartner

In this paper we demonstrate how logic programming systems and Automated
first-order logic Theorem Provers (ATPs) can improve the accuracy of Large
Language Models (LLMs) for logical reasoning tasks where the baseline
performance is given by direct LLM solutions. We first evaluate LLM reasoning
on steamroller problems using the PRONTOQA benchmark. We show how accuracy can
be improved with a neuro-symbolic architecture where the LLM acts solely as a
front-end for translating a given problem into a formal logic language and an
automated reasoning engine is called for solving it. However, this approach
critically hinges on the correctness of the LLM translation. To assess this
translation correctness, we secondly define a framework of syntactic and
semantic error categories. We implemented the framework and used it to identify
errors that LLMs make in the benchmark domain. Based on these findings, we
thirdly extended our method with capabilities for automatically correcting
syntactic and semantic errors. For semantic error correction we integrate
first-order logic ATPs, which is our main and novel contribution. We
demonstrate that this approach reduces semantic errors significantly and
further increases the accurracy of LLM logical reasoning.

ÊëòË¶ÅÔºö<paragraph>Âú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÈÇèËºØÁ®ãÂºèÁ≥ªÁµ±ÂíåËá™ÂãïÂåñ‰∏ÄÈöéÈÇèËºØÂÆöÁêÜË≠âÊòéÂô® (ATP) Â¶Ç‰ΩïÊèêÂçáÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÈÇèËºØÊé®ÁêÜ‰ªªÂãô‰∏≠ÁöÑÊ∫ñÁ¢∫ÊÄßÔºåÂÖ∂‰∏≠Âü∫Ê∫ñÊïàËÉΩÁî±Áõ¥Êé•ÁöÑ LLM Ëß£Ê±∫ÊñπÊ°àÊèê‰æõ„ÄÇÊàëÂÄëÈ¶ñÂÖà‰ΩøÁî® PRONTOQA Âü∫Ê∫ñË©ï‰º∞ LLM Êé®ÁêÜÂú®Â£ìË∑ØÊ©üÂïèÈ°å‰∏äÁöÑË°®Áèæ„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂ¶Ç‰ΩïÈÄèÈÅéÁ•ûÁ∂ìÁ¨¶ËôüÊû∂ÊßãÊèêÂçáÊ∫ñÁ¢∫ÊÄßÔºåÂÖ∂‰∏≠ LLM ÂÉÖ‰ΩúÁÇ∫ÂâçÁ´ØÔºåÂ∞áÁµ¶ÂÆöÁöÑÂïèÈ°åËΩâÊèõÁÇ∫ÂΩ¢ÂºèÈÇèËºØË™ûË®ÄÔºå‰∏¶ÂëºÂè´Ëá™ÂãïÊé®ÁêÜÂºïÊìé‰æÜËß£Ê±∫ÂÆÉ„ÄÇÁÑ∂ËÄåÔºåÊ≠§ÊñπÊ≥ïËá≥ÈóúÈáçË¶ÅÂú∞ÂèñÊ±∫Êñº LLM ËΩâÊèõÁöÑÊ≠£Á¢∫ÊÄß„ÄÇÁÇ∫‰∫ÜË©ï‰º∞Ê≠§ËΩâÊèõÁöÑÊ≠£Á¢∫ÊÄßÔºåÊàëÂÄëÂÖ∂Ê¨°ÂÆöÁæ©‰∫ÜË™ûÊ≥ïÂíåË™ûÁæ©ÈåØË™§È°ûÂà•ÁöÑÊ°ÜÊû∂„ÄÇÊàëÂÄëÂØ¶‰Ωú‰∫ÜÈÄôÂÄãÊ°ÜÊû∂Ôºå‰∏¶‰ΩøÁî®ÂÆÉ‰æÜË≠òÂà• LLM Âú®Âü∫Ê∫ñÈ†òÂüü‰∏≠Áî¢ÁîüÁöÑÈåØË™§„ÄÇÂü∫ÊñºÈÄô‰∫õÁôºÁèæÔºåÊàëÂÄëÁ¨¨‰∏âÈªûÊì¥ÂÖÖ‰∫ÜÊàëÂÄëÁöÑÁ®ãÂºèÔºå‰ΩøÂÖ∂ÂÖ∑ÂÇôËá™Âãï‰øÆÊ≠£Ë™ûÊ≥ïÂíåË™ûÁæ©ÈåØË™§ÁöÑËÉΩÂäõ„ÄÇÂ∞çÊñºË™ûÁæ©ÈåØË™§‰øÆÊ≠£ÔºåÊàëÂÄëÊï¥Âêà‰∫Ü‰∏ÄÈöéÈÇèËºØ ATPÔºåÈÄôÊòØÊàëÂÄëÁöÑ‰∏ªË¶Å‰∏îÊñ∞Á©éÁöÑË≤¢Áçª„ÄÇÊàëÂÄëÂ±ïÁ§∫‰∫ÜÊ≠§ÊñπÊ≥ïÂ§ßÂπÖÊ∏õÂ∞ë‰∫ÜË™ûÁæ©ÈåØË™§Ôºå‰∏¶ÈÄ≤‰∏ÄÊ≠•ÊèêÂçá‰∫Ü LLM ÈÇèËºØÊé®ÁêÜÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇ</paragraph>

##### **Harnessing the Power of LLMs in Source Code Vulnerability Detection**
2408.03489v1 by Andrew A Mahyari

Software vulnerabilities, caused by unintentional flaws in source code, are a
primary root cause of cyberattacks. Static analysis of source code has been
widely used to detect these unintentional defects introduced by software
developers. Large Language Models (LLMs) have demonstrated human-like
conversational abilities due to their capacity to capture complex patterns in
sequential data, such as natural languages. In this paper, we harness LLMs'
capabilities to analyze source code and detect known vulnerabilities. To ensure
the proposed vulnerability detection method is universal across multiple
programming languages, we convert source code to LLVM IR and train LLMs on
these intermediate representations. We conduct extensive experiments on various
LLM architectures and compare their accuracy. Our comprehensive experiments on
real-world and synthetic codes from NVD and SARD demonstrate high accuracy in
identifying source code vulnerabilities.

ÊëòË¶ÅÔºöËªüÈ´îÊºèÊ¥ûÊòØÁî±ÂéüÂßãÁ¢º‰∏≠ÁöÑÁÑ°ÂøÉÁëïÁñµÊâÄÈÄ†ÊàêÔºåÊòØÁ∂≤Ë∑ØÊîªÊìäÁöÑ‰∏ªË¶ÅÊ†πÊ∫ê„ÄÇÂéüÂßãÁ¢ºÁöÑÈùúÊÖãÂàÜÊûêÂ∑≤Âª£Ê≥õÁî®ÊñºÂÅµÊ∏¨ËªüÈ´îÈñãÁôº‰∫∫Âì°ÊâÄÂºïÂÖ•ÁöÑÈÄô‰∫õÁÑ°ÂøÉÁº∫Èô∑„ÄÇÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Â∑≤Â±ïÁèæÂá∫È°û‰ºº‰∫∫È°ûÁöÑÂ∞çË©±ËÉΩÂäõÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÊúâËÉΩÂäõÊì∑ÂèñÂ∫èÂàóË≥áÊñô‰∏≠ÁöÑË§áÈõúÊ®°ÂºèÔºå‰æãÂ¶ÇËá™ÁÑ∂Ë™ûË®Ä„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂà©Áî® LLM ÁöÑËÉΩÂäõ‰æÜÂàÜÊûêÂéüÂßãÁ¢º‰∏¶ÂÅµÊ∏¨Â∑≤Áü•ÁöÑÊºèÊ¥û„ÄÇÁÇ∫‰∫ÜÁ¢∫‰øùÊâÄÊèêÂá∫ÁöÑÊºèÊ¥ûÂÅµÊ∏¨ÊñπÊ≥ïÂú®Â§öÁ®ÆÁ®ãÂºèË™ûË®Ä‰∏≠ÈÄöÁî®ÔºåÊàëÂÄëÂ∞áÂéüÂßãÁ¢ºËΩâÊèõÁÇ∫ LLVM IRÔºå‰∏¶Âú®ÈÄô‰∫õ‰∏≠ÈñìË°®Á§∫‰∏äË®ìÁ∑¥ LLM„ÄÇÊàëÂÄëÂ∞çÂêÑÁ®Æ LLM Êû∂ÊßãÈÄ≤Ë°åÂª£Ê≥õÁöÑÂØ¶È©óÔºå‰∏¶ÊØîËºÉÂÖ∂Ê∫ñÁ¢∫ÊÄß„ÄÇÊàëÂÄëÂ∞ç‰æÜËá™ NVD Âíå SARD ÁöÑÁúüÂØ¶‰∏ñÁïåÂíåÂêàÊàêÁ®ãÂºèÁ¢ºÈÄ≤Ë°åÁöÑÂÖ®Èù¢ÂØ¶È©óÔºåË≠âÊòé‰∫ÜÂú®Ë≠òÂà•ÂéüÂßãÁ¢ºÊºèÊ¥ûÊñπÈù¢ÂÖ∑ÊúâÂæàÈ´òÁöÑÊ∫ñÁ¢∫ÊÄß„ÄÇ

##### **Can LLMs Serve As Time Series Anomaly Detectors?**
2408.03475v1 by Manqing Dong, Hao Huang, Longbing Cao

An emerging topic in large language models (LLMs) is their application to
time series forecasting, characterizing mainstream and patternable
characteristics of time series. A relevant but rarely explored and more
challenging question is whether LLMs can detect and explain time series
anomalies, a critical task across various real-world applications. In this
paper, we investigate the capabilities of LLMs, specifically GPT-4 and LLaMA3,
in detecting and explaining anomalies in time series. Our studies reveal that:
1) LLMs cannot be directly used for time series anomaly detection. 2) By
designing prompt strategies such as in-context learning and chain-of-thought
prompting, GPT-4 can detect time series anomalies with results competitive to
baseline methods. 3) We propose a synthesized dataset to automatically generate
time series anomalies with corresponding explanations. By applying instruction
fine-tuning on this dataset, LLaMA3 demonstrates improved performance in time
series anomaly detection tasks. In summary, our exploration shows the promising
potential of LLMs as time series anomaly detectors.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏≠‰∏ÄÂÄãÊñ∞ËààÁöÑ‰∏ªÈ°åÊòØÂÖ∂Âú®ÊôÇÈñìÂ∫èÂàóÈ†êÊ∏¨‰∏≠ÁöÑÊáâÁî®ÔºåÊèèËø∞ÊôÇÈñìÂ∫èÂàóÁöÑ‰∏ªÊµÅÂíåÂèØÊ®°ÂºèÂåñÁâπÂæµ„ÄÇ‰∏ÄÂÄãÁõ∏Èóú‰ΩÜÈÆÆÂ∞ëÊé¢Ë®é‰∏îÊõ¥ÂÖ∑ÊåëÊà∞ÊÄßÁöÑÂïèÈ°åÊòØ LLM ÊòØÂê¶ËÉΩÂÅµÊ∏¨‰∏¶Ëß£ÈáãÊôÇÈñìÂ∫èÂàóÁï∞Â∏∏ÂÄºÔºåÈÄôÊòØ‰∏ÄÂÄãÂêÑÁ®ÆÂØ¶ÈöõÊáâÁî®‰∏≠Ëá≥ÈóúÈáçË¶ÅÁöÑ‰ªªÂãô„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é LLM ÁöÑËÉΩÂäõÔºåÁâπÂà•ÊòØ GPT-4 Âíå LLaMA3ÔºåÂú®ÊôÇÈñìÂ∫èÂàó‰∏≠ÂÅµÊ∏¨‰∏¶Ëß£ÈáãÁï∞Â∏∏ÂÄº„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂È°ØÁ§∫Ôºö
1) LLM ÁÑ°Ê≥ïÁõ¥Êé•Áî®ÊñºÊôÇÈñìÂ∫èÂàóÁï∞Â∏∏ÂÄºÂÅµÊ∏¨„ÄÇ2) ÈÄèÈÅéË®≠Ë®àÊèêÁ§∫Á≠ñÁï•Ôºå‰æãÂ¶ÇÊÉÖÂ¢ÉÂ≠∏ÁøíÂíåÊÄùÊÉ≥ÈèàÊèêÁ§∫ÔºåGPT-4 ÂèØ‰ª•ÂÅµÊ∏¨ÊôÇÈñìÂ∫èÂàóÁï∞Â∏∏ÂÄºÔºåÂÖ∂ÁµêÊûúËàáÂü∫Ê∫ñÊñπÊ≥ïÂÖ∑ÊúâÁ´∂Áà≠Âäõ„ÄÇ3) ÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÁ∂úÂêàË≥áÊñôÈõÜÔºå‰ª•Ëá™ÂãïÁî¢ÁîüÂ∏∂ÊúâÂ∞çÊáâËß£ÈáãÁöÑÊôÇÈñìÂ∫èÂàóÁï∞Â∏∏ÂÄº„ÄÇÈÄèÈÅéÂú®Ê≠§Ë≥áÊñôÈõÜ‰∏äÊáâÁî®Êåá‰ª§ÂæÆË™øÔºåLLaMA3 Âú®ÊôÇÈñìÂ∫èÂàóÁï∞Â∏∏ÂÄºÂÅµÊ∏¨‰ªªÂãô‰∏≠Â±ïÁèæÂá∫ÈÄ≤Ê≠•ÁöÑÊïàËÉΩ„ÄÇÁ∏ΩËÄåË®Ä‰πãÔºåÊàëÂÄëÁöÑÊé¢Ë®éÈ°ØÁ§∫Âá∫ LLM ‰ΩúÁÇ∫ÊôÇÈñìÂ∫èÂàóÁï∞Â∏∏ÂÄºÂÅµÊ∏¨Âô®ÁöÑÊΩõÂäõ„ÄÇ

##### **Identifying treatment response subgroups in observational time-to-event data**
2408.03463v1 by Vincent Jeanselme, Chang Ho Yoon, Fabian Falck, Brian Tom, Jessica Barrett

Identifying patient subgroups with different treatment responses is an
important task to inform medical recommendations, guidelines, and the design of
future clinical trials. Existing approaches for subgroup analysis primarily
focus on Randomised Controlled Trials (RCTs), in which treatment assignment is
randomised. Furthermore, the patient cohort of an RCT is often constrained by
cost, and is not representative of the heterogeneity of patients likely to
receive treatment in real-world clinical practice. Therefore, when applied to
observational studies, such approaches suffer from significant statistical
biases because of the non-randomisation of treatment. Our work introduces a
novel, outcome-guided method for identifying treatment response subgroups in
observational studies. Our approach assigns each patient to a subgroup
associated with two time-to-event distributions: one under treatment and one
under control regime. It hence positions itself in between individualised and
average treatment effect estimation. The assumptions of our model result in a
simple correction of the statistical bias from treatment non-randomisation
through inverse propensity weighting. In experiments, our approach
significantly outperforms the current state-of-the-art method for
outcome-guided subgroup analysis in both randomised and observational treatment
regimes.

ÊëòË¶ÅÔºöË≠òÂà•ÂÖ∑Êúâ‰∏çÂêåÊ≤ªÁôÇÂèçÊáâÁöÑÊÇ£ËÄÖÂ≠êÁæ§ÊòØÁÇ∫ÈÜ´ÁôÇÂª∫Ë≠∞„ÄÅÊåáÂçóÂíåÊú™‰æÜËá®Â∫äË©¶È©óÁöÑË®≠Ë®àÊèê‰æõË≥áË®äÁöÑ‰∏ÄÈ†ÖÈáçË¶Å‰ªªÂãô„ÄÇÁèæÊúâÁöÑÂ≠êÁæ§ÂàÜÊûêÊñπÊ≥ï‰∏ªË¶ÅÈõÜ‰∏≠ÊñºÈö®Ê©üÂ∞çÁÖßË©¶È©ó (RCT)ÔºåÂÖ∂‰∏≠Ê≤ªÁôÇÂàÜÈÖçÊòØÈö®Ê©üÁöÑ„ÄÇÊ≠§Â§ñÔºåRCT ÁöÑÊÇ£ËÄÖÁæ§È´îÈÄöÂ∏∏ÂèóÂà∞ÊàêÊú¨ÁöÑÈôêÂà∂Ôºå‰∏îÁÑ°Ê≥ï‰ª£Ë°®Âú®ÁèæÂØ¶‰∏ñÁïåËá®Â∫äÂØ¶Âãô‰∏≠ÂèØËÉΩÊé•ÂèóÊ≤ªÁôÇÁöÑÊÇ£ËÄÖÁï∞Ë≥™ÊÄß„ÄÇÂõ†Ê≠§ÔºåÁï∂ÊáâÁî®ÊñºËßÄÂØüÊÄßÁ†îÁ©∂ÊôÇÔºåÊ≠§È°ûÊñπÊ≥ïÊúÉÂõ†Ê≤ªÁôÇÁöÑÈùûÈö®Ê©üÂåñËÄåÁî¢ÁîüÈ°ØËëóÁöÑÁµ±Ë®àÂÅèÂ∑Æ„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÂºïÂÖ•‰∫Ü‰∏ÄÁ®ÆÊñ∞ÁöÑ„ÄÅÁµêÊûúÂ∞éÂêëÁöÑÊñπÊ≥ïÔºåÁî®ÊñºË≠òÂà•ËßÄÂØüÊÄßÁ†îÁ©∂‰∏≠ÁöÑÊ≤ªÁôÇÂèçÊáâÂ≠êÁæ§„ÄÇÊàëÂÄëÁöÑÂÅöÊ≥ïÊòØÂ∞áÊØèÂÄãÊÇ£ËÄÖÂàÜÈÖçÂà∞‰∏ÄÂÄãÂ≠êÁæ§ÔºåË©≤Â≠êÁæ§ËàáÂÖ©ÂÄã‰∫ã‰ª∂ÁôºÁîüÊôÇÈñìÂàÜÈÖçÁõ∏ÈóúÔºö‰∏ÄÂÄãÂú®Ê≤ªÁôÇ‰∏ãÔºåÂè¶‰∏ÄÂÄãÂú®Â∞çÁÖßÊ©üÂà∂‰∏ã„ÄÇÂõ†Ê≠§ÔºåÂÆÉ‰ªãÊñºÂÄãÂà•ÂåñÂíåÂπ≥ÂùáÊ≤ªÁôÇÊïàÊûú‰º∞Ë®à‰πãÈñì„ÄÇÊàëÂÄëÊ®°ÂûãÁöÑÂÅáË®≠Â∞éËá¥ÈÄöÈÅéÈÄÜÂêëÂÇæÂêëÂä†Ê¨äÂ∞ç‰æÜËá™Ê≤ªÁôÇÈùûÈö®Ê©üÂåñÁöÑÁµ±Ë®àÂÅèÂ∑ÆÈÄ≤Ë°åÁ∞°ÂñÆÊ†°Ê≠£„ÄÇÂú®ÂØ¶È©ó‰∏≠ÔºåÊàëÂÄëÁöÑÂÅöÊ≥ïÂú®Èö®Ê©üÂíåËßÄÂØüÊÄßÊ≤ªÁôÇÊ©üÂà∂‰∏≠ÈÉΩÈ°ØËëóÂÑ™ÊñºÁï∂ÂâçÊúÄÂÖàÈÄ≤ÁöÑÁµêÊûúÂ∞éÂêëÂ≠êÁæ§ÂàÜÊûêÊñπÊ≥ï„ÄÇ

##### **EEGMobile: Enhancing Speed and Accuracy in EEG-Based Gaze Prediction with Advanced Mobile Architectures**
2408.03449v1 by Teng Liang, Andrews Damoah

Electroencephalography (EEG) analysis is an important domain in the realm of
Brain-Computer Interface (BCI) research. To ensure BCI devices are capable of
providing practical applications in the real world, brain signal processing
techniques must be fast, accurate, and resource-conscious to deliver
low-latency neural analytics. This study presents a model that leverages a
pre-trained MobileViT alongside Knowledge Distillation (KD) for EEG regression
tasks. Our results showcase that this model is capable of performing at a level
comparable (only 3% lower) to the previous State-Of-The-Art (SOTA) on the
EEGEyeNet Absolute Position Task while being 33% faster and 60% smaller. Our
research presents a cost-effective model applicable to resource-constrained
devices and contributes to expanding future research on lightweight,
mobile-friendly models for EEG regression.

ÊëòË¶ÅÔºöËÖ¶ÈõªÂúñ (EEG) ÂàÜÊûêÊòØËÖ¶Ê©ü‰ªãÈù¢ (BCI) Á†îÁ©∂‰∏≠ÁöÑ‰∏ÄÂÄãÈáçË¶ÅÈ†òÂüü„ÄÇÁÇ∫‰∫ÜÁ¢∫‰øù BCI Ë£ùÁΩÆËÉΩÂ§†Âú®ÁèæÂØ¶‰∏ñÁïå‰∏≠Êèê‰æõÂØ¶ÈöõÊáâÁî®ÔºåËÖ¶‰ø°ËôüËôïÁêÜÊäÄË°ìÂøÖÈ†àÂø´ÈÄü„ÄÅÊ∫ñÁ¢∫‰∏îÊ≥®ÈáçË≥áÊ∫êÔºåÊâçËÉΩÊèê‰æõ‰ΩéÂª∂ÈÅ≤Á•ûÁ∂ìÂàÜÊûê„ÄÇÊú¨Á†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÊ®°ÂûãÔºåË©≤Ê®°ÂûãÂà©Áî®È†êÂÖàË®ìÁ∑¥ÁöÑ MobileViT ËàáÁü•Ë≠òËí∏È§æ (KD) ‰æÜÈÄ≤Ë°å EEG ÂõûÊ≠∏‰ªªÂãô„ÄÇÊàëÂÄëÁöÑÁµêÊûúÈ°ØÁ§∫ÔºåÈÄôÂÄãÊ®°ÂûãËÉΩÂ§†‰ª•ËàáÂÖàÂâçÊúÄÂÖàÈÄ≤ÊäÄË°ì (SOTA) Áõ∏Áï∂ÁöÑÂ±§Á¥öÂü∑Ë°åÔºàÂÉÖ‰Ωé 3%ÔºâÔºåÂêåÊôÇÂü∑Ë°åÈÄüÂ∫¶Âø´ 33%ÔºåÂ§ßÂ∞èÂ∞è 60%„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÊèêÂá∫‰∏ÄÂÄãÈÅ©Áî®ÊñºÂèóÈôêË≥áÊ∫êË£ùÁΩÆÁöÑÂÖ∑ÊàêÊú¨ÊïàÁõäÊ®°ÂûãÔºå‰∏¶ÊúâÂä©ÊñºÊì¥Â±ïÊú™‰æÜÈáùÂ∞ç EEG ÂõûÊ≠∏ÁöÑËºïÈáèÂåñ„ÄÅÈÅ©Áî®ÊñºË°åÂãïË£ùÁΩÆÁöÑÊ®°ÂûãÁ†îÁ©∂„ÄÇ

##### **Logistic Regression makes small LLMs strong and explainable "tens-of-shot" classifiers**
2408.03414v1 by Marcus Buckmann, Edward Hill

For simple classification tasks, we show that users can benefit from the
advantages of using small, local, generative language models instead of large
commercial models without a trade-off in performance or introducing extra
labelling costs. These advantages, including those around privacy,
availability, cost, and explainability, are important both in commercial
applications and in the broader democratisation of AI. Through experiments on
17 sentence classification tasks (2-4 classes), we show that penalised logistic
regression on the embeddings from a small LLM equals (and usually betters) the
performance of a large LLM in the "tens-of-shot" regime. This requires no more
labelled instances than are needed to validate the performance of the large
LLM. Finally, we extract stable and sensible explanations for classification
decisions.

ÊëòË¶ÅÔºöÂ∞çÊñºÁ∞°ÂñÆÁöÑÂàÜÈ°û‰ªªÂãôÔºåÊàëÂÄëÂ±ïÁ§∫‰∫Ü‰ΩøÁî®ËÄÖÂèØ‰ª•ÂèóÁõäÊñº‰ΩøÁî®Â∞èÂûã„ÄÅÊú¨Âú∞ÁöÑÁîüÊàêË™ûË®ÄÊ®°ÂûãÔºåËÄå‰∏çÊòØÂ§ßÂûãÂïÜÊ•≠Ê®°ÂûãÔºåËÄå‰∏çÊúÉÂú®ÊïàËÉΩ‰∏äÊúâÊâÄÂèñÊç®ÊàñÁî¢ÁîüÈ°çÂ§ñÁöÑÊ®ôË®òÊàêÊú¨„ÄÇÈÄô‰∫õÂÑ™ÈªûÔºåÂåÖÊã¨Èö±ÁßÅ„ÄÅÂèØÁî®ÊÄß„ÄÅÊàêÊú¨ÂíåÂèØËß£ÈáãÊÄßÔºåÂú®ÂïÜÊ•≠ÊáâÁî®ÂíåÊõ¥Âª£Ê≥õÁöÑ AI Ê∞ë‰∏ªÂåñ‰∏≠ÈÉΩÂæàÈáçË¶Å„ÄÇÈÄèÈÅéÂ∞ç 17 ÂÄãÂè•Â≠êÂàÜÈ°û‰ªªÂãôÔºà2-4 ÂÄãÈ°ûÂà•ÔºâÈÄ≤Ë°åÂØ¶È©óÔºåÊàëÂÄëÂ±ïÁ§∫‰∫ÜÂ∞ç‰æÜËá™Â∞èÂûã LLM ÁöÑÂµåÂÖ•ÈÄ≤Ë°åÊá≤ÁΩ∞ÂºèÈÇèËºØËø¥Ê≠∏Á≠âÊñºÔºàÈÄöÂ∏∏ÂÑ™ÊñºÔºâÂ§ßÂûã LLM Âú®„ÄåÊï∏ÂçÅÊ¨°ÊãçÊîù„ÄçÊ®°Âºè‰∏ãÁöÑÊïàËÉΩ„ÄÇÈÄô‰∏çÈúÄË¶ÅÊØîÈ©óË≠âÂ§ßÂûã LLM ÁöÑÊïàËÉΩÊâÄÈúÄÁöÑÊ®ôË®òÂØ¶‰æãÊõ¥Â§ö„ÄÇÊúÄÂæåÔºåÊàëÂÄëÈáùÂ∞çÂàÜÈ°ûÊ±∫Á≠ñÊèêÂèñÂá∫Á©©ÂÆö‰∏îÊòéÊô∫ÁöÑËß£Èáã„ÄÇ

##### **Combining Diverse Information for Coordinated Action: Stochastic Bandit Algorithms for Heterogeneous Agents**
2408.03405v1 by Lucia Gordon, Esther Rolf, Milind Tambe

Stochastic multi-agent multi-armed bandits typically assume that the rewards
from each arm follow a fixed distribution, regardless of which agent pulls the
arm. However, in many real-world settings, rewards can depend on the
sensitivity of each agent to their environment. In medical screening, disease
detection rates can vary by test type; in preference matching, rewards can
depend on user preferences; and in environmental sensing, observation quality
can vary across sensors. Since past work does not specify how to allocate
agents of heterogeneous but known sensitivity of these types in a stochastic
bandit setting, we introduce a UCB-style algorithm, Min-Width, which aggregates
information from diverse agents. In doing so, we address the joint challenges
of (i) aggregating the rewards, which follow different distributions for each
agent-arm pair, and (ii) coordinating the assignments of agents to arms.
Min-Width facilitates efficient collaboration among heterogeneous agents,
exploiting the known structure in the agents' reward functions to weight their
rewards accordingly. We analyze the regret of Min-Width and conduct
pseudo-synthetic and fully synthetic experiments to study the performance of
different levels of information sharing. Our results confirm that the gains to
modeling agent heterogeneity tend to be greater when the sensitivities are more
varied across agents, while combining more information does not always improve
performance.

ÊëòË¶ÅÔºöÈö®Ê©üÂ§öÊô∫ËÉΩÈ´îÂ§öËáÇË≥≠ÂæíÈÄöÂ∏∏ÂÅáË®≠ÊØèÂÄãÊâãËáÇÁöÑÂõûÂ†±ÈÅµÂæ™Âõ∫ÂÆöÂàÜ‰ΩàÔºåÁÑ°Ë´ñÂì™ÂÄãÊô∫ËÉΩÈ´îÊãâÂãïÊâãËáÇ„ÄÇÁÑ∂ËÄåÔºåÂú®Ë®±Â§öÁúüÂØ¶‰∏ñÁïåË®≠ÂÆö‰∏≠ÔºåÂõûÂ†±ÂèØËÉΩÂèñÊ±∫ÊñºÊØèÂÄãÊô∫ËÉΩÈ´îÂ∞çÂÖ∂Áí∞Â¢ÉÁöÑÊïèÊÑüÂ∫¶„ÄÇÂú®ÈÜ´Â≠∏ÁØ©Ê™¢‰∏≠ÔºåÁñæÁóÖÊ™¢Ê∏¨ÁéáÊúÉÂõ†Ê∏¨Ë©¶È°ûÂûãËÄåÁï∞ÔºõÂú®ÂÅèÂ•ΩÂåπÈÖç‰∏≠ÔºåÂõûÂ†±ÂèØËÉΩÂèñÊ±∫Êñº‰ΩøÁî®ËÄÖÂÅèÂ•ΩÔºõÂú®Áí∞Â¢ÉÊÑüÊ∏¨‰∏≠ÔºåËßÄÂØüÂìÅË≥™ÂèØËÉΩÂõ†ÊÑüÊ∏¨Âô®ËÄåÁï∞„ÄÇÁî±ÊñºÈÅéÂéªÁöÑÂ∑•‰ΩúÊú™Ë™™ÊòéÂ¶Ç‰ΩïÈÖçÁΩÆÈÄô‰∫õÈ°ûÂûãÁï∞Ë≥™‰ΩÜÂ∑≤Áü•ÊïèÊÑüÂ∫¶ÁöÑÊô∫ËÉΩÈ´îÂú®Èö®Ê©üË≥≠ÂæíË®≠ÂÆö‰∏≠ÔºåÊàëÂÄëÂºïÂÖ•‰∏ÄÁ®Æ UCB È¢®Ê†ºÊºîÁÆóÊ≥ïÔºåMin-WidthÔºåÂÆÉÊúÉÂΩôÁ∏Ω‰æÜËá™‰∏çÂêåÊô∫ËÉΩÈ´îÁöÑË≥áË®ä„ÄÇÂú®ÈÄôÊ®£ÂÅöÁöÑÈÅéÁ®ã‰∏≠ÔºåÊàëÂÄëËß£Ê±∫‰∫Ü (i) ÂΩôÁ∏ΩÂõûÂ†±ÁöÑÂÖ±ÂêåÊåëÊà∞ÔºåÈÄô‰∫õÂõûÂ†±ÈÅµÂæ™ÊØèÂÄãÊô∫ËÉΩÈ´îÊâãËáÇÈÖçÂ∞çÁöÑ‰∏çÂêåÂàÜ‰ΩàÔºå‰ª•Âèä (ii) ÂçîË™øÂ∞áÊô∫ËÉΩÈ´îÊåáÂÆöÁµ¶ÊâãËáÇ„ÄÇMin-Width ‰øÉÈÄ≤Áï∞Ë≥™Êô∫ËÉΩÈ´î‰πãÈñìÁöÑÊúâÊïàÂçî‰ΩúÔºåÂà©Áî®Êô∫ËÉΩÈ´îÂõûÂ†±ÂáΩÊï∏‰∏≠ÁöÑÂ∑≤Áü•ÁµêÊßã‰æÜÈÅ©Áï∂Âú∞Âä†Ê¨äÂÖ∂ÂõûÂ†±„ÄÇÊàëÂÄëÂàÜÊûê Min-Width ÁöÑÈÅ∫ÊÜæÔºå‰∏¶ÈÄ≤Ë°åÂÅΩÂêàÊàêÂíåÂÆåÂÖ®ÂêàÊàêÂØ¶È©ó‰æÜÁ†îÁ©∂‰∏çÂêåÂ±§Á¥öË≥áË®äÂÖ±‰∫´ÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÁµêÊûúË≠âÂØ¶ÔºåÁï∂ÊïèÊÑüÂ∫¶Âú®‰∏çÂêåÊô∫ËÉΩÈ´îÈñìÂ∑ÆÁï∞ËºÉÂ§ßÊôÇÔºåÂ∞çÊô∫ËÉΩÈ´îÁï∞Ë≥™ÊÄßÂª∫Ê®°ÁöÑÊî∂ÁõäÂæÄÂæÄËºÉÈ´òÔºåËÄåÁµêÂêàÊõ¥Â§öË≥áË®ä‰∏¶‰∏çÁ∏ΩÊòØÊúÉÊîπÂñÑÊïàËÉΩ„ÄÇ

##### **ULLME: A Unified Framework for Large Language Model Embeddings with Generation-Augmented Learning**
2408.03402v1 by Hieu Man, Nghia Trung Ngo, Franck Dernoncourt, Thien Huu Nguyen

Large Language Models (LLMs) excel in various natural language processing
tasks, but leveraging them for dense passage embedding remains challenging.
This is due to their causal attention mechanism and the misalignment between
their pre-training objectives and the text ranking tasks. Despite some recent
efforts to address these issues, existing frameworks for LLM-based text
embeddings have been limited by their support for only a limited range of LLM
architectures and fine-tuning strategies, limiting their practical application
and versatility. In this work, we introduce the Unified framework for Large
Language Model Embedding (ULLME), a flexible, plug-and-play implementation that
enables bidirectional attention across various LLMs and supports a range of
fine-tuning strategies. We also propose Generation-augmented Representation
Learning (GRL), a novel fine-tuning method to boost LLMs for text embedding
tasks. GRL enforces consistency between representation-based and
generation-based relevance scores, leveraging LLMs' powerful generative
abilities for learning passage embeddings. To showcase our framework's
flexibility and effectiveness, we release three pre-trained models from ULLME
with different backbone architectures, ranging from 1.5B to 8B parameters, all
of which demonstrate strong performance on the Massive Text Embedding
Benchmark. Our framework is publicly available at:
https://github.com/nlp-uoregon/ullme. A demo video for ULLME can also be found
at https://rb.gy/ws1ile.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®ÂêÑÁ®ÆËá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãô‰∏≠Ë°®ÁèæÂá∫Ëâ≤Ôºå‰ΩÜÂà©Áî®ÂÆÉÂÄëÈÄ≤Ë°åÂØÜÈõÜÊÆµËêΩÂµåÂÖ•‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊà∞ÊÄß„ÄÇÈÄôÊòØÂõ†ÁÇ∫ÂÆÉÂÄëÁöÑÂõ†ÊûúÊ≥®ÊÑèÊ©üÂà∂‰ª•ÂèäÂÆÉÂÄëÁöÑÈ†êË®ìÁ∑¥ÁõÆÊ®ôËàáÊñáÊú¨ÊéíÂ∫è‰ªªÂãô‰πãÈñìÁöÑÈåØ‰Ωç„ÄÇÂÑòÁÆ°ÊúÄËøëÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÂÅöÂá∫‰∫Ü‰∫õË®±Âä™ÂäõÔºå‰ΩÜÁèæÊúâÁöÑÂü∫Êñº LLM ÁöÑÊñáÊú¨ÂµåÂÖ•Êû∂ÊßãÂèóÂà∞ÂÖ∂ÂÉÖÊîØÊè¥ÊúâÈôêÁØÑÂúçÁöÑ LLM Êû∂ÊßãÂíåÂæÆË™øÁ≠ñÁï•ÁöÑÈôêÂà∂ÔºåÂæûËÄåÈôêÂà∂‰∫ÜÂÆÉÂÄëÁöÑÂØ¶ÈöõÊáâÁî®ÂíåÂ§öÂäüËÉΩÊÄß„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂµåÂÖ•ÁöÑÁµ±‰∏ÄÊ°ÜÊû∂ (ULLME)ÔºåÈÄôÊòØ‰∏ÄÂÄãÈùàÊ¥ªÁöÑÂç≥ÊèíÂç≥Áî®ÂØ¶‰ΩúÔºåÂèØ‰ª•Âú®ÂêÑÁ®Æ LLM ‰∏≠ÂïüÁî®ÈõôÂêëÊ≥®ÊÑèÔºå‰∏¶ÊîØÊè¥‰∏ÄÁ≥ªÂàóÂæÆË™øÁ≠ñÁï•„ÄÇÊàëÂÄëÈÇÑÊèêÂá∫‰∫ÜÁîüÊàêÂ¢ûÂº∑Ë°®Á§∫Â≠∏Áøí (GRL)ÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞ÁöÑÂæÆË™øÊñπÊ≥ïÔºåÂèØ‰ª•ÊèêÂçá LLM ‰ª•ÈÄ≤Ë°åÊñáÊú¨ÂµåÂÖ•‰ªªÂãô„ÄÇGRL Á¢∫‰øùÂü∫ÊñºË°®Á§∫ÂíåÂü∫ÊñºÁîüÊàêÁöÑÁõ∏ÈóúÊÄßÂàÜÊï∏‰πãÈñìÁöÑ‰∏ÄËá¥ÊÄßÔºåÂà©Áî® LLM Âº∑Â§ßÁöÑÁîüÊàêËÉΩÂäõ‰æÜÂ≠∏ÁøíÊÆµËêΩÂµåÂÖ•„ÄÇÁÇ∫‰∫ÜÂ±ïÁ§∫ÊàëÂÄëÊ°ÜÊû∂ÁöÑÈùàÊ¥ªÊÄßËàáÊúâÊïàÊÄßÔºåÊàëÂÄëÂæû ULLME ÁôºÂ∏É‰∫Ü‰∏âÂÄãÈ†êË®ìÁ∑¥Ê®°ÂûãÔºåÂÆÉÂÄëÂÖ∑Êúâ‰∏çÂêåÁöÑ‰∏ªÂππÊû∂ÊßãÔºåÁØÑÂúçÂæû 1.5B Âà∞ 8B ÂèÉÊï∏ÔºåÊâÄÊúâÈÄô‰∫õÊ®°ÂûãÂú® Massive Text Embedding Benchmark ‰∏äÈÉΩË°®ÁèæÂá∫Âº∑ÂãÅÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÁöÑÊ°ÜÊû∂ÂÖ¨ÈñãÊñºÔºöhttps://github.com/nlp-uoregon/ullme„ÄÇULLME ÁöÑÁ§∫ÁØÑÂΩ±Áâá‰πüÂèØ‰ª•Âú® https://rb.gy/ws1ile ÊâæÂà∞„ÄÇ

##### **Attacks and Defenses for Generative Diffusion Models: A Comprehensive Survey**
2408.03400v1 by Vu Tuan Truong, Luan Ba Dang, Long Bao Le

Diffusion models (DMs) have achieved state-of-the-art performance on various
generative tasks such as image synthesis, text-to-image, and text-guided
image-to-image generation. However, the more powerful the DMs, the more harmful
they potentially are. Recent studies have shown that DMs are prone to a wide
range of attacks, including adversarial attacks, membership inference, backdoor
injection, and various multi-modal threats. Since numerous pre-trained DMs are
published widely on the Internet, potential threats from these attacks are
especially detrimental to the society, making DM-related security a worth
investigating topic. Therefore, in this paper, we conduct a comprehensive
survey on the security aspect of DMs, focusing on various attack and defense
methods for DMs. First, we present crucial knowledge of DMs with five main
types of DMs, including denoising diffusion probabilistic models, denoising
diffusion implicit models, noise conditioned score networks, stochastic
differential equations, and multi-modal conditional DMs. We further survey a
variety of recent studies investigating different types of attacks that exploit
the vulnerabilities of DMs. Then, we thoroughly review potential
countermeasures to mitigate each of the presented threats. Finally, we discuss
open challenges of DM-related security and envision certain research directions
for this topic.

ÊëòË¶ÅÔºöÊì¥Êï£Ê®°Âûã (DM) Âú®ÂêÑÁ®ÆÁîüÊàê‰ªªÂãô‰∏äÈÅîÂà∞‰∫ÜÊúÄÂÖàÈÄ≤ÁöÑÊÄßËÉΩÔºå‰æãÂ¶ÇÂΩ±ÂÉèÂêàÊàê„ÄÅÊñáÂ≠óËΩâÂΩ±ÂÉèÂíåÊñáÂ≠óÂºïÂ∞éÂΩ±ÂÉèËΩâÂΩ±ÂÉèÁîüÊàê„ÄÇÁÑ∂ËÄåÔºåDM Ë∂äÂº∑Â§ßÔºåÊΩõÂú®ÁöÑÂç±ÂÆ≥Â∞±Ë∂äÂ§ß„ÄÇÊúÄËøëÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåDM ÂÆπÊòìÂèóÂà∞Âª£Ê≥õÁöÑÊîªÊìäÔºåÂåÖÊã¨Â∞çÊäóÊÄßÊîªÊìä„ÄÅÊàêÂì°Êé®Ë´ñ„ÄÅÂæåÈñÄÊ≥®ÂÖ•ÂíåÂêÑÁ®ÆÂ§öÊ®°ÂºèÂ®ÅËÑÖ„ÄÇÁî±ÊñºË®±Â§öÈ†êÂÖàË®ìÁ∑¥ÁöÑ DM Âª£Ê≥õÁôºÂ∏ÉÂú®Á∂≤Ë∑Ø‰∏äÔºåÈÄô‰∫õÊîªÊìäÁöÑÊΩõÂú®Â®ÅËÑÖÁâπÂà•ÊúâÂÆ≥ÊñºÁ§æÊúÉÔºå‰ΩøÂæóËàá DM Áõ∏ÈóúÁöÑÂÆâÂÖ®ÊÄßÊàêÁÇ∫‰∏ÄÂÄãÂÄºÂæóÊé¢Ë®éÁöÑ‰∏ªÈ°å„ÄÇÂõ†Ê≠§ÔºåÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÂ∞ç DM ÁöÑÂÆâÂÖ®ÊÄßÊñπÈù¢ÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑË™øÊü•ÔºåÈáçÈªûÈóúÊ≥® DM ÁöÑÂêÑÁ®ÆÊîªÊìäÂíåÈò≤Á¶¶ÊñπÊ≥ï„ÄÇÈ¶ñÂÖàÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü DM ÁöÑÈóúÈçµÁü•Ë≠òÔºåÂåÖÊã¨‰∫îÁ®ÆÈ°ûÂûãÁöÑ DMÔºåÂåÖÊã¨ÂéªÂô™Êì¥Êï£Ê©üÁéáÊ®°Âûã„ÄÅÂéªÂô™Êì¥Êï£Èö±ÂºèÊ®°Âûã„ÄÅÈõúË®äÊ¢ù‰ª∂ÂàÜÊï∏Á∂≤Ë∑Ø„ÄÅÈö®Ê©üÂæÆÂàÜÊñπÁ®ãÂºèÂíåÂ§öÊ®°ÂºèÊ¢ù‰ª∂ DM„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Ë™øÊü•‰∫ÜÂêÑÁ®ÆÊúÄËøëÁöÑÁ†îÁ©∂ÔºåÊé¢Ë®é‰∫ÜÂà©Áî® DM ÊºèÊ¥ûÁöÑ‰∏çÂêåÈ°ûÂûãÁöÑÊîªÊìä„ÄÇÁÑ∂ÂæåÔºåÊàëÂÄëÂæπÂ∫ïÊ™¢Ë¶ñ‰∫ÜÊ∏õËºïÊØèÁ®ÆÂëàÁèæÂ®ÅËÑÖÁöÑÊΩõÂú®Â∞çÁ≠ñ„ÄÇÊúÄÂæåÔºåÊàëÂÄëË®éË´ñ‰∫ÜËàá DM Áõ∏ÈóúÁöÑÂÆâÂÖ®ÊÄßÁöÑÂÖ¨ÈñãÊåëÊà∞Ôºå‰∏¶È†êÊÉ≥ÈÄôÂÄã‰∏ªÈ°åÁöÑÊüê‰∫õÁ†îÁ©∂ÊñπÂêë„ÄÇ

##### **RHiOTS: A Framework for Evaluating Hierarchical Time Series Forecasting Algorithms**
2408.03399v1 by Luis Roque, Carlos Soares, Lu√≠s Torgo

We introduce the Robustness of Hierarchically Organized Time Series (RHiOTS)
framework, designed to assess the robustness of hierarchical time series
forecasting models and algorithms on real-world datasets. Hierarchical time
series, where lower-level forecasts must sum to upper-level ones, are prevalent
in various contexts, such as retail sales across countries. Current empirical
evaluations of forecasting methods are often limited to a small set of
benchmark datasets, offering a narrow view of algorithm behavior. RHiOTS
addresses this gap by systematically altering existing datasets and modifying
the characteristics of individual series and their interrelations. It uses a
set of parameterizable transformations to simulate those changes in the data
distribution. Additionally, RHiOTS incorporates an innovative visualization
component, turning complex, multidimensional robustness evaluation results into
intuitive, easily interpretable visuals. This approach allows an in-depth
analysis of algorithm and model behavior under diverse conditions. We
illustrate the use of RHiOTS by analyzing the predictive performance of several
algorithms. Our findings show that traditional statistical methods are more
robust than state-of-the-art deep learning algorithms, except when the
transformation effect is highly disruptive. Furthermore, we found no
significant differences in the robustness of the algorithms when applying
specific reconciliation methods, such as MinT. RHiOTS provides researchers with
a comprehensive tool for understanding the nuanced behavior of forecasting
algorithms, offering a more reliable basis for selecting the most appropriate
method for a given problem.

ÊëòË¶ÅÔºö<paragraph>ÊàëÂÄë‰ªãÁ¥πÈöéÂ±§ÂåñÊôÇÈñìÂ∫èÂàóÁöÑÁ©©ÂÅ•ÊÄß (RHiOTS) Ê°ÜÊû∂ÔºåÊó®Âú®Ë©ï‰º∞ÈöéÂ±§ÂåñÊôÇÈñìÂ∫èÂàóÈ†êÊ∏¨Ê®°ÂûãÂíåÊºîÁÆóÊ≥ïÂú®ÂØ¶ÈöõË≥áÊñôÈõÜ‰∏äÁöÑÁ©©ÂÅ•ÊÄß„ÄÇÈöéÂ±§ÂåñÊôÇÈñìÂ∫èÂàóÔºàÂÖ∂‰∏≠ËºÉ‰ΩéÂ±§Á¥öÁöÑÈ†êÊ∏¨ÂøÖÈ†àÂä†Á∏ΩÁÇ∫ËºÉÈ´òÂ±§Á¥öÁöÑÈ†êÊ∏¨ÔºâÂú®ÂêÑÁ®ÆÊÉÖÂ¢É‰∏≠ÂæàÂ∏∏Ë¶ãÔºå‰æãÂ¶ÇÂêÑÂúãÁöÑÈõ∂ÂîÆÈä∑ÂîÆ„ÄÇÈ†êÊ∏¨ÊñπÊ≥ïÁöÑÁèæÊúâÁ∂ìÈ©óË©ï‰º∞ÈÄöÂ∏∏ÂÉÖÈôêÊñºÂ∞ëÊï∏Âü∫Ê∫ñË≥áÊñôÈõÜÔºåÁÑ°Ê≥ïÂÖ®Èù¢‰∫ÜËß£ÊºîÁÆóÊ≥ïË°åÁÇ∫„ÄÇRHiOTS ÈÄèÈÅéÁ≥ªÁµ±ÊÄßÂú∞ÊîπËÆäÁèæÊúâË≥áÊñôÈõÜ‰∏¶‰øÆÊîπÂÄãÂà•Â∫èÂàóÂèäÂÖ∂Áõ∏‰∫íÈóú‰øÇÁöÑÁâπÂæµÔºå‰æÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°å„ÄÇÂÆÉ‰ΩøÁî®‰∏ÄÁµÑÂèØÂèÉÊï∏ÂåñÁöÑËΩâÊèõ‰æÜÊ®°Êì¨Ë≥áÊñôÂàÜ‰Ωà‰∏≠ÁöÑÈÄô‰∫õËÆäÂåñ„ÄÇÊ≠§Â§ñÔºåRHiOTS ÁµêÂêà‰∫Ü‰∏ÄÂÄãÂâµÊñ∞ÁöÑË¶ñË¶∫ÂåñÂÖÉ‰ª∂ÔºåÂ∞áË§áÈõúÁöÑÂ§öÁ∂≠Á©©ÂÅ•ÊÄßË©ï‰º∞ÁµêÊûúËΩâÊèõÁÇ∫Áõ¥ËßÄ‰∏îÊòìÊñºËß£ËÆÄÁöÑË¶ñË¶∫ÊïàÊûú„ÄÇÈÄôÁ®ÆÊñπÊ≥ïÂÖÅË®±Ê∑±ÂÖ•ÂàÜÊûêÊºîÁÆóÊ≥ïÂíåÊ®°ÂûãÂú®‰∏çÂêåÊ¢ù‰ª∂‰∏ãÁöÑË°åÁÇ∫„ÄÇÊàëÂÄëÈÄèÈÅéÂàÜÊûêÂ§öÁ®ÆÊºîÁÆóÊ≥ïÁöÑÈ†êÊ∏¨ÊïàËÉΩ‰æÜË™™Êòé RHiOTS ÁöÑ‰ΩøÁî®ÊñπÂºè„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúÈ°ØÁ§∫ÔºåÂÇ≥Áµ±ÁöÑÁµ±Ë®àÊñπÊ≥ïÊØîÊúÄÂÖàÈÄ≤ÁöÑÊ∑±Â∫¶Â≠∏ÁøíÊºîÁÆóÊ≥ïÊõ¥Á©©ÂÅ•ÔºåÈô§ÈùûËΩâÊèõÊïàÊáâÂÖ∑ÊúâÈ´òÂ∫¶Á†¥Â£ûÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁôºÁèæÁï∂ÊáâÁî®ÁâπÂÆöÁöÑË™øÂíåÊñπÊ≥ïÔºà‰æãÂ¶Ç MinTÔºâÊôÇÔºåÊºîÁÆóÊ≥ïÁöÑÁ©©ÂÅ•ÊÄßÊ≤íÊúâÈ°ØËëóÂ∑ÆÁï∞„ÄÇRHiOTS ÁÇ∫Á†îÁ©∂‰∫∫Âì°Êèê‰æõ‰∫Ü‰∏ÄÂÄãÂÖ®Èù¢ÁöÑÂ∑•ÂÖ∑ÔºåÁî®Êñº‰∫ÜËß£È†êÊ∏¨ÊºîÁÆóÊ≥ïÁöÑÁ¥∞ÂæÆË°åÁÇ∫Ôºå‰∏¶ÁÇ∫ÈÅ∏ÊìáÊúÄÈÅ©ÂêàÁâπÂÆöÂïèÈ°åÁöÑÊñπÊ≥ïÊèê‰æõÊõ¥ÂèØÈù†ÁöÑ‰æùÊìö„ÄÇ</paragraph>

##### **A Non-negative VAE:the Generalized Gamma Belief Network**
2408.03388v1 by Zhibin Duan, Tiansheng Wen, Muyao Wang, Bo Chen, Mingyuan Zhou

The gamma belief network (GBN), often regarded as a deep topic model, has
demonstrated its potential for uncovering multi-layer interpretable latent
representations in text data. Its notable capability to acquire interpretable
latent factors is partially attributed to sparse and non-negative
gamma-distributed latent variables. However, the existing GBN and its
variations are constrained by the linear generative model, thereby limiting
their expressiveness and applicability. To address this limitation, we
introduce the generalized gamma belief network (Generalized GBN) in this paper,
which extends the original linear generative model to a more expressive
non-linear generative model. Since the parameters of the Generalized GBN no
longer possess an analytic conditional posterior, we further propose an
upward-downward Weibull inference network to approximate the posterior
distribution of the latent variables. The parameters of both the generative
model and the inference network are jointly trained within the variational
inference framework. Finally, we conduct comprehensive experiments on both
expressivity and disentangled representation learning tasks to evaluate the
performance of the Generalized GBN against state-of-the-art Gaussian
variational autoencoders serving as baselines.

ÊëòË¶ÅÔºö‰ºΩÈ©¨‰ø°ÂøµÁ∂≤Ë∑Ø (GBN) ÈÄöÂ∏∏Ë¢´Ë¶ñÁÇ∫Ê∑±Â∫¶‰∏ªÈ°åÊ®°ÂûãÔºåÂ∑≤Â±ïÁèæÂá∫ÂÖ∂Âú®Ëß£ÊßãÊñáÊú¨Ë≥áÊñô‰∏≠Â§öÂ±§ÂèØËß£ÈáãÊΩõÂú®Ë°®ÂæµÁöÑÊΩõÂäõ„ÄÇÂÖ∂Áç≤ÂèñÂèØËß£ÈáãÊΩõÂú®Âõ†Â≠êÁöÑÈ°ØËëóËÉΩÂäõÈÉ®ÂàÜÊ≠∏Âõ†ÊñºÁ®ÄÁñè‰∏îÈùûË≤†ÁöÑ‰ºΩÈ¶¨ÂàÜÂ∏ÉÊΩõÂú®ËÆäÊï∏„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑ GBN ÂèäÂÖ∂ËÆäÁï∞ÂèóÂà∞Á∑öÊÄßÁîüÊàêÊ®°ÂûãÁöÑÁ¥ÑÊùüÔºåÂæûËÄåÈôêÂà∂‰∫ÜÂÖ∂Ë°®ÁèæÂäõÂíåÈÅ©Áî®ÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÈôêÂà∂ÔºåÊàëÂÄëÂú®ÈÄôÁØáË´ñÊñá‰∏≠ÂºïÂÖ•‰∫ÜÂª£Áæ©‰ºΩÈ¶¨‰ø°ÂøµÁ∂≤Ë∑Ø (Âª£Áæ© GBN)ÔºåÂÆÉÂ∞áÂéüÂßãÁ∑öÊÄßÁîüÊàêÊ®°ÂûãÊì¥Â±ïÂà∞Êõ¥ÂÖ∑Ë°®ÁèæÂäõÁöÑÈùûÁ∑öÊÄßÁîüÊàêÊ®°Âûã„ÄÇÁî±ÊñºÂª£Áæ© GBN ÁöÑÂèÉÊï∏‰∏çÂÜçÂÖ∑ÊúâËß£ÊûêÊ¢ù‰ª∂ÂæåÈ©óÔºåÊàëÂÄëÈÄ≤‰∏ÄÊ≠•ÊèêÂá∫‰∫ÜÂêë‰∏äÂêë‰∏ãÂ®ÅÂ∏ÉÁàæÊé®Ë´ñÁ∂≤Ë∑Ø‰æÜËøë‰ººÊΩõÂú®ËÆäÊï∏ÁöÑÂæåÈ©óÂàÜ‰Ωà„ÄÇÁîüÊàêÊ®°ÂûãÂíåÊé®Ë´ñÁ∂≤Ë∑ØÁöÑÂèÉÊï∏Âú®ËÆäÂàÜÊé®Ë´ñÊû∂ÊßãÂÖßËÅØÂêàË®ìÁ∑¥„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ∞çË°®ÁèæÂäõÂíåËß£Á≥æÁ∫èË°®ÂæµÂ≠∏Áøí‰ªªÂãôÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÁöÑÂØ¶È©óÔºå‰ª•Ë©ï‰º∞Âª£Áæ© GBN Áõ∏Â∞çÊñº‰ΩúÁÇ∫Âü∫Ê∫ñÁöÑÈ´òÊñØËÆäÂàÜËá™ÂãïÁ∑®Á¢ºÂô®ÁöÑÊïàËÉΩ„ÄÇ

##### **LLaVA-OneVision: Easy Visual Task Transfer**
2408.03326v1 by Bo Li, Yuanhan Zhang, Dong Guo, Renrui Zhang, Feng Li, Hao Zhang, Kaichen Zhang, Yanwei Li, Ziwei Liu, Chunyuan Li

We present LLaVA-OneVision, a family of open large multimodal models (LMMs)
developed by consolidating our insights into data, models, and visual
representations in the LLaVA-NeXT blog series. Our experimental results
demonstrate that LLaVA-OneVision is the first single model that can
simultaneously push the performance boundaries of open LMMs in three important
computer vision scenarios: single-image, multi-image, and video scenarios.
Importantly, the design of LLaVA-OneVision allows strong transfer learning
across different modalities/scenarios, yielding new emerging capabilities. In
particular, strong video understanding and cross-scenario capabilities are
demonstrated through task transfer from images to videos.

ÊëòË¶ÅÔºöÊàëÂÄëÂ±ïÁ§∫ LLaVA-OneVisionÔºå‰∏ÄÂÄãÈñãÊîæÂºèÂ§ßÂûãÂ§öÊ®°ÊÖãÊ®°Âûã (LMM) ÂÆ∂ÊóèÔºå
ÈÄèÈÅéÊï¥ÂêàÊàëÂÄëÂ∞ç LLaVA-NeXT ÈÉ®ËêΩÊ†ºÁ≥ªÂàó‰∏≠Ë≥áÊñô„ÄÅÊ®°ÂûãÂíåË¶ñË¶∫
Ë°®ÁèæÁöÑË¶ãËß£ËÄåÈñãÁôº„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÁµêÊûúË≠âÊòé LLaVA-OneVision ÊòØÁ¨¨‰∏ÄÂÄãÂñÆ‰∏ÄÊ®°ÂûãÔºåÂèØ‰ª•
ÂêåÊôÇÂú®‰∏âÂÄãÈáçË¶ÅÁöÑÈõªËÖ¶Ë¶ñË¶∫Â†¥ÊôØ‰∏≠Êì¥Â±ïÈñãÊîæÂºè LMM ÁöÑÊïàËÉΩÁïåÈôêÔºöÂñÆ‰∏ÄÂΩ±ÂÉè„ÄÅÂ§öÈáçÂΩ±ÂÉèÂíåÂΩ±ÁâáÂ†¥ÊôØ„ÄÇ
ÈáçË¶ÅÁöÑÊòØÔºåLLaVA-OneVision ÁöÑË®≠Ë®àÂÖÅË®±Âú®‰∏çÂêåÁöÑÊ®°ÊÖã/Â†¥ÊôØ‰∏≠ÈÄ≤Ë°åÂº∑Â§ßÁöÑËΩâÁßªÂ≠∏ÁøíÔºåÁî¢ÁîüÊñ∞ÁöÑÊñ∞ËààËÉΩÂäõ„ÄÇÁâπÂà•ÊòØÔºå
ÈÄèÈÅéÂæûÂΩ±ÂÉèÂà∞ÂΩ±ÁâáÁöÑ‰ªªÂãôËΩâÁßªÔºåÂ±ïÁ§∫‰∫ÜÂº∑Â§ßÁöÑÂΩ±ÁâáÁêÜËß£ÂíåË∑®Â†¥ÊôØËÉΩÂäõ„ÄÇ

##### **CoverBench: A Challenging Benchmark for Complex Claim Verification**
2408.03325v1 by Alon Jacovi, Moran Ambar, Eyal Ben-David, Uri Shaham, Amir Feder, Mor Geva, Dror Marcus, Avi Caciularu

There is a growing line of research on verifying the correctness of language
models' outputs. At the same time, LMs are being used to tackle complex queries
that require reasoning. We introduce CoverBench, a challenging benchmark
focused on verifying LM outputs in complex reasoning settings. Datasets that
can be used for this purpose are often designed for other complex reasoning
tasks (e.g., QA) targeting specific use-cases (e.g., financial tables),
requiring transformations, negative sampling and selection of hard examples to
collect such a benchmark. CoverBench provides a diversified evaluation for
complex claim verification in a variety of domains, types of reasoning,
relatively long inputs, and a variety of standardizations, such as multiple
representations for tables where available, and a consistent schema. We
manually vet the data for quality to ensure low levels of label noise. Finally,
we report a variety of competitive baseline results to show CoverBench is
challenging and has very significant headroom. The data is available at
https://huggingface.co/datasets/google/coverbench .

ÊëòË¶ÅÔºöÂ∞çÊñºÈ©óË≠âË™ûË®ÄÊ®°ÂûãËº∏Âá∫ÁöÑÊ≠£Á¢∫ÊÄßÔºåÊúâË∂ä‰æÜË∂äÂ§öÁöÑÁ†îÁ©∂„ÄÇÂêåÊôÇÔºåLM Ë¢´Áî®ÊñºËß£Ê±∫ÈúÄË¶ÅÊé®ÁêÜÁöÑË§áÈõúÊü•Ë©¢„ÄÇÊàëÂÄë‰ªãÁ¥π CoverBenchÔºåÈÄôÊòØ‰∏ÄÂÄãÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÂü∫Ê∫ñÔºåÂ∞àÊ≥®ÊñºÈ©óË≠âË§áÈõúÊé®ÁêÜË®≠ÂÆö‰∏≠ÁöÑ LM Ëº∏Âá∫„ÄÇÂèØÁî®ÊñºÊ≠§ÁõÆÁöÑÁöÑË≥áÊñôÈõÜÈÄöÂ∏∏ÊòØÁÇ∫ÂÖ∂‰ªñË§áÈõúÊé®ÁêÜ‰ªªÂãôÔºà‰æãÂ¶ÇÔºåQAÔºâËÄåË®≠Ë®àÁöÑÔºåÈÄô‰∫õ‰ªªÂãôÈáùÂ∞çÁâπÂÆöÁî®‰æãÔºà‰æãÂ¶ÇÔºåË≤°ÂãôË°®Ê†ºÔºâÔºåÈúÄË¶ÅËΩâÊèõ„ÄÅË≤†Èù¢ÊäΩÊ®£ÂíåÈÅ∏ÊìáÂõ∞Èõ£ÁØÑ‰æã‰æÜÊî∂ÈõÜÊ≠§È°ûÂü∫Ê∫ñ„ÄÇCoverBench Êèê‰æõ‰∫ÜÂ∞çÂêÑÁ®ÆÈ†òÂüü„ÄÅÊé®ÁêÜÈ°ûÂûã„ÄÅÁõ∏Â∞çËºÉÈï∑ÁöÑËº∏ÂÖ•‰ª•ÂèäÂêÑÁ®ÆÊ®ôÊ∫ñÂåñÁöÑÂ§öÂÖÉË©ï‰º∞Ôºå‰æãÂ¶ÇË°®Ê†ºÁöÑÂêÑÁ®ÆË°®Á§∫ÔºàÂ¶ÇÊûúÂèØÁî®ÔºâÂíå‰∏ÄËá¥ÁöÑÊû∂Êßã„ÄÇÊàëÂÄëÊâãÂãïÂØ©Êü•Ë≥áÊñôÁöÑÂìÅË≥™Ôºå‰ª•Á¢∫‰øù‰ΩéÁ®ãÂ∫¶ÁöÑÊ®ôÁ±§ÈõúË®ä„ÄÇÊúÄÂæåÔºåÊàëÂÄëÂ†±Âëä‰∫ÜÂêÑÁ®ÆÁ´∂Áà≠ÊÄßÁöÑÂü∫Ê∫ñÁµêÊûúÔºå‰ª•È°ØÁ§∫ CoverBench ÂÖ∑ÊúâÊåëÊà∞ÊÄß‰∏îÊúâÈùûÂ∏∏È°ØËëóÁöÑÈÄ≤Ê≠•Á©∫Èñì„ÄÇË≥áÊñôÂèØÂú® https://huggingface.co/datasets/google/coverbench ÂèñÂæó„ÄÇ

##### **Training LLMs to Recognize Hedges in Spontaneous Narratives**
2408.03319v1 by Amie J. Paige, Adil Soubki, John Murzaku, Owen Rambow, Susan E. Brennan

Hedges allow speakers to mark utterances as provisional, whether to signal
non-prototypicality or "fuzziness", to indicate a lack of commitment to an
utterance, to attribute responsibility for a statement to someone else, to
invite input from a partner, or to soften critical feedback in the service of
face-management needs. Here we focus on hedges in an experimentally
parameterized corpus of 63 Roadrunner cartoon narratives spontaneously produced
from memory by 21 speakers for co-present addressees, transcribed to text
(Galati and Brennan, 2010). We created a gold standard of hedges annotated by
human coders (the Roadrunner-Hedge corpus) and compared three LLM-based
approaches for hedge detection: fine-tuning BERT, and zero and few-shot
prompting with GPT-4o and LLaMA-3. The best-performing approach was a
fine-tuned BERT model, followed by few-shot GPT-4o. After an error analysis on
the top performing approaches, we used an LLM-in-the-Loop approach to improve
the gold standard coding, as well as to highlight cases in which hedges are
ambiguous in linguistically interesting ways that will guide future research.
This is the first step in our research program to train LLMs to interpret and
generate collateral signals appropriately and meaningfully in conversation.

ÊëòË¶ÅÔºö<paragraph>Â∞çÊ≤ñÂÖÅË®±Ë™™Ë©±ËÄÖÂ∞áË®ÄË´ñÊ®ôË®òÁÇ∫Êö´ÂÆöÁöÑÔºåÁÑ°Ë´ñÊòØË¶ÅÊ®ôÁ§∫ÈùûÂéüÂûãÊàñ„ÄåÊ®°Á≥äÊÄß„ÄçÔºåË°®Á§∫Â∞çË®ÄË´ñÁº∫‰πèÊâøË´æÔºåÂ∞áËÅ≤ÊòéÁöÑË≤¨‰ªªÊ≠∏ÂíéÊñº‰ªñ‰∫∫ÔºåÈÇÄË´ãÂ§•‰º¥Êèê‰æõÊÑèË¶ãÔºåÊàñÂú®Èù¢Â≠êÁÆ°ÁêÜÈúÄÊ±ÇÁöÑÊúçÂãô‰∏≠ËªüÂåñÊâπË©ïÊÄßÁöÑÂõûÈ•ã„ÄÇÂú®ÈÄôË£°ÔºåÊàëÂÄëÂ∞àÊ≥®Êñº 21 ‰ΩçË™™Ë©±ËÄÖÁÇ∫ÂÖ±ÂêåÂá∫Â∏≠ÁöÑÂèóË©±ËÄÖËá™ÁôºÊÄßÂú∞ÂæûË®òÊÜ∂‰∏≠Áî¢Áîü 63 ÂÄã Roadrunner Âç°ÈÄöÊïò‰∫ãÁöÑÂØ¶È©óÊÄßÂèÉÊï∏ÂåñË™ûÊñôÂ∫´‰∏≠ÁöÑÂ∞çÊ≤ñÔºå‰∏¶ËΩâÈåÑÊàêÊñáÂ≠óÔºàGalati Âíå BrennanÔºå2010 Âπ¥Ôºâ„ÄÇÊàëÂÄëÂª∫Á´ã‰∫ÜÁî±‰∫∫È°ûÁ∑®Á¢ºÂô®Ë®ªÈáãÁöÑÂ∞çÊ≤ñÈªÉÈáëÊ®ôÊ∫ñÔºàRoadrunner-Hedge Ë™ûÊñôÂ∫´ÔºâÔºå‰∏¶ÊØîËºÉ‰∫Ü‰∏âÁ®ÆÂü∫Êñº LLM ÁöÑÂ∞çÊ≤ñÂÅµÊ∏¨ÊñπÊ≥ïÔºöÂæÆË™ø BERTÔºå‰ª•Âèä‰ΩøÁî® GPT-4o Âíå LLaMA-3 ÈÄ≤Ë°åÈõ∂Ê¨°ÂíåÂ∞ëÊ¨°ÊèêÁ§∫„ÄÇË°®ÁèæÊúÄ‰Ω≥ÁöÑÊñπÊ≥ïÊòØÂæÆË™øÂæåÁöÑ BERT Ê®°ÂûãÔºåÂÖ∂Ê¨°ÊòØÂ∞ëÊ¨°ÊèêÁ§∫ÁöÑ GPT-4o„ÄÇÂú®Â∞çË°®ÁèæÊúÄ‰Ω≥ÁöÑÊñπÊ≥ïÈÄ≤Ë°åÈåØË™§ÂàÜÊûêÂæåÔºåÊàëÂÄë‰ΩøÁî® LLM-in-the-Loop ÊñπÊ≥ï‰æÜÊîπÈÄ≤ÈªÉÈáëÊ®ôÊ∫ñÁ∑®Á¢ºÔºå‰∏¶Âº∑Ë™øÂ∞çÊ≤ñÂú®Ë™ûË®ÄÂ≠∏‰∏äÊúâË∂£ÁöÑÊñπÈù¢‰∏≠Ê®°Á®úÂÖ©ÂèØÁöÑÊÉÖÊ≥ÅÔºåÈÄôÂ∞áÊåáÂ∞éÊú™‰æÜÁöÑÁ†îÁ©∂„ÄÇÈÄôÊòØÊàëÂÄëÁ†îÁ©∂Ë®àÁï´ÁöÑÁ¨¨‰∏ÄÊ≠•ÔºåÁõÆÁöÑÊòØË®ìÁ∑¥ LLM Âú®Â∞çË©±‰∏≠ÈÅ©Áï∂Âú∞‰∏îÊúâÊÑèÁæ©Âú∞Ëß£ÈáãÂíåÁî¢ÁîüÈôÑÂ∏∂‰ø°Ëôü„ÄÇ</paragraph>

##### **Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters**
2408.03314v1 by Charlie Snell, Jaehoon Lee, Kelvin Xu, Aviral Kumar

Enabling LLMs to improve their outputs by using more test-time computation is
a critical step towards building generally self-improving agents that can
operate on open-ended natural language. In this paper, we study the scaling of
inference-time computation in LLMs, with a focus on answering the question: if
an LLM is allowed to use a fixed but non-trivial amount of inference-time
compute, how much can it improve its performance on a challenging prompt?
Answering this question has implications not only on the achievable performance
of LLMs, but also on the future of LLM pretraining and how one should tradeoff
inference-time and pre-training compute. Despite its importance, little
research attempted to understand the scaling behaviors of various test-time
inference methods. Moreover, current work largely provides negative results for
a number of these strategies. In this work, we analyze two primary mechanisms
to scale test-time computation: (1) searching against dense, process-based
verifier reward models; and (2) updating the model's distribution over a
response adaptively, given the prompt at test time. We find that in both cases,
the effectiveness of different approaches to scaling test-time compute
critically varies depending on the difficulty of the prompt. This observation
motivates applying a "compute-optimal" scaling strategy, which acts to most
effectively allocate test-time compute adaptively per prompt. Using this
compute-optimal strategy, we can improve the efficiency of test-time compute
scaling by more than 4x compared to a best-of-N baseline. Additionally, in a
FLOPs-matched evaluation, we find that on problems where a smaller base model
attains somewhat non-trivial success rates, test-time compute can be used to
outperform a 14x larger model.

ÊëòË¶ÅÔºöËÆì LLM ËÉΩÂ§†ÈÄèÈÅé‰ΩøÁî®Êõ¥Â§öÊ∏¨Ë©¶ÊôÇÈñìÈÅãÁÆó‰æÜÊîπÂñÑÂÖ∂Áî¢Âá∫ÔºåÊòØÂª∫Á´ã‰∏ÄËà¨Ëá™ÊîπÂñÑ‰ª£ÁêÜÁ®ãÂºèÁöÑÈáçË¶ÅÊ≠•È©üÔºåË©≤‰ª£ÁêÜÁ®ãÂºèÂèØ‰ª•Âú®ÈñãÊîæÂºèËá™ÁÑ∂Ë™ûË®Ä‰∏≠ÈÅã‰Ωú„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÁ†îÁ©∂‰∫Ü LLM ‰∏≠Êé®Ë´ñÊôÇÈñìÈÅãÁÆóÁöÑÊì¥ÂÖÖÔºåÈáçÈªûÂú®ÂõûÁ≠î‰∏ãÂàóÂïèÈ°åÔºöÂ¶ÇÊûúÂÖÅË®± LLM ‰ΩøÁî®Âõ∫ÂÆö‰ΩÜÈùûÁë£Á¢éÁöÑÊé®Ë´ñÊôÇÈñìÈÅãÁÆóÈáèÔºåÂÆÉÂèØ‰ª•Âú®ÂÖ∑ÊåëÊà∞ÊÄßÁöÑÊèêÁ§∫‰∏≠ÊîπÂñÑÂ§öÂ∞ëÊïàËÉΩÔºüÂõûÁ≠îÈÄôÂÄãÂïèÈ°å‰∏çÂÉÖÂ∞ç LLM ÂèØÈÅîÂà∞ÁöÑÊïàËÉΩÊúâÂΩ±ÈüøÔºå‰πüÂ∞ç LLM È†êË®ìÁ∑¥ÁöÑÊú™‰æÜ‰ª•ÂèäÂ¶Ç‰ΩïÊ¨äË°°Êé®Ë´ñÊôÇÈñìËàáÈ†êË®ìÁ∑¥ÈÅãÁÆóÁî¢ÁîüÂΩ±Èüø„ÄÇÂÑòÁÆ°ÂÖ∂ÈáçË¶ÅÊÄßÔºå‰ΩÜÂæàÂ∞ëÊúâÁ†îÁ©∂ÂòóË©¶‰∫ÜËß£ÂêÑÁ®ÆÊ∏¨Ë©¶ÊôÇÈñìÊé®Ë´ñÊñπÊ≥ïÁöÑÊì¥ÂÖÖË°åÁÇ∫„ÄÇÊ≠§Â§ñÔºåÁõÆÂâçÁöÑÂ∑•‰ΩúÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏äÁÇ∫Ë®±Â§öÈÄô‰∫õÁ≠ñÁï•Êèê‰æõ‰∫ÜË≤†Èù¢ÁµêÊûú„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÂàÜÊûê‰∫ÜÂÖ©Á®ÆÊì¥ÂÖÖÊ∏¨Ë©¶ÊôÇÈñìÈÅãÁÆóÁöÑ‰∏ªË¶ÅÊ©üÂà∂Ôºö(1) ÈáùÂ∞çÂØÜÈõÜÁöÑ„ÄÅÂü∫ÊñºÁ®ãÂ∫èÁöÑÈ©óË≠âÂô®ÁçéÂãµÊ®°ÂûãÈÄ≤Ë°åÊêúÂ∞ãÔºõ‰ª•Âèä (2) Ê†πÊìöÊ∏¨Ë©¶ÊôÇÈñìÁöÑÊèêÁ§∫ÔºåËá™ÈÅ©ÊáâÂú∞Êõ¥Êñ∞Ê®°ÂûãÂú®ÂõûÊáâ‰∏äÁöÑÂàÜ‰Ωà„ÄÇÊàëÂÄëÁôºÁèæÔºåÂú®ÈÄôÂÖ©Á®ÆÊÉÖÊ≥Å‰∏ãÔºåÊì¥ÂÖÖÊ∏¨Ë©¶ÊôÇÈñìÈÅãÁÆóÁöÑ‰∏çÂêåÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÔºåÊúÉÊ†πÊìöÊèêÁ§∫ÁöÑÈõ£Â∫¶ËÄåÊúâÈ°ØËëóÂ∑ÆÁï∞„ÄÇÈÄôÂÄãËßÄÂØüÁµêÊûú‰øÉ‰ΩøÊàëÂÄëÊé°Áî®„ÄåÈÅãÁÆóÊúÄ‰Ω≥Âåñ„ÄçÊì¥ÂÖÖÁ≠ñÁï•ÔºåË©≤Á≠ñÁï•ÁöÑ‰ΩúÁî®ÊòØÈáùÂ∞çÊØèÂÄãÊèêÁ§∫Ëá™ÈÅ©ÊáâÂú∞ÊúÄÊúâÊïàÂú∞ÈÖçÁΩÆÊ∏¨Ë©¶ÊôÇÈñìÈÅãÁÆó„ÄÇ‰ΩøÁî®ÈÄôÂÄãÈÅãÁÆóÊúÄ‰Ω≥ÂåñÁ≠ñÁï•ÔºåËàáÊúÄ‰Ω≥ N Âü∫Ê∫ñÁ∑öÁõ∏ÊØîÔºåÊàëÂÄëÂèØ‰ª•Â∞áÊ∏¨Ë©¶ÊôÇÈñìÈÅãÁÆóÊì¥ÂÖÖÁöÑÊïàÁéáÊèêÈ´ò 4 ÂÄç‰ª•‰∏ä„ÄÇÊ≠§Â§ñÔºåÂú® FLOPs ÂåπÈÖçÁöÑË©ï‰º∞‰∏≠ÔºåÊàëÂÄëÁôºÁèæÂ∞çÊñºËºÉÂ∞èÁöÑÂü∫Á§éÊ®°ÂûãÈÅîÂà∞Áõ∏Áï∂‰∏çÂπ≥Âá°ÁöÑÊàêÂäüÁéáÁöÑÂïèÈ°åÔºåÊ∏¨Ë©¶ÊôÇÈñìÈÅãÁÆóÂèØÁî®ÊñºÂÑ™ÊñºÂ§ß 14 ÂÄçÁöÑÊ®°Âûã„ÄÇ

##### **Prioritize Alignment in Dataset Distillation**
2408.03360v1 by Zekai Li, Ziyao Guo, Wangbo Zhao, Tianle Zhang, Zhi-Qi Cheng, Samir Khaki, Kaipeng Zhang, Ahmad Sajed, Konstantinos N Plataniotis, Kai Wang, Yang You

Dataset Distillation aims to compress a large dataset into a significantly
more compact, synthetic one without compromising the performance of the trained
models. To achieve this, existing methods use the agent model to extract
information from the target dataset and embed it into the distilled dataset.
Consequently, the quality of extracted and embedded information determines the
quality of the distilled dataset. In this work, we find that existing methods
introduce misaligned information in both information extraction and embedding
stages. To alleviate this, we propose Prioritize Alignment in Dataset
Distillation (PAD), which aligns information from the following two
perspectives. 1) We prune the target dataset according to the compressing ratio
to filter the information that can be extracted by the agent model. 2) We use
only deep layers of the agent model to perform the distillation to avoid
excessively introducing low-level information. This simple strategy effectively
filters out misaligned information and brings non-trivial improvement for
mainstream matching-based distillation algorithms. Furthermore, built on
trajectory matching, \textbf{PAD} achieves remarkable improvements on various
benchmarks, achieving state-of-the-art performance.

ÊëòË¶ÅÔºöÊï∞ÊçÆÈõÜËí∏È¶èÊó®Âú®Â∞ÜÂ§ßÂûãÊï∞ÊçÆÈõÜÂéãÁº©Êàê‰∏Ä‰∏™ÊòæËëóÊõ¥Á¥ßÂáë„ÄÅÂêàÊàêÁöÑÊï∞ÊçÆÈõÜÔºåËÄå‰∏ç‰ºöÊçüÂÆ≥ËÆ≠ÁªÉÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇ‰∏∫‰∫ÜÂÆûÁé∞Ëøô‰∏ÄÁõÆÊ†áÔºåÁé∞ÊúâÊñπÊ≥ï‰ΩøÁî®‰ª£ÁêÜÊ®°Âûã‰ªéÁõÆÊ†áÊï∞ÊçÆÈõÜ‰∏≠ÊèêÂèñ‰ø°ÊÅØÔºåÂπ∂Â∞ÜÂÖ∂ÂµåÂÖ•Âà∞Ëí∏È¶èÊï∞ÊçÆÈõÜ‰∏≠„ÄÇÂõ†Ê≠§ÔºåÊèêÂèñÂíåÂµåÂÖ•ÁöÑ‰ø°ÊÅØÁöÑË¥®ÈáèÂÜ≥ÂÆö‰∫ÜËí∏È¶èÊï∞ÊçÆÈõÜÁöÑË¥®Èáè„ÄÇÂú®ËøôÈ°πÂ∑•‰Ωú‰∏≠ÔºåÊàë‰ª¨ÂèëÁé∞Áé∞ÊúâÊñπÊ≥ïÂú®‰ø°ÊÅØÊèêÂèñÂíåÂµåÂÖ•Èò∂ÊÆµÈÉΩÂºïÂÖ•‰∫Ü‰∏ç‰∏ÄËá¥ÁöÑ‰ø°ÊÅØ„ÄÇ‰∏∫‰∫ÜÁºìËß£ËøôÁßçÊÉÖÂÜµÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜÊï∞ÊçÆÈõÜËí∏È¶è‰∏≠ÁöÑ‰ºòÂÖàÂØπÈΩêÔºàPADÔºâÔºåÂÆÉ‰ªé‰ª•‰∏ã‰∏§‰∏™ËßíÂ∫¶ÂØπÈΩê‰ø°ÊÅØ„ÄÇ1) Êàë‰ª¨Ê†πÊçÆÂéãÁº©ÁéáÂØπÁõÆÊ†áÊï∞ÊçÆÈõÜËøõË°åÂâ™ÊûùÔºå‰ª•ËøáÊª§Êéâ‰ª£ÁêÜÊ®°ÂûãÂèØ‰ª•ÊèêÂèñÁöÑ‰ø°ÊÅØ„ÄÇ2) Êàë‰ª¨‰ªÖ‰ΩøÁî®‰ª£ÁêÜÊ®°ÂûãÁöÑÊ∑±Â∫¶Â±ÇÊù•ÊâßË°åËí∏È¶èÔºå‰ª•ÈÅøÂÖçËøáÂ∫¶ÂºïÂÖ•‰ΩéÁ∫ß‰ø°ÊÅØ„ÄÇËøôÁßçÁÆÄÂçïÁöÑÁ≠ñÁï•ÊúâÊïàÂú∞ËøáÊª§Êéâ‰∫Ü‰∏ç‰∏ÄËá¥ÁöÑ‰ø°ÊÅØÔºåÂπ∂‰∏∫Âü∫‰∫éÂåπÈÖçÁöÑ‰∏ªÊµÅËí∏È¶èÁÆóÊ≥ïÂ∏¶Êù•‰∫ÜÈùûÂπ≥Âá°ÁöÑÊîπËøõ„ÄÇÊ≠§Â§ñÔºåÂü∫‰∫éËΩ®ËøπÂåπÈÖçÔºå\textbf{PAD} Âú®ÂêÑÁßçÂü∫ÂáÜ‰∏äÂèñÂæó‰∫ÜÊòæÁùÄÁöÑÊîπËøõÔºåÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇ

##### **KaPO: Knowledge-aware Preference Optimization for Controllable Knowledge Selection in Retrieval-Augmented Language Models**
2408.03297v1 by Ruizhe Zhang, Yongxin Xu, Yuzhen Xiao, Runchuan Zhu, Xinke Jiang, Xu Chu, Junfeng Zhao, Yasha Wang

By integrating external knowledge, Retrieval-Augmented Generation (RAG) has
become an effective strategy for mitigating the hallucination problems that
large language models (LLMs) encounter when dealing with knowledge-intensive
tasks. However, in the process of integrating external non-parametric
supporting evidence with internal parametric knowledge, inevitable knowledge
conflicts may arise, leading to confusion in the model's responses. To enhance
the knowledge selection of LLMs in various contexts, some research has focused
on refining their behavior patterns through instruction-tuning. Nonetheless,
due to the absence of explicit negative signals and comparative objectives,
models fine-tuned in this manner may still exhibit undesirable behaviors in the
intricate and realistic retrieval scenarios. To this end, we propose a
Knowledge-aware Preference Optimization, dubbed KaPO, aimed at achieving
controllable knowledge selection in real retrieval scenarios. Concretely, we
explore and simulate error types across diverse context combinations and learn
how to avoid these negative signals through preference optimization methods.
Simultaneously, by adjusting the balance between response length and the
proportion of preference data representing different behavior patterns, we
enhance the adherence capabilities and noise robustness of LLMs in a balanced
manner. Experimental results show that KaPO outperforms previous methods for
handling knowledge conflicts by over 37%, while also exhibiting robust
generalization across various out-of-distribution datasets.

ÊëòË¶ÅÔºöÈÄèÈÅéÊï¥ÂêàÂ§ñÈÉ®Áü•Ë≠òÔºåÊ™¢Á¥¢Â¢ûÂº∑ÁîüÊàêÔºàRAGÔºâÂ∑≤ÊàêÁÇ∫Ê∏õËºïÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂú®ËôïÁêÜÁü•Ë≠òÂØÜÈõÜÂûã‰ªªÂãôÊôÇÊâÄÈÅáÂà∞ÁöÑÂπªË¶∫ÂïèÈ°åÁöÑÊúâÊïàÁ≠ñÁï•„ÄÇÁÑ∂ËÄåÔºåÂú®Â∞áÂ§ñÈÉ®ÈùûÂèÉÊï∏ÊîØÊåÅË≠âÊìöËàáÂÖßÈÉ®ÂèÉÊï∏Áü•Ë≠òÊï¥ÂêàÁöÑÈÅéÁ®ã‰∏≠ÔºåÂèØËÉΩÊúÉÁî¢Áîü‰∏çÂèØÈÅøÂÖçÁöÑÁü•Ë≠òË°ùÁ™ÅÔºåÂ∞éËá¥Ê®°ÂûãÂõûÊáâÊ∑∑Ê∑Ü„ÄÇÁÇ∫‰∫ÜÂ¢ûÂº∑ LLM Âú®ÂêÑÁ®ÆÊÉÖÂ¢É‰∏≠ÁöÑÁü•Ë≠òÈÅ∏ÊìáÔºå‰∏Ä‰∫õÁ†îÁ©∂Â∑≤Â∞àÊ≥®ÊñºÈÄèÈÅéÊåá‰ª§ÂæÆË™ø‰æÜÊîπÂñÑÂÖ∂Ë°åÁÇ∫Ê®°Âºè„ÄÇÂÑòÁÆ°Â¶ÇÊ≠§ÔºåÁî±ÊñºÁº∫‰πèÊòéÁ¢∫ÁöÑË≤†Èù¢Ë®äËôüÂíåÊØîËºÉÁõÆÊ®ôÔºå‰ª•ÈÄôÁ®ÆÊñπÂºèÂæÆË™øÁöÑÊ®°ÂûãÂú®Ë§áÈõú‰∏îÁúüÂØ¶ÁöÑÊ™¢Á¥¢ÊÉÖÂ¢É‰∏≠‰ªçÂèØËÉΩË°®ÁèæÂá∫‰∏çËâØË°åÁÇ∫„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÁ®±ÁÇ∫ KaPO ÁöÑÁü•Ë≠òÊÑüÁü•ÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÔºåÊó®Âú®ÂØ¶ÁèæÂØ¶ÈöõÊ™¢Á¥¢ÊÉÖÂ¢É‰∏≠ÁöÑÂèØÊéßÁü•Ë≠òÈÅ∏Êìá„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÊé¢Á¥¢‰∏¶Ê®°Êì¨ÂêÑÁ®ÆÊÉÖÂ¢ÉÁµÑÂêà‰∏≠ÁöÑÈåØË™§È°ûÂûãÔºå‰∏¶Â≠∏ÁøíÂ¶Ç‰ΩïÈÄèÈÅéÂÅèÂ•ΩÊúÄ‰Ω≥ÂåñÊñπÊ≥ï‰æÜÈÅøÂÖçÈÄô‰∫õË≤†Èù¢Ë®äËôü„ÄÇÂêåÊôÇÔºåÈÄèÈÅéË™øÊï¥ÂõûÊáâÈï∑Â∫¶Âíå‰ª£Ë°®‰∏çÂêåË°åÁÇ∫Ê®°ÂºèÁöÑÂÅèÂ•ΩË≥áÊñôÊØî‰æã‰πãÈñìÁöÑÂπ≥Ë°°ÔºåÊàëÂÄë‰ª•Âπ≥Ë°°ÁöÑÊñπÂºèÂ¢ûÂº∑‰∫Ü LLM ÁöÑÈÅµÂÆàËÉΩÂäõÂíåÊäóÂô™ÊÄß„ÄÇÂØ¶È©óÁµêÊûúÈ°ØÁ§∫ÔºåKaPO Âú®ËôïÁêÜÁü•Ë≠òË°ùÁ™ÅÊñπÈù¢ÂÑ™ÊñºÂÖàÂâçÁöÑÂêÑÁ®ÆÊñπÊ≥ïÔºåÂÑ™Âã¢Ë∂ÖÈÅé 37%ÔºåÂêåÊôÇÂú®ÂêÑÁ®ÆÈùûÂàÜ‰ΩàË≥áÊñôÈõÜ‰∏ä‰πüË°®ÁèæÂá∫Âº∑Â§ßÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

##### **Static IR Drop Prediction with Attention U-Net and Saliency-Based Explainability**
2408.03292v1 by Lizi Zhang, Azadeh Davoodi

There has been significant recent progress to reduce the computational effort
of static IR drop analysis using neural networks, and modeling as an
image-to-image translation task. A crucial issue is the lack of sufficient data
from real industry designs to train these networks. Additionally, there is no
methodology to explain a high-drop pixel in a predicted IR drop image to its
specific root-causes. In this work, we first propose a U-Net neural network
model with attention gates which is specifically tailored to achieve fast and
accurate image-based static IR drop prediction. Attention gates allow selective
emphasis on relevant parts of the input data without supervision which is
desired because of the often sparse nature of the IR drop map. We propose a
two-phase training process which utilizes a mix of artificially-generated data
and a limited number of points from real designs. The results are, on-average,
18% (53%) better in MAE and 14% (113%) in F1 score compared to the winner of
the ICCAD 2023 contest (and U-Net only) when tested on real designs. Second, we
propose a fast method using saliency maps which can explain a predicted IR drop
in terms of specific input pixels contributing the most to a drop. In our
experiments, we show the number of high IR drop pixels can be reduced
on-average by 18% by mimicking upsize of a tiny portion of PDN's resistive
edges.

ÊëòË¶ÅÔºö<paragraph>Âà©Áî®Á•ûÁ∂ìÁ∂≤Ë∑ØÂíåÂ∞áÂÖ∂Âª∫Ê®°ÁÇ∫ÂΩ±ÂÉèËΩâÊèõ‰ªªÂãôÔºåÊúÄËøëÂú®Èôç‰ΩéÈùúÊÖã IR ÈôçÂ£ìÂàÜÊûêÁöÑË®àÁÆóÂ∑•‰Ωú‰∏äÂèñÂæóÈ°ØËëóÈÄ≤Â±ï„ÄÇ‰∏ÄÂÄãÈóúÈçµÂïèÈ°åÊòØÁº∫‰πè‰æÜËá™ÁúüÂØ¶Áî¢Ê•≠Ë®≠Ë®àÁöÑË∂≥Â§†Ë≥áÊñô‰æÜË®ìÁ∑¥ÈÄô‰∫õÁ∂≤Ë∑Ø„ÄÇÊ≠§Â§ñÔºåÊ≤íÊúâÊñπÊ≥ïÂèØ‰ª•Ëß£ÈáãÈ†êÊ∏¨ IR ÈôçÂ£ìÂΩ±ÂÉè‰∏≠ÁöÑÈ´òÈôçÂ£ìÂÉèÁ¥†ÂèäÂÖ∂ÂÖ∑È´îÊ†πÊú¨ÂéüÂõ†„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖàÊèêÂá∫‰∏ÄÂÄãÂÖ∑ÊúâÊ≥®ÊÑèÂäõÈñòÁöÑ U-Net Á•ûÁ∂ìÁ∂≤Ë∑ØÊ®°ÂûãÔºåÂÆÉÂ∞àÈñÄË®≠Ë®àÁî®ÊñºÂØ¶ÁèæÂø´ÈÄü‰∏îÊ∫ñÁ¢∫ÁöÑÂü∫ÊñºÂΩ±ÂÉèÁöÑÈùúÊÖã IR ÈôçÂ£ìÈ†êÊ∏¨„ÄÇÊ≥®ÊÑèÂäõÈñòÂÖÅË®±ÈÅ∏ÊìáÊÄßÂú∞Âº∑Ë™øËº∏ÂÖ•Ë≥áÊñô‰∏≠Áõ∏ÈóúÈÉ®ÂàÜÔºåËÄåÁÑ°ÈúÄÁõ£Áù£ÔºåÈÄôÊòØÂõ†ÁÇ∫ IR ÈôçÂ£ìÂúñÈÄöÂ∏∏ÂÖ∑ÊúâÁ®ÄÁñèÁâπÊÄßÁöÑÁ∑£ÊïÖ„ÄÇÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂÖ©ÈöéÊÆµË®ìÁ∑¥ÈÅéÁ®ãÔºåÂÆÉÂà©Áî®‰∫∫Â∑•ÁîüÊàêË≥áÊñôÂíå‰æÜËá™ÁúüÂØ¶Ë®≠Ë®àÁöÑÊúâÈôêÊï∏ÈáèÁöÑÈªû„ÄÇËàá ICCAD 2023 Á´∂Ë≥ΩÁöÑÁç≤ÂãùËÄÖÔºàÂÉÖ U-NetÔºâÁõ∏ÊØîÔºåÂú®ÁúüÂØ¶Ë®≠Ë®à‰∏äÊ∏¨Ë©¶ÊôÇÔºåÁµêÊûúÂú® MAE ‰∏äÂπ≥ÂùáÊèêÈ´ò 18%Ôºà53%ÔºâÔºåÂú® F1 ÂàÜÊï∏‰∏äÊèêÈ´ò 14%Ôºà113%Ôºâ„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®Æ‰ΩøÁî®È°ØËëóÊÄßÂúñÁöÑÂø´ÈÄüÊñπÊ≥ïÔºåÂÆÉÂèØ‰ª•Áî®Ë≤¢ÁçªÈôçÂ£ìÊúÄÂ§öÁöÑÁâπÂÆöËº∏ÂÖ•ÂÉèÁ¥†‰æÜËß£ÈáãÈ†êÊ∏¨ÁöÑ IR ÈôçÂ£ì„ÄÇÂú®ÊàëÂÄëÁöÑÂØ¶È©ó‰∏≠ÔºåÊàëÂÄëË°®ÊòéÔºåÈÄöÈÅéÊ®°Êì¨Á∏ÆÂ∞è PDN ÈõªÈòªÈÇäÁ∑£ÁöÑ‰∏ÄÂ∞èÈÉ®ÂàÜÔºåÂèØ‰ª•Â∞áÈ´ò IR ÈôçÂ£ìÂÉèÁ¥†ÁöÑÊï∏ÈáèÂπ≥ÂùáÊ∏õÂ∞ë 18%„ÄÇ</paragraph>

##### **SARA: Singular-Value Based Adaptive Low-Rank Adaption**
2408.03290v1 by Jihao Gu, Shuai Chen, Zelin Wang, Yibo Zhang, Ping Gong

With the increasing number of parameters in large pre-trained models, LoRA as
a parameter-efficient fine-tuning(PEFT) method is widely used for not adding
inference overhead. The LoRA method assumes that weight changes during
fine-tuning can be approximated by low-rank matrices. However, the rank values
need to be manually verified to match different downstream tasks, and they
cannot accommodate the varying importance of different layers in the model. In
this work, we first analyze the relationship between the performance of
different layers and their ranks using SVD. Based on this, we design the
Singular-Value Based Adaptive Low-Rank Adaption(SARA), which adaptively finds
the rank during initialization by performing SVD on the pre-trained weights.
Additionally, we explore the Mixture-of-SARA(Mo-SARA), which significantly
reduces the number of parameters by fine-tuning only multiple parallel sets of
singular values controlled by a router. Extensive experiments on various
complex tasks demonstrate the simplicity and parameter efficiency of our
methods. They can effectively and adaptively find the most suitable rank for
each layer of each model.

ÊëòË¶ÅÔºöÈö®ËëóÂ§ßÂûãÈ†êË®ìÁ∑¥Ê®°Âûã‰∏≠ÂèÉÊï∏Êï∏ÈáèÁöÑÂ¢ûÂä†ÔºåLoRA ‰ΩúÁÇ∫‰∏ÄÁ®ÆÂèÉÊï∏È´òÊïàÁöÑÂæÆË™ø (PEFT) ÊñπÊ≥ïË¢´Âª£Ê≥õÁî®Êñº‰∏çÂ¢ûÂä†Êé®ÁêÜÈñãÈä∑„ÄÇLoRA ÊñπÊ≥ïÂÅáË®≠ÂæÆË™øÊúüÈñìÁöÑÊ¨äÈáçËÆäÂåñÂèØ‰ª•Áî®‰ΩéÁß©Áü©Èô£Ëøë‰ºº„ÄÇÁÑ∂ËÄåÔºåÁß©ÂÄºÈúÄË¶ÅÊâãÂãïÈ©óË≠â‰ª•ÂåπÈÖç‰∏çÂêåÁöÑ‰∏ãÊ∏∏‰ªªÂãôÔºå‰∏¶‰∏îÂÆÉÂÄëÁÑ°Ê≥ïÈÅ©ÊáâÊ®°Âûã‰∏≠‰∏çÂêåÂ±§ÁöÑ‰∏çÂêåÈáçË¶ÅÊÄß„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÈ¶ñÂÖà‰ΩøÁî® SVD ÂàÜÊûê‰∏çÂêåÂ±§ÁöÑÊÄßËÉΩËàáÂÖ∂Áß©‰πãÈñìÁöÑÈóú‰øÇ„ÄÇÂü∫ÊñºÊ≠§ÔºåÊàëÂÄëË®≠Ë®à‰∫ÜÂü∫ÊñºÂ•áÁï∞ÂÄºÁöÑËá™ÈÅ©Êáâ‰ΩéÁß©ÈÅ©Êáâ (SARA)ÔºåÂÆÉÈÄöÈÅéÂ∞çÈ†êË®ìÁ∑¥Ê¨äÈáçÂü∑Ë°å SVD ‰æÜËá™ÈÅ©ÊáâÂú∞ÊâæÂà∞ÂàùÂßãÂåñÊúüÈñìÁöÑÁß©„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Á¥¢‰∫ÜÊ∑∑Âêà SARA (Mo-SARA)ÔºåÂÆÉÈÄöÈÅéÂÉÖÂæÆË™øÁî±Ë∑ØÁî±Âô®ÊéßÂà∂ÁöÑÂ•áÁï∞ÂÄºÁöÑÂ§öÂÄã‰∏¶Ë°åÈõÜ‰æÜÈ°ØËëóÊ∏õÂ∞ëÂèÉÊï∏Êï∏Èáè„ÄÇÂú®ÂêÑÁ®ÆË§áÈõú‰ªªÂãô‰∏äÁöÑÂ§ßÈáèÂØ¶È©óË≠âÊòé‰∫ÜÊàëÂÄëÊñπÊ≥ïÁöÑÁ∞°ÊΩîÊÄßÂíåÂèÉÊï∏ÊïàÁéá„ÄÇÂÆÉÂÄëÂèØ‰ª•ÊúâÊïà‰∏îËá™ÈÅ©ÊáâÂú∞ÊâæÂà∞ÊØèÂÄãÊ®°ÂûãÊØè‰∏ÄÂ±§ÊúÄÂêàÈÅ©ÁöÑÁß©„ÄÇ

##### **StructEval: Deepen and Broaden Large Language Model Assessment via Structured Evaluation**
2408.03281v2 by Boxi Cao, Mengjie Ren, Hongyu Lin, Xianpei Han, Feng Zhang, Junfeng Zhan, Le Sun

Evaluation is the baton for the development of large language models. Current
evaluations typically employ a single-item assessment paradigm for each atomic
test objective, which struggles to discern whether a model genuinely possesses
the required capabilities or merely memorizes/guesses the answers to specific
questions. To this end, we propose a novel evaluation framework referred to as
StructEval. Starting from an atomic test objective, StructEval deepens and
broadens the evaluation by conducting a structured assessment across multiple
cognitive levels and critical concepts, and therefore offers a comprehensive,
robust and consistent evaluation for LLMs. Experiments on three widely-used
benchmarks demonstrate that StructEval serves as a reliable tool for resisting
the risk of data contamination and reducing the interference of potential
biases, thereby providing more reliable and consistent conclusions regarding
model capabilities. Our framework also sheds light on the design of future
principled and trustworthy LLM evaluation protocols.

ÊëòË¶ÅÔºöË©ï‰º∞ÊòØÂ§ßË™ûË®ÄÊ®°ÂûãÁôºÂ±ïÁöÑÊåáÊ®ô„ÄÇÁõÆÂâçÁöÑË©ï‰º∞ÈÄöÂ∏∏Â∞çÊØèÂÄãÂéüÂ≠êÊ∏¨Ë©¶ÁõÆÊ®ôÊé°Áî®ÂñÆ‰∏ÄÈ†ÖÁõÆË©ï‰º∞ÁØÑ‰æãÔºåÈÄôÂæàÈõ£Ëæ®Âà•Ê®°ÂûãÊòØÂê¶ÁúüÊ≠£ÂÖ∑ÂÇôÊâÄÈúÄÁöÑÊäÄËÉΩÔºåÊàñÂÉÖÂÉÖÊòØË®òÊÜ∂/ÁåúÊ∏¨ÁâπÂÆöÂïèÈ°åÁöÑÁ≠îÊ°à„ÄÇÁÇ∫Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÁ®±ÁÇ∫ StructEval ÁöÑÊñ∞Ë©ï‰º∞Êû∂Êßã„ÄÇÂæû‰∏ÄÂÄãÂéüÂ≠êÊ∏¨Ë©¶ÁõÆÊ®ôÈñãÂßãÔºåStructEval ÈÄèÈÅéÂú®Â§öÂÄãË™çÁü•Â±§Èù¢ÂíåÈóúÈçµÊ¶ÇÂøµ‰∏≠ÈÄ≤Ë°åÁµêÊßãÂåñË©ï‰º∞‰æÜÂä†Ê∑±ÂíåÊì¥Â±ïË©ï‰º∞ÔºåÂõ†Ê≠§ÁÇ∫ LLM Êèê‰æõÂÖ®Èù¢„ÄÅÁ©©ÂÅ•‰∏î‰∏ÄËá¥ÁöÑË©ï‰º∞„ÄÇÂú®‰∏âÂÄãÂª£Ê≥õ‰ΩøÁî®ÁöÑÂü∫Ê∫ñÊ∏¨Ë©¶‰∏äÁöÑÂØ¶È©óË°®ÊòéÔºåStructEval ÂèØ‰ΩúÁÇ∫ÊäµÊäóË≥áÊñôÊ±°ÊüìÈ¢®Èö™ÂíåÊ∏õÂ∞ëÊΩõÂú®ÂÅèÂ∑ÆÂπ≤ÊìæÁöÑÂèØÈù†Â∑•ÂÖ∑ÔºåÂæûËÄåÂ∞çÊ®°ÂûãËÉΩÂäõÊèê‰æõÊõ¥ÂèØÈù†‰∏î‰∏ÄËá¥ÁöÑÁµêË´ñ„ÄÇÊàëÂÄëÁöÑÊû∂Êßã‰πüÁÇ∫Êú™‰æÜÂü∫ÊñºÂéüÂâá‰∏îÂÄºÂæó‰ø°Ë≥¥ÁöÑ LLM Ë©ï‰º∞ÂçîÂÆöÁöÑË®≠Ë®àÊèê‰æõ‰∫ÜÂïüÁ§∫„ÄÇ

##### **Compress and Compare: Interactively Evaluating Efficiency and Behavior Across ML Model Compression Experiments**
2408.03274v1 by Angie Boggust, Venkatesh Sivaraman, Yannick Assogba, Donghao Ren, Dominik Moritz, Fred Hohman

To deploy machine learning models on-device, practitioners use compression
algorithms to shrink and speed up models while maintaining their high-quality
output. A critical aspect of compression in practice is model comparison,
including tracking many compression experiments, identifying subtle changes in
model behavior, and negotiating complex accuracy-efficiency trade-offs.
However, existing compression tools poorly support comparison, leading to
tedious and, sometimes, incomplete analyses spread across disjoint tools. To
support real-world comparative workflows, we develop an interactive visual
system called Compress and Compare. Within a single interface, Compress and
Compare surfaces promising compression strategies by visualizing provenance
relationships between compressed models and reveals compression-induced
behavior changes by comparing models' predictions, weights, and activations. We
demonstrate how Compress and Compare supports common compression analysis tasks
through two case studies, debugging failed compression on generative language
models and identifying compression artifacts in image classification models. We
further evaluate Compress and Compare in a user study with eight compression
experts, illustrating its potential to provide structure to compression
workflows, help practitioners build intuition about compression, and encourage
thorough analysis of compression's effect on model behavior. Through these
evaluations, we identify compression-specific challenges that future visual
analytics tools should consider and Compress and Compare visualizations that
may generalize to broader model comparison tasks.

ÊëòË¶ÅÔºöÁÇ∫‰∫ÜÂú®Ë£ùÁΩÆ‰∏äÈÉ®ÁΩ≤Ê©üÂô®Â≠∏ÁøíÊ®°ÂûãÔºåÂØ¶ÂãôÂ∑•‰ΩúËÄÖÊúÉ‰ΩøÁî®Â£ìÁ∏ÆÊºîÁÆóÊ≥ï‰æÜÁ∏ÆÂ∞èÊ®°ÂûãÁöÑË¶èÊ®°‰∏¶Âä†Âø´Ê®°ÂûãÁöÑÈÄüÂ∫¶ÔºåÂêåÊôÇÁ∂≠ÊåÅÂÖ∂È´òÂìÅË≥™ÁöÑËº∏Âá∫„ÄÇÂú®ÂØ¶ÈöõÊáâÁî®‰∏≠ÔºåÂ£ìÁ∏ÆÁöÑ‰∏ÄÂÄãÈáçË¶ÅÈù¢ÂêëÊòØÊ®°ÂûãÊØîËºÉÔºåÂåÖÊã¨ËøΩËπ§Ë®±Â§öÂ£ìÁ∏ÆÂØ¶È©ó„ÄÅÊâæÂá∫Ê®°ÂûãË°åÁÇ∫‰∏≠ÁöÑÁ¥∞ÂæÆËÆäÂåñÔºå‰ª•ÂèäÂçîÂïÜË§áÈõúÁöÑÊ∫ñÁ¢∫Â∫¶ËàáÊïàÁéáÊäòË°∑„ÄÇÁÑ∂ËÄåÔºåÁèæÊúâÁöÑÂ£ìÁ∏ÆÂ∑•ÂÖ∑Â∞çÊñºÊØîËºÉÁöÑÊîØÊåÅÂæàÂ∑ÆÔºåÂ∞éËá¥ÁπÅÁë£‰∏îÊúâÊôÇ‰∏çÂÆåÊï¥ÁöÑÂàÜÊûêÊï£Â∏ÉÂú®‰∏çÂêåÁöÑÂ∑•ÂÖ∑‰∏≠„ÄÇÁÇ∫‰∫ÜÊîØÊè¥ÁúüÂØ¶‰∏ñÁïåÁöÑÊØîËºÉÂ∑•‰ΩúÊµÅÁ®ãÔºåÊàëÂÄëÈñãÁôº‰∫Ü‰∏ÄÂÄã‰∫íÂãïÂºèË¶ñË¶∫Á≥ªÁµ±ÔºåÁ®±ÁÇ∫„ÄåÂ£ìÁ∏ÆËàáÊØîËºÉ„Äç„ÄÇÂú®ÂñÆ‰∏Ä‰ªãÈù¢‰∏≠Ôºå„ÄåÂ£ìÁ∏ÆËàáÊØîËºÉ„ÄçÊúÉÈÄèÈÅéË¶ñË¶∫ÂåñÂ£ìÁ∏ÆÊ®°Âûã‰πãÈñìÁöÑ‰æÜÊ∫êÈóú‰øÇÔºåÊâæÂá∫ÊúâÂâçÊôØÁöÑÂ£ìÁ∏ÆÁ≠ñÁï•Ôºå‰∏¶ÈÄèÈÅéÊØîËºÉÊ®°ÂûãÁöÑÈ†êÊ∏¨„ÄÅÊ¨äÈáçÂíåÊøÄÂãµÔºåÊè≠Èú≤Â£ìÁ∏ÆÂºïÁôºÁöÑË°åÁÇ∫ËÆäÂåñ„ÄÇÊàëÂÄëÈÄèÈÅéÂÖ©ÂÄãÊ°à‰æãÁ†îÁ©∂Â±ïÁ§∫„ÄåÂ£ìÁ∏ÆËàáÊØîËºÉ„ÄçÂ¶Ç‰ΩïÊîØÊè¥Â∏∏Ë¶ãÁöÑÂ£ìÁ∏ÆÂàÜÊûê‰ªªÂãôÔºåÂåÖÊã¨ÂÅµÈåØÁîüÊàêË™ûË®ÄÊ®°Âûã‰∏≠Â§±ÊïóÁöÑÂ£ìÁ∏ÆÔºå‰ª•ÂèäÊâæÂá∫ÂΩ±ÂÉèÂàÜÈ°ûÊ®°Âûã‰∏≠ÁöÑÂ£ìÁ∏Æ‰∫∫Â∑•Ë£ΩÂìÅ„ÄÇÊàëÂÄëÈÄ≤‰∏ÄÊ≠•Âú®‰∏ÄÂÄã‰ΩøÁî®ËÄÖÁ†îÁ©∂‰∏≠Ë©ï‰º∞„ÄåÂ£ìÁ∏ÆËàáÊØîËºÉ„ÄçÔºåË©≤Á†îÁ©∂ÊúâÂÖ´‰ΩçÂ£ìÁ∏ÆÂ∞àÂÆ∂ÂèÉËàáÔºåË™™ÊòéÂÖ∂Êèê‰æõÁµêÊßãÁµ¶Â£ìÁ∏ÆÂ∑•‰ΩúÊµÅÁ®ã„ÄÅÂçîÂä©ÂØ¶ÂãôÂ∑•‰ΩúËÄÖÂª∫Á´ãÈóúÊñºÂ£ìÁ∏ÆÁöÑÁõ¥Ë¶∫Ôºå‰ª•ÂèäÈºìÂãµÂæπÂ∫ïÂàÜÊûêÂ£ìÁ∏ÆÂ∞çÊ®°ÂûãË°åÁÇ∫ÁöÑÂΩ±ÈüøÁöÑÊΩõÂäõ„ÄÇÈÄèÈÅéÈÄô‰∫õË©ï‰º∞ÔºåÊàëÂÄëÊâæÂá∫Êú™‰æÜÁöÑË¶ñË¶∫ÂàÜÊûêÂ∑•ÂÖ∑ÊáâËÄÉÈáèÁöÑÁâπÂÆöÊñºÂ£ìÁ∏ÆÁöÑÊåëÊà∞Ôºå‰ª•ÂèäÂèØËÉΩÊúÉÊé®Âª£Âà∞Êõ¥Âª£Ê≥õÁöÑÊ®°ÂûãÊØîËºÉ‰ªªÂãôÁöÑ„ÄåÂ£ìÁ∏ÆËàáÊØîËºÉ„ÄçË¶ñË¶∫Âåñ„ÄÇ

##### **LAMPO: Large Language Models as Preference Machines for Few-shot Ordinal Classification**
2408.03359v1 by Zhen Qin, Junru Wu, Jiaming Shen, Tianqi Liu, Xuanhui Wang

We introduce LAMPO, a novel paradigm that leverages Large Language Models
(LLMs) for solving few-shot multi-class ordinal classification tasks. Unlike
conventional methods, which concatenate all demonstration examples with the
test instance and prompt LLMs to produce the pointwise prediction, our
framework uses the LLM as a preference machine that makes a relative
comparative decision between the test instance and each demonstration. A
self-supervised method is then introduced to aggregate these binary comparisons
into the final ordinal decision. LAMPO addresses several limitations inherent
in previous methods, including context length constraints, ordering biases, and
challenges associated with absolute point-wise estimation. Extensive
experiments on seven public datasets demonstrate LAMPO's remarkably competitive
performance across a diverse spectrum of applications (e.g., movie review
analysis and hate speech detection). Notably, in certain applications, the
improvement can be substantial, exceeding 20% in an absolute term. Moreover, we
believe LAMPO represents an interesting addition to the non-parametric
application layered on top of LLMs, as it supports black-box LLMs without
necessitating the outputting of LLM's internal states (e.g., embeddings), as
seen in previous approaches.

ÊëòË¶ÅÔºöÊàëÂÄë‰ªãÁ¥π LAMPOÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÁØÑ‰æãÔºåÂÆÉÂà©Áî®Â§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰æÜËß£Ê±∫Â∞ëÊ¨°Êï∏Â§öÈ°ûÂà•Â∫èÊï∏ÂàÜÈ°û‰ªªÂãô„ÄÇËàáÂÇ≥Áµ±ÊñπÊ≥ï‰∏çÂêåÔºåÂÇ≥Áµ±ÊñπÊ≥ïÊúÉÂ∞áÊâÄÊúâÁ§∫ÁØÑÁØÑ‰æãËàáÊ∏¨Ë©¶ÂØ¶‰æã‰∏≤ËÅØÔºå‰∏¶ÊèêÁ§∫ LLM Áî¢ÁîüÈÄêÈªûÈ†êÊ∏¨ÔºåÊàëÂÄëÁöÑÊû∂Êßã‰ΩøÁî® LLM ‰ΩúÁÇ∫ÂÅèÂ•ΩÊ©üÂô®ÔºåÂú®Ê∏¨Ë©¶ÂØ¶‰æãÂíåÊØèÂÄãÁ§∫ÁØÑ‰πãÈñìÂÅöÂá∫Áõ∏Â∞çÊØîËºÉÊ±∫Á≠ñ„ÄÇÁÑ∂ÂæåÂºïÂÖ•‰∏ÄÁ®ÆËá™ÊàëÁõ£Áù£ÊñπÊ≥ïÔºåÂ∞áÈÄô‰∫õ‰∫åÂÖÉÊØîËºÉÂΩôÁ∏ΩÊàêÊúÄÁµÇÁöÑÂ∫èÊï∏Ê±∫Á≠ñ„ÄÇLAMPO Ëß£Ê±∫‰∫ÜÂÖàÂâçÊñπÊ≥ï‰∏≠Âõ∫ÊúâÁöÑÂπæÂÄãÈôêÂà∂ÔºåÂåÖÊã¨‰∏ä‰∏ãÊñáÈï∑Â∫¶ÈôêÂà∂„ÄÅÊéíÂ∫èÂÅèÂ∑Æ‰ª•ÂèäËàáÁµïÂ∞çÈÄêÈªû‰º∞Ë®àÁõ∏ÈóúÁöÑÊåëÊà∞„ÄÇÂú®‰∏ÉÂÄãÂÖ¨ÂÖ±Ë≥áÊñôÈõÜ‰∏äÁöÑÂ§ßÈáèÂØ¶È©óË≠âÊòé‰∫Ü LAMPO Âú®ÂêÑÁ®ÆÊáâÁî®Ôºà‰æãÂ¶ÇÔºåÈõªÂΩ±Ë©ïË´ñÂàÜÊûêÂíå‰ªáÊÅ®Ë®ÄË´ñÂÅµÊ∏¨Ôºâ‰∏≠ÂÖ∑ÊúâÈ°ØËëóÁöÑÁ´∂Áà≠Âäõ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÂú®Êüê‰∫õÊáâÁî®‰∏≠ÔºåÈÄ≤Ê≠•ÂèØËÉΩÊòØÂØ¶Ë≥™ÊÄßÁöÑÔºå‰ª•ÁµïÂ∞çÂÄºË∂ÖÈÅé 20%„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁõ∏‰ø° LAMPO ÊòØÂª∫Á´ãÂú® LLM ‰πã‰∏äÁöÑÈùûÂèÉÊï∏ÊáâÁî®ÁöÑ‰∏ÄÂÄãÊúâË∂£ÁöÑË£úÂÖÖÔºåÂõ†ÁÇ∫ÂÆÉÊîØÊè¥ÈªëÁõí LLMÔºåËÄå‰∏çÈúÄË¶ÅËº∏Âá∫ LLM ÁöÑÂÖßÈÉ®ÁãÄÊÖãÔºà‰æãÂ¶ÇÔºåÂµåÂÖ•ÔºâÔºåÂ¶ÇÂÖàÂâçÊñπÊ≥ï‰∏≠ÊâÄË¶ã„ÄÇ

##### **Synthesizing Text-to-SQL Data from Weak and Strong LLMs**
2408.03256v1 by Jiaxi Yang, Binyuan Hui, Min Yang, Jian Yang, Junyang Lin, Chang Zhou

The capability gap between open-source and closed-source large language
models (LLMs) remains a challenge in text-to-SQL tasks. In this paper, we
introduce a synthetic data approach that combines data produced by larger, more
powerful models (strong models) with error information data generated by
smaller, not well-aligned models (weak models). The method not only enhances
the domain generalization of text-to-SQL models but also explores the potential
of error data supervision through preference learning. Furthermore, we employ
the synthetic data approach for instruction tuning on open-source LLMs,
resulting SENSE, a specialized text-to-SQL model. The effectiveness of SENSE is
demonstrated through state-of-the-art results on the SPIDER and BIRD
benchmarks, bridging the performance gap between open-source models and methods
prompted by closed-source models.

ÊëòË¶ÅÔºöÈñãÊîæÂéüÂßãÁ¢ºËàáÈñâÊ∫êÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰πãÈñìÁöÑËÉΩÂäõÂ∑ÆË∑ùÔºå‰ªçÁÑ∂ÊòØÊñáÂ≠óËΩâ SQL ‰ªªÂãô‰∏≠ÁöÑ‰∏ÄÈ†ÖÊåëÊà∞„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÁ®ÆÂêàÊàêË≥áÊñôÊñπÊ≥ïÔºåÂÆÉÁµêÂêà‰∫ÜÁî±Êõ¥Â§ß„ÄÅÊõ¥Âº∑Â§ßÁöÑÊ®°Âûã (Âº∑Ê®°Âûã) ÊâÄÁî¢ÁîüÁöÑË≥áÊñôÔºå‰ª•ÂèäÁî±ËºÉÂ∞è„ÄÅÂ∞çÈΩä‰∏ç‰Ω≥ÁöÑÊ®°Âûã (Âº±Ê®°Âûã) ÊâÄÁî¢ÁîüÁöÑÈåØË™§Ë≥áË®äË≥áÊñô„ÄÇÊ≠§ÊñπÊ≥ï‰∏çÂÉÖÂ¢ûÂº∑‰∫ÜÊñáÂ≠óËΩâ SQL Ê®°ÂûãÁöÑÈ†òÂüüÊ¶ÇÊã¨ÊÄßÔºåÈÇÑÈÄèÈÅéÂÅèÂ•ΩÂ≠∏ÁøíÊé¢Á¥¢‰∫ÜÈåØË™§Ë≥áÊñôÁõ£Áù£ÁöÑÊΩõÂäõ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÂ∞áÂêàÊàêË≥áÊñôÊñπÊ≥ïÁî®ÊñºÈñãÊîæÂéüÂßãÁ¢º LLM ‰∏äÁöÑÊåá‰ª§Ë™øÊï¥ÔºåÁî¢Áîü‰∫Ü SENSEÔºå‰∏ÄÁ®ÆÂ∞àÈñÄÁöÑÊñáÂ≠óËΩâ SQL Ê®°Âûã„ÄÇSENSE ÁöÑÊúâÊïàÊÄßÈÄèÈÅé SPIDER Âíå BIRD Âü∫Ê∫ñÊ∏¨Ë©¶ÁöÑÊúÄÊñ∞ÁµêÊûúÂæóÂà∞Ë≠âÊòéÔºåÁ∏ÆÂ∞è‰∫ÜÈñãÊîæÂéüÂßãÁ¢ºÊ®°ÂûãËàáÈñâÊ∫êÊ®°ÂûãÊèêÁ§∫ÊñπÊ≥ï‰πãÈñìÁöÑÊïàËÉΩÂ∑ÆË∑ù„ÄÇ

##### **Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons**
2408.03247v1 by Yifei Wang, Yuheng Chen, Wanting Wen, Yu Sheng, Linjing Li, Daniel Dajun Zeng

In this paper, we investigate whether Large Language Models (LLMs) actively
recall or retrieve their internal repositories of factual knowledge when faced
with reasoning tasks. Through an analysis of LLMs' internal factual recall at
each reasoning step via Knowledge Neurons, we reveal that LLMs fail to harness
the critical factual associations under certain circumstances. Instead, they
tend to opt for alternative, shortcut-like pathways to answer reasoning
questions. By manually manipulating the recall process of parametric knowledge
in LLMs, we demonstrate that enhancing this recall process directly improves
reasoning performance whereas suppressing it leads to notable degradation.
Furthermore, we assess the effect of Chain-of-Thought (CoT) prompting, a
powerful technique for addressing complex reasoning tasks. Our findings
indicate that CoT can intensify the recall of factual knowledge by encouraging
LLMs to engage in orderly and reliable reasoning. Furthermore, we explored how
contextual conflicts affect the retrieval of facts during the reasoning process
to gain a comprehensive understanding of the factual recall behaviors of LLMs.
Code and data will be available soon.

ÊëòË¶ÅÔºö<paragraph>Âú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé¢Ë®éÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Èù¢Â∞çÊé®ÁêÜ‰ªªÂãôÊôÇÔºåÊòØÂê¶ÊúÉ‰∏ªÂãïÂõûÊÜ∂ÊàñÊ™¢Á¥¢ÂÖ∂ÂÖßÈÉ®‰∫ãÂØ¶Áü•Ë≠òÂ∫´„ÄÇÈÄèÈÅéÁü•Ë≠òÁ•ûÁ∂ìÂÖÉÂàÜÊûê LLM Âú®ÊØèÂÄãÊé®ÁêÜÊ≠•È©ü‰∏≠ÁöÑÂÖßÈÉ®‰∫ãÂØ¶ÂõûÊÜ∂ÔºåÊàëÂÄëÁôºÁèæ LLM Âú®Êüê‰∫õÊÉÖÊ≥Å‰∏ãÁÑ°Ê≥ïÂà©Áî®ÈóúÈçµÁöÑ‰∫ãÂØ¶ÈóúËÅØ„ÄÇÁõ∏ÂèçÂú∞Ôºå‰ªñÂÄëÂÇæÂêëÊñºÈÅ∏ÊìáÊõø‰ª£ÁöÑÊç∑ÂæëÈÄîÂæë‰æÜÂõûÁ≠îÊé®ÁêÜÂïèÈ°å„ÄÇÈÄèÈÅéÊâãÂãïÊìç‰Ωú LLM ‰∏≠ÂèÉÊï∏ÂåñÁü•Ë≠òÁöÑÂõûÊÜ∂ÈÅéÁ®ãÔºåÊàëÂÄëË≠âÊòé‰∫ÜÂ¢ûÂº∑Ê≠§ÂõûÊÜ∂ÈÅéÁ®ãÊúÉÁõ¥Êé•ÊîπÂñÑÊé®ÁêÜË°®ÁèæÔºåËÄåÊäëÂà∂ÂÆÉÂâáÊúÉÂ∞éËá¥È°ØËëóÁöÑÈÄÄÂåñ„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëË©ï‰º∞‰∫ÜÊÄùÊÉ≥Èèà (CoT) ÊèêÁ§∫ÁöÑÂΩ±ÈüøÔºåÈÄôÊòØ‰∏ÄÁ®ÆËß£Ê±∫Ë§áÈõúÊé®ÁêÜ‰ªªÂãôÁöÑÂº∑Â§ßÊäÄË°ì„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåCoT ÂèØ‰ª•ÈÄèÈÅéÈºìÂãµ LLM Âæû‰∫ãÊúâÂ∫è‰∏îÂèØÈù†ÁöÑÊé®ÁêÜ‰æÜÂä†Âº∑Â∞ç‰∫ãÂØ¶Áü•Ë≠òÁöÑÂõûÊÜ∂„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜËÉåÊôØË°ùÁ™ÅÂ¶Ç‰ΩïÂΩ±ÈüøÊé®ÁêÜÈÅéÁ®ã‰∏≠‰∫ãÂØ¶ÁöÑÊ™¢Á¥¢Ôºå‰ª•ÂÖ®Èù¢‰∫ÜËß£ LLM ÁöÑ‰∫ãÂØ¶ÂõûÊÜ∂Ë°åÁÇ∫„ÄÇ‰ª£Á¢ºÂíåÊï∏ÊìöÂ∞áÂæàÂø´Êèê‰æõ„ÄÇ</paragraph>

##### **Making Long-Context Language Models Better Multi-Hop Reasoners**
2408.03246v1 by Yanyang Li, Shuo Liang, Michael R. Lyu, Liwei Wang

Recent advancements in long-context modeling have enhanced language models
(LMs) for complex tasks across multiple NLP applications. Despite this
progress, we find that these models struggle with multi-hop reasoning and
exhibit decreased performance in the presence of noisy contexts. In this paper,
we introduce Reasoning with Attributions, a novel approach that prompts LMs to
supply attributions for each assertion during their reasoning. We validate our
approach through experiments on three multi-hop datasets, employing both
proprietary and open-source models, and demonstrate its efficacy and
resilience. Furthermore, we explore methods to augment reasoning capabilities
via fine-tuning and offer an attribution-annotated dataset and a specialized
training strategy. Our fine-tuned model achieves competitive performance on
multi-hop reasoning benchmarks, closely paralleling proprietary LMs such as
ChatGPT and Claude-instant.

ÊëòË¶ÅÔºöÊúÄËøëÂú®Èï∑ÊñáÊú¨Âª∫Ê®°ÊñπÈù¢ÁöÑÈÄ≤Â±ïÂ¢ûÂº∑‰∫ÜË™ûË®ÄÊ®°Âûã (LM) Âú®Â§öÂÄã NLP ÊáâÁî®‰∏≠ËôïÁêÜË§áÈõú‰ªªÂãôÁöÑËÉΩÂäõ„ÄÇÂÑòÁÆ°ÊúâÈÄô‰∫õÈÄ≤Â±ïÔºåÊàëÂÄëÁôºÁèæÈÄô‰∫õÊ®°ÂûãÂú®Â§öË∑≥Êé®ÁêÜÊñπÈù¢ÈÅáÂà∞Âõ∞Èõ£Ôºå‰∏¶‰∏îÂú®Â≠òÂú®ÂòàÈõúÁí∞Â¢ÉÊôÇË°®Áèæ‰∏ãÈôç„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫ÜÊ≠∏Âõ†Êé®ÁêÜÔºåÈÄôÊòØ‰∏ÄÁ®ÆÊñ∞Á©éÁöÑÊñπÊ≥ïÔºåÂÆÉÊèêÁ§∫ LM Âú®Êé®ÁêÜÈÅéÁ®ã‰∏≠ÁÇ∫ÊØèÂÄãÊñ∑Ë®ÄÊèê‰æõÊ≠∏Âõ†„ÄÇÊàëÂÄëÈÄöÈÅéÂú®‰∏âÂÄãÂ§öË∑≥Êï∏ÊìöÈõÜ‰∏äÈÄ≤Ë°åÂØ¶È©óÈ©óË≠â‰∫ÜÊàëÂÄëÁöÑÂÅöÊ≥ïÔºåÂêåÊôÇÊé°Áî®Â∞àÊúâÊ®°ÂûãÂíåÈñãÊ∫êÊ®°ÂûãÔºå‰∏¶Â±ïÁ§∫‰∫ÜÂÖ∂ÊúâÊïàÊÄßÂíåÂΩàÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÊé¢Á¥¢‰∫ÜÈÄöÈÅéÂæÆË™ø‰æÜÊì¥ÂÖÖÊé®ÁêÜËÉΩÂäõÁöÑÊñπÊ≥ïÔºå‰∏¶Êèê‰æõ‰∫Ü‰∏ÄÂÄãÊ≠∏Âõ†Ë®ªÈáãÊï∏ÊìöÈõÜÂíå‰∏ÄÂÄãÂ∞àÈñÄÁöÑË®ìÁ∑¥Á≠ñÁï•„ÄÇÊàëÂÄëÂæÆË™øÂæåÁöÑÊ®°ÂûãÂú®Â§öË∑≥Êé®ÁêÜÂü∫Ê∫ñ‰∏äÂèñÂæó‰∫ÜÊúâÁ´∂Áà≠ÂäõÁöÑË°®ÁèæÔºåËàáÂ∞àÊúâ LMÔºà‰æãÂ¶Ç ChatGPT Âíå Claude-instantÔºâÂØÜÂàáÁõ∏Èóú„ÄÇ

##### **MLC-GCN: Multi-Level Generated Connectome Based GCN for AD Analysis**
2408.03358v1 by Wenqi Zhu, Yinghua Fu, Ze Wang

Alzheimer's Disease (AD) is a currently incurable neurodegeneartive disease.
Accurately detecting AD, especially in the early stage, represents a high
research priority. AD is characterized by progressive cognitive impairments
that are related to alterations in brain functional connectivity (FC). Based on
this association, many studies have been published over the decades using FC
and machine learning to differentiate AD from healthy aging. The most recent
development in this detection method highlights the use of graph neural network
(GNN) as the brain functionality analysis. In this paper, we proposed a stack
of spatio-temporal feature extraction and graph generation based AD
classification model using resting state fMRI. The proposed multi-level
generated connectome (MLC) based graph convolutional network (GCN) (MLC-GCN)
contains a multi-graph generation block and a GCN prediction block. The
multi-graph generation block consists of a hierarchy of spatio-temporal feature
extraction layers for extracting spatio-temporal rsfMRI features at different
depths and building the corresponding connectomes. The GCN prediction block
takes the learned multi-level connectomes to build and optimize GCNs at each
level and concatenates the learned graphical features as the final predicting
features for AD classification. Through independent cohort validations, MLC-GCN
shows better performance for differentiating MCI, AD, and normal aging than
state-of-art GCN and rsfMRI based AD classifiers. The proposed MLC-GCN also
showed high explainability in terms of learning clinically reasonable
connectome node and connectivity features from two independent datasets. While
we only tested MLC-GCN on AD, the basic rsfMRI-based multi-level learned GCN
based outcome prediction strategy is valid for other diseases or clinical
outcomes.

ÊëòË¶ÅÔºöÈòøËå≤Êµ∑ÈªòÁóá (AD) ÊòØ‰∏ÄÁ®ÆÁõÆÂâçÁÑ°Ê≥ïÊ≤ªÁôíÁöÑÁ•ûÁ∂ìÈÄÄÂåñÊÄßÁñæÁóÖ„ÄÇ
Ê∫ñÁ¢∫Âú∞ÂÅµÊ∏¨ ADÔºåÁâπÂà•ÊòØÂú®Êó©ÊúüÈöéÊÆµÔºå‰ª£Ë°®‰∏ÄÈ†ÖÈ´òÂ∫¶ÁöÑÁ†îÁ©∂ÂÑ™ÂÖà‰∫ãÈ†Ö„ÄÇAD ÁöÑÁâπÂæµÊòØÊúÉÈÄêÊº∏Ë™çÁü•ÂäüËÉΩÂèóÊêçÔºåÈÄôËàáËÖ¶ÈÉ®ÂäüËÉΩÈÄ£Êé•ÊÄß (FC) ÁöÑÊîπËÆäÊúâÈóú„ÄÇÂü∫ÊñºÈÄôÁ®ÆÈóúËÅØÔºåÂú®ÈÅéÂéªÁöÑÊï∏ÂçÅÂπ¥‰∏≠ÔºåË®±Â§öÁ†îÁ©∂Â∑≤‰ΩøÁî® FC ÂíåÊ©üÂô®Â≠∏Áøí‰æÜÂçÄÂàÜ AD ÂíåÂÅ•Â∫∑ËÄÅÂåñ„ÄÇÈÄôÁ®ÆÂÅµÊ∏¨ÊñπÊ≥ïÁöÑÊúÄÊñ∞ÁôºÂ±ïÔºåÁ™ÅÈ°Ø‰∫Ü‰ΩøÁî®ÂúñÁ•ûÁ∂ìÁ∂≤Ë∑Ø (GNN) ‰ΩúÁÇ∫ËÖ¶ÈÉ®ÂäüËÉΩÂàÜÊûê„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÂÄãÂ†ÜÁñäÁöÑÊôÇÁ©∫ÁâπÂæµËêÉÂèñÂíåÂúñÂΩ¢ÁîüÊàêÔºåÂü∫Êñº AD ÂàÜÈ°ûÊ®°ÂûãÔºå‰ΩøÁî®ÈùúÊ≠¢ÁãÄÊÖã fMRI„ÄÇÊâÄÊèêÂá∫ÁöÑÂ§öÂ±§Á¥öÁîüÊàêÈÄ£Êé•ÁµÑ (MLC) Âü∫ÊñºÂúñÂΩ¢Âç∑Á©çÁ∂≤Ë∑Ø (GCN) (MLC-GCN) ÂåÖÂê´‰∏ÄÂÄãÂ§öÂúñÂΩ¢ÁîüÊàêÂçÄÂ°äÂíå‰∏ÄÂÄã GCN È†êÊ∏¨ÂçÄÂ°ä„ÄÇÂ§öÂúñÂΩ¢ÁîüÊàêÂçÄÂ°äÂåÖÂê´‰∏ÄÂÄãÊôÇÁ©∫ÁâπÂæµËêÉÂèñÂ±§ÁöÑÈöéÂ±§ÔºåÁî®ÊñºËêÉÂèñ‰∏çÂêåÊ∑±Â∫¶‰∏ãÁöÑÊôÇÁ©∫ rsfMRI ÁâπÂæµÔºå‰∏¶Âª∫Á´ãÂ∞çÊáâÁöÑÈÄ£Êé•ÁµÑ„ÄÇGCN È†êÊ∏¨ÂçÄÂ°äÊé°Áî®Â∑≤Â≠∏ÁøíÁöÑÂ§öÂ±§Á¥öÈÄ£Êé•ÁµÑÔºåÂú®ÊØèÂÄãÂ±§Á¥öÂª∫Á´ã‰∏¶ÊúÄ‰Ω≥Âåñ GCNÔºå‰∏¶Â∞áÂ∑≤Â≠∏ÁøíÁöÑÂúñÂΩ¢ÁâπÂæµ‰∏≤ËÅØÊàêÁî®Êñº AD ÂàÜÈ°ûÁöÑÊúÄÁµÇÈ†êÊ∏¨ÁâπÂæµ„ÄÇÈÄèÈÅéÁç®Á´ãÁöÑÁæ§ÁµÑÈ©óË≠âÔºåMLC-GCN Âú®ÂçÄÂàÜ MCI„ÄÅAD ÂíåÊ≠£Â∏∏ËÄÅÂåñÊñπÈù¢ÔºåË°®ÁèæÂÑ™ÊñºÊúÄÂÖàÈÄ≤ÁöÑ GCN ÂíåÂü∫Êñº rsfMRI ÁöÑ AD ÂàÜÈ°ûÂô®„ÄÇÊâÄÊèêÂá∫ÁöÑ MLC-GCN ‰πüÂú®ÂæûÂÖ©ÂÄãÁç®Á´ãÁöÑË≥áÊñôÈõÜ‰∏≠Â≠∏ÁøíËá®Â∫ä‰∏äÂêàÁêÜÁöÑÈÄ£Êé•ÁµÑÁØÄÈªûÂíåÈÄ£Êé•ÁâπÂæµÊñπÈù¢ÔºåË°®ÁèæÂá∫È´òÂ∫¶ÁöÑÂèØËß£ÈáãÊÄß„ÄÇÈõñÁÑ∂ÊàëÂÄëÂè™Âú® AD ‰∏äÊ∏¨Ë©¶ MLC-GCNÔºå‰ΩÜÂü∫Êú¨ÁöÑÂü∫Êñº rsfMRI ÁöÑÂ§öÂ±§Á¥öÂ≠∏Áøí GCN Âü∫ÊñºÁµêÊûúÈ†êÊ∏¨Á≠ñÁï•ÔºåÂ∞çÂÖ∂‰ªñÁñæÁóÖÊàñËá®Â∫äÁµêÊûúÊúâÊïà„ÄÇ

##### **Personalizing Federated Instrument Segmentation with Visual Trait Priors in Robotic Surgery**
2408.03208v1 by Jialang Xu, Jiacheng Wang, Lequan Yu, Danail Stoyanov, Yueming Jin, Evangelos B. Mazomenos

Personalized federated learning (PFL) for surgical instrument segmentation
(SIS) is a promising approach. It enables multiple clinical sites to
collaboratively train a series of models in privacy, with each model tailored
to the individual distribution of each site. Existing PFL methods rarely
consider the personalization of multi-headed self-attention, and do not account
for appearance diversity and instrument shape similarity, both inherent in
surgical scenes. We thus propose PFedSIS, a novel PFL method with visual trait
priors for SIS, incorporating global-personalized disentanglement (GPD),
appearance-regulation personalized enhancement (APE), and shape-similarity
global enhancement (SGE), to boost SIS performance in each site. GPD represents
the first attempt at head-wise assignment for multi-headed self-attention
personalization. To preserve the unique appearance representation of each site
and gradually leverage the inter-site difference, APE introduces appearance
regulation and provides customized layer-wise aggregation solutions via
hypernetworks for each site's personalized parameters. The mutual shape
information of instruments is maintained and shared via SGE, which enhances the
cross-style shape consistency on the image level and computes the
shape-similarity contribution of each site on the prediction level for updating
the global parameters. PFedSIS outperforms state-of-the-art methods with +1.51%
Dice, +2.11% IoU, -2.79 ASSD, -15.55 HD95 performance gains. The corresponding
code and models will be released at https://github.com/wzjialang/PFedSIS.

ÊëòË¶ÅÔºö<paragraph>ÈáùÂ∞çÊâãË°ìÂô®Ê¢∞ÂàÜÂâ≤ÔºàSISÔºâÁöÑÂÄã‰∫∫ÂåñËÅØÈÇ¶Â≠∏ÁøíÔºàPFLÔºâÊòØ‰∏ÄÁ®ÆÊúâÂâçÊôØÁöÑÊñπÊ≥ï„ÄÇÂÆÉËÆìÂ§öÂÄãËá®Â∫äÂú∞ÈªûËÉΩÂ§†Âú®Èö±ÁßÅÁöÑÊ¢ù‰ª∂‰∏ãÂÖ±ÂêåË®ìÁ∑¥‰∏ÄÁ≥ªÂàóÊ®°ÂûãÔºåÊØèÂÄãÊ®°ÂûãÈÉΩÊ†πÊìöÊØèÂÄãÂú∞ÈªûÁöÑÂÄãÂà•ÂàÜ‰ΩàÈÄ≤Ë°åË™øÊï¥„ÄÇÁèæÊúâÁöÑ PFL ÊñπÊ≥ïÂæàÂ∞ëËÄÉÊÖÆÂ§öÈ†≠Ëá™ÊàëÊ≥®ÊÑèÂäõÁöÑÂÄã‰∫∫ÂåñÔºåËÄå‰∏îÊ≤íÊúâËÄÉÊÖÆÂ§ñËßÄÁöÑÂ§öÊ®£ÊÄßÂíåÂô®Ê¢∞ÂΩ¢ÁãÄÁöÑÁõ∏‰ººÊÄßÔºåÈÄôÂÖ©ËÄÖÈÉΩÂ≠òÂú®ÊñºÊâãË°ìÂ†¥ÊôØ‰∏≠„ÄÇÂõ†Ê≠§ÔºåÊàëÂÄëÊèêÂá∫‰∫Ü PFedSISÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂÖ∑ÊúâË¶ñË¶∫ÁâπÂæµÂÖàÈ©óÁöÑ SIS ÁöÑÊñ∞Âûã PFL ÊñπÊ≥ïÔºåÂÆÉÁµêÂêà‰∫ÜÂÖ®Â±ÄÂÄãÊÄßÂåñËß£Á≥æÁ∫èÔºàGPDÔºâ„ÄÅÂ§ñËßÄË™øÁØÄÂÄãÊÄßÂåñÂ¢ûÂº∑ÔºàAPEÔºâÂíåÂΩ¢ÁãÄÁõ∏‰ººÊÄßÂÖ®Â±ÄÂ¢ûÂº∑ÔºàSGEÔºâÔºå‰ª•ÊèêÂçáÊØèÂÄãÂú∞ÈªûÁöÑ SIS ÊïàËÉΩ„ÄÇGPD ‰ª£Ë°®‰∫ÜÈáùÂ∞çÂ§öÈ†≠Ëá™ÊàëÊ≥®ÊÑèÂäõÂÄãÊÄßÂåñÈÄ≤Ë°åÈ†≠ÈÉ®ÂàÜÈÖçÁöÑÈ¶ñÊ¨°ÂòóË©¶„ÄÇÁÇ∫‰∫Ü‰øùÁïôÊØèÂÄãÂú∞ÈªûÁöÑÁç®ÁâπÂ§ñËßÄË°®Á§∫‰∏¶ÈÄêÊº∏Âà©Áî®Âú∞ÈªûÈñìÁöÑÂ∑ÆÁï∞ÔºåAPE ÂºïÂÖ•‰∫ÜÂ§ñËßÄË™øÁØÄÔºå‰∏¶ÈÄèÈÅéË∂ÖÁ∂≤Ë∑ØÁÇ∫ÊØèÂÄãÂú∞ÈªûÁöÑÂÄãÊÄßÂåñÂèÉÊï∏Êèê‰æõËá™Ë®ÇÁöÑÈÄêÂ±§ËÅöÂêàËß£Ê±∫ÊñπÊ°à„ÄÇÂô®Ê¢∞ÁöÑÁõ∏‰∫íÂΩ¢ÁãÄË≥áË®äÈÄèÈÅé SGE ÈÄ≤Ë°åÁ∂≠Ë≠∑ÂíåÂÖ±‰∫´ÔºåÈÄôÂ¢ûÂº∑‰∫ÜÂΩ±ÂÉèÂ±§Á¥ö‰∏äÁöÑË∑®È¢®Ê†ºÂΩ¢ÁãÄ‰∏ÄËá¥ÊÄßÔºå‰∏¶Ë®àÁÆóÊØèÂÄãÂú∞ÈªûÂú®È†êÊ∏¨Â±§Á¥ö‰∏äÁöÑÂΩ¢ÁãÄÁõ∏‰ººÊÄßË≤¢ÁçªÔºå‰ª•Êõ¥Êñ∞ÂÖ®Â±ÄÂèÉÊï∏„ÄÇPFedSIS Âú®È™∞Â≠êÁ≥ªÊï∏‰∏äÂÑ™ÊñºÁèæÊúâÊúÄÂÖàÈÄ≤ÁöÑÊñπÊ≥ïÔºåÂàÜÂà•ÊèêÂçá‰∫Ü +1.51%„ÄÅIoU ÊèêÂçá‰∫Ü +2.11%„ÄÅASSD Èôç‰Ωé‰∫Ü -2.79„ÄÅHD95 ÊïàËÉΩÊèêÂçá‰∫Ü -15.55„ÄÇÂ∞çÊáâÁöÑÁ®ãÂºèÁ¢ºÂíåÊ®°ÂûãÂ∞áÂú® https://github.com/wzjialang/PFedSIS ‰∏äÁôºÂ∏É„ÄÇ</paragraph>

##### **A Debiased Nearest Neighbors Framework for Multi-Label Text Classification**
2408.03202v1 by Zifeng Cheng, Zhiwei Jiang, Yafeng Yin, Zhaoling Chen, Cong Wang, Shiping Ge, Qiguo Huang, Qing Gu

Multi-Label Text Classification (MLTC) is a practical yet challenging task
that involves assigning multiple non-exclusive labels to each document.
Previous studies primarily focus on capturing label correlations to assist
label prediction by introducing special labeling schemes, designing specific
model structures, or adding auxiliary tasks. Recently, the $k$ Nearest Neighbor
($k$NN) framework has shown promise by retrieving labeled samples as references
to mine label co-occurrence information in the embedding space. However, two
critical biases, namely embedding alignment bias and confidence estimation
bias, are often overlooked, adversely affecting prediction performance. In this
paper, we introduce a DEbiased Nearest Neighbors (DENN) framework for MLTC,
specifically designed to mitigate these biases. To address embedding alignment
bias, we propose a debiased contrastive learning strategy, enhancing neighbor
consistency on label co-occurrence. For confidence estimation bias, we present
a debiased confidence estimation strategy, improving the adaptive combination
of predictions from $k$NN and inductive binary classifications. Extensive
experiments conducted on four public benchmark datasets (i.e., AAPD, RCV1-V2,
Amazon-531, and EUR-LEX57K) showcase the effectiveness of our proposed method.
Besides, our method does not introduce any extra parameters.

ÊëòË¶ÅÔºöÂ§öÊ®ôÁ±§ÊñáÂ≠óÂàÜÈ°û (MLTC) ÊòØ‰∏ÄÈ†ÖÂØ¶Áî®ÂçªÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑ‰ªªÂãôÔºåÊ∂âÂèäÂ∞áÂ§öÂÄãÈùûÁç®‰ΩîÊ®ôÁ±§ÊåáÊ¥æÁµ¶ÊØèÂÄãÊñá‰ª∂„ÄÇÂÖàÂâçÁöÑÁ†îÁ©∂‰∏ªË¶ÅÂ∞àÊ≥®ÊñºÊì∑ÂèñÊ®ôÁ±§ÈóúËÅØÊÄßÔºåËóâÁî±ÂºïÂÖ•ÁâπÊÆäÊ®ôÁ±§Êû∂Êßã„ÄÅË®≠Ë®àÁâπÂÆöÊ®°ÂûãÁµêÊßãÊàñÊñ∞Â¢ûËºîÂä©‰ªªÂãô‰æÜÂçîÂä©Ê®ôÁ±§È†êÊ∏¨„ÄÇÊúÄËøëÔºåk ÊúÄËøëÈÑ∞ ($k$NN) Êû∂ÊßãÈÄèÈÅéÊì∑ÂèñÊ®ôÁ±§Ê®£Êú¨‰ΩúÁÇ∫ÂèÉËÄÉÔºåÂú®ÂµåÂÖ•Á©∫Èñì‰∏≠ÊåñÊéòÊ®ôÁ±§ÂÖ±ÁèæË≥áË®äÔºåÂ±ïÁèæ‰∫ÜÂâçÊôØ„ÄÇÁÑ∂ËÄåÔºåÂÖ©ÂÄãÈóúÈçµÂÅèÂ∑ÆÔºåÂç≥ÂµåÂÖ•Â∞çÈΩäÂÅèÂ∑ÆÂíå‰ø°ÂøÉ‰º∞Ë®àÂÅèÂ∑ÆÔºåÁ∂ìÂ∏∏Ë¢´ÂøΩÁï•ÔºåÂ∞çÈ†êÊ∏¨ÊïàËÉΩÁî¢ÁîüË≤†Èù¢ÂΩ±Èüø„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫ÜÁî®Êñº MLTC ÁöÑÂéªÂÅèÂ∑ÆÊúÄËøëÈÑ∞ (DENN) Êû∂ÊßãÔºåÁâπÂà•Ë®≠Ë®àÁî®ÊñºÊ∏õËºïÈÄô‰∫õÂÅèÂ∑Æ„ÄÇÁÇ∫‰∫ÜËôïÁêÜÂµåÂÖ•Â∞çÈΩäÂÅèÂ∑ÆÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂéªÂÅèÂ∑ÆÂ∞çÊØîÂ≠∏ÁøíÁ≠ñÁï•ÔºåÂ¢ûÂº∑ÈÑ∞Â±ÖÂú®Ê®ôÁ±§ÂÖ±Áèæ‰∏äÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÂ∞çÊñº‰ø°ÂøÉ‰º∞Ë®àÂÅèÂ∑ÆÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÂéªÂÅèÂ∑Æ‰ø°ÂøÉ‰º∞Ë®àÁ≠ñÁï•ÔºåÊîπÂñÑ‰∫Ü‰æÜËá™ $k$NN ÂíåÊ≠∏Á¥ç‰∫åÂÖÉÂàÜÈ°ûÁöÑÈ†êÊ∏¨ÁöÑÈÅ©ÊáâÊÄßÁµÑÂêà„ÄÇÂú®ÂõõÂÄãÂÖ¨ÈñãÂü∫Ê∫ñË≥áÊñôÈõÜÔºàÂç≥ AAPD„ÄÅRCV1-V2„ÄÅAmazon-531 Âíå EUR-LEX57KÔºâ‰∏äÈÄ≤Ë°åÁöÑÂª£Ê≥õÂØ¶È©óÂ±ïÁ§∫‰∫ÜÊàëÂÄëÊèêÂá∫ÁöÑÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëÁöÑÊñπÊ≥ïÊ≤íÊúâÂºïÂÖ•‰ªª‰ΩïÈ°çÂ§ñÂèÉÊï∏„ÄÇ

##### **Adversarial Safety-Critical Scenario Generation using Naturalistic Human Driving Priors**
2408.03200v2 by Kunkun Hao, Yonggang Luo, Wen Cui, Yuqiao Bai, Jucheng Yang, Songyang Yan, Yuxi Pan, Zijiang Yang

Evaluating the decision-making system is indispensable in developing
autonomous vehicles, while realistic and challenging safety-critical test
scenarios play a crucial role. Obtaining these scenarios is non-trivial, thanks
to the long-tailed distribution, sparsity, and rarity in real-world data sets.
To tackle this problem, in this paper, we introduce a natural adversarial
scenario generation solution using naturalistic human driving priors and
reinforcement learning techniques. By doing this, we can obtain large-scale
test scenarios that are both diverse and realistic. Specifically, we build a
simulation environment that mimics natural traffic interaction scenarios.
Informed by this environment, we implement a two-stage procedure. The first
stage incorporates conventional rule-based models, e.g., IDM~(Intelligent
Driver Model) and MOBIL~(Minimizing Overall Braking Induced by Lane changes)
model, to coarsely and discretely capture and calibrate key control parameters
from the real-world dataset. Next, we leverage GAIL~(Generative Adversarial
Imitation Learning) to represent driver behaviors continuously. The derived
GAIL can be further used to design a PPO~(Proximal Policy Optimization)-based
actor-critic network framework to fine-tune the reward function, and then
optimizes our natural adversarial scenario generation solution. Extensive
experiments have been conducted in the NGSIM dataset including the trajectory
of 3,000 vehicles. Essential traffic parameters were measured in comparison
with the baseline model, e.g., the collision rate, accelerations, steering, and
the number of lane changes. Our findings demonstrate that the proposed model
can generate realistic safety-critical test scenarios covering both naturalness
and adversariality, which can be a cornerstone for the development of
autonomous vehicles.

ÊëòË¶ÅÔºöÂú®ÈñãÁôºËá™ÂãïÈßïÈßõËªäËºõÊôÇÔºåË©ï‰º∞Ê±∫Á≠ñÁ≥ªÁµ±ÊòØ‰∏çÂèØÊàñÁº∫ÁöÑÔºåËÄåÈÄºÁúü‰∏îÂÖ∑ÊúâÊåëÊà∞ÊÄßÁöÑÂÆâÂÖ®ÈóúÈçµÊ∏¨Ë©¶ÊÉÖÂ¢ÉÊâÆÊºîËëóËá≥ÈóúÈáçË¶ÅÁöÑËßíËâ≤„ÄÇË¶ÅÂèñÂæóÈÄô‰∫õÊÉÖÂ¢É‰∏¶ÈùûÊòì‰∫ãÔºåÈÄôÊòØÂõ†ÁÇ∫Âú®ÁèæÂØ¶‰∏ñÁïåÁöÑË≥áÊñôÈõÜ‰∏≠Â≠òÂú®Èï∑Â∞æÂàÜÂ∏É„ÄÅÁ®ÄÁñèÊÄßÂíåÁ®ÄÊúâÊÄß„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÊàëÂÄëÂú®Êú¨Êñá‰∏≠‰ªãÁ¥π‰∫Ü‰∏ÄÁ®Æ‰ΩøÁî®Ëá™ÁÑ∂Â∞çÊäóÊÉÖÂ¢ÉÁîüÊàêËß£Ê±∫ÊñπÊ°àÔºåË©≤Ëß£Ê±∫ÊñπÊ°àÊé°Áî®Ëá™ÁÑ∂ÁöÑ‰∫∫È°ûÈßïÈßõÂÖàÈ©óÂíåÂº∑ÂåñÂ≠∏ÁøíÊäÄË°ì„ÄÇÈÄèÈÅéÈÄôÊ®£ÂÅöÔºåÊàëÂÄëÂèØ‰ª•ÂèñÂæóÊó¢Â§öÊ®£ÂåñÂèàÈÄºÁúüÁöÑÂ§ßË¶èÊ®°Ê∏¨Ë©¶ÊÉÖÂ¢É„ÄÇÂÖ∑È´î‰æÜË™™ÔºåÊàëÂÄëÂª∫Á´ã‰∫Ü‰∏ÄÂÄãÊ®°Êì¨Áí∞Â¢ÉÔºåÊ®°Êì¨‰∫ÜËá™ÁÑ∂ÁöÑ‰∫§ÈÄö‰∫íÂãïÊÉÖÂ¢É„ÄÇÂú®ÈÄôÂÄãÁí∞Â¢ÉÁöÑÊåáÂ∞é‰∏ãÔºåÊàëÂÄëÂØ¶ÊñΩ‰∫Ü‰∏ÄÂÄãÂÖ©ÈöéÊÆµÁ®ãÂ∫è„ÄÇÁ¨¨‰∏ÄÈöéÊÆµÁ¥çÂÖ•‰∫ÜÂÇ≥Áµ±ÁöÑÂü∫ÊñºË¶èÂâáÁöÑÊ®°ÂûãÔºå‰æãÂ¶Ç IDMÔºàÊô∫ÊÖßÈßïÈßõÊ®°ÂûãÔºâÂíå MOBILÔºàÊúÄÂ∞èÂåñÊèõËªäÈÅìÈÄ†ÊàêÁöÑÊï¥È´îÁÖûËªäÔºâÊ®°ÂûãÔºå‰ª•Á≤óÁï•‰∏îÈõ¢Êï£ÁöÑÊñπÂºèÊì∑ÂèñÂíåÊ†°Ê∫ñ‰æÜËá™ÁèæÂØ¶‰∏ñÁïåË≥áÊñôÈõÜÁöÑ‰∏ªË¶ÅÊéßÂà∂ÂèÉÊï∏„ÄÇÊé•‰∏ã‰æÜÔºåÊàëÂÄëÂà©Áî® GAILÔºàÁîüÊàêÂ∞çÊäóÊ®°‰ªøÂ≠∏ÁøíÔºâ‰æÜÊåÅÁ∫åË°®Á§∫ÈßïÈßõË°åÁÇ∫„ÄÇË°çÁîüÁöÑ GAIL ÂèØÈÄ≤‰∏ÄÊ≠•Áî®ÊñºË®≠Ë®à‰∏ÄÂÄãÂü∫Êñº PPOÔºàËøëÁ´ØÁ≠ñÁï•ÊúÄ‰Ω≥ÂåñÔºâÁöÑÂãï‰Ωú-Ë©ïË´ñÁ∂≤Ë∑ØÊû∂ÊßãÔºå‰ª•ÂæÆË™øÁçéÂãµÂáΩÊï∏ÔºåÁÑ∂ÂæåÊúÄ‰Ω≥ÂåñÊàëÂÄëÁöÑËá™ÁÑ∂Â∞çÊäóÊÉÖÂ¢ÉÁîüÊàêËß£Ê±∫ÊñπÊ°à„ÄÇÊàëÂÄëÂú® NGSIM Ë≥áÊñôÈõÜ‰∏≠ÈÄ≤Ë°å‰∫ÜÂª£Ê≥õÁöÑÂØ¶È©óÔºåÂÖ∂‰∏≠ÂåÖÊã¨ 3,000 ËºõËªäËºõÁöÑËªåË∑°„ÄÇËàáÂü∫Ê∫ñÊ®°ÂûãÁõ∏ÊØîÔºåÊàëÂÄëÊ∏¨Èáè‰∫ÜÈáçË¶ÅÁöÑ‰∫§ÈÄöÂèÉÊï∏Ôºå‰æãÂ¶ÇÁ¢∞ÊíûÁéá„ÄÅÂä†ÈÄüÂ∫¶„ÄÅËΩâÂêëÂíåÊèõËªäÈÅìÊ¨°Êï∏„ÄÇÊàëÂÄëÁöÑÁ†îÁ©∂ÁµêÊûúË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑÊ®°ÂûãÂèØ‰ª•ÁîüÊàêÊ∂µËìãËá™ÁÑ∂ÊÄßÂíåÂ∞çÊäóÊÄßÁöÑÈÄºÁúüÂÆâÂÖ®ÈóúÈçµÊ∏¨Ë©¶ÊÉÖÂ¢ÉÔºåÈÄôÂèØËÉΩÊòØÈñãÁôºËá™ÂãïÈßïÈßõËªäËºõÁöÑÂü∫Áü≥„ÄÇ

##### **Leveraging Parameter Efficient Training Methods for Low Resource Text Classification: A Case Study in Marathi**
2408.03172v1 by Pranita Deshmukh, Nikita Kulkarni, Sanhita Kulkarni, Kareena Manghani, Raviraj Joshi

With the surge in digital content in low-resource languages, there is an
escalating demand for advanced Natural Language Processing (NLP) techniques
tailored to these languages. BERT (Bidirectional Encoder Representations from
Transformers), serving as the foundational framework for numerous NLP
architectures and language models, is increasingly employed for the development
of low-resource NLP models. Parameter Efficient Fine-Tuning (PEFT) is a method
for fine-tuning Large Language Models (LLMs) and reducing the training
parameters to some extent to decrease the computational costs needed for
training the model and achieve results comparable to a fully fine-tuned model.
In this work, we present a study of PEFT methods for the Indic low-resource
language Marathi. We conduct a comprehensive analysis of PEFT methods applied
to various monolingual and multilingual Marathi BERT models. These approaches
are evaluated on prominent text classification datasets like MahaSent,
MahaHate, and MahaNews. The incorporation of PEFT techniques is demonstrated to
significantly expedite the training speed of the models, addressing a critical
aspect of model development and deployment. In this study, we explore Low-Rank
Adaptation of Large Language Models (LoRA) and adapter methods for low-resource
text classification. We show that these methods are competitive with full
fine-tuning and can be used without loss in accuracy. This study contributes
valuable insights into the effectiveness of Marathi BERT models, offering a
foundation for the continued advancement of NLP capabilities in Marathi and
similar Indic languages.

ÊëòË¶ÅÔºö<paragraph>Èö®Ëëó‰ΩéË≥áÊ∫êË™ûË®ÄÁöÑÊï∏‰ΩçÂÖßÂÆπÊøÄÂ¢ûÔºåÂ∞çÊñºÈáùÂ∞çÈÄô‰∫õË™ûË®ÄÈáèË∫´ÊâìÈÄ†ÁöÑÂÖàÈÄ≤Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ (NLP) ÊäÄË°ìÁöÑÈúÄÊ±Ç‰πüËàáÊó•‰ø±Â¢û„ÄÇBERTÔºà‰æÜËá™ Transformer ÁöÑÈõôÂêëÁ∑®Á¢ºÂô®Ë°®Á§∫Ê≥ïÔºâ‰ΩúÁÇ∫Ë®±Â§ö NLP Êû∂ÊßãÂíåË™ûË®ÄÊ®°ÂûãÁöÑÂü∫Êú¨Êû∂ÊßãÔºåÊ≠£Êó•ÁõäÁî®ÊñºÈñãÁôº‰ΩéË≥áÊ∫ê NLP Ê®°Âûã„ÄÇÂèÉÊï∏È´òÊïàÂæÆË™ø (PEFT) ÊòØ‰∏ÄÁ®ÆÂæÆË™øÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ‰∏¶Âú®‰∏ÄÂÆöÁ®ãÂ∫¶‰∏äÊ∏õÂ∞ëË®ìÁ∑¥ÂèÉÊï∏ÁöÑÊñπÊ≥ïÔºå‰ª•Èôç‰ΩéË®ìÁ∑¥Ê®°ÂûãÊâÄÈúÄÁöÑÈÅãÁÆóÊàêÊú¨Ôºå‰∏¶Áç≤ÂæóËàáÂÆåÂÖ®ÂæÆË™øÊ®°ÂûãÁõ∏Áï∂ÁöÑÁµêÊûú„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫Â∞çÂç∞Â∫¶‰ΩéË≥áÊ∫êË™ûË®ÄÈ¶¨ÊãâÊèêË™ûÁöÑ PEFT ÊñπÊ≥ïÈÄ≤Ë°åÁ†îÁ©∂„ÄÇÊàëÂÄëÂ∞çÊáâÁî®ÊñºÂêÑÁ®ÆÂñÆË™ûÂíåÂ§öË™ûÈ¶¨ÊãâÊèêË™û BERT Ê®°ÂûãÁöÑ PEFT ÊñπÊ≥ïÈÄ≤Ë°å‰∫ÜÂÖ®Èù¢ÂàÜÊûê„ÄÇÈÄô‰∫õÊñπÊ≥ïÂú®ËëóÂêçÁöÑÊñáÊú¨ÂàÜÈ°ûË≥áÊñôÈõÜÔºà‰æãÂ¶Ç MahaSent„ÄÅMahaHate Âíå MahaNewsÔºâ‰∏äÈÄ≤Ë°åË©ï‰º∞„ÄÇPEFT ÊäÄË°ìÁöÑÊï¥ÂêàË¢´Ë≠âÊòéÂèØ‰ª•È°ØËëóÂä†Âø´Ê®°ÂûãÁöÑË®ìÁ∑¥ÈÄüÂ∫¶ÔºåËß£Ê±∫‰∫ÜÊ®°ÂûãÈñãÁôºÂíåÈÉ®ÁΩ≤ÁöÑ‰∏ÄÂÄãÈóúÈçµÊñπÈù¢„ÄÇÂú®ÈÄôÈ†ÖÁ†îÁ©∂‰∏≠ÔºåÊàëÂÄëÊé¢Ë®é‰∫ÜÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LoRA) ÁöÑ‰ΩéÁß©ÈÅ©ÊáâÂíå‰ΩéË≥áÊ∫êÊñáÊú¨ÂàÜÈ°ûÁöÑÈÅ©ÈÖçÂô®ÊñπÊ≥ï„ÄÇÊàëÂÄëË°®ÊòéÔºåÈÄô‰∫õÊñπÊ≥ïËàáÂÆåÂÖ®ÂæÆË™øÂÖ∑ÊúâÁ´∂Áà≠ÂäõÔºå‰∏¶‰∏îÂèØ‰ª•Âú®‰∏çÊêçÂ§±Ê∫ñÁ¢∫ÊÄßÁöÑÊÉÖÊ≥Å‰∏ã‰ΩøÁî®„ÄÇÈÄôÈ†ÖÁ†îÁ©∂Â∞çÈ¶¨ÊãâÊèêË™û BERT Ê®°ÂûãÁöÑÊúâÊïàÊÄßÊèê‰æõ‰∫ÜÊúâÂÉπÂÄºÁöÑË¶ãËß£ÔºåÁÇ∫È¶¨ÊãâÊèêË™ûÂíåÈ°û‰ººÂç∞Â∫¶Ë™ûË®ÄÁöÑ NLP ËÉΩÂäõÊåÅÁ∫åÈÄ≤Ê≠•Â•†ÂÆö‰∫ÜÂü∫Á§é„ÄÇ</paragraph>

##### **Training on the Fly: On-device Self-supervised Learning aboard Nano-drones within 20 mW**
2408.03168v1 by Elia Cereda, Alessandro Giusti, Daniele Palossi

Miniaturized cyber-physical systems (CPSes) powered by tiny machine learning
(TinyML), such as nano-drones, are becoming an increasingly attractive
technology. Their small form factor (i.e., ~10cm diameter) ensures vast
applicability, ranging from the exploration of narrow disaster scenarios to
safe human-robot interaction. Simple electronics make these CPSes inexpensive,
but strongly limit the computational, memory, and sensing resources available
on board. In real-world applications, these limitations are further exacerbated
by domain shift. This fundamental machine learning problem implies that model
perception performance drops when moving from the training domain to a
different deployment one. To cope with and mitigate this general problem, we
present a novel on-device fine-tuning approach that relies only on the limited
ultra-low power resources available aboard nano-drones. Then, to overcome the
lack of ground-truth training labels aboard our CPS, we also employ a
self-supervised method based on ego-motion consistency. Albeit our work builds
on top of a specific real-world vision-based human pose estimation task, it is
widely applicable for many embedded TinyML use cases. Our 512-image on-device
training procedure is fully deployed aboard an ultra-low power GWT GAP9
System-on-Chip and requires only 1MB of memory while consuming as low as 19mW
or running in just 510ms (at 38mW). Finally, we demonstrate the benefits of our
on-device learning approach by field-testing our closed-loop CPS, showing a
reduction in horizontal position error of up to 26% vs. a non-fine-tuned
state-of-the-art baseline. In the most challenging never-seen-before
environment, our on-device learning procedure makes the difference between
succeeding or failing the mission.

ÊëòË¶ÅÔºö<paragraph>Áî±ÂæÆÂûãÊ©üÂô®Â≠∏ÁøíÔºàTinyMLÔºâÈ©ÖÂãïÁöÑÂæÆÂûãÂåñÁ∂≤ÈöõÁ∂≤Ë∑ØÂØ¶È´îÁ≥ªÁµ±ÔºàCPSÔºâÔºå‰æãÂ¶ÇÂ•àÁ±≥ÁÑ°‰∫∫Ê©üÔºåÊ≠£ÊàêÁÇ∫Ë∂ä‰æÜË∂äÊúâÂê∏ÂºïÂäõÁöÑÊäÄË°ì„ÄÇÂÆÉÂÄëÁöÑÂ∞èÂ§ñÂΩ¢ÔºàÂç≥Áõ¥ÂæëÁ¥Ñ 10 ÂÖ¨ÂàÜÔºâÁ¢∫‰øù‰∫ÜÂª£Ê≥õÁöÑÈÅ©Áî®ÊÄßÔºåÂæûÊé¢Á¥¢ÁãπÁ™ÑÁöÑÁÅΩÈõ£Â†¥ÊôØÂà∞ÂÆâÂÖ®ÁöÑ‰∫∫Ê©ü‰∫íÂãï„ÄÇÁ∞°ÂñÆÁöÑÈõªÂ≠êÁî¢ÂìÅËÆìÈÄô‰∫õ CPS ÂÉπÊ†º‰ΩéÂªâÔºå‰ΩÜÊ•µÂ§ßÂú∞ÈôêÂà∂‰∫ÜÊ©üËºâÁöÑÈÅãÁÆó„ÄÅË®òÊÜ∂È´îÂíåÊÑüÊ∏¨Ë≥áÊ∫ê„ÄÇÂú®ÂØ¶ÈöõÊáâÁî®‰∏≠ÔºåÈÄô‰∫õÈôêÂà∂Âõ†È†òÂüüËΩâÁßªËÄåÈÄ≤‰∏ÄÊ≠•ÊÉ°Âåñ„ÄÇÈÄôÂÄãÂü∫Êú¨ÁöÑÊ©üÂô®Â≠∏ÁøíÂïèÈ°åÊÑèÂë≥ËëóÔºåÁï∂ÂæûË®ìÁ∑¥È†òÂüüËΩâÁßªÂà∞‰∏çÂêåÁöÑÈÉ®ÁΩ≤È†òÂüüÊôÇÔºåÊ®°ÂûãÊÑüÁü•ÊïàËÉΩÊúÉ‰∏ãÈôç„ÄÇÁÇ∫‰∫ÜÊáâÂ∞çÂíåÊ∏õËºïÈÄôÂÄãÊôÆÈÅçÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫‰∫Ü‰∏ÄÁ®ÆÊñ∞Á©éÁöÑË£ùÁΩÆ‰∏äÂæÆË™øÊñπÊ≥ïÔºåÂÉÖ‰æùË≥¥ÊñºÂ•àÁ±≥ÁÑ°‰∫∫Ê©ü‰∏äÂèØÁî®ÁöÑÊúâÈôêË∂Ö‰ΩéÂäüÁéáË≥áÊ∫ê„ÄÇÁÑ∂ÂæåÔºåÁÇ∫‰∫ÜÂÖãÊúçÊàëÂÄëÁöÑ CPS ‰∏äÁº∫‰πèÂú∞Èù¢ÁúüÂØ¶Ë®ìÁ∑¥Ê®ôÁ±§ÔºåÊàëÂÄëÈÇÑÊé°Áî®‰∫Ü‰∏ÄÁ®ÆÂü∫ÊñºËá™ÊàëÈÅãÂãï‰∏ÄËá¥ÊÄßÁöÑËá™Áõ£Áù£ÊñπÊ≥ï„ÄÇÂÑòÁÆ°ÊàëÂÄëÁöÑÁ†îÁ©∂Âª∫Á´ãÂú®ÂÖ∑È´îÁöÑÁúüÂØ¶‰∏ñÁïåÂü∫ÊñºË¶ñË¶∫ÁöÑ‰∫∫È´îÂßøÂã¢‰º∞Ë®à‰ªªÂãô‰πã‰∏äÔºå‰ΩÜÂÆÉÂª£Ê≥õÈÅ©Áî®ÊñºË®±Â§öÂµåÂÖ•Âºè TinyML ‰ΩøÁî®Ê°à‰æã„ÄÇÊàëÂÄëÁöÑ 512 ÂΩ±ÂÉèË£ùÁΩÆ‰∏äË®ìÁ∑¥Á®ãÂ∫èÂÆåÂÖ®ÈÉ®ÁΩ≤Âú®Ë∂Ö‰ΩéÂäüÁéá GWT GAP9 Êô∂ÁâáÁµÑ‰∏äÔºåÂè™ÈúÄË¶Å 1MB ÁöÑË®òÊÜ∂È´îÔºåÂêåÊôÇÊ∂àËÄó‰ΩéËá≥ 19mWÔºåÊàñÂÉÖÂú® 510msÔºà38mWÔºâ‰∏ãÂü∑Ë°å„ÄÇÊúÄÂæåÔºåÊàëÂÄëÈÄèÈÅéÂØ¶Âú∞Ê∏¨Ë©¶ÊàëÂÄëÁöÑÈñâÁí∞ CPS ‰æÜÂ±ïÁ§∫ÊàëÂÄëÁöÑË£ùÁΩÆ‰∏äÂ≠∏ÁøíÊñπÊ≥ïÁöÑÂÑ™ÈªûÔºåËàáÈùûÂæÆË™øÁöÑÊúÄÊñ∞Âü∫Ê∫ñÁõ∏ÊØîÔºåÈ°ØÁ§∫Ê∞¥Âπ≥‰ΩçÁΩÆË™§Â∑ÆÊ∏õÂ∞ë‰∫Ü 26%„ÄÇÂú®ÊúÄÂÖ∑ÊåëÊà∞ÊÄßÁöÑÂâçÊâÄÊú™Ë¶ãÁí∞Â¢É‰∏≠ÔºåÊàëÂÄëÁöÑË£ùÁΩÆ‰∏äÂ≠∏ÁøíÁ®ãÂ∫èÂú®‰ªªÂãôÁöÑÊàêÂäüÊàñÂ§±Êïó‰πãÈñìÁî¢Áîü‰∫ÜÂ∑ÆÁï∞„ÄÇ</paragraph>

##### **Dilated Convolution with Learnable Spacings makes visual models more aligned with humans: a Grad-CAM study**
2408.03164v1 by Rabih Chamas, Ismail Khalfaoui-Hassani, Timothee Masquelier

Dilated Convolution with Learnable Spacing (DCLS) is a recent advanced
convolution method that allows enlarging the receptive fields (RF) without
increasing the number of parameters, like the dilated convolution, yet without
imposing a regular grid. DCLS has been shown to outperform the standard and
dilated convolutions on several computer vision benchmarks. Here, we show that,
in addition, DCLS increases the models' interpretability, defined as the
alignment with human visual strategies. To quantify it, we use the Spearman
correlation between the models' GradCAM heatmaps and the ClickMe dataset
heatmaps, which reflect human visual attention. We took eight reference models
- ResNet50, ConvNeXt (T, S and B), CAFormer, ConvFormer, and FastViT (sa 24 and
36) - and drop-in replaced the standard convolution layers with DCLS ones. This
improved the interpretability score in seven of them. Moreover, we observed
that Grad-CAM generated random heatmaps for two models in our study: CAFormer
and ConvFormer models, leading to low interpretability scores. We addressed
this issue by introducing Threshold-Grad-CAM, a modification built on top of
Grad-CAM that enhanced interpretability across nearly all models. The code and
checkpoints to reproduce this study are available at:
https://github.com/rabihchamas/DCLS-GradCAM-Eval.

ÊëòË¶ÅÔºöÂèØÂ≠∏ÁøíÈñìË∑ùÊì¥Â±ïÂç∑Á©ç (DCLS) ÊòØ‰∏ÄÁ®ÆËøëÊúüÈÄ≤ÈöéÁöÑÂç∑Á©çÊñπÊ≥ïÔºåÂÖÅË®±Êì¥Â±ïÊÑüÂèóÈáé (RF)ÔºåËÄåÁÑ°È†àÂ¢ûÂä†ÂèÉÊï∏Êï∏ÈáèÔºåÂ∞±ÂÉèÊì¥Â±ïÂç∑Á©ç‰∏ÄÊ®£Ôºå‰ΩÜÁÑ°È†àÂº∑Âà∂‰ΩøÁî®Ë¶èÂâáÁ∂≤Ê†º„ÄÇÂ∑≤Ë≠âÂØ¶ DCLS Âú®Â§öÂÄãÈõªËÖ¶Ë¶ñË¶∫Âü∫Ê∫ñ‰∏äÂÑ™ÊñºÊ®ôÊ∫ñÂç∑Á©çÂíåÊì¥Â±ïÂç∑Á©ç„ÄÇÂú®Ê≠§ÔºåÊàëÂÄëÂ±ïÁ§∫ DCLS Èô§‰∫ÜËÉΩÊèêÂçáÊ®°ÂûãÁöÑÂèØË©ÆÈáãÊÄßÔºåÂÆöÁæ©ÁÇ∫Ëàá‰∫∫È°ûË¶ñË¶∫Á≠ñÁï•ÁöÑ‰∏ÄËá¥ÊÄß„ÄÇÁÇ∫ÈáèÂåñÂÆÉÔºåÊàëÂÄë‰ΩøÁî®Ê®°ÂûãÁöÑ GradCAM ÁÜ±ÂúñËàá ClickMe Ë≥áÊñôÈõÜÁÜ±Âúñ‰πãÈñìÁöÑ Spearman Áõ∏ÈóúÊÄßÔºåÂÆÉÂèçÊò†‰∫Ü‰∫∫È°ûÁöÑË¶ñË¶∫Ê≥®ÊÑèÂäõ„ÄÇÊàëÂÄëÊé°Áî®‰∫ÜÂÖ´ÂÄãÂèÉËÄÉÊ®°Âûã - ResNet50„ÄÅConvNeXt (T„ÄÅS Âíå B)„ÄÅCAFormer„ÄÅConvFormer Âíå FastViT (sa 24 Âíå 36) - ‰∏¶‰ª• DCLS Âèñ‰ª£Ê®ôÊ∫ñÂç∑Á©çÂ±§„ÄÇÈÄôÊèêÂçá‰∫ÜÂÖ∂‰∏≠‰∏ÉÂÄãÊ®°ÂûãÁöÑÂèØË©ÆÈáãÊÄßÂàÜÊï∏„ÄÇÊ≠§Â§ñÔºåÊàëÂÄëËßÄÂØüÂà∞ Grad-CAM ÁÇ∫ÊàëÂÄëÁ†îÁ©∂‰∏≠ÁöÑÂÖ©ÂÄãÊ®°ÂûãÁî¢Áîü‰∫ÜÈö®Ê©üÁÜ±ÂúñÔºöCAFormer Âíå ConvFormer Ê®°ÂûãÔºåÂ∞éËá¥ÂèØË©ÆÈáãÊÄßÂàÜÊï∏‰Ωé„ÄÇÊàëÂÄëÈÄèÈÅéÂºïÂÖ• Threshold-Grad-CAM ‰æÜËß£Ê±∫ÈÄôÂÄãÂïèÈ°åÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂª∫Á´ãÂú® Grad-CAM ‰πã‰∏äÁöÑ‰øÆÊîπÔºåÂèØÂ¢ûÂº∑Âπæ‰πéÊâÄÊúâÊ®°ÂûãÁöÑÂèØË©ÆÈáãÊÄß„ÄÇÂèØÊñº‰ª•‰∏ãÁ∂≤ÂùÄÂèñÂæóÈáçÁèæÊ≠§Á†îÁ©∂ÁöÑÁ®ãÂºèÁ¢ºÂíåÊ™¢Êü•ÈªûÔºöhttps://github.com/rabihchamas/DCLS-GradCAM-Eval„ÄÇ

##### **Conditioning LLMs with Emotion in Neural Machine Translation**
2408.03150v1 by Charles Brazier, Jean-Luc Rouas

Large Language Models (LLMs) have shown remarkable performance in Natural
Language Processing tasks, including Machine Translation (MT). In this work, we
propose a novel MT pipeline that integrates emotion information extracted from
a Speech Emotion Recognition (SER) model into LLMs to enhance translation
quality. We first fine-tune five existing LLMs on the Libri-trans dataset and
select the most performant model. Subsequently, we augment LLM prompts with
different dimensional emotions and train the selected LLM under these different
configurations. Our experiments reveal that integrating emotion information,
especially arousal, into LLM prompts leads to notable improvements in
translation quality.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) Âú®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãôÔºåÂåÖÊã¨Ê©üÂô®ÁøªË≠Ø (MT)Ôºå‰∏≠Â±ïÁèæÂá∫ÂçìË∂äÁöÑË°®Áèæ„ÄÇÂú®ÈÄôÈ†ÖÂ∑•‰Ωú‰∏≠ÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂâµÊñ∞ÁöÑ MT ÁÆ°ÈÅìÔºåÂ∞áÂæûË™ûÈü≥ÊÉÖÁ∑íËæ®Ë≠ò (SER) Ê®°Âûã‰∏≠ÊèêÂèñÁöÑÊÉÖÁ∑íË≥áË®äÊï¥ÂêàÂà∞ LLM ‰∏≠Ôºå‰ª•ÊèêÂçáÁøªË≠ØÂìÅË≥™„ÄÇÊàëÂÄëÈ¶ñÂÖàÂú® Libri-trans Ë≥áÊñôÈõÜ‰∏äÂæÆË™ø‰∫îÂÄãÁèæÊúâÁöÑ LLMÔºå‰∏¶ÈÅ∏Âá∫Ë°®ÁèæÊúÄ‰Ω≥ÁöÑÊ®°Âûã„ÄÇÊé•ËëóÔºåÊàëÂÄë‰ΩøÁî®‰∏çÂêåÁ∂≠Â∫¶ÁöÑÊÉÖÁ∑íÊì¥ÂÖÖ LLM ÊèêÁ§∫Ôºå‰∏¶Âú®ÈÄô‰∫õ‰∏çÂêåÁöÑË®≠ÂÆö‰∏ãË®ìÁ∑¥ÈÅ∏ÂÆöÁöÑ LLM„ÄÇÊàëÂÄëÁöÑÂØ¶È©óÈ°ØÁ§∫ÔºåÂ∞áÊÉÖÁ∑íË≥áË®äÔºåÂ∞§ÂÖ∂ÊòØÂñöÈÜíÔºåÊï¥ÂêàÂà∞ LLM ÊèêÁ§∫‰∏≠ÔºåÊúÉÈ°ØËëóÊèêÂçáÁøªË≠ØÂìÅË≥™„ÄÇ

##### **Leveraging Entity Information for Cross-Modality Correlation Learning: The Entity-Guided Multimodal Summarization**
2408.03149v1 by Yanghai Zhang, Ye Liu, Shiwei Wu, Kai Zhang, Xukai Liu, Qi Liu, Enhong Chen

The rapid increase in multimedia data has spurred advancements in Multimodal
Summarization with Multimodal Output (MSMO), which aims to produce a multimodal
summary that integrates both text and relevant images. The inherent
heterogeneity of content within multimodal inputs and outputs presents a
significant challenge to the execution of MSMO. Traditional approaches
typically adopt a holistic perspective on coarse image-text data or individual
visual objects, overlooking the essential connections between objects and the
entities they represent. To integrate the fine-grained entity knowledge, we
propose an Entity-Guided Multimodal Summarization model (EGMS). Our model,
building on BART, utilizes dual multimodal encoders with shared weights to
process text-image and entity-image information concurrently. A gating
mechanism then combines visual data for enhanced textual summary generation,
while image selection is refined through knowledge distillation from a
pre-trained vision-language model. Extensive experiments on public MSMO dataset
validate the superiority of the EGMS method, which also prove the necessity to
incorporate entity information into MSMO problem.

ÊëòË¶ÅÔºöÈö®ËëóÂ§öÂ™íÈ´îË≥áÊñôÁöÑÂø´ÈÄüÂ¢ûÂä†ÔºåÂà∫ÊøÄ‰∫ÜÂ§öÊ®°ÊÖãËº∏Âá∫Â§öÊ®°ÊÖãÊëòË¶Å (MSMO) ÁöÑÈÄ≤Â±ïÔºåÂÖ∂ÁõÆÊ®ôÊòØÁî¢Áîü‰∏ÄÂÄãÊï¥ÂêàÊñáÂ≠óÂíåÁõ∏ÈóúÂΩ±ÂÉèÁöÑÂ§öÊ®°ÊÖãÊëòË¶Å„ÄÇÂ§öÊ®°ÊÖãËº∏ÂÖ•ÂíåËº∏Âá∫ÂÖßÂú®ÁöÑÁï∞Ë≥™ÊÄßÔºåÂ∞ç MSMO ÁöÑÂü∑Ë°åÊßãÊàêÈáçÂ§ßÊåëÊà∞„ÄÇÂÇ≥Áµ±ÊñπÊ≥ïÈÄöÂ∏∏Êé°Áî®Êï¥È´îËßÄÈªûÔºåÈáùÂ∞çÁ≤óÁï•ÁöÑÂΩ±ÂÉèÊñáÂ≠óË≥áÊñôÊàñÂÄãÂà•Ë¶ñË¶∫Áâ©‰ª∂ÔºåÂøΩÁï•‰∫ÜÁâ©‰ª∂ËàáÂÖ∂ÊâÄ‰ª£Ë°®ÂØ¶È´î‰πãÈñìÁöÑÊú¨Ë≥™ÈóúËÅØÊÄß„ÄÇÁÇ∫‰∫ÜÊï¥ÂêàÁ¥∞Á≤íÂ∫¶ÁöÑÂØ¶È´îÁü•Ë≠òÔºåÊàëÂÄëÊèêÂá∫‰∏ÄÂÄãÂØ¶È´îÂºïÂ∞éÂºèÂ§öÊ®°ÊÖãÊëòË¶ÅÊ®°Âûã (EGMS)„ÄÇÊàëÂÄëÁöÑÊ®°ÂûãÂª∫ÊßãÂú® BART ‰∏äÔºåÂà©Áî®ÂÖ∑ÊúâÂÖ±‰∫´Ê¨äÈáçÁöÑÈõôÈáçÂ§öÊ®°ÊÖãÁ∑®Á¢ºÂô®ÔºåÂêåÊôÇËôïÁêÜÊñáÂ≠óÂΩ±ÂÉèÂíåÂØ¶È´îÂΩ±ÂÉèË≥áË®ä„ÄÇ‰∏ÄÂÄãÈñòÊéßÊ©üÂà∂Êé•ËëóÁµêÂêàË¶ñË¶∫Ë≥áÊñôÔºå‰ª•Â¢ûÂº∑ÊñáÂ≠óÊëòË¶ÅÁöÑÁîüÊàêÔºåÂêåÊôÇÈÄèÈÅéÈ†êÂÖàË®ìÁ∑¥ÁöÑË¶ñË¶∫Ë™ûË®ÄÊ®°ÂûãÁöÑÁü•Ë≠òËêÉÂèñÔºåÁ≤æÁÖâÂΩ±ÂÉèÈÅ∏Êìá„ÄÇÂú®ÂÖ¨Èñã MSMO Ë≥áÊñôÈõÜ‰∏äÁöÑÂª£Ê≥õÂØ¶È©óÈ©óË≠â‰∫Ü EGMS ÊñπÊ≥ïÁöÑÂÑ™Ë∂äÊÄßÔºå‰πüË≠âÊòé‰∫ÜÂ∞áÂØ¶È´îË≥áË®äÁ¥çÂÖ• MSMO ÂïèÈ°åÁöÑÂøÖË¶ÅÊÄß„ÄÇ

##### **Inference Optimizations for Large Language Models: Effects, Challenges, and Practical Considerations**
2408.03130v1 by Leo Donisch, Sigurd Schacht, Carsten Lanquillon

Large language models are ubiquitous in natural language processing because
they can adapt to new tasks without retraining. However, their sheer scale and
complexity present unique challenges and opportunities, prompting researchers
and practitioners to explore novel model training, optimization, and deployment
methods. This literature review focuses on various techniques for reducing
resource requirements and compressing large language models, including
quantization, pruning, knowledge distillation, and architectural optimizations.
The primary objective is to explore each method in-depth and highlight its
unique challenges and practical applications. The discussed methods are
categorized into a taxonomy that presents an overview of the optimization
landscape and helps navigate it to understand the research trajectory better.

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰∏≠ÁÑ°Ëôï‰∏çÂú®ÔºåÂõ†ÁÇ∫ÂÆÉÂÄëÁÑ°ÈúÄÈáçÊñ∞Ë®ìÁ∑¥Âç≥ÂèØÈÅ©ÊáâÊñ∞‰ªªÂãô„ÄÇÁÑ∂ËÄåÔºåÂÆÉÂÄëÁöÑË¶èÊ®°ÂíåË§áÈõúÊÄßÂ∏∂‰æÜ‰∫ÜÁç®ÁâπÁöÑÊåëÊà∞ÂíåÊ©üÈÅáÔºå‰øÉ‰ΩøÁ†îÁ©∂‰∫∫Âì°ÂíåÂæûÊ•≠ËÄÖÊé¢Á¥¢Êñ∞ÁöÑÊ®°ÂûãË®ìÁ∑¥„ÄÅÊúÄ‰Ω≥ÂåñÂíåÈÉ®ÁΩ≤ÊñπÊ≥ï„ÄÇÈÄôÁØáÊñáÁçªÂõûÈ°ßÈáçÈªûÊé¢Ë®éÂêÑÁ®ÆÊäÄË°ìÔºå‰ª•Ê∏õÂ∞ëË≥áÊ∫êÈúÄÊ±Ç‰∏¶Â£ìÁ∏ÆÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºåÂåÖÊã¨ÈáèÂåñ„ÄÅÂâ™Êûù„ÄÅÁü•Ë≠òËí∏È§æÂíåÊû∂ÊßãÊúÄ‰Ω≥Âåñ„ÄÇ‰∏ªË¶ÅÁõÆÊ®ôÊòØÊ∑±ÂÖ•Êé¢Ë®éÊØèÁ®ÆÊñπÊ≥ïÔºå‰∏¶Âº∑Ë™øÂÖ∂Áç®ÁâπÁöÑÊåëÊà∞ÂíåÂØ¶ÈöõÊáâÁî®„ÄÇÊâÄË®éË´ñÁöÑÊñπÊ≥ïË¢´ÂàÜÈ°ûÂà∞‰∏ÄÂÄãÂàÜÈ°ûÊ≥ï‰∏≠ÔºåË©≤ÂàÜÈ°ûÊ≥ïÊ¶ÇËø∞‰∫ÜÊúÄ‰Ω≥ÂåñÈ†òÂüüÔºå‰∏¶ÊúâÂä©ÊñºÁÄèË¶ΩÂÆÉ‰ª•Êõ¥Â•ΩÂú∞ÁêÜËß£Á†îÁ©∂ËªåË∑°„ÄÇ

##### **Lisbon Computational Linguists at SemEval-2024 Task 2: Using A Mistral 7B Model and Data Augmentation**
2408.03127v1 by Artur Guimar√£es, Bruno Martins, Jo√£o Magalh√£es

This paper describes our approach to the SemEval-2024 safe biomedical Natural
Language Inference for Clinical Trials (NLI4CT) task, which concerns
classifying statements about Clinical Trial Reports (CTRs). We explored the
capabilities of Mistral-7B, a generalist open-source Large Language Model
(LLM). We developed a prompt for the NLI4CT task, and fine-tuned a quantized
version of the model using an augmented version of the training dataset. The
experimental results show that this approach can produce notable results in
terms of the macro F1-score, while having limitations in terms of faithfulness
and consistency. All the developed code is publicly available on a GitHub
repository

ÊëòË¶ÅÔºöÊú¨ÊñáÊèèËø∞‰∫ÜÊàëÂÄëÂ∞ç SemEval-2024 ÂÆâÂÖ®ÁîüÁâ©ÈÜ´Â≠∏Ëá™ÁÑ∂Ë™ûË®ÄÊé®Ë´ñËá®Â∫äË©¶È©ó (NLI4CT) ‰ªªÂãôÁöÑÊñπÊ≥ïÔºåË©≤‰ªªÂãôÊ∂âÂèäÂ∞çËá®Â∫äË©¶È©óÂ†±Âëä (CTR) ‰∏≠ÁöÑÈô≥Ëø∞ÈÄ≤Ë°åÂàÜÈ°û„ÄÇÊàëÂÄëÊé¢Ë®é‰∫Ü Mistral-7B ÁöÑËÉΩÂäõÔºåÈÄôÊòØ‰∏ÄÂÄãÈÄöÊâçÁöÑÈñãÊ∫êÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM)„ÄÇÊàëÂÄëÁÇ∫ NLI4CT ‰ªªÂãôÈñãÁôº‰∫Ü‰∏ÄÂÄãÊèêÁ§∫Ôºå‰∏¶‰ΩøÁî®Ë®ìÁ∑¥Êï∏ÊìöÈõÜÁöÑÊì¥ÂÖÖÁâàÊú¨Â∞çÊ®°ÂûãÁöÑÈáèÂåñÁâàÊú¨ÈÄ≤Ë°å‰∫ÜÂæÆË™ø„ÄÇÂØ¶È©óÁµêÊûúË°®ÊòéÔºåÈÄôÁ®ÆÊñπÊ≥ïÂú®ÂÆèËßÄ F1 ÂàÜÊï∏ÊñπÈù¢ÂèØ‰ª•Áî¢ÁîüÈ°ØËëóÁöÑÁµêÊûúÔºåÂêåÊôÇÂú®‰øùÁúüÂ∫¶Âíå‰∏ÄËá¥ÊÄßÊñπÈù¢Â≠òÂú®Â±ÄÈôêÊÄß„ÄÇÊâÄÊúâÂ∑≤ÈñãÁôºÁöÑ‰ª£Á¢ºÈÉΩÂÖ¨ÈñãÁôºÂ∏ÉÂú® GitHub ÂÄâÂ∫´‰∏≠

##### **COMMENTATOR: A Code-mixed Multilingual Text Annotation Framework**
2408.03125v1 by Rajvee Sheth, Shubh Nisar, Heenaben Prajapati, Himanshu Beniwal, Mayank Singh

As the NLP community increasingly addresses challenges associated with
multilingualism, robust annotation tools are essential to handle multilingual
datasets efficiently. In this paper, we introduce a code-mixed multilingual
text annotation framework, COMMENTATOR, specifically designed for annotating
code-mixed text. The tool demonstrates its effectiveness in token-level and
sentence-level language annotation tasks for Hinglish text. We perform robust
qualitative human-based evaluations to showcase COMMENTATOR led to 5x faster
annotations than the best baseline. Our code is publicly available at
\url{https://github.com/lingo-iitgn/commentator}. The demonstration video is
available at \url{https://bit.ly/commentator_video}.

ÊëòË¶ÅÔºöÈö®Ëëó NLP Á§æÁæ§Êó•ÁõäËëóÈáçÊñºÂõ†Â§öË™ûË®ÄÊÄßËÄåÈù¢Ëá®ÁöÑÊåëÊà∞ÔºåÁ©©ÂÅ•ÁöÑË®ªËß£Â∑•ÂÖ∑Â∞çÊñºÊúâÊïàËôïÁêÜÂ§öË™ûË®ÄË≥áÊñôÈõÜËá≥ÈóúÈáçË¶Å„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄë‰ªãÁ¥π‰∫Ü‰∏ÄÂÄãÁ®ãÂºèÁ¢ºÊ∑∑ÂêàÂ§öË™ûË®ÄÊñáÂ≠óË®ªËß£Êû∂Êßã COMMENTATORÔºåÂ∞àÈñÄË®≠Ë®àÁî®ÊñºË®ªËß£Á®ãÂºèÁ¢ºÊ∑∑ÂêàÊñáÂ≠ó„ÄÇÊ≠§Â∑•ÂÖ∑Â±ïÁèæÂÖ∂Âú® Hinglish ÊñáÂ≠óÁöÑË©ûÂÖÉÂ±§Á¥öÂíåÂè•Â≠êÂ±§Á¥öË™ûË®ÄË®ªËß£‰ªªÂãô‰∏≠ÁöÑÊïàËÉΩ„ÄÇÊàëÂÄëÂü∑Ë°åÁ©©ÂÅ•ÁöÑÂÆöÊÄß‰∫∫Â∑•Ë©ï‰º∞Ôºå‰ª•Â±ïÁ§∫ COMMENTATOR ÁöÑË®ªËß£ÈÄüÂ∫¶ÊØîÊúÄ‰Ω≥Âü∫Á∑öÂø´ 5 ÂÄç„ÄÇÊàëÂÄëÁöÑÁ®ãÂºèÁ¢ºÂ∑≤ÂÖ¨ÈñãÊñº \url{https://github.com/lingo-iitgn/commentator}„ÄÇÁ§∫ÁØÑÂΩ±ÁâáÂèØÊñº \url{https://bit.ly/commentator_video} ÂèñÂæó„ÄÇ

##### **Evaluating the Translation Performance of Large Language Models Based on Euas-20**
2408.03119v1 by Yan Huang, Wei Liu

In recent years, with the rapid development of deep learning technology,
large language models (LLMs) such as BERT and GPT have achieved breakthrough
results in natural language processing tasks. Machine translation (MT), as one
of the core tasks of natural language processing, has also benefited from the
development of large language models and achieved a qualitative leap. Despite
the significant progress in translation performance achieved by large language
models, machine translation still faces many challenges. Therefore, in this
paper, we construct the dataset Euas-20 to evaluate the performance of large
language models on translation tasks, the translation ability on different
languages, and the effect of pre-training data on the translation ability of
LLMs for researchers and developers.

ÊëòË¶ÅÔºöËøëÂπ¥‰æÜÔºåÈö®ËëóÊ∑±Â∫¶Â≠∏ÁøíÊäÄË°ìÁöÑÂø´ÈÄüÁôºÂ±ïÔºå
BERT Âíå GPT Á≠âÂ§ßÂûãË™ûË®ÄÊ®°ÂûãÔºàLLMÔºâÂú®Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜ‰ªªÂãô‰∏≠ÂèñÂæó‰∫ÜÁ™ÅÁ†¥ÊÄßÁöÑ
ÊàêÊûú„ÄÇÊ©üÂô®ÁøªË≠ØÔºàMTÔºâ‰ΩúÁÇ∫Ëá™ÁÑ∂Ë™ûË®ÄËôïÁêÜÁöÑÊ†∏ÂøÉ‰ªªÂãô‰πã‰∏ÄÔºå‰πüÂèóÁõäÊñº
Â§ßÂûãË™ûË®ÄÊ®°ÂûãÁöÑÁôºÂ±ïËÄåÂèñÂæó‰∫ÜË≥™ÁöÑÈ£õË∫ç„ÄÇÂÑòÁÆ°Â§ßÂûãË™ûË®ÄÊ®°ÂûãÂú®ÁøªË≠ØÊÄßËÉΩ‰∏äÂèñÂæó‰∫ÜÈ°ØËëóÈÄ≤Â±ïÔºå
Ê©üÂô®ÁøªË≠Ø‰ªçÁÑ∂Èù¢Ëá®ËëóË´∏Â§öÊåëÊà∞„ÄÇÂõ†Ê≠§ÔºåÊú¨ÊñáÊßãÂª∫‰∫Ü Euas-20 Êï∏ÊìöÈõÜÔºåÁî®ÊñºË©ï‰º∞Â§ßÂûã
Ë™ûË®ÄÊ®°ÂûãÂú®ÁøªË≠Ø‰ªªÂãô‰∏äÁöÑË°®Áèæ„ÄÅ‰∏çÂêåË™ûË®ÄÁöÑÁøªË≠ØËÉΩÂäõÔºå‰ª•ÂèäÈ†êË®ìÁ∑¥Êï∏ÊìöÂ∞ç LLM ÁøªË≠ØËÉΩÂäõÁöÑÂΩ±ÈüøÔºå‰æõÁ†îÁ©∂‰∫∫Âì°ÂíåÈñãÁôº‰∫∫Âì°‰ΩøÁî®„ÄÇ

##### **Topic Modeling with Fine-tuning LLMs and Bag of Sentences**
2408.03099v1 by Johannes Schneider

Large language models (LLM)'s are increasingly used for topic modeling
outperforming classical topic models such as LDA. Commonly, pre-trained LLM
encoders such as BERT are used out-of-the-box despite the fact that fine-tuning
is known to improve LLMs considerably. The challenge lies in obtaining a
suitable (labeled) dataset for fine-tuning. In this paper, we use the recent
idea to use bag of sentences as the elementary unit in computing topics. In
turn, we derive an approach FT-Topic to perform unsupervised fine-tuning
relying primarily on two steps for constructing a training dataset in an
automatic fashion. First, a heuristic method to identifies pairs of sentence
groups that are either assumed to be of the same or different topics. Second,
we remove sentence pairs that are likely labeled incorrectly. The dataset is
then used to fine-tune an encoder LLM, which can be leveraged by any topic
modeling approach using embeddings. However, in this work, we demonstrate its
effectiveness by deriving a novel state-of-the-art topic modeling method called
SenClu, which achieves fast inference through an expectation-maximization
algorithm and hard assignments of sentence groups to a single topic, while
giving users the possibility to encode prior knowledge on the topic-document
distribution. Code is at \url{https://github.com/JohnTailor/FT-Topic}

ÊëòË¶ÅÔºöÂ§ßÂûãË™ûË®ÄÊ®°Âûã (LLM) ÊÑà‰æÜÊÑàÂ∏∏Ë¢´Áî®Êñº‰∏ªÈ°åÊ®°ÂûãÔºåÂÖ∂ÊïàËÉΩÂÑ™Êñº LDA Á≠âÂÇ≥Áµ±‰∏ªÈ°åÊ®°Âûã„ÄÇÂÑòÁÆ°ÂæÆË™øÂ∑≤Áü•ËÉΩÂ§ßÂπÖÊîπÂñÑ LLMÔºå‰ΩÜÈÄöÂ∏∏ÊúÉÁõ¥Êé•‰ΩøÁî®È†êÂÖàË®ìÁ∑¥Â•ΩÁöÑ LLM Á∑®Á¢ºÂô®Ôºå‰æãÂ¶Ç BERT„ÄÇÊåëÊà∞Âú®ÊñºÂèñÂæóÈÅ©ÂêàÁöÑÔºàÊ®ôÁ±§ÔºâË≥áÊñôÈõÜ‰ª•ÈÄ≤Ë°åÂæÆË™ø„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàëÂÄëÊé°Áî®ÊúÄËøëÁöÑÊÉ≥Ê≥ïÔºåÂ∞áÂè•Â≠êÁµÑÁï∂‰ΩúÈÅãÁÆó‰∏ªÈ°åÁöÑÂü∫Êú¨ÂñÆ‰Ωç„ÄÇÂèçÈÅé‰æÜÔºåÊàëÂÄëË°çÁîüÂá∫ FT-Topic ÊñπÊ≥ïÔºå‰ª•Âü∑Ë°åÈùûÁõ£Áù£ÂºèÂæÆË™øÔºå‰∏ªË¶Å‰æùË≥¥ÂÖ©ÂÄãÊ≠•È©üËá™ÂãïÂª∫ÊßãË®ìÁ∑¥Ë≥áÊñôÈõÜ„ÄÇÈ¶ñÂÖàÔºåÊé°Áî®ÂïüÁôºÂºèÊñπÊ≥ï‰æÜË≠òÂà•ÂÅáË®≠ÁÇ∫Âêå‰∏ªÈ°åÊàñ‰∏çÂêå‰∏ªÈ°åÁöÑÂè•Â≠êÁµÑÂ∞ç„ÄÇÂÖ∂Ê¨°ÔºåÊàëÂÄëÁßªÈô§Ê®ôÁ±§ÂèØËÉΩ‰∏çÊ≠£Á¢∫ÁöÑÂè•Â≠êÂ∞ç„ÄÇÁÑ∂Âæå‰ΩøÁî®Ë≥áÊñôÈõÜÂæÆË™øÁ∑®Á¢ºÂô® LLMÔºå‰ªª‰Ωï‰ΩøÁî®ÂµåÂÖ•ÂºèÁöÑ‰∏ªÈ°åÊ®°ÂûãÊñπÊ≥ïÈÉΩËÉΩÈÅãÁî®Ë©≤Á∑®Á¢ºÂô®„ÄÇÁÑ∂ËÄåÔºåÊàëÂÄëÂú®Ê≠§Â∑•‰Ωú‰∏≠ÈÄèÈÅéË°çÁîüÂá∫Á®±ÁÇ∫ SenClu ÁöÑÊñ∞ÂºèÊúÄÂÖàÈÄ≤‰∏ªÈ°åÊ®°ÂûãÊñπÊ≥ïÔºå‰æÜË≠âÊòéÂÖ∂ÊúâÊïàÊÄß„ÄÇË©≤ÊñπÊ≥ïÈÄèÈÅéÊúüÊúõÂÄºÊúÄÂ§ßÂåñÊºîÁÆóÊ≥ïÂíåÂè•Â≠êÁµÑÂ∞çÂñÆ‰∏Ä‰∏ªÈ°åÁöÑÁ°¨ÂºèÊåáÊ¥æÔºåÂø´ÈÄüÈÄ≤Ë°åÊé®Ë´ñÔºåÂêåÊôÇËÆì‰ΩøÁî®ËÄÖËÉΩÂ§†Â∞ç‰∏ªÈ°åÊñá‰ª∂ÂàÜÂ∏ÉÁ∑®Á¢ºÂÖàÈ©óÁü•Ë≠ò„ÄÇÁ®ãÂºèÁ¢º‰ΩçÊñº \url{https://github.com/JohnTailor/FT-Topic}

##### **500xCompressor: Generalized Prompt Compression for Large Language Models**
2408.03094v1 by Zongqian Li, Yixuan Su, Nigel Collier

Prompt compression is crucial for enhancing inference speed, reducing costs,
and improving user experience. However, current methods face challenges such as
low compression ratios and potential data leakage during evaluation. To address
these issues, we propose 500xCompressor, a method that compresses extensive
natural language contexts into a minimum of one single special token. The
500xCompressor introduces approximately 0.3% additional parameters and achieves
compression ratios ranging from 6x to 480x. It is designed to compress any
text, answer various types of questions, and could be utilized by the original
large language model (LLM) without requiring fine-tuning. Initially,
500xCompressor was pretrained on the Arxiv Corpus, followed by fine-tuning on
the ArxivQA dataset, and subsequently evaluated on strictly unseen and
classical question answering (QA) datasets. The results demonstrate that the
LLM retained 62.26-72.89% of its capabilities compared to using non-compressed
prompts. This study also shows that not all the compressed tokens are equally
utilized and that K V values have significant advantages over embeddings in
preserving information at high compression ratios. The highly compressive
nature of natural language prompts, even for fine-grained complex information,
suggests promising potential for future applications and further research into
developing a new LLM language.

ÊëòË¶ÅÔºöÊèêÁ§∫Â£ìÁ∏ÆÂ∞çÊñºÊèêÂçáÊé®Ë´ñÈÄüÂ∫¶„ÄÅÈôç‰ΩéÊàêÊú¨ÂíåÊîπÂñÑ‰ΩøÁî®ËÄÖÈ´îÈ©óËá≥ÈóúÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÁõÆÂâçÁöÑÊñπÊ≥ïÈù¢Ëá®‰ΩéÂ£ìÁ∏ÆÁéáÂíåË©ï‰º∞ÊúüÈñìÊΩõÂú®Ë≥áÊñôÂ§ñÊ¥©Á≠âÊåëÊà∞„ÄÇÁÇ∫‰∫ÜËß£Ê±∫ÈÄô‰∫õÂïèÈ°åÔºåÊàëÂÄëÊèêÂá∫ 500xCompressorÔºåÈÄôÊòØ‰∏ÄÁ®ÆÂ∞áÂª£Ê≥õÁöÑËá™ÁÑ∂Ë™ûË®ÄËÑàÁµ°Â£ìÁ∏ÆÊàêÊúÄÂ∞ë‰∏ÄÂÄãÁâπÊÆäÁ¨¶ËôüÁöÑÊñπÊ≥ï„ÄÇ500xCompressor ÂºïÂÖ•‰∫ÜÁ¥Ñ 0.3% ÁöÑÈ°çÂ§ñÂèÉÊï∏Ôºå‰∏¶ÈÅîÂà∞‰∫Ü 6 ÂÄçÂà∞ 480 ÂÄçÁöÑÂ£ìÁ∏ÆÁéá„ÄÇÂÆÉË¢´Ë®≠Ë®àÁî®ÊñºÂ£ìÁ∏Æ‰ªª‰ΩïÊñáÂ≠ó„ÄÅÂõûÁ≠îÂêÑÁ®ÆÈ°ûÂûãÁöÑÂïèÈ°åÔºå‰∏¶‰∏îÂèØ‰ª•Âú®‰∏çÈúÄÂæÆË™øÁöÑÊÉÖÊ≥Å‰∏ãÁî±ÂéüÂßãÁöÑÂ§ßË™ûË®ÄÊ®°Âûã (LLM) ‰ΩøÁî®„ÄÇÊúÄÂàùÔºå500xCompressor Âú® Arxiv Corpus ‰∏äÈÄ≤Ë°åÈ†êË®ìÁ∑¥ÔºåÁÑ∂ÂæåÂú® ArxivQA Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åÂæÆË™øÔºåÊúÄÂæåÂú®ÂÆåÂÖ®Êú™Ë¶ãÈÅéÂíåÁ∂ìÂÖ∏ÁöÑÂïèÈ°åËß£Á≠î (QA) Ë≥áÊñôÈõÜ‰∏äÈÄ≤Ë°åË©ï‰º∞„ÄÇÁµêÊûúË°®ÊòéÔºåËàá‰ΩøÁî®Êú™Â£ìÁ∏ÆÊèêÁ§∫Áõ∏ÊØîÔºåLLM ‰øùÁïô‰∫Ü 62.26-72.89% ÁöÑËÉΩÂäõ„ÄÇÈÄôÈ†ÖÁ†îÁ©∂ÈÇÑË°®ÊòéÔºå‰∏¶ÈùûÊâÄÊúâÂ£ìÁ∏ÆÁöÑÁ¨¶ËôüÈÉΩÂæóÂà∞Âπ≥Á≠âÂà©Áî®Ôºå‰∏¶‰∏î K V ÂÄºÂú®È´òÂ£ìÁ∏ÆÁéá‰∏ãÊØîÂµåÂÖ•ÂºèÊõ¥ÂÖ∑ÂÇô‰øùÁïôË≥áË®äÁöÑÂÑ™Âã¢„ÄÇÂç≥‰ΩøÂ∞çÊñºÁ¥∞Á∑ªË§áÈõúÁöÑË≥áË®äÔºåËá™ÁÑ∂Ë™ûË®ÄÊèêÁ§∫ÁöÑÈ´òÂ∫¶Â£ìÁ∏ÆÁâπÊÄß‰πüÈ°ØÁ§∫Âá∫Êú™‰æÜÊáâÁî®ÂíåÈÄ≤‰∏ÄÊ≠•Á†îÁ©∂ÈñãÁôºÊñ∞ÁöÑ LLM Ë™ûË®ÄÁöÑÊΩõÂäõ„ÄÇ

