# arxiv-daily
 Automated deployment @ 2024-11-22 20:36:48 Asia/Taipei
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/jawatech/arxiv-daily-in-place/blob/main/database/storage).

## AI

### Medical
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-21**|**Uterine Ultrasound Image Captioning Using Deep Learning Techniques**|Abdennour Boulesnane et.al.|[2411.14039v1](http://arxiv.org/abs/2411.14039v1)|null|
|**2024-11-21**|**Logic Augmented Generation**|Aldo Gangemi et.al.|[2411.14012v1](http://arxiv.org/abs/2411.14012v1)|null|
|**2024-11-21**|**AmpliNetECG12: A lightweight SoftMax-based relativistic amplitude amplification architecture for 12 lead ECG classification**|Shreya Srivastava et.al.|[2411.13903v1](http://arxiv.org/abs/2411.13903v1)|null|
|**2024-11-21**|**PIORS: Personalized Intelligent Outpatient Reception based on Large Language Model with Multi-Agents Medical Scenario Simulation**|Zhijie Bao et.al.|[2411.13902v1](http://arxiv.org/abs/2411.13902v1)|null|
|**2024-11-20**|**Advancing Complex Medical Communication in Arabic with Sporo AraSum: Surpassing Existing Large Language Models**|Chanseo Lee et.al.|[2411.13518v1](http://arxiv.org/abs/2411.13518v1)|null|
|**2024-11-20**|**SynEHRgy: Synthesizing Mixed-Type Structured Electronic Health Records using Decoder-Only Transformers**|Hojjat Karami et.al.|[2411.13428v1](http://arxiv.org/abs/2411.13428v1)|null|
|**2024-11-20**|**Are Large Language Models Memorizing Bug Benchmarks?**|Daniel Ramos et.al.|[2411.13323v1](http://arxiv.org/abs/2411.13323v1)|null|
|**2024-11-20**|**GraphCL: Graph-based Clustering for Semi-Supervised Medical Image Segmentation**|Mengzhu Wang et.al.|[2411.13147v1](http://arxiv.org/abs/2411.13147v1)|null|
|**2024-11-20**|**Training Physics-Driven Deep Learning Reconstruction without Raw Data Access for Equitable Fast MRI**|Yaşar Utku Alçalar et.al.|[2411.13022v1](http://arxiv.org/abs/2411.13022v1)|null|
|**2024-11-20**|**Automating Sonologists USG Commands with AI and Voice Interface**|Emad Mohamed et.al.|[2411.13006v1](http://arxiv.org/abs/2411.13006v1)|null|
|**2024-11-20**|**DrugGen: Advancing Drug Discovery with Large Language Models and Reinforcement Learning Feedback**|Mahsa Sheikholeslami et.al.|[2411.14157v1](http://arxiv.org/abs/2411.14157v1)|[link](https://huggingface.co/alimotahharynia/DrugGen)|
|**2024-11-19**|**Efficient Medicinal Image Transmission and Resolution Enhancement via GAN**|Rishabh Kumar Sharma et.al.|[2411.12833v1](http://arxiv.org/abs/2411.12833v1)|null|
|**2024-11-19**|**Conversational Medical AI: Ready for Practice**|Antoine Lizée et.al.|[2411.12808v1](http://arxiv.org/abs/2411.12808v1)|null|
|**2024-11-19**|**Enhancing Multi-Class Disease Classification: Neoplasms, Cardiovascular, Nervous System, and Digestive Disorders Using Advanced LLMs**|Ahmed Akib Jawad Karim et.al.|[2411.12712v1](http://arxiv.org/abs/2411.12712v1)|null|
|**2024-11-19**|**AI Guided Early Screening of Cervical Cancer**|Dharanidharan S I et.al.|[2411.12681v1](http://arxiv.org/abs/2411.12681v1)|null|
|**2024-11-19**|**Deep Learning-Driven Heat Map Analysis for Evaluating thickness of Wounded Skin Layers**|Devakumar GR et.al.|[2411.12678v1](http://arxiv.org/abs/2411.12678v1)|null|
|**2024-11-19**|**DiM: $f$-Divergence Minimization Guided Sharpness-Aware Optimization for Semi-supervised Medical Image Segmentation**|Bingli Wang et.al.|[2411.12350v1](http://arxiv.org/abs/2411.12350v1)|null|
|**2024-11-19**|**Can ChatGPT Overcome Behavioral Biases in the Financial Sector? Classify-and-Rethink: Multi-Step Zero-Shot Reasoning in the Gold Investment**|Shuoling Liu et.al.|[2411.13599v1](http://arxiv.org/abs/2411.13599v1)|null|
|**2024-11-19**|**Contrast Similarity-Aware Dual-Pathway Mamba for Multivariate Time Series Node Classification**|Mingsen Du et.al.|[2411.12222v1](http://arxiv.org/abs/2411.12222v1)|null|
|**2024-11-19**|**CCIS-Diff: A Generative Model with Stable Diffusion Prior for Controlled Colonoscopy Image Synthesis**|Yifan Xie et.al.|[2411.12198v1](http://arxiv.org/abs/2411.12198v1)|null|
|**2024-11-18**|**Medical Video Generation for Disease Progression Simulation**|Xu Cao et.al.|[2411.11943v1](http://arxiv.org/abs/2411.11943v1)|null|
|**2024-11-18**|**Edge-Enhanced Dilated Residual Attention Network for Multimodal Medical Image Fusion**|Meng Zhou et.al.|[2411.11799v1](http://arxiv.org/abs/2411.11799v1)|[link](https://github.com/simonzhou86/en_dran)|
|**2024-11-18**|**Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**|Jeffrey N. Clark et.al.|[2411.11774v1](http://arxiv.org/abs/2411.11774v1)|null|
|**2024-11-18**|**SP${ }^3$ : Superpixel-propagated pseudo-label learning for weakly semi-supervised medical image segmentation**|Shiman Li et.al.|[2411.11636v1](http://arxiv.org/abs/2411.11636v1)|null|
|**2024-11-18**|**HistoEncoder: a digital pathology foundation model for prostate cancer**|Joona Pohjonen et.al.|[2411.11458v1](http://arxiv.org/abs/2411.11458v1)|null|
|**2024-11-18**|**TP-UNet: Temporal Prompt Guided UNet for Medical Image Segmentation**|Ranmin Wang et.al.|[2411.11305v2](http://arxiv.org/abs/2411.11305v2)|null|
|**2024-11-18**|**Deep learning waterways for rural infrastructure development**|Matthew Pierson et.al.|[2411.13590v1](http://arxiv.org/abs/2411.13590v1)|null|
|**2024-11-18**|**Zero-Shot Automatic Annotation and Instance Segmentation using LLM-Generated Datasets: Eliminating Field Imaging and Manual Annotation for Deep Learning Model Development**|Ranjan Sapkota et.al.|[2411.11285v1](http://arxiv.org/abs/2411.11285v1)|null|
|**2024-11-18**|**Continuous K-space Recovery Network with Image Guidance for Fast MRI Reconstruction**|Yucong Meng et.al.|[2411.11282v1](http://arxiv.org/abs/2411.11282v1)|null|
|**2024-11-17**|**F$^3$OCUS -- Federated Finetuning of Vision-Language Foundation Models with Optimal Client Layer Updating Strategy via Multi-objective Meta-Heuristics**|Pramit Saha et.al.|[2411.11912v1](http://arxiv.org/abs/2411.11912v1)|null|
|**2024-11-17**|**MPLite: Multi-Aspect Pretraining for Mining Clinical Health Records**|Eric Yang et.al.|[2411.11161v1](http://arxiv.org/abs/2411.11161v1)|null|
|**2024-11-17**|**Label Sharing Incremental Learning Framework for Independent Multi-Label Segmentation Tasks**|Deepa Anand et.al.|[2411.11105v1](http://arxiv.org/abs/2411.11105v1)|null|
|**2024-11-17**|**BianCang: A Traditional Chinese Medicine Large Language Model**|Sibo Wei et.al.|[2411.11027v1](http://arxiv.org/abs/2411.11027v1)|[link](https://github.com/qlu-nlp/biancang)|
|**2024-11-16**|**MpoxVLM: A Vision-Language Model for Diagnosing Skin Lesions from Mpox Virus Infection**|Xu Cao et.al.|[2411.10888v1](http://arxiv.org/abs/2411.10888v1)|[link](https://github.com/IrohXu/MpoxVLM)|
|**2024-11-16**|**A Novel Adaptive Hybrid Focal-Entropy Loss for Enhancing Diabetic Retinopathy Detection Using Convolutional Neural Networks**|Pandiyaraju V et.al.|[2411.10843v1](http://arxiv.org/abs/2411.10843v1)|null|
|**2024-11-16**|**MRI Parameter Mapping via Gaussian Mixture VAE: Breaking the Assumption of Independent Pixels**|Moucheng Xu et.al.|[2411.10772v1](http://arxiv.org/abs/2411.10772v1)|[link](https://github.com/moucheng2017/MRI-GMM-VAE)|
|**2024-11-16**|**Integrated Machine Learning and Survival Analysis Modeling for Enhanced Chronic Kidney Disease Risk Stratification**|Zachary Dana et.al.|[2411.10754v1](http://arxiv.org/abs/2411.10754v1)|null|
|**2024-11-16**|**LTCXNet: Advancing Chest X-Ray Analysis with Solutions for Long-Tailed Multi-Label Classification and Fairness Challenges**|Chin-Wei Huang et.al.|[2411.10746v1](http://arxiv.org/abs/2411.10746v1)|null|
|**2024-11-15**|**Chain of Alignment: Integrating Public Will with Expert Intelligence for Language Model Alignment**|Andrew Konya et.al.|[2411.10534v1](http://arxiv.org/abs/2411.10534v1)|null|
|**2024-11-15**|**Deep Learning for Micro-Scale Crack Detection on Imbalanced Datasets Using Key Point Localization**|Fatahlla Moreh et.al.|[2411.10389v1](http://arxiv.org/abs/2411.10389v1)|null|
|**2024-11-15**|**Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**|Mohammed Yaseen Jabarulla et.al.|[2411.10255v1](http://arxiv.org/abs/2411.10255v1)|null|
|**2024-11-15**|**FedCL-Ensemble Learning: A Framework of Federated Continual Learning with Ensemble Transfer Learning Enhanced for Alzheimer's MRI Classifications while Preserving Privacy**|Rishit Kapoor et.al.|[2411.12756v1](http://arxiv.org/abs/2411.12756v1)|null|
|**2024-11-15**|**Evaluating the role of `Constitutions' for learning from AI feedback**|Saskia Redgate et.al.|[2411.10168v1](http://arxiv.org/abs/2411.10168v1)|null|
|**2024-11-15**|**PFML: Self-Supervised Learning of Time-Series Data Without Representation Collapse**|Einari Vaaras et.al.|[2411.10087v1](http://arxiv.org/abs/2411.10087v1)|[link](https://github.com/SPEECHCOG/PFML)|
|**2024-11-15**|**Rethinking Normalization Strategies and Convolutional Kernels for Multimodal Image Fusion**|Dan He et.al.|[2411.10036v1](http://arxiv.org/abs/2411.10036v1)|null|
|**2024-11-15**|**JRadiEvo: A Japanese Radiology Report Generation Model Enhanced by Evolutionary Optimization of Model Merging**|Kaito Baba et.al.|[2411.09933v1](http://arxiv.org/abs/2411.09933v1)|null|
|**2024-11-15**|**A Hybrid Artificial Intelligence System for Automated EEG Background Analysis and Report Generation**|Chin-Sung Tung et.al.|[2411.09874v1](http://arxiv.org/abs/2411.09874v1)|[link](https://github.com/tcs211/ai_eeeg_report)|
|**2024-11-14**|**A Benchmark for Long-Form Medical Question Answering**|Pedram Hosseini et.al.|[2411.09834v2](http://arxiv.org/abs/2411.09834v2)|null|
|**2024-11-14**|**A Self-Supervised Model for Multi-modal Stroke Risk Prediction**|Camille Delgrange et.al.|[2411.09822v1](http://arxiv.org/abs/2411.09822v1)|[link](https://github.com/CamilleDelgrange/SSMSRPM)|
|**2024-11-14**|**Deep Learning for Fetal Inflammatory Response Diagnosis in the Umbilical Cord**|Marina A. Ayad et.al.|[2411.09767v1](http://arxiv.org/abs/2411.09767v1)|null|
|**2024-11-14**|**Med-Bot: An AI-Powered Assistant to Provide Accurate and Reliable Medical Information**|Ahan Bhatt et.al.|[2411.09648v1](http://arxiv.org/abs/2411.09648v1)|null|
|**2024-11-14**|**An Explainable Attention Model for Cervical Precancer Risk Classification using Colposcopic Images**|Smith K. Khare et.al.|[2411.09469v1](http://arxiv.org/abs/2411.09469v1)|null|
|**2024-11-14**|**Script-centric behavior understanding for assisted autism spectrum disorder diagnosis**|Wenxing Liu et.al.|[2411.09413v1](http://arxiv.org/abs/2411.09413v1)|null|
|**2024-11-14**|**NFRs in Medical Imaging**|Amanda Vallentin et.al.|[2411.09718v1](http://arxiv.org/abs/2411.09718v1)|null|
|**2024-11-14**|**Comprehensive and Practical Evaluation of Retrieval-Augmented Generation Systems for Medical Question Answering**|Nghia Trung Ngo et.al.|[2411.09213v1](http://arxiv.org/abs/2411.09213v1)|null|
|**2024-11-14**|**Advancing Diffusion Models: Alias-Free Resampling and Enhanced Rotational Equivariance**|Md Fahim Anjum et.al.|[2411.09174v1](http://arxiv.org/abs/2411.09174v1)|null|
|**2024-11-14**|**Artificial Intelligence for Infectious Disease Prediction and Prevention: A Comprehensive Review**|Selestine Melchane et.al.|[2411.10486v1](http://arxiv.org/abs/2411.10486v1)|null|
|**2024-11-13**|**The Limited Impact of Medical Adaptation of Large Language and Vision-Language Models**|Daniel P. Jeong et.al.|[2411.08870v1](http://arxiv.org/abs/2411.08870v1)|null|
|**2024-11-13**|**MVKTrans: Multi-View Knowledge Transfer for Robust Multiomics Classification**|Shan Cong et.al.|[2411.08703v1](http://arxiv.org/abs/2411.08703v1)|null|
|**2024-11-13**|**TRACE: Transformer-based Risk Assessment for Clinical Evaluation**|Dionysis Christopoulos et.al.|[2411.08701v1](http://arxiv.org/abs/2411.08701v1)|null|
|**2024-11-13**|**Rethinking negative sampling in content-based news recommendation**|Miguel Ângelo Rebelo et.al.|[2411.08700v1](http://arxiv.org/abs/2411.08700v1)|null|
|**2024-11-13**|**A Survey on Vision Autoregressive Model**|Kai Jiang et.al.|[2411.08666v2](http://arxiv.org/abs/2411.08666v2)|null|
|**2024-11-13**|**Optimizing Automatic Summarization of Long Clinical Records Using Dynamic Context Extension:Testing and Evaluation of the NBCE Method**|Guoqing Zhang et.al.|[2411.08586v2](http://arxiv.org/abs/2411.08586v2)|null|
|**2024-11-13**|**A Heterogeneous Graph Neural Network Fusing Functional and Structural Connectivity for MCI Diagnosis**|Feiyu Yin et.al.|[2411.08424v1](http://arxiv.org/abs/2411.08424v1)|null|
|**2024-11-13**|**A Fuzzy Reinforcement LSTM-based Long-term Prediction Model for Fault Conditions in Nuclear Power Plants**|Siwei Li et.al.|[2411.08370v1](http://arxiv.org/abs/2411.08370v1)|null|
|**2024-11-13**|**TowerDebias: A Novel Debiasing Method based on the Tower Property**|Norman Matloff et.al.|[2411.08297v1](http://arxiv.org/abs/2411.08297v1)|null|
|**2024-11-12**|**Scaling Properties of Diffusion Models for Perceptual Tasks**|Rahul Ravishankar et.al.|[2411.08034v3](http://arxiv.org/abs/2411.08034v3)|null|
|**2024-11-12**|**Investigating the Effectiveness of Explainability Methods in Parkinson's Detection from Speech**|Eleonora Mancini et.al.|[2411.08013v2](http://arxiv.org/abs/2411.08013v2)|null|
|**2024-11-12**|**DuoLift-GAN:Reconstructing CT from Single-view and Biplanar X-Rays with Generative Adversarial Networks**|Zhaoxi Zhang et.al.|[2411.07941v1](http://arxiv.org/abs/2411.07941v1)|null|
|**2024-11-12**|**Automatic dataset shift identification to support root cause analysis of AI performance drift**|Mélanie Roschewitz et.al.|[2411.07940v2](http://arxiv.org/abs/2411.07940v2)|[link](https://github.com/biomedia-mira/shift_identification)|
|**2024-11-12**|**INTRABENCH: Interactive Radiological Benchmark**|Constantin Ulrich et.al.|[2411.07885v1](http://arxiv.org/abs/2411.07885v1)|null|
|**2024-11-12**|**Leveraging Multimodal Models for Enhanced Neuroimaging Diagnostics in Alzheimer's Disease**|Francesco Chiumento et.al.|[2411.07871v1](http://arxiv.org/abs/2411.07871v1)|null|
|**2024-11-12**|**PatchCTG: Patch Cardiotocography Transformer for Antepartum Fetal Health Monitoring**|M. Jaleed Khan et.al.|[2411.07796v1](http://arxiv.org/abs/2411.07796v1)|null|
|**2024-11-12**|**Multimodal Clinical Reasoning through Knowledge-augmented Rationale Generation**|Shuai Niu et.al.|[2411.07611v1](http://arxiv.org/abs/2411.07611v1)|null|
|**2024-11-12**|**Contrastive Language Prompting to Ease False Positives in Medical Anomaly Detection**|YeongHyeon Park et.al.|[2411.07546v1](http://arxiv.org/abs/2411.07546v1)|null|
|**2024-11-11**|**Beyond Keywords: A Context-based Hybrid Approach to Mining Ethical Concern-related App Reviews**|Aakash Sorathiya et.al.|[2411.07398v1](http://arxiv.org/abs/2411.07398v1)|null|
|**2024-11-11**|**Data-Centric Learning Framework for Real-Time Detection of Aiming Beam in Fluorescence Lifetime Imaging Guided Surgery**|Mohamed Abul Hassan et.al.|[2411.07395v1](http://arxiv.org/abs/2411.07395v1)|null|
|**2024-11-11**|**Data-Driven Analysis of AI in Medical Device Software in China: Deep Learning and General AI Trends Based on Regulatory Data**|Yu Han et.al.|[2411.07378v1](http://arxiv.org/abs/2411.07378v1)|null|
|**2024-11-11**|**A Domain-Agnostic Neurosymbolic Approach for Big Social Data Analysis: Evaluating Mental Health Sentiment on Social Media during COVID-19**|Vedant Khandelwal et.al.|[2411.07163v1](http://arxiv.org/abs/2411.07163v1)|null|
|**2024-11-11**|**Ambient AI Scribing Support: Comparing the Performance of Specialized AI Agentic Architecture to Leading Foundational Models**|Chanseo Lee et.al.|[2411.06713v1](http://arxiv.org/abs/2411.06713v1)|null|
|**2024-11-10**|**In-Context Learning for Preserving Patient Privacy: A Framework for Synthesizing Realistic Patient Portal Messages**|Joseph Gatto et.al.|[2411.06549v1](http://arxiv.org/abs/2411.06549v1)|[link](https://github.com/persist-lab/syntheticportalgen)|
|**2024-11-09**|**NeuReg: Domain-invariant 3D Image Registration on Human and Mouse Brains**|Taha Razzaq et.al.|[2411.06315v1](http://arxiv.org/abs/2411.06315v1)|null|
|**2024-11-09**|**GuidelineGuard: An Agentic Framework for Medical Note Evaluation with Guideline Adherence**|MD Ragib Shahriyear et.al.|[2411.06264v1](http://arxiv.org/abs/2411.06264v1)|null|
|**2024-11-09**|**Deep Reinforcement Learning for Digital Twin-Oriented Complex Networked Systems**|Jiaqi Wen et.al.|[2411.06148v1](http://arxiv.org/abs/2411.06148v1)|null|
|**2024-11-09**|**Evaluating the Propensity of Generative AI for Producing Disinformation During an Election Cycle**|Erik J Schlicht et.al.|[2411.06120v1](http://arxiv.org/abs/2411.06120v1)|null|
|**2024-11-09**|**Personalize to generalize: Towards a universal medical multi-modality generalization through personalization**|Zhaorui Tan et.al.|[2411.06106v2](http://arxiv.org/abs/2411.06106v2)|null|
|**2024-11-08**|**Assessing Foundational Medical 'Segment Anything' (Med-SAM1, Med-SAM2) Deep Learning Models for Left Atrial Segmentation in 3D LGE MRI**|Mehri Mehrnia et.al.|[2411.05963v1](http://arxiv.org/abs/2411.05963v1)|null|
|**2024-11-08**|**GazeSearch: Radiology Findings Search Benchmark**|Trong Thang Pham et.al.|[2411.05780v1](http://arxiv.org/abs/2411.05780v1)|null|
|**2024-11-08**|**Humans Continue to Outperform Large Language Models in Complex Clinical Decision-Making: A Study with Medical Calculators**|Nicholas Wan et.al.|[2411.05897v1](http://arxiv.org/abs/2411.05897v1)|null|
|**2024-11-08**|**Identifying and Decomposing Compound Ingredients in Meal Plans Using Large Language Models**|Leon Kopitar et.al.|[2411.05892v1](http://arxiv.org/abs/2411.05892v1)|null|
|**2024-11-08**|**SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark**|Sithursan Sivasubramaniam et.al.|[2411.05521v2](http://arxiv.org/abs/2411.05521v2)|[link](https://github.com/jf87/sm3-text-to-query)|
|**2024-11-08**|**Towards Scalable Foundation Models for Digital Dermatology**|Fabian Gröger et.al.|[2411.05514v1](http://arxiv.org/abs/2411.05514v1)|[link](https://github.com/digital-dermatology/self-supervised-dermatology)|
|**2024-11-08**|**Towards Equitable ASD Diagnostics: A Comparative Study of Machine and Deep Learning Models Using Behavioral and Facial Data**|Mohammed Aledhari et.al.|[2411.05880v1](http://arxiv.org/abs/2411.05880v1)|null|
|**2024-11-07**|**Interactive Dialogue Agents via Reinforcement Learning on Hindsight Regenerations**|Joey Hong et.al.|[2411.05194v1](http://arxiv.org/abs/2411.05194v1)|null|
|**2024-11-07**|**Inverse Transition Learning: Learning Dynamics from Demonstrations**|Leo Benac et.al.|[2411.05174v1](http://arxiv.org/abs/2411.05174v1)|null|
|**2024-11-07**|**PadChest-GR: A Bilingual Chest X-ray Dataset for Grounded Radiology Report Generation**|Daniel C. Castro et.al.|[2411.05085v1](http://arxiv.org/abs/2411.05085v1)|null|
|**2024-11-07**|**Position Paper On Diagnostic Uncertainty Estimation from Large Language Models: Next-Word Probability Is Not Pre-test Probability**|Yanjun Gao et.al.|[2411.04962v1](http://arxiv.org/abs/2411.04962v1)|null|
|**2024-11-07**|**FineTuneBench: How well do commercial fine-tuning APIs infuse knowledge into LLMs?**|Eric Wu et.al.|[2411.05059v2](http://arxiv.org/abs/2411.05059v2)|[link](https://github.com/kevinwu23/stanfordfinetunebench)|
|**2024-11-07**|**Green My LLM: Studying the key factors affecting the energy consumption of code assistants**|Tristan Coignion et.al.|[2411.11892v1](http://arxiv.org/abs/2411.11892v1)|null|
|**2024-11-07**|**Integrating Large Language Models for Genetic Variant Classification**|Youssef Boulaimen et.al.|[2411.05055v1](http://arxiv.org/abs/2411.05055v1)|null|

#### Abstracts
##### **Uterine Ultrasound Image Captioning Using Deep Learning Techniques**
2411.14039v1 by Abdennour Boulesnane, Boutheina Mokhtari, Oumnia Rana Segueni, Slimane Segueni

Medical imaging has significantly revolutionized medical diagnostics and
treatment planning, progressing from early X-ray usage to sophisticated methods
like MRIs, CT scans, and ultrasounds. This paper investigates the use of deep
learning for medical image captioning, with a particular focus on uterine
ultrasound images. These images are vital in obstetrics and gynecology for
diagnosing and monitoring various conditions across different age groups.
However, their interpretation is often challenging due to their complexity and
variability. To address this, a deep learning-based medical image captioning
system was developed, integrating Convolutional Neural Networks with a
Bidirectional Gated Recurrent Unit network. This hybrid model processes both
image and text features to generate descriptive captions for uterine ultrasound
images. Our experimental results demonstrate the effectiveness of this approach
over baseline methods, with the proposed model achieving superior performance
in generating accurate and informative captions, as indicated by higher BLEU
and ROUGE scores. By enhancing the interpretation of uterine ultrasound images,
our research aims to assist medical professionals in making timely and accurate
diagnoses, ultimately contributing to improved patient care.

摘要：醫學影像大幅革新了醫療診斷和治療計畫，從早期的 X 光使用進展到 MRI、電腦斷層掃描和超音波等精密方法。這篇論文探討深度學習在醫學影像標題中的應用，特別著重於子宮超音波影像。這些影像在婦產科中對於診斷和追蹤不同年齡層的各種疾病至關重要。然而，由於其複雜性和變異性，它們的詮釋通常具有挑戰性。為了解決這個問題，開發了一個基於深度學習的醫學影像標題系統，將卷積神經網路與雙向門控循環單元網路整合在一起。這個混合模型處理影像和文字特徵，為子宮超音波影像產生描述性標題。我們的實驗結果證明了此方法優於基線方法的有效性，所提出的模型在產生準確且有意義的標題方面達到了卓越的效能，這由較高的 BLEU 和 ROUGE 分數所證明。透過增強子宮超音波影像的詮釋，我們的研究旨在協助醫療專業人員進行及時且準確的診斷，最終有助於改善病患照護。

##### **Logic Augmented Generation**
2411.14012v1 by Aldo Gangemi, Andrea Giovanni Nuzzolese

Semantic Knowledge Graphs (SKG) face challenges with scalability,
flexibility, contextual understanding, and handling unstructured or ambiguous
information. However, they offer formal and structured knowledge enabling
highly interpretable and reliable results by means of reasoning and querying.
Large Language Models (LLMs) overcome those limitations making them suitable in
open-ended tasks and unstructured environments. Nevertheless, LLMs are neither
interpretable nor reliable. To solve the dichotomy between LLMs and SKGs we
envision Logic Augmented Generation (LAG) that combines the benefits of the two
worlds. LAG uses LLMs as Reactive Continuous Knowledge Graphs that can generate
potentially infinite relations and tacit knowledge on-demand. SKGs are key for
injecting a discrete heuristic dimension with clear logical and factual
boundaries. We exemplify LAG in two tasks of collective intelligence, i.e.,
medical diagnostics and climate projections. Understanding the properties and
limitations of LAG, which are still mostly unknown, is of utmost importance for
enabling a variety of tasks involving tacit knowledge in order to provide
interpretable and effective results.

摘要：語意知識圖 (SKG) 面臨可擴充性、彈性、脈絡理解和處理非結構化或模稜兩可資訊的挑戰。然而，它們提供正式且結構化的知識，藉由推理和查詢提供高度可解釋且可靠的結果。大型語言模型 (LLM) 克服了這些限制，使其適用於開放式任務和非結構化環境。儘管如此，LLM 既不可解釋也不可靠。為了解決 LLM 和 SKG 之間的二分法，我們設想結合兩者優點的邏輯增強生成 (LAG)。LAG 使用 LLM 作為反應式連續知識圖，可以根據需要產生潛在的無限關係和默會知識。SKG 是注入具有明確邏輯和事實邊界的離散啟發式維度的關鍵。我們在集體智慧的兩個任務中舉例說明 LAG，即醫療診斷和氣候預測。了解 LAG 的特性和限制（目前仍大多未知）對於啟用涉及默會知識的各種任務以提供可解釋且有效的結果至關重要。

##### **AmpliNetECG12: A lightweight SoftMax-based relativistic amplitude amplification architecture for 12 lead ECG classification**
2411.13903v1 by Shreya Srivastava

The urgent need to promptly detect cardiac disorders from 12-lead
Electrocardiograms using limited computations is motivated by the heart's fast
and complex electrical activity and restricted computational power of portable
devices. Timely and precise diagnoses are crucial since delays might
significantly impact patient health outcomes. This research presents a novel
deep-learning architecture that aims to diagnose heart abnormalities quickly
and accurately. We devised a new activation function called aSoftMax, designed
to improve the visibility of ECG deflections. The proposed activation function
is used with Convolutional Neural Network architecture to includes kernel
weight sharing across the ECG's various leads. This innovative method
thoroughly generalizes the global 12-lead ECG features and minimizes the
model's complexity by decreasing the trainable parameters. aSoftMax, combined
with enhanced CNN architecture yielded AmpliNetECG12, we obtain exceptional
accuracy of 84% in diagnosing cardiac disorders. AmpliNetECG12 shows
outstanding prediction ability when used with the CPSC2018 dataset for
arrhythmia classification. The model attains an F1-score of 80.71% and a
ROC-AUC score of 96.00%, with 280,000 trainable parameters which signifies the
lightweight yet efficient nature of AmpliNetECG12. The stochastic
characteristics of aSoftMax, a fundamental element of AmpliNetECG12, improve
prediction accuracy and also increasse the model's interpretability. This
feature enhances comprehension of important ECG segments in different forms of
arrhythmias, establishing a new standard of explainable architecture for
cardiac disorder classification.

摘要：<paragraph>由於心臟的快速且複雜的電氣活動和攜帶式裝置受限的運算能力，因此迫切需要使用 12 導程心電圖來快速偵測心臟疾病。及時且精確的診斷至關重要，因為延誤可能會對患者的健康狀況產生重大影響。本研究提出了一種新穎的深度學習架構，旨在快速且準確地診斷心臟異常。我們設計了一個稱為 aSoftMax 的新激活函數，旨在提高心電圖偏轉的可見度。所提出的激活函數與卷積神經網路架構一起使用，以在心電圖的各種導程之間包含核權重共享。這種創新方法徹底概括了全球 12 導程心電圖特徵，並通過減少可訓練參數來最小化模型的複雜性。aSoftMax 結合增強的 CNN 架構產生了 AmpliNetECG12，我們在診斷心臟疾病方面獲得了 84% 的出色準確度。AmpliNetECG12 在與 CPSC2018 資料集一起用於心律不整分類時顯示出出色的預測能力。該模型以 280,000 個可訓練參數獲得 80.71% 的 F1 分數和 96.00% 的 ROC-AUC 分數，這表明 AmpliNetECG12 的輕量級且高效的本質。aSoftMax 的隨機特徵是 AmpliNetECG12 的基本要素，它提高了預測準確度，也增加了模型的可解釋性。此功能增強了對不同形式心律不整中重要心電圖區段的理解，為心臟疾病分類建立了一個新的可解釋架構標準。</paragraph>

##### **PIORS: Personalized Intelligent Outpatient Reception based on Large Language Model with Multi-Agents Medical Scenario Simulation**
2411.13902v1 by Zhijie Bao, Qingyun Liu, Ying Guo, Zhengqiang Ye, Jun Shen, Shirong Xie, Jiajie Peng, Xuanjing Huang, Zhongyu Wei

In China, receptionist nurses face overwhelming workloads in outpatient
settings, limiting their time and attention for each patient and ultimately
reducing service quality. In this paper, we present the Personalized
Intelligent Outpatient Reception System (PIORS). This system integrates an
LLM-based reception nurse and a collaboration between LLM and hospital
information system (HIS) into real outpatient reception setting, aiming to
deliver personalized, high-quality, and efficient reception services.
Additionally, to enhance the performance of LLMs in real-world healthcare
scenarios, we propose a medical conversational data generation framework named
Service Flow aware Medical Scenario Simulation (SFMSS), aiming to adapt the LLM
to the real-world environments and PIORS settings. We evaluate the
effectiveness of PIORS and SFMSS through automatic and human assessments
involving 15 users and 15 clinical experts. The results demonstrate that
PIORS-Nurse outperforms all baselines, including the current state-of-the-art
model GPT-4o, and aligns with human preferences and clinical needs. Further
details and demo can be found at https://github.com/FudanDISC/PIORS

摘要：<paragraph>在中国，接待护士在门诊环境中面临着繁重的工作量，限制了他们对每位患者的时间和注意力，最终降低了服务质量。在本文中，我们提出了个性化智能门诊接待系统 (PIORS)。该系统将基于 LLM 的接待护士和 LLM 与医院信息系统 (HIS) 之间的协作整合到真实的门诊接待环境中，旨在提供个性化、高质量和高效的接待服务。此外，为了提高 LLM 在真实医疗保健场景中的性能，我们提出了一个名为服务流感知医疗场景模拟 (SFMSS) 的医疗会话数据生成框架，旨在使 LLM 适应真实世界环境和 PIORS 设置。我们通过涉及 15 名用户和 15 名临床专家的自动和人工评估来评估 PIORS 和 SFMSS 的有效性。结果表明，PIORS-Nurse 优于所有基线，包括当前最先进的模型 GPT-4o，并且符合人类偏好和临床需求。更多详细信息和演示可在 https://github.com/FudanDISC/PIORS 中找到</paragraph>

##### **Advancing Complex Medical Communication in Arabic with Sporo AraSum: Surpassing Existing Large Language Models**
2411.13518v1 by Chanseo Lee, Sonu Kumar, Kimon A. Vogt, Sam Meraj, Antonia Vogt

The increasing demand for multilingual capabilities in healthcare underscores
the need for AI models adept at processing diverse languages, particularly in
clinical documentation and decision-making. Arabic, with its complex
morphology, syntax, and diglossia, poses unique challenges for natural language
processing (NLP) in medical contexts. This case study evaluates Sporo AraSum, a
language model tailored for Arabic clinical documentation, against JAIS, the
leading Arabic NLP model. Using synthetic datasets and modified PDQI-9 metrics
modified ourselves for the purposes of assessing model performances in a
different language. The study assessed the models' performance in summarizing
patient-physician interactions, focusing on accuracy, comprehensiveness,
clinical utility, and linguistic-cultural competence.
  Results indicate that Sporo AraSum significantly outperforms JAIS in
AI-centric quantitative metrics and all qualitative attributes measured in our
modified version of the PDQI-9. AraSum's architecture enables precise and
culturally sensitive documentation, addressing the linguistic nuances of Arabic
while mitigating risks of AI hallucinations. These findings suggest that Sporo
AraSum is better suited to meet the demands of Arabic-speaking healthcare
environments, offering a transformative solution for multilingual clinical
workflows. Future research should incorporate real-world data to further
validate these findings and explore broader integration into healthcare
systems.

摘要：醫療保健領域對多語言能力的需求日益增加，這凸顯了對善於處理各種語言的 AI 模型的需求，特別是在臨床文件和決策制定中。阿拉伯語具有複雜的形態、語法和雙語現象，這對醫療環境中的自然語言處理 (NLP) 構成了獨特的挑戰。本案例研究評估了 Sporo AraSum（一種專為阿拉伯語臨床文件量身打造的語言模型）和阿拉伯語 NLP 模型的領導者 JAIS。我們使用合成資料集和修改後的 PDQI-9 指標（我們自行修改，以評估模型在不同語言中的表現）。本研究評估了模型在總結患者與醫師互動時的表現，重點在於準確性、全面性、臨床效用和語言文化能力。
結果表明，在以 AI 為中心的定量指標和我們修改後的 PDQI-9 版本中測量的所有定性屬性中，Sporo AraSum 明顯優於 JAIS。AraSum 的架構能產生精確且具有文化敏感度的文件，它能處理阿拉伯語的語言差異，同時降低 AI 產生幻覺的風險。這些發現表明，Sporo AraSum 更適合滿足講阿拉伯語的醫療保健環境的需求，為多語言臨床工作流程提供了一個變革性的解決方案。未來的研究應納入真實世界的資料，以進一步驗證這些發現，並探索更廣泛地整合到醫療保健系統中。

##### **SynEHRgy: Synthesizing Mixed-Type Structured Electronic Health Records using Decoder-Only Transformers**
2411.13428v1 by Hojjat Karami, David Atienza, Anisoara Ionescu

Generating synthetic Electronic Health Records (EHRs) offers significant
potential for data augmentation, privacy-preserving data sharing, and improving
machine learning model training. We propose a novel tokenization strategy
tailored for structured EHR data, which encompasses diverse data types such as
covariates, ICD codes, and irregularly sampled time series. Using a GPT-like
decoder-only transformer model, we demonstrate the generation of high-quality
synthetic EHRs. Our approach is evaluated using the MIMIC-III dataset, and we
benchmark the fidelity, utility, and privacy of the generated data against
state-of-the-art models.

摘要：生成合成電子病歷 (EHR) 提供了顯著的數據擴充、隱私保護數據共享以及改進機器學習模型訓練的潛力。我們提出了一種針對結構化電子病歷數據量身打造的新型標記化策略，它包含了各種數據類型，例如協變量、ICD 代碼和不規則採樣的時序。使用類似 GPT 的僅解碼器Transformer模型，我們展示了高品質合成電子病歷的生成。我們的做法使用 MIMIC-III 數據集進行評估，我們根據最先進的模型對生成數據的保真度、實用性和隱私性進行基準測試。

##### **Are Large Language Models Memorizing Bug Benchmarks?**
2411.13323v1 by Daniel Ramos, Claudia Mamede, Kush Jain, Paulo Canelas, Catarina Gamboa, Claire Le Goues

Large Language Models (LLMs) have become integral to various software
engineering tasks, including code generation, bug detection, and repair. To
evaluate model performance in these domains, numerous bug benchmarks containing
real-world bugs from software projects have been developed. However, a growing
concern within the software engineering community is that these benchmarks may
not reliably reflect true LLM performance due to the risk of data leakage.
Despite this concern, limited research has been conducted to quantify the
impact of potential leakage.
  In this paper, we systematically evaluate popular LLMs to assess their
susceptibility to data leakage from widely used bug benchmarks. To identify
potential leakage, we use multiple metrics, including a study of benchmark
membership within commonly used training datasets, as well as analyses of
negative log-likelihood and n-gram accuracy. Our findings show that certain
models, in particular codegen-multi, exhibit significant evidence of
memorization in widely used benchmarks like Defects4J, while newer models
trained on larger datasets like LLaMa 3.1 exhibit limited signs of leakage.
These results highlight the need for careful benchmark selection and the
adoption of robust metrics to adequately assess models capabilities.

摘要：大型語言模型 (LLM) 已成為各種軟體工程任務中不可或缺的一部分，包括程式碼產生、錯誤偵測和修復。為了評估這些領域中的模型效能，已開發出許多包含軟體專案中真實錯誤的錯誤基準測試。然而，軟體工程社群中日益關注的是，由於資料外洩的風險，這些基準測試可能無法可靠地反映真正的 LLM 效能。儘管有此疑慮，但針對量化潛在外洩影響的研究卻十分有限。
在本文中，我們系統性地評估熱門 LLM，以評估它們對廣泛使用的錯誤基準測試中資料外洩的敏感性。為了識別潛在的外洩，我們使用多種指標，包括研究基準測試成員資格在常用的訓練資料集中的情況，以及對負對數似然和 n-gram 精確度的分析。我們的研究結果顯示，某些模型，特別是 codegen-multi，在 Defects4J 等廣泛使用的基準測試中展現出顯著的記憶證據，而訓練於較大型資料集（例如 LLaMa 3.1）的較新模型則展現出有限的外洩跡象。這些結果突顯了仔細選擇基準測試和採用穩健指標以充分評估模型功能的必要性。

##### **GraphCL: Graph-based Clustering for Semi-Supervised Medical Image Segmentation**
2411.13147v1 by Mengzhu Wang, Jiao Li, Houcheng Su, Nan Yin, Shen Li

Semi-supervised learning (SSL) has made notable advancements in medical image
segmentation (MIS), particularly in scenarios with limited labeled data and
significantly enhancing data utilization efficiency. Previous methods primarily
focus on complex training strategies to utilize unlabeled data but neglect the
importance of graph structural information. Different from existing methods, we
propose a graph-based clustering for semi-supervised medical image segmentation
(GraphCL) by jointly modeling graph data structure in a unified deep model. The
proposed GraphCL model enjoys several advantages. Firstly, to the best of our
knowledge, this is the first work to model the data structure information for
semi-supervised medical image segmentation (SSMIS). Secondly, to get the
clustered features across different graphs, we integrate both pairwise
affinities between local image features and raw features as inputs. Extensive
experimental results on three standard benchmarks show that the proposed
GraphCL algorithm outperforms state-of-the-art semi-supervised medical image
segmentation methods.

摘要：半监督学习（SSL）在医学影像分割（MIS）中取得了显着进展，特别是在标注数据有限且显著提高数据利用效率的场景中。以前的方法主要集中在复杂的训练策略上以利用未标注的数据，但忽略了图结构信息的重要性。与现有方法不同，我们提出了一种基于图的聚类方法用于半监督医学影像分割（GraphCL），通过在统一的深度模型中联合建模图数据结构。所提出的 GraphCL 模型具有以下几个优点。首先，据我们所知，这是第一个为半监督医学影像分割（SSMIS）建模数据结构信息的模型。其次，为了获得不同图中聚类的特征，我们将局部图像特征和原始特征之间的成对相似性作为输入进行整合。在三个标准基准上的大量实验结果表明，所提出的 GraphCL 算法优于最先进的半监督医学影像分割方法。

##### **Training Physics-Driven Deep Learning Reconstruction without Raw Data Access for Equitable Fast MRI**
2411.13022v1 by Yaşar Utku Alçalar, Merve Gülle, Mehmet Akçakaya

Physics-driven deep learning (PD-DL) approaches have become popular for
improved reconstruction of fast magnetic resonance imaging (MRI) scans. Even
though PD-DL offers higher acceleration rates compared to existing clinical
fast MRI techniques, their use has been limited outside specialized MRI
centers. One impediment for their deployment is the difficulties with
generalization to pathologies or population groups that are not
well-represented in training sets. This has been noted in several studies, and
fine-tuning on target populations to improve reconstruction has been suggested.
However, current approaches for PD-DL training require access to raw k-space
measurements, which is typically only available at specialized MRI centers that
have research agreements for such data access. This is especially an issue for
rural and underserved areas, where commercial MRI scanners only provide access
to a final reconstructed image. To tackle these challenges, we propose
Compressibility-inspired Unsupervised Learning via Parallel Imaging Fidelity
(CUPID) for high-quality PD-DL training, using only routine clinical
reconstructed images exported from an MRI scanner. CUPID evaluates the goodness
of the output with a compressibility-based approach, while ensuring that the
output stays consistent with the clinical parallel imaging reconstruction
through well-designed perturbations. Our results show that CUPID achieves
similar quality compared to well-established PD-DL training strategies that
require raw k-space data access, while outperforming conventional compressed
sensing (CS) and state-of-the-art generative methods. We also demonstrate its
effectiveness in a zero-shot training setup for retrospectively and
prospectively sub-sampled acquisitions, attesting to its minimal training
burden.

摘要：<paragraph>物理驅動深度學習 (PD-DL) 方法已廣受歡迎，用於改善快速磁振造影 (MRI) 掃描的重建。儘管與現有的臨床快速 MRI 技術相比，PD-DL 提供了更高的加速率，但其使用已被限制在專門的 MRI 中心之外。部署它們的一個障礙是難以推廣到訓練集中未充分呈現的病理或人群。這已在多項研究中註明，並且建議對目標人群進行微調以改善重建。然而，當前 PD-DL 訓練方法需要存取原始 k-space 量測，而這通常僅在具有此類資料存取研究協議的專門 MRI 中心才可取得。這對於鄉村和服務不足的地區來說尤其成問題，因為商業 MRI 掃描儀僅提供存取最終重建影像。為了應對這些挑戰，我們提出透過平行影像保真度 (CUPID) 進行受壓縮性啟發的非監督式學習，僅使用從 MRI 掃描儀輸出的例行臨床重建影像，以進行高品質 PD-DL 訓練。CUPID 使用基於壓縮性的方法評估輸出的優劣，同時確保輸出透過精心設計的擾動與臨床平行影像重建保持一致。我們的結果顯示，與需要原始 k-space 資料存取的完善 PD-DL 訓練策略相比，CUPID 達到了類似的品質，同時優於傳統的壓縮感測 (CS) 和最先進的生成方法。我們還展示了它在零次學習設定中對回溯性和前瞻性子抽樣擷取的有效性，證明了它的訓練負擔很小。</paragraph>

##### **Automating Sonologists USG Commands with AI and Voice Interface**
2411.13006v1 by Emad Mohamed, Shruti Tiwari, Sheena Christabel Pravin

This research presents an advanced AI-powered ultrasound imaging system that
incorporates real-time image processing, organ tracking, and voice commands to
enhance the efficiency and accuracy of diagnoses in clinical practice.
Traditional ultrasound diagnostics often require significant time and introduce
a degree of subjectivity due to user interaction. The goal of this innovative
solution is to provide Sonologists with a more predictable and productive
imaging procedure utilizing artificial intelligence, computer vision, and voice
technology. The functionality of the system employs computer vision and deep
learning algorithms, specifically adopting the Mask R-CNN model from Detectron2
for semantic segmentation of organs and key landmarks. This automation improves
diagnostic accuracy by enabling the extraction of valuable information with
minimal human input. Additionally, it includes a voice recognition feature that
allows for hands-free operation, enabling users to control the system with
commands such as freeze or liver, all while maintaining their focus on the
patient. The architecture comprises video processing and real-time segmentation
modules that prepare the system to perform essential imaging functions, such as
freezing and zooming in on frames. The liver histopathology module, optimized
for detecting fibrosis, achieved an impressive accuracy of 98.6%. Furthermore,
the organ segmentation module produces output confidence levels between 50% and
95%, demonstrating its efficacy in organ detection.

摘要：本研究提出了一個進階的人工智慧超音波影像系統，它結合了即時影像處理、器官追蹤和語音指令，以增強臨床實務中診斷的效率和準確性。傳統的超音波診斷通常需要大量的時間，並由於使用者的互動而引入了一定的主觀性。這個創新解決方案的目標是為超音波檢查醫師提供一個更可預測且更具生產力的影像程序，利用人工智慧、電腦視覺和語音技術。該系統的功能採用電腦視覺和深度學習演算法，特別是採用 Detectron2 中的 Mask R-CNN 模型來進行器官和關鍵地標的語意分割。此自動化透過以最少的人工輸入提取有價值的資訊來提高診斷準確性。此外，它還包括一個語音辨識功能，允許免持操作，使用戶能夠使用凍結或肝臟等指令來控制系統，同時將注意力集中在患者身上。架構包含視訊處理和即時分割模組，準備系統執行必要的影像功能，例如凍結和縮放畫面。針對纖維化偵測而最佳化的肝臟組織病理學模組，達到了令人印象深刻的 98.6% 準確度。此外，器官分割模組產生的輸出信心水準在 50% 到 95% 之間，證明了其在器官偵測中的效能。

##### **DrugGen: Advancing Drug Discovery with Large Language Models and Reinforcement Learning Feedback**
2411.14157v1 by Mahsa Sheikholeslami, Navid Mazrouei, Yousof Gheisari, Afshin Fasihi, Matin Irajpour, Ali Motahharynia

Traditional drug design faces significant challenges due to inherent chemical
and biological complexities, often resulting in high failure rates in clinical
trials. Deep learning advancements, particularly generative models, offer
potential solutions to these challenges. One promising algorithm is DrugGPT, a
transformer-based model, that generates small molecules for input protein
sequences. Although promising, it generates both chemically valid and invalid
structures and does not incorporate the features of approved drugs, resulting
in time-consuming and inefficient drug discovery. To address these issues, we
introduce DrugGen, an enhanced model based on the DrugGPT structure. DrugGen is
fine-tuned on approved drug-target interactions and optimized with proximal
policy optimization. By giving reward feedback from protein-ligand binding
affinity prediction using pre-trained transformers (PLAPT) and a customized
invalid structure assessor, DrugGen significantly improves performance.
Evaluation across multiple targets demonstrated that DrugGen achieves 100%
valid structure generation compared to 95.5% with DrugGPT and produced
molecules with higher predicted binding affinities (7.22 [6.30-8.07]) compared
to DrugGPT (5.81 [4.97-6.63]) while maintaining diversity and novelty. Docking
simulations further validate its ability to generate molecules targeting
binding sites effectively. For example, in the case of fatty acid-binding
protein 5 (FABP5), DrugGen generated molecules with superior docking scores
(FABP5/11, -9.537 and FABP5/5, -8.399) compared to the reference molecule
(Palmitic acid, -6.177). Beyond lead compound generation, DrugGen also shows
potential for drug repositioning and creating novel pharmacophores for existing
targets. By producing high-quality small molecules, DrugGen provides a
high-performance medium for advancing pharmaceutical research and drug
discovery.

摘要：傳統藥物設計因其化學和生物複雜性而面臨重大挑戰，這通常會導致臨床試驗的高失敗率。深度學習的進展，特別是生成模型，為這些挑戰提供了潛在的解決方案。一種有前途的演算法是 DrugGPT，這是一種基於轉換器的模型，它為輸入蛋白質序列生成小分子。儘管有前景，但它既產生化學有效結構，也產生無效結構，並且不包含已核准藥物的特徵，導致耗時且低效的藥物發現。為了解決這些問題，我們引入了 DrugGen，這是一種基於 DrugGPT 結構的增強模型。DrugGen 在已核准的藥物目標交互作用上進行微調，並使用近端策略最佳化進行最佳化。通過使用預先訓練的轉換器 (PLAPT) 和自訂無效結構評估器，從蛋白質配體結合親和力預測中提供獎勵回饋，DrugGen 大幅提升了效能。多個目標的評估顯示，與 DrugGPT 的 95.5% 相比，DrugGen 達到了 100% 的有效結構生成，並且產生了預測結合親和力較高的分子 (7.22 [6.30-8.07])，而 DrugGPT 為 (5.81 [4.97-6.63])，同時保持了多樣性和新穎性。對接模擬進一步驗證了其有效生成分子以針對結合位點的能力。例如，在脂肪酸結合蛋白 5 (FABP5) 的情況下，與參考分子（棕櫚酸，-6.177）相比，DrugGen 生成了對接評分較高的分子 (FABP5/11，-9.537 和 FABP5/5，-8.399)。除了先導化合物生成之外，DrugGen 還顯示了藥物重新定位和為現有目標建立新型藥效團的潛力。通過產生高品質的小分子，DrugGen 為推進製藥研究和藥物發現提供了一個高性能的媒介。

##### **Efficient Medicinal Image Transmission and Resolution Enhancement via GAN**
2411.12833v1 by Rishabh Kumar Sharma, Mukund Sharma, Pushkar Sharma, Jeetashree Aparjeeta

While X-ray imaging is indispensable in medical diagnostics, it inherently
carries with it those noises and limitations on resolution that mask the
details necessary for diagnosis. B/W X-ray images require a careful balance
between noise suppression and high-detail preservation to ensure clarity in
soft-tissue structures and bone edges. While traditional methods, such as CNNs
and early super-resolution models like ESRGAN, have enhanced image resolution,
they often perform poorly regarding high-frequency detail preservation and
noise control for B/W imaging. We are going to present one efficient approach
that improves the quality of an image with the optimization of network
transmission in the following paper. The pre-processing of X-ray images into
low-resolution files by Real-ESRGAN, a version of ESRGAN elucidated and
improved, helps reduce the server load and transmission bandwidth.
Lower-resolution images are upscaled at the receiving end using Real-ESRGAN,
fine-tuned for real-world image degradation. The model integrates
Residual-in-Residual Dense Blocks with perceptual and adversarial loss
functions for high-quality upscaled images with low noise. We further fine-tune
Real-ESRGAN by adapting it to the specific B/W noise and contrast
characteristics. This suppresses noise artifacts without compromising detail.
The comparative evaluation conducted shows that our approach achieves superior
noise reduction and detail clarity compared to state-of-the-art CNN-based and
ESRGAN models, apart from reducing network bandwidth requirements. These
benefits are confirmed both by quantitative metrics, including Peak
Signal-to-Noise Ratio and Structural Similarity Index, and by qualitative
assessments, which indicate the potential of Real-ESRGAN for diagnostic-quality
X-ray imaging and for efficient medical data transmission.

摘要：儘管 X 光影像在醫療診斷中不可或缺，但它本身就帶有那些會遮蔽診斷所需細節的雜訊和解析度限制。黑白 X 光影像需要在雜訊抑制和高細節保留之間取得仔細的平衡，以確保軟組織結構和骨骼邊緣的清晰度。儘管 CNN 和 ESRGAN 等傳統方法和早期超解析度模型已增強影像解析度，但它們在高頻率細節保留和黑白影像的雜訊控制方面通常表現不佳。我們將在以下論文中提出一種有效的方法，該方法透過最佳化網路傳輸來提升影像品質。將 X 光影像預處理成低解析度檔案，透過經過闡明和改良的 ESRGAN 版本 Real-ESRGAN，有助於降低伺服器負載和傳輸頻寬。低解析度影像在接收端使用針對真實世界影像劣化進行微調的 Real-ESRGAN 升級。該模型整合了殘差中殘差密集區塊與感知和對抗損失函數，以產生雜訊低的高品質升級影像。我們進一步微調 Real-ESRGAN，使其適應特定黑白雜訊和對比特徵。這抑制了雜訊偽影，同時不影響細節。進行的比較評估顯示，除了降低網路頻寬需求外，我們的做法在雜訊降低和細節清晰度方面都優於最先進的基於 CNN 和 ESRGAN 的模型。這些優點已透過定量指標（包括峰值信噪比和結構相似性指標）和定性評估得到證實，這表明 Real-ESRGAN 具有診斷品質 X 光影像和有效醫療資料傳輸的潛力。

##### **Conversational Medical AI: Ready for Practice**
2411.12808v1 by Antoine Lizée, Pierre-Auguste Beaucoté, James Whitbeck, Marion Doumeingts, Anaël Beaugnon, Isabelle Feldhaus

The shortage of doctors is creating a critical squeeze in access to medical
expertise. While conversational Artificial Intelligence (AI) holds promise in
addressing this problem, its safe deployment in patient-facing roles remains
largely unexplored in real-world medical settings. We present the first
large-scale evaluation of a physician-supervised LLM-based conversational agent
in a real-world medical setting.
  Our agent, Mo, was integrated into an existing medical advice chat service.
Over a three-week period, we conducted a randomized controlled experiment with
926 cases to evaluate patient experience and satisfaction. Among these, Mo
handled 298 complete patient interactions, for which we report
physician-assessed measures of safety and medical accuracy.
  Patients reported higher clarity of information (3.73 vs 3.62 out of 4, p <
0.05) and overall satisfaction (4.58 vs 4.42 out of 5, p < 0.05) with
AI-assisted conversations compared to standard care, while showing equivalent
levels of trust and perceived empathy. The high opt-in rate (81% among
respondents) exceeded previous benchmarks for AI acceptance in healthcare.
Physician oversight ensured safety, with 95% of conversations rated as "good"
or "excellent" by general practitioners experienced in operating a medical
advice chat service.
  Our findings demonstrate that carefully implemented AI medical assistants can
enhance patient experience while maintaining safety standards through physician
supervision. This work provides empirical evidence for the feasibility of AI
deployment in healthcare communication and insights into the requirements for
successful integration into existing healthcare services.

摘要：<paragraph>醫生短缺正在造成取得醫療專業知識的嚴重擠壓。儘管對話式人工智慧 (AI) 有望解決此問題，但在現實世界的醫療環境中，其在面對患者的角色中的安全部署仍未得到充分探討。我們提出在現實世界的醫療環境中，對基於 LLM 的醫師監督對話代理進行首次大規模評估。
我們的代理 Mo 已整合到現有的醫療諮詢聊天服務中。在三週的時間裡，我們進行了一項隨機對照實驗，包含 926 個案例，以評估患者體驗和滿意度。其中，Mo 處理了 298 次完整的患者互動，我們報告了醫師評估的安全性和醫療準確性指標。
與標準照護相比，患者報告了更高的資訊清晰度（4 分中的 3.73 對 3.62，p < 0.05）和整體滿意度（5 分中的 4.58 對 4.42，p < 0.05），同時顯示出同等的信任度和同理心。高選擇參與率（受訪者中為 81%）超過了醫療保健中 AI 接受度的先前基準。醫師監督確保了安全性，95% 的對話被經驗豐富的醫療諮詢聊天服務操作員評為「良好」或「極佳」。
我們的研究結果表明，仔細實施的 AI 醫療助理可以在維持醫師監督下的安全標準的同時，提升患者體驗。這項工作為 AI 部署在醫療保健溝通中的可行性提供了實證，並深入了解了成功整合到現有醫療保健服務中的要求。</paragraph>

##### **Enhancing Multi-Class Disease Classification: Neoplasms, Cardiovascular, Nervous System, and Digestive Disorders Using Advanced LLMs**
2411.12712v1 by Ahmed Akib Jawad Karim, Muhammad Zawad Mahmud, Samiha Islam, Aznur Azam

In this research, we explored the improvement in terms of multi-class disease
classification via pre-trained language models over Medical-Abstracts-TC-Corpus
that spans five medical conditions. We excluded non-cancer conditions and
examined four specific diseases. We assessed four LLMs, BioBERT, XLNet, and
BERT, as well as a novel base model (Last-BERT). BioBERT, which was pre-trained
on medical data, demonstrated superior performance in medical text
classification (97% accuracy). Surprisingly, XLNet followed closely (96%
accuracy), demonstrating its generalizability across domains even though it was
not pre-trained on medical data. LastBERT, a custom model based on the lighter
version of BERT, also proved competitive with 87.10% accuracy (just under
BERT's 89.33%). Our findings confirm the importance of specialized models such
as BioBERT and also support impressions around more general solutions like
XLNet and well-tuned transformer architectures with fewer parameters (in this
case, LastBERT) in medical domain tasks.

摘要：在這項研究中，我們探討了透過預先訓練的語言模型在跨越五種醫療疾病的 Medical-Abstracts-TC-Corpus 上，多類疾病分類的改進。我們排除了非癌症疾病，並檢查了四種特定疾病。我們評估了四個 LLM，BioBERT、XLNet 和 BERT，以及一個新的基礎模型 (Last-BERT)。在醫學文本分類中，經過醫學資料預先訓練的 BioBERT 表現出優異的效能（97% 準確度）。令人驚訝的是，XLNet 緊隨其後（96% 準確度），展示了它在不同領域的概括能力，即使它不是在醫學資料上預先訓練的。LastBERT 是一個基於較輕版本的 BERT 的自訂模型，也證明了競爭力，準確度為 87.10%（僅低於 BERT 的 89.33%）。我們的發現證實了 BioBERT 等專用模型的重要性，也支持了對更通用的解決方案的印象，例如 XLNet 和在醫學領域任務中具有較少參數的微調Transformer架構（在本例中為 LastBERT）。

##### **AI Guided Early Screening of Cervical Cancer**
2411.12681v1 by Dharanidharan S I, Suhitha Renuka S V, Ajishi Singh, Sheena Christabel Pravin

In order to support the creation of reliable machine learning models for
anomaly detection, this project focuses on preprocessing, enhancing, and
organizing a medical imaging dataset. There are two classifications in the
dataset: normal and abnormal, along with extra noise fluctuations. In order to
improve the photographs' quality, undesirable artifacts, including visible
medical equipment at the edges, were eliminated using central cropping.
Adjusting the brightness and contrast was one of the additional preprocessing
processes. Normalization was then performed to normalize the data. To make
classification jobs easier, the dataset was methodically handled by combining
several image subsets into two primary categories: normal and pathological. To
provide a strong training set that adapts well to real-world situations,
sophisticated picture preprocessing techniques were used, such as contrast
enhancement and real-time augmentation (including rotations, zooms, and
brightness modifications). To guarantee efficient model evaluation, the data
was subsequently divided into training and testing subsets. In order to create
precise and effective machine learning models for medical anomaly detection,
high-quality input data is ensured via this thorough approach. Because of the
project pipeline's flexible and scalable design, it can be easily integrated
with bigger clinical decision-support systems.

摘要：<paragraph>為了支持建立用於異常偵測的可靠機器學習模型，此專案專注於預處理、增強和組織醫學影像資料集。資料集中有兩個分類：正常和異常，以及額外的雜訊波動。為了提高照片的品質，包括邊緣可見的醫療設備在內的不可取的人工製品已使用中央裁切予以消除。調整亮度和對比度是額外預處理程序之一。然後執行正規化以正規化資料。為了使分類工作更輕鬆，資料集透過將多個影像子集組合成兩個主要類別（正常和病理）來有條理地處理。為了提供一個能良好適應真實世界情況的強大訓練集，使用了先進的圖片預處理技術，例如對比增強和即時擴充（包括旋轉、縮放和亮度修改）。為了保證有效的模型評估，資料隨後被分為訓練和測試子集。為了建立用於醫學異常偵測的精確且有效的機器學習模型，透過此徹底的方法確保了高品質的輸入資料。由於專案管線的靈活且可擴充的設計，它可以輕鬆地整合到更大的臨床決策支援系統中。</paragraph>

##### **Deep Learning-Driven Heat Map Analysis for Evaluating thickness of Wounded Skin Layers**
2411.12678v1 by Devakumar GR, JB Kaarthikeyan, Dominic Immanuel T, Sheena Christabel Pravin

Understanding the appropriate skin layer thickness in wounded sites is an
important tool to move forward on wound healing practices and treatment
protocols. Methods to measure depth often are invasive and less specific. This
paper introduces a novel method that is non-invasive with deep learning
techniques using classifying of skin layers that helps in measurement of wound
depth through heatmap analysis. A set of approximately 200 labeled images of
skin allows five classes to be distinguished: scars, wounds, and healthy skin,
among others. Each image has annotated key layers, namely the stratum cornetum,
the epidermis, and the dermis, in the software Roboflow. In the preliminary
stage, the Heatmap generator VGG16 was used to enhance the visibility of tissue
layers, based upon which their annotated images were used to train ResNet18
with early stopping techniques. It ended up at a very high accuracy rate of
97.67%. To do this, the comparison of the models ResNet18, VGG16, DenseNet121,
and EfficientNet has been done where both EfficientNet and ResNet18 have
attained accuracy rates of almost 95.35%. For further hyperparameter tuning,
EfficientNet and ResNet18 were trained at six different learning rates to
determine the best model configuration. It has been noted that the accuracy has
huge variations with different learning rates. In the case of EfficientNet, the
maximum achievable accuracy was 95.35% at the rate of 0.0001. The same was true
for ResNet18, which also attained its peak value of 95.35% at the same rate.
These facts indicate that the model can be applied and utilized in actual-time,
non-invasive wound assessment, which holds a great promise to improve clinical
diagnosis and treatment planning.

摘要：了解傷口部位適當的皮膚層厚度，是推動傷口癒合實務和治療方案的重要工具。測量深度的方法通常具有侵入性且不夠具體。本文介紹一種非侵入性的新方法，使用深度學習技術對皮膚層進行分類，有助於透過熱圖分析測量傷口深度。一組約 200 張標記的皮膚影像，可區分為五類：疤痕、傷口和健康皮膚等。每張影像在 Roboflow 軟體中都標註了關鍵層，即角質層、表皮和真皮。在初步階段，使用熱圖產生器 VGG16 來增強組織層的可見度，根據其標註的影像用於訓練 ResNet18，並採用早期停止技術。最終達到非常高的準確率 97.67%。為此，對 ResNet18、VGG16、DenseNet121 和 EfficientNet 進行了模型比較，其中 EfficientNet 和 ResNet18 都達到了接近 95.35% 的準確率。為了進一步調整超參數，以六種不同的學習率訓練 EfficientNet 和 ResNet18，以確定最佳模型配置。已注意到準確率會隨著不同的學習率而有很大的變化。在 EfficientNet 的情況下，在 0.0001 的速率下，可達到的最大準確率為 95.35%。ResNet18 也是如此，在相同的速率下也達到了 95.35% 的峰值。這些事實表明，該模型可以應用於實際時間的非侵入性傷口評估中，這對改善臨床診斷和治療計畫具有很大的前景。

##### **DiM: $f$-Divergence Minimization Guided Sharpness-Aware Optimization for Semi-supervised Medical Image Segmentation**
2411.12350v1 by Bingli Wang, Houcheng Su, Nan Yin, Mengzhu Wang, Li Shen

As a technique to alleviate the pressure of data annotation, semi-supervised
learning (SSL) has attracted widespread attention. In the specific domain of
medical image segmentation, semi-supervised methods (SSMIS) have become a
research hotspot due to their ability to reduce the need for large amounts of
precisely annotated data. SSMIS focuses on enhancing the model's generalization
performance by leveraging a small number of labeled samples and a large number
of unlabeled samples. The latest sharpness-aware optimization (SAM) technique,
which optimizes the model by reducing the sharpness of the loss function, has
shown significant success in SSMIS. However, SAM and its variants may not fully
account for the distribution differences between different datasets. To address
this issue, we propose a sharpness-aware optimization method based on
$f$-divergence minimization (DiM) for semi-supervised medical image
segmentation. This method enhances the model's stability by fine-tuning the
sensitivity of model parameters and improves the model's adaptability to
different datasets through the introduction of $f$-divergence. By reducing
$f$-divergence, the DiM method not only improves the performance balance
between the source and target datasets but also prevents performance
degradation due to overfitting on the source dataset.

摘要：作為一種減輕資料標註壓力的技術，半監督式學習 (SSL) 已廣受關注。在醫學影像分割的特定領域中，半監督式方法 (SSMIS) 由於能夠減少對大量精確標註資料的需求而成為研究熱點。SSMIS 專注於透過利用少數標籤樣本和大量未標籤樣本來增強模型的泛化效能。最新的銳利度感知最佳化 (SAM) 技術透過降低損失函數的銳利度來最佳化模型，已在 SSMIS 中展現顯著的成功。然而，SAM 及其變體可能無法完全考量不同資料集之間的分布差異。為了解決此問題，我們提出了一種基於 $f$-散度最小化 (DiM) 的銳利度感知最佳化方法，用於半監督式醫學影像分割。此方法透過微調模型參數的敏感度並透過引入 $f$-散度來改善模型對不同資料集的適應性，進而增強模型的穩定性。透過降低 $f$-散度，DiM 方法不僅改善了來源資料集和目標資料集之間的效能平衡，還防止了因過度擬合來源資料集而導致的效能下降。

##### **Can ChatGPT Overcome Behavioral Biases in the Financial Sector? Classify-and-Rethink: Multi-Step Zero-Shot Reasoning in the Gold Investment**
2411.13599v1 by Shuoling Liu, Gaoguo Jia, Yuhang Jiang, Liyuan Chen, Qiang Yang

Large Language Models (LLMs) have achieved remarkable success recently,
displaying exceptional capabilities in creating understandable and organized
text. These LLMs have been utilized in diverse fields, such as clinical
research, where domain-specific models like Med-Palm have achieved human-level
performance. Recently, researchers have employed advanced prompt engineering to
enhance the general reasoning ability of LLMs. Despite the remarkable success
of zero-shot Chain-of-Thoughts (CoT) in solving general reasoning tasks, the
potential of these methods still remains paid limited attention in the
financial reasoning task.To address this issue, we explore multiple prompt
strategies and incorporated semantic news information to improve LLMs'
performance on financial reasoning tasks.To the best of our knowledge, we are
the first to explore this important issue by applying ChatGPT to the gold
investment.In this work, our aim is to investigate the financial reasoning
capabilities of LLMs and their capacity to generate logical and persuasive
investment opinions. We will use ChatGPT, one of the most powerful LLMs
recently, and prompt engineering to achieve this goal. Our research will focus
on understanding the ability of LLMs in sophisticated analysis and reasoning
within the context of investment decision-making. Our study finds that ChatGPT
with CoT prompt can provide more explainable predictions and overcome
behavioral biases, which is crucial in finance-related tasks and can achieve
higher investment returns.

摘要：大型語言模型 (LLM) 近期已取得顯著成功，在建立可理解且有條理的文本方面展現出非凡的能力。這些 LLM 已運用於不同的領域，例如臨床研究，其中特定領域的模型（例如 Med-Palm）已達到人類等級的表現。最近，研究人員採用進階提示工程來提升 LLM 的一般推理能力。儘管零次學習思考鏈 (CoT) 在解決一般推理任務方面取得顯著成功，但這些方法的潛力在財務推理任務中仍未受到足夠的關注。為了解決這個問題，我們探討多種提示策略，並納入語義新聞資訊來提升 LLM 在財務推理任務上的表現。據我們所知，我們是第一個透過將 ChatGPT 應用於黃金投資來探討這個重要問題的人。在這項工作中，我們的目標是調查 LLM 的財務推理能力，以及它們產生合乎邏輯且有說服力的投資意見的能力。我們將使用 ChatGPT（最近最强大的 LLM 之一）和提示工程來達成這個目標。我們的研究將專注於了解 LLM 在投資決策制定脈絡中進行複雜分析和推理的能力。我們的研究發現，具備 CoT 提示的 ChatGPT 可以提供更具說明性的預測，並克服行為偏差（這在與財務相關的任務中至關重要），並能獲得更高的投資報酬。

##### **Contrast Similarity-Aware Dual-Pathway Mamba for Multivariate Time Series Node Classification**
2411.12222v1 by Mingsen Du, Meng Chen, Yongjian Li, Xiuxin Zhang, Jiahui Gao, Cun Ji, Shoushui Wei

Multivariate time series (MTS) data is generated through multiple sensors
across various domains such as engineering application, health monitoring, and
the internet of things, characterized by its temporal changes and high
dimensional characteristics. Over the past few years, many studies have
explored the long-range dependencies and similarities in MTS. However,
long-range dependencies are difficult to model due to their temporal changes
and high dimensionality makes it difficult to obtain similarities effectively
and efficiently. Thus, to address these issues, we propose contrast
similarity-aware dual-pathway Mamba for MTS node classification (CS-DPMamba).
Firstly, to obtain the dynamic similarity of each sample, we initially use
temporal contrast learning module to acquire MTS representations. And then we
construct a similarity matrix between MTS representations using Fast Dynamic
Time Warping (FastDTW). Secondly, we apply the DPMamba to consider the
bidirectional nature of MTS, allowing us to better capture long-range and
short-range dependencies within the data. Finally, we utilize the
Kolmogorov-Arnold Network enhanced Graph Isomorphism Network to complete the
information interaction in the matrix and MTS node classification task. By
comprehensively considering the long-range dependencies and dynamic similarity
features, we achieved precise MTS node classification. We conducted experiments
on multiple University of East Anglia (UEA) MTS datasets, which encompass
diverse application scenarios. Our results demonstrate the superiority of our
method through both supervised and semi-supervised experiments on the MTS
classification task.

摘要：多變量時間序列 (MTS) 資料是透過多個感測器在各種領域中產生的，例如工程應用、健康監測和物聯網，其特徵在於其時間變化和高維度特徵。在過去幾年中，許多研究探索了 MTS 中的長程依賴性和相似性。然而，由於時間變化，長程依賴性難以建模，而高維度性使得難以有效且有效地取得相似性。因此，為了解決這些問題，我們提出對比相似度感知雙路徑 Mamba 進行 MTS 節點分類 (CS-DPMamba)。首先，為了取得每個樣本的動態相似度，我們最初使用時間對比學習模組來取得 MTS 表徵。然後，我們使用快速動態時間扭曲 (FastDTW) 在 MTS 表徵之間建立相似矩陣。其次，我們應用 DPMamba 來考量 MTS 的雙向性質，讓我們能夠在資料中更好地擷取長程和短程依賴性。最後，我們利用 Kolmogorov-Arnold 網路增強圖同構網路來完成矩陣中的資訊互動和 MTS 節點分類任務。透過全面考量長程依賴性和動態相似性特徵，我們達到了精確的 MTS 節點分類。我們在多個東英格蘭大學 (UEA) MTS 資料集上進行了實驗，這些資料集涵蓋了不同的應用場景。我們的結果透過 MTS 分類任務上的監督式和半監督式實驗證明了我們方法的優越性。

##### **CCIS-Diff: A Generative Model with Stable Diffusion Prior for Controlled Colonoscopy Image Synthesis**
2411.12198v1 by Yifan Xie, Jingge Wang, Tao Feng, Fei Ma, Yang Li

Colonoscopy is crucial for identifying adenomatous polyps and preventing
colorectal cancer. However, developing robust models for polyp detection is
challenging by the limited size and accessibility of existing colonoscopy
datasets. While previous efforts have attempted to synthesize colonoscopy
images, current methods suffer from instability and insufficient data
diversity. Moreover, these approaches lack precise control over the generation
process, resulting in images that fail to meet clinical quality standards. To
address these challenges, we propose CCIS-DIFF, a Controlled generative model
for high-quality Colonoscopy Image Synthesis based on a Diffusion architecture.
Our method offers precise control over both the spatial attributes (polyp
location and shape) and clinical characteristics of polyps that align with
clinical descriptions. Specifically, we introduce a blur mask weighting
strategy to seamlessly blend synthesized polyps with the colonic mucosa, and a
text-aware attention mechanism to guide the generated images to reflect
clinical characteristics. Notably, to achieve this, we construct a new
multi-modal colonoscopy dataset that integrates images, mask annotations, and
corresponding clinical text descriptions. Experimental results demonstrate that
our method generates high-quality, diverse colonoscopy images with fine control
over both spatial constraints and clinical consistency, offering valuable
support for downstream segmentation and diagnostic tasks.

摘要：結腸鏡檢查對於腺瘤性息肉的辨識與預防大腸直腸癌至關重要。然而，由於現有結腸鏡檢查資料集的規模與取得不易，開發穩健的息肉偵測模型極具挑戰性。雖然先前的研究已嘗試合成結腸鏡影像，但目前的方法存在不穩定與資料多樣性不足的問題。此外，這些方法對於生成過程缺乏精確的控制，導致影像無法達到臨床品質標準。為了應對這些挑戰，我們提出 CCIS-DIFF，一種基於擴散架構的高品質結腸鏡影像合成受控生成模型。我們的方法能精確控制息肉的空間屬性（息肉位置與形狀）與臨床特徵，並與臨床描述相符。具體來說，我們引入模糊遮罩加權策略，以無縫地將合成的息肉與結腸黏膜融合，並使用文字感知注意力機制來引導生成的影像反映臨床特徵。值得注意的是，為了達成此目標，我們建構了一個新的多模式結腸鏡檢查資料集，其中整合了影像、遮罩標註與對應的臨床文字描述。實驗結果證明，我們的方法能生成高品質、多樣化的結腸鏡影像，並能精細地控制空間約束與臨床一致性，為下游分割與診斷任務提供有價值的支援。

##### **Medical Video Generation for Disease Progression Simulation**
2411.11943v1 by Xu Cao, Kaizhao Liang, Kuei-Da Liao, Tianren Gao, Wenqian Ye, Jintai Chen, Zhiguang Ding, Jianguo Cao, James M. Rehg, Jimeng Sun

Modeling disease progression is crucial for improving the quality and
efficacy of clinical diagnosis and prognosis, but it is often hindered by a
lack of longitudinal medical image monitoring for individual patients. To
address this challenge, we propose the first Medical Video Generation (MVG)
framework that enables controlled manipulation of disease-related image and
video features, allowing precise, realistic, and personalized simulations of
disease progression. Our approach begins by leveraging large language models
(LLMs) to recaption prompt for disease trajectory. Next, a controllable
multi-round diffusion model simulates the disease progression state for each
patient, creating realistic intermediate disease state sequence. Finally, a
diffusion-based video transition generation model interpolates disease
progression between these states. We validate our framework across three
medical imaging domains: chest X-ray, fundus photography, and skin image. Our
results demonstrate that MVG significantly outperforms baseline models in
generating coherent and clinically plausible disease trajectories. Two user
studies by veteran physicians, provide further validation and insights into the
clinical utility of the generated sequences. MVG has the potential to assist
healthcare providers in modeling disease trajectories, interpolating missing
medical image data, and enhancing medical education through realistic, dynamic
visualizations of disease progression.

摘要：疾病進程建模對於提升臨床診斷和預後的品質和效能至關重要，但通常會受到缺乏針對個別患者的縱向醫學影像監測的阻礙。為了應對此挑戰，我們提出第一個醫學影片生成 (MVG) 架構，它能控制操作與疾病相關的影像和影片特徵，允許精確、逼真且客製化的疾病進程模擬。我們的做法首先利用大型語言模型 (LLM) 來重新標記疾病軌跡的提示。接下來，可控制的多輪擴散模型會模擬每個患者的疾病進程狀態，建立逼真的中間疾病狀態序列。最後，基於擴散的影片轉換生成模型會內插這些狀態之間的疾病進程。我們在三個醫學影像領域驗證了我們的架構：胸部 X 光、眼底攝影和皮膚影像。我們的結果證明，MVG 在生成連貫且臨床上合理的疾病軌跡方面顯著優於基準模型。兩項由資深醫師進行的使用者研究進一步驗證並深入探討了生成序列的臨床效用。MVG 有潛力協助醫療保健提供者建模疾病軌跡、內插遺失的醫學影像資料，並透過逼真、動態的疾病進程視覺化來加強醫學教育。

##### **Edge-Enhanced Dilated Residual Attention Network for Multimodal Medical Image Fusion**
2411.11799v1 by Meng Zhou, Yuxuan Zhang, Xiaolan Xu, Jiayi Wang, Farzad Khalvati

Multimodal medical image fusion is a crucial task that combines complementary
information from different imaging modalities into a unified representation,
thereby enhancing diagnostic accuracy and treatment planning. While deep
learning methods, particularly Convolutional Neural Networks (CNNs) and
Transformers, have significantly advanced fusion performance, some of the
existing CNN-based methods fall short in capturing fine-grained multiscale and
edge features, leading to suboptimal feature integration. Transformer-based
models, on the other hand, are computationally intensive in both the training
and fusion stages, making them impractical for real-time clinical use.
Moreover, the clinical application of fused images remains unexplored. In this
paper, we propose a novel CNN-based architecture that addresses these
limitations by introducing a Dilated Residual Attention Network Module for
effective multiscale feature extraction, coupled with a gradient operator to
enhance edge detail learning. To ensure fast and efficient fusion, we present a
parameter-free fusion strategy based on the weighted nuclear norm of softmax,
which requires no additional computations during training or inference.
Extensive experiments, including a downstream brain tumor classification task,
demonstrate that our approach outperforms various baseline methods in terms of
visual quality, texture preservation, and fusion speed, making it a possible
practical solution for real-world clinical applications. The code will be
released at https://github.com/simonZhou86/en_dran.

摘要：多模态医学图像融合是一项至关重要的任务，它将来自不同成像方式的互补信息融合到一个统一的表示中，从而提高诊断准确性和治疗计划。虽然深度学习方法，尤其是卷积神经网络 (CNN) 和 Transformer，已经显著提升了融合性能，但一些现有的基于 CNN 的方法在捕捉细粒度多尺度和边缘特征方面存在不足，导致次优特征集成。另一方面，基于 Transformer 的模型在训练和融合阶段计算量很大，这使得它们不适用于实时临床使用。此外，融合图像的临床应用仍未得到探索。在本文中，我们提出了一种新颖的基于 CNN 的架构，通过引入膨胀残差注意力网络模块来解决这些限制，以进行有效的多分辨率特征提取，并结合梯度算子来增强边缘细节学习。为了确保快速而高效的融合，我们提出了一种基于 softmax 的加权核范数的参数化融合策略，它在训练或推理过程中不需要额外的计算。广泛的实验，包括下游脑肿瘤分类任务，表明我们的方法在视觉质量、纹理保留和融合速度方面优于各种基准方法，使其成为现实世界临床应用的可能实用解决方案。代码将在 https://github.com/simonZhou86/en_dran 发布。

##### **Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**
2411.11774v1 by Jeffrey N. Clark, Matthew Wragg, Emily Nielsen, Miquel Perello-Nieto, Nawid Keshtmand, Michael Ambler, Shiv Sharma, Christopher P. Bourdeaux, Amberly Brigden, Raul Santos-Rodriguez

There is a growing need to understand how digital systems can support
clinical decision-making, particularly as artificial intelligence (AI) models
become increasingly complex and less human-interpretable. This complexity
raises concerns about trustworthiness, impacting safe and effective adoption of
such technologies. Improved understanding of decision-making processes and
requirements for explanations coming from decision support tools is a vital
component in providing effective explainable solutions. This is particularly
relevant in the data-intensive, fast-paced environments of intensive care units
(ICUs). To explore these issues, group interviews were conducted with seven ICU
clinicians, representing various roles and experience levels. Thematic analysis
revealed three core themes: (T1) ICU decision-making relies on a wide range of
factors, (T2) the complexity of patient state is challenging for shared
decision-making, and (T3) requirements and capabilities of AI decision support
systems. We include design recommendations from clinical input, providing
insights to inform future AI systems for intensive care.

摘要：隨著人工智慧 (AI) 模型變得越來越複雜，且越來越難以被人理解，了解數位系統如何支援臨床決策的需求也日益增加。這種複雜性引發了對可信度的疑慮，影響了此類技術的安全且有效採用。改善對決策制定流程的理解，以及對決策支援工具所提供說明的要求，是提供有效可解釋解決方案的重要組成部分。這在資料密集、快節奏的加護病房 (ICU) 環境中特別相關。為了探討這些問題，對七位 ICU 臨床醫師進行了小組訪談，這些醫師代表了不同的角色和經驗層級。主題分析揭露了三個核心主題：(T1) ICU 決策制定依賴於廣泛的因素，(T2) 病患狀態的複雜性對共同決策制定構成挑戰，以及 (T3) AI 決策支援系統的要求和能力。我們納入了臨床輸入的設計建議，提供見解以提供資訊給未來用於加護的 AI 系統。

##### **SP${ }^3$ : Superpixel-propagated pseudo-label learning for weakly semi-supervised medical image segmentation**
2411.11636v1 by Shiman Li, Jiayue Zhao, Shaolei Liu, Xiaokun Dai, Chenxi Zhang, Zhijian Song

Deep learning-based medical image segmentation helps assist diagnosis and
accelerate the treatment process while the model training usually requires
large-scale dense annotation datasets. Weakly semi-supervised medical image
segmentation is an essential application because it only requires a small
amount of scribbles and a large number of unlabeled data to train the model,
which greatly reduces the clinician's effort to fully annotate images. To
handle the inadequate supervisory information challenge in weakly
semi-supervised segmentation (WSSS), a SuperPixel-Propagated Pseudo-label
(SP${}^3$) learning method is proposed, using the structural information
contained in superpixel for supplemental information. Specifically, the
annotation of scribbles is propagated to superpixels and thus obtains a dense
annotation for supervised training. Since the quality of pseudo-labels is
limited by the low-quality annotation, the beneficial superpixels selected by
dynamic thresholding are used to refine pseudo-labels. Furthermore, aiming to
alleviate the negative impact of noise in pseudo-label, superpixel-level
uncertainty is incorporated to guide the pseudo-label supervision for stable
learning. Our method achieves state-of-the-art performance on both tumor and
organ segmentation datasets under the WSSS setting, using only 3\% of the
annotation workload compared to fully supervised methods and attaining
approximately 80\% Dice score. Additionally, our method outperforms eight
weakly and semi-supervised methods under both weakly supervised and
semi-supervised settings. Results of extensive experiments validate the
effectiveness and annotation efficiency of our weakly semi-supervised
segmentation, which can assist clinicians in achieving automated segmentation
for organs or tumors quickly and ultimately benefit patients.

摘要：<paragraph>基於深度學習的醫學影像分割有助於診斷並加速治療過程，而模型訓練通常需要大規模密集標註的資料集。弱半監督醫學影像分割是一項重要的應用，因為它只需要少量的塗鴉和大量的未標註資料來訓練模型，這大大減少了臨床醫生完全標註影像的工作量。為了應對弱半監督分割 (WSSS) 中監督資訊不足的挑戰，提出了一種超像素傳播偽標籤 (SP${}^3$) 學習方法，利用超像素中包含的結構資訊作為補充資訊。具體來說，將塗鴉的標註傳播到超像素，從而獲得用於監督訓練的密集標註。由於偽標籤的品質受到低品質標註的限制，因此使用動態閾值選取的有利超像素來精緻偽標籤。此外，為了減輕偽標籤中雜訊的負面影響，將超像素層級的不確定性納入其中，以指導偽標籤監督以進行穩定的學習。我們的模型在 WSSS 設定下，在腫瘤和器官分割資料集上都達到了最先進的效能，與完全監督的方法相比，只使用了 3% 的標註工作量，並達到了約 80% 的 Dice 分數。此外，我們的模型在弱監督和半監督設定下都優於八種弱監督和半監督方法。廣泛實驗的結果驗證了我們弱半監督分割的有效性和標註效率，這可以協助臨床醫生快速實現器官或腫瘤的自動分割，並最終使患者受益。</paragraph>

##### **HistoEncoder: a digital pathology foundation model for prostate cancer**
2411.11458v1 by Joona Pohjonen, Abderrahim-Oussama Batouche, Antti Rannikko, Kevin Sandeman, Andrew Erickson, Esa Pitkanen, Tuomas Mirtti

Foundation models are trained on massive amounts of data to distinguish
complex patterns and can be adapted to a wide range of downstream tasks with
minimal computational resources. Here, we develop a foundation model for
prostate cancer digital pathology called HistoEncoder by pre-training on 48
million prostate tissue tile images. We demonstrate that HistoEncoder features
extracted from tile images with similar histological patterns map closely
together in the feature space. HistoEncoder outperforms models pre-trained with
natural images, even without fine-tuning or with 1000 times less training data.
We describe two use cases that leverage the capabilities of HistoEncoder by
fine-tuning the model with a limited amount of data and computational
resources. First, we show how HistoEncoder can be used to automatically
annotate large-scale datasets with high accuracy. Second, we combine histomics
with commonly used clinical nomograms, significantly improving prostate
cancer-specific death survival models. Foundation models such as HistoEncoder
can allow organizations with limited resources to build effective clinical
software tools without needing extensive datasets or significant amounts of
computing.

摘要：基礎模型在大量資料上進行訓練，以區分複雜模式，並可適應廣泛的下游任務，且只需最少的運算資源。在此，我們開發了一個名為 HistoEncoder 的攝護腺癌數位病理基礎模型，方法是預先在 4800 萬張攝護腺組織切片影像上進行訓練。我們證明了從具有相似組織學模式的切片影像中萃取的 HistoEncoder 特徵，在特徵空間中緊密地對應在一起。即使不進行微調或訓練資料減少 1000 倍，HistoEncoder 的表現仍優於預先使用自然影像進行訓練的模型。我們描述了兩個使用案例，它們透過使用有限的資料和運算資源微調模型，來利用 HistoEncoder 的功能。首先，我們展示了如何使用 HistoEncoder 自動註解大規模資料集，並具有高準確度。其次，我們將組織學與常用的臨床列線圖結合，大幅改善了攝護腺癌特異性死亡存活模型。像 HistoEncoder 這樣的基礎模型，可讓資源有限的組織建立有效的臨床軟體工具，而無需廣泛的資料集或大量的運算。

##### **TP-UNet: Temporal Prompt Guided UNet for Medical Image Segmentation**
2411.11305v2 by Ranmin Wang, Limin Zhuang, Hongkun Chen, Boyan Xu, Ruichu Cai

The advancement of medical image segmentation techniques has been propelled
by the adoption of deep learning techniques, particularly UNet-based
approaches, which exploit semantic information to improve the accuracy of
segmentations. However, the order of organs in scanned images has been
disregarded by current medical image segmentation approaches based on UNet.
Furthermore, the inherent network structure of UNet does not provide direct
capabilities for integrating temporal information. To efficiently integrate
temporal information, we propose TP-UNet that utilizes temporal prompts,
encompassing organ-construction relationships, to guide the segmentation UNet
model. Specifically, our framework is featured with cross-attention and
semantic alignment based on unsupervised contrastive learning to combine
temporal prompts and image features effectively. Extensive evaluations on two
medical image segmentation datasets demonstrate the state-of-the-art
performance of TP-UNet. Our implementation will be open-sourced after
acceptance.

摘要：醫療影像分割技術的進步已受到深度學習技術的採用所推動，特別是基於 UNet 的方法，它利用語義資訊來提高分割的準確性。然而，當前基於 UNet 的醫學影像分割方法忽略了掃描影像中器官的順序。此外，UNet 的固有網路結構無法直接整合時間資訊。為了有效整合時間資訊，我們提出了 TP-UNet，它利用時間提示，包含器官建構關係，來引導分割 UNet 模型。具體來說，我們的框架以無監督對比學習為基礎，具有交叉注意和語義對齊，以有效結合時間提示和影像特徵。在兩個醫學影像分割資料集上的廣泛評估證明了 TP-UNet 的最先進效能。我們的實作將在接受後開源。

##### **Deep learning waterways for rural infrastructure development**
2411.13590v1 by Matthew Pierson, Zia Mehrabi

Surprisingly a number of Earth's waterways remain unmapped, with a
significant number in low and middle income countries. Here we build a computer
vision model (WaterNet) to learn the location of waterways in the United
States, based on high resolution satellite imagery and digital elevation
models, and then deploy this in novel environments in the African continent.
Our outputs provide detail of waterways structures hereto unmapped. When
assessed against community needs requests for rural bridge building related to
access to schools, health care facilities and agricultural markets, we find
these newly generated waterways capture on average 93% (country range: 88-96%)
of these requests whereas Open Street Map, and the state of the art data from
TDX-Hydro, capture only 36% (5-72%) and 62% (37%-85%), respectively. Because
these new machine learning enabled maps are built on public and operational
data acquisition this approach offers promise for capturing humanitarian needs
and planning for social development in places where cartographic efforts have
so far failed to deliver. The improved performance in identifying community
needs missed by existing data suggests significant value for rural
infrastructure development and better targeting of development interventions.

摘要：令人驚訝的是，地球上的許多水道仍然未繪製，其中有大量低收入和中等收入國家。在這裡，我們建立了一個電腦視覺模型（WaterNet）來學習美國水道的所在位置，該模型基於高解析度衛星影像和數位高程模型，然後將其部署到非洲大陸的新環境中。我們的輸出提供了迄今未繪製的水道結構的詳細資訊。在根據社區需求評估與學校、醫療保健設施和農業市場的通路相關的農村橋樑建設請求時，我們發現這些新生成的航道平均涵蓋了這些請求的 93%（國家範圍：88-96%），而 Open Street Map 和 TDX-Hydro 中最先進的資料分別只涵蓋了 36%（5-72%）和 62%（37%-85%）。因為這些新的機器學習啟用地圖建立在公開和運作的資料採集中，所以這種方法有望捕捉人道主義需求，並為製圖工作迄今未能提供的地區的社會發展進行規劃。在識別現有資料遺漏的社區需求方面表現的改善，顯示出對農村基礎設施開發和更佳的發展干預目標具有重大價值。

##### **Zero-Shot Automatic Annotation and Instance Segmentation using LLM-Generated Datasets: Eliminating Field Imaging and Manual Annotation for Deep Learning Model Development**
2411.11285v1 by Ranjan Sapkota, Achyut Paudel, Manoj Karkee

Currently, deep learning-based instance segmentation for various applications
(e.g., Agriculture) is predominantly performed using a labor-intensive process
involving extensive field data collection using sophisticated sensors, followed
by careful manual annotation of images, presenting significant logistical and
financial challenges to researchers and organizations. The process also slows
down the model development and training process. In this study, we presented a
novel method for deep learning-based instance segmentation of apples in
commercial orchards that eliminates the need for labor-intensive field data
collection and manual annotation. Utilizing a Large Language Model (LLM), we
synthetically generated orchard images and automatically annotated them using
the Segment Anything Model (SAM) integrated with a YOLO11 base model. This
method significantly reduces reliance on physical sensors and manual data
processing, presenting a major advancement in "Agricultural AI". The synthetic,
auto-annotated dataset was used to train the YOLO11 model for Apple instance
segmentation, which was then validated on real orchard images. The results
showed that the automatically generated annotations achieved a Dice Coefficient
of 0.9513 and an IoU of 0.9303, validating the accuracy and overlap of the mask
annotations. All YOLO11 configurations, trained solely on these synthetic
datasets with automated annotations, accurately recognized and delineated
apples, highlighting the method's efficacy. Specifically, the YOLO11m-seg
configuration achieved a mask precision of 0.902 and a mask mAP@50 of 0.833 on
test images collected from a commercial orchard. Additionally, the YOLO11l-seg
configuration outperformed other models in validation on 40 LLM-generated
images, achieving the highest mask precision and mAP@50 metrics.
  Keywords: YOLO, SAM, SAMv2, YOLO11, YOLOv11, Segment Anything, YOLO-SAM

摘要：<paragraph>目前，針對各種應用（例如農業）的深度學習實例分割，主要透過勞力密集的程序執行，包括使用精密感測器廣泛收集現場資料，接著仔細手動標註影像，對研究人員和組織而言，這會造成顯著的後勤和財務挑戰。此程序也會減緩模型開發和訓練的過程。在此研究中，我們提出了一種創新的方法，可針對商業果園中的蘋果執行深度學習實例分割，無需勞力密集的現場資料收集和手動標註。我們利用大型語言模型 (LLM) 合成產生果園影像，並使用與 YOLO11 基礎模型整合的 Segment Anything Model (SAM) 自動標註這些影像。這種方法大幅降低對實體感測器和手動資料處理的依賴性，代表「農業 AI」的一大進步。合成自動標註的資料集用於訓練 YOLO11 模型，以進行蘋果實例分割，接著在真實果園影像中驗證。結果顯示，自動產生的標註達到了 0.9513 的 Dice 係數和 0.9303 的 IoU，驗證了遮罩標註的準確性和重疊性。所有 YOLO11 組態僅使用這些具有自動化標註的合成資料集進行訓練，就能準確辨識和描繪蘋果，突顯了此方法的效能。具體來說，YOLO11m-seg 組態在從商業果園收集的測試影像上達到了 0.902 的遮罩準確度和 0.833 的遮罩 mAP@50。此外，YOLO11l-seg 組態在針對 40 張 LLM 生成的影像進行驗證時，優於其他模型，達到了最高的遮罩準確度和 mAP@50 指標。
關鍵字：YOLO、SAM、SAMv2、YOLO11、YOLOv11、Segment Anything、YOLO-SAM</paragraph>

##### **Continuous K-space Recovery Network with Image Guidance for Fast MRI Reconstruction**
2411.11282v1 by Yucong Meng, Zhiwei Yang, Minghong Duan, Yonghong Shi, Zhijian Song

Magnetic resonance imaging (MRI) is a crucial tool for clinical diagnosis
while facing the challenge of long scanning time. To reduce the acquisition
time, fast MRI reconstruction aims to restore high-quality images from the
undersampled k-space. Existing methods typically train deep learning models to
map the undersampled data to artifact-free MRI images. However, these studies
often overlook the unique properties of k-space and directly apply general
networks designed for image processing to k-space recovery, leaving the precise
learning of k-space largely underexplored. In this work, we propose a
continuous k-space recovery network from a new perspective of implicit neural
representation with image domain guidance, which boosts the performance of MRI
reconstruction. Specifically, (1) an implicit neural representation based
encoder-decoder structure is customized to continuously query unsampled
k-values. (2) an image guidance module is designed to mine the semantic
information from the low-quality MRI images to further guide the k-space
recovery. (3) a multi-stage training strategy is proposed to recover dense
k-space progressively. Extensive experiments conducted on CC359, fastMRI, and
IXI datasets demonstrate the effectiveness of our method and its superiority
over other competitors.

摘要：磁共振成像 (MRI) 對於臨床診斷至關重要，但卻面臨掃描時間長的問題。為了縮短擷取時間，快速 MRI 重建旨在從欠採樣 k 空間恢復高品質影像。現有方法通常訓練深度學習模型，將欠採樣資料對應到沒有偽影的 MRI 影像。然而，這些研究常常忽略 k 空間的獨特屬性，並直接套用設計用於影像處理的一般網路到 k 空間重建，導致 k 空間的精確學習在很大程度上仍未被探索。在這項工作中，我們從隱式神經表徵與影像網域引導的新觀點提出一個連續的 k 空間重建網路，提升 MRI 重建的效能。具體來說，(1) 根據隱式神經表徵設計編碼器-解碼器結構，用於連續查詢未採樣的 k 值。(2) 設計一個影像引導模組，從低品質的 MRI 影像中挖掘語義資訊，進一步引導 k 空間重建。(3) 提出一個多階段訓練策略，用於逐步重建密集的 k 空間。在 CC359、fastMRI 和 IXI 資料集上進行的大量實驗證明了我們方法的有效性，以及其優於其他競爭對手的優越性。

##### **F$^3$OCUS -- Federated Finetuning of Vision-Language Foundation Models with Optimal Client Layer Updating Strategy via Multi-objective Meta-Heuristics**
2411.11912v1 by Pramit Saha, Felix Wagner, Divyanshu Mishra, Can Peng, Anshul Thakur, David Clifton, Konstantinos Kamnitsas, J. Alison Noble

Effective training of large Vision-Language Models (VLMs) on
resource-constrained client devices in Federated Learning (FL) requires the
usage of parameter-efficient fine-tuning (PEFT) strategies. To this end, we
demonstrate the impact of two factors \textit{viz.}, client-specific layer
importance score that selects the most important VLM layers for fine-tuning and
inter-client layer diversity score that encourages diverse layer selection
across clients for optimal VLM layer selection. We first theoretically motivate
and leverage the principal eigenvalue magnitude of layerwise Neural Tangent
Kernels and show its effectiveness as client-specific layer importance score.
Next, we propose a novel layer updating strategy dubbed F$^3$OCUS that jointly
optimizes the layer importance and diversity factors by employing a data-free,
multi-objective, meta-heuristic optimization on the server. We explore 5
different meta-heuristic algorithms and compare their effectiveness for
selecting model layers and adapter layers towards PEFT-FL. Furthermore, we
release a new MedVQA-FL dataset involving overall 707,962 VQA triplets and 9
modality-specific clients and utilize it to train and evaluate our method.
Overall, we conduct more than 10,000 client-level experiments on 6
Vision-Language FL task settings involving 58 medical image datasets and 4
different VLM architectures of varying sizes to demonstrate the effectiveness
of the proposed method.

摘要：<paragraph>在聯合學習 (FL) 中，在資源受限的用戶端裝置上有效訓練大型視覺語言模型 (VLM)，需要使用參數有效微調 (PEFT) 策略。為此，我們展示了兩個因素的影響，即客戶端特定層重要性評分，它選擇了最重要的 VLM 層進行微調，以及客戶端間層多樣性評分，它鼓勵在客戶端之間進行不同的層選擇，以實現最佳的 VLM 層選擇。我們首先從理論上激勵並利用層級神經切線核的主特徵值大小，並展示其作為客戶端特定層重要性評分的有效性。接下來，我們提出了一種名為 F$^3$OCUS 的新穎層更新策略，它通過在伺服器上使用無數據、多目標、元啟發式優化，共同優化層重要性和多樣性因素。我們探索了 5 種不同的元啟發式演算法，並比較了它們在選擇模型層和適配器層以進行 PEFT-FL 的有效性。此外，我們發布了一個新的 MedVQA-FL 資料集，其中包含 707,962 個 VQA 三元組和 9 個特定於模式的用戶端，並利用它來訓練和評估我們的模型。總體而言，我們在 6 個視覺語言 FL 任務設置上進行了 10,000 多個用戶端級別的實驗，涉及 58 個醫學影像資料集和 4 個不同大小的 VLM 架構，以證明所提出方法的有效性。</paragraph>

##### **MPLite: Multi-Aspect Pretraining for Mining Clinical Health Records**
2411.11161v1 by Eric Yang, Pengfei Hu, Xiaoxue Han, Yue Ning

The adoption of digital systems in healthcare has resulted in the
accumulation of vast electronic health records (EHRs), offering valuable data
for machine learning methods to predict patient health outcomes. However,
single-visit records of patients are often neglected in the training process
due to the lack of annotations of next-visit information, thereby limiting the
predictive and expressive power of machine learning models. In this paper, we
present a novel framework MPLite that utilizes Multi-aspect Pretraining with
Lab results through a light-weight neural network to enhance medical concept
representation and predict future health outcomes of individuals. By
incorporating both structured medical data and additional information from lab
results, our approach fully leverages patient admission records. We design a
pretraining module that predicts medical codes based on lab results, ensuring
robust prediction by fusing multiple aspects of features. Our experimental
evaluation using both MIMIC-III and MIMIC-IV datasets demonstrates improvements
over existing models in diagnosis prediction and heart failure prediction
tasks, achieving a higher weighted-F1 and recall with MPLite. This work reveals
the potential of integrating diverse aspects of data to advance predictive
modeling in healthcare.

摘要：數位系統在醫療保健中的採用導致了大量電子健康記錄 (EHR) 的累積，這些記錄提供了有價值的資料，可供機器學習方法用來預測患者的健康結果。然而，由於缺乏下次就診資訊的註解，患者的單次就診記錄在訓練過程中常常被忽略，因此限制了機器學習模型的預測和表達能力。在本文中，我們提出了一個創新的框架 MPLite，它利用透過輕量級神經網路進行多面向預訓練與實驗室結果，來增強醫療概念的表徵並預測個人的未來健康結果。透過結合結構化的醫療資料和來自實驗室結果的額外資訊，我們的做法充分利用了患者的入院記錄。我們設計了一個預訓練模組，根據實驗室結果預測醫療代碼，確保透過融合特徵的各個面向來進行穩健的預測。我們使用 MIMIC-III 和 MIMIC-IV 資料集進行的實驗評估證明，在診斷預測和心臟衰竭預測任務中，我們的模型優於現有的模型，使用 MPLite 達到了更高的加權 F1 和召回率。這項工作揭示了整合資料中不同面向的潛力，以推進醫療保健中的預測建模。

##### **Label Sharing Incremental Learning Framework for Independent Multi-Label Segmentation Tasks**
2411.11105v1 by Deepa Anand, Bipul Das, Vyshnav Dangeti, Antony Jerald, Rakesh Mullick, Uday Patil, Pakhi Sharma, Prasad Sudhakar

In a setting where segmentation models have to be built for multiple
datasets, each with its own corresponding label set, a straightforward way is
to learn one model for every dataset and its labels. Alternatively, multi-task
architectures with shared encoders and multiple segmentation heads or shared
weights with compound labels can also be made use of. This work proposes a
novel label sharing framework where a shared common label space is constructed
and each of the individual label sets are systematically mapped to the common
labels. This transforms multiple datasets with disparate label sets into a
single large dataset with shared labels, and therefore all the segmentation
tasks can be addressed by learning a single model. This eliminates the need for
task specific adaptations in network architectures and also results in
parameter and data efficient models. Furthermore, label sharing framework is
naturally amenable for incremental learning where segmentations for new
datasets can be easily learnt. We experimentally validate our method on various
medical image segmentation datasets, each involving multi-label segmentation.
Furthermore, we demonstrate the efficacy of the proposed method in terms of
performance and incremental learning ability vis-a-vis alternative methods.

摘要：在必須為多個資料集建立分割模型的設定中，每個資料集都有自己對應的標籤集，一個直接的方法是為每個資料集及其標籤學習一個模型。或者，也可以利用具有共享編碼器和多個分割頭或具有複合標籤的共享權重的多任務架構。這項工作提出了一個新穎的標籤共享框架，其中構建了一個共享的共同標籤空間，並且每個單獨的標籤集都系統性地映射到共同標籤。這將具有不同標籤集的多個資料集轉換為具有共享標籤的單一大型資料集，因此所有分割任務都可以通過學習單一模型來解決。這消除了對網路架構中特定任務適應的需求，並且還產生了參數和資料有效率的模型。此外，標籤共享框架自然適用於增量學習，其中可以輕鬆學習新資料集的分割。我們在涉及多標籤分割的各種醫學影像分割資料集上對我們的模型進行實驗驗證。此外，我們根據效能和增量學習能力證明了所提出模型的有效性，相對於其他方法。

##### **BianCang: A Traditional Chinese Medicine Large Language Model**
2411.11027v1 by Sibo Wei, Xueping Peng, Yi-fei Wang, Jiasheng Si, Weiyu Zhang, Wenpeng Lu, Xiaoming Wu, Yinglong Wang

The rise of large language models (LLMs) has driven significant progress in
medical applications, including traditional Chinese medicine (TCM). However,
current medical LLMs struggle with TCM diagnosis and syndrome differentiation
due to substantial differences between TCM and modern medical theory, and the
scarcity of specialized, high-quality corpora. This paper addresses these
challenges by proposing BianCang, a TCM-specific LLM, using a two-stage
training process that first injects domain-specific knowledge and then aligns
it through targeted stimulation. To enhance diagnostic and differentiation
capabilities, we constructed pre-training corpora, instruction-aligned datasets
based on real hospital records, and the ChP-TCM dataset derived from the
Pharmacopoeia of the People's Republic of China. We compiled extensive TCM and
medical corpora for continuous pre-training and supervised fine-tuning,
building a comprehensive dataset to refine the model's understanding of TCM.
Evaluations across 11 test sets involving 29 models and 4 tasks demonstrate the
effectiveness of BianCang, offering valuable insights for future research.
Code, datasets, and models are available at
https://github.com/QLU-NLP/BianCang.

摘要：大型語言模型 (LLM) 的興起推動了醫療應用領域的重大進展，包括中醫學 (TCM)。然而，由於中醫學與現代醫學理論之間存在著實質性的差異，以及缺乏專業、高品質的語料庫，當前的醫學 LLM 在中醫診斷和證候鑑別方面遇到了困難。本文通過提出 BianCang，一種特定於中醫學的 LLM，來應對這些挑戰，使用一個兩階段訓練過程，首先注入特定領域的知識，然後通過有針對性的刺激來對齊它。為了增強診斷和鑑別能力，我們構建了預訓練語料庫、基於真實醫院記錄的指令對齊數據集，以及源自中華人民共和國藥典的 ChP-TCM 數據集。我們編譯了大量的 TCM 和醫學語料庫，用於持續的預訓練和監督微調，構建了一個全面的數據集來完善模型對 TCM 的理解。涉及 29 個模型和 4 項任務的 11 個測試集的評估證明了 BianCang 的有效性，為未來的研究提供了有價值的見解。程式碼、數據集和模型可在 https://github.com/QLU-NLP/BianCang 獲得。

##### **MpoxVLM: A Vision-Language Model for Diagnosing Skin Lesions from Mpox Virus Infection**
2411.10888v1 by Xu Cao, Wenqian Ye, Kenny Moise, Megan Coffee

In the aftermath of the COVID-19 pandemic and amid accelerating climate
change, emerging infectious diseases, particularly those arising from zoonotic
spillover, remain a global threat. Mpox (caused by the monkeypox virus) is a
notable example of a zoonotic infection that often goes undiagnosed, especially
as its rash progresses through stages, complicating detection across diverse
populations with different presentations. In August 2024, the WHO
Director-General declared the mpox outbreak a public health emergency of
international concern for a second time. Despite the deployment of deep
learning techniques for detecting diseases from skin lesion images, a robust
and publicly accessible foundation model for mpox diagnosis is still lacking
due to the unavailability of open-source mpox skin lesion images, multimodal
clinical data, and specialized training pipelines. To address this gap, we
propose MpoxVLM, a vision-language model (VLM) designed to detect mpox by
analyzing both skin lesion images and patient clinical information. MpoxVLM
integrates the CLIP visual encoder, an enhanced Vision Transformer (ViT)
classifier for skin lesions, and LLaMA-2-7B models, pre-trained and fine-tuned
on visual instruction-following question-answer pairs from our newly released
mpox skin lesion dataset. Our work achieves 90.38% accuracy for mpox detection,
offering a promising pathway to improve early diagnostic accuracy in combating
mpox.

摘要：在 COVID-19 大流行之後，在加速的氣候變遷和新興傳染病中，特別是那些源自人畜共通傳染病的疾病，仍然是一個全球性的威脅。猴痘（由猴痘病毒引起）是一個顯著的人畜共通傳染病感染範例，通常未被診斷出來，特別是隨著其皮疹進展到各個階段，使得在具有不同表現形式的多元族群中進行偵測變得複雜。2024 年 8 月，世界衛生組織總幹事第二次宣布猴痘疫情為國際關注的公共衛生緊急事件。儘管已部署深度學習技術用於從皮膚病灶影像中偵測疾病，但由於缺乏開放原始碼的猴痘皮膚病灶影像、多模式臨床資料和專業的訓練管道，因此仍然缺乏一個穩健且公開可用的猴痘診斷基礎模型。為了解決這個差距，我們提出 MpoxVLM，這是一個視覺語言模型 (VLM)，旨在透過分析皮膚病灶影像和患者臨床資訊來偵測猴痘。MpoxVLM 整合了 CLIP 視覺編碼器、一個針對皮膚病灶增強的視覺轉換器 (ViT) 分類器，以及 LLaMA-2-7B 模型，這些模型經過預先訓練和微調，並根據我們新發布的猴痘皮膚病灶資料集中的視覺指令遵循問題解答配對。我們的研究在猴痘偵測方面達到了 90.38% 的準確度，為提高早期診斷準確度以對抗猴痘提供了有希望的途徑。

##### **A Novel Adaptive Hybrid Focal-Entropy Loss for Enhancing Diabetic Retinopathy Detection Using Convolutional Neural Networks**
2411.10843v1 by Pandiyaraju V, Santhosh Malarvannan, Shravan Venkatraman, Abeshek A, Priyadarshini B, Kannan A

Diabetic retinopathy is a leading cause of blindness around the world and
demands precise AI-based diagnostic tools. Traditional loss functions in
multi-class classification, such as Categorical Cross-Entropy (CCE), are very
common but break down with class imbalance, especially in cases with inherently
challenging or overlapping classes, which leads to biased and less sensitive
models. Since a heavy imbalance exists in the number of examples for higher
severity stage 4 diabetic retinopathy, etc., classes compared to those very
early stages like class 0, achieving class balance is key. For this purpose, we
propose the Adaptive Hybrid Focal-Entropy Loss which combines the ideas of
focal loss and entropy loss with adaptive weighting in order to focus on
minority classes and highlight the challenging samples. The state-of-the art
models applied for diabetic retinopathy detection with AHFE revealed good
performance improvements, indicating the top performances of ResNet50 at
99.79%, DenseNet121 at 98.86%, Xception at 98.92%, MobileNetV2 at 97.84%, and
InceptionV3 at 93.62% accuracy. This sheds light into how AHFE promotes
enhancement in AI-driven diagnostics for complex and imbalanced medical
datasets.

摘要：糖尿病視網膜病變是全球失明的主要原因，需要精準的 AI 診斷工具。多類別分類中的傳統損失函數，例如分類交叉熵 (CCE)，非常常見，但會隨著類別失衡而失效，特別是在類別本身具有挑戰性或重疊的情況下，這會導致有偏差且不敏感的模型。由於嚴重度較高的第 4 期糖尿病視網膜病變等類別的範例數量嚴重失衡，與第 0 期等非常早期的類別相比，達成類別平衡至關重要。為此，我們提出自適應混合焦點熵損失，它結合了焦點損失和熵損失的概念，並採用自適應加權，以專注於少數類別並突顯具有挑戰性的範例。應用於糖尿病視網膜病變偵測的最新模型搭配 AHFE，顯示出良好的效能提升，表示 ResNet50 的最高效能為 99.79%、DenseNet121 為 98.86%、Xception 為 98.92%、MobileNetV2 為 97.84%，以及 InceptionV3 的準確度為 93.62%。這揭示了 AHFE 如何促進以 AI 為主的診斷，以應對複雜且不平衡的醫療資料集。

##### **MRI Parameter Mapping via Gaussian Mixture VAE: Breaking the Assumption of Independent Pixels**
2411.10772v1 by Moucheng Xu, Yukun Zhou, Tobias Goodwin-Allcock, Kimia Firoozabadi, Joseph Jacob, Daniel C. Alexander, Paddy J. Slator

We introduce and demonstrate a new paradigm for quantitative parameter
mapping in MRI. Parameter mapping techniques, such as diffusion MRI and
quantitative MRI, have the potential to robustly and repeatably measure
biologically-relevant tissue maps that strongly relate to underlying
microstructure. Quantitative maps are calculated by fitting a model to multiple
images, e.g. with least-squares or machine learning. However, the overwhelming
majority of model fitting techniques assume that each voxel is independent,
ignoring any co-dependencies in the data. This makes model fitting sensitive to
voxelwise measurement noise, hampering reliability and repeatability. We
propose a self-supervised deep variational approach that breaks the assumption
of independent pixels, leveraging redundancies in the data to effectively
perform data-driven regularisation of quantitative maps. We demonstrate that
our approach outperforms current model fitting techniques in dMRI simulations
and real data. Especially with a Gaussian mixture prior, our model enables
sharper quantitative maps, revealing finer anatomical details that are not
presented in the baselines. Our approach can hence support the clinical
adoption of parameter mapping methods such as dMRI and qMRI.

摘要：<paragraph>我們介紹並展示一種新的範例，用於 MRI 中的定量參數對應。參數對應技術，例如擴散 MRI 和定量 MRI，具有強健且可重複測量與底層微結構密切相關的生物相關組織對應的能力。定量對應是透過將模型套用到多個影像來計算，例如使用最小平方或機器學習。然而，絕大多數的模型擬合技術假設每個體素都是獨立的，忽略資料中的任何共依賴性。這使得模型擬合容易受到體素測量雜訊的影響，阻礙了可靠性和可重複性。我們提出一個自我監督的深度變異方法，打破了獨立像素的假設，利用資料中的冗餘來有效執行定量對應的資料驅動正規化。我們證明我們的模型在 dMRI 模擬和真實資料中優於目前的模型擬合技術。特別是使用高斯混合先驗，我們的模型能產生更清晰的定量對應，揭示出基準線中未呈現的更精細解剖細節。因此，我們的模型可以支援 dMRI 和 qMRI 等參數對應方法的臨床採用。</paragraph>

##### **Integrated Machine Learning and Survival Analysis Modeling for Enhanced Chronic Kidney Disease Risk Stratification**
2411.10754v1 by Zachary Dana, Ahmed Ammar Naseer, Botros Toro, Sumanth Swaminathan

Chronic kidney disease (CKD) is a significant public health challenge, often
progressing to end-stage renal disease (ESRD) if not detected and managed
early. Early intervention, warranted by silent disease progression, can
significantly reduce associated morbidity, mortality, and financial burden. In
this study, we propose a novel approach to modeling CKD progression using a
combination of machine learning techniques and classical statistical models.
Building on the work of Liu et al. (2023), we evaluate linear models,
tree-based methods, and deep learning models to extract novel predictors for
CKD progression, with feature importance assessed using Shapley values. These
newly identified predictors, integrated with established clinical features from
the Kidney Failure Risk Equation, are then applied within the framework of Cox
proportional hazards models to predict CKD progression.

摘要：慢性腎臟病 (CKD) 是一項重大的公共衛生挑戰，如果未及早發現和管理，通常會進展到末期腎臟疾病 (ESRD)。無聲疾病進程所致的早期介入，可以顯著降低相關的發病率、死亡率和財務負擔。在這項研究中，我們提出了一種使用機器學習技術和經典統計模型相結合來建模 CKD 進程的新方法。在 Liu 等人 (2023) 的研究基礎上，我們評估了線性模型、基於樹的方法和深度學習模型，以提取 CKD 進程的新預測因子，並使用 Shapley 值評估特徵重要性。這些新識別的預測因子與腎臟衰竭風險方程式中已建立的臨床特徵相結合，然後應用於 Cox 比例風險模型的框架中以預測 CKD 進程。

##### **LTCXNet: Advancing Chest X-Ray Analysis with Solutions for Long-Tailed Multi-Label Classification and Fairness Challenges**
2411.10746v1 by Chin-Wei Huang, Mu-Yi Shen, Kuan-Chang Shih, Shih-Chih Lin, Chi-Yu Chen, Po-Chih Kuo

Chest X-rays (CXRs) often display various diseases with disparate class
frequencies, leading to a long-tailed, multi-label data distribution. In
response to this challenge, we explore the Pruned MIMIC-CXR-LT dataset, a
curated collection derived from the MIMIC-CXR dataset, specifically designed to
represent a long-tailed and multi-label data scenario. We introduce LTCXNet, a
novel framework that integrates the ConvNeXt model, ML-Decoder, and strategic
data augmentation, further enhanced by an ensemble approach. We demonstrate
that LTCXNet improves the performance of CXR interpretation across all classes,
especially enhancing detection in rarer classes like `Pneumoperitoneum' and
`Pneumomediastinum' by 79\% and 48\%, respectively. Beyond performance metrics,
our research extends into evaluating fairness, highlighting that some methods,
while improving model accuracy, could inadvertently affect fairness across
different demographic groups negatively. This work contributes to advancing the
understanding and management of long-tailed, multi-label data distributions in
medical imaging, paving the way for more equitable and effective diagnostic
tools.

摘要：胸部 X 光片 (CXR) 通常會顯示各種疾病，且各類別的頻率不同，導致長尾的多標籤資料分佈。為了應對這項挑戰，我們探討了精簡的 MIMIC-CXR-LT 資料集，這是一個從 MIMIC-CXR 資料集衍生的精選集合，專門設計用於表示長尾和多標籤資料情境。我們引入了 LTCXNet，這是一個整合了 ConvNeXt 模型、ML-Decoder 和策略性資料擴充的新架構，並透過整體方法進一步增強。我們證明 LTCXNet 可提升所有類別的 CXR 解釋效能，特別是將較罕見類別（如「氣腹」和「縱膈氣腫」）的偵測功能分別提升了 79% 和 48%。除了效能指標之外，我們的研究還擴展到評估公平性，強調一些方法在提升模型準確度的同時，可能會無意間對不同人口群體的公平性產生負面影響。這項工作有助於促進對醫學影像中長尾、多標籤資料分佈的理解和管理，為更公平、有效的診斷工具鋪路。

##### **Chain of Alignment: Integrating Public Will with Expert Intelligence for Language Model Alignment**
2411.10534v1 by Andrew Konya, Aviv Ovadya, Kevin Feng, Quan Ze Chen, Lisa Schirch, Colin Irwin, Amy X. Zhang

We introduce a method to measure the alignment between public will and
language model (LM) behavior that can be applied to fine-tuning, online
oversight, and pre-release safety checks. Our `chain of alignment' (CoA)
approach produces a rule based reward (RBR) by creating model behavior
$\textit{rules}$ aligned to normative $\textit{objectives}$ aligned to
$\textit{public will}$. This factoring enables a nonexpert public to directly
specify their will through the normative objectives, while expert intelligence
is used to figure out rules entailing model behavior that best achieves those
objectives. We validate our approach by applying it across three different
domains of LM prompts related to mental health. We demonstrate a public input
process built on collective dialogues and bridging-based ranking that reliably
produces normative objectives supported by at least $96\% \pm 2\%$ of the US
public. We then show that rules developed by mental health experts to achieve
those objectives enable a RBR that evaluates an LM response's alignment with
the objectives similarly to human experts (Pearson's $r=0.841$, $AUC=0.964$).
By measuring alignment with objectives that have near unanimous public support,
these CoA RBRs provide an approximate measure of alignment between LM behavior
and public will.

摘要：<paragraph>我們提出了一種方法來衡量公眾意願與語言模型 (LM) 行為之間的一致性，這種方法可以應用於微調、線上監督和預發佈安全檢查。我們的「一致性鏈」(CoA) 方法透過建立模型行為 $\textit{規則}$，使其與規範性 $\textit{目標}$ 保持一致，進而與 $\textit{公眾意願}$ 保持一致，從而產生基於規則的獎勵 (RBR)。這種分解使非專家公眾能夠透過規範性目標直接表達他們的意願，而專家智慧則用於找出蘊含模型行為的規則，這些規則最能實現這些目標。我們透過將方法應用在與心理健康相關的 LM 提示的三個不同領域來驗證我們的做法。我們展示了一個建立在集體對話和基於橋接的排名上的公眾意見輸入流程，該流程可靠地產生至少有 $96\% \pm 2\%$ 的美國公眾支持的規範性目標。然後我們展示由心理健康專家制定以實現這些目標的規則，使 RBR 能夠評估 LM 回應與目標的一致性，其方式與人類專家類似（Pearson's $r=0.841$，$AUC=0.964$）。透過衡量與獲得近乎一致公眾支持的目標的一致性，這些 CoA RBR 提供了 LM 行為與公眾意願之間一致性的近似衡量標準。</paragraph>

##### **Deep Learning for Micro-Scale Crack Detection on Imbalanced Datasets Using Key Point Localization**
2411.10389v1 by Fatahlla Moreh, Yusuf Hasan, Bilal Zahid Hussain, Mohammad Ammar, Sven Tomforde

Internal crack detection has been a subject of focus in structural health
monitoring. By focusing on crack detection in structural datasets, it is
demonstrated that deep learning (DL) methods can effectively analyze seismic
wave fields interacting with micro-scale cracks, which are beyond the
resolution of conventional visual inspection. This work explores a novel
application of DL-based key point detection technique, where cracks are
localized by predicting the coordinates of four key points that define a
bounding region of the crack. The study not only opens new research directions
for non-visual applications but also effectively mitigates the impact of
imbalanced data which poses a challenge for previous DL models, as it can be
biased toward predicting the majority class (non-crack regions). Popular DL
techniques, such as the Inception blocks, are used and investigated. The model
shows an overall reduction in loss when applied to micro-scale crack detection
and is reflected in the lower average deviation between the location of actual
and predicted cracks, with an average Intersection over Union (IoU) being 0.511
for all micro cracks (greater than 0.00 micrometers) and 0.631 for larger micro
cracks (greater than 4 micrometers).

摘要：內部裂縫偵測一直是結構健康監測的重點。透過專注於結構資料集中的裂縫偵測，證明深度學習 (DL) 方法可以有效分析與微尺度裂縫交互作用的地震波場，這超出了傳統目視檢查的解析度。這項工作探索了基於 DL 的關鍵點偵測技術的一項新應用，其中透過預測定義裂縫邊界區域的四個關鍵點的座標來定位裂縫。這項研究不僅為非視覺應用開啟了新的研究方向，還能有效減輕不平衡資料的影響，而這對先前的 DL 模型構成挑戰，因為它可能偏向於預測多數類別（非裂縫區域）。使用並研究了流行的 DL 技術，例如 Inception 區塊。該模型在應用於微尺度裂縫偵測時顯示出整體損失減少，並且反映在實際裂縫和預測裂縫的位置之間的較低平均偏差中，所有微裂縫（大於 0.00 微米）的平均交集比聯合（IoU）為 0.511，而較大的微裂縫（大於 4 微米）則為 0.631。

##### **Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**
2411.10255v1 by Mohammed Yaseen Jabarulla, Theodor Uden, Thomas Jack, Philipp Beerbaum, Steffen Oeltze-Jafra

Pediatric heart diseases present a broad spectrum of congenital and acquired
diseases. More complex congenital malformations require a differentiated and
multimodal decision-making process, usually including echocardiography as a
central imaging method. Artificial intelligence (AI) offers considerable
promise for clinicians by facilitating automated interpretation of pediatric
echocardiography data. However, adapting AI technologies for pediatric
echocardiography analysis has challenges such as limited public data
availability, data privacy, and AI model transparency. Recently, researchers
have focused on disruptive technologies, such as federated learning (FL) and
explainable AI (XAI), to improve automatic diagnostic and decision support
workflows. This study offers a comprehensive overview of the limitations and
opportunities of AI in pediatric echocardiography, emphasizing the synergistic
workflow and role of XAI and FL, identifying research gaps, and exploring
potential future developments. Additionally, three relevant clinical use cases
demonstrate the functionality of XAI and FL with a focus on (i) view
recognition, (ii) disease classification, (iii) segmentation of cardiac
structures, and (iv) quantitative assessment of cardiac function.

摘要：小兒心臟疾病呈現先天性與後天性疾病的廣泛光譜。較複雜的先天性畸形需要一個差異化且多模式的決策過程，通常包括超音波檢查作為主要的影像方法。人工智慧 (AI) 為臨床醫生提供了相當大的希望，因為它可以促進小兒超音波檢查資料的自動化解讀。然而，將人工智慧技術應用於小兒超音波檢查分析有許多挑戰，例如有限的公開資料可用性、資料隱私和人工智慧模型透明度。最近，研究人員專注於破壞性技術，例如聯合學習 (FL) 和可解釋人工智慧 (XAI)，以改善自動診斷和決策支援工作流程。本研究提供了人工智慧在小兒超音波檢查中的限制和機會的全面概述，強調了 XAI 和 FL 的協同工作流程和角色，找出研究差距並探討潛在的未來發展。此外，三個相關的臨床使用案例展示了 XAI 和 FL 的功能，重點在於 (i) 檢視辨識、(ii) 疾病分類、(iii) 心臟結構分割和 (iv) 心臟功能的量化評估。

##### **FedCL-Ensemble Learning: A Framework of Federated Continual Learning with Ensemble Transfer Learning Enhanced for Alzheimer's MRI Classifications while Preserving Privacy**
2411.12756v1 by Rishit Kapoor, Jesher Joshua, Muralidharan Vijayarangan, Natarajan B

This research work introduces a novel approach to the classification of
Alzheimer's disease by using the advanced deep learning techniques combined
with secure data processing methods. This research work primary uses transfer
learning models such as ResNet, ImageNet, and VNet to extract high-level
features from medical image data. Thereafter, these pre-trained models were
fine-tuned for Alzheimer's related subtle patterns such that the model is
capable of robust feature extraction over varying data sources. Further, the
federated learning approaches were incorporated to tackle a few other
challenges related to classification, aimed to provide better prediction
performance and protect data privacy. The proposed model was built using
federated learning without sharing sensitive patient data. This way, the
decentralized model benefits from the large and diversified dataset that it is
trained upon while ensuring confidentiality. The cipher-based encryption
mechanism is added that allows us to secure the transportation of data and
further ensure the privacy and integrity of patient information throughout
training and classification. The results of the experiments not only help to
improve the accuracy of the classification of Alzheimer's but at the same time
provides a framework for secure and collaborative analysis of health care data.

摘要：本研究工作提出了一種新的阿茲海默症分類方法，該方法結合了先進的深度學習技術和安全的數據處理方法。本研究工作主要使用 ResNet、ImageNet 和 VNet 等遷移學習模型從醫學影像數據中提取高級特徵。隨後，這些預訓練模型針對阿茲海默症相關的細微模式進行微調，使模型能夠對不同數據源中的特徵進行穩健提取。此外，聯邦學習方法被納入以應對與分類相關的幾個其他挑戰，旨在提供更好的預測性能和保護數據隱私。所提出的模型是使用聯邦學習構建的，而無需共享敏感的患者數據。這樣，分散式模型可以從其訓練的大型且多樣化的數據集中受益，同時確保機密性。添加了基於密碼的加密機制，它使我們能夠確保數據傳輸的安全性，並進一步確保患者信息在整個訓練和分類過程中的隱私和完整性。實驗結果不僅有助於提高阿茲海默症分類的準確性，同時還為醫療保健數據的安全和協作分析提供了一個框架。

##### **Evaluating the role of `Constitutions' for learning from AI feedback**
2411.10168v1 by Saskia Redgate, Andrew M. Bean, Adam Mahdi

The growing capabilities of large language models (LLMs) have led to their
use as substitutes for human feedback for training and assessing other LLMs.
These methods often rely on `constitutions', written guidelines which a critic
model uses to provide feedback and improve generations. We investigate how the
choice of constitution affects feedback quality by using four different
constitutions to improve patient-centered communication in medical interviews.
In pairwise comparisons conducted by 215 human raters, we found that detailed
constitutions led to better results regarding emotive qualities. However, none
of the constitutions outperformed the baseline in learning more
practically-oriented skills related to information gathering and provision. Our
findings indicate that while detailed constitutions should be prioritised,
there are possible limitations to the effectiveness of AI feedback as a reward
signal in certain areas.

摘要：大型語言模型（LLM）功能不斷增強，促使它們被用作人類回饋的替代品，以訓練和評估其他 LLM。這些方法通常依賴於「憲法」，也就是評論模型用來提供回饋和改進生成的書面準則。我們探討憲法選擇如何影響回饋品質，方法是使用四種不同的憲法來改善醫療訪談中的以患者為中心的溝通。在 215 位人類評分員進行的成對比較中，我們發現詳細的憲法在情緒品質方面帶來更好的結果。然而，沒有任何憲法在學習與資訊收集和提供相關的更實用技能方面優於基準。我們的研究結果表明，雖然應優先考慮詳細的憲法，但 AI 回饋作為特定領域的獎勵訊號的有效性可能有限。

##### **PFML: Self-Supervised Learning of Time-Series Data Without Representation Collapse**
2411.10087v1 by Einari Vaaras, Manu Airaksinen, Okko Räsänen

Self-supervised learning (SSL) is a data-driven learning approach that
utilizes the innate structure of the data to guide the learning process. In
contrast to supervised learning, which depends on external labels, SSL utilizes
the inherent characteristics of the data to produce its own supervisory signal.
However, one frequent issue with SSL methods is representation collapse, where
the model outputs a constant input-invariant feature representation. This issue
hinders the potential application of SSL methods to new data modalities, as
trying to avoid representation collapse wastes researchers' time and effort.
This paper introduces a novel SSL algorithm for time-series data called
Prediction of Functionals from Masked Latents (PFML). Instead of predicting
masked input signals or their latent representations directly, PFML operates by
predicting statistical functionals of the input signal corresponding to masked
embeddings, given a sequence of unmasked embeddings. The algorithm is designed
to avoid representation collapse, rendering it straightforwardly applicable to
different time-series data domains, such as novel sensor modalities in clinical
data. We demonstrate the effectiveness of PFML through complex, real-life
classification tasks across three different data modalities: infant posture and
movement classification from multi-sensor inertial measurement unit data,
emotion recognition from speech data, and sleep stage classification from EEG
data. The results show that PFML is superior to a conceptually similar
pre-existing SSL method and competitive against the current state-of-the-art
SSL method, while also being conceptually simpler and without suffering from
representation collapse.

摘要：自监督学习 (SSL) 是一种数据驱动的学习方法，它利用数据的内在结构来指导学习过程。与依赖外部标签的监督学习相反，SSL 利用数据本身的固有特征来产生自己的监督信号。然而，SSL 方法的一个常见问题是表示坍塌，其中模型输出一个常数输入不变特征表示。这个问题阻碍了 SSL 方法在新的数据模式中的潜在应用，因为试图避免表示坍塌会浪费研究人员的时间和精力。本文介绍了一种针对时间序列数据的新型 SSL 算法，称为掩码潜在变量的功能预测 (PFML)。PFML 不是直接预测掩码输入信号或其潜在表示，而是通过预测输入信号的统计函数（对应于掩码嵌入）来操作，给定一系列未掩码嵌入。该算法旨在避免表示坍塌，使其可以直接应用于不同的时间序列数据域，例如临床数据中的新型传感器模式。我们通过三个不同数据模式的复杂现实生活分类任务展示了 PFML 的有效性：多传感器惯性测量单元数据的婴儿姿势和运动分类、语音数据的语音识别以及脑电图数据的睡眠阶段分类。结果表明，PFML 优于概念上相似的现有 SSL 方法，并且与当前最先进的 SSL 方法具有竞争力，同时在概念上更简单，并且不会出现表示坍塌。

##### **Rethinking Normalization Strategies and Convolutional Kernels for Multimodal Image Fusion**
2411.10036v1 by Dan He, Guofen Wang, Weisheng Li, Yucheng Shu, Wenbo Li, Lijian Yang, Yuping Huang, Feiyan Li

Multimodal image fusion (MMIF) aims to integrate information from different
modalities to obtain a comprehensive image, aiding downstream tasks. However,
existing methods tend to prioritize natural image fusion and focus on
information complementary and network training strategies. They ignore the
essential distinction between natural and medical image fusion and the
influence of underlying components. This paper dissects the significant
differences between the two tasks regarding fusion goals, statistical
properties, and data distribution. Based on this, we rethink the suitability of
the normalization strategy and convolutional kernels for end-to-end
MMIF.Specifically, this paper proposes a mixture of instance normalization and
group normalization to preserve sample independence and reinforce intrinsic
feature correlation.This strategy promotes the potential of enriching feature
maps, thus boosting fusion performance. To this end, we further introduce the
large kernel convolution, effectively expanding receptive fields and enhancing
the preservation of image detail. Moreover, the proposed multipath adaptive
fusion module recalibrates the decoder input with features of various scales
and receptive fields, ensuring the transmission of crucial information.
Extensive experiments demonstrate that our method exhibits state-of-the-art
performance in multiple fusion tasks and significantly improves downstream
applications. The code is available at https://github.com/HeDan-11/LKC-FUNet.

摘要：多模態影像融合 (MMIF) 旨在整合來自不同模態的資訊，以取得全面的影像，協助下游任務。然而，現有方法傾向於優先考慮自然影像融合，並專注於資訊互補和網路訓練策略。它們忽略了自然影像融合與醫學影像融合之間的本質區別，以及底層組成的影響。本文剖析了這兩個任務在融合目標、統計性質和資料分佈方面的顯著差異。基於此，我們重新思考正規化策略和捲積核對端到端 MMIF 的適用性。具體而言，本文提出實例正規化和群組正規化的混合，以保留樣本獨立性並加強內在特徵關聯。此策略提升了豐富特徵圖的潛力，從而提升融合效能。為此，我們進一步引入了大核卷積，有效地擴展感受野並增強影像細節的保留。此外，提出的多路徑自適應融合模組重新校準解碼器輸入，其特徵具有不同的比例和感受野，確保關鍵資訊的傳輸。廣泛的實驗證明，我們的模型在多個融合任務中展現出最先進的效能，並顯著改善下游應用。程式碼可在 https://github.com/HeDan-11/LKC-FUNet 取得。

##### **JRadiEvo: A Japanese Radiology Report Generation Model Enhanced by Evolutionary Optimization of Model Merging**
2411.09933v1 by Kaito Baba, Ryota Yagi, Junichiro Takahashi, Risa Kishikawa, Satoshi Kodera

With the rapid advancement of large language models (LLMs), foundational
models (FMs) have seen significant advancements. Healthcare is one of the most
crucial application areas for these FMs, given the significant time and effort
required for physicians to analyze large volumes of patient data. Recent
efforts have focused on adapting multimodal FMs to the medical domain through
techniques like instruction-tuning, leading to the development of medical
foundation models (MFMs). However, these approaches typically require large
amounts of training data to effectively adapt models to the medical field.
Moreover, most existing models are trained on English datasets, limiting their
practicality in non-English-speaking regions where healthcare professionals and
patients are not always fluent in English. The need for translation introduces
additional costs and inefficiencies. To address these challenges, we propose a
\textbf{J}apanese \textbf{Radi}ology report generation model enhanced by
\textbf{Evo}lutionary optimization of model merging (JRadiEvo). This is the
first attempt to extend a non-medical vision-language foundation model to the
medical domain through evolutionary optimization of model merging. We
successfully created a model that generates accurate Japanese reports from
X-ray images using only 50 translated samples from publicly available data.
This model, developed with highly efficient use of limited data, outperformed
leading models from recent research trained on much larger datasets.
Additionally, with only 8 billion parameters, this relatively compact
foundation model can be deployed locally within hospitals, making it a
practical solution for environments where APIs and other external services
cannot be used due to strict privacy and security requirements.

摘要：<paragraph>隨著大型語言模型 (LLM) 的快速進展，基礎模型 (FM) 已經獲得顯著的進步。醫療保健是這些 FM 最重要的應用領域之一，因為醫生需要花費大量時間和精力來分析大量的患者資料。最近的研究重點在於透過指令微調等技術將多模態 FM 適應到醫療領域，從而開發出醫療基礎模型 (MFM)。然而，這些方法通常需要大量的訓練資料才能有效地將模型適應到醫療領域。此外，大多數現有模型都是針對英語資料集進行訓練，這限制了它們在非英語地區的實用性，那裡的醫療專業人員和患者並不總是精通英語。翻譯的需求引入了額外的成本和低效率。為了應對這些挑戰，我們提出了一個由模型合併的進化優化增強的**J**apanese **Radi**ology 報告生成模型 (JRadiEvo)。這是首次嘗試透過模型合併的進化優化將非醫療視覺語言基礎模型擴展到醫療領域。我們成功地建立了一個模型，僅使用來自公開資料的 50 個翻譯範例，就能從 X 光影像中產生準確的日文報告。這個模型使用有限資料進行高效率的開發，其效能優於最近研究中在更大資料集上訓練出來的領先模型。此外，這個相對精簡的基礎模型只有 80 億個參數，可以在醫院內部進行本地部署，使其成為在嚴格的隱私和安全要求下無法使用 API 和其他外部服務的環境中的實用解決方案。</paragraph>

##### **A Hybrid Artificial Intelligence System for Automated EEG Background Analysis and Report Generation**
2411.09874v1 by Chin-Sung Tung, Sheng-Fu Liang, Shu-Feng Chang, Chung-Ping Young

Electroencephalography (EEG) plays a crucial role in the diagnosis of various
neurological disorders. However, small hospitals and clinics often lack
advanced EEG signal analysis systems and are prone to misinterpretation in
manual EEG reading. This study proposes an innovative hybrid artificial
intelligence (AI) system for automatic interpretation of EEG background
activity and report generation. The system combines deep learning models for
posterior dominant rhythm (PDR) prediction, unsupervised artifact removal, and
expert-designed algorithms for abnormality detection. For PDR prediction, 1530
labeled EEGs were used, and the best ensemble model achieved a mean absolute
error (MAE) of 0.237, a root mean square error (RMSE) of 0.359, an accuracy of
91.8% within a 0.6Hz error, and an accuracy of 99% within a 1.2Hz error. The AI
system significantly outperformed neurologists in detecting generalized
background slowing (p = 0.02; F1: AI 0.93, neurologists 0.82) and demonstrated
improved focal abnormality detection, although not statistically significant (p
= 0.79; F1: AI 0.71, neurologists 0.55). Validation on both an internal dataset
and the Temple University Abnormal EEG Corpus showed consistent performance
(F1: 0.884 and 0.835, respectively; p = 0.66), demonstrating generalizability.
The use of large language models (LLMs) for report generation demonstrated 100%
accuracy, verified by three other independent LLMs. This hybrid AI system
provides an easily scalable and accurate solution for EEG interpretation in
resource-limited settings, assisting neurologists in improving diagnostic
accuracy and reducing misdiagnosis rates.

摘要：腦電圖（EEG）在診斷各種神經疾病中扮演至關重要的角色。然而，小型醫院和診所通常缺乏進階的 EEG 訊號分析系統，且容易在手動判讀 EEG 時產生誤解。本研究提出一個創新的混合人工智慧（AI）系統，用於自動判讀 EEG 背景活動並產生報告。此系統結合深度學習模型，用於預測後優勢律動（PDR）、非監督人工製品移除，以及專家設計的異常偵測演算法。在 PDR 預測中，使用了 1530 個標記 EEG，最佳的整體模型達到了 0.237 的平均絕對誤差（MAE）、0.359 的均方根誤差（RMSE）、91.8% 的 0.6Hz 誤差準確度，以及 99% 的 1.2Hz 誤差準確度。AI 系統在偵測廣泛背景減慢方面明顯優於神經學家（p = 0.02；F1：AI 0.93，神經學家 0.82），並展現出改善的局部異常偵測，儘管沒有統計意義（p = 0.79；F1：AI 0.71，神經學家 0.55）。在內部資料集和 Temple University 異常 EEG 語料庫上的驗證顯示了一致的效能（F1：分別為 0.884 和 0.835；p = 0.66），證明了其普遍性。使用大型語言模型（LLM）來產生報告證明了 100% 的準確度，並由其他三個獨立的 LLM 驗證。此混合 AI 系統提供了一個易於擴充且準確的解決方案，用於在資源有限的環境中進行 EEG 判讀，協助神經學家提高診斷準確度並降低誤診率。

##### **A Benchmark for Long-Form Medical Question Answering**
2411.09834v2 by Pedram Hosseini, Jessica M. Sin, Bing Ren, Bryceton G. Thomas, Elnaz Nouri, Ali Farahanchi, Saeed Hassanpour

There is a lack of benchmarks for evaluating large language models (LLMs) in
long-form medical question answering (QA). Most existing medical QA evaluation
benchmarks focus on automatic metrics and multiple-choice questions. While
valuable, these benchmarks fail to fully capture or assess the complexities of
real-world clinical applications where LLMs are being deployed. Furthermore,
existing studies on evaluating long-form answer generation in medical QA are
primarily closed-source, lacking access to human medical expert annotations,
which makes it difficult to reproduce results and enhance existing baselines.
In this work, we introduce a new publicly available benchmark featuring
real-world consumer medical questions with long-form answer evaluations
annotated by medical doctors. We performed pairwise comparisons of responses
from various open and closed-source medical and general-purpose LLMs based on
criteria such as correctness, helpfulness, harmfulness, and bias. Additionally,
we performed a comprehensive LLM-as-a-judge analysis to study the alignment
between human judgments and LLMs. Our preliminary results highlight the strong
potential of open LLMs in medical QA compared to leading closed models. Code &
Data: https://github.com/lavita-ai/medical-eval-sphere

摘要：大型語言模型 (LLM) 在長篇醫療問題解答 (QA) 中的評估基準有所不足。現有的醫療 QA 評估基準大多集中在自動化指標和多選題上。儘管有價值，但這些基準無法完全捕捉或評估 LLM 部署的現實臨床應用的複雜性。此外，現有的關於評估醫療 QA 中長篇答案生成的研究所主要是閉源的，缺乏對人類醫學專家註釋的訪問權限，這使得難以重現結果並增強現有的基準。在這項工作中，我們引入了一個新的公開基準，其中包含實際的消費者醫療問題，以及由醫生註釋的長篇答案評估。我們根據正確性、有用性、有害性和偏差等標準，對來自各種開放和閉源醫療和通用 LLM 的回應進行了成對比較。此外，我們進行了一項全面的 LLM 作為評審的分析，以研究人類判斷和 LLM 之間的一致性。我們的初步結果突出了開放式 LLM 在醫療 QA 中的強大潛力，與領先的閉源模型相比。程式碼和資料：https://github.com/lavita-ai/medical-eval-sphere

##### **A Self-Supervised Model for Multi-modal Stroke Risk Prediction**
2411.09822v1 by Camille Delgrange, Olga Demler, Samia Mora, Bjoern Menze, Ezequiel de la Rosa, Neda Davoudi

Predicting stroke risk is a complex challenge that can be enhanced by
integrating diverse clinically available data modalities. This study introduces
a self-supervised multimodal framework that combines 3D brain imaging, clinical
data, and image-derived features to improve stroke risk prediction prior to
onset. By leveraging large unannotated clinical datasets, the framework
captures complementary and synergistic information across image and tabular
data modalities. Our approach is based on a contrastive learning framework that
couples contrastive language-image pretraining with an image-tabular matching
module, to better align multimodal data representations in a shared latent
space. The model is trained on the UK Biobank, which includes structural brain
MRI and clinical data. We benchmark its performance against state-of-the-art
unimodal and multimodal methods using tabular, image, and image-tabular
combinations under diverse frozen and trainable model settings. The proposed
model outperformed self-supervised tabular (image) methods by 2.6% (2.6%) in
ROC-AUC and by 3.3% (5.6%) in balanced accuracy. Additionally, it showed a 7.6%
increase in balanced accuracy compared to the best multimodal supervised model.
Through interpretable tools, our approach demonstrated better integration of
tabular and image data, providing richer and more aligned embeddings.
Gradient-weighted Class Activation Mapping heatmaps further revealed activated
brain regions commonly associated in the literature with brain aging, stroke
risk, and clinical outcomes. This robust self-supervised multimodal framework
surpasses state-of-the-art methods for stroke risk prediction and offers a
strong foundation for future studies integrating diverse data modalities to
advance clinical predictive modelling.

摘要：<paragraph>預測中風風險是一項複雜的挑戰，可以透過整合多樣化的臨床可用數據模式來加強。本研究介紹了一個自監督多模式架構，結合 3D 大腦影像、臨床數據和影像衍生特徵，以在發作前改善中風風險預測。透過利用大量的未標記臨床數據集，該架構擷取了影像和表格數據模式之間的互補和協同資訊。我們的做法基於對比學習架構，將對比語言影像預訓練與影像表格匹配模組結合，以在共享潛在空間中更好地對齊多模式數據表示。該模型是在英國生物銀行中訓練的，其中包括結構性腦部 MRI 和臨床數據。我們使用表格、影像和影像表格組合，在不同的凍結和可訓練模型設定下，根據最先進的單模式和多模式方法對其效能進行基準測試。所提出的模型在 ROC-AUC 中比自監督表格（影像）方法高出 2.6%（2.6%），在平衡準確度中高出 3.3%（5.6%）。此外，與最佳多模式監督模型相比，它的平衡準確度提高了 7.6%。透過可解釋的工具，我們的做法證明了表格和影像數據的整合性更好，提供了更豐富且更一致的嵌入。梯度加權類別啟用對應熱圖進一步揭示了文獻中通常與腦部老化、中風風險和臨床結果相關的活化腦區。這個強健的自監督多模式架構超越了中風風險預測的最新方法，並為整合不同數據模式以推進臨床預測建模的未來研究提供了堅實的基礎。</paragraph>

##### **Deep Learning for Fetal Inflammatory Response Diagnosis in the Umbilical Cord**
2411.09767v1 by Marina A. Ayad, Ramin Nateghi, Abhishek Sharma, Lawrence Chillrud, Tilly Seesillapachai, Lee A. D. Cooper, Jeffery A. Goldstein

Inflammation of the umbilical cord can be seen as a result of ascending
intrauterine infection or other inflammatory stimuli. Acute fetal inflammatory
response (FIR) is characterized by infiltration of the umbilical cord by fetal
neutrophils, and can be associated with neonatal sepsis or fetal inflammatory
response syndrome. Recent advances in deep learning in digital pathology have
demonstrated favorable performance across a wide range of clinical tasks, such
as diagnosis and prognosis. In this study we classified FIR from whole slide
images (WSI). We digitized 4100 histological slides of umbilical cord stained
with hematoxylin and eosin(H&E) and extracted placental diagnoses from the
electronic health record. We build models using attention-based whole slide
learning models. We compared strategies between features extracted by a model
(ConvNeXtXLarge) pretrained on non-medical images (ImageNet), and one
pretrained using histopathology images (UNI). We trained multiple iterations of
each model and combined them into an ensemble. The predictions from the
ensemble of models trained using UNI achieved an overall balanced accuracy of
0.836 on the test dataset. In comparison, the ensembled predictions using
ConvNeXtXLarge had a lower balanced accuracy of 0.7209. Heatmaps generated from
top accuracy model appropriately highlighted arteritis in cases of FIR 2. In
FIR 1, the highest performing model assigned high attention to areas of
activated-appearing stroma in Wharton's Jelly. However, other high-performing
models assigned attention to umbilical vessels. We developed models for
diagnosis of FIR from placental histology images, helping reduce interobserver
variability among pathologists. Future work may examine the utility of these
models for identifying infants at risk of systemic inflammatory response or
early onset neonatal sepsis.

摘要：臍帶發炎可視為上行性子宮內感染或其他發炎刺激所致。急性胎兒發炎反應 (FIR) 的特徵是胎兒中性球浸潤臍帶，可能與新生兒敗血症或胎兒發炎反應症候群有關。數位病理學中深度學習的最新進展已證明在廣泛的臨床任務中表現良好，例如診斷和預後。在這項研究中，我們從全切片影像 (WSI) 中分類 FIR。我們將 4100 張用蘇木精和曙紅 (H&E) 染色的臍帶組織切片數位化，並從電子病歷中提取胎盤診斷。我們使用基於注意力的全切片學習模型建立模型。我們比較了非醫療影像 (ImageNet) 預訓練模型 (ConvNeXtXLarge) 和使用組織病理學影像 (UNI) 預訓練模型提取的特徵之間的策略。我們訓練了每個模型的多次迭代，並將它們組合成一個整體。使用 UNI 訓練的模型整體的預測在測試資料集上達到 0.836 的整體平衡準確度。相比之下，使用 ConvNeXtXLarge 的整體預測的平衡準確度較低，為 0.7209。從準確度最高的模型產生的熱圖適當地突出了 FIR 2 病例中的動脈炎。在 FIR 1 中，表現最好的模型將高度關注分配給沃頓氏膠中的活化外觀基質區域。然而，其他表現良好的模型將注意力分配給臍帶血管。我們開發了從胎盤組織學影像診斷 FIR 的模型，有助於減少病理學家之間的觀察者間變異性。未來的研究可能會探討這些模型在識別有全身性發炎反應風險或早期發作新生兒敗血症的嬰兒方面的效用。

##### **Med-Bot: An AI-Powered Assistant to Provide Accurate and Reliable Medical Information**
2411.09648v1 by Ahan Bhatt, Nandan Vaghela

This paper introduces Med-Bot, an AI-powered chatbot designed to provide
users with accurate and reliable medical information. Utilizing advanced
libraries and frameworks such as PyTorch, Chromadb, Langchain and Autogptq,
Med-Bot is built to handle the complexities of natural language understanding
in a healthcare context. The integration of llamaassisted data processing and
AutoGPT-Q provides enhanced performance in processing and responding to queries
based on PDFs of medical literature, ensuring that users receive precise and
trustworthy information. This research details the methodologies employed in
developing Med-Bot and evaluates its effectiveness in disseminating healthcare
information.

摘要：本文介紹 Med-Bot，一個由人工智慧驅動的聊天機器人，旨在為使用者提供準確且可靠的醫療資訊。Med-Bot 利用進階函式庫和框架，例如 PyTorch、Chromadb、Langchain 和 Autogptq，建構來處理醫療保健環境中自然語言理解的複雜性。整合了 Llama 輔助資料處理和 AutoGPT-Q，在處理和回應基於醫學文獻 PDF 的查詢時提供了增強的效能，確保使用者收到精確且可信賴的資訊。本研究詳細說明了開發 Med-Bot 所採用的方法，並評估其在傳播醫療保健資訊方面的有效性。

##### **An Explainable Attention Model for Cervical Precancer Risk Classification using Colposcopic Images**
2411.09469v1 by Smith K. Khare, Berit Bargum Booth, Victoria Blanes-Vidal, Lone Kjeld Petersen, Esmaeil S. Nadimi

Cervical cancer remains a major worldwide health issue, with early
identification and risk assessment playing critical roles in effective
preventive interventions. This paper presents the Cervix-AID-Net model for
cervical precancer risk classification. The study designs and evaluates the
proposed Cervix-AID-Net model based on patients colposcopy images. The model
comprises a Convolutional Block Attention Module (CBAM) and convolutional
layers that extract interpretable and representative features of colposcopic
images to distinguish high-risk and low-risk cervical precancer. In addition,
the proposed Cervix-AID-Net model integrates four explainable techniques,
namely gradient class activation maps, Local Interpretable Model-agnostic
Explanations, CartoonX, and pixel rate distortion explanation based on output
feature maps and input features. The evaluation using holdout and ten-fold
cross-validation techniques yielded a classification accuracy of 99.33\% and
99.81\%. The analysis revealed that CartoonX provides meticulous explanations
for the decision of the Cervix-AID-Net model due to its ability to provide the
relevant piece-wise smooth part of the image. The effect of Gaussian noise and
blur on the input shows that the performance remains unchanged up to Gaussian
noise of 3\% and blur of 10\%, while the performance reduces thereafter. A
comparison study of the proposed model's performance compared to other deep
learning approaches highlights the Cervix-AID-Net model's potential as a
supplemental tool for increasing the effectiveness of cervical precancer risk
assessment. The proposed method, which incorporates the CBAM and explainable
artificial integration, has the potential to influence cervical cancer
prevention and early detection, improving patient outcomes and lowering the
worldwide burden of this preventable disease.

摘要：子宮頸癌仍然是全球主要的健康議題，早期辨識和風險評估在有效的預防性干預措施中扮演著關鍵性的角色。本文提出子宮頸輔助網路模型，用於子宮頸癌前病變風險分類。本研究基於病患的陰道鏡影像設計並評估所提出的子宮頸輔助網路模型。該模型包含卷積區塊注意力模組 (CBAM) 和卷積層，用於萃取可解釋且具代表性的陰道鏡影像特徵，以區分高風險和低風險的子宮頸癌前病變。此外，所提出的子宮頸輔助網路模型整合了四種可解釋的技術，分別為梯度類別激活圖、局部可解釋模型不可知解釋、CartoonX 和基於輸出特徵圖和輸入特徵的像素率失真解釋。使用留存法和十倍交叉驗證技術進行評估，得到 99.33% 和 99.81% 的分類準確率。分析顯示，CartoonX 能夠提供影像中相關的分段平滑部分，因此能為子宮頸輔助網路模型的決策提供細緻的解釋。高斯噪聲和模糊對輸入的影響顯示，在高斯噪聲低於 3% 和模糊低於 10% 的情況下，效能保持不變，但之後效能便會下降。所提出的模型效能與其他深度學習方法的比較研究，突顯了子宮頸輔助網路模型作為補充工具的潛力，用於提高子宮頸癌前病變風險評估的有效性。所提出的方法結合了 CBAM 和可解釋的人工整合，有潛力影響子宮頸癌的預防和早期偵測，改善病患的預後並降低這種可預防疾病在全球的負擔。

##### **Script-centric behavior understanding for assisted autism spectrum disorder diagnosis**
2411.09413v1 by Wenxing Liu, Yueran Pan, Ming Li

Observing and analyzing children's social behaviors is crucial for the early
diagnosis of Autism Spectrum Disorders (ASD). This work focuses on
automatically detecting ASD using computer vision techniques and large language
models (LLMs). Existing methods typically rely on supervised learning. However,
the scarcity of ASD diagnostic datasets and the lack of interpretability in
diagnostic results significantly limits its clinical application. To address
these challenges, we introduce a novel unsupervised approach based on
script-centric behavior understanding. Our pipeline converts video content into
scripts that describe the behavior of characters, leveraging the
generalizability of large language models to detect ASD in a zero-shot or
few-shot manner. Specifically, we propose a scripts transcription module for
multimodal behavior data textualization and a domain prompts module to bridge
LLMs. Our method achieves an accuracy of 92.00\% in diagnosing ASD in children
with an average age of 24 months, surpassing the performance of supervised
learning methods by 3.58\% absolutely. Extensive experiments confirm the
effectiveness of our approach and suggest its potential for advancing ASD
research through LLMs.

摘要：觀察和分析兒童的社交行為對於自閉症譜系障礙 (ASD) 的早期診斷至關重要。這項工作著重於使用電腦視覺技術和大語言模型 (LLM) 自動偵測 ASD。現有方法通常依賴於監督式學習。然而，ASD 診斷資料集的稀少性和診斷結果缺乏可解釋性，顯著地限制了其臨床應用。為了應對這些挑戰，我們引入了一種基於以腳本為中心的行為理解的新型非監督式方法。我們的管道將影片內容轉換成描述角色行為的腳本，利用大語言模型的泛化性以零次或少次學習的方式偵測 ASD。具體來說，我們提出了一個腳本轉錄模組用於多模態行為資料文字化，以及一個網域提示模組來橋接 LLM。我們的模型在診斷平均年齡為 24 個月的兒童 ASD 時，達到了 92.00% 的準確率，絕對優於監督式學習方法 3.58%。大量的實驗證實了我們方法的有效性，並表明其通過 LLM 推動 ASD 研究的潛力。

##### **NFRs in Medical Imaging**
2411.09718v1 by Amanda Vallentin

The diagnostic imaging departments are under great pressure due to a growing
workload. The number of required scans is growing and there is a shortage of
qualified labor. AI solutions for medical imaging applications have shown great
potential. However, very few diagnostic imaging models have been approved for
hospital use and even fewer are being implemented at the hospitals. The most
common reason why software projects fail is poor requirement engineering,
especially non-functional requirements (NFRs) can be detrimental to a project.
Research shows that machine learning professionals struggle to work with NFRs
and that there is a need to adapt NFR frameworks to machine learning, AI-based,
software. This study uses qualitative methods to interact with key stakeholders
to identify which types of NFRs are important for medical imaging applications.
The study was done on a single Danish hospital and found that NFRs of type
Efficiency, Accuracy, Interoperability, Reliability, Usability, Adaptability,
and Fairness were important to the stakeholders. Especially Efficiency since
the diagnostic imaging department is trying to spend as little time as possible
on each scan.

摘要：由於工作負載增加，診斷影像部門承受著極大的壓力。所需掃描的數量正在增加，而且合格的勞動力短缺。醫療影像應用的人工智慧解決方案顯示出巨大的潛力。然而，很少有診斷影像模型被批准用於醫院，甚至更少被實施於醫院。軟體專案失敗的最常見原因是需求工程不佳，特別是非功能性需求 (NFR) 可能對專案有害。研究顯示，機器學習專業人員難以使用 NFR，並且需要將 NFR 框架調整為機器學習、基於 AI 的軟體。本研究使用定性方法與主要利害關係人互動，以找出哪些類型的 NFR 對醫學影像應用程式很重要。該研究在一家丹麥醫院進行，發現效率、準確性、互操作性、可靠性、可用性、適應性和公平性類型的 NFR 對利害關係人很重要。特別是效率，因為診斷影像部門正努力盡可能減少每項掃描所花的時間。

##### **Comprehensive and Practical Evaluation of Retrieval-Augmented Generation Systems for Medical Question Answering**
2411.09213v1 by Nghia Trung Ngo, Chien Van Nguyen, Franck Dernoncourt, Thien Huu Nguyen

Retrieval-augmented generation (RAG) has emerged as a promising approach to
enhance the performance of large language models (LLMs) in knowledge-intensive
tasks such as those from medical domain. However, the sensitive nature of the
medical domain necessitates a completely accurate and trustworthy system. While
existing RAG benchmarks primarily focus on the standard retrieve-answer
setting, they overlook many practical scenarios that measure crucial aspects of
a reliable medical system. This paper addresses this gap by providing a
comprehensive evaluation framework for medical question-answering (QA) systems
in a RAG setting for these situations, including sufficiency, integration, and
robustness. We introduce Medical Retrieval-Augmented Generation Benchmark
(MedRGB) that provides various supplementary elements to four medical QA
datasets for testing LLMs' ability to handle these specific scenarios.
Utilizing MedRGB, we conduct extensive evaluations of both state-of-the-art
commercial LLMs and open-source models across multiple retrieval conditions.
Our experimental results reveals current models' limited ability to handle
noise and misinformation in the retrieved documents. We further analyze the
LLMs' reasoning processes to provides valuable insights and future directions
for developing RAG systems in this critical medical domain.

摘要：檢索增強生成（RAG）已成為一種有前途的方法，可增強大型語言模型（LLM）在知識密集型任務中的效能，例如醫療領域的任務。然而，醫療領域的敏感性質需要一個完全準確且值得信賴的系統。雖然現有的 RAG 評量基準主要著重於標準檢索回答設定，但它們忽略了許多衡量可靠醫療系統關鍵面向的實際情境。本文透過提供一個全面的評量架構來解決這個差距，這個架構適用於這些情境的 RAG 設定中的醫療問答（QA）系統，包括充足性、整合性與穩健性。我們引入了醫療檢索增強生成評量基準（MedRGB），它為四個醫療 QA 資料集提供了各種補充元素，以測試 LLM 處理這些特定情境的的能力。利用 MedRGB，我們對多種檢索條件下的最新商業 LLM 和開源模型進行了廣泛的評量。我們的實驗結果顯示，目前模型處理檢索文件中的雜訊和錯誤資訊的能力有限。我們進一步分析了 LLM 的推理程序，為在這個關鍵的醫療領域開發 RAG 系統提供了寶貴的見解和未來的方向。

##### **Advancing Diffusion Models: Alias-Free Resampling and Enhanced Rotational Equivariance**
2411.09174v1 by Md Fahim Anjum

Recent advances in image generation, particularly via diffusion models, have
led to impressive improvements in image synthesis quality. Despite this,
diffusion models are still challenged by model-induced artifacts and limited
stability in image fidelity. In this work, we hypothesize that the primary
cause of this issue is the improper resampling operation that introduces
aliasing in the diffusion model and a careful alias-free resampling dictated by
image processing theory can improve the model's performance in image synthesis.
We propose the integration of alias-free resampling layers into the UNet
architecture of diffusion models without adding extra trainable parameters,
thereby maintaining computational efficiency. We then assess whether these
theory-driven modifications enhance image quality and rotational equivariance.
Our experimental results on benchmark datasets, including CIFAR-10, MNIST, and
MNIST-M, reveal consistent gains in image quality, particularly in terms of FID
and KID scores. Furthermore, we propose a modified diffusion process that
enables user-controlled rotation of generated images without requiring
additional training. Our findings highlight the potential of theory-driven
enhancements such as alias-free resampling in generative models to improve
image quality while maintaining model efficiency and pioneer future research
directions to incorporate them into video-generating diffusion models, enabling
deeper exploration of the applications of alias-free resampling in generative
modeling.

摘要：影像生成技術的最新進展，特別是透過擴散模型，已大幅提升影像合成品質。儘管如此，擴散模型仍受限於模型引發的人工製品，且影像保真度穩定性有限。在這項工作中，我們假設此問題的主要原因是不適當的重新取樣運算，這會在擴散模型中引入混疊，而由影像處理理論指導的仔細無混疊重新取樣可以提升模型在影像合成的效能。我們建議將無混疊重新取樣層整合到擴散模型的 UNet 架構中，而無須增加額外的可訓練參數，進而維持運算效率。接著我們評估這些理論驅動的修改是否能提升影像品質和旋轉等變性。我們在基準資料集（包括 CIFAR-10、MNIST 和 MNIST-M）上的實驗結果顯示，影像品質獲得一致的提升，特別是在 FID 和 KID 分數方面。此外，我們提出一個修改過的擴散程序，它能讓使用者控制生成影像的旋轉，而無需額外訓練。我們的發現突顯了理論驅動的強化（例如無混疊重新取樣）在生成模型中的潛力，它能在維持模型效率的同時提升影像品質，並為未來研究開拓方向，將其納入生成影片的擴散模型中，進一步探索無混疊重新取樣在生成模型中的應用。

##### **Artificial Intelligence for Infectious Disease Prediction and Prevention: A Comprehensive Review**
2411.10486v1 by Selestine Melchane, Youssef Elmir, Farid Kacimi, Larbi Boubchir

Artificial Intelligence (AI) and infectious diseases prediction have recently
experienced a common development and advancement. Machine learning (ML)
apparition, along with deep learning (DL) emergence, extended many approaches
against diseases apparition and their spread. And despite their outstanding
results in predicting infectious diseases, conflicts appeared regarding the
types of data used and how they can be studied, analyzed, and exploited using
various emerging methods. This has led to some ongoing discussions in the
field. This research aims not only to provide an overview of what has been
accomplished, but also to highlight the difficulties related to the types of
data used, and the learning methods applied for each research objective. It
categorizes these contributions into three areas: predictions using Public
Health Data to prevent the spread of a transmissible disease within a region;
predictions using Patients' Medical Data to detect whether a person is infected
by a transmissible disease; and predictions using both Public and patient
medical data to estimate the extent of disease spread in a population. The
paper also critically assesses the potential of AI and outlines its limitations
in infectious disease management.

摘要：人工智能 (AI) 和傳染病預測最近經歷了一段共同發展和進步。機器學習 (ML) 的出現，以及深度學習 (DL) 的興起，擴展了許多對抗疾病出現及其傳播的方法。儘管它們在預測傳染病方面取得了傑出的成果，但對於所使用數據的類型以及如何使用各種新興方法對其進行研究、分析和利用，出現了爭議。這導致了該領域的一些持續討論。本研究不僅旨在概述已取得的成果，還旨在強調與所使用數據類型相關的難點，以及針對每個研究目標應用的學習方法。它將這些貢獻歸類為三個領域：使用公共衛生數據來預防傳染病在一個地區內傳播的預測；使用患者醫療數據來檢測一個人是否感染了傳染病的預測；以及使用公共和患者醫療數據來估計疾病在人群中傳播程度的預測。本文還批判性地評估了人工智能的潛力，並概述了它在傳染病管理中的局限性。

##### **The Limited Impact of Medical Adaptation of Large Language and Vision-Language Models**
2411.08870v1 by Daniel P. Jeong, Pranav Mani, Saurabh Garg, Zachary C. Lipton, Michael Oberst

Several recent works seek to develop foundation models specifically for
medical applications, adapting general-purpose large language models (LLMs) and
vision-language models (VLMs) via continued pretraining on publicly available
biomedical corpora. These works typically claim that such domain-adaptive
pretraining (DAPT) improves performance on downstream medical tasks, such as
answering medical licensing exam questions. In this paper, we compare ten
public "medical" LLMs and two VLMs against their corresponding base models,
arriving at a different conclusion: all medical VLMs and nearly all medical
LLMs fail to consistently improve over their base models in the zero-/few-shot
prompting and supervised fine-tuning regimes for medical question-answering
(QA). For instance, across all tasks and model pairs we consider in the 3-shot
setting, medical LLMs only outperform their base models in 22.7% of cases,
reach a (statistical) tie in 36.8% of cases, and are significantly worse than
their base models in the remaining 40.5% of cases. Our conclusions are based on
(i) comparing each medical model head-to-head, directly against the
corresponding base model; (ii) optimizing the prompts for each model separately
in zero-/few-shot prompting; and (iii) accounting for statistical uncertainty
in comparisons. While these basic practices are not consistently adopted in the
literature, our ablations show that they substantially impact conclusions.
Meanwhile, we find that after fine-tuning on specific QA tasks, medical LLMs
can show performance improvements, but the benefits do not carry over to tasks
based on clinical notes. Our findings suggest that state-of-the-art
general-domain models may already exhibit strong medical knowledge and
reasoning capabilities, and offer recommendations to strengthen the conclusions
of future studies.

摘要：<paragraph>最近有許多研究專門開發醫療應用基礎模型，透過持續預訓練公開的生物醫學語料庫，改編通用大型語言模型 (LLM) 和視覺語言模型 (VLM)。這些研究通常聲稱此類領域自適應預訓練 (DAPT) 能提升下游醫療任務的效能，例如回答醫療執照考試題目。在本文中，我們比較了十個公開的「醫療」LLM 和兩個 VLM，並將其與對應的基本模型進行比較，得出了不同的結論：所有醫療 VLM 和幾乎所有醫療 LLM 都無法在醫療問題解答 (QA) 的零次/小樣本提示和監督微調機制中持續優於其基本模型。例如，在我們在 3 次取樣設定中考量的所有任務和模型配對中，醫療 LLM 僅在 22.7% 的案例中優於其基本模型，在 36.8% 的案例中達到（統計）平手，而在其餘 40.5% 的案例中則顯著低於其基本模型。我們的結論基於 (i) 將每個醫療模型與對應的基本模型進行一對一比較；(ii) 在零次/小樣本提示中分別針對每個模型最佳化提示；以及 (iii) 在比較中考量統計不確定性。儘管這些基本做法並未在文獻中一致採用，但我們的消融研究顯示，它們對結論有重大影響。同時，我們發現，在針對特定 QA 任務進行微調後，醫療 LLM 可以展現效能提升，但這些好處並未延續到基於臨床筆記的任務。我們的研究結果表明，最先進的通用領域模型可能已經展現出強大的醫療知識和推理能力，並提供建議以強化未來研究的結論。</paragraph>

##### **MVKTrans: Multi-View Knowledge Transfer for Robust Multiomics Classification**
2411.08703v1 by Shan Cong, Zhiling Sang, Hongwei Liu, Haoran Luo, Xin Wang, Hong Liang, Jie Hao, Xiaohui Yao

The distinct characteristics of multiomics data, including complex
interactions within and across biological layers and disease heterogeneity
(e.g., heterogeneity in etiology and clinical symptoms), drive us to develop
novel designs to address unique challenges in multiomics prediction. In this
paper, we propose the multi-view knowledge transfer learning (MVKTrans)
framework, which transfers intra- and inter-omics knowledge in an adaptive
manner by reviewing data heterogeneity and suppressing bias transfer, thereby
enhancing classification performance. Specifically, we design a graph
contrastive module that is trained on unlabeled data to effectively learn and
transfer the underlying intra-omics patterns to the supervised task. This
unsupervised pretraining promotes learning general and unbiased representations
for each modality, regardless of the downstream tasks. In light of the varying
discriminative capacities of modalities across different diseases and/or
samples, we introduce an adaptive and bi-directional cross-omics distillation
module. This module automatically identifies richer modalities and facilitates
dynamic knowledge transfer from more informative to less informative omics,
thereby enabling a more robust and generalized integration. Extensive
experiments on four real biomedical datasets demonstrate the superior
performance and robustness of MVKTrans compared to the state-of-the-art. Code
and data are available at https://github.com/Yaolab-fantastic/MVKTrans.

摘要：多組學資料的獨特特徵，包括生物層內和層間的複雜交互作用和疾病異質性（例如，病因和臨床症狀的異質性），促使我們開發新穎的設計來應對多組學預測中的獨特挑戰。在本文中，我們提出了多視角知識遷移學習 (MVKTrans) 框架，它通過審查數據異質性和抑制偏差轉移，以自適應的方式傳遞組內和組間知識，從而增強分類性能。具體來說，我們設計了一個圖對比模組，在未標記數據上進行訓練，以有效地學習和將組內模式轉移到監督任務中。這種無監督的預訓練促進了學習一般且無偏差的表示，適用於每個模態，無論下游任務為何。鑑於不同疾病和/或樣本中模態的不同辨別能力，我們引入了一個自適應且雙向的組間知識蒸餾模組。此模組自動識別更豐富的模態，並促進從更有資訊性的組學到資訊較少的組學的動態知識轉移，從而實現更強健且更廣泛的整合。對四個真實生物醫學資料集的廣泛實驗證明了 MVKTrans 與最先進技術相比具有優異的性能和強健性。程式碼和資料可在 https://github.com/Yaolab-fantastic/MVKTrans 取得。

##### **TRACE: Transformer-based Risk Assessment for Clinical Evaluation**
2411.08701v1 by Dionysis Christopoulos, Sotiris Spanos, Valsamis Ntouskos, Konstantinos Karantzalos

We present TRACE (Transformer-based Risk Assessment for Clinical Evaluation),
a novel method for clinical risk assessment based on clinical data, leveraging
the self-attention mechanism for enhanced feature interaction and result
interpretation. Our approach is able to handle different data modalities,
including continuous, categorical and multiple-choice (checkbox) attributes.
The proposed architecture features a shared representation of the clinical data
obtained by integrating specialized embeddings of each data modality, enabling
the detection of high-risk individuals using Transformer encoder layers. To
assess the effectiveness of the proposed method, a strong baseline based on
non-negative multi-layer perceptrons (MLPs) is introduced. The proposed method
outperforms various baselines widely used in the domain of clinical risk
assessment, while effectively handling missing values. In terms of
explainability, our Transformer-based method offers easily interpretable
results via attention weights, further enhancing the clinicians'
decision-making process.

摘要：我們提出 TRACE（臨床評估的基於 Transformer 的風險評估），這是一種基於臨床數據的臨床風險評估新方法，利用自注意力機制增強特徵交互和結果解讀。我們的做法能夠處理不同的數據模式，包括連續、分類和多選（核取方塊）屬性。提議的架構特徵是通過整合每個數據模式的專用嵌入來獲得臨床數據的共享表示，從而能夠使用 Transformer 編碼器層檢測高風險個體。為了評估所提出方法的有效性，引入了基於非負多層感知器 (MLP) 的強大基線。所提出的方法優於臨床風險評估領域中廣泛使用的各種基線，同時有效地處理缺失值。在可解釋性方面，我們基於 Transformer 的方法通過注意力權重提供了易於解釋的結果，進一步增強了臨床醫生的決策制定過程。

##### **Rethinking negative sampling in content-based news recommendation**
2411.08700v1 by Miguel Ângelo Rebelo, João Vinagre, Ivo Pereira, Álvaro Figueira

News recommender systems are hindered by the brief lifespan of articles, as
they undergo rapid relevance decay. Recent studies have demonstrated the
potential of content-based neural techniques in tackling this problem. However,
these models often involve complex neural architectures and often lack
consideration for negative examples. In this study, we posit that the careful
sampling of negative examples has a big impact on the model's outcome. We
devise a negative sampling technique that not only improves the accuracy of the
model but also facilitates the decentralization of the recommendation system.
The experimental results obtained using the MIND dataset demonstrate that the
accuracy of the method under consideration can compete with that of
State-of-the-Art models. The utilization of the sampling technique is essential
in reducing model complexity and accelerating the training process, while
maintaining a high level of accuracy. Finally, we discuss how decentralized
models can help improve privacy and scalability.

摘要：新聞推薦系統受到文章生命週期短暫的阻礙，因為它們會快速衰退。最近的研究已證明基於內容的神經技術在解決這個問題上的潛力。然而，這些模型通常涉及複雜的神經架構，而且常常缺乏對負面範例的考量。在這項研究中，我們假設負面範例的仔細抽樣對模型的結果有很大的影響。我們設計了一種負面抽樣技術，它不僅提高了模型的準確性，還促进了推薦系統的分散化。使用 MIND 資料集獲得的實驗結果證明，所考慮方法的準確性可以與最先進的模型相媲美。抽樣技術的使用對於降低模型複雜性和加速訓練過程至關重要，同時保持高準確度。最後，我們討論了分散式模型如何有助於改善隱私和可擴展性。

##### **A Survey on Vision Autoregressive Model**
2411.08666v2 by Kai Jiang, Jiaxing Huang

Autoregressive models have demonstrated great performance in natural language
processing (NLP) with impressive scalability, adaptability and
generalizability. Inspired by their notable success in NLP field,
autoregressive models have been intensively investigated recently for computer
vision, which perform next-token predictions by representing visual data as
visual tokens and enables autoregressive modelling for a wide range of vision
tasks, ranging from visual generation and visual understanding to the very
recent multimodal generation that unifies visual generation and understanding
with a single autoregressive model. This paper provides a systematic review of
vision autoregressive models, including the development of a taxonomy of
existing methods and highlighting their major contributions, strengths, and
limitations, covering various vision tasks such as image generation, video
generation, image editing, motion generation, medical image analysis, 3D
generation, robotic manipulation, unified multimodal generation, etc. Besides,
we investigate and analyze the latest advancements in autoregressive models,
including thorough benchmarking and discussion of existing methods across
various evaluation datasets. Finally, we outline key challenges and promising
directions for future research, offering a roadmap to guide further
advancements in vision autoregressive models.

摘要：自回归模型在自然语言处理 (NLP) 中展现了极佳的性能，具有令人印象深刻的可扩展性、适应性和泛化性。受其在 NLP 领域的显著成功启发，自回归模型最近在计算机视觉领域得到了深入研究，通过将视觉数据表示为视觉标记来执行下一个标记预测，并为广泛的视觉任务启用自回归建模，从视觉生成和视觉理解到最近将视觉生成和理解统一到一个自回归模型中的多模态生成。本文对视觉自回归模型进行了系统性综述，包括对现有方法进行分类，并重点介绍了它们的主要贡献、优点和局限性，涵盖了图像生成、视频生成、图像编辑、动作生成、医学图像分析、3D 生成、机器人操作、统一多模态生成等各种视觉任务。此外，我们还调查和分析了自回归模型的最新进展，包括对现有方法在各种评估数据集上的全面基准测试和讨论。最后，我们概述了未来研究的关键挑战和有希望的方向，为视觉自回归模型的进一步发展提供了路线图。

##### **Optimizing Automatic Summarization of Long Clinical Records Using Dynamic Context Extension:Testing and Evaluation of the NBCE Method**
2411.08586v2 by Guoqing Zhang, Keita Fukuyama, Kazumasa Kishimoto, Tomohiro Kuroda

Summarizing patient clinical notes is vital for reducing documentation
burdens. Current manual summarization makes medical staff struggle. We propose
an automatic method using LLMs, but long inputs cause LLMs to lose context,
reducing output quality especially in small size model. We used a 7B model,
open-calm-7b, enhanced with Native Bayes Context Extend and a redesigned
decoding mechanism to reference one sentence at a time, keeping inputs within
context windows, 2048 tokens. Our improved model achieved near parity with
Google's over 175B Gemini on ROUGE-L metrics with 200 samples, indicating
strong performance using less resources, enhancing automated EMR summarization
feasibility.

摘要：摘要病患臨床筆記對於減輕文件負擔至關重要。目前的摘要手冊讓醫療人員難以應付。我們提出使用大型語言模型 (LLM) 的自動化方法，但過長的輸入會導致大型語言模型失去上下文，降低輸出品質，特別是在小型模型中。我們使用一個 7B 模型，open-calm-7b，並搭配 Native Bayes Context Extend 和重新設計的解碼機制，一次參考一個句子，將輸入保持在上下文視窗中，2048 個符號。我們改進的模型在 ROUGE-L 指標上達到接近 Google 超過 175B 的 Gemini，有 200 個範本，表示使用較少資源就能有強大的效能，提升自動化電子病歷摘要的可行性。

##### **A Heterogeneous Graph Neural Network Fusing Functional and Structural Connectivity for MCI Diagnosis**
2411.08424v1 by Feiyu Yin, Yu Lei, Siyuan Dai, Wenwen Zeng, Guoqing Wu, Liang Zhan, Jinhua Yu

Brain connectivity alternations associated with brain disorders have been
widely reported in resting-state functional imaging (rs-fMRI) and diffusion
tensor imaging (DTI). While many dual-modal fusion methods based on graph
neural networks (GNNs) have been proposed, they generally follow homogenous
fusion ways ignoring rich heterogeneity of dual-modal information. To address
this issue, we propose a novel method that integrates functional and structural
connectivity based on heterogeneous graph neural networks (HGNNs) to better
leverage the rich heterogeneity in dual-modal images. We firstly use blood
oxygen level dependency and whiter matter structure information provided by
rs-fMRI and DTI to establish homo-meta-path, capturing node relationships
within the same modality. At the same time, we propose to establish
hetero-meta-path based on structure-function coupling and brain community
searching to capture relations among cross-modal nodes. Secondly, we further
introduce a heterogeneous graph pooling strategy that automatically balances
homo- and hetero-meta-path, effectively leveraging heterogeneous information
and preventing feature confusion after pooling. Thirdly, based on the
flexibility of heterogeneous graphs, we propose a heterogeneous graph data
augmentation approach that can conveniently address the sample imbalance issue
commonly seen in clinical diagnosis. We evaluate our method on ADNI-3 dataset
for mild cognitive impairment (MCI) diagnosis. Experimental results indicate
the proposed method is effective and superior to other algorithms, with a mean
classification accuracy of 93.3%.

摘要：腦部連通性變化與腦部疾病的關聯性已在靜態功能性影像 (rs-fMRI) 和擴散張量影像 (DTI) 中廣泛報導。雖然已經提出許多基於圖形神經網路 (GNN) 的雙模態融合方法，但它們通常遵循同質融合方式，忽略了雙模態資訊的豐富異質性。為了解決這個問題，我們提出了一種新方法，它整合了基於異質圖形神經網路 (HGNN) 的功能性和結構性連通性，以更好地利用雙模態影像中的豐富異質性。我們首先使用 rs-fMRI 和 DTI 提供的血氧濃度依賴性和白質結構資訊來建立同質元路徑，捕捉同一模式內的節點關係。同時，我們提議建立基於結構功能耦合和腦部社群搜尋的異質元路徑，以捕捉跨模式節點之間的關係。其次，我們進一步引入了一個異質圖形池化策略，該策略自動平衡同質和異質元路徑，有效利用異質資訊並防止池化後特徵混淆。第三，基於異質圖形的靈活性，我們提出了一種異質圖形資料擴充方法，可以方便地解決臨床診斷中常見的樣本不平衡問題。我們在 ADNI-3 資料集上評估了我們的方法，用於輕度認知障礙 (MCI) 診斷。實驗結果表明，所提出的方法有效且優於其他演算法，平均分類準確率為 93.3%。

##### **A Fuzzy Reinforcement LSTM-based Long-term Prediction Model for Fault Conditions in Nuclear Power Plants**
2411.08370v1 by Siwei Li, Jiayan Fang, Yichun Wua, Wei Wang, Chengxin Li, Jiangwen Chen

Early fault detection and timely maintenance scheduling can significantly
mitigate operational risks in NPPs and enhance the reliability of operator
decision-making. Therefore, it is necessary to develop an efficient Prognostics
and Health Management (PHM) multi-step prediction model for predicting of
system health status and prompt execution of maintenance operations. In this
study, we propose a novel predictive model that integrates reinforcement
learning with Long Short-Term Memory (LSTM) neural networks and the Expert
Fuzzy Evaluation Method. The model is validated using parameter data for 20
different breach sizes in the Main Steam Line Break (MSLB) accident condition
of the CPR1000 pressurized water reactor simulation model and it demonstrates a
remarkable capability in accurately forecasting NPP parameter changes up to 128
steps ahead (with a time interval of 10 seconds per step, i.e., 1280 seconds),
thereby satisfying the temporal advance requirement for fault prognostics in
NPPs. Furthermore, this method provides an effective reference solution for PHM
applications such as anomaly detection and remaining useful life prediction.

摘要：早期故障偵測和及時維護排程可以顯著降低核能電廠的營運風險，並提升操作人員決策的可靠性。因此，有必要開發一個高效的預測與健康管理 (PHM) 多步驟預測模型，用於預測系統健康狀態和及時執行維護作業。在此研究中，我們提出一個創新的預測模型，它整合了強化學習與長期短期記憶 (LSTM) 神經網路和專家模糊評估方法。該模型使用 CPR1000 加壓水反應爐模擬模型中主蒸汽管破裂 (MSLB) 事故條件下 20 種不同破裂尺寸的參數資料進行驗證，它展現出準確預測核能電廠參數變化長達 128 個步驟（每個步驟的時間間隔為 10 秒，即 1280 秒）的卓越能力，從而滿足核能電廠故障預測的時間提前需求。此外，此方法為異常偵測和剩餘使用壽命預測等 PHM 應用提供了一個有效的參考解決方案。

##### **TowerDebias: A Novel Debiasing Method based on the Tower Property**
2411.08297v1 by Norman Matloff, Aditya Mittal

Decision-making processes have increasingly come to rely on sophisticated
machine learning tools, raising concerns about the fairness of their
predictions with respect to any sensitive groups. The widespread use of
commercial black-box machine learning models necessitates careful consideration
of their legal and ethical implications on consumers. In situations where users
have access to these "black-box" models, a key question emerges: how can we
mitigate or eliminate the influence of sensitive attributes, such as race or
gender? We propose towerDebias (tDB), a novel approach designed to reduce the
influence of sensitive variables in predictions made by black-box models. Using
the Tower Property from probability theory, tDB aims to improve prediction
fairness during the post-processing stage in a manner amenable to the
Fairness-Utility Tradeoff. This method is highly flexible, requiring no prior
knowledge of the original model's internal structure, and can be extended to a
range of different applications. We provide a formal improvement theorem for
tDB and demonstrate its effectiveness in both regression and classification
tasks, underscoring its impact on the fairness-utility tradeoff.

摘要：決策制定過程越來越依賴於先進機器學習工具，這引起了人們對其預測的公平性是否會對任何敏感群體造成影響的擔憂。商業黑盒機器學習模型的廣泛使用需要仔細考慮其對消費者的法律和道德影響。在使用者能夠使用這些「黑盒」模型的情況下，一個關鍵問題浮現：我們如何減輕或消除敏感屬性（例如種族或性別）的影響？我們提出 towerDebias (tDB)，這是一種新穎的方法，旨在減少黑盒模型所做預測中敏感變數的影響。tDB 使用機率論中的 Tower 屬性，旨在以有利於公平性-效用權衡的方式在後處理階段改善預測公平性。此方法非常靈活，不需要事先了解原始模型的內部結構，並且可以擴展到各種不同的應用程式。我們為 tDB 提供了正式的改進定理，並展示了它在迴歸和分類任務中的有效性，強調了它對公平性-效用權衡的影響。

##### **Scaling Properties of Diffusion Models for Perceptual Tasks**
2411.08034v3 by Rahul Ravishankar, Zeeshan Patel, Jathushan Rajasegaran, Jitendra Malik

In this paper, we argue that iterative computation with diffusion models
offers a powerful paradigm for not only generation but also visual perception
tasks. We unify tasks such as depth estimation, optical flow, and amodal
segmentation under the framework of image-to-image translation, and show how
diffusion models benefit from scaling training and test-time compute for these
perceptual tasks. Through a careful analysis of these scaling properties, we
formulate compute-optimal training and inference recipes to scale diffusion
models for visual perception tasks. Our models achieve competitive performance
to state-of-the-art methods using significantly less data and compute. To
access our code and models, see https://scaling-diffusion-perception.github.io .

摘要：在本文中，我們論證使用擴散模型進行迭代計算提供了一個強大的範例，不僅適用於生成任務，也適用於視覺感知任務。我們將深度估計、光流和非模態分割等任務統一在圖像到圖像轉換的框架下，並展示擴散模型如何從擴展訓練和測試時間計算中受益，以執行這些感知任務。透過仔細分析這些擴展屬性，我們制定了計算最佳的訓練和推論範例，以擴展用於視覺感知任務的擴散模型。我們的模型使用明顯較少資料和運算，便能達到與最先進方法相當的效能。若要存取我們的程式碼和模型，請參閱 https://scaling-diffusion-perception.github.io 。

##### **Investigating the Effectiveness of Explainability Methods in Parkinson's Detection from Speech**
2411.08013v2 by Eleonora Mancini, Francesco Paissan, Paolo Torroni, Mirco Ravanelli, Cem Subakan

Speech impairments in Parkinson's disease (PD) provide significant early
indicators for diagnosis. While models for speech-based PD detection have shown
strong performance, their interpretability remains underexplored. This study
systematically evaluates several explainability methods to identify PD-specific
speech features, aiming to support the development of accurate, interpretable
models for clinical decision-making in PD diagnosis and monitoring. Our
methodology involves (i) obtaining attributions and saliency maps using
mainstream interpretability techniques, (ii) quantitatively evaluating the
faithfulness of these maps and their combinations obtained via union and
intersection through a range of established metrics, and (iii) assessing the
information conveyed by the saliency maps for PD detection from an auxiliary
classifier. Our results reveal that, while explanations are aligned with the
classifier, they often fail to provide valuable information for domain experts.

摘要：帕金森氏症 (PD) 的言語障礙提供了重要的早期診斷指標。雖然基於言語的 PD 檢測模型已顯示出強勁的效能，但其可解釋性仍未得到充分探討。本研究系統性地評估了幾種可解釋性方法，以識別 PD 特有的言語特徵，旨在支援開發準確、可解釋的模型，用於 PD 診斷和監測中的臨床決策。我們的研究方法包括：(i) 使用主流可解釋性技術獲得歸因和顯著性圖，(ii) 定量評估這些圖及其通過聯集和交集獲得的組合的忠實度，通過一系列已建立的指標，以及 (iii) 評估顯著性圖傳達的資訊，用於輔助分類器的 PD 檢測。我們的結果表明，雖然解釋與分類器一致，但它們通常無法為領域專家提供有價值的資訊。

##### **DuoLift-GAN:Reconstructing CT from Single-view and Biplanar X-Rays with Generative Adversarial Networks**
2411.07941v1 by Zhaoxi Zhang, Yueliang Ying

Computed tomography (CT) provides highly detailed three-dimensional (3D)
medical images but is costly, time-consuming, and often inaccessible in
intraoperative settings (Organization et al. 2011). Recent advancements have
explored reconstructing 3D chest volumes from sparse 2D X-rays, such as
single-view or orthogonal double-view images. However, current models tend to
process 2D images in a planar manner, prioritizing visual realism over
structural accuracy. In this work, we introduce DuoLift Generative Adversarial
Networks (DuoLift-GAN), a novel architecture with dual branches that
independently elevate 2D images and their features into 3D representations.
These 3D outputs are merged into a unified 3D feature map and decoded into a
complete 3D chest volume, enabling richer 3D information capture. We also
present a masked loss function that directs reconstruction towards critical
anatomical regions, improving structural accuracy and visual quality. This
paper demonstrates that DuoLift-GAN significantly enhances reconstruction
accuracy while achieving superior visual realism compared to existing methods.

摘要：電腦斷層掃描 (CT) 能提供高度詳細的三維 (3D) 醫學影像，但昂貴、耗時且在術中環境中通常無法取得 (Organization et al. 2011)。最近的進展探索從稀疏的 2D X 光重建 3D 胸部體積，例如單視圖或正交雙視圖影像。然而，目前的模型傾向於以平面方式處理 2D 影像，優先考慮視覺真實性而非結構準確性。在這項工作中，我們介紹了 DuoLift 生成對抗網路 (DuoLift-GAN)，一種具有雙分支的新穎架構，可獨立地將 2D 影像及其特徵提升到 3D 表現形式。這些 3D 輸出會合併成一個統一的 3D 特徵圖，並解碼成一個完整的 3D 胸部體積，從而能夠擷取更豐富的 3D 資訊。我們也提出了一個遮罩損失函數，將重建導向關鍵解剖區域，改善結構準確性和視覺品質。這篇論文證明了 DuoLift-GAN 與現有方法相比，顯著提升了重建準確性，同時達到了卓越的視覺真實性。

##### **Automatic dataset shift identification to support root cause analysis of AI performance drift**
2411.07940v2 by Mélanie Roschewitz, Raghav Mehta, Charles Jones, Ben Glocker

Shifts in data distribution can substantially harm the performance of
clinical AI models. Hence, various methods have been developed to detect the
presence of such shifts at deployment time. However, root causes of dataset
shifts are varied, and the choice of shift mitigation strategies is highly
dependent on the precise type of shift encountered at test time. As such,
detecting test-time dataset shift is not sufficient: precisely identifying
which type of shift has occurred is critical. In this work, we propose the
first unsupervised dataset shift identification framework, effectively
distinguishing between prevalence shift (caused by a change in the label
distribution), covariate shift (caused by a change in input characteristics)
and mixed shifts (simultaneous prevalence and covariate shifts). We discuss the
importance of self-supervised encoders for detecting subtle covariate shifts
and propose a novel shift detector leveraging both self-supervised encoders and
task model outputs for improved shift detection. We report promising results
for the proposed shift identification framework across three different imaging
modalities (chest radiography, digital mammography, and retinal fundus images)
on five types of real-world dataset shifts, using four large publicly available
datasets.

摘要：數據分佈的轉變會大幅影響臨床 AI 模型的效能。因此，已開發出各種方法來偵測部署時出現此類轉變。然而，資料集轉變的根本原因各不相同，而轉變緩解策略的選擇高度依賴於測試時遇到的轉變類型。因此，偵測測試時資料集轉變並不足夠：精確識別發生何種類型的轉變至關重要。在這項工作中，我們提出第一個無監督資料集轉變識別架構，有效區分流行率轉變（由標籤分佈的變化引起）、共變量轉變（由輸入特徵的變化引起）和混合轉變（同時發生流行率和共變量轉變）。我們討論了自監督編碼器在偵測細微共變量轉變中的重要性，並提出了一種新穎的轉變偵測器，它同時利用自監督編碼器和任務模型輸出，以改善轉變偵測。我們報告了所提出的轉變識別架構在三種不同影像模式（胸部 X 光、數位乳房攝影和視網膜眼底影像）中針對五種類型的真實世界資料集轉變所獲得的令人滿意的結果，並使用了四個大型公開資料集。

##### **INTRABENCH: Interactive Radiological Benchmark**
2411.07885v1 by Constantin Ulrich, Tassilo Wald, Emily Tempus, Maximilian Rokuss, Paul F. Jaeger, Klaus Maier-Hein

Current interactive segmentation approaches, inspired by the success of
META's Segment Anything model, have achieved notable advancements, however,
they come with substantial limitations that hinder their practical application
in real clinical scenarios. These include unrealistic human interaction
requirements, such as slice-by-slice operations for 2D models on 3D data, a
lack of iterative refinement, and insufficient evaluation experiments. These
shortcomings prevent accurate assessment of model performance and lead to
inconsistent outcomes across studies. IntRaBench overcomes these challenges by
offering a comprehensive and reproducible framework for evaluating interactive
segmentation methods in realistic, clinically relevant scenarios. It includes
diverse datasets, target structures, and segmentation models, and provides a
flexible codebase that allows seamless integration of new models and prompting
strategies. Additionally, we introduce advanced techniques to minimize
clinician interaction, ensuring fair comparisons between 2D and 3D models. By
open-sourcing IntRaBench, we invite the research community to integrate their
models and prompting techniques, ensuring continuous and transparent evaluation
of interactive segmentation models in 3D medical imaging.

摘要：目前互動式分割方法受到 META 的 Segment Anything 模型成功的啟發，已取得顯著進展，但它們仍有很大的限制，會阻礙它們在實際臨床場景中的應用。這些限制包括不切實際的人機互動需求，例如 3D 資料上的 2D 模型的逐層操作、缺乏反覆改進以及評估實驗不足。這些缺點會妨礙準確評估模型效能，並導致各項研究結果不一致。IntRaBench 克服了這些挑戰，提供了一個全面且可重現的架構，用於評估實際臨床相關場景中的互動式分割方法。它包含多元的資料集、目標結構和分割模型，並提供了一個彈性的程式碼庫，允許無縫整合新的模型和提示策略。此外，我們引進了先進技術來最小化臨床醫師的互動，確保 2D 和 3D 模型之間的公平比較。透過開放原始碼 IntRaBench，我們邀請研究社群整合他們的模型和提示技術，確保在 3D 醫學影像中持續且透明地評估互動式分割模型。

##### **Leveraging Multimodal Models for Enhanced Neuroimaging Diagnostics in Alzheimer's Disease**
2411.07871v1 by Francesco Chiumento, Mingming Liu

The rapid advancements in Large Language Models (LLMs) and Vision-Language
Models (VLMs) have shown great potential in medical diagnostics, particularly
in radiology, where datasets such as X-rays are paired with human-generated
diagnostic reports. However, a significant research gap exists in the
neuroimaging field, especially for conditions such as Alzheimer's disease, due
to the lack of comprehensive diagnostic reports that can be utilized for model
fine-tuning. This paper addresses this gap by generating synthetic diagnostic
reports using GPT-4o-mini on structured data from the OASIS-4 dataset, which
comprises 663 patients. Using the synthetic reports as ground truth for
training and validation, we then generated neurological reports directly from
the images in the dataset leveraging the pre-trained BiomedCLIP and T5 models.
Our proposed method achieved a BLEU-4 score of 0.1827, ROUGE-L score of 0.3719,
and METEOR score of 0.4163, revealing its potential in generating clinically
relevant and accurate diagnostic reports.

摘要：大型語言模型 (LLM) 和視覺語言模型 (VLM) 的快速進展在醫學診斷中展現了巨大的潛力，特別是在放射學中，其中 X 射線等數據集與人類產生的診斷報告配對。然而，神經影像領域存在著顯著的研究差距，特別是對於阿茲海默症等疾病，因為缺乏可供模型微調使用的全面診斷報告。本文通過使用 GPT-4o-mini 在來自 OASIS-4 數據集的結構化數據上生成合成診斷報告來解決這一差距，該數據集包含 663 名患者。使用合成報告作為訓練和驗證的真實數據，然後我們直接從數據集中的圖像中生成神經報告，利用預先訓練的 BiomedCLIP 和 T5 模型。我們提出的方法實現了 BLEU-4 分數為 0.1827、ROUGE-L 分數為 0.3719 和 METEOR 分數為 0.4163，揭示了其生成臨床相關且準確的診斷報告的潛力。

##### **PatchCTG: Patch Cardiotocography Transformer for Antepartum Fetal Health Monitoring**
2411.07796v1 by M. Jaleed Khan, Manu Vatish, Gabriel Davis Jones

Antepartum Cardiotocography (CTG) is vital for fetal health monitoring, but
traditional methods like the Dawes-Redman system are often limited by high
inter-observer variability, leading to inconsistent interpretations and
potential misdiagnoses. This paper introduces PatchCTG, a transformer-based
model specifically designed for CTG analysis, employing patch-based
tokenisation, instance normalisation and channel-independent processing to
capture essential local and global temporal dependencies within CTG signals.
PatchCTG was evaluated on the Oxford Maternity (OXMAT) dataset, comprising over
20,000 CTG traces across diverse clinical outcomes after applying the inclusion
and exclusion criteria. With extensive hyperparameter optimisation, PatchCTG
achieved an AUC of 77%, with specificity of 88% and sensitivity of 57% at
Youden's index threshold, demonstrating adaptability to various clinical needs.
Testing across varying temporal thresholds showed robust predictive
performance, particularly with finetuning on data closer to delivery, achieving
a sensitivity of 52% and specificity of 88% for near-delivery cases. These
findings suggest the potential of PatchCTG to enhance clinical decision-making
in antepartum care by providing a reliable, objective tool for fetal health
assessment. The source code is available at
https://github.com/jaleedkhan/PatchCTG.

摘要：產前胎兒心搏圖 (CTG) 對於胎兒健康監測至關重要，但傳統方法（如 Dawes-Redman 系統）通常受到高觀察者間變異性的限制，導致解釋不一致和潛在的誤診。本文介紹 PatchCTG，一種專門設計用於 CTG 分析的基於Transformer的模型，採用基於區塊的標記化、實例正規化和通道獨立處理，以捕捉 CTG 信號中的基本局部和全局時間依賴性。PatchCTG 在牛津婦產 (OXMAT) 資料集上進行評估，該資料集包含超過 20,000 個 CTG 軌跡，涵蓋在應用包含和排除標準後不同的臨床結果。透過廣泛的超參數最佳化，PatchCTG 在 Youden 指數閾值下達到 77% 的 AUC，特異性為 88%，敏感性為 57%，證明了其對各種臨床需求的適應性。在不同的時間閾值下進行測試顯示出穩健的預測效能，特別是在接近分娩時對資料進行微調，對於接近分娩的病例，敏感性達到 52%，特異性達到 88%。這些發現表明 PatchCTG 有潛力透過提供可靠、客觀的胎兒健康評估工具來加強產前照護中的臨床決策制定。原始程式碼可在 https://github.com/jaleedkhan/PatchCTG 取得。

##### **Multimodal Clinical Reasoning through Knowledge-augmented Rationale Generation**
2411.07611v1 by Shuai Niu, Jing Ma, Liang Bai, Zhihua Wang, Yida Xu, Yunya Song, Xian Yang

Clinical rationales play a pivotal role in accurate disease diagnosis;
however, many models predominantly use discriminative methods and overlook the
importance of generating supportive rationales. Rationale distillation is a
process that transfers knowledge from large language models (LLMs) to smaller
language models (SLMs), thereby enhancing the latter's ability to break down
complex tasks. Despite its benefits, rationale distillation alone is inadequate
for addressing domain knowledge limitations in tasks requiring specialized
expertise, such as disease diagnosis. Effectively embedding domain knowledge in
SLMs poses a significant challenge. While current LLMs are primarily geared
toward processing textual data, multimodal LLMs that incorporate time series
data, especially electronic health records (EHRs), are still evolving. To
tackle these limitations, we introduce ClinRaGen, an SLM optimized for
multimodal rationale generation in disease diagnosis. ClinRaGen incorporates a
unique knowledge-augmented attention mechanism to merge domain knowledge with
time series EHR data, utilizing a stepwise rationale distillation strategy to
produce both textual and time series-based clinical rationales. Our evaluations
show that ClinRaGen markedly improves the SLM's capability to interpret
multimodal EHR data and generate accurate clinical rationales, supporting more
reliable disease diagnosis, advancing LLM applications in healthcare, and
narrowing the performance divide between LLMs and SLMs.

摘要：<paragraph>臨床依據在準確的疾病診斷中扮演著關鍵角色；
然而，許多模型主要使用判別式方法，而忽略了生成支持性依據的重要性。依據萃取是一種將知識從大型語言模型 (LLM) 轉移到小型語言模型 (SLM) 的過程，從而增強後者分解複雜任務的能力。儘管有其好處，但單獨的依據萃取不足以解決需要專業知識的任務（例如疾病診斷）中的領域知識限制。有效地將領域知識嵌入 SLM 是一個重大的挑戰。雖然目前的 LLM 主要用於處理文本資料，但整合時間序列資料（特別是電子健康記錄 (EHR)）的多模態 LLM 仍在發展中。為了解決這些限制，我們引入了 ClinRaGen，一種針對疾病診斷中多模態依據生成的最佳化 SLM。ClinRaGen 結合了一個獨特的知識增強注意力機制，將領域知識與時間序列 EHR 資料合併，利用逐步的依據萃取策略來產生基於文本和時間序列的臨床依據。我們的評估表明，ClinRaGen 明顯改善了 SLM 解釋多模態 EHR 資料和生成準確臨床依據的能力，支持更可靠的疾病診斷，推進 LLM 在醫療保健中的應用，並縮小 LLM 和 SLM 之間的效能差距。</paragraph>

##### **Contrastive Language Prompting to Ease False Positives in Medical Anomaly Detection**
2411.07546v1 by YeongHyeon Park, Myung Jin Kim, Hyeong Seok Kim

A pre-trained visual-language model, contrastive language-image pre-training
(CLIP), successfully accomplishes various downstream tasks with text prompts,
such as finding images or localizing regions within the image. Despite CLIP's
strong multi-modal data capabilities, it remains limited in specialized
environments, such as medical applications. For this purpose, many CLIP
variants-i.e., BioMedCLIP, and MedCLIP-SAMv2-have emerged, but false positives
related to normal regions persist. Thus, we aim to present a simple yet
important goal of reducing false positives in medical anomaly detection. We
introduce a Contrastive LAnguage Prompting (CLAP) method that leverages both
positive and negative text prompts. This straightforward approach identifies
potential lesion regions by visual attention to the positive prompts in the
given image. To reduce false positives, we attenuate attention on normal
regions using negative prompts. Extensive experiments with the BMAD dataset,
including six biomedical benchmarks, demonstrate that CLAP method enhances
anomaly detection performance. Our future plans include developing an automated
fine prompting method for more practical usage.

摘要：預訓練的視覺語言模型，對比語言影像預訓練 (CLIP)，成功使用文字提示完成各種下游任務，例如尋找影像或定位影像中的區域。儘管 CLIP 擁有強大的多模態資料功能，但在專門的環境中，例如醫療應用，仍然有限。為此，出現了許多 CLIP 變體，即 BioMedCLIP 和 MedCLIP-SAMv2，但與正常區域相關的假陽性仍然存在。因此，我們的目標是提出一個簡單但重要的目標，以減少醫療異常檢測中的假陽性。我們引入了對比語言提示 (CLAP) 方法，該方法同時利用正向和負向文字提示。這種直接的方法透過視覺注意給定影像中的正向提示，來識別潛在的病灶區域。為了減少假陽性，我們使用負向提示來減弱對正常區域的注意。使用 BMAD 資料集進行的廣泛實驗，包括六個生物醫學基準，證明 CLAP 方法增強了異常檢測效能。我們未來的計畫包括開發一種自動化精細提示方法，以供更實用的使用。

##### **Beyond Keywords: A Context-based Hybrid Approach to Mining Ethical Concern-related App Reviews**
2411.07398v1 by Aakash Sorathiya, Gouri Ginde

With the increasing proliferation of mobile applications in our everyday
experiences, the concerns surrounding ethics have surged significantly. Users
generally communicate their feedback, report issues, and suggest new
functionalities in application (app) reviews, frequently emphasizing safety,
privacy, and accountability concerns. Incorporating these reviews is essential
to developing successful products. However, app reviews related to ethical
concerns generally use domain-specific language and are expressed using a more
varied vocabulary. Thus making automated ethical concern-related app review
extraction a challenging and time-consuming effort.
  This study proposes a novel Natural Language Processing (NLP) based approach
that combines Natural Language Inference (NLI), which provides a deep
comprehension of language nuances, and a decoder-only (LLaMA-like) Large
Language Model (LLM) to extract ethical concern-related app reviews at scale.
Utilizing 43,647 app reviews from the mental health domain, the proposed
methodology 1) Evaluates four NLI models to extract potential privacy reviews
and compares the results of domain-specific privacy hypotheses with generic
privacy hypotheses; 2) Evaluates four LLMs for classifying app reviews to
privacy concerns; and 3) Uses the best NLI and LLM models further to extract
new privacy reviews from the dataset. Results show that the
DeBERTa-v3-base-mnli-fever-anli NLI model with domain-specific hypotheses
yields the best performance, and Llama3.1-8B-Instruct LLM performs best in the
classification of app reviews. Then, using NLI+LLM, an additional 1,008 new
privacy-related reviews were extracted that were not identified through the
keyword-based approach in previous research, thus demonstrating the
effectiveness of the proposed approach.

摘要：<paragraph>隨著行動應用程式在我們日常體驗中激增，圍繞倫理的疑慮也大幅增加。使用者通常在應用程式（app）評論中傳達他們的回饋、回報問題，並建議新的功能，經常強調安全性、隱私和問責疑慮。納入這些評論對於開發成功的產品至關重要。然而，與倫理疑慮相關的 app 評論通常使用特定領域語言，並使用更多變化的詞彙表達。因此，自動化與倫理疑慮相關的 app 評論擷取是一項具有挑戰性且耗時的工作。
本研究提出了一種基於自然語言處理 (NLP) 的新穎方法，它結合了自然語言推論 (NLI)，它提供了對語言細微差別的深入理解，以及僅解碼器（類似 LLaMA）的大型語言模型 (LLM)，以大規模擷取與倫理疑慮相關的 app 評論。利用心理健康領域的 43,647 個 app 評論，提出的方法 1) 評估四個 NLI 模型以擷取潛在的隱私評論，並將特定領域隱私假設的結果與一般隱私假設進行比較；2) 評估四個 LLM 以將 app 評論分類為隱私疑慮；以及 3) 進一步使用最佳的 NLI 和 LLM 模型從資料集中擷取新的隱私評論。結果顯示，具有特定領域假設的 DeBERTa-v3-base-mnli-fever-anli NLI 模型產生最佳效能，而 Llama3.1-8B-Instruct LLM 在 app 評論分類中表現最佳。然後，使用 NLI+LLM，額外擷取了 1,008 個新的與隱私相關的評論，這些評論未透過先前研究中的基於關鍵字的方法識別出來，因此證明了所提出方法的有效性。</paragraph>

##### **Data-Centric Learning Framework for Real-Time Detection of Aiming Beam in Fluorescence Lifetime Imaging Guided Surgery**
2411.07395v1 by Mohamed Abul Hassan, Pu Sun, Xiangnan Zhou, Lisanne Kraft, Kelsey T Hadfield, Katjana Ehrlich, Jinyi Qi, Andrew Birkeland, Laura Marcu

This study introduces a novel data-centric approach to improve real-time
surgical guidance using fiber-based fluorescence lifetime imaging (FLIm). A key
aspect of the methodology is the accurate detection of the aiming beam, which
is essential for localizing points used to map FLIm measurements onto the
tissue region within the surgical field. The primary challenge arises from the
complex and variable conditions encountered in the surgical environment,
particularly in Transoral Robotic Surgery (TORS). Uneven illumination in the
surgical field can cause reflections, reduce contrast, and results in
inconsistent color representation, further complicating aiming beam detection.
To overcome these challenges, an instance segmentation model was developed
using a data-centric training strategy that improves accuracy by minimizing
label noise and enhancing detection robustness. The model was evaluated on a
dataset comprising 40 in vivo surgical videos, demonstrating a median detection
rate of 85%. This performance was maintained when the model was integrated in a
clinical system, achieving a similar detection rate of 85% during TORS
procedures conducted in patients. The system's computational efficiency,
measured at approximately 24 frames per second (FPS), was sufficient for
real-time surgical guidance. This study enhances the reliability of FLIm-based
aiming beam detection in complex surgical environments, advancing the
feasibility of real-time, image-guided interventions for improved surgical
precision

摘要：本研究提出了一種新穎的以數據為中心的策略，以使用基於光纖的螢光生命期成像 (FLIm) 來改善實時手術導引。此方法的一個關鍵面向是準確偵測瞄準光束，這對於定位用於將 FLIm 測量結果對應到手術視野內組織區域的點至關重要。主要的挑戰來自於手術環境中遇到的複雜且變化的條件，特別是在經口機器人手術 (TORS) 中。手術視野中的照明不均會導致反射、降低對比度，並造成不一致的顏色呈現，進一步使瞄準光束偵測複雜化。為了克服這些挑戰，開發了一個實例分割模型，使用以數據為中心的訓練策略，透過最小化標籤雜訊和增強偵測穩健性來提高準確度。此模型在包含 40 個體內手術影片的資料集上進行評估，顯示出 85% 的中位數偵測率。當此模型整合到臨床系統中時，此效能得以維持，在患者進行 TORS 手術期間達成相似的 85% 偵測率。此系統的運算效率，測量結果約為每秒 24 幀 (FPS)，足以進行實時手術導引。本研究增強了 FLIm 為基礎的瞄準光束偵測在複雜手術環境中的可靠性，提升了實時、影像導引介入的可行性，以改善手術精準度

##### **Data-Driven Analysis of AI in Medical Device Software in China: Deep Learning and General AI Trends Based on Regulatory Data**
2411.07378v1 by Yu Han, Aaron Ceross, Sarim Ather, Jeroen H. M. Bergmann

Artificial intelligence (AI) in medical device software (MDSW) represents a
transformative clinical technology, attracting increasing attention within both
the medical community and the regulators. In this study, we leverage a
data-driven approach to automatically extract and analyze AI-enabled medical
devices (AIMD) from the National Medical Products Administration (NMPA)
regulatory database. The continued increase in publicly available regulatory
data requires scalable methods for analysis. Automation of regulatory
information screening is essential to create reproducible insights that can be
quickly updated in an ever changing medical device landscape. More than 4
million entries were assessed, identifying 2,174 MDSW registrations, including
531 standalone applications and 1,643 integrated within medical devices, of
which 43 were AI-enabled. It was shown that the leading medical specialties
utilizing AIMD include respiratory (20.5%), ophthalmology/endocrinology
(12.8%), and orthopedics (10.3%). This approach greatly improves the speed of
data extracting providing a greater ability to compare and contrast. This study
provides the first extensive, data-driven exploration of AIMD in China,
showcasing the potential of automated regulatory data analysis in understanding
and advancing the landscape of AI in medical technology.

摘要：醫療器材軟體 (MDSW) 中的人工智慧 (AI) 代表著變革性的臨床技術，在醫療社群和法規單位中都吸引了越來越多的關注。在本研究中，我們利用資料驅動的方法，從國家藥品監督管理局 (NMPA) 法規資料庫中自動擷取和分析具備 AI 功能的醫療器材 (AIMD)。持續增加的公開法規資料需要可擴充的分析方法。法規資訊篩選的自動化對於建立可重製的見解至關重要，這些見解可以在不斷變化的醫療器材領域中快速更新。評估了超過 400 萬筆條目，識別出 2,174 筆 MDSW 註冊，包括 531 筆獨立應用和 1,643 筆整合於醫療器材中，其中 43 筆具備 AI 功能。結果顯示，使用 AIMD 的主要醫療專科包括呼吸科 (20.5%)、眼科/內分泌科 (12.8%) 和骨科 (10.3%)。這種方法大幅提升了資料擷取速度，提供了更強大的比較和對比能力。本研究提供了中國 AIMD 的第一個廣泛資料驅動探索，展示了自動化法規資料分析在了解和推進醫療技術中 AI 領域的潛力。

##### **A Domain-Agnostic Neurosymbolic Approach for Big Social Data Analysis: Evaluating Mental Health Sentiment on Social Media during COVID-19**
2411.07163v1 by Vedant Khandelwal, Manas Gaur, Ugur Kursuncu, Valerie Shalin, Amit Sheth

Monitoring public sentiment via social media is potentially helpful during
health crises such as the COVID-19 pandemic. However, traditional
frequency-based, data-driven neural network-based approaches can miss newly
relevant content due to the evolving nature of language in a dynamically
evolving environment. Human-curated symbolic knowledge sources, such as
lexicons for standard language and slang terms, can potentially elevate social
media signals in evolving language. We introduce a neurosymbolic method that
integrates neural networks with symbolic knowledge sources, enhancing the
detection and interpretation of mental health-related tweets relevant to
COVID-19. Our method was evaluated using a corpus of large datasets
(approximately 12 billion tweets, 2.5 million subreddit data, and 700k news
articles) and multiple knowledge graphs. This method dynamically adapts to
evolving language, outperforming purely data-driven models with an F1 score
exceeding 92\%. This approach also showed faster adaptation to new data and
lower computational demands than fine-tuning pre-trained large language models
(LLMs). This study demonstrates the benefit of neurosymbolic methods in
interpreting text in a dynamic environment for tasks such as health
surveillance.

摘要：透過社群媒體監控公眾情緒在 COVID-19 等健康危機期間可能很有幫助。然而，傳統的基於頻率、資料驅動的神經網路方法可能會錯過新相關的內容，因為語言在動態演化的環境中會持續演化。由人類策劃的象徵性知識來源（例如標準語言和俚語術語的詞彙）可能會提升社群媒體在演化語言中的訊號。我們引入一種將神經網路與象徵性知識來源整合的神經符號方法，增強與 COVID-19 相關的心理健康相關推文的偵測和詮釋。我們的做法使用大型資料集語料庫（約 120 億則推文、250 萬個 subreddit 資料和 70 萬則新聞文章）和多個知識圖譜進行評估。這種方法動態適應演化的語言，優於純資料驅動模型，F1 分數超過 92%。這種方法也顯示出比微調預訓練大型語言模型 (LLM) 更快適應新資料和更低的運算需求。本研究證明了神經符號方法在動態環境中詮釋文字的優點，適用於健康監控等任務。

##### **Ambient AI Scribing Support: Comparing the Performance of Specialized AI Agentic Architecture to Leading Foundational Models**
2411.06713v1 by Chanseo Lee, Sonu Kumar, Kimon A. Vogt, Sam Meraj

This study compares Sporo Health's AI Scribe, a proprietary model fine-tuned
for medical scribing, with various LLMs (GPT-4o, GPT-3.5, Gemma-9B, and
Llama-3.2-3B) in clinical documentation. We analyzed de-identified patient
transcripts from partner clinics, using clinician-provided SOAP notes as the
ground truth. Each model generated SOAP summaries using zero-shot prompting,
with performance assessed via recall, precision, and F1 scores. Sporo
outperformed all models, achieving the highest recall (73.3%), precision
(78.6%), and F1 score (75.3%) with the lowest performance variance.
Statistically significant differences (p < 0.05) were found between Sporo and
the other models, with post-hoc tests showing significant improvements over
GPT-3.5, Gemma-9B, and Llama 3.2-3B. While Sporo outperformed GPT-4o by up to
10%, the difference was not statistically significant (p = 0.25). Clinical user
satisfaction, measured with a modified PDQI-9 inventory, favored Sporo.
Evaluations indicated Sporo's outputs were more accurate and relevant. This
highlights the potential of Sporo's multi-agentic architecture to improve
clinical workflows.

摘要：本研究比较了 Sporo Health 的 AI Scribe，一种针对医疗记录专门微调的专有模型，与临床记录中的各种 LLM（GPT-4o、GPT-3.5、Gemma-9B 和 Llama-3.2-3B）。我们分析了来自合作诊所的去标识患者记录，使用临床医生提供的 SOAP 记录作为基本事实。每个模型使用零次提示生成了 SOAP 摘要，通过召回率、精确率和 F1 分数评估性能。Sporo 优于所有模型，以最低的性能差异实现了最高的召回率 (73.3%)、精确率 (78.6%) 和 F1 分数 (75.3%)。在 Sporo 和其他模型之间发现了统计学上的显着差异 (p < 0.05)，事后检验显示与 GPT-3.5、Gemma-9B 和 Llama 3.2-3B 相比有显着改善。虽然 Sporo 的表现优于 GPT-4o 达 10%，但差异在统计学上并不显着 (p = 0.25)。使用修改后的 PDQI-9 清单衡量的临床用户满意度偏好 Sporo。评估表明 Sporo 的输出更准确、更相关。这突出了 Sporo 的多代理架构在改进临床工作流程方面的潜力。

##### **In-Context Learning for Preserving Patient Privacy: A Framework for Synthesizing Realistic Patient Portal Messages**
2411.06549v1 by Joseph Gatto, Parker Seegmiller, Timothy E. Burdick, Sarah Masud Preum

Since the COVID-19 pandemic, clinicians have seen a large and sustained
influx in patient portal messages, significantly contributing to clinician
burnout. To the best of our knowledge, there are no large-scale public patient
portal messages corpora researchers can use to build tools to optimize
clinician portal workflows. Informed by our ongoing work with a regional
hospital, this study introduces an LLM-powered framework for configurable and
realistic patient portal message generation. Our approach leverages few-shot
grounded text generation, requiring only a small number of de-identified
patient portal messages to help LLMs better match the true style and tone of
real data. Clinical experts in our team deem this framework as HIPAA-friendly,
unlike existing privacy-preserving approaches to synthetic text generation
which cannot guarantee all sensitive attributes will be protected. Through
extensive quantitative and human evaluation, we show that our framework
produces data of higher quality than comparable generation methods as well as
all related datasets. We believe this work provides a path forward for (i) the
release of large-scale synthetic patient message datasets that are
stylistically similar to ground-truth samples and (ii) HIPAA-friendly data
generation which requires minimal human de-identification efforts.

摘要：自 COVID-19 大流行以來，臨床醫生收到了大量的持續性患者入口訊息，這顯著加劇了臨床醫生的倦怠感。據我們所知，沒有大型公共患者入口訊息語料庫可供研究人員用於建構工具來最佳化臨床醫生入口工作流程。本研究借鑒了我們與區域醫院正在進行的工作，介紹了一個由 LLM 驅動的框架，用於可配置且逼真的患者入口訊息產生。我們的做法利用了少樣本接地文本產生，只需少數去識別化的患者入口訊息，就能幫助 LLM 更佳匹配真實資料的真實風格和語氣。我們團隊中的臨床專家認為這個框架符合 HIPAA，這與現有的合成文本產生隱私保護方法不同，後者無法保證所有敏感屬性都受到保護。透過廣泛的量化和人工評估，我們證明了我們的框架產生的資料品質高於可比較的產生方法以及所有相關的資料集。我們相信這項工作為以下事項提供了前進的道路：(i) 發布與真實樣本在風格上相似的、大規模的合成患者訊息資料集，以及 (ii) 符合 HIPAA 的資料產生，而這需要最少的人工去識別化工作。

##### **NeuReg: Domain-invariant 3D Image Registration on Human and Mouse Brains**
2411.06315v1 by Taha Razzaq, Asim Iqbal

Medical brain imaging relies heavily on image registration to accurately
curate structural boundaries of brain features for various healthcare
applications. Deep learning models have shown remarkable performance in image
registration in recent years. Still, they often struggle to handle the
diversity of 3D brain volumes, challenged by their structural and contrastive
variations and their imaging domains. In this work, we present NeuReg, a
Neuro-inspired 3D image registration architecture with the feature of domain
invariance. NeuReg generates domain-agnostic representations of imaging
features and incorporates a shifting window-based Swin Transformer block as the
encoder. This enables our model to capture the variations across brain imaging
modalities and species. We demonstrate a new benchmark in multi-domain publicly
available datasets comprising human and mouse 3D brain volumes. Extensive
experiments reveal that our model (NeuReg) outperforms the existing baseline
deep learning-based image registration models and provides a high-performance
boost on cross-domain datasets, where models are trained on 'source-only'
domain and tested on completely 'unseen' target domains. Our work establishes a
new state-of-the-art for domain-agnostic 3D brain image registration,
underpinned by Neuro-inspired Transformer-based architecture.

摘要：醫學腦部影像高度依賴影像配準，以準確策畫大腦特徵的結構性邊界，用於各種醫療保健應用。深度學習模型近年來在影像配準中展現出卓越的效能。儘管如此，這些模型在處理多元的 3D 大腦體積時常常會遇到困難，受到其結構和對比變化以及影像領域的挑戰。在這項工作中，我們提出 NeuReg，一種具備領域不變性特徵的神經啟發式 3D 影像配準架構。NeuReg 產生影像特徵的領域不可知表示，並將基於滑動視窗的 Swin Transformer 區塊作為編碼器。這使我們的模型能夠擷取跨大腦影像模式和物種的變化。我們展示了一個新的基準，包含人類和老鼠 3D 大腦體積的多領域公開可用資料集。廣泛的實驗顯示，我們的模型 (NeuReg) 優於現有的基準深度學習影像配準模型，並在跨領域資料集上提供高性能提升，其中模型在「僅來源」領域上訓練，並在完全「未見」的目標領域上進行測試。我們的研究建立了領域不可知 3D 大腦影像配準的新技術，由神經啟發式 Transformer 為基礎的架構所支撐。

##### **GuidelineGuard: An Agentic Framework for Medical Note Evaluation with Guideline Adherence**
2411.06264v1 by MD Ragib Shahriyear

Although rapid advancements in Large Language Models (LLMs) are facilitating
the integration of artificial intelligence-based applications and services in
healthcare, limited research has focused on the systematic evaluation of
medical notes for guideline adherence. This paper introduces GuidelineGuard, an
agentic framework powered by LLMs that autonomously analyzes medical notes,
such as hospital discharge and office visit notes, to ensure compliance with
established healthcare guidelines. By identifying deviations from recommended
practices and providing evidence-based suggestions, GuidelineGuard helps
clinicians adhere to the latest standards from organizations like the WHO and
CDC. This framework offers a novel approach to improving documentation quality
and reducing clinical errors.

摘要：儘管大型語言模型 (LLM) 的快速進展促進了人工智慧應用程式和服務在醫療保健中的整合，但有限的研究專注於對醫療記錄進行系統評估以符合準則。本文介紹了 GuidelineGuard，一個由 LLM 提供動力的代理架構，它會自動分析醫療記錄，例如醫院出院和門診記錄，以確保符合既定的醫療保健準則。透過找出與建議做法的偏差並提供基於證據的建議，GuidelineGuard 可協助臨床醫生遵守世界衛生組織 (WHO) 和疾病管制中心 (CDC) 等組織的最新標準。此架構提供了一種改善文件品質和減少臨床錯誤的新方法。

##### **Deep Reinforcement Learning for Digital Twin-Oriented Complex Networked Systems**
2411.06148v1 by Jiaqi Wen, Bogdan Gabrys, Katarzyna Musial

The Digital Twin Oriented Complex Networked System (DT-CNS) aims to build and
extend a Complex Networked System (CNS) model with progressively increasing
dynamics complexity towards an accurate reflection of reality -- a Digital Twin
of reality. Our previous work proposed evolutionary DT-CNSs to model the
long-term adaptive network changes in an epidemic outbreak. This study extends
this framework by proposeing the temporal DT-CNS model, where reinforcement
learning-driven nodes make decisions on temporal directed interactions in an
epidemic outbreak. We consider cooperative nodes, as well as egocentric and
ignorant "free-riders" in the cooperation. We describe this epidemic spreading
process with the Susceptible-Infected-Recovered ($SIR$) model and investigate
the impact of epidemic severity on the epidemic resilience for different types
of nodes. Our experimental results show that (i) the full cooperation leads to
a higher reward and lower infection number than a cooperation with egocentric
or ignorant "free-riders"; (ii) an increasing number of "free-riders" in a
cooperation leads to a smaller reward, while an increasing number of egocentric
"free-riders" further escalate the infection numbers and (iii) higher infection
rates and a slower recovery weakens networks' resilience to severe epidemic
outbreaks. These findings also indicate that promoting cooperation and reducing
"free-riders" can improve public health during epidemics.

摘要：數位孿生導向複雜網路系統（DT-CNS）旨在建立和擴展複雜網路系統（CNS）模型，並逐步增加動態複雜性以準確反映現實——現實的數位孿生。我們先前的工作提出演化的 DT-CNS 來建模流行病爆發中的長期適應性網路變化。本研究透過提出時間 DT-CNS 模型來延伸這個架構，其中強化學習驅動的節點在流行病爆發中對時間導向互動做出決策。我們考慮合作節點，以及合作中的自我中心和無知的「搭便車者」。我們使用易感者-受感染者-康復者（$SIR$）模型描述這個流行病擴散過程，並調查流行病嚴重性對不同類型節點的流行病復原力的影響。我們的實驗結果顯示 (i) 全面合作會導致比與自我中心或無知的「搭便車者」合作更高的回報和更低的感染數；(ii) 合作中的「搭便車者」數量增加會導致較小的回報，而自我中心的「搭便車者」數量增加會進一步提升感染數；(iii) 較高的感染率和較慢的復原會削弱網路對嚴重流行病爆發的復原力。這些發現也表示，在流行病期間促進合作和減少「搭便車者」可以改善公共衛生。

##### **Evaluating the Propensity of Generative AI for Producing Disinformation During an Election Cycle**
2411.06120v1 by Erik J Schlicht

Generative Artificial Intelligence offers a powerful tool for adversaries who
wish to engage in influence operations, such as the Chinese Spamouflage
operation and the Russian Internet Research Agency effort that both sought to
interfere with recent US election cycles. Therefore, this study seeks to
investigate the propensity of current Generative AI models for producing
harmful disinformation during an election cycle. The probability that different
Generative AI models produced disinformation when given adversarial prompts was
evaluated, in addition the associated harm. This allows for the expected harm
for each model to be computed and it was discovered that Copilot and Gemini
tied for the overall safest performance by realizing the lowest expected harm,
while GPT-4o produced the greatest rates of harmful disinformation, resulting
in much higher expected harm scores. The impact of disinformation category was
also investigated and Gemini was safest within the political category of
disinformation, while Copilot was safest for topics related to health.
Moreover, characteristics of adversarial roles were discovered that led to
greater expected harm across all models. Finally, classification models were
developed that predicted disinformation production based on the conditions
considered in this study, which offers insight into factors important for
predicting disinformation production. Based on all of these insights,
recommendations are provided that seek to mitigate factors that lead to harmful
disinformation being produced by Generative AI models. It is hoped that
developers will use these insights to improve future models.

摘要：生成式人工智慧為有意從事影響力操作的敵對者提供強大的工具，例如中國的垃圾郵件偽裝行動和俄羅斯的網路研究機構努力，這兩者都試圖干預最近的美國選舉週期。因此，本研究旨在調查當前生成式 AI 模型在選舉週期中產生有害錯誤訊息的傾向。除了相關危害之外，還評估了在給定對抗提示時不同生成式 AI 模型產生錯誤訊息的可能性。這允許計算每個模型的預期危害，並且發現 Copilot 和 Gemini 在實現最低預期危害方面並列為最安全的整體效能，而 GPT-4o 產生了最高比率的有害錯誤訊息，導致預期危害分數高得多。還調查了錯誤訊息類別的影響，並且 Gemini 在政治類別的錯誤訊息中是最安全的，而 Copilot 在與健康相關的主題中最安全。此外，發現了對抗角色的特性，導致所有模型的預期危害更大。最後，開發了分類模型，根據本研究中考慮的條件預測錯誤訊息產生，這提供了對預測錯誤訊息產生很重要的因素的見解。根據所有這些見解，提供了建議，旨在減輕導致生成式 AI 模型產生有害錯誤訊息的因素。希望開發人員將使用這些見解來改進未來的模型。

##### **Personalize to generalize: Towards a universal medical multi-modality generalization through personalization**
2411.06106v2 by Zhaorui Tan, Xi Yang, Tan Pan, Tianyi Liu, Chen Jiang, Xin Guo, Qiufeng Wang, Anh Nguyen, Yuan Qi, Kaizhu Huang, Yuan Cheng

The differences among medical imaging modalities, driven by distinct
underlying principles, pose significant challenges for generalization in
multi-modal medical tasks. Beyond modality gaps, individual variations, such as
differences in organ size and metabolic rate, further impede a model's ability
to generalize effectively across both modalities and diverse populations.
Despite the importance of personalization, existing approaches to multi-modal
generalization often neglect individual differences, focusing solely on common
anatomical features. This limitation may result in weakened generalization in
various medical tasks. In this paper, we unveil that personalization is
critical for multi-modal generalization. Specifically, we propose an approach
to achieve personalized generalization through approximating the underlying
personalized invariant representation ${X}_h$ across various modalities by
leveraging individual-level constraints and a learnable biological prior. We
validate the feasibility and benefits of learning a personalized ${X}_h$,
showing that this representation is highly generalizable and transferable
across various multi-modal medical tasks. Extensive experimental results
consistently show that the additionally incorporated personalization
significantly improves performance and generalization across diverse scenarios,
confirming its effectiveness.

摘要：由於不同的基礎原理所驅動的醫學影像模式之間的差異，對多模式醫療任務中的概化提出了重大挑戰。除了模式差異之外，個體差異（例如器官大小和代謝率的差異）進一步阻礙了模型在不同模式和不同人群中有效概化的能力。儘管個性化很重要，但現有的多模式概化方法通常忽略個體差異，僅關注共同的解剖特徵。這種限制可能會導致各種醫療任務中概化能力減弱。在本文中，我們揭示了個性化對於多模式概化至關重要。具體來說，我們提出了一種方法，通過利用個體級約束和可學習的生物學先驗，在各種模式中近似底層個性化不變表示 ${X}_h$ 來實現個性化概化。我們驗證了學習個性化 ${X}_h$ 的可行性和好處，表明這種表示具有高度的概化性和可轉移性，適用於各種多模式醫療任務。廣泛的實驗結果一致表明，額外納入的個性化顯著提高了不同場景下的性能和概化能力，證實了其有效性。

##### **Assessing Foundational Medical 'Segment Anything' (Med-SAM1, Med-SAM2) Deep Learning Models for Left Atrial Segmentation in 3D LGE MRI**
2411.05963v1 by Mehri Mehrnia, Mohamed Elbayumi, Mohammed S. M. Elbaz

Atrial fibrillation (AF), the most common cardiac arrhythmia, is associated
with heart failure and stroke. Accurate segmentation of the left atrium (LA) in
3D late gadolinium-enhanced (LGE) MRI is helpful for evaluating AF, as fibrotic
remodeling in the LA myocardium contributes to arrhythmia and serves as a key
determinant of therapeutic strategies. However, manual LA segmentation is
labor-intensive and challenging. Recent foundational deep learning models, such
as the Segment Anything Model (SAM), pre-trained on diverse datasets, have
demonstrated promise in generic segmentation tasks. MedSAM, a fine-tuned
version of SAM for medical applications, enables efficient, zero-shot
segmentation without domain-specific training. Despite the potential of MedSAM
model, it has not yet been evaluated for the complex task of LA segmentation in
3D LGE-MRI. This study aims to (1) evaluate the performance of MedSAM in
automating LA segmentation, (2) compare the performance of the MedSAM2 model,
which uses a single prompt with automated tracking, with the MedSAM1 model,
which requires separate prompt for each slice, and (3) analyze the performance
of MedSAM1 in terms of Dice score(i.e., segmentation accuracy) by varying the
size and location of the box prompt.

摘要：心房顫動 (AF) 是最常見的心律不整，與心臟衰竭和中風有關。3D 晚期钆增強 (LGE) MRI 中左心房 (LA) 的精確分割有助於評估 AF，因為 LA 心肌中的纖維化重塑會導致心律不整，並作為治療策略的關鍵決定因素。然而，手動 LA 分割既費力又具有挑戰性。最近基礎深度學習模型（例如在不同資料集上預先訓練的 Segment Anything Model (SAM)）已在通用分割任務中展現出前景。MedSAM 是 SAM 的微調版本，適用於醫療應用，它能進行有效、零次學習的分割，而無需特定領域的訓練。儘管 MedSAM 模型具有潛力，但尚未評估其在 3D LGE-MRI 中 LA 分割的複雜任務。本研究旨在 (1) 評估 MedSAM 在自動化 LA 分割中的效能，(2) 比較使用單一提示和自動追蹤的 MedSAM2 模型與需要為每個切片提供單獨提示的 MedSAM1 模型的效能，以及 (3) 分析 MedSAM1 在骰子分數（即分割準確度）方面的效能，方法是改變方框提示的大小和位置。

##### **GazeSearch: Radiology Findings Search Benchmark**
2411.05780v1 by Trong Thang Pham, Tien-Phat Nguyen, Yuki Ikebe, Akash Awasthi, Zhigang Deng, Carol C. Wu, Hien Nguyen, Ngan Le

Medical eye-tracking data is an important information source for
understanding how radiologists visually interpret medical images. This
information not only improves the accuracy of deep learning models for X-ray
analysis but also their interpretability, enhancing transparency in
decision-making. However, the current eye-tracking data is dispersed,
unprocessed, and ambiguous, making it difficult to derive meaningful insights.
Therefore, there is a need to create a new dataset with more focus and
purposeful eyetracking data, improving its utility for diagnostic applications.
In this work, we propose a refinement method inspired by the target-present
visual search challenge: there is a specific finding and fixations are guided
to locate it. After refining the existing eye-tracking datasets, we transform
them into a curated visual search dataset, called GazeSearch, specifically for
radiology findings, where each fixation sequence is purposefully aligned to the
task of locating a particular finding. Subsequently, we introduce a scan path
prediction baseline, called ChestSearch, specifically tailored to GazeSearch.
Finally, we employ the newly introduced GazeSearch as a benchmark to evaluate
the performance of current state-of-the-art methods, offering a comprehensive
assessment for visual search in the medical imaging domain.

摘要：醫療眼動追蹤資料是了解放射科醫師如何視覺化詮釋醫療影像的重要資訊來源。這些資訊不僅提升了深度學習模型在 X 光分析中的準確度，也提升了其可解釋性，增進決策制定中的透明度。然而，目前的醫療眼動追蹤資料分散、未經處理且不明確，這使得難以推導出有意義的見解。因此，有必要建立一個新的資料集，其中包含更多焦點和有目的的眼動追蹤資料，以提升其在診斷應用中的效用。在這項工作中，我們提出了一種改良方法，其靈感來自目標呈現視覺搜尋挑戰：有一個特定的發現，而固定則用於定位它。在改良現有的眼動追蹤資料集後，我們將其轉換為一個名為 GazeSearch 的精選視覺搜尋資料集，專門用於放射科發現，其中每個固定序列都刻意與定位特定發現的任務對齊。隨後，我們介紹了一個掃描路徑預測基準，稱為 ChestSearch，專門針對 GazeSearch 量身打造。最後，我們採用新推出的 GazeSearch 作為基準，評估目前最先進方法的效能，提供醫療影像領域中視覺搜尋的全面評估。

##### **Humans Continue to Outperform Large Language Models in Complex Clinical Decision-Making: A Study with Medical Calculators**
2411.05897v1 by Nicholas Wan, Qiao Jin, Joey Chan, Guangzhi Xiong, Serina Applebaum, Aidan Gilson, Reid McMurry, R. Andrew Taylor, Aidong Zhang, Qingyu Chen, Zhiyong Lu

Although large language models (LLMs) have been assessed for general medical
knowledge using medical licensing exams, their ability to effectively support
clinical decision-making tasks, such as selecting and using medical
calculators, remains uncertain. Here, we evaluate the capability of both
medical trainees and LLMs to recommend medical calculators in response to
various multiple-choice clinical scenarios such as risk stratification,
prognosis, and disease diagnosis. We assessed eight LLMs, including
open-source, proprietary, and domain-specific models, with 1,009
question-answer pairs across 35 clinical calculators and measured human
performance on a subset of 100 questions. While the highest-performing LLM,
GPT-4o, provided an answer accuracy of 74.3% (CI: 71.5-76.9%), human
annotators, on average, outperformed LLMs with an accuracy of 79.5% (CI:
73.5-85.0%). With error analysis showing that the highest-performing LLMs
continue to make mistakes in comprehension (56.6%) and calculator knowledge
(8.1%), our findings emphasize that humans continue to surpass LLMs on complex
clinical tasks such as calculator recommendation.

摘要：儘管大型語言模型 (LLM) 已使用醫學執照考試評估其一般醫學知識，但它們有效支援臨床決策任務（例如選擇和使用醫學計算器）的能力仍不確定。在此，我們評估醫學受訓者和 LLM 推薦醫學計算器的能力，以回應各種多選題臨床情境，例如風險分層、預後和疾病診斷。我們評估了八個 LLM，包括開源、專有和特定領域的模型，其中包含 35 個臨床計算器的 1,009 個問答對，並測量了人類在 100 個問題子集上的表現。表現最佳的 LLM GPT-4o 提供了 74.3% 的回答準確度 (CI：71.5-76.9%)，而人類註解者平均表現優於 LLM，準確度為 79.5% (CI：73.5-85.0%)。錯誤分析顯示，表現最佳的 LLM 在理解 (56.6%) 和計算器知識 (8.1%) 方面仍會犯錯，我們的研究結果強調，人類在計算器推薦等複雜臨床任務上仍然優於 LLM。

##### **Identifying and Decomposing Compound Ingredients in Meal Plans Using Large Language Models**
2411.05892v1 by Leon Kopitar, Leon Bedrac, Larissa J Strath, Jiang Bian, Gregor Stiglic

This study explores the effectiveness of Large Language Models in meal
planning, focusing on their ability to identify and decompose compound
ingredients. We evaluated three models-GPT-4o, Llama-3 (70b), and Mixtral
(8x7b)-to assess their proficiency in recognizing and breaking down complex
ingredient combinations. Preliminary results indicate that while Llama-3 (70b)
and GPT-4o excels in accurate decomposition, all models encounter difficulties
with identifying essential elements like seasonings and oils. Despite strong
overall performance, variations in accuracy and completeness were observed
across models. These findings underscore LLMs' potential to enhance
personalized nutrition but highlight the need for further refinement in
ingredient decomposition. Future research should address these limitations to
improve nutritional recommendations and health outcomes.

摘要：這項研究探討大型語言模型在餐點規劃中的效能，著重於其辨識並分解複合食材的能力。我們評估了三個模型：GPT-4o、Llama-3 (70b) 和 Mixtral (8x7b)，以評量其辨識並分解複雜食材組合的能力。初步結果顯示，雖然 Llama-3 (70b) 和 GPT-4o 在準確分解方面表現出色，但所有模型在辨識調味料和油脂等必要元素時都遇到困難。儘管整體表現強勁，但各個模型在準確性和完整性方面仍有差異。這些發現強調了 LLM 增強個人化營養的潛力，但同時也突顯了進一步優化食材分解技術的必要性。未來的研究應針對這些限制進行探討，以改善營養建議和健康成果。

##### **SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark**
2411.05521v2 by Sithursan Sivasubramaniam, Cedric Osei-Akoto, Yi Zhang, Kurt Stockinger, Jonathan Fuerst

Electronic health records (EHRs) are stored in various database systems with
different database models on heterogeneous storage architectures, such as
relational databases, document stores, or graph databases. These different
database models have a big impact on query complexity and performance. While
this has been a known fact in database research, its implications for the
growing number of Text-to-Query systems have surprisingly not been investigated
so far. In this paper, we present SM3-Text-to-Query, the first multi-model
medical Text-to-Query benchmark based on synthetic patient data from Synthea,
following the SNOMED-CT taxonomy -- a widely used knowledge graph ontology
covering medical terminology. SM3-Text-to-Query provides data representations
for relational databases (PostgreSQL), document stores (MongoDB), and graph
databases (Neo4j and GraphDB (RDF)), allowing the evaluation across four
popular query languages, namely SQL, MQL, Cypher, and SPARQL. We systematically
and manually develop 408 template questions, which we augment to construct a
benchmark of 10K diverse natural language question/query pairs for these four
query languages (40K pairs overall). On our dataset, we evaluate several common
in-context-learning (ICL) approaches for a set of representative closed and
open-source LLMs. Our evaluation sheds light on the trade-offs between database
models and query languages for different ICL strategies and LLMs. Last,
SM3-Text-to-Query is easily extendable to additional query languages or real,
standard-based patient databases.

摘要：電子健康記錄 (EHR) 儲存在具有不同資料庫模型的各種資料庫系統中，採用異質儲存架構，例如關聯式資料庫、文件儲存庫或圖形資料庫。這些不同的資料庫模型對查詢複雜度和效能有很大的影響。雖然這在資料庫研究中是一個已知的事實，但其對越來越多的文字轉查詢系統的影響卻令人驚訝地尚未被研究。在本文中，我們提出 SM3-Text-to-Query，這是第一個基於 Synthea 合成患者資料的多模型醫療文字轉查詢基準，遵循 SNOMED-CT 分類法，這是一個廣泛使用的知識圖形本體，涵蓋醫學術語。SM3-Text-to-Query 提供了關係資料庫 (PostgreSQL)、文件儲存庫 (MongoDB) 和圖形資料庫 (Neo4j 和 GraphDB (RDF)) 的資料表示，允許跨四種流行的查詢語言進行評估，即 SQL、MQL、Cypher 和 SPARQL。我們系統且手動開發了 408 個範本問題，並擴充這些問題以建構一個基準，其中包含 10K 個針對這四種查詢語言的多樣化自然語言問題/查詢配對（總共 40K 個配對）。在我們的資料集上，我們評估了一組代表性的封閉和開放原始碼 LLM 的幾個常見情境學習 (ICL) 方法。我們的評估揭示了不同 ICL 策略和 LLM 的資料庫模型和查詢語言之間的權衡。最後，SM3-Text-to-Query 可以輕鬆擴充到其他查詢語言或真實的、基於標準的患者資料庫。

##### **Towards Scalable Foundation Models for Digital Dermatology**
2411.05514v1 by Fabian Gröger, Philippe Gottfrois, Ludovic Amruthalingam, Alvaro Gonzalez-Jimenez, Simone Lionetti, Luis R. Soenksen-Martinez, Alexander A. Navarini, Marc Pouly

The growing demand for accurate and equitable AI models in digital
dermatology faces a significant challenge: the lack of diverse, high-quality
labeled data. In this work, we investigate the potential of domain-specific
foundation models for dermatology in addressing this challenge. We utilize
self-supervised learning (SSL) techniques to pre-train models on a dataset of
over 240,000 dermatological images from public and private collections. Our
study considers several SSL methods and compares the resulting foundation
models against domain-agnostic models like those pre-trained on ImageNet and
state-of-the-art models such as MONET across 12 downstream tasks. Unlike
previous research, we emphasize the development of smaller models that are more
suitable for resource-limited clinical settings, facilitating easier adaptation
to a broad range of use cases. Results show that models pre-trained in this
work not only outperform general-purpose models but also approach the
performance of models 50 times larger on clinically relevant diagnostic tasks.
To promote further research in this direction, we publicly release both the
training code and the foundation models, which can benefit clinicians in
dermatological applications.

摘要：數位皮膚科對精準且公平的 AI 模型需求日益增加，但面臨一項重大挑戰：缺乏多元且高品質的標記資料。在這項研究中，我們探討特定領域的基礎模型在皮膚科中解決此挑戰的可能性。我們利用自監督學習 (SSL) 技術在包含超過 24 萬張來自公有和私有資料庫的皮膚科影像的資料集上預先訓練模型。我們的研究考量了多種 SSL 方法，並將產生的基礎模型與不受領域限制的模型（例如在 ImageNet 上預先訓練的模型）以及最先進的模型（例如 MONET）在 12 個下游任務中進行比較。與先前的研究不同，我們強調開發更適合資源有限的臨床環境的小型模型，以利於更輕鬆地適應廣泛的用例。結果顯示，在這項研究中預先訓練的模型不僅優於通用模型，而且在臨床上相關的診斷任務中，其效能也接近大 50 倍的模型。為了促進此方向的進一步研究，我們公開發布訓練程式碼和基礎模型，這些模型可讓皮膚科應用中的臨床醫生受益。

##### **Towards Equitable ASD Diagnostics: A Comparative Study of Machine and Deep Learning Models Using Behavioral and Facial Data**
2411.05880v1 by Mohammed Aledhari, Mohamed Rahouti, Ali Alfatemi

Autism Spectrum Disorder (ASD) is often underdiagnosed in females due to
gender-specific symptom differences overlooked by conventional diagnostics.
This study evaluates machine learning models, particularly Random Forest and
convolutional neural networks, for enhancing ASD diagnosis through structured
data and facial image analysis. Random Forest achieved 100% validation accuracy
across datasets, highlighting its ability to manage complex relationships and
reduce false negatives, which is crucial for early intervention and addressing
gender biases. In image-based analysis, MobileNet outperformed the baseline
CNN, achieving 87% accuracy, though a 30% validation loss suggests possible
overfitting, requiring further optimization for robustness in clinical
settings. Future work will emphasize hyperparameter tuning, regularization, and
transfer learning. Integrating behavioral data with facial analysis could
improve diagnosis for underdiagnosed groups. These findings suggest Random
Forest's high accuracy and balanced precision-recall metrics could enhance
clinical workflows. MobileNet's lightweight structure also shows promise for
resource-limited environments, enabling accessible ASD screening. Addressing
model explainability and clinician trust will be vital.

摘要：自閉症譜系障礙 (ASD) 由於性別特異的症狀差異，常被忽略而漏診。本研究評估機器學習模型，特別是隨機森林和卷積神經網路，以透過結構化資料和臉部影像分析來強化 ASD 診斷。隨機森林在所有資料集中的驗證準確度達到 100%，突顯其處理複雜關係和減少假陰性的能力，這對於早期介入和解決性別偏見至關重要。在基於影像的分析中，MobileNet 優於基準 CNN，準確度達到 87%，儘管 30% 的驗證損失表明可能過度擬合，需要進一步最佳化以提高臨床環境中的穩健性。未來的研究將強調超參數調整、正則化和遷移學習。將行為資料與臉部分析整合，可以改善漏診群體的診斷。這些發現表明隨機森林的高準確度和平衡的精確度召回指標可以增強臨床工作流程。MobileNet 的輕量級結構也顯示出在資源受限的環境中很有前景，可以進行無障礙的 ASD 篩檢。解決模型可解釋性和臨床醫師的信任至關重要。

##### **Interactive Dialogue Agents via Reinforcement Learning on Hindsight Regenerations**
2411.05194v1 by Joey Hong, Jessica Lin, Anca Dragan, Sergey Levine

Recent progress on large language models (LLMs) has enabled dialogue agents
to generate highly naturalistic and plausible text. However, current LLM
language generation focuses on responding accurately to questions and requests
with a single effective response. In reality, many real dialogues are
interactive, meaning an agent's utterances will influence their conversational
partner, elicit information, or change their opinion. Accounting for how an
agent can effectively steer a conversation is a crucial ability in many
dialogue tasks, from healthcare to preference elicitation. Existing methods for
fine-tuning dialogue agents to accomplish such tasks would rely on curating
some amount of expert data. However, doing so often requires understanding the
underlying cognitive processes of the conversational partner, which is a skill
neither humans nor LLMs trained on human data can reliably do. Our key insight
is that while LLMs may not be adept at identifying effective strategies for
steering conversations a priori, or in the middle of an ongoing conversation,
they can do so post-hoc, or in hindsight, after seeing how their conversational
partner responds. We use this fact to rewrite and augment existing suboptimal
data, and train via offline reinforcement learning (RL) an agent that
outperforms both prompting and learning from unaltered human demonstrations. We
apply our approach to two domains that require understanding human mental
state, intelligent interaction, and persuasion: mental health support, and
soliciting charitable donations. Our results in a user study with real humans
show that our approach greatly outperforms existing state-of-the-art dialogue
agents.

摘要：大型語言模型 (LLM) 的最新進展使對話代理能夠生成高度自然且合理的文字。然而，目前的 LLM 語言生成著重於以單一有效的回應準確回應問題和要求。在現實中，許多真實對話都是互動的，這表示代理人的發言會影響他們的對話夥伴、引出資訊或改變他們的意見。考量代理人如何有效引導對話的能力在許多對話任務中至關重要，從醫療保健到偏好引導皆是如此。現有的微調對話代理方法以完成此類任務會依賴於策劃一定量的專家資料。然而，這麼做通常需要了解對話夥伴的基礎認知歷程，而這項技能既不是人類也不是訓練過人類資料的 LLM 可靠具備的。我們的關鍵見解在於，儘管 LLM 可能不擅長於事先或在對話進行中識別出引導對話的有效策略，但他們可以在事後或回顧時，在看到他們的對話夥伴如何回應後這麼做。我們利用這個事實來改寫並擴充現有的次佳資料，並透過離線強化學習 (RL) 訓練一名代理人，其表現優於提示和從未經修改的人類示範中學習。我們將我們的做法應用於需要了解人類心理狀態、智慧互動和說服的兩個領域：心理健康支持和募集慈善捐款。我們在與真實人類進行的使用者研究中的結果顯示，我們的做法大幅優於現有的最先進對話代理。

##### **Inverse Transition Learning: Learning Dynamics from Demonstrations**
2411.05174v1 by Leo Benac, Abhishek Sharma, Sonali Parbhoo, Finale Doshi-Velez

We consider the problem of estimating the transition dynamics $T^*$ from
near-optimal expert trajectories in the context of offline model-based
reinforcement learning. We develop a novel constraint-based method, Inverse
Transition Learning, that treats the limited coverage of the expert
trajectories as a \emph{feature}: we use the fact that the expert is
near-optimal to inform our estimate of $T^*$. We integrate our constraints into
a Bayesian approach. Across both synthetic environments and real healthcare
scenarios like Intensive Care Unit (ICU) patient management in hypotension, we
demonstrate not only significant improvements in decision-making, but that our
posterior can inform when transfer will be successful.

摘要：我們考慮在離線模型基礎強化學習的脈絡中，從接近最佳的專家軌跡估計轉換動態 $T^*$ 的問題。我們開發一種新的基於約束的方法，逆轉換學習，它將專家軌跡的有限覆蓋範圍視為一種「特徵」：我們利用專家接近最佳的事實來告知我們對 $T^*$ 的估計。我們將我們的約束整合到貝氏方法中。在綜合環境和實際醫療保健場景（例如低血壓重症監護病房 (ICU) 病患管理）中，我們不僅展示了決策制定方面的顯著進步，而且我們的後驗可以告知轉移何時會成功。

##### **PadChest-GR: A Bilingual Chest X-ray Dataset for Grounded Radiology Report Generation**
2411.05085v1 by Daniel C. Castro, Aurelia Bustos, Shruthi Bannur, Stephanie L. Hyland, Kenza Bouzid, Maria Teodora Wetscherek, Maria Dolores Sánchez-Valverde, Lara Jaques-Pérez, Lourdes Pérez-Rodríguez, Kenji Takeda, José María Salinas, Javier Alvarez-Valle, Joaquín Galant Herrero, Antonio Pertusa

Radiology report generation (RRG) aims to create free-text radiology reports
from clinical imaging. Grounded radiology report generation (GRRG) extends RRG
by including the localisation of individual findings on the image. Currently,
there are no manually annotated chest X-ray (CXR) datasets to train GRRG
models. In this work, we present a dataset called PadChest-GR
(Grounded-Reporting) derived from PadChest aimed at training GRRG models for
CXR images. We curate a public bi-lingual dataset of 4,555 CXR studies with
grounded reports (3,099 abnormal and 1,456 normal), each containing complete
lists of sentences describing individual present (positive) and absent
(negative) findings in English and Spanish. In total, PadChest-GR contains
7,037 positive and 3,422 negative finding sentences. Every positive finding
sentence is associated with up to two independent sets of bounding boxes
labelled by different readers and has categorical labels for finding type,
locations, and progression. To the best of our knowledge, PadChest-GR is the
first manually curated dataset designed to train GRRG models for understanding
and interpreting radiological images and generated text. By including detailed
localization and comprehensive annotations of all clinically relevant findings,
it provides a valuable resource for developing and evaluating GRRG models from
CXR images. PadChest-GR can be downloaded under request from
https://bimcv.cipf.es/bimcv-projects/padchest-gr/

摘要：<paragraph>放射學報告生成 (RRG) 旨在從臨床影像建立自由文字的放射學報告。基礎放射學報告生成 (GRRG) 透過納入影像上個別發現的定位，來延伸 RRG。目前，沒有手動標記的胸部 X 光 (CXR) 資料集，可供訓練 GRRG 模型。在此研究中，我們提出一個名為 PadChest-GR（基礎報告）的資料集，其源自 PadChest，旨在訓練 CXR 影像的 GRRG 模型。我們策劃了一個公開的雙語資料集，其中包含 4,555 份 CXR 研究，附有基礎報告（3,099 份異常報告和 1,456 份正常報告），每個報告都包含完整的句子清單，用英文和西班牙文描述個別存在的（陽性）和不存在的（陰性）發現。總計，PadChest-GR 包含 7,037 個陽性發現句子和 3,422 個陰性發現句子。每個陽性發現句子最多與兩組獨立的邊界框相關聯，由不同的讀者標記，並具有發現類型、位置和進展的分類標籤。據我們所知，PadChest-GR 是第一個手動策劃的資料集，旨在訓練 GRRG 模型，以理解和詮釋放射學影像和產生的文字。透過納入所有臨床相關發現的詳細定位和綜合註解，它為從 CXR 影像開發和評估 GRRG 模型提供了寶貴的資源。PadChest-GR 可應要求從 https://bimcv.cipf.es/bimcv-projects/padchest-gr/ 下載</paragraph>

##### **Position Paper On Diagnostic Uncertainty Estimation from Large Language Models: Next-Word Probability Is Not Pre-test Probability**
2411.04962v1 by Yanjun Gao, Skatje Myers, Shan Chen, Dmitriy Dligach, Timothy A Miller, Danielle Bitterman, Guanhua Chen, Anoop Mayampurath, Matthew Churpek, Majid Afshar

Large language models (LLMs) are being explored for diagnostic decision
support, yet their ability to estimate pre-test probabilities, vital for
clinical decision-making, remains limited. This study evaluates two LLMs,
Mistral-7B and Llama3-70B, using structured electronic health record data on
three diagnosis tasks. We examined three current methods of extracting LLM
probability estimations and revealed their limitations. We aim to highlight the
need for improved techniques in LLM confidence estimation.

摘要：大型語言模型 (LLM) 正在被探索用於診斷決策支持，但它們估計臨床決策制定中至關重要的預測試概率的能力仍然有限。本研究使用三個診斷任務的結構化電子健康記錄數據評估了兩個 LLM，Mistral-7B 和 Llama3-70B。我們檢查了提取 LLM 概率估計的三種當前方法並揭示了它們的局限性。我們的目標是強調改進 LLM 置信度估計技術的必要性。

##### **FineTuneBench: How well do commercial fine-tuning APIs infuse knowledge into LLMs?**
2411.05059v2 by Eric Wu, Kevin Wu, James Zou

There is great interest in fine-tuning frontier large language models (LLMs)
to inject new information and update existing knowledge. While commercial LLM
fine-tuning APIs from providers such as OpenAI and Google promise flexible
adaptation for various applications, the efficacy of fine-tuning remains
unclear. In this study, we introduce FineTuneBench, an evaluation framework and
dataset for understanding how well commercial fine-tuning APIs can successfully
learn new and updated knowledge. We analyze five frontier LLMs with
commercially available fine-tuning APIs, including GPT-4o and Gemini 1.5 Pro,
on their effectiveness in two settings: (1) ingesting novel information, such
as recent news events and new people profiles, and (2) updating existing
knowledge, such as updated medical guidelines and code frameworks. Our results
reveal substantial shortcomings in all the models' abilities to effectively
learn new information through fine-tuning, with an average generalization
accuracy of 37% across all models. When updating existing knowledge, such as
incorporating medical guideline updates, commercial fine-tuning APIs show even
more limited capability (average generalization accuracy of 19%). Overall,
fine-tuning GPT-4o mini is the most effective for infusing new knowledge and
updating knowledge, followed by GPT-3.5 Turbo and GPT-4o. The fine-tuning APIs
for Gemini 1.5 Flesh and Gemini 1.5 Pro are unable to learn new knowledge or
update existing knowledge. These findings underscore a major shortcoming in
using current commercial fine-tuning services to achieve reliable knowledge
infusion in common scenarios. We open source the FineTuneBench dataset at
https://github.com/kevinwu23/StanfordFineTuneBench.

摘要：<paragraph>微调前沿大型语言模型 (LLM) 以注入新信息并更新现有知识引起了极大的兴趣。虽然来自 OpenAI 和 Google 等提供商的商业 LLM 微调 API 承诺为各种应用程序提供灵活的适应性，但微调的功效仍不明确。在这项研究中，我们介绍了 FineTuneBench，这是一个评估框架和数据集，用于理解商业微调 API 如何成功学习新的和更新的知识。我们分析了五种前沿 LLM，它们具有可商用的微调 API，包括 GPT-4o 和 Gemini 1.5 Pro，在两种设置中的有效性：(1) 摄取新信息，例如最近的新闻事件和新的人物简介，以及 (2) 更新现有知识，例如更新的医疗指南和代码框架。我们的结果揭示了所有模型在通过微调有效学习新信息方面的重大缺陷，所有模型的平均泛化准确度为 37%。在更新现有知识时，例如纳入医疗指南更新，商业微调 API 显示出更有限的能力（平均泛化准确度为 19%）。总体而言，微调 GPT-4o mini 在灌输新知识和更新知识方面最有效，其次是 GPT-3.5 Turbo 和 GPT-4o。Gemini 1.5 Flesh 和 Gemini 1.5 Pro 的微调 API 无法学习新知识或更新现有知识。这些发现强调了在常见场景中使用当前商业微调服务来实现可靠知识注入的重大缺陷。我们在 https://github.com/kevinwu23/StanfordFineTuneBench 上开源了 FineTuneBench 数据集。</paragraph>

##### **Green My LLM: Studying the key factors affecting the energy consumption of code assistants**
2411.11892v1 by Tristan Coignion, Clément Quinton, Romain Rouvoy

In recent years,Large Language Models (LLMs) have significantly improved in
generating high-quality code, enabling their integration into developers'
Integrated Development Environments (IDEs) as code assistants. These
assistants, such as GitHub Copilot, deliver real-time code suggestions and can
greatly enhance developers' productivity. However, the environmental impact of
these tools, in particular their energy consumption, remains a key concern.
This paper investigates the energy consumption of LLM-based code assistants by
simulating developer interactions with GitHub Copilot and analyzing various
configuration factors. We collected a dataset of development traces from 20
developers and conducted extensive software project development simulations to
measure energy usage under different scenarios. Our findings reveal that the
energy consumption and performance of code assistants are influenced by various
factors, such as the number of concurrent developers, model size, quantization
methods, and the use of streaming. Notably, a substantial portion of generation
requests made by GitHub Copilot is either canceled or rejected by developers,
indicating a potential area for reducing wasted computations. Based on these
findings, we share actionable insights into optimizing configurations for
different use cases, demonstrating that careful adjustments can lead to
significant energy savings.

摘要：<paragraph>近年來，大型語言模型 (LLM) 在產生高品質程式碼方面已大幅進步，使其能夠整合到開發人員的整合開發環境 (IDE) 中作為程式碼助理。這些助理，例如 GitHub Copilot，提供即時的程式碼建議，並且可以大幅提升開發人員的生產力。然而，這些工具的環境影響，特別是其能源消耗，仍然是一個關鍵問題。本文透過模擬開發人員與 GitHub Copilot 的互動並分析各種組態因素，來探討基於 LLM 的程式碼助理的能源消耗。我們從 20 位開發人員收集了一組開發追蹤資料集，並進行了廣泛的軟體專案開發模擬，以測量不同情況下的能源使用。我們的研究結果顯示，程式碼助理的能源消耗和效能會受到各種因素的影響，例如同時開發的人數、模型大小、量化方法以及串流的使用。值得注意的是，GitHub Copilot 進行的大量產生要求，會被開發人員取消或拒絕，這表示有潛在的空間可以減少浪費的運算。根據這些研究結果，我們分享了針對不同使用案例最佳化組態的可行見解，證明仔細調整可以帶來顯著的節能效果。</paragraph>

##### **Integrating Large Language Models for Genetic Variant Classification**
2411.05055v1 by Youssef Boulaimen, Gabriele Fossi, Leila Outemzabet, Nathalie Jeanray, Oleksandr Levenets, Stephane Gerart, Sebastien Vachenc, Salvatore Raieli, Joanna Giemza

The classification of genetic variants, particularly Variants of Uncertain
Significance (VUS), poses a significant challenge in clinical genetics and
precision medicine. Large Language Models (LLMs) have emerged as transformative
tools in this realm. These models can uncover intricate patterns and predictive
insights that traditional methods might miss, thus enhancing the predictive
accuracy of genetic variant pathogenicity.
  This study investigates the integration of state-of-the-art LLMs, including
GPN-MSA, ESM1b, and AlphaMissense, which leverage DNA and protein sequence data
alongside structural insights to form a comprehensive analytical framework for
variant classification. Our approach evaluates these integrated models using
the well-annotated ProteinGym and ClinVar datasets, setting new benchmarks in
classification performance. The models were rigorously tested on a set of
challenging variants, demonstrating substantial improvements over existing
state-of-the-art tools, especially in handling ambiguous and clinically
uncertain variants.
  The results of this research underline the efficacy of combining multiple
modeling approaches to significantly refine the accuracy and reliability of
genetic variant classification systems. These findings support the deployment
of these advanced computational models in clinical environments, where they can
significantly enhance the diagnostic processes for genetic disorders,
ultimately pushing the boundaries of personalized medicine by offering more
detailed and actionable genetic insights.

摘要：遺傳變異的分類，特別是不確定意義變異（VUS），對臨床遺傳學和精準醫療提出了重大挑戰。大型語言模型（LLM）已成為這個領域的變革性工具。這些模型可以揭示傳統方法可能遺漏的複雜模式和預測見解，從而提高遺傳變異致病性的預測準確度。
本研究調查了最先進 LLM 的整合，包括 GPN-MSA、ESM1b 和 AlphaMissense，這些 LLM 利用 DNA 和蛋白質序列數據以及結構見解，形成了一個全面的變異分類分析框架。我們的做法使用標註完善的 ProteinGym 和 ClinVar 數據集來評估這些整合模型，在分類效能上設定了新的基準。這些模型經過嚴格測試，使用一組具有挑戰性的變異，證明了對現有最先進工具的實質性改進，特別是在處理模稜兩可和臨床上不確定的變異方面。
這項研究的結果強調了結合多種建模方法以顯著提高遺傳變異分類系統的準確度和可靠性的有效性。這些發現支持在臨床環境中部署這些先進的計算模型，它們可以在那裡顯著增強遺傳疾病的診斷程序，最終通過提供更詳細且可操作的遺傳見解來突破個人化醫療的界限。


### Knowledge Graphs
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-21**|**Knowledge Graphs, Large Language Models, and Hallucinations: An NLP Perspective**|Ernests Lavrinovics et.al.|[2411.14258v1](http://arxiv.org/abs/2411.14258v1)|null|
|**2024-11-21**|**Logic Augmented Generation**|Aldo Gangemi et.al.|[2411.14012v1](http://arxiv.org/abs/2411.14012v1)|null|
|**2024-11-21**|**FastRAG: Retrieval Augmented Generation for Semi-structured Data**|Amar Abane et.al.|[2411.13773v1](http://arxiv.org/abs/2411.13773v1)|null|
|**2024-11-20**|**Predictive Insights into LGBTQ+ Minority Stress: A Transductive Exploration of Social Media Discourse**|S. Chapagain et.al.|[2411.13534v1](http://arxiv.org/abs/2411.13534v1)|[link](https://github.com/chapagaisa/transductive)|
|**2024-11-20**|**KAAE: Numerical Reasoning for Knowledge Graphs via Knowledge-aware Attributes Learning**|Ming Yin et.al.|[2411.12950v1](http://arxiv.org/abs/2411.12950v1)|null|
|**2024-11-19**|**Neurosymbolic Graph Enrichment for Grounded World Models**|Stefano De Giorgis et.al.|[2411.12671v1](http://arxiv.org/abs/2411.12671v1)|null|
|**2024-11-19**|**Instant Policy: In-Context Imitation Learning via Graph Diffusion**|Vitalis Vosylius et.al.|[2411.12633v1](http://arxiv.org/abs/2411.12633v1)|null|
|**2024-11-19**|**Bias Free Sentiment Analysis**|Hubert Plisiecki et.al.|[2411.12493v1](http://arxiv.org/abs/2411.12493v1)|null|
|**2024-11-19**|**Neon: News Entity-Interaction Extraction for Enhanced Question Answering**|Sneha Singhania et.al.|[2411.12449v2](http://arxiv.org/abs/2411.12449v2)|null|
|**2024-11-19**|**Just KIDDIN: Knowledge Infusion and Distillation for Detection of INdecent Memes**|Rahul Garg et.al.|[2411.12174v1](http://arxiv.org/abs/2411.12174v1)|null|
|**2024-11-18**|**Regret-Free Reinforcement Learning for LTL Specifications**|Rupak Majumdar et.al.|[2411.12019v1](http://arxiv.org/abs/2411.12019v1)|null|
|**2024-11-18**|**Semantic-Geometric-Physical-Driven Robot Manipulation Skill Transfer via Skill Library and Tactile Representation**|Mingchao Qi et.al.|[2411.11714v1](http://arxiv.org/abs/2411.11714v1)|[link](https://github.com/mingchaoqi/skill_transfer)|
|**2024-11-18**|**Addressing Hallucinations in Language Models with Knowledge Graph Embeddings as an Additional Modality**|Viktoriia Chekalina et.al.|[2411.11531v1](http://arxiv.org/abs/2411.11531v1)|null|
|**2024-11-17**|**RPN 2: On Interdependence Function Learning Towards Unifying and Advancing CNN, RNN, GNN, and Transformer**|Jiawei Zhang et.al.|[2411.11162v1](http://arxiv.org/abs/2411.11162v1)|null|
|**2024-11-16**|**A Novel Approach to Eliminating Hallucinations in Large Language Model-Assisted Causal Discovery**|Grace Sng et.al.|[2411.12759v1](http://arxiv.org/abs/2411.12759v1)|null|
|**2024-11-15**|**VeriGraph: Scene Graphs for Execution Verifiable Robot Planning**|Daniel Ekpo et.al.|[2411.10446v2](http://arxiv.org/abs/2411.10446v2)|null|
|**2024-11-15**|**A Survey of Event Causality Identification: Principles, Taxonomy, Challenges, and Assessment**|Zefan Zeng et.al.|[2411.10371v1](http://arxiv.org/abs/2411.10371v1)|null|
|**2024-11-15**|**Prompting and Fine-tuning Large Language Models for Automated Code Review Comment Generation**|Md. Asif Haider et.al.|[2411.10129v1](http://arxiv.org/abs/2411.10129v1)|null|
|**2024-11-15**|**HistoLens: An LLM-Powered Framework for Multi-Layered Analysis of Historical Texts -- A Case Application of Yantie Lun**|Yifan Zeng et.al.|[2411.09978v1](http://arxiv.org/abs/2411.09978v1)|null|
|**2024-11-14**|**Accelerating Knowledge Graph and Ontology Engineering with Large Language Models**|Cogan Shimizu et.al.|[2411.09601v1](http://arxiv.org/abs/2411.09601v1)|null|
|**2024-11-14**|**Automating Reformulation of Essence Specifications via Graph Rewriting**|Ian Miguel et.al.|[2411.09576v1](http://arxiv.org/abs/2411.09576v1)|null|
|**2024-11-13**|**Towards Evaluating Large Language Models for Graph Query Generation**|Siraj Munir et.al.|[2411.08449v2](http://arxiv.org/abs/2411.08449v2)|null|
|**2024-11-13**|**Knowledge Bases in Support of Large Language Models for Processing Web News**|Yihe Zhang et.al.|[2411.08278v2](http://arxiv.org/abs/2411.08278v2)|null|
|**2024-11-12**|**Retrieval, Reasoning, Re-ranking: A Context-Enriched Framework for Knowledge Graph Completion**|Muzhi Li et.al.|[2411.08165v1](http://arxiv.org/abs/2411.08165v1)|null|
|**2024-11-12**|**Language Models as Causal Effect Generators**|Lucius E. J. Bynum et.al.|[2411.08019v1](http://arxiv.org/abs/2411.08019v1)|[link](https://github.com/lbynum/sequence-driven-scms)|
|**2024-11-12**|**From General to Specific: Utilizing General Hallucation to Automatically Measure the Role Relationship Fidelity for Specific Role-Play Agents**|Chuyi Kong et.al.|[2411.07965v1](http://arxiv.org/abs/2411.07965v1)|null|
|**2024-11-12**|**Chain Association-based Attacking and Shielding Natural Language Processing Systems**|Jiacheng Huang et.al.|[2411.07843v1](http://arxiv.org/abs/2411.07843v1)|null|
|**2024-11-11**|**Gradual Fine-Tuning with Graph Routing for Multi-Source Unsupervised Domain Adaptation**|Yao Ma et.al.|[2411.07185v1](http://arxiv.org/abs/2411.07185v1)|null|
|**2024-11-11**|**A Domain-Agnostic Neurosymbolic Approach for Big Social Data Analysis: Evaluating Mental Health Sentiment on Social Media during COVID-19**|Vedant Khandelwal et.al.|[2411.07163v1](http://arxiv.org/abs/2411.07163v1)|null|
|**2024-11-11**|**A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs**|Myeongsoo Kim et.al.|[2411.07098v1](http://arxiv.org/abs/2411.07098v1)|null|
|**2024-11-11**|**Bridge: A Unified Framework to Knowledge Graph Completion via Language Models and Knowledge Representation**|Qiao Qiao et.al.|[2411.06660v1](http://arxiv.org/abs/2411.06660v1)|null|
|**2024-11-10**|**CausalStock: Deep End-to-end Causal Discovery for News-driven Stock Movement Prediction**|Shuqi Li et.al.|[2411.06391v1](http://arxiv.org/abs/2411.06391v1)|null|
|**2024-11-09**|**Analyzing the Evolution of Graphs and Texts**|Xingzhi Guo et.al.|[2411.06295v1](http://arxiv.org/abs/2411.06295v1)|null|
|**2024-11-09**|**An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models**|Fatemeh Shiri et.al.|[2411.06048v1](http://arxiv.org/abs/2411.06048v1)|[link](https://github.com/fatemehshiri/spatial-mm)|
|**2024-11-08**|**Mitigating Hallucination with ZeroG: An Advanced Knowledge Management Engine**|Anantha Sharma et.al.|[2411.05936v1](http://arxiv.org/abs/2411.05936v1)|null|
|**2024-11-08**|**SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark**|Sithursan Sivasubramaniam et.al.|[2411.05521v2](http://arxiv.org/abs/2411.05521v2)|[link](https://github.com/jf87/sm3-text-to-query)|
|**2024-11-08**|**EUREKHA: Enhancing User Representation for Key Hackers Identification in Underground Forums**|Abdoul Nasser Hassane Amadou et.al.|[2411.05479v1](http://arxiv.org/abs/2411.05479v1)|[link](https://github.com/jumbo110/eurekha)|
|**2024-11-08**|**When are 1.58 bits enough? A Bottom-up Exploration of BitNet Quantization**|Jacob Nielsen et.al.|[2411.05882v1](http://arxiv.org/abs/2411.05882v1)|null|
|**2024-11-08**|**Exploring the Alignment Landscape: LLMs and Geometric Deep Models in Protein Representation**|Dong Shu et.al.|[2411.05316v1](http://arxiv.org/abs/2411.05316v1)|[link](https://github.com/tizzzzy/llm-gdm-alignment)|
|**2024-11-07**|**AMSnet-KG: A Netlist Dataset for LLM-based AMS Circuit Auto-Design Using Knowledge Graph RAG**|Yichen Shi et.al.|[2411.13560v1](http://arxiv.org/abs/2411.13560v1)|null|
|**2024-11-06**|**LEGO-GraphRAG: Modularizing Graph-based Retrieval-Augmented Generation for Design Space Exploration**|Yukun Cao et.al.|[2411.05844v1](http://arxiv.org/abs/2411.05844v1)|null|
|**2024-11-06**|**MEG: Medical Knowledge-Augmented Large Language Models for Question Answering**|Laura Cabello et.al.|[2411.03883v2](http://arxiv.org/abs/2411.03883v2)|[link](https://github.com/lautel/meg)|
|**2024-11-06**|**A Library Perspective on Supervised Text Processing in Digital Libraries: An Investigation in the Biomedical Domain**|Hermann Kroll et.al.|[2411.12752v1](http://arxiv.org/abs/2411.12752v1)|null|
|**2024-11-06**|**The American Sign Language Knowledge Graph: Infusing ASL Models with Linguistic Knowledge**|Lee Kezar et.al.|[2411.03568v1](http://arxiv.org/abs/2411.03568v1)|null|
|**2024-11-05**|**Graph-DPEP: Decomposed Plug and Ensemble Play for Few-Shot Document Relation Extraction with Graph-of-Thoughts Reasoning**|Tao Zhang et.al.|[2411.02864v1](http://arxiv.org/abs/2411.02864v1)|null|
|**2024-11-05**|**Multimodal Commonsense Knowledge Distillation for Visual Question Answering**|Shuo Yang et.al.|[2411.02722v1](http://arxiv.org/abs/2411.02722v1)|null|
|**2024-11-04**|**Geometry of orofacial neuromuscular signals: speech articulation decoding using surface electromyography**|Harshavardhana T. Gowda et.al.|[2411.02591v2](http://arxiv.org/abs/2411.02591v2)|[link](https://github.com/HarshavardhanaTG/geometryOfOrofacialNeuromuscularSystem)|
|**2024-11-04**|**GraphXAIN: Narratives to Explain Graph Neural Networks**|Mateusz Cedro et.al.|[2411.02540v2](http://arxiv.org/abs/2411.02540v2)|[link](https://github.com/ADMAntwerp/GraphXAIN)|
|**2024-11-04**|**Improving Scientific Hypothesis Generation with Knowledge Grounded Large Language Models**|Guangzhi Xiong et.al.|[2411.02382v1](http://arxiv.org/abs/2411.02382v1)|null|
|**2024-11-04**|**QCG-Rerank: Chunks Graph Rerank with Query Expansion in Retrieval-Augmented LLMs for Tourism Domain**|Qikai Wei et.al.|[2411.08724v1](http://arxiv.org/abs/2411.08724v1)|null|
|**2024-11-04**|**Can Language Models Enable In-Context Database?**|Yu Pan et.al.|[2411.01807v1](http://arxiv.org/abs/2411.01807v1)|null|
|**2024-11-03**|**Graph-based Confidence Calibration for Large Language Models**|Yukun Li et.al.|[2411.02454v1](http://arxiv.org/abs/2411.02454v1)|null|
|**2024-11-03**|**Ontology Population using LLMs**|Sanaz Saki Norouzi et.al.|[2411.01612v1](http://arxiv.org/abs/2411.01612v1)|null|
|**2024-11-03**|**Pre-trained Molecular Language Models with Random Functional Group Masking**|Tianhao Peng et.al.|[2411.01401v1](http://arxiv.org/abs/2411.01401v1)|null|
|**2024-11-01**|**Narrative Analysis of True Crime Podcasts With Knowledge Graph-Augmented Large Language Models**|Xinyi Leng et.al.|[2411.02435v1](http://arxiv.org/abs/2411.02435v1)|null|
|**2024-11-01**|**WLPlan: Relational Features for Symbolic Planning**|Dillon Z. Chen et.al.|[2411.00577v1](http://arxiv.org/abs/2411.00577v1)|null|
|**2024-11-01**|**GRS-QA -- Graph Reasoning-Structured Question Answering Dataset**|Anish Pahilajani et.al.|[2411.00369v3](http://arxiv.org/abs/2411.00369v3)|null|
|**2024-11-01**|**Evaluating the Impact of Lab Test Results on Large Language Models Generated Differential Diagnoses from Clinical Case Vignettes**|Balu Bhasuran et.al.|[2411.02523v1](http://arxiv.org/abs/2411.02523v1)|null|
|**2024-10-31**|**Compositional Automata Embeddings for Goal-Conditioned Reinforcement Learning**|Beyazit Yalcinkaya et.al.|[2411.00205v1](http://arxiv.org/abs/2411.00205v1)|null|
|**2024-10-31**|**Building Multi-Agent Copilot towards Autonomous Agricultural Data Management and Analysis**|Yu Pan et.al.|[2411.00188v1](http://arxiv.org/abs/2411.00188v1)|null|
|**2024-10-31**|**Exploring the Knowledge Mismatch Hypothesis: Hallucination Propensity in Small Models Fine-tuned on Data from Larger Models**|Phil Wee et.al.|[2411.00878v1](http://arxiv.org/abs/2411.00878v1)|null|
|**2024-10-31**|**Failure Modes of LLMs for Causal Reasoning on Narratives**|Khurram Yamin et.al.|[2410.23884v1](http://arxiv.org/abs/2410.23884v1)|[link](https://github.com/shantanu95/llm_causal_reasoning)|
|**2024-10-31**|**Plan-on-Graph: Self-Correcting Adaptive Planning of Large Language Model on Knowledge Graphs**|Liyi Chen et.al.|[2410.23875v1](http://arxiv.org/abs/2410.23875v1)|[link](https://github.com/liyichen-cly/pog)|
|**2024-10-31**|**LLaMo: Large Language Model-based Molecular Graph Assistant**|Jinyoung Park et.al.|[2411.00871v1](http://arxiv.org/abs/2411.00871v1)|[link](https://github.com/mlvlab/llamo)|
|**2024-10-31**|**End-to-End Ontology Learning with Large Language Models**|Andy Lo et.al.|[2410.23584v1](http://arxiv.org/abs/2410.23584v1)|[link](https://github.com/andylolu2/ollm)|
|**2024-10-30**|**Graph-Augmented Relation Extraction Model with LLMs-Generated Support Document**|Vicky Dong et.al.|[2410.23452v1](http://arxiv.org/abs/2410.23452v1)|null|
|**2024-10-30**|**FlowLLM: Flow Matching for Material Generation with Large Language Models as Base Distributions**|Anuroop Sriram et.al.|[2410.23405v1](http://arxiv.org/abs/2410.23405v1)|[link](https://github.com/facebookresearch/flowmm)|
|**2024-10-30**|**EMMA: End-to-End Multimodal Model for Autonomous Driving**|Jyh-Jing Hwang et.al.|[2410.23262v2](http://arxiv.org/abs/2410.23262v2)|null|
|**2024-10-30**|**ProTransformer: Robustify Transformers via Plug-and-Play Paradigm**|Zhichao Hou et.al.|[2410.23182v1](http://arxiv.org/abs/2410.23182v1)|null|
|**2024-10-30**|**Semantic Enrichment of the Quantum Cascade Laser Properties in Text- A Knowledge Graph Generation Approach**|Deperias Kerre et.al.|[2410.22996v1](http://arxiv.org/abs/2410.22996v1)|null|
|**2024-10-30**|**How Well Do Large Language Models Disambiguate Swedish Words?**|Richard Johansson et.al.|[2410.22827v1](http://arxiv.org/abs/2410.22827v1)|null|
|**2024-10-30**|**Beyond Ontology in Dialogue State Tracking for Goal-Oriented Chatbot**|Sejin Lee et.al.|[2410.22767v1](http://arxiv.org/abs/2410.22767v1)|[link](https://github.com/eastha0526/beyond-ontology-in-dst)|
|**2024-10-30**|**The Graph's Apprentice: Teaching an LLM Low Level Knowledge for Circuit Quality Estimation**|Reza Moravej et.al.|[2411.00843v1](http://arxiv.org/abs/2411.00843v1)|null|
|**2024-10-29**|**Are Large-Language Models Graph Algorithmic Reasoners?**|Alexander K Taylor et.al.|[2410.22597v1](http://arxiv.org/abs/2410.22597v1)|[link](https://github.com/ataylor24/magma)|
|**2024-10-29**|**Advancing Agentic Systems: Dynamic Task Decomposition, Tool Integration and Evaluation using Novel Metrics and Dataset**|Adrian Garret Gabriel et.al.|[2410.22457v1](http://arxiv.org/abs/2410.22457v1)|null|
|**2024-10-29**|**DynaMath: A Dynamic Visual Benchmark for Evaluating Mathematical Reasoning Robustness of Vision Language Models**|Chengke Zou et.al.|[2411.00836v1](http://arxiv.org/abs/2411.00836v1)|null|
|**2024-10-29**|**ADAM: An Embodied Causal Agent in Open-World Environments**|Shu Yu et.al.|[2410.22194v1](http://arxiv.org/abs/2410.22194v1)|null|
|**2024-10-29**|**GraphAide: Advanced Graph-Assisted Query and Reasoning System**|Sumit Purohit et.al.|[2411.08041v1](http://arxiv.org/abs/2411.08041v1)|null|
|**2024-10-29**|**Synergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction in LBSN**|Zhilun Zhou et.al.|[2411.00028v2](http://arxiv.org/abs/2411.00028v2)|null|
|**2024-10-29**|**A Hierarchical Language Model For Interpretable Graph Reasoning**|Sambhav Khurana et.al.|[2410.22372v1](http://arxiv.org/abs/2410.22372v1)|null|
|**2024-10-28**|**LLM-Forest for Health Tabular Data Imputation**|Xinrui He et.al.|[2410.21520v1](http://arxiv.org/abs/2410.21520v1)|null|
|**2024-10-28**|**Hierarchical Knowledge Graph Construction from Images for Scalable E-Commerce**|Zhantao Yang et.al.|[2410.21237v1](http://arxiv.org/abs/2410.21237v1)|null|
|**2024-10-28**|**CRAT: A Multi-Agent Framework for Causality-Enhanced Reflective and Retrieval-Augmented Translation with Large Language Models**|Meiqi Chen et.al.|[2410.21067v1](http://arxiv.org/abs/2410.21067v1)|null|
|**2024-10-28**|**CTINEXUS: Leveraging Optimized LLM In-Context Learning for Constructing Cybersecurity Knowledge Graphs Under Data Scarcity**|Yutong Cheng et.al.|[2410.21060v1](http://arxiv.org/abs/2410.21060v1)|null|
|**2024-10-28**|**Graph-based Uncertainty Metrics for Long-form Language Model Outputs**|Mingjian Jiang et.al.|[2410.20783v1](http://arxiv.org/abs/2410.20783v1)|[link](https://github.com/mingjianjiang-1/graph-based-uncertainty)|
|**2024-10-28**|**Plan$\times$RAG: Planning-guided Retrieval Augmented Generation**|Prakhar Verma et.al.|[2410.20753v1](http://arxiv.org/abs/2410.20753v1)|null|
|**2024-10-28**|**Simple is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation**|Mufei Li et.al.|[2410.20724v2](http://arxiv.org/abs/2410.20724v2)|[link](https://github.com/graph-com/subgraphrag)|
|**2024-10-27**|**Effective Instruction Parsing Plugin for Complex Logical Query Answering on Knowledge Graphs**|Xingrui Zhuo et.al.|[2410.20321v1](http://arxiv.org/abs/2410.20321v1)|null|
|**2024-10-26**|**Mathematical Derivation Graphs: A Task for Summarizing Equation Dependencies in STEM Manuscripts**|Vishesh Prasad et.al.|[2410.21324v1](http://arxiv.org/abs/2410.21324v1)|null|
|**2024-10-25**|**DualMAR: Medical-Augmented Representation from Dual-Expertise Perspectives**|Pengfei Hu et.al.|[2410.19955v1](http://arxiv.org/abs/2410.19955v1)|null|
|**2024-10-25**|**FISHNET: Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert Swarms, and Task Planning**|Nicole Cho et.al.|[2410.19727v1](http://arxiv.org/abs/2410.19727v1)|null|
|**2024-10-25**|**Knowledge Graph Enhanced Language Agents for Recommendation**|Taicheng Guo et.al.|[2410.19627v1](http://arxiv.org/abs/2410.19627v1)|null|
|**2024-10-25**|**Graph Linearization Methods for Reasoning on Graphs with Large Language Models**|Christos Xypolopoulos et.al.|[2410.19494v1](http://arxiv.org/abs/2410.19494v1)|null|
|**2024-10-25**|**Hierarchical Mixture of Experts: Generalizable Learning for High-Level Synthesis**|Weikai Li et.al.|[2410.19225v1](http://arxiv.org/abs/2410.19225v1)|null|
|**2024-10-24**|**Enriching GNNs with Text Contextual Representations for Detecting Disinformation Campaigns on Social Media**|Bruno Croso Cunha da Silva et.al.|[2410.19193v1](http://arxiv.org/abs/2410.19193v1)|null|
|**2024-10-24**|**GCoder: Improving Large Language Model for Generalized Graph Problem Solving**|Qifan Zhang et.al.|[2410.19084v1](http://arxiv.org/abs/2410.19084v1)|[link](https://github.com/bklight999/www25-gcoder)|
|**2024-10-24**|**LLM-based Online Prediction of Time-varying Graph Signals**|Dayu Qin et.al.|[2410.18718v1](http://arxiv.org/abs/2410.18718v1)|null|
|**2024-10-24**|**Gene-Metabolite Association Prediction with Interactive Knowledge Transfer Enhanced Graph for Metabolite Production**|Kexuan Xin et.al.|[2410.18475v2](http://arxiv.org/abs/2410.18475v2)|null|
|**2024-10-24**|**ToolFlow: Boosting LLM Tool-Calling Through Natural and Coherent Dialogue Synthesis**|Zezhong Wang et.al.|[2410.18447v1](http://arxiv.org/abs/2410.18447v1)|null|
|**2024-10-24**|**Decoding on Graphs: Faithful and Sound Reasoning on Knowledge Graphs through Generation of Well-Formed Chains**|Kun Li et.al.|[2410.18415v1](http://arxiv.org/abs/2410.18415v1)|null|

#### Abstracts
##### **Knowledge Graphs, Large Language Models, and Hallucinations: An NLP Perspective**
2411.14258v1 by Ernests Lavrinovics, Russa Biswas, Johannes Bjerva, Katja Hose

Large Language Models (LLMs) have revolutionized Natural Language Processing
(NLP) based applications including automated text generation, question
answering, chatbots, and others. However, they face a significant challenge:
hallucinations, where models produce plausible-sounding but factually incorrect
responses. This undermines trust and limits the applicability of LLMs in
different domains. Knowledge Graphs (KGs), on the other hand, provide a
structured collection of interconnected facts represented as entities (nodes)
and their relationships (edges). In recent research, KGs have been leveraged to
provide context that can fill gaps in an LLM understanding of certain topics
offering a promising approach to mitigate hallucinations in LLMs, enhancing
their reliability and accuracy while benefiting from their wide applicability.
Nonetheless, it is still a very active area of research with various unresolved
open problems. In this paper, we discuss these open challenges covering
state-of-the-art datasets and benchmarks as well as methods for knowledge
integration and evaluating hallucinations. In our discussion, we consider the
current use of KGs in LLM systems and identify future directions within each of
these challenges.

摘要：大型語言模型（LLM）徹底改變了基於自然語言處理（NLP）的應用，包括自動文字生成、問題解答、聊天機器人等。然而，它們面臨著一個重大的挑戰：幻覺，模型產生聽起來合理但事實上不正確的回應。這會破壞信任，並限制 LLM 在不同領域的適用性。另一方面，知識圖譜（KG）提供了以實體（節點）及其關係（邊緣）表示的相互連接事實的結構化集合。在最近的研究中，KG 已被用於提供上下文，可以填補 LLM 對某些主題理解的空白，提供了一種有希望的方法來減輕 LLM 中的幻覺，提高它們的可靠性和準確性，同時受益於它們的廣泛適用性。儘管如此，這仍然是一個非常活躍的研究領域，有各種未解決的開放問題。在本文中，我們討論了這些開放挑戰，涵蓋了最先進的數據集和基準，以及知識整合和評估幻覺的方法。在我們的討論中，我們考慮了 LLM 系統中 KG 的當前使用，並確定了這些挑戰中的每一個未來的方向。

##### **Logic Augmented Generation**
2411.14012v1 by Aldo Gangemi, Andrea Giovanni Nuzzolese

Semantic Knowledge Graphs (SKG) face challenges with scalability,
flexibility, contextual understanding, and handling unstructured or ambiguous
information. However, they offer formal and structured knowledge enabling
highly interpretable and reliable results by means of reasoning and querying.
Large Language Models (LLMs) overcome those limitations making them suitable in
open-ended tasks and unstructured environments. Nevertheless, LLMs are neither
interpretable nor reliable. To solve the dichotomy between LLMs and SKGs we
envision Logic Augmented Generation (LAG) that combines the benefits of the two
worlds. LAG uses LLMs as Reactive Continuous Knowledge Graphs that can generate
potentially infinite relations and tacit knowledge on-demand. SKGs are key for
injecting a discrete heuristic dimension with clear logical and factual
boundaries. We exemplify LAG in two tasks of collective intelligence, i.e.,
medical diagnostics and climate projections. Understanding the properties and
limitations of LAG, which are still mostly unknown, is of utmost importance for
enabling a variety of tasks involving tacit knowledge in order to provide
interpretable and effective results.

摘要：語意知識圖（SKG）在可擴充性、靈活性、情境理解以及處理非結構化或含糊資訊方面面臨挑戰。然而，它們提供正式且結構化的知識，能透過推理和查詢提供高度可解釋且可靠的結果。大型語言模型（LLM）克服了這些限制，使其適用於開放式任務和非結構化環境。儘管如此，LLM 既不可解釋也不可靠。為了解決 LLM 和 SKG 之間的二分法，我們設想了邏輯增強生成（LAG），它結合了兩個世界的優點。LAG 使用 LLM 作為反應式連續知識圖，它可以按需產生潛在的無限關係和默會知識。SKG 是注入離散啟發式維度（具有明確邏輯和事實邊界）的關鍵。我們在集體智慧的兩個任務中舉例說明 LAG，即醫療診斷和氣候預測。理解 LAG 的特性和限制（目前仍然大多數未知）對於啟用涉及默會知識的各種任務以提供可解釋且有效的結果至關重要。

##### **FastRAG: Retrieval Augmented Generation for Semi-structured Data**
2411.13773v1 by Amar Abane, Anis Bekri, Abdella Battou

Efficiently processing and interpreting network data is critical for the
operation of increasingly complex networks. Recent advances in Large Language
Models (LLM) and Retrieval-Augmented Generation (RAG) techniques have improved
data processing in network management. However, existing RAG methods like
VectorRAG and GraphRAG struggle with the complexity and implicit nature of
semi-structured technical data, leading to inefficiencies in time, cost, and
retrieval. This paper introduces FastRAG, a novel RAG approach designed for
semi-structured data. FastRAG employs schema learning and script learning to
extract and structure data without needing to submit entire data sources to an
LLM. It integrates text search with knowledge graph (KG) querying to improve
accuracy in retrieving context-rich information. Evaluation results demonstrate
that FastRAG provides accurate question answering, while improving up to 90% in
time and 85% in cost compared to GraphRAG.

摘要：有效率地處理和解讀網路資料對於日益複雜的網路操作至關重要。大型語言模型 (LLM) 和檢索增強產生 (RAG) 技術的最新進展已經改善了網路管理中的資料處理。然而，現有的 RAG 方法（例如 VectorRAG 和 GraphRAG）難以應付半結構化技術資料的複雜性和隱含性質，導致時間、成本和檢索效率不彰。本文介紹 FastRAG，一種專為半結構化資料設計的新穎 RAG 方法。FastRAG 使用架構學習和腳本學習來萃取和建構資料，而無需將整個資料來源提交給 LLM。它將文字搜尋與知識圖譜 (KG) 查詢整合，以提高檢索內容豐富資訊的準確性。評估結果證明，FastRAG 提供了準確的問答，同時與 GraphRAG 相比，時間改善了 90%，成本改善了 85%。

##### **Predictive Insights into LGBTQ+ Minority Stress: A Transductive Exploration of Social Media Discourse**
2411.13534v1 by S. Chapagain, Y. Zhao, T. K. Rohleen, S. M. Hamdi, S. F. Boubrahimi, R. E. Flinn, E. M. Lund, D. Klooster, J. R. Scheer, C. J. Cascalheira

Individuals who identify as sexual and gender minorities, including lesbian,
gay, bisexual, transgender, queer, and others (LGBTQ+) are more likely to
experience poorer health than their heterosexual and cisgender counterparts.
One primary source that drives these health disparities is minority stress
(i.e., chronic and social stressors unique to LGBTQ+ communities' experiences
adapting to the dominant culture). This stress is frequently expressed in
LGBTQ+ users' posts on social media platforms. However, these expressions are
not just straightforward manifestations of minority stress. They involve
linguistic complexity (e.g., idiom or lexical diversity), rendering them
challenging for many traditional natural language processing methods to detect.
In this work, we designed a hybrid model using Graph Neural Networks (GNN) and
Bidirectional Encoder Representations from Transformers (BERT), a pre-trained
deep language model to improve the classification performance of minority
stress detection. We experimented with our model on a benchmark social media
dataset for minority stress detection (LGBTQ+ MiSSoM+). The dataset is
comprised of 5,789 human-annotated Reddit posts from LGBTQ+ subreddits. Our
approach enables the extraction of hidden linguistic nuances through
pretraining on a vast amount of raw data, while also engaging in transductive
learning to jointly develop representations for both labeled training data and
unlabeled test data. The RoBERTa-GCN model achieved an accuracy of 0.86 and an
F1 score of 0.86, surpassing the performance of other baseline models in
predicting LGBTQ+ minority stress. Improved prediction of minority stress
expressions on social media could lead to digital health interventions to
improve the wellbeing of LGBTQ+ people-a community with high rates of
stress-sensitive health problems.

摘要：<paragraph>認同自己是性與性別少數族群的人，包括女同性戀、男同性戀、雙性戀、跨性別、酷兒和其他 LGBTQ+ 族群，比異性戀和順性別者更容易有較差的健康狀況。造成這些健康差異的主要來源之一是少數族群壓力（即 LGBTQ+ 社群在適應主流文化時獨有的慢性與社會壓力）。這種壓力經常在 LGBTQ+ 使用者於社群媒體平台上的貼文中表達出來。然而，這些表達並不僅僅是少數族群壓力的直接表現。它們包含了語言複雜性（例如慣用語或詞彙多樣性），讓許多傳統的自然語言處理方法難以辨識。在這項研究中，我們設計了一個混合模型，使用圖神經網路 (GNN) 和來自 Transformer 的雙向編碼器表徵 (BERT)，這是一個經過預先訓練的深度語言模型，以提升少數族群壓力辨識的分類效能。我們在一個用於少數族群壓力辨識的基準社群媒體資料集 (LGBTQ+ MiSSoM+) 上對我們的模型進行實驗。該資料集包含了 5,789 篇由人類註解的 Reddit 貼文，來自於 LGBTQ+ 的 subreddit。我們的做法能夠透過在大量的原始資料上進行預訓練來萃取隱藏的語言差異，同時也參與轉導式學習，以共同開發標籤訓練資料和未標籤測試資料的表徵。RoBERTa-GCN 模型達到了 0.86 的準確率和 0.86 的 F1 分數，在預測 LGBTQ+ 少數族群壓力方面超越了其他基線模型的效能。在社群媒體上對少數族群壓力表達的預測改善，可以導致數位健康介入措施，以改善 LGBTQ+ 族群的福祉，而這個族群有很高的壓力敏感性健康問題發生率。</paragraph>

##### **KAAE: Numerical Reasoning for Knowledge Graphs via Knowledge-aware Attributes Learning**
2411.12950v1 by Ming Yin, Qiang Zhou, Zongsheng Cao, Mei Li

Numerical reasoning is pivotal in various artificial intelligence
applications, such as natural language processing and recommender systems,
where it involves using entities, relations, and attribute values (e.g.,
weight, length) to infer new factual relations (e.g., the Nile is longer than
the Amazon). However, existing approaches encounter two critical challenges in
modeling: (1) semantic relevance-the challenge of insufficiently capturing the
necessary contextual interactions among entities, relations, and numerical
attributes, often resulting in suboptimal inference; and (2) semantic
ambiguity-the difficulty in accurately distinguishing ordinal relationships
during numerical reasoning, which compromises the generation of high-quality
samples and limits the effectiveness of contrastive learning. To address these
challenges, we propose the novel Knowledge-Aware Attributes Embedding model
(KAAE) for knowledge graph embeddings in numerical reasoning. Specifically, to
overcome the challenge of semantic relevance, we introduce a
Mixture-of-Experts-Knowledge-Aware (MoEKA) Encoder, designed to integrate the
semantics of entities, relations, and numerical attributes into a joint
semantic space. To tackle semantic ambiguity, we implement a new ordinal
knowledge contrastive learning (OKCL) strategy that generates high-quality
ordinal samples from the original data with the aid of ordinal relations,
capturing fine-grained semantic nuances essential for accurate numerical
reasoning. Experiments on three public benchmark datasets demonstrate the
superior performance of KAAE across various attribute value distributions.

摘要：數字推理在各種人工智慧應用中至關重要，例如自然語言處理和推薦系統，其中涉及使用實體、關係和屬性值（例如，重量、長度）來推斷新的事實關係（例如，尼羅河比亞馬遜河長）。然而，現有方法在建模中遇到兩個關鍵挑戰：(1) 語義相關性 - 無法充分捕捉實體、關係和數值屬性之間必要的上下文交互的挑戰，通常導致次優推論；(2) 語義模糊 - 在數字推理過程中準確區分序數關係的難度，這會損害高品質樣本的生成並限制對比學習的有效性。為了應對這些挑戰，我們提出了用於數字推理中知識圖嵌入的知識感知屬性嵌入模型 (KAAE)。具體來說，為了克服語義相關性的挑戰，我們引入了一個混合專家知識感知 (MoEKA) 編碼器，旨在將實體、關係和數值屬性的語義整合到一個聯合語義空間中。為了應對語義模糊，我們實施了一種新的序數知識對比學習 (OKCL) 策略，該策略利用序數關係從原始數據中生成高品質序數樣本，捕捉對準確數字推理至關重要的細粒度語義細微差別。在三個公共基準數據集上的實驗證明了 KAAE 在各種屬性值分佈中的卓越性能。

##### **Neurosymbolic Graph Enrichment for Grounded World Models**
2411.12671v1 by Stefano De Giorgis, Aldo Gangemi, Alessandro Russo

The development of artificial intelligence systems capable of understanding
and reasoning about complex real-world scenarios is a significant challenge. In
this work we present a novel approach to enhance and exploit LLM reactive
capability to address complex problems and interpret deeply contextual
real-world meaning. We introduce a method and a tool for creating a multimodal,
knowledge-augmented formal representation of meaning that combines the
strengths of large language models with structured semantic representations.
Our method begins with an image input, utilizing state-of-the-art large
language models to generate a natural language description. This description is
then transformed into an Abstract Meaning Representation (AMR) graph, which is
formalized and enriched with logical design patterns, and layered semantics
derived from linguistic and factual knowledge bases. The resulting graph is
then fed back into the LLM to be extended with implicit knowledge activated by
complex heuristic learning, including semantic implicatures, moral values,
embodied cognition, and metaphorical representations. By bridging the gap
between unstructured language models and formal semantic structures, our method
opens new avenues for tackling intricate problems in natural language
understanding and reasoning.

摘要：人工智能系統的發展能夠理解並推理複雜的真實世界場景是一個重大的挑戰。在這項工作中，我們提出了一種新穎的方法來增強和利用 LLM 反應能力，以解決複雜的問題並解釋深層的語境真實世界意義。我們介紹了一種方法和工具，用於建立多模態、知識增強的意義形式化表示，結合了大型語言模型與結構化語義表示的優點。我們的模型從影像輸入開始，利用最先進的大型語言模型來產生自然語言描述。然後將此描述轉換為抽象意義表示 (AMR) 圖形，並使用邏輯設計模式進行形式化和豐富，以及從語言和事實知識庫中衍生的分層語義。然後將結果圖形回饋到 LLM，以擴充 LLM 中由複雜的啟發式學習所啟用的內隱知識，包括語義蘊涵、道德價值、具身認知和隱喻表示。我們的模型透過彌合非結構化語言模型與形式語義結構之間的差距，為解決自然語言理解和推理中的複雜問題開闢了新的途徑。

##### **Instant Policy: In-Context Imitation Learning via Graph Diffusion**
2411.12633v1 by Vitalis Vosylius, Edward Johns

Following the impressive capabilities of in-context learning with large
transformers, In-Context Imitation Learning (ICIL) is a promising opportunity
for robotics. We introduce Instant Policy, which learns new tasks instantly
(without further training) from just one or two demonstrations, achieving ICIL
through two key components. First, we introduce inductive biases through a
graph representation and model ICIL as a graph generation problem with a
learned diffusion process, enabling structured reasoning over demonstrations,
observations, and actions. Second, we show that such a model can be trained
using pseudo-demonstrations - arbitrary trajectories generated in simulation -
as a virtually infinite pool of training data. Simulated and real experiments
show that Instant Policy enables rapid learning of various everyday robot
tasks. We also show how it can serve as a foundation for cross-embodiment and
zero-shot transfer to language-defined tasks. Code and videos are available at
https://www.robot-learning.uk/instant-policy.

摘要：繼大型Transformer在情境學習中表現出令人印象深刻的能力後，情境模仿學習 (ICIL) 成為了機器人領域中一個有前途的機會。我們引入了即時策略，它僅從一或兩次示範中立即學習新任務（無需進一步訓練），並通過兩個關鍵組成部分實現 ICIL。首先，我們通過圖形表示和模型 ICIL 引入歸納偏差，並將其作為具有學習擴散過程的圖形生成問題，從而能夠對示範、觀察和動作進行結構化推理。其次，我們展示了這種模型可以使用偽示範進行訓練，而偽示範是模擬中產生的任意軌跡，可用作幾乎無限的訓練數據池。模擬和真實實驗表明，即時策略能夠快速學習各種日常機器人任務。我們還展示了它如何作為跨具身和零次傳輸到語言定義任務的基礎。代碼和影片可在 https://www.robot-learning.uk/instant-policy 取得。

##### **Bias Free Sentiment Analysis**
2411.12493v1 by Hubert Plisiecki

This paper introduces the Semantic Propagation Graph Neural Network (SProp
GNN), a machine learning sentiment analysis (SA) architecture that relies
exclusively on syntactic structures and word-level emotional cues to predict
emotions in text. By semantically blinding the model to information about
specific words, it is robust to biases such as political or gender bias that
have been plaguing previous machine learning-based SA systems. The SProp GNN
shows performance superior to lexicon-based alternatives such as VADER and
EmoAtlas on two different prediction tasks, and across two languages.
Additionally, it approaches the accuracy of transformer-based models while
significantly reducing bias in emotion prediction tasks. By offering improved
explainability and reducing bias, the SProp GNN bridges the methodological gap
between interpretable lexicon approaches and powerful, yet often opaque, deep
learning models, offering a robust tool for fair and effective emotion analysis
in understanding human behavior through text.

摘要：本文介紹語意傳播圖神經網路 (SProp GNN)，這是一種機器學習情緒分析 (SA) 架構，僅依賴語法結構和字詞層級的情緒線索來預測文字中的情緒。透過在語意上讓模型對特定字詞的資訊視而不見，它能抵抗政治或性別偏見等偏差，而這些偏差一直困擾著先前的基於機器學習的 SA 系統。SProp GNN 在兩項不同的預測任務和兩種語言中都表現出優於 VADER 和 EmoAtlas 等基於詞彙的替代方案。此外，它接近基於轉換器的模型的準確性，同時大幅減少情緒預測任務中的偏差。透過提供更好的可解釋性並減少偏差，SProp GNN 彌合了可解釋詞彙方法與強大但通常不透明的深度學習模型之間的方法論差距，提供了一個強大的工具，用於透過文字理解人類行為的公平和有效的情緒分析。

##### **Neon: News Entity-Interaction Extraction for Enhanced Question Answering**
2411.12449v2 by Sneha Singhania, Silviu Cucerzan, Allen Herring, Sujay Kumar Jauhar

Capturing fresh information in near real-time and using it to augment
existing large language models (LLMs) is essential to generate up-to-date,
grounded, and reliable output. This problem becomes particularly challenging
when LLMs are used for informational tasks in rapidly evolving fields, such as
Web search related to recent or unfolding events involving entities, where
generating temporally relevant responses requires access to up-to-the-hour news
sources. However, the information modeled by the parametric memory of LLMs is
often outdated, and Web results from prototypical retrieval systems may fail to
capture the latest relevant information and struggle to handle conflicting
reports in evolving news. To address this challenge, we present the NEON
framework, designed to extract emerging entity interactions -- such as events
or activities -- as described in news articles. NEON constructs an
entity-centric timestamped knowledge graph that captures such interactions,
thereby facilitating enhanced QA capabilities related to news events. Our
framework innovates by integrating open Information Extraction (openIE) style
tuples into LLMs to enable in-context retrieval-augmented generation. This
integration demonstrates substantial improvements in QA performance when
tackling temporal, entity-centric search queries. Through NEON, LLMs can
deliver more accurate, reliable, and up-to-date responses.

摘要：捕捉近乎實時的最新資訊，並利用它來擴充現有的大型語言模型 (LLM)，對於產生即時、有根據且可靠的輸出至關重要。當 LLM 被用於快速演化的領域中的訊息任務時，這個問題會變得特別具有挑戰性，例如與涉及實體的近期或正在發生的事件相關的網路搜尋，在這種情況下，產生時間相關的回應需要取得最新的新聞來源。然而，LLM 的參數記憶體建模的資訊經常過時，而原型檢索系統的網路結果可能無法捕捉最新的相關資訊，並且難以處理演化中的新聞中的相互矛盾的報導。為了應對這個挑戰，我們提出了 NEON 框架，旨在萃取新興實體互動（例如事件或活動），如新聞文章中所描述的。NEON 建構了一個以實體為中心的帶時間戳記的知識圖譜，用來捕捉此類互動，從而促進與新聞事件相關的增強式問答能力。我們的框架透過將開放資訊萃取 (openIE) 風格元組整合到 LLM 中，以啟用情境內檢索增強式產生，進而創新。當處理時間、以實體為中心的搜尋查詢時，這種整合顯示出問答效能的顯著提升。透過 NEON，LLM 可以提供更準確、可靠且最新的回應。

##### **Just KIDDIN: Knowledge Infusion and Distillation for Detection of INdecent Memes**
2411.12174v1 by Rahul Garg, Trilok Padhi, Hemang Jain, Ugur Kursuncu, Ponnurangam Kumaraguru

Toxicity identification in online multimodal environments remains a
challenging task due to the complexity of contextual connections across
modalities (e.g., textual and visual). In this paper, we propose a novel
framework that integrates Knowledge Distillation (KD) from Large Visual
Language Models (LVLMs) and knowledge infusion to enhance the performance of
toxicity detection in hateful memes. Our approach extracts sub-knowledge graphs
from ConceptNet, a large-scale commonsense Knowledge Graph (KG) to be infused
within a compact VLM framework. The relational context between toxic phrases in
captions and memes, as well as visual concepts in memes enhance the model's
reasoning capabilities. Experimental results from our study on two hate speech
benchmark datasets demonstrate superior performance over the state-of-the-art
baselines across AU-ROC, F1, and Recall with improvements of 1.1%, 7%, and 35%,
respectively. Given the contextual complexity of the toxicity detection task,
our approach showcases the significance of learning from both explicit (i.e.
KG) as well as implicit (i.e. LVLMs) contextual cues incorporated through a
hybrid neurosymbolic approach. This is crucial for real-world applications
where accurate and scalable recognition of toxic content is critical for
creating safer online environments.

摘要：網路多模態環境中的毒性辨識，由於模態間（例如文字和視覺）的脈絡關聯複雜，因此仍是一項具有挑戰性的任務。在本文中，我們提出一個新穎的架構，整合來自大型視覺語言模型 (LVLMs) 的知識蒸餾 (KD) 和知識注入，以增強仇恨迷因中毒性偵測的效能。我們的做法從 ConceptNet（一個大型常識知識圖譜 (KG)）中萃取子知識圖，並注入到一個緊湊的 VLM 架構中。標題和迷因中具有毒性的詞彙之間的關係脈絡，以及迷因中的視覺概念，增強了模型的推理能力。我們在兩個仇恨言論基準資料集上進行的研究的實驗結果，證明了在 AU-ROC、F1 和召回率方面，我們的做法優於最先進的基準，分別提升了 1.1%、7% 和 35%。鑑於毒性偵測任務的脈絡複雜性，我們的做法展示了從明確（例如 KG）和隱含（例如 LVLMs）脈絡線索中學習，並透過混合神經符號方法整合起來的重要性。這對於真實世界的應用至關重要，在這些應用中，準確且可擴充的毒性內容辨識對於創造更安全的網路環境至關重要。

##### **Regret-Free Reinforcement Learning for LTL Specifications**
2411.12019v1 by Rupak Majumdar, Mahmoud Salamati, Sadegh Soudjani

Reinforcement learning (RL) is a promising method to learn optimal control
policies for systems with unknown dynamics. In particular, synthesizing
controllers for safety-critical systems based on high-level specifications,
such as those expressed in temporal languages like linear temporal logic (LTL),
presents a significant challenge in control systems research. Current RL-based
methods designed for LTL tasks typically offer only asymptotic guarantees,
which provide no insight into the transient performance during the learning
phase. While running an RL algorithm, it is crucial to assess how close we are
to achieving optimal behavior if we stop learning.
  In this paper, we present the first regret-free online algorithm for learning
a controller that addresses the general class of LTL specifications over Markov
decision processes (MDPs) with a finite set of states and actions. We begin by
proposing a regret-free learning algorithm to solve infinite-horizon
reach-avoid problems. For general LTL specifications, we show that the
synthesis problem can be reduced to a reach-avoid problem when the graph
structure is known. Additionally, we provide an algorithm for learning the
graph structure, assuming knowledge of a minimum transition probability, which
operates independently of the main regret-free algorithm.

摘要：強化學習 (RL) 是一種有希望的方法，可以學習未知動態系統的最佳控制策略。特別是，基於高階規範（例如用線性時序邏輯 (LTL) 等時序語言表達的規範）為安全關鍵系統合成控制器，這在控制系統研究中是一個重大挑戰。目前的基於 RL 的 LTL 任務方法通常僅提供漸近保證，這在學習階段沒有提供暫態效能的見解。在執行 RL 演算法時，如果我們停止學習，評估我們距離達成最佳行為有多近至關重要。在本文中，我們提出了第一個無遺憾線上演算法，用於學習一個控制器，該控制器解決了馬可夫決策過程 (MDP) 上的一般類別 LTL 規範，其中包含有限的狀態和動作集合。我們首先提出一個無遺憾學習演算法來解決無限時域到達避免問題。對於一般 LTL 規範，我們表明當圖形結構已知時，合成問題可以簡化為到達避免問題。此外，我們提供了一個演算法來學習圖形結構，假設知道最小轉移機率，它獨立於主要的無遺憾演算法運作。

##### **Semantic-Geometric-Physical-Driven Robot Manipulation Skill Transfer via Skill Library and Tactile Representation**
2411.11714v1 by Mingchao Qi, Yuanjin Li, Xing Liu, Zhengxiong Liu, Panfeng Huang

Deploying robots in open-world environments involves complex tasks
characterized by long sequences and rich interactions, necessitating efficient
transfer of robotic skills across diverse and complex scenarios. To address
this challenge, we propose a skill library framework based on knowledge graphs,
which endows robots with high-level skill awareness and spatial semantic
understanding. The framework hierarchically organizes operational knowledge by
constructing a "task graph" and a "scene graph" to represent task and scene
semantic information, respectively. We introduce a "state graph" to facilitate
interaction between high-level task planning and low-level scene information.
Furthermore, we propose a hierarchical transfer framework for operational
skills. At the task level, the framework integrates contextual learning and
chain-of-thought prompting within a four-stage prompt paradigm, leveraging
large language models' (LLMs) reasoning and generalization capabilities to
achieve task-level subtask sequence transfer. At the motion level, an adaptive
trajectory transfer method is developed using the A* algorithm and the skill
library, enabling motion-level adaptive trajectory transfer. At the physical
level, we introduce an adaptive contour extraction and posture perception
method based on tactile perception. This method dynamically obtains
high-precision contour and posture information from visual-tactile texture data
and adjusts transferred skills, such as contact positions and postures, to
ensure effectiveness in new environments. Experimental results validate the
effectiveness of the proposed methods. Project
website:https://github.com/MingchaoQi/skill_transfer

摘要：<paragraph>在开放世界环境中部署机器人涉及复杂的任务，其特点是序列长、交互丰富，需要在不同且复杂的场景中高效地转移机器人技能。为了应对这一挑战，我们提出一个基于知识图谱的技能库框架，它赋予机器人高级技能意识和空间语义理解。该框架通过构建“任务图”和“场景图”来分层组织操作知识，分别表示任务和场景语义信息。我们引入一个“状态图”来促进高级任务规划和低级场景信息之间的交互。此外，我们提出了一个操作技能的分层转移框架。在任务层面，该框架在一个四阶段提示范式中集成了上下文学习和思想链提示，利用大语言模型 (LLM) 的推理和泛化能力来实现任务级子任务序列转移。在运动层面，使用 A* 算法和技能库开发了一种自适应轨迹转移方法，实现运动级自适应轨迹转移。在物理层面，我们引入了一种基于触觉感知的自适应轮廓提取和姿态感知方法。该方法从视觉触觉纹理数据中动态获取高精度的轮廓和姿态信息，并调整转移的技能，例如接触位置和姿态，以确保在新的环境中有效。实验结果验证了所提出方法的有效性。项目网站：https://github.com/MingchaoQi/skill_transfer</paragraph>

##### **Addressing Hallucinations in Language Models with Knowledge Graph Embeddings as an Additional Modality**
2411.11531v1 by Viktoriia Chekalina, Anton Razzigaev, Elizaveta Goncharova, Andrey Kuznetsov

In this paper we present an approach to reduce hallucinations in Large
Language Models (LLMs) by incorporating Knowledge Graphs (KGs) as an additional
modality. Our method involves transforming input text into a set of KG
embeddings and using an adapter to integrate these embeddings into the language
model space, without relying on external retrieval processes.
  To facilitate this, we created WikiEntities, a dataset containing over 3
million Wikipedia texts annotated with entities from Wikidata and their
corresponding embeddings from PyTorch-BigGraph. This dataset serves as a
valuable resource for training Entity Linking models and adapting the described
method to various LLMs using specialized adapters.
  Our method does not require fine-tuning of the language models themselves;
instead, we only train the adapter. This ensures that the model's performance
on other tasks is not affected. We trained an adapter for the Mistral 7B, LLaMA
2-7B (chat), and LLaMA 3-8B (instruct) models using this dataset and
demonstrated that our approach improves performance on the HaluEval, True-False
benchmarks and FEVER dataset. The results indicate that incorporating KGs as a
new modality can effectively reduce hallucinations and improve the factual
accuracy of language models, all without the need for external retrieval.

摘要：<paragraph>在本文中，我們提出了一種方法，透過將知識圖譜 (KG) 作為附加方式納入大型語言模型 (LLM)，以減少幻覺。我們的做法包括將輸入文字轉換成一組 KG 嵌入，並使用適配器將這些嵌入整合到語言模型空間，而無需依賴外部檢索程序。
為了促進這一點，我們建立了 WikiEntities，這是一個包含超過 300 萬個維基百科文字的資料集，其中附有來自 Wikidata 的實體註解，以及它們來自 PyTorch-BigGraph 的對應嵌入。此資料集作為訓練實體連結模型和使用專門適配器將所述方法調整到各種 LLM 的寶貴資源。
我們的做法不需要微調語言模型本身；相反，我們只訓練適配器。這確保了模型在其他任務上的效能不受影響。我們使用此資料集訓練了 Mistral 7B、LLaMA 2-7B (聊天) 和 LLaMA 3-8B (指令) 模型的適配器，並證明了我們的做法改善了 HaluEval、真假基準和 FEVER 資料集的效能。結果表明，將 KG 作為一種新方式納入可以有效減少幻覺，並提高語言模型的事實準確性，而無需外部檢索。</paragraph>

##### **RPN 2: On Interdependence Function Learning Towards Unifying and Advancing CNN, RNN, GNN, and Transformer**
2411.11162v1 by Jiawei Zhang

This paper builds upon our previous work on the Reconciled Polynomial Network
(RPN). The original RPN model was designed under the assumption of input data
independence, presuming the independence among both individual instances within
data batches and attributes in each data instance. However, this assumption
often proves invalid for function learning tasks involving complex,
interdependent data such as language, images, time series, and graphs. Ignoring
such data interdependence may inevitably lead to significant performance
degradation.
  To overcome these limitations, we introduce the new Reconciled Polynomial
Network (version 2), namely RPN 2, in this paper. By incorporating data and
structural interdependence functions, RPN 2 explicitly models data
interdependence via new component functions in its architecture.
  This enhancement not only significantly improves RPN 2's learning performance
but also substantially expands its unifying potential, enabling it to encompass
a broader range of contemporary dominant backbone models within its canonical
representation. These backbones include, but are not limited to, convolutional
neural networks (CNNs), recurrent neural networks (RNNs), graph neural networks
(GNNs), and Transformers. Our analysis reveals that the fundamental
distinctions among these backbone models primarily stem from their diverse
approaches to defining the interdependence functions. Furthermore, this unified
representation opens up new opportunities for designing innovative
architectures with the potential to surpass the performance of these dominant
backbones.

摘要：本文建立在我们先前关于协调多项式网络 (RPN) 的工作之上。最初的 RPN 模型是在输入数据独立性的假设下设计的，假定数据批次中各个实例之间的独立性以及每个数据实例中的属性之间的独立性。然而，对于涉及复杂相互依赖数据（例如语言、图像、时间序列和图形）的功能学习任务，这种假设通常被证明是无效的。忽略此类数据相互依赖性不可避免地会导致性能显着下降。
为了克服这些限制，我们在本文中引入了新的协调多项式网络（版本 2），即 RPN 2。通过结合数据和结构相互依赖函数，RPN 2 通过其架构中的新组件函数明确地对数据相互依赖性进行建模。
这种增强不仅显着提高了 RPN 2 的学习性能，而且还大幅扩展了其统一潜力，使其能够在其规范表示中包含更广泛的当代主干模型。这些主干包括但不限于卷积神经网络 (CNN)、循环神经网络 (RNN)、图神经网络 (GNN) 和 Transformer。我们的分析表明，这些主干模型之间的根本区别主要源于它们定义相互依赖函数的不同方法。此外，这种统一表示为设计创新架构开辟了新的机会，这些架构有可能超越这些主干的性能。

##### **A Novel Approach to Eliminating Hallucinations in Large Language Model-Assisted Causal Discovery**
2411.12759v1 by Grace Sng, Yanming Zhang, Klaus Mueller

The increasing use of large language models (LLMs) in causal discovery as a
substitute for human domain experts highlights the need for optimal model
selection. This paper presents the first hallucination survey of popular LLMs
for causal discovery. We show that hallucinations exist when using LLMs in
causal discovery so the choice of LLM is important. We propose using Retrieval
Augmented Generation (RAG) to reduce hallucinations when quality data is
available. Additionally, we introduce a novel method employing multiple LLMs
with an arbiter in a debate to audit edges in causal graphs, achieving a
comparable reduction in hallucinations to RAG.

摘要：隨著大型語言模型 (LLM) 在因果發現中作為人類領域專家的替代品使用日益增加，這凸顯了最佳模型選擇的需求。本文提出了第一份流行 LLM 的幻覺調查以進行因果發現。我們表明在因果發現中使用 LLM 時存在幻覺，因此 LLM 的選擇很重要。我們建議使用檢索強化生成 (RAG) 來減少在有品質資料時產生的幻覺。此外，我們引入了一種新的方法，在辯論中使用多個 LLM 和仲裁者來審核因果圖中的邊緣，與 RAG 相比，幻覺減少了許多。

##### **VeriGraph: Scene Graphs for Execution Verifiable Robot Planning**
2411.10446v2 by Daniel Ekpo, Mara Levy, Saksham Suri, Chuong Huynh, Abhinav Shrivastava

Recent advancements in vision-language models (VLMs) offer potential for
robot task planning, but challenges remain due to VLMs' tendency to generate
incorrect action sequences. To address these limitations, we propose VeriGraph,
a novel framework that integrates VLMs for robotic planning while verifying
action feasibility. VeriGraph employs scene graphs as an intermediate
representation, capturing key objects and spatial relationships to improve plan
verification and refinement. The system generates a scene graph from input
images and uses it to iteratively check and correct action sequences generated
by an LLM-based task planner, ensuring constraints are respected and actions
are executable. Our approach significantly enhances task completion rates
across diverse manipulation scenarios, outperforming baseline methods by 58%
for language-based tasks and 30% for image-based tasks.

摘要：視覺語言模型 (VLM) 的最新進展為機器人任務規劃提供了潛力，但由於 VLM 傾向於生成不正確的動作序列，因此仍存在挑戰。為了解決這些限制，我們提出了 VeriGraph，這是一個新穎的架構，它整合了 VLM 以進行機器人規劃，同時驗證動作的可行性。VeriGraph 使用場景圖作為中間表示，擷取關鍵物件和空間關係以改善計畫驗證和精煉。系統從輸入影像中生成場景圖，並使用它來反覆檢查和修正由基於 LLM 的任務規劃器產生的動作序列，確保遵守約束且動作可執行。我們的做法大幅提高了在各種操作場景中的任務完成率，在基於語言的任務中優於基線方法 58%，在基於影像的任務中優於 30%。

##### **A Survey of Event Causality Identification: Principles, Taxonomy, Challenges, and Assessment**
2411.10371v1 by Zefan Zeng, Qing Cheng, Xingchen Hu, Yuehang Si, Zhong Liu

Event Causality Identification (ECI) has become a crucial task in Natural
Language Processing (NLP), aimed at automatically extracting causalities from
textual data. In this survey, we systematically address the foundational
principles, technical frameworks, and challenges of ECI, offering a
comprehensive taxonomy to categorize and clarify current research
methodologies, as well as a quantitative assessment of existing models. We
first establish a conceptual framework for ECI, outlining key definitions,
problem formulations, and evaluation standards. Our taxonomy classifies ECI
methods according to the two primary tasks of sentence-level (SECI) and
document-level (DECI) event causality identification. For SECI, we examine
feature pattern-based matching, deep semantic encoding, causal knowledge
pre-training and prompt-based fine-tuning, and external knowledge enhancement
methods. For DECI, we highlight approaches focused on event graph reasoning and
prompt-based techniques to address the complexity of cross-sentence causal
inference. Additionally, we analyze the strengths, limitations, and open
challenges of each approach. We further conduct an extensive quantitative
evaluation of various ECI methods on two benchmark datasets. Finally, we
explore future research directions, highlighting promising pathways to overcome
current limitations and broaden ECI applications.

摘要：事件因果關係識別（ECI）已成為自然語言處理（NLP）中的一項關鍵任務，旨在從文本資料中自動提取因果關係。在本次調查中，我們系統性地探討 ECI 的基礎原理、技術框架和挑戰，提供一個全面的分類法來分類和釐清當前研究方法，以及對現有模型進行定量評估。我們首先為 ECI 建立一個概念框架，概述關鍵定義、問題表述和評估標準。我們的分類法根據句子層級（SECI）和文件層級（DECI）事件因果關係識別這兩個主要任務對 ECI 方法進行分類。對於 SECI，我們探討基於特徵模式的匹配、深度語義編碼、因果知識預訓練和基於提示的微調，以及外部知識增強方法。對於 DECI，我們重點介紹專注於事件圖形推理和基於提示的技術，以解決跨句子因果推論的複雜性。此外，我們分析了每種方法的優點、限制和開放性挑戰。我們進一步對兩種基準資料集上的各種 ECI 方法進行廣泛的定量評估。最後，我們探討未來的研究方向，重點介紹克服當前限制和擴展 ECI 應用程式的有希望的途徑。

##### **Prompting and Fine-tuning Large Language Models for Automated Code Review Comment Generation**
2411.10129v1 by Md. Asif Haider, Ayesha Binte Mostofa, Sk. Sabit Bin Mosaddek, Anindya Iqbal, Toufique Ahmed

Generating accurate code review comments remains a significant challenge due
to the inherently diverse and non-unique nature of the task output. Large
language models pretrained on both programming and natural language data tend
to perform well in code-oriented tasks. However, large-scale pretraining is not
always feasible due to its environmental impact and project-specific
generalizability issues. In this work, first we fine-tune open-source Large
language models (LLM) in parameter-efficient, quantized low-rank (QLoRA)
fashion on consumer-grade hardware to improve review comment generation. Recent
studies demonstrate the efficacy of augmenting semantic metadata information
into prompts to boost performance in other code-related tasks. To explore this
in code review activities, we also prompt proprietary, closed-source LLMs
augmenting the input code patch with function call graphs and code summaries.
Both of our strategies improve the review comment generation performance, with
function call graph augmented few-shot prompting on the GPT-3.5 model
surpassing the pretrained baseline by around 90% BLEU-4 score on the
CodeReviewer dataset. Moreover, few-shot prompted Gemini-1.0 Pro, QLoRA
fine-tuned Code Llama and Llama 3.1 models achieve competitive results (ranging
from 25% to 83% performance improvement) on this task. An additional human
evaluation study further validates our experimental findings, reflecting
real-world developers' perceptions of LLM-generated code review comments based
on relevant qualitative metrics.

摘要：<paragraph>產生準確的程式碼審查評論仍然是一個重大挑戰，因為任務輸出的本質上是多樣且非獨特的。在程式設計和自然語言資料上進行預訓練的大型語言模型往往在以程式碼為導向的任務中表現良好。然而，由於其對環境的影響和專案特定的一般化問題，大規模預訓練並非總是可行的。在這項工作中，我們首先在參數有效、量化的低秩 (QLoRA) 方式中微調開源大型語言模型 (LLM)，在消費級硬體上改善審查評論的產生。最近的研究證明了在提示中增加語義元資料資訊以提升其他與程式碼相關任務中效能的功效。為了在程式碼審查活動中探索這一點，我們也提示專有的、閉源 LLM，使用函數呼叫圖和程式碼摘要來增加輸入程式碼修補程式。我們的兩種策略都改善了審查評論產生的效能，在 GPT-3.5 模型上使用函數呼叫圖增加的少量提示，在 CodeReviewer 資料集上超越了預訓練基準，BLEU-4 分數提高了約 90%。此外，少量提示的 Gemini-1.0 Pro、QLoRA 微調的 Code Llama 和 Llama 3.1 模型在此任務上達到了有競爭力的結果（效能提升範圍為 25% 至 83%）。額外的使用者評估研究進一步驗證了我們的實驗結果，反映了實際開發人員對 LLM 產生的程式碼審查評論的看法，這些看法基於相關的定性指標。</paragraph>

##### **HistoLens: An LLM-Powered Framework for Multi-Layered Analysis of Historical Texts -- A Case Application of Yantie Lun**
2411.09978v1 by Yifan Zeng

This paper proposes HistoLens, a multi-layered analysis framework for
historical texts based on Large Language Models (LLMs). Using the important
Western Han dynasty text "Yantie Lun" as a case study, we demonstrate the
framework's potential applications in historical research and education.
HistoLens integrates NLP technology (especially LLMs), including named entity
recognition, knowledge graph construction, and geographic information
visualization. The paper showcases how HistoLens explores Western Han culture
in "Yantie Lun" through multi-dimensional, visual, and quantitative methods,
focusing particularly on the influence of Confucian and Legalist thoughts on
political, economic, military, and ethnic. We also demonstrate how HistoLens
constructs a machine teaching scenario using LLMs for explainable analysis,
based on a dataset of Confucian and Legalist ideas extracted with LLM
assistance. This approach offers novel and diverse perspectives for studying
historical texts like "Yantie Lun" and provides new auxiliary tools for history
education. The framework aims to equip historians and learners with
LLM-assisted tools to facilitate in-depth, multi-layered analysis of historical
texts and foster innovation in historical education.

摘要：本文提出 HistoLens，一個基於大型語言模型 (LLM) 的多層分析架構，用於歷史文本。使用重要的西漢王朝文本「鹽鐵論」作為個案研究，我們展示了該架構在歷史研究和教育中的潛在應用。HistoLens 整合了 NLP 技術（尤其是 LLM），包括命名實體識別、知識圖譜建構和地理資訊視覺化。本文展示了 HistoLens 如何透過多維度、視覺化和量化方法探索「鹽鐵論」中的西漢文化，特別關注儒家和法家思想對政治、經濟、軍事和種族的影響。我們還展示了 HistoLens 如何建構一個使用 LLM 的機器教學場景，以進行可解釋分析，這是基於 LLM 協助提取的儒家和法家思想資料集。這種方法為研究「鹽鐵論」等歷史文本提供了新穎且多樣化的觀點，並為歷史教育提供了新的輔助工具。該架構旨在為歷史學家和學習者提供 LLM 協助的工具，以利於深入、多層次地分析歷史文本，並促進歷史教育的創新。

##### **Accelerating Knowledge Graph and Ontology Engineering with Large Language Models**
2411.09601v1 by Cogan Shimizu, Pascal Hitzler

Large Language Models bear the promise of significant acceleration of key
Knowledge Graph and Ontology Engineering tasks, including ontology modeling,
extension, modification, population, alignment, as well as entity
disambiguation. We lay out LLM-based Knowledge Graph and Ontology Engineering
as a new and coming area of research, and argue that modular approaches to
ontologies will be of central importance.

摘要：大型語言模型承諾大幅加速關鍵知識圖譜和本体工程任務，包括本体建模、擴充、修改、填充、比對以及實體消歧。我們將 LLM 為基礎的知識圖譜和本体工程規劃為一個新興的研究領域，並主張模組化本体方法將至關重要。

##### **Automating Reformulation of Essence Specifications via Graph Rewriting**
2411.09576v1 by Ian Miguel, András Z. Salamon, Christopher Stone

Formulating an effective constraint model of a parameterised problem class is
crucial to the efficiency with which instances of the class can subsequently be
solved. It is difficult to know beforehand which of a set of candidate models
will perform best in practice. This paper presents a system that employs graph
rewriting to reformulate an input model for improved performance automatically.
By situating our work in the Essence abstract constraint specification
language, we can use the structure in its high level variable types to trigger
rewrites directly. We implement our system via rewrite rules expressed in the
Graph Programs 2 language, applied to the abstract syntax tree of an input
specification. We show how to automatically translate the solution of the
reformulated problem into a solution of the original problem for verification
and presentation. We demonstrate the efficacy of our system with a detailed
case study.

摘要：制定一個參數化問題類別的有效約束模型對於隨後求解該類別的實例的效率至關重要。事先很難知道一組候選模型中哪一個在實務上表現最佳。本文提出一個系統，採用圖形重寫來自動重新制定輸入模型以改善效能。透過將我們的工作置於 Essence 抽象約束規範語言中，我們可以使用其高層級變數類型中的結構來直接觸發重寫。我們透過以 Graph Programs 2 語言表示的重寫規則來實作我們的系統，應用於輸入規範的抽象語法樹。我們展示如何自動將重新制定問題的解法轉換為原始問題的解法，以進行驗證和呈現。我們透過詳細的個案研究來展示我們系統的效能。

##### **Towards Evaluating Large Language Models for Graph Query Generation**
2411.08449v2 by Siraj Munir, Alessandro Aldini

Large Language Models (LLMs) are revolutionizing the landscape of Generative
Artificial Intelligence (GenAI), with innovative LLM-backed solutions emerging
rapidly. However, when applied to database technologies, specifically query
generation for graph databases and Knowledge Graphs (KGs), LLMs still face
significant challenges. While research on LLM-driven query generation for
Structured Query Language (SQL) exists, similar systems for graph databases
remain underdeveloped. This paper presents a comparative study addressing the
challenge of generating Cypher queries a powerful language for interacting with
graph databases using open-access LLMs. We rigorously evaluate several LLM
agents (OpenAI ChatGPT 4o, Claude Sonnet 3.5, Google Gemini Pro 1.5, and a
locally deployed Llama 3.1 8B) using a designed few-shot learning prompt and
Retrieval Augmented Generation (RAG) backed by Chain-of-Thoughts (CoT)
reasoning. Our empirical analysis of query generation accuracy reveals that
Claude Sonnet 3.5 outperforms its counterparts in this specific domain.
Further, we highlight promising future research directions to address the
identified limitations and advance LLM-driven query generation for graph
databases.

摘要：大型語言模型 (LLM) 正在革新生成式人工智慧 (GenAI) 的領域，創新的 LLM 支持解決方案迅速湧現。然而，當應用於資料庫技術，特別是圖形資料庫和知識圖譜 (KG) 的查詢產生時，LLM 仍然面臨重大挑戰。雖然存在針對結構化查詢語言 (SQL) 的 LLM 驅動查詢產生的研究，但圖形資料庫的類似系統仍未充分發展。本文提出了一項比較研究，以解決使用開放式 LLM 產生 Cypher 查詢的挑戰，Cypher 查詢是一種用於與圖形資料庫互動的強大語言。我們使用設計的少量學習提示和由思想鏈 (CoT) 推理支持的檢索擴充生成 (RAG) 嚴格評估了多個 LLM 代理（OpenAI ChatGPT 4o、Claude Sonnet 3.5、Google Gemini Pro 1.5 和本地部署的 Llama 3.1 8B）。我們對查詢產生準確性的實證分析表明，Claude Sonnet 3.5 在這個特定領域優於其同類產品。此外，我們重點介紹了有希望的未來研究方向，以解決已識別的限制並推進 LLM 驅動的圖形資料庫查詢產生。

##### **Knowledge Bases in Support of Large Language Models for Processing Web News**
2411.08278v2 by Yihe Zhang, Nabin Pakka, Nian-Feng Tzeng

Large Language Models (LLMs) have received considerable interest in wide
applications lately. During pre-training via massive datasets, such a model
implicitly memorizes the factual knowledge of trained datasets in its hidden
parameters. However, knowledge held implicitly in parameters often makes its
use by downstream applications ineffective due to the lack of common-sense
reasoning. In this article, we introduce a general framework that permits to
build knowledge bases with an aid of LLMs, tailored for processing Web news.
The framework applies a rule-based News Information Extractor (NewsIE) to news
items for extracting their relational tuples, referred to as knowledge bases,
which are then graph-convoluted with the implicit knowledge facts of news items
obtained by LLMs, for their classification. It involves two lightweight
components: 1) NewsIE: for extracting the structural information of every news
item, in the form of relational tuples; 2) BERTGraph: for graph convoluting the
implicit knowledge facts with relational tuples extracted by NewsIE. We have
evaluated our framework under different news-related datasets for news category
classification, with promising experimental results.

摘要：大型語言模型 (LLM) 近來在廣泛的應用中備受關注。在透過大量資料集進行預訓練期間，此類模型會隱含地將訓練資料集的事實知識記憶在其隱藏參數中。然而，隱含在參數中的知識通常會因為缺乏常識推理而導致下游應用無法有效使用。在本文中，我們介紹了一個通用架構，允許在 LLM 的協助下建立知識庫，專門用於處理網路新聞。此架構將基於規則的新聞資訊萃取器 (NewsIE) 套用到新聞項目，以萃取其關係元組（稱為知識庫），然後將其與 LLM 取得的新聞項目的隱含知識事實進行圖形卷積，以進行分類。它包含兩個輕量級元件：1) NewsIE：用於萃取每個新聞項目的結構化資訊，以關係元組的形式呈現；2) BERTGraph：用於將 NewsIE 萃取的關係元組與隱含知識事實進行圖形卷積。我們已在不同的與新聞相關的資料集下評估我們的架構，用於新聞類別分類，並獲得有希望的實驗結果。

##### **Retrieval, Reasoning, Re-ranking: A Context-Enriched Framework for Knowledge Graph Completion**
2411.08165v1 by Muzhi Li, Cehao Yang, Chengjin Xu, Xuhui Jiang, Yiyan Qi, Jian Guo, Ho-fung Leung, Irwin King

The Knowledge Graph Completion~(KGC) task aims to infer the missing entity
from an incomplete triple. Existing embedding-based methods rely solely on
triples in the KG, which is vulnerable to specious relation patterns and
long-tail entities. On the other hand, text-based methods struggle with the
semantic gap between KG triples and natural language. Apart from triples,
entity contexts (e.g., labels, descriptions, aliases) also play a significant
role in augmenting KGs. To address these limitations, we propose KGR3, a
context-enriched framework for KGC. KGR3 is composed of three modules. Firstly,
the Retrieval module gathers supporting triples from the KG, collects plausible
candidate answers from a base embedding model, and retrieves context for each
related entity. Then, the Reasoning module employs a large language model to
generate potential answers for each query triple. Finally, the Re-ranking
module combines candidate answers from the two modules mentioned above, and
fine-tunes an LLM to provide the best answer. Extensive experiments on widely
used datasets demonstrate that KGR3 consistently improves various KGC methods.
Specifically, the best variant of KGR3 achieves absolute Hits@1 improvements of
12.3% and 5.6% on the FB15k237 and WN18RR datasets.

摘要：知識圖譜完成功能 (KGC) 的任務旨在從不完整的 3 元組中推斷出遺失的實體。現有的嵌入式方法僅依賴於 KG 中的 3 元組，這容易受到虛假關係模式和長尾實體的影響。另一方面，基於文本的方法難以處理 KG 3 元組和自然語言之間的語義差距。除了 3 元組之外，實體上下文（例如標籤、描述、別名）在擴充 KG 中也扮演著重要的角色。為了解決這些限制，我們提出了 KGR3，一個用於 KGC 的上下文豐富架構。KGR3 由三個模組組成。首先，檢索模組從 KG 中收集支援 3 元組，從基礎嵌入模型中收集可能的候選答案，並為每個相關實體檢索上下文。接著，推理模組採用大型語言模型為每個查詢 3 元組生成潛在答案。最後，重新排名模組將上述兩個模組的候選答案結合起來，並微調 LLM 以提供最佳答案。在廣泛使用的資料集上進行的廣泛實驗證明，KGR3 持續改進各種 KGC 方法。具體來說，KGR3 的最佳變體在 FB15k237 和 WN18RR 資料集上分別實現了 12.3% 和 5.6% 的絕對 Hits@1 改進。

##### **Language Models as Causal Effect Generators**
2411.08019v1 by Lucius E. J. Bynum, Kyunghyun Cho

We present a framework for large language model (LLM) based data generation
with controllable causal structure. In particular, we define a procedure for
turning any language model and any directed acyclic graph (DAG) into a
sequence-driven structural causal model (SD-SCM). Broadly speaking, an SD-SCM
is a causal model with user-defined structure and LLM-defined structural
equations. We characterize how an SD-SCM allows sampling from observational,
interventional, and counterfactual distributions according to the desired
causal structure. We then leverage this procedure to propose a new type of
benchmark for causal inference methods, generating individual-level
counterfactual data without needing to manually specify functional
relationships between variables. We create an example benchmark consisting of
thousands of datasets, and test a suite of popular estimation methods on these
datasets for average, conditional average, and individual treatment effect
estimation, both with and without hidden confounding. Apart from generating
data, the same procedure also allows us to test for the presence of a causal
effect that might be encoded in an LLM. This procedure can underpin auditing
LLMs for misinformation, discrimination, or otherwise undesirable behavior. We
believe SD-SCMs can serve as a useful tool in any application that would
benefit from sequential data with controllable causal structure.

摘要：<paragraph>我們提出了一個基於大型語言模型 (LLM) 的資料生成架構，具有可控制的因果結構。具體來說，我們定義了一個程序，將任何語言模型和任何有向無環圖 (DAG) 轉換成一個序列驅動的結構因果模型 (SD-SCM)。廣義來說，SD-SCM 是一個因果模型，具有使用者定義的結構和 LLM 定義的結構方程式。我們描述了 SD-SCM 如何根據所需的因果結構，允許從觀測、介入和反事實分佈中進行抽樣。然後，我們利用這個程序提出了一種類型的因果推論方法基準，生成個體層級的反事實資料，而無需手動指定變數之間的功能關係。我們建立了一個範例基準，包含數千個資料集，並在這些資料集上測試了一系列流行的估計方法，用於平均值、條件平均值和個別處理效果估計，無論是有或沒有隱藏混淆。除了生成資料之外，相同的程序也允許我們測試 LLM 中可能編碼的因果效應的存在。此程序可以支持審核 LLM 的錯誤資訊、歧視或其他不良行為。我們相信 SD-SCM 可以作為任何應用程式的有用工具，這些應用程式可以從具有可控制因果結構的序列資料中受益。</paragraph>

##### **From General to Specific: Utilizing General Hallucation to Automatically Measure the Role Relationship Fidelity for Specific Role-Play Agents**
2411.07965v1 by Chuyi Kong, Ziyang Luo, Hongzhan Lin, Zhiyuan Fan, Yaxin Fan, Yuxi Sun, Jing Ma

The advanced role-playing capabilities of Large Language Models (LLMs) have
paved the way for developing Role-Playing Agents (RPAs). However, existing
benchmarks, such as HPD, which incorporates manually scored character
relationships into the context for LLMs to sort coherence, and SocialBench,
which uses specific profiles generated by LLMs in the context of
multiple-choice tasks to assess character preferences, face limitations like
poor generalizability, implicit and inaccurate judgments, and excessive context
length. To address the above issues, we propose an automatic, scalable, and
generalizable paradigm. Specifically, we construct a benchmark by extracting
relations from a general knowledge graph and leverage RPA's inherent
hallucination properties to prompt it to interact across roles, employing
ChatGPT for stance detection and defining relationship hallucination along with
three related metrics. Extensive experiments validate the effectiveness and
stability of our metrics. Our findings further explore factors influencing
these metrics and discuss the trade-off between relationship hallucination and
factuality.

摘要：大型語言模型 (LLM) 的先進角色扮演能力已為開發角色扮演代理 (RPA) 鋪平道路。然而，現有的基準，例如 HPD（將手動評分的角色關係納入 LLM 的背景中以對連貫性進行排序），以及 SocialBench（在多選題任務的背景下使用 LLM 生成的特定個人資料來評估角色偏好）面臨著諸如通用性差、判斷含蓄且不準確以及背景長度過長等限制。為了解決上述問題，我們提出了一個自動、可擴充且可概括的範例。具體來說，我們通過從通用知識圖譜中提取關係來構建基準，並利用 RPA 固有的幻覺屬性提示它跨角色互動，採用 ChatGPT 進行立場檢測並定義關係幻覺以及三個相關指標。廣泛的實驗驗證了我們指標的有效性和穩定性。我們的研究結果進一步探討了影響這些指標的因素，並討論了關係幻覺和事實性之間的權衡。

##### **Chain Association-based Attacking and Shielding Natural Language Processing Systems**
2411.07843v1 by Jiacheng Huang, Long Chen

Association as a gift enables people do not have to mention something in
completely straightforward words and allows others to understand what they
intend to refer to. In this paper, we propose a chain association-based
adversarial attack against natural language processing systems, utilizing the
comprehension gap between humans and machines. We first generate a chain
association graph for Chinese characters based on the association paradigm for
building search space of potential adversarial examples. Then, we introduce an
discrete particle swarm optimization algorithm to search for the optimal
adversarial examples. We conduct comprehensive experiments and show that
advanced natural language processing models and applications, including large
language models, are vulnerable to our attack, while humans appear good at
understanding the perturbed text. We also explore two methods, including
adversarial training and associative graph-based recovery, to shield systems
from chain association-based attack. Since a few examples that use some
derogatory terms, this paper contains materials that may be offensive or
upsetting to some people.

摘要：聯想作為一種禮物，使人們不必用完全直白的話語提及某事，並讓其他人明白他們想提的是什麼。在本文中，我們提出了一種基於鏈式聯想的對抗性攻擊，用於自然語言處理系統，利用了人類與機器之間的理解差距。我們首先基於聯想範例為漢字生成一個鏈式聯想圖，用於構建潛在對抗性範例的搜索空間。然後，我們引入一個離散粒子群優化演算法來搜索最佳的對抗性範例。我們進行了全面的實驗，並表明先進的自然語言處理模型和應用程式，包括大型語言模型，都容易受到我們的攻擊，而人類似乎很擅長理解擾動後的文字。我們還探索了兩種方法，包括對抗性訓練和基於聯想圖的恢復，以保護系統免受基於鏈式聯想的攻擊。由於一些範例使用了某些貶義詞，因此本文包含可能冒犯或令某些人感到不安的材料。

##### **Gradual Fine-Tuning with Graph Routing for Multi-Source Unsupervised Domain Adaptation**
2411.07185v1 by Yao Ma, Samuel Louvan, Zhunxuan Wang

Multi-source unsupervised domain adaptation aims to leverage labeled data
from multiple source domains for training a machine learning model to
generalize well on a target domain without labels. Source domain selection
plays a crucial role in determining the model's performance. It relies on the
similarities amongst source and target domains. Nonetheless, existing work for
source domain selection often involves heavyweight computational procedures,
especially when dealing with numerous source domains and the need to identify
the best ones from them. In this paper, we introduce a framework for gradual
fine tuning (GFT) of machine learning models on multiple source domains. We
represent multiple source domains as an undirected weighted graph. We then give
a new generalization error bound for GFT along any path within the graph, which
is used to determine the optimal path corresponding to the optimal training
order. With this formulation, we introduce three lightweight graph-routing
strategies which tend to minimize the error bound. Our best strategy improves
$2.3\%$ of accuracy over the state-of-the-art on Natural Language Inference
(NLI) task and achieves competitive performance on Sentiment Analysis (SA)
task, especially a $3.9\%$ improvement on a more diverse subset of data we use
for SA.

摘要：多源无监督域自适应旨在利用来自多个源域的标记数据，训练机器学习模型，以便在没有标签的目标域上很好地泛化。源域选择在确定模型性能方面起着至关重要的作用。它依赖于源域和目标域之间的相似性。尽管如此，现有的源域选择工作通常涉及重量级计算程序，尤其是在处理众多源域以及需要从中识别最佳源域时。在本文中，我们介绍了一个在多个源域上对机器学习模型进行逐步微调 (GFT) 的框架。我们将多个源域表示为无向加权图。然后，我们为图中沿任何路径的 GFT 给出了一个新的泛化误差界，用于确定对应于最佳训练顺序的最佳路径。通过这种表述，我们介绍了三种轻量级的图路由策略，这些策略倾向于最小化误差界。我们最好的策略在自然语言推理 (NLI) 任务上比最先进的技术提高了 2.3% 的准确率，并在情感分析 (SA) 任务上取得了有竞争力的性能，特别是在我们用于 SA 的更多样化的数据子集上提高了 3.9%。

##### **A Domain-Agnostic Neurosymbolic Approach for Big Social Data Analysis: Evaluating Mental Health Sentiment on Social Media during COVID-19**
2411.07163v1 by Vedant Khandelwal, Manas Gaur, Ugur Kursuncu, Valerie Shalin, Amit Sheth

Monitoring public sentiment via social media is potentially helpful during
health crises such as the COVID-19 pandemic. However, traditional
frequency-based, data-driven neural network-based approaches can miss newly
relevant content due to the evolving nature of language in a dynamically
evolving environment. Human-curated symbolic knowledge sources, such as
lexicons for standard language and slang terms, can potentially elevate social
media signals in evolving language. We introduce a neurosymbolic method that
integrates neural networks with symbolic knowledge sources, enhancing the
detection and interpretation of mental health-related tweets relevant to
COVID-19. Our method was evaluated using a corpus of large datasets
(approximately 12 billion tweets, 2.5 million subreddit data, and 700k news
articles) and multiple knowledge graphs. This method dynamically adapts to
evolving language, outperforming purely data-driven models with an F1 score
exceeding 92\%. This approach also showed faster adaptation to new data and
lower computational demands than fine-tuning pre-trained large language models
(LLMs). This study demonstrates the benefit of neurosymbolic methods in
interpreting text in a dynamic environment for tasks such as health
surveillance.

摘要：透過社群媒體監控公眾情緒在 COVID-19 等健康危機期間可能很有幫助。然而，傳統的基於頻率、資料驅動的神經網路方法可能會錯過新相關的內容，因為語言在動態演化的環境中會持續演化。由人類策劃的象徵性知識來源（例如標準語言和俚語術語的詞彙）可能會提升社群媒體在演化語言中的訊號。我們引入一種將神經網路與象徵性知識來源整合的神經符號方法，增強與 COVID-19 相關的心理健康相關推文的偵測和詮釋。我們的做法使用大型資料集語料庫（約 120 億則推文、250 萬個 subreddit 資料和 70 萬則新聞文章）和多個知識圖譜進行評估。這種方法動態適應演化的語言，優於純資料驅動模型，F1 分數超過 92%。這種方法也顯示出比微調預訓練大型語言模型 (LLM) 更快適應新資料和更低的運算需求。本研究證明了神經符號方法在動態環境中詮釋文字的優點，適用於健康監控等任務。

##### **A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs**
2411.07098v1 by Myeongsoo Kim, Tyler Stennett, Saurabh Sinha, Alessandro Orso

As modern web services increasingly rely on REST APIs, their thorough testing
has become crucial. Furthermore, the advent of REST API specifications such as
the OpenAPI Specification has led to the emergence of many black-box REST API
testing tools. However, these tools often focus on individual test elements in
isolation (e.g., APIs, parameters, values), resulting in lower coverage and
less effectiveness in detecting faults (i.e., 500 response codes). To address
these limitations, we present AutoRestTest, the first black-box framework to
adopt a dependency-embedded multi-agent approach for REST API testing,
integrating Multi-Agent Reinforcement Learning (MARL) with a Semantic Property
Dependency Graph (SPDG) and Large Language Models (LLMs). Our approach treats
REST API testing as a separable problem, where four agents -- API, dependency,
parameter, and value -- collaborate to optimize API exploration. LLMs handle
domain-specific value restrictions, the SPDG model simplifies the search space
for dependencies using a similarity score between API operations, and MARL
dynamically optimizes the agents' behavior. Evaluated on 12 real-world REST
services, AutoRestTest outperforms the four leading black-box REST API testing
tools, including those assisted by RESTGPT (which augments realistic test
inputs using LLMs), in terms of code coverage, operation coverage, and fault
detection. Notably, AutoRestTest is the only tool able to identify an internal
server error in Spotify. Our ablation study underscores the significant
contributions of the agent learning, SPDG, and LLM components.

摘要：<paragraph>隨著現代網路服務日益依賴 REST API，其徹底的測試變得至關重要。此外，REST API 規範（例如 OpenAPI 規範）的出現，導致許多黑盒 REST API 測試工具的出現。然而，這些工具通常專注於單獨的測試元素（例如 API、參數、值），導致覆蓋率較低，且在偵測錯誤（即 500 回應碼）方面效率較低。為了解決這些限制，我們提出 AutoRestTest，這是第一個採用依賴嵌入式多代理方法進行 REST API 測試的黑盒框架，將多代理強化學習 (MARL) 與語義屬性依賴圖 (SPDG) 和大型語言模型 (LLM) 整合在一起。我們的做法將 REST API 測試視為一個可分離的問題，其中四個代理（API、依賴關係、參數和值）協同合作以最佳化 API 探索。LLM 處理特定領域的值限制，SPDG 模型使用 API 操作之間的相似性分數簡化依賴關係的搜尋空間，而 MARL 則動態最佳化代理的行為。在 12 項真實世界的 REST 服務上進行評估，AutoRestTest 在程式碼覆蓋率、操作覆蓋率和錯誤偵測方面，優於四種領先的黑盒 REST API 測試工具，包括那些由 RESTGPT（使用 LLM 增加逼真的測試輸入）輔助的工具。值得注意的是，AutoRestTest 是唯一能夠識別 Spotify 中內部伺服器錯誤的工具。我們的消融研究強調了代理學習、SPDG 和 LLM 組件的重大貢獻。</paragraph>

##### **Bridge: A Unified Framework to Knowledge Graph Completion via Language Models and Knowledge Representation**
2411.06660v1 by Qiao Qiao, Yuepei Li, Qing Wang, Kang Zhou, Qi Li

Knowledge graph completion (KGC) is a task of inferring missing triples based
on existing Knowledge Graphs (KGs). Both structural and semantic information
are vital for successful KGC. However, existing methods only use either the
structural knowledge from the KG embeddings or the semantic information from
pre-trained language models (PLMs), leading to suboptimal model performance.
Moreover, since PLMs are not trained on KGs, directly using PLMs to encode
triples may be inappropriate. To overcome these limitations, we propose a novel
framework called Bridge, which jointly encodes structural and semantic
information of KGs. Specifically, we strategically encode entities and
relations separately by PLMs to better utilize the semantic knowledge of PLMs
and enable structured representation learning via a structural learning
principle. Furthermore, to bridge the gap between KGs and PLMs, we employ a
self-supervised representation learning method called BYOL to fine-tune PLMs
with two different views of a triple. Unlike BYOL, which uses augmentation
methods to create two semantically similar views of the same image, potentially
altering the semantic information. We strategically separate the triple into
two parts to create different views, thus avoiding semantic alteration.
Experiments demonstrate that Bridge outperforms the SOTA models on three
benchmark datasets.

摘要：知識圖譜補全 (KGC) 是一項根據現有知識圖譜 (KG) 推論遺失三元組的任務。結構和語義資訊對於成功的 KGC 至關重要。然而，現有方法僅使用來自 KG 嵌入的結構知識或來自預訓練語言模型 (PLM) 的語義資訊，導致模型效能不佳。此外，由於 PLM 沒有在 KG 上訓練，因此直接使用 PLM 編碼三元組可能並不適當。為了克服這些限制，我們提出一個名為 Bridge 的新架構，該架構聯合編碼 KG 的結構和語義資訊。具體來說，我們透過 PLM 分別對實體和關係進行策略性編碼，以更好地利用 PLM 的語義知識，並透過結構學習原則啟用結構化表示學習。此外，為了彌合 KG 和 PLM 之間的差距，我們採用一種稱為 BYOL 的自監督表示學習方法，以三元組的兩個不同視圖微調 PLM。與 BYOL 不同，BYOL 使用擴充方法來建立兩個語義上相似的相同影像視圖，可能會改變語義資訊。我們策略性地將三元組分為兩部分以建立不同的視圖，從而避免語義改變。實驗證明 Bridge 在三個基準資料集上優於 SOTA 模型。

##### **CausalStock: Deep End-to-end Causal Discovery for News-driven Stock Movement Prediction**
2411.06391v1 by Shuqi Li, Yuebo Sun, Yuxin Lin, Xin Gao, Shuo Shang, Rui Yan

There are two issues in news-driven multi-stock movement prediction tasks
that are not well solved in the existing works. On the one hand, "relation
discovery" is a pivotal part when leveraging the price information of other
stocks to achieve accurate stock movement prediction. Given that stock
relations are often unidirectional, such as the "supplier-consumer"
relationship, causal relations are more appropriate to capture the impact
between stocks. On the other hand, there is substantial noise existing in the
news data leading to extracting effective information with difficulty. With
these two issues in mind, we propose a novel framework called CausalStock for
news-driven multi-stock movement prediction, which discovers the temporal
causal relations between stocks. We design a lag-dependent temporal causal
discovery mechanism to model the temporal causal graph distribution. Then a
Functional Causal Model is employed to encapsulate the discovered causal
relations and predict the stock movements. Additionally, we propose a Denoised
News Encoder by taking advantage of the excellent text evaluation ability of
large language models (LLMs) to extract useful information from massive news
data. The experiment results show that CausalStock outperforms the strong
baselines for both news-driven multi-stock movement prediction and multi-stock
movement prediction tasks on six real-world datasets collected from the US,
China, Japan, and UK markets. Moreover, getting benefit from the causal
relations, CausalStock could offer a clear prediction mechanism with good
explainability.

摘要：<paragraph>在新聞驅動的多股票移動預測任務中，現有研究尚未妥善解決兩個問題。一方面，在利用其他股票的價格資訊來實現準確的股票移動預測時，「關係發現」是一個關鍵部分。由於股票關係通常是單向的，例如「供應商-消費者」關係，因此因果關係更適合捕捉股票之間的影響。另一方面，新聞資料中存在大量雜訊，導致難以提取有效資訊。考慮到這兩個問題，我們提出了一個名為 CausalStock 的新框架，用於新聞驅動的多股票移動預測，該框架發現了股票之間的時序因果關係。我們設計了一個延遲依賴的時序因果發現機制，以建模時序因果圖分布。然後採用功能因果模型來封裝發現的因果關係並預測股票走勢。此外，我們提出了一個去噪新聞編碼器，利用大型語言模型 (LLM) 出色的文本評估能力從大量新聞資料中提取有用資訊。實驗結果表明，CausalStock 在從美國、中國、日本和英國市場收集的六個真實世界資料集上，在新聞驅動的多股票移動預測和多股票移動預測任務中都優於強大的基線。此外，CausalStock 受益於因果關係，可以提供具有良好可解釋性的清晰預測機制。</paragraph>

##### **Analyzing the Evolution of Graphs and Texts**
2411.06295v1 by Xingzhi Guo

With the recent advance of representation learning algorithms on graphs
(e.g., DeepWalk/GraphSage) and natural languages (e.g., Word2Vec/BERT) , the
state-of-the art models can even achieve human-level performance over many
downstream tasks, particularly for the task of node and sentence
classification. However, most algorithms focus on large-scale models for static
graphs and text corpus without considering the inherent dynamic characteristics
or discovering the reasons behind the changes. This dissertation aims to
efficiently model the dynamics in graphs (such as social networks and citation
graphs) and understand the changes in texts (specifically news titles and
personal biographies). To achieve this goal, we utilize the renowned
Personalized PageRank algorithm to create effective dynamic network embeddings
for evolving graphs. Our proposed approaches significantly improve the running
time and accuracy for both detecting network abnormal intruders and discovering
entity meaning shifts over large-scale dynamic graphs. For text changes, we
analyze the post-publication changes in news titles to understand the intents
behind the edits and discuss the potential impact of titles changes from
information integrity perspective. Moreover, we investigate self-presented
occupational identities in Twitter users' biographies over five years,
investigating job prestige and demographics effects in how people disclose
jobs, quantifying over-represented jobs and their transitions over time.

摘要：隨著圖形表示學習演算法的最新進展（例如 DeepWalk/GraphSage）和自然語言（例如 Word2Vec/BERT），最先進的模型甚至可以在許多下游任務中達到人類等級的效能，特別是對於節點和句子分類的任務。然而，大多數演算法都專注於靜態圖形和大規模文字語料庫的模型，而沒有考慮固有的動態特性或找出變化的原因。本論文旨在有效地為圖形（例如社群網路和引文圖形）建模動態，並了解文字的變化（特別是新聞標題和個人傳記）。為了達成這個目標，我們利用著名的 Personalized PageRank 演算法為不斷變化的圖形建立有效的動態網路嵌入。我們提出的方法顯著改善了偵測網路異常入侵者和找出大規模動態圖形中實體含義轉移的執行時間和準確度。對於文字變化的部分，我們分析了新聞標題在出版後的變化，以了解編輯背後的意圖，並討論標題變更對資訊完整性的潛在影響。此外，我們調查了 Twitter 使用者在傳記中呈現的職業身分長達五年，探討了工作聲望和人口統計資料對人們揭露工作的影響，並量化了過度代表的工作及其隨著時間推移的轉變。

##### **An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models**
2411.06048v1 by Fatemeh Shiri, Xiao-Yu Guo, Mona Golestan Far, Xin Yu, Gholamreza Haffari, Yuan-Fang Li

Large Multimodal Models (LMMs) have achieved strong performance across a
range of vision and language tasks. However, their spatial reasoning
capabilities are under-investigated. In this paper, we construct a novel VQA
dataset, Spatial-MM, to comprehensively study LMMs' spatial understanding and
reasoning capabilities. Our analyses on object-relationship and multi-hop
reasoning reveal several important findings. Firstly, bounding boxes and scene
graphs, even synthetic ones, can significantly enhance LMMs' spatial reasoning.
Secondly, LMMs struggle more with questions posed from the human perspective
than the camera perspective about the image. Thirdly, chain of thought (CoT)
prompting does not improve model performance on complex multi-hop questions
involving spatial relations. % Moreover, spatial reasoning steps are much less
accurate than non-spatial ones across MLLMs. Lastly, our perturbation analysis
on GQA-spatial reveals that LMMs are much stronger at basic object detection
than complex spatial reasoning. We believe our benchmark dataset and in-depth
analyses can spark further research on LMMs spatial reasoning. Spatial-MM
benchmark is available at: https://github.com/FatemehShiri/Spatial-MM

摘要：大型多模態模型 (LMM) 已在各種視覺和語言任務中取得強勁的表現。然而，它們的空間推理能力尚未得到充分研究。在本文中，我們構建了一個新穎的 VQA 資料集 Spatial-MM，以全面研究 LMM 的空間理解和推理能力。我們對物件關係和多跳推理的分析揭示了幾個重要的發現。首先，邊界框和場景圖，即使是合成的，也可以顯著增強 LMM 的空間推理能力。其次，LMM 在回答從人類視角提出的問題時比從相機視角提出的問題時遇到更多困難。第三，思考鏈 (CoT) 提示並未改善模型在涉及空間關係的複雜多跳問題上的效能。% 此外，在 MLLM 中，空間推理步驟的準確度遠低於非空間步驟。最後，我們對 GQA-spatial 的擾動分析表明，LMM 在基本物件偵測方面的能力遠強於複雜的空間推理。我們相信我們的基準資料集和深入分析可以激發對 LMM 空間推理的進一步研究。Spatial-MM 基準可在以下網址取得：https://github.com/FatemehShiri/Spatial-MM

##### **Mitigating Hallucination with ZeroG: An Advanced Knowledge Management Engine**
2411.05936v1 by Anantha Sharma, Sheeba Elizabeth John, Fatemeh Rezapoor Nikroo, Krupali Bhatt, Mrunal Zambre, Aditi Wikhe

The growth of digital documents presents significant challenges in efficient
management and knowledge extraction. Traditional methods often struggle with
complex documents, leading to issues such as hallucinations and high latency in
responses from Large Language Models (LLMs). ZeroG, an innovative approach,
significantly mitigates these challenges by leveraging knowledge distillation
and prompt tuning to enhance model performance.
  ZeroG utilizes a smaller model that replicates the behavior of a larger
teacher model, ensuring contextually relevant and grounded responses, by
employing a black-box distillation approach, it creates a distilled dataset
without relying on intermediate features, optimizing computational efficiency.
This method significantly enhances accuracy and reduces response times,
providing a balanced solution for modern document management.
  Incorporating advanced techniques for document ingestion and metadata
utilization, ZeroG improves the accuracy of question-and-answer systems. The
integration of graph databases and robust metadata management further
streamlines information retrieval, allowing for precise and context-aware
responses. By transforming how organizations interact with complex data, ZeroG
enhances productivity and user experience, offering a scalable solution for the
growing demands of digital document management.

摘要：數位文件成長帶來顯著的挑戰，包括有效管理和知識萃取。傳統方法經常難以處理複雜文件，導致問題，例如產生幻覺和大型語言模型 (LLM) 回應的高延遲。ZeroG 是一種創新的方法，透過利用知識蒸餾和提示調整來增強模型效能，大幅減輕這些挑戰。
ZeroG 使用較小的模型複製較大的教師模型的行為，透過採用黑盒蒸餾方法，確保在脈絡上相關且有根據的回應，它建立一個蒸餾的資料集，而不需要依賴中間特徵，最佳化運算效率。這種方法大幅提升準確度並減少回應時間，提供現代文件管理的平衡解決方案。
透過整合進階技術來擷取文件和使用元資料，ZeroG 改善問答系統的準確度。圖形資料庫和強健的元資料管理的整合進一步簡化資訊擷取，允許精確且符合脈絡的回應。透過轉換組織與複雜資料互動的方式，ZeroG 提升生產力和使用者體驗，提供可擴充的解決方案，以滿足數位文件管理日益增長的需求。

##### **SM3-Text-to-Query: Synthetic Multi-Model Medical Text-to-Query Benchmark**
2411.05521v2 by Sithursan Sivasubramaniam, Cedric Osei-Akoto, Yi Zhang, Kurt Stockinger, Jonathan Fuerst

Electronic health records (EHRs) are stored in various database systems with
different database models on heterogeneous storage architectures, such as
relational databases, document stores, or graph databases. These different
database models have a big impact on query complexity and performance. While
this has been a known fact in database research, its implications for the
growing number of Text-to-Query systems have surprisingly not been investigated
so far. In this paper, we present SM3-Text-to-Query, the first multi-model
medical Text-to-Query benchmark based on synthetic patient data from Synthea,
following the SNOMED-CT taxonomy -- a widely used knowledge graph ontology
covering medical terminology. SM3-Text-to-Query provides data representations
for relational databases (PostgreSQL), document stores (MongoDB), and graph
databases (Neo4j and GraphDB (RDF)), allowing the evaluation across four
popular query languages, namely SQL, MQL, Cypher, and SPARQL. We systematically
and manually develop 408 template questions, which we augment to construct a
benchmark of 10K diverse natural language question/query pairs for these four
query languages (40K pairs overall). On our dataset, we evaluate several common
in-context-learning (ICL) approaches for a set of representative closed and
open-source LLMs. Our evaluation sheds light on the trade-offs between database
models and query languages for different ICL strategies and LLMs. Last,
SM3-Text-to-Query is easily extendable to additional query languages or real,
standard-based patient databases.

摘要：電子健康記錄 (EHR) 儲存在具有不同資料庫模型的各種資料庫系統中，採用異質儲存架構，例如關聯式資料庫、文件儲存庫或圖形資料庫。這些不同的資料庫模型對查詢複雜度和效能有很大的影響。雖然這在資料庫研究中是一個已知的事實，但其對越來越多的文字轉查詢系統的影響卻令人驚訝地尚未被研究。在本文中，我們提出 SM3-Text-to-Query，這是第一個基於 Synthea 合成患者資料的多模型醫療文字轉查詢基準，遵循 SNOMED-CT 分類法，這是一個廣泛使用的知識圖形本體，涵蓋醫學術語。SM3-Text-to-Query 提供了關係資料庫 (PostgreSQL)、文件儲存庫 (MongoDB) 和圖形資料庫 (Neo4j 和 GraphDB (RDF)) 的資料表示，允許跨四種流行的查詢語言進行評估，即 SQL、MQL、Cypher 和 SPARQL。我們系統且手動開發了 408 個範本問題，並擴充這些問題以建構一個基準，其中包含 10K 個針對這四種查詢語言的多樣化自然語言問題/查詢配對（總共 40K 個配對）。在我們的資料集上，我們評估了一組代表性的封閉和開放原始碼 LLM 的幾個常見情境學習 (ICL) 方法。我們的評估揭示了不同 ICL 策略和 LLM 的資料庫模型和查詢語言之間的權衡。最後，SM3-Text-to-Query 可以輕鬆擴充到其他查詢語言或真實的、基於標準的患者資料庫。

##### **EUREKHA: Enhancing User Representation for Key Hackers Identification in Underground Forums**
2411.05479v1 by Abdoul Nasser Hassane Amadou, Anas Motii, Saida Elouardi, EL Houcine Bergou

Underground forums serve as hubs for cybercriminal activities, offering a
space for anonymity and evasion of conventional online oversight. In these
hidden communities, malicious actors collaborate to exchange illicit knowledge,
tools, and tactics, driving a range of cyber threats from hacking techniques to
the sale of stolen data, malware, and zero-day exploits. Identifying the key
instigators (i.e., key hackers), behind these operations is essential but
remains a complex challenge. This paper presents a novel method called EUREKHA
(Enhancing User Representation for Key Hacker Identification in Underground
Forums), designed to identify these key hackers by modeling each user as a
textual sequence. This sequence is processed through a large language model
(LLM) for domain-specific adaptation, with LLMs acting as feature extractors.
These extracted features are then fed into a Graph Neural Network (GNN) to
model user structural relationships, significantly improving identification
accuracy. Furthermore, we employ BERTopic (Bidirectional Encoder
Representations from Transformers Topic Modeling) to extract personalized
topics from user-generated content, enabling multiple textual representations
per user and optimizing the selection of the most representative sequence. Our
study demonstrates that fine-tuned LLMs outperform state-of-the-art methods in
identifying key hackers. Additionally, when combined with GNNs, our model
achieves significant improvements, resulting in approximately 6% and 10%
increases in accuracy and F1-score, respectively, over existing methods.
EUREKHA was tested on the Hack-Forums dataset, and we provide open-source
access to our code.

摘要：<paragraph>地下論壇是網路犯罪活動的樞紐，提供匿名和規避傳統網路監督的空間。在這些隱藏的社群中，惡意行為者合作交換非法知識、工具和策略，推動從駭客技術到銷售竊取資料、惡意軟體和零時差漏洞的各種網路威脅。找出這些行動背後的關鍵煽動者（即關鍵駭客）至關重要，但仍然是一個複雜的挑戰。本文提出了一種稱為 EUREKHA（增強使用者表徵以識別地下論壇中的關鍵駭客）的新方法，旨在透過將每個使用者建模為文字序列來識別這些關鍵駭客。此序列透過大型語言模型（LLM）處理以進行特定領域的適應，其中 LLM 作為特徵萃取器。然後將這些萃取的特徵輸入圖神經網路（GNN）以建模使用者結構關係，大幅提升識別準確度。此外，我們採用 BERTopic（來自 Transformer 主題建模的雙向編碼器表徵）從使用者產生的內容中萃取個人化主題，為每個使用者啟用多個文字表徵，並最佳化最具代表性序列的選擇。我們的研究表明，微調後的 LLM 在識別關鍵駭客方面優於最先進的方法。此外，當與 GNN 結合使用時，我們的模型獲得顯著的提升，與現有方法相比，準確度和 F1 分數分別提高了約 6% 和 10%。EUREKHA 已在 Hack-Forums 資料集上進行測試，我們提供開源方式存取我們的程式碼。</paragraph>

##### **When are 1.58 bits enough? A Bottom-up Exploration of BitNet Quantization**
2411.05882v1 by Jacob Nielsen, Lukas Galke, Peter Schneider-Kamp

Contemporary machine learning models, such as language models, are powerful,
but come with immense resource requirements both at training and inference
time. It has been shown that decoder-only language models can be trained to a
competitive state with ternary weights (1.58 bits per weight), facilitating
efficient inference. Here, we start our exploration with non-transformer model
architectures, investigating 1.58-bit training for multi-layer perceptrons and
graph neural networks. Then, we explore 1.58-bit training in other
transformer-based language models, namely encoder-only and encoder-decoder
models. Our results show that in all of these settings, 1.58-bit training is on
par with or sometimes even better than the standard 32/16-bit models.

摘要：當代機器學習模型（例如語言模型）功能強大，
但在訓練和推論時間上都需要大量的資源。已經證明，僅解碼器語言模型可以用三元權重（每個權重 1.58 位元）訓練到競爭狀態，促進有效率的推論。在此，我們從非Transformer模型架構開始探討，研究多層感知器和圖神經網路的 1.58 位元訓練。接著，我們探討其他基於Transformer的語言模型（即僅編碼器和編碼器-解碼器模型）的 1.58 位元訓練。我們的結果顯示，在所有這些設定中，1.58 位元訓練與標準 32/16 位元模型相當，有時甚至更好。

##### **Exploring the Alignment Landscape: LLMs and Geometric Deep Models in Protein Representation**
2411.05316v1 by Dong Shu, Bingbing Duan, Kai Guo, Kaixiong Zhou, Jiliang Tang, Mengnan Du

Latent representation alignment has become a foundational technique for
constructing multimodal large language models (MLLM) by mapping embeddings from
different modalities into a shared space, often aligned with the embedding
space of large language models (LLMs) to enable effective cross-modal
understanding. While preliminary protein-focused MLLMs have emerged, they have
predominantly relied on heuristic approaches, lacking a fundamental
understanding of optimal alignment practices across representations. In this
study, we explore the alignment of multimodal representations between LLMs and
Geometric Deep Models (GDMs) in the protein domain. We comprehensively evaluate
three state-of-the-art LLMs (Gemma2-2B, LLaMa3.1-8B, and LLaMa3.1-70B) with
four protein-specialized GDMs (GearNet, GVP, ScanNet, GAT). Our work examines
alignment factors from both model and protein perspectives, identifying
challenges in current alignment methodologies and proposing strategies to
improve the alignment process. Our key findings reveal that GDMs incorporating
both graph and 3D structural information align better with LLMs, larger LLMs
demonstrate improved alignment capabilities, and protein rarity significantly
impacts alignment performance. We also find that increasing GDM embedding
dimensions, using two-layer projection heads, and fine-tuning LLMs on
protein-specific data substantially enhance alignment quality. These strategies
offer potential enhancements to the performance of protein-related multimodal
models. Our code and data are available at
https://github.com/Tizzzzy/LLM-GDM-alignment.

摘要：潛在表徵對齊已成為建構多模態大型語言模型 (MLLM) 的基礎技術，方法是將不同模態的嵌入映射到共享空間中，通常與大型語言模型 (LLM) 的嵌入空間對齊，以實現有效的跨模態理解。雖然初步以蛋白質為重點的 MLLM 已出現，但它們主要依賴啟發式方法，缺乏對跨表徵最佳對齊實務的基本理解。在本研究中，我們探討了蛋白質領域中 LLM 與幾何深度模型 (GDM) 之間的多模態表徵對齊。我們全面評估了三個最先進的 LLM（Gemma2-2B、LLaMa3.1-8B 和 LLaMa3.1-70B）與四個蛋白質專用 GDM（GearNet、GVP、ScanNet、GAT）。我們的研究從模型和蛋白質角度檢視對齊因素，識別當前對齊方法的挑戰，並提出改善對齊程序的策略。我們的關鍵發現顯示，同時包含圖形和 3D 結構資訊的 GDM 與 LLM 的對齊效果較佳，較大的 LLM 展現出更佳的對齊能力，而蛋白質的稀有性顯著影響對齊效能。我們還發現，增加 GDM 嵌入維度、使用兩層投影頭，以及針對蛋白質特定資料微調 LLM，可以大幅提升對齊品質。這些策略為蛋白質相關多模態模型的效能提供潛在的強化。我們的程式碼和資料可在 https://github.com/Tizzzzy/LLM-GDM-alignment 取得。

##### **AMSnet-KG: A Netlist Dataset for LLM-based AMS Circuit Auto-Design Using Knowledge Graph RAG**
2411.13560v1 by Yichen Shi, Zhuofu Tao, Yuhao Gao, Tianjia Zhou, Cheng Chang, Yaxing Wang, Bingyu Chen, Genhao Zhang, Alvin Liu, Zhiping Yu, Ting-Jung Lin, Lei He

High-performance analog and mixed-signal (AMS) circuits are mainly
full-custom designed, which is time-consuming and labor-intensive. A
significant portion of the effort is experience-driven, which makes the
automation of AMS circuit design a formidable challenge. Large language models
(LLMs) have emerged as powerful tools for Electronic Design Automation (EDA)
applications, fostering advancements in the automatic design process for
large-scale AMS circuits. However, the absence of high-quality datasets has led
to issues such as model hallucination, which undermines the robustness of
automatically generated circuit designs. To address this issue, this paper
introduces AMSnet-KG, a dataset encompassing various AMS circuit schematics and
netlists. We construct a knowledge graph with annotations on detailed
functional and performance characteristics. Facilitated by AMSnet-KG, we
propose an automated AMS circuit generation framework that utilizes the
comprehensive knowledge embedded in LLMs. We first formulate a design strategy
(e.g., circuit architecture using a number of circuit components) based on
required specifications. Next, matched circuit components are retrieved and
assembled into a complete topology, and transistor sizing is obtained through
Bayesian optimization. Simulation results of the netlist are fed back to the
LLM for further topology refinement, ensuring the circuit design specifications
are met. We perform case studies of operational amplifier and comparator design
to verify the automatic design flow from specifications to netlists with
minimal human effort. The dataset used in this paper will be open-sourced upon
publishing of this paper.

摘要：高性能類比與混合訊號 (AMS) 電路主要為全客製化設計，這相當耗時且費工。其中很大一部分的工作仰賴經驗，這讓 AMS 電路設計的自動化成為一項艱鉅的挑戰。大型語言模型 (LLM) 已成為電子設計自動化 (EDA) 應用程式強大的工具，促進大規模 AMS 電路自動設計流程的進展。然而，缺乏高品質的資料集導致模型出現幻覺等問題，這損害了自動產生電路設計的穩健性。為了解決此問題，本文介紹了 AMSnet-KG，這是一個包含各種 AMS 電路原理圖和網路清單的資料集。我們建立了一個包含詳細功能和效能特徵註解的知識圖譜。在 AMSnet-KG 的協助下，我們提出了一個自動化 AMS 電路產生架構，它利用了內嵌在 LLM 中的全面知識。我們首先根據所需規格制定設計策略（例如使用多個電路元件的電路架構）。接著，擷取匹配的電路元件並組裝成一個完整的拓撲，並透過貝氏最佳化取得電晶體尺寸。網路清單的模擬結果會回饋給 LLM 以進一步優化拓撲，確保電路設計規格得到滿足。我們執行運算放大器和比較器設計的個案研究，以驗證從規格到網路清單的自動設計流程，並將人為介入降到最低。本文中使用的資料集將在本文發布後開源。

##### **LEGO-GraphRAG: Modularizing Graph-based Retrieval-Augmented Generation for Design Space Exploration**
2411.05844v1 by Yukun Cao, Zengyi Gao, Zhiyang Li, Xike Xie, S Kevin Zhou

GraphRAG addresses significant challenges in Retrieval-Augmented Generation
(RAG) by leveraging graphs with embedded knowledge to enhance the reasoning
capabilities of Large Language Models (LLMs). Despite its promising potential,
the GraphRAG community currently lacks a unified framework for fine-grained
decomposition of the graph-based knowledge retrieval process. Furthermore,
there is no systematic categorization or evaluation of existing solutions
within the retrieval process. In this paper, we present LEGO-GraphRAG, a
modular framework that decomposes the retrieval process of GraphRAG into three
interconnected modules: subgraph-extraction, path-filtering, and
path-refinement. We systematically summarize and classify the algorithms and
neural network (NN) models relevant to each module, providing a clearer
understanding of the design space for GraphRAG instances. Additionally, we
identify key design factors, such as Graph Coupling and Computational Cost,
that influence the effectiveness of GraphRAG implementations. Through extensive
empirical studies, we construct high-quality GraphRAG instances using a
representative selection of solutions and analyze their impact on retrieval and
reasoning performance. Our findings offer critical insights into optimizing
GraphRAG instance design, ultimately contributing to the advancement of more
accurate and contextually relevant LLM applications.

摘要：GraphRAG 透過利用具嵌入知識的圖表來增強大型語言模型 (LLM) 的推理能力，解決了檢索增強生成 (RAG) 中的重大挑戰。儘管具有令人期待的潛力，但 GraphRAG 社群目前缺乏一個統一的架構，用於對基於圖表的知識檢索過程進行細粒度的分解。此外，在檢索過程中，現有解決方案並未進行系統性的分類或評估。在本文中，我們提出了 LEGO-GraphRAG，這是一個模組化架構，將 GraphRAG 的檢索過程分解為三個相互連接的模組：子圖萃取、路徑過濾和路徑精煉。我們系統性地總結和分類與每個模組相關的演算法和神經網路 (NN) 模型，提供對 GraphRAG 實例設計空間的更清晰理解。此外，我們找出影響 GraphRAG 實作有效性的關鍵設計因素，例如圖表耦合和運算成本。透過廣泛的經驗研究，我們使用具代表性的解決方案選擇來建構高品質的 GraphRAG 實例，並分析它們對檢索和推理效能的影響。我們的研究結果提供了優化 GraphRAG 實例設計的重要見解，最終有助於推進更準確且與脈絡相關的 LLM 應用。

##### **MEG: Medical Knowledge-Augmented Large Language Models for Question Answering**
2411.03883v2 by Laura Cabello, Carmen Martin-Turrero, Uchenna Akujuobi, Anders Søgaard, Carlos Bobed

Question answering is a natural language understanding task that involves
reasoning over both explicit context and unstated, relevant domain knowledge.
Large language models (LLMs), which underpin most contemporary question
answering systems, struggle to induce how concepts relate in specialized
domains such as medicine. Existing medical LLMs are also costly to train. In
this work, we present MEG, a parameter-efficient approach for medical
knowledge-augmented LLMs. MEG uses a lightweight mapping network to integrate
graph embeddings into the LLM, enabling it to leverage external knowledge in a
cost-effective way. We evaluate our method on four popular medical
multiple-choice datasets and show that LLMs greatly benefit from the factual
grounding provided by knowledge graph embeddings. MEG attains an average of
+10.2% accuracy over the Mistral-Instruct baseline, and +6.7% over specialized
models like BioMistral. We also show results based on Llama-3. Finally, we show
that MEG's performance remains robust to the choice of graph encoder.

摘要：問答是自然語言理解任務，涉及對明確的上下文和未說明的相關領域知識進行推理。支撐大多數當代問答系統的大型語言模型 (LLM) 難以推論概念如何在醫學等專業領域中關聯。現有的醫學 LLM 訓練成本也很高。在這項工作中，我們提出了 MEG，這是一種用於醫學知識增強 LLM 的參數有效方法。MEG 使用輕量級映射網路將圖表嵌入整合到 LLM 中，使其能夠以經濟有效的方式利用外部知識。我們在四個流行的醫學多選題資料集上評估了我們的方法，並表明 LLM 從知識圖表嵌入提供的實際依據中受益匪淺。MEG 在 Mistral-Instruct 基準上平均提高了 +10.2% 的準確度，在 BioMistral 等專門模型上提高了 +6.7%。我們還展示了基於 Llama-3 的結果。最後，我們表明 MEG 的性能對圖表編碼器的選擇保持穩健。

##### **A Library Perspective on Supervised Text Processing in Digital Libraries: An Investigation in the Biomedical Domain**
2411.12752v1 by Hermann Kroll, Pascal Sackhoff, Bill Matthias Thang, Maha Ksouri, Wolf-Tilo Balke

Digital libraries that maintain extensive textual collections may want to
further enrich their content for certain downstream applications, e.g.,
building knowledge graphs, semantic enrichment of documents, or implementing
novel access paths. All of these applications require some text processing,
either to identify relevant entities, extract semantic relationships between
them, or to classify documents into some categories. However, implementing
reliable, supervised workflows can become quite challenging for a digital
library because suitable training data must be crafted, and reliable models
must be trained. While many works focus on achieving the highest accuracy on
some benchmarks, we tackle the problem from a digital library practitioner. In
other words, we also consider trade-offs between accuracy and application
costs, dive into training data generation through distant supervision and large
language models such as ChatGPT, LLama, and Olmo, and discuss how to design
final pipelines. Therefore, we focus on relation extraction and text
classification, using the showcase of eight biomedical benchmarks.

摘要：維護廣泛文本集合的數位圖書館可能希望進一步豐富其內容以供特定下游應用程式使用，例如建構知識圖譜、文件語意豐富化或實作新穎的存取路徑。所有這些應用程式都需要一些文字處理，才能識別相關實體、萃取它們之間的語意關係，或將文件分類到某些類別中。然而，對於數位圖書館來說，實作可靠的監督式工作流程可能會變得相當具有挑戰性，因為必須建立適當的訓練資料，並訓練可靠的模型。雖然許多研究專注於在某些基準上達成最高準確度，但我們從數位圖書館實務者的角度來解決這個問題。換句話說，我們也考慮準確度和應用成本之間的權衡，深入探討透過遠距監督和大型語言模型（例如 ChatGPT、LLama 和 Olmo）來產生訓練資料，並討論如何設計最終管線。因此，我們專注於關係萃取和文字分類，並使用八個生物醫學基準作為展示案例。

##### **The American Sign Language Knowledge Graph: Infusing ASL Models with Linguistic Knowledge**
2411.03568v1 by Lee Kezar, Nidhi Munikote, Zian Zeng, Zed Sehyr, Naomi Caselli, Jesse Thomason

Language models for American Sign Language (ASL) could make language
technologies substantially more accessible to those who sign. To train models
on tasks such as isolated sign recognition (ISR) and ASL-to-English
translation, datasets provide annotated video examples of ASL signs. To
facilitate the generalizability and explainability of these models, we
introduce the American Sign Language Knowledge Graph (ASLKG), compiled from
twelve sources of expert linguistic knowledge. We use the ASLKG to train
neuro-symbolic models for 3 ASL understanding tasks, achieving accuracies of
91% on ISR, 14% for predicting the semantic features of unseen signs, and 36%
for classifying the topic of Youtube-ASL videos.

摘要：美國手語 (ASL) 的語言模型可以讓語言技術對手語使用者更易於使用。為了訓練模型執行手語辨識 (ISR) 和 ASL 轉換成英文等任務，資料集提供 ASL 手勢的註解影片範例。為了促進這些模型的概括性和可解釋性，我們引入了美國手語知識圖譜 (ASLKG)，它是由十二個專家語言知識來源編譯而成的。我們使用 ASLKG 訓練神經符號模型來執行 3 項 ASL 理解任務，在 ISR 上達到 91% 的準確度、在預測未見手勢的語義特徵上達到 14%，以及在分類 YouTube-ASL 影片主題上達到 36%。

##### **Graph-DPEP: Decomposed Plug and Ensemble Play for Few-Shot Document Relation Extraction with Graph-of-Thoughts Reasoning**
2411.02864v1 by Tao Zhang, Ning Yan, Masood Mortazavi, Hoang H. Nguyen, Zhongfen Deng, Philip S. Yu

Large language models (LLMs) pre-trained on massive corpora have demonstrated
impressive few-shot learning capability on many NLP tasks. Recasting an NLP
task into a text-to-text generation task is a common practice so that
generative LLMs can be prompted to resolve it. However, performing
document-level relation extraction (DocRE) tasks with generative LLM models is
still challenging due to the structured output format of DocRE, which
complicates the conversion to plain text. Limited information available in
few-shot samples and prompt instructions induce further difficulties and
challenges in relation extraction for mentioned entities in a document. In this
paper, we represent the structured output as a graph-style triplet rather than
natural language expressions and leverage generative LLMs for the DocRE task.
Our approach, the Graph-DPEP framework is grounded in the reasoning behind
triplet explanation thoughts presented in natural language. In this framework,
we first introduce a ``decomposed-plug" method for performing the generation
from LLMs over prompts with type-space decomposition to alleviate the burden of
distinguishing all relation types. Second, we employ a verifier for calibrating
the generation and identifying overlooked query entity pairs. Third, we develop
"ensemble-play", reapplying generation on the entire type list by leveraging
the reasoning thoughts embedded in a sub-graph associated with the missing
query pair to address the missingness issue. Through extensive comparisons with
existing prompt techniques and alternative Language Models (LLMs), our
framework demonstrates superior performance on publicly available benchmarks in
experiments.

摘要：大型語言模型 (LLM) 在海量語料庫上預先訓練，已在許多自然語言處理任務上展現出令人印象深刻的少量樣本學習能力。將自然語言處理任務轉化為文字到文字的生成任務是一種常見做法，這樣生成式大型語言模型就可以提示解決它。然而，由於 DocRE 的結構化輸出格式，使用生成式大型語言模型來執行文件級別關係萃取 (DocRE) 任務仍然具有挑戰性，這使得轉換為純文字變得複雜。少量樣本和提示說明中可用的資訊有限，會導致在文件中提到實體的關係萃取中產生進一步的困難和挑戰。在本文中，我們將結構化輸出表示為圖形樣式的三元組，而不是自然語言表達，並利用生成式大型語言模型來執行 DocRE 任務。我們的做法，圖形 DPEP 框架，是基於自然語言中呈現的三元組解釋思想背後的推理。在這個框架中，我們首先介紹一種「分解插入」方法，用於對具有類型空間分解的提示進行大型語言模型生成，以減輕區分所有關係類型的負擔。其次，我們使用驗證器來校準生成並識別被忽略的查詢實體對。第三，我們開發「整體遊戲」，通過利用與遺失查詢對相關的子圖中嵌入的推理思想，在整個類型列表上重新應用生成，以解決遺失問題。通過與現有提示技術和替代語言模型 (LLM) 的廣泛比較，我們的框架在實驗中證明了在公開基準上的優異性能。

##### **Multimodal Commonsense Knowledge Distillation for Visual Question Answering**
2411.02722v1 by Shuo Yang, Siwen Luo, Soyeon Caren Han

Existing Multimodal Large Language Models (MLLMs) and Visual Language
Pretrained Models (VLPMs) have shown remarkable performances in the general
Visual Question Answering (VQA). However, these models struggle with VQA
questions that require external commonsense knowledge due to the challenges in
generating high-quality prompts and the high computational costs of
fine-tuning. In this work, we propose a novel graph-based multimodal
commonsense knowledge distillation framework that constructs a unified
relational graph over commonsense knowledge, visual objects and questions
through a Graph Convolutional Network (GCN) following a teacher-student
environment. This proposed framework is flexible with any type of teacher and
student models without further fine-tuning, and has achieved competitive
performances on the ScienceQA dataset.

摘要：現有的多模態大型語言模型 (MLLM) 和視覺語言預訓練模型 (VLPM) 在一般的視覺問答 (VQA) 中展現了卓越的表現。然而，這些模型在需要外部常識知識的 VQA 問題上會遇到困難，原因在於產生高品質提示的挑戰以及微調的高運算成本。在這項工作中，我們提出了一個新穎的基於圖形的模態常識知識萃取架構，透過圖形卷積網路 (GCN) 在常識知識、視覺物件和問題上建構一個統一的關聯圖形，遵循師生環境。這個提出的架構對於任何類型的教師和學生模型都具有彈性，無需進一步微調，並在 ScienceQA 資料集上取得了有競爭力的表現。

##### **Geometry of orofacial neuromuscular signals: speech articulation decoding using surface electromyography**
2411.02591v2 by Harshavardhana T. Gowda, Zachary D. McNaughton, Lee M. Miller

Each year, millions of individuals lose the ability to speak intelligibly due
to causes such as neuromuscular disease, stroke, trauma, and head/neck cancer
surgery (e.g. laryngectomy) or treatment (e.g. radiotherapy toxicity to the
speech articulators). Effective communication is crucial for daily activities,
and losing the ability to speak leads to isolation, depression, anxiety, and a
host of detrimental sequelae. Noninvasive surface electromyography (sEMG) has
shown promise to restore speech output in these individuals. The goal is to
collect sEMG signals from multiple articulatory sites as people silently
produce speech and then decode the signals to enable fluent and natural
communication. Currently, many fundamental properties of orofacial
neuromuscular signals relating to speech articulation remain unanswered. They
include questions relating to 1) the data structure of the orofacial sEMG
signals, 2)the signal distribution shift of sEMG across individuals, 3) ability
of sEMG signals to span the entire English language phonetic space during
silent speech articulations, and 4) the generalization capability of
non-invasive sEMG based silent speech interfaces. We address these questions
through a series of experiments involving healthy human subjects. We show that
sEMG signals evince graph data structure and that the signal distribution shift
is given by a change of basis. Furthermore, we show that silently voiced
articulations spanning the entire English language phonetic space can be
decoded using small neural networks which can be trained with little data and
that such architectures work well across individuals. To ensure transparency
and reproducibility, we open-source all the data and codes used in this study.

摘要：每年，數百萬人因神經肌肉疾病、中風、創傷、頭頸癌手術（例如喉切除術）或治療（例如放射治療對言語構音器官的毒性）而失去清晰說話的能力。有效的溝通對於日常活動至關重要，而失去說話的能力會導致孤立、沮喪、焦慮和一系列有害的後遺症。非侵入性表面肌電圖 (sEMG) 已顯示出恢復這些人說話輸出的希望。目標是從多個構音部位收集 sEMG 信號，因為人們在無聲地發音，然後解碼信號以實現流利而自然的溝通。目前，許多與言語構音有關的面部神經肌肉信號的基本特性仍未得到解答。它們包括與 1) 面部 sEMG 信號的數據結構、2) sEMG 在個人之間的信號分佈轉移、3) sEMG 信號在無聲言語構音過程中跨越整個英語語音空間的能力以及 4) 基於非侵入性 sEMG 的無聲言語介面的泛化能力相關的問題。我們通過一系列涉及健康人類受試者的實驗來解決這些問題。我們表明 sEMG 信號表現出圖數據結構，並且信號分佈轉移是由基變化的給出的。此外，我們表明，使用可以通過少量數據訓練的小神經網路可以解碼跨越整個英語語音空間的無聲發音，並且這種架構在不同個體之間都能很好地工作。為了確保透明度和可複製性，我們公開了本研究中使用的所有數據和代碼。

##### **GraphXAIN: Narratives to Explain Graph Neural Networks**
2411.02540v2 by Mateusz Cedro, David Martens

Graph Neural Networks (GNNs) are a powerful technique for machine learning on
graph-structured data, yet they pose interpretability challenges, especially
for non-expert users. Existing GNN explanation methods often yield technical
outputs such as subgraphs and feature importance scores, which are not easily
understood. Building on recent insights from social science and other
Explainable AI (XAI) methods, we propose GraphXAIN, a natural language
narrative that explains individual predictions made by GNNs. We present a
model-agnostic and explainer-agnostic XAI approach that complements graph
explainers by generating GraphXAINs, using Large Language Models (LLMs) and
integrating graph data, individual predictions from GNNs, explanatory
subgraphs, and feature importances. We define XAI Narratives and XAI
Descriptions, highlighting their distinctions and emphasizing the importance of
narrative principles in effective explanations. By incorporating natural
language narratives, our approach supports graph practitioners and non-expert
users, aligning with social science research on explainability and enhancing
user understanding and trust in complex GNN models. We demonstrate GraphXAIN's
capabilities on a real-world graph dataset, illustrating how its generated
narratives can aid understanding compared to traditional graph explainer
outputs or other descriptive explanation methods.

摘要：圖形神經網路 (GNN) 是用於圖形結構資料的機器學習強大技術，但它們會造成可解釋性挑戰，特別是對於非專家使用者。現有的 GNN 解釋方法通常會產生技術輸出，例如子圖和特徵重要性分數，這些輸出不容易理解。建構於社會科學和其他可解釋 AI (XAI) 方法的最新見解，我們提出 GraphXAIN，這是一種自然語言敘述，可以解釋 GNN 做出的個別預測。我們提出一個與模型無關且與解釋器無關的 XAI 方法，它透過使用大型語言模型 (LLM) 和整合圖形資料、GNN 的個別預測、說明性子圖和特徵重要性來補充圖形解釋器，進而產生 GraphXAIN。我們定義 XAI 敘述和 XAI 描述，強調它們的區別，並強調敘述原則在有效解釋中的重要性。透過結合自然語言敘述，我們的做法支援圖形從業者和非專家使用者，與可解釋性的社會科學研究保持一致，並增強使用者對複雜 GNN 模型的理解和信任。我們在真實世界圖形資料集上展示 GraphXAIN 的功能，說明與傳統圖形解釋器輸出或其他描述性解釋方法相比，其產生的敘述如何有助於理解。

##### **Improving Scientific Hypothesis Generation with Knowledge Grounded Large Language Models**
2411.02382v1 by Guangzhi Xiong, Eric Xie, Amir Hassan Shariatmadari, Sikun Guo, Stefan Bekiranov, Aidong Zhang

Large language models (LLMs) have demonstrated remarkable capabilities in
various scientific domains, from natural language processing to complex
problem-solving tasks. Their ability to understand and generate human-like text
has opened up new possibilities for advancing scientific research, enabling
tasks such as data analysis, literature review, and even experimental design.
One of the most promising applications of LLMs in this context is hypothesis
generation, where they can identify novel research directions by analyzing
existing knowledge. However, despite their potential, LLMs are prone to
generating ``hallucinations'', outputs that are plausible-sounding but
factually incorrect. Such a problem presents significant challenges in
scientific fields that demand rigorous accuracy and verifiability, potentially
leading to erroneous or misleading conclusions. To overcome these challenges,
we propose KG-CoI (Knowledge Grounded Chain of Ideas), a novel system that
enhances LLM hypothesis generation by integrating external, structured
knowledge from knowledge graphs (KGs). KG-CoI guides LLMs through a structured
reasoning process, organizing their output as a chain of ideas (CoI), and
includes a KG-supported module for the detection of hallucinations. With
experiments on our newly constructed hypothesis generation dataset, we
demonstrate that KG-CoI not only improves the accuracy of LLM-generated
hypotheses but also reduces the hallucination in their reasoning chains,
highlighting its effectiveness in advancing real-world scientific research.

摘要：大型語言模型 (LLM) 已在各種科學領域展現卓越的能力，從自然語言處理到複雜的解決問題任務。它們理解和產生類似人類文字的能力為推進科學研究開啟了新的可能性，讓資料分析、文獻回顧，甚至實驗設計等任務成為可能。LLM 在此脈絡中最有希望的應用之一是假設產生，它們能透過分析現有知識來找出新的研究方向。然而，儘管 LLM 具有潛力，它們卻容易產生「幻覺」，也就是聽起來合理但事實上不正確的輸出。此類問題在需要嚴謹準確性和可驗證性的科學領域中會造成重大挑戰，有可能導致錯誤或誤導性的結論。為了克服這些挑戰，我們提出 KG-CoI（知識基礎觀念鏈），這是一個創新的系統，它透過整合知識圖譜 (KG) 中的外部結構化知識來增強 LLM 假設產生。KG-CoI 引導 LLM 進行結構化推理程序，將其輸出整理成觀念鏈 (CoI)，並包含一個由 KG 支援的模組來偵測幻覺。透過我們新建立的假設產生資料集進行的實驗，我們證明 KG-CoI 不僅改善了 LLM 產生的假設的準確性，也減少了其推理鏈中的幻覺，突顯了其在推進現實世界科學研究中的效能。

##### **QCG-Rerank: Chunks Graph Rerank with Query Expansion in Retrieval-Augmented LLMs for Tourism Domain**
2411.08724v1 by Qikai Wei, Mingzhi Yang, Chunlong Han, Jingfu Wei, Minghao Zhang, Feifei Shi, Huansheng Ning

Retrieval-Augmented Generation (RAG) mitigates the issue of hallucination in
Large Language Models (LLMs) by integrating information retrieval techniques.
However, in the tourism domain, since the query is usually brief and the
content in the database is diverse, existing RAG may contain a significant
amount of irrelevant or contradictory information contents after retrieval. To
address this challenge, we propose the QCG-Rerank model. This model first
performs an initial retrieval to obtain candidate chunks and then enhances
semantics by extracting critical information to expand the original query.
Next, we utilize the expanded query and candidate chunks to calculate
similarity scores as the initial transition probability and construct the
chunks graph. Subsequently, We iteratively compute the transition probabilities
based on an initial estimate until convergence. The chunks with the highest
score are selected and input into the LLMs to generate responses. We evaluate
the model on Cultour, IIRC, StrategyQA, HotpotQA, SQuAD, and MuSiQue datasets.
The experimental results demonstrate the effectiveness and superiority of the
QCG-Rerank method.

摘要：擷取增強生成（RAG）透過整合資訊擷取技術來緩解大型語言模型（LLM）中的幻覺問題。然而，在旅遊領域中，由於查詢通常很簡短，而資料庫中的內容多樣，因此現有的 RAG 可能會在擷取後包含大量不相關或矛盾的資訊內容。為了應對這個挑戰，我們提出了 QCG-Rerank 模型。此模型首先執行初始擷取以取得候選區塊，然後透過擷取關鍵資訊來擴充原始查詢以增強語意。接著，我們利用擴充的查詢和候選區塊來計算相似度分數作為初始轉移機率，並建構區塊圖。隨後，我們根據初始估計反覆計算轉移機率，直到收斂。會選取分數最高的區塊，並輸入到 LLM 以產生回應。我們在 Cultour、IIRC、StrategyQA、HotpotQA、SQuAD 和 MuSiQue 資料集上評估此模型。實驗結果證明了 QCG-Rerank 方法的有效性和優越性。

##### **Can Language Models Enable In-Context Database?**
2411.01807v1 by Yu Pan, Hongfeng Yu, Tianjiao Zhao, Jianxin Sun

Large language models (LLMs) are emerging as few-shot learners capable of
handling a variety of tasks, including comprehension, planning, reasoning,
question answering, arithmetic calculations, and more. At the core of these
capabilities is LLMs' proficiency in representing and understanding structural
or semi-structural data, such as tables and graphs. Numerous studies have
demonstrated that reasoning on tabular data or graphs is not only feasible for
LLMs but also gives a promising research direction which treats these data as
in-context data. The lightweight and human readable characteristics of
in-context database can potentially make it an alternative for the traditional
database in typical RAG (Retrieval Augmented Generation) settings. However,
almost all current work focuses on static in-context data, which does not allow
dynamic update. In this paper, to enable dynamic database update, delta
encoding of database is proposed. We explore how data stored in traditional
RDBMS can be encoded as in-context text and evaluate LLMs' proficiency for CRUD
(Create, Read, Update and Delete) operations on in-context databases. A
benchmark named InConDB is presented and extensive experiments are conducted to
show the performance of different language models in enabling in-context
database by varying the database encoding method, prompting method, operation
type and input data distribution, revealing both the proficiency and
limitations.

摘要：大型語言模型 (LLM) 逐漸成為僅需少量範例就能處理各種任務的學習者，包括理解、規劃、推理、問答、算術計算等。這些能力的核心是 LLM 在表示和理解結構化或半結構化資料（例如表格和圖形）方面的能力。許多研究已證明，LLM 不僅可以推論表格資料或圖形，還提供了一個有前景的研究方向，將這些資料視為語境資料。語境資料庫的輕量級和人類可讀取特性有可能使其成為典型 RAG（檢索擴充生成）設定中傳統資料庫的替代方案。然而，幾乎所有目前的工作都專注於靜態語境資料，這不允許動態更新。在本文中，為了實現動態資料庫更新，提出了資料庫的 delta 編碼。我們探討了如何將儲存在傳統 RDBMS 中的資料編碼為語境文字，並評估 LLM 在語境資料庫上進行 CRUD（建立、讀取、更新和刪除）操作的能力。提出了名為 InConDB 的基準，並進行了廣泛的實驗，以顯示不同語言模型在通過改變資料庫編碼方法、提示方法、操作類型和輸入資料分佈來啟用語境資料庫方面的效能，揭示了能力和限制。

##### **Graph-based Confidence Calibration for Large Language Models**
2411.02454v1 by Yukun Li, Sijia Wang, Lifu Huang, Li-Ping Liu

One important approach to improving the reliability of large language models
(LLMs) is to provide accurate confidence estimations regarding the correctness
of their answers. However, developing a well-calibrated confidence estimation
model is challenging, as mistakes made by LLMs can be difficult to detect. We
propose a novel method combining the LLM's self-consistency with labeled data
and training an auxiliary model to estimate the correctness of its responses to
questions. This auxiliary model predicts the correctness of responses based
solely on their consistent information. To set up the learning problem, we use
a weighted graph to represent the consistency among the LLM's multiple
responses to a question. Correctness labels are assigned to these responses
based on their similarity to the correct answer. We then train a graph neural
network to estimate the probability of correct responses. Experiments
demonstrate that the proposed approach substantially outperforms several of the
most recent methods in confidence calibration across multiple widely adopted
benchmark datasets. Furthermore, the proposed approach significantly improves
the generalization capability of confidence calibration on out-of-domain (OOD)
data.

摘要：一種改善大型語言模型 (LLM) 可靠性的重要方法是提供有關其答案正確性的準確信心估計。然而，開發一個校準良好的信心估計模型具有挑戰性，因為 LLM 所犯的錯誤可能難以偵測。我們提出一個新方法，結合 LLM 的自我一致性與標籤資料，並訓練一個輔助模型來估計其對問題的回應正確性。這個輔助模型僅根據其一致性資訊來預測回應的正確性。為了設定學習問題，我們使用一個加權圖形來表示 LLM 對一個問題的多次回應之間的一致性。正確性標籤會根據這些回應與正確答案的相似性分配給這些回應。然後，我們訓練一個圖形神經網路來估計正確回應的機率。實驗證明，所提出的方法在多個廣泛採用的基準資料集上，在信心校準方面明顯優於多種最新方法。此外，所提出的方法顯著改善了在領域外 (OOD) 資料上信心校準的泛化能力。

##### **Ontology Population using LLMs**
2411.01612v1 by Sanaz Saki Norouzi, Adrita Barua, Antrea Christou, Nikita Gautam, Andrew Eells, Pascal Hitzler, Cogan Shimizu

Knowledge graphs (KGs) are increasingly utilized for data integration,
representation, and visualization. While KG population is critical, it is often
costly, especially when data must be extracted from unstructured text in
natural language, which presents challenges, such as ambiguity and complex
interpretations. Large Language Models (LLMs) offer promising capabilities for
such tasks, excelling in natural language understanding and content generation.
However, their tendency to ``hallucinate'' can produce inaccurate outputs.
Despite these limitations, LLMs offer rapid and scalable processing of natural
language data, and with prompt engineering and fine-tuning, they can
approximate human-level performance in extracting and structuring data for KGs.
This study investigates LLM effectiveness for the KG population, focusing on
the Enslaved.org Hub Ontology. In this paper, we report that compared to the
ground truth, LLM's can extract ~90% of triples, when provided a modular
ontology as guidance in the prompts.

摘要：知識圖譜 (KG) 愈來愈多用於資料整合、表示和視覺化。儘管 KG 填充至關重要，但它通常很昂貴，特別是在必須從自然語言中非結構化文字中提取資料時，這會帶來挑戰，例如歧義和複雜的詮釋。大型語言模型 (LLM) 為此類任務提供了有前景的能力，擅長自然語言理解和內容生成。然而，它們「產生幻覺」的傾向可能會產生不準確的輸出。儘管有這些限制，LLM 提供了自然語言資料的快速且可擴充處理，並且透過提示工程和微調，它們可以近似人類層級的效能，以提取和建構 KG 的資料。本研究調查 LLM 對 KG 填充的有效性，重點關注 Enslaved.org Hub Ontology。在本文中，我們報告與真實情況相比，當在提示中提供模組化本体作為指導時，LLM 可以提取約 90% 的三元組。

##### **Pre-trained Molecular Language Models with Random Functional Group Masking**
2411.01401v1 by Tianhao Peng, Yuchen Li, Xuhong Li, Jiang Bian, Zeke Xie, Ning Sui, Shahid Mumtaz, Yanwu Xu, Linghe Kong, Haoyi Xiong

Recent advancements in computational chemistry have leveraged the power of
trans-former-based language models, such as MoLFormer, pre-trained using a vast
amount of simplified molecular-input line-entry system (SMILES) sequences, to
understand and predict molecular properties and activities, a critical step in
fields like drug discovery and materials science. To further improve
performance, researchers have introduced graph neural networks with graph-based
molecular representations, such as GEM, incorporating the topology, geometry,
2D or even 3D structures of molecules into pre-training. While most of
molecular graphs in existing studies were automatically converted from SMILES
sequences, it is to assume that transformer-based language models might be able
to implicitly learn structure-aware representations from SMILES sequences. In
this paper, we propose \ours{} -- a SMILES-based \underline{\em M}olecular
\underline{\em L}anguage \underline{\em M}odel, which randomly masking SMILES
subsequences corresponding to specific molecular \underline{\em F}unctional
\underline{\em G}roups to incorporate structure information of atoms during the
pre-training phase. This technique aims to compel the model to better infer
molecular structures and properties, thus enhancing its predictive
capabilities. Extensive experimental evaluations across 11 benchmark
classification and regression tasks in the chemical domain demonstrate the
robustness and superiority of \ours{}. Our findings reveal that \ours{}
outperforms existing pre-training models, either based on SMILES or graphs, in
9 out of the 11 downstream tasks, ranking as a close second in the remaining
ones.

摘要：<paragraph>計算化學的近期進展已利用轉換器語言模型的力量，例如 MoLFormer，使用大量簡化分子輸入線條輸入系統 (SMILES) 序列進行預訓練，以了解和預測分子特性和活性，這是藥物發現和材料科學等領域的重要步驟。為了進一步提升效能，研究人員引入了具有圖形為基礎的分子表示的圖形神經網路，例如 GEM，將分子的拓樸、幾何、2D 甚至 3D 結構納入預訓練中。雖然現有研究中的大多數分子圖形都是從 SMILES 序列自動轉換而來的，但可以假設基於轉換器的語言模型可能能夠從 SMILES 序列中隱式學習結構感知表示。在本文中，我們提出 \ours{} -- 一個基於 SMILES 的\underline{\em M}olecular\underline{\em L}anguage \underline{\em M}odel，它隨機遮蔽對應於特定分子\underline{\em F}unctional\underline{\em G}roups 的 SMILES 子序列，以在預訓練階段納入原子的結構資訊。此技術旨在強制模型更好地推斷分子結構和特性，從而增強其預測能力。在化學領域的 11 個基準分類和回歸任務中進行的廣泛實驗評估證明了 \ours{} 的穩健性和優越性。我們的研究結果顯示，\ours{} 在 11 個下游任務中的 9 個任務中優於現有的預訓練模型（基於 SMILES 或圖形），在剩下的任務中排名第二。</paragraph>

##### **Narrative Analysis of True Crime Podcasts With Knowledge Graph-Augmented Large Language Models**
2411.02435v1 by Xinyi Leng, Jason Liang, Jack Mauro, Xu Wang, Andrea L. Bertozzi, James Chapman, Junyuan Lin, Bohan Chen, Chenchen Ye, Temple Daniel, P. Jeffrey Brantingham

Narrative data spans all disciplines and provides a coherent model of the
world to the reader or viewer. Recent advancement in machine learning and Large
Language Models (LLMs) have enable great strides in analyzing natural language.
However, Large language models (LLMs) still struggle with complex narrative
arcs as well as narratives containing conflicting information. Recent work
indicates LLMs augmented with external knowledge bases can improve the accuracy
and interpretability of the resulting models. In this work, we analyze the
effectiveness of applying knowledge graphs (KGs) in understanding true-crime
podcast data from both classical Natural Language Processing (NLP) and LLM
approaches. We directly compare KG-augmented LLMs (KGLLMs) with classical
methods for KG construction, topic modeling, and sentiment analysis.
Additionally, the KGLLM allows us to query the knowledge base in natural
language and test its ability to factually answer questions. We examine the
robustness of the model to adversarial prompting in order to test the model's
ability to deal with conflicting information. Finally, we apply classical
methods to understand more subtle aspects of the text such as the use of
hearsay and sentiment in narrative construction and propose future directions.
Our results indicate that KGLLMs outperform LLMs on a variety of metrics, are
more robust to adversarial prompts, and are more capable of summarizing the
text into topics.

摘要：敘事資料涵蓋所有學科，並為讀者或觀眾提供一個連貫的世界模型。機器學習和大型語言模型 (LLM) 的最新進展在分析自然語言方面取得了長足的進步。然而，大型語言模型 (LLM) 仍然難以應付複雜的敘事弧線以及包含相互矛盾資訊的敘事。最近的研究表明，使用外部知識庫增強的 LLM 可以提高所產生模型的準確性和可解釋性。在這項工作中，我們分析了在從傳統自然語言處理 (NLP) 和 LLM 方法中理解真實犯罪播客資料時，應用知識圖譜 (KG) 的有效性。我們直接比較了 KG 增強的 LLM (KGLLM) 與用於 KG 建構、主題建模和情緒分析的傳統方法。此外，KGLLM 允許我們以自然語言查詢知識庫，並測試其事實回答問題的能力。我們檢查了模型對對抗性提示的穩健性，以測試模型處理相互矛盾資訊的能力。最後，我們應用傳統方法來理解文本的更細微方面，例如在敘事建構中使用道聽途說和情緒，並提出未來的方向。我們的結果表明，KGLLM 在各種指標上優於 LLM，對對抗提示更穩健，並且更能夠將文本總結為主題。

##### **WLPlan: Relational Features for Symbolic Planning**
2411.00577v1 by Dillon Z. Chen

Scalable learning for planning research generally involves juggling between
different programming languages for handling learning and planning modules
effectively. Interpreted languages such as Python are commonly used for
learning routines due to their ease of use and the abundance of highly
maintained learning libraries they exhibit, while compiled languages such as
C++ are used for planning routines due to their optimised resource usage.
Motivated by the need for tools for developing scalable learning planners, we
introduce WLPlan, a C++ package with Python bindings which implements recent
promising work for automatically generating relational features of planning
tasks. Such features can be used for any downstream routine, such as learning
domain control knowledge or probing and understanding planning tasks. More
specifically, WLPlan provides functionality for (1) transforming planning tasks
into graphs, and (2) embedding planning graphs into feature vectors via graph
kernels. The source code and instructions for the installation and usage of
WLPlan are available at tinyurl.com/42kymswc

摘要：可擴充的學習規劃研究通常需要在不同的程式語言之間切換，才能有效地處理學習和規劃模組。例如 Python 等直譯語言通常用於學習常式，因為它們易於使用，且有許多維護完善的學習函式庫；而例如 C++ 等編譯語言則用於規劃常式，因為它們能最佳化資源使用。由於需要開發可擴充學習規劃器的工具，我們引進了 WLPlan，這是一個具有 Python 繫結的 C++ 套件，實作了近期有前途的自動產生規劃任務關係特徵的工作。此類特徵可用於任何下游常式，例如學習領域控制知識或探測和理解規劃任務。更具體地說，WLPlan 提供了以下功能：(1) 將規劃任務轉換為圖形，以及 (2) 透過圖形核將規劃圖形嵌入特徵向量。WLPlan 的原始碼和安裝及使用說明可在 tinyurl.com/42kymswc 取得

##### **GRS-QA -- Graph Reasoning-Structured Question Answering Dataset**
2411.00369v3 by Anish Pahilajani, Devasha Trivedi, Jincen Shuai, Khin S. Yone, Samyak Rajesh Jain, Namyong Park, Ryan A. Rossi, Nesreen K. Ahmed, Franck Dernoncourt, Yu Wang

Large Language Models (LLMs) have excelled in multi-hop question-answering
(M-QA) due to their advanced reasoning abilities. However, the impact of the
inherent reasoning structures on LLM M-QA performance remains unclear, largely
due to the absence of QA datasets that provide fine-grained reasoning
structures. To address this gap, we introduce the Graph Reasoning-Structured
Question Answering Dataset (GRS-QA), which includes both semantic contexts and
reasoning structures for QA pairs. Unlike existing M-QA datasets, where
different reasoning structures are entangled together, GRS-QA explicitly
captures intricate reasoning pathways by constructing reasoning graphs, where
nodes represent textual contexts and edges denote logical flows. These
reasoning graphs of different structures enable a fine-grained evaluation of
LLM reasoning capabilities across various reasoning structures. Our empirical
analysis reveals that LLMs perform differently when handling questions with
varying reasoning structures. This finding facilitates the exploration of
textual structures as compared with semantics.

摘要：大型語言模型 (LLM) 由於其先進的推理能力，在多跳問答 (M-QA) 中表現出色。然而，固有推理結構對 LLM M-QA 效能的影響仍不清楚，這主要是由於缺乏提供細粒度推理結構的 QA 資料集。為了解決這個差距，我們引入了圖形推理結構化問答資料集 (GRS-QA)，其中包含語義脈絡和 QA 對應的推理結構。與現有的 M-QA 資料集不同，其中不同的推理結構糾纏在一起，GRS-QA 透過建構推理圖形明確捕捉複雜的推理路徑，其中節點表示文字脈絡，邊緣表示邏輯流程。這些不同結構的推理圖形能夠細緻地評估 LLM 在各種推理結構中的推理能力。我們的實證分析顯示，LLM 在處理具有不同推理結構的問題時表現不同。這個發現促進了對文字結構與語義的比較探索。

##### **Evaluating the Impact of Lab Test Results on Large Language Models Generated Differential Diagnoses from Clinical Case Vignettes**
2411.02523v1 by Balu Bhasuran, Qiao Jin, Yuzhang Xie, Carl Yang, Karim Hanna, Jennifer Costa, Cindy Shavor, Zhiyong Lu, Zhe He

Differential diagnosis is crucial for medicine as it helps healthcare
providers systematically distinguish between conditions that share similar
symptoms. This study assesses the impact of lab test results on differential
diagnoses (DDx) made by large language models (LLMs). Clinical vignettes from
50 case reports from PubMed Central were created incorporating patient
demographics, symptoms, and lab results. Five LLMs GPT-4, GPT-3.5, Llama-2-70b,
Claude-2, and Mixtral-8x7B were tested to generate Top 10, Top 5, and Top 1 DDx
with and without lab data. A comprehensive evaluation involving GPT-4, a
knowledge graph, and clinicians was conducted. GPT-4 performed best, achieving
55% accuracy for Top 1 diagnoses and 60% for Top 10 with lab data, with lenient
accuracy up to 80%. Lab results significantly improved accuracy, with GPT-4 and
Mixtral excelling, though exact match rates were low. Lab tests, including
liver function, metabolic/toxicology panels, and serology/immune tests, were
generally interpreted correctly by LLMs for differential diagnosis.

摘要：鑑別診斷對於醫學至關重要，因為它有助於醫療保健提供者系統區分具有相似症狀的疾病。這項研究評估了實驗室檢驗結果對大型語言模型 (LLM) 做出的鑑別診斷 (DDx) 的影響。從 PubMed Central 的 50 份病例報告中建立了臨床簡報，其中包含患者人口統計、症狀和實驗室結果。測試了五個 LLM GPT-4、GPT-3.5、Llama-2-70b、Claude-2 和 Mixtral-8x7B，以生成帶和不帶實驗室數據的前 10、前 5 和前 1 DDx。進行了一項涉及 GPT-4、知識圖譜和臨床醫生的綜合評估。GPT-4 表現最佳，在有實驗室數據的情況下，前 1 名診斷的準確率達到 55%，前 10 名的準確率達到 60%，寬鬆準確率高達 80%。實驗室結果顯著提高了準確率，GPT-4 和 Mixtral 表現出色，儘管完全匹配率較低。LLM 通常可以正確解釋包括肝功能、代謝/毒理學檢查和血清學/免疫測試在內的實驗室檢驗，以進行鑑別診斷。

##### **Compositional Automata Embeddings for Goal-Conditioned Reinforcement Learning**
2411.00205v1 by Beyazit Yalcinkaya, Niklas Lauffer, Marcell Vazquez-Chanlatte, Sanjit A. Seshia

Goal-conditioned reinforcement learning is a powerful way to control an AI
agent's behavior at runtime. That said, popular goal representations, e.g.,
target states or natural language, are either limited to Markovian tasks or
rely on ambiguous task semantics. We propose representing temporal goals using
compositions of deterministic finite automata (cDFAs) and use cDFAs to guide RL
agents. cDFAs balance the need for formal temporal semantics with ease of
interpretation: if one can understand a flow chart, one can understand a cDFA.
On the other hand, cDFAs form a countably infinite concept class with Boolean
semantics, and subtle changes to the automaton can result in very different
tasks, making them difficult to condition agent behavior on. To address this,
we observe that all paths through a DFA correspond to a series of reach-avoid
tasks and propose pre-training graph neural network embeddings on "reach-avoid
derived" DFAs. Through empirical evaluation, we demonstrate that the proposed
pre-training method enables zero-shot generalization to various cDFA task
classes and accelerated policy specialization without the myopic suboptimality
of hierarchical methods.

摘要：目標條件強化學習是一種在執行階段控制 AI 代理行為的強大方法。話雖如此，熱門的目標表示，例如目標狀態或自然語言，僅限於馬可夫任務或依賴於含糊不清的任務語義。我們建議使用確定性有限狀態自動機 (cDFA) 的組合來表示時間目標，並使用 cDFA 來指導 RL 代理。cDFA 平衡了對形式時間語義的需求與易於解釋之間的關係：如果一個人能理解流程圖，那麼他就能理解 cDFA。另一方面，cDFA 形成了一個具有布林語義的可數無限概念類，而對自動機的細微更改可能會導致非常不同的任務，這使得它們難以對代理行為進行條件化。為了解決這個問題，我們觀察到通過 DFA 的所有路徑都對應於一系列到達避免任務，並提出對「到達避免衍生」DFA 進行預訓練圖神經網路嵌入。通過經驗評估，我們證明了所提出的預訓練方法能夠對各種 cDFA 任務類別進行零次學習泛化，並加速策略專業化，而沒有分層方法的近視次優性。

##### **Building Multi-Agent Copilot towards Autonomous Agricultural Data Management and Analysis**
2411.00188v1 by Yu Pan, Jianxin Sun, Hongfeng Yu, Joe Luck, Geng Bai, Nipuna Chamara, Yufeng Ge, Tala Awada

Current agricultural data management and analysis paradigms are to large
extent traditional, in which data collecting, curating, integration, loading,
storing, sharing and analyzing still involve too much human effort and
know-how. The experts, researchers and the farm operators need to understand
the data and the whole process of data management pipeline to make fully use of
the data. The essential problem of the traditional paradigm is the lack of a
layer of orchestrational intelligence which can understand, organize and
coordinate the data processing utilities to maximize data management and
analysis outcome. The emerging reasoning and tool mastering abilities of large
language models (LLM) make it a potentially good fit to this position, which
helps a shift from the traditional user-driven paradigm to AI-driven paradigm.
In this paper, we propose and explore the idea of a LLM based copilot for
autonomous agricultural data management and analysis. Based on our previously
developed platform of Agricultural Data Management and Analytics (ADMA), we
build a proof-of-concept multi-agent system called ADMA Copilot, which can
understand user's intent, makes plans for data processing pipeline and
accomplishes tasks automatically, in which three agents: a LLM based
controller, an input formatter and an output formatter collaborate together.
Different from existing LLM based solutions, by defining a meta-program graph,
our work decouples control flow and data flow to enhance the predictability of
the behaviour of the agents. Experiments demonstrates the intelligence,
autonomy, efficacy, efficiency, extensibility, flexibility and privacy of our
system. Comparison is also made between ours and existing systems to show the
superiority and potential of our system.

摘要：<paragraph>目前的農業資料管理與分析模式在很大程度上仍是傳統的，其中資料收集、整理、整合、載入、儲存、分享和分析仍然需要太多的人力與專業知識。專家、研究人員和農場經營者需要了解資料和整個資料管理流程，才能充分利用資料。傳統模式的基本問題是缺乏一層編排智能，無法理解、組織和協調資料處理工具，以最大化資料管理和分析成果。大型語言模型 (LLM) 新興的推理和工具掌握能力使其潛在適合這個職位，這有助於從傳統的使用者驅動模式轉變為 AI 驅動模式。在本文中，我們提出並探討了基於 LLM 的副駕駛的想法，用於自動化農業資料管理和分析。基於我們先前開發的農業資料管理和分析 (ADMA) 平台，我們建立了一個名為 ADMA Copilot 的概念驗證多代理系統，它可以理解使用者的意圖、規劃資料處理流程並自動完成任務，其中三個代理：基於 LLM 的控制器、輸入格式化程式和輸出格式化程式共同合作。與現有的基於 LLM 的解決方案不同，透過定義元程式圖，我們的研究將控制流程和資料流程解耦，以增強代理行為的可預測性。實驗證明了我們系統的智慧、自主性、效能、效率、可擴充性、靈活性與隱私性。我們也與現有系統進行比較，以顯示我們系統的優越性和潛力。</paragraph>

##### **Exploring the Knowledge Mismatch Hypothesis: Hallucination Propensity in Small Models Fine-tuned on Data from Larger Models**
2411.00878v1 by Phil Wee, Riyadh Baghdadi

Recently, there has been an explosion of large language models created
through fine-tuning with data from larger models. These small models able to
produce outputs that appear qualitatively similar to significantly larger
models. However, one of the key limitations that have been observed with these
models is their propensity to hallucinate significantly more often than larger
models. In particular, they have been observed to generate coherent outputs
that involve factually incorrect information and spread misinformation,
toxicity, and stereotypes. There are many potential causes of hallucination, of
which, one hypothesis is that fine-tuning a model on data produced by a larger
model leads to a knowledge mismatch which contributes to hallucination. In
particular, it is hypothesized that there is a mismatch between the knowledge
that is fed to the model to fine-tune it and the knowledge that is already
present in the graph. Fine-tuning the model on data that has such mismatch
could contribute to an increased propensity to hallucinate. We show that on an
unseen test set, a smaller model fine-tuned on data generated from a larger
model produced more wrong answers when compared to models fine-tuned on data
created by the small model, which confirms the hypothesis.

摘要：最近，通过使用更大模型的数据进行微调，创建了大量语言模型爆炸。这些小模型能够产生与明显更大的模型在质量上类似的输出。然而，在这些模型中观察到的一个关键限制是，它们比更大的模型更容易出现幻觉。特别是，已经观察到它们会生成涉及事实不正确的信息并传播错误信息、毒性和刻板印象的连贯输出。幻觉有很多潜在原因，其中一个假设是，在更大模型生成的数据上微调模型会导致知识不匹配，从而导致幻觉。特别是，假设模型微调所馈送的知识与图中已有的知识之间存在不匹配。在具有这种不匹配的数据上微调模型可能会导致幻觉倾向增加。我们表明，在一个看不见的测试集中，一个在从一个更大的模型生成的数据上微调的小模型，与在小模型创建的数据上微调的模型相比，产生了更多错误的答案，这证实了这一假设。

##### **Failure Modes of LLMs for Causal Reasoning on Narratives**
2410.23884v1 by Khurram Yamin, Shantanu Gupta, Gaurav R. Ghosal, Zachary C. Lipton, Bryan Wilder

In this work, we investigate the causal reasoning abilities of large language
models (LLMs) through the representative problem of inferring causal
relationships from narratives. We find that even state-of-the-art language
models rely on unreliable shortcuts, both in terms of the narrative
presentation and their parametric knowledge. For example, LLMs tend to
determine causal relationships based on the topological ordering of events
(i.e., earlier events cause later ones), resulting in lower performance
whenever events are not narrated in their exact causal order. Similarly, we
demonstrate that LLMs struggle with long-term causal reasoning and often fail
when the narratives are long and contain many events. Additionally, we show
LLMs appear to rely heavily on their parametric knowledge at the expense of
reasoning over the provided narrative. This degrades their abilities whenever
the narrative opposes parametric knowledge. We extensively validate these
failure modes through carefully controlled synthetic experiments, as well as
evaluations on real-world narratives. Finally, we observe that explicitly
generating a causal graph generally improves performance while naive
chain-of-thought is ineffective. Collectively, our results distill precise
failure modes of current state-of-the-art models and can pave the way for
future techniques to enhance causal reasoning in LLMs.

摘要：在這項工作中，我們透過推論敘述中的因果關係這個代表性問題，來探討大型語言模型 (LLM) 的因果推理能力。我們發現，即使是最先進的語言模型，也會依賴於不可靠的捷徑，無論是在敘述呈現或其參數知識方面。例如，LLM 傾向於根據事件的拓撲順序（即，較早的事件導致較晚的事件）來確定因果關係，當事件未按其確切的因果順序敘述時，就會導致較低的效能。同樣地，我們證明 LLM 難以進行長期因果推理，並且當敘述很長且包含許多事件時，它們通常會失敗。此外，我們表明 LLM 似乎過度依賴其參數知識，而犧牲了對所提供敘述的推理。每當敘述與參數知識相衝突時，這就會降低它們的能力。我們透過仔細控制的合成實驗以及對真實世界敘述的評估，廣泛驗證了這些失敗模式。最後，我們觀察到，明確產生因果圖通常會改善效能，而天真的思考鏈則無效。總的來說，我們的結果精確地提煉了當前最先進模型的失敗模式，並可以為未來增強 LLM 中因果推理的技術鋪路。

##### **Plan-on-Graph: Self-Correcting Adaptive Planning of Large Language Model on Knowledge Graphs**
2410.23875v1 by Liyi Chen, Panrong Tong, Zhongming Jin, Ying Sun, Jieping Ye, Hui Xiong

Large Language Models (LLMs) have shown remarkable reasoning capabilities on
complex tasks, but they still suffer from out-of-date knowledge,
hallucinations, and opaque decision-making. In contrast, Knowledge Graphs (KGs)
can provide explicit and editable knowledge for LLMs to alleviate these issues.
Existing paradigm of KG-augmented LLM manually predefines the breadth of
exploration space and requires flawless navigation in KGs. However, this
paradigm cannot adaptively explore reasoning paths in KGs based on the question
semantics and self-correct erroneous reasoning paths, resulting in a bottleneck
in efficiency and effect. To address these limitations, we propose a novel
self-correcting adaptive planning paradigm for KG-augmented LLM named
Plan-on-Graph (PoG), which first decomposes the question into several
sub-objectives and then repeats the process of adaptively exploring reasoning
paths, updating memory, and reflecting on the need to self-correct erroneous
reasoning paths until arriving at the answer. Specifically, three important
mechanisms of Guidance, Memory, and Reflection are designed to work together,
to guarantee the adaptive breadth of self-correcting planning for graph
reasoning. Finally, extensive experiments on three real-world datasets
demonstrate the effectiveness and efficiency of PoG.

摘要：大型語言模型 (LLM) 在複雜任務中展現出非凡的推理能力，但仍存在知識過時、幻覺和決策不透明的問題。相反地，知識圖譜 (KG) 可以提供明確且可編輯的知識，供 LLM 緩解這些問題。現有的 KG 增強 LLM 典範手動預先定義探索空間的廣度，並需要在 KG 中完美導航。然而，此典範無法根據問題語意自適應地探索 KG 中的推理路徑，並自行糾正錯誤的推理路徑，導致效率和效果的瓶頸。為了解決這些限制，我們提出了一個名為圖形計畫 (PoG) 的 KG 增強 LLM 的新穎自修正自適應規劃典範，它首先將問題分解成幾個子目標，然後重複自適應探索推理路徑、更新記憶體和反思需要自行糾正錯誤推理路徑的過程，直到得出答案。具體來說，指導、記憶和反思這三個重要機制被設計為協同運作，以保證自修正規劃在圖形推理中的自適應廣度。最後，在三個真實世界資料集上的廣泛實驗證明了 PoG 的有效性和效率。

##### **LLaMo: Large Language Model-based Molecular Graph Assistant**
2411.00871v1 by Jinyoung Park, Minseong Bae, Dohwan Ko, Hyunwoo J. Kim

Large Language Models (LLMs) have demonstrated remarkable generalization and
instruction-following capabilities with instruction tuning. The advancements in
LLMs and instruction tuning have led to the development of Large
Vision-Language Models (LVLMs). However, the competency of the LLMs and
instruction tuning have been less explored in the molecular domain. Thus, we
propose LLaMo: Large Language Model-based Molecular graph assistant, which is
an end-to-end trained large molecular graph-language model. To bridge the
discrepancy between the language and graph modalities, we present the
multi-level graph projector that transforms graph representations into graph
tokens by abstracting the output representations of each GNN layer and motif
representations with the cross-attention mechanism. We also introduce
machine-generated molecular graph instruction data to instruction-tune the
large molecular graph-language model for general-purpose molecule and language
understanding. Our extensive experiments demonstrate that LLaMo shows the best
performance on diverse tasks, such as molecular description generation,
property prediction, and IUPAC name prediction. The code of LLaMo is available
at https://github.com/mlvlab/LLaMo.

摘要：大型语言模型 (LLM) 已展示出卓越的概括和指令遵循能力，并进行指令调整。LLM 和指令调整的进步导致了大型视觉语言模型 (LVLMs) 的发展。然而，LLM 和指令调整的能力在分子领域的研究较少。因此，我们提出了 LLaMo：基于大语言模型的分子图助手，这是一个端到端训练的大分子图语言模型。为了弥合语言和图模式之间的差异，我们提出了多级图投影仪，它通过抽象每个 GNN 层的输出表示和基序表示（使用交叉注意力机制）将图表示转换为图标记。我们还引入了机器生成的分子图指令数据，以对大型分子图语言模型进行指令调整，以用于通用分子和语言理解。我们广泛的实验表明，LLaMo 在分子描述生成、属性预测和 IUPAC 名称预测等不同任务上表现出最佳性能。LLaMo 的代码可在 https://github.com/mlvlab/LLaMo 获得。

##### **End-to-End Ontology Learning with Large Language Models**
2410.23584v1 by Andy Lo, Albert Q. Jiang, Wenda Li, Mateja Jamnik

Ontologies are useful for automatic machine processing of domain knowledge as
they represent it in a structured format. Yet, constructing ontologies requires
substantial manual effort. To automate part of this process, large language
models (LLMs) have been applied to solve various subtasks of ontology learning.
However, this partial ontology learning does not capture the interactions
between subtasks. We address this gap by introducing OLLM, a general and
scalable method for building the taxonomic backbone of an ontology from
scratch. Rather than focusing on subtasks, like individual relations between
entities, we model entire subcomponents of the target ontology by finetuning an
LLM with a custom regulariser that reduces overfitting on high-frequency
concepts. We introduce a novel suite of metrics for evaluating the quality of
the generated ontology by measuring its semantic and structural similarity to
the ground truth. In contrast to standard metrics, our metrics use deep
learning techniques to define more robust distance measures between graphs.
Both our quantitative and qualitative results on Wikipedia show that OLLM
outperforms subtask composition methods, producing more semantically accurate
ontologies while maintaining structural integrity. We further demonstrate that
our model can be effectively adapted to new domains, like arXiv, needing only a
small number of training examples. Our source code and datasets are available
at https://github.com/andylolu2/ollm.

摘要：本体对于领域知识的自动机器处理很有用，因为它们以结构化格式表示知识。然而，构建本体需要大量的手动工作。为了自动化这个过程的一部分，大型语言模型（LLM）已被应用于解决本体学习的各种子任务。然而，这种部分本体学习并没有捕捉到子任务之间的交互。我们通过引入 OLLM 来解决这一差距，这是一种从头开始构建本体分类骨架的通用且可扩展的方法。我们没有专注于子任务，例如实体之间的个别关系，而是通过使用自定义正则化器微调 LLM 来对目标本体的整个子组件进行建模，该正则化器减少了对高频概念的过度拟合。我们引入了一套新的指标来评估生成本体的质量，方法是测量它与地面真实值的语义和结构相似性。与标准指标相反，我们的指标使用深度学习技术来定义图之间的更稳健的距离度量。我们在维基百科上的定量和定性结果表明，OLLM 优于子任务组合方法，在保持结构完整性的同时生成语义上更准确的本体。我们进一步证明，我们的模型可以有效地适应新的领域，如 arXiv，只需要少量的训练样本。我们的源代码和数据集可在 https://github.com/andylolu2/ollm 获得。

##### **Graph-Augmented Relation Extraction Model with LLMs-Generated Support Document**
2410.23452v1 by Vicky Dong, Hao Yu, Yao Chen

This study introduces a novel approach to sentence-level relation extraction
(RE) that integrates Graph Neural Networks (GNNs) with Large Language Models
(LLMs) to generate contextually enriched support documents. By harnessing the
power of LLMs to generate auxiliary information, our approach crafts an
intricate graph representation of textual data. This graph is subsequently
processed through a Graph Neural Network (GNN) to refine and enrich the
embeddings associated with each entity ensuring a more nuanced and
interconnected understanding of the data. This methodology addresses the
limitations of traditional sentence-level RE models by incorporating broader
contexts and leveraging inter-entity interactions, thereby improving the
model's ability to capture complex relationships across sentences. Our
experiments, conducted on the CrossRE dataset, demonstrate the effectiveness of
our approach, with notable improvements in performance across various domains.
The results underscore the potential of combining GNNs with LLM-generated
context to advance the field of relation extraction.

摘要：本研究提出了一個句子層級關係萃取 (RE) 的新方法，該方法整合了圖形神經網路 (GNN) 和大型語言模型 (LLM)，以產生脈絡豐富的支援文件。透過利用 LLM 的功能來產生輔助資訊，我們的做法建立了一個文本資料的複雜圖形表示。此圖形隨後透過圖形神經網路 (GNN) 進行處理，以改善和豐富與每個實體相關的嵌入，確保對資料有更細緻且相互連結的理解。此方法透過納入更廣泛的脈絡並利用實體間互動，來解決傳統句子層級 RE 模型的限制，進而提升模型捕捉跨句子的複雜關係的能力。我們在 CrossRE 資料集上執行的實驗證明了我們方法的有效性，在各種領域的效能都有顯著的提升。這些結果強調了將 GNN 與 LLM 產生的脈絡相結合，以推進關係萃取領域的潛力。

##### **FlowLLM: Flow Matching for Material Generation with Large Language Models as Base Distributions**
2410.23405v1 by Anuroop Sriram, Benjamin Kurt Miller, Ricky T. Q. Chen, Brandon M. Wood

Material discovery is a critical area of research with the potential to
revolutionize various fields, including carbon capture, renewable energy, and
electronics. However, the immense scale of the chemical space makes it
challenging to explore all possible materials experimentally. In this paper, we
introduce FlowLLM, a novel generative model that combines large language models
(LLMs) and Riemannian flow matching (RFM) to design novel crystalline
materials. FlowLLM first fine-tunes an LLM to learn an effective base
distribution of meta-stable crystals in a text representation. After converting
to a graph representation, the RFM model takes samples from the LLM and
iteratively refines the coordinates and lattice parameters. Our approach
significantly outperforms state-of-the-art methods, increasing the generation
rate of stable materials by over three times and increasing the rate for
stable, unique, and novel crystals by $\sim50\%$ - a huge improvement on a
difficult problem. Additionally, the crystals generated by FlowLLM are much
closer to their relaxed state when compared with another leading model,
significantly reducing post-hoc computational cost.

摘要：材料發現是一個重要的研究領域，具有革新各種領域的潛力，包括碳捕集、可再生能源和電子產品。然而，化學空間的巨大規模使得實驗探索所有可能的材料具有挑戰性。在本文中，我們介紹了 FlowLLM，這是一種新穎的生成模型，結合了大型語言模型 (LLM) 和黎曼流匹配 (RFM) 來設計新型晶體材料。FlowLLM 首先微調 LLM，以學習文本表示中亞穩態晶體的有效基礎分佈。在轉換為圖形表示後，RFM 模型從 LLM 中獲取樣本，並反覆精煉坐標和晶格參數。我們的做法顯著優於最先進的方法，將穩定材料的生成率提高了三倍以上，並將穩定、獨特和新穎晶體的生成率提高了約 50%——這在一個困難的問題上是一個巨大的改進。此外，與另一種領先模型相比，FlowLLM 生成的晶體更接近其鬆弛狀態，顯著降低了事後計算成本。

##### **EMMA: End-to-End Multimodal Model for Autonomous Driving**
2410.23262v2 by Jyh-Jing Hwang, Runsheng Xu, Hubert Lin, Wei-Chih Hung, Jingwei Ji, Kristy Choi, Di Huang, Tong He, Paul Covington, Benjamin Sapp, Yin Zhou, James Guo, Dragomir Anguelov, Mingxing Tan

We introduce EMMA, an End-to-end Multimodal Model for Autonomous driving.
Built on a multi-modal large language model foundation, EMMA directly maps raw
camera sensor data into various driving-specific outputs, including planner
trajectories, perception objects, and road graph elements. EMMA maximizes the
utility of world knowledge from the pre-trained large language models, by
representing all non-sensor inputs (e.g. navigation instructions and ego
vehicle status) and outputs (e.g. trajectories and 3D locations) as natural
language text. This approach allows EMMA to jointly process various driving
tasks in a unified language space, and generate the outputs for each task using
task-specific prompts. Empirically, we demonstrate EMMA's effectiveness by
achieving state-of-the-art performance in motion planning on nuScenes as well
as competitive results on the Waymo Open Motion Dataset (WOMD). EMMA also
yields competitive results for camera-primary 3D object detection on the Waymo
Open Dataset (WOD). We show that co-training EMMA with planner trajectories,
object detection, and road graph tasks yields improvements across all three
domains, highlighting EMMA's potential as a generalist model for autonomous
driving applications. However, EMMA also exhibits certain limitations: it can
process only a small amount of image frames, does not incorporate accurate 3D
sensing modalities like LiDAR or radar and is computationally expensive. We
hope that our results will inspire further research to mitigate these issues
and to further evolve the state of the art in autonomous driving model
architectures.

摘要：<paragraph>我們介紹 EMMA，一種用於自動駕駛的端到端多模態模型。
建立在多模態大型語言模型基礎上，EMMA 直接將原始
相機感測器資料對應到各種特定於駕駛的輸出，包括規劃器
軌跡、感知物件和道路圖形元素。EMMA 最大化利用預訓練大型語言模型中的世界知識，方法是
將所有非感測器輸入（例如導航指示和自我
車輛狀態）和輸出（例如軌跡和 3D 位置）表示為自然
語言文字。這種方法允許 EMMA 在統一的語言空間中共同處理各種駕駛
任務，並使用特定於任務的提示為每個任務產生輸出。
根據經驗，我們證明了 EMMA 的有效性，在 nuScenes 上的運動規劃中達到了最先進的性能，以及
在 Waymo 開放運動資料集 (WOMD) 上取得了有競爭力的結果。EMMA 也
在 Waymo 開放資料集 (WOD) 上對相機優先的 3D 物件偵測產生了有競爭力的結果。我們展示了使用規劃器軌跡、
物件偵測和道路圖形任務共同訓練 EMMA 會在所有三個
領域產生改進，突顯了 EMMA 作為自動駕駛應用程式通用模型的潛力。然而，EMMA 也表現出某些限制：它只能
處理少量的影像幀，不包含像 LiDAR 或雷達等準確的 3D 感測模式，並且計算成本昂貴。我們
希望我們的結果能激勵進一步的研究，以減輕這些問題並進一步發展自動駕駛模型
架構的最新技術。</paragraph>

##### **ProTransformer: Robustify Transformers via Plug-and-Play Paradigm**
2410.23182v1 by Zhichao Hou, Weizhi Gao, Yuchen Shen, Feiyi Wang, Xiaorui Liu

Transformer-based architectures have dominated various areas of machine
learning in recent years. In this paper, we introduce a novel robust attention
mechanism designed to enhance the resilience of transformer-based
architectures. Crucially, this technique can be integrated into existing
transformers as a plug-and-play layer, improving their robustness without the
need for additional training or fine-tuning. Through comprehensive experiments
and ablation studies, we demonstrate that our ProTransformer significantly
enhances the robustness of transformer models across a variety of prediction
tasks, attack mechanisms, backbone architectures, and data domains. Notably,
without further fine-tuning, the ProTransformer consistently improves the
performance of vanilla transformers by 19.5%, 28.3%, 16.1%, and 11.4% for BERT,
ALBERT, DistilBERT, and RoBERTa, respectively, under the classical TextFooler
attack. Furthermore, ProTransformer shows promising resilience in large
language models (LLMs) against prompting-based attacks, improving the
performance of T5 and LLaMA by 24.8% and 17.8%, respectively, and enhancing
Vicuna by an average of 10.4% against the Jailbreaking attack. Beyond the
language domain, ProTransformer also demonstrates outstanding robustness in
both vision and graph domains.

摘要：<paragraph>近年來，基於 Transformer 的架構主導了機器學習的各個領域。在本文中，我們介紹了一種新穎且強大的注意力機制，旨在增強基於 Transformer 的架構的韌性。至關重要的是，此技術可以作為即插即用的層整合到現有的 Transformer 中，在無需額外訓練或微調的情況下提高其穩健性。通過全面的實驗和消融研究，我們證明了我們的 ProTransformer 在各種預測任務、攻擊機制、主幹架構和數據領域中顯著增強了 Transformer 模型的穩健性。值得注意的是，在不進一步微調的情況下，ProTransformer 在經典的 TextFooler 攻擊下，分別為 BERT、ALBERT、DistilBERT 和 RoBERTa 提升了 19.5%、28.3%、16.1% 和 11.4% 的性能。此外，ProTransformer 在基於提示的攻擊中對大型語言模型 (LLM) 顯示出有希望的韌性，分別將 T5 和 LLaMA 的性能提升了 24.8% 和 17.8%，並在越獄攻擊中將 Vicuna 的性能平均提升了 10.4%。除了語言領域之外，ProTransformer 在視覺和圖形領域也表現出出色的穩健性。</paragraph>

##### **Semantic Enrichment of the Quantum Cascade Laser Properties in Text- A Knowledge Graph Generation Approach**
2410.22996v1 by Deperias Kerre, Anne Laurent, Kenneth Maussang, Dickson Owuor

A well structured collection of the various Quantum Cascade Laser (QCL)
design and working properties data provides a platform to analyze and
understand the relationships between these properties. By analyzing these
relationships, we can gain insights into how different design features impact
laser performance properties such as the working temperature. Most of these QCL
properties are captured in scientific text. There is therefore need for
efficient methodologies that can be utilized to extract QCL properties from
text and generate a semantically enriched and interlinked platform where the
properties can be analyzed to uncover hidden relations. There is also the need
to maintain provenance and reference information on which these properties are
based. Semantic Web technologies such as Ontologies and Knowledge Graphs have
proven capability in providing interlinked data platforms for knowledge
representation in various domains. In this paper, we propose an approach for
generating a QCL properties Knowledge Graph (KG) from text for semantic
enrichment of the properties. The approach is based on the QCL ontology and a
Retrieval Augmented Generation (RAG) enabled information extraction pipeline
based on GPT 4-Turbo language model. The properties of interest include:
working temperature, laser design type, lasing frequency, laser optical power
and the heterostructure. The experimental results demonstrate the feasibility
and effectiveness of this approach for efficiently extracting QCL properties
from unstructured text and generating a QCL properties Knowledge Graph, which
has potential applications in semantic enrichment and analysis of QCL data.

摘要：一個結構良好的各種量子層疊雷射 (QCL) 設計和工作特性數據集合，提供了一個平台來分析和理解這些特性之間的關係。透過分析這些關係，我們可以深入了解不同的設計特徵如何影響雷射效能特性，例如工作溫度。這些 QCL 特性大多數都捕捉在科學文字中。因此，需要有效的方法，可以用於從文字中萃取 QCL 特性，並產生一個語義豐富且相互連結的平台，可以在其中分析這些特性以發現隱藏的關係。還需要維護這些特性所依據的來源和參考資訊。語義網路技術，例如本体和知識圖譜，已證明它們在提供各種領域中知識表徵的相互連結資料平台方面具有能力。在本文中，我們提出一個從文字中產生 QCL 特性知識圖譜 (KG) 的方法，以進行特性的語義豐富化。此方法基於 QCL 本体和基於 GPT 4-Turbo 語言模型的檢索擴增生成 (RAG) 啟用資訊萃取管線。感興趣的特性包括：工作溫度、雷射設計類型、雷射頻率、雷射光功率和異質結構。實驗結果證明了此方法對於從非結構化文字中有效萃取 QCL 特性和產生 QCL 特性知識圖譜的可行性和有效性，這在 QCL 數據的語義豐富化和分析中具有潛在應用。

##### **How Well Do Large Language Models Disambiguate Swedish Words?**
2410.22827v1 by Richard Johansson

We evaluate a battery of recent large language models on two benchmarks for
word sense disambiguation in Swedish. At present, all current models are less
accurate than the best supervised disambiguators in cases where a training set
is available, but most models outperform graph-based unsupervised systems.
Different prompting approaches are compared, with a focus on how to express the
set of possible senses in a given context. The best accuracies are achieved
when human-written definitions of the senses are included in the prompts.

摘要：我們針對兩個瑞典語詞彙意義消歧基準，評估一系列近期的大型語言模型。目前，在有訓練集可用的情況下，所有現有模型的準確度都低於最佳監督式消歧器，但大多數模型的表現都優於基於圖形的非監督式系統。比較了不同的提示方法，重點在於如何在特定脈絡中表達可能的意義集合。當提示中包含人類撰寫的意義定義時，可達到最佳準確度。

##### **Beyond Ontology in Dialogue State Tracking for Goal-Oriented Chatbot**
2410.22767v1 by Sejin Lee, Dongha Kim, Min Song

Goal-oriented chatbots are essential for automating user tasks, such as
booking flights or making restaurant reservations. A key component of these
systems is Dialogue State Tracking (DST), which interprets user intent and
maintains the dialogue state. However, existing DST methods often rely on fixed
ontologies and manually compiled slot values, limiting their adaptability to
open-domain dialogues. We propose a novel approach that leverages instruction
tuning and advanced prompt strategies to enhance DST performance, without
relying on any predefined ontologies. Our method enables Large Language Model
(LLM) to infer dialogue states through carefully designed prompts and includes
an anti-hallucination mechanism to ensure accurate tracking in diverse
conversation contexts. Additionally, we employ a Variational Graph Auto-Encoder
(VGAE) to model and predict subsequent user intent. Our approach achieved
state-of-the-art with a JGA of 42.57% outperforming existing ontology-less DST
models, and performed well in open-domain real-world conversations. This work
presents a significant advancement in creating more adaptive and accurate
goal-oriented chatbots.

摘要：以目標為導向的聊天機器人在自動化使用者任務中至關重要，例如預訂航班或進行餐廳訂位。這些系統的一個關鍵組成部分是對話狀態追蹤 (DST)，它會解譯使用者的意圖並維護對話狀態。然而，現有的 DST 方法通常依賴於固定的本体和手動編譯的槽位值，這限制了它們對開放領域對話的適應性。我們提出了一種新穎的方法，它利用指令調整和先進的提示策略來增強 DST 效能，而無需依賴任何預定義的本体。我們的方法使大型語言模型 (LLM) 能夠透過精心設計的提示來推論對話狀態，並包含一個反幻覺機制，以確保在不同的對話情境中準確追蹤。此外，我們採用變分圖自編碼器 (VGAE) 來建模和預測後續使用者的意圖。我們的做法以 42.57% 的 JGA 達到了現有技術的頂峰，優於現有的無本体 DST 模型，並在開放領域的真實對話中表現良好。這項工作在建立更具適應性和準確性的以目標為導向的聊天機器人方面取得了重大進展。

##### **The Graph's Apprentice: Teaching an LLM Low Level Knowledge for Circuit Quality Estimation**
2411.00843v1 by Reza Moravej, Saurabh Bodhe, Zhanguang Zhang, Didier Chetelat, Dimitrios Tsaras, Yingxue Zhang, Hui-Ling Zhen, Jianye Hao, Mingxuan Yuan

Logic synthesis is a crucial phase in the circuit design process, responsible
for transforming hardware description language (HDL) designs into optimized
netlists. However, traditional logic synthesis methods are computationally
intensive, restricting their iterative use in refining chip designs. Recent
advancements in large language models (LLMs), particularly those fine-tuned on
programming languages, present a promising alternative. In this paper, we
introduce VeriDistill, the first end-to-end machine learning model that
directly processes raw Verilog code to predict circuit quality-of-result
metrics. Our model employs a novel knowledge distillation method, transferring
low-level circuit insights via graphs into the predictor based on LLM.
Experiments show VeriDistill outperforms state-of-the-art baselines on
large-scale Verilog datasets and demonstrates robust performance when evaluated
on out-of-distribution datasets.

摘要：邏輯合成是電路設計過程中至關重要的一個階段，負責將硬體描述語言 (HDL) 設計轉換為最佳化的網路表。然而，傳統的邏輯合成方法在運算上很密集，限制了它們在精煉晶片設計中的反覆使用。最近大型語言模型 (LLM) 的進展，特別是那些經過程式語言微調的，提供了一個有希望的替代方案。在本文中，我們介紹了 VeriDistill，第一個端到端的機器學習模型，它直接處理原始 Verilog 程式碼以預測電路品質結果指標。我們的模型採用了一種新穎的知識提煉方法，通過圖表將低階電路見解傳輸到基於 LLM 的預測器中。實驗表明，VeriDistill 在大規模 Verilog 資料集上優於最先進的基準，並且在在分佈外資料集上進行評估時表現出穩健的效能。

##### **Are Large-Language Models Graph Algorithmic Reasoners?**
2410.22597v1 by Alexander K Taylor, Anthony Cuturrufo, Vishal Yathish, Mingyu Derek Ma, Wei Wang

We seek to address a core challenge facing current Large Language Models
(LLMs). LLMs have demonstrated superior performance in many tasks, yet continue
to struggle with reasoning problems on explicit graphs that require multiple
steps. To address this gap, we introduce a novel benchmark designed to evaluate
LLM performance on classical algorithmic reasoning tasks on explicit graphs.
Our benchmark encompasses five fundamental algorithms: Breadth-First Search
(BFS) and Depth-First Search (DFS) for connectivity, Dijkstra's algorithm and
Floyd-Warshall algorithm for all nodes shortest path, and Prim's Minimum
Spanning Tree (MST-Prim's) algorithm. Through extensive experimentation, we
assess the capabilities of state-of-the-art LLMs in executing these algorithms
step-by-step and systematically evaluate their performance at each stage. Our
findings highlight the persistent challenges LLMs face in this domain and
underscore the necessity for advanced prompting techniques and algorithmic
instruction to enhance their graph reasoning abilities. This work presents
MAGMA, the first comprehensive benchmark focused on LLMs completing classical
graph algorithms, and provides a critical step toward understanding and
improving their structured problem-solving skills.

摘要：我們試圖解決當前大型語言模型 (LLM) 面臨的核心挑戰。LLM 在許多任務中表現出優異的性能，但仍難以應對需要多個步驟的明確圖表中的推理問題。為了解決這個差距，我們引入了一個新的基準，用於評估 LLM 在明確圖表上的經典演算法推理任務上的性能。我們的基準包含五個基本演算法：廣度優先搜尋 (BFS) 和深度優先搜尋 (DFS) 以進行連通性、Dijkstra 演算法和 Floyd-Warshall 演算法以找出所有節點的最短路徑，以及 Prim 最小生成樹 (MST-Prim) 演算法。透過廣泛的實驗，我們評估了最先進的 LLM 在逐步執行這些演算法的能力，並系統性地評估它們在每個階段的性能。我們的研究結果突出了 LLM 在這個領域面臨的持續挑戰，並強調了使用進階提示技術和演算法指令來增強其圖形推理能力的必要性。這項工作提出了 MAGMA，這是第一個專注於 LLM 完成經典圖形演算法的綜合基準，並為了解和改進其結構化問題解決技能提供了關鍵的一步。

##### **Advancing Agentic Systems: Dynamic Task Decomposition, Tool Integration and Evaluation using Novel Metrics and Dataset**
2410.22457v1 by Adrian Garret Gabriel, Alaa Alameer Ahmad, Shankar Kumar Jeyakumar

Advancements in Large Language Models (LLMs) are revolutionizing the
development of autonomous agentic systems by enabling dynamic, context-aware
task decomposition and automated tool selection. These sophisticated systems
possess significant automation potential across various industries, managing
complex tasks, interacting with external systems to enhance knowledge, and
executing actions independently. This paper presents three primary
contributions to advance this field:
  - Advanced Agentic Framework: A system that handles multi-hop queries,
generates and executes task graphs, selects appropriate tools, and adapts to
real-time changes.
  - Novel Evaluation Metrics: Introduction of Node F1 Score, Structural
Similarity Index (SSI), and Tool F1 Score to comprehensively assess agentic
systems.
  - Specialized Dataset: Development of an AsyncHow-based dataset for analyzing
agent behavior across different task complexities.
  Our findings reveal that asynchronous and dynamic task graph decomposition
significantly enhances system responsiveness and scalability, particularly for
complex, multi-step tasks. Detailed analysis shows that structural and
node-level metrics are crucial for sequential tasks, while tool-related metrics
are more important for parallel tasks. Specifically, the Structural Similarity
Index (SSI) is the most significant predictor of performance in sequential
tasks, and the Tool F1 Score is essential for parallel tasks. These insights
highlight the need for balanced evaluation methods that capture both structural
and operational dimensions of agentic systems. Additionally, our evaluation
framework, validated through empirical analysis and statistical testing,
provides valuable insights for improving the adaptability and reliability of
agentic systems in dynamic environments.

摘要：大型語言模型 (LLM) 的進展正透過啟用動態、具情境感知能力的任務分解和自動化工具選擇，革新自主代理系統的開發。這些精密的系統在各產業中擁有顯著的自動化潛力，管理複雜的任務、與外部系統互動以增強知識，並獨立執行動作。本文提出了三個主要貢獻以推動這個領域的進展：
  - 進階代理架構：一種處理多重跳躍查詢、產生並執行任務圖表、選擇適當的工具，並適應即時變化的系統。
  - 新穎的評估指標：導入節點 F1 分數、結構相似性指標 (SSI) 和工具 F1 分數，以全面評估代理系統。
  - 專業資料集：開發一個基於 AsyncHow 的資料集，用於分析代理行為在不同任務複雜度之間的差異。
  我們的研究結果顯示，非同步和動態任務圖表分解能顯著增強系統的回應能力和可擴充性，特別是對於複雜的多步驟任務。詳細的分析顯示，結構和節點層級的指標對於順序任務至關重要，而與工具相關的指標對於並行任務更為重要。具體來說，結構相似性指標 (SSI) 是順序任務中效能最顯著的預測指標，而工具 F1 分數對於並行任務至關重要。這些見解突顯了平衡評估方法的需求，該方法能捕捉代理系統的結構和操作面向。此外，我們的評估架構透過實證分析和統計檢定驗證，為改善代理系統在動態環境中的適應性和可靠性提供了有價值的見解。

##### **DynaMath: A Dynamic Visual Benchmark for Evaluating Mathematical Reasoning Robustness of Vision Language Models**
2411.00836v1 by Chengke Zou, Xingang Guo, Rui Yang, Junyu Zhang, Bin Hu, Huan Zhang

The rapid advancements in Vision-Language Models (VLMs) have shown great
potential in tackling mathematical reasoning tasks that involve visual context.
Unlike humans who can reliably apply solution steps to similar problems with
minor modifications, we found that SOTA VLMs like GPT-4o can consistently fail
in these scenarios, revealing limitations in their mathematical reasoning
capabilities. In this paper, we investigate the mathematical reasoning
robustness in VLMs and evaluate how well these models perform under different
variants of the same question, such as changes in visual numerical values or
function graphs. While several vision-based math benchmarks have been developed
to assess VLMs' problem-solving capabilities, these benchmarks contain only
static sets of problems and cannot easily evaluate mathematical reasoning
robustness. To fill this gap, we introduce DynaMath, a dynamic visual math
benchmark designed for in-depth assessment of VLMs. DynaMath includes 501
high-quality, multi-topic seed questions, each represented as a Python program.
Those programs are carefully designed and annotated to enable the automatic
generation of a much larger set of concrete questions, including many different
types of visual and textual variations. DynaMath allows us to evaluate the
generalization ability of VLMs, by assessing their performance under varying
input conditions of a seed question. We evaluated 14 SOTA VLMs with 5,010
generated concrete questions. Our results show that the worst-case model
accuracy, defined as the percentage of correctly answered seed questions in all
10 variants, is significantly lower than the average-case accuracy. Our
analysis emphasizes the need to study the robustness of VLMs' reasoning
abilities, and DynaMath provides valuable insights to guide the development of
more reliable models for mathematical reasoning.

摘要：<paragraph>視覺語言模型 (VLM) 的快速進步在解決涉及視覺背景的數學推理任務方面展現了巨大的潛力。與人類可以將解決步驟可靠地應用於類似問題（並進行微小的修改）不同，我們發現像 GPT-4o 等 SOTA VLM 在這些場景中可能會持續失敗，揭露了其數學推理能力的限制。在本文中，我們研究了 VLM 中的數學推理穩健性，並評估了這些模型在同一問題的不同變體（例如視覺數值或函數圖形的變化）下的表現。雖然已經開發了多個基於視覺的數學基準來評估 VLM 的問題解決能力，但這些基準只包含靜態問題集，無法輕鬆評估數學推理穩健性。為了填補這一空白，我們引入了 DynaMath，這是一個動態視覺數學基準，專門用於深入評估 VLM。DynaMath 包含 501 個高品質、多主題種子問題，每個問題都表示為一個 Python 程式。這些程式經過仔細設計和註解，以便自動產生一組更大的具體問題，包括許多不同類型的視覺和文字變體。DynaMath 允許我們評估 VLM 的泛化能力，方法是在種子問題的不同輸入條件下評估其表現。我們使用 5,010 個生成的具體問題評估了 14 個 SOTA VLM。我們的結果顯示，最差情況的模型準確度（定義為在所有 10 個變體中正確回答的種子問題的百分比）顯著低於平均情況準確度。我們的分析強調了研究 VLM 推理能力穩健性的必要性，而 DynaMath 提供了有價值的見解，以指導開發更可靠的數學推理模型。</paragraph>

##### **ADAM: An Embodied Causal Agent in Open-World Environments**
2410.22194v1 by Shu Yu, Chaochao Lu

In open-world environments like Minecraft, existing agents face challenges in
continuously learning structured knowledge, particularly causality. These
challenges stem from the opacity inherent in black-box models and an excessive
reliance on prior knowledge during training, which impair their
interpretability and generalization capability. To this end, we introduce ADAM,
An emboDied causal Agent in Minecraft, that can autonomously navigate the open
world, perceive multimodal contexts, learn causal world knowledge, and tackle
complex tasks through lifelong learning. ADAM is empowered by four key
components: 1) an interaction module, enabling the agent to execute actions
while documenting the interaction processes; 2) a causal model module, tasked
with constructing an ever-growing causal graph from scratch, which enhances
interpretability and diminishes reliance on prior knowledge; 3) a controller
module, comprising a planner, an actor, and a memory pool, which uses the
learned causal graph to accomplish tasks; 4) a perception module, powered by
multimodal large language models, which enables ADAM to perceive like a human
player. Extensive experiments show that ADAM constructs an almost perfect
causal graph from scratch, enabling efficient task decomposition and execution
with strong interpretability. Notably, in our modified Minecraft games where no
prior knowledge is available, ADAM maintains its performance and shows
remarkable robustness and generalization capability. ADAM pioneers a novel
paradigm that integrates causal methods and embodied agents in a synergistic
manner. Our project page is at https://opencausalab.github.io/ADAM.

摘要：在像 Minecraft 這樣的開放世界環境中，現有的代理人面臨持續學習結構化知識的挑戰，尤其是因果關係。這些挑戰源於黑盒模型固有的不透明性，以及在訓練期間過度依賴先驗知識，這會損害它們的可解釋性和泛化能力。為此，我們引入了 ADAM，Minecraft 中的一個具身因果代理，它可以自主導航開放世界，感知多模式上下文，學習因果世界知識，並通過終身學習來應對複雜任務。ADAM 由四個關鍵組成部分賦能：1) 一個交互模組，使代理能夠執行動作，同時記錄交互過程；2) 一個因果模型模組，負責從頭開始構建一個不斷增長的因果圖，這增強了可解釋性並減少了對先驗知識的依賴；3) 一個控制器模組，包括一個規劃器、一個執行器和一個記憶池，它使用學習到的因果圖來完成任務；4) 一個感知模組，由多模式大型語言模型提供支援，使 ADAM 能夠像人類玩家一樣感知。大量的實驗表明，ADAM 從頭開始構建了一個幾乎完美的因果圖，實現了高效的任務分解和執行，並具有很強的可解釋性。值得注意的是，在我們修改過的 Minecraft 遊戲中，沒有可用的先驗知識，ADAM 保持了其性能，並表現出顯著的魯棒性和泛化能力。ADAM 開創了一種新穎的範例，以協同方式整合因果方法和具身代理。我們的專案頁面位於 https://opencausalab.github.io/ADAM。

##### **GraphAide: Advanced Graph-Assisted Query and Reasoning System**
2411.08041v1 by Sumit Purohit, George Chin, Patrick S Mackey, Joseph A Cottam

Curating knowledge from multiple siloed sources that contain both structured
and unstructured data is a major challenge in many real-world applications.
Pattern matching and querying represent fundamental tasks in modern data
analytics that leverage this curated knowledge. The development of such
applications necessitates overcoming several research challenges, including
data extraction, named entity recognition, data modeling, and designing query
interfaces. Moreover, the explainability of these functionalities is critical
for their broader adoption.
  The emergence of Large Language Models (LLMs) has accelerated the development
lifecycle of new capabilities. Nonetheless, there is an ongoing need for
domain-specific tools tailored to user activities. The creation of digital
assistants has gained considerable traction in recent years, with LLMs offering
a promising avenue to develop such assistants utilizing domain-specific
knowledge and assumptions.
  In this context, we introduce an advanced query and reasoning system,
GraphAide, which constructs a knowledge graph (KG) from diverse sources and
allows to query and reason over the resulting KG. GraphAide harnesses both the
KG and LLMs to rapidly develop domain-specific digital assistants. It
integrates design patterns from retrieval augmented generation (RAG) and the
semantic web to create an agentic LLM application. GraphAide underscores the
potential for streamlined and efficient development of specialized digital
assistants, thereby enhancing their applicability across various domains.

摘要：從包含結構化和非結構化資料的多個孤立來源中整理知識，是許多實際應用中的一項重大挑戰。
模式比對和查詢代表了現代資料分析的基本任務，利用這些整理好的知識。這種應用的發展需要克服多項研究挑戰，包括資料萃取、命名實體辨識、資料建模和設計查詢介面。此外，這些功能的可解釋性對於其更廣泛的採用至關重要。
大型語言模型 (LLM) 的出現加速了新功能的開發週期。儘管如此，仍然需要針對使用者活動量身打造的特定領域工具。近年來，數位助理的建立獲得了相當大的進展，LLM 提供了一個有前途的途徑，可以利用特定領域的知識和假設來開發此類助理。
在此背景下，我們介紹了一個先進的查詢和推理系統 GraphAide，它從不同的來源構建一個知識圖譜 (KG)，並允許查詢和推理所得的 KG。GraphAide 利用 KG 和 LLM 來快速開發特定領域的數位助理。它整合了檢索擴充生成 (RAG) 和語義網路的設計模式，以建立一個代理 LLM 應用程式。GraphAide 強調了簡化和有效開發專業數位助理的潛力，從而增強其在各個領域的適用性。

##### **Synergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction in LBSN**
2411.00028v2 by Zhilun Zhou, Jingyang Fan, Yu Liu, Fengli Xu, Depeng Jin, Yong Li

The fast development of location-based social networks (LBSNs) has led to
significant changes in society, resulting in popular studies of using LBSN data
for socioeconomic prediction, e.g., regional population and commercial activity
estimation. Existing studies design various graphs to model heterogeneous LBSN
data, and further apply graph representation learning methods for socioeconomic
prediction. However, these approaches heavily rely on heuristic ideas and
expertise to extract task-relevant knowledge from diverse data, which may not
be optimal for specific tasks. Additionally, they tend to overlook the inherent
relationships between different indicators, limiting the prediction accuracy.
Motivated by the remarkable abilities of large language models (LLMs) in
commonsense reasoning, embedding, and multi-agent collaboration, in this work,
we synergize LLM agents and knowledge graph for socioeconomic prediction. We
first construct a location-based knowledge graph (LBKG) to integrate
multi-sourced LBSN data. Then we leverage the reasoning power of LLM agent to
identify relevant meta-paths in the LBKG for each type of socioeconomic
prediction task, and design a semantic-guided attention module for knowledge
fusion with meta-paths. Moreover, we introduce a cross-task communication
mechanism to further enhance performance by enabling knowledge sharing across
tasks at both LLM agent and KG levels. On the one hand, the LLM agents for
different tasks collaborate to generate more diverse and comprehensive
meta-paths. On the other hand, the embeddings from different tasks are
adaptively merged for better socioeconomic prediction. Experiments on two
datasets demonstrate the effectiveness of the synergistic design between LLM
and KG, providing insights for information sharing across socioeconomic
prediction tasks.

摘要：<paragraph>基於位置的社群網路 (LBSN) 快速發展，已對社會造成重大變革，導致針對使用 LBSN 資料進行社會經濟預測（例如區域人口和商業活動估計）的研究蔚為風行。現有研究設計各種圖形來建模異質的 LBSN 資料，並進一步應用圖形表示學習方法進行社會經濟預測。然而，這些方法高度依賴試探法構想和專業知識，從不同的資料中萃取與任務相關的知識，這可能無法針對特定任務進行最佳化。此外，這些方法往往忽略不同指標之間的內在關聯性，限制了預測準確度。我們受到大型語言模型 (LLM) 在常識推理、嵌入和多重代理協作方面的顯著能力所激勵，因此在這項工作中，我們將 LLM 代理和知識圖譜協同應用於社會經濟預測。我們首先建構一個基於位置的知識圖譜 (LBKG)，以整合多來源的 LBSN 資料。然後，我們利用 LLM 代理的推理能力，針對每種類型的社會經濟預測任務識別 LBKG 中相關的元路徑，並設計一個語義導向的注意力模組，用於與元路徑融合知識。此外，我們引入一個跨任務溝通機制，透過在 LLM 代理和 KG 層級上讓知識跨任務分享，進一步提升效能。一方面，不同任務的 LLM 代理協作，以產生更多樣化且全面的元路徑。另一方面，不同任務的嵌入式會以適應性方式合併，以進行更佳的社會經濟預測。針對兩個資料集的實驗證明了 LLM 和 KG 之間協同設計的有效性，並為跨社會經濟預測任務的資訊分享提供見解。</paragraph>

##### **A Hierarchical Language Model For Interpretable Graph Reasoning**
2410.22372v1 by Sambhav Khurana, Xiner Li, Shurui Gui, Shuiwang Ji

Large language models (LLMs) are being increasingly explored for graph tasks.
Despite their remarkable success in text-based tasks, LLMs' capabilities in
understanding explicit graph structures remain limited, particularly with large
graphs. In this work, we introduce Hierarchical Language Model for Graph
(HLM-G), which employs a two-block architecture to capture node-centric local
information and interaction-centric global structure, effectively enhancing
graph structure understanding abilities. The proposed scheme allows LLMs to
address various graph queries with high efficacy, efficiency, and robustness,
while reducing computational costs on large-scale graph tasks. Furthermore, we
demonstrate the interpretability of our model using intrinsic attention weights
and established explainers. Comprehensive evaluations across diverse graph
reasoning and real-world tasks of node, link, and graph-levels highlight the
superiority of our method, marking a significant advancement in the application
of LLMs to graph understanding.

摘要：大型語言模型 (LLM) 愈來愈多用於圖形任務。
儘管 LLM 在基於文字的任務中取得顯著的成功，但其在理解明確圖形結構方面的能力仍然有限，特別是對於大型圖形。在這項工作中，我們引入了圖形階層語言模型 (HLM-G)，它採用雙區塊架構來擷取以節點為中心的局部資訊和以互動為中心的整體結構，有效地增強了圖形結構理解能力。所提出的架構允許 LLM 以高效率、高效率和高穩健性來處理各種圖形查詢，同時降低大型圖形任務的運算成本。此外，我們使用內在注意力權重和已建立的解釋器來展示我們模型的可解釋性。在節點、連結和圖形層級的各種圖形推理和真實世界任務中進行的全面評估突顯了我們方法的優越性，標誌著 LLM 在圖形理解應用方面取得重大進展。

##### **LLM-Forest for Health Tabular Data Imputation**
2410.21520v1 by Xinrui He, Yikun Ban, Jiaru Zou, Tianxin Wei, Curtiss B. Cook, Jingrui He

Missing data imputation is a critical challenge in tabular datasets,
especially in healthcare, where data completeness is vital for accurate
analysis. Large language models (LLMs), trained on vast corpora, have shown
strong potential in data generation, making them a promising tool for tabular
data imputation. However, challenges persist in designing effective prompts for
a finetuning-free process and in mitigating the risk of LLM hallucinations. To
address these issues, we propose a novel framework, LLM-Forest, which
introduces a "forest" of few-shot learning LLM "trees" with confidence-based
weighted voting. This framework is established on a new concept of bipartite
information graphs to identify high-quality relevant neighboring entries with
both feature and value granularity. Extensive experiments on four real-world
healthcare datasets demonstrate the effectiveness and efficiency of LLM-Forest.

摘要：遺失資料推估是表格資料集中的重大挑戰，
特別是在醫療保健中，資料完整性對於準確分析至關重要。
大型語言模型 (LLM) 在龐大的語料庫上訓練，在資料產生方面展現出強大的潛力，使其成為表格資料推估的有前途工具。
然而，在設計有效提示以進行微調免費流程和減輕 LLM 幻覺風險方面仍存在挑戰。
為了解決這些問題，我們提出一個新的框架，LLM-Forest，它引入了一個「森林」的少量學習 LLM「樹」，並採用基於信心的加權投票。
這個框架建立在雙分資訊圖的新概念上，以識別具有特徵和值粒度的優質相關鄰近項目。
在四個真實世界的醫療保健資料集上進行的廣泛實驗證明了 LLM-Forest 的有效性和效率。

##### **Hierarchical Knowledge Graph Construction from Images for Scalable E-Commerce**
2410.21237v1 by Zhantao Yang, Han Zhang, Fangyi Chen, Anudeepsekhar Bolimera, Marios Savvides

Knowledge Graph (KG) is playing an increasingly important role in various AI
systems. For e-commerce, an efficient and low-cost automated knowledge graph
construction method is the foundation of enabling various successful downstream
applications. In this paper, we propose a novel method for constructing
structured product knowledge graphs from raw product images. The method
cooperatively leverages recent advances in the vision-language model (VLM) and
large language model (LLM), fully automating the process and allowing timely
graph updates. We also present a human-annotated e-commerce product dataset for
benchmarking product property extraction in knowledge graph construction. Our
method outperforms our baseline in all metrics and evaluated properties,
demonstrating its effectiveness and bright usage potential.

摘要：知識圖譜 (KG) 在各種 AI 系統中扮演越來越重要的角色。對於電子商務來說，一種有效且低成本的自動化知識圖譜建構方法是促成各種成功的下游應用程式的基礎。在本文中，我們提出了一種從原始產品影像建構結構化產品知識圖譜的新穎方法。該方法協同利用了視覺語言模型 (VLM) 和大型語言模型 (LLM) 的最新進展，完全自動化了流程並允許及時更新圖譜。我們還提供了一個由人工標註的電子商務產品資料集，用於評量知識圖譜建構中的產品屬性萃取。我們的模型在所有指標和評估屬性上都優於我們的基準，證明了其有效性和廣闊的使用潛力。

##### **CRAT: A Multi-Agent Framework for Causality-Enhanced Reflective and Retrieval-Augmented Translation with Large Language Models**
2410.21067v1 by Meiqi Chen, Fandong Meng, Yingxue Zhang, Yan Zhang, Jie Zhou

Large language models (LLMs) have shown great promise in machine translation,
but they still struggle with contextually dependent terms, such as new or
domain-specific words. This leads to inconsistencies and errors that are
difficult to address. Existing solutions often depend on manual identification
of such terms, which is impractical given the complexity and evolving nature of
language. While Retrieval-Augmented Generation (RAG) could provide some
assistance, its application to translation is limited by issues such as
hallucinations from information overload. In this paper, we propose CRAT, a
novel multi-agent translation framework that leverages RAG and
causality-enhanced self-reflection to address these challenges. This framework
consists of several specialized agents: the Unknown Terms Identification agent
detects unknown terms within the context, the Knowledge Graph (KG) Constructor
agent extracts relevant internal knowledge about these terms and retrieves
bilingual information from external sources, the Causality-enhanced Judge agent
validates the accuracy of the information, and the Translator agent
incorporates the refined information into the final output. This automated
process allows for more precise and consistent handling of key terms during
translation. Our results show that CRAT significantly improves translation
accuracy, particularly in handling context-sensitive terms and emerging
vocabulary.

摘要：大型語言模型（LLM）在機器翻譯方面展現出極大的前景，
但它們仍然難以應對依賴於語境的詞彙，例如新詞或特定領域的詞彙。這會導致不一致和錯誤，而這些錯誤很難解決。現有的解決方案通常依賴於手動識別此類詞彙，但由於語言的複雜性和不斷演變的特性，這並不可行。雖然檢索增強生成（RAG）可以提供一些協助，但其在翻譯中的應用受到諸如資訊超載產生的幻覺等問題的限制。在本文中，我們提出 CRAT，這是一個新穎的多代理翻譯架構，它利用 RAG 和因果增強自省來應對這些挑戰。此架構包含幾個專門的代理：未知詞彙識別代理會偵測語境中的未知詞彙，知識圖譜（KG）建構代理會擷取這些詞彙相關的內部知識，並從外部來源中檢索雙語資訊，因果增強判斷代理會驗證資訊的準確性，而翻譯代理會將精煉過的資訊納入最終輸出。這個自動化的流程允許在翻譯過程中更精確且一致地處理關鍵詞彙。我們的結果顯示，CRAT 大幅提升了翻譯準確性，特別是在處理對語境敏感的詞彙和新興詞彙方面。

##### **CTINEXUS: Leveraging Optimized LLM In-Context Learning for Constructing Cybersecurity Knowledge Graphs Under Data Scarcity**
2410.21060v1 by Yutong Cheng, Osama Bajaber, Saimon Amanuel Tsegai, Dawn Song, Peng Gao

Textual descriptions in cyber threat intelligence (CTI) reports, such as
security articles and news, are rich sources of knowledge about cyber threats,
crucial for organizations to stay informed about the rapidly evolving threat
landscape. However, current CTI extraction methods lack flexibility and
generalizability, often resulting in inaccurate and incomplete knowledge
extraction. Syntax parsing relies on fixed rules and dictionaries, while model
fine-tuning requires large annotated datasets, making both paradigms
challenging to adapt to new threats and ontologies. To bridge the gap, we
propose CTINexus, a novel framework leveraging optimized in-context learning
(ICL) of large language models (LLMs) for data-efficient CTI knowledge
extraction and high-quality cybersecurity knowledge graph (CSKG) construction.
Unlike existing methods, CTINexus requires neither extensive data nor parameter
tuning and can adapt to various ontologies with minimal annotated examples.
This is achieved through (1) a carefully designed automatic prompt construction
strategy with optimal demonstration retrieval for extracting a wide range of
cybersecurity entities and relations; (2) a hierarchical entity alignment
technique that canonicalizes the extracted knowledge and removes redundancy;
(3) an ICL-enhanced long-distance relation prediction technique to further
complete the CKSG with missing links. Our extensive evaluations using 150
real-world CTI reports collected from 10 platforms demonstrate that CTINexus
significantly outperforms existing methods in constructing accurate and
complete CSKGs, highlighting its potential to transform CTI analysis with an
efficient and adaptable solution for the dynamic threat landscape.

摘要：網路威脅情報 (CTI) 報告中的文字描述，例如安全文章和新聞，是網路威脅的豐富知識來源，對於組織而言至關重要，可以隨時了解快速演變的威脅環境。然而，目前的 CTI 提取方法缺乏靈活性且難以概括，通常會導致知識提取不準確且不完整。語法解析依賴於固定規則和字典，而模型微調需要大量標註的資料集，這使得這兩種範例都難以適應新的威脅和本体。為了彌補差距，我們提出了 CTINexus，這是一個新穎的框架，利用大型語言模型 (LLM) 的最佳化情境學習 (ICL) 來進行資料有效率的 CTI 知識提取和高品質的網路安全知識圖 (CSKG) 建構。與現有方法不同，CTINexus 不需要廣泛的資料或參數調整，並且可以透過最少的標註範例適應各種本体。這是透過 (1) 經過精心設計的自動提示建構策略，並透過最佳示範檢索來提取廣泛的網路安全實體和關係來實現的；(2) 一種階層式實體比對技術，可以將提取的知識標準化並消除冗餘；(3) 一種 ICL 增強的長距離關係預測技術，可以進一步完成具有遺失連結的 CKSG。我們使用從 10 個平台收集的 150 份真實世界 CTI 報告進行廣泛評估，證明 CTINexus 在建構準確且完整的 CSKG 方面明顯優於現有方法，突顯了其以有效且適應性強的解決方案轉換 CTI 分析的潛力，以應對動態的威脅環境。

##### **Graph-based Uncertainty Metrics for Long-form Language Model Outputs**
2410.20783v1 by Mingjian Jiang, Yangjun Ruan, Prasanna Sattigeri, Salim Roukos, Tatsunori Hashimoto

Recent advancements in Large Language Models (LLMs) have significantly
improved text generation capabilities, but these systems are still known to
hallucinate, and granular uncertainty estimation for long-form LLM generations
remains challenging. In this work, we propose Graph Uncertainty -- which
represents the relationship between LLM generations and claims within them as a
bipartite graph and estimates the claim-level uncertainty with a family of
graph centrality metrics. Under this view, existing uncertainty estimation
methods based on the concept of self-consistency can be viewed as using degree
centrality as an uncertainty measure, and we show that more sophisticated
alternatives such as closeness centrality provide consistent gains at
claim-level uncertainty estimation. Moreover, we present uncertainty-aware
decoding techniques that leverage both the graph structure and uncertainty
estimates to improve the factuality of LLM generations by preserving only the
most reliable claims. Compared to existing methods, our graph-based uncertainty
metrics lead to an average of 6.8% relative gains on AUPRC across various
long-form generation settings, and our end-to-end system provides consistent
2-4% gains in factuality over existing decoding techniques while significantly
improving the informativeness of generated responses.

摘要：大型語言模型 (LLM) 的最新進展顯著提升了文字生成能力，但這些系統仍以產生幻覺著稱，而針對長篇 LLM 生成的細緻不確定性估計仍是一項挑戰。在這項工作中，我們提出圖形不確定性，它將 LLM 生成和其中的主張表示為二部圖，並使用一系列圖形中心性指標估計主張層級的不確定性。在此觀點下，現有的基於自洽性概念的不確定性估計方法可視為使用度量中心性作為不確定性指標，我們證明了更精密的替代方案（例如接近中心性）在主張層級不確定性估計中提供了穩定的增益。此外，我們提出了不確定性感知解碼技術，該技術利用圖形結構和不確定性估計來提升 LLM 生成的真實性，方法是僅保留最可靠的主張。與現有方法相比，我們的基於圖形的指標在各種長篇生成設定中平均提升了 AUPRC 的 6.8%，而我們的端到端系統在真實性方面提供了 2-4% 的穩定增益，同時顯著提升了生成回應的資訊性。

##### **Plan$\times$RAG: Planning-guided Retrieval Augmented Generation**
2410.20753v1 by Prakhar Verma, Sukruta Prakash Midigeshi, Gaurav Sinha, Arno Solin, Nagarajan Natarajan, Amit Sharma

We introduce Planning-guided Retrieval Augmented Generation
(Plan$\times$RAG), a novel framework that augments the
\emph{retrieve-then-reason} paradigm of existing RAG frameworks to
\emph{plan-then-retrieve}. Plan$\times$RAG formulates a reasoning plan as a
directed acyclic graph (DAG), decomposing queries into interrelated atomic
sub-queries. Answer generation follows the DAG structure, allowing significant
gains in efficiency through parallelized retrieval and generation. While
state-of-the-art RAG solutions require extensive data generation and
fine-tuning of language models (LMs), Plan$\times$RAG incorporates frozen LMs
as plug-and-play experts to generate high-quality answers. Compared to existing
RAG solutions, Plan$\times$RAG demonstrates significant improvements in
reducing hallucinations and bolstering attribution due to its structured
sub-query decomposition. Overall, Plan$\times$RAG offers a new perspective on
integrating external knowledge in LMs while ensuring attribution by design,
contributing towards more reliable LM-based systems.

摘要：<paragraph>我們引入了規劃引導的檢索增強生成 (Plan$\times$RAG)，這是一個新穎的框架，它擴充了現有 RAG 框架的「先檢索後推理」範例，改為「先規劃後檢索」。Plan$\times$RAG 將推理計畫制定為有向無環圖 (DAG)，將查詢分解成相互關聯的原子子查詢。答案生成遵循 DAG 結構，透過並行檢索和生成，大幅提升效率。雖然最先進的 RAG 解决方案需要大量資料生成和語言模型 (LM) 的微調，但 Plan$\times$RAG 將凍結的 LM 整合為即插即用的專家，以生成高品質的答案。與現有的 RAG 解决方案相比，Plan$\times$RAG 在減少幻覺和加強歸因方面表現出顯著的進步，這要歸功於其結構化的子查詢分解。總體而言，Plan$\times$RAG 提供了一個新的觀點，以整合 LM 中的外部知識，同時確保歸因設計，有助於建立更可靠的基於 LM 的系統。</paragraph>

##### **Simple is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation**
2410.20724v2 by Mufei Li, Siqi Miao, Pan Li

Large Language Models (LLMs) demonstrate strong reasoning abilities but face
limitations such as hallucinations and outdated knowledge. Knowledge Graph
(KG)-based Retrieval-Augmented Generation (RAG) addresses these issues by
grounding LLM outputs in structured external knowledge from KGs. However,
current KG-based RAG frameworks still struggle to optimize the trade-off
between retrieval effectiveness and efficiency in identifying a suitable amount
of relevant graph information for the LLM to digest. We introduce SubgraphRAG,
extending the KG-based RAG framework that retrieves subgraphs and leverages
LLMs for reasoning and answer prediction. Our approach innovatively integrates
a lightweight multilayer perceptron with a parallel triple-scoring mechanism
for efficient and flexible subgraph retrieval while encoding directional
structural distances to enhance retrieval effectiveness. The size of retrieved
subgraphs can be flexibly adjusted to match the query's need and the downstream
LLM's capabilities. This design strikes a balance between model complexity and
reasoning power, enabling scalable and generalizable retrieval processes.
Notably, based on our retrieved subgraphs, smaller LLMs like
Llama3.1-8B-Instruct deliver competitive results with explainable reasoning,
while larger models like GPT-4o achieve state-of-the-art accuracy compared with
previous baselines -- all without fine-tuning. Extensive evaluations on the
WebQSP and CWQ benchmarks highlight SubgraphRAG's strengths in efficiency,
accuracy, and reliability by reducing hallucinations and improving response
grounding.

摘要：<paragraph>大型語言模型 (LLM) 具有強大的推理能力，但面臨幻覺和過時知識等限制。基於知識圖譜 (KG) 的檢索增強生成 (RAG) 透過將 LLM 輸出結果奠基於 KG 中的結構化外部知識，來解決這些問題。然而，目前基於 KG 的 RAG 架構仍難以在檢索效能和效率之間取得最佳平衡，以找出 LLM 能夠消化的適當相關圖表資訊量。我們引進 SubgraphRAG，擴充基於 KG 的 RAG 架構，以檢索子圖表並利用 LLM 進行推理和答案預測。我們的做法創新地整合了一個輕量多層感知器與一個並行三元組計分機制，用於高效且靈活地檢索子圖表，同時編碼方向結構距離以增強檢索效能。檢索到的子圖表大小可以靈活調整，以符合查詢需求和下游 LLM 的功能。這種設計在模型複雜度和推理能力之間取得平衡，實現可擴充且可概化的檢索程序。值得注意的是，根據我們檢索到的子圖表，較小的 LLM（例如 Llama3.1-8B-Instruct）可以提供具備可解釋推理的競爭結果，而較大的模型（例如 GPT-4o）則達到與先前基準相比的最新準確度，而且所有這些都不需要微調。在 WebQSP 和 CWQ 基準上的廣泛評估突顯了 SubgraphRAG 在效率、準確度和可靠性方面的優勢，透過減少幻覺並改善回應依據。</paragraph>

##### **Effective Instruction Parsing Plugin for Complex Logical Query Answering on Knowledge Graphs**
2410.20321v1 by Xingrui Zhuo, Jiapu Wang, Gongqing Wu, Shirui Pan, Xindong Wu

Knowledge Graph Query Embedding (KGQE) aims to embed First-Order Logic (FOL)
queries in a low-dimensional KG space for complex reasoning over incomplete
KGs. To enhance the generalization of KGQE models, recent studies integrate
various external information (such as entity types and relation context) to
better capture the logical semantics of FOL queries. The whole process is
commonly referred to as Query Pattern Learning (QPL). However, current QPL
methods typically suffer from the pattern-entity alignment bias problem,
leading to the learned defective query patterns limiting KGQE models'
performance. To address this problem, we propose an effective Query Instruction
Parsing Plugin (QIPP) that leverages the context awareness of Pre-trained
Language Models (PLMs) to capture latent query patterns from code-like query
instructions. Unlike the external information introduced by previous QPL
methods, we first propose code-like instructions to express FOL queries in an
alternative format. This format utilizes textual variables and nested tuples to
convey the logical semantics within FOL queries, serving as raw materials for a
PLM-based instruction encoder to obtain complete query patterns. Building on
this, we design a query-guided instruction decoder to adapt query patterns to
KGQE models. To further enhance QIPP's effectiveness across various KGQE
models, we propose a query pattern injection mechanism based on compressed
optimization boundaries and an adaptive normalization component, allowing KGQE
models to utilize query patterns more efficiently. Extensive experiments
demonstrate that our plug-and-play method improves the performance of eight
basic KGQE models and outperforms two state-of-the-art QPL methods.

摘要：知識圖譜查詢嵌入（KGQE）旨在將一階邏輯（FOL）查詢嵌入到低維 KG 空間中，以便對不完整的 KG 進行複雜推理。為了增強 KGQE 模型的泛化能力，最近的研究整合了各種外部資訊（例如實體類型和關係上下文），以更好地捕捉 FOL 查詢的邏輯語義。整個過程通常稱為查詢模式學習（QPL）。然而，當前的 QPL 方法通常會受到模式實體對齊偏差問題的影響，導致學習到的有缺陷查詢模式限制了 KGQE 模型的效能。為了解決這個問題，我們提出了一個有效的查詢指令解析外掛程式（QIPP），它利用預訓練語言模型（PLM）的上下文感知來從類代碼的查詢指令中擷取潛在查詢模式。與先前 QPL 方法引入的外部資訊不同，我們首先提出類代碼的指令以另類格式表達 FOL 查詢。此格式利用文字變數和巢狀元組來傳達 FOL 查詢中的邏輯語義，作為基於 PLM 的指令編碼器的原料，以取得完整的查詢模式。在此基礎上，我們設計了一個查詢引導的指令解碼器，以將查詢模式調整到 KGQE 模型。為了進一步增強 QIPP 在各種 KGQE 模型中的有效性，我們提出了一個基於壓縮最佳化邊界和自適應正規化元件的查詢模式注入機制，允許 KGQE 模型更有效地利用查詢模式。廣泛的實驗表明，我們的即插即用方法改善了八個基本 KGQE 模型的效能，並優於兩種最先進的 QPL 方法。

##### **Mathematical Derivation Graphs: A Task for Summarizing Equation Dependencies in STEM Manuscripts**
2410.21324v1 by Vishesh Prasad, Brian Kim, Nickvash Kani

Recent advances in natural language processing (NLP), particularly with the
emergence of large language models (LLMs), have significantly enhanced the
field of textual analysis. However, while these developments have yielded
substantial progress in analyzing textual data, applying analysis to
mathematical equations and their relationships within texts has produced mixed
results. In this paper, we take the initial steps toward understanding the
dependency relationships between mathematical expressions in STEM articles. Our
dataset, sourced from a random sampling of the arXiv corpus, contains an
analysis of 107 published STEM manuscripts whose inter-equation dependency
relationships have been hand-labeled, resulting in a new object we refer to as
a derivation graph that summarizes the mathematical content of the manuscript.
We exhaustively evaluate analytical and NLP-based models to assess their
capability to identify and extract the derivation relationships for each
article and compare the results with the ground truth. Our comprehensive
testing finds that both analytical and NLP models (including LLMs) achieve
$\sim$40-50% F1 scores for extracting derivation graphs from articles,
revealing that the recent advances in NLP have not made significant inroads in
comprehending mathematical texts compared to simpler analytic models. While
current approaches offer a solid foundation for extracting mathematical
information, further research is necessary to improve accuracy and depth in
this area.

摘要：自然語言處理（NLP）的最新進展，特別是大語言模型（LLM）的出現，已顯著增強了文本分析領域。然而，儘管這些發展在分析文本資料方面取得了實質性進展，但將分析應用於數學方程式及其在文本中的關係卻產生了不同的結果。在本文中，我們採取了初步步驟來了解 STEM 文章中數學表達式之間的依賴關係。我們的資料集取自 arXiv 語料庫的隨機抽樣，其中包含對 107 篇已發表的 STEM 手稿的分析，其方程式間的依賴關係已進行手動標記，產生了一個我們稱為衍生圖的新物件，該物件總結了手稿的數學內容。我們徹底評估了分析和基於 NLP 的模型，以評估它們識別和提取每篇文章的衍生關係的能力，並將結果與真實情況進行比較。我們的全面測試發現，分析和 NLP 模型（包括 LLM）在從文章中提取衍生圖方面的 F1 分數均達到 $\sim$40-50%，這表明與更簡單的分析模型相比，NLP 的最新進展並沒有在理解數學文本方面取得重大進展。儘管目前的方法為提取數學資訊提供了堅實的基礎，但仍需要進一步的研究來提高此領域的準確性和深度。

##### **DualMAR: Medical-Augmented Representation from Dual-Expertise Perspectives**
2410.19955v1 by Pengfei Hu, Chang Lu, Fei Wang, Yue Ning

Electronic Health Records (EHR) has revolutionized healthcare data management
and prediction in the field of AI and machine learning. Accurate predictions of
diagnosis and medications significantly mitigate health risks and provide
guidance for preventive care. However, EHR driven models often have limited
scope on understanding medical-domain knowledge and mostly rely on
simple-and-sole ontologies. In addition, due to the missing features and
incomplete disease coverage of EHR, most studies only focus on basic analysis
on conditions and medication. We propose DualMAR, a framework that enhances EHR
prediction tasks through both individual observation data and public knowledge
bases. First, we construct a bi-hierarchical Diagnosis Knowledge Graph (KG)
using verified public clinical ontologies and augment this KG via Large
Language Models (LLMs); Second, we design a new proxy-task learning on lab
results in EHR for pretraining, which further enhance KG representation and
patient embeddings. By retrieving radial and angular coordinates upon polar
space, DualMAR enables accurate predictions based on rich hierarchical and
semantic embeddings from KG. Experiments also demonstrate that DualMAR
outperforms state-of-the-art models, validating its effectiveness in EHR
prediction and KG integration in medical domains.

摘要：電子健康紀錄 (EHR) 已徹底改變了醫療保健資料管理，並預測了人工智慧和機器學習領域。準確預測診斷和藥物可大幅減輕健康風險，並提供預防性照護的指導方針。然而，EHR 驅動的模型在理解醫療領域知識上通常具有局限性，而且大多依賴於簡單且單一的本体。此外，由於 EHR 遺漏了功能且疾病涵蓋不完整，大多數研究僅專注於疾病和藥物的基本分析。我們提出 DualMAR，一個透過個人觀察資料和公共知識庫增強 EHR 預測任務的架構。首先，我們使用經過驗證的公共臨床本体構建一個雙層級診斷知識圖 (KG)，並透過大型語言模型 (LLM) 擴充這個 KG；其次，我們設計一個新的代理任務學習，針對 EHR 中的實驗室結果進行預訓練，進一步增強 KG 表示和患者嵌入。透過擷取極座標空間上的徑向和角向坐標，DualMAR 能夠根據 KG 中豐富的層級和語意嵌入進行準確的預測。實驗也證明 DualMAR 優於最先進的模型，驗證了其在 EHR 預測和醫療領域中 KG 整合的有效性。

##### **FISHNET: Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert Swarms, and Task Planning**
2410.19727v1 by Nicole Cho, Nishan Srishankar, Lucas Cecchi, William Watson

Financial intelligence generation from vast data sources has typically relied
on traditional methods of knowledge-graph construction or database engineering.
Recently, fine-tuned financial domain-specific Large Language Models (LLMs),
have emerged. While these advancements are promising, limitations such as high
inference costs, hallucinations, and the complexity of concurrently analyzing
high-dimensional financial data, emerge. This motivates our invention FISHNET
(Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning,
Expert swarming, and Task planning), an agentic architecture that accomplishes
highly complex analytical tasks for more than 98,000 regulatory filings that
vary immensely in terms of semantics, data hierarchy, or format. FISHNET shows
remarkable performance for financial insight generation (61.8% success rate
over 5.0% Routing, 45.6% RAG R-Precision). We conduct rigorous ablations to
empirically prove the success of FISHNET, each agent's importance, and the
optimized performance of assembling all agents. Our modular architecture can be
leveraged for a myriad of use-cases, enabling scalability, flexibility, and
data integrity that are critical for financial tasks.

摘要：財務情報生成通常依賴於傳統的知識圖表建構或資料庫工程方法，這些方法來自於龐大的資料來源。最近，針對財務領域進行微調的大型語言模型 (LLM) 已應運而生。儘管這些進展令人振奮，但仍存在一些限制，例如高推理成本、幻覺，以及同時分析高維度財務資料的複雜性。這促使我們發明了 FISHNET（來自子查詢、協調、神經條件化、專家群集和任務規劃的財務情報），這是一種代理架構，可針對超過 98,000 份法規文件執行高度複雜的分析任務，而這些文件在語義、資料階層或格式方面差異極大。FISHNET 在產生財務見解方面表現出色（成功率為 61.8%，路由率為 5.0%，RAG R-Precision 為 45.6%）。我們進行了嚴格的消融，以實證證明 FISHNET 的成功、每個代理的重要性，以及組裝所有代理的最佳化效能。我們模組化的架構可運用於各種使用案例，提供財務任務至關重要的可擴充性、彈性和資料完整性。

##### **Knowledge Graph Enhanced Language Agents for Recommendation**
2410.19627v1 by Taicheng Guo, Chaochun Liu, Hai Wang, Varun Mannam, Fang Wang, Xin Chen, Xiangliang Zhang, Chandan K. Reddy

Language agents have recently been used to simulate human behavior and
user-item interactions for recommendation systems. However, current language
agent simulations do not understand the relationships between users and items,
leading to inaccurate user profiles and ineffective recommendations. In this
work, we explore the utility of Knowledge Graphs (KGs), which contain extensive
and reliable relationships between users and items, for recommendation. Our key
insight is that the paths in a KG can capture complex relationships between
users and items, eliciting the underlying reasons for user preferences and
enriching user profiles. Leveraging this insight, we propose Knowledge Graph
Enhanced Language Agents(KGLA), a framework that unifies language agents and KG
for recommendation systems. In the simulated recommendation scenario, we
position the user and item within the KG and integrate KG paths as natural
language descriptions into the simulation. This allows language agents to
interact with each other and discover sufficient rationale behind their
interactions, making the simulation more accurate and aligned with real-world
cases, thus improving recommendation performance. Our experimental results show
that KGLA significantly improves recommendation performance (with a 33%-95%
boost in NDCG@1 among three widely used benchmarks) compared to the previous
best baseline method.

摘要：語言代理最近已被用於模擬人類行為和推薦系統中的使用者項目互動。然而，目前的語言代理模擬並未了解使用者和項目之間的關係，導致使用者輪廓不準確和推薦效果不佳。在這項工作中，我們探討了知識圖譜 (KG) 的效用，其中包含使用者和項目之間廣泛且可靠的關係，以供推薦。我們的關鍵見解是，KG 中的路徑可以捕捉使用者和項目之間的複雜關係，引出使用者偏好的根本原因並豐富使用者輪廓。利用此見解，我們提出了知識圖譜增強語言代理 (KGLA)，一個統一語言代理和 KG 以用於推薦系統的架構。在模擬推薦情境中，我們將使用者和項目定位在 KG 中，並將 KG 路徑整合為自然語言描述到模擬中。這允許語言代理彼此互動並發現其互動背後的充分依據，使模擬更準確且與實際案例相符，從而改善推薦效能。我們的實驗結果顯示，與先前最佳基準方法相比，KGLA 大幅改善了推薦效能（在三個廣泛使用的基準中，NDCG@1 提升了 33%-95%）。

##### **Graph Linearization Methods for Reasoning on Graphs with Large Language Models**
2410.19494v1 by Christos Xypolopoulos, Guokan Shang, Xiao Fei, Giannis Nikolentzos, Hadi Abdine, Iakovos Evdaimon, Michail Chatzianastasis, Giorgos Stamou, Michalis Vazirgiannis

Large language models have evolved to process multiple modalities beyond
text, such as images and audio, which motivates us to explore how to
effectively leverage them for graph machine learning tasks. The key question,
therefore, is how to transform graphs into linear sequences of tokens, a
process we term graph linearization, so that LLMs can handle graphs naturally.
We consider that graphs should be linearized meaningfully to reflect certain
properties of natural language text, such as local dependency and global
alignment, in order to ease contemporary LLMs, trained on trillions of textual
tokens, better understand graphs. To achieve this, we developed several graph
linearization methods based on graph centrality, degeneracy, and node
relabeling schemes. We then investigated their effect on LLM performance in
graph reasoning tasks. Experimental results on synthetic graphs demonstrate the
effectiveness of our methods compared to random linearization baselines. Our
work introduces novel graph representations suitable for LLMs, contributing to
the potential integration of graph machine learning with the trend of
multi-modal processing using a unified transformer model.

摘要：大型語言模型已演化為處理文字之外的多種模式，例如影像和音訊，這促使我們探索如何有效地運用它們於圖形機器學習任務。因此，關鍵問題在於如何將圖形轉換為線性序列的代幣，這是一個我們稱為圖形線性化的過程，讓 LLM 能自然地處理圖形。我們認為圖形應有意義地進行線性化，以反映自然語言文字的特定屬性，例如局部依賴性和全局對齊，以便讓在數兆個文字代幣上訓練的當代 LLM 更能理解圖形。為達成此目的，我們開發了幾種基於圖形中心性、簡併性和節點重新標籤架構的圖形線性化方法。接著，我們探討它們對 LLM 在圖形推理任務中的效能影響。合成圖形上的實驗結果證明了我們的方法比隨機線性化基準更有效。我們的研究引入了適合 LLM 的新穎圖形表示法，有助於將圖形機器學習與使用統一Transformer模型的多模式處理趨勢整合起來。

##### **Hierarchical Mixture of Experts: Generalizable Learning for High-Level Synthesis**
2410.19225v1 by Weikai Li, Ding Wang, Zijian Ding, Atefeh Sohrabizadeh, Zongyue Qin, Jason Cong, Yizhou Sun

High-level synthesis (HLS) is a widely used tool in designing Field
Programmable Gate Array (FPGA). HLS enables FPGA design with software
programming languages by compiling the source code into an FPGA circuit. The
source code includes a program (called ``kernel'') and several pragmas that
instruct hardware synthesis, such as parallelization, pipeline, etc. While it
is relatively easy for software developers to design the program, it heavily
relies on hardware knowledge to design the pragmas, posing a big challenge for
software developers. Recently, different machine learning algorithms, such as
GNNs, have been proposed to automate the pragma design via performance
prediction. However, when applying the trained model on new kernels, the
significant domain shift often leads to unsatisfactory performance. We propose
a more domain-generalizable model structure: a two-level hierarchical Mixture
of Experts (MoE), that can be flexibly adapted to any GNN model. Different
expert networks can learn to deal with different regions in the representation
space, and they can utilize similar patterns between the old kernels and new
kernels. In the low-level MoE, we apply MoE on three natural granularities of a
program: node, basic block, and graph. The high-level MoE learns to aggregate
the three granularities for the final decision. To stably train the
hierarchical MoE, we further propose a two-stage training method. Extensive
experiments verify the effectiveness of the hierarchical MoE.

摘要：高階綜合（HLS）是設計現場可編程閘陣列（FPGA）中廣泛使用的工具。HLS 透過將原始碼編譯成 FPGA 電路，使用軟體程式語言進行 FPGA 設計。原始碼包含一個程式（稱為「核心」）和多個指導硬體綜合的指示，例如平行化、管線等。雖然軟體開發人員設計程式相對容易，但它極度依賴硬體知識來設計指示，這對軟體開發人員來說是一大挑戰。最近，不同的機器學習演算法，例如 GNN，已被提出用於透過效能預測自動進行指示設計。然而，在新的核心上應用訓練好的模型時，顯著的領域轉移通常會導致效能不佳。我們提出一個更具領域通用性的模型結構：一個二階層混合專家（MoE），它可以靈活地適應任何 GNN 模型。不同的專家網路可以學習處理表示空間中的不同區域，並且它們可以利用舊核心和新核心之間的相似模式。在低階 MoE 中，我們對程式的三個自然粒度應用 MoE：節點、基本區塊和圖。高階 MoE 學習彙總這三個粒度以做出最終決策。為了穩定訓練階層式 MoE，我們進一步提出一個二階段訓練方法。廣泛的實驗驗證了階層式 MoE 的有效性。

##### **Enriching GNNs with Text Contextual Representations for Detecting Disinformation Campaigns on Social Media**
2410.19193v1 by Bruno Croso Cunha da Silva, Thomas Palmeira Ferraz, Roseli De Deus Lopes

Disinformation on social media poses both societal and technical challenges.
While previous studies have integrated textual information into propagation
networks, they have yet to fully leverage the advancements in Transformer-based
language models for high-quality contextual text representations. This work
investigates the impact of incorporating textual features into Graph Neural
Networks (GNNs) for fake news detection. Our experiments demonstrate that
contextual representations improve performance by 9.3% in Macro F1 over static
ones and 33.8% over GNNs without textual features. However, noisy data
augmentation degrades performance and increases instability. We expect our
methodology to open avenues for further research, and all code is made publicly
available.

摘要：社群媒體上的錯誤訊息造成社會和技術層面的挑戰。
儘管過往的研究已將文字資訊整合到傳播網路中，但尚未充分利用基於 Transformer 的語言模型在高品質脈絡文字表徵上的進展。這項研究探討將文字特徵納入圖形神經網路 (GNN) 中對於假新聞偵測的影響。我們的實驗結果顯示，脈絡表徵將巨觀 F1 的效能提升了 9.3%，優於靜態表徵，並比沒有文字特徵的 GNN 提升了 33.8%。然而，有雜訊的資料擴充會降低效能並增加不穩定性。我們預期我們的研究方法將開啟進一步研究的途徑，所有程式碼皆公開提供。

##### **GCoder: Improving Large Language Model for Generalized Graph Problem Solving**
2410.19084v1 by Qifan Zhang, Xiaobin Hong, Jianheng Tang, Nuo Chen, Yuhan Li, Wenzhong Li, Jing Tang, Jia Li

Large Language Models (LLMs) have demonstrated strong reasoning abilities,
making them suitable for complex tasks such as graph computation. Traditional
reasoning steps paradigm for graph problems is hindered by unverifiable steps,
limited long-term reasoning, and poor generalization to graph variations. To
overcome these limitations, we introduce GCoder, a code-based LLM designed to
enhance problem-solving in generalized graph computation problems. Our method
involves constructing an extensive training dataset, GraphWild, featuring
diverse graph formats and algorithms. We employ a multi-stage training process,
including Supervised Fine-Tuning (SFT) and Reinforcement Learning from Compiler
Feedback (RLCF), to refine model capabilities. For unseen tasks, a hybrid
retrieval technique is used to augment performance. Experiments demonstrate
that GCoder outperforms GPT-4o, with an average accuracy improvement of 16.42%
across various graph computational problems. Furthermore, GCoder efficiently
manages large-scale graphs with millions of nodes and diverse input formats,
overcoming the limitations of previous models focused on the reasoning steps
paradigm. This advancement paves the way for more intuitive and effective graph
problem-solving using LLMs. Code and data are available at here:
https://github.com/Bklight999/WWW25-GCoder/tree/master.

摘要：大型語言模型 (LLM) 已展現強大的推理能力，使其適用於複雜任務，例如圖形運算。傳統圖形問題的推理步驟範例受到不可驗證的步驟、有限的長期推理和對圖形變化的概括性不佳的阻礙。為了克服這些限制，我們引入了 GCoder，一種基於代碼的 LLM，旨在增強廣義圖形運算問題中的問題解決能力。我們的技術涉及構建一個廣泛的訓練資料集 GraphWild，其中包含多樣的圖形格式和演算法。我們採用多階段訓練流程，包括監督微調 (SFT) 和編譯器回饋強化學習 (RLCF)，以改善模型能力。對於未知任務，使用混合擷取技術來增強效能。實驗證明，GCoder 優於 GPT-4o，在各種圖形運算問題中平均準確度提升了 16.42%。此外，GCoder 有效地管理著擁有數百萬個節點和多樣輸入格式的大規模圖形，克服了先前專注於推理步驟範例的模型的限制。這項進展為使用 LLM 進行更直觀且有效的圖形問題解決鋪平了道路。程式碼和資料可於此處取得：https://github.com/Bklight999/WWW25-GCoder/tree/master。

##### **LLM-based Online Prediction of Time-varying Graph Signals**
2410.18718v1 by Dayu Qin, Yi Yan, Ercan Engin Kuruoglu

In this paper, we propose a novel framework that leverages large language
models (LLMs) for predicting missing values in time-varying graph signals by
exploiting spatial and temporal smoothness. We leverage the power of LLM to
achieve a message-passing scheme. For each missing node, its neighbors and
previous estimates are fed into and processed by LLM to infer the missing
observations. Tested on the task of the online prediction of wind-speed graph
signals, our model outperforms online graph filtering algorithms in terms of
accuracy, demonstrating the potential of LLMs in effectively addressing
partially observed signals in graphs.

摘要：在本文中，我們提出了一個新穎的框架，該框架利用大型語言模型 (LLM) 來預測時變圖形信號中的缺失值，方法是利用空間和時間平滑度。我們利用 LLM 的能力來實現消息傳遞方案。對於每個缺失節點，其鄰居和先前的估計值會被輸入到 LLM 中並由 LLM 進行處理，以推斷出缺失的觀測值。在風速圖形信號的線上預測任務中進行測試，我們的模型在準確性方面優於線上圖形過濾演算法，這證明了 LLM 在有效處理圖形中部分觀測到的信號方面的潛力。

##### **Gene-Metabolite Association Prediction with Interactive Knowledge Transfer Enhanced Graph for Metabolite Production**
2410.18475v2 by Kexuan Xin, Qingyun Wang, Junyu Chen, Pengfei Yu, Huimin Zhao, Heng Ji

In the rapidly evolving field of metabolic engineering, the quest for
efficient and precise gene target identification for metabolite production
enhancement presents significant challenges. Traditional approaches, whether
knowledge-based or model-based, are notably time-consuming and labor-intensive,
due to the vast scale of research literature and the approximation nature of
genome-scale metabolic model (GEM) simulations. Therefore, we propose a new
task, Gene-Metabolite Association Prediction based on metabolic graphs, to
automate the process of candidate gene discovery for a given pair of metabolite
and candidate-associated genes, as well as presenting the first benchmark
containing 2474 metabolites and 1947 genes of two commonly used microorganisms
Saccharomyces cerevisiae (SC) and Issatchenkia orientalis (IO). This task is
challenging due to the incompleteness of the metabolic graphs and the
heterogeneity among distinct metabolisms. To overcome these limitations, we
propose an Interactive Knowledge Transfer mechanism based on Metabolism Graph
(IKT4Meta), which improves the association prediction accuracy by integrating
the knowledge from different metabolism graphs. First, to build a bridge
between two graphs for knowledge transfer, we utilize Pretrained Language
Models (PLMs) with external knowledge of genes and metabolites to help generate
inter-graph links, significantly alleviating the impact of heterogeneity.
Second, we propagate intra-graph links from different metabolic graphs using
inter-graph links as anchors. Finally, we conduct the gene-metabolite
association prediction based on the enriched metabolism graphs, which integrate
the knowledge from multiple microorganisms. Experiments on both types of
organisms demonstrate that our proposed methodology outperforms baselines by up
to 12.3% across various link prediction frameworks.

摘要：<paragraph>在快速發展的代謝工程領域中，尋求有效且精確的基因目標識別以提升代謝產物產量，是一項重大的挑戰。傳統方法，無論是基於知識或基於模型，都相當耗時且費力，這是因為研究文獻的規模龐大，且基因組規模代謝模型 (GEM) 模擬的近似性質。因此，我們提出了一項新的任務，即基於代謝圖的基因-代謝物關聯預測，以自動化候選基因發現的過程，針對給定的代謝物對和候選相關基因，並呈現第一個基準，其中包含 2474 種代謝物和 1947 個基因，來自兩種常用的微生物釀酒酵母 (SC) 和東方伊薩琴科酵母 (IO)。由於代謝圖的不完整性和不同代謝物之間的異質性，這項任務具有挑戰性。為了克服這些限制，我們提出了一個基於代謝圖的互動知識傳輸機制 (IKT4Meta)，它透過整合來自不同代謝圖的知識來提高關聯預測的準確性。首先，為了在兩個圖之間建立知識傳輸的橋樑，我們利用具備基因和代謝物外部知識的預訓練語言模型 (PLM) 來幫助產生圖間連結，大幅減輕異質性的影響。其次，我們使用圖間連結作為錨點，從不同的代謝圖傳播圖內連結。最後，我們根據整合了多種微生物知識的豐富代謝圖，進行基因-代謝物關聯預測。兩種生物體的實驗都證明，我們提出的方法在各種連結預測架構中，比基準高出 12.3%。</paragraph>

##### **ToolFlow: Boosting LLM Tool-Calling Through Natural and Coherent Dialogue Synthesis**
2410.18447v1 by Zezhong Wang, Xingshan Zeng, Weiwen Liu, Liangyou Li, Yasheng Wang, Lifeng Shang, Xin Jiang, Qun Liu, Kam-Fai Wong

Supervised fine-tuning (SFT) is a common method to enhance the tool calling
capabilities of Large Language Models (LLMs), with the training data often
being synthesized. The current data synthesis process generally involves
sampling a set of tools, formulating a requirement based on these tools, and
generating the call statements. However, tools sampled randomly lack relevance,
making them difficult to combine and thus reducing the diversity of the data.
Additionally, current work overlooks the coherence between turns of dialogues,
leading to a gap between the synthesized data and real-world scenarios. To
address these issues, we propose a Graph-based Sampling strategy to sample more
relevant tool combinations, and a Planned-generation strategy to create plans
that guide the synthesis of coherent dialogues. We integrate these two
strategies and enable multiple agents to synthesize the dialogue data
interactively, resulting in our tool-calling data synthesis pipeline ToolFlow.
Data quality assessments demonstrate improvements in the naturalness and
coherence of our synthesized dialogues. Finally, we apply SFT on LLaMA-3.1-8B
using 8,000 synthetic dialogues generated with ToolFlow. Results show that the
model achieves tool-calling performance comparable to or even surpassing GPT-4,
while maintaining strong general capabilities.

摘要：監督微調 (SFT) 是增強大型語言模型 (LLM) 工具呼叫功能的常見方法，訓練資料通常是合成資料。目前的資料合成流程通常涉及抽樣一組工具、根據這些工具制定需求，並產生呼叫陳述。然而，隨機抽樣的工具缺乏關聯性，使得它們難以組合，從而降低資料的多樣性。此外，目前的工作忽略了對話回合之間的連貫性，導致合成資料與現實世界場景之間存在差距。為了解決這些問題，我們提出了一個基於圖形的抽樣策略來抽取更多相關的工具組合，以及一個計畫生成策略來建立計畫，以引導連貫對話的合成。我們整合這兩種策略，並使多個代理能夠互動地合成對話資料，從而產生我們的工具呼叫資料合成管線 ToolFlow。資料品質評估證明了我們合成對話的自然性和連貫性有了改進。最後，我們使用 ToolFlow 生成的 8,000 個合成對話在 LLaMA-3.1-8B 上應用 SFT。結果表明，該模型實現了與 GPT-4 相當甚至超越 GPT-4 的工具呼叫效能，同時保持強大的通用能力。

##### **Decoding on Graphs: Faithful and Sound Reasoning on Knowledge Graphs through Generation of Well-Formed Chains**
2410.18415v1 by Kun Li, Tianhua Zhang, Xixin Wu, Hongyin Luo, James Glass, Helen Meng

Knowledge Graphs (KGs) can serve as reliable knowledge sources for question
answering (QA) due to their structured representation of knowledge. Existing
research on the utilization of KG for large language models (LLMs) prevalently
relies on subgraph retriever or iterative prompting, overlooking the potential
synergy of LLMs' step-wise reasoning capabilities and KGs' structural nature.
In this paper, we present DoG (Decoding on Graphs), a novel framework that
facilitates a deep synergy between LLMs and KGs. We first define a concept,
well-formed chain, which consists of a sequence of interrelated fact triplets
on the KGs, starting from question entities and leading to answers. We argue
that this concept can serve as a principle for making faithful and sound
reasoning for KGQA. To enable LLMs to generate well-formed chains, we propose
graph-aware constrained decoding, in which a constraint derived from the
topology of the KG regulates the decoding process of the LLMs. This constrained
decoding method ensures the generation of well-formed chains while making full
use of the step-wise reasoning capabilities of LLMs. Based on the above, DoG, a
training-free approach, is able to provide faithful and sound reasoning
trajectories grounded on the KGs. Experiments across various KGQA tasks with
different background KGs demonstrate that DoG achieves superior and robust
performance. DoG also shows general applicability with various open-source
LLMs.

摘要：知識圖譜 (KG) 由於其結構化的知識表示，可用作問答 (QA) 的可靠知識來源。現有關於利用 KG 的大型語言模型 (LLM) 的研究普遍依賴於子圖檢索器或反覆提示，忽視了 LLM 的逐步推理能力和 KG 的結構特性的潛在協同作用。在本文中，我們提出了 DoG（圖形解碼），一個促進 LLM 和 KG 之間深度協同作用的新框架。我們首先定義了一個概念，即良好形成的鏈，它由 KG 上一系列相互關聯的事實三元組組成，從問題實體開始並導致答案。我們認為這個概念可以作為對 KGQA 進行忠實和合理的推理的原則。為了使 LLM 能夠生成良好的鏈，我們提出了圖感知約束解碼，其中源自 KG 拓撲的約束約束了 LLM 的解碼過程。這種受約束的解碼方法確保了良好形成的鏈的生成，同時充分利用了 LLM 的逐步推理能力。基於上述，DoG 是一種無需訓練的方法，能夠提供基於 KG 的忠實且合理的推理軌跡。在具有不同背景 KG 的各種 KGQA 任務中的實驗表明，DoG 達到了卓越且穩健的性能。DoG 還顯示了與各種開源 LLM 的通用適用性。


### Medical explainable AI
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-18**|**Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**|Jeffrey N. Clark et.al.|[2411.11774v1](http://arxiv.org/abs/2411.11774v1)|null|
|**2024-11-15**|**Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**|Mohammed Yaseen Jabarulla et.al.|[2411.10255v1](http://arxiv.org/abs/2411.10255v1)|null|
|**2024-11-01**|**Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**|Mehdi Hosseini Chagahi et.al.|[2411.00916v2](http://arxiv.org/abs/2411.00916v2)|null|
|**2024-10-25**|**A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**|Muath Alsuhaibani et.al.|[2410.19898v1](http://arxiv.org/abs/2410.19898v1)|null|
|**2024-10-23**|**An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**|Shruthi Chari et.al.|[2410.17504v1](http://arxiv.org/abs/2410.17504v1)|[link](https://github.com/tetherless-world/metaexplainer)|
|**2024-10-22**|**Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**|Lukas Hughes-Noehrer et.al.|[2410.16879v1](http://arxiv.org/abs/2410.16879v1)|null|
|**2024-10-19**|**Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**|Gesa Mittmann et.al.|[2410.15012v1](http://arxiv.org/abs/2410.15012v1)|null|
|**2024-10-15**|**Explainable AI Methods for Multi-Omics Analysis: A Survey**|Ahmad Hussein et.al.|[2410.11910v1](http://arxiv.org/abs/2410.11910v1)|null|
|**2024-10-14**|**Study on the Helpfulness of Explainable Artificial Intelligence**|Tobias Labarta et.al.|[2410.11896v1](http://arxiv.org/abs/2410.11896v1)|[link](https://github.com/tlabarta/helpfulnessofxai)|
|**2024-10-12**|**Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**|Abdullah Mamun et.al.|[2410.09635v1](http://arxiv.org/abs/2410.09635v1)|[link](https://github.com/ab9mamun/aimen)|
|**2024-10-10**|**Artificial intelligence techniques in inherited retinal diseases: A review**|Han Trinh et.al.|[2410.09105v1](http://arxiv.org/abs/2410.09105v1)|null|
|**2024-10-07**|**CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**|Ekaterina Sviridova et.al.|[2410.05235v2](http://arxiv.org/abs/2410.05235v2)|[link](https://github.com/ixa-ehu/antidote-casimedicos)|
|**2024-10-01**|**Explainable Diagnosis Prediction through Neuro-Symbolic Integration**|Qiuhao Lu et.al.|[2410.01855v1](http://arxiv.org/abs/2410.01855v1)|null|
|**2024-10-01**|**Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**|Prasenjit Maji et.al.|[2410.00366v1](http://arxiv.org/abs/2410.00366v1)|null|
|**2024-09-20**|**Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**|Tirtha Chanda et.al.|[2409.13476v1](http://arxiv.org/abs/2409.13476v1)|null|
|**2024-09-19**|**Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**|Suryansh Vidya et.al.|[2409.15374v1](http://arxiv.org/abs/2409.15374v1)|null|
|**2024-09-19**|**Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**|Daniel Flores-Araiza et.al.|[2409.12883v1](http://arxiv.org/abs/2409.12883v1)|null|
|**2024-09-18**|**Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**|Yubo Li et.al.|[2409.12087v3](http://arxiv.org/abs/2409.12087v3)|null|
|**2024-09-09**|**Explainable AI: Definition and attributes of a good explanation for health AI**|Evangelia Kyrimi et.al.|[2409.15338v1](http://arxiv.org/abs/2409.15338v1)|null|
|**2024-08-30**|**Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**|Antonio Rago et.al.|[2408.17401v1](http://arxiv.org/abs/2408.17401v1)|null|
|**2024-08-29**|**A Survey for Large Language Models in Biomedicine**|Chong Wang et.al.|[2409.00133v1](http://arxiv.org/abs/2409.00133v1)|null|
|**2024-08-27**|**Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**|Francesco Sovrano et.al.|[2408.15121v1](http://arxiv.org/abs/2408.15121v1)|null|
|**2024-08-24**|**Towards Case-based Interpretability for Medical Federated Learning**|Laura Latorre et.al.|[2408.13626v1](http://arxiv.org/abs/2408.13626v1)|null|
|**2024-08-22**|**AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**|Douwe J. Spaanderman et.al.|[2408.12491v1](http://arxiv.org/abs/2408.12491v1)|null|
|**2024-08-14**|**Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**|Kimji N. Pellano et.al.|[2409.00001v1](http://arxiv.org/abs/2409.00001v1)|null|
|**2024-08-06**|**MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**|Hanchen David Wang et.al.|[2408.11837v1](http://arxiv.org/abs/2408.11837v1)|null|
|**2024-08-05**|**The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**|Joshua Morriss et.al.|[2408.05239v1](http://arxiv.org/abs/2408.05239v1)|null|
|**2024-08-05**|**Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**|Chi Him Ng et.al.|[2408.02709v1](http://arxiv.org/abs/2408.02709v1)|null|
|**2024-08-05**|**Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**|Masoud Muhammed Hassan et.al.|[2408.02706v1](http://arxiv.org/abs/2408.02706v1)|null|
|**2024-07-26**|**MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**|Shyam Dongre et.al.|[2407.20284v1](http://arxiv.org/abs/2407.20284v1)|null|
|**2024-07-25**|**Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**|Alessandro De Carlo et.al.|[2407.18343v2](http://arxiv.org/abs/2407.18343v2)|null|
|**2024-07-24**|**Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**|Nikolaos Ntampakis et.al.|[2407.17324v2](http://arxiv.org/abs/2407.17324v2)|null|
|**2024-07-24**|**Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**|Michele Fiori et.al.|[2408.06352v1](http://arxiv.org/abs/2408.06352v1)|null|
|**2024-07-21**|**Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**|Naseem Khan et.al.|[2408.03335v1](http://arxiv.org/abs/2408.03335v1)|null|
|**2024-07-18**|**A Comparative Study on Automatic Coding of Medical Letters with Explainability**|Jamie Glen et.al.|[2407.13638v1](http://arxiv.org/abs/2407.13638v1)|[link](https://github.com/Glenj01/Medical-Coding)|
|**2024-07-09**|**Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**|Abdul Karim Gizzini et.al.|[2407.07009v1](http://arxiv.org/abs/2407.07009v1)|null|
|**2024-07-07**|**Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**|P. N. Karthikayan et.al.|[2407.05440v2](http://arxiv.org/abs/2407.05440v2)|null|
|**2024-07-03**|**A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**|Congzhen Shi et.al.|[2407.15851v2](http://arxiv.org/abs/2407.15851v2)|null|
|**2024-07-01**|**The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**|Ximing Wen et.al.|[2407.06206v1](http://arxiv.org/abs/2407.06206v1)|null|
|**2024-06-28**|**Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**|Sai Krishna Revanth Vuruma et.al.|[2407.00167v1](http://arxiv.org/abs/2407.00167v1)|null|
|**2024-06-25**|**Towards Compositional Interpretability for XAI**|Sean Tull et.al.|[2406.17583v1](http://arxiv.org/abs/2406.17583v1)|null|
|**2024-06-17**|**Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**|Vincent Olesen et.al.|[2406.12142v2](http://arxiv.org/abs/2406.12142v2)|[link](https://github.com/volesen/slicing-through-bias)|
|**2024-06-11**|**Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**|Fatemeh Ebrahimzadeh et.al.|[2406.07114v2](http://arxiv.org/abs/2406.07114v2)|null|
|**2024-06-10**|**AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**|K M Tawsik Jawad et.al.|[2406.06728v1](http://arxiv.org/abs/2406.06728v1)|null|
|**2024-06-10**|**Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**|Yusif Ibrahimov et.al.|[2406.05984v1](http://arxiv.org/abs/2406.05984v1)|null|
|**2024-06-09**|**Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**|Zhan Zhang et.al.|[2406.05746v1](http://arxiv.org/abs/2406.05746v1)|null|
|**2024-06-07**|**Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**|Faseela Abdullakutty et.al.|[2406.12897v1](http://arxiv.org/abs/2406.12897v1)|null|
|**2024-06-07**|**Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**|Yong-Min Shin et.al.|[2406.04612v1](http://arxiv.org/abs/2406.04612v1)|[link](https://github.com/jordan7186/gatt)|
|**2024-06-04**|**Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**|Dinuka Sandun Udayantha et.al.|[2406.16908v3](http://arxiv.org/abs/2406.16908v3)|[link](https://github.com/dinuka-1999/braineocare)|
|**2024-06-01**|**Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**|Samita Bai et.al.|[2406.00532v1](http://arxiv.org/abs/2406.00532v1)|null|
|**2024-06-01**|**Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**|Alaa Nfissi et.al.|[2406.01624v2](http://arxiv.org/abs/2406.01624v2)|[link](https://github.com/alaanfissi/unveiling-hidden-factors-explainable-ai-for-feature-boosting-in-speech-emotion-recognition)|
|**2024-05-31**|**The Explanation Necessity for Healthcare AI**|Michail Mamalakis et.al.|[2406.00216v1](http://arxiv.org/abs/2406.00216v1)|null|
|**2024-05-29**|**Interdisciplinary Expertise to Advance Equitable Explainable AI**|Chloe R. Bennett et.al.|[2406.18563v1](http://arxiv.org/abs/2406.18563v1)|null|
|**2024-05-27**|**"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**|Hubert D. Zając et.al.|[2407.11978v1](http://arxiv.org/abs/2407.11978v1)|null|
|**2024-05-26**|**Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**|Min Hun Lee et.al.|[2405.16424v1](http://arxiv.org/abs/2405.16424v1)|null|
|**2024-05-26**|**Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**|Ziming Liu et.al.|[2405.17502v1](http://arxiv.org/abs/2405.17502v1)|null|
|**2024-05-24**|**Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**|Catalina Gomez et.al.|[2407.11974v1](http://arxiv.org/abs/2407.11974v1)|null|
|**2024-05-23**|**Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**|Yingying Fang et.al.|[2406.18552v1](http://arxiv.org/abs/2406.18552v1)|null|
|**2024-05-21**|**The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**|Mohsen Jozani et.al.|[2405.13099v1](http://arxiv.org/abs/2405.13099v1)|null|
|**2024-05-17**|**ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**|Harris Bin Munawar et.al.|[2405.10645v1](http://arxiv.org/abs/2405.10645v1)|null|
|**2024-05-13**|**Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**|Camelia Oprea et.al.|[2405.07590v1](http://arxiv.org/abs/2405.07590v1)|null|
|**2024-05-10**|**XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**|Fatemeh Nazary et.al.|[2405.06270v3](http://arxiv.org/abs/2405.06270v3)|null|
|**2024-05-09**|**To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**|Miquel Miró-Nicolau et.al.|[2405.05766v1](http://arxiv.org/abs/2405.05766v1)|null|
|**2024-05-05**|**Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**|Zhusi Zhong et.al.|[2405.02815v1](http://arxiv.org/abs/2405.02815v1)|[link](https://github.com/zzs95/RSP_COVID)|
|**2024-04-26**|**Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**|Francesco Prinzi et.al.|[2405.02334v1](http://arxiv.org/abs/2405.02334v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v2](http://arxiv.org/abs/2404.12832v2)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-15**|**Hybrid Intelligence for Digital Humanities**|Victor de Boer et.al.|[2406.15374v1](http://arxiv.org/abs/2406.15374v1)|null|
|**2024-04-14**|**Ethical Framework for Responsible Foundational Models in Medical Imaging**|Abhijit Das et.al.|[2406.11868v1](http://arxiv.org/abs/2406.11868v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-06**|**Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**|Taminul Islam et.al.|[2404.04686v1](http://arxiv.org/abs/2404.04686v1)|null|
|**2024-04-05**|**Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**|Maryam Ahmed et.al.|[2404.03892v3](http://arxiv.org/abs/2404.03892v3)|null|
|**2024-03-30**|**Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**|Xingrui Gu et.al.|[2404.00320v2](http://arxiv.org/abs/2404.00320v2)|null|
|**2024-03-26**|**Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**|Andrea Ferrario et.al.|[2403.17873v1](http://arxiv.org/abs/2403.17873v1)|null|
|**2024-03-26**|**Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**|Han Yuan et.al.|[2403.18871v1](http://arxiv.org/abs/2403.18871v1)|[link](https://github.com/han-yuan-med/template-explanation)|
|**2024-03-03**|**Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**|Séamus Lankford et.al.|[2403.01580v1](http://arxiv.org/abs/2403.01580v1)|null|
|**2024-02-28**|**Cause and Effect: Can Large Language Models Truly Understand Causality?**|Swagata Ashwani et.al.|[2402.18139v3](http://arxiv.org/abs/2402.18139v3)|null|
|**2024-02-28**|**Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**|Yasin Sadeghi Bazargani et.al.|[2402.18600v1](http://arxiv.org/abs/2402.18600v1)|null|
|**2024-02-22**|**Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**|A. J. Karran et.al.|[2402.15027v2](http://arxiv.org/abs/2402.15027v2)|null|
|**2024-02-12**|**Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**|Aruna Mohan et.al.|[2402.09474v2](http://arxiv.org/abs/2402.09474v2)|null|
|**2024-02-05**|**Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**|Aryan Agrawal et.al.|[2402.05127v1](http://arxiv.org/abs/2402.05127v1)|null|
|**2024-01-24**|**Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**|Timothée Schmude et.al.|[2401.13324v6](http://arxiv.org/abs/2401.13324v6)|null|
|**2024-01-02**|**Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**|Vahid Ashrafimoghari et.al.|[2401.02985v1](http://arxiv.org/abs/2401.02985v1)|null|
|**2023-12-29**|**XAI for In-hospital Mortality Prediction via Multimodal ICU Data**|Xingqiao Li et.al.|[2312.17624v1](http://arxiv.org/abs/2312.17624v1)|[link](https://github.com/lixingqiao/xai-icu)|
|**2023-12-22**|**Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**|Norman Zerbe et.al.|[2401.09450v2](http://arxiv.org/abs/2401.09450v2)|null|
|**2023-12-18**|**Robust Stochastic Graph Generator for Counterfactual Explanations**|Mario Alfonso Prado-Romero et.al.|[2312.11747v2](http://arxiv.org/abs/2312.11747v2)|null|
|**2023-12-10**|**Evaluating the Utility of Model Explanations for Model Development**|Shawn Im et.al.|[2312.06032v1](http://arxiv.org/abs/2312.06032v1)|null|
|**2023-12-05**|**Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**|Manas Gaur et.al.|[2312.06798v1](http://arxiv.org/abs/2312.06798v1)|null|
|**2023-12-04**|**Class-Discriminative Attention Maps for Vision Transformers**|Lennart Brocki et.al.|[2312.02364v3](http://arxiv.org/abs/2312.02364v3)|null|
|**2023-11-28**|**Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**|Jacob R. Epifano et.al.|[2311.17133v1](http://arxiv.org/abs/2311.17133v1)|null|
|**2023-11-27**|**Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**|Benjamin Keel et.al.|[2311.15719v1](http://arxiv.org/abs/2311.15719v1)|[link](https://github.com/benkeel/vae_lung_lesion_bmvc)|
|**2023-11-24**|**MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**|Nathan Blake et.al.|[2311.14471v1](http://arxiv.org/abs/2311.14471v1)|null|
|**2023-11-21**|**Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**|Robert Gorwa et.al.|[2311.12573v3](http://arxiv.org/abs/2311.12573v3)|null|
|**2023-11-20**|**Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**|Muta Tah Hira et.al.|[2311.11932v1](http://arxiv.org/abs/2311.11932v1)|null|
|**2023-11-18**|**Representing visual classification as a linear combination of words**|Shobhit Agarwal et.al.|[2311.10933v1](http://arxiv.org/abs/2311.10933v1)|[link](https://github.com/lotterlab/task_word_explainability)|
|**2023-11-03**|**Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**|Emma A. M. Stanley et.al.|[2311.02115v2](http://arxiv.org/abs/2311.02115v2)|[link](https://github.com/estanley16/simba)|
|**2023-10-29**|**Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**|Adam White et.al.|[2310.19174v1](http://arxiv.org/abs/2310.19174v1)|null|
|**2023-10-03**|**Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**|Hossein Shreim et.al.|[2310.01828v2](http://arxiv.org/abs/2310.01828v2)|[link](https://github.com/geoaigroup/geoai-ecrs2023)|

#### Abstracts
##### **Exploring the Requirements of Clinicians for Explainable AI Decision Support Systems in Intensive Care**
2411.11774v1 by Jeffrey N. Clark, Matthew Wragg, Emily Nielsen, Miquel Perello-Nieto, Nawid Keshtmand, Michael Ambler, Shiv Sharma, Christopher P. Bourdeaux, Amberly Brigden, Raul Santos-Rodriguez

There is a growing need to understand how digital systems can support
clinical decision-making, particularly as artificial intelligence (AI) models
become increasingly complex and less human-interpretable. This complexity
raises concerns about trustworthiness, impacting safe and effective adoption of
such technologies. Improved understanding of decision-making processes and
requirements for explanations coming from decision support tools is a vital
component in providing effective explainable solutions. This is particularly
relevant in the data-intensive, fast-paced environments of intensive care units
(ICUs). To explore these issues, group interviews were conducted with seven ICU
clinicians, representing various roles and experience levels. Thematic analysis
revealed three core themes: (T1) ICU decision-making relies on a wide range of
factors, (T2) the complexity of patient state is challenging for shared
decision-making, and (T3) requirements and capabilities of AI decision support
systems. We include design recommendations from clinical input, providing
insights to inform future AI systems for intensive care.

摘要：隨著人工智慧 (AI) 模型變得越來越複雜，且越來越難以被人理解，了解數位系統如何支援臨床決策的需求也日益增加。這種複雜性引發了對可信度的疑慮，影響了此類技術的安全且有效採用。改善對決策制定流程的理解，以及對決策支援工具所提供說明的要求，是提供有效可解釋解決方案的重要組成部分。這在資料密集、快節奏的加護病房 (ICU) 環境中特別相關。為了探討這些問題，對七位 ICU 臨床醫師進行了小組訪談，這些醫師代表了不同的角色和經驗層級。主題分析揭露了三個核心主題：(T1) ICU 決策制定依賴於廣泛的因素，(T2) 病患狀態的複雜性對共同決策制定構成挑戰，以及 (T3) AI 決策支援系統的要求和能力。我們納入了臨床輸入的設計建議，提供見解以提供資訊給未來用於加護的 AI 系統。

##### **Artificial Intelligence in Pediatric Echocardiography: Exploring Challenges, Opportunities, and Clinical Applications with Explainable AI and Federated Learning**
2411.10255v1 by Mohammed Yaseen Jabarulla, Theodor Uden, Thomas Jack, Philipp Beerbaum, Steffen Oeltze-Jafra

Pediatric heart diseases present a broad spectrum of congenital and acquired
diseases. More complex congenital malformations require a differentiated and
multimodal decision-making process, usually including echocardiography as a
central imaging method. Artificial intelligence (AI) offers considerable
promise for clinicians by facilitating automated interpretation of pediatric
echocardiography data. However, adapting AI technologies for pediatric
echocardiography analysis has challenges such as limited public data
availability, data privacy, and AI model transparency. Recently, researchers
have focused on disruptive technologies, such as federated learning (FL) and
explainable AI (XAI), to improve automatic diagnostic and decision support
workflows. This study offers a comprehensive overview of the limitations and
opportunities of AI in pediatric echocardiography, emphasizing the synergistic
workflow and role of XAI and FL, identifying research gaps, and exploring
potential future developments. Additionally, three relevant clinical use cases
demonstrate the functionality of XAI and FL with a focus on (i) view
recognition, (ii) disease classification, (iii) segmentation of cardiac
structures, and (iv) quantitative assessment of cardiac function.

摘要：小兒心臟疾病呈現先天性與後天性疾病的廣泛光譜。較複雜的先天性畸形需要一個差異化且多模式的決策過程，通常包括超音波檢查作為主要的影像方法。人工智慧 (AI) 為臨床醫生提供了相當大的希望，因為它可以促進小兒超音波檢查資料的自動化解讀。然而，將人工智慧技術應用於小兒超音波檢查分析有許多挑戰，例如有限的公開資料可用性、資料隱私和人工智慧模型透明度。最近，研究人員專注於破壞性技術，例如聯合學習 (FL) 和可解釋人工智慧 (XAI)，以改善自動診斷和決策支援工作流程。本研究提供了人工智慧在小兒超音波檢查中的限制和機會的全面概述，強調了 XAI 和 FL 的協同工作流程和角色，找出研究差距並探討潛在的未來發展。此外，三個相關的臨床使用案例展示了 XAI 和 FL 的功能，重點在於 (i) 檢視辨識、(ii) 疾病分類、(iii) 心臟結構分割和 (iv) 心臟功能的量化評估。

##### **Enhancing Osteoporosis Detection: An Explainable Multi-Modal Learning Framework with Feature Fusion and Variable Clustering**
2411.00916v2 by Mehdi Hosseini Chagahi, Saeed Mohammadi Dashtaki, Niloufar Delfan, Nadia Mohammadi, Alireza Samari, Behzad Moshiri, Md. Jalil Piran, Oliver Faust

Osteoporosis is a common condition that increases fracture risk, especially
in older adults. Early diagnosis is vital for preventing fractures, reducing
treatment costs, and preserving mobility. However, healthcare providers face
challenges like limited labeled data and difficulties in processing medical
images. This study presents a novel multi-modal learning framework that
integrates clinical and imaging data to improve diagnostic accuracy and model
interpretability. The model utilizes three pre-trained networks-VGG19,
InceptionV3, and ResNet50-to extract deep features from X-ray images. These
features are transformed using PCA to reduce dimensionality and focus on the
most relevant components. A clustering-based selection process identifies the
most representative components, which are then combined with preprocessed
clinical data and processed through a fully connected network (FCN) for final
classification. A feature importance plot highlights key variables, showing
that Medical History, BMI, and Height were the main contributors, emphasizing
the significance of patient-specific data. While imaging features were
valuable, they had lower importance, indicating that clinical data are crucial
for accurate predictions. This framework promotes precise and interpretable
predictions, enhancing transparency and building trust in AI-driven diagnoses
for clinical integration.

摘要：骨質疏鬆症是一種常見的疾病，會增加骨折的風險，特別是老年人。早期診斷對於預防骨折、降低治療成本和維持行動能力至關重要。然而，醫療保健提供者面臨著標記數據有限和處理醫學影像困難等挑戰。本研究提出了一個新穎的多模式學習框架，該框架整合了臨床和影像數據，以提高診斷準確性和模型可解釋性。該模型利用三個預訓練的網路，VGG19、InceptionV3 和 ResNet50，從 X 射線影像中提取深度特徵。這些特徵使用 PCA 轉換以降低維度並專注於最相關的組成部分。基於聚類的選擇過程識別出最具代表性的組成部分，然後將這些組成部分與預處理的臨床數據結合，並通過全連接網路 (FCN) 進行最終分類。特徵重要性圖突出了關鍵變數，表明病史、BMI 和身高是主要貢獻因素，強調了患者特定數據的重要性。雖然影像特徵很有價值，但它們的重要性較低，這表明臨床數據對於準確預測至關重要。此框架促进了準確且可解釋的預測，提高了透明度，並建立了對 AI 驅動診斷在臨床整合中的信任。

##### **A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection**
2410.19898v1 by Muath Alsuhaibani, Ali Pourramezan Fard, Jian Sun, Farida Far Poor, Peter S. Pressman, Mohammad H. Mahoor

This review paper explores recent advances in deep learning approaches for
non-invasive cognitive impairment detection. We examine various non-invasive
indicators of cognitive decline, including speech and language, facial, and
motoric mobility. The paper provides an overview of relevant datasets,
feature-extracting techniques, and deep-learning architectures applied to this
domain. We have analyzed the performance of different methods across modalities
and observed that speech and language-based methods generally achieved the
highest detection performance. Studies combining acoustic and linguistic
features tended to outperform those using a single modality. Facial analysis
methods showed promise for visual modalities but were less extensively studied.
Most papers focused on binary classification (impaired vs. non-impaired), with
fewer addressing multi-class or regression tasks. Transfer learning and
pre-trained language models emerged as popular and effective techniques,
especially for linguistic analysis. Despite significant progress, several
challenges remain, including data standardization and accessibility, model
explainability, longitudinal analysis limitations, and clinical adaptation.
Lastly, we propose future research directions, such as investigating
language-agnostic speech analysis methods, developing multi-modal diagnostic
systems, and addressing ethical considerations in AI-assisted healthcare. By
synthesizing current trends and identifying key obstacles, this review aims to
guide further development of deep learning-based cognitive impairment detection
systems to improve early diagnosis and ultimately patient outcomes.

摘要：本篇評論探討了深度學習方法在非侵入式認知功能障礙檢測上的最新進展。我們檢視了各種非侵入式的認知衰退指標，包括語言和語言、面部和運動機能。本文概述了與此領域相關的資料集、特徵提取技術和深度學習架構。我們分析了不同方法在不同方式上的表現，並觀察到基於語言和語言的方法通常能達到最高的檢測表現。結合聲學和語言特徵的研究往往優於使用單一方式的研究。面部分析方法顯示出視覺方式的潛力，但研究較少。大多數論文專注於二元分類（受損與未受損），較少探討多類或回歸任務。遷移學習和預訓練語言模型已成為流行且有效的技術，特別是對於語言分析。儘管取得了重大進展，但仍存在一些挑戰，包括資料標準化和可及性、模型可解釋性、縱向分析限制和臨床適應性。最後，我們提出了未來的研究方向，例如調查與語言無關的語音分析方法、開發多模式診斷系統，以及解決人工智慧輔助醫療保健中的倫理考量。透過綜合目前的趨勢和找出關鍵障礙，本篇評論旨在引導深度學習為基礎的認知功能障礙檢測系統的進一步發展，以改善早期診斷，並最終改善患者的治療結果。

##### **An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems**
2410.17504v1 by Shruthi Chari

Explainable Artificial Intelligence (AI) focuses on helping humans understand
the working of AI systems or their decisions and has been a cornerstone of AI
for decades. Recent research in explainability has focused on explaining the
workings of AI models or model explainability. There have also been several
position statements and review papers detailing the needs of end-users for
user-centered explainability but fewer implementations. Hence, this thesis
seeks to bridge some gaps between model and user-centered explainability. We
create an explanation ontology (EO) to represent literature-derived explanation
types via their supporting components. We implement a knowledge-augmented
question-answering (QA) pipeline to support contextual explanations in a
clinical setting. Finally, we are implementing a system to combine explanations
from different AI methods and data modalities. Within the EO, we can represent
fifteen different explanation types, and we have tested these representations
in six exemplar use cases. We find that knowledge augmentations improve the
performance of base large language models in the contextualized QA, and the
performance is variable across disease groups. In the same setting, clinicians
also indicated that they prefer to see actionability as one of the main foci in
explanations. In our explanations combination method, we plan to use similarity
metrics to determine the similarity of explanations in a chronic disease
detection setting. Overall, through this thesis, we design methods that can
support knowledge-enabled explanations across different use cases, accounting
for the methods in today's AI era that can generate the supporting components
of these explanations and domain knowledge sources that can enhance them.

摘要：可解釋人工智慧（AI）專注於協助人類了解 AI 系統運作或其決策，數十年來一直是 AI 的基石。最近的可解釋性研究專注於解釋 AI 模型或模型可解釋性的運作。也有幾份立場聲明和評論論文詳細說明了最終使用者對以使用者為中心的可解釋性的需求，但實作較少。因此，本論文旨在彌補模型和以使用者為中心的可解釋性之間的一些差距。我們建立一個解釋本體（EO）以透過其支援元件來表示從文獻中衍生的解釋類型。我們實作一個知識增強的問答（QA）管線，以在臨床環境中支援情境解釋。最後，我們正在實作一個系統，以結合來自不同 AI 方法和資料模式的解釋。在 EO 中，我們可以表示 15 種不同的解釋類型，並且我們已在六個範例使用案例中測試這些表示。我們發現，知識增強改善了基礎大型語言模型在情境化 QA 中的效能，並且效能因疾病群組而異。在相同的環境中，臨床醫生也表示他們希望將可操作性視為解釋中的主要焦點之一。在我們的解釋組合方法中，我們計畫使用相似性指標來確定慢性病偵測環境中解釋的相似性。總體而言，透過本論文，我們設計了可以在不同使用案例中支援知識啟用解釋的方法，考量到當今 AI 時代中可以產生這些解釋的支援元件和可以增強這些解釋的領域知識來源的方法。

##### **Contrasting Attitudes Towards Current and Future AI Applications for Computerised Interpretation of ECG: A Clinical Stakeholder Interview Study**
2410.16879v1 by Lukas Hughes-Noehrer, Leda Channer, Gabriel Strain, Gregory Yates, Richard Body, Caroline Jay

Objectives: To investigate clinicians' attitudes towards current automated
interpretation of ECG and novel AI technologies and their perception of
computer-assisted interpretation. Materials and Methods: We conducted a series
of interviews with clinicians in the UK. Our study: (i) explores the potential
for AI, specifically future 'human-like' computing approaches, to facilitate
ECG interpretation and support clinical decision making, and (ii) elicits their
opinions about the importance of explainability and trustworthiness of AI
algorithms. Results: We performed inductive thematic analysis on interview
transcriptions from 23 clinicians and identified the following themes: (i) a
lack of trust in current systems, (ii) positive attitudes towards future AI
applications and requirements for these, (iii) the relationship between the
accuracy and explainability of algorithms, and (iv) opinions on education,
possible deskilling, and the impact of AI on clinical competencies. Discussion:
Clinicians do not trust current computerised methods, but welcome future 'AI'
technologies. Where clinicians trust future AI interpretation to be accurate,
they are less concerned that it is explainable. They also preferred ECG
interpretation that demonstrated the results of the algorithm visually. Whilst
clinicians do not fear job losses, they are concerned about deskilling and the
need to educate the workforce to use AI responsibly. Conclusion: Clinicians are
positive about the future application of AI in clinical decision-making.
Accuracy is a key factor of uptake and visualisations are preferred over
current computerised methods. This is viewed as a potential means of training
and upskilling, in contrast to the deskilling that automation might be
perceived to bring.

摘要：<paragraph>目的：調查臨床醫生對目前自動化心電圖解讀和新的人工智慧技術的態度，以及他們對電腦輔助解讀的看法。材料和方法：我們對英國的臨床醫生進行了一系列訪談。我們的研究：(i) 探討人工智慧的潛力，特別是未來的「類人類」運算方法，以促進心電圖解讀並支持臨床決策制定，以及 (ii) 徵求他們對人工智慧演算法的可解釋性和可信度的看法。結果：我們對 23 位臨床醫生的訪談記錄進行了歸納主題分析，並找出以下主題：(i) 對目前系統缺乏信任，(ii) 對未來人工智慧應用和對這些應用的要求持正面態度，(iii) 演算法的準確性和可解釋性之間的關係，以及 (iv) 對教育、可能的技能退化，以及人工智慧對臨床能力的影響的看法。討論：臨床醫生不信任目前的電腦化方法，但歡迎未來的「人工智慧」技術。在臨床醫生相信未來的 AI 解讀準確的情況下，他們不太擔心它是否可解釋。他們也比較喜歡能以視覺方式呈現演算法結果的心電圖解讀。雖然臨床醫生不害怕失業，但他們擔心技能退化，以及需要教育員工負責任地使用人工智慧。結論：臨床醫生對人工智慧在臨床決策制定中的未來應用持正面態度。準確性是採用人工智慧的一個關鍵因素，而視覺化比目前的電腦化方法更受青睞。這被視為一種潛在的培訓和提升技能的方法，與自動化可能帶來的技能退化形成對比。</paragraph>

##### **Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer**
2410.15012v1 by Gesa Mittmann, Sara Laiouar-Pedari, Hendrik A. Mehrtens, Sarah Haggenmüller, Tabea-Clara Bucher, Tirtha Chanda, Nadine T. Gaisa, Mathias Wagner, Gilbert Georg Klamminger, Tilman T. Rau, Christina Neppl, Eva Maria Compérat, Andreas Gocht, Monika Hämmerle, Niels J. Rupp, Jula Westhoff, Irene Krücken, Maximillian Seidl, Christian M. Schürch, Marcus Bauer, Wiebke Solass, Yu Chun Tam, Florian Weber, Rainer Grobholz, Jaroslaw Augustyniak, Thomas Kalinski, Christian Hörner, Kirsten D. Mertz, Constanze Döring, Andreas Erbersdobler, Gabriele Deubler, Felix Bremmer, Ulrich Sommer, Michael Brodhun, Jon Griffin, Maria Sarah L. Lenon, Kiril Trpkov, Liang Cheng, Fei Chen, Angelique Levi, Guoping Cai, Tri Q. Nguyen, Ali Amin, Alessia Cimadamore, Ahmed Shabaik, Varsha Manucha, Nazeel Ahmad, Nidia Messias, Francesca Sanguedolce, Diana Taheri, Ezra Baraban, Liwei Jia, Rajal B. Shah, Farshid Siadat, Nicole Swarbrick, Kyung Park, Oudai Hassan, Siamak Sakhaie, Michelle R. Downes, Hiroshi Miyamoto, Sean R. Williamson, Tim Holland-Letz, Carolin V. Schneider, Jakob Nikolas Kather, Yuri Tolkach, Titus J. Brinker

The aggressiveness of prostate cancer, the most common cancer in men
worldwide, is primarily assessed based on histopathological data using the
Gleason scoring system. While artificial intelligence (AI) has shown promise in
accurately predicting Gleason scores, these predictions often lack inherent
explainability, potentially leading to distrust in human-machine interactions.
To address this issue, we introduce a novel dataset of 1,015 tissue microarray
core images, annotated by an international group of 54 pathologists. The
annotations provide detailed localized pattern descriptions for Gleason grading
in line with international guidelines. Utilizing this dataset, we develop an
inherently explainable AI system based on a U-Net architecture that provides
predictions leveraging pathologists' terminology. This approach circumvents
post-hoc explainability methods while maintaining or exceeding the performance
of methods trained directly for Gleason pattern segmentation (Dice score: 0.713
$\pm$ 0.003 trained on explanations vs. 0.691 $\pm$ 0.010 trained on Gleason
patterns). By employing soft labels during training, we capture the intrinsic
uncertainty in the data, yielding strong results in Gleason pattern
segmentation even in the context of high interobserver variability. With the
release of this dataset, we aim to encourage further research into segmentation
in medical tasks with high levels of subjectivity and to advance the
understanding of pathologists' reasoning processes.

摘要：前列腺癌是全球男性最常見的癌症，其惡性程度主要根據 Gleason 評分系統使用組織病理學數據進行評估。雖然人工智慧 (AI) 在準確預測 Gleason 評分方面已展現潛力，但這些預測通常缺乏內在的可解釋性，可能會導致對人機互動的不信任。為了解決這個問題，我們引進了一個由 54 位病理學家組成的國際團隊註解的 1,015 個組織微陣列核心影像的新穎資料集。這些註解提供了詳細的局部模式描述，用於符合國際準則的 Gleason 分級。利用這個資料集，我們開發了一個基於 U-Net 架構的內在可解釋 AI 系統，該系統提供了利用病理學家術語進行預測。這種方法規避了事後可解釋性方法，同時維持或超越了直接訓練用於 Gleason 模式分割的方法的效能（Dice 分數：0.713 ± 0.003，訓練於解釋，相對於 0.691 ± 0.010，訓練於 Gleason 模式）。透過在訓練期間採用軟標籤，我們捕捉了資料中的內在不確定性，即使在觀察者間變異性高的情況下，也能在 Gleason 模式分割中產生強大的結果。透過釋出這個資料集，我們旨在鼓勵進一步研究主觀性高的醫療任務中的分割，並增進對病理學家推理過程的理解。

##### **Explainable AI Methods for Multi-Omics Analysis: A Survey**
2410.11910v1 by Ahmad Hussein, Mukesh Prasad, Ali Braytee

Advancements in high-throughput technologies have led to a shift from
traditional hypothesis-driven methodologies to data-driven approaches.
Multi-omics refers to the integrative analysis of data derived from multiple
'omes', such as genomics, proteomics, transcriptomics, metabolomics, and
microbiomics. This approach enables a comprehensive understanding of biological
systems by capturing different layers of biological information. Deep learning
methods are increasingly utilized to integrate multi-omics data, offering
insights into molecular interactions and enhancing research into complex
diseases. However, these models, with their numerous interconnected layers and
nonlinear relationships, often function as black boxes, lacking transparency in
decision-making processes. To overcome this challenge, explainable artificial
intelligence (xAI) methods are crucial for creating transparent models that
allow clinicians to interpret and work with complex data more effectively. This
review explores how xAI can improve the interpretability of deep learning
models in multi-omics research, highlighting its potential to provide
clinicians with clear insights, thereby facilitating the effective application
of such models in clinical settings.

摘要：高通量技術的進步導致從傳統的假設驅動方法轉變為資料驅動的方法。多組學是指整合分析來自多個「組學」的資料，例如基因組學、蛋白質組學、轉錄組學、代謝組學和微生物組學。此方法透過擷取生物資訊的不同層面，能全面了解生物系統。深度學習方法愈來愈常被用於整合多組學資料，提供分子交互作用的洞察力，並加強對複雜疾病的研究。然而，這些模型具有許多相互連接的層級和非線性關係，通常會像黑盒子一樣運作，缺乏決策過程的透明度。為了克服此挑戰，可解釋人工智慧 (xAI) 方法對於建立透明模型至關重要，讓臨床醫生可以更有效地解釋和處理複雜資料。此評論探討 xAI 如何能改善多組學研究中深度學習模型的可解釋性，強調其提供臨床醫生明確見解的潛力，進而促進此類模型在臨床環境中的有效應用。

##### **Study on the Helpfulness of Explainable Artificial Intelligence**
2410.11896v1 by Tobias Labarta, Elizaveta Kulicheva, Ronja Froelian, Christian Geißler, Xenia Melman, Julian von Klitzing

Explainable Artificial Intelligence (XAI) is essential for building advanced
machine learning-powered applications, especially in critical domains such as
medical diagnostics or autonomous driving. Legal, business, and ethical
requirements motivate using effective XAI, but the increasing number of
different methods makes it challenging to pick the right ones. Further, as
explanations are highly context-dependent, measuring the effectiveness of XAI
methods without users can only reveal a limited amount of information,
excluding human factors such as the ability to understand it. We propose to
evaluate XAI methods via the user's ability to successfully perform a proxy
task, designed such that a good performance is an indicator for the explanation
to provide helpful information. In other words, we address the helpfulness of
XAI for human decision-making. Further, a user study on state-of-the-art
methods was conducted, showing differences in their ability to generate trust
and skepticism and the ability to judge the rightfulness of an AI decision
correctly. Based on the results, we highly recommend using and extending this
approach for more objective-based human-centered user studies to measure XAI
performance in an end-to-end fashion.

摘要：可解釋人工智慧 (XAI) 對於建構先進的機器學習驅動應用程式至關重要，特別是在醫療診斷或自動駕駛等關鍵領域。法律、商業和倫理要求促使使用有效的 XAI，但數量日益增加的不同方法使得挑選正確的方法具有挑戰性。此外，由於解釋高度依賴於背景，在沒有使用者的情況下衡量 XAI 方法的有效性只能揭示有限的資訊，排除人類因素，例如理解它的能力。我們建議透過使用者成功執行代理任務的能力來評估 XAI 方法，設計使得良好的執行表現是解釋提供有用資訊的指標。換句話說，我們探討 XAI 對人類決策制定的幫助。此外，對最先進的方法進行使用者研究，顯示出它們在產生信任和懷疑的能力以及正確判斷 AI 決策是否正確的能力方面存在差異。根據結果，我們強烈建議使用和擴充這種方法，以進行更多以目標為基礎的人為中心使用者研究，以終端到終端的方式衡量 XAI 效能。

##### **Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health**
2410.09635v1 by Abdullah Mamun, Lawrence D. Devoe, Mark I. Evans, David W. Britt, Judith Klein-Seetharaman, Hassan Ghasemzadeh

Early detection of intrapartum risk enables interventions to potentially
prevent or mitigate adverse labor outcomes such as cerebral palsy. Currently,
there is no accurate automated system to predict such events to assist with
clinical decision-making. To fill this gap, we propose "Artificial Intelligence
(AI) for Modeling and Explaining Neonatal Health" (AIMEN), a deep learning
framework that not only predicts adverse labor outcomes from maternal, fetal,
obstetrical, and intrapartum risk factors but also provides the model's
reasoning behind the predictions made. The latter can provide insights into
what modifications in the input variables of the model could have changed the
predicted outcome. We address the challenges of imbalance and small datasets by
synthesizing additional training data using Adaptive Synthetic Sampling
(ADASYN) and Conditional Tabular Generative Adversarial Networks (CTGAN). AIMEN
uses an ensemble of fully-connected neural networks as the backbone for its
classification with the data augmentation supported by either ADASYN or CTGAN.
AIMEN, supported by CTGAN, outperforms AIMEN supported by ADASYN in
classification. AIMEN can predict a high risk for adverse labor outcomes with
an average F1 score of 0.784. It also provides counterfactual explanations that
can be achieved by changing 2 to 3 attributes on average. Resources available:
https://github.com/ab9mamun/AIMEN.

摘要：產程中風險的早期偵測有助於進行干預措施，以預防或減輕不利的生產結果，例如腦性麻痺。目前，沒有準確的自動化系統可以預測此類事件，以協助臨床決策。為了填補這一空白，我們提出「用於建模和解釋新生兒健康的人工智慧」(AIMEN)，這是一個深度學習架構，它不僅可以根據孕產婦、胎兒、產科和產程風險因素預測不利的生產結果，還能提供模型做出預測背後的原因。後者可以提供見解，說明模型輸入變數中的哪些修改可能會改變預測結果。我們透過使用適應性合成抽樣 (ADASYN) 和條件表格生成對抗網路 (CTGAN) 來合成額外的訓練資料，以解決不平衡和小型資料集的挑戰。AIMEN 使用全連接神經網路的集合作為其分類的骨幹，並透過 ADASYN 或 CTGAN 支援資料擴充。由 CTGAN 支援的 AIMEN 在分類方面優於由 ADASYN 支援的 AIMEN。AIMEN 可以預測不利的生產結果的高風險，平均 F1 分數為 0.784。它還提供反事實解釋，可透過平均變更 2 至 3 個屬性來達成。可用資源：https://github.com/ab9mamun/AIMEN。

##### **Artificial intelligence techniques in inherited retinal diseases: A review**
2410.09105v1 by Han Trinh, Jordan Vice, Jason Charng, Zahra Tajbakhsh, Khyber Alam, Fred K. Chen, Ajmal Mian

Inherited retinal diseases (IRDs) are a diverse group of genetic disorders
that lead to progressive vision loss and are a major cause of blindness in
working-age adults. The complexity and heterogeneity of IRDs pose significant
challenges in diagnosis, prognosis, and management. Recent advancements in
artificial intelligence (AI) offer promising solutions to these challenges.
However, the rapid development of AI techniques and their varied applications
have led to fragmented knowledge in this field. This review consolidates
existing studies, identifies gaps, and provides an overview of AI's potential
in diagnosing and managing IRDs. It aims to structure pathways for advancing
clinical applications by exploring AI techniques like machine learning and deep
learning, particularly in disease detection, progression prediction, and
personalized treatment planning. Special focus is placed on the effectiveness
of convolutional neural networks in these areas. Additionally, the integration
of explainable AI is discussed, emphasizing its importance in clinical settings
to improve transparency and trust in AI-based systems. The review addresses the
need to bridge existing gaps in focused studies on AI's role in IRDs, offering
a structured analysis of current AI techniques and outlining future research
directions. It concludes with an overview of the challenges and opportunities
in deploying AI for IRDs, highlighting the need for interdisciplinary
collaboration and the continuous development of robust, interpretable AI models
to advance clinical applications.

摘要：遺傳性視網膜疾病 (IRD) 是一組多樣化的遺傳疾病，
會導致視力逐漸喪失，是工作年齡成人失明的主要原因。IRD 的複雜性和異質性對診斷、預後和管理提出了重大挑戰。最近人工智能 (AI) 的進步為這些挑戰提供了有希望的解決方案。
然而，AI 技術的快速發展及其多種應用導致了該領域的知識分散。本綜述整合了現有研究，找出差距，並概述了 AI 在診斷和管理 IRD 中的潛力。它旨在通過探索機器學習和深度學習等 AI 技術，特別是在疾病檢測、進程預測和個性化治療計劃中，為推進臨床應用構建途徑。特別關注這些領域中卷積神經網路的有效性。此外，討論了可解釋 AI 的整合，強調了其在臨床環境中提高透明度和對基於 AI 的系統的信任的重要性。該綜述解決了彌合 AI 在 IRD 中作用的重點研究中現有差距的必要性，提供了對當前 AI 技術的結構化分析，並概述了未來的研究方向。最後概述了在 IRD 中部署 AI 的挑戰和機遇，強調了跨學科合作和持續開發強大、可解釋的 AI 模型以推進臨床應用的必要性。

##### **CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures**
2410.05235v2 by Ekaterina Sviridova, Anar Yeginbergen, Ainara Estarrona, Elena Cabrio, Serena Villata, Rodrigo Agerri

Explaining Artificial Intelligence (AI) decisions is a major challenge
nowadays in AI, in particular when applied to sensitive scenarios like medicine
and law. However, the need to explain the rationale behind decisions is a main
issue also for human-based deliberation as it is important to justify
\textit{why} a certain decision has been taken. Resident medical doctors for
instance are required not only to provide a (possibly correct) diagnosis, but
also to explain how they reached a certain conclusion. Developing new tools to
aid residents to train their explanation skills is therefore a central
objective of AI in education. In this paper, we follow this direction, and we
present, to the best of our knowledge, the first multilingual dataset for
Medical Question Answering where correct and incorrect diagnoses for a clinical
case are enriched with a natural language explanation written by doctors. These
explanations have been manually annotated with argument components (i.e.,
premise, claim) and argument relations (i.e., attack, support), resulting in
the Multilingual CasiMedicos-Arg dataset which consists of 558 clinical cases
in four languages (English, Spanish, French, Italian) with explanations, where
we annotated 5021 claims, 2313 premises, 2431 support relations, and 1106
attack relations. We conclude by showing how competitive baselines perform over
this challenging dataset for the argument mining task.

摘要：解釋人工智慧 (AI) 的決策是現在 AI 的一項重大挑戰，特別是應用於像醫學和法律等敏感情境時。然而，解釋決策背後理由的需求也是基於人類的考量的一個主要問題，因為有必要證明為什麼做出某個決策。例如，住院醫師不僅需要提供（可能是正確的）診斷，還需要解釋他們如何達成某個結論。因此，開發新的工具來幫助住院醫師訓練他們的解釋技巧是教育中 AI 的一項核心目標。在本文中，我們遵循這個方向，並且根據我們的了解，提出第一個多語言醫學問答資料集，其中臨床病例的正確和不正確診斷都附有由醫生撰寫的自然語言解釋。這些解釋已使用論證組成（即前提、主張）和論證關係（即攻擊、支持）進行手動註解，產生多語言 CasiMedicos-Arg 資料集，其中包含 558 個具有解釋的四種語言（英語、西班牙語、法語、義大利語）的臨床病例，我們註解了 5021 個主張、2313 個前提、2431 個支持關係和 1106 個攻擊關係。我們最後展示了競爭基準如何針對論證探勘任務執行此具挑戰性的資料集。

##### **Explainable Diagnosis Prediction through Neuro-Symbolic Integration**
2410.01855v1 by Qiuhao Lu, Rui Li, Elham Sagheb, Andrew Wen, Jinlian Wang, Liwei Wang, Jungwei W. Fan, Hongfang Liu

Diagnosis prediction is a critical task in healthcare, where timely and
accurate identification of medical conditions can significantly impact patient
outcomes. Traditional machine learning and deep learning models have achieved
notable success in this domain but often lack interpretability which is a
crucial requirement in clinical settings. In this study, we explore the use of
neuro-symbolic methods, specifically Logical Neural Networks (LNNs), to develop
explainable models for diagnosis prediction. Essentially, we design and
implement LNN-based models that integrate domain-specific knowledge through
logical rules with learnable thresholds. Our models, particularly
$M_{\text{multi-pathway}}$ and $M_{\text{comprehensive}}$, demonstrate superior
performance over traditional models such as Logistic Regression, SVM, and
Random Forest, achieving higher accuracy (up to 80.52\%) and AUROC scores (up
to 0.8457) in the case study of diabetes prediction. The learned weights and
thresholds within the LNN models provide direct insights into feature
contributions, enhancing interpretability without compromising predictive
power. These findings highlight the potential of neuro-symbolic approaches in
bridging the gap between accuracy and explainability in healthcare AI
applications. By offering transparent and adaptable diagnostic models, our work
contributes to the advancement of precision medicine and supports the
development of equitable healthcare solutions. Future research will focus on
extending these methods to larger and more diverse datasets to further validate
their applicability across different medical conditions and populations.

摘要：診斷預測是醫療保健中的一項關鍵任務，及時且準確地識別醫療狀況會對患者的結果產生重大影響。傳統機器學習和深度學習模型已在此領域取得顯著成功，但通常缺乏可解釋性，這是臨床環境中的關鍵要求。在本研究中，我們探討了神經符號方法，特別是邏輯神經網路 (LNN)，以開發可解釋的診斷預測模型。基本上，我們設計並實作了基於 LNN 的模型，該模型透過邏輯規則和可學習的閾值整合領域特定的知識。我們的模型，特別是 $M_{\text{multi-pathway}}$ 和 $M_{\text{comprehensive}}$，表現出優於傳統模型（如邏輯迴歸、SVM 和隨機森林）的卓越效能，在糖尿病預測的案例研究中，達到了更高的準確度（高達 80.52%）和 AUROC 分數（高達 0.8457）。LNN 模型中學習的權重和閾值提供了對特徵貢獻的直接見解，增強了可解釋性，同時不損害預測能力。這些發現突顯了神經符號方法在彌合醫療保健 AI 應用中準確性和可解釋性差距方面的潛力。透過提供透明且適應性強的診斷模型，我們的研究有助於精準醫療的進步，並支援公平醫療保健解決方案的開發。未來的研究將專注於將這些方法擴展到更大且更多樣化的資料集，以進一步驗證其在不同醫療狀況和人群中的適用性。

##### **Easydiagnos: a framework for accurate feature selection for automatic diagnosis in smart healthcare**
2410.00366v1 by Prasenjit Maji, Amit Kumar Mondal, Hemanta Kumar Mondal, Saraju P. Mohanty

The rapid advancements in artificial intelligence (AI) have revolutionized
smart healthcare, driving innovations in wearable technologies, continuous
monitoring devices, and intelligent diagnostic systems. However, security,
explainability, robustness, and performance optimization challenges remain
critical barriers to widespread adoption in clinical environments. This
research presents an innovative algorithmic method using the Adaptive Feature
Evaluator (AFE) algorithm to improve feature selection in healthcare datasets
and overcome problems. AFE integrating Genetic Algorithms (GA), Explainable
Artificial Intelligence (XAI), and Permutation Combination Techniques (PCT),
the algorithm optimizes Clinical Decision Support Systems (CDSS), thereby
enhancing predictive accuracy and interpretability. The proposed method is
validated across three diverse healthcare datasets using six distinct machine
learning algorithms, demonstrating its robustness and superiority over
conventional feature selection techniques. The results underscore the
transformative potential of AFE in smart healthcare, enabling personalized and
transparent patient care. Notably, the AFE algorithm, when combined with a
Multi-layer Perceptron (MLP), achieved an accuracy of up to 98.5%, highlighting
its capability to improve clinical decision-making processes in real-world
healthcare applications.

摘要：人工智慧 (AI) 的快速進展徹底改變了智慧醫療保健，推動了可穿戴技術、持續監控裝置和智慧診斷系統的創新。然而，安全性、可解釋性、穩健性和效能最佳化挑戰仍然是臨床環境中廣泛採用的關鍵障礙。本研究提出一個創新的演算法方法，使用自適應特徵評估器 (AFE) 演算法來改善醫療保健資料集中的特徵選取並克服問題。AFE 整合了遺傳演算法 (GA)、可解釋人工智慧 (XAI) 和排列組合技術 (PCT)，該演算法最佳化了臨床決策支援系統 (CDSS)，從而提高了預測準確性和可解釋性。所提出的方法使用六種不同的機器學習演算法驗證了三個不同的醫療保健資料集，證明了其穩健性和優於傳統特徵選取技術。結果強調了 AFE 在智慧醫療保健中的轉變潛力，實現了個人化和透明的患者照護。值得注意的是，AFE 演算法與多層感知器 (MLP) 結合使用時，準確度高達 98.5%，突顯了其改善實際醫療保健應用中臨床決策制定流程的能力。

##### **Dermatologist-like explainable AI enhances melanoma diagnosis accuracy: eye-tracking study**
2409.13476v1 by Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker

Artificial intelligence (AI) systems have substantially improved
dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI)
systems further enhancing clinicians' confidence and trust in AI-driven
decisions. Despite these advancements, there remains a critical need for
objective evaluation of how dermatologists engage with both AI and XAI tools.
In this study, 76 dermatologists participated in a reader study, diagnosing 16
dermoscopic images of melanomas and nevi using an XAI system that provides
detailed, domain-specific explanations. Eye-tracking technology was employed to
assess their interactions. Diagnostic performance was compared with that of a
standard AI system lacking explanatory features. Our findings reveal that XAI
systems improved balanced diagnostic accuracy by 2.8 percentage points relative
to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and
complex lesions were associated with elevated cognitive load, as evidenced by
increased ocular fixations. These insights have significant implications for
clinical practice, the design of AI tools for visual tasks, and the broader
development of XAI in medical diagnostics.

摘要：人工智慧 (AI) 系統已大幅改善皮膚科醫師對黑色素瘤的診斷準確度，而可解釋 AI (XAI) 系統進一步提升臨床醫師對 AI 驅動決策的信心與信賴。儘管有這些進展，對於皮膚科醫師如何使用 AI 和 XAI 工具，仍有客觀評估的迫切需求。在這項研究中，76 位皮膚科醫師參與了一項讀者研究，使用 XAI 系統診斷 16 張黑色素瘤和痣的皮膚鏡影像，該系統提供詳細的領域特定說明。採用眼球追蹤技術來評估他們的互動。將診斷表現與缺乏說明功能的標準 AI 系統進行比較。我們的研究結果顯示，XAI 系統相較於標準 AI，將平衡診斷準確度提升了 2.8 個百分點。此外，與 AI/XAI 系統的診斷分歧和複雜的病灶與認知負擔升高有關，這由增加的眼睛注視次數所證實。這些見解對臨床實務、視覺任務 AI 工具的設計和醫學診斷中 XAI 的廣泛發展具有重大意義。

##### **Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions Using fMRI Data**
2409.15374v1 by Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar

Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been
shown to significantly improve the quality of life of autistic individuals.
However, diagnostics methods for ASD rely on assessments based on clinical
presentation that are prone to bias and can be challenging to arrive at an
early diagnosis. There is a need for objective biomarkers of ASD which can help
improve diagnostic accuracy. Deep learning (DL) has achieved outstanding
performance in diagnosing diseases and conditions from medical imaging data.
Extensive research has been conducted on creating models that classify ASD
using resting-state functional Magnetic Resonance Imaging (fMRI) data. However,
existing models lack interpretability. This research aims to improve the
accuracy and interpretability of ASD diagnosis by creating a DL model that can
not only accurately classify ASD but also provide explainable insights into its
working. The dataset used is a preprocessed version of the Autism Brain Imaging
Data Exchange (ABIDE) with 884 samples. Our findings show a model that can
accurately classify ASD and highlight critical brain regions differing between
ASD and typical controls, with potential implications for early diagnosis and
understanding of the neural basis of ASD. These findings are validated by
studies in the literature that use different datasets and modalities,
confirming that the model actually learned characteristics of ASD and not just
the dataset. This study advances the field of explainable AI in medical imaging
by providing a robust and interpretable model, thereby contributing to a future
with objective and reliable ASD diagnostics.

摘要：自閉症譜系障礙 (ASD) 的早期診斷和介入已被證實能顯著改善自閉症患者的生活品質。然而，ASD 的診斷方法依賴於基於臨床表現的評估，容易產生偏見，且可能難以做出早期診斷。有必要找出 ASD 的客觀生物標記，以幫助提高診斷準確性。深度學習 (DL) 在從醫學影像資料診斷疾病和病症方面取得傑出的表現。已經針對建立使用靜態功能性磁振造影 (fMRI) 資料對 ASD 進行分類的模型進行廣泛的研究。然而，現有的模型缺乏可解釋性。本研究旨在透過建立一個不僅能準確分類 ASD，還能提供可解釋見解說明其運作原理的 DL 模型，來改善 ASD 診斷的準確性和可解釋性。所使用的資料集是自閉症大腦影像資料交換 (ABIDE) 的預處理版本，包含 884 個樣本。我們的研究結果顯示，該模型能準確分類 ASD，並強調 ASD 與典型對照組之間存在差異的關鍵腦區，對於 ASD 的早期診斷和神經基礎的理解具有潛在的意義。這些研究結果已由使用不同資料集和方式的文獻研究驗證，證實該模型實際上學習了 ASD 的特徵，而不僅僅是資料集。本研究透過提供一個強健且可解釋的模型，推動了醫學影像中可解釋 AI 的領域，從而為未來提供客觀且可靠的 ASD 診斷做出貢獻。

##### **Improving Prototypical Parts Abstraction for Case-Based Reasoning Explanations Designed for the Kidney Stone Type Recognition**
2409.12883v1 by Daniel Flores-Araiza, Francisco Lopez-Tiro, Clément Larose, Salvador Hinojosa, Andres Mendez-Vazquez, Miguel Gonzalez-Mendoza, Gilberto Ochoa-Ruiz, Christian Daul

The in-vivo identification of the kidney stone types during an ureteroscopy
would be a major medical advance in urology, as it could reduce the time of the
tedious renal calculi extraction process, while diminishing infection risks.
Furthermore, such an automated procedure would make possible to prescribe
anti-recurrence treatments immediately. Nowadays, only few experienced
urologists are able to recognize the kidney stone types in the images of the
videos displayed on a screen during the endoscopy. Thus, several deep learning
(DL) models have recently been proposed to automatically recognize the kidney
stone types using ureteroscopic images. However, these DL models are of black
box nature whicl limits their applicability in clinical settings. This
contribution proposes a case-based reasoning DL model which uses prototypical
parts (PPs) and generates local and global descriptors. The PPs encode for each
class (i.e., kidney stone type) visual feature information (hue, saturation,
intensity and textures) similar to that used by biologists. The PPs are
optimally generated due a new loss function used during the model training.
Moreover, the local and global descriptors of PPs allow to explain the
decisions ("what" information, "where in the images") in an understandable way
for biologists and urologists. The proposed DL model has been tested on a
database including images of the six most widespread kidney stone types. The
overall average classification accuracy was 90.37. When comparing this results
with that of the eight other DL models of the kidney stone state-of-the-art, it
can be seen that the valuable gain in explanability was not reached at the
expense of accuracy which was even slightly increased with respect to that
(88.2) of the best method of the literature. These promising and interpretable
results also encourage urologists to put their trust in AI-based solutions.

摘要：尿路鏡檢查中腎結石類型的體內識別將是泌尿科的一項重大進展，因為它可以減少繁瑣的腎結石取出過程的時間，同時降低感染風險。此外，這種自動化程序將使立即開立抗復發治療成為可能。如今，只有少數經驗豐富的泌尿科醫生能夠在內視鏡檢查期間屏幕上顯示的視頻圖像中識別腎結石類型。因此，最近已提出多種深度學習 (DL) 模型，以使用輸尿管鏡圖像自動識別腎結石類型。然而，這些 DL 模型本質上是黑盒子，這限制了它們在臨床環境中的應用性。本文提出了一個基於案例推理的 DL 模型，它使用原型部分 (PP) 並生成局部和全局描述符。PP 為每種類型（即腎結石類型）編碼視覺特徵信息（色調、飽和度、強度和紋理），類似於生物學家使用的信息。由於在模型訓練期間使用的新損失函數，PP 得到了最佳生成。此外，PP 的局部和全局描述符允許以生物學家和泌尿科醫生可以理解的方式解釋決策（“什麼”信息，“圖像中的什麼位置”）。所提出的 DL 模型已在一個包含六種最廣泛的腎結石類型圖像的數據庫上進行了測試。總體平均分類準確率為 90.37。將此結果與腎結石最先進的八個其他 DL 模型的結果進行比較時，可以看出，可解釋性的寶貴增益並未以準確性為代價，甚至略有增加與文獻中最好的方法 (88.2) 相比。這些有希望且可解釋的結果也鼓勵泌尿科醫生相信基於人工智能的解決方案。

##### **Towards Interpretable End-Stage Renal Disease (ESRD) Prediction: Utilizing Administrative Claims Data with Explainable AI Techniques**
2409.12087v3 by Yubo Li, Saba Al-Sayouri, Rema Padman

This study explores the potential of utilizing administrative claims data,
combined with advanced machine learning and deep learning techniques, to
predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal
Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major
health insurance organization to develop prediction models for multiple
observation windows using traditional machine learning methods such as Random
Forest and XGBoost as well as deep learning approaches such as Long Short-Term
Memory (LSTM) networks. Our findings demonstrate that the LSTM model,
particularly with a 24-month observation window, exhibits superior performance
in predicting ESRD progression, outperforming existing models in the
literature. We further apply SHapley Additive exPlanations (SHAP) analysis to
enhance interpretability, providing insights into the impact of individual
features on predictions at the individual patient level. This study underscores
the value of leveraging administrative claims data for CKD management and
predicting ESRD progression.

摘要：本研究探討利用行政申報資料，結合先進機器學習與深度學習技術，預測慢性腎臟病 (CKD) 進展至末期腎臟疾病 (ESRD) 的可能性。我們分析一家大型健康保險組織提供的 10 年綜合資料集，使用傳統機器學習方法（例如隨機森林和 XGBoost）以及深度學習方法（例如長期短期記憶 (LSTM) 網路）開發多個觀察視窗的預測模型。我們的研究結果顯示，LSTM 模型（尤其是 24 個月觀察視窗）在預測 ESRD 進展方面表現優異，優於文獻中的現有模型。我們進一步應用 SHapley 可加性解釋 (SHAP) 分析以增強可解釋性，深入了解個別特徵對個別患者層級預測的影響。本研究強調了利用行政申報資料進行 CKD 管理和預測 ESRD 進展的價值。

##### **Explainable AI: Definition and attributes of a good explanation for health AI**
2409.15338v1 by Evangelia Kyrimi, Scott McLachlan, Jared M Wohlgemut, Zane B Perkins, David A. Lagnado, William Marsh, the ExAIDSS Expert Group

Proposals of artificial intelligence (AI) solutions based on increasingly
complex and accurate predictive models are becoming ubiquitous across many
disciplines. As the complexity of these models grows, transparency and users'
understanding often diminish. This suggests that accurate prediction alone is
insufficient for making an AI-based solution truly useful. In the development
of healthcare systems, this introduces new issues related to accountability and
safety. Understanding how and why an AI system makes a recommendation may
require complex explanations of its inner workings and reasoning processes.
Although research on explainable AI (XAI) has significantly increased in recent
years and there is high demand for XAI in medicine, defining what constitutes a
good explanation remains ad hoc, and providing adequate explanations continues
to be challenging. To fully realize the potential of AI, it is critical to
address two fundamental questions about explanations for safety-critical AI
applications, such as health-AI: (1) What is an explanation in health-AI? and
(2) What are the attributes of a good explanation in health-AI? In this study,
we examined published literature and gathered expert opinions through a
two-round Delphi study. The research outputs include (1) a definition of what
constitutes an explanation in health-AI and (2) a comprehensive list of
attributes that characterize a good explanation in health-AI.

摘要：隨著越來越複雜且準確的預測模型，基於人工智慧 (AI) 解決方案的提案在許多領域中變得無處不在。隨著這些模型複雜性的增加，透明度和使用者的理解力往往會降低。這表示僅有準確的預測並不足以讓 AI 解決方案真正有用。在醫療保健系統的開發中，這引入了與問責制和安全性相關的新問題。瞭解 AI 系統如何以及為何提出建議可能需要對其內部運作和推理過程進行複雜的說明。儘管近年來對可解釋 AI (XAI) 的研究已大幅增加，且醫學領域對 XAI 有很高的需求，但定義什麼構成一個好的解釋仍是臨時性的，而提供適當的解釋仍然具有挑戰性。為了充分發揮 AI 的潛力，對於安全關鍵型 AI 應用（例如健康 AI）的解釋，探討兩個基本問題至關重要：(1) 什麼是健康 AI 中的解釋？以及 (2) 健康 AI 中一個好的解釋有哪些屬性？在本研究中，我們檢視了已發表的文獻，並透過兩輪德爾菲研究收集了專家意見。研究成果包括：(1) 健康 AI 中什麼構成解釋的定義，以及 (2) 健康 AI 中一個好解釋的屬性清單。

##### **Exploring the Effect of Explanation Content and Format on User Comprehension and Trust**
2408.17401v1 by Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli, Kavyesh Vivek, Olga Kostopoulou, James Kinross, Francesca Toni

In recent years, various methods have been introduced for explaining the
outputs of "black-box" AI models. However, it is not well understood whether
users actually comprehend and trust these explanations. In this paper, we focus
on explanations for a regression tool for assessing cancer risk and examine the
effect of the explanations' content and format on the user-centric metrics of
comprehension and trust. Regarding content, we experiment with two explanation
methods: the popular SHAP, based on game-theoretic notions and thus potentially
complex for everyday users to comprehend, and occlusion-1, based on feature
occlusion which may be more comprehensible. Regarding format, we present SHAP
explanations as charts (SC), as is conventional, and occlusion-1 explanations
as charts (OC) as well as text (OT), to which their simpler nature also lends
itself. The experiments amount to user studies questioning participants, with
two different levels of expertise (the general population and those with some
medical training), on their subjective and objective comprehension of and trust
in explanations for the outputs of the regression tool. In both studies we
found a clear preference in terms of subjective comprehension and trust for
occlusion-1 over SHAP explanations in general, when comparing based on content.
However, direct comparisons of explanations when controlling for format only
revealed evidence for OT over SC explanations in most cases, suggesting that
the dominance of occlusion-1 over SHAP explanations may be driven by a
preference for text over charts as explanations. Finally, we found no evidence
of a difference between the explanation types in terms of objective
comprehension. Thus overall, the choice of the content and format of
explanations needs careful attention, since in some contexts format, rather
than content, may play the critical role in improving user experience.

摘要：<paragraph>近年來，已經引進各種方法來解釋「黑箱」AI 模型的輸出。然而，目前並不清楚使用者是否實際理解和信任這些解釋。在本文中，我們專注於評估癌症風險的回歸工具的解釋，並探討解釋的內容和格式對以使用者為中心的理解和信任指標的影響。關於內容，我們實驗了兩種解釋方法：流行的 SHAP，基於博弈論概念，因此對於日常使用者來說可能很複雜，以及基於特徵遮蔽的 occlusion-1，可能更易於理解。關於格式，我們將 SHAP 解釋呈現為圖表 (SC)，這是慣例，而將 occlusion-1 解釋呈現為圖表 (OC) 以及文字 (OT)，其較為簡單的性質也適用於此。這些實驗等同於使用者研究，詢問參與者，具有兩種不同程度的專業知識（一般民眾和具備一些醫學訓練的人），他們對回歸工具輸出解釋的主觀和客觀理解和信任。在兩項研究中，我們發現，在基於內容進行比較時，一般來說，occlusion-1 優於 SHAP 解釋，在主觀理解和信任方面有明顯的偏好。然而，在僅控制格式的情況下直接比較解釋，在大多數情況下只顯示 OT 優於 SC 解釋的證據，這表明 occlusion-1 優於 SHAP 解釋的主導地位可能是由偏好文字而非圖表作為解釋所驅動的。最後，我們沒有發現解釋類型在客觀理解方面的差異證據。因此，總體而言，對解釋的內容和格式的選擇需要仔細注意，因為在某些情況下，格式而非內容，可能在改善使用者體驗方面發揮關鍵作用。</paragraph>

##### **A Survey for Large Language Models in Biomedicine**
2409.00133v1 by Chong Wang, Mengyao Li, Junjun He, Zhongruo Wang, Erfan Darzi, Zan Chen, Jin Ye, Tianbin Li, Yanzhou Su, Jing Ke, Kaili Qu, Shuxin Li, Yi Yu, Pietro Liò, Tianyun Wang, Yu Guang Wang, Yiqing Shen

Recent breakthroughs in large language models (LLMs) offer unprecedented
natural language understanding and generation capabilities. However, existing
surveys on LLMs in biomedicine often focus on specific applications or model
architectures, lacking a comprehensive analysis that integrates the latest
advancements across various biomedical domains. This review, based on an
analysis of 484 publications sourced from databases including PubMed, Web of
Science, and arXiv, provides an in-depth examination of the current landscape,
applications, challenges, and prospects of LLMs in biomedicine, distinguishing
itself by focusing on the practical implications of these models in real-world
biomedical contexts. Firstly, we explore the capabilities of LLMs in zero-shot
learning across a broad spectrum of biomedical tasks, including diagnostic
assistance, drug discovery, and personalized medicine, among others, with
insights drawn from 137 key studies. Then, we discuss adaptation strategies of
LLMs, including fine-tuning methods for both uni-modal and multi-modal LLMs to
enhance their performance in specialized biomedical contexts where zero-shot
fails to achieve, such as medical question answering and efficient processing
of biomedical literature. Finally, we discuss the challenges that LLMs face in
the biomedicine domain including data privacy concerns, limited model
interpretability, issues with dataset quality, and ethics due to the sensitive
nature of biomedical data, the need for highly reliable model outputs, and the
ethical implications of deploying AI in healthcare. To address these
challenges, we also identify future research directions of LLM in biomedicine
including federated learning methods to preserve data privacy and integrating
explainable AI methodologies to enhance the transparency of LLMs.

摘要：大型語言模型 (LLM) 的最新突破提供了前所未有的自然語言理解和生成能力。然而，現有關於生物醫學中 LLM 的調查通常專注於特定應用或模型架構，缺乏整合各種生物醫學領域最新進展的全面分析。本綜述基於對來自 PubMed、Web of Science 和 arXiv 等數據庫的 484 篇出版物的分析，深入探討了生物醫學中 LLM 的當前現況、應用、挑戰和前景，其特點是關注這些模型在現實世界生物醫學背景中的實際應用。首先，我們探討了 LLM 在廣泛的生物醫學任務中的零次學習能力，包括診斷輔助、藥物發現和個性化醫療等，並從 137 項關鍵研究中汲取見解。然後，我們討論了 LLM 的適應策略，包括單模態和多模態 LLM 的微調方法，以增強它們在零次學習無法實現的專業生物醫學背景中的性能，例如醫療問題解答和生物醫學文獻的有效處理。最後，我們討論了 LLM 在生物醫學領域面臨的挑戰，包括數據隱私問題、模型可解釋性有限、數據集質量問題以及由於生物醫學數據的敏感性、對高度可靠模型輸出的需求以及在醫療保健中部署 AI 的倫理影響而產生的倫理問題。為了應對這些挑戰，我們還確定了生物醫學中 LLM 未來的研究方向，包括用於保護數據隱私的聯合學習方法以及整合可解釋 AI 方法以增強 LLM 的透明度。

##### **Aligning XAI with EU Regulations for Smart Biomedical Devices: A Methodology for Compliance Analysis**
2408.15121v1 by Francesco Sovrano, Michael Lognoul, Giulia Vilone

Significant investment and development have gone into integrating Artificial
Intelligence (AI) in medical and healthcare applications, leading to advanced
control systems in medical technology. However, the opacity of AI systems
raises concerns about essential characteristics needed in such sensitive
applications, like transparency and trustworthiness. Our study addresses these
concerns by investigating a process for selecting the most adequate Explainable
AI (XAI) methods to comply with the explanation requirements of key EU
regulations in the context of smart bioelectronics for medical devices. The
adopted methodology starts with categorising smart devices by their control
mechanisms (open-loop, closed-loop, and semi-closed-loop systems) and delving
into their technology. Then, we analyse these regulations to define their
explainability requirements for the various devices and related goals.
Simultaneously, we classify XAI methods by their explanatory objectives. This
allows for matching legal explainability requirements with XAI explanatory
goals and determining the suitable XAI algorithms for achieving them. Our
findings provide a nuanced understanding of which XAI algorithms align better
with EU regulations for different types of medical devices. We demonstrate this
through practical case studies on different neural implants, from chronic
disease management to advanced prosthetics. This study fills a crucial gap in
aligning XAI applications in bioelectronics with stringent provisions of EU
regulations. It provides a practical framework for developers and researchers,
ensuring their AI innovations advance healthcare technology and adhere to legal
and ethical standards.

摘要：人工智慧（AI）在醫療和保健應用中投入了大量的投資和開發，進而導致醫療技術中的先進控制系統。然而，AI 系統的不透明性引發了對此類敏感應用中所需基本特性的擔憂，例如透明度和可信度。我們的研究透過調查一個程序來解決這些問題，用於選擇最充分的可解釋 AI（XAI）方法，以符合歐盟法規在醫療器材的智慧型生物電子學中的說明要求。採用的方法從透過其控制機制（開迴路、閉迴路和半閉迴路系統）對智慧型裝置進行分類，並深入探討其技術開始。然後，我們分析這些法規以定義其對各種裝置和相關目標的可解釋性要求。同時，我們透過其說明目標對 XAI 方法進行分類。這允許將法律可解釋性要求與 XAI 說明目標相匹配，並確定適當的 XAI 演算法來達成它們。我們的研究結果提供了對哪些 XAI 演算法更符合歐盟法規以適用於不同類型的醫療器材的細緻理解。我們透過不同神經植入物的實際案例研究來證明這一點，從慢性疾病管理到先進的義肢。這項研究填補了將生物電子學中的 XAI 應用與歐盟法規的嚴格規定相符的重要空白。它為開發人員和研究人員提供了一個實用的架構，確保其 AI 創新能促進醫療技術並遵守法律和道德標準。

##### **Towards Case-based Interpretability for Medical Federated Learning**
2408.13626v1 by Laura Latorre, Liliana Petrychenko, Regina Beets-Tan, Taisiya Kopytova, Wilson Silva

We explore deep generative models to generate case-based explanations in a
medical federated learning setting. Explaining AI model decisions through
case-based interpretability is paramount to increasing trust and allowing
widespread adoption of AI in clinical practice. However, medical AI training
paradigms are shifting towards federated learning settings in order to comply
with data protection regulations. In a federated scenario, past data is
inaccessible to the current user. Thus, we use a deep generative model to
generate synthetic examples that protect privacy and explain decisions. Our
proof-of-concept focuses on pleural effusion diagnosis and uses publicly
available Chest X-ray data.

摘要：我們探索深度生成模型，在醫療聯邦學習設置中生成基於案例的說明。透過基於案例的可解釋性來解釋 AI 模型決策，對於增加信任並允許 AI 在臨床實務中廣泛採用至關重要。然而，醫療 AI 訓練範例正轉向聯邦學習設置，以符合資料保護法規。在聯邦情境中，過去的資料對目前的使用者而言是無法取得的。因此，我們使用深度生成模型來產生保護隱私和解釋決策的合成範例。我們的概念驗證著重於胸腔積液診斷，並使用公開可取得的胸部 X 光資料。

##### **AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines**
2408.12491v1 by Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, Jacob J. Visser, Robert Hemke, Kirsten van Langevelde, David F. Hanff, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. Gruühagen, Wiro J. Niessen, Stefan Klein, Martijn P. A. Starmans

Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging
lesions with variable clinical behaviours and treatment approaches. This
systematic review provides an overview of Artificial Intelligence (AI) methods
using radiological imaging for diagnosis and prognosis of these tumours,
highlighting challenges in clinical translation, and evaluating study alignment
with the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI
international consensus guidelines for trustworthy and deployable AI to promote
the clinical translation of AI methods. The review covered literature from
several bibliographic databases, including papers published before 17/07/2024.
Original research in peer-reviewed journals focused on radiology-based AI for
diagnosing or prognosing primary STBT was included. Exclusion criteria were
animal, cadaveric, or laboratory studies, and non-English papers. Abstracts
were screened by two of three independent reviewers for eligibility. Eligible
papers were assessed against guidelines by one of three independent reviewers.
The search identified 15,015 abstracts, from which 325 articles were included
for evaluation. Most studies performed moderately on CLAIM, averaging a score
of 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 out
of 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,
indicating significant room for improvement. Future efforts by AI developers
should focus on design (e.g. define unmet clinical need, intended clinical
setting and how AI would be integrated in clinical workflow), development (e.g.
build on previous work, explainability), evaluation (e.g. evaluating and
addressing biases, evaluating AI against best practices), and data
reproducibility and availability (making documented code and data publicly
available). Following these recommendations could improve clinical translation
of AI methods.

摘要：軟組織和骨骼腫瘤（STBT）是罕見、診斷具有挑戰性的病灶，其臨床行為和治療方法各不相同。這篇系統性回顧提供了使用放射影像進行診斷和預後的人工智慧 (AI) 方法的概觀，重點說明了臨床轉譯的挑戰，並評估研究與醫療影像 AI 核查表 (CLAIM) 和 FUTURE-AI 可信賴且可部署 AI 的國際共識準則的一致性，以促進 AI 方法的臨床轉譯。這篇回顧涵蓋了幾個書目資料庫中的文獻，包括在 2024 年 7 月 17 日之前發表的論文。納入了以放射為基礎的 AI 診斷或預後原發性 STBT 的同行評審期刊中的原始研究。排除標準是動物、屍體或實驗室研究，以及非英文論文。摘要由三位獨立審查員中的兩位篩選資格。合格的論文由三位獨立審查員中的一位根據準則進行評估。搜索識別出 15,015 篇摘要，其中 325 篇文章被納入評估。大多數研究在 CLAIM 中表現中等，平均得分為 53 分中的 28.9±7.5 分，但在 FUTURE-AI 中表現不佳，平均得分為 30 分中的 5.1±2.1 分。STBT 的影像 AI 工具仍處於概念驗證階段，表明有顯著的改進空間。AI 開發人員未來的努力應集中在設計（例如定義未滿足的臨床需求、預期的臨床環境以及 AI 如何整合到臨床工作流程中）、開發（例如建立在先前的工作、可解釋性）、評估（例如評估和解決偏差、評估 AI 與最佳實務）、以及數據可複製性和可用性（公開提供文件化的代碼和數據）。遵循這些建議可以改善 AI 方法的臨床轉譯。

##### **Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy**
2409.00001v1 by Kimji N. Pellano, Inga Strümke, Daniel Groos, Lars Adde, Espen Alexander F. Ihlen

Early detection of Cerebral Palsy (CP) is crucial for effective intervention
and monitoring. This paper tests the reliability and applicability of
Explainable AI (XAI) methods using a deep learning method that predicts CP by
analyzing skeletal data extracted from video recordings of infant movements.
Specifically, we use XAI evaluation metrics -- namely faithfulness and
stability -- to quantitatively assess the reliability of Class Activation
Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this
specific medical application. We utilize a unique dataset of infant movements
and apply skeleton data perturbations without distorting the original dynamics
of the infant movements. Our CP prediction model utilizes an ensemble approach,
so we evaluate the XAI metrics performances for both the overall ensemble and
the individual models. Our findings indicate that both XAI methods effectively
identify key body points influencing CP predictions and that the explanations
are robust against minor data perturbations. Grad-CAM significantly outperforms
CAM in the RISv metric, which measures stability in terms of velocity. In
contrast, CAM performs better in the RISb metric, which relates to bone
stability, and the RRS metric, which assesses internal representation
robustness. Individual models within the ensemble show varied results, and
neither CAM nor Grad-CAM consistently outperform the other, with the ensemble
approach providing a representation of outcomes from its constituent models.

摘要：腦性麻痺 (CP) 的早期偵測對於有效的介入和監測至關重要。本文測試了可解釋 AI (XAI) 方法的可靠性和適用性，使用深度學習方法，透過分析從嬰兒動作影片記錄中提取的骨骼資料來預測 CP。具體來說，我們使用 XAI 評估指標（即忠實度和穩定性）來量化評估類別激活映射 (CAM) 和梯度加權類別激活映射 (Grad-CAM) 在這個特定醫療應用中的可靠性。我們利用一個獨特的嬰兒動作資料集，並應用骨骼資料擾動，而不會扭曲嬰兒動作的原始動力。我們的 CP 預測模型利用整體方法，因此我們評估了整體整體和個別模型的 XAI 指標表現。我們的研究結果表明，兩種 XAI 方法都能有效識別影響 CP 預測的關鍵身體部位，並且這些解釋對於微小的資料擾動具有魯棒性。Grad-CAM 在 RISv 指標中顯著優於 CAM，該指標衡量速度方面的穩定性。相比之下，CAM 在 RISb 指標中表現得更好，該指標與骨骼穩定性有關，而 RRS 指標則評估內部表示的魯棒性。整體中的個別模型顯示出不同的結果，CAM 和 Grad-CAM 都不一致地優於另一種，整體方法提供了其組成模型結果的表示。

##### **MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy**
2408.11837v1 by Hanchen David Wang, Nibraas Khan, Anna Chen, Nilanjan Sarkar, Pamela Wisniewski, Meiyi Ma

Recent global estimates suggest that as many as 2.41 billion individuals have
health conditions that would benefit from rehabilitation services. Home-based
Physical Therapy (PT) faces significant challenges in providing interactive
feedback and meaningful observation for therapists and patients. To fill this
gap, we present MicroXercise, which integrates micro-motion analysis with
wearable sensors, providing therapists and patients with a comprehensive
feedback interface, including video, text, and scores. Crucially, it employs
multi-dimensional Dynamic Time Warping (DTW) and attribution-based explainable
methods to analyze the existing deep learning neural networks in monitoring
exercises, focusing on a high granularity of exercise. This synergistic
approach is pivotal, providing output matching the input size to precisely
highlight critical subtleties and movements in PT, thus transforming complex AI
analysis into clear, actionable feedback. By highlighting these micro-motions
in different metrics, such as stability and range of motion, MicroXercise
significantly enhances the understanding and relevance of feedback for
end-users. Comparative performance metrics underscore its effectiveness over
traditional methods, such as a 39% and 42% improvement in Feature Mutual
Information (FMI) and Continuity. MicroXercise is a step ahead in home-based
physical therapy, providing a technologically advanced and intuitively helpful
solution to enhance patient care and outcomes.

摘要：最近的全球估計表明，多達 24.1 億人有
健康狀況可從復健服務中受益。居家
物理治療 (PT) 在提供互動式
回饋和有意義的觀察方面面臨重大挑戰，供治療師和患者使用。為了填補這
個缺口，我們提出 MicroXercise，它將微動作分析與
可穿戴式感測器整合在一起，為治療師和患者提供一個全面的
回饋介面，包括影片、文字和分數。至關重要的是，它採用
多維動態時間規整 (DTW) 和基於歸因的可解釋
方法來分析監控運動中現有的深度學習神經網路，專注於運動的高粒度。這種協同
方法至關重要，提供與輸入大小匹配的輸出，以精確地
突出 PT 中關鍵的細微差別和動作，從而將複雜的 AI
分析轉換為清晰、可操作的回饋。透過在不同指標中突顯這些微動作，例如穩定性和動作範圍，MicroXercise
顯著提升最終使用者對回饋的理解和相關性。比較效能指標強調其優於
傳統方法的有效性，例如特徵互惠資訊 (FMI) 和連續性分別提升了 39% 和 42%。MicroXercise 在居家
物理治療方面更進一步，提供技術先進且直覺有用的
解決方案，以提升患者照護和結果。

##### **The Literature Review Network: An Explainable Artificial Intelligence for Systematic Literature Reviews, Meta-analyses, and Method Development**
2408.05239v1 by Joshua Morriss, Tod Brindle, Jessica Bah Rösman, Daniel Reibsamen, Andreas Enz

Systematic literature reviews are the highest quality of evidence in
research. However, the review process is hindered by significant resource and
data constraints. The Literature Review Network (LRN) is the first of its kind
explainable AI platform adhering to PRISMA 2020 standards, designed to automate
the entire literature review process. LRN was evaluated in the domain of
surgical glove practices using 3 search strings developed by experts to query
PubMed. A non-expert trained all LRN models. Performance was benchmarked
against an expert manual review. Explainability and performance metrics
assessed LRN's ability to replicate the experts' review. Concordance was
measured with the Jaccard index and confusion matrices. Researchers were
blinded to the other's results until study completion. Overlapping studies were
integrated into an LRN-generated systematic review. LRN models demonstrated
superior classification accuracy without expert training, achieving 84.78% and
85.71% accuracy. The highest performance model achieved high interrater
reliability (k = 0.4953) and explainability metrics, linking 'reduce',
'accident', and 'sharp' with 'double-gloving'. Another LRN model covered 91.51%
of the relevant literature despite diverging from the non-expert's judgments (k
= 0.2174), with the terms 'latex', 'double' (gloves), and 'indication'. LRN
outperformed the manual review (19,920 minutes over 11 months), reducing the
entire process to 288.6 minutes over 5 days. This study demonstrates that
explainable AI does not require expert training to successfully conduct
PRISMA-compliant systematic literature reviews like an expert. LRN summarized
the results of surgical glove studies and identified themes that were nearly
identical to the clinical researchers' findings. Explainable AI can accurately
expedite our understanding of clinical practices, potentially revolutionizing
healthcare research.

摘要：系統性文獻回顧是研究中證據品質最高的。然而，回顧過程受到顯著資源和資料限制的阻礙。文獻回顧網路 (LRN) 是第一個遵循 PRISMA 2020 標準的可解釋 AI 平台，旨在自動化整個文獻回顧過程。LRN 在外科手套實務領域中進行評估，使用專家開發的 3 個搜尋字串來查詢 PubMed。非專家訓練所有 LRN 模型。效能以專家手動回顧作為基準。可解釋性和效能指標評估 LRN 複製專家回顧的能力。一致性以 Jaccard 指數和混淆矩陣測量。研究人員在研究完成前對彼此的結果保密。重疊的研究整合到 LRN 生成的系統性回顧中。LRN 模型在沒有專家訓練的情況下展現出優異的分類準確率，達到 84.78% 和 85.71% 的準確率。效能最高的模型達到了高評分者間信賴度 (k = 0.4953) 和可解釋性指標，將「減少」、「意外」和「銳利」與「雙重戴手套」連結在一起。另一個 LRN 模型涵蓋了 91.51% 的相關文獻，儘管與非專家的判斷不同 (k = 0.2174)，但包含了「乳膠」、「雙重」（手套）和「適應症」等詞彙。LRN 優於手動回顧（11 個月超過 19,920 分鐘），將整個過程縮短為 5 天超過 288.6 分鐘。這項研究顯示，可解釋的 AI 不需要專家訓練即可成功進行專家等級的 PRISMA 相容系統性文獻回顧。LRN 總結了外科手套研究的結果，並找出與臨床研究人員發現幾乎相同的主题。可解釋的 AI 可以準確地加快我們對臨床實務的理解，有潛力革新醫療保健研究。

##### **Enhancing Medical Learning and Reasoning Systems: A Boxology-Based Comparative Analysis of Design Patterns**
2408.02709v1 by Chi Him Ng

This study analyzes hybrid AI systems' design patterns and their
effectiveness in clinical decision-making using the boxology framework. It
categorizes and copares various architectures combining machine learning and
rule-based reasoning to provide insights into their structural foundations and
healthcare applications. Addressing two main questions, how to categorize these
systems againts established design patterns and how to extract insights through
comparative analysis, the study uses design patterns from software engineering
to understand and optimize healthcare AI systems. Boxology helps identify
commonalities and create reusable solutions, enhancing these systems'
scalability, reliability, and performance. Five primary architectures are
examined: REML, MLRB, RBML, RMLT, and PERML. Each has unique strengths and
weaknesses, highlighting the need for tailored approaches in clinical tasks.
REML excels in high-accuracy prediction for datasets with limited data; MLRB in
handling large datasets and complex data integration; RBML in explainability
and trustworthiness; RMLT in managing high-dimensional data; and PERML, though
limited in analysis, shows promise in urgent care scenarios. The study
introduces four new patterns, creates five abstract categorization patterns,
and refines those five further to specific systems. These contributions enhance
Boxlogy's taxonomical organization and offer novel approaches to integrating
expert knowledge with machine learning. Boxology's structured, modular apporach
offers significant advantages in developing and analyzing hybrid AI systems,
revealing commonalities, and promoting reusable solutions. In conclusion, this
study underscores hybrid AI systems' crucial role in advancing healthcare and
Boxology's potential to drive further innovation in AI integration, ultimately
improving clinical decision support and patient outcomes.

摘要：本研究使用盒子學框架分析混合人工智慧系統的設計模式及其在臨床決策中的有效性。它分類並比較結合機器學習和基於規則的推理的各種架構，以深入了解其結構基礎和醫療保健應用。針對兩個主要問題，如何根據既定的設計模式對這些系統進行分類，以及如何通過比較分析提取見解，本研究使用軟體工程中的設計模式來了解和優化醫療保健人工智慧系統。盒子學有助於識別共性並建立可重複使用的解決方案，從而增強這些系統的可擴充性、可靠性和效能。檢查了五種主要的架構：REML、MLRB、RBML、RMLT 和 PERML。每種架構都有獨特的優缺點，強調了在臨床任務中需要量身打造的方法。REML 在資料有限的資料集中表現出高精度的預測；MLRB 在處理大型資料集和複雜資料整合方面表現出色；RBML 在可解釋性和可信度方面表現出色；RMLT 在管理高維資料方面表現出色；而 PERML 儘管在分析方面有限，但在緊急照護場景中表現出潛力。本研究引入了四種新模式，建立了五種抽象分類模式，並進一步將這五種模式細化為具體的系統。這些貢獻增強了盒子學的分類組織，並提供了將專家知識與機器學習整合的新方法。盒子學的結構化、模組化方法在開發和分析混合人工智慧系統、揭示共性以及推廣可重複使用的解決方案方面具有顯著優勢。總之，本研究強調了混合人工智慧系統在推進醫療保健中的關鍵作用，以及盒子學在推動人工智慧整合進一步創新方面的潛力，最終改善臨床決策支援和患者的治療成果。

##### **Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability**
2408.02706v1 by Masoud Muhammed Hassan

Because of its strong predictive skills, deep learning has emerged as an
essential tool in many industries, including healthcare. Traditional deep
learning models, on the other hand, frequently lack interpretability and omit
to take prediction uncertainty into account two crucial components of clinical
decision making. In order to produce explainable and uncertainty aware
predictions, this study presents a novel framework called Bayesian Kolmogorov
Arnold Networks (BKANs), which combines the expressive capacity of Kolmogorov
Arnold Networks with Bayesian inference. We employ BKANs on two medical
datasets, which are widely used benchmarks for assessing machine learning
models in medical diagnostics: the Pima Indians Diabetes dataset and the
Cleveland Heart Disease dataset. Our method provides useful insights into
prediction confidence and decision boundaries and outperforms traditional deep
learning models in terms of prediction accuracy. Moreover, BKANs' capacity to
represent aleatoric and epistemic uncertainty guarantees doctors receive more
solid and trustworthy decision support. Our Bayesian strategy improves the
interpretability of the model and considerably minimises overfitting, which is
important for tiny and imbalanced medical datasets, according to experimental
results. We present possible expansions to further use BKANs in more
complicated multimodal datasets and address the significance of these
discoveries for future research in building reliable AI systems for healthcare.
This work paves the way for a new paradigm in deep learning model deployment in
vital sectors where transparency and reliability are crucial.

摘要：由於其強大的預測能力，深度學習已成為許多產業中不可或缺的工具，包括醫療保健。然而，傳統的深度學習模型通常缺乏可解釋性，並且忽略了將預測不確定性納入考量，而這兩個因素是臨床決策制定的關鍵組成部分。為了產生可解釋且具有不確定性意識的預測，本研究提出了一個名為貝氏柯爾莫哥洛夫阿諾德網路 (BKAN) 的新架構，它結合了柯爾莫哥洛夫阿諾德網路的表達能力與貝氏推論。我們在兩個醫學資料集上使用 BKAN，這些資料集是評估機器學習模型在醫學診斷中的廣泛使用基準：皮馬印第安人糖尿病資料集和克里夫蘭心臟病資料集。我們的模型提供了對預測信心和決策邊界的有益見解，並且在預測準確度方面優於傳統的深度學習模型。此外，BKAN 表現隨機和認識不確定性的能力，可確保醫生獲得更可靠且值得信賴的決策支援。根據實驗結果，我們的貝氏策略提高了模型的可解釋性，並大幅減少了過度擬合，這對於小型且不平衡的醫學資料集非常重要。我們提出了可能的擴充功能，以進一步將 BKAN 用於更複雜的多模式資料集，並探討這些發現對於未來建立可靠的醫療保健 AI 系統研究的重要性。這項工作為深度學習模型部署在透明度和可靠性至關重要的重要領域中開啟了一個新的典範。

##### **MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI**
2407.20284v1 by Shyam Dongre, Ritesh Chandra, Sonali Agarwal

In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.

摘要：在現代醫療保健中，解決準確疾病預測和個性化建議的複雜性既至關重要又具有挑戰性。本研究引入了 MLtoGAI，它將語義網路技術與機器學習 (ML) 相結合，以增強疾病預測並透過 ChatGPT 提供使用者友善的說明。該系統包含三個關鍵組成部分：一個可重複使用的疾病本体，其中包含有關各種疾病的詳細知識；一個診斷分類模型，它使用患者症狀來準確檢測特定疾病；以及語義網路規則語言 (SWRL) 與本体和 ChatGPT 的整合，以產生清晰、個性化的健康建議。這種方法顯著提高了預測準確性，並確保了易於理解的結果，解決了疾病和不同症狀的複雜性。MLtoGAI 系統展示了準確性和使用者滿意度的實質性進步，有助於開發更智慧且更易於取得的醫療保健解決方案。這種創新的方法結合了 ML 演算法的優點，以及透過 ChatGPT 提供透明且人類可以理解的說明的能力，在預測準確性和使用者理解方面取得了顯著的進步。透過利用語義技術和可解釋的 AI，該系統提高了疾病預測的準確性，並確保了建議與個別患者相關且易於理解。我們的研究強調了整合先進技術以克服醫療診斷中現有挑戰的潛力，為智慧醫療保健系統的未來發展鋪路。此外，該系統使用 200 個合成患者資料記錄進行驗證，確保了穩健的效能和可靠性。

##### **Introducing δ-XAI: a novel sensitivity-based method for local AI explanations**
2407.18343v2 by Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora

Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.

摘要：可解釋人工智慧 (XAI) 是將人工智慧 (AI) 和機器學習 (ML) 演算法整合到臨床實務中的辯論核心。高執行效能的 AI/ML 模型，例如整體學習器和深度神經網路，通常缺乏可解釋性，阻礙臨床醫生對其預測的信任。為了解決這個問題，正在開發 XAI 技術，以人類可以理解的術語描述 AI/ML 預測。一個有希望的方向是採用敏感度分析 (SA) 和全球敏感度分析 (GSA)，它們本質上會依據模型輸入對預測的影響來對其進行排名。在此，我們介紹一種新的 delta-XAI 方法，透過擴充 GSA 指標 delta 指數來提供 ML 模型預測的局部解釋。delta-XAI 指數評估每個特徵值對回歸和分類問題中個別例項的預測輸出之影響。我們將 delta-XAI 指數形式化，並提供其實作的程式碼。使用線性回歸模型對模擬情境評估 delta-XAI 方法，並以 Shapley 值作為基準。結果顯示 delta-XAI 指數通常與 Shapley 值一致，但在具有高度影響力或極端特徵值的模型中存在顯著差異。delta-XAI 指數在偵測主要特徵和處理極端特徵值方面表現出更高的敏感度。定性地來說，delta-XAI 透過利用機率密度函數提供直觀的解釋，使特徵排名更清晰且對從業人員來說更具可解釋性。總體而言，delta-XAI 方法對於穩健地取得 ML 模型預測的局部解釋似乎很有希望。將在真實世界的臨床環境中進行進一步調查，以評估其對 AI 輔助臨床工作流程的影響。

##### **Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population**
2407.17324v2 by Nikolaos Ntampakis, Konstantinos Diamantaras, Ioanna Chouvarda, Vasileios Argyriou, Panagiotis Sarigianndis

Dementia, a debilitating neurological condition affecting millions worldwide,
presents significant diagnostic challenges. In this work, we introduce a novel
methodology for the classification of demented and non-demented elderly
patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach
features a unique technique for selectively processing MRI slices, focusing on
the most relevant brain regions and excluding less informative sections. This
methodology is complemented by a confidence-based classification committee
composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and
Dem3D EfficientNet. These models work synergistically to enhance
decision-making accuracy, leveraging their collective strengths. Tested on the
Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an
impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore,
validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset
confirmed the robustness and generalizability of our approach. The use of
explainable AI (XAI) techniques and comprehensive ablation studies further
substantiate the effectiveness of our techniques, providing insights into the
decision-making process and the importance of our methodology. This research
offers a significant advancement in dementia diagnosis, providing a highly
accurate and efficient tool for clinical applications.

摘要：失智症是一種影響全球數百萬人的衰弱性神經疾病，在診斷上具有重大挑戰。在這項工作中，我們提出了一種新的方法，用於對失智和非失智老年患者進行分類，使用 3D 大腦磁振造影 (MRI) 掃描。我們的做法採用了一種獨特技術，用於選擇性處理 MRI 切片，重點關注最相關的大腦區域，並排除信息量較少的部分。這種方法由一個基於信心的分類委員會補充，該委員會由三個自定義深度學習模型組成：Dem3D ResNet、Dem3D CNN 和 Dem3D EfficientNet。這些模型協同工作以增強決策的準確性，利用它們的集體優勢。在影像研究開放存取系列 (OASIS) 資料集上進行測試，我們的模型達到了 94.12% 的驚人準確度，超過了現有方法。此外，在阿茲海默症神經影像倡議 (ADNI) 資料集上的驗證證實了我們方法的穩健性和普遍性。可解釋 AI (XAI) 技術和全面的消融研究進一步證實了我們技術的有效性，提供了對決策過程和我們方法重要性的見解。這項研究為失智症診斷提供了重大進展，為臨床應用提供了一個高度準確且高效的工具。

##### **Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition**
2408.06352v1 by Michele Fiori, Gabriele Civitarese, Claudio Bettini

Recognizing daily activities with unobtrusive sensors in smart environments
enables various healthcare applications. Monitoring how subjects perform
activities at home and their changes over time can reveal early symptoms of
health issues, such as cognitive decline. Most approaches in this field use
deep learning models, which are often seen as black boxes mapping sensor data
to activities. However, non-expert users like clinicians need to trust and
understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human
Activity Recognition have emerged to provide intuitive natural language
explanations from these models. Different XAI methods generate different
explanations, and their effectiveness is typically evaluated through user
surveys, that are often challenging in terms of costs and fairness. This paper
proposes an automatic evaluation method using Large Language Models (LLMs) to
identify, in a pool of candidates, the best XAI approach for non-expert users.
Our preliminary results suggest that LLM evaluation aligns with user surveys.

摘要：藉由智慧環境中不引人注目的感測器辨識日常活動，能啟用各種醫療保健應用。監控受試者在家中如何執行活動，以及其隨著時間的變化，可以揭示健康問題的早期症狀，例如認知能力下降。此領域中的大多數方法都使用深度學習模型，這些模型通常被視為將感測器資料對應至活動的黑盒子。然而，非專家使用者（例如臨床醫師）需要信任並了解這些模型的輸出。因此，人類活動辨識的可解釋 AI (XAI) 方法應運而生，以提供來自這些模型的直覺自然語言說明。不同的 XAI 方法會產生不同的說明，而其有效性通常透過使用者調查來評估，這在成本和公平性方面通常具有挑戰性。本文提出使用大型語言模型 (LLM) 的自動評估方法，以在候選者中找出最適合非專家使用者的 XAI 方法。我們的初步結果表明，LLM 評估與使用者調查一致。

##### **Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions**
2408.03335v1 by Naseem Khan, Kashif Ahmad, Aref Al Tamimi, Mohammed M. Alani, Amine Bermak, Issa Khalil

Industry 5.0, which focuses on human and Artificial Intelligence (AI)
collaboration for performing different tasks in manufacturing, involves a
higher number of robots, Internet of Things (IoTs) devices and
interconnections, Augmented/Virtual Reality (AR), and other smart devices. The
huge involvement of these devices and interconnection in various critical
areas, such as economy, health, education and defense systems, poses several
types of potential security flaws. AI itself has been proven a very effective
and powerful tool in different areas of cybersecurity, such as intrusion
detection, malware detection, and phishing detection, among others. Just as in
many application areas, cybersecurity professionals were reluctant to accept
black-box ML solutions for cybersecurity applications. This reluctance pushed
forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool
that helps explain how decisions are made in ML-based systems. In this survey,
we present a comprehensive study of different XAI-based intrusion detection
systems for industry 5.0, and we also examine the impact of explainability and
interpretability on Cybersecurity practices through the lens of Adversarial
XIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities
and challenges in XAI cybersecurity systems for industry 5.0 that elicit future
research toward XAI-based solutions to be adopted by high-stakes industry 5.0
applications. We believe this rigorous analysis will establish a foundational
framework for subsequent research endeavors within the specified domain.

摘要：工業 5.0 著重於人類與人工智慧 (AI) 合作執行製造中的不同任務，涉及更多機器人、物聯網 (IoT) 裝置和互連、擴增/虛擬實境 (AR) 和其他智慧裝置。這些裝置和互連在經濟、醫療保健、教育和國防系統等各種關鍵領域的廣泛參與，引發了多種類型的潛在安全漏洞。AI 本身已被證明是網路安全不同領域中非常有效且強大的工具，例如入侵偵測、惡意軟體偵測和網路釣魚偵測等。就像在許多應用領域一樣，網路安全專業人員不願意接受黑盒 ML 解決方案來應用於網路安全。這種不願意促使可解釋人工智慧 (XAI) 作為一種工具被採用，有助於說明在基於 ML 的系統中如何做出決策。在這項調查中，我們對工業 5.0 的不同基於 XAI 的入侵偵測系統進行了全面的研究，並且我們也透過對抗式 XIDS (Adv-XIDS) 方法的觀點來探討可解釋性和可詮釋性對網路安全實務的影響。此外，我們分析了工業 5.0 的 XAI 網路安全系統中可能存在的機會和挑戰，引發了未來針對 XAI 基礎解決方案的研究，以供高風險的工業 5.0 應用採用。我們相信這項嚴謹的分析將為指定領域內的後續研究工作建立基礎架構。

##### **A Comparative Study on Automatic Coding of Medical Letters with Explainability**
2407.13638v1 by Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic

This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.

摘要：本研究旨在探討將自然語言處理 (NLP) 和機器學習 (ML) 技術實作於醫療信函編碼自動化，並具備視覺化說明能力和輕量化的本地電腦設定。目前在臨床環境中，編碼是一種手動流程，涉及為病患文件中的每項病症、程序和藥物指派代碼 (例如，使用 SNOMED CT 代碼 56265001 表示心臟病)。此領域有使用最新 ML 模型進行自動編碼的初步研究；然而，由於模型的複雜性和大小，並未實現實際部署。為了進一步促進自動編碼實務的可能性，我們在本地電腦設定中探討了一些解決方案；此外，我們探討了說明功能在 AI 模型透明度中的功能。我們使用公開的 MIMIC-III 資料庫和 HAN/HLAN 網路模型進行 ICD 代碼預測。我們還試驗了 ICD 和 SNOMED CT 知識庫之間的對應。在我們的實驗中，這些模型提供了 97.98% 代碼的有用資訊。這項調查結果可以為實務中的自動臨床編碼實作提供一些見解，例如在醫院環境中，由臨床醫生使用的本地電腦，專案頁面 \url{https://github.com/Glenj01/Medical-Coding}。

##### **Explainable AI for Enhancing Efficiency of DL-based Channel Estimation**
2407.07009v1 by Abdul Karim Gizzini, Yahia Medjahdi, Ali J. Ghandour, Laurent Clavier

The support of artificial intelligence (AI) based decision-making is a key
element in future 6G networks, where the concept of native AI will be
introduced. Moreover, AI is widely employed in different critical applications
such as autonomous driving and medical diagnosis. In such applications, using
AI as black-box models is risky and challenging. Hence, it is crucial to
understand and trust the decisions taken by these models. Tackling this issue
can be achieved by developing explainable AI (XAI) schemes that aim to explain
the logic behind the black-box model behavior, and thus, ensure its efficient
and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST
framework that is oriented toward channel estimation in wireless
communications. The core idea of the XAI-CHEST framework is to identify the
relevant model inputs by inducing high noise on the irrelevant ones. This
manuscript provides the detailed theoretical foundations of the XAI-CHEST
framework. In particular, we derive the analytical expressions of the XAI-CHEST
loss functions and the noise threshold fine-tuning optimization problem. Hence
the designed XAI-CHEST delivers a smart input feature selection methodology
that can further improve the overall performance while optimizing the
architecture of the employed model. Simulation results show that the XAI-CHEST
framework provides valid interpretations, where it offers an improved bit error
rate performance while reducing the required computational complexity in
comparison to the classical DL-based channel estimation.

摘要：人工智能 (AI) 支持的決策制定是未來 6G 網路中的關鍵元素，其中將引入原生 AI 的概念。此外，AI 廣泛用於不同的關鍵應用中，例如自動駕駛和醫療診斷。在這些應用中，使用 AI 作為黑盒模型是有風險且具有挑戰性的。因此，理解和信任這些模型做出的決策至關重要。解決此問題的方法是開發可解釋 AI (XAI) 架構，旨在解釋黑盒模型行為背後的邏輯，從而確保其有效且安全的部署。最近，我們提出了一個新的基於擾動的 XAI-CHEST 框架，該框架面向無線通信中的信道估計。XAI-CHEST 框架的核心思想是通過在無關輸入上引入高噪聲來識別相關模型輸入。這份手稿提供了 XAI-CHEST 框架的詳細理論基礎。特別是，我們推導了 XAI-CHEST 損失函數和噪聲閾值微調優化問題的解析表達式。因此，設計的 XAI-CHEST 提供了一種智能輸入特徵選擇方法，可以在優化所用模型的架構的同時進一步提高整體性能。模擬結果表明，XAI-CHEST 框架提供了有效的解釋，在降低所需的計算複雜度的同時，提供了改進的比特錯誤率性能，而這與基於傳統 DL 的信道估計相比。

##### **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification**
2407.05440v2 by P. N. Karthikayan, Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Umarani Jayaraman

This paper presents dilated Residual Network (ResNet) models for disease
classification from retinal fundus images. Dilated convolution filters are used
to replace normal convolution filters in the higher layers of the ResNet model
(dilated ResNet) in order to improve the receptive field compared to the normal
ResNet model for disease classification. This study introduces
computer-assisted diagnostic tools that employ deep learning, enhanced with
explainable AI techniques. These techniques aim to make the tool's
decision-making process transparent, thereby enabling medical professionals to
understand and trust the AI's diagnostic decision. They are particularly
relevant in today's healthcare landscape, where there is a growing demand for
transparency in AI applications to ensure their reliability and ethical use.
The dilated ResNet is used as a replacement for the normal ResNet to enhance
the classification accuracy of retinal eye diseases and reduce the required
computing time. The dataset used in this work is the Ocular Disease Intelligent
Recognition (ODIR) dataset which is a structured ophthalmic database with eight
classes covering most of the common retinal eye diseases. The evaluation
metrics used in this work include precision, recall, accuracy, and F1 score. In
this work, a comparative study has been made between normal ResNet models and
dilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,
ResNet-101, and ResNet-152. The dilated ResNet model shows promising results as
compared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,
and 0.70 respectively for the above respective variants in ODIR multiclass
disease classification.

摘要：这篇论文提出了用于从视网膜眼底图像进行疾病分类的扩张残差网络 (ResNet) 模型。扩张卷积滤波器用于替换 ResNet 模型较高层中的正常卷积滤波器（扩张 ResNet），以改善感知场，从而针对疾病分类对正常 ResNet 模型进行改进。本研究引入了采用深度学习的计算机辅助诊断工具，并通过可解释的 AI 技术进行了增强。这些技术旨在使该工具的决策过程透明化，从而使医学专业人士能够理解和信任 AI 的诊断决策。它们与当今的医疗保健领域尤为相关，在该领域，对 AI 应用的透明度需求不断增长，以确保其可靠性和合乎道德的使用。扩张 ResNet 用作正常 ResNet 的替代品，以提高视网膜眼部疾病的分类准确性并减少所需的计算时间。本工作中使用的数据集是眼科疾病智能识别 (ODIR) 数据集，这是一个结构化的眼科数据库，包含八类涵盖大多数常见视网膜眼部疾病。本工作中使用的评估指标包括精确度、召回率、准确度和 F1 得分。在这项工作中，对 ResNet-18、ResNet-34、ResNet-50、ResNet-101 和 ResNet-152 五个变体的正常 ResNet 模型和扩张 ResNet 模型进行了比较研究。与正常 ResNet 相比，扩张 ResNet 模型显示出有希望的结果，在 ODIR 多类疾病分类中，上述各个变体的平均 F1 得分为 0.71、0.70、0.69、0.67 和 0.70。

##### **A Survey on Trustworthiness in Foundation Models for Medical Image Analysis**
2407.15851v2 by Congzhen Shi, Ryan Rezai, Jiaxi Yang, Qi Dou, Xiaoxiao Li

The rapid advancement of foundation models in medical imaging represents a
significant leap toward enhancing diagnostic accuracy and personalized
treatment. However, the deployment of foundation models in healthcare
necessitates a rigorous examination of their trustworthiness, encompassing
privacy, robustness, reliability, explainability, and fairness. The current
body of survey literature on foundation models in medical imaging reveals
considerable gaps, particularly in the area of trustworthiness. Additionally,
existing surveys on the trustworthiness of foundation models do not adequately
address their specific variations and applications within the medical imaging
domain. This survey aims to fill that gap by presenting a novel taxonomy of
foundation models used in medical imaging and analyzing the key motivations for
ensuring their trustworthiness. We review current research on foundation models
in major medical imaging applications, focusing on segmentation, medical report
generation, medical question and answering (Q\&A), and disease diagnosis. These
areas are highlighted because they have seen a relatively mature and
substantial number of foundation models compared to other applications. We
focus on literature that discusses trustworthiness in medical image analysis
manuscripts. We explore the complex challenges of building trustworthy
foundation models for each application, summarizing current concerns and
strategies for enhancing trustworthiness. Furthermore, we examine the potential
of these models to revolutionize patient care. Our analysis underscores the
imperative for advancing towards trustworthy AI in medical image analysis,
advocating for a balanced approach that fosters innovation while ensuring
ethical and equitable healthcare delivery.

摘要：基礎模型在醫學影像方面的快速進展，代表著在加強診斷準確性和個人化治療方面邁出一大步。然而，基礎模型在醫療保健中的部署需要對其可信度進行嚴格的審查，包括隱私、穩健性、可靠性、可解釋性和公平性。目前關於醫學影像中基礎模型的調查文獻中顯示出相當大的差距，特別是在可信度方面。此外，現有關於基礎模型可信度的調查並未充分解決其在醫學影像領域中的特定變化和應用。本調查旨在通過提出醫學影像中使用的基礎模型的新分類法並分析確保其可信度的關鍵動機，來填補這一空白。我們回顧了基礎模型在主要醫學影像應用中的當前研究，重點關注分割、醫療報告生成、醫療問題和回答 (Q&A) 以及疾病診斷。這些領域之所以被強調，是因為與其他應用相比，它們已經看到相對成熟且大量的基礎模型。我們專注於探討醫學影像分析手稿中可信度的文獻。我們探討了為每個應用構建可信基礎模型的複雜挑戰，總結了當前關注點和增強可信度的策略。此外，我們探討了這些模型在革新患者護理方面的潛力。我們的分析強調了在醫學影像分析中朝著可信賴的人工智慧邁進的必要性，並倡導一種平衡的方法，既能促進創新，又能確保道德和公平的醫療保健服務。

##### **The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data**
2407.06206v1 by Ximing Wen, Rosina O. Weber, Anik Sen, Darryl Hannan, Steven C. Nesbit, Vincent Chan, Alberto Goffi, Michael Morris, John C. Hunninghake, Nicholas E. Villalobos, Edward Kim, Christopher J. MacLellan

Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and
interpreting ultrasound scans right at the patient's bedside. However, the
expertise needed to interpret these images is considerable and may not always
be present in emergency situations. This reality makes algorithms such as
machine learning classifiers extremely valuable to augment human decisions.
POCUS devices are becoming available at a reasonable cost in the size of a
mobile phone. The challenge of turning POCUS devices into life-saving tools is
that interpretation of ultrasound images requires specialist training and
experience. Unfortunately, the difficulty to obtain positive training images
represents an important obstacle to building efficient and accurate
classifiers. Hence, the problem we try to investigate is how to explore
strategies to increase accuracy of classifiers trained with scarce data. We
hypothesize that training with a few data instances may not suffice for
classifiers to generalize causing them to overfit. Our approach uses an
Explainable AI-Augmented approach to help the algorithm learn more from less
and potentially help the classifier better generalize.

摘要：床邊超音波 (POCUS) 是臨床醫師在患者床邊進行和解讀超音波掃描的實務。然而，解讀這些影像所需的專業知識相當可觀，而且在緊急情況下可能並非隨時具備。這種現實情況使得機器學習分類器等演算法對於加強人類決策變得極為有價值。POCUS 裝置正以合理成本推出，尺寸為手機大小。將 POCUS 裝置轉變為救生工具的挑戰在於，解讀超音波影像需要專門訓練和經驗。不幸的是，取得正向訓練影像的困難度代表著建置有效率且準確的分類器的一大障礙。因此，我們嘗試探討的問題是如何探索策略，以提高使用稀疏資料訓練的分類器的準確度。我們假設使用少數資料實例進行訓練可能不足以讓分類器概括，導致它們過度擬合。我們的做法使用可解釋 AI 增強方法，以協助演算法從較少的資料中學習更多，並潛在協助分類器更好地概括。

##### **Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach**
2407.00167v1 by Sai Krishna Revanth Vuruma, Dezhi Wu, Saborny Sen Gupta, Lucas Aust, Valerie Lookingbill, Wyatt Bellamy, Yang Ren, Erin Kasson, Li-Shiun Chen, Patricia Cavazos-Rehg, Dian Hu, Ming Huang

In recent years, the United States has witnessed a significant surge in the
popularity of vaping or e-cigarette use, leading to a notable rise in cases of
e-cigarette and vaping use-associated lung injury (EVALI) that caused
hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting
the urgency to comprehend vaping behaviors and develop effective strategies for
cessation. Due to the ubiquity of social media platforms, over 4.7 billion
users worldwide use them for connectivity, communications, news, and
entertainment with a significant portion of the discourse related to health,
thereby establishing social media data as an invaluable organic data resource
for public health research. In this study, we extracted a sample dataset from
one vaping sub-community on Reddit to analyze users' quit-vaping intentions.
Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit
vaping intention detection, this study compares the outcomes of this model
against layman and clinical expert annotations. Using different prompting
strategies such as zero-shot, one-shot, few-shot and chain-of-thought
prompting, we developed 8 prompts with varying levels of detail to explain the
task to GPT-4 and also evaluated the performance of the strategies against each
other. These preliminary findings emphasize the potential of GPT-4 in social
media data analysis, especially in identifying users' subtle intentions that
may elude human detection.

摘要：近年來，美國見證了電子煙或電子香菸使用率大幅激增，導致電子煙和電子煙使用相關肺損傷 (EVALI) 病例顯著增加，在 2019 年 EVALI 爆發期間造成住院和死亡，凸顯了理解電子煙行為和制定有效戒菸策略的迫切性。由於社群媒體平台的普及，全球超過 47 億使用者使用它們進行連結、溝通、新聞和娛樂，其中很大一部分與健康相關，因此將社群媒體資料建立為公共衛生研究中無價的有機資料資源。在本研究中，我們從 Reddit 上一個電子煙子社群中提取一個範例資料集，以分析使用者的戒電子煙意圖。利用 OpenAI 最新的大型語言模型 GPT-4 進行句子層級的戒電子煙意圖偵測，本研究比較了此模型的結果與外行人和臨床專家註解。使用不同的提示策略，例如零次學習、一次學習、少次學習和思考鏈提示，我們開發了 8 個提示，詳細程度不同，向 GPT-4 解釋任務，並評估這些策略彼此之間的效能。這些初步發現強調了 GPT-4 在社群媒體資料分析中的潛力，特別是在識別人類偵測可能無法察覺的使用者微妙意圖方面。

##### **Towards Compositional Interpretability for XAI**
2406.17583v1 by Sean Tull, Robin Lorenz, Stephen Clark, Ilyas Khan, Bob Coecke

Artificial intelligence (AI) is currently based largely on black-box machine
learning models which lack interpretability. The field of eXplainable AI (XAI)
strives to address this major concern, being critical in high-stakes areas such
as the finance, legal and health sectors.
  We present an approach to defining AI models and their interpretability based
on category theory. For this we employ the notion of a compositional model,
which sees a model in terms of formal string diagrams which capture its
abstract structure together with its concrete implementation. This
comprehensive view incorporates deterministic, probabilistic and quantum
models. We compare a wide range of AI models as compositional models, including
linear and rule-based models, (recurrent) neural networks, transformers, VAEs,
and causal and DisCoCirc models.
  Next we give a definition of interpretation of a model in terms of its
compositional structure, demonstrating how to analyse the interpretability of a
model, and using this to clarify common themes in XAI. We find that what makes
the standard 'intrinsically interpretable' models so transparent is brought out
most clearly diagrammatically. This leads us to the more general notion of
compositionally-interpretable (CI) models, which additionally include, for
instance, causal, conceptual space, and DisCoCirc models.
  We next demonstrate the explainability benefits of CI models. Firstly, their
compositional structure may allow the computation of other quantities of
interest, and may facilitate inference from the model to the modelled
phenomenon by matching its structure. Secondly, they allow for diagrammatic
explanations for their behaviour, based on influence constraints, diagram
surgery and rewrite explanations. Finally, we discuss many future directions
for the approach, raising the question of how to learn such meaningfully
structured models in practice.

摘要：<paragraph>人工智慧（AI）目前在很大程度上依賴於缺乏可解釋性的黑盒機器學習模型。可解釋性人工智慧（XAI）領域致力於解決這個主要問題，這在金融、法律和健康等高風險領域至關重要。
我們提出了一種基於範疇論定義 AI 模型及其可解釋性的方法。為此，我們採用組合模型的概念，它以形式弦圖的形式看待模型，這些弦圖捕獲了模型的抽象結構及其具體實現。這種綜合觀點包含了確定性、概率性和量子模型。我們將各種 AI 模型作為組合模型進行比較，包括線性和基於規則的模型、（遞迴）神經網路、Transformer、VAE，以及因果和 DisCoCirc 模型。
接下來，我們根據模型的組合結構給出模型解釋的定義，展示如何分析模型的可解釋性，並使用它來澄清 XAI 中的常見主題。我們發現，讓標準的「內在可解釋」模型如此透明的原因在圖表中表現得最為清楚。這引導我們得出更一般的組合可解釋（CI）模型概念，它另外還包括因果、概念空間和 DisCoCirc 模型。
接下來，我們展示了 CI 模型的可解釋性優勢。首先，它們的組合結構允許計算其他感興趣的量，並可能通過匹配模型的結構來促進從模型到被建模現象的推理。其次，它們允許對其行為進行圖解說明，這些說明基於影響約束、圖解手術和重寫說明。最後，我們討論了這種方法的許多未來方向，提出了如何在實踐中學習這種有意義的結構化模型的問題。</paragraph>

##### **Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods**
2406.12142v2 by Vincent Olesen, Nina Weng, Aasa Feragen, Eike Petersen

Machine learning models have achieved high overall accuracy in medical image
analysis. However, performance disparities on specific patient groups pose
challenges to their clinical utility, safety, and fairness. This can affect
known patient groups - such as those based on sex, age, or disease subtype - as
well as previously unknown and unlabeled groups. Furthermore, the root cause of
such observed performance disparities is often challenging to uncover,
hindering mitigation efforts. In this paper, to address these issues, we
leverage Slice Discovery Methods (SDMs) to identify interpretable
underperforming subsets of data and formulate hypotheses regarding the cause of
observed performance disparities. We introduce a novel SDM and apply it in a
case study on the classification of pneumothorax and atelectasis from chest
x-rays. Our study demonstrates the effectiveness of SDMs in hypothesis
formulation and yields an explanation of previously observed but unexplained
performance disparities between male and female patients in widely used chest
X-ray datasets and models. Our findings indicate shortcut learning in both
classification tasks, through the presence of chest drains and ECG wires,
respectively. Sex-based differences in the prevalence of these shortcut
features appear to cause the observed classification performance gap,
representing a previously underappreciated interaction between shortcut
learning and model fairness analyses.

摘要：機器學習模型在醫學影像分析中已達到整體高準確度。然而，特定患者群體的效能差異對其臨床效用、安全性與公平性構成挑戰。這可能會影響已知的患者群體（例如基於性別、年齡或疾病亞型）以及先前未知且未標籤的群體。此外，此類觀察到的效能差異的根本原因通常難以發現，阻礙了緩解措施。在本文中，為了解決這些問題，我們利用切片發現方法 (SDM) 來識別可解釋的資料效能不佳子集，並針對觀察到的效能差異原因制定假設。我們引入一種新的 SDM，並在胸部 X 光片中肺炎和肺不張分類的案例研究中應用它。我們的研究證明了 SDM 在假設制定中的有效性，並對廣泛使用的胸部 X 光片資料集和模型中先前觀察到但無法解釋的男性和女性患者之間的效能差異提供了解釋。我們的發現表明，在分類任務中，透過胸腔引流管和心電圖導線的存在，存在捷徑學習。這些捷徑特徵的盛行率存在基於性別的差異，似乎會導致觀察到的分類效能差距，這代表捷徑學習和模型公平性分析之間先前未受到重視的交互作用。

##### **Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health**
2406.07114v2 by Fatemeh Ebrahimzadeh, Ramin Safa

The concept of Metaverse has attracted a lot of attention in various fields
and one of its important applications is health and treatment. The Metaverse
has enormous potential to transform healthcare by changing patient care,
medical education, and the way teaching/learning and research are done. The
purpose of this research is to provide an introduction to the basic concepts
and fundamental technologies of the Metaverse. This paper examines the pros and
cons of the Metaverse in healthcare context and analyzes its potential from the
technology and AI perspective. In particular, the role of machine learning
methods is discussed; We will explain how machine learning algorithms can be
applied to the Metaverse generated data to gain better insights in healthcare
applications. Additionally, we examine the future visions of the Metaverse in
health delivery, by examining emerging technologies such as blockchain and also
addressing privacy concerns. The findings of this study contribute to a deeper
understanding of the applications of Metaverse in healthcare and its potential
to revolutionize the delivery of medical services.

摘要：元宇宙的概念在各個領域都備受關注，其重要應用之一便是醫療保健。元宇宙有巨大的潛力透過改變病患照護、醫學教育，以及教學/學習和研究的方式來轉型醫療保健。本研究的目的是提供元宇宙基本概念和基礎技術的介紹。本文探討了元宇宙在醫療保健背景下的優缺點，並從技術和 AI 的角度分析其潛力。特別是，討論了機器學習方法的角色；我們將說明如何將機器學習演算法應用於元宇宙產生的資料，以獲得醫療保健應用方面的更佳見解。此外，我們透過探討區塊鏈等新興技術，並解決隱私問題，來探討元宇宙在醫療保健方面的未來願景。本研究的發現有助於更深入地了解元宇宙在醫療保健中的應用，以及其在醫療服務提供方面發揮革命性變革的潛力。

##### **AI-Driven Predictive Analytics Approach for Early Prognosis of Chronic Kidney Disease Using Ensemble Learning and Explainable AI**
2406.06728v1 by K M Tawsik Jawad, Anusha Verma, Fathi Amsaad

Chronic Kidney Disease (CKD) is one of the widespread Chronic diseases with
no known ultimo cure and high morbidity. Research demonstrates that progressive
Chronic Kidney Disease (CKD) is a heterogeneous disorder that significantly
impacts kidney structure and functions, eventually leading to kidney failure.
With the progression of time, chronic kidney disease has moved from a
life-threatening disease affecting few people to a common disorder of varying
severity. The goal of this research is to visualize dominating features,
feature scores, and values exhibited for early prognosis and detection of CKD
using ensemble learning and explainable AI. For that, an AI-driven predictive
analytics approach is proposed to aid clinical practitioners in prescribing
lifestyle modifications for individual patients to reduce the rate of
progression of this disease. Our dataset is collected on body vitals from
individuals with CKD and healthy subjects to develop our proposed AI-driven
solution accurately. In this regard, blood and urine test results are provided,
and ensemble tree-based machine-learning models are applied to predict unseen
cases of CKD. Our research findings are validated after lengthy consultations
with nephrologists. Our experiments and interpretation results are compared
with existing explainable AI applications in various healthcare domains,
including CKD. The comparison shows that our developed AI models, particularly
the Random Forest model, have identified more features as significant
contributors than XgBoost. Interpretability (I), which measures the ratio of
important to masked features, indicates that our XgBoost model achieved a
higher score, specifically a Fidelity of 98\%, in this metric and naturally in
the FII index compared to competing models.

摘要：慢性腎臟病（CKD）是一種廣泛的慢性疾病，沒有已知的最終療法且發病率很高。研究表明，進行性慢性腎臟病（CKD）是一種異質性疾病，會顯著影響腎臟結構和功能，最終導致腎衰竭。隨著時間的推移，慢性腎臟病已從影響少數人的致命疾病轉變為一種嚴重程度不同的常見疾病。本研究的目標是使用集成學習和可解釋的 AI 進行早期預後和 CKD 檢測，並視覺化主導特徵、特徵分數和表現出的值。為此，提出了一種 AI 驅動的預測分析方法，以幫助臨床醫生為個別患者開具生活方式修改建議，以降低這種疾病的進展速度。我們的數據集是從 CKD 患者和健康受試者的身體生命體徵中收集的，以準確開發我們提出的 AI 驅動的解決方案。在這方面，提供了血液和尿液檢測結果，並應用基於集成樹的機器學習模型來預測未發現的 CKD 病例。我們的研究結果經過與腎臟科醫生的長期諮詢後得到驗證。我們的實驗和解釋結果與各種醫療保健領域中現有的可解釋 AI 應用進行了比較，包括 CKD。比較表明，我們開發的 AI 模型，特別是隨機森林模型，已經確定了比 XgBoost 更多作為重要貢獻者的特徵。可解釋性 (I) 衡量重要特徵與掩蓋特徵的比率，表明我們的 XgBoost 模型在這個指標中獲得了更高的分數，特別是 98% 的保真度，並且在 FII 指數中自然高於競爭模型。

##### **Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook**
2406.05984v1 by Yusif Ibrahimov, Tarique Anwar, Tommy Yuan

Mental health constitutes a complex and pervasive global challenge, affecting
millions of lives and often leading to severe consequences. In this paper, we
conduct a thorough survey to explore the intersection of data science,
artificial intelligence, and mental healthcare, focusing on the recent
developments of mental disorder detection through online social media (OSM). A
significant portion of the population actively engages in OSM platforms,
creating a vast repository of personal data that holds immense potential for
mental health analytics. The paper navigates through traditional diagnostic
methods, state-of-the-art data- and AI-driven research studies, and the
emergence of explainable AI (XAI) models for mental healthcare. We review
state-of-the-art machine learning methods, particularly those based on modern
deep learning, while emphasising the need for explainability in healthcare AI
models. The experimental design section provides insights into prevalent
practices, including available datasets and evaluation approaches. We also
identify key issues and challenges in the field and propose promising future
research directions. As mental health decisions demand transparency,
interpretability, and ethical considerations, this paper contributes to the
ongoing discourse on advancing XAI in mental healthcare through social media.
The comprehensive overview presented here aims to guide researchers,
practitioners, and policymakers in developing the area of mental disorder
detection.

摘要：心理健康構成了一項複雜且普遍的全球挑戰，影響了數百萬人的生活，並經常導致嚴重的後果。在本文中，我們進行了一項徹底的調查，以探索數據科學、人工智慧和心理保健的交集，重點關注通過線上社交媒體 (OSM) 進行心理疾病檢測的最新發展。很大一部分人口積極參與 OSM 平台，創造了一個龐大的人員資料庫，對心理健康分析具有巨大的潛力。本文探討了傳統的診斷方法、最先進的資料和 AI 驅動的研究，以及心理保健中可解釋 AI (XAI) 模型的出現。我們回顧了最先進的機器學習方法，特別是那些基於現代深度學習的方法，同時強調了醫療保健 AI 模型中可解釋性的必要性。實驗設計部分提供了對普遍做法的見解，包括可用的資料集和評估方法。我們還找出該領域的主要問題和挑戰，並提出了有希望的未來研究方向。由於心理健康決策需要透明度、可解釋性和道德考量，本文有助於推進心理保健中透過社交媒體推進 XAI 的持續討論。這裡提出的全面概述旨在引導研究人員、從業人員和政策制定者發展心理疾病檢測領域。

##### **Methodology and Real-World Applications of Dynamic Uncertain Causality Graph for Clinical Diagnosis with Explainability and Invariance**
2406.05746v1 by Zhan Zhang, Qin Zhang, Yang Jiao, Lin Lu, Lin Ma, Aihua Liu, Xiao Liu, Juan Zhao, Yajun Xue, Bing Wei, Mingxia Zhang, Ru Gao, Hong Zhao, Jie Lu, Fan Li, Yang Zhang, Yiming Wang, Lei Zhang, Fengwei Tian, Jie Hu, Xin Gou

AI-aided clinical diagnosis is desired in medical care. Existing deep
learning models lack explainability and mainly focus on image analysis. The
recently developed Dynamic Uncertain Causality Graph (DUCG) approach is
causality-driven, explainable, and invariant across different application
scenarios, without problems of data collection, labeling, fitting, privacy,
bias, generalization, high cost and high energy consumption. Through close
collaboration between clinical experts and DUCG technicians, 46 DUCG models
covering 54 chief complaints were constructed. Over 1,000 diseases can be
diagnosed without triage. Before being applied in real-world, the 46 DUCG
models were retrospectively verified by third-party hospitals. The verified
diagnostic precisions were no less than 95%, in which the diagnostic precision
for every disease including uncommon ones was no less than 80%. After
verifications, the 46 DUCG models were applied in the real-world in China. Over
one million real diagnosis cases have been performed, with only 17 incorrect
diagnoses identified. Due to DUCG's transparency, the mistakes causing the
incorrect diagnoses were found and corrected. The diagnostic abilities of the
clinicians who applied DUCG frequently were improved significantly. Following
the introduction to the earlier presented DUCG methodology, the recommendation
algorithm for potential medical checks is presented and the key idea of DUCG is
extracted.

摘要：<paragraph>醫療照護中需要 AI 輔助的臨床診斷。現有的深度學習模型缺乏可解釋性，並且主要專注於影像分析。最近開發的動態不確定因果關係圖 (DUCG) 方法是因果驅動的、可解釋的，並且在不同的應用場景中是不變的，沒有資料收集、標記、擬合、隱私、偏見、概化、高成本和高能耗的問題。通過臨床專家和 DUCG 技術人員之間的密切合作，構建了涵蓋 54 個主訴的 46 個 DUCG 模型。可以在沒有分流的情況下診斷出 1,000 多種疾病。在應用於實際世界之前，46 個 DUCG 模型已由第三方醫院回溯性驗證。驗證的診斷精度不低於 95%，其中包括罕見疾病在內的每種疾病的診斷精度不低於 80%。驗證後，46 個 DUCG 模型已在中國實際應用。已經執行了超過一百萬個真實診斷案例，僅發現 17 個不正確的診斷。由於 DUCG 的透明性，發現並糾正了導致不正確診斷的錯誤。頻繁應用 DUCG 的臨床醫生的診斷能力得到了顯著提高。在介紹了前面提出的 DUCG 方法論之後，提出了潛在健康檢查的推薦演算法，並提取了 DUCG 的關鍵思想。</paragraph>

##### **Advancing Histopathology-Based Breast Cancer Diagnosis: Insights into Multi-Modality and Explainability**
2406.12897v1 by Faseela Abdullakutty, Younes Akbari, Somaya Al-Maadeed, Ahmed Bouridane, Rifat Hamoudi

It is imperative that breast cancer is detected precisely and timely to
improve patient outcomes. Diagnostic methodologies have traditionally relied on
unimodal approaches; however, medical data analytics is integrating diverse
data sources beyond conventional imaging. Using multi-modal techniques,
integrating both image and non-image data, marks a transformative advancement
in breast cancer diagnosis. The purpose of this review is to explore the
burgeoning field of multimodal techniques, particularly the fusion of
histopathology images with non-image data. Further, Explainable AI (XAI) will
be used to elucidate the decision-making processes of complex algorithms,
emphasizing the necessity of explainability in diagnostic processes. This
review utilizes multi-modal data and emphasizes explainability to enhance
diagnostic accuracy, clinician confidence, and patient engagement, ultimately
fostering more personalized treatment strategies for breast cancer, while also
identifying research gaps in multi-modality and explainability, guiding future
studies, and contributing to the strategic direction of the field.

摘要：精確且及時地偵測乳癌對於改善患者預後至關重要。診斷方法傳統上依賴於單一模式方法；然而，醫療資料分析正在整合超越傳統影像的各種資料來源。使用整合影像和非影像資料的多模式技術，標誌著乳癌診斷的變革性進展。本篇綜述的目的是探討多模式技術的新興領域，特別是將組織病理學影像與非影像資料融合。此外，可解釋人工智慧 (XAI) 將用於闡明複雜演算法的決策過程，強調診斷過程中可解釋性的必要性。本綜述利用多模式資料並強調可解釋性，以提高診斷準確性、臨床醫師的信心和患者參與度，最終促進乳癌更個人化的治療策略，同時也找出多模式和可解釋性的研究差距，引導未來的研究，並為該領域的策略方向做出貢獻。

##### **Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks**
2406.04612v1 by Yong-Min Shin, Siqing Li, Xin Cao, Won-Yong Shin

The self-attention mechanism has been adopted in several widely-used
message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls
the amount of information that flows along the edges of the underlying graph.
This usage of attention has made such models a baseline for studies on
explainable AI (XAI) since interpretations via attention have been popularized
in various domains (e.g., natural language processing and computer vision).
However, existing studies often use naive calculations to derive attribution
scores from attention, and do not take the precise and careful calculation of
edge attribution into consideration. In our study, we aim to fill the gap
between the widespread usage of attention-enabled MPNNs and their potential in
largely under-explored explainability, a topic that has been actively
investigated in other areas. To this end, as the first attempt, we formalize
the problem of edge attribution from attention weights in GNNs. Then, we
propose GATT, an edge attribution calculation method built upon the computation
tree. Through comprehensive experiments, we demonstrate the effectiveness of
our proposed method when evaluating attributions from GATs. Conversely, we
empirically validate that simply averaging attention weights over graph
attention layers is insufficient to interpret the GAT model's behavior. Code is
publicly available at https://github.com/jordan7186/GAtt/tree/main.

摘要：自注意力機制已被採用於多個廣泛使用的訊息傳遞神經網路 (MPNN)（例如 GAT），它可以自適應地控制沿著底層圖形邊緣流動的資訊量。這種注意力的使用使得此類模型成為可解釋 AI (XAI) 研究的基線，因為透過注意力的詮釋已在各種領域（例如自然語言處理和電腦視覺）中普及。然而，現有的研究通常使用天真的計算方法從注意力中推導出歸因分數，並且沒有考慮到邊緣歸因的精確且仔細的計算。在我們的研究中，我們旨在填補注意力啟用 MPNN 的廣泛使用與它們在很大程度上未被充分探索的可解釋性之間的差距，這個主題已在其他領域積極研究。為此，作為第一次嘗試，我們將 GNN 中注意力權重的邊緣歸因問題形式化。然後，我們提出 GATT，一種建立在計算樹上的邊緣歸因計算方法。透過全面的實驗，我們展示了我們提出的方法在評估 GAT 的歸因時所具有的效果。相反地，我們憑經驗驗證了僅對圖注意力層上的注意力權重取平均值不足以詮釋 GAT 模型的行為。程式碼已公開於 https://github.com/jordan7186/GAtt/tree/main。

##### **Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection**
2406.16908v3 by Dinuka Sandun Udayantha, Kavindu Weerasinghe, Nima Wickramasinghe, Akila Abeyratne, Kithmin Wickremasinghe, Jithangi Wanigasinghe, Anjula De Silva, Chamira U. S. Edussooriya

The neonatal period is the most vulnerable time for the development of
seizures. Seizures in the immature brain lead to detrimental consequences,
therefore require early diagnosis. The gold-standard for neonatal seizure
detection currently relies on continuous video-EEG monitoring; which involves
recording multi-channel electroencephalogram (EEG) alongside real-time video
monitoring within a neonatal intensive care unit (NICU). However, video-EEG
monitoring technology requires clinical expertise and is often limited to
technologically advanced and resourceful settings. Cost-effective new
techniques could help the medical fraternity make an accurate diagnosis and
advocate treatment without delay. In this work, a novel explainable deep
learning model to automate the neonatal seizure detection process with a
reduced EEG montage is proposed, which employs convolutional nets, graph
attention layers, and fully connected layers. Beyond its ability to detect
seizures in real-time with a reduced montage, this model offers the unique
advantage of real-time interpretability. By evaluating the performance on the
Zenodo dataset with 10-fold cross-validation, the presented model achieves an
absolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,
respectively.

摘要：新生兒期是大腦發育最脆弱的時期，容易出現癲癇發作。大腦發育不成熟時出現癲癇發作會造成不良後果，因此需要及早診斷。目前新生兒癲癇發作的黃金標準依賴於連續的視訊腦電圖 (EEG) 監測；其中包括在新生兒加護病房 (NICU) 內同時進行多頻道腦電圖 (EEG) 記錄和即時視訊監控。然而，視訊腦電圖監控技術需要臨床專業知識，而且通常僅限於技術先進且資源豐富的環境。具成本效益的新技術可以幫助醫療界準確診斷並立即提倡治療。在這項工作中，提出了一個新穎的可解釋深度學習模型，以自動化新生兒癲癇發作偵測過程，並採用減少的腦電圖裝置，其中採用了卷積神經網路、圖形注意力層和全連接層。除了能夠使用減少的裝置即時偵測癲癇發作外，此模型還提供了即時可解釋性的獨特優勢。透過在 Zenodo 資料集上使用 10 倍交叉驗證評估效能，所提出的模型在曲線下面積 (AUC) 和召回率方面分別達到了 8.31% 和 42.86% 的絕對改善。

##### **Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques**
2406.00532v1 by Samita Bai, Sidra Nasir, Rizwan Ahmed Khan, Sheeraz Arif, Alexandre Meyer, Hubert Konik

Breast cancer (BC) stands as one of the most common malignancies affecting
women worldwide, necessitating advancements in diagnostic methodologies for
better clinical outcomes. This article provides a comprehensive exploration of
the application of Explainable Artificial Intelligence (XAI) techniques in the
detection and diagnosis of breast cancer. As Artificial Intelligence (AI)
technologies continue to permeate the healthcare sector, particularly in
oncology, the need for transparent and interpretable models becomes imperative
to enhance clinical decision-making and patient care. This review discusses the
integration of various XAI approaches, such as SHAP, LIME, Grad-CAM, and
others, with machine learning and deep learning models utilized in breast
cancer detection and classification. By investigating the modalities of breast
cancer datasets, including mammograms, ultrasounds and their processing with
AI, the paper highlights how XAI can lead to more accurate diagnoses and
personalized treatment plans. It also examines the challenges in implementing
these techniques and the importance of developing standardized metrics for
evaluating XAI's effectiveness in clinical settings. Through detailed analysis
and discussion, this article aims to highlight the potential of XAI in bridging
the gap between complex AI models and practical healthcare applications,
thereby fostering trust and understanding among medical professionals and
improving patient outcomes.

摘要：乳癌 (BC) 是影響全球女性最常見的惡性腫瘤之一，因此需要進步的診斷方法，以改善臨床結果。本文全面探討了可解釋人工智慧 (XAI) 技術在乳癌偵測和診斷中的應用。隨著人工智慧 (AI) 技術持續滲透醫療保健領域，特別是在腫瘤學中，透明且可解釋的模型需求變得勢在必行，以增強臨床決策制定和患者照護。此篇評論探討了各種 XAI 方法的整合，例如 SHAP、LIME、Grad-CAM 等，以及用於乳癌偵測和分類的機器學習和深度學習模型。透過探討乳癌資料集的模式，包括乳房攝影、超音波及其在 AI 中的處理，本文重點說明 XAI 如何能導致更準確的診斷和個人化治療計畫。它也探討了實施這些技術的挑戰，以及制定標準化評量指標以評估 XAI 在臨床環境中的有效性的重要性。透過詳細的分析和討論，本文旨在強調 XAI 在縮小複雜 AI 模型與實務醫療保健應用之間差距的潛力，進而促進醫療專業人員之間的信任與理解，並改善患者的結果。

##### **Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech Emotion Recognition**
2406.01624v2 by Alaa Nfissi, Wassim Bouachir, Nizar Bouguila, Brian Mishara

Speech emotion recognition (SER) has gained significant attention due to its
several application fields, such as mental health, education, and
human-computer interaction. However, the accuracy of SER systems is hindered by
high-dimensional feature sets that may contain irrelevant and redundant
information. To overcome this challenge, this study proposes an iterative
feature boosting approach for SER that emphasizes feature relevance and
explainability to enhance machine learning model performance. Our approach
involves meticulous feature selection and analysis to build efficient SER
systems. In addressing our main problem through model explainability, we employ
a feature evaluation loop with Shapley values to iteratively refine feature
sets. This process strikes a balance between model performance and
transparency, which enables a comprehensive understanding of the model's
predictions. The proposed approach offers several advantages, including the
identification and removal of irrelevant and redundant features, leading to a
more effective model. Additionally, it promotes explainability, facilitating
comprehension of the model's predictions and the identification of crucial
features for emotion determination. The effectiveness of the proposed method is
validated on the SER benchmarks of the Toronto emotional speech set (TESS),
Berlin Database of Emotional Speech (EMO-DB), Ryerson Audio-Visual Database of
Emotional Speech and Song (RAVDESS), and Surrey Audio-Visual Expressed Emotion
(SAVEE) datasets, outperforming state-of-the-art methods. To the best of our
knowledge, this is the first work to incorporate model explainability into an
SER framework. The source code of this paper is publicly available via this
https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition.

摘要：語音情緒辨識 (SER) 由於其在心理健康、教育和人機互動等多個應用領域而備受關注。然而，SER 系統的準確性受到高維特徵集的阻礙，這些特徵集可能包含不相關和冗餘的資訊。為了克服這個挑戰，本研究提出了一種用於 SER 的迭代特徵提升方法，該方法強調特徵相關性和可解釋性，以增強機器學習模型的效能。我們的做法涉及仔細的特徵選擇和分析，以建立高效的 SER 系統。為了透過模型可解釋性解決我們的核心問題，我們採用了具有 Shapley 值的特徵評估迴圈，以反覆改善特徵集。這個過程在模型效能和透明度之間取得平衡，這使得我們能夠全面了解模型的預測。所提出的方法提供了多項優點，包括識別和移除不相關和冗餘的特徵，從而建立更有效的模型。此外，它促進了可解釋性，有助於理解模型的預測以及識別情緒決定的關鍵特徵。所提出的方法的有效性已在多倫多情緒語音集 (TESS)、柏林情緒語音資料庫 (EMO-DB)、賴爾森音訊視覺情緒語音和歌曲資料庫 (RAVDESS) 和薩里音訊視覺表達情緒 (SAVEE) 資料集的 SER 基準上得到驗證，其效能優於現有方法。據我們所知，這是第一個將模型可解釋性納入 SER 架構的研究。本文的原始碼可透過此連結公開取得：https://github.com/alaaNfissi/Unveiling-Hidden-Factors-Explainable-AI-for-Feature-Boosting-in-Speech-Emotion-Recognition。

##### **The Explanation Necessity for Healthcare AI**
2406.00216v1 by Michail Mamalakis, Héloïse de Vareilles, Graham Murray, Pietro Lio, John Suckling

Explainability is often critical to the acceptable implementation of
artificial intelligence (AI). Nowhere is this more important than healthcare
where decision-making directly impacts patients and trust in AI systems is
essential. This trust is often built on the explanations and interpretations
the AI provides. Despite significant advancements in AI interpretability, there
remains the need for clear guidelines on when and to what extent explanations
are necessary in the medical context. We propose a novel categorization system
with four distinct classes of explanation necessity, guiding the level of
explanation required: patient or sample (local) level, cohort or dataset
(global) level, or both levels. We introduce a mathematical formulation that
distinguishes these categories and offers a practical framework for researchers
to determine the necessity and depth of explanations required in medical AI
applications. Three key factors are considered: the robustness of the
evaluation protocol, the variability of expert observations, and the
representation dimensionality of the application. In this perspective, we
address the question: When does an AI medical application need to be explained,
and at what level of detail?

摘要：可解释性通常对于人工智能 (AI) 的可接受实施至关重要。在医疗保健领域，这一点尤为重要，因为决策直接影响患者，并且对 AI 系统的信任至关重要。这种信任通常建立在 AI 提供的解释和诠释之上。尽管 AI 可解释性取得了重大进展，但仍然需要明确的指导方针，说明在医疗环境中何时以及在多大程度上需要解释。我们提出了一种新颖的分类系统，该系统具有四种不同的解释必要性类别，指导所需的解释级别：患者或样本（局部）级别、队列或数据集（全局）级别，或两个级别。我们引入了一个数学公式，该公式区分了这些类别，并为研究人员提供了一个实用框架，以确定医疗 AI 应用中所需的解释的必要性和深度。考虑了三个关键因素：评估协议的稳健性、专家观察的可变性以及应用程序的表示维数。从这个角度来看，我们解决了这个问题：AI 医疗应用何时需要解释，以及需要解释到何种程度？

##### **Interdisciplinary Expertise to Advance Equitable Explainable AI**
2406.18563v1 by Chloe R. Bennett, Heather Cole-Lewis, Stephanie Farquhar, Naama Haamel, Boris Babenko, Oran Lang, Mat Fleck, Ilana Traynis, Charles Lau, Ivor Horn, Courtney Lyles

The field of artificial intelligence (AI) is rapidly influencing health and
healthcare, but bias and poor performance persists for populations who face
widespread structural oppression. Previous work has clearly outlined the need
for more rigorous attention to data representativeness and model performance to
advance equity and reduce bias. However, there is an opportunity to also
improve the explainability of AI by leveraging best practices of social
epidemiology and health equity to help us develop hypotheses for associations
found. In this paper, we focus on explainable AI (XAI) and describe a framework
for interdisciplinary expert panel review to discuss and critically assess AI
model explanations from multiple perspectives and identify areas of bias and
directions for future research. We emphasize the importance of the
interdisciplinary expert panel to produce more accurate, equitable
interpretations which are historically and contextually informed.
Interdisciplinary panel discussions can help reduce bias, identify potential
confounders, and identify opportunities for additional research where there are
gaps in the literature. In turn, these insights can suggest opportunities for
AI model improvement.

摘要：人工智慧 (AI) 領域正快速影響著健康與醫療保健，但對於面臨廣泛結構性壓迫的人群來說，偏見和不良表現依然存在。先前的研究已清楚說明，需要更嚴格地注意資料代表性和模型效能，以促進公平性並減少偏見。然而，我們有機會透過運用社會流行病學和健康公平的最佳實務，來改善 AI 的可解釋性，以幫助我們針對發現的關聯性，發展假設。在本文中，我們專注於可解釋 AI (XAI)，並描述一個跨領域專家小組審查架構，以從多重觀點討論和批判性評估 AI 模型的解釋，並找出偏見領域和未來研究的方向。我們強調跨領域專家小組對於產生更準確、公平的詮釋至關重要，而這些詮釋是根據歷史和脈絡而來的。跨領域小組討論有助於減少偏見、找出潛在的混淆因素，並在文獻中有缺口時找出額外研究的機會。反過來，這些見解可以建議 AI 模型改進的機會。

##### **"It depends": Configuring AI to Improve Clinical Usefulness Across Contexts**
2407.11978v1 by Hubert D. Zając, Jorge M. N. Ribeiro, Silvia Ingala, Simona Gentile, Ruth Wanjohi, Samuel N. Gitau, Jonathan F. Carlsen, Michael B. Nielsen, Tariq O. Andersen

Artificial Intelligence (AI) repeatedly match or outperform radiologists in
lab experiments. However, real-world implementations of radiological AI-based
systems are found to provide little to no clinical value. This paper explores
how to design AI for clinical usefulness in different contexts. We conducted 19
design sessions and design interventions with 13 radiologists from 7 clinical
sites in Denmark and Kenya, based on three iterations of a functional AI-based
prototype. Ten sociotechnical dependencies were identified as crucial for the
design of AI in radiology. We conceptualised four technical dimensions that
must be configured to the intended clinical context of use: AI functionality,
AI medical focus, AI decision threshold, and AI Explainability. We present four
design recommendations on how to address dependencies pertaining to the medical
knowledge, clinic type, user expertise level, patient context, and user
situation that condition the configuration of these technical dimensions.

摘要：人工智慧（AI）在實驗室實驗中不斷地與放射科醫師匹敵或表現得更出色。然而，發現放射科 AI 為基礎系統的實際執行幾乎沒有提供臨床價值。本文探討如何為 AI 設計在不同情境中臨床上的效用。我們根據功能性 AI 為基礎原型的三次迭代，在丹麥和肯亞的 7 個臨床場域與 13 位放射科醫師進行了 19 次設計會議和設計介入。十個社會技術依賴關係被認為對於放射科中 AI 的設計至關重要。我們概念化了四個技術面向，必須根據預期的臨床使用情境進行設定：AI 功能、AI 醫療重點、AI 決策門檻，以及 AI 可解釋性。我們提出四項設計建議，說明如何處理與醫療知識、診所類型、使用者專業知識等級、患者情境，以及影響這些技術面向設定的使用者情境相關的依賴關係。

##### **Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making**
2405.16424v1 by Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah

With advanced AI/ML, there has been growing research on explainable AI (XAI)
and studies on how humans interact with AI and XAI for effective human-AI
collaborative decision-making. However, we still have a lack of understanding
of how AI systems and XAI should be first presented to users without technical
backgrounds. In this paper, we present the findings of semi-structured
interviews with health professionals (n=12) and students (n=4) majoring in
medicine and health to study how to improve onboarding with AI and XAI. For the
interviews, we built upon human-AI interaction guidelines to create onboarding
materials of an AI system for stroke rehabilitation assessment and AI
explanations and introduce them to the participants. Our findings reveal that
beyond presenting traditional performance metrics on AI, participants desired
benchmark information, the practical benefits of AI, and interaction trials to
better contextualize AI performance, and refine the objectives and performance
of AI. Based on these findings, we highlight directions for improving
onboarding with AI and XAI and human-AI collaborative decision-making.

摘要：隨著先進的 AI/ML，對可解釋 AI (XAI) 的研究不斷增加，以及關於人類如何與 AI 和 XAI 互動以進行有效的人工智慧協作決策制定。然而，我們仍然缺乏對 AI 系統和 XAI 應如何首先呈現給沒有技術背景的用戶的了解。在本文中，我們展示了與醫療專業人員 (n=12) 和主修醫學和健康的學生 (n=4) 進行半結構化訪談的結果，以研究如何改善 AI 和 XAI 的入門。對於訪談，我們建立在人機互動準則之上，為中風康復評估和 AI 解釋的 AI 系統創建入門材料，並將它們介紹給參與者。我們的研究結果表明，除了呈現傳統的 AI 性能指標外，參與者還希望基准信息、AI 的實際好處以及交互試驗，以更好地將 AI 性能情境化，並完善 AI 的目標和性能。根據這些發現，我們強調了改進 AI 和 XAI 以及人機協作決策制定的入門方向。

##### **Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach**
2405.17502v1 by Ziming Liu, Longjian Liu, Robert E. Heidel, Xiaopeng Zhao

This article uses machine learning (ML) and explainable artificial
intelligence (XAI) techniques to investigate the relationship between
nutritional status and mortality rates associated with Alzheimers disease (AD).
The Third National Health and Nutrition Examination Survey (NHANES III)
database is employed for analysis. The random forest model is selected as the
base model for XAI analysis, and the Shapley Additive Explanations (SHAP)
method is used to assess feature importance. The results highlight significant
nutritional factors such as serum vitamin B12 and glycated hemoglobin. The
study demonstrates the effectiveness of random forests in predicting AD
mortality compared to other diseases. This research provides insights into the
impact of nutrition on AD and contributes to a deeper understanding of disease
progression.

摘要：本文使用機器學習 (ML) 和可解釋人工智慧 (XAI) 技術來探討營養狀況與阿茲海默症 (AD) 相關的死亡率之間的關係。採用第三次全國健康與營養檢查調查 (NHANES III) 資料庫進行分析。選擇隨機森林模型作為 XAI 分析的基礎模型，並使用 Shapley Additive Explanations (SHAP) 方法來評估特徵重要性。結果突顯了重要的營養因素，例如血清維生素 B12 和糖化血紅蛋白。該研究證明了隨機森林在預測 AD 死亡率方面相較於其他疾病的有效性。本研究提供了營養對 AD 的影響的見解，並有助於更深入地了解疾病的進展。

##### **Explainable AI Enhances Glaucoma Referrals, Yet the Human-AI Team Still Falls Short of the AI Alone**
2407.11974v1 by Catalina Gomez, Ruolin Wang, Katharina Breininger, Corinne Casey, Chris Bradley, Mitchell Pavlak, Alex Pham, Jithin Yohannan, Mathias Unberath

Primary care providers are vital for initial triage and referrals to
specialty care. In glaucoma, asymptomatic and fast progression can lead to
vision loss, necessitating timely referrals to specialists. However, primary
eye care providers may not identify urgent cases, potentially delaying care.
Artificial Intelligence (AI) offering explanations could enhance their referral
decisions. We investigate how various AI explanations help providers
distinguish between patients needing immediate or non-urgent specialist
referrals. We built explainable AI algorithms to predict glaucoma surgery needs
from routine eyecare data as a proxy for identifying high-risk patients. We
incorporated intrinsic and post-hoc explainability and conducted an online
study with optometrists to assess human-AI team performance, measuring referral
accuracy and analyzing interactions with AI, including agreement rates, task
time, and user experience perceptions. AI support enhanced referral accuracy
among 87 participants (59.9%/50.8% with/without AI), though Human-AI teams
underperformed compared to AI alone. Participants believed they included AI
advice more when using the intrinsic model, and perceived it more useful and
promising. Without explanations, deviations from AI recommendations increased.
AI support did not increase workload, confidence, and trust, but reduced
challenges. On a separate test set, our black-box and intrinsic models achieved
an accuracy of 77% and 71%, respectively, in predicting surgical outcomes. We
identify opportunities of human-AI teaming for glaucoma management in primary
eye care, noting that while AI enhances referral accuracy, it also shows a
performance gap compared to AI alone, even with explanations. Human involvement
remains essential in medical decision making, underscoring the need for future
research to optimize collaboration, ensuring positive experiences and safe AI
use.

摘要：<paragraph>初級保健提供者對於最初的分流和轉診到專科照護至關重要。在青光眼的情況下，無症狀且快速惡化可能導致視力喪失，因此需要及時轉診給專家。然而，初級眼科保健提供者可能無法識別緊急情況，可能會延誤照護。提供解釋的人工智慧 (AI) 可以加強他們的轉診決策。我們研究各種 AI 解釋如何幫助提供者區分需要立即或非緊急專科轉診的患者。我們建立了解釋性 AI 演算法，以從例行眼科護理資料預測青光眼手術需求，作為識別高風險患者的代理。我們納入了內在和事後解釋性，並與驗光師進行了一項線上研究，以評估人機團隊的表現，衡量轉診準確度並分析與 AI 的互動，包括同意率、任務時間和使用者體驗感知。在 87 名參與者中，AI 支援提高了轉診準確度（使用 AI/未使用的比例為 59.9%/50.8%），儘管人機團隊的表現不如單獨使用 AI。參與者認為他們在使用內在模型時更多地納入了 AI 建議，並認為它更有用且更有希望。沒有解釋，AI 建議的偏差會增加。AI 支援並未增加工作量、信心和信任，但減少了挑戰。在一個單獨的測試集中，我們的黑盒子和內在模型在預測手術結果方面分別達到了 77% 和 71% 的準確度。我們找出在初級眼科保健中，人機團隊合作管理青光眼的機會，並注意到雖然 AI 提高了轉診準確度，但即使有解釋，它也顯示出與單獨使用 AI 相比的效能差距。人類參與在醫療決策中仍然至關重要，這強調了未來研究優化協作、確保正面經驗和安全使用 AI 的必要性。</paragraph>

##### **Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery**
2406.18552v1 by Yingying Fang, Zihao Jin, Xiaodan Xing, Simon Walsh, Guang Yang

In medical imaging, particularly in early disease detection and prognosis
tasks, discerning the rationale behind an AI model's predictions is crucial for
evaluating the reliability of its decisions. Conventional explanation methods
face challenges in identifying discernible decisive features in medical image
classifications, where discriminative features are subtle or not immediately
apparent. To bridge this gap, we propose an explainable model that is equipped
with both decision reasoning and feature identification capabilities. Our
approach not only detects influential image patterns but also uncovers the
decisive features that drive the model's final predictions. By implementing our
method, we can efficiently identify and visualise class-specific features
leveraged by the data-driven model, providing insights into the decision-making
processes of deep learning models. We validated our model in the demanding
realm of medical prognosis task, demonstrating its efficacy and potential in
enhancing the reliability of AI in healthcare and in discovering new knowledge
in diseases where prognostic understanding is limited.

摘要：在醫學影像中，特別是在早期疾病檢測和預後任務中，辨別 AI 模型預測背後的原理對於評估其決策的可靠性至關重要。傳統的解釋方法在識別醫學影像分類中可識別的決定性特徵時面臨挑戰，其中區別性特徵很微妙或並不明顯。為了彌合這一差距，我們提出了一個可解釋的模型，該模型具備決策推理和特徵識別能力。我們的做法不僅檢測有影響力的影像模式，還揭示了推動模型最終預測的決定性特徵。通過實施我們的模型，我們可以有效識別和視覺化由數據驅動模型利用的類特定特徵，從而深入了解深度學習模型的決策過程。我們在要求嚴格的醫學預後任務領域驗證了我們的模型，展示了其在提高 AI 在醫療保健中的可靠性和發現預後理解受限疾病的新知識方面的功效和潛力。

##### **The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach**
2405.13099v1 by Mohsen Jozani, Jason A. Williams, Ahmed Aleroud, Sarbottam Bhagat

This study explores the relationship between informational support seeking
questions, responses, and helpfulness ratings in online health communities. We
created a labeled data set of question-response pairs and developed multimodal
machine learning and deep learning models to reliably predict informational
support questions and responses. We employed explainable AI to reveal the
emotions embedded in informational support exchanges, demonstrating the
importance of emotion in providing informational support. This complex
interplay between emotional and informational support has not been previously
researched. The study refines social support theory and lays the groundwork for
the development of user decision aids. Further implications are discussed.

摘要：本研究探討線上健康社群中尋求資訊支持的問題、回應，以及有幫助的評分之間的關係。我們建立了一組標記的問答配對資料集，並開發了多模態機器學習和深度學習模型，以可靠地預測資訊支持問題和回應。我們採用可解釋的 AI 來揭示資訊支持交流中蘊含的情緒，證明情緒在提供資訊支持中的重要性。這種情緒支持和資訊支持之間的複雜交互作用以前並未被研究過。本研究改進了社會支持理論，並為使用者決策輔助工具的開發奠定了基礎。討論了進一步的影響。

##### **ChatGPT in Classrooms: Transforming Challenges into Opportunities in Education**
2405.10645v1 by Harris Bin Munawar, Nikolaos Misirlis

In the era of exponential technology growth, one unexpected guest has claimed
a seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as
ChatGPT, promises a revolution in education, yet it arrives with a double-edged
sword. Its potential for personalized learning is offset by issues of cheating,
inaccuracies, and educators struggling to incorporate it effectively into their
lesson design. We are standing on the brink of this educational frontier, and
it is clear that we need to navigate this terrain with a lot of care. This is a
major challenge that could undermine the integrity and value of our educational
process. So, how can we turn these challenges into opportunities? When used
inappropriately, AI tools can become the perfect tool for the cut copy paste
mentality, and quickly begin to corrode critical thinking, creativity, and deep
understanding, the most important skills in our rapidly changing world.
Teachers feel that they are not equipped to leverage this technology, widening
the digital divide among educators and institutions. Addressing these concerns
calls for an in depth research approach. We will employ empirical research,
drawing on the Technology Acceptance Model, to assess the attitudes toward
generative AI among educators and students. Understanding their perceptions,
usage patterns, and hurdles is the first crucial step in creating an effective
solution. The present study will be used as a process manual for future
researchers to apply, running their own data, based on the steps explained here

摘要：在科技飛速發展的時代，一位意外的訪客已在全球教室中佔有一席之地，那就是人工智慧。生成式 AI，例如 ChatGPT，承諾在教育領域掀起一場革命，但它卻是一把雙面刃。它在個人化學習方面的潛力，卻因作弊、不準確以及教育工作者難以將其有效融入教學設計等問題而抵銷。我們正站在這教育前沿的邊緣，顯然我們需要非常小心地探索這片領域。這是一個重大的挑戰，可能會損害我們教育過程的完整性和價值。那麼，我們如何將這些挑戰轉化為機遇？當不適當地使用時，AI 工具可能會成為複製貼上心態的完美工具，並迅速腐蝕批判性思維、創造力和深入理解，這些都是我們快速變化的世界中最重要的技能。教師們覺得他們沒有能力利用這項技術，這擴大了教育工作者和機構之間的數位鴻溝。解決這些問題需要深入的研究方法。我們將採用實證研究，借鑑技術接受模型，來評估教育工作者和學生對生成式 AI 的態度。了解他們的看法、使用模式和障礙是創造有效解決方案的第一個關鍵步驟。本研究將作為未來研究人員應用的流程手冊，根據此處說明的步驟運行他們自己的數據

##### **Evaluating the Explainable AI Method Grad-CAM for Breath Classification on Newborn Time Series Data**
2405.07590v1 by Camelia Oprea, Mike Grüne, Mateusz Buglowski, Lena Olivier, Thorsten Orlikowsky, Stefan Kowalewski, Mark Schoberer, André Stollenwerk

With the digitalization of health care systems, artificial intelligence
becomes more present in medicine. Especially machine learning shows great
potential for complex tasks such as time series classification, usually at the
cost of transparency and comprehensibility. This leads to a lack of trust by
humans and thus hinders its active usage. Explainable artificial intelligence
tries to close this gap by providing insight into the decision-making process,
the actual usefulness of its different methods is however unclear. This paper
proposes a user study based evaluation of the explanation method Grad-CAM with
application to a neural network for the classification of breaths in time
series neonatal ventilation data. We present the perceived usefulness of the
explainability method by different stakeholders, exposing the difficulty to
achieve actual transparency and the wish for more in-depth explanations by many
of the participants.

摘要：隨著醫療保健系統的數位化，人工智慧在醫學領域中變得更加普及。特別是機器學習在時間序列分類等複雜任務中展現出極大的潛力，但通常是以透明度和可理解性為代價。這導致人類缺乏信任，從而阻礙了其積極使用。可解釋的人工智慧試圖通過提供對決策過程的洞察來彌補這一差距，但其不同方法的實際效用尚不清楚。本文提出了一個基於使用者研究的評估，其中包含了 Grad-CAM 解釋方法，並將其應用於神經網路以分類時間序列新生兒呼吸數據中的呼吸。我們展示了不同利益相關者對可解釋性方法的感知效用，揭示了實現實際透明度的難度，以及許多參與者希望獲得更深入的解釋。

##### **XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare**
2405.06270v3 by Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia, Eugenio di Sciascio

The integration of Large Language Models (LLMs) into healthcare diagnostics
offers a promising avenue for clinical decision-making. This study outlines the
development of a novel method for zero-shot/few-shot in-context learning (ICL)
by integrating medical domain knowledge using a multi-layered structured
prompt. We also explore the efficacy of two communication styles between the
user and LLMs: the Numerical Conversational (NC) style, which processes data
incrementally, and the Natural Language Single-Turn (NL-ST) style, which
employs long narrative prompts.
  Our study systematically evaluates the diagnostic accuracy and risk factors,
including gender bias and false negative rates, using a dataset of 920 patient
records in various few-shot scenarios. Results indicate that traditional
clinical machine learning (ML) models generally outperform LLMs in zero-shot
and few-shot settings. However, the performance gap narrows significantly when
employing few-shot examples alongside effective explainable AI (XAI) methods as
sources of domain knowledge. Moreover, with sufficient time and an increased
number of examples, the conversational style (NC) nearly matches the
performance of ML models. Most notably, LLMs demonstrate comparable or superior
cost-sensitive accuracy relative to ML models.
  This research confirms that, with appropriate domain knowledge and tailored
communication strategies, LLMs can significantly enhance diagnostic processes.
The findings highlight the importance of optimizing the number of training
examples and communication styles to improve accuracy and reduce biases in LLM
applications.

摘要：大型語言模型 (LLM) 與醫療診斷整合
為臨床決策提供了一個有前景的途徑。本研究概述了一種新穎方法的開發，用於零次學習/少量學習情境學習 (ICL)，方法是使用多層結構化提示整合醫療領域知識。我們還探討了使用者與 LLM 之間兩種溝通方式的功效：數值對話 (NC) 方式，它會逐步處理資料，以及自然語言單回合 (NL-ST) 方式，它會使用長篇敘事提示。
我們的研究系統性地評估了診斷準確性和風險因子，包括性別偏見和假陰性率，使用了一個包含 920 個患者記錄的資料集，採用各種少量學習情境。結果表明，傳統的臨床機器學習 (ML) 模型通常在零次學習和少量學習設定中表現優於 LLM。然而，當使用少量學習範例以及有效的可解釋 AI (XAI) 方法作為領域知識來源時，效能差距會顯著縮小。此外，隨著時間充足和範例數量增加，對話方式 (NC) 幾乎可以媲美 ML 模型的效能。最值得注意的是，LLM 相對於 ML 模型展現出相當或更佳的成本敏感準確度。
本研究證實，透過適當的領域知識和量身打造的溝通策略，LLM 可以顯著增強診斷程序。這些發現突顯了最佳化訓練範例數量和溝通方式的重要性，以提高準確度並減少 LLM 應用中的偏差。

##### **To Trust or Not to Trust: Towards a novel approach to measure trust for XAI systems**
2405.05766v1 by Miquel Miró-Nicolau, Gabriel Moyà-Alcover, Antoni Jaume-i-Capó, Manuel González-Hidalgo, Maria Gemma Sempere Campello, Juan Antonio Palmer Sancho

The increasing reliance on Deep Learning models, combined with their inherent
lack of transparency, has spurred the development of a novel field of study
known as eXplainable AI (XAI) methods. These methods seek to enhance the trust
of end-users in automated systems by providing insights into the rationale
behind their decisions. This paper presents a novel approach for measuring user
trust in XAI systems, allowing their refinement. Our proposed metric combines
both performance metrics and trust indicators from an objective perspective. To
validate this novel methodology, we conducted a case study in a realistic
medical scenario: the usage of XAI system for the detection of pneumonia from
x-ray images.

摘要：隨著對深度學習模型依賴性的增加，加上其固有的透明度不足，促使一個新的研究領域發展，稱為可解釋 AI (XAI) 方法。這些方法旨在透過深入了解決策背後的原理，來提升最終使用者對自動化系統的信賴。本文提出了一種衡量使用者對 XAI 系統信賴度的新穎方法，允許對其進行改進。我們提出的指標結合了客觀觀點下的效能指標和信賴指標。為了驗證這個新穎的方法，我們在一個真實的醫療場景中進行了一個案例研究：使用 XAI 系統從 X 光影像中偵測肺炎。

##### **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19**
2405.02815v1 by Zhusi Zhong, Jie Li, Zhuoqi Ma, Scott Collins, Harrison Bai, Paul Zhang, Terrance Healey, Xinbo Gao, Michael K. Atalay, Zhicheng Jiao

The COVID-19 pandemic has strained global public health, necessitating
accurate diagnosis and intervention to control disease spread and reduce
mortality rates. This paper introduces an interpretable deep survival
prediction model designed specifically for improved understanding and trust in
COVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale
pretrained image encoder, Risk-specific Grad-CAM, and anatomical region
detection techniques, our approach produces regional interpretable outcomes
that effectively capture essential disease features while focusing on rare but
critical abnormal regions. Our model's predictive results provide enhanced
clarity and transparency through risk area localization, enabling clinicians to
make informed decisions regarding COVID-19 diagnosis with better understanding
of prognostic insights. We evaluate the proposed method on a multi-center
survival dataset and demonstrate its effectiveness via quantitative and
qualitative assessments, achieving superior C-indexes (0.764 and 0.727) and
time-dependent AUCs (0.799 and 0.691). These results suggest that our
explainable deep survival prediction model surpasses traditional survival
analysis methods in risk prediction, improving interpretability for clinical
decision making and enhancing AI system trustworthiness.

摘要：COVID-19 疫情對全球公共衛生造成壓力，必須進行準確的診斷和干預，以控制疾病傳播並降低死亡率。本文介紹了一個可解釋的深度生存預測模型，專門設計用於透過胸部 X 光 (CXR) 影像改善對 COVID-19 預後的理解和信賴。透過整合大規模預訓練影像編碼器、風險特定 Grad-CAM 和解剖區域偵測技術，我們的做法產生區域可解釋的結果，有效捕捉必要的疾病特徵，同時專注於罕見但關鍵的異常區域。我們的模型預測結果透過風險區域定位提供增強的清晰度和透明度，讓臨床醫生能夠在更了解預後見解的情況下，就 COVID-19 診斷做出明智的決策。我們在多中心生存資料集上評估所提出的方法，並透過量化和質化評估證明其有效性，達到優異的 C 指數（0.764 和 0.727）和時間相關 AUC（0.799 和 0.691）。這些結果表明，我們可解釋的深度生存預測模型在風險預測方面超越傳統的生存分析方法，提升臨床決策的解釋性，並增強 AI 系統的信賴度。

##### **Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics**
2405.02334v1 by Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile

In the last years, artificial intelligence (AI) in clinical decision support
systems (CDSS) played a key role in harnessing machine learning and deep
learning architectures. Despite their promising capabilities, the lack of
transparency and explainability of AI models poses significant challenges,
particularly in medical contexts where reliability is a mandatory aspect.
Achieving transparency without compromising predictive accuracy remains a key
challenge. This paper presents a novel method, namely Rad4XCNN, to enhance the
predictive power of CNN-derived features with the interpretability inherent in
radiomic features. Rad4XCNN diverges from conventional methods based on
saliency map, by associating intelligible meaning to CNN-derived features by
means of Radiomics, offering new perspectives on explanation methods beyond
visualization maps. Using a breast cancer classification task as a case study,
we evaluated Rad4XCNN on ultrasound imaging datasets, including an online
dataset and two in-house datasets for internal and external validation. Some
key results are: i) CNN-derived features guarantee more robust accuracy when
compared against ViT-derived and radiomic features; ii) conventional
visualization map methods for explanation present several pitfalls; iii)
Rad4XCNN does not sacrifice model accuracy for their explainability; iv)
Rad4XCNN provides global explanation insights enabling the physician to analyze
the model outputs and findings. In addition, we highlight the importance of
integrating interpretability into AI models for enhanced trust and adoption in
clinical practice, emphasizing how our method can mitigate some concerns
related to explainable AI methods.

摘要：<paragraph>在過去幾年，臨床決策支援系統 (CDSS) 中的人工智慧 (AI) 在利用機器學習和深度學習架構方面發揮了關鍵作用。儘管 AI 模型具有令人滿意的能力，但缺乏透明度和可解釋性，特別是在可靠性為必要考量的醫療背景下，這帶來了重大的挑戰。在不影響預測精準度的情況下實現透明度仍然是一項關鍵挑戰。本文提出了一種新方法，即 Rad4XCNN，以增強 CNN 衍生特徵的預測能力，同時具備放射特徵固有的可解釋性。Rad4XCNN 不同於基於顯著性圖的傳統方法，它通過放射組學將可理解的含義與 CNN 衍生特徵關聯起來，為超越視覺化圖表的解釋方法提供了新的觀點。我們以乳癌分類任務作為案例研究，在超音波影像資料集上評估 Rad4XCNN，包括一個線上資料集和兩個用於內部和外部驗證的內部資料集。一些關鍵結果如下：i) 與 ViT 衍生特徵和放射特徵相比，CNN 衍生特徵保證了更穩健的準確度；ii) 傳統的視覺化圖解釋方法存在一些缺陷；iii) Rad4XCNN 沒有犧牲模型準確度來換取其可解釋性；iv) Rad4XCNN 提供了全局解釋見解，使醫師能夠分析模型輸出和發現。此外，我們強調將可解釋性整合到 AI 模型中對於增強臨床實務中的信任和採用至關重要，並強調了我們的方法如何能緩解與可解釋 AI 方法相關的一些疑慮。</paragraph>

##### **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
2404.16957v1 by Yunfei Ge, Quanyan Zhu

The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.

摘要：隨著人工智慧 (AI) 的普及整合，在涉及 AI 驅動系統的事故中，責任和義務歸屬產生了複雜的挑戰。這些系統的互連性、AI 引發事故的倫理問題，加上 AI 技術的不確定性和缺乏相應法規，使得傳統責任歸屬面臨挑戰。為此，本研究提出了一種計算反思均衡 (CRE) 方法，以建立一個連貫且在倫理上可接受的責任歸屬架構，適用於所有利害關係人。計算方法提供了結構化的分析，克服了概念方法在處理動態且多面向情境時的限制，展示了該架構在責任歸屬過程中具備的可解釋性、連貫性和適應性。我們探討了與均衡計算中索賠相關的初始啟動層級的關鍵作用。我們以 AI 輔助醫療決策支援系統為案例研究，說明不同的初始化如何導致不同的責任分配。該架構提供了對 AI 引發事故中問責制的寶貴見解，透過持續監控、修訂和反思，促進了永續且有韌性的系統發展。

##### **Explainable AI for Fair Sepsis Mortality Predictive Model**
2404.13139v1 by Chia-Hsuan Chang, Xiaoyang Wang, Christopher C. Yang

Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.

摘要：人工智慧透過預測模型協助醫療專業人員，大幅轉變了臨床決策制定。本研究探討了在醫療保健中使用人工智慧應用程式時公平性和可解釋性的關鍵需求，以確保在不同的患者人口統計資料中獲得公平的結果。透過專注於敗血症相關死亡率的預測模型，我們提出了一種方法，該方法會學習一個效能最佳化的預測模型，然後採用轉移學習過程來產生一個具有更好公平性的模型。我們的模型還引入了一種新穎的基於排列的特徵重要性演算法，旨在闡明每個特徵在增強預測公平性方面的貢獻。與現有的可解釋性方法專注於解釋特徵對預測效能的貢獻不同，我們提出的方法獨特地彌補了理解每個特徵如何有助於公平性的差距。這項進展至關重要，因為敗血症的死亡率很高，且在三分之一的醫院死亡中扮演著角色。我們的模型不僅有助於識別和減輕預測模型中的偏差，還能透過提高模型預測的透明度和公平性來培養醫療保健利益相關者之間的信任，進而有助於提供更公平且值得信賴的醫療保健服務。

##### **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
2404.13104v1 by Muhammad Osama Nusrat, Waseem Shahzad, Saad Ahmed Jamal

Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.

摘要：現今，憂鬱症是一個重要的議題。根據世界衛生組織 (WHO) 的資料，在 2023 年，超過 2.8 億人正在與憂鬱症搏鬥。這是一個龐大的數字；如果不認真看待，這些數字將會快速增加。大約有 48.9 億人是社群媒體使用者。人們在 Twitter、Facebook、Reddit、Instagram 等平台上表達自己的感受和情緒。這些平台包含有價值的資訊，可用於研究目的。已經在各種社群媒體平台上進行了大量的研究。然而，這些努力仍存在某些限制。特別是，先前的研究僅專注於偵測推文中的憂鬱症和憂鬱症的強度。此外，資料集標籤中存在不準確的情況。在這項研究工作中，使用基於詞彙標籤的 Twitter 資料庫中的推文預測了五種類型的憂鬱症（雙極型、重度、精神病型、非典型和產後）。可解釋的 AI 用於透過強調代表憂鬱症類型的推文部分來提供推理。從 Transformers（BERT）中提取的雙向編碼器表示用於特徵提取和訓練。機器學習和深度學習方法用於訓練模型。BERT 模型呈現出最有希望的結果，達到 0.96 的整體準確度。

##### **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
2404.12832v2 by Dmytro Shvetsov, Joonas Ariva, Marharyta Domnich, Raul Vicente, Dmytro Fishman

Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.

摘要：深度学习正大幅轉變醫學影像和放射線學領域，能辨識醫學影像中的病理，包括電腦斷層掃描 (CT) 和 X 光掃描。然而，深度學習模型的效能，特別是在分割任務中，常常受到廣泛註解資料集需求的限制。為了應對此挑戰，透過可解釋 AI 和反事實解釋的產生，探索弱監督語意分割的能力。本研究的範圍是開發一種新的反事實內插方法 (COIN)，該方法使用生成模型將預測的分類標籤從異常翻轉為正常。例如，如果分類器將輸入的醫學影像 X 視為異常，表示存在病理，則生成模型旨在內插異常區域，從而逆轉分類器的原始預測標籤。此方法使我們能夠產生病理的精確分割，而無需依賴於預先存在的分割遮罩。至關重要的是，利用影像層級標籤，這比建立詳細的分割遮罩容易取得。該方法的有效性透過分割合成目標和從愛沙尼亞塔爾圖大學醫院取得的 CT 影像中的實際腎臟腫瘤來證明。研究結果表明，COIN 遠遠超過已建立的歸因方法，例如 RISE、ScoreCAM 和 LayerCAM，以及 Singla 等人提出的另一種反事實解釋方法。此證據表明，COIN 是一種很有前途的 CT 影像中腫瘤語意分割方法，並在醫療保健中讓深度學習應用更易於取得和更有效率邁進一步，其中註解資料很稀少。

##### **Hybrid Intelligence for Digital Humanities**
2406.15374v1 by Victor de Boer, Lise Stork

In this paper, we explore the synergies between Digital Humanities (DH) as a
discipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,
the use of digital methods and specifically that of Artificial Intelligence is
subject to a set of requirements and constraints. We argue that these are
well-supported by the capabilities and goals of HI. Our contribution includes
the identification of five such DH requirements: Successful AI systems need to
be able to 1) collaborate with the (human) scholar; 2) support data criticism;
3) support tool criticism; 4) be aware of and cater to various perspectives and
5) support distant and close reading. We take the CARE principles of Hybrid
Intelligence (collaborative, adaptive, responsible and explainable) as
theoretical framework and map these to the DH requirements. In this mapping, we
include example research projects. We finally address how insights from DH can
be applied to HI and discuss open challenges for the combination of the two
disciplines.

摘要：在本文中，我們探討數位人文學科 (DH) 作為一門學科與混合智能 (HI) 作為一個研究典範之間的協同作用。在 DH 研究中，數位方法的使用，特別是人工智慧的使用，受到一系列要求和限制。我們認為這些要求和限制獲得 HI 的能力和目標的充分支持。我們的貢獻包括找出五個這樣的 DH 要求：成功的 AI 系統需要能夠 1) 與（人類）學者合作；2) 支援資料批評；3) 支援工具批評；4) 察覺並迎合各種觀點；5) 支援遠距和近距離閱讀。我們將混合智能的 CARE 原則（協作、適應、負責和可解釋）作為理論架構，並將這些原則對應到 DH 要求。在此對應中，我們納入範例研究專案。最後，我們探討如何將 DH 的見解應用於 HI，並討論結合這兩個學科的開放挑戰。

##### **Ethical Framework for Responsible Foundational Models in Medical Imaging**
2406.11868v1 by Abhijit Das, Debesh Jha, Jasmer Sanjotra, Onkar Susladkar, Suramyaa Sarkar, Ashish Rauniyar, Nikhil Tomar, Vanshali Sharma, Ulas Bagci

Foundational models (FMs) have tremendous potential to revolutionize medical
imaging. However, their deployment in real-world clinical settings demands
extensive ethical considerations. This paper aims to highlight the ethical
concerns related to FMs and propose a framework to guide their responsible
development and implementation within medicine. We meticulously examine ethical
issues such as privacy of patient data, bias mitigation, algorithmic
transparency, explainability and accountability. The proposed framework is
designed to prioritize patient welfare, mitigate potential risks, and foster
trust in AI-assisted healthcare.

摘要：基礎模型 (FM) 具有徹底改變醫學影像的巨大潛力。然而，它們在現實世界臨床環境中的部署需要廣泛的倫理考量。本文旨在強調與 FM 相關的倫理問題，並提出一個框架來指導它們在醫學中的負責任開發和實施。我們仔細審查了倫理問題，例如患者數據隱私、偏差緩解、演算法透明度、可解釋性和問責制。所提出的框架旨在優先考慮患者福利、減輕潛在風險，並培養對 AI 輔助醫療保健的信任。

##### **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
2404.07239v1 by Milad Yousefi, Shadi Farabi Maleki, Ali Jafarizadeh, Mahya Ahmadpour Youshanlui, Aida Jafari, Siamak Pedrammehr, Roohallah Alizadehsani, Ryszard Tadeusiewicz, Pawel Plawiak

Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.

摘要：甲狀腺癌是一種日益嚴重的全球健康問題，需要先進的診斷方法。本篇評論探討了人工智能與放射特徵分析在甲狀腺癌診斷中的應用。在符合 PRISMA 指南的情況下，對多個資料庫進行了回顧，直到 2023 年 10 月。通過結合關鍵字，發現了一篇關於甲狀腺癌和相關主題的英文學術出版物。在移除 109 篇重複文獻後，原始搜尋共回傳 267 篇論文。在根據預先確定的標準，淘汰了 124 篇文章的摘要和標題後，選出了相關研究。在進行全面分析後，額外排除了六項研究。在納入的 28 項研究中，結合超音波 (US) 影像的放射特徵分析，證明了其在診斷甲狀腺癌方面的有效性。研究結果不一，有些研究提出了優於現狀的新策略。文獻強調了人工智能模型面臨的各種挑戰，包括可解釋性問題、資料集限制和操作員依賴性。28 項納入研究的綜合發現提到，需要標準化工作和前瞻性多中心研究來解決這些問題。此外，還確定了克服這些障礙的方法，例如可解釋人工智能技術和個人化醫療技術的進步。本篇評論重點探討了人工智能和放射特徵分析如何轉變甲狀腺癌的診斷和治療。儘管存在挑戰，但未來對多學科合作、臨床適用性驗證和演算法改進的研究，仍有潛力改善甲狀腺癌治療中的患者預後和診斷精準度。

##### **Predictive Modeling for Breast Cancer Classification in the Context of Bangladeshi Patients: A Supervised Machine Learning Approach with Explainable AI**
2404.04686v1 by Taminul Islam, Md. Alif Sheakh, Mst. Sazia Tahosin, Most. Hasna Hena, Shopnil Akash, Yousef A. Bin Jardan, Gezahign Fentahun Wondmie, Hiba-Allah Nafidi, Mohammed Bourhia

Breast cancer has rapidly increased in prevalence in recent years, making it
one of the leading causes of mortality worldwide. Among all cancers, it is by
far the most common. Diagnosing this illness manually requires significant time
and expertise. Since detecting breast cancer is a time-consuming process,
preventing its further spread can be aided by creating machine-based forecasts.
Machine learning and Explainable AI are crucial in classification as they not
only provide accurate predictions but also offer insights into how the model
arrives at its decisions, aiding in the understanding and trustworthiness of
the classification results. In this study, we evaluate and compare the
classification accuracy, precision, recall, and F-1 scores of five different
machine learning methods using a primary dataset (500 patients from Dhaka
Medical College Hospital). Five different supervised machine learning
techniques, including decision tree, random forest, logistic regression, naive
bayes, and XGBoost, have been used to achieve optimal results on our dataset.
Additionally, this study applied SHAP analysis to the XGBoost model to
interpret the model's predictions and understand the impact of each feature on
the model's output. We compared the accuracy with which several algorithms
classified the data, as well as contrasted with other literature in this field.
After final evaluation, this study found that XGBoost achieved the best model
accuracy, which is 97%.

摘要：<paragraph>近年來，乳癌的盛行率迅速增加，使其成為全球主要的死亡原因之一。在所有癌症中，乳癌迄今為止是最常見的。手動診斷此疾病需要大量的時間和專業知識。由於乳癌的檢測過程耗時，因此透過建立機器學習模型來預測，有助於防止其進一步擴散。機器學習和可解釋 AI 在分類中至關重要，因為它們不僅可以提供準確的預測，還可以深入了解模型如何做出決策，有助於理解和信賴分類結果。在此研究中，我們評估並比較了五種不同的機器學習方法的分類準確度、精確度、召回率和 F1 分數，使用了一個主要的資料集（達卡醫學院醫院的 500 名患者）。五種不同的監督式機器學習技術，包括決策樹、隨機森林、邏輯迴歸、朴素貝氏和 XGBoost，已用於在我們的資料集上取得最佳結果。此外，本研究將 SHAP 分析應用於 XGBoost 模型，以解釋模型的預測並了解每個特徵對模型輸出的影響。我們比較了幾種演算法對資料進行分類的準確度，並與該領域的其他文獻進行對比。在最後評估後，本研究發現 XGBoost 達到了最佳的模型準確度，為 97%。</paragraph>

##### **Enhancing Breast Cancer Diagnosis in Mammography: Evaluation and Integration of Convolutional Neural Networks and Explainable AI**
2404.03892v3 by Maryam Ahmed, Tooba Bibi, Rizwan Ahmed Khan, Sidra Nasir

The Deep learning (DL) models for diagnosing breast cancer from mammographic
images often operate as "black boxes", making it difficult for healthcare
professionals to trust and understand their decision-making processes. The
study presents an integrated framework combining Convolutional Neural Networks
(CNNs) and Explainable Artificial Intelligence (XAI) for the enhanced diagnosis
of breast cancer using the CBIS-DDSM dataset. The methodology encompasses an
elaborate data preprocessing pipeline and advanced data augmentation techniques
to counteract dataset limitations and transfer learning using pre-trained
networks such as VGG-16, Inception-V3 and ResNet was employed. A focal point of
our study is the evaluation of XAI's effectiveness in interpreting model
predictions, highlighted by utilizing the Hausdorff measure to assess the
alignment between AI-generated explanations and expert annotations
quantitatively. This approach is critical for XAI in promoting trustworthiness
and ethical fairness in AI-assisted diagnostics. The findings from our research
illustrate the effective collaboration between CNNs and XAI in advancing
diagnostic methods for breast cancer, thereby facilitating a more seamless
integration of advanced AI technologies within clinical settings. By enhancing
the interpretability of AI driven decisions, this work lays the groundwork for
improved collaboration between AI systems and medical practitioners, ultimately
enriching patient care. Furthermore, the implications of our research extended
well beyond the current methodologies. It encourages further research into how
to combine multimodal data and improve AI explanations to meet the needs of
clinical practice.

摘要：深度學習 (DL) 用於從乳房攝影術影像診斷乳癌的模型通常以「黑盒子」方式運作，這使得醫療保健專業人員難以信任和理解其決策過程。本研究提出一個整合架構，結合卷積神經網路 (CNN) 和可解釋人工智慧 (XAI)，以使用 CBIS-DDSM 資料集增強乳癌的診斷。方法包含一個精細的資料前處理管線和進階資料擴充技術，以對抗資料集限制，並採用預先訓練的網路（例如 VGG-16、Inception-V3 和 ResNet）進行遷移學習。我們研究的重點是評估 XAI 在解釋模型預測中的有效性，重點利用豪斯多夫測度量化評估 AI 生成的解釋和專家註解之間的一致性。這種方法對於 XAI 在促進 AI 輔助診斷中的可信度和倫理公平性至關重要。我們研究的發現說明了 CNN 和 XAI 在推進乳癌診斷方法中的有效協作，從而促進了先進 AI 技術在臨床環境中的更順暢整合。透過增強 AI 驅動決策的可解釋性，這項工作為 AI 系統和醫療從業人員之間的改善協作奠定了基礎，最終豐富了患者照護。此外，我們研究的影響遠遠超出了目前的技術。它鼓勵進一步研究如何結合多模式資料並改善 AI 解釋，以滿足臨床實務的需求。

##### **Advancing Multimodal Data Fusion in Pain Recognition: A Strategy Leveraging Statistical Correlation and Human-Centered Perspectives**
2404.00320v2 by Xingrui Gu, Zhixuan Wang, Irisa Jin, Zekun Wu

This research presents a novel multimodal data fusion methodology for pain
behavior recognition, integrating statistical correlation analysis with
human-centered insights. Our approach introduces two key innovations: 1)
integrating data-driven statistical relevance weights into the fusion strategy
to effectively utilize complementary information from heterogeneous modalities,
and 2) incorporating human-centric movement characteristics into multimodal
representation learning for detailed modeling of pain behaviors. Validated
across various deep learning architectures, our method demonstrates superior
performance and broad applicability. We propose a customizable framework that
aligns each modality with a suitable classifier based on statistical
significance, advancing personalized and effective multimodal fusion.
Furthermore, our methodology provides explainable analysis of multimodal data,
contributing to interpretable and explainable AI in healthcare. By highlighting
the importance of data diversity and modality-specific representations, we
enhance traditional fusion techniques and set new standards for recognizing
complex pain behaviors. Our findings have significant implications for
promoting patient-centered healthcare interventions and supporting explainable
clinical decision-making.

摘要：本研究提出了一種創新的多模態數據融合方法，用於疼痛行為識別，將統計相關分析與以人為中心的見解相結合。我們的做法引入了兩項關鍵創新：1) 將數據驅動的統計相關權重整合到融合策略中，以有效利用來自異質模態的補充信息，以及 2) 將以人為中心的運動特徵納入多模態表示學習中，以詳細建模疼痛行為。我們的模型在各種深度學習架構中得到驗證，展示了卓越的性能和廣泛的適用性。我們提出了一個可自定義的框架，根據統計顯著性將每個模態與合適的分類器對齊，推進個性化和有效的多模態融合。此外，我們的模型提供對多模態數據的可解釋分析，有助於醫療保健中的可解釋和可解釋 AI。通過強調數據多樣性和模態特定表示的重要性，我們增強了傳統的融合技術，並為識別複雜的疼痛行為設定了新的標準。我們的發現對促進以患者為中心的醫療保健干預和支持可解釋的臨床決策制定具有重要意義。

##### **Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach**
2403.17873v1 by Andrea Ferrario, Alberto Termine, Alessandro Facchini

Human-centered explainable AI (HCXAI) advocates for the integration of social
aspects into AI explanations. Central to the HCXAI discourse is the Social
Transparency (ST) framework, which aims to make the socio-organizational
context of AI systems accessible to their users. In this work, we suggest
extending the ST framework to address the risks of social misattributions in
Large Language Models (LLMs), particularly in sensitive areas like mental
health. In fact LLMs, which are remarkably capable of simulating roles and
personas, may lead to mismatches between designers' intentions and users'
perceptions of social attributes, risking to promote emotional manipulation and
dangerous behaviors, cases of epistemic injustice, and unwarranted trust. To
address these issues, we propose enhancing the ST framework with a fifth
'W-question' to clarify the specific social attributions assigned to LLMs by
its designers and users. This addition aims to bridge the gap between LLM
capabilities and user perceptions, promoting the ethically responsible
development and use of LLM-based technology.

摘要：以人为本的可解释 AI (HCXAI) 倡导将社会层面整合到 AI 解释中。HCXAI 话语的核心是社会透明度 (ST) 框架，其目标是让 AI 系统的社会组织背景对用户来说是可理解的。在这项工作中，我们建议扩展 ST 框架以解决大型语言模型 (LLM) 中社会错误归因的风险，尤其是在心理健康等敏感领域。事实上，LLM 能够出色地模拟角色和人格，这可能导致设计者的意图和用户对社会属性的认知之间出现错配，从而有风险促进情绪操纵和危险行为、认知不公正和不合理的信任。为了解决这些问题，我们建议用第五个“W 问题”来增强 ST 框架，以明确设计者和用户赋予 LLM 的具体社会属性。此补充旨在弥合 LLM 能力和用户认知之间的差距，促进基于 LLM 的技术在道德上负责任地开发和使用。

##### **Clinical Domain Knowledge-Derived Template Improves Post Hoc AI Explanations in Pneumothorax Classification**
2403.18871v1 by Han Yuan, Chuan Hong, Pengtao Jiang, Gangming Zhao, Nguyen Tuan Anh Tran, Xinxing Xu, Yet Yen Yan, Nan Liu

Background: Pneumothorax is an acute thoracic disease caused by abnormal air
collection between the lungs and chest wall. To address the opaqueness often
associated with deep learning (DL) models, explainable artificial intelligence
(XAI) methods have been introduced to outline regions related to pneumothorax
diagnoses made by DL models. However, these explanations sometimes diverge from
actual lesion areas, highlighting the need for further improvement. Method: We
propose a template-guided approach to incorporate the clinical knowledge of
pneumothorax into model explanations generated by XAI methods, thereby
enhancing the quality of these explanations. Utilizing one lesion delineation
created by radiologists, our approach first generates a template that
represents potential areas of pneumothorax occurrence. This template is then
superimposed on model explanations to filter out extraneous explanations that
fall outside the template's boundaries. To validate its efficacy, we carried
out a comparative analysis of three XAI methods with and without our template
guidance when explaining two DL models in two real-world datasets. Results: The
proposed approach consistently improved baseline XAI methods across twelve
benchmark scenarios built on three XAI methods, two DL models, and two
datasets. The average incremental percentages, calculated by the performance
improvements over the baseline performance, were 97.8% in Intersection over
Union (IoU) and 94.1% in Dice Similarity Coefficient (DSC) when comparing model
explanations and ground-truth lesion areas. Conclusions: In the context of
pneumothorax diagnoses, we proposed a template-guided approach for improving AI
explanations. We anticipate that our template guidance will forge a fresh
approach to elucidating AI models by integrating clinical domain expertise.

摘要：<paragraph>背景：氣胸是一種因肺部與胸壁之間異常集氣所引起的急性胸腔疾病。為了解決深度學習（DL）模型經常伴隨的不透明性，可解釋人工智慧（XAI）方法已被引入，用於概述與 DL 模型做出的氣胸診斷相關的區域。然而，這些解釋有時會與實際病灶區域有所出入，突顯出進一步改進的必要性。方法：我們提出了一種模板引導式方法，將氣胸的臨床知識納入 XAI 方法產生的模型解釋中，從而提升這些解釋的品質。利用放射科醫師建立的病灶描繪，我們的做法首先產生一個模板，用於表示氣胸可能發生的區域。然後將此模板疊加在模型解釋上，以篩選出超出模板邊界的無關解釋。為了驗證其效力，我們對三種 XAI 方法進行了比較分析，在兩個真實世界資料集中解釋兩個 DL 模型時，分別採用和不採用我們的模板引導。結果：所提出的方法在建立於三種 XAI 方法、兩個 DL 模型和兩個資料集的十二種基準情境中，始終改善了基準 XAI 方法。在比較模型解釋和真實病灶區域時，透過基準效能的效能改進計算出的平均增量百分比為交集比（IoU）的 97.8% 和骰子相似性係數（DSC）的 94.1%。結論：在氣胸診斷的背景下，我們提出了一種模板引導式方法，用於改善 AI 解釋。我們預期我們的模板引導將透過整合臨床領域專業知識，為闡明 AI 模型建立一種新方法。</paragraph>

##### **Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures**
2403.01580v1 by Séamus Lankford

In the current machine translation (MT) landscape, the Transformer
architecture stands out as the gold standard, especially for high-resource
language pairs. This research delves into its efficacy for low-resource
language pairs including both the English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi language pairs. Notably, the study identifies
the optimal hyperparameters and subword model type to significantly improve the
translation quality of Transformer models for low-resource language pairs.
  The scarcity of parallel datasets for low-resource languages can hinder MT
development. To address this, gaHealth was developed, the first bilingual
corpus of health data for the Irish language. Focusing on the health domain,
models developed using this in-domain dataset exhibited very significant
improvements in BLEU score when compared with models from the LoResMT2021
Shared Task. A subsequent human evaluation using the multidimensional quality
metrics error taxonomy showcased the superior performance of the Transformer
system in reducing both accuracy and fluency errors compared to an RNN-based
counterpart.
  Furthermore, this thesis introduces adaptNMT and adaptMLLM, two open-source
applications streamlined for the development, fine-tuning, and deployment of
neural machine translation models. These tools considerably simplify the setup
and evaluation process, making MT more accessible to both developers and
translators. Notably, adaptNMT, grounded in the OpenNMT ecosystem, promotes
eco-friendly natural language processing research by highlighting the
environmental footprint of model development. Fine-tuning of MLLMs by adaptMLLM
demonstrated advancements in translation performance for two low-resource
language pairs: English$\leftrightarrow$Irish and
English$\leftrightarrow$Marathi, compared to baselines from the LoResMT2021
Shared Task.

摘要：<paragraph>在當前機器翻譯 (MT) 領域中，Transformer 架構脫穎而出，成為黃金標準，特別是對於高資源語言對。本研究探討其對低資源語言對的效能，包括英語↔愛爾蘭語和英語↔馬拉地語語言對。值得注意的是，本研究識別出最佳超參數和子詞模型類型，以顯著提高 Transformer 模型對低資源語言對的翻譯品質。
低資源語言的平行資料集的稀缺會阻礙 MT 的發展。為了解決這個問題，開發了 gaHealth，這是愛爾蘭語的第一個雙語健康資料語料庫。專注於健康領域，使用此域內資料集開發的模型在 BLEU 得分方面表現出非常顯著的進步，與 LoResMT2021 共享任務中的模型相比。隨後使用多維品質指標錯誤分類法進行的人工評估顯示，與基於 RNN 的對應模型相比，Transformer 系統在減少準確性和流暢性錯誤方面表現出優異的性能。
此外，本論文介紹了 adaptNMT 和 adaptMLLM，這兩個開源應用程式簡化了神經機器翻譯模型的開發、微調和部署。這些工具大幅簡化了設定和評估流程，讓 MT 更容易讓開發人員和翻譯人員使用。值得注意的是，adaptNMT 以 OpenNMT 生態系統為基礎，通過強調模型開發的環境足跡來促進生態友好的自然語言處理研究。與 LoResMT2021 共享任務中的基準相比，adaptMLLM 對 MLLM 的微調證明了英語↔愛爾蘭語和英語↔馬拉地語這兩個低資源語言對的翻譯性能進步。</paragraph>

##### **Cause and Effect: Can Large Language Models Truly Understand Causality?**
2402.18139v3 by Swagata Ashwani, Kshiteesh Hegde, Nishith Reddy Mannuru, Mayank Jindal, Dushyant Singh Sengar, Krishna Chaitanya Rao Kathala, Dishant Banga, Vinija Jain, Aman Chadha

With the rise of Large Language Models(LLMs), it has become crucial to
understand their capabilities and limitations in deciphering and explaining the
complex web of causal relationships that language entails. Current methods use
either explicit or implicit causal reasoning, yet there is a strong need for a
unified approach combining both to tackle a wide array of causal relationships
more effectively. This research proposes a novel architecture called Context
Aware Reasoning Enhancement with Counterfactual Analysis(CARE CA) framework to
enhance causal reasoning and explainability. The proposed framework
incorporates an explicit causal detection module with ConceptNet and
counterfactual statements, as well as implicit causal detection through LLMs.
Our framework goes one step further with a layer of counterfactual explanations
to accentuate LLMs understanding of causality. The knowledge from ConceptNet
enhances the performance of multiple causal reasoning tasks such as causal
discovery, causal identification and counterfactual reasoning. The
counterfactual sentences add explicit knowledge of the not caused by scenarios.
By combining these powerful modules, our model aims to provide a deeper
understanding of causal relationships, enabling enhanced interpretability.
Evaluation of benchmark datasets shows improved performance across all metrics,
such as accuracy, precision, recall, and F1 scores. We also introduce
CausalNet, a new dataset accompanied by our code, to facilitate further
research in this domain.

摘要：隨著大型語言模型 (LLM) 的興起，了解它們在解碼和解釋語言所蘊含的複雜因果關係網路中的能力和限制變得至關重要。目前的技術使用明確或隱含的因果推理，但強烈需要一種統一的方法，結合兩者以更有效地處理廣泛的因果關係。本研究提出了一種稱為情境感知推理增強與反事實分析 (CARE CA) 框架的新架構，以增強因果推理和可解釋性。提出的框架結合了使用 ConceptNet 和反事實陳述的明確因果檢測模組，以及透過 LLM 進行的隱含因果檢測。我們的框架更進一步，加入一層反事實解釋，以強調 LLM 對因果關係的理解。來自 ConceptNet 的知識增強了多項因果推理任務的執行，例如因果發現、因果識別和反事實推理。反事實句加入了未由情境造成的明確知識。透過結合這些強大的模組，我們的模型旨在提供對因果關係更深入的理解，實現增強的可解釋性。基準資料集的評估顯示在所有指標（例如準確度、精確度、召回率和 F1 分數）上都有所提升。我們還引入了 CausalNet，一個新的資料集，並附上了我們的程式碼，以促進在這個領域的進一步研究。

##### **Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina**
2402.18600v1 by Yasin Sadeghi Bazargani, Majid Mirzaei, Navid Sobhi, Mirsaeed Abdollahi, Ali Jafarizadeh, Siamak Pedrammehr, Roohallah Alizadehsani, Ru San Tan, Sheikh Mohammed Shariful Islam, U. Rajendra Acharya

Diabetes mellitus (DM) predisposes patients to vascular complications.
Retinal images and vasculature reflect the body's micro- and macrovascular
health. They can be used to diagnose DM complications, including diabetic
retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular
disease, as well as forecast the risk of cardiovascular events. Artificial
intelligence (AI)-enabled systems developed for high-throughput detection of DR
using digitized retinal images have become clinically adopted. Beyond DR
screening, AI integration also holds immense potential to address challenges
associated with the holistic care of the patient with DM. In this work, we aim
to comprehensively review the literature for studies on AI applications based
on retinal images related to DM diagnosis, prognostication, and management. We
will describe the findings of holistic AI-assisted diabetes care, including but
not limited to DR screening, and discuss barriers to implementing such systems,
including issues concerning ethics, data privacy, equitable access, and
explainability. With the ability to evaluate the patient's health status vis a
vis DM complication as well as risk prognostication of future cardiovascular
complications, AI-assisted retinal image analysis has the potential to become a
central tool for modern personalized medicine in patients with DM.

摘要：糖尿病（DM）使患者容易出現血管併發症。
視網膜影像和血管反映身體的微血管和巨血管健康狀況。它們可用於診斷糖尿病併發症，包括糖尿病視網膜病變（DR）、神經病變、腎病和動脈粥樣硬化性心血管疾病，以及預測心血管事件的風險。為使用數位化視網膜影像進行高通量 DR 檢測而開發的人工智慧（AI）啟用系統已在臨床採用。除了 DR 篩檢外，AI 整合也具有巨大的潛力來應對與糖尿病患者整體照護相關的挑戰。在這項工作中，我們旨在全面回顧基於視網膜影像的 AI 應用相關研究的文獻，這些研究與糖尿病的診斷、預後和管理有關。我們將描述整體 AI 輔助糖尿病照護的發現，包括但不限於 DR 篩檢，並討論實施此類系統的障礙，包括與倫理、資料隱私、公平存取和可解釋性有關的問題。透過評估患者的健康狀況，同時考量糖尿病併發症以及未來心血管併發症的風險預後，AI 輔助視網膜影像分析有潛力成為糖尿病患者現代化個人化醫療的中心工具。

##### **Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education**
2402.15027v2 by A. J. Karran, P. Charland, J-T. Martineau, A. Ortiz de Guinea Lopez de Arana, AM. Lesage, S. Senecal, P-M. Leger

This study investigates the acceptability of different artificial
intelligence (AI) applications in education from a multi-stakeholder
perspective, including students, teachers, and parents. Acknowledging the
transformative potential of AI in education, it addresses concerns related to
data privacy, AI agency, transparency, explainability and the ethical
deployment of AI. Through a vignette methodology, participants were presented
with four scenarios where AI's agency, transparency, explainability, and
privacy were manipulated. After each scenario, participants completed a survey
that captured their perceptions of AI's global utility, individual usefulness,
justice, confidence, risk, and intention to use each scenario's AI if
available. The data collection comprising a final sample of 1198
multi-stakeholder participants was distributed through a partner institution
and social media campaigns and focused on individual responses to four AI use
cases. A mediation analysis of the data indicated that acceptance and trust in
AI varies significantly across stakeholder groups. We found that the key
mediators between high and low levels of AI's agency, transparency, and
explainability, as well as the intention to use the different educational AI,
included perceived global utility, justice, and confidence. The study
highlights that the acceptance of AI in education is a nuanced and multifaceted
issue that requires careful consideration of specific AI applications and their
characteristics, in addition to the diverse stakeholders' perceptions.

摘要：這項研究從多個利害關係人的角度探討不同的人工智慧 (AI) 應用在教育上的可接受性，包括學生、老師和家長。承認 AI 在教育上的轉型潛力，它解決了與資料隱私、AI 代理、透明度、可解釋性和 AI 的道德部署相關的疑慮。透過小插曲方法，參與者被呈現了四種情境，其中 AI 的代理、透明度、可解釋性和隱私受到操縱。在每個情境後，參與者完成了一項調查，該調查捕捉了他們對 AI 的整體效用、個人效用、正義、信心、風險和如果可用，使用每個情境的 AI 的意圖的看法。資料蒐集包含來自合作機構和社群媒體活動的 1198 位多利害關係人參與者的最終樣本，並專注於對四個 AI 使用案例的個別回應。對資料的調解分析表明，對 AI 的接受度和信任在利害關係人團體之間有顯著差異。我們發現，AI 的代理、透明度和可解釋性高低程度之間的關鍵調解者，以及使用不同教育 AI 的意圖，包括感知到的整體效用、正義和信心。這項研究強調，接受 AI 在教育上的應用是一個微妙且多面向的問題，除了不同的利害關係人的看法外，還需要仔細考慮具體的 AI 應用及其特徵。

##### **Deciphering Heartbeat Signatures: A Vision Transformer Approach to Explainable Atrial Fibrillation Detection from ECG Signals**
2402.09474v2 by Aruna Mohan, Danne Elbers, Or Zilbershot, Fatemeh Afghah, David Vorchheimer

Remote patient monitoring based on wearable single-lead electrocardiogram
(ECG) devices has significant potential for enabling the early detection of
heart disease, especially in combination with artificial intelligence (AI)
approaches for automated heart disease detection. There have been prior studies
applying AI approaches based on deep learning for heart disease detection.
However, these models are yet to be widely accepted as a reliable aid for
clinical diagnostics, in part due to the current black-box perception
surrounding many AI algorithms. In particular, there is a need to identify the
key features of the ECG signal that contribute toward making an accurate
diagnosis, thereby enhancing the interpretability of the model. In the present
study, we develop a vision transformer approach to identify atrial fibrillation
based on single-lead ECG data. A residual network (ResNet) approach is also
developed for comparison with the vision transformer approach. These models are
applied to the Chapman-Shaoxing dataset to classify atrial fibrillation, as
well as another common arrhythmia, sinus bradycardia, and normal sinus rhythm
heartbeats. The models enable the identification of the key regions of the
heartbeat that determine the resulting classification, and highlight the
importance of P-waves and T-waves, as well as heartbeat duration and signal
amplitude, in distinguishing normal sinus rhythm from atrial fibrillation and
sinus bradycardia.

摘要：<paragraph>基於可穿戴式單導程心電圖 (ECG) 裝置的遠端病患監測在早期偵測心臟疾病方面具有顯著的潛力，特別是與用於自動化心臟疾病偵測的人工智慧 (AI) 方法結合使用時。先前已有研究應用基於深度學習的 AI 方法進行心臟疾病偵測。然而，這些模型尚未被廣泛接受為臨床診斷的可靠輔助工具，部分原因在於圍繞許多 AI 演算法的當前黑箱感知。特別是，有必要找出有助於做出準確診斷的 ECG 訊號關鍵特徵，從而增強模型的可解釋性。在本研究中，我們開發了一種視覺轉換器方法，以根據單導程 ECG 資料找出心房顫動。殘差網路 (ResNet) 方法也已開發出來，以便與視覺轉換器方法進行比較。這些模型應用於 Chapman-Shaoxing 資料集，以分類心房顫動，以及另一種常見的心律不整，竇性心動過緩，和正常竇性心律的心跳。這些模型能夠找出決定最終分類的心跳關鍵區域，並強調 P 波和 T 波，以及心跳持續時間和訊號振幅在區分正常竇性心律與心房顫動和竇性心動過緩方面的重要性。</paragraph>

##### **Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering**
2402.05127v1 by Aryan Agrawal

This paper introduces a novel paradigm for depression detection and treatment
using advanced Large Language Models (LLMs): Generative Pre-trained Transformer
4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized
prompts to diagnose, explain, and suggest therapeutic interventions for
depression. A unique few-shot prompting method enhances the models' ability to
analyze and explain depressive symptoms based on the DSM-5 criteria. In the
interaction phase, the models engage in empathetic dialogue management, drawing
from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,
fostering supportive interactions with individuals experiencing major
depressive disorders. Additionally, the research introduces the Illuminate
Database, enriched with various CBT modules, aiding in personalized therapy
recommendations. The study evaluates LLM performance using metrics such as F1
scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy
for Gisting Evaluation (ROUGE) across different test sets, demonstrating their
effectiveness. This comprehensive approach blends cutting-edge AI with
established psychological methods, offering new possibilities in mental health
care and showcasing the potential of LLMs in revolutionizing depression
diagnosis and treatment strategies.

摘要：本文介紹了一種使用先進大型語言模型 (LLM) 進行憂鬱症偵測和治療的新模式：生成式預訓練Transformer 4 (GPT-4)、Llama 2 聊天機器人和 Gemini。這些 LLM 經過微調，具備專業提示，可診斷、解釋並建議憂鬱症的治療介入方法。一種獨特的少次提示方法增強了模型根據 DSM-5 標準分析和解釋憂鬱症狀的能力。在互動階段，這些模型會參與同理心對話管理，從 PsychDB 和認知行為療法 (CBT) 指南等資源中汲取，促進與經歷重度憂鬱症的人們的支持性互動。此外，這項研究還介紹了 Illuminate 資料庫，其中包含各種 CBT 模組，有助於個性化治療建議。這項研究使用 F1 分數、準確率、召回率、餘弦相似度和面向召回率的 Gisting 評估替身 (ROUGE) 等指標，在不同的測試集中評估 LLM 的表現，證明了它們的有效性。這種綜合方法結合了尖端的 AI 與既定的心理方法，為心理保健提供了新的可能性，並展示了 LLM 在革新憂鬱症診斷和治療策略方面的潛力。

##### **Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions**
2401.13324v6 by Timothée Schmude, Laura Koesten, Torsten Möller, Sebastian Tschiatschek

Every AI system that makes decisions about people has a group of stakeholders
that are personally affected by these decisions. However, explanations of AI
systems rarely address the information needs of this stakeholder group, who
often are AI novices. This creates a gap between conveyed information and
information that matters to those who are impacted by the system's decisions,
such as domain experts and decision subjects. To address this, we present the
"XAI Novice Question Bank," an extension of the XAI Question Bank containing a
catalog of information needs from AI novices in two use cases: employment
prediction and health monitoring. The catalog covers the categories of data,
system context, system usage, and system specifications. We gathered
information needs through task-based interviews where participants asked
questions about two AI systems to decide on their adoption and received verbal
explanations in response. Our analysis showed that participants' confidence
increased after receiving explanations but that their understanding faced
challenges. These included difficulties in locating information and in
assessing their own understanding, as well as attempts to outsource
understanding. Additionally, participants' prior perceptions of the systems'
risks and benefits influenced their information needs. Participants who
perceived high risks sought explanations about the intentions behind a system's
deployment, while those who perceived low risks rather asked about the system's
operation. Our work aims to support the inclusion of AI novices in
explainability efforts by highlighting their information needs, aims, and
challenges. We summarize our findings as five key implications that can inform
the design of future explanations for lay stakeholder audiences.

摘要：<paragraph>每個對人做出決定的 AI 系統都有一群利害關係人
受到這些決定的親身影響。然而，AI
系統的解釋很少能滿足這群利害關係人的資訊需求，而他們
通常都是 AI 新手。這造成了傳達資訊與
受到系統決策影響的人士（例如領域專家和決策主體）重視的資訊之間的落差。為了解決這個問題，我們提出了
「XAI 新手問題庫」，它是 XAI 問題庫的延伸，包含來自 AI 新手在兩個使用案例中的資訊需求目錄：就業
預測和健康監測。目錄涵蓋了資料、
系統背景、系統使用和系統規格等類別。我們透過任務型訪談收集資訊需求，參與者在訪談中詢問了兩個 AI 系統的問題，以決定是否採用它們，並收到口頭
解釋作為回應。我們的分析顯示，參與者在收到解釋後信心有所提升，但他們的理解卻面臨挑戰。這些挑戰包括難以找到資訊和評估自己的理解，以及試圖外包
理解。此外，參與者對系統風險和好處的先前回饋影響了他們的資訊需求。認為風險高的參與者尋求解釋系統部署背後的意圖，而認為風險低的人則詢問系統的
操作。我們的研究旨在透過強調 AI 新手的資訊需求、目標和
挑戰，來支持將 AI 新手納入可解釋性工作中。我們將我們的研究結果總結為五個關鍵啟示，這些啟示可以為未來針對非專業利害關係人受眾的解釋設計提供參考。</paragraph>

##### **Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education**
2401.02985v1 by Vahid Ashrafimoghari, Necdet Gürkan, Jordan W. Suchow

The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.

摘要：人工智慧 (AI) 的快速演進，尤其是在大型語言模型 (LLM) 和生成式 AI 的領域，為各個領域的應用開啟了新途徑，但其在商業教育中的角色仍未被充分探討。本研究首次引入了基準，用以評估七個主要 LLM 的效能，包括 OpenAI 的模型 (GPT-3.5 Turbo、GPT-4 和 GPT-4 Turbo)、Google 的模型 (PaLM 2、Gemini 1.0 Pro) 和 Anthropic 的模型 (Claude 2 和 Claude 2.1)，這些模型將用於研究生商業課程入學程序中的關鍵考試 GMAT。我們的分析顯示，大多數 LLM 的表現都優於人類考生，其中 GPT-4 Turbo 不僅優於其他模型，更超越了頂尖商學院的研究生平均分數。透過案例研究，本研究探討了 GPT-4 Turbo 在解釋答案、評估回應、辨識錯誤、調整說明和產生替代情境方面的能力。與前一代版本相比，最新的 LLM 版本 GPT-4 Turbo、Claude 2.1 和 Gemini 1.0 Pro 在推理任務方面有顯著的進步，凸顯了其在解決複雜問題方面的潛力。儘管 AI 在教育、評量和輔導方面的承諾很明確，但仍有挑戰存在。我們的研究不僅闡明了 LLM 的學術潛力，也強調了在教育中審慎開發和應用 AI 的必要性。隨著 AI 技術的進步，建立 AI 互動的架構和協定、驗證 AI 生成的內容的準確性、確保全球各地多元學習者的存取權，以及創造一個 AI 支持人類專業知識的教育環境至關重要。本研究為進一步探索負責任地使用 AI 來豐富教育體驗並改善考試準備和評量方法奠定了基礎。

##### **XAI for In-hospital Mortality Prediction via Multimodal ICU Data**
2312.17624v1 by Xingqiao Li, Jindong Gu, Zhiyong Wang, Yancheng Yuan, Bo Du, Fengxiang He

Predicting in-hospital mortality for intensive care unit (ICU) patients is
key to final clinical outcomes. AI has shown advantaged accuracy but suffers
from the lack of explainability. To address this issue, this paper proposes an
eXplainable Multimodal Mortality Predictor (X-MMP) approaching an efficient,
explainable AI solution for predicting in-hospital mortality via multimodal ICU
data. We employ multimodal learning in our framework, which can receive
heterogeneous inputs from clinical data and make decisions. Furthermore, we
introduce an explainable method, namely Layer-Wise Propagation to Transformer,
as a proper extension of the LRP method to Transformers, producing explanations
over multimodal inputs and revealing the salient features attributed to
prediction. Moreover, the contribution of each modality to clinical outcomes
can be visualized, assisting clinicians in understanding the reasoning behind
decision-making. We construct a multimodal dataset based on MIMIC-III and
MIMIC-III Waveform Database Matched Subset. Comprehensive experiments on
benchmark datasets demonstrate that our proposed framework can achieve
reasonable interpretation with competitive prediction accuracy. In particular,
our framework can be easily transferred to other clinical tasks, which
facilitates the discovery of crucial factors in healthcare research.

摘要：預測加護病房 (ICU) 病患的院內死亡率是最終臨床結果的關鍵。AI 已展現出優異的準確度，但卻缺乏可解釋性。為了解決這個問題，本文提出了一個可解釋的多模式死亡率預測器 (X-MMP)，採用有效且可解釋的 AI 方式，藉由多模式 ICU 資料來預測院內死亡率。我們在架構中採用多模式學習，可以接收來自臨床資料的異質輸入並做出決策。此外，我們引入了一個可解釋的方法，也就是分層傳播至 Transformer，作為 LRP 方法適當地延伸至 Transformer，對多模式輸入產生解釋，並揭露歸因於預測的顯著特徵。此外，每個模式對臨床結果的貢獻可以視覺化，協助臨床醫師了解決策背後的理由。我們根據 MIMIC-III 和 MIMIC-III 波形資料庫比對子集建構了一個多模式資料集。在基準資料集上的全面實驗證明，我們提出的架構可以達成合理的詮釋，並具備競爭力的預測準確度。特別是，我們的架構可以輕鬆地轉移到其他臨床任務，這有助於在醫療保健研究中發現關鍵因素。

##### **Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA Initiative**
2401.09450v2 by Norman Zerbe, Lars Ole Schwen, Christian Geißler, Katja Wiesemann, Tom Bisson, Peter Boor, Rita Carvalho, Michael Franz, Christoph Jansen, Tim-Rasmus Kiehl, Björn Lindequist, Nora Charlotte Pohlan, Sarah Schmell, Klaus Strohmenger, Falk Zakrzewski, Markus Plass, Michael Takla, Tobias Küster, André Homeyer, Peter Hufnagl

Over the past decade, artificial intelligence (AI) methods in pathology have
advanced substantially. However, integration into routine clinical practice has
been slow due to numerous challenges, including technical and regulatory
hurdles in translating research results into clinical diagnostic products and
the lack of standardized interfaces. The open and vendor-neutral EMPAIA
initiative addresses these challenges. Here, we provide an overview of EMPAIA's
achievements and lessons learned. EMPAIA integrates various stakeholders of the
pathology AI ecosystem, i.e., pathologists, computer scientists, and industry.
In close collaboration, we developed technical interoperability standards,
recommendations for AI testing and product development, and explainability
methods. We implemented the modular and open-source EMPAIA platform and
successfully integrated 14 AI-based image analysis apps from 8 different
vendors, demonstrating how different apps can use a single standardized
interface. We prioritized requirements and evaluated the use of AI in real
clinical settings with 14 different pathology laboratories in Europe and Asia.
In addition to technical developments, we created a forum for all stakeholders
to share information and experiences on digital pathology and AI. Commercial,
clinical, and academic stakeholders can now adopt EMPAIA's common open-source
interfaces, providing a unique opportunity for large-scale standardization and
streamlining of processes. Further efforts are needed to effectively and
broadly establish AI assistance in routine laboratory use. To this end, a
sustainable infrastructure, the non-profit association EMPAIA International,
has been established to continue standardization and support broad
implementation and advocacy for an AI-assisted digital pathology future.

摘要：在過去的十年中，病理學中的人工智慧 (AI) 方法已大幅進步。然而，由於許多挑戰，包括將研究結果轉化為臨床診斷產品在技術和法規方面的障礙，以及缺乏標準化介面，導致整合到常規臨床實務中進展緩慢。開放且與供應商無關的 EMPAIA 計畫應對了這些挑戰。在此，我們提供 EMPAIA 的成就和經驗教訓的概述。EMPAIA 整合了病理學 AI 生態系統的各個利害關係人，即病理學家、電腦科學家和產業。在密切合作下，我們制定了技術互通性標準、AI 測試和產品開發建議，以及可解釋性方法。我們實作了模組化且開放原始碼的 EMPAIA 平臺，並成功整合了來自 8 個不同供應商的 14 個基於 AI 的影像分析應用程式，展示了不同的應用程式如何使用單一的標準化介面。我們優先考慮需求，並評估了 AI 在歐洲和亞洲的 14 個不同病理實驗室中的實際臨床應用。除了技術開發外，我們還為所有利害關係人建立了一個論壇，以分享數位病理學和 AI 的資訊和經驗。商業、臨床和學術利害關係人現在可以採用 EMPAIA 的常見開放原始碼介面，這為大規模標準化和簡化流程提供了獨特的機會。需要進一步的努力才能有效且廣泛地建立例行實驗室使用中的 AI 輔助。為此，已成立非營利協會 EMPAIA International，以作為永續基礎架構，繼續進行標準化，並支援廣泛實作和倡導 AI 輔助數位病理學的未來。

##### **Robust Stochastic Graph Generator for Counterfactual Explanations**
2312.11747v2 by Mario Alfonso Prado-Romero, Bardh Prenkaj, Giovanni Stilo

Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.

摘要：反事實解釋 (CE) 技術已引起關注，作為一種為與 AI 系統互動的使用者提供見解的方法。雖然在醫學影像和自動駕駛汽車等領域廣泛研究，圖形反事實解釋 (GCE) 方法相對較少被探索。GCE 會產生一個類似於原始圖形的新圖形，並根據基礎預測模型產生不同的結果。在這些 GCE 技術中，儘管在其他領域（例如藝術風格和自然語言建模）中展現出令人印象深刻的成就，但植基於生成機制的技術獲得的關注相對有限。對生成式解釋器的偏好源於它們在推理期間產生反事實實例的能力，利用輸入圖形的自主獲取擾動。基於上述理由，我們的研究引入了 RSGG-CE，一種用於反事實解釋的新型穩健隨機圖形生成器，能夠從學習到的潛在空間中產生反事實範例，考慮部分有序的生成序列。此外，我們進行定量和定性分析，以比較 RSGG-CE 的效能與 SoA 生成式解釋器，強調其增強了產生合理解釋候選的能力。

##### **Evaluating the Utility of Model Explanations for Model Development**
2312.06032v1 by Shawn Im, Jacob Andreas, Yilun Zhou

One of the motivations for explainable AI is to allow humans to make better
and more informed decisions regarding the use and deployment of AI models. But
careful evaluations are needed to assess whether this expectation has been
fulfilled. Current evaluations mainly focus on algorithmic properties of
explanations, and those that involve human subjects often employ subjective
questions to test human's perception of explanation usefulness, without being
grounded in objective metrics and measurements. In this work, we evaluate
whether explanations can improve human decision-making in practical scenarios
of machine learning model development. We conduct a mixed-methods user study
involving image data to evaluate saliency maps generated by SmoothGrad,
GradCAM, and an oracle explanation on two tasks: model selection and
counterfactual simulation. To our surprise, we did not find evidence of
significant improvement on these tasks when users were provided with any of the
saliency maps, even the synthetic oracle explanation designed to be simple to
understand and highly indicative of the answer. Nonetheless, explanations did
help users more accurately describe the models. These findings suggest caution
regarding the usefulness and potential for misunderstanding in saliency-based
explanations.

摘要：可解釋 AI 的動機之一是讓人們在使用和部署 AI 模型時做出更好、更明智的決策。但需要仔細評估以評估是否已達到此預期。目前的評估主要集中在解釋的演算法特性，而涉及人類受試者的評估通常採用主觀問題來測試人類對解釋有用性的看法，而沒有基於客觀指標和測量。在這項工作中，我們評估解釋是否可以在機器學習模型開發的實際場景中改善人類決策制定。我們進行了一項涉及影像資料的混合方法使用者研究，以評估 SmoothGrad、GradCAM 和預言解釋在兩個任務中產生的顯著性圖：模型選擇和反事實模擬。令人驚訝的是，我們沒有發現任何顯著性圖（即使是設計為易於理解且高度指示答案的合成預言解釋）能讓使用者在這些任務上顯著改善的證據。儘管如此，解釋確實有助於使用者更準確地描述模型。這些發現提示我們要對基於顯著性的解釋中可能存在誤解的有用性保持謹慎。

##### **Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability, Explainability, and Safety**
2312.06798v1 by Manas Gaur, Amit Sheth

Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.

摘要：可解釋性和安全性建立信任。這些需要一個模型來展示一致性和可靠性。為了實現這些，有必要使用和分析數據和知識，並使用與 AI 應用相關的統計和符號 AI 方法 - 單獨使用任何一種方法都不會奏效。因此，我們主張並試圖證明 NeuroSymbolic AI 方法更適合於使 AI 成為受信任的 AI 系統。我們提出了 CREST 框架，展示了一致性、可靠性、使用者層級的可解釋性和安全性是如何建立在 NeuroSymbolic 方法上的，該方法使用數據和知識來支持關鍵應用（例如健康和福祉）的要求。本文重點關注大型語言模型 (LLM)，因為它是 CREST 框架中選擇的 AI 系統。LLM 因其在處理廣泛的自然語言處理 (NLP) 場景方面的多功能性而備受研究人員的關注。例如，ChatGPT 和 Google 的 MedPaLM 已成為提供一般和健康相關查詢信息的極有希望的平台。儘管如此，這些模型仍然是黑盒子，儘管納入了人類反饋和指令引導的調整。例如，儘管制定了安全防護措施，ChatGPT 仍可能產生不安全的回應。CREST 提出了一種合理的方法，在 NeuroSymbolic 框架中利用程序和基於圖表的知識，以闡明與 LLM 相關的挑戰。

##### **Class-Discriminative Attention Maps for Vision Transformers**
2312.02364v3 by Lennart Brocki, Jakub Binda, Neo Christopher Chung

Importance estimators are explainability methods that quantify feature
importance for deep neural networks (DNN). In vision transformers (ViT), the
self-attention mechanism naturally leads to attention maps, which are sometimes
interpreted as importance scores that indicate which input features ViT models
are focusing on. However, attention maps do not account for signals from
downstream tasks. To generate explanations that are sensitive to downstream
tasks, we have developed class-discriminative attention maps (CDAM), a
gradient-based extension that estimates feature importance with respect to a
known class or a latent concept. CDAM scales attention scores by how relevant
the corresponding tokens are for the predictions of a classifier head. In
addition to targeting the supervised classifier, CDAM can explain an arbitrary
concept shared by selected samples by measuring similarity in the latent space
of ViT. Additionally, we introduce Smooth CDAM and Integrated CDAM, which
average a series of CDAMs with slightly altered tokens. Our quantitative
benchmarks include correctness, compactness, and class sensitivity, in
comparison to 7 other importance estimators. Vanilla, Smooth, and Integrated
CDAM excel across all three benchmarks. In particular, our results suggest that
existing importance estimators may not provide sufficient class-sensitivity. We
demonstrate the utility of CDAM in medical images by training and explaining
malignancy and biomarker prediction models based on lung Computed Tomography
(CT) scans. Overall, CDAM is shown to be highly class-discriminative and
semantically relevant, while providing compact explanations.

摘要：<paragraph>重要性估計器是一種可解釋性方法，用於量化深度神經網路 (DNN) 的特徵重要性。在視覺Transformer (ViT) 中，自我注意機制自然會導致注意力圖，有時會將其解釋為重要性分數，表示 ViT 模型關注哪些輸入特徵。然而，注意力圖並未考慮來自下游任務的信號。為了產生對下游任務敏感的解釋，我們開發了類別區分注意力圖 (CDAM)，這是一種基於梯度的擴充，用於估計相對於已知類別或潛在概念的特徵重要性。CDAM 根據對應的符號與分類器頭的預測相關程度，調整注意力分數。除了針對監督分類器外，CDAM 還可以通過測量 ViT 的潛在空間中的相似性來解釋選定樣本共有的任意概念。此外，我們引入了平滑 CDAM 和積分 CDAM，它們對一系列具有略微改變的符號的 CDAM 進行平均。我們的量化基準包括正確性、緊湊性和類別敏感性，與其他 7 個重要性估計器相比。香草、平滑和積分 CDAM 在所有三個基準中表現出色。特別是，我們的結果表明現有的重要性估計器可能無法提供足夠的類別敏感性。我們通過基於肺部電腦斷層掃描 (CT) 掃描訓練和解釋惡性腫瘤和生物標記預測模型，證明了 CDAM 在醫學影像中的效用。總的來說，CDAM 被證明具有高度類別區分性和語義相關性，同時提供簡潔的解釋。</paragraph>

##### **Deployment of a Robust and Explainable Mortality Prediction Model: The COVID-19 Pandemic and Beyond**
2311.17133v1 by Jacob R. Epifano, Stephen Glass, Ravi P. Ramachandran, Sharad Patel, Aaron J. Masino, Ghulam Rasool

This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.

摘要：本研究调查了在 COVID-19 疫情期间及以后预测死亡率时，已部署人工智能 (AI) 模型的性能、可解释性和稳健性。作为同类研究中的首例，我们发现贝叶斯神经网络 (BNN) 和智能训练技术让我们的模型在数据发生重大变化时仍能保持性能。我们的结果强调了开发稳健的 AI 模型的重要性，即使在具有挑战性的条件下，这些模型也能匹配或超越临床医生的预测。我们对模型可解释性的探索表明，随机模型会产生更多样化且个性化的解释，从而突出了在现实世界的临床环境中提供详细且个性化见解的 AI 模型的必要性。此外，我们强调了量化 AI 模型中不确定性的重要性，这使临床医生能够根据可靠的预测做出更明智的决策。我们的研究提倡在医疗保健的 AI 研究中优先考虑实施科学，并确保 AI 解决方案在现实世界的临床环境中实用、有益且可持续。通过解决医疗保健环境中的独特挑战和复杂性，研究人员可以开发出有效改善临床实践和患者预后的 AI 模型。

##### **Variational Autoencoders for Feature Exploration and Malignancy Prediction of Lung Lesions**
2311.15719v1 by Benjamin Keel, Aaron Quyn, David Jayne, Samuel D. Relton

Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.

摘要：肺癌占英國癌症死亡人數的 21%，五年存活率很大程度取決於癌症被發現的階段。最近的研究已證明人工智能方法具有從例行掃描中準確及早診斷肺癌的能力。然而，此證據尚未轉化為臨床實務，其中一個障礙是缺乏可解釋的模型。本研究探討了應用變分自動編碼器 (VAE)，一種生成式人工智能模型，於肺癌病灶。將提出的模型訓練於從 LIDC-IDRI 公共數據集中提取的 3D 電腦斷層掃描病灶。通過聚類探索了 VAE 生成的 2D 切片的潛在向量表示，以證明其品質，並用於肺癌診斷的 MLP 分類器模型，最佳模型達到了 AUC 0.98 和 93.1% 準確度的最先進指標。聚類分析顯示，VAE 潛在空間根據有意義的特徵組成（包括腫瘤大小、形狀、患者和惡性類別）將惡性和良性病灶的數據集分開。我們還包括標準高斯 VAE (GVAE) 和更新的狄利克雷 VAE (DirVAE) 的比較分析，後者用狄利克雷分佈取代先驗，以促進具有解開特徵表示的更具可解釋性的潛在空間。最後，我們展示了與臨床有意義的特徵變化相應的潛在空間橫越的潛力。

##### **MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting**
2311.14471v1 by Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal

Existing tools for explaining the output of image classifiers can be divided
into white-box, which rely on access to the model internals, and black-box,
agnostic to the model. As the usage of AI in the medical domain grows, so too
does the usage of explainability tools. Existing work on medical image
explanations focuses on white-box tools, such as gradcam. However, there are
clear advantages to switching to a black-box tool, including the ability to use
it with any classifier and the wide selection of black-box tools available. On
standard images, black-box tools are as precise as white-box. In this paper we
compare the performance of several black-box methods against gradcam on a brain
cancer MRI dataset. We demonstrate that most black-box tools are not suitable
for explaining medical image classifications and present a detailed analysis of
the reasons for their shortcomings. We also show that one black-box tool, a
causal explainability-based rex, performs as well as \gradcam.

摘要：現有的圖像分類器輸出解釋工具可分為依賴於模型內部存取權限的白盒，以及與模型無關的黑盒。隨著 AI 在醫療領域的使用增加，可解釋性工具的使用也隨之增加。現有醫學影像解釋的工作重點在於白盒工具，例如 gradcam。然而，切換到黑盒工具有明顯的優點，包括能夠與任何分類器一起使用，以及廣泛的黑盒工具可供選擇。在標準影像上，黑盒工具與白盒一樣精確。在本文中，我們比較了多種黑盒方法在腦癌 MRI 資料集上與 gradcam 的效能。我們證明大多數黑盒工具不適合解釋醫學影像分類，並詳細分析其缺點的原因。我們還表明一種黑盒工具，基於因果可解釋性的 rex，表現與 \gradcam 一樣好。

##### **Moderating Model Marketplaces: Platform Governance Puzzles for AI Intermediaries**
2311.12573v3 by Robert Gorwa, Michael Veale

The AI development community is increasingly making use of hosting
intermediaries such as Hugging Face provide easy access to user-uploaded models
and training data. These model marketplaces lower technical deployment barriers
for hundreds of thousands of users, yet can be used in numerous potentially
harmful and illegal ways. In this article, we explain ways in which AI systems,
which can both `contain' content and be open-ended tools, present one of the
trickiest platform governance challenges seen to date. We provide case studies
of several incidents across three illustrative platforms -- Hugging Face,
GitHub and Civitai -- to examine how model marketplaces moderate models.
Building on this analysis, we outline important (and yet nevertheless limited)
practices that industry has been developing to respond to moderation demands:
licensing, access and use restrictions, automated content moderation, and open
policy development. While the policy challenge at hand is a considerable one,
we conclude with some ideas as to how platforms could better mobilize resources
to act as a careful, fair, and proportionate regulatory access point.

摘要：AI 開發社群日益利用 Hugging Face 等託管中介機構提供用戶上傳的模型和訓練資料的簡易存取權限。這些模型市集降低了數十萬名用戶的技術部署障礙，但可能會被用於許多潛在有害和非法的方式。在本文中，我們說明 AI 系統既可以「包含」內容，又可以作為開放式工具，這提出了迄今為止最棘手的平台治理挑戰之一。我們提供 Hugging Face、GitHub 和 Civitai 等三個說明性平台上數起事件的案例研究，以檢視模型市集如何審核模型。根據此分析，我們概述產業為回應審核需求而開發的重要（但仍有限）實務：授權、存取和使用限制、自動化內容審核和開放政策制定。雖然當前政策挑戰相當可觀，我們最後提出一些構想，說明平台如何能更好地動員資源，作為謹慎、公平且適度的法規存取點。

##### **Ovarian Cancer Data Analysis using Deep Learning: A Systematic Review from the Perspectives of Key Features of Data Analysis and AI Assurance**
2311.11932v1 by Muta Tah Hira, Mohammad A. Razzaque, Mosharraf Sarker

Background and objectives: By extracting this information, Machine or Deep
Learning (ML/DL)-based autonomous data analysis tools can assist clinicians and
cancer researchers in discovering patterns and relationships from complex data
sets. Many DL-based analyses on ovarian cancer (OC) data have recently been
published. These analyses are highly diverse in various aspects of cancer
(e.g., subdomain(s) and cancer type they address) and data analysis features.
However, a comprehensive understanding of these analyses in terms of these
features and AI assurance (AIA) is currently lacking. This systematic review
aims to fill this gap by examining the existing literature and identifying
important aspects of OC data analysis using DL, explicitly focusing on the key
features and AI assurance perspectives. Methods: The PRISMA framework was used
to conduct comprehensive searches in three journal databases. Only studies
published between 2015 and 2023 in peer-reviewed journals were included in the
analysis. Results: In the review, a total of 96 DL-driven analyses were
examined. The findings reveal several important insights regarding DL-driven
ovarian cancer data analysis: - Most studies 71% (68 out of 96) focused on
detection and diagnosis, while no study addressed the prediction and prevention
of OC. - The analyses were predominantly based on samples from a non-diverse
population (75% (72/96 studies)), limited to a geographic location or country.
- Only a small proportion of studies (only 33% (32/96)) performed integrated
analyses, most of which used homogeneous data (clinical or omics). - Notably, a
mere 8.3% (8/96) of the studies validated their models using external and
diverse data sets, highlighting the need for enhanced model validation, and -
The inclusion of AIA in cancer data analysis is in a very early stage; only
2.1% (2/96) explicitly addressed AIA through explainability.

摘要：<paragraph>背景和目標：通過提取這些資訊，機器或深度學習 (ML/DL) 基於自主數據分析工具可以協助臨床醫生和癌症研究人員從複雜的數據集中發現模式和關係。最近已發表許多基於 DL 的卵巢癌 (OC) 數據分析。這些分析在癌症的各個方面（例如，它們涉及的子領域和癌症類型）和數據分析功能方面高度多樣化。然而，目前缺乏對這些分析在這些特徵和 AI 保證 (AIA) 方面的全面理解。這篇系統性回顧旨在通過檢視現有文獻並明確關注關鍵特徵和 AI 保證觀點，來填補這個空白。方法：使用 PRISMA 架構在三個期刊資料庫中進行全面搜尋。分析僅包括 2015 年至 2023 年間發表於同行評審期刊的研究。結果：在回顧中，總共檢視了 96 項由 DL 驅動的分析。研究結果揭示了幾個關於由 DL 驅動的卵巢癌數據分析的重要見解：- 大多數研究 71%（96 項中有 68 項）專注於檢測和診斷，而沒有研究探討 OC 的預測和預防。- 這些分析主要基於來自非多元族群的樣本（75%（96 項研究中的 72 項）），僅限於某個地理位置或國家。- 只有少部分研究（僅 33%（96 項研究中的 32 項）執行整合分析，其中大多數使用同質數據（臨床或組學）。- 值得注意的是，只有 8.3%（96 項研究中的 8 項）使用外部和多元數據集驗證了其模型，強調了加強模型驗證的必要性，以及- 將 AIA 納入癌症數據分析仍處於非常早期的階段；只有 2.1%（96 項研究中的 2 項）透過可解釋性明確探討了 AIA。</paragraph>

##### **Representing visual classification as a linear combination of words**
2311.10933v1 by Shobhit Agarwal, Yevgeniy R. Semenov, William Lotter

Explainability is a longstanding challenge in deep learning, especially in
high-stakes domains like healthcare. Common explainability methods highlight
image regions that drive an AI model's decision. Humans, however, heavily rely
on language to convey explanations of not only "where" but "what".
Additionally, most explainability approaches focus on explaining individual AI
predictions, rather than describing the features used by an AI model in
general. The latter would be especially useful for model and dataset auditing,
and potentially even knowledge generation as AI is increasingly being used in
novel tasks. Here, we present an explainability strategy that uses a
vision-language model to identify language-based descriptors of a visual
classification task. By leveraging a pre-trained joint embedding space between
images and text, our approach estimates a new classification task as a linear
combination of words, resulting in a weight for each word that indicates its
alignment with the vision-based classifier. We assess our approach using two
medical imaging classification tasks, where we find that the resulting
descriptors largely align with clinical knowledge despite a lack of
domain-specific language training. However, our approach also identifies the
potential for 'shortcut connections' in the public datasets used. Towards a
functional measure of explainability, we perform a pilot reader study where we
find that the AI-identified words can enable non-expert humans to perform a
specialized medical task at a non-trivial level. Altogether, our results
emphasize the potential of using multimodal foundational models to deliver
intuitive, language-based explanations of visual tasks.

摘要：<paragraph>解釋性是深度學習中長期的挑戰，特別是在醫療保健等高風險領域。常見的解釋性方法會強調驅動 AI 模型決策的影像區域。然而，人類很大程度依賴語言來傳達不僅是「在哪裡」，還有「是什麼」的解釋。此外，大多數解釋性方法都專注於解釋個別 AI 預測，而不是描述 AI 模型一般使用的特徵。後者對於模型和資料集稽核特別有用，甚至可能在 AI 愈來愈用於新穎任務時產生知識。在此，我們提出一個使用視覺語言模型來辨識視覺分類任務的語言描述符的解釋性策略。透過利用影像和文字之間預先訓練的聯合嵌入空間，我們的做法將新的分類任務估計為一個線性文字組合，導致每個文字都有權重，表示它與基於視覺的分類器對齊。我們使用兩個醫學影像分類任務來評估我們的做法，我們發現產生的描述符在很大程度上與臨床知識一致，儘管缺乏特定領域的語言訓練。然而，我們的做法也發現了所用公開資料集中的「捷徑連線」的可能性。為了達到解釋性的功能性衡量，我們進行了一項試驗讀者研究，發現 AI 識別的文字能讓非專家人類在非平凡的層級執行專業的醫療任務。總之，我們的結果強調了使用多模式基礎模型來提供直觀的、基於語言的視覺任務解釋的潛力。</paragraph>

##### **Towards objective and systematic evaluation of bias in artificial intelligence for medical imaging**
2311.02115v2 by Emma A. M. Stanley, Raissa Souza, Anthony Winder, Vedant Gulve, Kimberly Amador, Matthias Wilms, Nils D. Forkert

Artificial intelligence (AI) models trained using medical images for clinical
tasks often exhibit bias in the form of disparities in performance between
subgroups. Since not all sources of biases in real-world medical imaging data
are easily identifiable, it is challenging to comprehensively assess how those
biases are encoded in models, and how capable bias mitigation methods are at
ameliorating performance disparities. In this article, we introduce a novel
analysis framework for systematically and objectively investigating the impact
of biases in medical images on AI models. We developed and tested this
framework for conducting controlled in silico trials to assess bias in medical
imaging AI using a tool for generating synthetic magnetic resonance images with
known disease effects and sources of bias. The feasibility is showcased by
using three counterfactual bias scenarios to measure the impact of simulated
bias effects on a convolutional neural network (CNN) classifier and the
efficacy of three bias mitigation strategies. The analysis revealed that the
simulated biases resulted in expected subgroup performance disparities when the
CNN was trained on the synthetic datasets. Moreover, reweighing was identified
as the most successful bias mitigation strategy for this setup, and we
demonstrated how explainable AI methods can aid in investigating the
manifestation of bias in the model using this framework. Developing fair AI
models is a considerable challenge given that many and often unknown sources of
biases can be present in medical imaging datasets. In this work, we present a
novel methodology to objectively study the impact of biases and mitigation
strategies on deep learning pipelines, which can support the development of
clinical AI that is robust and responsible.

摘要：<paragraph>使用醫療影像訓練的人工智慧 (AI) 模型，用於臨床任務時，常會在效能上展現出次群體之間的差異，形成偏見。由於並非所有真實世界醫療影像資料中的偏見來源都容易辨識，因此全面評估這些偏見是如何編碼到模型中，以及偏見緩解方法在改善效能差異方面的能力，是一項挑戰。在本文中，我們介紹了一個新穎的分析架構，用於系統化且客觀地調查醫療影像中的偏見對 AI 模型的影響。我們開發並測試了這個架構，以進行受控的電腦模擬試驗，使用一個工具來評估醫療影像 AI 中的偏見，該工具用於產生具有已知疾病影響和偏見來源的合成磁共振影像。可行性透過使用三個反事實偏見情境來衡量模擬偏見效應對卷積神經網路 (CNN) 分類器和三個偏見緩解策略的影響，並展示出來。分析顯示，當 CNN 在合成資料集上受訓時，模擬偏見會導致預期的次群體效能差異。此外，重新加權被認為是此設定中最成功的偏見緩解策略，我們展示了解釋性 AI 方法如何協助使用這個架構調查模型中偏見的表現。開發公平的 AI 模型是一項重大的挑戰，因為醫療影像資料集中可能存在許多且經常未知的偏見來源。在這項工作中，我們提出了一種新穎的方法，用於客觀地研究偏見和緩解策略對深度學習管線的影響，這可以支援健全且負責任的臨床 AI 的開發。</paragraph>

##### **Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI**
2310.19174v1 by Adam White, Margarita Saranti, Artur d'Avila Garcez, Thomas M. H. Hope, Cathy J. Price, Howard Bowman

Machine learning offers great potential for automated prediction of
post-stroke symptoms and their response to rehabilitation. Major challenges for
this endeavour include the very high dimensionality of neuroimaging data, the
relatively small size of the datasets available for learning, and how to
effectively combine neuroimaging and tabular data (e.g. demographic information
and clinical characteristics). This paper evaluates several solutions based on
two strategies. The first is to use 2D images that summarise MRI scans. The
second is to select key features that improve classification accuracy.
Additionally, we introduce the novel approach of training a convolutional
neural network (CNN) on images that combine regions-of-interest extracted from
MRIs, with symbolic representations of tabular data. We evaluate a series of
CNN architectures (both 2D and a 3D) that are trained on different
representations of MRI and tabular data, to predict whether a composite measure
of post-stroke spoken picture description ability is in the aphasic or
non-aphasic range. MRI and tabular data were acquired from 758 English speaking
stroke survivors who participated in the PLORAS study. The classification
accuracy for a baseline logistic regression was 0.678 for lesion size alone,
rising to 0.757 and 0.813 when initial symptom severity and recovery time were
successively added. The highest classification accuracy 0.854 was observed when
8 regions-of-interest was extracted from each MRI scan and combined with lesion
size, initial severity and recovery time in a 2D Residual Neural Network.Our
findings demonstrate how imaging and tabular data can be combined for high
post-stroke classification accuracy, even when the dataset is small in machine
learning terms. We conclude by proposing how the current models could be
improved to achieve even higher levels of accuracy using images from hospital
scanners.

摘要：機器學習為自動預測中風後症狀及其對復健的反應提供了極大的潛力。這項工作的重大挑戰包括神經影像資料的維度非常高、可用於學習的資料集規模相對較小，以及如何有效結合神經影像和表格資料（例如人口統計資訊和臨床特徵）。本文根據兩種策略評估了多種解決方案。第一種是使用總結 MRI 掃描的 2D 影像。第二種是選擇有助於提高分類精確度的關鍵特徵。此外，我們引入了在結合從 MRI 中提取的感興趣區域與表格資料的符號表示的影像上訓練卷積神經網路 (CNN) 的新穎方法。我們評估了一系列 CNN 架構（2D 和 3D），這些架構在 MRI 和表格資料的不同表示上進行訓練，以預測中風後口述圖片描述能力的綜合測量是否在失語症或非失語症範圍內。MRI 和表格資料來自 758 名參與 PLORAS 研究的英語中風倖存者。僅針對病灶大小的基線邏輯迴歸分類準確度為 0.678，當依序加入初始症狀嚴重程度和恢復時間時，上升至 0.757 和 0.813。在從每個 MRI 掃描中提取 8 個感興趣區域並在 2D 殘差神經網路中與病灶大小、初始嚴重程度和恢復時間結合時，觀察到最高的分類準確度 0.854。我們的研究結果展示了如何將影像和表格資料結合起來以獲得高於中風後分類準確度，即使在機器學習術語中資料集很小的情況下也是如此。最後，我們提出如何改進目前的模型，以使用來自醫院掃描儀的影像來實現更高的準確度。

##### **Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation**
2310.01828v2 by Hossein Shreim, Abdul Karim Gizzini, Ali J. Ghandour

eXplainable Artificial Intelligence (XAI) has emerged as an essential
requirement when dealing with mission-critical applications, ensuring
transparency and interpretability of the employed black box AI models. The
significance of XAI spans various domains, from healthcare to finance, where
understanding the decision-making process of deep learning algorithms is
essential. Most AI-based computer vision models are often black boxes; hence,
providing explainability of deep neural networks in image processing is crucial
for their wide adoption and deployment in medical image analysis, autonomous
driving, and remote sensing applications. Recently, several XAI methods for
image classification tasks have been introduced. On the contrary, image
segmentation has received comparatively less attention in the context of
explainability, although it is a fundamental task in computer vision
applications, especially in remote sensing. Only some research proposes
gradient-based XAI algorithms for image segmentation. This paper adapts the
recent gradient-free Sobol XAI method for semantic segmentation. To measure the
performance of the Sobol method for segmentation, we propose a quantitative XAI
evaluation method based on a learnable noise model. The main objective of this
model is to induce noise on the explanation maps, where higher induced noise
signifies low accuracy and vice versa. A benchmark analysis is conducted to
evaluate and compare performance of three XAI methods, including Seg-Grad-CAM,
Seg-Grad-CAM++ and Seg-Sobol using the proposed noise-based evaluation
technique. This constitutes the first attempt to run and evaluate XAI methods
using high-resolution satellite images.

摘要：可解釋人工智慧 (XAI) 已成為處理任務關鍵應用程式時的一項基本需求，確保採用黑盒 AI 模型的透明度和可解釋性。XAI 的重要性涵蓋從醫療保健到金融的各種領域，在這些領域中，了解深度學習演算法的決策制定過程至關重要。大多數基於 AI 的電腦視覺模型通常是黑盒子；因此，在影像處理中提供深度神經網路的可解釋性對於其在醫學影像分析、自動駕駛和遙測應用中的廣泛採用和部署至關重要。最近，已針對影像分類任務引入了多種 XAI 方法。相反地，影像分割在可解釋性的背景下受到的關注相對較少，儘管它是電腦視覺應用中的一項基本任務，特別是在遙測中。只有部分研究提出用於影像分割的基於梯度的 XAI 演算法。本文改編了最近的無梯度 Sobol XAI 方法以進行語意分割。為了衡量 Sobol 方法在分割中的效能，我們提出了一種基於可學習雜訊模型的定量 XAI 評估方法。此模型的主要目的是在解釋圖上誘發雜訊，其中較高的誘發雜訊表示較低的準確度，反之亦然。進行基準分析以評估和比較三種 XAI 方法的效能，包括 Seg-Grad-CAM、Seg-Grad-CAM++ 和 Seg-Sobol，並使用所提出的基於雜訊的評估技術。這構成了使用高解析度衛星影像執行和評估 XAI 方法的首次嘗試。


### LLM
|Publish Date|Title|Authors|Homepage|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-11-21**|**Whack-a-Chip: The Futility of Hardware-Centric Export Controls**|Ritwik Gupta et.al.|[2411.14425v1](http://arxiv.org/abs/2411.14425v1)|null|
|**2024-11-21**|**Marco-o1: Towards Open Reasoning Models for Open-Ended Solutions**|Yu Zhao et.al.|[2411.14405v1](http://arxiv.org/abs/2411.14405v1)|null|
|**2024-11-21**|**Resolving Multiple-Dynamic Model Uncertainty in Hypothesis-Driven Belief-MDPs**|Ofer Dagan et.al.|[2411.14404v1](http://arxiv.org/abs/2411.14404v1)|null|
|**2024-11-21**|**Landing Trajectory Prediction for UAS Based on Generative Adversarial Network**|Jun Xiang et.al.|[2411.14403v1](http://arxiv.org/abs/2411.14403v1)|null|
|**2024-11-21**|**Lightweight Safety Guardrails Using Fine-tuned BERT Embeddings**|Aaron Zheng et.al.|[2411.14398v1](http://arxiv.org/abs/2411.14398v1)|null|
|**2024-11-21**|**POS-tagging to highlight the skeletal structure of sentences**|Grigorii Churakov et.al.|[2411.14393v1](http://arxiv.org/abs/2411.14393v1)|[link](https://github.com/disk0Dancer/rubert-finetuned-pos)|
|**2024-11-21**|**Using Formal Models, Safety Shields and Certified Control to Validate AI-Based Train Systems**|Jan Gruteser et.al.|[2411.14374v1](http://arxiv.org/abs/2411.14374v1)|null|
|**2024-11-21**|**Synthesising Robust Controllers for Robot Collectives with Recurrent Tasks: A Case Study**|Till Schnittka et.al.|[2411.14371v1](http://arxiv.org/abs/2411.14371v1)|null|
|**2024-11-21**|**Contrasting local and global modeling with machine learning and satellite data: A case study estimating tree canopy height in African savannas**|Esther Rolf et.al.|[2411.14354v1](http://arxiv.org/abs/2411.14354v1)|null|
|**2024-11-21**|**UnifiedCrawl: Aggregated Common Crawl for Affordable Adaptation of LLMs on Low-Resource Languages**|Bethel Melesse Tessema et.al.|[2411.14343v1](http://arxiv.org/abs/2411.14343v1)|[link](https://github.com/bethelmelesse/unifiedcrawl)|
|**2024-11-21**|**Velocitune: A Velocity-based Dynamic Domain Reweighting Method for Continual Pre-training**|Zheheng Luo et.al.|[2411.14318v1](http://arxiv.org/abs/2411.14318v1)|null|
|**2024-11-21**|**Automated Generation of Code Debugging Exercises**|Victor-Alexandru Pădurean et.al.|[2411.14303v1](http://arxiv.org/abs/2411.14303v1)|null|
|**2024-11-21**|**Looking Beyond Text: Reducing Language bias in Large Vision-Language Models via Multimodal Dual-Attention and Soft-Image Guidance**|Haozhe Zhao et.al.|[2411.14279v1](http://arxiv.org/abs/2411.14279v1)|null|
|**2024-11-21**|**Neuro-Symbolic Query Optimization in Knowledge Graphs**|Maribel Acosta et.al.|[2411.14277v1](http://arxiv.org/abs/2411.14277v1)|null|
|**2024-11-21**|**Efficient Aspect-Based Summarization of Climate Change Reports with Small Language Models**|Iacopo Ghinassi et.al.|[2411.14272v1](http://arxiv.org/abs/2411.14272v1)|[link](https://github.com/ighina/llmclimate2024)|
|**2024-11-21**|**Generating Realistic Adversarial Examples for Business Processes using Variational Autoencoders**|Alexander Stevens et.al.|[2411.14263v1](http://arxiv.org/abs/2411.14263v1)|null|
|**2024-11-21**|**Knowledge Graphs, Large Language Models, and Hallucinations: An NLP Perspective**|Ernests Lavrinovics et.al.|[2411.14258v1](http://arxiv.org/abs/2411.14258v1)|null|
|**2024-11-21**|**Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models**|Javier Ferrando et.al.|[2411.14257v1](http://arxiv.org/abs/2411.14257v1)|null|
|**2024-11-21**|**BERT-Based Approach for Automating Course Articulation Matrix Construction with Explainable AI**|Natenaile Asmamaw Shiferaw et.al.|[2411.14254v1](http://arxiv.org/abs/2411.14254v1)|[link](https://github.com/natenaile/bert-based-approach-for-automating-course-articulation-matrix-construction-with-explainable-ai)|
|**2024-11-21**|**Intent-Aware Dialogue Generation and Multi-Task Contrastive Learning for Multi-Turn Intent Classification**|Junhua Liu et.al.|[2411.14252v1](http://arxiv.org/abs/2411.14252v1)|null|
|**2024-11-21**|**Natural Language Reinforcement Learning**|Xidong Feng et.al.|[2411.14251v1](http://arxiv.org/abs/2411.14251v1)|null|
|**2024-11-21**|**AnywhereDoor: Multi-Target Backdoor Attacks on Object Detection**|Jialin Lu et.al.|[2411.14243v1](http://arxiv.org/abs/2411.14243v1)|null|
|**2024-11-21**|**Towards Context-Rich Automated Biodiversity Assessments: Deriving AI-Powered Insights from Camera Trap Data**|Paul Fergus et.al.|[2411.14219v1](http://arxiv.org/abs/2411.14219v1)|null|
|**2024-11-21**|**Evaluating the Robustness of Analogical Reasoning in Large Language Models**|Martha Lewis et.al.|[2411.14215v1](http://arxiv.org/abs/2411.14215v1)|[link](https://github.com/marthaflinderslewis/robust-analogy)|
|**2024-11-21**|**Physics-Informed LLM-Agent for Automated Modulation Design in Power Electronics Systems**|Junhua Liu et.al.|[2411.14214v1](http://arxiv.org/abs/2411.14214v1)|null|
|**2024-11-21**|**HARP: A Large-Scale Higher-Order Ambisonic Room Impulse Response Dataset**|Shivam Saini et.al.|[2411.14207v1](http://arxiv.org/abs/2411.14207v1)|[link](https://github.com/whojavumusic/harp)|
|**2024-11-21**|**Is this Generated Person Existed in Real-world? Fine-grained Detecting and Calibrating Abnormal Human-body**|Zeqing Wang et.al.|[2411.14205v1](http://arxiv.org/abs/2411.14205v1)|null|
|**2024-11-21**|**OpenScholar: Synthesizing Scientific Literature with Retrieval-augmented LMs**|Akari Asai et.al.|[2411.14199v1](http://arxiv.org/abs/2411.14199v1)|[link](https://github.com/akariasai/scholarbench)|
|**2024-11-21**|**Why do language models perform worse for morphologically complex languages?**|Catherine Arnett et.al.|[2411.14198v1](http://arxiv.org/abs/2411.14198v1)|[link](https://github.com/catherinearnett/morphscore)|
|**2024-11-21**|**ComfyGI: Automatic Improvement of Image Generation Workflows**|Dominik Sobania et.al.|[2411.14193v1](http://arxiv.org/abs/2411.14193v1)|null|
|**2024-11-21**|**FoPru: Focal Pruning for Efficient Large Vision-Language Models**|Lei Jiang et.al.|[2411.14164v1](http://arxiv.org/abs/2411.14164v1)|null|
|**2024-11-21**|**Visual Contexts Clarify Ambiguous Expressions: A Benchmark Dataset**|Heejeong Nam et.al.|[2411.14137v1](http://arxiv.org/abs/2411.14137v1)|null|
|**2024-11-21**|**GASP: Efficient Black-Box Generation of Adversarial Suffixes for Jailbreaking LLMs**|Advik Raj Basani et.al.|[2411.14133v1](http://arxiv.org/abs/2411.14133v1)|[link](https://github.com/llm-gasp/gasp)|
|**2024-11-21**|**Learning from "Silly" Questions Improves Large Language Models, But Only Slightly**|Tingyuan Zhu et.al.|[2411.14121v1](http://arxiv.org/abs/2411.14121v1)|null|
|**2024-11-21**|**Lost in Inference: Rediscovering the Role of Natural Language Inference for Large Language Models**|Lovish Madaan et.al.|[2411.14103v1](http://arxiv.org/abs/2411.14103v1)|null|
|**2024-11-21**|**BEST-STD: Bidirectional Mamba-Enhanced Speech Tokenization for Spoken Term Detection**|Anup Singh et.al.|[2411.14100v1](http://arxiv.org/abs/2411.14100v1)|[link](https://github.com/anupsingh15/BEST-STD)|
|**2024-11-21**|**Meaning at the Planck scale? Contextualized word embeddings for doing history, philosophy, and sociology of science**|Arno Simons et.al.|[2411.14073v1](http://arxiv.org/abs/2411.14073v1)|null|
|**2024-11-21**|**The Master-Slave Encoder Model for Improving Patent Text Summarization: A New Approach to Combining Specifications and Claims**|Shu Zhou et.al.|[2411.14072v1](http://arxiv.org/abs/2411.14072v1)|null|
|**2024-11-21**|**Multi LoRA Meets Vision: Merging multiple adapters to create a multi task model**|Ege Kesim et.al.|[2411.14064v1](http://arxiv.org/abs/2411.14064v1)|null|
|**2024-11-21**|**MMGenBench: Evaluating the Limits of LMMs from the Text-to-Image Generation Perspective**|Hailang Huang et.al.|[2411.14062v1](http://arxiv.org/abs/2411.14062v1)|[link](https://github.com/lerogo/mmgenbench)|
|**2024-11-21**|**DRPruning: Efficient Large Language Model Pruning through Distributionally Robust Optimization**|Hexuan Deng et.al.|[2411.14055v1](http://arxiv.org/abs/2411.14055v1)|[link](https://github.com/hexuandeng/drpruning)|
|**2024-11-21**|**FunctionChat-Bench: Comprehensive Evaluation of Language Models' Generative Capabilities in Korean Tool-use Dialogs**|Shinbok Lee et.al.|[2411.14054v1](http://arxiv.org/abs/2411.14054v1)|[link](https://github.com/kakao/functionchat-bench)|
|**2024-11-21**|**Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling**|Daehoon Gwak et.al.|[2411.14042v1](http://arxiv.org/abs/2411.14042v1)|null|
|**2024-11-21**|**Uterine Ultrasound Image Captioning Using Deep Learning Techniques**|Abdennour Boulesnane et.al.|[2411.14039v1](http://arxiv.org/abs/2411.14039v1)|null|
|**2024-11-21**|**Assessing data-driven predictions of band gap and electrical conductivity for transparent conducting materials**|Federico Ottomano et.al.|[2411.14034v1](http://arxiv.org/abs/2411.14034v1)|null|
|**2024-11-21**|**Multi-LLM-Agent Systems: Techniques and Business Perspectives**|Yingxuan Yang et.al.|[2411.14033v1](http://arxiv.org/abs/2411.14033v1)|null|
|**2024-11-21**|**Logic Augmented Generation**|Aldo Gangemi et.al.|[2411.14012v1](http://arxiv.org/abs/2411.14012v1)|null|
|**2024-11-21**|**Mirror Target YOLO: An Improved YOLOv8 Method with Indirect Vision for Heritage Buildings Fire Detection**|Jian Liang et.al.|[2411.13997v1](http://arxiv.org/abs/2411.13997v1)|null|
|**2024-11-21**|**Safety Without Semantic Disruptions: Editing-free Safe Image Generation via Context-preserving Dual Latent Reconstruction**|Jordan Vice et.al.|[2411.13982v1](http://arxiv.org/abs/2411.13982v1)|null|
|**2024-11-21**|**On the Fairness, Diversity and Reliability of Text-to-Image Generative Models**|Jordan Vice et.al.|[2411.13981v1](http://arxiv.org/abs/2411.13981v1)|null|
|**2024-11-21**|**FedRAV: Hierarchically Federated Region-Learning for Traffic Object Classification of Autonomous Vehicles**|Yijun Zhai et.al.|[2411.13979v1](http://arxiv.org/abs/2411.13979v1)|[link](https://github.com/yjzhai-cs/fedrav)|
|**2024-11-21**|**Separable Mixture of Low-Rank Adaptation for Continual Visual Instruction Tuning**|Ziqi Wang et.al.|[2411.13949v1](http://arxiv.org/abs/2411.13949v1)|null|
|**2024-11-21**|**LLMs as Continuous Learners: Improving the Reproduction of Defective Code in Software Issues**|Yalan Lin et.al.|[2411.13941v1](http://arxiv.org/abs/2411.13941v1)|null|
|**2024-11-21**|**Learning to Cooperate with Humans using Generative Agents**|Yancheng Liang et.al.|[2411.13934v1](http://arxiv.org/abs/2411.13934v1)|[link](https://github.com/lych1233/gamma-human-ai-collaboration)|
|**2024-11-21**|**XAgents: A Framework for Interpretable Rule-Based Multi-Agents Cooperation**|Hailong Yang et.al.|[2411.13932v1](http://arxiv.org/abs/2411.13932v1)|null|
|**2024-11-21**|**Split Federated Learning Over Heterogeneous Edge Devices: Algorithm and Optimization**|Yunrui Sun et.al.|[2411.13907v1](http://arxiv.org/abs/2411.13907v1)|null|
|**2024-11-21**|**Towards Full Delegation: Designing Ideal Agentic Behaviors for Travel Planning**|Song Jiang et.al.|[2411.13904v1](http://arxiv.org/abs/2411.13904v1)|null|
|**2024-11-21**|**AmpliNetECG12: A lightweight SoftMax-based relativistic amplitude amplification architecture for 12 lead ECG classification**|Shreya Srivastava et.al.|[2411.13903v1](http://arxiv.org/abs/2411.13903v1)|null|
|**2024-11-21**|**PIORS: Personalized Intelligent Outpatient Reception based on Large Language Model with Multi-Agents Medical Scenario Simulation**|Zhijie Bao et.al.|[2411.13902v1](http://arxiv.org/abs/2411.13902v1)|null|
|**2024-11-21**|**When Online Algorithms Influence the Environment: A Dynamical Systems Analysis of the Unintended Consequences**|Prabhat Lankireddy et.al.|[2411.13883v1](http://arxiv.org/abs/2411.13883v1)|null|
|**2024-11-21**|**Next-Generation Phishing: How LLM Agents Empower Cyber Attackers**|Khalifa Afane et.al.|[2411.13874v1](http://arxiv.org/abs/2411.13874v1)|null|
|**2024-11-21**|**Robust Detection of Watermarks for Large Language Models Under Human Edits**|Xiang Li et.al.|[2411.13868v1](http://arxiv.org/abs/2411.13868v1)|null|
|**2024-11-21**|**Generative Fuzzy System for Sequence Generation**|Hailong Yang et.al.|[2411.13867v1](http://arxiv.org/abs/2411.13867v1)|null|
|**2024-11-21**|**HARec: Hyperbolic Graph-LLM Alignment for Exploration and Exploitation in Recommender Systems**|Qiyao Ma et.al.|[2411.13865v1](http://arxiv.org/abs/2411.13865v1)|null|
|**2024-11-21**|**Exploratory Study Of Human-AI Interaction For Hindustani Music**|Nithya Shikarpur et.al.|[2411.13846v1](http://arxiv.org/abs/2411.13846v1)|null|
|**2024-11-21**|**Interactive and Expressive Code-Augmented Planning with Large Language Models**|Anthony Z. Liu et.al.|[2411.13826v1](http://arxiv.org/abs/2411.13826v1)|null|
|**2024-11-21**|**Heterophilic Graph Neural Networks Optimization with Causal Message-passing**|Botao Wang et.al.|[2411.13821v1](http://arxiv.org/abs/2411.13821v1)|null|
|**2024-11-21**|**InstCache: A Predictive Cache for LLM Serving**|Longwei Zou et.al.|[2411.13820v1](http://arxiv.org/abs/2411.13820v1)|null|
|**2024-11-21**|**AutoMixQ: Self-Adjusting Quantization for High Performance Memory-Efficient Fine-Tuning**|Changhai Zhou et.al.|[2411.13814v1](http://arxiv.org/abs/2411.13814v1)|null|
|**2024-11-21**|**SemiKong: Curating, Training, and Evaluating A Semiconductor Industry-Specific Large Language Model**|Christopher Nguyen et.al.|[2411.13802v1](http://arxiv.org/abs/2411.13802v1)|[link](https://github.com/aitomatic/semikong)|
|**2024-11-21**|**Explaining GPT-4's Schema of Depression Using Machine Behavior Analysis**|Adithya V Ganesan et.al.|[2411.13800v1](http://arxiv.org/abs/2411.13800v1)|null|
|**2024-11-21**|**NewsInterview: a Dataset and a Playground to Evaluate LLMs' Ground Gap via Informational Interviews**|Michael Lu et.al.|[2411.13779v1](http://arxiv.org/abs/2411.13779v1)|[link](https://github.com/alex2awesome/news-interview-question-generation)|
|**2024-11-21**|**Benchmarking GPT-4 against Human Translators: A Comprehensive Evaluation Across Languages, Domains, and Expertise Levels**|Jianhao Yan et.al.|[2411.13775v1](http://arxiv.org/abs/2411.13775v1)|null|
|**2024-11-21**|**FastRAG: Retrieval Augmented Generation for Semi-structured Data**|Amar Abane et.al.|[2411.13773v1](http://arxiv.org/abs/2411.13773v1)|null|
|**2024-11-21**|**An Evaluation-Driven Approach to Designing LLM Agents: Process and Architecture**|Boming Xia et.al.|[2411.13768v1](http://arxiv.org/abs/2411.13768v1)|null|
|**2024-11-21**|**Tiny-Align: Bridging Automatic Speech Recognition and Large Language Model on the Edge**|Ruiyang Qin et.al.|[2411.13766v1](http://arxiv.org/abs/2411.13766v1)|null|
|**2024-11-21**|**A Framework for Evaluating LLMs Under Task Indeterminacy**|Luke Guerdan et.al.|[2411.13760v1](http://arxiv.org/abs/2411.13760v1)|null|
|**2024-11-21**|**AttentionBreaker: Adaptive Evolutionary Optimization for Unmasking Vulnerabilities in LLMs through Bit-Flip Attacks**|Sanjay Das et.al.|[2411.13757v1](http://arxiv.org/abs/2411.13757v1)|null|
|**2024-11-20**|**AI-Driven Agents with Prompts Designed for High Agreeableness Increase the Likelihood of Being Mistaken for a Human in the Turing Test**|U. León-Domínguez et.al.|[2411.13749v1](http://arxiv.org/abs/2411.13749v1)|null|
|**2024-11-20**|**Federated Continual Learning for Edge-AI: A Comprehensive Survey**|Zi Wang et.al.|[2411.13740v1](http://arxiv.org/abs/2411.13740v1)|null|
|**2024-11-20**|**Assessing Gender Bias in LLMs: Comparing LLM Outputs with Human Perceptions and Official Statistics**|Tetiana Bas et.al.|[2411.13738v1](http://arxiv.org/abs/2411.13738v1)|[link](https://github.com/tetianabas/llm_biases)|
|**2024-11-20**|**Exploring Large Language Models for Climate Forecasting**|Yang Wang et.al.|[2411.13724v1](http://arxiv.org/abs/2411.13724v1)|null|
|**2024-11-20**|**SimPhony: A Device-Circuit-Architecture Cross-Layer Modeling and Simulation Framework for Heterogeneous Electronic-Photonic AI System**|Ziang Yin et.al.|[2411.13715v1](http://arxiv.org/abs/2411.13715v1)|null|
|**2024-11-20**|**Retrieval-Augmented Generation for Domain-Specific Question Answering: A Case Study on Pittsburgh and CMU**|Haojia Sun et.al.|[2411.13691v1](http://arxiv.org/abs/2411.13691v1)|null|
|**2024-11-20**|**Hierarchical Text Classification (HTC) vs. eXtreme Multilabel Classification (XML): Two Sides of the Same Medal**|Nerijus Bertalis et.al.|[2411.13687v1](http://arxiv.org/abs/2411.13687v1)|[link](https://github.com/flohauss/xmc_htc)|
|**2024-11-20**|**Hymba: A Hybrid-head Architecture for Small Language Models**|Xin Dong et.al.|[2411.13676v1](http://arxiv.org/abs/2411.13676v1)|null|
|**2024-11-20**|**FabuLight-ASD: Unveiling Speech Activity via Body Language**|Hugo Carneiro et.al.|[2411.13674v1](http://arxiv.org/abs/2411.13674v1)|[link](https://github.com/knowledgetechnologyuhh/fabulight-asd)|
|**2024-11-20**|**No Free Delivery Service: Epistemic limits of passive data collection in complex social systems**|Maximilian Nickel et.al.|[2411.13653v1](http://arxiv.org/abs/2411.13653v1)|null|
|**2024-11-20**|**SpecTool: A Benchmark for Characterizing Errors in Tool-Use LLMs**|Shirley Kokane et.al.|[2411.13547v1](http://arxiv.org/abs/2411.13547v1)|null|
|**2024-11-20**|**BALROG: Benchmarking Agentic LLM and VLM Reasoning On Games**|Davide Paglieri et.al.|[2411.13543v1](http://arxiv.org/abs/2411.13543v1)|null|
|**2024-11-20**|**Metacognition for Unknown Situations and Environments (MUSE)**|Rodolfo Valiente et.al.|[2411.13537v1](http://arxiv.org/abs/2411.13537v1)|null|
|**2024-11-20**|**Identity Preserving 3D Head Stylization with Multiview Score Distillation**|Bahri Batuhan Bilecen et.al.|[2411.13536v1](http://arxiv.org/abs/2411.13536v1)|null|
|**2024-11-20**|**Predictive Insights into LGBTQ+ Minority Stress: A Transductive Exploration of Social Media Discourse**|S. Chapagain et.al.|[2411.13534v1](http://arxiv.org/abs/2411.13534v1)|[link](https://github.com/chapagaisa/transductive)|
|**2024-11-20**|**Advancing Complex Medical Communication in Arabic with Sporo AraSum: Surpassing Existing Large Language Models**|Chanseo Lee et.al.|[2411.13518v1](http://arxiv.org/abs/2411.13518v1)|null|
|**2024-11-20**|**Disentangling Memory and Reasoning Ability in Large Language Models**|Mingyu Jin et.al.|[2411.13504v2](http://arxiv.org/abs/2411.13504v2)|[link](https://github.com/mingyuj666/disentangling-memory-and-reasoning)|
|**2024-11-20**|**Utilizing Large Language Models to Synthesize Product Desirability Datasets**|John D. Hastings et.al.|[2411.13485v1](http://arxiv.org/abs/2411.13485v1)|null|
|**2024-11-20**|**PatentEdits: Framing Patent Novelty as Textual Entailment**|Ryan Lee et.al.|[2411.13477v1](http://arxiv.org/abs/2411.13477v1)|null|
|**2024-11-20**|**When Precision Meets Position: BFloat16 Breaks Down RoPE in Long-Context Training**|Haonan Wang et.al.|[2411.13476v1](http://arxiv.org/abs/2411.13476v1)|[link](https://github.com/haonan3/anchorcontext)|
|**2024-11-20**|**SoK: A Systems Perspective on Compound AI Threats and Countermeasures**|Sarbartha Banerjee et.al.|[2411.13459v1](http://arxiv.org/abs/2411.13459v1)|null|
|**2024-11-20**|**LIMBA: An Open-Source Framework for the Preservation and Valorization of Low-Resource Languages using Generative Models**|Salvatore Mario Carta et.al.|[2411.13453v1](http://arxiv.org/abs/2411.13453v1)|null|

#### Abstracts
##### **Whack-a-Chip: The Futility of Hardware-Centric Export Controls**
2411.14425v1 by Ritwik Gupta, Leah Walker, Andrew W. Reddie

U.S. export controls on semiconductors are widely known to be permeable, with
the People's Republic of China (PRC) steadily creating state-of-the-art
artificial intelligence (AI) models with exfiltrated chips. This paper presents
the first concrete, public evidence of how leading PRC AI labs evade and
circumvent U.S. export controls. We examine how Chinese companies, notably
Tencent, are not only using chips that are restricted under U.S. export
controls but are also finding ways to circumvent these regulations by using
software and modeling techniques that maximize less capable hardware.
Specifically, we argue that Tencent's ability to power its Hunyuan-Large model
with non-export controlled NVIDIA H20s exemplifies broader gains in efficiency
in machine learning that have eroded the moat that the United States initially
built via its existing export controls. Finally, we examine the implications of
this finding for the future of the United States' export control strategy.

摘要：美國對半導體的出口管制措施眾所周知是具有滲透性的，而中華人民共和國（PRC）則持續透過外洩的晶片打造最先進的人工智慧（AI）模型。本文提出第一個具體的公開證據，說明中國領先的 AI 實驗室如何規避和繞過美國的出口管制。我們探討中國公司，尤其是騰訊，如何不僅使用美國出口管制限制的晶片，還透過使用軟體和建模技術，最大化功能較弱的硬體，來找出規避這些法規的方法。具體來說，我們認為騰訊能夠使用非出口管制的 NVIDIA H20s 來為其 Hunyuan-Large 模型供電，這說明了機器學習效率的更廣泛提升，而這已侵蝕了美國最初透過其現有出口管制措施所建立的護城河。最後，我們探討這一發現對美國未來出口管制策略的影響。

##### **Marco-o1: Towards Open Reasoning Models for Open-Ended Solutions**
2411.14405v1 by Yu Zhao, Huifeng Yin, Bo Zeng, Hao Wang, Tianqi Shi, Chenyang Lyu, Longyue Wang, Weihua Luo, Kaifu Zhang

Currently OpenAI o1 has sparked a surge of interest in the study of large
reasoning models (LRM). Building on this momentum, Marco-o1 not only focuses on
disciplines with standard answers, such as mathematics, physics, and coding --
which are well-suited for reinforcement learning (RL) -- but also places
greater emphasis on open-ended resolutions. We aim to address the question:
"Can the o1 model effectively generalize to broader domains where clear
standards are absent and rewards are challenging to quantify?" Marco-o1 is
powered by Chain-of-Thought (CoT) fine-tuning, Monte Carlo Tree Search (MCTS),
reflection mechanisms, and innovative reasoning strategies -- optimized for
complex real-world problem-solving tasks.

摘要：目前，OpenAI o1 在大型推理模型 (LRM) 研究領域引起了極大的興趣。馬可 o1 不僅專注於具有標準答案的學科，例如數學、物理和編碼，這些學科非常適合強化學習 (RL)，還更加強調開放式的解決方案。我們的目標是解決這個問題：「o1 模型是否可以有效地概括到缺乏明確標準且獎勵難以量化的更廣泛領域？」馬可 o1 由思想鏈 (CoT) 微調、蒙地卡羅樹搜尋 (MCTS)、反思機制和創新推理策略提供支援，這些策略經過優化，可用於解決複雜的現實世界問題。

##### **Resolving Multiple-Dynamic Model Uncertainty in Hypothesis-Driven Belief-MDPs**
2411.14404v1 by Ofer Dagan, Tyler Becker, Zachary N. Sunberg

When human operators of cyber-physical systems encounter surprising behavior,
they often consider multiple hypotheses that might explain it. In some cases,
taking information-gathering actions such as additional measurements or control
inputs given to the system can help resolve uncertainty and determine the most
accurate hypothesis. The task of optimizing these actions can be formulated as
a belief-space Markov decision process that we call a hypothesis-driven belief
MDP. Unfortunately, this problem suffers from the curse of history similar to a
partially observable Markov decision process (POMDP). To plan in continuous
domains, an agent needs to reason over countlessly many possible
action-observation histories, each resulting in a different belief over the
unknown state. The problem is exacerbated in the hypothesis-driven context
because each action-observation pair spawns a different belief for each
hypothesis, leading to additional branching. This paper considers the case in
which each hypothesis corresponds to a different dynamic model in an underlying
POMDP. We present a new belief MDP formulation that: (i) enables reasoning over
multiple hypotheses, (ii) balances the goals of determining the (most likely)
correct hypothesis and performing well in the underlying POMDP, and (iii) can
be solved with sparse tree search.

摘要：當網路物理系統的人類操作員遇到令人驚訝的行為時，他們通常會考慮多種假設來解釋它。在某些情況下，採取資訊收集動作（例如額外的量測或給予系統的控制輸入）有助於解決不確定性並確定最準確的假設。最佳化這些動作的任務可以表述為一個信念空間馬可夫決策過程，我們稱之為假設驅動信念 MDP。不幸的是，這個問題與部分可觀察馬可夫決策過程 (POMDP) 類似，會受到歷史詛咒的影響。要在連續領域中規劃，代理需要對無數可能的動作觀察歷史進行推理，每個歷史都會導致對未知狀態的不同信念。這個問題在假設驅動的背景下會更加惡化，因為每對動作觀察會為每個假設產生不同的信念，導致額外的分支。本文考慮了每個假設在基礎 POMDP 中對應於不同動態模型的情況。我們提出一個新的信念 MDP 公式，它：(i) 能夠對多個假設進行推理，(ii) 平衡確定（最可能）正確假設和在基礎 POMDP 中表現良好的目標，以及 (iii) 可以透過稀疏樹搜尋來解決。

##### **Landing Trajectory Prediction for UAS Based on Generative Adversarial Network**
2411.14403v1 by Jun Xiang, Drake Essick, Luiz Gonzalez Bautista, Junfei Xie, Jun Chen

Models for trajectory prediction are an essential component of many advanced
air mobility studies. These models help aircraft detect conflict and plan
avoidance maneuvers, which is especially important in Unmanned Aircraft systems
(UAS) landing management due to the congested airspace near vertiports. In this
paper, we propose a landing trajectory prediction model for UAS based on
Generative Adversarial Network (GAN). The GAN is a prestigious neural network
that has been developed for many years. In previous research, GAN has achieved
many state-of-the-art results in many generation tasks. The GAN consists of one
neural network generator and a neural network discriminator. Because of the
learning capacity of the neural networks, the generator is capable to
understand the features of the sample trajectory. The generator takes the
previous trajectory as input and outputs some random status of a flight.
According to the results of the experiences, the proposed model can output more
accurate predictions than the baseline method(GMR) in various datasets. To
evaluate the proposed model, we also create a real UAV landing dataset that
includes more than 2600 trajectories of drone control manually by real pilots.

摘要：航跡預測模型是許多先進空中流動性研究中不可或缺的組成部分。這些模型有助於飛機偵測衝突並規劃避讓動作，這在無人機系統（UAS）著陸管理中尤其重要，這是因為垂直起降機場附近的空域壅塞。在本文中，我們提出一個基於生成對抗網路（GAN）的 UAS 著陸航跡預測模型。GAN 是一個久負盛名的神經網路，已經發展多年。在先前的研究中，GAN 在許多生成任務中取得許多最先進的成果。GAN 包含一個神經網路產生器和一個神經網路判別器。由於神經網路的學習能力，產生器能夠了解樣本航跡的特徵。產生器將先前的航跡作為輸入，並輸出飛行的某些隨機狀態。根據經驗結果，所提出的模型可以在各種資料集中輸出比基線方法（GMR）更準確的預測。為了評估所提出的模型，我們還建立了一個真實的無人機著陸資料集，其中包含超過 2600 條由真實飛行員手動控制的無人機航跡。

##### **Lightweight Safety Guardrails Using Fine-tuned BERT Embeddings**
2411.14398v1 by Aaron Zheng, Mansi Rana, Andreas Stolcke

With the recent proliferation of large language models (LLMs), enterprises
have been able to rapidly develop proof-of-concepts and prototypes. As a
result, there is a growing need to implement robust guardrails that monitor,
quantize and control an LLM's behavior, ensuring that the use is reliable,
safe, accurate and also aligned with the users' expectations. Previous
approaches for filtering out inappropriate user prompts or system outputs, such
as LlamaGuard and OpenAI's MOD API, have achieved significant success by
fine-tuning existing LLMs. However, using fine-tuned LLMs as guardrails
introduces increased latency and higher maintenance costs, which may not be
practical or scalable for cost-efficient deployments. We take a different
approach, focusing on fine-tuning a lightweight architecture: Sentence-BERT.
This method reduces the model size from LlamaGuard's 7 billion parameters to
approximately 67 million, while maintaining comparable performance on the AEGIS
safety benchmark.

摘要：隨著大型語言模型 (LLM) 的快速擴散，企業已能快速開發概念驗證和原型。因此，越來越需要實施強固的防護措施，以監控、量化和控制 LLM 的行為，確保使用可靠、安全、準確，且符合使用者的預期。先前用於過濾不適當使用者提示或系統輸出的方法，例如 LlamaGuard 和 OpenAI 的 MOD API，已透過微調現有的 LLM 而獲得顯著的成功。然而，使用微調的 LLM 作為防護措施會增加延遲和更高的維護成本，這對於經濟高效的部署而言可能不切實際或無法擴展。我們採用不同的方法，專注於微調輕量級架構：Sentence-BERT。此方法將模型大小從 LlamaGuard 的 70 億個參數減少到約 6,700 萬個，同時在 AEGIS 安全基準上維持相當的效能。

##### **POS-tagging to highlight the skeletal structure of sentences**
2411.14393v1 by Grigorii Churakov

This study presents the development of a part-of-speech (POS) tagging model
to extract the skeletal structure of sentences using transfer learning with the
BERT architecture for token classification. The model, fine-tuned on Russian
text, demonstrating its effectiveness. The approach offers potential
applications in enhancing natural language processing tasks, such as improving
machine translation.
  Keywords: part of speech tagging, morphological analysis, natural language
processing, BERT.

摘要：本研究提出了一個詞性標記模型的開發
使用 BERT 架構進行標記分類，以轉移學習來提取句子的骨架結構。該模型針對俄語文本進行微調，證明了其有效性。此方法提供了增強自然語言處理任務的潛在應用，例如改進機器翻譯。
關鍵字：詞性標記、形態分析、自然語言處理、BERT。

##### **Using Formal Models, Safety Shields and Certified Control to Validate AI-Based Train Systems**
2411.14374v1 by Jan Gruteser, Jan Roßbach, Fabian Vu, Michael Leuschel

The certification of autonomous systems is an important concern in science
and industry. The KI-LOK project explores new methods for certifying and safely
integrating AI components into autonomous trains. We pursued a two-layered
approach: (1) ensuring the safety of the steering system by formal analysis
using the B method, and (2) improving the reliability of the perception system
with a runtime certificate checker. This work links both strategies within a
demonstrator that runs simulations on the formal model, controlled by the real
AI output and the real certificate checker. The demonstrator is integrated into
the validation tool ProB. This enables runtime monitoring, runtime
verification, and statistical validation of formal safety properties using a
formal B model. Consequently, one can detect and analyse potential
vulnerabilities and weaknesses of the AI and the certificate checker. We apply
these techniques to a signal detection case study and present our findings.

摘要：自主系統的認證是科學和產業中的重要課題。KI-LOK 計畫探索用於認證和安全地將 AI 元件整合到自動駕駛火車中的新方法。我們採用了雙層方法：(1) 使用 B 方法透過形式化分析確保轉向系統的安全，以及 (2) 使用執行時期證書檢查器來提升感知系統的可靠性。此項工作在一個示範程式中連結了這兩種策略，在形式化模型上執行模擬，由實際的 AI 輸出和實際的證書檢查器控制。此示範程式整合到驗證工具 ProB 中。這能使用形式化 B 模型進行執行時期監控、執行時期驗證和形式化安全屬性的統計驗證。因此，可以偵測和分析 AI 和證書檢查器的潛在漏洞和弱點。我們將這些技術應用於訊號偵測案例研究，並提出我們的發現。

##### **Synthesising Robust Controllers for Robot Collectives with Recurrent Tasks: A Case Study**
2411.14371v1 by Till Schnittka, Mario Gleirscher

When designing correct-by-construction controllers for autonomous
collectives, three key challenges are the task specification, the modelling,
and its use at practical scale. In this paper, we focus on a simple yet useful
abstraction for high-level controller synthesis for robot collectives with
optimisation goals (e.g., maximum cleanliness, minimum energy consumption) and
recurrence (e.g., re-establish contamination and charge thresholds) and safety
(e.g., avoid full discharge, mutually exclusive room occupation) constraints.
Due to technical limitations (related to scalability and using constraints in
the synthesis), we simplify our graph-based setting from a stochastic
two-player game into a single-player game on a partially observable Markov
decision process (POMDP). Robustness against environmental uncertainty is
encoded via partial observability. Linear-time correctness properties are
verified separately after synthesising the POMDP strategy. We contribute
at-scale guidance on POMDP modelling and controller synthesis for tasked robot
collectives exemplified by the scenario of battery-driven robots responsible
for cleaning public buildings with utilisation constraints.

摘要：在為自主集體設計正確的建構控制器時，有三個主要的挑戰：任務規範、建模，以及在實際規模下的使用。在本文中，我們專注於一個簡單但有用的抽象化，用於具有最佳化目標（例如，最大清潔度、最低能源消耗）和遞迴（例如，重新建立污染和充電閾值）以及安全（例如，避免完全放電、相互排斥的房間佔用）約束的機器人集體的高階控制器合成。由於技術限制（與擴充性和在合成中使用約束有關），我們將基於圖表的設定從隨機雙人遊戲簡化為部分可觀察馬可夫決策過程 (POMDP) 中的單人遊戲。對環境不確定性的魯棒性通過部分可觀察性編碼。線性時間正確性屬性在合成 POMDP 策略後單獨驗證。我們為任務機器人集體的 POMDP 建模和控制器合成提供了大規模指導，這些集體以負責在利用約束下清潔公共建築的電池驅動機器人為例。

##### **Contrasting local and global modeling with machine learning and satellite data: A case study estimating tree canopy height in African savannas**
2411.14354v1 by Esther Rolf, Lucia Gordon, Milind Tambe, Andrew Davies

While advances in machine learning with satellite imagery (SatML) are
facilitating environmental monitoring at a global scale, developing SatML
models that are accurate and useful for local regions remains critical to
understanding and acting on an ever-changing planet. As increasing attention
and resources are being devoted to training SatML models with global data, it
is important to understand when improvements in global models will make it
easier to train or fine-tune models that are accurate in specific regions. To
explore this question, we contrast local and global training paradigms for
SatML through a case study of tree canopy height (TCH) mapping in the Karingani
Game Reserve, Mozambique. We find that recent advances in global TCH mapping do
not necessarily translate to better local modeling abilities in our study
region. Specifically, small models trained only with locally-collected data
outperform published global TCH maps, and even outperform globally pretrained
models that we fine-tune using local data. Analyzing these results further, we
identify specific points of conflict and synergy between local and global
modeling paradigms that can inform future research toward aligning local and
global performance objectives in geospatial machine learning.

摘要：雖然機器學習與衛星影像（SatML）的進展促進了全球環境監測，但開發出對局部地區準確且有用的 SatML 模型對於理解和應對不斷變化的地球仍然至關重要。隨著越來越多的關注和資源投入到使用全球數據訓練 SatML 模型，了解何時全球模型的改進將使訓練或微調特定區域準確的模型變得更容易，這一點非常重要。為了探討這個問題，我們通過莫三比克卡林加尼野生動物保護區的樹冠高度（TCH）製圖案例研究，對比了 SatML 的局部和全球訓練範例。我們發現，全球 TCH 製圖的最新進展並非一定能轉化為我們研究區域中更好的局部建模能力。具體來說，僅使用當地收集的數據訓練的小模型優於已發布的全球 TCH 地圖，甚至優於我們使用當地數據微調的全球預訓練模型。進一步分析這些結果，我們找出了局部和全球建模範例之間衝突和協同作用的具體點，這些點可以為未來的研究提供信息，以調整地理空間機器學習中的局部和全球性能目標。

##### **UnifiedCrawl: Aggregated Common Crawl for Affordable Adaptation of LLMs on Low-Resource Languages**
2411.14343v1 by Bethel Melesse Tessema, Akhil Kedia, Tae-Sun Chung

Large language models (LLMs) under-perform on low-resource languages due to
limited training data. We present a method to efficiently collect text data for
low-resource languages from the entire Common Crawl corpus. Our approach,
UnifiedCrawl, filters and extracts common crawl using minimal compute
resources, yielding mono-lingual datasets much larger than previously available
sources. We demonstrate that leveraging this data to fine-tuning multilingual
LLMs via efficient adapter methods (QLoRA) significantly boosts performance on
the low-resource language, while minimizing VRAM usage. Our experiments show
large improvements in language modeling perplexity and an increase in few-shot
prompting scores. Our work and released source code provide an affordable
approach to improve LLMs for low-resource languages using consumer hardware.
Our source code is available here at
https://github.com/bethelmelesse/unifiedcrawl.

摘要：由於訓練資料有限，大型語言模型 (LLM) 在低資源語言上的表現不佳。我們提出了一種方法，可以從整個 Common Crawl 語料庫中有效地收集低資源語言的文字資料。我們的 UnifiedCrawl 方法使用最少的運算資源來過濾和擷取 Common Crawl，產生比先前可用的來源大得多的單一語言資料集。我們證明利用這些資料微調多語言 LLM，透過有效率的適配器方法 (QLoRA)，可以大幅提升低資源語言的效能，同時將 VRAM 使用量降至最低。我們的實驗顯示，語言模型困惑度大幅改善，且少次提示分數增加。我們的研究和釋出的原始碼提供了一種經濟實惠的方法，可以使用消費者硬體改善低資源語言的 LLM。我們的原始碼可在以下位置取得：https://github.com/bethelmelesse/unifiedcrawl。

##### **Velocitune: A Velocity-based Dynamic Domain Reweighting Method for Continual Pre-training**
2411.14318v1 by Zheheng Luo, Xin Zhang, Xiao Liu, Haoling Li, Yeyun Gong, Chen Qi, Peng Cheng

It is well-known that a diverse corpus is critical for training large
language models, which are typically constructed from a mixture of various
domains. In general, previous efforts resort to sampling training data from
different domains with static proportions, as well as adjusting data
proportions during training. However, few methods have addressed the
complexities of domain-adaptive continual pre-training. To fill this gap, we
propose Velocitune, a novel framework dynamically assesses learning velocity
and adjusts data proportions accordingly, favoring slower-learning domains
while shunning faster-learning ones, which is guided by a scaling law to
indicate the desired learning goal for each domain with less associated cost.
To evaluate the effectiveness of Velocitune, we conduct experiments in a
reasoning-focused dataset with CodeLlama, as well as in a corpus specialised
for system command generation with Llama3 and Mistral. Velocitune achieves
performance gains in both math and code reasoning tasks and command-line
generation benchmarks. Further analysis reveals that key factors driving
Velocitune's effectiveness include target loss prediction and data ordering.

摘要：众所周知，多样化的语料库对于训练大型语言模型至关重要，而大型语言模型通常由来自不同领域的数据混合构建而成。一般来说，之前的研究诉诸于以静态比例从不同领域采样训练数据，以及在训练期间调整数据比例。然而，很少有方法解决域自适应持续预训练的复杂性。为了填补这一空白，我们提出了 Velocitune，这是一个新颖的框架，可以动态评估学习速度并相应地调整数据比例，偏爱学习较慢的领域，同时回避学习较快的领域，这由一个比例定律指导，以较低的相关成本为每个领域指示所需的学习目标。为了评估 Velocitune 的有效性，我们在一个以推理为重点的数据集中使用 CodeLlama 进行了实验，以及在一个专门用于使用 Llama3 和 Mistral 生成系统命令的语料库中进行了实验。Velocitune 在数学和代码推理任务以及命令行生成基准测试中都取得了性能提升。进一步的分析表明，推动 Velocitune 有效性的关键因素包括目标损失预测和数据排序。

##### **Automated Generation of Code Debugging Exercises**
2411.14303v1 by Victor-Alexandru Pădurean, Paul Denny, Adish Singla

Debugging is an essential skill when learning to program, yet its instruction
and emphasis often vary widely across introductory courses. In the era of
code-generating large language models (LLMs), the ability for students to
reason about code and identify errors is increasingly important. However,
students frequently resort to trial-and-error methods to resolve bugs without
fully understanding the underlying issues. Developing the ability to identify
and hypothesize the cause of bugs is crucial but can be time-consuming to teach
effectively through traditional means. This paper introduces BugSpotter, an
innovative tool that leverages an LLM to generate buggy code from a problem
description and verify the synthesized bugs via a test suite. Students interact
with BugSpotter by designing failing test cases, where the buggy code's output
differs from the expected result as defined by the problem specification. This
not only provides opportunities for students to enhance their debugging skills,
but also to practice reading and understanding problem specifications. We
deployed BugSpotter in a large classroom setting and compared the debugging
exercises it generated to exercises hand-crafted by an instructor for the same
problems. We found that the LLM-generated exercises produced by BugSpotter
varied in difficulty and were well-matched to the problem specifications.
Importantly, the LLM-generated exercises were comparable to those manually
created by instructors with respect to student performance, suggesting that
BugSpotter could be an effective and efficient aid for learning debugging.

摘要：<paragraph>除錯是學習程式設計時必備的技能，但其教學和重點在各入門課程中往往差異很大。在產生程式碼的大型語言模型（LLM）的時代，學生推理程式碼和找出錯誤的能力越來越重要。然而，學生常常訴諸試錯法來解決錯誤，而沒有完全理解其背後的根本問題。培養找出錯誤並對其成因提出假設的能力至關重要，但透過傳統方式有效地教授這項能力可能很耗時。本文介紹了 BugSpotter，這是一個創新的工具，它利用 LLM 從問題描述中產生有錯誤的程式碼，並透過測試套件驗證合成的錯誤。學生透過設計失敗的測試案例與 BugSpotter 互動，其中有錯誤的程式碼輸出與問題規格所定義的預期結果不同。這不僅能提供學生增進其除錯技能的機會，還能練習閱讀和理解問題規格。我們在一個大型教室環境中部署了 BugSpotter，並將其產生的除錯練習與由教師親自為相同問題設計的練習進行比較。我們發現，BugSpotter 產生的 LLM 練習難度不一，且與問題規格十分相符。重要的是，LLM 產生的練習在學生表現方面與人工產生的練習相當，這表明 BugSpotter 可能是學習除錯的有效且高效的輔助工具。</paragraph>

##### **Looking Beyond Text: Reducing Language bias in Large Vision-Language Models via Multimodal Dual-Attention and Soft-Image Guidance**
2411.14279v1 by Haozhe Zhao, Shuzheng Si, Liang Chen, Yichi Zhang, Maosong Sun, Mingjia Zhang, Baobao Chang

Large vision-language models (LVLMs) have achieved impressive results in
various vision-language tasks. However, despite showing promising performance,
LVLMs suffer from hallucinations caused by language bias, leading to diminished
focus on images and ineffective visual comprehension. We identify two primary
reasons for this bias: 1. Different scales of training data between the
pretraining stage of LLM and multimodal alignment stage. 2. The learned
inference bias due to short-term dependency of text data. Therefore, we propose
LACING, a systemic framework designed to address the language bias of LVLMs
with muLtimodal duAl-attention meChanIsm (MDA) aNd soft-image Guidance (IFG).
Specifically, MDA introduces a parallel dual-attention mechanism that enhances
the integration of visual inputs across the model. IFG introduces a learnable
soft visual prompt during training and inference to replace visual inputs,
designed to compel LVLMs to prioritize text inputs. Then, IFG further proposes
a novel decoding strategy using the soft visual prompt to mitigate the model's
over-reliance on adjacent text inputs. Comprehensive experiments demonstrate
that our method effectively debiases LVLMs from their language bias, enhancing
visual comprehension and reducing hallucinations without requiring additional
training resources or data. The code and model are available at
[lacing-lvlm.github.io](https://lacing-lvlm.github.io).

摘要：大型視覺語言模型 (LVLMs) 已在各種視覺語言任務中取得令人印象深刻的成果。然而，儘管表現出令人滿意的效能，LVLMs 仍會因語言偏誤而產生幻覺，導致對影像的關注度降低和視覺理解力不佳。我們找出造成這種偏誤的兩個主要原因：1. LLM 預訓練階段與多模態對齊階段的訓練資料規模不同。2. 由於文字資料的短期依賴性所產生的學習推論偏誤。因此，我們提出 LACING，一個系統性框架，旨在透過多模態雙注意力機制 (MDA) 和軟影像引導 (IFG) 來解決 LVLMs 的語言偏誤。具體來說，MDA 引入一個平行的雙注意力機制，增強模型中視覺輸入的整合。IFG 在訓練和推論期間引入一個可學習的軟視覺提示，以取代視覺輸入，旨在迫使 LVLMs 優先考慮文字輸入。然後，IFG 進一步提出一個新的解碼策略，使用軟視覺提示來減輕模型對相鄰文字輸入的過度依賴。全面的實驗證明，我們的模型有效地消除了 LVLMs 的語言偏誤，增強了視覺理解力，並減少了幻覺，而不需要額外的訓練資源或資料。程式碼和模型可在 [lacing-lvlm.github.io](https://lacing-lvlm.github.io) 取得。

##### **Neuro-Symbolic Query Optimization in Knowledge Graphs**
2411.14277v1 by Maribel Acosta, Chang Qin, Tim Schwabe

This chapter delves into the emerging field of neuro-symbolic query
optimization for knowledge graphs (KGs), presenting a comprehensive exploration
of how neural and symbolic techniques can be integrated to enhance query
processing. Traditional query optimizers in knowledge graphs rely heavily on
symbolic methods, utilizing dataset summaries, statistics, and cost models to
select efficient execution plans. However, these approaches often suffer from
misestimations and inaccuracies, particularly when dealing with complex queries
or large-scale datasets. Recent advancements have introduced neural models,
which capture non-linear aspects of query optimization, offering promising
alternatives to purely symbolic methods. In this chapter, we introduce
neuro-symbolic query optimizers, a novel approach that combines the strengths
of symbolic reasoning with the adaptability of neural computation. We discuss
the architecture of these hybrid systems, highlighting the interplay between
neural and symbolic components to improve the optimizer's ability to navigate
the search space and produce efficient execution plans. Additionally, the
chapter reviews existing neural components tailored for optimizing queries over
knowledge graphs and examines the limitations and challenges in deploying
neuro-symbolic query optimizers in real-world environments.

摘要：本章深入探討知識圖譜 (KG) 的新興領域神經符號查詢最佳化，全面探討如何整合神經和符號技術以增強查詢處理。知識圖譜中的傳統查詢最佳化器高度依賴符號方法，利用資料集摘要、統計資料和成本模型來選擇有效率的執行計畫。然而，這些方法通常會產生錯誤估計和不準確的結果，特別是在處理複雜查詢或大型資料集時。最近的進展引入了神經模型，它能捕捉查詢最佳化的非線性面向，提供純粹符號方法的有希望的替代方案。在本章中，我們介紹神經符號查詢最佳化器，這是一種新穎的方法，結合符號推理的優點和神經運算的適應性。我們討論這些混合系統的架構，強調神經和符號元件之間的交互作用，以提高最佳化器導航搜尋空間和產生有效率執行計畫的能力。此外，本章回顧了針對最佳化知識圖譜查詢而量身打造的現有神經元件，並探討在現實環境中部署神經符號查詢最佳化器的限制和挑戰。

##### **Efficient Aspect-Based Summarization of Climate Change Reports with Small Language Models**
2411.14272v1 by Iacopo Ghinassi, Leonardo Catalano, Tommaso Colella

The use of Natural Language Processing (NLP) for helping decision-makers with
Climate Change action has recently been highlighted as a use case aligning with
a broader drive towards NLP technologies for social good. In this context,
Aspect-Based Summarization (ABS) systems that extract and summarize relevant
information are particularly useful as they provide stakeholders with a
convenient way of finding relevant information in expert-curated reports. In
this work, we release a new dataset for ABS of Climate Change reports and we
employ different Large Language Models (LLMs) and so-called Small Language
Models (SLMs) to tackle this problem in an unsupervised way. Considering the
problem at hand, we also show how SLMs are not significantly worse for the
problem while leading to reduced carbon footprint; we do so by applying for the
first time an existing framework considering both energy efficiency and task
performance to the evaluation of zero-shot generative models for ABS. Overall,
our results show that modern language models, both big and small, can
effectively tackle ABS for Climate Change reports but more research is needed
when we frame the problem as a Retrieval Augmented Generation (RAG) problem and
our work and dataset will help foster efforts in this direction.

摘要：自然語言處理 (NLP) 用於協助決策者採取氣候變遷行動，最近被強調為與更廣泛推動 NLP 技術用於社會公益的用例一致。在此背景下，擷取和摘要相關資訊的面向面向摘要 (ABS) 系統特別有用，因為它們為利害關係人提供一種便利的方式，可以在專家策劃的報告中找到相關資訊。在這項工作中，我們發布了一個新的 ABS 氣候變遷報告資料集，並且我們使用不同的大型語言模型 (LLM) 和所謂的小型語言模型 (SLM) 以無監督的方式來解決這個問題。考量手邊的問題，我們也展示了 SLM 對於這個問題並未顯著惡化，同時導致碳足跡減少；我們這樣做是首次應用現有架構，考量能源效率和任務效能來評估 ABS 的零次學習生成模型。整體而言，我們的結果顯示，無論大小，現代語言模型都能有效處理氣候變遷報告的 ABS，但當我們將問題設定為檢索擴充生成 (RAG) 問題時，需要更多研究，而我們的研究和資料集將有助於促進朝此方向的努力。

##### **Generating Realistic Adversarial Examples for Business Processes using Variational Autoencoders**
2411.14263v1 by Alexander Stevens, Jari Peeperkorn, Johannes De Smedt, Jochen De Weerdt

In predictive process monitoring, predictive models are vulnerable to
adversarial attacks, where input perturbations can lead to incorrect
predictions. Unlike in computer vision, where these perturbations are designed
to be imperceptible to the human eye, the generation of adversarial examples in
predictive process monitoring poses unique challenges. Minor changes to the
activity sequences can create improbable or even impossible scenarios to occur
due to underlying constraints such as regulatory rules or process constraints.
To address this, we focus on generating realistic adversarial examples tailored
to the business process context, in contrast to the imperceptible, pixel-level
changes commonly seen in computer vision adversarial attacks. This paper
introduces two novel latent space attacks, which generate adversaries by adding
noise to the latent space representation of the input data, rather than
directly modifying the input attributes. These latent space methods are
domain-agnostic and do not rely on process-specific knowledge, as we restrict
the generation of adversarial examples to the learned class-specific data
distributions by directly perturbing the latent space representation of the
business process executions. We evaluate these two latent space methods with
six other adversarial attacking methods on eleven real-life event logs and four
predictive models. The first three attacking methods directly permute the
activities of the historically observed business process executions. The fourth
method constrains the adversarial examples to lie within the same data
distribution as the original instances, by projecting the adversarial examples
to the original data distribution.

摘要：在预测过程监控中，预测模型容易受到对抗性攻击，输入扰动可能导致预测不正确。与计算机视觉中这些扰动被设计为对人眼不可察觉不同，在预测过程监控中生成对抗性示例提出了独特的挑战。由于法规规则或过程约束等基本约束，活动序列的微小变化可能会产生不可能甚至不可能发生的场景。为了解决这个问题，我们专注于生成针对业务流程上下文的现实对抗性示例，这与计算机视觉对抗性攻击中常见的不可察觉的像素级变化形成对比。本文介绍了两种新颖的潜在空间攻击，它们通过向输入数据的潜在空间表示添加噪声来生成对抗者，而不是直接修改输入属性。这些潜在空间方法与域无关，并且不依赖于特定于过程的知识，因为我们将对抗性示例的生成限制在学习的特定于类的分布数据上，通过直接扰动业务流程执行的潜在空间表示。我们使用六种其他对抗性攻击方法在十一个真实事件日志和四个预测模型上评估了这两种潜在空间方法。前三种攻击方法直接排列历史观察到的业务流程执行的活动。第四种方法通过将对抗性示例投影到原始数据分布，将对抗性示例限制在与原始实例相同的分布中。

##### **Knowledge Graphs, Large Language Models, and Hallucinations: An NLP Perspective**
2411.14258v1 by Ernests Lavrinovics, Russa Biswas, Johannes Bjerva, Katja Hose

Large Language Models (LLMs) have revolutionized Natural Language Processing
(NLP) based applications including automated text generation, question
answering, chatbots, and others. However, they face a significant challenge:
hallucinations, where models produce plausible-sounding but factually incorrect
responses. This undermines trust and limits the applicability of LLMs in
different domains. Knowledge Graphs (KGs), on the other hand, provide a
structured collection of interconnected facts represented as entities (nodes)
and their relationships (edges). In recent research, KGs have been leveraged to
provide context that can fill gaps in an LLM understanding of certain topics
offering a promising approach to mitigate hallucinations in LLMs, enhancing
their reliability and accuracy while benefiting from their wide applicability.
Nonetheless, it is still a very active area of research with various unresolved
open problems. In this paper, we discuss these open challenges covering
state-of-the-art datasets and benchmarks as well as methods for knowledge
integration and evaluating hallucinations. In our discussion, we consider the
current use of KGs in LLM systems and identify future directions within each of
these challenges.

摘要：大型語言模型（LLM）徹底改變了基於自然語言處理（NLP）的應用，包括自動文字生成、問題解答、聊天機器人等。然而，它們面臨著一個重大的挑戰：幻覺，模型產生聽起來合理但事實上不正確的回應。這會破壞信任，並限制 LLM 在不同領域的適用性。另一方面，知識圖譜（KG）提供了以實體（節點）及其關係（邊緣）表示的相互連接事實的結構化集合。在最近的研究中，KG 已被用於提供上下文，可以填補 LLM 對某些主題理解的空白，提供了一種有希望的方法來減輕 LLM 中的幻覺，提高它們的可靠性和準確性，同時受益於它們的廣泛適用性。儘管如此，這仍然是一個非常活躍的研究領域，有各種未解決的開放問題。在本文中，我們討論了這些開放挑戰，涵蓋了最先進的數據集和基準，以及知識整合和評估幻覺的方法。在我們的討論中，我們考慮了 LLM 系統中 KG 的當前使用，並確定了這些挑戰中的每一個未來的方向。

##### **Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models**
2411.14257v1 by Javier Ferrando, Oscar Obeso, Senthooran Rajamanoharan, Neel Nanda

Hallucinations in large language models are a widespread problem, yet the
mechanisms behind whether models will hallucinate are poorly understood,
limiting our ability to solve this problem. Using sparse autoencoders as an
interpretability tool, we discover that a key part of these mechanisms is
entity recognition, where the model detects if an entity is one it can recall
facts about. Sparse autoencoders uncover meaningful directions in the
representation space, these detect whether the model recognizes an entity, e.g.
detecting it doesn't know about an athlete or a movie. This suggests that
models can have self-knowledge: internal representations about their own
capabilities. These directions are causally relevant: capable of steering the
model to refuse to answer questions about known entities, or to hallucinate
attributes of unknown entities when it would otherwise refuse. We demonstrate
that despite the sparse autoencoders being trained on the base model, these
directions have a causal effect on the chat model's refusal behavior,
suggesting that chat finetuning has repurposed this existing mechanism.
Furthermore, we provide an initial exploration into the mechanistic role of
these directions in the model, finding that they disrupt the attention of
downstream heads that typically move entity attributes to the final token.

摘要：大型语言模型中的幻觉是一个普遍的问题，但模型是否会产生幻觉背后的机制却鲜为人知，这限制了我们解决这一问题的能力。使用稀疏自动编码器作为可解释性工具，我们发现这些机制的关键部分是实体识别，其中模型检测实体是否是可以回忆事实的实体。稀疏自动编码器揭示了表示空间中的有意义的方向，这些方向检测模型是否识别实体，例如检测到它不知道运动员或电影。这表明模型可以自我认知：关于自身能力的内部表征。这些方向具有因果相关性：能够引导模型拒绝回答有关已知实体的问题，或在它原本会拒绝的情况下对未知实体的属性产生幻觉。我们证明，尽管稀疏自动编码器是在基础模型上训练的，但这些方向对聊天模型的拒绝行为有因果关系，这表明聊天微调已经重新利用了这种现有机制。此外，我们对这些方向在模型中的机制作用进行了初步探索，发现它们破坏了下游头的注意力，而下游头通常将实体属性移动到最终标记。

##### **BERT-Based Approach for Automating Course Articulation Matrix Construction with Explainable AI**
2411.14254v1 by Natenaile Asmamaw Shiferaw, Simpenzwe Honore Leandre, Aman Sinha, Dillip Rout

Course Outcome (CO) and Program Outcome (PO)/Program-Specific Outcome (PSO)
alignment is a crucial task for ensuring curriculum coherence and assessing
educational effectiveness. The construction of a Course Articulation Matrix
(CAM), which quantifies the relationship between COs and POs/PSOs, typically
involves assigning numerical values (0, 1, 2, 3) to represent the degree of
alignment. In this study, We experiment with four models from the BERT family:
BERT Base, DistilBERT, ALBERT, and RoBERTa, and use multiclass classification
to assess the alignment between CO and PO/PSO pairs. We first evaluate
traditional machine learning classifiers, such as Decision Tree, Random Forest,
and XGBoost, and then apply transfer learning to evaluate the performance of
the pretrained BERT models. To enhance model interpretability, we apply
Explainable AI technique, specifically Local Interpretable Model-agnostic
Explanations (LIME), to provide transparency into the decision-making process.
Our system achieves accuracy, precision, recall, and F1-score values of 98.66%,
98.67%, 98.66%, and 98.66%, respectively. This work demonstrates the potential
of utilizing transfer learning with BERT-based models for the automated
generation of CAMs, offering high performance and interpretability in
educational outcome assessment.

摘要：課程成果 (CO) 與計畫成果 (PO)/計畫特定成果 (PSO)
對齊對於確保課程架構一致性及評量教育成效至關重要。課程關聯矩陣 (CAM) 的建構量化 CO 與 PO/PSO 之間的關係，通常
會指派數值 (0、1、2、3) 來表示對齊程度。在本研究中，我們實驗 BERT 家族中的四個模型：BERT Base、DistilBERT、ALBERT 和 RoBERTa，並使用多類別分類來評估 CO 和 PO/PSO 成對之間的對齊。我們首先評估傳統機器學習分類器，例如決策樹、隨機森林，
以及 XGBoost，然後應用遷移學習來評估預訓練 BERT 模型的效能。為了增強模型可解釋性，我們應用可解釋 AI 技術，特別是局部可解釋模型不可知解釋 (LIME)，以提供決策制定過程的透明度。
我們的系統達到準確率、精準度、召回率和 F1 分數值分別為 98.66%、98.67%、98.66% 和 98.66%。這項工作展示了利用遷移學習與 BERT 為基礎的模型進行 CAM 自動產生的潛力，在教育成果評量中提供高性能和可解釋性。

##### **Intent-Aware Dialogue Generation and Multi-Task Contrastive Learning for Multi-Turn Intent Classification**
2411.14252v1 by Junhua Liu, Yong Keat Tan, Bin Fu, Kwan Hui Lim

Generating large-scale, domain-specific, multilingual multi-turn dialogue
datasets remains a significant hurdle for training effective Multi-Turn Intent
Classification models in chatbot systems. In this paper, we introduce
Chain-of-Intent, a novel mechanism that combines Hidden Markov Models with
Large Language Models (LLMs) to generate contextually aware, intent-driven
conversations through self-play. By extracting domain-specific knowledge from
e-commerce chat logs, we estimate conversation turns and intent transitions,
which guide the generation of coherent dialogues. Leveraging LLMs to enhance
emission probabilities, our approach produces natural and contextually
consistent questions and answers. We also propose MINT-CL, a framework for
multi-turn intent classification using multi-task contrastive learning,
improving classification accuracy without the need for extensive annotated
data. Evaluations show that our methods outperform baselines in dialogue
quality and intent classification accuracy, especially in multilingual
settings, while significantly reducing data generation efforts. Furthermore, we
release MINT-E, a multilingual, intent-aware multi-turn e-commerce dialogue
corpus to support future research in this area.

摘要：生成大规模、特定领域、多语言的多轮对话数据集对于训练聊天机器人系统中的有效多轮意图分类模型仍然是一个重大障碍。在本文中，我们介绍了意图链，这是一种将隐马尔可夫模型与大语言模型 (LLM) 相结合的新机制，通过自博弈生成上下文感知、意图驱动的对话。通过从电子商务聊天记录中提取特定领域的知识，我们估计对话轮次和意图转换，从而指导生成连贯的对话。利用 LLM 来提高发射概率，我们的方法产生了自然且在上下文上一致的问题和答案。我们还提出了 MINT-CL，一个用于多任务对比学习的多轮意图分类框架，提高了分类准确性，而无需大量注释数据。评估表明，我们的方法在对话质量和意图分类准确性方面优于基准，特别是在多语言环境中，同时显着减少了数据生成工作。此外，我们发布了 MINT-E，这是一个多语言、意图感知的多轮电子商务对话语料库，以支持该领域的未来研究。

##### **Natural Language Reinforcement Learning**
2411.14251v1 by Xidong Feng, Ziyu Wan, Haotian Fu, Bo Liu, Mengyue Yang, Girish A. Koushik, Zhiyuan Hu, Ying Wen, Jun Wang

Reinforcement Learning (RL) mathematically formulates decision-making with
Markov Decision Process (MDP). With MDPs, researchers have achieved remarkable
breakthroughs across various domains, including games, robotics, and language
models. This paper seeks a new possibility, Natural Language Reinforcement
Learning (NLRL), by extending traditional MDP to natural language-based
representation space. Specifically, NLRL innovatively redefines RL principles,
including task objectives, policy, value function, Bellman equation, and policy
iteration, into their language counterparts. With recent advancements in large
language models (LLMs), NLRL can be practically implemented to achieve RL-like
policy and value improvement by either pure prompting or gradient-based
training. Experiments over Maze, Breakthrough, and Tic-Tac-Toe games
demonstrate the effectiveness, efficiency, and interpretability of the NLRL
framework among diverse use cases. Our code will be released at
https://github.com/waterhorse1/Natural-language-RL.

摘要：強化學習（RL）以馬可夫決策過程（MDP）數學化制定決策。透過 MDP，研究人員在各種領域（包括遊戲、機器人和語言模型）取得顯著突破。本文探討一種新的可能性，自然語言強化學習（NLRL），方法是將傳統的 MDP 擴展到基於自然語言的表示空間。具體來說，NLRL 創新地將 RL 原理（包括任務目標、策略、價值函數、貝爾曼方程式和策略迭代）重新定義為它們的語言對應物。隨著大型語言模型（LLM）的最新進展，NLRL 可以實際實作，藉由純粹提示或基於梯度的訓練來達成類 RL 的策略和價值改善。在迷宮、突破和井字遊戲的實驗證明了 NLRL 架構在各種使用案例中的有效性、效率和可解釋性。我們的程式碼將在 https://github.com/waterhorse1/Natural-language-RL 發布。

##### **AnywhereDoor: Multi-Target Backdoor Attacks on Object Detection**
2411.14243v1 by Jialin Lu, Junjie Shan, Ziqi Zhao, Ka-Ho Chow

As object detection becomes integral to many safety-critical applications,
understanding its vulnerabilities is essential. Backdoor attacks, in
particular, pose a significant threat by implanting hidden backdoor in a victim
model, which adversaries can later exploit to trigger malicious behaviors
during inference. However, current backdoor techniques are limited to static
scenarios where attackers must define a malicious objective before training,
locking the attack into a predetermined action without inference-time
adaptability. Given the expressive output space in object detection, including
object existence detection, bounding box estimation, and object classification,
the feasibility of implanting a backdoor that provides inference-time control
with a high degree of freedom remains unexplored. This paper introduces
AnywhereDoor, a flexible backdoor attack tailored for object detection. Once
implanted, AnywhereDoor enables adversaries to specify different attack types
(object vanishing, fabrication, or misclassification) and configurations
(untargeted or targeted with specific classes) to dynamically control detection
behavior. This flexibility is achieved through three key innovations: (i)
objective disentanglement to support a broader range of attack combinations
well beyond what existing methods allow; (ii) trigger mosaicking to ensure
backdoor activations are robust, even against those object detectors that
extract localized regions from the input image for recognition; and (iii)
strategic batching to address object-level data imbalances that otherwise
hinders a balanced manipulation. Extensive experiments demonstrate that
AnywhereDoor provides attackers with a high degree of control, achieving an
attack success rate improvement of nearly 80% compared to adaptations of
existing methods for such flexible control.

摘要：隨著目標偵測逐漸成為許多安全關鍵應用程式中不可或缺的一部分，了解其漏洞至關重要。後門攻擊尤其會構成重大威脅，它會在受害者模型中植入隱藏的後門，而對手之後可以利用它在推論期間觸發惡意行為。然而，目前的後門技術僅限於靜態場景，其中攻擊者必須在訓練前定義惡意目標，將攻擊鎖定在預先決定的動作中，而沒有推論時間的適應性。考量到目標偵測中具有表現力的輸出空間，包括目標存在偵測、邊界框估計和目標分類，植入後門以提供推論時間控制並具備高度自由度的可行性仍未被探索。本文介紹了 AnywhereDoor，這是一種針對目標偵測量身打造的靈活後門攻擊。一旦植入，AnywhereDoor 便能讓對手指定不同的攻擊類型（目標消失、偽造或誤分類）和組態（未鎖定目標或鎖定特定類別），以動態控制偵測行為。這種靈活性是透過三項關鍵創新實現的：(i) 目標解開，以支援比現有方法允許的範圍更廣的攻擊組合；(ii) 觸發馬賽克，以確保後門啟動具有穩健性，即使針對那些從輸入影像中擷取局部區域以進行辨識的目標偵測器也是如此；以及 (iii) 策略性批次處理，以解決物件層級資料不平衡的問題，否則會妨礙平衡操作。廣泛的實驗證明，與現有方法的改編相比，AnywhereDoor 為攻擊者提供了高度的控制，實現了近 80% 的攻擊成功率提升，以實現這種靈活控制。

##### **Towards Context-Rich Automated Biodiversity Assessments: Deriving AI-Powered Insights from Camera Trap Data**
2411.14219v1 by Paul Fergus, Carl Chalmers, Naomi Matthews, Stuart Nixon, Andre Burger, Oliver Hartley, Chris Sutherland, Xavier Lambin, Steven Longmore, Serge Wich

Camera traps offer enormous new opportunities in ecological studies, but
current automated image analysis methods often lack the contextual richness
needed to support impactful conservation outcomes. Here we present an
integrated approach that combines deep learning-based vision and language
models to improve ecological reporting using data from camera traps. We
introduce a two-stage system: YOLOv10-X to localise and classify species
(mammals and birds) within images, and a Phi-3.5-vision-instruct model to read
YOLOv10-X binding box labels to identify species, overcoming its limitation
with hard to classify objects in images. Additionally, Phi-3.5 detects broader
variables, such as vegetation type, and time of day, providing rich ecological
and environmental context to YOLO's species detection output. When combined,
this output is processed by the model's natural language system to answer
complex queries, and retrieval-augmented generation (RAG) is employed to enrich
responses with external information, like species weight and IUCN status
(information that cannot be obtained through direct visual analysis). This
information is used to automatically generate structured reports, providing
biodiversity stakeholders with deeper insights into, for example, species
abundance, distribution, animal behaviour, and habitat selection. Our approach
delivers contextually rich narratives that aid in wildlife management
decisions. By providing contextually rich insights, our approach not only
reduces manual effort but also supports timely decision-making in conservation,
potentially shifting efforts from reactive to proactive management.

摘要：相機陷阱在生態研究中提供了新的龐大機會，但目前的自動化影像分析方法通常缺乏支持有影響力的保育成果所需的豐富脈絡。在此，我們提出一個整合方法，結合基於深度學習的視覺和語言模型，以使用相機陷阱的資料改善生態報告。我們引入一個兩階段系統：YOLOv10-X 用於定位和分類影像中的物種（哺乳動物和鳥類），以及 Phi-3.5-vision-instruct 模型用於讀取 YOLOv10-X 繫結框標籤以識別物種，克服其在影像中難以分類物體的限制。此外，Phi-3.5 可偵測更廣泛的變數，例如植被類型和時間，為 YOLO 的物種偵測輸出提供豐富的生態和環境脈絡。結合後，此輸出會由模型的自然語言系統處理以回答複雜的查詢，並採用檢索增強生成（RAG）來使用外部資訊（例如物種重量和 IUCN 狀態，這些資訊無法透過直接視覺分析取得）豐富回應。這些資訊用於自動產生結構化報告，為生物多樣性利益相關者提供更深入的見解，例如物種豐富度、分佈、動物行為和棲息地選擇。我們的做法提供有助於野生動物管理決策的豐富脈絡敘述。透過提供豐富的脈絡見解，我們的做法不僅減少手動工作，還支援保育中的及時決策制定，潛在地將工作從被動管理轉移到主動管理。

##### **Evaluating the Robustness of Analogical Reasoning in Large Language Models**
2411.14215v1 by Martha Lewis, Melanie Mitchell

LLMs have performed well on several reasoning benchmarks, including ones that
test analogical reasoning abilities. However, there is debate on the extent to
which they are performing general abstract reasoning versus employing
non-robust processes, e.g., that overly rely on similarity to pre-training
data. Here we investigate the robustness of analogy-making abilities previously
claimed for LLMs on three of four domains studied by Webb, Holyoak, and Lu
(2023): letter-string analogies, digit matrices, and story analogies. For each
domain we test humans and GPT models on robustness to variants of the original
analogy problems that test the same abstract reasoning abilities but are likely
dissimilar from tasks in the pre-training data. The performance of a system
that uses robust abstract reasoning should not decline substantially on these
variants.
  On simple letter-string analogies, we find that while the performance of
humans remains high for two types of variants we tested, the GPT models'
performance declines sharply. This pattern is less pronounced as the complexity
of these problems is increased, as both humans and GPT models perform poorly on
both the original and variant problems requiring more complex analogies. On
digit-matrix problems, we find a similar pattern but only on one out of the two
types of variants we tested. On story-based analogy problems, we find that,
unlike humans, the performance of GPT models are susceptible to answer-order
effects, and that GPT models also may be more sensitive than humans to
paraphrasing.
  This work provides evidence that LLMs often lack the robustness of zero-shot
human analogy-making, exhibiting brittleness on most of the variations we
tested. More generally, this work points to the importance of carefully
evaluating AI systems not only for accuracy but also robustness when testing
their cognitive capabilities.

摘要：<paragraph>LLM 在許多推理基準上表現良好，包括測試類比推理能力的基準。然而，對於它們執行一般抽象推理的程度，與採用非穩健的程序（例如過度依賴與預訓練資料的相似性）之間的爭論不休。在此，我們探討了 Webb、Holyoak 和 Lu（2023 年）研究的四個領域中，LLM 先前聲稱的類比建構能力的穩健性：字母串類比、數字矩陣和故事類比。對於每個領域，我們針對人類和 GPT 模型測試其對原始類比問題變體的穩健性，這些變體測試了相同的抽象推理能力，但可能與預訓練資料中的任務不同。使用穩健抽象推理的系統，在這些變體上的表現不應大幅下降。
在簡單的字母串類比中，我們發現雖然人類的表現對於我們測試的兩種變體類型仍然很高，但 GPT 模型的表現急劇下降。隨著這些問題的複雜性增加，這種模式不太明顯，因為人類和 GPT 模型在需要更複雜類比的原始問題和變體問題上表現都很差。在數字矩陣問題中，我們發現類似的模式，但僅出現在我們測試的兩種變體類型中的一種。在基於故事的類比問題中，我們發現與人類不同，GPT 模型的表現容易受到答案順序效應的影響，而且 GPT 模型也可能比人類對同義改寫更敏感。
這項工作提供了證據，證明 LLM 通常缺乏零次學習人類類比建構的穩健性，在我們測試的大多數變體上表現出脆弱性。更一般地說，這項工作指出在測試 AI 系統的認知能力時，不僅要仔細評估其準確性，還要評估其穩健性的重要性。</paragraph>

##### **Physics-Informed LLM-Agent for Automated Modulation Design in Power Electronics Systems**
2411.14214v1 by Junhua Liu, Fanfan Lin, Xinze Li, Kwan Hui Lim, Shuai Zhao

LLM-based autonomous agents have demonstrated outstanding performance in
solving complex industrial tasks. However, in the pursuit of carbon neutrality
and high-performance renewable energy systems, existing AI-assisted design
automation faces significant limitations in explainability, scalability, and
usability. To address these challenges, we propose LP-COMDA, an LLM-based,
physics-informed autonomous agent that automates the modulation design of power
converters in Power Electronics Systems with minimal human supervision. Unlike
traditional AI-assisted approaches, LP-COMDA contains an LLM-based planner that
gathers and validates design specifications through a user-friendly chat
interface. The planner then coordinates with physics-informed design and
optimization tools to iteratively generate and refine modulation designs
autonomously. Through the chat interface, LP-COMDA provides an explainable
design process, presenting explanations and charts. Experiments show that
LP-COMDA outperforms all baseline methods, achieving a 63.2% reduction in error
compared to the second-best benchmark method in terms of standard mean absolute
error. Furthermore, empirical studies with 20 experts conclude that design time
with LP-COMDA is over 33 times faster than conventional methods, showing its
significant improvement on design efficiency over the current processes.

摘要：基於 LLM 的自主代理已在解決複雜的產業任務方面展現出色的效能。然而，在追求碳中和和高性能再生能源系統的過程中，現有的 AI 輔助設計自動化在可解釋性、可擴充性和可用性方面面臨重大限制。為了應對這些挑戰，我們提出 LP-COMDA，這是一種基於 LLM、以物理為基礎的自主代理，它自動化了電力電子系統中功率轉換器的調變設計，並將人為監督減至最低。與傳統的 AI 輔助方法不同，LP-COMDA 包含一個基於 LLM 的規劃器，它透過使用者友善的聊天介面收集並驗證設計規範。然後，規劃器與以物理為基礎的設計和最佳化工具協調，以自主方式反覆生成並改善調變設計。透過聊天介面，LP-COMDA 提供可解釋的設計流程，並提供說明和圖表。實驗顯示，LP-COMDA 優於所有基線方法，在標準平均絕對誤差方面，與第二好的基準方法相比，誤差減少了 63.2%。此外，與 20 位專家的實證研究得出，使用 LP-COMDA 的設計時間比傳統方法快了 33 倍以上，顯示出它對當前流程的設計效率有顯著的改善。

##### **HARP: A Large-Scale Higher-Order Ambisonic Room Impulse Response Dataset**
2411.14207v1 by Shivam Saini, Jürgen Peissig

This contribution introduces a dataset of 7th-order Ambisonic Room Impulse
Responses (HOA-RIRs), created using the Image Source Method. By employing
higher-order Ambisonics, our dataset enables precise spatial audio
reproduction, a critical requirement for realistic immersive audio
applications. Leveraging the virtual simulation, we present a unique microphone
configuration, based on the superposition principle, designed to optimize sound
field coverage while addressing the limitations of traditional microphone
arrays. The presented 64-microphone configuration allows us to capture RIRs
directly in the Spherical Harmonics domain. The dataset features a wide range
of room configurations, encompassing variations in room geometry, acoustic
absorption materials, and source-receiver distances. A detailed description of
the simulation setup is provided alongside for an accurate reproduction. The
dataset serves as a vital resource for researchers working on spatial audio,
particularly in applications involving machine learning to improve room
acoustics modeling and sound field synthesis. It further provides a very high
level of spatial resolution and realism crucial for tasks such as source
localization, reverberation prediction, and immersive sound reproduction.

摘要：此貢獻引入了一個使用影像來源方法創建的 7 階 Ambisonic 房間脈衝響應 (HOA-RIR) 資料集。透過採用高階 Ambisonics，我們的資料集能進行精確的空間音訊重現，這是逼真沉浸式音訊應用的一項關鍵需求。利用虛擬模擬，我們根據疊加原理，提出了一種獨特的麥克風配置，旨在最佳化聲音場覆蓋範圍，同時解決傳統麥克風陣列的限制。所提出的 64 麥克風配置讓我們能夠直接在球諧域中擷取 RIR。該資料集具有廣泛的房間配置，包含房間幾何形狀、吸音材料和聲源接收器距離的變化。模擬設定的詳細說明也隨附提供，以進行準確的重現。該資料集可作為從事空間音訊研究人員的重要資源，特別是在涉及機器學習以改善房間聲學建模和聲音場合成的應用中。它進一步提供了非常高的空間解析度和真實感，這對於聲源定位、混響預測和沉浸式聲音重現等任務至關重要。

##### **Is this Generated Person Existed in Real-world? Fine-grained Detecting and Calibrating Abnormal Human-body**
2411.14205v1 by Zeqing Wang, Qingyang Ma, Wentao Wan, Haojie Li, Keze Wang, Yonghong Tian

Recent improvements in visual synthesis have significantly enhanced the
depiction of generated human photos, which are pivotal due to their wide
applicability and demand. Nonetheless, the existing text-to-image or
text-to-video models often generate low-quality human photos that might differ
considerably from real-world body structures, referred to as "abnormal human
bodies". Such abnormalities, typically deemed unacceptable, pose considerable
challenges in the detection and repair of them within human photos. These
challenges require precise abnormality recognition capabilities, which entail
pinpointing both the location and the abnormality type. Intuitively, Visual
Language Models (VLMs) that have obtained remarkable performance on various
visual tasks are quite suitable for this task. However, their performance on
abnormality detection in human photos is quite poor. Hence, it is quite
important to highlight this task for the research community. In this paper, we
first introduce a simple yet challenging task, i.e., \textbf{F}ine-grained
\textbf{H}uman-body \textbf{A}bnormality \textbf{D}etection \textbf{(FHAD)},
and construct two high-quality datasets for evaluation. Then, we propose a
meticulous framework, named HumanCalibrator, which identifies and repairs
abnormalities in human body structures while preserving the other content.
Experiments indicate that our HumanCalibrator achieves high accuracy in
abnormality detection and accomplishes an increase in visual comparisons while
preserving the other visual content.

摘要：<paragraph>最近視覺合成技術的進步，顯著增強了生成的人像照片的描繪，由於其廣泛的適用性和需求，因此至關重要。儘管如此，現有的文字轉圖像或文字轉影片模型通常會產生低品質的人像照片，這些照片可能與真實的身體結構有很大不同，稱為「異常人體」。這種異常通常被認為是不可接受的，在人像照片中檢測和修復它們會帶來相當大的挑戰。這些挑戰需要精確的異常識別能力，這需要精確指出位置和異常類型。直觀地說，在各種視覺任務中獲得顯著表現的視覺語言模型 (VLM) 非常適合這項任務。然而，它們在人像照片中異常檢測的表現非常差。因此，對於研究社群來說，強調這項任務非常重要。在本文中，我們首先介紹一個簡單但具有挑戰性的任務，即\textbf{F}ine-grained \textbf{H}uman-body \textbf{A}bnormality \textbf{D}etection \textbf{(FHAD)}，並建立兩個高品質的資料集進行評估。然後，我們提出一個細緻的框架，稱為 HumanCalibrator，它識別並修復人體結構中的異常，同時保留其他內容。實驗表明，我們的 HumanCalibrator 在異常檢測中實現了高準確度，並在保留其他視覺內容的同時，在視覺比較中取得了進展。</paragraph>

##### **OpenScholar: Synthesizing Scientific Literature with Retrieval-augmented LMs**
2411.14199v1 by Akari Asai, Jacqueline He, Rulin Shao, Weijia Shi, Amanpreet Singh, Joseph Chee Chang, Kyle Lo, Luca Soldaini, Sergey Feldman, Mike D'arcy, David Wadden, Matt Latzke, Minyang Tian, Pan Ji, Shengyan Liu, Hao Tong, Bohao Wu, Yanyu Xiong, Luke Zettlemoyer, Graham Neubig, Dan Weld, Doug Downey, Wen-tau Yih, Pang Wei Koh, Hannaneh Hajishirzi

Scientific progress depends on researchers' ability to synthesize the growing
body of literature. Can large language models (LMs) assist scientists in this
task? We introduce OpenScholar, a specialized retrieval-augmented LM that
answers scientific queries by identifying relevant passages from 45 million
open-access papers and synthesizing citation-backed responses. To evaluate
OpenScholar, we develop ScholarQABench, the first large-scale multi-domain
benchmark for literature search, comprising 2,967 expert-written queries and
208 long-form answers across computer science, physics, neuroscience, and
biomedicine. On ScholarQABench, OpenScholar-8B outperforms GPT-4o by 5% and
PaperQA2 by 7% in correctness, despite being a smaller, open model. While GPT4o
hallucinates citations 78 to 90% of the time, OpenScholar achieves citation
accuracy on par with human experts. OpenScholar's datastore, retriever, and
self-feedback inference loop also improves off-the-shelf LMs: for instance,
OpenScholar-GPT4o improves GPT-4o's correctness by 12%. In human evaluations,
experts preferred OpenScholar-8B and OpenScholar-GPT4o responses over
expert-written ones 51% and 70% of the time, respectively, compared to GPT4o's
32%. We open-source all of our code, models, datastore, data and a public demo.

摘要：<paragraph>科學進步有賴於研究人員綜合日益龐大的文獻資料的能力。大型語言模型 (LM) 能否協助科學家執行這項任務？我們推出 OpenScholar，一種專門的檢索增強型 LM，它透過識別來自 4500 萬篇開放取用論文中的相關段落並綜合引用備註的回應，來回答科學問題。為了評估 OpenScholar，我們開發了 ScholarQABench，這是第一個針對文獻搜尋的大規模多領域基準，包含 2967 個專家撰寫的問題和 208 個長篇答案，涵蓋電腦科學、物理學、神經科學和生物醫學。在 ScholarQABench 上，OpenScholar-8B 在正確性方面比 GPT-4o 高出 5%，比 PaperQA2 高出 7%，儘管它是一個較小的開放模型。雖然 GPT-4o 在 78% 到 90% 的時間內會產生幻覺引文，但 OpenScholar 的引文準確度與人類專家不相上下。OpenScholar 的資料儲存庫、檢索器和自我回饋推理迴圈也改進了現成的 LM：例如，OpenScholar-GPT4o 將 GPT-4o 的正確性提高了 12%。在人類評估中，專家分別有 51% 和 70% 的時間偏好 OpenScholar-8B 和 OpenScholar-GPT4o 回應，而 GPT-4o 為 32%。我們開放原始碼、模型、資料儲存庫、資料和公開示範。</paragraph>

##### **Why do language models perform worse for morphologically complex languages?**
2411.14198v1 by Catherine Arnett, Benjamin K. Bergen

Language models perform differently across languages. It has been previously
suggested that morphological typology may explain some of this variability
(Cotterell et al., 2018). We replicate previous analyses and find additional
new evidence for a performance gap between agglutinative and fusional
languages, where fusional languages, such as English, tend to have better
language modeling performance than morphologically more complex languages like
Turkish. We then propose and test three possible causes for this performance
gap: morphological alignment of tokenizers, tokenization quality, and
disparities in dataset sizes and measurement. To test the morphological
alignment hypothesis, we present MorphScore, a tokenizer evaluation metric, and
supporting datasets for 22 languages. We find some evidence that tokenization
quality explains the performance gap, but none for the role of morphological
alignment. Instead we find that the performance gap is most reduced when
training datasets are of equivalent size across language types, but only when
scaled according to the so-called "byte-premium" -- the different encoding
efficiencies of different languages and orthographies. These results suggest
that no language is harder or easier for a language model to learn on the basis
of its morphological typology. Differences in performance can be attributed to
disparities in dataset size. These results bear on ongoing efforts to improve
performance for low-performing and under-resourced languages.

摘要：語言模型在不同語言中的表現不同。先前曾提出形態類型學可能解釋了這種變異性的一部分（Cotterell 等人，2018 年）。我們複製先前的分析並發現更多證據，證明黏著語和融合語之間存在效能差距，其中融合語，例如英語，往往比形態更複雜的語言（例如土耳其語）有更好的語言建模效能。然後，我們提出並測試了造成這種效能差距的三個可能原因：分詞器的形態對齊、分詞品質，以及資料集大小和測量上的差異。為了測試形態對齊假設，我們提出了 MorphScore，一種分詞器評估指標，以及支援 22 種語言的資料集。我們發現一些證據表明分詞品質解釋了效能差距，但沒有證據支持形態對齊的作用。相反，我們發現當訓練資料集在不同語言類型中具有相同大小時，效能差距會最大程度地縮小，但僅當根據所謂的「位元組溢價」進行縮放時才會發生這種情況——不同語言和正寫法的編碼效率不同。這些結果表明，沒有哪種語言對語言模型來說更難或更容易學習，取決於其形態類型。效能差異可歸因於資料集大小的差異。這些結果與持續進行的改善低效能和資源不足語言效能的努力有關。

##### **ComfyGI: Automatic Improvement of Image Generation Workflows**
2411.14193v1 by Dominik Sobania, Martin Briesch, Franz Rothlauf

Automatic image generation is no longer just of interest to researchers, but
also to practitioners. However, current models are sensitive to the settings
used and automatic optimization methods often require human involvement. To
bridge this gap, we introduce ComfyGI, a novel approach to automatically
improve workflows for image generation without the need for human intervention
driven by techniques from genetic improvement. This enables image generation
with significantly higher quality in terms of the alignment with the given
description and the perceived aesthetics. On the performance side, we find that
overall, the images generated with an optimized workflow are about 50% better
compared to the initial workflow in terms of the median ImageReward score.
These already good results are even surpassed in our human evaluation, as the
participants preferred the images improved by ComfyGI in around 90% of the
cases.

摘要：自動影像生成不再僅是研究人員有興趣的領域，
實務工作者也開始關注。然而，目前的模型對所使用的設定很敏感，而自動最佳化方法通常需要人工介入。為了彌補這個差距，我們引入了 ComfyGI，一種新穎的方法，可自動改善影像生成工作流程，無需人工介入，並由遺傳改良技術驅動。這使得影像生成在與給定描述的一致性和感知美學方面具有顯著更高的品質。在效能方面，我們發現整體而言，使用最佳化工作流程生成的影像在 ImageReward 中位數評分方面比初始工作流程高出約 50%。這些已經不錯的結果在我們的人類評估中甚至被超越，因為參與者在約 90% 的情況下更喜歡 ComfyGI 改進的影像。

##### **FoPru: Focal Pruning for Efficient Large Vision-Language Models**
2411.14164v1 by Lei Jiang, Weizhe Huang, Tongxuan Liu, Yuting Zeng, Jing Li, Lechao Cheng, Xiaohua Xu

Large Vision-Language Models (LVLMs) represent a significant advancement
toward achieving superior multimodal capabilities by enabling powerful Large
Language Models (LLMs) to understand visual input. Typically, LVLMs utilize
visual encoders, such as CLIP, to transform images into visual tokens, which
are then aligned with textual tokens through projection layers before being
input into the LLM for inference. Although existing LVLMs have achieved
significant success, their inference efficiency is still limited by the
substantial number of visual tokens and the potential redundancy among them. To
mitigate this issue, we propose Focal Pruning (FoPru), a training-free method
that prunes visual tokens based on the attention-based token significance
derived from the vision encoder. Specifically, we introduce two alternative
pruning strategies: 1) the rank strategy, which leverages all token
significance scores to retain more critical tokens in a global view; 2) the row
strategy, which focuses on preserving continuous key information in images from
a local perspective. Finally, the selected tokens are reordered to maintain
their original positional relationships. Extensive experiments across various
LVLMs and multimodal datasets demonstrate that our method can prune a large
number of redundant tokens while maintaining high accuracy, leading to
significant improvements in inference efficiency.

摘要：大型视觉语言模型 (LVLMs) 藉由让强大的大型语言模型 (LLMs) 理解视觉输入，展现出在达成卓越多模态能力上的一大进步。LVLMs 一般会利用视觉编码器，例如 CLIP，将图像转换为视觉标记，然后在输入 LLM 进行推理之前，透过投影层与文本标记对齐。虽然现有的 LVLMs 已获得显著的成功，但其推理效率仍受到大量视觉标记和标记之间潜在冗余的限制。为了减轻此问题，我们提出了焦点修剪 (FoPru)，这是一种无需训练的方法，它会根据视觉编码器衍生的基于注意力的标记重要性来修剪视觉标记。具体来说，我们引入了两种替代修剪策略：1) 排名策略，它利用所有标记重要性分数来在全局视图中保留更重要的标记；2) 行策略，它专注于从局部角度保留图像中的连续关键信息。最后，选定的标记会重新排序以维持其原始位置关系。在各种 LVLMs 和多模态数据集上的广泛实验表明，我们的方法可以修剪大量冗余标记，同时维持高准确度，从而大幅提升推理效率。

##### **Visual Contexts Clarify Ambiguous Expressions: A Benchmark Dataset**
2411.14137v1 by Heejeong Nam, Jinwoo Ahn

The ability to perform complex reasoning across multimodal inputs is
essential for models to effectively interact with humans in real-world
scenarios. Advancements in vision-language models have significantly improved
performance on tasks that require processing explicit and direct textual
inputs, such as Visual Question Answering (VQA) and Visual Grounding (VG).
However, less attention has been given to improving the model capabilities to
comprehend nuanced and ambiguous forms of communication. This presents a
critical challenge, as human language in real-world interactions often convey
hidden intentions that rely on context for accurate interpretation. To address
this gap, we propose VAGUE, a multimodal benchmark comprising 3.9K indirect
human utterances paired with corresponding scenes. Additionally, we contribute
a model-based pipeline for generating prompt-solution pairs from input images.
Our work aims to delve deeper into the ability of models to understand indirect
communication and seek to contribute to the development of models capable of
more refined and human-like interactions. Extensive evaluation on multiple VLMs
reveals that mainstream models still struggle with indirect communication when
required to perform complex linguistic and visual reasoning. We release our
code and data at https://github.com/Hazel-Heejeong-Nam/VAGUE.git.

摘要：在真實世界的場景中，模型要有效地與人類互動，就必須具備跨多模態輸入進行複雜推理的能力。視覺語言模型的進步顯著提升了需要處理明確且直接的文字輸入的任務的效能，例如視覺問答 (VQA) 和視覺基礎 (VG)。然而，對於提升模型理解細微且模稜兩可的溝通形式的能力，關注較少。這是一個重大的挑戰，因為在真實世界的互動中，人類語言通常會傳達隱藏的意圖，而這些意圖依賴於背景才能準確解讀。為了解決這個差距，我們提出 VAGUE，一個由 3.9K 個間接的人類話語與對應場景配對組成的多模態基準。此外，我們提供了一個基於模型的管道，用於從輸入影像產生提示解決方案對。我們的研究旨在深入探討模型理解間接溝通的能力，並致力於開發能夠進行更精緻且更類似人類互動的模型。對多個 VLM 的廣泛評估顯示，主流模型在需要執行複雜的語言和視覺推理時，仍然難以處理間接溝通。我們在 https://github.com/Hazel-Heejeong-Nam/VAGUE.git/ 釋出我們的程式碼和資料。

##### **GASP: Efficient Black-Box Generation of Adversarial Suffixes for Jailbreaking LLMs**
2411.14133v1 by Advik Raj Basani, Xiao Zhang

Large Language Models (LLMs) have shown impressive proficiency across a range
of natural language processing tasks yet remain vulnerable to adversarial
prompts, known as jailbreak attacks, carefully designed to elicit harmful
responses from LLMs. Traditional methods rely on manual heuristics, which
suffer from limited generalizability. While being automatic, optimization-based
attacks often produce unnatural jailbreak prompts that are easy to detect by
safety filters or require high computational overhead due to discrete token
optimization. Witnessing the limitations of existing jailbreak methods, we
introduce Generative Adversarial Suffix Prompter (GASP), a novel framework that
combines human-readable prompt generation with Latent Bayesian Optimization
(LBO) to improve adversarial suffix creation in a fully black-box setting. GASP
leverages LBO to craft adversarial suffixes by efficiently exploring continuous
embedding spaces, gradually optimizing the model to improve attack efficacy
while balancing prompt coherence through a targeted iterative refinement
procedure. Our experiments show that GASP can generate natural jailbreak
prompts, significantly improving attack success rates, reducing training times,
and accelerating inference speed, thus making it an efficient and scalable
solution for red-teaming LLMs.

摘要：大型語言模型 (LLM) 在各種自然語言處理任務中展現出驚人的能力，但仍然容易受到對抗性提示的攻擊，稱為越獄攻擊，這些提示經過精心設計，可以引發 LLM 產生有害的回應。傳統方法依賴於手動啟發法，這種方法的泛化能力有限。雖然是自動化的，但基於優化的攻擊通常會產生不自然的越獄提示，這些提示很容易被安全過濾器檢測到，或者由於離散令牌優化而需要很高的計算開銷。鑑於現有越獄方法的局限性，我們引入了生成對抗後綴提示器 (GASP)，這是一個新穎的框架，它將人類可讀的提示生成與潛在貝葉斯優化 (LBO) 相結合，以在完全黑盒設置中改進對抗性後綴的創建。GASP 利用 LBO 通過有效探索連續嵌入空間來製作對抗性後綴，逐漸優化模型以提高攻擊效率，同時通過有針對性的迭代改進程序來平衡提示一致性。我們的實驗表明，GASP 可以生成自然的越獄提示，顯著提高攻擊成功率，減少訓練時間，並加快推理速度，從而使其成為一種高效且可擴展的紅隊 LLM 解決方案。

##### **Learning from "Silly" Questions Improves Large Language Models, But Only Slightly**
2411.14121v1 by Tingyuan Zhu, Shudong Liu, Yidong Wang, Derek F. Wong, Han Yu, Takahiro Shinozaki, Jindong Wang

Constructing high-quality Supervised Fine-Tuning (SFT) datasets is critical
for the training of large language models (LLMs). Recent studies have shown
that using data from a specific source, Ruozhiba, a Chinese website where users
ask "silly" questions to better understand certain topics, can lead to better
fine-tuning performance. This paper aims to explore some hidden factors: the
potential interpretations of its success and a large-scale evaluation of the
performance. First, we leverage GPT-4 to analyze the successful cases of
Ruozhiba questions from the perspective of education, psychology, and cognitive
science, deriving a set of explanatory rules. Then, we construct fine-tuning
datasets by applying these rules to the MMLU training set. Surprisingly, our
results indicate that rules can significantly improve model performance in
certain tasks, while potentially diminishing performance on others. For
example, SFT data generated following the "Counterintuitive Thinking" rule can
achieve approximately a 5% improvement on the "Global Facts" task, whereas the
"Blurring the Conceptual Boundaries" rule leads to a performance drop of 6.14%
on the "Econometrics" task. In addition, for specific tasks, different rules
tend to have a consistent impact on model performance. This suggests that the
differences between the extracted rules are not as significant, and the
effectiveness of the rules is relatively consistent across tasks. Our research
highlights the importance of considering task diversity and rule applicability
when constructing SFT datasets to achieve more comprehensive performance
improvements.

摘要：<paragraph>建構高品質的監督式微調 (SFT) 資料集對於訓練大型語言模型 (LLM) 至關重要。最近的研究顯示，使用來自特定來源的資料，例如 Ruozhiba，一個使用者提出「愚蠢」問題以更深入了解特定主題的中文網站，可以提升微調的效能。本文旨在探討一些隱藏的因素：成功背後的潛在詮釋以及效能的大規模評估。首先，我們利用 GPT-4 從教育、心理學和認知科學的角度分析 Ruozhiba 問題的成功案例，推導出一組解釋性規則。接著，我們將這些規則套用至 MMLU 訓練集，建構微調資料集。令人驚訝的是，我們的結果顯示規則可以顯著提升模型在特定任務中的效能，但可能會降低其他任務的效能。例如，遵循「反直覺思考」規則產生的 SFT 資料，在「全球事實」任務中可以提升約 5%，而「模糊概念界線」規則則導致「計量經濟學」任務的效能下降 6.14%。此外，對於特定任務，不同的規則往往對模型效能產生一致的影響。這表示提取出的規則之間的差異並不明顯，而且規則的有效性在各項任務中相對一致。我們的研究強調在建構 SFT 資料集時，考量任務的多樣性和規則的適用性非常重要，才能達成更全面的效能提升。</paragraph>

##### **Lost in Inference: Rediscovering the Role of Natural Language Inference for Large Language Models**
2411.14103v1 by Lovish Madaan, David Esiobu, Pontus Stenetorp, Barbara Plank, Dieuwke Hupkes

In the recent past, a popular way of evaluating natural language
understanding (NLU), was to consider a model's ability to perform natural
language inference (NLI) tasks. In this paper, we investigate if NLI tasks,
that are rarely used for LLM evaluation, can still be informative for
evaluating LLMs. Focusing on five different NLI benchmarks across six models of
different scales, we investigate if they are able to discriminate models of
different size and quality and how their accuracies develop during training.
Furthermore, we investigate the extent to which the softmax distributions of
models align with human distributions in cases where statements are ambiguous
or vague. Overall, our results paint a positive picture for the NLI tasks: we
find that they are able to discriminate well between models at various stages
of training, yet are not (all) saturated. Furthermore, we find that while the
similarity of model distributions with human label distributions increases with
scale, it is still much higher than the similarity between two populations of
humans, making it a potentially interesting statistic to consider.

摘要：在不久的過去，評估自然語言理解 (NLU) 的一種流行方式，是考慮模型執行自然語言推理 (NLI) 任務的能力。在本文中，我們探討了很少用於 LLM 評估的 NLI 任務，是否仍能為評估 LLM 提供資訊。我們專注於六個不同規模模型中的五個不同的 NLI 基準，探討它們是否能夠區分不同大小和品質的模型，以及它們的準確度如何在訓練過程中發展。此外，我們探討了在語句模稜兩可或含糊不清的情況下，模型的 softmax 分布與人類分布一致的程度。總的來說，我們的結果為 NLI 任務描繪了一幅正面的圖像：我們發現它們能夠很好地區分訓練不同階段的模型，但並未（全部）飽和。此外，我們發現雖然模型分布與人類標籤分布的相似性隨著規模而增加，但它仍然遠高於兩個人群之間的相似性，這使其成為一個值得考慮的潛在有趣統計數據。

##### **BEST-STD: Bidirectional Mamba-Enhanced Speech Tokenization for Spoken Term Detection**
2411.14100v1 by Anup Singh, Kris Demuynck, Vipul Arora

Spoken term detection (STD) is often hindered by reliance on frame-level
features and the computationally intensive DTW-based template matching,
limiting its practicality. To address these challenges, we propose a novel
approach that encodes speech into discrete, speaker-agnostic semantic tokens.
This facilitates fast retrieval using text-based search algorithms and
effectively handles out-of-vocabulary terms. Our approach focuses on generating
consistent token sequences across varying utterances of the same term. We also
propose a bidirectional state space modeling within the Mamba encoder, trained
in a self-supervised learning framework, to learn contextual frame-level
features that are further encoded into discrete tokens. Our analysis shows that
our speech tokens exhibit greater speaker invariance than those from existing
tokenizers, making them more suitable for STD tasks. Empirical evaluation on
LibriSpeech and TIMIT databases indicates that our method outperforms existing
STD baselines while being more efficient.

摘要：語音詞彙偵測 (STD) 經常受到依賴於幀層級特徵和計算密集的 DTW 基於範本匹配的阻礙，限制了其實用性。為了應對這些挑戰，我們提出了一種新穎的方法，將語音編碼成離散的、與說話者無關的語義符號。這有助於使用基於文字的搜尋演算法快速檢索，並有效處理詞彙外用語。我們的做法專注於在同一個詞彙的不同語句中產生一致的符號序列。我們還提出在 Mamba 編碼器內部使用雙向狀態空間建模，在自監督式學習架構中訓練，以學習進一步編碼成離散符號的上下文幀層級特徵。我們的分析顯示，我們的語音符號比現有符號化工具的符號表現出更大的說話者不變性，這使得它們更適合於 STD 任務。在 LibriSpeech 和 TIMIT 資料庫上的經驗評估表明，我們的模型優於現有的 STD 基準，同時更有效率。

##### **Meaning at the Planck scale? Contextualized word embeddings for doing history, philosophy, and sociology of science**
2411.14073v1 by Arno Simons

This paper explores the potential of contextualized word embeddings (CWEs) as
a new tool in the history, philosophy, and sociology of science (HPSS) for
studying contextual and evolving meanings of scientific concepts. Using the
term "Planck" as a test case, I evaluate five BERT-based models with varying
degrees of domain-specific pretraining, including my custom model
Astro-HEP-BERT, trained on the Astro-HEP Corpus, a dataset containing 21.84
million paragraphs from 600,000 articles in astrophysics and high-energy
physics. For this analysis, I compiled two labeled datasets: (1) the
Astro-HEP-Planck Corpus, consisting of 2,900 labeled occurrences of "Planck"
sampled from 1,500 paragraphs in the Astro-HEP Corpus, and (2) a
physics-related Wikipedia dataset comprising 1,186 labeled occurrences of
"Planck" across 885 paragraphs. Results demonstrate that the domain-adapted
models outperform the general-purpose ones in disambiguating the target term,
predicting its known meanings, and generating high-quality sense clusters, as
measured by a novel purity indicator I developed. Additionally, this approach
reveals semantic shifts in the target term over three decades in the unlabeled
Astro-HEP Corpus, highlighting the emergence of the Planck space mission as a
dominant sense. The study underscores the importance of domain-specific
pretraining for analyzing scientific language and demonstrates the
cost-effectiveness of adapting pretrained models for HPSS research. By offering
a scalable and transferable method for modeling the meanings of scientific
concepts, CWEs open up new avenues for investigating the socio-historical
dynamics of scientific discourses.

摘要：<paragraph>本文探討了語境化字詞嵌入 (CWE) 作為科學史、哲學和社會學 (HPSS) 中一項新工具的潛力，用於研究科學概念的語境和演化意義。使用「普朗克」一詞作為測試案例，我評估了五個基於 BERT 的模型，它們具有不同程度的特定領域預訓練，包括我在 Astro-HEP 語料庫上訓練的客製化模型 Astro-HEP-BERT，該資料集包含來自天體物理學和高能物理學中 600,000 篇文章的 21.84 百萬段落。對於此分析，我編譯了兩個標記資料集：(1) Astro-HEP-Planck 語料庫，包含從 Astro-HEP 語料庫中 1,500 段落中抽取的 2,900 個標記「普朗克」出現次數，以及 (2) 一個物理相關的維基百科資料集，包含跨越 885 段落的 1,186 個標記「普朗克」出現次數。結果證明，領域適應模型在消除目標術語歧義、預測其已知意義和產生高品質意義叢集方面優於通用模型，這是透過我開發的一項新穎純度指標測量的。此外，這種方法揭示了目標術語在未標記的 Astro-HEP 語料庫中超過三十年的語義轉變，突顯了普朗克太空任務作為主要意義的出現。這項研究強調了特定領域預訓練對於分析科學語言的重要性，並證明了適應預訓練模型對於 HPSS 研究的成本效益。透過提供一種可擴充且可轉移的方法來建模科學概念的意義，CWE 開啟了研究科學論述的社會歷史動態的新途徑。</paragraph>

##### **The Master-Slave Encoder Model for Improving Patent Text Summarization: A New Approach to Combining Specifications and Claims**
2411.14072v1 by Shu Zhou, Xin Wang, Zhengda Zhou, Haohan Yi, Xuhui Zheng, Hao Wan

In order to solve the problem of insufficient generation quality caused by
traditional patent text abstract generation models only originating from patent
specifications, the problem of new terminology OOV caused by rapid patent
updates, and the problem of information redundancy caused by insufficient
consideration of the high professionalism, accuracy, and uniqueness of patent
texts, we proposes a patent text abstract generation model (MSEA) based on a
master-slave encoder architecture; Firstly, the MSEA model designs a
master-slave encoder, which combines the instructions in the patent text with
the claims as input, and fully explores the characteristics and details between
the two through the master-slave encoder; Then, the model enhances the
consideration of new technical terms in the input sequence based on the pointer
network, and further enhances the correlation with the input text by re
weighing the "remembered" and "for-gotten" parts of the input sequence from the
encoder; Finally, an enhanced repetition suppression mechanism for patent text
was introduced to ensure accurate and non redundant abstracts generated. On a
publicly available patent text dataset, compared to the state-of-the-art model,
Improved Multi-Head Attention Mechanism (IMHAM), the MSEA model achieves an
improvement of 0.006, 0.005, and 0.005 in Rouge-1, Rouge-2, and Rouge-L scores,
respectively. MSEA leverages the characteristics of patent texts to effectively
enhance the quality of patent text generation, demonstrating its advancement
and effectiveness in the experiments.

摘要：<paragraph>為了解決傳統專利文本摘要生成模型僅源自專利說明書導致生成品質不足的問題、專利更新快速導致新術語 OOV 的問題，以及對專利文本專業性、準確性、獨特性考量不足導致資訊冗餘的問題，我們提出一個基於主從編碼器架構的專利文本摘要生成模型 (MSEA)；首先，MSEA 模型設計一個主從編碼器，將專利文本中的說明書與權利要求書結合作為輸入，並透過主從編碼器充分探索兩者之間的特性與細節；接著，模型基於 pointer network 增強輸入序列中新技術詞彙的考量，並透過重新加權編碼器中「記住」與「遺忘」的輸入序列部分，進一步提升與輸入文本的關聯性；最後，導入增強的專利文本重複抑制機制，以確保生成摘要的準確性與非冗餘性。在一個公開的專利文本資料集上，與目前最先進的模型 Improved Multi-Head Attention Mechanism (IMHAM) 相比，MSEA 模型在 Rouge-1、Rouge-2、Rouge-L 分數上分別提升了 0.006、0.005、0.005。MSEA 充分利用專利文本的特性，有效提升專利文本生成的品質，在實驗中展現其先進性與有效性。</paragraph>

##### **Multi LoRA Meets Vision: Merging multiple adapters to create a multi task model**
2411.14064v1 by Ege Kesim, Selahattin Serdar Helli

Parameter efficient finetuning (PEFT) methods are widely used in LLMs and
generative models in computer vision. Especially one can use multiple of these
during inference to change the behavior of the base model. In this paper we
investigated whether multiple LoRA adapters trained on computer vision tasks
can be merged together and used during inference without loss in performance.
By achieving this, multitask models can be created just by merging different
LoRAs. Merging these will reduce inference time and it will not require any
additional retraining. We have trained adapters on six different tasks and
evaluated their performance when they are merged together. For comparison we
used a model with a frozen backbone and finetuned its head. Our results show
that even with simple merging techniques creating a multitask model by merging
adapters is achievable by slightly loosing performance in some cases. In our
experiments we merged up to three adapters together. Depending on the task and
the similarity of the data adapters were trained on, merges can outperform head
finetuning. We have observed that LoRAs trained with dissimilar datasets tend
to perform better compared to model trained on similar datasets.

摘要：参数高效微调 (PEFT) 方法广泛用于语言大模型和计算机视觉中的生成模型。特别是在推理期间，可以利用其中多个方法来改变基础模型的行为。在本文中，我们研究了是否可以将针对计算机视觉任务训练的多个 LoRA 适配器合并在一起并在推理期间使用，而不会损失性能。通过实现这一点，只需合并不同的 LoRA 即可创建多任务模型。合并这些模型将减少推理时间，并且不需要任何额外的重新训练。我们在六个不同的任务上训练了适配器，并在合并后评估了它们的性能。为了进行比较，我们使用了一个冻结主干并对其头部进行微调的模型。我们的结果表明，即使使用简单的合并技术，通过合并适配器创建多任务模型也是可行的，在某些情况下会略微降低性能。在我们的实验中，我们将多达三个适配器合并在一起。根据任务和训练适配器的数据的相似性，合并可以优于头部微调。我们观察到，使用不同数据集训练的 LoRA 与在类似数据集上训练的模型相比，往往表现得更好。

##### **MMGenBench: Evaluating the Limits of LMMs from the Text-to-Image Generation Perspective**
2411.14062v1 by Hailang Huang, Yong Wang, Zixuan Huang, Huaqiu Li, Tongwen Huang, Xiangxiang Chu, Richong Zhang

Large Multimodal Models (LMMs) have demonstrated remarkable capabilities.
While existing benchmarks for evaluating LMMs mainly focus on image
comprehension, few works evaluate them from the image generation perspective.
To address this issue, we propose a straightforward automated evaluation
pipeline. Specifically, this pipeline requires LMMs to generate an image-prompt
from a given input image. Subsequently, it employs text-to-image generative
models to create a new image based on these generated prompts. Finally, we
evaluate the performance of LMMs by comparing the original image with the
generated one. Furthermore, we introduce MMGenBench-Test, a comprehensive
benchmark developed to evaluate LMMs across 13 distinct image patterns, and
MMGenBench-Domain, targeting the performance evaluation of LMMs within the
generative image domain. A thorough evaluation involving over 50 popular LMMs
demonstrates the effectiveness and reliability in both the pipeline and
benchmark. Our observations indicate that numerous LMMs excelling in existing
benchmarks fail to adequately complete the basic tasks, related to image
understanding and description. This finding highlights the substantial
potential for performance improvement in current LMMs and suggests avenues for
future model optimization. Concurrently, our pipeline facilitates the efficient
assessment of LMMs performance across diverse domains by using solely image
inputs.

摘要：大型多模态模型 (LMM) 已展示出惊人的能力。
虽然用于评估 LMM 的现有基准主要关注图像理解，但很少有研究从图像生成的角度对其进行评估。
为了解决这个问题，我们提出了一种直接的自动化评估管道。具体来说，此管道要求 LMM 从给定的输入图像生成图像提示。随后，它使用文本到图像生成模型根据这些生成的提示创建新图像。最后，我们通过比较原始图像和生成图像来评估 LMM 的性能。此外，我们引入了 MMGenBench-Test，这是一个综合基准，用于评估 13 种不同图像模式的 LMM，以及 MMGenBench-Domain，针对生成图像域中 LMM 的性能评估。涉及 50 多个流行 LMM 的全面评估证明了管道和基准的有效性和可靠性。我们的观察结果表明，许多在现有基准中表现出色的 LMM 无法充分完成与图像理解和描述相关的基本任务。这一发现突显了当前 LMM 中性能改进的巨大潜力，并为未来的模型优化提供了途径。同时，我们的管道仅使用图像输入即可促进跨不同领域的 LMM 性能的有效评估。

##### **DRPruning: Efficient Large Language Model Pruning through Distributionally Robust Optimization**
2411.14055v1 by Hexuan Deng, Wenxiang Jiao, Xuebo Liu, Min Zhang, Zhaopeng Tu

Large language models (LLMs) deliver impressive results but face challenges
from increasing model sizes and computational costs. Structured pruning reduces
model size and speeds up inference but often causes uneven degradation across
domains, leading to biased performance. To address this, we propose DRPruning,
which incorporates distributionally robust optimization to restore balanced
performance across domains, along with further improvements to enhance
robustness. Experiments in monolingual and multilingual settings show that our
method surpasses similarly sized models in pruning and continued pretraining
over perplexity, downstream tasks, and instruction tuning. We further provide
analysis demonstrating the robustness of our method towards various domains and
distribution shifts. Furthermore, our method automatically determines optimal
reference losses and data ratios, suggesting potential for broader
applications. Our code is available at https://github.com/hexuandeng/DRPruning.

摘要：大型語言模型 (LLM) 提供令人印象深刻的結果，但面臨模型規模和運算成本增加的挑戰。結構化剪枝可減少模型大小並加速推理，但通常會導致不同領域的性能下降不均，進而導致性能偏差。為了解決這個問題，我們提出了 DRPruning，它結合了分布穩健最佳化，以恢復不同領域的平衡性能，同時進一步改進以增強穩健性。單語和多語環境中的實驗表明，我們的模型在剪枝和持續預訓練方面優於大小相似的模型，在困惑度、下游任務和指令調整方面表現出色。我們進一步提供了分析，證明了我們的模型對各種領域和分佈轉移的穩健性。此外，我們的模型自動確定最佳參考損失和數據比率，表明其在更廣泛的應用中具有潛力。我們的程式碼可在 https://github.com/hexuandeng/DRPruning 取得。

##### **FunctionChat-Bench: Comprehensive Evaluation of Language Models' Generative Capabilities in Korean Tool-use Dialogs**
2411.14054v1 by Shinbok Lee, Gaeun Seo, Daniel Lee, Byeongil Ko, Sunghee Jung, Myeongcheol Shin

This study investigates language models' generative capabilities in tool-use
dialogs. We categorize the models' outputs in tool-use dialogs into four
distinct types: Tool Call, Answer Completion, Slot Question, and Relevance
Detection, which serve as aspects for evaluation. We introduce
FunctionChat-Bench, comprising 700 evaluation items and automated assessment
programs. Using this benchmark, we evaluate several language models that
support function calling. Our findings indicate that while language models may
exhibit high accuracy in single-turn Tool Call scenarios, this does not
necessarily translate to superior generative performance in multi-turn
environments. We argue that the capabilities required for function calling
extend beyond generating tool call messages; they must also effectively
generate conversational messages that engage the user.

摘要：本研究探討語言模型在工具使用對話中的生成能力。我們將模型在工具使用對話中的輸出分為四種類型：工具呼叫、答案完成、插槽問題和相關性偵測，作為評估的方面。我們引入了 FunctionChat-Bench，包含 700 個評估項目和自動化評估程式。使用此基準，我們評估了支援函式呼叫的幾個語言模型。我們的研究結果表明，儘管語言模型在單回合工具呼叫場景中可能表現出高準確性，但這並不一定能轉化為多回合環境中的優異生成效能。我們認為，函式呼叫所需的能力不只限於產生工具呼叫訊息；它們還必須有效產生能與使用者互動的對話訊息。

##### **Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling**
2411.14042v1 by Daehoon Gwak, Junwoo Park, Minho Park, Chaehun Park, Hyunchan Lee, Edward Choi, Jaegul Choo

Predicting future international events from textual information, such as news
articles, has tremendous potential for applications in global policy, strategic
decision-making, and geopolitics. However, existing datasets available for this
task are often limited in quality, hindering the progress of related research.
In this paper, we introduce WORLDREP (WORLD Relationship and Event Prediction),
a novel dataset designed to address these limitations by leveraging the
advanced reasoning capabilities of large-language models (LLMs). Our dataset
features high-quality scoring labels generated through advanced prompt modeling
and rigorously validated by domain experts in political science. We showcase
the quality and utility of WORLDREP for real-world event prediction tasks,
demonstrating its effectiveness through extensive experiments and analysis.
Furthermore, we publicly release our dataset along with the full automation
source code for data collection, labeling, and benchmarking, aiming to support
and advance research in text-based event prediction.

摘要：從新聞文章等文字資訊預測未來國際事件，在全球政策、策略決策和地緣政治等應用領域具有巨大的潛力。然而，現有可用的資料集品質往往有限，阻礙了相關研究的進展。在本文中，我們介紹了 WORLDREP（世界關係與事件預測），這是一個新穎的資料集，旨在透過利用大型語言模型 (LLM) 的先進推理能力來解決這些限制。我們的資料集的特點是透過先進提示建模產生的高品質評分標籤，並由政治科學領域專家嚴格驗證。我們展示了 WORLDREP 在現實世界事件預測任務中的品質和效用，並透過廣泛的實驗和分析證明了其有效性。此外，我們公開發布我們的資料集，以及用於資料收集、標記和基準測試的完整自動化原始碼，旨在支援和推進基於文字的事件預測研究。

##### **Uterine Ultrasound Image Captioning Using Deep Learning Techniques**
2411.14039v1 by Abdennour Boulesnane, Boutheina Mokhtari, Oumnia Rana Segueni, Slimane Segueni

Medical imaging has significantly revolutionized medical diagnostics and
treatment planning, progressing from early X-ray usage to sophisticated methods
like MRIs, CT scans, and ultrasounds. This paper investigates the use of deep
learning for medical image captioning, with a particular focus on uterine
ultrasound images. These images are vital in obstetrics and gynecology for
diagnosing and monitoring various conditions across different age groups.
However, their interpretation is often challenging due to their complexity and
variability. To address this, a deep learning-based medical image captioning
system was developed, integrating Convolutional Neural Networks with a
Bidirectional Gated Recurrent Unit network. This hybrid model processes both
image and text features to generate descriptive captions for uterine ultrasound
images. Our experimental results demonstrate the effectiveness of this approach
over baseline methods, with the proposed model achieving superior performance
in generating accurate and informative captions, as indicated by higher BLEU
and ROUGE scores. By enhancing the interpretation of uterine ultrasound images,
our research aims to assist medical professionals in making timely and accurate
diagnoses, ultimately contributing to improved patient care.

摘要：醫學影像大幅革新了醫療診斷和治療計畫，從早期的 X 光使用進展到 MRI、電腦斷層掃描和超音波等精密方法。這篇論文探討深度學習在醫學影像標題中的應用，特別著重於子宮超音波影像。這些影像在婦產科中對於診斷和追蹤不同年齡層的各種疾病至關重要。然而，由於其複雜性和變異性，它們的詮釋通常具有挑戰性。為了解決這個問題，開發了一個基於深度學習的醫學影像標題系統，將卷積神經網路與雙向門控循環單元網路整合在一起。這個混合模型處理影像和文字特徵，為子宮超音波影像產生描述性標題。我們的實驗結果證明了此方法優於基線方法的有效性，所提出的模型在產生準確且有意義的標題方面達到了卓越的效能，這由較高的 BLEU 和 ROUGE 分數所證明。透過增強子宮超音波影像的詮釋，我們的研究旨在協助醫療專業人員進行及時且準確的診斷，最終有助於改善病患照護。

##### **Assessing data-driven predictions of band gap and electrical conductivity for transparent conducting materials**
2411.14034v1 by Federico Ottomano, John Y. Goulermas, Vladimir Gusev, Rahul Savani, Michael W. Gaultois, Troy D. Manning, Hai Lin, Teresa P. Manzanera, Emmeline G. Poole, Matthew S. Dyer, John B. Claridge, Jon Alaria, Luke M. Daniels, Su Varma, David Rimmer, Kevin Sanderson, Matthew J. Rosseinsky

Machine Learning (ML) has offered innovative perspectives for accelerating
the discovery of new functional materials, leveraging the increasing
availability of material databases. Despite the promising advances, data-driven
methods face constraints imposed by the quantity and quality of available data.
Moreover, ML is often employed in tandem with simulated datasets originating
from density functional theory (DFT), and assessed through in-sample evaluation
schemes. This scenario raises questions about the practical utility of ML in
uncovering new and significant material classes for industrial applications.
Here, we propose a data-driven framework aimed at accelerating the discovery of
new transparent conducting materials (TCMs), an important category of
semiconductors with a wide range of applications. To mitigate the shortage of
available data, we create and validate unique experimental databases,
comprising several examples of existing TCMs. We assess state-of-the-art (SOTA)
ML models for property prediction from the stoichiometry alone. We propose a
bespoke evaluation scheme to provide empirical evidence on the ability of ML to
uncover new, previously unseen materials of interest. We test our approach on a
list of 55 compositions containing typical elements of known TCMs. Although our
study indicates that ML tends to identify new TCMs compositionally similar to
those in the training data, we empirically demonstrate that it can highlight
material candidates that may have been previously overlooked, offering a
systematic approach to identify materials that are likely to display TCMs
characteristics.

摘要：機器學習 (ML) 提供了創新的觀點，可加速新功能材料的發現，利用日益增加的材料資料庫。儘管有這些有前景的進展，但資料驅動方法面臨可用資料數量和品質所施加的限制。此外，ML 通常與源自密度泛函理論 (DFT) 的模擬資料集結合使用，並透過樣本內評估方案進行評估。此情境引發了關於 ML 在發現工業應用中新的且重要的材料類別方面的實用性問題。在此，我們提出一個資料驅動的架構，旨在加速發現新的透明導電材料 (TCM)，這類半導體非常重要，應用範圍廣泛。為了減少可用資料的短缺，我們建立並驗證了獨特的實驗資料庫，其中包含了現有 TCM 的幾個範例。我們評估了最先進 (SOTA) ML 模型，僅從化學計量學預測特性。我們提出了一個客製化的評估方案，以提供經驗證據，證明 ML 能夠發現新的、以前未見過的感興趣材料。我們在包含已知 TCM 的典型元素的 55 種成分清單上測試了我們的方法。儘管我們的研究表明，ML 傾向於識別與訓練資料中類似的組成新 TCM，但我們經驗性地證明，它可以突顯可能以前被忽略的材料候選，提供一種系統性的方法來識別可能顯示 TCM 特性的材料。

##### **Multi-LLM-Agent Systems: Techniques and Business Perspectives**
2411.14033v1 by Yingxuan Yang, Qiuying Peng, Jun Wang, Weinan Zhang

In the era of (multi-modal) large language models, most operational processes
can be reformulated and reproduced using LLM agents. The LLM agents can
perceive, control, and get feedback from the environment so as to accomplish
the given tasks in an autonomous manner. Besides the environment-interaction
property, the LLM agents can call various external tools to ease the task
completion process. The tools can be regarded as a predefined operational
process with private or real-time knowledge that does not exist in the
parameters of LLMs. As a natural trend of development, the tools for calling
are becoming autonomous agents, thus the full intelligent system turns out to
be a multi-LLM-agent system (MLAS). This paper discusses the technical and
business landscapes of MLAS. Compared to the previous single-LLM-agent system,
a MLAS has the advantages of i) higher potential of task-solving performance,
ii) higher flexibility for system changing, iii) proprietary data preserving
for each participating entity, and iv) feasibility of monetization for each
entity. To support the ecosystem of MLAS, we provide a preliminary version of
such MLAS protocol considering technical requirements, data privacy, and
business incentives. As such, MLAS would be a practical solution to achieve
artificial collective intelligence in the near future.

摘要：在（多模态）大语言模型的时代，大多数操作流程
可以使用 LLM 代理重新表述和复制。LLM 代理可以
感知、控制和从环境中获取反馈，以便以自主的方式完成
给定的任务。除了环境交互
属性外，LLM 代理还可以调用各种外部工具来简化任务
完成过程。这些工具可以被视为具有私有或实时知识的预定义操作
流程，这些知识不存在于 LLM 的参数中。作为一种自然的发展趋势，用于调用的工具
正在成为自主代理，因此完整的智能系统变成了
多 LLM 代理系统 (MLAS)。本文讨论了 MLAS 的技术和
商业前景。与之前的单 LLM 代理系统相比，
MLAS 具有以下优势：i) 更高的任务解决性能潜力，
ii) 更高的系统更改灵活性，iii) 每个参与实体的专有数据保留，以及 iv) 每个
实体的货币化可行性。为了支持 MLAS 生态系统，我们提供了一个初步版本
此类 MLAS 协议考虑技术要求、数据隐私和
商业激励。因此，MLAS 将成为在不久的将来实现
人工智能集体智能的实用解决方案。

##### **Logic Augmented Generation**
2411.14012v1 by Aldo Gangemi, Andrea Giovanni Nuzzolese

Semantic Knowledge Graphs (SKG) face challenges with scalability,
flexibility, contextual understanding, and handling unstructured or ambiguous
information. However, they offer formal and structured knowledge enabling
highly interpretable and reliable results by means of reasoning and querying.
Large Language Models (LLMs) overcome those limitations making them suitable in
open-ended tasks and unstructured environments. Nevertheless, LLMs are neither
interpretable nor reliable. To solve the dichotomy between LLMs and SKGs we
envision Logic Augmented Generation (LAG) that combines the benefits of the two
worlds. LAG uses LLMs as Reactive Continuous Knowledge Graphs that can generate
potentially infinite relations and tacit knowledge on-demand. SKGs are key for
injecting a discrete heuristic dimension with clear logical and factual
boundaries. We exemplify LAG in two tasks of collective intelligence, i.e.,
medical diagnostics and climate projections. Understanding the properties and
limitations of LAG, which are still mostly unknown, is of utmost importance for
enabling a variety of tasks involving tacit knowledge in order to provide
interpretable and effective results.

摘要：語意知識圖（SKG）在可擴充性、靈活性、情境理解以及處理非結構化或含糊資訊方面面臨挑戰。然而，它們提供正式且結構化的知識，能透過推理和查詢提供高度可解釋且可靠的結果。大型語言模型（LLM）克服了這些限制，使其適用於開放式任務和非結構化環境。儘管如此，LLM 既不可解釋也不可靠。為了解決 LLM 和 SKG 之間的二分法，我們設想了邏輯增強生成（LAG），它結合了兩個世界的優點。LAG 使用 LLM 作為反應式連續知識圖，它可以按需產生潛在的無限關係和默會知識。SKG 是注入離散啟發式維度（具有明確邏輯和事實邊界）的關鍵。我們在集體智慧的兩個任務中舉例說明 LAG，即醫療診斷和氣候預測。理解 LAG 的特性和限制（目前仍然大多數未知）對於啟用涉及默會知識的各種任務以提供可解釋且有效的結果至關重要。

##### **Mirror Target YOLO: An Improved YOLOv8 Method with Indirect Vision for Heritage Buildings Fire Detection**
2411.13997v1 by Jian Liang, JunSheng Cheng

Fires can cause severe damage to heritage buildings, making timely fire
detection essential. Traditional dense cabling and drilling can harm these
structures, so reducing the number of cameras to minimize such impact is
challenging. Additionally, avoiding false alarms due to noise sensitivity and
preserving the expertise of managers in fire-prone areas is crucial. To address
these needs, we propose a fire detection method based on indirect vision,
called Mirror Target YOLO (MITA-YOLO). MITA-YOLO integrates indirect vision
deployment and an enhanced detection module. It uses mirror angles to achieve
indirect views, solving issues with limited visibility in irregular spaces and
aligning each indirect view with the target monitoring area. The Target-Mask
module is designed to automatically identify and isolate the indirect vision
areas in each image, filtering out non-target areas. This enables the model to
inherit managers' expertise in assessing fire-risk zones, improving focus and
resistance to interference in fire detection.In our experiments, we created an
800-image fire dataset with indirect vision. Results show that MITA-YOLO
significantly reduces camera requirements while achieving superior detection
performance compared to other mainstream models.

摘要：火災會對古蹟建築造成嚴重損害，因此及時偵測火災至關重要。傳統的密集佈線和鑽孔可能會損害這些結構，因此減少相機數量以將此類影響降至最低具有挑戰性。此外，避免因噪音敏感性而發出錯誤警報並保留火災多發地區管理人員的專業知識至關重要。為了滿足這些需求，我們提出了一種基於間接視覺的火災檢測方法，稱為 Mirror Target YOLO (MITA-YOLO)。MITA-YOLO 整合了間接視覺部署和增強的檢測模組。它使用鏡面角度來獲得間接視角，解決了不規則空間中能見度受限的問題，並將每個間接視角與目標監控區域對齊。Target-Mask 模組旨在自動識別和隔離每個影像中的間接視覺區域，濾除非目標區域。這使模型能夠繼承管理人員在評估火災風險區域方面的專業知識，提高焦點和抗干擾能力，以進行火災檢測。在我們的實驗中，我們創建了一個具有間接視覺的 800 張影像火災資料集。結果表明，與其他主流模型相比，MITA-YOLO 大幅減少了相機需求，同時實現了卓越的檢測效能。

##### **Safety Without Semantic Disruptions: Editing-free Safe Image Generation via Context-preserving Dual Latent Reconstruction**
2411.13982v1 by Jordan Vice, Naveed Akhtar, Richard Hartley, Ajmal Mian

Training multimodal generative models on large, uncurated datasets can result
in users being exposed to harmful, unsafe and controversial or
culturally-inappropriate outputs. While model editing has been proposed to
remove or filter undesirable concepts in embedding and latent spaces, it can
inadvertently damage learned manifolds, distorting concepts in close semantic
proximity. We identify limitations in current model editing techniques, showing
that even benign, proximal concepts may become misaligned. To address the need
for safe content generation, we propose a modular, dynamic solution that
leverages safety-context embeddings and a dual reconstruction process using
tunable weighted summation in the latent space to generate safer images. Our
method preserves global context without compromising the structural integrity
of the learned manifolds. We achieve state-of-the-art results on safe image
generation benchmarks, while offering controllable variation of model safety.
We identify trade-offs between safety and censorship, which presents a
necessary perspective in the development of ethical AI models. We will release
our code.
  Keywords: Text-to-Image Models, Generative AI, Safety, Reliability, Model
Editing

摘要：<paragraph>在大型、未整理的数据集上训练多模态生成模型可能会导致
用户接触到有害、不安全和有争议或
文化上不恰当的输出。虽然已经提出模型编辑来
删除或过滤嵌入和潜在空间中的不良概念，但它可以
无意中损坏学习流形，扭曲语义中紧密的概念
邻近度。我们发现当前模型编辑技术的局限性，表明
即使是良性的、近似的概念也可能变得不一致。为了解决
安全内容生成的需求，我们提出了一种模块化、动态的解决方案，
利用安全上下文嵌入和使用可调加权和的双重重建过程
在潜在空间中生成更安全的图像。我们的
方法保留了全局上下文，同时不损害学习流形的结构完整性。我们在安全图像中取得了最先进的结果
生成基准，同时提供模型安全性的可控变化。
我们确定了安全和审查之间的权衡，这提出了一个
在开发道德人工智能模型中必要的视角。我们将发布
我们的代码。
关键词：文本到图像模型、生成式人工智能、安全、可靠性、模型
编辑</paragraph>

##### **On the Fairness, Diversity and Reliability of Text-to-Image Generative Models**
2411.13981v1 by Jordan Vice, Naveed Akhtar, Richard Hartley, Ajmal Mian

The widespread availability of multimodal generative models has sparked
critical discussions on their fairness, reliability, and potential for misuse.
While text-to-image models can produce high-fidelity, user-guided images, they
also exhibit unpredictable behavior and vulnerabilities, which can be exploited
to manipulate class or concept representations. To address this, we propose an
evaluation framework designed to assess model reliability through their
responses to globally- and locally-applied `semantic' perturbations in the
embedding space, pinpointing inputs that trigger unreliable behavior. Our
approach offers deeper insights into two essential aspects: (i) generative
diversity, evaluating the breadth of visual representations for learned
concepts, and (ii) generative fairness, examining how removing concepts from
input prompts affects semantic guidance. Beyond these evaluations, our method
lays the groundwork for detecting unreliable, bias-injected models and
retrieval of bias provenance. We will release our code.
  Keywords: Fairness, Reliability, AI Ethics, Bias, Text-to-Image Models

摘要：多模态生成模型的广泛可用性引发了对其公平性、可靠性和潜在滥用风险的关键讨论。虽然文本到图像模型可以生成高保真度、用户引导的图像，但它们也表现出不可预测的行为和漏洞，这些行为和漏洞可被利用来操纵类别或概念表征。为了解决这个问题，我们提出了一个评估框架，旨在通过模型对嵌入空间中全局和局部应用的“语义”扰动的响应来评估模型可靠性，从而找出触发不可靠行为的输入。我们的方法对两个基本方面提供了更深入的见解：(i) 生成多样性，评估学习概念的可视化表征的广度，以及 (ii) 生成公平性，检查从输入提示中移除概念如何影响语义指导。除了这些评估之外，我们的方法还为检测不可靠的、注入偏差的模型和检索偏差来源奠定了基础。我们将发布我们的代码。
关键词：公平性、可靠性、人工智能伦理、偏差、文本到图像模型

##### **FedRAV: Hierarchically Federated Region-Learning for Traffic Object Classification of Autonomous Vehicles**
2411.13979v1 by Yijun Zhai, Pengzhan Zhou, Yuepeng He, Fang Qu, Zhida Qin, Xianlong Jiao, Guiyan Liu, Songtao Guo

The emerging federated learning enables distributed autonomous vehicles to
train equipped deep learning models collaboratively without exposing their raw
data, providing great potential for utilizing explosively growing autonomous
driving data. However, considering the complicated traffic environments and
driving scenarios, deploying federated learning for autonomous vehicles is
inevitably challenged by non-independent and identically distributed (Non-IID)
data of vehicles, which may lead to failed convergence and low training
accuracy. In this paper, we propose a novel hierarchically Federated
Region-learning framework of Autonomous Vehicles (FedRAV), a two-stage
framework, which adaptively divides a large area containing vehicles into
sub-regions based on the defined region-wise distance, and achieves
personalized vehicular models and regional models. This approach ensures that
the personalized vehicular model adopts the beneficial models while discarding
the unprofitable ones. We validate our FedRAV framework against existing
federated learning algorithms on three real-world autonomous driving datasets
in various heterogeneous settings. The experiment results demonstrate that our
framework outperforms those known algorithms, and improves the accuracy by at
least 3.69%. The source code of FedRAV is available at:
https://github.com/yjzhai-cs/FedRAV.

摘要：新興的聯邦學習使分散的自動駕駛車輛能夠在不公開其原始數據的情況下協作訓練配備的深度學習模型，為利用爆炸性增長的自動駕駛數據提供了巨大的潛力。然而，考慮到複雜的交通環境和駕駛場景，為自動駕駛車輛部署聯邦學習不可避免地會受到車輛的非獨立同分布 (Non-IID) 數據的挑戰，這可能導致收斂失敗和訓練精度低。在本文中，我們提出了一個新穎的分層聯邦區域學習自動駕駛車輛框架 (FedRAV)，這是一個兩階段框架，它根據定義的區域距離自適應地將包含車輛的大區域劃分為子區域，並實現個性化車輛模型和區域模型。此方法確保個性化車輛模型採用有益模型，同時捨棄無利可圖的模型。我們在各種異構設置下的三個真實世界自動駕駛數據集上驗證了我們的 FedRAV 框架與現有的聯邦學習演算法。實驗結果表明，我們的框架優於那些已知的演算法，並將準確度提高了至少 3.69%。FedRAV 的原始碼可在以下位置取得：
https://github.com/yjzhai-cs/FedRAV。

##### **Separable Mixture of Low-Rank Adaptation for Continual Visual Instruction Tuning**
2411.13949v1 by Ziqi Wang, Chang Che, Qi Wang, Yangyang Li, Zenglin Shi, Meng Wang

Visual instruction tuning (VIT) enables multimodal large language models
(MLLMs) to effectively handle a wide range of vision tasks by framing them as
language-based instructions. Building on this, continual visual instruction
tuning (CVIT) extends the capability of MLLMs to incrementally learn new tasks,
accommodating evolving functionalities. While prior work has advanced CVIT
through the development of new benchmarks and approaches to mitigate
catastrophic forgetting, these efforts largely follow traditional continual
learning paradigms, neglecting the unique challenges specific to CVIT. We
identify a dual form of catastrophic forgetting in CVIT, where MLLMs not only
forget previously learned visual understanding but also experience a decline in
instruction following abilities as they acquire new tasks. To address this, we
introduce the Separable Mixture of Low-Rank Adaptation (SMoLoRA) framework,
which employs separable routing through two distinct modules - one for visual
understanding and another for instruction following. This dual-routing design
enables specialized adaptation in both domains, preventing forgetting while
improving performance. Furthermore, we propose a novel CVIT benchmark that goes
beyond existing benchmarks by additionally evaluating a model's ability to
generalize to unseen tasks and handle diverse instructions across various
tasks. Extensive experiments demonstrate that SMoLoRA outperforms existing
methods in mitigating dual forgetting, improving generalization to unseen
tasks, and ensuring robustness in following diverse instructions.

摘要：視覺指令微調 (VIT) 能讓多模態大型語言模型 (MLLM) 有效處理廣泛的視覺任務，方法是將它們建構為基於語言的指令。在此基礎上，持續視覺指令微調 (CVIT) 擴展了 MLLM 的能力，讓它們能逐步學習新任務，以適應不斷變化的功能。儘管先前的工作已透過開發新的基準和方法來緩解災難性遺忘，進而推動 CVIT 的進步，但這些努力在很大程度上遵循傳統的持續學習範例，忽略了 CVIT 特有的獨特挑戰。我們在 CVIT 中發現了一種災難性遺忘的雙重形式，其中 MLLM 不僅遺忘了先前學習的視覺理解，而且在獲得新任務時，其遵循指令的能力也會下降。為了解決這個問題，我們引入了可分離低秩適應混合 (SMoLoRA) 框架，它採用可分離路由，透過兩個不同的模組來執行，一個模組用於視覺理解，另一個模組用於遵循指令。這種雙重路由設計可以在兩個領域中進行專門適應，防止遺忘，同時提升效能。此外，我們提出了一個新穎的 CVIT 基準，它超越了現有的基準，進一步評估模型在各種任務中概括到未見任務和處理不同指令的能力。廣泛的實驗證明，SMoLoRA 在減輕雙重遺忘、改善對未見任務的概括以及確保遵循不同指令的穩健性方面，都優於現有方法。

##### **LLMs as Continuous Learners: Improving the Reproduction of Defective Code in Software Issues**
2411.13941v1 by Yalan Lin, Yingwei Ma, Rongyu Cao, Binhua Li, Fei Huang, Xiaodong Gu, Yongbin Li

Reproducing buggy code is the first and crucially important step in issue
resolving, as it aids in identifying the underlying problems and validating
that generated patches resolve the problem. While numerous approaches have been
proposed for this task, they primarily address common, widespread errors and
struggle to adapt to unique, evolving errors specific to individual code
repositories. To fill this gap, we propose EvoCoder, a multi-agent continuous
learning framework for issue code reproduction. EvoCoder adopts a reflection
mechanism that allows the LLM to continuously learn from previously resolved
problems and dynamically refine its strategies to new emerging challenges. To
prevent experience bloating, EvoCoder introduces a novel hierarchical
experience pool that enables the model to adaptively update common and
repo-specific experiences. Our experimental results show a 20\% improvement in
issue reproduction rates over existing SOTA methods. Furthermore, integrating
our reproduction mechanism significantly boosts the overall accuracy of the
existing issue-resolving pipeline.

摘要：重现错误代码是解决问题的第一个也是至关重要的一步，因为它有助于识别潜在的问题并验证所生成的补丁是否解决了问题。虽然针对此任务已提出许多方法，但它们主要解决常见、广泛的错误，并且难以适应特定于各个代码存储库的独特、不断发展的错误。为了填补这一空白，我们提出了 EvoCoder，一个用于问题代码重现的多代理连续学习框架。EvoCoder 采用了一种反射机制，允许 LLM 持续从先前解决的问题中学习，并动态地完善其应对新出现的挑战的策略。为了防止经验膨胀，EvoCoder 引入了一个新颖的分层经验池，使模型能够自适应地更新常见和特定于存储库的经验。我们的实验结果表明，与现有的 SOTA 方法相比，问题重现率提高了 20%。此外，集成我们的重现机制显著提高了现有问题解决管道的整体准确性。

##### **Learning to Cooperate with Humans using Generative Agents**
2411.13934v1 by Yancheng Liang, Daphne Chen, Abhishek Gupta, Simon S. Du, Natasha Jaques

Training agents that can coordinate zero-shot with humans is a key mission in
multi-agent reinforcement learning (MARL). Current algorithms focus on training
simulated human partner policies which are then used to train a Cooperator
agent. The simulated human is produced either through behavior cloning over a
dataset of human cooperation behavior, or by using MARL to create a population
of simulated agents. However, these approaches often struggle to produce a
Cooperator that can coordinate well with real humans, since the simulated
humans fail to cover the diverse strategies and styles employed by people in
the real world. We show \emph{learning a generative model of human partners}
can effectively address this issue. Our model learns a latent variable
representation of the human that can be regarded as encoding the human's unique
strategy, intention, experience, or style. This generative model can be
flexibly trained from any (human or neural policy) agent interaction data. By
sampling from the latent space, we can use the generative model to produce
different partners to train Cooperator agents. We evaluate our method --
\textbf{G}enerative \textbf{A}gent \textbf{M}odeling for \textbf{M}ulti-agent
\textbf{A}daptation (GAMMA) -- on Overcooked, a challenging cooperative cooking
game that has become a standard benchmark for zero-shot coordination. We
conduct an evaluation with real human teammates, and the results show that
GAMMA consistently improves performance, whether the generative model is
trained on simulated populations or human datasets. Further, we propose a
method for posterior sampling from the generative model that is biased towards
the human data, enabling us to efficiently improve performance with only a
small amount of expensive human interaction data.

摘要：<paragraph>訓練能與人類零次學習協調的代理程式，是多重代理強化學習 (MARL) 的一項關鍵任務。目前的演算法專注於訓練模擬的人類夥伴政策，然後用於訓練合作代理程式。模擬的人類是透過對人類合作行為資料集進行行為複製產生，或透過使用 MARL 建立模擬代理程式族群。然而，這些方法通常難以產生能與真實人類協調良好的合作代理程式，因為模擬的人類無法涵蓋現實世界中人類所使用的各種策略和風格。我們展示「學習人類夥伴的生成模型」能有效解決這個問題。我們的模型學習人類的潛在變數表示，可視為編碼人類的獨特策略、意圖、經驗或風格。這個生成模型能靈活地從任何（人類或神經網路政策）代理程式互動資料中進行訓練。透過從潛在空間取樣，我們可以使用生成模型產生不同的夥伴來訓練合作代理程式。我們評估我們的模型——多重代理適應的生成代理程式建模 (GAMMA)——在 Overcooked 上，這是一個具有挑戰性的合作烹飪遊戲，已成為零次學習協調的標準基準。我們與真實的人類隊友進行評估，結果顯示無論生成模型是針對模擬族群或人類資料集進行訓練，GAMMA 都能持續改善效能。此外，我們提出一個從生成模型中進行後驗取樣的模型，該模型偏向於人類資料，使我們能夠僅使用少量的昂貴人類互動資料來有效提升效能。</paragraph>

##### **XAgents: A Framework for Interpretable Rule-Based Multi-Agents Cooperation**
2411.13932v1 by Hailong Yang, Mingxian Gu, Renhuo Zhao, Fuping Hu, Zhaohong Deng, Yitang Chen

Extracting implicit knowledge and logical reasoning abilities from large
language models (LLMs) has consistently been a significant challenge. The
advancement of multi-agent systems has further en-hanced the capabilities of
LLMs. Inspired by the structure of multi-polar neurons (MNs), we propose the
XAgents framework, an in-terpretable multi-agent cooperative framework based on
the IF-THEN rule-based system. The IF-Parts of the rules are responsible for
logical reasoning and domain membership calculation, while the THEN-Parts are
comprised of domain expert agents that generate domain-specific contents.
Following the calculation of the member-ship, XAgetns transmits the task to the
disparate domain rules, which subsequently generate the various responses.
These re-sponses are analogous to the answers provided by different experts to
the same question. The final response is reached at by eliminat-ing the
hallucinations and erroneous knowledge of the LLM through membership
computation and semantic adversarial genera-tion of the various domain rules.
The incorporation of rule-based interpretability serves to bolster user
confidence in the XAgents framework. We evaluate the efficacy of XAgents
through a com-parative analysis with the latest AutoAgents, in which XAgents
demonstrated superior performance across three distinct datasets. We perform
post-hoc interpretable studies with SHAP algorithm and case studies, proving
the interpretability of XAgent in terms of input-output feature correlation and
rule-based semantics.

摘要：<paragraph>從大型語言模型 (LLM) 中萃取隱含知識和邏輯推理能力一直都是一項重大挑戰。多主體系統的進展進一步增強了 LLM 的能力。受多極神經元 (MN) 的結構啟發，我們提出 XAgents 框架，一個基於 IF-THEN 規則系統的可解釋多主體合作框架。規則的 IF 部分負責邏輯推理和領域成員計算，而 THEN 部分由產生特定領域內容的領域專家主體組成。在計算成員資格後，XAgetns 將任務傳遞給不同的領域規則，隨後生成各種回應。這些回應類似於不同專家對同一個問題提供的答案。最終的回應是透過消除 LLM 的幻覺和錯誤知識，藉由成員計算和各種領域規則的語義對抗產生而達成的。基於規則的可解釋性的納入有助於提升使用者對 XAgents 框架的信心。我們透過與最新的 AutoAgents 進行比較分析來評估 XAgents 的效能，其中 XAgents 在三個不同的資料集上展現出優異的效能。我們使用 SHAP 演算法和案例研究進行事後可解釋性研究，證明 XAgent 在輸入輸出特徵關聯性和基於規則的語義方面的可解釋性。</paragraph>

##### **Split Federated Learning Over Heterogeneous Edge Devices: Algorithm and Optimization**
2411.13907v1 by Yunrui Sun, Gang Hu, Yinglei Teng, Dunbo Cai

Split Learning (SL) is a promising collaborative machine learning approach,
enabling resource-constrained devices to train models without sharing raw data,
while reducing computational load and preserving privacy simultaneously.
However, current SL algorithms face limitations in training efficiency and
suffer from prolonged latency, particularly in sequential settings, where the
slowest device can bottleneck the entire process due to heterogeneous resources
and frequent data exchanges between clients and servers. To address these
challenges, we propose the Heterogeneous Split Federated Learning (HSFL)
framework, which allows resource-constrained clients to train their
personalized client-side models in parallel, utilizing different cut layers.
Aiming to mitigate the impact of heterogeneous environments and accelerate the
training process, we formulate a latency minimization problem that optimizes
computational and transmission resources jointly. Additionally, we design a
resource allocation algorithm that combines the Sample Average Approximation
(SAA), Genetic Algorithm (GA), Lagrangian relaxation and Branch and Bound
(B\&B) methods to efficiently solve this problem. Simulation results
demonstrate that HSFL outperforms other frameworks in terms of both convergence
rate and model accuracy on heterogeneous devices with non-iid data, while the
optimization algorithm is better than other baseline methods in reducing
latency.

摘要：分離式學習 (SL) 是一種有前景的協作機器學習方法，
讓資源受限的裝置能夠在不共用原始資料的情況下訓練模型，
同時減少運算負載並維護隱私。
然而，目前的 SL 演算法在訓練效率上遇到限制，
並在順序設定中遭受延遲過長的問題，特別是在順序設定中，
由於異質資源和客戶端與伺服器之間頻繁的資料交換，
最慢的裝置會成為整個流程的瓶頸。為了應對這些挑戰，
我們提出異質分離式聯邦學習 (HSFL) 架構，
允許資源受限的客戶端並行訓練其個人化的客戶端模型，
利用不同的切割層。為了減輕異質環境的影響並加速
訓練流程，我們制定了一個延遲最小化問題，
以最佳化運算和傳輸資源。此外，我們設計了一個
資源分配演算法，結合樣本平均近似 (SAA)、遺傳演算法 (GA)、
拉格朗日鬆弛和分支定界 (B&B) 方法來有效解決這個問題。
模擬結果證明，在具有非獨立同分布資料的異質裝置上，
HSFL 在收斂率和模型準確度方面都優於其他架構，
而最佳化演算法在降低延遲方面優於其他基準方法。

##### **Towards Full Delegation: Designing Ideal Agentic Behaviors for Travel Planning**
2411.13904v1 by Song Jiang, Da JU, Andrew Cohen, Sasha Mitts, Aaron Foss, Justine T Kao, Xian Li, Yuandong Tian

How are LLM-based agents used in the future? While many of the existing work
on agents has focused on improving the performance of a specific family of
objective and challenging tasks, in this work, we take a different perspective
by thinking about full delegation: agents take over humans' routine
decision-making processes and are trusted by humans to find solutions that fit
people's personalized needs and are adaptive to ever-changing context. In order
to achieve such a goal, the behavior of the agents, i.e., agentic behaviors,
should be evaluated not only on their achievements (i.e., outcome evaluation),
but also how they achieved that (i.e., procedure evaluation). For this, we
propose APEC Agent Constitution, a list of criteria that an agent should follow
for good agentic behaviors, including Accuracy, Proactivity, Efficiency and
Credibility. To verify whether APEC aligns with human preferences, we develop
APEC-Travel, a travel planning agent that proactively extracts hidden
personalized needs via multi-round dialog with travelers. APEC-Travel is
constructed purely from synthetic data generated by Llama3.1-405B-Instruct with
a diverse set of travelers' persona to simulate rich distribution of dialogs.
Iteratively fine-tuned to follow APEC Agent Constitution, APEC-Travel surpasses
baselines by 20.7% on rule-based metrics and 9.1% on LLM-as-a-Judge scores
across the constitution axes.

摘要：未來 LLM 基礎代理如何使用？儘管許多現有代理工作都專注於改善特定目標和挑戰任務的執行成效，但在此工作中，我們採用不同的觀點，思考全面委派：代理接手人類的例行決策過程，並獲得人類信任，為符合個人化需求且能適應不斷變化的脈絡找出解決方案。為了達成此一目標，代理的行為，亦即代理行為，應不僅根據其成就（亦即結果評估），還應根據其達成目標的方式（亦即程序評估）進行評估。為此，我們提出 APEC 代理憲法，這是一份代理應遵循的準則清單，以展現良好的代理行為，包括準確性、主動性、效率和可信度。為驗證 APEC 是否符合人類偏好，我們開發了 APEC-Travel，這是一個主動透過多輪對話從旅客身上找出隱藏個人化需求的旅遊規劃代理。APEC-Travel 純粹建構自 Llama3.1-405B-Instruct 所產生的合成資料，並具備多元的旅客角色，以模擬對話的豐富分佈。APEC-Travel 經過反覆微調以遵循 APEC 代理憲法，在基於規則的指標上超越基準 20.7%，在 LLM 作為評審分數上超越憲法軸線 9.1%。

##### **AmpliNetECG12: A lightweight SoftMax-based relativistic amplitude amplification architecture for 12 lead ECG classification**
2411.13903v1 by Shreya Srivastava

The urgent need to promptly detect cardiac disorders from 12-lead
Electrocardiograms using limited computations is motivated by the heart's fast
and complex electrical activity and restricted computational power of portable
devices. Timely and precise diagnoses are crucial since delays might
significantly impact patient health outcomes. This research presents a novel
deep-learning architecture that aims to diagnose heart abnormalities quickly
and accurately. We devised a new activation function called aSoftMax, designed
to improve the visibility of ECG deflections. The proposed activation function
is used with Convolutional Neural Network architecture to includes kernel
weight sharing across the ECG's various leads. This innovative method
thoroughly generalizes the global 12-lead ECG features and minimizes the
model's complexity by decreasing the trainable parameters. aSoftMax, combined
with enhanced CNN architecture yielded AmpliNetECG12, we obtain exceptional
accuracy of 84% in diagnosing cardiac disorders. AmpliNetECG12 shows
outstanding prediction ability when used with the CPSC2018 dataset for
arrhythmia classification. The model attains an F1-score of 80.71% and a
ROC-AUC score of 96.00%, with 280,000 trainable parameters which signifies the
lightweight yet efficient nature of AmpliNetECG12. The stochastic
characteristics of aSoftMax, a fundamental element of AmpliNetECG12, improve
prediction accuracy and also increasse the model's interpretability. This
feature enhances comprehension of important ECG segments in different forms of
arrhythmias, establishing a new standard of explainable architecture for
cardiac disorder classification.

摘要：<paragraph>由於心臟的快速且複雜的電氣活動和攜帶式裝置受限的運算能力，因此迫切需要使用 12 導程心電圖來快速偵測心臟疾病。及時且精確的診斷至關重要，因為延誤可能會對患者的健康狀況產生重大影響。本研究提出了一種新穎的深度學習架構，旨在快速且準確地診斷心臟異常。我們設計了一個稱為 aSoftMax 的新激活函數，旨在提高心電圖偏轉的可見度。所提出的激活函數與卷積神經網路架構一起使用，以在心電圖的各種導程之間包含核權重共享。這種創新方法徹底概括了全球 12 導程心電圖特徵，並通過減少可訓練參數來最小化模型的複雜性。aSoftMax 結合增強的 CNN 架構產生了 AmpliNetECG12，我們在診斷心臟疾病方面獲得了 84% 的出色準確度。AmpliNetECG12 在與 CPSC2018 資料集一起用於心律不整分類時顯示出出色的預測能力。該模型以 280,000 個可訓練參數獲得 80.71% 的 F1 分數和 96.00% 的 ROC-AUC 分數，這表明 AmpliNetECG12 的輕量級且高效的本質。aSoftMax 的隨機特徵是 AmpliNetECG12 的基本要素，它提高了預測準確度，也增加了模型的可解釋性。此功能增強了對不同形式心律不整中重要心電圖區段的理解，為心臟疾病分類建立了一個新的可解釋架構標準。</paragraph>

##### **PIORS: Personalized Intelligent Outpatient Reception based on Large Language Model with Multi-Agents Medical Scenario Simulation**
2411.13902v1 by Zhijie Bao, Qingyun Liu, Ying Guo, Zhengqiang Ye, Jun Shen, Shirong Xie, Jiajie Peng, Xuanjing Huang, Zhongyu Wei

In China, receptionist nurses face overwhelming workloads in outpatient
settings, limiting their time and attention for each patient and ultimately
reducing service quality. In this paper, we present the Personalized
Intelligent Outpatient Reception System (PIORS). This system integrates an
LLM-based reception nurse and a collaboration between LLM and hospital
information system (HIS) into real outpatient reception setting, aiming to
deliver personalized, high-quality, and efficient reception services.
Additionally, to enhance the performance of LLMs in real-world healthcare
scenarios, we propose a medical conversational data generation framework named
Service Flow aware Medical Scenario Simulation (SFMSS), aiming to adapt the LLM
to the real-world environments and PIORS settings. We evaluate the
effectiveness of PIORS and SFMSS through automatic and human assessments
involving 15 users and 15 clinical experts. The results demonstrate that
PIORS-Nurse outperforms all baselines, including the current state-of-the-art
model GPT-4o, and aligns with human preferences and clinical needs. Further
details and demo can be found at https://github.com/FudanDISC/PIORS

摘要：<paragraph>在中国，接待护士在门诊环境中面临着繁重的工作量，限制了他们对每位患者的时间和注意力，最终降低了服务质量。在本文中，我们提出了个性化智能门诊接待系统 (PIORS)。该系统将基于 LLM 的接待护士和 LLM 与医院信息系统 (HIS) 之间的协作整合到真实的门诊接待环境中，旨在提供个性化、高质量和高效的接待服务。此外，为了提高 LLM 在真实医疗保健场景中的性能，我们提出了一个名为服务流感知医疗场景模拟 (SFMSS) 的医疗会话数据生成框架，旨在使 LLM 适应真实世界环境和 PIORS 设置。我们通过涉及 15 名用户和 15 名临床专家的自动和人工评估来评估 PIORS 和 SFMSS 的有效性。结果表明，PIORS-Nurse 优于所有基线，包括当前最先进的模型 GPT-4o，并且符合人类偏好和临床需求。更多详细信息和演示可在 https://github.com/FudanDISC/PIORS 中找到</paragraph>

##### **When Online Algorithms Influence the Environment: A Dynamical Systems Analysis of the Unintended Consequences**
2411.13883v1 by Prabhat Lankireddy, Jayakrishnan Nair, D Manjunath

We analyze the effect that online algorithms have on the environment that
they are learning. As a motivation, consider recommendation systems that use
online algorithms to learn optimal product recommendations based on user and
product attributes. It is well known that the sequence of recommendations
affects user preferences. However, typical learning algorithms treat the user
attributes as static and disregard the impact of their recommendations on user
preferences. Our interest is to analyze the effect of this mismatch between the
model assumption of a static environment, and the reality of an evolving
environment affected by the recommendations. To perform this analysis, we first
introduce a model for a generic coupled evolution of the parameters that are
being learned, and the environment that is affected by it. We then frame a
linear bandit recommendation system (RS) into this generic model where the
users are characterized by a state variable that evolves based on the sequence
of recommendations. The learning algorithm of the RS does not explicitly
account for this evolution and assumes that the users are static. A dynamical
system model that captures the coupled evolution of the population state and
the learning algorithm is described, and its equilibrium behavior is analyzed.
We show that when the recommendation algorithm is able to learn the population
preferences in the presence of this mismatch, the algorithm induces similarity
in the preferences of the user population. In particular, we present results on
how different properties of the recommendation algorithm, namely the user
attribute space and the exploration-exploitation tradeoff, effect the
population preferences when they are learned by the algorithm. We demonstrate
these results using model simulations.

摘要：<paragraph>我們分析線上演算法對其學習的環境所產生的影響。作為動機，考慮使用線上演算法來學習最佳產品推薦的推薦系統，該系統是根據使用者和產品屬性。眾所周知，推薦順序會影響使用者的偏好。然而，典型的學習演算法將使用者屬性視為靜態的，並忽略其推薦對使用者偏好的影響。我們的興趣是分析靜態環境的模型假設與受推薦影響的演化環境現實之間的不匹配的影響。為了執行此分析，我們首先為正在學習的參數和受其影響的環境引入一個通用耦合演化的模型。然後，我們將線性賭徒推薦系統 (RS) 構建到這個通用模型中，其中使用者以根據推薦順序演化的狀態變數為特徵。RS 的學習演算法並未明確考慮此演化，並假設使用者是靜態的。描述了一個捕捉族群狀態和學習演算法的耦合演化的動態系統模型，並分析其平衡行為。我們表明，當推薦演算法能夠在這種不匹配的情況下學習族群偏好時，該演算法會誘導使用者族群偏好的相似性。特別是，我們展示了推薦演算法的不同屬性（即使用者屬性空間和探索開發權衡）如何影響演算法學習時族群偏好的結果。我們使用模型模擬來證明這些結果。</paragraph>

##### **Next-Generation Phishing: How LLM Agents Empower Cyber Attackers**
2411.13874v1 by Khalifa Afane, Wenqi Wei, Ying Mao, Junaid Farooq, Juntao Chen

The escalating threat of phishing emails has become increasingly
sophisticated with the rise of Large Language Models (LLMs). As attackers
exploit LLMs to craft more convincing and evasive phishing emails, it is
crucial to assess the resilience of current phishing defenses. In this study we
conduct a comprehensive evaluation of traditional phishing detectors, such as
Gmail Spam Filter, Apache SpamAssassin, and Proofpoint, as well as machine
learning models like SVM, Logistic Regression, and Naive Bayes, in identifying
both traditional and LLM-rephrased phishing emails. We also explore the
emerging role of LLMs as phishing detection tools, a method already adopted by
companies like NTT Security Holdings and JPMorgan Chase. Our results reveal
notable declines in detection accuracy for rephrased emails across all
detectors, highlighting critical weaknesses in current phishing defenses. As
the threat landscape evolves, our findings underscore the need for stronger
security controls and regulatory oversight on LLM-generated content to prevent
its misuse in creating advanced phishing attacks. This study contributes to the
development of more effective Cyber Threat Intelligence (CTI) by leveraging
LLMs to generate diverse phishing variants that can be used for data
augmentation, harnessing the power of LLMs to enhance phishing detection, and
paving the way for more robust and adaptable threat detection systems.

摘要：隨著大型語言模型 (LLM) 的興起，網路釣魚電子郵件的威脅日益嚴重且複雜。由於攻擊者利用 LLM 製作更具說服力和規避性的網路釣魚電子郵件，因此評估當前網路釣魚防禦的韌性至關重要。在這項研究中，我們對傳統的網路釣魚偵測器進行全面評估，例如 Gmail 垃圾郵件過濾器、Apache SpamAssassin 和 Proofpoint，以及機器學習模型（例如 SVM、邏輯迴歸和樸素貝氏），以識別傳統和 LLM 改寫的網路釣魚電子郵件。我們還探討了 LLM 作為網路釣魚偵測工具的新興角色，這是一種 NTT Security Holdings 和 JPMorgan Chase 等公司已採用的方法。我們的結果顯示，所有偵測器對改寫電子郵件的偵測準確度都有顯著下降，突顯出當前網路釣魚防禦的嚴重弱點。隨著威脅環境的演變，我們的研究結果強調需要對 LLM 生成的內容進行更強的安全性控制和法規監督，以防止其被濫用於製造進階網路釣魚攻擊。本研究有助於開發更有效的網路威脅情報 (CTI)，方法是利用 LLM 生成可用于資料擴充的多樣化網路釣魚變體，利用 LLM 的功能來增強網路釣魚偵測，並為更強大且適應性更強的威脅偵測系統鋪路。

##### **Robust Detection of Watermarks for Large Language Models Under Human Edits**
2411.13868v1 by Xiang Li, Feng Ruan, Huiyuan Wang, Qi Long, Weijie J. Su

Watermarking has offered an effective approach to distinguishing text
generated by large language models (LLMs) from human-written text. However, the
pervasive presence of human edits on LLM-generated text dilutes watermark
signals, thereby significantly degrading detection performance of existing
methods. In this paper, by modeling human edits through mixture model
detection, we introduce a new method in the form of a truncated goodness-of-fit
test for detecting watermarked text under human edits, which we refer to as
Tr-GoF. We prove that the Tr-GoF test achieves optimality in robust detection
of the Gumbel-max watermark in a certain asymptotic regime of substantial text
modifications and vanishing watermark signals. Importantly, Tr-GoF achieves
this optimality \textit{adaptively} as it does not require precise knowledge of
human edit levels or probabilistic specifications of the LLMs, in contrast to
the optimal but impractical (Neyman--Pearson) likelihood ratio test. Moreover,
we establish that the Tr-GoF test attains the highest detection efficiency rate
in a certain regime of moderate text modifications. In stark contrast, we show
that sum-based detection rules, as employed by existing methods, fail to
achieve optimal robustness in both regimes because the additive nature of their
statistics is less resilient to edit-induced noise. Finally, we demonstrate the
competitive and sometimes superior empirical performance of the Tr-GoF test on
both synthetic data and open-source LLMs in the OPT and LLaMA families.

摘要：<paragraph>浮水印提供了一種有效的方法來區分大型語言模型 (LLM) 生成的文字和人工撰寫的文字。然而，人工編輯在 LLM 生成的文字中普遍存在，會稀釋浮水印訊號，從而顯著降低現有方法的偵測效能。在本文中，我們透過混合模型偵測來建構人工編輯，並以截斷的優良擬合檢定形式提出一個新方法，用於偵測人工編輯下的浮水印文字，我們稱之為 Tr-GoF。我們證明 Tr-GoF 檢定在大量文字修改和消失的浮水印訊號的特定漸近範圍內，在 Gumbel-max 浮水印的穩健偵測中達到最佳化。重要的是，Tr-GoF 以「自適應」方式達到這個最佳化，因為它不需要人工編輯層級或 LLM 機率規格的精確知識，這與最佳但不可行的 (Neyman--Pearson) 似然比檢定形成對比。此外，我們確立 Tr-GoF 檢定在特定範圍的適度文字修改中達到最高的偵測效率率。形成鮮明對比的是，我們表明現有方法所採用的基於總和的偵測規則無法在兩種範圍內達到最佳穩健性，因為它們統計資料的加法性質較無法抵禦編輯引起的雜訊。最後，我們展示 Tr-GoF 檢定在 OPT 和 LLaMA 家族的合成資料和開源 LLM 上具有競爭力，有時甚至表現優異。</paragraph>

##### **Generative Fuzzy System for Sequence Generation**
2411.13867v1 by Hailong Yang, Zhaohong Deng, Wei Zhang, Zhuangzhuang Zhao, Guanjin Wang, Kup-sze Choi

Generative Models (GMs), particularly Large Language Models (LLMs), have
garnered significant attention in machine learning and artificial intelligence
for their ability to generate new data by learning the statistical properties
of training data and creating data that resemble the original. This capability
offers a wide range of applications across various domains. However, the
complex structures and numerous model parameters of GMs make the input-output
processes opaque, complicating the understanding and control of outputs.
Moreover, the purely data-driven learning mechanism limits GM's ability to
acquire broader knowledge. There remains substantial potential for enhancing
the robustness and generalization capabilities of GMs. In this work, we
introduce the fuzzy system, a classical modeling method that combines data and
knowledge-driven mechanisms, to generative tasks. We propose a novel Generative
Fuzzy System framework, named GenFS, which integrates the deep learning
capabilities of GM with the interpretability and dual-driven mechanisms of
fuzzy systems. Specifically, we propose an end-to-end GenFS-based model for
sequence generation, called FuzzyS2S. A series of experimental studies were
conducted on 12 datasets, covering three distinct categories of generative
tasks: machine translation, code generation, and summary generation. The
results demonstrate that FuzzyS2S outperforms the Transformer in terms of
accuracy and fluency. Furthermore, it exhibits better performance on some
datasets compared to state-of-the-art models T5 and CodeT5.

摘要：生成模型 (GM)，尤其是大語言模型 (LLM)，因其通過學習訓練資料的統計特性並建立類似原始資料的資料來生成新資料的能力，而在機器學習和人工智慧領域備受關注。這種能力在各個領域提供了廣泛的應用。然而，GM 的複雜結構和大量的模型參數使得輸入輸出過程不透明，加劇了對輸出理解和控制的複雜性。此外，純粹由資料驅動的學習機制限制了 GM 獲取更廣泛知識的能力。GM 的穩健性和泛化能力仍有很大的增強潛力。在這項工作中，我們引入了模糊系統，一種結合資料和知識驅動機制的經典建模方法，用於生成任務。我們提出了一個名為 GenFS 的新穎生成模糊系統框架，它將 GM 的深度學習能力與模糊系統的可解釋性和雙重驅動機制相結合。具體來說，我們提出了基於 GenFS 的端到端模型，用於序列生成，稱為 FuzzyS2S。在 12 個資料集上進行了一系列實驗研究，涵蓋了生成任務的三個不同類別：機器翻譯、程式碼生成和摘要生成。結果表明，FuzzyS2S 在準確性和流暢性方面優於 Transformer。此外，與最先進的模型 T5 和 CodeT5 相比，它在某些資料集上表現出更好的效能。

##### **HARec: Hyperbolic Graph-LLM Alignment for Exploration and Exploitation in Recommender Systems**
2411.13865v1 by Qiyao Ma, Menglin Yang, Mingxuan Ju, Tong Zhao, Neil Shah, Rex Ying

Modern recommendation systems often create information cocoons, limiting
users' exposure to diverse content. To enhance user experience, a crucial
challenge is developing systems that can balance content exploration and
exploitation, allowing users to adjust their recommendation preferences.
Intuitively, this balance can be achieved through a tree-structured
representation, where depth search facilitates exploitation and breadth search
enables exploration. However, current works face two challenges to achieve this
target: (1) Euclidean methods fail to fully capture hierarchical structures and
lack flexibility in balancing exploration-exploitation, while (2) hyperbolic
approaches, despite better hierarchical modeling, suffer from insufficient
semantic alignment due to their reliance on Euclidean text encoders. To address
these challenges, we propose HARec, a hyperbolic representation learning
framework that jointly aligns user-item collaborative information with textual
descriptions in hyperbolic space. Our framework introduces two key technique
novelty: (1) a hierarchical-aware graph-llm alignment mechanism that enables
better hierarchical representation, and (2) a hyperbolic hierarchical tree
structure that facilitates user-adjustable exploration-exploitation trade-offs.
Extensive experiments demonstrate that HARec consistently outperforms both
Euclidean and hyperbolic baselines, achieving up to 5.49% improvement in
utility metrics and 11.39% increase in diversity metrics.

摘要：現代推薦系統經常會產生資訊繭房，限制使用者接觸到多元的內容。為了提升使用者體驗，一個重要的挑戰在於開發出能夠平衡內容探索與開發的系統，讓使用者調整他們的推薦偏好。直覺上來說，這個平衡可以透過樹狀結構的表達來達成，其中深度搜尋能促進開發，廣度搜尋則能促進探索。然而，現有的工作在達成這個目標時面臨兩個挑戰：(1) 歐幾里得方法無法完全捕捉階層結構，在平衡探索與開發時也缺乏彈性，而 (2) 雙曲線方法儘管有更好的階層建模，但由於依賴歐幾里得文本編碼器，導致語意對齊不足。為了應對這些挑戰，我們提出 HARec，一個雙曲線表達學習架構，它在雙曲線空間中聯合對齊使用者項目協作資訊和文本描述。我們的架構引入了兩個關鍵技術新穎性：(1) 一個階層感知圖形 llm 對齊機制，它能促進更好的階層表達，以及 (2) 一個雙曲線階層樹狀結構，它能促進使用者可調整的探索開發權衡。廣泛的實驗證明，HARec 持續優於歐幾里得和雙曲線基線，在效用指標上提升了 5.49%，在多樣性指標上提升了 11.39%。

##### **Exploratory Study Of Human-AI Interaction For Hindustani Music**
2411.13846v1 by Nithya Shikarpur, Cheng-Zhi Anna Huang

This paper presents a study of participants interacting with and using
GaMaDHaNi, a novel hierarchical generative model for Hindustani vocal contours.
To explore possible use cases in human-AI interaction, we conducted a user
study with three participants, each engaging with the model through three
predefined interaction modes. Although this study was conducted "in the wild"-
with the model unadapted for the shift from the training data to real-world
interaction - we use it as a pilot to better understand the expectations,
reactions, and preferences of practicing musicians when engaging with such a
model. We note their challenges as (1) the lack of restrictions in model
output, and (2) the incoherence of model output. We situate these challenges in
the context of Hindustani music and aim to suggest future directions for the
model design to address these gaps.

摘要：本文介紹參與者與 GaMaDHaNi 互動和使用情況的研究，GaMaDHaNi 是一種新型的階層式生成模型，用於印度斯坦語聲調輪廓。為了探索人機互動中的可能用例，我們進行了一項使用者研究，共有三名參與者參與，每位參與者透過三種預定義的互動模式與模型互動。儘管這項研究是在「野外」進行的，但模型並未針對從訓練資料轉移到真實世界互動的情況進行調整，我們將其用作試點研究，以便更深入瞭解實務音樂家在與此類模型互動時的期望、反應和偏好。我們注意到他們的挑戰在於：(1) 模型輸出缺乏限制，以及 (2) 模型輸出的不連貫性。我們將這些挑戰置於印度斯坦音樂的背景中，並旨在建議模型設計的未來方向，以解決這些差距。

##### **Interactive and Expressive Code-Augmented Planning with Large Language Models**
2411.13826v1 by Anthony Z. Liu, Xinhe Wang, Jacob Sansom, Yao Fu, Jongwook Choi, Sungryull Sohn, Jaekyeom Kim, Honglak Lee

Large Language Models (LLMs) demonstrate strong abilities in common-sense
reasoning and interactive decision-making, but often struggle with complex,
long-horizon planning tasks. Recent techniques have sought to structure LLM
outputs using control flow and other code-adjacent techniques to improve
planning performance. These techniques include using variables (to track
important information) and functions (to divide complex tasks into smaller
re-usable sub-tasks). However, purely code-based approaches can be error-prone
and insufficient for handling ambiguous or unstructured data. To address these
challenges, we propose REPL-Plan, an LLM planning approach that is fully
code-expressive (it can utilize all the benefits of code) while also being
dynamic (it can flexibly adapt from errors and use the LLM for fuzzy
situations). In REPL-Plan, an LLM solves tasks by interacting with a
Read-Eval-Print Loop (REPL), which iteratively executes and evaluates code,
similar to language shells or interactive code notebooks, allowing the model to
flexibly correct errors and handle tasks dynamically. We demonstrate that
REPL-Plan achieves strong results across various planning domains compared to
previous methods.

摘要：大型語言模型 (LLM) 在常識推理和互動式決策制定方面表現出強大的能力，但通常難以應付複雜、長期的規劃任務。最近的技術已尋求使用控制流程和其他與程式碼相鄰的技術來建構 LLM 輸出，以改善規劃效能。這些技術包括使用變數（追蹤重要資訊）和函式（將複雜任務分為較小的可重複使用子任務）。然而，純粹基於程式碼的方法容易出錯，且不足以處理模稜兩可或非結構化的資料。為了應對這些挑戰，我們提出了 REPL-Plan，這是一種 LLM 規劃方法，它完全具有程式碼表達能力（它可以利用程式碼的所有優點），同時也是動態的（它可以靈活地從錯誤中調整，並使用 LLM 來處理模糊情況）。在 REPL-Plan 中，LLM 透過與讀取-評估-列印迴圈 (REPL) 互動來解決任務，類似於語言殼層或互動式程式碼筆記本，允許模型靈活地更正錯誤並動態地處理任務。我們證明了與先前的各種方法相比，REPL-Plan 在各種規劃領域中都取得了顯著的成果。

##### **Heterophilic Graph Neural Networks Optimization with Causal Message-passing**
2411.13821v1 by Botao Wang, Jia Li, Heng Chang, Keli Zhang, Fugee Tsung

In this work, we discover that causal inference provides a promising approach
to capture heterophilic message-passing in Graph Neural Network (GNN). By
leveraging cause-effect analysis, we can discern heterophilic edges based on
asymmetric node dependency. The learned causal structure offers more accurate
relationships among nodes. To reduce the computational complexity, we introduce
intervention-based causal inference in graph learning. We first simplify causal
analysis on graphs by formulating it as a structural learning model and define
the optimization problem within the Bayesian scheme. We then present an
analysis of decomposing the optimization target into a consistency penalty and
a structure modification based on cause-effect relations. We then estimate this
target by conditional entropy and present insights into how conditional entropy
quantifies the heterophily. Accordingly, we propose CausalMP, a causal
message-passing discovery network for heterophilic graph learning, that
iteratively learns the explicit causal structure of input graphs. We conduct
extensive experiments in both heterophilic and homophilic graph settings. The
result demonstrates that the our model achieves superior link prediction
performance. Training on causal structure can also enhance node representation
in classification task across different base models.

摘要：在这项工作中，我们发现因果推理提供了一种有前途的方法，可以捕捉图神经网络 (GNN) 中的异质信息传递。通过利用因果分析，我们可以根据不对称节点依赖关系来识别异质边。学习到的因果结构提供了节点之间更准确的关系。为了降低计算复杂度，我们在图学习中引入了基于干预的因果推理。我们首先通过将其表述为结构学习模型来简化图上的因果分析，并在贝叶斯方案中定义优化问题。然后，我们提出了将优化目标分解为一致性惩罚和基于因果关系的结构修改的分析。然后，我们通过条件熵估计这个目标，并展示条件熵如何量化异质性。相应地，我们提出了 CausalMP，一个用于异质图学习的因果信息传递发现网络，它迭代学习输入图的显式因果结构。我们在异质和同质图设置中进行了广泛的实验。结果表明，我们的模型实现了卓越的链接预测性能。在因果结构上进行训练还可以增强不同基础模型在分类任务中的节点表示。

##### **InstCache: A Predictive Cache for LLM Serving**
2411.13820v1 by Longwei Zou, Tingfeng Liu, Kai Chen, Jiangang Kong, Yangdong Deng

Large language models are revolutionizing every aspect of human life.
However, the unprecedented power comes at the cost of significant computing
intensity, suggesting long latency and large energy footprint. Key-Value Cache
and Semantic Cache have been proposed as a solution to the above problem, but
both suffer from limited scalability due to significant memory cost for each
token or instruction embeddings. Motivated by the observations that most
instructions are short, repetitive and predictable by LLMs, we propose to
predict user-instructions by an instruction-aligned LLM and store them in a
predictive cache, so-called InstCache. We introduce an instruction
pre-population algorithm based on the negative log likelihood of instructions,
determining the cache size with regard to the hit rate. The proposed InstCache
is efficiently implemented as a hash table with minimal lookup latency for
deployment. Experimental results show that InstCache can achieve up to 51.34%
hit rate on LMSys dataset, which corresponds to a 2x speedup, at a memory cost
of only 4.5GB.

摘要：大型語言模型正在改變人類生活的各個方面。
然而，這種前所未有的能力是以巨大的運算強度為代價的，這意味著延遲時間長和能源消耗大。關鍵值快取和語義快取已被提出作為上述問題的解決方案，但由於每個符號或指令嵌入的記憶體成本巨大，這兩種方法都受到可擴充性有限的困擾。由於大多數指令都是簡短、重複且可由 LLM 預測的，因此我們提出通過指令對齊的 LLM 預測使用者指令，並將它們儲存在一個預測快取中，稱為 InstCache。我們引入了一種基於指令負對數似然的指令預填充演算法，根據命中率確定快取大小。建議的 InstCache 以雜湊表的形式有效實作，具有最小的查詢延遲，以便部署。實驗結果表明，InstCache 可以對 LMSys 資料集實現高達 51.34% 的命中率，這相當於速度提升 2 倍，而記憶體成本僅為 4.5GB。

##### **AutoMixQ: Self-Adjusting Quantization for High Performance Memory-Efficient Fine-Tuning**
2411.13814v1 by Changhai Zhou, Shiyang Zhang, Yuhua Zhou, Zekai Liu, Shichao Weng

Fine-tuning large language models (LLMs) under resource constraints is a
significant challenge in deep learning. Low-Rank Adaptation (LoRA), pruning,
and quantization are all effective methods for improving resource efficiency.
However, combining them directly often results in suboptimal performance,
especially with uniform quantization across all model layers. This is due to
the complex, uneven interlayer relationships introduced by pruning,
necessitating more refined quantization strategies. To address this, we propose
AutoMixQ, an end-to-end optimization framework that selects optimal
quantization configurations for each LLM layer. AutoMixQ leverages lightweight
performance models to guide the selection process, significantly reducing time
and computational resources compared to exhaustive search methods. By
incorporating Pareto optimality, AutoMixQ balances memory usage and
performance, approaching the upper bounds of model capability under strict
resource constraints. Our experiments on widely used benchmarks show that
AutoMixQ reduces memory consumption while achieving superior performance. For
example, at a 30\% pruning rate in LLaMA-7B, AutoMixQ achieved 66.21\% on BoolQ
compared to 62.45\% for LoRA and 58.96\% for LoftQ, while reducing memory
consumption by 35.5\% compared to LoRA and 27.5\% compared to LoftQ.

摘要：在资源受限的情况下微调大型语言模型 (LLM) 是深度学习中的一项重大挑战。低秩自适应 (LoRA)、剪枝和量化都是提高资源效率的有效方法。然而，直接组合它们通常会导致次优性能，尤其是在所有模型层上进行均匀量化时。这是由于剪枝引入的复杂、不均匀的层间关系，需要更精细的量化策略。为了解决这个问题，我们提出了 AutoMixQ，这是一个端到端优化框架，用于为每个 LLM 层选择最佳量化配置。AutoMixQ 利用轻量级性能模型来指导选择过程，与穷举搜索方法相比，显著减少了时间和计算资源。通过结合帕累托最优性，AutoMixQ 平衡了内存使用和性能，在严格的资源限制下接近模型能力的上限。我们在广泛使用的基准测试中的实验表明，AutoMixQ 减少了内存消耗，同时实现了卓越的性能。例如，在 LLaMA-7B 中以 30% 的剪枝率，AutoMixQ 在 BoolQ 上达到 66.21%，而 LoRA 为 62.45%，LoftQ 为 58.96%，同时与 LoRA 相比减少了 35.5% 的内存消耗，与 LoftQ 相比减少了 27.5%。

##### **SemiKong: Curating, Training, and Evaluating A Semiconductor Industry-Specific Large Language Model**
2411.13802v1 by Christopher Nguyen, William Nguyen, Atsushi Suzuki, Daisuke Oku, Hong An Phan, Sang Dinh, Zooey Nguyen, Anh Ha, Shruti Raghavan, Huy Vo, Thang Nguyen, Lan Nguyen, Yoshikuni Hirayama

Large Language Models (LLMs) have demonstrated the potential to address some
issues within the semiconductor industry. However, they are often
general-purpose models that lack the specialized knowledge needed to tackle the
unique challenges of this sector, such as the intricate physics and chemistry
of semiconductor devices and processes. SemiKong, the first industry-specific
LLM for the semiconductor domain, provides a foundation that can be used to
develop tailored proprietary models. With SemiKong 1.0, we aim to develop a
foundational model capable of understanding etching problems at an expert
level. Our key contributions include (a) curating a comprehensive corpus of
semiconductor-related texts, (b) creating a foundational model with in-depth
semiconductor knowledge, and (c) introducing a framework for integrating expert
knowledge, thereby advancing the evaluation process of domain-specific AI
models. Through fine-tuning a pre-trained LLM using our curated dataset, we
have shown that SemiKong outperforms larger, general-purpose LLMs in various
semiconductor manufacturing and design tasks. Our extensive experiments
underscore the importance of developing domain-specific LLMs as a foundation
for company- or tool-specific proprietary models, paving the way for further
research and applications in the semiconductor domain. Code and dataset will be
available at https://github.com/aitomatic/semikong

摘要：大型語言模型 (LLM) 已展現出解決半導體產業內部一些問題的潛力。然而，它們通常是缺乏解決此產業獨特挑戰所需專業知識的通用模型，例如半導體裝置和製程的複雜物理和化學。SemiKong 是半導體領域的第一個產業特定 LLM，它提供了可供用於開發客製化專有模型的基礎。有了 SemiKong 1.0，我們的目標是開發一個基礎模型，能夠在專家層級理解蝕刻問題。我們的關鍵貢獻包括：(a) 策劃一個全面的半導體相關文本語料庫、(b) 建立一個具有深入半導體知識的基礎模型，以及 (c) 介紹一個整合專家知識的架構，藉此推進領域特定 AI 模型的評估程序。透過使用我們策劃的資料集微調一個預先訓練的 LLM，我們已證明 SemiKong 在各種半導體製造和設計任務中優於更大、更通用的 LLM。我們廣泛的實驗強調了開發領域特定 LLM 作為公司或工具特定專有模型基礎的重要性，為半導體領域的進一步研究和應用鋪路。程式碼和資料集將可在 https://github.com/aitomatic/semikong 取得

##### **Explaining GPT-4's Schema of Depression Using Machine Behavior Analysis**
2411.13800v1 by Adithya V Ganesan, Vasudha Varadarajan, Yash Kumar Lal, Veerle C. Eijsbroek, Katarina Kjell, Oscar N. E. Kjell, Tanuja Dhanasekaran, Elizabeth C. Stade, Johannes C. Eichstaedt, Ryan L. Boyd, H. Andrew Schwartz, Lucie Flek

Use of large language models such as ChatGPT (GPT-4) for mental health
support has grown rapidly, emerging as a promising route to assess and help
people with mood disorders, like depression. However, we have a limited
understanding of GPT-4's schema of mental disorders, that is, how it internally
associates and interprets symptoms. In this work, we leveraged contemporary
measurement theory to decode how GPT-4 interrelates depressive symptoms to
inform both clinical utility and theoretical understanding. We found GPT-4's
assessment of depression: (a) had high overall convergent validity (r = .71
with self-report on 955 samples, and r = .81 with experts judgments on 209
samples); (b) had moderately high internal consistency (symptom
inter-correlates r = .23 to .78 ) that largely aligned with literature and
self-report; except that GPT-4 (c) underemphasized suicidality's -- and
overemphasized psychomotor's -- relationship with other symptoms, and (d) had
symptom inference patterns that suggest nuanced hypotheses (e.g. sleep and
fatigue are influenced by most other symptoms while feelings of
worthlessness/guilt is mostly influenced by depressed mood).

摘要：大型語言模型（例如 ChatGPT (GPT-4)）在心理健康方面的使用迅速增長，成為評估和幫助情緒障礙（例如憂鬱症）患者的有前途途徑。然而，我們對 GPT-4 的心理障礙模式了解有限，也就是說，它在內部如何關聯和詮釋症狀。在這項工作中，我們利用當代測量理論來解碼 GPT-4 如何將憂鬱症狀相互關聯，以告知臨床效用和理論理解。我們發現 GPT-4 對憂鬱症的評估：(a) 具有很高的整體收斂效度（r = .71，來自 955 個樣本的自陳，以及 r = .81，來自 209 個樣本的專家判斷）；(b) 具有中等偏高的內部一致性（症狀互相關係 r = .23 至 .78），這在很大程度上與文獻和自陳一致；GPT-4 (c) 除了低估自殺傾向與其他症狀的關係，以及高估精神運動與其他症狀的關係之外，(d) 還有暗示細微假設的症狀推論模式（例如，睡眠和疲勞受大多數其他症狀影響，而無價值感/罪惡感則主要受憂鬱情緒影響）。

##### **NewsInterview: a Dataset and a Playground to Evaluate LLMs' Ground Gap via Informational Interviews**
2411.13779v1 by Michael Lu, Hyundong Justin Cho, Weiyan Shi, Jonathan May, Alexander Spangher

Large Language Models (LLMs) have demonstrated impressive capabilities in
generating coherent text but often struggle with grounding language and
strategic dialogue. To address this gap, we focus on journalistic interviews, a
domain rich in grounding communication and abundant in data. We curate a
dataset of 40,000 two-person informational interviews from NPR and CNN, and
reveal that LLMs are significantly less likely than human interviewers to use
acknowledgements and to pivot to higher-level questions. Realizing that a
fundamental deficit exists in multi-turn planning and strategic thinking, we
develop a realistic simulated environment, incorporating source personas and
persuasive elements, in order to facilitate the development of agents with
longer-horizon rewards. Our experiments show that while source LLMs mimic human
behavior in information sharing, interviewer LLMs struggle with recognizing
when questions are answered and engaging persuasively, leading to suboptimal
information extraction across model size and capability. These findings
underscore the need for enhancing LLMs' strategic dialogue capabilities.

摘要：大型語言模型 (LLM) 在生成連貫文字方面展現了令人印象深刻的能力，但常常在語言基礎和策略性對話方面遇到困難。為了解決這個差距，我們專注於新聞採訪，這是一個以基礎溝通和豐富數據為主的領域。我們從 NPR 和 CNN 策劃了一個包含 40,000 個雙人資訊性採訪的資料集，並揭示出 LLM 使用確認和轉向更高層次問題的可能性遠低於人類採訪者。意識到多輪規劃和策略性思考中存在根本缺陷，我們開發了一個逼真的模擬環境，結合來源角色和說服元素，以促進具有更長遠回報的代理開發。我們的實驗表明，雖然來源 LLM 在資訊共享方面模仿人類行為，但採訪者 LLM 難以辨識問題何時獲得解答並進行有說服力的互動，導致跨模型大小和能力的資訊提取次佳。這些發現強調了加強 LLM 策略性對話能力的必要性。

##### **Benchmarking GPT-4 against Human Translators: A Comprehensive Evaluation Across Languages, Domains, and Expertise Levels**
2411.13775v1 by Jianhao Yan, Pingchuan Yan, Yulong Chen, Jing Li, Xianchao Zhu, Yue Zhang

This study presents a comprehensive evaluation of GPT-4's translation
capabilities compared to human translators of varying expertise levels. Through
systematic human evaluation using the MQM schema, we assess translations across
three language pairs (Chinese$\longleftrightarrow$English,
Russian$\longleftrightarrow$English, and Chinese$\longleftrightarrow$Hindi) and
three domains (News, Technology, and Biomedical). Our findings reveal that
GPT-4 achieves performance comparable to junior-level translators in terms of
total errors, while still lagging behind senior translators. Unlike traditional
Neural Machine Translation systems, which show significant performance
degradation in resource-poor language directions, GPT-4 maintains consistent
translation quality across all evaluated language pairs. Through qualitative
analysis, we identify distinctive patterns in translation approaches: GPT-4
tends toward overly literal translations and exhibits lexical inconsistency,
while human translators sometimes over-interpret context and introduce
hallucinations. This study represents the first systematic comparison between
LLM and human translators across different proficiency levels, providing
valuable insights into the current capabilities and limitations of LLM-based
translation systems.

摘要：本研究對 GPT-4 的翻譯能力進行了全面評估，並將其與不同專業水準的人類翻譯員進行比較。透過使用 MQM 架構進行系統性的人類評估，我們評估了三組語言對（中文 ↔ 英文、俄文 ↔ 英文和中文 ↔ 印地文）和三個領域（新聞、科技和生物醫學）的翻譯。我們的研究結果顯示，GPT-4 在總錯誤方面達到了與初階翻譯員相當的表現，但仍落後於資深翻譯員。與傳統的神經機器翻譯系統不同，後者在資源匱乏的語言方向上表現出顯著的效能下降，而 GPT-4 在所有評估的語言對中都維持了一致的翻譯品質。透過定性分析，我們在翻譯方法中發現了獨特的模式：GPT-4 傾向於過度直譯，並表現出詞彙不一致，而人類翻譯員有時會過度詮釋上下文並引入幻覺。本研究代表了 LLM 和不同熟練程度的人類翻譯員之間的首次系統性比較，對基於 LLM 的翻譯系統的當前能力和限制提供了有價值的見解。

##### **FastRAG: Retrieval Augmented Generation for Semi-structured Data**
2411.13773v1 by Amar Abane, Anis Bekri, Abdella Battou

Efficiently processing and interpreting network data is critical for the
operation of increasingly complex networks. Recent advances in Large Language
Models (LLM) and Retrieval-Augmented Generation (RAG) techniques have improved
data processing in network management. However, existing RAG methods like
VectorRAG and GraphRAG struggle with the complexity and implicit nature of
semi-structured technical data, leading to inefficiencies in time, cost, and
retrieval. This paper introduces FastRAG, a novel RAG approach designed for
semi-structured data. FastRAG employs schema learning and script learning to
extract and structure data without needing to submit entire data sources to an
LLM. It integrates text search with knowledge graph (KG) querying to improve
accuracy in retrieving context-rich information. Evaluation results demonstrate
that FastRAG provides accurate question answering, while improving up to 90% in
time and 85% in cost compared to GraphRAG.

摘要：有效率地處理和解讀網路資料對於日益複雜的網路操作至關重要。大型語言模型 (LLM) 和檢索增強產生 (RAG) 技術的最新進展已經改善了網路管理中的資料處理。然而，現有的 RAG 方法（例如 VectorRAG 和 GraphRAG）難以應付半結構化技術資料的複雜性和隱含性質，導致時間、成本和檢索效率不彰。本文介紹 FastRAG，一種專為半結構化資料設計的新穎 RAG 方法。FastRAG 使用架構學習和腳本學習來萃取和建構資料，而無需將整個資料來源提交給 LLM。它將文字搜尋與知識圖譜 (KG) 查詢整合，以提高檢索內容豐富資訊的準確性。評估結果證明，FastRAG 提供了準確的問答，同時與 GraphRAG 相比，時間改善了 90%，成本改善了 85%。

##### **An Evaluation-Driven Approach to Designing LLM Agents: Process and Architecture**
2411.13768v1 by Boming Xia, Qinghua Lu, Liming Zhu, Zhenchang Xing, Dehai Zhao, Hao Zhang

The advent of Large Language Models (LLMs) has enabled the development of LLM
agents capable of autonomously achieving under-specified goals and continuously
evolving through post-deployment improvement, sometimes without requiring code
or model updates. Conventional approaches, such as pre-defined test cases and
code/model redevelopment pipelines, are inadequate for addressing the unique
challenges of LLM agent development, particularly in terms of quality and risk
control. This paper introduces an evaluation-driven design approach, inspired
by test-driven development, to address these challenges. Through a multivocal
literature review (MLR), we synthesize existing LLM evaluation methods and
propose a novel process model and reference architecture specifically designed
for LLM agents. The proposed approach integrates online and offline evaluations
to support adaptive runtime adjustments and systematic offline redevelopment,
improving runtime pipelines, artifacts, system architecture, and LLMs by
continuously incorporating evaluation results, including fine-grained feedback
from human and AI evaluators.

摘要：大型語言模型 (LLM) 的出現促成了 LLM 代理的開發，此類代理能夠在未指定目標下自主實現目標，並透過部署後持續改進不斷進化，有時不需要程式碼或模型更新。傳統方法，例如預先定義的測試案例和程式碼/模型重新開發管線，不足以解決 LLM 代理開發的獨特挑戰，特別是在品質和風險控制方面。本文介紹了一種評估驅動設計方法，靈感來自測試驅動開發，以應對這些挑戰。透過多聲道文獻回顧 (MLR)，我們綜合現有的 LLM 評估方法，並提出專門為 LLM 代理設計的新穎流程模型和參考架構。所提出的方法整合線上和離線評估，以支援適應性執行時期調整和系統性離線重新開發，透過持續納入評估結果（包括來自人類和 AI 評估者的細微回饋），改善執行時期管線、人工製品、系統架構和 LLM。

##### **Tiny-Align: Bridging Automatic Speech Recognition and Large Language Model on the Edge**
2411.13766v1 by Ruiyang Qin, Dancheng Liu, Gelei Xu, Zheyu Yan, Chenhui Xu, Yuting Hu, X. Sharon Hu, Jinjun Xiong, Yiyu Shi

The combination of Large Language Models (LLM) and Automatic Speech
Recognition (ASR), when deployed on edge devices (called edge ASR-LLM), can
serve as a powerful personalized assistant to enable audio-based interaction
for users. Compared to text-based interaction, edge ASR-LLM allows accessible
and natural audio interactions. Unfortunately, existing ASR-LLM models are
mainly trained in high-performance computing environments and produce
substantial model weights, making them difficult to deploy on edge devices.
More importantly, to better serve users' personalized needs, the ASR-LLM must
be able to learn from each distinct user, given that audio input often contains
highly personalized characteristics that necessitate personalized on-device
training. Since individually fine-tuning the ASR or LLM often leads to
suboptimal results due to modality-specific limitations, end-to-end training
ensures seamless integration of audio features and language understanding
(cross-modal alignment), ultimately enabling a more personalized and efficient
adaptation on edge devices. However, due to the complex training requirements
and substantial computational demands of existing approaches, cross-modal
alignment between ASR audio and LLM can be challenging on edge devices. In this
work, we propose a resource-efficient cross-modal alignment framework that
bridges ASR and LLMs on edge devices to handle personalized audio input. Our
framework enables efficient ASR-LLM alignment on resource-constrained devices
like NVIDIA Jetson Orin (8GB RAM), achieving 50x training time speedup while
improving the alignment quality by more than 50\%. To the best of our
knowledge, this is the first work to study efficient ASR-LLM alignment on
resource-constrained edge devices.

摘要：大型語言模型 (LLM) 和自動語音辨識 (ASR) 的結合，在部署於邊緣裝置（稱為邊緣 ASR-LLM）時，可用作強大的個人化助理，讓使用者能進行基於音訊的互動。與基於文字的互動相比，邊緣 ASR-LLM 允許無障礙且自然的音訊互動。不幸的是，現有的 ASR-LLM 模型主要是在高性能運算環境中訓練，並產生大量的模型權重，這使得它們難以部署在邊緣裝置上。更重要的是，為了更好地滿足使用者的個人化需求，ASR-LLM 必須能夠從每個不同的使用者學習，因為音訊輸入通常包含高度個人化的特徵，需要進行個人化的裝置上訓練。由於個別微調 ASR 或 LLM 通常會因特定於模式的限制而導致次佳結果，端到端訓練確保音訊特徵和語言理解（跨模式對齊）的無縫整合，最終實現更個人化且更有效率的邊緣裝置適應。然而，由於現有方法複雜的訓練需求和大量的運算需求，ASR 音訊和 LLM 之間的跨模式對齊在邊緣裝置上可能具有挑戰性。在這項工作中，我們提出一個資源有效率的跨模式對齊架構，在邊緣裝置上橋接 ASR 和 LLM 以處理個人化的音訊輸入。我們的架構可以在資源受限的裝置（例如 NVIDIA Jetson Orin（8GB RAM））上實現高效的 ASR-LLM 對齊，將訓練時間加速 50 倍，同時將對齊品質提升 50% 以上。據我們所知，這是第一個研究在資源受限的邊緣裝置上進行高效 ASR-LLM 對齊的工作。

##### **A Framework for Evaluating LLMs Under Task Indeterminacy**
2411.13760v1 by Luke Guerdan, Hanna Wallach, Solon Barocas, Alexandra Chouldechova

Large language model (LLM) evaluations often assume there is a single correct
response -- a gold label -- for each item in the evaluation corpus. However,
some tasks can be ambiguous -- i.e., they provide insufficient information to
identify a unique interpretation -- or vague -- i.e., they do not clearly
indicate where to draw the line when making a determination. Both ambiguity and
vagueness can cause task indeterminacy -- the condition where some items in the
evaluation corpus have more than one correct response. In this paper, we
develop a framework for evaluating LLMs under task indeterminacy. Our framework
disentangles the relationships between task specification, human ratings, and
LLM responses in the LLM evaluation pipeline. Using our framework, we conduct a
synthetic experiment showing that evaluations that use the "gold label"
assumption underestimate the true performance. We also provide a method for
estimating an error-adjusted performance interval given partial knowledge about
indeterminate items in the evaluation corpus. We conclude by outlining
implications of our work for the research community.

摘要：大型語言模型 (LLM) 評估通常假設評估語料庫中的每個項目都有單一的正確
回應——一個黃金標籤。然而，有些任務可能是模稜兩可的——即，它們提供的資訊不足以
識別出一個獨特的詮釋——或含糊不清的——即，它們沒有明確指出在做出判斷時應在哪裡劃清界線。模稜兩可和含糊不清都會導致任務不確定性——評估語料庫中某些項目有多個正確回應的情況。在本文中，我們
開發了一個在任務不確定性下評估 LLM 的框架。我們的框架解開了 LLM 評估管道中任務規範、人類評分和 LLM 回應之間的關係。使用我們的框架，我們進行了一個合成實驗，表明使用「黃金標籤」假設的評估低估了真實效能。我們還提供了一種方法，用於估計評估語料庫中不確定項目的部分知識所給出的誤差調整效能區間。我們最後概述了我們的工作對研究社群的影響。

##### **AttentionBreaker: Adaptive Evolutionary Optimization for Unmasking Vulnerabilities in LLMs through Bit-Flip Attacks**
2411.13757v1 by Sanjay Das, Swastik Bhattacharya, Souvik Kundu, Shamik Kundu, Anand Menon, Arnab Raha, Kanad Basu

Large Language Models (LLMs) have revolutionized natural language processing
(NLP), excelling in tasks like text generation and summarization. However,
their increasing adoption in mission-critical applications raises concerns
about hardware-based threats, particularly bit-flip attacks (BFAs). BFAs,
enabled by fault injection methods such as Rowhammer, target model parameters
in memory, compromising both integrity and performance. Identifying critical
parameters for BFAs in the vast parameter space of LLMs poses significant
challenges. While prior research suggests transformer-based architectures are
inherently more robust to BFAs compared to traditional deep neural networks, we
challenge this assumption. For the first time, we demonstrate that as few as
three bit-flips can cause catastrophic performance degradation in an LLM with
billions of parameters. Current BFA techniques are inadequate for exploiting
this vulnerability due to the difficulty of efficiently identifying critical
parameters within the immense parameter space. To address this, we propose
AttentionBreaker, a novel framework tailored for LLMs that enables efficient
traversal of the parameter space to identify critical parameters. Additionally,
we introduce GenBFA, an evolutionary optimization strategy designed to refine
the search further, isolating the most critical bits for an efficient and
effective attack. Empirical results reveal the profound vulnerability of LLMs
to AttentionBreaker. For example, merely three bit-flips (4.129 x 10^-9% of
total parameters) in the LLaMA3-8B-Instruct 8-bit quantized (W8) model result
in a complete performance collapse: accuracy on MMLU tasks drops from 67.3% to
0%, and Wikitext perplexity skyrockets from 12.6 to 4.72 x 10^5. These findings
underscore the effectiveness of AttentionBreaker in uncovering and exploiting
critical vulnerabilities within LLM architectures.

摘要：大型語言模型 (LLM) 徹底改變了自然語言處理 (NLP)，在文本生成和摘要等任務中表現出色。然而，它們在任務關鍵型應用中的採用越來越多，這引起了對基於硬體的威脅的擔憂，特別是位元翻轉攻擊 (BFA)。BFA 由故障注入方法（例如 Rowhammer）啟用，針對記憶體中的模型參數，損害完整性和效能。在 LLM 巨大參數空間中識別 BFA 的關鍵參數提出了重大挑戰。雖然先前的研究表明，與傳統深度神經網路相比，基於Transformer的架構天生對 BFA 更具魯棒性，但我們挑戰了這一假設。我們首次證明，僅三處位元翻轉即可導致具有數十億個參數的 LLM 發生災難性的效能下降。由於難以在巨大的參數空間中有效識別關鍵參數，目前的 BFA 技術不足以利用此漏洞。為了解決這個問題，我們提出了 AttentionBreaker，這是一個專門針對 LLM 的新框架，它可以有效遍歷參數空間以識別關鍵參數。此外，我們引入了 GenBFA，這是一種進化優化策略，旨在進一步優化搜尋，隔離最關鍵的位元，以進行有效率且有效的攻擊。經驗結果揭示了 LLM 對 AttentionBreaker 的嚴重漏洞。例如，LLaMA3-8B-Instruct 8 位元量化 (W8) 模型中僅三處位元翻轉（總參數的 4.129 x 10^-9%）就會導致效能完全崩潰：MMLU 任務的準確度從 67.3% 降至 0%，而 Wikitext 的困惑度從 12.6 飆升至 4.72 x 10^5。這些發現強調了 AttentionBreaker 在揭露和利用 LLM 架構中的關鍵漏洞方面的有效性。

##### **AI-Driven Agents with Prompts Designed for High Agreeableness Increase the Likelihood of Being Mistaken for a Human in the Turing Test**
2411.13749v1 by U. León-Domínguez, E. D. Flores-Flores, A. J. García-Jasso, M. K. Gómez-Cuellar, D. Torres-Sánchez, A. Basora-Marimon

Large Language Models based on transformer algorithms have revolutionized
Artificial Intelligence by enabling verbal interaction with machines akin to
human conversation. These AI agents have surpassed the Turing Test, achieving
confusion rates up to 50%. However, challenges persist, especially with the
advent of robots and the need to humanize machines for improved Human-AI
collaboration. In this experiment, three GPT agents with varying levels of
agreeableness (disagreeable, neutral, agreeable) based on the Big Five
Inventory were tested in a Turing Test. All exceeded a 50% confusion rate, with
the highly agreeable AI agent surpassing 60%. This agent was also recognized as
exhibiting the most human-like traits. Various explanations in the literature
address why these GPT agents were perceived as human, including psychological
frameworks for understanding anthropomorphism. These findings highlight the
importance of personality engineering as an emerging discipline in artificial
intelligence, calling for collaboration with psychology to develop ergonomic
psychological models that enhance system adaptability in collaborative
activities.

摘要：大型語言模型基於轉換器演算法，透過讓機器與人類對話般互動，徹底革新了人工智慧。這些人工智慧代理人已超越圖靈測試，達到高達 50% 的混淆率。然而，挑戰依然存在，特別是隨著機器人的出現以及為了改善人機協作而使機器人性化的需求。在這個實驗中，三個具有不同程度的親和性（令人不快、中立、令人愉快）的 GPT 代理人根據大五人格量表在圖靈測試中受到測試。所有代理人都超過了 50% 的混淆率，高度令人愉快的 AI 代理人更超過了 60%。這個代理人也被認為展現出最像人類的特質。文獻中各種解釋說明了為什麼這些 GPT 代理人被認為是人類，包括用於理解擬人化的心理架構。這些發現突顯了人格工程作為人工智慧中一個新興領域的重要性，呼籲與心理學合作，開發符合人體工學的心理模型，以增強系統在協作活動中的適應性。

##### **Federated Continual Learning for Edge-AI: A Comprehensive Survey**
2411.13740v1 by Zi Wang, Fei Wu, Feng Yu, Yurui Zhou, Jia Hu, Geyong Min

Edge-AI, the convergence of edge computing and artificial intelligence (AI),
has become a promising paradigm that enables the deployment of advanced AI
models at the network edge, close to users. In Edge-AI, federated continual
learning (FCL) has emerged as an imperative framework, which fuses knowledge
from different clients while preserving data privacy and retaining knowledge
from previous tasks as it learns new ones. By so doing, FCL aims to ensure
stable and reliable performance of learning models in dynamic and distributed
environments. In this survey, we thoroughly review the state-of-the-art
research and present the first comprehensive survey of FCL for Edge-AI. We
categorize FCL methods based on three task characteristics: federated class
continual learning, federated domain continual learning, and federated task
continual learning. For each category, an in-depth investigation and review of
the representative methods are provided, covering background, challenges,
problem formalisation, solutions, and limitations. Besides, existing real-world
applications empowered by FCL are reviewed, indicating the current progress and
potential of FCL in diverse application domains. Furthermore, we discuss and
highlight several prospective research directions of FCL such as
algorithm-hardware co-design for FCL and FCL with foundation models, which
could provide insights into the future development and practical deployment of
FCL in the era of Edge-AI.

摘要：邊緣人工智慧（Edge-AI）是邊緣運算和人工智慧（AI）的融合，
已成為一種有前途的範例，可以在靠近使用者的網路邊緣部署進階的人工智慧模型。在 Edge-AI 中，聯邦持續學習（FCL）已成為一個必要的架構，它融合了來自不同用戶的知識，同時在學習新任務時保護資料隱私和保留先前任務的知識。透過這樣做，FCL 旨在確保學習模型在動態且分散的環境中具有穩定且可靠的效能。在本次調查中，我們徹底檢視了最先進的研究，並提出了 FCL 在 Edge-AI 中的第一份全面調查。我們根據三項任務特性對 FCL 方法進行分類：聯邦類別持續學習、聯邦領域持續學習和聯邦任務持續學習。對於每個類別，我們提供了代表性方法的深入調查和回顧，涵蓋背景、挑戰、問題形式化、解決方案和限制。此外，我們回顧了由 FCL 賦能的現有真實世界應用程式，說明了 FCL 在各種應用領域的當前進度和潛力。此外，我們討論並強調了 FCL 的幾個潛在研究方向，例如 FCL 的演算法硬體共同設計和具備基礎模型的 FCL，這些方向可以提供對 FCL 在 Edge-AI 時代的未來發展和實際部署的見解。

##### **Assessing Gender Bias in LLMs: Comparing LLM Outputs with Human Perceptions and Official Statistics**
2411.13738v1 by Tetiana Bas

This study investigates gender bias in large language models (LLMs) by
comparing their gender perception to that of human respondents, U.S. Bureau of
Labor Statistics data, and a 50% no-bias benchmark. We created a new evaluation
set using occupational data and role-specific sentences. Unlike common
benchmarks included in LLM training data, our set is newly developed,
preventing data leakage and test set contamination. Five LLMs were tested to
predict the gender for each role using single-word answers. We used
Kullback-Leibler (KL) divergence to compare model outputs with human
perceptions, statistical data, and the 50% neutrality benchmark. All LLMs
showed significant deviation from gender neutrality and aligned more with
statistical data, still reflecting inherent biases.

摘要：本研究透過將大型語言模型 (LLM) 的性別感知與人類受訪者、美國勞工統計局資料和 50% 無偏見基準進行比較，來調查大型語言模型中的性別偏見。我們使用職業資料和角色特定句子建立了一個新的評量集。與 LLM 訓練資料中常見的基準不同，我們的集合是新開發的，可防止資料外洩和測試集污染。測試了五個 LLM，使用單字答案來預測每個角色的性別。我們使用 Kullback-Leibler (KL) 距離來比較模型輸出與人類感知、統計資料和 50% 中立基準。所有 LLM 都顯示出與性別中立有顯著偏差，並且更符合統計資料，仍然反映出固有的偏見。

##### **Exploring Large Language Models for Climate Forecasting**
2411.13724v1 by Yang Wang, Hassan A. Karimi

With the increasing impacts of climate change, there is a growing demand for
accessible tools that can provide reliable future climate information to
support planning, finance, and other decision-making applications. Large
language models (LLMs), such as GPT-4, present a promising approach to bridging
the gap between complex climate data and the general public, offering a way for
non-specialist users to obtain essential climate insights through natural
language interaction. However, an essential challenge remains under-explored:
evaluating the ability of LLMs to provide accurate and reliable future climate
predictions, which is crucial for applications that rely on anticipating
climate trends. In this study, we investigate the capability of GPT-4 in
predicting rainfall at short-term (15-day) and long-term (12-month) scales. We
designed a series of experiments to assess GPT's performance under different
conditions, including scenarios with and without expert data inputs. Our
results indicate that GPT, when operating independently, tends to generate
conservative forecasts, often reverting to historical averages in the absence
of clear trend signals. This study highlights both the potential and challenges
of applying LLMs for future climate predictions, providing insights into their
integration with climate-related applications and suggesting directions for
enhancing their predictive capabilities in the field.

摘要：隨著氣候變遷的影響日益加劇，對於可提供可靠未來氣候資訊的平易近人工具需求日益殷切，以支援規劃、財務和其他決策制定應用程式。大型語言模型 (LLM)，例如 GPT-4，提供了一種有前景的方法，可以彌合複雜氣候資料與一般大眾之間的鴻溝，提供一種方式讓非專家使用者透過自然語言互動取得必要的氣候見解。然而，有一個重要的挑戰仍然未被充分探討：評估 LLM 提供準確且可靠未來氣候預測的能力，這對於依賴預測氣候趨勢的應用程式至關重要。在本研究中，我們調查了 GPT-4 在短期 (15 天) 和長期 (12 個月) 尺度預測降雨的能力。我們設計了一系列實驗，以評估 GPT 在不同條件下的效能，包括有和沒有專家資料輸入的場景。我們的結果表明，GPT 在獨立運作時，傾向於產生保守的預測，在沒有明確趨勢信號的情況下，通常會恢復到歷史平均值。本研究強調了將 LLM 應用於未來氣候預測的潛力與挑戰，提供了將其整合到與氣候相關的應用程式中的見解，並提出了在該領域增強其預測能力的方向。

##### **SimPhony: A Device-Circuit-Architecture Cross-Layer Modeling and Simulation Framework for Heterogeneous Electronic-Photonic AI System**
2411.13715v1 by Ziang Yin, Meng Zhang, Amir Begovic, Rena Huang, Jeff Zhang, Jiaqi Gu

Electronic-photonic integrated circuits (EPICs) offer transformative
potential for next-generation high-performance AI but require interdisciplinary
advances across devices, circuits, architecture, and design automation. The
complexity of hybrid systems makes it challenging even for domain experts to
understand distinct behaviors and interactions across design stack. The lack of
a flexible, accurate, fast, and easy-to-use EPIC AI system simulation framework
significantly limits the exploration of hardware innovations and system
evaluations on common benchmarks. To address this gap, we propose SimPhony, a
cross-layer modeling and simulation framework for heterogeneous
electronic-photonic AI systems. SimPhony offers a platform that enables (1)
generic, extensible hardware topology representation that supports
heterogeneous multi-core architectures with diverse photonic tensor core
designs; (2) optics-specific dataflow modeling with unique multi-dimensional
parallelism and reuse beyond spatial/temporal dimensions; (3) data-aware energy
modeling with realistic device responses, layout-aware area estimation, link
budget analysis, and bandwidth-adaptive memory modeling; and (4) seamless
integration with model training framework for hardware/software co-simulation.
By providing a unified, versatile, and high-fidelity simulation platform,
SimPhony enables researchers to innovate and evaluate EPIC AI hardware across
multiple domains, facilitating the next leap in emerging AI hardware. We
open-source our codes at https://github.com/ScopeX-ASU/SimPhony

摘要：電子光子整合電路 (EPIC) 為次世代高效能人工智慧帶來轉型潛力，但需要在裝置、電路、架構和設計自動化方面跨領域進展。混合系統的複雜性讓即使是領域專家也很難理解設計堆疊中的不同行為和互動。缺乏一個靈活、精確、快速且易於使用的 EPIC 人工智慧系統模擬架構，大幅限制了對硬體創新和系統評估的探索。為了解決這個差距，我們提出 SimPhony，一個異質電子光子人工智慧系統的跨層建模和模擬架構。SimPhony 提供了一個平台，可以實現 (1) 支援異質多核心架構和多樣光子張量核心設計的通用、可擴充硬體拓撲表示；(2) 具有獨特多維度平行性和空間/時間維度之外的再利用的光學特定資料流建模；(3) 透過實際裝置反應、考量佈局的面積估計、鏈路預算分析和頻寬適應式記憶體建模來進行資料感知的能源建模；以及 (4) 與模型訓練架構無縫整合，以進行硬體/軟體協同模擬。透過提供一個統一、多功能且高保真度的模擬平台，SimPhony 能讓研究人員跨多個領域創新和評估 EPIC 人工智慧硬體，促進新興人工智慧硬體的下一步飛躍。我們的程式碼已在 https://github.com/ScopeX-ASU/SimPhony 開源。

##### **Retrieval-Augmented Generation for Domain-Specific Question Answering: A Case Study on Pittsburgh and CMU**
2411.13691v1 by Haojia Sun, Yaqi Wang, Shuting Zhang

We designed a Retrieval-Augmented Generation (RAG) system to provide large
language models with relevant documents for answering domain-specific questions
about Pittsburgh and Carnegie Mellon University (CMU). We extracted over 1,800
subpages using a greedy scraping strategy and employed a hybrid annotation
process, combining manual and Mistral-generated question-answer pairs,
achieving an inter-annotator agreement (IAA) score of 0.7625. Our RAG framework
integrates BM25 and FAISS retrievers, enhanced with a reranker for improved
document retrieval accuracy. Experimental results show that the RAG system
significantly outperforms a non-RAG baseline, particularly in time-sensitive
and complex queries, with an F1 score improvement from 5.45% to 42.21% and
recall of 56.18%. This study demonstrates the potential of RAG systems in
enhancing answer precision and relevance, while identifying areas for further
optimization in document retrieval and model training.

摘要：我們設計了一個檢索增強生成 (RAG) 系統，為大型語言模型提供相關文件，以回答有關匹茲堡和卡內基美隆大學 (CMU) 的特定領域問題。我們使用貪婪的網路爬取策略提取了超過 1,800 個子頁面，並採用了混合註釋處理程序，結合手動和 Mistral 生成的問答對，達到了 0.7625 的標記間一致性 (IAA) 分數。我們的 RAG 框架整合了 BM25 和 FAISS 檢索器，並增強了重新排序器，以提高文件檢索準確度。實驗結果表明，RAG 系統明顯優於非 RAG 基準，特別是在時間敏感和複雜的查詢中，F1 分數從 5.45% 提高到 42.21%，召回率為 56.18%。本研究展示了 RAG 系統在增強答案精確度和相關性方面的潛力，同時找出文件檢索和模型訓練中進一步最佳化的領域。

##### **Hierarchical Text Classification (HTC) vs. eXtreme Multilabel Classification (XML): Two Sides of the Same Medal**
2411.13687v1 by Nerijus Bertalis, Paul Granse, Ferhat Gül, Florian Hauss, Leon Menkel, David Schüler, Tom Speier, Lukas Galke, Ansgar Scherp

Assigning a subset of labels from a fixed pool of labels to a given input
text is a text classification problem with many real-world applications, such
as in recommender systems. Two separate research streams address this issue.
Hierarchical Text Classification (HTC) focuses on datasets with smaller label
pools of hundreds of entries, accompanied by a semantic label hierarchy. In
contrast, eXtreme Multi-Label Text Classification (XML) considers very large
label pools with up to millions of entries, in which the labels are not
arranged in any particular manner. However, in XML, a common approach is to
construct an artificial hierarchy without any semantic information before or
during the training process. Here, we investigate how state-of-the-art models
from one domain perform when trained and tested on datasets from the other
domain. The HBGL and HGLCR models from the HTC domain are trained and tested on
the datasets Wiki10-31K, AmazonCat-13K, and Amazon-670K from the XML domain. On
the other side, the XML models CascadeXML and XR-Transformer are trained and
tested on the datasets Web of Science, The New York Times Annotated Corpus, and
RCV1-V2 from the HTC domain. HTC models, on the other hand, are not equipped to
handle the size of XML datasets and achieve poor transfer results. The code and
numerous files that are needed to reproduce our results can be obtained from
https://github.com/FloHauss/XMC_HTC

摘要：將固定標籤池中的標籤子集指定給特定輸入文字是文字分類問題，在許多實際應用中會遇到，例如推薦系統。兩個獨立的研究領域探討此議題。階層式文字分類 (HTC) 專注於標籤池較小的資料集，其中包含數百個項目，並附帶語意標籤階層。相反地，極端多標籤文字分類 (XML) 考量包含數百萬個項目的非常大的標籤池，其中標籤並未以任何特定方式排列。然而，在 XML 中，一種常見的方法是在訓練過程中或之前建構一個不含任何語意資訊的人工階層。在此，我們探討來自一個領域的最新模型在針對來自另一個領域的資料集進行訓練和測試時如何執行。HTC 領域的 HBGL 和 HGLCR 模型在 XML 領域的資料集 Wiki10-31K、AmazonCat-13K 和 Amazon-670K 上進行訓練和測試。另一方面，XML 模型 CascadeXML 和 XR-Transformer 在 HTC 領域的資料集 Web of Science、The New York Times Annotated Corpus 和 RCV1-V2 上進行訓練和測試。另一方面，HTC 模型並未具備處理 XML 資料集大小的能力，且轉移結果不佳。可以在 https://github.com/FloHauss/XMC_HTC 取得重現我們結果所需的程式碼和大量檔案。

##### **Hymba: A Hybrid-head Architecture for Small Language Models**
2411.13676v1 by Xin Dong, Yonggan Fu, Shizhe Diao, Wonmin Byeon, Zijia Chen, Ameya Sunil Mahabaleshwarkar, Shih-Yang Liu, Matthijs Van Keirsbilck, Min-Hung Chen, Yoshi Suhara, Yingyan Lin, Jan Kautz, Pavlo Molchanov

We propose Hymba, a family of small language models featuring a hybrid-head
parallel architecture that integrates transformer attention mechanisms with
state space models (SSMs) for enhanced efficiency. Attention heads provide
high-resolution recall, while SSM heads enable efficient context summarization.
Additionally, we introduce learnable meta tokens that are prepended to prompts,
storing critical information and alleviating the "forced-to-attend" burden
associated with attention mechanisms. This model is further optimized by
incorporating cross-layer key-value (KV) sharing and partial sliding window
attention, resulting in a compact cache size. During development, we conducted
a controlled study comparing various architectures under identical settings and
observed significant advantages of our proposed architecture. Notably, Hymba
achieves state-of-the-art results for small LMs: Our Hymba-1.5B-Base model
surpasses all sub-2B public models in performance and even outperforms
Llama-3.2-3B with 1.32% higher average accuracy, an 11.67x cache size
reduction, and 3.49x throughput.

摘要：我們提出 Hymba，一個小型語言模型系列，具有整合Transformer注意力機制與狀態空間模型 (SSM) 的混合頭平行架構，以提高效率。注意力頭提供高解析度召回，而 SSM 頭則能有效地對內容進行摘要。此外，我們引入了可學習的元標記，並將其置於提示之前，儲存關鍵資訊，並減輕與注意力機制相關的「被迫關注」負擔。此模型進一步透過整合跨層鍵值 (KV) 共享和部分滑動視窗注意力進行最佳化，進而縮小快取大小。在開發過程中，我們進行了一項受控研究，在相同的設定下比較各種架構，並觀察到我們提出的架構具有顯著的優點。值得注意的是，Hymba 達到了小型語言模型的最新技術成果：我們的 Hymba-1.5B-Base 模型在效能上超越所有低於 2B 的公開模型，甚至以高出 1.32% 的平均準確度、減少 11.67 倍的快取大小和 3.49 倍的吞吐量，優於 Llama-3.2-3B。

##### **FabuLight-ASD: Unveiling Speech Activity via Body Language**
2411.13674v1 by Hugo Carneiro, Stefan Wermter

Active speaker detection (ASD) in multimodal environments is crucial for
various applications, from video conferencing to human-robot interaction. This
paper introduces FabuLight-ASD, an advanced ASD model that integrates facial,
audio, and body pose information to enhance detection accuracy and robustness.
Our model builds upon the existing Light-ASD framework by incorporating human
pose data, represented through skeleton graphs, which minimises computational
overhead. Using the Wilder Active Speaker Detection (WASD) dataset, renowned
for reliable face and body bounding box annotations, we demonstrate
FabuLight-ASD's effectiveness in real-world scenarios. Achieving an overall
mean average precision (mAP) of 94.3%, FabuLight-ASD outperforms Light-ASD,
which has an overall mAP of 93.7% across various challenging scenarios. The
incorporation of body pose information shows a particularly advantageous
impact, with notable improvements in mAP observed in scenarios with speech
impairment, face occlusion, and human voice background noise. Furthermore,
efficiency analysis indicates only a modest increase in parameter count (27.3%)
and multiply-accumulate operations (up to 2.4%), underscoring the model's
efficiency and feasibility. These findings validate the efficacy of
FabuLight-ASD in enhancing ASD performance through the integration of body pose
data. FabuLight-ASD's code and model weights are available at
https://github.com/knowledgetechnologyuhh/FabuLight-ASD.

摘要：<paragraph>在多模式環境中的主動說話者偵測 (ASD) 對於各種應用至關重要，從視訊會議到人機互動皆是如此。本文介紹了 FabuLight-ASD，這是一種先進的 ASD 模型，它整合了臉部、音訊和身體姿勢資訊，以增強偵測準確度和穩健性。我們的模型建構於現有的 Light-ASD 架構之上，透過納入人體姿勢資料（以骨架圖表表示），將運算開銷降至最低。使用以可靠的臉部和身體邊界框註解而聞名的 Wilder Active Speaker Detection (WASD) 資料集，我們展示了 FabuLight-ASD 在真實世界場景中的有效性。FabuLight-ASD 的整體平均平均準確度 (mAP) 達到 94.3%，在各種具有挑戰性的場景中都優於 Light-ASD，後者的整體 mAP 為 93.7%。人體姿勢資訊的納入顯示出特別有利的影響，在有言語障礙、臉部遮擋和人聲背景噪音的場景中，mAP 有顯著的提升。此外，效率分析僅顯示參數計數（27.3%）和乘累加運算（最多 2.4%）有小幅增加，這突顯了此模型的效率和可行性。這些發現驗證了 FabuLight-ASD 在整合人體姿勢資料後，可提升 ASD 效能。FabuLight-ASD 的程式碼和模型權重可在 https://github.com/knowledgetechnologyuhh/FabuLight-ASD 取得。</paragraph>

##### **No Free Delivery Service: Epistemic limits of passive data collection in complex social systems**
2411.13653v1 by Maximilian Nickel

Rapid model validation via the train-test paradigm has been a key driver for
the breathtaking progress in machine learning and AI. However, modern AI
systems often depend on a combination of tasks and data collection practices
that violate all assumptions ensuring test validity. Yet, without rigorous
model validation we cannot ensure the intended outcomes of deployed AI systems,
including positive social impact, nor continue to advance AI research in a
scientifically sound way. In this paper, I will show that for widely considered
inference settings in complex social systems the train-test paradigm does not
only lack a justification but is indeed invalid for any risk estimator,
including counterfactual and causal estimators, with high probability. These
formal impossibility results highlight a fundamental epistemic issue, i.e.,
that for key tasks in modern AI we cannot know whether models are valid under
current data collection practices. Importantly, this includes variants of both
recommender systems and reasoning via large language models, and neither
na\"ive scaling nor limited benchmarks are suited to address this issue. I am
illustrating these results via the widely used MovieLens benchmark and conclude
by discussing the implications of these results for AI in social systems,
including possible remedies such as participatory data curation and open
science.

摘要：透過訓練測試典範進行快速模型驗證，一直是機器學習和 AI 令人驚嘆的進展的關鍵驅動力。然而，現代的 AI 系統通常依賴於任務和資料收集實務的組合，這些實務違反了確保測試有效性的所有假設。然而，如果沒有嚴謹的模型驗證，我們無法確保已部署的 AI 系統的預期結果，包括正面的社會影響，也無法以科學健全的方式持續推進 AI 研究。在本文中，我將說明對於複雜社會系統中廣泛考量的推論設定，訓練測試典範不僅缺乏依據，而且對於任何風險估計器（包括反事實和因果估計器）來說，在高機率下都是無效的。這些形式上的不可能結果突顯了一個基本的認識論問題，也就是對於現代 AI 中的關鍵任務，我們無法知道在當前的資料收集實務下，模型是否有效。重要的是，這包括推薦系統和透過大型語言模型進行推理的變體，而且天真的擴充或有限的基準都不適合解決這個問題。我透過廣泛使用的 MovieLens 基準來說明這些結果，並透過討論這些結果對社會系統中 AI 的影響，包括可能的補救措施，例如參與式資料策展和開放科學，來作為結論。

##### **SpecTool: A Benchmark for Characterizing Errors in Tool-Use LLMs**
2411.13547v1 by Shirley Kokane, Ming Zhu, Tulika Awalgaonkar, Jianguo Zhang, Thai Hoang, Akshara Prabhakar, Zuxin Liu, Tian Lan, Liangwei Yang, Juntao Tan, Rithesh Murthy, Weiran Yao, Zhiwei Liu, Juan Carlos Niebles, Huan Wang, Shelby Heinecke, Caiming Xiong, Silivo Savarese

Evaluating the output of Large Language Models (LLMs) is one of the most
critical aspects of building a performant compound AI system. Since the output
from LLMs propagate to downstream steps, identifying LLM errors is crucial to
system performance. A common task for LLMs in AI systems is tool use. While
there are several benchmark environments for evaluating LLMs on this task, they
typically only give a success rate without any explanation of the failure
cases. To solve this problem, we introduce SpecTool, a new benchmark to
identify error patterns in LLM output on tool-use tasks. Our benchmark data set
comprises of queries from diverse environments that can be used to test for the
presence of seven newly characterized error patterns. Using SPECTOOL , we show
that even the most prominent LLMs exhibit these error patterns in their
outputs. Researchers can use the analysis and insights from SPECTOOL to guide
their error mitigation strategies.

摘要：評估大型語言模型 (LLM) 的輸出是建構高效能複合式 AI 系統最重要的面向之一。由於 LLM 的輸出會傳播到下游步驟，因此找出 LLM 錯誤對於系統效能至關重要。在 AI 系統中，LLM 的一項常見任務是使用工具。雖然有幾個用於評估 LLM 執行此項任務的基準環境，但它們通常只提供成功率，而沒有說明失敗案例。為了解決這個問題，我們引進 SpecTool，一個用於找出 LLM 在工具使用任務中輸出錯誤模式的新基準。我們的基準資料集包含來自不同環境的查詢，可據以測試七種新特徵化錯誤模式的存在。使用 SPECTOOL，我們顯示出即使是最傑出的 LLM 也會在其輸出中展現這些錯誤模式。研究人員可以使用 SPECTOOL 的分析和見解來引導他們的錯誤緩解策略。

##### **BALROG: Benchmarking Agentic LLM and VLM Reasoning On Games**
2411.13543v1 by Davide Paglieri, Bartłomiej Cupiał, Samuel Coward, Ulyana Piterbarg, Maciej Wolczyk, Akbir Khan, Eduardo Pignatelli, Łukasz Kuciński, Lerrel Pinto, Rob Fergus, Jakob Nicolaus Foerster, Jack Parker-Holder, Tim Rocktäschel

Large Language Models (LLMs) and Vision Language Models (VLMs) possess
extensive knowledge and exhibit promising reasoning abilities; however, they
still struggle to perform well in complex, dynamic environments. Real-world
tasks require handling intricate interactions, advanced spatial reasoning,
long-term planning, and continuous exploration of new strategies-areas in which
we lack effective methodologies for comprehensively evaluating these
capabilities. To address this gap, we introduce BALROG, a novel benchmark
designed to assess the agentic capabilities of LLMs and VLMs through a diverse
set of challenging games. Our benchmark incorporates a range of existing
reinforcement learning environments with varying levels of difficulty,
including tasks that are solvable by non-expert humans in seconds to extremely
challenging ones that may take years to master (e.g., the NetHack Learning
Environment). We devise fine-grained metrics to measure performance and conduct
an extensive evaluation of several popular open-source and closed-source LLMs
and VLMs. Our findings indicate that while current models achieve partial
success in the easier games, they struggle significantly with more challenging
tasks. Notably, we observe severe deficiencies in vision-based decision-making,
as models perform worse when visual representations of the environments are
provided. We release BALROG as an open and user-friendly benchmark to
facilitate future research and development in the agentic community.

摘要：大型語言模型 (LLM) 和視覺語言模型 (VLM) 擁有
廣泛的知識並展現出有前途的推理能力；然而，它們
在複雜、動態的環境中仍然難以表現良好。現實世界的
任務需要處理複雜的互動、先進的空間推理、
長期規劃和持續探索新的策略，我們缺乏有效的
方法來全面評估這些能力。為了解決這個差距，我們引入了 BALROG，一個新基準
旨在通過一系列具有挑戰性的遊戲來評估 LLM 和 VLM 的代理能力。我們的基準納入了範圍廣泛的現有
強化學習環境，難度各不相同，
包括非專家人類可以在幾秒鐘內解決的任務到可能需要數年才能掌握的極具挑戰性的任務（例如 NetHack 學習
環境）。我們設計了細緻的指標來衡量性能並進行
對幾個流行的開源和閉源 LLM
和 VLM 進行廣泛的評估。我們的研究結果表明，雖然當前模型在較簡單的遊戲中取得了部分成功，但它們在更具挑戰性的
任務中顯著掙扎。值得注意的是，我們觀察到基於視覺的決策制定存在嚴重缺陷，
因為當提供環境的視覺表示時，模型的表現會更差。我們將 BALROG 發布為一個開放且用戶友好的基準，以
促進代理社區未來的研究和開發。

##### **Metacognition for Unknown Situations and Environments (MUSE)**
2411.13537v1 by Rodolfo Valiente, Praveen K. Pilly

Metacognition--the awareness and regulation of one's cognitive processes--is
central to human adaptability in unknown situations. In contrast, current
autonomous agents often struggle in novel environments due to their limited
capacity for adaptation. We hypothesize that metacognition is a critical
missing ingredient in adaptive autonomous systems, equipping them with the
cognitive flexibility needed to tackle unfamiliar challenges. Given the broad
scope of metacognitive abilities, we focus on two key aspects: competence
awareness and strategy selection for novel tasks. To this end, we propose the
Metacognition for Unknown Situations and Environments (MUSE) framework, which
integrates metacognitive processes--specifically self-awareness and
self-regulation--into autonomous agents. We present two initial implementations
of MUSE: one based on world modeling and another leveraging large language
models (LLMs), both instantiating the metacognitive cycle. Our system
continuously learns to assess its competence on a given task and uses this
self-awareness to guide iterative cycles of strategy selection. MUSE agents
show significant improvements in self-awareness and self-regulation, enabling
them to solve novel, out-of-distribution tasks more effectively compared to
Dreamer-v3-based reinforcement learning and purely prompt-based LLM agent
approaches. This work highlights the promise of approaches inspired by
cognitive and neural systems in enabling autonomous systems to adapt to new
environments, overcoming the limitations of current methods that rely heavily
on extensive training data.

摘要：元認知——對自身認知過程的覺察與調節——是人類在未知情境中適應能力的中心。相比之下，當前的自主代理經常在新的環境中掙扎，因為它們的適應能力有限。我們假設元認知是適應性自主系統中一個重要的遺失成分，它為它們提供了應對不熟悉挑戰所需的認知靈活性。鑑於元認知能力的廣泛範圍，我們專注於兩個關鍵方面：能力意識和新任務的策略選擇。為此，我們提出了未知情境和環境的元認知 (MUSE) 框架，它將元認知過程——特別是自我意識和自我調節——整合到自主代理中。我們提出了 MUSE 的兩個初始實現：一個基於世界建模，另一個利用大型語言模型 (LLM)，兩者都實例化了元認知迴圈。我們的系統持續學習評估其在給定任務上的能力，並利用這種自我意識來指導策略選擇的迭代迴圈。與基於 Dreamer-v3 的強化學習和純粹基於提示的 LLM 代理方法相比，MUSE 代理在自我意識和自我調節方面表現出顯著的改進，使它們能夠更有效地解決新穎的、分布外的任務。這項工作突出了受認知和神經系統啟發的方法在使自主系統適應新環境方面的前景，克服了當前方法的局限性，而當前方法過於依賴於大量的訓練資料。

##### **Identity Preserving 3D Head Stylization with Multiview Score Distillation**
2411.13536v1 by Bahri Batuhan Bilecen, Ahmet Berke Gokmen, Furkan Guzelant, Aysegul Dundar

3D head stylization transforms realistic facial features into artistic
representations, enhancing user engagement across gaming and virtual reality
applications. While 3D-aware generators have made significant advancements,
many 3D stylization methods primarily provide near-frontal views and struggle
to preserve the unique identities of original subjects, often resulting in
outputs that lack diversity and individuality. This paper addresses these
challenges by leveraging the PanoHead model, synthesizing images from a
comprehensive 360-degree perspective. We propose a novel framework that employs
negative log-likelihood distillation (LD) to enhance identity preservation and
improve stylization quality. By integrating multi-view grid score and mirror
gradients within the 3D GAN architecture and introducing a score rank weighing
technique, our approach achieves substantial qualitative and quantitative
improvements. Our findings not only advance the state of 3D head stylization
but also provide valuable insights into effective distillation processes
between diffusion models and GANs, focusing on the critical issue of identity
preservation. Please visit the https://three-bee.github.io/head_stylization for
more visuals.

摘要：3D 頭部風格化將逼真的臉部特徵轉換成藝術表現，提升遊戲和虛擬實境應用中的使用者參與度。雖然 3D 感知生成器已取得顯著進展，但許多 3D 風格化方法主要提供近乎正面的視角，且難以保留原始主體的獨特身分，通常導致產出缺乏多樣性和個性。本文透過利用 PanoHead 模型，從全面的 360 度視角合成影像，來解決這些挑戰。我們提出一個新的架構，採用負對數似然蒸餾 (LD) 來增強身分保留並提升風格化品質。透過整合多視角網格評分和鏡像梯度於 3D GAN 架構中，並引入評分等級加權技術，我們的做法在質量和數量上皆取得顯著的進步。我們的發現不僅推進了 3D 頭部風格化的現況，也提供了關於擴散模型和 GAN 之間有效蒸餾程序的寶貴見解，重點關注身分保留的關鍵問題。請造訪 https://three-bee.github.io/head_stylization 以取得更多視覺效果。

##### **Predictive Insights into LGBTQ+ Minority Stress: A Transductive Exploration of Social Media Discourse**
2411.13534v1 by S. Chapagain, Y. Zhao, T. K. Rohleen, S. M. Hamdi, S. F. Boubrahimi, R. E. Flinn, E. M. Lund, D. Klooster, J. R. Scheer, C. J. Cascalheira

Individuals who identify as sexual and gender minorities, including lesbian,
gay, bisexual, transgender, queer, and others (LGBTQ+) are more likely to
experience poorer health than their heterosexual and cisgender counterparts.
One primary source that drives these health disparities is minority stress
(i.e., chronic and social stressors unique to LGBTQ+ communities' experiences
adapting to the dominant culture). This stress is frequently expressed in
LGBTQ+ users' posts on social media platforms. However, these expressions are
not just straightforward manifestations of minority stress. They involve
linguistic complexity (e.g., idiom or lexical diversity), rendering them
challenging for many traditional natural language processing methods to detect.
In this work, we designed a hybrid model using Graph Neural Networks (GNN) and
Bidirectional Encoder Representations from Transformers (BERT), a pre-trained
deep language model to improve the classification performance of minority
stress detection. We experimented with our model on a benchmark social media
dataset for minority stress detection (LGBTQ+ MiSSoM+). The dataset is
comprised of 5,789 human-annotated Reddit posts from LGBTQ+ subreddits. Our
approach enables the extraction of hidden linguistic nuances through
pretraining on a vast amount of raw data, while also engaging in transductive
learning to jointly develop representations for both labeled training data and
unlabeled test data. The RoBERTa-GCN model achieved an accuracy of 0.86 and an
F1 score of 0.86, surpassing the performance of other baseline models in
predicting LGBTQ+ minority stress. Improved prediction of minority stress
expressions on social media could lead to digital health interventions to
improve the wellbeing of LGBTQ+ people-a community with high rates of
stress-sensitive health problems.

摘要：<paragraph>認同自己是性與性別少數族群的人，包括女同性戀、男同性戀、雙性戀、跨性別、酷兒和其他 LGBTQ+ 族群，比異性戀和順性別者更容易有較差的健康狀況。造成這些健康差異的主要來源之一是少數族群壓力（即 LGBTQ+ 社群在適應主流文化時獨有的慢性與社會壓力）。這種壓力經常在 LGBTQ+ 使用者於社群媒體平台上的貼文中表達出來。然而，這些表達並不僅僅是少數族群壓力的直接表現。它們包含了語言複雜性（例如慣用語或詞彙多樣性），讓許多傳統的自然語言處理方法難以辨識。在這項研究中，我們設計了一個混合模型，使用圖神經網路 (GNN) 和來自 Transformer 的雙向編碼器表徵 (BERT)，這是一個經過預先訓練的深度語言模型，以提升少數族群壓力辨識的分類效能。我們在一個用於少數族群壓力辨識的基準社群媒體資料集 (LGBTQ+ MiSSoM+) 上對我們的模型進行實驗。該資料集包含了 5,789 篇由人類註解的 Reddit 貼文，來自於 LGBTQ+ 的 subreddit。我們的做法能夠透過在大量的原始資料上進行預訓練來萃取隱藏的語言差異，同時也參與轉導式學習，以共同開發標籤訓練資料和未標籤測試資料的表徵。RoBERTa-GCN 模型達到了 0.86 的準確率和 0.86 的 F1 分數，在預測 LGBTQ+ 少數族群壓力方面超越了其他基線模型的效能。在社群媒體上對少數族群壓力表達的預測改善，可以導致數位健康介入措施，以改善 LGBTQ+ 族群的福祉，而這個族群有很高的壓力敏感性健康問題發生率。</paragraph>

##### **Advancing Complex Medical Communication in Arabic with Sporo AraSum: Surpassing Existing Large Language Models**
2411.13518v1 by Chanseo Lee, Sonu Kumar, Kimon A. Vogt, Sam Meraj, Antonia Vogt

The increasing demand for multilingual capabilities in healthcare underscores
the need for AI models adept at processing diverse languages, particularly in
clinical documentation and decision-making. Arabic, with its complex
morphology, syntax, and diglossia, poses unique challenges for natural language
processing (NLP) in medical contexts. This case study evaluates Sporo AraSum, a
language model tailored for Arabic clinical documentation, against JAIS, the
leading Arabic NLP model. Using synthetic datasets and modified PDQI-9 metrics
modified ourselves for the purposes of assessing model performances in a
different language. The study assessed the models' performance in summarizing
patient-physician interactions, focusing on accuracy, comprehensiveness,
clinical utility, and linguistic-cultural competence.
  Results indicate that Sporo AraSum significantly outperforms JAIS in
AI-centric quantitative metrics and all qualitative attributes measured in our
modified version of the PDQI-9. AraSum's architecture enables precise and
culturally sensitive documentation, addressing the linguistic nuances of Arabic
while mitigating risks of AI hallucinations. These findings suggest that Sporo
AraSum is better suited to meet the demands of Arabic-speaking healthcare
environments, offering a transformative solution for multilingual clinical
workflows. Future research should incorporate real-world data to further
validate these findings and explore broader integration into healthcare
systems.

摘要：醫療保健領域對多語言能力的需求日益增加，這凸顯了對善於處理各種語言的 AI 模型的需求，特別是在臨床文件和決策制定中。阿拉伯語具有複雜的形態、語法和雙語現象，這對醫療環境中的自然語言處理 (NLP) 構成了獨特的挑戰。本案例研究評估了 Sporo AraSum（一種專為阿拉伯語臨床文件量身打造的語言模型）和阿拉伯語 NLP 模型的領導者 JAIS。我們使用合成資料集和修改後的 PDQI-9 指標（我們自行修改，以評估模型在不同語言中的表現）。本研究評估了模型在總結患者與醫師互動時的表現，重點在於準確性、全面性、臨床效用和語言文化能力。
結果表明，在以 AI 為中心的定量指標和我們修改後的 PDQI-9 版本中測量的所有定性屬性中，Sporo AraSum 明顯優於 JAIS。AraSum 的架構能產生精確且具有文化敏感度的文件，它能處理阿拉伯語的語言差異，同時降低 AI 產生幻覺的風險。這些發現表明，Sporo AraSum 更適合滿足講阿拉伯語的醫療保健環境的需求，為多語言臨床工作流程提供了一個變革性的解決方案。未來的研究應納入真實世界的資料，以進一步驗證這些發現，並探索更廣泛地整合到醫療保健系統中。

##### **Disentangling Memory and Reasoning Ability in Large Language Models**
2411.13504v2 by Mingyu Jin, Weidi Luo, Sitao Cheng, Xinyi Wang, Wenyue Hua, Ruixiang Tang, William Yang Wang, Yongfeng Zhang

Large Language Models (LLMs) have demonstrated strong performance in handling
complex tasks requiring both extensive knowledge and reasoning abilities.
However, the existing LLM inference pipeline operates as an opaque process
without explicit separation between knowledge retrieval and reasoning steps,
making the model's decision-making process unclear and disorganized. This
ambiguity can lead to issues such as hallucinations and knowledge forgetting,
which significantly impact the reliability of LLMs in high-stakes domains. In
this paper, we propose a new inference paradigm that decomposes the complex
inference process into two distinct and clear actions: (1) memory recall: which
retrieves relevant knowledge, and (2) reasoning: which performs logical steps
based on the recalled knowledge. To facilitate this decomposition, we introduce
two special tokens memory and reason, guiding the model to distinguish between
steps that require knowledge retrieval and those that involve reasoning. Our
experiment results show that this decomposition not only improves model
performance but also enhances the interpretability of the inference process,
enabling users to identify sources of error and refine model responses
effectively. The code is available at
https://github.com/MingyuJ666/Disentangling-Memory-and-Reasoning.

摘要：大型語言模型 (LLM) 在處理需要廣泛知識和推理能力的複雜任務方面表現出強勁的效能。然而，現有的 LLM 推論管線以不透明的流程運作，知識擷取和推理步驟之間沒有明確的區分，使得模型的決策過程不清不楚且雜亂無章。這種模稜兩可可能會導致幻覺和知識遺忘等問題，這會顯著影響 LLM 在高風險領域的可靠性。在本文中，我們提出了一種新的推論範例，將複雜的推論過程分解成兩個不同且明確的動作：(1) 記憶回想：擷取相關知識，以及 (2) 推理：根據回想的知識執行邏輯步驟。為了促進這種分解，我們引入了兩個特殊符號記憶和推理，引導模型區分需要知識擷取的步驟和涉及推理的步驟。我們的實驗結果顯示，這種分解不僅改善了模型效能，也增強了推論過程的可解釋性，使用戶能夠找出錯誤來源並有效地改善模型反應。程式碼可在 https://github.com/MingyuJ666/Disentangling-Memory-and-Reasoning 取得。

##### **Utilizing Large Language Models to Synthesize Product Desirability Datasets**
2411.13485v1 by John D. Hastings, Sherri Weitl-Harms, Joseph Doty, Zachary L. Myers, Warren Thompson

This research explores the application of large language models (LLMs) to
generate synthetic datasets for Product Desirability Toolkit (PDT) testing, a
key component in evaluating user sentiment and product experience. Utilizing
gpt-4o-mini, a cost-effective alternative to larger commercial LLMs, three
methods, Word+Review, Review+Word, and Supply-Word, were each used to
synthesize 1000 product reviews. The generated datasets were assessed for
sentiment alignment, textual diversity, and data generation cost. Results
demonstrated high sentiment alignment across all methods, with Pearson
correlations ranging from 0.93 to 0.97. Supply-Word exhibited the highest
diversity and coverage of PDT terms, although with increased generation costs.
Despite minor biases toward positive sentiments, in situations with limited
test data, LLM-generated synthetic data offers significant advantages,
including scalability, cost savings, and flexibility in dataset production.

摘要：本研究探討將大型語言模型 (LLM) 應用於產生產品可欲性工具組 (PDT) 測試的合成資料集，這是評估使用者情緒和產品體驗的關鍵組成部分。利用 gpt-4o-mini，這是一種具備成本效益且可替代大型商業 LLM 的方法，三種方法（Word+Review、Review+Word 和 Supply-Word）各用於合成 1000 個產品評論。對產生的資料集進行情緒對齊、文字多樣性和資料產生成本的評估。結果顯示所有方法的情緒對齊度都很高，皮爾森相關係數介於 0.93 到 0.97 之間。Supply-Word 展現出最高的 PDT 術語多樣性和涵蓋範圍，儘管產生成本也隨之增加。儘管對正面情緒有輕微的偏見，但在測試資料有限的情況下，LLM 產生的合成資料提供了顯著的優勢，包括可擴充性、成本節省和資料集製作的靈活性。

##### **PatentEdits: Framing Patent Novelty as Textual Entailment**
2411.13477v1 by Ryan Lee, Alexander Spangher, Xuezhe Ma

A patent must be deemed novel and non-obvious in order to be granted by the
US Patent Office (USPTO). If it is not, a US patent examiner will cite the
prior work, or prior art, that invalidates the novelty and issue a non-final
rejection. Predicting what claims of the invention should change given the
prior art is an essential and crucial step in securing invention rights, yet
has not been studied before as a learnable task. In this work we introduce the
PatentEdits dataset, which contains 105K examples of successful revisions that
overcome objections to novelty. We design algorithms to label edits sentence by
sentence, then establish how well these edits can be predicted with large
language models (LLMs). We demonstrate that evaluating textual entailment
between cited references and draft sentences is especially effective in
predicting which inventive claims remained unchanged or are novel in relation
to prior art.

摘要：要獲得美國專利商標局 (USPTO) 授予專利，該專利必須被視為新穎且非顯而易見的。如果不是這樣，美國專利審查員將引用先前作品或先前技術，使新穎性失效並發出非最終駁回。預測在先技術下應更改哪些發明權利要求是確保發明權利的必要且關鍵步驟，但尚未作為可學習的任務進行研究。在這項工作中，我們引入了 PatentEdits 資料集，其中包含 105K 個成功修改範例，克服了對新穎性的反對意見。我們設計演算法來逐句標記編輯，然後確定使用大型語言模型 (LLM) 可以預測這些編輯的程度。我們證明評估引用的參考文獻和草稿句子之間的文本蘊涵對於預測哪些發明權利要求保持不變或相對於先前技術而言是新穎的特別有效。

##### **When Precision Meets Position: BFloat16 Breaks Down RoPE in Long-Context Training**
2411.13476v1 by Haonan Wang, Qian Liu, Chao Du, Tongyao Zhu, Cunxiao Du, Kenji Kawaguchi, Tianyu Pang

Extending context window sizes allows large language models (LLMs) to process
longer sequences and handle more complex tasks. Rotary Positional Embedding
(RoPE) has become the de facto standard due to its relative positional encoding
properties that benefit long-context training. However, we observe that using
RoPE with BFloat16 format results in numerical issues, causing it to deviate
from its intended relative positional encoding, especially in long-context
scenarios. This issue arises from BFloat16's limited precision and accumulates
as context length increases, with the first token contributing significantly to
this problem. To address this, we develop AnchorAttention, a plug-and-play
attention method that alleviates numerical issues caused by BFloat16, improves
long-context capabilities, and speeds up training. AnchorAttention reduces
unnecessary attention computations, maintains semantic coherence, and boosts
computational efficiency by treating the first token as a shared anchor with a
consistent position ID, making it visible to all documents within the training
context. Experiments on three types of LLMs demonstrate that AnchorAttention
significantly improves long-context performance and reduces training time by
over 50\% compared to standard full attention mechanisms, while preserving the
original LLM's capabilities on general tasks. Our code is available at
https://github.com/haonan3/AnchorContext.

摘要：擴展上下文視窗大小允許大型語言模型 (LLM) 處理更長的序列並處理更複雜的任務。旋轉位置嵌入 (RoPE) 已成為事實上的標準，因為它具有相對位置編碼特性，有利於長文脈訓練。然而，我們觀察到使用 BFloat16 格式的 RoPE 會導致數值問題，導致它偏離其預期的相對位置編碼，特別是在長文脈場景中。此問題源自 BFloat16 的有限精度，並隨著文脈長度的增加而累積，其中第一個標記對此問題有顯著的影響。為了解決這個問題，我們開發了 AnchorAttention，這是一種即插即用的注意力方法，可以減輕由 BFloat16 引起的數值問題，改善長文脈能力，並加快訓練速度。AnchorAttention 減少了不必要的注意力計算，維持語義一致性，並通過將第一個標記視為具有固定位置 ID 的共享錨點來提升運算效率，使其在訓練文脈中的所有文件都可見。在三種類型的 LLM 上進行的實驗表明，與標準全注意力機制相比，AnchorAttention 大幅提升了長文脈效能，並將訓練時間縮短了 50% 以上，同時保留了 LLM 在一般任務上的原始能力。我們的程式碼可在 https://github.com/haonan3/AnchorContext 取得。

##### **SoK: A Systems Perspective on Compound AI Threats and Countermeasures**
2411.13459v1 by Sarbartha Banerjee, Prateek Sahu, Mulong Luo, Anjo Vahldiek-Oberwagner, Neeraja J. Yadwadkar, Mohit Tiwari

Large language models (LLMs) used across enterprises often use proprietary
models and operate on sensitive inputs and data. The wide range of attack
vectors identified in prior research - targeting various software and hardware
components used in training and inference - makes it extremely challenging to
enforce confidentiality and integrity policies.
  As we advance towards constructing compound AI inference pipelines that
integrate multiple large language models (LLMs), the attack surfaces expand
significantly. Attackers now focus on the AI algorithms as well as the software
and hardware components associated with these systems. While current research
often examines these elements in isolation, we find that combining cross-layer
attack observations can enable powerful end-to-end attacks with minimal
assumptions about the threat model. Given, the sheer number of existing attacks
at each layer, we need a holistic and systemized understanding of different
attack vectors at each layer.
  This SoK discusses different software and hardware attacks applicable to
compound AI systems and demonstrates how combining multiple attack mechanisms
can reduce the threat model assumptions required for an isolated attack. Next,
we systematize the ML attacks in lines with the Mitre Att&ck framework to
better position each attack based on the threat model. Finally, we outline the
existing countermeasures for both software and hardware layers and discuss the
necessity of a comprehensive defense strategy to enable the secure and
high-performance deployment of compound AI systems.

摘要：大型語言模型 (LLM) 在企業中廣泛使用，通常使用專有模型並對敏感輸入和數據進行操作。先前研究中發現的各種攻擊媒介 - 針對訓練和推理中使用的各種軟體和硬體元件 - 使得執行機密性和完整性政策極具挑戰性。
當我們朝著構建整合多個大型語言模型 (LLM) 的複合式 AI 推理管線邁進時，攻擊面會顯著擴大。攻擊者現在專注於 AI 演算法以及與這些系統相關的軟體和硬體元件。雖然目前的研究所調查通常孤立地檢查這些元素，但我們發現結合跨層攻擊觀察可以實現強大的端對端攻擊，對威脅模型的假設最少。由於每一層現有攻擊的數量龐大，我們需要對每一層的不同攻擊媒介有全面且系統化的了解。
本 SoK 討論了適用於複合式 AI 系統的不同軟體和硬體攻擊，並展示了結合多種攻擊機制如何降低孤立攻擊所需的威脅模型假設。接下來，我們系統化 ML 攻擊，並與 Mitre Att&ck 架構保持一致，以便根據威脅模型更好地定位每個攻擊。最後，我們概述了軟體和硬體層的現有對策，並討論了全面防禦策略的必要性，以實現複合式 AI 系統的安全和高性能部署。

##### **LIMBA: An Open-Source Framework for the Preservation and Valorization of Low-Resource Languages using Generative Models**
2411.13453v1 by Salvatore Mario Carta, Stefano Chessa, Giulia Contu, Andrea Corriga, Andrea Deidda, Gianni Fenu, Luca Frigau, Alessandro Giuliani, Luca Grassi, Marco Manolo Manca, Mirko Marras, Francesco Mola, Bastianino Mossa, Piergiorgio Mura, Marco Ortu, Leonardo Piano, Simone Pisano, Alessia Pisu, Alessandro Sebastian Podda, Livio Pompianu, Simone Seu, Sandro Gabriele Tiddia

Minority languages are vital to preserving cultural heritage, yet they face
growing risks of extinction due to limited digital resources and the dominance
of artificial intelligence models trained on high-resource languages. This
white paper proposes a framework to generate linguistic tools for low-resource
languages, focusing on data creation to support the development of language
models that can aid in preservation efforts. Sardinian, an endangered language,
serves as the case study to demonstrate the framework's effectiveness. By
addressing the data scarcity that hinders intelligent applications for such
languages, we contribute to promoting linguistic diversity and support ongoing
efforts in language standardization and revitalization through modern
technologies.

摘要：少數語言對於保存文化遺產至關重要，但由於數位資源有限以及以高資源語言訓練的人工智慧模型的普及，這些語言面臨越來越高的滅絕風險。本白皮書提出了一個框架，用於產生低資源語言的語言工具，重點在於建立資料，以支援語言模型的開發，進而協助保存工作。薩丁尼亞語是一種瀕臨滅絕的語言，作為案例研究來證明此框架的有效性。透過解決阻礙此類語言的智慧型應用程式的資料短缺問題，我們可以協助推廣語言多樣性，並透過現代科技支援語言標準化和復興的持續努力。

