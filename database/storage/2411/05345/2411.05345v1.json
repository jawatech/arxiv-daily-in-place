{"2411.05345": {"publish_time": "2024-11-08", "title": "Reasoning Robustness of LLMs to Adversarial Typographical Errors", "paper_summary": "Large Language Models (LLMs) have demonstrated impressive capabilities in\nreasoning using Chain-of-Thought (CoT) prompting. However, CoT can be biased by\nusers' instruction. In this work, we study the reasoning robustness of LLMs to\ntypographical errors, which can naturally occur in users' queries. We design an\nAdversarial Typo Attack ($\\texttt{ATA}$) algorithm that iteratively samples\ntypos for words that are important to the query and selects the edit that is\nmost likely to succeed in attacking. It shows that LLMs are sensitive to\nminimal adversarial typographical changes. Notably, with 1 character edit,\nMistral-7B-Instruct's accuracy drops from 43.7% to 38.6% on GSM8K, while with 8\ncharacter edits the performance further drops to 19.2%. To extend our\nevaluation to larger and closed-source LLMs, we develop the $\\texttt{R$^2$ATA}$\nbenchmark, which assesses models' $\\underline{R}$easoning\n$\\underline{R}$obustness to $\\underline{\\texttt{ATA}}$. It includes adversarial\ntypographical questions derived from three widely used reasoning\ndatasets-GSM8K, BBH, and MMLU-by applying $\\texttt{ATA}$ to open-source LLMs.\n$\\texttt{R$^2$ATA}$ demonstrates remarkable transferability and causes notable\nperformance drops across multiple super large and closed-source LLMs.", "paper_summary_zh": "\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5df2\u5728\u4f7f\u7528\u601d\u8003\u93c8 (CoT) \u63d0\u793a\u9032\u884c\u63a8\u7406\u65b9\u9762\u5c55\u73fe\u51fa\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u80fd\u529b\u3002\u7136\u800c\uff0cCoT \u53ef\u80fd\u6703\u53d7\u5230\u4f7f\u7528\u8005\u6307\u4ee4\u7684\u5f71\u97ff\u3002\u5728\u9019\u9805\u5de5\u4f5c\u4e2d\uff0c\u6211\u5011\u7814\u7a76\u4e86 LLM \u5c0d\u5370\u5237\u932f\u8aa4\u7684\u63a8\u7406\u7a69\u5065\u6027\uff0c\u9019\u53ef\u80fd\u6703\u81ea\u7136\u767c\u751f\u5728\u4f7f\u7528\u8005\u7684\u67e5\u8a62\u4e2d\u3002\u6211\u5011\u8a2d\u8a08\u4e86\u4e00\u7a2e\u5c0d\u6297\u6027\u5370\u5237\u653b\u64ca (ATA) \u6f14\u7b97\u6cd5\uff0c\u8a72\u6f14\u7b97\u6cd5\u6703\u53cd\u8986\u5c0d\u67e5\u8a62\u4e2d\u91cd\u8981\u7684\u5b57\u8a5e\u9032\u884c\u5370\u5237\u932f\u8aa4\u53d6\u6a23\uff0c\u4e26\u9078\u64c7\u6700\u6709\u53ef\u80fd\u6210\u529f\u653b\u64ca\u7684\u7de8\u8f2f\u5167\u5bb9\u3002\u5b83\u986f\u793a\u51fa LLM \u5c0d\u6700\u5c0f\u7684\u5c0d\u6297\u6027\u5370\u5237\u8b8a\u66f4\u5f88\u654f\u611f\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5728 1 \u500b\u5b57\u5143\u7de8\u8f2f\u4e0b\uff0cMistral-7B-Instruct \u5728 GSM8K \u4e0a\u7684\u6e96\u78ba\u5ea6\u5f9e 43.7% \u964d\u81f3 38.6%\uff0c\u800c\u5728 8 \u500b\u5b57\u5143\u7de8\u8f2f\u4e0b\uff0c\u6548\u80fd\u9032\u4e00\u6b65\u964d\u81f3 19.2%\u3002\u70ba\u4e86\u5c07\u6211\u5011\u7684\u8a55\u4f30\u64f4\u5c55\u5230\u66f4\u5927\u4e14\u5c01\u9589\u539f\u59cb\u78bc\u7684 LLM\uff0c\u6211\u5011\u958b\u767c\u4e86 R2ATA \u57fa\u6e96\uff0c\u8a72\u57fa\u6e96\u8a55\u4f30\u6a21\u578b\u5c0d ATA \u7684\u63a8\u7406\u7a69\u5065\u6027\u3002\u5b83\u5305\u542b\u900f\u904e\u5c07 ATA \u5957\u7528\u65bc\u958b\u653e\u539f\u59cb\u78bc LLM\uff0c\u5f9e\u4e09\u500b\u5ee3\u6cdb\u4f7f\u7528\u7684\u63a8\u7406\u8cc7\u6599\u96c6 (GSM8K\u3001BBH \u548c MMLU) \u4e2d\u884d\u751f\u7684\u5c0d\u6297\u6027\u5370\u5237\u554f\u984c\u3002R2ATA \u8868\u73fe\u51fa\u986f\u8457\u7684\u53ef\u8f49\u79fb\u6027\uff0c\u4e26\u5c0e\u81f4\u591a\u500b\u8d85\u5927\u578b\u4e14\u5c01\u9589\u539f\u59cb\u78bc\u7684 LLM \u6548\u80fd\u5927\u5e45\u4e0b\u964d\u3002", "author": "Esther Gan et.al.", "authors": "Esther Gan, Yiran Zhao, Liying Cheng, Yancan Mao, Anirudh Goyal, Kenji Kawaguchi, Min-Yen Kan, Michael Shieh", "id": "2411.05345v1", "paper_url": "http://arxiv.org/abs/2411.05345v1", "repo": "null"}}