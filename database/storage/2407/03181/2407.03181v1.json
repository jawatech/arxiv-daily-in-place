{"2407.03181": {"publish_time": "2024-07-03", "title": "Fine-Tuning with Divergent Chains of Thought Boosts Reasoning Through Self-Correction in Language Models", "paper_summary": "Requiring a Large Language Model to generate intermediary reasoning steps has\nbeen shown to be an effective way of boosting performance. In fact, it has been\nfound that instruction tuning on these intermediary reasoning steps improves\nmodel performance. In this work, we present a novel method of further improving\nperformance by requiring models to compare multiple reasoning chains before\ngenerating a solution in a single inference step. We call this method Divergent\nCoT (DCoT). We find that instruction tuning on DCoT datasets boosts the\nperformance of even smaller, and therefore more accessible, LLMs. Through a\nrigorous set of experiments spanning a wide range of tasks that require various\nreasoning types, we show that fine-tuning on DCoT consistently improves\nperformance over the CoT baseline across model families and scales (1.3B to\n70B). Through a combination of empirical and manual evaluation, we additionally\nshow that these performance gains stem from models generating multiple\ndivergent reasoning chains in a single inference step, indicative of the\nenabling of self-correction in language models. Our code and data are publicly\navailable at https://github.com/UKPLab/arxiv2024-divergent-cot.", "paper_summary_zh": "<paragraph>\u8981\u6c42\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u5df2\u88ab\u8bc1\u660e\u662f\u63d0\u5347\u6027\u80fd\u7684\u6709\u6548\u65b9\u6cd5\u3002\u4e8b\u5b9e\u4e0a\uff0c\u5df2\u7ecf\u53d1\u73b0\u5bf9\u8fd9\u4e9b\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u7684\u6307\u4ee4\u5fae\u8c03\u53ef\u4ee5\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u8981\u6c42\u6a21\u578b\u5728\u5355\u4e2a\u63a8\u7406\u6b65\u9aa4\u4e2d\u751f\u6210\u89e3\u51b3\u65b9\u6848\u4e4b\u524d\u6bd4\u8f83\u591a\u4e2a\u63a8\u7406\u94fe\u6765\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u7684\u65b0\u65b9\u6cd5\u3002\u6211\u4eec\u79f0\u8fd9\u79cd\u65b9\u6cd5\u4e3a\u53d1\u6563 CoT (DCoT)\u3002\u6211\u4eec\u53d1\u73b0\u5bf9 DCoT \u6570\u636e\u96c6\u7684\u6307\u4ee4\u5fae\u8c03\u53ef\u4ee5\u63d0\u5347\u66f4\u5c0f\u4e14\u56e0\u6b64\u66f4\u5bb9\u6613\u83b7\u53d6\u7684 LLM \u7684\u6027\u80fd\u3002\u901a\u8fc7\u4e00\u7ec4\u4e25\u683c\u7684\u5b9e\u9a8c\uff0c\u6db5\u76d6\u9700\u8981\u5404\u79cd\u63a8\u7406\u7c7b\u578b\u7684\u5e7f\u6cdb\u4efb\u52a1\uff0c\u6211\u4eec\u8868\u660e\u5728 DCoT \u4e0a\u8fdb\u884c\u5fae\u8c03\u53ef\u4ee5\u6301\u7eed\u63d0\u5347 CoT \u57fa\u7ebf\u5728\u6a21\u578b\u7cfb\u5217\u548c\u89c4\u6a21\uff081.3B \u5230 70B\uff09\u4e0a\u7684\u6027\u80fd\u3002\u901a\u8fc7\u5b9e\u8bc1\u548c\u624b\u52a8\u8bc4\u4f30\u7684\u7ed3\u5408\uff0c\u6211\u4eec\u8fd8\u8868\u660e\u8fd9\u4e9b\u6027\u80fd\u63d0\u5347\u6e90\u4e8e\u6a21\u578b\u5728\u5355\u4e2a\u63a8\u7406\u6b65\u9aa4\u4e2d\u751f\u6210\u591a\u4e2a\u53d1\u6563\u63a8\u7406\u94fe\uff0c\u8fd9\u8868\u660e\u8bed\u8a00\u6a21\u578b\u4e2d\u542f\u7528\u4e86\u81ea\u6211\u7ea0\u6b63\u3002\u6211\u4eec\u7684\u4ee3\u7801\u548c\u6570\u636e\u5df2\u516c\u5f00\u53d1\u5e03\u5728 https://github.com/UKPLab/arxiv2024-divergent-cot\u3002</paragraph>", "author": "Haritz Puerto et.al.", "authors": "Haritz Puerto, Tilek Chubakov, Xiaodan Zhu, Harish Tayyar Madabushi, Iryna Gurevych", "id": "2407.03181v1", "paper_url": "http://arxiv.org/abs/2407.03181v1", "repo": "https://github.com/ukplab/arxiv2024-divergent-cot"}}