
### Medical
|Publish Date|Title|Authors|PDF|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2024-04-26**|**Domain Adaptive and Fine-grained Anomaly Detection for Single-cell Sequencing Data and Beyond**|Kaichen Xu et.al.|[2404.17454v1](http://arxiv.org/abs/2404.17454v1)|[link](https://github.com/catchxu/acsleuth)|
|**2024-04-26**|**M3BAT: Unsupervised Domain Adaptation for Multimodal Mobile Sensing with Multi-Branch Adversarial Training**|Lakmal Meegahapola et.al.|[2404.17391v1](http://arxiv.org/abs/2404.17391v1)|null|
|**2024-04-26**|**Prevalent Frequency of Emotional and Physical Symptoms in Social Anxiety using Zero Shot Classification: An Observational Study**|Muhammad Rizwan et.al.|[2404.17183v1](http://arxiv.org/abs/2404.17183v1)|null|
|**2024-04-26**|**Deep Evidential Learning for Dose Prediction**|Hai Siong Tan et.al.|[2404.17126v1](http://arxiv.org/abs/2404.17126v1)|null|
|**2024-04-25**|**Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**|Yunfei Ge et.al.|[2404.16957v1](http://arxiv.org/abs/2404.16957v1)|null|
|**2024-04-25**|**Taming False Positives in Out-of-Distribution Detection with Human Feedback**|Harit Vishwakarma et.al.|[2404.16954v1](http://arxiv.org/abs/2404.16954v1)|[link](https://github.com/2454511550lin/tamefalsepositives-ood)|
|**2024-04-25**|**Features Fusion for Dual-View Mammography Mass Detection**|Arina Varlamova et.al.|[2404.16718v1](http://arxiv.org/abs/2404.16718v1)|null|
|**2024-04-25**|**Report on Candidate Computational Indicators for Conscious Valenced Experience**|Andres Campero et.al.|[2404.16696v1](http://arxiv.org/abs/2404.16696v1)|null|
|**2024-04-25**|**ProbGate at EHRSQL 2024: Enhancing SQL Query Generation Accuracy through Probabilistic Threshold Filtering and Error Handling**|Sangryul Kim et.al.|[2404.16659v1](http://arxiv.org/abs/2404.16659v1)|[link](https://github.com/venzino-han/probgate_ehrsql)|
|**2024-04-25**|**Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare**|Emre Can Acikgoz et.al.|[2404.16621v1](http://arxiv.org/abs/2404.16621v1)|null|
|**2024-04-25**|**DiffSeg: A Segmentation Model for Skin Lesions Based on Diffusion Difference**|Zhihao Shuai et.al.|[2404.16474v1](http://arxiv.org/abs/2404.16474v1)|null|
|**2024-04-25**|**Light-weight Retinal Layer Segmentation with Global Reasoning**|Xiang He et.al.|[2404.16346v1](http://arxiv.org/abs/2404.16346v1)|null|
|**2024-04-25**|**Semantic Segmentation Refiner for Ultrasound Applications with Zero-Shot Foundation Models**|Hedda Cohen Indelman et.al.|[2404.16325v1](http://arxiv.org/abs/2404.16325v1)|null|
|**2024-04-25**|**LLM-Based Section Identifiers Excel on Open Source but Stumble in Real World Applications**|Saranya Krishnamoorthy et.al.|[2404.16294v1](http://arxiv.org/abs/2404.16294v1)|[link](https://github.com/inqbator-evicore/llm_section_identifiers)|
|**2024-04-24**|**Investigating the prompt leakage effect and black-box defenses for multi-turn LLM interactions**|Divyansh Agarwal et.al.|[2404.16251v2](http://arxiv.org/abs/2404.16251v2)|null|
|**2024-04-24**|**ABCD: Trust enhanced Attention based Convolutional Autoencoder for Risk Assessment**|Sarala Naidu et.al.|[2404.16183v1](http://arxiv.org/abs/2404.16183v1)|null|
|**2024-04-24**|**Mamba-360: Survey of State Space Models as Transformer Alternative for Long Sequence Modelling: Methods, Applications, and Challenges**|Badri Narayana Patro et.al.|[2404.16112v1](http://arxiv.org/abs/2404.16112v1)|[link](https://github.com/badripatro/mamba360)|
|**2024-04-24**|**Mammo-CLIP: Leveraging Contrastive Language-Image Pre-training (CLIP) for Enhanced Breast Cancer Diagnosis with Multi-view Mammography**|Xuxin Chen et.al.|[2404.15946v1](http://arxiv.org/abs/2404.15946v1)|null|
|**2024-04-24**|**Assessing The Potential Of Mid-Sized Language Models For Clinical QA**|Elliot Bolton et.al.|[2404.15894v1](http://arxiv.org/abs/2404.15894v1)|null|
|**2024-04-24**|**Enhancing Diagnosis through AI-driven Analysis of Reflectance Confocal Microscopy**|Hong-Jun Yoon et.al.|[2404.16080v1](http://arxiv.org/abs/2404.16080v1)|null|
|**2024-04-24**|**Anomaly Detection for Incident Response at Scale**|Hanzhang Wang et.al.|[2404.16887v1](http://arxiv.org/abs/2404.16887v1)|null|
|**2024-04-23**|**Adapting an Artificial Intelligence Sexually Transmitted Diseases Symptom Checker Tool for Mpox Detection: The HeHealth Experience**|Rayner Kay Jin Tan et.al.|[2404.16885v1](http://arxiv.org/abs/2404.16885v1)|null|
|**2024-04-23**|**PRISM: Patient Records Interpretation for Semantic Clinical Trial Matching using Large Language Models**|Shashi Kant Gupta et.al.|[2404.15549v1](http://arxiv.org/abs/2404.15549v1)|null|
|**2024-04-23**|**Multi-scale Intervention Planning based on Generative Design**|Ioannis Kavouras et.al.|[2404.15492v1](http://arxiv.org/abs/2404.15492v1)|null|
|**2024-04-23**|**IryoNLP at MEDIQA-CORR 2024: Tackling the Medical Error Detection & Correction Task On the Shoulders of Medical Agents**|Jean-Philippe Corbeil et.al.|[2404.15488v1](http://arxiv.org/abs/2404.15488v1)|[link](https://github.com/microsoft/iryonlp-mediqa-corr-2024)|
|**2024-04-23**|**Machine Learning Techniques with Fairness for Prediction of Completion of Drug and Alcohol Rehabilitation**|Karen Roberts-Licklider et.al.|[2404.15418v1](http://arxiv.org/abs/2404.15418v1)|null|
|**2024-04-23**|**CT-GLIP: 3D Grounded Language-Image Pretraining with CT Scans and Radiology Reports for Full-Body Scenarios**|Jingyang Lin et.al.|[2404.15272v2](http://arxiv.org/abs/2404.15272v2)|null|
|**2024-04-23**|**A review of deep learning-based information fusion techniques for multimodal medical image classification**|Yihao Li et.al.|[2404.15022v1](http://arxiv.org/abs/2404.15022v1)|null|
|**2024-04-23**|**Clustering of timed sequences -- Application to the analysis of care pathways**|Thomas Guyet et.al.|[2404.15379v1](http://arxiv.org/abs/2404.15379v1)|null|
|**2024-04-23**|**Grounded Knowledge-Enhanced Medical VLP for Chest X-Ray**|Qiao Deng et.al.|[2404.14750v1](http://arxiv.org/abs/2404.14750v1)|null|
|**2024-04-22**|**DAIC-WOZ: On the Validity of Using the Therapist's prompts in Automatic Depression Detection from Clinical Interviews**|Sergio Burdisso et.al.|[2404.14463v1](http://arxiv.org/abs/2404.14463v1)|null|
|**2024-04-22**|**Adaptive Collaboration Strategy for LLMs in Medical Decision Making**|Yubin Kim et.al.|[2404.15155v1](http://arxiv.org/abs/2404.15155v1)|[link](https://github.com/mitmedialab/mdagents)|
|**2024-04-21**|**A Nasal Cytology Dataset for Object Detection and Deep Learning**|Mauro Camporeale et.al.|[2404.13745v1](http://arxiv.org/abs/2404.13745v1)|null|
|**2024-04-21**|**Bt-GAN: Generating Fair Synthetic Healthdata via Bias-transforming Generative Adversarial Networks**|Resmi Ramachandranpillai et.al.|[2404.13634v3](http://arxiv.org/abs/2404.13634v3)|null|
|**2024-04-21**|**SmartMem: Layout Transformation Elimination and Adaptation for Efficient DNN Execution on Mobile**|Wei Niu et.al.|[2404.13528v1](http://arxiv.org/abs/2404.13528v1)|null|
|**2024-04-21**|**Parameter Efficient Fine Tuning: A Comprehensive Analysis Across Applications**|Charith Chandra Sai Balne et.al.|[2404.13506v2](http://arxiv.org/abs/2404.13506v2)|null|
|**2024-04-20**|**SiNC+: Adaptive Camera-Based Vitals with Unsupervised Learning of Periodic Signals**|Jeremy Speth et.al.|[2404.13449v1](http://arxiv.org/abs/2404.13449v1)|null|
|**2024-04-20**|**MultiConfederated Learning: Inclusive Non-IID Data handling with Decentralized Federated Learning**|Michael Duchesne et.al.|[2404.13421v1](http://arxiv.org/abs/2404.13421v1)|null|
|**2024-04-20**|**UnibucLLM: Harnessing LLMs for Automated Prediction of Item Difficulty and Response Time for Multiple-Choice Questions**|Ana-Cristina Rogoz et.al.|[2404.13343v1](http://arxiv.org/abs/2404.13343v1)|[link](https://github.com/ana-rogoz/bea-2024)|
|**2024-04-20**|**Practical Battery Health Monitoring using Uncertainty-Aware Bayesian Neural Network**|Yunyi Zhao et.al.|[2404.14444v1](http://arxiv.org/abs/2404.14444v1)|null|
|**2024-04-19**|**Beyond Self-Consistency: Ensemble Reasoning Boosts Consistency and Accuracy of LLMs in Cancer Staging**|Chia-Hsuan Chang et.al.|[2404.13149v1](http://arxiv.org/abs/2404.13149v1)|null|
|**2024-04-19**|**Explainable AI for Fair Sepsis Mortality Predictive Model**|Chia-Hsuan Chang et.al.|[2404.13139v1](http://arxiv.org/abs/2404.13139v1)|null|
|**2024-04-19**|**Eye-tracking in Mixed Reality for Diagnosis of Neurodegenerative Diseases**|Mateusz Daniol et.al.|[2404.12984v1](http://arxiv.org/abs/2404.12984v1)|null|
|**2024-04-19**|**A Large-scale Medical Visual Task Adaptation Benchmark**|Shentong Mo et.al.|[2404.12876v1](http://arxiv.org/abs/2404.12876v1)|null|
|**2024-04-19**|**Multi Class Depression Detection Through Tweets using Artificial Intelligence**|Muhammad Osama Nusrat et.al.|[2404.13104v1](http://arxiv.org/abs/2404.13104v1)|[link](https://github.com/mnusrat786/masters-thesis)|
|**2024-04-19**|**COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**|Dmytro Shvetsov et.al.|[2404.12832v1](http://arxiv.org/abs/2404.12832v1)|[link](https://github.com/dmytro-shvetsov/counterfactual-search)|
|**2024-04-19**|**DensePANet: An improved generative adversarial network for photoacoustic tomography image reconstruction from sparse data**|Hesam Hakimnejad et.al.|[2404.13101v1](http://arxiv.org/abs/2404.13101v1)|null|
|**2024-04-19**|**Transformer-Based Classification Outcome Prediction for Multimodal Stroke Treatment**|Danqing Ma et.al.|[2404.12634v1](http://arxiv.org/abs/2404.12634v1)|null|
|**2024-04-19**|**GluMarker: A Novel Predictive Modeling of Glycemic Control Through Digital Biomarkers**|Ziyi Zhou et.al.|[2404.12605v1](http://arxiv.org/abs/2404.12605v1)|null|
|**2024-04-18**|**DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era**|David Restrepo et.al.|[2404.12278v1](http://arxiv.org/abs/2404.12278v1)|null|
|**2024-04-18**|**Relationship Discovery for Drug Recommendation**|Xiang Li et.al.|[2404.12228v1](http://arxiv.org/abs/2404.12228v1)|null|
|**2024-04-18**|**A Symmetric Regressor for MRI-Based Assessment of Striatal Dopamine Transporter Uptake in Parkinson's Disease**|Walid Abdullah Al et.al.|[2404.11929v1](http://arxiv.org/abs/2404.11929v1)|[link](https://github.com/awjibon/mri_dat)|
|**2024-04-18**|**Cross-model Mutual Learning for Exemplar-based Medical Image Segmentation**|Qing En et.al.|[2404.11812v1](http://arxiv.org/abs/2404.11812v1)|null|
|**2024-04-17**|**A Secure and Trustworthy Network Architecture for Federated Learning Healthcare Applications**|Antonio Boiano et.al.|[2404.11698v1](http://arxiv.org/abs/2404.11698v1)|null|
|**2024-04-17**|**Towards Reliable Empirical Machine Unlearning Evaluation: A Game-Theoretic View**|Yiwen Tu et.al.|[2404.11577v1](http://arxiv.org/abs/2404.11577v1)|null|
|**2024-04-17**|**Prompt-Guided Generation of Structured Chest X-Ray Report Using a Pre-trained LLM**|Hongzhao Li et.al.|[2404.11209v1](http://arxiv.org/abs/2404.11209v1)|null|
|**2024-04-17**|**Explainable Machine Learning System for Predicting Chronic Kidney Disease in High-Risk Cardiovascular Patients**|Nantika Nguycharoen et.al.|[2404.11148v1](http://arxiv.org/abs/2404.11148v1)|null|
|**2024-04-17**|**AKGNet: Attribute Knowledge-Guided Unsupervised Lung-Infected Area Segmentation**|Qing En et.al.|[2404.11008v1](http://arxiv.org/abs/2404.11008v1)|null|
|**2024-04-17**|**Leveraging 3D LiDAR Sensors to Enable Enhanced Urban Safety and Public Health: Pedestrian Monitoring and Abnormal Activity Detection**|Nawfal Guefrachi et.al.|[2404.10978v1](http://arxiv.org/abs/2404.10978v1)|null|
|**2024-04-16**|**CrossGP: Cross-Day Glucose Prediction Excluding Physiological Information**|Ziyi Zhou et.al.|[2404.10901v1](http://arxiv.org/abs/2404.10901v1)|null|
|**2024-04-16**|**Mixed Prototype Consistency Learning for Semi-supervised Medical Image Segmentation**|Lijian Li et.al.|[2404.10717v1](http://arxiv.org/abs/2404.10717v1)|null|
|**2024-04-16**|**AAVDiff: Experimental Validation of Enhanced Viability and Diversity in Recombinant Adeno-Associated Virus (AAV) Capsids through Diffusion Generation**|Lijun Liu et.al.|[2404.10573v2](http://arxiv.org/abs/2404.10573v2)|null|
|**2024-04-16**|**A Sentiment Analysis of Medical Text Based on Deep Learning**|Yinan Chen et.al.|[2404.10503v1](http://arxiv.org/abs/2404.10503v1)|null|
|**2024-04-16**|**Integration of Self-Supervised BYOL in Semi-Supervised Medical Image Recognition**|Hao Feng et.al.|[2404.10405v1](http://arxiv.org/abs/2404.10405v1)|null|
|**2024-04-16**|**Generating Counterfactual Trajectories with Latent Diffusion Models for Concept Discovery**|Payal Varshney et.al.|[2404.10356v1](http://arxiv.org/abs/2404.10356v1)|null|
|**2024-04-16**|**CARE to Compare: A real-world dataset for anomaly detection in wind turbine data**|Christian Gück et.al.|[2404.10320v2](http://arxiv.org/abs/2404.10320v2)|null|
|**2024-04-16**|**Clustering and Data Augmentation to Improve Accuracy of Sleep Assessment and Sleep Individuality Analysis**|Shintaro Tamai et.al.|[2404.10299v1](http://arxiv.org/abs/2404.10299v1)|null|
|**2024-04-15**|**Emergent Language Symbolic Autoencoder (ELSA) with Weak Supervision to Model Hierarchical Brain Networks**|Ammar Ahmed Pallikonda Latheef et.al.|[2404.10031v1](http://arxiv.org/abs/2404.10031v1)|null|
|**2024-04-15**|**Harnessing GPT-4V(ision) for Insurance: A Preliminary Exploration**|Chenwei Lin et.al.|[2404.09690v1](http://arxiv.org/abs/2404.09690v1)|null|
|**2024-04-15**|**Privacy-Preserving Intrusion Detection using Convolutional Neural Networks**|Martin Kodys et.al.|[2404.09625v1](http://arxiv.org/abs/2404.09625v1)|null|
|**2024-04-15**|**Efficient and accurate neural field reconstruction using resistive memory**|Yifei Yu et.al.|[2404.09613v1](http://arxiv.org/abs/2404.09613v1)|null|
|**2024-04-15**|**WiTUnet: A U-Shaped Architecture Integrating CNN and Transformer for Improved Feature Alignment and Local Information Fusion**|Bin Wang et.al.|[2404.09533v1](http://arxiv.org/abs/2404.09533v1)|[link](https://github.com/woldier/witunet)|
|**2024-04-14**|**Weight Copy and Low-Rank Adaptation for Few-Shot Distillation of Vision Transformers**|Diana-Nicoleta Grigore et.al.|[2404.09326v2](http://arxiv.org/abs/2404.09326v2)|null|
|**2024-04-14**|**Characterizing Soft-Error Resiliency in Arm's Ethos-U55 Embedded Machine Learning Accelerator**|Abhishek Tyagi et.al.|[2404.09317v1](http://arxiv.org/abs/2404.09317v1)|null|
|**2024-04-14**|**TLDR at SemEval-2024 Task 2: T5-generated clinical-Language summaries for DeBERTa Report Analysis**|Spandan Das et.al.|[2404.09136v1](http://arxiv.org/abs/2404.09136v1)|[link](https://github.com/shahriarnz14/tldr-t5-generated-clinical-language-for-deberta-report-analysis)|
|**2024-04-13**|**Advanced Neural Network Architecture for Enhanced Multi-Lead ECG Arrhythmia Detection through Optimized Feature Extraction**|Bhavith Chandra Challagundla et.al.|[2404.15347v1](http://arxiv.org/abs/2404.15347v1)|null|
|**2024-04-13**|**Adapting Mental Health Prediction Tasks for Cross-lingual Learning via Meta-Training and In-context Learning with Large Language Model**|Zita Lifelo et.al.|[2404.09045v1](http://arxiv.org/abs/2404.09045v1)|null|
|**2024-04-13**|**A Fourier-enhanced multi-modal 3D small object optical mark recognition and positioning method for percutaneous abdominal puncture surgical navigation**|Zezhao Guo et.al.|[2404.08990v1](http://arxiv.org/abs/2404.08990v1)|null|
|**2024-04-13**|**Leveraging Large Language Model as Simulated Patients for Clinical Education**|Yanzeng Li et.al.|[2404.13066v2](http://arxiv.org/abs/2404.13066v2)|null|
|**2024-04-12**|**Is ChatGPT Transforming Academics' Writing Style?**|Mingmeng Geng et.al.|[2404.08627v1](http://arxiv.org/abs/2404.08627v1)|null|
|**2024-04-12**|**Automatic Quantification of Serial PET/CT Images for Pediatric Hodgkin Lymphoma Patients Using a Longitudinally-Aware Segmentation Network**|Xin Tie et.al.|[2404.08611v1](http://arxiv.org/abs/2404.08611v1)|[link](https://github.com/xtie97/las-net)|
|**2024-04-12**|**RLHF Deciphered: A Critical Analysis of Reinforcement Learning from Human Feedback for LLMs**|Shreyas Chaudhari et.al.|[2404.08555v2](http://arxiv.org/abs/2404.08555v2)|null|
|**2024-04-12**|**An improved tabular data generator with VAE-GMM integration**|Patricia A. Apellániz et.al.|[2404.08434v1](http://arxiv.org/abs/2404.08434v1)|null|
|**2024-04-12**|**Improving Health Question Answering with Reliable and Time-Aware Evidence Retrieval**|Juraj Vladika et.al.|[2404.08359v1](http://arxiv.org/abs/2404.08359v1)|[link](https://github.com/jvladika/improving-health-qa)|
|**2024-04-11**|**Generating Synthetic Satellite Imagery With Deep-Learning Text-to-Image Models -- Technical Challenges and Implications for Monitoring and Verification**|Tuong Vy Nguyen et.al.|[2404.07754v1](http://arxiv.org/abs/2404.07754v1)|null|
|**2024-04-11**|**Medical mT5: An Open-Source Multilingual Text-to-Text LLM for The Medical Domain**|Iker García-Ferrero et.al.|[2404.07613v1](http://arxiv.org/abs/2404.07613v1)|null|
|**2024-04-11**|**Contrastive-Based Deep Embeddings for Label Noise-Resilient Histopathology Image Classification**|Lucas Dedieu et.al.|[2404.07605v1](http://arxiv.org/abs/2404.07605v1)|[link](https://github.com/lucasdedieu/noiseresilienthistopathology)|
|**2024-04-11**|**Socially Pertinent Robots in Gerontological Healthcare**|Xavier Alameda-Pineda et.al.|[2404.07560v1](http://arxiv.org/abs/2404.07560v1)|null|
|**2024-04-11**|**Introducing L2M3, A Multilingual Medical Large Language Model to Advance Health Equity in Low-Resource Regions**|Agasthya Gangavarapu et.al.|[2404.08705v1](http://arxiv.org/abs/2404.08705v1)|null|
|**2024-04-10**|**Measuring proximity to standard planes during fetal brain ultrasound scanning**|Chiara Di Vece et.al.|[2404.07124v1](http://arxiv.org/abs/2404.07124v1)|null|
|**2024-04-10**|**Advancing Real-time Pandemic Forecasting Using Large Language Models: A COVID-19 Case Study**|Hongru Du et.al.|[2404.06962v1](http://arxiv.org/abs/2404.06962v1)|[link](https://github.com/miemieyanga/pandemicllm)|
|**2024-04-10**|**SleepPPG-Net2: Deep learning generalization for sleep staging from photoplethysmography**|Shirel Attia et.al.|[2404.06869v1](http://arxiv.org/abs/2404.06869v1)|null|
|**2024-04-10**|**Multi-Label Continual Learning for the Medical Domain: A Novel Benchmark**|Marina Ceccon et.al.|[2404.06859v2](http://arxiv.org/abs/2404.06859v2)|null|
|**2024-04-10**|**Accuracy of a Large Language Model in Distinguishing Anti- And Pro-vaccination Messages on Social Media: The Case of Human Papillomavirus Vaccination**|Soojong Kim et.al.|[2404.06731v1](http://arxiv.org/abs/2404.06731v1)|null|
|**2024-04-09**|**Federated learning model for predicting major postoperative complications**|Yonggi Park et.al.|[2404.06641v1](http://arxiv.org/abs/2404.06641v1)|null|
|**2024-04-09**|**Test-Time Adaptation with SaLIP: A Cascade of SAM and CLIP for Zero shot Medical Image Segmentation**|Sidra Aleem et.al.|[2404.06362v1](http://arxiv.org/abs/2404.06362v1)|null|
|**2024-04-09**|**Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**|Milad Yousefi et.al.|[2404.07239v1](http://arxiv.org/abs/2404.07239v1)|null|
|**2024-04-09**|**EPL: Evidential Prototype Learning for Semi-supervised Medical Image Segmentation**|Yuanpeng He et.al.|[2404.06181v1](http://arxiv.org/abs/2404.06181v1)|null|
|**2024-04-09**|**Uncertainty-aware Evidential Fusion-based Learning for Semi-supervised Medical Image Segmentation**|Yuanpeng He et.al.|[2404.06177v2](http://arxiv.org/abs/2404.06177v2)|null|
|**2024-04-09**|**Tackling Structural Hallucination in Image Translation with Local Diffusion**|Seunghoi Kim et.al.|[2404.05980v3](http://arxiv.org/abs/2404.05980v3)|null|

#### Abstracts
##### 2404.17454v1 **Domain Adaptive and Fine-grained Anomaly Detection for Single-cell Sequencing Data and Beyond**
Kaichen Xu et.al.
Fined-grained anomalous cell detection from affected tissues is critical for
clinical diagnosis and pathological research. Single-cell sequencing data
provide unprecedented opportunities for this task. However, current anomaly
detection methods struggle to handle domain shifts prevalent in multi-sample
and multi-domain single-cell sequencing data, leading to suboptimal
performance. Moreover, these methods fall short of distinguishing anomalous
cells into pathologically distinct subtypes. In response, we propose ACSleuth,
a novel, reconstruction deviation-guided generative framework that integrates
the detection, domain adaptation, and fine-grained annotating of anomalous
cells into a methodologically cohesive workflow. Notably, we present the first
theoretical analysis of using reconstruction deviations output by generative
models for anomaly detection in lieu of domain shifts. This analysis informs us
to develop a novel and superior maximum mean discrepancy-based anomaly scorer
in ACSleuth. Extensive benchmarks over various single-cell data and other types
of tabular data demonstrate ACSleuth's superiority over the state-of-the-art
methods in identifying and subtyping anomalies in multi-sample and multi-domain
contexts. Our code is available at https://github.com/Catchxu/ACsleuth.|
##### 2404.17391v1 **M3BAT: Unsupervised Domain Adaptation for Multimodal Mobile Sensing with Multi-Branch Adversarial Training**
Lakmal Meegahapola et.al.
Over the years, multimodal mobile sensing has been used extensively for
inferences regarding health and well being, behavior, and context. However, a
significant challenge hindering the widespread deployment of such models in
real world scenarios is the issue of distribution shift. This is the phenomenon
where the distribution of data in the training set differs from the
distribution of data in the real world, the deployment environment. While
extensively explored in computer vision and natural language processing, and
while prior research in mobile sensing briefly addresses this concern, current
work primarily focuses on models dealing with a single modality of data, such
as audio or accelerometer readings, and consequently, there is little research
on unsupervised domain adaptation when dealing with multimodal sensor data. To
address this gap, we did extensive experiments with domain adversarial neural
networks (DANN) showing that they can effectively handle distribution shifts in
multimodal sensor data. Moreover, we proposed a novel improvement over DANN,
called M3BAT, unsupervised domain adaptation for multimodal mobile sensing with
multi-branch adversarial training, to account for the multimodality of sensor
data during domain adaptation with multiple branches. Through extensive
experiments conducted on two multimodal mobile sensing datasets, three
inference tasks, and 14 source-target domain pairs, including both regression
and classification, we demonstrate that our approach performs effectively on
unseen domains. Compared to directly deploying a model trained in the source
domain to the target domain, the model shows performance increases up to 12%
AUC (area under the receiver operating characteristics curves) on
classification tasks, and up to 0.13 MAE (mean absolute error) on regression
tasks.|
##### 2404.17183v1 **Prevalent Frequency of Emotional and Physical Symptoms in Social Anxiety using Zero Shot Classification: An Observational Study**
Muhammad Rizwan et.al.
Social anxiety represents a prevalent challenge in modern society, affecting
individuals across personal and professional spheres. Left unaddressed, this
condition can yield substantial negative consequences, impacting social
interactions and performance. Further understanding its diverse physical and
emotional symptoms becomes pivotal for comprehensive diagnosis and tailored
therapeutic interventions. This study analyze prevalence and frequency of
social anxiety symptoms taken from Mayo Clinic, exploring diverse human
experiences from utilizing a large Reddit dataset dedicated to this issue.
Leveraging these platforms, the research aims to extract insights and examine a
spectrum of physical and emotional symptoms linked to social anxiety disorder.
Upholding ethical considerations, the study maintains strict user anonymity
within the dataset. By employing a novel approach, the research utilizes
BART-based multi-label zero-shot classification to identify and measure symptom
prevalence and significance in the form of probability score for each symptom
under consideration. Results uncover distinctive patterns: "Trembling" emerges
as a prevalent physical symptom, while emotional symptoms like "Fear of being
judged negatively" exhibit high frequencies. These findings offer insights into
the multifaceted nature of social anxiety, aiding clinical practices and
interventions tailored to its diverse expressions.|
##### 2404.17126v1 **Deep Evidential Learning for Dose Prediction**
Hai Siong Tan et.al.
In this work, we present a novel application of an uncertainty-quantification
framework called Deep Evidential Learning in the domain of radiotherapy dose
prediction. Using medical images of the Open Knowledge-Based Planning Challenge
dataset, we found that this model can be effectively harnessed to yield
uncertainty estimates that inherited correlations with prediction errors upon
completion of network training. This was achieved only after reformulating the
original loss function for a stable implementation. We found that (i)epistemic
uncertainty was highly correlated with prediction errors, with various
association indices comparable or stronger than those for Monte-Carlo Dropout
and Deep Ensemble methods, (ii)the median error varied with uncertainty
threshold much more linearly for epistemic uncertainty in Deep Evidential
Learning relative to these other two conventional frameworks, indicative of a
more uniformly calibrated sensitivity to model errors, (iii)relative to
epistemic uncertainty, aleatoric uncertainty demonstrated a more significant
shift in its distribution in response to Gaussian noise added to CT intensity,
compatible with its interpretation as reflecting data noise. Collectively, our
results suggest that Deep Evidential Learning is a promising approach that can
endow deep-learning models in radiotherapy dose prediction with statistical
robustness. Towards enhancing its clinical relevance, we demonstrate how we can
use such a model to construct the predicted Dose-Volume-Histograms' confidence
intervals.|
##### 2404.16957v1 **Attributing Responsibility in AI-Induced Incidents: A Computational Reflective Equilibrium Framework for Accountability**
Yunfei Ge et.al.
The pervasive integration of Artificial Intelligence (AI) has introduced
complex challenges in the responsibility and accountability in the event of
incidents involving AI-enabled systems. The interconnectivity of these systems,
ethical concerns of AI-induced incidents, coupled with uncertainties in AI
technology and the absence of corresponding regulations, have made traditional
responsibility attribution challenging. To this end, this work proposes a
Computational Reflective Equilibrium (CRE) approach to establish a coherent and
ethically acceptable responsibility attribution framework for all stakeholders.
The computational approach provides a structured analysis that overcomes the
limitations of conceptual approaches in dealing with dynamic and multifaceted
scenarios, showcasing the framework's explainability, coherence, and adaptivity
properties in the responsibility attribution process. We examine the pivotal
role of the initial activation level associated with claims in equilibrium
computation. Using an AI-assisted medical decision-support system as a case
study, we illustrate how different initializations lead to diverse
responsibility distributions. The framework offers valuable insights into
accountability in AI-induced incidents, facilitating the development of a
sustainable and resilient system through continuous monitoring, revision, and
reflection.|
##### 2404.16954v1 **Taming False Positives in Out-of-Distribution Detection with Human Feedback**
Harit Vishwakarma et.al.
Robustness to out-of-distribution (OOD) samples is crucial for safely
deploying machine learning models in the open world. Recent works have focused
on designing scoring functions to quantify OOD uncertainty. Setting appropriate
thresholds for these scoring functions for OOD detection is challenging as OOD
samples are often unavailable up front. Typically, thresholds are set to
achieve a desired true positive rate (TPR), e.g., $95\%$ TPR. However, this can
lead to very high false positive rates (FPR), ranging from 60 to 96\%, as
observed in the Open-OOD benchmark. In safety-critical real-life applications,
e.g., medical diagnosis, controlling the FPR is essential when dealing with
various OOD samples dynamically. To address these challenges, we propose a
mathematically grounded OOD detection framework that leverages expert feedback
to \emph{safely} update the threshold on the fly. We provide theoretical
results showing that it is guaranteed to meet the FPR constraint at all times
while minimizing the use of human feedback. Another key feature of our
framework is that it can work with any scoring function for OOD uncertainty
quantification. Empirical evaluation of our system on synthetic and benchmark
OOD datasets shows that our method can maintain FPR at most $5\%$ while
maximizing TPR.|
##### 2404.16718v1 **Features Fusion for Dual-View Mammography Mass Detection**
Arina Varlamova et.al.
Detection of malignant lesions on mammography images is extremely important
for early breast cancer diagnosis. In clinical practice, images are acquired
from two different angles, and radiologists can fully utilize information from
both views, simultaneously locating the same lesion. However, for automatic
detection approaches such information fusion remains a challenge. In this
paper, we propose a new model called MAMM-Net, which allows the processing of
both mammography views simultaneously by sharing information not only on an
object level, as seen in existing works, but also on a feature level.
MAMM-Net's key component is the Fusion Layer, based on deformable attention and
designed to increase detection precision while keeping high recall. Our
experiments show superior performance on the public DDSM dataset compared to
the previous state-of-the-art model, while introducing new helpful features
such as lesion annotation on pixel-level and classification of lesions
malignancy.|
##### 2404.16696v1 **Report on Candidate Computational Indicators for Conscious Valenced Experience**
Andres Campero et.al.
This report enlists 13 functional conditions cashed out in computational
terms that have been argued to be constituent of conscious valenced experience.
These are extracted from existing empirical and theoretical literature on,
among others, animal sentience, medical disorders, anaesthetics, philosophy,
evolution, neuroscience, and artificial intelligence.|
##### 2404.16659v1 **ProbGate at EHRSQL 2024: Enhancing SQL Query Generation Accuracy through Probabilistic Threshold Filtering and Error Handling**
Sangryul Kim et.al.
Recently, deep learning-based language models have significantly enhanced
text-to-SQL tasks, with promising applications in retrieving patient records
within the medical domain. One notable challenge in such applications is
discerning unanswerable queries. Through fine-tuning model, we demonstrate the
feasibility of converting medical record inquiries into SQL queries.
Additionally, we introduce an entropy-based method to identify and filter out
unanswerable results. We further enhance result quality by filtering
low-confidence SQL through log probability-based distribution, while
grammatical and schema errors are mitigated by executing queries on the actual
database. We experimentally verified that our method can filter unanswerable
questions, which can be widely utilized even when the parameters of the model
are not accessible, and that it can be effectively utilized in practice.|
##### 2404.16621v1 **Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare**
Emre Can Acikgoz et.al.
The integration of Large Language Models (LLMs) into healthcare promises to
transform medical diagnostics, research, and patient care. Yet, the progression
of medical LLMs faces obstacles such as complex training requirements, rigorous
evaluation demands, and the dominance of proprietary models that restrict
academic exploration. Transparent, comprehensive access to LLM resources is
essential for advancing the field, fostering reproducibility, and encouraging
innovation in healthcare AI. We present Hippocrates, an open-source LLM
framework specifically developed for the medical domain. In stark contrast to
previous efforts, it offers unrestricted access to its training datasets,
codebase, checkpoints, and evaluation protocols. This open approach is designed
to stimulate collaborative research, allowing the community to build upon,
refine, and rigorously evaluate medical LLMs within a transparent ecosystem.
Also, we introduce Hippo, a family of 7B models tailored for the medical
domain, fine-tuned from Mistral and LLaMA2 through continual pre-training,
instruction tuning, and reinforcement learning from human and AI feedback. Our
models outperform existing open medical LLMs models by a large-margin, even
surpassing models with 70B parameters. Through Hippocrates, we aspire to unlock
the full potential of LLMs not just to advance medical knowledge and patient
care but also to democratize the benefits of AI research in healthcare, making
them available across the globe.|
##### 2404.16474v1 **DiffSeg: A Segmentation Model for Skin Lesions Based on Diffusion Difference**
Zhihao Shuai et.al.
Weakly supervised medical image segmentation (MIS) using generative models is
crucial for clinical diagnosis. However, the accuracy of the segmentation
results is often limited by insufficient supervision and the complex nature of
medical imaging. Existing models also only provide a single outcome, which does
not allow for the measurement of uncertainty. In this paper, we introduce
DiffSeg, a segmentation model for skin lesions based on diffusion difference
which exploits diffusion model principles to ex-tract noise-based features from
images with diverse semantic information. By discerning difference between
these noise features, the model identifies diseased areas. Moreover, its
multi-output capability mimics doctors' annotation behavior, facilitating the
visualization of segmentation result consistency and ambiguity. Additionally,
it quantifies output uncertainty using Generalized Energy Distance (GED),
aiding interpretability and decision-making for physicians. Finally, the model
integrates outputs through the Dense Conditional Random Field (DenseCRF)
algorithm to refine the segmentation boundaries by considering inter-pixel
correlations, which improves the accuracy and optimizes the segmentation
results. We demonstrate the effectiveness of DiffSeg on the ISIC 2018 Challenge
dataset, outperforming state-of-the-art U-Net-based methods.|
##### 2404.16346v1 **Light-weight Retinal Layer Segmentation with Global Reasoning**
Xiang He et.al.
Automatic retinal layer segmentation with medical images, such as optical
coherence tomography (OCT) images, serves as an important tool for diagnosing
ophthalmic diseases. However, it is challenging to achieve accurate
segmentation due to low contrast and blood flow noises presented in the images.
In addition, the algorithm should be light-weight to be deployed for practical
clinical applications. Therefore, it is desired to design a light-weight
network with high performance for retinal layer segmentation. In this paper, we
propose LightReSeg for retinal layer segmentation which can be applied to OCT
images. Specifically, our approach follows an encoder-decoder structure, where
the encoder part employs multi-scale feature extraction and a Transformer block
for fully exploiting the semantic information of feature maps at all scales and
making the features have better global reasoning capabilities, while the
decoder part, we design a multi-scale asymmetric attention (MAA) module for
preserving the semantic information at each encoder scale. The experiments show
that our approach achieves a better segmentation performance compared to the
current state-of-the-art method TransUnet with 105.7M parameters on both our
collected dataset and two other public datasets, with only 3.3M parameters.|
##### 2404.16325v1 **Semantic Segmentation Refiner for Ultrasound Applications with Zero-Shot Foundation Models**
Hedda Cohen Indelman et.al.
Despite the remarkable success of deep learning in medical imaging analysis,
medical image segmentation remains challenging due to the scarcity of
high-quality labeled images for supervision. Further, the significant domain
gap between natural and medical images in general and ultrasound images in
particular hinders fine-tuning models trained on natural images to the task at
hand. In this work, we address the performance degradation of segmentation
models in low-data regimes and propose a prompt-less segmentation method
harnessing the ability of segmentation foundation models to segment abstract
shapes. We do that via our novel prompt point generation algorithm which uses
coarse semantic segmentation masks as input and a zero-shot prompt-able
foundation model as an optimization target. We demonstrate our method on a
segmentation findings task (pathologic anomalies) in ultrasound images. Our
method's advantages are brought to light in varying degrees of low-data regime
experiments on a small-scale musculoskeletal ultrasound images dataset,
yielding a larger performance gain as the training set size decreases.|
##### 2404.16294v1 **LLM-Based Section Identifiers Excel on Open Source but Stumble in Real World Applications**
Saranya Krishnamoorthy et.al.
Electronic health records (EHR) even though a boon for healthcare
practitioners, are growing convoluted and longer every day. Sifting around
these lengthy EHRs is taxing and becomes a cumbersome part of physician-patient
interaction. Several approaches have been proposed to help alleviate this
prevalent issue either via summarization or sectioning, however, only a few
approaches have truly been helpful in the past. With the rise of automated
methods, machine learning (ML) has shown promise in solving the task of
identifying relevant sections in EHR. However, most ML methods rely on labeled
data which is difficult to get in healthcare. Large language models (LLMs) on
the other hand, have performed impressive feats in natural language processing
(NLP), that too in a zero-shot manner, i.e. without any labeled data. To that
end, we propose using LLMs to identify relevant section headers. We find that
GPT-4 can effectively solve the task on both zero and few-shot settings as well
as segment dramatically better than state-of-the-art methods. Additionally, we
also annotate a much harder real world dataset and find that GPT-4 struggles to
perform well, alluding to further research and harder benchmarks.|
##### 2404.16251v2 **Investigating the prompt leakage effect and black-box defenses for multi-turn LLM interactions**
Divyansh Agarwal et.al.
Prompt leakage in large language models (LLMs) poses a significant security
and privacy threat, particularly in retrieval-augmented generation (RAG)
systems. However, leakage in multi-turn LLM interactions along with mitigation
strategies has not been studied in a standardized manner. This paper
investigates LLM vulnerabilities against prompt leakage across 4 diverse
domains and 10 closed- and open-source LLMs. Our unique multi-turn threat model
leverages the LLM's sycophancy effect and our analysis dissects task
instruction and knowledge leakage in the LLM response. In a multi-turn setting,
our threat model elevates the average attack success rate (ASR) to 86.2%,
including a 99% leakage with GPT-4 and claude-1.3. We find that some black-box
LLMs like Gemini show variable susceptibility to leakage across domains - they
are more likely to leak contextual knowledge in the news domain compared to the
medical domain. Our experiments measure specific effects of 6 black-box defense
strategies, including a query-rewriter in the RAG scenario. Our proposed
multi-tier combination of defenses still has an ASR of 5.3% for black-box LLMs,
indicating room for enhancement and future direction for LLM security research.|
##### 2404.16183v1 **ABCD: Trust enhanced Attention based Convolutional Autoencoder for Risk Assessment**
Sarala Naidu et.al.
Anomaly detection in industrial systems is crucial for preventing equipment
failures, ensuring risk identification, and maintaining overall system
efficiency. Traditional monitoring methods often rely on fixed thresholds and
empirical rules, which may not be sensitive enough to detect subtle changes in
system health and predict impending failures. To address this limitation, this
paper proposes, a novel Attention-based convolutional autoencoder (ABCD) for
risk detection and map the risk value derive to the maintenance planning. ABCD
learns the normal behavior of conductivity from historical data of a real-world
industrial cooling system and reconstructs the input data, identifying
anomalies that deviate from the expected patterns. The framework also employs
calibration techniques to ensure the reliability of its predictions. Evaluation
results demonstrate that with the attention mechanism in ABCD a 57.4% increase
in performance and a reduction of false alarms by 9.37% is seen compared to
without attention. The approach can effectively detect risks, the risk priority
rank mapped to maintenance, providing valuable insights for cooling system
designers and service personnel. Calibration error of 0.03% indicates that the
model is well-calibrated and enhances model's trustworthiness, enabling
informed decisions about maintenance strategies|
##### 2404.16112v1 **Mamba-360: Survey of State Space Models as Transformer Alternative for Long Sequence Modelling: Methods, Applications, and Challenges**
Badri Narayana Patro et.al.
Sequence modeling is a crucial area across various domains, including Natural
Language Processing (NLP), speech recognition, time series forecasting, music
generation, and bioinformatics. Recurrent Neural Networks (RNNs) and Long Short
Term Memory Networks (LSTMs) have historically dominated sequence modeling
tasks like Machine Translation, Named Entity Recognition (NER), etc. However,
the advancement of transformers has led to a shift in this paradigm, given
their superior performance. Yet, transformers suffer from $O(N^2)$ attention
complexity and challenges in handling inductive bias. Several variations have
been proposed to address these issues which use spectral networks or
convolutions and have performed well on a range of tasks. However, they still
have difficulty in dealing with long sequences. State Space Models(SSMs) have
emerged as promising alternatives for sequence modeling paradigms in this
context, especially with the advent of S4 and its variants, such as S4nd,
Hippo, Hyena, Diagnol State Spaces (DSS), Gated State Spaces (GSS), Linear
Recurrent Unit (LRU), Liquid-S4, Mamba, etc. In this survey, we categorize the
foundational SSMs based on three paradigms namely, Gating architectures,
Structural architectures, and Recurrent architectures. This survey also
highlights diverse applications of SSMs across domains such as vision, video,
audio, speech, language (especially long sequence modeling), medical (including
genomics), chemical (like drug design), recommendation systems, and time series
analysis, including tabular data. Moreover, we consolidate the performance of
SSMs on benchmark datasets like Long Range Arena (LRA), WikiText, Glue, Pile,
ImageNet, Kinetics-400, sstv2, as well as video datasets such as Breakfast,
COIN, LVU, and various time series datasets. The project page for Mamba-360
work is available on this webpage.\url{https://github.com/badripatro/mamba360}.|
##### 2404.15946v1 **Mammo-CLIP: Leveraging Contrastive Language-Image Pre-training (CLIP) for Enhanced Breast Cancer Diagnosis with Multi-view Mammography**
Xuxin Chen et.al.
Although fusion of information from multiple views of mammograms plays an
important role to increase accuracy of breast cancer detection, developing
multi-view mammograms-based computer-aided diagnosis (CAD) schemes still faces
challenges and no such CAD schemes have been used in clinical practice. To
overcome the challenges, we investigate a new approach based on Contrastive
Language-Image Pre-training (CLIP), which has sparked interest across various
medical imaging tasks. By solving the challenges in (1) effectively adapting
the single-view CLIP for multi-view feature fusion and (2) efficiently
fine-tuning this parameter-dense model with limited samples and computational
resources, we introduce Mammo-CLIP, the first multi-modal framework to process
multi-view mammograms and corresponding simple texts. Mammo-CLIP uses an early
feature fusion strategy to learn multi-view relationships in four mammograms
acquired from the CC and MLO views of the left and right breasts. To enhance
learning efficiency, plug-and-play adapters are added into CLIP image and text
encoders for fine-tuning parameters and limiting updates to about 1% of the
parameters. For framework evaluation, we assembled two datasets
retrospectively. The first dataset, comprising 470 malignant and 479 benign
cases, was used for few-shot fine-tuning and internal evaluation of the
proposed Mammo-CLIP via 5-fold cross-validation. The second dataset, including
60 malignant and 294 benign cases, was used to test generalizability of
Mammo-CLIP. Study results show that Mammo-CLIP outperforms the state-of-art
cross-view transformer in AUC (0.841 vs. 0.817, 0.837 vs. 0.807) on both
datasets. It also surpasses previous two CLIP-based methods by 20.3% and 14.3%.
This study highlights the potential of applying the finetuned vision-language
models for developing next-generation, image-text-based CAD schemes of breast
cancer.|
##### 2404.15894v1 **Assessing The Potential Of Mid-Sized Language Models For Clinical QA**
Elliot Bolton et.al.
Large language models, such as GPT-4 and Med-PaLM, have shown impressive
performance on clinical tasks; however, they require access to compute, are
closed-source, and cannot be deployed on device. Mid-size models such as
BioGPT-large, BioMedLM, LLaMA 2, and Mistral 7B avoid these drawbacks, but
their capacity for clinical tasks has been understudied. To help assess their
potential for clinical use and help researchers decide which model they should
use, we compare their performance on two clinical question-answering (QA)
tasks: MedQA and consumer query answering. We find that Mistral 7B is the best
performing model, winning on all benchmarks and outperforming models trained
specifically for the biomedical domain. While Mistral 7B's MedQA score of 63.0%
approaches the original Med-PaLM, and it often can produce plausible responses
to consumer health queries, room for improvement still exists. This study
provides the first head-to-head assessment of open source mid-sized models on
clinical tasks.|
##### 2404.16080v1 **Enhancing Diagnosis through AI-driven Analysis of Reflectance Confocal Microscopy**
Hong-Jun Yoon et.al.
Reflectance Confocal Microscopy (RCM) is a non-invasive imaging technique
used in biomedical research and clinical dermatology. It provides virtual
high-resolution images of the skin and superficial tissues, reducing the need
for physical biopsies. RCM employs a laser light source to illuminate the
tissue, capturing the reflected light to generate detailed images of
microscopic structures at various depths. Recent studies explored AI and
machine learning, particularly CNNs, for analyzing RCM images. Our study
proposes a segmentation strategy based on textural features to identify
clinically significant regions, empowering dermatologists in effective image
interpretation and boosting diagnostic confidence. This approach promises to
advance dermatological diagnosis and treatment.|
##### 2404.16887v1 **Anomaly Detection for Incident Response at Scale**
Hanzhang Wang et.al.
We present a machine learning-based anomaly detection product, AI Detect and
Respond (AIDR), that monitors Walmart's business and system health in
real-time. During the validation over 3 months, the product served predictions
from over 3000 models to more than 25 application, platform, and operation
teams, covering 63\% of major incidents and reducing the mean-time-to-detect
(MTTD) by more than 7 minutes. Unlike previous anomaly detection methods, our
solution leverages statistical, ML and deep learning models while continuing to
incorporate rule-based static thresholds to incorporate domain-specific
knowledge. Both univariate and multivariate ML models are deployed and
maintained through distributed services for scalability and high availability.
AIDR has a feedback loop that assesses model quality with a combination of
drift detection algorithms and customer feedback. It also offers
self-onboarding capabilities and customizability. AIDR has achieved success
with various internal teams with lower time to detection and fewer false
positives than previous methods. As we move forward, we aim to expand incident
coverage and prevention, reduce noise, and integrate further with root cause
recommendation (RCR) to enable an end-to-end AIDR experience.|
##### 2404.16885v1 **Adapting an Artificial Intelligence Sexually Transmitted Diseases Symptom Checker Tool for Mpox Detection: The HeHealth Experience**
Rayner Kay Jin Tan et.al.
Artificial Intelligence applications have shown promise in the management of
pandemics and have been widely used to assist the identification,
classification, and diagnosis of medical images. In response to the global
outbreak of Monkeypox (Mpox), the HeHealth.ai team leveraged an existing tool
to screen for sexually transmitted diseases to develop a digital screening test
for symptomatic Mpox through AI approaches. Prior to the global outbreak of
Mpox, the team developed a smartphone app, where app users can use their own
smartphone cameras to take pictures of their own penises to screen for
symptomatic STD. The AI model was initially developed using 5000 cases and use
a modified convolutional neural network to output prediction scores across
visually diagnosable penis pathologies including Syphilis, Herpes Simplex
Virus, and Human Papilloma Virus. From June 2022 to October 2022, a total of
about 22,000 users downloaded the HeHealth app, and about 21,000 images have
been analyzed using HeHealth AI technology. We then engaged in formative
research, stakeholder engagement, rapid consolidation images, a validation
study, and implementation of the tool from July 2022. From July 2022 to October
2022, a total of 1000 Mpox related images had been used to train the Mpox
symptom checker tool. Our digital symptom checker tool showed accuracy of 87%
to rule in Mpox and 90% to rule out symptomatic Mpox. Several hurdles
identified included issues of data privacy and security for app users, initial
lack of data to train the AI tool, and the potential generalizability of input
data. We offer several suggestions to help others get started on similar
projects in emergency situations, including engaging a wide range of
stakeholders, having a multidisciplinary team, prioritizing pragmatism, as well
as the concept that big data in fact is made up of small data.|
##### 2404.15549v1 **PRISM: Patient Records Interpretation for Semantic Clinical Trial Matching using Large Language Models**
Shashi Kant Gupta et.al.
Clinical trial matching is the task of identifying trials for which patients
may be potentially eligible. Typically, this task is labor-intensive and
requires detailed verification of patient electronic health records (EHRs)
against the stringent inclusion and exclusion criteria of clinical trials. This
process is manual, time-intensive, and challenging to scale up, resulting in
many patients missing out on potential therapeutic options. Recent advancements
in Large Language Models (LLMs) have made automating patient-trial matching
possible, as shown in multiple concurrent research studies. However, the
current approaches are confined to constrained, often synthetic datasets that
do not adequately mirror the complexities encountered in real-world medical
data. In this study, we present the first, end-to-end large-scale empirical
evaluation of clinical trial matching using real-world EHRs. Our study
showcases the capability of LLMs to accurately match patients with appropriate
clinical trials. We perform experiments with proprietary LLMs, including GPT-4
and GPT-3.5, as well as our custom fine-tuned model called OncoLLM and show
that OncoLLM, despite its significantly smaller size, not only outperforms
GPT-3.5 but also matches the performance of qualified medical doctors. All
experiments were carried out on real-world EHRs that include clinical notes and
available clinical trials from a single cancer center in the United States.|
##### 2404.15492v1 **Multi-scale Intervention Planning based on Generative Design**
Ioannis Kavouras et.al.
The scarcity of green spaces, in urban environments, consists a critical
challenge. There are multiple adverse effects, impacting the health and
well-being of the citizens. Small scale interventions, e.g. pocket parks, is a
viable solution, but comes with multiple constraints, involving the design and
implementation over a specific area. In this study, we harness the capabilities
of generative AI for multi-scale intervention planning, focusing on nature
based solutions. By leveraging image-to-image and image inpainting algorithms,
we propose a methodology to address the green space deficit in urban areas.
Focusing on two alleys in Thessaloniki, where greenery is lacking, we
demonstrate the efficacy of our approach in visualizing NBS interventions. Our
findings underscore the transformative potential of emerging technologies in
shaping the future of urban intervention planning processes.|
##### 2404.15488v1 **IryoNLP at MEDIQA-CORR 2024: Tackling the Medical Error Detection & Correction Task On the Shoulders of Medical Agents**
Jean-Philippe Corbeil et.al.
In natural language processing applied to the clinical domain, utilizing
large language models has emerged as a promising avenue for error detection and
correction on clinical notes, a knowledge-intensive task for which annotated
data is scarce. This paper presents MedReAct'N'MedReFlex, which leverages a
suite of four LLM-based medical agents. The MedReAct agent initiates the
process by observing, analyzing, and taking action, generating trajectories to
guide the search to target a potential error in the clinical notes.
Subsequently, the MedEval agent employs five evaluators to assess the targeted
error and the proposed correction. In cases where MedReAct's actions prove
insufficient, the MedReFlex agent intervenes, engaging in reflective analysis
and proposing alternative strategies. Finally, the MedFinalParser agent formats
the final output, preserving the original style while ensuring the integrity of
the error correction process. One core component of our method is our RAG
pipeline based on our ClinicalCorp corpora. Among other well-known sources
containing clinical guidelines and information, we preprocess and release the
open-source MedWiki dataset for clinical RAG application. Our results
demonstrate the central role of our RAG approach with ClinicalCorp leveraged
through the MedReAct'N'MedReFlex framework. It achieved the ninth rank on the
MEDIQA-CORR 2024 final leaderboard.|
##### 2404.15418v1 **Machine Learning Techniques with Fairness for Prediction of Completion of Drug and Alcohol Rehabilitation**
Karen Roberts-Licklider et.al.
The aim of this study is to look at predicting whether a person will complete
a drug and alcohol rehabilitation program and the number of times a person
attends. The study is based on demographic data obtained from Substance Abuse
and Mental Health Services Administration (SAMHSA) from both admissions and
discharge data from drug and alcohol rehabilitation centers in Oklahoma.
Demographic data is highly categorical which led to binary encoding being used
and various fairness measures being utilized to mitigate bias of nine
demographic variables. Kernel methods such as linear, polynomial, sigmoid, and
radial basis functions were compared using support vector machines at various
parameter ranges to find the optimal values. These were then compared to
methods such as decision trees, random forests, and neural networks. Synthetic
Minority Oversampling Technique Nominal (SMOTEN) for categorical data was used
to balance the data with imputation for missing data. The nine bias variables
were then intersectionalized to mitigate bias and the dual and triple
interactions were integrated to use the probabilities to look at worst case
ratio fairness mitigation. Disparate Impact, Statistical Parity difference,
Conditional Statistical Parity Ratio, Demographic Parity, Demographic Parity
Ratio, Equalized Odds, Equalized Odds Ratio, Equal Opportunity, and Equalized
Opportunity Ratio were all explored at both the binary and multiclass
scenarios.|
##### 2404.15272v2 **CT-GLIP: 3D Grounded Language-Image Pretraining with CT Scans and Radiology Reports for Full-Body Scenarios**
Jingyang Lin et.al.
Medical Vision-Language Pretraining (Med-VLP) establishes a connection
between visual content from medical images and the relevant textual
descriptions. Existing Med-VLP methods primarily focus on 2D images depicting a
single body part, notably chest X-rays. In this paper, we extend the scope of
Med-VLP to encompass 3D images, specifically targeting full-body scenarios, by
using a multimodal dataset of CT images and reports. Compared with the 2D
counterpart, 3D VLP is required to effectively capture essential semantics from
significantly sparser representation in 3D imaging. In this paper, we introduce
CT-GLIP (Grounded Language-Image Pretraining with CT scans), a novel method
that constructs organ-level image-text pairs to enhance multimodal contrastive
learning, aligning grounded visual features with precise diagnostic text.
Additionally, we developed an abnormality dictionary to augment contrastive
learning with diverse contrastive pairs. Our method, trained on a multimodal CT
dataset comprising 44,011 organ-level vision-text pairs from 17,702 patients
across 104 organs, demonstrates it can identify organs and abnormalities in a
zero-shot manner using natural languages. The performance of CT-GLIP is
validated on a separate test set of 1,130 patients, focusing on the 16 most
frequent abnormalities across 7 organs. The experimental results show our
model's superior performance over the standard CLIP framework across zero-shot
and fine-tuning scenarios, using both CNN and ViT architectures.|
##### 2404.15022v1 **A review of deep learning-based information fusion techniques for multimodal medical image classification**
Yihao Li et.al.
Multimodal medical imaging plays a pivotal role in clinical diagnosis and
research, as it combines information from various imaging modalities to provide
a more comprehensive understanding of the underlying pathology. Recently, deep
learning-based multimodal fusion techniques have emerged as powerful tools for
improving medical image classification. This review offers a thorough analysis
of the developments in deep learning-based multimodal fusion for medical
classification tasks. We explore the complementary relationships among
prevalent clinical modalities and outline three main fusion schemes for
multimodal classification networks: input fusion, intermediate fusion
(encompassing single-level fusion, hierarchical fusion, and attention-based
fusion), and output fusion. By evaluating the performance of these fusion
techniques, we provide insight into the suitability of different network
architectures for various multimodal fusion scenarios and application domains.
Furthermore, we delve into challenges related to network architecture
selection, handling incomplete multimodal data management, and the potential
limitations of multimodal fusion. Finally, we spotlight the promising future of
Transformer-based multimodal fusion techniques and give recommendations for
future research in this rapidly evolving field.|
##### 2404.15379v1 **Clustering of timed sequences -- Application to the analysis of care pathways**
Thomas Guyet et.al.
Improving the future of healthcare starts by better understanding the current
actual practices in hospitals. This motivates the objective of discovering
typical care pathways from patient data. Revealing homogeneous groups of care
pathways can be achieved through clustering. The difficulty in clustering care
pathways, represented by sequences of timestamped events, lies in defining a
semantically appropriate metric and clustering algorithms.
  In this article, we adapt two methods developed for time series to time
sequences: the drop-DTW metric and the DBA approach for the construction of
averaged time sequences. These methods are then applied in clustering
algorithms to propose original and sound clustering algorithms for timed
sequences.
  This approach is experimented with and evaluated on synthetic and real use
cases.|
##### 2404.14750v1 **Grounded Knowledge-Enhanced Medical VLP for Chest X-Ray**
Qiao Deng et.al.
Medical vision-language pre-training has emerged as a promising approach for
learning domain-general representations of medical image and text. Current
algorithms that exploit the global and local alignment between medical image
and text could however be marred by the redundant information in medical data.
To address this issue, we propose a grounded knowledge-enhanced medical
vision-language pre-training (GK-MVLP) framework for chest X-ray. In this
framework, medical knowledge is grounded to the appropriate anatomical regions
by using a transformer-based grounded knowledge-enhanced module for
fine-grained alignment between anatomical region-level visual features and the
textural features of medical knowledge. The performance of GK-MVLP is
competitive with or exceeds the state of the art on downstream chest X-ray
disease classification, disease localization, report generation, and medical
visual question-answering tasks. Our results show the advantage of
incorporating grounding mechanism to remove biases and improve the alignment
between chest X-ray image and radiology report.|
##### 2404.14463v1 **DAIC-WOZ: On the Validity of Using the Therapist's prompts in Automatic Depression Detection from Clinical Interviews**
Sergio Burdisso et.al.
Automatic depression detection from conversational data has gained
significant interest in recent years. The DAIC-WOZ dataset, interviews
conducted by a human-controlled virtual agent, has been widely used for this
task. Recent studies have reported enhanced performance when incorporating
interviewer's prompts into the model. In this work, we hypothesize that this
improvement might be mainly due to a bias present in these prompts, rather than
the proposed architectures and methods. Through ablation experiments and
qualitative analysis, we discover that models using interviewer's prompts learn
to focus on a specific region of the interviews, where questions about past
experiences with mental health issues are asked, and use them as discriminative
shortcuts to detect depressed participants. In contrast, models using
participant responses gather evidence from across the entire interview.
Finally, to highlight the magnitude of this bias, we achieve a 0.90 F1 score by
intentionally exploiting it, the highest result reported to date on this
dataset using only textual information. Our findings underline the need for
caution when incorporating interviewers' prompts into models, as they may
inadvertently learn to exploit targeted prompts, rather than learning to
characterize the language and behavior that are genuinely indicative of the
patient's mental health condition.|
##### 2404.15155v1 **Adaptive Collaboration Strategy for LLMs in Medical Decision Making**
Yubin Kim et.al.
Foundation models have become invaluable in advancing the medical field.
Despite their promise, the strategic deployment of LLMs for effective utility
in complex medical tasks remains an open question. Our novel framework, Medical
Decision-making Agents (MDAgents) aims to address this gap by automatically
assigning the effective collaboration structure for LLMs. Assigned solo or
group collaboration structure is tailored to the complexity of the medical task
at hand, emulating real-world medical decision making processes. We evaluate
our framework and baseline methods with state-of-the-art LLMs across a suite of
challenging medical benchmarks: MedQA, MedMCQA, PubMedQA, DDXPlus, PMC-VQA,
Path-VQA, and MedVidQA, achieving the best performance in 5 out of 7 benchmarks
that require an understanding of multi-modal medical reasoning. Ablation
studies reveal that MDAgents excels in adapting the number of collaborating
agents to optimize efficiency and accuracy, showcasing its robustness in
diverse scenarios. We also explore the dynamics of group consensus, offering
insights into how collaborative agents could behave in complex clinical team
dynamics. Our code can be found at https://github.com/mitmedialab/MDAgents.|
##### 2404.13745v1 **A Nasal Cytology Dataset for Object Detection and Deep Learning**
Mauro Camporeale et.al.
Nasal Cytology is a new and efficient clinical technique to diagnose rhinitis
and allergies that is not much widespread due to the time-consuming nature of
cell counting; that is why AI-aided counting could be a turning point for the
diffusion of this technique. In this article we present the first dataset of
rhino-cytological field images: the NCD (Nasal Cytology Dataset), aimed to
train and deploy Object Detection models to support physicians and biologists
during clinical practice. The real distribution of the cytotypes, populating
the nasal mucosa has been replicated, sampling images from slides of clinical
patients, and manually annotating each cell found on them. The correspondent
object detection task presents non'trivial issues associated with the strong
class imbalancement, involving the rarest cell types. This work contributes to
some of open challenges by presenting a novel machine learning-based approach
to aid the automated detection and classification of nasal mucosa cells: the
DETR and YOLO models shown good performance in detecting cells and classifying
them correctly, revealing great potential to accelerate the work of rhinology
experts.|
##### 2404.13634v3 **Bt-GAN: Generating Fair Synthetic Healthdata via Bias-transforming Generative Adversarial Networks**
Resmi Ramachandranpillai et.al.
Synthetic data generation offers a promising solution to enhance the
usefulness of Electronic Healthcare Records (EHR) by generating realistic
de-identified data. However, the existing literature primarily focuses on the
quality of synthetic health data, neglecting the crucial aspect of fairness in
downstream predictions. Consequently, models trained on synthetic EHR have
faced criticism for producing biased outcomes in target tasks. These biases can
arise from either spurious correlations between features or the failure of
models to accurately represent sub-groups. To address these concerns, we
present Bias-transforming Generative Adversarial Networks (Bt-GAN), a GAN-based
synthetic data generator specifically designed for the healthcare domain. In
order to tackle spurious correlations (i), we propose an
information-constrained Data Generation Process that enables the generator to
learn a fair deterministic transformation based on a well-defined notion of
algorithmic fairness. To overcome the challenge of capturing exact sub-group
representations (ii), we incentivize the generator to preserve sub-group
densities through score-based weighted sampling. This approach compels the
generator to learn from underrepresented regions of the data manifold. We
conduct extensive experiments using the MIMIC-III database. Our results
demonstrate that Bt-GAN achieves SOTA accuracy while significantly improving
fairness and minimizing bias amplification. We also perform an in-depth
explainability analysis to provide additional evidence supporting the validity
of our study. In conclusion, our research introduces a novel and professional
approach to addressing the limitations of synthetic data generation in the
healthcare domain. By incorporating fairness considerations and leveraging
advanced techniques such as GANs, we pave the way for more reliable and
unbiased predictions in healthcare applications.|
##### 2404.13528v1 **SmartMem: Layout Transformation Elimination and Adaptation for Efficient DNN Execution on Mobile**
Wei Niu et.al.
This work is motivated by recent developments in Deep Neural Networks,
particularly the Transformer architectures underlying applications such as
ChatGPT, and the need for performing inference on mobile devices. Focusing on
emerging transformers (specifically the ones with computationally efficient
Swin-like architectures) and large models (e.g., Stable Diffusion and LLMs)
based on transformers, we observe that layout transformations between the
computational operators cause a significant slowdown in these applications.
This paper presents SmartMem, a comprehensive framework for eliminating most
layout transformations, with the idea that multiple operators can use the same
tensor layout through careful choice of layout and implementation of
operations. Our approach is based on classifying the operators into four
groups, and considering combinations of producer-consumer edges between the
operators. We develop a set of methods for searching such layouts. Another
component of our work is developing efficient memory layouts for 2.5
dimensional memory commonly seen in mobile devices. Our experimental results
show that SmartMem outperforms 5 state-of-the-art DNN execution frameworks on
mobile devices across 18 varied neural networks, including CNNs, Transformers
with both local and global attention, as well as LLMs. In particular, compared
to DNNFusion, SmartMem achieves an average speedup of 2.8$\times$, and
outperforms TVM and MNN with speedups of 6.9$\times$ and 7.9$\times$,
respectively, on average.|
##### 2404.13506v2 **Parameter Efficient Fine Tuning: A Comprehensive Analysis Across Applications**
Charith Chandra Sai Balne et.al.
The rise of deep learning has marked significant progress in fields such as
computer vision, natural language processing, and medical imaging, primarily
through the adaptation of pre-trained models for specific tasks. Traditional
fine-tuning methods, involving adjustments to all parameters, face challenges
due to high computational and memory demands. This has led to the development
of Parameter Efficient Fine-Tuning (PEFT) techniques, which selectively update
parameters to balance computational efficiency with performance. This review
examines PEFT approaches, offering a detailed comparison of various strategies
highlighting applications across different domains, including text generation,
medical imaging, protein modeling, and speech synthesis. By assessing the
effectiveness of PEFT methods in reducing computational load, speeding up
training, and lowering memory usage, this paper contributes to making deep
learning more accessible and adaptable, facilitating its wider application and
encouraging innovation in model optimization. Ultimately, the paper aims to
contribute towards insights into PEFT's evolving landscape, guiding researchers
and practitioners in overcoming the limitations of conventional fine-tuning
approaches.|
##### 2404.13449v1 **SiNC+: Adaptive Camera-Based Vitals with Unsupervised Learning of Periodic Signals**
Jeremy Speth et.al.
Subtle periodic signals, such as blood volume pulse and respiration, can be
extracted from RGB video, enabling noncontact health monitoring at low cost.
Advancements in remote pulse estimation -- or remote photoplethysmography
(rPPG) -- are currently driven by deep learning solutions. However, modern
approaches are trained and evaluated on benchmark datasets with ground truth
from contact-PPG sensors. We present the first non-contrastive unsupervised
learning framework for signal regression to mitigate the need for labelled
video data. With minimal assumptions of periodicity and finite bandwidth, our
approach discovers the blood volume pulse directly from unlabelled videos. We
find that encouraging sparse power spectra within normal physiological
bandlimits and variance over batches of power spectra is sufficient for
learning visual features of periodic signals. We perform the first experiments
utilizing unlabelled video data not specifically created for rPPG to train
robust pulse rate estimators. Given the limited inductive biases, we
successfully applied the same approach to camera-based respiration by changing
the bandlimits of the target signal. This shows that the approach is general
enough for unsupervised learning of bandlimited quasi-periodic signals from
different domains. Furthermore, we show that the framework is effective for
finetuning models on unlabelled video from a single subject, allowing for
personalized and adaptive signal regressors.|
##### 2404.13421v1 **MultiConfederated Learning: Inclusive Non-IID Data handling with Decentralized Federated Learning**
Michael Duchesne et.al.
Federated Learning (FL) has emerged as a prominent privacy-preserving
technique for enabling use cases like confidential clinical machine learning.
FL operates by aggregating models trained by remote devices which owns the
data. Thus, FL enables the training of powerful global models using
crowd-sourced data from a large number of learners, without compromising their
privacy. However, the aggregating server is a single point of failure when
generating the global model. Moreover, the performance of the model suffers
when the data is not independent and identically distributed (non-IID data) on
all remote devices. This leads to vastly different models being aggregated,
which can reduce the performance by as much as 50% in certain scenarios.
  In this paper, we seek to address the aforementioned issues while retaining
the benefits of FL. We propose MultiConfederated Learning: a decentralized FL
framework which is designed to handle non-IID data. Unlike traditional FL,
MultiConfederated Learning will maintain multiple models in parallel (instead
of a single global model) to help with convergence when the data is non-IID.
With the help of transfer learning, learners can converge to fewer models. In
order to increase adaptability, learners are allowed to choose which updates to
aggregate from their peers.|
##### 2404.13343v1 **UnibucLLM: Harnessing LLMs for Automated Prediction of Item Difficulty and Response Time for Multiple-Choice Questions**
Ana-Cristina Rogoz et.al.
This work explores a novel data augmentation method based on Large Language
Models (LLMs) for predicting item difficulty and response time of retired USMLE
Multiple-Choice Questions (MCQs) in the BEA 2024 Shared Task. Our approach is
based on augmenting the dataset with answers from zero-shot LLMs (Falcon,
Meditron, Mistral) and employing transformer-based models based on six
alternative feature combinations. The results suggest that predicting the
difficulty of questions is more challenging. Notably, our top performing
methods consistently include the question text, and benefit from the
variability of LLM answers, highlighting the potential of LLMs for improving
automated assessment in medical licensing exams. We make our code available
https://github.com/ana-rogoz/BEA-2024.|
##### 2404.14444v1 **Practical Battery Health Monitoring using Uncertainty-Aware Bayesian Neural Network**
Yunyi Zhao et.al.
Battery health monitoring and prediction are critically important in the era
of electric mobility with a huge impact on safety, sustainability, and economic
aspects. Existing research often focuses on prediction accuracy but tends to
neglect practical factors that may hinder the technology's deployment in
real-world applications. In this paper, we address these practical
considerations and develop models based on the Bayesian neural network for
predicting battery end-of-life. Our models use sensor data related to battery
health and apply distributions, rather than single-point, for each parameter of
the models. This allows the models to capture the inherent randomness and
uncertainty of battery health, which leads to not only accurate predictions but
also quantifiable uncertainty. We conducted an experimental study and
demonstrated the effectiveness of our proposed models, with a prediction error
rate averaging 13.9%, and as low as 2.9% for certain tested batteries.
Additionally, all predictions include quantifiable certainty, which improved by
66% from the initial to the mid-life stage of the battery. This research has
practical values for battery technologies and contributes to accelerating the
technology adoption in the industry.|
##### 2404.13149v1 **Beyond Self-Consistency: Ensemble Reasoning Boosts Consistency and Accuracy of LLMs in Cancer Staging**
Chia-Hsuan Chang et.al.
Advances in large language models (LLMs) have encouraged their adoption in
the healthcare domain where vital clinical information is often contained in
unstructured notes. Cancer staging status is available in clinical reports, but
it requires natural language processing to extract the status from the
unstructured text. With the advance in clinical-oriented LLMs, it is promising
to extract such status without extensive efforts in training the algorithms.
Prompting approaches of the pre-trained LLMs that elicit a model's reasoning
process, such as chain-of-thought, may help to improve the trustworthiness of
the generated responses. Using self-consistency further improves model
performance, but often results in inconsistent generations across the multiple
reasoning paths. In this study, we propose an ensemble reasoning approach with
the aim of improving the consistency of the model generations. Using an open
access clinical large language model to determine the pathologic cancer stage
from real-world pathology reports, we show that the ensemble reasoning approach
is able to improve both the consistency and performance of the LLM in
determining cancer stage, thereby demonstrating the potential to use these
models in clinical or other domains where reliability and trustworthiness are
critical.|
##### 2404.13139v1 **Explainable AI for Fair Sepsis Mortality Predictive Model**
Chia-Hsuan Chang et.al.
Artificial intelligence supports healthcare professionals with predictive
modeling, greatly transforming clinical decision-making. This study addresses
the crucial need for fairness and explainability in AI applications within
healthcare to ensure equitable outcomes across diverse patient demographics. By
focusing on the predictive modeling of sepsis-related mortality, we propose a
method that learns a performance-optimized predictive model and then employs
the transfer learning process to produce a model with better fairness. Our
method also introduces a novel permutation-based feature importance algorithm
aiming at elucidating the contribution of each feature in enhancing fairness on
predictions. Unlike existing explainability methods concentrating on explaining
feature contribution to predictive performance, our proposed method uniquely
bridges the gap in understanding how each feature contributes to fairness. This
advancement is pivotal, given sepsis's significant mortality rate and its role
in one-third of hospital deaths. Our method not only aids in identifying and
mitigating biases within the predictive model but also fosters trust among
healthcare stakeholders by improving the transparency and fairness of model
predictions, thereby contributing to more equitable and trustworthy healthcare
delivery.|
##### 2404.12984v1 **Eye-tracking in Mixed Reality for Diagnosis of Neurodegenerative Diseases**
Mateusz Daniol et.al.
Parkinson's disease ranks as the second most prevalent neurodegenerative
disorder globally. This research aims to develop a system leveraging Mixed
Reality capabilities for tracking and assessing eye movements. In this paper,
we present a medical scenario and outline the development of an application
designed to capture eye-tracking signals through Mixed Reality technology for
the evaluation of neurodegenerative diseases. Additionally, we introduce a
pipeline for extracting clinically relevant features from eye-gaze analysis,
describing the capabilities of the proposed system from a medical perspective.
The study involved a cohort of healthy control individuals and patients
suffering from Parkinson's disease, showcasing the feasibility and potential of
the proposed technology for non-intrusive monitoring of eye movement patterns
for the diagnosis of neurodegenerative diseases.
  Clinical relevance - Developing a non-invasive biomarker for Parkinson's
disease is urgently needed to accurately detect the disease's onset. This would
allow for the timely introduction of neuroprotective treatment at the earliest
stage and enable the continuous monitoring of intervention outcomes. The
ability to detect subtle changes in eye movements allows for early diagnosis,
offering a critical window for intervention before more pronounced symptoms
emerge. Eye tracking provides objective and quantifiable biomarkers, ensuring
reliable assessments of disease progression and cognitive function. The eye
gaze analysis using Mixed Reality glasses is wireless, facilitating convenient
assessments in both home and hospital settings. The approach offers the
advantage of utilizing hardware that requires no additional specialized
attachments, enabling examinations through personal eyewear.|
##### 2404.12876v1 **A Large-scale Medical Visual Task Adaptation Benchmark**
Shentong Mo et.al.
Visual task adaptation has been demonstrated to be effective in adapting
pre-trained Vision Transformers (ViTs) to general downstream visual tasks using
specialized learnable layers or tokens. However, there is yet a large-scale
benchmark to fully explore the effect of visual task adaptation on the
realistic and important medical domain, particularly across diverse medical
visual modalities, such as color images, X-ray, and CT. To close this gap, we
present Med-VTAB, a large-scale Medical Visual Task Adaptation Benchmark
consisting of 1.68 million medical images for diverse organs, modalities, and
adaptation approaches. Based on Med-VTAB, we explore the scaling law of medical
prompt tuning concerning tunable parameters and the generalizability of medical
visual adaptation using non-medical/medical pre-train weights. Besides, we
study the impact of patient ID out-of-distribution on medical visual
adaptation, which is a real and challenging scenario. Furthermore, results from
Med-VTAB indicate that a single pre-trained model falls short in medical task
adaptation. Therefore, we introduce GMoE-Adapter, a novel method that combines
medical and general pre-training weights through a gated mixture-of-experts
adapter, achieving state-of-the-art results in medical visual task adaptation.|
##### 2404.13104v1 **Multi Class Depression Detection Through Tweets using Artificial Intelligence**
Muhammad Osama Nusrat et.al.
Depression is a significant issue nowadays. As per the World Health
Organization (WHO), in 2023, over 280 million individuals are grappling with
depression. This is a huge number; if not taken seriously, these numbers will
increase rapidly. About 4.89 billion individuals are social media users. People
express their feelings and emotions on platforms like Twitter, Facebook,
Reddit, Instagram, etc. These platforms contain valuable information which can
be used for research purposes. Considerable research has been conducted across
various social media platforms. However, certain limitations persist in these
endeavors. Particularly, previous studies were only focused on detecting
depression and the intensity of depression in tweets. Also, there existed
inaccuracies in dataset labeling. In this research work, five types of
depression (Bipolar, major, psychotic, atypical, and postpartum) were predicted
using tweets from the Twitter database based on lexicon labeling. Explainable
AI was used to provide reasoning by highlighting the parts of tweets that
represent type of depression. Bidirectional Encoder Representations from
Transformers (BERT) was used for feature extraction and training. Machine
learning and deep learning methodologies were used to train the model. The BERT
model presented the most promising results, achieving an overall accuracy of
0.96.|
##### 2404.12832v1 **COIN: Counterfactual inpainting for weakly supervised semantic segmentation for medical images**
Dmytro Shvetsov et.al.
Deep learning is dramatically transforming the field of medical imaging and
radiology, enabling the identification of pathologies in medical images,
including computed tomography (CT) and X-ray scans. However, the performance of
deep learning models, particularly in segmentation tasks, is often limited by
the need for extensive annotated datasets. To address this challenge, the
capabilities of weakly supervised semantic segmentation are explored through
the lens of Explainable AI and the generation of counterfactual explanations.
The scope of this research is development of a novel counterfactual inpainting
approach (COIN) that flips the predicted classification label from abnormal to
normal by using a generative model. For instance, if the classifier deems an
input medical image X as abnormal, indicating the presence of a pathology, the
generative model aims to inpaint the abnormal region, thus reversing the
classifier's original prediction label. The approach enables us to produce
precise segmentations for pathologies without depending on pre-existing
segmentation masks. Crucially, image-level labels are utilized, which are
substantially easier to acquire than creating detailed segmentation masks. The
effectiveness of the method is demonstrated by segmenting synthetic targets and
actual kidney tumors from CT images acquired from Tartu University Hospital in
Estonia. The findings indicate that COIN greatly surpasses established
attribution methods, such as RISE, ScoreCAM, and LayerCAM, as well as an
alternative counterfactual explanation method introduced by Singla et al. This
evidence suggests that COIN is a promising approach for semantic segmentation
of tumors in CT images, and presents a step forward in making deep learning
applications more accessible and effective in healthcare, where annotated data
is scarce.|
##### 2404.13101v1 **DensePANet: An improved generative adversarial network for photoacoustic tomography image reconstruction from sparse data**
Hesam Hakimnejad et.al.
Image reconstruction is an essential step of every medical imaging method,
including Photoacoustic Tomography (PAT), which is a promising modality of
imaging, that unites the benefits of both ultrasound and optical imaging
methods. Reconstruction of PAT images using conventional methods results in
rough artifacts, especially when applied directly to sparse PAT data. In recent
years, generative adversarial networks (GANs) have shown a powerful performance
in image generation as well as translation, rendering them a smart choice to be
applied to reconstruction tasks. In this study, we proposed an end-to-end
method called DensePANet to solve the problem of PAT image reconstruction from
sparse data. The proposed model employs a novel modification of UNet in its
generator, called FD-UNet++, which considerably improves the reconstruction
performance. We evaluated the method on various in-vivo and simulated datasets.
Quantitative and qualitative results show the better performance of our model
over other prevalent deep learning techniques.|
##### 2404.12634v1 **Transformer-Based Classification Outcome Prediction for Multimodal Stroke Treatment**
Danqing Ma et.al.
This study proposes a multi-modal fusion framework Multitrans based on the
Transformer architecture and self-attention mechanism. This architecture
combines the study of non-contrast computed tomography (NCCT) images and
discharge diagnosis reports of patients undergoing stroke treatment, using a
variety of methods based on Transformer architecture approach to predicting
functional outcomes of stroke treatment. The results show that the performance
of single-modal text classification is significantly better than single-modal
image classification, but the effect of multi-modal combination is better than
any single modality. Although the Transformer model only performs worse on
imaging data, when combined with clinical meta-diagnostic information, both can
learn better complementary information and make good contributions to
accurately predicting stroke treatment effects..|
##### 2404.12605v1 **GluMarker: A Novel Predictive Modeling of Glycemic Control Through Digital Biomarkers**
Ziyi Zhou et.al.
The escalating prevalence of diabetes globally underscores the need for
diabetes management. Recent research highlights the growing focus on digital
biomarkers in diabetes management, with innovations in computational frameworks
and noninvasive monitoring techniques using personalized glucose metrics.
However, they predominantly focus on insulin dosing and specific glucose
values, or with limited attention given to overall glycemic control. This
leaves a gap in expanding the scope of digital biomarkers for overall glycemic
control in diabetes management. To address such a research gap, we propose
GluMarker -- an end-to-end framework for modeling digital biomarkers using
broader factors sources to predict glycemic control. Through the assessment and
refinement of various machine learning baselines, GluMarker achieves
state-of-the-art on Anderson's dataset in predicting next-day glycemic control.
Moreover, our research identifies key digital biomarkers for the next day's
glycemic control prediction. These identified biomarkers are instrumental in
illuminating the daily factors that influence glycemic management, offering
vital insights for diabetes care.|
##### 2404.12278v1 **DF-DM: A foundational process model for multimodal data fusion in the artificial intelligence era**
David Restrepo et.al.
In the big data era, integrating diverse data modalities poses significant
challenges, particularly in complex fields like healthcare. This paper
introduces a new process model for multimodal Data Fusion for Data Mining,
integrating embeddings and the Cross-Industry Standard Process for Data Mining
with the existing Data Fusion Information Group model. Our model aims to
decrease computational costs, complexity, and bias while improving efficiency
and reliability. We also propose "disentangled dense fusion", a novel embedding
fusion method designed to optimize mutual information and facilitate dense
inter-modality feature interaction, thereby minimizing redundant information.
  We demonstrate the model's efficacy through three use cases: predicting
diabetic retinopathy using retinal images and patient metadata, domestic
violence prediction employing satellite imagery, internet, and census data, and
identifying clinical and demographic features from radiography images and
clinical notes. The model achieved a Macro F1 score of 0.92 in diabetic
retinopathy prediction, an R-squared of 0.854 and sMAPE of 24.868 in domestic
violence prediction, and a macro AUC of 0.92 and 0.99 for disease prediction
and sex classification, respectively, in radiological analysis.
  These results underscore the Data Fusion for Data Mining model's potential to
significantly impact multimodal data processing, promoting its adoption in
diverse, resource-constrained settings.|
##### 2404.12228v1 **Relationship Discovery for Drug Recommendation**
Xiang Li et.al.
Medication recommendation systems are designed to deliver personalized drug
suggestions that are closely aligned with individual patient needs. Previous
studies have primarily concentrated on developing medication embeddings,
achieving significant progress. Nonetheless, these approaches often fall short
in accurately reflecting individual patient profiles, mainly due to challenges
in distinguishing between various patient conditions and the inability to
establish precise correlations between specific conditions and appropriate
medications. In response to these issues, we introduce DisMed, a model that
focuses on patient conditions to enhance personalization. DisMed employs causal
inference to discern clear, quantifiable causal links. It then examines patient
conditions in depth, recognizing and adapting to the evolving nuances of these
conditions, and mapping them directly to corresponding medications.
Additionally, DisMed leverages data from multiple patient visits to propose
combinations of medications. Comprehensive testing on real-world datasets
demonstrates that DisMed not only improves the customization of patient
profiles but also surpasses leading models in both precision and safety.|
##### 2404.11929v1 **A Symmetric Regressor for MRI-Based Assessment of Striatal Dopamine Transporter Uptake in Parkinson's Disease**
Walid Abdullah Al et.al.
Dopamine transporter (DAT) imaging is commonly used for monitoring
Parkinson's disease (PD), where striatal DAT uptake amount is computed to
assess PD severity. However, DAT imaging has a high cost and the risk of
radiance exposure and is not available in general clinics. Recently, MRI patch
of the nigral region has been proposed as a safer and easier alternative. This
paper proposes a symmetric regressor for predicting the DAT uptake amount from
the nigral MRI patch. Acknowledging the symmetry between the right and left
nigrae, the proposed regressor incorporates a paired input-output model that
simultaneously predicts the DAT uptake amounts for both the right and left
striata. Moreover, it employs a symmetric loss that imposes a constraint on the
difference between right-to-left predictions, resembling the high correlation
in DAT uptake amounts in the two lateral sides. Additionally, we propose a
symmetric Monte-Carlo (MC) dropout method for providing a fruitful uncertainty
estimate of the DAT uptake prediction, which utilizes the above symmetry. We
evaluated the proposed approach on 734 nigral patches, which demonstrated
significantly improved performance of the symmetric regressor compared with the
standard regressors while giving better explainability and feature
representation. The symmetric MC dropout also gave precise uncertainty ranges
with a high probability of including the true DAT uptake amounts within the
range.|
##### 2404.11812v1 **Cross-model Mutual Learning for Exemplar-based Medical Image Segmentation**
Qing En et.al.
Medical image segmentation typically demands extensive dense annotations for
model training, which is both time-consuming and skill-intensive. To mitigate
this burden, exemplar-based medical image segmentation methods have been
introduced to achieve effective training with only one annotated image. In this
paper, we introduce a novel Cross-model Mutual learning framework for
Exemplar-based Medical image Segmentation (CMEMS), which leverages two models
to mutually excavate implicit information from unlabeled data at multiple
granularities. CMEMS can eliminate confirmation bias and enable collaborative
training to learn complementary information by enforcing consistency at
different granularities across models. Concretely, cross-model image
perturbation based mutual learning is devised by using weakly perturbed images
to generate high-confidence pseudo-labels, supervising predictions of strongly
perturbed images across models. This approach enables joint pursuit of
prediction consistency at the image granularity. Moreover, cross-model
multi-level feature perturbation based mutual learning is designed by letting
pseudo-labels supervise predictions from perturbed multi-level features with
different resolutions, which can broaden the perturbation space and enhance the
robustness of our framework. CMEMS is jointly trained using exemplar data,
synthetic data, and unlabeled data in an end-to-end manner. Experimental
results on two medical image datasets indicate that the proposed CMEMS
outperforms the state-of-the-art segmentation methods with extremely limited
supervision.|
##### 2404.11698v1 **A Secure and Trustworthy Network Architecture for Federated Learning Healthcare Applications**
Antonio Boiano et.al.
Federated Learning (FL) has emerged as a promising approach for
privacy-preserving machine learning, particularly in sensitive domains such as
healthcare. In this context, the TRUSTroke project aims to leverage FL to
assist clinicians in ischemic stroke prediction. This paper provides an
overview of the TRUSTroke FL network infrastructure. The proposed architecture
adopts a client-server model with a central Parameter Server (PS). We introduce
a Docker-based design for the client nodes, offering a flexible solution for
implementing FL processes in clinical settings. The impact of different
communication protocols (HTTP or MQTT) on FL network operation is analyzed,
with MQTT selected for its suitability in FL scenarios. A control plane to
support the main operations required by FL processes is also proposed. The
paper concludes with an analysis of security aspects of the FL architecture,
addressing potential threats and proposing mitigation strategies to increase
the trustworthiness level.|
##### 2404.11577v1 **Towards Reliable Empirical Machine Unlearning Evaluation: A Game-Theoretic View**
Yiwen Tu et.al.
Machine unlearning is the process of updating machine learning models to
remove the information of specific training data samples, in order to comply
with data protection regulations that allow individuals to request the removal
of their personal data. Despite the recent development of numerous unlearning
algorithms, reliable evaluation of these algorithms remains an open research
question. In this work, we focus on membership inference attack (MIA) based
evaluation, one of the most common approaches for evaluating unlearning
algorithms, and address various pitfalls of existing evaluation metrics that
lack reliability. Specifically, we propose a game-theoretic framework that
formalizes the evaluation process as a game between unlearning algorithms and
MIA adversaries, measuring the data removal efficacy of unlearning algorithms
by the capability of the MIA adversaries. Through careful design of the game,
we demonstrate that the natural evaluation metric induced from the game enjoys
provable guarantees that the existing evaluation metrics fail to satisfy.
Furthermore, we propose a practical and efficient algorithm to estimate the
evaluation metric induced from the game, and demonstrate its effectiveness
through both theoretical analysis and empirical experiments. This work presents
a novel and reliable approach to empirically evaluating unlearning algorithms,
paving the way for the development of more effective unlearning techniques.|
##### 2404.11209v1 **Prompt-Guided Generation of Structured Chest X-Ray Report Using a Pre-trained LLM**
Hongzhao Li et.al.
Medical report generation automates radiology descriptions from images,
easing the burden on physicians and minimizing errors. However, current methods
lack structured outputs and physician interactivity for clear, clinically
relevant reports. Our method introduces a prompt-guided approach to generate
structured chest X-ray reports using a pre-trained large language model (LLM).
First, we identify anatomical regions in chest X-rays to generate focused
sentences that center on key visual elements, thereby establishing a structured
report foundation with anatomy-based sentences. We also convert the detected
anatomy into textual prompts conveying anatomical comprehension to the LLM.
Additionally, the clinical context prompts guide the LLM to emphasize
interactivity and clinical requirements. By integrating anatomy-focused
sentences and anatomy/clinical prompts, the pre-trained LLM can generate
structured chest X-ray reports tailored to prompted anatomical regions and
clinical contexts. We evaluate using language generation and clinical
effectiveness metrics, demonstrating strong performance.|
##### 2404.11148v1 **Explainable Machine Learning System for Predicting Chronic Kidney Disease in High-Risk Cardiovascular Patients**
Nantika Nguycharoen et.al.
As the global population ages, the incidence of Chronic Kidney Disease (CKD)
is rising. CKD often remains asymptomatic until advanced stages, which
significantly burdens both the healthcare system and patient quality of life.
This research developed an explainable machine learning system for predicting
CKD in patients with cardiovascular risks, utilizing medical history and
laboratory data. The Random Forest model achieved the highest sensitivity of
88.2%. The study introduces a comprehensive explainability framework that
extends beyond traditional feature importance methods, incorporating global and
local interpretations, bias inspection, biomedical relevance, and safety
assessments. Key predictive features identified in global interpretation were
the use of diabetic and ACEI/ARB medications, and initial eGFR values. Local
interpretation provided model insights through counterfactual explanations,
which aligned with other system parts. After conducting a bias inspection, it
was found that the initial eGFR values and CKD predictions exhibited some bias,
but no significant gender bias was identified. The model's logic, extracted by
scoped rules, was confirmed to align with existing medical literature. The
safety assessment tested potentially dangerous cases and confirmed that the
model behaved safely. This system enhances the explainability, reliability, and
accountability of the model, promoting its potential integration into
healthcare settings and compliance with upcoming regulatory standards, and
showing promise for broader applications in healthcare machine learning.|
##### 2404.11008v1 **AKGNet: Attribute Knowledge-Guided Unsupervised Lung-Infected Area Segmentation**
Qing En et.al.
Lung-infected area segmentation is crucial for assessing the severity of lung
diseases. However, existing image-text multi-modal methods typically rely on
labour-intensive annotations for model training, posing challenges regarding
time and expertise. To address this issue, we propose a novel attribute
knowledge-guided framework for unsupervised lung-infected area segmentation
(AKGNet), which achieves segmentation solely based on image-text data without
any mask annotation. AKGNet facilitates text attribute knowledge learning,
attribute-image cross-attention fusion, and high-confidence-based pseudo-label
exploration simultaneously. It can learn statistical information and capture
spatial correlations between image and text attributes in the embedding space,
iteratively refining the mask to enhance segmentation. Specifically, we
introduce a text attribute knowledge learning module by extracting attribute
knowledge and incorporating it into feature representations, enabling the model
to learn statistical information and adapt to different attributes. Moreover,
we devise an attribute-image cross-attention module by calculating the
correlation between attributes and images in the embedding space to capture
spatial dependency information, thus selectively focusing on relevant regions
while filtering irrelevant areas. Finally, a self-training mask improvement
process is employed by generating pseudo-labels using high-confidence
predictions to iteratively enhance the mask and segmentation. Experimental
results on a benchmark medical image dataset demonstrate the superior
performance of our method compared to state-of-the-art segmentation techniques
in unsupervised scenarios.|
##### 2404.10978v1 **Leveraging 3D LiDAR Sensors to Enable Enhanced Urban Safety and Public Health: Pedestrian Monitoring and Abnormal Activity Detection**
Nawfal Guefrachi et.al.
The integration of Light Detection and Ranging (LiDAR) and Internet of Things
(IoT) technologies offers transformative opportunities for public health
informatics in urban safety and pedestrian well-being. This paper proposes a
novel framework utilizing these technologies for enhanced 3D object detection
and activity classification in urban traffic scenarios. By employing elevated
LiDAR, we obtain detailed 3D point cloud data, enabling precise pedestrian
activity monitoring. To overcome urban data scarcity, we create a specialized
dataset through simulated traffic environments in Blender, facilitating
targeted model training. Our approach employs a modified Point
Voxel-Region-based Convolutional Neural Network (PV-RCNN) for robust 3D
detection and PointNet for classifying pedestrian activities, significantly
benefiting urban traffic management and public health by offering insights into
pedestrian behavior and promoting safer urban environments. Our dual-model
approach not only enhances urban traffic management but also contributes
significantly to public health by providing insights into pedestrian behavior
and promoting safer urban environment.|
##### 2404.10901v1 **CrossGP: Cross-Day Glucose Prediction Excluding Physiological Information**
Ziyi Zhou et.al.
The increasing number of diabetic patients is a serious issue in society
today, which has significant negative impacts on people's health and the
country's financial expenditures. Because diabetes may develop into potential
serious complications, early glucose prediction for diabetic patients is
necessary for timely medical treatment. Existing glucose prediction methods
typically utilize patients' private data (e.g. age, gender, ethnicity) and
physiological parameters (e.g. blood pressure, heart rate) as reference
features for glucose prediction, which inevitably leads to privacy protection
concerns. Moreover, these models generally focus on either long-term
(monthly-based) or short-term (minute-based) predictions. Long-term prediction
methods are generally inaccurate because of the external uncertainties that can
greatly affect the glucose values, while short-term ones fail to provide timely
medical guidance. Based on the above issues, we propose CrossGP, a novel
machine-learning framework for cross-day glucose prediction solely based on the
patient's external activities without involving any physiological parameters.
Meanwhile, we implement three baseline models for comparison. Extensive
experiments on Anderson's dataset strongly demonstrate the superior performance
of CrossGP and prove its potential for future real-life applications.|
##### 2404.10717v1 **Mixed Prototype Consistency Learning for Semi-supervised Medical Image Segmentation**
Lijian Li et.al.
Recently, prototype learning has emerged in semi-supervised medical image
segmentation and achieved remarkable performance. However, the scarcity of
labeled data limits the expressiveness of prototypes in previous methods,
potentially hindering the complete representation of prototypes for class
embedding. To address this problem, we propose the Mixed Prototype Consistency
Learning (MPCL) framework, which includes a Mean Teacher and an auxiliary
network. The Mean Teacher generates prototypes for labeled and unlabeled data,
while the auxiliary network produces additional prototypes for mixed data
processed by CutMix. Through prototype fusion, mixed prototypes provide extra
semantic information to both labeled and unlabeled prototypes. High-quality
global prototypes for each class are formed by fusing two enhanced prototypes,
optimizing the distribution of hidden embeddings used in consistency learning.
Extensive experiments on the left atrium and type B aortic dissection datasets
demonstrate MPCL's superiority over previous state-of-the-art approaches,
confirming the effectiveness of our framework. The code will be released soon.|
##### 2404.10573v2 **AAVDiff: Experimental Validation of Enhanced Viability and Diversity in Recombinant Adeno-Associated Virus (AAV) Capsids through Diffusion Generation**
Lijun Liu et.al.
Recombinant adeno-associated virus (rAAV) vectors have revolutionized gene
therapy, but their broad tropism and suboptimal transduction efficiency limit
their clinical applications. To overcome these limitations, researchers have
focused on designing and screening capsid libraries to identify improved
vectors. However, the large sequence space and limited resources present
challenges in identifying viable capsid variants. In this study, we propose an
end-to-end diffusion model to generate capsid sequences with enhanced
viability. Using publicly available AAV2 data, we generated 38,000 diverse AAV2
viral protein (VP) sequences, and evaluated 8,000 for viral selection. The
results attested the superiority of our model compared to traditional methods.
Additionally, in the absence of AAV9 capsid data, apart from one wild-type
sequence, we used the same model to directly generate a number of viable
sequences with up to 9 mutations. we transferred the remaining 30,000 samples
to the AAV9 domain. Furthermore, we conducted mutagenesis on AAV9 VP
hypervariable regions VI and V, contributing to the continuous improvement of
the AAV9 VP sequence. This research represents a significant advancement in the
design and functional validation of rAAV vectors, offering innovative solutions
to enhance specificity and transduction efficiency in gene therapy
applications.|
##### 2404.10503v1 **A Sentiment Analysis of Medical Text Based on Deep Learning**
Yinan Chen et.al.
The field of natural language processing (NLP) has made significant progress
with the rapid development of deep learning technologies. One of the research
directions in text sentiment analysis is sentiment analysis of medical texts,
which holds great potential for application in clinical diagnosis. However, the
medical field currently lacks sufficient text datasets, and the effectiveness
of sentiment analysis is greatly impacted by different model design approaches,
which presents challenges. Therefore, this paper focuses on the medical domain,
using bidirectional encoder representations from transformers (BERT) as the
basic pre-trained model and experimenting with modules such as convolutional
neural network (CNN), fully connected network (FCN), and graph convolutional
networks (GCN) at the output layer. Experiments and analyses were conducted on
the METS-CoV dataset to explore the training performance after integrating
different deep learning networks. The results indicate that CNN models
outperform other networks when trained on smaller medical text datasets in
combination with pre-trained models like BERT. This study highlights the
significance of model selection in achieving effective sentiment analysis in
the medical domain and provides a reference for future research to develop more
efficient model architectures.|
##### 2404.10405v1 **Integration of Self-Supervised BYOL in Semi-Supervised Medical Image Recognition**
Hao Feng et.al.
Image recognition techniques heavily rely on abundant labeled data,
particularly in medical contexts. Addressing the challenges associated with
obtaining labeled data has led to the prominence of self-supervised learning
and semi-supervised learning, especially in scenarios with limited annotated
data. In this paper, we proposed an innovative approach by integrating
self-supervised learning into semi-supervised models to enhance medical image
recognition. Our methodology commences with pre-training on unlabeled data
utilizing the BYOL method. Subsequently, we merge pseudo-labeled and labeled
datasets to construct a neural network classifier, refining it through
iterative fine-tuning. Experimental results on three different datasets
demonstrate that our approach optimally leverages unlabeled data, outperforming
existing methods in terms of accuracy for medical image recognition.|
##### 2404.10356v1 **Generating Counterfactual Trajectories with Latent Diffusion Models for Concept Discovery**
Payal Varshney et.al.
Trustworthiness is a major prerequisite for the safe application of opaque
deep learning models in high-stakes domains like medicine. Understanding the
decision-making process not only contributes to fostering trust but might also
reveal previously unknown decision criteria of complex models that could
advance the state of medical research. The discovery of decision-relevant
concepts from black box models is a particularly challenging task. This study
proposes Concept Discovery through Latent Diffusion-based Counterfactual
Trajectories (CDCT), a novel three-step framework for concept discovery
leveraging the superior image synthesis capabilities of diffusion models. In
the first step, CDCT uses a Latent Diffusion Model (LDM) to generate a
counterfactual trajectory dataset. This dataset is used to derive a
disentangled representation of classification-relevant concepts using a
Variational Autoencoder (VAE). Finally, a search algorithm is applied to
identify relevant concepts in the disentangled latent space. The application of
CDCT to a classifier trained on the largest public skin lesion dataset revealed
not only the presence of several biases but also meaningful biomarkers.
Moreover, the counterfactuals generated within CDCT show better FID scores than
those produced by a previously established state-of-the-art method, while being
12 times more resource-efficient. Unsupervised concept discovery holds great
potential for the application of trustworthy AI and the further development of
human knowledge in various domains. CDCT represents a further step in this
direction.|
##### 2404.10320v2 **CARE to Compare: A real-world dataset for anomaly detection in wind turbine data**
Christian Gück et.al.
Anomaly detection plays a crucial role in the field of predictive maintenance
for wind turbines, yet the comparison of different algorithms poses a difficult
task because domain specific public datasets are scarce. Many comparisons of
different approaches either use benchmarks composed of data from many different
domains, inaccessible data or one of the few publicly available datasets which
lack detailed information about the faults. Moreover, many publications
highlight a couple of case studies where fault detection was successful. With
this paper we publish a high quality dataset that contains data from 36 wind
turbines across 3 different wind farms as well as the most detailed fault
information of any public wind turbine dataset as far as we know. The new
dataset contains 89 years worth of real-world operating data of wind turbines,
distributed across 44 labeled time frames for anomalies that led up to faults,
as well as 51 time series representing normal behavior. Additionally, the
quality of training data is ensured by turbine-status-based labels for each
data point. Furthermore, we propose a new scoring method, called CARE
(Coverage, Accuracy, Reliability and Earliness), which takes advantage of the
information depth that is present in the dataset to identify a good all-around
anomaly detection model. This score considers the anomaly detection
performance, the ability to recognize normal behavior properly and the
capability to raise as few false alarms as possible while simultaneously
detecting anomalies early.|
##### 2404.10299v1 **Clustering and Data Augmentation to Improve Accuracy of Sleep Assessment and Sleep Individuality Analysis**
Shintaro Tamai et.al.
Recently, growing health awareness, novel methods allow individuals to
monitor sleep at home. Utilizing sleep sounds offers advantages over
conventional methods like smartwatches, being non-intrusive, and capable of
detecting various physiological activities. This study aims to construct a
machine learning-based sleep assessment model providing evidence-based
assessments, such as poor sleep due to frequent movement during sleep onset.
Extracting sleep sound events, deriving latent representations using VAE,
clustering with GMM, and training LSTM for subjective sleep assessment achieved
a high accuracy of 94.8% in distinguishing sleep satisfaction. Moreover,
TimeSHAP revealed differences in impactful sound event types and timings for
different individuals.|
##### 2404.10031v1 **Emergent Language Symbolic Autoencoder (ELSA) with Weak Supervision to Model Hierarchical Brain Networks**
Ammar Ahmed Pallikonda Latheef et.al.
Brain networks display a hierarchical organization, a complexity that poses a
challenge for existing deep learning models, often structured as flat
classifiers, leading to difficulties in interpretability and the 'black box'
issue. To bridge this gap, we propose a novel architecture: a symbolic
autoencoder informed by weak supervision and an Emergent Language (EL)
framework. This model moves beyond traditional flat classifiers by producing
hierarchical clusters and corresponding imagery, subsequently represented
through symbolic sentences to improve the clinical interpretability of
hierarchically organized data such as intrinsic brain networks, which can be
characterized using resting-state fMRI images. Our innovation includes a
generalized hierarchical loss function designed to ensure that both sentences
and images accurately reflect the hierarchical structure of functional brain
networks. This enables us to model functional brain networks from a broader
perspective down to more granular details. Furthermore, we introduce a
quantitative method to assess the hierarchical consistency of these symbolic
representations. Our qualitative analyses show that our model successfully
generates hierarchically organized, clinically interpretable images, a finding
supported by our quantitative evaluations. We find that our best performing
loss function leads to a hierarchical consistency of over 97% when identifying
images corresponding to brain networks. This approach not only advances the
interpretability of deep learning models in neuroimaging analysis but also
represents a significant step towards modeling the intricate hierarchical
nature of brain networks.|
##### 2404.09690v1 **Harnessing GPT-4V(ision) for Insurance: A Preliminary Exploration**
Chenwei Lin et.al.
The emergence of Large Multimodal Models (LMMs) marks a significant milestone
in the development of artificial intelligence. Insurance, as a vast and complex
discipline, involves a wide variety of data forms in its operational processes,
including text, images, and videos, thereby giving rise to diverse multimodal
tasks. Despite this, there has been limited systematic exploration of
multimodal tasks specific to insurance, nor a thorough investigation into how
LMMs can address these challenges. In this paper, we explore GPT-4V's
capabilities in the insurance domain. We categorize multimodal tasks by
focusing primarily on visual aspects based on types of insurance (e.g., auto,
household/commercial property, health, and agricultural insurance) and
insurance stages (e.g., risk assessment, risk monitoring, and claims
processing). Our experiment reveals that GPT-4V exhibits remarkable abilities
in insurance-related tasks, demonstrating not only a robust understanding of
multimodal content in the insurance domain but also a comprehensive knowledge
of insurance scenarios. However, there are notable shortcomings: GPT-4V
struggles with detailed risk rating and loss assessment, suffers from
hallucination in image understanding, and shows variable support for different
languages. Through this work, we aim to bridge the insurance domain with
cutting-edge LMM technology, facilitate interdisciplinary exchange and
development, and provide a foundation for the continued advancement and
evolution of future research endeavors.|
##### 2404.09625v1 **Privacy-Preserving Intrusion Detection using Convolutional Neural Networks**
Martin Kodys et.al.
Privacy-preserving analytics is designed to protect valuable assets. A common
service provision involves the input data from the client and the model on the
analyst's side. The importance of the privacy preservation is fuelled by legal
obligations and intellectual property concerns. We explore the use case of a
model owner providing an analytic service on customer's private data. No
information about the data shall be revealed to the analyst and no information
about the model shall be leaked to the customer. Current methods involve costs:
accuracy deterioration and computational complexity. The complexity, in turn,
results in a longer processing time, increased requirement on computing
resources, and involves data communication between the client and the server.
In order to deploy such service architecture, we need to evaluate the optimal
setting that fits the constraints. And that is what this paper addresses. In
this work, we enhance an attack detection system based on Convolutional Neural
Networks with privacy-preserving technology based on PriMIA framework that is
initially designed for medical data.|
##### 2404.09613v1 **Efficient and accurate neural field reconstruction using resistive memory**
Yifei Yu et.al.
Human beings construct perception of space by integrating sparse observations
into massively interconnected synapses and neurons, offering a superior
parallelism and efficiency. Replicating this capability in AI finds wide
applications in medical imaging, AR/VR, and embodied AI, where input data is
often sparse and computing resources are limited. However, traditional signal
reconstruction methods on digital computers face both software and hardware
challenges. On the software front, difficulties arise from storage
inefficiencies in conventional explicit signal representation. Hardware
obstacles include the von Neumann bottleneck, which limits data transfer
between the CPU and memory, and the limitations of CMOS circuits in supporting
parallel processing. We propose a systematic approach with software-hardware
co-optimizations for signal reconstruction from sparse inputs. Software-wise,
we employ neural field to implicitly represent signals via neural networks,
which is further compressed using low-rank decomposition and structured
pruning. Hardware-wise, we design a resistive memory-based computing-in-memory
(CIM) platform, featuring a Gaussian Encoder (GE) and an MLP Processing Engine
(PE). The GE harnesses the intrinsic stochasticity of resistive memory for
efficient input encoding, while the PE achieves precise weight mapping through
a Hardware-Aware Quantization (HAQ) circuit. We demonstrate the system's
efficacy on a 40nm 256Kb resistive memory-based in-memory computing macro,
achieving huge energy efficiency and parallelism improvements without
compromising reconstruction quality in tasks like 3D CT sparse reconstruction,
novel view synthesis, and novel view synthesis for dynamic scenes. This work
advances the AI-driven signal restoration technology and paves the way for
future efficient and robust medical AI and 3D vision applications.|
##### 2404.09533v1 **WiTUnet: A U-Shaped Architecture Integrating CNN and Transformer for Improved Feature Alignment and Local Information Fusion**
Bin Wang et.al.
Low-dose computed tomography (LDCT) has become the technology of choice for
diagnostic medical imaging, given its lower radiation dose compared to standard
CT, despite increasing image noise and potentially affecting diagnostic
accuracy. To address this, advanced deep learning-based LDCT denoising
algorithms have been developed, primarily using Convolutional Neural Networks
(CNNs) or Transformer Networks with the Unet architecture. This architecture
enhances image detail by integrating feature maps from the encoder and decoder
via skip connections. However, current methods often overlook enhancements to
the Unet architecture itself, focusing instead on optimizing encoder and
decoder structures. This approach can be problematic due to the significant
differences in feature map characteristics between the encoder and decoder,
where simple fusion strategies may not effectively reconstruct images.In this
paper, we introduce WiTUnet, a novel LDCT image denoising method that utilizes
nested, dense skip pathways instead of traditional skip connections to improve
feature integration. WiTUnet also incorporates a windowed Transformer structure
to process images in smaller, non-overlapping segments, reducing computational
load. Additionally, the integration of a Local Image Perception Enhancement
(LiPe) module in both the encoder and decoder replaces the standard multi-layer
perceptron (MLP) in Transformers, enhancing local feature capture and
representation. Through extensive experimental comparisons, WiTUnet has
demonstrated superior performance over existing methods in key metrics such as
Peak Signal-to-Noise Ratio (PSNR), Structural Similarity (SSIM), and Root Mean
Square Error (RMSE), significantly improving noise removal and image quality.|
##### 2404.09326v2 **Weight Copy and Low-Rank Adaptation for Few-Shot Distillation of Vision Transformers**
Diana-Nicoleta Grigore et.al.
Few-shot knowledge distillation recently emerged as a viable approach to
harness the knowledge of large-scale pre-trained models, using limited data and
computational resources. In this paper, we propose a novel few-shot feature
distillation approach for vision transformers. Our approach is based on two key
steps. Leveraging the fact that vision transformers have a consistent
depth-wise structure, we first copy the weights from intermittent layers of
existing pre-trained vision transformers (teachers) into shallower
architectures (students), where the intermittence factor controls the
complexity of the student transformer with respect to its teacher. Next, we
employ an enhanced version of Low-Rank Adaptation (LoRA) to distill knowledge
into the student in a few-shot scenario, aiming to recover the information
processing carried out by the skipped teacher layers. We present comprehensive
experiments with supervised and self-supervised transformers as teachers, on
five data sets from various domains, including natural, medical and satellite
images. The empirical results confirm the superiority of our approach over
competitive baselines. Moreover, the ablation results demonstrate the
usefulness of each component of the proposed pipeline.|
##### 2404.09317v1 **Characterizing Soft-Error Resiliency in Arm's Ethos-U55 Embedded Machine Learning Accelerator**
Abhishek Tyagi et.al.
As Neural Processing Units (NPU) or accelerators are increasingly deployed in
a variety of applications including safety critical applications such as
autonomous vehicle, and medical imaging, it is critical to understand the
fault-tolerance nature of the NPUs. We present a reliability study of Arm's
Ethos-U55, an important industrial-scale NPU being utilised in embedded and IoT
applications. We perform large scale RTL-level fault injections to characterize
Ethos-U55 against the Automotive Safety Integrity Level D (ASIL-D) resiliency
standard commonly used for safety-critical applications such as autonomous
vehicles. We show that, under soft errors, all four configurations of the NPU
fall short of the required level of resiliency for a variety of neural networks
running on the NPU. We show that it is possible to meet the ASIL-D level
resiliency without resorting to conventional strategies like Dual Core Lock
Step (DCLS) that has an area overhead of 100%. We achieve so through selective
protection, where hardware structures are selectively protected (e.g.,
duplicated, hardened) based on their sensitivity to soft errors and their
silicon areas. To identify the optimal configuration that minimizes the area
overhead while meeting the ASIL-D standard, the main challenge is the large
search space associated with the time-consuming RTL simulation. To address this
challenge, we present a statistical analysis tool that is validated against Arm
silicon and that allows us to quickly navigate hundreds of billions of fault
sites without exhaustive RTL fault injections. We show that by carefully
duplicating a small fraction of the functional blocks and hardening the Flops
in other blocks meets the ASIL-D safety standard while introducing an area
overhead of only 38%.|
##### 2404.09136v1 **TLDR at SemEval-2024 Task 2: T5-generated clinical-Language summaries for DeBERTa Report Analysis**
Spandan Das et.al.
This paper introduces novel methodologies for the Natural Language Inference
for Clinical Trials (NLI4CT) task. We present TLDR (T5-generated
clinical-Language summaries for DeBERTa Report Analysis) which incorporates
T5-model generated premise summaries for improved entailment and contradiction
analysis in clinical NLI tasks. This approach overcomes the challenges posed by
small context windows and lengthy premises, leading to a substantial
improvement in Macro F1 scores: a 0.184 increase over truncated premises. Our
comprehensive experimental evaluation, including detailed error analysis and
ablations, confirms the superiority of TLDR in achieving consistency and
faithfulness in predictions against semantically altered inputs.|
##### 2404.15347v1 **Advanced Neural Network Architecture for Enhanced Multi-Lead ECG Arrhythmia Detection through Optimized Feature Extraction**
Bhavith Chandra Challagundla et.al.
Cardiovascular diseases are a pervasive global health concern, contributing
significantly to morbidity and mortality rates worldwide. Among these
conditions, arrhythmia, characterized by irregular heart rhythms, presents
formidable diagnostic challenges. This study introduces an innovative approach
utilizing deep learning techniques, specifically Convolutional Neural Networks
(CNNs), to address the complexities of arrhythmia classification. Leveraging
multi-lead Electrocardiogram (ECG) data, our CNN model, comprising six layers
with a residual block, demonstrates promising outcomes in identifying five
distinct heartbeat types: Left Bundle Branch Block (LBBB), Right Bundle Branch
Block (RBBB), Atrial Premature Contraction (APC), Premature Ventricular
Contraction (PVC), and Normal Beat. Through rigorous experimentation, we
highlight the transformative potential of our methodology in enhancing
diagnostic accuracy for cardiovascular arrhythmias. Arrhythmia diagnosis
remains a critical challenge in cardiovascular care, often relying on manual
interpretation of ECG signals, which can be time-consuming and prone to
subjectivity. To address these limitations, we propose a novel approach that
leverages deep learning algorithms to automate arrhythmia classification. By
employing advanced CNN architectures and multi-lead ECG data, our methodology
offers a robust solution for precise and efficient arrhythmia detection.
Through comprehensive evaluation, we demonstrate the effectiveness of our
approach in facilitating more accurate clinical decision-making, thereby
improving patient outcomes in managing cardiovascular arrhythmias.|
##### 2404.09045v1 **Adapting Mental Health Prediction Tasks for Cross-lingual Learning via Meta-Training and In-context Learning with Large Language Model**
Zita Lifelo et.al.
Timely identification is essential for the efficient handling of mental
health illnesses such as depression. However, the current research fails to
adequately address the prediction of mental health conditions from social media
data in low-resource African languages like Swahili. This study introduces two
distinct approaches utilising model-agnostic meta-learning and leveraging large
language models (LLMs) to address this gap. Experiments are conducted on three
datasets translated to low-resource language and applied to four mental health
tasks, which include stress, depression, depression severity and suicidal
ideation prediction. we first apply a meta-learning model with
self-supervision, which results in improved model initialisation for rapid
adaptation and cross-lingual transfer. The results show that our meta-trained
model performs significantly better than standard fine-tuning methods,
outperforming the baseline fine-tuning in macro F1 score with 18\% and 0.8\%
over XLM-R and mBERT. In parallel, we use LLMs' in-context learning
capabilities to assess their performance accuracy across the Swahili mental
health prediction tasks by analysing different cross-lingual prompting
approaches. Our analysis showed that Swahili prompts performed better than
cross-lingual prompts but less than English prompts. Our findings show that
in-context learning can be achieved through cross-lingual transfer through
carefully crafted prompt templates with examples and instructions.|
##### 2404.08990v1 **A Fourier-enhanced multi-modal 3D small object optical mark recognition and positioning method for percutaneous abdominal puncture surgical navigation**
Zezhao Guo et.al.
Navigation for thoracoabdominal puncture surgery is used to locate the needle
entry point on the patient's body surface. The traditional reflective ball
navigation method is difficult to position the needle entry point on the soft,
irregular, smooth chest and abdomen. Due to the lack of clear characteristic
points on the body surface using structured light technology, it is difficult
to identify and locate arbitrary needle insertion points. Based on the high
stability and high accuracy requirements of surgical navigation, this paper
proposed a novel method, a muti-modal 3D small object medical marker detection
method, which identifies the center of a small single ring as the needle
insertion point. Moreover, this novel method leverages Fourier transform
enhancement technology to augment the dataset, enrich image details, and
enhance the network's capability. The method extracts the Region of Interest
(ROI) of the feature image from both enhanced and original images, followed by
generating a mask map. Subsequently, the point cloud of the ROI from the depth
map is obtained through the registration of ROI point cloud contour fitting. In
addition, this method employs Tukey loss for optimal precision. The
experimental results show this novel method proposed in this paper not only
achieves high-precision and high-stability positioning, but also enables the
positioning of any needle insertion point.|
##### 2404.13066v2 **Leveraging Large Language Model as Simulated Patients for Clinical Education**
Yanzeng Li et.al.
Simulated Patients (SPs) play a crucial role in clinical medical education by
providing realistic scenarios for student practice. However, the high cost of
training and hiring qualified SPs, along with the heavy workload and potential
risks they face in consistently portraying actual patients, limit students'
access to this type of clinical training. Consequently, the integration of
computer program-based simulated patients has emerged as a valuable educational
tool in recent years. With the rapid development of Large Language Models
(LLMs), their exceptional capabilities in conversational artificial
intelligence and role-playing have been demonstrated, making them a feasible
option for implementing Virtual Simulated Patient (VSP). In this paper, we
present an integrated model-agnostic framework called CureFun that harnesses
the potential of LLMs in clinical medical education. This framework facilitates
natural conversations between students and simulated patients, evaluates their
dialogue, and provides suggestions to enhance students' clinical inquiry
skills. Through comprehensive evaluations, our approach demonstrates more
authentic and professional SP-scenario dialogue flows compared to other
LLM-based chatbots, thus proving its proficiency in simulating patients.
Additionally, leveraging CureFun's evaluation ability, we assess several
medical LLMs and discuss the possibilities and limitations of using LLMs as
virtual doctors from the perspective of their diagnostic abilities.|
##### 2404.08627v1 **Is ChatGPT Transforming Academics' Writing Style?**
Mingmeng Geng et.al.
Based on one million arXiv papers submitted from May 2018 to January 2024, we
assess the textual density of ChatGPT's writing style in their abstracts by
means of a statistical analysis of word frequency changes. Our model is
calibrated and validated on a mixture of real abstracts and ChatGPT-modified
abstracts (simulated data) after a careful noise analysis. We find that ChatGPT
is having an increasing impact on arXiv abstracts, especially in the field of
computer science, where the fraction of ChatGPT-revised abstracts is estimated
to be approximately 35%, if we take the output of one of the simplest prompts,
"revise the following sentences", as a baseline. We conclude with an analysis
of both positive and negative aspects of the penetration of ChatGPT into
academics' writing style.|
##### 2404.08611v1 **Automatic Quantification of Serial PET/CT Images for Pediatric Hodgkin Lymphoma Patients Using a Longitudinally-Aware Segmentation Network**
Xin Tie et.al.
$\textbf{Purpose}$: Automatic quantification of longitudinal changes in PET
scans for lymphoma patients has proven challenging, as residual disease in
interim-therapy scans is often subtle and difficult to detect. Our goal was to
develop a longitudinally-aware segmentation network (LAS-Net) that can quantify
serial PET/CT images for pediatric Hodgkin lymphoma patients.
$\textbf{Materials and Methods}$: This retrospective study included baseline
(PET1) and interim (PET2) PET/CT images from 297 patients enrolled in two
Children's Oncology Group clinical trials (AHOD1331 and AHOD0831). LAS-Net
incorporates longitudinal cross-attention, allowing relevant features from PET1
to inform the analysis of PET2. Model performance was evaluated using Dice
coefficients for PET1 and detection F1 scores for PET2. Additionally, we
extracted and compared quantitative PET metrics, including metabolic tumor
volume (MTV) and total lesion glycolysis (TLG) in PET1, as well as qPET and
$\Delta$SUVmax in PET2, against physician measurements. We quantified their
agreement using Spearman's $\rho$ correlations and employed bootstrap
resampling for statistical analysis. $\textbf{Results}$: LAS-Net detected
residual lymphoma in PET2 with an F1 score of 0.606 (precision/recall:
0.615/0.600), outperforming all comparator methods (P<0.01). For baseline
segmentation, LAS-Net achieved a mean Dice score of 0.772. In PET
quantification, LAS-Net's measurements of qPET, $\Delta$SUVmax, MTV and TLG
were strongly correlated with physician measurements, with Spearman's $\rho$ of
0.78, 0.80, 0.93 and 0.96, respectively. The performance remained high, with a
slight decrease, in an external testing cohort. $\textbf{Conclusion}$: LAS-Net
achieved high performance in quantifying PET metrics across serial scans,
highlighting the value of longitudinal awareness in evaluating multi-time-point
imaging datasets.|
##### 2404.08555v2 **RLHF Deciphered: A Critical Analysis of Reinforcement Learning from Human Feedback for LLMs**
Shreyas Chaudhari et.al.
State-of-the-art large language models (LLMs) have become indispensable tools
for various tasks. However, training LLMs to serve as effective assistants for
humans requires careful consideration. A promising approach is reinforcement
learning from human feedback (RLHF), which leverages human feedback to update
the model in accordance with human preferences and mitigate issues like
toxicity and hallucinations. Yet, an understanding of RLHF for LLMs is largely
entangled with initial design choices that popularized the method and current
research focuses on augmenting those choices rather than fundamentally
improving the framework. In this paper, we analyze RLHF through the lens of
reinforcement learning principles to develop an understanding of its
fundamentals, dedicating substantial focus to the core component of RLHF -- the
reward model. Our study investigates modeling choices, caveats of function
approximation, and their implications on RLHF training algorithms, highlighting
the underlying assumptions made about the expressivity of reward. Our analysis
improves the understanding of the role of reward models and methods for their
training, concurrently revealing limitations of the current methodology. We
characterize these limitations, including incorrect generalization, model
misspecification, and the sparsity of feedback, along with their impact on the
performance of a language model. The discussion and analysis are substantiated
by a categorical review of current literature, serving as a reference for
researchers and practitioners to understand the challenges of RLHF and build
upon existing efforts.|
##### 2404.08434v1 **An improved tabular data generator with VAE-GMM integration**
Patricia A. Apellániz et.al.
The rising use of machine learning in various fields requires robust methods
to create synthetic tabular data. Data should preserve key characteristics
while addressing data scarcity challenges. Current approaches based on
Generative Adversarial Networks, such as the state-of-the-art CTGAN model,
struggle with the complex structures inherent in tabular data. These data often
contain both continuous and discrete features with non-Gaussian distributions.
Therefore, we propose a novel Variational Autoencoder (VAE)-based model that
addresses these limitations. Inspired by the TVAE model, our approach
incorporates a Bayesian Gaussian Mixture model (BGM) within the VAE
architecture. This avoids the limitations imposed by assuming a strictly
Gaussian latent space, allowing for a more accurate representation of the
underlying data distribution during data generation. Furthermore, our model
offers enhanced flexibility by allowing the use of various differentiable
distributions for individual features, making it possible to handle both
continuous and discrete data types. We thoroughly validate our model on three
real-world datasets with mixed data types, including two medically relevant
ones, based on their resemblance and utility. This evaluation demonstrates
significant outperformance against CTGAN and TVAE, establishing its potential
as a valuable tool for generating synthetic tabular data in various domains,
particularly in healthcare.|
##### 2404.08359v1 **Improving Health Question Answering with Reliable and Time-Aware Evidence Retrieval**
Juraj Vladika et.al.
In today's digital world, seeking answers to health questions on the Internet
is a common practice. However, existing question answering (QA) systems often
rely on using pre-selected and annotated evidence documents, thus making them
inadequate for addressing novel questions. Our study focuses on the open-domain
QA setting, where the key challenge is to first uncover relevant evidence in
large knowledge bases. By utilizing the common retrieve-then-read QA pipeline
and PubMed as a trustworthy collection of medical research documents, we answer
health questions from three diverse datasets. We modify different retrieval
settings to observe their influence on the QA pipeline's performance, including
the number of retrieved documents, sentence selection process, the publication
year of articles, and their number of citations. Our results reveal that
cutting down on the amount of retrieved documents and favoring more recent and
highly cited documents can improve the final macro F1 score up to 10%. We
discuss the results, highlight interesting examples, and outline challenges for
future research, like managing evidence disagreement and crafting user-friendly
explanations.|
##### 2404.07754v1 **Generating Synthetic Satellite Imagery With Deep-Learning Text-to-Image Models -- Technical Challenges and Implications for Monitoring and Verification**
Tuong Vy Nguyen et.al.
Novel deep-learning (DL) architectures have reached a level where they can
generate digital media, including photorealistic images, that are difficult to
distinguish from real data. These technologies have already been used to
generate training data for Machine Learning (ML) models, and large
text-to-image models like DALL-E 2, Imagen, and Stable Diffusion are achieving
remarkable results in realistic high-resolution image generation. Given these
developments, issues of data authentication in monitoring and verification
deserve a careful and systematic analysis: How realistic are synthetic images?
How easily can they be generated? How useful are they for ML researchers, and
what is their potential for Open Science? In this work, we use novel DL models
to explore how synthetic satellite images can be created using conditioning
mechanisms. We investigate the challenges of synthetic satellite image
generation and evaluate the results based on authenticity and state-of-the-art
metrics. Furthermore, we investigate how synthetic data can alleviate the lack
of data in the context of ML methods for remote-sensing. Finally we discuss
implications of synthetic satellite imagery in the context of monitoring and
verification.|
##### 2404.07613v1 **Medical mT5: An Open-Source Multilingual Text-to-Text LLM for The Medical Domain**
Iker García-Ferrero et.al.
Research on language technology for the development of medical applications
is currently a hot topic in Natural Language Understanding and Generation.
Thus, a number of large language models (LLMs) have recently been adapted to
the medical domain, so that they can be used as a tool for mediating in
human-AI interaction. While these LLMs display competitive performance on
automated medical texts benchmarks, they have been pre-trained and evaluated
with a focus on a single language (English mostly). This is particularly true
of text-to-text models, which typically require large amounts of
domain-specific pre-training data, often not easily accessible for many
languages. In this paper, we address these shortcomings by compiling, to the
best of our knowledge, the largest multilingual corpus for the medical domain
in four languages, namely English, French, Italian and Spanish. This new corpus
has been used to train Medical mT5, the first open-source text-to-text
multilingual model for the medical domain. Additionally, we present two new
evaluation benchmarks for all four languages with the aim of facilitating
multilingual research in this domain. A comprehensive evaluation shows that
Medical mT5 outperforms both encoders and similarly sized text-to-text models
for the Spanish, French, and Italian benchmarks, while being competitive with
current state-of-the-art LLMs in English.|
##### 2404.07605v1 **Contrastive-Based Deep Embeddings for Label Noise-Resilient Histopathology Image Classification**
Lucas Dedieu et.al.
Recent advancements in deep learning have proven highly effective in medical
image classification, notably within histopathology. However, noisy labels
represent a critical challenge in histopathology image classification, where
accurate annotations are vital for training robust deep learning models.
Indeed, deep neural networks can easily overfit label noise, leading to severe
degradations in model performance. While numerous public pathology foundation
models have emerged recently, none have evaluated their resilience to label
noise. Through thorough empirical analyses across multiple datasets, we exhibit
the label noise resilience property of embeddings extracted from foundation
models trained in a self-supervised contrastive manner. We demonstrate that
training with such embeddings substantially enhances label noise robustness
when compared to non-contrastive-based ones as well as commonly used
noise-resilient methods. Our results unequivocally underline the superiority of
contrastive learning in effectively mitigating the label noise challenge. Code
is publicly available at
https://github.com/LucasDedieu/NoiseResilientHistopathology.|
##### 2404.07560v1 **Socially Pertinent Robots in Gerontological Healthcare**
Xavier Alameda-Pineda et.al.
Despite the many recent achievements in developing and deploying social
robotics, there are still many underexplored environments and applications for
which systematic evaluation of such systems by end-users is necessary. While
several robotic platforms have been used in gerontological healthcare, the
question of whether or not a social interactive robot with multi-modal
conversational capabilities will be useful and accepted in real-life facilities
is yet to be answered. This paper is an attempt to partially answer this
question, via two waves of experiments with patients and companions in a
day-care gerontological facility in Paris with a full-sized humanoid robot
endowed with social and conversational interaction capabilities. The software
architecture, developed during the H2020 SPRING project, together with the
experimental protocol, allowed us to evaluate the acceptability (AES) and
usability (SUS) with more than 60 end-users. Overall, the users are receptive
to this technology, especially when the robot perception and action skills are
robust to environmental clutter and flexible to handle a plethora of different
interactions.|
##### 2404.08705v1 **Introducing L2M3, A Multilingual Medical Large Language Model to Advance Health Equity in Low-Resource Regions**
Agasthya Gangavarapu et.al.
Addressing the imminent shortfall of 10 million health workers by 2030,
predominantly in Low- and Middle-Income Countries (LMICs), this paper
introduces an innovative approach that harnesses the power of Large Language
Models (LLMs) integrated with machine translation models. This solution is
engineered to meet the unique needs of Community Health Workers (CHWs),
overcoming language barriers, cultural sensitivities, and the limited
availability of medical dialog datasets. I have crafted a model that not only
boasts superior translation capabilities but also undergoes rigorous
fine-tuning on open-source datasets to ensure medical accuracy and is equipped
with comprehensive safety features to counteract the risks of misinformation.
  Featuring a modular design, this approach is specifically structured for
swift adaptation across various linguistic and cultural contexts, utilizing
open-source components to significantly reduce healthcare operational costs.
This strategic innovation markedly improves the accessibility and quality of
healthcare services by providing CHWs with contextually appropriate medical
knowledge and diagnostic tools. This paper highlights the transformative impact
of this context-aware LLM, underscoring its crucial role in addressing the
global healthcare workforce deficit and propelling forward healthcare outcomes
in LMICs.|
##### 2404.07124v1 **Measuring proximity to standard planes during fetal brain ultrasound scanning**
Chiara Di Vece et.al.
This paper introduces a novel pipeline designed to bring ultrasound (US)
plane pose estimation closer to clinical use for more effective navigation to
the standard planes (SPs) in the fetal brain. We propose a semi-supervised
segmentation model utilizing both labeled SPs and unlabeled 3D US volume
slices. Our model enables reliable segmentation across a diverse set of fetal
brain images. Furthermore, the model incorporates a classification mechanism to
identify the fetal brain precisely. Our model not only filters out frames
lacking the brain but also generates masks for those containing it, enhancing
the relevance of plane pose regression in clinical settings. We focus on fetal
brain navigation from 2D ultrasound (US) video analysis and combine this model
with a US plane pose regression network to provide sensorless proximity
detection to SPs and non-SPs planes; we emphasize the importance of proximity
detection to SPs for guiding sonographers, offering a substantial advantage
over traditional methods by allowing earlier and more precise adjustments
during scanning. We demonstrate the practical applicability of our approach
through validation on real fetal scan videos obtained from sonographers of
varying expertise levels. Our findings demonstrate the potential of our
approach to complement existing fetal US technologies and advance prenatal
diagnostic practices.|
##### 2404.06962v1 **Advancing Real-time Pandemic Forecasting Using Large Language Models: A COVID-19 Case Study**
Hongru Du et.al.
Forecasting the short-term spread of an ongoing disease outbreak is a
formidable challenge due to the complexity of contributing factors, some of
which can be characterized through interlinked, multi-modality variables such
as epidemiological time series data, viral biology, population demographics,
and the intersection of public policy and human behavior. Existing forecasting
model frameworks struggle with the multifaceted nature of relevant data and
robust results translation, which hinders their performances and the provision
of actionable insights for public health decision-makers. Our work introduces
PandemicLLM, a novel framework with multi-modal Large Language Models (LLMs)
that reformulates real-time forecasting of disease spread as a text reasoning
problem, with the ability to incorporate real-time, complex, non-numerical
information that previously unattainable in traditional forecasting models.
This approach, through a unique AI-human cooperative prompt design and time
series representation learning, encodes multi-modal data for LLMs. The model is
applied to the COVID-19 pandemic, and trained to utilize textual public health
policies, genomic surveillance, spatial, and epidemiological time series data,
and is subsequently tested across all 50 states of the U.S. Empirically,
PandemicLLM is shown to be a high-performing pandemic forecasting framework
that effectively captures the impact of emerging variants and can provide
timely and accurate predictions. The proposed PandemicLLM opens avenues for
incorporating various pandemic-related data in heterogeneous formats and
exhibits performance benefits over existing models. This study illuminates the
potential of adapting LLMs and representation learning to enhance pandemic
forecasting, illustrating how AI innovations can strengthen pandemic responses
and crisis management in the future.|
##### 2404.06869v1 **SleepPPG-Net2: Deep learning generalization for sleep staging from photoplethysmography**
Shirel Attia et.al.
Background: Sleep staging is a fundamental component in the diagnosis of
sleep disorders and the management of sleep health. Traditionally, this
analysis is conducted in clinical settings and involves a time-consuming
scoring procedure. Recent data-driven algorithms for sleep staging, using the
photoplethysmogram (PPG) time series, have shown high performance on local test
sets but lower performance on external datasets due to data drift. Methods:
This study aimed to develop a generalizable deep learning model for the task of
four class (wake, light, deep, and rapid eye movement (REM)) sleep staging from
raw PPG physiological time-series. Six sleep datasets, totaling 2,574 patients
recordings, were used. In order to create a more generalizable representation,
we developed and evaluated a deep learning model called SleepPPG-Net2, which
employs a multi-source domain training approach.SleepPPG-Net2 was benchmarked
against two state-of-the-art models. Results: SleepPPG-Net2 showed consistently
higher performance over benchmark approaches, with generalization performance
(Cohen's kappa) improving by up to 19%. Performance disparities were observed
in relation to age, sex, and sleep apnea severity. Conclusion: SleepPPG-Net2
sets a new standard for staging sleep from raw PPG time-series.|
##### 2404.06859v2 **Multi-Label Continual Learning for the Medical Domain: A Novel Benchmark**
Marina Ceccon et.al.
Multi-label image classification in dynamic environments is a problem that
poses significant challenges. Previous studies have primarily focused on
scenarios such as Domain Incremental Learning and Class Incremental Learning,
which do not fully capture the complexity of real-world applications. In this
paper, we study the problem of classification of medical imaging in the
scenario termed New Instances and New Classes, which combines the challenges of
both new class arrivals and domain shifts in a single framework. Unlike
traditional scenarios, it reflects the realistic nature of CL in domains such
as medical imaging, where updates may introduce both new classes and changes in
domain characteristics. To address the unique challenges posed by this complex
scenario, we introduce a novel approach called Pseudo-Label Replay. This method
aims to mitigate forgetting while adapting to new classes and domain shifts by
combining the advantages of the Replay and Pseudo-Label methods and solving
their limitations in the proposed scenario. We evaluate our proposed approach
on a challenging benchmark consisting of two datasets, seven tasks, and
nineteen classes, modeling a realistic Continual Learning scenario. Our
experimental findings demonstrate the effectiveness of Pseudo-Label Replay in
addressing the challenges posed by the complex scenario proposed. Our method
surpasses existing approaches, exhibiting superior performance while showing
minimal forgetting.|
##### 2404.06731v1 **Accuracy of a Large Language Model in Distinguishing Anti- And Pro-vaccination Messages on Social Media: The Case of Human Papillomavirus Vaccination**
Soojong Kim et.al.
Objective. Vaccination has engendered a spectrum of public opinions, with
social media acting as a crucial platform for health-related discussions. The
emergence of artificial intelligence technologies, such as large language
models (LLMs), offers a novel opportunity to efficiently investigate public
discourses. This research assesses the accuracy of ChatGPT, a widely used and
freely available service built upon an LLM, for sentiment analysis to discern
different stances toward Human Papillomavirus (HPV) vaccination. Methods.
Messages related to HPV vaccination were collected from social media supporting
different message formats: Facebook (long format) and Twitter (short format). A
selection of 1,000 human-evaluated messages was input into the LLM, which
generated multiple response instances containing its classification results.
Accuracy was measured for each message as the level of concurrence between
human and machine decisions, ranging between 0 and 1. Results. Average accuracy
was notably high when 20 response instances were used to determine the machine
decision of each message: .882 (SE = .021) and .750 (SE = .029) for anti- and
pro-vaccination long-form; .773 (SE = .027) and .723 (SE = .029) for anti- and
pro-vaccination short-form, respectively. Using only three or even one instance
did not lead to a severe decrease in accuracy. However, for long-form messages,
the language model exhibited significantly lower accuracy in categorizing
pro-vaccination messages than anti-vaccination ones. Conclusions. ChatGPT shows
potential in analyzing public opinions on HPV vaccination using social media
content. However, understanding the characteristics and limitations of a
language model within specific public health contexts remains imperative.|
##### 2404.06641v1 **Federated learning model for predicting major postoperative complications**
Yonggi Park et.al.
Background: The accurate prediction of postoperative complication risk using
Electronic Health Records (EHR) and artificial intelligence shows great
potential. Training a robust artificial intelligence model typically requires
large-scale and diverse datasets. In reality, collecting medical data often
encounters challenges surrounding privacy protection. Methods: This
retrospective cohort study includes adult patients who were admitted to UFH
Gainesville (GNV) (n = 79,850) and Jacksonville (JAX) (n = 28,636) for any type
of inpatient surgical procedure. Using perioperative and intraoperative
features, we developed federated learning models to predict nine major
postoperative complications (i.e., prolonged intensive care unit stay and
mechanical ventilation). We compared federated learning models with local
learning models trained on a single site and central learning models trained on
pooled dataset from two centers. Results: Our federated learning models
achieved the area under the receiver operating characteristics curve (AUROC)
values ranged from 0.81 for wound complications to 0.92 for prolonged ICU stay
at UFH GNV center. At UFH JAX center, these values ranged from 0.73-0.74 for
wound complications to 0.92-0.93 for hospital mortality. Federated learning
models achieved comparable AUROC performance to central learning models, except
for prolonged ICU stay, where the performance of federated learning models was
slightly higher than central learning models at UFH GNV center, but slightly
lower at UFH JAX center. In addition, our federated learning model obtained
comparable performance to the best local learning model at each center,
demonstrating strong generalizability. Conclusion: Federated learning is shown
to be a useful tool to train robust and generalizable models from large scale
data across multiple institutions where data protection barriers are high.|
##### 2404.06362v1 **Test-Time Adaptation with SaLIP: A Cascade of SAM and CLIP for Zero shot Medical Image Segmentation**
Sidra Aleem et.al.
The Segment Anything Model (SAM) and CLIP are remarkable vision foundation
models (VFMs). SAM, a prompt driven segmentation model, excels in segmentation
tasks across diverse domains, while CLIP is renowned for its zero shot
recognition capabilities. However, their unified potential has not yet been
explored in medical image segmentation. To adapt SAM to medical imaging,
existing methods primarily rely on tuning strategies that require extensive
data or prior prompts tailored to the specific task, making it particularly
challenging when only a limited number of data samples are available. This work
presents an in depth exploration of integrating SAM and CLIP into a unified
framework for medical image segmentation. Specifically, we propose a simple
unified framework, SaLIP, for organ segmentation. Initially, SAM is used for
part based segmentation within the image, followed by CLIP to retrieve the mask
corresponding to the region of interest (ROI) from the pool of SAM generated
masks. Finally, SAM is prompted by the retrieved ROI to segment a specific
organ. Thus, SaLIP is training and fine tuning free and does not rely on domain
expertise or labeled data for prompt engineering. Our method shows substantial
enhancements in zero shot segmentation, showcasing notable improvements in DICE
scores across diverse segmentation tasks like brain (63.46%), lung (50.11%),
and fetal head (30.82%), when compared to un prompted SAM. Code and text
prompts will be available online.|
##### 2404.07239v1 **Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis**
Milad Yousefi et.al.
Thyroid cancer is an increasing global health concern that requires advanced
diagnostic methods. The application of AI and radiomics to thyroid cancer
diagnosis is examined in this review. A review of multiple databases was
conducted in compliance with PRISMA guidelines until October 2023. A
combination of keywords led to the discovery of an English academic publication
on thyroid cancer and related subjects. 267 papers were returned from the
original search after 109 duplicates were removed. Relevant studies were
selected according to predetermined criteria after 124 articles were eliminated
based on an examination of their abstract and title. After the comprehensive
analysis, an additional six studies were excluded. Among the 28 included
studies, radiomics analysis, which incorporates ultrasound (US) images,
demonstrated its effectiveness in diagnosing thyroid cancer. Various results
were noted, some of the studies presenting new strategies that outperformed the
status quo. The literature has emphasized various challenges faced by AI
models, including interpretability issues, dataset constraints, and operator
dependence. The synthesized findings of the 28 included studies mentioned the
need for standardization efforts and prospective multicenter studies to address
these concerns. Furthermore, approaches to overcome these obstacles were
identified, such as advances in explainable AI technology and personalized
medicine techniques. The review focuses on how AI and radiomics could transform
the diagnosis and treatment of thyroid cancer. Despite challenges, future
research on multidisciplinary cooperation, clinical applicability validation,
and algorithm improvement holds the potential to improve patient outcomes and
diagnostic precision in the treatment of thyroid cancer.|
##### 2404.06181v1 **EPL: Evidential Prototype Learning for Semi-supervised Medical Image Segmentation**
Yuanpeng He et.al.
Although current semi-supervised medical segmentation methods can achieve
decent performance, they are still affected by the uncertainty in unlabeled
data and model predictions, and there is currently a lack of effective
strategies that can explore the uncertain aspects of both simultaneously. To
address the aforementioned issues, we propose Evidential Prototype Learning
(EPL), which utilizes an extended probabilistic framework to effectively fuse
voxel probability predictions from different sources and achieves prototype
fusion utilization of labeled and unlabeled data under a generalized evidential
framework, leveraging voxel-level dual uncertainty masking. The uncertainty not
only enables the model to self-correct predictions but also improves the guided
learning process with pseudo-labels and is able to feed back into the
construction of hidden features. The method proposed in this paper has been
experimented on LA, Pancreas-CT and TBAD datasets, achieving the
state-of-the-art performance in three different labeled ratios, which strongly
demonstrates the effectiveness of our strategy.|
##### 2404.06177v2 **Uncertainty-aware Evidential Fusion-based Learning for Semi-supervised Medical Image Segmentation**
Yuanpeng He et.al.
Although the existing uncertainty-based semi-supervised medical segmentation
methods have achieved excellent performance, they usually only consider a
single uncertainty evaluation, which often fails to solve the problem related
to credibility completely. Therefore, based on the framework of evidential deep
learning, this paper integrates the evidential predictive results in the
cross-region of mixed and original samples to reallocate the confidence degree
and uncertainty measure of each voxel, which is realized by emphasizing
uncertain information of probability assignments fusion rule of traditional
evidence theory. Furthermore, we design a voxel-level asymptotic learning
strategy by introducing information entropy to combine with the fused
uncertainty measure to estimate voxel prediction more precisely. The model will
gradually pay attention to the prediction results with high uncertainty in the
learning process, to learn the features that are difficult to master. The
experimental results on LA, Pancreas-CT, ACDC and TBAD datasets demonstrate the
superior performance of our proposed method in comparison with the existing
state of the arts.|
##### 2404.05980v3 **Tackling Structural Hallucination in Image Translation with Local Diffusion**
Seunghoi Kim et.al.
Recent developments in diffusion models have advanced conditioned image
generation, yet they struggle with reconstructing out-of-distribution (OOD)
images, such as unseen tumors in medical images, causing "image hallucination"
and risking misdiagnosis. We hypothesize such hallucinations result from local
OOD regions in the conditional images. We verify that partitioning the OOD
region and conducting separate image generations alleviates hallucinations in
several applications. From this, we propose a training-free diffusion framework
that reduces hallucination with multiple Local Diffusion processes. Our
approach involves OOD estimation followed by two modules: a "branching" module
generates locally both within and outside OOD regions, and a "fusion" module
integrates these predictions into one. Our evaluation shows our method
mitigates hallucination over baseline models quantitatively and qualitatively,
reducing misdiagnosis by 40% and 25% in the real-world medical and natural
image datasets, respectively. It also demonstrates compatibility with various
pre-trained diffusion models.|
