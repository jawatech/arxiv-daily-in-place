{"2405.09980": {"publish_time": "2024-05-16", "title": "FinTextQA: A Dataset for Long-form Financial Question Answering", "paper_summary": "Accurate evaluation of financial question answering (QA) systems necessitates\na comprehensive dataset encompassing diverse question types and contexts.\nHowever, current financial QA datasets lack scope diversity and question\ncomplexity. This work introduces FinTextQA, a novel dataset for long-form\nquestion answering (LFQA) in finance. FinTextQA comprises 1,262 high-quality,\nsource-attributed QA pairs extracted and selected from finance textbooks and\ngovernment agency websites.Moreover, we developed a Retrieval-Augmented\nGeneration (RAG)-based LFQA system, comprising an embedder, retriever,\nreranker, and generator. A multi-faceted evaluation approach, including human\nranking, automatic metrics, and GPT-4 scoring, was employed to benchmark the\nperformance of different LFQA system configurations under heightened noisy\nconditions. The results indicate that: (1) Among all compared generators,\nBaichuan2-7B competes closely with GPT-3.5-turbo in accuracy score; (2) The\nmost effective system configuration on our dataset involved setting the\nembedder, retriever, reranker, and generator as Ada2, Automated Merged\nRetrieval, Bge-Reranker-Base, and Baichuan2-7B, respectively; (3) models are\nless susceptible to noise after the length of contexts reaching a specific\nthreshold.", "paper_summary_zh": "\u6e96\u78ba\u8a55\u4f30\u8ca1\u52d9\u554f\u7b54 (QA) \u7cfb\u7d71\u9700\u8981\u4e00\u500b\u5305\u542b\u5404\u7a2e\u554f\u984c\u985e\u578b\u548c\u80cc\u666f\u7684\u7d9c\u5408\u8cc7\u6599\u96c6\u3002\u7136\u800c\uff0c\u7576\u524d\u7684\u8ca1\u52d9 QA \u8cc7\u6599\u96c6\u7f3a\u4e4f\u7bc4\u570d\u7684\u591a\u6a23\u6027\u548c\u554f\u984c\u7684\u8907\u96dc\u6027\u3002\u9019\u9805\u5de5\u4f5c\u5f15\u5165\u4e86 FinTextQA\uff0c\u4e00\u500b\u7528\u65bc\u8ca1\u52d9\u4e2d\u7684\u9577\u7bc7\u554f\u7b54 (LFQA) \u7684\u65b0\u7a4e\u8cc7\u6599\u96c6\u3002FinTextQA \u5305\u542b 1,262 \u500b\u9ad8\u54c1\u8cea\u3001\u4f86\u6e90\u660e\u78ba\u7684 QA \u5c0d\uff0c\u5f9e\u8ca1\u52d9\u6559\u79d1\u66f8\u548c\u653f\u5e9c\u6a5f\u69cb\u7db2\u7ad9\u4e2d\u63d0\u53d6\u548c\u9078\u53d6\u3002\u6b64\u5916\uff0c\u6211\u5011\u958b\u767c\u4e86\u4e00\u500b\u57fa\u65bc\u6aa2\u7d22\u589e\u5f37\u751f\u6210 (RAG) \u7684 LFQA \u7cfb\u7d71\uff0c\u5305\u62ec\u5d4c\u5165\u5668\u3001\u6aa2\u7d22\u5668\u3001\u91cd\u65b0\u6392\u5e8f\u5668\u548c\u751f\u6210\u5668\u3002\u63a1\u7528\u4e86\u4e00\u500b\u591a\u65b9\u9762\u7684\u8a55\u4f30\u65b9\u6cd5\uff0c\u5305\u62ec\u4eba\u5de5\u6392\u540d\u3001\u81ea\u52d5\u5316\u6307\u6a19\u548c GPT-4 \u8a55\u5206\uff0c\u7528\u65bc\u5728\u52a0\u5f37\u7684\u96dc\u8a0a\u689d\u4ef6\u4e0b\u5c0d\u4e0d\u540c LFQA \u7cfb\u7d71\u7d44\u614b\u7684\u6548\u80fd\u9032\u884c\u57fa\u6e96\u6e2c\u8a66\u3002\u7d50\u679c\u8868\u660e\uff1a(1) \u5728\u6240\u6709\u6bd4\u8f03\u904e\u7684\u751f\u6210\u5668\u4e2d\uff0cBaichuan2-7B \u5728\u6e96\u78ba\u5ea6\u5206\u6578\u4e0a\u8207 GPT-3.5-turbo \u7af6\u722d\u6fc0\u70c8\uff1b(2) \u5728\u6211\u5011\u7684\u8cc7\u6599\u96c6\u4e0a\u6700\u6709\u6548\u7684\u7cfb\u7d71\u7d44\u614b\u6d89\u53ca\u5c07\u5d4c\u5165\u5668\u3001\u6aa2\u7d22\u5668\u3001\u91cd\u65b0\u6392\u5e8f\u5668\u548c\u751f\u6210\u5668\u5206\u5225\u8a2d\u5b9a\u70ba Ada2\u3001\u81ea\u52d5\u5408\u4f75\u6aa2\u7d22\u3001Bge-Reranker-Base \u548c Baichuan2-7B\uff1b(3) \u5728\u80cc\u666f\u9577\u5ea6\u9054\u5230\u7279\u5b9a\u95be\u503c\u5f8c\uff0c\u6a21\u578b\u5c0d\u96dc\u8a0a\u7684\u5f71\u97ff\u8f03\u5c0f\u3002", "author": "Jian Chen et.al.", "authors": "Jian Chen, Peilin Zhou, Yining Hua, Yingxin Loh, Kehui Chen, Ziyuan Li, Bing Zhu, Junwei Liang", "id": "2405.09980v1", "paper_url": "http://arxiv.org/abs/2405.09980v1", "repo": "null"}}