{"2412.12609": {"publish_time": "2024-12-17", "title": "MultiLingPoT: Enhancing Mathematical Reasoning with Multilingual Program Fine-tuning", "paper_summary": "Program-of-Thought (PoT), which aims to use programming language instead of\nnatural language as an intermediate step in reasoning, is an important way for\nLLMs to solve mathematical problems. Since different programming languages\nexcel in different areas, it is natural to use the most suitable language for\nsolving specific problems. However, current PoT research only focuses on single\nlanguage PoT, ignoring the differences between different programming languages.\nTherefore, this paper proposes an multilingual program reasoning method,\nMultiLingPoT. This method allows the model to answer questions using multiple\nprogramming languages by fine-tuning on multilingual data. Additionally, prior\nand posterior hybrid methods are used to help the model select the most\nsuitable language for each problem. Our experimental results show that the\ntraining of MultiLingPoT improves each program's mathematical reasoning by\nabout 2.5\\%. Moreover, with proper mixing, the performance of MultiLingPoT can\nbe further improved, achieving a 6\\% increase compared to the single-language\nPoT with the data augmentation.Resources of this paper can be found at\nhttps://github.com/Nianqi-Li/MultiLingPoT.", "paper_summary_zh": "\u601d\u60f3\u7a0b\u5f0f\uff08PoT\uff09\u65e8\u5728\u4f7f\u7528\u7a0b\u5f0f\u8a9e\u8a00\u800c\u975e\u81ea\u7136\u8a9e\u8a00\u4f5c\u70ba\u63a8\u7406\u7684\u6b65\u9a5f\uff0c\u662f LLM \u89e3\u6c7a\u6578\u5b78\u554f\u984c\u7684\u91cd\u8981\u65b9\u5f0f\u3002\u7531\u65bc\u4e0d\u540c\u7684\u7a0b\u5f0f\u8a9e\u8a00\u64c5\u9577\u4e0d\u540c\u7684\u9818\u57df\uff0c\u56e0\u6b64\u4f7f\u7528\u6700\u9069\u5408\u7684\u8a9e\u8a00\u4f86\u89e3\u6c7a\u7279\u5b9a\u554f\u984c\u662f\u7406\u6240\u7576\u7136\u7684\u3002\u7136\u800c\uff0c\u76ee\u524d\u7684 PoT \u7814\u7a76\u50c5\u5c08\u6ce8\u65bc\u55ae\u4e00\u8a9e\u8a00 PoT\uff0c\u800c\u5ffd\u7565\u4e86\u4e0d\u540c\u7a0b\u5f0f\u8a9e\u8a00\u4e4b\u9593\u7684\u5dee\u7570\u3002\u56e0\u6b64\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u7a2e\u591a\u8a9e\u8a00\u7a0b\u5f0f\u63a8\u7406\u65b9\u6cd5 MultiLingPoT\u3002\u6b64\u65b9\u6cd5\u5141\u8a31\u6a21\u578b\u900f\u904e\u5c0d\u591a\u8a9e\u8a00\u8cc7\u6599\u9032\u884c\u5fae\u8abf\uff0c\u4f7f\u7528\u591a\u7a2e\u7a0b\u5f0f\u8a9e\u8a00\u4f86\u56de\u7b54\u554f\u984c\u3002\u6b64\u5916\uff0c\u4f7f\u7528\u5148\u9a57\u548c\u5f8c\u9a57\u6df7\u5408\u65b9\u6cd5\u4f86\u5e6b\u52a9\u6a21\u578b\u70ba\u6bcf\u500b\u554f\u984c\u9078\u64c7\u6700\u5408\u9069\u7684\u8a9e\u8a00\u3002\u6211\u5011\u7684\u5be6\u9a57\u7d50\u679c\u8868\u660e\uff0cMultiLingPoT \u7684\u8a13\u7df4\u5c07\u6bcf\u500b\u7a0b\u5f0f\u7684\u6578\u5b78\u63a8\u7406\u80fd\u529b\u63d0\u9ad8\u4e86\u7d04 2.5%\u3002\u6b64\u5916\uff0c\u900f\u904e\u9069\u7576\u7684\u6df7\u5408\uff0cMultiLingPoT \u7684\u6548\u80fd\u53ef\u4ee5\u9032\u4e00\u6b65\u63d0\u9ad8\uff0c\u8207\u4f7f\u7528\u8cc7\u6599\u64f4\u5145\u7684\u55ae\u4e00\u8a9e\u8a00 PoT \u76f8\u6bd4\uff0c\u63d0\u9ad8\u4e86 6%\u3002\u672c\u6587\u7684\u8cc7\u6e90\u53ef\u4ee5\u5728 https://github.com/Nianqi-Li/MultiLingPoT \u627e\u5230\u3002", "author": "Nianqi Li et.al.", "authors": "Nianqi Li, Zujie Liang, Siyu Yuan, Jiaqing Liang, Feng Wei, Yanghua Xiao", "id": "2412.12609v1", "paper_url": "http://arxiv.org/abs/2412.12609v1", "repo": "https://github.com/nianqi-li/multilingpot"}}