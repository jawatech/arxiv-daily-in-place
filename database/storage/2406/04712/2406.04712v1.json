{"2406.04712": {"publish_time": "2024-06-07", "title": "AICoderEval: Improving AI Domain Code Generation of Large Language Models", "paper_summary": "Automated code generation is a pivotal capability of large language models\n(LLMs). However, assessing this capability in real-world scenarios remains\nchallenging. Previous methods focus more on low-level code generation, such as\nmodel loading, instead of generating high-level codes catering for real-world\ntasks, such as image-to-text, text classification, in various domains.\nTherefore, we construct AICoderEval, a dataset focused on real-world tasks in\nvarious domains based on HuggingFace, PyTorch, and TensorFlow, along with\ncomprehensive metrics for evaluation and enhancing LLMs' task-specific code\ngeneration capability. AICoderEval contains test cases and complete programs\nfor automated evaluation of these tasks, covering domains such as natural\nlanguage processing, computer vision, and multimodal learning. To facilitate\nresearch in this area, we open-source the AICoderEval dataset at\n\\url{https://huggingface.co/datasets/vixuowis/AICoderEval}. After that, we\npropose CoderGen, an agent-based framework, to help LLMs generate codes related\nto real-world tasks on the constructed AICoderEval. Moreover, we train a more\npowerful task-specific code generation model, named AICoder, which is refined\non llama-3 based on AICoderEval. Our experiments demonstrate the effectiveness\nof CoderGen in improving LLMs' task-specific code generation capability (by\n12.00\\% on pass@1 for original model and 9.50\\% on pass@1 for ReAct Agent).\nAICoder also outperforms current code generation LLMs, indicating the great\nquality of the AICoderEval benchmark.", "paper_summary_zh": "<paragraph>\u81ea\u52d5\u7a0b\u5f0f\u78bc\u7522\u751f\u662f\u5927\u8a9e\u8a00\u6a21\u578b (LLM) \u7684\u95dc\u9375\u80fd\u529b\u3002\u7136\u800c\uff0c\u5728\u73fe\u5be6\u4e16\u754c\u7684\u5834\u666f\u4e2d\u8a55\u4f30\u6b64\u80fd\u529b\u4ecd\u7136\u5177\u6709\u6311\u6230\u6027\u3002\u5148\u524d\u7684\u505a\u6cd5\u66f4\u5c08\u6ce8\u65bc\u4f4e\u5c64\u7d1a\u7a0b\u5f0f\u78bc\u7522\u751f\uff0c\u4f8b\u5982\u6a21\u578b\u8f09\u5165\uff0c\u800c\u4e0d\u662f\u7522\u751f\u9069\u7528\u65bc\u73fe\u5be6\u4e16\u754c\u4efb\u52d9\u7684\u9ad8\u5c64\u7d1a\u7a0b\u5f0f\u78bc\uff0c\u4f8b\u5982\u5f71\u50cf\u8f49\u6587\u5b57\u3001\u6587\u5b57\u5206\u985e\u7b49\uff0c\u6db5\u84cb\u5404\u7a2e\u9818\u57df\u3002\u56e0\u6b64\uff0c\u6211\u5011\u5efa\u69cb\u4e86 AICoderEval\uff0c\u4e00\u500b\u5c08\u6ce8\u65bc\u5404\u7a2e\u9818\u57df\u7684\u73fe\u5be6\u4e16\u754c\u4efb\u52d9\u7684\u8cc7\u6599\u96c6\uff0c\u57fa\u65bc HuggingFace\u3001PyTorch \u548c TensorFlow\uff0c\u4ee5\u53ca\u7528\u65bc\u8a55\u4f30\u548c\u589e\u5f37 LLM \u4efb\u52d9\u7279\u5b9a\u7a0b\u5f0f\u78bc\u7522\u751f\u80fd\u529b\u7684\u7d9c\u5408\u6307\u6a19\u3002AICoderEval \u5305\u542b\u6e2c\u8a66\u6848\u4f8b\u548c\u5b8c\u6574\u7a0b\u5f0f\uff0c\u7528\u65bc\u81ea\u52d5\u8a55\u4f30\u9019\u4e9b\u4efb\u52d9\uff0c\u6db5\u84cb\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u3001\u96fb\u8166\u8996\u89ba\u548c\u591a\u6a21\u614b\u5b78\u7fd2\u7b49\u9818\u57df\u3002\u70ba\u4e86\u4fc3\u9032\u9019\u65b9\u9762\u7684\u7814\u7a76\uff0c\u6211\u5011\u5728 \\url{https://huggingface.co/datasets/vixuowis/AICoderEval} \u958b\u6e90\u4e86 AICoderEval \u8cc7\u6599\u96c6\u3002\u5728\u90a3\u4e4b\u5f8c\uff0c\u6211\u5011\u63d0\u51fa\u4e86\u57fa\u65bc\u4ee3\u7406\u7684\u67b6\u69cb CoderGen\uff0c\u4ee5\u5e6b\u52a9 LLM \u5728\u5efa\u69cb\u7684 AICoderEval \u4e0a\u7522\u751f\u8207\u73fe\u5be6\u4e16\u754c\u4efb\u52d9\u76f8\u95dc\u7684\u7a0b\u5f0f\u78bc\u3002\u6b64\u5916\uff0c\u6211\u5011\u8a13\u7df4\u4e86\u4e00\u500b\u66f4\u5f37\u5927\u7684\u4efb\u52d9\u7279\u5b9a\u7a0b\u5f0f\u78bc\u7522\u751f\u6a21\u578b\uff0c\u7a31\u70ba AICoder\uff0c\u5b83\u6839\u64da AICoderEval \u5728 llama-3 \u4e0a\u9032\u884c\u4e86\u6539\u9032\u3002\u6211\u5011\u7684\u5be6\u9a57\u8b49\u660e\u4e86 CoderGen \u5728\u6539\u9032 LLM \u7684\u4efb\u52d9\u7279\u5b9a\u7a0b\u5f0f\u78bc\u7522\u751f\u80fd\u529b\u65b9\u9762\u7684\u6709\u6548\u6027\uff08\u5c0d\u65bc\u539f\u59cb\u6a21\u578b\uff0cpass@1 \u63d0\u9ad8\u4e86 12.00%\uff0c\u5c0d\u65bc ReAct Agent\uff0cpass@1 \u63d0\u9ad8\u4e86 9.50%\uff09\u3002AICoder \u4e5f\u8d85\u8d8a\u4e86\u76ee\u524d\u7684\u7a0b\u5f0f\u78bc\u7522\u751f LLM\uff0c\u9019\u8868\u793a AICoderEval \u57fa\u6e96\u7684\u54c1\u8cea\u6975\u4f73\u3002</paragraph>", "author": "Yinghui Xia et.al.", "authors": "Yinghui Xia, Yuyan Chen, Tianyu Shi, Jun Wang, Jinsong Yang", "id": "2406.04712v1", "paper_url": "http://arxiv.org/abs/2406.04712v1", "repo": "null"}}