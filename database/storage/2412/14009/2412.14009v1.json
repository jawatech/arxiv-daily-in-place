{"2412.14009": {"publish_time": "2024-12-18", "title": "Cognition Chain for Explainable Psychological Stress Detection on Social Media", "paper_summary": "Stress is a pervasive global health issue that can lead to severe mental\nhealth problems. Early detection offers timely intervention and prevention of\nstress-related disorders. The current early detection models perform \"black\nbox\" inference suffering from limited explainability and trust which blocks the\nreal-world clinical application. Thanks to the generative properties introduced\nby the Large Language Models (LLMs), the decision and the prediction from such\nmodels are semi-interpretable through the corresponding description. However,\nthe existing LLMs are mostly trained for general purposes without the guidance\nof psychological cognitive theory. To this end, we first highlight the\nimportance of prior theory with the observation of performance boosted by the\nchain-of-thoughts tailored for stress detection. This method termed Cognition\nChain explicates the generation of stress through a step-by-step cognitive\nperspective based on cognitive appraisal theory with a progress pipeline:\nStimulus $\\rightarrow$ Evaluation $\\rightarrow$ Reaction $\\rightarrow$ Stress\nState, guiding LLMs to provide comprehensive reasoning explanations. We further\nstudy the benefits brought by the proposed Cognition Chain format by utilising\nit as a synthetic dataset generation template for LLMs instruction-tuning and\nintroduce CogInstruct, an instruction-tuning dataset for stress detection. This\ndataset is developed using a three-stage self-reflective annotation pipeline\nthat enables LLMs to autonomously generate and refine instructional data. By\ninstruction-tuning Llama3 with CogInstruct, we develop CogLLM, an explainable\nstress detection model. Evaluations demonstrate that CogLLM achieves\noutstanding performance while enhancing explainability. Our work contributes a\nnovel approach by integrating cognitive theories into LLM reasoning processes,\noffering a promising direction for future explainable AI research.", "paper_summary_zh": "\u58d3\u529b\u662f\u4e00\u500b\u666e\u904d\u7684\u5168\u7403\u6027\u5065\u5eb7\u554f\u984c\uff0c\u53ef\u80fd\u6703\u5c0e\u81f4\u56b4\u91cd\u7684\u7cbe\u795e\n\u5065\u5eb7\u554f\u984c\u3002\u65e9\u671f\u767c\u73fe\u63d0\u4f9b\u53ca\u6642\u7684\u5e72\u9810\u548c\u9810\u9632\n\u58d3\u529b\u76f8\u95dc\u75be\u75c5\u3002\u76ee\u524d\u7684\u65e9\u671f\u767c\u73fe\u6a21\u578b\u57f7\u884c\u300c\u9ed1\n\u76d2\u5b50\u300d\u63a8\u8ad6\uff0c\u5b58\u5728\u53ef\u89e3\u91cb\u6027\u548c\u4fe1\u4efb\u5ea6\u6709\u9650\u7684\u554f\u984c\uff0c\u963b\u7919\u4e86\n\u73fe\u5be6\u4e16\u754c\u7684\u81e8\u5e8a\u61c9\u7528\u3002\u591a\u8667\u4e86\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM) \u5f15\u5165\u7684\u751f\u6210\u5c6c\u6027\uff0c\u6b64\u985e\n\u6a21\u578b\u7684\u6c7a\u7b56\u548c\u9810\u6e2c\u901a\u904e\u5c0d\u61c9\u63cf\u8ff0\u5177\u6709\u534a\u53ef\u89e3\u91cb\u6027\u3002\u7136\u800c\uff0c\n\u73fe\u6709\u7684 LLM \u4e3b\u8981\u91dd\u5c0d\u4e00\u822c\u7528\u9014\u9032\u884c\u8a13\u7df4\uff0c\u6c92\u6709\u5fc3\u7406\u8a8d\u77e5\u7406\u8ad6\u7684\u6307\u5c0e\u3002\u70ba\u6b64\uff0c\u6211\u5011\u9996\u5148\u5f37\u8abf\n\u5148\u9a57\u7406\u8ad6\u7684\u91cd\u8981\u6027\uff0c\u4e26\u89c0\u5bdf\u5230\u91dd\u5c0d\u58d3\u529b\u6aa2\u6e2c\u91cf\u8eab\u5b9a\u5236\u7684\u601d\u60f3\u93c8\u63d0\u5347\u4e86\u6027\u80fd\u3002\u9019\u7a2e\u65b9\u6cd5\u7a31\u70ba\u8a8d\u77e5\n\u93c8\u901a\u904e\u57fa\u65bc\u8a8d\u77e5\u8a55\u4f30\u7406\u8ad6\u7684\u5faa\u5e8f\u6f38\u9032\u7684\u8a8d\u77e5\u8996\u89d2\u95e1\u660e\u4e86\u58d3\u529b\u7684\u7522\u751f\uff0c\u4e26\u5177\u6709\u9032\u5ea6\u7ba1\u9053\uff1a\n\u523a\u6fc0 $\\rightarrow$ \u8a55\u4f30 $\\rightarrow$ \u53cd\u61c9 $\\rightarrow$ \u58d3\u529b\n\u72c0\u614b\uff0c\u6307\u5c0e LLM \u63d0\u4f9b\u5168\u9762\u7684\u63a8\u7406\u89e3\u91cb\u3002\u6211\u5011\u9032\u4e00\u6b65\n\u901a\u904e\u5c07\u5176\u7528\u4f5c LLM \u6307\u4ee4\u8abf\u6574\u7684\u5408\u6210\u6578\u64da\u96c6\u751f\u6210\u6a21\u677f\u4f86\u7814\u7a76\u6240\u63d0\u51fa\u7684\u8a8d\u77e5\u93c8\u683c\u5f0f\u5e36\u4f86\u7684\u512a\u9ede\uff0c\u4e26\u4ecb\u7d39 CogInstruct\uff0c\u9019\u662f\u4e00\u500b\u91dd\u5c0d\u58d3\u529b\u6aa2\u6e2c\u7684\u6307\u4ee4\u8abf\u6574\u6578\u64da\u96c6\u3002\u9019\u500b\n\u6578\u64da\u96c6\u662f\u4f7f\u7528\u4e00\u500b\u4e09\u968e\u6bb5\u7684\u81ea\u7701\u6a19\u8a3b\u7ba1\u9053\u958b\u767c\u7684\uff0c\u4f7f LLM \u80fd\u5920\u81ea\u4e3b\u751f\u6210\u548c\u512a\u5316\u6307\u4ee4\u6578\u64da\u3002\u901a\u904e\n\u4f7f\u7528 CogInstruct \u5c0d Llama3 \u9032\u884c\u6307\u4ee4\u8abf\u6574\uff0c\u6211\u5011\u958b\u767c\u4e86 CogLLM\uff0c\u9019\u662f\u4e00\u500b\u53ef\u89e3\u91cb\u7684\n\u58d3\u529b\u6aa2\u6e2c\u6a21\u578b\u3002\u8a55\u4f30\u8868\u660e\uff0cCogLLM \u5728\u63d0\u9ad8\u53ef\u89e3\u91cb\u6027\u7684\u540c\u6642\u5be6\u73fe\u4e86\u51fa\u8272\u7684\u6027\u80fd\u3002\u6211\u5011\u7684\u7814\u7a76\u901a\u904e\u5c07\u8a8d\u77e5\u7406\u8ad6\u6574\u5408\u5230 LLM \u63a8\u7406\u904e\u7a0b\u4e2d\uff0c\u63d0\u51fa\u4e86\u4e00\u7a2e\u65b0\u7a4e\u7684\u65b9\u6cd5\uff0c\n\u70ba\u672a\u4f86\u7684\u53ef\u89e3\u91cb\u4eba\u5de5\u667a\u80fd\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u500b\u6709\u5e0c\u671b\u7684\u65b9\u5411\u3002", "author": "Xin Wang et.al.", "authors": "Xin Wang, Boyan Gao, Yi Dai, Lei Cao, Liang Zhao, Yibo Yang, David Clifton", "id": "2412.14009v1", "paper_url": "http://arxiv.org/abs/2412.14009v1", "repo": "null"}}